Epoch: 1| Step: 0
Training loss: 2.831264713072284
Validation loss: 3.402026529922216

Epoch: 6| Step: 1
Training loss: 3.474156333546237
Validation loss: 3.386013991649761

Epoch: 6| Step: 2
Training loss: 3.752285959949206
Validation loss: 3.371417345743372

Epoch: 6| Step: 3
Training loss: 3.7496508117859655
Validation loss: 3.3545340263796697

Epoch: 6| Step: 4
Training loss: 3.5406724918207186
Validation loss: 3.335529347092352

Epoch: 6| Step: 5
Training loss: 3.2575323409775456
Validation loss: 3.3211876168480345

Epoch: 6| Step: 6
Training loss: 3.6377844473140004
Validation loss: 3.3050657135571435

Epoch: 6| Step: 7
Training loss: 3.0096040220648472
Validation loss: 3.2866898267238183

Epoch: 6| Step: 8
Training loss: 3.185351526572751
Validation loss: 3.27404073105202

Epoch: 6| Step: 9
Training loss: 3.150029463857274
Validation loss: 3.257186670972693

Epoch: 6| Step: 10
Training loss: 2.9324913340877092
Validation loss: 3.2409361113336654

Epoch: 6| Step: 11
Training loss: 4.105341683407657
Validation loss: 3.2238804566935952

Epoch: 6| Step: 12
Training loss: 3.382586394543787
Validation loss: 3.2091924499675226

Epoch: 6| Step: 13
Training loss: 3.680237423245283
Validation loss: 3.191918022742738

Epoch: 2| Step: 0
Training loss: 3.2333475591077865
Validation loss: 3.1722656159811367

Epoch: 6| Step: 1
Training loss: 3.5761845420225553
Validation loss: 3.156592762782533

Epoch: 6| Step: 2
Training loss: 3.1658517558609547
Validation loss: 3.1366903478746693

Epoch: 6| Step: 3
Training loss: 3.5474710509803944
Validation loss: 3.1146313505181857

Epoch: 6| Step: 4
Training loss: 3.470137722349468
Validation loss: 3.094419541782857

Epoch: 6| Step: 5
Training loss: 3.0611857494186543
Validation loss: 3.073484999692525

Epoch: 6| Step: 6
Training loss: 2.944725888874533
Validation loss: 3.052052668047451

Epoch: 6| Step: 7
Training loss: 3.3266558202695395
Validation loss: 3.034161025260941

Epoch: 6| Step: 8
Training loss: 2.6511472270062058
Validation loss: 3.009739259492559

Epoch: 6| Step: 9
Training loss: 2.912737752354176
Validation loss: 2.983941211430704

Epoch: 6| Step: 10
Training loss: 2.8498777664474324
Validation loss: 2.9651035334076443

Epoch: 6| Step: 11
Training loss: 3.074934026739245
Validation loss: 2.94284055069599

Epoch: 6| Step: 12
Training loss: 3.365196117110593
Validation loss: 2.918525938790935

Epoch: 6| Step: 13
Training loss: 2.996083882500863
Validation loss: 2.8933025434352904

Epoch: 3| Step: 0
Training loss: 2.2311241135760835
Validation loss: 2.867017001176696

Epoch: 6| Step: 1
Training loss: 3.0173736404219293
Validation loss: 2.8409156647808427

Epoch: 6| Step: 2
Training loss: 3.099489994550452
Validation loss: 2.8188198856281166

Epoch: 6| Step: 3
Training loss: 2.792012169557299
Validation loss: 2.792557465119395

Epoch: 6| Step: 4
Training loss: 3.4456846421129526
Validation loss: 2.7651106145920945

Epoch: 6| Step: 5
Training loss: 2.671477349566724
Validation loss: 2.7354160615833676

Epoch: 6| Step: 6
Training loss: 2.789127124710857
Validation loss: 2.7090005541820013

Epoch: 6| Step: 7
Training loss: 2.3238958054262113
Validation loss: 2.6810894293377627

Epoch: 6| Step: 8
Training loss: 2.951982065068789
Validation loss: 2.6536370084776184

Epoch: 6| Step: 9
Training loss: 2.7599544690011597
Validation loss: 2.6235836991784827

Epoch: 6| Step: 10
Training loss: 2.704968832404053
Validation loss: 2.592526066648125

Epoch: 6| Step: 11
Training loss: 2.9204811402639135
Validation loss: 2.5729662366614523

Epoch: 6| Step: 12
Training loss: 2.725934587551644
Validation loss: 2.54662437219933

Epoch: 6| Step: 13
Training loss: 2.624777375726415
Validation loss: 2.526067538309173

Epoch: 4| Step: 0
Training loss: 2.067150767858529
Validation loss: 2.5155025476068595

Epoch: 6| Step: 1
Training loss: 2.5270480848235266
Validation loss: 2.502202097297257

Epoch: 6| Step: 2
Training loss: 2.69212812202139
Validation loss: 2.479714514736039

Epoch: 6| Step: 3
Training loss: 2.5709939070829337
Validation loss: 2.4725818271294457

Epoch: 6| Step: 4
Training loss: 2.264454506371409
Validation loss: 2.460521004768879

Epoch: 6| Step: 5
Training loss: 3.0740166371080826
Validation loss: 2.4553153187215804

Epoch: 6| Step: 6
Training loss: 2.6943647846974206
Validation loss: 2.4566413800539713

Epoch: 6| Step: 7
Training loss: 2.268934897042355
Validation loss: 2.4523961144550475

Epoch: 6| Step: 8
Training loss: 2.6605488715684498
Validation loss: 2.4449546804043965

Epoch: 6| Step: 9
Training loss: 2.7230410858035845
Validation loss: 2.444778335290055

Epoch: 6| Step: 10
Training loss: 2.144790828260641
Validation loss: 2.461063329315582

Epoch: 6| Step: 11
Training loss: 2.2166809320588343
Validation loss: 2.460235156395627

Epoch: 6| Step: 12
Training loss: 2.6344245480621327
Validation loss: 2.4669565696300446

Epoch: 6| Step: 13
Training loss: 2.3227689436625654
Validation loss: 2.4763711721038875

Epoch: 5| Step: 0
Training loss: 2.6756638995423563
Validation loss: 2.477267336501491

Epoch: 6| Step: 1
Training loss: 2.427113632427785
Validation loss: 2.4770255473214093

Epoch: 6| Step: 2
Training loss: 2.59277196621898
Validation loss: 2.4821365956864248

Epoch: 6| Step: 3
Training loss: 2.0524191283115827
Validation loss: 2.476102495442629

Epoch: 6| Step: 4
Training loss: 1.7079664937469374
Validation loss: 2.491235070714194

Epoch: 6| Step: 5
Training loss: 2.189891271112992
Validation loss: 2.4919172756339454

Epoch: 6| Step: 6
Training loss: 3.28975237137661
Validation loss: 2.4930518952262832

Epoch: 6| Step: 7
Training loss: 2.9780074489646373
Validation loss: 2.493106859813281

Epoch: 6| Step: 8
Training loss: 2.711148036729641
Validation loss: 2.5004612417707657

Epoch: 6| Step: 9
Training loss: 2.373460270544521
Validation loss: 2.486893742610471

Epoch: 6| Step: 10
Training loss: 2.376207747307002
Validation loss: 2.4832804525962104

Epoch: 6| Step: 11
Training loss: 2.7984511553475375
Validation loss: 2.4764251349989066

Epoch: 6| Step: 12
Training loss: 2.691538238610922
Validation loss: 2.4767167357222246

Epoch: 6| Step: 13
Training loss: 1.9655136270916773
Validation loss: 2.470382601286014

Epoch: 6| Step: 0
Training loss: 2.7371790867656696
Validation loss: 2.4675401386885736

Epoch: 6| Step: 1
Training loss: 2.082815741774718
Validation loss: 2.458778273732292

Epoch: 6| Step: 2
Training loss: 2.216843551614869
Validation loss: 2.4511450453223307

Epoch: 6| Step: 3
Training loss: 3.0781662062002377
Validation loss: 2.452950748807077

Epoch: 6| Step: 4
Training loss: 2.784463804393678
Validation loss: 2.4556407137191885

Epoch: 6| Step: 5
Training loss: 1.8578011399315606
Validation loss: 2.447096266471747

Epoch: 6| Step: 6
Training loss: 1.7702507257415616
Validation loss: 2.4426224021735776

Epoch: 6| Step: 7
Training loss: 2.705443341771753
Validation loss: 2.4501921987076667

Epoch: 6| Step: 8
Training loss: 2.4060701575510763
Validation loss: 2.4376605380409986

Epoch: 6| Step: 9
Training loss: 2.780495787808226
Validation loss: 2.4440488871556356

Epoch: 6| Step: 10
Training loss: 2.2695747410715645
Validation loss: 2.441268868204967

Epoch: 6| Step: 11
Training loss: 2.602934787573791
Validation loss: 2.4511298065830975

Epoch: 6| Step: 12
Training loss: 2.570340512943378
Validation loss: 2.433204313563597

Epoch: 6| Step: 13
Training loss: 2.6620591313524833
Validation loss: 2.4445074541708203

Epoch: 7| Step: 0
Training loss: 1.9868614658543937
Validation loss: 2.4385002072957143

Epoch: 6| Step: 1
Training loss: 2.251553740739164
Validation loss: 2.441189492330825

Epoch: 6| Step: 2
Training loss: 2.415133932913434
Validation loss: 2.4357431715536397

Epoch: 6| Step: 3
Training loss: 2.3986127460088595
Validation loss: 2.4421666133652122

Epoch: 6| Step: 4
Training loss: 2.952986779586078
Validation loss: 2.4350375591517213

Epoch: 6| Step: 5
Training loss: 1.9911380172630633
Validation loss: 2.4412090740689645

Epoch: 6| Step: 6
Training loss: 2.5844999160928945
Validation loss: 2.4317291447921145

Epoch: 6| Step: 7
Training loss: 2.6915701275058277
Validation loss: 2.4391569065132876

Epoch: 6| Step: 8
Training loss: 2.51574915230081
Validation loss: 2.4392672270166225

Epoch: 6| Step: 9
Training loss: 2.6383414241580763
Validation loss: 2.4437062814871906

Epoch: 6| Step: 10
Training loss: 2.512091482932464
Validation loss: 2.4341200519169894

Epoch: 6| Step: 11
Training loss: 2.9588880063721454
Validation loss: 2.4314991451504837

Epoch: 6| Step: 12
Training loss: 2.12618020886721
Validation loss: 2.4373221862362073

Epoch: 6| Step: 13
Training loss: 2.8091915592647445
Validation loss: 2.439817394774256

Epoch: 8| Step: 0
Training loss: 2.723316960777769
Validation loss: 2.439468925349568

Epoch: 6| Step: 1
Training loss: 1.7223030126073426
Validation loss: 2.445524797577861

Epoch: 6| Step: 2
Training loss: 2.8187411255284442
Validation loss: 2.434487102834516

Epoch: 6| Step: 3
Training loss: 2.5079454998744644
Validation loss: 2.4352094043767734

Epoch: 6| Step: 4
Training loss: 2.1113421274685997
Validation loss: 2.436387713059723

Epoch: 6| Step: 5
Training loss: 2.305427044679012
Validation loss: 2.4301498480173116

Epoch: 6| Step: 6
Training loss: 2.3598187768182175
Validation loss: 2.424538409161125

Epoch: 6| Step: 7
Training loss: 2.489474933983054
Validation loss: 2.4359426169253005

Epoch: 6| Step: 8
Training loss: 2.9588407878218494
Validation loss: 2.431748214445455

Epoch: 6| Step: 9
Training loss: 2.413584640267431
Validation loss: 2.423194952148498

Epoch: 6| Step: 10
Training loss: 2.470469202117946
Validation loss: 2.4350133748506386

Epoch: 6| Step: 11
Training loss: 2.4321400324887295
Validation loss: 2.4317729214345913

Epoch: 6| Step: 12
Training loss: 2.464551228184891
Validation loss: 2.423428486377474

Epoch: 6| Step: 13
Training loss: 2.7959347641610552
Validation loss: 2.433547083293446

Epoch: 9| Step: 0
Training loss: 2.450220806525898
Validation loss: 2.441110740579214

Epoch: 6| Step: 1
Training loss: 2.504568122593772
Validation loss: 2.4432266731929855

Epoch: 6| Step: 2
Training loss: 2.4257748614486627
Validation loss: 2.4389026306791535

Epoch: 6| Step: 3
Training loss: 3.256813682926214
Validation loss: 2.4296656584090166

Epoch: 6| Step: 4
Training loss: 2.4643676104472294
Validation loss: 2.433452228576521

Epoch: 6| Step: 5
Training loss: 2.3058752070702035
Validation loss: 2.4335791198062107

Epoch: 6| Step: 6
Training loss: 2.7528993754428215
Validation loss: 2.44008391923894

Epoch: 6| Step: 7
Training loss: 2.5395270758873667
Validation loss: 2.4404725916544643

Epoch: 6| Step: 8
Training loss: 2.3501085621532996
Validation loss: 2.427537348990624

Epoch: 6| Step: 9
Training loss: 2.1224929381703506
Validation loss: 2.428983711127334

Epoch: 6| Step: 10
Training loss: 2.2220550421241803
Validation loss: 2.4221120246654766

Epoch: 6| Step: 11
Training loss: 2.1351812713642073
Validation loss: 2.4292753141871213

Epoch: 6| Step: 12
Training loss: 2.7164495096610204
Validation loss: 2.4409728782029503

Epoch: 6| Step: 13
Training loss: 2.345742764483451
Validation loss: 2.423395249871387

Epoch: 10| Step: 0
Training loss: 2.8183405948893525
Validation loss: 2.43090062250223

Epoch: 6| Step: 1
Training loss: 2.3537816320756226
Validation loss: 2.435125465920551

Epoch: 6| Step: 2
Training loss: 2.650049129966339
Validation loss: 2.424100726810867

Epoch: 6| Step: 3
Training loss: 2.5393907540217846
Validation loss: 2.427937145977109

Epoch: 6| Step: 4
Training loss: 2.396158235053468
Validation loss: 2.421139053588858

Epoch: 6| Step: 5
Training loss: 2.8050073637840183
Validation loss: 2.4239312415636984

Epoch: 6| Step: 6
Training loss: 2.90059875358045
Validation loss: 2.4195977282031587

Epoch: 6| Step: 7
Training loss: 2.590322412873872
Validation loss: 2.4192622375883075

Epoch: 6| Step: 8
Training loss: 2.591953068779293
Validation loss: 2.423809345509714

Epoch: 6| Step: 9
Training loss: 2.7255344146811966
Validation loss: 2.421911005552354

Epoch: 6| Step: 10
Training loss: 2.2417686150872234
Validation loss: 2.4162701796708466

Epoch: 6| Step: 11
Training loss: 1.6986433787004644
Validation loss: 2.4222892981126383

Epoch: 6| Step: 12
Training loss: 2.420408629447143
Validation loss: 2.4232629798014966

Epoch: 6| Step: 13
Training loss: 1.9562505508763326
Validation loss: 2.421386973114421

Epoch: 11| Step: 0
Training loss: 2.029059769819389
Validation loss: 2.424582643414303

Epoch: 6| Step: 1
Training loss: 1.9775775218096623
Validation loss: 2.420966324515412

Epoch: 6| Step: 2
Training loss: 2.356540821857446
Validation loss: 2.4291978528707427

Epoch: 6| Step: 3
Training loss: 2.8736904313001927
Validation loss: 2.4235734951837147

Epoch: 6| Step: 4
Training loss: 2.469903797021359
Validation loss: 2.430789235704266

Epoch: 6| Step: 5
Training loss: 1.7220135309394422
Validation loss: 2.432862606198182

Epoch: 6| Step: 6
Training loss: 2.156471351650822
Validation loss: 2.427106428786865

Epoch: 6| Step: 7
Training loss: 2.1758651854181466
Validation loss: 2.4419071589001464

Epoch: 6| Step: 8
Training loss: 2.7070647178441596
Validation loss: 2.434065322538042

Epoch: 6| Step: 9
Training loss: 3.089962577222853
Validation loss: 2.433385277764141

Epoch: 6| Step: 10
Training loss: 2.7715106987055904
Validation loss: 2.4449294890239326

Epoch: 6| Step: 11
Training loss: 2.205735519982518
Validation loss: 2.4482541818810613

Epoch: 6| Step: 12
Training loss: 3.187162493620648
Validation loss: 2.448972406729551

Epoch: 6| Step: 13
Training loss: 2.5970166329551496
Validation loss: 2.4364700586744372

Epoch: 12| Step: 0
Training loss: 3.134026270870094
Validation loss: 2.428867115725113

Epoch: 6| Step: 1
Training loss: 2.0085780246613134
Validation loss: 2.4285900339981987

Epoch: 6| Step: 2
Training loss: 2.78115578824041
Validation loss: 2.4352355611232315

Epoch: 6| Step: 3
Training loss: 2.8248209331103067
Validation loss: 2.426668489118388

Epoch: 6| Step: 4
Training loss: 2.0329986088302814
Validation loss: 2.41827126101494

Epoch: 6| Step: 5
Training loss: 2.018015309150024
Validation loss: 2.4261873307700825

Epoch: 6| Step: 6
Training loss: 2.021838878562458
Validation loss: 2.4200433511240207

Epoch: 6| Step: 7
Training loss: 2.2357334728975897
Validation loss: 2.4165248884070047

Epoch: 6| Step: 8
Training loss: 2.958002815229767
Validation loss: 2.4241809490837003

Epoch: 6| Step: 9
Training loss: 2.7972783485126427
Validation loss: 2.426761889694135

Epoch: 6| Step: 10
Training loss: 2.8831231174756415
Validation loss: 2.424272511351526

Epoch: 6| Step: 11
Training loss: 2.4639293104906086
Validation loss: 2.4140631748762287

Epoch: 6| Step: 12
Training loss: 2.368398023236839
Validation loss: 2.426605723352866

Epoch: 6| Step: 13
Training loss: 1.7006046650325133
Validation loss: 2.418625897912814

Epoch: 13| Step: 0
Training loss: 2.6069432422940246
Validation loss: 2.4212336767825104

Epoch: 6| Step: 1
Training loss: 2.839895801513173
Validation loss: 2.416543157205684

Epoch: 6| Step: 2
Training loss: 2.5656438011381955
Validation loss: 2.4212542486933066

Epoch: 6| Step: 3
Training loss: 2.6106752365498975
Validation loss: 2.414821781061396

Epoch: 6| Step: 4
Training loss: 2.4894070316813934
Validation loss: 2.4219236143421807

Epoch: 6| Step: 5
Training loss: 2.774815348762249
Validation loss: 2.414502956532606

Epoch: 6| Step: 6
Training loss: 2.1414693016614774
Validation loss: 2.408358941937507

Epoch: 6| Step: 7
Training loss: 2.5600296766825976
Validation loss: 2.4227856800450334

Epoch: 6| Step: 8
Training loss: 3.025326633946396
Validation loss: 2.406473710861349

Epoch: 6| Step: 9
Training loss: 1.9949459351596988
Validation loss: 2.417787166056957

Epoch: 6| Step: 10
Training loss: 2.5504783929606196
Validation loss: 2.4162262043814824

Epoch: 6| Step: 11
Training loss: 2.4740127289798446
Validation loss: 2.4142886717357133

Epoch: 6| Step: 12
Training loss: 1.749014440669909
Validation loss: 2.4197483857502164

Epoch: 6| Step: 13
Training loss: 1.859678355883433
Validation loss: 2.4118075080226857

Epoch: 14| Step: 0
Training loss: 2.6642731614038113
Validation loss: 2.4205782956779567

Epoch: 6| Step: 1
Training loss: 2.701150338286341
Validation loss: 2.420357522038831

Epoch: 6| Step: 2
Training loss: 2.192821134322206
Validation loss: 2.414904845596261

Epoch: 6| Step: 3
Training loss: 2.4653085793255958
Validation loss: 2.4193545772866822

Epoch: 6| Step: 4
Training loss: 2.575502483635551
Validation loss: 2.423704198988511

Epoch: 6| Step: 5
Training loss: 1.8988410301060317
Validation loss: 2.420095089103008

Epoch: 6| Step: 6
Training loss: 1.9615312262584335
Validation loss: 2.4234706913281796

Epoch: 6| Step: 7
Training loss: 2.4587280042834854
Validation loss: 2.426794588870816

Epoch: 6| Step: 8
Training loss: 2.7465576821837367
Validation loss: 2.4102715166372146

Epoch: 6| Step: 9
Training loss: 2.7188590016931085
Validation loss: 2.419835008771404

Epoch: 6| Step: 10
Training loss: 3.099603529157216
Validation loss: 2.4197045393612377

Epoch: 6| Step: 11
Training loss: 2.242904388981843
Validation loss: 2.4237031579110404

Epoch: 6| Step: 12
Training loss: 2.1279296875
Validation loss: 2.422739018372682

Epoch: 6| Step: 13
Training loss: 2.342509640864153
Validation loss: 2.414680887335587

Epoch: 15| Step: 0
Training loss: 2.7708992531949264
Validation loss: 2.418127717198758

Epoch: 6| Step: 1
Training loss: 2.22539353051581
Validation loss: 2.412641615326556

Epoch: 6| Step: 2
Training loss: 2.911390618826025
Validation loss: 2.4307142666058357

Epoch: 6| Step: 3
Training loss: 2.966576834900894
Validation loss: 2.41067467981599

Epoch: 6| Step: 4
Training loss: 2.2716829536210508
Validation loss: 2.42135398756981

Epoch: 6| Step: 5
Training loss: 2.520938261596368
Validation loss: 2.411803183124387

Epoch: 6| Step: 6
Training loss: 2.1334209761895346
Validation loss: 2.4161838564409823

Epoch: 6| Step: 7
Training loss: 2.039246415653612
Validation loss: 2.4145791695278844

Epoch: 6| Step: 8
Training loss: 2.415871741559862
Validation loss: 2.4170199716942613

Epoch: 6| Step: 9
Training loss: 1.8940221358056064
Validation loss: 2.413590764740094

Epoch: 6| Step: 10
Training loss: 2.0228203380944985
Validation loss: 2.426105487836284

Epoch: 6| Step: 11
Training loss: 2.7288033532358287
Validation loss: 2.4114868513910594

Epoch: 6| Step: 12
Training loss: 2.2623690656848354
Validation loss: 2.4166038494057664

Epoch: 6| Step: 13
Training loss: 2.9646706913837173
Validation loss: 2.4283340953213925

Epoch: 16| Step: 0
Training loss: 2.5259570130521043
Validation loss: 2.4264141409955657

Epoch: 6| Step: 1
Training loss: 3.0965577302734895
Validation loss: 2.415939572452276

Epoch: 6| Step: 2
Training loss: 2.5145308680040137
Validation loss: 2.41025291178965

Epoch: 6| Step: 3
Training loss: 1.878280186390637
Validation loss: 2.41204051384079

Epoch: 6| Step: 4
Training loss: 2.212341294280874
Validation loss: 2.414900880020775

Epoch: 6| Step: 5
Training loss: 2.451230234614027
Validation loss: 2.4055138820252124

Epoch: 6| Step: 6
Training loss: 2.792738941048139
Validation loss: 2.4122708615341137

Epoch: 6| Step: 7
Training loss: 2.03007590767389
Validation loss: 2.414190262229397

Epoch: 6| Step: 8
Training loss: 2.327635438381361
Validation loss: 2.410540269360362

Epoch: 6| Step: 9
Training loss: 2.5139213147773916
Validation loss: 2.403017399317328

Epoch: 6| Step: 10
Training loss: 2.6872311834694544
Validation loss: 2.411632133356152

Epoch: 6| Step: 11
Training loss: 2.5681590419136797
Validation loss: 2.414690678744443

Epoch: 6| Step: 12
Training loss: 2.4139362783673612
Validation loss: 2.415842587178159

Epoch: 6| Step: 13
Training loss: 2.065320254193129
Validation loss: 2.4012875599979235

Epoch: 17| Step: 0
Training loss: 2.5071666991202908
Validation loss: 2.414141097121566

Epoch: 6| Step: 1
Training loss: 1.9204056868512065
Validation loss: 2.4110070472982414

Epoch: 6| Step: 2
Training loss: 2.101114558586862
Validation loss: 2.407038274678619

Epoch: 6| Step: 3
Training loss: 2.5063303908394947
Validation loss: 2.406233172337204

Epoch: 6| Step: 4
Training loss: 1.5505183306917192
Validation loss: 2.4101016771597945

Epoch: 6| Step: 5
Training loss: 2.290376357756178
Validation loss: 2.417284333012104

Epoch: 6| Step: 6
Training loss: 2.4682713298063375
Validation loss: 2.4215114197541494

Epoch: 6| Step: 7
Training loss: 2.9492921529565717
Validation loss: 2.4206340112443736

Epoch: 6| Step: 8
Training loss: 2.633147809780734
Validation loss: 2.4272184757269626

Epoch: 6| Step: 9
Training loss: 3.19660755578827
Validation loss: 2.421546913812592

Epoch: 6| Step: 10
Training loss: 2.7740953981460583
Validation loss: 2.423452655114396

Epoch: 6| Step: 11
Training loss: 2.4601365496566534
Validation loss: 2.418926125487422

Epoch: 6| Step: 12
Training loss: 2.1331603496672673
Validation loss: 2.408094665114508

Epoch: 6| Step: 13
Training loss: 2.566981049476997
Validation loss: 2.4166428685386756

Epoch: 18| Step: 0
Training loss: 2.5591928494090297
Validation loss: 2.401195121269093

Epoch: 6| Step: 1
Training loss: 2.6756233558569535
Validation loss: 2.409995858385424

Epoch: 6| Step: 2
Training loss: 2.0884890149361652
Validation loss: 2.4147974601199778

Epoch: 6| Step: 3
Training loss: 2.7983930506496173
Validation loss: 2.404849268128041

Epoch: 6| Step: 4
Training loss: 2.0289979628265518
Validation loss: 2.400386900313043

Epoch: 6| Step: 5
Training loss: 1.9934785735866336
Validation loss: 2.4071470132699977

Epoch: 6| Step: 6
Training loss: 2.442277871752177
Validation loss: 2.4083076365682827

Epoch: 6| Step: 7
Training loss: 2.302983678987672
Validation loss: 2.3990759978188576

Epoch: 6| Step: 8
Training loss: 3.1354816890492727
Validation loss: 2.399573836637069

Epoch: 6| Step: 9
Training loss: 2.2673513215265673
Validation loss: 2.4010828115340246

Epoch: 6| Step: 10
Training loss: 2.0843330527778767
Validation loss: 2.4087918880075625

Epoch: 6| Step: 11
Training loss: 2.6529702077401356
Validation loss: 2.417873645693148

Epoch: 6| Step: 12
Training loss: 2.103797149945811
Validation loss: 2.4071061233815993

Epoch: 6| Step: 13
Training loss: 2.859702669974055
Validation loss: 2.4128766238614503

Epoch: 19| Step: 0
Training loss: 2.5748401407044876
Validation loss: 2.4061236988295116

Epoch: 6| Step: 1
Training loss: 2.2566023490714344
Validation loss: 2.401467264206849

Epoch: 6| Step: 2
Training loss: 2.688506714097178
Validation loss: 2.4102020918795293

Epoch: 6| Step: 3
Training loss: 2.6923713005852004
Validation loss: 2.406517013993742

Epoch: 6| Step: 4
Training loss: 2.9533904425593938
Validation loss: 2.398721353009632

Epoch: 6| Step: 5
Training loss: 2.495868702565168
Validation loss: 2.406510202780518

Epoch: 6| Step: 6
Training loss: 2.3550383267857624
Validation loss: 2.4014900820387863

Epoch: 6| Step: 7
Training loss: 2.6596258813880147
Validation loss: 2.397030826892902

Epoch: 6| Step: 8
Training loss: 2.536693418497924
Validation loss: 2.399471809624887

Epoch: 6| Step: 9
Training loss: 2.0971829184020416
Validation loss: 2.404146298719457

Epoch: 6| Step: 10
Training loss: 1.792095694813789
Validation loss: 2.39498293061568

Epoch: 6| Step: 11
Training loss: 2.1073820518711903
Validation loss: 2.403902006429655

Epoch: 6| Step: 12
Training loss: 2.2792874608176406
Validation loss: 2.400234034174164

Epoch: 6| Step: 13
Training loss: 2.64593531694882
Validation loss: 2.410979778902223

Epoch: 20| Step: 0
Training loss: 2.3926717934470716
Validation loss: 2.399019947218722

Epoch: 6| Step: 1
Training loss: 2.824887524956703
Validation loss: 2.403410652423031

Epoch: 6| Step: 2
Training loss: 1.9676718408752545
Validation loss: 2.417002117509063

Epoch: 6| Step: 3
Training loss: 2.0756773337245344
Validation loss: 2.4071691334691603

Epoch: 6| Step: 4
Training loss: 2.1899952417261
Validation loss: 2.403155793851301

Epoch: 6| Step: 5
Training loss: 2.4744270817574257
Validation loss: 2.410374512519504

Epoch: 6| Step: 6
Training loss: 2.693476574113436
Validation loss: 2.4165925776426285

Epoch: 6| Step: 7
Training loss: 2.351661249159483
Validation loss: 2.4249948403215082

Epoch: 6| Step: 8
Training loss: 2.6791949917812246
Validation loss: 2.4202617235236352

Epoch: 6| Step: 9
Training loss: 2.4943287419269207
Validation loss: 2.4234507367092135

Epoch: 6| Step: 10
Training loss: 1.8328028113587962
Validation loss: 2.4138940713307604

Epoch: 6| Step: 11
Training loss: 3.2991383092216706
Validation loss: 2.4303006198941444

Epoch: 6| Step: 12
Training loss: 2.1296318287615392
Validation loss: 2.4245211020235966

Epoch: 6| Step: 13
Training loss: 2.5010946738205115
Validation loss: 2.4252408009686177

Epoch: 21| Step: 0
Training loss: 2.248008694560658
Validation loss: 2.428212346650143

Epoch: 6| Step: 1
Training loss: 2.2045919526048885
Validation loss: 2.412748232112668

Epoch: 6| Step: 2
Training loss: 2.417203569512933
Validation loss: 2.4120037843396185

Epoch: 6| Step: 3
Training loss: 2.6880412776479745
Validation loss: 2.4219809150096117

Epoch: 6| Step: 4
Training loss: 2.6005241452595906
Validation loss: 2.4170328854817478

Epoch: 6| Step: 5
Training loss: 2.414774471833114
Validation loss: 2.40247789127314

Epoch: 6| Step: 6
Training loss: 2.3532632652888745
Validation loss: 2.408932499342214

Epoch: 6| Step: 7
Training loss: 2.3339708910436863
Validation loss: 2.4024514688465324

Epoch: 6| Step: 8
Training loss: 2.566549497464838
Validation loss: 2.3971673209439603

Epoch: 6| Step: 9
Training loss: 2.8701643704653517
Validation loss: 2.4060816767885296

Epoch: 6| Step: 10
Training loss: 2.2295340000664696
Validation loss: 2.3959801559794034

Epoch: 6| Step: 11
Training loss: 2.216965938624782
Validation loss: 2.394135650432089

Epoch: 6| Step: 12
Training loss: 2.7998631886709497
Validation loss: 2.4096849950454917

Epoch: 6| Step: 13
Training loss: 2.118426984171998
Validation loss: 2.4072361696372693

Epoch: 22| Step: 0
Training loss: 1.8937575185897184
Validation loss: 2.3945158998911116

Epoch: 6| Step: 1
Training loss: 2.175984398828004
Validation loss: 2.4079288884442587

Epoch: 6| Step: 2
Training loss: 2.622694910768445
Validation loss: 2.4033998809212767

Epoch: 6| Step: 3
Training loss: 2.33486862989331
Validation loss: 2.413066119312441

Epoch: 6| Step: 4
Training loss: 2.4764922219301964
Validation loss: 2.39828011061584

Epoch: 6| Step: 5
Training loss: 1.9092290769466786
Validation loss: 2.3966646134452176

Epoch: 6| Step: 6
Training loss: 1.9992663706884024
Validation loss: 2.412528084309822

Epoch: 6| Step: 7
Training loss: 2.242072763730595
Validation loss: 2.398775919710762

Epoch: 6| Step: 8
Training loss: 2.8128634747769707
Validation loss: 2.407364219871816

Epoch: 6| Step: 9
Training loss: 2.99995024957731
Validation loss: 2.3982848409805224

Epoch: 6| Step: 10
Training loss: 2.6303008916199193
Validation loss: 2.4014517929646866

Epoch: 6| Step: 11
Training loss: 2.4818085663933447
Validation loss: 2.4068145089780892

Epoch: 6| Step: 12
Training loss: 2.977085498108732
Validation loss: 2.4120346984423477

Epoch: 6| Step: 13
Training loss: 2.1441863569572996
Validation loss: 2.398982446913474

Epoch: 23| Step: 0
Training loss: 2.8976026294032806
Validation loss: 2.401449658421847

Epoch: 6| Step: 1
Training loss: 2.639532822685426
Validation loss: 2.404376419367089

Epoch: 6| Step: 2
Training loss: 2.4927840998594246
Validation loss: 2.409968751675745

Epoch: 6| Step: 3
Training loss: 2.1689650986828255
Validation loss: 2.414184312103047

Epoch: 6| Step: 4
Training loss: 2.9337657161855684
Validation loss: 2.4104694758515284

Epoch: 6| Step: 5
Training loss: 2.617610703598467
Validation loss: 2.4046258275264165

Epoch: 6| Step: 6
Training loss: 1.933146230369535
Validation loss: 2.4077099256143577

Epoch: 6| Step: 7
Training loss: 2.3454075356275954
Validation loss: 2.408729464765591

Epoch: 6| Step: 8
Training loss: 1.9583469011634866
Validation loss: 2.4062822348016732

Epoch: 6| Step: 9
Training loss: 2.366106145146514
Validation loss: 2.4154459621707525

Epoch: 6| Step: 10
Training loss: 2.3767867143691728
Validation loss: 2.415380231424456

Epoch: 6| Step: 11
Training loss: 2.5840588340497996
Validation loss: 2.4117752152614855

Epoch: 6| Step: 12
Training loss: 2.4804563507010466
Validation loss: 2.4027719007602717

Epoch: 6| Step: 13
Training loss: 1.910349019002786
Validation loss: 2.401330700163145

Epoch: 24| Step: 0
Training loss: 2.1494476717826116
Validation loss: 2.412504629680823

Epoch: 6| Step: 1
Training loss: 1.6390739011413458
Validation loss: 2.406201234133443

Epoch: 6| Step: 2
Training loss: 2.140312561846106
Validation loss: 2.4014738001562104

Epoch: 6| Step: 3
Training loss: 2.0263283599442743
Validation loss: 2.4035243661152097

Epoch: 6| Step: 4
Training loss: 2.4515386421010374
Validation loss: 2.4185684109651464

Epoch: 6| Step: 5
Training loss: 2.3646897839575125
Validation loss: 2.4213591323597035

Epoch: 6| Step: 6
Training loss: 2.8224872858455474
Validation loss: 2.403756439099851

Epoch: 6| Step: 7
Training loss: 2.779921653796221
Validation loss: 2.408321834545558

Epoch: 6| Step: 8
Training loss: 2.7432215987758326
Validation loss: 2.4176520169421436

Epoch: 6| Step: 9
Training loss: 2.8473332225799837
Validation loss: 2.414640997219227

Epoch: 6| Step: 10
Training loss: 2.7091833590233123
Validation loss: 2.4045361860200107

Epoch: 6| Step: 11
Training loss: 2.60282990796857
Validation loss: 2.398933533311055

Epoch: 6| Step: 12
Training loss: 2.408231637604931
Validation loss: 2.386261941551195

Epoch: 6| Step: 13
Training loss: 1.9325188008882974
Validation loss: 2.401805116389709

Epoch: 25| Step: 0
Training loss: 2.0659965007933296
Validation loss: 2.3955343363957855

Epoch: 6| Step: 1
Training loss: 1.8109268727949341
Validation loss: 2.399355220940042

Epoch: 6| Step: 2
Training loss: 2.4525452918984953
Validation loss: 2.4081669722475976

Epoch: 6| Step: 3
Training loss: 2.0553213091999787
Validation loss: 2.3874117214132977

Epoch: 6| Step: 4
Training loss: 2.6810214000788326
Validation loss: 2.4006001086452113

Epoch: 6| Step: 5
Training loss: 3.1720698254513664
Validation loss: 2.398927255468668

Epoch: 6| Step: 6
Training loss: 2.6997044260223233
Validation loss: 2.400526944566031

Epoch: 6| Step: 7
Training loss: 2.4746706502624765
Validation loss: 2.3933678145125192

Epoch: 6| Step: 8
Training loss: 2.4389039911233654
Validation loss: 2.4008696626189545

Epoch: 6| Step: 9
Training loss: 2.5385989661018455
Validation loss: 2.4055516108841988

Epoch: 6| Step: 10
Training loss: 2.6634343544998402
Validation loss: 2.3976191347426763

Epoch: 6| Step: 11
Training loss: 2.160637855303952
Validation loss: 2.400680776906657

Epoch: 6| Step: 12
Training loss: 2.3342455602094794
Validation loss: 2.403718384501597

Epoch: 6| Step: 13
Training loss: 1.8680886364559917
Validation loss: 2.4063843858852314

Epoch: 26| Step: 0
Training loss: 2.218940834112746
Validation loss: 2.4080427023036277

Epoch: 6| Step: 1
Training loss: 2.1700472379192637
Validation loss: 2.4070533881014935

Epoch: 6| Step: 2
Training loss: 2.1776843420191416
Validation loss: 2.406714159302301

Epoch: 6| Step: 3
Training loss: 2.8029193032958646
Validation loss: 2.4057379503923206

Epoch: 6| Step: 4
Training loss: 1.9158989018186074
Validation loss: 2.399249309120345

Epoch: 6| Step: 5
Training loss: 2.55361701398741
Validation loss: 2.3981756011420354

Epoch: 6| Step: 6
Training loss: 2.5284783530173334
Validation loss: 2.398915743287568

Epoch: 6| Step: 7
Training loss: 2.000266057437637
Validation loss: 2.412315641945645

Epoch: 6| Step: 8
Training loss: 2.7744299603832174
Validation loss: 2.406431050941156

Epoch: 6| Step: 9
Training loss: 2.341105889703454
Validation loss: 2.414015735555972

Epoch: 6| Step: 10
Training loss: 2.526152009946345
Validation loss: 2.4099957099918576

Epoch: 6| Step: 11
Training loss: 2.619216451322451
Validation loss: 2.399840318480441

Epoch: 6| Step: 12
Training loss: 2.2876342900782025
Validation loss: 2.4040131844419794

Epoch: 6| Step: 13
Training loss: 2.558847010068218
Validation loss: 2.4150542821634677

Epoch: 27| Step: 0
Training loss: 2.2198262358010994
Validation loss: 2.395142975457117

Epoch: 6| Step: 1
Training loss: 2.752891147826853
Validation loss: 2.4093599245595096

Epoch: 6| Step: 2
Training loss: 2.3156162606716624
Validation loss: 2.410102707625172

Epoch: 6| Step: 3
Training loss: 2.075107420013708
Validation loss: 2.391425204521266

Epoch: 6| Step: 4
Training loss: 2.1009651100787727
Validation loss: 2.405514608856457

Epoch: 6| Step: 5
Training loss: 2.7520336087913675
Validation loss: 2.406441181399035

Epoch: 6| Step: 6
Training loss: 1.921201758588772
Validation loss: 2.4051974004863497

Epoch: 6| Step: 7
Training loss: 2.4871386624998344
Validation loss: 2.4054305179799997

Epoch: 6| Step: 8
Training loss: 2.5861325838659175
Validation loss: 2.416135702230488

Epoch: 6| Step: 9
Training loss: 2.1181460529720777
Validation loss: 2.4142686741427224

Epoch: 6| Step: 10
Training loss: 2.5549540249444957
Validation loss: 2.413382993203872

Epoch: 6| Step: 11
Training loss: 3.145901929768503
Validation loss: 2.408993234829966

Epoch: 6| Step: 12
Training loss: 2.1897821783146276
Validation loss: 2.4115275846112865

Epoch: 6| Step: 13
Training loss: 2.195261998800527
Validation loss: 2.401901063733812

Epoch: 28| Step: 0
Training loss: 2.6702491319703356
Validation loss: 2.4011880136326793

Epoch: 6| Step: 1
Training loss: 2.14165889525828
Validation loss: 2.3907885194259095

Epoch: 6| Step: 2
Training loss: 2.002026723113614
Validation loss: 2.402769817003453

Epoch: 6| Step: 3
Training loss: 2.8980577739382603
Validation loss: 2.3838015312088556

Epoch: 6| Step: 4
Training loss: 2.5981979837781677
Validation loss: 2.399743965850046

Epoch: 6| Step: 5
Training loss: 2.252755279470482
Validation loss: 2.3865044430480173

Epoch: 6| Step: 6
Training loss: 2.4962910796535547
Validation loss: 2.4077187551460066

Epoch: 6| Step: 7
Training loss: 2.1857589332444265
Validation loss: 2.393192782175617

Epoch: 6| Step: 8
Training loss: 2.840280785179463
Validation loss: 2.3949453836901933

Epoch: 6| Step: 9
Training loss: 2.42618025540434
Validation loss: 2.3924948333982075

Epoch: 6| Step: 10
Training loss: 2.786403724396741
Validation loss: 2.3994954910092874

Epoch: 6| Step: 11
Training loss: 2.2768050484143583
Validation loss: 2.3952213970924223

Epoch: 6| Step: 12
Training loss: 1.6077149356938638
Validation loss: 2.4087205564543375

Epoch: 6| Step: 13
Training loss: 2.1927218644426127
Validation loss: 2.3977427351306617

Epoch: 29| Step: 0
Training loss: 2.9343475308011073
Validation loss: 2.4146472671202743

Epoch: 6| Step: 1
Training loss: 2.1658384011554124
Validation loss: 2.413583767693448

Epoch: 6| Step: 2
Training loss: 2.7632274688241125
Validation loss: 2.4011712580619498

Epoch: 6| Step: 3
Training loss: 2.786263223157184
Validation loss: 2.402807357424712

Epoch: 6| Step: 4
Training loss: 1.8893013095649869
Validation loss: 2.4016814851623582

Epoch: 6| Step: 5
Training loss: 2.1201997281404954
Validation loss: 2.4141529975726237

Epoch: 6| Step: 6
Training loss: 2.5604837440372483
Validation loss: 2.4073070499771037

Epoch: 6| Step: 7
Training loss: 2.4896723094240714
Validation loss: 2.401074842994735

Epoch: 6| Step: 8
Training loss: 2.6247495804275944
Validation loss: 2.411681926295

Epoch: 6| Step: 9
Training loss: 2.3103272824644585
Validation loss: 2.400201883699462

Epoch: 6| Step: 10
Training loss: 2.139922534930966
Validation loss: 2.3895492044642914

Epoch: 6| Step: 11
Training loss: 2.4111676188506364
Validation loss: 2.4144786159221203

Epoch: 6| Step: 12
Training loss: 1.9693617097484257
Validation loss: 2.408727617118558

Epoch: 6| Step: 13
Training loss: 2.07299262695179
Validation loss: 2.414278245027854

Epoch: 30| Step: 0
Training loss: 2.1349313572160615
Validation loss: 2.407053668743074

Epoch: 6| Step: 1
Training loss: 2.1725651584419237
Validation loss: 2.4018802350731923

Epoch: 6| Step: 2
Training loss: 2.46915403512416
Validation loss: 2.4109268893661278

Epoch: 6| Step: 3
Training loss: 1.7519812948456424
Validation loss: 2.409669766204792

Epoch: 6| Step: 4
Training loss: 2.7303587273300236
Validation loss: 2.4152109239478197

Epoch: 6| Step: 5
Training loss: 2.940199565212601
Validation loss: 2.424508400210535

Epoch: 6| Step: 6
Training loss: 1.7664809051354073
Validation loss: 2.422759192070656

Epoch: 6| Step: 7
Training loss: 2.155562139066275
Validation loss: 2.4157348732843

Epoch: 6| Step: 8
Training loss: 2.2767775078633616
Validation loss: 2.4160786494322806

Epoch: 6| Step: 9
Training loss: 2.64915128108434
Validation loss: 2.4118487630436714

Epoch: 6| Step: 10
Training loss: 2.696501980795505
Validation loss: 2.4036639465332863

Epoch: 6| Step: 11
Training loss: 2.25801397038506
Validation loss: 2.401467429674141

Epoch: 6| Step: 12
Training loss: 2.793239169601083
Validation loss: 2.3886566452742763

Epoch: 6| Step: 13
Training loss: 2.233775772091212
Validation loss: 2.3984438950974223

Epoch: 31| Step: 0
Training loss: 2.5894751192920578
Validation loss: 2.395413997828037

Epoch: 6| Step: 1
Training loss: 2.2058623062419653
Validation loss: 2.4065952878979813

Epoch: 6| Step: 2
Training loss: 2.4698207802560237
Validation loss: 2.3809872750154937

Epoch: 6| Step: 3
Training loss: 2.5151780957665943
Validation loss: 2.3839511506283757

Epoch: 6| Step: 4
Training loss: 2.7558013239423187
Validation loss: 2.3888308039954596

Epoch: 6| Step: 5
Training loss: 2.264041847361215
Validation loss: 2.3967557928025203

Epoch: 6| Step: 6
Training loss: 2.6359200179103146
Validation loss: 2.3860665536888974

Epoch: 6| Step: 7
Training loss: 1.9591128306237555
Validation loss: 2.393533753005614

Epoch: 6| Step: 8
Training loss: 2.6501588881741336
Validation loss: 2.3955109476099286

Epoch: 6| Step: 9
Training loss: 1.8681308167087207
Validation loss: 2.3876082390820565

Epoch: 6| Step: 10
Training loss: 2.429952821626797
Validation loss: 2.374433031503472

Epoch: 6| Step: 11
Training loss: 1.9018126574730634
Validation loss: 2.3966230390165277

Epoch: 6| Step: 12
Training loss: 2.81621255618625
Validation loss: 2.418911176596459

Epoch: 6| Step: 13
Training loss: 2.2630060251773556
Validation loss: 2.4147290870136633

Epoch: 32| Step: 0
Training loss: 2.1510202870141613
Validation loss: 2.4090796342785463

Epoch: 6| Step: 1
Training loss: 3.2392488329409
Validation loss: 2.4206311384931363

Epoch: 6| Step: 2
Training loss: 2.9527947781124153
Validation loss: 2.4222329726281977

Epoch: 6| Step: 3
Training loss: 1.8185820642917379
Validation loss: 2.424287378009956

Epoch: 6| Step: 4
Training loss: 2.490241842819685
Validation loss: 2.4191511197783635

Epoch: 6| Step: 5
Training loss: 2.0510356055060845
Validation loss: 2.414555915850203

Epoch: 6| Step: 6
Training loss: 2.200699790283892
Validation loss: 2.413085888098821

Epoch: 6| Step: 7
Training loss: 1.8987025951020389
Validation loss: 2.4113528652210445

Epoch: 6| Step: 8
Training loss: 2.343975005475516
Validation loss: 2.4214082165519097

Epoch: 6| Step: 9
Training loss: 2.06820974988492
Validation loss: 2.422262534033092

Epoch: 6| Step: 10
Training loss: 2.731622149430763
Validation loss: 2.415591055371242

Epoch: 6| Step: 11
Training loss: 2.0395202123000926
Validation loss: 2.4263139468476873

Epoch: 6| Step: 12
Training loss: 2.6729034764436905
Validation loss: 2.4048379495315437

Epoch: 6| Step: 13
Training loss: 2.166219689651871
Validation loss: 2.397162870173575

Epoch: 33| Step: 0
Training loss: 2.7689437350655908
Validation loss: 2.3954290187072873

Epoch: 6| Step: 1
Training loss: 2.456016828423418
Validation loss: 2.3938507390882

Epoch: 6| Step: 2
Training loss: 2.8591076668596798
Validation loss: 2.3943008054746926

Epoch: 6| Step: 3
Training loss: 1.869677108896446
Validation loss: 2.398230495072805

Epoch: 6| Step: 4
Training loss: 2.859512575935982
Validation loss: 2.3950225840428216

Epoch: 6| Step: 5
Training loss: 2.070913896842055
Validation loss: 2.3984443424222515

Epoch: 6| Step: 6
Training loss: 1.8383968681683935
Validation loss: 2.3933159470347265

Epoch: 6| Step: 7
Training loss: 2.7639311005027634
Validation loss: 2.3905651608626104

Epoch: 6| Step: 8
Training loss: 2.0649569355905477
Validation loss: 2.3936677903682377

Epoch: 6| Step: 9
Training loss: 2.010117688126043
Validation loss: 2.4028956412536604

Epoch: 6| Step: 10
Training loss: 2.7441828497085026
Validation loss: 2.4190136321420797

Epoch: 6| Step: 11
Training loss: 2.3974427387611215
Validation loss: 2.4125462763141265

Epoch: 6| Step: 12
Training loss: 2.265833141368518
Validation loss: 2.402175326762514

Epoch: 6| Step: 13
Training loss: 1.7591273158864666
Validation loss: 2.4082164408245252

Epoch: 34| Step: 0
Training loss: 2.3411638360326723
Validation loss: 2.402079332474627

Epoch: 6| Step: 1
Training loss: 2.5120149855986758
Validation loss: 2.414889822448096

Epoch: 6| Step: 2
Training loss: 2.2393990965772983
Validation loss: 2.413224635556647

Epoch: 6| Step: 3
Training loss: 2.162845420812836
Validation loss: 2.4126487303958952

Epoch: 6| Step: 4
Training loss: 2.402305739187348
Validation loss: 2.3981165800658464

Epoch: 6| Step: 5
Training loss: 2.461107133135464
Validation loss: 2.4283684342159546

Epoch: 6| Step: 6
Training loss: 2.088480453038086
Validation loss: 2.4422693298649514

Epoch: 6| Step: 7
Training loss: 2.236036309938641
Validation loss: 2.4476340651559467

Epoch: 6| Step: 8
Training loss: 2.2768860973807095
Validation loss: 2.4584203047373476

Epoch: 6| Step: 9
Training loss: 2.7760468578946145
Validation loss: 2.4347823390247263

Epoch: 6| Step: 10
Training loss: 2.2313653910742377
Validation loss: 2.441414965804755

Epoch: 6| Step: 11
Training loss: 2.110463857421265
Validation loss: 2.43792448667703

Epoch: 6| Step: 12
Training loss: 2.069616121457734
Validation loss: 2.421586928103897

Epoch: 6| Step: 13
Training loss: 3.07067154587979
Validation loss: 2.415737702511136

Epoch: 35| Step: 0
Training loss: 2.7215213024644997
Validation loss: 2.395872801303576

Epoch: 6| Step: 1
Training loss: 2.5188726466303586
Validation loss: 2.3988875506337797

Epoch: 6| Step: 2
Training loss: 2.7131297457217856
Validation loss: 2.4165428612226476

Epoch: 6| Step: 3
Training loss: 2.5893558830938526
Validation loss: 2.395438805866721

Epoch: 6| Step: 4
Training loss: 2.5941443086128984
Validation loss: 2.396743391486327

Epoch: 6| Step: 5
Training loss: 2.4091488109847505
Validation loss: 2.39528315211576

Epoch: 6| Step: 6
Training loss: 1.9833233066380187
Validation loss: 2.396152928362346

Epoch: 6| Step: 7
Training loss: 2.945662338567339
Validation loss: 2.4015603543042188

Epoch: 6| Step: 8
Training loss: 2.439398784047476
Validation loss: 2.39936227604138

Epoch: 6| Step: 9
Training loss: 2.2428359313565784
Validation loss: 2.3950393411515085

Epoch: 6| Step: 10
Training loss: 1.6788039611642427
Validation loss: 2.3947985086651653

Epoch: 6| Step: 11
Training loss: 1.9779070476488003
Validation loss: 2.4061002478301345

Epoch: 6| Step: 12
Training loss: 2.1399974042217162
Validation loss: 2.3945159994597027

Epoch: 6| Step: 13
Training loss: 1.8037532353256511
Validation loss: 2.4079952103830147

Epoch: 36| Step: 0
Training loss: 2.215944047131951
Validation loss: 2.3972155412374816

Epoch: 6| Step: 1
Training loss: 1.8957006876167555
Validation loss: 2.403763175461411

Epoch: 6| Step: 2
Training loss: 2.79086108944443
Validation loss: 2.399231438627553

Epoch: 6| Step: 3
Training loss: 2.5143590549510537
Validation loss: 2.4136001489825736

Epoch: 6| Step: 4
Training loss: 2.2445887026154017
Validation loss: 2.4052767581274024

Epoch: 6| Step: 5
Training loss: 2.588918575322221
Validation loss: 2.4430289122522817

Epoch: 6| Step: 6
Training loss: 2.5653048725644445
Validation loss: 2.463055299864754

Epoch: 6| Step: 7
Training loss: 2.808065945793744
Validation loss: 2.486888821277366

Epoch: 6| Step: 8
Training loss: 2.9287749229735076
Validation loss: 2.5103903224296182

Epoch: 6| Step: 9
Training loss: 1.9654522478760532
Validation loss: 2.4822125730561297

Epoch: 6| Step: 10
Training loss: 2.3825682467986256
Validation loss: 2.482642347308212

Epoch: 6| Step: 11
Training loss: 1.8703725296878135
Validation loss: 2.4685338002111563

Epoch: 6| Step: 12
Training loss: 1.7263147512966555
Validation loss: 2.4650230282061854

Epoch: 6| Step: 13
Training loss: 2.4171316642205767
Validation loss: 2.43315549183163

Epoch: 37| Step: 0
Training loss: 2.0755028494546766
Validation loss: 2.420727726727865

Epoch: 6| Step: 1
Training loss: 2.0615840380718695
Validation loss: 2.412602531481194

Epoch: 6| Step: 2
Training loss: 2.642219739070945
Validation loss: 2.395540739243447

Epoch: 6| Step: 3
Training loss: 2.2153976259195947
Validation loss: 2.40032395222925

Epoch: 6| Step: 4
Training loss: 2.3620071381437633
Validation loss: 2.4088619967496614

Epoch: 6| Step: 5
Training loss: 2.2009298873611556
Validation loss: 2.4074128879039147

Epoch: 6| Step: 6
Training loss: 2.31295617217989
Validation loss: 2.3967844581661617

Epoch: 6| Step: 7
Training loss: 2.0877372606866564
Validation loss: 2.4041491498479797

Epoch: 6| Step: 8
Training loss: 2.9404029300198196
Validation loss: 2.399240481544156

Epoch: 6| Step: 9
Training loss: 2.3487036680450104
Validation loss: 2.3967753396666165

Epoch: 6| Step: 10
Training loss: 1.9150665763656474
Validation loss: 2.3993644786861394

Epoch: 6| Step: 11
Training loss: 1.6582596300829793
Validation loss: 2.392260870627486

Epoch: 6| Step: 12
Training loss: 2.667008993905303
Validation loss: 2.394768052373949

Epoch: 6| Step: 13
Training loss: 2.845222511104415
Validation loss: 2.403363531913213

Epoch: 38| Step: 0
Training loss: 2.1275186758869022
Validation loss: 2.3901317478189283

Epoch: 6| Step: 1
Training loss: 2.377312989526389
Validation loss: 2.399800694985115

Epoch: 6| Step: 2
Training loss: 3.0178644433340347
Validation loss: 2.388907985709497

Epoch: 6| Step: 3
Training loss: 2.383759557407785
Validation loss: 2.3965377490777224

Epoch: 6| Step: 4
Training loss: 1.7277287475577088
Validation loss: 2.4052022163728557

Epoch: 6| Step: 5
Training loss: 2.4374046307026562
Validation loss: 2.414510041430931

Epoch: 6| Step: 6
Training loss: 2.577917564601155
Validation loss: 2.404271208034495

Epoch: 6| Step: 7
Training loss: 2.0452938816281003
Validation loss: 2.3876447530540847

Epoch: 6| Step: 8
Training loss: 1.9346845536293513
Validation loss: 2.4004923315515696

Epoch: 6| Step: 9
Training loss: 2.091861955358694
Validation loss: 2.403221486919728

Epoch: 6| Step: 10
Training loss: 3.1068578912006455
Validation loss: 2.3991847825986765

Epoch: 6| Step: 11
Training loss: 2.2442214725496195
Validation loss: 2.4083414937797367

Epoch: 6| Step: 12
Training loss: 2.1963767733430792
Validation loss: 2.403478132344326

Epoch: 6| Step: 13
Training loss: 2.1013842652477233
Validation loss: 2.4148285030104564

Epoch: 39| Step: 0
Training loss: 2.011269765582501
Validation loss: 2.4011792428299916

Epoch: 6| Step: 1
Training loss: 2.4833826926358924
Validation loss: 2.401748839946324

Epoch: 6| Step: 2
Training loss: 2.3797838318050246
Validation loss: 2.4168528918062475

Epoch: 6| Step: 3
Training loss: 2.289297462877019
Validation loss: 2.432836276938416

Epoch: 6| Step: 4
Training loss: 2.2898312472337574
Validation loss: 2.4251152348749505

Epoch: 6| Step: 5
Training loss: 1.719397890915464
Validation loss: 2.4275740808143413

Epoch: 6| Step: 6
Training loss: 1.9423302767530808
Validation loss: 2.41883835282067

Epoch: 6| Step: 7
Training loss: 2.136548915996724
Validation loss: 2.4314500522110243

Epoch: 6| Step: 8
Training loss: 2.0332855589001713
Validation loss: 2.4135194433048284

Epoch: 6| Step: 9
Training loss: 2.326855614248668
Validation loss: 2.4396671866044453

Epoch: 6| Step: 10
Training loss: 2.74670672460005
Validation loss: 2.418633192529258

Epoch: 6| Step: 11
Training loss: 2.618172167118424
Validation loss: 2.420758176502519

Epoch: 6| Step: 12
Training loss: 2.846668799561082
Validation loss: 2.4156302553607447

Epoch: 6| Step: 13
Training loss: 2.627687713131627
Validation loss: 2.415647017562428

Epoch: 40| Step: 0
Training loss: 3.0347361230907692
Validation loss: 2.3953711575307746

Epoch: 6| Step: 1
Training loss: 1.901174322925792
Validation loss: 2.4041504225245474

Epoch: 6| Step: 2
Training loss: 2.7734460964875574
Validation loss: 2.3958801734878943

Epoch: 6| Step: 3
Training loss: 2.3500885764128303
Validation loss: 2.389598501390665

Epoch: 6| Step: 4
Training loss: 1.8029781685055946
Validation loss: 2.389492123854985

Epoch: 6| Step: 5
Training loss: 2.3373938266080203
Validation loss: 2.4054465913676024

Epoch: 6| Step: 6
Training loss: 2.1420895654953376
Validation loss: 2.399792175765378

Epoch: 6| Step: 7
Training loss: 2.3291902089393526
Validation loss: 2.3918743151951243

Epoch: 6| Step: 8
Training loss: 2.530206158949723
Validation loss: 2.399746234378853

Epoch: 6| Step: 9
Training loss: 1.8170102007531805
Validation loss: 2.4020636997484752

Epoch: 6| Step: 10
Training loss: 2.7027437679934154
Validation loss: 2.41122062670488

Epoch: 6| Step: 11
Training loss: 2.417763450177288
Validation loss: 2.415896281957103

Epoch: 6| Step: 12
Training loss: 2.4865495294009943
Validation loss: 2.4093629261972698

Epoch: 6| Step: 13
Training loss: 1.5721473412416669
Validation loss: 2.434322372605464

Epoch: 41| Step: 0
Training loss: 2.3141670404346217
Validation loss: 2.440380163607418

Epoch: 6| Step: 1
Training loss: 1.6985477218728988
Validation loss: 2.417806140236693

Epoch: 6| Step: 2
Training loss: 2.634448168769062
Validation loss: 2.4157850257734315

Epoch: 6| Step: 3
Training loss: 2.461024110269073
Validation loss: 2.410455579012236

Epoch: 6| Step: 4
Training loss: 2.680401320514089
Validation loss: 2.4252901179014854

Epoch: 6| Step: 5
Training loss: 1.770714774557352
Validation loss: 2.4067990225785456

Epoch: 6| Step: 6
Training loss: 2.6177213665209824
Validation loss: 2.422655164514795

Epoch: 6| Step: 7
Training loss: 1.9051751405199728
Validation loss: 2.409817911447462

Epoch: 6| Step: 8
Training loss: 1.8258046479658139
Validation loss: 2.393803480196642

Epoch: 6| Step: 9
Training loss: 2.5485612400683375
Validation loss: 2.398313289246648

Epoch: 6| Step: 10
Training loss: 1.9864084233170312
Validation loss: 2.4034525475671416

Epoch: 6| Step: 11
Training loss: 2.023713671126693
Validation loss: 2.3878202170353937

Epoch: 6| Step: 12
Training loss: 2.7914034211651284
Validation loss: 2.4005099443577844

Epoch: 6| Step: 13
Training loss: 2.6648375874282855
Validation loss: 2.378652933933014

Epoch: 42| Step: 0
Training loss: 2.1888061983310765
Validation loss: 2.41372539219955

Epoch: 6| Step: 1
Training loss: 2.2594057157547005
Validation loss: 2.405460756674116

Epoch: 6| Step: 2
Training loss: 2.174582132121208
Validation loss: 2.3965823592114543

Epoch: 6| Step: 3
Training loss: 2.067365398522845
Validation loss: 2.407115846554867

Epoch: 6| Step: 4
Training loss: 2.3892535096498286
Validation loss: 2.394456340537007

Epoch: 6| Step: 5
Training loss: 2.4876399628641734
Validation loss: 2.4094786513248856

Epoch: 6| Step: 6
Training loss: 2.5363760953779293
Validation loss: 2.4122125065592885

Epoch: 6| Step: 7
Training loss: 2.588385307967583
Validation loss: 2.3768298311210616

Epoch: 6| Step: 8
Training loss: 2.7338695821959127
Validation loss: 2.3995863558028243

Epoch: 6| Step: 9
Training loss: 2.2474122531212952
Validation loss: 2.3917380008847755

Epoch: 6| Step: 10
Training loss: 2.275716995605054
Validation loss: 2.4091635483024767

Epoch: 6| Step: 11
Training loss: 2.3660853876488708
Validation loss: 2.390530544899971

Epoch: 6| Step: 12
Training loss: 2.0495099296022175
Validation loss: 2.39576650332799

Epoch: 6| Step: 13
Training loss: 1.7104452461460076
Validation loss: 2.4009239736137338

Epoch: 43| Step: 0
Training loss: 2.8037699524113817
Validation loss: 2.401680492446922

Epoch: 6| Step: 1
Training loss: 2.6217076681252878
Validation loss: 2.399932370623766

Epoch: 6| Step: 2
Training loss: 2.0129838539533433
Validation loss: 2.4061727387546163

Epoch: 6| Step: 3
Training loss: 2.8470274096162047
Validation loss: 2.4318382826292804

Epoch: 6| Step: 4
Training loss: 2.2780712398679666
Validation loss: 2.4223923981622457

Epoch: 6| Step: 5
Training loss: 1.6440529025678128
Validation loss: 2.448570120959964

Epoch: 6| Step: 6
Training loss: 1.9282866424121636
Validation loss: 2.449357251434512

Epoch: 6| Step: 7
Training loss: 2.8979374950399968
Validation loss: 2.457926479444388

Epoch: 6| Step: 8
Training loss: 1.7435814451290597
Validation loss: 2.4408420572052267

Epoch: 6| Step: 9
Training loss: 2.227806841163121
Validation loss: 2.4360165687372355

Epoch: 6| Step: 10
Training loss: 2.4612355854005608
Validation loss: 2.4221216876002445

Epoch: 6| Step: 11
Training loss: 1.7550647197646998
Validation loss: 2.4141361097781604

Epoch: 6| Step: 12
Training loss: 1.844877383285049
Validation loss: 2.4142884495411456

Epoch: 6| Step: 13
Training loss: 2.5003999390180573
Validation loss: 2.4281222094270634

Epoch: 44| Step: 0
Training loss: 1.996441237928343
Validation loss: 2.4040091265184103

Epoch: 6| Step: 1
Training loss: 2.064233918042235
Validation loss: 2.4068632954382467

Epoch: 6| Step: 2
Training loss: 1.9658063650228637
Validation loss: 2.41174812855079

Epoch: 6| Step: 3
Training loss: 2.4477464549089905
Validation loss: 2.440110577412384

Epoch: 6| Step: 4
Training loss: 2.8411853669816725
Validation loss: 2.418815567218759

Epoch: 6| Step: 5
Training loss: 2.037136527563529
Validation loss: 2.4142109353068197

Epoch: 6| Step: 6
Training loss: 1.7653574107800438
Validation loss: 2.443304730603982

Epoch: 6| Step: 7
Training loss: 2.4915022431114124
Validation loss: 2.4494049634217707

Epoch: 6| Step: 8
Training loss: 2.374684162220377
Validation loss: 2.4421354949288814

Epoch: 6| Step: 9
Training loss: 2.6648585229361847
Validation loss: 2.435329187898043

Epoch: 6| Step: 10
Training loss: 2.177984194261212
Validation loss: 2.4419005521738075

Epoch: 6| Step: 11
Training loss: 2.09159672026181
Validation loss: 2.433108539083035

Epoch: 6| Step: 12
Training loss: 2.729069035848892
Validation loss: 2.4303565867289136

Epoch: 6| Step: 13
Training loss: 2.1575997592321934
Validation loss: 2.4005577830006812

Epoch: 45| Step: 0
Training loss: 2.7263202723594357
Validation loss: 2.418916400505121

Epoch: 6| Step: 1
Training loss: 1.7513439603617924
Validation loss: 2.403113480148847

Epoch: 6| Step: 2
Training loss: 2.170870102505704
Validation loss: 2.3971981197170518

Epoch: 6| Step: 3
Training loss: 2.3713007778427864
Validation loss: 2.3997732578563578

Epoch: 6| Step: 4
Training loss: 2.0929291667662406
Validation loss: 2.396226955641963

Epoch: 6| Step: 5
Training loss: 2.3463025244400706
Validation loss: 2.4045306003569764

Epoch: 6| Step: 6
Training loss: 1.7233255690664753
Validation loss: 2.387032262977491

Epoch: 6| Step: 7
Training loss: 2.690286212287127
Validation loss: 2.410233828688699

Epoch: 6| Step: 8
Training loss: 2.335188627608843
Validation loss: 2.37617383358254

Epoch: 6| Step: 9
Training loss: 2.630779262305665
Validation loss: 2.4033975331738877

Epoch: 6| Step: 10
Training loss: 2.23216223354104
Validation loss: 2.397821220886872

Epoch: 6| Step: 11
Training loss: 2.262378550267818
Validation loss: 2.3943268448592456

Epoch: 6| Step: 12
Training loss: 2.430147967601911
Validation loss: 2.4032814242841147

Epoch: 6| Step: 13
Training loss: 2.0224062379433003
Validation loss: 2.3911916356293217

Epoch: 46| Step: 0
Training loss: 2.155913174623717
Validation loss: 2.4231926481774355

Epoch: 6| Step: 1
Training loss: 2.755729082840898
Validation loss: 2.3860147773037794

Epoch: 6| Step: 2
Training loss: 2.807876176913421
Validation loss: 2.39425119875069

Epoch: 6| Step: 3
Training loss: 2.219928052612709
Validation loss: 2.420047653086365

Epoch: 6| Step: 4
Training loss: 2.9545785061781524
Validation loss: 2.3972999617121276

Epoch: 6| Step: 5
Training loss: 2.4818953128964254
Validation loss: 2.403875269053275

Epoch: 6| Step: 6
Training loss: 2.1195939805238524
Validation loss: 2.4021295384785017

Epoch: 6| Step: 7
Training loss: 1.8861723872877183
Validation loss: 2.404367990730632

Epoch: 6| Step: 8
Training loss: 2.5676025203751296
Validation loss: 2.4219373141239933

Epoch: 6| Step: 9
Training loss: 1.8794511730512036
Validation loss: 2.389033051386835

Epoch: 6| Step: 10
Training loss: 1.874395654557548
Validation loss: 2.4034349067253062

Epoch: 6| Step: 11
Training loss: 1.6328184136826598
Validation loss: 2.3930526823293605

Epoch: 6| Step: 12
Training loss: 2.0036925560706487
Validation loss: 2.4058140941978587

Epoch: 6| Step: 13
Training loss: 1.9202886718066239
Validation loss: 2.4220452443655303

Epoch: 47| Step: 0
Training loss: 2.4105555668811554
Validation loss: 2.4438090389629115

Epoch: 6| Step: 1
Training loss: 2.119155925924024
Validation loss: 2.4280132155050884

Epoch: 6| Step: 2
Training loss: 2.477903370128532
Validation loss: 2.453207747568228

Epoch: 6| Step: 3
Training loss: 1.9535851508729856
Validation loss: 2.4658293207085866

Epoch: 6| Step: 4
Training loss: 2.580893400004638
Validation loss: 2.483438231239005

Epoch: 6| Step: 5
Training loss: 2.2949960509953984
Validation loss: 2.4695210922564907

Epoch: 6| Step: 6
Training loss: 1.6002626680296748
Validation loss: 2.4303694051272577

Epoch: 6| Step: 7
Training loss: 2.2650328816096574
Validation loss: 2.4496640130703153

Epoch: 6| Step: 8
Training loss: 2.2453248938826995
Validation loss: 2.4335480793381667

Epoch: 6| Step: 9
Training loss: 2.0771580791384125
Validation loss: 2.4139665998156716

Epoch: 6| Step: 10
Training loss: 3.153309273604478
Validation loss: 2.4146560877409042

Epoch: 6| Step: 11
Training loss: 1.4871485447215362
Validation loss: 2.420828488575415

Epoch: 6| Step: 12
Training loss: 2.645279884024645
Validation loss: 2.3892378512146117

Epoch: 6| Step: 13
Training loss: 1.799108957575735
Validation loss: 2.4123736979310744

Epoch: 48| Step: 0
Training loss: 2.2746312523768664
Validation loss: 2.3881100742273333

Epoch: 6| Step: 1
Training loss: 1.9137742428829394
Validation loss: 2.407870684033559

Epoch: 6| Step: 2
Training loss: 2.627728089106314
Validation loss: 2.397890738958273

Epoch: 6| Step: 3
Training loss: 2.351933750997164
Validation loss: 2.392409836436391

Epoch: 6| Step: 4
Training loss: 2.512407982502928
Validation loss: 2.4025119794956438

Epoch: 6| Step: 5
Training loss: 2.5088143412384487
Validation loss: 2.387806396396696

Epoch: 6| Step: 6
Training loss: 2.1092368751796644
Validation loss: 2.415729543801493

Epoch: 6| Step: 7
Training loss: 2.3904518613262975
Validation loss: 2.402335975861828

Epoch: 6| Step: 8
Training loss: 2.070878091964214
Validation loss: 2.4343480328627924

Epoch: 6| Step: 9
Training loss: 2.223726735499946
Validation loss: 2.4088240063128055

Epoch: 6| Step: 10
Training loss: 2.413991982624485
Validation loss: 2.4353875355627554

Epoch: 6| Step: 11
Training loss: 2.095178600701012
Validation loss: 2.438621621584388

Epoch: 6| Step: 12
Training loss: 2.210068602727021
Validation loss: 2.4460578408169646

Epoch: 6| Step: 13
Training loss: 1.6834624697311813
Validation loss: 2.4079917119835113

Epoch: 49| Step: 0
Training loss: 2.7100807617090217
Validation loss: 2.407358582998688

Epoch: 6| Step: 1
Training loss: 2.912584845489953
Validation loss: 2.406155390345099

Epoch: 6| Step: 2
Training loss: 2.3863750903362497
Validation loss: 2.3850083286211956

Epoch: 6| Step: 3
Training loss: 2.5384011683810312
Validation loss: 2.4046630250025243

Epoch: 6| Step: 4
Training loss: 2.164207150689363
Validation loss: 2.3829592133261315

Epoch: 6| Step: 5
Training loss: 2.0561754763934132
Validation loss: 2.383107668412363

Epoch: 6| Step: 6
Training loss: 2.254751063645118
Validation loss: 2.3827819989029333

Epoch: 6| Step: 7
Training loss: 2.0470126739094696
Validation loss: 2.408227199032946

Epoch: 6| Step: 8
Training loss: 1.683340881192247
Validation loss: 2.424103972471312

Epoch: 6| Step: 9
Training loss: 1.9179155455005967
Validation loss: 2.398814814707211

Epoch: 6| Step: 10
Training loss: 2.049610552197644
Validation loss: 2.3782460466374284

Epoch: 6| Step: 11
Training loss: 2.237184052563934
Validation loss: 2.414166198280964

Epoch: 6| Step: 12
Training loss: 2.130045342835833
Validation loss: 2.401410367602557

Epoch: 6| Step: 13
Training loss: 2.0615523502087854
Validation loss: 2.433061585428355

Epoch: 50| Step: 0
Training loss: 2.6477609856253097
Validation loss: 2.4569470705006693

Epoch: 6| Step: 1
Training loss: 1.9389618926649035
Validation loss: 2.460080533453956

Epoch: 6| Step: 2
Training loss: 2.281783995118385
Validation loss: 2.501043117977697

Epoch: 6| Step: 3
Training loss: 2.3620830430332163
Validation loss: 2.482695269592833

Epoch: 6| Step: 4
Training loss: 2.471803539222167
Validation loss: 2.4824959388487122

Epoch: 6| Step: 5
Training loss: 2.6656721068465044
Validation loss: 2.4610949107694875

Epoch: 6| Step: 6
Training loss: 1.9822933061372114
Validation loss: 2.4286083511142356

Epoch: 6| Step: 7
Training loss: 2.052196312390665
Validation loss: 2.442386530085656

Epoch: 6| Step: 8
Training loss: 1.7577273878049113
Validation loss: 2.4110648134164783

Epoch: 6| Step: 9
Training loss: 1.7021106183944028
Validation loss: 2.417811259706194

Epoch: 6| Step: 10
Training loss: 1.9799065930075874
Validation loss: 2.394075301520821

Epoch: 6| Step: 11
Training loss: 2.518394320153662
Validation loss: 2.411618094922884

Epoch: 6| Step: 12
Training loss: 2.2179331820633497
Validation loss: 2.383636240505947

Epoch: 6| Step: 13
Training loss: 2.3094200036976824
Validation loss: 2.401692173372566

Epoch: 51| Step: 0
Training loss: 2.043406802418074
Validation loss: 2.4107709911613657

Epoch: 6| Step: 1
Training loss: 1.6582687598584511
Validation loss: 2.3781662966216652

Epoch: 6| Step: 2
Training loss: 2.1433106442086562
Validation loss: 2.3902856257613556

Epoch: 6| Step: 3
Training loss: 1.7232734110957693
Validation loss: 2.3987077442719267

Epoch: 6| Step: 4
Training loss: 2.5339642324715856
Validation loss: 2.3907511725612487

Epoch: 6| Step: 5
Training loss: 2.2222715557768242
Validation loss: 2.4111333728334876

Epoch: 6| Step: 6
Training loss: 1.3346464376847422
Validation loss: 2.409617054049341

Epoch: 6| Step: 7
Training loss: 2.446969442871264
Validation loss: 2.386088686127017

Epoch: 6| Step: 8
Training loss: 2.9593438764182243
Validation loss: 2.4339936133535742

Epoch: 6| Step: 9
Training loss: 2.1727257029911144
Validation loss: 2.4021559065492197

Epoch: 6| Step: 10
Training loss: 2.741453936671132
Validation loss: 2.401979579046782

Epoch: 6| Step: 11
Training loss: 1.995304436842863
Validation loss: 2.3917499463494143

Epoch: 6| Step: 12
Training loss: 2.0475865648762253
Validation loss: 2.4072968076163814

Epoch: 6| Step: 13
Training loss: 2.214520143149866
Validation loss: 2.4022004867883524

Epoch: 52| Step: 0
Training loss: 1.3915893982472736
Validation loss: 2.430750688863948

Epoch: 6| Step: 1
Training loss: 1.8207834314045008
Validation loss: 2.4748462622831853

Epoch: 6| Step: 2
Training loss: 1.841083861894819
Validation loss: 2.4789359255141648

Epoch: 6| Step: 3
Training loss: 2.3137587137331277
Validation loss: 2.503793524447775

Epoch: 6| Step: 4
Training loss: 2.582381001156072
Validation loss: 2.5182121983731958

Epoch: 6| Step: 5
Training loss: 2.7163376903467005
Validation loss: 2.501895869143647

Epoch: 6| Step: 6
Training loss: 2.6229644330689608
Validation loss: 2.488758562380797

Epoch: 6| Step: 7
Training loss: 1.9951544117267441
Validation loss: 2.488122221347791

Epoch: 6| Step: 8
Training loss: 2.272956613760124
Validation loss: 2.4315011634308763

Epoch: 6| Step: 9
Training loss: 2.893787365665969
Validation loss: 2.417583930022514

Epoch: 6| Step: 10
Training loss: 2.1834631592490523
Validation loss: 2.4124192505995192

Epoch: 6| Step: 11
Training loss: 1.826160516550572
Validation loss: 2.4046197215330003

Epoch: 6| Step: 12
Training loss: 1.8899970154511638
Validation loss: 2.4153358121873794

Epoch: 6| Step: 13
Training loss: 2.262532721857159
Validation loss: 2.4175547058874503

Epoch: 53| Step: 0
Training loss: 2.134824816554157
Validation loss: 2.4165168803482033

Epoch: 6| Step: 1
Training loss: 2.0308891562750744
Validation loss: 2.3971938264780146

Epoch: 6| Step: 2
Training loss: 2.273342274772235
Validation loss: 2.3972098556362638

Epoch: 6| Step: 3
Training loss: 1.9110046873968378
Validation loss: 2.410794841759278

Epoch: 6| Step: 4
Training loss: 2.442497607633108
Validation loss: 2.3820969638119767

Epoch: 6| Step: 5
Training loss: 2.2986090725073045
Validation loss: 2.42610563524449

Epoch: 6| Step: 6
Training loss: 2.6384420005346993
Validation loss: 2.4245853803719637

Epoch: 6| Step: 7
Training loss: 2.0453248888402604
Validation loss: 2.4385938146447823

Epoch: 6| Step: 8
Training loss: 2.082116216532581
Validation loss: 2.4164372587388114

Epoch: 6| Step: 9
Training loss: 1.9381032435313321
Validation loss: 2.443872744964667

Epoch: 6| Step: 10
Training loss: 2.931302940036995
Validation loss: 2.427965312274254

Epoch: 6| Step: 11
Training loss: 2.174264485313023
Validation loss: 2.4553011335449932

Epoch: 6| Step: 12
Training loss: 1.6762459917468593
Validation loss: 2.425055812573575

Epoch: 6| Step: 13
Training loss: 1.8780268714899828
Validation loss: 2.4023672872904793

Epoch: 54| Step: 0
Training loss: 1.439565253063705
Validation loss: 2.410925274148575

Epoch: 6| Step: 1
Training loss: 2.231307905711978
Validation loss: 2.3981155610199103

Epoch: 6| Step: 2
Training loss: 2.17290510818855
Validation loss: 2.39306198936459

Epoch: 6| Step: 3
Training loss: 2.4202836253522926
Validation loss: 2.401800508769277

Epoch: 6| Step: 4
Training loss: 2.500596928857258
Validation loss: 2.4268555077192353

Epoch: 6| Step: 5
Training loss: 2.5350893831765737
Validation loss: 2.4015273280847422

Epoch: 6| Step: 6
Training loss: 2.1977369286204103
Validation loss: 2.390982773547922

Epoch: 6| Step: 7
Training loss: 2.1531389432546986
Validation loss: 2.4013847028794975

Epoch: 6| Step: 8
Training loss: 2.7084372476058496
Validation loss: 2.4021847555999147

Epoch: 6| Step: 9
Training loss: 1.4566802964929524
Validation loss: 2.4145260872910455

Epoch: 6| Step: 10
Training loss: 1.7295540831403822
Validation loss: 2.44153528304851

Epoch: 6| Step: 11
Training loss: 2.558634191295372
Validation loss: 2.4094025326222352

Epoch: 6| Step: 12
Training loss: 1.5753727698833586
Validation loss: 2.412628883911694

Epoch: 6| Step: 13
Training loss: 2.2837926203149403
Validation loss: 2.401339486960251

Epoch: 55| Step: 0
Training loss: 1.9863700749741493
Validation loss: 2.416818989414706

Epoch: 6| Step: 1
Training loss: 2.1660031867809577
Validation loss: 2.4191805956504453

Epoch: 6| Step: 2
Training loss: 1.976093040472817
Validation loss: 2.411968339305264

Epoch: 6| Step: 3
Training loss: 2.0792007530134717
Validation loss: 2.4069323872609516

Epoch: 6| Step: 4
Training loss: 2.9652546433303972
Validation loss: 2.4057250172679128

Epoch: 6| Step: 5
Training loss: 2.0148633360604107
Validation loss: 2.396471441680158

Epoch: 6| Step: 6
Training loss: 1.665590256548699
Validation loss: 2.4064170647295513

Epoch: 6| Step: 7
Training loss: 2.712284775734546
Validation loss: 2.408071662344485

Epoch: 6| Step: 8
Training loss: 1.7791632090169407
Validation loss: 2.4380566540092485

Epoch: 6| Step: 9
Training loss: 2.4603076916064643
Validation loss: 2.4541049951685436

Epoch: 6| Step: 10
Training loss: 1.8664993869669102
Validation loss: 2.4576727874100515

Epoch: 6| Step: 11
Training loss: 2.0741265630261534
Validation loss: 2.4734027653671267

Epoch: 6| Step: 12
Training loss: 2.250929004886712
Validation loss: 2.4549763328877243

Epoch: 6| Step: 13
Training loss: 1.8519244906519645
Validation loss: 2.4398766285682907

Epoch: 56| Step: 0
Training loss: 2.4032687259548884
Validation loss: 2.437777674582352

Epoch: 6| Step: 1
Training loss: 2.2352666609586564
Validation loss: 2.381439130052298

Epoch: 6| Step: 2
Training loss: 2.3508084631245167
Validation loss: 2.385188726226356

Epoch: 6| Step: 3
Training loss: 1.74599666453564
Validation loss: 2.422646856879221

Epoch: 6| Step: 4
Training loss: 1.827962036694369
Validation loss: 2.4074861068034217

Epoch: 6| Step: 5
Training loss: 2.6296314979252076
Validation loss: 2.4081191032542746

Epoch: 6| Step: 6
Training loss: 1.6853199758563677
Validation loss: 2.3950957918355966

Epoch: 6| Step: 7
Training loss: 2.4797819853907237
Validation loss: 2.410308190105378

Epoch: 6| Step: 8
Training loss: 1.342652027536787
Validation loss: 2.379785351276631

Epoch: 6| Step: 9
Training loss: 2.399357026120528
Validation loss: 2.4335675347856722

Epoch: 6| Step: 10
Training loss: 2.4859723408173875
Validation loss: 2.3766968588184203

Epoch: 6| Step: 11
Training loss: 1.6433094406067532
Validation loss: 2.4191762839334325

Epoch: 6| Step: 12
Training loss: 2.483286493188206
Validation loss: 2.4085808978715866

Epoch: 6| Step: 13
Training loss: 2.0791978863020306
Validation loss: 2.420308301612951

Epoch: 57| Step: 0
Training loss: 1.9037256254563164
Validation loss: 2.4445100550323486

Epoch: 6| Step: 1
Training loss: 1.93010852251665
Validation loss: 2.441492210400756

Epoch: 6| Step: 2
Training loss: 1.9392548889082795
Validation loss: 2.4826194110334514

Epoch: 6| Step: 3
Training loss: 1.9421978877335278
Validation loss: 2.4930521183704517

Epoch: 6| Step: 4
Training loss: 2.227577914877908
Validation loss: 2.5396872666339556

Epoch: 6| Step: 5
Training loss: 2.735072194180466
Validation loss: 2.4857729131824287

Epoch: 6| Step: 6
Training loss: 2.2814546258156794
Validation loss: 2.4918260541436252

Epoch: 6| Step: 7
Training loss: 1.8981704838101108
Validation loss: 2.460496578377738

Epoch: 6| Step: 8
Training loss: 1.9768769990306085
Validation loss: 2.429218013824903

Epoch: 6| Step: 9
Training loss: 2.2214091310189277
Validation loss: 2.417990910886116

Epoch: 6| Step: 10
Training loss: 1.560013279980597
Validation loss: 2.400083029158503

Epoch: 6| Step: 11
Training loss: 2.5029128271659493
Validation loss: 2.4111685499795366

Epoch: 6| Step: 12
Training loss: 1.9641211453151561
Validation loss: 2.4030620627890293

Epoch: 6| Step: 13
Training loss: 2.439582521963487
Validation loss: 2.4056948231895845

Epoch: 58| Step: 0
Training loss: 1.7672074914639628
Validation loss: 2.417847744857105

Epoch: 6| Step: 1
Training loss: 2.4483454119144383
Validation loss: 2.4271153842190496

Epoch: 6| Step: 2
Training loss: 2.5333688603804543
Validation loss: 2.406784559710309

Epoch: 6| Step: 3
Training loss: 1.863809506689936
Validation loss: 2.415019021758993

Epoch: 6| Step: 4
Training loss: 1.7576086307558547
Validation loss: 2.4013954999675935

Epoch: 6| Step: 5
Training loss: 2.2145224040403897
Validation loss: 2.3915965779985826

Epoch: 6| Step: 6
Training loss: 1.8005909850255346
Validation loss: 2.4353651495434767

Epoch: 6| Step: 7
Training loss: 2.7124804412558547
Validation loss: 2.4578356697104353

Epoch: 6| Step: 8
Training loss: 1.8915782448469252
Validation loss: 2.449745798871869

Epoch: 6| Step: 9
Training loss: 2.157255297737544
Validation loss: 2.4861649756631583

Epoch: 6| Step: 10
Training loss: 1.8915123236565057
Validation loss: 2.4912058253119302

Epoch: 6| Step: 11
Training loss: 2.3772170109206474
Validation loss: 2.459714959256706

Epoch: 6| Step: 12
Training loss: 2.6847774110732674
Validation loss: 2.4728236490788342

Epoch: 6| Step: 13
Training loss: 1.7063118053602677
Validation loss: 2.4348914052885595

Epoch: 59| Step: 0
Training loss: 1.8421981228820627
Validation loss: 2.401620341398417

Epoch: 6| Step: 1
Training loss: 2.3961580360527632
Validation loss: 2.4371113100455384

Epoch: 6| Step: 2
Training loss: 2.317516247508224
Validation loss: 2.4017319476564736

Epoch: 6| Step: 3
Training loss: 2.5834078214017406
Validation loss: 2.3859132446974765

Epoch: 6| Step: 4
Training loss: 1.9521226676091108
Validation loss: 2.4126475445524624

Epoch: 6| Step: 5
Training loss: 2.3026844695477466
Validation loss: 2.391533921929731

Epoch: 6| Step: 6
Training loss: 1.6981020711137769
Validation loss: 2.3862087206353255

Epoch: 6| Step: 7
Training loss: 1.9483414321135009
Validation loss: 2.3762810079955115

Epoch: 6| Step: 8
Training loss: 1.8035110668565153
Validation loss: 2.406160096970231

Epoch: 6| Step: 9
Training loss: 2.1657664067064037
Validation loss: 2.4089877997095113

Epoch: 6| Step: 10
Training loss: 2.250669273866858
Validation loss: 2.43344326380626

Epoch: 6| Step: 11
Training loss: 2.1989357801829166
Validation loss: 2.4550947392603812

Epoch: 6| Step: 12
Training loss: 1.757751463784075
Validation loss: 2.4550764093466393

Epoch: 6| Step: 13
Training loss: 2.0794737604993885
Validation loss: 2.408531197556314

Epoch: 60| Step: 0
Training loss: 2.5270380840564086
Validation loss: 2.439395615750158

Epoch: 6| Step: 1
Training loss: 1.6114433108687618
Validation loss: 2.4454140525262686

Epoch: 6| Step: 2
Training loss: 2.2444274559679
Validation loss: 2.4522511085883423

Epoch: 6| Step: 3
Training loss: 1.9081844457768264
Validation loss: 2.4291747309538354

Epoch: 6| Step: 4
Training loss: 1.8462039974321032
Validation loss: 2.421157197304535

Epoch: 6| Step: 5
Training loss: 2.0556544360300135
Validation loss: 2.429974889573182

Epoch: 6| Step: 6
Training loss: 1.8380829956692668
Validation loss: 2.4078792159277227

Epoch: 6| Step: 7
Training loss: 2.2346498547075626
Validation loss: 2.4450568409808886

Epoch: 6| Step: 8
Training loss: 2.140222219177471
Validation loss: 2.415209073032843

Epoch: 6| Step: 9
Training loss: 2.0959480476711194
Validation loss: 2.4030721578422716

Epoch: 6| Step: 10
Training loss: 2.000431729449174
Validation loss: 2.407376211594609

Epoch: 6| Step: 11
Training loss: 2.2626746600265943
Validation loss: 2.420924437007423

Epoch: 6| Step: 12
Training loss: 1.494154427657856
Validation loss: 2.3930765849812006

Epoch: 6| Step: 13
Training loss: 2.3917652477545137
Validation loss: 2.403233590254174

Epoch: 61| Step: 0
Training loss: 2.2846065544781773
Validation loss: 2.3966556022593792

Epoch: 6| Step: 1
Training loss: 1.6844863118775866
Validation loss: 2.421345724702559

Epoch: 6| Step: 2
Training loss: 2.497411245882582
Validation loss: 2.4004699015219906

Epoch: 6| Step: 3
Training loss: 1.573143527952804
Validation loss: 2.417442153506834

Epoch: 6| Step: 4
Training loss: 1.9684870710851878
Validation loss: 2.4093428052572836

Epoch: 6| Step: 5
Training loss: 2.5123686001707193
Validation loss: 2.399803170437852

Epoch: 6| Step: 6
Training loss: 1.8917950249142435
Validation loss: 2.407268275685539

Epoch: 6| Step: 7
Training loss: 1.822881302263459
Validation loss: 2.428411068751005

Epoch: 6| Step: 8
Training loss: 2.546951667240187
Validation loss: 2.428723715500706

Epoch: 6| Step: 9
Training loss: 1.9523050647091726
Validation loss: 2.424492633480336

Epoch: 6| Step: 10
Training loss: 1.4829116032467422
Validation loss: 2.4251711739103294

Epoch: 6| Step: 11
Training loss: 2.2767689210074717
Validation loss: 2.450232418220763

Epoch: 6| Step: 12
Training loss: 2.360865444293073
Validation loss: 2.416009605357042

Epoch: 6| Step: 13
Training loss: 1.4063840590261427
Validation loss: 2.447057132105437

Epoch: 62| Step: 0
Training loss: 1.9274677065112025
Validation loss: 2.391416298214675

Epoch: 6| Step: 1
Training loss: 2.3600761937918295
Validation loss: 2.434578522322658

Epoch: 6| Step: 2
Training loss: 2.274759648799923
Validation loss: 2.4267768229732

Epoch: 6| Step: 3
Training loss: 2.2954780326760993
Validation loss: 2.3978836795273493

Epoch: 6| Step: 4
Training loss: 2.140720337464103
Validation loss: 2.4319970539947287

Epoch: 6| Step: 5
Training loss: 2.394867367824919
Validation loss: 2.4273762396586265

Epoch: 6| Step: 6
Training loss: 2.063815766458649
Validation loss: 2.3955856831030693

Epoch: 6| Step: 7
Training loss: 1.7827260777943077
Validation loss: 2.365399078506235

Epoch: 6| Step: 8
Training loss: 2.068929879933947
Validation loss: 2.42252627404094

Epoch: 6| Step: 9
Training loss: 2.089486635302769
Validation loss: 2.4290473315424075

Epoch: 6| Step: 10
Training loss: 2.2216362246778893
Validation loss: 2.4137698986906506

Epoch: 6| Step: 11
Training loss: 1.9551765958242147
Validation loss: 2.418070489553803

Epoch: 6| Step: 12
Training loss: 1.066146595402855
Validation loss: 2.423833920300011

Epoch: 6| Step: 13
Training loss: 1.3950911394379426
Validation loss: 2.4483251244407582

Epoch: 63| Step: 0
Training loss: 2.339867899010659
Validation loss: 2.438478583153114

Epoch: 6| Step: 1
Training loss: 2.217599919937595
Validation loss: 2.374331530810448

Epoch: 6| Step: 2
Training loss: 1.7884091179472157
Validation loss: 2.424452790070057

Epoch: 6| Step: 3
Training loss: 2.204305995102301
Validation loss: 2.429186148808014

Epoch: 6| Step: 4
Training loss: 1.5144485154769287
Validation loss: 2.4042218070315404

Epoch: 6| Step: 5
Training loss: 1.8845291859063789
Validation loss: 2.4082035292609363

Epoch: 6| Step: 6
Training loss: 1.5133387045127789
Validation loss: 2.436228298131699

Epoch: 6| Step: 7
Training loss: 1.9027631794662647
Validation loss: 2.39959422992719

Epoch: 6| Step: 8
Training loss: 1.5872472606929107
Validation loss: 2.432459681805061

Epoch: 6| Step: 9
Training loss: 1.7589537582087955
Validation loss: 2.402967782369602

Epoch: 6| Step: 10
Training loss: 2.5523792536437746
Validation loss: 2.4738061369543147

Epoch: 6| Step: 11
Training loss: 2.249411929951722
Validation loss: 2.445460492775537

Epoch: 6| Step: 12
Training loss: 1.547967082144302
Validation loss: 2.409809971792602

Epoch: 6| Step: 13
Training loss: 2.8070349260365055
Validation loss: 2.416779849811108

Epoch: 64| Step: 0
Training loss: 2.1157731966434894
Validation loss: 2.401997015516855

Epoch: 6| Step: 1
Training loss: 2.268010849780415
Validation loss: 2.3951144646492732

Epoch: 6| Step: 2
Training loss: 1.8478990842835008
Validation loss: 2.4316541147943047

Epoch: 6| Step: 3
Training loss: 1.8208940747544404
Validation loss: 2.4261154133021603

Epoch: 6| Step: 4
Training loss: 1.9210969544050835
Validation loss: 2.427788305975081

Epoch: 6| Step: 5
Training loss: 2.0896580123361113
Validation loss: 2.4292448403117612

Epoch: 6| Step: 6
Training loss: 1.9305143245194227
Validation loss: 2.443719119293927

Epoch: 6| Step: 7
Training loss: 2.0546640605097206
Validation loss: 2.40443506367944

Epoch: 6| Step: 8
Training loss: 2.1451364021236086
Validation loss: 2.420495072881775

Epoch: 6| Step: 9
Training loss: 1.1508722770412596
Validation loss: 2.4378393866165515

Epoch: 6| Step: 10
Training loss: 1.7198692838766663
Validation loss: 2.4401345564918557

Epoch: 6| Step: 11
Training loss: 2.357064435735991
Validation loss: 2.4543526851532356

Epoch: 6| Step: 12
Training loss: 2.044892960337602
Validation loss: 2.4178190744774186

Epoch: 6| Step: 13
Training loss: 1.891348203944597
Validation loss: 2.4266513936728926

Epoch: 65| Step: 0
Training loss: 1.6036610322508504
Validation loss: 2.439400070912564

Epoch: 6| Step: 1
Training loss: 1.7097453662839086
Validation loss: 2.4287773136547397

Epoch: 6| Step: 2
Training loss: 1.904237591725454
Validation loss: 2.4361677359922504

Epoch: 6| Step: 3
Training loss: 1.9458667624281993
Validation loss: 2.4660168821840323

Epoch: 6| Step: 4
Training loss: 1.9396073970537981
Validation loss: 2.446991925716135

Epoch: 6| Step: 5
Training loss: 1.8774581055214739
Validation loss: 2.448964602128257

Epoch: 6| Step: 6
Training loss: 2.535672598098926
Validation loss: 2.431238429704738

Epoch: 6| Step: 7
Training loss: 1.7895978767890597
Validation loss: 2.447068336614505

Epoch: 6| Step: 8
Training loss: 1.7411893713830244
Validation loss: 2.431651982251548

Epoch: 6| Step: 9
Training loss: 1.9771151768887203
Validation loss: 2.4530233698241113

Epoch: 6| Step: 10
Training loss: 2.248116552630269
Validation loss: 2.4198343847683113

Epoch: 6| Step: 11
Training loss: 2.064111484636501
Validation loss: 2.444105555302223

Epoch: 6| Step: 12
Training loss: 2.2656426790797304
Validation loss: 2.4555399158702778

Epoch: 6| Step: 13
Training loss: 1.5766744462373088
Validation loss: 2.433410784607917

Epoch: 66| Step: 0
Training loss: 2.182632698840296
Validation loss: 2.404466132934167

Epoch: 6| Step: 1
Training loss: 2.2699194886302205
Validation loss: 2.4240287884181946

Epoch: 6| Step: 2
Training loss: 1.9717088293800442
Validation loss: 2.430099158049624

Epoch: 6| Step: 3
Training loss: 1.9796060041048666
Validation loss: 2.416136113387304

Epoch: 6| Step: 4
Training loss: 2.1284673115803456
Validation loss: 2.3807182572695624

Epoch: 6| Step: 5
Training loss: 2.02087522902434
Validation loss: 2.3722826654693305

Epoch: 6| Step: 6
Training loss: 1.9950193137474488
Validation loss: 2.4074868990606704

Epoch: 6| Step: 7
Training loss: 2.0319062566685187
Validation loss: 2.439179453223829

Epoch: 6| Step: 8
Training loss: 2.12835585452566
Validation loss: 2.419717118593806

Epoch: 6| Step: 9
Training loss: 1.2859588713973227
Validation loss: 2.399874245474923

Epoch: 6| Step: 10
Training loss: 1.8594384703502052
Validation loss: 2.4407356826490982

Epoch: 6| Step: 11
Training loss: 1.755740423703004
Validation loss: 2.439742287773553

Epoch: 6| Step: 12
Training loss: 1.7460710835532443
Validation loss: 2.4272543119747882

Epoch: 6| Step: 13
Training loss: 1.7812604401934995
Validation loss: 2.4343316279584726

Epoch: 67| Step: 0
Training loss: 2.2433604717833164
Validation loss: 2.4275475959813018

Epoch: 6| Step: 1
Training loss: 1.7890879533447948
Validation loss: 2.451304268269484

Epoch: 6| Step: 2
Training loss: 2.082888314082844
Validation loss: 2.4155060897189222

Epoch: 6| Step: 3
Training loss: 2.07051977883357
Validation loss: 2.3905329302176783

Epoch: 6| Step: 4
Training loss: 2.0779939767935645
Validation loss: 2.406969945304993

Epoch: 6| Step: 5
Training loss: 1.738130232862423
Validation loss: 2.473883558782948

Epoch: 6| Step: 6
Training loss: 1.6660603453524963
Validation loss: 2.415752572346545

Epoch: 6| Step: 7
Training loss: 2.1220941309638897
Validation loss: 2.3899510166969096

Epoch: 6| Step: 8
Training loss: 1.4814932707917938
Validation loss: 2.3965882369761196

Epoch: 6| Step: 9
Training loss: 1.9595432872385767
Validation loss: 2.3984574970484487

Epoch: 6| Step: 10
Training loss: 2.421431765451748
Validation loss: 2.425179685902927

Epoch: 6| Step: 11
Training loss: 1.8960208031603571
Validation loss: 2.4274702841514317

Epoch: 6| Step: 12
Training loss: 1.8538635377589365
Validation loss: 2.40880538203697

Epoch: 6| Step: 13
Training loss: 0.9761308250023848
Validation loss: 2.4782622848909703

Epoch: 68| Step: 0
Training loss: 2.2934276634969044
Validation loss: 2.55149291598297

Epoch: 6| Step: 1
Training loss: 1.56942632921655
Validation loss: 2.5714218080270217

Epoch: 6| Step: 2
Training loss: 2.4403782992163596
Validation loss: 2.550020635122444

Epoch: 6| Step: 3
Training loss: 2.62756603706049
Validation loss: 2.4787981309704876

Epoch: 6| Step: 4
Training loss: 2.159236553518181
Validation loss: 2.4252105795153507

Epoch: 6| Step: 5
Training loss: 1.6585809391800943
Validation loss: 2.398392203666412

Epoch: 6| Step: 6
Training loss: 1.7463382831339993
Validation loss: 2.415231316823811

Epoch: 6| Step: 7
Training loss: 2.2683849492905135
Validation loss: 2.4037095568067053

Epoch: 6| Step: 8
Training loss: 1.5492675465773127
Validation loss: 2.375281250345825

Epoch: 6| Step: 9
Training loss: 1.5869725049334644
Validation loss: 2.4215940579133424

Epoch: 6| Step: 10
Training loss: 1.7139754128044666
Validation loss: 2.40314962624977

Epoch: 6| Step: 11
Training loss: 2.403168129006877
Validation loss: 2.4247607031141314

Epoch: 6| Step: 12
Training loss: 1.3613994037898667
Validation loss: 2.369327002163022

Epoch: 6| Step: 13
Training loss: 1.8517096094851095
Validation loss: 2.401970414096202

Epoch: 69| Step: 0
Training loss: 2.1872738312558693
Validation loss: 2.4679244065333763

Epoch: 6| Step: 1
Training loss: 1.872596089809564
Validation loss: 2.4294674396519453

Epoch: 6| Step: 2
Training loss: 1.3182817450379232
Validation loss: 2.3975939349274817

Epoch: 6| Step: 3
Training loss: 1.5254368891031576
Validation loss: 2.360909777515774

Epoch: 6| Step: 4
Training loss: 2.262397835463928
Validation loss: 2.433379056143888

Epoch: 6| Step: 5
Training loss: 1.6778163690037489
Validation loss: 2.412351839592397

Epoch: 6| Step: 6
Training loss: 1.5596303910332479
Validation loss: 2.3583578818383657

Epoch: 6| Step: 7
Training loss: 2.123858537959606
Validation loss: 2.4135825987730897

Epoch: 6| Step: 8
Training loss: 2.096077379865842
Validation loss: 2.408014591754223

Epoch: 6| Step: 9
Training loss: 1.26600057421727
Validation loss: 2.3974002082006325

Epoch: 6| Step: 10
Training loss: 1.491600360497748
Validation loss: 2.404099217421279

Epoch: 6| Step: 11
Training loss: 2.013831353370514
Validation loss: 2.3906255069640707

Epoch: 6| Step: 12
Training loss: 1.9384247818572204
Validation loss: 2.4130118263604037

Epoch: 6| Step: 13
Training loss: 2.556327083703201
Validation loss: 2.431855782791008

Epoch: 70| Step: 0
Training loss: 1.1342515946617293
Validation loss: 2.4263531128035707

Epoch: 6| Step: 1
Training loss: 1.6501111397737265
Validation loss: 2.443372873278645

Epoch: 6| Step: 2
Training loss: 2.184968519005853
Validation loss: 2.406487226145707

Epoch: 6| Step: 3
Training loss: 1.527909976364453
Validation loss: 2.37665697487259

Epoch: 6| Step: 4
Training loss: 2.060210488870826
Validation loss: 2.413529124177281

Epoch: 6| Step: 5
Training loss: 1.9488510365992584
Validation loss: 2.406722472403297

Epoch: 6| Step: 6
Training loss: 1.7897848478405018
Validation loss: 2.4140215626427564

Epoch: 6| Step: 7
Training loss: 1.3590163711504928
Validation loss: 2.4288887109181503

Epoch: 6| Step: 8
Training loss: 1.6241868992591264
Validation loss: 2.425144146702115

Epoch: 6| Step: 9
Training loss: 2.6605815799495596
Validation loss: 2.466065093628487

Epoch: 6| Step: 10
Training loss: 1.7600239723913802
Validation loss: 2.421976952816682

Epoch: 6| Step: 11
Training loss: 2.458148550642859
Validation loss: 2.4143714419042546

Epoch: 6| Step: 12
Training loss: 1.7534510100270322
Validation loss: 2.444025759410849

Epoch: 6| Step: 13
Training loss: 1.2978743414103342
Validation loss: 2.4190069711029376

Epoch: 71| Step: 0
Training loss: 1.1807138386749352
Validation loss: 2.4212158782870663

Epoch: 6| Step: 1
Training loss: 2.17704344595793
Validation loss: 2.3845811793892895

Epoch: 6| Step: 2
Training loss: 1.2756303967852818
Validation loss: 2.4038519366268147

Epoch: 6| Step: 3
Training loss: 1.8151155213302337
Validation loss: 2.431431029247653

Epoch: 6| Step: 4
Training loss: 1.8955714565403716
Validation loss: 2.4153359931562988

Epoch: 6| Step: 5
Training loss: 2.1838793627499027
Validation loss: 2.4061654311342506

Epoch: 6| Step: 6
Training loss: 2.7637388187563565
Validation loss: 2.414198598965438

Epoch: 6| Step: 7
Training loss: 1.3421272415294476
Validation loss: 2.4371250874992705

Epoch: 6| Step: 8
Training loss: 1.5204893881600905
Validation loss: 2.4040063991932215

Epoch: 6| Step: 9
Training loss: 2.199523796214705
Validation loss: 2.470062759904539

Epoch: 6| Step: 10
Training loss: 1.843672152669981
Validation loss: 2.4885413464598822

Epoch: 6| Step: 11
Training loss: 1.9638925604791175
Validation loss: 2.4972448744245654

Epoch: 6| Step: 12
Training loss: 2.1001066816571057
Validation loss: 2.4573920651622116

Epoch: 6| Step: 13
Training loss: 1.242937545336718
Validation loss: 2.429943811240568

Epoch: 72| Step: 0
Training loss: 1.5608882220397047
Validation loss: 2.3847017563440525

Epoch: 6| Step: 1
Training loss: 2.1100684262430294
Validation loss: 2.4062498761461897

Epoch: 6| Step: 2
Training loss: 2.101618315795731
Validation loss: 2.4368064415324535

Epoch: 6| Step: 3
Training loss: 1.4423828125
Validation loss: 2.4497996832252014

Epoch: 6| Step: 4
Training loss: 1.6511211516524407
Validation loss: 2.402389004909114

Epoch: 6| Step: 5
Training loss: 2.053642790602899
Validation loss: 2.4199852082034266

Epoch: 6| Step: 6
Training loss: 1.4653178757438563
Validation loss: 2.436673309466713

Epoch: 6| Step: 7
Training loss: 1.8976916822232792
Validation loss: 2.3989855277910417

Epoch: 6| Step: 8
Training loss: 1.8007624494849668
Validation loss: 2.431624332562345

Epoch: 6| Step: 9
Training loss: 1.9934683478229527
Validation loss: 2.440516105628932

Epoch: 6| Step: 10
Training loss: 1.8224608223763494
Validation loss: 2.5291504649398022

Epoch: 6| Step: 11
Training loss: 2.0543798644237765
Validation loss: 2.5019243622356666

Epoch: 6| Step: 12
Training loss: 2.0804305516803465
Validation loss: 2.4687049958195244

Epoch: 6| Step: 13
Training loss: 1.423641239664144
Validation loss: 2.4697884817973024

Epoch: 73| Step: 0
Training loss: 1.1995534026075694
Validation loss: 2.407424689567786

Epoch: 6| Step: 1
Training loss: 1.908925289756343
Validation loss: 2.404344200331666

Epoch: 6| Step: 2
Training loss: 1.504893268843459
Validation loss: 2.4264905857909964

Epoch: 6| Step: 3
Training loss: 2.070382171034363
Validation loss: 2.3930882663917945

Epoch: 6| Step: 4
Training loss: 1.2056847132266524
Validation loss: 2.4332883509523717

Epoch: 6| Step: 5
Training loss: 1.9401899553486235
Validation loss: 2.4147911083317437

Epoch: 6| Step: 6
Training loss: 2.0249158253070316
Validation loss: 2.420888203400132

Epoch: 6| Step: 7
Training loss: 1.95821845617253
Validation loss: 2.4386363192936993

Epoch: 6| Step: 8
Training loss: 2.0636738991064036
Validation loss: 2.4211529793746216

Epoch: 6| Step: 9
Training loss: 1.705567804134483
Validation loss: 2.3999007211125405

Epoch: 6| Step: 10
Training loss: 2.731639256443601
Validation loss: 2.480339579585585

Epoch: 6| Step: 11
Training loss: 1.4181577278082937
Validation loss: 2.4056893062874987

Epoch: 6| Step: 12
Training loss: 1.3854907118817401
Validation loss: 2.4429662171145243

Epoch: 6| Step: 13
Training loss: 1.163982772657061
Validation loss: 2.444661046555946

Epoch: 74| Step: 0
Training loss: 1.7039875331207697
Validation loss: 2.487238706989924

Epoch: 6| Step: 1
Training loss: 1.6726428969027076
Validation loss: 2.486041695556879

Epoch: 6| Step: 2
Training loss: 1.2903715480561309
Validation loss: 2.449927714637382

Epoch: 6| Step: 3
Training loss: 1.7789203065259036
Validation loss: 2.4029356353982987

Epoch: 6| Step: 4
Training loss: 1.2843713653587276
Validation loss: 2.4393001495196973

Epoch: 6| Step: 5
Training loss: 1.6669288270124045
Validation loss: 2.4601247989586037

Epoch: 6| Step: 6
Training loss: 2.027744848892654
Validation loss: 2.445067794629605

Epoch: 6| Step: 7
Training loss: 1.7442178570264024
Validation loss: 2.4313860615736935

Epoch: 6| Step: 8
Training loss: 1.785342016925923
Validation loss: 2.3695122075450286

Epoch: 6| Step: 9
Training loss: 1.8702684465795594
Validation loss: 2.430059700900995

Epoch: 6| Step: 10
Training loss: 2.076840455430612
Validation loss: 2.4512595273743285

Epoch: 6| Step: 11
Training loss: 2.2829234634783746
Validation loss: 2.3872650570136433

Epoch: 6| Step: 12
Training loss: 1.3207600754760251
Validation loss: 2.470007837543074

Epoch: 6| Step: 13
Training loss: 1.7644887323103526
Validation loss: 2.4734707535905898

Epoch: 75| Step: 0
Training loss: 1.4680216992357027
Validation loss: 2.420317823988245

Epoch: 6| Step: 1
Training loss: 2.006584296495024
Validation loss: 2.450028378458518

Epoch: 6| Step: 2
Training loss: 1.6865076043336116
Validation loss: 2.444407644018923

Epoch: 6| Step: 3
Training loss: 1.9111288204161168
Validation loss: 2.442570563839003

Epoch: 6| Step: 4
Training loss: 1.8931914635795255
Validation loss: 2.426587759567289

Epoch: 6| Step: 5
Training loss: 2.191214758790344
Validation loss: 2.411977631012333

Epoch: 6| Step: 6
Training loss: 1.82061843593264
Validation loss: 2.4140024187991904

Epoch: 6| Step: 7
Training loss: 1.9509543602169206
Validation loss: 2.419728449700318

Epoch: 6| Step: 8
Training loss: 1.193118306736184
Validation loss: 2.447360122938612

Epoch: 6| Step: 9
Training loss: 1.7029873853609387
Validation loss: 2.4858496426047214

Epoch: 6| Step: 10
Training loss: 1.5290675277518153
Validation loss: 2.417903400086522

Epoch: 6| Step: 11
Training loss: 1.0142855100708263
Validation loss: 2.424640086099201

Epoch: 6| Step: 12
Training loss: 1.9207203815981386
Validation loss: 2.481325785442818

Epoch: 6| Step: 13
Training loss: 1.5594218642659632
Validation loss: 2.489317306499995

Epoch: 76| Step: 0
Training loss: 1.645947931219319
Validation loss: 2.4926167818933873

Epoch: 6| Step: 1
Training loss: 1.544846254371611
Validation loss: 2.4175628666558806

Epoch: 6| Step: 2
Training loss: 1.6650290391010616
Validation loss: 2.4448462824876316

Epoch: 6| Step: 3
Training loss: 1.8082325123516572
Validation loss: 2.40493808008374

Epoch: 6| Step: 4
Training loss: 1.045709730091118
Validation loss: 2.4403861312775175

Epoch: 6| Step: 5
Training loss: 1.5318574284479964
Validation loss: 2.4130493391825976

Epoch: 6| Step: 6
Training loss: 1.7587791667111252
Validation loss: 2.4155840065435874

Epoch: 6| Step: 7
Training loss: 1.6982501897903037
Validation loss: 2.4474307179865327

Epoch: 6| Step: 8
Training loss: 2.15270727172026
Validation loss: 2.3885014479176716

Epoch: 6| Step: 9
Training loss: 1.5772997520775982
Validation loss: 2.444679072587938

Epoch: 6| Step: 10
Training loss: 1.6852726541990435
Validation loss: 2.3961387163223007

Epoch: 6| Step: 11
Training loss: 2.138665297685377
Validation loss: 2.4759606112344765

Epoch: 6| Step: 12
Training loss: 1.2766635962134774
Validation loss: 2.4005917329609368

Epoch: 6| Step: 13
Training loss: 2.0074613390248497
Validation loss: 2.4450490645105827

Epoch: 77| Step: 0
Training loss: 1.367760064259733
Validation loss: 2.435562790423787

Epoch: 6| Step: 1
Training loss: 1.3692178527557453
Validation loss: 2.4543102988766927

Epoch: 6| Step: 2
Training loss: 1.6628933233338234
Validation loss: 2.4553372881858615

Epoch: 6| Step: 3
Training loss: 1.0970954955967782
Validation loss: 2.435542845142725

Epoch: 6| Step: 4
Training loss: 1.6239098046347487
Validation loss: 2.4218000338857517

Epoch: 6| Step: 5
Training loss: 1.337531627744548
Validation loss: 2.4242011927400084

Epoch: 6| Step: 6
Training loss: 1.3879247444869816
Validation loss: 2.43132271482225

Epoch: 6| Step: 7
Training loss: 2.3444517992254825
Validation loss: 2.461235633835294

Epoch: 6| Step: 8
Training loss: 2.2381062331021364
Validation loss: 2.396347593317687

Epoch: 6| Step: 9
Training loss: 2.122396894271367
Validation loss: 2.4558327991116964

Epoch: 6| Step: 10
Training loss: 1.4784079831244283
Validation loss: 2.480943176875515

Epoch: 6| Step: 11
Training loss: 1.5984605476157163
Validation loss: 2.438916846061748

Epoch: 6| Step: 12
Training loss: 1.4249721792081886
Validation loss: 2.419805352025464

Epoch: 6| Step: 13
Training loss: 1.578095992926484
Validation loss: 2.463343232586198

Epoch: 78| Step: 0
Training loss: 1.5336181079020323
Validation loss: 2.4520730842974654

Epoch: 6| Step: 1
Training loss: 1.4249717609217518
Validation loss: 2.4685956608940156

Epoch: 6| Step: 2
Training loss: 1.6551145584241498
Validation loss: 2.4330309956556087

Epoch: 6| Step: 3
Training loss: 2.300413766214368
Validation loss: 2.431812579549053

Epoch: 6| Step: 4
Training loss: 1.4143212856151504
Validation loss: 2.4544751365807804

Epoch: 6| Step: 5
Training loss: 1.549304787790308
Validation loss: 2.4421299383140824

Epoch: 6| Step: 6
Training loss: 1.1580937094251833
Validation loss: 2.4295863941085902

Epoch: 6| Step: 7
Training loss: 1.5755520231664384
Validation loss: 2.4853473096210337

Epoch: 6| Step: 8
Training loss: 2.289784600734582
Validation loss: 2.445867083531635

Epoch: 6| Step: 9
Training loss: 1.4686542236267393
Validation loss: 2.4727492151767896

Epoch: 6| Step: 10
Training loss: 2.0570648712180697
Validation loss: 2.443900751990958

Epoch: 6| Step: 11
Training loss: 1.1961864692137025
Validation loss: 2.4491438582964427

Epoch: 6| Step: 12
Training loss: 1.058547747411282
Validation loss: 2.404833901261468

Epoch: 6| Step: 13
Training loss: 1.5181020571159576
Validation loss: 2.414309088860383

Epoch: 79| Step: 0
Training loss: 1.3760377695671917
Validation loss: 2.4760060933828485

Epoch: 6| Step: 1
Training loss: 1.5696683862681733
Validation loss: 2.4530680947476515

Epoch: 6| Step: 2
Training loss: 1.5994151536642236
Validation loss: 2.388885180768627

Epoch: 6| Step: 3
Training loss: 1.3421634356614056
Validation loss: 2.447584346101068

Epoch: 6| Step: 4
Training loss: 1.5353232722386871
Validation loss: 2.4536621250839015

Epoch: 6| Step: 5
Training loss: 1.398648123623383
Validation loss: 2.4707430910438912

Epoch: 6| Step: 6
Training loss: 1.6935324046996627
Validation loss: 2.4488448040564035

Epoch: 6| Step: 7
Training loss: 1.6546314896423655
Validation loss: 2.474945471063381

Epoch: 6| Step: 8
Training loss: 1.685069700661562
Validation loss: 2.409404932241056

Epoch: 6| Step: 9
Training loss: 1.1716944237501068
Validation loss: 2.425028775886665

Epoch: 6| Step: 10
Training loss: 1.4908111775889397
Validation loss: 2.4011038870758936

Epoch: 6| Step: 11
Training loss: 1.533212843943121
Validation loss: 2.507126346891384

Epoch: 6| Step: 12
Training loss: 1.8257613592733375
Validation loss: 2.4196288490995927

Epoch: 6| Step: 13
Training loss: 2.2791421636720655
Validation loss: 2.4868690399765763

Epoch: 80| Step: 0
Training loss: 1.4269745314209272
Validation loss: 2.489794404301226

Epoch: 6| Step: 1
Training loss: 1.55567984803471
Validation loss: 2.4478061542861353

Epoch: 6| Step: 2
Training loss: 1.4113319969176925
Validation loss: 2.480800031832076

Epoch: 6| Step: 3
Training loss: 1.6836979030600832
Validation loss: 2.4482230596678947

Epoch: 6| Step: 4
Training loss: 1.2671627545557056
Validation loss: 2.438658170158987

Epoch: 6| Step: 5
Training loss: 1.308662936530981
Validation loss: 2.450939184646517

Epoch: 6| Step: 6
Training loss: 1.7964465086501078
Validation loss: 2.4700080788566474

Epoch: 6| Step: 7
Training loss: 1.3902569830337868
Validation loss: 2.507773631776083

Epoch: 6| Step: 8
Training loss: 1.52545478480725
Validation loss: 2.4710848909135428

Epoch: 6| Step: 9
Training loss: 1.6881241527161208
Validation loss: 2.3857929288361057

Epoch: 6| Step: 10
Training loss: 1.972729249113425
Validation loss: 2.4339814017668524

Epoch: 6| Step: 11
Training loss: 1.592470740224661
Validation loss: 2.482550544915696

Epoch: 6| Step: 12
Training loss: 2.1091551489523703
Validation loss: 2.5595674714877164

Epoch: 6| Step: 13
Training loss: 1.2725021578127809
Validation loss: 2.5905518175194913

Epoch: 81| Step: 0
Training loss: 1.8251309125794177
Validation loss: 2.5269530287627755

Epoch: 6| Step: 1
Training loss: 1.2032943210107345
Validation loss: 2.5438728502805663

Epoch: 6| Step: 2
Training loss: 1.8279364725046703
Validation loss: 2.514963935886722

Epoch: 6| Step: 3
Training loss: 1.4615496816474725
Validation loss: 2.4306217372300525

Epoch: 6| Step: 4
Training loss: 1.6500109354292574
Validation loss: 2.4370698630820007

Epoch: 6| Step: 5
Training loss: 2.3013699722305567
Validation loss: 2.441119384188266

Epoch: 6| Step: 6
Training loss: 1.0170496412106773
Validation loss: 2.5238732118273854

Epoch: 6| Step: 7
Training loss: 1.6549171266810465
Validation loss: 2.4878716882811647

Epoch: 6| Step: 8
Training loss: 1.7910464418312175
Validation loss: 2.568823262180832

Epoch: 6| Step: 9
Training loss: 2.0798379822132973
Validation loss: 2.4362721733439945

Epoch: 6| Step: 10
Training loss: 1.4112608326850102
Validation loss: 2.436094726682357

Epoch: 6| Step: 11
Training loss: 1.6199985711362213
Validation loss: 2.4602698818246282

Epoch: 6| Step: 12
Training loss: 1.23783881048002
Validation loss: 2.51392800094031

Epoch: 6| Step: 13
Training loss: 1.5732103625156308
Validation loss: 2.438820986344372

Epoch: 82| Step: 0
Training loss: 1.3200508174362129
Validation loss: 2.52385072897274

Epoch: 6| Step: 1
Training loss: 1.3936776933602586
Validation loss: 2.5120507352629717

Epoch: 6| Step: 2
Training loss: 1.1406123539471806
Validation loss: 2.452139071141925

Epoch: 6| Step: 3
Training loss: 2.3223690077321804
Validation loss: 2.4466832942900028

Epoch: 6| Step: 4
Training loss: 1.2831159820462716
Validation loss: 2.452970285254593

Epoch: 6| Step: 5
Training loss: 1.8504190898152992
Validation loss: 2.39927317488136

Epoch: 6| Step: 6
Training loss: 1.474052596925292
Validation loss: 2.323825732428851

Epoch: 6| Step: 7
Training loss: 1.8503448087670515
Validation loss: 2.4268859706633648

Epoch: 6| Step: 8
Training loss: 1.70307040345762
Validation loss: 2.4380318069672837

Epoch: 6| Step: 9
Training loss: 1.5026030207144225
Validation loss: 2.3720877426761358

Epoch: 6| Step: 10
Training loss: 1.2500668984631342
Validation loss: 2.4469220812584913

Epoch: 6| Step: 11
Training loss: 1.457717529343468
Validation loss: 2.460537687249054

Epoch: 6| Step: 12
Training loss: 1.489106197456537
Validation loss: 2.4710765772498293

Epoch: 6| Step: 13
Training loss: 1.4259293988741977
Validation loss: 2.471087302996426

Epoch: 83| Step: 0
Training loss: 1.2525473388131954
Validation loss: 2.5209978906394914

Epoch: 6| Step: 1
Training loss: 1.8936761243655975
Validation loss: 2.524741765782536

Epoch: 6| Step: 2
Training loss: 1.9482113484401322
Validation loss: 2.649713806976738

Epoch: 6| Step: 3
Training loss: 1.2890733660615654
Validation loss: 2.655301062929037

Epoch: 6| Step: 4
Training loss: 2.1630358963596583
Validation loss: 2.567035321186706

Epoch: 6| Step: 5
Training loss: 1.748254041276775
Validation loss: 2.4379781107401017

Epoch: 6| Step: 6
Training loss: 1.7518817457544866
Validation loss: 2.394779601086762

Epoch: 6| Step: 7
Training loss: 1.704102541860392
Validation loss: 2.4735114701231753

Epoch: 6| Step: 8
Training loss: 1.3446542225912652
Validation loss: 2.5186589428870922

Epoch: 6| Step: 9
Training loss: 1.9163153644320268
Validation loss: 2.567649691042975

Epoch: 6| Step: 10
Training loss: 1.6165496747791088
Validation loss: 2.5890469943717807

Epoch: 6| Step: 11
Training loss: 1.6270981960944726
Validation loss: 2.518847042893104

Epoch: 6| Step: 12
Training loss: 1.5475380757566994
Validation loss: 2.444493767091427

Epoch: 6| Step: 13
Training loss: 1.267297463872818
Validation loss: 2.438926931194114

Epoch: 84| Step: 0
Training loss: 1.4057598531378728
Validation loss: 2.412555936385594

Epoch: 6| Step: 1
Training loss: 1.7140726428223005
Validation loss: 2.556899657701299

Epoch: 6| Step: 2
Training loss: 1.511375210783542
Validation loss: 2.5481915961651316

Epoch: 6| Step: 3
Training loss: 1.8448759617242427
Validation loss: 2.5384822867211723

Epoch: 6| Step: 4
Training loss: 1.1723954126037268
Validation loss: 2.4777798553804016

Epoch: 6| Step: 5
Training loss: 1.6188699567379132
Validation loss: 2.4233373021544113

Epoch: 6| Step: 6
Training loss: 1.6233005440211872
Validation loss: 2.4076020211706863

Epoch: 6| Step: 7
Training loss: 0.9789086806867643
Validation loss: 2.430371481570627

Epoch: 6| Step: 8
Training loss: 1.3713628173431647
Validation loss: 2.417971773818451

Epoch: 6| Step: 9
Training loss: 2.067009244745894
Validation loss: 2.4343446213047297

Epoch: 6| Step: 10
Training loss: 1.2418322745020742
Validation loss: 2.438382575836592

Epoch: 6| Step: 11
Training loss: 2.1170061885435154
Validation loss: 2.4929655608425065

Epoch: 6| Step: 12
Training loss: 1.6407089211934767
Validation loss: 2.4861653272896205

Epoch: 6| Step: 13
Training loss: 1.6471253004002173
Validation loss: 2.467909899351378

Epoch: 85| Step: 0
Training loss: 1.423861195791135
Validation loss: 2.434630636913082

Epoch: 6| Step: 1
Training loss: 1.1966070009585612
Validation loss: 2.3943367858880236

Epoch: 6| Step: 2
Training loss: 1.905382052580633
Validation loss: 2.3829740042229686

Epoch: 6| Step: 3
Training loss: 1.3695746807168971
Validation loss: 2.415899275473756

Epoch: 6| Step: 4
Training loss: 1.5953098965884196
Validation loss: 2.3725892765196317

Epoch: 6| Step: 5
Training loss: 1.2841668770154764
Validation loss: 2.442479707854207

Epoch: 6| Step: 6
Training loss: 1.3982620555426866
Validation loss: 2.449899938706907

Epoch: 6| Step: 7
Training loss: 1.5352546330344632
Validation loss: 2.4850865750547557

Epoch: 6| Step: 8
Training loss: 1.389035463016366
Validation loss: 2.456449600535063

Epoch: 6| Step: 9
Training loss: 1.9810019232496527
Validation loss: 2.4390537005210176

Epoch: 6| Step: 10
Training loss: 1.4431234742524552
Validation loss: 2.44719663270563

Epoch: 6| Step: 11
Training loss: 1.8944485675820346
Validation loss: 2.4313585069202324

Epoch: 6| Step: 12
Training loss: 1.0127294492347954
Validation loss: 2.4361051660385677

Epoch: 6| Step: 13
Training loss: 1.494632973925574
Validation loss: 2.436274138739289

Epoch: 86| Step: 0
Training loss: 0.990741787834314
Validation loss: 2.4641525903591504

Epoch: 6| Step: 1
Training loss: 1.1225741511026415
Validation loss: 2.435151525661539

Epoch: 6| Step: 2
Training loss: 1.4176551324904494
Validation loss: 2.4500807158480167

Epoch: 6| Step: 3
Training loss: 1.8568873714418808
Validation loss: 2.398803682983889

Epoch: 6| Step: 4
Training loss: 1.6613188139912192
Validation loss: 2.4501984425060135

Epoch: 6| Step: 5
Training loss: 1.4860651934096702
Validation loss: 2.437509308495639

Epoch: 6| Step: 6
Training loss: 2.2138945414195645
Validation loss: 2.4614376952449217

Epoch: 6| Step: 7
Training loss: 1.3403480848452312
Validation loss: 2.5055197497748933

Epoch: 6| Step: 8
Training loss: 1.2901581702738392
Validation loss: 2.5621860280788558

Epoch: 6| Step: 9
Training loss: 1.4794331252392092
Validation loss: 2.456600440524584

Epoch: 6| Step: 10
Training loss: 1.6083838364309555
Validation loss: 2.5209335170626272

Epoch: 6| Step: 11
Training loss: 1.0413451397902593
Validation loss: 2.450323680010037

Epoch: 6| Step: 12
Training loss: 1.3582540252951691
Validation loss: 2.4260863656402742

Epoch: 6| Step: 13
Training loss: 1.432921873221663
Validation loss: 2.4687026779854393

Epoch: 87| Step: 0
Training loss: 1.0601583369774963
Validation loss: 2.4524734749560197

Epoch: 6| Step: 1
Training loss: 1.344791629632683
Validation loss: 2.4433581227462735

Epoch: 6| Step: 2
Training loss: 1.5064588409888622
Validation loss: 2.4785060536686006

Epoch: 6| Step: 3
Training loss: 1.762557208708684
Validation loss: 2.495202786544372

Epoch: 6| Step: 4
Training loss: 1.4632748759996987
Validation loss: 2.4513521693009768

Epoch: 6| Step: 5
Training loss: 1.3459905530589544
Validation loss: 2.45900101942631

Epoch: 6| Step: 6
Training loss: 1.348005874173867
Validation loss: 2.4487981683583615

Epoch: 6| Step: 7
Training loss: 1.178753009035835
Validation loss: 2.5008272789061223

Epoch: 6| Step: 8
Training loss: 1.8586605205945088
Validation loss: 2.546063190412198

Epoch: 6| Step: 9
Training loss: 1.3011373771278882
Validation loss: 2.5443351110162884

Epoch: 6| Step: 10
Training loss: 1.3581063500224095
Validation loss: 2.511374458379638

Epoch: 6| Step: 11
Training loss: 1.676297621765252
Validation loss: 2.4898551781859597

Epoch: 6| Step: 12
Training loss: 2.1960482738865816
Validation loss: 2.4481437631874403

Epoch: 6| Step: 13
Training loss: 1.1790644029591337
Validation loss: 2.4893017028315456

Epoch: 88| Step: 0
Training loss: 1.3642760311758864
Validation loss: 2.4332307123292276

Epoch: 6| Step: 1
Training loss: 1.467586381049816
Validation loss: 2.506285736450716

Epoch: 6| Step: 2
Training loss: 1.6871979761054543
Validation loss: 2.5072017888652502

Epoch: 6| Step: 3
Training loss: 1.4333738735291355
Validation loss: 2.4667997906391532

Epoch: 6| Step: 4
Training loss: 1.1539608228998326
Validation loss: 2.4093486766309042

Epoch: 6| Step: 5
Training loss: 1.7715561083619291
Validation loss: 2.4453513047914432

Epoch: 6| Step: 6
Training loss: 1.587376134650791
Validation loss: 2.427549592993618

Epoch: 6| Step: 7
Training loss: 1.360133869089989
Validation loss: 2.490457649942562

Epoch: 6| Step: 8
Training loss: 1.0451854908052538
Validation loss: 2.486590103687193

Epoch: 6| Step: 9
Training loss: 1.3099160872221376
Validation loss: 2.5005242592750307

Epoch: 6| Step: 10
Training loss: 2.0257562143681724
Validation loss: 2.490057646021565

Epoch: 6| Step: 11
Training loss: 1.2116228686728858
Validation loss: 2.4340140202802063

Epoch: 6| Step: 12
Training loss: 1.1610522679401023
Validation loss: 2.4860322970560578

Epoch: 6| Step: 13
Training loss: 1.1209931544453036
Validation loss: 2.5038864206370994

Epoch: 89| Step: 0
Training loss: 1.9321843723282293
Validation loss: 2.529819602415192

Epoch: 6| Step: 1
Training loss: 1.7703542921582627
Validation loss: 2.5308382774792926

Epoch: 6| Step: 2
Training loss: 1.6503630325448622
Validation loss: 2.5388045585876684

Epoch: 6| Step: 3
Training loss: 1.7525537114204444
Validation loss: 2.4611087073459563

Epoch: 6| Step: 4
Training loss: 1.231294675684558
Validation loss: 2.482484542091701

Epoch: 6| Step: 5
Training loss: 1.2309376141213264
Validation loss: 2.394690470460721

Epoch: 6| Step: 6
Training loss: 1.200134077131783
Validation loss: 2.438539430100432

Epoch: 6| Step: 7
Training loss: 1.115534646785848
Validation loss: 2.5098649892173723

Epoch: 6| Step: 8
Training loss: 1.4541007426857158
Validation loss: 2.450716265602306

Epoch: 6| Step: 9
Training loss: 1.055220010334464
Validation loss: 2.4636270590264893

Epoch: 6| Step: 10
Training loss: 1.7134724132453252
Validation loss: 2.4486669378130763

Epoch: 6| Step: 11
Training loss: 1.3372954221047648
Validation loss: 2.426910907258028

Epoch: 6| Step: 12
Training loss: 1.230847497202984
Validation loss: 2.4162002036562615

Epoch: 6| Step: 13
Training loss: 1.1854641176904788
Validation loss: 2.4203897085038584

Epoch: 90| Step: 0
Training loss: 1.3895559166181943
Validation loss: 2.4324085662217962

Epoch: 6| Step: 1
Training loss: 1.4557245444381932
Validation loss: 2.424226689671439

Epoch: 6| Step: 2
Training loss: 1.0278037314245363
Validation loss: 2.4746214503289963

Epoch: 6| Step: 3
Training loss: 1.1595356626828892
Validation loss: 2.4883057629522147

Epoch: 6| Step: 4
Training loss: 1.5573651435724472
Validation loss: 2.4010962164937277

Epoch: 6| Step: 5
Training loss: 1.3915801893232584
Validation loss: 2.468631628876565

Epoch: 6| Step: 6
Training loss: 1.0500039554703096
Validation loss: 2.3968992985534467

Epoch: 6| Step: 7
Training loss: 1.4332546072046957
Validation loss: 2.551976078400659

Epoch: 6| Step: 8
Training loss: 2.1801219220146
Validation loss: 2.474138616049762

Epoch: 6| Step: 9
Training loss: 1.1558779556106265
Validation loss: 2.4700055048439777

Epoch: 6| Step: 10
Training loss: 1.5246891455339455
Validation loss: 2.4943570028477966

Epoch: 6| Step: 11
Training loss: 1.3261949315264914
Validation loss: 2.4441811703983105

Epoch: 6| Step: 12
Training loss: 1.2634989459475312
Validation loss: 2.466476125596333

Epoch: 6| Step: 13
Training loss: 1.3796264237464526
Validation loss: 2.5141603617156565

Epoch: 91| Step: 0
Training loss: 2.076110551848946
Validation loss: 2.44930356014228

Epoch: 6| Step: 1
Training loss: 1.3876602630162036
Validation loss: 2.5169522198196295

Epoch: 6| Step: 2
Training loss: 1.191420658212058
Validation loss: 2.588018634437205

Epoch: 6| Step: 3
Training loss: 0.9598207885638667
Validation loss: 2.4905187905646895

Epoch: 6| Step: 4
Training loss: 1.2704248657829433
Validation loss: 2.4512916403966467

Epoch: 6| Step: 5
Training loss: 1.7264428420914104
Validation loss: 2.442443212397588

Epoch: 6| Step: 6
Training loss: 1.580775989758626
Validation loss: 2.508822814944023

Epoch: 6| Step: 7
Training loss: 1.3987727269566905
Validation loss: 2.543775923563263

Epoch: 6| Step: 8
Training loss: 1.4156032198478856
Validation loss: 2.5011878529481693

Epoch: 6| Step: 9
Training loss: 1.7949000908294508
Validation loss: 2.560984031280896

Epoch: 6| Step: 10
Training loss: 1.2609792142299938
Validation loss: 2.4318465343552162

Epoch: 6| Step: 11
Training loss: 0.9989550614659757
Validation loss: 2.4531460171910804

Epoch: 6| Step: 12
Training loss: 1.2254584622294797
Validation loss: 2.4447464942957704

Epoch: 6| Step: 13
Training loss: 1.4003515517398062
Validation loss: 2.5033335236533643

Epoch: 92| Step: 0
Training loss: 1.2871693436540736
Validation loss: 2.4967176347206395

Epoch: 6| Step: 1
Training loss: 1.4403753962226156
Validation loss: 2.5244886415583285

Epoch: 6| Step: 2
Training loss: 1.5525914156378533
Validation loss: 2.49934719622544

Epoch: 6| Step: 3
Training loss: 1.2367908160381906
Validation loss: 2.461028679667301

Epoch: 6| Step: 4
Training loss: 0.9141536243369586
Validation loss: 2.43192440149121

Epoch: 6| Step: 5
Training loss: 0.9537006265901994
Validation loss: 2.432077554976153

Epoch: 6| Step: 6
Training loss: 1.140841006375561
Validation loss: 2.4175180437268704

Epoch: 6| Step: 7
Training loss: 1.9696498812424366
Validation loss: 2.481911099217075

Epoch: 6| Step: 8
Training loss: 1.3745230367679007
Validation loss: 2.444039018260728

Epoch: 6| Step: 9
Training loss: 1.7314523351433302
Validation loss: 2.4076784856172484

Epoch: 6| Step: 10
Training loss: 0.7924119469615781
Validation loss: 2.4498668748018955

Epoch: 6| Step: 11
Training loss: 1.7685289386326155
Validation loss: 2.4266926092116523

Epoch: 6| Step: 12
Training loss: 1.3741398201504755
Validation loss: 2.485256942216938

Epoch: 6| Step: 13
Training loss: 1.263531684469159
Validation loss: 2.4084168623152276

Epoch: 93| Step: 0
Training loss: 1.4186258606228699
Validation loss: 2.422495190366649

Epoch: 6| Step: 1
Training loss: 1.1533558684188971
Validation loss: 2.4324498802424186

Epoch: 6| Step: 2
Training loss: 1.44952611414271
Validation loss: 2.4289866067185475

Epoch: 6| Step: 3
Training loss: 1.092202154014851
Validation loss: 2.4593021024946147

Epoch: 6| Step: 4
Training loss: 1.3319483756408559
Validation loss: 2.393484346208822

Epoch: 6| Step: 5
Training loss: 1.3939625838798393
Validation loss: 2.4517339500186375

Epoch: 6| Step: 6
Training loss: 1.3498096897064018
Validation loss: 2.397429968069981

Epoch: 6| Step: 7
Training loss: 0.8397914426616072
Validation loss: 2.432312556196821

Epoch: 6| Step: 8
Training loss: 1.322653821930569
Validation loss: 2.439711342006898

Epoch: 6| Step: 9
Training loss: 1.4781588850915843
Validation loss: 2.4831720634767254

Epoch: 6| Step: 10
Training loss: 1.1181704591793016
Validation loss: 2.4808962796441065

Epoch: 6| Step: 11
Training loss: 1.885703372407685
Validation loss: 2.4448343851599215

Epoch: 6| Step: 12
Training loss: 1.5123605080586604
Validation loss: 2.4479694333713358

Epoch: 6| Step: 13
Training loss: 1.1454700356422778
Validation loss: 2.4736121701778444

Epoch: 94| Step: 0
Training loss: 1.4605308415526825
Validation loss: 2.39131207866952

Epoch: 6| Step: 1
Training loss: 1.213785378974705
Validation loss: 2.457056212184717

Epoch: 6| Step: 2
Training loss: 1.1385018956298862
Validation loss: 2.482656000133195

Epoch: 6| Step: 3
Training loss: 1.1865761827589685
Validation loss: 2.43894377767116

Epoch: 6| Step: 4
Training loss: 1.2914524926262092
Validation loss: 2.4800933794161417

Epoch: 6| Step: 5
Training loss: 1.2935008541645523
Validation loss: 2.448619146532806

Epoch: 6| Step: 6
Training loss: 1.368995560866655
Validation loss: 2.4503001249824923

Epoch: 6| Step: 7
Training loss: 0.944460587425895
Validation loss: 2.462945254327801

Epoch: 6| Step: 8
Training loss: 1.956470157800276
Validation loss: 2.4961112931679255

Epoch: 6| Step: 9
Training loss: 1.2569674858009325
Validation loss: 2.4762671100937443

Epoch: 6| Step: 10
Training loss: 1.4525890387395564
Validation loss: 2.4125521316561804

Epoch: 6| Step: 11
Training loss: 1.3398404580123098
Validation loss: 2.505036351466172

Epoch: 6| Step: 12
Training loss: 1.1469261968759465
Validation loss: 2.4680275000663547

Epoch: 6| Step: 13
Training loss: 0.9447744430323527
Validation loss: 2.437250369078291

Epoch: 95| Step: 0
Training loss: 1.1577273029894208
Validation loss: 2.541844093404366

Epoch: 6| Step: 1
Training loss: 1.347022839285316
Validation loss: 2.4485871932006624

Epoch: 6| Step: 2
Training loss: 0.8608601654821807
Validation loss: 2.443234715685496

Epoch: 6| Step: 3
Training loss: 1.4150026683984405
Validation loss: 2.472214147528369

Epoch: 6| Step: 4
Training loss: 0.7733408549644544
Validation loss: 2.5384115470396376

Epoch: 6| Step: 5
Training loss: 1.049801167326947
Validation loss: 2.4057444582217307

Epoch: 6| Step: 6
Training loss: 1.3527330830915132
Validation loss: 2.453769769185707

Epoch: 6| Step: 7
Training loss: 1.2216559757703378
Validation loss: 2.4821879679131014

Epoch: 6| Step: 8
Training loss: 1.240092303932142
Validation loss: 2.4418252732859025

Epoch: 6| Step: 9
Training loss: 1.2440865353694204
Validation loss: 2.383047123598742

Epoch: 6| Step: 10
Training loss: 1.3048483012808305
Validation loss: 2.4579194469428636

Epoch: 6| Step: 11
Training loss: 1.6525576477845179
Validation loss: 2.4836554614913218

Epoch: 6| Step: 12
Training loss: 1.8837022380684538
Validation loss: 2.4857262749231426

Epoch: 6| Step: 13
Training loss: 1.2913107945771725
Validation loss: 2.4699775283707615

Epoch: 96| Step: 0
Training loss: 1.2295904991348723
Validation loss: 2.4915766111789504

Epoch: 6| Step: 1
Training loss: 0.9208219300221364
Validation loss: 2.49810283519668

Epoch: 6| Step: 2
Training loss: 1.0209807983595462
Validation loss: 2.4792009452779453

Epoch: 6| Step: 3
Training loss: 1.3021107886916619
Validation loss: 2.4370519764287812

Epoch: 6| Step: 4
Training loss: 1.1274931091639355
Validation loss: 2.4546743954722112

Epoch: 6| Step: 5
Training loss: 0.8212982068363551
Validation loss: 2.4945475645375077

Epoch: 6| Step: 6
Training loss: 1.0682697153912408
Validation loss: 2.4483157272259817

Epoch: 6| Step: 7
Training loss: 1.511444303454907
Validation loss: 2.479321632564158

Epoch: 6| Step: 8
Training loss: 1.9745243103238654
Validation loss: 2.481770555803751

Epoch: 6| Step: 9
Training loss: 1.5187430801547925
Validation loss: 2.490198439793824

Epoch: 6| Step: 10
Training loss: 1.1063688138961891
Validation loss: 2.490506584897565

Epoch: 6| Step: 11
Training loss: 1.222161921304455
Validation loss: 2.4323895997637925

Epoch: 6| Step: 12
Training loss: 1.7177429716998818
Validation loss: 2.471804873520276

Epoch: 6| Step: 13
Training loss: 1.3014636841410523
Validation loss: 2.431414482090179

Epoch: 97| Step: 0
Training loss: 1.8062525976881731
Validation loss: 2.524994707259369

Epoch: 6| Step: 1
Training loss: 1.211215473387635
Validation loss: 2.5007839483715095

Epoch: 6| Step: 2
Training loss: 1.3506864674432593
Validation loss: 2.5497404957540026

Epoch: 6| Step: 3
Training loss: 1.3314545129561923
Validation loss: 2.4601089939793104

Epoch: 6| Step: 4
Training loss: 1.2214360104639461
Validation loss: 2.444733182394219

Epoch: 6| Step: 5
Training loss: 0.7235400594760638
Validation loss: 2.453542232465316

Epoch: 6| Step: 6
Training loss: 1.3580116362993142
Validation loss: 2.473382538831263

Epoch: 6| Step: 7
Training loss: 1.456251001971641
Validation loss: 2.503644496112422

Epoch: 6| Step: 8
Training loss: 1.3434518882618085
Validation loss: 2.4448235523651394

Epoch: 6| Step: 9
Training loss: 1.433503940689956
Validation loss: 2.426612338970567

Epoch: 6| Step: 10
Training loss: 1.2863323546385537
Validation loss: 2.4754566888720646

Epoch: 6| Step: 11
Training loss: 1.359107155556332
Validation loss: 2.4415539668853734

Epoch: 6| Step: 12
Training loss: 0.992399057977207
Validation loss: 2.4259138741637405

Epoch: 6| Step: 13
Training loss: 0.8930911670253566
Validation loss: 2.4584350295503157

Epoch: 98| Step: 0
Training loss: 0.823913517700528
Validation loss: 2.484495819800705

Epoch: 6| Step: 1
Training loss: 1.583422616482506
Validation loss: 2.5146135780856453

Epoch: 6| Step: 2
Training loss: 1.883586676895614
Validation loss: 2.428385411212229

Epoch: 6| Step: 3
Training loss: 0.887005226139211
Validation loss: 2.3661078749297646

Epoch: 6| Step: 4
Training loss: 1.6837375517500397
Validation loss: 2.456392448766188

Epoch: 6| Step: 5
Training loss: 1.1285048566484714
Validation loss: 2.43854788728225

Epoch: 6| Step: 6
Training loss: 0.6938496320509782
Validation loss: 2.4255982686769686

Epoch: 6| Step: 7
Training loss: 1.1281083927358702
Validation loss: 2.487640410123404

Epoch: 6| Step: 8
Training loss: 0.9968147211774202
Validation loss: 2.449857329411995

Epoch: 6| Step: 9
Training loss: 1.1915622296396784
Validation loss: 2.4621824637487926

Epoch: 6| Step: 10
Training loss: 1.4883220196443796
Validation loss: 2.483093314978048

Epoch: 6| Step: 11
Training loss: 1.1704072025215648
Validation loss: 2.415861231219652

Epoch: 6| Step: 12
Training loss: 0.9718955562171645
Validation loss: 2.460083893169889

Epoch: 6| Step: 13
Training loss: 1.5109017305765549
Validation loss: 2.442663592245355

Epoch: 99| Step: 0
Training loss: 1.3459922800990511
Validation loss: 2.489706927520924

Epoch: 6| Step: 1
Training loss: 0.8130619599918739
Validation loss: 2.459755305768913

Epoch: 6| Step: 2
Training loss: 1.3430874987834664
Validation loss: 2.514474017072407

Epoch: 6| Step: 3
Training loss: 1.1762347186532003
Validation loss: 2.5021849462080765

Epoch: 6| Step: 4
Training loss: 0.6677693967426394
Validation loss: 2.4222008926821266

Epoch: 6| Step: 5
Training loss: 1.156120550796472
Validation loss: 2.4698138137997816

Epoch: 6| Step: 6
Training loss: 1.3289845994641145
Validation loss: 2.4574614988605124

Epoch: 6| Step: 7
Training loss: 1.3472288919176698
Validation loss: 2.471353791494445

Epoch: 6| Step: 8
Training loss: 1.8268426163133054
Validation loss: 2.4338576008985866

Epoch: 6| Step: 9
Training loss: 1.0878715581952343
Validation loss: 2.449457654805143

Epoch: 6| Step: 10
Training loss: 1.1811839332472216
Validation loss: 2.452329745642066

Epoch: 6| Step: 11
Training loss: 0.9860909658412952
Validation loss: 2.4972720044211347

Epoch: 6| Step: 12
Training loss: 1.1467100892790514
Validation loss: 2.509144176921652

Epoch: 6| Step: 13
Training loss: 1.2090399364220623
Validation loss: 2.4348984063826786

Epoch: 100| Step: 0
Training loss: 1.0069848735775595
Validation loss: 2.435842553703231

Epoch: 6| Step: 1
Training loss: 1.2918920730474004
Validation loss: 2.5013275118714664

Epoch: 6| Step: 2
Training loss: 0.9642158967431654
Validation loss: 2.4873800756789057

Epoch: 6| Step: 3
Training loss: 1.0637259423015486
Validation loss: 2.470449530612975

Epoch: 6| Step: 4
Training loss: 1.3644284992851623
Validation loss: 2.4656703266317592

Epoch: 6| Step: 5
Training loss: 1.3674045063548803
Validation loss: 2.45381050493885

Epoch: 6| Step: 6
Training loss: 1.1547437083768102
Validation loss: 2.4268796505139716

Epoch: 6| Step: 7
Training loss: 1.105100320948443
Validation loss: 2.4184284091700885

Epoch: 6| Step: 8
Training loss: 0.79801231455085
Validation loss: 2.475113068512135

Epoch: 6| Step: 9
Training loss: 0.9730616264802426
Validation loss: 2.4801985866371674

Epoch: 6| Step: 10
Training loss: 0.8585530598572642
Validation loss: 2.4563797823436024

Epoch: 6| Step: 11
Training loss: 2.013371235172823
Validation loss: 2.4652107074431355

Epoch: 6| Step: 12
Training loss: 1.1964862520836463
Validation loss: 2.422388526863382

Epoch: 6| Step: 13
Training loss: 1.019228309260197
Validation loss: 2.428837258418496

Epoch: 101| Step: 0
Training loss: 1.0600054010217648
Validation loss: 2.4139590976795415

Epoch: 6| Step: 1
Training loss: 1.071546636615854
Validation loss: 2.437408885720066

Epoch: 6| Step: 2
Training loss: 1.1134398765656373
Validation loss: 2.5032864426878714

Epoch: 6| Step: 3
Training loss: 1.4405718613627867
Validation loss: 2.4964033321890353

Epoch: 6| Step: 4
Training loss: 0.8824914331533654
Validation loss: 2.454754929776876

Epoch: 6| Step: 5
Training loss: 1.9306772759332234
Validation loss: 2.4485191063831677

Epoch: 6| Step: 6
Training loss: 0.9619845136994011
Validation loss: 2.443896776557425

Epoch: 6| Step: 7
Training loss: 1.4068286129232397
Validation loss: 2.4200642369154415

Epoch: 6| Step: 8
Training loss: 1.1343559536766772
Validation loss: 2.5101803131485667

Epoch: 6| Step: 9
Training loss: 1.1593537300400285
Validation loss: 2.4737187373271032

Epoch: 6| Step: 10
Training loss: 0.6736947190177262
Validation loss: 2.529859451315274

Epoch: 6| Step: 11
Training loss: 1.2437531782713493
Validation loss: 2.445548487967

Epoch: 6| Step: 12
Training loss: 1.172652126765007
Validation loss: 2.4369285027643603

Epoch: 6| Step: 13
Training loss: 0.8441896352878621
Validation loss: 2.445543905893175

Epoch: 102| Step: 0
Training loss: 0.8044868144916093
Validation loss: 2.3975064586039276

Epoch: 6| Step: 1
Training loss: 1.0228771976436617
Validation loss: 2.510973315961717

Epoch: 6| Step: 2
Training loss: 1.1611870190774292
Validation loss: 2.5025497944006614

Epoch: 6| Step: 3
Training loss: 0.9950557910670741
Validation loss: 2.402805902124155

Epoch: 6| Step: 4
Training loss: 1.7165452167301336
Validation loss: 2.4466616044221663

Epoch: 6| Step: 5
Training loss: 1.2568394943222545
Validation loss: 2.4264366914780733

Epoch: 6| Step: 6
Training loss: 1.1121442375976047
Validation loss: 2.406135771050639

Epoch: 6| Step: 7
Training loss: 1.0501325228484872
Validation loss: 2.4660267517493035

Epoch: 6| Step: 8
Training loss: 1.381169264147
Validation loss: 2.4520979268026806

Epoch: 6| Step: 9
Training loss: 1.001903629381768
Validation loss: 2.4418840190069

Epoch: 6| Step: 10
Training loss: 1.3883220162146017
Validation loss: 2.445962066013655

Epoch: 6| Step: 11
Training loss: 0.9014829683181284
Validation loss: 2.464191525793695

Epoch: 6| Step: 12
Training loss: 1.2303668752004977
Validation loss: 2.4064163546835826

Epoch: 6| Step: 13
Training loss: 0.953858202974709
Validation loss: 2.515937122387112

Epoch: 103| Step: 0
Training loss: 0.9324733443451755
Validation loss: 2.457252973570179

Epoch: 6| Step: 1
Training loss: 0.9719161929511235
Validation loss: 2.5472363798727247

Epoch: 6| Step: 2
Training loss: 1.256493344627451
Validation loss: 2.4901386955679548

Epoch: 6| Step: 3
Training loss: 0.9208083366580077
Validation loss: 2.42655027590733

Epoch: 6| Step: 4
Training loss: 1.0714223634449174
Validation loss: 2.5146157113819103

Epoch: 6| Step: 5
Training loss: 1.5254710392386301
Validation loss: 2.510563119333516

Epoch: 6| Step: 6
Training loss: 0.6423646520110359
Validation loss: 2.4765705866636507

Epoch: 6| Step: 7
Training loss: 1.135732950843782
Validation loss: 2.457630159275657

Epoch: 6| Step: 8
Training loss: 0.936357501368445
Validation loss: 2.4354190339097874

Epoch: 6| Step: 9
Training loss: 1.0587092825706312
Validation loss: 2.4629118815348523

Epoch: 6| Step: 10
Training loss: 0.9934445625526918
Validation loss: 2.5032046441509452

Epoch: 6| Step: 11
Training loss: 1.5011094282087343
Validation loss: 2.4776604321575553

Epoch: 6| Step: 12
Training loss: 1.8706359940450192
Validation loss: 2.5065708116793775

Epoch: 6| Step: 13
Training loss: 0.8701743846722249
Validation loss: 2.512500014550255

Epoch: 104| Step: 0
Training loss: 0.8329706038363351
Validation loss: 2.452000759250135

Epoch: 6| Step: 1
Training loss: 1.1113414260792334
Validation loss: 2.461713412242846

Epoch: 6| Step: 2
Training loss: 1.093088058711184
Validation loss: 2.523325489498967

Epoch: 6| Step: 3
Training loss: 1.1993231712382233
Validation loss: 2.5289944618921667

Epoch: 6| Step: 4
Training loss: 1.2239110193509062
Validation loss: 2.502584075582454

Epoch: 6| Step: 5
Training loss: 1.3955477047471274
Validation loss: 2.5340318189538626

Epoch: 6| Step: 6
Training loss: 0.6699375339824427
Validation loss: 2.4768768977413758

Epoch: 6| Step: 7
Training loss: 1.0251577348993424
Validation loss: 2.488505634309403

Epoch: 6| Step: 8
Training loss: 1.1612340371273804
Validation loss: 2.5007186174717737

Epoch: 6| Step: 9
Training loss: 1.106323019947584
Validation loss: 2.4701721988014866

Epoch: 6| Step: 10
Training loss: 0.9517283290442974
Validation loss: 2.4815981719140034

Epoch: 6| Step: 11
Training loss: 1.6898150635152525
Validation loss: 2.4704363330845998

Epoch: 6| Step: 12
Training loss: 1.9450467705680667
Validation loss: 2.4659042213188367

Epoch: 6| Step: 13
Training loss: 1.1688434298293335
Validation loss: 2.51005165854965

Epoch: 105| Step: 0
Training loss: 0.8868593953045474
Validation loss: 2.4583952836673877

Epoch: 6| Step: 1
Training loss: 1.095499546769996
Validation loss: 2.4950438486806177

Epoch: 6| Step: 2
Training loss: 0.942899825035206
Validation loss: 2.510358617172117

Epoch: 6| Step: 3
Training loss: 1.0832393250880321
Validation loss: 2.4758656962550156

Epoch: 6| Step: 4
Training loss: 0.9824720487428505
Validation loss: 2.4568700853788843

Epoch: 6| Step: 5
Training loss: 1.067552669932132
Validation loss: 2.4667308614299035

Epoch: 6| Step: 6
Training loss: 0.8233789441246033
Validation loss: 2.4258079670670005

Epoch: 6| Step: 7
Training loss: 0.9733087273866745
Validation loss: 2.473346760431467

Epoch: 6| Step: 8
Training loss: 0.9939858666495516
Validation loss: 2.4784177616038683

Epoch: 6| Step: 9
Training loss: 0.7552230482750603
Validation loss: 2.4723142334130537

Epoch: 6| Step: 10
Training loss: 1.9653072227665573
Validation loss: 2.422229437374992

Epoch: 6| Step: 11
Training loss: 1.0972644473185318
Validation loss: 2.460993900359199

Epoch: 6| Step: 12
Training loss: 1.3258524132120355
Validation loss: 2.4438156242697624

Epoch: 6| Step: 13
Training loss: 0.6780547118786187
Validation loss: 2.53543865118053

Epoch: 106| Step: 0
Training loss: 0.7725291457125367
Validation loss: 2.441639214145451

Epoch: 6| Step: 1
Training loss: 1.3230151442672338
Validation loss: 2.385971310252532

Epoch: 6| Step: 2
Training loss: 0.7893611984677378
Validation loss: 2.469074034852813

Epoch: 6| Step: 3
Training loss: 1.032401626740526
Validation loss: 2.4134123748758345

Epoch: 6| Step: 4
Training loss: 1.0682914196209374
Validation loss: 2.4697936383168044

Epoch: 6| Step: 5
Training loss: 1.7722097171526947
Validation loss: 2.4955934312649917

Epoch: 6| Step: 6
Training loss: 1.1045280740778327
Validation loss: 2.485757279272188

Epoch: 6| Step: 7
Training loss: 1.086994342975232
Validation loss: 2.4515813194251157

Epoch: 6| Step: 8
Training loss: 1.3044857394519855
Validation loss: 2.458868798167475

Epoch: 6| Step: 9
Training loss: 1.0020844074225006
Validation loss: 2.4635142727404795

Epoch: 6| Step: 10
Training loss: 0.6760878997260454
Validation loss: 2.465679254809238

Epoch: 6| Step: 11
Training loss: 1.0207846234176952
Validation loss: 2.425181947023946

Epoch: 6| Step: 12
Training loss: 1.1437464813011533
Validation loss: 2.4016083209353845

Epoch: 6| Step: 13
Training loss: 0.8867977964147601
Validation loss: 2.4744502384970803

Epoch: 107| Step: 0
Training loss: 0.5066423579342983
Validation loss: 2.393779227905851

Epoch: 6| Step: 1
Training loss: 0.9689870052214293
Validation loss: 2.520221530875231

Epoch: 6| Step: 2
Training loss: 0.9426562293109737
Validation loss: 2.4952863602293243

Epoch: 6| Step: 3
Training loss: 0.8151382382292917
Validation loss: 2.468907958824124

Epoch: 6| Step: 4
Training loss: 0.9938136614195414
Validation loss: 2.472257689484725

Epoch: 6| Step: 5
Training loss: 1.074550785421296
Validation loss: 2.542006178104307

Epoch: 6| Step: 6
Training loss: 1.9057679739440645
Validation loss: 2.4268281554191384

Epoch: 6| Step: 7
Training loss: 1.206457896921172
Validation loss: 2.5004289576957226

Epoch: 6| Step: 8
Training loss: 1.1324530195550404
Validation loss: 2.481254056835942

Epoch: 6| Step: 9
Training loss: 1.025533786044153
Validation loss: 2.471901977944839

Epoch: 6| Step: 10
Training loss: 1.0670067071319538
Validation loss: 2.427530261190615

Epoch: 6| Step: 11
Training loss: 0.9127314404701078
Validation loss: 2.4861002116139015

Epoch: 6| Step: 12
Training loss: 1.0366754288522864
Validation loss: 2.393143800050752

Epoch: 6| Step: 13
Training loss: 0.653475185677645
Validation loss: 2.416475343256001

Epoch: 108| Step: 0
Training loss: 0.9037162943842643
Validation loss: 2.4250239829879856

Epoch: 6| Step: 1
Training loss: 1.4136422307283827
Validation loss: 2.4962139150462472

Epoch: 6| Step: 2
Training loss: 0.7316955219942467
Validation loss: 2.4078064050582855

Epoch: 6| Step: 3
Training loss: 2.0500429986305484
Validation loss: 2.446654628867836

Epoch: 6| Step: 4
Training loss: 0.6629395358418597
Validation loss: 2.4590173405504747

Epoch: 6| Step: 5
Training loss: 0.9900377669018328
Validation loss: 2.4142428004679664

Epoch: 6| Step: 6
Training loss: 0.7883823598358178
Validation loss: 2.5457564473963816

Epoch: 6| Step: 7
Training loss: 1.090775942262884
Validation loss: 2.4474156834252723

Epoch: 6| Step: 8
Training loss: 1.3525646221073204
Validation loss: 2.481738476910903

Epoch: 6| Step: 9
Training loss: 0.9430416986018268
Validation loss: 2.509938211605066

Epoch: 6| Step: 10
Training loss: 0.8950747708569671
Validation loss: 2.4465861228328323

Epoch: 6| Step: 11
Training loss: 0.9973609493254126
Validation loss: 2.4971690043416586

Epoch: 6| Step: 12
Training loss: 1.0179181546733742
Validation loss: 2.5165009168227437

Epoch: 6| Step: 13
Training loss: 1.037584558740865
Validation loss: 2.4712894110977226

Epoch: 109| Step: 0
Training loss: 0.9595164514694701
Validation loss: 2.4357462793464255

Epoch: 6| Step: 1
Training loss: 0.9456227951881336
Validation loss: 2.4540467524957332

Epoch: 6| Step: 2
Training loss: 0.9570276999894298
Validation loss: 2.5407553717151585

Epoch: 6| Step: 3
Training loss: 1.154290213783524
Validation loss: 2.4934150279612917

Epoch: 6| Step: 4
Training loss: 1.2123535736390019
Validation loss: 2.3748492142846414

Epoch: 6| Step: 5
Training loss: 0.9009945844282172
Validation loss: 2.534044097232676

Epoch: 6| Step: 6
Training loss: 1.1102962161372363
Validation loss: 2.554241487569826

Epoch: 6| Step: 7
Training loss: 0.8593443431587937
Validation loss: 2.5300228927792854

Epoch: 6| Step: 8
Training loss: 0.7413619017124905
Validation loss: 2.469198210385266

Epoch: 6| Step: 9
Training loss: 1.8954537259639201
Validation loss: 2.4698277466926157

Epoch: 6| Step: 10
Training loss: 0.9546753203618727
Validation loss: 2.4662897268744386

Epoch: 6| Step: 11
Training loss: 0.7616223005218473
Validation loss: 2.5076448378563816

Epoch: 6| Step: 12
Training loss: 1.1559720091813392
Validation loss: 2.447042533689845

Epoch: 6| Step: 13
Training loss: 0.5704674183755011
Validation loss: 2.417793707194204

Epoch: 110| Step: 0
Training loss: 0.9255955827817799
Validation loss: 2.477979413149963

Epoch: 6| Step: 1
Training loss: 1.3007890397488695
Validation loss: 2.4645719302750146

Epoch: 6| Step: 2
Training loss: 0.9390323196105949
Validation loss: 2.431789033132231

Epoch: 6| Step: 3
Training loss: 0.7506903411732704
Validation loss: 2.390179046058645

Epoch: 6| Step: 4
Training loss: 0.9014072264667524
Validation loss: 2.501666491108413

Epoch: 6| Step: 5
Training loss: 1.0566120249602444
Validation loss: 2.50634813187946

Epoch: 6| Step: 6
Training loss: 0.859366607625037
Validation loss: 2.5394824810411456

Epoch: 6| Step: 7
Training loss: 1.0184693634489246
Validation loss: 2.487185649721758

Epoch: 6| Step: 8
Training loss: 0.8620517312168722
Validation loss: 2.438359541014472

Epoch: 6| Step: 9
Training loss: 0.9969594447325205
Validation loss: 2.430919616923748

Epoch: 6| Step: 10
Training loss: 1.8836494579961345
Validation loss: 2.474074051141686

Epoch: 6| Step: 11
Training loss: 0.9722035898209438
Validation loss: 2.4488225897375893

Epoch: 6| Step: 12
Training loss: 0.6479751363255123
Validation loss: 2.4791466581247774

Epoch: 6| Step: 13
Training loss: 0.5637816292544907
Validation loss: 2.479768188548308

Epoch: 111| Step: 0
Training loss: 0.7717938538805073
Validation loss: 2.4125610505254182

Epoch: 6| Step: 1
Training loss: 0.7383261369249722
Validation loss: 2.4274257996779216

Epoch: 6| Step: 2
Training loss: 0.9430302584861263
Validation loss: 2.523794583938744

Epoch: 6| Step: 3
Training loss: 0.8379163760338546
Validation loss: 2.5252030753630725

Epoch: 6| Step: 4
Training loss: 1.1810074552160192
Validation loss: 2.4935907700262256

Epoch: 6| Step: 5
Training loss: 0.6427943552856569
Validation loss: 2.4917079659508468

Epoch: 6| Step: 6
Training loss: 1.0370020694141837
Validation loss: 2.499666763984599

Epoch: 6| Step: 7
Training loss: 1.0245546838995945
Validation loss: 2.519076962385522

Epoch: 6| Step: 8
Training loss: 1.1112452578362977
Validation loss: 2.5251494782018313

Epoch: 6| Step: 9
Training loss: 1.158306972743443
Validation loss: 2.381366979173706

Epoch: 6| Step: 10
Training loss: 0.9345007285558679
Validation loss: 2.4617861298758807

Epoch: 6| Step: 11
Training loss: 1.5966318292473984
Validation loss: 2.521209331456166

Epoch: 6| Step: 12
Training loss: 0.9218224979256499
Validation loss: 2.485482806604478

Epoch: 6| Step: 13
Training loss: 1.040827807576457
Validation loss: 2.4950338390784736

Epoch: 112| Step: 0
Training loss: 0.9774929039543914
Validation loss: 2.475993037812834

Epoch: 6| Step: 1
Training loss: 0.878719360826712
Validation loss: 2.4894610791269085

Epoch: 6| Step: 2
Training loss: 1.7147496225857461
Validation loss: 2.501651409220396

Epoch: 6| Step: 3
Training loss: 0.9685330301776207
Validation loss: 2.5089641236251063

Epoch: 6| Step: 4
Training loss: 1.3361995060857423
Validation loss: 2.5194126308226594

Epoch: 6| Step: 5
Training loss: 0.8916326143470963
Validation loss: 2.554823612238522

Epoch: 6| Step: 6
Training loss: 1.000689268984895
Validation loss: 2.49696607873191

Epoch: 6| Step: 7
Training loss: 0.7199925587190108
Validation loss: 2.4900103140365877

Epoch: 6| Step: 8
Training loss: 0.7801593415412792
Validation loss: 2.5498272531875212

Epoch: 6| Step: 9
Training loss: 0.6377884707674107
Validation loss: 2.467053937366941

Epoch: 6| Step: 10
Training loss: 0.7415798309654414
Validation loss: 2.431922252845952

Epoch: 6| Step: 11
Training loss: 1.1757885498631366
Validation loss: 2.4835177848040364

Epoch: 6| Step: 12
Training loss: 1.2497324657244127
Validation loss: 2.581409835485062

Epoch: 6| Step: 13
Training loss: 1.2839783253192112
Validation loss: 2.421180773263845

Epoch: 113| Step: 0
Training loss: 0.9665529502103352
Validation loss: 2.4990996169911157

Epoch: 6| Step: 1
Training loss: 0.9203611325430684
Validation loss: 2.525241305526219

Epoch: 6| Step: 2
Training loss: 0.7700640387967493
Validation loss: 2.5027948175241397

Epoch: 6| Step: 3
Training loss: 0.6523845225858171
Validation loss: 2.5466941816115125

Epoch: 6| Step: 4
Training loss: 0.784881771563295
Validation loss: 2.536881465723495

Epoch: 6| Step: 5
Training loss: 0.9424148158830711
Validation loss: 2.548966794973613

Epoch: 6| Step: 6
Training loss: 0.9337493894439703
Validation loss: 2.541768702559058

Epoch: 6| Step: 7
Training loss: 1.2022006955474938
Validation loss: 2.5024296001372925

Epoch: 6| Step: 8
Training loss: 1.693827457697925
Validation loss: 2.459340565370512

Epoch: 6| Step: 9
Training loss: 1.0620197444919444
Validation loss: 2.4434853289305365

Epoch: 6| Step: 10
Training loss: 0.918659940185153
Validation loss: 2.4673116976832037

Epoch: 6| Step: 11
Training loss: 1.2641848152499142
Validation loss: 2.518650896695824

Epoch: 6| Step: 12
Training loss: 1.1337933733297139
Validation loss: 2.4680874414291822

Epoch: 6| Step: 13
Training loss: 1.0060888528623209
Validation loss: 2.4133711136535565

Epoch: 114| Step: 0
Training loss: 0.5567639665980129
Validation loss: 2.4378142032096557

Epoch: 6| Step: 1
Training loss: 0.6941111612587424
Validation loss: 2.4453795792516737

Epoch: 6| Step: 2
Training loss: 0.6139111533761661
Validation loss: 2.3603104006579776

Epoch: 6| Step: 3
Training loss: 1.3108022699638504
Validation loss: 2.4607274041487583

Epoch: 6| Step: 4
Training loss: 0.943311038467103
Validation loss: 2.479722078335064

Epoch: 6| Step: 5
Training loss: 0.7813103461800789
Validation loss: 2.4731404501858396

Epoch: 6| Step: 6
Training loss: 1.0149681901880008
Validation loss: 2.4499911236764396

Epoch: 6| Step: 7
Training loss: 1.2112876139844386
Validation loss: 2.446294260431936

Epoch: 6| Step: 8
Training loss: 0.811410136295255
Validation loss: 2.4340493646723487

Epoch: 6| Step: 9
Training loss: 1.2039003722327721
Validation loss: 2.4763743492560653

Epoch: 6| Step: 10
Training loss: 1.043502499594297
Validation loss: 2.593334241276887

Epoch: 6| Step: 11
Training loss: 0.9748145672941999
Validation loss: 2.614599924427499

Epoch: 6| Step: 12
Training loss: 1.0384017449605296
Validation loss: 2.4488070931431287

Epoch: 6| Step: 13
Training loss: 1.5874962874241467
Validation loss: 2.4927161920542895

Epoch: 115| Step: 0
Training loss: 0.9674489298113947
Validation loss: 2.452336923800995

Epoch: 6| Step: 1
Training loss: 0.8359527586498019
Validation loss: 2.5144573131631294

Epoch: 6| Step: 2
Training loss: 1.136928054049793
Validation loss: 2.512647505521735

Epoch: 6| Step: 3
Training loss: 0.6146357939577062
Validation loss: 2.44399429882319

Epoch: 6| Step: 4
Training loss: 1.0610261680619069
Validation loss: 2.5168216536547114

Epoch: 6| Step: 5
Training loss: 0.6671218410943935
Validation loss: 2.4628702959980795

Epoch: 6| Step: 6
Training loss: 1.6315279201371369
Validation loss: 2.4983378288868194

Epoch: 6| Step: 7
Training loss: 0.9127206000088814
Validation loss: 2.488638021382262

Epoch: 6| Step: 8
Training loss: 1.0158386592605415
Validation loss: 2.421138610457059

Epoch: 6| Step: 9
Training loss: 1.2356894532345921
Validation loss: 2.447855722737387

Epoch: 6| Step: 10
Training loss: 0.8904790256735359
Validation loss: 2.4828867743337346

Epoch: 6| Step: 11
Training loss: 0.8031295583276488
Validation loss: 2.489878718092007

Epoch: 6| Step: 12
Training loss: 0.7463021511596362
Validation loss: 2.5597021444214803

Epoch: 6| Step: 13
Training loss: 0.6055000050999132
Validation loss: 2.4698472944409455

Epoch: 116| Step: 0
Training loss: 0.8252242766042953
Validation loss: 2.4659958699494218

Epoch: 6| Step: 1
Training loss: 1.09920015732821
Validation loss: 2.418944080461813

Epoch: 6| Step: 2
Training loss: 0.8056819659469083
Validation loss: 2.526205695945228

Epoch: 6| Step: 3
Training loss: 0.9186480342309323
Validation loss: 2.475590608430628

Epoch: 6| Step: 4
Training loss: 1.0895812562785339
Validation loss: 2.4408512308574406

Epoch: 6| Step: 5
Training loss: 0.8246367782022247
Validation loss: 2.443332931168104

Epoch: 6| Step: 6
Training loss: 0.8050768752738511
Validation loss: 2.4523268776133236

Epoch: 6| Step: 7
Training loss: 0.9128826384221538
Validation loss: 2.37579387647641

Epoch: 6| Step: 8
Training loss: 1.6505517643920975
Validation loss: 2.4448883127473895

Epoch: 6| Step: 9
Training loss: 0.6401657225951041
Validation loss: 2.387745305053496

Epoch: 6| Step: 10
Training loss: 0.8557698664831835
Validation loss: 2.382035183885061

Epoch: 6| Step: 11
Training loss: 1.3419434579799863
Validation loss: 2.447372681797171

Epoch: 6| Step: 12
Training loss: 0.6613933326041957
Validation loss: 2.4229082098102883

Epoch: 6| Step: 13
Training loss: 0.9697137161433524
Validation loss: 2.4714944288502387

Epoch: 117| Step: 0
Training loss: 0.8517176285580447
Validation loss: 2.435010176369084

Epoch: 6| Step: 1
Training loss: 0.682927968193726
Validation loss: 2.4641405362947713

Epoch: 6| Step: 2
Training loss: 0.7475845860622536
Validation loss: 2.456098952757169

Epoch: 6| Step: 3
Training loss: 0.6879753723449598
Validation loss: 2.4555160791389397

Epoch: 6| Step: 4
Training loss: 0.9883507564664327
Validation loss: 2.4813455628922685

Epoch: 6| Step: 5
Training loss: 1.0300813468735166
Validation loss: 2.485490032902779

Epoch: 6| Step: 6
Training loss: 0.7881107444593218
Validation loss: 2.4238843888262305

Epoch: 6| Step: 7
Training loss: 0.9410794905877933
Validation loss: 2.4007328411319198

Epoch: 6| Step: 8
Training loss: 0.603612305634677
Validation loss: 2.374629259452434

Epoch: 6| Step: 9
Training loss: 0.5776002925631661
Validation loss: 2.470475040809227

Epoch: 6| Step: 10
Training loss: 0.7757255157703066
Validation loss: 2.499036428406095

Epoch: 6| Step: 11
Training loss: 1.0393530647316696
Validation loss: 2.4754902376616674

Epoch: 6| Step: 12
Training loss: 1.7325403631003027
Validation loss: 2.4952875227246394

Epoch: 6| Step: 13
Training loss: 1.2063565142947166
Validation loss: 2.5631355955036215

Epoch: 118| Step: 0
Training loss: 0.8516553775638852
Validation loss: 2.43527735748709

Epoch: 6| Step: 1
Training loss: 1.1620231019381095
Validation loss: 2.4835376407972634

Epoch: 6| Step: 2
Training loss: 1.133162976999883
Validation loss: 2.436004342823302

Epoch: 6| Step: 3
Training loss: 0.806808121773574
Validation loss: 2.439375823979683

Epoch: 6| Step: 4
Training loss: 1.1097497978545416
Validation loss: 2.4636213412045986

Epoch: 6| Step: 5
Training loss: 0.787453323070847
Validation loss: 2.5101223426172705

Epoch: 6| Step: 6
Training loss: 0.8139999922112692
Validation loss: 2.4345692026212538

Epoch: 6| Step: 7
Training loss: 0.8102042703550372
Validation loss: 2.452641222766951

Epoch: 6| Step: 8
Training loss: 1.668955026668628
Validation loss: 2.4565246577304864

Epoch: 6| Step: 9
Training loss: 0.6580439072195223
Validation loss: 2.4826194350422237

Epoch: 6| Step: 10
Training loss: 1.0578753859789591
Validation loss: 2.4772245162072455

Epoch: 6| Step: 11
Training loss: 0.8986059279753386
Validation loss: 2.5008929485785956

Epoch: 6| Step: 12
Training loss: 0.7077547028714437
Validation loss: 2.4397261145876286

Epoch: 6| Step: 13
Training loss: 0.973317607029716
Validation loss: 2.455943179522211

Epoch: 119| Step: 0
Training loss: 1.0832614997131875
Validation loss: 2.406636855168861

Epoch: 6| Step: 1
Training loss: 0.8605351679728992
Validation loss: 2.4760936048487627

Epoch: 6| Step: 2
Training loss: 1.0156540499714102
Validation loss: 2.498482513817458

Epoch: 6| Step: 3
Training loss: 0.719033558514666
Validation loss: 2.393331271633794

Epoch: 6| Step: 4
Training loss: 0.5391045153180218
Validation loss: 2.4041643723378288

Epoch: 6| Step: 5
Training loss: 0.818615238368568
Validation loss: 2.4004816379990337

Epoch: 6| Step: 6
Training loss: 0.7477624018618575
Validation loss: 2.417967484596591

Epoch: 6| Step: 7
Training loss: 1.7078901351775149
Validation loss: 2.4868422438925033

Epoch: 6| Step: 8
Training loss: 1.205284657392883
Validation loss: 2.4149630943779745

Epoch: 6| Step: 9
Training loss: 0.7239716800767566
Validation loss: 2.401093709275473

Epoch: 6| Step: 10
Training loss: 0.6808736251416585
Validation loss: 2.376220289242265

Epoch: 6| Step: 11
Training loss: 0.6916135918886187
Validation loss: 2.4434741079916478

Epoch: 6| Step: 12
Training loss: 1.126848186188715
Validation loss: 2.5125073687443766

Epoch: 6| Step: 13
Training loss: 0.8988201487492747
Validation loss: 2.4166420875044783

Epoch: 120| Step: 0
Training loss: 0.978622247974416
Validation loss: 2.4742046407593

Epoch: 6| Step: 1
Training loss: 0.4802270917338612
Validation loss: 2.428481903750168

Epoch: 6| Step: 2
Training loss: 0.8207551760828392
Validation loss: 2.410808209199222

Epoch: 6| Step: 3
Training loss: 0.6775927216963145
Validation loss: 2.4251716081127923

Epoch: 6| Step: 4
Training loss: 0.7417088621616345
Validation loss: 2.4704779681919486

Epoch: 6| Step: 5
Training loss: 0.678422518037166
Validation loss: 2.3924847850628015

Epoch: 6| Step: 6
Training loss: 0.876240157971364
Validation loss: 2.462730150392103

Epoch: 6| Step: 7
Training loss: 1.0819302177772494
Validation loss: 2.4412733850565216

Epoch: 6| Step: 8
Training loss: 0.881582162361246
Validation loss: 2.426866076873243

Epoch: 6| Step: 9
Training loss: 1.0036467576760888
Validation loss: 2.484635401420139

Epoch: 6| Step: 10
Training loss: 1.5873613402117377
Validation loss: 2.4711749886509655

Epoch: 6| Step: 11
Training loss: 0.7647252147807073
Validation loss: 2.36903784922858

Epoch: 6| Step: 12
Training loss: 0.9898085421568396
Validation loss: 2.4554835520650253

Epoch: 6| Step: 13
Training loss: 0.71883304779586
Validation loss: 2.4742992982640426

Epoch: 121| Step: 0
Training loss: 1.0168433291257553
Validation loss: 2.443854241452791

Epoch: 6| Step: 1
Training loss: 0.9140262759603274
Validation loss: 2.462596693254445

Epoch: 6| Step: 2
Training loss: 0.5334372652630996
Validation loss: 2.374393712005425

Epoch: 6| Step: 3
Training loss: 0.8344528347672385
Validation loss: 2.4245729902874706

Epoch: 6| Step: 4
Training loss: 1.6531572075574572
Validation loss: 2.4388452713796993

Epoch: 6| Step: 5
Training loss: 0.6592346394557268
Validation loss: 2.4489827262889174

Epoch: 6| Step: 6
Training loss: 1.1346445462210737
Validation loss: 2.4081104402013684

Epoch: 6| Step: 7
Training loss: 0.8662809496328236
Validation loss: 2.440156890614369

Epoch: 6| Step: 8
Training loss: 0.6770279030240628
Validation loss: 2.4090830733677286

Epoch: 6| Step: 9
Training loss: 0.6758049315784895
Validation loss: 2.469735379477968

Epoch: 6| Step: 10
Training loss: 1.0451438026411284
Validation loss: 2.40657596114282

Epoch: 6| Step: 11
Training loss: 0.7516392040169867
Validation loss: 2.3893496866138433

Epoch: 6| Step: 12
Training loss: 0.7086803951093995
Validation loss: 2.4150714103402926

Epoch: 6| Step: 13
Training loss: 0.6299145594440205
Validation loss: 2.3966988257990423

Epoch: 122| Step: 0
Training loss: 0.8415998330035425
Validation loss: 2.3989186917363354

Epoch: 6| Step: 1
Training loss: 0.5837419702112417
Validation loss: 2.5072725057299006

Epoch: 6| Step: 2
Training loss: 0.6202906088245288
Validation loss: 2.526055598794067

Epoch: 6| Step: 3
Training loss: 1.0027378273916756
Validation loss: 2.440180014317296

Epoch: 6| Step: 4
Training loss: 1.004969645938529
Validation loss: 2.5160169276389235

Epoch: 6| Step: 5
Training loss: 1.8861468536306216
Validation loss: 2.367025120099989

Epoch: 6| Step: 6
Training loss: 0.7294509242795653
Validation loss: 2.3841726454715726

Epoch: 6| Step: 7
Training loss: 0.7470608180820295
Validation loss: 2.51281117304227

Epoch: 6| Step: 8
Training loss: 1.0854706343830358
Validation loss: 2.4534884060132973

Epoch: 6| Step: 9
Training loss: 0.6607499923042126
Validation loss: 2.4209482039896173

Epoch: 6| Step: 10
Training loss: 1.0469194089665401
Validation loss: 2.4991974178133987

Epoch: 6| Step: 11
Training loss: 0.8218183229579406
Validation loss: 2.4158316079333453

Epoch: 6| Step: 12
Training loss: 0.7840696948904591
Validation loss: 2.437915016773139

Epoch: 6| Step: 13
Training loss: 0.6607015039614209
Validation loss: 2.448226817077341

Epoch: 123| Step: 0
Training loss: 0.48909746233980433
Validation loss: 2.383327340961028

Epoch: 6| Step: 1
Training loss: 0.7417674833705193
Validation loss: 2.408573407831614

Epoch: 6| Step: 2
Training loss: 1.496681277296518
Validation loss: 2.358877041038223

Epoch: 6| Step: 3
Training loss: 0.6888396908469536
Validation loss: 2.435196627772783

Epoch: 6| Step: 4
Training loss: 1.133531434379228
Validation loss: 2.5484228754705684

Epoch: 6| Step: 5
Training loss: 1.0186858783037074
Validation loss: 2.4944557064607396

Epoch: 6| Step: 6
Training loss: 0.5582353202232468
Validation loss: 2.405826547857779

Epoch: 6| Step: 7
Training loss: 0.901436551980448
Validation loss: 2.4112603344521975

Epoch: 6| Step: 8
Training loss: 0.588662056439183
Validation loss: 2.4635413709536826

Epoch: 6| Step: 9
Training loss: 0.6378559652093962
Validation loss: 2.415357372070954

Epoch: 6| Step: 10
Training loss: 1.0055309166767077
Validation loss: 2.4366908075186564

Epoch: 6| Step: 11
Training loss: 1.0382727009096226
Validation loss: 2.5075743216507247

Epoch: 6| Step: 12
Training loss: 1.0107036196219537
Validation loss: 2.4857108405438555

Epoch: 6| Step: 13
Training loss: 0.563556764603725
Validation loss: 2.4823791676310925

Epoch: 124| Step: 0
Training loss: 0.7147552352051745
Validation loss: 2.3568654977463095

Epoch: 6| Step: 1
Training loss: 0.7746182301256098
Validation loss: 2.437491702204217

Epoch: 6| Step: 2
Training loss: 0.6087160215353378
Validation loss: 2.416727251630771

Epoch: 6| Step: 3
Training loss: 0.7243768776580463
Validation loss: 2.393878692275124

Epoch: 6| Step: 4
Training loss: 0.8075915774213697
Validation loss: 2.414825845497948

Epoch: 6| Step: 5
Training loss: 0.720520658060556
Validation loss: 2.441655195641072

Epoch: 6| Step: 6
Training loss: 0.6675973941885831
Validation loss: 2.3973042133224314

Epoch: 6| Step: 7
Training loss: 0.6788973545417931
Validation loss: 2.3873276253832376

Epoch: 6| Step: 8
Training loss: 0.682551565003929
Validation loss: 2.4578670501313984

Epoch: 6| Step: 9
Training loss: 0.6710320441017894
Validation loss: 2.4211632780037924

Epoch: 6| Step: 10
Training loss: 1.1520862356267776
Validation loss: 2.415156588720019

Epoch: 6| Step: 11
Training loss: 1.0956370831882476
Validation loss: 2.3950813661370827

Epoch: 6| Step: 12
Training loss: 1.6270938734558986
Validation loss: 2.416919947100133

Epoch: 6| Step: 13
Training loss: 0.8197244261940346
Validation loss: 2.4734373541273857

Epoch: 125| Step: 0
Training loss: 0.7864985213632623
Validation loss: 2.423389019000564

Epoch: 6| Step: 1
Training loss: 0.567803546958801
Validation loss: 2.4136507903350766

Epoch: 6| Step: 2
Training loss: 0.9317828375759354
Validation loss: 2.5054538841746234

Epoch: 6| Step: 3
Training loss: 1.1136365892272042
Validation loss: 2.3851149144668904

Epoch: 6| Step: 4
Training loss: 0.6563086256452867
Validation loss: 2.52972337816324

Epoch: 6| Step: 5
Training loss: 0.533521284821062
Validation loss: 2.481266211929976

Epoch: 6| Step: 6
Training loss: 0.783655773077662
Validation loss: 2.5051036873663293

Epoch: 6| Step: 7
Training loss: 0.8237674435749783
Validation loss: 2.4784815239570697

Epoch: 6| Step: 8
Training loss: 0.7071970118322504
Validation loss: 2.4784911595132306

Epoch: 6| Step: 9
Training loss: 0.41238849462172
Validation loss: 2.4124684425622323

Epoch: 6| Step: 10
Training loss: 1.6888756972489292
Validation loss: 2.4455148858929117

Epoch: 6| Step: 11
Training loss: 0.8077749630970681
Validation loss: 2.5214027570835946

Epoch: 6| Step: 12
Training loss: 0.44867507542859125
Validation loss: 2.477212990933264

Epoch: 6| Step: 13
Training loss: 0.9587651952064096
Validation loss: 2.459613019774962

Epoch: 126| Step: 0
Training loss: 0.7340039472421849
Validation loss: 2.448312107909115

Epoch: 6| Step: 1
Training loss: 0.5641252826188722
Validation loss: 2.434460774821582

Epoch: 6| Step: 2
Training loss: 0.5545125604845969
Validation loss: 2.472217410388888

Epoch: 6| Step: 3
Training loss: 0.6041198964486485
Validation loss: 2.4155930951681728

Epoch: 6| Step: 4
Training loss: 0.5489655455007556
Validation loss: 2.4001736233745543

Epoch: 6| Step: 5
Training loss: 0.9144383171411101
Validation loss: 2.395399374982108

Epoch: 6| Step: 6
Training loss: 0.9169792523756547
Validation loss: 2.4007943633532727

Epoch: 6| Step: 7
Training loss: 1.6715126001337848
Validation loss: 2.4040834986572395

Epoch: 6| Step: 8
Training loss: 0.5369890667816409
Validation loss: 2.3641217211096155

Epoch: 6| Step: 9
Training loss: 0.8454326875602836
Validation loss: 2.419649065150835

Epoch: 6| Step: 10
Training loss: 0.6417021186332332
Validation loss: 2.438609807951159

Epoch: 6| Step: 11
Training loss: 0.962832033181453
Validation loss: 2.4047880975024314

Epoch: 6| Step: 12
Training loss: 0.6537982464086215
Validation loss: 2.3930472940292624

Epoch: 6| Step: 13
Training loss: 0.8576460351959407
Validation loss: 2.3892646692367263

Epoch: 127| Step: 0
Training loss: 0.524762370054172
Validation loss: 2.3895365911389272

Epoch: 6| Step: 1
Training loss: 1.0515620510786212
Validation loss: 2.394517725314621

Epoch: 6| Step: 2
Training loss: 0.897588710385483
Validation loss: 2.4319003904767666

Epoch: 6| Step: 3
Training loss: 0.8832853958029889
Validation loss: 2.46885743692067

Epoch: 6| Step: 4
Training loss: 0.8432905571031498
Validation loss: 2.46538779113254

Epoch: 6| Step: 5
Training loss: 0.7441269280081708
Validation loss: 2.4502151141805215

Epoch: 6| Step: 6
Training loss: 1.0160625395600313
Validation loss: 2.4429009096627623

Epoch: 6| Step: 7
Training loss: 1.4365090810964725
Validation loss: 2.472678684094681

Epoch: 6| Step: 8
Training loss: 0.6331055515988878
Validation loss: 2.444407830963571

Epoch: 6| Step: 9
Training loss: 0.5612359148394843
Validation loss: 2.4631509827297915

Epoch: 6| Step: 10
Training loss: 0.5831008402407994
Validation loss: 2.4656499722001426

Epoch: 6| Step: 11
Training loss: 0.7260503296811892
Validation loss: 2.454415745122947

Epoch: 6| Step: 12
Training loss: 0.7413373394567434
Validation loss: 2.4510441841818325

Epoch: 6| Step: 13
Training loss: 0.7724453506151031
Validation loss: 2.444005240975321

Epoch: 128| Step: 0
Training loss: 0.504842110917203
Validation loss: 2.370390501270752

Epoch: 6| Step: 1
Training loss: 0.5803828354273114
Validation loss: 2.460666120794555

Epoch: 6| Step: 2
Training loss: 0.6160587660947334
Validation loss: 2.4456095002239944

Epoch: 6| Step: 3
Training loss: 0.6922004577939411
Validation loss: 2.4525142160380176

Epoch: 6| Step: 4
Training loss: 0.8611575625992712
Validation loss: 2.467983698319129

Epoch: 6| Step: 5
Training loss: 1.7770404263407642
Validation loss: 2.467875072105757

Epoch: 6| Step: 6
Training loss: 0.4625605440463083
Validation loss: 2.3930293440113597

Epoch: 6| Step: 7
Training loss: 0.6834197994708165
Validation loss: 2.364531333004262

Epoch: 6| Step: 8
Training loss: 0.7856508661350217
Validation loss: 2.3986653438205403

Epoch: 6| Step: 9
Training loss: 0.48835448669515974
Validation loss: 2.4409647387237174

Epoch: 6| Step: 10
Training loss: 0.8080555327046721
Validation loss: 2.3896883956131294

Epoch: 6| Step: 11
Training loss: 0.7821608383627557
Validation loss: 2.468300951587102

Epoch: 6| Step: 12
Training loss: 0.5288682729590325
Validation loss: 2.4457128926201785

Epoch: 6| Step: 13
Training loss: 1.018994361730818
Validation loss: 2.351036553693515

Epoch: 129| Step: 0
Training loss: 0.47164322927405866
Validation loss: 2.4549377126101617

Epoch: 6| Step: 1
Training loss: 0.6036488654450259
Validation loss: 2.421759703157992

Epoch: 6| Step: 2
Training loss: 0.8689144568903759
Validation loss: 2.4242924264244965

Epoch: 6| Step: 3
Training loss: 0.8818111986511219
Validation loss: 2.444695993205775

Epoch: 6| Step: 4
Training loss: 0.46460737100633737
Validation loss: 2.371242160331705

Epoch: 6| Step: 5
Training loss: 0.9064206587486763
Validation loss: 2.4199721049180174

Epoch: 6| Step: 6
Training loss: 0.7869170831966487
Validation loss: 2.444379569647366

Epoch: 6| Step: 7
Training loss: 0.6570361061234247
Validation loss: 2.4135132774908223

Epoch: 6| Step: 8
Training loss: 0.7806473887449774
Validation loss: 2.415904727940986

Epoch: 6| Step: 9
Training loss: 0.698348457412398
Validation loss: 2.3595706866966903

Epoch: 6| Step: 10
Training loss: 0.7203064527278439
Validation loss: 2.455900707436063

Epoch: 6| Step: 11
Training loss: 0.7197349268350891
Validation loss: 2.4104392340506786

Epoch: 6| Step: 12
Training loss: 0.8472610466474171
Validation loss: 2.3860967796535766

Epoch: 6| Step: 13
Training loss: 1.4488710875838056
Validation loss: 2.434575861886141

Epoch: 130| Step: 0
Training loss: 0.6737523133020551
Validation loss: 2.4405184746555997

Epoch: 6| Step: 1
Training loss: 1.1265481257480592
Validation loss: 2.4495925820825946

Epoch: 6| Step: 2
Training loss: 1.5788857920669466
Validation loss: 2.5244601591661904

Epoch: 6| Step: 3
Training loss: 0.7417996648060032
Validation loss: 2.4687437467858033

Epoch: 6| Step: 4
Training loss: 0.9367654147705995
Validation loss: 2.3903834235442174

Epoch: 6| Step: 5
Training loss: 0.550072233918627
Validation loss: 2.4382204963492007

Epoch: 6| Step: 6
Training loss: 0.72810806451184
Validation loss: 2.47408209775572

Epoch: 6| Step: 7
Training loss: 0.5723130919263978
Validation loss: 2.4670711394063787

Epoch: 6| Step: 8
Training loss: 0.8569486524340171
Validation loss: 2.3997814045803194

Epoch: 6| Step: 9
Training loss: 0.9584196335178584
Validation loss: 2.470906181183605

Epoch: 6| Step: 10
Training loss: 0.5163529776884694
Validation loss: 2.3260500235662973

Epoch: 6| Step: 11
Training loss: 0.6444590441399249
Validation loss: 2.42427056081295

Epoch: 6| Step: 12
Training loss: 0.6058316527565897
Validation loss: 2.4093092919743873

Epoch: 6| Step: 13
Training loss: 0.7112367440381201
Validation loss: 2.4183148211930257

Epoch: 131| Step: 0
Training loss: 0.9789380591263728
Validation loss: 2.412184897616306

Epoch: 6| Step: 1
Training loss: 0.8480988854229906
Validation loss: 2.4218281895205274

Epoch: 6| Step: 2
Training loss: 0.8363958510406789
Validation loss: 2.442854298756207

Epoch: 6| Step: 3
Training loss: 0.6956619927371612
Validation loss: 2.4098269146381455

Epoch: 6| Step: 4
Training loss: 0.4926266603207141
Validation loss: 2.3612084580592807

Epoch: 6| Step: 5
Training loss: 1.4271198834196135
Validation loss: 2.4454783341763475

Epoch: 6| Step: 6
Training loss: 0.8451202357259022
Validation loss: 2.336162594567995

Epoch: 6| Step: 7
Training loss: 0.8207401432510996
Validation loss: 2.4418197891949465

Epoch: 6| Step: 8
Training loss: 0.5785650176831788
Validation loss: 2.3601072577171314

Epoch: 6| Step: 9
Training loss: 0.6463807821109244
Validation loss: 2.392265720861796

Epoch: 6| Step: 10
Training loss: 0.8352931025600824
Validation loss: 2.431964457446682

Epoch: 6| Step: 11
Training loss: 0.798769773856389
Validation loss: 2.4313137013410078

Epoch: 6| Step: 12
Training loss: 0.8674269337074132
Validation loss: 2.449561817533015

Epoch: 6| Step: 13
Training loss: 0.6728565675413677
Validation loss: 2.4634940779258447

Epoch: 132| Step: 0
Training loss: 0.6114404106004573
Validation loss: 2.4216092363790716

Epoch: 6| Step: 1
Training loss: 1.4258149443525063
Validation loss: 2.4042257323741847

Epoch: 6| Step: 2
Training loss: 0.5611738891650387
Validation loss: 2.4417092748142286

Epoch: 6| Step: 3
Training loss: 1.0403240261201387
Validation loss: 2.4822081467097443

Epoch: 6| Step: 4
Training loss: 0.816663783580855
Validation loss: 2.418348686183549

Epoch: 6| Step: 5
Training loss: 0.6364525080371078
Validation loss: 2.3673494994878173

Epoch: 6| Step: 6
Training loss: 1.127015322021745
Validation loss: 2.484917075719942

Epoch: 6| Step: 7
Training loss: 0.4164577516695165
Validation loss: 2.439825464791492

Epoch: 6| Step: 8
Training loss: 0.5660194391578863
Validation loss: 2.377008442168436

Epoch: 6| Step: 9
Training loss: 0.8891376993191352
Validation loss: 2.38951500615082

Epoch: 6| Step: 10
Training loss: 0.586840277427679
Validation loss: 2.4258172549054855

Epoch: 6| Step: 11
Training loss: 0.7113682207164244
Validation loss: 2.43651304886208

Epoch: 6| Step: 12
Training loss: 0.5410597469915922
Validation loss: 2.474498622857676

Epoch: 6| Step: 13
Training loss: 0.8085961088431777
Validation loss: 2.399739511579215

Epoch: 133| Step: 0
Training loss: 0.7870743509456228
Validation loss: 2.486860986800977

Epoch: 6| Step: 1
Training loss: 0.6556539553493075
Validation loss: 2.480793688859593

Epoch: 6| Step: 2
Training loss: 0.6619894093447147
Validation loss: 2.413958105897869

Epoch: 6| Step: 3
Training loss: 0.8119272267235876
Validation loss: 2.382698698400965

Epoch: 6| Step: 4
Training loss: 0.8129013244130077
Validation loss: 2.44548902595526

Epoch: 6| Step: 5
Training loss: 0.5195544244860704
Validation loss: 2.3577241658996595

Epoch: 6| Step: 6
Training loss: 0.8296583842253273
Validation loss: 2.3514994362520794

Epoch: 6| Step: 7
Training loss: 1.5669212350920585
Validation loss: 2.444182812411642

Epoch: 6| Step: 8
Training loss: 0.4144214657584194
Validation loss: 2.4153378521998676

Epoch: 6| Step: 9
Training loss: 0.4775911704499638
Validation loss: 2.41542191073239

Epoch: 6| Step: 10
Training loss: 0.6130795481222193
Validation loss: 2.4498481164940333

Epoch: 6| Step: 11
Training loss: 0.9223510676757205
Validation loss: 2.444632650003292

Epoch: 6| Step: 12
Training loss: 0.6079733942070653
Validation loss: 2.374254126294102

Epoch: 6| Step: 13
Training loss: 0.49106020728827826
Validation loss: 2.467369353453613

Epoch: 134| Step: 0
Training loss: 1.5383498967451046
Validation loss: 2.414280261245593

Epoch: 6| Step: 1
Training loss: 0.5802319768977042
Validation loss: 2.485419431707779

Epoch: 6| Step: 2
Training loss: 0.5760908684116572
Validation loss: 2.4078896950987216

Epoch: 6| Step: 3
Training loss: 0.9868029367470463
Validation loss: 2.4460973566792825

Epoch: 6| Step: 4
Training loss: 0.7911248779200344
Validation loss: 2.3647849099255924

Epoch: 6| Step: 5
Training loss: 0.5840833701236535
Validation loss: 2.3866645569587774

Epoch: 6| Step: 6
Training loss: 0.7194063672635292
Validation loss: 2.4798527791307525

Epoch: 6| Step: 7
Training loss: 0.5435770044601151
Validation loss: 2.43944810796038

Epoch: 6| Step: 8
Training loss: 0.7427586817071907
Validation loss: 2.4180810395904633

Epoch: 6| Step: 9
Training loss: 0.6643615722375884
Validation loss: 2.3657109320959915

Epoch: 6| Step: 10
Training loss: 0.8905561989427404
Validation loss: 2.4146364223205254

Epoch: 6| Step: 11
Training loss: 0.8716411837639025
Validation loss: 2.378391471166467

Epoch: 6| Step: 12
Training loss: 0.5878793202070521
Validation loss: 2.3790407774355384

Epoch: 6| Step: 13
Training loss: 0.5286632560026271
Validation loss: 2.395448203160987

Epoch: 135| Step: 0
Training loss: 0.778505578481083
Validation loss: 2.4172194659818116

Epoch: 6| Step: 1
Training loss: 0.6165718678044573
Validation loss: 2.4121422151499905

Epoch: 6| Step: 2
Training loss: 0.7987004483513167
Validation loss: 2.4010079823501216

Epoch: 6| Step: 3
Training loss: 1.5649292943905326
Validation loss: 2.498717901174126

Epoch: 6| Step: 4
Training loss: 0.6836795644030198
Validation loss: 2.4554347606462437

Epoch: 6| Step: 5
Training loss: 0.9524011834016679
Validation loss: 2.3982765400541823

Epoch: 6| Step: 6
Training loss: 0.45455468653385217
Validation loss: 2.4423896456946594

Epoch: 6| Step: 7
Training loss: 0.6499752746060872
Validation loss: 2.357549217764828

Epoch: 6| Step: 8
Training loss: 1.0001136595983344
Validation loss: 2.39491244046542

Epoch: 6| Step: 9
Training loss: 0.6458112087356829
Validation loss: 2.371062712699286

Epoch: 6| Step: 10
Training loss: 0.6485515861802397
Validation loss: 2.385097871047838

Epoch: 6| Step: 11
Training loss: 0.6190740266715636
Validation loss: 2.3904006370692743

Epoch: 6| Step: 12
Training loss: 0.43672619234953347
Validation loss: 2.351746831789664

Epoch: 6| Step: 13
Training loss: 0.3879103940783719
Validation loss: 2.379952637497683

Epoch: 136| Step: 0
Training loss: 0.7112697202365531
Validation loss: 2.4196863436976352

Epoch: 6| Step: 1
Training loss: 0.9324446753282002
Validation loss: 2.4223660781291594

Epoch: 6| Step: 2
Training loss: 0.7108516850921821
Validation loss: 2.439797044531541

Epoch: 6| Step: 3
Training loss: 0.5260216706003735
Validation loss: 2.494513244595784

Epoch: 6| Step: 4
Training loss: 0.6907156820011213
Validation loss: 2.406065657188846

Epoch: 6| Step: 5
Training loss: 0.528837447995107
Validation loss: 2.474228040482817

Epoch: 6| Step: 6
Training loss: 0.9257300640393881
Validation loss: 2.455024243200782

Epoch: 6| Step: 7
Training loss: 0.6383018938552536
Validation loss: 2.4473315303906347

Epoch: 6| Step: 8
Training loss: 0.7358780757942802
Validation loss: 2.4455204754382156

Epoch: 6| Step: 9
Training loss: 0.8588332809644649
Validation loss: 2.4123836963666214

Epoch: 6| Step: 10
Training loss: 1.0526525009108896
Validation loss: 2.380236616460484

Epoch: 6| Step: 11
Training loss: 1.4560121137303734
Validation loss: 2.3873267265675104

Epoch: 6| Step: 12
Training loss: 0.8950463024075175
Validation loss: 2.43043939010101

Epoch: 6| Step: 13
Training loss: 0.8303167381652243
Validation loss: 2.4251343483430827

Epoch: 137| Step: 0
Training loss: 0.7506356724370254
Validation loss: 2.3954753331832164

Epoch: 6| Step: 1
Training loss: 0.8636160499063712
Validation loss: 2.417643749640543

Epoch: 6| Step: 2
Training loss: 0.6814957166832415
Validation loss: 2.4633236574216086

Epoch: 6| Step: 3
Training loss: 1.5386292288245842
Validation loss: 2.4864392611588912

Epoch: 6| Step: 4
Training loss: 0.7356158385763704
Validation loss: 2.4266196914552167

Epoch: 6| Step: 5
Training loss: 0.8671917958196139
Validation loss: 2.457033659706895

Epoch: 6| Step: 6
Training loss: 0.47493718447187194
Validation loss: 2.4704790458539447

Epoch: 6| Step: 7
Training loss: 0.6291493011334911
Validation loss: 2.401322600064639

Epoch: 6| Step: 8
Training loss: 0.6443321845392537
Validation loss: 2.4360585800658594

Epoch: 6| Step: 9
Training loss: 0.48191692783406465
Validation loss: 2.420674557712475

Epoch: 6| Step: 10
Training loss: 0.6256084579811282
Validation loss: 2.3676371886919068

Epoch: 6| Step: 11
Training loss: 0.871508991162246
Validation loss: 2.3766370786275903

Epoch: 6| Step: 12
Training loss: 0.7623770974338824
Validation loss: 2.3850483061605523

Epoch: 6| Step: 13
Training loss: 0.47978462577928704
Validation loss: 2.426138711781591

Epoch: 138| Step: 0
Training loss: 0.636652867003708
Validation loss: 2.4089045888761373

Epoch: 6| Step: 1
Training loss: 0.5968996132773823
Validation loss: 2.3597034958287275

Epoch: 6| Step: 2
Training loss: 0.6596084217722944
Validation loss: 2.402820388940416

Epoch: 6| Step: 3
Training loss: 1.401229543272862
Validation loss: 2.383504556516423

Epoch: 6| Step: 4
Training loss: 0.8761809417894953
Validation loss: 2.3243650844465398

Epoch: 6| Step: 5
Training loss: 0.4812329270690877
Validation loss: 2.44356415050838

Epoch: 6| Step: 6
Training loss: 0.6986637363516469
Validation loss: 2.439328396379942

Epoch: 6| Step: 7
Training loss: 0.5455208771012222
Validation loss: 2.4305961520725337

Epoch: 6| Step: 8
Training loss: 0.7933748830672293
Validation loss: 2.399194173501701

Epoch: 6| Step: 9
Training loss: 0.6504076248100896
Validation loss: 2.4201408658657333

Epoch: 6| Step: 10
Training loss: 0.8281165788330304
Validation loss: 2.35444603728004

Epoch: 6| Step: 11
Training loss: 0.7622065229493621
Validation loss: 2.3454438425417585

Epoch: 6| Step: 12
Training loss: 0.36832944358020364
Validation loss: 2.441547733530606

Epoch: 6| Step: 13
Training loss: 0.8517781255863266
Validation loss: 2.315567765448789

Epoch: 139| Step: 0
Training loss: 0.5405653584387399
Validation loss: 2.407816422459475

Epoch: 6| Step: 1
Training loss: 0.6733428977139091
Validation loss: 2.4981065732549768

Epoch: 6| Step: 2
Training loss: 0.4705278062194677
Validation loss: 2.422532621950711

Epoch: 6| Step: 3
Training loss: 0.3877615691868768
Validation loss: 2.410522021005458

Epoch: 6| Step: 4
Training loss: 0.4148963233982531
Validation loss: 2.5116002364846093

Epoch: 6| Step: 5
Training loss: 0.5824368235091599
Validation loss: 2.4981274426521254

Epoch: 6| Step: 6
Training loss: 0.6501508391030698
Validation loss: 2.479594319320886

Epoch: 6| Step: 7
Training loss: 0.37734083881400393
Validation loss: 2.4308915420701447

Epoch: 6| Step: 8
Training loss: 0.7571649045638916
Validation loss: 2.3373545555519333

Epoch: 6| Step: 9
Training loss: 0.8162777448206298
Validation loss: 2.482884981871108

Epoch: 6| Step: 10
Training loss: 0.5807601566912688
Validation loss: 2.437176968288904

Epoch: 6| Step: 11
Training loss: 0.5129599623867147
Validation loss: 2.4890478561171747

Epoch: 6| Step: 12
Training loss: 0.9457452587399083
Validation loss: 2.4309679850085555

Epoch: 6| Step: 13
Training loss: 1.431936111245059
Validation loss: 2.4332471083252805

Epoch: 140| Step: 0
Training loss: 0.6135554581426806
Validation loss: 2.456612054415358

Epoch: 6| Step: 1
Training loss: 0.7700372958749606
Validation loss: 2.4157276028140933

Epoch: 6| Step: 2
Training loss: 0.7414471195963231
Validation loss: 2.4961020121788384

Epoch: 6| Step: 3
Training loss: 1.4488439358002558
Validation loss: 2.411995044629356

Epoch: 6| Step: 4
Training loss: 0.676078995397528
Validation loss: 2.443480734856714

Epoch: 6| Step: 5
Training loss: 0.9018748993321691
Validation loss: 2.4534525075591223

Epoch: 6| Step: 6
Training loss: 0.5119529362967353
Validation loss: 2.4670736359470786

Epoch: 6| Step: 7
Training loss: 0.7636454155672369
Validation loss: 2.363517862880695

Epoch: 6| Step: 8
Training loss: 0.42510079773316767
Validation loss: 2.4317306644871963

Epoch: 6| Step: 9
Training loss: 0.600574003271608
Validation loss: 2.4101166477175044

Epoch: 6| Step: 10
Training loss: 0.8181387301138734
Validation loss: 2.447667313449377

Epoch: 6| Step: 11
Training loss: 0.5817911049485122
Validation loss: 2.4360930302827475

Epoch: 6| Step: 12
Training loss: 0.7198405906586387
Validation loss: 2.421014259545866

Epoch: 6| Step: 13
Training loss: 0.5699890996493044
Validation loss: 2.4055439131878145

Epoch: 141| Step: 0
Training loss: 0.47162352991772316
Validation loss: 2.4179806644801456

Epoch: 6| Step: 1
Training loss: 0.5535679654483318
Validation loss: 2.3817835185930156

Epoch: 6| Step: 2
Training loss: 0.6368118405306396
Validation loss: 2.3792467296466033

Epoch: 6| Step: 3
Training loss: 0.5876116930524623
Validation loss: 2.377308718878397

Epoch: 6| Step: 4
Training loss: 1.0055270044009708
Validation loss: 2.4376794471873415

Epoch: 6| Step: 5
Training loss: 0.6038460182068769
Validation loss: 2.38815420950709

Epoch: 6| Step: 6
Training loss: 0.5681093590223156
Validation loss: 2.431186127988172

Epoch: 6| Step: 7
Training loss: 1.2869547865423905
Validation loss: 2.3235571082462942

Epoch: 6| Step: 8
Training loss: 0.5884418881212694
Validation loss: 2.2881433683517916

Epoch: 6| Step: 9
Training loss: 0.68948943391025
Validation loss: 2.451223847546204

Epoch: 6| Step: 10
Training loss: 0.7390467394061664
Validation loss: 2.3489187086418593

Epoch: 6| Step: 11
Training loss: 0.6483102236929994
Validation loss: 2.305048458475396

Epoch: 6| Step: 12
Training loss: 0.6634969210147206
Validation loss: 2.4450842006333335

Epoch: 6| Step: 13
Training loss: 0.5077958324337979
Validation loss: 2.4767127086763145

Epoch: 142| Step: 0
Training loss: 0.6155240300443535
Validation loss: 2.3802057568113932

Epoch: 6| Step: 1
Training loss: 0.5330286823574731
Validation loss: 2.443039061735407

Epoch: 6| Step: 2
Training loss: 0.45844340808808487
Validation loss: 2.431598708929016

Epoch: 6| Step: 3
Training loss: 0.552540775537785
Validation loss: 2.395973737721343

Epoch: 6| Step: 4
Training loss: 0.7817030165448301
Validation loss: 2.3548537886033962

Epoch: 6| Step: 5
Training loss: 0.4569180014082505
Validation loss: 2.408625004495782

Epoch: 6| Step: 6
Training loss: 0.7113323582330019
Validation loss: 2.4057264790613213

Epoch: 6| Step: 7
Training loss: 0.5502909649302192
Validation loss: 2.4641562105984094

Epoch: 6| Step: 8
Training loss: 0.7129560884701167
Validation loss: 2.46672024561282

Epoch: 6| Step: 9
Training loss: 0.5786912567778103
Validation loss: 2.4021549636558213

Epoch: 6| Step: 10
Training loss: 1.331531374929472
Validation loss: 2.4510364348137808

Epoch: 6| Step: 11
Training loss: 0.5971735582066706
Validation loss: 2.444119260813579

Epoch: 6| Step: 12
Training loss: 0.8504782957865555
Validation loss: 2.441075335646434

Epoch: 6| Step: 13
Training loss: 0.5052352649025537
Validation loss: 2.376204703787397

Epoch: 143| Step: 0
Training loss: 0.5904706945132409
Validation loss: 2.4404266752255235

Epoch: 6| Step: 1
Training loss: 0.8346355317225305
Validation loss: 2.416230644705067

Epoch: 6| Step: 2
Training loss: 1.3591794717412757
Validation loss: 2.406526409308347

Epoch: 6| Step: 3
Training loss: 0.6448241984141911
Validation loss: 2.442179784683273

Epoch: 6| Step: 4
Training loss: 0.5541758528165545
Validation loss: 2.417826108571663

Epoch: 6| Step: 5
Training loss: 0.43173349684588375
Validation loss: 2.405407910983297

Epoch: 6| Step: 6
Training loss: 0.7821675062805694
Validation loss: 2.3222605601202826

Epoch: 6| Step: 7
Training loss: 0.35880557849230277
Validation loss: 2.4081384506265766

Epoch: 6| Step: 8
Training loss: 0.5504539003949023
Validation loss: 2.4103299021182325

Epoch: 6| Step: 9
Training loss: 0.5368354792587056
Validation loss: 2.3808777004973063

Epoch: 6| Step: 10
Training loss: 0.5355327979977728
Validation loss: 2.3928990238404353

Epoch: 6| Step: 11
Training loss: 0.5195655237809913
Validation loss: 2.422351371921944

Epoch: 6| Step: 12
Training loss: 0.955180468858309
Validation loss: 2.4125628870013243

Epoch: 6| Step: 13
Training loss: 0.6792676878806928
Validation loss: 2.375268820556879

Epoch: 144| Step: 0
Training loss: 0.7690638948045814
Validation loss: 2.422378618934721

Epoch: 6| Step: 1
Training loss: 0.6318221643470807
Validation loss: 2.373804745316541

Epoch: 6| Step: 2
Training loss: 0.6215602394473327
Validation loss: 2.3739344565672296

Epoch: 6| Step: 3
Training loss: 0.4558300960130588
Validation loss: 2.3909581436371563

Epoch: 6| Step: 4
Training loss: 0.5168426470335072
Validation loss: 2.35800944846204

Epoch: 6| Step: 5
Training loss: 0.6767762637134566
Validation loss: 2.378413633257635

Epoch: 6| Step: 6
Training loss: 0.6754136601717863
Validation loss: 2.391649895009993

Epoch: 6| Step: 7
Training loss: 0.9528841433516143
Validation loss: 2.426409113372129

Epoch: 6| Step: 8
Training loss: 0.8276778759470649
Validation loss: 2.3675194267327204

Epoch: 6| Step: 9
Training loss: 0.5082807289587588
Validation loss: 2.4424540394806162

Epoch: 6| Step: 10
Training loss: 0.45919252910692365
Validation loss: 2.389753610873681

Epoch: 6| Step: 11
Training loss: 0.5321757441066182
Validation loss: 2.5171026545882165

Epoch: 6| Step: 12
Training loss: 0.5127486137657826
Validation loss: 2.4369447678933756

Epoch: 6| Step: 13
Training loss: 1.3114155876257199
Validation loss: 2.4734169511549937

Epoch: 145| Step: 0
Training loss: 1.308045411876067
Validation loss: 2.4268082365941552

Epoch: 6| Step: 1
Training loss: 0.3486545246105851
Validation loss: 2.461734630517756

Epoch: 6| Step: 2
Training loss: 0.4056770061839429
Validation loss: 2.378604663091374

Epoch: 6| Step: 3
Training loss: 0.6514758887231717
Validation loss: 2.372761968560848

Epoch: 6| Step: 4
Training loss: 1.0072218472657228
Validation loss: 2.4702345573391202

Epoch: 6| Step: 5
Training loss: 0.47021181733453793
Validation loss: 2.4859778713654186

Epoch: 6| Step: 6
Training loss: 0.944593802653346
Validation loss: 2.438347921668961

Epoch: 6| Step: 7
Training loss: 0.7669290219829173
Validation loss: 2.4170175056544325

Epoch: 6| Step: 8
Training loss: 0.6103595946737111
Validation loss: 2.394203781794472

Epoch: 6| Step: 9
Training loss: 0.5119505495576827
Validation loss: 2.439177824133232

Epoch: 6| Step: 10
Training loss: 0.6280660288443305
Validation loss: 2.455974972431718

Epoch: 6| Step: 11
Training loss: 0.44669008497272406
Validation loss: 2.5007604237239143

Epoch: 6| Step: 12
Training loss: 0.5695841593295705
Validation loss: 2.382405047157369

Epoch: 6| Step: 13
Training loss: 0.5399431415929452
Validation loss: 2.4189940678540975

Epoch: 146| Step: 0
Training loss: 0.527503716966451
Validation loss: 2.3771885442115077

Epoch: 6| Step: 1
Training loss: 0.454003961390383
Validation loss: 2.4432066278360662

Epoch: 6| Step: 2
Training loss: 0.6635115188944095
Validation loss: 2.4109302104477974

Epoch: 6| Step: 3
Training loss: 0.7025049442578833
Validation loss: 2.391436677988611

Epoch: 6| Step: 4
Training loss: 0.7653001368541588
Validation loss: 2.4718632604140987

Epoch: 6| Step: 5
Training loss: 0.653596144126248
Validation loss: 2.4145207139969442

Epoch: 6| Step: 6
Training loss: 1.4091929265257568
Validation loss: 2.39073345461901

Epoch: 6| Step: 7
Training loss: 0.6904854758680445
Validation loss: 2.4528379819092874

Epoch: 6| Step: 8
Training loss: 0.5445442395186579
Validation loss: 2.34996688291874

Epoch: 6| Step: 9
Training loss: 0.5453299358389553
Validation loss: 2.4115103983081805

Epoch: 6| Step: 10
Training loss: 0.48825314250155466
Validation loss: 2.446426186744395

Epoch: 6| Step: 11
Training loss: 0.637873719570124
Validation loss: 2.3927753061020463

Epoch: 6| Step: 12
Training loss: 0.9169227971969285
Validation loss: 2.406409122110385

Epoch: 6| Step: 13
Training loss: 0.5002526598568444
Validation loss: 2.369507579054272

Epoch: 147| Step: 0
Training loss: 1.5699907419211163
Validation loss: 2.421074511408597

Epoch: 6| Step: 1
Training loss: 0.40695902500280634
Validation loss: 2.307982043678517

Epoch: 6| Step: 2
Training loss: 0.6354800854495684
Validation loss: 2.3829462482875012

Epoch: 6| Step: 3
Training loss: 0.5507141234703524
Validation loss: 2.397955084878795

Epoch: 6| Step: 4
Training loss: 0.592425978257886
Validation loss: 2.3793183602934085

Epoch: 6| Step: 5
Training loss: 0.5776309918388179
Validation loss: 2.4190788945714043

Epoch: 6| Step: 6
Training loss: 0.4774424449326501
Validation loss: 2.4247704046567953

Epoch: 6| Step: 7
Training loss: 0.5388913090095492
Validation loss: 2.32775418530842

Epoch: 6| Step: 8
Training loss: 0.819499966703441
Validation loss: 2.450686034020025

Epoch: 6| Step: 9
Training loss: 0.5469576364480176
Validation loss: 2.4777243823934936

Epoch: 6| Step: 10
Training loss: 0.4875337448423057
Validation loss: 2.4206465528155565

Epoch: 6| Step: 11
Training loss: 0.5620099157972275
Validation loss: 2.4467196249968914

Epoch: 6| Step: 12
Training loss: 0.7368378026243301
Validation loss: 2.4019305610434416

Epoch: 6| Step: 13
Training loss: 0.6231873930798149
Validation loss: 2.3852300834702533

Epoch: 148| Step: 0
Training loss: 0.6592264342510056
Validation loss: 2.494544251238128

Epoch: 6| Step: 1
Training loss: 0.36332888957391735
Validation loss: 2.4150257184783066

Epoch: 6| Step: 2
Training loss: 0.72503349457025
Validation loss: 2.41656126965417

Epoch: 6| Step: 3
Training loss: 0.5776038785291067
Validation loss: 2.502090517828349

Epoch: 6| Step: 4
Training loss: 0.6223243422263136
Validation loss: 2.4055219101945053

Epoch: 6| Step: 5
Training loss: 0.3976973222007889
Validation loss: 2.453873133524459

Epoch: 6| Step: 6
Training loss: 0.48550401898988427
Validation loss: 2.407778976639443

Epoch: 6| Step: 7
Training loss: 0.6304417459029725
Validation loss: 2.3582071188546974

Epoch: 6| Step: 8
Training loss: 0.3154386158910778
Validation loss: 2.389901369565599

Epoch: 6| Step: 9
Training loss: 1.2877449006424193
Validation loss: 2.4007299362907237

Epoch: 6| Step: 10
Training loss: 0.9550684828944362
Validation loss: 2.3895743311407864

Epoch: 6| Step: 11
Training loss: 0.45619003607309844
Validation loss: 2.427491989986825

Epoch: 6| Step: 12
Training loss: 0.5718128900204529
Validation loss: 2.4328250885500746

Epoch: 6| Step: 13
Training loss: 0.5695120799078764
Validation loss: 2.377427600489627

Epoch: 149| Step: 0
Training loss: 0.4726980837129245
Validation loss: 2.427918881079853

Epoch: 6| Step: 1
Training loss: 0.4655172293708393
Validation loss: 2.432840000945312

Epoch: 6| Step: 2
Training loss: 1.3753142864663817
Validation loss: 2.4978283032676565

Epoch: 6| Step: 3
Training loss: 0.5807240034024966
Validation loss: 2.384691141950835

Epoch: 6| Step: 4
Training loss: 0.5809172395617529
Validation loss: 2.4220446619472487

Epoch: 6| Step: 5
Training loss: 0.5308357474912465
Validation loss: 2.4252259565393106

Epoch: 6| Step: 6
Training loss: 0.5653740784702723
Validation loss: 2.4069048993540028

Epoch: 6| Step: 7
Training loss: 0.5068203550673931
Validation loss: 2.4205828839706127

Epoch: 6| Step: 8
Training loss: 0.6984066642764439
Validation loss: 2.3478533957710934

Epoch: 6| Step: 9
Training loss: 0.4391622979720749
Validation loss: 2.35682641625941

Epoch: 6| Step: 10
Training loss: 0.625476560103146
Validation loss: 2.3417021387836794

Epoch: 6| Step: 11
Training loss: 0.7577891395350381
Validation loss: 2.362547520423657

Epoch: 6| Step: 12
Training loss: 0.5749013567359245
Validation loss: 2.4216905913338365

Epoch: 6| Step: 13
Training loss: 0.9138620596976414
Validation loss: 2.3634703169087814

Epoch: 150| Step: 0
Training loss: 0.4709663762970627
Validation loss: 2.387853025130704

Epoch: 6| Step: 1
Training loss: 0.7984691456833359
Validation loss: 2.392893053983702

Epoch: 6| Step: 2
Training loss: 0.5463745824916538
Validation loss: 2.3426752974941576

Epoch: 6| Step: 3
Training loss: 0.46775298581579733
Validation loss: 2.4112121148739774

Epoch: 6| Step: 4
Training loss: 0.8151553851885867
Validation loss: 2.370560612828714

Epoch: 6| Step: 5
Training loss: 0.4390700132602774
Validation loss: 2.36713902892793

Epoch: 6| Step: 6
Training loss: 0.30963282149595944
Validation loss: 2.3031077256195402

Epoch: 6| Step: 7
Training loss: 0.5858436509314062
Validation loss: 2.3472706609790324

Epoch: 6| Step: 8
Training loss: 1.354265982091496
Validation loss: 2.3952938356976703

Epoch: 6| Step: 9
Training loss: 0.5600584607178215
Validation loss: 2.3941531108344525

Epoch: 6| Step: 10
Training loss: 0.7652927378372846
Validation loss: 2.4096061783649323

Epoch: 6| Step: 11
Training loss: 0.4986663556051219
Validation loss: 2.321154337883693

Epoch: 6| Step: 12
Training loss: 0.6176641772239421
Validation loss: 2.397140624485993

Epoch: 6| Step: 13
Training loss: 0.4982986412231152
Validation loss: 2.395063132726205

Epoch: 151| Step: 0
Training loss: 0.4089559521494857
Validation loss: 2.4046276948501304

Epoch: 6| Step: 1
Training loss: 0.5275258632846105
Validation loss: 2.3902765323424604

Epoch: 6| Step: 2
Training loss: 0.6044245914756845
Validation loss: 2.33370671236729

Epoch: 6| Step: 3
Training loss: 0.31718007581694513
Validation loss: 2.3702960612884385

Epoch: 6| Step: 4
Training loss: 0.5271957472340972
Validation loss: 2.4284156176996134

Epoch: 6| Step: 5
Training loss: 0.45364360071531423
Validation loss: 2.351249395164562

Epoch: 6| Step: 6
Training loss: 0.5778891623657579
Validation loss: 2.3622018750449723

Epoch: 6| Step: 7
Training loss: 0.9509720484700289
Validation loss: 2.439840937000143

Epoch: 6| Step: 8
Training loss: 0.5015622706427599
Validation loss: 2.3287167831757483

Epoch: 6| Step: 9
Training loss: 0.48488064491858784
Validation loss: 2.381603538787954

Epoch: 6| Step: 10
Training loss: 1.3408759675835478
Validation loss: 2.383011089450157

Epoch: 6| Step: 11
Training loss: 0.59055601151029
Validation loss: 2.3833676384633278

Epoch: 6| Step: 12
Training loss: 0.5283735604520401
Validation loss: 2.4354968684043268

Epoch: 6| Step: 13
Training loss: 0.7578495449174779
Validation loss: 2.441662698119739

Epoch: 152| Step: 0
Training loss: 0.37211958991908195
Validation loss: 2.4462388206698207

Epoch: 6| Step: 1
Training loss: 0.8398216067211671
Validation loss: 2.431253090327766

Epoch: 6| Step: 2
Training loss: 0.5781772177543469
Validation loss: 2.401826334491807

Epoch: 6| Step: 3
Training loss: 0.5141683579648403
Validation loss: 2.314291955672027

Epoch: 6| Step: 4
Training loss: 0.6694351296438549
Validation loss: 2.3597298075350914

Epoch: 6| Step: 5
Training loss: 0.5832748440529444
Validation loss: 2.4314284715956087

Epoch: 6| Step: 6
Training loss: 0.5217615026989091
Validation loss: 2.3094017908231153

Epoch: 6| Step: 7
Training loss: 0.6514832995097419
Validation loss: 2.4229000752461265

Epoch: 6| Step: 8
Training loss: 0.6209392475397316
Validation loss: 2.4352024857642878

Epoch: 6| Step: 9
Training loss: 1.286396344296281
Validation loss: 2.4334469378964267

Epoch: 6| Step: 10
Training loss: 0.7670994399239638
Validation loss: 2.481912444091678

Epoch: 6| Step: 11
Training loss: 0.3264455503741552
Validation loss: 2.371972312489039

Epoch: 6| Step: 12
Training loss: 0.5322158672413049
Validation loss: 2.396364017812612

Epoch: 6| Step: 13
Training loss: 0.4669156741358043
Validation loss: 2.3917249422140032

Epoch: 153| Step: 0
Training loss: 0.36935192700920433
Validation loss: 2.4549919362139687

Epoch: 6| Step: 1
Training loss: 0.7201650207872689
Validation loss: 2.4338957556816077

Epoch: 6| Step: 2
Training loss: 0.6794166902385913
Validation loss: 2.357673115420204

Epoch: 6| Step: 3
Training loss: 0.6661064108446862
Validation loss: 2.3656266105374253

Epoch: 6| Step: 4
Training loss: 0.6271063358950371
Validation loss: 2.3727783218615786

Epoch: 6| Step: 5
Training loss: 0.7662515995575232
Validation loss: 2.3554361150282705

Epoch: 6| Step: 6
Training loss: 0.5278731338066918
Validation loss: 2.3955824236856196

Epoch: 6| Step: 7
Training loss: 1.3408793903846874
Validation loss: 2.428371461448082

Epoch: 6| Step: 8
Training loss: 0.5848952114773369
Validation loss: 2.3105600313149055

Epoch: 6| Step: 9
Training loss: 0.6016969406704429
Validation loss: 2.324218151616038

Epoch: 6| Step: 10
Training loss: 0.6665711980253091
Validation loss: 2.381822357410121

Epoch: 6| Step: 11
Training loss: 0.7166309632419686
Validation loss: 2.3540297161766546

Epoch: 6| Step: 12
Training loss: 0.6491036727401739
Validation loss: 2.369789313570189

Epoch: 6| Step: 13
Training loss: 0.8339762988805026
Validation loss: 2.3712483103787507

Epoch: 154| Step: 0
Training loss: 0.4468076935345658
Validation loss: 2.368870865783793

Epoch: 6| Step: 1
Training loss: 0.5478694865240671
Validation loss: 2.362098132876831

Epoch: 6| Step: 2
Training loss: 0.6714292422613022
Validation loss: 2.41879122893609

Epoch: 6| Step: 3
Training loss: 0.5616025918650117
Validation loss: 2.450561333921939

Epoch: 6| Step: 4
Training loss: 0.5502600943520344
Validation loss: 2.4146248204702068

Epoch: 6| Step: 5
Training loss: 0.6369877814404106
Validation loss: 2.386610196189632

Epoch: 6| Step: 6
Training loss: 0.7768707369797133
Validation loss: 2.381651114841706

Epoch: 6| Step: 7
Training loss: 0.5341804685708983
Validation loss: 2.355493076213609

Epoch: 6| Step: 8
Training loss: 0.43244077990936974
Validation loss: 2.357318588307635

Epoch: 6| Step: 9
Training loss: 0.5361309225191527
Validation loss: 2.348389200647476

Epoch: 6| Step: 10
Training loss: 0.4602437698734125
Validation loss: 2.3326477905640632

Epoch: 6| Step: 11
Training loss: 1.3245225405994532
Validation loss: 2.415496795134174

Epoch: 6| Step: 12
Training loss: 0.8683787918150804
Validation loss: 2.378201552039098

Epoch: 6| Step: 13
Training loss: 0.5227151697815815
Validation loss: 2.3970046759734727

Epoch: 155| Step: 0
Training loss: 0.5502271096625844
Validation loss: 2.396378062697781

Epoch: 6| Step: 1
Training loss: 0.5312859579146629
Validation loss: 2.4072405605154197

Epoch: 6| Step: 2
Training loss: 0.3937782618053028
Validation loss: 2.435828964754986

Epoch: 6| Step: 3
Training loss: 0.34370894620405046
Validation loss: 2.367895912116597

Epoch: 6| Step: 4
Training loss: 1.4139598998894853
Validation loss: 2.376402256913979

Epoch: 6| Step: 5
Training loss: 0.5245482772049808
Validation loss: 2.401905398190124

Epoch: 6| Step: 6
Training loss: 0.518904515889253
Validation loss: 2.385126526580008

Epoch: 6| Step: 7
Training loss: 0.9591039517003547
Validation loss: 2.4063211075485893

Epoch: 6| Step: 8
Training loss: 0.5679998670027134
Validation loss: 2.420296341128143

Epoch: 6| Step: 9
Training loss: 0.5102423999711931
Validation loss: 2.4023782040159327

Epoch: 6| Step: 10
Training loss: 0.525029423434128
Validation loss: 2.3910562296698066

Epoch: 6| Step: 11
Training loss: 0.5541024144528831
Validation loss: 2.358152666574166

Epoch: 6| Step: 12
Training loss: 0.6409189201277008
Validation loss: 2.3674289257118835

Epoch: 6| Step: 13
Training loss: 0.7083866763131192
Validation loss: 2.3015545601674385

Epoch: 156| Step: 0
Training loss: 0.31721334774891513
Validation loss: 2.420848546880387

Epoch: 6| Step: 1
Training loss: 0.7278152658386221
Validation loss: 2.35902383645717

Epoch: 6| Step: 2
Training loss: 0.6815200742786267
Validation loss: 2.3774064654868705

Epoch: 6| Step: 3
Training loss: 0.7320767415994175
Validation loss: 2.3721194282473403

Epoch: 6| Step: 4
Training loss: 0.6320875277177842
Validation loss: 2.3915044293111047

Epoch: 6| Step: 5
Training loss: 0.5769689187152564
Validation loss: 2.3972243762703425

Epoch: 6| Step: 6
Training loss: 0.4965575445658918
Validation loss: 2.351920386842966

Epoch: 6| Step: 7
Training loss: 0.6126408483140048
Validation loss: 2.476374959012078

Epoch: 6| Step: 8
Training loss: 1.3133910197370824
Validation loss: 2.4313798021513566

Epoch: 6| Step: 9
Training loss: 0.5763769786885965
Validation loss: 2.3487047339072333

Epoch: 6| Step: 10
Training loss: 0.4975567968334211
Validation loss: 2.383995337900941

Epoch: 6| Step: 11
Training loss: 0.608470930798431
Validation loss: 2.3805489884113706

Epoch: 6| Step: 12
Training loss: 0.8011258756097397
Validation loss: 2.4524288283042894

Epoch: 6| Step: 13
Training loss: 0.33463874647015157
Validation loss: 2.371696525429558

Epoch: 157| Step: 0
Training loss: 0.5863623286975987
Validation loss: 2.370979620560772

Epoch: 6| Step: 1
Training loss: 0.744257760027639
Validation loss: 2.3802671251333023

Epoch: 6| Step: 2
Training loss: 0.4031326928994166
Validation loss: 2.3436052828721023

Epoch: 6| Step: 3
Training loss: 0.3130508574538772
Validation loss: 2.370382186478838

Epoch: 6| Step: 4
Training loss: 0.5935902631616565
Validation loss: 2.3926263547434825

Epoch: 6| Step: 5
Training loss: 1.282290989462175
Validation loss: 2.4452613118331943

Epoch: 6| Step: 6
Training loss: 0.48467654409514327
Validation loss: 2.341532306504477

Epoch: 6| Step: 7
Training loss: 0.45046831570914325
Validation loss: 2.4482679453203504

Epoch: 6| Step: 8
Training loss: 0.821835729436786
Validation loss: 2.4144847545846853

Epoch: 6| Step: 9
Training loss: 0.6193889517035573
Validation loss: 2.3692547256236365

Epoch: 6| Step: 10
Training loss: 0.5788339186152033
Validation loss: 2.400857092216676

Epoch: 6| Step: 11
Training loss: 0.5811662070060395
Validation loss: 2.403474437241475

Epoch: 6| Step: 12
Training loss: 0.7040260052185695
Validation loss: 2.4156152202742165

Epoch: 6| Step: 13
Training loss: 0.6900786029231428
Validation loss: 2.387573039350682

Epoch: 158| Step: 0
Training loss: 0.5310802749580843
Validation loss: 2.4030324388130326

Epoch: 6| Step: 1
Training loss: 0.4426733919454102
Validation loss: 2.3588288034962375

Epoch: 6| Step: 2
Training loss: 0.5968133055673225
Validation loss: 2.379914001919992

Epoch: 6| Step: 3
Training loss: 0.7980805048716355
Validation loss: 2.3951097031370905

Epoch: 6| Step: 4
Training loss: 0.4306519348789774
Validation loss: 2.357625940356296

Epoch: 6| Step: 5
Training loss: 0.71259567220735
Validation loss: 2.343024959740063

Epoch: 6| Step: 6
Training loss: 0.6072104475521652
Validation loss: 2.411695503013254

Epoch: 6| Step: 7
Training loss: 0.8075666308002504
Validation loss: 2.3445636608472853

Epoch: 6| Step: 8
Training loss: 0.540528336190654
Validation loss: 2.2993447655828354

Epoch: 6| Step: 9
Training loss: 0.6345805676008215
Validation loss: 2.3874102234396655

Epoch: 6| Step: 10
Training loss: 1.2426351544347394
Validation loss: 2.3216890389824347

Epoch: 6| Step: 11
Training loss: 0.4143675813830745
Validation loss: 2.3051178266429755

Epoch: 6| Step: 12
Training loss: 0.46115527423471836
Validation loss: 2.3544743992246784

Epoch: 6| Step: 13
Training loss: 0.5932202987968186
Validation loss: 2.4480828222063518

Epoch: 159| Step: 0
Training loss: 0.8741027796018662
Validation loss: 2.369087170414277

Epoch: 6| Step: 1
Training loss: 0.6344454383267027
Validation loss: 2.3298131638084647

Epoch: 6| Step: 2
Training loss: 0.63588243100785
Validation loss: 2.4383865276678285

Epoch: 6| Step: 3
Training loss: 0.550942579950291
Validation loss: 2.4597953043005307

Epoch: 6| Step: 4
Training loss: 1.2426764527564491
Validation loss: 2.438292757541074

Epoch: 6| Step: 5
Training loss: 0.5408125954322286
Validation loss: 2.3646304984297237

Epoch: 6| Step: 6
Training loss: 0.31174917622314374
Validation loss: 2.3701689758636464

Epoch: 6| Step: 7
Training loss: 0.6912162433473442
Validation loss: 2.3219668295334044

Epoch: 6| Step: 8
Training loss: 0.7561453344884113
Validation loss: 2.3066849495690565

Epoch: 6| Step: 9
Training loss: 0.6175728090118987
Validation loss: 2.3754292986853502

Epoch: 6| Step: 10
Training loss: 0.5183255251401628
Validation loss: 2.338705508829885

Epoch: 6| Step: 11
Training loss: 0.442321958419449
Validation loss: 2.3791321228067166

Epoch: 6| Step: 12
Training loss: 0.5390671716017713
Validation loss: 2.3566001085579353

Epoch: 6| Step: 13
Training loss: 0.5562347538605285
Validation loss: 2.3745611186833906

Epoch: 160| Step: 0
Training loss: 0.5702467318720907
Validation loss: 2.3335714105218557

Epoch: 6| Step: 1
Training loss: 0.5430171588202848
Validation loss: 2.354617697346244

Epoch: 6| Step: 2
Training loss: 0.3627206722631564
Validation loss: 2.3547398254885357

Epoch: 6| Step: 3
Training loss: 0.3242371795196226
Validation loss: 2.2745406193544717

Epoch: 6| Step: 4
Training loss: 0.713782017084921
Validation loss: 2.3943973107602505

Epoch: 6| Step: 5
Training loss: 0.3836663707663795
Validation loss: 2.334246956115004

Epoch: 6| Step: 6
Training loss: 0.43035727232675014
Validation loss: 2.305270880878973

Epoch: 6| Step: 7
Training loss: 0.32287726879762674
Validation loss: 2.3444290194774853

Epoch: 6| Step: 8
Training loss: 0.6932488581733641
Validation loss: 2.3660517235044205

Epoch: 6| Step: 9
Training loss: 0.5217600176114106
Validation loss: 2.399895033594008

Epoch: 6| Step: 10
Training loss: 0.3308755282947976
Validation loss: 2.404842980943425

Epoch: 6| Step: 11
Training loss: 0.6266543903653288
Validation loss: 2.3564134414610667

Epoch: 6| Step: 12
Training loss: 0.5486092453400424
Validation loss: 2.410879413055797

Epoch: 6| Step: 13
Training loss: 1.4467334257857059
Validation loss: 2.3529867630637704

Epoch: 161| Step: 0
Training loss: 0.5578703831578428
Validation loss: 2.392794088361149

Epoch: 6| Step: 1
Training loss: 0.5277513130005406
Validation loss: 2.3687144811109464

Epoch: 6| Step: 2
Training loss: 0.561207239437923
Validation loss: 2.325110444484455

Epoch: 6| Step: 3
Training loss: 0.44649065335349203
Validation loss: 2.370251593480981

Epoch: 6| Step: 4
Training loss: 1.3928601593292327
Validation loss: 2.3682203819683014

Epoch: 6| Step: 5
Training loss: 0.4425949194500193
Validation loss: 2.393515408195061

Epoch: 6| Step: 6
Training loss: 0.3219019947953941
Validation loss: 2.352802815529908

Epoch: 6| Step: 7
Training loss: 0.6655675997632274
Validation loss: 2.330243403500959

Epoch: 6| Step: 8
Training loss: 0.5890124696891487
Validation loss: 2.390578574932825

Epoch: 6| Step: 9
Training loss: 0.7484569172739526
Validation loss: 2.3749762249476025

Epoch: 6| Step: 10
Training loss: 0.5379493110683528
Validation loss: 2.2848082709477957

Epoch: 6| Step: 11
Training loss: 0.4166874363808922
Validation loss: 2.359774406259742

Epoch: 6| Step: 12
Training loss: 0.48812137275158907
Validation loss: 2.2746802360305836

Epoch: 6| Step: 13
Training loss: 0.6407706164966285
Validation loss: 2.3110515078883545

Epoch: 162| Step: 0
Training loss: 0.5596823055978367
Validation loss: 2.2729579598941303

Epoch: 6| Step: 1
Training loss: 0.36265331265477435
Validation loss: 2.386747103042472

Epoch: 6| Step: 2
Training loss: 0.5210665911641663
Validation loss: 2.2999685046900584

Epoch: 6| Step: 3
Training loss: 0.7579380993139628
Validation loss: 2.3695156705222367

Epoch: 6| Step: 4
Training loss: 0.7587299888523497
Validation loss: 2.3260448985939335

Epoch: 6| Step: 5
Training loss: 0.5545106256583112
Validation loss: 2.3069545479474827

Epoch: 6| Step: 6
Training loss: 0.5551139105926316
Validation loss: 2.416930107578166

Epoch: 6| Step: 7
Training loss: 0.5220346868927669
Validation loss: 2.3368456126825174

Epoch: 6| Step: 8
Training loss: 0.4489423150068955
Validation loss: 2.3460388366864624

Epoch: 6| Step: 9
Training loss: 1.3497272887109422
Validation loss: 2.3500565177127317

Epoch: 6| Step: 10
Training loss: 0.6856617627507071
Validation loss: 2.415690222053369

Epoch: 6| Step: 11
Training loss: 0.5660226509495353
Validation loss: 2.340103262391642

Epoch: 6| Step: 12
Training loss: 0.5722821854939041
Validation loss: 2.356173551686961

Epoch: 6| Step: 13
Training loss: 0.431116830609598
Validation loss: 2.34090018902001

Epoch: 163| Step: 0
Training loss: 0.3977210016499344
Validation loss: 2.4016489404275223

Epoch: 6| Step: 1
Training loss: 0.5649436218693048
Validation loss: 2.3757469023396283

Epoch: 6| Step: 2
Training loss: 0.5130336843775463
Validation loss: 2.35928910459073

Epoch: 6| Step: 3
Training loss: 0.4898054062287171
Validation loss: 2.3261219599034293

Epoch: 6| Step: 4
Training loss: 0.5395708589572469
Validation loss: 2.4038813438774165

Epoch: 6| Step: 5
Training loss: 0.43610305513782666
Validation loss: 2.3914280791243354

Epoch: 6| Step: 6
Training loss: 0.5233410703741136
Validation loss: 2.3287889357414184

Epoch: 6| Step: 7
Training loss: 0.4460447548384163
Validation loss: 2.3598778548798003

Epoch: 6| Step: 8
Training loss: 0.5903155227511042
Validation loss: 2.373750324406601

Epoch: 6| Step: 9
Training loss: 1.4150049430572116
Validation loss: 2.342299915590876

Epoch: 6| Step: 10
Training loss: 0.3259828213775961
Validation loss: 2.329399493960139

Epoch: 6| Step: 11
Training loss: 0.5681392597385506
Validation loss: 2.371049313911789

Epoch: 6| Step: 12
Training loss: 0.7708766813375844
Validation loss: 2.3736823592911622

Epoch: 6| Step: 13
Training loss: 0.4583046933098002
Validation loss: 2.4001417369845375

Epoch: 164| Step: 0
Training loss: 0.42268283640505383
Validation loss: 2.316287761914981

Epoch: 6| Step: 1
Training loss: 0.4549104438929608
Validation loss: 2.3815802384380698

Epoch: 6| Step: 2
Training loss: 0.6974443906403837
Validation loss: 2.3381819643098516

Epoch: 6| Step: 3
Training loss: 0.76476971869036
Validation loss: 2.340505957366809

Epoch: 6| Step: 4
Training loss: 0.44301516240976063
Validation loss: 2.3271022487362263

Epoch: 6| Step: 5
Training loss: 1.2344817586194607
Validation loss: 2.3529855640399244

Epoch: 6| Step: 6
Training loss: 0.3421553230834023
Validation loss: 2.3923942152691

Epoch: 6| Step: 7
Training loss: 0.581734037359798
Validation loss: 2.3426828455665754

Epoch: 6| Step: 8
Training loss: 0.4696083633901882
Validation loss: 2.4000476481423187

Epoch: 6| Step: 9
Training loss: 0.43457240414919734
Validation loss: 2.375860334470616

Epoch: 6| Step: 10
Training loss: 0.5339352398850998
Validation loss: 2.337601603715435

Epoch: 6| Step: 11
Training loss: 0.45557409282058736
Validation loss: 2.350662067502774

Epoch: 6| Step: 12
Training loss: 0.47403544193466146
Validation loss: 2.390521651882662

Epoch: 6| Step: 13
Training loss: 0.36216943072057023
Validation loss: 2.3456821615408354

Epoch: 165| Step: 0
Training loss: 1.2016616939083773
Validation loss: 2.359756607285127

Epoch: 6| Step: 1
Training loss: 0.5190260876326445
Validation loss: 2.352433289498543

Epoch: 6| Step: 2
Training loss: 0.5160062709656471
Validation loss: 2.3568125740415504

Epoch: 6| Step: 3
Training loss: 0.6123048335171029
Validation loss: 2.3413096884365925

Epoch: 6| Step: 4
Training loss: 0.6876703398096847
Validation loss: 2.3438599963337694

Epoch: 6| Step: 5
Training loss: 0.44900766471913595
Validation loss: 2.31926468160827

Epoch: 6| Step: 6
Training loss: 0.5894294951438072
Validation loss: 2.337002803670768

Epoch: 6| Step: 7
Training loss: 0.46912032439994134
Validation loss: 2.3216929327124123

Epoch: 6| Step: 8
Training loss: 0.6956784860316414
Validation loss: 2.3466086946401616

Epoch: 6| Step: 9
Training loss: 0.4319075022610914
Validation loss: 2.36660089558114

Epoch: 6| Step: 10
Training loss: 0.5346611127021897
Validation loss: 2.348530095234127

Epoch: 6| Step: 11
Training loss: 0.8771711728350341
Validation loss: 2.3221717347077204

Epoch: 6| Step: 12
Training loss: 0.32993906240568444
Validation loss: 2.3312552996618665

Epoch: 6| Step: 13
Training loss: 0.3890528513006865
Validation loss: 2.316347246882065

Epoch: 166| Step: 0
Training loss: 0.5195771390682838
Validation loss: 2.315827819069082

Epoch: 6| Step: 1
Training loss: 0.5328082903922238
Validation loss: 2.3376490043978477

Epoch: 6| Step: 2
Training loss: 0.46934369954307603
Validation loss: 2.3849307874450827

Epoch: 6| Step: 3
Training loss: 0.5088575320749132
Validation loss: 2.3764227069217436

Epoch: 6| Step: 4
Training loss: 1.1982620349536723
Validation loss: 2.262612438042482

Epoch: 6| Step: 5
Training loss: 0.6412692668318105
Validation loss: 2.376322996840049

Epoch: 6| Step: 6
Training loss: 0.49072256515274343
Validation loss: 2.3186899456736976

Epoch: 6| Step: 7
Training loss: 0.6008261347598272
Validation loss: 2.2911119020768798

Epoch: 6| Step: 8
Training loss: 0.4457871099675873
Validation loss: 2.3411571996043055

Epoch: 6| Step: 9
Training loss: 0.6403688058071432
Validation loss: 2.3278488405023006

Epoch: 6| Step: 10
Training loss: 0.47260372405955986
Validation loss: 2.334519099188658

Epoch: 6| Step: 11
Training loss: 0.40827866361830245
Validation loss: 2.3485776391161046

Epoch: 6| Step: 12
Training loss: 0.5618376541031904
Validation loss: 2.3973682020474776

Epoch: 6| Step: 13
Training loss: 0.8968441642218754
Validation loss: 2.4055118667192485

Epoch: 167| Step: 0
Training loss: 0.7655256557239171
Validation loss: 2.33555477413431

Epoch: 6| Step: 1
Training loss: 0.6739901140631277
Validation loss: 2.410624618813766

Epoch: 6| Step: 2
Training loss: 0.47003384252715463
Validation loss: 2.349725235777515

Epoch: 6| Step: 3
Training loss: 0.6652403315458331
Validation loss: 2.349572168458877

Epoch: 6| Step: 4
Training loss: 0.5545359391019314
Validation loss: 2.354604415929679

Epoch: 6| Step: 5
Training loss: 0.49165071250063175
Validation loss: 2.3095199009539678

Epoch: 6| Step: 6
Training loss: 0.3962151877336919
Validation loss: 2.3626693227597295

Epoch: 6| Step: 7
Training loss: 0.4018654063074876
Validation loss: 2.382192428872677

Epoch: 6| Step: 8
Training loss: 0.29726078666128125
Validation loss: 2.4252434061074353

Epoch: 6| Step: 9
Training loss: 1.1882834109074132
Validation loss: 2.3593464359129093

Epoch: 6| Step: 10
Training loss: 0.688670808701493
Validation loss: 2.34495726963308

Epoch: 6| Step: 11
Training loss: 0.5285059237946661
Validation loss: 2.3859784715453443

Epoch: 6| Step: 12
Training loss: 0.6992552763706077
Validation loss: 2.3936041260470393

Epoch: 6| Step: 13
Training loss: 0.38608572426284876
Validation loss: 2.369414806093643

Epoch: 168| Step: 0
Training loss: 1.1983984213454488
Validation loss: 2.3684085764286786

Epoch: 6| Step: 1
Training loss: 0.5588056255873864
Validation loss: 2.3790607370910966

Epoch: 6| Step: 2
Training loss: 0.48958435126124406
Validation loss: 2.3216192331372714

Epoch: 6| Step: 3
Training loss: 0.5983060408542137
Validation loss: 2.313247954921189

Epoch: 6| Step: 4
Training loss: 0.5307972044255246
Validation loss: 2.3778325890698357

Epoch: 6| Step: 5
Training loss: 0.4673329869966044
Validation loss: 2.3274540286333503

Epoch: 6| Step: 6
Training loss: 0.6264482408257568
Validation loss: 2.338306276387374

Epoch: 6| Step: 7
Training loss: 0.9009535347645902
Validation loss: 2.3510702469192393

Epoch: 6| Step: 8
Training loss: 0.6286226426856171
Validation loss: 2.34286296589141

Epoch: 6| Step: 9
Training loss: 0.5131091091933963
Validation loss: 2.401254347996347

Epoch: 6| Step: 10
Training loss: 0.4763544285040338
Validation loss: 2.345661350357878

Epoch: 6| Step: 11
Training loss: 0.6866432834165359
Validation loss: 2.375230250992865

Epoch: 6| Step: 12
Training loss: 0.41333379141079735
Validation loss: 2.3234186243121266

Epoch: 6| Step: 13
Training loss: 0.48114172782668735
Validation loss: 2.3594581134632633

Epoch: 169| Step: 0
Training loss: 0.5463299896544442
Validation loss: 2.3129719604835492

Epoch: 6| Step: 1
Training loss: 0.44458828980824056
Validation loss: 2.3876051435236554

Epoch: 6| Step: 2
Training loss: 0.5282837014196429
Validation loss: 2.375106917869155

Epoch: 6| Step: 3
Training loss: 0.5119812852486453
Validation loss: 2.398934800472499

Epoch: 6| Step: 4
Training loss: 0.3332345699485559
Validation loss: 2.3990673352377843

Epoch: 6| Step: 5
Training loss: 0.42856369444419323
Validation loss: 2.3988164049491827

Epoch: 6| Step: 6
Training loss: 0.41325950132664185
Validation loss: 2.311267283656799

Epoch: 6| Step: 7
Training loss: 0.479819937450212
Validation loss: 2.3822768646389756

Epoch: 6| Step: 8
Training loss: 0.5531244418039037
Validation loss: 2.278333375852185

Epoch: 6| Step: 9
Training loss: 0.5015272122147548
Validation loss: 2.3110979314676885

Epoch: 6| Step: 10
Training loss: 0.47471564088322704
Validation loss: 2.3774681651286853

Epoch: 6| Step: 11
Training loss: 0.8492583503368765
Validation loss: 2.3610299560836308

Epoch: 6| Step: 12
Training loss: 1.2051948973033968
Validation loss: 2.307503285114654

Epoch: 6| Step: 13
Training loss: 0.46530915050953486
Validation loss: 2.320506232294592

Epoch: 170| Step: 0
Training loss: 0.4227386923044126
Validation loss: 2.37850835235949

Epoch: 6| Step: 1
Training loss: 0.42541918978314947
Validation loss: 2.3627482335974004

Epoch: 6| Step: 2
Training loss: 0.42750304424585084
Validation loss: 2.3483891752664

Epoch: 6| Step: 3
Training loss: 0.6137354438438539
Validation loss: 2.3474931792517966

Epoch: 6| Step: 4
Training loss: 0.46093003218468903
Validation loss: 2.3546731510919097

Epoch: 6| Step: 5
Training loss: 0.5283102715008744
Validation loss: 2.3340283505434862

Epoch: 6| Step: 6
Training loss: 0.6719033878450504
Validation loss: 2.3756003541244204

Epoch: 6| Step: 7
Training loss: 1.134023295545055
Validation loss: 2.2521285655666436

Epoch: 6| Step: 8
Training loss: 0.3706909804771703
Validation loss: 2.3443293724274294

Epoch: 6| Step: 9
Training loss: 0.5582212259655935
Validation loss: 2.3260258335976056

Epoch: 6| Step: 10
Training loss: 0.46188986716907215
Validation loss: 2.315700592921289

Epoch: 6| Step: 11
Training loss: 0.5069321263644241
Validation loss: 2.3540042185366117

Epoch: 6| Step: 12
Training loss: 0.6017886145563487
Validation loss: 2.379195406106064

Epoch: 6| Step: 13
Training loss: 0.4730975715316051
Validation loss: 2.336216887539946

Epoch: 171| Step: 0
Training loss: 0.45246951606454316
Validation loss: 2.3913466583939216

Epoch: 6| Step: 1
Training loss: 0.47853873060845586
Validation loss: 2.4027574632651985

Epoch: 6| Step: 2
Training loss: 0.5442585342940162
Validation loss: 2.3174564238960578

Epoch: 6| Step: 3
Training loss: 0.5272453216247501
Validation loss: 2.337596002603038

Epoch: 6| Step: 4
Training loss: 0.6738866808230433
Validation loss: 2.348041868778304

Epoch: 6| Step: 5
Training loss: 0.40248753469131676
Validation loss: 2.342251336650974

Epoch: 6| Step: 6
Training loss: 0.3626061596478218
Validation loss: 2.388269980664713

Epoch: 6| Step: 7
Training loss: 0.3041454041029841
Validation loss: 2.3649326072107337

Epoch: 6| Step: 8
Training loss: 0.4641314105365041
Validation loss: 2.345623174867056

Epoch: 6| Step: 9
Training loss: 0.44513171692418513
Validation loss: 2.3582962045566305

Epoch: 6| Step: 10
Training loss: 0.415699583546437
Validation loss: 2.3850559533817908

Epoch: 6| Step: 11
Training loss: 0.536738735976269
Validation loss: 2.3722383019033635

Epoch: 6| Step: 12
Training loss: 1.1198225623311744
Validation loss: 2.3461841912610186

Epoch: 6| Step: 13
Training loss: 0.7935790921739203
Validation loss: 2.406923406261617

Epoch: 172| Step: 0
Training loss: 0.5585176642825299
Validation loss: 2.3573436118311064

Epoch: 6| Step: 1
Training loss: 0.36880675865039614
Validation loss: 2.327462897996921

Epoch: 6| Step: 2
Training loss: 0.48326518986999445
Validation loss: 2.347761933565674

Epoch: 6| Step: 3
Training loss: 0.33739022041324457
Validation loss: 2.38151501626804

Epoch: 6| Step: 4
Training loss: 0.4816355145779624
Validation loss: 2.4025900613693385

Epoch: 6| Step: 5
Training loss: 0.6233390912089227
Validation loss: 2.320958947618101

Epoch: 6| Step: 6
Training loss: 1.359666551916503
Validation loss: 2.4320028543371883

Epoch: 6| Step: 7
Training loss: 0.5468903403174208
Validation loss: 2.4012843496899734

Epoch: 6| Step: 8
Training loss: 0.338205003845537
Validation loss: 2.327795188806323

Epoch: 6| Step: 9
Training loss: 0.3962439949952475
Validation loss: 2.3901414901690967

Epoch: 6| Step: 10
Training loss: 0.47900655047729956
Validation loss: 2.3424259430026257

Epoch: 6| Step: 11
Training loss: 0.5072891472891639
Validation loss: 2.325607389325131

Epoch: 6| Step: 12
Training loss: 0.4817320954153595
Validation loss: 2.390416420873459

Epoch: 6| Step: 13
Training loss: 0.6168673687030939
Validation loss: 2.3955175827496857

Epoch: 173| Step: 0
Training loss: 0.43896677867560546
Validation loss: 2.2838600416698744

Epoch: 6| Step: 1
Training loss: 0.41696735102640314
Validation loss: 2.314300695193657

Epoch: 6| Step: 2
Training loss: 0.5131051886540597
Validation loss: 2.3397788249472273

Epoch: 6| Step: 3
Training loss: 0.5449022952701577
Validation loss: 2.338002307660106

Epoch: 6| Step: 4
Training loss: 0.7072907282542622
Validation loss: 2.3298622920309207

Epoch: 6| Step: 5
Training loss: 0.49865981139840315
Validation loss: 2.3573697560302924

Epoch: 6| Step: 6
Training loss: 0.5087393298893006
Validation loss: 2.3669750928268045

Epoch: 6| Step: 7
Training loss: 0.41709091125651776
Validation loss: 2.2640335807769865

Epoch: 6| Step: 8
Training loss: 0.587897240484282
Validation loss: 2.3768132214839395

Epoch: 6| Step: 9
Training loss: 0.44790442213429255
Validation loss: 2.338499860382783

Epoch: 6| Step: 10
Training loss: 0.5670065493970714
Validation loss: 2.3111300319677577

Epoch: 6| Step: 11
Training loss: 0.684768648026665
Validation loss: 2.3712377698251452

Epoch: 6| Step: 12
Training loss: 1.1886114641045273
Validation loss: 2.402847030562859

Epoch: 6| Step: 13
Training loss: 0.6345026498533307
Validation loss: 2.3546722229358847

Epoch: 174| Step: 0
Training loss: 0.3879859661164764
Validation loss: 2.3053349334478845

Epoch: 6| Step: 1
Training loss: 1.3283714514559597
Validation loss: 2.3187429254908913

Epoch: 6| Step: 2
Training loss: 0.5386895257770331
Validation loss: 2.3290444506368044

Epoch: 6| Step: 3
Training loss: 0.43479430180354117
Validation loss: 2.3644214748379886

Epoch: 6| Step: 4
Training loss: 0.4896093236504104
Validation loss: 2.3349030584705304

Epoch: 6| Step: 5
Training loss: 0.5748264703955696
Validation loss: 2.316249102300479

Epoch: 6| Step: 6
Training loss: 0.4141560214968939
Validation loss: 2.315170413007399

Epoch: 6| Step: 7
Training loss: 0.6628222383595782
Validation loss: 2.323185624316911

Epoch: 6| Step: 8
Training loss: 0.5847459757936723
Validation loss: 2.4203905047461016

Epoch: 6| Step: 9
Training loss: 0.6737024162347676
Validation loss: 2.3869308319181113

Epoch: 6| Step: 10
Training loss: 0.6758154711575551
Validation loss: 2.30493964416194

Epoch: 6| Step: 11
Training loss: 0.670205615042772
Validation loss: 2.3704060076092093

Epoch: 6| Step: 12
Training loss: 0.37161741952898697
Validation loss: 2.3422203582501497

Epoch: 6| Step: 13
Training loss: 0.658682945429005
Validation loss: 2.3767661003064218

Epoch: 175| Step: 0
Training loss: 0.7381319167469581
Validation loss: 2.385331228689044

Epoch: 6| Step: 1
Training loss: 0.6940169748613106
Validation loss: 2.409871270526083

Epoch: 6| Step: 2
Training loss: 1.087220949786137
Validation loss: 2.303504200415883

Epoch: 6| Step: 3
Training loss: 0.5211001634560554
Validation loss: 2.304673672219729

Epoch: 6| Step: 4
Training loss: 0.5626906760546766
Validation loss: 2.3454428768494973

Epoch: 6| Step: 5
Training loss: 0.5781945882619853
Validation loss: 2.404508282363788

Epoch: 6| Step: 6
Training loss: 0.8209457133346599
Validation loss: 2.3382905741738393

Epoch: 6| Step: 7
Training loss: 0.7969375660587906
Validation loss: 2.356137511302761

Epoch: 6| Step: 8
Training loss: 0.3779626087763727
Validation loss: 2.344587091791252

Epoch: 6| Step: 9
Training loss: 0.5668399071477198
Validation loss: 2.3140003045734985

Epoch: 6| Step: 10
Training loss: 0.4044831809565854
Validation loss: 2.359017856674237

Epoch: 6| Step: 11
Training loss: 0.578881825126161
Validation loss: 2.2847742266728654

Epoch: 6| Step: 12
Training loss: 0.525359510897282
Validation loss: 2.336820046573756

Epoch: 6| Step: 13
Training loss: 0.5820120993926299
Validation loss: 2.3182866492965624

Epoch: 176| Step: 0
Training loss: 0.38790207737422705
Validation loss: 2.3587847680846665

Epoch: 6| Step: 1
Training loss: 0.6026837192295366
Validation loss: 2.341987124900382

Epoch: 6| Step: 2
Training loss: 0.3794755493223418
Validation loss: 2.3799919319416785

Epoch: 6| Step: 3
Training loss: 0.541699249559164
Validation loss: 2.4202248971385467

Epoch: 6| Step: 4
Training loss: 0.48187181256498024
Validation loss: 2.4148731208100354

Epoch: 6| Step: 5
Training loss: 0.5207050801359933
Validation loss: 2.3655564802586175

Epoch: 6| Step: 6
Training loss: 0.4832948515908469
Validation loss: 2.316692383941322

Epoch: 6| Step: 7
Training loss: 0.437199404174725
Validation loss: 2.3713742403962157

Epoch: 6| Step: 8
Training loss: 0.8234315339945424
Validation loss: 2.420146234891285

Epoch: 6| Step: 9
Training loss: 0.3949111393677695
Validation loss: 2.3424227198796546

Epoch: 6| Step: 10
Training loss: 0.4296055455513207
Validation loss: 2.3884203017542

Epoch: 6| Step: 11
Training loss: 1.2218118987899815
Validation loss: 2.4120476965798523

Epoch: 6| Step: 12
Training loss: 0.5092460937275274
Validation loss: 2.329501331923672

Epoch: 6| Step: 13
Training loss: 0.6174660066367696
Validation loss: 2.417528209909601

Epoch: 177| Step: 0
Training loss: 0.5464304343182022
Validation loss: 2.3236898723427286

Epoch: 6| Step: 1
Training loss: 0.5363282227984935
Validation loss: 2.3339925215191903

Epoch: 6| Step: 2
Training loss: 0.5999968329981827
Validation loss: 2.2971261853776888

Epoch: 6| Step: 3
Training loss: 0.6291307084332205
Validation loss: 2.3432688070758245

Epoch: 6| Step: 4
Training loss: 0.35566550877217873
Validation loss: 2.3438507567047013

Epoch: 6| Step: 5
Training loss: 0.5357818288457886
Validation loss: 2.359999702394327

Epoch: 6| Step: 6
Training loss: 0.4277449654439506
Validation loss: 2.371238205524633

Epoch: 6| Step: 7
Training loss: 0.5870293172439466
Validation loss: 2.324499802466122

Epoch: 6| Step: 8
Training loss: 0.6685953157446265
Validation loss: 2.3519754311268795

Epoch: 6| Step: 9
Training loss: 0.6329270247448309
Validation loss: 2.3678031934830743

Epoch: 6| Step: 10
Training loss: 1.2012607944729947
Validation loss: 2.367085218580458

Epoch: 6| Step: 11
Training loss: 0.4471521525138276
Validation loss: 2.4054978008277392

Epoch: 6| Step: 12
Training loss: 0.48922796405800967
Validation loss: 2.3528839994360204

Epoch: 6| Step: 13
Training loss: 0.5430896542091395
Validation loss: 2.3661577190145713

Epoch: 178| Step: 0
Training loss: 0.47456965653112526
Validation loss: 2.317981726705778

Epoch: 6| Step: 1
Training loss: 0.6795586650245142
Validation loss: 2.3491520826417704

Epoch: 6| Step: 2
Training loss: 0.6881029779304071
Validation loss: 2.3099989210404246

Epoch: 6| Step: 3
Training loss: 0.5926919343777047
Validation loss: 2.33049748865819

Epoch: 6| Step: 4
Training loss: 0.6314434737023277
Validation loss: 2.2802678785453745

Epoch: 6| Step: 5
Training loss: 0.6377465313705332
Validation loss: 2.3756777147778667

Epoch: 6| Step: 6
Training loss: 0.5325570016896554
Validation loss: 2.361299685508623

Epoch: 6| Step: 7
Training loss: 0.42796469283644234
Validation loss: 2.3717784699443234

Epoch: 6| Step: 8
Training loss: 0.441400122810981
Validation loss: 2.2892758353575418

Epoch: 6| Step: 9
Training loss: 1.1159375540958456
Validation loss: 2.3211190377142623

Epoch: 6| Step: 10
Training loss: 0.5791463336074019
Validation loss: 2.3429904639516344

Epoch: 6| Step: 11
Training loss: 0.5139429515747573
Validation loss: 2.3487442550602458

Epoch: 6| Step: 12
Training loss: 0.37093920250158874
Validation loss: 2.272741099662335

Epoch: 6| Step: 13
Training loss: 0.5868029243239701
Validation loss: 2.330102545756003

Epoch: 179| Step: 0
Training loss: 0.4281826718322242
Validation loss: 2.3564536511742267

Epoch: 6| Step: 1
Training loss: 0.45412814154825887
Validation loss: 2.299219228381739

Epoch: 6| Step: 2
Training loss: 0.5809257556616677
Validation loss: 2.327572067789434

Epoch: 6| Step: 3
Training loss: 0.5174656583844665
Validation loss: 2.3501763974262375

Epoch: 6| Step: 4
Training loss: 0.31880360601358915
Validation loss: 2.2836504286767507

Epoch: 6| Step: 5
Training loss: 0.48442246604430333
Validation loss: 2.2900023803809617

Epoch: 6| Step: 6
Training loss: 1.066374222829936
Validation loss: 2.349862465317102

Epoch: 6| Step: 7
Training loss: 0.39191490821895414
Validation loss: 2.26858141704505

Epoch: 6| Step: 8
Training loss: 0.6636407747217089
Validation loss: 2.326994021713081

Epoch: 6| Step: 9
Training loss: 0.6915493833157265
Validation loss: 2.335603466838074

Epoch: 6| Step: 10
Training loss: 0.46448855894553137
Validation loss: 2.385941024407942

Epoch: 6| Step: 11
Training loss: 0.35537764670841926
Validation loss: 2.3387010402505806

Epoch: 6| Step: 12
Training loss: 0.46994749333922303
Validation loss: 2.372392712342226

Epoch: 6| Step: 13
Training loss: 0.3550697854450738
Validation loss: 2.346632850233535

Epoch: 180| Step: 0
Training loss: 0.39990770944202486
Validation loss: 2.321724219237568

Epoch: 6| Step: 1
Training loss: 0.47824986142656517
Validation loss: 2.326784981430993

Epoch: 6| Step: 2
Training loss: 0.47892825961293317
Validation loss: 2.296582798093184

Epoch: 6| Step: 3
Training loss: 0.37196044100621534
Validation loss: 2.358706415363677

Epoch: 6| Step: 4
Training loss: 0.6586610463288065
Validation loss: 2.3259115940960906

Epoch: 6| Step: 5
Training loss: 0.2583886125214813
Validation loss: 2.2911034383202353

Epoch: 6| Step: 6
Training loss: 0.48159205925864795
Validation loss: 2.382926279488727

Epoch: 6| Step: 7
Training loss: 0.4147718579198864
Validation loss: 2.3254185334046453

Epoch: 6| Step: 8
Training loss: 0.42645773387072305
Validation loss: 2.407360431696454

Epoch: 6| Step: 9
Training loss: 1.130628440349821
Validation loss: 2.3598958886749277

Epoch: 6| Step: 10
Training loss: 0.458426473286016
Validation loss: 2.424877528738996

Epoch: 6| Step: 11
Training loss: 0.6615432975047205
Validation loss: 2.382011912780256

Epoch: 6| Step: 12
Training loss: 0.5383042240638266
Validation loss: 2.381072796546809

Epoch: 6| Step: 13
Training loss: 0.36689992560045137
Validation loss: 2.3275398611417497

Epoch: 181| Step: 0
Training loss: 0.6547819019438729
Validation loss: 2.3069435413850563

Epoch: 6| Step: 1
Training loss: 0.28063715286107677
Validation loss: 2.353259482895476

Epoch: 6| Step: 2
Training loss: 0.5632902528252353
Validation loss: 2.3520620835602695

Epoch: 6| Step: 3
Training loss: 0.40449209613881904
Validation loss: 2.352409936705845

Epoch: 6| Step: 4
Training loss: 0.3974163208459581
Validation loss: 2.3246603922821705

Epoch: 6| Step: 5
Training loss: 0.33849341586638887
Validation loss: 2.371225955635447

Epoch: 6| Step: 6
Training loss: 0.46327627993100096
Validation loss: 2.3069382189440133

Epoch: 6| Step: 7
Training loss: 1.1130424377220152
Validation loss: 2.283740152074345

Epoch: 6| Step: 8
Training loss: 0.4918493592826887
Validation loss: 2.4060679940752383

Epoch: 6| Step: 9
Training loss: 0.541611188712898
Validation loss: 2.374606350851165

Epoch: 6| Step: 10
Training loss: 0.3578250049921282
Validation loss: 2.324884296942784

Epoch: 6| Step: 11
Training loss: 0.3780532950202845
Validation loss: 2.321046210159207

Epoch: 6| Step: 12
Training loss: 0.379383455210548
Validation loss: 2.2936632013485547

Epoch: 6| Step: 13
Training loss: 0.5550597110622816
Validation loss: 2.358953333009966

Epoch: 182| Step: 0
Training loss: 0.39238542600514215
Validation loss: 2.299719677303572

Epoch: 6| Step: 1
Training loss: 0.4904779080073389
Validation loss: 2.3641022740405324

Epoch: 6| Step: 2
Training loss: 0.3021572641909381
Validation loss: 2.3350547049497212

Epoch: 6| Step: 3
Training loss: 0.418363883513334
Validation loss: 2.2898459455431213

Epoch: 6| Step: 4
Training loss: 0.5154822180758564
Validation loss: 2.2944131403653603

Epoch: 6| Step: 5
Training loss: 1.1733165775171934
Validation loss: 2.2908178462530375

Epoch: 6| Step: 6
Training loss: 0.645265473137029
Validation loss: 2.2866876584202593

Epoch: 6| Step: 7
Training loss: 0.34275115720496513
Validation loss: 2.3465365904507434

Epoch: 6| Step: 8
Training loss: 0.5711287314246536
Validation loss: 2.3478259693309274

Epoch: 6| Step: 9
Training loss: 0.6979895288001691
Validation loss: 2.3552693862009217

Epoch: 6| Step: 10
Training loss: 0.33816693424936844
Validation loss: 2.31175842079226

Epoch: 6| Step: 11
Training loss: 0.4061544012415201
Validation loss: 2.3170016522259638

Epoch: 6| Step: 12
Training loss: 0.5941669104666119
Validation loss: 2.3551614623120805

Epoch: 6| Step: 13
Training loss: 0.49567383543618365
Validation loss: 2.3132439696762663

Epoch: 183| Step: 0
Training loss: 0.3268290654651416
Validation loss: 2.362309817912689

Epoch: 6| Step: 1
Training loss: 0.3062881947074422
Validation loss: 2.361100952899498

Epoch: 6| Step: 2
Training loss: 0.49927135363505987
Validation loss: 2.4071257347671966

Epoch: 6| Step: 3
Training loss: 0.5694321932159665
Validation loss: 2.3988646252233385

Epoch: 6| Step: 4
Training loss: 0.5142335323131991
Validation loss: 2.319547233727764

Epoch: 6| Step: 5
Training loss: 1.1980142912959566
Validation loss: 2.3402173779394135

Epoch: 6| Step: 6
Training loss: 0.5113359140337626
Validation loss: 2.2768996227132683

Epoch: 6| Step: 7
Training loss: 0.38559878617254906
Validation loss: 2.3659670026138317

Epoch: 6| Step: 8
Training loss: 0.45355797503367956
Validation loss: 2.326675646617943

Epoch: 6| Step: 9
Training loss: 0.44310628918743195
Validation loss: 2.365875434469531

Epoch: 6| Step: 10
Training loss: 0.5142364880015746
Validation loss: 2.2976969245251317

Epoch: 6| Step: 11
Training loss: 0.33272139685839064
Validation loss: 2.37737307865247

Epoch: 6| Step: 12
Training loss: 0.7545244123631314
Validation loss: 2.3090472693007027

Epoch: 6| Step: 13
Training loss: 0.4090475629289781
Validation loss: 2.331336833369626

Epoch: 184| Step: 0
Training loss: 0.6738085757750675
Validation loss: 2.3891467674800695

Epoch: 6| Step: 1
Training loss: 0.5327728827282235
Validation loss: 2.325209411296373

Epoch: 6| Step: 2
Training loss: 0.3668177345852641
Validation loss: 2.3630377273566645

Epoch: 6| Step: 3
Training loss: 0.4060907968939934
Validation loss: 2.3631140195249594

Epoch: 6| Step: 4
Training loss: 1.0658907360419805
Validation loss: 2.289866214131385

Epoch: 6| Step: 5
Training loss: 0.4145539264537176
Validation loss: 2.310004537462344

Epoch: 6| Step: 6
Training loss: 0.3271972847525667
Validation loss: 2.307774363387538

Epoch: 6| Step: 7
Training loss: 0.5735220802566372
Validation loss: 2.3528074599936732

Epoch: 6| Step: 8
Training loss: 0.6817836666040744
Validation loss: 2.3704830851787855

Epoch: 6| Step: 9
Training loss: 0.4854941206712599
Validation loss: 2.27792092845242

Epoch: 6| Step: 10
Training loss: 0.7282357995206784
Validation loss: 2.4319132987753105

Epoch: 6| Step: 11
Training loss: 0.55844007392209
Validation loss: 2.353808145032798

Epoch: 6| Step: 12
Training loss: 0.5610367498549494
Validation loss: 2.323779263872163

Epoch: 6| Step: 13
Training loss: 0.45778300740414224
Validation loss: 2.3542263873016847

Epoch: 185| Step: 0
Training loss: 0.649072405207378
Validation loss: 2.373175840706432

Epoch: 6| Step: 1
Training loss: 1.0919592775814395
Validation loss: 2.330614026740203

Epoch: 6| Step: 2
Training loss: 0.6498807449248315
Validation loss: 2.3668744978741763

Epoch: 6| Step: 3
Training loss: 0.48711686728924697
Validation loss: 2.3417331749463792

Epoch: 6| Step: 4
Training loss: 0.4173477050982309
Validation loss: 2.312309635334385

Epoch: 6| Step: 5
Training loss: 0.6010850274782128
Validation loss: 2.3331550007746094

Epoch: 6| Step: 6
Training loss: 0.2873878426090216
Validation loss: 2.349683566466642

Epoch: 6| Step: 7
Training loss: 0.4643038330891857
Validation loss: 2.305362167316339

Epoch: 6| Step: 8
Training loss: 0.5435229704441257
Validation loss: 2.2825231352626276

Epoch: 6| Step: 9
Training loss: 0.5046605519283761
Validation loss: 2.320929602561654

Epoch: 6| Step: 10
Training loss: 0.33473370242953837
Validation loss: 2.385427039066957

Epoch: 6| Step: 11
Training loss: 0.5027724825888753
Validation loss: 2.274607843268275

Epoch: 6| Step: 12
Training loss: 0.4958698939086258
Validation loss: 2.2762882497731027

Epoch: 6| Step: 13
Training loss: 0.4475752912083077
Validation loss: 2.3533714999525124

Epoch: 186| Step: 0
Training loss: 1.0631722399281525
Validation loss: 2.348813880713541

Epoch: 6| Step: 1
Training loss: 0.5838268156788612
Validation loss: 2.290636330958605

Epoch: 6| Step: 2
Training loss: 0.4392216560270347
Validation loss: 2.336678760509058

Epoch: 6| Step: 3
Training loss: 0.6545768480406595
Validation loss: 2.362500291316369

Epoch: 6| Step: 4
Training loss: 0.5425907713018429
Validation loss: 2.3674130306094003

Epoch: 6| Step: 5
Training loss: 0.40007231550388117
Validation loss: 2.3299906976183964

Epoch: 6| Step: 6
Training loss: 0.4085342487898325
Validation loss: 2.3635444599626583

Epoch: 6| Step: 7
Training loss: 0.5008442129465145
Validation loss: 2.3446189625836493

Epoch: 6| Step: 8
Training loss: 0.428886117097867
Validation loss: 2.32711094014849

Epoch: 6| Step: 9
Training loss: 0.4574843711737071
Validation loss: 2.371128356446429

Epoch: 6| Step: 10
Training loss: 0.4628647100864015
Validation loss: 2.3267118017943282

Epoch: 6| Step: 11
Training loss: 0.4191116856292765
Validation loss: 2.3827186274147008

Epoch: 6| Step: 12
Training loss: 0.4511622968705643
Validation loss: 2.308744560087962

Epoch: 6| Step: 13
Training loss: 0.7084175976017661
Validation loss: 2.3038278474313523

Epoch: 187| Step: 0
Training loss: 0.3944658281831102
Validation loss: 2.3392406486668675

Epoch: 6| Step: 1
Training loss: 0.66803513581846
Validation loss: 2.297345266835699

Epoch: 6| Step: 2
Training loss: 0.3274977114830429
Validation loss: 2.261486913452699

Epoch: 6| Step: 3
Training loss: 0.40600749260349683
Validation loss: 2.3573754197257553

Epoch: 6| Step: 4
Training loss: 0.4362282661773503
Validation loss: 2.302014774204948

Epoch: 6| Step: 5
Training loss: 0.38527026703763917
Validation loss: 2.3261579528614043

Epoch: 6| Step: 6
Training loss: 1.046544777329138
Validation loss: 2.37310839496088

Epoch: 6| Step: 7
Training loss: 0.2396565909269472
Validation loss: 2.314942487657283

Epoch: 6| Step: 8
Training loss: 0.29708541139533057
Validation loss: 2.3672115127470237

Epoch: 6| Step: 9
Training loss: 0.6415883705954506
Validation loss: 2.294721004271447

Epoch: 6| Step: 10
Training loss: 0.4191059791487951
Validation loss: 2.2965035949203823

Epoch: 6| Step: 11
Training loss: 0.5654728005004077
Validation loss: 2.276447239639269

Epoch: 6| Step: 12
Training loss: 0.4879464489387505
Validation loss: 2.3104470737429637

Epoch: 6| Step: 13
Training loss: 0.3455684205457224
Validation loss: 2.3155781647222526

Epoch: 188| Step: 0
Training loss: 0.44059325773467456
Validation loss: 2.3712625124019224

Epoch: 6| Step: 1
Training loss: 0.39832504405823066
Validation loss: 2.4000184588252282

Epoch: 6| Step: 2
Training loss: 0.2495950757439584
Validation loss: 2.307767415709362

Epoch: 6| Step: 3
Training loss: 0.6050973799260282
Validation loss: 2.2883592117589258

Epoch: 6| Step: 4
Training loss: 0.3959277713787755
Validation loss: 2.3085525259434925

Epoch: 6| Step: 5
Training loss: 0.4303714510693505
Validation loss: 2.3177249322075397

Epoch: 6| Step: 6
Training loss: 0.44516919155730655
Validation loss: 2.339215635333664

Epoch: 6| Step: 7
Training loss: 0.46719522118965817
Validation loss: 2.2771186433819155

Epoch: 6| Step: 8
Training loss: 0.4286946530388387
Validation loss: 2.273740689225556

Epoch: 6| Step: 9
Training loss: 0.482633567417853
Validation loss: 2.3244333205565746

Epoch: 6| Step: 10
Training loss: 1.0592865313383597
Validation loss: 2.387255111504567

Epoch: 6| Step: 11
Training loss: 0.5146778539831856
Validation loss: 2.3614884735683344

Epoch: 6| Step: 12
Training loss: 0.2972938945226101
Validation loss: 2.2893415070532064

Epoch: 6| Step: 13
Training loss: 0.34723150903150474
Validation loss: 2.330461051195868

Epoch: 189| Step: 0
Training loss: 0.3809241606557198
Validation loss: 2.3847443467465865

Epoch: 6| Step: 1
Training loss: 0.4333007784988097
Validation loss: 2.339638184617495

Epoch: 6| Step: 2
Training loss: 0.3095587839573217
Validation loss: 2.349714835430245

Epoch: 6| Step: 3
Training loss: 0.35945284041899417
Validation loss: 2.372042428977373

Epoch: 6| Step: 4
Training loss: 0.43385212734822354
Validation loss: 2.3552187253938435

Epoch: 6| Step: 5
Training loss: 1.280385214016578
Validation loss: 2.328152837736211

Epoch: 6| Step: 6
Training loss: 0.4427783200163468
Validation loss: 2.356374285023108

Epoch: 6| Step: 7
Training loss: 0.4082674587240256
Validation loss: 2.298228498681605

Epoch: 6| Step: 8
Training loss: 0.35538921933704326
Validation loss: 2.3831727052681413

Epoch: 6| Step: 9
Training loss: 0.5707165841167663
Validation loss: 2.342289516202903

Epoch: 6| Step: 10
Training loss: 0.4481442080521722
Validation loss: 2.3591840216203686

Epoch: 6| Step: 11
Training loss: 0.3004942056879546
Validation loss: 2.329238369360654

Epoch: 6| Step: 12
Training loss: 0.40303149284739404
Validation loss: 2.3838086406774237

Epoch: 6| Step: 13
Training loss: 0.35181174449937797
Validation loss: 2.3851510334509705

Epoch: 190| Step: 0
Training loss: 0.4452781998658845
Validation loss: 2.387377159593439

Epoch: 6| Step: 1
Training loss: 0.3143520074175628
Validation loss: 2.350758986633361

Epoch: 6| Step: 2
Training loss: 0.39871879072837163
Validation loss: 2.2949540459292073

Epoch: 6| Step: 3
Training loss: 0.6702808497143717
Validation loss: 2.3061118686733697

Epoch: 6| Step: 4
Training loss: 0.4845473690359495
Validation loss: 2.2890479876130905

Epoch: 6| Step: 5
Training loss: 0.5340314586227592
Validation loss: 2.303698828755534

Epoch: 6| Step: 6
Training loss: 1.059231048976264
Validation loss: 2.2712277207010536

Epoch: 6| Step: 7
Training loss: 0.36582539927076885
Validation loss: 2.3030733393444134

Epoch: 6| Step: 8
Training loss: 0.3933708765039857
Validation loss: 2.290171999892251

Epoch: 6| Step: 9
Training loss: 0.3548866788226287
Validation loss: 2.325218605374502

Epoch: 6| Step: 10
Training loss: 0.7382657892132166
Validation loss: 2.2717527196579685

Epoch: 6| Step: 11
Training loss: 0.3037234607334744
Validation loss: 2.3375675803630322

Epoch: 6| Step: 12
Training loss: 0.29028648843021065
Validation loss: 2.3032822112313966

Epoch: 6| Step: 13
Training loss: 0.4198584042864037
Validation loss: 2.2996924975676505

Epoch: 191| Step: 0
Training loss: 0.4040349950670682
Validation loss: 2.3414660027301966

Epoch: 6| Step: 1
Training loss: 0.30710246301294947
Validation loss: 2.349244886176176

Epoch: 6| Step: 2
Training loss: 1.0735097313889803
Validation loss: 2.3173574603516274

Epoch: 6| Step: 3
Training loss: 0.3352136464979127
Validation loss: 2.4126273192441707

Epoch: 6| Step: 4
Training loss: 0.3257850363166021
Validation loss: 2.4536483190258447

Epoch: 6| Step: 5
Training loss: 0.3866509272123373
Validation loss: 2.3212436301931954

Epoch: 6| Step: 6
Training loss: 0.4581046418926817
Validation loss: 2.358275454140056

Epoch: 6| Step: 7
Training loss: 0.4442483668965477
Validation loss: 2.323458849208755

Epoch: 6| Step: 8
Training loss: 0.48594083263566884
Validation loss: 2.4120073181060304

Epoch: 6| Step: 9
Training loss: 0.4124228564288831
Validation loss: 2.3571770305688466

Epoch: 6| Step: 10
Training loss: 0.49592354625645174
Validation loss: 2.3529432853930037

Epoch: 6| Step: 11
Training loss: 0.657446882437549
Validation loss: 2.3487090819433534

Epoch: 6| Step: 12
Training loss: 0.33547198400195666
Validation loss: 2.2876216967231096

Epoch: 6| Step: 13
Training loss: 0.4528703631806754
Validation loss: 2.362702824869527

Epoch: 192| Step: 0
Training loss: 0.40012095604413844
Validation loss: 2.348698135704749

Epoch: 6| Step: 1
Training loss: 0.622622378204591
Validation loss: 2.3896876805965848

Epoch: 6| Step: 2
Training loss: 0.440479453377317
Validation loss: 2.3554802552169436

Epoch: 6| Step: 3
Training loss: 0.34731708012379353
Validation loss: 2.378967184153924

Epoch: 6| Step: 4
Training loss: 0.2919837924936971
Validation loss: 2.3170926479990865

Epoch: 6| Step: 5
Training loss: 0.4082032345128255
Validation loss: 2.3153772239581705

Epoch: 6| Step: 6
Training loss: 1.029930831568138
Validation loss: 2.4075830903574436

Epoch: 6| Step: 7
Training loss: 0.6608047009246603
Validation loss: 2.3323571058948787

Epoch: 6| Step: 8
Training loss: 0.38190771730685946
Validation loss: 2.321278303648618

Epoch: 6| Step: 9
Training loss: 0.275956242617114
Validation loss: 2.2989070665951825

Epoch: 6| Step: 10
Training loss: 0.3501740589064382
Validation loss: 2.3234513755029997

Epoch: 6| Step: 11
Training loss: 0.44084050204548286
Validation loss: 2.3451531003848314

Epoch: 6| Step: 12
Training loss: 0.2451378103144845
Validation loss: 2.3107592758360673

Epoch: 6| Step: 13
Training loss: 0.4063261951003903
Validation loss: 2.3957830893735195

Epoch: 193| Step: 0
Training loss: 0.3150708546120086
Validation loss: 2.3080250168055536

Epoch: 6| Step: 1
Training loss: 0.34025359378671377
Validation loss: 2.304949462140758

Epoch: 6| Step: 2
Training loss: 0.32363285992471813
Validation loss: 2.248917001117978

Epoch: 6| Step: 3
Training loss: 0.4766925884358862
Validation loss: 2.313029323173758

Epoch: 6| Step: 4
Training loss: 0.3902021026249658
Validation loss: 2.3143080439210757

Epoch: 6| Step: 5
Training loss: 0.3609673838608968
Validation loss: 2.3096562848747153

Epoch: 6| Step: 6
Training loss: 0.5023334709765105
Validation loss: 2.300721241676299

Epoch: 6| Step: 7
Training loss: 0.521306125308737
Validation loss: 2.296302161720549

Epoch: 6| Step: 8
Training loss: 0.6304418404472197
Validation loss: 2.3018631002681498

Epoch: 6| Step: 9
Training loss: 0.41705839895561336
Validation loss: 2.339683446556681

Epoch: 6| Step: 10
Training loss: 0.37700075629333
Validation loss: 2.304917835859198

Epoch: 6| Step: 11
Training loss: 0.4789608499539124
Validation loss: 2.3055594825966517

Epoch: 6| Step: 12
Training loss: 0.4445505483289921
Validation loss: 2.3446076413414136

Epoch: 6| Step: 13
Training loss: 1.0450733681070254
Validation loss: 2.3269428435025854

Epoch: 194| Step: 0
Training loss: 0.44080615817405217
Validation loss: 2.259486228136104

Epoch: 6| Step: 1
Training loss: 0.46164098494614625
Validation loss: 2.359255301363358

Epoch: 6| Step: 2
Training loss: 0.1879635484947657
Validation loss: 2.3180334113238956

Epoch: 6| Step: 3
Training loss: 0.42542195690775053
Validation loss: 2.2976698073326896

Epoch: 6| Step: 4
Training loss: 0.43682895013855644
Validation loss: 2.291145739447322

Epoch: 6| Step: 5
Training loss: 0.381590137246221
Validation loss: 2.3393919460271593

Epoch: 6| Step: 6
Training loss: 0.49083080713154165
Validation loss: 2.3262140338022976

Epoch: 6| Step: 7
Training loss: 0.6978467555164783
Validation loss: 2.321686326204063

Epoch: 6| Step: 8
Training loss: 0.34536099071855647
Validation loss: 2.3154320557967116

Epoch: 6| Step: 9
Training loss: 0.39976869988614777
Validation loss: 2.352688356156691

Epoch: 6| Step: 10
Training loss: 1.0467229704281356
Validation loss: 2.3232261098075813

Epoch: 6| Step: 11
Training loss: 0.3569292102132289
Validation loss: 2.314855252513187

Epoch: 6| Step: 12
Training loss: 0.4248621759210463
Validation loss: 2.3676289397552086

Epoch: 6| Step: 13
Training loss: 0.34727232876154596
Validation loss: 2.303186908719743

Epoch: 195| Step: 0
Training loss: 0.4364811409549994
Validation loss: 2.274023043984057

Epoch: 6| Step: 1
Training loss: 0.4950613859434034
Validation loss: 2.3269707209957238

Epoch: 6| Step: 2
Training loss: 0.6644984441212278
Validation loss: 2.2889707718351477

Epoch: 6| Step: 3
Training loss: 0.3697056356836291
Validation loss: 2.313020699104546

Epoch: 6| Step: 4
Training loss: 0.311552829611486
Validation loss: 2.287384650791127

Epoch: 6| Step: 5
Training loss: 0.3326892167756014
Validation loss: 2.294027990391589

Epoch: 6| Step: 6
Training loss: 1.1472273178900811
Validation loss: 2.3491260838011243

Epoch: 6| Step: 7
Training loss: 0.465982420922313
Validation loss: 2.2824486061457674

Epoch: 6| Step: 8
Training loss: 0.4840662495201295
Validation loss: 2.3708415685509543

Epoch: 6| Step: 9
Training loss: 0.4719867851783518
Validation loss: 2.339194299471015

Epoch: 6| Step: 10
Training loss: 0.49156573547346133
Validation loss: 2.3045871001535643

Epoch: 6| Step: 11
Training loss: 0.4583815003863386
Validation loss: 2.277385992636601

Epoch: 6| Step: 12
Training loss: 0.5885686164919728
Validation loss: 2.3137865525760044

Epoch: 6| Step: 13
Training loss: 0.3624976125178147
Validation loss: 2.3159922443714636

Epoch: 196| Step: 0
Training loss: 0.29614109375433073
Validation loss: 2.382799192297624

Epoch: 6| Step: 1
Training loss: 0.31537911213368525
Validation loss: 2.3107798768702197

Epoch: 6| Step: 2
Training loss: 0.43881988677933415
Validation loss: 2.31086716268681

Epoch: 6| Step: 3
Training loss: 0.6375642089671264
Validation loss: 2.2428380574012237

Epoch: 6| Step: 4
Training loss: 1.0266637255783395
Validation loss: 2.332845565926077

Epoch: 6| Step: 5
Training loss: 0.27239502687255823
Validation loss: 2.3669538225215163

Epoch: 6| Step: 6
Training loss: 0.4831681753115059
Validation loss: 2.270662438381236

Epoch: 6| Step: 7
Training loss: 0.4592583994899385
Validation loss: 2.2763011764060797

Epoch: 6| Step: 8
Training loss: 0.6588321928398335
Validation loss: 2.315685852802475

Epoch: 6| Step: 9
Training loss: 0.5333535677329824
Validation loss: 2.359617966021597

Epoch: 6| Step: 10
Training loss: 0.4447125190993697
Validation loss: 2.3223680666655033

Epoch: 6| Step: 11
Training loss: 0.37342136619543104
Validation loss: 2.306043960616558

Epoch: 6| Step: 12
Training loss: 0.3656907927176298
Validation loss: 2.384301167716129

Epoch: 6| Step: 13
Training loss: 0.45274152643119564
Validation loss: 2.3466287184847543

Epoch: 197| Step: 0
Training loss: 0.48202696169239423
Validation loss: 2.3217364051223393

Epoch: 6| Step: 1
Training loss: 0.5022667228056588
Validation loss: 2.32339244868117

Epoch: 6| Step: 2
Training loss: 1.02670662853776
Validation loss: 2.327672312716234

Epoch: 6| Step: 3
Training loss: 0.3788908335902131
Validation loss: 2.325879962412266

Epoch: 6| Step: 4
Training loss: 0.42398474475907033
Validation loss: 2.384373538115567

Epoch: 6| Step: 5
Training loss: 0.4287499864038849
Validation loss: 2.313776377097013

Epoch: 6| Step: 6
Training loss: 0.45124746903108615
Validation loss: 2.2677087343700677

Epoch: 6| Step: 7
Training loss: 0.3570221087998797
Validation loss: 2.3028038732703844

Epoch: 6| Step: 8
Training loss: 0.2692131708754853
Validation loss: 2.2931495434929268

Epoch: 6| Step: 9
Training loss: 0.6264310903517192
Validation loss: 2.329833161448091

Epoch: 6| Step: 10
Training loss: 0.5429456966638163
Validation loss: 2.306450750130425

Epoch: 6| Step: 11
Training loss: 0.39325759692290085
Validation loss: 2.3528415585214435

Epoch: 6| Step: 12
Training loss: 0.59101798793928
Validation loss: 2.350574602734473

Epoch: 6| Step: 13
Training loss: 0.39446869911399624
Validation loss: 2.294825125744866

Epoch: 198| Step: 0
Training loss: 0.5661061248142709
Validation loss: 2.3368034756408576

Epoch: 6| Step: 1
Training loss: 0.382802612799813
Validation loss: 2.301101869480865

Epoch: 6| Step: 2
Training loss: 0.4574425631567504
Validation loss: 2.290365011284929

Epoch: 6| Step: 3
Training loss: 0.49958491977612624
Validation loss: 2.2559184189152557

Epoch: 6| Step: 4
Training loss: 0.4273828603641451
Validation loss: 2.2719328665239784

Epoch: 6| Step: 5
Training loss: 0.41986910466254257
Validation loss: 2.3246250171505825

Epoch: 6| Step: 6
Training loss: 0.3679995789136758
Validation loss: 2.36587938144539

Epoch: 6| Step: 7
Training loss: 1.071485892533616
Validation loss: 2.284125471076478

Epoch: 6| Step: 8
Training loss: 0.3805379048815249
Validation loss: 2.3575863489792845

Epoch: 6| Step: 9
Training loss: 0.4814435018694956
Validation loss: 2.390507065600398

Epoch: 6| Step: 10
Training loss: 0.29019648842464857
Validation loss: 2.2734028572160994

Epoch: 6| Step: 11
Training loss: 0.461183191542191
Validation loss: 2.3851385551368534

Epoch: 6| Step: 12
Training loss: 0.3527709114018901
Validation loss: 2.329780007429017

Epoch: 6| Step: 13
Training loss: 0.421311284426656
Validation loss: 2.2806587062584516

Epoch: 199| Step: 0
Training loss: 0.5047041320422267
Validation loss: 2.19469380739162

Epoch: 6| Step: 1
Training loss: 0.3696980380235554
Validation loss: 2.2557105693756614

Epoch: 6| Step: 2
Training loss: 0.9997488242846189
Validation loss: 2.3071592018789113

Epoch: 6| Step: 3
Training loss: 0.32472140631728674
Validation loss: 2.289591713966071

Epoch: 6| Step: 4
Training loss: 0.5511026188888718
Validation loss: 2.276811375014792

Epoch: 6| Step: 5
Training loss: 0.3921565358982173
Validation loss: 2.3521911862167384

Epoch: 6| Step: 6
Training loss: 0.568518862026404
Validation loss: 2.3112742294106075

Epoch: 6| Step: 7
Training loss: 0.4863791381554015
Validation loss: 2.321697331335785

Epoch: 6| Step: 8
Training loss: 0.28380289693823
Validation loss: 2.295263845517959

Epoch: 6| Step: 9
Training loss: 0.3019958594161513
Validation loss: 2.279772702551634

Epoch: 6| Step: 10
Training loss: 0.5359703331946686
Validation loss: 2.3672096746600024

Epoch: 6| Step: 11
Training loss: 0.38754830828383463
Validation loss: 2.307184003007238

Epoch: 6| Step: 12
Training loss: 0.32477842994389844
Validation loss: 2.321542236319109

Epoch: 6| Step: 13
Training loss: 0.49638445289120187
Validation loss: 2.302199810988144

Epoch: 200| Step: 0
Training loss: 0.37509424296928845
Validation loss: 2.311150354603407

Epoch: 6| Step: 1
Training loss: 0.32189866182704463
Validation loss: 2.3355537192846296

Epoch: 6| Step: 2
Training loss: 0.5366763779796165
Validation loss: 2.2931466150049213

Epoch: 6| Step: 3
Training loss: 0.4829516262843397
Validation loss: 2.294370535778031

Epoch: 6| Step: 4
Training loss: 0.6441670631548939
Validation loss: 2.325853746143053

Epoch: 6| Step: 5
Training loss: 0.3770721919519637
Validation loss: 2.267416357665839

Epoch: 6| Step: 6
Training loss: 0.3331913596040448
Validation loss: 2.321579284456672

Epoch: 6| Step: 7
Training loss: 0.3433484419643327
Validation loss: 2.336759441790489

Epoch: 6| Step: 8
Training loss: 0.3602559859726878
Validation loss: 2.263340352763367

Epoch: 6| Step: 9
Training loss: 0.9599571189144709
Validation loss: 2.3553825434339735

Epoch: 6| Step: 10
Training loss: 0.508728843830188
Validation loss: 2.307499281337925

Epoch: 6| Step: 11
Training loss: 0.5455890249516059
Validation loss: 2.253378689011324

Epoch: 6| Step: 12
Training loss: 0.36790315403790386
Validation loss: 2.333188679729872

Epoch: 6| Step: 13
Training loss: 0.3818434887697916
Validation loss: 2.3022808893513167

Epoch: 201| Step: 0
Training loss: 0.2625663327239515
Validation loss: 2.288718413616447

Epoch: 6| Step: 1
Training loss: 0.39493519338908256
Validation loss: 2.3084376282892243

Epoch: 6| Step: 2
Training loss: 0.34637990535620256
Validation loss: 2.2774230698937474

Epoch: 6| Step: 3
Training loss: 0.5425802254138385
Validation loss: 2.291653465464167

Epoch: 6| Step: 4
Training loss: 0.35197665932876077
Validation loss: 2.2958204569054526

Epoch: 6| Step: 5
Training loss: 0.3936785557432297
Validation loss: 2.2598084160246246

Epoch: 6| Step: 6
Training loss: 0.3332182591211173
Validation loss: 2.283026225837927

Epoch: 6| Step: 7
Training loss: 0.6410427127301055
Validation loss: 2.251908076051607

Epoch: 6| Step: 8
Training loss: 1.002124020760976
Validation loss: 2.3355514734740455

Epoch: 6| Step: 9
Training loss: 0.4418802838636823
Validation loss: 2.3091828723597163

Epoch: 6| Step: 10
Training loss: 0.43176618104950726
Validation loss: 2.3323570207097446

Epoch: 6| Step: 11
Training loss: 0.4502246706444801
Validation loss: 2.3567023223417034

Epoch: 6| Step: 12
Training loss: 0.5576803569120349
Validation loss: 2.281490069433845

Epoch: 6| Step: 13
Training loss: 0.48372993277295445
Validation loss: 2.3411435193371113

Epoch: 202| Step: 0
Training loss: 0.33914821525749755
Validation loss: 2.3896139828601797

Epoch: 6| Step: 1
Training loss: 0.5843889754965046
Validation loss: 2.3188153027218457

Epoch: 6| Step: 2
Training loss: 0.268275014730433
Validation loss: 2.368502848404362

Epoch: 6| Step: 3
Training loss: 0.35613506872498635
Validation loss: 2.2793483123597658

Epoch: 6| Step: 4
Training loss: 0.46375874104963294
Validation loss: 2.326684911755653

Epoch: 6| Step: 5
Training loss: 0.40006196093481977
Validation loss: 2.328283360021656

Epoch: 6| Step: 6
Training loss: 0.37009486229228605
Validation loss: 2.293996326133183

Epoch: 6| Step: 7
Training loss: 0.3587710862492309
Validation loss: 2.3102239800729816

Epoch: 6| Step: 8
Training loss: 0.929668907171946
Validation loss: 2.2625854272328207

Epoch: 6| Step: 9
Training loss: 0.4061269757254163
Validation loss: 2.3624333481578526

Epoch: 6| Step: 10
Training loss: 0.5661091518596969
Validation loss: 2.3138523872730543

Epoch: 6| Step: 11
Training loss: 0.4684399374045287
Validation loss: 2.3156326829213967

Epoch: 6| Step: 12
Training loss: 0.5177240130111568
Validation loss: 2.2925400427951113

Epoch: 6| Step: 13
Training loss: 0.46506616736915307
Validation loss: 2.285047740479295

Epoch: 203| Step: 0
Training loss: 0.35990861997878176
Validation loss: 2.363337963253951

Epoch: 6| Step: 1
Training loss: 0.3086155147361823
Validation loss: 2.329955514270326

Epoch: 6| Step: 2
Training loss: 0.4349719131379927
Validation loss: 2.353052640885667

Epoch: 6| Step: 3
Training loss: 0.9640643721056896
Validation loss: 2.317733564489522

Epoch: 6| Step: 4
Training loss: 0.29363614676093347
Validation loss: 2.2965175930146358

Epoch: 6| Step: 5
Training loss: 0.42117364298924037
Validation loss: 2.296660657643216

Epoch: 6| Step: 6
Training loss: 0.3808103480939546
Validation loss: 2.278563864550611

Epoch: 6| Step: 7
Training loss: 0.43119187999999453
Validation loss: 2.297068330409129

Epoch: 6| Step: 8
Training loss: 0.41081925348034914
Validation loss: 2.3019889938794007

Epoch: 6| Step: 9
Training loss: 0.5481722567988386
Validation loss: 2.354728493843078

Epoch: 6| Step: 10
Training loss: 0.34394601088566146
Validation loss: 2.3272167712835032

Epoch: 6| Step: 11
Training loss: 0.3379026862841781
Validation loss: 2.318462906207346

Epoch: 6| Step: 12
Training loss: 0.7246894483716927
Validation loss: 2.3374054887945817

Epoch: 6| Step: 13
Training loss: 0.39334846943622603
Validation loss: 2.3950042506361413

Epoch: 204| Step: 0
Training loss: 0.48670284741232805
Validation loss: 2.3352612778633923

Epoch: 6| Step: 1
Training loss: 0.4482470908966809
Validation loss: 2.325864406948979

Epoch: 6| Step: 2
Training loss: 0.6418432654286986
Validation loss: 2.298748912759164

Epoch: 6| Step: 3
Training loss: 0.3610312814790931
Validation loss: 2.288671327742688

Epoch: 6| Step: 4
Training loss: 0.31283972870327814
Validation loss: 2.384441765100033

Epoch: 6| Step: 5
Training loss: 0.42704386257356786
Validation loss: 2.4069532052206135

Epoch: 6| Step: 6
Training loss: 0.5745103835071413
Validation loss: 2.3441480001969137

Epoch: 6| Step: 7
Training loss: 0.38915919898476603
Validation loss: 2.2787569087975794

Epoch: 6| Step: 8
Training loss: 0.2819514137822854
Validation loss: 2.3391195714558655

Epoch: 6| Step: 9
Training loss: 0.38093900581669343
Validation loss: 2.369966174956003

Epoch: 6| Step: 10
Training loss: 1.02540219255008
Validation loss: 2.341779295723044

Epoch: 6| Step: 11
Training loss: 0.29146389071574513
Validation loss: 2.297183476707766

Epoch: 6| Step: 12
Training loss: 0.3855667681137017
Validation loss: 2.262604491137488

Epoch: 6| Step: 13
Training loss: 0.41535804607863414
Validation loss: 2.318795801277608

Epoch: 205| Step: 0
Training loss: 0.5230752630984173
Validation loss: 2.38275442417433

Epoch: 6| Step: 1
Training loss: 0.3088632445049333
Validation loss: 2.373379078912628

Epoch: 6| Step: 2
Training loss: 0.4996807300951168
Validation loss: 2.3707711902735924

Epoch: 6| Step: 3
Training loss: 0.3733415887479042
Validation loss: 2.3450840184086346

Epoch: 6| Step: 4
Training loss: 0.4154900467985334
Validation loss: 2.380887539128242

Epoch: 6| Step: 5
Training loss: 0.9548841408158331
Validation loss: 2.292541602758036

Epoch: 6| Step: 6
Training loss: 0.4536404801705075
Validation loss: 2.376386471996147

Epoch: 6| Step: 7
Training loss: 0.41772792687762494
Validation loss: 2.3828957881858837

Epoch: 6| Step: 8
Training loss: 0.45118320335268974
Validation loss: 2.378386976906435

Epoch: 6| Step: 9
Training loss: 0.5418282475701685
Validation loss: 2.340988100118048

Epoch: 6| Step: 10
Training loss: 0.4601342103663798
Validation loss: 2.371362569319156

Epoch: 6| Step: 11
Training loss: 0.44544649617817483
Validation loss: 2.3519327203887337

Epoch: 6| Step: 12
Training loss: 0.3424045501441188
Validation loss: 2.296427053770129

Epoch: 6| Step: 13
Training loss: 0.35861382521739793
Validation loss: 2.3101804974319484

Epoch: 206| Step: 0
Training loss: 0.3268702106781417
Validation loss: 2.276096515009195

Epoch: 6| Step: 1
Training loss: 0.240377042632765
Validation loss: 2.323936415334836

Epoch: 6| Step: 2
Training loss: 0.3923527844238456
Validation loss: 2.323852578604808

Epoch: 6| Step: 3
Training loss: 0.38162818974331103
Validation loss: 2.3621613005737743

Epoch: 6| Step: 4
Training loss: 0.47615136719651296
Validation loss: 2.3220296856989338

Epoch: 6| Step: 5
Training loss: 0.4218110283280368
Validation loss: 2.290379419905836

Epoch: 6| Step: 6
Training loss: 0.16262505561071175
Validation loss: 2.277821398591319

Epoch: 6| Step: 7
Training loss: 0.23124783779112892
Validation loss: 2.3049283349018483

Epoch: 6| Step: 8
Training loss: 1.00118447726352
Validation loss: 2.3674627968625397

Epoch: 6| Step: 9
Training loss: 0.4560933719540657
Validation loss: 2.3611656871422126

Epoch: 6| Step: 10
Training loss: 0.6840715319027207
Validation loss: 2.370715224727071

Epoch: 6| Step: 11
Training loss: 0.5324034510648238
Validation loss: 2.351721131982514

Epoch: 6| Step: 12
Training loss: 0.5361667198479155
Validation loss: 2.2830532036718516

Epoch: 6| Step: 13
Training loss: 0.5555511520794028
Validation loss: 2.3605631937425264

Epoch: 207| Step: 0
Training loss: 0.42014700598884186
Validation loss: 2.359082437527778

Epoch: 6| Step: 1
Training loss: 0.47729273646798276
Validation loss: 2.350159066816154

Epoch: 6| Step: 2
Training loss: 0.3196664785183866
Validation loss: 2.336795755535534

Epoch: 6| Step: 3
Training loss: 0.9336265015543432
Validation loss: 2.3829499085209873

Epoch: 6| Step: 4
Training loss: 0.3786678940941725
Validation loss: 2.324288443580988

Epoch: 6| Step: 5
Training loss: 0.351947435932138
Validation loss: 2.3432272264470155

Epoch: 6| Step: 6
Training loss: 0.21329887862239358
Validation loss: 2.283460747744165

Epoch: 6| Step: 7
Training loss: 0.437172801416226
Validation loss: 2.3868206895201634

Epoch: 6| Step: 8
Training loss: 0.3059674058817842
Validation loss: 2.3369886825046993

Epoch: 6| Step: 9
Training loss: 0.6493388885355719
Validation loss: 2.3213285882259704

Epoch: 6| Step: 10
Training loss: 0.4129964131772198
Validation loss: 2.3352212988075234

Epoch: 6| Step: 11
Training loss: 0.44991618210293705
Validation loss: 2.313900806823218

Epoch: 6| Step: 12
Training loss: 0.34596945853647915
Validation loss: 2.3214979729042073

Epoch: 6| Step: 13
Training loss: 0.36234301752474546
Validation loss: 2.3012418776988186

Epoch: 208| Step: 0
Training loss: 0.5796144732518304
Validation loss: 2.3005953132353496

Epoch: 6| Step: 1
Training loss: 0.43154683539753186
Validation loss: 2.2964061941988803

Epoch: 6| Step: 2
Training loss: 0.219894819475659
Validation loss: 2.2787991513942876

Epoch: 6| Step: 3
Training loss: 0.5668903781104597
Validation loss: 2.298372018703821

Epoch: 6| Step: 4
Training loss: 0.9731879868210039
Validation loss: 2.358336272647855

Epoch: 6| Step: 5
Training loss: 0.523550334554563
Validation loss: 2.3252476570553156

Epoch: 6| Step: 6
Training loss: 0.40119470013220426
Validation loss: 2.358357864989171

Epoch: 6| Step: 7
Training loss: 0.42268054490414664
Validation loss: 2.3228607912285755

Epoch: 6| Step: 8
Training loss: 0.39111989143110054
Validation loss: 2.367173281921728

Epoch: 6| Step: 9
Training loss: 0.33986334908632
Validation loss: 2.364112846408218

Epoch: 6| Step: 10
Training loss: 0.5503086470339631
Validation loss: 2.286075678777788

Epoch: 6| Step: 11
Training loss: 0.30533713995876816
Validation loss: 2.2772632931455212

Epoch: 6| Step: 12
Training loss: 0.3819598804109777
Validation loss: 2.251897144531665

Epoch: 6| Step: 13
Training loss: 0.34944541112452393
Validation loss: 2.3332246743742022

Epoch: 209| Step: 0
Training loss: 0.5241425164587031
Validation loss: 2.359148515689635

Epoch: 6| Step: 1
Training loss: 0.5014713216361355
Validation loss: 2.2978002021260204

Epoch: 6| Step: 2
Training loss: 0.37374174102537727
Validation loss: 2.3609929715937485

Epoch: 6| Step: 3
Training loss: 0.6946057145628622
Validation loss: 2.3101206214590415

Epoch: 6| Step: 4
Training loss: 0.2965783092276532
Validation loss: 2.3249587048517335

Epoch: 6| Step: 5
Training loss: 0.3172102356264942
Validation loss: 2.3202026889217784

Epoch: 6| Step: 6
Training loss: 0.45861348527233076
Validation loss: 2.297708105085597

Epoch: 6| Step: 7
Training loss: 0.4477195435362058
Validation loss: 2.2735451304683365

Epoch: 6| Step: 8
Training loss: 0.4802341508717446
Validation loss: 2.322353497193662

Epoch: 6| Step: 9
Training loss: 0.947067554648442
Validation loss: 2.304565124711065

Epoch: 6| Step: 10
Training loss: 0.6074273946333445
Validation loss: 2.3224164541087156

Epoch: 6| Step: 11
Training loss: 0.4143630322645552
Validation loss: 2.3012238245768204

Epoch: 6| Step: 12
Training loss: 0.39023482863941117
Validation loss: 2.31267668933993

Epoch: 6| Step: 13
Training loss: 0.4211257710074718
Validation loss: 2.2921596228099

Epoch: 210| Step: 0
Training loss: 0.8721821917184748
Validation loss: 2.3036563096543845

Epoch: 6| Step: 1
Training loss: 0.40399770678917457
Validation loss: 2.2802149632408217

Epoch: 6| Step: 2
Training loss: 0.47789591929901987
Validation loss: 2.2912358370306967

Epoch: 6| Step: 3
Training loss: 0.3762755951144038
Validation loss: 2.2562977110378757

Epoch: 6| Step: 4
Training loss: 0.2690997332110548
Validation loss: 2.28729627775624

Epoch: 6| Step: 5
Training loss: 0.4842447136426471
Validation loss: 2.309677962414781

Epoch: 6| Step: 6
Training loss: 0.3323352880257011
Validation loss: 2.2860062194910933

Epoch: 6| Step: 7
Training loss: 0.43486008144994415
Validation loss: 2.2721979141748685

Epoch: 6| Step: 8
Training loss: 0.7270141346382518
Validation loss: 2.268521984541733

Epoch: 6| Step: 9
Training loss: 0.32645178108886314
Validation loss: 2.2426473963340867

Epoch: 6| Step: 10
Training loss: 0.22773470674101287
Validation loss: 2.3416365525378433

Epoch: 6| Step: 11
Training loss: 0.42569824599594025
Validation loss: 2.3037211746865895

Epoch: 6| Step: 12
Training loss: 0.5312939233012731
Validation loss: 2.2343011412606546

Epoch: 6| Step: 13
Training loss: 0.3750575339368847
Validation loss: 2.3412137019949752

Epoch: 211| Step: 0
Training loss: 0.3246643726751199
Validation loss: 2.272964288461501

Epoch: 6| Step: 1
Training loss: 0.3534134248144689
Validation loss: 2.2781058814315323

Epoch: 6| Step: 2
Training loss: 0.9379626086413843
Validation loss: 2.3161588025242876

Epoch: 6| Step: 3
Training loss: 0.3176897413515061
Validation loss: 2.2791239965188326

Epoch: 6| Step: 4
Training loss: 0.5201276639885258
Validation loss: 2.306230776188926

Epoch: 6| Step: 5
Training loss: 0.2669302343167042
Validation loss: 2.331837674301186

Epoch: 6| Step: 6
Training loss: 0.5743496285066144
Validation loss: 2.3055188075230375

Epoch: 6| Step: 7
Training loss: 0.16189998294000849
Validation loss: 2.2846056674290214

Epoch: 6| Step: 8
Training loss: 0.4273585231535832
Validation loss: 2.2537829951055395

Epoch: 6| Step: 9
Training loss: 0.3720527905120496
Validation loss: 2.262290140117446

Epoch: 6| Step: 10
Training loss: 0.3459346879329639
Validation loss: 2.3652074105121987

Epoch: 6| Step: 11
Training loss: 0.3986449916835034
Validation loss: 2.3210730028846247

Epoch: 6| Step: 12
Training loss: 0.3887426800667322
Validation loss: 2.3042777607805047

Epoch: 6| Step: 13
Training loss: 0.20805444329047518
Validation loss: 2.351994893990811

Epoch: 212| Step: 0
Training loss: 0.274787458735117
Validation loss: 2.305527252830402

Epoch: 6| Step: 1
Training loss: 0.9506312092835977
Validation loss: 2.3607478747490425

Epoch: 6| Step: 2
Training loss: 0.5627257635794124
Validation loss: 2.3324191368835288

Epoch: 6| Step: 3
Training loss: 0.311600582890706
Validation loss: 2.3120243597171806

Epoch: 6| Step: 4
Training loss: 0.5255638319205714
Validation loss: 2.2651425604345077

Epoch: 6| Step: 5
Training loss: 0.4029283812922849
Validation loss: 2.3397370803964885

Epoch: 6| Step: 6
Training loss: 0.7680742441639575
Validation loss: 2.308221415848952

Epoch: 6| Step: 7
Training loss: 0.5888685792618685
Validation loss: 2.3508464952506314

Epoch: 6| Step: 8
Training loss: 0.2772454369602036
Validation loss: 2.3071725841875206

Epoch: 6| Step: 9
Training loss: 0.4253360976064079
Validation loss: 2.3854131629174056

Epoch: 6| Step: 10
Training loss: 0.63536510623131
Validation loss: 2.3235959369928825

Epoch: 6| Step: 11
Training loss: 0.42917071389941097
Validation loss: 2.385064666852357

Epoch: 6| Step: 12
Training loss: 0.38810124513475014
Validation loss: 2.4352780999106485

Epoch: 6| Step: 13
Training loss: 0.37503162886431407
Validation loss: 2.392022565840488

Epoch: 213| Step: 0
Training loss: 0.46415711026082135
Validation loss: 2.3042609299548844

Epoch: 6| Step: 1
Training loss: 0.2337070882264425
Validation loss: 2.3798903260486135

Epoch: 6| Step: 2
Training loss: 0.4554734048229291
Validation loss: 2.3151171197232077

Epoch: 6| Step: 3
Training loss: 0.2796608480616213
Validation loss: 2.3236150133756723

Epoch: 6| Step: 4
Training loss: 0.32544032309230586
Validation loss: 2.37787135873181

Epoch: 6| Step: 5
Training loss: 0.8852555895124993
Validation loss: 2.3117213957490916

Epoch: 6| Step: 6
Training loss: 0.47901057900730226
Validation loss: 2.3564823683644263

Epoch: 6| Step: 7
Training loss: 0.5817267370175196
Validation loss: 2.361131851878105

Epoch: 6| Step: 8
Training loss: 0.32825538905601664
Validation loss: 2.3065039077109337

Epoch: 6| Step: 9
Training loss: 0.5757984050125763
Validation loss: 2.3026190317141917

Epoch: 6| Step: 10
Training loss: 0.4170373181973177
Validation loss: 2.34063813359065

Epoch: 6| Step: 11
Training loss: 0.3020230457831578
Validation loss: 2.3036433726524774

Epoch: 6| Step: 12
Training loss: 0.35148511670728144
Validation loss: 2.3233753971641264

Epoch: 6| Step: 13
Training loss: 0.5047915761771484
Validation loss: 2.3212009531432756

Epoch: 214| Step: 0
Training loss: 0.9119324604465381
Validation loss: 2.3072251137348103

Epoch: 6| Step: 1
Training loss: 0.41860101241432673
Validation loss: 2.260870546633902

Epoch: 6| Step: 2
Training loss: 0.6554022945138638
Validation loss: 2.31027116847673

Epoch: 6| Step: 3
Training loss: 0.37663512578216357
Validation loss: 2.3023119909268317

Epoch: 6| Step: 4
Training loss: 0.3638825720965965
Validation loss: 2.3303816353329116

Epoch: 6| Step: 5
Training loss: 0.29932460804789907
Validation loss: 2.2914179117847

Epoch: 6| Step: 6
Training loss: 0.32903606091218573
Validation loss: 2.336960788487627

Epoch: 6| Step: 7
Training loss: 0.4976347470990239
Validation loss: 2.3454223092041167

Epoch: 6| Step: 8
Training loss: 0.6155670235535711
Validation loss: 2.3483974917843327

Epoch: 6| Step: 9
Training loss: 0.4951254488464571
Validation loss: 2.3421232045454796

Epoch: 6| Step: 10
Training loss: 0.42898408360732754
Validation loss: 2.275737931319086

Epoch: 6| Step: 11
Training loss: 0.3472792370663292
Validation loss: 2.2319800873401396

Epoch: 6| Step: 12
Training loss: 0.521412648043704
Validation loss: 2.347579878645473

Epoch: 6| Step: 13
Training loss: 0.5397713188901351
Validation loss: 2.266607435471666

Epoch: 215| Step: 0
Training loss: 0.4220192627261862
Validation loss: 2.331917355821669

Epoch: 6| Step: 1
Training loss: 0.36334668872432574
Validation loss: 2.2626804817250394

Epoch: 6| Step: 2
Training loss: 0.8206143505047505
Validation loss: 2.2395252013239575

Epoch: 6| Step: 3
Training loss: 0.30553855391125023
Validation loss: 2.2859139167227953

Epoch: 6| Step: 4
Training loss: 0.5463203069366702
Validation loss: 2.3105420681969804

Epoch: 6| Step: 5
Training loss: 0.3515679570940125
Validation loss: 2.3025242022285775

Epoch: 6| Step: 6
Training loss: 0.49375698591674255
Validation loss: 2.302090128432612

Epoch: 6| Step: 7
Training loss: 0.3507502603754231
Validation loss: 2.3542639506896426

Epoch: 6| Step: 8
Training loss: 0.3850807409958027
Validation loss: 2.2755963976022135

Epoch: 6| Step: 9
Training loss: 0.3382350731535529
Validation loss: 2.3192554553607416

Epoch: 6| Step: 10
Training loss: 0.4376193292550576
Validation loss: 2.3031204844706146

Epoch: 6| Step: 11
Training loss: 0.41087126397505014
Validation loss: 2.321422880640845

Epoch: 6| Step: 12
Training loss: 0.3851747612828215
Validation loss: 2.281837492242473

Epoch: 6| Step: 13
Training loss: 0.47995064876590837
Validation loss: 2.276762620468628

Epoch: 216| Step: 0
Training loss: 0.4862955074785638
Validation loss: 2.2601568685091897

Epoch: 6| Step: 1
Training loss: 0.5424939831167112
Validation loss: 2.2781395282465255

Epoch: 6| Step: 2
Training loss: 0.4869014623597679
Validation loss: 2.2942594657093847

Epoch: 6| Step: 3
Training loss: 0.368260075118616
Validation loss: 2.315588615430218

Epoch: 6| Step: 4
Training loss: 0.2596942401979869
Validation loss: 2.277231378329306

Epoch: 6| Step: 5
Training loss: 0.4985651647968289
Validation loss: 2.3659748962534533

Epoch: 6| Step: 6
Training loss: 0.41395556670545713
Validation loss: 2.3541325985854353

Epoch: 6| Step: 7
Training loss: 0.582448310687045
Validation loss: 2.349813095735972

Epoch: 6| Step: 8
Training loss: 0.38904009681758894
Validation loss: 2.292451747163219

Epoch: 6| Step: 9
Training loss: 0.6212758690957101
Validation loss: 2.285949977824187

Epoch: 6| Step: 10
Training loss: 0.3307832263208164
Validation loss: 2.2948237318331737

Epoch: 6| Step: 11
Training loss: 0.9125819809548624
Validation loss: 2.295728297753043

Epoch: 6| Step: 12
Training loss: 0.5017836466457198
Validation loss: 2.3208036405991312

Epoch: 6| Step: 13
Training loss: 0.6268632533226985
Validation loss: 2.2752040104341327

Epoch: 217| Step: 0
Training loss: 0.8896067637827911
Validation loss: 2.377965080107505

Epoch: 6| Step: 1
Training loss: 0.4007633614219435
Validation loss: 2.317482246487298

Epoch: 6| Step: 2
Training loss: 0.5569518440650297
Validation loss: 2.315917771433442

Epoch: 6| Step: 3
Training loss: 0.46159771334885025
Validation loss: 2.430396791147203

Epoch: 6| Step: 4
Training loss: 0.451319236965001
Validation loss: 2.2875514245289437

Epoch: 6| Step: 5
Training loss: 0.2431823080180687
Validation loss: 2.3406049522964008

Epoch: 6| Step: 6
Training loss: 0.4442383543741095
Validation loss: 2.342663322300153

Epoch: 6| Step: 7
Training loss: 0.45320888269032306
Validation loss: 2.327307060322146

Epoch: 6| Step: 8
Training loss: 0.38686202506646
Validation loss: 2.331356860550539

Epoch: 6| Step: 9
Training loss: 0.3246803674290782
Validation loss: 2.354038046527499

Epoch: 6| Step: 10
Training loss: 0.38939312288043293
Validation loss: 2.339197340183077

Epoch: 6| Step: 11
Training loss: 0.5084908869216507
Validation loss: 2.3655244128109034

Epoch: 6| Step: 12
Training loss: 0.3938429654591898
Validation loss: 2.2374407492239072

Epoch: 6| Step: 13
Training loss: 0.43836943203381595
Validation loss: 2.2986248556329927

Epoch: 218| Step: 0
Training loss: 0.47049667452894695
Validation loss: 2.2581770271553308

Epoch: 6| Step: 1
Training loss: 0.33445113732385096
Validation loss: 2.3525632838819

Epoch: 6| Step: 2
Training loss: 0.3223382116702724
Validation loss: 2.288311875384644

Epoch: 6| Step: 3
Training loss: 0.47014705371325005
Validation loss: 2.3346396150283524

Epoch: 6| Step: 4
Training loss: 0.8703793388739566
Validation loss: 2.24893653426767

Epoch: 6| Step: 5
Training loss: 0.31232275704790924
Validation loss: 2.225503859457833

Epoch: 6| Step: 6
Training loss: 0.3664984019857439
Validation loss: 2.306496310154144

Epoch: 6| Step: 7
Training loss: 0.22223917899323334
Validation loss: 2.2912643830908785

Epoch: 6| Step: 8
Training loss: 0.3958148094494172
Validation loss: 2.2521843726694537

Epoch: 6| Step: 9
Training loss: 0.34943658405389283
Validation loss: 2.255916225933506

Epoch: 6| Step: 10
Training loss: 0.6107936387307272
Validation loss: 2.2716181096041543

Epoch: 6| Step: 11
Training loss: 0.4313432350821663
Validation loss: 2.297082022335519

Epoch: 6| Step: 12
Training loss: 0.3591117309206221
Validation loss: 2.2084761849270076

Epoch: 6| Step: 13
Training loss: 0.39687258877359655
Validation loss: 2.264298219346844

Epoch: 219| Step: 0
Training loss: 0.40670844033855424
Validation loss: 2.274254196661291

Epoch: 6| Step: 1
Training loss: 0.47472532449367977
Validation loss: 2.3359228535578924

Epoch: 6| Step: 2
Training loss: 0.4316204981189362
Validation loss: 2.2676866468713532

Epoch: 6| Step: 3
Training loss: 0.5031918925485819
Validation loss: 2.2921353525558743

Epoch: 6| Step: 4
Training loss: 0.27423336826931044
Validation loss: 2.3447983325765778

Epoch: 6| Step: 5
Training loss: 0.22227992496178672
Validation loss: 2.260842811976116

Epoch: 6| Step: 6
Training loss: 0.5536039272560441
Validation loss: 2.315934114334884

Epoch: 6| Step: 7
Training loss: 0.3562864184587302
Validation loss: 2.3117971555033234

Epoch: 6| Step: 8
Training loss: 0.2878679905848459
Validation loss: 2.3142909598108865

Epoch: 6| Step: 9
Training loss: 0.3016383604386062
Validation loss: 2.347165268489818

Epoch: 6| Step: 10
Training loss: 0.3285372052265713
Validation loss: 2.324107328249901

Epoch: 6| Step: 11
Training loss: 0.8352000111747061
Validation loss: 2.290263549820126

Epoch: 6| Step: 12
Training loss: 0.4518990539543411
Validation loss: 2.3807114473555724

Epoch: 6| Step: 13
Training loss: 0.534194583441046
Validation loss: 2.335462455969873

Epoch: 220| Step: 0
Training loss: 0.2908015263665936
Validation loss: 2.3398445057217625

Epoch: 6| Step: 1
Training loss: 0.1738997751077664
Validation loss: 2.3119162260836426

Epoch: 6| Step: 2
Training loss: 0.4001205650067118
Validation loss: 2.3138916107071155

Epoch: 6| Step: 3
Training loss: 0.45566980429447895
Validation loss: 2.331217041668995

Epoch: 6| Step: 4
Training loss: 0.4147537327748478
Validation loss: 2.3051779359886755

Epoch: 6| Step: 5
Training loss: 0.518660022791516
Validation loss: 2.308136698430393

Epoch: 6| Step: 6
Training loss: 0.41096478650839807
Validation loss: 2.302994618204012

Epoch: 6| Step: 7
Training loss: 0.3833106556003196
Validation loss: 2.330747454409894

Epoch: 6| Step: 8
Training loss: 0.8605344060616987
Validation loss: 2.3156997778415005

Epoch: 6| Step: 9
Training loss: 0.3949494741815664
Validation loss: 2.302128913623785

Epoch: 6| Step: 10
Training loss: 0.44389750889970525
Validation loss: 2.3362289042819007

Epoch: 6| Step: 11
Training loss: 0.23078782413806806
Validation loss: 2.310931283677213

Epoch: 6| Step: 12
Training loss: 0.3282800035847928
Validation loss: 2.311116251330997

Epoch: 6| Step: 13
Training loss: 0.5757579286321748
Validation loss: 2.3197236004147492

Epoch: 221| Step: 0
Training loss: 0.6005669815669603
Validation loss: 2.325066530991683

Epoch: 6| Step: 1
Training loss: 0.23355977216367377
Validation loss: 2.285653693241847

Epoch: 6| Step: 2
Training loss: 0.527925551860839
Validation loss: 2.269726769434433

Epoch: 6| Step: 3
Training loss: 0.5485181917565973
Validation loss: 2.318569209204613

Epoch: 6| Step: 4
Training loss: 0.42567971094981233
Validation loss: 2.332451386894037

Epoch: 6| Step: 5
Training loss: 0.5428053246321983
Validation loss: 2.3329516649309374

Epoch: 6| Step: 6
Training loss: 0.28613377593727785
Validation loss: 2.2809213898060166

Epoch: 6| Step: 7
Training loss: 0.560639430256934
Validation loss: 2.3628464311917154

Epoch: 6| Step: 8
Training loss: 0.420891409901589
Validation loss: 2.3638785708175223

Epoch: 6| Step: 9
Training loss: 0.6026281355891205
Validation loss: 2.3285340242128765

Epoch: 6| Step: 10
Training loss: 0.8686327189586843
Validation loss: 2.377530540058899

Epoch: 6| Step: 11
Training loss: 0.4326324460199765
Validation loss: 2.293021535617843

Epoch: 6| Step: 12
Training loss: 0.4170437139976075
Validation loss: 2.297056766160095

Epoch: 6| Step: 13
Training loss: 0.3073307944564945
Validation loss: 2.228327929086725

Epoch: 222| Step: 0
Training loss: 0.37328223348482403
Validation loss: 2.29486957463399

Epoch: 6| Step: 1
Training loss: 0.36588567912498465
Validation loss: 2.3799078909630476

Epoch: 6| Step: 2
Training loss: 0.2554411636997039
Validation loss: 2.251373684069763

Epoch: 6| Step: 3
Training loss: 0.4705072208969305
Validation loss: 2.3687040970379867

Epoch: 6| Step: 4
Training loss: 0.2652463879343822
Validation loss: 2.303167205934521

Epoch: 6| Step: 5
Training loss: 0.39736108673832227
Validation loss: 2.339445238349051

Epoch: 6| Step: 6
Training loss: 0.44216984555213346
Validation loss: 2.3156699285640268

Epoch: 6| Step: 7
Training loss: 0.29944473428015245
Validation loss: 2.3872464892556358

Epoch: 6| Step: 8
Training loss: 0.5029088284509298
Validation loss: 2.305300390787353

Epoch: 6| Step: 9
Training loss: 0.504879536424408
Validation loss: 2.2894605132168544

Epoch: 6| Step: 10
Training loss: 0.8487902671913911
Validation loss: 2.300925724694169

Epoch: 6| Step: 11
Training loss: 0.32749262681334307
Validation loss: 2.327424995956624

Epoch: 6| Step: 12
Training loss: 0.34931565845335877
Validation loss: 2.3067031408285383

Epoch: 6| Step: 13
Training loss: 0.35601801931929283
Validation loss: 2.349362760746873

Epoch: 223| Step: 0
Training loss: 0.381693020584712
Validation loss: 2.3497358559220207

Epoch: 6| Step: 1
Training loss: 0.35109654383445416
Validation loss: 2.297473483494717

Epoch: 6| Step: 2
Training loss: 0.30215363944962975
Validation loss: 2.2738780133444783

Epoch: 6| Step: 3
Training loss: 0.47499464433561983
Validation loss: 2.3341364386699817

Epoch: 6| Step: 4
Training loss: 0.33288662626724713
Validation loss: 2.3207080302721437

Epoch: 6| Step: 5
Training loss: 0.5440456770345218
Validation loss: 2.318522326798686

Epoch: 6| Step: 6
Training loss: 0.29561139023000804
Validation loss: 2.3077388585522525

Epoch: 6| Step: 7
Training loss: 0.8652929281912333
Validation loss: 2.2901420694811687

Epoch: 6| Step: 8
Training loss: 0.48536923105788804
Validation loss: 2.2617928378060888

Epoch: 6| Step: 9
Training loss: 0.37013882697062944
Validation loss: 2.3025504684025524

Epoch: 6| Step: 10
Training loss: 0.34653512868981845
Validation loss: 2.2853840510620964

Epoch: 6| Step: 11
Training loss: 0.27981295622276553
Validation loss: 2.31300118316387

Epoch: 6| Step: 12
Training loss: 0.2728491720915431
Validation loss: 2.2971049515885356

Epoch: 6| Step: 13
Training loss: 0.3423235187446096
Validation loss: 2.2956992533094374

Epoch: 224| Step: 0
Training loss: 0.4644762557985722
Validation loss: 2.3446983622748845

Epoch: 6| Step: 1
Training loss: 0.4871134717290262
Validation loss: 2.28992441591242

Epoch: 6| Step: 2
Training loss: 0.40401279217466424
Validation loss: 2.342629219801111

Epoch: 6| Step: 3
Training loss: 0.5278803602990253
Validation loss: 2.2244425178807

Epoch: 6| Step: 4
Training loss: 0.37010647801025454
Validation loss: 2.308428410409387

Epoch: 6| Step: 5
Training loss: 0.47284444104787593
Validation loss: 2.3011972497091353

Epoch: 6| Step: 6
Training loss: 0.2844568323461115
Validation loss: 2.3376730740913247

Epoch: 6| Step: 7
Training loss: 0.34615197649882834
Validation loss: 2.275864824863803

Epoch: 6| Step: 8
Training loss: 0.4530285370850681
Validation loss: 2.2712671641273507

Epoch: 6| Step: 9
Training loss: 0.36707160013364143
Validation loss: 2.2445911810637256

Epoch: 6| Step: 10
Training loss: 0.8458260673686919
Validation loss: 2.305161370305957

Epoch: 6| Step: 11
Training loss: 0.40504855615447743
Validation loss: 2.2780567882845486

Epoch: 6| Step: 12
Training loss: 0.3222279150892012
Validation loss: 2.2904864884739737

Epoch: 6| Step: 13
Training loss: 0.5403063700622228
Validation loss: 2.330406010280148

Epoch: 225| Step: 0
Training loss: 0.268757372577587
Validation loss: 2.3088203228627733

Epoch: 6| Step: 1
Training loss: 0.41135206741540525
Validation loss: 2.3306151690744192

Epoch: 6| Step: 2
Training loss: 0.4480068777601619
Validation loss: 2.29771450383509

Epoch: 6| Step: 3
Training loss: 0.37347758728403835
Validation loss: 2.2910407136246396

Epoch: 6| Step: 4
Training loss: 0.354759514845713
Validation loss: 2.278473867557697

Epoch: 6| Step: 5
Training loss: 0.35200939384911417
Validation loss: 2.3186565959588146

Epoch: 6| Step: 6
Training loss: 0.3314330040844191
Validation loss: 2.2858576988602506

Epoch: 6| Step: 7
Training loss: 0.3719699353764281
Validation loss: 2.313669235603252

Epoch: 6| Step: 8
Training loss: 0.8921662429976269
Validation loss: 2.352215681471891

Epoch: 6| Step: 9
Training loss: 0.35650868309756834
Validation loss: 2.3535717462836745

Epoch: 6| Step: 10
Training loss: 0.4264976004950049
Validation loss: 2.3520582823409035

Epoch: 6| Step: 11
Training loss: 0.4292670707318663
Validation loss: 2.352552262677332

Epoch: 6| Step: 12
Training loss: 0.55077145615115
Validation loss: 2.324645905551402

Epoch: 6| Step: 13
Training loss: 0.4584148363415385
Validation loss: 2.3110681689024424

Epoch: 226| Step: 0
Training loss: 0.42835504101444966
Validation loss: 2.293701903820344

Epoch: 6| Step: 1
Training loss: 0.4114850635135323
Validation loss: 2.3323598488545345

Epoch: 6| Step: 2
Training loss: 0.36483655264900655
Validation loss: 2.2846957968201744

Epoch: 6| Step: 3
Training loss: 0.28593388435287403
Validation loss: 2.2746628979642014

Epoch: 6| Step: 4
Training loss: 0.42824043750274887
Validation loss: 2.322743812824051

Epoch: 6| Step: 5
Training loss: 0.5381701450263057
Validation loss: 2.2822556304059884

Epoch: 6| Step: 6
Training loss: 0.43211380237110625
Validation loss: 2.339593295458007

Epoch: 6| Step: 7
Training loss: 0.4443239985947573
Validation loss: 2.364021441768521

Epoch: 6| Step: 8
Training loss: 0.3249960280138998
Validation loss: 2.30415451869786

Epoch: 6| Step: 9
Training loss: 0.30264206986498704
Validation loss: 2.2895056476783004

Epoch: 6| Step: 10
Training loss: 0.5706982810188903
Validation loss: 2.3411749532810058

Epoch: 6| Step: 11
Training loss: 0.4204357817280015
Validation loss: 2.3050120841734936

Epoch: 6| Step: 12
Training loss: 0.37552407519475073
Validation loss: 2.3100450905476633

Epoch: 6| Step: 13
Training loss: 0.840739282830677
Validation loss: 2.3355737443335274

Epoch: 227| Step: 0
Training loss: 0.4172422566001064
Validation loss: 2.3337159751314687

Epoch: 6| Step: 1
Training loss: 0.3275273193001222
Validation loss: 2.3483207130454

Epoch: 6| Step: 2
Training loss: 0.3741400713626751
Validation loss: 2.2769349452674

Epoch: 6| Step: 3
Training loss: 0.5625309670719215
Validation loss: 2.35476927232414

Epoch: 6| Step: 4
Training loss: 0.8608694780066559
Validation loss: 2.2753845127443832

Epoch: 6| Step: 5
Training loss: 0.32580463499304746
Validation loss: 2.278556801646085

Epoch: 6| Step: 6
Training loss: 0.3894329383385801
Validation loss: 2.365118870748614

Epoch: 6| Step: 7
Training loss: 0.3521380693260244
Validation loss: 2.326832781775933

Epoch: 6| Step: 8
Training loss: 0.454311592998536
Validation loss: 2.34822966670563

Epoch: 6| Step: 9
Training loss: 0.39113663545334804
Validation loss: 2.295348224400836

Epoch: 6| Step: 10
Training loss: 0.4511995843742533
Validation loss: 2.335919961682741

Epoch: 6| Step: 11
Training loss: 0.30188848388364337
Validation loss: 2.3705933496890275

Epoch: 6| Step: 12
Training loss: 0.4539003644289183
Validation loss: 2.330811539940073

Epoch: 6| Step: 13
Training loss: 0.2685469192768526
Validation loss: 2.3211791949068843

Epoch: 228| Step: 0
Training loss: 0.38340036835769686
Validation loss: 2.3123548135630894

Epoch: 6| Step: 1
Training loss: 0.34115787174251366
Validation loss: 2.300492929766267

Epoch: 6| Step: 2
Training loss: 0.32821933207804876
Validation loss: 2.3171044466615855

Epoch: 6| Step: 3
Training loss: 0.2501557878040854
Validation loss: 2.32466800739471

Epoch: 6| Step: 4
Training loss: 0.6706273893187551
Validation loss: 2.3225546128470222

Epoch: 6| Step: 5
Training loss: 0.29062344540416074
Validation loss: 2.289109890287758

Epoch: 6| Step: 6
Training loss: 0.34737791213441216
Validation loss: 2.259249686269797

Epoch: 6| Step: 7
Training loss: 0.2552496656047637
Validation loss: 2.3378425408360584

Epoch: 6| Step: 8
Training loss: 0.27599357989867546
Validation loss: 2.3320600549398134

Epoch: 6| Step: 9
Training loss: 0.23350197797801317
Validation loss: 2.355603603806678

Epoch: 6| Step: 10
Training loss: 0.2826871183039846
Validation loss: 2.338512655529931

Epoch: 6| Step: 11
Training loss: 0.38019821292872585
Validation loss: 2.327949380757997

Epoch: 6| Step: 12
Training loss: 0.4289417384184337
Validation loss: 2.3109565085832298

Epoch: 6| Step: 13
Training loss: 0.7957007788734513
Validation loss: 2.3347128695511756

Epoch: 229| Step: 0
Training loss: 0.3532326551081567
Validation loss: 2.302852956508188

Epoch: 6| Step: 1
Training loss: 0.5088302683481284
Validation loss: 2.2778793586265422

Epoch: 6| Step: 2
Training loss: 0.3147775859742598
Validation loss: 2.306364175852809

Epoch: 6| Step: 3
Training loss: 0.4052973728695275
Validation loss: 2.26655375419138

Epoch: 6| Step: 4
Training loss: 0.7689986733895158
Validation loss: 2.281127316733796

Epoch: 6| Step: 5
Training loss: 0.36194465207368587
Validation loss: 2.2604421154177645

Epoch: 6| Step: 6
Training loss: 0.582445291807008
Validation loss: 2.2930239270582957

Epoch: 6| Step: 7
Training loss: 0.38468909107564064
Validation loss: 2.2581328678425168

Epoch: 6| Step: 8
Training loss: 0.5097953232339294
Validation loss: 2.2830760388537725

Epoch: 6| Step: 9
Training loss: 0.3301397187137798
Validation loss: 2.311999481609203

Epoch: 6| Step: 10
Training loss: 0.44459837824001874
Validation loss: 2.27570422280419

Epoch: 6| Step: 11
Training loss: 0.29472779209899236
Validation loss: 2.3056050171455365

Epoch: 6| Step: 12
Training loss: 0.39486347977949826
Validation loss: 2.3465860289659304

Epoch: 6| Step: 13
Training loss: 0.3657419889710896
Validation loss: 2.3348694723188315

Epoch: 230| Step: 0
Training loss: 0.28920232123357487
Validation loss: 2.3184991466078326

Epoch: 6| Step: 1
Training loss: 0.42431380750696573
Validation loss: 2.3293741275972346

Epoch: 6| Step: 2
Training loss: 0.44166680469450803
Validation loss: 2.2984357102985964

Epoch: 6| Step: 3
Training loss: 0.2995508716267483
Validation loss: 2.2501572624631447

Epoch: 6| Step: 4
Training loss: 0.7577434783649868
Validation loss: 2.28467430836205

Epoch: 6| Step: 5
Training loss: 0.3152463397812628
Validation loss: 2.2809349608948337

Epoch: 6| Step: 6
Training loss: 0.4625154898601317
Validation loss: 2.321181874039842

Epoch: 6| Step: 7
Training loss: 0.3172305049775735
Validation loss: 2.333208529222711

Epoch: 6| Step: 8
Training loss: 0.4522446927465107
Validation loss: 2.3836546363418516

Epoch: 6| Step: 9
Training loss: 0.36833340825357724
Validation loss: 2.2842036247765973

Epoch: 6| Step: 10
Training loss: 0.5503255162603298
Validation loss: 2.3625751207575894

Epoch: 6| Step: 11
Training loss: 0.38170387345258255
Validation loss: 2.3365145834825425

Epoch: 6| Step: 12
Training loss: 0.3629896162376455
Validation loss: 2.3323538433020197

Epoch: 6| Step: 13
Training loss: 0.3145937397900859
Validation loss: 2.342450955982509

Epoch: 231| Step: 0
Training loss: 0.25039498597630744
Validation loss: 2.3180788036963675

Epoch: 6| Step: 1
Training loss: 0.48188415088202696
Validation loss: 2.3289810245440297

Epoch: 6| Step: 2
Training loss: 0.37446305457387774
Validation loss: 2.3056807796782954

Epoch: 6| Step: 3
Training loss: 0.3715323416210729
Validation loss: 2.3451169245240475

Epoch: 6| Step: 4
Training loss: 0.7142153620133611
Validation loss: 2.362991365671224

Epoch: 6| Step: 5
Training loss: 0.3579433784834758
Validation loss: 2.3001192238217243

Epoch: 6| Step: 6
Training loss: 0.3378576802857485
Validation loss: 2.341840500222433

Epoch: 6| Step: 7
Training loss: 0.4668447238547575
Validation loss: 2.3354204641192755

Epoch: 6| Step: 8
Training loss: 0.401678702317888
Validation loss: 2.3276903570274214

Epoch: 6| Step: 9
Training loss: 0.3134372959915973
Validation loss: 2.312089436831736

Epoch: 6| Step: 10
Training loss: 0.32501997244427694
Validation loss: 2.3286896603313014

Epoch: 6| Step: 11
Training loss: 0.3579511423829935
Validation loss: 2.3065450822432436

Epoch: 6| Step: 12
Training loss: 0.34952458893282673
Validation loss: 2.3119779031785463

Epoch: 6| Step: 13
Training loss: 0.5731702561226798
Validation loss: 2.28880465707704

Epoch: 232| Step: 0
Training loss: 0.34493101503179324
Validation loss: 2.262618356492819

Epoch: 6| Step: 1
Training loss: 0.43675776940255057
Validation loss: 2.28325180293334

Epoch: 6| Step: 2
Training loss: 0.43559442782292856
Validation loss: 2.314042169969725

Epoch: 6| Step: 3
Training loss: 0.43244842957767116
Validation loss: 2.2934109869505312

Epoch: 6| Step: 4
Training loss: 0.37001704569807586
Validation loss: 2.3263073766165534

Epoch: 6| Step: 5
Training loss: 0.2698833681013335
Validation loss: 2.275226850168535

Epoch: 6| Step: 6
Training loss: 0.35345709300352895
Validation loss: 2.345541798943655

Epoch: 6| Step: 7
Training loss: 0.3796881444164192
Validation loss: 2.3508688240477906

Epoch: 6| Step: 8
Training loss: 0.30466490441681476
Validation loss: 2.2618070155848176

Epoch: 6| Step: 9
Training loss: 0.33442386911809413
Validation loss: 2.3440264899034005

Epoch: 6| Step: 10
Training loss: 0.3702637475350831
Validation loss: 2.347046123823462

Epoch: 6| Step: 11
Training loss: 0.5275001576500246
Validation loss: 2.2620384855585707

Epoch: 6| Step: 12
Training loss: 0.39452033452712226
Validation loss: 2.327879088383951

Epoch: 6| Step: 13
Training loss: 0.7435961956986721
Validation loss: 2.329934878128241

Epoch: 233| Step: 0
Training loss: 0.36721103673941347
Validation loss: 2.3209755118312394

Epoch: 6| Step: 1
Training loss: 0.7433512347963884
Validation loss: 2.343616108778685

Epoch: 6| Step: 2
Training loss: 0.3600295781196983
Validation loss: 2.3288334188981588

Epoch: 6| Step: 3
Training loss: 0.5993516846657707
Validation loss: 2.3873071273070936

Epoch: 6| Step: 4
Training loss: 0.6041830625172809
Validation loss: 2.355868540207177

Epoch: 6| Step: 5
Training loss: 0.3255698650308425
Validation loss: 2.377937900703967

Epoch: 6| Step: 6
Training loss: 0.39908091634795234
Validation loss: 2.284047227715276

Epoch: 6| Step: 7
Training loss: 0.3572386600371036
Validation loss: 2.3725216968590734

Epoch: 6| Step: 8
Training loss: 0.4139590763987051
Validation loss: 2.3412936329819414

Epoch: 6| Step: 9
Training loss: 0.47043323297898004
Validation loss: 2.3702630604713826

Epoch: 6| Step: 10
Training loss: 0.2810462372485718
Validation loss: 2.3811941018473073

Epoch: 6| Step: 11
Training loss: 0.3203437603838953
Validation loss: 2.349040904711918

Epoch: 6| Step: 12
Training loss: 0.2924579745448661
Validation loss: 2.2534360433716705

Epoch: 6| Step: 13
Training loss: 0.15836407868523353
Validation loss: 2.328473869315816

Epoch: 234| Step: 0
Training loss: 0.3569036176334105
Validation loss: 2.370355884051871

Epoch: 6| Step: 1
Training loss: 0.6060355210170234
Validation loss: 2.390781131541028

Epoch: 6| Step: 2
Training loss: 0.3897972683153199
Validation loss: 2.346395948731668

Epoch: 6| Step: 3
Training loss: 0.3780758794295431
Validation loss: 2.320729964149834

Epoch: 6| Step: 4
Training loss: 0.5689409302301432
Validation loss: 2.3172818652346447

Epoch: 6| Step: 5
Training loss: 0.3061377173524044
Validation loss: 2.3679622477634403

Epoch: 6| Step: 6
Training loss: 0.42703229513923274
Validation loss: 2.357778215169591

Epoch: 6| Step: 7
Training loss: 0.28922649834803904
Validation loss: 2.3085229199038495

Epoch: 6| Step: 8
Training loss: 0.41208442503987347
Validation loss: 2.298974373097043

Epoch: 6| Step: 9
Training loss: 0.2917844103253586
Validation loss: 2.3746421109303744

Epoch: 6| Step: 10
Training loss: 0.3004444019611231
Validation loss: 2.3041251148342567

Epoch: 6| Step: 11
Training loss: 0.2567647392885834
Validation loss: 2.2557509535238887

Epoch: 6| Step: 12
Training loss: 0.791538470747261
Validation loss: 2.2586730320308592

Epoch: 6| Step: 13
Training loss: 0.33122642811091524
Validation loss: 2.330475731964002

Epoch: 235| Step: 0
Training loss: 0.7841274676388248
Validation loss: 2.2448920266595587

Epoch: 6| Step: 1
Training loss: 0.4621518835410506
Validation loss: 2.2794132328270003

Epoch: 6| Step: 2
Training loss: 0.5645756044128586
Validation loss: 2.304227837020199

Epoch: 6| Step: 3
Training loss: 0.3845870867277732
Validation loss: 2.3311245943349648

Epoch: 6| Step: 4
Training loss: 0.3096838661619643
Validation loss: 2.240978282634856

Epoch: 6| Step: 5
Training loss: 0.348027106514669
Validation loss: 2.2283109793282416

Epoch: 6| Step: 6
Training loss: 0.3989937209660649
Validation loss: 2.2807118203414634

Epoch: 6| Step: 7
Training loss: 0.4496195125016958
Validation loss: 2.302720483722369

Epoch: 6| Step: 8
Training loss: 0.28631509176154174
Validation loss: 2.3284884858188373

Epoch: 6| Step: 9
Training loss: 0.3674969890691717
Validation loss: 2.2401648779202246

Epoch: 6| Step: 10
Training loss: 0.33852410882266704
Validation loss: 2.340791555946036

Epoch: 6| Step: 11
Training loss: 0.5216609355908266
Validation loss: 2.2815644731152993

Epoch: 6| Step: 12
Training loss: 0.35107869661364355
Validation loss: 2.286566526826409

Epoch: 6| Step: 13
Training loss: 0.3319814644682048
Validation loss: 2.2407408953442736

Epoch: 236| Step: 0
Training loss: 0.5139455320168334
Validation loss: 2.258118218268248

Epoch: 6| Step: 1
Training loss: 0.3569146189101321
Validation loss: 2.2736338457438845

Epoch: 6| Step: 2
Training loss: 0.5188413930149096
Validation loss: 2.250542398702713

Epoch: 6| Step: 3
Training loss: 0.2709483061574733
Validation loss: 2.2812254917448214

Epoch: 6| Step: 4
Training loss: 0.7707753073700834
Validation loss: 2.332153197848169

Epoch: 6| Step: 5
Training loss: 0.6460061047298045
Validation loss: 2.3374279204898305

Epoch: 6| Step: 6
Training loss: 0.35342070849100615
Validation loss: 2.3190083119066736

Epoch: 6| Step: 7
Training loss: 0.33887701542479065
Validation loss: 2.336940027165228

Epoch: 6| Step: 8
Training loss: 0.406761617552056
Validation loss: 2.368112750464289

Epoch: 6| Step: 9
Training loss: 0.39569509334264785
Validation loss: 2.3035857244887943

Epoch: 6| Step: 10
Training loss: 0.34624258074747466
Validation loss: 2.3225474613022716

Epoch: 6| Step: 11
Training loss: 0.2830715531518425
Validation loss: 2.304422973279679

Epoch: 6| Step: 12
Training loss: 0.35111875079193383
Validation loss: 2.3403861001587893

Epoch: 6| Step: 13
Training loss: 0.5469123827555159
Validation loss: 2.2796225817655453

Epoch: 237| Step: 0
Training loss: 0.4997272492583467
Validation loss: 2.386279093220483

Epoch: 6| Step: 1
Training loss: 0.717976693160291
Validation loss: 2.326615768174649

Epoch: 6| Step: 2
Training loss: 0.27617463322277824
Validation loss: 2.3019661564298706

Epoch: 6| Step: 3
Training loss: 0.38432835164043866
Validation loss: 2.3475176558204702

Epoch: 6| Step: 4
Training loss: 0.8654135352788066
Validation loss: 2.3600783320805503

Epoch: 6| Step: 5
Training loss: 0.34781450248751883
Validation loss: 2.2576392964209178

Epoch: 6| Step: 6
Training loss: 0.4713265496974869
Validation loss: 2.383391171422712

Epoch: 6| Step: 7
Training loss: 0.34692402141009965
Validation loss: 2.2835000929765967

Epoch: 6| Step: 8
Training loss: 0.35961928565080026
Validation loss: 2.351020522410567

Epoch: 6| Step: 9
Training loss: 0.28139178358020916
Validation loss: 2.301622013687387

Epoch: 6| Step: 10
Training loss: 0.49081720608488344
Validation loss: 2.2800314274512545

Epoch: 6| Step: 11
Training loss: 0.3864078620725848
Validation loss: 2.297207114154481

Epoch: 6| Step: 12
Training loss: 0.4703117104457172
Validation loss: 2.2855478847764177

Epoch: 6| Step: 13
Training loss: 0.4030763936865304
Validation loss: 2.2912082444801856

Epoch: 238| Step: 0
Training loss: 0.4170215069292641
Validation loss: 2.308371182990971

Epoch: 6| Step: 1
Training loss: 0.3617936923867914
Validation loss: 2.289823091106395

Epoch: 6| Step: 2
Training loss: 0.4350571552085855
Validation loss: 2.3529866701816635

Epoch: 6| Step: 3
Training loss: 0.39661129202659506
Validation loss: 2.3292697592515403

Epoch: 6| Step: 4
Training loss: 0.42088990523680414
Validation loss: 2.3614195497545047

Epoch: 6| Step: 5
Training loss: 0.38183162520917524
Validation loss: 2.3151115071223587

Epoch: 6| Step: 6
Training loss: 0.7228732633799063
Validation loss: 2.2968989347218556

Epoch: 6| Step: 7
Training loss: 0.37542664576373774
Validation loss: 2.271153232078525

Epoch: 6| Step: 8
Training loss: 0.5926149461203576
Validation loss: 2.342358180149583

Epoch: 6| Step: 9
Training loss: 0.39567532229871655
Validation loss: 2.274808035775705

Epoch: 6| Step: 10
Training loss: 0.5172912378369553
Validation loss: 2.299485615209665

Epoch: 6| Step: 11
Training loss: 0.29493834594812185
Validation loss: 2.311208037591543

Epoch: 6| Step: 12
Training loss: 0.2737448327565347
Validation loss: 2.2963725122099805

Epoch: 6| Step: 13
Training loss: 0.3404162506585787
Validation loss: 2.3031212091091224

Epoch: 239| Step: 0
Training loss: 0.6973479834036396
Validation loss: 2.3572427659996684

Epoch: 6| Step: 1
Training loss: 0.35124225865857617
Validation loss: 2.289129019715713

Epoch: 6| Step: 2
Training loss: 0.3736083513738596
Validation loss: 2.3256094397010894

Epoch: 6| Step: 3
Training loss: 0.37764664334320985
Validation loss: 2.323099836189768

Epoch: 6| Step: 4
Training loss: 0.6031856190157356
Validation loss: 2.286115639508154

Epoch: 6| Step: 5
Training loss: 0.842985230462415
Validation loss: 2.3184100399678367

Epoch: 6| Step: 6
Training loss: 0.3367310842569459
Validation loss: 2.254953794379562

Epoch: 6| Step: 7
Training loss: 0.34977573294111214
Validation loss: 2.260291123895851

Epoch: 6| Step: 8
Training loss: 0.4155400741545613
Validation loss: 2.3119937067562195

Epoch: 6| Step: 9
Training loss: 0.3665562946740705
Validation loss: 2.2858335702997747

Epoch: 6| Step: 10
Training loss: 0.5039232827789939
Validation loss: 2.3746387474643518

Epoch: 6| Step: 11
Training loss: 0.4644402908849146
Validation loss: 2.271188539027882

Epoch: 6| Step: 12
Training loss: 0.3533740734996329
Validation loss: 2.305472530136534

Epoch: 6| Step: 13
Training loss: 0.5049214449772516
Validation loss: 2.255907251419716

Epoch: 240| Step: 0
Training loss: 0.38226941569725503
Validation loss: 2.309336087351134

Epoch: 6| Step: 1
Training loss: 0.2851449624531823
Validation loss: 2.288256124521536

Epoch: 6| Step: 2
Training loss: 0.27060416808791476
Validation loss: 2.266305019007474

Epoch: 6| Step: 3
Training loss: 0.43506912578331935
Validation loss: 2.2724853829059586

Epoch: 6| Step: 4
Training loss: 0.4726090525872818
Validation loss: 2.311078743167961

Epoch: 6| Step: 5
Training loss: 0.4131306473004072
Validation loss: 2.3264323488291225

Epoch: 6| Step: 6
Training loss: 0.5045177091433599
Validation loss: 2.331314206709311

Epoch: 6| Step: 7
Training loss: 0.4137568155171055
Validation loss: 2.361721143890625

Epoch: 6| Step: 8
Training loss: 0.305313408907862
Validation loss: 2.2682173093944993

Epoch: 6| Step: 9
Training loss: 0.5004661890131714
Validation loss: 2.309723364158843

Epoch: 6| Step: 10
Training loss: 0.7892191514229608
Validation loss: 2.3440720230978425

Epoch: 6| Step: 11
Training loss: 0.4347850826053104
Validation loss: 2.326534521627676

Epoch: 6| Step: 12
Training loss: 0.3798785957161228
Validation loss: 2.381302852494632

Epoch: 6| Step: 13
Training loss: 0.2489051388262547
Validation loss: 2.283325818552984

Epoch: 241| Step: 0
Training loss: 0.2751713684798243
Validation loss: 2.3630426459804768

Epoch: 6| Step: 1
Training loss: 0.414578566052553
Validation loss: 2.3289166668344676

Epoch: 6| Step: 2
Training loss: 0.3229944253431586
Validation loss: 2.408126297689762

Epoch: 6| Step: 3
Training loss: 0.25121665484222266
Validation loss: 2.3269932362035077

Epoch: 6| Step: 4
Training loss: 0.35842758184943746
Validation loss: 2.3088765323472673

Epoch: 6| Step: 5
Training loss: 0.39553685964660246
Validation loss: 2.2967371391046205

Epoch: 6| Step: 6
Training loss: 0.5693994293666937
Validation loss: 2.266814697798583

Epoch: 6| Step: 7
Training loss: 0.3506019503621072
Validation loss: 2.3401622778302995

Epoch: 6| Step: 8
Training loss: 0.45158367437328795
Validation loss: 2.3133581476593807

Epoch: 6| Step: 9
Training loss: 0.37843456601077335
Validation loss: 2.35744910552346

Epoch: 6| Step: 10
Training loss: 0.3486835966334484
Validation loss: 2.338476954685553

Epoch: 6| Step: 11
Training loss: 0.3457152369904407
Validation loss: 2.3202118942764556

Epoch: 6| Step: 12
Training loss: 0.773538062753937
Validation loss: 2.2923597992652494

Epoch: 6| Step: 13
Training loss: 0.5012142814600195
Validation loss: 2.3155941067521177

Epoch: 242| Step: 0
Training loss: 0.3794881344361353
Validation loss: 2.331855941990406

Epoch: 6| Step: 1
Training loss: 0.41375766185223956
Validation loss: 2.311984262434318

Epoch: 6| Step: 2
Training loss: 0.3505898371827583
Validation loss: 2.347249855415561

Epoch: 6| Step: 3
Training loss: 0.27023421405259185
Validation loss: 2.318907049846509

Epoch: 6| Step: 4
Training loss: 0.43318603867182653
Validation loss: 2.2487107927976813

Epoch: 6| Step: 5
Training loss: 0.3395930384885341
Validation loss: 2.3799107794774383

Epoch: 6| Step: 6
Training loss: 0.32380801921866914
Validation loss: 2.3538599292693423

Epoch: 6| Step: 7
Training loss: 0.2920194377112424
Validation loss: 2.3413453715448673

Epoch: 6| Step: 8
Training loss: 0.3967589756936474
Validation loss: 2.344438892423716

Epoch: 6| Step: 9
Training loss: 0.4348742504436879
Validation loss: 2.3607861423006216

Epoch: 6| Step: 10
Training loss: 0.884023359233891
Validation loss: 2.341341408667654

Epoch: 6| Step: 11
Training loss: 0.31542078247727684
Validation loss: 2.3055689790889007

Epoch: 6| Step: 12
Training loss: 0.3499595763500103
Validation loss: 2.355920481554788

Epoch: 6| Step: 13
Training loss: 0.35964617656694403
Validation loss: 2.3537717729946794

Epoch: 243| Step: 0
Training loss: 0.3854787192352463
Validation loss: 2.341601527202887

Epoch: 6| Step: 1
Training loss: 0.32983563335918525
Validation loss: 2.3075412560711803

Epoch: 6| Step: 2
Training loss: 0.23897036198027072
Validation loss: 2.3041289089022583

Epoch: 6| Step: 3
Training loss: 0.3544970005013421
Validation loss: 2.3430549608265134

Epoch: 6| Step: 4
Training loss: 0.30830142504745994
Validation loss: 2.384579388019027

Epoch: 6| Step: 5
Training loss: 0.3963588647484601
Validation loss: 2.327056434724054

Epoch: 6| Step: 6
Training loss: 0.5112141166629549
Validation loss: 2.3043999271615516

Epoch: 6| Step: 7
Training loss: 0.5222358575296606
Validation loss: 2.246049317735905

Epoch: 6| Step: 8
Training loss: 0.7291557220364211
Validation loss: 2.314591647481421

Epoch: 6| Step: 9
Training loss: 0.36290458923343505
Validation loss: 2.2607971843843684

Epoch: 6| Step: 10
Training loss: 0.5784453458166328
Validation loss: 2.390620279411359

Epoch: 6| Step: 11
Training loss: 0.37095814285107753
Validation loss: 2.302232061446499

Epoch: 6| Step: 12
Training loss: 0.33572602823991804
Validation loss: 2.3632195078453337

Epoch: 6| Step: 13
Training loss: 0.330826706157307
Validation loss: 2.291625392426535

Epoch: 244| Step: 0
Training loss: 0.41254911419333345
Validation loss: 2.281580400273479

Epoch: 6| Step: 1
Training loss: 0.3298521340414626
Validation loss: 2.3413635395962933

Epoch: 6| Step: 2
Training loss: 0.3881056605387482
Validation loss: 2.3461915586791053

Epoch: 6| Step: 3
Training loss: 0.3229306728135283
Validation loss: 2.364304838431104

Epoch: 6| Step: 4
Training loss: 0.4914879444425042
Validation loss: 2.3325752718529063

Epoch: 6| Step: 5
Training loss: 0.20589693186511057
Validation loss: 2.340431254253549

Epoch: 6| Step: 6
Training loss: 0.34550099471262324
Validation loss: 2.3507465455069307

Epoch: 6| Step: 7
Training loss: 0.2943171054052845
Validation loss: 2.3183653396748247

Epoch: 6| Step: 8
Training loss: 0.36006918494030143
Validation loss: 2.3211431333051418

Epoch: 6| Step: 9
Training loss: 0.8881358783439584
Validation loss: 2.276062759429707

Epoch: 6| Step: 10
Training loss: 0.3403756375063426
Validation loss: 2.343358765903179

Epoch: 6| Step: 11
Training loss: 0.4374886579405744
Validation loss: 2.3340090613343185

Epoch: 6| Step: 12
Training loss: 0.3582210465568665
Validation loss: 2.265653614433504

Epoch: 6| Step: 13
Training loss: 0.4969180010536126
Validation loss: 2.3310953090640436

Epoch: 245| Step: 0
Training loss: 0.8135386577229816
Validation loss: 2.2656984690011788

Epoch: 6| Step: 1
Training loss: 0.29173908299677326
Validation loss: 2.3039498824451434

Epoch: 6| Step: 2
Training loss: 0.41344357062948295
Validation loss: 2.307861452954471

Epoch: 6| Step: 3
Training loss: 0.35138594114543975
Validation loss: 2.2360037622556614

Epoch: 6| Step: 4
Training loss: 0.30885600764394405
Validation loss: 2.264663343118687

Epoch: 6| Step: 5
Training loss: 0.4591477772842206
Validation loss: 2.2706219169357063

Epoch: 6| Step: 6
Training loss: 0.268276500537669
Validation loss: 2.272394087239435

Epoch: 6| Step: 7
Training loss: 0.27722014775728476
Validation loss: 2.334847373439664

Epoch: 6| Step: 8
Training loss: 0.4998153554203486
Validation loss: 2.3270331687836516

Epoch: 6| Step: 9
Training loss: 0.5053802341979863
Validation loss: 2.3166221273609544

Epoch: 6| Step: 10
Training loss: 0.3868477923943732
Validation loss: 2.291490120300663

Epoch: 6| Step: 11
Training loss: 0.41452622986826126
Validation loss: 2.3458926600469074

Epoch: 6| Step: 12
Training loss: 0.39279518010354103
Validation loss: 2.314790261738861

Epoch: 6| Step: 13
Training loss: 0.23712033304599875
Validation loss: 2.323673344579497

Epoch: 246| Step: 0
Training loss: 0.28135345463602035
Validation loss: 2.29992762707442

Epoch: 6| Step: 1
Training loss: 0.3154211131722705
Validation loss: 2.2997726189820087

Epoch: 6| Step: 2
Training loss: 0.36672339632709694
Validation loss: 2.3414822182239114

Epoch: 6| Step: 3
Training loss: 0.2572620903163862
Validation loss: 2.3298824598001016

Epoch: 6| Step: 4
Training loss: 0.6072374168056551
Validation loss: 2.3102878265184743

Epoch: 6| Step: 5
Training loss: 0.4643744335453486
Validation loss: 2.3297066319117348

Epoch: 6| Step: 6
Training loss: 0.2760966833937834
Validation loss: 2.304044575644138

Epoch: 6| Step: 7
Training loss: 0.4033537289720988
Validation loss: 2.3576000855264088

Epoch: 6| Step: 8
Training loss: 0.2911493646934138
Validation loss: 2.32310283810076

Epoch: 6| Step: 9
Training loss: 0.2470889480257372
Validation loss: 2.363379492701245

Epoch: 6| Step: 10
Training loss: 0.7669921657405857
Validation loss: 2.301304704222108

Epoch: 6| Step: 11
Training loss: 0.48018883095263504
Validation loss: 2.398428255243533

Epoch: 6| Step: 12
Training loss: 0.6412573229128073
Validation loss: 2.3640488399994255

Epoch: 6| Step: 13
Training loss: 0.4070027053986782
Validation loss: 2.2977660563531925

Epoch: 247| Step: 0
Training loss: 0.27346570005776893
Validation loss: 2.3386650194516068

Epoch: 6| Step: 1
Training loss: 0.4285664760354534
Validation loss: 2.3276267318559354

Epoch: 6| Step: 2
Training loss: 0.4345176750622264
Validation loss: 2.356912536295211

Epoch: 6| Step: 3
Training loss: 0.440901104339459
Validation loss: 2.3695768042332963

Epoch: 6| Step: 4
Training loss: 0.5841713290316444
Validation loss: 2.3377163513207457

Epoch: 6| Step: 5
Training loss: 0.3192451884729369
Validation loss: 2.296439321981942

Epoch: 6| Step: 6
Training loss: 0.43451184511665114
Validation loss: 2.349230052065348

Epoch: 6| Step: 7
Training loss: 0.4398625818696464
Validation loss: 2.327134811483136

Epoch: 6| Step: 8
Training loss: 0.571824903326327
Validation loss: 2.3039908870355648

Epoch: 6| Step: 9
Training loss: 0.45744653728140616
Validation loss: 2.305433318588576

Epoch: 6| Step: 10
Training loss: 0.7858865482506645
Validation loss: 2.29884297321011

Epoch: 6| Step: 11
Training loss: 0.3477522899544061
Validation loss: 2.3115801743148037

Epoch: 6| Step: 12
Training loss: 0.3855222050620846
Validation loss: 2.3239527531421054

Epoch: 6| Step: 13
Training loss: 0.4427463477774041
Validation loss: 2.27485800254541

Epoch: 248| Step: 0
Training loss: 0.36985938925124845
Validation loss: 2.2998178361542476

Epoch: 6| Step: 1
Training loss: 0.4830834181090557
Validation loss: 2.2589025539017804

Epoch: 6| Step: 2
Training loss: 0.36803381358812876
Validation loss: 2.2683279291163787

Epoch: 6| Step: 3
Training loss: 0.38041449753364664
Validation loss: 2.3156164408537174

Epoch: 6| Step: 4
Training loss: 0.5186003756466235
Validation loss: 2.3002710472945855

Epoch: 6| Step: 5
Training loss: 0.4109151268441979
Validation loss: 2.2794503555553844

Epoch: 6| Step: 6
Training loss: 0.286574364773265
Validation loss: 2.3170299665971545

Epoch: 6| Step: 7
Training loss: 0.2683891757371421
Validation loss: 2.260851617503188

Epoch: 6| Step: 8
Training loss: 0.26357714046118236
Validation loss: 2.2551773515530447

Epoch: 6| Step: 9
Training loss: 0.7131001621772005
Validation loss: 2.297098404103571

Epoch: 6| Step: 10
Training loss: 0.37821066808083237
Validation loss: 2.2083245463166468

Epoch: 6| Step: 11
Training loss: 0.5204613469839042
Validation loss: 2.2595995614225672

Epoch: 6| Step: 12
Training loss: 0.25261112904867267
Validation loss: 2.2824256428183616

Epoch: 6| Step: 13
Training loss: 0.5476429043829362
Validation loss: 2.3081608692931637

Epoch: 249| Step: 0
Training loss: 0.2872353102411428
Validation loss: 2.2510126713678966

Epoch: 6| Step: 1
Training loss: 0.3621423774173523
Validation loss: 2.2512230374763655

Epoch: 6| Step: 2
Training loss: 0.386432233307801
Validation loss: 2.3261320557537255

Epoch: 6| Step: 3
Training loss: 0.44090036080350625
Validation loss: 2.334595438240292

Epoch: 6| Step: 4
Training loss: 0.7579358973762591
Validation loss: 2.334048252481884

Epoch: 6| Step: 5
Training loss: 0.4306757572861177
Validation loss: 2.3462127208237717

Epoch: 6| Step: 6
Training loss: 0.3405133589380041
Validation loss: 2.282259752464511

Epoch: 6| Step: 7
Training loss: 0.33537809237015265
Validation loss: 2.3293361201827363

Epoch: 6| Step: 8
Training loss: 0.5502765047171074
Validation loss: 2.302563135425353

Epoch: 6| Step: 9
Training loss: 0.31016033035400076
Validation loss: 2.304229087283014

Epoch: 6| Step: 10
Training loss: 0.42405620713649433
Validation loss: 2.3962542012177335

Epoch: 6| Step: 11
Training loss: 0.292169408697128
Validation loss: 2.380006131877533

Epoch: 6| Step: 12
Training loss: 0.3790599275393204
Validation loss: 2.357064806621646

Epoch: 6| Step: 13
Training loss: 0.46972664180762874
Validation loss: 2.2986080871387986

Epoch: 250| Step: 0
Training loss: 0.49220366678480265
Validation loss: 2.3108021199341953

Epoch: 6| Step: 1
Training loss: 0.3606305786706229
Validation loss: 2.342538902179532

Epoch: 6| Step: 2
Training loss: 0.39665669422009076
Validation loss: 2.357841448040538

Epoch: 6| Step: 3
Training loss: 0.2732854420344222
Validation loss: 2.3323297442698054

Epoch: 6| Step: 4
Training loss: 0.3056624293664564
Validation loss: 2.328585056531959

Epoch: 6| Step: 5
Training loss: 0.36866847122991253
Validation loss: 2.316936284323136

Epoch: 6| Step: 6
Training loss: 0.29519549680883034
Validation loss: 2.268861935659173

Epoch: 6| Step: 7
Training loss: 0.7049247173263438
Validation loss: 2.3590052738138834

Epoch: 6| Step: 8
Training loss: 0.32676270932155516
Validation loss: 2.3636055884047247

Epoch: 6| Step: 9
Training loss: 0.44591292676472416
Validation loss: 2.3322016293273484

Epoch: 6| Step: 10
Training loss: 0.42593265606259173
Validation loss: 2.289475135803724

Epoch: 6| Step: 11
Training loss: 0.4089659357878437
Validation loss: 2.3569643281922033

Epoch: 6| Step: 12
Training loss: 0.2851238885571041
Validation loss: 2.3032811761058203

Epoch: 6| Step: 13
Training loss: 0.35702354873598396
Validation loss: 2.2789108616334683

Epoch: 251| Step: 0
Training loss: 0.41796375877751435
Validation loss: 2.330339543401932

Epoch: 6| Step: 1
Training loss: 0.27487030655695066
Validation loss: 2.2981953275278775

Epoch: 6| Step: 2
Training loss: 0.3341054306600242
Validation loss: 2.278369818546225

Epoch: 6| Step: 3
Training loss: 0.7014269351607176
Validation loss: 2.2935904808600656

Epoch: 6| Step: 4
Training loss: 0.35194610224585693
Validation loss: 2.3086770909171626

Epoch: 6| Step: 5
Training loss: 0.27104719900124064
Validation loss: 2.2685309616996103

Epoch: 6| Step: 6
Training loss: 0.24066234088338262
Validation loss: 2.3143809289845145

Epoch: 6| Step: 7
Training loss: 0.4639620392846499
Validation loss: 2.3108110360153047

Epoch: 6| Step: 8
Training loss: 0.3595968888307313
Validation loss: 2.2773807407033697

Epoch: 6| Step: 9
Training loss: 0.52171174996642
Validation loss: 2.337178184673313

Epoch: 6| Step: 10
Training loss: 0.41557284866920824
Validation loss: 2.2679294135554113

Epoch: 6| Step: 11
Training loss: 0.32437731990094876
Validation loss: 2.2934883564388118

Epoch: 6| Step: 12
Training loss: 0.42495680968226557
Validation loss: 2.2634555207484497

Epoch: 6| Step: 13
Training loss: 0.5709402731341083
Validation loss: 2.3440515620882474

Epoch: 252| Step: 0
Training loss: 0.29987712072089245
Validation loss: 2.359798772282608

Epoch: 6| Step: 1
Training loss: 0.269351498470348
Validation loss: 2.334395615275167

Epoch: 6| Step: 2
Training loss: 0.33991665989797154
Validation loss: 2.3206363028187607

Epoch: 6| Step: 3
Training loss: 0.33624395542313285
Validation loss: 2.305469169172841

Epoch: 6| Step: 4
Training loss: 0.33461336392223395
Validation loss: 2.333995764796346

Epoch: 6| Step: 5
Training loss: 0.41956040549242024
Validation loss: 2.2841969446316184

Epoch: 6| Step: 6
Training loss: 0.29090233972420887
Validation loss: 2.294937787372804

Epoch: 6| Step: 7
Training loss: 0.3932535235543581
Validation loss: 2.309996362252557

Epoch: 6| Step: 8
Training loss: 0.27818510552624726
Validation loss: 2.358953627796416

Epoch: 6| Step: 9
Training loss: 0.747458801984166
Validation loss: 2.2171446853672525

Epoch: 6| Step: 10
Training loss: 0.4554313304049264
Validation loss: 2.345406807111667

Epoch: 6| Step: 11
Training loss: 0.35261147090985234
Validation loss: 2.3063436129074857

Epoch: 6| Step: 12
Training loss: 0.41621630489302225
Validation loss: 2.325565988430472

Epoch: 6| Step: 13
Training loss: 0.282864730184975
Validation loss: 2.331298730117626

Epoch: 253| Step: 0
Training loss: 0.29528783362174005
Validation loss: 2.336007141640167

Epoch: 6| Step: 1
Training loss: 0.3800759106656816
Validation loss: 2.3898926820429263

Epoch: 6| Step: 2
Training loss: 0.36740560344312423
Validation loss: 2.387112698921757

Epoch: 6| Step: 3
Training loss: 0.36394507761578476
Validation loss: 2.264788286771952

Epoch: 6| Step: 4
Training loss: 0.3962349130363667
Validation loss: 2.3173054434250657

Epoch: 6| Step: 5
Training loss: 0.2839060511402028
Validation loss: 2.2920139280831386

Epoch: 6| Step: 6
Training loss: 0.385278853272307
Validation loss: 2.276822789030142

Epoch: 6| Step: 7
Training loss: 0.2884265373312342
Validation loss: 2.3563377165045556

Epoch: 6| Step: 8
Training loss: 0.46857344163298575
Validation loss: 2.2606992823221215

Epoch: 6| Step: 9
Training loss: 0.47731485544712193
Validation loss: 2.297850870785418

Epoch: 6| Step: 10
Training loss: 0.21337217586561322
Validation loss: 2.3225977526194064

Epoch: 6| Step: 11
Training loss: 0.365980844056313
Validation loss: 2.3206720469628945

Epoch: 6| Step: 12
Training loss: 0.6842295278679045
Validation loss: 2.3367976515549533

Epoch: 6| Step: 13
Training loss: 0.4018137505755572
Validation loss: 2.3484417388870993

Epoch: 254| Step: 0
Training loss: 0.2198621289284967
Validation loss: 2.3062232638827806

Epoch: 6| Step: 1
Training loss: 0.29076331036638725
Validation loss: 2.241063340146604

Epoch: 6| Step: 2
Training loss: 0.5101304484410345
Validation loss: 2.3084392119362103

Epoch: 6| Step: 3
Training loss: 0.42813097190868504
Validation loss: 2.325593515066976

Epoch: 6| Step: 4
Training loss: 0.4282187762894797
Validation loss: 2.278275453529478

Epoch: 6| Step: 5
Training loss: 0.2751921621755535
Validation loss: 2.3457323295390906

Epoch: 6| Step: 6
Training loss: 0.21946879207736153
Validation loss: 2.359280691725151

Epoch: 6| Step: 7
Training loss: 0.35608173797018516
Validation loss: 2.326650310334077

Epoch: 6| Step: 8
Training loss: 0.7897816015709227
Validation loss: 2.38095141830879

Epoch: 6| Step: 9
Training loss: 0.28123556205990263
Validation loss: 2.3316193370728167

Epoch: 6| Step: 10
Training loss: 0.34897846429557655
Validation loss: 2.300674418725493

Epoch: 6| Step: 11
Training loss: 0.35868871507639916
Validation loss: 2.337920029109245

Epoch: 6| Step: 12
Training loss: 0.39079559415766213
Validation loss: 2.356515174332846

Epoch: 6| Step: 13
Training loss: 0.42080938897455267
Validation loss: 2.3154592910347898

Epoch: 255| Step: 0
Training loss: 0.268442359320786
Validation loss: 2.3692487213473727

Epoch: 6| Step: 1
Training loss: 0.2289472806826742
Validation loss: 2.3551807807436638

Epoch: 6| Step: 2
Training loss: 0.6315481482700857
Validation loss: 2.3987174766393786

Epoch: 6| Step: 3
Training loss: 0.40952706897730634
Validation loss: 2.359288228778295

Epoch: 6| Step: 4
Training loss: 0.3221337135144509
Validation loss: 2.3340487547099564

Epoch: 6| Step: 5
Training loss: 0.5252143535801106
Validation loss: 2.341194438040817

Epoch: 6| Step: 6
Training loss: 0.3415678837588341
Validation loss: 2.3471684258470273

Epoch: 6| Step: 7
Training loss: 0.46322098544271795
Validation loss: 2.3423841268785486

Epoch: 6| Step: 8
Training loss: 0.3327832625535384
Validation loss: 2.3556612778526382

Epoch: 6| Step: 9
Training loss: 0.3817915049113397
Validation loss: 2.3241469684703913

Epoch: 6| Step: 10
Training loss: 0.3047602151030224
Validation loss: 2.3493163575375666

Epoch: 6| Step: 11
Training loss: 0.3593600311478978
Validation loss: 2.3525530565436013

Epoch: 6| Step: 12
Training loss: 0.33795144520484577
Validation loss: 2.303675922010719

Epoch: 6| Step: 13
Training loss: 0.36398124934203563
Validation loss: 2.2575658995739163

Epoch: 256| Step: 0
Training loss: 0.5657505844389644
Validation loss: 2.311254561182325

Epoch: 6| Step: 1
Training loss: 0.4079545099000488
Validation loss: 2.3189256078914853

Epoch: 6| Step: 2
Training loss: 0.45998973715777786
Validation loss: 2.3691472669038185

Epoch: 6| Step: 3
Training loss: 0.36193672681517397
Validation loss: 2.3145044248665956

Epoch: 6| Step: 4
Training loss: 0.6877849811835968
Validation loss: 2.337087681898276

Epoch: 6| Step: 5
Training loss: 0.2489418644159756
Validation loss: 2.3085821229972163

Epoch: 6| Step: 6
Training loss: 0.47714594786873193
Validation loss: 2.339847588045075

Epoch: 6| Step: 7
Training loss: 0.49308063065729063
Validation loss: 2.3257728317667077

Epoch: 6| Step: 8
Training loss: 0.44039554844260004
Validation loss: 2.324561094401155

Epoch: 6| Step: 9
Training loss: 0.3084857486102446
Validation loss: 2.3002504212427057

Epoch: 6| Step: 10
Training loss: 0.4223900053356794
Validation loss: 2.2960928625429804

Epoch: 6| Step: 11
Training loss: 0.3893520212511186
Validation loss: 2.2936002434705896

Epoch: 6| Step: 12
Training loss: 0.3144621995836747
Validation loss: 2.3135886679771067

Epoch: 6| Step: 13
Training loss: 0.35705071861559096
Validation loss: 2.342104609750844

Epoch: 257| Step: 0
Training loss: 0.39913576312416416
Validation loss: 2.3021504462860594

Epoch: 6| Step: 1
Training loss: 0.346686371215006
Validation loss: 2.252945226233484

Epoch: 6| Step: 2
Training loss: 0.34161506176858
Validation loss: 2.299021334376162

Epoch: 6| Step: 3
Training loss: 0.3913233427462637
Validation loss: 2.2634085501231342

Epoch: 6| Step: 4
Training loss: 0.26671949859138655
Validation loss: 2.335289906836967

Epoch: 6| Step: 5
Training loss: 0.7431681127851397
Validation loss: 2.3360336096819236

Epoch: 6| Step: 6
Training loss: 0.5156800789748145
Validation loss: 2.242534012552504

Epoch: 6| Step: 7
Training loss: 0.4169443178953238
Validation loss: 2.293449234538057

Epoch: 6| Step: 8
Training loss: 0.32939451858335006
Validation loss: 2.3315884389654284

Epoch: 6| Step: 9
Training loss: 0.4095271417498335
Validation loss: 2.3034841380825233

Epoch: 6| Step: 10
Training loss: 0.38197889846918565
Validation loss: 2.2695272142524314

Epoch: 6| Step: 11
Training loss: 0.2935575544733794
Validation loss: 2.2739156633102415

Epoch: 6| Step: 12
Training loss: 0.3741951889234443
Validation loss: 2.3967204953048102

Epoch: 6| Step: 13
Training loss: 0.38729805375582066
Validation loss: 2.2588194259447727

Epoch: 258| Step: 0
Training loss: 0.3544314624068328
Validation loss: 2.2444309083396132

Epoch: 6| Step: 1
Training loss: 0.24871615730752747
Validation loss: 2.3018141944484936

Epoch: 6| Step: 2
Training loss: 0.4116102332586375
Validation loss: 2.3652878830577446

Epoch: 6| Step: 3
Training loss: 0.2902869119238801
Validation loss: 2.28647000621924

Epoch: 6| Step: 4
Training loss: 0.3991890345672788
Validation loss: 2.36483434501553

Epoch: 6| Step: 5
Training loss: 0.2900896509923272
Validation loss: 2.3199542932557127

Epoch: 6| Step: 6
Training loss: 0.31923278402436445
Validation loss: 2.34314038295789

Epoch: 6| Step: 7
Training loss: 0.44968386910399566
Validation loss: 2.31440887194255

Epoch: 6| Step: 8
Training loss: 0.2384453193012373
Validation loss: 2.29853746796262

Epoch: 6| Step: 9
Training loss: 0.23424874719938168
Validation loss: 2.3042307255574004

Epoch: 6| Step: 10
Training loss: 0.6951179017773115
Validation loss: 2.2990691934487875

Epoch: 6| Step: 11
Training loss: 0.4740848389896286
Validation loss: 2.3241997469598017

Epoch: 6| Step: 12
Training loss: 0.3269346307152045
Validation loss: 2.34724333776824

Epoch: 6| Step: 13
Training loss: 0.4187635547664624
Validation loss: 2.3338744921069843

Epoch: 259| Step: 0
Training loss: 0.22636032949859788
Validation loss: 2.2603722463951503

Epoch: 6| Step: 1
Training loss: 0.6455865255082986
Validation loss: 2.326644307122916

Epoch: 6| Step: 2
Training loss: 0.5071890892431682
Validation loss: 2.267554958508832

Epoch: 6| Step: 3
Training loss: 0.3940370883053804
Validation loss: 2.279881009976126

Epoch: 6| Step: 4
Training loss: 0.322420129440829
Validation loss: 2.2637438539126324

Epoch: 6| Step: 5
Training loss: 0.35721569680884807
Validation loss: 2.3571984733829487

Epoch: 6| Step: 6
Training loss: 0.2907913931461667
Validation loss: 2.2524473514253773

Epoch: 6| Step: 7
Training loss: 0.31768819349064276
Validation loss: 2.329008852048512

Epoch: 6| Step: 8
Training loss: 0.24845546201635146
Validation loss: 2.294541339031652

Epoch: 6| Step: 9
Training loss: 0.3832125616904575
Validation loss: 2.2802188929392733

Epoch: 6| Step: 10
Training loss: 0.417974864166318
Validation loss: 2.3170448010629516

Epoch: 6| Step: 11
Training loss: 0.3188446652329083
Validation loss: 2.3287270213488367

Epoch: 6| Step: 12
Training loss: 0.4057015972376809
Validation loss: 2.269403284418933

Epoch: 6| Step: 13
Training loss: 0.5280716570036423
Validation loss: 2.363859012483196

Epoch: 260| Step: 0
Training loss: 0.5354199281981562
Validation loss: 2.3618669549825695

Epoch: 6| Step: 1
Training loss: 0.21518541391886634
Validation loss: 2.306153325895011

Epoch: 6| Step: 2
Training loss: 0.22098185231656217
Validation loss: 2.2564826489629612

Epoch: 6| Step: 3
Training loss: 0.41920121920140796
Validation loss: 2.338434685608498

Epoch: 6| Step: 4
Training loss: 0.4481623792554363
Validation loss: 2.3087900490308657

Epoch: 6| Step: 5
Training loss: 0.46448854290513475
Validation loss: 2.3101366613540373

Epoch: 6| Step: 6
Training loss: 0.3176290173357214
Validation loss: 2.3268285807131646

Epoch: 6| Step: 7
Training loss: 0.38685651694965784
Validation loss: 2.2615792643788546

Epoch: 6| Step: 8
Training loss: 0.7334795016861537
Validation loss: 2.240837550312395

Epoch: 6| Step: 9
Training loss: 0.36523155986496547
Validation loss: 2.283154045732659

Epoch: 6| Step: 10
Training loss: 0.2649182847729473
Validation loss: 2.323054328112387

Epoch: 6| Step: 11
Training loss: 0.22146785378439623
Validation loss: 2.328579237487698

Epoch: 6| Step: 12
Training loss: 0.34801445412900195
Validation loss: 2.3265287572336537

Epoch: 6| Step: 13
Training loss: 0.38272301932107755
Validation loss: 2.2630110909823307

Epoch: 261| Step: 0
Training loss: 0.5887472811917582
Validation loss: 2.3402808900303684

Epoch: 6| Step: 1
Training loss: 0.2858484436972654
Validation loss: 2.316994226291813

Epoch: 6| Step: 2
Training loss: 0.3592212182118234
Validation loss: 2.3322220239184346

Epoch: 6| Step: 3
Training loss: 0.46302267195083024
Validation loss: 2.3302052567901788

Epoch: 6| Step: 4
Training loss: 0.4013544345138346
Validation loss: 2.3221381269810397

Epoch: 6| Step: 5
Training loss: 0.45079804493311776
Validation loss: 2.295855972976891

Epoch: 6| Step: 6
Training loss: 0.45877096206212603
Validation loss: 2.2906970978579926

Epoch: 6| Step: 7
Training loss: 0.2571830289783481
Validation loss: 2.3155999069467326

Epoch: 6| Step: 8
Training loss: 0.3993649254305757
Validation loss: 2.307974924455415

Epoch: 6| Step: 9
Training loss: 0.430586135284204
Validation loss: 2.3276212006346304

Epoch: 6| Step: 10
Training loss: 0.3233901777063924
Validation loss: 2.25879054022055

Epoch: 6| Step: 11
Training loss: 0.5577116183142756
Validation loss: 2.2885586614821305

Epoch: 6| Step: 12
Training loss: 0.20935337965633202
Validation loss: 2.34633927476386

Epoch: 6| Step: 13
Training loss: 0.33042462913392506
Validation loss: 2.300518372764478

Epoch: 262| Step: 0
Training loss: 0.3451426429190451
Validation loss: 2.3329967159466682

Epoch: 6| Step: 1
Training loss: 0.38301143537536303
Validation loss: 2.31546188239866

Epoch: 6| Step: 2
Training loss: 0.37214173359867353
Validation loss: 2.274954081340913

Epoch: 6| Step: 3
Training loss: 0.637276224055459
Validation loss: 2.336984958787449

Epoch: 6| Step: 4
Training loss: 0.5118409804333237
Validation loss: 2.2966276887715193

Epoch: 6| Step: 5
Training loss: 0.4869391957026919
Validation loss: 2.2819772545262964

Epoch: 6| Step: 6
Training loss: 0.5928092329853226
Validation loss: 2.3233147067723983

Epoch: 6| Step: 7
Training loss: 0.27014888265789233
Validation loss: 2.3409856643172637

Epoch: 6| Step: 8
Training loss: 0.3201308316761265
Validation loss: 2.313205662877056

Epoch: 6| Step: 9
Training loss: 0.31834282861315816
Validation loss: 2.356012461904588

Epoch: 6| Step: 10
Training loss: 0.323513689143587
Validation loss: 2.311494178946728

Epoch: 6| Step: 11
Training loss: 0.34498354273049986
Validation loss: 2.3263639322210654

Epoch: 6| Step: 12
Training loss: 0.3769883845940554
Validation loss: 2.3226449719157447

Epoch: 6| Step: 13
Training loss: 0.42483692266121004
Validation loss: 2.2528786435054315

Epoch: 263| Step: 0
Training loss: 0.2955468484191318
Validation loss: 2.270338019034864

Epoch: 6| Step: 1
Training loss: 0.28979015266074154
Validation loss: 2.3617409807177476

Epoch: 6| Step: 2
Training loss: 0.4842289119810002
Validation loss: 2.294971568333877

Epoch: 6| Step: 3
Training loss: 0.7445158325392287
Validation loss: 2.2850965704012536

Epoch: 6| Step: 4
Training loss: 0.43735603961256736
Validation loss: 2.3257382851176134

Epoch: 6| Step: 5
Training loss: 0.408968887108714
Validation loss: 2.2632935289816434

Epoch: 6| Step: 6
Training loss: 0.4109962218359231
Validation loss: 2.2969883655070213

Epoch: 6| Step: 7
Training loss: 0.43070002814386477
Validation loss: 2.2927708017752373

Epoch: 6| Step: 8
Training loss: 0.3045468005520373
Validation loss: 2.279043166622871

Epoch: 6| Step: 9
Training loss: 0.2594978845726917
Validation loss: 2.2961555703671173

Epoch: 6| Step: 10
Training loss: 0.33177018841731193
Validation loss: 2.2911828715273326

Epoch: 6| Step: 11
Training loss: 0.41846696625959573
Validation loss: 2.3038852049516514

Epoch: 6| Step: 12
Training loss: 0.4470296178772621
Validation loss: 2.3149139246033203

Epoch: 6| Step: 13
Training loss: 0.355085396770888
Validation loss: 2.266215999297015

Epoch: 264| Step: 0
Training loss: 0.30699212890344857
Validation loss: 2.279087408966996

Epoch: 6| Step: 1
Training loss: 0.4352930638067614
Validation loss: 2.283558239499228

Epoch: 6| Step: 2
Training loss: 0.5428656061577576
Validation loss: 2.3195841766825502

Epoch: 6| Step: 3
Training loss: 0.6241199496382146
Validation loss: 2.293762884008549

Epoch: 6| Step: 4
Training loss: 0.2833211192602507
Validation loss: 2.2676339198741498

Epoch: 6| Step: 5
Training loss: 0.3652175042646961
Validation loss: 2.307761173973214

Epoch: 6| Step: 6
Training loss: 0.36013026278197896
Validation loss: 2.320304194134746

Epoch: 6| Step: 7
Training loss: 0.44559274187541803
Validation loss: 2.289398081964524

Epoch: 6| Step: 8
Training loss: 0.5240961173005627
Validation loss: 2.296979179528216

Epoch: 6| Step: 9
Training loss: 0.35608029422553733
Validation loss: 2.351665684663535

Epoch: 6| Step: 10
Training loss: 0.3889004212705528
Validation loss: 2.304916973866708

Epoch: 6| Step: 11
Training loss: 0.5174628939202501
Validation loss: 2.2751586097230168

Epoch: 6| Step: 12
Training loss: 0.40871807635756596
Validation loss: 2.3172740972400976

Epoch: 6| Step: 13
Training loss: 0.3614515969952347
Validation loss: 2.352736981381121

Epoch: 265| Step: 0
Training loss: 0.41226381418229135
Validation loss: 2.306884873282168

Epoch: 6| Step: 1
Training loss: 0.3046932586712597
Validation loss: 2.3285204148367264

Epoch: 6| Step: 2
Training loss: 0.40796859063299157
Validation loss: 2.4181570905178162

Epoch: 6| Step: 3
Training loss: 0.2550596303500304
Validation loss: 2.26136677780851

Epoch: 6| Step: 4
Training loss: 0.3133471569455477
Validation loss: 2.355457480906052

Epoch: 6| Step: 5
Training loss: 0.2718547380504576
Validation loss: 2.298301081063429

Epoch: 6| Step: 6
Training loss: 0.3590226311789257
Validation loss: 2.363643734037917

Epoch: 6| Step: 7
Training loss: 0.4855655835353651
Validation loss: 2.3111398494392716

Epoch: 6| Step: 8
Training loss: 0.30840269041118623
Validation loss: 2.351137251651034

Epoch: 6| Step: 9
Training loss: 0.6274855305040697
Validation loss: 2.325132934981152

Epoch: 6| Step: 10
Training loss: 0.2788912355030633
Validation loss: 2.3373421960830583

Epoch: 6| Step: 11
Training loss: 0.43846368239756356
Validation loss: 2.331168674962955

Epoch: 6| Step: 12
Training loss: 0.4818075337908039
Validation loss: 2.3548185126855454

Epoch: 6| Step: 13
Training loss: 0.2999361973706603
Validation loss: 2.3657606165792595

Epoch: 266| Step: 0
Training loss: 0.213815177620271
Validation loss: 2.2888302994480227

Epoch: 6| Step: 1
Training loss: 0.49194408634406583
Validation loss: 2.339112453568587

Epoch: 6| Step: 2
Training loss: 0.4429230917084494
Validation loss: 2.2648973195237887

Epoch: 6| Step: 3
Training loss: 0.6200229362890582
Validation loss: 2.31115732649858

Epoch: 6| Step: 4
Training loss: 0.33881738390179467
Validation loss: 2.250444951036544

Epoch: 6| Step: 5
Training loss: 0.30184098366001794
Validation loss: 2.2863640617337118

Epoch: 6| Step: 6
Training loss: 0.35458219452184625
Validation loss: 2.2860102522201013

Epoch: 6| Step: 7
Training loss: 0.30570176839588414
Validation loss: 2.34041215364296

Epoch: 6| Step: 8
Training loss: 0.32780422698455686
Validation loss: 2.306704053833046

Epoch: 6| Step: 9
Training loss: 0.24667228331217636
Validation loss: 2.251093369195724

Epoch: 6| Step: 10
Training loss: 0.37537841777026815
Validation loss: 2.3213866430904724

Epoch: 6| Step: 11
Training loss: 0.30483555253355854
Validation loss: 2.3091523451574956

Epoch: 6| Step: 12
Training loss: 0.36701661049467205
Validation loss: 2.3040697207299563

Epoch: 6| Step: 13
Training loss: 0.2838866436895554
Validation loss: 2.3390075514052975

Epoch: 267| Step: 0
Training loss: 0.3263115612316821
Validation loss: 2.3140909032218295

Epoch: 6| Step: 1
Training loss: 0.33455808342153337
Validation loss: 2.3011763556730394

Epoch: 6| Step: 2
Training loss: 0.3790048687201931
Validation loss: 2.276996173801818

Epoch: 6| Step: 3
Training loss: 0.24237147388480393
Validation loss: 2.3254552805604747

Epoch: 6| Step: 4
Training loss: 0.33354083943706214
Validation loss: 2.3349728500889833

Epoch: 6| Step: 5
Training loss: 0.27374117201240045
Validation loss: 2.279109708526435

Epoch: 6| Step: 6
Training loss: 0.3853731732271039
Validation loss: 2.307412522525582

Epoch: 6| Step: 7
Training loss: 0.3157618990579254
Validation loss: 2.2987683595522626

Epoch: 6| Step: 8
Training loss: 0.27536728942697775
Validation loss: 2.2878170509399065

Epoch: 6| Step: 9
Training loss: 0.2821573350737424
Validation loss: 2.322168928378483

Epoch: 6| Step: 10
Training loss: 0.43735123557403255
Validation loss: 2.3394467755278923

Epoch: 6| Step: 11
Training loss: 0.6307148723625796
Validation loss: 2.3067177488572956

Epoch: 6| Step: 12
Training loss: 0.30587421298422696
Validation loss: 2.3104556128266704

Epoch: 6| Step: 13
Training loss: 0.4373509970742907
Validation loss: 2.2854066716975057

Epoch: 268| Step: 0
Training loss: 0.3001649413074242
Validation loss: 2.275467297486036

Epoch: 6| Step: 1
Training loss: 0.29741981357334035
Validation loss: 2.237752961931686

Epoch: 6| Step: 2
Training loss: 0.32335608973542734
Validation loss: 2.285710698434308

Epoch: 6| Step: 3
Training loss: 0.36682886506189705
Validation loss: 2.2845335630953016

Epoch: 6| Step: 4
Training loss: 0.41737334009042104
Validation loss: 2.261649877963328

Epoch: 6| Step: 5
Training loss: 0.3411453140293663
Validation loss: 2.2951013719419957

Epoch: 6| Step: 6
Training loss: 0.33080467979042494
Validation loss: 2.2906759519231557

Epoch: 6| Step: 7
Training loss: 0.48056556532595723
Validation loss: 2.305768853078602

Epoch: 6| Step: 8
Training loss: 0.3239799677298614
Validation loss: 2.317619362027086

Epoch: 6| Step: 9
Training loss: 0.24284587862659818
Validation loss: 2.259113055988129

Epoch: 6| Step: 10
Training loss: 0.5009537184119134
Validation loss: 2.309548255433346

Epoch: 6| Step: 11
Training loss: 0.3705747890715522
Validation loss: 2.243457111308881

Epoch: 6| Step: 12
Training loss: 0.4000976979630653
Validation loss: 2.285629188743079

Epoch: 6| Step: 13
Training loss: 0.5723408464071201
Validation loss: 2.266917752168759

Epoch: 269| Step: 0
Training loss: 0.2778586859227684
Validation loss: 2.3595999806233556

Epoch: 6| Step: 1
Training loss: 0.3605656181910789
Validation loss: 2.301323197012437

Epoch: 6| Step: 2
Training loss: 0.22795471407042087
Validation loss: 2.3101451929847157

Epoch: 6| Step: 3
Training loss: 0.4013856015772918
Validation loss: 2.285735541057531

Epoch: 6| Step: 4
Training loss: 0.20915829026375432
Validation loss: 2.2683539956595475

Epoch: 6| Step: 5
Training loss: 0.32706147361811555
Validation loss: 2.279621396447434

Epoch: 6| Step: 6
Training loss: 0.27577103387859403
Validation loss: 2.239449046049335

Epoch: 6| Step: 7
Training loss: 0.29837258217051305
Validation loss: 2.336501734876543

Epoch: 6| Step: 8
Training loss: 0.6767019273546996
Validation loss: 2.3210904308300924

Epoch: 6| Step: 9
Training loss: 0.42464903687480515
Validation loss: 2.3032993511181092

Epoch: 6| Step: 10
Training loss: 0.2590199717918453
Validation loss: 2.307720907912353

Epoch: 6| Step: 11
Training loss: 0.4483520439679923
Validation loss: 2.2737951008366126

Epoch: 6| Step: 12
Training loss: 0.3837106250853705
Validation loss: 2.3492324539459766

Epoch: 6| Step: 13
Training loss: 0.47086434353627515
Validation loss: 2.281518214932006

Epoch: 270| Step: 0
Training loss: 0.51171875
Validation loss: 2.3235206731067164

Epoch: 6| Step: 1
Training loss: 0.345414682519887
Validation loss: 2.305789757199522

Epoch: 6| Step: 2
Training loss: 0.4144359020569954
Validation loss: 2.306074012030711

Epoch: 6| Step: 3
Training loss: 0.5144824750286325
Validation loss: 2.32280852974167

Epoch: 6| Step: 4
Training loss: 0.3066361663882973
Validation loss: 2.272246110873987

Epoch: 6| Step: 5
Training loss: 0.45441788351662166
Validation loss: 2.326844172424219

Epoch: 6| Step: 6
Training loss: 0.4690539328385553
Validation loss: 2.3057104566797446

Epoch: 6| Step: 7
Training loss: 0.4021189533854553
Validation loss: 2.3330776948763163

Epoch: 6| Step: 8
Training loss: 0.23098227300476473
Validation loss: 2.323187753799462

Epoch: 6| Step: 9
Training loss: 0.3821108479647889
Validation loss: 2.347859657856905

Epoch: 6| Step: 10
Training loss: 0.29912132639289
Validation loss: 2.259139167292765

Epoch: 6| Step: 11
Training loss: 0.34597934313050044
Validation loss: 2.280837513807501

Epoch: 6| Step: 12
Training loss: 0.21868071139936351
Validation loss: 2.3175001643845032

Epoch: 6| Step: 13
Training loss: 0.4101844232964901
Validation loss: 2.316358834907677

Epoch: 271| Step: 0
Training loss: 0.4713311180956786
Validation loss: 2.316307867747437

Epoch: 6| Step: 1
Training loss: 0.3763853154867164
Validation loss: 2.318711093188879

Epoch: 6| Step: 2
Training loss: 0.3828774221993152
Validation loss: 2.285737088279857

Epoch: 6| Step: 3
Training loss: 0.3273742579626156
Validation loss: 2.28013609772767

Epoch: 6| Step: 4
Training loss: 0.22864276251037824
Validation loss: 2.254103539006576

Epoch: 6| Step: 5
Training loss: 0.35744246960283715
Validation loss: 2.2971004107323862

Epoch: 6| Step: 6
Training loss: 0.611278154079729
Validation loss: 2.3607178039461356

Epoch: 6| Step: 7
Training loss: 0.3470821998977625
Validation loss: 2.300547909089704

Epoch: 6| Step: 8
Training loss: 0.366721283392329
Validation loss: 2.326520934714628

Epoch: 6| Step: 9
Training loss: 0.28001496894452627
Validation loss: 2.296818479504281

Epoch: 6| Step: 10
Training loss: 0.24143521311074595
Validation loss: 2.2743634133263493

Epoch: 6| Step: 11
Training loss: 0.30446030631539167
Validation loss: 2.30630334794147

Epoch: 6| Step: 12
Training loss: 0.4204518544499935
Validation loss: 2.3466771136759363

Epoch: 6| Step: 13
Training loss: 0.4339422251836796
Validation loss: 2.3125154907120127

Epoch: 272| Step: 0
Training loss: 0.43758091859448484
Validation loss: 2.2620954007763556

Epoch: 6| Step: 1
Training loss: 0.292658145285364
Validation loss: 2.280944568619422

Epoch: 6| Step: 2
Training loss: 0.3481333277372295
Validation loss: 2.2522254551998815

Epoch: 6| Step: 3
Training loss: 0.5792794943303057
Validation loss: 2.2722148251069822

Epoch: 6| Step: 4
Training loss: 0.5203879613826786
Validation loss: 2.2915157152802736

Epoch: 6| Step: 5
Training loss: 0.44079288977095615
Validation loss: 2.3384936412023114

Epoch: 6| Step: 6
Training loss: 0.21875367842714996
Validation loss: 2.2548028847224626

Epoch: 6| Step: 7
Training loss: 0.30167721162634814
Validation loss: 2.2977054418170426

Epoch: 6| Step: 8
Training loss: 0.3796214795896145
Validation loss: 2.3031701993194913

Epoch: 6| Step: 9
Training loss: 0.2943609473848953
Validation loss: 2.2831238579784188

Epoch: 6| Step: 10
Training loss: 0.3692423362479005
Validation loss: 2.2832781167790785

Epoch: 6| Step: 11
Training loss: 0.37247911157861346
Validation loss: 2.2885869631294753

Epoch: 6| Step: 12
Training loss: 0.459793497697543
Validation loss: 2.3395316245348097

Epoch: 6| Step: 13
Training loss: 0.4504813818296773
Validation loss: 2.333741481597234

Epoch: 273| Step: 0
Training loss: 0.31187084760940353
Validation loss: 2.3597581059740693

Epoch: 6| Step: 1
Training loss: 0.2655900483417111
Validation loss: 2.3497331163351975

Epoch: 6| Step: 2
Training loss: 0.3165529405557013
Validation loss: 2.2766089499889834

Epoch: 6| Step: 3
Training loss: 0.19808356981586991
Validation loss: 2.3207933503501557

Epoch: 6| Step: 4
Training loss: 0.6724102195030083
Validation loss: 2.3012185407094434

Epoch: 6| Step: 5
Training loss: 0.3904799955167557
Validation loss: 2.242854817649277

Epoch: 6| Step: 6
Training loss: 0.3863987224630794
Validation loss: 2.2785724795205677

Epoch: 6| Step: 7
Training loss: 0.23713969550547853
Validation loss: 2.299666648010277

Epoch: 6| Step: 8
Training loss: 0.46195041763438727
Validation loss: 2.322372036253261

Epoch: 6| Step: 9
Training loss: 0.36792417446582226
Validation loss: 2.3201525683359567

Epoch: 6| Step: 10
Training loss: 0.39252465866163433
Validation loss: 2.294683695668825

Epoch: 6| Step: 11
Training loss: 0.36714269486445456
Validation loss: 2.28645035055124

Epoch: 6| Step: 12
Training loss: 0.32300577421164567
Validation loss: 2.2624474528131078

Epoch: 6| Step: 13
Training loss: 0.2954751944078696
Validation loss: 2.299416716531509

Epoch: 274| Step: 0
Training loss: 0.2944363013502034
Validation loss: 2.312892777361881

Epoch: 6| Step: 1
Training loss: 0.39808725408681295
Validation loss: 2.291108017077712

Epoch: 6| Step: 2
Training loss: 0.4695413585215784
Validation loss: 2.300813857118971

Epoch: 6| Step: 3
Training loss: 0.3572513194236656
Validation loss: 2.31661233312255

Epoch: 6| Step: 4
Training loss: 0.3057574047367886
Validation loss: 2.2878075502360584

Epoch: 6| Step: 5
Training loss: 0.3748414578671835
Validation loss: 2.2927401167107804

Epoch: 6| Step: 6
Training loss: 0.3623843658108043
Validation loss: 2.2902658660647797

Epoch: 6| Step: 7
Training loss: 0.6860216458439462
Validation loss: 2.3420049995371173

Epoch: 6| Step: 8
Training loss: 0.34167793384248946
Validation loss: 2.3798400098655934

Epoch: 6| Step: 9
Training loss: 0.3634709918924072
Validation loss: 2.27860043435057

Epoch: 6| Step: 10
Training loss: 0.42538319801033275
Validation loss: 2.311066569862957

Epoch: 6| Step: 11
Training loss: 0.5205668975904474
Validation loss: 2.276932170442318

Epoch: 6| Step: 12
Training loss: 0.4681552610815319
Validation loss: 2.32438914638754

Epoch: 6| Step: 13
Training loss: 0.32467169318397615
Validation loss: 2.3514376213229777

Epoch: 275| Step: 0
Training loss: 0.61258614381967
Validation loss: 2.33239001267945

Epoch: 6| Step: 1
Training loss: 0.3330412817102125
Validation loss: 2.3325961572003098

Epoch: 6| Step: 2
Training loss: 0.4153166437337003
Validation loss: 2.2808501271986295

Epoch: 6| Step: 3
Training loss: 0.4476650570041399
Validation loss: 2.3259087837370576

Epoch: 6| Step: 4
Training loss: 0.40939551149189696
Validation loss: 2.336120266606003

Epoch: 6| Step: 5
Training loss: 0.4038947865613645
Validation loss: 2.3309773289927986

Epoch: 6| Step: 6
Training loss: 0.4271982918292177
Validation loss: 2.2697448017195145

Epoch: 6| Step: 7
Training loss: 0.38546534394118975
Validation loss: 2.287078987525633

Epoch: 6| Step: 8
Training loss: 0.490292245557144
Validation loss: 2.304986173597946

Epoch: 6| Step: 9
Training loss: 0.3308646407716065
Validation loss: 2.308691961842574

Epoch: 6| Step: 10
Training loss: 0.3457511717603388
Validation loss: 2.319527490033976

Epoch: 6| Step: 11
Training loss: 0.2971205950335449
Validation loss: 2.2586115266919986

Epoch: 6| Step: 12
Training loss: 0.38752081569014446
Validation loss: 2.2535980913080347

Epoch: 6| Step: 13
Training loss: 0.32754541480786126
Validation loss: 2.240155317025129

Epoch: 276| Step: 0
Training loss: 0.2873954645098958
Validation loss: 2.2468522093231145

Epoch: 6| Step: 1
Training loss: 0.4358383024830782
Validation loss: 2.2346501036548356

Epoch: 6| Step: 2
Training loss: 0.2544287513956751
Validation loss: 2.3115553515924834

Epoch: 6| Step: 3
Training loss: 0.26405905094941484
Validation loss: 2.2864326064299676

Epoch: 6| Step: 4
Training loss: 0.3531067733786968
Validation loss: 2.2176404426280287

Epoch: 6| Step: 5
Training loss: 0.552112485607772
Validation loss: 2.302686160690735

Epoch: 6| Step: 6
Training loss: 0.2974082524411681
Validation loss: 2.26479904202612

Epoch: 6| Step: 7
Training loss: 0.3449095545606371
Validation loss: 2.2609750494555345

Epoch: 6| Step: 8
Training loss: 0.26683620983942513
Validation loss: 2.2585625112267396

Epoch: 6| Step: 9
Training loss: 0.31197423814288794
Validation loss: 2.2155506725963185

Epoch: 6| Step: 10
Training loss: 0.3273915540435955
Validation loss: 2.205668448941473

Epoch: 6| Step: 11
Training loss: 0.4167403771846148
Validation loss: 2.3117174508453293

Epoch: 6| Step: 12
Training loss: 0.36363662237461597
Validation loss: 2.2717279777546717

Epoch: 6| Step: 13
Training loss: 0.49494625654734636
Validation loss: 2.208526195045757

Epoch: 277| Step: 0
Training loss: 0.27639578950969357
Validation loss: 2.272995354129213

Epoch: 6| Step: 1
Training loss: 0.40298102195604674
Validation loss: 2.2320620785583563

Epoch: 6| Step: 2
Training loss: 0.5559659114565991
Validation loss: 2.273695032099498

Epoch: 6| Step: 3
Training loss: 0.4494619291793594
Validation loss: 2.3146451760404454

Epoch: 6| Step: 4
Training loss: 0.3772108155813613
Validation loss: 2.2506179579088164

Epoch: 6| Step: 5
Training loss: 0.3565962798343345
Validation loss: 2.243998824891606

Epoch: 6| Step: 6
Training loss: 0.36459324914072755
Validation loss: 2.2773517937842596

Epoch: 6| Step: 7
Training loss: 0.40332116226217607
Validation loss: 2.2786740081498458

Epoch: 6| Step: 8
Training loss: 0.4368088405814446
Validation loss: 2.2527874352023014

Epoch: 6| Step: 9
Training loss: 0.33200791220831005
Validation loss: 2.2777399554898716

Epoch: 6| Step: 10
Training loss: 0.3591157143703886
Validation loss: 2.281685112692161

Epoch: 6| Step: 11
Training loss: 0.29713453693354386
Validation loss: 2.253980109791295

Epoch: 6| Step: 12
Training loss: 0.2690777210976631
Validation loss: 2.262786156558481

Epoch: 6| Step: 13
Training loss: 0.2661352585982901
Validation loss: 2.2794779596905306

Epoch: 278| Step: 0
Training loss: 0.255528607486713
Validation loss: 2.327498247068778

Epoch: 6| Step: 1
Training loss: 0.4440752543282829
Validation loss: 2.3040073490307083

Epoch: 6| Step: 2
Training loss: 0.28170950757531277
Validation loss: 2.3037596823146815

Epoch: 6| Step: 3
Training loss: 0.5970548209095168
Validation loss: 2.26341418559628

Epoch: 6| Step: 4
Training loss: 0.41956386830064013
Validation loss: 2.266528035113146

Epoch: 6| Step: 5
Training loss: 0.3777246830987835
Validation loss: 2.296585341546857

Epoch: 6| Step: 6
Training loss: 0.38119548736199865
Validation loss: 2.30704715429177

Epoch: 6| Step: 7
Training loss: 0.2876230432675086
Validation loss: 2.2389306706878096

Epoch: 6| Step: 8
Training loss: 0.28712084481301303
Validation loss: 2.3021869003221243

Epoch: 6| Step: 9
Training loss: 0.34225231889269353
Validation loss: 2.260476948041239

Epoch: 6| Step: 10
Training loss: 0.23527938875781285
Validation loss: 2.342905460362299

Epoch: 6| Step: 11
Training loss: 0.28491314231600323
Validation loss: 2.392193481251793

Epoch: 6| Step: 12
Training loss: 0.4559109969930359
Validation loss: 2.3145200395099086

Epoch: 6| Step: 13
Training loss: 0.3579611956541473
Validation loss: 2.3461026230816935

Epoch: 279| Step: 0
Training loss: 0.4229714838058683
Validation loss: 2.2601883299742305

Epoch: 6| Step: 1
Training loss: 0.3041677810809653
Validation loss: 2.2807994728608705

Epoch: 6| Step: 2
Training loss: 0.3014093504291895
Validation loss: 2.316288336614833

Epoch: 6| Step: 3
Training loss: 0.3218035882600113
Validation loss: 2.2797638742413966

Epoch: 6| Step: 4
Training loss: 0.2798998665788189
Validation loss: 2.271168497415112

Epoch: 6| Step: 5
Training loss: 0.5745773493220279
Validation loss: 2.330606507780122

Epoch: 6| Step: 6
Training loss: 0.2765716227950306
Validation loss: 2.3218873798490423

Epoch: 6| Step: 7
Training loss: 0.3260986108787754
Validation loss: 2.308795840502411

Epoch: 6| Step: 8
Training loss: 0.44513565031881397
Validation loss: 2.2737105774708093

Epoch: 6| Step: 9
Training loss: 0.40590150263861313
Validation loss: 2.293446722258562

Epoch: 6| Step: 10
Training loss: 0.34296620483149215
Validation loss: 2.275320175892144

Epoch: 6| Step: 11
Training loss: 0.20768591101351677
Validation loss: 2.3340926779674205

Epoch: 6| Step: 12
Training loss: 0.45751230077414273
Validation loss: 2.336411784152387

Epoch: 6| Step: 13
Training loss: 0.5912708676790935
Validation loss: 2.2711498028312063

Epoch: 280| Step: 0
Training loss: 0.3186454891457787
Validation loss: 2.2606395283426335

Epoch: 6| Step: 1
Training loss: 0.25859027641245325
Validation loss: 2.2984262102663657

Epoch: 6| Step: 2
Training loss: 0.6154129980034321
Validation loss: 2.305469875837409

Epoch: 6| Step: 3
Training loss: 0.5012009027270493
Validation loss: 2.372449475773094

Epoch: 6| Step: 4
Training loss: 0.5496729257548039
Validation loss: 2.3517277977385627

Epoch: 6| Step: 5
Training loss: 0.3780376664498758
Validation loss: 2.329765151717046

Epoch: 6| Step: 6
Training loss: 0.3546665908095152
Validation loss: 2.3086682698657977

Epoch: 6| Step: 7
Training loss: 0.38881879933682173
Validation loss: 2.3812223788283964

Epoch: 6| Step: 8
Training loss: 0.4429297361063525
Validation loss: 2.34252137087882

Epoch: 6| Step: 9
Training loss: 0.5115058397759584
Validation loss: 2.3102530827125545

Epoch: 6| Step: 10
Training loss: 0.4268661291728274
Validation loss: 2.3498760610052116

Epoch: 6| Step: 11
Training loss: 0.31103199428705774
Validation loss: 2.3328712948243706

Epoch: 6| Step: 12
Training loss: 0.3368017368766541
Validation loss: 2.3598422667761314

Epoch: 6| Step: 13
Training loss: 0.33864260660349543
Validation loss: 2.31294199869253

Epoch: 281| Step: 0
Training loss: 0.3496265620263905
Validation loss: 2.32807831856098

Epoch: 6| Step: 1
Training loss: 0.49455882834724274
Validation loss: 2.3119126338599294

Epoch: 6| Step: 2
Training loss: 0.40098869502335044
Validation loss: 2.331508899592927

Epoch: 6| Step: 3
Training loss: 0.4484512074465642
Validation loss: 2.3598132789555906

Epoch: 6| Step: 4
Training loss: 0.32085131475087986
Validation loss: 2.3573571138038347

Epoch: 6| Step: 5
Training loss: 0.3146078072852952
Validation loss: 2.33738411940836

Epoch: 6| Step: 6
Training loss: 0.42114010132876756
Validation loss: 2.3660429484117667

Epoch: 6| Step: 7
Training loss: 0.5163163838413046
Validation loss: 2.337595169659532

Epoch: 6| Step: 8
Training loss: 0.41124544390441714
Validation loss: 2.3793305685191695

Epoch: 6| Step: 9
Training loss: 0.27970038123277
Validation loss: 2.3604779644307743

Epoch: 6| Step: 10
Training loss: 0.5916955187528085
Validation loss: 2.341867453789751

Epoch: 6| Step: 11
Training loss: 0.3092760558804678
Validation loss: 2.291768710436532

Epoch: 6| Step: 12
Training loss: 0.3896230818450678
Validation loss: 2.2418366178685565

Epoch: 6| Step: 13
Training loss: 0.6400934665945437
Validation loss: 2.322877418859349

Epoch: 282| Step: 0
Training loss: 0.435697315732065
Validation loss: 2.245670134914227

Epoch: 6| Step: 1
Training loss: 0.48960325187042614
Validation loss: 2.278386823193236

Epoch: 6| Step: 2
Training loss: 0.25055956802118085
Validation loss: 2.2871955053984467

Epoch: 6| Step: 3
Training loss: 0.36978321558290417
Validation loss: 2.369682960671916

Epoch: 6| Step: 4
Training loss: 0.5322111075020968
Validation loss: 2.3257617946635816

Epoch: 6| Step: 5
Training loss: 0.45296373457301536
Validation loss: 2.3396222026129068

Epoch: 6| Step: 6
Training loss: 0.618951810812911
Validation loss: 2.2621502505841553

Epoch: 6| Step: 7
Training loss: 0.3163876704659658
Validation loss: 2.2660094187160027

Epoch: 6| Step: 8
Training loss: 0.4647017991483258
Validation loss: 2.2626193926590896

Epoch: 6| Step: 9
Training loss: 0.6072102266889116
Validation loss: 2.315660327636746

Epoch: 6| Step: 10
Training loss: 0.6202070276257097
Validation loss: 2.2904746481144667

Epoch: 6| Step: 11
Training loss: 0.3426262411779102
Validation loss: 2.341725785017121

Epoch: 6| Step: 12
Training loss: 0.5221457127596829
Validation loss: 2.2391369456098182

Epoch: 6| Step: 13
Training loss: 0.41332486865325874
Validation loss: 2.2761996204960573

Epoch: 283| Step: 0
Training loss: 0.32562140881979823
Validation loss: 2.2560058193920822

Epoch: 6| Step: 1
Training loss: 0.3135700027149131
Validation loss: 2.2734958776645384

Epoch: 6| Step: 2
Training loss: 0.3385918897886628
Validation loss: 2.2624232414390155

Epoch: 6| Step: 3
Training loss: 0.31507546580521667
Validation loss: 2.299004309510955

Epoch: 6| Step: 4
Training loss: 0.38531224881153936
Validation loss: 2.3098445802067924

Epoch: 6| Step: 5
Training loss: 0.3079847289671641
Validation loss: 2.2381166016990046

Epoch: 6| Step: 6
Training loss: 0.3422576196670816
Validation loss: 2.328438637449507

Epoch: 6| Step: 7
Training loss: 0.36503160937493806
Validation loss: 2.2915330558899134

Epoch: 6| Step: 8
Training loss: 0.3736035253250221
Validation loss: 2.254973442643028

Epoch: 6| Step: 9
Training loss: 0.42840168776139614
Validation loss: 2.302675565141729

Epoch: 6| Step: 10
Training loss: 0.5299974710476117
Validation loss: 2.242619954582719

Epoch: 6| Step: 11
Training loss: 0.4107939712452547
Validation loss: 2.30925063648816

Epoch: 6| Step: 12
Training loss: 0.37779166291157185
Validation loss: 2.3037448830426124

Epoch: 6| Step: 13
Training loss: 0.2575995693009934
Validation loss: 2.2889543145385396

Epoch: 284| Step: 0
Training loss: 0.25264184546236307
Validation loss: 2.255831772496398

Epoch: 6| Step: 1
Training loss: 0.39589067930459143
Validation loss: 2.2218450351989065

Epoch: 6| Step: 2
Training loss: 0.41341758383070104
Validation loss: 2.3393243500830665

Epoch: 6| Step: 3
Training loss: 0.27680570501659607
Validation loss: 2.2892614805427964

Epoch: 6| Step: 4
Training loss: 0.40084065523155127
Validation loss: 2.2920843668495414

Epoch: 6| Step: 5
Training loss: 0.5253779470055661
Validation loss: 2.300416737271845

Epoch: 6| Step: 6
Training loss: 0.4376774836615252
Validation loss: 2.2874807593226087

Epoch: 6| Step: 7
Training loss: 0.49166551794575264
Validation loss: 2.344818931114909

Epoch: 6| Step: 8
Training loss: 0.3770138192603713
Validation loss: 2.228026755201407

Epoch: 6| Step: 9
Training loss: 0.20059959714265269
Validation loss: 2.304283348035601

Epoch: 6| Step: 10
Training loss: 0.3856675860540454
Validation loss: 2.3465123322609402

Epoch: 6| Step: 11
Training loss: 0.3969921374731493
Validation loss: 2.3656298188429634

Epoch: 6| Step: 12
Training loss: 0.28221686059452167
Validation loss: 2.288954800620726

Epoch: 6| Step: 13
Training loss: 0.3591214405020174
Validation loss: 2.346404517872269

Epoch: 285| Step: 0
Training loss: 0.3640809639763188
Validation loss: 2.344269199084023

Epoch: 6| Step: 1
Training loss: 0.289972368272254
Validation loss: 2.2969070051735763

Epoch: 6| Step: 2
Training loss: 0.4464120173791055
Validation loss: 2.341981245837223

Epoch: 6| Step: 3
Training loss: 0.6311943180718104
Validation loss: 2.3381536851510285

Epoch: 6| Step: 4
Training loss: 0.5110445896111226
Validation loss: 2.30193399718821

Epoch: 6| Step: 5
Training loss: 0.38748364952416664
Validation loss: 2.378570641541102

Epoch: 6| Step: 6
Training loss: 0.28860394732970573
Validation loss: 2.3273832005587614

Epoch: 6| Step: 7
Training loss: 0.3496362366826063
Validation loss: 2.344508306960298

Epoch: 6| Step: 8
Training loss: 0.5128392480712245
Validation loss: 2.295546461022502

Epoch: 6| Step: 9
Training loss: 0.30509826896483366
Validation loss: 2.254714653360963

Epoch: 6| Step: 10
Training loss: 0.2439367129396002
Validation loss: 2.297185967602749

Epoch: 6| Step: 11
Training loss: 0.31277198875971196
Validation loss: 2.3032305061401193

Epoch: 6| Step: 12
Training loss: 0.29646967523494183
Validation loss: 2.2705687068307054

Epoch: 6| Step: 13
Training loss: 0.2982388214540922
Validation loss: 2.3100076079965786

Epoch: 286| Step: 0
Training loss: 0.40864462453699196
Validation loss: 2.299463539171236

Epoch: 6| Step: 1
Training loss: 0.48405387447151416
Validation loss: 2.2687087721708594

Epoch: 6| Step: 2
Training loss: 0.4248788878433286
Validation loss: 2.290241783946007

Epoch: 6| Step: 3
Training loss: 0.25916729044353654
Validation loss: 2.3022198241033958

Epoch: 6| Step: 4
Training loss: 0.49830955609186783
Validation loss: 2.276663109784492

Epoch: 6| Step: 5
Training loss: 0.4134949807527805
Validation loss: 2.2912439187581883

Epoch: 6| Step: 6
Training loss: 0.26814978853982374
Validation loss: 2.245607415220763

Epoch: 6| Step: 7
Training loss: 0.30865244971084443
Validation loss: 2.2790026285486378

Epoch: 6| Step: 8
Training loss: 0.3657598132826695
Validation loss: 2.298798480149278

Epoch: 6| Step: 9
Training loss: 0.2281191149043948
Validation loss: 2.3416820473578754

Epoch: 6| Step: 10
Training loss: 0.3657582244078732
Validation loss: 2.345321509885922

Epoch: 6| Step: 11
Training loss: 0.441012721901082
Validation loss: 2.3350931638311034

Epoch: 6| Step: 12
Training loss: 0.3492576812105622
Validation loss: 2.323720439417117

Epoch: 6| Step: 13
Training loss: 0.2571645744553424
Validation loss: 2.29412751863359

Epoch: 287| Step: 0
Training loss: 0.34369615653305535
Validation loss: 2.2842631885389566

Epoch: 6| Step: 1
Training loss: 0.4178368547484178
Validation loss: 2.327665612215017

Epoch: 6| Step: 2
Training loss: 0.3262505122432853
Validation loss: 2.329537630878627

Epoch: 6| Step: 3
Training loss: 0.4632316009523861
Validation loss: 2.314859561134471

Epoch: 6| Step: 4
Training loss: 0.5176539239621027
Validation loss: 2.2736061444387197

Epoch: 6| Step: 5
Training loss: 0.2633691109097103
Validation loss: 2.302273243339166

Epoch: 6| Step: 6
Training loss: 0.43136484303174555
Validation loss: 2.3288729018935825

Epoch: 6| Step: 7
Training loss: 0.5577822305710347
Validation loss: 2.323678243923536

Epoch: 6| Step: 8
Training loss: 0.4030686856642687
Validation loss: 2.342262643834859

Epoch: 6| Step: 9
Training loss: 0.3945868424632494
Validation loss: 2.3189883665692568

Epoch: 6| Step: 10
Training loss: 0.3119449215638394
Validation loss: 2.271976836317032

Epoch: 6| Step: 11
Training loss: 0.4223746413979838
Validation loss: 2.2963886740890658

Epoch: 6| Step: 12
Training loss: 0.3639360085322016
Validation loss: 2.2782565469180667

Epoch: 6| Step: 13
Training loss: 0.2879953015527001
Validation loss: 2.2468970236231662

Epoch: 288| Step: 0
Training loss: 0.4058169110491858
Validation loss: 2.330458664070357

Epoch: 6| Step: 1
Training loss: 0.43693823169881074
Validation loss: 2.3120288540756686

Epoch: 6| Step: 2
Training loss: 0.46305425785744553
Validation loss: 2.2477813572739085

Epoch: 6| Step: 3
Training loss: 0.3659591012340262
Validation loss: 2.289301368306189

Epoch: 6| Step: 4
Training loss: 0.38722561843342923
Validation loss: 2.316182598019238

Epoch: 6| Step: 5
Training loss: 0.43437711728904155
Validation loss: 2.3152281674681103

Epoch: 6| Step: 6
Training loss: 0.6009703607645229
Validation loss: 2.344288751352468

Epoch: 6| Step: 7
Training loss: 0.4579926347962828
Validation loss: 2.3661618502494126

Epoch: 6| Step: 8
Training loss: 0.5581787274890445
Validation loss: 2.2765843306807976

Epoch: 6| Step: 9
Training loss: 0.5186098001219821
Validation loss: 2.259727704107222

Epoch: 6| Step: 10
Training loss: 0.4269531989904621
Validation loss: 2.332402193949734

Epoch: 6| Step: 11
Training loss: 0.4675593354059806
Validation loss: 2.294349622870996

Epoch: 6| Step: 12
Training loss: 0.5575122634325779
Validation loss: 2.3088386435875745

Epoch: 6| Step: 13
Training loss: 0.37968386660120723
Validation loss: 2.297557158604891

Epoch: 289| Step: 0
Training loss: 0.5559094629621072
Validation loss: 2.274249854792973

Epoch: 6| Step: 1
Training loss: 0.6979845972356485
Validation loss: 2.319106108404482

Epoch: 6| Step: 2
Training loss: 0.6664257408949938
Validation loss: 2.3873617301966403

Epoch: 6| Step: 3
Training loss: 0.5417834730629133
Validation loss: 2.281178599594536

Epoch: 6| Step: 4
Training loss: 0.2701063792506722
Validation loss: 2.317040016314996

Epoch: 6| Step: 5
Training loss: 0.27637031472529505
Validation loss: 2.3180439281025977

Epoch: 6| Step: 6
Training loss: 0.3063743917699634
Validation loss: 2.366463562036391

Epoch: 6| Step: 7
Training loss: 0.49604226393371964
Validation loss: 2.3410986760149233

Epoch: 6| Step: 8
Training loss: 0.32881821339887146
Validation loss: 2.2938419912603045

Epoch: 6| Step: 9
Training loss: 0.4648695065070423
Validation loss: 2.3548427865560884

Epoch: 6| Step: 10
Training loss: 0.2274095141931554
Validation loss: 2.316870571557927

Epoch: 6| Step: 11
Training loss: 0.42569733588975867
Validation loss: 2.29348852969641

Epoch: 6| Step: 12
Training loss: 0.3836460963502152
Validation loss: 2.300435487665248

Epoch: 6| Step: 13
Training loss: 0.6285949078539018
Validation loss: 2.3374773476602915

Epoch: 290| Step: 0
Training loss: 0.26233299256035636
Validation loss: 2.3255147617057204

Epoch: 6| Step: 1
Training loss: 0.33209037254384277
Validation loss: 2.307885850529726

Epoch: 6| Step: 2
Training loss: 0.5867720700352582
Validation loss: 2.2803489699777177

Epoch: 6| Step: 3
Training loss: 0.3311279238373412
Validation loss: 2.3135853531543114

Epoch: 6| Step: 4
Training loss: 0.3416076681421335
Validation loss: 2.241501422969841

Epoch: 6| Step: 5
Training loss: 0.39124633964069466
Validation loss: 2.2532052239656175

Epoch: 6| Step: 6
Training loss: 0.34285348245605346
Validation loss: 2.2888153428799565

Epoch: 6| Step: 7
Training loss: 0.35405620320201353
Validation loss: 2.2633808290089057

Epoch: 6| Step: 8
Training loss: 0.3226968827421253
Validation loss: 2.2648061215170983

Epoch: 6| Step: 9
Training loss: 0.2875359668210059
Validation loss: 2.304589160609966

Epoch: 6| Step: 10
Training loss: 0.33042383993539287
Validation loss: 2.2696682860716537

Epoch: 6| Step: 11
Training loss: 0.17334478129487071
Validation loss: 2.297228346999323

Epoch: 6| Step: 12
Training loss: 0.30532784297503157
Validation loss: 2.2515891520722673

Epoch: 6| Step: 13
Training loss: 0.40666960174186656
Validation loss: 2.280368634673046

Epoch: 291| Step: 0
Training loss: 0.440670987698602
Validation loss: 2.250837223266645

Epoch: 6| Step: 1
Training loss: 0.4634465127069859
Validation loss: 2.2539051216779384

Epoch: 6| Step: 2
Training loss: 0.31460535617607954
Validation loss: 2.26617478463446

Epoch: 6| Step: 3
Training loss: 0.22817811739461666
Validation loss: 2.2305769039550745

Epoch: 6| Step: 4
Training loss: 0.40026081120759693
Validation loss: 2.3282444558443696

Epoch: 6| Step: 5
Training loss: 0.4463902198121769
Validation loss: 2.2867061043370005

Epoch: 6| Step: 6
Training loss: 0.4065786462871877
Validation loss: 2.2740109344237425

Epoch: 6| Step: 7
Training loss: 0.5661418429189905
Validation loss: 2.3065406977934937

Epoch: 6| Step: 8
Training loss: 0.24138809370384987
Validation loss: 2.312062110338295

Epoch: 6| Step: 9
Training loss: 0.32902139881584386
Validation loss: 2.324073004761048

Epoch: 6| Step: 10
Training loss: 0.4608344916638975
Validation loss: 2.310768897126545

Epoch: 6| Step: 11
Training loss: 0.5373319684794977
Validation loss: 2.3229955708284558

Epoch: 6| Step: 12
Training loss: 0.3216783432043599
Validation loss: 2.259616127003633

Epoch: 6| Step: 13
Training loss: 0.5826406424926307
Validation loss: 2.351097542556946

Epoch: 292| Step: 0
Training loss: 0.22957916234918638
Validation loss: 2.26774627649131

Epoch: 6| Step: 1
Training loss: 0.49140917075157936
Validation loss: 2.2987410734942646

Epoch: 6| Step: 2
Training loss: 0.5487385741241279
Validation loss: 2.342234999243112

Epoch: 6| Step: 3
Training loss: 0.2535020398466063
Validation loss: 2.256531542315742

Epoch: 6| Step: 4
Training loss: 0.3114392995068494
Validation loss: 2.3452729935339787

Epoch: 6| Step: 5
Training loss: 0.28108497917652114
Validation loss: 2.307340700361888

Epoch: 6| Step: 6
Training loss: 0.43575237540967104
Validation loss: 2.2773544197857674

Epoch: 6| Step: 7
Training loss: 0.362172578236018
Validation loss: 2.2634887796804604

Epoch: 6| Step: 8
Training loss: 0.358227764517719
Validation loss: 2.3019613058161803

Epoch: 6| Step: 9
Training loss: 0.3941246619266956
Validation loss: 2.2898506569647026

Epoch: 6| Step: 10
Training loss: 0.3813775474565785
Validation loss: 2.297173772570305

Epoch: 6| Step: 11
Training loss: 0.26087958041411935
Validation loss: 2.319991957661512

Epoch: 6| Step: 12
Training loss: 0.2878019581954776
Validation loss: 2.252714850438842

Epoch: 6| Step: 13
Training loss: 0.21890861857111024
Validation loss: 2.3507378400600145

Epoch: 293| Step: 0
Training loss: 0.4020071566108388
Validation loss: 2.2702208635039773

Epoch: 6| Step: 1
Training loss: 0.6593831970283869
Validation loss: 2.362646802751266

Epoch: 6| Step: 2
Training loss: 0.23450000925918105
Validation loss: 2.267478815839873

Epoch: 6| Step: 3
Training loss: 0.34185049453862504
Validation loss: 2.2901343655903212

Epoch: 6| Step: 4
Training loss: 0.3268969124037597
Validation loss: 2.309883269598739

Epoch: 6| Step: 5
Training loss: 0.17897868293492877
Validation loss: 2.32626806359757

Epoch: 6| Step: 6
Training loss: 0.2974759469406492
Validation loss: 2.338823719191469

Epoch: 6| Step: 7
Training loss: 0.40938963317925664
Validation loss: 2.260300836950107

Epoch: 6| Step: 8
Training loss: 0.2513040120869412
Validation loss: 2.309865636674776

Epoch: 6| Step: 9
Training loss: 0.43205548540952227
Validation loss: 2.278199965678642

Epoch: 6| Step: 10
Training loss: 0.3655753966045961
Validation loss: 2.2803795996056397

Epoch: 6| Step: 11
Training loss: 0.4723400760902728
Validation loss: 2.2554581454602194

Epoch: 6| Step: 12
Training loss: 0.4079865971916315
Validation loss: 2.3482984700084395

Epoch: 6| Step: 13
Training loss: 0.2951824477096749
Validation loss: 2.2554871267149936

Epoch: 294| Step: 0
Training loss: 0.22601304349140355
Validation loss: 2.2392639701304984

Epoch: 6| Step: 1
Training loss: 0.4690998043751924
Validation loss: 2.3108094453958343

Epoch: 6| Step: 2
Training loss: 0.4033628538293122
Validation loss: 2.313526424086945

Epoch: 6| Step: 3
Training loss: 0.35887035929444056
Validation loss: 2.2492270908198853

Epoch: 6| Step: 4
Training loss: 0.37455186293004644
Validation loss: 2.352866705657953

Epoch: 6| Step: 5
Training loss: 0.3634660517399151
Validation loss: 2.2965307518375493

Epoch: 6| Step: 6
Training loss: 0.2457440328581793
Validation loss: 2.3213222716869684

Epoch: 6| Step: 7
Training loss: 0.5429139418349416
Validation loss: 2.2879663561796066

Epoch: 6| Step: 8
Training loss: 0.49340565117841884
Validation loss: 2.270200524540899

Epoch: 6| Step: 9
Training loss: 0.19015508562043407
Validation loss: 2.2703504194719035

Epoch: 6| Step: 10
Training loss: 0.3360366785779336
Validation loss: 2.2429657492622543

Epoch: 6| Step: 11
Training loss: 0.3448842690208408
Validation loss: 2.282104018793621

Epoch: 6| Step: 12
Training loss: 0.2702285895454781
Validation loss: 2.34733691929084

Epoch: 6| Step: 13
Training loss: 0.4616873025270182
Validation loss: 2.258096028161532

Epoch: 295| Step: 0
Training loss: 0.38002048929715904
Validation loss: 2.3354558203548934

Epoch: 6| Step: 1
Training loss: 0.5868243309142318
Validation loss: 2.3115738311375713

Epoch: 6| Step: 2
Training loss: 0.29238816271048734
Validation loss: 2.3246041200151395

Epoch: 6| Step: 3
Training loss: 0.24570114365401968
Validation loss: 2.257952359101558

Epoch: 6| Step: 4
Training loss: 0.2610269341849006
Validation loss: 2.2389309546549936

Epoch: 6| Step: 5
Training loss: 0.4019747773651051
Validation loss: 2.2687930352619268

Epoch: 6| Step: 6
Training loss: 0.3610429411614506
Validation loss: 2.3138951569261508

Epoch: 6| Step: 7
Training loss: 0.2854566559424669
Validation loss: 2.274308805649419

Epoch: 6| Step: 8
Training loss: 0.31355332239903394
Validation loss: 2.334112877281037

Epoch: 6| Step: 9
Training loss: 0.34019687546666555
Validation loss: 2.277583193091783

Epoch: 6| Step: 10
Training loss: 0.3358971549359095
Validation loss: 2.295286368785464

Epoch: 6| Step: 11
Training loss: 0.5589020418515791
Validation loss: 2.2784613630919717

Epoch: 6| Step: 12
Training loss: 0.2893481132301118
Validation loss: 2.309874134900787

Epoch: 6| Step: 13
Training loss: 0.3345502999951613
Validation loss: 2.3264970912410967

Epoch: 296| Step: 0
Training loss: 0.31325863307068424
Validation loss: 2.349472739542719

Epoch: 6| Step: 1
Training loss: 0.42539594872876624
Validation loss: 2.302096981048405

Epoch: 6| Step: 2
Training loss: 0.4952577620865162
Validation loss: 2.301351220817639

Epoch: 6| Step: 3
Training loss: 0.33152051801891663
Validation loss: 2.285524752647874

Epoch: 6| Step: 4
Training loss: 0.32035310999535255
Validation loss: 2.276015664889794

Epoch: 6| Step: 5
Training loss: 0.5423567911622664
Validation loss: 2.2537116766146923

Epoch: 6| Step: 6
Training loss: 0.35238128259206397
Validation loss: 2.2622602184665035

Epoch: 6| Step: 7
Training loss: 0.3181488885884984
Validation loss: 2.3075113184779767

Epoch: 6| Step: 8
Training loss: 0.31205475798388493
Validation loss: 2.345441377484409

Epoch: 6| Step: 9
Training loss: 0.3052511381570153
Validation loss: 2.3370975773563676

Epoch: 6| Step: 10
Training loss: 0.32911294979690775
Validation loss: 2.316544183974032

Epoch: 6| Step: 11
Training loss: 0.3852463831487317
Validation loss: 2.2740319033185052

Epoch: 6| Step: 12
Training loss: 0.35679465119245407
Validation loss: 2.278155113059566

Epoch: 6| Step: 13
Training loss: 0.34857495680026757
Validation loss: 2.2926449912676183

Epoch: 297| Step: 0
Training loss: 0.23931391311302017
Validation loss: 2.2867583568233045

Epoch: 6| Step: 1
Training loss: 0.363057057102649
Validation loss: 2.280894229964716

Epoch: 6| Step: 2
Training loss: 0.37091923675955113
Validation loss: 2.293102860522786

Epoch: 6| Step: 3
Training loss: 0.24152329332747483
Validation loss: 2.263154491579002

Epoch: 6| Step: 4
Training loss: 0.3993711191982786
Validation loss: 2.2775516753156477

Epoch: 6| Step: 5
Training loss: 0.5342204132455851
Validation loss: 2.2634805286317974

Epoch: 6| Step: 6
Training loss: 0.33642230426558434
Validation loss: 2.3099683186118636

Epoch: 6| Step: 7
Training loss: 0.2820595639881345
Validation loss: 2.2915048079695826

Epoch: 6| Step: 8
Training loss: 0.299175235382954
Validation loss: 2.3306192439635547

Epoch: 6| Step: 9
Training loss: 0.23353139529893036
Validation loss: 2.310747969263886

Epoch: 6| Step: 10
Training loss: 0.5714621257296879
Validation loss: 2.32410896960952

Epoch: 6| Step: 11
Training loss: 0.3708673891045782
Validation loss: 2.2684551408208504

Epoch: 6| Step: 12
Training loss: 0.45508261093089764
Validation loss: 2.367763579283903

Epoch: 6| Step: 13
Training loss: 0.2637898640314706
Validation loss: 2.2899219778531865

Epoch: 298| Step: 0
Training loss: 0.39309855264510296
Validation loss: 2.343630011983952

Epoch: 6| Step: 1
Training loss: 0.3431029189844524
Validation loss: 2.2951779226759736

Epoch: 6| Step: 2
Training loss: 0.3576263093227724
Validation loss: 2.345504663411133

Epoch: 6| Step: 3
Training loss: 0.2678941405948121
Validation loss: 2.2630786134801006

Epoch: 6| Step: 4
Training loss: 0.21720813714922338
Validation loss: 2.2985160397566107

Epoch: 6| Step: 5
Training loss: 0.23254207900692608
Validation loss: 2.2576066641605337

Epoch: 6| Step: 6
Training loss: 0.23151167388992303
Validation loss: 2.2174850583209227

Epoch: 6| Step: 7
Training loss: 0.39041656655290286
Validation loss: 2.2549218942221727

Epoch: 6| Step: 8
Training loss: 0.5373526282435312
Validation loss: 2.3051393400044478

Epoch: 6| Step: 9
Training loss: 0.3698069699125209
Validation loss: 2.26769971891165

Epoch: 6| Step: 10
Training loss: 0.24083355096099904
Validation loss: 2.278998688035012

Epoch: 6| Step: 11
Training loss: 0.32807815308163557
Validation loss: 2.2524404183261617

Epoch: 6| Step: 12
Training loss: 0.3991075192824893
Validation loss: 2.2610567976650553

Epoch: 6| Step: 13
Training loss: 0.3767371077556094
Validation loss: 2.326998871375011

Epoch: 299| Step: 0
Training loss: 0.2788050529402119
Validation loss: 2.3133075438206143

Epoch: 6| Step: 1
Training loss: 0.3721385502755611
Validation loss: 2.3392038292872184

Epoch: 6| Step: 2
Training loss: 0.3595308297696532
Validation loss: 2.323107473522649

Epoch: 6| Step: 3
Training loss: 0.45651703623186557
Validation loss: 2.3258570007692745

Epoch: 6| Step: 4
Training loss: 0.2920439811368464
Validation loss: 2.3496498787238225

Epoch: 6| Step: 5
Training loss: 0.3424880750000203
Validation loss: 2.2832848953297677

Epoch: 6| Step: 6
Training loss: 0.4348060225837327
Validation loss: 2.2822189363573377

Epoch: 6| Step: 7
Training loss: 0.4723566540246675
Validation loss: 2.2835578653755046

Epoch: 6| Step: 8
Training loss: 0.3455370703558294
Validation loss: 2.3018207630455683

Epoch: 6| Step: 9
Training loss: 0.2711723373132192
Validation loss: 2.2875945035247085

Epoch: 6| Step: 10
Training loss: 0.29220716032906674
Validation loss: 2.2727601920258005

Epoch: 6| Step: 11
Training loss: 0.23442752567450956
Validation loss: 2.305992567310668

Epoch: 6| Step: 12
Training loss: 0.3435615976927943
Validation loss: 2.3709745591867644

Epoch: 6| Step: 13
Training loss: 0.5407119614885392
Validation loss: 2.349314784531359

Epoch: 300| Step: 0
Training loss: 0.326844110852874
Validation loss: 2.2948106411429245

Epoch: 6| Step: 1
Training loss: 0.5133006563974297
Validation loss: 2.2474116431277285

Epoch: 6| Step: 2
Training loss: 0.3067786155300794
Validation loss: 2.286219614090148

Epoch: 6| Step: 3
Training loss: 0.4055666862209428
Validation loss: 2.3216187881257637

Epoch: 6| Step: 4
Training loss: 0.3128680565132541
Validation loss: 2.266430845218117

Epoch: 6| Step: 5
Training loss: 0.22952484547799212
Validation loss: 2.263127469680648

Epoch: 6| Step: 6
Training loss: 0.4247470334271076
Validation loss: 2.254376931411315

Epoch: 6| Step: 7
Training loss: 0.4106778415954337
Validation loss: 2.310625536609629

Epoch: 6| Step: 8
Training loss: 0.34002414387991403
Validation loss: 2.2425389739880885

Epoch: 6| Step: 9
Training loss: 0.38415238361465687
Validation loss: 2.2995548142244497

Epoch: 6| Step: 10
Training loss: 0.4752994434236253
Validation loss: 2.338766691826919

Epoch: 6| Step: 11
Training loss: 0.4019331827953582
Validation loss: 2.350514986546691

Epoch: 6| Step: 12
Training loss: 0.2631122159683874
Validation loss: 2.269916363868463

Epoch: 6| Step: 13
Training loss: 0.3025042489833188
Validation loss: 2.288818138020823

Epoch: 301| Step: 0
Training loss: 0.274437194066495
Validation loss: 2.3175076744284473

Epoch: 6| Step: 1
Training loss: 0.42654724513013764
Validation loss: 2.289962192484279

Epoch: 6| Step: 2
Training loss: 0.3678831045338392
Validation loss: 2.3021286374520584

Epoch: 6| Step: 3
Training loss: 0.2433257886509513
Validation loss: 2.2995763537100613

Epoch: 6| Step: 4
Training loss: 0.2514003930319428
Validation loss: 2.2880850083830495

Epoch: 6| Step: 5
Training loss: 0.23821341221191292
Validation loss: 2.3375008071381234

Epoch: 6| Step: 6
Training loss: 0.47012326625290274
Validation loss: 2.3328078620593704

Epoch: 6| Step: 7
Training loss: 0.39218404548005076
Validation loss: 2.2805742194753904

Epoch: 6| Step: 8
Training loss: 0.27817751249418216
Validation loss: 2.223412052812249

Epoch: 6| Step: 9
Training loss: 0.2283404730518216
Validation loss: 2.278496225441128

Epoch: 6| Step: 10
Training loss: 0.6481318385352924
Validation loss: 2.2833923661705953

Epoch: 6| Step: 11
Training loss: 0.3202687908216577
Validation loss: 2.2689068231248504

Epoch: 6| Step: 12
Training loss: 0.2132640852675891
Validation loss: 2.325446822187307

Epoch: 6| Step: 13
Training loss: 0.3845368300509314
Validation loss: 2.3145605563998193

Epoch: 302| Step: 0
Training loss: 0.44590597593307224
Validation loss: 2.289363429020925

Epoch: 6| Step: 1
Training loss: 0.4160581396882109
Validation loss: 2.319125418762828

Epoch: 6| Step: 2
Training loss: 0.3789751245883093
Validation loss: 2.340975106322194

Epoch: 6| Step: 3
Training loss: 0.3365498882753705
Validation loss: 2.3239975938910384

Epoch: 6| Step: 4
Training loss: 0.2913606122153735
Validation loss: 2.3013177925055155

Epoch: 6| Step: 5
Training loss: 0.5587306888494679
Validation loss: 2.3617215981709725

Epoch: 6| Step: 6
Training loss: 0.35587633262119467
Validation loss: 2.266534442995314

Epoch: 6| Step: 7
Training loss: 0.41706584842640543
Validation loss: 2.349052737440168

Epoch: 6| Step: 8
Training loss: 0.3684325921117607
Validation loss: 2.287336217162226

Epoch: 6| Step: 9
Training loss: 0.1830946855548813
Validation loss: 2.2434090577542967

Epoch: 6| Step: 10
Training loss: 0.4970179082380372
Validation loss: 2.3273483534134924

Epoch: 6| Step: 11
Training loss: 0.4400839283670743
Validation loss: 2.2637669628623467

Epoch: 6| Step: 12
Training loss: 0.39458155547362184
Validation loss: 2.2518524209163786

Epoch: 6| Step: 13
Training loss: 0.29735567681371794
Validation loss: 2.2546952055166942

Epoch: 303| Step: 0
Training loss: 0.44939981211682556
Validation loss: 2.284402828508012

Epoch: 6| Step: 1
Training loss: 0.44181043973381107
Validation loss: 2.35327403832247

Epoch: 6| Step: 2
Training loss: 0.32987647132357495
Validation loss: 2.289914750423907

Epoch: 6| Step: 3
Training loss: 0.30450424160688744
Validation loss: 2.321691101376489

Epoch: 6| Step: 4
Training loss: 0.22630817838976225
Validation loss: 2.275978355196409

Epoch: 6| Step: 5
Training loss: 0.3501907182382544
Validation loss: 2.2753348980848043

Epoch: 6| Step: 6
Training loss: 0.2867752518447995
Validation loss: 2.251155300587948

Epoch: 6| Step: 7
Training loss: 0.27471090531694115
Validation loss: 2.328463689758927

Epoch: 6| Step: 8
Training loss: 0.530096934469038
Validation loss: 2.307534256030253

Epoch: 6| Step: 9
Training loss: 0.40643168934800084
Validation loss: 2.28589961902089

Epoch: 6| Step: 10
Training loss: 0.504067712982712
Validation loss: 2.3104447175350558

Epoch: 6| Step: 11
Training loss: 0.46928986614157026
Validation loss: 2.257098761605507

Epoch: 6| Step: 12
Training loss: 0.3492715364709442
Validation loss: 2.2866029338833753

Epoch: 6| Step: 13
Training loss: 0.627314620808468
Validation loss: 2.28970426865429

Epoch: 304| Step: 0
Training loss: 0.6254989539731531
Validation loss: 2.2103513697819936

Epoch: 6| Step: 1
Training loss: 0.3290400688155455
Validation loss: 2.306091415480253

Epoch: 6| Step: 2
Training loss: 0.27455491221828243
Validation loss: 2.220983097854851

Epoch: 6| Step: 3
Training loss: 0.38663134887692074
Validation loss: 2.3046445680919208

Epoch: 6| Step: 4
Training loss: 0.45568317907908923
Validation loss: 2.3126151511588096

Epoch: 6| Step: 5
Training loss: 0.4113344617683372
Validation loss: 2.2679929438732973

Epoch: 6| Step: 6
Training loss: 0.3006572467774347
Validation loss: 2.3423811920880535

Epoch: 6| Step: 7
Training loss: 0.3169806411906101
Validation loss: 2.2844845211077685

Epoch: 6| Step: 8
Training loss: 0.3369561763371427
Validation loss: 2.2871312575538125

Epoch: 6| Step: 9
Training loss: 0.23155852659319698
Validation loss: 2.2524097219052877

Epoch: 6| Step: 10
Training loss: 0.23707386454801374
Validation loss: 2.257019114767048

Epoch: 6| Step: 11
Training loss: 0.4093443509633375
Validation loss: 2.3081410540247878

Epoch: 6| Step: 12
Training loss: 0.5447305596424838
Validation loss: 2.281393595317426

Epoch: 6| Step: 13
Training loss: 0.2772828962160458
Validation loss: 2.238565769719624

Epoch: 305| Step: 0
Training loss: 0.28302601504973185
Validation loss: 2.281397392353815

Epoch: 6| Step: 1
Training loss: 0.33203472808811363
Validation loss: 2.2693668903446516

Epoch: 6| Step: 2
Training loss: 0.4675251694140998
Validation loss: 2.3227307768429206

Epoch: 6| Step: 3
Training loss: 0.35488856830033716
Validation loss: 2.3355045151217353

Epoch: 6| Step: 4
Training loss: 0.4632031315369074
Validation loss: 2.293291605326735

Epoch: 6| Step: 5
Training loss: 0.38394938219261415
Validation loss: 2.2778040146544263

Epoch: 6| Step: 6
Training loss: 0.24540743418351607
Validation loss: 2.2899726082622562

Epoch: 6| Step: 7
Training loss: 0.4698855315477095
Validation loss: 2.310082882114

Epoch: 6| Step: 8
Training loss: 0.3160758235824417
Validation loss: 2.269276992641236

Epoch: 6| Step: 9
Training loss: 0.263155905659587
Validation loss: 2.3168419893964423

Epoch: 6| Step: 10
Training loss: 0.44720468564069576
Validation loss: 2.3141444090213668

Epoch: 6| Step: 11
Training loss: 0.2157190093754957
Validation loss: 2.2939872061221065

Epoch: 6| Step: 12
Training loss: 0.3743170638940748
Validation loss: 2.3137187839011837

Epoch: 6| Step: 13
Training loss: 0.3915624813070696
Validation loss: 2.2499533224562263

Epoch: 306| Step: 0
Training loss: 0.31186697741263725
Validation loss: 2.290909786657748

Epoch: 6| Step: 1
Training loss: 0.3530478570447087
Validation loss: 2.307913088731758

Epoch: 6| Step: 2
Training loss: 0.3544773067156908
Validation loss: 2.3163201164369545

Epoch: 6| Step: 3
Training loss: 0.264020251669572
Validation loss: 2.2943909375856366

Epoch: 6| Step: 4
Training loss: 0.26405906505720694
Validation loss: 2.2848085492130865

Epoch: 6| Step: 5
Training loss: 0.2861784029629255
Validation loss: 2.2768309830012905

Epoch: 6| Step: 6
Training loss: 0.370492387690831
Validation loss: 2.284452568020995

Epoch: 6| Step: 7
Training loss: 0.5005391611428017
Validation loss: 2.323850629275085

Epoch: 6| Step: 8
Training loss: 0.25338112741559915
Validation loss: 2.275561883727396

Epoch: 6| Step: 9
Training loss: 0.2522088165444531
Validation loss: 2.293616355585186

Epoch: 6| Step: 10
Training loss: 0.39055209433175125
Validation loss: 2.366809877799682

Epoch: 6| Step: 11
Training loss: 0.33457064341870013
Validation loss: 2.2561958183200677

Epoch: 6| Step: 12
Training loss: 0.49607846093835517
Validation loss: 2.2651937841699374

Epoch: 6| Step: 13
Training loss: 0.2994945052268562
Validation loss: 2.2366761671092865

Epoch: 307| Step: 0
Training loss: 0.3313266121241294
Validation loss: 2.24120757768278

Epoch: 6| Step: 1
Training loss: 0.4821448824350518
Validation loss: 2.309836563559871

Epoch: 6| Step: 2
Training loss: 0.3300519628144816
Validation loss: 2.3409275013945168

Epoch: 6| Step: 3
Training loss: 0.31515000406637766
Validation loss: 2.335403364304139

Epoch: 6| Step: 4
Training loss: 0.291613687517403
Validation loss: 2.328076918956765

Epoch: 6| Step: 5
Training loss: 0.3644364560680978
Validation loss: 2.359596654656882

Epoch: 6| Step: 6
Training loss: 0.3436933817619444
Validation loss: 2.3303071874307566

Epoch: 6| Step: 7
Training loss: 0.36189915667006345
Validation loss: 2.2792991675218537

Epoch: 6| Step: 8
Training loss: 0.4286953829852386
Validation loss: 2.3182422208764852

Epoch: 6| Step: 9
Training loss: 0.1882161530466429
Validation loss: 2.3093863136382597

Epoch: 6| Step: 10
Training loss: 0.2648390192830281
Validation loss: 2.279978497944771

Epoch: 6| Step: 11
Training loss: 0.3081436738087341
Validation loss: 2.2837305039114946

Epoch: 6| Step: 12
Training loss: 0.32366399528456496
Validation loss: 2.301924218134878

Epoch: 6| Step: 13
Training loss: 0.3178929381475058
Validation loss: 2.220320571072231

Epoch: 308| Step: 0
Training loss: 0.40117568299325773
Validation loss: 2.2577790254533547

Epoch: 6| Step: 1
Training loss: 0.20290548126977498
Validation loss: 2.3238829127004927

Epoch: 6| Step: 2
Training loss: 0.31103071272474114
Validation loss: 2.3465956896330806

Epoch: 6| Step: 3
Training loss: 0.3694072950997174
Validation loss: 2.3064376134466937

Epoch: 6| Step: 4
Training loss: 0.44349780841337505
Validation loss: 2.305095046049759

Epoch: 6| Step: 5
Training loss: 0.34266423934062584
Validation loss: 2.3316191836910556

Epoch: 6| Step: 6
Training loss: 0.38071029875517515
Validation loss: 2.3152495096509105

Epoch: 6| Step: 7
Training loss: 0.431012140550024
Validation loss: 2.3091617150209442

Epoch: 6| Step: 8
Training loss: 0.27498888242530045
Validation loss: 2.2849882841192457

Epoch: 6| Step: 9
Training loss: 0.34777142192175514
Validation loss: 2.337511525321195

Epoch: 6| Step: 10
Training loss: 0.3714435534907457
Validation loss: 2.276305976960066

Epoch: 6| Step: 11
Training loss: 0.26581816101324685
Validation loss: 2.3191669346321144

Epoch: 6| Step: 12
Training loss: 0.2428618855373921
Validation loss: 2.3318884042753187

Epoch: 6| Step: 13
Training loss: 0.2572372260522795
Validation loss: 2.321165876231969

Epoch: 309| Step: 0
Training loss: 0.33686226709255807
Validation loss: 2.3138714237731945

Epoch: 6| Step: 1
Training loss: 0.2699390588085179
Validation loss: 2.2734148301854677

Epoch: 6| Step: 2
Training loss: 0.2072624049707642
Validation loss: 2.326971549204041

Epoch: 6| Step: 3
Training loss: 0.26805430178247486
Validation loss: 2.3145521526370967

Epoch: 6| Step: 4
Training loss: 0.3703112533805885
Validation loss: 2.3006213337147847

Epoch: 6| Step: 5
Training loss: 0.5423838531956701
Validation loss: 2.2839416753923545

Epoch: 6| Step: 6
Training loss: 0.40926292865537667
Validation loss: 2.3245113242082684

Epoch: 6| Step: 7
Training loss: 0.2712290819074537
Validation loss: 2.276016101358956

Epoch: 6| Step: 8
Training loss: 0.35451501189595863
Validation loss: 2.302311041661875

Epoch: 6| Step: 9
Training loss: 0.40080810739455974
Validation loss: 2.2996828385758685

Epoch: 6| Step: 10
Training loss: 0.34395554206188456
Validation loss: 2.277637940342561

Epoch: 6| Step: 11
Training loss: 0.3209657868880022
Validation loss: 2.2875644351659945

Epoch: 6| Step: 12
Training loss: 0.21307263774258348
Validation loss: 2.264636979671092

Epoch: 6| Step: 13
Training loss: 0.2892581947422013
Validation loss: 2.267708848267758

Epoch: 310| Step: 0
Training loss: 0.2812942364130373
Validation loss: 2.256301744031509

Epoch: 6| Step: 1
Training loss: 0.29578591400999354
Validation loss: 2.2974936242580672

Epoch: 6| Step: 2
Training loss: 0.2652431436024669
Validation loss: 2.3023460433908842

Epoch: 6| Step: 3
Training loss: 0.4989749115941967
Validation loss: 2.280378410324677

Epoch: 6| Step: 4
Training loss: 0.31356280320023433
Validation loss: 2.275022288621983

Epoch: 6| Step: 5
Training loss: 0.28390728456416814
Validation loss: 2.298827070583295

Epoch: 6| Step: 6
Training loss: 0.40992505051415434
Validation loss: 2.2842931611882533

Epoch: 6| Step: 7
Training loss: 0.1740716128985779
Validation loss: 2.301075863069626

Epoch: 6| Step: 8
Training loss: 0.22100469359261973
Validation loss: 2.3239555487679477

Epoch: 6| Step: 9
Training loss: 0.3661866853948759
Validation loss: 2.263517605448424

Epoch: 6| Step: 10
Training loss: 0.2544918350135312
Validation loss: 2.327730081333093

Epoch: 6| Step: 11
Training loss: 0.3709617379937911
Validation loss: 2.306875485558236

Epoch: 6| Step: 12
Training loss: 0.37507044607325885
Validation loss: 2.3204783370739728

Epoch: 6| Step: 13
Training loss: 0.3124656539162349
Validation loss: 2.286686607094098

Epoch: 311| Step: 0
Training loss: 0.24430882572603246
Validation loss: 2.296809517755235

Epoch: 6| Step: 1
Training loss: 0.3829601548038502
Validation loss: 2.3072485363605284

Epoch: 6| Step: 2
Training loss: 0.24233776476200142
Validation loss: 2.329150867806651

Epoch: 6| Step: 3
Training loss: 0.35459963428593566
Validation loss: 2.2980337355793186

Epoch: 6| Step: 4
Training loss: 0.23778813570660823
Validation loss: 2.3084384373264073

Epoch: 6| Step: 5
Training loss: 0.31439183508615126
Validation loss: 2.332930339912379

Epoch: 6| Step: 6
Training loss: 0.40976449331703685
Validation loss: 2.322073665178717

Epoch: 6| Step: 7
Training loss: 0.2682857068046557
Validation loss: 2.3287653202488703

Epoch: 6| Step: 8
Training loss: 0.23326728839065278
Validation loss: 2.34987815784563

Epoch: 6| Step: 9
Training loss: 0.4425003030474212
Validation loss: 2.2841869504719887

Epoch: 6| Step: 10
Training loss: 0.2753132515289753
Validation loss: 2.3074476104690893

Epoch: 6| Step: 11
Training loss: 0.2502651447692368
Validation loss: 2.2938848221989367

Epoch: 6| Step: 12
Training loss: 0.3583848415363304
Validation loss: 2.3372657937339687

Epoch: 6| Step: 13
Training loss: 0.37730103087043015
Validation loss: 2.260688595448975

Epoch: 312| Step: 0
Training loss: 0.35138496578717127
Validation loss: 2.2900903193113225

Epoch: 6| Step: 1
Training loss: 0.37085248231559786
Validation loss: 2.2265951053842103

Epoch: 6| Step: 2
Training loss: 0.4572480494466467
Validation loss: 2.2780614804804045

Epoch: 6| Step: 3
Training loss: 0.28040072909963043
Validation loss: 2.3284900984921846

Epoch: 6| Step: 4
Training loss: 0.35301670675754
Validation loss: 2.3298379113952614

Epoch: 6| Step: 5
Training loss: 0.25821025105625467
Validation loss: 2.360726337932488

Epoch: 6| Step: 6
Training loss: 0.25562324985007623
Validation loss: 2.311740905304893

Epoch: 6| Step: 7
Training loss: 0.36966065203704274
Validation loss: 2.3114013983470727

Epoch: 6| Step: 8
Training loss: 0.49537742141143387
Validation loss: 2.32800342148489

Epoch: 6| Step: 9
Training loss: 0.3997895730371141
Validation loss: 2.2617546961535218

Epoch: 6| Step: 10
Training loss: 0.3012711387356451
Validation loss: 2.298823406049346

Epoch: 6| Step: 11
Training loss: 0.2555834906249738
Validation loss: 2.289294824538876

Epoch: 6| Step: 12
Training loss: 0.2488210641167554
Validation loss: 2.3334517675951023

Epoch: 6| Step: 13
Training loss: 0.4520621330663731
Validation loss: 2.2895981267208767

Epoch: 313| Step: 0
Training loss: 0.4961127330121769
Validation loss: 2.2681167755720666

Epoch: 6| Step: 1
Training loss: 0.3950703968923887
Validation loss: 2.280254739144205

Epoch: 6| Step: 2
Training loss: 0.34946101786319667
Validation loss: 2.241451953569567

Epoch: 6| Step: 3
Training loss: 0.35742289642021274
Validation loss: 2.2630679905188216

Epoch: 6| Step: 4
Training loss: 0.41347552025924456
Validation loss: 2.359382309386529

Epoch: 6| Step: 5
Training loss: 0.28840105312111486
Validation loss: 2.3308398399857757

Epoch: 6| Step: 6
Training loss: 0.4028211187560759
Validation loss: 2.286467242965776

Epoch: 6| Step: 7
Training loss: 0.381746130330996
Validation loss: 2.291787453560487

Epoch: 6| Step: 8
Training loss: 0.3188238909103018
Validation loss: 2.2949756978534426

Epoch: 6| Step: 9
Training loss: 0.3684320258849353
Validation loss: 2.2800924421275592

Epoch: 6| Step: 10
Training loss: 0.4454571338478395
Validation loss: 2.2405568749620204

Epoch: 6| Step: 11
Training loss: 0.266376875770978
Validation loss: 2.2440417129325168

Epoch: 6| Step: 12
Training loss: 0.3446886728012593
Validation loss: 2.2899330054954423

Epoch: 6| Step: 13
Training loss: 0.23551067339800924
Validation loss: 2.369204259040384

Epoch: 314| Step: 0
Training loss: 0.43725555266556454
Validation loss: 2.280039662175115

Epoch: 6| Step: 1
Training loss: 0.48620983967994635
Validation loss: 2.292750134246615

Epoch: 6| Step: 2
Training loss: 0.2889982229371197
Validation loss: 2.2913998246170584

Epoch: 6| Step: 3
Training loss: 0.4093876858558383
Validation loss: 2.2316003301797447

Epoch: 6| Step: 4
Training loss: 0.38993473099809006
Validation loss: 2.2812979793293215

Epoch: 6| Step: 5
Training loss: 0.1946864298152748
Validation loss: 2.307692849534126

Epoch: 6| Step: 6
Training loss: 0.3971881352021115
Validation loss: 2.3453924824094723

Epoch: 6| Step: 7
Training loss: 0.3344128409034635
Validation loss: 2.2689952469080077

Epoch: 6| Step: 8
Training loss: 0.3918201473850995
Validation loss: 2.291457449870687

Epoch: 6| Step: 9
Training loss: 0.4662219221645279
Validation loss: 2.3670869812223554

Epoch: 6| Step: 10
Training loss: 0.4214702006335074
Validation loss: 2.3146952785428025

Epoch: 6| Step: 11
Training loss: 0.4539897329801692
Validation loss: 2.3159881952190258

Epoch: 6| Step: 12
Training loss: 0.3650165663186501
Validation loss: 2.2756032164970863

Epoch: 6| Step: 13
Training loss: 0.3404472954946151
Validation loss: 2.339873554122709

Epoch: 315| Step: 0
Training loss: 0.22470111631908532
Validation loss: 2.3036867113228916

Epoch: 6| Step: 1
Training loss: 0.4320699533023553
Validation loss: 2.355514500618086

Epoch: 6| Step: 2
Training loss: 0.26221241581394406
Validation loss: 2.3259201532841423

Epoch: 6| Step: 3
Training loss: 0.3004555734928123
Validation loss: 2.30629316529056

Epoch: 6| Step: 4
Training loss: 0.3096154357563365
Validation loss: 2.331659914715443

Epoch: 6| Step: 5
Training loss: 0.20449394400205673
Validation loss: 2.3068685265602435

Epoch: 6| Step: 6
Training loss: 0.21544881063129917
Validation loss: 2.2967188775596945

Epoch: 6| Step: 7
Training loss: 0.3045156801372366
Validation loss: 2.2932106943200186

Epoch: 6| Step: 8
Training loss: 0.39679835247704315
Validation loss: 2.2894408832234263

Epoch: 6| Step: 9
Training loss: 0.28014002425889856
Validation loss: 2.2808701185838074

Epoch: 6| Step: 10
Training loss: 0.33843748127874745
Validation loss: 2.329595370297102

Epoch: 6| Step: 11
Training loss: 0.4572993739122367
Validation loss: 2.314949439549181

Epoch: 6| Step: 12
Training loss: 0.5199825649823171
Validation loss: 2.3169322968471087

Epoch: 6| Step: 13
Training loss: 0.31169427474457473
Validation loss: 2.333108828734082

Epoch: 316| Step: 0
Training loss: 0.3378898091389062
Validation loss: 2.2652704772686048

Epoch: 6| Step: 1
Training loss: 0.4202935104618351
Validation loss: 2.273375266710115

Epoch: 6| Step: 2
Training loss: 0.22566614747962035
Validation loss: 2.3382279002192337

Epoch: 6| Step: 3
Training loss: 0.30943955027394715
Validation loss: 2.305293177097555

Epoch: 6| Step: 4
Training loss: 0.28505015032379033
Validation loss: 2.346300509083085

Epoch: 6| Step: 5
Training loss: 0.41814279943194244
Validation loss: 2.3498557519943364

Epoch: 6| Step: 6
Training loss: 0.279647140681093
Validation loss: 2.32118290974217

Epoch: 6| Step: 7
Training loss: 0.25175262576043633
Validation loss: 2.3232163605143707

Epoch: 6| Step: 8
Training loss: 0.39802853782576153
Validation loss: 2.3367601389924992

Epoch: 6| Step: 9
Training loss: 0.5992826882758016
Validation loss: 2.3037979133275055

Epoch: 6| Step: 10
Training loss: 0.341882466089991
Validation loss: 2.3275887471238357

Epoch: 6| Step: 11
Training loss: 0.3122983758895765
Validation loss: 2.293895874096978

Epoch: 6| Step: 12
Training loss: 0.27797940440180735
Validation loss: 2.325489489667007

Epoch: 6| Step: 13
Training loss: 0.41284688611449577
Validation loss: 2.274384134373322

Epoch: 317| Step: 0
Training loss: 0.3325359659712847
Validation loss: 2.3070060317808485

Epoch: 6| Step: 1
Training loss: 0.298716717565961
Validation loss: 2.3288343573522297

Epoch: 6| Step: 2
Training loss: 0.3303711172042419
Validation loss: 2.2882618898193754

Epoch: 6| Step: 3
Training loss: 0.39503024432127704
Validation loss: 2.2981795760331223

Epoch: 6| Step: 4
Training loss: 0.29318313384113726
Validation loss: 2.3094876232224384

Epoch: 6| Step: 5
Training loss: 0.3818311959286902
Validation loss: 2.318156378369017

Epoch: 6| Step: 6
Training loss: 0.3244462191946517
Validation loss: 2.3123097384427966

Epoch: 6| Step: 7
Training loss: 0.3518005201136901
Validation loss: 2.2891743776931937

Epoch: 6| Step: 8
Training loss: 0.4588758624429062
Validation loss: 2.352600721810379

Epoch: 6| Step: 9
Training loss: 0.23653714733253722
Validation loss: 2.3281890041078874

Epoch: 6| Step: 10
Training loss: 0.2879813699549465
Validation loss: 2.35718566166213

Epoch: 6| Step: 11
Training loss: 0.30681517668578523
Validation loss: 2.295790279928607

Epoch: 6| Step: 12
Training loss: 0.37898851268540784
Validation loss: 2.2654922358757923

Epoch: 6| Step: 13
Training loss: 0.25182660201070683
Validation loss: 2.3428916546199225

Epoch: 318| Step: 0
Training loss: 0.36207159723870247
Validation loss: 2.240934936992935

Epoch: 6| Step: 1
Training loss: 0.2661195246812752
Validation loss: 2.2979364861757343

Epoch: 6| Step: 2
Training loss: 0.266676043492106
Validation loss: 2.3408480501872284

Epoch: 6| Step: 3
Training loss: 0.3762903662664636
Validation loss: 2.3105218176021802

Epoch: 6| Step: 4
Training loss: 0.2939471881591164
Validation loss: 2.3117777753374016

Epoch: 6| Step: 5
Training loss: 0.4078845556041765
Validation loss: 2.2524650545475517

Epoch: 6| Step: 6
Training loss: 0.3719765652676244
Validation loss: 2.324518247482832

Epoch: 6| Step: 7
Training loss: 0.3866675757254953
Validation loss: 2.3206333490864144

Epoch: 6| Step: 8
Training loss: 0.23901432649018184
Validation loss: 2.3120374818445355

Epoch: 6| Step: 9
Training loss: 0.3301729596482004
Validation loss: 2.325551831991782

Epoch: 6| Step: 10
Training loss: 0.535175350989954
Validation loss: 2.254958517027128

Epoch: 6| Step: 11
Training loss: 0.2597193712629375
Validation loss: 2.28678417852904

Epoch: 6| Step: 12
Training loss: 0.2036492295400711
Validation loss: 2.28327021569588

Epoch: 6| Step: 13
Training loss: 0.33730848141266667
Validation loss: 2.2790490772753977

Epoch: 319| Step: 0
Training loss: 0.20819232261360565
Validation loss: 2.276864194897586

Epoch: 6| Step: 1
Training loss: 0.3154526102813009
Validation loss: 2.2664248928919393

Epoch: 6| Step: 2
Training loss: 0.33615843582683846
Validation loss: 2.3049555218557156

Epoch: 6| Step: 3
Training loss: 0.360456725284998
Validation loss: 2.2659513304265557

Epoch: 6| Step: 4
Training loss: 0.24906234437274738
Validation loss: 2.2836245193348694

Epoch: 6| Step: 5
Training loss: 0.3846087838028311
Validation loss: 2.3338597646139734

Epoch: 6| Step: 6
Training loss: 0.357930348075233
Validation loss: 2.3371500038824826

Epoch: 6| Step: 7
Training loss: 0.26297460124531996
Validation loss: 2.2300874792853755

Epoch: 6| Step: 8
Training loss: 0.22623403350595642
Validation loss: 2.286128006508702

Epoch: 6| Step: 9
Training loss: 0.24917254004578382
Validation loss: 2.282453924760672

Epoch: 6| Step: 10
Training loss: 0.39584773020747066
Validation loss: 2.28381663994459

Epoch: 6| Step: 11
Training loss: 0.5482413525332082
Validation loss: 2.2948937380533554

Epoch: 6| Step: 12
Training loss: 0.4822128399008476
Validation loss: 2.2175675765115854

Epoch: 6| Step: 13
Training loss: 0.22459624708206538
Validation loss: 2.275508317645937

Epoch: 320| Step: 0
Training loss: 0.371891749830249
Validation loss: 2.327222755943345

Epoch: 6| Step: 1
Training loss: 0.38691041993800385
Validation loss: 2.33436730726984

Epoch: 6| Step: 2
Training loss: 0.26553542365814026
Validation loss: 2.3253429696533403

Epoch: 6| Step: 3
Training loss: 0.3012930738750084
Validation loss: 2.3255145395727026

Epoch: 6| Step: 4
Training loss: 0.41527834109555545
Validation loss: 2.265723075059361

Epoch: 6| Step: 5
Training loss: 0.3527022430553554
Validation loss: 2.324503204292074

Epoch: 6| Step: 6
Training loss: 0.3490367013794335
Validation loss: 2.302602646079457

Epoch: 6| Step: 7
Training loss: 0.465087890625
Validation loss: 2.269953825714872

Epoch: 6| Step: 8
Training loss: 0.2869863311348664
Validation loss: 2.3323037282800225

Epoch: 6| Step: 9
Training loss: 0.34465664811110913
Validation loss: 2.302696920127497

Epoch: 6| Step: 10
Training loss: 0.3242206343630528
Validation loss: 2.3100850838794154

Epoch: 6| Step: 11
Training loss: 0.24178908247708644
Validation loss: 2.242982747720648

Epoch: 6| Step: 12
Training loss: 0.341979125343682
Validation loss: 2.3169144431606163

Epoch: 6| Step: 13
Training loss: 0.2077644428817124
Validation loss: 2.338041295906498

Epoch: 321| Step: 0
Training loss: 0.31419423505167376
Validation loss: 2.311935905870487

Epoch: 6| Step: 1
Training loss: 0.3765408925232157
Validation loss: 2.2153965586989215

Epoch: 6| Step: 2
Training loss: 0.31974905747013
Validation loss: 2.364012322961733

Epoch: 6| Step: 3
Training loss: 0.40268642684009626
Validation loss: 2.272562756652809

Epoch: 6| Step: 4
Training loss: 0.32721654837709874
Validation loss: 2.2960325932327073

Epoch: 6| Step: 5
Training loss: 0.41196565698334847
Validation loss: 2.289128012907701

Epoch: 6| Step: 6
Training loss: 0.41824068154159827
Validation loss: 2.279301756412582

Epoch: 6| Step: 7
Training loss: 0.2901123416691626
Validation loss: 2.2462926627275297

Epoch: 6| Step: 8
Training loss: 0.28281483833652993
Validation loss: 2.274457896972978

Epoch: 6| Step: 9
Training loss: 0.20128078660584406
Validation loss: 2.277033021818387

Epoch: 6| Step: 10
Training loss: 0.2869587198070857
Validation loss: 2.288975276739066

Epoch: 6| Step: 11
Training loss: 0.28367204977632654
Validation loss: 2.276125652471727

Epoch: 6| Step: 12
Training loss: 0.46151167458659603
Validation loss: 2.2945099416281747

Epoch: 6| Step: 13
Training loss: 0.262693156974486
Validation loss: 2.195427327077394

Epoch: 322| Step: 0
Training loss: 0.3271121332322426
Validation loss: 2.2778601347241403

Epoch: 6| Step: 1
Training loss: 0.3117167910177298
Validation loss: 2.2944904154476693

Epoch: 6| Step: 2
Training loss: 0.3226921264801468
Validation loss: 2.298710018679414

Epoch: 6| Step: 3
Training loss: 0.2626170499143931
Validation loss: 2.2624678087842294

Epoch: 6| Step: 4
Training loss: 0.3794858177070619
Validation loss: 2.3008707889389792

Epoch: 6| Step: 5
Training loss: 0.342000366670847
Validation loss: 2.340631215554555

Epoch: 6| Step: 6
Training loss: 0.3780447614673391
Validation loss: 2.271760512121023

Epoch: 6| Step: 7
Training loss: 0.4032387639471037
Validation loss: 2.2731887926043455

Epoch: 6| Step: 8
Training loss: 0.19494464565437153
Validation loss: 2.3360281408919636

Epoch: 6| Step: 9
Training loss: 0.28941501567331956
Validation loss: 2.3398058192469566

Epoch: 6| Step: 10
Training loss: 0.28623891432089676
Validation loss: 2.3076021030108964

Epoch: 6| Step: 11
Training loss: 0.4391778210732025
Validation loss: 2.267383357885429

Epoch: 6| Step: 12
Training loss: 0.5367286303636633
Validation loss: 2.335934455044568

Epoch: 6| Step: 13
Training loss: 0.4381265071293353
Validation loss: 2.3304341788418017

Epoch: 323| Step: 0
Training loss: 0.2969535798930172
Validation loss: 2.3063897694427737

Epoch: 6| Step: 1
Training loss: 0.3954474697469074
Validation loss: 2.298951246431873

Epoch: 6| Step: 2
Training loss: 0.294208649448264
Validation loss: 2.341585304050446

Epoch: 6| Step: 3
Training loss: 0.3355487969979606
Validation loss: 2.2801639288256683

Epoch: 6| Step: 4
Training loss: 0.4273264782080996
Validation loss: 2.303028608812807

Epoch: 6| Step: 5
Training loss: 0.2936078285548874
Validation loss: 2.3093634116880457

Epoch: 6| Step: 6
Training loss: 0.34015887547234547
Validation loss: 2.2888724168963543

Epoch: 6| Step: 7
Training loss: 0.2467468239827198
Validation loss: 2.3381195678620643

Epoch: 6| Step: 8
Training loss: 0.25639095848927085
Validation loss: 2.305679504351439

Epoch: 6| Step: 9
Training loss: 0.29141277377519453
Validation loss: 2.2144630279830992

Epoch: 6| Step: 10
Training loss: 0.3073710107470785
Validation loss: 2.286705982696963

Epoch: 6| Step: 11
Training loss: 0.37350316128803646
Validation loss: 2.295337274710693

Epoch: 6| Step: 12
Training loss: 0.2452421439776191
Validation loss: 2.2565511416226993

Epoch: 6| Step: 13
Training loss: 0.33468399610564126
Validation loss: 2.3182623097583037

Epoch: 324| Step: 0
Training loss: 0.42302893955467424
Validation loss: 2.341892252155112

Epoch: 6| Step: 1
Training loss: 0.43112493581265365
Validation loss: 2.3069376935891346

Epoch: 6| Step: 2
Training loss: 0.3582901336260638
Validation loss: 2.303255021778549

Epoch: 6| Step: 3
Training loss: 0.5373799700120064
Validation loss: 2.2820416474750296

Epoch: 6| Step: 4
Training loss: 0.3897971345173758
Validation loss: 2.26551353794269

Epoch: 6| Step: 5
Training loss: 0.3246149836123403
Validation loss: 2.3256104136290365

Epoch: 6| Step: 6
Training loss: 0.617953320297345
Validation loss: 2.3748702800192567

Epoch: 6| Step: 7
Training loss: 0.4008668997635812
Validation loss: 2.311579443732947

Epoch: 6| Step: 8
Training loss: 0.3814776756984272
Validation loss: 2.256684563827355

Epoch: 6| Step: 9
Training loss: 0.32350431572188887
Validation loss: 2.3016596414300916

Epoch: 6| Step: 10
Training loss: 0.24199441934931082
Validation loss: 2.2990889140696966

Epoch: 6| Step: 11
Training loss: 0.15869077242211163
Validation loss: 2.2850011354495066

Epoch: 6| Step: 12
Training loss: 0.3507845855078532
Validation loss: 2.3025972100611325

Epoch: 6| Step: 13
Training loss: 0.38159205069994157
Validation loss: 2.3043558604107135

Epoch: 325| Step: 0
Training loss: 0.24217573260360617
Validation loss: 2.291338157227342

Epoch: 6| Step: 1
Training loss: 0.3556833981532344
Validation loss: 2.2685442303118055

Epoch: 6| Step: 2
Training loss: 0.3270999701737542
Validation loss: 2.3055499171248077

Epoch: 6| Step: 3
Training loss: 0.3334333883065975
Validation loss: 2.3060457871471742

Epoch: 6| Step: 4
Training loss: 0.3297817095620756
Validation loss: 2.3336058582374486

Epoch: 6| Step: 5
Training loss: 0.45041373161338305
Validation loss: 2.301878239628251

Epoch: 6| Step: 6
Training loss: 0.28029612539088966
Validation loss: 2.2519835541459488

Epoch: 6| Step: 7
Training loss: 0.2832630620210581
Validation loss: 2.2568730002286737

Epoch: 6| Step: 8
Training loss: 0.22638591099768493
Validation loss: 2.3112137112503146

Epoch: 6| Step: 9
Training loss: 0.22858938836182227
Validation loss: 2.270727370936753

Epoch: 6| Step: 10
Training loss: 0.3778447097540234
Validation loss: 2.2375100290084355

Epoch: 6| Step: 11
Training loss: 0.5756834902128299
Validation loss: 2.268734160018565

Epoch: 6| Step: 12
Training loss: 0.4234074381330824
Validation loss: 2.3679141533461436

Epoch: 6| Step: 13
Training loss: 0.22433199963242859
Validation loss: 2.3166186796565365

Epoch: 326| Step: 0
Training loss: 0.2359354445386871
Validation loss: 2.275200578559752

Epoch: 6| Step: 1
Training loss: 0.2529352253782618
Validation loss: 2.3104247154689572

Epoch: 6| Step: 2
Training loss: 0.3151079432468722
Validation loss: 2.3068294765459556

Epoch: 6| Step: 3
Training loss: 0.3675826969328596
Validation loss: 2.2971554885493024

Epoch: 6| Step: 4
Training loss: 0.4321070261442948
Validation loss: 2.274252327125446

Epoch: 6| Step: 5
Training loss: 0.3003516039164268
Validation loss: 2.314811719539127

Epoch: 6| Step: 6
Training loss: 0.3426497146463312
Validation loss: 2.2990690724628613

Epoch: 6| Step: 7
Training loss: 0.1994463424635103
Validation loss: 2.3494595643459504

Epoch: 6| Step: 8
Training loss: 0.3617222054565691
Validation loss: 2.348585312033193

Epoch: 6| Step: 9
Training loss: 0.30255379982621894
Validation loss: 2.2622381216836147

Epoch: 6| Step: 10
Training loss: 0.225721343385622
Validation loss: 2.3596081650069687

Epoch: 6| Step: 11
Training loss: 0.2841278763041012
Validation loss: 2.3370862366818175

Epoch: 6| Step: 12
Training loss: 0.3417402820056576
Validation loss: 2.293601620800939

Epoch: 6| Step: 13
Training loss: 0.4218357209181139
Validation loss: 2.2894581701230368

Epoch: 327| Step: 0
Training loss: 0.30969075889296965
Validation loss: 2.338253442437705

Epoch: 6| Step: 1
Training loss: 0.3159164122081776
Validation loss: 2.3001466922005593

Epoch: 6| Step: 2
Training loss: 0.3223390553364157
Validation loss: 2.306972220346319

Epoch: 6| Step: 3
Training loss: 0.3482249248716805
Validation loss: 2.2507619362412603

Epoch: 6| Step: 4
Training loss: 0.22553240153190623
Validation loss: 2.302440966506202

Epoch: 6| Step: 5
Training loss: 0.34656445374552974
Validation loss: 2.2719773610110954

Epoch: 6| Step: 6
Training loss: 0.3073273398280569
Validation loss: 2.3016335032056063

Epoch: 6| Step: 7
Training loss: 0.2827084660840174
Validation loss: 2.3147717563721715

Epoch: 6| Step: 8
Training loss: 0.2927805614050069
Validation loss: 2.282502061579018

Epoch: 6| Step: 9
Training loss: 0.415411210108778
Validation loss: 2.266840255859491

Epoch: 6| Step: 10
Training loss: 0.30856845848646286
Validation loss: 2.2717595500899934

Epoch: 6| Step: 11
Training loss: 0.4799587675604236
Validation loss: 2.293974898813213

Epoch: 6| Step: 12
Training loss: 0.24371136884961458
Validation loss: 2.3304937289931864

Epoch: 6| Step: 13
Training loss: 0.22288325098664422
Validation loss: 2.303651341854245

Epoch: 328| Step: 0
Training loss: 0.41850268049304595
Validation loss: 2.315404837400039

Epoch: 6| Step: 1
Training loss: 0.22064133851067186
Validation loss: 2.28175702840052

Epoch: 6| Step: 2
Training loss: 0.2634220069637383
Validation loss: 2.330565724245221

Epoch: 6| Step: 3
Training loss: 0.35324339105750535
Validation loss: 2.3349867026517446

Epoch: 6| Step: 4
Training loss: 0.28992030734124324
Validation loss: 2.2579529222514365

Epoch: 6| Step: 5
Training loss: 0.3193968618528705
Validation loss: 2.3026931840978153

Epoch: 6| Step: 6
Training loss: 0.3775833672243057
Validation loss: 2.324259063627533

Epoch: 6| Step: 7
Training loss: 0.3348441406902788
Validation loss: 2.3124347454177574

Epoch: 6| Step: 8
Training loss: 0.3974993263094969
Validation loss: 2.320196198054385

Epoch: 6| Step: 9
Training loss: 0.4273674492828659
Validation loss: 2.2785110753493174

Epoch: 6| Step: 10
Training loss: 0.25652507636817573
Validation loss: 2.3509487225559913

Epoch: 6| Step: 11
Training loss: 0.30614406933470434
Validation loss: 2.2744460692609807

Epoch: 6| Step: 12
Training loss: 0.319926447946286
Validation loss: 2.2874872822225605

Epoch: 6| Step: 13
Training loss: 0.216984178204714
Validation loss: 2.3317365859561883

Epoch: 329| Step: 0
Training loss: 0.2587835203333069
Validation loss: 2.298375640735166

Epoch: 6| Step: 1
Training loss: 0.30123917289129126
Validation loss: 2.2695378857689046

Epoch: 6| Step: 2
Training loss: 0.24560533223992076
Validation loss: 2.317186383971419

Epoch: 6| Step: 3
Training loss: 0.2748162793803393
Validation loss: 2.2499442535134855

Epoch: 6| Step: 4
Training loss: 0.348952427382334
Validation loss: 2.3290671846530415

Epoch: 6| Step: 5
Training loss: 0.24297056964057961
Validation loss: 2.323884879102274

Epoch: 6| Step: 6
Training loss: 0.4571713289958836
Validation loss: 2.2697654861497245

Epoch: 6| Step: 7
Training loss: 0.2638892090458071
Validation loss: 2.279004781879532

Epoch: 6| Step: 8
Training loss: 0.37377560923306447
Validation loss: 2.339581338457552

Epoch: 6| Step: 9
Training loss: 0.29934766895513737
Validation loss: 2.289500336766904

Epoch: 6| Step: 10
Training loss: 0.40113876042668006
Validation loss: 2.2848664624393287

Epoch: 6| Step: 11
Training loss: 0.21658242418857446
Validation loss: 2.302931734255157

Epoch: 6| Step: 12
Training loss: 0.3375560559415359
Validation loss: 2.2930772659297824

Epoch: 6| Step: 13
Training loss: 0.3256351943992072
Validation loss: 2.328589237361234

Epoch: 330| Step: 0
Training loss: 0.2878974427201387
Validation loss: 2.2917964089397858

Epoch: 6| Step: 1
Training loss: 0.48321008577012853
Validation loss: 2.2956923296691194

Epoch: 6| Step: 2
Training loss: 0.46144567376102213
Validation loss: 2.295520668639683

Epoch: 6| Step: 3
Training loss: 0.28952031353193824
Validation loss: 2.279324890679322

Epoch: 6| Step: 4
Training loss: 0.3167895832469071
Validation loss: 2.3315832920815023

Epoch: 6| Step: 5
Training loss: 0.27306066159000353
Validation loss: 2.2964563485594116

Epoch: 6| Step: 6
Training loss: 0.3949063472543923
Validation loss: 2.267532641699158

Epoch: 6| Step: 7
Training loss: 0.4423775072600709
Validation loss: 2.2700292814497622

Epoch: 6| Step: 8
Training loss: 0.41051325928093474
Validation loss: 2.3572238606135

Epoch: 6| Step: 9
Training loss: 0.24963385621608586
Validation loss: 2.3147789491064845

Epoch: 6| Step: 10
Training loss: 0.2767005904327879
Validation loss: 2.3069124333519047

Epoch: 6| Step: 11
Training loss: 0.36082956095537666
Validation loss: 2.295835064946772

Epoch: 6| Step: 12
Training loss: 0.35201582821092536
Validation loss: 2.3278277162547973

Epoch: 6| Step: 13
Training loss: 0.45429532419007257
Validation loss: 2.2796860651086237

Epoch: 331| Step: 0
Training loss: 0.26593184979507034
Validation loss: 2.345803577602522

Epoch: 6| Step: 1
Training loss: 0.442091418500067
Validation loss: 2.2920882675301786

Epoch: 6| Step: 2
Training loss: 0.343928691629217
Validation loss: 2.3105353610132644

Epoch: 6| Step: 3
Training loss: 0.3570632177352703
Validation loss: 2.313052858816556

Epoch: 6| Step: 4
Training loss: 0.2992289728156387
Validation loss: 2.3257671936245963

Epoch: 6| Step: 5
Training loss: 0.2874251205953727
Validation loss: 2.2742865551129787

Epoch: 6| Step: 6
Training loss: 0.32784863595555136
Validation loss: 2.3128292261783447

Epoch: 6| Step: 7
Training loss: 0.29759944814337946
Validation loss: 2.333684925996686

Epoch: 6| Step: 8
Training loss: 0.3148572942504007
Validation loss: 2.301312966425508

Epoch: 6| Step: 9
Training loss: 0.23437083558515467
Validation loss: 2.3618792450001855

Epoch: 6| Step: 10
Training loss: 0.19312460933263084
Validation loss: 2.3074103268205803

Epoch: 6| Step: 11
Training loss: 0.3544108610156807
Validation loss: 2.296088440828263

Epoch: 6| Step: 12
Training loss: 0.4168105433331322
Validation loss: 2.2940110410603642

Epoch: 6| Step: 13
Training loss: 0.372680564103174
Validation loss: 2.2623386444948235

Epoch: 332| Step: 0
Training loss: 0.3682368482285799
Validation loss: 2.307830718874016

Epoch: 6| Step: 1
Training loss: 0.41054688879243517
Validation loss: 2.280494739105149

Epoch: 6| Step: 2
Training loss: 0.2956743808416991
Validation loss: 2.2914766810878264

Epoch: 6| Step: 3
Training loss: 0.3707453648386132
Validation loss: 2.2662044091188034

Epoch: 6| Step: 4
Training loss: 0.48696122841937184
Validation loss: 2.3290221941185134

Epoch: 6| Step: 5
Training loss: 0.4743630982967861
Validation loss: 2.288559130285275

Epoch: 6| Step: 6
Training loss: 0.24971319675106796
Validation loss: 2.3354763821928275

Epoch: 6| Step: 7
Training loss: 0.291164398568197
Validation loss: 2.3242231694882047

Epoch: 6| Step: 8
Training loss: 0.24732690988784758
Validation loss: 2.2660232807729996

Epoch: 6| Step: 9
Training loss: 0.29528064253194825
Validation loss: 2.2990000230275633

Epoch: 6| Step: 10
Training loss: 0.2786854005808523
Validation loss: 2.263219885344808

Epoch: 6| Step: 11
Training loss: 0.3007069533102654
Validation loss: 2.3597762585578073

Epoch: 6| Step: 12
Training loss: 0.2157754463061686
Validation loss: 2.3528526712582956

Epoch: 6| Step: 13
Training loss: 0.22582057623591295
Validation loss: 2.3332744630698583

Epoch: 333| Step: 0
Training loss: 0.3575306919568007
Validation loss: 2.3202560366558296

Epoch: 6| Step: 1
Training loss: 0.3433699891551389
Validation loss: 2.3274763257563715

Epoch: 6| Step: 2
Training loss: 0.28507775049245104
Validation loss: 2.289168770919553

Epoch: 6| Step: 3
Training loss: 0.3308335187192409
Validation loss: 2.323255408753057

Epoch: 6| Step: 4
Training loss: 0.32568655627503207
Validation loss: 2.279171915995558

Epoch: 6| Step: 5
Training loss: 0.2946687837646201
Validation loss: 2.3282269193114966

Epoch: 6| Step: 6
Training loss: 0.26406968801071384
Validation loss: 2.3099859507520195

Epoch: 6| Step: 7
Training loss: 0.21476873475366592
Validation loss: 2.293214454462176

Epoch: 6| Step: 8
Training loss: 0.31634885950360736
Validation loss: 2.3161514339346425

Epoch: 6| Step: 9
Training loss: 0.26107252818896054
Validation loss: 2.3085553316124376

Epoch: 6| Step: 10
Training loss: 0.3004360199398424
Validation loss: 2.2935133747004417

Epoch: 6| Step: 11
Training loss: 0.41043077999705513
Validation loss: 2.306584955373261

Epoch: 6| Step: 12
Training loss: 0.3080307375661855
Validation loss: 2.334792546553242

Epoch: 6| Step: 13
Training loss: 0.2619703563753332
Validation loss: 2.2732853439818235

Epoch: 334| Step: 0
Training loss: 0.31927368303845327
Validation loss: 2.2629460687143133

Epoch: 6| Step: 1
Training loss: 0.38634116109332206
Validation loss: 2.3024441420482273

Epoch: 6| Step: 2
Training loss: 0.36006575003853786
Validation loss: 2.305042304190725

Epoch: 6| Step: 3
Training loss: 0.3610198484337596
Validation loss: 2.35358434130968

Epoch: 6| Step: 4
Training loss: 0.3479583584861547
Validation loss: 2.2863946151254884

Epoch: 6| Step: 5
Training loss: 0.36631205879266865
Validation loss: 2.3010016844697834

Epoch: 6| Step: 6
Training loss: 0.2795312338371123
Validation loss: 2.265100922753619

Epoch: 6| Step: 7
Training loss: 0.4704360520812024
Validation loss: 2.263918143813423

Epoch: 6| Step: 8
Training loss: 0.2841478310259417
Validation loss: 2.2964907820040628

Epoch: 6| Step: 9
Training loss: 0.23776040451506592
Validation loss: 2.2576727378380967

Epoch: 6| Step: 10
Training loss: 0.2124619937315698
Validation loss: 2.3168268534855554

Epoch: 6| Step: 11
Training loss: 0.31011663179051085
Validation loss: 2.3007246700253345

Epoch: 6| Step: 12
Training loss: 0.2800340061739613
Validation loss: 2.3119280167882796

Epoch: 6| Step: 13
Training loss: 0.378946282543124
Validation loss: 2.324579444914366

Epoch: 335| Step: 0
Training loss: 0.4042341948494033
Validation loss: 2.384492975718574

Epoch: 6| Step: 1
Training loss: 0.1873307059855805
Validation loss: 2.387398314515849

Epoch: 6| Step: 2
Training loss: 0.4419041922340422
Validation loss: 2.336062586400471

Epoch: 6| Step: 3
Training loss: 0.38168206980633973
Validation loss: 2.379866416184884

Epoch: 6| Step: 4
Training loss: 0.28692008285490417
Validation loss: 2.274636624209218

Epoch: 6| Step: 5
Training loss: 0.30190580868330913
Validation loss: 2.29356240554356

Epoch: 6| Step: 6
Training loss: 0.34615152449420233
Validation loss: 2.331969217213388

Epoch: 6| Step: 7
Training loss: 0.22011260981568118
Validation loss: 2.3188181131097787

Epoch: 6| Step: 8
Training loss: 0.2887372429411786
Validation loss: 2.301392099046614

Epoch: 6| Step: 9
Training loss: 0.38888080291440325
Validation loss: 2.329353699541975

Epoch: 6| Step: 10
Training loss: 0.1516029675032066
Validation loss: 2.340117644941846

Epoch: 6| Step: 11
Training loss: 0.2504116483958838
Validation loss: 2.308162745795426

Epoch: 6| Step: 12
Training loss: 0.3338325556972802
Validation loss: 2.319244121674963

Epoch: 6| Step: 13
Training loss: 0.38380038023900515
Validation loss: 2.357799054228185

Epoch: 336| Step: 0
Training loss: 0.3446496007666855
Validation loss: 2.3353698619153116

Epoch: 6| Step: 1
Training loss: 0.24990538952645805
Validation loss: 2.3675934178103337

Epoch: 6| Step: 2
Training loss: 0.24126991137920317
Validation loss: 2.287321858861026

Epoch: 6| Step: 3
Training loss: 0.2328346657921937
Validation loss: 2.291761012013735

Epoch: 6| Step: 4
Training loss: 0.20268858280357288
Validation loss: 2.357159835718501

Epoch: 6| Step: 5
Training loss: 0.2741842699245417
Validation loss: 2.341329867916359

Epoch: 6| Step: 6
Training loss: 0.318428874474562
Validation loss: 2.296110168585235

Epoch: 6| Step: 7
Training loss: 0.3498192269239214
Validation loss: 2.31933708538897

Epoch: 6| Step: 8
Training loss: 0.42998352257629424
Validation loss: 2.336609997690233

Epoch: 6| Step: 9
Training loss: 0.23554764489701246
Validation loss: 2.2887255666954007

Epoch: 6| Step: 10
Training loss: 0.259228933524066
Validation loss: 2.352367757511934

Epoch: 6| Step: 11
Training loss: 0.4119103299040095
Validation loss: 2.2936990366721592

Epoch: 6| Step: 12
Training loss: 0.45440422554423004
Validation loss: 2.3359335874867075

Epoch: 6| Step: 13
Training loss: 0.2108540811541978
Validation loss: 2.352026943164916

Epoch: 337| Step: 0
Training loss: 0.22997613566663835
Validation loss: 2.3094155644840537

Epoch: 6| Step: 1
Training loss: 0.33456467525189065
Validation loss: 2.2881256894587563

Epoch: 6| Step: 2
Training loss: 0.28874955119473805
Validation loss: 2.3163727902102065

Epoch: 6| Step: 3
Training loss: 0.34381701076359117
Validation loss: 2.2770594598810594

Epoch: 6| Step: 4
Training loss: 0.1597594369561993
Validation loss: 2.3017827408802494

Epoch: 6| Step: 5
Training loss: 0.29893792073856057
Validation loss: 2.25171843003588

Epoch: 6| Step: 6
Training loss: 0.2921971778490845
Validation loss: 2.2873323431225048

Epoch: 6| Step: 7
Training loss: 0.19463014616621538
Validation loss: 2.3532762841053927

Epoch: 6| Step: 8
Training loss: 0.2926739290094172
Validation loss: 2.3278626159689244

Epoch: 6| Step: 9
Training loss: 0.2926729871013811
Validation loss: 2.2810038429427455

Epoch: 6| Step: 10
Training loss: 0.27011025475730405
Validation loss: 2.3074754824012613

Epoch: 6| Step: 11
Training loss: 0.22672396693941266
Validation loss: 2.336659833292236

Epoch: 6| Step: 12
Training loss: 0.3137281839985379
Validation loss: 2.302451183451878

Epoch: 6| Step: 13
Training loss: 0.4064342007820619
Validation loss: 2.278920573792305

Epoch: 338| Step: 0
Training loss: 0.3868505080055194
Validation loss: 2.333805714769521

Epoch: 6| Step: 1
Training loss: 0.33143265564579494
Validation loss: 2.271804380303133

Epoch: 6| Step: 2
Training loss: 0.3264096130336626
Validation loss: 2.319752001469672

Epoch: 6| Step: 3
Training loss: 0.3166392845729689
Validation loss: 2.3728184635873326

Epoch: 6| Step: 4
Training loss: 0.23342920044746324
Validation loss: 2.2614141598438406

Epoch: 6| Step: 5
Training loss: 0.25657521638010866
Validation loss: 2.2842923435994393

Epoch: 6| Step: 6
Training loss: 0.30798497088103094
Validation loss: 2.330535494182915

Epoch: 6| Step: 7
Training loss: 0.3321139849636941
Validation loss: 2.3411919939683417

Epoch: 6| Step: 8
Training loss: 0.3922104893363771
Validation loss: 2.3279328490974396

Epoch: 6| Step: 9
Training loss: 0.41816660396083355
Validation loss: 2.3459423238619053

Epoch: 6| Step: 10
Training loss: 0.1967952426692781
Validation loss: 2.313295794502149

Epoch: 6| Step: 11
Training loss: 0.250922497815127
Validation loss: 2.302348727179995

Epoch: 6| Step: 12
Training loss: 0.2734651006665007
Validation loss: 2.3414738516880638

Epoch: 6| Step: 13
Training loss: 0.44804966600608065
Validation loss: 2.353081796425973

Epoch: 339| Step: 0
Training loss: 0.47126369415947034
Validation loss: 2.3026445547613075

Epoch: 6| Step: 1
Training loss: 0.4933246313382239
Validation loss: 2.29631606586838

Epoch: 6| Step: 2
Training loss: 0.2878178399674764
Validation loss: 2.3044957485279767

Epoch: 6| Step: 3
Training loss: 0.31166742997067526
Validation loss: 2.3237659087995124

Epoch: 6| Step: 4
Training loss: 0.28127884716867724
Validation loss: 2.314279241240272

Epoch: 6| Step: 5
Training loss: 0.1885970131023693
Validation loss: 2.3357897045113396

Epoch: 6| Step: 6
Training loss: 0.25445523700066003
Validation loss: 2.331942115157979

Epoch: 6| Step: 7
Training loss: 0.3280509910679577
Validation loss: 2.3468191947008123

Epoch: 6| Step: 8
Training loss: 0.3357324861785908
Validation loss: 2.2735706565637845

Epoch: 6| Step: 9
Training loss: 0.37997984443717187
Validation loss: 2.2659549516721214

Epoch: 6| Step: 10
Training loss: 0.2358339360288955
Validation loss: 2.309163736979144

Epoch: 6| Step: 11
Training loss: 0.2614505731841906
Validation loss: 2.3073118795940393

Epoch: 6| Step: 12
Training loss: 0.3285877280198184
Validation loss: 2.2986883500699866

Epoch: 6| Step: 13
Training loss: 0.2599997075244286
Validation loss: 2.330572953485723

Epoch: 340| Step: 0
Training loss: 0.3636494278254335
Validation loss: 2.300257763032791

Epoch: 6| Step: 1
Training loss: 0.4887727018971835
Validation loss: 2.3153823382189893

Epoch: 6| Step: 2
Training loss: 0.6252175906024677
Validation loss: 2.333722343260515

Epoch: 6| Step: 3
Training loss: 0.4057659419789057
Validation loss: 2.344273207863232

Epoch: 6| Step: 4
Training loss: 0.39599387359937516
Validation loss: 2.3236844001527106

Epoch: 6| Step: 5
Training loss: 0.3450532829215832
Validation loss: 2.3366763032105924

Epoch: 6| Step: 6
Training loss: 0.3205793711149128
Validation loss: 2.2505314605492583

Epoch: 6| Step: 7
Training loss: 0.3278716108050263
Validation loss: 2.2640146078867356

Epoch: 6| Step: 8
Training loss: 0.3417699094761984
Validation loss: 2.3082120077380055

Epoch: 6| Step: 9
Training loss: 0.33046159533608327
Validation loss: 2.2509161443869896

Epoch: 6| Step: 10
Training loss: 0.2726031926732537
Validation loss: 2.251001523666284

Epoch: 6| Step: 11
Training loss: 0.3083012921314278
Validation loss: 2.2970018589685957

Epoch: 6| Step: 12
Training loss: 0.20800062176091083
Validation loss: 2.2994866779646808

Epoch: 6| Step: 13
Training loss: 0.2577613866595978
Validation loss: 2.2943950594907814

Epoch: 341| Step: 0
Training loss: 0.3647054626630498
Validation loss: 2.275452960337917

Epoch: 6| Step: 1
Training loss: 0.2897961687994775
Validation loss: 2.26219342685525

Epoch: 6| Step: 2
Training loss: 0.29994141384114065
Validation loss: 2.2179736090868105

Epoch: 6| Step: 3
Training loss: 0.32238381270439864
Validation loss: 2.2929929074558832

Epoch: 6| Step: 4
Training loss: 0.2666538313046608
Validation loss: 2.2802468275849663

Epoch: 6| Step: 5
Training loss: 0.2473618517509447
Validation loss: 2.3142243906728956

Epoch: 6| Step: 6
Training loss: 0.31091793851806143
Validation loss: 2.2846044846962776

Epoch: 6| Step: 7
Training loss: 0.275136898384894
Validation loss: 2.2847797833592773

Epoch: 6| Step: 8
Training loss: 0.38716923840725487
Validation loss: 2.330795173491764

Epoch: 6| Step: 9
Training loss: 0.2932712265033331
Validation loss: 2.326376529363441

Epoch: 6| Step: 10
Training loss: 0.26591573960136583
Validation loss: 2.3091010984732074

Epoch: 6| Step: 11
Training loss: 0.22832237941044603
Validation loss: 2.330869009131115

Epoch: 6| Step: 12
Training loss: 0.256843320211034
Validation loss: 2.3059522272864816

Epoch: 6| Step: 13
Training loss: 0.3569686809781173
Validation loss: 2.3015497259513675

Epoch: 342| Step: 0
Training loss: 0.3008738660034249
Validation loss: 2.3109365453367774

Epoch: 6| Step: 1
Training loss: 0.16887677737485907
Validation loss: 2.3227657103704686

Epoch: 6| Step: 2
Training loss: 0.35003914869571556
Validation loss: 2.2788340521687873

Epoch: 6| Step: 3
Training loss: 0.29512124554250657
Validation loss: 2.3227310334574285

Epoch: 6| Step: 4
Training loss: 0.3365333064177009
Validation loss: 2.3364799150435895

Epoch: 6| Step: 5
Training loss: 0.44531598006110035
Validation loss: 2.300341889637138

Epoch: 6| Step: 6
Training loss: 0.3112889905429967
Validation loss: 2.257385389503254

Epoch: 6| Step: 7
Training loss: 0.22033938250651575
Validation loss: 2.332069452037827

Epoch: 6| Step: 8
Training loss: 0.2738101735672537
Validation loss: 2.2372240606749387

Epoch: 6| Step: 9
Training loss: 0.34011448566541724
Validation loss: 2.3293293477013215

Epoch: 6| Step: 10
Training loss: 0.38419974293648074
Validation loss: 2.2992531019801477

Epoch: 6| Step: 11
Training loss: 0.3843245131978187
Validation loss: 2.254275066451139

Epoch: 6| Step: 12
Training loss: 0.225106990066279
Validation loss: 2.2912745458186823

Epoch: 6| Step: 13
Training loss: 0.3925670033867544
Validation loss: 2.294586304283493

Epoch: 343| Step: 0
Training loss: 0.44523228374578444
Validation loss: 2.2762722244867573

Epoch: 6| Step: 1
Training loss: 0.3918980263450316
Validation loss: 2.294644386343299

Epoch: 6| Step: 2
Training loss: 0.28299728015917036
Validation loss: 2.2959643005244077

Epoch: 6| Step: 3
Training loss: 0.2854453150207885
Validation loss: 2.2978033840815373

Epoch: 6| Step: 4
Training loss: 0.23195289933016044
Validation loss: 2.3249352042764033

Epoch: 6| Step: 5
Training loss: 0.2777119060070964
Validation loss: 2.31344643548125

Epoch: 6| Step: 6
Training loss: 0.32822423524258276
Validation loss: 2.334444510885923

Epoch: 6| Step: 7
Training loss: 0.33869166596872746
Validation loss: 2.2486651310889556

Epoch: 6| Step: 8
Training loss: 0.33204695720545035
Validation loss: 2.338549715182608

Epoch: 6| Step: 9
Training loss: 0.30533721316224127
Validation loss: 2.2817187763874056

Epoch: 6| Step: 10
Training loss: 0.34809664360793685
Validation loss: 2.3031086831828245

Epoch: 6| Step: 11
Training loss: 0.21798011996239938
Validation loss: 2.248814933013257

Epoch: 6| Step: 12
Training loss: 0.3436374371637947
Validation loss: 2.317986192370837

Epoch: 6| Step: 13
Training loss: 0.5184021346416204
Validation loss: 2.3169520626555964

Epoch: 344| Step: 0
Training loss: 0.32833450304870276
Validation loss: 2.36583613230813

Epoch: 6| Step: 1
Training loss: 0.48562034364134754
Validation loss: 2.317528747001711

Epoch: 6| Step: 2
Training loss: 0.29931839760247037
Validation loss: 2.3038664653866223

Epoch: 6| Step: 3
Training loss: 0.32582492992942147
Validation loss: 2.2958214607785647

Epoch: 6| Step: 4
Training loss: 0.31730716684160093
Validation loss: 2.3478562475608924

Epoch: 6| Step: 5
Training loss: 0.44418349113711086
Validation loss: 2.3176393020007815

Epoch: 6| Step: 6
Training loss: 0.25438032641446195
Validation loss: 2.307643705655045

Epoch: 6| Step: 7
Training loss: 0.2486071903784181
Validation loss: 2.2786046022590396

Epoch: 6| Step: 8
Training loss: 0.19497302116317247
Validation loss: 2.3313576360677013

Epoch: 6| Step: 9
Training loss: 0.427443226702977
Validation loss: 2.3016718817515294

Epoch: 6| Step: 10
Training loss: 0.3686573558744546
Validation loss: 2.2402483876773136

Epoch: 6| Step: 11
Training loss: 0.2689043854688143
Validation loss: 2.300072690948407

Epoch: 6| Step: 12
Training loss: 0.22485976153551163
Validation loss: 2.292839934821096

Epoch: 6| Step: 13
Training loss: 0.3396648067414708
Validation loss: 2.278479596568234

Epoch: 345| Step: 0
Training loss: 0.24373408993124088
Validation loss: 2.279009637764

Epoch: 6| Step: 1
Training loss: 0.23528480374391836
Validation loss: 2.241712885478243

Epoch: 6| Step: 2
Training loss: 0.31769817237031134
Validation loss: 2.2600296116889163

Epoch: 6| Step: 3
Training loss: 0.26424505311509333
Validation loss: 2.2906594114680887

Epoch: 6| Step: 4
Training loss: 0.2904933492823342
Validation loss: 2.312517647203349

Epoch: 6| Step: 5
Training loss: 0.3202412107268074
Validation loss: 2.263667223192975

Epoch: 6| Step: 6
Training loss: 0.4049648902827469
Validation loss: 2.3174248568448546

Epoch: 6| Step: 7
Training loss: 0.2991732804334174
Validation loss: 2.272901718785137

Epoch: 6| Step: 8
Training loss: 0.2684049431594371
Validation loss: 2.3043964870366067

Epoch: 6| Step: 9
Training loss: 0.25074628366338736
Validation loss: 2.2741521387229096

Epoch: 6| Step: 10
Training loss: 0.2908806968085202
Validation loss: 2.3287442469734825

Epoch: 6| Step: 11
Training loss: 0.3407178905237955
Validation loss: 2.2778296936393865

Epoch: 6| Step: 12
Training loss: 0.28150583922799
Validation loss: 2.3058992637782763

Epoch: 6| Step: 13
Training loss: 0.33667735754796424
Validation loss: 2.313902008927197

Epoch: 346| Step: 0
Training loss: 0.19586959542874366
Validation loss: 2.3029725499208813

Epoch: 6| Step: 1
Training loss: 0.2376273202938353
Validation loss: 2.320022787552216

Epoch: 6| Step: 2
Training loss: 0.29234426699194566
Validation loss: 2.3103537179152824

Epoch: 6| Step: 3
Training loss: 0.29199721418155744
Validation loss: 2.35853945861377

Epoch: 6| Step: 4
Training loss: 0.29956647871715186
Validation loss: 2.2723290973883308

Epoch: 6| Step: 5
Training loss: 0.35997783850962733
Validation loss: 2.3138939118861885

Epoch: 6| Step: 6
Training loss: 0.42656406569979544
Validation loss: 2.3159850039328784

Epoch: 6| Step: 7
Training loss: 0.3581780111812932
Validation loss: 2.3418342729455786

Epoch: 6| Step: 8
Training loss: 0.20180032767762138
Validation loss: 2.3187913971501883

Epoch: 6| Step: 9
Training loss: 0.23640860613741163
Validation loss: 2.311659978248622

Epoch: 6| Step: 10
Training loss: 0.33343647190711306
Validation loss: 2.329111073899058

Epoch: 6| Step: 11
Training loss: 0.4151572025677223
Validation loss: 2.297560072823655

Epoch: 6| Step: 12
Training loss: 0.2568485851582298
Validation loss: 2.3546908703640463

Epoch: 6| Step: 13
Training loss: 0.28776379694039295
Validation loss: 2.334279878815482

Epoch: 347| Step: 0
Training loss: 0.3082828524973731
Validation loss: 2.270799887407945

Epoch: 6| Step: 1
Training loss: 0.25570996122374035
Validation loss: 2.29774685183512

Epoch: 6| Step: 2
Training loss: 0.4065832092030601
Validation loss: 2.2964560630538178

Epoch: 6| Step: 3
Training loss: 0.25143583556327675
Validation loss: 2.2795748286459605

Epoch: 6| Step: 4
Training loss: 0.3491148728036494
Validation loss: 2.2997583469654495

Epoch: 6| Step: 5
Training loss: 0.4187631099698421
Validation loss: 2.3530815515648453

Epoch: 6| Step: 6
Training loss: 0.19259926677974776
Validation loss: 2.264079722322961

Epoch: 6| Step: 7
Training loss: 0.29791564252094926
Validation loss: 2.3240235147834976

Epoch: 6| Step: 8
Training loss: 0.39374793067267266
Validation loss: 2.3121062106702546

Epoch: 6| Step: 9
Training loss: 0.4310601936268676
Validation loss: 2.324401181538468

Epoch: 6| Step: 10
Training loss: 0.4552373321107211
Validation loss: 2.2953465624749434

Epoch: 6| Step: 11
Training loss: 0.3490790922068619
Validation loss: 2.344667839894215

Epoch: 6| Step: 12
Training loss: 0.32797507993742364
Validation loss: 2.304583884458511

Epoch: 6| Step: 13
Training loss: 0.35890918064540134
Validation loss: 2.325291003197205

Epoch: 348| Step: 0
Training loss: 0.43655180358889895
Validation loss: 2.339508202406001

Epoch: 6| Step: 1
Training loss: 0.2567086720360411
Validation loss: 2.326635938467

Epoch: 6| Step: 2
Training loss: 0.2582245048870533
Validation loss: 2.3255002034045815

Epoch: 6| Step: 3
Training loss: 0.33536144146506747
Validation loss: 2.316862879363727

Epoch: 6| Step: 4
Training loss: 0.33974646129407354
Validation loss: 2.252304248284795

Epoch: 6| Step: 5
Training loss: 0.2621706292654636
Validation loss: 2.2795360867873042

Epoch: 6| Step: 6
Training loss: 0.3784498238230368
Validation loss: 2.2824774013791904

Epoch: 6| Step: 7
Training loss: 0.245727326818944
Validation loss: 2.343416800656169

Epoch: 6| Step: 8
Training loss: 0.31397982927929596
Validation loss: 2.315535572022313

Epoch: 6| Step: 9
Training loss: 0.4310103427770029
Validation loss: 2.254927097137364

Epoch: 6| Step: 10
Training loss: 0.3810870737051712
Validation loss: 2.268411961112307

Epoch: 6| Step: 11
Training loss: 0.23269748374869892
Validation loss: 2.2625275847297206

Epoch: 6| Step: 12
Training loss: 0.2541935835458071
Validation loss: 2.2617792924103117

Epoch: 6| Step: 13
Training loss: 0.43974555564269696
Validation loss: 2.295864730754117

Epoch: 349| Step: 0
Training loss: 0.38673560751191133
Validation loss: 2.3364389023899026

Epoch: 6| Step: 1
Training loss: 0.19960279472538395
Validation loss: 2.3061283758359536

Epoch: 6| Step: 2
Training loss: 0.21153064620396342
Validation loss: 2.3047308793807697

Epoch: 6| Step: 3
Training loss: 0.29005742897938763
Validation loss: 2.3446961591180133

Epoch: 6| Step: 4
Training loss: 0.3027207525326267
Validation loss: 2.2393954235170845

Epoch: 6| Step: 5
Training loss: 0.261148529036285
Validation loss: 2.2830221095145906

Epoch: 6| Step: 6
Training loss: 0.21159077080750602
Validation loss: 2.259773573096257

Epoch: 6| Step: 7
Training loss: 0.322850650017586
Validation loss: 2.3059977626960624

Epoch: 6| Step: 8
Training loss: 0.30328092153493086
Validation loss: 2.353581589319136

Epoch: 6| Step: 9
Training loss: 0.35777075994651464
Validation loss: 2.2980008036985837

Epoch: 6| Step: 10
Training loss: 0.4209076776397463
Validation loss: 2.315226648535659

Epoch: 6| Step: 11
Training loss: 0.2751788684705095
Validation loss: 2.3222076691116227

Epoch: 6| Step: 12
Training loss: 0.21675155784614683
Validation loss: 2.32210383427791

Epoch: 6| Step: 13
Training loss: 0.2546306546669053
Validation loss: 2.315333254578634

Epoch: 350| Step: 0
Training loss: 0.3187151716876541
Validation loss: 2.335180476754179

Epoch: 6| Step: 1
Training loss: 0.28234966193777267
Validation loss: 2.3412248190065217

Epoch: 6| Step: 2
Training loss: 0.3668713730627919
Validation loss: 2.3095544407240705

Epoch: 6| Step: 3
Training loss: 0.2746879052950112
Validation loss: 2.2968835289898424

Epoch: 6| Step: 4
Training loss: 0.38024798495669787
Validation loss: 2.3132666184876154

Epoch: 6| Step: 5
Training loss: 0.21439391640763253
Validation loss: 2.2826453344196516

Epoch: 6| Step: 6
Training loss: 0.38993599207458607
Validation loss: 2.277666534702776

Epoch: 6| Step: 7
Training loss: 0.20968612606491022
Validation loss: 2.2960335623999604

Epoch: 6| Step: 8
Training loss: 0.3529626620858106
Validation loss: 2.2770508130105136

Epoch: 6| Step: 9
Training loss: 0.2578213141119526
Validation loss: 2.246895175537302

Epoch: 6| Step: 10
Training loss: 0.30024751148574297
Validation loss: 2.3394510303657152

Epoch: 6| Step: 11
Training loss: 0.27970893181037343
Validation loss: 2.3115903938415103

Epoch: 6| Step: 12
Training loss: 0.25523129022588936
Validation loss: 2.301167980737542

Epoch: 6| Step: 13
Training loss: 0.3900987131563508
Validation loss: 2.260525254016042

Epoch: 351| Step: 0
Training loss: 0.2160980198535552
Validation loss: 2.315017343844759

Epoch: 6| Step: 1
Training loss: 0.35695350685358024
Validation loss: 2.327935665547648

Epoch: 6| Step: 2
Training loss: 0.27153643102155806
Validation loss: 2.321937231955799

Epoch: 6| Step: 3
Training loss: 0.3203178614656154
Validation loss: 2.294857523130889

Epoch: 6| Step: 4
Training loss: 0.27417560140106034
Validation loss: 2.3251930054160908

Epoch: 6| Step: 5
Training loss: 0.4482045708457283
Validation loss: 2.271509784305992

Epoch: 6| Step: 6
Training loss: 0.34260451672981607
Validation loss: 2.255274612357296

Epoch: 6| Step: 7
Training loss: 0.32950694984420614
Validation loss: 2.2571240951897664

Epoch: 6| Step: 8
Training loss: 0.2823563643541929
Validation loss: 2.2963794164955837

Epoch: 6| Step: 9
Training loss: 0.3646106596197234
Validation loss: 2.283847131721916

Epoch: 6| Step: 10
Training loss: 0.37819616893288444
Validation loss: 2.3165827957815583

Epoch: 6| Step: 11
Training loss: 0.3657293993910126
Validation loss: 2.3212285144244995

Epoch: 6| Step: 12
Training loss: 0.2985119112727705
Validation loss: 2.289946852876597

Epoch: 6| Step: 13
Training loss: 0.19012628496301381
Validation loss: 2.2908938116159954

Epoch: 352| Step: 0
Training loss: 0.27637373845723884
Validation loss: 2.274187634996828

Epoch: 6| Step: 1
Training loss: 0.3750278144693689
Validation loss: 2.325254663582833

Epoch: 6| Step: 2
Training loss: 0.3926834041194243
Validation loss: 2.2762736995859116

Epoch: 6| Step: 3
Training loss: 0.32384996237019137
Validation loss: 2.2774320206893743

Epoch: 6| Step: 4
Training loss: 0.48882236252348626
Validation loss: 2.2987651702894722

Epoch: 6| Step: 5
Training loss: 0.37475570032569916
Validation loss: 2.3181114332004884

Epoch: 6| Step: 6
Training loss: 0.3434288301840105
Validation loss: 2.3083886724051887

Epoch: 6| Step: 7
Training loss: 0.3227406786171674
Validation loss: 2.3241519352047217

Epoch: 6| Step: 8
Training loss: 0.42024481132612834
Validation loss: 2.284747277856456

Epoch: 6| Step: 9
Training loss: 0.3986278528019909
Validation loss: 2.2488001873981602

Epoch: 6| Step: 10
Training loss: 0.24475198112909488
Validation loss: 2.3193223855141354

Epoch: 6| Step: 11
Training loss: 0.23490672988456904
Validation loss: 2.234409829959742

Epoch: 6| Step: 12
Training loss: 0.5580750838424701
Validation loss: 2.2588830189749287

Epoch: 6| Step: 13
Training loss: 0.33619706527795207
Validation loss: 2.2680426928618838

Epoch: 353| Step: 0
Training loss: 0.5045662630985838
Validation loss: 2.277766995934294

Epoch: 6| Step: 1
Training loss: 0.24970648343679216
Validation loss: 2.263989895502643

Epoch: 6| Step: 2
Training loss: 0.31136974740929235
Validation loss: 2.3298154663172936

Epoch: 6| Step: 3
Training loss: 0.30757716084998465
Validation loss: 2.2925209158300675

Epoch: 6| Step: 4
Training loss: 0.48105046482997477
Validation loss: 2.3788989254359008

Epoch: 6| Step: 5
Training loss: 0.32705040217207054
Validation loss: 2.3139190959090854

Epoch: 6| Step: 6
Training loss: 0.3155467994049503
Validation loss: 2.303146683458441

Epoch: 6| Step: 7
Training loss: 0.339387389952703
Validation loss: 2.298997119276209

Epoch: 6| Step: 8
Training loss: 0.36251214352360633
Validation loss: 2.3227572250957302

Epoch: 6| Step: 9
Training loss: 0.33029332566344927
Validation loss: 2.3251957226480107

Epoch: 6| Step: 10
Training loss: 0.48879756332635316
Validation loss: 2.3237889851539855

Epoch: 6| Step: 11
Training loss: 0.2620428839542185
Validation loss: 2.341172305513673

Epoch: 6| Step: 12
Training loss: 0.35973860134890784
Validation loss: 2.3596908155864327

Epoch: 6| Step: 13
Training loss: 0.5287762717445572
Validation loss: 2.307222125610677

Epoch: 354| Step: 0
Training loss: 0.30780297375959603
Validation loss: 2.3027967035272305

Epoch: 6| Step: 1
Training loss: 0.2856052991220518
Validation loss: 2.3078714392902713

Epoch: 6| Step: 2
Training loss: 0.4078298258115507
Validation loss: 2.2853527191127014

Epoch: 6| Step: 3
Training loss: 0.3763450699203165
Validation loss: 2.279206471092689

Epoch: 6| Step: 4
Training loss: 0.5261726090525921
Validation loss: 2.3139305157814096

Epoch: 6| Step: 5
Training loss: 0.3738814002075598
Validation loss: 2.2714328032937146

Epoch: 6| Step: 6
Training loss: 0.23795722599141492
Validation loss: 2.314868367176134

Epoch: 6| Step: 7
Training loss: 0.38224072476417714
Validation loss: 2.2720076356533405

Epoch: 6| Step: 8
Training loss: 0.3793541924868039
Validation loss: 2.274720667713275

Epoch: 6| Step: 9
Training loss: 0.4215165133946437
Validation loss: 2.2680030444341743

Epoch: 6| Step: 10
Training loss: 0.45708677166549977
Validation loss: 2.3513196733215125

Epoch: 6| Step: 11
Training loss: 0.2984530519757292
Validation loss: 2.324056881522556

Epoch: 6| Step: 12
Training loss: 0.26531508542206367
Validation loss: 2.287731022104057

Epoch: 6| Step: 13
Training loss: 0.3728913986802242
Validation loss: 2.332778487199215

Epoch: 355| Step: 0
Training loss: 0.47299006000421717
Validation loss: 2.36411681313493

Epoch: 6| Step: 1
Training loss: 0.47537373972787644
Validation loss: 2.3408628355643026

Epoch: 6| Step: 2
Training loss: 0.36224957070019165
Validation loss: 2.369535232475197

Epoch: 6| Step: 3
Training loss: 0.3046002507610441
Validation loss: 2.336132777120259

Epoch: 6| Step: 4
Training loss: 0.44770142092663545
Validation loss: 2.2588231377863273

Epoch: 6| Step: 5
Training loss: 0.2570098752117214
Validation loss: 2.3198482678386676

Epoch: 6| Step: 6
Training loss: 0.3872049531243493
Validation loss: 2.2926471404512077

Epoch: 6| Step: 7
Training loss: 0.5260654355964635
Validation loss: 2.322509299397543

Epoch: 6| Step: 8
Training loss: 0.4176534372471187
Validation loss: 2.2781668081402366

Epoch: 6| Step: 9
Training loss: 0.49937495263854986
Validation loss: 2.282836493040315

Epoch: 6| Step: 10
Training loss: 0.24838921059635713
Validation loss: 2.2746949012238695

Epoch: 6| Step: 11
Training loss: 0.35969160480294726
Validation loss: 2.273541364012324

Epoch: 6| Step: 12
Training loss: 0.7625064005348601
Validation loss: 2.2947587278555925

Epoch: 6| Step: 13
Training loss: 0.5473865296516582
Validation loss: 2.2764114993078493

Epoch: 356| Step: 0
Training loss: 0.3869657402053991
Validation loss: 2.26403447588629

Epoch: 6| Step: 1
Training loss: 0.3095402146398344
Validation loss: 2.3085534210038943

Epoch: 6| Step: 2
Training loss: 0.4371694269596109
Validation loss: 2.269285450251265

Epoch: 6| Step: 3
Training loss: 0.3783427502108577
Validation loss: 2.336427584029259

Epoch: 6| Step: 4
Training loss: 0.5120056745691551
Validation loss: 2.332480868090375

Epoch: 6| Step: 5
Training loss: 0.5636682564453379
Validation loss: 2.3232806708863465

Epoch: 6| Step: 6
Training loss: 0.4935211399694761
Validation loss: 2.3062821383420853

Epoch: 6| Step: 7
Training loss: 0.25511417630704813
Validation loss: 2.316265580107238

Epoch: 6| Step: 8
Training loss: 0.30714748793339625
Validation loss: 2.2860790161077955

Epoch: 6| Step: 9
Training loss: 0.48410629694924506
Validation loss: 2.2752774757554057

Epoch: 6| Step: 10
Training loss: 0.46096252114871344
Validation loss: 2.309189239312699

Epoch: 6| Step: 11
Training loss: 0.4981260947259722
Validation loss: 2.289228830381074

Epoch: 6| Step: 12
Training loss: 0.32921960451280435
Validation loss: 2.2641771184403674

Epoch: 6| Step: 13
Training loss: 0.44525775238262133
Validation loss: 2.3026721914672765

Epoch: 357| Step: 0
Training loss: 0.4945239815320953
Validation loss: 2.2739511458009116

Epoch: 6| Step: 1
Training loss: 0.34293170546413637
Validation loss: 2.3277500627269347

Epoch: 6| Step: 2
Training loss: 0.3147364696294168
Validation loss: 2.2724235257275542

Epoch: 6| Step: 3
Training loss: 0.3565818629578112
Validation loss: 2.31956950407004

Epoch: 6| Step: 4
Training loss: 0.6230271674121588
Validation loss: 2.304566892065111

Epoch: 6| Step: 5
Training loss: 0.39308990976896163
Validation loss: 2.2880493282700454

Epoch: 6| Step: 6
Training loss: 0.30107744916134965
Validation loss: 2.287851961779732

Epoch: 6| Step: 7
Training loss: 0.2721515389127882
Validation loss: 2.2385895734737242

Epoch: 6| Step: 8
Training loss: 0.5116566627634511
Validation loss: 2.2981682940234873

Epoch: 6| Step: 9
Training loss: 0.29761625907363604
Validation loss: 2.273496000011363

Epoch: 6| Step: 10
Training loss: 0.27122312091778084
Validation loss: 2.273583074324467

Epoch: 6| Step: 11
Training loss: 0.5159046686217453
Validation loss: 2.303821060332136

Epoch: 6| Step: 12
Training loss: 0.4473701921190275
Validation loss: 2.2721767010076057

Epoch: 6| Step: 13
Training loss: 0.3131433302259638
Validation loss: 2.2864827797060028

Epoch: 358| Step: 0
Training loss: 0.23983565636811607
Validation loss: 2.3305179066876147

Epoch: 6| Step: 1
Training loss: 0.4190693562719791
Validation loss: 2.2494649339175443

Epoch: 6| Step: 2
Training loss: 0.38604878662811964
Validation loss: 2.331997562848841

Epoch: 6| Step: 3
Training loss: 0.4373662096902575
Validation loss: 2.283352531807188

Epoch: 6| Step: 4
Training loss: 0.3120333764047236
Validation loss: 2.199474331158444

Epoch: 6| Step: 5
Training loss: 0.3256517020057024
Validation loss: 2.241558398736669

Epoch: 6| Step: 6
Training loss: 0.4279749468117656
Validation loss: 2.301594960004742

Epoch: 6| Step: 7
Training loss: 0.3896434659330001
Validation loss: 2.3018685552828084

Epoch: 6| Step: 8
Training loss: 0.45339152291655943
Validation loss: 2.3274912814404862

Epoch: 6| Step: 9
Training loss: 0.4058025169748542
Validation loss: 2.2837114684625415

Epoch: 6| Step: 10
Training loss: 0.27493959381163
Validation loss: 2.3062130894933563

Epoch: 6| Step: 11
Training loss: 0.37725612341661796
Validation loss: 2.2816286948476168

Epoch: 6| Step: 12
Training loss: 0.2949405815810698
Validation loss: 2.2936478691681654

Epoch: 6| Step: 13
Training loss: 0.2797002480441355
Validation loss: 2.266240038645601

Epoch: 359| Step: 0
Training loss: 0.333264227001823
Validation loss: 2.3040123850497296

Epoch: 6| Step: 1
Training loss: 0.3106119099781303
Validation loss: 2.277503381524924

Epoch: 6| Step: 2
Training loss: 0.32978780947028274
Validation loss: 2.295046868133131

Epoch: 6| Step: 3
Training loss: 0.26194269648180324
Validation loss: 2.329447266242647

Epoch: 6| Step: 4
Training loss: 0.32147162911605504
Validation loss: 2.2817197864647407

Epoch: 6| Step: 5
Training loss: 0.33365128175159714
Validation loss: 2.3090216105162846

Epoch: 6| Step: 6
Training loss: 0.2740360928669902
Validation loss: 2.307223184802095

Epoch: 6| Step: 7
Training loss: 0.26571499478063154
Validation loss: 2.3196068406756885

Epoch: 6| Step: 8
Training loss: 0.19728532069620186
Validation loss: 2.3528137933385778

Epoch: 6| Step: 9
Training loss: 0.3403760534025739
Validation loss: 2.2099745487744133

Epoch: 6| Step: 10
Training loss: 0.47797250871530333
Validation loss: 2.2804073711001123

Epoch: 6| Step: 11
Training loss: 0.4032329621756797
Validation loss: 2.3116969698968965

Epoch: 6| Step: 12
Training loss: 0.29815873113179
Validation loss: 2.308282838767197

Epoch: 6| Step: 13
Training loss: 0.29451217994373025
Validation loss: 2.318089345981966

Epoch: 360| Step: 0
Training loss: 0.31853145792993726
Validation loss: 2.3421458285787407

Epoch: 6| Step: 1
Training loss: 0.2595332691176094
Validation loss: 2.2572347392350314

Epoch: 6| Step: 2
Training loss: 0.24596162306907504
Validation loss: 2.3092470573254293

Epoch: 6| Step: 3
Training loss: 0.29334044719237495
Validation loss: 2.302865794419232

Epoch: 6| Step: 4
Training loss: 0.1969337882718464
Validation loss: 2.363546813672311

Epoch: 6| Step: 5
Training loss: 0.25996609173257196
Validation loss: 2.3281340118848233

Epoch: 6| Step: 6
Training loss: 0.26817543300185814
Validation loss: 2.3072912820395213

Epoch: 6| Step: 7
Training loss: 0.3397188395560684
Validation loss: 2.3075636078432273

Epoch: 6| Step: 8
Training loss: 0.4489166570851932
Validation loss: 2.303065411276891

Epoch: 6| Step: 9
Training loss: 0.32946422302210054
Validation loss: 2.2828062923833516

Epoch: 6| Step: 10
Training loss: 0.3454615939954989
Validation loss: 2.2958123653259754

Epoch: 6| Step: 11
Training loss: 0.2752377105822616
Validation loss: 2.275813317501291

Epoch: 6| Step: 12
Training loss: 0.23604535296648815
Validation loss: 2.2892531054128096

Epoch: 6| Step: 13
Training loss: 0.36295385887679094
Validation loss: 2.3533540409066815

Epoch: 361| Step: 0
Training loss: 0.34545462777453906
Validation loss: 2.3056129623323582

Epoch: 6| Step: 1
Training loss: 0.1770476078479168
Validation loss: 2.2977287453122264

Epoch: 6| Step: 2
Training loss: 0.3626008994987133
Validation loss: 2.27670167363603

Epoch: 6| Step: 3
Training loss: 0.2865028462360133
Validation loss: 2.277505998627977

Epoch: 6| Step: 4
Training loss: 0.3080574034425799
Validation loss: 2.2705348078172296

Epoch: 6| Step: 5
Training loss: 0.2672770957860327
Validation loss: 2.308292306840706

Epoch: 6| Step: 6
Training loss: 0.23995865917785356
Validation loss: 2.2985241563938463

Epoch: 6| Step: 7
Training loss: 0.37033032643994224
Validation loss: 2.2849232177160017

Epoch: 6| Step: 8
Training loss: 0.3442148836449458
Validation loss: 2.340388927090454

Epoch: 6| Step: 9
Training loss: 0.23788105079414223
Validation loss: 2.3251131618128595

Epoch: 6| Step: 10
Training loss: 0.2516539371952166
Validation loss: 2.3138159624641257

Epoch: 6| Step: 11
Training loss: 0.24454111438878867
Validation loss: 2.2709149658042587

Epoch: 6| Step: 12
Training loss: 0.2128094159545599
Validation loss: 2.3051834607294373

Epoch: 6| Step: 13
Training loss: 0.3627714661583357
Validation loss: 2.3484117981567505

Epoch: 362| Step: 0
Training loss: 0.27619482535864004
Validation loss: 2.3043633270726755

Epoch: 6| Step: 1
Training loss: 0.23904252779190854
Validation loss: 2.2872345344748037

Epoch: 6| Step: 2
Training loss: 0.2723822257810943
Validation loss: 2.3233587987517605

Epoch: 6| Step: 3
Training loss: 0.29476227136357747
Validation loss: 2.281271529422701

Epoch: 6| Step: 4
Training loss: 0.36214791167954175
Validation loss: 2.336018997863047

Epoch: 6| Step: 5
Training loss: 0.437820249239775
Validation loss: 2.338803390662837

Epoch: 6| Step: 6
Training loss: 0.3133435427599494
Validation loss: 2.307606184098158

Epoch: 6| Step: 7
Training loss: 0.25487006729239436
Validation loss: 2.2993872607229924

Epoch: 6| Step: 8
Training loss: 0.26346700267825424
Validation loss: 2.287896893504472

Epoch: 6| Step: 9
Training loss: 0.2208563517473887
Validation loss: 2.2925448440109406

Epoch: 6| Step: 10
Training loss: 0.28544098212162705
Validation loss: 2.3810711443890398

Epoch: 6| Step: 11
Training loss: 0.2801626697662143
Validation loss: 2.2385257767127693

Epoch: 6| Step: 12
Training loss: 0.41335971137959404
Validation loss: 2.2621900630704017

Epoch: 6| Step: 13
Training loss: 0.27573673332063153
Validation loss: 2.250997304648423

Epoch: 363| Step: 0
Training loss: 0.2934161394162918
Validation loss: 2.321320645474958

Epoch: 6| Step: 1
Training loss: 0.391506725823518
Validation loss: 2.3156995376074025

Epoch: 6| Step: 2
Training loss: 0.25971975853772017
Validation loss: 2.264035292015053

Epoch: 6| Step: 3
Training loss: 0.19659141484021106
Validation loss: 2.3335068643846473

Epoch: 6| Step: 4
Training loss: 0.24840194339740632
Validation loss: 2.272314670490954

Epoch: 6| Step: 5
Training loss: 0.30995788140043273
Validation loss: 2.265318452989781

Epoch: 6| Step: 6
Training loss: 0.3425290032274724
Validation loss: 2.3121505679498577

Epoch: 6| Step: 7
Training loss: 0.28202770579639286
Validation loss: 2.294251230064468

Epoch: 6| Step: 8
Training loss: 0.29591153056067654
Validation loss: 2.259625631934539

Epoch: 6| Step: 9
Training loss: 0.3087591621259585
Validation loss: 2.2902968098276544

Epoch: 6| Step: 10
Training loss: 0.27411791748989917
Validation loss: 2.280919003097837

Epoch: 6| Step: 11
Training loss: 0.38262422953381336
Validation loss: 2.2984033114831557

Epoch: 6| Step: 12
Training loss: 0.2452183093118919
Validation loss: 2.2571141043904586

Epoch: 6| Step: 13
Training loss: 0.18550094236728332
Validation loss: 2.296277130581348

Epoch: 364| Step: 0
Training loss: 0.2613557319143188
Validation loss: 2.3057985375631254

Epoch: 6| Step: 1
Training loss: 0.1910891728699085
Validation loss: 2.3058935684270137

Epoch: 6| Step: 2
Training loss: 0.3609813366316146
Validation loss: 2.3450743854033393

Epoch: 6| Step: 3
Training loss: 0.3102689615114323
Validation loss: 2.2860965630830763

Epoch: 6| Step: 4
Training loss: 0.2417729429070508
Validation loss: 2.3343672562027735

Epoch: 6| Step: 5
Training loss: 0.22959937980834758
Validation loss: 2.26783096082383

Epoch: 6| Step: 6
Training loss: 0.19544903751081655
Validation loss: 2.331939175746051

Epoch: 6| Step: 7
Training loss: 0.19904260702159265
Validation loss: 2.292299778499902

Epoch: 6| Step: 8
Training loss: 0.3540718802600892
Validation loss: 2.288315339690292

Epoch: 6| Step: 9
Training loss: 0.3954240121484088
Validation loss: 2.3340432131704985

Epoch: 6| Step: 10
Training loss: 0.3795159537137141
Validation loss: 2.3335482521078865

Epoch: 6| Step: 11
Training loss: 0.22501454505001672
Validation loss: 2.312158335971703

Epoch: 6| Step: 12
Training loss: 0.18823492540804826
Validation loss: 2.307722879476271

Epoch: 6| Step: 13
Training loss: 0.26856790683462445
Validation loss: 2.251878589941716

Epoch: 365| Step: 0
Training loss: 0.426513741749243
Validation loss: 2.3060872800189913

Epoch: 6| Step: 1
Training loss: 0.24232801852395172
Validation loss: 2.232946130176517

Epoch: 6| Step: 2
Training loss: 0.32439564854164604
Validation loss: 2.299601383496656

Epoch: 6| Step: 3
Training loss: 0.3313696609147538
Validation loss: 2.2648055512986938

Epoch: 6| Step: 4
Training loss: 0.2583066077918285
Validation loss: 2.2641395171382475

Epoch: 6| Step: 5
Training loss: 0.39923991018455374
Validation loss: 2.3105871348072604

Epoch: 6| Step: 6
Training loss: 0.2331383105484562
Validation loss: 2.2606539330719615

Epoch: 6| Step: 7
Training loss: 0.1710814395377547
Validation loss: 2.3083484000759764

Epoch: 6| Step: 8
Training loss: 0.2983497580521365
Validation loss: 2.2692712666637562

Epoch: 6| Step: 9
Training loss: 0.3382477168847035
Validation loss: 2.297029848998959

Epoch: 6| Step: 10
Training loss: 0.2789347909167153
Validation loss: 2.3296277532116227

Epoch: 6| Step: 11
Training loss: 0.30940012059190886
Validation loss: 2.286820634249741

Epoch: 6| Step: 12
Training loss: 0.5088766831642151
Validation loss: 2.2701617889893346

Epoch: 6| Step: 13
Training loss: 0.33730132471825913
Validation loss: 2.3005337973371818

Epoch: 366| Step: 0
Training loss: 0.28931862850542245
Validation loss: 2.32488484387994

Epoch: 6| Step: 1
Training loss: 0.25969089781263155
Validation loss: 2.3160418716498743

Epoch: 6| Step: 2
Training loss: 0.36096127419387614
Validation loss: 2.2745797607548486

Epoch: 6| Step: 3
Training loss: 0.3178210358237664
Validation loss: 2.322539171984211

Epoch: 6| Step: 4
Training loss: 0.3957123404180117
Validation loss: 2.324291512341438

Epoch: 6| Step: 5
Training loss: 0.25163147969816596
Validation loss: 2.2986243543086515

Epoch: 6| Step: 6
Training loss: 0.3570368626526919
Validation loss: 2.336619521040467

Epoch: 6| Step: 7
Training loss: 0.23136510143147881
Validation loss: 2.284649810751469

Epoch: 6| Step: 8
Training loss: 0.4224110482607901
Validation loss: 2.2869648701802925

Epoch: 6| Step: 9
Training loss: 0.27281139080787814
Validation loss: 2.3083293180281585

Epoch: 6| Step: 10
Training loss: 0.36342593357511827
Validation loss: 2.2599659190519863

Epoch: 6| Step: 11
Training loss: 0.24788856711075954
Validation loss: 2.30730860741957

Epoch: 6| Step: 12
Training loss: 0.6364474976694731
Validation loss: 2.28904874274554

Epoch: 6| Step: 13
Training loss: 0.4101069466158582
Validation loss: 2.25772263503173

Epoch: 367| Step: 0
Training loss: 0.34460767041158596
Validation loss: 2.2780939767240054

Epoch: 6| Step: 1
Training loss: 0.33031557785448007
Validation loss: 2.28594307680421

Epoch: 6| Step: 2
Training loss: 0.22797045110286152
Validation loss: 2.289118482927169

Epoch: 6| Step: 3
Training loss: 0.38563737048767377
Validation loss: 2.293252601362285

Epoch: 6| Step: 4
Training loss: 0.3121547580041381
Validation loss: 2.273832516255584

Epoch: 6| Step: 5
Training loss: 0.28602615034903844
Validation loss: 2.2631205254044957

Epoch: 6| Step: 6
Training loss: 0.3954310024698972
Validation loss: 2.321058724882862

Epoch: 6| Step: 7
Training loss: 0.43669664330394614
Validation loss: 2.2908322520257536

Epoch: 6| Step: 8
Training loss: 0.48089540348144766
Validation loss: 2.28354771180825

Epoch: 6| Step: 9
Training loss: 0.32873201988279904
Validation loss: 2.292992716831331

Epoch: 6| Step: 10
Training loss: 0.3679494054937504
Validation loss: 2.289043014148322

Epoch: 6| Step: 11
Training loss: 0.3035554518522507
Validation loss: 2.3140231863902736

Epoch: 6| Step: 12
Training loss: 0.26321344436339866
Validation loss: 2.276438546804441

Epoch: 6| Step: 13
Training loss: 0.3690067230054106
Validation loss: 2.272099786313278

Epoch: 368| Step: 0
Training loss: 0.3860643031810158
Validation loss: 2.2938416621215825

Epoch: 6| Step: 1
Training loss: 0.37366813337178284
Validation loss: 2.2860789118163067

Epoch: 6| Step: 2
Training loss: 0.24880398074736146
Validation loss: 2.2483297612487303

Epoch: 6| Step: 3
Training loss: 0.2948884881934152
Validation loss: 2.323710102233321

Epoch: 6| Step: 4
Training loss: 0.2726759250395394
Validation loss: 2.284987884144343

Epoch: 6| Step: 5
Training loss: 0.31477502967416837
Validation loss: 2.2842374948985453

Epoch: 6| Step: 6
Training loss: 0.34055261017708227
Validation loss: 2.318070481256555

Epoch: 6| Step: 7
Training loss: 0.3787690730375639
Validation loss: 2.3238745084515173

Epoch: 6| Step: 8
Training loss: 0.33345585548194934
Validation loss: 2.319303933441472

Epoch: 6| Step: 9
Training loss: 0.35569554733693914
Validation loss: 2.3302114639863727

Epoch: 6| Step: 10
Training loss: 0.24912427468775672
Validation loss: 2.3106107039246235

Epoch: 6| Step: 11
Training loss: 0.3159420823765753
Validation loss: 2.3277184048133774

Epoch: 6| Step: 12
Training loss: 0.3759602134419698
Validation loss: 2.305967693056229

Epoch: 6| Step: 13
Training loss: 0.32946017504958425
Validation loss: 2.341019391869953

Epoch: 369| Step: 0
Training loss: 0.24942821441625465
Validation loss: 2.2630725030886305

Epoch: 6| Step: 1
Training loss: 0.24300117858897208
Validation loss: 2.3092366983712638

Epoch: 6| Step: 2
Training loss: 0.3787955879561227
Validation loss: 2.265219763984797

Epoch: 6| Step: 3
Training loss: 0.3202268439415007
Validation loss: 2.326559099135551

Epoch: 6| Step: 4
Training loss: 0.3115717094116316
Validation loss: 2.3249659002531162

Epoch: 6| Step: 5
Training loss: 0.3483034603110198
Validation loss: 2.305679185519614

Epoch: 6| Step: 6
Training loss: 0.30191866590475136
Validation loss: 2.2985366727282086

Epoch: 6| Step: 7
Training loss: 0.3124686463839694
Validation loss: 2.294135997214798

Epoch: 6| Step: 8
Training loss: 0.32637327223926405
Validation loss: 2.2903120950420983

Epoch: 6| Step: 9
Training loss: 0.3869866108167653
Validation loss: 2.2943516145846408

Epoch: 6| Step: 10
Training loss: 0.2952337069073578
Validation loss: 2.3296353776722483

Epoch: 6| Step: 11
Training loss: 0.37332446570309974
Validation loss: 2.2558978453159124

Epoch: 6| Step: 12
Training loss: 0.3019279938340202
Validation loss: 2.3223646617119775

Epoch: 6| Step: 13
Training loss: 0.3201635758849657
Validation loss: 2.295430410328638

Epoch: 370| Step: 0
Training loss: 0.2997703656857428
Validation loss: 2.3108993695638085

Epoch: 6| Step: 1
Training loss: 0.2325545821673255
Validation loss: 2.3097677585973226

Epoch: 6| Step: 2
Training loss: 0.32345458828662493
Validation loss: 2.284225796107345

Epoch: 6| Step: 3
Training loss: 0.2801121104541953
Validation loss: 2.3255293199157214

Epoch: 6| Step: 4
Training loss: 0.36680810685678605
Validation loss: 2.275910351163687

Epoch: 6| Step: 5
Training loss: 0.4261071943645738
Validation loss: 2.3398209084068307

Epoch: 6| Step: 6
Training loss: 0.20081392868333992
Validation loss: 2.2452323876275484

Epoch: 6| Step: 7
Training loss: 0.44676780482047135
Validation loss: 2.3108676613551715

Epoch: 6| Step: 8
Training loss: 0.28537819990652374
Validation loss: 2.325676759374362

Epoch: 6| Step: 9
Training loss: 0.3403738097458285
Validation loss: 2.282351180159152

Epoch: 6| Step: 10
Training loss: 0.29498866253419326
Validation loss: 2.3155930771302535

Epoch: 6| Step: 11
Training loss: 0.20500130804156308
Validation loss: 2.312830377296684

Epoch: 6| Step: 12
Training loss: 0.37160308417332805
Validation loss: 2.2941511269442745

Epoch: 6| Step: 13
Training loss: 0.20286172531001637
Validation loss: 2.290639913179945

Epoch: 371| Step: 0
Training loss: 0.3373904412429458
Validation loss: 2.302582532747553

Epoch: 6| Step: 1
Training loss: 0.24983565322753398
Validation loss: 2.2967455301968984

Epoch: 6| Step: 2
Training loss: 0.25636074940986187
Validation loss: 2.316523599895385

Epoch: 6| Step: 3
Training loss: 0.28055282119062663
Validation loss: 2.335643294741427

Epoch: 6| Step: 4
Training loss: 0.2325248650360044
Validation loss: 2.272151447811611

Epoch: 6| Step: 5
Training loss: 0.30659279176878984
Validation loss: 2.3096785989743904

Epoch: 6| Step: 6
Training loss: 0.44860793340749705
Validation loss: 2.2920877994488524

Epoch: 6| Step: 7
Training loss: 0.19088003264601971
Validation loss: 2.317844469737067

Epoch: 6| Step: 8
Training loss: 0.2783596078002881
Validation loss: 2.2932114827374335

Epoch: 6| Step: 9
Training loss: 0.30502484060189045
Validation loss: 2.2387007874362586

Epoch: 6| Step: 10
Training loss: 0.329344096932761
Validation loss: 2.3006166875306144

Epoch: 6| Step: 11
Training loss: 0.2162877281579086
Validation loss: 2.3077711693522134

Epoch: 6| Step: 12
Training loss: 0.3929272138663913
Validation loss: 2.350333077248885

Epoch: 6| Step: 13
Training loss: 0.23393685394858313
Validation loss: 2.327774422553878

Epoch: 372| Step: 0
Training loss: 0.2783779954530717
Validation loss: 2.2948480688901918

Epoch: 6| Step: 1
Training loss: 0.2569131191306523
Validation loss: 2.292113985851677

Epoch: 6| Step: 2
Training loss: 0.2882752136177408
Validation loss: 2.3152332906397066

Epoch: 6| Step: 3
Training loss: 0.23932444364761404
Validation loss: 2.2888377820356465

Epoch: 6| Step: 4
Training loss: 0.25829864674138736
Validation loss: 2.321238229270156

Epoch: 6| Step: 5
Training loss: 0.3285389741090992
Validation loss: 2.339670420039532

Epoch: 6| Step: 6
Training loss: 0.31442074579374407
Validation loss: 2.2864313985734155

Epoch: 6| Step: 7
Training loss: 0.20714188264866568
Validation loss: 2.3260537647889925

Epoch: 6| Step: 8
Training loss: 0.3019131751238081
Validation loss: 2.304922731970424

Epoch: 6| Step: 9
Training loss: 0.3742482478356228
Validation loss: 2.3241555170598978

Epoch: 6| Step: 10
Training loss: 0.3563609402230333
Validation loss: 2.2618737483348337

Epoch: 6| Step: 11
Training loss: 0.2835290414637343
Validation loss: 2.25821851095921

Epoch: 6| Step: 12
Training loss: 0.2209267285323287
Validation loss: 2.3391798942562474

Epoch: 6| Step: 13
Training loss: 0.26059668835429944
Validation loss: 2.329843488520153

Epoch: 373| Step: 0
Training loss: 0.3198735322862697
Validation loss: 2.3227914739381013

Epoch: 6| Step: 1
Training loss: 0.29993811008703714
Validation loss: 2.2804287342282192

Epoch: 6| Step: 2
Training loss: 0.4309788632476255
Validation loss: 2.313401982812325

Epoch: 6| Step: 3
Training loss: 0.24034488276253252
Validation loss: 2.29784841519697

Epoch: 6| Step: 4
Training loss: 0.454106862026998
Validation loss: 2.2990884992643377

Epoch: 6| Step: 5
Training loss: 0.2296598106354296
Validation loss: 2.3228206072961397

Epoch: 6| Step: 6
Training loss: 0.36407633906571807
Validation loss: 2.288372547728665

Epoch: 6| Step: 7
Training loss: 0.23875014493598334
Validation loss: 2.279427989597955

Epoch: 6| Step: 8
Training loss: 0.29092276454940946
Validation loss: 2.3258694639808564

Epoch: 6| Step: 9
Training loss: 0.2269919206351499
Validation loss: 2.2689383471504825

Epoch: 6| Step: 10
Training loss: 0.294057628173686
Validation loss: 2.2750632731403524

Epoch: 6| Step: 11
Training loss: 0.24110206278168128
Validation loss: 2.246858912071247

Epoch: 6| Step: 12
Training loss: 0.25289116938040107
Validation loss: 2.2825306733442567

Epoch: 6| Step: 13
Training loss: 0.39595102978045094
Validation loss: 2.2831940401939126

Epoch: 374| Step: 0
Training loss: 0.500420691415492
Validation loss: 2.3203869860132205

Epoch: 6| Step: 1
Training loss: 0.34453639115284285
Validation loss: 2.2755569069807855

Epoch: 6| Step: 2
Training loss: 0.31920541784945744
Validation loss: 2.283632662799723

Epoch: 6| Step: 3
Training loss: 0.2439390036604775
Validation loss: 2.2701453528732465

Epoch: 6| Step: 4
Training loss: 0.2709265404874889
Validation loss: 2.275625489083042

Epoch: 6| Step: 5
Training loss: 0.3062415958730577
Validation loss: 2.2801944607352906

Epoch: 6| Step: 6
Training loss: 0.29791360427820807
Validation loss: 2.2608892998503882

Epoch: 6| Step: 7
Training loss: 0.3526283531496064
Validation loss: 2.289579955755999

Epoch: 6| Step: 8
Training loss: 0.2989540582721147
Validation loss: 2.2920276935451067

Epoch: 6| Step: 9
Training loss: 0.22986014877519975
Validation loss: 2.293402514352205

Epoch: 6| Step: 10
Training loss: 0.21831738745599552
Validation loss: 2.302037550757205

Epoch: 6| Step: 11
Training loss: 0.3811717390813505
Validation loss: 2.3294850927343855

Epoch: 6| Step: 12
Training loss: 0.38526090705032084
Validation loss: 2.296588032067915

Epoch: 6| Step: 13
Training loss: 0.4880248502839451
Validation loss: 2.267916982359768

Epoch: 375| Step: 0
Training loss: 0.3775613650914428
Validation loss: 2.2992464914829154

Epoch: 6| Step: 1
Training loss: 0.2605456636735247
Validation loss: 2.2253724515124977

Epoch: 6| Step: 2
Training loss: 0.4583446833621253
Validation loss: 2.307698462958971

Epoch: 6| Step: 3
Training loss: 0.3228520808184018
Validation loss: 2.332986232508198

Epoch: 6| Step: 4
Training loss: 0.26951646073166624
Validation loss: 2.2874248318577233

Epoch: 6| Step: 5
Training loss: 0.2547501843782156
Validation loss: 2.272586003233406

Epoch: 6| Step: 6
Training loss: 0.2916898278281843
Validation loss: 2.2857187562356667

Epoch: 6| Step: 7
Training loss: 0.399390632669689
Validation loss: 2.3073183980961915

Epoch: 6| Step: 8
Training loss: 0.33915971557694
Validation loss: 2.268044804038002

Epoch: 6| Step: 9
Training loss: 0.32155554019673394
Validation loss: 2.257463139979046

Epoch: 6| Step: 10
Training loss: 0.29058409064529434
Validation loss: 2.3204118855060027

Epoch: 6| Step: 11
Training loss: 0.2853234467176932
Validation loss: 2.2477390355826476

Epoch: 6| Step: 12
Training loss: 0.1755864229291034
Validation loss: 2.298398634882162

Epoch: 6| Step: 13
Training loss: 0.37209169821967636
Validation loss: 2.275276611265834

Epoch: 376| Step: 0
Training loss: 0.26863013854865564
Validation loss: 2.295689162096712

Epoch: 6| Step: 1
Training loss: 0.274169921875
Validation loss: 2.2746276012705624

Epoch: 6| Step: 2
Training loss: 0.22225547995317668
Validation loss: 2.3426373192955987

Epoch: 6| Step: 3
Training loss: 0.26658409536522476
Validation loss: 2.2987510216637905

Epoch: 6| Step: 4
Training loss: 0.34567172236517435
Validation loss: 2.301836265205606

Epoch: 6| Step: 5
Training loss: 0.303821335135738
Validation loss: 2.2884472051499163

Epoch: 6| Step: 6
Training loss: 0.33918134215110685
Validation loss: 2.2721367662019554

Epoch: 6| Step: 7
Training loss: 0.1462357381852315
Validation loss: 2.290618922844389

Epoch: 6| Step: 8
Training loss: 0.26216873940695096
Validation loss: 2.3048865798054385

Epoch: 6| Step: 9
Training loss: 0.3664668092114328
Validation loss: 2.307027493086375

Epoch: 6| Step: 10
Training loss: 0.18093752398186033
Validation loss: 2.297697521168944

Epoch: 6| Step: 11
Training loss: 0.2827370985689977
Validation loss: 2.3213851795402993

Epoch: 6| Step: 12
Training loss: 0.2712334358194237
Validation loss: 2.307444028509617

Epoch: 6| Step: 13
Training loss: 0.43360768544940564
Validation loss: 2.3196699063966917

Epoch: 377| Step: 0
Training loss: 0.265503575115954
Validation loss: 2.2889536114551947

Epoch: 6| Step: 1
Training loss: 0.3939107793708729
Validation loss: 2.3483949367636465

Epoch: 6| Step: 2
Training loss: 0.2513123281232108
Validation loss: 2.291514414729261

Epoch: 6| Step: 3
Training loss: 0.34926628881574073
Validation loss: 2.2870640455662654

Epoch: 6| Step: 4
Training loss: 0.43333509823855426
Validation loss: 2.308083432117054

Epoch: 6| Step: 5
Training loss: 0.2890376647384208
Validation loss: 2.275458042090156

Epoch: 6| Step: 6
Training loss: 0.27725043540315003
Validation loss: 2.2859980844816166

Epoch: 6| Step: 7
Training loss: 0.3609536782474273
Validation loss: 2.272562546829261

Epoch: 6| Step: 8
Training loss: 0.20307916344147248
Validation loss: 2.3633830066979136

Epoch: 6| Step: 9
Training loss: 0.2092623599798961
Validation loss: 2.2828394434577137

Epoch: 6| Step: 10
Training loss: 0.2978594669481376
Validation loss: 2.3358390557714293

Epoch: 6| Step: 11
Training loss: 0.34446358308167446
Validation loss: 2.2565260657494064

Epoch: 6| Step: 12
Training loss: 0.24983662243827948
Validation loss: 2.2861646117429912

Epoch: 6| Step: 13
Training loss: 0.3350497981501092
Validation loss: 2.3241090550969683

Epoch: 378| Step: 0
Training loss: 0.25392312213886503
Validation loss: 2.2661216103876685

Epoch: 6| Step: 1
Training loss: 0.31445125318645384
Validation loss: 2.257500350828203

Epoch: 6| Step: 2
Training loss: 0.2692121468839567
Validation loss: 2.300199649963582

Epoch: 6| Step: 3
Training loss: 0.3231109052900672
Validation loss: 2.3187988773071675

Epoch: 6| Step: 4
Training loss: 0.35798977204448995
Validation loss: 2.331127781941204

Epoch: 6| Step: 5
Training loss: 0.222903164933019
Validation loss: 2.2705363741483127

Epoch: 6| Step: 6
Training loss: 0.35717954915459804
Validation loss: 2.312632084416481

Epoch: 6| Step: 7
Training loss: 0.2778970411030234
Validation loss: 2.3109776408930838

Epoch: 6| Step: 8
Training loss: 0.27150992403632707
Validation loss: 2.2619111237878653

Epoch: 6| Step: 9
Training loss: 0.287616502439032
Validation loss: 2.318769624872094

Epoch: 6| Step: 10
Training loss: 0.2108984310562068
Validation loss: 2.302737386203789

Epoch: 6| Step: 11
Training loss: 0.4526186613330663
Validation loss: 2.2968082548032336

Epoch: 6| Step: 12
Training loss: 0.36940388652076733
Validation loss: 2.3307550581589704

Epoch: 6| Step: 13
Training loss: 0.20750398465432607
Validation loss: 2.26537124265037

Epoch: 379| Step: 0
Training loss: 0.2730426935358723
Validation loss: 2.307559552510832

Epoch: 6| Step: 1
Training loss: 0.30067199109777026
Validation loss: 2.3116990498000636

Epoch: 6| Step: 2
Training loss: 0.41928529615710947
Validation loss: 2.257361555110462

Epoch: 6| Step: 3
Training loss: 0.3276633011655443
Validation loss: 2.3252345069424063

Epoch: 6| Step: 4
Training loss: 0.4023264168274127
Validation loss: 2.2711762131507864

Epoch: 6| Step: 5
Training loss: 0.40358745604011015
Validation loss: 2.3627594679183734

Epoch: 6| Step: 6
Training loss: 0.3486830838073001
Validation loss: 2.3171854065027984

Epoch: 6| Step: 7
Training loss: 0.25154827918853745
Validation loss: 2.3611472423132627

Epoch: 6| Step: 8
Training loss: 0.3746638778481481
Validation loss: 2.3387582815959154

Epoch: 6| Step: 9
Training loss: 0.3015894744351797
Validation loss: 2.339616224194185

Epoch: 6| Step: 10
Training loss: 0.30377500784325107
Validation loss: 2.325059891342953

Epoch: 6| Step: 11
Training loss: 0.20716389419463088
Validation loss: 2.306889386266131

Epoch: 6| Step: 12
Training loss: 0.3111767888046317
Validation loss: 2.261386827216644

Epoch: 6| Step: 13
Training loss: 0.24061278646609516
Validation loss: 2.279902238604295

Epoch: 380| Step: 0
Training loss: 0.4478166342821966
Validation loss: 2.2925167645555904

Epoch: 6| Step: 1
Training loss: 0.36481502754808914
Validation loss: 2.277403152938652

Epoch: 6| Step: 2
Training loss: 0.3219524364468701
Validation loss: 2.3334773450642237

Epoch: 6| Step: 3
Training loss: 0.2673091511100752
Validation loss: 2.3054834920148357

Epoch: 6| Step: 4
Training loss: 0.3135637774016601
Validation loss: 2.2998025018097144

Epoch: 6| Step: 5
Training loss: 0.2431557588806409
Validation loss: 2.293688183054573

Epoch: 6| Step: 6
Training loss: 0.3900723171432074
Validation loss: 2.2968606407772

Epoch: 6| Step: 7
Training loss: 0.26530202696655336
Validation loss: 2.3066603239565766

Epoch: 6| Step: 8
Training loss: 0.18478204803384787
Validation loss: 2.272068297406782

Epoch: 6| Step: 9
Training loss: 0.38771072472366575
Validation loss: 2.2658145518317787

Epoch: 6| Step: 10
Training loss: 0.2513628558398462
Validation loss: 2.3015130201080964

Epoch: 6| Step: 11
Training loss: 0.28992687328967276
Validation loss: 2.2715593163287853

Epoch: 6| Step: 12
Training loss: 0.3166341078901939
Validation loss: 2.278523274350048

Epoch: 6| Step: 13
Training loss: 0.3979384906469482
Validation loss: 2.291551957004955

Epoch: 381| Step: 0
Training loss: 0.11540356839161003
Validation loss: 2.2591069260759697

Epoch: 6| Step: 1
Training loss: 0.25953770440588764
Validation loss: 2.2112183229640467

Epoch: 6| Step: 2
Training loss: 0.2463009582599239
Validation loss: 2.2681370543832955

Epoch: 6| Step: 3
Training loss: 0.3319109530469934
Validation loss: 2.2270111791937937

Epoch: 6| Step: 4
Training loss: 0.44673176517319974
Validation loss: 2.259837341489411

Epoch: 6| Step: 5
Training loss: 0.2753503377678571
Validation loss: 2.2920918561505017

Epoch: 6| Step: 6
Training loss: 0.2855959859172577
Validation loss: 2.254264031832366

Epoch: 6| Step: 7
Training loss: 0.26490995991718963
Validation loss: 2.256225010248294

Epoch: 6| Step: 8
Training loss: 0.3698499212809777
Validation loss: 2.28162874709507

Epoch: 6| Step: 9
Training loss: 0.26758365207727586
Validation loss: 2.263346471209966

Epoch: 6| Step: 10
Training loss: 0.3137597323234237
Validation loss: 2.2995612639953142

Epoch: 6| Step: 11
Training loss: 0.2109242717692369
Validation loss: 2.3011924233763246

Epoch: 6| Step: 12
Training loss: 0.2089687591137434
Validation loss: 2.2590793280731747

Epoch: 6| Step: 13
Training loss: 0.254086518483723
Validation loss: 2.246330200133502

Epoch: 382| Step: 0
Training loss: 0.3245528464553781
Validation loss: 2.2857966729271224

Epoch: 6| Step: 1
Training loss: 0.3219869159830175
Validation loss: 2.2676464051911487

Epoch: 6| Step: 2
Training loss: 0.23269420985328348
Validation loss: 2.265682877426144

Epoch: 6| Step: 3
Training loss: 0.2296309599411842
Validation loss: 2.317796089711222

Epoch: 6| Step: 4
Training loss: 0.3254290362305673
Validation loss: 2.2912814828083627

Epoch: 6| Step: 5
Training loss: 0.2207600258589588
Validation loss: 2.2778950149970587

Epoch: 6| Step: 6
Training loss: 0.2987623453981212
Validation loss: 2.2369836104811087

Epoch: 6| Step: 7
Training loss: 0.4081241586042672
Validation loss: 2.2295354347974823

Epoch: 6| Step: 8
Training loss: 0.21779476796877092
Validation loss: 2.2378763716990604

Epoch: 6| Step: 9
Training loss: 0.266600249011259
Validation loss: 2.2251380156098555

Epoch: 6| Step: 10
Training loss: 0.3297699160862646
Validation loss: 2.2515717597328044

Epoch: 6| Step: 11
Training loss: 0.15915429316436924
Validation loss: 2.2801959681506037

Epoch: 6| Step: 12
Training loss: 0.2049943934668329
Validation loss: 2.2766392939454705

Epoch: 6| Step: 13
Training loss: 0.24954168210709235
Validation loss: 2.280247646624311

Epoch: 383| Step: 0
Training loss: 0.2869611863713191
Validation loss: 2.2908473688830986

Epoch: 6| Step: 1
Training loss: 0.2531866440062883
Validation loss: 2.2366851832546724

Epoch: 6| Step: 2
Training loss: 0.3295055140235082
Validation loss: 2.287633647384518

Epoch: 6| Step: 3
Training loss: 0.26436251858857235
Validation loss: 2.232522049439358

Epoch: 6| Step: 4
Training loss: 0.3670698951523152
Validation loss: 2.259963457464773

Epoch: 6| Step: 5
Training loss: 0.37489152372525414
Validation loss: 2.251884104279469

Epoch: 6| Step: 6
Training loss: 0.3395354418050363
Validation loss: 2.2248800959764936

Epoch: 6| Step: 7
Training loss: 0.18871628138012012
Validation loss: 2.264826263293557

Epoch: 6| Step: 8
Training loss: 0.21983921130388356
Validation loss: 2.2772952075144706

Epoch: 6| Step: 9
Training loss: 0.24324328499333994
Validation loss: 2.2238546402377524

Epoch: 6| Step: 10
Training loss: 0.23723910646080107
Validation loss: 2.3108062555556512

Epoch: 6| Step: 11
Training loss: 0.30922597995226214
Validation loss: 2.243438672893788

Epoch: 6| Step: 12
Training loss: 0.2906359557681186
Validation loss: 2.258061607548676

Epoch: 6| Step: 13
Training loss: 0.26665582908025814
Validation loss: 2.2501185703824653

Epoch: 384| Step: 0
Training loss: 0.20160200375081988
Validation loss: 2.2427434287460604

Epoch: 6| Step: 1
Training loss: 0.3533681171861529
Validation loss: 2.273686555938831

Epoch: 6| Step: 2
Training loss: 0.23283007382623752
Validation loss: 2.2818291682280867

Epoch: 6| Step: 3
Training loss: 0.2883758379407729
Validation loss: 2.2415724917723185

Epoch: 6| Step: 4
Training loss: 0.39205649342155297
Validation loss: 2.254758086567909

Epoch: 6| Step: 5
Training loss: 0.2755938517341811
Validation loss: 2.2471806558359697

Epoch: 6| Step: 6
Training loss: 0.26121978737928264
Validation loss: 2.282576876192132

Epoch: 6| Step: 7
Training loss: 0.28602555123062573
Validation loss: 2.269608225477304

Epoch: 6| Step: 8
Training loss: 0.24388862574291467
Validation loss: 2.2350151461031866

Epoch: 6| Step: 9
Training loss: 0.3111282879918896
Validation loss: 2.2719930230730907

Epoch: 6| Step: 10
Training loss: 0.35875021485910397
Validation loss: 2.2660647699903196

Epoch: 6| Step: 11
Training loss: 0.1989612691889015
Validation loss: 2.2867274520633725

Epoch: 6| Step: 12
Training loss: 0.30363376286999716
Validation loss: 2.2858133007214314

Epoch: 6| Step: 13
Training loss: 0.2333054776395649
Validation loss: 2.280597776426633

Epoch: 385| Step: 0
Training loss: 0.46617774925155675
Validation loss: 2.2822334747579767

Epoch: 6| Step: 1
Training loss: 0.4827259202134334
Validation loss: 2.266776027098218

Epoch: 6| Step: 2
Training loss: 0.35315338037599403
Validation loss: 2.2532838152583454

Epoch: 6| Step: 3
Training loss: 0.2848856961935895
Validation loss: 2.303601301019964

Epoch: 6| Step: 4
Training loss: 0.17853027342080685
Validation loss: 2.278752619103095

Epoch: 6| Step: 5
Training loss: 0.3023341579049238
Validation loss: 2.255406815132497

Epoch: 6| Step: 6
Training loss: 0.21400191361583326
Validation loss: 2.2402549505466767

Epoch: 6| Step: 7
Training loss: 0.40532307148531505
Validation loss: 2.309496294896122

Epoch: 6| Step: 8
Training loss: 0.3673961939141617
Validation loss: 2.246231561385898

Epoch: 6| Step: 9
Training loss: 0.19315915385953206
Validation loss: 2.28368658642073

Epoch: 6| Step: 10
Training loss: 0.37840028783039253
Validation loss: 2.301439054156363

Epoch: 6| Step: 11
Training loss: 0.30563761441306364
Validation loss: 2.2795076989151744

Epoch: 6| Step: 12
Training loss: 0.3703889277012366
Validation loss: 2.3143113147840695

Epoch: 6| Step: 13
Training loss: 0.3566766484630018
Validation loss: 2.295318465358183

Epoch: 386| Step: 0
Training loss: 0.33787953353053235
Validation loss: 2.26817672674713

Epoch: 6| Step: 1
Training loss: 0.3206491097277142
Validation loss: 2.2251860083648314

Epoch: 6| Step: 2
Training loss: 0.37661759855870836
Validation loss: 2.309328017318251

Epoch: 6| Step: 3
Training loss: 0.1717810699249595
Validation loss: 2.2247856947743134

Epoch: 6| Step: 4
Training loss: 0.3247430996473754
Validation loss: 2.2910827384066144

Epoch: 6| Step: 5
Training loss: 0.14598120418903415
Validation loss: 2.296851973299267

Epoch: 6| Step: 6
Training loss: 0.2831861556658369
Validation loss: 2.266632066724399

Epoch: 6| Step: 7
Training loss: 0.2754827845693412
Validation loss: 2.2844621174660995

Epoch: 6| Step: 8
Training loss: 0.2550948711465491
Validation loss: 2.2328689941776503

Epoch: 6| Step: 9
Training loss: 0.32939118226127556
Validation loss: 2.318511400859598

Epoch: 6| Step: 10
Training loss: 0.2460192991595926
Validation loss: 2.316059071521558

Epoch: 6| Step: 11
Training loss: 0.43022794547956056
Validation loss: 2.267906697443083

Epoch: 6| Step: 12
Training loss: 0.22865092518784236
Validation loss: 2.2950869150540205

Epoch: 6| Step: 13
Training loss: 0.2152116746233795
Validation loss: 2.277898582366708

Epoch: 387| Step: 0
Training loss: 0.2714688687733201
Validation loss: 2.316740821319364

Epoch: 6| Step: 1
Training loss: 0.3132865543820149
Validation loss: 2.31960463081762

Epoch: 6| Step: 2
Training loss: 0.39821816933697407
Validation loss: 2.287888244172622

Epoch: 6| Step: 3
Training loss: 0.42937053780826046
Validation loss: 2.289790188646561

Epoch: 6| Step: 4
Training loss: 0.3358427845703288
Validation loss: 2.2598098315347084

Epoch: 6| Step: 5
Training loss: 0.309367453357861
Validation loss: 2.25367978091525

Epoch: 6| Step: 6
Training loss: 0.22692592017892965
Validation loss: 2.2341741369346173

Epoch: 6| Step: 7
Training loss: 0.3928964567330029
Validation loss: 2.2857274920076374

Epoch: 6| Step: 8
Training loss: 0.2869237442408582
Validation loss: 2.259565893527153

Epoch: 6| Step: 9
Training loss: 0.20948122802838057
Validation loss: 2.2340129123196193

Epoch: 6| Step: 10
Training loss: 0.2223523391490792
Validation loss: 2.2539015427776614

Epoch: 6| Step: 11
Training loss: 0.2603417940589438
Validation loss: 2.2186144756064867

Epoch: 6| Step: 12
Training loss: 0.316576264469092
Validation loss: 2.2967527447816245

Epoch: 6| Step: 13
Training loss: 0.33865613713816556
Validation loss: 2.1836021027379657

Epoch: 388| Step: 0
Training loss: 0.2656257853776877
Validation loss: 2.2758098865457326

Epoch: 6| Step: 1
Training loss: 0.25598140165358624
Validation loss: 2.248770209944875

Epoch: 6| Step: 2
Training loss: 0.180376772953792
Validation loss: 2.274616403343387

Epoch: 6| Step: 3
Training loss: 0.33916604223396934
Validation loss: 2.28901360712358

Epoch: 6| Step: 4
Training loss: 0.25928122307413015
Validation loss: 2.2485579885399765

Epoch: 6| Step: 5
Training loss: 0.21212104498301357
Validation loss: 2.2898432210702326

Epoch: 6| Step: 6
Training loss: 0.2806416395729848
Validation loss: 2.279554093771334

Epoch: 6| Step: 7
Training loss: 0.269991081629151
Validation loss: 2.2775161878538825

Epoch: 6| Step: 8
Training loss: 0.33239871615685235
Validation loss: 2.2774737208134743

Epoch: 6| Step: 9
Training loss: 0.3307993756762313
Validation loss: 2.3056795129685144

Epoch: 6| Step: 10
Training loss: 0.34376637463149584
Validation loss: 2.2924550492106643

Epoch: 6| Step: 11
Training loss: 0.4869414602223158
Validation loss: 2.2873602169526506

Epoch: 6| Step: 12
Training loss: 0.24203322480580006
Validation loss: 2.2751323329598545

Epoch: 6| Step: 13
Training loss: 0.29714253567796783
Validation loss: 2.2934832539966843

Epoch: 389| Step: 0
Training loss: 0.31996986625395457
Validation loss: 2.2873078913526834

Epoch: 6| Step: 1
Training loss: 0.2361345680745811
Validation loss: 2.3550682845073263

Epoch: 6| Step: 2
Training loss: 0.2756550378499259
Validation loss: 2.295421174837169

Epoch: 6| Step: 3
Training loss: 0.27604046707372504
Validation loss: 2.2744195746134857

Epoch: 6| Step: 4
Training loss: 0.24022001518193248
Validation loss: 2.341610962373743

Epoch: 6| Step: 5
Training loss: 0.33108963683428194
Validation loss: 2.3023809755524156

Epoch: 6| Step: 6
Training loss: 0.42285628459311253
Validation loss: 2.3062386589150496

Epoch: 6| Step: 7
Training loss: 0.3114778132497388
Validation loss: 2.2888024522016672

Epoch: 6| Step: 8
Training loss: 0.3759888485969452
Validation loss: 2.260226840883648

Epoch: 6| Step: 9
Training loss: 0.3857600727039421
Validation loss: 2.2702796914411665

Epoch: 6| Step: 10
Training loss: 0.39010488215517947
Validation loss: 2.28989416991209

Epoch: 6| Step: 11
Training loss: 0.29945450003945456
Validation loss: 2.279567245926799

Epoch: 6| Step: 12
Training loss: 0.27179402592485097
Validation loss: 2.2526896524838067

Epoch: 6| Step: 13
Training loss: 0.3181130562134634
Validation loss: 2.27215931760501

Epoch: 390| Step: 0
Training loss: 0.23782599061254173
Validation loss: 2.2914711493115147

Epoch: 6| Step: 1
Training loss: 0.28652398773119725
Validation loss: 2.28015566840999

Epoch: 6| Step: 2
Training loss: 0.2677945285228916
Validation loss: 2.3124014429620967

Epoch: 6| Step: 3
Training loss: 0.18043171143372205
Validation loss: 2.2383041513812585

Epoch: 6| Step: 4
Training loss: 0.21734638851492133
Validation loss: 2.2772801315643174

Epoch: 6| Step: 5
Training loss: 0.3333107250215718
Validation loss: 2.2816309501949195

Epoch: 6| Step: 6
Training loss: 0.3459365616934714
Validation loss: 2.307417353069231

Epoch: 6| Step: 7
Training loss: 0.21259778556767228
Validation loss: 2.339871796454211

Epoch: 6| Step: 8
Training loss: 0.2923911440674531
Validation loss: 2.312904623219366

Epoch: 6| Step: 9
Training loss: 0.31203361517974926
Validation loss: 2.2380405050230934

Epoch: 6| Step: 10
Training loss: 0.30227978939136135
Validation loss: 2.2618102481761997

Epoch: 6| Step: 11
Training loss: 0.2682530738151399
Validation loss: 2.279789583440586

Epoch: 6| Step: 12
Training loss: 0.34740353089154036
Validation loss: 2.2929035547921264

Epoch: 6| Step: 13
Training loss: 0.21096483689234574
Validation loss: 2.2963979662528438

Epoch: 391| Step: 0
Training loss: 0.27899561820639884
Validation loss: 2.300142036419813

Epoch: 6| Step: 1
Training loss: 0.3342106370623374
Validation loss: 2.2961444687755264

Epoch: 6| Step: 2
Training loss: 0.2829383928180796
Validation loss: 2.304015368713341

Epoch: 6| Step: 3
Training loss: 0.26457523023156837
Validation loss: 2.3096897989539564

Epoch: 6| Step: 4
Training loss: 0.23592391006538918
Validation loss: 2.258341902074945

Epoch: 6| Step: 5
Training loss: 0.21965637781538633
Validation loss: 2.269645911256807

Epoch: 6| Step: 6
Training loss: 0.34026411519983657
Validation loss: 2.2994000056556527

Epoch: 6| Step: 7
Training loss: 0.3142902592231288
Validation loss: 2.265165611258798

Epoch: 6| Step: 8
Training loss: 0.35416226758281816
Validation loss: 2.2840134330611694

Epoch: 6| Step: 9
Training loss: 0.3447373040014378
Validation loss: 2.268701801190903

Epoch: 6| Step: 10
Training loss: 0.21692825323173304
Validation loss: 2.261559937061746

Epoch: 6| Step: 11
Training loss: 0.18458999044484958
Validation loss: 2.2920494944696927

Epoch: 6| Step: 12
Training loss: 0.31155860487130177
Validation loss: 2.265284115808247

Epoch: 6| Step: 13
Training loss: 0.48367466596273523
Validation loss: 2.3101541030008614

Epoch: 392| Step: 0
Training loss: 0.3581597887487941
Validation loss: 2.26691358906635

Epoch: 6| Step: 1
Training loss: 0.19655354080645052
Validation loss: 2.314895214238708

Epoch: 6| Step: 2
Training loss: 0.2739899640020421
Validation loss: 2.2518398921452136

Epoch: 6| Step: 3
Training loss: 0.16950342020238462
Validation loss: 2.301517802605322

Epoch: 6| Step: 4
Training loss: 0.39256271407970755
Validation loss: 2.3512448321239536

Epoch: 6| Step: 5
Training loss: 0.27298178162936004
Validation loss: 2.2759471993006373

Epoch: 6| Step: 6
Training loss: 0.2841266831718631
Validation loss: 2.28944845059715

Epoch: 6| Step: 7
Training loss: 0.3359807674134625
Validation loss: 2.287314397373089

Epoch: 6| Step: 8
Training loss: 0.22859741442670778
Validation loss: 2.2942890479713927

Epoch: 6| Step: 9
Training loss: 0.29034366731906297
Validation loss: 2.2597234046660444

Epoch: 6| Step: 10
Training loss: 0.23225929279850746
Validation loss: 2.306626094004668

Epoch: 6| Step: 11
Training loss: 0.28568000247174435
Validation loss: 2.303221112147586

Epoch: 6| Step: 12
Training loss: 0.3517424017174315
Validation loss: 2.2950216588180536

Epoch: 6| Step: 13
Training loss: 0.22008607063940763
Validation loss: 2.296064826477707

Epoch: 393| Step: 0
Training loss: 0.30280791589201966
Validation loss: 2.2587696409400673

Epoch: 6| Step: 1
Training loss: 0.19937424108008037
Validation loss: 2.290399293417849

Epoch: 6| Step: 2
Training loss: 0.24308362649232537
Validation loss: 2.2944364686395766

Epoch: 6| Step: 3
Training loss: 0.20313228080612145
Validation loss: 2.327808930449818

Epoch: 6| Step: 4
Training loss: 0.18089842158552052
Validation loss: 2.301499449502295

Epoch: 6| Step: 5
Training loss: 0.3034408570525255
Validation loss: 2.3504262314455144

Epoch: 6| Step: 6
Training loss: 0.2491958470119804
Validation loss: 2.336394793638117

Epoch: 6| Step: 7
Training loss: 0.25183099551623156
Validation loss: 2.316026318738225

Epoch: 6| Step: 8
Training loss: 0.18389889539534163
Validation loss: 2.2924624853000934

Epoch: 6| Step: 9
Training loss: 0.2609926656554839
Validation loss: 2.2610732734861387

Epoch: 6| Step: 10
Training loss: 0.262260076460157
Validation loss: 2.32946870843761

Epoch: 6| Step: 11
Training loss: 0.3800729310169901
Validation loss: 2.2796564066498397

Epoch: 6| Step: 12
Training loss: 0.262755603324022
Validation loss: 2.3134520864741814

Epoch: 6| Step: 13
Training loss: 0.242553956675297
Validation loss: 2.32055703875013

Epoch: 394| Step: 0
Training loss: 0.2832630883237472
Validation loss: 2.2912276685604245

Epoch: 6| Step: 1
Training loss: 0.3330713026988415
Validation loss: 2.2960704683307007

Epoch: 6| Step: 2
Training loss: 0.25094648841541306
Validation loss: 2.2964285245747207

Epoch: 6| Step: 3
Training loss: 0.21268857764868693
Validation loss: 2.2980549694322696

Epoch: 6| Step: 4
Training loss: 0.3312231889706749
Validation loss: 2.3417136267934375

Epoch: 6| Step: 5
Training loss: 0.32217963256258253
Validation loss: 2.2401489489851616

Epoch: 6| Step: 6
Training loss: 0.268905646142276
Validation loss: 2.3120848136929655

Epoch: 6| Step: 7
Training loss: 0.409857486722976
Validation loss: 2.34048802883708

Epoch: 6| Step: 8
Training loss: 0.2445714430028148
Validation loss: 2.276754626962122

Epoch: 6| Step: 9
Training loss: 0.3877249641513876
Validation loss: 2.252580522769625

Epoch: 6| Step: 10
Training loss: 0.25385003568011505
Validation loss: 2.269483739779108

Epoch: 6| Step: 11
Training loss: 0.34197102061266194
Validation loss: 2.2362749251655245

Epoch: 6| Step: 12
Training loss: 0.2782264149533448
Validation loss: 2.2867996262337917

Epoch: 6| Step: 13
Training loss: 0.4071913596473155
Validation loss: 2.2636970121465256

Epoch: 395| Step: 0
Training loss: 0.2483561682576586
Validation loss: 2.2110221496121287

Epoch: 6| Step: 1
Training loss: 0.2518191609830727
Validation loss: 2.2459227565969533

Epoch: 6| Step: 2
Training loss: 0.2810381647890496
Validation loss: 2.24020057570689

Epoch: 6| Step: 3
Training loss: 0.2972309337930726
Validation loss: 2.2799307087078757

Epoch: 6| Step: 4
Training loss: 0.28270930942000516
Validation loss: 2.2533857514794717

Epoch: 6| Step: 5
Training loss: 0.34319948416345464
Validation loss: 2.2577048763333045

Epoch: 6| Step: 6
Training loss: 0.2526833207036976
Validation loss: 2.234464968134928

Epoch: 6| Step: 7
Training loss: 0.31443249889514663
Validation loss: 2.3172618793151916

Epoch: 6| Step: 8
Training loss: 0.3630225993824512
Validation loss: 2.255582700554545

Epoch: 6| Step: 9
Training loss: 0.37973058636623663
Validation loss: 2.2763460131860103

Epoch: 6| Step: 10
Training loss: 0.321316923655296
Validation loss: 2.2607553524240966

Epoch: 6| Step: 11
Training loss: 0.29564817313570624
Validation loss: 2.25135821391451

Epoch: 6| Step: 12
Training loss: 0.3065371733692154
Validation loss: 2.2725893079179245

Epoch: 6| Step: 13
Training loss: 0.36974136476060254
Validation loss: 2.3580425112340504

Epoch: 396| Step: 0
Training loss: 0.2807028800014124
Validation loss: 2.3422793118646035

Epoch: 6| Step: 1
Training loss: 0.27130605481007236
Validation loss: 2.25889988006315

Epoch: 6| Step: 2
Training loss: 0.4410153573967094
Validation loss: 2.372362730519016

Epoch: 6| Step: 3
Training loss: 0.32395818880002314
Validation loss: 2.322081117650053

Epoch: 6| Step: 4
Training loss: 0.23683186116863905
Validation loss: 2.3244782546036835

Epoch: 6| Step: 5
Training loss: 0.26149592237046804
Validation loss: 2.3774604433595057

Epoch: 6| Step: 6
Training loss: 0.23111061651079376
Validation loss: 2.349880322324099

Epoch: 6| Step: 7
Training loss: 0.3450219938966098
Validation loss: 2.3055205224399953

Epoch: 6| Step: 8
Training loss: 0.3177981783772963
Validation loss: 2.3073102779513266

Epoch: 6| Step: 9
Training loss: 0.2270094146782254
Validation loss: 2.307876673490396

Epoch: 6| Step: 10
Training loss: 0.36113707156684566
Validation loss: 2.3186665529383053

Epoch: 6| Step: 11
Training loss: 0.3278256481323084
Validation loss: 2.3696198677138476

Epoch: 6| Step: 12
Training loss: 0.24199274908189983
Validation loss: 2.283270702988146

Epoch: 6| Step: 13
Training loss: 0.22739112530801833
Validation loss: 2.356855499826232

Epoch: 397| Step: 0
Training loss: 0.22468287882343527
Validation loss: 2.2609930285155526

Epoch: 6| Step: 1
Training loss: 0.4177817166842501
Validation loss: 2.347715913392101

Epoch: 6| Step: 2
Training loss: 0.24286726951272553
Validation loss: 2.303345784302259

Epoch: 6| Step: 3
Training loss: 0.2288264907044006
Validation loss: 2.3097131277692737

Epoch: 6| Step: 4
Training loss: 0.31071564748658237
Validation loss: 2.3388743231232487

Epoch: 6| Step: 5
Training loss: 0.2928109316137563
Validation loss: 2.2760072933950597

Epoch: 6| Step: 6
Training loss: 0.27513827943795893
Validation loss: 2.2605652796913054

Epoch: 6| Step: 7
Training loss: 0.3870659242759109
Validation loss: 2.2746122368618718

Epoch: 6| Step: 8
Training loss: 0.3114407348870547
Validation loss: 2.328433065492548

Epoch: 6| Step: 9
Training loss: 0.2851489209840143
Validation loss: 2.3052412068372674

Epoch: 6| Step: 10
Training loss: 0.2820377180039386
Validation loss: 2.2865434658274406

Epoch: 6| Step: 11
Training loss: 0.2596569407554085
Validation loss: 2.285873778631249

Epoch: 6| Step: 12
Training loss: 0.20076689650294524
Validation loss: 2.3201865387880245

Epoch: 6| Step: 13
Training loss: 0.3177694694397905
Validation loss: 2.303008024712166

Epoch: 398| Step: 0
Training loss: 0.29772885405787625
Validation loss: 2.3354335313562964

Epoch: 6| Step: 1
Training loss: 0.1933490866033555
Validation loss: 2.309420614519045

Epoch: 6| Step: 2
Training loss: 0.24720731713663555
Validation loss: 2.2648094550987423

Epoch: 6| Step: 3
Training loss: 0.264247633011249
Validation loss: 2.318449014903417

Epoch: 6| Step: 4
Training loss: 0.4053561390521643
Validation loss: 2.305233898156113

Epoch: 6| Step: 5
Training loss: 0.3437792158715959
Validation loss: 2.265774943333739

Epoch: 6| Step: 6
Training loss: 0.31115112059249045
Validation loss: 2.323435119682415

Epoch: 6| Step: 7
Training loss: 0.37474200195139945
Validation loss: 2.277551212970266

Epoch: 6| Step: 8
Training loss: 0.22021384566730062
Validation loss: 2.3053304518944007

Epoch: 6| Step: 9
Training loss: 0.25495585129534404
Validation loss: 2.2759392640379663

Epoch: 6| Step: 10
Training loss: 0.2866469961286459
Validation loss: 2.299454397641998

Epoch: 6| Step: 11
Training loss: 0.3230642883699983
Validation loss: 2.270565959226882

Epoch: 6| Step: 12
Training loss: 0.3426907431466234
Validation loss: 2.313053614701845

Epoch: 6| Step: 13
Training loss: 0.34846896641036673
Validation loss: 2.3011870876334575

Epoch: 399| Step: 0
Training loss: 0.21951914852360196
Validation loss: 2.256408650957189

Epoch: 6| Step: 1
Training loss: 0.31028897594861105
Validation loss: 2.2944175912867686

Epoch: 6| Step: 2
Training loss: 0.3570047456348443
Validation loss: 2.273839558883533

Epoch: 6| Step: 3
Training loss: 0.2584529349251033
Validation loss: 2.322923041592961

Epoch: 6| Step: 4
Training loss: 0.3222884083410341
Validation loss: 2.249963715931825

Epoch: 6| Step: 5
Training loss: 0.27791968171477827
Validation loss: 2.301856574948824

Epoch: 6| Step: 6
Training loss: 0.2517318197228055
Validation loss: 2.251090121214779

Epoch: 6| Step: 7
Training loss: 0.21962720531926147
Validation loss: 2.302075853522622

Epoch: 6| Step: 8
Training loss: 0.37535352732000915
Validation loss: 2.2899153577717835

Epoch: 6| Step: 9
Training loss: 0.25440006652784675
Validation loss: 2.299809041596197

Epoch: 6| Step: 10
Training loss: 0.39286199905750513
Validation loss: 2.307501795538317

Epoch: 6| Step: 11
Training loss: 0.3029192944237352
Validation loss: 2.3187421457546638

Epoch: 6| Step: 12
Training loss: 0.3652327838393858
Validation loss: 2.3153149080137396

Epoch: 6| Step: 13
Training loss: 0.2984301591140087
Validation loss: 2.264319997693828

Epoch: 400| Step: 0
Training loss: 0.3148029821614521
Validation loss: 2.2818793730675155

Epoch: 6| Step: 1
Training loss: 0.2380330638052651
Validation loss: 2.310157801163494

Epoch: 6| Step: 2
Training loss: 0.3756009888869056
Validation loss: 2.2496726363063253

Epoch: 6| Step: 3
Training loss: 0.2179440398891007
Validation loss: 2.299325703863838

Epoch: 6| Step: 4
Training loss: 0.2922883971315336
Validation loss: 2.3167450749784115

Epoch: 6| Step: 5
Training loss: 0.2572179354044279
Validation loss: 2.3211971527421786

Epoch: 6| Step: 6
Training loss: 0.18654093235914554
Validation loss: 2.382076912827308

Epoch: 6| Step: 7
Training loss: 0.31424701641308217
Validation loss: 2.3231981275158597

Epoch: 6| Step: 8
Training loss: 0.28572642138797893
Validation loss: 2.3228671891170554

Epoch: 6| Step: 9
Training loss: 0.27335180574650675
Validation loss: 2.336723221009676

Epoch: 6| Step: 10
Training loss: 0.28783350084044446
Validation loss: 2.339253083039261

Epoch: 6| Step: 11
Training loss: 0.2706019378949377
Validation loss: 2.264294963983671

Epoch: 6| Step: 12
Training loss: 0.2448061302998368
Validation loss: 2.3527531867510523

Epoch: 6| Step: 13
Training loss: 0.3362122676198573
Validation loss: 2.3075112840370364

Epoch: 401| Step: 0
Training loss: 0.24237127407253614
Validation loss: 2.2693216617738323

Epoch: 6| Step: 1
Training loss: 0.3160136341838583
Validation loss: 2.322636725716511

Epoch: 6| Step: 2
Training loss: 0.3243179514227002
Validation loss: 2.3237489626237298

Epoch: 6| Step: 3
Training loss: 0.23784923475269504
Validation loss: 2.240437426091051

Epoch: 6| Step: 4
Training loss: 0.18809411178683363
Validation loss: 2.2908930224009474

Epoch: 6| Step: 5
Training loss: 0.3862005287265566
Validation loss: 2.217664927901016

Epoch: 6| Step: 6
Training loss: 0.2407875283132585
Validation loss: 2.2835577348672143

Epoch: 6| Step: 7
Training loss: 0.19647534389482743
Validation loss: 2.292019475886321

Epoch: 6| Step: 8
Training loss: 0.2821585233307154
Validation loss: 2.294335308460762

Epoch: 6| Step: 9
Training loss: 0.23920317045342554
Validation loss: 2.288250081362425

Epoch: 6| Step: 10
Training loss: 0.2737547532631321
Validation loss: 2.2897439231010295

Epoch: 6| Step: 11
Training loss: 0.3271385419117605
Validation loss: 2.329823073108062

Epoch: 6| Step: 12
Training loss: 0.26872511571075536
Validation loss: 2.290363458514231

Epoch: 6| Step: 13
Training loss: 0.3036801975798768
Validation loss: 2.282332316015875

Epoch: 402| Step: 0
Training loss: 0.28973724896875025
Validation loss: 2.3013647491313525

Epoch: 6| Step: 1
Training loss: 0.20226847268314127
Validation loss: 2.3316461190778717

Epoch: 6| Step: 2
Training loss: 0.2926915446769099
Validation loss: 2.308728338407421

Epoch: 6| Step: 3
Training loss: 0.27476085863705635
Validation loss: 2.2889589583552095

Epoch: 6| Step: 4
Training loss: 0.2904225136256337
Validation loss: 2.2803971773673113

Epoch: 6| Step: 5
Training loss: 0.28151204564237553
Validation loss: 2.275771717907575

Epoch: 6| Step: 6
Training loss: 0.30158421235660465
Validation loss: 2.285575145789341

Epoch: 6| Step: 7
Training loss: 0.27400982769253446
Validation loss: 2.31307460759912

Epoch: 6| Step: 8
Training loss: 0.30564285546003733
Validation loss: 2.3061825057493874

Epoch: 6| Step: 9
Training loss: 0.32770406880709124
Validation loss: 2.2504616458039717

Epoch: 6| Step: 10
Training loss: 0.13241914391866183
Validation loss: 2.257235223345826

Epoch: 6| Step: 11
Training loss: 0.17602926347892578
Validation loss: 2.254189952182429

Epoch: 6| Step: 12
Training loss: 0.3829616723093344
Validation loss: 2.311761910122762

Epoch: 6| Step: 13
Training loss: 0.19980182589721907
Validation loss: 2.269835705014078

Epoch: 403| Step: 0
Training loss: 0.37155833024620083
Validation loss: 2.263345918180322

Epoch: 6| Step: 1
Training loss: 0.17142372057961483
Validation loss: 2.302170054210532

Epoch: 6| Step: 2
Training loss: 0.21139364901400032
Validation loss: 2.2914611738723596

Epoch: 6| Step: 3
Training loss: 0.2914003734660848
Validation loss: 2.2731253725404166

Epoch: 6| Step: 4
Training loss: 0.26812485021306903
Validation loss: 2.248699651355586

Epoch: 6| Step: 5
Training loss: 0.3044985405318514
Validation loss: 2.2645670733764454

Epoch: 6| Step: 6
Training loss: 0.28782546342447785
Validation loss: 2.272184920477615

Epoch: 6| Step: 7
Training loss: 0.15767320726992534
Validation loss: 2.2562026430128332

Epoch: 6| Step: 8
Training loss: 0.2855817416048138
Validation loss: 2.2596017508295776

Epoch: 6| Step: 9
Training loss: 0.31625814857087176
Validation loss: 2.2630848116476967

Epoch: 6| Step: 10
Training loss: 0.31827101622184173
Validation loss: 2.311716428091403

Epoch: 6| Step: 11
Training loss: 0.27278006401245575
Validation loss: 2.298534312954913

Epoch: 6| Step: 12
Training loss: 0.3480652214549429
Validation loss: 2.310149157774136

Epoch: 6| Step: 13
Training loss: 0.2216662432253051
Validation loss: 2.2869228739808576

Epoch: 404| Step: 0
Training loss: 0.1873048322913731
Validation loss: 2.2868468027738755

Epoch: 6| Step: 1
Training loss: 0.19370752838144206
Validation loss: 2.2864242991446706

Epoch: 6| Step: 2
Training loss: 0.2627389013721181
Validation loss: 2.2993654170402156

Epoch: 6| Step: 3
Training loss: 0.18470028937863914
Validation loss: 2.2790028203433748

Epoch: 6| Step: 4
Training loss: 0.24746723483171304
Validation loss: 2.288137724319251

Epoch: 6| Step: 5
Training loss: 0.30776333440453174
Validation loss: 2.3116412931157644

Epoch: 6| Step: 6
Training loss: 0.27715944156751093
Validation loss: 2.251729662423633

Epoch: 6| Step: 7
Training loss: 0.2890481429787519
Validation loss: 2.316916235395684

Epoch: 6| Step: 8
Training loss: 0.24280354381426816
Validation loss: 2.245626862140566

Epoch: 6| Step: 9
Training loss: 0.43379416430554935
Validation loss: 2.309789254454591

Epoch: 6| Step: 10
Training loss: 0.30297502366604223
Validation loss: 2.26792974645471

Epoch: 6| Step: 11
Training loss: 0.290414124554783
Validation loss: 2.294369739099351

Epoch: 6| Step: 12
Training loss: 0.3718462091408367
Validation loss: 2.2854643350484967

Epoch: 6| Step: 13
Training loss: 0.23253014390895374
Validation loss: 2.3127621167069328

Epoch: 405| Step: 0
Training loss: 0.37303980476110454
Validation loss: 2.301256183682957

Epoch: 6| Step: 1
Training loss: 0.22596785183193782
Validation loss: 2.293914322679624

Epoch: 6| Step: 2
Training loss: 0.32148351843014117
Validation loss: 2.2686370646353713

Epoch: 6| Step: 3
Training loss: 0.3442850825101718
Validation loss: 2.3023099111730976

Epoch: 6| Step: 4
Training loss: 0.31619196570387753
Validation loss: 2.297246370979188

Epoch: 6| Step: 5
Training loss: 0.4716602108174333
Validation loss: 2.2800649935677684

Epoch: 6| Step: 6
Training loss: 0.3194938292661144
Validation loss: 2.325093995180246

Epoch: 6| Step: 7
Training loss: 0.3285853471828906
Validation loss: 2.286230424950477

Epoch: 6| Step: 8
Training loss: 0.21713395590750986
Validation loss: 2.2513385870500118

Epoch: 6| Step: 9
Training loss: 0.21866985112950796
Validation loss: 2.283608423725966

Epoch: 6| Step: 10
Training loss: 0.3670406453703068
Validation loss: 2.2807837754499736

Epoch: 6| Step: 11
Training loss: 0.3323758861139715
Validation loss: 2.302029791737239

Epoch: 6| Step: 12
Training loss: 0.30452072029444854
Validation loss: 2.2948739121206954

Epoch: 6| Step: 13
Training loss: 0.23222251163475532
Validation loss: 2.3101512218700564

Epoch: 406| Step: 0
Training loss: 0.2183830640769085
Validation loss: 2.3208577278631224

Epoch: 6| Step: 1
Training loss: 0.3104553687634551
Validation loss: 2.2768987850175857

Epoch: 6| Step: 2
Training loss: 0.24793737352405013
Validation loss: 2.310450814433064

Epoch: 6| Step: 3
Training loss: 0.23696613101248953
Validation loss: 2.303649953283193

Epoch: 6| Step: 4
Training loss: 0.2961986516964971
Validation loss: 2.3061314601465503

Epoch: 6| Step: 5
Training loss: 0.2892393911241098
Validation loss: 2.265027495772407

Epoch: 6| Step: 6
Training loss: 0.31486692508945635
Validation loss: 2.2982879064421486

Epoch: 6| Step: 7
Training loss: 0.2905007229958498
Validation loss: 2.3071296037945372

Epoch: 6| Step: 8
Training loss: 0.40994993197792623
Validation loss: 2.2976717096971893

Epoch: 6| Step: 9
Training loss: 0.27172622611151503
Validation loss: 2.253771534931633

Epoch: 6| Step: 10
Training loss: 0.2902108014725895
Validation loss: 2.252006236781986

Epoch: 6| Step: 11
Training loss: 0.2738737305063748
Validation loss: 2.2493554445974606

Epoch: 6| Step: 12
Training loss: 0.2911888477485025
Validation loss: 2.222856956139985

Epoch: 6| Step: 13
Training loss: 0.30183360311544216
Validation loss: 2.269001262542275

Epoch: 407| Step: 0
Training loss: 0.4470654168617109
Validation loss: 2.2481614566152213

Epoch: 6| Step: 1
Training loss: 0.28043166954146703
Validation loss: 2.2486650073911165

Epoch: 6| Step: 2
Training loss: 0.36451329739311605
Validation loss: 2.2469451263760374

Epoch: 6| Step: 3
Training loss: 0.32550840226915023
Validation loss: 2.278926763746269

Epoch: 6| Step: 4
Training loss: 0.2806703767218861
Validation loss: 2.254907386792363

Epoch: 6| Step: 5
Training loss: 0.27610132484429045
Validation loss: 2.2757095047982028

Epoch: 6| Step: 6
Training loss: 0.2032181727855638
Validation loss: 2.2604651087010446

Epoch: 6| Step: 7
Training loss: 0.28997295923607624
Validation loss: 2.3084397455561456

Epoch: 6| Step: 8
Training loss: 0.20305994716071657
Validation loss: 2.2880875786495793

Epoch: 6| Step: 9
Training loss: 0.2670219097881153
Validation loss: 2.3281377838944404

Epoch: 6| Step: 10
Training loss: 0.2628989299125557
Validation loss: 2.2702046728639957

Epoch: 6| Step: 11
Training loss: 0.233791913466889
Validation loss: 2.2949297705981198

Epoch: 6| Step: 12
Training loss: 0.25614523025158326
Validation loss: 2.311188600906438

Epoch: 6| Step: 13
Training loss: 0.2984952131858796
Validation loss: 2.3137809023999463

Epoch: 408| Step: 0
Training loss: 0.3059297327257709
Validation loss: 2.314328235631412

Epoch: 6| Step: 1
Training loss: 0.23646969141267996
Validation loss: 2.261359274610063

Epoch: 6| Step: 2
Training loss: 0.19757032939393873
Validation loss: 2.240052681172862

Epoch: 6| Step: 3
Training loss: 0.36965279142945207
Validation loss: 2.2866995444543132

Epoch: 6| Step: 4
Training loss: 0.31950747114648737
Validation loss: 2.3081147739994052

Epoch: 6| Step: 5
Training loss: 0.22109876465249587
Validation loss: 2.30253540249315

Epoch: 6| Step: 6
Training loss: 0.29636020950342284
Validation loss: 2.2668562075895884

Epoch: 6| Step: 7
Training loss: 0.41965105061808045
Validation loss: 2.2703102425102184

Epoch: 6| Step: 8
Training loss: 0.22425042370636036
Validation loss: 2.2885117025472734

Epoch: 6| Step: 9
Training loss: 0.2594893571089717
Validation loss: 2.260312756261007

Epoch: 6| Step: 10
Training loss: 0.33901308200570035
Validation loss: 2.316753753790794

Epoch: 6| Step: 11
Training loss: 0.3048774665007032
Validation loss: 2.2964471171939005

Epoch: 6| Step: 12
Training loss: 0.3517277647038431
Validation loss: 2.2961962728595213

Epoch: 6| Step: 13
Training loss: 0.46515342270745036
Validation loss: 2.34430423541294

Epoch: 409| Step: 0
Training loss: 0.21197800616447338
Validation loss: 2.276828871245838

Epoch: 6| Step: 1
Training loss: 0.30455539969706996
Validation loss: 2.3083193164588076

Epoch: 6| Step: 2
Training loss: 0.30575328658108414
Validation loss: 2.2276615754112656

Epoch: 6| Step: 3
Training loss: 0.4018829076769117
Validation loss: 2.2705581976656344

Epoch: 6| Step: 4
Training loss: 0.23386100994085818
Validation loss: 2.3276923799618197

Epoch: 6| Step: 5
Training loss: 0.22134973110167994
Validation loss: 2.295276544097569

Epoch: 6| Step: 6
Training loss: 0.31450913208892345
Validation loss: 2.2892378218064686

Epoch: 6| Step: 7
Training loss: 0.29667736050042887
Validation loss: 2.2695966088518515

Epoch: 6| Step: 8
Training loss: 0.4323183840419744
Validation loss: 2.32976368490223

Epoch: 6| Step: 9
Training loss: 0.3983023358132639
Validation loss: 2.3156538240369384

Epoch: 6| Step: 10
Training loss: 0.3784745500164405
Validation loss: 2.2953973112630743

Epoch: 6| Step: 11
Training loss: 0.3515428961480315
Validation loss: 2.30684470389085

Epoch: 6| Step: 12
Training loss: 0.2925831864330459
Validation loss: 2.2789503202905714

Epoch: 6| Step: 13
Training loss: 0.40180789114284304
Validation loss: 2.293424198250496

Epoch: 410| Step: 0
Training loss: 0.27890424540678205
Validation loss: 2.2922345295948205

Epoch: 6| Step: 1
Training loss: 0.24026283622800734
Validation loss: 2.292082927930119

Epoch: 6| Step: 2
Training loss: 0.22682960977033553
Validation loss: 2.295297985234427

Epoch: 6| Step: 3
Training loss: 0.23145121957186082
Validation loss: 2.3044511059577193

Epoch: 6| Step: 4
Training loss: 0.26708724946430595
Validation loss: 2.230227268595329

Epoch: 6| Step: 5
Training loss: 0.196671639725746
Validation loss: 2.294069518755089

Epoch: 6| Step: 6
Training loss: 0.4397681569378766
Validation loss: 2.318847202138454

Epoch: 6| Step: 7
Training loss: 0.25401922793524906
Validation loss: 2.278723114156391

Epoch: 6| Step: 8
Training loss: 0.2323296708649423
Validation loss: 2.317507160042652

Epoch: 6| Step: 9
Training loss: 0.2789548500309831
Validation loss: 2.2608986851880513

Epoch: 6| Step: 10
Training loss: 0.26954026138058057
Validation loss: 2.248149543580862

Epoch: 6| Step: 11
Training loss: 0.2754619722403428
Validation loss: 2.298593202836832

Epoch: 6| Step: 12
Training loss: 0.37508735036757684
Validation loss: 2.2835694718829447

Epoch: 6| Step: 13
Training loss: 0.26341444093326477
Validation loss: 2.296475442746886

Epoch: 411| Step: 0
Training loss: 0.12304861582175537
Validation loss: 2.33581102043688

Epoch: 6| Step: 1
Training loss: 0.2574687457792474
Validation loss: 2.295730859462259

Epoch: 6| Step: 2
Training loss: 0.2850912098326622
Validation loss: 2.3154381481430635

Epoch: 6| Step: 3
Training loss: 0.27774172423091437
Validation loss: 2.2891995993255296

Epoch: 6| Step: 4
Training loss: 0.3362408975695089
Validation loss: 2.3219387379416823

Epoch: 6| Step: 5
Training loss: 0.2211232027581357
Validation loss: 2.3934086900746845

Epoch: 6| Step: 6
Training loss: 0.3171949799130191
Validation loss: 2.27416686847705

Epoch: 6| Step: 7
Training loss: 0.2572757885289658
Validation loss: 2.3156652267744073

Epoch: 6| Step: 8
Training loss: 0.333254401229418
Validation loss: 2.2934094275789563

Epoch: 6| Step: 9
Training loss: 0.28100222693779264
Validation loss: 2.2850829892492186

Epoch: 6| Step: 10
Training loss: 0.2676434263196012
Validation loss: 2.302737731327181

Epoch: 6| Step: 11
Training loss: 0.33019105683547767
Validation loss: 2.3056881558792517

Epoch: 6| Step: 12
Training loss: 0.2662873425063725
Validation loss: 2.342449556484076

Epoch: 6| Step: 13
Training loss: 0.25324662430180706
Validation loss: 2.2178584174500693

Epoch: 412| Step: 0
Training loss: 0.2949867556112342
Validation loss: 2.3137753724270396

Epoch: 6| Step: 1
Training loss: 0.3594901688177203
Validation loss: 2.264560712568581

Epoch: 6| Step: 2
Training loss: 0.28030049794847267
Validation loss: 2.2926220000767907

Epoch: 6| Step: 3
Training loss: 0.25756067924439124
Validation loss: 2.306961196643632

Epoch: 6| Step: 4
Training loss: 0.2585151806548269
Validation loss: 2.335858499983636

Epoch: 6| Step: 5
Training loss: 0.24136059091607082
Validation loss: 2.2636968717163146

Epoch: 6| Step: 6
Training loss: 0.3022920145330305
Validation loss: 2.274389873685578

Epoch: 6| Step: 7
Training loss: 0.3302264585644869
Validation loss: 2.335819917609232

Epoch: 6| Step: 8
Training loss: 0.23428926489244187
Validation loss: 2.239523533458914

Epoch: 6| Step: 9
Training loss: 0.20437789535804698
Validation loss: 2.2937544213719248

Epoch: 6| Step: 10
Training loss: 0.3034067255594572
Validation loss: 2.268832871295816

Epoch: 6| Step: 11
Training loss: 0.34737833037123467
Validation loss: 2.3097585374239666

Epoch: 6| Step: 12
Training loss: 0.22659145367529018
Validation loss: 2.2833268105165447

Epoch: 6| Step: 13
Training loss: 0.29833255140816567
Validation loss: 2.2901283187118966

Epoch: 413| Step: 0
Training loss: 0.23508698086397553
Validation loss: 2.241923814037762

Epoch: 6| Step: 1
Training loss: 0.2886359315002322
Validation loss: 2.2657956201609615

Epoch: 6| Step: 2
Training loss: 0.22610786467746266
Validation loss: 2.2789522557175097

Epoch: 6| Step: 3
Training loss: 0.2981940379868215
Validation loss: 2.338326158909068

Epoch: 6| Step: 4
Training loss: 0.3084501705060065
Validation loss: 2.3186592351623623

Epoch: 6| Step: 5
Training loss: 0.3208194535626077
Validation loss: 2.2784011767606027

Epoch: 6| Step: 6
Training loss: 0.261970527018568
Validation loss: 2.337307633424963

Epoch: 6| Step: 7
Training loss: 0.3342358607174045
Validation loss: 2.275753113520002

Epoch: 6| Step: 8
Training loss: 0.26681568643539727
Validation loss: 2.3138749270903927

Epoch: 6| Step: 9
Training loss: 0.3206890498056769
Validation loss: 2.3419938183612503

Epoch: 6| Step: 10
Training loss: 0.2768038074121645
Validation loss: 2.2721815627402675

Epoch: 6| Step: 11
Training loss: 0.2888919610780703
Validation loss: 2.318198211561526

Epoch: 6| Step: 12
Training loss: 0.24447213363256362
Validation loss: 2.253871650804877

Epoch: 6| Step: 13
Training loss: 0.15206927246474974
Validation loss: 2.2921581666019053

Epoch: 414| Step: 0
Training loss: 0.30621816605917995
Validation loss: 2.286992270677474

Epoch: 6| Step: 1
Training loss: 0.279659835683317
Validation loss: 2.272326360656656

Epoch: 6| Step: 2
Training loss: 0.3161515753327758
Validation loss: 2.267605847373516

Epoch: 6| Step: 3
Training loss: 0.3485507173877492
Validation loss: 2.283666750193186

Epoch: 6| Step: 4
Training loss: 0.24549397541100765
Validation loss: 2.2902755907967314

Epoch: 6| Step: 5
Training loss: 0.2536937411194455
Validation loss: 2.281187074045952

Epoch: 6| Step: 6
Training loss: 0.28787715264400465
Validation loss: 2.3060449428077296

Epoch: 6| Step: 7
Training loss: 0.3287219906431523
Validation loss: 2.252737781479528

Epoch: 6| Step: 8
Training loss: 0.31700393363545726
Validation loss: 2.3204373926529556

Epoch: 6| Step: 9
Training loss: 0.24993277182259888
Validation loss: 2.2935788471004477

Epoch: 6| Step: 10
Training loss: 0.23257963452347444
Validation loss: 2.315870269127603

Epoch: 6| Step: 11
Training loss: 0.19865254742044944
Validation loss: 2.257148777115838

Epoch: 6| Step: 12
Training loss: 0.24814036252101768
Validation loss: 2.2376350415358606

Epoch: 6| Step: 13
Training loss: 0.2254333558062569
Validation loss: 2.2405038464794185

Epoch: 415| Step: 0
Training loss: 0.27907201077955895
Validation loss: 2.22642804905474

Epoch: 6| Step: 1
Training loss: 0.20321838359749872
Validation loss: 2.3210442927126858

Epoch: 6| Step: 2
Training loss: 0.33440688106034216
Validation loss: 2.292871701701218

Epoch: 6| Step: 3
Training loss: 0.32457024697663395
Validation loss: 2.280714346648858

Epoch: 6| Step: 4
Training loss: 0.1796210414885652
Validation loss: 2.2805423684177093

Epoch: 6| Step: 5
Training loss: 0.16845472583022492
Validation loss: 2.275569244053746

Epoch: 6| Step: 6
Training loss: 0.2329325155406044
Validation loss: 2.2896636763670855

Epoch: 6| Step: 7
Training loss: 0.21832379476050112
Validation loss: 2.321078566830354

Epoch: 6| Step: 8
Training loss: 0.21652910518643778
Validation loss: 2.2789775904789127

Epoch: 6| Step: 9
Training loss: 0.379824557900308
Validation loss: 2.2610052605215856

Epoch: 6| Step: 10
Training loss: 0.2592750161276612
Validation loss: 2.284656037361094

Epoch: 6| Step: 11
Training loss: 0.18875369515180926
Validation loss: 2.264780365047189

Epoch: 6| Step: 12
Training loss: 0.2372824733054003
Validation loss: 2.258175777790349

Epoch: 6| Step: 13
Training loss: 0.40226007721098633
Validation loss: 2.292999787258666

Epoch: 416| Step: 0
Training loss: 0.25453753122315376
Validation loss: 2.2537849962222376

Epoch: 6| Step: 1
Training loss: 0.200444183107944
Validation loss: 2.2953698033606016

Epoch: 6| Step: 2
Training loss: 0.2822413325157291
Validation loss: 2.2841538537478034

Epoch: 6| Step: 3
Training loss: 0.2938068355200094
Validation loss: 2.3051714545286566

Epoch: 6| Step: 4
Training loss: 0.18633293489529873
Validation loss: 2.2987204510005

Epoch: 6| Step: 5
Training loss: 0.26565533352603926
Validation loss: 2.2636247245435497

Epoch: 6| Step: 6
Training loss: 0.27140164658546634
Validation loss: 2.270491816419907

Epoch: 6| Step: 7
Training loss: 0.3360603684465413
Validation loss: 2.263922874088979

Epoch: 6| Step: 8
Training loss: 0.30119896654322814
Validation loss: 2.306767773764373

Epoch: 6| Step: 9
Training loss: 0.21742504631577983
Validation loss: 2.2692045413258453

Epoch: 6| Step: 10
Training loss: 0.3129705462735107
Validation loss: 2.2821887014108073

Epoch: 6| Step: 11
Training loss: 0.35292806324165465
Validation loss: 2.287597630194437

Epoch: 6| Step: 12
Training loss: 0.28328885063499476
Validation loss: 2.31259709231715

Epoch: 6| Step: 13
Training loss: 0.3632777019040337
Validation loss: 2.277446641991359

Epoch: 417| Step: 0
Training loss: 0.20618102191786505
Validation loss: 2.2896566650569072

Epoch: 6| Step: 1
Training loss: 0.21131146800734976
Validation loss: 2.2446676619783097

Epoch: 6| Step: 2
Training loss: 0.2712038498174458
Validation loss: 2.2937869811303444

Epoch: 6| Step: 3
Training loss: 0.3290014029657023
Validation loss: 2.2350830343469155

Epoch: 6| Step: 4
Training loss: 0.2128222994571768
Validation loss: 2.272517215746082

Epoch: 6| Step: 5
Training loss: 0.2253205029974967
Validation loss: 2.284376284089708

Epoch: 6| Step: 6
Training loss: 0.1715140508204349
Validation loss: 2.280707778243811

Epoch: 6| Step: 7
Training loss: 0.24036641097829087
Validation loss: 2.264176302362727

Epoch: 6| Step: 8
Training loss: 0.27166157709417005
Validation loss: 2.26568220219803

Epoch: 6| Step: 9
Training loss: 0.31900976012285626
Validation loss: 2.2942283848715626

Epoch: 6| Step: 10
Training loss: 0.2646949136049321
Validation loss: 2.2819290805169676

Epoch: 6| Step: 11
Training loss: 0.2518095598094149
Validation loss: 2.25705189636583

Epoch: 6| Step: 12
Training loss: 0.23930765528095044
Validation loss: 2.2793112925705734

Epoch: 6| Step: 13
Training loss: 0.25283861914192907
Validation loss: 2.3200803527125973

Epoch: 418| Step: 0
Training loss: 0.2554681276319663
Validation loss: 2.315402717921297

Epoch: 6| Step: 1
Training loss: 0.2807150362430095
Validation loss: 2.294538628792861

Epoch: 6| Step: 2
Training loss: 0.28716015528855493
Validation loss: 2.232095244490224

Epoch: 6| Step: 3
Training loss: 0.2200521472878147
Validation loss: 2.295281945517088

Epoch: 6| Step: 4
Training loss: 0.24888804625991068
Validation loss: 2.2885057642439537

Epoch: 6| Step: 5
Training loss: 0.2766739722995521
Validation loss: 2.310795396309294

Epoch: 6| Step: 6
Training loss: 0.2200796638600177
Validation loss: 2.276602020653729

Epoch: 6| Step: 7
Training loss: 0.24794258718798487
Validation loss: 2.2486805402522094

Epoch: 6| Step: 8
Training loss: 0.2730230733077809
Validation loss: 2.2547756834314563

Epoch: 6| Step: 9
Training loss: 0.2711239762179162
Validation loss: 2.3060669989203526

Epoch: 6| Step: 10
Training loss: 0.24634217030765032
Validation loss: 2.282633836366221

Epoch: 6| Step: 11
Training loss: 0.267756924443504
Validation loss: 2.28965007024061

Epoch: 6| Step: 12
Training loss: 0.3712563409488553
Validation loss: 2.3128257384580886

Epoch: 6| Step: 13
Training loss: 0.24333425487110835
Validation loss: 2.27769228502137

Epoch: 419| Step: 0
Training loss: 0.21842545036786
Validation loss: 2.2629643306255747

Epoch: 6| Step: 1
Training loss: 0.2963268590367553
Validation loss: 2.3079284294486597

Epoch: 6| Step: 2
Training loss: 0.3609111132203684
Validation loss: 2.300590312917007

Epoch: 6| Step: 3
Training loss: 0.2019423018899651
Validation loss: 2.312528128925426

Epoch: 6| Step: 4
Training loss: 0.33793969432004806
Validation loss: 2.2749218109863425

Epoch: 6| Step: 5
Training loss: 0.2203944588117801
Validation loss: 2.2789855238803587

Epoch: 6| Step: 6
Training loss: 0.2822242393530034
Validation loss: 2.250920248809778

Epoch: 6| Step: 7
Training loss: 0.3912787879005405
Validation loss: 2.3033837461636217

Epoch: 6| Step: 8
Training loss: 0.28696545737187834
Validation loss: 2.3052344928491957

Epoch: 6| Step: 9
Training loss: 0.34473319763195553
Validation loss: 2.3601658655598117

Epoch: 6| Step: 10
Training loss: 0.29450472957702484
Validation loss: 2.2727996700488933

Epoch: 6| Step: 11
Training loss: 0.37327217368855264
Validation loss: 2.33355286678077

Epoch: 6| Step: 12
Training loss: 0.22250307402469624
Validation loss: 2.31797597532793

Epoch: 6| Step: 13
Training loss: 0.34906987167948345
Validation loss: 2.2716527533670696

Epoch: 420| Step: 0
Training loss: 0.3170906600260236
Validation loss: 2.3055955208017243

Epoch: 6| Step: 1
Training loss: 0.21102689685396084
Validation loss: 2.2420884663224694

Epoch: 6| Step: 2
Training loss: 0.4850043084995379
Validation loss: 2.2857056047070365

Epoch: 6| Step: 3
Training loss: 0.19825985082851813
Validation loss: 2.2954632319432804

Epoch: 6| Step: 4
Training loss: 0.2693435734253555
Validation loss: 2.2633793718415136

Epoch: 6| Step: 5
Training loss: 0.240064623025069
Validation loss: 2.2794019799622665

Epoch: 6| Step: 6
Training loss: 0.3060600470175274
Validation loss: 2.307586889273894

Epoch: 6| Step: 7
Training loss: 0.19373728687354153
Validation loss: 2.3063489539498705

Epoch: 6| Step: 8
Training loss: 0.1937809884762118
Validation loss: 2.2808376009167945

Epoch: 6| Step: 9
Training loss: 0.3637077535105405
Validation loss: 2.2878012800972822

Epoch: 6| Step: 10
Training loss: 0.41664069412662913
Validation loss: 2.3188413158165933

Epoch: 6| Step: 11
Training loss: 0.2929131645876869
Validation loss: 2.3069076017509804

Epoch: 6| Step: 12
Training loss: 0.23599830185048906
Validation loss: 2.308908594891007

Epoch: 6| Step: 13
Training loss: 0.24989712356773883
Validation loss: 2.321961712662024

Epoch: 421| Step: 0
Training loss: 0.31094569861563304
Validation loss: 2.286099100821697

Epoch: 6| Step: 1
Training loss: 0.32731096016982547
Validation loss: 2.3133062297550655

Epoch: 6| Step: 2
Training loss: 0.22734039867854286
Validation loss: 2.2952558558507454

Epoch: 6| Step: 3
Training loss: 0.28810203636575893
Validation loss: 2.343944727967475

Epoch: 6| Step: 4
Training loss: 0.29904195826585644
Validation loss: 2.2982077505570864

Epoch: 6| Step: 5
Training loss: 0.24815547998527693
Validation loss: 2.2858023314321243

Epoch: 6| Step: 6
Training loss: 0.19075368071238433
Validation loss: 2.3061450896484557

Epoch: 6| Step: 7
Training loss: 0.29120156409300746
Validation loss: 2.3476939438995483

Epoch: 6| Step: 8
Training loss: 0.28150069137322337
Validation loss: 2.278024431057439

Epoch: 6| Step: 9
Training loss: 0.30803547833514605
Validation loss: 2.2704209527796473

Epoch: 6| Step: 10
Training loss: 0.3406916378177954
Validation loss: 2.3177376791707105

Epoch: 6| Step: 11
Training loss: 0.2586117983048739
Validation loss: 2.3435336203827974

Epoch: 6| Step: 12
Training loss: 0.22738919213616213
Validation loss: 2.3009617059530942

Epoch: 6| Step: 13
Training loss: 0.2785884970502974
Validation loss: 2.2252655981608793

Epoch: 422| Step: 0
Training loss: 0.2844217455873665
Validation loss: 2.2819485052218003

Epoch: 6| Step: 1
Training loss: 0.25597624984947986
Validation loss: 2.315536618830534

Epoch: 6| Step: 2
Training loss: 0.33867345103388835
Validation loss: 2.276780195612412

Epoch: 6| Step: 3
Training loss: 0.27195765729599714
Validation loss: 2.2634431264265706

Epoch: 6| Step: 4
Training loss: 0.2100656026737625
Validation loss: 2.274198922398793

Epoch: 6| Step: 5
Training loss: 0.28950793510558154
Validation loss: 2.2838342477994793

Epoch: 6| Step: 6
Training loss: 0.2485591824353081
Validation loss: 2.2857545857268593

Epoch: 6| Step: 7
Training loss: 0.18190223558744503
Validation loss: 2.292812439563798

Epoch: 6| Step: 8
Training loss: 0.3814459953555916
Validation loss: 2.2392264562342046

Epoch: 6| Step: 9
Training loss: 0.27917918146369647
Validation loss: 2.2696203235123464

Epoch: 6| Step: 10
Training loss: 0.29797163247293035
Validation loss: 2.2604091720339614

Epoch: 6| Step: 11
Training loss: 0.24791960567580873
Validation loss: 2.2772988325327397

Epoch: 6| Step: 12
Training loss: 0.30339599421757374
Validation loss: 2.2599834489919632

Epoch: 6| Step: 13
Training loss: 0.2774480972637956
Validation loss: 2.2512758664218384

Epoch: 423| Step: 0
Training loss: 0.33140227263715405
Validation loss: 2.2767872116696575

Epoch: 6| Step: 1
Training loss: 0.30660940120657837
Validation loss: 2.3054149277119365

Epoch: 6| Step: 2
Training loss: 0.280985482651159
Validation loss: 2.2614584659369625

Epoch: 6| Step: 3
Training loss: 0.2429162566708812
Validation loss: 2.3431218131942426

Epoch: 6| Step: 4
Training loss: 0.3223418405747177
Validation loss: 2.297392287360059

Epoch: 6| Step: 5
Training loss: 0.24132546705892147
Validation loss: 2.2826240790778733

Epoch: 6| Step: 6
Training loss: 0.3602353247102799
Validation loss: 2.301238035702413

Epoch: 6| Step: 7
Training loss: 0.2318191406541262
Validation loss: 2.292910235566535

Epoch: 6| Step: 8
Training loss: 0.2718116379489767
Validation loss: 2.331788059421213

Epoch: 6| Step: 9
Training loss: 0.22319507652461718
Validation loss: 2.269486147267697

Epoch: 6| Step: 10
Training loss: 0.331177241503949
Validation loss: 2.3002361867405816

Epoch: 6| Step: 11
Training loss: 0.2473834921452402
Validation loss: 2.2557417757722247

Epoch: 6| Step: 12
Training loss: 0.28545092681050077
Validation loss: 2.2743359130955816

Epoch: 6| Step: 13
Training loss: 0.34516093738320863
Validation loss: 2.3362033314242256

Epoch: 424| Step: 0
Training loss: 0.26841880828741677
Validation loss: 2.306004009205293

Epoch: 6| Step: 1
Training loss: 0.21304991651041902
Validation loss: 2.2778391138466163

Epoch: 6| Step: 2
Training loss: 0.32725782700657696
Validation loss: 2.263751331654042

Epoch: 6| Step: 3
Training loss: 0.2535040384004791
Validation loss: 2.2511457422414227

Epoch: 6| Step: 4
Training loss: 0.3550029049673903
Validation loss: 2.283509376682035

Epoch: 6| Step: 5
Training loss: 0.4568221763309384
Validation loss: 2.315338617789274

Epoch: 6| Step: 6
Training loss: 0.2735911346432543
Validation loss: 2.2836936856602996

Epoch: 6| Step: 7
Training loss: 0.3644487632171542
Validation loss: 2.3211423543752105

Epoch: 6| Step: 8
Training loss: 0.267775024587434
Validation loss: 2.258735476885016

Epoch: 6| Step: 9
Training loss: 0.22652539409773254
Validation loss: 2.279230852867932

Epoch: 6| Step: 10
Training loss: 0.23445999670588297
Validation loss: 2.2634483492546167

Epoch: 6| Step: 11
Training loss: 0.309591009850051
Validation loss: 2.269638426674438

Epoch: 6| Step: 12
Training loss: 0.3583301198430833
Validation loss: 2.319625059076518

Epoch: 6| Step: 13
Training loss: 0.36750453086577184
Validation loss: 2.305971492708579

Epoch: 425| Step: 0
Training loss: 0.26369327882147464
Validation loss: 2.2743399839893383

Epoch: 6| Step: 1
Training loss: 0.2878449935670867
Validation loss: 2.2728291120253834

Epoch: 6| Step: 2
Training loss: 0.446736601759369
Validation loss: 2.3090786583313103

Epoch: 6| Step: 3
Training loss: 0.3693177136504934
Validation loss: 2.2690532485163186

Epoch: 6| Step: 4
Training loss: 0.17365548315182663
Validation loss: 2.3167545513480086

Epoch: 6| Step: 5
Training loss: 0.19446551732890927
Validation loss: 2.282166501583754

Epoch: 6| Step: 6
Training loss: 0.23180752188797923
Validation loss: 2.2849781629936574

Epoch: 6| Step: 7
Training loss: 0.1911512057530778
Validation loss: 2.248231183717945

Epoch: 6| Step: 8
Training loss: 0.42189184790983925
Validation loss: 2.252900320588429

Epoch: 6| Step: 9
Training loss: 0.302039783177656
Validation loss: 2.2958750288881573

Epoch: 6| Step: 10
Training loss: 0.3248026198036319
Validation loss: 2.275326349444792

Epoch: 6| Step: 11
Training loss: 0.20648934860965376
Validation loss: 2.2967619230155303

Epoch: 6| Step: 12
Training loss: 0.30584535919854355
Validation loss: 2.3055822327486273

Epoch: 6| Step: 13
Training loss: 0.27560876093491693
Validation loss: 2.2647794614599905

Epoch: 426| Step: 0
Training loss: 0.3558209529363799
Validation loss: 2.2595670190224904

Epoch: 6| Step: 1
Training loss: 0.3801979777698225
Validation loss: 2.265887313214746

Epoch: 6| Step: 2
Training loss: 0.22024114751940685
Validation loss: 2.266850405379872

Epoch: 6| Step: 3
Training loss: 0.24400336412451876
Validation loss: 2.24246369188246

Epoch: 6| Step: 4
Training loss: 0.327335247393688
Validation loss: 2.2817521261182527

Epoch: 6| Step: 5
Training loss: 0.2888496491612804
Validation loss: 2.2423882743450623

Epoch: 6| Step: 6
Training loss: 0.40610670350137495
Validation loss: 2.268880097413391

Epoch: 6| Step: 7
Training loss: 0.41228434387355417
Validation loss: 2.2407355663875017

Epoch: 6| Step: 8
Training loss: 0.27078698140642204
Validation loss: 2.221495420758157

Epoch: 6| Step: 9
Training loss: 0.23517689218251597
Validation loss: 2.2288853090454435

Epoch: 6| Step: 10
Training loss: 0.3620777910567072
Validation loss: 2.270420462729485

Epoch: 6| Step: 11
Training loss: 0.21068382904670485
Validation loss: 2.275775917187532

Epoch: 6| Step: 12
Training loss: 0.4076908675584978
Validation loss: 2.281817491918241

Epoch: 6| Step: 13
Training loss: 0.3293656554516175
Validation loss: 2.2797360556897943

Epoch: 427| Step: 0
Training loss: 0.4362514254265263
Validation loss: 2.237358528864709

Epoch: 6| Step: 1
Training loss: 0.3282541974344794
Validation loss: 2.295634023134726

Epoch: 6| Step: 2
Training loss: 0.24411589688001334
Validation loss: 2.2233547460686856

Epoch: 6| Step: 3
Training loss: 0.34945192467739
Validation loss: 2.2785737264214156

Epoch: 6| Step: 4
Training loss: 0.4399187122380995
Validation loss: 2.2856779453959337

Epoch: 6| Step: 5
Training loss: 0.4275148255025046
Validation loss: 2.2821120022689874

Epoch: 6| Step: 6
Training loss: 0.37918556379380675
Validation loss: 2.260973054702528

Epoch: 6| Step: 7
Training loss: 0.2838860269334025
Validation loss: 2.2731062133197333

Epoch: 6| Step: 8
Training loss: 0.279939033308214
Validation loss: 2.2685425662656873

Epoch: 6| Step: 9
Training loss: 0.30388454859900355
Validation loss: 2.2561714253784606

Epoch: 6| Step: 10
Training loss: 0.49606087342906735
Validation loss: 2.240555602470488

Epoch: 6| Step: 11
Training loss: 0.245139611119013
Validation loss: 2.2955439943138587

Epoch: 6| Step: 12
Training loss: 0.29888480403156975
Validation loss: 2.2763090056680086

Epoch: 6| Step: 13
Training loss: 0.32713947568546603
Validation loss: 2.300648554293003

Epoch: 428| Step: 0
Training loss: 0.24296843077954483
Validation loss: 2.2369494156789003

Epoch: 6| Step: 1
Training loss: 0.21218129198097016
Validation loss: 2.2335192413195832

Epoch: 6| Step: 2
Training loss: 0.3126378708927394
Validation loss: 2.2942074360280875

Epoch: 6| Step: 3
Training loss: 0.3801212494115378
Validation loss: 2.2728929249764493

Epoch: 6| Step: 4
Training loss: 0.3088721214895147
Validation loss: 2.2967720441168997

Epoch: 6| Step: 5
Training loss: 0.24857500877203872
Validation loss: 2.2785904069244824

Epoch: 6| Step: 6
Training loss: 0.2539371765082081
Validation loss: 2.2914003361927935

Epoch: 6| Step: 7
Training loss: 0.34782066100863457
Validation loss: 2.2395956231304934

Epoch: 6| Step: 8
Training loss: 0.2014614077195069
Validation loss: 2.277949859417311

Epoch: 6| Step: 9
Training loss: 0.2684603022393102
Validation loss: 2.288413796710813

Epoch: 6| Step: 10
Training loss: 0.39300335680520504
Validation loss: 2.349990319171201

Epoch: 6| Step: 11
Training loss: 0.2225705534000975
Validation loss: 2.287539204190302

Epoch: 6| Step: 12
Training loss: 0.2744673544835113
Validation loss: 2.2878960424672465

Epoch: 6| Step: 13
Training loss: 0.2354962232797131
Validation loss: 2.300958062088307

Epoch: 429| Step: 0
Training loss: 0.33590401992746066
Validation loss: 2.2796363348967996

Epoch: 6| Step: 1
Training loss: 0.311887426797677
Validation loss: 2.29297847193358

Epoch: 6| Step: 2
Training loss: 0.2544785725017601
Validation loss: 2.2948209266915494

Epoch: 6| Step: 3
Training loss: 0.28403972836613206
Validation loss: 2.247127553781872

Epoch: 6| Step: 4
Training loss: 0.20721303408486544
Validation loss: 2.284219316081973

Epoch: 6| Step: 5
Training loss: 0.24845953279838295
Validation loss: 2.273626645184721

Epoch: 6| Step: 6
Training loss: 0.3271179184983477
Validation loss: 2.2759761029772805

Epoch: 6| Step: 7
Training loss: 0.33841721619241477
Validation loss: 2.292877732679485

Epoch: 6| Step: 8
Training loss: 0.3186501421371567
Validation loss: 2.247539746983585

Epoch: 6| Step: 9
Training loss: 0.2780227140865883
Validation loss: 2.2852173712835087

Epoch: 6| Step: 10
Training loss: 0.19798397291707276
Validation loss: 2.3258556767092875

Epoch: 6| Step: 11
Training loss: 0.39437205813802373
Validation loss: 2.264364747064486

Epoch: 6| Step: 12
Training loss: 0.2935381378970675
Validation loss: 2.296493991728501

Epoch: 6| Step: 13
Training loss: 0.2858836680950876
Validation loss: 2.285050870633798

Epoch: 430| Step: 0
Training loss: 0.21082902697706166
Validation loss: 2.30903070556404

Epoch: 6| Step: 1
Training loss: 0.2116284445281209
Validation loss: 2.227571716024663

Epoch: 6| Step: 2
Training loss: 0.17608196180162725
Validation loss: 2.245910566295934

Epoch: 6| Step: 3
Training loss: 0.3088077334430068
Validation loss: 2.2352067870785

Epoch: 6| Step: 4
Training loss: 0.25841219830076284
Validation loss: 2.2154798631429493

Epoch: 6| Step: 5
Training loss: 0.41101340691541327
Validation loss: 2.2612016138256483

Epoch: 6| Step: 6
Training loss: 0.329399585204451
Validation loss: 2.2267718121930855

Epoch: 6| Step: 7
Training loss: 0.2608872485171085
Validation loss: 2.289981627133779

Epoch: 6| Step: 8
Training loss: 0.46745289310225535
Validation loss: 2.3009413365022056

Epoch: 6| Step: 9
Training loss: 0.31733487280671235
Validation loss: 2.2437510781741583

Epoch: 6| Step: 10
Training loss: 0.2741156479335674
Validation loss: 2.2624870229668557

Epoch: 6| Step: 11
Training loss: 0.3171898475334602
Validation loss: 2.2685149254053196

Epoch: 6| Step: 12
Training loss: 0.35485308642851826
Validation loss: 2.265968314281225

Epoch: 6| Step: 13
Training loss: 0.1875623758195506
Validation loss: 2.2517130123520004

Epoch: 431| Step: 0
Training loss: 0.2036872016047738
Validation loss: 2.2885128832607173

Epoch: 6| Step: 1
Training loss: 0.24991975927098314
Validation loss: 2.2686802400595276

Epoch: 6| Step: 2
Training loss: 0.33599256463424054
Validation loss: 2.2820404721197467

Epoch: 6| Step: 3
Training loss: 0.28206738269585496
Validation loss: 2.287946235754202

Epoch: 6| Step: 4
Training loss: 0.2769231293095688
Validation loss: 2.2993011895350834

Epoch: 6| Step: 5
Training loss: 0.3496464331395456
Validation loss: 2.2865633292338092

Epoch: 6| Step: 6
Training loss: 0.1726198313351553
Validation loss: 2.2894535620315324

Epoch: 6| Step: 7
Training loss: 0.2732483073074809
Validation loss: 2.312965518044038

Epoch: 6| Step: 8
Training loss: 0.31927772014630973
Validation loss: 2.293164575761541

Epoch: 6| Step: 9
Training loss: 0.2884933952322585
Validation loss: 2.304581401559529

Epoch: 6| Step: 10
Training loss: 0.2668935832269541
Validation loss: 2.2364345386401907

Epoch: 6| Step: 11
Training loss: 0.426555227560014
Validation loss: 2.288833545956562

Epoch: 6| Step: 12
Training loss: 0.48506165102783744
Validation loss: 2.3286743710642797

Epoch: 6| Step: 13
Training loss: 0.20144423778366347
Validation loss: 2.2987610907924068

Epoch: 432| Step: 0
Training loss: 0.32953661453489275
Validation loss: 2.2543675189224177

Epoch: 6| Step: 1
Training loss: 0.2479488374302243
Validation loss: 2.2966467642325474

Epoch: 6| Step: 2
Training loss: 0.253422437565969
Validation loss: 2.2750945808675973

Epoch: 6| Step: 3
Training loss: 0.37327890020934656
Validation loss: 2.3342217701058816

Epoch: 6| Step: 4
Training loss: 0.31375818882092765
Validation loss: 2.293798431938457

Epoch: 6| Step: 5
Training loss: 0.37901811816357206
Validation loss: 2.3285473946008888

Epoch: 6| Step: 6
Training loss: 0.229651586488617
Validation loss: 2.300748607876734

Epoch: 6| Step: 7
Training loss: 0.21353233809370453
Validation loss: 2.266363448894157

Epoch: 6| Step: 8
Training loss: 0.2356124713840211
Validation loss: 2.2829930165568753

Epoch: 6| Step: 9
Training loss: 0.3500463003800817
Validation loss: 2.287349906541508

Epoch: 6| Step: 10
Training loss: 0.2949703505131433
Validation loss: 2.2972432920367893

Epoch: 6| Step: 11
Training loss: 0.32727639272336806
Validation loss: 2.3353434629194303

Epoch: 6| Step: 12
Training loss: 0.136297681081676
Validation loss: 2.276007066430227

Epoch: 6| Step: 13
Training loss: 0.23693975795141897
Validation loss: 2.291334428690224

Epoch: 433| Step: 0
Training loss: 0.20478940349025554
Validation loss: 2.2509626960465208

Epoch: 6| Step: 1
Training loss: 0.19806104756042717
Validation loss: 2.3440326604998036

Epoch: 6| Step: 2
Training loss: 0.17009081061194226
Validation loss: 2.279430186108558

Epoch: 6| Step: 3
Training loss: 0.34994137307020146
Validation loss: 2.329508189194398

Epoch: 6| Step: 4
Training loss: 0.2716674187616652
Validation loss: 2.3295515328191954

Epoch: 6| Step: 5
Training loss: 0.19220431029451474
Validation loss: 2.294166204612049

Epoch: 6| Step: 6
Training loss: 0.22081308242025693
Validation loss: 2.242743543911613

Epoch: 6| Step: 7
Training loss: 0.32084680978949526
Validation loss: 2.2936958490228396

Epoch: 6| Step: 8
Training loss: 0.3287112357851648
Validation loss: 2.300580476335043

Epoch: 6| Step: 9
Training loss: 0.3404392199513993
Validation loss: 2.2944786910004633

Epoch: 6| Step: 10
Training loss: 0.3002256984881407
Validation loss: 2.2657800730985502

Epoch: 6| Step: 11
Training loss: 0.28822605152512387
Validation loss: 2.2810105672800853

Epoch: 6| Step: 12
Training loss: 0.18722003658771413
Validation loss: 2.282607889372721

Epoch: 6| Step: 13
Training loss: 0.2504722634709804
Validation loss: 2.334451668538657

Epoch: 434| Step: 0
Training loss: 0.14867501956623014
Validation loss: 2.3222177648678985

Epoch: 6| Step: 1
Training loss: 0.3446426721786974
Validation loss: 2.2701449677870977

Epoch: 6| Step: 2
Training loss: 0.2553144869966356
Validation loss: 2.2966486674444564

Epoch: 6| Step: 3
Training loss: 0.2091167066631774
Validation loss: 2.267947267401477

Epoch: 6| Step: 4
Training loss: 0.32697355236197045
Validation loss: 2.2837362458347834

Epoch: 6| Step: 5
Training loss: 0.3522839032285329
Validation loss: 2.2925693612541354

Epoch: 6| Step: 6
Training loss: 0.21069901725094475
Validation loss: 2.3205640423165206

Epoch: 6| Step: 7
Training loss: 0.401429016103217
Validation loss: 2.292169868247139

Epoch: 6| Step: 8
Training loss: 0.44063233579115857
Validation loss: 2.2609967543634792

Epoch: 6| Step: 9
Training loss: 0.2559031237989962
Validation loss: 2.2853750966364914

Epoch: 6| Step: 10
Training loss: 0.30698047926749106
Validation loss: 2.343497004099638

Epoch: 6| Step: 11
Training loss: 0.2533502800715005
Validation loss: 2.269003057597445

Epoch: 6| Step: 12
Training loss: 0.3412198018067345
Validation loss: 2.2674452211267524

Epoch: 6| Step: 13
Training loss: 0.3128168407219045
Validation loss: 2.2649746103807553

Epoch: 435| Step: 0
Training loss: 0.34030489491844107
Validation loss: 2.2251939103284974

Epoch: 6| Step: 1
Training loss: 0.3621302387765866
Validation loss: 2.285200469629805

Epoch: 6| Step: 2
Training loss: 0.22486847569902088
Validation loss: 2.2271949806692577

Epoch: 6| Step: 3
Training loss: 0.32547703130389827
Validation loss: 2.2747052689955467

Epoch: 6| Step: 4
Training loss: 0.2929378493225346
Validation loss: 2.238056866204306

Epoch: 6| Step: 5
Training loss: 0.2863436758442406
Validation loss: 2.2668900126158267

Epoch: 6| Step: 6
Training loss: 0.2985262000001104
Validation loss: 2.220746453991209

Epoch: 6| Step: 7
Training loss: 0.2952831405093057
Validation loss: 2.2380131532642196

Epoch: 6| Step: 8
Training loss: 0.30707596897282
Validation loss: 2.2608386552632966

Epoch: 6| Step: 9
Training loss: 0.26744849134691123
Validation loss: 2.2808302401697187

Epoch: 6| Step: 10
Training loss: 0.30238709989168583
Validation loss: 2.2966145132018454

Epoch: 6| Step: 11
Training loss: 0.21369551818980567
Validation loss: 2.247564817037785

Epoch: 6| Step: 12
Training loss: 0.11706741060842324
Validation loss: 2.216218175428275

Epoch: 6| Step: 13
Training loss: 0.317768742597583
Validation loss: 2.265931391551915

Epoch: 436| Step: 0
Training loss: 0.3472346632106182
Validation loss: 2.2470563954156253

Epoch: 6| Step: 1
Training loss: 0.2556187029205184
Validation loss: 2.2338851445093497

Epoch: 6| Step: 2
Training loss: 0.21358241103463463
Validation loss: 2.2398630514600573

Epoch: 6| Step: 3
Training loss: 0.25760758087779173
Validation loss: 2.240222277909343

Epoch: 6| Step: 4
Training loss: 0.20321732953563731
Validation loss: 2.2624034119813423

Epoch: 6| Step: 5
Training loss: 0.2963373938151061
Validation loss: 2.2636905084632457

Epoch: 6| Step: 6
Training loss: 0.36282007621852236
Validation loss: 2.252325816220362

Epoch: 6| Step: 7
Training loss: 0.22045950820877516
Validation loss: 2.233664659813554

Epoch: 6| Step: 8
Training loss: 0.25834035299874913
Validation loss: 2.290812737862749

Epoch: 6| Step: 9
Training loss: 0.20951887212230327
Validation loss: 2.2723376922781986

Epoch: 6| Step: 10
Training loss: 0.29363288624640643
Validation loss: 2.277317699111068

Epoch: 6| Step: 11
Training loss: 0.22969841314846312
Validation loss: 2.3171872156768507

Epoch: 6| Step: 12
Training loss: 0.27347934947605046
Validation loss: 2.2954748734633625

Epoch: 6| Step: 13
Training loss: 0.24315002891152845
Validation loss: 2.312287647360564

Epoch: 437| Step: 0
Training loss: 0.293242136237619
Validation loss: 2.3022387928204755

Epoch: 6| Step: 1
Training loss: 0.21497503950808708
Validation loss: 2.2814099765232725

Epoch: 6| Step: 2
Training loss: 0.21154275349826268
Validation loss: 2.293581480510621

Epoch: 6| Step: 3
Training loss: 0.28932102344670646
Validation loss: 2.2741000771013806

Epoch: 6| Step: 4
Training loss: 0.32431715885064694
Validation loss: 2.261287544884916

Epoch: 6| Step: 5
Training loss: 0.3029166503501339
Validation loss: 2.2836046303659434

Epoch: 6| Step: 6
Training loss: 0.31705959588165916
Validation loss: 2.2915052935107494

Epoch: 6| Step: 7
Training loss: 0.24398538613086976
Validation loss: 2.2890518413898784

Epoch: 6| Step: 8
Training loss: 0.2104986093009668
Validation loss: 2.3036406817469532

Epoch: 6| Step: 9
Training loss: 0.17551531808962664
Validation loss: 2.2673091811081085

Epoch: 6| Step: 10
Training loss: 0.22279280105976446
Validation loss: 2.2783206177193636

Epoch: 6| Step: 11
Training loss: 0.25674357040604406
Validation loss: 2.2746065068454775

Epoch: 6| Step: 12
Training loss: 0.2667881239521241
Validation loss: 2.2713571492605404

Epoch: 6| Step: 13
Training loss: 0.26906059470482363
Validation loss: 2.2859985711924

Epoch: 438| Step: 0
Training loss: 0.2531321977840005
Validation loss: 2.299910911272089

Epoch: 6| Step: 1
Training loss: 0.16625551954944778
Validation loss: 2.3132998827220685

Epoch: 6| Step: 2
Training loss: 0.23953445167417353
Validation loss: 2.232461808259943

Epoch: 6| Step: 3
Training loss: 0.20164911826454326
Validation loss: 2.2710940768365546

Epoch: 6| Step: 4
Training loss: 0.22828431118917272
Validation loss: 2.2896824020135313

Epoch: 6| Step: 5
Training loss: 0.28382397704029566
Validation loss: 2.293885185976993

Epoch: 6| Step: 6
Training loss: 0.2386558823916721
Validation loss: 2.2755942585080624

Epoch: 6| Step: 7
Training loss: 0.16142148256203404
Validation loss: 2.263500023880269

Epoch: 6| Step: 8
Training loss: 0.18440076316644025
Validation loss: 2.206748912835357

Epoch: 6| Step: 9
Training loss: 0.2241921738083409
Validation loss: 2.2744452830741038

Epoch: 6| Step: 10
Training loss: 0.29546684793054734
Validation loss: 2.3104443821622023

Epoch: 6| Step: 11
Training loss: 0.33825608703904825
Validation loss: 2.259815897996455

Epoch: 6| Step: 12
Training loss: 0.356230224093944
Validation loss: 2.2443497319376173

Epoch: 6| Step: 13
Training loss: 0.1620302179408519
Validation loss: 2.2965137171602445

Epoch: 439| Step: 0
Training loss: 0.2232365241212606
Validation loss: 2.2491463878669555

Epoch: 6| Step: 1
Training loss: 0.30822477131724546
Validation loss: 2.260762752167537

Epoch: 6| Step: 2
Training loss: 0.3549431488694592
Validation loss: 2.225919057218143

Epoch: 6| Step: 3
Training loss: 0.30148852780169005
Validation loss: 2.305388073666041

Epoch: 6| Step: 4
Training loss: 0.2892926562828629
Validation loss: 2.2668758578632344

Epoch: 6| Step: 5
Training loss: 0.18163360048883076
Validation loss: 2.3468739438043986

Epoch: 6| Step: 6
Training loss: 0.23319743291658965
Validation loss: 2.2709687452160248

Epoch: 6| Step: 7
Training loss: 0.29360638212158824
Validation loss: 2.314875851426925

Epoch: 6| Step: 8
Training loss: 0.33949556820649657
Validation loss: 2.2787690454504275

Epoch: 6| Step: 9
Training loss: 0.32977924697457095
Validation loss: 2.303767323393465

Epoch: 6| Step: 10
Training loss: 0.23326669749804813
Validation loss: 2.257324509204975

Epoch: 6| Step: 11
Training loss: 0.16485388372106852
Validation loss: 2.3161377003307275

Epoch: 6| Step: 12
Training loss: 0.19750757770245977
Validation loss: 2.319465362685464

Epoch: 6| Step: 13
Training loss: 0.19478030175869174
Validation loss: 2.325696553379653

Epoch: 440| Step: 0
Training loss: 0.2005781281760913
Validation loss: 2.318010637663206

Epoch: 6| Step: 1
Training loss: 0.2955239447245124
Validation loss: 2.3086691993049935

Epoch: 6| Step: 2
Training loss: 0.1827165669819214
Validation loss: 2.3249381867262144

Epoch: 6| Step: 3
Training loss: 0.3264505372377352
Validation loss: 2.2609914292110216

Epoch: 6| Step: 4
Training loss: 0.18906803911149925
Validation loss: 2.2978442476077525

Epoch: 6| Step: 5
Training loss: 0.29608393982511017
Validation loss: 2.298511942529484

Epoch: 6| Step: 6
Training loss: 0.1980122985602583
Validation loss: 2.3015036104726305

Epoch: 6| Step: 7
Training loss: 0.27406753435371795
Validation loss: 2.3078755715545145

Epoch: 6| Step: 8
Training loss: 0.2799495460403694
Validation loss: 2.290169145675719

Epoch: 6| Step: 9
Training loss: 0.20942500712907117
Validation loss: 2.313473092931741

Epoch: 6| Step: 10
Training loss: 0.17074215964249675
Validation loss: 2.286051135347026

Epoch: 6| Step: 11
Training loss: 0.26280835353651133
Validation loss: 2.2755486822283193

Epoch: 6| Step: 12
Training loss: 0.2444392399853992
Validation loss: 2.3047459999030724

Epoch: 6| Step: 13
Training loss: 0.2839104993142131
Validation loss: 2.2977689962472407

Epoch: 441| Step: 0
Training loss: 0.4180071447688114
Validation loss: 2.30119871746487

Epoch: 6| Step: 1
Training loss: 0.2668849989427206
Validation loss: 2.3058709333594214

Epoch: 6| Step: 2
Training loss: 0.19431251116311185
Validation loss: 2.271098870900525

Epoch: 6| Step: 3
Training loss: 0.22801577683708213
Validation loss: 2.2760594161423247

Epoch: 6| Step: 4
Training loss: 0.3523065323215109
Validation loss: 2.302127774415201

Epoch: 6| Step: 5
Training loss: 0.19548023650574434
Validation loss: 2.296857059607648

Epoch: 6| Step: 6
Training loss: 0.2473191828524938
Validation loss: 2.288519542125864

Epoch: 6| Step: 7
Training loss: 0.292630088887376
Validation loss: 2.1891054710583413

Epoch: 6| Step: 8
Training loss: 0.18019112208943805
Validation loss: 2.305397346792986

Epoch: 6| Step: 9
Training loss: 0.25069145603429976
Validation loss: 2.3138566204821616

Epoch: 6| Step: 10
Training loss: 0.3454100665177824
Validation loss: 2.2510276849310427

Epoch: 6| Step: 11
Training loss: 0.2071488064671467
Validation loss: 2.2650817570586885

Epoch: 6| Step: 12
Training loss: 0.21828308683590547
Validation loss: 2.279519639819418

Epoch: 6| Step: 13
Training loss: 0.379354997732894
Validation loss: 2.30019532251964

Epoch: 442| Step: 0
Training loss: 0.1848049892083614
Validation loss: 2.2533970637262755

Epoch: 6| Step: 1
Training loss: 0.24254279071278925
Validation loss: 2.273744018446157

Epoch: 6| Step: 2
Training loss: 0.3129172876930085
Validation loss: 2.2441353483832476

Epoch: 6| Step: 3
Training loss: 0.22170665761757297
Validation loss: 2.3051516825154232

Epoch: 6| Step: 4
Training loss: 0.29657265676907046
Validation loss: 2.278535560482768

Epoch: 6| Step: 5
Training loss: 0.2811776174015606
Validation loss: 2.2743912888562368

Epoch: 6| Step: 6
Training loss: 0.32304469641766176
Validation loss: 2.2549784560066057

Epoch: 6| Step: 7
Training loss: 0.29816475333272835
Validation loss: 2.276650333564707

Epoch: 6| Step: 8
Training loss: 0.24571618377478796
Validation loss: 2.245759455917185

Epoch: 6| Step: 9
Training loss: 0.2127074582333798
Validation loss: 2.2541982107958014

Epoch: 6| Step: 10
Training loss: 0.26120138986901964
Validation loss: 2.246519628867363

Epoch: 6| Step: 11
Training loss: 0.25586235976480204
Validation loss: 2.27604285675879

Epoch: 6| Step: 12
Training loss: 0.3129017869575242
Validation loss: 2.270901807283455

Epoch: 6| Step: 13
Training loss: 0.2783467865783946
Validation loss: 2.2408601241131616

Epoch: 443| Step: 0
Training loss: 0.30625607134192057
Validation loss: 2.311944456642696

Epoch: 6| Step: 1
Training loss: 0.27689556389902864
Validation loss: 2.2860015262199282

Epoch: 6| Step: 2
Training loss: 0.1718601307072426
Validation loss: 2.266844112332001

Epoch: 6| Step: 3
Training loss: 0.33526427433239464
Validation loss: 2.3248878520319987

Epoch: 6| Step: 4
Training loss: 0.2552516504751828
Validation loss: 2.3209476479320084

Epoch: 6| Step: 5
Training loss: 0.2495075979471053
Validation loss: 2.26156128997932

Epoch: 6| Step: 6
Training loss: 0.3101395388696669
Validation loss: 2.3074635828408825

Epoch: 6| Step: 7
Training loss: 0.27827426462546667
Validation loss: 2.286841172917471

Epoch: 6| Step: 8
Training loss: 0.17633049246263918
Validation loss: 2.290696057045423

Epoch: 6| Step: 9
Training loss: 0.2654506588048371
Validation loss: 2.2375481843643943

Epoch: 6| Step: 10
Training loss: 0.21954879351258128
Validation loss: 2.2462719302061283

Epoch: 6| Step: 11
Training loss: 0.2743150525655512
Validation loss: 2.280518296877396

Epoch: 6| Step: 12
Training loss: 0.3221870904655333
Validation loss: 2.2859578609537565

Epoch: 6| Step: 13
Training loss: 0.25145805868235466
Validation loss: 2.263655760397506

Epoch: 444| Step: 0
Training loss: 0.2808695843025508
Validation loss: 2.271162015127124

Epoch: 6| Step: 1
Training loss: 0.33522630417335614
Validation loss: 2.2728724350953864

Epoch: 6| Step: 2
Training loss: 0.31522404016809535
Validation loss: 2.265016987212692

Epoch: 6| Step: 3
Training loss: 0.22174749303677943
Validation loss: 2.289419187632583

Epoch: 6| Step: 4
Training loss: 0.28251883608550893
Validation loss: 2.317966958235873

Epoch: 6| Step: 5
Training loss: 0.3162831431953057
Validation loss: 2.3326803866240318

Epoch: 6| Step: 6
Training loss: 0.2297799031588966
Validation loss: 2.3279466155322956

Epoch: 6| Step: 7
Training loss: 0.24297829698162055
Validation loss: 2.2805675896830313

Epoch: 6| Step: 8
Training loss: 0.20677702067331838
Validation loss: 2.2941404746551526

Epoch: 6| Step: 9
Training loss: 0.369357433934148
Validation loss: 2.250579441481285

Epoch: 6| Step: 10
Training loss: 0.2720465705190239
Validation loss: 2.2223762733654224

Epoch: 6| Step: 11
Training loss: 0.3031143511051966
Validation loss: 2.2629443478727698

Epoch: 6| Step: 12
Training loss: 0.2857917341141474
Validation loss: 2.286860694906541

Epoch: 6| Step: 13
Training loss: 0.2647606446401932
Validation loss: 2.2735184942370936

Epoch: 445| Step: 0
Training loss: 0.2184018788060614
Validation loss: 2.250585576963684

Epoch: 6| Step: 1
Training loss: 0.28041134408846813
Validation loss: 2.238610119761897

Epoch: 6| Step: 2
Training loss: 0.29326262675578896
Validation loss: 2.315970445778728

Epoch: 6| Step: 3
Training loss: 0.270297467910784
Validation loss: 2.2715115511387314

Epoch: 6| Step: 4
Training loss: 0.22663406359942542
Validation loss: 2.257386304851578

Epoch: 6| Step: 5
Training loss: 0.27842893655797146
Validation loss: 2.2747666274182503

Epoch: 6| Step: 6
Training loss: 0.2763667696353193
Validation loss: 2.2990873066985134

Epoch: 6| Step: 7
Training loss: 0.24781560253688178
Validation loss: 2.2608485680880137

Epoch: 6| Step: 8
Training loss: 0.24164219963974076
Validation loss: 2.311737329997738

Epoch: 6| Step: 9
Training loss: 0.21245207807189376
Validation loss: 2.3188669858967463

Epoch: 6| Step: 10
Training loss: 0.22075054199469746
Validation loss: 2.2918986000834267

Epoch: 6| Step: 11
Training loss: 0.3552009495986669
Validation loss: 2.2981561560754127

Epoch: 6| Step: 12
Training loss: 0.3050252314199397
Validation loss: 2.3248543006610904

Epoch: 6| Step: 13
Training loss: 0.2923938960622862
Validation loss: 2.238016615530657

Epoch: 446| Step: 0
Training loss: 0.2672976673837188
Validation loss: 2.2583428082378805

Epoch: 6| Step: 1
Training loss: 0.30696431466530993
Validation loss: 2.3199859115293395

Epoch: 6| Step: 2
Training loss: 0.23721886483989815
Validation loss: 2.288580877436685

Epoch: 6| Step: 3
Training loss: 0.22655683543260036
Validation loss: 2.268304989259518

Epoch: 6| Step: 4
Training loss: 0.35015148350247355
Validation loss: 2.294934177230435

Epoch: 6| Step: 5
Training loss: 0.39435647171313903
Validation loss: 2.255946698500954

Epoch: 6| Step: 6
Training loss: 0.2058006456194928
Validation loss: 2.2763197763143284

Epoch: 6| Step: 7
Training loss: 0.23396220412637384
Validation loss: 2.2626471582259957

Epoch: 6| Step: 8
Training loss: 0.2575596378531178
Validation loss: 2.303707410101665

Epoch: 6| Step: 9
Training loss: 0.4358357382514106
Validation loss: 2.3329905246771663

Epoch: 6| Step: 10
Training loss: 0.32029493795492403
Validation loss: 2.2823425968627147

Epoch: 6| Step: 11
Training loss: 0.24866509179329502
Validation loss: 2.2816013866817375

Epoch: 6| Step: 12
Training loss: 0.24013199213999023
Validation loss: 2.2287701999892104

Epoch: 6| Step: 13
Training loss: 0.3913309013342847
Validation loss: 2.2835129265800433

Epoch: 447| Step: 0
Training loss: 0.3231303548830314
Validation loss: 2.277923649740625

Epoch: 6| Step: 1
Training loss: 0.31187259157126157
Validation loss: 2.3246291367273044

Epoch: 6| Step: 2
Training loss: 0.2631776770101817
Validation loss: 2.2812989460471327

Epoch: 6| Step: 3
Training loss: 0.3151833484670499
Validation loss: 2.2476767448769976

Epoch: 6| Step: 4
Training loss: 0.22859311216503966
Validation loss: 2.281154404122168

Epoch: 6| Step: 5
Training loss: 0.24238035767915933
Validation loss: 2.3018028180428542

Epoch: 6| Step: 6
Training loss: 0.3381354486892356
Validation loss: 2.2985212174656757

Epoch: 6| Step: 7
Training loss: 0.46237266308311753
Validation loss: 2.2883308204707467

Epoch: 6| Step: 8
Training loss: 0.40558614042141644
Validation loss: 2.2607659510990077

Epoch: 6| Step: 9
Training loss: 0.30180494316943224
Validation loss: 2.269576456885802

Epoch: 6| Step: 10
Training loss: 0.22304232069934274
Validation loss: 2.2761136850330037

Epoch: 6| Step: 11
Training loss: 0.3073507456911771
Validation loss: 2.2837459461723917

Epoch: 6| Step: 12
Training loss: 0.4143296765300094
Validation loss: 2.333839094889002

Epoch: 6| Step: 13
Training loss: 0.2694861885771078
Validation loss: 2.325913721082889

Epoch: 448| Step: 0
Training loss: 0.20465350924427575
Validation loss: 2.306845444584927

Epoch: 6| Step: 1
Training loss: 0.3475826485550204
Validation loss: 2.286570037221831

Epoch: 6| Step: 2
Training loss: 0.3411118754989441
Validation loss: 2.2518494916606313

Epoch: 6| Step: 3
Training loss: 0.36478953887925997
Validation loss: 2.284261640318299

Epoch: 6| Step: 4
Training loss: 0.41270931019764495
Validation loss: 2.277181978407035

Epoch: 6| Step: 5
Training loss: 0.2882349307884689
Validation loss: 2.251949163622541

Epoch: 6| Step: 6
Training loss: 0.28117638525242994
Validation loss: 2.241556236023985

Epoch: 6| Step: 7
Training loss: 0.2869924969124362
Validation loss: 2.258641698999721

Epoch: 6| Step: 8
Training loss: 0.29636530036772935
Validation loss: 2.2649392855143926

Epoch: 6| Step: 9
Training loss: 0.25152388685067517
Validation loss: 2.2551202441154916

Epoch: 6| Step: 10
Training loss: 0.33276870958820826
Validation loss: 2.25088680416612

Epoch: 6| Step: 11
Training loss: 0.26441976655208393
Validation loss: 2.2380061221835863

Epoch: 6| Step: 12
Training loss: 0.24990206528737935
Validation loss: 2.209155061773582

Epoch: 6| Step: 13
Training loss: 0.22653638755012864
Validation loss: 2.240451029572591

Epoch: 449| Step: 0
Training loss: 0.3272413435010349
Validation loss: 2.245468158675393

Epoch: 6| Step: 1
Training loss: 0.23688028005085005
Validation loss: 2.239110237246263

Epoch: 6| Step: 2
Training loss: 0.28623098830843274
Validation loss: 2.2320185063556557

Epoch: 6| Step: 3
Training loss: 0.22714631726627627
Validation loss: 2.3064840782074114

Epoch: 6| Step: 4
Training loss: 0.27348237350647714
Validation loss: 2.2549812842788555

Epoch: 6| Step: 5
Training loss: 0.26890820903164225
Validation loss: 2.2863312224651686

Epoch: 6| Step: 6
Training loss: 0.31616896691857166
Validation loss: 2.2603247282489494

Epoch: 6| Step: 7
Training loss: 0.3212047454671376
Validation loss: 2.2726033046898135

Epoch: 6| Step: 8
Training loss: 0.35037309991904503
Validation loss: 2.2906584747213863

Epoch: 6| Step: 9
Training loss: 0.35763470509416223
Validation loss: 2.2727305830584608

Epoch: 6| Step: 10
Training loss: 0.2726146305531138
Validation loss: 2.282055063895029

Epoch: 6| Step: 11
Training loss: 0.19414356429026036
Validation loss: 2.2988133544793063

Epoch: 6| Step: 12
Training loss: 0.283305366739365
Validation loss: 2.2626774698980006

Epoch: 6| Step: 13
Training loss: 0.24732187152668444
Validation loss: 2.2881285462243

Epoch: 450| Step: 0
Training loss: 0.2733785565741902
Validation loss: 2.2672708430746704

Epoch: 6| Step: 1
Training loss: 0.23677942832829033
Validation loss: 2.269447382013647

Epoch: 6| Step: 2
Training loss: 0.25632331369262595
Validation loss: 2.283510229354119

Epoch: 6| Step: 3
Training loss: 0.2909166052390341
Validation loss: 2.2956468408329567

Epoch: 6| Step: 4
Training loss: 0.19657967533342852
Validation loss: 2.278661923306288

Epoch: 6| Step: 5
Training loss: 0.34283044672458407
Validation loss: 2.2582856664753197

Epoch: 6| Step: 6
Training loss: 0.27917312334669425
Validation loss: 2.2869517171300244

Epoch: 6| Step: 7
Training loss: 0.16678918244537452
Validation loss: 2.2616247883430804

Epoch: 6| Step: 8
Training loss: 0.2927718708996534
Validation loss: 2.307053552974688

Epoch: 6| Step: 9
Training loss: 0.20002394994744496
Validation loss: 2.311622435933436

Epoch: 6| Step: 10
Training loss: 0.30821212881108995
Validation loss: 2.279296722455688

Epoch: 6| Step: 11
Training loss: 0.22580388097629253
Validation loss: 2.306014977172977

Epoch: 6| Step: 12
Training loss: 0.1924036857009076
Validation loss: 2.2758017587397874

Epoch: 6| Step: 13
Training loss: 0.26354372654488045
Validation loss: 2.307336696303036

Epoch: 451| Step: 0
Training loss: 0.3073478730841018
Validation loss: 2.2613446898673804

Epoch: 6| Step: 1
Training loss: 0.24703997399345443
Validation loss: 2.250790810247489

Epoch: 6| Step: 2
Training loss: 0.23210211805094616
Validation loss: 2.314964012706667

Epoch: 6| Step: 3
Training loss: 0.23482078437416362
Validation loss: 2.313021369103107

Epoch: 6| Step: 4
Training loss: 0.33384749747571413
Validation loss: 2.296635284370903

Epoch: 6| Step: 5
Training loss: 0.2104425362855856
Validation loss: 2.261738620598296

Epoch: 6| Step: 6
Training loss: 0.26763174814467544
Validation loss: 2.2764968300561406

Epoch: 6| Step: 7
Training loss: 0.4304277805556504
Validation loss: 2.2644290091236328

Epoch: 6| Step: 8
Training loss: 0.372643237416582
Validation loss: 2.2800957533600554

Epoch: 6| Step: 9
Training loss: 0.2642658748369531
Validation loss: 2.2924926887487143

Epoch: 6| Step: 10
Training loss: 0.29682279428931463
Validation loss: 2.2758634542592535

Epoch: 6| Step: 11
Training loss: 0.2277788691297479
Validation loss: 2.2635725348998585

Epoch: 6| Step: 12
Training loss: 0.18968960661873124
Validation loss: 2.3166733448929433

Epoch: 6| Step: 13
Training loss: 0.2428293337196943
Validation loss: 2.3153297191433864

Epoch: 452| Step: 0
Training loss: 0.2558649077072068
Validation loss: 2.287446077333135

Epoch: 6| Step: 1
Training loss: 0.251683186671485
Validation loss: 2.2724843337523053

Epoch: 6| Step: 2
Training loss: 0.3177719782049602
Validation loss: 2.2980125188218152

Epoch: 6| Step: 3
Training loss: 0.3691277072805922
Validation loss: 2.2936114180137084

Epoch: 6| Step: 4
Training loss: 0.16784685724422427
Validation loss: 2.3351809361976827

Epoch: 6| Step: 5
Training loss: 0.14240566692940285
Validation loss: 2.283883982296664

Epoch: 6| Step: 6
Training loss: 0.2813899830972845
Validation loss: 2.2840604322859654

Epoch: 6| Step: 7
Training loss: 0.2920881643090771
Validation loss: 2.3214575171849345

Epoch: 6| Step: 8
Training loss: 0.2545010715201628
Validation loss: 2.2974110364933393

Epoch: 6| Step: 9
Training loss: 0.23523780637814684
Validation loss: 2.28975096017508

Epoch: 6| Step: 10
Training loss: 0.2813693693945748
Validation loss: 2.3140416719854597

Epoch: 6| Step: 11
Training loss: 0.2506599061397534
Validation loss: 2.2826895243554595

Epoch: 6| Step: 12
Training loss: 0.1947582869480525
Validation loss: 2.308171525739872

Epoch: 6| Step: 13
Training loss: 0.2335627627791064
Validation loss: 2.28995764614068

Epoch: 453| Step: 0
Training loss: 0.15298484742874108
Validation loss: 2.3009368032170907

Epoch: 6| Step: 1
Training loss: 0.194776151459098
Validation loss: 2.2833897819177706

Epoch: 6| Step: 2
Training loss: 0.32645248859839926
Validation loss: 2.2769931809104476

Epoch: 6| Step: 3
Training loss: 0.2932093331838212
Validation loss: 2.2906891616502043

Epoch: 6| Step: 4
Training loss: 0.20530566353643748
Validation loss: 2.291056514200574

Epoch: 6| Step: 5
Training loss: 0.2639976608080618
Validation loss: 2.31869408436385

Epoch: 6| Step: 6
Training loss: 0.30794841554069663
Validation loss: 2.254711040498185

Epoch: 6| Step: 7
Training loss: 0.2304425628784654
Validation loss: 2.3215640253854573

Epoch: 6| Step: 8
Training loss: 0.20189415792080295
Validation loss: 2.2779944369801064

Epoch: 6| Step: 9
Training loss: 0.27855022370674054
Validation loss: 2.3180644301126585

Epoch: 6| Step: 10
Training loss: 0.22470949678092123
Validation loss: 2.311861809311928

Epoch: 6| Step: 11
Training loss: 0.23293112414523306
Validation loss: 2.291348597098995

Epoch: 6| Step: 12
Training loss: 0.19720845291004577
Validation loss: 2.283705552477166

Epoch: 6| Step: 13
Training loss: 0.2319910881657462
Validation loss: 2.3028900896248996

Epoch: 454| Step: 0
Training loss: 0.17267806834456007
Validation loss: 2.2925324682933765

Epoch: 6| Step: 1
Training loss: 0.17831737144025317
Validation loss: 2.3083212961188315

Epoch: 6| Step: 2
Training loss: 0.30804861181912585
Validation loss: 2.3006242095080927

Epoch: 6| Step: 3
Training loss: 0.28158603567729157
Validation loss: 2.2892127568183387

Epoch: 6| Step: 4
Training loss: 0.24452123347233393
Validation loss: 2.2588553302795025

Epoch: 6| Step: 5
Training loss: 0.36343604040795796
Validation loss: 2.3205410965678657

Epoch: 6| Step: 6
Training loss: 0.36087176397264736
Validation loss: 2.2950535686393896

Epoch: 6| Step: 7
Training loss: 0.16181074350102842
Validation loss: 2.300375884895173

Epoch: 6| Step: 8
Training loss: 0.36991595028862817
Validation loss: 2.277105416007314

Epoch: 6| Step: 9
Training loss: 0.2749689268850145
Validation loss: 2.3201225879498333

Epoch: 6| Step: 10
Training loss: 0.167901968432998
Validation loss: 2.2919033853052464

Epoch: 6| Step: 11
Training loss: 0.18619481442052374
Validation loss: 2.287574301661178

Epoch: 6| Step: 12
Training loss: 0.3592587780646542
Validation loss: 2.341964991380887

Epoch: 6| Step: 13
Training loss: 0.22440609233039488
Validation loss: 2.307714709097796

Epoch: 455| Step: 0
Training loss: 0.2853916972902769
Validation loss: 2.2858558909654105

Epoch: 6| Step: 1
Training loss: 0.1930692692777362
Validation loss: 2.2437319426310247

Epoch: 6| Step: 2
Training loss: 0.20914021145334777
Validation loss: 2.2887161565723315

Epoch: 6| Step: 3
Training loss: 0.369153986290411
Validation loss: 2.2541376146100247

Epoch: 6| Step: 4
Training loss: 0.2750733082768598
Validation loss: 2.2671010876169366

Epoch: 6| Step: 5
Training loss: 0.25578912833541434
Validation loss: 2.260407405312781

Epoch: 6| Step: 6
Training loss: 0.21904511639872562
Validation loss: 2.253441095422925

Epoch: 6| Step: 7
Training loss: 0.20788418315094534
Validation loss: 2.2864585360886838

Epoch: 6| Step: 8
Training loss: 0.32059988062877776
Validation loss: 2.265990006432938

Epoch: 6| Step: 9
Training loss: 0.31914033644626977
Validation loss: 2.2955384723389365

Epoch: 6| Step: 10
Training loss: 0.2162300122125034
Validation loss: 2.2439177833807746

Epoch: 6| Step: 11
Training loss: 0.18192984003278576
Validation loss: 2.256454816347127

Epoch: 6| Step: 12
Training loss: 0.213148765497438
Validation loss: 2.267113137685224

Epoch: 6| Step: 13
Training loss: 0.25875359058192426
Validation loss: 2.2655558257669

Epoch: 456| Step: 0
Training loss: 0.16768509733950587
Validation loss: 2.2882501595068256

Epoch: 6| Step: 1
Training loss: 0.24500751701569004
Validation loss: 2.2931465803482363

Epoch: 6| Step: 2
Training loss: 0.21571147124692894
Validation loss: 2.239457438870834

Epoch: 6| Step: 3
Training loss: 0.2548808539888984
Validation loss: 2.254264736921443

Epoch: 6| Step: 4
Training loss: 0.30057160391041926
Validation loss: 2.2441725146244242

Epoch: 6| Step: 5
Training loss: 0.1927586867728881
Validation loss: 2.270155295074834

Epoch: 6| Step: 6
Training loss: 0.20597890391358273
Validation loss: 2.2937645644055555

Epoch: 6| Step: 7
Training loss: 0.2725327236536804
Validation loss: 2.2375362059436106

Epoch: 6| Step: 8
Training loss: 0.2731476473639065
Validation loss: 2.2868117549547184

Epoch: 6| Step: 9
Training loss: 0.2939606215840546
Validation loss: 2.2747997733794247

Epoch: 6| Step: 10
Training loss: 0.2263755191194595
Validation loss: 2.2520898897097346

Epoch: 6| Step: 11
Training loss: 0.17731619465380236
Validation loss: 2.3059418104505145

Epoch: 6| Step: 12
Training loss: 0.30784003042658103
Validation loss: 2.257220365498126

Epoch: 6| Step: 13
Training loss: 0.23705364024731138
Validation loss: 2.254173884377291

Epoch: 457| Step: 0
Training loss: 0.2663827354367718
Validation loss: 2.3235643763940033

Epoch: 6| Step: 1
Training loss: 0.22934947344755077
Validation loss: 2.246394880813103

Epoch: 6| Step: 2
Training loss: 0.3118271498198709
Validation loss: 2.2597512058159603

Epoch: 6| Step: 3
Training loss: 0.29549067637294646
Validation loss: 2.2809571639976065

Epoch: 6| Step: 4
Training loss: 0.2639547596598966
Validation loss: 2.3183599920360383

Epoch: 6| Step: 5
Training loss: 0.27606587783633146
Validation loss: 2.2863739942377745

Epoch: 6| Step: 6
Training loss: 0.25267047929298697
Validation loss: 2.254599937735486

Epoch: 6| Step: 7
Training loss: 0.3985656270476814
Validation loss: 2.267860309611492

Epoch: 6| Step: 8
Training loss: 0.3123406242225649
Validation loss: 2.2773464283564824

Epoch: 6| Step: 9
Training loss: 0.2749961841925401
Validation loss: 2.3012144828292014

Epoch: 6| Step: 10
Training loss: 0.21091615604215486
Validation loss: 2.3125653300636895

Epoch: 6| Step: 11
Training loss: 0.22467363516377195
Validation loss: 2.251052398397156

Epoch: 6| Step: 12
Training loss: 0.18703463540961032
Validation loss: 2.2985817499837014

Epoch: 6| Step: 13
Training loss: 0.2927653305834837
Validation loss: 2.275626266131302

Epoch: 458| Step: 0
Training loss: 0.19752291151134466
Validation loss: 2.2988407866054463

Epoch: 6| Step: 1
Training loss: 0.35139630946054373
Validation loss: 2.2500803632866244

Epoch: 6| Step: 2
Training loss: 0.14357868305437846
Validation loss: 2.292886033913856

Epoch: 6| Step: 3
Training loss: 0.23842382855549052
Validation loss: 2.2856101691071107

Epoch: 6| Step: 4
Training loss: 0.13906373816378298
Validation loss: 2.280323118966054

Epoch: 6| Step: 5
Training loss: 0.34358947430318665
Validation loss: 2.2958312744805256

Epoch: 6| Step: 6
Training loss: 0.3250703428327506
Validation loss: 2.295874102923373

Epoch: 6| Step: 7
Training loss: 0.25757106399924035
Validation loss: 2.242771351790129

Epoch: 6| Step: 8
Training loss: 0.23054275294425502
Validation loss: 2.2353513936245064

Epoch: 6| Step: 9
Training loss: 0.2779181268235205
Validation loss: 2.3173761079682915

Epoch: 6| Step: 10
Training loss: 0.29375337436442367
Validation loss: 2.271599243793316

Epoch: 6| Step: 11
Training loss: 0.25131212059624186
Validation loss: 2.2625854272328207

Epoch: 6| Step: 12
Training loss: 0.2530753699261815
Validation loss: 2.274474109748569

Epoch: 6| Step: 13
Training loss: 0.17143242381442003
Validation loss: 2.2821617307692

Epoch: 459| Step: 0
Training loss: 0.23214530517785983
Validation loss: 2.238314288274429

Epoch: 6| Step: 1
Training loss: 0.24306178718858656
Validation loss: 2.2582206489161516

Epoch: 6| Step: 2
Training loss: 0.2677548235789118
Validation loss: 2.2739946047630264

Epoch: 6| Step: 3
Training loss: 0.28110328132284346
Validation loss: 2.207730864869168

Epoch: 6| Step: 4
Training loss: 0.3155401172372383
Validation loss: 2.261665532480329

Epoch: 6| Step: 5
Training loss: 0.11273885642679153
Validation loss: 2.2819532068287747

Epoch: 6| Step: 6
Training loss: 0.2849256288382096
Validation loss: 2.2636848297933336

Epoch: 6| Step: 7
Training loss: 0.21842481079682796
Validation loss: 2.271625141604827

Epoch: 6| Step: 8
Training loss: 0.25338183312595386
Validation loss: 2.312850934112044

Epoch: 6| Step: 9
Training loss: 0.29075407269135484
Validation loss: 2.2585272796044076

Epoch: 6| Step: 10
Training loss: 0.23841480514591207
Validation loss: 2.2805157703528214

Epoch: 6| Step: 11
Training loss: 0.18318213320197752
Validation loss: 2.2564064760623843

Epoch: 6| Step: 12
Training loss: 0.28011931857297323
Validation loss: 2.289673585880251

Epoch: 6| Step: 13
Training loss: 0.26062522007683625
Validation loss: 2.265885384165089

Epoch: 460| Step: 0
Training loss: 0.2603462298820833
Validation loss: 2.2817801813106677

Epoch: 6| Step: 1
Training loss: 0.24541176804158596
Validation loss: 2.30988794875206

Epoch: 6| Step: 2
Training loss: 0.2624176287839867
Validation loss: 2.276695983785459

Epoch: 6| Step: 3
Training loss: 0.19547713017052515
Validation loss: 2.3002142301938258

Epoch: 6| Step: 4
Training loss: 0.26123573084014556
Validation loss: 2.3089934216638706

Epoch: 6| Step: 5
Training loss: 0.3181978295604668
Validation loss: 2.2943678253374777

Epoch: 6| Step: 6
Training loss: 0.38185449345372285
Validation loss: 2.263153043044877

Epoch: 6| Step: 7
Training loss: 0.3293716499621514
Validation loss: 2.2731867648678312

Epoch: 6| Step: 8
Training loss: 0.23585199044422636
Validation loss: 2.2921486232158994

Epoch: 6| Step: 9
Training loss: 0.3107540591098348
Validation loss: 2.2344413694114693

Epoch: 6| Step: 10
Training loss: 0.3630814772111858
Validation loss: 2.2805382040506985

Epoch: 6| Step: 11
Training loss: 0.2665953862519334
Validation loss: 2.3072822318016937

Epoch: 6| Step: 12
Training loss: 0.21474867364254002
Validation loss: 2.263815347833117

Epoch: 6| Step: 13
Training loss: 0.26884769061414315
Validation loss: 2.2911916991962546

Epoch: 461| Step: 0
Training loss: 0.3024191168558558
Validation loss: 2.25774850721651

Epoch: 6| Step: 1
Training loss: 0.24822778187273592
Validation loss: 2.2844437577962564

Epoch: 6| Step: 2
Training loss: 0.2940412852613792
Validation loss: 2.255743035293138

Epoch: 6| Step: 3
Training loss: 0.2971688873848457
Validation loss: 2.2982168970450645

Epoch: 6| Step: 4
Training loss: 0.30347516883847286
Validation loss: 2.313638819120739

Epoch: 6| Step: 5
Training loss: 0.24939672877362043
Validation loss: 2.3183951885282057

Epoch: 6| Step: 6
Training loss: 0.2928694874769366
Validation loss: 2.3334918876546715

Epoch: 6| Step: 7
Training loss: 0.3440418846509595
Validation loss: 2.3096565859530536

Epoch: 6| Step: 8
Training loss: 0.32825685304226915
Validation loss: 2.34470397184188

Epoch: 6| Step: 9
Training loss: 0.35732914289702905
Validation loss: 2.304997948033984

Epoch: 6| Step: 10
Training loss: 0.2585944253503561
Validation loss: 2.3323591247816466

Epoch: 6| Step: 11
Training loss: 0.2142456572848128
Validation loss: 2.3392450142942125

Epoch: 6| Step: 12
Training loss: 0.2811748881177255
Validation loss: 2.302856856203788

Epoch: 6| Step: 13
Training loss: 0.34847734762290833
Validation loss: 2.2967191543819236

Epoch: 462| Step: 0
Training loss: 0.2406649723540402
Validation loss: 2.334779518277148

Epoch: 6| Step: 1
Training loss: 0.2724259877092734
Validation loss: 2.287152531816885

Epoch: 6| Step: 2
Training loss: 0.33850344173112906
Validation loss: 2.3260438992230066

Epoch: 6| Step: 3
Training loss: 0.23013252852120913
Validation loss: 2.2783901369045445

Epoch: 6| Step: 4
Training loss: 0.1693795747420677
Validation loss: 2.311893692951682

Epoch: 6| Step: 5
Training loss: 0.20208368784752126
Validation loss: 2.3161637091856475

Epoch: 6| Step: 6
Training loss: 0.21633344382666286
Validation loss: 2.3175080173522473

Epoch: 6| Step: 7
Training loss: 0.2829769941758306
Validation loss: 2.2740180813437614

Epoch: 6| Step: 8
Training loss: 0.2551230690400364
Validation loss: 2.3047789991933456

Epoch: 6| Step: 9
Training loss: 0.30248137946788267
Validation loss: 2.294614540244858

Epoch: 6| Step: 10
Training loss: 0.18223299830807244
Validation loss: 2.298370134207928

Epoch: 6| Step: 11
Training loss: 0.2934175740912058
Validation loss: 2.2700310669396164

Epoch: 6| Step: 12
Training loss: 0.20001281235306156
Validation loss: 2.241883925246548

Epoch: 6| Step: 13
Training loss: 0.221198159761043
Validation loss: 2.3035817484027783

Epoch: 463| Step: 0
Training loss: 0.2087721772320211
Validation loss: 2.296203766054356

Epoch: 6| Step: 1
Training loss: 0.19818995872976589
Validation loss: 2.2774878271470604

Epoch: 6| Step: 2
Training loss: 0.3133017269301222
Validation loss: 2.2884723566597303

Epoch: 6| Step: 3
Training loss: 0.2551500811885261
Validation loss: 2.28661712292067

Epoch: 6| Step: 4
Training loss: 0.2464146036220925
Validation loss: 2.2874498643227485

Epoch: 6| Step: 5
Training loss: 0.2523214029154573
Validation loss: 2.2792391515034787

Epoch: 6| Step: 6
Training loss: 0.2272943646253071
Validation loss: 2.2812294022836466

Epoch: 6| Step: 7
Training loss: 0.24821385447767538
Validation loss: 2.26350429859263

Epoch: 6| Step: 8
Training loss: 0.2687794386464824
Validation loss: 2.289727306496328

Epoch: 6| Step: 9
Training loss: 0.24297288480227147
Validation loss: 2.2826735004890204

Epoch: 6| Step: 10
Training loss: 0.263424679771157
Validation loss: 2.2705131678364263

Epoch: 6| Step: 11
Training loss: 0.22693559739784291
Validation loss: 2.2813713006643512

Epoch: 6| Step: 12
Training loss: 0.19220901035483445
Validation loss: 2.2971039742240653

Epoch: 6| Step: 13
Training loss: 0.2842018931519085
Validation loss: 2.2666098635465497

Epoch: 464| Step: 0
Training loss: 0.27970056769675183
Validation loss: 2.271912945164199

Epoch: 6| Step: 1
Training loss: 0.26567354880572236
Validation loss: 2.278196137150061

Epoch: 6| Step: 2
Training loss: 0.3220299755073066
Validation loss: 2.3030139860108663

Epoch: 6| Step: 3
Training loss: 0.22332242389859877
Validation loss: 2.269790678358162

Epoch: 6| Step: 4
Training loss: 0.24440259992251429
Validation loss: 2.266199955388567

Epoch: 6| Step: 5
Training loss: 0.2680533150566651
Validation loss: 2.301426873027604

Epoch: 6| Step: 6
Training loss: 0.34106641917662134
Validation loss: 2.2391274690574865

Epoch: 6| Step: 7
Training loss: 0.2038290403790753
Validation loss: 2.3436272822147908

Epoch: 6| Step: 8
Training loss: 0.2907945189812802
Validation loss: 2.264776048879843

Epoch: 6| Step: 9
Training loss: 0.17642020551286716
Validation loss: 2.291173775003834

Epoch: 6| Step: 10
Training loss: 0.28612338626684813
Validation loss: 2.2791604178538836

Epoch: 6| Step: 11
Training loss: 0.2147112264251958
Validation loss: 2.2467418056406663

Epoch: 6| Step: 12
Training loss: 0.337960781685996
Validation loss: 2.256928029775023

Epoch: 6| Step: 13
Training loss: 0.3097421307691818
Validation loss: 2.2501296959690213

Epoch: 465| Step: 0
Training loss: 0.2921788566249306
Validation loss: 2.2576425173789723

Epoch: 6| Step: 1
Training loss: 0.1690152745560205
Validation loss: 2.2548500522344557

Epoch: 6| Step: 2
Training loss: 0.20644533271031565
Validation loss: 2.29661769680013

Epoch: 6| Step: 3
Training loss: 0.3759777514946703
Validation loss: 2.22131482380547

Epoch: 6| Step: 4
Training loss: 0.21526693800499266
Validation loss: 2.2813670420124765

Epoch: 6| Step: 5
Training loss: 0.23680740811271847
Validation loss: 2.248127511371012

Epoch: 6| Step: 6
Training loss: 0.28621979520764945
Validation loss: 2.2294560865480646

Epoch: 6| Step: 7
Training loss: 0.2487944204358737
Validation loss: 2.260028433677142

Epoch: 6| Step: 8
Training loss: 0.22869359120849808
Validation loss: 2.2919476828082668

Epoch: 6| Step: 9
Training loss: 0.5038138607997237
Validation loss: 2.2635449035686928

Epoch: 6| Step: 10
Training loss: 0.2926249330407302
Validation loss: 2.3104363417984426

Epoch: 6| Step: 11
Training loss: 0.4196424042197801
Validation loss: 2.299145940452402

Epoch: 6| Step: 12
Training loss: 0.3415079148766051
Validation loss: 2.328999638809781

Epoch: 6| Step: 13
Training loss: 0.31123775429363076
Validation loss: 2.296777805339298

Epoch: 466| Step: 0
Training loss: 0.21532928049834762
Validation loss: 2.3031773333942116

Epoch: 6| Step: 1
Training loss: 0.2654568757201939
Validation loss: 2.274636589270512

Epoch: 6| Step: 2
Training loss: 0.23461045518055457
Validation loss: 2.275505768096035

Epoch: 6| Step: 3
Training loss: 0.2940589076966962
Validation loss: 2.294958634318854

Epoch: 6| Step: 4
Training loss: 0.36731056423693
Validation loss: 2.3026110330539833

Epoch: 6| Step: 5
Training loss: 0.21257202561673183
Validation loss: 2.309249681471724

Epoch: 6| Step: 6
Training loss: 0.23888300908015067
Validation loss: 2.3259323684380884

Epoch: 6| Step: 7
Training loss: 0.21573534540077083
Validation loss: 2.2919727698989294

Epoch: 6| Step: 8
Training loss: 0.23023302339973242
Validation loss: 2.3114709626572383

Epoch: 6| Step: 9
Training loss: 0.18174266000235392
Validation loss: 2.291859572412146

Epoch: 6| Step: 10
Training loss: 0.2560200368799666
Validation loss: 2.3059926362379137

Epoch: 6| Step: 11
Training loss: 0.2874708300802533
Validation loss: 2.303391759391808

Epoch: 6| Step: 12
Training loss: 0.2253521207054341
Validation loss: 2.3099932788018984

Epoch: 6| Step: 13
Training loss: 0.2810297209338484
Validation loss: 2.368401806620243

Epoch: 467| Step: 0
Training loss: 0.21214322475153333
Validation loss: 2.3297431664539756

Epoch: 6| Step: 1
Training loss: 0.16977037603977768
Validation loss: 2.3110481378440686

Epoch: 6| Step: 2
Training loss: 0.40436376488243764
Validation loss: 2.3066300562294257

Epoch: 6| Step: 3
Training loss: 0.27791490977950634
Validation loss: 2.3065524901354757

Epoch: 6| Step: 4
Training loss: 0.24100633971197613
Validation loss: 2.321401321335035

Epoch: 6| Step: 5
Training loss: 0.2829022091377117
Validation loss: 2.316231020324538

Epoch: 6| Step: 6
Training loss: 0.1807177386577975
Validation loss: 2.299265311907417

Epoch: 6| Step: 7
Training loss: 0.23233549933288153
Validation loss: 2.306033742357275

Epoch: 6| Step: 8
Training loss: 0.3682356949388939
Validation loss: 2.3085955917256387

Epoch: 6| Step: 9
Training loss: 0.3028455960637975
Validation loss: 2.3199374134429527

Epoch: 6| Step: 10
Training loss: 0.28176405076462024
Validation loss: 2.298738826291017

Epoch: 6| Step: 11
Training loss: 0.20660662740960326
Validation loss: 2.2672707466810835

Epoch: 6| Step: 12
Training loss: 0.2889217343263251
Validation loss: 2.2792382710824426

Epoch: 6| Step: 13
Training loss: 0.328682607335439
Validation loss: 2.295984869892719

Epoch: 468| Step: 0
Training loss: 0.24780957442741877
Validation loss: 2.2591229675899593

Epoch: 6| Step: 1
Training loss: 0.32127438311681994
Validation loss: 2.2785673436770146

Epoch: 6| Step: 2
Training loss: 0.25885020559390065
Validation loss: 2.2979838490860636

Epoch: 6| Step: 3
Training loss: 0.29427575076335327
Validation loss: 2.2457562621509655

Epoch: 6| Step: 4
Training loss: 0.2457723789833149
Validation loss: 2.3231607032394836

Epoch: 6| Step: 5
Training loss: 0.3317576908321106
Validation loss: 2.2599557561960326

Epoch: 6| Step: 6
Training loss: 0.2485965960092153
Validation loss: 2.2929575030058054

Epoch: 6| Step: 7
Training loss: 0.3432127807808045
Validation loss: 2.319264013413303

Epoch: 6| Step: 8
Training loss: 0.24044178328778062
Validation loss: 2.253846439337101

Epoch: 6| Step: 9
Training loss: 0.24237510890230327
Validation loss: 2.2580501162967854

Epoch: 6| Step: 10
Training loss: 0.24440661627065638
Validation loss: 2.3467362601173054

Epoch: 6| Step: 11
Training loss: 0.27472442506793704
Validation loss: 2.273583109279363

Epoch: 6| Step: 12
Training loss: 0.31190963054033133
Validation loss: 2.291586637544529

Epoch: 6| Step: 13
Training loss: 0.3495185670184407
Validation loss: 2.3057062688333505

Epoch: 469| Step: 0
Training loss: 0.40453541670650245
Validation loss: 2.3245652910147636

Epoch: 6| Step: 1
Training loss: 0.24453611003445797
Validation loss: 2.2560629044131795

Epoch: 6| Step: 2
Training loss: 0.3045260661952776
Validation loss: 2.272514374326953

Epoch: 6| Step: 3
Training loss: 0.3499901046375892
Validation loss: 2.324190694174812

Epoch: 6| Step: 4
Training loss: 0.19300095254719832
Validation loss: 2.285382121082068

Epoch: 6| Step: 5
Training loss: 0.35704604437495524
Validation loss: 2.2936765064796627

Epoch: 6| Step: 6
Training loss: 0.3084998893443918
Validation loss: 2.2573157691343586

Epoch: 6| Step: 7
Training loss: 0.2666238768464946
Validation loss: 2.283639692605003

Epoch: 6| Step: 8
Training loss: 0.2791208766396946
Validation loss: 2.2161742917186174

Epoch: 6| Step: 9
Training loss: 0.38944495296800297
Validation loss: 2.2922449047109517

Epoch: 6| Step: 10
Training loss: 0.32025864776471885
Validation loss: 2.2906129986776906

Epoch: 6| Step: 11
Training loss: 0.2561091448780688
Validation loss: 2.2479956847813507

Epoch: 6| Step: 12
Training loss: 0.20925077945297438
Validation loss: 2.319229224176075

Epoch: 6| Step: 13
Training loss: 0.2957544763440739
Validation loss: 2.2818876707779996

Epoch: 470| Step: 0
Training loss: 0.2897200708689373
Validation loss: 2.260746678347209

Epoch: 6| Step: 1
Training loss: 0.3565140331336594
Validation loss: 2.2874604956545803

Epoch: 6| Step: 2
Training loss: 0.1866312364569747
Validation loss: 2.3112664842060733

Epoch: 6| Step: 3
Training loss: 0.25016122328170787
Validation loss: 2.3228603122415628

Epoch: 6| Step: 4
Training loss: 0.30231545288776307
Validation loss: 2.291756113792075

Epoch: 6| Step: 5
Training loss: 0.26502170491850546
Validation loss: 2.3045563827545332

Epoch: 6| Step: 6
Training loss: 0.19425696297050765
Validation loss: 2.2578338745231803

Epoch: 6| Step: 7
Training loss: 0.31769737500954504
Validation loss: 2.264450259774706

Epoch: 6| Step: 8
Training loss: 0.2422752605909781
Validation loss: 2.255625791139958

Epoch: 6| Step: 9
Training loss: 0.3190485860086627
Validation loss: 2.263349403142647

Epoch: 6| Step: 10
Training loss: 0.30613443179260236
Validation loss: 2.2609698472766033

Epoch: 6| Step: 11
Training loss: 0.16634029729120323
Validation loss: 2.2445185259856597

Epoch: 6| Step: 12
Training loss: 0.24194631565108615
Validation loss: 2.232477987835204

Epoch: 6| Step: 13
Training loss: 0.3080533523130117
Validation loss: 2.290785821054466

Epoch: 471| Step: 0
Training loss: 0.19760469058189722
Validation loss: 2.259103056395454

Epoch: 6| Step: 1
Training loss: 0.3458516830819486
Validation loss: 2.233226018315323

Epoch: 6| Step: 2
Training loss: 0.24174569964208395
Validation loss: 2.2801741758820118

Epoch: 6| Step: 3
Training loss: 0.21692483579487185
Validation loss: 2.2582274059025607

Epoch: 6| Step: 4
Training loss: 0.2928825251532009
Validation loss: 2.2937730703137835

Epoch: 6| Step: 5
Training loss: 0.32492804785347756
Validation loss: 2.253721911706159

Epoch: 6| Step: 6
Training loss: 0.2248442624121388
Validation loss: 2.245340131298944

Epoch: 6| Step: 7
Training loss: 0.1742758129308721
Validation loss: 2.2735427534945027

Epoch: 6| Step: 8
Training loss: 0.27029473902394613
Validation loss: 2.2547560510680715

Epoch: 6| Step: 9
Training loss: 0.2756516862782741
Validation loss: 2.2587899684835473

Epoch: 6| Step: 10
Training loss: 0.1404599970126162
Validation loss: 2.283373145176366

Epoch: 6| Step: 11
Training loss: 0.2017454839671317
Validation loss: 2.2879612587903373

Epoch: 6| Step: 12
Training loss: 0.2334177974827658
Validation loss: 2.28601889127511

Epoch: 6| Step: 13
Training loss: 0.3453316605546902
Validation loss: 2.259077015032134

Epoch: 472| Step: 0
Training loss: 0.26355193907176916
Validation loss: 2.275502878020603

Epoch: 6| Step: 1
Training loss: 0.3091536163307357
Validation loss: 2.2938251964636622

Epoch: 6| Step: 2
Training loss: 0.32184115111504297
Validation loss: 2.307954995679048

Epoch: 6| Step: 3
Training loss: 0.2523794485534265
Validation loss: 2.2767941404412904

Epoch: 6| Step: 4
Training loss: 0.24610242374211705
Validation loss: 2.24236571592812

Epoch: 6| Step: 5
Training loss: 0.17672444655649716
Validation loss: 2.2663036864553545

Epoch: 6| Step: 6
Training loss: 0.29024916722837807
Validation loss: 2.2595974247703077

Epoch: 6| Step: 7
Training loss: 0.2542239915322664
Validation loss: 2.238507643829103

Epoch: 6| Step: 8
Training loss: 0.30503966691080253
Validation loss: 2.3007594454584317

Epoch: 6| Step: 9
Training loss: 0.22754875457161325
Validation loss: 2.2501004779421

Epoch: 6| Step: 10
Training loss: 0.3378127565127095
Validation loss: 2.3000809662154165

Epoch: 6| Step: 11
Training loss: 0.2526264508567647
Validation loss: 2.301202671766838

Epoch: 6| Step: 12
Training loss: 0.23870884722901095
Validation loss: 2.292924974793759

Epoch: 6| Step: 13
Training loss: 0.26460347374281545
Validation loss: 2.255290698749112

Epoch: 473| Step: 0
Training loss: 0.17116742355081213
Validation loss: 2.2715334352600163

Epoch: 6| Step: 1
Training loss: 0.21626355324428012
Validation loss: 2.28731957438011

Epoch: 6| Step: 2
Training loss: 0.14590230372360607
Validation loss: 2.3082030902250756

Epoch: 6| Step: 3
Training loss: 0.310715395709343
Validation loss: 2.2754251851307346

Epoch: 6| Step: 4
Training loss: 0.21923172225146545
Validation loss: 2.3055195572607587

Epoch: 6| Step: 5
Training loss: 0.17106553763931973
Validation loss: 2.237296251081004

Epoch: 6| Step: 6
Training loss: 0.3646518325034654
Validation loss: 2.2382452109177784

Epoch: 6| Step: 7
Training loss: 0.2901960006132657
Validation loss: 2.25388651309746

Epoch: 6| Step: 8
Training loss: 0.2773823509755047
Validation loss: 2.333717728922753

Epoch: 6| Step: 9
Training loss: 0.2238774689613315
Validation loss: 2.287549140277286

Epoch: 6| Step: 10
Training loss: 0.2841745487548166
Validation loss: 2.32671210920485

Epoch: 6| Step: 11
Training loss: 0.17176005464590832
Validation loss: 2.274442487740784

Epoch: 6| Step: 12
Training loss: 0.33070431513293924
Validation loss: 2.292311150063766

Epoch: 6| Step: 13
Training loss: 0.20365922624462848
Validation loss: 2.2976762926597445

Epoch: 474| Step: 0
Training loss: 0.2828071720190458
Validation loss: 2.2579055819744114

Epoch: 6| Step: 1
Training loss: 0.20511049287674032
Validation loss: 2.271040755315092

Epoch: 6| Step: 2
Training loss: 0.359239262363992
Validation loss: 2.307699289474359

Epoch: 6| Step: 3
Training loss: 0.3365781906671178
Validation loss: 2.2890186327310196

Epoch: 6| Step: 4
Training loss: 0.2915149731348387
Validation loss: 2.256492026214295

Epoch: 6| Step: 5
Training loss: 0.2424268309086317
Validation loss: 2.2797724846766694

Epoch: 6| Step: 6
Training loss: 0.2830360972379111
Validation loss: 2.22899074097917

Epoch: 6| Step: 7
Training loss: 0.35813255738145067
Validation loss: 2.304177489666299

Epoch: 6| Step: 8
Training loss: 0.29348333307542407
Validation loss: 2.2186085114116834

Epoch: 6| Step: 9
Training loss: 0.1789113885233196
Validation loss: 2.268790635795037

Epoch: 6| Step: 10
Training loss: 0.26934809612357585
Validation loss: 2.2480250804119724

Epoch: 6| Step: 11
Training loss: 0.272744936578746
Validation loss: 2.2630640573767073

Epoch: 6| Step: 12
Training loss: 0.21068467777617292
Validation loss: 2.1975285668047904

Epoch: 6| Step: 13
Training loss: 0.22340135382002585
Validation loss: 2.248470263212612

Epoch: 475| Step: 0
Training loss: 0.2929156954727966
Validation loss: 2.2578641540180113

Epoch: 6| Step: 1
Training loss: 0.29583130128368534
Validation loss: 2.2853597870955213

Epoch: 6| Step: 2
Training loss: 0.31289515545597596
Validation loss: 2.2446400590461453

Epoch: 6| Step: 3
Training loss: 0.20657453002756196
Validation loss: 2.240082402771415

Epoch: 6| Step: 4
Training loss: 0.2310971728078501
Validation loss: 2.256787939921684

Epoch: 6| Step: 5
Training loss: 0.24055146790617363
Validation loss: 2.2408783177572373

Epoch: 6| Step: 6
Training loss: 0.33032850215914333
Validation loss: 2.2731716004878484

Epoch: 6| Step: 7
Training loss: 0.2616189225389037
Validation loss: 2.2633688644079104

Epoch: 6| Step: 8
Training loss: 0.2702216138911846
Validation loss: 2.2936136355909853

Epoch: 6| Step: 9
Training loss: 0.35119111259816893
Validation loss: 2.2625098900903735

Epoch: 6| Step: 10
Training loss: 0.32245993102833304
Validation loss: 2.255483752928499

Epoch: 6| Step: 11
Training loss: 0.224243745507165
Validation loss: 2.291383783625053

Epoch: 6| Step: 12
Training loss: 0.2500166738433418
Validation loss: 2.28253566970335

Epoch: 6| Step: 13
Training loss: 0.24163298036388858
Validation loss: 2.2911101156718305

Epoch: 476| Step: 0
Training loss: 0.23806192904459217
Validation loss: 2.284788392283368

Epoch: 6| Step: 1
Training loss: 0.2589758720555608
Validation loss: 2.271253762711813

Epoch: 6| Step: 2
Training loss: 0.3141798288946653
Validation loss: 2.2730123203149

Epoch: 6| Step: 3
Training loss: 0.3960208720440768
Validation loss: 2.2839341941624243

Epoch: 6| Step: 4
Training loss: 0.2239972605622899
Validation loss: 2.2816073690789427

Epoch: 6| Step: 5
Training loss: 0.2378465329730279
Validation loss: 2.260463104708595

Epoch: 6| Step: 6
Training loss: 0.24323043530206162
Validation loss: 2.257389297333894

Epoch: 6| Step: 7
Training loss: 0.25637167681823764
Validation loss: 2.2913624359253104

Epoch: 6| Step: 8
Training loss: 0.13992623395322887
Validation loss: 2.2588065839814373

Epoch: 6| Step: 9
Training loss: 0.2698474494358001
Validation loss: 2.3054923855759157

Epoch: 6| Step: 10
Training loss: 0.20361781858516126
Validation loss: 2.307406383156939

Epoch: 6| Step: 11
Training loss: 0.2669816992484917
Validation loss: 2.309934335507436

Epoch: 6| Step: 12
Training loss: 0.32254701524881224
Validation loss: 2.3003686557626946

Epoch: 6| Step: 13
Training loss: 0.256652694139659
Validation loss: 2.2764161512557672

Epoch: 477| Step: 0
Training loss: 0.23587598188122116
Validation loss: 2.266660011038639

Epoch: 6| Step: 1
Training loss: 0.3622706723761365
Validation loss: 2.289522265891729

Epoch: 6| Step: 2
Training loss: 0.22411825971951618
Validation loss: 2.316959445849263

Epoch: 6| Step: 3
Training loss: 0.3916400500479191
Validation loss: 2.2658768963270886

Epoch: 6| Step: 4
Training loss: 0.2052378350479167
Validation loss: 2.345373295134328

Epoch: 6| Step: 5
Training loss: 0.2535966452752362
Validation loss: 2.2882925915222665

Epoch: 6| Step: 6
Training loss: 0.27609638655417773
Validation loss: 2.2689000891859354

Epoch: 6| Step: 7
Training loss: 0.2134546368115859
Validation loss: 2.288180010809082

Epoch: 6| Step: 8
Training loss: 0.2132154663696334
Validation loss: 2.291630360286836

Epoch: 6| Step: 9
Training loss: 0.29965303045777625
Validation loss: 2.25614343041035

Epoch: 6| Step: 10
Training loss: 0.3211309629534836
Validation loss: 2.263714855489311

Epoch: 6| Step: 11
Training loss: 0.33556024304940235
Validation loss: 2.2896851353550463

Epoch: 6| Step: 12
Training loss: 0.17462536868723436
Validation loss: 2.253310302719196

Epoch: 6| Step: 13
Training loss: 0.18524079424717166
Validation loss: 2.2740651473574727

Epoch: 478| Step: 0
Training loss: 0.23962574908139944
Validation loss: 2.27392972181712

Epoch: 6| Step: 1
Training loss: 0.20284250679569568
Validation loss: 2.2772711103751195

Epoch: 6| Step: 2
Training loss: 0.17970105824941707
Validation loss: 2.233836929516866

Epoch: 6| Step: 3
Training loss: 0.2408179661248984
Validation loss: 2.261119756622199

Epoch: 6| Step: 4
Training loss: 0.21906495411269591
Validation loss: 2.246368179141967

Epoch: 6| Step: 5
Training loss: 0.27308006084952313
Validation loss: 2.295801504391046

Epoch: 6| Step: 6
Training loss: 0.2024454524017252
Validation loss: 2.259163624930178

Epoch: 6| Step: 7
Training loss: 0.23286490330638215
Validation loss: 2.2544450650256858

Epoch: 6| Step: 8
Training loss: 0.21671632180919795
Validation loss: 2.2714837627240594

Epoch: 6| Step: 9
Training loss: 0.24756146792336556
Validation loss: 2.2585835091882007

Epoch: 6| Step: 10
Training loss: 0.27806889739665314
Validation loss: 2.2951090937873646

Epoch: 6| Step: 11
Training loss: 0.22788701446571036
Validation loss: 2.286333125574051

Epoch: 6| Step: 12
Training loss: 0.3449092089356821
Validation loss: 2.2665580845050903

Epoch: 6| Step: 13
Training loss: 0.2564444804123615
Validation loss: 2.2333132481976627

Epoch: 479| Step: 0
Training loss: 0.22931909729665462
Validation loss: 2.288763771050423

Epoch: 6| Step: 1
Training loss: 0.2995809907162843
Validation loss: 2.276294080295917

Epoch: 6| Step: 2
Training loss: 0.3220622258880118
Validation loss: 2.2772423191067355

Epoch: 6| Step: 3
Training loss: 0.19486411123642888
Validation loss: 2.284053525556932

Epoch: 6| Step: 4
Training loss: 0.2565774233028898
Validation loss: 2.2639265951151244

Epoch: 6| Step: 5
Training loss: 0.31141347349433723
Validation loss: 2.2856430708911697

Epoch: 6| Step: 6
Training loss: 0.27219802039013075
Validation loss: 2.2745067271269184

Epoch: 6| Step: 7
Training loss: 0.29143878714211574
Validation loss: 2.2733266220058965

Epoch: 6| Step: 8
Training loss: 0.1736278290779013
Validation loss: 2.247770582466135

Epoch: 6| Step: 9
Training loss: 0.30835337874403346
Validation loss: 2.237394706550202

Epoch: 6| Step: 10
Training loss: 0.29504719023366227
Validation loss: 2.262731251920309

Epoch: 6| Step: 11
Training loss: 0.24591468927006815
Validation loss: 2.2502052337151404

Epoch: 6| Step: 12
Training loss: 0.2698622205649494
Validation loss: 2.2589145509545734

Epoch: 6| Step: 13
Training loss: 0.25469987523255966
Validation loss: 2.249010574937889

Epoch: 480| Step: 0
Training loss: 0.3243180318284525
Validation loss: 2.2886217059615714

Epoch: 6| Step: 1
Training loss: 0.2538871904702305
Validation loss: 2.291582484577577

Epoch: 6| Step: 2
Training loss: 0.2596810568917979
Validation loss: 2.3141416444708907

Epoch: 6| Step: 3
Training loss: 0.284558545080728
Validation loss: 2.3064394741225116

Epoch: 6| Step: 4
Training loss: 0.3254540934492644
Validation loss: 2.3111018258477816

Epoch: 6| Step: 5
Training loss: 0.26565686203092176
Validation loss: 2.2718733992608127

Epoch: 6| Step: 6
Training loss: 0.21454445191928445
Validation loss: 2.2560743265279948

Epoch: 6| Step: 7
Training loss: 0.13283922122970204
Validation loss: 2.288904646811001

Epoch: 6| Step: 8
Training loss: 0.1442137530113118
Validation loss: 2.288551594697175

Epoch: 6| Step: 9
Training loss: 0.15579867746635928
Validation loss: 2.28962940057489

Epoch: 6| Step: 10
Training loss: 0.21990645779763437
Validation loss: 2.2725065145059955

Epoch: 6| Step: 11
Training loss: 0.17452343632958345
Validation loss: 2.294654508126073

Epoch: 6| Step: 12
Training loss: 0.2957704474989925
Validation loss: 2.2889811009851337

Epoch: 6| Step: 13
Training loss: 0.28945562333278496
Validation loss: 2.2888771737235087

Epoch: 481| Step: 0
Training loss: 0.29510979633681944
Validation loss: 2.2972101326034537

Epoch: 6| Step: 1
Training loss: 0.18978591084955942
Validation loss: 2.2988691431630217

Epoch: 6| Step: 2
Training loss: 0.2132138414719475
Validation loss: 2.31893330181118

Epoch: 6| Step: 3
Training loss: 0.21169668906163017
Validation loss: 2.2916123354858073

Epoch: 6| Step: 4
Training loss: 0.36219214159120006
Validation loss: 2.2802233018611813

Epoch: 6| Step: 5
Training loss: 0.277451453988711
Validation loss: 2.2997183295556414

Epoch: 6| Step: 6
Training loss: 0.29221533219483803
Validation loss: 2.2598645697725286

Epoch: 6| Step: 7
Training loss: 0.2682159229206464
Validation loss: 2.2600062359524102

Epoch: 6| Step: 8
Training loss: 0.23379467006959884
Validation loss: 2.2874390331683463

Epoch: 6| Step: 9
Training loss: 0.23791516432702578
Validation loss: 2.2803408844888824

Epoch: 6| Step: 10
Training loss: 0.34150770761775673
Validation loss: 2.3302219087503406

Epoch: 6| Step: 11
Training loss: 0.31561294051067124
Validation loss: 2.2527262277920506

Epoch: 6| Step: 12
Training loss: 0.2580617942042826
Validation loss: 2.2590872961736097

Epoch: 6| Step: 13
Training loss: 0.27671093001858793
Validation loss: 2.268514942921814

Epoch: 482| Step: 0
Training loss: 0.34918539882196387
Validation loss: 2.2832059792228026

Epoch: 6| Step: 1
Training loss: 0.289608774279745
Validation loss: 2.2662676634172927

Epoch: 6| Step: 2
Training loss: 0.20681109508856874
Validation loss: 2.278080711405193

Epoch: 6| Step: 3
Training loss: 0.21020922507206252
Validation loss: 2.2764719738892993

Epoch: 6| Step: 4
Training loss: 0.2838791375448699
Validation loss: 2.2524306360926256

Epoch: 6| Step: 5
Training loss: 0.261419595011782
Validation loss: 2.2528665966718266

Epoch: 6| Step: 6
Training loss: 0.260845935197696
Validation loss: 2.2759085615564385

Epoch: 6| Step: 7
Training loss: 0.29916493751155443
Validation loss: 2.278471539325554

Epoch: 6| Step: 8
Training loss: 0.18517412590298482
Validation loss: 2.2582697421853415

Epoch: 6| Step: 9
Training loss: 0.17002914046598636
Validation loss: 2.304836824396494

Epoch: 6| Step: 10
Training loss: 0.2687458537025862
Validation loss: 2.256307687840862

Epoch: 6| Step: 11
Training loss: 0.2236520350827799
Validation loss: 2.2838375275084406

Epoch: 6| Step: 12
Training loss: 0.43123815077936556
Validation loss: 2.326099470427947

Epoch: 6| Step: 13
Training loss: 0.3439415376402987
Validation loss: 2.2103886906048613

Epoch: 483| Step: 0
Training loss: 0.18084522134259137
Validation loss: 2.2629409149655775

Epoch: 6| Step: 1
Training loss: 0.23842827372867875
Validation loss: 2.2485734072733834

Epoch: 6| Step: 2
Training loss: 0.2733486031031358
Validation loss: 2.2622882255651917

Epoch: 6| Step: 3
Training loss: 0.23604436658345962
Validation loss: 2.2761349051529187

Epoch: 6| Step: 4
Training loss: 0.3247014554340931
Validation loss: 2.283201915434992

Epoch: 6| Step: 5
Training loss: 0.18291250615359433
Validation loss: 2.2824223871952465

Epoch: 6| Step: 6
Training loss: 0.2673066565075815
Validation loss: 2.215510461426565

Epoch: 6| Step: 7
Training loss: 0.21352976478965666
Validation loss: 2.2430198179087477

Epoch: 6| Step: 8
Training loss: 0.2994367472695492
Validation loss: 2.2282137453187185

Epoch: 6| Step: 9
Training loss: 0.2639051747455453
Validation loss: 2.2597363293418504

Epoch: 6| Step: 10
Training loss: 0.2656825508153853
Validation loss: 2.271982433047459

Epoch: 6| Step: 11
Training loss: 0.3306074694509113
Validation loss: 2.3194781514787715

Epoch: 6| Step: 12
Training loss: 0.18952444051726144
Validation loss: 2.2827423822982373

Epoch: 6| Step: 13
Training loss: 0.36224169324876987
Validation loss: 2.2415503328713666

Epoch: 484| Step: 0
Training loss: 0.2866917641644635
Validation loss: 2.2912180605984593

Epoch: 6| Step: 1
Training loss: 0.24724403124346098
Validation loss: 2.269671621265775

Epoch: 6| Step: 2
Training loss: 0.2646351772237945
Validation loss: 2.284252942429931

Epoch: 6| Step: 3
Training loss: 0.36536407207834803
Validation loss: 2.262886523324208

Epoch: 6| Step: 4
Training loss: 0.22448365383280613
Validation loss: 2.274416359943536

Epoch: 6| Step: 5
Training loss: 0.21789439652530868
Validation loss: 2.307044062593395

Epoch: 6| Step: 6
Training loss: 0.23827642686058634
Validation loss: 2.316976218731412

Epoch: 6| Step: 7
Training loss: 0.20531609669965017
Validation loss: 2.3088733140211866

Epoch: 6| Step: 8
Training loss: 0.20245726578930778
Validation loss: 2.2954283156843465

Epoch: 6| Step: 9
Training loss: 0.27283517710502186
Validation loss: 2.2908866479617465

Epoch: 6| Step: 10
Training loss: 0.19621654138720915
Validation loss: 2.258877442562293

Epoch: 6| Step: 11
Training loss: 0.284301535056368
Validation loss: 2.2958824452468334

Epoch: 6| Step: 12
Training loss: 0.1955774512867921
Validation loss: 2.2432879539801056

Epoch: 6| Step: 13
Training loss: 0.2583081653599552
Validation loss: 2.280733746854114

Epoch: 485| Step: 0
Training loss: 0.2819279077192387
Validation loss: 2.285452729470644

Epoch: 6| Step: 1
Training loss: 0.15139311291574334
Validation loss: 2.282064736553832

Epoch: 6| Step: 2
Training loss: 0.17135381790365267
Validation loss: 2.276773607131011

Epoch: 6| Step: 3
Training loss: 0.21830680774002714
Validation loss: 2.2726917594967175

Epoch: 6| Step: 4
Training loss: 0.17599364270844686
Validation loss: 2.2369606245261995

Epoch: 6| Step: 5
Training loss: 0.15858583313109628
Validation loss: 2.298568032415826

Epoch: 6| Step: 6
Training loss: 0.3597761486059254
Validation loss: 2.2475971000666255

Epoch: 6| Step: 7
Training loss: 0.2025802533633361
Validation loss: 2.272789914250467

Epoch: 6| Step: 8
Training loss: 0.3025532826873618
Validation loss: 2.1991405303758826

Epoch: 6| Step: 9
Training loss: 0.2523299216387723
Validation loss: 2.228212407819953

Epoch: 6| Step: 10
Training loss: 0.37704035881159365
Validation loss: 2.255123979666256

Epoch: 6| Step: 11
Training loss: 0.2762140449583263
Validation loss: 2.244113126253727

Epoch: 6| Step: 12
Training loss: 0.2093235988294185
Validation loss: 2.259340431437857

Epoch: 6| Step: 13
Training loss: 0.2562346872546121
Validation loss: 2.251030068027095

Epoch: 486| Step: 0
Training loss: 0.21875488752627065
Validation loss: 2.2543255500245456

Epoch: 6| Step: 1
Training loss: 0.2381035188813031
Validation loss: 2.2288207174889383

Epoch: 6| Step: 2
Training loss: 0.2959744447086363
Validation loss: 2.2151084172142057

Epoch: 6| Step: 3
Training loss: 0.30747045014449603
Validation loss: 2.2559605167058643

Epoch: 6| Step: 4
Training loss: 0.16713726144519284
Validation loss: 2.2576732130546664

Epoch: 6| Step: 5
Training loss: 0.20679310831603404
Validation loss: 2.2605266514988576

Epoch: 6| Step: 6
Training loss: 0.3161876299952647
Validation loss: 2.296359387088505

Epoch: 6| Step: 7
Training loss: 0.27444198574934153
Validation loss: 2.2906632972280985

Epoch: 6| Step: 8
Training loss: 0.2137226853290728
Validation loss: 2.2725952615834606

Epoch: 6| Step: 9
Training loss: 0.264199414394518
Validation loss: 2.28128769377481

Epoch: 6| Step: 10
Training loss: 0.2827402607457211
Validation loss: 2.272379319763918

Epoch: 6| Step: 11
Training loss: 0.2179603458821613
Validation loss: 2.2901588392350414

Epoch: 6| Step: 12
Training loss: 0.2983495083256489
Validation loss: 2.2614078955968426

Epoch: 6| Step: 13
Training loss: 0.23579396814586023
Validation loss: 2.2977841712287597

Epoch: 487| Step: 0
Training loss: 0.2950392988262849
Validation loss: 2.285898802006651

Epoch: 6| Step: 1
Training loss: 0.23783722138707555
Validation loss: 2.277073952695389

Epoch: 6| Step: 2
Training loss: 0.33330305776592617
Validation loss: 2.2611672932078073

Epoch: 6| Step: 3
Training loss: 0.33811253223243454
Validation loss: 2.2928134014267725

Epoch: 6| Step: 4
Training loss: 0.3259615762693021
Validation loss: 2.2610865682878414

Epoch: 6| Step: 5
Training loss: 0.32234990722870294
Validation loss: 2.2799905148108093

Epoch: 6| Step: 6
Training loss: 0.4217528060272521
Validation loss: 2.283153645436425

Epoch: 6| Step: 7
Training loss: 0.260582049624867
Validation loss: 2.272825475507364

Epoch: 6| Step: 8
Training loss: 0.17346299323458342
Validation loss: 2.2729678548287207

Epoch: 6| Step: 9
Training loss: 0.273073007972979
Validation loss: 2.244419488935986

Epoch: 6| Step: 10
Training loss: 0.23580504292947044
Validation loss: 2.2329052090112116

Epoch: 6| Step: 11
Training loss: 0.23508432657131614
Validation loss: 2.241141098363793

Epoch: 6| Step: 12
Training loss: 0.2671042513404757
Validation loss: 2.2610189247891537

Epoch: 6| Step: 13
Training loss: 0.3606515891455942
Validation loss: 2.20637524963404

Epoch: 488| Step: 0
Training loss: 0.38044595043008955
Validation loss: 2.2581863973706593

Epoch: 6| Step: 1
Training loss: 0.2935287844865949
Validation loss: 2.217070727581035

Epoch: 6| Step: 2
Training loss: 0.24622936145348615
Validation loss: 2.1914542289826247

Epoch: 6| Step: 3
Training loss: 0.24157127307688403
Validation loss: 2.229179833869431

Epoch: 6| Step: 4
Training loss: 0.2926426280365209
Validation loss: 2.2885549631428486

Epoch: 6| Step: 5
Training loss: 0.2729605056530871
Validation loss: 2.220614737678347

Epoch: 6| Step: 6
Training loss: 0.23425203117448756
Validation loss: 2.26578669354708

Epoch: 6| Step: 7
Training loss: 0.30899586613985497
Validation loss: 2.2418565849297276

Epoch: 6| Step: 8
Training loss: 0.2692324876075444
Validation loss: 2.221315387299383

Epoch: 6| Step: 9
Training loss: 0.2830425859758608
Validation loss: 2.259364244955168

Epoch: 6| Step: 10
Training loss: 0.3376321961971697
Validation loss: 2.258898446391791

Epoch: 6| Step: 11
Training loss: 0.2580757242326553
Validation loss: 2.2640612236951307

Epoch: 6| Step: 12
Training loss: 0.27325103396423384
Validation loss: 2.279924033472153

Epoch: 6| Step: 13
Training loss: 0.20709304067404735
Validation loss: 2.303687021805947

Epoch: 489| Step: 0
Training loss: 0.31930915183557357
Validation loss: 2.2916563958602554

Epoch: 6| Step: 1
Training loss: 0.2572416864466088
Validation loss: 2.2454924997745103

Epoch: 6| Step: 2
Training loss: 0.22207176724698036
Validation loss: 2.2343377241390945

Epoch: 6| Step: 3
Training loss: 0.35294010672629217
Validation loss: 2.3143453538056775

Epoch: 6| Step: 4
Training loss: 0.35795482653377003
Validation loss: 2.3098313682073077

Epoch: 6| Step: 5
Training loss: 0.35974280567676514
Validation loss: 2.2678966139743744

Epoch: 6| Step: 6
Training loss: 0.28129910993967505
Validation loss: 2.314290513390236

Epoch: 6| Step: 7
Training loss: 0.43378621203066975
Validation loss: 2.243378476878511

Epoch: 6| Step: 8
Training loss: 0.3962751503613265
Validation loss: 2.269399519843654

Epoch: 6| Step: 9
Training loss: 0.3268989408708104
Validation loss: 2.308938677860527

Epoch: 6| Step: 10
Training loss: 0.34696114089113617
Validation loss: 2.3061566514004515

Epoch: 6| Step: 11
Training loss: 0.21983381408871894
Validation loss: 2.2669054994791753

Epoch: 6| Step: 12
Training loss: 0.2558700617531265
Validation loss: 2.2881243175153734

Epoch: 6| Step: 13
Training loss: 0.2857257434131371
Validation loss: 2.2658578687234785

Epoch: 490| Step: 0
Training loss: 0.293513313266077
Validation loss: 2.266900398554545

Epoch: 6| Step: 1
Training loss: 0.3038695923729321
Validation loss: 2.2363812347280283

Epoch: 6| Step: 2
Training loss: 0.17723730816886232
Validation loss: 2.275452384056019

Epoch: 6| Step: 3
Training loss: 0.22306146056258247
Validation loss: 2.2347080542689084

Epoch: 6| Step: 4
Training loss: 0.19394808072883393
Validation loss: 2.214086179891559

Epoch: 6| Step: 5
Training loss: 0.3397270418786356
Validation loss: 2.226172108473651

Epoch: 6| Step: 6
Training loss: 0.2874234227115221
Validation loss: 2.2390601559875387

Epoch: 6| Step: 7
Training loss: 0.21836399182674732
Validation loss: 2.2420482082719437

Epoch: 6| Step: 8
Training loss: 0.22294101574678607
Validation loss: 2.2330001567112205

Epoch: 6| Step: 9
Training loss: 0.2310477596737345
Validation loss: 2.281741093767771

Epoch: 6| Step: 10
Training loss: 0.2768206835226356
Validation loss: 2.250121448912516

Epoch: 6| Step: 11
Training loss: 0.3362751528042991
Validation loss: 2.289711835157539

Epoch: 6| Step: 12
Training loss: 0.3184381633223793
Validation loss: 2.2446533184094597

Epoch: 6| Step: 13
Training loss: 0.346193257099579
Validation loss: 2.2589259410593696

Epoch: 491| Step: 0
Training loss: 0.24602387965319078
Validation loss: 2.2489921820529983

Epoch: 6| Step: 1
Training loss: 0.2123291766546072
Validation loss: 2.2284810773716415

Epoch: 6| Step: 2
Training loss: 0.33382045895063206
Validation loss: 2.245126249392688

Epoch: 6| Step: 3
Training loss: 0.2793331789550795
Validation loss: 2.296946042231589

Epoch: 6| Step: 4
Training loss: 0.4470461677640873
Validation loss: 2.2482567851291075

Epoch: 6| Step: 5
Training loss: 0.30928837786914803
Validation loss: 2.258055202018848

Epoch: 6| Step: 6
Training loss: 0.17744932267244365
Validation loss: 2.2440229782904497

Epoch: 6| Step: 7
Training loss: 0.38085964887560264
Validation loss: 2.280257483786647

Epoch: 6| Step: 8
Training loss: 0.2883149481412464
Validation loss: 2.2523135282562103

Epoch: 6| Step: 9
Training loss: 0.3568053217272902
Validation loss: 2.2714348500899884

Epoch: 6| Step: 10
Training loss: 0.38493368670715794
Validation loss: 2.2375933981072595

Epoch: 6| Step: 11
Training loss: 0.2083735228556524
Validation loss: 2.2644675619742047

Epoch: 6| Step: 12
Training loss: 0.20983382524665498
Validation loss: 2.22527482125025

Epoch: 6| Step: 13
Training loss: 0.44167766834747885
Validation loss: 2.2163226321948817

Epoch: 492| Step: 0
Training loss: 0.4180757082693119
Validation loss: 2.214434335265197

Epoch: 6| Step: 1
Training loss: 0.22369826912250812
Validation loss: 2.260634175982356

Epoch: 6| Step: 2
Training loss: 0.24514415486235724
Validation loss: 2.274115794437435

Epoch: 6| Step: 3
Training loss: 0.3211807021865281
Validation loss: 2.2345370076096014

Epoch: 6| Step: 4
Training loss: 0.25494435177662556
Validation loss: 2.2442775648017146

Epoch: 6| Step: 5
Training loss: 0.25623553049127185
Validation loss: 2.2457729121510157

Epoch: 6| Step: 6
Training loss: 0.2642786320889004
Validation loss: 2.234458103724118

Epoch: 6| Step: 7
Training loss: 0.2477642536821827
Validation loss: 2.262934575926333

Epoch: 6| Step: 8
Training loss: 0.2373969679631403
Validation loss: 2.2685083391937213

Epoch: 6| Step: 9
Training loss: 0.2503153481005918
Validation loss: 2.2833535150578124

Epoch: 6| Step: 10
Training loss: 0.2169785296985826
Validation loss: 2.2630367973534233

Epoch: 6| Step: 11
Training loss: 0.18108679312902906
Validation loss: 2.2765775409062856

Epoch: 6| Step: 12
Training loss: 0.34655555329442234
Validation loss: 2.2600331369294397

Epoch: 6| Step: 13
Training loss: 0.23689388305565318
Validation loss: 2.2871806163209087

Epoch: 493| Step: 0
Training loss: 0.2567309175743404
Validation loss: 2.2649004512100523

Epoch: 6| Step: 1
Training loss: 0.24771232271043261
Validation loss: 2.295556457656707

Epoch: 6| Step: 2
Training loss: 0.20844037564422968
Validation loss: 2.3149061658282744

Epoch: 6| Step: 3
Training loss: 0.31910108977418333
Validation loss: 2.2772796866128835

Epoch: 6| Step: 4
Training loss: 0.26631369786954395
Validation loss: 2.3098673741688716

Epoch: 6| Step: 5
Training loss: 0.2596054587239567
Validation loss: 2.3107110226114616

Epoch: 6| Step: 6
Training loss: 0.21903947001710233
Validation loss: 2.2701929017586533

Epoch: 6| Step: 7
Training loss: 0.14648700711746557
Validation loss: 2.2881765028835934

Epoch: 6| Step: 8
Training loss: 0.2406617681477209
Validation loss: 2.2906321589213623

Epoch: 6| Step: 9
Training loss: 0.28669815717124175
Validation loss: 2.3172899761592185

Epoch: 6| Step: 10
Training loss: 0.3459567524343472
Validation loss: 2.2795058947001157

Epoch: 6| Step: 11
Training loss: 0.23517773172092288
Validation loss: 2.2557354076941842

Epoch: 6| Step: 12
Training loss: 0.2574982751168191
Validation loss: 2.229207213796565

Epoch: 6| Step: 13
Training loss: 0.31991528095534166
Validation loss: 2.2738611934205593

Epoch: 494| Step: 0
Training loss: 0.24536108519888472
Validation loss: 2.252395299735517

Epoch: 6| Step: 1
Training loss: 0.20172353676775737
Validation loss: 2.246008936068523

Epoch: 6| Step: 2
Training loss: 0.24060335743167668
Validation loss: 2.2559744493162626

Epoch: 6| Step: 3
Training loss: 0.25133635562300966
Validation loss: 2.289267486316628

Epoch: 6| Step: 4
Training loss: 0.1593102113081211
Validation loss: 2.2269300547833786

Epoch: 6| Step: 5
Training loss: 0.12495713318486083
Validation loss: 2.2553907119504477

Epoch: 6| Step: 6
Training loss: 0.21614586971849495
Validation loss: 2.2838530560399786

Epoch: 6| Step: 7
Training loss: 0.3285218745123667
Validation loss: 2.262177890167503

Epoch: 6| Step: 8
Training loss: 0.2312360856019813
Validation loss: 2.250385463333236

Epoch: 6| Step: 9
Training loss: 0.25164480343854856
Validation loss: 2.2790559904527825

Epoch: 6| Step: 10
Training loss: 0.17491209470488897
Validation loss: 2.2449843522385313

Epoch: 6| Step: 11
Training loss: 0.2423577863636129
Validation loss: 2.2584187926654287

Epoch: 6| Step: 12
Training loss: 0.25987872192888195
Validation loss: 2.2490177217963856

Epoch: 6| Step: 13
Training loss: 0.24479550838837713
Validation loss: 2.2680723980679733

Epoch: 495| Step: 0
Training loss: 0.18706326483950272
Validation loss: 2.2319698326625543

Epoch: 6| Step: 1
Training loss: 0.2350609278830445
Validation loss: 2.2847889140353006

Epoch: 6| Step: 2
Training loss: 0.3166554258677097
Validation loss: 2.2725700392664425

Epoch: 6| Step: 3
Training loss: 0.1767240618523814
Validation loss: 2.276040037199669

Epoch: 6| Step: 4
Training loss: 0.27222188765208993
Validation loss: 2.238816548460077

Epoch: 6| Step: 5
Training loss: 0.20023952089053487
Validation loss: 2.250227660564777

Epoch: 6| Step: 6
Training loss: 0.272013566999743
Validation loss: 2.2794472525751814

Epoch: 6| Step: 7
Training loss: 0.16346978227052059
Validation loss: 2.2697771806912623

Epoch: 6| Step: 8
Training loss: 0.2339780067889148
Validation loss: 2.298527034811029

Epoch: 6| Step: 9
Training loss: 0.2852194598437684
Validation loss: 2.286051265712971

Epoch: 6| Step: 10
Training loss: 0.24956231248171684
Validation loss: 2.30611300591383

Epoch: 6| Step: 11
Training loss: 0.2107517519557893
Validation loss: 2.301674177883561

Epoch: 6| Step: 12
Training loss: 0.26558814073522047
Validation loss: 2.2637177342840213

Epoch: 6| Step: 13
Training loss: 0.2936448751196914
Validation loss: 2.290993788220251

Epoch: 496| Step: 0
Training loss: 0.24673304701795545
Validation loss: 2.2956372427118423

Epoch: 6| Step: 1
Training loss: 0.20745906173211448
Validation loss: 2.281928026998442

Epoch: 6| Step: 2
Training loss: 0.2906548228395436
Validation loss: 2.2510627603197193

Epoch: 6| Step: 3
Training loss: 0.29856254893704387
Validation loss: 2.2831363891211676

Epoch: 6| Step: 4
Training loss: 0.15903330431927046
Validation loss: 2.255633137245119

Epoch: 6| Step: 5
Training loss: 0.29481362888944124
Validation loss: 2.2672372978590176

Epoch: 6| Step: 6
Training loss: 0.3100556380964563
Validation loss: 2.254182848164222

Epoch: 6| Step: 7
Training loss: 0.2834672682585378
Validation loss: 2.2622347316175406

Epoch: 6| Step: 8
Training loss: 0.23691554403195614
Validation loss: 2.260104633950184

Epoch: 6| Step: 9
Training loss: 0.32654598048283984
Validation loss: 2.301701670865501

Epoch: 6| Step: 10
Training loss: 0.30436361655816524
Validation loss: 2.2316954135206593

Epoch: 6| Step: 11
Training loss: 0.6481543232860779
Validation loss: 2.231386404560701

Epoch: 6| Step: 12
Training loss: 0.3308257039669379
Validation loss: 2.258069332875038

Epoch: 6| Step: 13
Training loss: 0.19901358567880895
Validation loss: 2.2219818111022014

Epoch: 497| Step: 0
Training loss: 0.4032014389904585
Validation loss: 2.2904948417457267

Epoch: 6| Step: 1
Training loss: 0.37095985004609583
Validation loss: 2.251346909073254

Epoch: 6| Step: 2
Training loss: 0.377584926071181
Validation loss: 2.2781630754886484

Epoch: 6| Step: 3
Training loss: 0.2832023357511901
Validation loss: 2.234166213375483

Epoch: 6| Step: 4
Training loss: 0.2803449107626473
Validation loss: 2.242771006297736

Epoch: 6| Step: 5
Training loss: 0.2243315844783543
Validation loss: 2.2579510568169257

Epoch: 6| Step: 6
Training loss: 0.31812792831002473
Validation loss: 2.259251840839239

Epoch: 6| Step: 7
Training loss: 0.44831920618657134
Validation loss: 2.2607814008196985

Epoch: 6| Step: 8
Training loss: 0.24565269668352116
Validation loss: 2.284170780542346

Epoch: 6| Step: 9
Training loss: 0.4023887460973077
Validation loss: 2.2706787220061253

Epoch: 6| Step: 10
Training loss: 0.39965374757104233
Validation loss: 2.2537579589579093

Epoch: 6| Step: 11
Training loss: 0.4329205002980609
Validation loss: 2.2640710873086656

Epoch: 6| Step: 12
Training loss: 0.3394927371565671
Validation loss: 2.28041820951475

Epoch: 6| Step: 13
Training loss: 0.3088562368138085
Validation loss: 2.2931871543037645

Epoch: 498| Step: 0
Training loss: 0.24263886721680133
Validation loss: 2.316052757768038

Epoch: 6| Step: 1
Training loss: 0.2891510750408396
Validation loss: 2.2611913862305797

Epoch: 6| Step: 2
Training loss: 0.2347011601425684
Validation loss: 2.23890222054302

Epoch: 6| Step: 3
Training loss: 0.14448543415236229
Validation loss: 2.2675439447044172

Epoch: 6| Step: 4
Training loss: 0.43467532828517097
Validation loss: 2.26346883666878

Epoch: 6| Step: 5
Training loss: 0.41039908350475957
Validation loss: 2.2429522496131065

Epoch: 6| Step: 6
Training loss: 0.27683387147335164
Validation loss: 2.2460069103315825

Epoch: 6| Step: 7
Training loss: 0.3164045545744507
Validation loss: 2.2391308408690924

Epoch: 6| Step: 8
Training loss: 0.23747802808417093
Validation loss: 2.2373572856348796

Epoch: 6| Step: 9
Training loss: 0.5456957500508275
Validation loss: 2.2885979190719947

Epoch: 6| Step: 10
Training loss: 0.4912457918273218
Validation loss: 2.2641213261324884

Epoch: 6| Step: 11
Training loss: 0.24784395222745212
Validation loss: 2.233426174919537

Epoch: 6| Step: 12
Training loss: 0.260455398858134
Validation loss: 2.262524520010531

Epoch: 6| Step: 13
Training loss: 0.2196398415563391
Validation loss: 2.2786346754981652

Epoch: 499| Step: 0
Training loss: 0.2866078622288625
Validation loss: 2.29009019785104

Epoch: 6| Step: 1
Training loss: 0.35100167364552876
Validation loss: 2.2821203861939696

Epoch: 6| Step: 2
Training loss: 0.3195438699631821
Validation loss: 2.2521570162463216

Epoch: 6| Step: 3
Training loss: 0.2400119651354972
Validation loss: 2.269587740958341

Epoch: 6| Step: 4
Training loss: 0.38092224384704504
Validation loss: 2.2592999179828874

Epoch: 6| Step: 5
Training loss: 0.23642916135329523
Validation loss: 2.2938745844214252

Epoch: 6| Step: 6
Training loss: 0.2424452394664771
Validation loss: 2.251098276462392

Epoch: 6| Step: 7
Training loss: 0.2583915392357834
Validation loss: 2.319445412712377

Epoch: 6| Step: 8
Training loss: 0.311969712463869
Validation loss: 2.3023900191679463

Epoch: 6| Step: 9
Training loss: 0.1806591136357661
Validation loss: 2.2723727272660663

Epoch: 6| Step: 10
Training loss: 0.2281050294469625
Validation loss: 2.285368619869892

Epoch: 6| Step: 11
Training loss: 0.19290230414011628
Validation loss: 2.313051596143989

Epoch: 6| Step: 12
Training loss: 0.3391372527943667
Validation loss: 2.2288635855967174

Epoch: 6| Step: 13
Training loss: 0.17230007320254162
Validation loss: 2.3293910243209295

Epoch: 500| Step: 0
Training loss: 0.2508555911149135
Validation loss: 2.290756059117852

Epoch: 6| Step: 1
Training loss: 0.2315832684607642
Validation loss: 2.279138441335286

Epoch: 6| Step: 2
Training loss: 0.21520890502324447
Validation loss: 2.210240059741543

Epoch: 6| Step: 3
Training loss: 0.2016272529563682
Validation loss: 2.3049332309907724

Epoch: 6| Step: 4
Training loss: 0.22371139977928425
Validation loss: 2.2844254153733554

Epoch: 6| Step: 5
Training loss: 0.25792056044277467
Validation loss: 2.2691562975355763

Epoch: 6| Step: 6
Training loss: 0.17981746368796694
Validation loss: 2.256559197892229

Epoch: 6| Step: 7
Training loss: 0.34949569345653353
Validation loss: 2.274393603793997

Epoch: 6| Step: 8
Training loss: 0.27518785735970674
Validation loss: 2.296985563008907

Epoch: 6| Step: 9
Training loss: 0.3290649755951735
Validation loss: 2.2404590373200395

Epoch: 6| Step: 10
Training loss: 0.1965743312095143
Validation loss: 2.264871020206085

Epoch: 6| Step: 11
Training loss: 0.38178192302978325
Validation loss: 2.2575386699689175

Epoch: 6| Step: 12
Training loss: 0.26780924595889016
Validation loss: 2.244225571510093

Epoch: 6| Step: 13
Training loss: 0.32424007483522205
Validation loss: 2.2853101021035838

Epoch: 501| Step: 0
Training loss: 0.20108484033559237
Validation loss: 2.2526530148422803

Epoch: 6| Step: 1
Training loss: 0.26801075731223917
Validation loss: 2.2704363105480914

Epoch: 6| Step: 2
Training loss: 0.15079914070880301
Validation loss: 2.2467980825728526

Epoch: 6| Step: 3
Training loss: 0.34024242606201416
Validation loss: 2.266381955030271

Epoch: 6| Step: 4
Training loss: 0.20053299128017313
Validation loss: 2.288670563804597

Epoch: 6| Step: 5
Training loss: 0.2759136076851419
Validation loss: 2.280614651208468

Epoch: 6| Step: 6
Training loss: 0.17608182428387045
Validation loss: 2.3059219933456427

Epoch: 6| Step: 7
Training loss: 0.2063097166539866
Validation loss: 2.2370626650863388

Epoch: 6| Step: 8
Training loss: 0.2424792562785506
Validation loss: 2.264785558473418

Epoch: 6| Step: 9
Training loss: 0.25219168199855674
Validation loss: 2.274834429825768

Epoch: 6| Step: 10
Training loss: 0.2545291010213845
Validation loss: 2.2802079403038844

Epoch: 6| Step: 11
Training loss: 0.17283249873838377
Validation loss: 2.266583557802476

Epoch: 6| Step: 12
Training loss: 0.27870545091154114
Validation loss: 2.292131677323575

Epoch: 6| Step: 13
Training loss: 0.23019933308977883
Validation loss: 2.2885117285924297

Epoch: 502| Step: 0
Training loss: 0.1956867256831515
Validation loss: 2.2949411983893926

Epoch: 6| Step: 1
Training loss: 0.21688456093768482
Validation loss: 2.2699412918201296

Epoch: 6| Step: 2
Training loss: 0.12826632114295378
Validation loss: 2.2600568552376865

Epoch: 6| Step: 3
Training loss: 0.2722793849275691
Validation loss: 2.2790513438932445

Epoch: 6| Step: 4
Training loss: 0.24746581978260776
Validation loss: 2.272449956216305

Epoch: 6| Step: 5
Training loss: 0.2760785351130077
Validation loss: 2.293103640312943

Epoch: 6| Step: 6
Training loss: 0.1995017341882579
Validation loss: 2.2769498664386316

Epoch: 6| Step: 7
Training loss: 0.16336856268901895
Validation loss: 2.29612970695018

Epoch: 6| Step: 8
Training loss: 0.18744530476090077
Validation loss: 2.2677906778992374

Epoch: 6| Step: 9
Training loss: 0.20709324754153502
Validation loss: 2.246931279255305

Epoch: 6| Step: 10
Training loss: 0.2722359689025337
Validation loss: 2.312880192682497

Epoch: 6| Step: 11
Training loss: 0.27865096411333734
Validation loss: 2.263288376024111

Epoch: 6| Step: 12
Training loss: 0.21880628508834735
Validation loss: 2.257293623949959

Epoch: 6| Step: 13
Training loss: 0.311689494010157
Validation loss: 2.29916294698586

Epoch: 503| Step: 0
Training loss: 0.2838211682005458
Validation loss: 2.2637173568812647

Epoch: 6| Step: 1
Training loss: 0.2369367785149741
Validation loss: 2.2785298316129436

Epoch: 6| Step: 2
Training loss: 0.19039515646831484
Validation loss: 2.280412851301733

Epoch: 6| Step: 3
Training loss: 0.2738778519475412
Validation loss: 2.2711597318876775

Epoch: 6| Step: 4
Training loss: 0.3164151272882391
Validation loss: 2.2537818314597704

Epoch: 6| Step: 5
Training loss: 0.18850174177311171
Validation loss: 2.273062746113079

Epoch: 6| Step: 6
Training loss: 0.24730253802835436
Validation loss: 2.2612077116996643

Epoch: 6| Step: 7
Training loss: 0.22246850614591968
Validation loss: 2.267862569890432

Epoch: 6| Step: 8
Training loss: 0.16357626842524123
Validation loss: 2.2326148420600807

Epoch: 6| Step: 9
Training loss: 0.3251959310989682
Validation loss: 2.3057431836618076

Epoch: 6| Step: 10
Training loss: 0.1256286118472118
Validation loss: 2.277684495406248

Epoch: 6| Step: 11
Training loss: 0.2494477938528294
Validation loss: 2.246166539878622

Epoch: 6| Step: 12
Training loss: 0.22399982171605032
Validation loss: 2.275012088226509

Epoch: 6| Step: 13
Training loss: 0.2255727095255447
Validation loss: 2.3100082186625643

Epoch: 504| Step: 0
Training loss: 0.24221473971351776
Validation loss: 2.2609699351513464

Epoch: 6| Step: 1
Training loss: 0.33075618508380944
Validation loss: 2.2711016528527144

Epoch: 6| Step: 2
Training loss: 0.2082085692819334
Validation loss: 2.259522543944185

Epoch: 6| Step: 3
Training loss: 0.24774360890955271
Validation loss: 2.3271007119408966

Epoch: 6| Step: 4
Training loss: 0.18625585726034172
Validation loss: 2.2562957649837845

Epoch: 6| Step: 5
Training loss: 0.20494724820491317
Validation loss: 2.2687798907059764

Epoch: 6| Step: 6
Training loss: 0.2589181685941794
Validation loss: 2.3099607238485595

Epoch: 6| Step: 7
Training loss: 0.19875832252351536
Validation loss: 2.26218865783243

Epoch: 6| Step: 8
Training loss: 0.3821530598416748
Validation loss: 2.297612450303367

Epoch: 6| Step: 9
Training loss: 0.18242666944783092
Validation loss: 2.2344881753780066

Epoch: 6| Step: 10
Training loss: 0.2525357894508342
Validation loss: 2.255136419710506

Epoch: 6| Step: 11
Training loss: 0.1634658796313291
Validation loss: 2.291710390771993

Epoch: 6| Step: 12
Training loss: 0.30323474509794063
Validation loss: 2.249835573475579

Epoch: 6| Step: 13
Training loss: 0.2741050473617257
Validation loss: 2.262967544004328

Epoch: 505| Step: 0
Training loss: 0.23980333068433987
Validation loss: 2.28890291076468

Epoch: 6| Step: 1
Training loss: 0.25739818573981466
Validation loss: 2.259795175247608

Epoch: 6| Step: 2
Training loss: 0.30745609243280847
Validation loss: 2.2450105482220377

Epoch: 6| Step: 3
Training loss: 0.2716720398979018
Validation loss: 2.2976268999477094

Epoch: 6| Step: 4
Training loss: 0.3075701117446718
Validation loss: 2.344928207952355

Epoch: 6| Step: 5
Training loss: 0.17874741312302542
Validation loss: 2.282104018793621

Epoch: 6| Step: 6
Training loss: 0.3614446915938947
Validation loss: 2.2585343875514945

Epoch: 6| Step: 7
Training loss: 0.24102420760690094
Validation loss: 2.2566017151486366

Epoch: 6| Step: 8
Training loss: 0.3323227892723581
Validation loss: 2.308094329946987

Epoch: 6| Step: 9
Training loss: 0.176219563257215
Validation loss: 2.28055167287552

Epoch: 6| Step: 10
Training loss: 0.3125181431271927
Validation loss: 2.2713255363420477

Epoch: 6| Step: 11
Training loss: 0.22114693908367047
Validation loss: 2.2706701820863016

Epoch: 6| Step: 12
Training loss: 0.2531495777018862
Validation loss: 2.2510517452590424

Epoch: 6| Step: 13
Training loss: 0.3557697111996918
Validation loss: 2.27584873548576

Epoch: 506| Step: 0
Training loss: 0.22006968516239692
Validation loss: 2.2620487444567097

Epoch: 6| Step: 1
Training loss: 0.2452675407661954
Validation loss: 2.3070213785292957

Epoch: 6| Step: 2
Training loss: 0.24713473177547973
Validation loss: 2.2359174370726387

Epoch: 6| Step: 3
Training loss: 0.23045512336921323
Validation loss: 2.2243350660600414

Epoch: 6| Step: 4
Training loss: 0.2892101014099756
Validation loss: 2.254183147837899

Epoch: 6| Step: 5
Training loss: 0.22661604741777264
Validation loss: 2.2535064007623262

Epoch: 6| Step: 6
Training loss: 0.1749844505861032
Validation loss: 2.273818990154624

Epoch: 6| Step: 7
Training loss: 0.20198963211617943
Validation loss: 2.2154322430508673

Epoch: 6| Step: 8
Training loss: 0.2422670802761877
Validation loss: 2.2496198845249293

Epoch: 6| Step: 9
Training loss: 0.17981144527952025
Validation loss: 2.260645153141091

Epoch: 6| Step: 10
Training loss: 0.15176774217088498
Validation loss: 2.191396748368624

Epoch: 6| Step: 11
Training loss: 0.1613360481533369
Validation loss: 2.3067328219032017

Epoch: 6| Step: 12
Training loss: 0.2100198884753596
Validation loss: 2.252850096109248

Epoch: 6| Step: 13
Training loss: 0.35621591789778984
Validation loss: 2.2365574703859123

Epoch: 507| Step: 0
Training loss: 0.19924977004948538
Validation loss: 2.2570197221640504

Epoch: 6| Step: 1
Training loss: 0.24468152209417848
Validation loss: 2.2784109172526894

Epoch: 6| Step: 2
Training loss: 0.21617871727573537
Validation loss: 2.2758487616758334

Epoch: 6| Step: 3
Training loss: 0.17527703980564904
Validation loss: 2.2802185705474156

Epoch: 6| Step: 4
Training loss: 0.2059376008810627
Validation loss: 2.27387607359856

Epoch: 6| Step: 5
Training loss: 0.18213356973440506
Validation loss: 2.284786000918819

Epoch: 6| Step: 6
Training loss: 0.2159098616328469
Validation loss: 2.259563466675925

Epoch: 6| Step: 7
Training loss: 0.18775068849571966
Validation loss: 2.245383453840814

Epoch: 6| Step: 8
Training loss: 0.24391355254331745
Validation loss: 2.2832590340501344

Epoch: 6| Step: 9
Training loss: 0.2769842369779479
Validation loss: 2.301665355890091

Epoch: 6| Step: 10
Training loss: 0.2097766688616783
Validation loss: 2.2790129418518257

Epoch: 6| Step: 11
Training loss: 0.20613082274661618
Validation loss: 2.255665727591015

Epoch: 6| Step: 12
Training loss: 0.3006403952401864
Validation loss: 2.297556890531169

Epoch: 6| Step: 13
Training loss: 0.11650663310310747
Validation loss: 2.284840514712863

Epoch: 508| Step: 0
Training loss: 0.26049129688273265
Validation loss: 2.2860593223139127

Epoch: 6| Step: 1
Training loss: 0.235926002260181
Validation loss: 2.2791495211535766

Epoch: 6| Step: 2
Training loss: 0.24765971900363565
Validation loss: 2.287478917967991

Epoch: 6| Step: 3
Training loss: 0.2637642592602711
Validation loss: 2.2911531190842345

Epoch: 6| Step: 4
Training loss: 0.1718716512700619
Validation loss: 2.2938510772026923

Epoch: 6| Step: 5
Training loss: 0.13518388085364155
Validation loss: 2.240990774606341

Epoch: 6| Step: 6
Training loss: 0.2550742501027331
Validation loss: 2.304414213540271

Epoch: 6| Step: 7
Training loss: 0.24398038564664193
Validation loss: 2.2541592707721243

Epoch: 6| Step: 8
Training loss: 0.26655150561897645
Validation loss: 2.2380624944940126

Epoch: 6| Step: 9
Training loss: 0.25054336150477047
Validation loss: 2.283320249626747

Epoch: 6| Step: 10
Training loss: 0.2514366948937202
Validation loss: 2.2624355974392336

Epoch: 6| Step: 11
Training loss: 0.24869026635005434
Validation loss: 2.273948847887355

Epoch: 6| Step: 12
Training loss: 0.1880746023975324
Validation loss: 2.2404727027454356

Epoch: 6| Step: 13
Training loss: 0.16711200631786582
Validation loss: 2.2822524006569394

Epoch: 509| Step: 0
Training loss: 0.2518992107578133
Validation loss: 2.2971643278623954

Epoch: 6| Step: 1
Training loss: 0.20100760929094874
Validation loss: 2.285655692533099

Epoch: 6| Step: 2
Training loss: 0.21041290961269715
Validation loss: 2.2816330705676666

Epoch: 6| Step: 3
Training loss: 0.14743258348921384
Validation loss: 2.256454534585262

Epoch: 6| Step: 4
Training loss: 0.3279659248946425
Validation loss: 2.250828219674761

Epoch: 6| Step: 5
Training loss: 0.23300105946068705
Validation loss: 2.2923195226882966

Epoch: 6| Step: 6
Training loss: 0.25626722254678763
Validation loss: 2.3097851084104577

Epoch: 6| Step: 7
Training loss: 0.21125767391983655
Validation loss: 2.2835694109793865

Epoch: 6| Step: 8
Training loss: 0.17110621763989092
Validation loss: 2.2956759465220524

Epoch: 6| Step: 9
Training loss: 0.19579461675438614
Validation loss: 2.257894010733443

Epoch: 6| Step: 10
Training loss: 0.22456234149253085
Validation loss: 2.27182467867091

Epoch: 6| Step: 11
Training loss: 0.27972451396650694
Validation loss: 2.3119814695200858

Epoch: 6| Step: 12
Training loss: 0.2628681224244377
Validation loss: 2.257747292814468

Epoch: 6| Step: 13
Training loss: 0.23329257559447367
Validation loss: 2.284392496051575

Epoch: 510| Step: 0
Training loss: 0.22803931848095452
Validation loss: 2.284435025812446

Epoch: 6| Step: 1
Training loss: 0.2937193474096381
Validation loss: 2.260382468906838

Epoch: 6| Step: 2
Training loss: 0.17722101796057277
Validation loss: 2.27865073648561

Epoch: 6| Step: 3
Training loss: 0.22306498438979275
Validation loss: 2.289852886860672

Epoch: 6| Step: 4
Training loss: 0.23011007524286547
Validation loss: 2.2505990661381183

Epoch: 6| Step: 5
Training loss: 0.22262154693538647
Validation loss: 2.2902869550609637

Epoch: 6| Step: 6
Training loss: 0.24956328275401587
Validation loss: 2.2565660126813762

Epoch: 6| Step: 7
Training loss: 0.300702988983068
Validation loss: 2.3108155241356907

Epoch: 6| Step: 8
Training loss: 0.2422354712199099
Validation loss: 2.2760143118348584

Epoch: 6| Step: 9
Training loss: 0.22758552175196245
Validation loss: 2.2877283993287882

Epoch: 6| Step: 10
Training loss: 0.37693339874358994
Validation loss: 2.2581683431745794

Epoch: 6| Step: 11
Training loss: 0.22657587570958562
Validation loss: 2.1991820165752065

Epoch: 6| Step: 12
Training loss: 0.20585447229558873
Validation loss: 2.236999410967692

Epoch: 6| Step: 13
Training loss: 0.21795868799098944
Validation loss: 2.2419444006656737

Epoch: 511| Step: 0
Training loss: 0.2698408780941882
Validation loss: 2.260424263819806

Epoch: 6| Step: 1
Training loss: 0.2928591968426134
Validation loss: 2.268750326123315

Epoch: 6| Step: 2
Training loss: 0.23267563823002935
Validation loss: 2.2063111697498288

Epoch: 6| Step: 3
Training loss: 0.17594780978118515
Validation loss: 2.27432260838555

Epoch: 6| Step: 4
Training loss: 0.24618968910063313
Validation loss: 2.2885402565420603

Epoch: 6| Step: 5
Training loss: 0.173576714300401
Validation loss: 2.2637894835487704

Epoch: 6| Step: 6
Training loss: 0.3131164907110138
Validation loss: 2.256603071038849

Epoch: 6| Step: 7
Training loss: 0.238226837449279
Validation loss: 2.2602877572799747

Epoch: 6| Step: 8
Training loss: 0.15480153331098861
Validation loss: 2.218394604726894

Epoch: 6| Step: 9
Training loss: 0.24483711838642097
Validation loss: 2.243721830214232

Epoch: 6| Step: 10
Training loss: 0.3255443132197644
Validation loss: 2.233666910221117

Epoch: 6| Step: 11
Training loss: 0.24994371197748788
Validation loss: 2.237710947787489

Epoch: 6| Step: 12
Training loss: 0.19165311191837886
Validation loss: 2.288017980717207

Epoch: 6| Step: 13
Training loss: 0.16244953155836028
Validation loss: 2.3060468554946

Epoch: 512| Step: 0
Training loss: 0.2897557888588256
Validation loss: 2.273618256154993

Epoch: 6| Step: 1
Training loss: 0.3011547098574633
Validation loss: 2.300387898851229

Epoch: 6| Step: 2
Training loss: 0.3545675066334391
Validation loss: 2.291192791813029

Epoch: 6| Step: 3
Training loss: 0.23343486581411502
Validation loss: 2.2599869127654193

Epoch: 6| Step: 4
Training loss: 0.23614012120802153
Validation loss: 2.2813079861452166

Epoch: 6| Step: 5
Training loss: 0.3071212403715901
Validation loss: 2.2807314819082594

Epoch: 6| Step: 6
Training loss: 0.387278912139118
Validation loss: 2.274706745110839

Epoch: 6| Step: 7
Training loss: 0.25729125244220535
Validation loss: 2.2645705827800335

Epoch: 6| Step: 8
Training loss: 0.3279494315423821
Validation loss: 2.2888468010385647

Epoch: 6| Step: 9
Training loss: 0.23119699863103477
Validation loss: 2.304970985693379

Epoch: 6| Step: 10
Training loss: 0.23280828875374798
Validation loss: 2.2871171759503044

Epoch: 6| Step: 11
Training loss: 0.25018470616606814
Validation loss: 2.2768795004796782

Epoch: 6| Step: 12
Training loss: 0.22568312528950343
Validation loss: 2.2628988943547568

Epoch: 6| Step: 13
Training loss: 0.17385062061435744
Validation loss: 2.292914724065517

Epoch: 513| Step: 0
Training loss: 0.2322949615951891
Validation loss: 2.2962668688602172

Epoch: 6| Step: 1
Training loss: 0.295831956099049
Validation loss: 2.252749017604255

Epoch: 6| Step: 2
Training loss: 0.23718769030758105
Validation loss: 2.2594936760019495

Epoch: 6| Step: 3
Training loss: 0.19124857577871948
Validation loss: 2.269378114174811

Epoch: 6| Step: 4
Training loss: 0.2751055926558372
Validation loss: 2.2791661102694074

Epoch: 6| Step: 5
Training loss: 0.3130337091528124
Validation loss: 2.2546118166869205

Epoch: 6| Step: 6
Training loss: 0.22567299818374703
Validation loss: 2.229882345260514

Epoch: 6| Step: 7
Training loss: 0.18319043032132049
Validation loss: 2.2454133349353986

Epoch: 6| Step: 8
Training loss: 0.3005267713985942
Validation loss: 2.2471523455064184

Epoch: 6| Step: 9
Training loss: 0.2613647401073958
Validation loss: 2.2777287030813165

Epoch: 6| Step: 10
Training loss: 0.199428868281208
Validation loss: 2.305412833521272

Epoch: 6| Step: 11
Training loss: 0.1978929948871932
Validation loss: 2.250936789999091

Epoch: 6| Step: 12
Training loss: 0.2211361493949018
Validation loss: 2.2673291692062736

Epoch: 6| Step: 13
Training loss: 0.21106068228610164
Validation loss: 2.2686978603007972

Epoch: 514| Step: 0
Training loss: 0.25500041251055694
Validation loss: 2.251193595347662

Epoch: 6| Step: 1
Training loss: 0.21765117891296015
Validation loss: 2.303861739508144

Epoch: 6| Step: 2
Training loss: 0.315605303650218
Validation loss: 2.268791616599328

Epoch: 6| Step: 3
Training loss: 0.1914671878735408
Validation loss: 2.2645593702165

Epoch: 6| Step: 4
Training loss: 0.18641221889842235
Validation loss: 2.2597803430234564

Epoch: 6| Step: 5
Training loss: 0.1584242993654738
Validation loss: 2.2778692931370803

Epoch: 6| Step: 6
Training loss: 0.21171062566505558
Validation loss: 2.2864852214324234

Epoch: 6| Step: 7
Training loss: 0.2262590365554725
Validation loss: 2.31555837860574

Epoch: 6| Step: 8
Training loss: 0.23360565595362745
Validation loss: 2.3159598509537367

Epoch: 6| Step: 9
Training loss: 0.23038304076803898
Validation loss: 2.2812607995740017

Epoch: 6| Step: 10
Training loss: 0.21643403766582495
Validation loss: 2.292259128164768

Epoch: 6| Step: 11
Training loss: 0.14743561558855323
Validation loss: 2.3247151419077383

Epoch: 6| Step: 12
Training loss: 0.23759000603604588
Validation loss: 2.266393412803842

Epoch: 6| Step: 13
Training loss: 0.21658328420362788
Validation loss: 2.304455520248078

Epoch: 515| Step: 0
Training loss: 0.34203635409307886
Validation loss: 2.275582043805386

Epoch: 6| Step: 1
Training loss: 0.25069613690977627
Validation loss: 2.315345302477624

Epoch: 6| Step: 2
Training loss: 0.19784985322204518
Validation loss: 2.291243251062898

Epoch: 6| Step: 3
Training loss: 0.23943309980236174
Validation loss: 2.2963333010113094

Epoch: 6| Step: 4
Training loss: 0.2600681436398928
Validation loss: 2.2868385491216334

Epoch: 6| Step: 5
Training loss: 0.2384813281683598
Validation loss: 2.283105252585443

Epoch: 6| Step: 6
Training loss: 0.27804823844813326
Validation loss: 2.288264425156598

Epoch: 6| Step: 7
Training loss: 0.2381977028634683
Validation loss: 2.2873522952255634

Epoch: 6| Step: 8
Training loss: 0.23731817199322391
Validation loss: 2.25082043418686

Epoch: 6| Step: 9
Training loss: 0.17105194826583248
Validation loss: 2.2838958829218337

Epoch: 6| Step: 10
Training loss: 0.2683077838953294
Validation loss: 2.2459689782911125

Epoch: 6| Step: 11
Training loss: 0.3100200599094407
Validation loss: 2.2803270746167588

Epoch: 6| Step: 12
Training loss: 0.24106499276072785
Validation loss: 2.2375092653619033

Epoch: 6| Step: 13
Training loss: 0.29890897068634004
Validation loss: 2.2221388301169704

Epoch: 516| Step: 0
Training loss: 0.2534593316869113
Validation loss: 2.2588142627806187

Epoch: 6| Step: 1
Training loss: 0.3294032041718104
Validation loss: 2.225748433096229

Epoch: 6| Step: 2
Training loss: 0.18189084855731052
Validation loss: 2.2800817764407224

Epoch: 6| Step: 3
Training loss: 0.2785898075049446
Validation loss: 2.297750872605228

Epoch: 6| Step: 4
Training loss: 0.34721071648078367
Validation loss: 2.281820757111576

Epoch: 6| Step: 5
Training loss: 0.2511631313006392
Validation loss: 2.2752614433499034

Epoch: 6| Step: 6
Training loss: 0.2566237642971042
Validation loss: 2.2466679024433542

Epoch: 6| Step: 7
Training loss: 0.2600622562919782
Validation loss: 2.258275047361824

Epoch: 6| Step: 8
Training loss: 0.2600735151914238
Validation loss: 2.2641312158098033

Epoch: 6| Step: 9
Training loss: 0.18417226669232328
Validation loss: 2.299482219574494

Epoch: 6| Step: 10
Training loss: 0.22028285496701086
Validation loss: 2.2497864462914987

Epoch: 6| Step: 11
Training loss: 0.4004829858459119
Validation loss: 2.294209168060432

Epoch: 6| Step: 12
Training loss: 0.2410157297959556
Validation loss: 2.303094725148887

Epoch: 6| Step: 13
Training loss: 0.14862215953852526
Validation loss: 2.263094934114366

Epoch: 517| Step: 0
Training loss: 0.19170209830983384
Validation loss: 2.2685608181574324

Epoch: 6| Step: 1
Training loss: 0.23341352022988193
Validation loss: 2.2809873978476984

Epoch: 6| Step: 2
Training loss: 0.18382822444473734
Validation loss: 2.2798084860532795

Epoch: 6| Step: 3
Training loss: 0.26468151491102315
Validation loss: 2.2753862241776113

Epoch: 6| Step: 4
Training loss: 0.22109601825049327
Validation loss: 2.26863321996851

Epoch: 6| Step: 5
Training loss: 0.2860600115238807
Validation loss: 2.2588340621756045

Epoch: 6| Step: 6
Training loss: 0.22708894962545864
Validation loss: 2.253615309318499

Epoch: 6| Step: 7
Training loss: 0.2392210484499552
Validation loss: 2.233895248091071

Epoch: 6| Step: 8
Training loss: 0.27404018467838864
Validation loss: 2.235942264234584

Epoch: 6| Step: 9
Training loss: 0.23382397090689894
Validation loss: 2.249281238616698

Epoch: 6| Step: 10
Training loss: 0.2296699241479031
Validation loss: 2.227818488412058

Epoch: 6| Step: 11
Training loss: 0.27201601843614015
Validation loss: 2.2158638535322854

Epoch: 6| Step: 12
Training loss: 0.28862790352264184
Validation loss: 2.239243775878424

Epoch: 6| Step: 13
Training loss: 0.21028766493948145
Validation loss: 2.2315138524587317

Epoch: 518| Step: 0
Training loss: 0.24458785483558312
Validation loss: 2.23796642989866

Epoch: 6| Step: 1
Training loss: 0.190612079620248
Validation loss: 2.2344403824209964

Epoch: 6| Step: 2
Training loss: 0.24938845342423552
Validation loss: 2.2575642450371536

Epoch: 6| Step: 3
Training loss: 0.22018312280739794
Validation loss: 2.2430816533394804

Epoch: 6| Step: 4
Training loss: 0.20754599907324134
Validation loss: 2.225424635296199

Epoch: 6| Step: 5
Training loss: 0.23860816729641324
Validation loss: 2.208322674947485

Epoch: 6| Step: 6
Training loss: 0.33664658474554543
Validation loss: 2.263597620485912

Epoch: 6| Step: 7
Training loss: 0.28085606855586975
Validation loss: 2.2478377319232186

Epoch: 6| Step: 8
Training loss: 0.19684551373939282
Validation loss: 2.2604640012317527

Epoch: 6| Step: 9
Training loss: 0.1556029811376352
Validation loss: 2.2340269907007033

Epoch: 6| Step: 10
Training loss: 0.236570635810647
Validation loss: 2.26338886974704

Epoch: 6| Step: 11
Training loss: 0.1484116983576307
Validation loss: 2.2562907897699924

Epoch: 6| Step: 12
Training loss: 0.218726344191894
Validation loss: 2.2607336012565304

Epoch: 6| Step: 13
Training loss: 0.1999691127231919
Validation loss: 2.2108788274701436

Epoch: 519| Step: 0
Training loss: 0.20233295146745325
Validation loss: 2.253559996102574

Epoch: 6| Step: 1
Training loss: 0.21430668894970814
Validation loss: 2.217285523634746

Epoch: 6| Step: 2
Training loss: 0.2403734161445779
Validation loss: 2.239288094747383

Epoch: 6| Step: 3
Training loss: 0.35781022116922395
Validation loss: 2.2559700282317645

Epoch: 6| Step: 4
Training loss: 0.1904612979573338
Validation loss: 2.2553160262145253

Epoch: 6| Step: 5
Training loss: 0.31314685155189365
Validation loss: 2.237401135709481

Epoch: 6| Step: 6
Training loss: 0.16456036865195747
Validation loss: 2.2412679117866023

Epoch: 6| Step: 7
Training loss: 0.19617008759881815
Validation loss: 2.259849236869468

Epoch: 6| Step: 8
Training loss: 0.1516356947724823
Validation loss: 2.2814253996563605

Epoch: 6| Step: 9
Training loss: 0.21609460652609852
Validation loss: 2.250050870885449

Epoch: 6| Step: 10
Training loss: 0.21918332233042653
Validation loss: 2.2844538291066527

Epoch: 6| Step: 11
Training loss: 0.20583789503458425
Validation loss: 2.247346072274112

Epoch: 6| Step: 12
Training loss: 0.14235367810478916
Validation loss: 2.2796804262835453

Epoch: 6| Step: 13
Training loss: 0.2939873852196799
Validation loss: 2.2413015442860713

Epoch: 520| Step: 0
Training loss: 0.16307630339165513
Validation loss: 2.3043514459294436

Epoch: 6| Step: 1
Training loss: 0.23269525046073186
Validation loss: 2.2959194920660364

Epoch: 6| Step: 2
Training loss: 0.23232700912255838
Validation loss: 2.295415332309319

Epoch: 6| Step: 3
Training loss: 0.21162556642207567
Validation loss: 2.259506821820954

Epoch: 6| Step: 4
Training loss: 0.25699046602729314
Validation loss: 2.298995105660765

Epoch: 6| Step: 5
Training loss: 0.21051061668375798
Validation loss: 2.2670245090315775

Epoch: 6| Step: 6
Training loss: 0.19698654867192214
Validation loss: 2.254696721168038

Epoch: 6| Step: 7
Training loss: 0.22096734561616846
Validation loss: 2.3072809315267393

Epoch: 6| Step: 8
Training loss: 0.2741132560454792
Validation loss: 2.2804803725779883

Epoch: 6| Step: 9
Training loss: 0.2528138650355131
Validation loss: 2.2837007500777684

Epoch: 6| Step: 10
Training loss: 0.2652832806406482
Validation loss: 2.313725825340948

Epoch: 6| Step: 11
Training loss: 0.18201009029802429
Validation loss: 2.276518177516505

Epoch: 6| Step: 12
Training loss: 0.1896768900215113
Validation loss: 2.273528823678773

Epoch: 6| Step: 13
Training loss: 0.2710434331012921
Validation loss: 2.2392598887058353

Epoch: 521| Step: 0
Training loss: 0.20919115763470625
Validation loss: 2.282320111258659

Epoch: 6| Step: 1
Training loss: 0.2820431862627359
Validation loss: 2.2750142104015953

Epoch: 6| Step: 2
Training loss: 0.20967783804746976
Validation loss: 2.241072852840416

Epoch: 6| Step: 3
Training loss: 0.25010409274266326
Validation loss: 2.294933510608801

Epoch: 6| Step: 4
Training loss: 0.1700699369415969
Validation loss: 2.263475156656289

Epoch: 6| Step: 5
Training loss: 0.20989208423178526
Validation loss: 2.2922574119940355

Epoch: 6| Step: 6
Training loss: 0.22685753586969018
Validation loss: 2.2721000836238394

Epoch: 6| Step: 7
Training loss: 0.21820889544206698
Validation loss: 2.2643129517809606

Epoch: 6| Step: 8
Training loss: 0.3067701029917254
Validation loss: 2.2911079910620704

Epoch: 6| Step: 9
Training loss: 0.30063131236549184
Validation loss: 2.275856836933957

Epoch: 6| Step: 10
Training loss: 0.19756097683716128
Validation loss: 2.219499729984041

Epoch: 6| Step: 11
Training loss: 0.19334877832834196
Validation loss: 2.2800847914193474

Epoch: 6| Step: 12
Training loss: 0.2573771992237902
Validation loss: 2.2524049321674036

Epoch: 6| Step: 13
Training loss: 0.3228302950353402
Validation loss: 2.2380879015183908

Epoch: 522| Step: 0
Training loss: 0.2375186379548176
Validation loss: 2.266948383602985

Epoch: 6| Step: 1
Training loss: 0.23585913758899305
Validation loss: 2.267910385651108

Epoch: 6| Step: 2
Training loss: 0.23049608973612154
Validation loss: 2.2404814109743354

Epoch: 6| Step: 3
Training loss: 0.26839350631863057
Validation loss: 2.217673241902224

Epoch: 6| Step: 4
Training loss: 0.1887056016493356
Validation loss: 2.253850926293778

Epoch: 6| Step: 5
Training loss: 0.24241667333462802
Validation loss: 2.2528027985303467

Epoch: 6| Step: 6
Training loss: 0.29740687459479465
Validation loss: 2.2533113343483557

Epoch: 6| Step: 7
Training loss: 0.4171342094188946
Validation loss: 2.2587282464240013

Epoch: 6| Step: 8
Training loss: 0.23426017332581037
Validation loss: 2.2030527360035235

Epoch: 6| Step: 9
Training loss: 0.3576206009189909
Validation loss: 2.236525383346769

Epoch: 6| Step: 10
Training loss: 0.2510875797759857
Validation loss: 2.252584712361614

Epoch: 6| Step: 11
Training loss: 0.4498545252578421
Validation loss: 2.2848445668906345

Epoch: 6| Step: 12
Training loss: 0.2698995451240692
Validation loss: 2.2508282020206236

Epoch: 6| Step: 13
Training loss: 0.32676852357481984
Validation loss: 2.2362796339527606

Epoch: 523| Step: 0
Training loss: 0.22981658895650406
Validation loss: 2.222269267008097

Epoch: 6| Step: 1
Training loss: 0.17256883894120986
Validation loss: 2.2420235639270207

Epoch: 6| Step: 2
Training loss: 0.2694310541092025
Validation loss: 2.2193889324782563

Epoch: 6| Step: 3
Training loss: 0.389274398519257
Validation loss: 2.2608565211650733

Epoch: 6| Step: 4
Training loss: 0.3480817569673836
Validation loss: 2.260243296383722

Epoch: 6| Step: 5
Training loss: 0.3433199164379273
Validation loss: 2.2446813770175096

Epoch: 6| Step: 6
Training loss: 0.2788318951651937
Validation loss: 2.244094365647181

Epoch: 6| Step: 7
Training loss: 0.3748492891730033
Validation loss: 2.2710125762006683

Epoch: 6| Step: 8
Training loss: 0.2290177818926032
Validation loss: 2.2660557655269264

Epoch: 6| Step: 9
Training loss: 0.2430833583022497
Validation loss: 2.2820392880575167

Epoch: 6| Step: 10
Training loss: 0.2732503386693463
Validation loss: 2.2867590084513627

Epoch: 6| Step: 11
Training loss: 0.3222275682577696
Validation loss: 2.28951202596247

Epoch: 6| Step: 12
Training loss: 0.3749101054209649
Validation loss: 2.2565729066913165

Epoch: 6| Step: 13
Training loss: 0.38927592968924346
Validation loss: 2.271156705060965

Epoch: 524| Step: 0
Training loss: 0.24570614702219032
Validation loss: 2.2812511322158024

Epoch: 6| Step: 1
Training loss: 0.38089675719863
Validation loss: 2.281677859171836

Epoch: 6| Step: 2
Training loss: 0.2531481208367232
Validation loss: 2.314130663506419

Epoch: 6| Step: 3
Training loss: 0.24869406365943336
Validation loss: 2.2884032653112065

Epoch: 6| Step: 4
Training loss: 0.2791019239483382
Validation loss: 2.339952163859422

Epoch: 6| Step: 5
Training loss: 0.480367277641672
Validation loss: 2.319808477081887

Epoch: 6| Step: 6
Training loss: 0.3114495742910075
Validation loss: 2.2911099682499927

Epoch: 6| Step: 7
Training loss: 0.24393848443229732
Validation loss: 2.273320565378947

Epoch: 6| Step: 8
Training loss: 0.289390764198416
Validation loss: 2.2719317646447266

Epoch: 6| Step: 9
Training loss: 0.19216664751639467
Validation loss: 2.2378280740107286

Epoch: 6| Step: 10
Training loss: 0.26914025017389737
Validation loss: 2.2460201527797357

Epoch: 6| Step: 11
Training loss: 0.33621336455525624
Validation loss: 2.2301348933517597

Epoch: 6| Step: 12
Training loss: 0.482807206306942
Validation loss: 2.237093909580777

Epoch: 6| Step: 13
Training loss: 0.34063993561223793
Validation loss: 2.2563410785499096

Epoch: 525| Step: 0
Training loss: 0.3219984160541292
Validation loss: 2.2082978431680877

Epoch: 6| Step: 1
Training loss: 0.29858453334155893
Validation loss: 2.2231107938661308

Epoch: 6| Step: 2
Training loss: 0.1796673473169507
Validation loss: 2.276773275524821

Epoch: 6| Step: 3
Training loss: 0.253557097183035
Validation loss: 2.2464643532003326

Epoch: 6| Step: 4
Training loss: 0.19812857844252896
Validation loss: 2.236411289406724

Epoch: 6| Step: 5
Training loss: 0.2814357197362347
Validation loss: 2.2612467587913283

Epoch: 6| Step: 6
Training loss: 0.2918539708871371
Validation loss: 2.2206898657839926

Epoch: 6| Step: 7
Training loss: 0.2889388051730711
Validation loss: 2.1905762885133715

Epoch: 6| Step: 8
Training loss: 0.2533769519224481
Validation loss: 2.268286297352766

Epoch: 6| Step: 9
Training loss: 0.2691854940587241
Validation loss: 2.1821154581701063

Epoch: 6| Step: 10
Training loss: 0.28958321400966974
Validation loss: 2.1905537770112216

Epoch: 6| Step: 11
Training loss: 0.3140950029549521
Validation loss: 2.244189176374552

Epoch: 6| Step: 12
Training loss: 0.16681910909364164
Validation loss: 2.244924932242912

Epoch: 6| Step: 13
Training loss: 0.21707474024953813
Validation loss: 2.2112975170032256

Epoch: 526| Step: 0
Training loss: 0.4192511591431819
Validation loss: 2.2487444111682313

Epoch: 6| Step: 1
Training loss: 0.27042453737271355
Validation loss: 2.235811158775371

Epoch: 6| Step: 2
Training loss: 0.27832228007374005
Validation loss: 2.253311113914814

Epoch: 6| Step: 3
Training loss: 0.38283602973091935
Validation loss: 2.2542899877786406

Epoch: 6| Step: 4
Training loss: 0.3564026271396787
Validation loss: 2.2595097939085633

Epoch: 6| Step: 5
Training loss: 0.3594822516244953
Validation loss: 2.2315643968811365

Epoch: 6| Step: 6
Training loss: 0.26365870690136384
Validation loss: 2.2959035605358977

Epoch: 6| Step: 7
Training loss: 0.2038165936730084
Validation loss: 2.2201769721886384

Epoch: 6| Step: 8
Training loss: 0.19551049686993702
Validation loss: 2.209079199615544

Epoch: 6| Step: 9
Training loss: 0.22986198013278408
Validation loss: 2.2219911998296396

Epoch: 6| Step: 10
Training loss: 0.26327457872309407
Validation loss: 2.2737350706086032

Epoch: 6| Step: 11
Training loss: 0.26285104496145695
Validation loss: 2.281883552400807

Epoch: 6| Step: 12
Training loss: 0.19483618830956823
Validation loss: 2.2514755920537466

Epoch: 6| Step: 13
Training loss: 0.2935726553671194
Validation loss: 2.2570854521172166

Epoch: 527| Step: 0
Training loss: 0.19621216515580978
Validation loss: 2.269787527159064

Epoch: 6| Step: 1
Training loss: 0.3351638890887489
Validation loss: 2.3068839947995303

Epoch: 6| Step: 2
Training loss: 0.3343596887202422
Validation loss: 2.2703445736850405

Epoch: 6| Step: 3
Training loss: 0.28821047661066046
Validation loss: 2.2485362695945943

Epoch: 6| Step: 4
Training loss: 0.20259970821061168
Validation loss: 2.2740782701005697

Epoch: 6| Step: 5
Training loss: 0.2556836638721163
Validation loss: 2.2988192229421323

Epoch: 6| Step: 6
Training loss: 0.21164718206590272
Validation loss: 2.290106369363366

Epoch: 6| Step: 7
Training loss: 0.22079634596610295
Validation loss: 2.2989950278815923

Epoch: 6| Step: 8
Training loss: 0.25584558639063004
Validation loss: 2.265057214206598

Epoch: 6| Step: 9
Training loss: 0.40094526998434526
Validation loss: 2.253412872562177

Epoch: 6| Step: 10
Training loss: 0.25940227192819093
Validation loss: 2.254187471066952

Epoch: 6| Step: 11
Training loss: 0.3421529386650898
Validation loss: 2.249549714701766

Epoch: 6| Step: 12
Training loss: 0.20712155945521232
Validation loss: 2.2926806778534643

Epoch: 6| Step: 13
Training loss: 0.2527136598142573
Validation loss: 2.2898236550948607

Epoch: 528| Step: 0
Training loss: 0.2923142943434242
Validation loss: 2.2942741183294593

Epoch: 6| Step: 1
Training loss: 0.14071447122292258
Validation loss: 2.312623570551536

Epoch: 6| Step: 2
Training loss: 0.26481365663043116
Validation loss: 2.2948017061844785

Epoch: 6| Step: 3
Training loss: 0.22266870597665248
Validation loss: 2.291175413941622

Epoch: 6| Step: 4
Training loss: 0.30088348632813117
Validation loss: 2.278232834945162

Epoch: 6| Step: 5
Training loss: 0.2599602737246321
Validation loss: 2.269729159158118

Epoch: 6| Step: 6
Training loss: 0.16593807877692887
Validation loss: 2.2003792320302797

Epoch: 6| Step: 7
Training loss: 0.25958015876735185
Validation loss: 2.2646968124111857

Epoch: 6| Step: 8
Training loss: 0.17782347405598267
Validation loss: 2.257794759608072

Epoch: 6| Step: 9
Training loss: 0.23587366813269497
Validation loss: 2.2503171273432776

Epoch: 6| Step: 10
Training loss: 0.1660994934962242
Validation loss: 2.2693854245179566

Epoch: 6| Step: 11
Training loss: 0.2298891651633799
Validation loss: 2.22615256300296

Epoch: 6| Step: 12
Training loss: 0.20978211172942082
Validation loss: 2.246148238695955

Epoch: 6| Step: 13
Training loss: 0.1760531653555746
Validation loss: 2.27078021859396

Epoch: 529| Step: 0
Training loss: 0.27686212925240916
Validation loss: 2.255202160504522

Epoch: 6| Step: 1
Training loss: 0.1992989173105617
Validation loss: 2.219120836385139

Epoch: 6| Step: 2
Training loss: 0.2133346965741271
Validation loss: 2.242588268798184

Epoch: 6| Step: 3
Training loss: 0.23028971296650086
Validation loss: 2.2105387675232215

Epoch: 6| Step: 4
Training loss: 0.2245509030070609
Validation loss: 2.266906025347041

Epoch: 6| Step: 5
Training loss: 0.1550860563887583
Validation loss: 2.217119611866156

Epoch: 6| Step: 6
Training loss: 0.20606316643937755
Validation loss: 2.265930041243595

Epoch: 6| Step: 7
Training loss: 0.2149898639080556
Validation loss: 2.2223422918730864

Epoch: 6| Step: 8
Training loss: 0.2939361114582713
Validation loss: 2.287996783970638

Epoch: 6| Step: 9
Training loss: 0.3472841178509943
Validation loss: 2.2523100791458237

Epoch: 6| Step: 10
Training loss: 0.20135007761536253
Validation loss: 2.245918890739426

Epoch: 6| Step: 11
Training loss: 0.23999909765848762
Validation loss: 2.253292174184409

Epoch: 6| Step: 12
Training loss: 0.2924904160885719
Validation loss: 2.2353005437443643

Epoch: 6| Step: 13
Training loss: 0.2899579920639052
Validation loss: 2.2398210502851827

Epoch: 530| Step: 0
Training loss: 0.2215495462760334
Validation loss: 2.2804280198038414

Epoch: 6| Step: 1
Training loss: 0.23002846737321167
Validation loss: 2.263439018378564

Epoch: 6| Step: 2
Training loss: 0.3203784595589968
Validation loss: 2.241010146333557

Epoch: 6| Step: 3
Training loss: 0.3217151448592978
Validation loss: 2.2891727026059128

Epoch: 6| Step: 4
Training loss: 0.320395133361872
Validation loss: 2.2545525534911692

Epoch: 6| Step: 5
Training loss: 0.25961170081842544
Validation loss: 2.2764946830805277

Epoch: 6| Step: 6
Training loss: 0.2613856059950518
Validation loss: 2.3093615533680736

Epoch: 6| Step: 7
Training loss: 0.31785855363759297
Validation loss: 2.2544986380514245

Epoch: 6| Step: 8
Training loss: 0.38028538807104884
Validation loss: 2.286774491079401

Epoch: 6| Step: 9
Training loss: 0.2739718257400276
Validation loss: 2.280257126547659

Epoch: 6| Step: 10
Training loss: 0.3786653952637392
Validation loss: 2.2594230214103237

Epoch: 6| Step: 11
Training loss: 0.25500310054464836
Validation loss: 2.2622171927748838

Epoch: 6| Step: 12
Training loss: 0.3151685265422822
Validation loss: 2.27462293693006

Epoch: 6| Step: 13
Training loss: 0.21307389656263667
Validation loss: 2.2486200692831755

Epoch: 531| Step: 0
Training loss: 0.22431664672360382
Validation loss: 2.2968065593323317

Epoch: 6| Step: 1
Training loss: 0.20153902863455897
Validation loss: 2.24596019403087

Epoch: 6| Step: 2
Training loss: 0.2495580507025603
Validation loss: 2.228069665336735

Epoch: 6| Step: 3
Training loss: 0.19563688996168524
Validation loss: 2.2670074366848727

Epoch: 6| Step: 4
Training loss: 0.2346437661607897
Validation loss: 2.270373679953763

Epoch: 6| Step: 5
Training loss: 0.228337536399564
Validation loss: 2.23863378104199

Epoch: 6| Step: 6
Training loss: 0.18408090808637068
Validation loss: 2.231203037412424

Epoch: 6| Step: 7
Training loss: 0.3294886794070284
Validation loss: 2.2672468672344563

Epoch: 6| Step: 8
Training loss: 0.2268346106094801
Validation loss: 2.281959893542008

Epoch: 6| Step: 9
Training loss: 0.263968294031511
Validation loss: 2.2824474222952644

Epoch: 6| Step: 10
Training loss: 0.2102586985749309
Validation loss: 2.300508527238465

Epoch: 6| Step: 11
Training loss: 0.164770494699301
Validation loss: 2.3092504213944025

Epoch: 6| Step: 12
Training loss: 0.3080747682779647
Validation loss: 2.279234792980173

Epoch: 6| Step: 13
Training loss: 0.2978148891197034
Validation loss: 2.24918832973673

Epoch: 532| Step: 0
Training loss: 0.2551511616149839
Validation loss: 2.2545345671335864

Epoch: 6| Step: 1
Training loss: 0.1881617055772653
Validation loss: 2.2581069032767647

Epoch: 6| Step: 2
Training loss: 0.15736912844682954
Validation loss: 2.2998546986362802

Epoch: 6| Step: 3
Training loss: 0.26406118121748945
Validation loss: 2.2876472394489733

Epoch: 6| Step: 4
Training loss: 0.26821470067295267
Validation loss: 2.2524429763423517

Epoch: 6| Step: 5
Training loss: 0.33906279093646385
Validation loss: 2.2975419907715775

Epoch: 6| Step: 6
Training loss: 0.315236106026398
Validation loss: 2.2780912992464173

Epoch: 6| Step: 7
Training loss: 0.27076202456400555
Validation loss: 2.2706903593451644

Epoch: 6| Step: 8
Training loss: 0.1541511656458031
Validation loss: 2.2593455846057933

Epoch: 6| Step: 9
Training loss: 0.17836337869956922
Validation loss: 2.26712169976755

Epoch: 6| Step: 10
Training loss: 0.2915975908953046
Validation loss: 2.2629211778431304

Epoch: 6| Step: 11
Training loss: 0.29273751352102384
Validation loss: 2.247919286161304

Epoch: 6| Step: 12
Training loss: 0.21653713096992833
Validation loss: 2.288836818501953

Epoch: 6| Step: 13
Training loss: 0.23705155014739374
Validation loss: 2.266073791953297

Epoch: 533| Step: 0
Training loss: 0.23223933897813318
Validation loss: 2.2538444559054676

Epoch: 6| Step: 1
Training loss: 0.19852911568912543
Validation loss: 2.2281526386389032

Epoch: 6| Step: 2
Training loss: 0.2899496923375952
Validation loss: 2.232236536875811

Epoch: 6| Step: 3
Training loss: 0.1396819721318642
Validation loss: 2.236711662974996

Epoch: 6| Step: 4
Training loss: 0.22570612624494601
Validation loss: 2.2779832556033517

Epoch: 6| Step: 5
Training loss: 0.17743198115710698
Validation loss: 2.235958400853443

Epoch: 6| Step: 6
Training loss: 0.2573132738829588
Validation loss: 2.269777994755159

Epoch: 6| Step: 7
Training loss: 0.23572578594353064
Validation loss: 2.2418079121369976

Epoch: 6| Step: 8
Training loss: 0.2239886954522549
Validation loss: 2.276855512380821

Epoch: 6| Step: 9
Training loss: 0.2610897933230977
Validation loss: 2.275207442303337

Epoch: 6| Step: 10
Training loss: 0.2161525309723791
Validation loss: 2.2532012559717156

Epoch: 6| Step: 11
Training loss: 0.3480959693885199
Validation loss: 2.2660112424449803

Epoch: 6| Step: 12
Training loss: 0.290134683895262
Validation loss: 2.2605176161858926

Epoch: 6| Step: 13
Training loss: 0.17230185692121963
Validation loss: 2.2675597600551898

Epoch: 534| Step: 0
Training loss: 0.23775171630973935
Validation loss: 2.194140065755485

Epoch: 6| Step: 1
Training loss: 0.20155011885712132
Validation loss: 2.2509674358941427

Epoch: 6| Step: 2
Training loss: 0.26187456531534103
Validation loss: 2.2277957557080716

Epoch: 6| Step: 3
Training loss: 0.26716043770248066
Validation loss: 2.255501872657309

Epoch: 6| Step: 4
Training loss: 0.25487708308185764
Validation loss: 2.257206431776022

Epoch: 6| Step: 5
Training loss: 0.23531349950681985
Validation loss: 2.253470605171406

Epoch: 6| Step: 6
Training loss: 0.186190802876199
Validation loss: 2.262864186813867

Epoch: 6| Step: 7
Training loss: 0.20006737691720256
Validation loss: 2.243590355792678

Epoch: 6| Step: 8
Training loss: 0.22228259807871317
Validation loss: 2.252196758377032

Epoch: 6| Step: 9
Training loss: 0.24177966079692537
Validation loss: 2.252124066356479

Epoch: 6| Step: 10
Training loss: 0.28088524796075115
Validation loss: 2.2394097608387575

Epoch: 6| Step: 11
Training loss: 0.23288170822717655
Validation loss: 2.239500573573458

Epoch: 6| Step: 12
Training loss: 0.3614906770195175
Validation loss: 2.2598027451834084

Epoch: 6| Step: 13
Training loss: 0.18325822688848384
Validation loss: 2.277994820739333

Epoch: 535| Step: 0
Training loss: 0.16974523834444885
Validation loss: 2.2475877564227726

Epoch: 6| Step: 1
Training loss: 0.2602128073356306
Validation loss: 2.2574098397377647

Epoch: 6| Step: 2
Training loss: 0.3260951608683065
Validation loss: 2.2554495479099765

Epoch: 6| Step: 3
Training loss: 0.3578374146029005
Validation loss: 2.2767485969075296

Epoch: 6| Step: 4
Training loss: 0.36489497443920343
Validation loss: 2.2508482835120858

Epoch: 6| Step: 5
Training loss: 0.19330552825233044
Validation loss: 2.2571239015359272

Epoch: 6| Step: 6
Training loss: 0.35257737646312953
Validation loss: 2.346548012457462

Epoch: 6| Step: 7
Training loss: 0.23694517429796425
Validation loss: 2.261862654162575

Epoch: 6| Step: 8
Training loss: 0.34384598258948373
Validation loss: 2.2684702403870336

Epoch: 6| Step: 9
Training loss: 0.26882926082620573
Validation loss: 2.24397723889948

Epoch: 6| Step: 10
Training loss: 0.2513566312077574
Validation loss: 2.2470512671162957

Epoch: 6| Step: 11
Training loss: 0.2830885030367804
Validation loss: 2.271009505434691

Epoch: 6| Step: 12
Training loss: 0.16648797549109598
Validation loss: 2.3180507035570033

Epoch: 6| Step: 13
Training loss: 0.27491245285066385
Validation loss: 2.2905755624471262

Epoch: 536| Step: 0
Training loss: 0.170224101853841
Validation loss: 2.2959040538005753

Epoch: 6| Step: 1
Training loss: 0.23117173197781496
Validation loss: 2.3036872374191555

Epoch: 6| Step: 2
Training loss: 0.3484984494260995
Validation loss: 2.2922633405783923

Epoch: 6| Step: 3
Training loss: 0.15190922684058902
Validation loss: 2.2400399090129497

Epoch: 6| Step: 4
Training loss: 0.20254793175284302
Validation loss: 2.300017873031168

Epoch: 6| Step: 5
Training loss: 0.17946624609907433
Validation loss: 2.2509721315992635

Epoch: 6| Step: 6
Training loss: 0.19471096867879187
Validation loss: 2.2139729577055305

Epoch: 6| Step: 7
Training loss: 0.2281102717883858
Validation loss: 2.2533266941044228

Epoch: 6| Step: 8
Training loss: 0.32979268931561445
Validation loss: 2.2447789332713888

Epoch: 6| Step: 9
Training loss: 0.43447782410943375
Validation loss: 2.2472248270181847

Epoch: 6| Step: 10
Training loss: 0.20533790483458628
Validation loss: 2.2460595258233855

Epoch: 6| Step: 11
Training loss: 0.3343352320900192
Validation loss: 2.2854957784790226

Epoch: 6| Step: 12
Training loss: 0.20398796607267633
Validation loss: 2.2229040060305465

Epoch: 6| Step: 13
Training loss: 0.27359460676964287
Validation loss: 2.2674385441839435

Epoch: 537| Step: 0
Training loss: 0.28421374244745534
Validation loss: 2.2697017690973444

Epoch: 6| Step: 1
Training loss: 0.2686537126556875
Validation loss: 2.262405853349995

Epoch: 6| Step: 2
Training loss: 0.23816039976181907
Validation loss: 2.249039493513969

Epoch: 6| Step: 3
Training loss: 0.3330722869477373
Validation loss: 2.268698665994442

Epoch: 6| Step: 4
Training loss: 0.185537187423782
Validation loss: 2.28149342218003

Epoch: 6| Step: 5
Training loss: 0.21962545823867402
Validation loss: 2.2397998675565045

Epoch: 6| Step: 6
Training loss: 0.2929627227163203
Validation loss: 2.2702762258685567

Epoch: 6| Step: 7
Training loss: 0.26877505884224
Validation loss: 2.250939173191375

Epoch: 6| Step: 8
Training loss: 0.2136038373757151
Validation loss: 2.2537776617241634

Epoch: 6| Step: 9
Training loss: 0.273181863905997
Validation loss: 2.2578844633150665

Epoch: 6| Step: 10
Training loss: 0.2762394397538199
Validation loss: 2.2762720499187465

Epoch: 6| Step: 11
Training loss: 0.2252705834507089
Validation loss: 2.306477316152678

Epoch: 6| Step: 12
Training loss: 0.21400147842181752
Validation loss: 2.2864307120935083

Epoch: 6| Step: 13
Training loss: 0.28890119382107216
Validation loss: 2.2702593880111905

Epoch: 538| Step: 0
Training loss: 0.2232059419298651
Validation loss: 2.300709471260256

Epoch: 6| Step: 1
Training loss: 0.1912551108001532
Validation loss: 2.261663591044993

Epoch: 6| Step: 2
Training loss: 0.20193156527573985
Validation loss: 2.275072469011202

Epoch: 6| Step: 3
Training loss: 0.24943975168443427
Validation loss: 2.30534639584312

Epoch: 6| Step: 4
Training loss: 0.2464594016746611
Validation loss: 2.2464063167083355

Epoch: 6| Step: 5
Training loss: 0.21663854161226104
Validation loss: 2.2778206659042337

Epoch: 6| Step: 6
Training loss: 0.35163294828078745
Validation loss: 2.2470921693988073

Epoch: 6| Step: 7
Training loss: 0.23727359489542962
Validation loss: 2.2848766362328923

Epoch: 6| Step: 8
Training loss: 0.2964345274423718
Validation loss: 2.2832736876510054

Epoch: 6| Step: 9
Training loss: 0.23908263819776177
Validation loss: 2.234643915528689

Epoch: 6| Step: 10
Training loss: 0.37305122892225656
Validation loss: 2.233927061623419

Epoch: 6| Step: 11
Training loss: 0.21305412173842136
Validation loss: 2.2716736128382045

Epoch: 6| Step: 12
Training loss: 0.29315773272812873
Validation loss: 2.2710401866620953

Epoch: 6| Step: 13
Training loss: 0.30427225867859037
Validation loss: 2.218726341587068

Epoch: 539| Step: 0
Training loss: 0.35148248821633093
Validation loss: 2.273848864555745

Epoch: 6| Step: 1
Training loss: 0.2980926538509839
Validation loss: 2.247529041737723

Epoch: 6| Step: 2
Training loss: 0.2920384960387962
Validation loss: 2.2727556374976174

Epoch: 6| Step: 3
Training loss: 0.38491920852744077
Validation loss: 2.2711284923925183

Epoch: 6| Step: 4
Training loss: 0.2812667152947773
Validation loss: 2.2604533923515953

Epoch: 6| Step: 5
Training loss: 0.16319695993834
Validation loss: 2.23429553906547

Epoch: 6| Step: 6
Training loss: 0.2840735771570928
Validation loss: 2.2516478932424193

Epoch: 6| Step: 7
Training loss: 0.32766161851027636
Validation loss: 2.25525181282776

Epoch: 6| Step: 8
Training loss: 0.3058259066300186
Validation loss: 2.290170672551875

Epoch: 6| Step: 9
Training loss: 0.3354986229376524
Validation loss: 2.265921509731517

Epoch: 6| Step: 10
Training loss: 0.23496605731970152
Validation loss: 2.2553686888129225

Epoch: 6| Step: 11
Training loss: 0.1804579203109959
Validation loss: 2.2120688591265174

Epoch: 6| Step: 12
Training loss: 0.24578624768762866
Validation loss: 2.2314481260809216

Epoch: 6| Step: 13
Training loss: 0.29664005218201395
Validation loss: 2.287724386997889

Epoch: 540| Step: 0
Training loss: 0.3247952678367405
Validation loss: 2.219990951874769

Epoch: 6| Step: 1
Training loss: 0.28647114407186175
Validation loss: 2.272270409946957

Epoch: 6| Step: 2
Training loss: 0.27711832260600977
Validation loss: 2.2606510679531233

Epoch: 6| Step: 3
Training loss: 0.17688430559461482
Validation loss: 2.2711524097594866

Epoch: 6| Step: 4
Training loss: 0.1865962720140563
Validation loss: 2.2696112893851854

Epoch: 6| Step: 5
Training loss: 0.2574399655227048
Validation loss: 2.279454792112439

Epoch: 6| Step: 6
Training loss: 0.2800071195352929
Validation loss: 2.266247683490762

Epoch: 6| Step: 7
Training loss: 0.5188927419593389
Validation loss: 2.2745623782477766

Epoch: 6| Step: 8
Training loss: 0.2868138693417089
Validation loss: 2.2544698027202004

Epoch: 6| Step: 9
Training loss: 0.3262925638554218
Validation loss: 2.2041886199357883

Epoch: 6| Step: 10
Training loss: 0.24557622352442093
Validation loss: 2.2547569498604343

Epoch: 6| Step: 11
Training loss: 0.25932646320249797
Validation loss: 2.2419421940150763

Epoch: 6| Step: 12
Training loss: 0.30792105062940295
Validation loss: 2.262049816017017

Epoch: 6| Step: 13
Training loss: 0.2182204785738083
Validation loss: 2.2466369149061505

Epoch: 541| Step: 0
Training loss: 0.21979982638165643
Validation loss: 2.228688453171106

Epoch: 6| Step: 1
Training loss: 0.24639949274080564
Validation loss: 2.2391435294830506

Epoch: 6| Step: 2
Training loss: 0.27516335382340773
Validation loss: 2.285418686102291

Epoch: 6| Step: 3
Training loss: 0.3687421878698395
Validation loss: 2.2778789748478636

Epoch: 6| Step: 4
Training loss: 0.31432858956861043
Validation loss: 2.281251437043038

Epoch: 6| Step: 5
Training loss: 0.2871145909672488
Validation loss: 2.27586602959833

Epoch: 6| Step: 6
Training loss: 0.3055484662835068
Validation loss: 2.243911682792423

Epoch: 6| Step: 7
Training loss: 0.26190597328250614
Validation loss: 2.2927498482795032

Epoch: 6| Step: 8
Training loss: 0.17937532549506238
Validation loss: 2.2546651830734135

Epoch: 6| Step: 9
Training loss: 0.3359753454315172
Validation loss: 2.276411403301319

Epoch: 6| Step: 10
Training loss: 0.16765087567023068
Validation loss: 2.272436177078257

Epoch: 6| Step: 11
Training loss: 0.15444172928583344
Validation loss: 2.264373802123673

Epoch: 6| Step: 12
Training loss: 0.2169153130548674
Validation loss: 2.2369417506424285

Epoch: 6| Step: 13
Training loss: 0.10711560805762123
Validation loss: 2.2350441790914424

Epoch: 542| Step: 0
Training loss: 0.25536492305616054
Validation loss: 2.222079451928527

Epoch: 6| Step: 1
Training loss: 0.21189595509881512
Validation loss: 2.2519457757129056

Epoch: 6| Step: 2
Training loss: 0.2234774887207126
Validation loss: 2.260065417679217

Epoch: 6| Step: 3
Training loss: 0.2661516634357906
Validation loss: 2.2823998240325634

Epoch: 6| Step: 4
Training loss: 0.18361810766117023
Validation loss: 2.2471053789263276

Epoch: 6| Step: 5
Training loss: 0.18150727699406688
Validation loss: 2.2213393311864165

Epoch: 6| Step: 6
Training loss: 0.20096492307302782
Validation loss: 2.2649931015487836

Epoch: 6| Step: 7
Training loss: 0.24623108619339595
Validation loss: 2.282325848024994

Epoch: 6| Step: 8
Training loss: 0.16570799318183088
Validation loss: 2.280516083990507

Epoch: 6| Step: 9
Training loss: 0.23958592396178618
Validation loss: 2.27306676684273

Epoch: 6| Step: 10
Training loss: 0.23884669424186597
Validation loss: 2.289544186128715

Epoch: 6| Step: 11
Training loss: 0.20189791280669941
Validation loss: 2.2552208375180345

Epoch: 6| Step: 12
Training loss: 0.18265170010919732
Validation loss: 2.244700504466939

Epoch: 6| Step: 13
Training loss: 0.3157736730256391
Validation loss: 2.272225361585845

Epoch: 543| Step: 0
Training loss: 0.16823660208644364
Validation loss: 2.2968781529619022

Epoch: 6| Step: 1
Training loss: 0.313144805380835
Validation loss: 2.280255139949339

Epoch: 6| Step: 2
Training loss: 0.2599976299480475
Validation loss: 2.2427191375410755

Epoch: 6| Step: 3
Training loss: 0.20158012409193232
Validation loss: 2.272827625949011

Epoch: 6| Step: 4
Training loss: 0.2317162227942952
Validation loss: 2.275583868593583

Epoch: 6| Step: 5
Training loss: 0.3276477590141984
Validation loss: 2.271419280396773

Epoch: 6| Step: 6
Training loss: 0.2350435893234802
Validation loss: 2.2830278010040903

Epoch: 6| Step: 7
Training loss: 0.30335483342302155
Validation loss: 2.314372395798903

Epoch: 6| Step: 8
Training loss: 0.1714092033396081
Validation loss: 2.285204434226464

Epoch: 6| Step: 9
Training loss: 0.18424086459841915
Validation loss: 2.269588940270743

Epoch: 6| Step: 10
Training loss: 0.24241275464087184
Validation loss: 2.257651484994812

Epoch: 6| Step: 11
Training loss: 0.23179885162703878
Validation loss: 2.236504133869242

Epoch: 6| Step: 12
Training loss: 0.22609980790591105
Validation loss: 2.2543023354770413

Epoch: 6| Step: 13
Training loss: 0.3037986138181284
Validation loss: 2.3152054005399503

Epoch: 544| Step: 0
Training loss: 0.24428940626487003
Validation loss: 2.279713195767521

Epoch: 6| Step: 1
Training loss: 0.281084594831926
Validation loss: 2.302473791734699

Epoch: 6| Step: 2
Training loss: 0.16728853399337282
Validation loss: 2.2419696130454336

Epoch: 6| Step: 3
Training loss: 0.22215792455081007
Validation loss: 2.250136706826263

Epoch: 6| Step: 4
Training loss: 0.2835816845809966
Validation loss: 2.303366037606762

Epoch: 6| Step: 5
Training loss: 0.28751413528274533
Validation loss: 2.270505029820203

Epoch: 6| Step: 6
Training loss: 0.24080390410201016
Validation loss: 2.2389947043761325

Epoch: 6| Step: 7
Training loss: 0.23881931215048233
Validation loss: 2.2693779128117324

Epoch: 6| Step: 8
Training loss: 0.19815839678520836
Validation loss: 2.243489931667048

Epoch: 6| Step: 9
Training loss: 0.2313741341120769
Validation loss: 2.250105908338455

Epoch: 6| Step: 10
Training loss: 0.2216105920601804
Validation loss: 2.2580228661341497

Epoch: 6| Step: 11
Training loss: 0.19389928711494042
Validation loss: 2.261753800141975

Epoch: 6| Step: 12
Training loss: 0.15066514412153198
Validation loss: 2.2704437487461786

Epoch: 6| Step: 13
Training loss: 0.2606328670768878
Validation loss: 2.2547397846267274

Epoch: 545| Step: 0
Training loss: 0.2649772965629427
Validation loss: 2.251303674812409

Epoch: 6| Step: 1
Training loss: 0.3106179306024071
Validation loss: 2.2687071345179453

Epoch: 6| Step: 2
Training loss: 0.29950393353205207
Validation loss: 2.2434006088659117

Epoch: 6| Step: 3
Training loss: 0.26659185091432663
Validation loss: 2.2621633282683202

Epoch: 6| Step: 4
Training loss: 0.257478208267902
Validation loss: 2.2799182296612415

Epoch: 6| Step: 5
Training loss: 0.21618642866239188
Validation loss: 2.29506709079012

Epoch: 6| Step: 6
Training loss: 0.2673234075256779
Validation loss: 2.266671370987592

Epoch: 6| Step: 7
Training loss: 0.21450001355151155
Validation loss: 2.2288089417633072

Epoch: 6| Step: 8
Training loss: 0.11952680006034158
Validation loss: 2.2874182827220793

Epoch: 6| Step: 9
Training loss: 0.31950118662609334
Validation loss: 2.309459371234315

Epoch: 6| Step: 10
Training loss: 0.3024900865900819
Validation loss: 2.2448470838275107

Epoch: 6| Step: 11
Training loss: 0.20133091833969366
Validation loss: 2.2537662544165067

Epoch: 6| Step: 12
Training loss: 0.26781369719799686
Validation loss: 2.236338341924214

Epoch: 6| Step: 13
Training loss: 0.21433417837993313
Validation loss: 2.275934838087362

Epoch: 546| Step: 0
Training loss: 0.19749253507884074
Validation loss: 2.314311649596556

Epoch: 6| Step: 1
Training loss: 0.23257295522687935
Validation loss: 2.255205746150717

Epoch: 6| Step: 2
Training loss: 0.25685308130869183
Validation loss: 2.2886669785008307

Epoch: 6| Step: 3
Training loss: 0.30239928373776737
Validation loss: 2.315345851668107

Epoch: 6| Step: 4
Training loss: 0.22593429222837239
Validation loss: 2.304417498446451

Epoch: 6| Step: 5
Training loss: 0.2542351280052611
Validation loss: 2.3052146524261405

Epoch: 6| Step: 6
Training loss: 0.2215906712279566
Validation loss: 2.2758562432943354

Epoch: 6| Step: 7
Training loss: 0.29999039455772025
Validation loss: 2.26668376518794

Epoch: 6| Step: 8
Training loss: 0.2946338130958315
Validation loss: 2.2821749027201736

Epoch: 6| Step: 9
Training loss: 0.309906040418915
Validation loss: 2.266095448024934

Epoch: 6| Step: 10
Training loss: 0.22088984802437567
Validation loss: 2.2665368010212648

Epoch: 6| Step: 11
Training loss: 0.33964209218868097
Validation loss: 2.2499030675141394

Epoch: 6| Step: 12
Training loss: 0.2459604114005463
Validation loss: 2.243155054681318

Epoch: 6| Step: 13
Training loss: 0.2238879435097337
Validation loss: 2.262363436390392

Epoch: 547| Step: 0
Training loss: 0.3341600948545277
Validation loss: 2.2151232615375216

Epoch: 6| Step: 1
Training loss: 0.21588841395182168
Validation loss: 2.238071194346153

Epoch: 6| Step: 2
Training loss: 0.31211426293051187
Validation loss: 2.2650266712294176

Epoch: 6| Step: 3
Training loss: 0.219563521188717
Validation loss: 2.24561049418016

Epoch: 6| Step: 4
Training loss: 0.2911728555812757
Validation loss: 2.2607821478171695

Epoch: 6| Step: 5
Training loss: 0.23005250746072045
Validation loss: 2.2654336081156625

Epoch: 6| Step: 6
Training loss: 0.2745894146715178
Validation loss: 2.2922149406928067

Epoch: 6| Step: 7
Training loss: 0.17864371948177865
Validation loss: 2.2776889877407287

Epoch: 6| Step: 8
Training loss: 0.22790425999665875
Validation loss: 2.278783588423447

Epoch: 6| Step: 9
Training loss: 0.27690186019360796
Validation loss: 2.235046757017668

Epoch: 6| Step: 10
Training loss: 0.19978331995094134
Validation loss: 2.2693006318448528

Epoch: 6| Step: 11
Training loss: 0.14641171242651838
Validation loss: 2.2501867358107135

Epoch: 6| Step: 12
Training loss: 0.3130252596097378
Validation loss: 2.302492456344413

Epoch: 6| Step: 13
Training loss: 0.19899639174230863
Validation loss: 2.2921580279153813

Epoch: 548| Step: 0
Training loss: 0.19723524671759476
Validation loss: 2.261336009265033

Epoch: 6| Step: 1
Training loss: 0.1874919730693526
Validation loss: 2.2533607638211213

Epoch: 6| Step: 2
Training loss: 0.2880633070510878
Validation loss: 2.2616202904545673

Epoch: 6| Step: 3
Training loss: 0.23173766845416338
Validation loss: 2.245631577860535

Epoch: 6| Step: 4
Training loss: 0.1832688378458886
Validation loss: 2.2534874538565832

Epoch: 6| Step: 5
Training loss: 0.19119383255197134
Validation loss: 2.270925963259498

Epoch: 6| Step: 6
Training loss: 0.283300764418519
Validation loss: 2.2976296497799673

Epoch: 6| Step: 7
Training loss: 0.20832384306431784
Validation loss: 2.294909027280083

Epoch: 6| Step: 8
Training loss: 0.20903320276856951
Validation loss: 2.266699420000431

Epoch: 6| Step: 9
Training loss: 0.22318936821960306
Validation loss: 2.2555489462748857

Epoch: 6| Step: 10
Training loss: 0.2782776515456016
Validation loss: 2.263298488801918

Epoch: 6| Step: 11
Training loss: 0.24136388616839996
Validation loss: 2.278445553651789

Epoch: 6| Step: 12
Training loss: 0.1871355010649224
Validation loss: 2.277669561601531

Epoch: 6| Step: 13
Training loss: 0.22630647465550047
Validation loss: 2.256109851841608

Epoch: 549| Step: 0
Training loss: 0.2828213980102192
Validation loss: 2.2514714974678935

Epoch: 6| Step: 1
Training loss: 0.2542756694384329
Validation loss: 2.292731035031471

Epoch: 6| Step: 2
Training loss: 0.2122880650165826
Validation loss: 2.250990031678565

Epoch: 6| Step: 3
Training loss: 0.2099405145692747
Validation loss: 2.262987825060032

Epoch: 6| Step: 4
Training loss: 0.16163206495405058
Validation loss: 2.270788014394261

Epoch: 6| Step: 5
Training loss: 0.1943807310688457
Validation loss: 2.3147381270385976

Epoch: 6| Step: 6
Training loss: 0.2560698102475994
Validation loss: 2.286513644326427

Epoch: 6| Step: 7
Training loss: 0.2282661478163389
Validation loss: 2.292342958940528

Epoch: 6| Step: 8
Training loss: 0.24520102051391096
Validation loss: 2.2721193912381823

Epoch: 6| Step: 9
Training loss: 0.2152641604630449
Validation loss: 2.2964631487730625

Epoch: 6| Step: 10
Training loss: 0.2793552097675942
Validation loss: 2.263439185158436

Epoch: 6| Step: 11
Training loss: 0.257063065388895
Validation loss: 2.281969784269407

Epoch: 6| Step: 12
Training loss: 0.17380748583389838
Validation loss: 2.286067500560479

Epoch: 6| Step: 13
Training loss: 0.2141785728095806
Validation loss: 2.2989941204577167

Epoch: 550| Step: 0
Training loss: 0.22769890438642598
Validation loss: 2.2620192587825527

Epoch: 6| Step: 1
Training loss: 0.1736389373625886
Validation loss: 2.2811432904930533

Epoch: 6| Step: 2
Training loss: 0.16835122033392938
Validation loss: 2.2495912251195973

Epoch: 6| Step: 3
Training loss: 0.32403577674148804
Validation loss: 2.2740802009372048

Epoch: 6| Step: 4
Training loss: 0.2823218742386735
Validation loss: 2.315318889694057

Epoch: 6| Step: 5
Training loss: 0.2519875140711025
Validation loss: 2.243243218147572

Epoch: 6| Step: 6
Training loss: 0.22520857785964757
Validation loss: 2.2692640172403507

Epoch: 6| Step: 7
Training loss: 0.21594295210517983
Validation loss: 2.262796192557346

Epoch: 6| Step: 8
Training loss: 0.1770855515472007
Validation loss: 2.258530552077875

Epoch: 6| Step: 9
Training loss: 0.2457695369390931
Validation loss: 2.2908278288300417

Epoch: 6| Step: 10
Training loss: 0.1851648513791948
Validation loss: 2.2518832661010006

Epoch: 6| Step: 11
Training loss: 0.18022084900129937
Validation loss: 2.257839075127897

Epoch: 6| Step: 12
Training loss: 0.20196897492476648
Validation loss: 2.2651344645223705

Epoch: 6| Step: 13
Training loss: 0.2774477347350749
Validation loss: 2.2411591833451197

Testing loss: 2.4981104152155087
