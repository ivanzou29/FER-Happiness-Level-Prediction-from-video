Epoch: 1| Step: 0
Training loss: 7.265323638916016
Validation loss: 5.95399934053421

Epoch: 5| Step: 1
Training loss: 5.5670552253723145
Validation loss: 5.926000793774922

Epoch: 5| Step: 2
Training loss: 6.1222639083862305
Validation loss: 5.897323290506999

Epoch: 5| Step: 3
Training loss: 5.411007881164551
Validation loss: 5.870547771453857

Epoch: 5| Step: 4
Training loss: 5.939929962158203
Validation loss: 5.842389265696208

Epoch: 5| Step: 5
Training loss: 6.163160800933838
Validation loss: 5.816481689612071

Epoch: 5| Step: 6
Training loss: 5.442591667175293
Validation loss: 5.788727283477783

Epoch: 5| Step: 7
Training loss: 6.739514350891113
Validation loss: 5.76507043838501

Epoch: 5| Step: 8
Training loss: 4.992945671081543
Validation loss: 5.738004724184672

Epoch: 5| Step: 9
Training loss: 4.9088006019592285
Validation loss: 5.711008807023366

Epoch: 5| Step: 10
Training loss: 5.942561626434326
Validation loss: 5.684868971506755

Epoch: 5| Step: 11
Training loss: 7.123048782348633
Validation loss: 5.6583892703056335

Epoch: 2| Step: 0
Training loss: 5.77586555480957
Validation loss: 5.631345411141713

Epoch: 5| Step: 1
Training loss: 5.9181718826293945
Validation loss: 5.6021837790807085

Epoch: 5| Step: 2
Training loss: 5.888026237487793
Validation loss: 5.574138005574544

Epoch: 5| Step: 3
Training loss: 5.669190883636475
Validation loss: 5.544126431147258

Epoch: 5| Step: 4
Training loss: 6.209951877593994
Validation loss: 5.513737519582112

Epoch: 5| Step: 5
Training loss: 4.949309825897217
Validation loss: 5.4836462537447614

Epoch: 5| Step: 6
Training loss: 4.505989074707031
Validation loss: 5.449702084064484

Epoch: 5| Step: 7
Training loss: 5.282721042633057
Validation loss: 5.417258381843567

Epoch: 5| Step: 8
Training loss: 5.7155866622924805
Validation loss: 5.379511773586273

Epoch: 5| Step: 9
Training loss: 5.436418056488037
Validation loss: 5.344010194142659

Epoch: 5| Step: 10
Training loss: 5.597115993499756
Validation loss: 5.308152596155803

Epoch: 5| Step: 11
Training loss: 5.730518341064453
Validation loss: 5.26972617705663

Epoch: 3| Step: 0
Training loss: 4.860898971557617
Validation loss: 5.230810026327769

Epoch: 5| Step: 1
Training loss: 4.681490898132324
Validation loss: 5.1880085070927935

Epoch: 5| Step: 2
Training loss: 4.753108024597168
Validation loss: 5.1442660093307495

Epoch: 5| Step: 3
Training loss: 4.784951210021973
Validation loss: 5.102341294288635

Epoch: 5| Step: 4
Training loss: 4.537843704223633
Validation loss: 5.056284725666046

Epoch: 5| Step: 5
Training loss: 5.599730491638184
Validation loss: 5.00408015648524

Epoch: 5| Step: 6
Training loss: 5.705435276031494
Validation loss: 4.955394387245178

Epoch: 5| Step: 7
Training loss: 5.3268723487854
Validation loss: 4.905599296092987

Epoch: 5| Step: 8
Training loss: 5.5403947830200195
Validation loss: 4.849490861097972

Epoch: 5| Step: 9
Training loss: 5.808022499084473
Validation loss: 4.788335561752319

Epoch: 5| Step: 10
Training loss: 4.012200355529785
Validation loss: 4.733701874812444

Epoch: 5| Step: 11
Training loss: 5.404636383056641
Validation loss: 4.669512669245402

Epoch: 4| Step: 0
Training loss: 5.090867519378662
Validation loss: 4.607623140017192

Epoch: 5| Step: 1
Training loss: 5.106738090515137
Validation loss: 4.537991126378377

Epoch: 5| Step: 2
Training loss: 3.463197708129883
Validation loss: 4.460861722628276

Epoch: 5| Step: 3
Training loss: 4.479433059692383
Validation loss: 4.387608031431834

Epoch: 5| Step: 4
Training loss: 4.809039115905762
Validation loss: 4.3032733996709185

Epoch: 5| Step: 5
Training loss: 5.005135536193848
Validation loss: 4.22278015812238

Epoch: 5| Step: 6
Training loss: 3.4946537017822266
Validation loss: 4.137515664100647

Epoch: 5| Step: 7
Training loss: 4.970297336578369
Validation loss: 4.050107538700104

Epoch: 5| Step: 8
Training loss: 4.661849021911621
Validation loss: 3.9618548353513083

Epoch: 5| Step: 9
Training loss: 3.4992446899414062
Validation loss: 3.8803641895453134

Epoch: 5| Step: 10
Training loss: 3.4668612480163574
Validation loss: 3.785280724366506

Epoch: 5| Step: 11
Training loss: 0.9593952298164368
Validation loss: 3.6902580559253693

Epoch: 5| Step: 0
Training loss: 3.892591953277588
Validation loss: 3.5986620585123696

Epoch: 5| Step: 1
Training loss: 3.244396209716797
Validation loss: 3.49507267276446

Epoch: 5| Step: 2
Training loss: 3.144118547439575
Validation loss: 3.400802820920944

Epoch: 5| Step: 3
Training loss: 3.404202938079834
Validation loss: 3.2953343192736306

Epoch: 5| Step: 4
Training loss: 3.25934100151062
Validation loss: 3.191314826409022

Epoch: 5| Step: 5
Training loss: 3.442613124847412
Validation loss: 3.079028695821762

Epoch: 5| Step: 6
Training loss: 3.8671646118164062
Validation loss: 2.9685522317886353

Epoch: 5| Step: 7
Training loss: 2.8106279373168945
Validation loss: 2.8586867252985635

Epoch: 5| Step: 8
Training loss: 3.4112014770507812
Validation loss: 2.760942260424296

Epoch: 5| Step: 9
Training loss: 1.9595876932144165
Validation loss: 2.6439494490623474

Epoch: 5| Step: 10
Training loss: 2.3692479133605957
Validation loss: 2.5303316861391068

Epoch: 5| Step: 11
Training loss: 3.832319974899292
Validation loss: 2.4493845800558725

Epoch: 6| Step: 0
Training loss: 2.6785950660705566
Validation loss: 2.3650713165601096

Epoch: 5| Step: 1
Training loss: 2.367368221282959
Validation loss: 2.3178188502788544

Epoch: 5| Step: 2
Training loss: 2.412440776824951
Validation loss: 2.2549181481202445

Epoch: 5| Step: 3
Training loss: 1.773648977279663
Validation loss: 2.23807426293691

Epoch: 5| Step: 4
Training loss: 1.4661228656768799
Validation loss: 2.2057167987028756

Epoch: 5| Step: 5
Training loss: 2.51904559135437
Validation loss: 2.1841413577397666

Epoch: 5| Step: 6
Training loss: 2.4310946464538574
Validation loss: 2.1794517437616983

Epoch: 5| Step: 7
Training loss: 2.255399703979492
Validation loss: 2.1687238117059073

Epoch: 5| Step: 8
Training loss: 2.7778635025024414
Validation loss: 2.151782731215159

Epoch: 5| Step: 9
Training loss: 1.8700084686279297
Validation loss: 2.161162868142128

Epoch: 5| Step: 10
Training loss: 2.2993550300598145
Validation loss: 2.1785550167163215

Epoch: 5| Step: 11
Training loss: 3.2684926986694336
Validation loss: 2.1992546170949936

Epoch: 7| Step: 0
Training loss: 2.8527309894561768
Validation loss: 2.199916794896126

Epoch: 5| Step: 1
Training loss: 1.7977771759033203
Validation loss: 2.206204811731974

Epoch: 5| Step: 2
Training loss: 2.453122615814209
Validation loss: 2.1977490931749344

Epoch: 5| Step: 3
Training loss: 2.4196386337280273
Validation loss: 2.194894254207611

Epoch: 5| Step: 4
Training loss: 2.2748725414276123
Validation loss: 2.1641090710957847

Epoch: 5| Step: 5
Training loss: 2.5940942764282227
Validation loss: 2.159704973300298

Epoch: 5| Step: 6
Training loss: 1.8664171695709229
Validation loss: 2.153330077727636

Epoch: 5| Step: 7
Training loss: 2.0303330421447754
Validation loss: 2.140931487083435

Epoch: 5| Step: 8
Training loss: 2.014277696609497
Validation loss: 2.1436117539803186

Epoch: 5| Step: 9
Training loss: 1.9229673147201538
Validation loss: 2.135981783270836

Epoch: 5| Step: 10
Training loss: 2.164689064025879
Validation loss: 2.150765041510264

Epoch: 5| Step: 11
Training loss: 1.1532278060913086
Validation loss: 2.150340810418129

Epoch: 8| Step: 0
Training loss: 2.662743330001831
Validation loss: 2.162432407339414

Epoch: 5| Step: 1
Training loss: 2.676237106323242
Validation loss: 2.1639528572559357

Epoch: 5| Step: 2
Training loss: 2.2601590156555176
Validation loss: 2.1732846001784005

Epoch: 5| Step: 3
Training loss: 1.9670114517211914
Validation loss: 2.1849754750728607

Epoch: 5| Step: 4
Training loss: 2.0042757987976074
Validation loss: 2.193656027317047

Epoch: 5| Step: 5
Training loss: 1.6771767139434814
Validation loss: 2.1959372460842133

Epoch: 5| Step: 6
Training loss: 1.6906894445419312
Validation loss: 2.1870081027348838

Epoch: 5| Step: 7
Training loss: 2.3359506130218506
Validation loss: 2.2194394071896872

Epoch: 5| Step: 8
Training loss: 2.48319149017334
Validation loss: 2.195896029472351

Epoch: 5| Step: 9
Training loss: 1.5933239459991455
Validation loss: 2.189199075102806

Epoch: 5| Step: 10
Training loss: 2.5466017723083496
Validation loss: 2.179854099949201

Epoch: 5| Step: 11
Training loss: 4.068048477172852
Validation loss: 2.1790802081425986

Epoch: 9| Step: 0
Training loss: 2.359423875808716
Validation loss: 2.1716090937455497

Epoch: 5| Step: 1
Training loss: 2.0119988918304443
Validation loss: 2.182645400365194

Epoch: 5| Step: 2
Training loss: 2.1100986003875732
Validation loss: 2.1749545633792877

Epoch: 5| Step: 3
Training loss: 2.365185260772705
Validation loss: 2.1743278006712594

Epoch: 5| Step: 4
Training loss: 2.632096767425537
Validation loss: 2.1731319228808084

Epoch: 5| Step: 5
Training loss: 2.609100580215454
Validation loss: 2.172762314478556

Epoch: 5| Step: 6
Training loss: 1.9799315929412842
Validation loss: 2.1550448735555015

Epoch: 5| Step: 7
Training loss: 1.9294630289077759
Validation loss: 2.14671698709329

Epoch: 5| Step: 8
Training loss: 1.8903297185897827
Validation loss: 2.1555014650026956

Epoch: 5| Step: 9
Training loss: 1.975898027420044
Validation loss: 2.139971911907196

Epoch: 5| Step: 10
Training loss: 2.1446645259857178
Validation loss: 2.1343178848425546

Epoch: 5| Step: 11
Training loss: 1.0763940811157227
Validation loss: 2.1278656919797263

Epoch: 10| Step: 0
Training loss: 2.5429553985595703
Validation loss: 2.128478998939196

Epoch: 5| Step: 1
Training loss: 2.173982620239258
Validation loss: 2.1161271582047143

Epoch: 5| Step: 2
Training loss: 2.543806552886963
Validation loss: 2.131912271181742

Epoch: 5| Step: 3
Training loss: 2.3552050590515137
Validation loss: 2.1174547572930655

Epoch: 5| Step: 4
Training loss: 1.6760625839233398
Validation loss: 2.124841252962748

Epoch: 5| Step: 5
Training loss: 2.402268648147583
Validation loss: 2.1078367978334427

Epoch: 5| Step: 6
Training loss: 1.9407689571380615
Validation loss: 2.1066279162963233

Epoch: 5| Step: 7
Training loss: 2.1184463500976562
Validation loss: 2.1138073901335397

Epoch: 5| Step: 8
Training loss: 2.124000072479248
Validation loss: 2.1216556827227273

Epoch: 5| Step: 9
Training loss: 1.7134621143341064
Validation loss: 2.1296939055124917

Epoch: 5| Step: 10
Training loss: 2.089003801345825
Validation loss: 2.1211372117201486

Epoch: 5| Step: 11
Training loss: 0.7348475456237793
Validation loss: 2.1110518723726273

Epoch: 11| Step: 0
Training loss: 1.9602981805801392
Validation loss: 2.115787466367086

Epoch: 5| Step: 1
Training loss: 2.9648470878601074
Validation loss: 2.1209985266129174

Epoch: 5| Step: 2
Training loss: 2.4378936290740967
Validation loss: 2.134355510274569

Epoch: 5| Step: 3
Training loss: 1.6929817199707031
Validation loss: 2.1248434334993362

Epoch: 5| Step: 4
Training loss: 2.042959213256836
Validation loss: 2.1288935840129852

Epoch: 5| Step: 5
Training loss: 1.95894455909729
Validation loss: 2.1341213385264077

Epoch: 5| Step: 6
Training loss: 1.733294129371643
Validation loss: 2.1200022250413895

Epoch: 5| Step: 7
Training loss: 1.9663362503051758
Validation loss: 2.1201451122760773

Epoch: 5| Step: 8
Training loss: 2.271496295928955
Validation loss: 2.136590545376142

Epoch: 5| Step: 9
Training loss: 2.2465624809265137
Validation loss: 2.1145846843719482

Epoch: 5| Step: 10
Training loss: 2.523306369781494
Validation loss: 2.119329258799553

Epoch: 5| Step: 11
Training loss: 0.8162150382995605
Validation loss: 2.125857730706533

Epoch: 12| Step: 0
Training loss: 1.6242119073867798
Validation loss: 2.1047832568486533

Epoch: 5| Step: 1
Training loss: 2.002699851989746
Validation loss: 2.1031216830015182

Epoch: 5| Step: 2
Training loss: 2.2685840129852295
Validation loss: 2.102444459994634

Epoch: 5| Step: 3
Training loss: 2.31535005569458
Validation loss: 2.098769093553225

Epoch: 5| Step: 4
Training loss: 2.5094292163848877
Validation loss: 2.115761304895083

Epoch: 5| Step: 5
Training loss: 1.4530775547027588
Validation loss: 2.104344666004181

Epoch: 5| Step: 6
Training loss: 2.3114326000213623
Validation loss: 2.094716966152191

Epoch: 5| Step: 7
Training loss: 2.0820395946502686
Validation loss: 2.1142560789982476

Epoch: 5| Step: 8
Training loss: 2.1168291568756104
Validation loss: 2.088621894518534

Epoch: 5| Step: 9
Training loss: 2.4898622035980225
Validation loss: 2.097227767109871

Epoch: 5| Step: 10
Training loss: 1.957000732421875
Validation loss: 2.097838342189789

Epoch: 5| Step: 11
Training loss: 2.5562596321105957
Validation loss: 2.0988899171352386

Epoch: 13| Step: 0
Training loss: 2.6092517375946045
Validation loss: 2.0906677891810737

Epoch: 5| Step: 1
Training loss: 2.184211254119873
Validation loss: 2.1028528412183127

Epoch: 5| Step: 2
Training loss: 1.7674115896224976
Validation loss: 2.0901375313599906

Epoch: 5| Step: 3
Training loss: 2.1463863849639893
Validation loss: 2.105105777581533

Epoch: 5| Step: 4
Training loss: 2.0088634490966797
Validation loss: 2.1101536949475608

Epoch: 5| Step: 5
Training loss: 1.7986046075820923
Validation loss: 2.084991529583931

Epoch: 5| Step: 6
Training loss: 2.479928731918335
Validation loss: 2.0997542291879654

Epoch: 5| Step: 7
Training loss: 1.6637824773788452
Validation loss: 2.090296283364296

Epoch: 5| Step: 8
Training loss: 2.5339133739471436
Validation loss: 2.098604475458463

Epoch: 5| Step: 9
Training loss: 1.7632337808609009
Validation loss: 2.08518419166406

Epoch: 5| Step: 10
Training loss: 2.1911556720733643
Validation loss: 2.075176879763603

Epoch: 5| Step: 11
Training loss: 1.990738034248352
Validation loss: 2.092626084884008

Epoch: 14| Step: 0
Training loss: 1.8958162069320679
Validation loss: 2.0935682505369186

Epoch: 5| Step: 1
Training loss: 2.424624443054199
Validation loss: 2.0902761270602546

Epoch: 5| Step: 2
Training loss: 1.6522966623306274
Validation loss: 2.107262114683787

Epoch: 5| Step: 3
Training loss: 2.6468875408172607
Validation loss: 2.0872762501239777

Epoch: 5| Step: 4
Training loss: 2.559854745864868
Validation loss: 2.091404234369596

Epoch: 5| Step: 5
Training loss: 2.1189448833465576
Validation loss: 2.0910706371068954

Epoch: 5| Step: 6
Training loss: 1.7819187641143799
Validation loss: 2.1022289345661798

Epoch: 5| Step: 7
Training loss: 1.925680160522461
Validation loss: 2.0890450527270636

Epoch: 5| Step: 8
Training loss: 2.1014723777770996
Validation loss: 2.0794781347115836

Epoch: 5| Step: 9
Training loss: 1.6293433904647827
Validation loss: 2.0885961651802063

Epoch: 5| Step: 10
Training loss: 2.090852737426758
Validation loss: 2.085984100898107

Epoch: 5| Step: 11
Training loss: 1.7768000364303589
Validation loss: 2.0914425949255624

Epoch: 15| Step: 0
Training loss: 2.1372690200805664
Validation loss: 2.0918645759423575

Epoch: 5| Step: 1
Training loss: 1.8181946277618408
Validation loss: 2.0930116226275763

Epoch: 5| Step: 2
Training loss: 1.8413150310516357
Validation loss: 2.0744777570168176

Epoch: 5| Step: 3
Training loss: 1.5028345584869385
Validation loss: 2.0733355581760406

Epoch: 5| Step: 4
Training loss: 2.5973668098449707
Validation loss: 2.0742580890655518

Epoch: 5| Step: 5
Training loss: 2.166649341583252
Validation loss: 2.0948441276947656

Epoch: 5| Step: 6
Training loss: 2.527086019515991
Validation loss: 2.08780966202418

Epoch: 5| Step: 7
Training loss: 1.927344560623169
Validation loss: 2.0880185812711716

Epoch: 5| Step: 8
Training loss: 2.09800386428833
Validation loss: 2.082381243507067

Epoch: 5| Step: 9
Training loss: 2.2346205711364746
Validation loss: 2.090341513355573

Epoch: 5| Step: 10
Training loss: 1.780402421951294
Validation loss: 2.0941843539476395

Epoch: 5| Step: 11
Training loss: 2.2463583946228027
Validation loss: 2.0850838174422583

Epoch: 16| Step: 0
Training loss: 1.4605205059051514
Validation loss: 2.0748643378416696

Epoch: 5| Step: 1
Training loss: 1.826891303062439
Validation loss: 2.0922629038492837

Epoch: 5| Step: 2
Training loss: 2.0549302101135254
Validation loss: 2.090316688021024

Epoch: 5| Step: 3
Training loss: 2.683211088180542
Validation loss: 2.0843517581621804

Epoch: 5| Step: 4
Training loss: 2.6428349018096924
Validation loss: 2.0936616410811744

Epoch: 5| Step: 5
Training loss: 1.89020574092865
Validation loss: 2.1068076342344284

Epoch: 5| Step: 6
Training loss: 2.637897253036499
Validation loss: 2.094964707891146

Epoch: 5| Step: 7
Training loss: 2.3010406494140625
Validation loss: 2.0998843163251877

Epoch: 5| Step: 8
Training loss: 1.5520893335342407
Validation loss: 2.1045734783013663

Epoch: 5| Step: 9
Training loss: 1.7770267724990845
Validation loss: 2.0828669518232346

Epoch: 5| Step: 10
Training loss: 1.9691299200057983
Validation loss: 2.0889700104792914

Epoch: 5| Step: 11
Training loss: 2.733111619949341
Validation loss: 2.0850962897141776

Epoch: 17| Step: 0
Training loss: 2.1524040699005127
Validation loss: 2.0808127323786416

Epoch: 5| Step: 1
Training loss: 1.451695203781128
Validation loss: 2.088208089272181

Epoch: 5| Step: 2
Training loss: 2.1513512134552
Validation loss: 2.0843334992726645

Epoch: 5| Step: 3
Training loss: 2.3659684658050537
Validation loss: 2.0908311853806176

Epoch: 5| Step: 4
Training loss: 2.06905198097229
Validation loss: 2.08759472767512

Epoch: 5| Step: 5
Training loss: 1.6462923288345337
Validation loss: 2.0844619472821555

Epoch: 5| Step: 6
Training loss: 2.0465259552001953
Validation loss: 2.084037631750107

Epoch: 5| Step: 7
Training loss: 2.5467536449432373
Validation loss: 2.068776786327362

Epoch: 5| Step: 8
Training loss: 1.8511899709701538
Validation loss: 2.081070060531298

Epoch: 5| Step: 9
Training loss: 1.6158149242401123
Validation loss: 2.070866197347641

Epoch: 5| Step: 10
Training loss: 2.509549617767334
Validation loss: 2.0709557284911475

Epoch: 5| Step: 11
Training loss: 2.5804240703582764
Validation loss: 2.074153890212377

Epoch: 18| Step: 0
Training loss: 2.1295056343078613
Validation loss: 2.08952267964681

Epoch: 5| Step: 1
Training loss: 1.6564260721206665
Validation loss: 2.0721812347571054

Epoch: 5| Step: 2
Training loss: 2.4010074138641357
Validation loss: 2.089105839530627

Epoch: 5| Step: 3
Training loss: 2.1272544860839844
Validation loss: 2.084287613630295

Epoch: 5| Step: 4
Training loss: 2.101807117462158
Validation loss: 2.0778355399767556

Epoch: 5| Step: 5
Training loss: 1.9626662731170654
Validation loss: 2.0671118994553885

Epoch: 5| Step: 6
Training loss: 1.9614951610565186
Validation loss: 2.079216738541921

Epoch: 5| Step: 7
Training loss: 2.205958843231201
Validation loss: 2.0829971383015313

Epoch: 5| Step: 8
Training loss: 2.2444114685058594
Validation loss: 2.074453890323639

Epoch: 5| Step: 9
Training loss: 2.3777518272399902
Validation loss: 2.069177344441414

Epoch: 5| Step: 10
Training loss: 1.6769649982452393
Validation loss: 2.0779071052869162

Epoch: 5| Step: 11
Training loss: 0.8691067099571228
Validation loss: 2.071096489826838

Epoch: 19| Step: 0
Training loss: 1.9057716131210327
Validation loss: 2.0836513290802636

Epoch: 5| Step: 1
Training loss: 2.248100757598877
Validation loss: 2.072544038295746

Epoch: 5| Step: 2
Training loss: 1.8482898473739624
Validation loss: 2.086777021487554

Epoch: 5| Step: 3
Training loss: 2.0650856494903564
Validation loss: 2.0842438439528146

Epoch: 5| Step: 4
Training loss: 2.561365842819214
Validation loss: 2.086779127518336

Epoch: 5| Step: 5
Training loss: 2.427865982055664
Validation loss: 2.083721528450648

Epoch: 5| Step: 6
Training loss: 2.1060714721679688
Validation loss: 2.094051480293274

Epoch: 5| Step: 7
Training loss: 2.377167224884033
Validation loss: 2.079116935531298

Epoch: 5| Step: 8
Training loss: 1.746603012084961
Validation loss: 2.0757561773061752

Epoch: 5| Step: 9
Training loss: 1.300571322441101
Validation loss: 2.0684818228085837

Epoch: 5| Step: 10
Training loss: 1.7547996044158936
Validation loss: 2.0721385180950165

Epoch: 5| Step: 11
Training loss: 2.953752040863037
Validation loss: 2.080167909463247

Epoch: 20| Step: 0
Training loss: 1.5331065654754639
Validation loss: 2.065094217658043

Epoch: 5| Step: 1
Training loss: 2.225015640258789
Validation loss: 2.0781380087137222

Epoch: 5| Step: 2
Training loss: 1.7308584451675415
Validation loss: 2.060515344142914

Epoch: 5| Step: 3
Training loss: 2.0107860565185547
Validation loss: 2.084470053513845

Epoch: 5| Step: 4
Training loss: 2.274199962615967
Validation loss: 2.062581350406011

Epoch: 5| Step: 5
Training loss: 2.206514835357666
Validation loss: 2.0611191044251123

Epoch: 5| Step: 6
Training loss: 1.9337663650512695
Validation loss: 2.0847118397553763

Epoch: 5| Step: 7
Training loss: 2.8031246662139893
Validation loss: 2.0694840252399445

Epoch: 5| Step: 8
Training loss: 1.8362257480621338
Validation loss: 2.0851084093252816

Epoch: 5| Step: 9
Training loss: 1.898357629776001
Validation loss: 2.0767475416262946

Epoch: 5| Step: 10
Training loss: 1.7393643856048584
Validation loss: 2.0753785769144693

Epoch: 5| Step: 11
Training loss: 2.7344374656677246
Validation loss: 2.07118658721447

Epoch: 21| Step: 0
Training loss: 2.5151145458221436
Validation loss: 2.061569020152092

Epoch: 5| Step: 1
Training loss: 1.6103473901748657
Validation loss: 2.0633585304021835

Epoch: 5| Step: 2
Training loss: 1.8510589599609375
Validation loss: 2.066133330265681

Epoch: 5| Step: 3
Training loss: 2.626338005065918
Validation loss: 2.0606176455815635

Epoch: 5| Step: 4
Training loss: 2.206467390060425
Validation loss: 2.0768893708785376

Epoch: 5| Step: 5
Training loss: 2.3020734786987305
Validation loss: 2.0567134569088616

Epoch: 5| Step: 6
Training loss: 1.5607426166534424
Validation loss: 2.0796200881401696

Epoch: 5| Step: 7
Training loss: 1.8208879232406616
Validation loss: 2.07769638299942

Epoch: 5| Step: 8
Training loss: 1.9791858196258545
Validation loss: 2.0743271311124167

Epoch: 5| Step: 9
Training loss: 1.859857201576233
Validation loss: 2.0615332225958505

Epoch: 5| Step: 10
Training loss: 2.0967605113983154
Validation loss: 2.084611122806867

Epoch: 5| Step: 11
Training loss: 1.6222586631774902
Validation loss: 2.0759487003087997

Epoch: 22| Step: 0
Training loss: 1.935320496559143
Validation loss: 2.0692338099082312

Epoch: 5| Step: 1
Training loss: 2.305543899536133
Validation loss: 2.064235786596934

Epoch: 5| Step: 2
Training loss: 1.4989135265350342
Validation loss: 2.065344368418058

Epoch: 5| Step: 3
Training loss: 2.120185375213623
Validation loss: 2.0777848809957504

Epoch: 5| Step: 4
Training loss: 2.0195155143737793
Validation loss: 2.064235125978788

Epoch: 5| Step: 5
Training loss: 2.033360242843628
Validation loss: 2.069487154483795

Epoch: 5| Step: 6
Training loss: 2.1648926734924316
Validation loss: 2.0535987416903176

Epoch: 5| Step: 7
Training loss: 1.8753917217254639
Validation loss: 2.0577498426040015

Epoch: 5| Step: 8
Training loss: 1.9774811267852783
Validation loss: 2.059596781929334

Epoch: 5| Step: 9
Training loss: 2.332143783569336
Validation loss: 2.0634824484586716

Epoch: 5| Step: 10
Training loss: 1.848926305770874
Validation loss: 2.060461396972338

Epoch: 5| Step: 11
Training loss: 2.9567956924438477
Validation loss: 2.0507682313521705

Epoch: 23| Step: 0
Training loss: 2.8696441650390625
Validation loss: 2.0670529703299203

Epoch: 5| Step: 1
Training loss: 1.9607925415039062
Validation loss: 2.076750546693802

Epoch: 5| Step: 2
Training loss: 2.158475637435913
Validation loss: 2.068966661890348

Epoch: 5| Step: 3
Training loss: 2.1433653831481934
Validation loss: 2.0623288999001184

Epoch: 5| Step: 4
Training loss: 2.295081377029419
Validation loss: 2.0590476344029107

Epoch: 5| Step: 5
Training loss: 1.554925799369812
Validation loss: 2.0763168931007385

Epoch: 5| Step: 6
Training loss: 1.8482602834701538
Validation loss: 2.0745163708925247

Epoch: 5| Step: 7
Training loss: 1.5762594938278198
Validation loss: 2.0643894424041114

Epoch: 5| Step: 8
Training loss: 1.4146897792816162
Validation loss: 2.074266240000725

Epoch: 5| Step: 9
Training loss: 2.3939411640167236
Validation loss: 2.0610353499650955

Epoch: 5| Step: 10
Training loss: 2.270223617553711
Validation loss: 2.0635194778442383

Epoch: 5| Step: 11
Training loss: 0.7514591813087463
Validation loss: 2.0814790030320487

Epoch: 24| Step: 0
Training loss: 2.817692518234253
Validation loss: 2.068308487534523

Epoch: 5| Step: 1
Training loss: 2.0605056285858154
Validation loss: 2.0643336276213327

Epoch: 5| Step: 2
Training loss: 2.0854897499084473
Validation loss: 2.0673016210397086

Epoch: 5| Step: 3
Training loss: 1.9657611846923828
Validation loss: 2.0566719820102057

Epoch: 5| Step: 4
Training loss: 2.4343247413635254
Validation loss: 2.0579759081204734

Epoch: 5| Step: 5
Training loss: 1.500956416130066
Validation loss: 2.0548920184373856

Epoch: 5| Step: 6
Training loss: 1.9610023498535156
Validation loss: 2.070476839939753

Epoch: 5| Step: 7
Training loss: 1.72976815700531
Validation loss: 2.0617266098658242

Epoch: 5| Step: 8
Training loss: 1.7815145254135132
Validation loss: 2.068680296341578

Epoch: 5| Step: 9
Training loss: 1.7659469842910767
Validation loss: 2.0640223870674768

Epoch: 5| Step: 10
Training loss: 2.0143401622772217
Validation loss: 2.067052165667216

Epoch: 5| Step: 11
Training loss: 2.0066540241241455
Validation loss: 2.0693990836540856

Epoch: 25| Step: 0
Training loss: 1.7559130191802979
Validation loss: 2.052185997366905

Epoch: 5| Step: 1
Training loss: 1.8833057880401611
Validation loss: 2.063340485095978

Epoch: 5| Step: 2
Training loss: 2.247739315032959
Validation loss: 2.0755091657241187

Epoch: 5| Step: 3
Training loss: 1.7678096294403076
Validation loss: 2.0506802201271057

Epoch: 5| Step: 4
Training loss: 2.283362865447998
Validation loss: 2.057791734735171

Epoch: 5| Step: 5
Training loss: 1.688585638999939
Validation loss: 2.0531739244858422

Epoch: 5| Step: 6
Training loss: 1.8668752908706665
Validation loss: 2.0592135985692344

Epoch: 5| Step: 7
Training loss: 2.355421543121338
Validation loss: 2.0665365109841027

Epoch: 5| Step: 8
Training loss: 1.8538649082183838
Validation loss: 2.073999638358752

Epoch: 5| Step: 9
Training loss: 2.094505786895752
Validation loss: 2.064433659116427

Epoch: 5| Step: 10
Training loss: 2.368840456008911
Validation loss: 2.0544001162052155

Epoch: 5| Step: 11
Training loss: 1.8522942066192627
Validation loss: 2.0688396990299225

Epoch: 26| Step: 0
Training loss: 2.6523900032043457
Validation loss: 2.0497715870539346

Epoch: 5| Step: 1
Training loss: 1.9553533792495728
Validation loss: 2.0747311462958655

Epoch: 5| Step: 2
Training loss: 1.8419338464736938
Validation loss: 2.0737151006857553

Epoch: 5| Step: 3
Training loss: 1.8184764385223389
Validation loss: 2.061859125892321

Epoch: 5| Step: 4
Training loss: 2.105414628982544
Validation loss: 2.077422628800074

Epoch: 5| Step: 5
Training loss: 1.817631483078003
Validation loss: 2.0767275293668113

Epoch: 5| Step: 6
Training loss: 1.8860890865325928
Validation loss: 2.077480986714363

Epoch: 5| Step: 7
Training loss: 1.6631724834442139
Validation loss: 2.0776911824941635

Epoch: 5| Step: 8
Training loss: 2.293194055557251
Validation loss: 2.0758714924256005

Epoch: 5| Step: 9
Training loss: 2.6553025245666504
Validation loss: 2.0672903060913086

Epoch: 5| Step: 10
Training loss: 1.652490258216858
Validation loss: 2.076219007372856

Epoch: 5| Step: 11
Training loss: 1.3494856357574463
Validation loss: 2.06996081272761

Epoch: 27| Step: 0
Training loss: 2.167609453201294
Validation loss: 2.064971079428991

Epoch: 5| Step: 1
Training loss: 2.137946605682373
Validation loss: 2.0565043638149896

Epoch: 5| Step: 2
Training loss: 1.9610258340835571
Validation loss: 2.054878200093905

Epoch: 5| Step: 3
Training loss: 2.6003928184509277
Validation loss: 2.0663571655750275

Epoch: 5| Step: 4
Training loss: 2.313488483428955
Validation loss: 2.0764074673255286

Epoch: 5| Step: 5
Training loss: 1.996912956237793
Validation loss: 2.074092298746109

Epoch: 5| Step: 6
Training loss: 1.6345348358154297
Validation loss: 2.066081936160723

Epoch: 5| Step: 7
Training loss: 2.1584086418151855
Validation loss: 2.0624595135450363

Epoch: 5| Step: 8
Training loss: 1.7667255401611328
Validation loss: 2.0485867957274118

Epoch: 5| Step: 9
Training loss: 2.157769203186035
Validation loss: 2.050597757101059

Epoch: 5| Step: 10
Training loss: 1.454576849937439
Validation loss: 2.048492138584455

Epoch: 5| Step: 11
Training loss: 1.3164794445037842
Validation loss: 2.063571592171987

Epoch: 28| Step: 0
Training loss: 1.5892417430877686
Validation loss: 2.0524232238531113

Epoch: 5| Step: 1
Training loss: 2.0000767707824707
Validation loss: 2.0699735581874847

Epoch: 5| Step: 2
Training loss: 2.374617099761963
Validation loss: 2.0545853028694787

Epoch: 5| Step: 3
Training loss: 2.41874361038208
Validation loss: 2.0701291412115097

Epoch: 5| Step: 4
Training loss: 2.2572062015533447
Validation loss: 2.063644309838613

Epoch: 5| Step: 5
Training loss: 1.496925950050354
Validation loss: 2.058809906244278

Epoch: 5| Step: 6
Training loss: 2.157193660736084
Validation loss: 2.0689289768536887

Epoch: 5| Step: 7
Training loss: 2.1918282508850098
Validation loss: 2.0550944606463113

Epoch: 5| Step: 8
Training loss: 1.661668062210083
Validation loss: 2.0675803869962692

Epoch: 5| Step: 9
Training loss: 1.6350364685058594
Validation loss: 2.058091680208842

Epoch: 5| Step: 10
Training loss: 1.8829914331436157
Validation loss: 2.0668816020091376

Epoch: 5| Step: 11
Training loss: 3.5857739448547363
Validation loss: 2.057397723197937

Epoch: 29| Step: 0
Training loss: 1.796779990196228
Validation loss: 2.068833669026693

Epoch: 5| Step: 1
Training loss: 1.3468748331069946
Validation loss: 2.0468572775522866

Epoch: 5| Step: 2
Training loss: 1.7570197582244873
Validation loss: 2.071577414870262

Epoch: 5| Step: 3
Training loss: 2.479414463043213
Validation loss: 2.0451380958159766

Epoch: 5| Step: 4
Training loss: 2.304429769515991
Validation loss: 2.0488442728916803

Epoch: 5| Step: 5
Training loss: 1.9758265018463135
Validation loss: 2.064622402191162

Epoch: 5| Step: 6
Training loss: 2.2607216835021973
Validation loss: 2.0469671487808228

Epoch: 5| Step: 7
Training loss: 1.7325493097305298
Validation loss: 2.056957244873047

Epoch: 5| Step: 8
Training loss: 2.1880316734313965
Validation loss: 2.051238273580869

Epoch: 5| Step: 9
Training loss: 2.6064910888671875
Validation loss: 2.0604408234357834

Epoch: 5| Step: 10
Training loss: 1.7544126510620117
Validation loss: 2.0609774192174277

Epoch: 5| Step: 11
Training loss: 1.0578632354736328
Validation loss: 2.0610638012488685

Epoch: 30| Step: 0
Training loss: 2.137497901916504
Validation loss: 2.0587945034106574

Epoch: 5| Step: 1
Training loss: 2.1439356803894043
Validation loss: 2.0580599308013916

Epoch: 5| Step: 2
Training loss: 1.8937040567398071
Validation loss: 2.053278719385465

Epoch: 5| Step: 3
Training loss: 2.0465123653411865
Validation loss: 2.0505503565073013

Epoch: 5| Step: 4
Training loss: 1.4972617626190186
Validation loss: 2.057162324587504

Epoch: 5| Step: 5
Training loss: 1.7962146997451782
Validation loss: 2.057441328962644

Epoch: 5| Step: 6
Training loss: 2.1197164058685303
Validation loss: 2.050109957655271

Epoch: 5| Step: 7
Training loss: 2.2932839393615723
Validation loss: 2.0384632498025894

Epoch: 5| Step: 8
Training loss: 1.9963417053222656
Validation loss: 2.061969662706057

Epoch: 5| Step: 9
Training loss: 2.464791774749756
Validation loss: 2.0645621915658317

Epoch: 5| Step: 10
Training loss: 1.6167141199111938
Validation loss: 2.05823715031147

Epoch: 5| Step: 11
Training loss: 2.1430788040161133
Validation loss: 2.0688122510910034

Epoch: 31| Step: 0
Training loss: 2.0792534351348877
Validation loss: 2.064686636130015

Epoch: 5| Step: 1
Training loss: 2.0464155673980713
Validation loss: 2.0654906382163367

Epoch: 5| Step: 2
Training loss: 2.0347604751586914
Validation loss: 2.047395810484886

Epoch: 5| Step: 3
Training loss: 1.6108672618865967
Validation loss: 2.0668048610289893

Epoch: 5| Step: 4
Training loss: 1.8021857738494873
Validation loss: 2.0663347293933234

Epoch: 5| Step: 5
Training loss: 2.1633200645446777
Validation loss: 2.0672964056332908

Epoch: 5| Step: 6
Training loss: 2.059070110321045
Validation loss: 2.054850240548452

Epoch: 5| Step: 7
Training loss: 2.03933048248291
Validation loss: 2.0458448082208633

Epoch: 5| Step: 8
Training loss: 1.835229516029358
Validation loss: 2.048667033513387

Epoch: 5| Step: 9
Training loss: 1.8256378173828125
Validation loss: 2.0589549442132316

Epoch: 5| Step: 10
Training loss: 2.4532439708709717
Validation loss: 2.0540075848499932

Epoch: 5| Step: 11
Training loss: 2.9030308723449707
Validation loss: 2.0638255178928375

Epoch: 32| Step: 0
Training loss: 1.9418331384658813
Validation loss: 2.0563539216915765

Epoch: 5| Step: 1
Training loss: 1.8910877704620361
Validation loss: 2.0477561006943383

Epoch: 5| Step: 2
Training loss: 1.7792854309082031
Validation loss: 2.074349453051885

Epoch: 5| Step: 3
Training loss: 1.8844680786132812
Validation loss: 2.064522460103035

Epoch: 5| Step: 4
Training loss: 2.4329631328582764
Validation loss: 2.0661992132663727

Epoch: 5| Step: 5
Training loss: 2.171081304550171
Validation loss: 2.065163552761078

Epoch: 5| Step: 6
Training loss: 1.2574989795684814
Validation loss: 2.067880555987358

Epoch: 5| Step: 7
Training loss: 2.1901516914367676
Validation loss: 2.073808565735817

Epoch: 5| Step: 8
Training loss: 2.3726840019226074
Validation loss: 2.0896456092596054

Epoch: 5| Step: 9
Training loss: 2.203500509262085
Validation loss: 2.0663941552241645

Epoch: 5| Step: 10
Training loss: 1.7196054458618164
Validation loss: 2.0790263017018638

Epoch: 5| Step: 11
Training loss: 2.0123865604400635
Validation loss: 2.071962038675944

Epoch: 33| Step: 0
Training loss: 1.7699174880981445
Validation loss: 2.0778886526823044

Epoch: 5| Step: 1
Training loss: 2.0362236499786377
Validation loss: 2.088233768939972

Epoch: 5| Step: 2
Training loss: 2.14951753616333
Validation loss: 2.0889930725097656

Epoch: 5| Step: 3
Training loss: 2.119199514389038
Validation loss: 2.0898218204577765

Epoch: 5| Step: 4
Training loss: 1.53266441822052
Validation loss: 2.0722116082906723

Epoch: 5| Step: 5
Training loss: 1.7938867807388306
Validation loss: 2.0672767708698907

Epoch: 5| Step: 6
Training loss: 2.126534938812256
Validation loss: 2.0852068215608597

Epoch: 5| Step: 7
Training loss: 2.115814208984375
Validation loss: 2.0735567013422647

Epoch: 5| Step: 8
Training loss: 1.8274142742156982
Validation loss: 2.0554842998584113

Epoch: 5| Step: 9
Training loss: 2.3145854473114014
Validation loss: 2.045319825410843

Epoch: 5| Step: 10
Training loss: 2.280646800994873
Validation loss: 2.0551923414071402

Epoch: 5| Step: 11
Training loss: 1.8723411560058594
Validation loss: 2.0728424936532974

Epoch: 34| Step: 0
Training loss: 1.4870458841323853
Validation loss: 2.051128546396891

Epoch: 5| Step: 1
Training loss: 2.4479281902313232
Validation loss: 2.061640198032061

Epoch: 5| Step: 2
Training loss: 2.5583856105804443
Validation loss: 2.052181288599968

Epoch: 5| Step: 3
Training loss: 1.853045105934143
Validation loss: 2.0562434593836465

Epoch: 5| Step: 4
Training loss: 1.6763519048690796
Validation loss: 2.05293703575929

Epoch: 5| Step: 5
Training loss: 2.0979371070861816
Validation loss: 2.049337923526764

Epoch: 5| Step: 6
Training loss: 2.6178078651428223
Validation loss: 2.0563610047101974

Epoch: 5| Step: 7
Training loss: 2.1085426807403564
Validation loss: 2.0662577748298645

Epoch: 5| Step: 8
Training loss: 2.1699392795562744
Validation loss: 2.06530669828256

Epoch: 5| Step: 9
Training loss: 1.7203924655914307
Validation loss: 2.062671129902204

Epoch: 5| Step: 10
Training loss: 1.3128645420074463
Validation loss: 2.0574228217204413

Epoch: 5| Step: 11
Training loss: 1.6427597999572754
Validation loss: 2.058977315823237

Epoch: 35| Step: 0
Training loss: 2.1109585762023926
Validation loss: 2.050441528360049

Epoch: 5| Step: 1
Training loss: 1.8018443584442139
Validation loss: 2.0653512328863144

Epoch: 5| Step: 2
Training loss: 1.6521886587142944
Validation loss: 2.0491876006126404

Epoch: 5| Step: 3
Training loss: 2.1031441688537598
Validation loss: 2.068778877456983

Epoch: 5| Step: 4
Training loss: 2.62192702293396
Validation loss: 2.0558884888887405

Epoch: 5| Step: 5
Training loss: 1.3697082996368408
Validation loss: 2.0514555970827737

Epoch: 5| Step: 6
Training loss: 2.083117961883545
Validation loss: 2.0469891180594764

Epoch: 5| Step: 7
Training loss: 2.1520016193389893
Validation loss: 2.0507359306017556

Epoch: 5| Step: 8
Training loss: 1.9226551055908203
Validation loss: 2.037570963303248

Epoch: 5| Step: 9
Training loss: 1.6056492328643799
Validation loss: 2.045271267493566

Epoch: 5| Step: 10
Training loss: 1.822739601135254
Validation loss: 2.0623705933491387

Epoch: 5| Step: 11
Training loss: 4.669608116149902
Validation loss: 2.059137667218844

Epoch: 36| Step: 0
Training loss: 1.9957389831542969
Validation loss: 2.0554750512043634

Epoch: 5| Step: 1
Training loss: 2.2035324573516846
Validation loss: 2.0446229030688605

Epoch: 5| Step: 2
Training loss: 1.8849258422851562
Validation loss: 2.04566653072834

Epoch: 5| Step: 3
Training loss: 2.1721317768096924
Validation loss: 2.0620707273483276

Epoch: 5| Step: 4
Training loss: 1.7756366729736328
Validation loss: 2.0510616302490234

Epoch: 5| Step: 5
Training loss: 1.9418970346450806
Validation loss: 2.0559023370345435

Epoch: 5| Step: 6
Training loss: 1.762674331665039
Validation loss: 2.053125043710073

Epoch: 5| Step: 7
Training loss: 2.0250165462493896
Validation loss: 2.059428329269091

Epoch: 5| Step: 8
Training loss: 1.6052427291870117
Validation loss: 2.0666688084602356

Epoch: 5| Step: 9
Training loss: 1.76913321018219
Validation loss: 2.059207116564115

Epoch: 5| Step: 10
Training loss: 2.7733654975891113
Validation loss: 2.0443918804327645

Epoch: 5| Step: 11
Training loss: 1.860377550125122
Validation loss: 2.0401779413223267

Epoch: 37| Step: 0
Training loss: 1.3518365621566772
Validation loss: 2.0505194664001465

Epoch: 5| Step: 1
Training loss: 2.364929676055908
Validation loss: 2.0653624335924783

Epoch: 5| Step: 2
Training loss: 2.337404251098633
Validation loss: 2.0689620872338614

Epoch: 5| Step: 3
Training loss: 1.962950348854065
Validation loss: 2.0709217389424643

Epoch: 5| Step: 4
Training loss: 1.8343591690063477
Validation loss: 2.0746298680702844

Epoch: 5| Step: 5
Training loss: 1.9835116863250732
Validation loss: 2.0987751285235086

Epoch: 5| Step: 6
Training loss: 2.179394483566284
Validation loss: 2.0955422123273215

Epoch: 5| Step: 7
Training loss: 2.409444808959961
Validation loss: 2.077353820204735

Epoch: 5| Step: 8
Training loss: 1.4358184337615967
Validation loss: 2.0812943279743195

Epoch: 5| Step: 9
Training loss: 1.5845028162002563
Validation loss: 2.0758446057637534

Epoch: 5| Step: 10
Training loss: 2.429307460784912
Validation loss: 2.0549312283595405

Epoch: 5| Step: 11
Training loss: 2.65158748626709
Validation loss: 2.08056433002154

Epoch: 38| Step: 0
Training loss: 2.3496155738830566
Validation loss: 2.047401304046313

Epoch: 5| Step: 1
Training loss: 2.4021453857421875
Validation loss: 2.0509021083513894

Epoch: 5| Step: 2
Training loss: 1.6871373653411865
Validation loss: 2.0612791031599045

Epoch: 5| Step: 3
Training loss: 1.7465041875839233
Validation loss: 2.0400951554377875

Epoch: 5| Step: 4
Training loss: 2.5457959175109863
Validation loss: 2.045962020754814

Epoch: 5| Step: 5
Training loss: 2.392704725265503
Validation loss: 2.062290315826734

Epoch: 5| Step: 6
Training loss: 1.730621576309204
Validation loss: 2.0551368792851767

Epoch: 5| Step: 7
Training loss: 1.5382932424545288
Validation loss: 2.0609372655550637

Epoch: 5| Step: 8
Training loss: 1.8947890996932983
Validation loss: 2.059130902091662

Epoch: 5| Step: 9
Training loss: 1.524831771850586
Validation loss: 2.059929961959521

Epoch: 5| Step: 10
Training loss: 2.280618667602539
Validation loss: 2.061014696955681

Epoch: 5| Step: 11
Training loss: 1.5704632997512817
Validation loss: 2.0416645059982934

Epoch: 39| Step: 0
Training loss: 1.7405954599380493
Validation loss: 2.048750400543213

Epoch: 5| Step: 1
Training loss: 2.1053366661071777
Validation loss: 2.0587128748496375

Epoch: 5| Step: 2
Training loss: 2.1229283809661865
Validation loss: 2.070134922862053

Epoch: 5| Step: 3
Training loss: 1.7953622341156006
Validation loss: 2.0449456622203193

Epoch: 5| Step: 4
Training loss: 2.2781448364257812
Validation loss: 2.0772381921609244

Epoch: 5| Step: 5
Training loss: 2.2732720375061035
Validation loss: 2.0818099677562714

Epoch: 5| Step: 6
Training loss: 1.6516050100326538
Validation loss: 2.084819177786509

Epoch: 5| Step: 7
Training loss: 1.8882114887237549
Validation loss: 2.0875146985054016

Epoch: 5| Step: 8
Training loss: 2.5223183631896973
Validation loss: 2.100275695323944

Epoch: 5| Step: 9
Training loss: 1.2917931079864502
Validation loss: 2.098164826631546

Epoch: 5| Step: 10
Training loss: 2.196229934692383
Validation loss: 2.0718916108210883

Epoch: 5| Step: 11
Training loss: 2.325793743133545
Validation loss: 2.0753616988658905

Epoch: 40| Step: 0
Training loss: 1.8453086614608765
Validation loss: 2.07159091035525

Epoch: 5| Step: 1
Training loss: 2.1129469871520996
Validation loss: 2.0595445185899734

Epoch: 5| Step: 2
Training loss: 1.8803062438964844
Validation loss: 2.050243765115738

Epoch: 5| Step: 3
Training loss: 1.6849658489227295
Validation loss: 2.0607420901457467

Epoch: 5| Step: 4
Training loss: 2.5413362979888916
Validation loss: 2.0504805892705917

Epoch: 5| Step: 5
Training loss: 2.3026509284973145
Validation loss: 2.0519905338684716

Epoch: 5| Step: 6
Training loss: 1.9883215427398682
Validation loss: 2.052152236302694

Epoch: 5| Step: 7
Training loss: 2.0452821254730225
Validation loss: 2.057129666209221

Epoch: 5| Step: 8
Training loss: 1.9976783990859985
Validation loss: 2.0437197585900626

Epoch: 5| Step: 9
Training loss: 1.4041101932525635
Validation loss: 2.057902986804644

Epoch: 5| Step: 10
Training loss: 1.9233081340789795
Validation loss: 2.051826705535253

Epoch: 5| Step: 11
Training loss: 1.6394174098968506
Validation loss: 2.035215566555659

Epoch: 41| Step: 0
Training loss: 1.7035808563232422
Validation loss: 2.050083522995313

Epoch: 5| Step: 1
Training loss: 1.4088070392608643
Validation loss: 2.0354244957367578

Epoch: 5| Step: 2
Training loss: 2.1647791862487793
Validation loss: 2.0367311586936316

Epoch: 5| Step: 3
Training loss: 1.9619977474212646
Validation loss: 2.0479165613651276

Epoch: 5| Step: 4
Training loss: 1.7227671146392822
Validation loss: 2.043978452682495

Epoch: 5| Step: 5
Training loss: 2.1753363609313965
Validation loss: 2.0545327017704644

Epoch: 5| Step: 6
Training loss: 2.4407196044921875
Validation loss: 2.039245436588923

Epoch: 5| Step: 7
Training loss: 2.016775131225586
Validation loss: 2.048104186852773

Epoch: 5| Step: 8
Training loss: 1.768000841140747
Validation loss: 2.0351738234361014

Epoch: 5| Step: 9
Training loss: 2.20721173286438
Validation loss: 2.047711819410324

Epoch: 5| Step: 10
Training loss: 1.9998964071273804
Validation loss: 2.0552374670902886

Epoch: 5| Step: 11
Training loss: 2.876725435256958
Validation loss: 2.0512164334456124

Epoch: 42| Step: 0
Training loss: 2.2960422039031982
Validation loss: 2.0519193907578788

Epoch: 5| Step: 1
Training loss: 2.2759697437286377
Validation loss: 2.054168383280436

Epoch: 5| Step: 2
Training loss: 1.7897727489471436
Validation loss: 2.0649758179982505

Epoch: 5| Step: 3
Training loss: 1.674187421798706
Validation loss: 2.0646213044722876

Epoch: 5| Step: 4
Training loss: 1.7449924945831299
Validation loss: 2.0618201047182083

Epoch: 5| Step: 5
Training loss: 1.5427340269088745
Validation loss: 2.0491290042797723

Epoch: 5| Step: 6
Training loss: 1.5882513523101807
Validation loss: 2.0479096869627633

Epoch: 5| Step: 7
Training loss: 2.2574644088745117
Validation loss: 2.0602842470010123

Epoch: 5| Step: 8
Training loss: 2.16888427734375
Validation loss: 2.057388057311376

Epoch: 5| Step: 9
Training loss: 2.014418363571167
Validation loss: 2.0624122619628906

Epoch: 5| Step: 10
Training loss: 2.1332709789276123
Validation loss: 2.0573242902755737

Epoch: 5| Step: 11
Training loss: 2.138461112976074
Validation loss: 2.0600122014681497

Epoch: 43| Step: 0
Training loss: 2.432222843170166
Validation loss: 2.0716560781002045

Epoch: 5| Step: 1
Training loss: 2.352827548980713
Validation loss: 2.0631564060846963

Epoch: 5| Step: 2
Training loss: 1.9772701263427734
Validation loss: 2.0656896034876504

Epoch: 5| Step: 3
Training loss: 2.0280938148498535
Validation loss: 2.052013104160627

Epoch: 5| Step: 4
Training loss: 1.401918649673462
Validation loss: 2.0702084998289743

Epoch: 5| Step: 5
Training loss: 1.3937551975250244
Validation loss: 2.0596226255098977

Epoch: 5| Step: 6
Training loss: 2.605353593826294
Validation loss: 2.064267565806707

Epoch: 5| Step: 7
Training loss: 2.066253423690796
Validation loss: 2.0555760016043982

Epoch: 5| Step: 8
Training loss: 2.0764522552490234
Validation loss: 2.063823545972506

Epoch: 5| Step: 9
Training loss: 1.7483733892440796
Validation loss: 2.0753916452328363

Epoch: 5| Step: 10
Training loss: 1.5375276803970337
Validation loss: 2.0421478102604547

Epoch: 5| Step: 11
Training loss: 1.6083585023880005
Validation loss: 2.0688687562942505

Epoch: 44| Step: 0
Training loss: 1.8398878574371338
Validation loss: 2.0581490198771157

Epoch: 5| Step: 1
Training loss: 2.266035795211792
Validation loss: 2.0478824277718863

Epoch: 5| Step: 2
Training loss: 1.6853258609771729
Validation loss: 2.0461740593115487

Epoch: 5| Step: 3
Training loss: 1.958822250366211
Validation loss: 2.0460571348667145

Epoch: 5| Step: 4
Training loss: 2.502941370010376
Validation loss: 2.0526646971702576

Epoch: 5| Step: 5
Training loss: 1.767695426940918
Validation loss: 2.040797824660937

Epoch: 5| Step: 6
Training loss: 2.1705386638641357
Validation loss: 2.0550375829140344

Epoch: 5| Step: 7
Training loss: 1.5319654941558838
Validation loss: 2.049291561047236

Epoch: 5| Step: 8
Training loss: 1.7569382190704346
Validation loss: 2.0367876440286636

Epoch: 5| Step: 9
Training loss: 2.205904006958008
Validation loss: 2.050376539429029

Epoch: 5| Step: 10
Training loss: 2.08667254447937
Validation loss: 2.045679986476898

Epoch: 5| Step: 11
Training loss: 1.6184953451156616
Validation loss: 2.0439913471539817

Epoch: 45| Step: 0
Training loss: 2.0268473625183105
Validation loss: 2.0592831124862037

Epoch: 5| Step: 1
Training loss: 2.581961154937744
Validation loss: 2.0521025558312735

Epoch: 5| Step: 2
Training loss: 1.5455125570297241
Validation loss: 2.0518078158299127

Epoch: 5| Step: 3
Training loss: 1.6429998874664307
Validation loss: 2.0453148583571115

Epoch: 5| Step: 4
Training loss: 1.9009370803833008
Validation loss: 2.0557754039764404

Epoch: 5| Step: 5
Training loss: 2.234955310821533
Validation loss: 2.059248462319374

Epoch: 5| Step: 6
Training loss: 1.997126817703247
Validation loss: 2.0575587898492813

Epoch: 5| Step: 7
Training loss: 1.4383913278579712
Validation loss: 2.0629318902889886

Epoch: 5| Step: 8
Training loss: 2.00911545753479
Validation loss: 2.073499103387197

Epoch: 5| Step: 9
Training loss: 1.9908727407455444
Validation loss: 2.072831908861796

Epoch: 5| Step: 10
Training loss: 1.9424784183502197
Validation loss: 2.06835546096166

Epoch: 5| Step: 11
Training loss: 2.486807346343994
Validation loss: 2.06184392174085

Epoch: 46| Step: 0
Training loss: 1.6322805881500244
Validation loss: 2.043119723598162

Epoch: 5| Step: 1
Training loss: 2.4117746353149414
Validation loss: 2.053112377723058

Epoch: 5| Step: 2
Training loss: 2.009307861328125
Validation loss: 2.063696483771006

Epoch: 5| Step: 3
Training loss: 1.8740335702896118
Validation loss: 2.0472443203131356

Epoch: 5| Step: 4
Training loss: 1.7677772045135498
Validation loss: 2.060389921069145

Epoch: 5| Step: 5
Training loss: 1.8062479496002197
Validation loss: 2.0523645132780075

Epoch: 5| Step: 6
Training loss: 2.035992383956909
Validation loss: 2.057871217528979

Epoch: 5| Step: 7
Training loss: 2.0369198322296143
Validation loss: 2.0556237598260245

Epoch: 5| Step: 8
Training loss: 2.3862786293029785
Validation loss: 2.045309752225876

Epoch: 5| Step: 9
Training loss: 1.8279870748519897
Validation loss: 2.0270235339800515

Epoch: 5| Step: 10
Training loss: 1.8521435260772705
Validation loss: 2.049349933862686

Epoch: 5| Step: 11
Training loss: 1.0531456470489502
Validation loss: 2.037130688627561

Epoch: 47| Step: 0
Training loss: 1.8074779510498047
Validation loss: 2.0532179176807404

Epoch: 5| Step: 1
Training loss: 2.1790504455566406
Validation loss: 2.0414747148752213

Epoch: 5| Step: 2
Training loss: 1.7101761102676392
Validation loss: 2.061230684320132

Epoch: 5| Step: 3
Training loss: 1.4320794343948364
Validation loss: 2.052188585201899

Epoch: 5| Step: 4
Training loss: 2.6047589778900146
Validation loss: 2.0632130602995553

Epoch: 5| Step: 5
Training loss: 1.9754283428192139
Validation loss: 2.066172038515409

Epoch: 5| Step: 6
Training loss: 2.0317721366882324
Validation loss: 2.056122213602066

Epoch: 5| Step: 7
Training loss: 1.9399598836898804
Validation loss: 2.062569002310435

Epoch: 5| Step: 8
Training loss: 1.9269351959228516
Validation loss: 2.0633702278137207

Epoch: 5| Step: 9
Training loss: 1.9546077251434326
Validation loss: 2.0462020536263785

Epoch: 5| Step: 10
Training loss: 2.1559178829193115
Validation loss: 2.0568399180968604

Epoch: 5| Step: 11
Training loss: 1.5292855501174927
Validation loss: 2.049368883172671

Epoch: 48| Step: 0
Training loss: 1.4600237607955933
Validation loss: 2.0630157540241876

Epoch: 5| Step: 1
Training loss: 1.6290791034698486
Validation loss: 2.0656533539295197

Epoch: 5| Step: 2
Training loss: 1.9580764770507812
Validation loss: 2.051803097128868

Epoch: 5| Step: 3
Training loss: 2.4334053993225098
Validation loss: 2.055547078450521

Epoch: 5| Step: 4
Training loss: 1.757796287536621
Validation loss: 2.048119435707728

Epoch: 5| Step: 5
Training loss: 1.7312138080596924
Validation loss: 2.051398033897082

Epoch: 5| Step: 6
Training loss: 2.2535572052001953
Validation loss: 2.056105002760887

Epoch: 5| Step: 7
Training loss: 2.2094998359680176
Validation loss: 2.050721446673075

Epoch: 5| Step: 8
Training loss: 1.8704544305801392
Validation loss: 2.06338669359684

Epoch: 5| Step: 9
Training loss: 1.5883044004440308
Validation loss: 2.054630016287168

Epoch: 5| Step: 10
Training loss: 2.413402795791626
Validation loss: 2.0513192415237427

Epoch: 5| Step: 11
Training loss: 2.4478037357330322
Validation loss: 2.0570180664459863

Epoch: 49| Step: 0
Training loss: 1.5605725049972534
Validation loss: 2.0694301426410675

Epoch: 5| Step: 1
Training loss: 1.7961375713348389
Validation loss: 2.0642946312824884

Epoch: 5| Step: 2
Training loss: 2.3059017658233643
Validation loss: 2.0708908289670944

Epoch: 5| Step: 3
Training loss: 2.243931293487549
Validation loss: 2.0926312853892646

Epoch: 5| Step: 4
Training loss: 2.0818991661071777
Validation loss: 2.085516835252444

Epoch: 5| Step: 5
Training loss: 2.328212261199951
Validation loss: 2.0664361814657846

Epoch: 5| Step: 6
Training loss: 2.1533355712890625
Validation loss: 2.0930860340595245

Epoch: 5| Step: 7
Training loss: 1.9909765720367432
Validation loss: 2.0821464359760284

Epoch: 5| Step: 8
Training loss: 1.6519238948822021
Validation loss: 2.0604833463827767

Epoch: 5| Step: 9
Training loss: 2.072953224182129
Validation loss: 2.0616237123807273

Epoch: 5| Step: 10
Training loss: 1.487206220626831
Validation loss: 2.0448183168967566

Epoch: 5| Step: 11
Training loss: 1.2635806798934937
Validation loss: 2.0375421593586602

Epoch: 50| Step: 0
Training loss: 1.569581151008606
Validation loss: 2.0389063159624734

Epoch: 5| Step: 1
Training loss: 1.9129104614257812
Validation loss: 2.0489263931910195

Epoch: 5| Step: 2
Training loss: 2.251319169998169
Validation loss: 2.065267706910769

Epoch: 5| Step: 3
Training loss: 1.9671961069107056
Validation loss: 2.051523134112358

Epoch: 5| Step: 4
Training loss: 1.7264385223388672
Validation loss: 2.055973822871844

Epoch: 5| Step: 5
Training loss: 2.2323527336120605
Validation loss: 2.0410161862770715

Epoch: 5| Step: 6
Training loss: 1.95595383644104
Validation loss: 2.045985162258148

Epoch: 5| Step: 7
Training loss: 1.9782317876815796
Validation loss: 2.052997683485349

Epoch: 5| Step: 8
Training loss: 1.8494408130645752
Validation loss: 2.0542847911516824

Epoch: 5| Step: 9
Training loss: 1.9794971942901611
Validation loss: 2.0603657364845276

Epoch: 5| Step: 10
Training loss: 2.064518451690674
Validation loss: 2.0449330459038415

Epoch: 5| Step: 11
Training loss: 0.8187382221221924
Validation loss: 2.0566762586434684

Epoch: 51| Step: 0
Training loss: 1.49663507938385
Validation loss: 2.0471795002619424

Epoch: 5| Step: 1
Training loss: 2.258474826812744
Validation loss: 2.0368864635626474

Epoch: 5| Step: 2
Training loss: 1.7468570470809937
Validation loss: 2.050534854332606

Epoch: 5| Step: 3
Training loss: 1.8178319931030273
Validation loss: 2.03270623087883

Epoch: 5| Step: 4
Training loss: 1.8679450750350952
Validation loss: 2.0633831520875296

Epoch: 5| Step: 5
Training loss: 1.9092648029327393
Validation loss: 2.0505583186944327

Epoch: 5| Step: 6
Training loss: 2.1363582611083984
Validation loss: 2.0484140813350677

Epoch: 5| Step: 7
Training loss: 1.6675927639007568
Validation loss: 2.0596564958492913

Epoch: 5| Step: 8
Training loss: 2.4392571449279785
Validation loss: 2.065519774953524

Epoch: 5| Step: 9
Training loss: 1.9018352031707764
Validation loss: 2.081645374496778

Epoch: 5| Step: 10
Training loss: 2.068556070327759
Validation loss: 2.0598361591498056

Epoch: 5| Step: 11
Training loss: 1.4201312065124512
Validation loss: 2.055809815724691

Epoch: 52| Step: 0
Training loss: 2.3785815238952637
Validation loss: 2.0559193591276803

Epoch: 5| Step: 1
Training loss: 1.808044672012329
Validation loss: 2.0628985663255057

Epoch: 5| Step: 2
Training loss: 1.8524166345596313
Validation loss: 2.0393662552038827

Epoch: 5| Step: 3
Training loss: 1.9620037078857422
Validation loss: 2.0628462930520377

Epoch: 5| Step: 4
Training loss: 1.4016268253326416
Validation loss: 2.040296117464701

Epoch: 5| Step: 5
Training loss: 2.255277633666992
Validation loss: 2.0459751089413962

Epoch: 5| Step: 6
Training loss: 1.857050895690918
Validation loss: 2.0640781223773956

Epoch: 5| Step: 7
Training loss: 2.4966378211975098
Validation loss: 2.0453003495931625

Epoch: 5| Step: 8
Training loss: 1.5197246074676514
Validation loss: 2.0609563489754996

Epoch: 5| Step: 9
Training loss: 1.792673110961914
Validation loss: 2.069881329933802

Epoch: 5| Step: 10
Training loss: 2.1331074237823486
Validation loss: 2.0548808525005975

Epoch: 5| Step: 11
Training loss: 1.2116212844848633
Validation loss: 2.047640323638916

Epoch: 53| Step: 0
Training loss: 1.6899515390396118
Validation loss: 2.0487022002538047

Epoch: 5| Step: 1
Training loss: 1.801648736000061
Validation loss: 2.0629422763983407

Epoch: 5| Step: 2
Training loss: 1.6702266931533813
Validation loss: 2.0558681885401406

Epoch: 5| Step: 3
Training loss: 2.005970001220703
Validation loss: 2.042286679148674

Epoch: 5| Step: 4
Training loss: 1.6092712879180908
Validation loss: 2.0520395040512085

Epoch: 5| Step: 5
Training loss: 2.1735057830810547
Validation loss: 2.0560835103193917

Epoch: 5| Step: 6
Training loss: 2.319330930709839
Validation loss: 2.051735450824102

Epoch: 5| Step: 7
Training loss: 1.8019578456878662
Validation loss: 2.039044032494227

Epoch: 5| Step: 8
Training loss: 2.089871883392334
Validation loss: 2.044997607668241

Epoch: 5| Step: 9
Training loss: 1.8520021438598633
Validation loss: 2.0459044128656387

Epoch: 5| Step: 10
Training loss: 2.2986903190612793
Validation loss: 2.057660828034083

Epoch: 5| Step: 11
Training loss: 1.065189242362976
Validation loss: 2.052073215444883

Epoch: 54| Step: 0
Training loss: 2.1624715328216553
Validation loss: 2.0475069681803384

Epoch: 5| Step: 1
Training loss: 1.7830661535263062
Validation loss: 2.058865870038668

Epoch: 5| Step: 2
Training loss: 1.9835125207901
Validation loss: 2.073885440826416

Epoch: 5| Step: 3
Training loss: 1.7577626705169678
Validation loss: 2.067731479803721

Epoch: 5| Step: 4
Training loss: 2.07346773147583
Validation loss: 2.063011849919955

Epoch: 5| Step: 5
Training loss: 2.621713399887085
Validation loss: 2.0597297499577203

Epoch: 5| Step: 6
Training loss: 1.627831220626831
Validation loss: 2.0490684608618417

Epoch: 5| Step: 7
Training loss: 1.6079654693603516
Validation loss: 2.0602769454320273

Epoch: 5| Step: 8
Training loss: 1.8433316946029663
Validation loss: 2.0435606886943183

Epoch: 5| Step: 9
Training loss: 2.0032906532287598
Validation loss: 2.0506397088368735

Epoch: 5| Step: 10
Training loss: 1.7506217956542969
Validation loss: 2.0544754962126413

Epoch: 5| Step: 11
Training loss: 2.314067840576172
Validation loss: 2.065635566910108

Epoch: 55| Step: 0
Training loss: 2.207458019256592
Validation loss: 2.05706779162089

Epoch: 5| Step: 1
Training loss: 2.1631569862365723
Validation loss: 2.0558163275321326

Epoch: 5| Step: 2
Training loss: 2.269453287124634
Validation loss: 2.0637942453225455

Epoch: 5| Step: 3
Training loss: 1.2461133003234863
Validation loss: 2.0530057549476624

Epoch: 5| Step: 4
Training loss: 1.719604730606079
Validation loss: 2.0634686897198358

Epoch: 5| Step: 5
Training loss: 1.8303018808364868
Validation loss: 2.06535767018795

Epoch: 5| Step: 6
Training loss: 1.590859055519104
Validation loss: 2.074675073226293

Epoch: 5| Step: 7
Training loss: 2.2648510932922363
Validation loss: 2.0778966744740806

Epoch: 5| Step: 8
Training loss: 2.392733335494995
Validation loss: 2.0388232469558716

Epoch: 5| Step: 9
Training loss: 1.608520269393921
Validation loss: 2.0721453626950583

Epoch: 5| Step: 10
Training loss: 1.9733260869979858
Validation loss: 2.053453748424848

Epoch: 5| Step: 11
Training loss: 1.5708558559417725
Validation loss: 2.0554387072722116

Epoch: 56| Step: 0
Training loss: 2.030203104019165
Validation loss: 2.0558992673953376

Epoch: 5| Step: 1
Training loss: 2.0482258796691895
Validation loss: 2.0528561224540076

Epoch: 5| Step: 2
Training loss: 1.5914841890335083
Validation loss: 2.02939801911513

Epoch: 5| Step: 3
Training loss: 2.026294708251953
Validation loss: 2.0555016795794168

Epoch: 5| Step: 4
Training loss: 2.1318612098693848
Validation loss: 2.047802746295929

Epoch: 5| Step: 5
Training loss: 2.120001792907715
Validation loss: 2.0520943800608316

Epoch: 5| Step: 6
Training loss: 1.885798454284668
Validation loss: 2.0480464498202005

Epoch: 5| Step: 7
Training loss: 1.6339067220687866
Validation loss: 2.0509884556134543

Epoch: 5| Step: 8
Training loss: 2.033573627471924
Validation loss: 2.0393238266309104

Epoch: 5| Step: 9
Training loss: 2.2041938304901123
Validation loss: 2.061526576677958

Epoch: 5| Step: 10
Training loss: 1.6896703243255615
Validation loss: 2.0619651873906455

Epoch: 5| Step: 11
Training loss: 0.31499040126800537
Validation loss: 2.0585161993900933

Epoch: 57| Step: 0
Training loss: 1.6114352941513062
Validation loss: 2.072006642818451

Epoch: 5| Step: 1
Training loss: 1.7515513896942139
Validation loss: 2.0836318085590997

Epoch: 5| Step: 2
Training loss: 2.081066608428955
Validation loss: 2.0706887344519296

Epoch: 5| Step: 3
Training loss: 1.7900161743164062
Validation loss: 2.0642778078715005

Epoch: 5| Step: 4
Training loss: 2.4834914207458496
Validation loss: 2.0715404748916626

Epoch: 5| Step: 5
Training loss: 1.8511444330215454
Validation loss: 2.0619750767946243

Epoch: 5| Step: 6
Training loss: 2.058563470840454
Validation loss: 2.0769941012064614

Epoch: 5| Step: 7
Training loss: 1.9040801525115967
Validation loss: 2.082863380511602

Epoch: 5| Step: 8
Training loss: 1.9128955602645874
Validation loss: 2.056421309709549

Epoch: 5| Step: 9
Training loss: 1.5780632495880127
Validation loss: 2.066823348402977

Epoch: 5| Step: 10
Training loss: 2.1488571166992188
Validation loss: 2.0510480453570685

Epoch: 5| Step: 11
Training loss: 1.0619884729385376
Validation loss: 2.057880366841952

Epoch: 58| Step: 0
Training loss: 2.0715880393981934
Validation loss: 2.0462468415498734

Epoch: 5| Step: 1
Training loss: 1.9585599899291992
Validation loss: 2.068440149227778

Epoch: 5| Step: 2
Training loss: 2.152611494064331
Validation loss: 2.061360021432241

Epoch: 5| Step: 3
Training loss: 2.0472500324249268
Validation loss: 2.048693065841993

Epoch: 5| Step: 4
Training loss: 2.184044599533081
Validation loss: 2.043143649895986

Epoch: 5| Step: 5
Training loss: 1.4847166538238525
Validation loss: 2.0573729226986566

Epoch: 5| Step: 6
Training loss: 2.3064043521881104
Validation loss: 2.0473479727904

Epoch: 5| Step: 7
Training loss: 1.8962587118148804
Validation loss: 2.063925117254257

Epoch: 5| Step: 8
Training loss: 1.694638967514038
Validation loss: 2.038308839003245

Epoch: 5| Step: 9
Training loss: 1.632491111755371
Validation loss: 2.0598520090182624

Epoch: 5| Step: 10
Training loss: 2.0975232124328613
Validation loss: 2.0483184456825256

Epoch: 5| Step: 11
Training loss: 0.8424786329269409
Validation loss: 2.0474637299776077

Epoch: 59| Step: 0
Training loss: 2.1154677867889404
Validation loss: 2.0725617359081903

Epoch: 5| Step: 1
Training loss: 1.4890626668930054
Validation loss: 2.057537411650022

Epoch: 5| Step: 2
Training loss: 1.9757730960845947
Validation loss: 2.072785104314486

Epoch: 5| Step: 3
Training loss: 2.296259641647339
Validation loss: 2.0636300394932428

Epoch: 5| Step: 4
Training loss: 1.7663440704345703
Validation loss: 2.0622897495826087

Epoch: 5| Step: 5
Training loss: 2.025029182434082
Validation loss: 2.056176414092382

Epoch: 5| Step: 6
Training loss: 1.9002830982208252
Validation loss: 2.085044796268145

Epoch: 5| Step: 7
Training loss: 1.949811577796936
Validation loss: 2.0725346306959787

Epoch: 5| Step: 8
Training loss: 2.089937210083008
Validation loss: 2.0717913856108985

Epoch: 5| Step: 9
Training loss: 1.8063900470733643
Validation loss: 2.0554890433947244

Epoch: 5| Step: 10
Training loss: 1.5041403770446777
Validation loss: 2.074232349793116

Epoch: 5| Step: 11
Training loss: 1.493800401687622
Validation loss: 2.0624027401208878

Epoch: 60| Step: 0
Training loss: 2.527434825897217
Validation loss: 2.049343019723892

Epoch: 5| Step: 1
Training loss: 2.07049822807312
Validation loss: 2.0618210981289544

Epoch: 5| Step: 2
Training loss: 1.9756557941436768
Validation loss: 2.0554456611474357

Epoch: 5| Step: 3
Training loss: 1.080143690109253
Validation loss: 2.0529090066750846

Epoch: 5| Step: 4
Training loss: 1.897650957107544
Validation loss: 2.0599967489639917

Epoch: 5| Step: 5
Training loss: 2.265547513961792
Validation loss: 2.0824924608071647

Epoch: 5| Step: 6
Training loss: 1.9898645877838135
Validation loss: 2.05470634996891

Epoch: 5| Step: 7
Training loss: 1.7233479022979736
Validation loss: 2.070168763399124

Epoch: 5| Step: 8
Training loss: 1.4345288276672363
Validation loss: 2.055313194791476

Epoch: 5| Step: 9
Training loss: 2.0850417613983154
Validation loss: 2.0659277737140656

Epoch: 5| Step: 10
Training loss: 1.3708264827728271
Validation loss: 2.0460630108912787

Epoch: 5| Step: 11
Training loss: 3.929670810699463
Validation loss: 2.0607973486185074

Epoch: 61| Step: 0
Training loss: 2.0556018352508545
Validation loss: 2.041312033931414

Epoch: 5| Step: 1
Training loss: 1.5228629112243652
Validation loss: 2.049949193994204

Epoch: 5| Step: 2
Training loss: 3.150961399078369
Validation loss: 2.074424977103869

Epoch: 5| Step: 3
Training loss: 1.8092067241668701
Validation loss: 2.0613401432832084

Epoch: 5| Step: 4
Training loss: 1.868323564529419
Validation loss: 2.0545666217803955

Epoch: 5| Step: 5
Training loss: 1.9177606105804443
Validation loss: 2.06985667347908

Epoch: 5| Step: 6
Training loss: 2.335658550262451
Validation loss: 2.054805805285772

Epoch: 5| Step: 7
Training loss: 1.6247907876968384
Validation loss: 2.054769272605578

Epoch: 5| Step: 8
Training loss: 1.711913824081421
Validation loss: 2.06354687611262

Epoch: 5| Step: 9
Training loss: 1.5496022701263428
Validation loss: 2.0533221314350762

Epoch: 5| Step: 10
Training loss: 1.9738037586212158
Validation loss: 2.060150161385536

Epoch: 5| Step: 11
Training loss: 0.5316622853279114
Validation loss: 2.055128743251165

Epoch: 62| Step: 0
Training loss: 2.250378370285034
Validation loss: 2.0421488732099533

Epoch: 5| Step: 1
Training loss: 1.8773524761199951
Validation loss: 2.0689749270677567

Epoch: 5| Step: 2
Training loss: 1.0626611709594727
Validation loss: 2.043939376870791

Epoch: 5| Step: 3
Training loss: 1.8811578750610352
Validation loss: 2.0735231836636863

Epoch: 5| Step: 4
Training loss: 1.901771903038025
Validation loss: 2.0730922867854438

Epoch: 5| Step: 5
Training loss: 2.2997374534606934
Validation loss: 2.083515783150991

Epoch: 5| Step: 6
Training loss: 2.249652862548828
Validation loss: 2.0688525835673013

Epoch: 5| Step: 7
Training loss: 1.9557793140411377
Validation loss: 2.084758842984835

Epoch: 5| Step: 8
Training loss: 1.8116401433944702
Validation loss: 2.0785839209953942

Epoch: 5| Step: 9
Training loss: 2.3387246131896973
Validation loss: 2.0806122521559396

Epoch: 5| Step: 10
Training loss: 1.3894107341766357
Validation loss: 2.0793948024511337

Epoch: 5| Step: 11
Training loss: 1.3814990520477295
Validation loss: 2.0639318029085794

Epoch: 63| Step: 0
Training loss: 2.1776089668273926
Validation loss: 2.0515378365914025

Epoch: 5| Step: 1
Training loss: 1.8236411809921265
Validation loss: 2.0450514753659568

Epoch: 5| Step: 2
Training loss: 1.9328330755233765
Validation loss: 2.0586977303028107

Epoch: 5| Step: 3
Training loss: 2.0092978477478027
Validation loss: 2.043604334195455

Epoch: 5| Step: 4
Training loss: 1.8070003986358643
Validation loss: 2.0561340053876243

Epoch: 5| Step: 5
Training loss: 1.964421033859253
Validation loss: 2.0728979657093682

Epoch: 5| Step: 6
Training loss: 1.7567657232284546
Validation loss: 2.0308105101188025

Epoch: 5| Step: 7
Training loss: 1.772487998008728
Validation loss: 2.0616542945305505

Epoch: 5| Step: 8
Training loss: 1.7680881023406982
Validation loss: 2.0346342027187347

Epoch: 5| Step: 9
Training loss: 1.6122804880142212
Validation loss: 2.0594952354828515

Epoch: 5| Step: 10
Training loss: 2.6193361282348633
Validation loss: 2.0711914201577506

Epoch: 5| Step: 11
Training loss: 0.7517760992050171
Validation loss: 2.0571845968564353

Epoch: 64| Step: 0
Training loss: 1.9915651082992554
Validation loss: 2.0652668525775275

Epoch: 5| Step: 1
Training loss: 2.2997803688049316
Validation loss: 2.077588826417923

Epoch: 5| Step: 2
Training loss: 1.9136873483657837
Validation loss: 2.1040413628021875

Epoch: 5| Step: 3
Training loss: 1.33982253074646
Validation loss: 2.1073943823575974

Epoch: 5| Step: 4
Training loss: 1.9227386713027954
Validation loss: 2.0860814352830253

Epoch: 5| Step: 5
Training loss: 1.5945227146148682
Validation loss: 2.094727377096812

Epoch: 5| Step: 6
Training loss: 1.8227317333221436
Validation loss: 2.093621850013733

Epoch: 5| Step: 7
Training loss: 1.8242721557617188
Validation loss: 2.092553516228994

Epoch: 5| Step: 8
Training loss: 1.4152835607528687
Validation loss: 2.0939888258775077

Epoch: 5| Step: 9
Training loss: 2.2598164081573486
Validation loss: 2.069297974308332

Epoch: 5| Step: 10
Training loss: 1.999839186668396
Validation loss: 2.0801502664883933

Epoch: 5| Step: 11
Training loss: 3.688328266143799
Validation loss: 2.062629053990046

Epoch: 65| Step: 0
Training loss: 1.5806567668914795
Validation loss: 2.0473260978857675

Epoch: 5| Step: 1
Training loss: 1.4020792245864868
Validation loss: 2.0576660533746085

Epoch: 5| Step: 2
Training loss: 2.755324363708496
Validation loss: 2.0617470939954123

Epoch: 5| Step: 3
Training loss: 1.7652575969696045
Validation loss: 2.030090550581614

Epoch: 5| Step: 4
Training loss: 2.068643808364868
Validation loss: 2.0700834492842355

Epoch: 5| Step: 5
Training loss: 2.0611464977264404
Validation loss: 2.069763367374738

Epoch: 5| Step: 6
Training loss: 2.063420295715332
Validation loss: 2.0702099204063416

Epoch: 5| Step: 7
Training loss: 2.1920523643493652
Validation loss: 2.053023954232534

Epoch: 5| Step: 8
Training loss: 1.870431900024414
Validation loss: 2.0484101672967276

Epoch: 5| Step: 9
Training loss: 1.7362525463104248
Validation loss: 2.0471047908067703

Epoch: 5| Step: 10
Training loss: 1.5008020401000977
Validation loss: 2.053066611289978

Epoch: 5| Step: 11
Training loss: 1.9655253887176514
Validation loss: 2.051682412624359

Epoch: 66| Step: 0
Training loss: 1.6628038883209229
Validation loss: 2.0483070562283197

Epoch: 5| Step: 1
Training loss: 1.5976872444152832
Validation loss: 2.05886738995711

Epoch: 5| Step: 2
Training loss: 1.4568766355514526
Validation loss: 2.0598842749993005

Epoch: 5| Step: 3
Training loss: 1.9608256816864014
Validation loss: 2.0785751789808273

Epoch: 5| Step: 4
Training loss: 1.5686194896697998
Validation loss: 2.1051814556121826

Epoch: 5| Step: 5
Training loss: 2.0701699256896973
Validation loss: 2.1135585010051727

Epoch: 5| Step: 6
Training loss: 1.756861686706543
Validation loss: 2.120597312847773

Epoch: 5| Step: 7
Training loss: 2.6153955459594727
Validation loss: 2.101183702548345

Epoch: 5| Step: 8
Training loss: 2.1606836318969727
Validation loss: 2.1273862024148307

Epoch: 5| Step: 9
Training loss: 2.309269428253174
Validation loss: 2.0905683040618896

Epoch: 5| Step: 10
Training loss: 1.6789474487304688
Validation loss: 2.1022013823191323

Epoch: 5| Step: 11
Training loss: 2.9178719520568848
Validation loss: 2.0779965817928314

Epoch: 67| Step: 0
Training loss: 1.9884910583496094
Validation loss: 2.0555707861979804

Epoch: 5| Step: 1
Training loss: 1.903744101524353
Validation loss: 2.0395695020755134

Epoch: 5| Step: 2
Training loss: 1.7484785318374634
Validation loss: 2.0600591798623404

Epoch: 5| Step: 3
Training loss: 1.6738611459732056
Validation loss: 2.0422840466101966

Epoch: 5| Step: 4
Training loss: 1.5060433149337769
Validation loss: 2.0657352904478707

Epoch: 5| Step: 5
Training loss: 2.0520005226135254
Validation loss: 2.069433276851972

Epoch: 5| Step: 6
Training loss: 2.5984573364257812
Validation loss: 2.0528965145349503

Epoch: 5| Step: 7
Training loss: 1.971024751663208
Validation loss: 2.0622953474521637

Epoch: 5| Step: 8
Training loss: 1.6443456411361694
Validation loss: 2.0598746041456857

Epoch: 5| Step: 9
Training loss: 2.163555860519409
Validation loss: 2.0713295191526413

Epoch: 5| Step: 10
Training loss: 1.9273521900177002
Validation loss: 2.052739679813385

Epoch: 5| Step: 11
Training loss: 2.9816575050354004
Validation loss: 2.067576472957929

Epoch: 68| Step: 0
Training loss: 1.9177290201187134
Validation loss: 2.0485821962356567

Epoch: 5| Step: 1
Training loss: 1.906653642654419
Validation loss: 2.066883017619451

Epoch: 5| Step: 2
Training loss: 1.9379993677139282
Validation loss: 2.0430274506409964

Epoch: 5| Step: 3
Training loss: 1.5985736846923828
Validation loss: 2.0609607001145682

Epoch: 5| Step: 4
Training loss: 1.8579127788543701
Validation loss: 2.070820694168409

Epoch: 5| Step: 5
Training loss: 1.5421531200408936
Validation loss: 2.078786164522171

Epoch: 5| Step: 6
Training loss: 2.2896037101745605
Validation loss: 2.0954039494196572

Epoch: 5| Step: 7
Training loss: 1.6942487955093384
Validation loss: 2.0835288017988205

Epoch: 5| Step: 8
Training loss: 1.8378565311431885
Validation loss: 2.0882307340701423

Epoch: 5| Step: 9
Training loss: 1.906031847000122
Validation loss: 2.0951831539471946

Epoch: 5| Step: 10
Training loss: 1.8771731853485107
Validation loss: 2.0867100208997726

Epoch: 5| Step: 11
Training loss: 1.7725688219070435
Validation loss: 2.1018876234690347

Epoch: 69| Step: 0
Training loss: 1.779484510421753
Validation loss: 2.0763176331917443

Epoch: 5| Step: 1
Training loss: 1.530066728591919
Validation loss: 2.0646764834721885

Epoch: 5| Step: 2
Training loss: 2.0293874740600586
Validation loss: 2.0552398512760797

Epoch: 5| Step: 3
Training loss: 1.7132209539413452
Validation loss: 2.059140900770823

Epoch: 5| Step: 4
Training loss: 1.8898460865020752
Validation loss: 2.0556289503971734

Epoch: 5| Step: 5
Training loss: 2.4757437705993652
Validation loss: 2.053043156862259

Epoch: 5| Step: 6
Training loss: 1.7947771549224854
Validation loss: 2.0718300541241965

Epoch: 5| Step: 7
Training loss: 2.247753620147705
Validation loss: 2.0606922954320908

Epoch: 5| Step: 8
Training loss: 1.9879356622695923
Validation loss: 2.056175803144773

Epoch: 5| Step: 9
Training loss: 2.100083351135254
Validation loss: 2.0737159699201584

Epoch: 5| Step: 10
Training loss: 1.4153172969818115
Validation loss: 2.06377645333608

Epoch: 5| Step: 11
Training loss: 0.9969990849494934
Validation loss: 2.0706177850564322

Epoch: 70| Step: 0
Training loss: 1.6985301971435547
Validation loss: 2.0813139329353967

Epoch: 5| Step: 1
Training loss: 1.898488998413086
Validation loss: 2.0661635299523673

Epoch: 5| Step: 2
Training loss: 1.3582265377044678
Validation loss: 2.057256097594897

Epoch: 5| Step: 3
Training loss: 1.9688276052474976
Validation loss: 2.061680813630422

Epoch: 5| Step: 4
Training loss: 1.8974586725234985
Validation loss: 2.0463719268639884

Epoch: 5| Step: 5
Training loss: 1.1307671070098877
Validation loss: 2.052054633696874

Epoch: 5| Step: 6
Training loss: 1.992422103881836
Validation loss: 2.061408132314682

Epoch: 5| Step: 7
Training loss: 2.177880048751831
Validation loss: 2.074695979555448

Epoch: 5| Step: 8
Training loss: 2.549044132232666
Validation loss: 2.064450497428576

Epoch: 5| Step: 9
Training loss: 2.083519458770752
Validation loss: 2.070023457209269

Epoch: 5| Step: 10
Training loss: 1.843849778175354
Validation loss: 2.0746343980232873

Epoch: 5| Step: 11
Training loss: 0.9496542811393738
Validation loss: 2.0768957883119583

Epoch: 71| Step: 0
Training loss: 1.959371566772461
Validation loss: 2.056752194960912

Epoch: 5| Step: 1
Training loss: 1.8753080368041992
Validation loss: 2.0647256821393967

Epoch: 5| Step: 2
Training loss: 1.5275065898895264
Validation loss: 2.0502737214167914

Epoch: 5| Step: 3
Training loss: 2.065978765487671
Validation loss: 2.0698024729887643

Epoch: 5| Step: 4
Training loss: 2.107475996017456
Validation loss: 2.0683800180753074

Epoch: 5| Step: 5
Training loss: 1.674721360206604
Validation loss: 2.0552151103814444

Epoch: 5| Step: 6
Training loss: 2.065335750579834
Validation loss: 2.056172971924146

Epoch: 5| Step: 7
Training loss: 1.9479951858520508
Validation loss: 2.044585332274437

Epoch: 5| Step: 8
Training loss: 2.1062283515930176
Validation loss: 2.042856514453888

Epoch: 5| Step: 9
Training loss: 1.689227819442749
Validation loss: 2.080275446176529

Epoch: 5| Step: 10
Training loss: 1.7128314971923828
Validation loss: 2.0401939352353415

Epoch: 5| Step: 11
Training loss: 1.573563575744629
Validation loss: 2.076261599858602

Epoch: 72| Step: 0
Training loss: 2.201442241668701
Validation loss: 2.1000199715296426

Epoch: 5| Step: 1
Training loss: 2.0890610218048096
Validation loss: 2.0833329955736795

Epoch: 5| Step: 2
Training loss: 1.976401925086975
Validation loss: 2.086421236395836

Epoch: 5| Step: 3
Training loss: 1.6874500513076782
Validation loss: 2.1135802567005157

Epoch: 5| Step: 4
Training loss: 1.3287078142166138
Validation loss: 2.0943552205959954

Epoch: 5| Step: 5
Training loss: 2.190004825592041
Validation loss: 2.087005471189817

Epoch: 5| Step: 6
Training loss: 1.9030472040176392
Validation loss: 2.077937180797259

Epoch: 5| Step: 7
Training loss: 1.3447834253311157
Validation loss: 2.065646489461263

Epoch: 5| Step: 8
Training loss: 1.6510006189346313
Validation loss: 2.0509117792050042

Epoch: 5| Step: 9
Training loss: 2.325247049331665
Validation loss: 2.0463891277710595

Epoch: 5| Step: 10
Training loss: 1.7451435327529907
Validation loss: 2.0466136982043586

Epoch: 5| Step: 11
Training loss: 1.7929530143737793
Validation loss: 2.055820554494858

Epoch: 73| Step: 0
Training loss: 1.8380935192108154
Validation loss: 2.075423220793406

Epoch: 5| Step: 1
Training loss: 1.9496351480484009
Validation loss: 2.079622740546862

Epoch: 5| Step: 2
Training loss: 2.4773011207580566
Validation loss: 2.1197202702363334

Epoch: 5| Step: 3
Training loss: 1.8433074951171875
Validation loss: 2.130588114261627

Epoch: 5| Step: 4
Training loss: 2.627561569213867
Validation loss: 2.1361260066429772

Epoch: 5| Step: 5
Training loss: 1.2291566133499146
Validation loss: 2.1236322124799094

Epoch: 5| Step: 6
Training loss: 1.1795035600662231
Validation loss: 2.1336172819137573

Epoch: 5| Step: 7
Training loss: 1.834181785583496
Validation loss: 2.1268709848324456

Epoch: 5| Step: 8
Training loss: 2.5316226482391357
Validation loss: 2.101817707220713

Epoch: 5| Step: 9
Training loss: 1.7032496929168701
Validation loss: 2.0900330593188605

Epoch: 5| Step: 10
Training loss: 1.6930181980133057
Validation loss: 2.072701280315717

Epoch: 5| Step: 11
Training loss: 1.4808768033981323
Validation loss: 2.058317636450132

Epoch: 74| Step: 0
Training loss: 1.9853836297988892
Validation loss: 2.0470296144485474

Epoch: 5| Step: 1
Training loss: 2.167142868041992
Validation loss: 2.0476536800463996

Epoch: 5| Step: 2
Training loss: 1.929389238357544
Validation loss: 2.070316274960836

Epoch: 5| Step: 3
Training loss: 1.6187502145767212
Validation loss: 2.0717356403668723

Epoch: 5| Step: 4
Training loss: 2.0443243980407715
Validation loss: 2.045490319530169

Epoch: 5| Step: 5
Training loss: 1.9113543033599854
Validation loss: 2.0483511090278625

Epoch: 5| Step: 6
Training loss: 2.0840375423431396
Validation loss: 2.048731947938601

Epoch: 5| Step: 7
Training loss: 1.9987350702285767
Validation loss: 2.065717950463295

Epoch: 5| Step: 8
Training loss: 1.7996444702148438
Validation loss: 2.0598345547914505

Epoch: 5| Step: 9
Training loss: 1.8829267024993896
Validation loss: 2.071118339896202

Epoch: 5| Step: 10
Training loss: 1.2302814722061157
Validation loss: 2.055906559030215

Epoch: 5| Step: 11
Training loss: 1.5340656042099
Validation loss: 2.0635105073451996

Epoch: 75| Step: 0
Training loss: 1.3868532180786133
Validation loss: 2.059290717045466

Epoch: 5| Step: 1
Training loss: 1.5461548566818237
Validation loss: 2.086222007870674

Epoch: 5| Step: 2
Training loss: 2.310701370239258
Validation loss: 2.067985941966375

Epoch: 5| Step: 3
Training loss: 1.644669771194458
Validation loss: 2.0978515495856604

Epoch: 5| Step: 4
Training loss: 1.9354808330535889
Validation loss: 2.057364205519358

Epoch: 5| Step: 5
Training loss: 2.4106876850128174
Validation loss: 2.102993736664454

Epoch: 5| Step: 6
Training loss: 1.8873403072357178
Validation loss: 2.076208606362343

Epoch: 5| Step: 7
Training loss: 1.4672701358795166
Validation loss: 2.085339292883873

Epoch: 5| Step: 8
Training loss: 1.6664230823516846
Validation loss: 2.0801503658294678

Epoch: 5| Step: 9
Training loss: 1.704627275466919
Validation loss: 2.0723248422145844

Epoch: 5| Step: 10
Training loss: 2.2915751934051514
Validation loss: 2.082553724447886

Epoch: 5| Step: 11
Training loss: 1.5067451000213623
Validation loss: 2.061605215072632

Epoch: 76| Step: 0
Training loss: 2.1465654373168945
Validation loss: 2.0603623489538827

Epoch: 5| Step: 1
Training loss: 1.724639892578125
Validation loss: 2.0717062205076218

Epoch: 5| Step: 2
Training loss: 1.533257246017456
Validation loss: 2.0712005297342935

Epoch: 5| Step: 3
Training loss: 2.332127094268799
Validation loss: 2.071082189679146

Epoch: 5| Step: 4
Training loss: 1.734986662864685
Validation loss: 2.056875010331472

Epoch: 5| Step: 5
Training loss: 2.2490525245666504
Validation loss: 2.063223257660866

Epoch: 5| Step: 6
Training loss: 1.8095035552978516
Validation loss: 2.0804104059934616

Epoch: 5| Step: 7
Training loss: 1.6674684286117554
Validation loss: 2.0711701263984046

Epoch: 5| Step: 8
Training loss: 2.2708182334899902
Validation loss: 2.0825002938508987

Epoch: 5| Step: 9
Training loss: 1.4123456478118896
Validation loss: 2.0563146819670997

Epoch: 5| Step: 10
Training loss: 1.3559645414352417
Validation loss: 2.077115977803866

Epoch: 5| Step: 11
Training loss: 1.1445951461791992
Validation loss: 2.0768438378969827

Epoch: 77| Step: 0
Training loss: 1.6871658563613892
Validation loss: 2.0862328012784324

Epoch: 5| Step: 1
Training loss: 1.8186384439468384
Validation loss: 2.1142968187729516

Epoch: 5| Step: 2
Training loss: 2.5366291999816895
Validation loss: 2.090645730495453

Epoch: 5| Step: 3
Training loss: 1.5276644229888916
Validation loss: 2.1149594485759735

Epoch: 5| Step: 4
Training loss: 2.0277256965637207
Validation loss: 2.12104469537735

Epoch: 5| Step: 5
Training loss: 1.9649324417114258
Validation loss: 2.1003316839536033

Epoch: 5| Step: 6
Training loss: 1.5781527757644653
Validation loss: 2.116099089384079

Epoch: 5| Step: 7
Training loss: 1.6525300741195679
Validation loss: 2.0965986450513205

Epoch: 5| Step: 8
Training loss: 1.6282352209091187
Validation loss: 2.057464445630709

Epoch: 5| Step: 9
Training loss: 1.90863835811615
Validation loss: 2.0659386813640594

Epoch: 5| Step: 10
Training loss: 1.263114333152771
Validation loss: 2.0693540076414743

Epoch: 5| Step: 11
Training loss: 5.052248954772949
Validation loss: 2.0561358282963433

Epoch: 78| Step: 0
Training loss: 1.761535406112671
Validation loss: 2.068518499533335

Epoch: 5| Step: 1
Training loss: 2.006629467010498
Validation loss: 2.0446055630842843

Epoch: 5| Step: 2
Training loss: 2.2706375122070312
Validation loss: 2.0499567737181983

Epoch: 5| Step: 3
Training loss: 1.8813978433609009
Validation loss: 2.0495990763107934

Epoch: 5| Step: 4
Training loss: 1.9373630285263062
Validation loss: 2.076601962248484

Epoch: 5| Step: 5
Training loss: 1.5089595317840576
Validation loss: 2.050038069486618

Epoch: 5| Step: 6
Training loss: 1.4013817310333252
Validation loss: 2.065883621573448

Epoch: 5| Step: 7
Training loss: 1.7360591888427734
Validation loss: 2.0571567118167877

Epoch: 5| Step: 8
Training loss: 1.9463647603988647
Validation loss: 2.1062405506769815

Epoch: 5| Step: 9
Training loss: 2.133546829223633
Validation loss: 2.0722826222578683

Epoch: 5| Step: 10
Training loss: 2.114035129547119
Validation loss: 2.0750246942043304

Epoch: 5| Step: 11
Training loss: 1.7889000177383423
Validation loss: 2.0869042674700418

Epoch: 79| Step: 0
Training loss: 2.2860350608825684
Validation loss: 2.0998696088790894

Epoch: 5| Step: 1
Training loss: 2.1011271476745605
Validation loss: 2.105482205748558

Epoch: 5| Step: 2
Training loss: 1.7388966083526611
Validation loss: 2.089527433117231

Epoch: 5| Step: 3
Training loss: 1.5223348140716553
Validation loss: 2.0937039107084274

Epoch: 5| Step: 4
Training loss: 2.305452823638916
Validation loss: 2.0767748604218164

Epoch: 5| Step: 5
Training loss: 1.4696375131607056
Validation loss: 2.0926964978377023

Epoch: 5| Step: 6
Training loss: 2.0289690494537354
Validation loss: 2.079027364651362

Epoch: 5| Step: 7
Training loss: 1.3082842826843262
Validation loss: 2.0707468539476395

Epoch: 5| Step: 8
Training loss: 1.4528881311416626
Validation loss: 2.094348435600599

Epoch: 5| Step: 9
Training loss: 1.8213169574737549
Validation loss: 2.0442679077386856

Epoch: 5| Step: 10
Training loss: 2.0043740272521973
Validation loss: 2.0420740644137063

Epoch: 5| Step: 11
Training loss: 1.4468657970428467
Validation loss: 2.059342384338379

Epoch: 80| Step: 0
Training loss: 1.4531500339508057
Validation loss: 2.0723468959331512

Epoch: 5| Step: 1
Training loss: 2.3212809562683105
Validation loss: 2.077773039539655

Epoch: 5| Step: 2
Training loss: 1.9275538921356201
Validation loss: 2.062998135884603

Epoch: 5| Step: 3
Training loss: 1.9566965103149414
Validation loss: 2.062518154581388

Epoch: 5| Step: 4
Training loss: 1.843496561050415
Validation loss: 2.0686586846907935

Epoch: 5| Step: 5
Training loss: 1.6345160007476807
Validation loss: 2.0503937055667243

Epoch: 5| Step: 6
Training loss: 2.192350387573242
Validation loss: 2.101197933157285

Epoch: 5| Step: 7
Training loss: 1.6979105472564697
Validation loss: 2.082707166671753

Epoch: 5| Step: 8
Training loss: 1.6045392751693726
Validation loss: 2.0608418037494025

Epoch: 5| Step: 9
Training loss: 1.5225448608398438
Validation loss: 2.084256192048391

Epoch: 5| Step: 10
Training loss: 1.819549322128296
Validation loss: 2.0694411446650824

Epoch: 5| Step: 11
Training loss: 1.6476483345031738
Validation loss: 2.111046473185221

Epoch: 81| Step: 0
Training loss: 2.442016124725342
Validation loss: 2.1029332925875983

Epoch: 5| Step: 1
Training loss: 2.2079901695251465
Validation loss: 2.0814611613750458

Epoch: 5| Step: 2
Training loss: 2.0066311359405518
Validation loss: 2.1097986499468484

Epoch: 5| Step: 3
Training loss: 1.6007646322250366
Validation loss: 2.0775514443715415

Epoch: 5| Step: 4
Training loss: 1.7604516744613647
Validation loss: 2.077402944366137

Epoch: 5| Step: 5
Training loss: 1.2028173208236694
Validation loss: 2.094752053419749

Epoch: 5| Step: 6
Training loss: 2.4114534854888916
Validation loss: 2.092913433909416

Epoch: 5| Step: 7
Training loss: 2.348092555999756
Validation loss: 2.095991184314092

Epoch: 5| Step: 8
Training loss: 1.3676022291183472
Validation loss: 2.063177133599917

Epoch: 5| Step: 9
Training loss: 1.6402181386947632
Validation loss: 2.047861402233442

Epoch: 5| Step: 10
Training loss: 0.8650608062744141
Validation loss: 2.086827263236046

Epoch: 5| Step: 11
Training loss: 1.9492722749710083
Validation loss: 2.0618727604548135

Epoch: 82| Step: 0
Training loss: 1.9493526220321655
Validation loss: 2.0843497266372046

Epoch: 5| Step: 1
Training loss: 1.539391279220581
Validation loss: 2.063782269755999

Epoch: 5| Step: 2
Training loss: 1.5260846614837646
Validation loss: 2.043422132730484

Epoch: 5| Step: 3
Training loss: 1.9946521520614624
Validation loss: 2.0642356673876443

Epoch: 5| Step: 4
Training loss: 1.8887319564819336
Validation loss: 2.0627139856417975

Epoch: 5| Step: 5
Training loss: 1.7693452835083008
Validation loss: 2.0789691507816315

Epoch: 5| Step: 6
Training loss: 1.6637260913848877
Validation loss: 2.09111395974954

Epoch: 5| Step: 7
Training loss: 1.7374074459075928
Validation loss: 2.085336367289225

Epoch: 5| Step: 8
Training loss: 1.4583097696304321
Validation loss: 2.0743936747312546

Epoch: 5| Step: 9
Training loss: 1.9945297241210938
Validation loss: 2.0754252721865973

Epoch: 5| Step: 10
Training loss: 2.144087314605713
Validation loss: 2.0733302185932794

Epoch: 5| Step: 11
Training loss: 1.5905706882476807
Validation loss: 2.0996601631244025

Epoch: 83| Step: 0
Training loss: 1.7610034942626953
Validation loss: 2.1228592892487845

Epoch: 5| Step: 1
Training loss: 1.7502796649932861
Validation loss: 2.0940184791882834

Epoch: 5| Step: 2
Training loss: 2.1414072513580322
Validation loss: 2.0931533724069595

Epoch: 5| Step: 3
Training loss: 1.8366254568099976
Validation loss: 2.113037725289663

Epoch: 5| Step: 4
Training loss: 1.3345779180526733
Validation loss: 2.089887171983719

Epoch: 5| Step: 5
Training loss: 1.8195276260375977
Validation loss: 2.095666711529096

Epoch: 5| Step: 6
Training loss: 1.274587631225586
Validation loss: 2.0748964498440423

Epoch: 5| Step: 7
Training loss: 1.9841034412384033
Validation loss: 2.0797380109628043

Epoch: 5| Step: 8
Training loss: 1.8420339822769165
Validation loss: 2.0810770889123282

Epoch: 5| Step: 9
Training loss: 2.0750679969787598
Validation loss: 2.0858705590168634

Epoch: 5| Step: 10
Training loss: 1.9206197261810303
Validation loss: 2.0516857157150903

Epoch: 5| Step: 11
Training loss: 1.834209680557251
Validation loss: 2.076264411211014

Epoch: 84| Step: 0
Training loss: 1.8244545459747314
Validation loss: 2.0639407287041345

Epoch: 5| Step: 1
Training loss: 1.1344711780548096
Validation loss: 2.0289050936698914

Epoch: 5| Step: 2
Training loss: 1.9589086771011353
Validation loss: 2.046720708409945

Epoch: 5| Step: 3
Training loss: 1.658791184425354
Validation loss: 2.0499874452749887

Epoch: 5| Step: 4
Training loss: 2.156057834625244
Validation loss: 2.033845772345861

Epoch: 5| Step: 5
Training loss: 1.8627275228500366
Validation loss: 2.0546500831842422

Epoch: 5| Step: 6
Training loss: 2.7940940856933594
Validation loss: 2.0725174844264984

Epoch: 5| Step: 7
Training loss: 1.609927773475647
Validation loss: 2.0847372909386954

Epoch: 5| Step: 8
Training loss: 1.6614882946014404
Validation loss: 2.076026822129885

Epoch: 5| Step: 9
Training loss: 1.2105743885040283
Validation loss: 2.0577632039785385

Epoch: 5| Step: 10
Training loss: 1.7977691888809204
Validation loss: 2.0799601525068283

Epoch: 5| Step: 11
Training loss: 2.034519672393799
Validation loss: 2.1014892806609473

Epoch: 85| Step: 0
Training loss: 1.5929151773452759
Validation loss: 2.0726965069770813

Epoch: 5| Step: 1
Training loss: 2.102327823638916
Validation loss: 2.057536318898201

Epoch: 5| Step: 2
Training loss: 1.5460110902786255
Validation loss: 2.0705550213654837

Epoch: 5| Step: 3
Training loss: 2.228677749633789
Validation loss: 2.07316946486632

Epoch: 5| Step: 4
Training loss: 1.4879748821258545
Validation loss: 2.062568431099256

Epoch: 5| Step: 5
Training loss: 1.5658022165298462
Validation loss: 2.0646615624427795

Epoch: 5| Step: 6
Training loss: 2.2853450775146484
Validation loss: 2.0708251744508743

Epoch: 5| Step: 7
Training loss: 1.6321747303009033
Validation loss: 2.066030333439509

Epoch: 5| Step: 8
Training loss: 1.2687510251998901
Validation loss: 2.068257659673691

Epoch: 5| Step: 9
Training loss: 2.1051025390625
Validation loss: 2.070680250724157

Epoch: 5| Step: 10
Training loss: 1.7791591882705688
Validation loss: 2.0624794165293374

Epoch: 5| Step: 11
Training loss: 1.5528490543365479
Validation loss: 2.079304590821266

Epoch: 86| Step: 0
Training loss: 2.2032740116119385
Validation loss: 2.064361254374186

Epoch: 5| Step: 1
Training loss: 1.4209258556365967
Validation loss: 2.0735339721043906

Epoch: 5| Step: 2
Training loss: 2.3483409881591797
Validation loss: 2.032390534877777

Epoch: 5| Step: 3
Training loss: 1.2909767627716064
Validation loss: 2.0705956369638443

Epoch: 5| Step: 4
Training loss: 1.8047059774398804
Validation loss: 2.059626986583074

Epoch: 5| Step: 5
Training loss: 1.6627094745635986
Validation loss: 2.0590536147356033

Epoch: 5| Step: 6
Training loss: 1.864689588546753
Validation loss: 2.07723738749822

Epoch: 5| Step: 7
Training loss: 2.0071568489074707
Validation loss: 2.0560404459635415

Epoch: 5| Step: 8
Training loss: 1.3931368589401245
Validation loss: 2.0398936172326407

Epoch: 5| Step: 9
Training loss: 2.335766315460205
Validation loss: 2.0452841172615686

Epoch: 5| Step: 10
Training loss: 1.6126304864883423
Validation loss: 2.053922285636266

Epoch: 5| Step: 11
Training loss: 0.6087846755981445
Validation loss: 2.0626242657502494

Epoch: 87| Step: 0
Training loss: 2.1811861991882324
Validation loss: 2.0724758207798004

Epoch: 5| Step: 1
Training loss: 1.481789231300354
Validation loss: 2.088299776117007

Epoch: 5| Step: 2
Training loss: 2.1073663234710693
Validation loss: 2.0479556818803153

Epoch: 5| Step: 3
Training loss: 1.736986517906189
Validation loss: 2.0347778598467507

Epoch: 5| Step: 4
Training loss: 1.8206427097320557
Validation loss: 2.0484762688477836

Epoch: 5| Step: 5
Training loss: 1.6853563785552979
Validation loss: 2.0817393014828363

Epoch: 5| Step: 6
Training loss: 1.606919288635254
Validation loss: 2.0237796703974404

Epoch: 5| Step: 7
Training loss: 1.7979443073272705
Validation loss: 2.052155002951622

Epoch: 5| Step: 8
Training loss: 1.7506608963012695
Validation loss: 2.073732480406761

Epoch: 5| Step: 9
Training loss: 1.9801515340805054
Validation loss: 2.0972816745440164

Epoch: 5| Step: 10
Training loss: 1.5778319835662842
Validation loss: 2.115018760164579

Epoch: 5| Step: 11
Training loss: 1.2791674137115479
Validation loss: 2.0849724610646567

Epoch: 88| Step: 0
Training loss: 1.6865133047103882
Validation loss: 2.095660616954168

Epoch: 5| Step: 1
Training loss: 1.7134109735488892
Validation loss: 2.1000011563301086

Epoch: 5| Step: 2
Training loss: 2.48111891746521
Validation loss: 2.119980345169703

Epoch: 5| Step: 3
Training loss: 2.2560112476348877
Validation loss: 2.112169032295545

Epoch: 5| Step: 4
Training loss: 1.57964289188385
Validation loss: 2.0904627392689386

Epoch: 5| Step: 5
Training loss: 1.407142996788025
Validation loss: 2.099194680651029

Epoch: 5| Step: 6
Training loss: 1.168704628944397
Validation loss: 2.112748384475708

Epoch: 5| Step: 7
Training loss: 1.7635635137557983
Validation loss: 2.055413916707039

Epoch: 5| Step: 8
Training loss: 1.934625267982483
Validation loss: 2.0816272497177124

Epoch: 5| Step: 9
Training loss: 1.8174841403961182
Validation loss: 2.0403148929278054

Epoch: 5| Step: 10
Training loss: 2.0433883666992188
Validation loss: 2.0656784872214

Epoch: 5| Step: 11
Training loss: 0.7327544689178467
Validation loss: 2.0383813430865607

Epoch: 89| Step: 0
Training loss: 1.926607370376587
Validation loss: 2.075782040754954

Epoch: 5| Step: 1
Training loss: 2.042604923248291
Validation loss: 2.0386698643366494

Epoch: 5| Step: 2
Training loss: 1.981224775314331
Validation loss: 2.052500441670418

Epoch: 5| Step: 3
Training loss: 1.328601598739624
Validation loss: 2.0482272456089654

Epoch: 5| Step: 4
Training loss: 1.2821033000946045
Validation loss: 2.0489959170420966

Epoch: 5| Step: 5
Training loss: 1.4816515445709229
Validation loss: 2.0392122069994607

Epoch: 5| Step: 6
Training loss: 2.1223526000976562
Validation loss: 2.0482843468586602

Epoch: 5| Step: 7
Training loss: 2.041100263595581
Validation loss: 2.0481270054976144

Epoch: 5| Step: 8
Training loss: 1.7808830738067627
Validation loss: 2.0668822278579078

Epoch: 5| Step: 9
Training loss: 1.7699849605560303
Validation loss: 2.0646714766820273

Epoch: 5| Step: 10
Training loss: 1.8498655557632446
Validation loss: 2.0871465851863227

Epoch: 5| Step: 11
Training loss: 1.5218760967254639
Validation loss: 2.120141143600146

Epoch: 90| Step: 0
Training loss: 2.0158097743988037
Validation loss: 2.102906713883082

Epoch: 5| Step: 1
Training loss: 1.6831474304199219
Validation loss: 2.0945914834737778

Epoch: 5| Step: 2
Training loss: 1.4155076742172241
Validation loss: 2.0933233350515366

Epoch: 5| Step: 3
Training loss: 2.1240828037261963
Validation loss: 2.068503881494204

Epoch: 5| Step: 4
Training loss: 1.8325096368789673
Validation loss: 2.0818165292342505

Epoch: 5| Step: 5
Training loss: 1.8261867761611938
Validation loss: 2.055899595220884

Epoch: 5| Step: 6
Training loss: 1.898103952407837
Validation loss: 2.0503639628489814

Epoch: 5| Step: 7
Training loss: 1.9884732961654663
Validation loss: 2.0384617249170938

Epoch: 5| Step: 8
Training loss: 1.7381728887557983
Validation loss: 2.0487777640422187

Epoch: 5| Step: 9
Training loss: 1.8859338760375977
Validation loss: 2.048553243279457

Epoch: 5| Step: 10
Training loss: 1.3860628604888916
Validation loss: 2.048842782775561

Epoch: 5| Step: 11
Training loss: 1.8580560684204102
Validation loss: 2.0628042022387185

Epoch: 91| Step: 0
Training loss: 2.3282599449157715
Validation loss: 2.1010673443476358

Epoch: 5| Step: 1
Training loss: 1.3551982641220093
Validation loss: 2.101524089773496

Epoch: 5| Step: 2
Training loss: 1.8338390588760376
Validation loss: 2.0977223068475723

Epoch: 5| Step: 3
Training loss: 1.3931318521499634
Validation loss: 2.112634683648745

Epoch: 5| Step: 4
Training loss: 1.473872423171997
Validation loss: 2.108308285474777

Epoch: 5| Step: 5
Training loss: 1.6257362365722656
Validation loss: 2.10484849413236

Epoch: 5| Step: 6
Training loss: 1.6651790142059326
Validation loss: 2.1089591830968857

Epoch: 5| Step: 7
Training loss: 1.7728265523910522
Validation loss: 2.0630907118320465

Epoch: 5| Step: 8
Training loss: 1.9765981435775757
Validation loss: 2.074478959043821

Epoch: 5| Step: 9
Training loss: 2.1047558784484863
Validation loss: 2.0576129058996835

Epoch: 5| Step: 10
Training loss: 1.7353652715682983
Validation loss: 2.054460729161898

Epoch: 5| Step: 11
Training loss: 2.1846814155578613
Validation loss: 2.0430638243754706

Epoch: 92| Step: 0
Training loss: 1.4246666431427002
Validation loss: 2.0395398239294686

Epoch: 5| Step: 1
Training loss: 1.846072793006897
Validation loss: 2.0300972958405814

Epoch: 5| Step: 2
Training loss: 1.9530446529388428
Validation loss: 2.065628930926323

Epoch: 5| Step: 3
Training loss: 1.4301702976226807
Validation loss: 2.031200955311457

Epoch: 5| Step: 4
Training loss: 1.3371031284332275
Validation loss: 2.050843651096026

Epoch: 5| Step: 5
Training loss: 1.6827642917633057
Validation loss: 2.03871780137221

Epoch: 5| Step: 6
Training loss: 2.1787052154541016
Validation loss: 2.0653129865725837

Epoch: 5| Step: 7
Training loss: 1.334675669670105
Validation loss: 2.08184577524662

Epoch: 5| Step: 8
Training loss: 2.0422613620758057
Validation loss: 2.0737605541944504

Epoch: 5| Step: 9
Training loss: 1.3412706851959229
Validation loss: 2.0823430866003036

Epoch: 5| Step: 10
Training loss: 2.083216667175293
Validation loss: 2.0778481165568032

Epoch: 5| Step: 11
Training loss: 3.2238399982452393
Validation loss: 2.111891597509384

Epoch: 93| Step: 0
Training loss: 1.1143138408660889
Validation loss: 2.0952200144529343

Epoch: 5| Step: 1
Training loss: 1.6601425409317017
Validation loss: 2.0860874007145562

Epoch: 5| Step: 2
Training loss: 1.377910852432251
Validation loss: 2.121162856618563

Epoch: 5| Step: 3
Training loss: 2.4761364459991455
Validation loss: 2.1055827289819717

Epoch: 5| Step: 4
Training loss: 1.930580496788025
Validation loss: 2.090209702650706

Epoch: 5| Step: 5
Training loss: 1.6656816005706787
Validation loss: 2.054341514905294

Epoch: 5| Step: 6
Training loss: 1.44687819480896
Validation loss: 2.091444825132688

Epoch: 5| Step: 7
Training loss: 2.0735249519348145
Validation loss: 2.0483204076687493

Epoch: 5| Step: 8
Training loss: 1.946014404296875
Validation loss: 2.0321008414030075

Epoch: 5| Step: 9
Training loss: 2.2047791481018066
Validation loss: 2.0477043241262436

Epoch: 5| Step: 10
Training loss: 1.30941641330719
Validation loss: 2.0553440550963082

Epoch: 5| Step: 11
Training loss: 1.389622688293457
Validation loss: 2.0309216479460397

Epoch: 94| Step: 0
Training loss: 1.7316566705703735
Validation loss: 2.025271311402321

Epoch: 5| Step: 1
Training loss: 1.459193468093872
Validation loss: 2.0304603576660156

Epoch: 5| Step: 2
Training loss: 1.8627502918243408
Validation loss: 2.0573783864577613

Epoch: 5| Step: 3
Training loss: 1.5738983154296875
Validation loss: 2.074164852499962

Epoch: 5| Step: 4
Training loss: 2.2338194847106934
Validation loss: 2.0742257684469223

Epoch: 5| Step: 5
Training loss: 1.7450764179229736
Validation loss: 2.093299607435862

Epoch: 5| Step: 6
Training loss: 1.7560951709747314
Validation loss: 2.0664094338814416

Epoch: 5| Step: 7
Training loss: 1.558241605758667
Validation loss: 2.0658034632603326

Epoch: 5| Step: 8
Training loss: 1.157820701599121
Validation loss: 2.068643733859062

Epoch: 5| Step: 9
Training loss: 1.6651973724365234
Validation loss: 2.091114729642868

Epoch: 5| Step: 10
Training loss: 2.229775905609131
Validation loss: 2.0604798942804337

Epoch: 5| Step: 11
Training loss: 1.216277837753296
Validation loss: 2.103629653652509

Epoch: 95| Step: 0
Training loss: 1.845343828201294
Validation loss: 2.084131653110186

Epoch: 5| Step: 1
Training loss: 1.409164547920227
Validation loss: 2.0692898333072662

Epoch: 5| Step: 2
Training loss: 1.391052484512329
Validation loss: 2.06622052192688

Epoch: 5| Step: 3
Training loss: 1.9168727397918701
Validation loss: 2.0816025932629905

Epoch: 5| Step: 4
Training loss: 1.866744041442871
Validation loss: 2.0448896090189614

Epoch: 5| Step: 5
Training loss: 1.970027208328247
Validation loss: 2.0480482379595437

Epoch: 5| Step: 6
Training loss: 1.7836319208145142
Validation loss: 2.0219225138425827

Epoch: 5| Step: 7
Training loss: 1.6152470111846924
Validation loss: 2.0334646006425223

Epoch: 5| Step: 8
Training loss: 1.451867938041687
Validation loss: 2.060529033342997

Epoch: 5| Step: 9
Training loss: 1.7150404453277588
Validation loss: 2.054030865430832

Epoch: 5| Step: 10
Training loss: 2.0144388675689697
Validation loss: 2.0758169243733087

Epoch: 5| Step: 11
Training loss: 1.483420968055725
Validation loss: 2.0869063635667167

Epoch: 96| Step: 0
Training loss: 1.9094552993774414
Validation loss: 2.1058267454306283

Epoch: 5| Step: 1
Training loss: 1.6780811548233032
Validation loss: 2.1247944285472236

Epoch: 5| Step: 2
Training loss: 0.9539801478385925
Validation loss: 2.144519165158272

Epoch: 5| Step: 3
Training loss: 2.1458537578582764
Validation loss: 2.129268949230512

Epoch: 5| Step: 4
Training loss: 1.7974754571914673
Validation loss: 2.075648615757624

Epoch: 5| Step: 5
Training loss: 1.4355595111846924
Validation loss: 2.145513584216436

Epoch: 5| Step: 6
Training loss: 2.20459246635437
Validation loss: 2.08683971563975

Epoch: 5| Step: 7
Training loss: 1.5831235647201538
Validation loss: 2.0576050033171973

Epoch: 5| Step: 8
Training loss: 1.9485228061676025
Validation loss: 2.0645789553721747

Epoch: 5| Step: 9
Training loss: 1.6531894207000732
Validation loss: 2.0295881778001785

Epoch: 5| Step: 10
Training loss: 1.5422741174697876
Validation loss: 2.042418663700422

Epoch: 5| Step: 11
Training loss: 1.5381550788879395
Validation loss: 2.0698030640681586

Epoch: 97| Step: 0
Training loss: 2.2765769958496094
Validation loss: 2.0494126280148826

Epoch: 5| Step: 1
Training loss: 1.0197633504867554
Validation loss: 2.020143449306488

Epoch: 5| Step: 2
Training loss: 1.9032701253890991
Validation loss: 2.0335914144913354

Epoch: 5| Step: 3
Training loss: 1.9110673666000366
Validation loss: 2.0620794693628945

Epoch: 5| Step: 4
Training loss: 1.8593038320541382
Validation loss: 2.038307254513105

Epoch: 5| Step: 5
Training loss: 1.5446892976760864
Validation loss: 2.0300712436437607

Epoch: 5| Step: 6
Training loss: 1.6751620769500732
Validation loss: 2.018880402048429

Epoch: 5| Step: 7
Training loss: 1.268507480621338
Validation loss: 2.0764028479655585

Epoch: 5| Step: 8
Training loss: 2.0038561820983887
Validation loss: 2.0866146137317023

Epoch: 5| Step: 9
Training loss: 2.0307092666625977
Validation loss: 2.102087433139483

Epoch: 5| Step: 10
Training loss: 1.4917867183685303
Validation loss: 2.1222192545731864

Epoch: 5| Step: 11
Training loss: 2.8648934364318848
Validation loss: 2.1535736322402954

Epoch: 98| Step: 0
Training loss: 2.090757369995117
Validation loss: 2.15231924255689

Epoch: 5| Step: 1
Training loss: 1.4625699520111084
Validation loss: 2.142545690139135

Epoch: 5| Step: 2
Training loss: 1.6993252038955688
Validation loss: 2.158369928598404

Epoch: 5| Step: 3
Training loss: 1.70528244972229
Validation loss: 2.0928584237893424

Epoch: 5| Step: 4
Training loss: 2.588827133178711
Validation loss: 2.1151225666205087

Epoch: 5| Step: 5
Training loss: 1.4931800365447998
Validation loss: 2.0687484244505563

Epoch: 5| Step: 6
Training loss: 1.397803544998169
Validation loss: 2.0390717883904776

Epoch: 5| Step: 7
Training loss: 1.9529094696044922
Validation loss: 2.0651356230179467

Epoch: 5| Step: 8
Training loss: 1.6086784601211548
Validation loss: 2.0381916711727777

Epoch: 5| Step: 9
Training loss: 1.5504733324050903
Validation loss: 2.062240774432818

Epoch: 5| Step: 10
Training loss: 1.6448720693588257
Validation loss: 2.060604840517044

Epoch: 5| Step: 11
Training loss: 1.2944204807281494
Validation loss: 2.0740573505560556

Epoch: 99| Step: 0
Training loss: 1.5009785890579224
Validation loss: 2.0406408260265985

Epoch: 5| Step: 1
Training loss: 1.5053160190582275
Validation loss: 2.0512958467006683

Epoch: 5| Step: 2
Training loss: 1.7870391607284546
Validation loss: 2.0442059685786567

Epoch: 5| Step: 3
Training loss: 1.1300041675567627
Validation loss: 2.0631027966737747

Epoch: 5| Step: 4
Training loss: 1.4715545177459717
Validation loss: 2.057466501990954

Epoch: 5| Step: 5
Training loss: 1.7294626235961914
Validation loss: 2.046101604898771

Epoch: 5| Step: 6
Training loss: 1.333727240562439
Validation loss: 2.024446095029513

Epoch: 5| Step: 7
Training loss: 2.336750030517578
Validation loss: 2.063188115755717

Epoch: 5| Step: 8
Training loss: 2.280777931213379
Validation loss: 2.057489891846975

Epoch: 5| Step: 9
Training loss: 1.678715467453003
Validation loss: 2.0426144947608313

Epoch: 5| Step: 10
Training loss: 1.8490291833877563
Validation loss: 2.0655049085617065

Epoch: 5| Step: 11
Training loss: 0.834281325340271
Validation loss: 2.0826513369878135

Epoch: 100| Step: 0
Training loss: 2.0077993869781494
Validation loss: 2.1034734497467675

Epoch: 5| Step: 1
Training loss: 2.15962290763855
Validation loss: 2.1665246188640594

Epoch: 5| Step: 2
Training loss: 1.9733524322509766
Validation loss: 2.194953223069509

Epoch: 5| Step: 3
Training loss: 1.6689332723617554
Validation loss: 2.2747400353352227

Epoch: 5| Step: 4
Training loss: 1.775481939315796
Validation loss: 2.2249387900034585

Epoch: 5| Step: 5
Training loss: 1.9760878086090088
Validation loss: 2.182301084200541

Epoch: 5| Step: 6
Training loss: 1.7098270654678345
Validation loss: 2.131261790792147

Epoch: 5| Step: 7
Training loss: 1.928676962852478
Validation loss: 2.090050001939138

Epoch: 5| Step: 8
Training loss: 1.6144145727157593
Validation loss: 2.031813537081083

Epoch: 5| Step: 9
Training loss: 1.5535123348236084
Validation loss: 2.0531875838836036

Epoch: 5| Step: 10
Training loss: 1.989617109298706
Validation loss: 2.0311250338951745

Epoch: 5| Step: 11
Training loss: 0.620927095413208
Validation loss: 2.041810914874077

Epoch: 101| Step: 0
Training loss: 1.6409651041030884
Validation loss: 2.051552027463913

Epoch: 5| Step: 1
Training loss: 1.6653703451156616
Validation loss: 2.040086348851522

Epoch: 5| Step: 2
Training loss: 1.8509299755096436
Validation loss: 2.044446369012197

Epoch: 5| Step: 3
Training loss: 1.272484540939331
Validation loss: 2.073378031452497

Epoch: 5| Step: 4
Training loss: 2.2297921180725098
Validation loss: 2.046138887604078

Epoch: 5| Step: 5
Training loss: 1.425959587097168
Validation loss: 2.0380238443613052

Epoch: 5| Step: 6
Training loss: 1.8675800561904907
Validation loss: 2.032645493745804

Epoch: 5| Step: 7
Training loss: 1.8336139917373657
Validation loss: 2.073807885249456

Epoch: 5| Step: 8
Training loss: 2.263126850128174
Validation loss: 2.092124874393145

Epoch: 5| Step: 9
Training loss: 0.8385425806045532
Validation loss: 2.096712817748388

Epoch: 5| Step: 10
Training loss: 2.151548385620117
Validation loss: 2.0920390089352927

Epoch: 5| Step: 11
Training loss: 2.1504883766174316
Validation loss: 2.0793970773617425

Epoch: 102| Step: 0
Training loss: 1.188773512840271
Validation loss: 2.0920693377653756

Epoch: 5| Step: 1
Training loss: 1.214882493019104
Validation loss: 2.0885661840438843

Epoch: 5| Step: 2
Training loss: 1.5196259021759033
Validation loss: 2.0866335729757943

Epoch: 5| Step: 3
Training loss: 1.6843912601470947
Validation loss: 2.047995761036873

Epoch: 5| Step: 4
Training loss: 1.7957000732421875
Validation loss: 2.090029646952947

Epoch: 5| Step: 5
Training loss: 1.526029109954834
Validation loss: 2.0411824782689414

Epoch: 5| Step: 6
Training loss: 1.4237703084945679
Validation loss: 2.040620431303978

Epoch: 5| Step: 7
Training loss: 1.2713340520858765
Validation loss: 2.0885273466507592

Epoch: 5| Step: 8
Training loss: 2.0262508392333984
Validation loss: 2.0796085794766745

Epoch: 5| Step: 9
Training loss: 1.8007440567016602
Validation loss: 2.0846172322829566

Epoch: 5| Step: 10
Training loss: 2.8637771606445312
Validation loss: 2.0911949574947357

Epoch: 5| Step: 11
Training loss: 2.2229580879211426
Validation loss: 2.0920323878526688

Epoch: 103| Step: 0
Training loss: 1.8568331003189087
Validation loss: 2.150349279244741

Epoch: 5| Step: 1
Training loss: 1.8363196849822998
Validation loss: 2.1520071725050607

Epoch: 5| Step: 2
Training loss: 2.466435670852661
Validation loss: 2.135041822989782

Epoch: 5| Step: 3
Training loss: 1.733303427696228
Validation loss: 2.1624500999848046

Epoch: 5| Step: 4
Training loss: 1.6584796905517578
Validation loss: 2.169699882467588

Epoch: 5| Step: 5
Training loss: 1.7156498432159424
Validation loss: 2.1617189397414527

Epoch: 5| Step: 6
Training loss: 1.386605978012085
Validation loss: 2.1016004184881845

Epoch: 5| Step: 7
Training loss: 1.8396003246307373
Validation loss: 2.0944405645132065

Epoch: 5| Step: 8
Training loss: 1.4334169626235962
Validation loss: 2.0509260296821594

Epoch: 5| Step: 9
Training loss: 1.2896807193756104
Validation loss: 2.0122673511505127

Epoch: 5| Step: 10
Training loss: 1.3079640865325928
Validation loss: 2.0585347414016724

Epoch: 5| Step: 11
Training loss: 2.5328726768493652
Validation loss: 2.0143485565980277

Epoch: 104| Step: 0
Training loss: 2.0368824005126953
Validation loss: 2.048941344022751

Epoch: 5| Step: 1
Training loss: 1.5404832363128662
Validation loss: 2.0540185819069543

Epoch: 5| Step: 2
Training loss: 0.7934989929199219
Validation loss: 2.0606954793135324

Epoch: 5| Step: 3
Training loss: 1.5389440059661865
Validation loss: 2.033832093079885

Epoch: 5| Step: 4
Training loss: 1.776671051979065
Validation loss: 2.0809410959482193

Epoch: 5| Step: 5
Training loss: 2.03053617477417
Validation loss: 2.097792704900106

Epoch: 5| Step: 6
Training loss: 1.9576839208602905
Validation loss: 2.0835143675406775

Epoch: 5| Step: 7
Training loss: 1.483659029006958
Validation loss: 2.082731048266093

Epoch: 5| Step: 8
Training loss: 1.6201874017715454
Validation loss: 2.1003574281930923

Epoch: 5| Step: 9
Training loss: 1.6782276630401611
Validation loss: 2.0996898810068765

Epoch: 5| Step: 10
Training loss: 1.6239019632339478
Validation loss: 2.109357143441836

Epoch: 5| Step: 11
Training loss: 1.1672543287277222
Validation loss: 2.0760097901026406

Epoch: 105| Step: 0
Training loss: 1.620252013206482
Validation loss: 2.1069884995619454

Epoch: 5| Step: 1
Training loss: 1.1781344413757324
Validation loss: 2.1250083992878595

Epoch: 5| Step: 2
Training loss: 1.7040977478027344
Validation loss: 2.142878050605456

Epoch: 5| Step: 3
Training loss: 1.9282143115997314
Validation loss: 2.161227156718572

Epoch: 5| Step: 4
Training loss: 1.9302194118499756
Validation loss: 2.170294592777888

Epoch: 5| Step: 5
Training loss: 1.4544131755828857
Validation loss: 2.126138985157013

Epoch: 5| Step: 6
Training loss: 1.9164791107177734
Validation loss: 2.108676622311274

Epoch: 5| Step: 7
Training loss: 1.7167587280273438
Validation loss: 2.089297523101171

Epoch: 5| Step: 8
Training loss: 1.7524789571762085
Validation loss: 2.040184572339058

Epoch: 5| Step: 9
Training loss: 1.580806851387024
Validation loss: 2.060389662782351

Epoch: 5| Step: 10
Training loss: 1.1182730197906494
Validation loss: 2.0529786249001822

Epoch: 5| Step: 11
Training loss: 1.4450783729553223
Validation loss: 2.0853182524442673

Epoch: 106| Step: 0
Training loss: 1.4835011959075928
Validation loss: 2.046977018316587

Epoch: 5| Step: 1
Training loss: 1.4430897235870361
Validation loss: 2.040159339706103

Epoch: 5| Step: 2
Training loss: 1.8967148065567017
Validation loss: 2.0650059481461844

Epoch: 5| Step: 3
Training loss: 1.8013397455215454
Validation loss: 2.0584136893351874

Epoch: 5| Step: 4
Training loss: 1.6902490854263306
Validation loss: 1.9943026552597682

Epoch: 5| Step: 5
Training loss: 2.0252108573913574
Validation loss: 2.0217279295126596

Epoch: 5| Step: 6
Training loss: 1.5960371494293213
Validation loss: 2.0966647962729135

Epoch: 5| Step: 7
Training loss: 1.2487818002700806
Validation loss: 2.0189457635084787

Epoch: 5| Step: 8
Training loss: 1.2763614654541016
Validation loss: 2.054983193675677

Epoch: 5| Step: 9
Training loss: 1.71637761592865
Validation loss: 2.089579999446869

Epoch: 5| Step: 10
Training loss: 2.008274555206299
Validation loss: 2.0440457314252853

Epoch: 5| Step: 11
Training loss: 1.708536148071289
Validation loss: 2.0975738217433295

Epoch: 107| Step: 0
Training loss: 2.714453935623169
Validation loss: 2.0609710415204368

Epoch: 5| Step: 1
Training loss: 1.286642074584961
Validation loss: 2.1028631130854287

Epoch: 5| Step: 2
Training loss: 1.6271250247955322
Validation loss: 2.0421487192312875

Epoch: 5| Step: 3
Training loss: 1.7576106786727905
Validation loss: 2.0628907283147178

Epoch: 5| Step: 4
Training loss: 1.4835336208343506
Validation loss: 2.0568091024955115

Epoch: 5| Step: 5
Training loss: 1.0330369472503662
Validation loss: 2.0615140895048776

Epoch: 5| Step: 6
Training loss: 1.5116386413574219
Validation loss: 2.0645188043514886

Epoch: 5| Step: 7
Training loss: 1.9816099405288696
Validation loss: 2.027404323220253

Epoch: 5| Step: 8
Training loss: 1.651956558227539
Validation loss: 2.0695866694053016

Epoch: 5| Step: 9
Training loss: 1.3405462503433228
Validation loss: 2.0558522095282874

Epoch: 5| Step: 10
Training loss: 1.644335150718689
Validation loss: 2.1302030036846795

Epoch: 5| Step: 11
Training loss: 2.1638059616088867
Validation loss: 2.095159669717153

Epoch: 108| Step: 0
Training loss: 1.8149662017822266
Validation loss: 2.0960598438978195

Epoch: 5| Step: 1
Training loss: 1.6806102991104126
Validation loss: 2.093094895283381

Epoch: 5| Step: 2
Training loss: 1.878922462463379
Validation loss: 2.036699796716372

Epoch: 5| Step: 3
Training loss: 1.7017320394515991
Validation loss: 2.0725038001934686

Epoch: 5| Step: 4
Training loss: 1.7583181858062744
Validation loss: 2.059583306312561

Epoch: 5| Step: 5
Training loss: 1.1675535440444946
Validation loss: 2.0225309133529663

Epoch: 5| Step: 6
Training loss: 1.7861133813858032
Validation loss: 2.0905285576979318

Epoch: 5| Step: 7
Training loss: 1.1348987817764282
Validation loss: 2.0418640474478402

Epoch: 5| Step: 8
Training loss: 1.7717396020889282
Validation loss: 2.0909354041020074

Epoch: 5| Step: 9
Training loss: 1.4341466426849365
Validation loss: 2.121303270260493

Epoch: 5| Step: 10
Training loss: 1.7610763311386108
Validation loss: 2.025383859872818

Epoch: 5| Step: 11
Training loss: 1.1255478858947754
Validation loss: 2.0656220416227975

Epoch: 109| Step: 0
Training loss: 1.6058342456817627
Validation loss: 2.044730708003044

Epoch: 5| Step: 1
Training loss: 1.7541335821151733
Validation loss: 2.0370692809422812

Epoch: 5| Step: 2
Training loss: 1.8234307765960693
Validation loss: 2.0781869292259216

Epoch: 5| Step: 3
Training loss: 1.4180694818496704
Validation loss: 2.042473057905833

Epoch: 5| Step: 4
Training loss: 1.3742733001708984
Validation loss: 2.0779494444529214

Epoch: 5| Step: 5
Training loss: 1.7219054698944092
Validation loss: 2.095617343982061

Epoch: 5| Step: 6
Training loss: 2.0084831714630127
Validation loss: 2.0385157614946365

Epoch: 5| Step: 7
Training loss: 1.7542736530303955
Validation loss: 2.090723291039467

Epoch: 5| Step: 8
Training loss: 1.1874802112579346
Validation loss: 2.0575460890928903

Epoch: 5| Step: 9
Training loss: 1.881182074546814
Validation loss: 2.0912230412165322

Epoch: 5| Step: 10
Training loss: 1.1660454273223877
Validation loss: 2.0318085153897605

Epoch: 5| Step: 11
Training loss: 1.6706606149673462
Validation loss: 2.0400557120641074

Epoch: 110| Step: 0
Training loss: 1.1752452850341797
Validation loss: 2.058628797531128

Epoch: 5| Step: 1
Training loss: 1.3983571529388428
Validation loss: 2.048272659381231

Epoch: 5| Step: 2
Training loss: 2.303001880645752
Validation loss: 2.052140404780706

Epoch: 5| Step: 3
Training loss: 1.32932710647583
Validation loss: 2.0998699019352594

Epoch: 5| Step: 4
Training loss: 1.480881690979004
Validation loss: 2.114742875099182

Epoch: 5| Step: 5
Training loss: 1.5515925884246826
Validation loss: 2.0623749593893685

Epoch: 5| Step: 6
Training loss: 2.149277448654175
Validation loss: 2.0517374177773795

Epoch: 5| Step: 7
Training loss: 1.4347777366638184
Validation loss: 2.05625918507576

Epoch: 5| Step: 8
Training loss: 1.8117634057998657
Validation loss: 2.0530863950649896

Epoch: 5| Step: 9
Training loss: 1.3074077367782593
Validation loss: 2.0415518085161843

Epoch: 5| Step: 10
Training loss: 1.507907509803772
Validation loss: 2.0707854479551315

Epoch: 5| Step: 11
Training loss: 0.6367003321647644
Validation loss: 2.0229038894176483

Epoch: 111| Step: 0
Training loss: 1.5081586837768555
Validation loss: 2.0679550071557364

Epoch: 5| Step: 1
Training loss: 0.9618598818778992
Validation loss: 2.04014790058136

Epoch: 5| Step: 2
Training loss: 1.776137113571167
Validation loss: 2.0470969527959824

Epoch: 5| Step: 3
Training loss: 1.963974952697754
Validation loss: 2.0530561258395514

Epoch: 5| Step: 4
Training loss: 1.436853051185608
Validation loss: 2.0891300787528357

Epoch: 5| Step: 5
Training loss: 1.235163927078247
Validation loss: 2.1285937825838723

Epoch: 5| Step: 6
Training loss: 1.6126108169555664
Validation loss: 2.1024916917085648

Epoch: 5| Step: 7
Training loss: 1.8511186838150024
Validation loss: 2.0844433903694153

Epoch: 5| Step: 8
Training loss: 1.7413524389266968
Validation loss: 2.0829921861489615

Epoch: 5| Step: 9
Training loss: 1.6659033298492432
Validation loss: 2.0257908552885056

Epoch: 5| Step: 10
Training loss: 1.8910577297210693
Validation loss: 2.0571130166451135

Epoch: 5| Step: 11
Training loss: 0.5612200498580933
Validation loss: 2.036243185400963

Epoch: 112| Step: 0
Training loss: 1.665763258934021
Validation loss: 2.0717514703671136

Epoch: 5| Step: 1
Training loss: 1.9649951457977295
Validation loss: 2.0352021555105844

Epoch: 5| Step: 2
Training loss: 1.4464874267578125
Validation loss: 2.031333953142166

Epoch: 5| Step: 3
Training loss: 1.718315839767456
Validation loss: 2.03756316502889

Epoch: 5| Step: 4
Training loss: 1.0093756914138794
Validation loss: 2.059320241212845

Epoch: 5| Step: 5
Training loss: 1.4368730783462524
Validation loss: 2.088359678785006

Epoch: 5| Step: 6
Training loss: 1.3113664388656616
Validation loss: 2.042891889810562

Epoch: 5| Step: 7
Training loss: 1.785294771194458
Validation loss: 2.0563104301691055

Epoch: 5| Step: 8
Training loss: 1.7077865600585938
Validation loss: 2.0493474105993905

Epoch: 5| Step: 9
Training loss: 1.6999671459197998
Validation loss: 2.0429890205462775

Epoch: 5| Step: 10
Training loss: 1.677130103111267
Validation loss: 2.05237969259421

Epoch: 5| Step: 11
Training loss: 0.6784530878067017
Validation loss: 2.0655381927887597

Epoch: 113| Step: 0
Training loss: 1.16011643409729
Validation loss: 2.1276794771353402

Epoch: 5| Step: 1
Training loss: 1.7309871912002563
Validation loss: 2.1526332795619965

Epoch: 5| Step: 2
Training loss: 1.7045338153839111
Validation loss: 2.1721275448799133

Epoch: 5| Step: 3
Training loss: 2.433954954147339
Validation loss: 2.187418152888616

Epoch: 5| Step: 4
Training loss: 1.7433913946151733
Validation loss: 2.2120772103468576

Epoch: 5| Step: 5
Training loss: 1.8601738214492798
Validation loss: 2.1912167221307755

Epoch: 5| Step: 6
Training loss: 1.2870304584503174
Validation loss: 2.1304070204496384

Epoch: 5| Step: 7
Training loss: 1.6605751514434814
Validation loss: 2.0774275958538055

Epoch: 5| Step: 8
Training loss: 1.7557342052459717
Validation loss: 2.0724676996469498

Epoch: 5| Step: 9
Training loss: 1.0515400171279907
Validation loss: 2.0604827255010605

Epoch: 5| Step: 10
Training loss: 1.3789315223693848
Validation loss: 2.0795371681451797

Epoch: 5| Step: 11
Training loss: 0.39615702629089355
Validation loss: 2.090914229551951

Epoch: 114| Step: 0
Training loss: 1.5709600448608398
Validation loss: 2.0432626207669577

Epoch: 5| Step: 1
Training loss: 1.1955076456069946
Validation loss: 2.0772920499245324

Epoch: 5| Step: 2
Training loss: 2.077258348464966
Validation loss: 2.0335935999949775

Epoch: 5| Step: 3
Training loss: 1.5637223720550537
Validation loss: 2.0357133050759635

Epoch: 5| Step: 4
Training loss: 1.3621609210968018
Validation loss: 2.077510416507721

Epoch: 5| Step: 5
Training loss: 1.2826669216156006
Validation loss: 2.103259618083636

Epoch: 5| Step: 6
Training loss: 1.375255823135376
Validation loss: 2.0748290618260703

Epoch: 5| Step: 7
Training loss: 1.7304607629776
Validation loss: 2.07845202088356

Epoch: 5| Step: 8
Training loss: 1.5538896322250366
Validation loss: 2.1073348621527352

Epoch: 5| Step: 9
Training loss: 1.6998016834259033
Validation loss: 2.0539986987908683

Epoch: 5| Step: 10
Training loss: 1.3759515285491943
Validation loss: 2.0504698355992637

Epoch: 5| Step: 11
Training loss: 1.8493633270263672
Validation loss: 2.0549126168092093

Epoch: 115| Step: 0
Training loss: 1.552004098892212
Validation loss: 2.085142051180204

Epoch: 5| Step: 1
Training loss: 1.5194823741912842
Validation loss: 2.032362883289655

Epoch: 5| Step: 2
Training loss: 1.4088785648345947
Validation loss: 2.0572515229384103

Epoch: 5| Step: 3
Training loss: 1.224236011505127
Validation loss: 2.051164522767067

Epoch: 5| Step: 4
Training loss: 1.4791619777679443
Validation loss: 2.014772782723109

Epoch: 5| Step: 5
Training loss: 1.7630466222763062
Validation loss: 2.082302466034889

Epoch: 5| Step: 6
Training loss: 1.8584457635879517
Validation loss: 2.0888166477282843

Epoch: 5| Step: 7
Training loss: 1.5615410804748535
Validation loss: 2.0925520807504654

Epoch: 5| Step: 8
Training loss: 1.1970055103302002
Validation loss: 2.1145296494166055

Epoch: 5| Step: 9
Training loss: 1.4265273809432983
Validation loss: 2.1412597646315894

Epoch: 5| Step: 10
Training loss: 1.9014766216278076
Validation loss: 2.106496920188268

Epoch: 5| Step: 11
Training loss: 0.7861933708190918
Validation loss: 2.105366508165995

Epoch: 116| Step: 0
Training loss: 1.3842580318450928
Validation loss: 2.08863099416097

Epoch: 5| Step: 1
Training loss: 1.3302332162857056
Validation loss: 2.0944783141215644

Epoch: 5| Step: 2
Training loss: 1.3174940347671509
Validation loss: 2.053805261850357

Epoch: 5| Step: 3
Training loss: 1.6050307750701904
Validation loss: 2.0452494521935782

Epoch: 5| Step: 4
Training loss: 1.1336581707000732
Validation loss: 2.092476025223732

Epoch: 5| Step: 5
Training loss: 1.5340116024017334
Validation loss: 2.0856751451889672

Epoch: 5| Step: 6
Training loss: 1.6910817623138428
Validation loss: 2.0974257737398148

Epoch: 5| Step: 7
Training loss: 1.8153820037841797
Validation loss: 2.0363027503093085

Epoch: 5| Step: 8
Training loss: 1.6449686288833618
Validation loss: 2.028446634610494

Epoch: 5| Step: 9
Training loss: 1.4866575002670288
Validation loss: 2.0432142515977225

Epoch: 5| Step: 10
Training loss: 1.484611988067627
Validation loss: 2.0753137171268463

Epoch: 5| Step: 11
Training loss: 1.1020783185958862
Validation loss: 2.0262846251328788

Epoch: 117| Step: 0
Training loss: 1.5844953060150146
Validation loss: 2.043199082215627

Epoch: 5| Step: 1
Training loss: 1.0479792356491089
Validation loss: 2.0437850952148438

Epoch: 5| Step: 2
Training loss: 1.505479097366333
Validation loss: 2.0647265315055847

Epoch: 5| Step: 3
Training loss: 1.6872284412384033
Validation loss: 2.0672314961751304

Epoch: 5| Step: 4
Training loss: 1.221933126449585
Validation loss: 2.018258363008499

Epoch: 5| Step: 5
Training loss: 2.2149739265441895
Validation loss: 2.041761746009191

Epoch: 5| Step: 6
Training loss: 1.5018234252929688
Validation loss: 2.036099369327227

Epoch: 5| Step: 7
Training loss: 1.4606678485870361
Validation loss: 2.081984822948774

Epoch: 5| Step: 8
Training loss: 1.5954259634017944
Validation loss: 2.0986091693242392

Epoch: 5| Step: 9
Training loss: 1.6036243438720703
Validation loss: 2.0458193123340607

Epoch: 5| Step: 10
Training loss: 1.0389503240585327
Validation loss: 2.043561652302742

Epoch: 5| Step: 11
Training loss: 1.5678126811981201
Validation loss: 2.0537140170733132

Epoch: 118| Step: 0
Training loss: 1.2499053478240967
Validation loss: 2.0117793679237366

Epoch: 5| Step: 1
Training loss: 1.7898451089859009
Validation loss: 2.0409289548794427

Epoch: 5| Step: 2
Training loss: 1.0462195873260498
Validation loss: 2.0348635762929916

Epoch: 5| Step: 3
Training loss: 1.0926624536514282
Validation loss: 2.065787265698115

Epoch: 5| Step: 4
Training loss: 1.664585828781128
Validation loss: 2.06448861459891

Epoch: 5| Step: 5
Training loss: 1.1762632131576538
Validation loss: 2.044380376736323

Epoch: 5| Step: 6
Training loss: 1.2959424257278442
Validation loss: 2.0511120011409125

Epoch: 5| Step: 7
Training loss: 1.6670284271240234
Validation loss: 2.1114156941572824

Epoch: 5| Step: 8
Training loss: 1.3518457412719727
Validation loss: 2.0512616087992988

Epoch: 5| Step: 9
Training loss: 1.7088438272476196
Validation loss: 2.087603802482287

Epoch: 5| Step: 10
Training loss: 1.675621747970581
Validation loss: 2.104827344417572

Epoch: 5| Step: 11
Training loss: 2.660398244857788
Validation loss: 2.110395540793737

Epoch: 119| Step: 0
Training loss: 1.1267828941345215
Validation loss: 2.0808058281739554

Epoch: 5| Step: 1
Training loss: 1.862338662147522
Validation loss: 2.0667344282070794

Epoch: 5| Step: 2
Training loss: 2.1573173999786377
Validation loss: 2.071301663915316

Epoch: 5| Step: 3
Training loss: 1.5817797183990479
Validation loss: 2.007183164358139

Epoch: 5| Step: 4
Training loss: 1.481210470199585
Validation loss: 2.0225284645954766

Epoch: 5| Step: 5
Training loss: 1.1290234327316284
Validation loss: 2.029694785674413

Epoch: 5| Step: 6
Training loss: 1.527856469154358
Validation loss: 2.0448548247416816

Epoch: 5| Step: 7
Training loss: 1.4318714141845703
Validation loss: 2.0261193364858627

Epoch: 5| Step: 8
Training loss: 1.6433852910995483
Validation loss: 2.0888325721025467

Epoch: 5| Step: 9
Training loss: 1.2655878067016602
Validation loss: 2.041474928458532

Epoch: 5| Step: 10
Training loss: 0.8903363347053528
Validation loss: 2.101703961690267

Epoch: 5| Step: 11
Training loss: 1.589805245399475
Validation loss: 2.033268998066584

Epoch: 120| Step: 0
Training loss: 1.9248756170272827
Validation loss: 2.0712542881568274

Epoch: 5| Step: 1
Training loss: 1.7412736415863037
Validation loss: 2.094546005129814

Epoch: 5| Step: 2
Training loss: 1.1221568584442139
Validation loss: 2.171353295445442

Epoch: 5| Step: 3
Training loss: 1.8086341619491577
Validation loss: 2.183382968107859

Epoch: 5| Step: 4
Training loss: 1.4504332542419434
Validation loss: 2.1198266396919885

Epoch: 5| Step: 5
Training loss: 1.2718355655670166
Validation loss: 2.059349368015925

Epoch: 5| Step: 6
Training loss: 1.167595624923706
Validation loss: 2.050962616999944

Epoch: 5| Step: 7
Training loss: 1.6513293981552124
Validation loss: 2.006196146210035

Epoch: 5| Step: 8
Training loss: 1.3148443698883057
Validation loss: 2.005090663830439

Epoch: 5| Step: 9
Training loss: 1.5323190689086914
Validation loss: 1.9939558058977127

Epoch: 5| Step: 10
Training loss: 1.7355684041976929
Validation loss: 2.0193478961785636

Epoch: 5| Step: 11
Training loss: 1.5099297761917114
Validation loss: 2.0148597906033197

Epoch: 121| Step: 0
Training loss: 1.2050676345825195
Validation loss: 1.9839936643838882

Epoch: 5| Step: 1
Training loss: 1.3048937320709229
Validation loss: 2.006777430574099

Epoch: 5| Step: 2
Training loss: 1.404004454612732
Validation loss: 2.1119821270306907

Epoch: 5| Step: 3
Training loss: 1.7989734411239624
Validation loss: 2.071037466327349

Epoch: 5| Step: 4
Training loss: 1.4221960306167603
Validation loss: 2.082395071784655

Epoch: 5| Step: 5
Training loss: 1.3108141422271729
Validation loss: 2.0574795454740524

Epoch: 5| Step: 6
Training loss: 0.9919179677963257
Validation loss: 2.0842317740122476

Epoch: 5| Step: 7
Training loss: 1.8746874332427979
Validation loss: 2.0420501629511514

Epoch: 5| Step: 8
Training loss: 1.265931487083435
Validation loss: 2.016490161418915

Epoch: 5| Step: 9
Training loss: 1.3015162944793701
Validation loss: 2.023703326781591

Epoch: 5| Step: 10
Training loss: 2.2479238510131836
Validation loss: 2.003625442584356

Epoch: 5| Step: 11
Training loss: 1.3466191291809082
Validation loss: 2.0096353193124137

Epoch: 122| Step: 0
Training loss: 1.4323811531066895
Validation loss: 1.991790696978569

Epoch: 5| Step: 1
Training loss: 0.970859706401825
Validation loss: 2.0563354790210724

Epoch: 5| Step: 2
Training loss: 1.4216889142990112
Validation loss: 2.01879912118117

Epoch: 5| Step: 3
Training loss: 1.818020224571228
Validation loss: 1.997720534602801

Epoch: 5| Step: 4
Training loss: 1.4300901889801025
Validation loss: 2.110556731621424

Epoch: 5| Step: 5
Training loss: 1.3472509384155273
Validation loss: 2.134367605050405

Epoch: 5| Step: 6
Training loss: 1.4728622436523438
Validation loss: 2.1086694796880088

Epoch: 5| Step: 7
Training loss: 1.2647815942764282
Validation loss: 2.107584605614344

Epoch: 5| Step: 8
Training loss: 1.8590625524520874
Validation loss: 2.1304889967044196

Epoch: 5| Step: 9
Training loss: 1.4324824810028076
Validation loss: 2.0169402211904526

Epoch: 5| Step: 10
Training loss: 1.551853060722351
Validation loss: 2.0449945429960885

Epoch: 5| Step: 11
Training loss: 1.3672235012054443
Validation loss: 1.9928226222594578

Epoch: 123| Step: 0
Training loss: 0.9652467966079712
Validation loss: 2.026260087887446

Epoch: 5| Step: 1
Training loss: 1.5620802640914917
Validation loss: 2.0465460419654846

Epoch: 5| Step: 2
Training loss: 1.3858528137207031
Validation loss: 2.013836309313774

Epoch: 5| Step: 3
Training loss: 1.1044319868087769
Validation loss: 2.06938145061334

Epoch: 5| Step: 4
Training loss: 1.3716726303100586
Validation loss: 2.0683481246232986

Epoch: 5| Step: 5
Training loss: 1.3583712577819824
Validation loss: 2.0266051242748895

Epoch: 5| Step: 6
Training loss: 1.6522417068481445
Validation loss: 2.0494773189226785

Epoch: 5| Step: 7
Training loss: 1.6541221141815186
Validation loss: 2.0691794008016586

Epoch: 5| Step: 8
Training loss: 1.5593076944351196
Validation loss: 2.0315326352914176

Epoch: 5| Step: 9
Training loss: 1.4025803804397583
Validation loss: 2.0144009242455163

Epoch: 5| Step: 10
Training loss: 1.6569225788116455
Validation loss: 2.0348035345474877

Epoch: 5| Step: 11
Training loss: 1.754801869392395
Validation loss: 2.0411625454823175

Epoch: 124| Step: 0
Training loss: 1.6640723943710327
Validation loss: 2.039433553814888

Epoch: 5| Step: 1
Training loss: 1.6526000499725342
Validation loss: 1.993724102775256

Epoch: 5| Step: 2
Training loss: 1.470463514328003
Validation loss: 2.096378435691198

Epoch: 5| Step: 3
Training loss: 1.180555820465088
Validation loss: 2.049236128727595

Epoch: 5| Step: 4
Training loss: 1.6244118213653564
Validation loss: 2.109033773342768

Epoch: 5| Step: 5
Training loss: 1.5034301280975342
Validation loss: 2.072644258538882

Epoch: 5| Step: 6
Training loss: 2.003927230834961
Validation loss: 2.1141803612311683

Epoch: 5| Step: 7
Training loss: 1.4081628322601318
Validation loss: 2.047387679417928

Epoch: 5| Step: 8
Training loss: 1.0819692611694336
Validation loss: 2.0618513027826944

Epoch: 5| Step: 9
Training loss: 1.2996031045913696
Validation loss: 1.9897093524535496

Epoch: 5| Step: 10
Training loss: 0.856678307056427
Validation loss: 1.979277362426122

Epoch: 5| Step: 11
Training loss: 0.46264195442199707
Validation loss: 2.0221609622240067

Epoch: 125| Step: 0
Training loss: 1.1805654764175415
Validation loss: 1.9760712881882985

Epoch: 5| Step: 1
Training loss: 1.7576824426651
Validation loss: 2.0428294936815896

Epoch: 5| Step: 2
Training loss: 0.792066216468811
Validation loss: 2.013538877169291

Epoch: 5| Step: 3
Training loss: 1.4288711547851562
Validation loss: 2.0080063492059708

Epoch: 5| Step: 4
Training loss: 1.7777286767959595
Validation loss: 2.0679804732402167

Epoch: 5| Step: 5
Training loss: 1.0496842861175537
Validation loss: 2.063093140721321

Epoch: 5| Step: 6
Training loss: 1.075435757637024
Validation loss: 2.071104258298874

Epoch: 5| Step: 7
Training loss: 2.586500406265259
Validation loss: 2.0693465222915015

Epoch: 5| Step: 8
Training loss: 0.7824602127075195
Validation loss: 2.048846776286761

Epoch: 5| Step: 9
Training loss: 1.6939287185668945
Validation loss: 2.0577954103549323

Epoch: 5| Step: 10
Training loss: 1.3629300594329834
Validation loss: 2.0312440246343613

Epoch: 5| Step: 11
Training loss: 0.8072763681411743
Validation loss: 2.026306296388308

Epoch: 126| Step: 0
Training loss: 1.4625732898712158
Validation loss: 1.9663335432608922

Epoch: 5| Step: 1
Training loss: 1.2217339277267456
Validation loss: 1.965907409787178

Epoch: 5| Step: 2
Training loss: 1.5416285991668701
Validation loss: 1.9804754654566448

Epoch: 5| Step: 3
Training loss: 1.6364206075668335
Validation loss: 1.9837287366390228

Epoch: 5| Step: 4
Training loss: 1.5559974908828735
Validation loss: 2.0251835584640503

Epoch: 5| Step: 5
Training loss: 1.3937098979949951
Validation loss: 1.9749123106400173

Epoch: 5| Step: 6
Training loss: 1.501186728477478
Validation loss: 2.0664174358050027

Epoch: 5| Step: 7
Training loss: 1.3465102910995483
Validation loss: 2.046683962146441

Epoch: 5| Step: 8
Training loss: 1.2805094718933105
Validation loss: 2.072847733894984

Epoch: 5| Step: 9
Training loss: 1.3277531862258911
Validation loss: 2.1060074319442115

Epoch: 5| Step: 10
Training loss: 1.7426992654800415
Validation loss: 2.1025368521610894

Epoch: 5| Step: 11
Training loss: 0.621825098991394
Validation loss: 2.146038850148519

Epoch: 127| Step: 0
Training loss: 1.1166232824325562
Validation loss: 2.1204820424318314

Epoch: 5| Step: 1
Training loss: 1.9452574253082275
Validation loss: 2.138811558485031

Epoch: 5| Step: 2
Training loss: 1.607722282409668
Validation loss: 2.0968548307816186

Epoch: 5| Step: 3
Training loss: 1.1927986145019531
Validation loss: 2.1117378969987235

Epoch: 5| Step: 4
Training loss: 1.8293298482894897
Validation loss: 2.032528966665268

Epoch: 5| Step: 5
Training loss: 1.1457109451293945
Validation loss: 2.0104258308808007

Epoch: 5| Step: 6
Training loss: 1.53887939453125
Validation loss: 1.9629625032345455

Epoch: 5| Step: 7
Training loss: 1.06157648563385
Validation loss: 1.9618759701649349

Epoch: 5| Step: 8
Training loss: 1.4147526025772095
Validation loss: 2.025230367978414

Epoch: 5| Step: 9
Training loss: 1.179299235343933
Validation loss: 1.984002560377121

Epoch: 5| Step: 10
Training loss: 1.5973594188690186
Validation loss: 1.982558826605479

Epoch: 5| Step: 11
Training loss: 1.355664610862732
Validation loss: 2.012529209256172

Epoch: 128| Step: 0
Training loss: 1.4193223714828491
Validation loss: 2.06568843126297

Epoch: 5| Step: 1
Training loss: 1.3990386724472046
Validation loss: 2.048740694920222

Epoch: 5| Step: 2
Training loss: 0.963840126991272
Validation loss: 2.0637047390143075

Epoch: 5| Step: 3
Training loss: 1.6179182529449463
Validation loss: 2.074081147710482

Epoch: 5| Step: 4
Training loss: 1.639459252357483
Validation loss: 2.0559310764074326

Epoch: 5| Step: 5
Training loss: 1.191367745399475
Validation loss: 2.046061451236407

Epoch: 5| Step: 6
Training loss: 1.5504498481750488
Validation loss: 2.0684676269690194

Epoch: 5| Step: 7
Training loss: 1.479900598526001
Validation loss: 2.030035217603048

Epoch: 5| Step: 8
Training loss: 0.8511260151863098
Validation loss: 1.984873577952385

Epoch: 5| Step: 9
Training loss: 1.3453184366226196
Validation loss: 1.9590851366519928

Epoch: 5| Step: 10
Training loss: 1.4424539804458618
Validation loss: 2.014768068989118

Epoch: 5| Step: 11
Training loss: 1.1576001644134521
Validation loss: 2.0057501941919327

Epoch: 129| Step: 0
Training loss: 1.8580198287963867
Validation loss: 2.0067235231399536

Epoch: 5| Step: 1
Training loss: 1.1455219984054565
Validation loss: 1.9824813654025395

Epoch: 5| Step: 2
Training loss: 1.3467971086502075
Validation loss: 1.981881558895111

Epoch: 5| Step: 3
Training loss: 0.9817463159561157
Validation loss: 2.0325132459402084

Epoch: 5| Step: 4
Training loss: 0.8932704925537109
Validation loss: 2.055029128988584

Epoch: 5| Step: 5
Training loss: 1.7122745513916016
Validation loss: 2.0603586534659066

Epoch: 5| Step: 6
Training loss: 1.6151726245880127
Validation loss: 2.0149252712726593

Epoch: 5| Step: 7
Training loss: 0.9834061861038208
Validation loss: 1.9969200988610585

Epoch: 5| Step: 8
Training loss: 1.1121852397918701
Validation loss: 2.040469298760096

Epoch: 5| Step: 9
Training loss: 1.60549795627594
Validation loss: 2.0136414964993796

Epoch: 5| Step: 10
Training loss: 1.1602977514266968
Validation loss: 2.0231194545825324

Epoch: 5| Step: 11
Training loss: 1.8457884788513184
Validation loss: 1.9585531453291576

Epoch: 130| Step: 0
Training loss: 1.4686222076416016
Validation loss: 2.0354200104872384

Epoch: 5| Step: 1
Training loss: 1.5443778038024902
Validation loss: 2.009226088722547

Epoch: 5| Step: 2
Training loss: 2.128715991973877
Validation loss: 1.9666154235601425

Epoch: 5| Step: 3
Training loss: 1.2785247564315796
Validation loss: 2.00738891462485

Epoch: 5| Step: 4
Training loss: 1.1579349040985107
Validation loss: 1.999054804444313

Epoch: 5| Step: 5
Training loss: 0.984022319316864
Validation loss: 2.0857336819171906

Epoch: 5| Step: 6
Training loss: 1.2718913555145264
Validation loss: 2.026367654403051

Epoch: 5| Step: 7
Training loss: 1.0711021423339844
Validation loss: 2.0255738645792007

Epoch: 5| Step: 8
Training loss: 1.246614933013916
Validation loss: 2.0037701576948166

Epoch: 5| Step: 9
Training loss: 1.0038185119628906
Validation loss: 1.9919560253620148

Epoch: 5| Step: 10
Training loss: 1.4310863018035889
Validation loss: 2.004489526152611

Epoch: 5| Step: 11
Training loss: 0.37338173389434814
Validation loss: 2.0140934685866037

Epoch: 131| Step: 0
Training loss: 1.1058634519577026
Validation loss: 2.0176595946153006

Epoch: 5| Step: 1
Training loss: 1.4844046831130981
Validation loss: 2.026454379161199

Epoch: 5| Step: 2
Training loss: 0.9644110798835754
Validation loss: 2.0119784077008567

Epoch: 5| Step: 3
Training loss: 1.5870931148529053
Validation loss: 1.9690328687429428

Epoch: 5| Step: 4
Training loss: 1.1536693572998047
Validation loss: 1.9636033028364182

Epoch: 5| Step: 5
Training loss: 1.0221879482269287
Validation loss: 2.007895295818647

Epoch: 5| Step: 6
Training loss: 1.6909135580062866
Validation loss: 1.9708297948042552

Epoch: 5| Step: 7
Training loss: 1.032671570777893
Validation loss: 2.0632394403219223

Epoch: 5| Step: 8
Training loss: 0.9695967435836792
Validation loss: 2.077397406101227

Epoch: 5| Step: 9
Training loss: 1.4943666458129883
Validation loss: 2.1447015603383384

Epoch: 5| Step: 10
Training loss: 1.6758896112442017
Validation loss: 2.0626749396324158

Epoch: 5| Step: 11
Training loss: 1.4251093864440918
Validation loss: 2.073663204908371

Epoch: 132| Step: 0
Training loss: 1.4521774053573608
Validation loss: 2.0124591986338296

Epoch: 5| Step: 1
Training loss: 1.823904275894165
Validation loss: 2.069667547941208

Epoch: 5| Step: 2
Training loss: 1.5083502531051636
Validation loss: 2.0083006024360657

Epoch: 5| Step: 3
Training loss: 1.1964970827102661
Validation loss: 2.05266635119915

Epoch: 5| Step: 4
Training loss: 1.0044167041778564
Validation loss: 1.9953636576732

Epoch: 5| Step: 5
Training loss: 1.4285763502120972
Validation loss: 2.035309041539828

Epoch: 5| Step: 6
Training loss: 1.1335664987564087
Validation loss: 2.0045707523822784

Epoch: 5| Step: 7
Training loss: 1.1136647462844849
Validation loss: 1.980348880092303

Epoch: 5| Step: 8
Training loss: 1.1716690063476562
Validation loss: 2.0442977249622345

Epoch: 5| Step: 9
Training loss: 1.3951938152313232
Validation loss: 2.0482732405265174

Epoch: 5| Step: 10
Training loss: 1.1597769260406494
Validation loss: 2.053136716286341

Epoch: 5| Step: 11
Training loss: 0.3997807502746582
Validation loss: 2.047050952911377

Epoch: 133| Step: 0
Training loss: 1.1262671947479248
Validation loss: 2.0739993353684745

Epoch: 5| Step: 1
Training loss: 1.660361647605896
Validation loss: 2.1431040863196054

Epoch: 5| Step: 2
Training loss: 1.1992442607879639
Validation loss: 2.0970255533854165

Epoch: 5| Step: 3
Training loss: 1.498982310295105
Validation loss: 2.0631281286478043

Epoch: 5| Step: 4
Training loss: 1.3521314859390259
Validation loss: 2.0775332550207772

Epoch: 5| Step: 5
Training loss: 1.1510686874389648
Validation loss: 2.0672709196805954

Epoch: 5| Step: 6
Training loss: 1.3512486219406128
Validation loss: 2.0361773322025933

Epoch: 5| Step: 7
Training loss: 1.314084768295288
Validation loss: 1.9984631091356277

Epoch: 5| Step: 8
Training loss: 1.5856592655181885
Validation loss: 1.9687363902727764

Epoch: 5| Step: 9
Training loss: 1.2020771503448486
Validation loss: 2.018272881706556

Epoch: 5| Step: 10
Training loss: 1.3977009057998657
Validation loss: 1.9999681959549587

Epoch: 5| Step: 11
Training loss: 1.183020830154419
Validation loss: 1.9955731481313705

Epoch: 134| Step: 0
Training loss: 1.1298208236694336
Validation loss: 1.9869827926158905

Epoch: 5| Step: 1
Training loss: 1.417443037033081
Validation loss: 1.9928487092256546

Epoch: 5| Step: 2
Training loss: 1.242077112197876
Validation loss: 2.0451047321160636

Epoch: 5| Step: 3
Training loss: 0.9678727984428406
Validation loss: 2.0176977664232254

Epoch: 5| Step: 4
Training loss: 0.9092367887496948
Validation loss: 2.0350301613410315

Epoch: 5| Step: 5
Training loss: 1.5155584812164307
Validation loss: 2.0304655681053796

Epoch: 5| Step: 6
Training loss: 1.8733608722686768
Validation loss: 1.992290884256363

Epoch: 5| Step: 7
Training loss: 0.9574230909347534
Validation loss: 1.9938019265731175

Epoch: 5| Step: 8
Training loss: 0.8135966062545776
Validation loss: 2.020577311515808

Epoch: 5| Step: 9
Training loss: 1.3594582080841064
Validation loss: 1.9724636773268382

Epoch: 5| Step: 10
Training loss: 1.3188817501068115
Validation loss: 2.036931057771047

Epoch: 5| Step: 11
Training loss: 0.8229355812072754
Validation loss: 2.022771661480268

Epoch: 135| Step: 0
Training loss: 0.976087749004364
Validation loss: 1.9866000960270565

Epoch: 5| Step: 1
Training loss: 1.2422325611114502
Validation loss: 2.0284734467665353

Epoch: 5| Step: 2
Training loss: 1.275720238685608
Validation loss: 2.0441813319921494

Epoch: 5| Step: 3
Training loss: 1.4946775436401367
Validation loss: 2.078471581141154

Epoch: 5| Step: 4
Training loss: 0.9435914754867554
Validation loss: 2.0886355191469193

Epoch: 5| Step: 5
Training loss: 1.1446964740753174
Validation loss: 2.088375752170881

Epoch: 5| Step: 6
Training loss: 1.511127233505249
Validation loss: 1.991925170024236

Epoch: 5| Step: 7
Training loss: 1.1075938940048218
Validation loss: 2.044132928053538

Epoch: 5| Step: 8
Training loss: 1.50433349609375
Validation loss: 2.042042002081871

Epoch: 5| Step: 9
Training loss: 1.0598974227905273
Validation loss: 2.0019449989000955

Epoch: 5| Step: 10
Training loss: 1.6236693859100342
Validation loss: 1.991413911183675

Epoch: 5| Step: 11
Training loss: 1.167680263519287
Validation loss: 1.979661300778389

Epoch: 136| Step: 0
Training loss: 1.5363165140151978
Validation loss: 1.9946791132291157

Epoch: 5| Step: 1
Training loss: 1.3256016969680786
Validation loss: 1.971403991182645

Epoch: 5| Step: 2
Training loss: 1.0857799053192139
Validation loss: 1.9529555042584736

Epoch: 5| Step: 3
Training loss: 1.25812828540802
Validation loss: 2.03501757979393

Epoch: 5| Step: 4
Training loss: 1.471045732498169
Validation loss: 2.074943795800209

Epoch: 5| Step: 5
Training loss: 1.3239319324493408
Validation loss: 2.093964303533236

Epoch: 5| Step: 6
Training loss: 1.2510615587234497
Validation loss: 2.159109224875768

Epoch: 5| Step: 7
Training loss: 1.1985948085784912
Validation loss: 2.1598370571931205

Epoch: 5| Step: 8
Training loss: 1.810129165649414
Validation loss: 2.1023250023523965

Epoch: 5| Step: 9
Training loss: 0.8886648416519165
Validation loss: 2.0225496093432107

Epoch: 5| Step: 10
Training loss: 1.170539140701294
Validation loss: 1.960573469599088

Epoch: 5| Step: 11
Training loss: 1.3225338459014893
Validation loss: 1.977688878774643

Epoch: 137| Step: 0
Training loss: 1.4413319826126099
Validation loss: 2.033455083767573

Epoch: 5| Step: 1
Training loss: 1.3121178150177002
Validation loss: 1.9561610966920853

Epoch: 5| Step: 2
Training loss: 1.129713535308838
Validation loss: 1.9762954612572987

Epoch: 5| Step: 3
Training loss: 1.5054101943969727
Validation loss: 1.9842264354228973

Epoch: 5| Step: 4
Training loss: 1.3524014949798584
Validation loss: 2.062222490708033

Epoch: 5| Step: 5
Training loss: 1.4198254346847534
Validation loss: 2.077909683187803

Epoch: 5| Step: 6
Training loss: 1.6009352207183838
Validation loss: 2.0718222906192145

Epoch: 5| Step: 7
Training loss: 1.3902595043182373
Validation loss: 2.067477564016978

Epoch: 5| Step: 8
Training loss: 1.119490623474121
Validation loss: 2.058633337418238

Epoch: 5| Step: 9
Training loss: 1.044951319694519
Validation loss: 2.0140067686637244

Epoch: 5| Step: 10
Training loss: 1.0891778469085693
Validation loss: 2.011336326599121

Epoch: 5| Step: 11
Training loss: 1.0864934921264648
Validation loss: 1.992599442601204

Epoch: 138| Step: 0
Training loss: 1.5846734046936035
Validation loss: 1.9701314469178517

Epoch: 5| Step: 1
Training loss: 1.163246512413025
Validation loss: 1.99394690990448

Epoch: 5| Step: 2
Training loss: 1.0464147329330444
Validation loss: 2.004398768146833

Epoch: 5| Step: 3
Training loss: 1.5125304460525513
Validation loss: 1.981939027706782

Epoch: 5| Step: 4
Training loss: 1.088148832321167
Validation loss: 2.0439089785019555

Epoch: 5| Step: 5
Training loss: 1.2647682428359985
Validation loss: 2.0513840119043985

Epoch: 5| Step: 6
Training loss: 0.9932816624641418
Validation loss: 2.071150705218315

Epoch: 5| Step: 7
Training loss: 1.655838966369629
Validation loss: 2.0859403759241104

Epoch: 5| Step: 8
Training loss: 0.6997637152671814
Validation loss: 2.0931645035743713

Epoch: 5| Step: 9
Training loss: 1.2274125814437866
Validation loss: 2.0776467472314835

Epoch: 5| Step: 10
Training loss: 1.2165441513061523
Validation loss: 2.076993852853775

Epoch: 5| Step: 11
Training loss: 1.6995365619659424
Validation loss: 2.0531444201866784

Epoch: 139| Step: 0
Training loss: 1.3141001462936401
Validation loss: 2.0216564933458963

Epoch: 5| Step: 1
Training loss: 0.8325067758560181
Validation loss: 2.095037211974462

Epoch: 5| Step: 2
Training loss: 1.3409850597381592
Validation loss: 2.0226538131634393

Epoch: 5| Step: 3
Training loss: 1.1984455585479736
Validation loss: 2.056577836473783

Epoch: 5| Step: 4
Training loss: 0.9690195322036743
Validation loss: 2.0087303618590036

Epoch: 5| Step: 5
Training loss: 1.3145225048065186
Validation loss: 1.952937016884486

Epoch: 5| Step: 6
Training loss: 1.4960194826126099
Validation loss: 2.0538727591435113

Epoch: 5| Step: 7
Training loss: 1.32172691822052
Validation loss: 1.9899982213974

Epoch: 5| Step: 8
Training loss: 0.7283837199211121
Validation loss: 1.9895244340101879

Epoch: 5| Step: 9
Training loss: 1.5683934688568115
Validation loss: 1.9748263557751973

Epoch: 5| Step: 10
Training loss: 1.5048766136169434
Validation loss: 2.0034932047128677

Epoch: 5| Step: 11
Training loss: 0.4350461959838867
Validation loss: 2.1075819532076516

Epoch: 140| Step: 0
Training loss: 1.0772931575775146
Validation loss: 2.024840439359347

Epoch: 5| Step: 1
Training loss: 0.915574848651886
Validation loss: 2.0060336540142694

Epoch: 5| Step: 2
Training loss: 0.8224496841430664
Validation loss: 2.0651226888100305

Epoch: 5| Step: 3
Training loss: 1.3454289436340332
Validation loss: 1.916238049666087

Epoch: 5| Step: 4
Training loss: 1.1708701848983765
Validation loss: 1.9833476096391678

Epoch: 5| Step: 5
Training loss: 1.3733675479888916
Validation loss: 1.980419213573138

Epoch: 5| Step: 6
Training loss: 1.4039613008499146
Validation loss: 1.9780284613370895

Epoch: 5| Step: 7
Training loss: 1.1483371257781982
Validation loss: 1.9729662736256917

Epoch: 5| Step: 8
Training loss: 1.2487399578094482
Validation loss: 1.997015838821729

Epoch: 5| Step: 9
Training loss: 1.3518422842025757
Validation loss: 2.0038350174824395

Epoch: 5| Step: 10
Training loss: 1.0016229152679443
Validation loss: 1.9856027513742447

Epoch: 5| Step: 11
Training loss: 2.2963051795959473
Validation loss: 2.0550907452901206

Epoch: 141| Step: 0
Training loss: 1.3367458581924438
Validation loss: 1.9854744225740433

Epoch: 5| Step: 1
Training loss: 0.8612391352653503
Validation loss: 2.0321221550305686

Epoch: 5| Step: 2
Training loss: 1.122362494468689
Validation loss: 2.0057148983081183

Epoch: 5| Step: 3
Training loss: 1.0174063444137573
Validation loss: 1.9892038156588872

Epoch: 5| Step: 4
Training loss: 1.5232547521591187
Validation loss: 2.0043270140886307

Epoch: 5| Step: 5
Training loss: 1.1853963136672974
Validation loss: 2.0255897492170334

Epoch: 5| Step: 6
Training loss: 0.7711742520332336
Validation loss: 1.9917820543050766

Epoch: 5| Step: 7
Training loss: 1.4091298580169678
Validation loss: 1.9882656981547673

Epoch: 5| Step: 8
Training loss: 1.1298723220825195
Validation loss: 1.9953923722108204

Epoch: 5| Step: 9
Training loss: 1.202667474746704
Validation loss: 2.0522815535465875

Epoch: 5| Step: 10
Training loss: 1.7914901971817017
Validation loss: 2.0279030005137124

Epoch: 5| Step: 11
Training loss: 0.3899356722831726
Validation loss: 2.0354556938012442

Epoch: 142| Step: 0
Training loss: 1.2534904479980469
Validation loss: 1.9721867392460506

Epoch: 5| Step: 1
Training loss: 1.2136155366897583
Validation loss: 2.0171416203180947

Epoch: 5| Step: 2
Training loss: 1.1120905876159668
Validation loss: 1.988237664103508

Epoch: 5| Step: 3
Training loss: 1.902889609336853
Validation loss: 2.0052183816830316

Epoch: 5| Step: 4
Training loss: 1.4218624830245972
Validation loss: 2.001708507537842

Epoch: 5| Step: 5
Training loss: 0.7492860555648804
Validation loss: 1.9732142289479573

Epoch: 5| Step: 6
Training loss: 1.4153339862823486
Validation loss: 1.98796113828818

Epoch: 5| Step: 7
Training loss: 0.8750187158584595
Validation loss: 1.9939338564872742

Epoch: 5| Step: 8
Training loss: 1.1858681440353394
Validation loss: 1.9972134083509445

Epoch: 5| Step: 9
Training loss: 0.7074388265609741
Validation loss: 2.044069225589434

Epoch: 5| Step: 10
Training loss: 1.1237298250198364
Validation loss: 2.070555085937182

Epoch: 5| Step: 11
Training loss: 0.6719823479652405
Validation loss: 2.009405622879664

Epoch: 143| Step: 0
Training loss: 1.1529968976974487
Validation loss: 1.9675990094741185

Epoch: 5| Step: 1
Training loss: 1.0388636589050293
Validation loss: 1.9806978454192479

Epoch: 5| Step: 2
Training loss: 1.9185212850570679
Validation loss: 1.9394769916931789

Epoch: 5| Step: 3
Training loss: 0.9732866287231445
Validation loss: 1.9546271959940593

Epoch: 5| Step: 4
Training loss: 1.1676130294799805
Validation loss: 1.980296179652214

Epoch: 5| Step: 5
Training loss: 0.554409384727478
Validation loss: 2.054101417462031

Epoch: 5| Step: 6
Training loss: 0.7938799858093262
Validation loss: 2.0518142879009247

Epoch: 5| Step: 7
Training loss: 1.3601818084716797
Validation loss: 2.0321363310019174

Epoch: 5| Step: 8
Training loss: 1.713616967201233
Validation loss: 2.101185272137324

Epoch: 5| Step: 9
Training loss: 1.5187276601791382
Validation loss: 2.092663417259852

Epoch: 5| Step: 10
Training loss: 1.122926115989685
Validation loss: 2.044091612100601

Epoch: 5| Step: 11
Training loss: 1.3448493480682373
Validation loss: 1.9683367659648259

Epoch: 144| Step: 0
Training loss: 0.9323621988296509
Validation loss: 1.9680475791295369

Epoch: 5| Step: 1
Training loss: 1.4773666858673096
Validation loss: 1.9490657796462376

Epoch: 5| Step: 2
Training loss: 1.2200847864151
Validation loss: 1.9641485859950383

Epoch: 5| Step: 3
Training loss: 1.7441002130508423
Validation loss: 1.9452911416689556

Epoch: 5| Step: 4
Training loss: 1.2575898170471191
Validation loss: 1.95399076739947

Epoch: 5| Step: 5
Training loss: 1.1842901706695557
Validation loss: 1.9967904289563496

Epoch: 5| Step: 6
Training loss: 1.290343999862671
Validation loss: 2.0542978197336197

Epoch: 5| Step: 7
Training loss: 1.0987741947174072
Validation loss: 2.0040131409962973

Epoch: 5| Step: 8
Training loss: 0.9321929812431335
Validation loss: 2.0779858926932016

Epoch: 5| Step: 9
Training loss: 1.1733729839324951
Validation loss: 2.024179145693779

Epoch: 5| Step: 10
Training loss: 1.223474144935608
Validation loss: 2.000390683611234

Epoch: 5| Step: 11
Training loss: 1.2803462743759155
Validation loss: 2.026218136151632

Epoch: 145| Step: 0
Training loss: 1.129336953163147
Validation loss: 1.9734237392743428

Epoch: 5| Step: 1
Training loss: 0.7492021322250366
Validation loss: 2.006567060947418

Epoch: 5| Step: 2
Training loss: 1.2206215858459473
Validation loss: 1.977892905473709

Epoch: 5| Step: 3
Training loss: 0.5702130198478699
Validation loss: 2.008386194705963

Epoch: 5| Step: 4
Training loss: 1.0626128911972046
Validation loss: 1.9453174024820328

Epoch: 5| Step: 5
Training loss: 1.0175899267196655
Validation loss: 2.0093282759189606

Epoch: 5| Step: 6
Training loss: 1.543353796005249
Validation loss: 1.956851288676262

Epoch: 5| Step: 7
Training loss: 1.7377179861068726
Validation loss: 1.9502832094828289

Epoch: 5| Step: 8
Training loss: 0.997715950012207
Validation loss: 1.9923777729272842

Epoch: 5| Step: 9
Training loss: 1.1219520568847656
Validation loss: 2.000649938980738

Epoch: 5| Step: 10
Training loss: 1.3753926753997803
Validation loss: 2.016843164960543

Epoch: 5| Step: 11
Training loss: 0.6795777082443237
Validation loss: 2.042557790875435

Epoch: 146| Step: 0
Training loss: 0.8496246337890625
Validation loss: 2.0074447095394135

Epoch: 5| Step: 1
Training loss: 0.8874505758285522
Validation loss: 2.034173235297203

Epoch: 5| Step: 2
Training loss: 1.371368646621704
Validation loss: 2.026668762167295

Epoch: 5| Step: 3
Training loss: 1.2539710998535156
Validation loss: 2.031171977519989

Epoch: 5| Step: 4
Training loss: 1.1460684537887573
Validation loss: 2.0328484624624252

Epoch: 5| Step: 5
Training loss: 1.153789758682251
Validation loss: 1.9914024025201797

Epoch: 5| Step: 6
Training loss: 0.6828335523605347
Validation loss: 1.9920379370450974

Epoch: 5| Step: 7
Training loss: 1.512633204460144
Validation loss: 1.9970065752665203

Epoch: 5| Step: 8
Training loss: 1.208160400390625
Validation loss: 1.9754542410373688

Epoch: 5| Step: 9
Training loss: 1.1424720287322998
Validation loss: 1.9629762371381123

Epoch: 5| Step: 10
Training loss: 1.5229110717773438
Validation loss: 1.9032101929187775

Epoch: 5| Step: 11
Training loss: 0.2644825279712677
Validation loss: 1.9673805733521779

Epoch: 147| Step: 0
Training loss: 1.8631761074066162
Validation loss: 1.990972101688385

Epoch: 5| Step: 1
Training loss: 0.934831976890564
Validation loss: 1.9899211873610814

Epoch: 5| Step: 2
Training loss: 0.7519871592521667
Validation loss: 2.0245046565930047

Epoch: 5| Step: 3
Training loss: 1.1741708517074585
Validation loss: 2.0329301804304123

Epoch: 5| Step: 4
Training loss: 1.150894284248352
Validation loss: 2.012071301539739

Epoch: 5| Step: 5
Training loss: 0.6412359476089478
Validation loss: 2.011180485288302

Epoch: 5| Step: 6
Training loss: 1.0983643531799316
Validation loss: 1.9966166416803997

Epoch: 5| Step: 7
Training loss: 1.1664676666259766
Validation loss: 2.050661727786064

Epoch: 5| Step: 8
Training loss: 0.8806193470954895
Validation loss: 2.0388140926758447

Epoch: 5| Step: 9
Training loss: 1.3141353130340576
Validation loss: 2.0307237108548484

Epoch: 5| Step: 10
Training loss: 0.9134283065795898
Validation loss: 2.0576655864715576

Epoch: 5| Step: 11
Training loss: 2.8733344078063965
Validation loss: 2.073707635203997

Epoch: 148| Step: 0
Training loss: 0.8201607465744019
Validation loss: 1.999857172369957

Epoch: 5| Step: 1
Training loss: 1.2963980436325073
Validation loss: 1.9871130138635635

Epoch: 5| Step: 2
Training loss: 1.5523064136505127
Validation loss: 2.022838478287061

Epoch: 5| Step: 3
Training loss: 0.9362872242927551
Validation loss: 1.9939439346392949

Epoch: 5| Step: 4
Training loss: 1.3797051906585693
Validation loss: 1.9909486869970958

Epoch: 5| Step: 5
Training loss: 1.0258890390396118
Validation loss: 1.9742228388786316

Epoch: 5| Step: 6
Training loss: 0.8617292642593384
Validation loss: 1.978864073753357

Epoch: 5| Step: 7
Training loss: 1.1348743438720703
Validation loss: 2.030090630054474

Epoch: 5| Step: 8
Training loss: 0.5698950886726379
Validation loss: 1.9308555920918782

Epoch: 5| Step: 9
Training loss: 1.140379786491394
Validation loss: 1.9765576322873433

Epoch: 5| Step: 10
Training loss: 1.2299511432647705
Validation loss: 2.0002924601236978

Epoch: 5| Step: 11
Training loss: 0.20344185829162598
Validation loss: 1.9865724245707195

Epoch: 149| Step: 0
Training loss: 1.1426299810409546
Validation loss: 1.9545754194259644

Epoch: 5| Step: 1
Training loss: 1.3192729949951172
Validation loss: 2.0230192840099335

Epoch: 5| Step: 2
Training loss: 0.8070084452629089
Validation loss: 2.0025851925214133

Epoch: 5| Step: 3
Training loss: 1.075899362564087
Validation loss: 1.9629889527956645

Epoch: 5| Step: 4
Training loss: 0.9330496788024902
Validation loss: 2.052181432644526

Epoch: 5| Step: 5
Training loss: 1.0085980892181396
Validation loss: 2.0536262840032578

Epoch: 5| Step: 6
Training loss: 0.9203870892524719
Validation loss: 2.0180992484092712

Epoch: 5| Step: 7
Training loss: 1.1990457773208618
Validation loss: 2.062365710735321

Epoch: 5| Step: 8
Training loss: 0.9624153971672058
Validation loss: 2.016177083055178

Epoch: 5| Step: 9
Training loss: 1.402315378189087
Validation loss: 1.9540842771530151

Epoch: 5| Step: 10
Training loss: 0.8711096048355103
Validation loss: 2.0411491791407266

Epoch: 5| Step: 11
Training loss: 1.0557634830474854
Validation loss: 2.020850951472918

Epoch: 150| Step: 0
Training loss: 1.0561968088150024
Validation loss: 1.9592109322547913

Epoch: 5| Step: 1
Training loss: 0.7692300081253052
Validation loss: 1.9487511018911998

Epoch: 5| Step: 2
Training loss: 0.799939751625061
Validation loss: 2.0110711057980857

Epoch: 5| Step: 3
Training loss: 0.7971727252006531
Validation loss: 2.0369613269964852

Epoch: 5| Step: 4
Training loss: 1.0491936206817627
Validation loss: 2.015391473968824

Epoch: 5| Step: 5
Training loss: 1.2769490480422974
Validation loss: 2.0508021116256714

Epoch: 5| Step: 6
Training loss: 1.351388692855835
Validation loss: 2.0420434325933456

Epoch: 5| Step: 7
Training loss: 1.209052324295044
Validation loss: 2.0395208994547525

Epoch: 5| Step: 8
Training loss: 0.7677541971206665
Validation loss: 2.0323381423950195

Epoch: 5| Step: 9
Training loss: 1.6177898645401
Validation loss: 1.9634546389182408

Epoch: 5| Step: 10
Training loss: 1.3626340627670288
Validation loss: 2.002217943469683

Epoch: 5| Step: 11
Training loss: 0.17504417896270752
Validation loss: 1.979149490594864

Epoch: 151| Step: 0
Training loss: 0.6718970537185669
Validation loss: 1.9879184812307358

Epoch: 5| Step: 1
Training loss: 0.8480637669563293
Validation loss: 1.9733255902926128

Epoch: 5| Step: 2
Training loss: 1.206658124923706
Validation loss: 2.0348022182782493

Epoch: 5| Step: 3
Training loss: 1.0091705322265625
Validation loss: 2.0065977623065314

Epoch: 5| Step: 4
Training loss: 1.104310393333435
Validation loss: 1.984554335474968

Epoch: 5| Step: 5
Training loss: 1.203731656074524
Validation loss: 2.046193396051725

Epoch: 5| Step: 6
Training loss: 0.7570953369140625
Validation loss: 2.0241591334342957

Epoch: 5| Step: 7
Training loss: 0.5046103000640869
Validation loss: 2.042673553029696

Epoch: 5| Step: 8
Training loss: 1.340917944908142
Validation loss: 1.9966635306676228

Epoch: 5| Step: 9
Training loss: 1.6167856454849243
Validation loss: 2.0107938845952353

Epoch: 5| Step: 10
Training loss: 1.8140227794647217
Validation loss: 1.9694515566031139

Epoch: 5| Step: 11
Training loss: 0.8377617001533508
Validation loss: 2.0231622060139975

Epoch: 152| Step: 0
Training loss: 0.9289304614067078
Validation loss: 1.9852250119050343

Epoch: 5| Step: 1
Training loss: 1.5770362615585327
Validation loss: 2.012380619843801

Epoch: 5| Step: 2
Training loss: 0.8636182546615601
Validation loss: 2.0180011292298636

Epoch: 5| Step: 3
Training loss: 1.535300612449646
Validation loss: 1.977073887983958

Epoch: 5| Step: 4
Training loss: 1.20723557472229
Validation loss: 1.9045859227577846

Epoch: 5| Step: 5
Training loss: 0.7665547132492065
Validation loss: 1.9305474311113358

Epoch: 5| Step: 6
Training loss: 1.579505205154419
Validation loss: 1.9940675248702366

Epoch: 5| Step: 7
Training loss: 0.8484493494033813
Validation loss: 2.0651559929052987

Epoch: 5| Step: 8
Training loss: 0.966377854347229
Validation loss: 2.037743111451467

Epoch: 5| Step: 9
Training loss: 1.0009698867797852
Validation loss: 2.130124414960543

Epoch: 5| Step: 10
Training loss: 0.8627828359603882
Validation loss: 2.0577320903539658

Epoch: 5| Step: 11
Training loss: 1.4694674015045166
Validation loss: 1.9705527623494465

Epoch: 153| Step: 0
Training loss: 0.8283443450927734
Validation loss: 1.991020565231641

Epoch: 5| Step: 1
Training loss: 1.1094377040863037
Validation loss: 2.002191041906675

Epoch: 5| Step: 2
Training loss: 1.1425552368164062
Validation loss: 1.9812291612227757

Epoch: 5| Step: 3
Training loss: 1.273499608039856
Validation loss: 1.988052214185397

Epoch: 5| Step: 4
Training loss: 0.6815924644470215
Validation loss: 1.9935840715964634

Epoch: 5| Step: 5
Training loss: 1.1175401210784912
Validation loss: 1.980337033669154

Epoch: 5| Step: 6
Training loss: 1.2623155117034912
Validation loss: 2.037872761487961

Epoch: 5| Step: 7
Training loss: 0.7665889859199524
Validation loss: 2.0592634032169976

Epoch: 5| Step: 8
Training loss: 0.8777809143066406
Validation loss: 1.9999621113141377

Epoch: 5| Step: 9
Training loss: 1.476496696472168
Validation loss: 1.9942419628302257

Epoch: 5| Step: 10
Training loss: 1.2098863124847412
Validation loss: 2.0231288969516754

Epoch: 5| Step: 11
Training loss: 0.6993046402931213
Validation loss: 1.9806567678848903

Epoch: 154| Step: 0
Training loss: 1.374276876449585
Validation loss: 1.9381288290023804

Epoch: 5| Step: 1
Training loss: 1.3834936618804932
Validation loss: 1.9555987566709518

Epoch: 5| Step: 2
Training loss: 0.6798356771469116
Validation loss: 1.9829910943905513

Epoch: 5| Step: 3
Training loss: 1.1326279640197754
Validation loss: 1.9768427362044652

Epoch: 5| Step: 4
Training loss: 0.8260136842727661
Validation loss: 1.9466227491696675

Epoch: 5| Step: 5
Training loss: 0.8145925402641296
Validation loss: 1.9729748616615932

Epoch: 5| Step: 6
Training loss: 0.756606936454773
Validation loss: 1.9981474826733272

Epoch: 5| Step: 7
Training loss: 1.088107705116272
Validation loss: 2.0630990167458854

Epoch: 5| Step: 8
Training loss: 1.4102084636688232
Validation loss: 2.080689643820127

Epoch: 5| Step: 9
Training loss: 0.8405311703681946
Validation loss: 2.060795689622561

Epoch: 5| Step: 10
Training loss: 1.3082947731018066
Validation loss: 2.0689527789751687

Epoch: 5| Step: 11
Training loss: 1.6614134311676025
Validation loss: 2.0282981594403586

Epoch: 155| Step: 0
Training loss: 1.3167378902435303
Validation loss: 2.0058577011028924

Epoch: 5| Step: 1
Training loss: 0.9586466550827026
Validation loss: 1.9746720641851425

Epoch: 5| Step: 2
Training loss: 1.2587664127349854
Validation loss: 2.075012614329656

Epoch: 5| Step: 3
Training loss: 1.0540874004364014
Validation loss: 2.0199594448010125

Epoch: 5| Step: 4
Training loss: 1.1323740482330322
Validation loss: 1.992148905992508

Epoch: 5| Step: 5
Training loss: 1.0542876720428467
Validation loss: 2.0348241726557412

Epoch: 5| Step: 6
Training loss: 0.7525831460952759
Validation loss: 1.9240635633468628

Epoch: 5| Step: 7
Training loss: 1.1933135986328125
Validation loss: 1.9731461703777313

Epoch: 5| Step: 8
Training loss: 0.6989443302154541
Validation loss: 1.974694495399793

Epoch: 5| Step: 9
Training loss: 0.8348320722579956
Validation loss: 1.9403320501248043

Epoch: 5| Step: 10
Training loss: 1.1487271785736084
Validation loss: 1.9702390034993489

Epoch: 5| Step: 11
Training loss: 0.19299232959747314
Validation loss: 1.9614380151033401

Epoch: 156| Step: 0
Training loss: 1.0794020891189575
Validation loss: 1.9684678117434184

Epoch: 5| Step: 1
Training loss: 0.8294973373413086
Validation loss: 1.9918266832828522

Epoch: 5| Step: 2
Training loss: 1.1948317289352417
Validation loss: 1.943680117527644

Epoch: 5| Step: 3
Training loss: 0.9376956820487976
Validation loss: 1.9684363057216008

Epoch: 5| Step: 4
Training loss: 0.7174845933914185
Validation loss: 1.969723512729009

Epoch: 5| Step: 5
Training loss: 0.8746616244316101
Validation loss: 2.00854899485906

Epoch: 5| Step: 6
Training loss: 1.2798734903335571
Validation loss: 1.9943030973275502

Epoch: 5| Step: 7
Training loss: 1.2611470222473145
Validation loss: 2.0115326096614203

Epoch: 5| Step: 8
Training loss: 0.9549857378005981
Validation loss: 2.0117422292629876

Epoch: 5| Step: 9
Training loss: 1.4705528020858765
Validation loss: 1.991986667116483

Epoch: 5| Step: 10
Training loss: 1.1040595769882202
Validation loss: 1.9877135455608368

Epoch: 5| Step: 11
Training loss: 0.9144012928009033
Validation loss: 1.9213280429442723

Epoch: 157| Step: 0
Training loss: 0.7926616072654724
Validation loss: 1.9847105493148167

Epoch: 5| Step: 1
Training loss: 0.9912005662918091
Validation loss: 1.9597028891245525

Epoch: 5| Step: 2
Training loss: 1.0116045475006104
Validation loss: 1.9660572161277134

Epoch: 5| Step: 3
Training loss: 1.0507011413574219
Validation loss: 1.999753013253212

Epoch: 5| Step: 4
Training loss: 0.9396478533744812
Validation loss: 2.037389720479647

Epoch: 5| Step: 5
Training loss: 1.0536019802093506
Validation loss: 1.9829879154761632

Epoch: 5| Step: 6
Training loss: 0.8906224370002747
Validation loss: 1.9851709355910618

Epoch: 5| Step: 7
Training loss: 1.0825315713882446
Validation loss: 1.9635072698195775

Epoch: 5| Step: 8
Training loss: 1.1579818725585938
Validation loss: 1.9422730406125386

Epoch: 5| Step: 9
Training loss: 0.9105329513549805
Validation loss: 1.9699872980515163

Epoch: 5| Step: 10
Training loss: 1.3266149759292603
Validation loss: 1.9437832484642665

Epoch: 5| Step: 11
Training loss: 0.32783615589141846
Validation loss: 1.9606173932552338

Epoch: 158| Step: 0
Training loss: 1.5239737033843994
Validation loss: 1.9953993012507756

Epoch: 5| Step: 1
Training loss: 0.7221897840499878
Validation loss: 2.056022306283315

Epoch: 5| Step: 2
Training loss: 1.0048983097076416
Validation loss: 2.1115882396698

Epoch: 5| Step: 3
Training loss: 0.701246440410614
Validation loss: 2.0378179599841437

Epoch: 5| Step: 4
Training loss: 0.8912340998649597
Validation loss: 1.9696021775404613

Epoch: 5| Step: 5
Training loss: 0.9271485209465027
Validation loss: 1.9786414355039597

Epoch: 5| Step: 6
Training loss: 1.3545747995376587
Validation loss: 1.9751966098944347

Epoch: 5| Step: 7
Training loss: 0.9007077217102051
Validation loss: 1.9150664607683818

Epoch: 5| Step: 8
Training loss: 1.339601755142212
Validation loss: 1.9461563378572464

Epoch: 5| Step: 9
Training loss: 0.7221361398696899
Validation loss: 1.9513852149248123

Epoch: 5| Step: 10
Training loss: 1.223955750465393
Validation loss: 1.9341882020235062

Epoch: 5| Step: 11
Training loss: 0.5608745813369751
Validation loss: 1.9739309400320053

Epoch: 159| Step: 0
Training loss: 1.0347785949707031
Validation loss: 1.9811709721883137

Epoch: 5| Step: 1
Training loss: 1.2042194604873657
Validation loss: 2.0530464301506677

Epoch: 5| Step: 2
Training loss: 1.5184988975524902
Validation loss: 1.9951616028944652

Epoch: 5| Step: 3
Training loss: 1.4880883693695068
Validation loss: 2.004869138201078

Epoch: 5| Step: 4
Training loss: 0.8271322250366211
Validation loss: 2.034790193041166

Epoch: 5| Step: 5
Training loss: 0.7022322416305542
Validation loss: 2.0355938176314035

Epoch: 5| Step: 6
Training loss: 1.0328733921051025
Validation loss: 1.9743207941452663

Epoch: 5| Step: 7
Training loss: 0.7599935531616211
Validation loss: 1.9877654314041138

Epoch: 5| Step: 8
Training loss: 0.8517223596572876
Validation loss: 1.9723677436510723

Epoch: 5| Step: 9
Training loss: 0.6983240246772766
Validation loss: 2.017714316646258

Epoch: 5| Step: 10
Training loss: 1.0675747394561768
Validation loss: 1.985295131802559

Epoch: 5| Step: 11
Training loss: 0.31975221633911133
Validation loss: 1.9901430706183116

Epoch: 160| Step: 0
Training loss: 0.7374497652053833
Validation loss: 1.9594070116678874

Epoch: 5| Step: 1
Training loss: 0.9103104472160339
Validation loss: 1.9772899995247524

Epoch: 5| Step: 2
Training loss: 0.8300491571426392
Validation loss: 1.9578627049922943

Epoch: 5| Step: 3
Training loss: 1.203346848487854
Validation loss: 2.0248987625042596

Epoch: 5| Step: 4
Training loss: 1.0767405033111572
Validation loss: 1.9987782488266628

Epoch: 5| Step: 5
Training loss: 0.4638862609863281
Validation loss: 2.0504446576038995

Epoch: 5| Step: 6
Training loss: 1.4060062170028687
Validation loss: 1.952951083580653

Epoch: 5| Step: 7
Training loss: 0.9000339508056641
Validation loss: 1.977077270547549

Epoch: 5| Step: 8
Training loss: 0.9005217552185059
Validation loss: 2.008288934826851

Epoch: 5| Step: 9
Training loss: 0.8553935885429382
Validation loss: 2.0077582001686096

Epoch: 5| Step: 10
Training loss: 1.2322120666503906
Validation loss: 2.0125921219587326

Epoch: 5| Step: 11
Training loss: 1.1554632186889648
Validation loss: 2.0190541446208954

Epoch: 161| Step: 0
Training loss: 0.6170138120651245
Validation loss: 1.999620462457339

Epoch: 5| Step: 1
Training loss: 0.9458044171333313
Validation loss: 2.071648816267649

Epoch: 5| Step: 2
Training loss: 0.9712265729904175
Validation loss: 2.028752699494362

Epoch: 5| Step: 3
Training loss: 0.8542672991752625
Validation loss: 2.010875607530276

Epoch: 5| Step: 4
Training loss: 1.0434539318084717
Validation loss: 1.9883357187112172

Epoch: 5| Step: 5
Training loss: 1.3262900114059448
Validation loss: 2.0600225230058036

Epoch: 5| Step: 6
Training loss: 0.8326475024223328
Validation loss: 2.1088753839333854

Epoch: 5| Step: 7
Training loss: 1.3943876028060913
Validation loss: 1.982980767885844

Epoch: 5| Step: 8
Training loss: 0.911847710609436
Validation loss: 1.969266985853513

Epoch: 5| Step: 9
Training loss: 1.2383396625518799
Validation loss: 1.9983069399992626

Epoch: 5| Step: 10
Training loss: 0.6384040117263794
Validation loss: 1.938680316011111

Epoch: 5| Step: 11
Training loss: 1.7058968544006348
Validation loss: 1.975773498415947

Epoch: 162| Step: 0
Training loss: 1.0540316104888916
Validation loss: 1.953510935107867

Epoch: 5| Step: 1
Training loss: 1.304517388343811
Validation loss: 1.9837441543738048

Epoch: 5| Step: 2
Training loss: 1.1313636302947998
Validation loss: 1.9513981640338898

Epoch: 5| Step: 3
Training loss: 1.0446827411651611
Validation loss: 1.9618793576955795

Epoch: 5| Step: 4
Training loss: 0.9694938659667969
Validation loss: 1.9693559209505718

Epoch: 5| Step: 5
Training loss: 0.648145318031311
Validation loss: 2.0484299709399543

Epoch: 5| Step: 6
Training loss: 1.0768030881881714
Validation loss: 1.9628215084473293

Epoch: 5| Step: 7
Training loss: 1.1911464929580688
Validation loss: 2.015437424182892

Epoch: 5| Step: 8
Training loss: 0.6096652746200562
Validation loss: 1.982980991403262

Epoch: 5| Step: 9
Training loss: 0.7691344022750854
Validation loss: 2.0295516550540924

Epoch: 5| Step: 10
Training loss: 0.7661336660385132
Validation loss: 1.98709640900294

Epoch: 5| Step: 11
Training loss: 1.9884388446807861
Validation loss: 2.002139136195183

Epoch: 163| Step: 0
Training loss: 0.908414363861084
Validation loss: 1.992539534966151

Epoch: 5| Step: 1
Training loss: 0.7798006534576416
Validation loss: 1.9852519035339355

Epoch: 5| Step: 2
Training loss: 0.8177149891853333
Validation loss: 1.984036386013031

Epoch: 5| Step: 3
Training loss: 1.0917530059814453
Validation loss: 2.0342509150505066

Epoch: 5| Step: 4
Training loss: 1.0693905353546143
Validation loss: 1.996085653702418

Epoch: 5| Step: 5
Training loss: 1.0521538257598877
Validation loss: 1.9874722758928935

Epoch: 5| Step: 6
Training loss: 0.9770454168319702
Validation loss: 1.9594328701496124

Epoch: 5| Step: 7
Training loss: 1.1083738803863525
Validation loss: 1.9543921152750652

Epoch: 5| Step: 8
Training loss: 0.7036911845207214
Validation loss: 1.9710838546355565

Epoch: 5| Step: 9
Training loss: 0.9939888715744019
Validation loss: 1.9018363704284031

Epoch: 5| Step: 10
Training loss: 1.358457326889038
Validation loss: 1.9774733781814575

Epoch: 5| Step: 11
Training loss: 0.3873410224914551
Validation loss: 1.9959380676349003

Epoch: 164| Step: 0
Training loss: 0.7994698882102966
Validation loss: 1.9880645126104355

Epoch: 5| Step: 1
Training loss: 0.9863272905349731
Validation loss: 2.047140210866928

Epoch: 5| Step: 2
Training loss: 0.8208521008491516
Validation loss: 1.9736839632193248

Epoch: 5| Step: 3
Training loss: 0.506592869758606
Validation loss: 1.9613808343807857

Epoch: 5| Step: 4
Training loss: 1.5473779439926147
Validation loss: 1.964007392525673

Epoch: 5| Step: 5
Training loss: 0.7451488375663757
Validation loss: 2.0197801689306893

Epoch: 5| Step: 6
Training loss: 1.0087718963623047
Validation loss: 2.007601877053579

Epoch: 5| Step: 7
Training loss: 0.9659913778305054
Validation loss: 2.012619932492574

Epoch: 5| Step: 8
Training loss: 0.8021280169487
Validation loss: 1.9249551792939503

Epoch: 5| Step: 9
Training loss: 1.2208796739578247
Validation loss: 1.9609542588392894

Epoch: 5| Step: 10
Training loss: 0.9675043821334839
Validation loss: 1.9868491391340892

Epoch: 5| Step: 11
Training loss: 1.8098759651184082
Validation loss: 1.9974259038766224

Epoch: 165| Step: 0
Training loss: 0.5690141916275024
Validation loss: 1.9550798386335373

Epoch: 5| Step: 1
Training loss: 0.9522746205329895
Validation loss: 1.940075397491455

Epoch: 5| Step: 2
Training loss: 0.7796599268913269
Validation loss: 1.9101053526004155

Epoch: 5| Step: 3
Training loss: 0.5713289976119995
Validation loss: 1.9966581364472706

Epoch: 5| Step: 4
Training loss: 1.0900661945343018
Validation loss: 1.922573318084081

Epoch: 5| Step: 5
Training loss: 1.2031774520874023
Validation loss: 1.9043409725030263

Epoch: 5| Step: 6
Training loss: 1.6017357110977173
Validation loss: 1.9755341062943141

Epoch: 5| Step: 7
Training loss: 0.7843323945999146
Validation loss: 2.017010733485222

Epoch: 5| Step: 8
Training loss: 0.8314558267593384
Validation loss: 1.955096145470937

Epoch: 5| Step: 9
Training loss: 0.7871819138526917
Validation loss: 1.991397847731908

Epoch: 5| Step: 10
Training loss: 1.453011393547058
Validation loss: 1.9791872998078663

Epoch: 5| Step: 11
Training loss: 0.3333078622817993
Validation loss: 1.9903046290079753

Epoch: 166| Step: 0
Training loss: 1.1602798700332642
Validation loss: 1.9745062788327534

Epoch: 5| Step: 1
Training loss: 0.7529749870300293
Validation loss: 1.948911041021347

Epoch: 5| Step: 2
Training loss: 0.9848780632019043
Validation loss: 2.011187896132469

Epoch: 5| Step: 3
Training loss: 0.6682264804840088
Validation loss: 2.013926327228546

Epoch: 5| Step: 4
Training loss: 0.8272686004638672
Validation loss: 2.038754567503929

Epoch: 5| Step: 5
Training loss: 0.8161624670028687
Validation loss: 1.9712602645158768

Epoch: 5| Step: 6
Training loss: 0.9739131927490234
Validation loss: 1.9250993480285008

Epoch: 5| Step: 7
Training loss: 0.8987061381340027
Validation loss: 1.9860643595457077

Epoch: 5| Step: 8
Training loss: 1.2351901531219482
Validation loss: 1.9942710449298222

Epoch: 5| Step: 9
Training loss: 1.0251922607421875
Validation loss: 1.9567588567733765

Epoch: 5| Step: 10
Training loss: 0.9097675085067749
Validation loss: 1.951766570409139

Epoch: 5| Step: 11
Training loss: 1.1512575149536133
Validation loss: 1.9584926913181941

Epoch: 167| Step: 0
Training loss: 0.4223853647708893
Validation loss: 2.0089438209931054

Epoch: 5| Step: 1
Training loss: 1.0591996908187866
Validation loss: 1.9806261857350667

Epoch: 5| Step: 2
Training loss: 0.9016318321228027
Validation loss: 2.0259835769732795

Epoch: 5| Step: 3
Training loss: 1.136642336845398
Validation loss: 2.0549031645059586

Epoch: 5| Step: 4
Training loss: 1.1772406101226807
Validation loss: 2.036495561401049

Epoch: 5| Step: 5
Training loss: 0.7859171628952026
Validation loss: 1.954381396373113

Epoch: 5| Step: 6
Training loss: 0.8061348795890808
Validation loss: 1.8784398486216862

Epoch: 5| Step: 7
Training loss: 1.1926567554473877
Validation loss: 1.9663012077411015

Epoch: 5| Step: 8
Training loss: 0.8491252660751343
Validation loss: 1.976784532268842

Epoch: 5| Step: 9
Training loss: 1.0187445878982544
Validation loss: 1.9674628525972366

Epoch: 5| Step: 10
Training loss: 1.4766161441802979
Validation loss: 1.9266745150089264

Epoch: 5| Step: 11
Training loss: 1.192040205001831
Validation loss: 1.9903931468725204

Epoch: 168| Step: 0
Training loss: 0.9004135131835938
Validation loss: 1.9693241814772289

Epoch: 5| Step: 1
Training loss: 0.6098825335502625
Validation loss: 2.0413945466279984

Epoch: 5| Step: 2
Training loss: 1.5371520519256592
Validation loss: 1.9863332659006119

Epoch: 5| Step: 3
Training loss: 0.7422879338264465
Validation loss: 2.018642927209536

Epoch: 5| Step: 4
Training loss: 1.1831623315811157
Validation loss: 2.0071498850981393

Epoch: 5| Step: 5
Training loss: 1.2356352806091309
Validation loss: 1.9903928637504578

Epoch: 5| Step: 6
Training loss: 1.474994421005249
Validation loss: 1.9931717813014984

Epoch: 5| Step: 7
Training loss: 0.5023182034492493
Validation loss: 1.995861252148946

Epoch: 5| Step: 8
Training loss: 0.4682517945766449
Validation loss: 1.9526116997003555

Epoch: 5| Step: 9
Training loss: 1.0171139240264893
Validation loss: 1.974323958158493

Epoch: 5| Step: 10
Training loss: 0.9156795740127563
Validation loss: 2.0036479185024896

Epoch: 5| Step: 11
Training loss: 0.3079286217689514
Validation loss: 1.9890698343515396

Epoch: 169| Step: 0
Training loss: 1.382352590560913
Validation loss: 1.9552552749713261

Epoch: 5| Step: 1
Training loss: 0.6968866586685181
Validation loss: 1.996627613902092

Epoch: 5| Step: 2
Training loss: 0.9657958745956421
Validation loss: 1.952894334991773

Epoch: 5| Step: 3
Training loss: 0.8500121235847473
Validation loss: 1.9715792040030162

Epoch: 5| Step: 4
Training loss: 0.9535840153694153
Validation loss: 1.9296688387791316

Epoch: 5| Step: 5
Training loss: 0.5814900994300842
Validation loss: 1.9674583673477173

Epoch: 5| Step: 6
Training loss: 1.6923919916152954
Validation loss: 1.9469856371482213

Epoch: 5| Step: 7
Training loss: 1.1926946640014648
Validation loss: 1.974533389012019

Epoch: 5| Step: 8
Training loss: 0.5856057405471802
Validation loss: 1.9822778503100078

Epoch: 5| Step: 9
Training loss: 0.7159520387649536
Validation loss: 1.98569351931413

Epoch: 5| Step: 10
Training loss: 0.6842309832572937
Validation loss: 1.9812410573164623

Epoch: 5| Step: 11
Training loss: 1.0322396755218506
Validation loss: 1.9687445710102718

Epoch: 170| Step: 0
Training loss: 1.2759864330291748
Validation loss: 1.9706266224384308

Epoch: 5| Step: 1
Training loss: 0.7602394223213196
Validation loss: 1.9587958753108978

Epoch: 5| Step: 2
Training loss: 0.46341103315353394
Validation loss: 1.9889264553785324

Epoch: 5| Step: 3
Training loss: 1.0708084106445312
Validation loss: 1.995283712943395

Epoch: 5| Step: 4
Training loss: 1.0814487934112549
Validation loss: 2.0060065339008966

Epoch: 5| Step: 5
Training loss: 1.1258952617645264
Validation loss: 1.99272188047568

Epoch: 5| Step: 6
Training loss: 0.645344078540802
Validation loss: 1.9566338111956914

Epoch: 5| Step: 7
Training loss: 0.8581196665763855
Validation loss: 1.9615047325690587

Epoch: 5| Step: 8
Training loss: 1.020607590675354
Validation loss: 1.8910660793383915

Epoch: 5| Step: 9
Training loss: 1.4498322010040283
Validation loss: 1.9360698858896892

Epoch: 5| Step: 10
Training loss: 0.7681133151054382
Validation loss: 1.974506249030431

Epoch: 5| Step: 11
Training loss: 0.9991125464439392
Validation loss: 2.0141817927360535

Epoch: 171| Step: 0
Training loss: 0.8010603785514832
Validation loss: 1.9874576429526012

Epoch: 5| Step: 1
Training loss: 1.2474807500839233
Validation loss: 1.9473481674989064

Epoch: 5| Step: 2
Training loss: 1.37234628200531
Validation loss: 1.9340392053127289

Epoch: 5| Step: 3
Training loss: 0.7161234021186829
Validation loss: 1.925155167778333

Epoch: 5| Step: 4
Training loss: 0.5142067670822144
Validation loss: 2.017278070251147

Epoch: 5| Step: 5
Training loss: 0.9016623497009277
Validation loss: 1.9458349446455638

Epoch: 5| Step: 6
Training loss: 1.034531593322754
Validation loss: 1.964331328868866

Epoch: 5| Step: 7
Training loss: 0.9313341379165649
Validation loss: 1.9289526740709941

Epoch: 5| Step: 8
Training loss: 0.8396884799003601
Validation loss: 1.930358111858368

Epoch: 5| Step: 9
Training loss: 1.086742639541626
Validation loss: 1.9716433485349019

Epoch: 5| Step: 10
Training loss: 0.5136284828186035
Validation loss: 1.9896964877843857

Epoch: 5| Step: 11
Training loss: 0.09362280368804932
Validation loss: 1.9435733358065288

Epoch: 172| Step: 0
Training loss: 0.8268316388130188
Validation loss: 1.9638823171456654

Epoch: 5| Step: 1
Training loss: 0.4654759466648102
Validation loss: 1.9664881527423859

Epoch: 5| Step: 2
Training loss: 1.1796373128890991
Validation loss: 1.9396697481473286

Epoch: 5| Step: 3
Training loss: 0.9282819628715515
Validation loss: 1.9692295690377553

Epoch: 5| Step: 4
Training loss: 1.288269281387329
Validation loss: 2.0339338183403015

Epoch: 5| Step: 5
Training loss: 1.1863590478897095
Validation loss: 2.035131032268206

Epoch: 5| Step: 6
Training loss: 0.9776638150215149
Validation loss: 1.9561502188444138

Epoch: 5| Step: 7
Training loss: 0.8150102496147156
Validation loss: 2.0245308578014374

Epoch: 5| Step: 8
Training loss: 0.4257773458957672
Validation loss: 1.9624990969896317

Epoch: 5| Step: 9
Training loss: 0.9045916795730591
Validation loss: 1.9710045556227367

Epoch: 5| Step: 10
Training loss: 1.0406821966171265
Validation loss: 1.9634458323319752

Epoch: 5| Step: 11
Training loss: 0.43135690689086914
Validation loss: 1.9573025951782863

Epoch: 173| Step: 0
Training loss: 0.8451008796691895
Validation loss: 1.9649343639612198

Epoch: 5| Step: 1
Training loss: 0.8700321316719055
Validation loss: 1.9536397010087967

Epoch: 5| Step: 2
Training loss: 0.6552270650863647
Validation loss: 2.0245838512976966

Epoch: 5| Step: 3
Training loss: 0.8123862147331238
Validation loss: 2.044994538029035

Epoch: 5| Step: 4
Training loss: 1.334254503250122
Validation loss: 1.9692367166280746

Epoch: 5| Step: 5
Training loss: 0.7040047645568848
Validation loss: 1.9870408922433853

Epoch: 5| Step: 6
Training loss: 1.1151138544082642
Validation loss: 1.935670018196106

Epoch: 5| Step: 7
Training loss: 0.6865413784980774
Validation loss: 1.9378682225942612

Epoch: 5| Step: 8
Training loss: 1.2015489339828491
Validation loss: 1.9530737201372783

Epoch: 5| Step: 9
Training loss: 0.9544049501419067
Validation loss: 1.9488074233134587

Epoch: 5| Step: 10
Training loss: 1.250105619430542
Validation loss: 1.9742618650197983

Epoch: 5| Step: 11
Training loss: 0.2441006600856781
Validation loss: 1.9357987592617671

Epoch: 174| Step: 0
Training loss: 0.994827926158905
Validation loss: 2.0318044970432916

Epoch: 5| Step: 1
Training loss: 0.5204960107803345
Validation loss: 2.025745168328285

Epoch: 5| Step: 2
Training loss: 0.4896770119667053
Validation loss: 1.994734858473142

Epoch: 5| Step: 3
Training loss: 1.022157907485962
Validation loss: 2.0028942823410034

Epoch: 5| Step: 4
Training loss: 1.2416421175003052
Validation loss: 1.9671179751555126

Epoch: 5| Step: 5
Training loss: 0.8767038583755493
Validation loss: 1.926784336566925

Epoch: 5| Step: 6
Training loss: 0.7922242879867554
Validation loss: 1.9778506805499394

Epoch: 5| Step: 7
Training loss: 0.9113270044326782
Validation loss: 1.9710251142581303

Epoch: 5| Step: 8
Training loss: 0.9313198924064636
Validation loss: 1.9279341648022335

Epoch: 5| Step: 9
Training loss: 0.6795259714126587
Validation loss: 2.0001652787129083

Epoch: 5| Step: 10
Training loss: 1.1502424478530884
Validation loss: 1.937131827076276

Epoch: 5| Step: 11
Training loss: 2.2028002738952637
Validation loss: 1.973639299472173

Epoch: 175| Step: 0
Training loss: 0.5751597881317139
Validation loss: 1.9134658227364223

Epoch: 5| Step: 1
Training loss: 0.9057213068008423
Validation loss: 1.9674345155556996

Epoch: 5| Step: 2
Training loss: 0.6747629046440125
Validation loss: 1.9475006759166718

Epoch: 5| Step: 3
Training loss: 1.0169503688812256
Validation loss: 1.9311776012182236

Epoch: 5| Step: 4
Training loss: 0.8922902941703796
Validation loss: 1.9363920589288075

Epoch: 5| Step: 5
Training loss: 0.9520250558853149
Validation loss: 1.9572232365608215

Epoch: 5| Step: 6
Training loss: 0.9643839001655579
Validation loss: 1.9673652251561482

Epoch: 5| Step: 7
Training loss: 1.1798189878463745
Validation loss: 1.951963722705841

Epoch: 5| Step: 8
Training loss: 0.9015941619873047
Validation loss: 1.9630980143944423

Epoch: 5| Step: 9
Training loss: 0.7745779752731323
Validation loss: 1.961092119415601

Epoch: 5| Step: 10
Training loss: 0.7395983934402466
Validation loss: 1.9457889646291733

Epoch: 5| Step: 11
Training loss: 0.6273905038833618
Validation loss: 1.9437160938978195

Epoch: 176| Step: 0
Training loss: 0.7558383941650391
Validation loss: 1.9544425010681152

Epoch: 5| Step: 1
Training loss: 0.6330593824386597
Validation loss: 1.938718522588412

Epoch: 5| Step: 2
Training loss: 1.3901761770248413
Validation loss: 1.9663886825243633

Epoch: 5| Step: 3
Training loss: 1.6186039447784424
Validation loss: 2.0038212140401206

Epoch: 5| Step: 4
Training loss: 0.5952896475791931
Validation loss: 1.9428733934958775

Epoch: 5| Step: 5
Training loss: 0.708513617515564
Validation loss: 1.9217004776000977

Epoch: 5| Step: 6
Training loss: 1.300068736076355
Validation loss: 1.9542948851982753

Epoch: 5| Step: 7
Training loss: 0.352475643157959
Validation loss: 1.9802030424276988

Epoch: 5| Step: 8
Training loss: 0.7560921907424927
Validation loss: 1.9420251448949177

Epoch: 5| Step: 9
Training loss: 0.8516360521316528
Validation loss: 2.0006572107474008

Epoch: 5| Step: 10
Training loss: 0.5338391661643982
Validation loss: 1.9566858609517415

Epoch: 5| Step: 11
Training loss: 0.20255327224731445
Validation loss: 1.9434593468904495

Epoch: 177| Step: 0
Training loss: 0.7603093385696411
Validation loss: 1.9396844059228897

Epoch: 5| Step: 1
Training loss: 1.37154221534729
Validation loss: 1.9304873943328857

Epoch: 5| Step: 2
Training loss: 1.0942504405975342
Validation loss: 1.8673346489667892

Epoch: 5| Step: 3
Training loss: 1.097589135169983
Validation loss: 1.9346016943454742

Epoch: 5| Step: 4
Training loss: 0.5717874765396118
Validation loss: 1.9449074814716976

Epoch: 5| Step: 5
Training loss: 1.1624711751937866
Validation loss: 1.9267920205990474

Epoch: 5| Step: 6
Training loss: 0.5712139010429382
Validation loss: 1.9616438696781795

Epoch: 5| Step: 7
Training loss: 0.82035893201828
Validation loss: 1.9222983966271083

Epoch: 5| Step: 8
Training loss: 0.5612689852714539
Validation loss: 1.9247436970472336

Epoch: 5| Step: 9
Training loss: 0.586412787437439
Validation loss: 1.9220311293999355

Epoch: 5| Step: 10
Training loss: 0.8819049596786499
Validation loss: 2.000104069709778

Epoch: 5| Step: 11
Training loss: 0.8132064342498779
Validation loss: 1.9751983781655629

Epoch: 178| Step: 0
Training loss: 0.7589918375015259
Validation loss: 2.0098667542139688

Epoch: 5| Step: 1
Training loss: 0.8543405532836914
Validation loss: 1.9583099236090977

Epoch: 5| Step: 2
Training loss: 0.2365952730178833
Validation loss: 1.9857660432656605

Epoch: 5| Step: 3
Training loss: 0.6694386601448059
Validation loss: 1.9404913187026978

Epoch: 5| Step: 4
Training loss: 0.6755667328834534
Validation loss: 1.99919293820858

Epoch: 5| Step: 5
Training loss: 0.9462383389472961
Validation loss: 1.9717794607083003

Epoch: 5| Step: 6
Training loss: 0.9546244740486145
Validation loss: 1.924597253402074

Epoch: 5| Step: 7
Training loss: 0.955380916595459
Validation loss: 1.9537590493758519

Epoch: 5| Step: 8
Training loss: 0.45308905839920044
Validation loss: 1.9518495599428813

Epoch: 5| Step: 9
Training loss: 1.2783958911895752
Validation loss: 1.9525359521309535

Epoch: 5| Step: 10
Training loss: 1.3170175552368164
Validation loss: 1.9782176961501439

Epoch: 5| Step: 11
Training loss: 1.0943273305892944
Validation loss: 1.9173849920431774

Epoch: 179| Step: 0
Training loss: 0.9648104906082153
Validation loss: 1.9357431083917618

Epoch: 5| Step: 1
Training loss: 0.7506245374679565
Validation loss: 2.000322009126345

Epoch: 5| Step: 2
Training loss: 1.0559532642364502
Validation loss: 1.9966947585344315

Epoch: 5| Step: 3
Training loss: 1.0771983861923218
Validation loss: 1.9868805507818859

Epoch: 5| Step: 4
Training loss: 0.4524417817592621
Validation loss: 2.002011686563492

Epoch: 5| Step: 5
Training loss: 0.6291092038154602
Validation loss: 2.013022239009539

Epoch: 5| Step: 6
Training loss: 0.8686220049858093
Validation loss: 1.9536219735940297

Epoch: 5| Step: 7
Training loss: 1.0557175874710083
Validation loss: 1.9874023745457332

Epoch: 5| Step: 8
Training loss: 0.9952774047851562
Validation loss: 2.000821982820829

Epoch: 5| Step: 9
Training loss: 0.670691192150116
Validation loss: 1.9939518223206203

Epoch: 5| Step: 10
Training loss: 0.923305332660675
Validation loss: 1.9702173868815105

Epoch: 5| Step: 11
Training loss: 1.4226642847061157
Validation loss: 1.9961196184158325

Epoch: 180| Step: 0
Training loss: 0.7588253021240234
Validation loss: 1.9580749770005543

Epoch: 5| Step: 1
Training loss: 0.6614044308662415
Validation loss: 2.0120680183172226

Epoch: 5| Step: 2
Training loss: 0.5297290086746216
Validation loss: 1.981401965022087

Epoch: 5| Step: 3
Training loss: 0.7301570177078247
Validation loss: 1.9926166981458664

Epoch: 5| Step: 4
Training loss: 0.7013617753982544
Validation loss: 1.974146768450737

Epoch: 5| Step: 5
Training loss: 1.6473557949066162
Validation loss: 1.9602084060509999

Epoch: 5| Step: 6
Training loss: 1.0973135232925415
Validation loss: 2.013723522424698

Epoch: 5| Step: 7
Training loss: 1.1691783666610718
Validation loss: 1.9949575165907543

Epoch: 5| Step: 8
Training loss: 0.6313105821609497
Validation loss: 1.972400039434433

Epoch: 5| Step: 9
Training loss: 0.9883130788803101
Validation loss: 2.0289472192525864

Epoch: 5| Step: 10
Training loss: 0.47282877564430237
Validation loss: 1.9824341634909313

Epoch: 5| Step: 11
Training loss: 1.4820588827133179
Validation loss: 2.0012734681367874

Epoch: 181| Step: 0
Training loss: 0.7940038442611694
Validation loss: 1.9780010730028152

Epoch: 5| Step: 1
Training loss: 0.7592085003852844
Validation loss: 1.9347574810187023

Epoch: 5| Step: 2
Training loss: 0.6913055181503296
Validation loss: 1.9832578301429749

Epoch: 5| Step: 3
Training loss: 0.7706567645072937
Validation loss: 1.9567871888478596

Epoch: 5| Step: 4
Training loss: 0.7179345488548279
Validation loss: 1.9665927191575368

Epoch: 5| Step: 5
Training loss: 0.8942838907241821
Validation loss: 1.9781002700328827

Epoch: 5| Step: 6
Training loss: 1.1209261417388916
Validation loss: 1.991977925101916

Epoch: 5| Step: 7
Training loss: 1.5512775182724
Validation loss: 2.0204221506913504

Epoch: 5| Step: 8
Training loss: 0.6195163130760193
Validation loss: 2.0248352736234665

Epoch: 5| Step: 9
Training loss: 1.1955684423446655
Validation loss: 2.0359063694874444

Epoch: 5| Step: 10
Training loss: 0.45664024353027344
Validation loss: 1.9465775390466054

Epoch: 5| Step: 11
Training loss: 0.4042550325393677
Validation loss: 1.9574963847796123

Epoch: 182| Step: 0
Training loss: 0.7941800951957703
Validation loss: 1.9685010462999344

Epoch: 5| Step: 1
Training loss: 0.8704485893249512
Validation loss: 1.9474147607882817

Epoch: 5| Step: 2
Training loss: 0.7032536268234253
Validation loss: 1.9722805966933568

Epoch: 5| Step: 3
Training loss: 0.8129459619522095
Validation loss: 1.9777862081925075

Epoch: 5| Step: 4
Training loss: 0.9547228813171387
Validation loss: 1.9695639262596767

Epoch: 5| Step: 5
Training loss: 0.6805160641670227
Validation loss: 1.991304650902748

Epoch: 5| Step: 6
Training loss: 0.9304315447807312
Validation loss: 1.9510461787382762

Epoch: 5| Step: 7
Training loss: 0.7458945512771606
Validation loss: 1.9612357666095097

Epoch: 5| Step: 8
Training loss: 0.25382450222969055
Validation loss: 1.9755896876255672

Epoch: 5| Step: 9
Training loss: 0.9603042602539062
Validation loss: 1.9155254413684208

Epoch: 5| Step: 10
Training loss: 1.2806901931762695
Validation loss: 1.9248865246772766

Epoch: 5| Step: 11
Training loss: 2.2293825149536133
Validation loss: 1.9801451464494069

Epoch: 183| Step: 0
Training loss: 0.49272972345352173
Validation loss: 1.9278749624888103

Epoch: 5| Step: 1
Training loss: 1.1814649105072021
Validation loss: 1.9923580586910248

Epoch: 5| Step: 2
Training loss: 0.7916745543479919
Validation loss: 1.983966256181399

Epoch: 5| Step: 3
Training loss: 1.096575379371643
Validation loss: 1.9799098322788875

Epoch: 5| Step: 4
Training loss: 1.42171311378479
Validation loss: 2.033004676302274

Epoch: 5| Step: 5
Training loss: 0.7027139663696289
Validation loss: 1.9241675833861034

Epoch: 5| Step: 6
Training loss: 0.8001254200935364
Validation loss: 1.9229101091623306

Epoch: 5| Step: 7
Training loss: 1.0204890966415405
Validation loss: 1.9817001024882

Epoch: 5| Step: 8
Training loss: 0.7837514877319336
Validation loss: 1.9468024919430416

Epoch: 5| Step: 9
Training loss: 0.5571316480636597
Validation loss: 1.9525139232476552

Epoch: 5| Step: 10
Training loss: 0.8935111165046692
Validation loss: 1.9615393628676732

Epoch: 5| Step: 11
Training loss: 1.0622227191925049
Validation loss: 2.0138755440711975

Epoch: 184| Step: 0
Training loss: 0.9886266589164734
Validation loss: 2.0354126691818237

Epoch: 5| Step: 1
Training loss: 0.6885294914245605
Validation loss: 1.9898919761180878

Epoch: 5| Step: 2
Training loss: 0.8642944097518921
Validation loss: 2.021681105097135

Epoch: 5| Step: 3
Training loss: 1.0430799722671509
Validation loss: 1.9881006230910618

Epoch: 5| Step: 4
Training loss: 0.9016040563583374
Validation loss: 1.9379655073086421

Epoch: 5| Step: 5
Training loss: 0.6757290959358215
Validation loss: 1.9671827505032222

Epoch: 5| Step: 6
Training loss: 0.8428823351860046
Validation loss: 1.972821518778801

Epoch: 5| Step: 7
Training loss: 0.9643470644950867
Validation loss: 1.9541625479857128

Epoch: 5| Step: 8
Training loss: 0.9023488759994507
Validation loss: 1.9851087431112926

Epoch: 5| Step: 9
Training loss: 0.5580131411552429
Validation loss: 1.9731426189343135

Epoch: 5| Step: 10
Training loss: 0.4757471978664398
Validation loss: 1.9505076905091603

Epoch: 5| Step: 11
Training loss: 2.6363091468811035
Validation loss: 2.035298064351082

Epoch: 185| Step: 0
Training loss: 0.9566976428031921
Validation loss: 1.9774458607037861

Epoch: 5| Step: 1
Training loss: 0.7819105982780457
Validation loss: 1.9362010111411412

Epoch: 5| Step: 2
Training loss: 1.0460999011993408
Validation loss: 1.944327289859454

Epoch: 5| Step: 3
Training loss: 1.0509755611419678
Validation loss: 1.9217408498128254

Epoch: 5| Step: 4
Training loss: 0.7226582765579224
Validation loss: 1.954634855190913

Epoch: 5| Step: 5
Training loss: 0.9568894505500793
Validation loss: 1.9826684544483821

Epoch: 5| Step: 6
Training loss: 0.415097713470459
Validation loss: 1.968915805220604

Epoch: 5| Step: 7
Training loss: 1.0766983032226562
Validation loss: 1.9437760810057323

Epoch: 5| Step: 8
Training loss: 0.7437232732772827
Validation loss: 2.009339759747187

Epoch: 5| Step: 9
Training loss: 0.765376091003418
Validation loss: 1.9539902061223984

Epoch: 5| Step: 10
Training loss: 0.7082434892654419
Validation loss: 1.9436981678009033

Epoch: 5| Step: 11
Training loss: 0.5040650367736816
Validation loss: 2.0448348174492517

Epoch: 186| Step: 0
Training loss: 0.8464948534965515
Validation loss: 2.0016659845908484

Epoch: 5| Step: 1
Training loss: 1.0953483581542969
Validation loss: 1.969341665506363

Epoch: 5| Step: 2
Training loss: 1.0973669290542603
Validation loss: 2.064448729157448

Epoch: 5| Step: 3
Training loss: 0.5869143605232239
Validation loss: 1.9582843134800594

Epoch: 5| Step: 4
Training loss: 0.7346702814102173
Validation loss: 1.9744373261928558

Epoch: 5| Step: 5
Training loss: 0.6644725799560547
Validation loss: 1.9323102086782455

Epoch: 5| Step: 6
Training loss: 0.5128922462463379
Validation loss: 1.9199649741252263

Epoch: 5| Step: 7
Training loss: 1.1856415271759033
Validation loss: 1.9305389076471329

Epoch: 5| Step: 8
Training loss: 0.9824816584587097
Validation loss: 1.957609862089157

Epoch: 5| Step: 9
Training loss: 0.6883907914161682
Validation loss: 1.9075748324394226

Epoch: 5| Step: 10
Training loss: 0.6262825131416321
Validation loss: 1.9364056835571926

Epoch: 5| Step: 11
Training loss: 0.38258838653564453
Validation loss: 1.9678210218747456

Epoch: 187| Step: 0
Training loss: 0.747712254524231
Validation loss: 1.9184755285580952

Epoch: 5| Step: 1
Training loss: 1.1521390676498413
Validation loss: 1.9945805470148723

Epoch: 5| Step: 2
Training loss: 0.877354621887207
Validation loss: 1.887198915084203

Epoch: 5| Step: 3
Training loss: 0.5418599247932434
Validation loss: 1.9268022030591965

Epoch: 5| Step: 4
Training loss: 0.613146960735321
Validation loss: 1.9369252820809681

Epoch: 5| Step: 5
Training loss: 0.782380223274231
Validation loss: 1.9781863689422607

Epoch: 5| Step: 6
Training loss: 1.357964038848877
Validation loss: 1.966185599565506

Epoch: 5| Step: 7
Training loss: 0.9352992177009583
Validation loss: 1.9945215831200283

Epoch: 5| Step: 8
Training loss: 0.36095550656318665
Validation loss: 1.9503399729728699

Epoch: 5| Step: 9
Training loss: 0.7262136340141296
Validation loss: 2.018908609946569

Epoch: 5| Step: 10
Training loss: 0.943299412727356
Validation loss: 1.9716034283240635

Epoch: 5| Step: 11
Training loss: 0.08234405517578125
Validation loss: 1.9821895360946655

Epoch: 188| Step: 0
Training loss: 0.5591481328010559
Validation loss: 1.9606516311566036

Epoch: 5| Step: 1
Training loss: 0.9667387008666992
Validation loss: 1.9218489478031795

Epoch: 5| Step: 2
Training loss: 0.5930219888687134
Validation loss: 1.9638654440641403

Epoch: 5| Step: 3
Training loss: 0.7067784070968628
Validation loss: 1.967708667119344

Epoch: 5| Step: 4
Training loss: 0.5079039931297302
Validation loss: 1.9546871682008107

Epoch: 5| Step: 5
Training loss: 0.9572063684463501
Validation loss: 1.953337127963702

Epoch: 5| Step: 6
Training loss: 0.8737987279891968
Validation loss: 1.9292554954687755

Epoch: 5| Step: 7
Training loss: 0.4951609969139099
Validation loss: 1.9371417512496312

Epoch: 5| Step: 8
Training loss: 0.9795366525650024
Validation loss: 1.9516792049010594

Epoch: 5| Step: 9
Training loss: 0.8804457783699036
Validation loss: 1.9451656142870586

Epoch: 5| Step: 10
Training loss: 1.2630140781402588
Validation loss: 2.005501240491867

Epoch: 5| Step: 11
Training loss: 0.956575870513916
Validation loss: 1.9521570950746536

Epoch: 189| Step: 0
Training loss: 0.7344712018966675
Validation loss: 1.9688901801904042

Epoch: 5| Step: 1
Training loss: 0.8349298238754272
Validation loss: 1.95985509455204

Epoch: 5| Step: 2
Training loss: 0.7879359126091003
Validation loss: 1.9268932243188222

Epoch: 5| Step: 3
Training loss: 0.7192134261131287
Validation loss: 1.949080303311348

Epoch: 5| Step: 4
Training loss: 0.9359698295593262
Validation loss: 1.9394404590129852

Epoch: 5| Step: 5
Training loss: 0.5214554071426392
Validation loss: 1.9323125779628754

Epoch: 5| Step: 6
Training loss: 1.0905888080596924
Validation loss: 1.9099536041418712

Epoch: 5| Step: 7
Training loss: 0.9775165319442749
Validation loss: 1.9345016926527023

Epoch: 5| Step: 8
Training loss: 0.9358760714530945
Validation loss: 1.9392346044381459

Epoch: 5| Step: 9
Training loss: 0.4131976068019867
Validation loss: 1.945803592602412

Epoch: 5| Step: 10
Training loss: 0.7040932774543762
Validation loss: 1.930362805724144

Epoch: 5| Step: 11
Training loss: 0.6251811981201172
Validation loss: 1.9443564713001251

Epoch: 190| Step: 0
Training loss: 1.2494386434555054
Validation loss: 1.9422236233949661

Epoch: 5| Step: 1
Training loss: 0.5499892234802246
Validation loss: 1.9560498346885045

Epoch: 5| Step: 2
Training loss: 0.9717286825180054
Validation loss: 1.9587027380863826

Epoch: 5| Step: 3
Training loss: 0.6502438187599182
Validation loss: 1.979231024781863

Epoch: 5| Step: 4
Training loss: 0.6164931058883667
Validation loss: 1.9402605940898259

Epoch: 5| Step: 5
Training loss: 0.8007692098617554
Validation loss: 1.9636222422122955

Epoch: 5| Step: 6
Training loss: 0.874350905418396
Validation loss: 1.969335565964381

Epoch: 5| Step: 7
Training loss: 0.895679771900177
Validation loss: 2.0250291526317596

Epoch: 5| Step: 8
Training loss: 0.5147305727005005
Validation loss: 1.9596293767293294

Epoch: 5| Step: 9
Training loss: 0.6636310815811157
Validation loss: 1.9267053256432216

Epoch: 5| Step: 10
Training loss: 0.5828684568405151
Validation loss: 1.9431016941865284

Epoch: 5| Step: 11
Training loss: 1.357100009918213
Validation loss: 1.9089790383974712

Epoch: 191| Step: 0
Training loss: 1.0506391525268555
Validation loss: 1.9389119098583858

Epoch: 5| Step: 1
Training loss: 0.5854376554489136
Validation loss: 1.9261176884174347

Epoch: 5| Step: 2
Training loss: 1.156532645225525
Validation loss: 1.9668587893247604

Epoch: 5| Step: 3
Training loss: 0.4177727699279785
Validation loss: 2.004892483353615

Epoch: 5| Step: 4
Training loss: 0.6249864101409912
Validation loss: 1.9457901815573375

Epoch: 5| Step: 5
Training loss: 0.6207739114761353
Validation loss: 1.9467686663071315

Epoch: 5| Step: 6
Training loss: 0.9982240796089172
Validation loss: 1.9783235838015873

Epoch: 5| Step: 7
Training loss: 0.7824156284332275
Validation loss: 1.9698757131894429

Epoch: 5| Step: 8
Training loss: 0.6531102061271667
Validation loss: 1.9569808940092723

Epoch: 5| Step: 9
Training loss: 0.9693126678466797
Validation loss: 1.9362844328085582

Epoch: 5| Step: 10
Training loss: 0.5209571719169617
Validation loss: 1.9634977132081985

Epoch: 5| Step: 11
Training loss: 0.9996848106384277
Validation loss: 1.965739240248998

Epoch: 192| Step: 0
Training loss: 0.36090201139450073
Validation loss: 1.915928527712822

Epoch: 5| Step: 1
Training loss: 0.9406777620315552
Validation loss: 1.9994555215040843

Epoch: 5| Step: 2
Training loss: 0.5249208211898804
Validation loss: 1.9330922663211823

Epoch: 5| Step: 3
Training loss: 1.0128629207611084
Validation loss: 1.936930388212204

Epoch: 5| Step: 4
Training loss: 1.3668873310089111
Validation loss: 1.958045169711113

Epoch: 5| Step: 5
Training loss: 0.9061811566352844
Validation loss: 1.9816039601961772

Epoch: 5| Step: 6
Training loss: 0.7777309417724609
Validation loss: 1.937993084390958

Epoch: 5| Step: 7
Training loss: 1.003661870956421
Validation loss: 1.9795104662577312

Epoch: 5| Step: 8
Training loss: 0.39752197265625
Validation loss: 1.9913098365068436

Epoch: 5| Step: 9
Training loss: 0.7356162071228027
Validation loss: 2.0035000145435333

Epoch: 5| Step: 10
Training loss: 0.42941704392433167
Validation loss: 1.9651169230540593

Epoch: 5| Step: 11
Training loss: 0.36153340339660645
Validation loss: 1.986633688211441

Epoch: 193| Step: 0
Training loss: 0.8645696640014648
Validation loss: 1.9840738326311111

Epoch: 5| Step: 1
Training loss: 0.7978489995002747
Validation loss: 1.963968018690745

Epoch: 5| Step: 2
Training loss: 0.4782351851463318
Validation loss: 1.9778198152780533

Epoch: 5| Step: 3
Training loss: 0.5309538841247559
Validation loss: 1.9183900505304337

Epoch: 5| Step: 4
Training loss: 0.5685257911682129
Validation loss: 1.9722597847382228

Epoch: 5| Step: 5
Training loss: 0.972726047039032
Validation loss: 1.9585174570480983

Epoch: 5| Step: 6
Training loss: 0.8003904223442078
Validation loss: 1.9379764199256897

Epoch: 5| Step: 7
Training loss: 0.9706729650497437
Validation loss: 1.9660149961709976

Epoch: 5| Step: 8
Training loss: 0.6414600610733032
Validation loss: 1.9659951974948247

Epoch: 5| Step: 9
Training loss: 0.5210391283035278
Validation loss: 1.9458895524342854

Epoch: 5| Step: 10
Training loss: 0.9000086784362793
Validation loss: 1.9447939346234004

Epoch: 5| Step: 11
Training loss: 2.2482643127441406
Validation loss: 1.9795970916748047

Epoch: 194| Step: 0
Training loss: 0.9090177416801453
Validation loss: 2.0393128047386804

Epoch: 5| Step: 1
Training loss: 0.9506848454475403
Validation loss: 2.045185705025991

Epoch: 5| Step: 2
Training loss: 0.972065806388855
Validation loss: 2.0329383114973703

Epoch: 5| Step: 3
Training loss: 0.473796546459198
Validation loss: 1.9957742094993591

Epoch: 5| Step: 4
Training loss: 1.0783588886260986
Validation loss: 2.003232846657435

Epoch: 5| Step: 5
Training loss: 0.6235486268997192
Validation loss: 1.950080414613088

Epoch: 5| Step: 6
Training loss: 0.9499883651733398
Validation loss: 1.9263053039709728

Epoch: 5| Step: 7
Training loss: 0.7582563161849976
Validation loss: 1.9126260578632355

Epoch: 5| Step: 8
Training loss: 0.6230772733688354
Validation loss: 1.917894721031189

Epoch: 5| Step: 9
Training loss: 1.0934664011001587
Validation loss: 1.9499575197696686

Epoch: 5| Step: 10
Training loss: 0.564835250377655
Validation loss: 1.9549006670713425

Epoch: 5| Step: 11
Training loss: 0.9535250067710876
Validation loss: 1.9481418232123058

Epoch: 195| Step: 0
Training loss: 0.7100381851196289
Validation loss: 1.9571487456560135

Epoch: 5| Step: 1
Training loss: 0.7531753778457642
Validation loss: 1.9198526442050934

Epoch: 5| Step: 2
Training loss: 0.5354287624359131
Validation loss: 1.9720275402069092

Epoch: 5| Step: 3
Training loss: 1.3686878681182861
Validation loss: 1.9313975671927135

Epoch: 5| Step: 4
Training loss: 1.018165946006775
Validation loss: 1.9308847486972809

Epoch: 5| Step: 5
Training loss: 0.6500604152679443
Validation loss: 1.951388602455457

Epoch: 5| Step: 6
Training loss: 0.8513786196708679
Validation loss: 1.8845164279143016

Epoch: 5| Step: 7
Training loss: 0.7334389686584473
Validation loss: 1.9732714345057805

Epoch: 5| Step: 8
Training loss: 0.4948429465293884
Validation loss: 2.059963663419088

Epoch: 5| Step: 9
Training loss: 0.8673864603042603
Validation loss: 2.079756091038386

Epoch: 5| Step: 10
Training loss: 0.9257088899612427
Validation loss: 2.005413527290026

Epoch: 5| Step: 11
Training loss: 0.5801883935928345
Validation loss: 2.029379516839981

Epoch: 196| Step: 0
Training loss: 0.8547064065933228
Validation loss: 1.9705515503883362

Epoch: 5| Step: 1
Training loss: 0.492544561624527
Validation loss: 1.9762341727813084

Epoch: 5| Step: 2
Training loss: 0.6005815267562866
Validation loss: 1.9383211483558018

Epoch: 5| Step: 3
Training loss: 0.8894829750061035
Validation loss: 1.9300652990738552

Epoch: 5| Step: 4
Training loss: 1.2740895748138428
Validation loss: 1.9314178725083668

Epoch: 5| Step: 5
Training loss: 0.7414280772209167
Validation loss: 1.9272509862979252

Epoch: 5| Step: 6
Training loss: 0.727249264717102
Validation loss: 2.0261058807373047

Epoch: 5| Step: 7
Training loss: 0.776505172252655
Validation loss: 2.014151563247045

Epoch: 5| Step: 8
Training loss: 0.7397348284721375
Validation loss: 1.9405723611513774

Epoch: 5| Step: 9
Training loss: 0.9287236928939819
Validation loss: 1.9098801215489705

Epoch: 5| Step: 10
Training loss: 0.7492955923080444
Validation loss: 1.9254343211650848

Epoch: 5| Step: 11
Training loss: 0.3318312168121338
Validation loss: 1.9250428825616837

Epoch: 197| Step: 0
Training loss: 0.8952978253364563
Validation loss: 1.956622024377187

Epoch: 5| Step: 1
Training loss: 0.7388454675674438
Validation loss: 2.0086255421241126

Epoch: 5| Step: 2
Training loss: 0.6734504699707031
Validation loss: 1.9496265550454457

Epoch: 5| Step: 3
Training loss: 0.771599292755127
Validation loss: 1.9544648230075836

Epoch: 5| Step: 4
Training loss: 0.9178334474563599
Validation loss: 2.051716367403666

Epoch: 5| Step: 5
Training loss: 0.5740913152694702
Validation loss: 1.9792642146348953

Epoch: 5| Step: 6
Training loss: 0.5016363263130188
Validation loss: 1.9609053432941437

Epoch: 5| Step: 7
Training loss: 0.8051804304122925
Validation loss: 1.9799877603848774

Epoch: 5| Step: 8
Training loss: 0.8412269353866577
Validation loss: 1.9640294512112935

Epoch: 5| Step: 9
Training loss: 0.5933431386947632
Validation loss: 1.956202248732249

Epoch: 5| Step: 10
Training loss: 0.894750714302063
Validation loss: 1.9427454123894374

Epoch: 5| Step: 11
Training loss: 0.8929572105407715
Validation loss: 1.9641402463118236

Epoch: 198| Step: 0
Training loss: 0.6769000887870789
Validation loss: 1.9133779903252919

Epoch: 5| Step: 1
Training loss: 0.6396046876907349
Validation loss: 1.9481088469425838

Epoch: 5| Step: 2
Training loss: 0.9002793431282043
Validation loss: 1.9882986793915431

Epoch: 5| Step: 3
Training loss: 0.6137410402297974
Validation loss: 1.9596596161524455

Epoch: 5| Step: 4
Training loss: 0.5679015517234802
Validation loss: 1.9638138711452484

Epoch: 5| Step: 5
Training loss: 0.7106725573539734
Validation loss: 2.0107450783252716

Epoch: 5| Step: 6
Training loss: 1.0733239650726318
Validation loss: 1.9349796772003174

Epoch: 5| Step: 7
Training loss: 0.8949815034866333
Validation loss: 1.9522978713115056

Epoch: 5| Step: 8
Training loss: 0.7875236868858337
Validation loss: 1.916691929101944

Epoch: 5| Step: 9
Training loss: 0.8190194964408875
Validation loss: 1.9471422284841537

Epoch: 5| Step: 10
Training loss: 0.5744001865386963
Validation loss: 1.9707499494155247

Epoch: 5| Step: 11
Training loss: 0.5268549919128418
Validation loss: 1.9571049759785335

Epoch: 199| Step: 0
Training loss: 0.28664714097976685
Validation loss: 1.9538267105817795

Epoch: 5| Step: 1
Training loss: 0.8889245986938477
Validation loss: 1.9425670901934307

Epoch: 5| Step: 2
Training loss: 0.9264028668403625
Validation loss: 1.919422949353854

Epoch: 5| Step: 3
Training loss: 0.8257668614387512
Validation loss: 1.890794187784195

Epoch: 5| Step: 4
Training loss: 0.8621967434883118
Validation loss: 1.9123748391866684

Epoch: 5| Step: 5
Training loss: 0.8000873327255249
Validation loss: 1.9286358108123143

Epoch: 5| Step: 6
Training loss: 0.7336417436599731
Validation loss: 1.948637415965398

Epoch: 5| Step: 7
Training loss: 0.8244697451591492
Validation loss: 1.9871429055929184

Epoch: 5| Step: 8
Training loss: 0.5086058378219604
Validation loss: 1.9787211418151855

Epoch: 5| Step: 9
Training loss: 1.2831958532333374
Validation loss: 2.0128571540117264

Epoch: 5| Step: 10
Training loss: 0.6446312069892883
Validation loss: 2.0142292926708856

Epoch: 5| Step: 11
Training loss: 0.7498589754104614
Validation loss: 1.9422859301169713

Epoch: 200| Step: 0
Training loss: 0.980792224407196
Validation loss: 1.9327541440725327

Epoch: 5| Step: 1
Training loss: 0.9393043518066406
Validation loss: 1.927932858467102

Epoch: 5| Step: 2
Training loss: 0.9719107747077942
Validation loss: 1.9446534862120946

Epoch: 5| Step: 3
Training loss: 0.760921835899353
Validation loss: 1.9549502233664195

Epoch: 5| Step: 4
Training loss: 0.988936722278595
Validation loss: 1.9574233442544937

Epoch: 5| Step: 5
Training loss: 0.8846443295478821
Validation loss: 1.913110891977946

Epoch: 5| Step: 6
Training loss: 0.7016695141792297
Validation loss: 1.950024942557017

Epoch: 5| Step: 7
Training loss: 0.8220050930976868
Validation loss: 1.9708751837412517

Epoch: 5| Step: 8
Training loss: 0.48205822706222534
Validation loss: 1.9231896698474884

Epoch: 5| Step: 9
Training loss: 0.6180835366249084
Validation loss: 1.9539920041958492

Epoch: 5| Step: 10
Training loss: 0.643961489200592
Validation loss: 1.9792460650205612

Epoch: 5| Step: 11
Training loss: 0.13779178261756897
Validation loss: 1.9670920471350353

Epoch: 201| Step: 0
Training loss: 0.5660020709037781
Validation loss: 1.921334981918335

Epoch: 5| Step: 1
Training loss: 0.622886061668396
Validation loss: 2.033315524458885

Epoch: 5| Step: 2
Training loss: 0.9695175290107727
Validation loss: 1.972356195251147

Epoch: 5| Step: 3
Training loss: 0.9052045941352844
Validation loss: 1.9862976918617885

Epoch: 5| Step: 4
Training loss: 0.5931453704833984
Validation loss: 1.958614965279897

Epoch: 5| Step: 5
Training loss: 0.5857852697372437
Validation loss: 1.9117260376612346

Epoch: 5| Step: 6
Training loss: 0.8428376317024231
Validation loss: 1.937894031405449

Epoch: 5| Step: 7
Training loss: 0.5124205946922302
Validation loss: 1.942462628086408

Epoch: 5| Step: 8
Training loss: 0.5851098299026489
Validation loss: 1.9302191138267517

Epoch: 5| Step: 9
Training loss: 1.1142690181732178
Validation loss: 1.9521054079135258

Epoch: 5| Step: 10
Training loss: 0.5400150418281555
Validation loss: 1.9626169006029766

Epoch: 5| Step: 11
Training loss: 0.4424175024032593
Validation loss: 1.9134533355633419

Epoch: 202| Step: 0
Training loss: 0.6283866167068481
Validation loss: 2.01612821718057

Epoch: 5| Step: 1
Training loss: 0.7409025430679321
Validation loss: 1.9818673580884933

Epoch: 5| Step: 2
Training loss: 1.0492689609527588
Validation loss: 1.9829755872488022

Epoch: 5| Step: 3
Training loss: 0.6665534973144531
Validation loss: 2.0222794711589813

Epoch: 5| Step: 4
Training loss: 0.9244652986526489
Validation loss: 1.9859954714775085

Epoch: 5| Step: 5
Training loss: 0.49622899293899536
Validation loss: 1.9621865153312683

Epoch: 5| Step: 6
Training loss: 0.3617765009403229
Validation loss: 1.9402039895455043

Epoch: 5| Step: 7
Training loss: 0.6373556852340698
Validation loss: 1.9334842761357625

Epoch: 5| Step: 8
Training loss: 0.9694903492927551
Validation loss: 1.9358971565961838

Epoch: 5| Step: 9
Training loss: 0.8136565089225769
Validation loss: 1.9530997077624004

Epoch: 5| Step: 10
Training loss: 0.35112398862838745
Validation loss: 1.9261167645454407

Epoch: 5| Step: 11
Training loss: 1.9237923622131348
Validation loss: 1.9768817474444706

Epoch: 203| Step: 0
Training loss: 0.578548789024353
Validation loss: 1.9546509633461635

Epoch: 5| Step: 1
Training loss: 0.7577778697013855
Validation loss: 1.9472535848617554

Epoch: 5| Step: 2
Training loss: 0.7770546078681946
Validation loss: 1.94315804541111

Epoch: 5| Step: 3
Training loss: 0.8349944949150085
Validation loss: 1.960323949654897

Epoch: 5| Step: 4
Training loss: 0.5813837647438049
Validation loss: 1.9233874926964443

Epoch: 5| Step: 5
Training loss: 0.2787359356880188
Validation loss: 1.9631470739841461

Epoch: 5| Step: 6
Training loss: 0.628341019153595
Validation loss: 1.8957757254441578

Epoch: 5| Step: 7
Training loss: 0.9302751421928406
Validation loss: 1.9065054655075073

Epoch: 5| Step: 8
Training loss: 0.5422574281692505
Validation loss: 1.9605397929747899

Epoch: 5| Step: 9
Training loss: 0.8115260004997253
Validation loss: 1.9480886161327362

Epoch: 5| Step: 10
Training loss: 0.727653443813324
Validation loss: 1.9288575798273087

Epoch: 5| Step: 11
Training loss: 0.7567638158798218
Validation loss: 1.9421893159548442

Epoch: 204| Step: 0
Training loss: 0.7007478475570679
Validation loss: 1.8945612410704296

Epoch: 5| Step: 1
Training loss: 0.6054522395133972
Validation loss: 1.9691185156504314

Epoch: 5| Step: 2
Training loss: 0.548308253288269
Validation loss: 1.8961473157008488

Epoch: 5| Step: 3
Training loss: 0.7123847007751465
Validation loss: 1.9371707687775295

Epoch: 5| Step: 4
Training loss: 0.45467066764831543
Validation loss: 1.929291640718778

Epoch: 5| Step: 5
Training loss: 0.6351866126060486
Validation loss: 1.9447242766618729

Epoch: 5| Step: 6
Training loss: 0.9382472038269043
Validation loss: 1.9817062218983967

Epoch: 5| Step: 7
Training loss: 0.9853237867355347
Validation loss: 1.9340507090091705

Epoch: 5| Step: 8
Training loss: 0.8384860754013062
Validation loss: 1.974129815896352

Epoch: 5| Step: 9
Training loss: 0.4566446840763092
Validation loss: 1.9139943967262905

Epoch: 5| Step: 10
Training loss: 0.6834264993667603
Validation loss: 1.9143851796785991

Epoch: 5| Step: 11
Training loss: 0.49157875776290894
Validation loss: 1.8950805713733037

Epoch: 205| Step: 0
Training loss: 0.7504774928092957
Validation loss: 1.9298157195250194

Epoch: 5| Step: 1
Training loss: 0.8484377861022949
Validation loss: 1.9845436016718547

Epoch: 5| Step: 2
Training loss: 0.4383201599121094
Validation loss: 1.9185571173826854

Epoch: 5| Step: 3
Training loss: 0.43649643659591675
Validation loss: 1.9481488764286041

Epoch: 5| Step: 4
Training loss: 0.9147012829780579
Validation loss: 2.0048932085434594

Epoch: 5| Step: 5
Training loss: 0.9812046885490417
Validation loss: 2.02134237686793

Epoch: 5| Step: 6
Training loss: 0.827934741973877
Validation loss: 2.037369797627131

Epoch: 5| Step: 7
Training loss: 0.8302448987960815
Validation loss: 2.0400506258010864

Epoch: 5| Step: 8
Training loss: 0.8555191159248352
Validation loss: 1.9613735030094783

Epoch: 5| Step: 9
Training loss: 0.6242292523384094
Validation loss: 1.8910293330748875

Epoch: 5| Step: 10
Training loss: 0.387539803981781
Validation loss: 1.8894007255633671

Epoch: 5| Step: 11
Training loss: 1.2568355798721313
Validation loss: 1.892895023028056

Epoch: 206| Step: 0
Training loss: 0.7011865377426147
Validation loss: 1.9361917525529861

Epoch: 5| Step: 1
Training loss: 0.653062641620636
Validation loss: 1.8999196738004684

Epoch: 5| Step: 2
Training loss: 0.5520644783973694
Validation loss: 1.944774940609932

Epoch: 5| Step: 3
Training loss: 0.4946576952934265
Validation loss: 1.9512547999620438

Epoch: 5| Step: 4
Training loss: 1.1900529861450195
Validation loss: 1.93753678103288

Epoch: 5| Step: 5
Training loss: 0.9286322593688965
Validation loss: 2.0447998394568763

Epoch: 5| Step: 6
Training loss: 0.7263825535774231
Validation loss: 2.0161889443794885

Epoch: 5| Step: 7
Training loss: 0.8011166453361511
Validation loss: 1.9839011530081432

Epoch: 5| Step: 8
Training loss: 0.6037977933883667
Validation loss: 1.9589202503363292

Epoch: 5| Step: 9
Training loss: 0.8466470837593079
Validation loss: 1.9344174712896347

Epoch: 5| Step: 10
Training loss: 0.8333978652954102
Validation loss: 1.9223279257615407

Epoch: 5| Step: 11
Training loss: 0.5350843667984009
Validation loss: 1.9274715433518093

Epoch: 207| Step: 0
Training loss: 0.5366758108139038
Validation loss: 1.8974453310171764

Epoch: 5| Step: 1
Training loss: 1.0842564105987549
Validation loss: 1.9530681173006694

Epoch: 5| Step: 2
Training loss: 0.6090449094772339
Validation loss: 1.9580497046311696

Epoch: 5| Step: 3
Training loss: 0.6330323219299316
Validation loss: 2.002011403441429

Epoch: 5| Step: 4
Training loss: 0.6495357751846313
Validation loss: 1.9301885962486267

Epoch: 5| Step: 5
Training loss: 0.7748208045959473
Validation loss: 1.9585119585196178

Epoch: 5| Step: 6
Training loss: 0.8748283386230469
Validation loss: 1.968577653169632

Epoch: 5| Step: 7
Training loss: 0.4117370545864105
Validation loss: 1.8879214177529018

Epoch: 5| Step: 8
Training loss: 0.7541844248771667
Validation loss: 1.9335506707429886

Epoch: 5| Step: 9
Training loss: 0.8477628827095032
Validation loss: 1.983462154865265

Epoch: 5| Step: 10
Training loss: 0.516211986541748
Validation loss: 1.9587370306253433

Epoch: 5| Step: 11
Training loss: 0.34053540229797363
Validation loss: 1.9108090847730637

Epoch: 208| Step: 0
Training loss: 0.5699159502983093
Validation loss: 1.971092517177264

Epoch: 5| Step: 1
Training loss: 0.7448598742485046
Validation loss: 1.9776470760504405

Epoch: 5| Step: 2
Training loss: 0.6534802317619324
Validation loss: 1.943801388144493

Epoch: 5| Step: 3
Training loss: 0.5481901168823242
Validation loss: 1.9745626598596573

Epoch: 5| Step: 4
Training loss: 0.8263788223266602
Validation loss: 1.962840422987938

Epoch: 5| Step: 5
Training loss: 0.7978655099868774
Validation loss: 1.9877762099107106

Epoch: 5| Step: 6
Training loss: 0.6249281764030457
Validation loss: 1.975788488984108

Epoch: 5| Step: 7
Training loss: 0.5746065378189087
Validation loss: 1.9267720977465312

Epoch: 5| Step: 8
Training loss: 0.7502321004867554
Validation loss: 1.972656379143397

Epoch: 5| Step: 9
Training loss: 0.47216111421585083
Validation loss: 1.9760448386271794

Epoch: 5| Step: 10
Training loss: 0.889171302318573
Validation loss: 1.967741350332896

Epoch: 5| Step: 11
Training loss: 0.7193388938903809
Validation loss: 1.9074281007051468

Epoch: 209| Step: 0
Training loss: 0.8680232763290405
Validation loss: 1.9851052463054657

Epoch: 5| Step: 1
Training loss: 1.204899549484253
Validation loss: 1.944907193382581

Epoch: 5| Step: 2
Training loss: 0.4226346015930176
Validation loss: 1.9854835470517476

Epoch: 5| Step: 3
Training loss: 0.8481184244155884
Validation loss: 1.944116622209549

Epoch: 5| Step: 4
Training loss: 0.3682321012020111
Validation loss: 1.9179587165514629

Epoch: 5| Step: 5
Training loss: 0.46954044699668884
Validation loss: 1.9341726352771123

Epoch: 5| Step: 6
Training loss: 0.3835661709308624
Validation loss: 1.9358119666576385

Epoch: 5| Step: 7
Training loss: 0.8007755279541016
Validation loss: 1.9058426916599274

Epoch: 5| Step: 8
Training loss: 0.6205667853355408
Validation loss: 1.9491547892491023

Epoch: 5| Step: 9
Training loss: 0.6639591455459595
Validation loss: 1.9482458233833313

Epoch: 5| Step: 10
Training loss: 0.7826861143112183
Validation loss: 1.9963268836339314

Epoch: 5| Step: 11
Training loss: 1.1824337244033813
Validation loss: 1.9899075329303741

Epoch: 210| Step: 0
Training loss: 0.230801060795784
Validation loss: 1.9653531809647877

Epoch: 5| Step: 1
Training loss: 0.8148559331893921
Validation loss: 2.006532371044159

Epoch: 5| Step: 2
Training loss: 1.2654842138290405
Validation loss: 1.9649355709552765

Epoch: 5| Step: 3
Training loss: 0.9504073262214661
Validation loss: 2.0371942619482675

Epoch: 5| Step: 4
Training loss: 0.8153748512268066
Validation loss: 2.002164532740911

Epoch: 5| Step: 5
Training loss: 0.5051673650741577
Validation loss: 1.9652599891026814

Epoch: 5| Step: 6
Training loss: 0.5877377986907959
Validation loss: 2.004954049984614

Epoch: 5| Step: 7
Training loss: 0.735123336315155
Validation loss: 1.9027204066514969

Epoch: 5| Step: 8
Training loss: 0.6827402114868164
Validation loss: 1.9621663838624954

Epoch: 5| Step: 9
Training loss: 0.6753612756729126
Validation loss: 2.003904784719149

Epoch: 5| Step: 10
Training loss: 0.7535448670387268
Validation loss: 1.9814767241477966

Epoch: 5| Step: 11
Training loss: 0.32669949531555176
Validation loss: 2.0098788340886435

Epoch: 211| Step: 0
Training loss: 0.4325118064880371
Validation loss: 2.029382199048996

Epoch: 5| Step: 1
Training loss: 0.5219758152961731
Validation loss: 1.9504729708035786

Epoch: 5| Step: 2
Training loss: 0.6428884267807007
Validation loss: 1.9389645159244537

Epoch: 5| Step: 3
Training loss: 0.8030710220336914
Validation loss: 1.9213649133841197

Epoch: 5| Step: 4
Training loss: 0.5741733312606812
Validation loss: 1.9684328734874725

Epoch: 5| Step: 5
Training loss: 0.9120351672172546
Validation loss: 1.979456792275111

Epoch: 5| Step: 6
Training loss: 0.4874706268310547
Validation loss: 1.9955432564020157

Epoch: 5| Step: 7
Training loss: 1.1743837594985962
Validation loss: 2.0169484863678613

Epoch: 5| Step: 8
Training loss: 0.4499847888946533
Validation loss: 2.0221019834280014

Epoch: 5| Step: 9
Training loss: 0.7835405468940735
Validation loss: 1.9566794633865356

Epoch: 5| Step: 10
Training loss: 1.0916218757629395
Validation loss: 1.9761687964200974

Epoch: 5| Step: 11
Training loss: 0.31729692220687866
Validation loss: 2.000635415315628

Epoch: 212| Step: 0
Training loss: 0.311475932598114
Validation loss: 1.9325684706370037

Epoch: 5| Step: 1
Training loss: 0.6542106866836548
Validation loss: 1.9877085089683533

Epoch: 5| Step: 2
Training loss: 0.8754295110702515
Validation loss: 1.935629149278005

Epoch: 5| Step: 3
Training loss: 1.0051296949386597
Validation loss: 1.9408413916826248

Epoch: 5| Step: 4
Training loss: 0.5979341864585876
Validation loss: 1.9031942735115688

Epoch: 5| Step: 5
Training loss: 0.7206528782844543
Validation loss: 1.9473142176866531

Epoch: 5| Step: 6
Training loss: 0.6402913928031921
Validation loss: 1.900382990638415

Epoch: 5| Step: 7
Training loss: 0.6205726861953735
Validation loss: 2.01149574915568

Epoch: 5| Step: 8
Training loss: 0.6035773158073425
Validation loss: 2.0000712474187217

Epoch: 5| Step: 9
Training loss: 0.6629896759986877
Validation loss: 1.9691167026758194

Epoch: 5| Step: 10
Training loss: 0.9873459935188293
Validation loss: 1.9320296545823414

Epoch: 5| Step: 11
Training loss: 0.15413931012153625
Validation loss: 1.9050240019957225

Epoch: 213| Step: 0
Training loss: 0.44368767738342285
Validation loss: 1.9844459642966588

Epoch: 5| Step: 1
Training loss: 0.7181111574172974
Validation loss: 1.934910108645757

Epoch: 5| Step: 2
Training loss: 0.5426207184791565
Validation loss: 1.9480377386013668

Epoch: 5| Step: 3
Training loss: 0.3909247815608978
Validation loss: 1.9360971252123516

Epoch: 5| Step: 4
Training loss: 0.8165234327316284
Validation loss: 1.914459024866422

Epoch: 5| Step: 5
Training loss: 0.569165050983429
Validation loss: 1.892039105296135

Epoch: 5| Step: 6
Training loss: 0.9172710180282593
Validation loss: 1.949945201476415

Epoch: 5| Step: 7
Training loss: 1.134054183959961
Validation loss: 1.9501017679770787

Epoch: 5| Step: 8
Training loss: 0.608996570110321
Validation loss: 1.9526891907056172

Epoch: 5| Step: 9
Training loss: 0.7259261012077332
Validation loss: 1.9395949443181355

Epoch: 5| Step: 10
Training loss: 0.5819253921508789
Validation loss: 1.8744283318519592

Epoch: 5| Step: 11
Training loss: 0.2349867820739746
Validation loss: 1.9359151273965836

Epoch: 214| Step: 0
Training loss: 0.34760791063308716
Validation loss: 1.9560728718837102

Epoch: 5| Step: 1
Training loss: 0.947546124458313
Validation loss: 1.9294299532969792

Epoch: 5| Step: 2
Training loss: 0.4506508708000183
Validation loss: 1.9303286721309025

Epoch: 5| Step: 3
Training loss: 0.49549445509910583
Validation loss: 1.9723274012406666

Epoch: 5| Step: 4
Training loss: 0.49618759751319885
Validation loss: 1.9718391448259354

Epoch: 5| Step: 5
Training loss: 0.618044912815094
Validation loss: 1.950956791639328

Epoch: 5| Step: 6
Training loss: 0.5927600264549255
Validation loss: 1.9417643894751866

Epoch: 5| Step: 7
Training loss: 0.8189326524734497
Validation loss: 1.9297826538483303

Epoch: 5| Step: 8
Training loss: 0.8330044746398926
Validation loss: 1.9172341724236805

Epoch: 5| Step: 9
Training loss: 1.0883502960205078
Validation loss: 1.9494796593983967

Epoch: 5| Step: 10
Training loss: 0.5944541692733765
Validation loss: 1.9191816300153732

Epoch: 5| Step: 11
Training loss: 1.313162088394165
Validation loss: 1.9160537372032802

Epoch: 215| Step: 0
Training loss: 0.7031679153442383
Validation loss: 1.9577641586462657

Epoch: 5| Step: 1
Training loss: 0.3078170716762543
Validation loss: 1.9940822372833888

Epoch: 5| Step: 2
Training loss: 0.5293429493904114
Validation loss: 1.9351311326026917

Epoch: 5| Step: 3
Training loss: 0.5241696834564209
Validation loss: 1.9560621231794357

Epoch: 5| Step: 4
Training loss: 0.680637001991272
Validation loss: 1.9235205352306366

Epoch: 5| Step: 5
Training loss: 0.6123680472373962
Validation loss: 1.9766266842683156

Epoch: 5| Step: 6
Training loss: 0.8416124582290649
Validation loss: 1.996725747982661

Epoch: 5| Step: 7
Training loss: 0.8418971300125122
Validation loss: 1.937768464287122

Epoch: 5| Step: 8
Training loss: 0.41341477632522583
Validation loss: 1.9693562785784404

Epoch: 5| Step: 9
Training loss: 0.7141422033309937
Validation loss: 1.9429120868444443

Epoch: 5| Step: 10
Training loss: 1.1121852397918701
Validation loss: 1.9246548066536586

Epoch: 5| Step: 11
Training loss: 0.7680124044418335
Validation loss: 1.9136988669633865

Epoch: 216| Step: 0
Training loss: 0.5939710736274719
Validation loss: 1.9108364135026932

Epoch: 5| Step: 1
Training loss: 0.3314116299152374
Validation loss: 1.993140920996666

Epoch: 5| Step: 2
Training loss: 0.5748216509819031
Validation loss: 1.9214495420455933

Epoch: 5| Step: 3
Training loss: 0.9335615038871765
Validation loss: 1.95774840315183

Epoch: 5| Step: 4
Training loss: 0.6969634890556335
Validation loss: 1.9480555603901546

Epoch: 5| Step: 5
Training loss: 0.4010263979434967
Validation loss: 1.945227821667989

Epoch: 5| Step: 6
Training loss: 0.7928882837295532
Validation loss: 1.956651856501897

Epoch: 5| Step: 7
Training loss: 0.769576907157898
Validation loss: 2.0164323101441064

Epoch: 5| Step: 8
Training loss: 0.6895578503608704
Validation loss: 1.9756188293298085

Epoch: 5| Step: 9
Training loss: 0.7694493532180786
Validation loss: 1.9686974833408992

Epoch: 5| Step: 10
Training loss: 0.6259654760360718
Validation loss: 1.9547996272643406

Epoch: 5| Step: 11
Training loss: 0.5742870569229126
Validation loss: 1.96965395907561

Epoch: 217| Step: 0
Training loss: 0.4738447070121765
Validation loss: 1.9937680661678314

Epoch: 5| Step: 1
Training loss: 0.6513351798057556
Validation loss: 1.9539266626040142

Epoch: 5| Step: 2
Training loss: 0.48773831129074097
Validation loss: 2.013844052950541

Epoch: 5| Step: 3
Training loss: 1.0414941310882568
Validation loss: 1.983810931444168

Epoch: 5| Step: 4
Training loss: 0.7747525572776794
Validation loss: 2.0235762347777686

Epoch: 5| Step: 5
Training loss: 0.8175750970840454
Validation loss: 2.0190565834442773

Epoch: 5| Step: 6
Training loss: 0.9546843767166138
Validation loss: 1.9608622292677562

Epoch: 5| Step: 7
Training loss: 0.3964013457298279
Validation loss: 2.010970562696457

Epoch: 5| Step: 8
Training loss: 0.6322698593139648
Validation loss: 1.9109565218289692

Epoch: 5| Step: 9
Training loss: 0.5237796902656555
Validation loss: 1.9338304251432419

Epoch: 5| Step: 10
Training loss: 0.7505263686180115
Validation loss: 1.928803190588951

Epoch: 5| Step: 11
Training loss: 0.8224223256111145
Validation loss: 1.9480199267466862

Epoch: 218| Step: 0
Training loss: 0.687263011932373
Validation loss: 1.919790541132291

Epoch: 5| Step: 1
Training loss: 0.455134779214859
Validation loss: 1.9473792264858882

Epoch: 5| Step: 2
Training loss: 0.7909982204437256
Validation loss: 1.9610492289066315

Epoch: 5| Step: 3
Training loss: 0.33484187722206116
Validation loss: 1.9302706718444824

Epoch: 5| Step: 4
Training loss: 0.5544518232345581
Validation loss: 1.9260226041078568

Epoch: 5| Step: 5
Training loss: 0.4390106797218323
Validation loss: 1.9639437794685364

Epoch: 5| Step: 6
Training loss: 0.658737301826477
Validation loss: 1.974005823334058

Epoch: 5| Step: 7
Training loss: 0.37809258699417114
Validation loss: 2.0117804606755576

Epoch: 5| Step: 8
Training loss: 0.4987519681453705
Validation loss: 2.0284074743588767

Epoch: 5| Step: 9
Training loss: 1.3328006267547607
Validation loss: 1.9853710780541103

Epoch: 5| Step: 10
Training loss: 0.8153931498527527
Validation loss: 1.9419860144456227

Epoch: 5| Step: 11
Training loss: 1.1215420961380005
Validation loss: 1.9717930207649867

Epoch: 219| Step: 0
Training loss: 0.5331110954284668
Validation loss: 1.9610345164934795

Epoch: 5| Step: 1
Training loss: 0.524081826210022
Validation loss: 1.9952926288048427

Epoch: 5| Step: 2
Training loss: 0.9782235026359558
Validation loss: 1.965001677473386

Epoch: 5| Step: 3
Training loss: 0.37606003880500793
Validation loss: 1.9240471869707108

Epoch: 5| Step: 4
Training loss: 0.5395077466964722
Validation loss: 1.941385641694069

Epoch: 5| Step: 5
Training loss: 0.7109695672988892
Validation loss: 1.9774931917587917

Epoch: 5| Step: 6
Training loss: 0.43698206543922424
Validation loss: 1.9705972969532013

Epoch: 5| Step: 7
Training loss: 0.6220295429229736
Validation loss: 1.9938921829064686

Epoch: 5| Step: 8
Training loss: 0.6778334975242615
Validation loss: 1.9642595946788788

Epoch: 5| Step: 9
Training loss: 0.7753868699073792
Validation loss: 1.9611946940422058

Epoch: 5| Step: 10
Training loss: 0.9477415084838867
Validation loss: 1.9826522966225941

Epoch: 5| Step: 11
Training loss: 0.7308434844017029
Validation loss: 1.9819113264481227

Epoch: 220| Step: 0
Training loss: 0.40461158752441406
Validation loss: 2.0010330776373544

Epoch: 5| Step: 1
Training loss: 0.6200662851333618
Validation loss: 1.9165396342674892

Epoch: 5| Step: 2
Training loss: 0.5386766195297241
Validation loss: 1.9518784979979198

Epoch: 5| Step: 3
Training loss: 1.0879642963409424
Validation loss: 1.94084732234478

Epoch: 5| Step: 4
Training loss: 0.7711213231086731
Validation loss: 1.9684479137261708

Epoch: 5| Step: 5
Training loss: 0.6946955919265747
Validation loss: 1.972237691283226

Epoch: 5| Step: 6
Training loss: 0.7421711683273315
Validation loss: 1.9697427054246266

Epoch: 5| Step: 7
Training loss: 0.970406711101532
Validation loss: 1.972174808382988

Epoch: 5| Step: 8
Training loss: 0.5778582096099854
Validation loss: 1.9655932933092117

Epoch: 5| Step: 9
Training loss: 0.558982253074646
Validation loss: 1.9366061091423035

Epoch: 5| Step: 10
Training loss: 0.2682580053806305
Validation loss: 1.9103395144144695

Epoch: 5| Step: 11
Training loss: 0.685135543346405
Validation loss: 1.945488433043162

Epoch: 221| Step: 0
Training loss: 1.236077070236206
Validation loss: 1.9156564474105835

Epoch: 5| Step: 1
Training loss: 0.5190899968147278
Validation loss: 1.9144274691740673

Epoch: 5| Step: 2
Training loss: 0.7090803384780884
Validation loss: 1.8793149441480637

Epoch: 5| Step: 3
Training loss: 0.5018630027770996
Validation loss: 1.9395313610633214

Epoch: 5| Step: 4
Training loss: 0.5171116590499878
Validation loss: 1.9558643500010173

Epoch: 5| Step: 5
Training loss: 0.5926170349121094
Validation loss: 1.961605578660965

Epoch: 5| Step: 6
Training loss: 0.5922316312789917
Validation loss: 2.0292246689399085

Epoch: 5| Step: 7
Training loss: 0.589826226234436
Validation loss: 1.9364757587512333

Epoch: 5| Step: 8
Training loss: 0.6634113192558289
Validation loss: 1.9197461009025574

Epoch: 5| Step: 9
Training loss: 0.7675992250442505
Validation loss: 1.9400420437256496

Epoch: 5| Step: 10
Training loss: 0.5542519092559814
Validation loss: 1.928572381536166

Epoch: 5| Step: 11
Training loss: 0.33609700202941895
Validation loss: 1.905340055624644

Epoch: 222| Step: 0
Training loss: 0.46225088834762573
Validation loss: 1.9595254957675934

Epoch: 5| Step: 1
Training loss: 0.46477586030960083
Validation loss: 1.928104430437088

Epoch: 5| Step: 2
Training loss: 0.7192631959915161
Validation loss: 2.041263302167257

Epoch: 5| Step: 3
Training loss: 0.7716367840766907
Validation loss: 2.0179308354854584

Epoch: 5| Step: 4
Training loss: 0.781076192855835
Validation loss: 1.9463316599527996

Epoch: 5| Step: 5
Training loss: 0.6629272699356079
Validation loss: 1.9427415033181508

Epoch: 5| Step: 6
Training loss: 0.4795052409172058
Validation loss: 1.919629658261935

Epoch: 5| Step: 7
Training loss: 0.6498324871063232
Validation loss: 1.8916385074456532

Epoch: 5| Step: 8
Training loss: 0.9202664494514465
Validation loss: 1.9165920068820317

Epoch: 5| Step: 9
Training loss: 0.7677503228187561
Validation loss: 1.9101402809222539

Epoch: 5| Step: 10
Training loss: 0.9701492190361023
Validation loss: 1.936702698469162

Epoch: 5| Step: 11
Training loss: 0.8905022144317627
Validation loss: 1.9725168695052464

Epoch: 223| Step: 0
Training loss: 0.35039812326431274
Validation loss: 1.903024231394132

Epoch: 5| Step: 1
Training loss: 0.7572444081306458
Validation loss: 1.9643856783707936

Epoch: 5| Step: 2
Training loss: 0.35952064394950867
Validation loss: 1.9253664761781693

Epoch: 5| Step: 3
Training loss: 0.3394988775253296
Validation loss: 1.9676875720421474

Epoch: 5| Step: 4
Training loss: 0.8179589509963989
Validation loss: 2.0101174265146255

Epoch: 5| Step: 5
Training loss: 0.8716179728507996
Validation loss: 2.0350325306256614

Epoch: 5| Step: 6
Training loss: 0.36381539702415466
Validation loss: 1.9945652335882187

Epoch: 5| Step: 7
Training loss: 0.7409082651138306
Validation loss: 1.9547494053840637

Epoch: 5| Step: 8
Training loss: 0.5190941095352173
Validation loss: 1.9357692350943883

Epoch: 5| Step: 9
Training loss: 0.7514311075210571
Validation loss: 1.9013962596654892

Epoch: 5| Step: 10
Training loss: 0.6415090560913086
Validation loss: 1.9032845397790272

Epoch: 5| Step: 11
Training loss: 2.301914930343628
Validation loss: 1.9308797468741734

Epoch: 224| Step: 0
Training loss: 0.6296111345291138
Validation loss: 1.9236716876427333

Epoch: 5| Step: 1
Training loss: 0.5401865243911743
Validation loss: 1.9349526514609654

Epoch: 5| Step: 2
Training loss: 0.4980026185512543
Validation loss: 1.949748456478119

Epoch: 5| Step: 3
Training loss: 0.8548533320426941
Validation loss: 2.009262442588806

Epoch: 5| Step: 4
Training loss: 0.5728214383125305
Validation loss: 1.9716850817203522

Epoch: 5| Step: 5
Training loss: 0.7967535257339478
Validation loss: 1.9356032659610112

Epoch: 5| Step: 6
Training loss: 0.4058884084224701
Validation loss: 1.8820997575918834

Epoch: 5| Step: 7
Training loss: 0.7656171917915344
Validation loss: 1.9157335261503856

Epoch: 5| Step: 8
Training loss: 0.5124865174293518
Validation loss: 1.9341184745232265

Epoch: 5| Step: 9
Training loss: 0.4215947091579437
Validation loss: 1.8992696503798168

Epoch: 5| Step: 10
Training loss: 0.7418082356452942
Validation loss: 1.8962145745754242

Epoch: 5| Step: 11
Training loss: 0.8986791968345642
Validation loss: 1.9293118168910344

Epoch: 225| Step: 0
Training loss: 0.5252407193183899
Validation loss: 1.9549771696329117

Epoch: 5| Step: 1
Training loss: 0.4122501313686371
Validation loss: 1.944516271352768

Epoch: 5| Step: 2
Training loss: 0.7958405017852783
Validation loss: 1.9281419664621353

Epoch: 5| Step: 3
Training loss: 0.6979873776435852
Validation loss: 1.9113547156254451

Epoch: 5| Step: 4
Training loss: 0.5503082871437073
Validation loss: 1.9384697129329045

Epoch: 5| Step: 5
Training loss: 0.8702112436294556
Validation loss: 1.9211169232924779

Epoch: 5| Step: 6
Training loss: 0.8986707925796509
Validation loss: 1.9571810215711594

Epoch: 5| Step: 7
Training loss: 0.31705838441848755
Validation loss: 1.9727006355921428

Epoch: 5| Step: 8
Training loss: 0.5579334497451782
Validation loss: 2.0104181369145713

Epoch: 5| Step: 9
Training loss: 0.7513037919998169
Validation loss: 1.9576194882392883

Epoch: 5| Step: 10
Training loss: 0.4878475069999695
Validation loss: 1.9346646318833034

Epoch: 5| Step: 11
Training loss: 0.3015722632408142
Validation loss: 1.9063565532366435

Epoch: 226| Step: 0
Training loss: 0.3801819086074829
Validation loss: 1.9441568950812023

Epoch: 5| Step: 1
Training loss: 0.7238231897354126
Validation loss: 1.9927496413389842

Epoch: 5| Step: 2
Training loss: 0.7874786257743835
Validation loss: 1.9411604702472687

Epoch: 5| Step: 3
Training loss: 0.6450928449630737
Validation loss: 2.0453673750162125

Epoch: 5| Step: 4
Training loss: 0.7195798754692078
Validation loss: 1.9793301969766617

Epoch: 5| Step: 5
Training loss: 0.8098145723342896
Validation loss: 2.020555168390274

Epoch: 5| Step: 6
Training loss: 0.7949311137199402
Validation loss: 1.9737114409605663

Epoch: 5| Step: 7
Training loss: 0.6078901290893555
Validation loss: 1.9758938749631245

Epoch: 5| Step: 8
Training loss: 0.6019039750099182
Validation loss: 1.9938044647375743

Epoch: 5| Step: 9
Training loss: 0.5299211144447327
Validation loss: 1.9229024350643158

Epoch: 5| Step: 10
Training loss: 0.4310951232910156
Validation loss: 1.914192443092664

Epoch: 5| Step: 11
Training loss: 1.0952039957046509
Validation loss: 1.9165828675031662

Epoch: 227| Step: 0
Training loss: 0.5425226092338562
Validation loss: 1.9263134648402531

Epoch: 5| Step: 1
Training loss: 0.3021914064884186
Validation loss: 1.921095535159111

Epoch: 5| Step: 2
Training loss: 1.0035254955291748
Validation loss: 1.9381671100854874

Epoch: 5| Step: 3
Training loss: 0.4155183732509613
Validation loss: 1.9798976629972458

Epoch: 5| Step: 4
Training loss: 0.5980309844017029
Validation loss: 1.974926397204399

Epoch: 5| Step: 5
Training loss: 1.1499836444854736
Validation loss: 1.967640181382497

Epoch: 5| Step: 6
Training loss: 0.5677756071090698
Validation loss: 1.942305400967598

Epoch: 5| Step: 7
Training loss: 0.5077118277549744
Validation loss: 1.971376712123553

Epoch: 5| Step: 8
Training loss: 0.6810811758041382
Validation loss: 1.9987733115752537

Epoch: 5| Step: 9
Training loss: 0.5076622366905212
Validation loss: 1.9949633131424587

Epoch: 5| Step: 10
Training loss: 0.5255536437034607
Validation loss: 1.9314525077740352

Epoch: 5| Step: 11
Training loss: 1.1101889610290527
Validation loss: 1.948250984152158

Epoch: 228| Step: 0
Training loss: 1.029840111732483
Validation loss: 1.9280256927013397

Epoch: 5| Step: 1
Training loss: 0.686246395111084
Validation loss: 1.9286886304616928

Epoch: 5| Step: 2
Training loss: 0.4979557394981384
Validation loss: 1.9569167892138164

Epoch: 5| Step: 3
Training loss: 0.7155743837356567
Validation loss: 1.9736855725447338

Epoch: 5| Step: 4
Training loss: 0.6923202276229858
Validation loss: 1.9685068875551224

Epoch: 5| Step: 5
Training loss: 0.524310827255249
Validation loss: 2.001213784019152

Epoch: 5| Step: 6
Training loss: 0.6176875829696655
Validation loss: 1.9609496345122654

Epoch: 5| Step: 7
Training loss: 0.6855210065841675
Validation loss: 1.9790537655353546

Epoch: 5| Step: 8
Training loss: 0.36651936173439026
Validation loss: 1.997524271408717

Epoch: 5| Step: 9
Training loss: 0.3914969265460968
Validation loss: 1.980908344189326

Epoch: 5| Step: 10
Training loss: 0.4825211465358734
Validation loss: 1.9454995940128963

Epoch: 5| Step: 11
Training loss: 0.6570713520050049
Validation loss: 1.980639820297559

Epoch: 229| Step: 0
Training loss: 0.5945794582366943
Validation loss: 1.9882911145687103

Epoch: 5| Step: 1
Training loss: 0.8362358808517456
Validation loss: 1.9577833811442058

Epoch: 5| Step: 2
Training loss: 0.595695436000824
Validation loss: 2.0148169497648873

Epoch: 5| Step: 3
Training loss: 0.4745566248893738
Validation loss: 2.0032006949186325

Epoch: 5| Step: 4
Training loss: 0.5661629438400269
Validation loss: 2.0423709601163864

Epoch: 5| Step: 5
Training loss: 0.6785439252853394
Validation loss: 1.9726427495479584

Epoch: 5| Step: 6
Training loss: 0.35858768224716187
Validation loss: 1.9945056786139805

Epoch: 5| Step: 7
Training loss: 0.6346220374107361
Validation loss: 1.9899926433960597

Epoch: 5| Step: 8
Training loss: 0.6731975674629211
Validation loss: 2.0083660185337067

Epoch: 5| Step: 9
Training loss: 0.7020313739776611
Validation loss: 1.9462565978368123

Epoch: 5| Step: 10
Training loss: 0.46615439653396606
Validation loss: 2.004032293955485

Epoch: 5| Step: 11
Training loss: 0.7351582646369934
Validation loss: 1.9543298383553822

Epoch: 230| Step: 0
Training loss: 0.4748605787754059
Validation loss: 2.032530759771665

Epoch: 5| Step: 1
Training loss: 0.5626648664474487
Validation loss: 1.9950714508692424

Epoch: 5| Step: 2
Training loss: 0.9384457468986511
Validation loss: 1.9756167779366176

Epoch: 5| Step: 3
Training loss: 0.4618164002895355
Validation loss: 1.9564060221115749

Epoch: 5| Step: 4
Training loss: 0.27839919924736023
Validation loss: 1.98862328628699

Epoch: 5| Step: 5
Training loss: 0.3236690163612366
Validation loss: 1.9154620915651321

Epoch: 5| Step: 6
Training loss: 0.6736388206481934
Validation loss: 1.956928347547849

Epoch: 5| Step: 7
Training loss: 0.6872242093086243
Validation loss: 1.9584266344706218

Epoch: 5| Step: 8
Training loss: 0.6017240881919861
Validation loss: 1.9763467659552891

Epoch: 5| Step: 9
Training loss: 0.7234548330307007
Validation loss: 1.9149137288331985

Epoch: 5| Step: 10
Training loss: 0.6728246808052063
Validation loss: 2.016608571012815

Epoch: 5| Step: 11
Training loss: 0.3785581588745117
Validation loss: 1.9957586129506428

Epoch: 231| Step: 0
Training loss: 0.320949912071228
Validation loss: 1.9148539652427037

Epoch: 5| Step: 1
Training loss: 0.3615562617778778
Validation loss: 1.9524515171845753

Epoch: 5| Step: 2
Training loss: 0.8136266469955444
Validation loss: 1.9483730842669804

Epoch: 5| Step: 3
Training loss: 0.9743474721908569
Validation loss: 1.9727775305509567

Epoch: 5| Step: 4
Training loss: 0.6049555540084839
Validation loss: 1.9313331991434097

Epoch: 5| Step: 5
Training loss: 0.906175971031189
Validation loss: 1.9073679149150848

Epoch: 5| Step: 6
Training loss: 0.5294370651245117
Validation loss: 1.9170372188091278

Epoch: 5| Step: 7
Training loss: 0.674900233745575
Validation loss: 1.9880603849887848

Epoch: 5| Step: 8
Training loss: 0.6330603361129761
Validation loss: 1.9855750600496929

Epoch: 5| Step: 9
Training loss: 0.7389834523200989
Validation loss: 1.974767620364825

Epoch: 5| Step: 10
Training loss: 0.7734988927841187
Validation loss: 1.9902812639872234

Epoch: 5| Step: 11
Training loss: 0.5693268775939941
Validation loss: 2.0222228467464447

Epoch: 232| Step: 0
Training loss: 0.7707432508468628
Validation loss: 1.9757115791241329

Epoch: 5| Step: 1
Training loss: 0.30385762453079224
Validation loss: 1.9526815017064412

Epoch: 5| Step: 2
Training loss: 0.4081669747829437
Validation loss: 1.9293479522069295

Epoch: 5| Step: 3
Training loss: 0.8164887428283691
Validation loss: 1.942390243212382

Epoch: 5| Step: 4
Training loss: 0.8010963201522827
Validation loss: 1.944784755508105

Epoch: 5| Step: 5
Training loss: 0.6393749117851257
Validation loss: 1.899643709262212

Epoch: 5| Step: 6
Training loss: 0.6912086606025696
Validation loss: 1.9449137051900227

Epoch: 5| Step: 7
Training loss: 0.5511473417282104
Validation loss: 1.9604050666093826

Epoch: 5| Step: 8
Training loss: 0.5800285339355469
Validation loss: 1.9673378815253575

Epoch: 5| Step: 9
Training loss: 0.44830846786499023
Validation loss: 1.9538198212782543

Epoch: 5| Step: 10
Training loss: 0.7253026962280273
Validation loss: 1.9873468826214473

Epoch: 5| Step: 11
Training loss: 0.20619133114814758
Validation loss: 1.9522201369206111

Epoch: 233| Step: 0
Training loss: 0.43535929918289185
Validation loss: 1.9525337169567745

Epoch: 5| Step: 1
Training loss: 0.6503263115882874
Validation loss: 1.9411564071973164

Epoch: 5| Step: 2
Training loss: 0.43130120635032654
Validation loss: 1.9913304646809895

Epoch: 5| Step: 3
Training loss: 0.44471511244773865
Validation loss: 1.9929657131433487

Epoch: 5| Step: 4
Training loss: 0.5644290447235107
Validation loss: 1.9322697669267654

Epoch: 5| Step: 5
Training loss: 0.7046272158622742
Validation loss: 1.9510714660088222

Epoch: 5| Step: 6
Training loss: 0.6105947494506836
Validation loss: 1.9688487549622853

Epoch: 5| Step: 7
Training loss: 0.4046235978603363
Validation loss: 1.9465979784727097

Epoch: 5| Step: 8
Training loss: 0.6146268844604492
Validation loss: 1.9433423280715942

Epoch: 5| Step: 9
Training loss: 0.9069541692733765
Validation loss: 1.8593516647815704

Epoch: 5| Step: 10
Training loss: 0.5458842515945435
Validation loss: 1.920237233241399

Epoch: 5| Step: 11
Training loss: 0.7507750988006592
Validation loss: 1.9895261873801549

Epoch: 234| Step: 0
Training loss: 0.9566361308097839
Validation loss: 2.0230594923098884

Epoch: 5| Step: 1
Training loss: 0.5031917691230774
Validation loss: 1.9644699643055599

Epoch: 5| Step: 2
Training loss: 0.5656369924545288
Validation loss: 1.998095100124677

Epoch: 5| Step: 3
Training loss: 0.4929965138435364
Validation loss: 1.990611657500267

Epoch: 5| Step: 4
Training loss: 0.5325345396995544
Validation loss: 1.9482162147760391

Epoch: 5| Step: 5
Training loss: 0.5648386478424072
Validation loss: 1.9286468227704365

Epoch: 5| Step: 6
Training loss: 0.6653443574905396
Validation loss: 1.9074207544326782

Epoch: 5| Step: 7
Training loss: 0.7054823637008667
Validation loss: 1.9841494659582775

Epoch: 5| Step: 8
Training loss: 0.5880286693572998
Validation loss: 1.9244830906391144

Epoch: 5| Step: 9
Training loss: 0.5494892001152039
Validation loss: 1.9216696669658024

Epoch: 5| Step: 10
Training loss: 0.683821976184845
Validation loss: 1.9181701441605885

Epoch: 5| Step: 11
Training loss: 0.40617480874061584
Validation loss: 1.9359216541051865

Epoch: 235| Step: 0
Training loss: 0.8899628520011902
Validation loss: 1.9728033939997356

Epoch: 5| Step: 1
Training loss: 0.47288018465042114
Validation loss: 1.97646002471447

Epoch: 5| Step: 2
Training loss: 0.5902889966964722
Validation loss: 1.979572261373202

Epoch: 5| Step: 3
Training loss: 0.6038804054260254
Validation loss: 2.004209150870641

Epoch: 5| Step: 4
Training loss: 0.4373248517513275
Validation loss: 1.9610723753770192

Epoch: 5| Step: 5
Training loss: 0.2601028382778168
Validation loss: 1.9630367159843445

Epoch: 5| Step: 6
Training loss: 0.6934361457824707
Validation loss: 1.9764123807350795

Epoch: 5| Step: 7
Training loss: 0.5474221706390381
Validation loss: 1.9911801765362422

Epoch: 5| Step: 8
Training loss: 0.8473857641220093
Validation loss: 1.916862115263939

Epoch: 5| Step: 9
Training loss: 0.3611581325531006
Validation loss: 1.9247262080510457

Epoch: 5| Step: 10
Training loss: 0.8238235712051392
Validation loss: 1.9398369193077087

Epoch: 5| Step: 11
Training loss: 0.9402617812156677
Validation loss: 1.931867818037669

Epoch: 236| Step: 0
Training loss: 1.0307872295379639
Validation loss: 1.9937169601519902

Epoch: 5| Step: 1
Training loss: 0.6628450155258179
Validation loss: 2.0268652190764747

Epoch: 5| Step: 2
Training loss: 0.4821869730949402
Validation loss: 1.961744527022044

Epoch: 5| Step: 3
Training loss: 0.642923891544342
Validation loss: 1.9660803625981014

Epoch: 5| Step: 4
Training loss: 0.3829464614391327
Validation loss: 1.9677753001451492

Epoch: 5| Step: 5
Training loss: 0.6018214821815491
Validation loss: 1.8811930765708287

Epoch: 5| Step: 6
Training loss: 0.7287189960479736
Validation loss: 1.9560701449712117

Epoch: 5| Step: 7
Training loss: 0.6683530807495117
Validation loss: 1.9367886384328206

Epoch: 5| Step: 8
Training loss: 0.46392732858657837
Validation loss: 1.9567704598108928

Epoch: 5| Step: 9
Training loss: 0.3866615891456604
Validation loss: 1.9560681978861492

Epoch: 5| Step: 10
Training loss: 0.48137497901916504
Validation loss: 2.006478721896807

Epoch: 5| Step: 11
Training loss: 0.5030677318572998
Validation loss: 2.0002617289622626

Epoch: 237| Step: 0
Training loss: 0.4915021061897278
Validation loss: 2.031719386577606

Epoch: 5| Step: 1
Training loss: 0.8578363656997681
Validation loss: 1.9882418761650722

Epoch: 5| Step: 2
Training loss: 0.6103676557540894
Validation loss: 1.9624954760074615

Epoch: 5| Step: 3
Training loss: 0.77444988489151
Validation loss: 1.9959681332111359

Epoch: 5| Step: 4
Training loss: 0.4261470437049866
Validation loss: 1.9668624301751454

Epoch: 5| Step: 5
Training loss: 0.3318350315093994
Validation loss: 1.9773461272319157

Epoch: 5| Step: 6
Training loss: 0.314769983291626
Validation loss: 1.933828741312027

Epoch: 5| Step: 7
Training loss: 0.6767928600311279
Validation loss: 2.0152450849612555

Epoch: 5| Step: 8
Training loss: 0.6158334016799927
Validation loss: 1.9930629034837086

Epoch: 5| Step: 9
Training loss: 0.5643963813781738
Validation loss: 1.9976263890663783

Epoch: 5| Step: 10
Training loss: 0.7017229795455933
Validation loss: 1.982956086595853

Epoch: 5| Step: 11
Training loss: 0.9960416555404663
Validation loss: 1.9786380330721538

Epoch: 238| Step: 0
Training loss: 0.5210201740264893
Validation loss: 2.0255687683820724

Epoch: 5| Step: 1
Training loss: 0.4271455705165863
Validation loss: 1.930662214756012

Epoch: 5| Step: 2
Training loss: 0.7259918451309204
Validation loss: 2.0271669874588647

Epoch: 5| Step: 3
Training loss: 0.7233004570007324
Validation loss: 1.9343858162562053

Epoch: 5| Step: 4
Training loss: 0.5450273752212524
Validation loss: 2.034056137005488

Epoch: 5| Step: 5
Training loss: 0.5619922876358032
Validation loss: 1.9939095626274745

Epoch: 5| Step: 6
Training loss: 0.4832840859889984
Validation loss: 1.963018998503685

Epoch: 5| Step: 7
Training loss: 0.5594285130500793
Validation loss: 2.02349820236365

Epoch: 5| Step: 8
Training loss: 0.3982815742492676
Validation loss: 1.980782796939214

Epoch: 5| Step: 9
Training loss: 0.8799333572387695
Validation loss: 1.989828606446584

Epoch: 5| Step: 10
Training loss: 0.54202800989151
Validation loss: 1.9526606400807698

Epoch: 5| Step: 11
Training loss: 0.48137781023979187
Validation loss: 1.9657838145891826

Epoch: 239| Step: 0
Training loss: 0.4672063887119293
Validation loss: 1.9145819147427876

Epoch: 5| Step: 1
Training loss: 0.37708061933517456
Validation loss: 1.9812290767828624

Epoch: 5| Step: 2
Training loss: 0.8195114135742188
Validation loss: 1.9646427035331726

Epoch: 5| Step: 3
Training loss: 0.8805242776870728
Validation loss: 1.992951030532519

Epoch: 5| Step: 4
Training loss: 0.6080401539802551
Validation loss: 1.9470125983158748

Epoch: 5| Step: 5
Training loss: 0.6307163834571838
Validation loss: 1.9752099066972733

Epoch: 5| Step: 6
Training loss: 0.4886504113674164
Validation loss: 1.9922517736752827

Epoch: 5| Step: 7
Training loss: 0.28918153047561646
Validation loss: 1.9879012952248256

Epoch: 5| Step: 8
Training loss: 0.5666530132293701
Validation loss: 2.0514877835909524

Epoch: 5| Step: 9
Training loss: 0.7033601999282837
Validation loss: 1.9840275446573894

Epoch: 5| Step: 10
Training loss: 0.7701836824417114
Validation loss: 1.9637748450040817

Epoch: 5| Step: 11
Training loss: 0.24627506732940674
Validation loss: 1.9884464343388875

Epoch: 240| Step: 0
Training loss: 0.8678447604179382
Validation loss: 1.9790123105049133

Epoch: 5| Step: 1
Training loss: 0.6846383213996887
Validation loss: 1.9791733870903652

Epoch: 5| Step: 2
Training loss: 0.545283854007721
Validation loss: 1.949338694413503

Epoch: 5| Step: 3
Training loss: 0.5109222531318665
Validation loss: 1.9222896943489711

Epoch: 5| Step: 4
Training loss: 0.6217876672744751
Validation loss: 1.9326737225055695

Epoch: 5| Step: 5
Training loss: 0.3840140104293823
Validation loss: 1.9793925285339355

Epoch: 5| Step: 6
Training loss: 0.3878743350505829
Validation loss: 1.9842235247294109

Epoch: 5| Step: 7
Training loss: 0.7669345140457153
Validation loss: 1.9867198318243027

Epoch: 5| Step: 8
Training loss: 0.5211621522903442
Validation loss: 1.971066842476527

Epoch: 5| Step: 9
Training loss: 0.4388345777988434
Validation loss: 1.9650580286979675

Epoch: 5| Step: 10
Training loss: 0.5241879224777222
Validation loss: 1.942645087838173

Epoch: 5| Step: 11
Training loss: 1.459252953529358
Validation loss: 1.945293515920639

Epoch: 241| Step: 0
Training loss: 0.6009091138839722
Validation loss: 1.9578446348508198

Epoch: 5| Step: 1
Training loss: 0.3966587781906128
Validation loss: 1.9585301727056503

Epoch: 5| Step: 2
Training loss: 0.4285380244255066
Validation loss: 1.9801599035660427

Epoch: 5| Step: 3
Training loss: 0.521708607673645
Validation loss: 1.93088631828626

Epoch: 5| Step: 4
Training loss: 0.5812665224075317
Validation loss: 1.949179584781329

Epoch: 5| Step: 5
Training loss: 0.6233474612236023
Validation loss: 2.002788409590721

Epoch: 5| Step: 6
Training loss: 0.4860714077949524
Validation loss: 1.9895212749640148

Epoch: 5| Step: 7
Training loss: 1.0688049793243408
Validation loss: 2.0353155930836997

Epoch: 5| Step: 8
Training loss: 0.7670066356658936
Validation loss: 1.9801767369111378

Epoch: 5| Step: 9
Training loss: 0.8096551895141602
Validation loss: 2.026433140039444

Epoch: 5| Step: 10
Training loss: 0.5331599712371826
Validation loss: 1.9296076546112697

Epoch: 5| Step: 11
Training loss: 0.5999875664710999
Validation loss: 1.887324258685112

Epoch: 242| Step: 0
Training loss: 0.7351640462875366
Validation loss: 1.9465540647506714

Epoch: 5| Step: 1
Training loss: 0.5057820677757263
Validation loss: 1.9583252221345901

Epoch: 5| Step: 2
Training loss: 0.6836525797843933
Validation loss: 1.990955223639806

Epoch: 5| Step: 3
Training loss: 0.5669464468955994
Validation loss: 1.9699012786149979

Epoch: 5| Step: 4
Training loss: 0.5599753260612488
Validation loss: 2.0076386829217276

Epoch: 5| Step: 5
Training loss: 0.513827919960022
Validation loss: 1.9703599909941356

Epoch: 5| Step: 6
Training loss: 0.5645505785942078
Validation loss: 1.9503726313511531

Epoch: 5| Step: 7
Training loss: 0.42943453788757324
Validation loss: 1.9519269168376923

Epoch: 5| Step: 8
Training loss: 0.502031147480011
Validation loss: 1.9099945177634556

Epoch: 5| Step: 9
Training loss: 0.9073854684829712
Validation loss: 1.8912233064572017

Epoch: 5| Step: 10
Training loss: 0.39905059337615967
Validation loss: 1.9670679569244385

Epoch: 5| Step: 11
Training loss: 0.4857584238052368
Validation loss: 1.9613136500120163

Epoch: 243| Step: 0
Training loss: 0.3828209340572357
Validation loss: 1.9662451694409053

Epoch: 5| Step: 1
Training loss: 0.6167589426040649
Validation loss: 1.9135033388932545

Epoch: 5| Step: 2
Training loss: 0.49205484986305237
Validation loss: 1.9546472082535427

Epoch: 5| Step: 3
Training loss: 0.4745025634765625
Validation loss: 1.928242360552152

Epoch: 5| Step: 4
Training loss: 0.7355582118034363
Validation loss: 2.0096823424100876

Epoch: 5| Step: 5
Training loss: 1.0151212215423584
Validation loss: 1.967876523733139

Epoch: 5| Step: 6
Training loss: 0.40341830253601074
Validation loss: 1.9456919233004253

Epoch: 5| Step: 7
Training loss: 0.6150819659233093
Validation loss: 1.8972794562578201

Epoch: 5| Step: 8
Training loss: 0.551079273223877
Validation loss: 1.9547909200191498

Epoch: 5| Step: 9
Training loss: 0.6656465530395508
Validation loss: 1.9196199079354603

Epoch: 5| Step: 10
Training loss: 0.47755974531173706
Validation loss: 1.9110135734081268

Epoch: 5| Step: 11
Training loss: 0.5078679919242859
Validation loss: 1.9700520932674408

Epoch: 244| Step: 0
Training loss: 0.5542119145393372
Validation loss: 1.9655905763308208

Epoch: 5| Step: 1
Training loss: 0.5154832005500793
Validation loss: 1.9826216300328572

Epoch: 5| Step: 2
Training loss: 0.37041711807250977
Validation loss: 2.0502806653579078

Epoch: 5| Step: 3
Training loss: 0.8589062690734863
Validation loss: 2.0148708621660867

Epoch: 5| Step: 4
Training loss: 0.3787102699279785
Validation loss: 1.954406624039014

Epoch: 5| Step: 5
Training loss: 0.4327053427696228
Validation loss: 1.9771895209948223

Epoch: 5| Step: 6
Training loss: 1.0286860466003418
Validation loss: 1.9424479405085247

Epoch: 5| Step: 7
Training loss: 0.9180845022201538
Validation loss: 1.9147574951251347

Epoch: 5| Step: 8
Training loss: 0.6306372880935669
Validation loss: 1.9224337885777156

Epoch: 5| Step: 9
Training loss: 0.47364434599876404
Validation loss: 1.9654532372951508

Epoch: 5| Step: 10
Training loss: 0.38233423233032227
Validation loss: 1.958764801422755

Epoch: 5| Step: 11
Training loss: 0.822533905506134
Validation loss: 1.997039218743642

Epoch: 245| Step: 0
Training loss: 0.5244079828262329
Validation loss: 1.9993786017100017

Epoch: 5| Step: 1
Training loss: 0.37435758113861084
Validation loss: 1.963456079363823

Epoch: 5| Step: 2
Training loss: 0.610927939414978
Validation loss: 2.0167587945858636

Epoch: 5| Step: 3
Training loss: 0.40940552949905396
Validation loss: 1.9619101136922836

Epoch: 5| Step: 4
Training loss: 0.4578394293785095
Validation loss: 1.9164876341819763

Epoch: 5| Step: 5
Training loss: 0.5931832790374756
Validation loss: 1.9153010149796803

Epoch: 5| Step: 6
Training loss: 0.3806592524051666
Validation loss: 1.883788526058197

Epoch: 5| Step: 7
Training loss: 0.40293097496032715
Validation loss: 1.913797413309415

Epoch: 5| Step: 8
Training loss: 0.6977735161781311
Validation loss: 1.890607217947642

Epoch: 5| Step: 9
Training loss: 0.7935778498649597
Validation loss: 1.9866139044364293

Epoch: 5| Step: 10
Training loss: 1.069361925125122
Validation loss: 1.9545548111200333

Epoch: 5| Step: 11
Training loss: 0.6493247151374817
Validation loss: 1.9683650384346645

Epoch: 246| Step: 0
Training loss: 0.24473324418067932
Validation loss: 1.9868727723757427

Epoch: 5| Step: 1
Training loss: 0.38672977685928345
Validation loss: 1.9694723983605702

Epoch: 5| Step: 2
Training loss: 0.46604686975479126
Validation loss: 2.0041134456793466

Epoch: 5| Step: 3
Training loss: 0.4143943786621094
Validation loss: 1.9536803265412648

Epoch: 5| Step: 4
Training loss: 0.47606220841407776
Validation loss: 1.9577949990828831

Epoch: 5| Step: 5
Training loss: 0.8636323809623718
Validation loss: 1.9912842164436977

Epoch: 5| Step: 6
Training loss: 0.5782011151313782
Validation loss: 1.9628006269534428

Epoch: 5| Step: 7
Training loss: 0.4822576940059662
Validation loss: 1.9722343931595485

Epoch: 5| Step: 8
Training loss: 1.1092307567596436
Validation loss: 1.9675176292657852

Epoch: 5| Step: 9
Training loss: 0.44751062989234924
Validation loss: 2.0034308632214866

Epoch: 5| Step: 10
Training loss: 0.3762337267398834
Validation loss: 1.999620685974757

Epoch: 5| Step: 11
Training loss: 0.22821694612503052
Validation loss: 2.010474676887194

Epoch: 247| Step: 0
Training loss: 0.6868826150894165
Validation loss: 2.041140874226888

Epoch: 5| Step: 1
Training loss: 0.4255673289299011
Validation loss: 2.033801640073458

Epoch: 5| Step: 2
Training loss: 0.7830298542976379
Validation loss: 1.9931184301773708

Epoch: 5| Step: 3
Training loss: 0.46060362458229065
Validation loss: 1.993332400918007

Epoch: 5| Step: 4
Training loss: 0.4459170699119568
Validation loss: 1.9810083756844203

Epoch: 5| Step: 5
Training loss: 0.47186604142189026
Validation loss: 1.9500738432010014

Epoch: 5| Step: 6
Training loss: 0.45362287759780884
Validation loss: 1.99288077155749

Epoch: 5| Step: 7
Training loss: 0.3685493469238281
Validation loss: 1.9800543040037155

Epoch: 5| Step: 8
Training loss: 0.7121705412864685
Validation loss: 1.9505855739116669

Epoch: 5| Step: 9
Training loss: 0.6284754276275635
Validation loss: 1.9987966666618984

Epoch: 5| Step: 10
Training loss: 0.5799494385719299
Validation loss: 2.0792421301205954

Epoch: 5| Step: 11
Training loss: 1.3328827619552612
Validation loss: 2.08483258386453

Epoch: 248| Step: 0
Training loss: 0.6396417617797852
Validation loss: 2.0761873523394265

Epoch: 5| Step: 1
Training loss: 0.5776200294494629
Validation loss: 2.017727921406428

Epoch: 5| Step: 2
Training loss: 0.6895220875740051
Validation loss: 1.9751524825890858

Epoch: 5| Step: 3
Training loss: 0.5570826530456543
Validation loss: 2.0084819147984185

Epoch: 5| Step: 4
Training loss: 0.6825586557388306
Validation loss: 1.950311412413915

Epoch: 5| Step: 5
Training loss: 0.558125376701355
Validation loss: 1.9848089565833409

Epoch: 5| Step: 6
Training loss: 0.6053000688552856
Validation loss: 1.965732564528783

Epoch: 5| Step: 7
Training loss: 0.430774986743927
Validation loss: 2.0162440041700997

Epoch: 5| Step: 8
Training loss: 0.49779683351516724
Validation loss: 2.03850719332695

Epoch: 5| Step: 9
Training loss: 0.6874686479568481
Validation loss: 2.0291340251763663

Epoch: 5| Step: 10
Training loss: 0.5674219727516174
Validation loss: 2.016887898246447

Epoch: 5| Step: 11
Training loss: 0.30896443128585815
Validation loss: 2.0267160534858704

Epoch: 249| Step: 0
Training loss: 0.581357479095459
Validation loss: 1.9734953542550404

Epoch: 5| Step: 1
Training loss: 0.8641921877861023
Validation loss: 2.0018402487039566

Epoch: 5| Step: 2
Training loss: 0.5290943384170532
Validation loss: 1.988931879401207

Epoch: 5| Step: 3
Training loss: 0.5882747769355774
Validation loss: 1.9935395419597626

Epoch: 5| Step: 4
Training loss: 0.7348114848136902
Validation loss: 2.0007891903320947

Epoch: 5| Step: 5
Training loss: 0.3663930296897888
Validation loss: 2.0064927836259208

Epoch: 5| Step: 6
Training loss: 0.5903425216674805
Validation loss: 1.957175036271413

Epoch: 5| Step: 7
Training loss: 0.4851676821708679
Validation loss: 2.0283435583114624

Epoch: 5| Step: 8
Training loss: 1.0086430311203003
Validation loss: 2.042120317618052

Epoch: 5| Step: 9
Training loss: 0.4763416647911072
Validation loss: 2.0356178830067315

Epoch: 5| Step: 10
Training loss: 0.6146957278251648
Validation loss: 2.0103154132763543

Epoch: 5| Step: 11
Training loss: 0.4583686888217926
Validation loss: 1.991894652446111

Epoch: 250| Step: 0
Training loss: 0.4889236092567444
Validation loss: 1.9729945709307988

Epoch: 5| Step: 1
Training loss: 0.5358648300170898
Validation loss: 1.9880292614301045

Epoch: 5| Step: 2
Training loss: 0.6687666177749634
Validation loss: 1.9345620920260747

Epoch: 5| Step: 3
Training loss: 0.7271682024002075
Validation loss: 1.9357251326243083

Epoch: 5| Step: 4
Training loss: 0.6871814131736755
Validation loss: 1.9897395273049672

Epoch: 5| Step: 5
Training loss: 0.48192232847213745
Validation loss: 1.9846697996060054

Epoch: 5| Step: 6
Training loss: 1.136218547821045
Validation loss: 1.9853641887505848

Epoch: 5| Step: 7
Training loss: 0.46146440505981445
Validation loss: 1.9433396955331166

Epoch: 5| Step: 8
Training loss: 0.4163912832736969
Validation loss: 2.002017622192701

Epoch: 5| Step: 9
Training loss: 0.4960412383079529
Validation loss: 2.035086343685786

Epoch: 5| Step: 10
Training loss: 0.4057387411594391
Validation loss: 1.992349550127983

Epoch: 5| Step: 11
Training loss: 0.4844619929790497
Validation loss: 1.9336159576972325

Epoch: 251| Step: 0
Training loss: 0.3904666304588318
Validation loss: 1.985577369729678

Epoch: 5| Step: 1
Training loss: 0.5978935360908508
Validation loss: 1.9599108695983887

Epoch: 5| Step: 2
Training loss: 0.4829392433166504
Validation loss: 1.93877612054348

Epoch: 5| Step: 3
Training loss: 0.5348512530326843
Validation loss: 1.9444827437400818

Epoch: 5| Step: 4
Training loss: 0.5334336757659912
Validation loss: 1.9378539820512135

Epoch: 5| Step: 5
Training loss: 0.4382450580596924
Validation loss: 1.9558356404304504

Epoch: 5| Step: 6
Training loss: 0.5049648284912109
Validation loss: 1.9418905129035313

Epoch: 5| Step: 7
Training loss: 0.3548356592655182
Validation loss: 1.978910778959592

Epoch: 5| Step: 8
Training loss: 0.99578458070755
Validation loss: 1.9191165218750637

Epoch: 5| Step: 9
Training loss: 0.5919076204299927
Validation loss: 1.963876947760582

Epoch: 5| Step: 10
Training loss: 0.39398127794265747
Validation loss: 1.9332696398099263

Epoch: 5| Step: 11
Training loss: 0.410528302192688
Validation loss: 1.998586763938268

Epoch: 252| Step: 0
Training loss: 0.48178425431251526
Validation loss: 1.97618301709493

Epoch: 5| Step: 1
Training loss: 0.23772208392620087
Validation loss: 1.9725419531265895

Epoch: 5| Step: 2
Training loss: 0.4982863962650299
Validation loss: 1.9701718538999557

Epoch: 5| Step: 3
Training loss: 1.0805373191833496
Validation loss: 1.9433735956748326

Epoch: 5| Step: 4
Training loss: 0.5017902255058289
Validation loss: 1.933683047691981

Epoch: 5| Step: 5
Training loss: 0.39042460918426514
Validation loss: 1.9573862999677658

Epoch: 5| Step: 6
Training loss: 0.8104063272476196
Validation loss: 1.9578895072142284

Epoch: 5| Step: 7
Training loss: 0.4000774919986725
Validation loss: 1.9251185804605484

Epoch: 5| Step: 8
Training loss: 0.5008325576782227
Validation loss: 1.968689039349556

Epoch: 5| Step: 9
Training loss: 0.4345744252204895
Validation loss: 1.969362124800682

Epoch: 5| Step: 10
Training loss: 0.4320562481880188
Validation loss: 1.953026756644249

Epoch: 5| Step: 11
Training loss: 0.29351842403411865
Validation loss: 1.9807704736789067

Epoch: 253| Step: 0
Training loss: 0.3501902222633362
Validation loss: 2.0326955318450928

Epoch: 5| Step: 1
Training loss: 0.45393142104148865
Validation loss: 2.00608928501606

Epoch: 5| Step: 2
Training loss: 0.3356393277645111
Validation loss: 1.9654218157132466

Epoch: 5| Step: 3
Training loss: 0.6957651972770691
Validation loss: 1.9463356683651607

Epoch: 5| Step: 4
Training loss: 0.7901421785354614
Validation loss: 1.967285618185997

Epoch: 5| Step: 5
Training loss: 0.2618125081062317
Validation loss: 1.9695049822330475

Epoch: 5| Step: 6
Training loss: 0.6866512298583984
Validation loss: 1.9556605319182079

Epoch: 5| Step: 7
Training loss: 0.39786019921302795
Validation loss: 1.9300132592519124

Epoch: 5| Step: 8
Training loss: 0.3566490709781647
Validation loss: 1.9265030473470688

Epoch: 5| Step: 9
Training loss: 0.3208337426185608
Validation loss: 1.9206264515717824

Epoch: 5| Step: 10
Training loss: 0.8199654817581177
Validation loss: 1.9891938020785649

Epoch: 5| Step: 11
Training loss: 3.0991616249084473
Validation loss: 1.9572997093200684

Epoch: 254| Step: 0
Training loss: 0.5751010179519653
Validation loss: 1.985432654619217

Epoch: 5| Step: 1
Training loss: 0.4315488338470459
Validation loss: 1.9146297226349513

Epoch: 5| Step: 2
Training loss: 0.585163414478302
Validation loss: 1.960779830813408

Epoch: 5| Step: 3
Training loss: 0.3790624439716339
Validation loss: 1.914304569363594

Epoch: 5| Step: 4
Training loss: 0.6867786645889282
Validation loss: 1.874390959739685

Epoch: 5| Step: 5
Training loss: 0.4038851857185364
Validation loss: 1.935673549771309

Epoch: 5| Step: 6
Training loss: 0.5725351572036743
Validation loss: 1.972069039940834

Epoch: 5| Step: 7
Training loss: 0.8124681711196899
Validation loss: 1.9550022234519322

Epoch: 5| Step: 8
Training loss: 0.48273295164108276
Validation loss: 1.949336474140485

Epoch: 5| Step: 9
Training loss: 0.2244594544172287
Validation loss: 1.9410180946191151

Epoch: 5| Step: 10
Training loss: 0.5474147796630859
Validation loss: 1.9693658500909805

Epoch: 5| Step: 11
Training loss: 0.3603780269622803
Validation loss: 1.9316225399573643

Epoch: 255| Step: 0
Training loss: 0.34203988313674927
Validation loss: 1.9863173514604568

Epoch: 5| Step: 1
Training loss: 0.5790601968765259
Validation loss: 1.9723569403092067

Epoch: 5| Step: 2
Training loss: 0.48365849256515503
Validation loss: 1.990839014450709

Epoch: 5| Step: 3
Training loss: 0.48437437415122986
Validation loss: 1.892901708682378

Epoch: 5| Step: 4
Training loss: 0.31500470638275146
Validation loss: 1.921576827764511

Epoch: 5| Step: 5
Training loss: 0.5069038271903992
Validation loss: 1.9573327501614888

Epoch: 5| Step: 6
Training loss: 0.42386072874069214
Validation loss: 1.9968784600496292

Epoch: 5| Step: 7
Training loss: 0.4302275776863098
Validation loss: 1.9189041753609974

Epoch: 5| Step: 8
Training loss: 0.7387453317642212
Validation loss: 1.9339834849039714

Epoch: 5| Step: 9
Training loss: 0.6421273350715637
Validation loss: 1.9294849783182144

Epoch: 5| Step: 10
Training loss: 0.9555946588516235
Validation loss: 1.993169327576955

Epoch: 5| Step: 11
Training loss: 0.6626184582710266
Validation loss: 1.9650172243515651

Epoch: 256| Step: 0
Training loss: 0.8390100598335266
Validation loss: 1.997835099697113

Epoch: 5| Step: 1
Training loss: 0.44039565324783325
Validation loss: 2.0475554913282394

Epoch: 5| Step: 2
Training loss: 0.44315558671951294
Validation loss: 1.9769346664349239

Epoch: 5| Step: 3
Training loss: 0.42865127325057983
Validation loss: 1.9708795299132664

Epoch: 5| Step: 4
Training loss: 0.3986946940422058
Validation loss: 1.928462381164233

Epoch: 5| Step: 5
Training loss: 0.572648286819458
Validation loss: 1.940978651245435

Epoch: 5| Step: 6
Training loss: 0.5426843166351318
Validation loss: 1.949213405450185

Epoch: 5| Step: 7
Training loss: 0.7203925848007202
Validation loss: 1.9359794557094574

Epoch: 5| Step: 8
Training loss: 0.31651103496551514
Validation loss: 1.981393759449323

Epoch: 5| Step: 9
Training loss: 0.265864759683609
Validation loss: 1.9321008374293644

Epoch: 5| Step: 10
Training loss: 0.9097779393196106
Validation loss: 1.9519100834925969

Epoch: 5| Step: 11
Training loss: 0.5298377275466919
Validation loss: 1.9469711383183796

Epoch: 257| Step: 0
Training loss: 0.5022413730621338
Validation loss: 1.9775027235349019

Epoch: 5| Step: 1
Training loss: 0.3974039554595947
Validation loss: 1.9216291507085164

Epoch: 5| Step: 2
Training loss: 0.3557918667793274
Validation loss: 1.9890464345614116

Epoch: 5| Step: 3
Training loss: 0.830236554145813
Validation loss: 1.941354309519132

Epoch: 5| Step: 4
Training loss: 0.6367551684379578
Validation loss: 1.942009061574936

Epoch: 5| Step: 5
Training loss: 0.7030494809150696
Validation loss: 1.9497553010781605

Epoch: 5| Step: 6
Training loss: 0.30759355425834656
Validation loss: 1.959393451611201

Epoch: 5| Step: 7
Training loss: 0.5635823011398315
Validation loss: 1.9507240504026413

Epoch: 5| Step: 8
Training loss: 0.4701710641384125
Validation loss: 1.9707819124062855

Epoch: 5| Step: 9
Training loss: 0.4593431353569031
Validation loss: 1.9489229867855709

Epoch: 5| Step: 10
Training loss: 0.4513925015926361
Validation loss: 1.9390315562486649

Epoch: 5| Step: 11
Training loss: 1.2120792865753174
Validation loss: 1.9162839303414028

Epoch: 258| Step: 0
Training loss: 0.6566756963729858
Validation loss: 1.9907168298959732

Epoch: 5| Step: 1
Training loss: 0.5704444050788879
Validation loss: 1.9316906034946442

Epoch: 5| Step: 2
Training loss: 0.6391298174858093
Validation loss: 1.9656902154286702

Epoch: 5| Step: 3
Training loss: 0.311937153339386
Validation loss: 1.9646074026823044

Epoch: 5| Step: 4
Training loss: 0.2606460452079773
Validation loss: 1.9779768884181976

Epoch: 5| Step: 5
Training loss: 0.4791220724582672
Validation loss: 1.9573755313952763

Epoch: 5| Step: 6
Training loss: 0.48594242334365845
Validation loss: 1.977331245938937

Epoch: 5| Step: 7
Training loss: 0.6139101982116699
Validation loss: 1.9887133191029231

Epoch: 5| Step: 8
Training loss: 0.32796216011047363
Validation loss: 1.8972247193257015

Epoch: 5| Step: 9
Training loss: 0.5471372604370117
Validation loss: 1.9705888430277507

Epoch: 5| Step: 10
Training loss: 0.7243361473083496
Validation loss: 1.9572170277436574

Epoch: 5| Step: 11
Training loss: 0.4878789782524109
Validation loss: 1.9636183579762776

Epoch: 259| Step: 0
Training loss: 0.5177044868469238
Validation loss: 1.9536295533180237

Epoch: 5| Step: 1
Training loss: 0.3861343264579773
Validation loss: 1.9767046521107356

Epoch: 5| Step: 2
Training loss: 0.5180169939994812
Validation loss: 2.030316799879074

Epoch: 5| Step: 3
Training loss: 0.5640257000923157
Validation loss: 2.007097671429316

Epoch: 5| Step: 4
Training loss: 0.46372857689857483
Validation loss: 1.959924469391505

Epoch: 5| Step: 5
Training loss: 0.525114893913269
Validation loss: 1.9258993417024612

Epoch: 5| Step: 6
Training loss: 0.33616718649864197
Validation loss: 1.9507928391297658

Epoch: 5| Step: 7
Training loss: 0.34381240606307983
Validation loss: 1.9553058296442032

Epoch: 5| Step: 8
Training loss: 0.3133378326892853
Validation loss: 1.971006582180659

Epoch: 5| Step: 9
Training loss: 0.6249839067459106
Validation loss: 2.0181919087966285

Epoch: 5| Step: 10
Training loss: 0.935771107673645
Validation loss: 1.9590475509564083

Epoch: 5| Step: 11
Training loss: 0.5077200531959534
Validation loss: 1.9977047890424728

Epoch: 260| Step: 0
Training loss: 0.5513827204704285
Validation loss: 1.9371862510840099

Epoch: 5| Step: 1
Training loss: 0.3643687665462494
Validation loss: 1.954138159751892

Epoch: 5| Step: 2
Training loss: 0.32386314868927
Validation loss: 1.9542016834020615

Epoch: 5| Step: 3
Training loss: 0.6583921313285828
Validation loss: 1.8968528062105179

Epoch: 5| Step: 4
Training loss: 0.5558614730834961
Validation loss: 1.9589619934558868

Epoch: 5| Step: 5
Training loss: 0.745040774345398
Validation loss: 1.9623160163561504

Epoch: 5| Step: 6
Training loss: 0.6427346467971802
Validation loss: 1.928139050801595

Epoch: 5| Step: 7
Training loss: 0.28629016876220703
Validation loss: 2.0030549615621567

Epoch: 5| Step: 8
Training loss: 0.35838931798934937
Validation loss: 1.9484810729821522

Epoch: 5| Step: 9
Training loss: 0.3677237033843994
Validation loss: 1.976327622930209

Epoch: 5| Step: 10
Training loss: 0.5527162551879883
Validation loss: 1.964090347290039

Epoch: 5| Step: 11
Training loss: 0.5028806924819946
Validation loss: 1.9860696246226628

Epoch: 261| Step: 0
Training loss: 0.7050529718399048
Validation loss: 1.9655739217996597

Epoch: 5| Step: 1
Training loss: 0.4515170454978943
Validation loss: 1.9653875678777695

Epoch: 5| Step: 2
Training loss: 0.850588321685791
Validation loss: 1.9834769467512767

Epoch: 5| Step: 3
Training loss: 0.2474210262298584
Validation loss: 1.979888916015625

Epoch: 5| Step: 4
Training loss: 0.6276358366012573
Validation loss: 1.928144559264183

Epoch: 5| Step: 5
Training loss: 0.4598613679409027
Validation loss: 1.9166853626569111

Epoch: 5| Step: 6
Training loss: 0.5104554891586304
Validation loss: 1.9858316332101822

Epoch: 5| Step: 7
Training loss: 0.8661168217658997
Validation loss: 1.9994963159163792

Epoch: 5| Step: 8
Training loss: 0.3360784351825714
Validation loss: 2.0390302687883377

Epoch: 5| Step: 9
Training loss: 0.4262399673461914
Validation loss: 1.9838201105594635

Epoch: 5| Step: 10
Training loss: 0.3547303080558777
Validation loss: 2.0074491649866104

Epoch: 5| Step: 11
Training loss: 0.36114969849586487
Validation loss: 1.984419013063113

Epoch: 262| Step: 0
Training loss: 0.8757433891296387
Validation loss: 1.9740784565607707

Epoch: 5| Step: 1
Training loss: 0.24225521087646484
Validation loss: 1.913537527124087

Epoch: 5| Step: 2
Training loss: 0.39202797412872314
Validation loss: 1.9165670325358708

Epoch: 5| Step: 3
Training loss: 0.7543693780899048
Validation loss: 1.955090085665385

Epoch: 5| Step: 4
Training loss: 0.6533017158508301
Validation loss: 2.0077432791392007

Epoch: 5| Step: 5
Training loss: 0.25920066237449646
Validation loss: 1.9377225389083226

Epoch: 5| Step: 6
Training loss: 0.5615161657333374
Validation loss: 1.9974406907955806

Epoch: 5| Step: 7
Training loss: 0.5083906054496765
Validation loss: 2.0217365274826684

Epoch: 5| Step: 8
Training loss: 0.37271231412887573
Validation loss: 1.9974908878405888

Epoch: 5| Step: 9
Training loss: 0.41995829343795776
Validation loss: 1.9982029348611832

Epoch: 5| Step: 10
Training loss: 0.5700104832649231
Validation loss: 2.0370491643746695

Epoch: 5| Step: 11
Training loss: 0.12262499332427979
Validation loss: 1.9799319754044216

Epoch: 263| Step: 0
Training loss: 0.329154372215271
Validation loss: 1.9614102095365524

Epoch: 5| Step: 1
Training loss: 1.059390664100647
Validation loss: 1.9862592468659084

Epoch: 5| Step: 2
Training loss: 0.6501782536506653
Validation loss: 1.965407356619835

Epoch: 5| Step: 3
Training loss: 0.44933566451072693
Validation loss: 1.9779082735379536

Epoch: 5| Step: 4
Training loss: 0.43212610483169556
Validation loss: 1.924725244442622

Epoch: 5| Step: 5
Training loss: 0.2865303158760071
Validation loss: 1.9696983297665913

Epoch: 5| Step: 6
Training loss: 0.4582401216030121
Validation loss: 1.9991676062345505

Epoch: 5| Step: 7
Training loss: 0.22506308555603027
Validation loss: 1.972800036271413

Epoch: 5| Step: 8
Training loss: 0.49667125940322876
Validation loss: 1.9481981645027797

Epoch: 5| Step: 9
Training loss: 0.5679563283920288
Validation loss: 1.930470918615659

Epoch: 5| Step: 10
Training loss: 0.32883208990097046
Validation loss: 1.8736471583445866

Epoch: 5| Step: 11
Training loss: 0.4459225535392761
Validation loss: 1.9237578362226486

Epoch: 264| Step: 0
Training loss: 0.4322574734687805
Validation loss: 1.9642791996399562

Epoch: 5| Step: 1
Training loss: 0.2638792395591736
Validation loss: 1.9426925430695217

Epoch: 5| Step: 2
Training loss: 0.3177833557128906
Validation loss: 1.939563125371933

Epoch: 5| Step: 3
Training loss: 0.6923588514328003
Validation loss: 1.9923152526219685

Epoch: 5| Step: 4
Training loss: 0.28012409806251526
Validation loss: 1.9584524532159169

Epoch: 5| Step: 5
Training loss: 0.5667296648025513
Validation loss: 1.9422275970379512

Epoch: 5| Step: 6
Training loss: 0.41956233978271484
Validation loss: 1.9122171451648076

Epoch: 5| Step: 7
Training loss: 0.7844377756118774
Validation loss: 1.9104971239964168

Epoch: 5| Step: 8
Training loss: 0.2395581305027008
Validation loss: 1.949781949321429

Epoch: 5| Step: 9
Training loss: 0.5389111042022705
Validation loss: 1.9474127143621445

Epoch: 5| Step: 10
Training loss: 0.7229979038238525
Validation loss: 1.9880286902189255

Epoch: 5| Step: 11
Training loss: 0.10571238398551941
Validation loss: 1.949016238252322

Epoch: 265| Step: 0
Training loss: 0.503583550453186
Validation loss: 1.9541121870279312

Epoch: 5| Step: 1
Training loss: 0.5386065244674683
Validation loss: 2.008795162041982

Epoch: 5| Step: 2
Training loss: 0.7331854104995728
Validation loss: 1.988032842675845

Epoch: 5| Step: 3
Training loss: 0.5410127639770508
Validation loss: 1.9706793973843257

Epoch: 5| Step: 4
Training loss: 0.49518150091171265
Validation loss: 2.0369712313016257

Epoch: 5| Step: 5
Training loss: 0.4200812876224518
Validation loss: 2.013001948595047

Epoch: 5| Step: 6
Training loss: 0.48968368768692017
Validation loss: 1.9877687046925228

Epoch: 5| Step: 7
Training loss: 0.25198668241500854
Validation loss: 1.9793923199176788

Epoch: 5| Step: 8
Training loss: 0.323993057012558
Validation loss: 1.9820790936549504

Epoch: 5| Step: 9
Training loss: 0.6124050617218018
Validation loss: 1.9625908235708873

Epoch: 5| Step: 10
Training loss: 0.5989024639129639
Validation loss: 2.005826582511266

Epoch: 5| Step: 11
Training loss: 0.3195061683654785
Validation loss: 2.0009262760480246

Epoch: 266| Step: 0
Training loss: 0.3726494014263153
Validation loss: 1.9703410863876343

Epoch: 5| Step: 1
Training loss: 0.5103936195373535
Validation loss: 1.9236066142717998

Epoch: 5| Step: 2
Training loss: 0.8065997362136841
Validation loss: 1.9872403740882874

Epoch: 5| Step: 3
Training loss: 0.4704255163669586
Validation loss: 1.9613188058137894

Epoch: 5| Step: 4
Training loss: 0.472433865070343
Validation loss: 1.9638604025046031

Epoch: 5| Step: 5
Training loss: 0.7508015632629395
Validation loss: 1.9982239504655201

Epoch: 5| Step: 6
Training loss: 0.7794879674911499
Validation loss: 2.0335340003172555

Epoch: 5| Step: 7
Training loss: 0.6038969159126282
Validation loss: 2.0209537545839944

Epoch: 5| Step: 8
Training loss: 0.4778170585632324
Validation loss: 1.978137676914533

Epoch: 5| Step: 9
Training loss: 0.4251523017883301
Validation loss: 1.9687013924121857

Epoch: 5| Step: 10
Training loss: 0.22091010212898254
Validation loss: 1.9751884589592617

Epoch: 5| Step: 11
Training loss: 0.1812712550163269
Validation loss: 1.957776462038358

Epoch: 267| Step: 0
Training loss: 0.3274485468864441
Validation loss: 1.9513764828443527

Epoch: 5| Step: 1
Training loss: 0.6419981718063354
Validation loss: 1.9861279477675755

Epoch: 5| Step: 2
Training loss: 0.506136953830719
Validation loss: 1.9145032664140065

Epoch: 5| Step: 3
Training loss: 0.45336228609085083
Validation loss: 1.907915363709132

Epoch: 5| Step: 4
Training loss: 0.28455352783203125
Validation loss: 1.9556379864613216

Epoch: 5| Step: 5
Training loss: 0.41169634461402893
Validation loss: 1.9637351383765538

Epoch: 5| Step: 6
Training loss: 0.6304336786270142
Validation loss: 1.9897109667460124

Epoch: 5| Step: 7
Training loss: 0.4158703684806824
Validation loss: 1.9622849275668461

Epoch: 5| Step: 8
Training loss: 0.4279988706111908
Validation loss: 1.9646881371736526

Epoch: 5| Step: 9
Training loss: 0.2610800862312317
Validation loss: 1.919469729065895

Epoch: 5| Step: 10
Training loss: 1.0084054470062256
Validation loss: 1.906238317489624

Epoch: 5| Step: 11
Training loss: 0.7905953526496887
Validation loss: 1.9037359257539113

Epoch: 268| Step: 0
Training loss: 0.4475889205932617
Validation loss: 1.9348382254441578

Epoch: 5| Step: 1
Training loss: 0.4532247483730316
Validation loss: 1.922563021381696

Epoch: 5| Step: 2
Training loss: 0.4953005909919739
Validation loss: 1.9532179286082585

Epoch: 5| Step: 3
Training loss: 0.9020916819572449
Validation loss: 2.015210966269175

Epoch: 5| Step: 4
Training loss: 0.32104286551475525
Validation loss: 1.9819216628869374

Epoch: 5| Step: 5
Training loss: 0.3927519917488098
Validation loss: 1.9965248902638753

Epoch: 5| Step: 6
Training loss: 0.4481561779975891
Validation loss: 1.9235563625892003

Epoch: 5| Step: 7
Training loss: 0.3994393050670624
Validation loss: 1.9130895634492238

Epoch: 5| Step: 8
Training loss: 0.28322893381118774
Validation loss: 1.904494841893514

Epoch: 5| Step: 9
Training loss: 0.5709871053695679
Validation loss: 1.9210563550392787

Epoch: 5| Step: 10
Training loss: 0.5057059526443481
Validation loss: 1.9573542475700378

Epoch: 5| Step: 11
Training loss: 0.2742982804775238
Validation loss: 1.900210107366244

Epoch: 269| Step: 0
Training loss: 0.42881107330322266
Validation loss: 1.9276340802510579

Epoch: 5| Step: 1
Training loss: 0.4856301248073578
Validation loss: 1.9189552813768387

Epoch: 5| Step: 2
Training loss: 0.6281949281692505
Validation loss: 1.9189390689134598

Epoch: 5| Step: 3
Training loss: 0.37030449509620667
Validation loss: 1.957010825475057

Epoch: 5| Step: 4
Training loss: 0.6527425050735474
Validation loss: 1.9231748829285304

Epoch: 5| Step: 5
Training loss: 0.40709391236305237
Validation loss: 1.9496000309785206

Epoch: 5| Step: 6
Training loss: 0.5791903734207153
Validation loss: 1.9059354364871979

Epoch: 5| Step: 7
Training loss: 0.5274262428283691
Validation loss: 1.9839260180791218

Epoch: 5| Step: 8
Training loss: 0.476762056350708
Validation loss: 1.9764509399731953

Epoch: 5| Step: 9
Training loss: 0.4152643084526062
Validation loss: 2.011306658387184

Epoch: 5| Step: 10
Training loss: 0.44809427857398987
Validation loss: 1.9457049171129863

Epoch: 5| Step: 11
Training loss: 0.41763895750045776
Validation loss: 1.9403818895419438

Epoch: 270| Step: 0
Training loss: 0.38685137033462524
Validation loss: 1.936566670735677

Epoch: 5| Step: 1
Training loss: 0.5394409894943237
Validation loss: 1.900433674454689

Epoch: 5| Step: 2
Training loss: 0.6606951951980591
Validation loss: 1.9056939085324605

Epoch: 5| Step: 3
Training loss: 0.8348855972290039
Validation loss: 1.9801369458436966

Epoch: 5| Step: 4
Training loss: 0.29011815786361694
Validation loss: 1.873437707622846

Epoch: 5| Step: 5
Training loss: 0.4281604290008545
Validation loss: 1.9373358537753422

Epoch: 5| Step: 6
Training loss: 0.5611721873283386
Validation loss: 2.0148051232099533

Epoch: 5| Step: 7
Training loss: 0.41638898849487305
Validation loss: 1.998302494486173

Epoch: 5| Step: 8
Training loss: 0.48195600509643555
Validation loss: 1.9903670648733776

Epoch: 5| Step: 9
Training loss: 0.5398317575454712
Validation loss: 1.9464937845865886

Epoch: 5| Step: 10
Training loss: 0.5187591314315796
Validation loss: 1.8920527150233586

Epoch: 5| Step: 11
Training loss: 0.3623887300491333
Validation loss: 1.9197000215450923

Epoch: 271| Step: 0
Training loss: 0.5730410814285278
Validation loss: 1.9359639137983322

Epoch: 5| Step: 1
Training loss: 0.8769171833992004
Validation loss: 1.950702741742134

Epoch: 5| Step: 2
Training loss: 0.653365969657898
Validation loss: 1.9018656015396118

Epoch: 5| Step: 3
Training loss: 0.4339072108268738
Validation loss: 1.9683084338903427

Epoch: 5| Step: 4
Training loss: 0.6219586133956909
Validation loss: 1.930793359875679

Epoch: 5| Step: 5
Training loss: 0.47840291261672974
Validation loss: 1.9387508084376652

Epoch: 5| Step: 6
Training loss: 0.5519384145736694
Validation loss: 1.9618988186120987

Epoch: 5| Step: 7
Training loss: 0.4391649663448334
Validation loss: 1.934989482164383

Epoch: 5| Step: 8
Training loss: 0.3190012574195862
Validation loss: 1.9175269703070323

Epoch: 5| Step: 9
Training loss: 0.3167382478713989
Validation loss: 1.9091439445813496

Epoch: 5| Step: 10
Training loss: 0.45609918236732483
Validation loss: 1.9040166636308034

Epoch: 5| Step: 11
Training loss: 0.1790211796760559
Validation loss: 1.920519232749939

Epoch: 272| Step: 0
Training loss: 0.34849438071250916
Validation loss: 1.8916020492712657

Epoch: 5| Step: 1
Training loss: 0.4925890564918518
Validation loss: 1.9256236056486766

Epoch: 5| Step: 2
Training loss: 0.40150386095046997
Validation loss: 1.894312749306361

Epoch: 5| Step: 3
Training loss: 0.5894120931625366
Validation loss: 1.9272034267584484

Epoch: 5| Step: 4
Training loss: 0.5354617834091187
Validation loss: 1.91506889462471

Epoch: 5| Step: 5
Training loss: 0.6495103240013123
Validation loss: 1.9230872839689255

Epoch: 5| Step: 6
Training loss: 0.42456188797950745
Validation loss: 1.9365081936120987

Epoch: 5| Step: 7
Training loss: 0.7003189325332642
Validation loss: 1.9555824051300685

Epoch: 5| Step: 8
Training loss: 0.3798291087150574
Validation loss: 2.0176219940185547

Epoch: 5| Step: 9
Training loss: 0.2520599961280823
Validation loss: 1.958552524447441

Epoch: 5| Step: 10
Training loss: 0.7322700619697571
Validation loss: 1.9109437714020412

Epoch: 5| Step: 11
Training loss: 0.2447962760925293
Validation loss: 1.9650513033072154

Epoch: 273| Step: 0
Training loss: 0.5659270286560059
Validation loss: 1.9240059306224186

Epoch: 5| Step: 1
Training loss: 0.5316140651702881
Validation loss: 1.8467132200797398

Epoch: 5| Step: 2
Training loss: 0.2681178152561188
Validation loss: 1.9407293597857158

Epoch: 5| Step: 3
Training loss: 0.33626845479011536
Validation loss: 1.9190534353256226

Epoch: 5| Step: 4
Training loss: 0.5172956585884094
Validation loss: 1.9430845727523167

Epoch: 5| Step: 5
Training loss: 0.40099066495895386
Validation loss: 1.9442290564378102

Epoch: 5| Step: 6
Training loss: 0.5042113065719604
Validation loss: 1.980101043979327

Epoch: 5| Step: 7
Training loss: 0.5764604806900024
Validation loss: 1.9465888688961666

Epoch: 5| Step: 8
Training loss: 0.4832293391227722
Validation loss: 1.9291810592015584

Epoch: 5| Step: 9
Training loss: 0.7279618978500366
Validation loss: 1.918629412849744

Epoch: 5| Step: 10
Training loss: 0.3458127975463867
Validation loss: 1.9145284791787465

Epoch: 5| Step: 11
Training loss: 1.1616501808166504
Validation loss: 1.9308538635571797

Epoch: 274| Step: 0
Training loss: 0.3827923536300659
Validation loss: 1.902584508061409

Epoch: 5| Step: 1
Training loss: 0.5810493230819702
Validation loss: 1.8748461504777272

Epoch: 5| Step: 2
Training loss: 0.7188417911529541
Validation loss: 1.89646215736866

Epoch: 5| Step: 3
Training loss: 0.32797640562057495
Validation loss: 1.9201266914606094

Epoch: 5| Step: 4
Training loss: 0.2764981687068939
Validation loss: 1.930257981022199

Epoch: 5| Step: 5
Training loss: 0.8950969576835632
Validation loss: 1.9305738111337025

Epoch: 5| Step: 6
Training loss: 0.4097159504890442
Validation loss: 1.9053869446118672

Epoch: 5| Step: 7
Training loss: 0.4446510672569275
Validation loss: 1.921822319428126

Epoch: 5| Step: 8
Training loss: 0.30754560232162476
Validation loss: 1.8898480435212452

Epoch: 5| Step: 9
Training loss: 0.622212290763855
Validation loss: 1.9189403156439464

Epoch: 5| Step: 10
Training loss: 0.29722699522972107
Validation loss: 1.9197674890359242

Epoch: 5| Step: 11
Training loss: 0.23153400421142578
Validation loss: 1.9699743290742238

Epoch: 275| Step: 0
Training loss: 0.5880128145217896
Validation loss: 1.9735466887553532

Epoch: 5| Step: 1
Training loss: 0.5460327863693237
Validation loss: 1.945797046025594

Epoch: 5| Step: 2
Training loss: 0.686210572719574
Validation loss: 1.9759219884872437

Epoch: 5| Step: 3
Training loss: 0.650847315788269
Validation loss: 1.928776130080223

Epoch: 5| Step: 4
Training loss: 0.2303454428911209
Validation loss: 1.9293031295140584

Epoch: 5| Step: 5
Training loss: 0.8914677500724792
Validation loss: 1.9140667865673702

Epoch: 5| Step: 6
Training loss: 0.3181007504463196
Validation loss: 1.903807024161021

Epoch: 5| Step: 7
Training loss: 0.33972597122192383
Validation loss: 1.8796943426132202

Epoch: 5| Step: 8
Training loss: 0.4901103973388672
Validation loss: 1.959067737062772

Epoch: 5| Step: 9
Training loss: 0.5582808256149292
Validation loss: 1.9281336863835652

Epoch: 5| Step: 10
Training loss: 0.36224597692489624
Validation loss: 1.9474485764900844

Epoch: 5| Step: 11
Training loss: 0.18045496940612793
Validation loss: 1.979152888059616

Epoch: 276| Step: 0
Training loss: 0.41847118735313416
Validation loss: 1.99584166208903

Epoch: 5| Step: 1
Training loss: 0.5714502334594727
Validation loss: 1.9985367159048717

Epoch: 5| Step: 2
Training loss: 0.5903403162956238
Validation loss: 1.977491522828738

Epoch: 5| Step: 3
Training loss: 0.5886566042900085
Validation loss: 1.9445990075667698

Epoch: 5| Step: 4
Training loss: 0.4671744406223297
Validation loss: 1.9475259631872177

Epoch: 5| Step: 5
Training loss: 0.5421691536903381
Validation loss: 1.8973339994748433

Epoch: 5| Step: 6
Training loss: 1.0347154140472412
Validation loss: 1.9457792242368062

Epoch: 5| Step: 7
Training loss: 0.5597060322761536
Validation loss: 1.936107744773229

Epoch: 5| Step: 8
Training loss: 0.41253072023391724
Validation loss: 1.9219820002714794

Epoch: 5| Step: 9
Training loss: 0.5099519491195679
Validation loss: 1.8925965478022893

Epoch: 5| Step: 10
Training loss: 0.32971638441085815
Validation loss: 1.961302936077118

Epoch: 5| Step: 11
Training loss: 0.44519340991973877
Validation loss: 1.9196567287047703

Epoch: 277| Step: 0
Training loss: 0.9596326947212219
Validation loss: 1.9597237159808476

Epoch: 5| Step: 1
Training loss: 0.7175307869911194
Validation loss: 1.970259889960289

Epoch: 5| Step: 2
Training loss: 0.44848600029945374
Validation loss: 1.943232739965121

Epoch: 5| Step: 3
Training loss: 0.7436489462852478
Validation loss: 1.8954005539417267

Epoch: 5| Step: 4
Training loss: 0.2701043486595154
Validation loss: 1.9473606447378795

Epoch: 5| Step: 5
Training loss: 0.39074963331222534
Validation loss: 1.9690657258033752

Epoch: 5| Step: 6
Training loss: 0.5470768213272095
Validation loss: 1.9432111928860347

Epoch: 5| Step: 7
Training loss: 0.36148732900619507
Validation loss: 1.9267672499020894

Epoch: 5| Step: 8
Training loss: 0.2442508190870285
Validation loss: 1.9562501808007557

Epoch: 5| Step: 9
Training loss: 0.2900179326534271
Validation loss: 1.9498969813187916

Epoch: 5| Step: 10
Training loss: 0.27944430708885193
Validation loss: 1.929365004102389

Epoch: 5| Step: 11
Training loss: 0.37506866455078125
Validation loss: 1.9561234364906948

Epoch: 278| Step: 0
Training loss: 0.8204951286315918
Validation loss: 1.9909428854783375

Epoch: 5| Step: 1
Training loss: 0.762799084186554
Validation loss: 1.9722993274529774

Epoch: 5| Step: 2
Training loss: 0.4482046663761139
Validation loss: 2.045885677138964

Epoch: 5| Step: 3
Training loss: 0.389401912689209
Validation loss: 1.983189880847931

Epoch: 5| Step: 4
Training loss: 0.3640141189098358
Validation loss: 1.952206273873647

Epoch: 5| Step: 5
Training loss: 0.44018611311912537
Validation loss: 1.9242089490095775

Epoch: 5| Step: 6
Training loss: 0.6182100176811218
Validation loss: 1.953614776333173

Epoch: 5| Step: 7
Training loss: 0.39019012451171875
Validation loss: 1.9277980873982112

Epoch: 5| Step: 8
Training loss: 0.34451398253440857
Validation loss: 1.9258653620878856

Epoch: 5| Step: 9
Training loss: 0.2843906283378601
Validation loss: 1.9150340308745701

Epoch: 5| Step: 10
Training loss: 0.4074368476867676
Validation loss: 1.9487022509177525

Epoch: 5| Step: 11
Training loss: 0.748501181602478
Validation loss: 1.9435193588336308

Epoch: 279| Step: 0
Training loss: 0.49537697434425354
Validation loss: 1.9842294106880825

Epoch: 5| Step: 1
Training loss: 0.5511138439178467
Validation loss: 1.934157818555832

Epoch: 5| Step: 2
Training loss: 0.44727593660354614
Validation loss: 1.9581392606099446

Epoch: 5| Step: 3
Training loss: 0.43260592222213745
Validation loss: 1.946188062429428

Epoch: 5| Step: 4
Training loss: 0.4071466326713562
Validation loss: 1.9957022567590077

Epoch: 5| Step: 5
Training loss: 0.3776547610759735
Validation loss: 1.9546717007954915

Epoch: 5| Step: 6
Training loss: 0.25872868299484253
Validation loss: 1.9263290266195934

Epoch: 5| Step: 7
Training loss: 0.670161247253418
Validation loss: 1.9544302920500438

Epoch: 5| Step: 8
Training loss: 0.31396499276161194
Validation loss: 1.967739313840866

Epoch: 5| Step: 9
Training loss: 0.24302668869495392
Validation loss: 1.963808998465538

Epoch: 5| Step: 10
Training loss: 0.774806797504425
Validation loss: 1.8763606051603954

Epoch: 5| Step: 11
Training loss: 0.2656903564929962
Validation loss: 1.902588943640391

Epoch: 280| Step: 0
Training loss: 0.3168243169784546
Validation loss: 1.9336940795183182

Epoch: 5| Step: 1
Training loss: 0.3631350100040436
Validation loss: 1.8847487767537434

Epoch: 5| Step: 2
Training loss: 0.4950740933418274
Validation loss: 1.9298741569121678

Epoch: 5| Step: 3
Training loss: 0.8539150357246399
Validation loss: 1.9264890750249226

Epoch: 5| Step: 4
Training loss: 0.4400561451911926
Validation loss: 1.9834381490945816

Epoch: 5| Step: 5
Training loss: 0.3944211006164551
Validation loss: 1.9937146107355754

Epoch: 5| Step: 6
Training loss: 0.41774147748947144
Validation loss: 1.9217355449994404

Epoch: 5| Step: 7
Training loss: 0.5279148817062378
Validation loss: 1.925700068473816

Epoch: 5| Step: 8
Training loss: 0.5833708643913269
Validation loss: 1.9813650747140248

Epoch: 5| Step: 9
Training loss: 0.38732901215553284
Validation loss: 1.921853522459666

Epoch: 5| Step: 10
Training loss: 0.623458743095398
Validation loss: 1.9016680270433426

Epoch: 5| Step: 11
Training loss: 0.9503936171531677
Validation loss: 1.9137330154577892

Epoch: 281| Step: 0
Training loss: 0.5407143831253052
Validation loss: 1.9674660414457321

Epoch: 5| Step: 1
Training loss: 0.4663950800895691
Validation loss: 1.9483903994162877

Epoch: 5| Step: 2
Training loss: 0.4424220025539398
Validation loss: 1.9859008540709813

Epoch: 5| Step: 3
Training loss: 0.609897792339325
Validation loss: 1.9912442763646443

Epoch: 5| Step: 4
Training loss: 0.3678160607814789
Validation loss: 2.0063335249821344

Epoch: 5| Step: 5
Training loss: 0.4382014274597168
Validation loss: 1.998242164651553

Epoch: 5| Step: 6
Training loss: 0.27421754598617554
Validation loss: 1.947994555036227

Epoch: 5| Step: 7
Training loss: 0.4371128976345062
Validation loss: 1.9363452792167664

Epoch: 5| Step: 8
Training loss: 0.8624510765075684
Validation loss: 1.901432454586029

Epoch: 5| Step: 9
Training loss: 0.4784373342990875
Validation loss: 1.9311686257521312

Epoch: 5| Step: 10
Training loss: 0.4137577414512634
Validation loss: 1.9063220272461574

Epoch: 5| Step: 11
Training loss: 0.41962772607803345
Validation loss: 1.9229283928871155

Epoch: 282| Step: 0
Training loss: 0.6146160960197449
Validation loss: 1.9386940052111943

Epoch: 5| Step: 1
Training loss: 0.3509711027145386
Validation loss: 1.9589286943276722

Epoch: 5| Step: 2
Training loss: 0.4290696978569031
Validation loss: 1.957209328810374

Epoch: 5| Step: 3
Training loss: 0.821682333946228
Validation loss: 1.93132280309995

Epoch: 5| Step: 4
Training loss: 0.3192911744117737
Validation loss: 1.9308559447526932

Epoch: 5| Step: 5
Training loss: 0.2394551932811737
Validation loss: 1.9529322634140651

Epoch: 5| Step: 6
Training loss: 0.6676279902458191
Validation loss: 1.959414189060529

Epoch: 5| Step: 7
Training loss: 0.4787692129611969
Validation loss: 1.924409677584966

Epoch: 5| Step: 8
Training loss: 0.45509153604507446
Validation loss: 1.9089948534965515

Epoch: 5| Step: 9
Training loss: 0.3358866274356842
Validation loss: 1.912913019458453

Epoch: 5| Step: 10
Training loss: 0.43849706649780273
Validation loss: 1.9082404673099518

Epoch: 5| Step: 11
Training loss: 0.5703704357147217
Validation loss: 1.9459382345279057

Epoch: 283| Step: 0
Training loss: 0.3315805196762085
Validation loss: 1.9937176803747814

Epoch: 5| Step: 1
Training loss: 0.6913674473762512
Validation loss: 2.0081111788749695

Epoch: 5| Step: 2
Training loss: 0.8306981921195984
Validation loss: 2.0344722171624503

Epoch: 5| Step: 3
Training loss: 0.6457622647285461
Validation loss: 2.018847112854322

Epoch: 5| Step: 4
Training loss: 0.33174270391464233
Validation loss: 1.971744845310847

Epoch: 5| Step: 5
Training loss: 0.6722416877746582
Validation loss: 1.9306290994087856

Epoch: 5| Step: 6
Training loss: 0.4388812482357025
Validation loss: 1.9659575819969177

Epoch: 5| Step: 7
Training loss: 0.5799045562744141
Validation loss: 1.9424313257137935

Epoch: 5| Step: 8
Training loss: 0.6319509744644165
Validation loss: 1.9571166684230168

Epoch: 5| Step: 9
Training loss: 0.33143001794815063
Validation loss: 1.9690501143534977

Epoch: 5| Step: 10
Training loss: 0.678442120552063
Validation loss: 1.95916943748792

Epoch: 5| Step: 11
Training loss: 0.3635420799255371
Validation loss: 1.987479344010353

Epoch: 284| Step: 0
Training loss: 0.520301103591919
Validation loss: 2.005906730890274

Epoch: 5| Step: 1
Training loss: 0.7832991480827332
Validation loss: 2.045109897851944

Epoch: 5| Step: 2
Training loss: 0.7271730303764343
Validation loss: 2.0512305945158005

Epoch: 5| Step: 3
Training loss: 0.5247659683227539
Validation loss: 1.97956849137942

Epoch: 5| Step: 4
Training loss: 0.4019816815853119
Validation loss: 2.016932730873426

Epoch: 5| Step: 5
Training loss: 0.30444055795669556
Validation loss: 1.9281446437040966

Epoch: 5| Step: 6
Training loss: 0.7509128451347351
Validation loss: 1.9323674192031224

Epoch: 5| Step: 7
Training loss: 0.4184330999851227
Validation loss: 1.902080277601878

Epoch: 5| Step: 8
Training loss: 0.6758704781532288
Validation loss: 1.964926744500796

Epoch: 5| Step: 9
Training loss: 0.761590838432312
Validation loss: 1.9105596045653026

Epoch: 5| Step: 10
Training loss: 0.3031718134880066
Validation loss: 1.9376045366128285

Epoch: 5| Step: 11
Training loss: 0.23098218441009521
Validation loss: 1.9740384270747502

Epoch: 285| Step: 0
Training loss: 0.5015084147453308
Validation loss: 2.012947748104731

Epoch: 5| Step: 1
Training loss: 0.33213475346565247
Validation loss: 1.9805989215771358

Epoch: 5| Step: 2
Training loss: 0.6108450889587402
Validation loss: 1.970104639728864

Epoch: 5| Step: 3
Training loss: 0.36778929829597473
Validation loss: 1.955011397600174

Epoch: 5| Step: 4
Training loss: 0.5604408979415894
Validation loss: 1.933215190966924

Epoch: 5| Step: 5
Training loss: 0.36380964517593384
Validation loss: 1.9419013460477192

Epoch: 5| Step: 6
Training loss: 0.530105710029602
Validation loss: 1.9208100189765294

Epoch: 5| Step: 7
Training loss: 0.4142161011695862
Validation loss: 1.9399137198925018

Epoch: 5| Step: 8
Training loss: 0.35198158025741577
Validation loss: 1.931220293045044

Epoch: 5| Step: 9
Training loss: 0.5446304082870483
Validation loss: 1.8970676114161809

Epoch: 5| Step: 10
Training loss: 0.42285043001174927
Validation loss: 1.9460746198892593

Epoch: 5| Step: 11
Training loss: 0.328427255153656
Validation loss: 1.9605531245470047

Epoch: 286| Step: 0
Training loss: 0.47386306524276733
Validation loss: 1.9389616250991821

Epoch: 5| Step: 1
Training loss: 0.3998921513557434
Validation loss: 1.942182665069898

Epoch: 5| Step: 2
Training loss: 0.4169600009918213
Validation loss: 1.936530331770579

Epoch: 5| Step: 3
Training loss: 0.5237041711807251
Validation loss: 1.9241675287485123

Epoch: 5| Step: 4
Training loss: 0.6153692603111267
Validation loss: 1.9234190086523693

Epoch: 5| Step: 5
Training loss: 0.6100227236747742
Validation loss: 1.9565716435511906

Epoch: 5| Step: 6
Training loss: 0.5215800404548645
Validation loss: 1.922451729575793

Epoch: 5| Step: 7
Training loss: 0.35743528604507446
Validation loss: 1.9981791973114014

Epoch: 5| Step: 8
Training loss: 0.5214080810546875
Validation loss: 1.9936474313338597

Epoch: 5| Step: 9
Training loss: 0.24218812584877014
Validation loss: 1.997979278365771

Epoch: 5| Step: 10
Training loss: 0.5789495706558228
Validation loss: 2.0333759685357413

Epoch: 5| Step: 11
Training loss: 0.37360507249832153
Validation loss: 1.9334052552779515

Epoch: 287| Step: 0
Training loss: 0.4251924455165863
Validation loss: 1.9341349800427754

Epoch: 5| Step: 1
Training loss: 0.3187451958656311
Validation loss: 2.022723212838173

Epoch: 5| Step: 2
Training loss: 0.6343679428100586
Validation loss: 1.9989520957072575

Epoch: 5| Step: 3
Training loss: 0.6579574942588806
Validation loss: 1.9589093774557114

Epoch: 5| Step: 4
Training loss: 0.3818632960319519
Validation loss: 1.9516780575116475

Epoch: 5| Step: 5
Training loss: 0.430049329996109
Validation loss: 1.9213580290476482

Epoch: 5| Step: 6
Training loss: 0.3909316062927246
Validation loss: 1.9674713065226872

Epoch: 5| Step: 7
Training loss: 0.39885959029197693
Validation loss: 1.9605153153340023

Epoch: 5| Step: 8
Training loss: 0.541436493396759
Validation loss: 1.9144346167643864

Epoch: 5| Step: 9
Training loss: 0.406821072101593
Validation loss: 1.8977326899766922

Epoch: 5| Step: 10
Training loss: 0.37070566415786743
Validation loss: 1.9402119666337967

Epoch: 5| Step: 11
Training loss: 0.6727874279022217
Validation loss: 1.9473202625910442

Epoch: 288| Step: 0
Training loss: 0.7093369960784912
Validation loss: 1.9681909283002217

Epoch: 5| Step: 1
Training loss: 0.7155308127403259
Validation loss: 1.9441542029380798

Epoch: 5| Step: 2
Training loss: 0.37773746252059937
Validation loss: 1.9485053072373073

Epoch: 5| Step: 3
Training loss: 0.7547281980514526
Validation loss: 1.9710608820120494

Epoch: 5| Step: 4
Training loss: 0.3637789785861969
Validation loss: 1.8724707514047623

Epoch: 5| Step: 5
Training loss: 0.3436688780784607
Validation loss: 1.9356823166211445

Epoch: 5| Step: 6
Training loss: 0.3556459844112396
Validation loss: 1.9012875308593113

Epoch: 5| Step: 7
Training loss: 0.5768938660621643
Validation loss: 1.9194026440382004

Epoch: 5| Step: 8
Training loss: 0.34523963928222656
Validation loss: 1.9447373400131862

Epoch: 5| Step: 9
Training loss: 0.31006112694740295
Validation loss: 1.9179302205642064

Epoch: 5| Step: 10
Training loss: 0.45424309372901917
Validation loss: 1.9352937638759613

Epoch: 5| Step: 11
Training loss: 0.14544560015201569
Validation loss: 1.9637476205825806

Epoch: 289| Step: 0
Training loss: 0.55670565366745
Validation loss: 2.0165821611881256

Epoch: 5| Step: 1
Training loss: 0.6268064379692078
Validation loss: 2.030504355827967

Epoch: 5| Step: 2
Training loss: 0.4597664475440979
Validation loss: 1.994044194618861

Epoch: 5| Step: 3
Training loss: 0.3831706643104553
Validation loss: 1.9545596639315288

Epoch: 5| Step: 4
Training loss: 0.2141120880842209
Validation loss: 1.9835931708415349

Epoch: 5| Step: 5
Training loss: 0.5759605169296265
Validation loss: 1.9101421733697255

Epoch: 5| Step: 6
Training loss: 0.38407188653945923
Validation loss: 1.9791110108296077

Epoch: 5| Step: 7
Training loss: 0.6200526356697083
Validation loss: 1.9638803452253342

Epoch: 5| Step: 8
Training loss: 0.5083240270614624
Validation loss: 1.9946307788292568

Epoch: 5| Step: 9
Training loss: 0.5834076404571533
Validation loss: 1.96001702050368

Epoch: 5| Step: 10
Training loss: 0.3456042408943176
Validation loss: 1.9554039140542347

Epoch: 5| Step: 11
Training loss: 0.5396329164505005
Validation loss: 1.997475768129031

Epoch: 290| Step: 0
Training loss: 0.46909791231155396
Validation loss: 2.014736130833626

Epoch: 5| Step: 1
Training loss: 0.6579362154006958
Validation loss: 2.029792288939158

Epoch: 5| Step: 2
Training loss: 0.3146205544471741
Validation loss: 1.9763185034195583

Epoch: 5| Step: 3
Training loss: 0.22094741463661194
Validation loss: 1.9784348607063293

Epoch: 5| Step: 4
Training loss: 0.44379884004592896
Validation loss: 1.9587058077255886

Epoch: 5| Step: 5
Training loss: 0.4311785101890564
Validation loss: 1.9678237984577815

Epoch: 5| Step: 6
Training loss: 0.3033970892429352
Validation loss: 1.8843886603911717

Epoch: 5| Step: 7
Training loss: 0.41433778405189514
Validation loss: 2.0012927055358887

Epoch: 5| Step: 8
Training loss: 0.3605274260044098
Validation loss: 1.9675518423318863

Epoch: 5| Step: 9
Training loss: 0.7299960851669312
Validation loss: 1.938291574517886

Epoch: 5| Step: 10
Training loss: 0.6766325831413269
Validation loss: 1.988488753636678

Epoch: 5| Step: 11
Training loss: 0.5920308232307434
Validation loss: 1.992616946498553

Epoch: 291| Step: 0
Training loss: 0.4252222180366516
Validation loss: 1.93215216199557

Epoch: 5| Step: 1
Training loss: 0.24296672642230988
Validation loss: 1.9685197571913402

Epoch: 5| Step: 2
Training loss: 0.41553670167922974
Validation loss: 1.9527109165986378

Epoch: 5| Step: 3
Training loss: 0.5242446660995483
Validation loss: 1.9443955222765605

Epoch: 5| Step: 4
Training loss: 0.4360359311103821
Validation loss: 1.9560524970293045

Epoch: 5| Step: 5
Training loss: 0.41379642486572266
Validation loss: 1.9260915517807007

Epoch: 5| Step: 6
Training loss: 0.40801969170570374
Validation loss: 1.9498370736837387

Epoch: 5| Step: 7
Training loss: 0.31000661849975586
Validation loss: 1.9821893125772476

Epoch: 5| Step: 8
Training loss: 0.9847160577774048
Validation loss: 2.007394293944041

Epoch: 5| Step: 9
Training loss: 0.3479512333869934
Validation loss: 1.9751951893170674

Epoch: 5| Step: 10
Training loss: 0.39301759004592896
Validation loss: 1.9939100792010624

Epoch: 5| Step: 11
Training loss: 0.6570450067520142
Validation loss: 2.0045393953720727

Epoch: 292| Step: 0
Training loss: 0.41318178176879883
Validation loss: 1.94871752957503

Epoch: 5| Step: 1
Training loss: 0.1880541890859604
Validation loss: 1.9330785274505615

Epoch: 5| Step: 2
Training loss: 0.5413742065429688
Validation loss: 1.9038798262675602

Epoch: 5| Step: 3
Training loss: 0.6584984064102173
Validation loss: 1.907983844478925

Epoch: 5| Step: 4
Training loss: 0.7053157091140747
Validation loss: 1.9739573746919632

Epoch: 5| Step: 5
Training loss: 0.23700609803199768
Validation loss: 1.9145561456680298

Epoch: 5| Step: 6
Training loss: 0.47094908356666565
Validation loss: 1.9562985102335613

Epoch: 5| Step: 7
Training loss: 0.7253812551498413
Validation loss: 1.9502494980891545

Epoch: 5| Step: 8
Training loss: 0.5434494614601135
Validation loss: 1.9295214017232258

Epoch: 5| Step: 9
Training loss: 0.36457645893096924
Validation loss: 1.978435570995013

Epoch: 5| Step: 10
Training loss: 0.29420632123947144
Validation loss: 1.9747085968653362

Epoch: 5| Step: 11
Training loss: 0.22210156917572021
Validation loss: 1.9942603756984074

Epoch: 293| Step: 0
Training loss: 0.2989794611930847
Validation loss: 1.9335871934890747

Epoch: 5| Step: 1
Training loss: 0.37970492243766785
Validation loss: 1.9766036967436473

Epoch: 5| Step: 2
Training loss: 0.6697012186050415
Validation loss: 1.937265728910764

Epoch: 5| Step: 3
Training loss: 0.46422162652015686
Validation loss: 1.9598800539970398

Epoch: 5| Step: 4
Training loss: 0.4160890579223633
Validation loss: 1.9624778081973393

Epoch: 5| Step: 5
Training loss: 0.5934537053108215
Validation loss: 1.9478865762551625

Epoch: 5| Step: 6
Training loss: 0.3119821548461914
Validation loss: 1.9436698506275814

Epoch: 5| Step: 7
Training loss: 0.2735261023044586
Validation loss: 1.9393465717633565

Epoch: 5| Step: 8
Training loss: 0.41982898116111755
Validation loss: 1.9640068709850311

Epoch: 5| Step: 9
Training loss: 0.5646342635154724
Validation loss: 1.9249745110670726

Epoch: 5| Step: 10
Training loss: 0.5402913093566895
Validation loss: 1.9416261663039525

Epoch: 5| Step: 11
Training loss: 0.3535498380661011
Validation loss: 1.9600738634665806

Epoch: 294| Step: 0
Training loss: 0.23486268520355225
Validation loss: 1.9399008850256603

Epoch: 5| Step: 1
Training loss: 0.3431274890899658
Validation loss: 1.9230924447377522

Epoch: 5| Step: 2
Training loss: 0.5412417650222778
Validation loss: 1.9586745351552963

Epoch: 5| Step: 3
Training loss: 0.517254650592804
Validation loss: 1.9431875695784886

Epoch: 5| Step: 4
Training loss: 0.5611422657966614
Validation loss: 1.9228649189074833

Epoch: 5| Step: 5
Training loss: 0.18974001705646515
Validation loss: 1.8912733048200607

Epoch: 5| Step: 6
Training loss: 0.47711554169654846
Validation loss: 1.9295847316582997

Epoch: 5| Step: 7
Training loss: 0.27830255031585693
Validation loss: 1.9226902226607006

Epoch: 5| Step: 8
Training loss: 0.4923602044582367
Validation loss: 1.9047857522964478

Epoch: 5| Step: 9
Training loss: 0.28842538595199585
Validation loss: 1.9621883779764175

Epoch: 5| Step: 10
Training loss: 0.6185609698295593
Validation loss: 1.9220724900563557

Epoch: 5| Step: 11
Training loss: 0.2112986296415329
Validation loss: 1.9365236014127731

Epoch: 295| Step: 0
Training loss: 0.4334603250026703
Validation loss: 1.9597649276256561

Epoch: 5| Step: 1
Training loss: 0.5997983813285828
Validation loss: 1.9924963812033336

Epoch: 5| Step: 2
Training loss: 0.605793833732605
Validation loss: 1.9981471796830494

Epoch: 5| Step: 3
Training loss: 0.31506457924842834
Validation loss: 1.9662524809439976

Epoch: 5| Step: 4
Training loss: 0.5079900622367859
Validation loss: 1.9441962291797001

Epoch: 5| Step: 5
Training loss: 0.34656617045402527
Validation loss: 2.003669038414955

Epoch: 5| Step: 6
Training loss: 0.3576461672782898
Validation loss: 1.8981442252794902

Epoch: 5| Step: 7
Training loss: 0.36968994140625
Validation loss: 1.9248982866605122

Epoch: 5| Step: 8
Training loss: 0.4355524480342865
Validation loss: 1.9390260775883992

Epoch: 5| Step: 9
Training loss: 0.3309580683708191
Validation loss: 1.9028413991133373

Epoch: 5| Step: 10
Training loss: 0.9126880764961243
Validation loss: 1.9128061334292095

Epoch: 5| Step: 11
Training loss: 0.4878607392311096
Validation loss: 1.9119499176740646

Epoch: 296| Step: 0
Training loss: 0.4474721848964691
Validation loss: 1.9637128661076229

Epoch: 5| Step: 1
Training loss: 0.26635268330574036
Validation loss: 1.9455797870953877

Epoch: 5| Step: 2
Training loss: 0.29315653443336487
Validation loss: 1.947263275583585

Epoch: 5| Step: 3
Training loss: 0.5260839462280273
Validation loss: 1.9137369741996129

Epoch: 5| Step: 4
Training loss: 0.583827018737793
Validation loss: 1.9508448640505474

Epoch: 5| Step: 5
Training loss: 0.41279205679893494
Validation loss: 1.9464887231588364

Epoch: 5| Step: 6
Training loss: 0.7703835368156433
Validation loss: 1.9405965904394786

Epoch: 5| Step: 7
Training loss: 0.5461258292198181
Validation loss: 1.8838813950618107

Epoch: 5| Step: 8
Training loss: 0.45189589262008667
Validation loss: 1.9420991291602452

Epoch: 5| Step: 9
Training loss: 0.38562241196632385
Validation loss: 1.960432380437851

Epoch: 5| Step: 10
Training loss: 0.30952292680740356
Validation loss: 1.9356008221705754

Epoch: 5| Step: 11
Training loss: 0.29205814003944397
Validation loss: 1.9747577706972759

Epoch: 297| Step: 0
Training loss: 0.32230144739151
Validation loss: 1.960784653822581

Epoch: 5| Step: 1
Training loss: 0.4058164656162262
Validation loss: 2.010622099041939

Epoch: 5| Step: 2
Training loss: 0.3203044533729553
Validation loss: 1.9386082490285237

Epoch: 5| Step: 3
Training loss: 0.7765101194381714
Validation loss: 1.9297315975030263

Epoch: 5| Step: 4
Training loss: 0.6064179539680481
Validation loss: 1.9687888969977696

Epoch: 5| Step: 5
Training loss: 0.4128722548484802
Validation loss: 1.9178409377733867

Epoch: 5| Step: 6
Training loss: 0.3802925944328308
Validation loss: 1.9262241125106812

Epoch: 5| Step: 7
Training loss: 0.4298911690711975
Validation loss: 1.945776437719663

Epoch: 5| Step: 8
Training loss: 0.37557801604270935
Validation loss: 1.9548701643943787

Epoch: 5| Step: 9
Training loss: 0.3702947497367859
Validation loss: 1.9874742130438487

Epoch: 5| Step: 10
Training loss: 0.4234181046485901
Validation loss: 1.9214180360237758

Epoch: 5| Step: 11
Training loss: 0.7936989665031433
Validation loss: 1.9960861504077911

Epoch: 298| Step: 0
Training loss: 0.4629850387573242
Validation loss: 1.9645848174889882

Epoch: 5| Step: 1
Training loss: 0.31650254130363464
Validation loss: 1.9101257572571437

Epoch: 5| Step: 2
Training loss: 0.24421855807304382
Validation loss: 1.960375001033147

Epoch: 5| Step: 3
Training loss: 0.7436695694923401
Validation loss: 1.9157052834828694

Epoch: 5| Step: 4
Training loss: 0.5002013444900513
Validation loss: 1.9922202626864116

Epoch: 5| Step: 5
Training loss: 0.2703574597835541
Validation loss: 1.9592925409475963

Epoch: 5| Step: 6
Training loss: 0.4785519540309906
Validation loss: 1.9545065114895503

Epoch: 5| Step: 7
Training loss: 0.5268210172653198
Validation loss: 1.9657833129167557

Epoch: 5| Step: 8
Training loss: 0.3827928900718689
Validation loss: 1.9258637328942616

Epoch: 5| Step: 9
Training loss: 0.38975661993026733
Validation loss: 1.9555153598388035

Epoch: 5| Step: 10
Training loss: 0.22309128940105438
Validation loss: 1.9056836813688278

Epoch: 5| Step: 11
Training loss: 0.19241178035736084
Validation loss: 1.9466794232527416

Epoch: 299| Step: 0
Training loss: 0.23483863472938538
Validation loss: 1.9791977951924007

Epoch: 5| Step: 1
Training loss: 0.28385138511657715
Validation loss: 1.9402378747860591

Epoch: 5| Step: 2
Training loss: 0.5195051431655884
Validation loss: 1.9129082163174946

Epoch: 5| Step: 3
Training loss: 0.43451642990112305
Validation loss: 1.9125007539987564

Epoch: 5| Step: 4
Training loss: 0.5366668701171875
Validation loss: 1.9485976447661717

Epoch: 5| Step: 5
Training loss: 0.9147368669509888
Validation loss: 1.9566543052593868

Epoch: 5| Step: 6
Training loss: 0.3429740369319916
Validation loss: 1.940167044599851

Epoch: 5| Step: 7
Training loss: 0.42416173219680786
Validation loss: 1.9812203645706177

Epoch: 5| Step: 8
Training loss: 0.5600727200508118
Validation loss: 2.001311108469963

Epoch: 5| Step: 9
Training loss: 0.25317883491516113
Validation loss: 1.956049730380376

Epoch: 5| Step: 10
Training loss: 0.34457534551620483
Validation loss: 1.953977808356285

Epoch: 5| Step: 11
Training loss: 0.13372524082660675
Validation loss: 1.9197651793559392

Epoch: 300| Step: 0
Training loss: 0.6569437980651855
Validation loss: 1.8855023284753163

Epoch: 5| Step: 1
Training loss: 0.37741819024086
Validation loss: 1.9190155863761902

Epoch: 5| Step: 2
Training loss: 0.36286661028862
Validation loss: 1.9273855934540431

Epoch: 5| Step: 3
Training loss: 0.4925605356693268
Validation loss: 1.9313052395979564

Epoch: 5| Step: 4
Training loss: 0.39803624153137207
Validation loss: 1.9339591811100643

Epoch: 5| Step: 5
Training loss: 0.539718747138977
Validation loss: 1.967905730009079

Epoch: 5| Step: 6
Training loss: 0.3918623924255371
Validation loss: 1.9497108310461044

Epoch: 5| Step: 7
Training loss: 0.4514356255531311
Validation loss: 1.9162873725096385

Epoch: 5| Step: 8
Training loss: 0.3270464241504669
Validation loss: 1.9351063321034114

Epoch: 5| Step: 9
Training loss: 0.26267677545547485
Validation loss: 1.943403775493304

Epoch: 5| Step: 10
Training loss: 0.32958298921585083
Validation loss: 1.9310323198636372

Epoch: 5| Step: 11
Training loss: 0.6955158710479736
Validation loss: 1.8913627515236537

Epoch: 301| Step: 0
Training loss: 0.5496867299079895
Validation loss: 1.9346547077099483

Epoch: 5| Step: 1
Training loss: 0.2777758240699768
Validation loss: 1.8845724016427994

Epoch: 5| Step: 2
Training loss: 0.4333828091621399
Validation loss: 1.9494087845087051

Epoch: 5| Step: 3
Training loss: 0.4472758173942566
Validation loss: 1.8924814562002819

Epoch: 5| Step: 4
Training loss: 0.43083199858665466
Validation loss: 1.9327638496955235

Epoch: 5| Step: 5
Training loss: 0.42789334058761597
Validation loss: 1.9621457954247792

Epoch: 5| Step: 6
Training loss: 0.4225592017173767
Validation loss: 1.9033012042442958

Epoch: 5| Step: 7
Training loss: 0.4388847351074219
Validation loss: 1.9383524109919865

Epoch: 5| Step: 8
Training loss: 0.33095383644104004
Validation loss: 1.8857475072145462

Epoch: 5| Step: 9
Training loss: 0.28284841775894165
Validation loss: 1.9151238650083542

Epoch: 5| Step: 10
Training loss: 0.45598167181015015
Validation loss: 1.9530615905920665

Epoch: 5| Step: 11
Training loss: 0.4027450978755951
Validation loss: 1.9412530809640884

Epoch: 302| Step: 0
Training loss: 0.6947662234306335
Validation loss: 1.9603575269381206

Epoch: 5| Step: 1
Training loss: 0.31515416502952576
Validation loss: 1.9649198452631633

Epoch: 5| Step: 2
Training loss: 0.3855488896369934
Validation loss: 2.0012695590655007

Epoch: 5| Step: 3
Training loss: 0.2781650722026825
Validation loss: 1.9274020045995712

Epoch: 5| Step: 4
Training loss: 0.3336261212825775
Validation loss: 1.9235774179299672

Epoch: 5| Step: 5
Training loss: 0.6209453344345093
Validation loss: 1.9097719093163807

Epoch: 5| Step: 6
Training loss: 0.5695751309394836
Validation loss: 1.8788434366385143

Epoch: 5| Step: 7
Training loss: 0.368425190448761
Validation loss: 1.923658862709999

Epoch: 5| Step: 8
Training loss: 0.39432045817375183
Validation loss: 1.9131056517362595

Epoch: 5| Step: 9
Training loss: 0.37987446784973145
Validation loss: 1.9379544307788212

Epoch: 5| Step: 10
Training loss: 0.6476941704750061
Validation loss: 1.9586873054504395

Epoch: 5| Step: 11
Training loss: 0.09234505891799927
Validation loss: 1.971181367834409

Epoch: 303| Step: 0
Training loss: 0.2993661165237427
Validation loss: 1.9540890157222748

Epoch: 5| Step: 1
Training loss: 0.5045110583305359
Validation loss: 1.9149567633867264

Epoch: 5| Step: 2
Training loss: 0.7630298733711243
Validation loss: 1.92593652009964

Epoch: 5| Step: 3
Training loss: 0.8064417839050293
Validation loss: 1.902724380294482

Epoch: 5| Step: 4
Training loss: 0.5306941866874695
Validation loss: 1.9022375643253326

Epoch: 5| Step: 5
Training loss: 0.4184432625770569
Validation loss: 1.903035079439481

Epoch: 5| Step: 6
Training loss: 0.3422371447086334
Validation loss: 1.8874499201774597

Epoch: 5| Step: 7
Training loss: 0.38463741540908813
Validation loss: 1.9036565224329631

Epoch: 5| Step: 8
Training loss: 0.27394309639930725
Validation loss: 1.9022845874230068

Epoch: 5| Step: 9
Training loss: 0.2877747416496277
Validation loss: 1.907205452521642

Epoch: 5| Step: 10
Training loss: 0.19532223045825958
Validation loss: 1.9156180620193481

Epoch: 5| Step: 11
Training loss: 0.31414973735809326
Validation loss: 1.9355937292178471

Epoch: 304| Step: 0
Training loss: 0.3436068594455719
Validation loss: 1.9208083947499592

Epoch: 5| Step: 1
Training loss: 0.55251145362854
Validation loss: 1.9632820188999176

Epoch: 5| Step: 2
Training loss: 0.24512434005737305
Validation loss: 1.8992767333984375

Epoch: 5| Step: 3
Training loss: 0.2997083365917206
Validation loss: 1.950381025671959

Epoch: 5| Step: 4
Training loss: 0.4608077108860016
Validation loss: 1.9216776589552562

Epoch: 5| Step: 5
Training loss: 0.35947710275650024
Validation loss: 1.9578545888264973

Epoch: 5| Step: 6
Training loss: 0.7119705080986023
Validation loss: 1.9198692739009857

Epoch: 5| Step: 7
Training loss: 0.33252185583114624
Validation loss: 1.9489687979221344

Epoch: 5| Step: 8
Training loss: 0.46091967821121216
Validation loss: 1.9404820303122203

Epoch: 5| Step: 9
Training loss: 0.33696916699409485
Validation loss: 1.931952695051829

Epoch: 5| Step: 10
Training loss: 0.5093971490859985
Validation loss: 1.9028117656707764

Epoch: 5| Step: 11
Training loss: 0.2351822853088379
Validation loss: 1.9695556461811066

Epoch: 305| Step: 0
Training loss: 0.3432663679122925
Validation loss: 1.9608697096506755

Epoch: 5| Step: 1
Training loss: 0.6078099012374878
Validation loss: 1.9673379858334858

Epoch: 5| Step: 2
Training loss: 0.3324646055698395
Validation loss: 1.9769581506649654

Epoch: 5| Step: 3
Training loss: 0.6504806876182556
Validation loss: 1.9443582793076832

Epoch: 5| Step: 4
Training loss: 0.41742438077926636
Validation loss: 1.9221622894207637

Epoch: 5| Step: 5
Training loss: 0.7107537388801575
Validation loss: 1.9204961856206257

Epoch: 5| Step: 6
Training loss: 0.46084022521972656
Validation loss: 1.901999145746231

Epoch: 5| Step: 7
Training loss: 0.35088053345680237
Validation loss: 1.9184648742278416

Epoch: 5| Step: 8
Training loss: 0.2712498903274536
Validation loss: 1.828376571337382

Epoch: 5| Step: 9
Training loss: 0.6319217085838318
Validation loss: 1.8998344888289769

Epoch: 5| Step: 10
Training loss: 0.30611443519592285
Validation loss: 1.9095298796892166

Epoch: 5| Step: 11
Training loss: 0.21272945404052734
Validation loss: 1.9159328540166218

Epoch: 306| Step: 0
Training loss: 0.5256139636039734
Validation loss: 1.9342178652683895

Epoch: 5| Step: 1
Training loss: 0.26986265182495117
Validation loss: 1.9090937276681264

Epoch: 5| Step: 2
Training loss: 0.47006845474243164
Validation loss: 1.8627819170554478

Epoch: 5| Step: 3
Training loss: 0.21903061866760254
Validation loss: 1.945888340473175

Epoch: 5| Step: 4
Training loss: 0.28512877225875854
Validation loss: 1.8877656211455662

Epoch: 5| Step: 5
Training loss: 0.6611323356628418
Validation loss: 1.891533891359965

Epoch: 5| Step: 6
Training loss: 0.5705180764198303
Validation loss: 1.899186983704567

Epoch: 5| Step: 7
Training loss: 0.4705497622489929
Validation loss: 1.9334818124771118

Epoch: 5| Step: 8
Training loss: 0.3513149321079254
Validation loss: 1.947795699040095

Epoch: 5| Step: 9
Training loss: 0.16723951697349548
Validation loss: 1.9212569395701091

Epoch: 5| Step: 10
Training loss: 0.4934338629245758
Validation loss: 1.9793474574883778

Epoch: 5| Step: 11
Training loss: 1.28898286819458
Validation loss: 1.9480227281649907

Epoch: 307| Step: 0
Training loss: 0.7656511068344116
Validation loss: 1.9749554445346196

Epoch: 5| Step: 1
Training loss: 0.513832688331604
Validation loss: 1.9775497665007908

Epoch: 5| Step: 2
Training loss: 0.2679658830165863
Validation loss: 1.9086292187372844

Epoch: 5| Step: 3
Training loss: 0.5143886804580688
Validation loss: 1.9013934483130772

Epoch: 5| Step: 4
Training loss: 0.2917844355106354
Validation loss: 1.9686046292384465

Epoch: 5| Step: 5
Training loss: 0.4375789165496826
Validation loss: 1.9301499525705974

Epoch: 5| Step: 6
Training loss: 0.5264562368392944
Validation loss: 1.9498376150925953

Epoch: 5| Step: 7
Training loss: 0.38815170526504517
Validation loss: 1.9662170708179474

Epoch: 5| Step: 8
Training loss: 0.3496236503124237
Validation loss: 1.9426434685786564

Epoch: 5| Step: 9
Training loss: 0.31135401129722595
Validation loss: 1.9930420468250911

Epoch: 5| Step: 10
Training loss: 0.4151706099510193
Validation loss: 2.004037300745646

Epoch: 5| Step: 11
Training loss: 0.5666576623916626
Validation loss: 1.9727369993925095

Epoch: 308| Step: 0
Training loss: 0.34142327308654785
Validation loss: 1.9353504727284114

Epoch: 5| Step: 1
Training loss: 0.5566271543502808
Validation loss: 1.940472240249316

Epoch: 5| Step: 2
Training loss: 0.41172170639038086
Validation loss: 1.9458043972651164

Epoch: 5| Step: 3
Training loss: 0.4991578161716461
Validation loss: 1.9530829042196274

Epoch: 5| Step: 4
Training loss: 0.4168630540370941
Validation loss: 1.9442452142635982

Epoch: 5| Step: 5
Training loss: 0.21727117896080017
Validation loss: 1.9270880421002705

Epoch: 5| Step: 6
Training loss: 0.3772944509983063
Validation loss: 1.928408255179723

Epoch: 5| Step: 7
Training loss: 0.5024632215499878
Validation loss: 1.955537110567093

Epoch: 5| Step: 8
Training loss: 0.49022379517555237
Validation loss: 1.971051846941312

Epoch: 5| Step: 9
Training loss: 0.37508636713027954
Validation loss: 1.988679826259613

Epoch: 5| Step: 10
Training loss: 0.307468980550766
Validation loss: 2.0083794246117272

Epoch: 5| Step: 11
Training loss: 2.1313846111297607
Validation loss: 1.9613177329301834

Epoch: 309| Step: 0
Training loss: 0.3194374442100525
Validation loss: 1.9313813348611195

Epoch: 5| Step: 1
Training loss: 0.7108346223831177
Validation loss: 1.90093994140625

Epoch: 5| Step: 2
Training loss: 0.3349519371986389
Validation loss: 1.8868142714103062

Epoch: 5| Step: 3
Training loss: 0.5191842317581177
Validation loss: 1.9158289035161336

Epoch: 5| Step: 4
Training loss: 0.42717471718788147
Validation loss: 1.9228018422921498

Epoch: 5| Step: 5
Training loss: 0.2760081887245178
Validation loss: 1.900042509039243

Epoch: 5| Step: 6
Training loss: 0.3874213695526123
Validation loss: 1.943956697980563

Epoch: 5| Step: 7
Training loss: 0.363513320684433
Validation loss: 1.9066150337457657

Epoch: 5| Step: 8
Training loss: 0.4144924581050873
Validation loss: 1.9125811209281285

Epoch: 5| Step: 9
Training loss: 0.41321617364883423
Validation loss: 1.8865565011898677

Epoch: 5| Step: 10
Training loss: 0.4348537027835846
Validation loss: 1.933732693394025

Epoch: 5| Step: 11
Training loss: 0.3107535243034363
Validation loss: 1.9084981779257457

Epoch: 310| Step: 0
Training loss: 0.3745385408401489
Validation loss: 1.929719512661298

Epoch: 5| Step: 1
Training loss: 0.7175958156585693
Validation loss: 1.9430579592784245

Epoch: 5| Step: 2
Training loss: 0.21827106177806854
Validation loss: 1.938112994035085

Epoch: 5| Step: 3
Training loss: 0.3817409574985504
Validation loss: 1.9389043649037678

Epoch: 5| Step: 4
Training loss: 0.37633606791496277
Validation loss: 1.9675883253415425

Epoch: 5| Step: 5
Training loss: 0.5000079274177551
Validation loss: 1.9594998806715012

Epoch: 5| Step: 6
Training loss: 0.479658842086792
Validation loss: 1.9682969550291698

Epoch: 5| Step: 7
Training loss: 0.2577168643474579
Validation loss: 1.964353879292806

Epoch: 5| Step: 8
Training loss: 0.33485597372055054
Validation loss: 1.9205414752165477

Epoch: 5| Step: 9
Training loss: 0.4757438600063324
Validation loss: 1.9174978981415431

Epoch: 5| Step: 10
Training loss: 0.31056156754493713
Validation loss: 1.9700328360001247

Epoch: 5| Step: 11
Training loss: 0.08510762453079224
Validation loss: 1.90219580133756

Epoch: 311| Step: 0
Training loss: 0.2202567607164383
Validation loss: 1.9257860332727432

Epoch: 5| Step: 1
Training loss: 0.4060351848602295
Validation loss: 1.9476830313603084

Epoch: 5| Step: 2
Training loss: 0.767176628112793
Validation loss: 2.024856468041738

Epoch: 5| Step: 3
Training loss: 0.4087666869163513
Validation loss: 2.0064445634682975

Epoch: 5| Step: 4
Training loss: 0.4887779653072357
Validation loss: 1.9448672781387966

Epoch: 5| Step: 5
Training loss: 0.25402408838272095
Validation loss: 1.9635571738084157

Epoch: 5| Step: 6
Training loss: 0.6609188914299011
Validation loss: 1.9008596390485764

Epoch: 5| Step: 7
Training loss: 0.30998462438583374
Validation loss: 1.9667693227529526

Epoch: 5| Step: 8
Training loss: 0.641282320022583
Validation loss: 1.9475370794534683

Epoch: 5| Step: 9
Training loss: 0.18449607491493225
Validation loss: 1.9052218794822693

Epoch: 5| Step: 10
Training loss: 0.28667593002319336
Validation loss: 1.9337028016646702

Epoch: 5| Step: 11
Training loss: 0.43941909074783325
Validation loss: 1.9318992992242177

Epoch: 312| Step: 0
Training loss: 0.3825779855251312
Validation loss: 1.9426785111427307

Epoch: 5| Step: 1
Training loss: 0.3900756239891052
Validation loss: 1.9385366588830948

Epoch: 5| Step: 2
Training loss: 0.14772994816303253
Validation loss: 1.9306643108526866

Epoch: 5| Step: 3
Training loss: 0.8678970336914062
Validation loss: 1.9039913068215053

Epoch: 5| Step: 4
Training loss: 0.2697741389274597
Validation loss: 1.8967047085364659

Epoch: 5| Step: 5
Training loss: 0.2026718109846115
Validation loss: 1.9061508973439534

Epoch: 5| Step: 6
Training loss: 0.46905454993247986
Validation loss: 1.9341572175423305

Epoch: 5| Step: 7
Training loss: 0.21963074803352356
Validation loss: 1.890472799539566

Epoch: 5| Step: 8
Training loss: 0.5088465809822083
Validation loss: 1.9170423398415248

Epoch: 5| Step: 9
Training loss: 0.3838074505329132
Validation loss: 1.9329703897237778

Epoch: 5| Step: 10
Training loss: 0.3744872212409973
Validation loss: 1.9544107764959335

Epoch: 5| Step: 11
Training loss: 0.5555115938186646
Validation loss: 1.908764272928238

Epoch: 313| Step: 0
Training loss: 0.4215991497039795
Validation loss: 1.9015616923570633

Epoch: 5| Step: 1
Training loss: 0.21653743088245392
Validation loss: 1.941746284564336

Epoch: 5| Step: 2
Training loss: 0.34454935789108276
Validation loss: 1.8942347417275112

Epoch: 5| Step: 3
Training loss: 0.4166475832462311
Validation loss: 1.911660169561704

Epoch: 5| Step: 4
Training loss: 0.23286893963813782
Validation loss: 1.923474133014679

Epoch: 5| Step: 5
Training loss: 0.37216028571128845
Validation loss: 1.9361031651496887

Epoch: 5| Step: 6
Training loss: 0.6126686930656433
Validation loss: 1.9636787225802739

Epoch: 5| Step: 7
Training loss: 0.6720872521400452
Validation loss: 1.985805129011472

Epoch: 5| Step: 8
Training loss: 0.21967509388923645
Validation loss: 1.9268154154221218

Epoch: 5| Step: 9
Training loss: 0.23996207118034363
Validation loss: 1.8991001546382904

Epoch: 5| Step: 10
Training loss: 0.6640204191207886
Validation loss: 1.9027732014656067

Epoch: 5| Step: 11
Training loss: 0.1535978466272354
Validation loss: 1.9231110761562984

Epoch: 314| Step: 0
Training loss: 0.1993618607521057
Validation loss: 1.8805355827013652

Epoch: 5| Step: 1
Training loss: 0.18261489272117615
Validation loss: 1.9187283664941788

Epoch: 5| Step: 2
Training loss: 0.35834643244743347
Validation loss: 1.939723551273346

Epoch: 5| Step: 3
Training loss: 0.9397310018539429
Validation loss: 1.9167589098215103

Epoch: 5| Step: 4
Training loss: 0.27075839042663574
Validation loss: 2.0022694816191993

Epoch: 5| Step: 5
Training loss: 0.42321261763572693
Validation loss: 1.9191618462403615

Epoch: 5| Step: 6
Training loss: 0.5297989249229431
Validation loss: 1.9279681295156479

Epoch: 5| Step: 7
Training loss: 0.3801872134208679
Validation loss: 1.860664630929629

Epoch: 5| Step: 8
Training loss: 0.32538944482803345
Validation loss: 1.915795346101125

Epoch: 5| Step: 9
Training loss: 0.5432943105697632
Validation loss: 1.9450927277406056

Epoch: 5| Step: 10
Training loss: 0.3754492402076721
Validation loss: 1.870941589275996

Epoch: 5| Step: 11
Training loss: 0.9859378337860107
Validation loss: 1.9132352123657863

Epoch: 315| Step: 0
Training loss: 0.3803127110004425
Validation loss: 1.9071641862392426

Epoch: 5| Step: 1
Training loss: 0.3393988609313965
Validation loss: 1.9554278900225956

Epoch: 5| Step: 2
Training loss: 0.277646005153656
Validation loss: 1.8993219236532848

Epoch: 5| Step: 3
Training loss: 0.3342720866203308
Validation loss: 1.9424965232610703

Epoch: 5| Step: 4
Training loss: 0.6737228631973267
Validation loss: 1.967148741086324

Epoch: 5| Step: 5
Training loss: 0.7539337873458862
Validation loss: 1.919402003288269

Epoch: 5| Step: 6
Training loss: 0.21545347571372986
Validation loss: 1.9334516525268555

Epoch: 5| Step: 7
Training loss: 0.2934191823005676
Validation loss: 1.9474163800477982

Epoch: 5| Step: 8
Training loss: 0.33440718054771423
Validation loss: 1.9149818668762844

Epoch: 5| Step: 9
Training loss: 0.28006502985954285
Validation loss: 1.9693539291620255

Epoch: 5| Step: 10
Training loss: 0.484668493270874
Validation loss: 1.9285432050625484

Epoch: 5| Step: 11
Training loss: 0.17203056812286377
Validation loss: 1.9205992221832275

Epoch: 316| Step: 0
Training loss: 0.3290690779685974
Validation loss: 1.9601616710424423

Epoch: 5| Step: 1
Training loss: 0.3259899914264679
Validation loss: 1.9351869821548462

Epoch: 5| Step: 2
Training loss: 0.3569011986255646
Validation loss: 1.9045416414737701

Epoch: 5| Step: 3
Training loss: 0.2988237738609314
Validation loss: 1.9255912055571873

Epoch: 5| Step: 4
Training loss: 0.3964138329029083
Validation loss: 1.8894051263729732

Epoch: 5| Step: 5
Training loss: 0.6251448392868042
Validation loss: 1.9664373745520909

Epoch: 5| Step: 6
Training loss: 0.4464193284511566
Validation loss: 1.9475874801476796

Epoch: 5| Step: 7
Training loss: 0.3241354823112488
Validation loss: 1.9819484303394954

Epoch: 5| Step: 8
Training loss: 0.4758118689060211
Validation loss: 1.9460120846827824

Epoch: 5| Step: 9
Training loss: 0.61529940366745
Validation loss: 1.924645905693372

Epoch: 5| Step: 10
Training loss: 0.20645923912525177
Validation loss: 1.8961103061834972

Epoch: 5| Step: 11
Training loss: 1.0790319442749023
Validation loss: 1.885185847679774

Epoch: 317| Step: 0
Training loss: 0.3321143686771393
Validation loss: 1.8904791921377182

Epoch: 5| Step: 1
Training loss: 0.6085265278816223
Validation loss: 1.926569367448489

Epoch: 5| Step: 2
Training loss: 0.734843909740448
Validation loss: 1.8916999051968257

Epoch: 5| Step: 3
Training loss: 0.3092833459377289
Validation loss: 1.8844873309135437

Epoch: 5| Step: 4
Training loss: 0.3964333236217499
Validation loss: 1.8472249805927277

Epoch: 5| Step: 5
Training loss: 0.381902813911438
Validation loss: 1.8709646910429

Epoch: 5| Step: 6
Training loss: 0.2803412675857544
Validation loss: 1.9201061477263768

Epoch: 5| Step: 7
Training loss: 0.5320046544075012
Validation loss: 1.9365889777739842

Epoch: 5| Step: 8
Training loss: 0.5293753743171692
Validation loss: 1.963310440381368

Epoch: 5| Step: 9
Training loss: 0.2146620750427246
Validation loss: 1.9331514288981755

Epoch: 5| Step: 10
Training loss: 0.4008534550666809
Validation loss: 1.8947088619073231

Epoch: 5| Step: 11
Training loss: 0.14943741261959076
Validation loss: 1.9543422261873882

Epoch: 318| Step: 0
Training loss: 0.65657639503479
Validation loss: 1.9391103386878967

Epoch: 5| Step: 1
Training loss: 0.6046844124794006
Validation loss: 1.92996251086394

Epoch: 5| Step: 2
Training loss: 0.38394659757614136
Validation loss: 1.9206905017296474

Epoch: 5| Step: 3
Training loss: 0.16291065514087677
Validation loss: 1.9017293204863865

Epoch: 5| Step: 4
Training loss: 0.24980345368385315
Validation loss: 1.9625029464562733

Epoch: 5| Step: 5
Training loss: 0.5328341126441956
Validation loss: 1.9491840998331706

Epoch: 5| Step: 6
Training loss: 0.39799603819847107
Validation loss: 1.9856366515159607

Epoch: 5| Step: 7
Training loss: 0.4091181755065918
Validation loss: 1.950502062837283

Epoch: 5| Step: 8
Training loss: 0.21160802245140076
Validation loss: 1.8868538836638133

Epoch: 5| Step: 9
Training loss: 0.3224959075450897
Validation loss: 1.9247017949819565

Epoch: 5| Step: 10
Training loss: 0.373683363199234
Validation loss: 1.9007917443911235

Epoch: 5| Step: 11
Training loss: 0.08730030804872513
Validation loss: 1.9314268479744594

Epoch: 319| Step: 0
Training loss: 0.29854243993759155
Validation loss: 1.9612861822048824

Epoch: 5| Step: 1
Training loss: 0.597435474395752
Validation loss: 1.9237544685602188

Epoch: 5| Step: 2
Training loss: 0.19363316893577576
Validation loss: 1.989075854420662

Epoch: 5| Step: 3
Training loss: 0.43667617440223694
Validation loss: 1.927947610616684

Epoch: 5| Step: 4
Training loss: 0.3689574599266052
Validation loss: 1.951418439547221

Epoch: 5| Step: 5
Training loss: 0.4081541895866394
Validation loss: 1.9527704914410908

Epoch: 5| Step: 6
Training loss: 0.6047044992446899
Validation loss: 1.9484840581814449

Epoch: 5| Step: 7
Training loss: 0.2111138552427292
Validation loss: 1.9006717453400295

Epoch: 5| Step: 8
Training loss: 0.3453832268714905
Validation loss: 1.946685532728831

Epoch: 5| Step: 9
Training loss: 0.5543553233146667
Validation loss: 1.911106099685033

Epoch: 5| Step: 10
Training loss: 0.35475030541419983
Validation loss: 1.9697772314151127

Epoch: 5| Step: 11
Training loss: 0.3005106449127197
Validation loss: 1.9176082114378612

Epoch: 320| Step: 0
Training loss: 0.3649675250053406
Validation loss: 1.948260098695755

Epoch: 5| Step: 1
Training loss: 0.49275606870651245
Validation loss: 1.9701266586780548

Epoch: 5| Step: 2
Training loss: 0.7575762867927551
Validation loss: 2.0043706546227136

Epoch: 5| Step: 3
Training loss: 0.3393479883670807
Validation loss: 1.9434491097927094

Epoch: 5| Step: 4
Training loss: 0.37379390001296997
Validation loss: 1.9362435589234035

Epoch: 5| Step: 5
Training loss: 0.3538134694099426
Validation loss: 1.908051609992981

Epoch: 5| Step: 6
Training loss: 0.4982271194458008
Validation loss: 1.8708161264657974

Epoch: 5| Step: 7
Training loss: 0.1899690330028534
Validation loss: 1.9392266819874446

Epoch: 5| Step: 8
Training loss: 0.3475663661956787
Validation loss: 1.9282081027825673

Epoch: 5| Step: 9
Training loss: 0.5781977772712708
Validation loss: 1.9365775535504024

Epoch: 5| Step: 10
Training loss: 0.2704732120037079
Validation loss: 1.9483614315589268

Epoch: 5| Step: 11
Training loss: 0.37128153443336487
Validation loss: 1.9243800987799962

Epoch: 321| Step: 0
Training loss: 0.20208939909934998
Validation loss: 1.9291841785113018

Epoch: 5| Step: 1
Training loss: 0.2408715784549713
Validation loss: 1.9167571167151134

Epoch: 5| Step: 2
Training loss: 0.4011310935020447
Validation loss: 1.9400312354167302

Epoch: 5| Step: 3
Training loss: 0.5011674761772156
Validation loss: 1.8995332022507985

Epoch: 5| Step: 4
Training loss: 0.37561291456222534
Validation loss: 1.9234707007805507

Epoch: 5| Step: 5
Training loss: 0.3647841513156891
Validation loss: 1.899899293979009

Epoch: 5| Step: 6
Training loss: 0.17912864685058594
Validation loss: 1.9261005421479542

Epoch: 5| Step: 7
Training loss: 0.2644408941268921
Validation loss: 1.9042287170886993

Epoch: 5| Step: 8
Training loss: 0.39470070600509644
Validation loss: 1.9285060167312622

Epoch: 5| Step: 9
Training loss: 0.4611188769340515
Validation loss: 1.9692125568787258

Epoch: 5| Step: 10
Training loss: 0.8632513284683228
Validation loss: 1.9664274454116821

Epoch: 5| Step: 11
Training loss: 0.6635993719100952
Validation loss: 1.957253431280454

Epoch: 322| Step: 0
Training loss: 0.3046792149543762
Validation loss: 1.9336401869853337

Epoch: 5| Step: 1
Training loss: 0.28539544343948364
Validation loss: 1.8973796566327412

Epoch: 5| Step: 2
Training loss: 0.47959351539611816
Validation loss: 1.915666287144025

Epoch: 5| Step: 3
Training loss: 0.4809085726737976
Validation loss: 1.9309087246656418

Epoch: 5| Step: 4
Training loss: 0.4224192202091217
Validation loss: 1.9572073221206665

Epoch: 5| Step: 5
Training loss: 0.2507621943950653
Validation loss: 1.957834353049596

Epoch: 5| Step: 6
Training loss: 0.21478626132011414
Validation loss: 1.963728244105975

Epoch: 5| Step: 7
Training loss: 0.44161123037338257
Validation loss: 1.9470601975917816

Epoch: 5| Step: 8
Training loss: 0.2908981740474701
Validation loss: 1.9789148221413295

Epoch: 5| Step: 9
Training loss: 0.3525773584842682
Validation loss: 1.9354331195354462

Epoch: 5| Step: 10
Training loss: 0.7194241285324097
Validation loss: 1.930961698293686

Epoch: 5| Step: 11
Training loss: 0.1025841236114502
Validation loss: 1.9568228423595428

Epoch: 323| Step: 0
Training loss: 0.36046507954597473
Validation loss: 1.9670400470495224

Epoch: 5| Step: 1
Training loss: 0.36292368173599243
Validation loss: 1.8888253072897594

Epoch: 5| Step: 2
Training loss: 0.48901090025901794
Validation loss: 1.9123015403747559

Epoch: 5| Step: 3
Training loss: 0.416421115398407
Validation loss: 1.8932172358036041

Epoch: 5| Step: 4
Training loss: 0.30872201919555664
Validation loss: 1.9375699112812679

Epoch: 5| Step: 5
Training loss: 0.34464919567108154
Validation loss: 1.9404671291510265

Epoch: 5| Step: 6
Training loss: 0.3589775562286377
Validation loss: 1.9979800780614216

Epoch: 5| Step: 7
Training loss: 0.7898150682449341
Validation loss: 1.986826668183009

Epoch: 5| Step: 8
Training loss: 0.46452197432518005
Validation loss: 1.904917041460673

Epoch: 5| Step: 9
Training loss: 0.47319379448890686
Validation loss: 1.889835109313329

Epoch: 5| Step: 10
Training loss: 0.20990581810474396
Validation loss: 1.893826887011528

Epoch: 5| Step: 11
Training loss: 0.277340292930603
Validation loss: 1.9087932507197063

Epoch: 324| Step: 0
Training loss: 0.5046230554580688
Validation loss: 1.9556753585735958

Epoch: 5| Step: 1
Training loss: 0.46895474195480347
Validation loss: 2.0178566525379815

Epoch: 5| Step: 2
Training loss: 0.6627839803695679
Validation loss: 1.9719454844792683

Epoch: 5| Step: 3
Training loss: 0.43448466062545776
Validation loss: 1.9420418739318848

Epoch: 5| Step: 4
Training loss: 0.30733880400657654
Validation loss: 1.8920113344987233

Epoch: 5| Step: 5
Training loss: 0.7726798057556152
Validation loss: 1.9353135973215103

Epoch: 5| Step: 6
Training loss: 0.20350134372711182
Validation loss: 1.9229331811269124

Epoch: 5| Step: 7
Training loss: 0.2700953483581543
Validation loss: 1.899963806072871

Epoch: 5| Step: 8
Training loss: 0.3709709346294403
Validation loss: 1.9062100599209468

Epoch: 5| Step: 9
Training loss: 0.6302809119224548
Validation loss: 1.9322544137636821

Epoch: 5| Step: 10
Training loss: 0.36046141386032104
Validation loss: 1.9538197716077168

Epoch: 5| Step: 11
Training loss: 0.22826743125915527
Validation loss: 2.0076221277316413

Epoch: 325| Step: 0
Training loss: 0.21082468330860138
Validation loss: 1.9699584046999614

Epoch: 5| Step: 1
Training loss: 0.23385891318321228
Validation loss: 2.0060936361551285

Epoch: 5| Step: 2
Training loss: 0.430563747882843
Validation loss: 1.9977513303359349

Epoch: 5| Step: 3
Training loss: 0.35443323850631714
Validation loss: 1.8972192307313283

Epoch: 5| Step: 4
Training loss: 0.24838538467884064
Validation loss: 1.960340107480685

Epoch: 5| Step: 5
Training loss: 0.33561426401138306
Validation loss: 1.9129706174135208

Epoch: 5| Step: 6
Training loss: 0.5780163407325745
Validation loss: 1.9124612659215927

Epoch: 5| Step: 7
Training loss: 0.3353738486766815
Validation loss: 1.9062364647785823

Epoch: 5| Step: 8
Training loss: 0.49069175124168396
Validation loss: 1.9678983787695568

Epoch: 5| Step: 9
Training loss: 0.37613388895988464
Validation loss: 1.9876893957455952

Epoch: 5| Step: 10
Training loss: 0.47003450989723206
Validation loss: 1.937098686893781

Epoch: 5| Step: 11
Training loss: 0.8846171498298645
Validation loss: 1.969476987918218

Epoch: 326| Step: 0
Training loss: 0.5817673802375793
Validation loss: 1.955397829413414

Epoch: 5| Step: 1
Training loss: 0.4776557981967926
Validation loss: 1.9193753451108932

Epoch: 5| Step: 2
Training loss: 0.3880337178707123
Validation loss: 1.9605181316534679

Epoch: 5| Step: 3
Training loss: 0.7486652135848999
Validation loss: 1.9314344028631847

Epoch: 5| Step: 4
Training loss: 0.331935852766037
Validation loss: 1.9726254890362422

Epoch: 5| Step: 5
Training loss: 0.34465301036834717
Validation loss: 1.8841499040524166

Epoch: 5| Step: 6
Training loss: 0.4022095799446106
Validation loss: 1.9290243337551753

Epoch: 5| Step: 7
Training loss: 0.23302611708641052
Validation loss: 1.9440676718950272

Epoch: 5| Step: 8
Training loss: 0.28417930006980896
Validation loss: 2.0145107557376227

Epoch: 5| Step: 9
Training loss: 0.394826203584671
Validation loss: 1.9094046354293823

Epoch: 5| Step: 10
Training loss: 0.35170871019363403
Validation loss: 1.9461092551549275

Epoch: 5| Step: 11
Training loss: 0.1968686580657959
Validation loss: 1.9120739499727886

Epoch: 327| Step: 0
Training loss: 0.37600192427635193
Validation loss: 1.8838736961285274

Epoch: 5| Step: 1
Training loss: 0.46214359998703003
Validation loss: 1.9287770241498947

Epoch: 5| Step: 2
Training loss: 0.8174597024917603
Validation loss: 1.9254528880119324

Epoch: 5| Step: 3
Training loss: 0.5195875763893127
Validation loss: 1.871672158439954

Epoch: 5| Step: 4
Training loss: 0.27024561166763306
Validation loss: 1.8820761640866597

Epoch: 5| Step: 5
Training loss: 0.2885856032371521
Validation loss: 1.8943957487742107

Epoch: 5| Step: 6
Training loss: 0.3707166910171509
Validation loss: 1.9354488203922908

Epoch: 5| Step: 7
Training loss: 0.47997069358825684
Validation loss: 1.917471374074618

Epoch: 5| Step: 8
Training loss: 0.38889575004577637
Validation loss: 1.957283228635788

Epoch: 5| Step: 9
Training loss: 0.3715559244155884
Validation loss: 1.920160378019015

Epoch: 5| Step: 10
Training loss: 0.36538833379745483
Validation loss: 1.9178092777729034

Epoch: 5| Step: 11
Training loss: 0.11515378952026367
Validation loss: 1.8990638901789982

Epoch: 328| Step: 0
Training loss: 0.495045006275177
Validation loss: 1.9004441102345784

Epoch: 5| Step: 1
Training loss: 0.27233320474624634
Validation loss: 1.901886026064555

Epoch: 5| Step: 2
Training loss: 0.4893370568752289
Validation loss: 1.8635974774758022

Epoch: 5| Step: 3
Training loss: 0.5025418400764465
Validation loss: 1.8885517567396164

Epoch: 5| Step: 4
Training loss: 0.8230676651000977
Validation loss: 1.9091239124536514

Epoch: 5| Step: 5
Training loss: 0.40083760023117065
Validation loss: 1.9187171757221222

Epoch: 5| Step: 6
Training loss: 0.22765186429023743
Validation loss: 1.929393693804741

Epoch: 5| Step: 7
Training loss: 0.33027806878089905
Validation loss: 1.9845624665419261

Epoch: 5| Step: 8
Training loss: 0.4954422414302826
Validation loss: 1.9574580043554306

Epoch: 5| Step: 9
Training loss: 0.3305477201938629
Validation loss: 1.9192685882250469

Epoch: 5| Step: 10
Training loss: 0.35182052850723267
Validation loss: 1.9519766867160797

Epoch: 5| Step: 11
Training loss: 0.8381215333938599
Validation loss: 1.9374686280886333

Epoch: 329| Step: 0
Training loss: 0.4187167286872864
Validation loss: 1.8849360396464665

Epoch: 5| Step: 1
Training loss: 0.7346525192260742
Validation loss: 1.8619931091864903

Epoch: 5| Step: 2
Training loss: 0.29127776622772217
Validation loss: 1.8627170771360397

Epoch: 5| Step: 3
Training loss: 0.3756377100944519
Validation loss: 1.9127568354209263

Epoch: 5| Step: 4
Training loss: 0.43994060158729553
Validation loss: 1.940573627750079

Epoch: 5| Step: 5
Training loss: 0.2359221875667572
Validation loss: 1.9104001571734746

Epoch: 5| Step: 6
Training loss: 0.7487552762031555
Validation loss: 1.9283493757247925

Epoch: 5| Step: 7
Training loss: 0.30381423234939575
Validation loss: 1.9966701318820317

Epoch: 5| Step: 8
Training loss: 0.3285589814186096
Validation loss: 1.9855526089668274

Epoch: 5| Step: 9
Training loss: 0.3490740954875946
Validation loss: 1.9690883805354435

Epoch: 5| Step: 10
Training loss: 0.2886693477630615
Validation loss: 1.9387103418509166

Epoch: 5| Step: 11
Training loss: 0.5735949277877808
Validation loss: 1.9210963894923527

Epoch: 330| Step: 0
Training loss: 0.24817319214344025
Validation loss: 1.9453921914100647

Epoch: 5| Step: 1
Training loss: 0.43192020058631897
Validation loss: 1.899676536520322

Epoch: 5| Step: 2
Training loss: 0.28422629833221436
Validation loss: 1.9178348282972972

Epoch: 5| Step: 3
Training loss: 0.291908860206604
Validation loss: 1.9371239095926285

Epoch: 5| Step: 4
Training loss: 0.5802459120750427
Validation loss: 1.949621210495631

Epoch: 5| Step: 5
Training loss: 0.4000421464443207
Validation loss: 1.9730882048606873

Epoch: 5| Step: 6
Training loss: 0.6774075627326965
Validation loss: 1.9774591078360875

Epoch: 5| Step: 7
Training loss: 0.5361021757125854
Validation loss: 1.98171466588974

Epoch: 5| Step: 8
Training loss: 0.4318157136440277
Validation loss: 1.9970751057068508

Epoch: 5| Step: 9
Training loss: 0.2823052406311035
Validation loss: 1.9703555752833684

Epoch: 5| Step: 10
Training loss: 0.3777981698513031
Validation loss: 1.9313476234674454

Epoch: 5| Step: 11
Training loss: 0.2264132797718048
Validation loss: 1.936872790257136

Epoch: 331| Step: 0
Training loss: 0.2586131989955902
Validation loss: 1.9210569510857265

Epoch: 5| Step: 1
Training loss: 0.5260328650474548
Validation loss: 1.9315931995709736

Epoch: 5| Step: 2
Training loss: 0.2709455192089081
Validation loss: 1.9783493330081303

Epoch: 5| Step: 3
Training loss: 0.28699904680252075
Validation loss: 1.9453414132197697

Epoch: 5| Step: 4
Training loss: 0.5950853228569031
Validation loss: 1.9540776213010151

Epoch: 5| Step: 5
Training loss: 0.37796851992607117
Validation loss: 1.9714276989301045

Epoch: 5| Step: 6
Training loss: 0.17803038656711578
Validation loss: 1.9421304613351822

Epoch: 5| Step: 7
Training loss: 0.3713413178920746
Validation loss: 1.9096079021692276

Epoch: 5| Step: 8
Training loss: 0.30719444155693054
Validation loss: 1.9553206066290538

Epoch: 5| Step: 9
Training loss: 0.5036487579345703
Validation loss: 1.9646485696236293

Epoch: 5| Step: 10
Training loss: 0.3700506091117859
Validation loss: 1.9165427933136623

Epoch: 5| Step: 11
Training loss: 0.5160031914710999
Validation loss: 1.95250570277373

Epoch: 332| Step: 0
Training loss: 0.3425827622413635
Validation loss: 1.940834750731786

Epoch: 5| Step: 1
Training loss: 0.3772772252559662
Validation loss: 1.9269959181547165

Epoch: 5| Step: 2
Training loss: 0.31740686297416687
Validation loss: 1.8691608756780624

Epoch: 5| Step: 3
Training loss: 0.887376606464386
Validation loss: 1.891460617383321

Epoch: 5| Step: 4
Training loss: 0.30273905396461487
Validation loss: 1.9195049206415813

Epoch: 5| Step: 5
Training loss: 0.2312477082014084
Validation loss: 1.9109088530143101

Epoch: 5| Step: 6
Training loss: 0.49217677116394043
Validation loss: 1.9702181567748387

Epoch: 5| Step: 7
Training loss: 0.3724021911621094
Validation loss: 1.9199790060520172

Epoch: 5| Step: 8
Training loss: 0.33610767126083374
Validation loss: 1.9250045865774155

Epoch: 5| Step: 9
Training loss: 0.28381016850471497
Validation loss: 1.910066823164622

Epoch: 5| Step: 10
Training loss: 0.22918248176574707
Validation loss: 1.9175236622492473

Epoch: 5| Step: 11
Training loss: 0.34041041135787964
Validation loss: 1.9380355427662532

Epoch: 333| Step: 0
Training loss: 0.27361732721328735
Validation loss: 1.9081364125013351

Epoch: 5| Step: 1
Training loss: 0.5520857572555542
Validation loss: 1.8902607560157776

Epoch: 5| Step: 2
Training loss: 0.2662688195705414
Validation loss: 1.9126037508249283

Epoch: 5| Step: 3
Training loss: 0.4378904402256012
Validation loss: 1.9252490103244781

Epoch: 5| Step: 4
Training loss: 0.3259665071964264
Validation loss: 1.9177151918411255

Epoch: 5| Step: 5
Training loss: 0.2754058241844177
Validation loss: 1.924163858095805

Epoch: 5| Step: 6
Training loss: 0.48737820982933044
Validation loss: 1.9630002528429031

Epoch: 5| Step: 7
Training loss: 0.41291338205337524
Validation loss: 1.9308961927890778

Epoch: 5| Step: 8
Training loss: 0.38208290934562683
Validation loss: 1.9079819321632385

Epoch: 5| Step: 9
Training loss: 0.28146108984947205
Validation loss: 1.9486815581719081

Epoch: 5| Step: 10
Training loss: 0.3391187787055969
Validation loss: 1.9355516582727432

Epoch: 5| Step: 11
Training loss: 0.07513308525085449
Validation loss: 1.9450166523456573

Epoch: 334| Step: 0
Training loss: 0.843622088432312
Validation loss: 1.9423620502154033

Epoch: 5| Step: 1
Training loss: 0.25768008828163147
Validation loss: 1.8848026643196742

Epoch: 5| Step: 2
Training loss: 0.40435370802879333
Validation loss: 1.9281578908363979

Epoch: 5| Step: 3
Training loss: 0.4378543794155121
Validation loss: 1.9343002984921138

Epoch: 5| Step: 4
Training loss: 0.3137555718421936
Validation loss: 1.9577002575000126

Epoch: 5| Step: 5
Training loss: 0.35785943269729614
Validation loss: 1.9600050846735637

Epoch: 5| Step: 6
Training loss: 0.3383035659790039
Validation loss: 1.9170666535695393

Epoch: 5| Step: 7
Training loss: 0.30051904916763306
Validation loss: 1.90070445338885

Epoch: 5| Step: 8
Training loss: 0.2678871750831604
Validation loss: 1.874627336859703

Epoch: 5| Step: 9
Training loss: 0.3126447796821594
Validation loss: 1.8984361390272777

Epoch: 5| Step: 10
Training loss: 0.3325258791446686
Validation loss: 1.9430445382992427

Epoch: 5| Step: 11
Training loss: 0.26826947927474976
Validation loss: 1.9342293938000996

Epoch: 335| Step: 0
Training loss: 0.5283709764480591
Validation loss: 1.9758517891168594

Epoch: 5| Step: 1
Training loss: 0.2335316687822342
Validation loss: 1.9738678187131882

Epoch: 5| Step: 2
Training loss: 0.5151110887527466
Validation loss: 1.9983689437309902

Epoch: 5| Step: 3
Training loss: 0.3403153121471405
Validation loss: 1.9583631853262584

Epoch: 5| Step: 4
Training loss: 0.2527964115142822
Validation loss: 1.9364710102478664

Epoch: 5| Step: 5
Training loss: 0.29448044300079346
Validation loss: 1.9151062568028767

Epoch: 5| Step: 6
Training loss: 0.658541202545166
Validation loss: 1.9639799197514851

Epoch: 5| Step: 7
Training loss: 0.29119426012039185
Validation loss: 1.9526339918375015

Epoch: 5| Step: 8
Training loss: 0.5486130714416504
Validation loss: 1.9870561957359314

Epoch: 5| Step: 9
Training loss: 0.3298603594303131
Validation loss: 1.9210288276274998

Epoch: 5| Step: 10
Training loss: 0.26776450872421265
Validation loss: 1.9890954345464706

Epoch: 5| Step: 11
Training loss: 0.05454665422439575
Validation loss: 1.9232776363690693

Epoch: 336| Step: 0
Training loss: 0.2784101068973541
Validation loss: 2.016987055540085

Epoch: 5| Step: 1
Training loss: 0.4585300385951996
Validation loss: 1.9757327487071354

Epoch: 5| Step: 2
Training loss: 0.4943349361419678
Validation loss: 1.9191761910915375

Epoch: 5| Step: 3
Training loss: 0.8541924357414246
Validation loss: 1.9779128730297089

Epoch: 5| Step: 4
Training loss: 0.17903773486614227
Validation loss: 1.9639455080032349

Epoch: 5| Step: 5
Training loss: 0.37645822763442993
Validation loss: 1.9502437313397725

Epoch: 5| Step: 6
Training loss: 0.3209918141365051
Validation loss: 1.918321008483569

Epoch: 5| Step: 7
Training loss: 0.252532035112381
Validation loss: 1.8775064547856648

Epoch: 5| Step: 8
Training loss: 0.42400074005126953
Validation loss: 1.9217727382977803

Epoch: 5| Step: 9
Training loss: 0.3421313166618347
Validation loss: 1.9029210011164348

Epoch: 5| Step: 10
Training loss: 0.2855059802532196
Validation loss: 1.9159605503082275

Epoch: 5| Step: 11
Training loss: 0.18895113468170166
Validation loss: 1.9879147956768672

Epoch: 337| Step: 0
Training loss: 0.3166190981864929
Validation loss: 1.9479656020800273

Epoch: 5| Step: 1
Training loss: 0.2431478500366211
Validation loss: 1.9510448575019836

Epoch: 5| Step: 2
Training loss: 0.32260385155677795
Validation loss: 1.9651191234588623

Epoch: 5| Step: 3
Training loss: 0.43275928497314453
Validation loss: 1.9279034634431202

Epoch: 5| Step: 4
Training loss: 0.6895596385002136
Validation loss: 1.9120594213406246

Epoch: 5| Step: 5
Training loss: 0.4090352952480316
Validation loss: 1.8942415316899617

Epoch: 5| Step: 6
Training loss: 0.41833624243736267
Validation loss: 1.8717845777670543

Epoch: 5| Step: 7
Training loss: 0.3517882227897644
Validation loss: 1.9035022805134456

Epoch: 5| Step: 8
Training loss: 0.2321290522813797
Validation loss: 1.917098398009936

Epoch: 5| Step: 9
Training loss: 0.3226433992385864
Validation loss: 1.9612930417060852

Epoch: 5| Step: 10
Training loss: 0.6800718307495117
Validation loss: 1.9512718617916107

Epoch: 5| Step: 11
Training loss: 1.0169968605041504
Validation loss: 1.9085227300723393

Epoch: 338| Step: 0
Training loss: 0.3867873549461365
Validation loss: 1.9752527177333832

Epoch: 5| Step: 1
Training loss: 0.3945719599723816
Validation loss: 1.9630259772141774

Epoch: 5| Step: 2
Training loss: 0.4075687825679779
Validation loss: 1.9357032130161922

Epoch: 5| Step: 3
Training loss: 0.254457950592041
Validation loss: 1.9226093937953312

Epoch: 5| Step: 4
Training loss: 0.2584245204925537
Validation loss: 1.8588109960158665

Epoch: 5| Step: 5
Training loss: 0.35365140438079834
Validation loss: 1.8685189187526703

Epoch: 5| Step: 6
Training loss: 0.47908249497413635
Validation loss: 1.862806186079979

Epoch: 5| Step: 7
Training loss: 0.7420319318771362
Validation loss: 1.9532015174627304

Epoch: 5| Step: 8
Training loss: 0.38038259744644165
Validation loss: 1.9039488832155864

Epoch: 5| Step: 9
Training loss: 0.8396888971328735
Validation loss: 1.9535084118445714

Epoch: 5| Step: 10
Training loss: 0.5123637914657593
Validation loss: 1.947147046526273

Epoch: 5| Step: 11
Training loss: 0.22819966077804565
Validation loss: 1.9432534923156102

Epoch: 339| Step: 0
Training loss: 0.35729724168777466
Validation loss: 1.9859069685141246

Epoch: 5| Step: 1
Training loss: 0.7379092574119568
Validation loss: 1.9641282707452774

Epoch: 5| Step: 2
Training loss: 0.4930775761604309
Validation loss: 1.9084642976522446

Epoch: 5| Step: 3
Training loss: 0.3836125433444977
Validation loss: 1.928545614083608

Epoch: 5| Step: 4
Training loss: 0.21494407951831818
Validation loss: 1.886414219935735

Epoch: 5| Step: 5
Training loss: 0.7601044178009033
Validation loss: 1.8834264278411865

Epoch: 5| Step: 6
Training loss: 0.4284943640232086
Validation loss: 1.8978762278954189

Epoch: 5| Step: 7
Training loss: 0.4242955148220062
Validation loss: 1.8918119072914124

Epoch: 5| Step: 8
Training loss: 0.17870934307575226
Validation loss: 1.8852205624183018

Epoch: 5| Step: 9
Training loss: 0.47216805815696716
Validation loss: 1.8945714334646861

Epoch: 5| Step: 10
Training loss: 0.25929689407348633
Validation loss: 1.9320421020189922

Epoch: 5| Step: 11
Training loss: 0.392638623714447
Validation loss: 1.9317624618609746

Epoch: 340| Step: 0
Training loss: 0.4217259883880615
Validation loss: 1.9149094273646672

Epoch: 5| Step: 1
Training loss: 0.4505687654018402
Validation loss: 1.936714510122935

Epoch: 5| Step: 2
Training loss: 0.3443811535835266
Validation loss: 1.9498332142829895

Epoch: 5| Step: 3
Training loss: 0.37980279326438904
Validation loss: 1.9231956501801808

Epoch: 5| Step: 4
Training loss: 0.2207268476486206
Validation loss: 1.9253895580768585

Epoch: 5| Step: 5
Training loss: 0.45048198103904724
Validation loss: 1.8937762627998989

Epoch: 5| Step: 6
Training loss: 0.31300464272499084
Validation loss: 1.9181045293807983

Epoch: 5| Step: 7
Training loss: 0.308742493391037
Validation loss: 1.9531488766272862

Epoch: 5| Step: 8
Training loss: 0.42941156029701233
Validation loss: 1.9373466571172078

Epoch: 5| Step: 9
Training loss: 0.6687185168266296
Validation loss: 1.9283571938673656

Epoch: 5| Step: 10
Training loss: 0.5724942088127136
Validation loss: 1.954227864742279

Epoch: 5| Step: 11
Training loss: 0.22175180912017822
Validation loss: 1.977117160956065

Epoch: 341| Step: 0
Training loss: 0.40273112058639526
Validation loss: 1.925013189514478

Epoch: 5| Step: 1
Training loss: 0.22954067587852478
Validation loss: 1.931008478005727

Epoch: 5| Step: 2
Training loss: 0.4110743999481201
Validation loss: 1.906646857659022

Epoch: 5| Step: 3
Training loss: 0.3387066721916199
Validation loss: 1.9327697654565175

Epoch: 5| Step: 4
Training loss: 0.38965925574302673
Validation loss: 1.8950093686580658

Epoch: 5| Step: 5
Training loss: 0.45006608963012695
Validation loss: 1.9362908750772476

Epoch: 5| Step: 6
Training loss: 0.6150927543640137
Validation loss: 1.8807679414749146

Epoch: 5| Step: 7
Training loss: 0.22572723031044006
Validation loss: 1.9293218453725178

Epoch: 5| Step: 8
Training loss: 0.7409929037094116
Validation loss: 1.9389658917983372

Epoch: 5| Step: 9
Training loss: 0.2506258487701416
Validation loss: 1.936629335085551

Epoch: 5| Step: 10
Training loss: 0.3887854516506195
Validation loss: 1.9559963097174962

Epoch: 5| Step: 11
Training loss: 0.13387882709503174
Validation loss: 1.8976297477881114

Epoch: 342| Step: 0
Training loss: 0.31714290380477905
Validation loss: 1.9286982417106628

Epoch: 5| Step: 1
Training loss: 0.2565661072731018
Validation loss: 1.8901201089223225

Epoch: 5| Step: 2
Training loss: 0.34295883774757385
Validation loss: 1.8926401138305664

Epoch: 5| Step: 3
Training loss: 0.22901983559131622
Validation loss: 1.913765162229538

Epoch: 5| Step: 4
Training loss: 0.3787463903427124
Validation loss: 1.9054091175397236

Epoch: 5| Step: 5
Training loss: 0.3337244689464569
Validation loss: 1.8864996830622356

Epoch: 5| Step: 6
Training loss: 0.4354076385498047
Validation loss: 1.9200927168130875

Epoch: 5| Step: 7
Training loss: 0.4175879955291748
Validation loss: 1.9081752200921376

Epoch: 5| Step: 8
Training loss: 0.2992252707481384
Validation loss: 1.952453648050626

Epoch: 5| Step: 9
Training loss: 0.7361873388290405
Validation loss: 1.8995294769605

Epoch: 5| Step: 10
Training loss: 0.204762265086174
Validation loss: 1.916405811905861

Epoch: 5| Step: 11
Training loss: 0.3005892038345337
Validation loss: 1.978220467766126

Epoch: 343| Step: 0
Training loss: 0.37570899724960327
Validation loss: 1.9409288714329402

Epoch: 5| Step: 1
Training loss: 0.18963098526000977
Validation loss: 1.9627461582422256

Epoch: 5| Step: 2
Training loss: 0.2893335521221161
Validation loss: 1.953438272078832

Epoch: 5| Step: 3
Training loss: 0.44586896896362305
Validation loss: 1.9556502203146617

Epoch: 5| Step: 4
Training loss: 0.41622042655944824
Validation loss: 1.9818338255087535

Epoch: 5| Step: 5
Training loss: 0.27118849754333496
Validation loss: 1.9831923047701518

Epoch: 5| Step: 6
Training loss: 0.4723479151725769
Validation loss: 1.9386719663937886

Epoch: 5| Step: 7
Training loss: 0.26680320501327515
Validation loss: 1.943677857518196

Epoch: 5| Step: 8
Training loss: 0.19243040680885315
Validation loss: 1.9500128825505574

Epoch: 5| Step: 9
Training loss: 0.4081096053123474
Validation loss: 1.9111056725184123

Epoch: 5| Step: 10
Training loss: 0.35696902871131897
Validation loss: 1.9149226943651836

Epoch: 5| Step: 11
Training loss: 2.0869874954223633
Validation loss: 1.9185924629370372

Epoch: 344| Step: 0
Training loss: 0.48543038964271545
Validation loss: 1.9483375946680705

Epoch: 5| Step: 1
Training loss: 0.33450546860694885
Validation loss: 1.943048780163129

Epoch: 5| Step: 2
Training loss: 0.6185703277587891
Validation loss: 1.9622356643279393

Epoch: 5| Step: 3
Training loss: 0.4013552665710449
Validation loss: 1.9773613661527634

Epoch: 5| Step: 4
Training loss: 0.1921214759349823
Validation loss: 1.8986055354277294

Epoch: 5| Step: 5
Training loss: 0.206852987408638
Validation loss: 1.9209336092074711

Epoch: 5| Step: 6
Training loss: 0.3440045714378357
Validation loss: 1.934103677670161

Epoch: 5| Step: 7
Training loss: 0.29091984033584595
Validation loss: 1.8999011864264805

Epoch: 5| Step: 8
Training loss: 0.2777012586593628
Validation loss: 1.8266729017098744

Epoch: 5| Step: 9
Training loss: 0.49732059240341187
Validation loss: 1.9204662789901097

Epoch: 5| Step: 10
Training loss: 0.3071405589580536
Validation loss: 1.9534089863300323

Epoch: 5| Step: 11
Training loss: 1.926896572113037
Validation loss: 1.9642890741427739

Epoch: 345| Step: 0
Training loss: 0.44954079389572144
Validation loss: 1.92380990087986

Epoch: 5| Step: 1
Training loss: 0.7931787967681885
Validation loss: 1.9238334447145462

Epoch: 5| Step: 2
Training loss: 0.32056790590286255
Validation loss: 1.9178215265274048

Epoch: 5| Step: 3
Training loss: 0.43461936712265015
Validation loss: 1.886738250652949

Epoch: 5| Step: 4
Training loss: 0.2896682322025299
Validation loss: 1.8777955621480942

Epoch: 5| Step: 5
Training loss: 0.43729114532470703
Validation loss: 1.8966221064329147

Epoch: 5| Step: 6
Training loss: 0.20553874969482422
Validation loss: 1.905025248726209

Epoch: 5| Step: 7
Training loss: 0.3309202790260315
Validation loss: 1.896431232492129

Epoch: 5| Step: 8
Training loss: 0.4516013562679291
Validation loss: 1.8949222614367802

Epoch: 5| Step: 9
Training loss: 0.2915937006473541
Validation loss: 1.929536372423172

Epoch: 5| Step: 10
Training loss: 0.33819451928138733
Validation loss: 1.8834653397401173

Epoch: 5| Step: 11
Training loss: 0.3136104941368103
Validation loss: 1.9077412833770115

Epoch: 346| Step: 0
Training loss: 0.3884899616241455
Validation loss: 1.909687762459119

Epoch: 5| Step: 1
Training loss: 0.27452170848846436
Validation loss: 1.947058583299319

Epoch: 5| Step: 2
Training loss: 0.6621239185333252
Validation loss: 1.8962903221448262

Epoch: 5| Step: 3
Training loss: 0.5829963088035583
Validation loss: 1.901958574851354

Epoch: 5| Step: 4
Training loss: 0.346768856048584
Validation loss: 1.9080151915550232

Epoch: 5| Step: 5
Training loss: 0.3724452555179596
Validation loss: 1.9096825023492177

Epoch: 5| Step: 6
Training loss: 0.2750488519668579
Validation loss: 1.9185592979192734

Epoch: 5| Step: 7
Training loss: 0.22394804656505585
Validation loss: 1.9080034494400024

Epoch: 5| Step: 8
Training loss: 0.3595316708087921
Validation loss: 1.9166090587774913

Epoch: 5| Step: 9
Training loss: 0.3068494200706482
Validation loss: 1.9515742460886638

Epoch: 5| Step: 10
Training loss: 0.342002809047699
Validation loss: 1.9340150654315948

Epoch: 5| Step: 11
Training loss: 0.2730119228363037
Validation loss: 1.9601411819458008

Epoch: 347| Step: 0
Training loss: 0.5430991053581238
Validation loss: 1.9074582358201344

Epoch: 5| Step: 1
Training loss: 0.3100580871105194
Validation loss: 1.947242130835851

Epoch: 5| Step: 2
Training loss: 0.37364667654037476
Validation loss: 1.958557277917862

Epoch: 5| Step: 3
Training loss: 0.4079205393791199
Validation loss: 1.9241828173398972

Epoch: 5| Step: 4
Training loss: 0.6287479400634766
Validation loss: 1.9488850086927414

Epoch: 5| Step: 5
Training loss: 0.4866114556789398
Validation loss: 1.9509219576915104

Epoch: 5| Step: 6
Training loss: 0.267750084400177
Validation loss: 1.9335224032402039

Epoch: 5| Step: 7
Training loss: 0.4001907408237457
Validation loss: 1.9150944550832112

Epoch: 5| Step: 8
Training loss: 0.2544880509376526
Validation loss: 1.9198267062505086

Epoch: 5| Step: 9
Training loss: 0.22568538784980774
Validation loss: 1.9319032579660416

Epoch: 5| Step: 10
Training loss: 0.32446953654289246
Validation loss: 1.9492413053909938

Epoch: 5| Step: 11
Training loss: 0.2626650929450989
Validation loss: 1.9213147064050038

Epoch: 348| Step: 0
Training loss: 0.538915753364563
Validation loss: 1.923699051141739

Epoch: 5| Step: 1
Training loss: 0.2941427230834961
Validation loss: 1.911540334423383

Epoch: 5| Step: 2
Training loss: 0.5638839602470398
Validation loss: 1.9084969013929367

Epoch: 5| Step: 3
Training loss: 0.3239867687225342
Validation loss: 1.905697877208392

Epoch: 5| Step: 4
Training loss: 0.4095483720302582
Validation loss: 1.9174181173245113

Epoch: 5| Step: 5
Training loss: 0.31750112771987915
Validation loss: 1.8981137772401173

Epoch: 5| Step: 6
Training loss: 0.2934277653694153
Validation loss: 1.9483821988105774

Epoch: 5| Step: 7
Training loss: 0.39722028374671936
Validation loss: 1.9297459423542023

Epoch: 5| Step: 8
Training loss: 0.2940632700920105
Validation loss: 1.9214178174734116

Epoch: 5| Step: 9
Training loss: 0.22428090870380402
Validation loss: 1.9310135940710704

Epoch: 5| Step: 10
Training loss: 0.20146207511425018
Validation loss: 1.9408830553293228

Epoch: 5| Step: 11
Training loss: 0.37118202447891235
Validation loss: 1.923280507326126

Epoch: 349| Step: 0
Training loss: 0.3543314039707184
Validation loss: 1.8762646118799846

Epoch: 5| Step: 1
Training loss: 0.35741931200027466
Validation loss: 1.9042309770981471

Epoch: 5| Step: 2
Training loss: 0.7213436365127563
Validation loss: 1.9050035228331883

Epoch: 5| Step: 3
Training loss: 0.33979812264442444
Validation loss: 1.895722175637881

Epoch: 5| Step: 4
Training loss: 0.21360726654529572
Validation loss: 1.9561005930105846

Epoch: 5| Step: 5
Training loss: 0.26914182305336
Validation loss: 1.950781727830569

Epoch: 5| Step: 6
Training loss: 0.46021610498428345
Validation loss: 1.8638818114995956

Epoch: 5| Step: 7
Training loss: 0.35308900475502014
Validation loss: 1.8921652535597484

Epoch: 5| Step: 8
Training loss: 0.434442937374115
Validation loss: 1.9100761065880458

Epoch: 5| Step: 9
Training loss: 0.29233336448669434
Validation loss: 1.8266446789105732

Epoch: 5| Step: 10
Training loss: 0.25315433740615845
Validation loss: 1.8774825880924861

Epoch: 5| Step: 11
Training loss: 0.3046005964279175
Validation loss: 1.9084047575791676

Epoch: 350| Step: 0
Training loss: 0.37492337822914124
Validation loss: 1.9413679887851079

Epoch: 5| Step: 1
Training loss: 0.5951132774353027
Validation loss: 1.922006626923879

Epoch: 5| Step: 2
Training loss: 0.3386015295982361
Validation loss: 1.9693456788857777

Epoch: 5| Step: 3
Training loss: 0.32009994983673096
Validation loss: 1.895560085773468

Epoch: 5| Step: 4
Training loss: 0.334817111492157
Validation loss: 1.9418912827968597

Epoch: 5| Step: 5
Training loss: 0.24561233818531036
Validation loss: 1.9452112366755803

Epoch: 5| Step: 6
Training loss: 0.5084108114242554
Validation loss: 1.9066538562377293

Epoch: 5| Step: 7
Training loss: 0.3097822666168213
Validation loss: 1.907891869544983

Epoch: 5| Step: 8
Training loss: 0.3122250437736511
Validation loss: 1.9199103911717732

Epoch: 5| Step: 9
Training loss: 0.4474993646144867
Validation loss: 1.8819469163815181

Epoch: 5| Step: 10
Training loss: 0.238668292760849
Validation loss: 1.9411011238892872

Epoch: 5| Step: 11
Training loss: 0.1731097549200058
Validation loss: 1.9223961184422176

Epoch: 351| Step: 0
Training loss: 0.32414692640304565
Validation loss: 1.9541131208340328

Epoch: 5| Step: 1
Training loss: 0.2551632821559906
Validation loss: 1.9192870557308197

Epoch: 5| Step: 2
Training loss: 0.6339250802993774
Validation loss: 1.909129758675893

Epoch: 5| Step: 3
Training loss: 0.205032616853714
Validation loss: 1.9278998573621113

Epoch: 5| Step: 4
Training loss: 0.6221668124198914
Validation loss: 1.9594660550355911

Epoch: 5| Step: 5
Training loss: 0.29994019865989685
Validation loss: 1.9071501245101292

Epoch: 5| Step: 6
Training loss: 0.2630228102207184
Validation loss: 1.9187964300314586

Epoch: 5| Step: 7
Training loss: 0.34325239062309265
Validation loss: 1.913471872607867

Epoch: 5| Step: 8
Training loss: 0.33801978826522827
Validation loss: 1.9310482690731685

Epoch: 5| Step: 9
Training loss: 0.2598329186439514
Validation loss: 1.947157974044482

Epoch: 5| Step: 10
Training loss: 0.3648674488067627
Validation loss: 1.9756895701090496

Epoch: 5| Step: 11
Training loss: 0.37503719329833984
Validation loss: 1.9345745493968327

Epoch: 352| Step: 0
Training loss: 0.5411509275436401
Validation loss: 1.9256902833779652

Epoch: 5| Step: 1
Training loss: 0.252368688583374
Validation loss: 1.9272687931855519

Epoch: 5| Step: 2
Training loss: 0.46549177169799805
Validation loss: 1.8597674469153087

Epoch: 5| Step: 3
Training loss: 0.372821569442749
Validation loss: 1.8647740085919697

Epoch: 5| Step: 4
Training loss: 0.40067118406295776
Validation loss: 1.8808068335056305

Epoch: 5| Step: 5
Training loss: 0.45078223943710327
Validation loss: 1.8875822772582371

Epoch: 5| Step: 6
Training loss: 0.34722575545310974
Validation loss: 1.9006536205609639

Epoch: 5| Step: 7
Training loss: 0.37418675422668457
Validation loss: 1.9460311532020569

Epoch: 5| Step: 8
Training loss: 0.35125967860221863
Validation loss: 1.909784937898318

Epoch: 5| Step: 9
Training loss: 0.40587615966796875
Validation loss: 1.9091697931289673

Epoch: 5| Step: 10
Training loss: 0.24831967055797577
Validation loss: 1.9265392770369847

Epoch: 5| Step: 11
Training loss: 0.24824932217597961
Validation loss: 1.9387790809075038

Epoch: 353| Step: 0
Training loss: 0.18360649049282074
Validation loss: 1.919061541557312

Epoch: 5| Step: 1
Training loss: 0.5138706564903259
Validation loss: 1.86745086312294

Epoch: 5| Step: 2
Training loss: 0.25217685103416443
Validation loss: 1.9063921471436818

Epoch: 5| Step: 3
Training loss: 0.3536582887172699
Validation loss: 1.9517209182182949

Epoch: 5| Step: 4
Training loss: 0.30030199885368347
Validation loss: 1.901543120543162

Epoch: 5| Step: 5
Training loss: 0.5301451086997986
Validation loss: 1.9024836073319118

Epoch: 5| Step: 6
Training loss: 0.3844286799430847
Validation loss: 1.9194362511237462

Epoch: 5| Step: 7
Training loss: 0.28169482946395874
Validation loss: 1.913490707675616

Epoch: 5| Step: 8
Training loss: 0.411318838596344
Validation loss: 1.9739560385545094

Epoch: 5| Step: 9
Training loss: 0.2923583686351776
Validation loss: 1.923419639468193

Epoch: 5| Step: 10
Training loss: 0.5034393072128296
Validation loss: 1.952448457479477

Epoch: 5| Step: 11
Training loss: 0.4742567539215088
Validation loss: 1.8812361905972164

Epoch: 354| Step: 0
Training loss: 0.45646828413009644
Validation loss: 1.9256154398123424

Epoch: 5| Step: 1
Training loss: 0.24548792839050293
Validation loss: 1.9092134982347488

Epoch: 5| Step: 2
Training loss: 0.2652980387210846
Validation loss: 1.9488513668378193

Epoch: 5| Step: 3
Training loss: 0.5587697625160217
Validation loss: 1.9941249837478001

Epoch: 5| Step: 4
Training loss: 0.24376139044761658
Validation loss: 1.977687507867813

Epoch: 5| Step: 5
Training loss: 0.3434239625930786
Validation loss: 1.9938630163669586

Epoch: 5| Step: 6
Training loss: 0.3016759157180786
Validation loss: 1.9149893323580425

Epoch: 5| Step: 7
Training loss: 0.28874945640563965
Validation loss: 1.9194326202074687

Epoch: 5| Step: 8
Training loss: 0.39648956060409546
Validation loss: 1.9131277253230412

Epoch: 5| Step: 9
Training loss: 0.3895478844642639
Validation loss: 1.8961436847845714

Epoch: 5| Step: 10
Training loss: 0.22012834250926971
Validation loss: 1.9083018948634465

Epoch: 5| Step: 11
Training loss: 0.2531387209892273
Validation loss: 1.9160429686307907

Epoch: 355| Step: 0
Training loss: 0.32190975546836853
Validation loss: 1.917388339837392

Epoch: 5| Step: 1
Training loss: 0.792890727519989
Validation loss: 1.8929775555928547

Epoch: 5| Step: 2
Training loss: 0.19143791496753693
Validation loss: 1.9429660240809123

Epoch: 5| Step: 3
Training loss: 0.2456977367401123
Validation loss: 1.8876612931489944

Epoch: 5| Step: 4
Training loss: 0.1623341292142868
Validation loss: 1.9271208147207897

Epoch: 5| Step: 5
Training loss: 0.452284038066864
Validation loss: 1.920478567481041

Epoch: 5| Step: 6
Training loss: 0.36703386902809143
Validation loss: 1.9323576142390568

Epoch: 5| Step: 7
Training loss: 0.5167121887207031
Validation loss: 1.9315053870280583

Epoch: 5| Step: 8
Training loss: 0.3164522051811218
Validation loss: 1.9255544145901997

Epoch: 5| Step: 9
Training loss: 0.3836129307746887
Validation loss: 1.928412675857544

Epoch: 5| Step: 10
Training loss: 0.2412032186985016
Validation loss: 1.9465483576059341

Epoch: 5| Step: 11
Training loss: 0.3599584400653839
Validation loss: 1.915499433875084

Epoch: 356| Step: 0
Training loss: 0.3523586690425873
Validation loss: 1.932044267654419

Epoch: 5| Step: 1
Training loss: 0.16815142333507538
Validation loss: 1.9150583893060684

Epoch: 5| Step: 2
Training loss: 0.24930648505687714
Validation loss: 1.9243949552377064

Epoch: 5| Step: 3
Training loss: 0.3950926661491394
Validation loss: 1.9321711113055546

Epoch: 5| Step: 4
Training loss: 0.26370224356651306
Validation loss: 1.8886245389779408

Epoch: 5| Step: 5
Training loss: 0.17341585457324982
Validation loss: 1.9295331984758377

Epoch: 5| Step: 6
Training loss: 0.24712805449962616
Validation loss: 1.8798774878184001

Epoch: 5| Step: 7
Training loss: 0.43624091148376465
Validation loss: 1.9147400707006454

Epoch: 5| Step: 8
Training loss: 0.9755892753601074
Validation loss: 1.9136151025692623

Epoch: 5| Step: 9
Training loss: 0.23671893775463104
Validation loss: 1.903730531533559

Epoch: 5| Step: 10
Training loss: 0.45219793915748596
Validation loss: 1.9020291219154994

Epoch: 5| Step: 11
Training loss: 0.2872130572795868
Validation loss: 1.9096603095531464

Epoch: 357| Step: 0
Training loss: 0.22231200337409973
Validation loss: 1.8723389754692714

Epoch: 5| Step: 1
Training loss: 0.5553271174430847
Validation loss: 1.9493174453576405

Epoch: 5| Step: 2
Training loss: 0.3195694088935852
Validation loss: 1.8842989106973012

Epoch: 5| Step: 3
Training loss: 0.20259657502174377
Validation loss: 1.9460777441660564

Epoch: 5| Step: 4
Training loss: 0.44876670837402344
Validation loss: 1.9471511542797089

Epoch: 5| Step: 5
Training loss: 0.3520404100418091
Validation loss: 1.9239334215720494

Epoch: 5| Step: 6
Training loss: 0.5976723432540894
Validation loss: 1.8929219742616017

Epoch: 5| Step: 7
Training loss: 0.2982201874256134
Validation loss: 1.9431993166605632

Epoch: 5| Step: 8
Training loss: 0.23943936824798584
Validation loss: 1.9264796823263168

Epoch: 5| Step: 9
Training loss: 0.43716731667518616
Validation loss: 1.9388310263554256

Epoch: 5| Step: 10
Training loss: 0.31589367985725403
Validation loss: 1.926215723156929

Epoch: 5| Step: 11
Training loss: 0.2336825132369995
Validation loss: 1.8894415746132533

Epoch: 358| Step: 0
Training loss: 0.410308837890625
Validation loss: 1.9165131251017253

Epoch: 5| Step: 1
Training loss: 0.5072153806686401
Validation loss: 1.9463883539040883

Epoch: 5| Step: 2
Training loss: 0.5806566476821899
Validation loss: 1.9541493505239487

Epoch: 5| Step: 3
Training loss: 0.2785309851169586
Validation loss: 1.9913553545872371

Epoch: 5| Step: 4
Training loss: 0.2344638556241989
Validation loss: 1.934697265426318

Epoch: 5| Step: 5
Training loss: 0.37586623430252075
Validation loss: 1.9435852070649464

Epoch: 5| Step: 6
Training loss: 0.5686101913452148
Validation loss: 1.933336744705836

Epoch: 5| Step: 7
Training loss: 0.4265303611755371
Validation loss: 1.8881600896517436

Epoch: 5| Step: 8
Training loss: 0.2319774627685547
Validation loss: 1.932546039422353

Epoch: 5| Step: 9
Training loss: 0.304936945438385
Validation loss: 1.8942757993936539

Epoch: 5| Step: 10
Training loss: 0.24190957844257355
Validation loss: 1.9190341035525005

Epoch: 5| Step: 11
Training loss: 0.2510462999343872
Validation loss: 1.9091150214274724

Epoch: 359| Step: 0
Training loss: 0.3036887049674988
Validation loss: 1.9255697826544445

Epoch: 5| Step: 1
Training loss: 0.4349782466888428
Validation loss: 1.9026467551787694

Epoch: 5| Step: 2
Training loss: 0.36285966634750366
Validation loss: 1.936055675148964

Epoch: 5| Step: 3
Training loss: 0.4219374656677246
Validation loss: 1.9540416797002156

Epoch: 5| Step: 4
Training loss: 0.26186782121658325
Validation loss: 1.8783260434865952

Epoch: 5| Step: 5
Training loss: 0.28992512822151184
Validation loss: 1.8932529141505559

Epoch: 5| Step: 6
Training loss: 0.31053441762924194
Validation loss: 1.907011980811755

Epoch: 5| Step: 7
Training loss: 0.5923401117324829
Validation loss: 1.9555521657069523

Epoch: 5| Step: 8
Training loss: 0.25777459144592285
Validation loss: 1.939468229810397

Epoch: 5| Step: 9
Training loss: 0.3262574076652527
Validation loss: 1.9064711978038151

Epoch: 5| Step: 10
Training loss: 0.3451104462146759
Validation loss: 1.8759310742219288

Epoch: 5| Step: 11
Training loss: 0.13827267289161682
Validation loss: 1.8802644610404968

Epoch: 360| Step: 0
Training loss: 0.24573516845703125
Validation loss: 1.889610692858696

Epoch: 5| Step: 1
Training loss: 0.27935990691185
Validation loss: 1.8932793587446213

Epoch: 5| Step: 2
Training loss: 0.27269214391708374
Validation loss: 1.872841273744901

Epoch: 5| Step: 3
Training loss: 0.45581215620040894
Validation loss: 1.9128436148166656

Epoch: 5| Step: 4
Training loss: 0.433590829372406
Validation loss: 1.9260161469380062

Epoch: 5| Step: 5
Training loss: 0.24316532909870148
Validation loss: 1.9018773088852565

Epoch: 5| Step: 6
Training loss: 0.13826201856136322
Validation loss: 1.936157112320264

Epoch: 5| Step: 7
Training loss: 0.679963231086731
Validation loss: 1.936505729953448

Epoch: 5| Step: 8
Training loss: 0.18011778593063354
Validation loss: 1.880301018555959

Epoch: 5| Step: 9
Training loss: 0.2956993877887726
Validation loss: 1.9300407618284225

Epoch: 5| Step: 10
Training loss: 0.40913382172584534
Validation loss: 1.9094957609971364

Epoch: 5| Step: 11
Training loss: 0.14120090007781982
Validation loss: 1.892380177974701

Epoch: 361| Step: 0
Training loss: 0.26003170013427734
Validation loss: 1.9011023094256718

Epoch: 5| Step: 1
Training loss: 0.24687767028808594
Validation loss: 1.9097632219394047

Epoch: 5| Step: 2
Training loss: 0.40765008330345154
Validation loss: 1.897400826215744

Epoch: 5| Step: 3
Training loss: 0.20231735706329346
Validation loss: 1.9481522490580876

Epoch: 5| Step: 4
Training loss: 0.6997246146202087
Validation loss: 1.8949334720770519

Epoch: 5| Step: 5
Training loss: 0.20169281959533691
Validation loss: 1.9149610102176666

Epoch: 5| Step: 6
Training loss: 0.2858680486679077
Validation loss: 1.917754719654719

Epoch: 5| Step: 7
Training loss: 0.30843010544776917
Validation loss: 1.887422760327657

Epoch: 5| Step: 8
Training loss: 0.37522029876708984
Validation loss: 1.8689149816830952

Epoch: 5| Step: 9
Training loss: 0.36832350492477417
Validation loss: 1.8834161857763927

Epoch: 5| Step: 10
Training loss: 0.5152194499969482
Validation loss: 1.8723088999589284

Epoch: 5| Step: 11
Training loss: 0.16361397504806519
Validation loss: 1.9049898187319438

Epoch: 362| Step: 0
Training loss: 0.23139457404613495
Validation loss: 1.9481852153937023

Epoch: 5| Step: 1
Training loss: 0.29193297028541565
Validation loss: 1.9590691576401393

Epoch: 5| Step: 2
Training loss: 0.541233479976654
Validation loss: 1.901280716061592

Epoch: 5| Step: 3
Training loss: 0.5080081820487976
Validation loss: 1.9563829600811005

Epoch: 5| Step: 4
Training loss: 0.5369359850883484
Validation loss: 1.8787658909956615

Epoch: 5| Step: 5
Training loss: 0.3049700856208801
Validation loss: 1.9214538633823395

Epoch: 5| Step: 6
Training loss: 0.5709222555160522
Validation loss: 1.8602132548888524

Epoch: 5| Step: 7
Training loss: 0.3268372416496277
Validation loss: 1.9065743188063304

Epoch: 5| Step: 8
Training loss: 0.19660112261772156
Validation loss: 1.9194398373365402

Epoch: 5| Step: 9
Training loss: 0.25670963525772095
Validation loss: 1.9118472735087078

Epoch: 5| Step: 10
Training loss: 0.4022149443626404
Validation loss: 1.9552915741999943

Epoch: 5| Step: 11
Training loss: 0.6442322731018066
Validation loss: 1.9882880399624507

Epoch: 363| Step: 0
Training loss: 0.6429424285888672
Validation loss: 1.9107838372389476

Epoch: 5| Step: 1
Training loss: 0.1863267719745636
Validation loss: 1.964919735987981

Epoch: 5| Step: 2
Training loss: 0.2941557466983795
Validation loss: 1.9163966526587803

Epoch: 5| Step: 3
Training loss: 0.3312358260154724
Validation loss: 1.9339902997016907

Epoch: 5| Step: 4
Training loss: 0.39510518312454224
Validation loss: 1.8972117751836777

Epoch: 5| Step: 5
Training loss: 0.4541565477848053
Validation loss: 1.917389636238416

Epoch: 5| Step: 6
Training loss: 0.17530713975429535
Validation loss: 1.9136075327793758

Epoch: 5| Step: 7
Training loss: 0.2579619288444519
Validation loss: 1.901378830273946

Epoch: 5| Step: 8
Training loss: 0.3170071244239807
Validation loss: 1.9203392763932545

Epoch: 5| Step: 9
Training loss: 0.4424761235713959
Validation loss: 1.9361423353354137

Epoch: 5| Step: 10
Training loss: 0.474165141582489
Validation loss: 1.9207002719243367

Epoch: 5| Step: 11
Training loss: 0.26804158091545105
Validation loss: 1.9093502561251323

Epoch: 364| Step: 0
Training loss: 0.33532124757766724
Validation loss: 1.9618674914042156

Epoch: 5| Step: 1
Training loss: 0.7605819702148438
Validation loss: 1.9862440129121144

Epoch: 5| Step: 2
Training loss: 0.31625232100486755
Validation loss: 1.9268290201822917

Epoch: 5| Step: 3
Training loss: 0.43497008085250854
Validation loss: 1.939840282003085

Epoch: 5| Step: 4
Training loss: 0.2548816502094269
Validation loss: 1.895986795425415

Epoch: 5| Step: 5
Training loss: 0.4738093316555023
Validation loss: 1.917031154036522

Epoch: 5| Step: 6
Training loss: 0.4430122971534729
Validation loss: 1.9199443459510803

Epoch: 5| Step: 7
Training loss: 0.6137329936027527
Validation loss: 1.9342117061217625

Epoch: 5| Step: 8
Training loss: 0.20673096179962158
Validation loss: 1.9233421285947163

Epoch: 5| Step: 9
Training loss: 0.23824742436408997
Validation loss: 1.920247495174408

Epoch: 5| Step: 10
Training loss: 0.493364155292511
Validation loss: 1.963361809651057

Epoch: 5| Step: 11
Training loss: 1.153686761856079
Validation loss: 1.9504218300183613

Epoch: 365| Step: 0
Training loss: 0.528516411781311
Validation loss: 1.9931280513604481

Epoch: 5| Step: 1
Training loss: 0.46412935853004456
Validation loss: 1.964924395084381

Epoch: 5| Step: 2
Training loss: 0.6532096862792969
Validation loss: 1.9157372216383617

Epoch: 5| Step: 3
Training loss: 0.4307621419429779
Validation loss: 1.9639187802871068

Epoch: 5| Step: 4
Training loss: 0.32617902755737305
Validation loss: 1.9304630160331726

Epoch: 5| Step: 5
Training loss: 0.27860796451568604
Validation loss: 1.898406058549881

Epoch: 5| Step: 6
Training loss: 0.3149035573005676
Validation loss: 1.9371098975340526

Epoch: 5| Step: 7
Training loss: 0.22686326503753662
Validation loss: 1.8639887770016987

Epoch: 5| Step: 8
Training loss: 0.35258781909942627
Validation loss: 1.8715595801671345

Epoch: 5| Step: 9
Training loss: 0.32043755054473877
Validation loss: 1.929612636566162

Epoch: 5| Step: 10
Training loss: 0.3675406277179718
Validation loss: 1.932939738035202

Epoch: 5| Step: 11
Training loss: 0.3766516447067261
Validation loss: 1.9782298703988392

Epoch: 366| Step: 0
Training loss: 0.6690776944160461
Validation loss: 1.9231893867254257

Epoch: 5| Step: 1
Training loss: 0.31354787945747375
Validation loss: 1.9632162352403004

Epoch: 5| Step: 2
Training loss: 0.3431902825832367
Validation loss: 1.9468377927939098

Epoch: 5| Step: 3
Training loss: 0.26044613122940063
Validation loss: 1.9627035856246948

Epoch: 5| Step: 4
Training loss: 0.3142412006855011
Validation loss: 1.9323653032382329

Epoch: 5| Step: 5
Training loss: 0.38439851999282837
Validation loss: 1.956256424387296

Epoch: 5| Step: 6
Training loss: 0.2566321790218353
Validation loss: 1.9510733286539714

Epoch: 5| Step: 7
Training loss: 0.4092636704444885
Validation loss: 1.987306813398997

Epoch: 5| Step: 8
Training loss: 0.4926026463508606
Validation loss: 1.9695472717285156

Epoch: 5| Step: 9
Training loss: 0.19136503338813782
Validation loss: 1.9500737984975178

Epoch: 5| Step: 10
Training loss: 0.3727031350135803
Validation loss: 1.9197545796632767

Epoch: 5| Step: 11
Training loss: 0.20831191539764404
Validation loss: 1.9140562216440837

Epoch: 367| Step: 0
Training loss: 0.38058608770370483
Validation loss: 1.9034261256456375

Epoch: 5| Step: 1
Training loss: 0.21403908729553223
Validation loss: 1.9470871637264888

Epoch: 5| Step: 2
Training loss: 0.5229681730270386
Validation loss: 1.9252530336380005

Epoch: 5| Step: 3
Training loss: 0.2641104459762573
Validation loss: 1.9233715931574504

Epoch: 5| Step: 4
Training loss: 0.3134322762489319
Validation loss: 1.920107717315356

Epoch: 5| Step: 5
Training loss: 0.2638462781906128
Validation loss: 1.9055952082077663

Epoch: 5| Step: 6
Training loss: 0.20852439105510712
Validation loss: 1.8888106892506282

Epoch: 5| Step: 7
Training loss: 0.30908623337745667
Validation loss: 1.8835112154483795

Epoch: 5| Step: 8
Training loss: 0.5165495276451111
Validation loss: 1.8409282515446346

Epoch: 5| Step: 9
Training loss: 0.5971122980117798
Validation loss: 1.9225011716286342

Epoch: 5| Step: 10
Training loss: 0.31855425238609314
Validation loss: 1.8898182113965352

Epoch: 5| Step: 11
Training loss: 0.08586686849594116
Validation loss: 1.8771046996116638

Epoch: 368| Step: 0
Training loss: 0.31532782316207886
Validation loss: 1.885979175567627

Epoch: 5| Step: 1
Training loss: 0.752273678779602
Validation loss: 1.8744226495424907

Epoch: 5| Step: 2
Training loss: 0.3476896286010742
Validation loss: 1.9103081474701564

Epoch: 5| Step: 3
Training loss: 0.1698022186756134
Validation loss: 1.8517623022198677

Epoch: 5| Step: 4
Training loss: 0.28665193915367126
Validation loss: 1.9329228450854619

Epoch: 5| Step: 5
Training loss: 0.2550830543041229
Validation loss: 1.930336947242419

Epoch: 5| Step: 6
Training loss: 0.48306626081466675
Validation loss: 1.9644936124483745

Epoch: 5| Step: 7
Training loss: 0.3498210906982422
Validation loss: 1.94431238869826

Epoch: 5| Step: 8
Training loss: 0.4376240670681
Validation loss: 1.9237042268117268

Epoch: 5| Step: 9
Training loss: 0.15645070374011993
Validation loss: 1.9733397960662842

Epoch: 5| Step: 10
Training loss: 0.24382562935352325
Validation loss: 1.932255133986473

Epoch: 5| Step: 11
Training loss: 0.11827385425567627
Validation loss: 1.961860607067744

Epoch: 369| Step: 0
Training loss: 0.23485322296619415
Validation loss: 1.8939105172952015

Epoch: 5| Step: 1
Training loss: 0.7217041254043579
Validation loss: 1.9269191424051921

Epoch: 5| Step: 2
Training loss: 0.33220410346984863
Validation loss: 1.9445329507191975

Epoch: 5| Step: 3
Training loss: 0.27902552485466003
Validation loss: 1.9180100659529369

Epoch: 5| Step: 4
Training loss: 0.2779107689857483
Validation loss: 1.9155823936065037

Epoch: 5| Step: 5
Training loss: 0.2531581521034241
Validation loss: 1.9390255163113277

Epoch: 5| Step: 6
Training loss: 0.38208580017089844
Validation loss: 1.9206609278917313

Epoch: 5| Step: 7
Training loss: 0.3390471935272217
Validation loss: 1.9310728510220845

Epoch: 5| Step: 8
Training loss: 0.2415916621685028
Validation loss: 1.9236943870782852

Epoch: 5| Step: 9
Training loss: 0.2838069796562195
Validation loss: 1.863169898589452

Epoch: 5| Step: 10
Training loss: 0.31387025117874146
Validation loss: 1.9206761221090953

Epoch: 5| Step: 11
Training loss: 0.22934497892856598
Validation loss: 1.8826829095681508

Epoch: 370| Step: 0
Training loss: 0.3714761734008789
Validation loss: 1.907755196094513

Epoch: 5| Step: 1
Training loss: 0.36548954248428345
Validation loss: 1.9484121799468994

Epoch: 5| Step: 2
Training loss: 0.31845468282699585
Validation loss: 1.9192277888456981

Epoch: 5| Step: 3
Training loss: 0.2016463577747345
Validation loss: 1.941761627793312

Epoch: 5| Step: 4
Training loss: 0.30667632818222046
Validation loss: 1.857712835073471

Epoch: 5| Step: 5
Training loss: 0.6548430323600769
Validation loss: 1.9233126640319824

Epoch: 5| Step: 6
Training loss: 0.402132511138916
Validation loss: 1.9229527413845062

Epoch: 5| Step: 7
Training loss: 0.2868749499320984
Validation loss: 1.8895133783419926

Epoch: 5| Step: 8
Training loss: 0.32888469099998474
Validation loss: 1.8913429031769435

Epoch: 5| Step: 9
Training loss: 0.41942816972732544
Validation loss: 1.8723846922318141

Epoch: 5| Step: 10
Training loss: 0.31554388999938965
Validation loss: 1.9090307553609211

Epoch: 5| Step: 11
Training loss: 0.8716172575950623
Validation loss: 1.9139840354522069

Epoch: 371| Step: 0
Training loss: 0.25994303822517395
Validation loss: 1.9174817353487015

Epoch: 5| Step: 1
Training loss: 0.682700514793396
Validation loss: 1.8549400518337886

Epoch: 5| Step: 2
Training loss: 0.25334277749061584
Validation loss: 1.8935882498820622

Epoch: 5| Step: 3
Training loss: 0.1908440887928009
Validation loss: 1.9157821536064148

Epoch: 5| Step: 4
Training loss: 0.24444511532783508
Validation loss: 1.8737614353497822

Epoch: 5| Step: 5
Training loss: 0.33777251839637756
Validation loss: 1.9441319902737935

Epoch: 5| Step: 6
Training loss: 0.45650163292884827
Validation loss: 1.9178079615036647

Epoch: 5| Step: 7
Training loss: 0.6523419618606567
Validation loss: 1.9469582438468933

Epoch: 5| Step: 8
Training loss: 0.41154199838638306
Validation loss: 1.8837310175100963

Epoch: 5| Step: 9
Training loss: 0.23058275878429413
Validation loss: 1.9513677060604095

Epoch: 5| Step: 10
Training loss: 0.4567648768424988
Validation loss: 1.9025130023558934

Epoch: 5| Step: 11
Training loss: 0.09209001064300537
Validation loss: 1.8985595703125

Epoch: 372| Step: 0
Training loss: 0.41931867599487305
Validation loss: 1.8736650695403416

Epoch: 5| Step: 1
Training loss: 0.6595381498336792
Validation loss: 1.9067616363366444

Epoch: 5| Step: 2
Training loss: 0.8296236991882324
Validation loss: 1.9180196672677994

Epoch: 5| Step: 3
Training loss: 0.41086140275001526
Validation loss: 1.9047310501337051

Epoch: 5| Step: 4
Training loss: 0.3717435896396637
Validation loss: 1.912165030837059

Epoch: 5| Step: 5
Training loss: 0.2889383137226105
Validation loss: 1.8860291242599487

Epoch: 5| Step: 6
Training loss: 0.1976931244134903
Validation loss: 1.9148130267858505

Epoch: 5| Step: 7
Training loss: 0.6344560980796814
Validation loss: 1.987950474023819

Epoch: 5| Step: 8
Training loss: 0.48626524209976196
Validation loss: 2.0221813917160034

Epoch: 5| Step: 9
Training loss: 0.49266546964645386
Validation loss: 1.9387618601322174

Epoch: 5| Step: 10
Training loss: 0.3402596116065979
Validation loss: 1.929732436935107

Epoch: 5| Step: 11
Training loss: 0.20046687126159668
Validation loss: 1.9021638482809067

Epoch: 373| Step: 0
Training loss: 0.3469849228858948
Validation loss: 1.8676277647415798

Epoch: 5| Step: 1
Training loss: 0.3379212021827698
Validation loss: 1.9070625056823094

Epoch: 5| Step: 2
Training loss: 0.2893737852573395
Validation loss: 1.882333904504776

Epoch: 5| Step: 3
Training loss: 0.3173600733280182
Validation loss: 1.8819063752889633

Epoch: 5| Step: 4
Training loss: 0.35586902499198914
Validation loss: 1.8935000747442245

Epoch: 5| Step: 5
Training loss: 0.2884557247161865
Validation loss: 1.9219820350408554

Epoch: 5| Step: 6
Training loss: 0.3538927137851715
Validation loss: 1.9035538037618

Epoch: 5| Step: 7
Training loss: 0.7582112550735474
Validation loss: 1.9237676461537678

Epoch: 5| Step: 8
Training loss: 0.3014788329601288
Validation loss: 1.9629171291987102

Epoch: 5| Step: 9
Training loss: 0.5500806570053101
Validation loss: 1.9466770887374878

Epoch: 5| Step: 10
Training loss: 0.563306987285614
Validation loss: 1.911480297644933

Epoch: 5| Step: 11
Training loss: 0.18252228200435638
Validation loss: 1.876934344569842

Epoch: 374| Step: 0
Training loss: 0.3978617489337921
Validation loss: 1.8962968736886978

Epoch: 5| Step: 1
Training loss: 0.9132372140884399
Validation loss: 1.8954517195622127

Epoch: 5| Step: 2
Training loss: 0.6033077239990234
Validation loss: 1.882758488257726

Epoch: 5| Step: 3
Training loss: 0.43942347168922424
Validation loss: 1.9123802135388057

Epoch: 5| Step: 4
Training loss: 0.2269042730331421
Validation loss: 1.8626225193341572

Epoch: 5| Step: 5
Training loss: 0.2815227806568146
Validation loss: 1.9151234378417332

Epoch: 5| Step: 6
Training loss: 0.30816584825515747
Validation loss: 1.9502084851264954

Epoch: 5| Step: 7
Training loss: 0.3280601501464844
Validation loss: 1.9686550895373027

Epoch: 5| Step: 8
Training loss: 0.31213849782943726
Validation loss: 1.9494677136341731

Epoch: 5| Step: 9
Training loss: 0.4276343286037445
Validation loss: 1.9714343001445134

Epoch: 5| Step: 10
Training loss: 0.5257270336151123
Validation loss: 1.9351682662963867

Epoch: 5| Step: 11
Training loss: 0.22765988111495972
Validation loss: 1.8980277925729752

Epoch: 375| Step: 0
Training loss: 0.3323802053928375
Validation loss: 1.8646814028422039

Epoch: 5| Step: 1
Training loss: 0.5439280271530151
Validation loss: 1.8888680984576542

Epoch: 5| Step: 2
Training loss: 0.7699170112609863
Validation loss: 1.9134229471286137

Epoch: 5| Step: 3
Training loss: 0.41129738092422485
Validation loss: 1.9031776736179988

Epoch: 5| Step: 4
Training loss: 0.3763698935508728
Validation loss: 1.9283455063899357

Epoch: 5| Step: 5
Training loss: 0.17550453543663025
Validation loss: 1.9558648367722828

Epoch: 5| Step: 6
Training loss: 0.49338260293006897
Validation loss: 1.9438100258509319

Epoch: 5| Step: 7
Training loss: 0.2754175364971161
Validation loss: 1.966488669315974

Epoch: 5| Step: 8
Training loss: 0.5070840716362
Validation loss: 1.9777367909749348

Epoch: 5| Step: 9
Training loss: 0.29756274819374084
Validation loss: 1.919737587372462

Epoch: 5| Step: 10
Training loss: 0.2982725501060486
Validation loss: 1.9193628082672756

Epoch: 5| Step: 11
Training loss: 0.506584644317627
Validation loss: 1.9089360535144806

Epoch: 376| Step: 0
Training loss: 0.36014485359191895
Validation loss: 1.9123014509677887

Epoch: 5| Step: 1
Training loss: 0.34584978222846985
Validation loss: 1.9260254800319672

Epoch: 5| Step: 2
Training loss: 0.588134765625
Validation loss: 1.8983546495437622

Epoch: 5| Step: 3
Training loss: 0.26775211095809937
Validation loss: 1.8866353382666905

Epoch: 5| Step: 4
Training loss: 0.2073398381471634
Validation loss: 1.8654646774133046

Epoch: 5| Step: 5
Training loss: 0.20499983429908752
Validation loss: 1.9270719041426976

Epoch: 5| Step: 6
Training loss: 0.32652658224105835
Validation loss: 1.9299113253752391

Epoch: 5| Step: 7
Training loss: 0.3163580596446991
Validation loss: 1.935951292514801

Epoch: 5| Step: 8
Training loss: 0.2942461371421814
Validation loss: 1.9072971791028976

Epoch: 5| Step: 9
Training loss: 0.7219893932342529
Validation loss: 1.9620113223791122

Epoch: 5| Step: 10
Training loss: 0.2565203309059143
Validation loss: 1.91834423939387

Epoch: 5| Step: 11
Training loss: 0.30254554748535156
Validation loss: 1.9178497244914372

Epoch: 377| Step: 0
Training loss: 0.2657420039176941
Validation loss: 1.9026195009549458

Epoch: 5| Step: 1
Training loss: 0.21391835808753967
Validation loss: 1.9232011437416077

Epoch: 5| Step: 2
Training loss: 0.25761139392852783
Validation loss: 1.9119898279507954

Epoch: 5| Step: 3
Training loss: 0.353171169757843
Validation loss: 1.9230415870745976

Epoch: 5| Step: 4
Training loss: 0.6315182447433472
Validation loss: 1.939674973487854

Epoch: 5| Step: 5
Training loss: 0.2578910291194916
Validation loss: 1.9330122123161952

Epoch: 5| Step: 6
Training loss: 0.49528321623802185
Validation loss: 1.9262768973906834

Epoch: 5| Step: 7
Training loss: 0.25063881278038025
Validation loss: 1.935762460033099

Epoch: 5| Step: 8
Training loss: 0.4374454617500305
Validation loss: 1.95620662967364

Epoch: 5| Step: 9
Training loss: 0.2939092218875885
Validation loss: 1.9811659355958302

Epoch: 5| Step: 10
Training loss: 0.37971556186676025
Validation loss: 1.9573156138261159

Epoch: 5| Step: 11
Training loss: 0.5403512120246887
Validation loss: 1.9463339000940323

Epoch: 378| Step: 0
Training loss: 0.33430635929107666
Validation loss: 1.943070873618126

Epoch: 5| Step: 1
Training loss: 0.7584123015403748
Validation loss: 1.9344115406274796

Epoch: 5| Step: 2
Training loss: 0.2554935812950134
Validation loss: 1.9276756097873051

Epoch: 5| Step: 3
Training loss: 0.3602813184261322
Validation loss: 1.933941900730133

Epoch: 5| Step: 4
Training loss: 0.24933254718780518
Validation loss: 1.8893881390492122

Epoch: 5| Step: 5
Training loss: 0.355404794216156
Validation loss: 1.9281800786654155

Epoch: 5| Step: 6
Training loss: 0.2031661570072174
Validation loss: 1.8945419788360596

Epoch: 5| Step: 7
Training loss: 0.31251588463783264
Validation loss: 1.908336654305458

Epoch: 5| Step: 8
Training loss: 0.19957193732261658
Validation loss: 1.9327746480703354

Epoch: 5| Step: 9
Training loss: 0.19631317257881165
Validation loss: 1.9417267392079036

Epoch: 5| Step: 10
Training loss: 0.3735355734825134
Validation loss: 1.9766739060481389

Epoch: 5| Step: 11
Training loss: 0.23936176300048828
Validation loss: 2.0053235789140067

Epoch: 379| Step: 0
Training loss: 0.29979950189590454
Validation loss: 1.9098148792982101

Epoch: 5| Step: 1
Training loss: 0.40427064895629883
Validation loss: 1.9350171635548274

Epoch: 5| Step: 2
Training loss: 0.34840843081474304
Validation loss: 1.9176598240931828

Epoch: 5| Step: 3
Training loss: 0.2992948591709137
Validation loss: 1.9145592153072357

Epoch: 5| Step: 4
Training loss: 0.43292608857154846
Validation loss: 1.9177267253398895

Epoch: 5| Step: 5
Training loss: 0.33630603551864624
Validation loss: 1.9265720148881276

Epoch: 5| Step: 6
Training loss: 0.19056108593940735
Validation loss: 1.9327278584241867

Epoch: 5| Step: 7
Training loss: 0.21885161101818085
Validation loss: 1.9540036022663116

Epoch: 5| Step: 8
Training loss: 0.7753046751022339
Validation loss: 1.9246225953102112

Epoch: 5| Step: 9
Training loss: 0.43192487955093384
Validation loss: 2.0051262875398

Epoch: 5| Step: 10
Training loss: 0.47048044204711914
Validation loss: 1.9717432856559753

Epoch: 5| Step: 11
Training loss: 0.5524718165397644
Validation loss: 1.9782207310199738

Epoch: 380| Step: 0
Training loss: 0.1716999113559723
Validation loss: 1.9141812821229298

Epoch: 5| Step: 1
Training loss: 0.33770185708999634
Validation loss: 1.8907426794370015

Epoch: 5| Step: 2
Training loss: 0.3585135340690613
Validation loss: 1.9033777564764023

Epoch: 5| Step: 3
Training loss: 0.4975354075431824
Validation loss: 1.8949872801701229

Epoch: 5| Step: 4
Training loss: 0.3291996419429779
Validation loss: 1.8926819115877151

Epoch: 5| Step: 5
Training loss: 0.2461031973361969
Validation loss: 1.924495627482732

Epoch: 5| Step: 6
Training loss: 0.5205705761909485
Validation loss: 1.864674836397171

Epoch: 5| Step: 7
Training loss: 0.24397549033164978
Validation loss: 1.9193477580944698

Epoch: 5| Step: 8
Training loss: 0.5533154606819153
Validation loss: 1.9249203205108643

Epoch: 5| Step: 9
Training loss: 0.28147563338279724
Validation loss: 1.9186045229434967

Epoch: 5| Step: 10
Training loss: 0.27462974190711975
Validation loss: 1.9368571589390438

Epoch: 5| Step: 11
Training loss: 0.047599971294403076
Validation loss: 1.9274070113897324

Epoch: 381| Step: 0
Training loss: 0.20555539429187775
Validation loss: 1.9351933300495148

Epoch: 5| Step: 1
Training loss: 0.6418944597244263
Validation loss: 1.901271680990855

Epoch: 5| Step: 2
Training loss: 0.44570961594581604
Validation loss: 1.916240359346072

Epoch: 5| Step: 3
Training loss: 0.4594140946865082
Validation loss: 1.906634251276652

Epoch: 5| Step: 4
Training loss: 0.26812708377838135
Validation loss: 1.923037091890971

Epoch: 5| Step: 5
Training loss: 0.3560340106487274
Validation loss: 1.9325728118419647

Epoch: 5| Step: 6
Training loss: 0.16501569747924805
Validation loss: 1.8611566523710887

Epoch: 5| Step: 7
Training loss: 0.2968369424343109
Validation loss: 1.9793071895837784

Epoch: 5| Step: 8
Training loss: 0.37756094336509705
Validation loss: 1.9527106781800587

Epoch: 5| Step: 9
Training loss: 0.4393154978752136
Validation loss: 1.9441444873809814

Epoch: 5| Step: 10
Training loss: 0.3154068887233734
Validation loss: 1.9477077225844066

Epoch: 5| Step: 11
Training loss: 0.5010360479354858
Validation loss: 1.963183065255483

Epoch: 382| Step: 0
Training loss: 0.36371374130249023
Validation loss: 1.954784428079923

Epoch: 5| Step: 1
Training loss: 0.6725679636001587
Validation loss: 1.9423944056034088

Epoch: 5| Step: 2
Training loss: 0.38870224356651306
Validation loss: 1.955663800239563

Epoch: 5| Step: 3
Training loss: 0.49599117040634155
Validation loss: 1.841648891568184

Epoch: 5| Step: 4
Training loss: 0.49990683794021606
Validation loss: 1.9337672392527263

Epoch: 5| Step: 5
Training loss: 0.3684646785259247
Validation loss: 1.9314911862214406

Epoch: 5| Step: 6
Training loss: 0.31824466586112976
Validation loss: 1.9880836705366771

Epoch: 5| Step: 7
Training loss: 0.34441807866096497
Validation loss: 2.011398106813431

Epoch: 5| Step: 8
Training loss: 0.4153539538383484
Validation loss: 1.9707563370466232

Epoch: 5| Step: 9
Training loss: 0.36067670583724976
Validation loss: 1.987890253464381

Epoch: 5| Step: 10
Training loss: 0.15301713347434998
Validation loss: 2.0209401845932007

Epoch: 5| Step: 11
Training loss: 0.36820918321609497
Validation loss: 1.892618214090665

Epoch: 383| Step: 0
Training loss: 0.2632080316543579
Validation loss: 1.886480137705803

Epoch: 5| Step: 1
Training loss: 0.3994064927101135
Validation loss: 1.8983972867329915

Epoch: 5| Step: 2
Training loss: 0.2565177083015442
Validation loss: 1.8822580873966217

Epoch: 5| Step: 3
Training loss: 0.2401677668094635
Validation loss: 1.9208474109570186

Epoch: 5| Step: 4
Training loss: 0.3166716992855072
Validation loss: 1.9308363298575084

Epoch: 5| Step: 5
Training loss: 0.21597711741924286
Validation loss: 1.9210179895162582

Epoch: 5| Step: 6
Training loss: 0.3441453278064728
Validation loss: 1.9097289095322292

Epoch: 5| Step: 7
Training loss: 0.5196027755737305
Validation loss: 1.9288231531778972

Epoch: 5| Step: 8
Training loss: 0.1296025514602661
Validation loss: 1.8871731559435527

Epoch: 5| Step: 9
Training loss: 0.09751754999160767
Validation loss: 1.8963799873987834

Epoch: 5| Step: 10
Training loss: 0.6874499917030334
Validation loss: 1.9369706064462662

Epoch: 5| Step: 11
Training loss: 0.10247465968132019
Validation loss: 1.9375148117542267

Epoch: 384| Step: 0
Training loss: 0.31720471382141113
Validation loss: 1.9845193922519684

Epoch: 5| Step: 1
Training loss: 0.34762319922447205
Validation loss: 1.986524720986684

Epoch: 5| Step: 2
Training loss: 0.6107808351516724
Validation loss: 1.97979869445165

Epoch: 5| Step: 3
Training loss: 0.6311169862747192
Validation loss: 1.9519554525613785

Epoch: 5| Step: 4
Training loss: 0.28788870573043823
Validation loss: 1.9111601213614147

Epoch: 5| Step: 5
Training loss: 0.37151971459388733
Validation loss: 1.922767549753189

Epoch: 5| Step: 6
Training loss: 0.3526723384857178
Validation loss: 1.9379221548636754

Epoch: 5| Step: 7
Training loss: 0.3357512056827545
Validation loss: 1.8878979831933975

Epoch: 5| Step: 8
Training loss: 0.40787047147750854
Validation loss: 1.90997876226902

Epoch: 5| Step: 9
Training loss: 0.22618798911571503
Validation loss: 1.9263399094343185

Epoch: 5| Step: 10
Training loss: 0.29717597365379333
Validation loss: 1.8939394106467564

Epoch: 5| Step: 11
Training loss: 0.18303567171096802
Validation loss: 1.912930354475975

Epoch: 385| Step: 0
Training loss: 0.4396488666534424
Validation loss: 1.9022942980130513

Epoch: 5| Step: 1
Training loss: 0.5957549214363098
Validation loss: 1.8996651420990627

Epoch: 5| Step: 2
Training loss: 0.38032713532447815
Validation loss: 1.9409209539492924

Epoch: 5| Step: 3
Training loss: 0.19146700203418732
Validation loss: 1.9423073828220367

Epoch: 5| Step: 4
Training loss: 0.4225265383720398
Validation loss: 1.9427558581034343

Epoch: 5| Step: 5
Training loss: 0.27650943398475647
Validation loss: 1.9313636124134064

Epoch: 5| Step: 6
Training loss: 0.21597161889076233
Validation loss: 1.9261012921730678

Epoch: 5| Step: 7
Training loss: 0.24064064025878906
Validation loss: 1.9227748215198517

Epoch: 5| Step: 8
Training loss: 0.3958669602870941
Validation loss: 1.9105704873800278

Epoch: 5| Step: 9
Training loss: 0.2778763175010681
Validation loss: 1.9849656075239182

Epoch: 5| Step: 10
Training loss: 0.22127752006053925
Validation loss: 1.92605226735274

Epoch: 5| Step: 11
Training loss: 0.04640266299247742
Validation loss: 1.9438971032698948

Epoch: 386| Step: 0
Training loss: 0.23348763585090637
Validation loss: 1.9513786534468334

Epoch: 5| Step: 1
Training loss: 0.27105528116226196
Validation loss: 1.9287538280089696

Epoch: 5| Step: 2
Training loss: 0.46611934900283813
Validation loss: 1.8888490746418636

Epoch: 5| Step: 3
Training loss: 0.4373924136161804
Validation loss: 1.9356970687707264

Epoch: 5| Step: 4
Training loss: 0.32321253418922424
Validation loss: 1.902526890238126

Epoch: 5| Step: 5
Training loss: 0.2723188102245331
Validation loss: 1.9333834052085876

Epoch: 5| Step: 6
Training loss: 0.2896990180015564
Validation loss: 1.9070964256922405

Epoch: 5| Step: 7
Training loss: 0.6892411112785339
Validation loss: 1.932853286465009

Epoch: 5| Step: 8
Training loss: 0.45179644227027893
Validation loss: 1.9420007864634197

Epoch: 5| Step: 9
Training loss: 0.3707084059715271
Validation loss: 1.9336142241954803

Epoch: 5| Step: 10
Training loss: 0.17831888794898987
Validation loss: 1.9843267351388931

Epoch: 5| Step: 11
Training loss: 0.264228492975235
Validation loss: 1.9744706799586613

Epoch: 387| Step: 0
Training loss: 0.21827340126037598
Validation loss: 1.9465448757012684

Epoch: 5| Step: 1
Training loss: 0.7027304768562317
Validation loss: 1.9135126372178395

Epoch: 5| Step: 2
Training loss: 0.4820147454738617
Validation loss: 1.8647839625676472

Epoch: 5| Step: 3
Training loss: 0.3493652641773224
Validation loss: 1.9156861305236816

Epoch: 5| Step: 4
Training loss: 0.18947681784629822
Validation loss: 1.9189543773730595

Epoch: 5| Step: 5
Training loss: 0.27075493335723877
Validation loss: 1.9282073974609375

Epoch: 5| Step: 6
Training loss: 0.34938305616378784
Validation loss: 1.9283405045668285

Epoch: 5| Step: 7
Training loss: 0.3445064425468445
Validation loss: 1.9658589214086533

Epoch: 5| Step: 8
Training loss: 0.46701279282569885
Validation loss: 1.9597163250048955

Epoch: 5| Step: 9
Training loss: 0.19097928702831268
Validation loss: 1.9210647493600845

Epoch: 5| Step: 10
Training loss: 0.31734469532966614
Validation loss: 1.9443805118401845

Epoch: 5| Step: 11
Training loss: 0.06390500068664551
Validation loss: 1.8678876509269078

Epoch: 388| Step: 0
Training loss: 0.45504847168922424
Validation loss: 1.886690005660057

Epoch: 5| Step: 1
Training loss: 0.43910542130470276
Validation loss: 1.8881860673427582

Epoch: 5| Step: 2
Training loss: 0.7667872905731201
Validation loss: 1.8654860804478328

Epoch: 5| Step: 3
Training loss: 0.4773224890232086
Validation loss: 1.8690156141916912

Epoch: 5| Step: 4
Training loss: 0.379328191280365
Validation loss: 1.8757888327042262

Epoch: 5| Step: 5
Training loss: 0.36280685663223267
Validation loss: 1.896625131368637

Epoch: 5| Step: 6
Training loss: 0.23416849970817566
Validation loss: 1.9706462621688843

Epoch: 5| Step: 7
Training loss: 0.36912599205970764
Validation loss: 1.9998888621727626

Epoch: 5| Step: 8
Training loss: 0.4637027680873871
Validation loss: 1.9137592713038127

Epoch: 5| Step: 9
Training loss: 0.2522485554218292
Validation loss: 1.9235935856898625

Epoch: 5| Step: 10
Training loss: 0.23010370135307312
Validation loss: 1.8967991322278976

Epoch: 5| Step: 11
Training loss: 0.2048715054988861
Validation loss: 1.8985485931237538

Epoch: 389| Step: 0
Training loss: 0.5422348380088806
Validation loss: 1.8866124699513118

Epoch: 5| Step: 1
Training loss: 0.478923499584198
Validation loss: 1.89935136338075

Epoch: 5| Step: 2
Training loss: 0.4367004930973053
Validation loss: 1.8954822421073914

Epoch: 5| Step: 3
Training loss: 0.2864246964454651
Validation loss: 1.911282608906428

Epoch: 5| Step: 4
Training loss: 0.6510303020477295
Validation loss: 1.9267069796721141

Epoch: 5| Step: 5
Training loss: 0.21339568495750427
Validation loss: 1.953164388736089

Epoch: 5| Step: 6
Training loss: 0.609048068523407
Validation loss: 2.003526215751966

Epoch: 5| Step: 7
Training loss: 0.290894091129303
Validation loss: 1.9674373716115952

Epoch: 5| Step: 8
Training loss: 0.4073886275291443
Validation loss: 1.9756943782170613

Epoch: 5| Step: 9
Training loss: 0.2621838450431824
Validation loss: 1.9740757296482723

Epoch: 5| Step: 10
Training loss: 0.24345123767852783
Validation loss: 1.9309833496809006

Epoch: 5| Step: 11
Training loss: 0.30348801612854004
Validation loss: 1.8929350276788075

Epoch: 390| Step: 0
Training loss: 0.3158453106880188
Validation loss: 1.9141263713439305

Epoch: 5| Step: 1
Training loss: 0.4471036493778229
Validation loss: 1.9649774481852849

Epoch: 5| Step: 2
Training loss: 0.35158437490463257
Validation loss: 1.9079198390245438

Epoch: 5| Step: 3
Training loss: 0.5149877667427063
Validation loss: 1.9528666536013286

Epoch: 5| Step: 4
Training loss: 0.338884174823761
Validation loss: 1.9097719341516495

Epoch: 5| Step: 5
Training loss: 0.3012266159057617
Validation loss: 1.9336011956135433

Epoch: 5| Step: 6
Training loss: 0.1982538104057312
Validation loss: 1.9823895295461018

Epoch: 5| Step: 7
Training loss: 0.473776251077652
Validation loss: 2.0139219711224237

Epoch: 5| Step: 8
Training loss: 0.3278238773345947
Validation loss: 1.9544578989346821

Epoch: 5| Step: 9
Training loss: 0.3839331269264221
Validation loss: 1.9432621747255325

Epoch: 5| Step: 10
Training loss: 0.5303889513015747
Validation loss: 1.9095090627670288

Epoch: 5| Step: 11
Training loss: 0.13050150871276855
Validation loss: 1.963137259085973

Epoch: 391| Step: 0
Training loss: 0.3606882691383362
Validation loss: 1.9080678075551987

Epoch: 5| Step: 1
Training loss: 0.30280762910842896
Validation loss: 1.9197338620821636

Epoch: 5| Step: 2
Training loss: 0.6920944452285767
Validation loss: 1.8950418680906296

Epoch: 5| Step: 3
Training loss: 0.34651634097099304
Validation loss: 1.8989147543907166

Epoch: 5| Step: 4
Training loss: 0.2578938603401184
Validation loss: 1.8776366064945857

Epoch: 5| Step: 5
Training loss: 0.2729261517524719
Validation loss: 1.9558653086423874

Epoch: 5| Step: 6
Training loss: 0.34333473443984985
Validation loss: 1.982515757282575

Epoch: 5| Step: 7
Training loss: 0.5164400339126587
Validation loss: 1.9691552023092906

Epoch: 5| Step: 8
Training loss: 0.1791558563709259
Validation loss: 1.9784030119578044

Epoch: 5| Step: 9
Training loss: 0.3210187554359436
Validation loss: 1.9176016598939896

Epoch: 5| Step: 10
Training loss: 0.3366072177886963
Validation loss: 1.8930331766605377

Epoch: 5| Step: 11
Training loss: 0.1223362386226654
Validation loss: 1.9090891182422638

Epoch: 392| Step: 0
Training loss: 0.2918859124183655
Validation loss: 1.948478067914645

Epoch: 5| Step: 1
Training loss: 0.20678457617759705
Validation loss: 1.9119798094034195

Epoch: 5| Step: 2
Training loss: 0.22765059769153595
Validation loss: 1.9496082713206608

Epoch: 5| Step: 3
Training loss: 0.31542930006980896
Validation loss: 1.955954040090243

Epoch: 5| Step: 4
Training loss: 0.6144685745239258
Validation loss: 1.9077424456675847

Epoch: 5| Step: 5
Training loss: 0.34954380989074707
Validation loss: 1.924278696378072

Epoch: 5| Step: 6
Training loss: 0.267432302236557
Validation loss: 1.9520606150229771

Epoch: 5| Step: 7
Training loss: 0.3824402093887329
Validation loss: 1.935622324546178

Epoch: 5| Step: 8
Training loss: 0.24300381541252136
Validation loss: 1.9297608584165573

Epoch: 5| Step: 9
Training loss: 0.260224312543869
Validation loss: 1.9261632561683655

Epoch: 5| Step: 10
Training loss: 0.27929896116256714
Validation loss: 1.9395486662785213

Epoch: 5| Step: 11
Training loss: 0.31632423400878906
Validation loss: 1.9104286481936772

Epoch: 393| Step: 0
Training loss: 0.2861183285713196
Validation loss: 1.9157829731702805

Epoch: 5| Step: 1
Training loss: 0.23300966620445251
Validation loss: 1.8973761747280757

Epoch: 5| Step: 2
Training loss: 0.3005041778087616
Validation loss: 1.9030966262022655

Epoch: 5| Step: 3
Training loss: 0.22098059952259064
Validation loss: 1.8968994617462158

Epoch: 5| Step: 4
Training loss: 0.19627848267555237
Validation loss: 1.875302940607071

Epoch: 5| Step: 5
Training loss: 0.5524801015853882
Validation loss: 1.8913553953170776

Epoch: 5| Step: 6
Training loss: 0.24284139275550842
Validation loss: 1.8565235535303752

Epoch: 5| Step: 7
Training loss: 0.7263498902320862
Validation loss: 1.8850760161876678

Epoch: 5| Step: 8
Training loss: 0.308191180229187
Validation loss: 1.9445774008830388

Epoch: 5| Step: 9
Training loss: 0.40432634949684143
Validation loss: 1.893394152323405

Epoch: 5| Step: 10
Training loss: 0.3998117446899414
Validation loss: 1.9010751644770305

Epoch: 5| Step: 11
Training loss: 0.4099811315536499
Validation loss: 1.8944767316182454

Epoch: 394| Step: 0
Training loss: 0.27060508728027344
Validation loss: 1.9366035411755245

Epoch: 5| Step: 1
Training loss: 0.4098351001739502
Validation loss: 1.9079846739768982

Epoch: 5| Step: 2
Training loss: 0.392609566450119
Validation loss: 1.8525207489728928

Epoch: 5| Step: 3
Training loss: 0.22293739020824432
Validation loss: 1.893012672662735

Epoch: 5| Step: 4
Training loss: 0.614820122718811
Validation loss: 1.899533063173294

Epoch: 5| Step: 5
Training loss: 0.28872495889663696
Validation loss: 1.8863500207662582

Epoch: 5| Step: 6
Training loss: 0.3096438944339752
Validation loss: 1.9149436901013057

Epoch: 5| Step: 7
Training loss: 0.4421962797641754
Validation loss: 1.9119510849316914

Epoch: 5| Step: 8
Training loss: 0.3991452157497406
Validation loss: 1.911586046218872

Epoch: 5| Step: 9
Training loss: 0.3154454529285431
Validation loss: 1.9453483422597249

Epoch: 5| Step: 10
Training loss: 0.3101360499858856
Validation loss: 1.9234198331832886

Epoch: 5| Step: 11
Training loss: 0.20440152287483215
Validation loss: 1.9117026974757512

Epoch: 395| Step: 0
Training loss: 0.31169402599334717
Validation loss: 1.907993644475937

Epoch: 5| Step: 1
Training loss: 0.3238452672958374
Validation loss: 1.8916525741418202

Epoch: 5| Step: 2
Training loss: 0.2039642632007599
Validation loss: 1.9186262488365173

Epoch: 5| Step: 3
Training loss: 0.2125585526227951
Validation loss: 1.8747273584206898

Epoch: 5| Step: 4
Training loss: 0.23056116700172424
Validation loss: 1.9101488143205643

Epoch: 5| Step: 5
Training loss: 0.5889109373092651
Validation loss: 1.9311382869879405

Epoch: 5| Step: 6
Training loss: 0.19532373547554016
Validation loss: 1.9052740037441254

Epoch: 5| Step: 7
Training loss: 0.24982300400733948
Validation loss: 1.9537366429964702

Epoch: 5| Step: 8
Training loss: 0.318206787109375
Validation loss: 1.9254563301801682

Epoch: 5| Step: 9
Training loss: 0.5475242137908936
Validation loss: 1.8983132590850194

Epoch: 5| Step: 10
Training loss: 0.322941392660141
Validation loss: 1.9014167189598083

Epoch: 5| Step: 11
Training loss: 0.6716299057006836
Validation loss: 1.8895499805609386

Epoch: 396| Step: 0
Training loss: 0.2802179455757141
Validation loss: 1.886068080862363

Epoch: 5| Step: 1
Training loss: 0.2547488808631897
Validation loss: 1.8898029426733653

Epoch: 5| Step: 2
Training loss: 0.6756858825683594
Validation loss: 1.843803773323695

Epoch: 5| Step: 3
Training loss: 0.2502231299877167
Validation loss: 1.912816454966863

Epoch: 5| Step: 4
Training loss: 0.2052694857120514
Validation loss: 1.9577774951855342

Epoch: 5| Step: 5
Training loss: 0.2195519655942917
Validation loss: 1.932882567246755

Epoch: 5| Step: 6
Training loss: 0.33324137330055237
Validation loss: 1.8885784596204758

Epoch: 5| Step: 7
Training loss: 0.33727675676345825
Validation loss: 1.9266538868347804

Epoch: 5| Step: 8
Training loss: 0.4112587869167328
Validation loss: 1.9352358827988307

Epoch: 5| Step: 9
Training loss: 0.2442486733198166
Validation loss: 1.907727340857188

Epoch: 5| Step: 10
Training loss: 0.49795442819595337
Validation loss: 1.909151703119278

Epoch: 5| Step: 11
Training loss: 0.13714268803596497
Validation loss: 1.9038849622011185

Epoch: 397| Step: 0
Training loss: 0.25420475006103516
Validation loss: 1.9094955970843632

Epoch: 5| Step: 1
Training loss: 0.3128332793712616
Validation loss: 1.9362642963727315

Epoch: 5| Step: 2
Training loss: 0.25824227929115295
Validation loss: 1.9328120698531468

Epoch: 5| Step: 3
Training loss: 0.13833549618721008
Validation loss: 1.9158452947934468

Epoch: 5| Step: 4
Training loss: 0.2515830099582672
Validation loss: 1.9174306790033977

Epoch: 5| Step: 5
Training loss: 0.3193361461162567
Validation loss: 1.9271761924028397

Epoch: 5| Step: 6
Training loss: 0.5513566136360168
Validation loss: 1.8942146400610607

Epoch: 5| Step: 7
Training loss: 0.28677576780319214
Validation loss: 1.8705828587214153

Epoch: 5| Step: 8
Training loss: 0.3222777545452118
Validation loss: 1.9041010737419128

Epoch: 5| Step: 9
Training loss: 0.48550525307655334
Validation loss: 1.9170424689849217

Epoch: 5| Step: 10
Training loss: 0.20425689220428467
Validation loss: 1.918266197045644

Epoch: 5| Step: 11
Training loss: 0.14622437953948975
Validation loss: 1.9296880811452866

Epoch: 398| Step: 0
Training loss: 0.2453680783510208
Validation loss: 1.9136360337336857

Epoch: 5| Step: 1
Training loss: 0.3281344473361969
Validation loss: 1.9416639904181163

Epoch: 5| Step: 2
Training loss: 0.25319042801856995
Validation loss: 1.930331215262413

Epoch: 5| Step: 3
Training loss: 0.5062595009803772
Validation loss: 1.91278309126695

Epoch: 5| Step: 4
Training loss: 0.18426966667175293
Validation loss: 1.909998173515002

Epoch: 5| Step: 5
Training loss: 0.4123271107673645
Validation loss: 1.907874658703804

Epoch: 5| Step: 6
Training loss: 0.3677138090133667
Validation loss: 1.884342223405838

Epoch: 5| Step: 7
Training loss: 0.2932508587837219
Validation loss: 1.887016514937083

Epoch: 5| Step: 8
Training loss: 0.2516913414001465
Validation loss: 1.8716370264689128

Epoch: 5| Step: 9
Training loss: 0.2896674871444702
Validation loss: 1.9014793187379837

Epoch: 5| Step: 10
Training loss: 0.5292056798934937
Validation loss: 1.8775576800107956

Epoch: 5| Step: 11
Training loss: 0.34203994274139404
Validation loss: 1.9557096759478252

Epoch: 399| Step: 0
Training loss: 0.340583860874176
Validation loss: 1.9437110722064972

Epoch: 5| Step: 1
Training loss: 0.3137759864330292
Validation loss: 1.9697351704041164

Epoch: 5| Step: 2
Training loss: 0.32661643624305725
Validation loss: 1.8906293660402298

Epoch: 5| Step: 3
Training loss: 0.1882227659225464
Validation loss: 1.9199244230985641

Epoch: 5| Step: 4
Training loss: 0.2103615701198578
Validation loss: 1.9338619410991669

Epoch: 5| Step: 5
Training loss: 0.6179556846618652
Validation loss: 1.889956419666608

Epoch: 5| Step: 6
Training loss: 0.30700522661209106
Validation loss: 1.9016580333312352

Epoch: 5| Step: 7
Training loss: 0.23509331047534943
Validation loss: 1.905099630355835

Epoch: 5| Step: 8
Training loss: 0.22828412055969238
Validation loss: 1.902199034889539

Epoch: 5| Step: 9
Training loss: 0.2265385091304779
Validation loss: 1.946361854672432

Epoch: 5| Step: 10
Training loss: 0.16229012608528137
Validation loss: 1.9356262385845184

Epoch: 5| Step: 11
Training loss: 1.2783163785934448
Validation loss: 1.939412107070287

Epoch: 400| Step: 0
Training loss: 0.3149804472923279
Validation loss: 1.884303053220113

Epoch: 5| Step: 1
Training loss: 0.15379932522773743
Validation loss: 1.9300139397382736

Epoch: 5| Step: 2
Training loss: 0.1441887617111206
Validation loss: 1.9134957144657772

Epoch: 5| Step: 3
Training loss: 0.5108109712600708
Validation loss: 1.9094926019509633

Epoch: 5| Step: 4
Training loss: 0.36863070726394653
Validation loss: 1.8676513582468033

Epoch: 5| Step: 5
Training loss: 0.32331809401512146
Validation loss: 1.9347364803155263

Epoch: 5| Step: 6
Training loss: 0.24834802746772766
Validation loss: 1.8797865957021713

Epoch: 5| Step: 7
Training loss: 0.16495302319526672
Validation loss: 1.9362807075182598

Epoch: 5| Step: 8
Training loss: 0.7011608481407166
Validation loss: 1.9191834628582

Epoch: 5| Step: 9
Training loss: 0.1959112137556076
Validation loss: 1.9133106817801793

Epoch: 5| Step: 10
Training loss: 0.25332432985305786
Validation loss: 1.9178907175858815

Epoch: 5| Step: 11
Training loss: 0.1504504382610321
Validation loss: 1.8939390579859416

Epoch: 401| Step: 0
Training loss: 0.20257744193077087
Validation loss: 1.940540725986163

Epoch: 5| Step: 1
Training loss: 0.23072712123394012
Validation loss: 1.923494776089986

Epoch: 5| Step: 2
Training loss: 0.3535957932472229
Validation loss: 1.932431474328041

Epoch: 5| Step: 3
Training loss: 0.6355807781219482
Validation loss: 1.9462009370326996

Epoch: 5| Step: 4
Training loss: 0.2586946487426758
Validation loss: 1.8838818023602169

Epoch: 5| Step: 5
Training loss: 0.3631751239299774
Validation loss: 1.8607819775740306

Epoch: 5| Step: 6
Training loss: 0.46479886770248413
Validation loss: 1.853635162115097

Epoch: 5| Step: 7
Training loss: 0.2499578446149826
Validation loss: 1.8889597654342651

Epoch: 5| Step: 8
Training loss: 0.29616376757621765
Validation loss: 1.879328469435374

Epoch: 5| Step: 9
Training loss: 0.3700428605079651
Validation loss: 1.862525959809621

Epoch: 5| Step: 10
Training loss: 0.2550734877586365
Validation loss: 1.8759233405192692

Epoch: 5| Step: 11
Training loss: 0.27026626467704773
Validation loss: 1.9397533386945724

Epoch: 402| Step: 0
Training loss: 0.31551051139831543
Validation loss: 1.9459420243899028

Epoch: 5| Step: 1
Training loss: 0.25019240379333496
Validation loss: 1.9135172665119171

Epoch: 5| Step: 2
Training loss: 0.2613371014595032
Validation loss: 1.873167132337888

Epoch: 5| Step: 3
Training loss: 0.20676366984844208
Validation loss: 1.9271947741508484

Epoch: 5| Step: 4
Training loss: 0.4253908097743988
Validation loss: 1.907148947318395

Epoch: 5| Step: 5
Training loss: 0.41338950395584106
Validation loss: 1.9106772790352504

Epoch: 5| Step: 6
Training loss: 0.2649569809436798
Validation loss: 1.8902707596619923

Epoch: 5| Step: 7
Training loss: 0.2913457155227661
Validation loss: 1.8770264039436977

Epoch: 5| Step: 8
Training loss: 0.34932228922843933
Validation loss: 1.9028483430544536

Epoch: 5| Step: 9
Training loss: 0.24968311190605164
Validation loss: 1.938366875052452

Epoch: 5| Step: 10
Training loss: 0.2703917622566223
Validation loss: 1.902532974878947

Epoch: 5| Step: 11
Training loss: 2.025071620941162
Validation loss: 1.91182242333889

Epoch: 403| Step: 0
Training loss: 0.24783316254615784
Validation loss: 1.933291842540105

Epoch: 5| Step: 1
Training loss: 0.20035254955291748
Validation loss: 1.9830858906110127

Epoch: 5| Step: 2
Training loss: 0.30026695132255554
Validation loss: 1.959712306658427

Epoch: 5| Step: 3
Training loss: 0.5251373052597046
Validation loss: 1.9576714287201564

Epoch: 5| Step: 4
Training loss: 0.574959397315979
Validation loss: 1.926717186967532

Epoch: 5| Step: 5
Training loss: 0.2601131796836853
Validation loss: 1.8750933806101482

Epoch: 5| Step: 6
Training loss: 0.3009907603263855
Validation loss: 1.90068918466568

Epoch: 5| Step: 7
Training loss: 0.47857552766799927
Validation loss: 1.9399966597557068

Epoch: 5| Step: 8
Training loss: 0.29187893867492676
Validation loss: 1.8709806849559147

Epoch: 5| Step: 9
Training loss: 0.31944289803504944
Validation loss: 1.9288810441891353

Epoch: 5| Step: 10
Training loss: 0.3389660716056824
Validation loss: 1.9020651082197826

Epoch: 5| Step: 11
Training loss: 0.13505083322525024
Validation loss: 1.9232676674922307

Epoch: 404| Step: 0
Training loss: 0.20885822176933289
Validation loss: 1.9070826172828674

Epoch: 5| Step: 1
Training loss: 0.19521263241767883
Validation loss: 1.8967998623847961

Epoch: 5| Step: 2
Training loss: 0.22384551167488098
Validation loss: 1.8605973422527313

Epoch: 5| Step: 3
Training loss: 0.4102429747581482
Validation loss: 1.9316634734471638

Epoch: 5| Step: 4
Training loss: 0.3016326129436493
Validation loss: 1.8652423322200775

Epoch: 5| Step: 5
Training loss: 0.3327314853668213
Validation loss: 1.946182866891225

Epoch: 5| Step: 6
Training loss: 0.3283642828464508
Validation loss: 1.9082191338141758

Epoch: 5| Step: 7
Training loss: 0.4295922815799713
Validation loss: 1.9470584293206532

Epoch: 5| Step: 8
Training loss: 0.6127841472625732
Validation loss: 1.950676217675209

Epoch: 5| Step: 9
Training loss: 0.2932527959346771
Validation loss: 1.9194366534550984

Epoch: 5| Step: 10
Training loss: 0.3004491925239563
Validation loss: 1.9478323310613632

Epoch: 5| Step: 11
Training loss: 0.12345585972070694
Validation loss: 1.9307124962409337

Epoch: 405| Step: 0
Training loss: 0.281448096036911
Validation loss: 1.8893666366736095

Epoch: 5| Step: 1
Training loss: 0.3525152802467346
Validation loss: 1.9408858219782512

Epoch: 5| Step: 2
Training loss: 0.4180164337158203
Validation loss: 1.8897824337085087

Epoch: 5| Step: 3
Training loss: 0.7146624326705933
Validation loss: 1.9158770243326824

Epoch: 5| Step: 4
Training loss: 0.17326238751411438
Validation loss: 1.900429755449295

Epoch: 5| Step: 5
Training loss: 0.21380087733268738
Validation loss: 1.9034066051244736

Epoch: 5| Step: 6
Training loss: 0.2785242199897766
Validation loss: 1.9172590573628743

Epoch: 5| Step: 7
Training loss: 0.1815367192029953
Validation loss: 1.917029653986295

Epoch: 5| Step: 8
Training loss: 0.2636585235595703
Validation loss: 1.9313614219427109

Epoch: 5| Step: 9
Training loss: 0.3993908166885376
Validation loss: 1.932926704486211

Epoch: 5| Step: 10
Training loss: 0.2988557815551758
Validation loss: 1.903444195787112

Epoch: 5| Step: 11
Training loss: 0.18556243181228638
Validation loss: 1.9276128709316254

Epoch: 406| Step: 0
Training loss: 0.5307084321975708
Validation loss: 1.896934335430463

Epoch: 5| Step: 1
Training loss: 0.17251190543174744
Validation loss: 1.906895950436592

Epoch: 5| Step: 2
Training loss: 0.3450481593608856
Validation loss: 1.9069485664367676

Epoch: 5| Step: 3
Training loss: 0.19541487097740173
Validation loss: 1.9360955109198887

Epoch: 5| Step: 4
Training loss: 0.5943571329116821
Validation loss: 1.8948278228441875

Epoch: 5| Step: 5
Training loss: 0.2633727788925171
Validation loss: 1.89743372797966

Epoch: 5| Step: 6
Training loss: 0.15383310616016388
Validation loss: 1.9097802887360256

Epoch: 5| Step: 7
Training loss: 0.272624671459198
Validation loss: 1.931990106900533

Epoch: 5| Step: 8
Training loss: 0.24982187151908875
Validation loss: 1.8864436348279316

Epoch: 5| Step: 9
Training loss: 0.29328805208206177
Validation loss: 1.8932603498299916

Epoch: 5| Step: 10
Training loss: 0.18125972151756287
Validation loss: 1.915673166513443

Epoch: 5| Step: 11
Training loss: 0.24337726831436157
Validation loss: 1.91696664194266

Epoch: 407| Step: 0
Training loss: 0.24086718261241913
Validation loss: 1.8907730430364609

Epoch: 5| Step: 1
Training loss: 0.19609203934669495
Validation loss: 1.914347176750501

Epoch: 5| Step: 2
Training loss: 0.5271393060684204
Validation loss: 1.9029974192380905

Epoch: 5| Step: 3
Training loss: 0.5262873768806458
Validation loss: 1.8935913542906444

Epoch: 5| Step: 4
Training loss: 0.32064709067344666
Validation loss: 1.8689150710900624

Epoch: 5| Step: 5
Training loss: 0.17690713703632355
Validation loss: 1.9386769930521648

Epoch: 5| Step: 6
Training loss: 0.20187032222747803
Validation loss: 1.878074546655019

Epoch: 5| Step: 7
Training loss: 0.30491113662719727
Validation loss: 1.8999207665522893

Epoch: 5| Step: 8
Training loss: 0.1403980255126953
Validation loss: 1.8967193216085434

Epoch: 5| Step: 9
Training loss: 0.29034724831581116
Validation loss: 1.9153489818175633

Epoch: 5| Step: 10
Training loss: 0.3335646390914917
Validation loss: 1.8565927396217983

Epoch: 5| Step: 11
Training loss: 0.26231226325035095
Validation loss: 1.9009602467219036

Epoch: 408| Step: 0
Training loss: 0.26663926243782043
Validation loss: 1.9459893157084782

Epoch: 5| Step: 1
Training loss: 0.24061712622642517
Validation loss: 1.8841574688752492

Epoch: 5| Step: 2
Training loss: 0.2716420590877533
Validation loss: 1.8774772485097249

Epoch: 5| Step: 3
Training loss: 0.23005087673664093
Validation loss: 1.947709212700526

Epoch: 5| Step: 4
Training loss: 0.24506989121437073
Validation loss: 1.8890623946984608

Epoch: 5| Step: 5
Training loss: 0.5580015182495117
Validation loss: 1.8386059155066807

Epoch: 5| Step: 6
Training loss: 0.4947163462638855
Validation loss: 1.9276263068119686

Epoch: 5| Step: 7
Training loss: 0.24683205783367157
Validation loss: 1.925008808573087

Epoch: 5| Step: 8
Training loss: 0.32447943091392517
Validation loss: 1.8911051998535793

Epoch: 5| Step: 9
Training loss: 0.25274521112442017
Validation loss: 1.8851502686738968

Epoch: 5| Step: 10
Training loss: 0.29490602016448975
Validation loss: 1.8989245494206746

Epoch: 5| Step: 11
Training loss: 0.5524656772613525
Validation loss: 1.8851514707008998

Epoch: 409| Step: 0
Training loss: 0.23832769691944122
Validation loss: 1.8825646291176479

Epoch: 5| Step: 1
Training loss: 0.20951008796691895
Validation loss: 1.9040731539328892

Epoch: 5| Step: 2
Training loss: 0.32618826627731323
Validation loss: 1.9114780972401302

Epoch: 5| Step: 3
Training loss: 0.3327735960483551
Validation loss: 1.9503433505694072

Epoch: 5| Step: 4
Training loss: 0.47744521498680115
Validation loss: 1.9065729528665543

Epoch: 5| Step: 5
Training loss: 0.5539848804473877
Validation loss: 1.9014179855585098

Epoch: 5| Step: 6
Training loss: 0.26593223214149475
Validation loss: 1.8821437309185665

Epoch: 5| Step: 7
Training loss: 0.15412703156471252
Validation loss: 1.9381169974803925

Epoch: 5| Step: 8
Training loss: 0.5063254833221436
Validation loss: 1.8918355405330658

Epoch: 5| Step: 9
Training loss: 0.2874687910079956
Validation loss: 1.8706967035929363

Epoch: 5| Step: 10
Training loss: 0.17449282109737396
Validation loss: 1.9181474099556606

Epoch: 5| Step: 11
Training loss: 0.34582966566085815
Validation loss: 1.9371255089839299

Epoch: 410| Step: 0
Training loss: 0.21075041592121124
Validation loss: 1.923087810476621

Epoch: 5| Step: 1
Training loss: 0.23753675818443298
Validation loss: 1.9317370355129242

Epoch: 5| Step: 2
Training loss: 0.20820645987987518
Validation loss: 1.910996397336324

Epoch: 5| Step: 3
Training loss: 0.213161438703537
Validation loss: 1.908783659338951

Epoch: 5| Step: 4
Training loss: 0.2702690362930298
Validation loss: 1.8929855624834697

Epoch: 5| Step: 5
Training loss: 0.4363139271736145
Validation loss: 1.8938202758630116

Epoch: 5| Step: 6
Training loss: 0.31844478845596313
Validation loss: 1.891027107834816

Epoch: 5| Step: 7
Training loss: 0.38775572180747986
Validation loss: 1.8925024370352428

Epoch: 5| Step: 8
Training loss: 0.6368621587753296
Validation loss: 1.8853149265050888

Epoch: 5| Step: 9
Training loss: 0.26365116238594055
Validation loss: 1.9108553926150005

Epoch: 5| Step: 10
Training loss: 0.3949829638004303
Validation loss: 1.9178482939799626

Epoch: 5| Step: 11
Training loss: 0.20374330878257751
Validation loss: 1.8912997841835022

Epoch: 411| Step: 0
Training loss: 0.6635643839836121
Validation loss: 1.8951603919267654

Epoch: 5| Step: 1
Training loss: 0.34697169065475464
Validation loss: 1.8625492403904598

Epoch: 5| Step: 2
Training loss: 0.25406140089035034
Validation loss: 1.8749926288922627

Epoch: 5| Step: 3
Training loss: 0.33054274320602417
Validation loss: 1.9318637152512868

Epoch: 5| Step: 4
Training loss: 0.35680752992630005
Validation loss: 1.9041117082039516

Epoch: 5| Step: 5
Training loss: 0.1970103681087494
Validation loss: 1.916305457552274

Epoch: 5| Step: 6
Training loss: 0.3328571319580078
Validation loss: 1.9345855663220088

Epoch: 5| Step: 7
Training loss: 0.3724187910556793
Validation loss: 1.924859603246053

Epoch: 5| Step: 8
Training loss: 0.22038617730140686
Validation loss: 1.9108535299698512

Epoch: 5| Step: 9
Training loss: 0.4157043397426605
Validation loss: 1.9315366297960281

Epoch: 5| Step: 10
Training loss: 0.18007208406925201
Validation loss: 1.8936749498049419

Epoch: 5| Step: 11
Training loss: 0.2146388292312622
Validation loss: 1.9046592166026433

Epoch: 412| Step: 0
Training loss: 0.539810061454773
Validation loss: 1.8612110763788223

Epoch: 5| Step: 1
Training loss: 0.3285568654537201
Validation loss: 1.8747831483681996

Epoch: 5| Step: 2
Training loss: 0.25290486216545105
Validation loss: 1.8634469360113144

Epoch: 5| Step: 3
Training loss: 0.17512914538383484
Validation loss: 1.8756619493166606

Epoch: 5| Step: 4
Training loss: 0.2397797852754593
Validation loss: 1.946912740667661

Epoch: 5| Step: 5
Training loss: 0.34269586205482483
Validation loss: 1.9787205755710602

Epoch: 5| Step: 6
Training loss: 0.18137216567993164
Validation loss: 1.90215864777565

Epoch: 5| Step: 7
Training loss: 0.29243263602256775
Validation loss: 1.9448221723238628

Epoch: 5| Step: 8
Training loss: 0.2787395417690277
Validation loss: 1.9195779313643773

Epoch: 5| Step: 9
Training loss: 0.6695703268051147
Validation loss: 1.9146746794382732

Epoch: 5| Step: 10
Training loss: 0.1599578857421875
Validation loss: 1.8932904948790867

Epoch: 5| Step: 11
Training loss: 0.35144710540771484
Validation loss: 1.8965986271699269

Epoch: 413| Step: 0
Training loss: 0.8306320905685425
Validation loss: 1.8992582609256108

Epoch: 5| Step: 1
Training loss: 0.3413088321685791
Validation loss: 1.87846939265728

Epoch: 5| Step: 2
Training loss: 0.3421739935874939
Validation loss: 1.8922254741191864

Epoch: 5| Step: 3
Training loss: 0.20690755546092987
Validation loss: 1.8500609298547108

Epoch: 5| Step: 4
Training loss: 0.24364285171031952
Validation loss: 1.9016868124405544

Epoch: 5| Step: 5
Training loss: 0.2975700795650482
Validation loss: 1.9162277281284332

Epoch: 5| Step: 6
Training loss: 0.2554587423801422
Validation loss: 1.9595321863889694

Epoch: 5| Step: 7
Training loss: 0.2993285059928894
Validation loss: 1.959714745481809

Epoch: 5| Step: 8
Training loss: 0.19796697795391083
Validation loss: 1.9415281514326732

Epoch: 5| Step: 9
Training loss: 0.2494608610868454
Validation loss: 1.9112273305654526

Epoch: 5| Step: 10
Training loss: 0.42579641938209534
Validation loss: 1.8970097104708354

Epoch: 5| Step: 11
Training loss: 0.38435834646224976
Validation loss: 1.9220169881979625

Epoch: 414| Step: 0
Training loss: 0.29149848222732544
Validation loss: 1.899121751387914

Epoch: 5| Step: 1
Training loss: 0.33411768078804016
Validation loss: 1.9077302316824596

Epoch: 5| Step: 2
Training loss: 0.38834547996520996
Validation loss: 1.8933508843183517

Epoch: 5| Step: 3
Training loss: 0.35469508171081543
Validation loss: 1.9757483353217442

Epoch: 5| Step: 4
Training loss: 0.20646846294403076
Validation loss: 1.9488601982593536

Epoch: 5| Step: 5
Training loss: 0.5052392482757568
Validation loss: 1.9188694059848785

Epoch: 5| Step: 6
Training loss: 0.22276639938354492
Validation loss: 1.9942507992188137

Epoch: 5| Step: 7
Training loss: 0.2323889285326004
Validation loss: 1.925122156739235

Epoch: 5| Step: 8
Training loss: 0.305427610874176
Validation loss: 1.9670896132787068

Epoch: 5| Step: 9
Training loss: 0.4459559917449951
Validation loss: 1.9134381512800853

Epoch: 5| Step: 10
Training loss: 0.24962329864501953
Validation loss: 1.9039052973190944

Epoch: 5| Step: 11
Training loss: 0.19138552248477936
Validation loss: 1.8971422463655472

Epoch: 415| Step: 0
Training loss: 0.18737128376960754
Validation loss: 1.934950644771258

Epoch: 5| Step: 1
Training loss: 0.31079480051994324
Validation loss: 1.923515111207962

Epoch: 5| Step: 2
Training loss: 0.22660835087299347
Validation loss: 1.95767746369044

Epoch: 5| Step: 3
Training loss: 0.2663607597351074
Validation loss: 1.9582075774669647

Epoch: 5| Step: 4
Training loss: 0.24152818322181702
Validation loss: 1.8985769500335057

Epoch: 5| Step: 5
Training loss: 0.31064489483833313
Validation loss: 1.8512335916360219

Epoch: 5| Step: 6
Training loss: 0.6159632205963135
Validation loss: 1.8757457335789998

Epoch: 5| Step: 7
Training loss: 0.29842692613601685
Validation loss: 1.912199338277181

Epoch: 5| Step: 8
Training loss: 0.420992374420166
Validation loss: 1.8600000987450283

Epoch: 5| Step: 9
Training loss: 0.19494767487049103
Validation loss: 1.8865908583005269

Epoch: 5| Step: 10
Training loss: 0.2273683249950409
Validation loss: 1.8806422501802444

Epoch: 5| Step: 11
Training loss: 0.47689926624298096
Validation loss: 1.8764590322971344

Epoch: 416| Step: 0
Training loss: 0.20625579357147217
Validation loss: 1.8662133465210597

Epoch: 5| Step: 1
Training loss: 0.3247537910938263
Validation loss: 1.9220126668612163

Epoch: 5| Step: 2
Training loss: 0.23338821530342102
Validation loss: 1.877165401975314

Epoch: 5| Step: 3
Training loss: 0.6903817057609558
Validation loss: 1.8863351543744404

Epoch: 5| Step: 4
Training loss: 0.3276747763156891
Validation loss: 1.9364041934410732

Epoch: 5| Step: 5
Training loss: 0.21541185677051544
Validation loss: 1.8888384699821472

Epoch: 5| Step: 6
Training loss: 0.3599873185157776
Validation loss: 1.922078788280487

Epoch: 5| Step: 7
Training loss: 0.2620188295841217
Validation loss: 1.9013647586107254

Epoch: 5| Step: 8
Training loss: 0.24253392219543457
Validation loss: 1.9415604571501415

Epoch: 5| Step: 9
Training loss: 0.2739954888820648
Validation loss: 1.9226533969243367

Epoch: 5| Step: 10
Training loss: 0.41228580474853516
Validation loss: 1.9389532456795375

Epoch: 5| Step: 11
Training loss: 0.3791401982307434
Validation loss: 1.8740304162104924

Epoch: 417| Step: 0
Training loss: 0.3444809317588806
Validation loss: 1.8583241254091263

Epoch: 5| Step: 1
Training loss: 0.5861336588859558
Validation loss: 1.9285150518019993

Epoch: 5| Step: 2
Training loss: 0.24167028069496155
Validation loss: 1.921945075194041

Epoch: 5| Step: 3
Training loss: 0.27678191661834717
Validation loss: 1.8943077971537907

Epoch: 5| Step: 4
Training loss: 0.4645657539367676
Validation loss: 1.9179740448792775

Epoch: 5| Step: 5
Training loss: 0.5620967745780945
Validation loss: 1.9021327296892803

Epoch: 5| Step: 6
Training loss: 0.30138298869132996
Validation loss: 1.9044069002072017

Epoch: 5| Step: 7
Training loss: 0.12281757593154907
Validation loss: 1.9184520343939464

Epoch: 5| Step: 8
Training loss: 0.18226344883441925
Validation loss: 1.9326142519712448

Epoch: 5| Step: 9
Training loss: 0.2861785888671875
Validation loss: 1.8787192503611247

Epoch: 5| Step: 10
Training loss: 0.37359774112701416
Validation loss: 1.8872759193181992

Epoch: 5| Step: 11
Training loss: 0.22158944606781006
Validation loss: 1.8770727415879567

Epoch: 418| Step: 0
Training loss: 0.2761705815792084
Validation loss: 1.9164536545674007

Epoch: 5| Step: 1
Training loss: 0.507099986076355
Validation loss: 1.9100700716177623

Epoch: 5| Step: 2
Training loss: 0.3055405914783478
Validation loss: 1.9159231583277385

Epoch: 5| Step: 3
Training loss: 0.46378153562545776
Validation loss: 1.8844364980856578

Epoch: 5| Step: 4
Training loss: 0.33925849199295044
Validation loss: 1.9314781824747722

Epoch: 5| Step: 5
Training loss: 0.3054026663303375
Validation loss: 1.930643344918887

Epoch: 5| Step: 6
Training loss: 0.33262476325035095
Validation loss: 1.8729032973448436

Epoch: 5| Step: 7
Training loss: 0.5425342321395874
Validation loss: 1.9074759880701702

Epoch: 5| Step: 8
Training loss: 0.2990071177482605
Validation loss: 1.8153116355339687

Epoch: 5| Step: 9
Training loss: 0.3073025047779083
Validation loss: 1.8720811903476715

Epoch: 5| Step: 10
Training loss: 0.19720283150672913
Validation loss: 1.8783996154864628

Epoch: 5| Step: 11
Training loss: 0.22781667113304138
Validation loss: 1.8833205004533131

Epoch: 419| Step: 0
Training loss: 0.23394262790679932
Validation loss: 1.928846036394437

Epoch: 5| Step: 1
Training loss: 0.28450775146484375
Validation loss: 1.8719308972358704

Epoch: 5| Step: 2
Training loss: 0.1865900307893753
Validation loss: 1.8984426806370418

Epoch: 5| Step: 3
Training loss: 0.31331244111061096
Validation loss: 1.8985062042872112

Epoch: 5| Step: 4
Training loss: 0.2861298620700836
Validation loss: 1.9718229174613953

Epoch: 5| Step: 5
Training loss: 0.37048888206481934
Validation loss: 1.965588167309761

Epoch: 5| Step: 6
Training loss: 0.24104702472686768
Validation loss: 1.903615449865659

Epoch: 5| Step: 7
Training loss: 0.2958180010318756
Validation loss: 1.9018757690985997

Epoch: 5| Step: 8
Training loss: 0.6677154302597046
Validation loss: 1.8610180070002873

Epoch: 5| Step: 9
Training loss: 0.276445597410202
Validation loss: 1.867681200305621

Epoch: 5| Step: 10
Training loss: 0.2725694179534912
Validation loss: 1.936357895533244

Epoch: 5| Step: 11
Training loss: 0.9177238345146179
Validation loss: 1.9267509480317433

Epoch: 420| Step: 0
Training loss: 0.18016135692596436
Validation loss: 1.8853471328814824

Epoch: 5| Step: 1
Training loss: 0.17445345222949982
Validation loss: 1.9379282544056575

Epoch: 5| Step: 2
Training loss: 0.23553583025932312
Validation loss: 1.9620060622692108

Epoch: 5| Step: 3
Training loss: 0.2640020549297333
Validation loss: 1.9333606610695522

Epoch: 5| Step: 4
Training loss: 0.18212644755840302
Validation loss: 1.9209295163551967

Epoch: 5| Step: 5
Training loss: 0.3283323645591736
Validation loss: 1.9538850635290146

Epoch: 5| Step: 6
Training loss: 0.35489219427108765
Validation loss: 1.8906097461779912

Epoch: 5| Step: 7
Training loss: 0.1577417552471161
Validation loss: 1.941877285639445

Epoch: 5| Step: 8
Training loss: 0.7572082281112671
Validation loss: 1.898760010798772

Epoch: 5| Step: 9
Training loss: 0.29793304204940796
Validation loss: 1.928163434068362

Epoch: 5| Step: 10
Training loss: 0.3870214819908142
Validation loss: 1.9193441371122997

Epoch: 5| Step: 11
Training loss: 0.6347607970237732
Validation loss: 1.892730842034022

Epoch: 421| Step: 0
Training loss: 0.6587706804275513
Validation loss: 1.8991460005442302

Epoch: 5| Step: 1
Training loss: 0.27935105562210083
Validation loss: 1.8777121404806774

Epoch: 5| Step: 2
Training loss: 0.15930354595184326
Validation loss: 1.9279677718877792

Epoch: 5| Step: 3
Training loss: 0.3973534107208252
Validation loss: 1.8721379141012828

Epoch: 5| Step: 4
Training loss: 0.30997389554977417
Validation loss: 1.9062789032856624

Epoch: 5| Step: 5
Training loss: 0.16551242768764496
Validation loss: 1.895385354757309

Epoch: 5| Step: 6
Training loss: 0.2377282828092575
Validation loss: 1.9657131334145863

Epoch: 5| Step: 7
Training loss: 0.36364930868148804
Validation loss: 1.9834422667821248

Epoch: 5| Step: 8
Training loss: 0.1989130675792694
Validation loss: 1.9123122195402782

Epoch: 5| Step: 9
Training loss: 0.31795740127563477
Validation loss: 1.896245871980985

Epoch: 5| Step: 10
Training loss: 0.22033004462718964
Validation loss: 1.8620749761660893

Epoch: 5| Step: 11
Training loss: 0.20555773377418518
Validation loss: 1.8609329809745152

Epoch: 422| Step: 0
Training loss: 0.16676560044288635
Validation loss: 1.9076812416315079

Epoch: 5| Step: 1
Training loss: 0.13297827541828156
Validation loss: 1.9159313291311264

Epoch: 5| Step: 2
Training loss: 0.6077431440353394
Validation loss: 1.8986123005549114

Epoch: 5| Step: 3
Training loss: 0.35112467408180237
Validation loss: 1.9234287639458973

Epoch: 5| Step: 4
Training loss: 0.3885636031627655
Validation loss: 1.9008562862873077

Epoch: 5| Step: 5
Training loss: 0.24252064526081085
Validation loss: 1.8937772115071614

Epoch: 5| Step: 6
Training loss: 0.19815415143966675
Validation loss: 1.8953162183364232

Epoch: 5| Step: 7
Training loss: 0.18416567146778107
Validation loss: 1.8321359753608704

Epoch: 5| Step: 8
Training loss: 0.4333104193210602
Validation loss: 1.8418164253234863

Epoch: 5| Step: 9
Training loss: 0.2416350543498993
Validation loss: 1.9008088062206905

Epoch: 5| Step: 10
Training loss: 0.40089544653892517
Validation loss: 1.8713377316792805

Epoch: 5| Step: 11
Training loss: 0.28317874670028687
Validation loss: 1.8915050675471623

Epoch: 423| Step: 0
Training loss: 0.28503575921058655
Validation loss: 1.8791883339484532

Epoch: 5| Step: 1
Training loss: 0.19989430904388428
Validation loss: 1.8692265550295513

Epoch: 5| Step: 2
Training loss: 0.4367710053920746
Validation loss: 1.9173436711231868

Epoch: 5| Step: 3
Training loss: 0.5773768424987793
Validation loss: 1.8811671485503514

Epoch: 5| Step: 4
Training loss: 0.21751590073108673
Validation loss: 1.8711890031894047

Epoch: 5| Step: 5
Training loss: 0.1552583873271942
Validation loss: 1.883048802614212

Epoch: 5| Step: 6
Training loss: 0.17283804714679718
Validation loss: 1.9214025686184566

Epoch: 5| Step: 7
Training loss: 0.21438750624656677
Validation loss: 1.8901242017745972

Epoch: 5| Step: 8
Training loss: 0.24948322772979736
Validation loss: 1.9577031284570694

Epoch: 5| Step: 9
Training loss: 0.31353825330734253
Validation loss: 1.9375221977631252

Epoch: 5| Step: 10
Training loss: 0.3952605724334717
Validation loss: 1.920992503563563

Epoch: 5| Step: 11
Training loss: 0.17847120761871338
Validation loss: 1.9571714848279953

Epoch: 424| Step: 0
Training loss: 0.12356722354888916
Validation loss: 1.8645051370064418

Epoch: 5| Step: 1
Training loss: 0.3519945740699768
Validation loss: 1.9255320976177852

Epoch: 5| Step: 2
Training loss: 0.3884356617927551
Validation loss: 1.909180223941803

Epoch: 5| Step: 3
Training loss: 0.6645895838737488
Validation loss: 1.8904835681120555

Epoch: 5| Step: 4
Training loss: 0.5219941139221191
Validation loss: 1.9114601413408916

Epoch: 5| Step: 5
Training loss: 0.3330334722995758
Validation loss: 1.8913687666257222

Epoch: 5| Step: 6
Training loss: 0.1650921106338501
Validation loss: 1.9354202101627986

Epoch: 5| Step: 7
Training loss: 0.3063792586326599
Validation loss: 1.9724875489870708

Epoch: 5| Step: 8
Training loss: 0.3309116065502167
Validation loss: 1.956414520740509

Epoch: 5| Step: 9
Training loss: 0.22536568343639374
Validation loss: 1.959184616804123

Epoch: 5| Step: 10
Training loss: 0.2632017135620117
Validation loss: 1.940411185224851

Epoch: 5| Step: 11
Training loss: 0.33571362495422363
Validation loss: 1.956344947218895

Epoch: 425| Step: 0
Training loss: 0.31022199988365173
Validation loss: 1.8793942282597225

Epoch: 5| Step: 1
Training loss: 0.1878904104232788
Validation loss: 1.8693091322978337

Epoch: 5| Step: 2
Training loss: 0.35571420192718506
Validation loss: 1.8933512220780055

Epoch: 5| Step: 3
Training loss: 0.3235464096069336
Validation loss: 1.9048195133606594

Epoch: 5| Step: 4
Training loss: 0.45828962326049805
Validation loss: 1.8961017231146495

Epoch: 5| Step: 5
Training loss: 0.3252207338809967
Validation loss: 1.9098355273405712

Epoch: 5| Step: 6
Training loss: 0.13477177917957306
Validation loss: 1.8770613571008046

Epoch: 5| Step: 7
Training loss: 0.12907668948173523
Validation loss: 1.9435904026031494

Epoch: 5| Step: 8
Training loss: 0.6058720350265503
Validation loss: 1.8665060698986053

Epoch: 5| Step: 9
Training loss: 0.2886509895324707
Validation loss: 1.9458810240030289

Epoch: 5| Step: 10
Training loss: 0.3178041875362396
Validation loss: 1.915394405523936

Epoch: 5| Step: 11
Training loss: 0.3865789473056793
Validation loss: 1.9464817146460216

Epoch: 426| Step: 0
Training loss: 0.2995036840438843
Validation loss: 1.8984404454628627

Epoch: 5| Step: 1
Training loss: 0.3578152060508728
Validation loss: 1.8706460396448772

Epoch: 5| Step: 2
Training loss: 0.6266082525253296
Validation loss: 1.9143657733996708

Epoch: 5| Step: 3
Training loss: 0.32989510893821716
Validation loss: 1.8727896114190419

Epoch: 5| Step: 4
Training loss: 0.35224246978759766
Validation loss: 1.8827908784151077

Epoch: 5| Step: 5
Training loss: 0.21885311603546143
Validation loss: 1.8657088925441105

Epoch: 5| Step: 6
Training loss: 0.2014487236738205
Validation loss: 1.8792353719472885

Epoch: 5| Step: 7
Training loss: 0.3787304759025574
Validation loss: 1.9197383572657902

Epoch: 5| Step: 8
Training loss: 0.32667601108551025
Validation loss: 1.9633807986974716

Epoch: 5| Step: 9
Training loss: 0.6255220174789429
Validation loss: 1.8984575768311818

Epoch: 5| Step: 10
Training loss: 0.23663075268268585
Validation loss: 1.878026083111763

Epoch: 5| Step: 11
Training loss: 0.35420265793800354
Validation loss: 1.9185033937295277

Epoch: 427| Step: 0
Training loss: 0.3482980728149414
Validation loss: 1.8510585923989613

Epoch: 5| Step: 1
Training loss: 0.23394231498241425
Validation loss: 1.9026463826497395

Epoch: 5| Step: 2
Training loss: 0.7168157696723938
Validation loss: 1.8903214434782665

Epoch: 5| Step: 3
Training loss: 0.2841319739818573
Validation loss: 1.9088422457377117

Epoch: 5| Step: 4
Training loss: 0.2536793649196625
Validation loss: 1.9162789682547252

Epoch: 5| Step: 5
Training loss: 0.23335818946361542
Validation loss: 1.9072924951712291

Epoch: 5| Step: 6
Training loss: 0.3436984717845917
Validation loss: 1.9050445506970088

Epoch: 5| Step: 7
Training loss: 0.30253884196281433
Validation loss: 1.931470309694608

Epoch: 5| Step: 8
Training loss: 0.3382943272590637
Validation loss: 1.918766900897026

Epoch: 5| Step: 9
Training loss: 0.17349910736083984
Validation loss: 1.9093289623657863

Epoch: 5| Step: 10
Training loss: 0.46086806058883667
Validation loss: 1.9101694921652477

Epoch: 5| Step: 11
Training loss: 0.15721267461776733
Validation loss: 1.8851244747638702

Epoch: 428| Step: 0
Training loss: 0.23373493552207947
Validation loss: 1.8589024792114894

Epoch: 5| Step: 1
Training loss: 0.26768821477890015
Validation loss: 1.8901516894499462

Epoch: 5| Step: 2
Training loss: 0.2031921148300171
Validation loss: 1.902284026145935

Epoch: 5| Step: 3
Training loss: 0.2531155049800873
Validation loss: 1.8943313360214233

Epoch: 5| Step: 4
Training loss: 0.22992029786109924
Validation loss: 1.8665506392717361

Epoch: 5| Step: 5
Training loss: 0.5979400873184204
Validation loss: 1.9057104339202244

Epoch: 5| Step: 6
Training loss: 0.2561361789703369
Validation loss: 1.928476557135582

Epoch: 5| Step: 7
Training loss: 0.35565662384033203
Validation loss: 1.9003494828939438

Epoch: 5| Step: 8
Training loss: 0.2891407310962677
Validation loss: 1.894114926457405

Epoch: 5| Step: 9
Training loss: 0.5344735980033875
Validation loss: 1.8953061699867249

Epoch: 5| Step: 10
Training loss: 0.23749661445617676
Validation loss: 1.8783213595549266

Epoch: 5| Step: 11
Training loss: 0.14069688320159912
Validation loss: 1.9039919873078663

Epoch: 429| Step: 0
Training loss: 0.2507506310939789
Validation loss: 1.9386436243851979

Epoch: 5| Step: 1
Training loss: 0.18395856022834778
Validation loss: 1.9290128350257874

Epoch: 5| Step: 2
Training loss: 0.22950749099254608
Validation loss: 1.95054329931736

Epoch: 5| Step: 3
Training loss: 0.27100247144699097
Validation loss: 1.8805590917666752

Epoch: 5| Step: 4
Training loss: 0.40785226225852966
Validation loss: 1.895635187625885

Epoch: 5| Step: 5
Training loss: 0.3449780344963074
Validation loss: 1.8731437921524048

Epoch: 5| Step: 6
Training loss: 0.23783163726329803
Validation loss: 1.884318898121516

Epoch: 5| Step: 7
Training loss: 0.25641122460365295
Validation loss: 1.8881918241580327

Epoch: 5| Step: 8
Training loss: 0.23002676665782928
Validation loss: 1.8340223679939907

Epoch: 5| Step: 9
Training loss: 0.24984058737754822
Validation loss: 1.8946150888999302

Epoch: 5| Step: 10
Training loss: 0.5542601943016052
Validation loss: 1.868471657236417

Epoch: 5| Step: 11
Training loss: 1.8610997200012207
Validation loss: 1.8416316211223602

Epoch: 430| Step: 0
Training loss: 0.35372471809387207
Validation loss: 1.9121013383070629

Epoch: 5| Step: 1
Training loss: 0.1669943630695343
Validation loss: 1.897022659579913

Epoch: 5| Step: 2
Training loss: 0.15102654695510864
Validation loss: 1.908582533399264

Epoch: 5| Step: 3
Training loss: 0.35747164487838745
Validation loss: 1.9033319900433223

Epoch: 5| Step: 4
Training loss: 0.23953524231910706
Validation loss: 1.8753703733285267

Epoch: 5| Step: 5
Training loss: 0.6099270582199097
Validation loss: 1.8754491806030273

Epoch: 5| Step: 6
Training loss: 0.26516062021255493
Validation loss: 1.8710420380036037

Epoch: 5| Step: 7
Training loss: 0.2981939911842346
Validation loss: 1.8797980844974518

Epoch: 5| Step: 8
Training loss: 0.3160487413406372
Validation loss: 1.913059671719869

Epoch: 5| Step: 9
Training loss: 0.20947441458702087
Validation loss: 1.9211744368076324

Epoch: 5| Step: 10
Training loss: 0.33712905645370483
Validation loss: 1.8875249177217484

Epoch: 5| Step: 11
Training loss: 0.30847012996673584
Validation loss: 1.9091685364643733

Epoch: 431| Step: 0
Training loss: 0.26655250787734985
Validation loss: 1.902286966641744

Epoch: 5| Step: 1
Training loss: 0.2439817488193512
Validation loss: 1.8819529960552852

Epoch: 5| Step: 2
Training loss: 0.2036483734846115
Validation loss: 1.890460878610611

Epoch: 5| Step: 3
Training loss: 0.35319414734840393
Validation loss: 1.8577498942613602

Epoch: 5| Step: 4
Training loss: 0.23516082763671875
Validation loss: 1.8810851126909256

Epoch: 5| Step: 5
Training loss: 0.2738243639469147
Validation loss: 1.8701884498198826

Epoch: 5| Step: 6
Training loss: 0.37409669160842896
Validation loss: 1.8738495359818141

Epoch: 5| Step: 7
Training loss: 0.22573938965797424
Validation loss: 1.8920435359080632

Epoch: 5| Step: 8
Training loss: 0.6427929997444153
Validation loss: 1.8891762097676594

Epoch: 5| Step: 9
Training loss: 0.5291645526885986
Validation loss: 1.8551258742809296

Epoch: 5| Step: 10
Training loss: 0.2229485958814621
Validation loss: 1.9002482046683629

Epoch: 5| Step: 11
Training loss: 0.2061983346939087
Validation loss: 1.904434969027837

Epoch: 432| Step: 0
Training loss: 0.21344760060310364
Validation loss: 1.9229831447203953

Epoch: 5| Step: 1
Training loss: 0.38069120049476624
Validation loss: 1.924504945675532

Epoch: 5| Step: 2
Training loss: 0.4339027404785156
Validation loss: 1.956765428185463

Epoch: 5| Step: 3
Training loss: 0.4557245671749115
Validation loss: 1.9278051406145096

Epoch: 5| Step: 4
Training loss: 0.2968774437904358
Validation loss: 1.9445490340391796

Epoch: 5| Step: 5
Training loss: 0.2015247642993927
Validation loss: 1.9186988075574238

Epoch: 5| Step: 6
Training loss: 0.24265456199645996
Validation loss: 1.9048651854197185

Epoch: 5| Step: 7
Training loss: 0.3104477524757385
Validation loss: 1.8769425302743912

Epoch: 5| Step: 8
Training loss: 0.31880834698677063
Validation loss: 1.9187826911608379

Epoch: 5| Step: 9
Training loss: 0.5751981139183044
Validation loss: 1.9075487703084946

Epoch: 5| Step: 10
Training loss: 0.3220078647136688
Validation loss: 1.897856131196022

Epoch: 5| Step: 11
Training loss: 0.5077974796295166
Validation loss: 1.9550689160823822

Epoch: 433| Step: 0
Training loss: 0.43432217836380005
Validation loss: 1.9901851614316304

Epoch: 5| Step: 1
Training loss: 0.37785401940345764
Validation loss: 1.9806579301754634

Epoch: 5| Step: 2
Training loss: 0.5213481783866882
Validation loss: 2.002634108066559

Epoch: 5| Step: 3
Training loss: 0.4202860891819
Validation loss: 1.9339500864346821

Epoch: 5| Step: 4
Training loss: 0.2722803056240082
Validation loss: 1.9234779824813206

Epoch: 5| Step: 5
Training loss: 0.7251635789871216
Validation loss: 1.921408732732137

Epoch: 5| Step: 6
Training loss: 0.34965214133262634
Validation loss: 1.9284754196802776

Epoch: 5| Step: 7
Training loss: 0.35533881187438965
Validation loss: 1.8755961706240971

Epoch: 5| Step: 8
Training loss: 0.35142335295677185
Validation loss: 1.8650194803873699

Epoch: 5| Step: 9
Training loss: 0.5346566438674927
Validation loss: 1.9098236958185832

Epoch: 5| Step: 10
Training loss: 0.2073984146118164
Validation loss: 1.90257228910923

Epoch: 5| Step: 11
Training loss: 0.30802908539772034
Validation loss: 1.9212504029273987

Epoch: 434| Step: 0
Training loss: 0.39697304368019104
Validation loss: 1.973885143796603

Epoch: 5| Step: 1
Training loss: 0.7364026308059692
Validation loss: 1.9741467485825221

Epoch: 5| Step: 2
Training loss: 0.4445745348930359
Validation loss: 1.9875321586926777

Epoch: 5| Step: 3
Training loss: 0.31378045678138733
Validation loss: 1.9027601182460785

Epoch: 5| Step: 4
Training loss: 0.192305326461792
Validation loss: 1.9173547476530075

Epoch: 5| Step: 5
Training loss: 0.2589341402053833
Validation loss: 1.9036258657773335

Epoch: 5| Step: 6
Training loss: 0.31172770261764526
Validation loss: 1.893619919816653

Epoch: 5| Step: 7
Training loss: 0.22214901447296143
Validation loss: 1.9097117185592651

Epoch: 5| Step: 8
Training loss: 0.3687341511249542
Validation loss: 1.8812376459439595

Epoch: 5| Step: 9
Training loss: 0.2545619606971741
Validation loss: 1.8973813901344936

Epoch: 5| Step: 10
Training loss: 0.38859397172927856
Validation loss: 1.9221422175566356

Epoch: 5| Step: 11
Training loss: 0.2290879189968109
Validation loss: 1.9551986157894135

Epoch: 435| Step: 0
Training loss: 0.33972033858299255
Validation loss: 2.000201786557833

Epoch: 5| Step: 1
Training loss: 0.5197867155075073
Validation loss: 2.0395737985769906

Epoch: 5| Step: 2
Training loss: 0.7615295648574829
Validation loss: 1.9554582387208939

Epoch: 5| Step: 3
Training loss: 0.46888431906700134
Validation loss: 1.9253272314866383

Epoch: 5| Step: 4
Training loss: 0.18560931086540222
Validation loss: 1.9072540154059727

Epoch: 5| Step: 5
Training loss: 0.23170307278633118
Validation loss: 1.846969649195671

Epoch: 5| Step: 6
Training loss: 0.3509494364261627
Validation loss: 1.8895597209533055

Epoch: 5| Step: 7
Training loss: 0.3171718716621399
Validation loss: 1.8676747381687164

Epoch: 5| Step: 8
Training loss: 0.3813611567020416
Validation loss: 1.871173471212387

Epoch: 5| Step: 9
Training loss: 0.2785169184207916
Validation loss: 1.8911036054293315

Epoch: 5| Step: 10
Training loss: 0.18940772116184235
Validation loss: 1.900732045372327

Epoch: 5| Step: 11
Training loss: 0.1390455961227417
Validation loss: 1.8726783245801926

Epoch: 436| Step: 0
Training loss: 0.20323018729686737
Validation loss: 1.9246472716331482

Epoch: 5| Step: 1
Training loss: 0.4675544202327728
Validation loss: 1.9020299315452576

Epoch: 5| Step: 2
Training loss: 0.3299093246459961
Validation loss: 1.9079582144816716

Epoch: 5| Step: 3
Training loss: 0.25544190406799316
Validation loss: 1.9111042817433674

Epoch: 5| Step: 4
Training loss: 0.6168612241744995
Validation loss: 1.9270132978757222

Epoch: 5| Step: 5
Training loss: 0.3152388632297516
Validation loss: 1.870321402947108

Epoch: 5| Step: 6
Training loss: 0.4358174204826355
Validation loss: 1.8822811742623646

Epoch: 5| Step: 7
Training loss: 0.34597960114479065
Validation loss: 1.8970878074566524

Epoch: 5| Step: 8
Training loss: 0.42209988832473755
Validation loss: 1.8641012609004974

Epoch: 5| Step: 9
Training loss: 0.2263106405735016
Validation loss: 1.8550552477439244

Epoch: 5| Step: 10
Training loss: 0.18796217441558838
Validation loss: 1.9323895474274952

Epoch: 5| Step: 11
Training loss: 0.32037246227264404
Validation loss: 1.8881368885437648

Epoch: 437| Step: 0
Training loss: 0.3399662971496582
Validation loss: 1.956618403395017

Epoch: 5| Step: 1
Training loss: 0.6003042459487915
Validation loss: 1.9270627250274022

Epoch: 5| Step: 2
Training loss: 0.24652156233787537
Validation loss: 1.9127811640501022

Epoch: 5| Step: 3
Training loss: 0.2512819766998291
Validation loss: 1.9228163709243138

Epoch: 5| Step: 4
Training loss: 0.31758564710617065
Validation loss: 1.914547175168991

Epoch: 5| Step: 5
Training loss: 0.2748905420303345
Validation loss: 1.922785406311353

Epoch: 5| Step: 6
Training loss: 0.23117241263389587
Validation loss: 1.9149348139762878

Epoch: 5| Step: 7
Training loss: 0.2921290397644043
Validation loss: 1.9097871482372284

Epoch: 5| Step: 8
Training loss: 0.25918853282928467
Validation loss: 1.9186525444189708

Epoch: 5| Step: 9
Training loss: 0.40029969811439514
Validation loss: 1.9327342957258224

Epoch: 5| Step: 10
Training loss: 0.2653563618659973
Validation loss: 1.914808914065361

Epoch: 5| Step: 11
Training loss: 0.3680883049964905
Validation loss: 1.9409095446268718

Epoch: 438| Step: 0
Training loss: 0.1857505738735199
Validation loss: 1.924741268157959

Epoch: 5| Step: 1
Training loss: 0.20888511836528778
Validation loss: 1.9184478372335434

Epoch: 5| Step: 2
Training loss: 0.2535918951034546
Validation loss: 1.919939438501994

Epoch: 5| Step: 3
Training loss: 0.3646296560764313
Validation loss: 1.90840079387029

Epoch: 5| Step: 4
Training loss: 0.2535478472709656
Validation loss: 1.9120509549975395

Epoch: 5| Step: 5
Training loss: 0.6933199763298035
Validation loss: 1.9021290391683578

Epoch: 5| Step: 6
Training loss: 0.2635704576969147
Validation loss: 1.9310346394777298

Epoch: 5| Step: 7
Training loss: 0.3787173628807068
Validation loss: 1.9228991568088531

Epoch: 5| Step: 8
Training loss: 0.23500171303749084
Validation loss: 1.8977851023276646

Epoch: 5| Step: 9
Training loss: 0.26157885789871216
Validation loss: 1.906452347834905

Epoch: 5| Step: 10
Training loss: 0.32556766271591187
Validation loss: 1.8991086781024933

Epoch: 5| Step: 11
Training loss: 0.5470203161239624
Validation loss: 1.9063087950150173

Epoch: 439| Step: 0
Training loss: 0.14602132141590118
Validation loss: 1.9295048713684082

Epoch: 5| Step: 1
Training loss: 0.38188809156417847
Validation loss: 1.8968885838985443

Epoch: 5| Step: 2
Training loss: 0.3419637084007263
Validation loss: 1.9019715040922165

Epoch: 5| Step: 3
Training loss: 0.2691359519958496
Validation loss: 1.890110323826472

Epoch: 5| Step: 4
Training loss: 0.159047931432724
Validation loss: 1.882009153564771

Epoch: 5| Step: 5
Training loss: 0.37312784790992737
Validation loss: 1.8619775374730427

Epoch: 5| Step: 6
Training loss: 0.17454521358013153
Validation loss: 1.8859286208947499

Epoch: 5| Step: 7
Training loss: 0.20363254845142365
Validation loss: 1.892354850967725

Epoch: 5| Step: 8
Training loss: 0.614693820476532
Validation loss: 1.8737598558266957

Epoch: 5| Step: 9
Training loss: 0.2828983664512634
Validation loss: 1.9204857051372528

Epoch: 5| Step: 10
Training loss: 0.1696084439754486
Validation loss: 1.8735653162002563

Epoch: 5| Step: 11
Training loss: 0.15064775943756104
Validation loss: 1.8705494503180187

Epoch: 440| Step: 0
Training loss: 0.18447116017341614
Validation loss: 1.8858993351459503

Epoch: 5| Step: 1
Training loss: 0.378911554813385
Validation loss: 1.8940716286500294

Epoch: 5| Step: 2
Training loss: 0.17766642570495605
Validation loss: 1.8786942412455876

Epoch: 5| Step: 3
Training loss: 0.2602098882198334
Validation loss: 1.8695131937662761

Epoch: 5| Step: 4
Training loss: 0.21501056849956512
Validation loss: 1.8747422695159912

Epoch: 5| Step: 5
Training loss: 0.7173582911491394
Validation loss: 1.8745658894379933

Epoch: 5| Step: 6
Training loss: 0.3157626688480377
Validation loss: 1.855371465285619

Epoch: 5| Step: 7
Training loss: 0.24651563167572021
Validation loss: 1.9432084461053212

Epoch: 5| Step: 8
Training loss: 0.3325576186180115
Validation loss: 1.8921805669864018

Epoch: 5| Step: 9
Training loss: 0.16365556418895721
Validation loss: 1.8791522532701492

Epoch: 5| Step: 10
Training loss: 0.17142833769321442
Validation loss: 1.8994833429654439

Epoch: 5| Step: 11
Training loss: 0.2814170718193054
Validation loss: 1.9082555621862411

Epoch: 441| Step: 0
Training loss: 0.564794659614563
Validation loss: 1.899151509006818

Epoch: 5| Step: 1
Training loss: 0.18710055947303772
Validation loss: 1.867773100733757

Epoch: 5| Step: 2
Training loss: 0.3283781409263611
Validation loss: 1.8721438149611156

Epoch: 5| Step: 3
Training loss: 0.2717309594154358
Validation loss: 1.9096944133440654

Epoch: 5| Step: 4
Training loss: 0.2566041350364685
Validation loss: 1.881787121295929

Epoch: 5| Step: 5
Training loss: 0.38988345861434937
Validation loss: 1.9350822220245998

Epoch: 5| Step: 6
Training loss: 0.16854748129844666
Validation loss: 1.9421268105506897

Epoch: 5| Step: 7
Training loss: 0.30340510606765747
Validation loss: 1.9562231252590816

Epoch: 5| Step: 8
Training loss: 0.3273831903934479
Validation loss: 1.9980618854363759

Epoch: 5| Step: 9
Training loss: 0.36588507890701294
Validation loss: 1.9358800897995632

Epoch: 5| Step: 10
Training loss: 0.29560619592666626
Validation loss: 1.921561449766159

Epoch: 5| Step: 11
Training loss: 0.11495161056518555
Validation loss: 1.9133633921543758

Epoch: 442| Step: 0
Training loss: 0.7354522347450256
Validation loss: 1.908298298716545

Epoch: 5| Step: 1
Training loss: 0.2588120400905609
Validation loss: 1.8872031817833583

Epoch: 5| Step: 2
Training loss: 0.33705538511276245
Validation loss: 1.8409978200991948

Epoch: 5| Step: 3
Training loss: 0.23251768946647644
Validation loss: 1.9087368994951248

Epoch: 5| Step: 4
Training loss: 0.2904798090457916
Validation loss: 1.8933145602544148

Epoch: 5| Step: 5
Training loss: 0.2626187801361084
Validation loss: 1.911770448088646

Epoch: 5| Step: 6
Training loss: 0.37143129110336304
Validation loss: 1.9255352765321732

Epoch: 5| Step: 7
Training loss: 0.3224703073501587
Validation loss: 1.9684093942244847

Epoch: 5| Step: 8
Training loss: 0.3469880521297455
Validation loss: 1.9320957611004512

Epoch: 5| Step: 9
Training loss: 0.22623410820960999
Validation loss: 1.936417614420255

Epoch: 5| Step: 10
Training loss: 0.20367352664470673
Validation loss: 1.8887252658605576

Epoch: 5| Step: 11
Training loss: 0.22712671756744385
Validation loss: 1.8995464940865834

Epoch: 443| Step: 0
Training loss: 0.38192662596702576
Validation loss: 1.912154624859492

Epoch: 5| Step: 1
Training loss: 0.2826313376426697
Validation loss: 1.85866683224837

Epoch: 5| Step: 2
Training loss: 0.19734881818294525
Validation loss: 1.8821158905824025

Epoch: 5| Step: 3
Training loss: 0.6014968156814575
Validation loss: 1.8912157317002614

Epoch: 5| Step: 4
Training loss: 0.2684110701084137
Validation loss: 1.9125403662522633

Epoch: 5| Step: 5
Training loss: 0.3437155783176422
Validation loss: 1.9169441213210423

Epoch: 5| Step: 6
Training loss: 0.23972992599010468
Validation loss: 1.9226507047812145

Epoch: 5| Step: 7
Training loss: 0.18700163066387177
Validation loss: 1.83552186191082

Epoch: 5| Step: 8
Training loss: 0.48521462082862854
Validation loss: 1.8700547715028126

Epoch: 5| Step: 9
Training loss: 0.23602032661437988
Validation loss: 1.8565128842989604

Epoch: 5| Step: 10
Training loss: 0.33417218923568726
Validation loss: 1.8840392380952835

Epoch: 5| Step: 11
Training loss: 0.4081748425960541
Validation loss: 1.8820307900508244

Epoch: 444| Step: 0
Training loss: 0.2215147465467453
Validation loss: 1.8866758694251378

Epoch: 5| Step: 1
Training loss: 0.2443576604127884
Validation loss: 1.8670014590024948

Epoch: 5| Step: 2
Training loss: 0.371562659740448
Validation loss: 1.8859915484984715

Epoch: 5| Step: 3
Training loss: 0.5793654322624207
Validation loss: 1.864185780286789

Epoch: 5| Step: 4
Training loss: 0.3613661229610443
Validation loss: 1.899059846997261

Epoch: 5| Step: 5
Training loss: 0.26914817094802856
Validation loss: 1.9124168554941814

Epoch: 5| Step: 6
Training loss: 0.22116205096244812
Validation loss: 1.896038442850113

Epoch: 5| Step: 7
Training loss: 0.12929348647594452
Validation loss: 1.885931099454562

Epoch: 5| Step: 8
Training loss: 0.2747485041618347
Validation loss: 1.9134294142325718

Epoch: 5| Step: 9
Training loss: 0.3024609386920929
Validation loss: 1.901371642947197

Epoch: 5| Step: 10
Training loss: 0.2891406714916229
Validation loss: 1.9156710356473923

Epoch: 5| Step: 11
Training loss: 0.24220716953277588
Validation loss: 1.9318150132894516

Epoch: 445| Step: 0
Training loss: 0.21817150712013245
Validation loss: 1.8833374579747517

Epoch: 5| Step: 1
Training loss: 0.26725059747695923
Validation loss: 1.9123632858196895

Epoch: 5| Step: 2
Training loss: 0.3277253210544586
Validation loss: 1.9036015619834263

Epoch: 5| Step: 3
Training loss: 0.47229069471359253
Validation loss: 1.875961810350418

Epoch: 5| Step: 4
Training loss: 0.25791794061660767
Validation loss: 1.9133867820103962

Epoch: 5| Step: 5
Training loss: 0.2708403468132019
Validation loss: 1.8680433928966522

Epoch: 5| Step: 6
Training loss: 0.23588447272777557
Validation loss: 1.9066373159488041

Epoch: 5| Step: 7
Training loss: 0.2759372293949127
Validation loss: 1.888999770085017

Epoch: 5| Step: 8
Training loss: 0.2502745985984802
Validation loss: 1.941210776567459

Epoch: 5| Step: 9
Training loss: 0.4651217460632324
Validation loss: 1.905867005387942

Epoch: 5| Step: 10
Training loss: 0.26605135202407837
Validation loss: 1.9036921262741089

Epoch: 5| Step: 11
Training loss: 0.22785359621047974
Validation loss: 1.896408925453822

Epoch: 446| Step: 0
Training loss: 0.24901866912841797
Validation loss: 1.861923451224963

Epoch: 5| Step: 1
Training loss: 0.20303376019001007
Validation loss: 1.8974956274032593

Epoch: 5| Step: 2
Training loss: 0.4625313878059387
Validation loss: 1.8364810744921367

Epoch: 5| Step: 3
Training loss: 0.2680414617061615
Validation loss: 1.847228412826856

Epoch: 5| Step: 4
Training loss: 0.25922277569770813
Validation loss: 1.8856015354394913

Epoch: 5| Step: 5
Training loss: 0.2942596971988678
Validation loss: 1.9254237363735835

Epoch: 5| Step: 6
Training loss: 0.2755676507949829
Validation loss: 1.841776301463445

Epoch: 5| Step: 7
Training loss: 0.23427990078926086
Validation loss: 1.9000074466069539

Epoch: 5| Step: 8
Training loss: 0.19280986487865448
Validation loss: 1.8995148191849391

Epoch: 5| Step: 9
Training loss: 0.61903315782547
Validation loss: 1.9135164022445679

Epoch: 5| Step: 10
Training loss: 0.2762677073478699
Validation loss: 1.9192242870728176

Epoch: 5| Step: 11
Training loss: 0.14822232723236084
Validation loss: 1.876845548550288

Epoch: 447| Step: 0
Training loss: 0.27966684103012085
Validation loss: 1.9021733303864796

Epoch: 5| Step: 1
Training loss: 0.40241509675979614
Validation loss: 1.955212006966273

Epoch: 5| Step: 2
Training loss: 0.3031954765319824
Validation loss: 1.9029279102881749

Epoch: 5| Step: 3
Training loss: 0.31050628423690796
Validation loss: 1.872834434111913

Epoch: 5| Step: 4
Training loss: 0.17887695133686066
Validation loss: 1.8531696250041325

Epoch: 5| Step: 5
Training loss: 0.21735815703868866
Validation loss: 1.8850352962811787

Epoch: 5| Step: 6
Training loss: 0.3243255615234375
Validation loss: 1.873600423336029

Epoch: 5| Step: 7
Training loss: 0.5495697259902954
Validation loss: 1.8868446002403896

Epoch: 5| Step: 8
Training loss: 0.2860535681247711
Validation loss: 1.85558287302653

Epoch: 5| Step: 9
Training loss: 0.20739150047302246
Validation loss: 1.8875954498847325

Epoch: 5| Step: 10
Training loss: 0.1750824898481369
Validation loss: 1.8850739101568859

Epoch: 5| Step: 11
Training loss: 0.5426599979400635
Validation loss: 1.8618295987447102

Epoch: 448| Step: 0
Training loss: 0.18877097964286804
Validation loss: 1.899418483177821

Epoch: 5| Step: 1
Training loss: 0.18440422415733337
Validation loss: 1.8744391252597172

Epoch: 5| Step: 2
Training loss: 0.27095192670822144
Validation loss: 1.9016446967919667

Epoch: 5| Step: 3
Training loss: 0.4387299120426178
Validation loss: 1.8983056495587032

Epoch: 5| Step: 4
Training loss: 0.3279876410961151
Validation loss: 1.9242897381385167

Epoch: 5| Step: 5
Training loss: 0.526215136051178
Validation loss: 1.9134986251592636

Epoch: 5| Step: 6
Training loss: 0.2781451344490051
Validation loss: 1.9126974046230316

Epoch: 5| Step: 7
Training loss: 0.3022194504737854
Validation loss: 1.892442395289739

Epoch: 5| Step: 8
Training loss: 0.23048821091651917
Validation loss: 1.8953060259421666

Epoch: 5| Step: 9
Training loss: 0.215728759765625
Validation loss: 1.8826968371868134

Epoch: 5| Step: 10
Training loss: 0.27609843015670776
Validation loss: 1.9391682992378871

Epoch: 5| Step: 11
Training loss: 0.22919654846191406
Validation loss: 1.9225957443316777

Epoch: 449| Step: 0
Training loss: 0.314170777797699
Validation loss: 1.9429901838302612

Epoch: 5| Step: 1
Training loss: 0.3462452292442322
Validation loss: 1.938064436117808

Epoch: 5| Step: 2
Training loss: 0.27716270089149475
Validation loss: 1.9332952002684276

Epoch: 5| Step: 3
Training loss: 0.3570381700992584
Validation loss: 1.9035213341315587

Epoch: 5| Step: 4
Training loss: 0.23284168541431427
Validation loss: 1.8984143137931824

Epoch: 5| Step: 5
Training loss: 0.6174927353858948
Validation loss: 1.8740323384602864

Epoch: 5| Step: 6
Training loss: 0.33516573905944824
Validation loss: 1.896401231487592

Epoch: 5| Step: 7
Training loss: 0.4304065704345703
Validation loss: 1.890476460258166

Epoch: 5| Step: 8
Training loss: 0.3556639850139618
Validation loss: 1.8718484093745549

Epoch: 5| Step: 9
Training loss: 0.20381994545459747
Validation loss: 1.9049546122550964

Epoch: 5| Step: 10
Training loss: 0.22404173016548157
Validation loss: 1.8881553659836452

Epoch: 5| Step: 11
Training loss: 0.37627190351486206
Validation loss: 1.9283155649900436

Epoch: 450| Step: 0
Training loss: 0.2920871376991272
Validation loss: 1.948974107702573

Epoch: 5| Step: 1
Training loss: 0.28234148025512695
Validation loss: 1.9230123658974965

Epoch: 5| Step: 2
Training loss: 0.4030025005340576
Validation loss: 1.9100706229607265

Epoch: 5| Step: 3
Training loss: 0.5652433633804321
Validation loss: 1.881958891948064

Epoch: 5| Step: 4
Training loss: 0.21087059378623962
Validation loss: 1.9047066420316696

Epoch: 5| Step: 5
Training loss: 0.2563965916633606
Validation loss: 1.9028980483611424

Epoch: 5| Step: 6
Training loss: 0.32677772641181946
Validation loss: 1.908274382352829

Epoch: 5| Step: 7
Training loss: 0.2299479991197586
Validation loss: 1.9065191249052684

Epoch: 5| Step: 8
Training loss: 0.2195894420146942
Validation loss: 1.896995688478152

Epoch: 5| Step: 9
Training loss: 0.35833996534347534
Validation loss: 1.9249119063218434

Epoch: 5| Step: 10
Training loss: 0.24550780653953552
Validation loss: 1.9195797195037205

Epoch: 5| Step: 11
Training loss: 0.11653244495391846
Validation loss: 1.9015975991884868

Epoch: 451| Step: 0
Training loss: 0.2303096354007721
Validation loss: 1.9407788912455242

Epoch: 5| Step: 1
Training loss: 0.22810029983520508
Validation loss: 1.9062555929025014

Epoch: 5| Step: 2
Training loss: 0.33483970165252686
Validation loss: 1.8837435344854991

Epoch: 5| Step: 3
Training loss: 0.42105960845947266
Validation loss: 1.9063652406136196

Epoch: 5| Step: 4
Training loss: 0.21827447414398193
Validation loss: 1.9109092007080715

Epoch: 5| Step: 5
Training loss: 0.6114517450332642
Validation loss: 1.9249270608027775

Epoch: 5| Step: 6
Training loss: 0.25093749165534973
Validation loss: 1.9362550874551137

Epoch: 5| Step: 7
Training loss: 0.22397324442863464
Validation loss: 1.9351619333028793

Epoch: 5| Step: 8
Training loss: 0.29153430461883545
Validation loss: 1.884374702970187

Epoch: 5| Step: 9
Training loss: 0.3834799826145172
Validation loss: 1.8615757077932358

Epoch: 5| Step: 10
Training loss: 0.26654964685440063
Validation loss: 1.897197296222051

Epoch: 5| Step: 11
Training loss: 0.22150015830993652
Validation loss: 1.8988387783368428

Epoch: 452| Step: 0
Training loss: 0.6506524682044983
Validation loss: 1.8574825624624889

Epoch: 5| Step: 1
Training loss: 0.3108564019203186
Validation loss: 1.8568158497412999

Epoch: 5| Step: 2
Training loss: 0.34808439016342163
Validation loss: 1.8678363809982936

Epoch: 5| Step: 3
Training loss: 0.29328304529190063
Validation loss: 1.8613536308209102

Epoch: 5| Step: 4
Training loss: 0.14376215636730194
Validation loss: 1.89887635409832

Epoch: 5| Step: 5
Training loss: 0.2044866532087326
Validation loss: 1.9003867357969284

Epoch: 5| Step: 6
Training loss: 0.23230206966400146
Validation loss: 1.9093983322381973

Epoch: 5| Step: 7
Training loss: 0.24652104079723358
Validation loss: 1.929090440273285

Epoch: 5| Step: 8
Training loss: 0.22017855942249298
Validation loss: 1.9031963845094044

Epoch: 5| Step: 9
Training loss: 0.2213069200515747
Validation loss: 1.8748298386732738

Epoch: 5| Step: 10
Training loss: 0.24220390617847443
Validation loss: 1.89406252404054

Epoch: 5| Step: 11
Training loss: 0.32425588369369507
Validation loss: 1.88559494415919

Epoch: 453| Step: 0
Training loss: 0.28341346979141235
Validation loss: 1.8440594722827275

Epoch: 5| Step: 1
Training loss: 0.18293340504169464
Validation loss: 1.8918745319048564

Epoch: 5| Step: 2
Training loss: 0.2652140259742737
Validation loss: 1.8782984266678493

Epoch: 5| Step: 3
Training loss: 0.30386561155319214
Validation loss: 1.9745849917332332

Epoch: 5| Step: 4
Training loss: 0.2953556776046753
Validation loss: 1.9253878494103749

Epoch: 5| Step: 5
Training loss: 0.27698031067848206
Validation loss: 1.9457512348890305

Epoch: 5| Step: 6
Training loss: 0.17646551132202148
Validation loss: 1.920364464322726

Epoch: 5| Step: 7
Training loss: 0.3369157910346985
Validation loss: 1.8704883307218552

Epoch: 5| Step: 8
Training loss: 0.26327186822891235
Validation loss: 1.8475874265034993

Epoch: 5| Step: 9
Training loss: 0.8147684335708618
Validation loss: 1.850961501399676

Epoch: 5| Step: 10
Training loss: 0.2642087936401367
Validation loss: 1.897970403234164

Epoch: 5| Step: 11
Training loss: 0.20466157793998718
Validation loss: 1.8674588004748027

Epoch: 454| Step: 0
Training loss: 0.30039510130882263
Validation loss: 1.9183661341667175

Epoch: 5| Step: 1
Training loss: 0.2134782373905182
Validation loss: 1.9010868817567825

Epoch: 5| Step: 2
Training loss: 0.37033796310424805
Validation loss: 1.939037909110387

Epoch: 5| Step: 3
Training loss: 0.38477909564971924
Validation loss: 1.9421369383732479

Epoch: 5| Step: 4
Training loss: 0.24122802913188934
Validation loss: 1.9394625127315521

Epoch: 5| Step: 5
Training loss: 0.8301820755004883
Validation loss: 1.91810242831707

Epoch: 5| Step: 6
Training loss: 0.15387950837612152
Validation loss: 1.863010550538699

Epoch: 5| Step: 7
Training loss: 0.22518274188041687
Validation loss: 1.9209905167420704

Epoch: 5| Step: 8
Training loss: 0.2914424538612366
Validation loss: 1.890699416399002

Epoch: 5| Step: 9
Training loss: 0.3767147362232208
Validation loss: 1.8937590370575588

Epoch: 5| Step: 10
Training loss: 0.27858129143714905
Validation loss: 1.8835168133179347

Epoch: 5| Step: 11
Training loss: 0.15581285953521729
Validation loss: 1.9012422611316044

Epoch: 455| Step: 0
Training loss: 0.2373797446489334
Validation loss: 1.9283306896686554

Epoch: 5| Step: 1
Training loss: 0.18992213904857635
Validation loss: 1.9238225817680359

Epoch: 5| Step: 2
Training loss: 0.22305040061473846
Validation loss: 1.8987643520037334

Epoch: 5| Step: 3
Training loss: 0.3154591917991638
Validation loss: 1.956360290447871

Epoch: 5| Step: 4
Training loss: 0.21082639694213867
Validation loss: 1.9262275298436482

Epoch: 5| Step: 5
Training loss: 0.13962006568908691
Validation loss: 1.8733539233605068

Epoch: 5| Step: 6
Training loss: 0.6156183481216431
Validation loss: 1.8926510214805603

Epoch: 5| Step: 7
Training loss: 0.4115537106990814
Validation loss: 1.8593389342228572

Epoch: 5| Step: 8
Training loss: 0.40692147612571716
Validation loss: 1.875708336631457

Epoch: 5| Step: 9
Training loss: 0.26972541213035583
Validation loss: 1.8727622429529827

Epoch: 5| Step: 10
Training loss: 0.1905214786529541
Validation loss: 1.8582226087649663

Epoch: 5| Step: 11
Training loss: 0.31807106733322144
Validation loss: 1.881028453509013

Epoch: 456| Step: 0
Training loss: 0.3726958632469177
Validation loss: 1.9369415243466694

Epoch: 5| Step: 1
Training loss: 0.36839646100997925
Validation loss: 1.9340241799751918

Epoch: 5| Step: 2
Training loss: 0.24735882878303528
Validation loss: 1.9118388841549556

Epoch: 5| Step: 3
Training loss: 0.19917356967926025
Validation loss: 1.9068046659231186

Epoch: 5| Step: 4
Training loss: 0.21566352248191833
Validation loss: 1.8644660512606304

Epoch: 5| Step: 5
Training loss: 0.31656116247177124
Validation loss: 1.8772121220827103

Epoch: 5| Step: 6
Training loss: 0.26524680852890015
Validation loss: 1.9369644323984783

Epoch: 5| Step: 7
Training loss: 0.3045670688152313
Validation loss: 1.8971345573663712

Epoch: 5| Step: 8
Training loss: 0.6544444561004639
Validation loss: 1.9195412298043568

Epoch: 5| Step: 9
Training loss: 0.30512315034866333
Validation loss: 1.9212998747825623

Epoch: 5| Step: 10
Training loss: 0.3090273439884186
Validation loss: 1.9141939133405685

Epoch: 5| Step: 11
Training loss: 0.2240111529827118
Validation loss: 1.947884460290273

Epoch: 457| Step: 0
Training loss: 0.2924503684043884
Validation loss: 1.8940128485361736

Epoch: 5| Step: 1
Training loss: 0.313187837600708
Validation loss: 1.8972343007723491

Epoch: 5| Step: 2
Training loss: 0.2721722424030304
Validation loss: 1.893777847290039

Epoch: 5| Step: 3
Training loss: 0.5236075520515442
Validation loss: 1.8337989350159962

Epoch: 5| Step: 4
Training loss: 0.3321538269519806
Validation loss: 1.9042412887016933

Epoch: 5| Step: 5
Training loss: 0.21928341686725616
Validation loss: 1.8874493837356567

Epoch: 5| Step: 6
Training loss: 0.289741188287735
Validation loss: 1.9116806189219158

Epoch: 5| Step: 7
Training loss: 0.28663167357444763
Validation loss: 1.9263262798388798

Epoch: 5| Step: 8
Training loss: 0.2457752525806427
Validation loss: 1.918981631596883

Epoch: 5| Step: 9
Training loss: 0.33649784326553345
Validation loss: 1.934749702612559

Epoch: 5| Step: 10
Training loss: 0.23949356377124786
Validation loss: 1.8996672729651134

Epoch: 5| Step: 11
Training loss: 0.1384480595588684
Validation loss: 1.9119806389013927

Epoch: 458| Step: 0
Training loss: 0.24936974048614502
Validation loss: 1.8762397915124893

Epoch: 5| Step: 1
Training loss: 0.16832157969474792
Validation loss: 1.8897662957509358

Epoch: 5| Step: 2
Training loss: 0.2411658763885498
Validation loss: 1.889758790532748

Epoch: 5| Step: 3
Training loss: 0.3549303412437439
Validation loss: 1.8972291499376297

Epoch: 5| Step: 4
Training loss: 0.3708644211292267
Validation loss: 1.9319319476683934

Epoch: 5| Step: 5
Training loss: 0.6947593688964844
Validation loss: 1.8686351478099823

Epoch: 5| Step: 6
Training loss: 0.21379318833351135
Validation loss: 1.9098560363054276

Epoch: 5| Step: 7
Training loss: 0.25730618834495544
Validation loss: 1.8514799425999324

Epoch: 5| Step: 8
Training loss: 0.16325776278972626
Validation loss: 1.8795207540194194

Epoch: 5| Step: 9
Training loss: 0.2770361304283142
Validation loss: 1.87375208735466

Epoch: 5| Step: 10
Training loss: 0.24778971076011658
Validation loss: 1.9142503142356873

Epoch: 5| Step: 11
Training loss: 0.6316774487495422
Validation loss: 1.8989210774501164

Epoch: 459| Step: 0
Training loss: 0.22773504257202148
Validation loss: 1.8574929038683574

Epoch: 5| Step: 1
Training loss: 0.2589886784553528
Validation loss: 1.8807680110136669

Epoch: 5| Step: 2
Training loss: 0.15270955860614777
Validation loss: 1.8837983806927998

Epoch: 5| Step: 3
Training loss: 0.22229167819023132
Validation loss: 1.900190273920695

Epoch: 5| Step: 4
Training loss: 0.3475685119628906
Validation loss: 1.9042744139830272

Epoch: 5| Step: 5
Training loss: 0.5496991276741028
Validation loss: 1.9117396821578343

Epoch: 5| Step: 6
Training loss: 0.2640705704689026
Validation loss: 1.9082518567641575

Epoch: 5| Step: 7
Training loss: 0.25854748487472534
Validation loss: 1.8784594138463337

Epoch: 5| Step: 8
Training loss: 0.2934386730194092
Validation loss: 1.9036710510651271

Epoch: 5| Step: 9
Training loss: 0.2627500593662262
Validation loss: 1.9154724528392155

Epoch: 5| Step: 10
Training loss: 0.2979549765586853
Validation loss: 1.9056106557448704

Epoch: 5| Step: 11
Training loss: 0.12974989414215088
Validation loss: 1.9168209830919902

Epoch: 460| Step: 0
Training loss: 0.18899385631084442
Validation loss: 1.8641862471898396

Epoch: 5| Step: 1
Training loss: 0.2853676676750183
Validation loss: 1.8950640161832173

Epoch: 5| Step: 2
Training loss: 0.2025517225265503
Validation loss: 1.8944177230199177

Epoch: 5| Step: 3
Training loss: 0.6960272192955017
Validation loss: 1.8582427551349003

Epoch: 5| Step: 4
Training loss: 0.24604444205760956
Validation loss: 1.930739129583041

Epoch: 5| Step: 5
Training loss: 0.24386024475097656
Validation loss: 1.8981579939524333

Epoch: 5| Step: 6
Training loss: 0.37966519594192505
Validation loss: 1.9417435824871063

Epoch: 5| Step: 7
Training loss: 0.24630522727966309
Validation loss: 1.9569756090641022

Epoch: 5| Step: 8
Training loss: 0.20313580334186554
Validation loss: 1.8797219196955364

Epoch: 5| Step: 9
Training loss: 0.2740229666233063
Validation loss: 1.9064531326293945

Epoch: 5| Step: 10
Training loss: 0.19749093055725098
Validation loss: 1.8552712400754292

Epoch: 5| Step: 11
Training loss: 0.16107302904129028
Validation loss: 1.903589740395546

Epoch: 461| Step: 0
Training loss: 0.1889422982931137
Validation loss: 1.9006459911664326

Epoch: 5| Step: 1
Training loss: 0.19957175850868225
Validation loss: 1.8876768549283345

Epoch: 5| Step: 2
Training loss: 0.5242773294448853
Validation loss: 1.8727420071760814

Epoch: 5| Step: 3
Training loss: 0.11787289381027222
Validation loss: 1.9103768567244213

Epoch: 5| Step: 4
Training loss: 0.2601436376571655
Validation loss: 1.869804431994756

Epoch: 5| Step: 5
Training loss: 0.20485463738441467
Validation loss: 1.9670683443546295

Epoch: 5| Step: 6
Training loss: 0.21872973442077637
Validation loss: 1.9504397014776866

Epoch: 5| Step: 7
Training loss: 0.42212915420532227
Validation loss: 1.9460525860389073

Epoch: 5| Step: 8
Training loss: 0.29205742478370667
Validation loss: 1.9618747383356094

Epoch: 5| Step: 9
Training loss: 0.34410223364830017
Validation loss: 1.9499040395021439

Epoch: 5| Step: 10
Training loss: 0.37520769238471985
Validation loss: 1.8940147409836452

Epoch: 5| Step: 11
Training loss: 0.07354217767715454
Validation loss: 1.9069901059071224

Epoch: 462| Step: 0
Training loss: 0.2639910876750946
Validation loss: 1.9059335192044575

Epoch: 5| Step: 1
Training loss: 0.2995677590370178
Validation loss: 1.912808616956075

Epoch: 5| Step: 2
Training loss: 0.4263420104980469
Validation loss: 1.9292349616686504

Epoch: 5| Step: 3
Training loss: 0.2758328318595886
Validation loss: 1.9230595032374065

Epoch: 5| Step: 4
Training loss: 0.24495263397693634
Validation loss: 1.9322281777858734

Epoch: 5| Step: 5
Training loss: 0.18524083495140076
Validation loss: 1.944031834602356

Epoch: 5| Step: 6
Training loss: 0.1975417137145996
Validation loss: 1.938355341553688

Epoch: 5| Step: 7
Training loss: 0.2116348296403885
Validation loss: 1.9420256117979686

Epoch: 5| Step: 8
Training loss: 0.5583618879318237
Validation loss: 1.92340091864268

Epoch: 5| Step: 9
Training loss: 0.24924294650554657
Validation loss: 1.8943657626708348

Epoch: 5| Step: 10
Training loss: 0.28725042939186096
Validation loss: 1.895352264245351

Epoch: 5| Step: 11
Training loss: 0.5560837388038635
Validation loss: 1.894564300775528

Epoch: 463| Step: 0
Training loss: 0.17372699081897736
Validation loss: 1.9044327586889267

Epoch: 5| Step: 1
Training loss: 0.18949201703071594
Validation loss: 1.8872739324967067

Epoch: 5| Step: 2
Training loss: 0.22388975322246552
Validation loss: 1.9029019623994827

Epoch: 5| Step: 3
Training loss: 0.47169917821884155
Validation loss: 1.8830892791350682

Epoch: 5| Step: 4
Training loss: 0.35033297538757324
Validation loss: 1.925003930926323

Epoch: 5| Step: 5
Training loss: 0.5900307893753052
Validation loss: 1.8825368682543437

Epoch: 5| Step: 6
Training loss: 0.18818192183971405
Validation loss: 1.9169392734766006

Epoch: 5| Step: 7
Training loss: 0.33183223009109497
Validation loss: 1.8820083886384964

Epoch: 5| Step: 8
Training loss: 0.2858417332172394
Validation loss: 1.8780242105325062

Epoch: 5| Step: 9
Training loss: 0.19513782858848572
Validation loss: 1.8648900240659714

Epoch: 5| Step: 10
Training loss: 0.16490226984024048
Validation loss: 1.8671021312475204

Epoch: 5| Step: 11
Training loss: 0.1275818943977356
Validation loss: 1.9107732226451237

Epoch: 464| Step: 0
Training loss: 0.22681550681591034
Validation loss: 1.871343309680621

Epoch: 5| Step: 1
Training loss: 0.28719398379325867
Validation loss: 1.8963141938050587

Epoch: 5| Step: 2
Training loss: 0.537041187286377
Validation loss: 1.9111593315998714

Epoch: 5| Step: 3
Training loss: 0.26105743646621704
Validation loss: 1.9041290978590648

Epoch: 5| Step: 4
Training loss: 0.2230844497680664
Validation loss: 1.8775565872589748

Epoch: 5| Step: 5
Training loss: 0.45382213592529297
Validation loss: 1.9237876782814662

Epoch: 5| Step: 6
Training loss: 0.22596637904644012
Validation loss: 1.8992248823245366

Epoch: 5| Step: 7
Training loss: 0.2520197331905365
Validation loss: 1.919541339079539

Epoch: 5| Step: 8
Training loss: 0.24546854197978973
Validation loss: 1.9323260138432186

Epoch: 5| Step: 9
Training loss: 0.2971460223197937
Validation loss: 1.8866344491640727

Epoch: 5| Step: 10
Training loss: 0.18486768007278442
Validation loss: 1.9557444552580516

Epoch: 5| Step: 11
Training loss: 0.08341920375823975
Validation loss: 1.9406354626019795

Epoch: 465| Step: 0
Training loss: 0.20087945461273193
Validation loss: 1.9075753688812256

Epoch: 5| Step: 1
Training loss: 0.19303588569164276
Validation loss: 1.9164564659198124

Epoch: 5| Step: 2
Training loss: 0.37086349725723267
Validation loss: 1.8796740472316742

Epoch: 5| Step: 3
Training loss: 0.17473164200782776
Validation loss: 1.9164665639400482

Epoch: 5| Step: 4
Training loss: 0.17825369536876678
Validation loss: 1.9384634991486867

Epoch: 5| Step: 5
Training loss: 0.21691635251045227
Validation loss: 1.932237833738327

Epoch: 5| Step: 6
Training loss: 0.24850070476531982
Validation loss: 1.9499994665384293

Epoch: 5| Step: 7
Training loss: 0.2567290663719177
Validation loss: 1.8963849892218907

Epoch: 5| Step: 8
Training loss: 0.2842913568019867
Validation loss: 1.9067289183537166

Epoch: 5| Step: 9
Training loss: 0.7150418162345886
Validation loss: 1.8925791283448536

Epoch: 5| Step: 10
Training loss: 0.24592705070972443
Validation loss: 1.915024757385254

Epoch: 5| Step: 11
Training loss: 0.07316815853118896
Validation loss: 1.8952520092328389

Epoch: 466| Step: 0
Training loss: 0.17303459346294403
Validation loss: 1.9109480778376262

Epoch: 5| Step: 1
Training loss: 0.2978929281234741
Validation loss: 1.8948418498039246

Epoch: 5| Step: 2
Training loss: 0.2781539559364319
Validation loss: 1.8875422130028408

Epoch: 5| Step: 3
Training loss: 0.3669191300868988
Validation loss: 1.9084390550851822

Epoch: 5| Step: 4
Training loss: 0.2718985974788666
Validation loss: 1.8972507516543071

Epoch: 5| Step: 5
Training loss: 0.2659485638141632
Validation loss: 1.898004725575447

Epoch: 5| Step: 6
Training loss: 0.19599653780460358
Validation loss: 1.9263347536325455

Epoch: 5| Step: 7
Training loss: 0.7005206346511841
Validation loss: 1.9617557972669601

Epoch: 5| Step: 8
Training loss: 0.33541688323020935
Validation loss: 1.953340212504069

Epoch: 5| Step: 9
Training loss: 0.4634859561920166
Validation loss: 1.9277304708957672

Epoch: 5| Step: 10
Training loss: 0.26628610491752625
Validation loss: 1.9339147955179214

Epoch: 5| Step: 11
Training loss: 0.3135702610015869
Validation loss: 1.8726749668518703

Epoch: 467| Step: 0
Training loss: 0.3839140832424164
Validation loss: 1.9015629589557648

Epoch: 5| Step: 1
Training loss: 0.3634900450706482
Validation loss: 1.8671579360961914

Epoch: 5| Step: 2
Training loss: 0.39077287912368774
Validation loss: 1.8861873398224513

Epoch: 5| Step: 3
Training loss: 0.24357891082763672
Validation loss: 1.913969357808431

Epoch: 5| Step: 4
Training loss: 0.19417704641819
Validation loss: 1.8980651646852493

Epoch: 5| Step: 5
Training loss: 0.22815176844596863
Validation loss: 1.8953782965739567

Epoch: 5| Step: 6
Training loss: 0.18084082007408142
Validation loss: 1.9387844403584797

Epoch: 5| Step: 7
Training loss: 0.2018454372882843
Validation loss: 1.918375586469968

Epoch: 5| Step: 8
Training loss: 0.31368058919906616
Validation loss: 1.9678413271903992

Epoch: 5| Step: 9
Training loss: 0.7057144045829773
Validation loss: 1.9517330080270767

Epoch: 5| Step: 10
Training loss: 0.24904783070087433
Validation loss: 1.9362719058990479

Epoch: 5| Step: 11
Training loss: 0.1763872504234314
Validation loss: 1.9424725472927094

Epoch: 468| Step: 0
Training loss: 0.32974398136138916
Validation loss: 1.9339657922585805

Epoch: 5| Step: 1
Training loss: 0.32298535108566284
Validation loss: 1.890711526075999

Epoch: 5| Step: 2
Training loss: 0.18955378234386444
Validation loss: 1.882324531674385

Epoch: 5| Step: 3
Training loss: 0.24308988451957703
Validation loss: 1.885542318224907

Epoch: 5| Step: 4
Training loss: 0.5283964276313782
Validation loss: 1.9196735322475433

Epoch: 5| Step: 5
Training loss: 0.2632670998573303
Validation loss: 1.9205211400985718

Epoch: 5| Step: 6
Training loss: 0.25750261545181274
Validation loss: 1.9104416519403458

Epoch: 5| Step: 7
Training loss: 0.36641961336135864
Validation loss: 1.9105069438616435

Epoch: 5| Step: 8
Training loss: 0.2056571990251541
Validation loss: 1.9056770652532578

Epoch: 5| Step: 9
Training loss: 0.22569870948791504
Validation loss: 1.9188382029533386

Epoch: 5| Step: 10
Training loss: 0.12471143901348114
Validation loss: 1.9065300176541011

Epoch: 5| Step: 11
Training loss: 0.1853434294462204
Validation loss: 1.8927869697411854

Epoch: 469| Step: 0
Training loss: 0.27704259753227234
Validation loss: 1.8941105902194977

Epoch: 5| Step: 1
Training loss: 0.1715715527534485
Validation loss: 1.9123318642377853

Epoch: 5| Step: 2
Training loss: 0.24670405685901642
Validation loss: 1.8991363992293675

Epoch: 5| Step: 3
Training loss: 0.2277839630842209
Validation loss: 1.8824357390403748

Epoch: 5| Step: 4
Training loss: 0.27115094661712646
Validation loss: 1.884634072581927

Epoch: 5| Step: 5
Training loss: 0.20181527733802795
Validation loss: 1.9085673441489537

Epoch: 5| Step: 6
Training loss: 0.41724443435668945
Validation loss: 1.9042572379112244

Epoch: 5| Step: 7
Training loss: 0.13698171079158783
Validation loss: 1.8883229941129684

Epoch: 5| Step: 8
Training loss: 0.14634211361408234
Validation loss: 1.9332328935464222

Epoch: 5| Step: 9
Training loss: 0.5851191282272339
Validation loss: 1.8842574258645375

Epoch: 5| Step: 10
Training loss: 0.34138935804367065
Validation loss: 1.8994104812542598

Epoch: 5| Step: 11
Training loss: 0.302249014377594
Validation loss: 1.8595791806777318

Epoch: 470| Step: 0
Training loss: 0.3710865378379822
Validation loss: 1.894063080350558

Epoch: 5| Step: 1
Training loss: 0.3258635401725769
Validation loss: 1.8467329343159993

Epoch: 5| Step: 2
Training loss: 0.3804439604282379
Validation loss: 1.8476050247748692

Epoch: 5| Step: 3
Training loss: 0.22407743334770203
Validation loss: 1.871986761689186

Epoch: 5| Step: 4
Training loss: 0.5556130409240723
Validation loss: 1.8738242487112682

Epoch: 5| Step: 5
Training loss: 0.20956771075725555
Validation loss: 1.8944636285305023

Epoch: 5| Step: 6
Training loss: 0.2321896106004715
Validation loss: 1.9233065793911617

Epoch: 5| Step: 7
Training loss: 0.20561926066875458
Validation loss: 1.934978539745013

Epoch: 5| Step: 8
Training loss: 0.4752231538295746
Validation loss: 1.9382488081852596

Epoch: 5| Step: 9
Training loss: 0.2549416124820709
Validation loss: 1.8786396433909733

Epoch: 5| Step: 10
Training loss: 0.26141780614852905
Validation loss: 1.8132097323735554

Epoch: 5| Step: 11
Training loss: 0.10848286747932434
Validation loss: 1.8840977797905605

Epoch: 471| Step: 0
Training loss: 0.5844513177871704
Validation loss: 1.8871124585469563

Epoch: 5| Step: 1
Training loss: 0.3475465774536133
Validation loss: 1.874364083011945

Epoch: 5| Step: 2
Training loss: 0.30961719155311584
Validation loss: 1.871171976129214

Epoch: 5| Step: 3
Training loss: 0.2027519941329956
Validation loss: 1.885824516415596

Epoch: 5| Step: 4
Training loss: 0.5451402068138123
Validation loss: 1.8593322783708572

Epoch: 5| Step: 5
Training loss: 0.28899699449539185
Validation loss: 1.8871260931094487

Epoch: 5| Step: 6
Training loss: 0.2381158173084259
Validation loss: 1.9263490984837215

Epoch: 5| Step: 7
Training loss: 0.4360875189304352
Validation loss: 1.8944077889124553

Epoch: 5| Step: 8
Training loss: 0.1796872317790985
Validation loss: 1.8944257299105327

Epoch: 5| Step: 9
Training loss: 0.18909254670143127
Validation loss: 1.901563326517741

Epoch: 5| Step: 10
Training loss: 0.310131311416626
Validation loss: 1.868725597858429

Epoch: 5| Step: 11
Training loss: 0.06854850053787231
Validation loss: 1.8712434818347294

Epoch: 472| Step: 0
Training loss: 0.28602176904678345
Validation loss: 1.8640847553809483

Epoch: 5| Step: 1
Training loss: 0.2858123183250427
Validation loss: 1.8795788288116455

Epoch: 5| Step: 2
Training loss: 0.17231985926628113
Validation loss: 1.8663484007120132

Epoch: 5| Step: 3
Training loss: 0.19103693962097168
Validation loss: 1.9310107131799061

Epoch: 5| Step: 4
Training loss: 0.23642757534980774
Validation loss: 1.926520307858785

Epoch: 5| Step: 5
Training loss: 0.23007836937904358
Validation loss: 1.9259404490391414

Epoch: 5| Step: 6
Training loss: 0.1908562332391739
Validation loss: 1.902473400036494

Epoch: 5| Step: 7
Training loss: 0.17473086714744568
Validation loss: 1.86848217745622

Epoch: 5| Step: 8
Training loss: 0.2163582295179367
Validation loss: 1.901422157883644

Epoch: 5| Step: 9
Training loss: 0.7411774396896362
Validation loss: 1.8809344669183095

Epoch: 5| Step: 10
Training loss: 0.34243160486221313
Validation loss: 1.8344135334094365

Epoch: 5| Step: 11
Training loss: 0.5529168844223022
Validation loss: 1.8464819888273876

Epoch: 473| Step: 0
Training loss: 0.17415158450603485
Validation loss: 1.8608441750208538

Epoch: 5| Step: 1
Training loss: 0.35353296995162964
Validation loss: 1.8718601514895756

Epoch: 5| Step: 2
Training loss: 0.5976948142051697
Validation loss: 1.8761368542909622

Epoch: 5| Step: 3
Training loss: 0.2489030808210373
Validation loss: 1.8645049631595612

Epoch: 5| Step: 4
Training loss: 0.4088587164878845
Validation loss: 1.8613041589657466

Epoch: 5| Step: 5
Training loss: 0.23062534630298615
Validation loss: 1.8894912898540497

Epoch: 5| Step: 6
Training loss: 0.2254633903503418
Validation loss: 1.8510557462771733

Epoch: 5| Step: 7
Training loss: 0.23550014197826385
Validation loss: 1.8852554162343342

Epoch: 5| Step: 8
Training loss: 0.3162025809288025
Validation loss: 1.8649490376313527

Epoch: 5| Step: 9
Training loss: 0.21403281390666962
Validation loss: 1.9197556128104527

Epoch: 5| Step: 10
Training loss: 0.23343339562416077
Validation loss: 1.8729286243518193

Epoch: 5| Step: 11
Training loss: 0.3119505047798157
Validation loss: 1.9043461034695308

Epoch: 474| Step: 0
Training loss: 0.26848816871643066
Validation loss: 1.86249444882075

Epoch: 5| Step: 1
Training loss: 0.2148117572069168
Validation loss: 1.8517821729183197

Epoch: 5| Step: 2
Training loss: 0.5625499486923218
Validation loss: 1.8793621510267258

Epoch: 5| Step: 3
Training loss: 0.25543084740638733
Validation loss: 1.8370899508396785

Epoch: 5| Step: 4
Training loss: 0.19026407599449158
Validation loss: 1.8782866497834523

Epoch: 5| Step: 5
Training loss: 0.1952458769083023
Validation loss: 1.9354937424262364

Epoch: 5| Step: 6
Training loss: 0.20781254768371582
Validation loss: 1.8936714281638463

Epoch: 5| Step: 7
Training loss: 0.25619617104530334
Validation loss: 1.8965322176615398

Epoch: 5| Step: 8
Training loss: 0.22798752784729004
Validation loss: 1.9100106904904048

Epoch: 5| Step: 9
Training loss: 0.41616955399513245
Validation loss: 1.8948611617088318

Epoch: 5| Step: 10
Training loss: 0.2313324511051178
Validation loss: 1.908593972524007

Epoch: 5| Step: 11
Training loss: 0.13526664674282074
Validation loss: 1.880547617872556

Epoch: 475| Step: 0
Training loss: 0.2259894609451294
Validation loss: 1.8844194064537685

Epoch: 5| Step: 1
Training loss: 0.3797544836997986
Validation loss: 1.9211070587237675

Epoch: 5| Step: 2
Training loss: 0.20783035457134247
Validation loss: 1.9524513334035873

Epoch: 5| Step: 3
Training loss: 0.3367490768432617
Validation loss: 1.9120315064986546

Epoch: 5| Step: 4
Training loss: 0.22378642857074738
Validation loss: 1.9300765097141266

Epoch: 5| Step: 5
Training loss: 0.6355673670768738
Validation loss: 1.9072334965070088

Epoch: 5| Step: 6
Training loss: 0.2714342474937439
Validation loss: 1.9006545792023342

Epoch: 5| Step: 7
Training loss: 0.3074882924556732
Validation loss: 1.9122956941525142

Epoch: 5| Step: 8
Training loss: 0.2174401581287384
Validation loss: 1.8788198481003444

Epoch: 5| Step: 9
Training loss: 0.1535339653491974
Validation loss: 1.92343973616759

Epoch: 5| Step: 10
Training loss: 0.22679169476032257
Validation loss: 1.8949326028426488

Epoch: 5| Step: 11
Training loss: 0.13736683130264282
Validation loss: 1.910216877857844

Epoch: 476| Step: 0
Training loss: 0.1752229481935501
Validation loss: 1.8613833039999008

Epoch: 5| Step: 1
Training loss: 0.2150096893310547
Validation loss: 1.896048019329707

Epoch: 5| Step: 2
Training loss: 0.22502820193767548
Validation loss: 1.954295481244723

Epoch: 5| Step: 3
Training loss: 0.2619013786315918
Validation loss: 1.8857611864805222

Epoch: 5| Step: 4
Training loss: 0.3048279583454132
Validation loss: 1.890285313129425

Epoch: 5| Step: 5
Training loss: 0.19475945830345154
Validation loss: 1.9082210312287013

Epoch: 5| Step: 6
Training loss: 0.6239107847213745
Validation loss: 1.895957425236702

Epoch: 5| Step: 7
Training loss: 0.207027405500412
Validation loss: 1.8858824123938878

Epoch: 5| Step: 8
Training loss: 0.45685476064682007
Validation loss: 1.8468336462974548

Epoch: 5| Step: 9
Training loss: 0.3045586943626404
Validation loss: 1.8809540073076885

Epoch: 5| Step: 10
Training loss: 0.18083611130714417
Validation loss: 1.9174694021542866

Epoch: 5| Step: 11
Training loss: 0.2451588213443756
Validation loss: 1.9716169734795888

Epoch: 477| Step: 0
Training loss: 0.31135720014572144
Validation loss: 1.8931855609019597

Epoch: 5| Step: 1
Training loss: 0.21995210647583008
Validation loss: 1.8982707510391872

Epoch: 5| Step: 2
Training loss: 0.2487390786409378
Validation loss: 1.9218942324320476

Epoch: 5| Step: 3
Training loss: 0.2311328947544098
Validation loss: 1.872478519876798

Epoch: 5| Step: 4
Training loss: 0.3590049743652344
Validation loss: 1.876126155257225

Epoch: 5| Step: 5
Training loss: 0.38305744528770447
Validation loss: 1.889256129662196

Epoch: 5| Step: 6
Training loss: 0.6151080131530762
Validation loss: 1.8548879424730937

Epoch: 5| Step: 7
Training loss: 0.29745274782180786
Validation loss: 1.8898700922727585

Epoch: 5| Step: 8
Training loss: 0.1913873553276062
Validation loss: 1.8842364350954692

Epoch: 5| Step: 9
Training loss: 0.23092953860759735
Validation loss: 1.8688242385784786

Epoch: 5| Step: 10
Training loss: 0.1932644098997116
Validation loss: 1.888272802035014

Epoch: 5| Step: 11
Training loss: 0.17692798376083374
Validation loss: 1.8701268881559372

Epoch: 478| Step: 0
Training loss: 0.26243218779563904
Validation loss: 1.9073204000790913

Epoch: 5| Step: 1
Training loss: 0.5580266714096069
Validation loss: 1.9569849620262783

Epoch: 5| Step: 2
Training loss: 0.2390858232975006
Validation loss: 1.907093584537506

Epoch: 5| Step: 3
Training loss: 0.27269646525382996
Validation loss: 1.8903226604064305

Epoch: 5| Step: 4
Training loss: 0.22041067481040955
Validation loss: 1.9138303846120834

Epoch: 5| Step: 5
Training loss: 0.46132078766822815
Validation loss: 1.8747939417759578

Epoch: 5| Step: 6
Training loss: 0.3117724061012268
Validation loss: 1.8803794185320537

Epoch: 5| Step: 7
Training loss: 0.24940386414527893
Validation loss: 1.8675399670998256

Epoch: 5| Step: 8
Training loss: 0.31107640266418457
Validation loss: 1.8788218349218369

Epoch: 5| Step: 9
Training loss: 0.20235669612884521
Validation loss: 1.8747173647085826

Epoch: 5| Step: 10
Training loss: 0.2034725397825241
Validation loss: 1.9036481926838558

Epoch: 5| Step: 11
Training loss: 0.75099116563797
Validation loss: 1.910950740178426

Epoch: 479| Step: 0
Training loss: 0.19365139305591583
Validation loss: 1.9121119727691014

Epoch: 5| Step: 1
Training loss: 0.2143564522266388
Validation loss: 1.9035263409217198

Epoch: 5| Step: 2
Training loss: 0.6068862676620483
Validation loss: 1.8942848841349285

Epoch: 5| Step: 3
Training loss: 0.2586615979671478
Validation loss: 1.8766089777151744

Epoch: 5| Step: 4
Training loss: 0.14177273213863373
Validation loss: 1.8804952204227448

Epoch: 5| Step: 5
Training loss: 0.23407301306724548
Validation loss: 1.8708297212918599

Epoch: 5| Step: 6
Training loss: 0.1637897491455078
Validation loss: 1.873200386762619

Epoch: 5| Step: 7
Training loss: 0.25299495458602905
Validation loss: 1.8685732732216518

Epoch: 5| Step: 8
Training loss: 0.352570116519928
Validation loss: 1.894306942820549

Epoch: 5| Step: 9
Training loss: 0.34483471512794495
Validation loss: 1.9081599513689678

Epoch: 5| Step: 10
Training loss: 0.1941060721874237
Validation loss: 1.8492661267518997

Epoch: 5| Step: 11
Training loss: 0.14369061589241028
Validation loss: 1.9067046244939168

Epoch: 480| Step: 0
Training loss: 0.43780526518821716
Validation loss: 1.8631735295057297

Epoch: 5| Step: 1
Training loss: 0.36057430505752563
Validation loss: 1.8533042867978413

Epoch: 5| Step: 2
Training loss: 0.263416051864624
Validation loss: 1.8510227054357529

Epoch: 5| Step: 3
Training loss: 0.3047923445701599
Validation loss: 1.8697867294152577

Epoch: 5| Step: 4
Training loss: 0.26387402415275574
Validation loss: 1.9116425315539043

Epoch: 5| Step: 5
Training loss: 0.28924641013145447
Validation loss: 1.9477462867895763

Epoch: 5| Step: 6
Training loss: 0.22149376571178436
Validation loss: 1.8876574685176213

Epoch: 5| Step: 7
Training loss: 0.6039854884147644
Validation loss: 1.9181167433659236

Epoch: 5| Step: 8
Training loss: 0.20414499938488007
Validation loss: 1.9087603837251663

Epoch: 5| Step: 9
Training loss: 0.16680428385734558
Validation loss: 1.9228425820668538

Epoch: 5| Step: 10
Training loss: 0.26226404309272766
Validation loss: 1.9008696327606838

Epoch: 5| Step: 11
Training loss: 0.08404293656349182
Validation loss: 1.8738813698291779

Epoch: 481| Step: 0
Training loss: 0.29682764410972595
Validation loss: 1.894091824690501

Epoch: 5| Step: 1
Training loss: 0.21490582823753357
Validation loss: 1.8949760248263676

Epoch: 5| Step: 2
Training loss: 0.20352871716022491
Validation loss: 1.9265009065469105

Epoch: 5| Step: 3
Training loss: 0.31500735878944397
Validation loss: 1.8906955520311992

Epoch: 5| Step: 4
Training loss: 0.2662726640701294
Validation loss: 1.9039550969998043

Epoch: 5| Step: 5
Training loss: 0.2280416488647461
Validation loss: 1.898789291580518

Epoch: 5| Step: 6
Training loss: 0.22488851845264435
Validation loss: 1.8950848927100499

Epoch: 5| Step: 7
Training loss: 0.21899652481079102
Validation loss: 1.8772208094596863

Epoch: 5| Step: 8
Training loss: 0.2050827294588089
Validation loss: 1.8619572867949803

Epoch: 5| Step: 9
Training loss: 0.5970650911331177
Validation loss: 1.887996291120847

Epoch: 5| Step: 10
Training loss: 0.2524365782737732
Validation loss: 1.907162715991338

Epoch: 5| Step: 11
Training loss: 0.06159240007400513
Validation loss: 1.9338395396868389

Epoch: 482| Step: 0
Training loss: 0.2721906900405884
Validation loss: 1.8664386173089345

Epoch: 5| Step: 1
Training loss: 0.27904582023620605
Validation loss: 1.9003475209077199

Epoch: 5| Step: 2
Training loss: 0.24531707167625427
Validation loss: 1.9299226303895314

Epoch: 5| Step: 3
Training loss: 0.21868976950645447
Validation loss: 1.8958336114883423

Epoch: 5| Step: 4
Training loss: 0.34357959032058716
Validation loss: 1.8839241017897923

Epoch: 5| Step: 5
Training loss: 0.22292788326740265
Validation loss: 1.8907418598731358

Epoch: 5| Step: 6
Training loss: 0.24762454628944397
Validation loss: 1.9035834521055222

Epoch: 5| Step: 7
Training loss: 0.5009363889694214
Validation loss: 1.9282795190811157

Epoch: 5| Step: 8
Training loss: 0.2367008626461029
Validation loss: 1.9513594309488933

Epoch: 5| Step: 9
Training loss: 0.3547538220882416
Validation loss: 1.9426425397396088

Epoch: 5| Step: 10
Training loss: 0.2917795777320862
Validation loss: 1.9017269363005955

Epoch: 5| Step: 11
Training loss: 0.11077392101287842
Validation loss: 1.8777192483345668

Epoch: 483| Step: 0
Training loss: 0.39501962065696716
Validation loss: 1.903106540441513

Epoch: 5| Step: 1
Training loss: 0.22085972130298615
Validation loss: 1.8661473592122395

Epoch: 5| Step: 2
Training loss: 0.25543177127838135
Validation loss: 1.9242040912310283

Epoch: 5| Step: 3
Training loss: 0.18956337869167328
Validation loss: 1.889699454108874

Epoch: 5| Step: 4
Training loss: 0.2560044825077057
Validation loss: 1.8811197380224864

Epoch: 5| Step: 5
Training loss: 0.2895706295967102
Validation loss: 1.8975542038679123

Epoch: 5| Step: 6
Training loss: 0.22900083661079407
Validation loss: 1.899994691212972

Epoch: 5| Step: 7
Training loss: 0.4845556616783142
Validation loss: 1.8940749019384384

Epoch: 5| Step: 8
Training loss: 0.30614668130874634
Validation loss: 1.8975740472475688

Epoch: 5| Step: 9
Training loss: 0.22999095916748047
Validation loss: 1.8936868806680043

Epoch: 5| Step: 10
Training loss: 0.24633879959583282
Validation loss: 1.937378540635109

Epoch: 5| Step: 11
Training loss: 0.08585405349731445
Validation loss: 1.8617978443702061

Epoch: 484| Step: 0
Training loss: 0.20116563141345978
Validation loss: 1.8930013924837112

Epoch: 5| Step: 1
Training loss: 0.2787356972694397
Validation loss: 1.8983674148718517

Epoch: 5| Step: 2
Training loss: 0.32799863815307617
Validation loss: 1.8958854774634044

Epoch: 5| Step: 3
Training loss: 0.20780983567237854
Validation loss: 1.8950895716746647

Epoch: 5| Step: 4
Training loss: 0.1643289029598236
Validation loss: 1.8686678806940715

Epoch: 5| Step: 5
Training loss: 0.3019842505455017
Validation loss: 1.8998506367206573

Epoch: 5| Step: 6
Training loss: 0.2433006316423416
Validation loss: 1.869337871670723

Epoch: 5| Step: 7
Training loss: 0.2707766890525818
Validation loss: 1.8748852610588074

Epoch: 5| Step: 8
Training loss: 0.4874610900878906
Validation loss: 1.841018905242284

Epoch: 5| Step: 9
Training loss: 0.3848182260990143
Validation loss: 1.8451061348120372

Epoch: 5| Step: 10
Training loss: 0.3332656919956207
Validation loss: 1.8384599536657333

Epoch: 5| Step: 11
Training loss: 0.2908603549003601
Validation loss: 1.8524811665217082

Epoch: 485| Step: 0
Training loss: 0.23932664096355438
Validation loss: 1.8954914063215256

Epoch: 5| Step: 1
Training loss: 0.23855003714561462
Validation loss: 1.9015193333228428

Epoch: 5| Step: 2
Training loss: 0.3125390410423279
Validation loss: 1.8786295255025227

Epoch: 5| Step: 3
Training loss: 0.3040732443332672
Validation loss: 1.8771972060203552

Epoch: 5| Step: 4
Training loss: 0.24091987311840057
Validation loss: 1.876119037469228

Epoch: 5| Step: 5
Training loss: 0.32033807039260864
Validation loss: 1.8806431541840236

Epoch: 5| Step: 6
Training loss: 0.21142928302288055
Validation loss: 1.8769738723834355

Epoch: 5| Step: 7
Training loss: 0.35648593306541443
Validation loss: 1.8469661970933278

Epoch: 5| Step: 8
Training loss: 0.5010648965835571
Validation loss: 1.85264885922273

Epoch: 5| Step: 9
Training loss: 0.23030726611614227
Validation loss: 1.8510701457659404

Epoch: 5| Step: 10
Training loss: 0.20711703598499298
Validation loss: 1.901968002319336

Epoch: 5| Step: 11
Training loss: 0.19506847858428955
Validation loss: 1.8709341436624527

Epoch: 486| Step: 0
Training loss: 0.26001986861228943
Validation loss: 1.8892487684885662

Epoch: 5| Step: 1
Training loss: 0.2104049026966095
Validation loss: 1.8833081523577373

Epoch: 5| Step: 2
Training loss: 0.3628471791744232
Validation loss: 1.8983165919780731

Epoch: 5| Step: 3
Training loss: 0.223770409822464
Validation loss: 1.9372191627820332

Epoch: 5| Step: 4
Training loss: 0.2507254481315613
Validation loss: 1.9146278599898021

Epoch: 5| Step: 5
Training loss: 0.5811957716941833
Validation loss: 1.921178087592125

Epoch: 5| Step: 6
Training loss: 0.34853267669677734
Validation loss: 1.9314463585615158

Epoch: 5| Step: 7
Training loss: 0.19812500476837158
Validation loss: 1.8689333895842235

Epoch: 5| Step: 8
Training loss: 0.20752723515033722
Validation loss: 1.958324243625005

Epoch: 5| Step: 9
Training loss: 0.1855093240737915
Validation loss: 1.8911802172660828

Epoch: 5| Step: 10
Training loss: 0.22114963829517365
Validation loss: 1.9450835486253102

Epoch: 5| Step: 11
Training loss: 0.21073263883590698
Validation loss: 1.9398782600959141

Epoch: 487| Step: 0
Training loss: 0.21798714995384216
Validation loss: 1.8932525664567947

Epoch: 5| Step: 1
Training loss: 0.20480577647686005
Validation loss: 1.91241222123305

Epoch: 5| Step: 2
Training loss: 0.2629489302635193
Validation loss: 1.8717781205972035

Epoch: 5| Step: 3
Training loss: 0.21378007531166077
Validation loss: 1.940868650873502

Epoch: 5| Step: 4
Training loss: 0.31839028000831604
Validation loss: 1.842430755496025

Epoch: 5| Step: 5
Training loss: 0.2647421956062317
Validation loss: 1.8563686857620876

Epoch: 5| Step: 6
Training loss: 0.2212918996810913
Validation loss: 1.891623968879382

Epoch: 5| Step: 7
Training loss: 0.24932439625263214
Validation loss: 1.8997095276912053

Epoch: 5| Step: 8
Training loss: 0.2871226668357849
Validation loss: 1.9213712513446808

Epoch: 5| Step: 9
Training loss: 0.509655237197876
Validation loss: 1.9089577049016953

Epoch: 5| Step: 10
Training loss: 0.24197325110435486
Validation loss: 1.914569452404976

Epoch: 5| Step: 11
Training loss: 0.13696768879890442
Validation loss: 1.888989229996999

Epoch: 488| Step: 0
Training loss: 0.2610183358192444
Validation loss: 1.8820976515611012

Epoch: 5| Step: 1
Training loss: 0.2269495278596878
Validation loss: 1.9102343370517094

Epoch: 5| Step: 2
Training loss: 0.16600780189037323
Validation loss: 1.900271624326706

Epoch: 5| Step: 3
Training loss: 0.4103162884712219
Validation loss: 1.901290163397789

Epoch: 5| Step: 4
Training loss: 0.22081604599952698
Validation loss: 1.9337455530961354

Epoch: 5| Step: 5
Training loss: 0.21855679154396057
Validation loss: 1.8823048571745555

Epoch: 5| Step: 6
Training loss: 0.1658923327922821
Validation loss: 1.8652119239171345

Epoch: 5| Step: 7
Training loss: 0.25988611578941345
Validation loss: 1.880747487147649

Epoch: 5| Step: 8
Training loss: 0.1611788421869278
Validation loss: 1.9059765885273616

Epoch: 5| Step: 9
Training loss: 0.5974756479263306
Validation loss: 1.900404100616773

Epoch: 5| Step: 10
Training loss: 0.1874888688325882
Validation loss: 1.9074065337578456

Epoch: 5| Step: 11
Training loss: 0.19284820556640625
Validation loss: 1.8709212044874828

Epoch: 489| Step: 0
Training loss: 0.17902612686157227
Validation loss: 1.8995093901952107

Epoch: 5| Step: 1
Training loss: 0.1846807599067688
Validation loss: 1.9136877059936523

Epoch: 5| Step: 2
Training loss: 0.38851696252822876
Validation loss: 1.9269392093022664

Epoch: 5| Step: 3
Training loss: 0.5582759976387024
Validation loss: 1.9475332647562027

Epoch: 5| Step: 4
Training loss: 0.2563255727291107
Validation loss: 1.9224178194999695

Epoch: 5| Step: 5
Training loss: 0.16560664772987366
Validation loss: 1.9491880188385646

Epoch: 5| Step: 6
Training loss: 0.2696695923805237
Validation loss: 1.8731174518664677

Epoch: 5| Step: 7
Training loss: 0.2081582099199295
Validation loss: 1.907765691479047

Epoch: 5| Step: 8
Training loss: 0.2982994019985199
Validation loss: 1.9145905375480652

Epoch: 5| Step: 9
Training loss: 0.278376966714859
Validation loss: 1.8890699446201324

Epoch: 5| Step: 10
Training loss: 0.22792024910449982
Validation loss: 1.8666823258002598

Epoch: 5| Step: 11
Training loss: 0.43272173404693604
Validation loss: 1.8809298972288768

Epoch: 490| Step: 0
Training loss: 0.26299580931663513
Validation loss: 1.8697728862365086

Epoch: 5| Step: 1
Training loss: 0.14760926365852356
Validation loss: 1.873524621129036

Epoch: 5| Step: 2
Training loss: 0.15837398171424866
Validation loss: 1.8924415757258732

Epoch: 5| Step: 3
Training loss: 0.35923677682876587
Validation loss: 1.9463532318671544

Epoch: 5| Step: 4
Training loss: 0.26740336418151855
Validation loss: 1.9385704795519512

Epoch: 5| Step: 5
Training loss: 0.2906778156757355
Validation loss: 1.9182479331890743

Epoch: 5| Step: 6
Training loss: 0.33979764580726624
Validation loss: 1.8807132840156555

Epoch: 5| Step: 7
Training loss: 0.28731828927993774
Validation loss: 1.8934404104948044

Epoch: 5| Step: 8
Training loss: 0.27779507637023926
Validation loss: 1.9284078081448872

Epoch: 5| Step: 9
Training loss: 0.5194676518440247
Validation loss: 1.8978483726580937

Epoch: 5| Step: 10
Training loss: 0.23018288612365723
Validation loss: 1.8853684862454732

Epoch: 5| Step: 11
Training loss: 0.16478002071380615
Validation loss: 1.864595835407575

Epoch: 491| Step: 0
Training loss: 0.39050090312957764
Validation loss: 1.8842774033546448

Epoch: 5| Step: 1
Training loss: 0.3333457112312317
Validation loss: 1.854134480158488

Epoch: 5| Step: 2
Training loss: 0.23160746693611145
Validation loss: 1.8899286339680355

Epoch: 5| Step: 3
Training loss: 0.14457015693187714
Validation loss: 1.88716721534729

Epoch: 5| Step: 4
Training loss: 0.23103466629981995
Validation loss: 1.8695541024208069

Epoch: 5| Step: 5
Training loss: 0.2393697053194046
Validation loss: 1.864811008175214

Epoch: 5| Step: 6
Training loss: 0.2380935400724411
Validation loss: 1.881866122285525

Epoch: 5| Step: 7
Training loss: 0.5964502096176147
Validation loss: 1.90438345571359

Epoch: 5| Step: 8
Training loss: 0.15646107494831085
Validation loss: 1.8689446498950322

Epoch: 5| Step: 9
Training loss: 0.22817416489124298
Validation loss: 1.9108993262052536

Epoch: 5| Step: 10
Training loss: 0.4086322784423828
Validation loss: 1.851248100399971

Epoch: 5| Step: 11
Training loss: 0.5537927150726318
Validation loss: 1.846136490503947

Epoch: 492| Step: 0
Training loss: 0.24253053963184357
Validation loss: 1.8384893387556076

Epoch: 5| Step: 1
Training loss: 0.5897840261459351
Validation loss: 1.9056500891844432

Epoch: 5| Step: 2
Training loss: 0.3280549645423889
Validation loss: 1.9341905117034912

Epoch: 5| Step: 3
Training loss: 0.4018530249595642
Validation loss: 1.8799728453159332

Epoch: 5| Step: 4
Training loss: 0.24344995617866516
Validation loss: 1.9282912661631901

Epoch: 5| Step: 5
Training loss: 0.17717313766479492
Validation loss: 1.9196624010801315

Epoch: 5| Step: 6
Training loss: 0.2947520315647125
Validation loss: 1.9237988044818242

Epoch: 5| Step: 7
Training loss: 0.18491166830062866
Validation loss: 1.864156112074852

Epoch: 5| Step: 8
Training loss: 0.19068273901939392
Validation loss: 1.8805432965358098

Epoch: 5| Step: 9
Training loss: 0.21386007964611053
Validation loss: 1.8769867320855458

Epoch: 5| Step: 10
Training loss: 0.2442621886730194
Validation loss: 1.9132021019856136

Epoch: 5| Step: 11
Training loss: 0.2703496217727661
Validation loss: 1.8877271910508473

Epoch: 493| Step: 0
Training loss: 0.3619304299354553
Validation loss: 1.8598579863707225

Epoch: 5| Step: 1
Training loss: 0.23647832870483398
Validation loss: 1.93185090025266

Epoch: 5| Step: 2
Training loss: 0.24277415871620178
Validation loss: 1.9264301011959712

Epoch: 5| Step: 3
Training loss: 0.2647847533226013
Validation loss: 1.947569986184438

Epoch: 5| Step: 4
Training loss: 0.1621919721364975
Validation loss: 1.865933507680893

Epoch: 5| Step: 5
Training loss: 0.26695019006729126
Validation loss: 1.8832307408253353

Epoch: 5| Step: 6
Training loss: 0.12647676467895508
Validation loss: 1.8738696972529094

Epoch: 5| Step: 7
Training loss: 0.2679606080055237
Validation loss: 1.8938501228888829

Epoch: 5| Step: 8
Training loss: 0.38030439615249634
Validation loss: 1.834487110376358

Epoch: 5| Step: 9
Training loss: 0.269125759601593
Validation loss: 1.8803659230470657

Epoch: 5| Step: 10
Training loss: 0.6184440851211548
Validation loss: 1.8790458540121715

Epoch: 5| Step: 11
Training loss: 0.1966252624988556
Validation loss: 1.9253522704044979

Epoch: 494| Step: 0
Training loss: 0.3455565571784973
Validation loss: 1.9273247917493184

Epoch: 5| Step: 1
Training loss: 0.3882371187210083
Validation loss: 1.9775683681170146

Epoch: 5| Step: 2
Training loss: 0.27897605299949646
Validation loss: 1.9228899280230205

Epoch: 5| Step: 3
Training loss: 0.3013562858104706
Validation loss: 1.9120833973089855

Epoch: 5| Step: 4
Training loss: 0.626232385635376
Validation loss: 1.8768724898497264

Epoch: 5| Step: 5
Training loss: 0.20197376608848572
Validation loss: 1.8817647645870845

Epoch: 5| Step: 6
Training loss: 0.22340993583202362
Validation loss: 1.9016065398852031

Epoch: 5| Step: 7
Training loss: 0.5015240907669067
Validation loss: 1.8492919156948726

Epoch: 5| Step: 8
Training loss: 0.30991819500923157
Validation loss: 1.8505552411079407

Epoch: 5| Step: 9
Training loss: 0.20090940594673157
Validation loss: 1.8910846759875615

Epoch: 5| Step: 10
Training loss: 0.2259128987789154
Validation loss: 1.871465598543485

Epoch: 5| Step: 11
Training loss: 0.3947427272796631
Validation loss: 1.9089888979991276

Epoch: 495| Step: 0
Training loss: 0.20922622084617615
Validation loss: 1.9055474748214085

Epoch: 5| Step: 1
Training loss: 0.2743292450904846
Validation loss: 1.9115856836239498

Epoch: 5| Step: 2
Training loss: 0.5506790280342102
Validation loss: 1.8767284005880356

Epoch: 5| Step: 3
Training loss: 0.19762341678142548
Validation loss: 1.8770362933476765

Epoch: 5| Step: 4
Training loss: 0.1681138426065445
Validation loss: 1.897246539592743

Epoch: 5| Step: 5
Training loss: 0.2746914029121399
Validation loss: 1.914798801143964

Epoch: 5| Step: 6
Training loss: 0.2785205543041229
Validation loss: 1.8919971287250519

Epoch: 5| Step: 7
Training loss: 0.24211318790912628
Validation loss: 1.8937045236428578

Epoch: 5| Step: 8
Training loss: 0.2641834616661072
Validation loss: 1.876346270243327

Epoch: 5| Step: 9
Training loss: 0.32855474948883057
Validation loss: 1.8579183171192806

Epoch: 5| Step: 10
Training loss: 0.23908746242523193
Validation loss: 1.8933571130037308

Epoch: 5| Step: 11
Training loss: 0.2241891622543335
Validation loss: 1.8528070151805878

Epoch: 496| Step: 0
Training loss: 0.18981432914733887
Validation loss: 1.8972939600547154

Epoch: 5| Step: 1
Training loss: 0.16854798793792725
Validation loss: 1.927852953473727

Epoch: 5| Step: 2
Training loss: 0.28777751326560974
Validation loss: 1.9361292868852615

Epoch: 5| Step: 3
Training loss: 0.27716246247291565
Validation loss: 1.908809835712115

Epoch: 5| Step: 4
Training loss: 0.19495277106761932
Validation loss: 1.9044602264960606

Epoch: 5| Step: 5
Training loss: 0.36578646302223206
Validation loss: 1.9112552652756374

Epoch: 5| Step: 6
Training loss: 0.5771985054016113
Validation loss: 1.8835656493902206

Epoch: 5| Step: 7
Training loss: 0.2174222469329834
Validation loss: 1.8812686949968338

Epoch: 5| Step: 8
Training loss: 0.22861714661121368
Validation loss: 1.8726075838009517

Epoch: 5| Step: 9
Training loss: 0.29117685556411743
Validation loss: 1.8724481711785

Epoch: 5| Step: 10
Training loss: 0.22464866936206818
Validation loss: 1.8924531092246373

Epoch: 5| Step: 11
Training loss: 0.2906627655029297
Validation loss: 1.953700249393781

Epoch: 497| Step: 0
Training loss: 0.3212422728538513
Validation loss: 1.9337869733572006

Epoch: 5| Step: 1
Training loss: 0.29400235414505005
Validation loss: 1.9394282301266987

Epoch: 5| Step: 2
Training loss: 0.2820200026035309
Validation loss: 1.9191567599773407

Epoch: 5| Step: 3
Training loss: 0.3293341398239136
Validation loss: 1.9294135322173436

Epoch: 5| Step: 4
Training loss: 0.6616421341896057
Validation loss: 1.9100259741147358

Epoch: 5| Step: 5
Training loss: 0.25332197546958923
Validation loss: 1.859603727857272

Epoch: 5| Step: 6
Training loss: 0.2473161518573761
Validation loss: 1.8817297120889027

Epoch: 5| Step: 7
Training loss: 0.3548904061317444
Validation loss: 1.873688871661822

Epoch: 5| Step: 8
Training loss: 0.36826255917549133
Validation loss: 1.9161213090022404

Epoch: 5| Step: 9
Training loss: 0.22092333436012268
Validation loss: 1.877720981836319

Epoch: 5| Step: 10
Training loss: 0.26382604241371155
Validation loss: 1.9095201293627422

Epoch: 5| Step: 11
Training loss: 0.30024614930152893
Validation loss: 1.9024917682011921

Epoch: 498| Step: 0
Training loss: 0.33760371804237366
Validation loss: 1.9364076753457387

Epoch: 5| Step: 1
Training loss: 0.5587291121482849
Validation loss: 1.9433237214883168

Epoch: 5| Step: 2
Training loss: 0.22530850768089294
Validation loss: 1.8940381358067195

Epoch: 5| Step: 3
Training loss: 0.2202199250459671
Validation loss: 1.9126794536908467

Epoch: 5| Step: 4
Training loss: 0.24282245337963104
Validation loss: 1.8806465516487758

Epoch: 5| Step: 5
Training loss: 0.36101168394088745
Validation loss: 1.8378747403621674

Epoch: 5| Step: 6
Training loss: 0.1867542862892151
Validation loss: 1.8853571712970734

Epoch: 5| Step: 7
Training loss: 0.2534722685813904
Validation loss: 1.868910585840543

Epoch: 5| Step: 8
Training loss: 0.23634152114391327
Validation loss: 1.9100545694430668

Epoch: 5| Step: 9
Training loss: 0.18367800116539001
Validation loss: 1.9108010182778041

Epoch: 5| Step: 10
Training loss: 0.1740158349275589
Validation loss: 1.8756131678819656

Epoch: 5| Step: 11
Training loss: 0.5620063543319702
Validation loss: 1.9203429619471233

Epoch: 499| Step: 0
Training loss: 0.18839046359062195
Validation loss: 1.8733239223559697

Epoch: 5| Step: 1
Training loss: 0.1728258728981018
Validation loss: 1.8820131570100784

Epoch: 5| Step: 2
Training loss: 0.22795024514198303
Validation loss: 1.8861144830783207

Epoch: 5| Step: 3
Training loss: 0.2761212885379791
Validation loss: 1.85702450076739

Epoch: 5| Step: 4
Training loss: 0.2510982155799866
Validation loss: 1.8730326741933823

Epoch: 5| Step: 5
Training loss: 0.1958926022052765
Validation loss: 1.8640449941158295

Epoch: 5| Step: 6
Training loss: 0.26587507128715515
Validation loss: 1.8713308274745941

Epoch: 5| Step: 7
Training loss: 0.1378612220287323
Validation loss: 1.8953563918670018

Epoch: 5| Step: 8
Training loss: 0.3047853410243988
Validation loss: 1.9057606607675552

Epoch: 5| Step: 9
Training loss: 0.26734644174575806
Validation loss: 1.899135818084081

Epoch: 5| Step: 10
Training loss: 0.2271619290113449
Validation loss: 1.9244710703690846

Epoch: 5| Step: 11
Training loss: 1.9197040796279907
Validation loss: 1.9253207445144653

Epoch: 500| Step: 0
Training loss: 0.1574028730392456
Validation loss: 1.8811654994885127

Epoch: 5| Step: 1
Training loss: 0.3320348858833313
Validation loss: 1.8918762405713399

Epoch: 5| Step: 2
Training loss: 0.34126630425453186
Validation loss: 1.868614286184311

Epoch: 5| Step: 3
Training loss: 0.1751691848039627
Validation loss: 1.833509291211764

Epoch: 5| Step: 4
Training loss: 0.22722265124320984
Validation loss: 1.838201289375623

Epoch: 5| Step: 5
Training loss: 0.16749770939350128
Validation loss: 1.8650796959797542

Epoch: 5| Step: 6
Training loss: 0.5766586661338806
Validation loss: 1.8802792181571324

Epoch: 5| Step: 7
Training loss: 0.25272607803344727
Validation loss: 1.9185482064882915

Epoch: 5| Step: 8
Training loss: 0.393623411655426
Validation loss: 1.8962468802928925

Epoch: 5| Step: 9
Training loss: 0.21833226084709167
Validation loss: 1.9082209765911102

Epoch: 5| Step: 10
Training loss: 0.23175950348377228
Validation loss: 1.91252101957798

Epoch: 5| Step: 11
Training loss: 0.28318023681640625
Validation loss: 1.902427206436793

Testing loss: 2.0928022621346893
