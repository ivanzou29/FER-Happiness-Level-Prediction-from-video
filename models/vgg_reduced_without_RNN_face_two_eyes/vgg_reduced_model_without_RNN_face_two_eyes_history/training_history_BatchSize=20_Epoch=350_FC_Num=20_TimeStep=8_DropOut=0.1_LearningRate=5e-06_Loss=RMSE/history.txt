Epoch: 1| Step: 0
Training loss: 7.897280705502617
Validation loss: 7.125570263266059

Epoch: 5| Step: 1
Training loss: 7.969702330885384
Validation loss: 7.095486466207843

Epoch: 5| Step: 2
Training loss: 7.0351101600031045
Validation loss: 7.068294927157948

Epoch: 5| Step: 3
Training loss: 6.731102663940713
Validation loss: 7.040053523304524

Epoch: 5| Step: 4
Training loss: 7.197248929339523
Validation loss: 7.015222120151308

Epoch: 5| Step: 5
Training loss: 7.317387439212637
Validation loss: 6.98835824007484

Epoch: 5| Step: 6
Training loss: 6.656615341261178
Validation loss: 6.960384462524315

Epoch: 5| Step: 7
Training loss: 6.363372970678745
Validation loss: 6.932973387281922

Epoch: 5| Step: 8
Training loss: 7.2334052274210405
Validation loss: 6.9015812117110125

Epoch: 5| Step: 9
Training loss: 7.360240067422914
Validation loss: 6.874547007115418

Epoch: 5| Step: 10
Training loss: 6.229327077511908
Validation loss: 6.842059282226861

Epoch: 5| Step: 11
Training loss: 6.186008774591754
Validation loss: 6.810715631236284

Epoch: 2| Step: 0
Training loss: 6.460963773846971
Validation loss: 6.7759054191275725

Epoch: 5| Step: 1
Training loss: 7.135504758713366
Validation loss: 6.744772935838847

Epoch: 5| Step: 2
Training loss: 7.623875769612742
Validation loss: 6.708131084197103

Epoch: 5| Step: 3
Training loss: 7.305456959389881
Validation loss: 6.672402020856179

Epoch: 5| Step: 4
Training loss: 6.757214681830647
Validation loss: 6.633043983832391

Epoch: 5| Step: 5
Training loss: 6.52231815808409
Validation loss: 6.597305207204626

Epoch: 5| Step: 6
Training loss: 5.76545892905306
Validation loss: 6.558760603962857

Epoch: 5| Step: 7
Training loss: 6.120872508166664
Validation loss: 6.517992731414735

Epoch: 5| Step: 8
Training loss: 6.275478159403504
Validation loss: 6.473344949239778

Epoch: 5| Step: 9
Training loss: 6.547332674840137
Validation loss: 6.427642719608699

Epoch: 5| Step: 10
Training loss: 7.344184245804848
Validation loss: 6.3820071387391

Epoch: 5| Step: 11
Training loss: 3.445190704338123
Validation loss: 6.3281308146634485

Epoch: 3| Step: 0
Training loss: 6.4241573983526115
Validation loss: 6.27998434192382

Epoch: 5| Step: 1
Training loss: 6.845898991937618
Validation loss: 6.231160902523348

Epoch: 5| Step: 2
Training loss: 6.832333313255287
Validation loss: 6.179738503883429

Epoch: 5| Step: 3
Training loss: 6.696618254381974
Validation loss: 6.1224106226366155

Epoch: 5| Step: 4
Training loss: 6.280894710684077
Validation loss: 6.062025654644002

Epoch: 5| Step: 5
Training loss: 5.734711598176303
Validation loss: 6.001554857226154

Epoch: 5| Step: 6
Training loss: 5.668476526294379
Validation loss: 5.937928114063083

Epoch: 5| Step: 7
Training loss: 5.550460473280943
Validation loss: 5.873718175991949

Epoch: 5| Step: 8
Training loss: 5.732752266351938
Validation loss: 5.799113880627474

Epoch: 5| Step: 9
Training loss: 4.99083384516984
Validation loss: 5.7313252168501565

Epoch: 5| Step: 10
Training loss: 5.987552128128869
Validation loss: 5.6602028019273956

Epoch: 5| Step: 11
Training loss: 5.844185389654605
Validation loss: 5.573357711404815

Epoch: 4| Step: 0
Training loss: 5.492747814090352
Validation loss: 5.501585435661503

Epoch: 5| Step: 1
Training loss: 3.9469098473926185
Validation loss: 5.40748631300879

Epoch: 5| Step: 2
Training loss: 5.730052680660496
Validation loss: 5.323883023665764

Epoch: 5| Step: 3
Training loss: 5.367812918437429
Validation loss: 5.2420455526812715

Epoch: 5| Step: 4
Training loss: 5.6739454457534855
Validation loss: 5.143821062884921

Epoch: 5| Step: 5
Training loss: 4.436329432013103
Validation loss: 5.047930360094055

Epoch: 5| Step: 6
Training loss: 5.745897903061135
Validation loss: 4.943243661664374

Epoch: 5| Step: 7
Training loss: 5.143713490019368
Validation loss: 4.839929144277611

Epoch: 5| Step: 8
Training loss: 4.48575413992535
Validation loss: 4.734379272123284

Epoch: 5| Step: 9
Training loss: 5.327466280762015
Validation loss: 4.609564911976422

Epoch: 5| Step: 10
Training loss: 4.274766007650713
Validation loss: 4.499942558416457

Epoch: 5| Step: 11
Training loss: 4.804922107458167
Validation loss: 4.365481084782994

Epoch: 5| Step: 0
Training loss: 3.9263065423206602
Validation loss: 4.237102741986401

Epoch: 5| Step: 1
Training loss: 4.232730334932387
Validation loss: 4.107350560281315

Epoch: 5| Step: 2
Training loss: 4.215549413457254
Validation loss: 3.9666218195444976

Epoch: 5| Step: 3
Training loss: 3.832616172269014
Validation loss: 3.8422534013939496

Epoch: 5| Step: 4
Training loss: 3.71757835074734
Validation loss: 3.672581771033723

Epoch: 5| Step: 5
Training loss: 4.323941077989252
Validation loss: 3.5403119619129297

Epoch: 5| Step: 6
Training loss: 3.41840705894993
Validation loss: 3.397822561935327

Epoch: 5| Step: 7
Training loss: 3.736361051295719
Validation loss: 3.2755844735196566

Epoch: 5| Step: 8
Training loss: 3.435358108444002
Validation loss: 3.154388067385834

Epoch: 5| Step: 9
Training loss: 2.5717967655338647
Validation loss: 3.039174314009349

Epoch: 5| Step: 10
Training loss: 2.2468883402591526
Validation loss: 2.924379407631116

Epoch: 5| Step: 11
Training loss: 2.6650225120581275
Validation loss: 2.8451751554335427

Epoch: 6| Step: 0
Training loss: 3.1975239234011457
Validation loss: 2.7717547975874077

Epoch: 5| Step: 1
Training loss: 2.8067688086431555
Validation loss: 2.7284472126304182

Epoch: 5| Step: 2
Training loss: 2.5264543858163835
Validation loss: 2.6998732270690438

Epoch: 5| Step: 3
Training loss: 2.647041155251273
Validation loss: 2.731791018304476

Epoch: 5| Step: 4
Training loss: 2.9424387220356127
Validation loss: 2.741726495115134

Epoch: 5| Step: 5
Training loss: 2.6955859059418334
Validation loss: 2.7341345036421023

Epoch: 5| Step: 6
Training loss: 2.955851270307377
Validation loss: 2.7738983434067612

Epoch: 5| Step: 7
Training loss: 3.054007295940805
Validation loss: 2.80135539974238

Epoch: 5| Step: 8
Training loss: 2.1291024493880593
Validation loss: 2.819276741022112

Epoch: 5| Step: 9
Training loss: 2.403999365985806
Validation loss: 2.836871341070682

Epoch: 5| Step: 10
Training loss: 3.0314957037380452
Validation loss: 2.8363521297342493

Epoch: 5| Step: 11
Training loss: 2.6269683723999884
Validation loss: 2.856674868496976

Epoch: 7| Step: 0
Training loss: 3.400900463465866
Validation loss: 2.831811213221526

Epoch: 5| Step: 1
Training loss: 2.453166402479537
Validation loss: 2.867223959404271

Epoch: 5| Step: 2
Training loss: 2.920543836612405
Validation loss: 2.836532645922074

Epoch: 5| Step: 3
Training loss: 2.380821421745535
Validation loss: 2.83789798659481

Epoch: 5| Step: 4
Training loss: 2.435795897453794
Validation loss: 2.814522796410907

Epoch: 5| Step: 5
Training loss: 3.2715662886200185
Validation loss: 2.818567269655156

Epoch: 5| Step: 6
Training loss: 2.6185687163978644
Validation loss: 2.79585694764043

Epoch: 5| Step: 7
Training loss: 2.765348000313106
Validation loss: 2.780193417479226

Epoch: 5| Step: 8
Training loss: 2.639404466244589
Validation loss: 2.734258067945971

Epoch: 5| Step: 9
Training loss: 3.282798619629077
Validation loss: 2.7311017526509014

Epoch: 5| Step: 10
Training loss: 2.595845398688609
Validation loss: 2.683527598151051

Epoch: 5| Step: 11
Training loss: 1.8991147312942993
Validation loss: 2.684589343826297

Epoch: 8| Step: 0
Training loss: 2.915172212201954
Validation loss: 2.7015442535213694

Epoch: 5| Step: 1
Training loss: 2.5159499627855237
Validation loss: 2.7036831523916423

Epoch: 5| Step: 2
Training loss: 2.7251031243645865
Validation loss: 2.6571551145915686

Epoch: 5| Step: 3
Training loss: 2.866360994794275
Validation loss: 2.714470275511455

Epoch: 5| Step: 4
Training loss: 2.4354649386966853
Validation loss: 2.7041896421360665

Epoch: 5| Step: 5
Training loss: 2.545465184474361
Validation loss: 2.6793390534996306

Epoch: 5| Step: 6
Training loss: 3.0092639938273775
Validation loss: 2.6912374272800665

Epoch: 5| Step: 7
Training loss: 2.233769901744132
Validation loss: 2.6980117955368255

Epoch: 5| Step: 8
Training loss: 2.3237225171085583
Validation loss: 2.6826697382474074

Epoch: 5| Step: 9
Training loss: 3.224057164729005
Validation loss: 2.6981711740131145

Epoch: 5| Step: 10
Training loss: 2.9960867472620247
Validation loss: 2.6787494022038216

Epoch: 5| Step: 11
Training loss: 2.643287896066045
Validation loss: 2.691843452248083

Epoch: 9| Step: 0
Training loss: 2.476565003017761
Validation loss: 2.6781751370568356

Epoch: 5| Step: 1
Training loss: 2.221627746645582
Validation loss: 2.6600209228330933

Epoch: 5| Step: 2
Training loss: 2.602169756425138
Validation loss: 2.672466963542105

Epoch: 5| Step: 3
Training loss: 2.7769470360732496
Validation loss: 2.665063612132809

Epoch: 5| Step: 4
Training loss: 3.288162652013831
Validation loss: 2.67872824891018

Epoch: 5| Step: 5
Training loss: 2.9469086953559738
Validation loss: 2.634109091018379

Epoch: 5| Step: 6
Training loss: 3.2723369341527344
Validation loss: 2.6710736669957127

Epoch: 5| Step: 7
Training loss: 2.3349700251090932
Validation loss: 2.6548024627718285

Epoch: 5| Step: 8
Training loss: 2.617958433562932
Validation loss: 2.6508034984473055

Epoch: 5| Step: 9
Training loss: 2.8680814342136887
Validation loss: 2.673195477307944

Epoch: 5| Step: 10
Training loss: 2.246765036405609
Validation loss: 2.658152373999858

Epoch: 5| Step: 11
Training loss: 3.8708390076058103
Validation loss: 2.6876057781427902

Epoch: 10| Step: 0
Training loss: 2.5435510018606196
Validation loss: 2.65425968401418

Epoch: 5| Step: 1
Training loss: 2.3320437228126454
Validation loss: 2.661447694213465

Epoch: 5| Step: 2
Training loss: 1.9978956834674382
Validation loss: 2.6652066560269474

Epoch: 5| Step: 3
Training loss: 3.2605860039527195
Validation loss: 2.650453923293432

Epoch: 5| Step: 4
Training loss: 2.950848383060297
Validation loss: 2.6517107306015553

Epoch: 5| Step: 5
Training loss: 2.6084121480943483
Validation loss: 2.6468011157440245

Epoch: 5| Step: 6
Training loss: 2.766714883483746
Validation loss: 2.659143405367459

Epoch: 5| Step: 7
Training loss: 2.888646453890003
Validation loss: 2.64981906531095

Epoch: 5| Step: 8
Training loss: 2.925880827692558
Validation loss: 2.663773603986645

Epoch: 5| Step: 9
Training loss: 2.5152308943159056
Validation loss: 2.666973823997239

Epoch: 5| Step: 10
Training loss: 2.8292264532215157
Validation loss: 2.652553559414808

Epoch: 5| Step: 11
Training loss: 1.8451751115190096
Validation loss: 2.6432044017113925

Epoch: 11| Step: 0
Training loss: 3.2206357598416497
Validation loss: 2.6166797202284817

Epoch: 5| Step: 1
Training loss: 3.2258882349168276
Validation loss: 2.6119822536664516

Epoch: 5| Step: 2
Training loss: 2.3996906796441895
Validation loss: 2.644936174188693

Epoch: 5| Step: 3
Training loss: 2.3838234679768235
Validation loss: 2.6256353086338655

Epoch: 5| Step: 4
Training loss: 2.560161547034019
Validation loss: 2.6353382254726485

Epoch: 5| Step: 5
Training loss: 2.377911640075251
Validation loss: 2.6359055609691064

Epoch: 5| Step: 6
Training loss: 2.0551072768823113
Validation loss: 2.614054555476145

Epoch: 5| Step: 7
Training loss: 2.775936923934703
Validation loss: 2.644016890134501

Epoch: 5| Step: 8
Training loss: 2.8517032954325146
Validation loss: 2.6384874830519554

Epoch: 5| Step: 9
Training loss: 3.0451808816838537
Validation loss: 2.635537221410401

Epoch: 5| Step: 10
Training loss: 2.3626337851129984
Validation loss: 2.6483030744588087

Epoch: 5| Step: 11
Training loss: 1.412476635629971
Validation loss: 2.6144321000231114

Epoch: 12| Step: 0
Training loss: 2.909413410592897
Validation loss: 2.6433017939970553

Epoch: 5| Step: 1
Training loss: 3.064327239835898
Validation loss: 2.6278541352785076

Epoch: 5| Step: 2
Training loss: 2.1719151774470618
Validation loss: 2.6373891811682957

Epoch: 5| Step: 3
Training loss: 2.9243776751622397
Validation loss: 2.668564051895744

Epoch: 5| Step: 4
Training loss: 2.1065385750969723
Validation loss: 2.6318780880338233

Epoch: 5| Step: 5
Training loss: 2.8939307203772624
Validation loss: 2.634248502265268

Epoch: 5| Step: 6
Training loss: 2.7211646395793516
Validation loss: 2.6290112796111975

Epoch: 5| Step: 7
Training loss: 2.601388461503361
Validation loss: 2.618525600454373

Epoch: 5| Step: 8
Training loss: 2.7558290951671913
Validation loss: 2.644559261862978

Epoch: 5| Step: 9
Training loss: 2.3718249530563327
Validation loss: 2.653651181640826

Epoch: 5| Step: 10
Training loss: 2.599217087905944
Validation loss: 2.643503805590818

Epoch: 5| Step: 11
Training loss: 2.917761533597864
Validation loss: 2.6413542363182008

Epoch: 13| Step: 0
Training loss: 2.5341642581418538
Validation loss: 2.612458556210029

Epoch: 5| Step: 1
Training loss: 3.9317022357629177
Validation loss: 2.5978963640567363

Epoch: 5| Step: 2
Training loss: 2.2881770064969893
Validation loss: 2.6595562871216862

Epoch: 5| Step: 3
Training loss: 3.219557873718328
Validation loss: 2.5871094835909068

Epoch: 5| Step: 4
Training loss: 2.06784209644294
Validation loss: 2.6348342000540943

Epoch: 5| Step: 5
Training loss: 2.042406519007785
Validation loss: 2.61748716622054

Epoch: 5| Step: 6
Training loss: 2.3164905449130653
Validation loss: 2.6126405037814053

Epoch: 5| Step: 7
Training loss: 2.1886225408698983
Validation loss: 2.608987033197433

Epoch: 5| Step: 8
Training loss: 2.8464481841972504
Validation loss: 2.5912316939091764

Epoch: 5| Step: 9
Training loss: 2.4680532124005596
Validation loss: 2.6067928893800922

Epoch: 5| Step: 10
Training loss: 2.8019684173579362
Validation loss: 2.600854611243035

Epoch: 5| Step: 11
Training loss: 1.439969470972056
Validation loss: 2.621924191552614

Epoch: 14| Step: 0
Training loss: 2.9751521095690623
Validation loss: 2.6056755780698833

Epoch: 5| Step: 1
Training loss: 2.531866022196239
Validation loss: 2.5878009478308073

Epoch: 5| Step: 2
Training loss: 2.2636741921229513
Validation loss: 2.5858787998632486

Epoch: 5| Step: 3
Training loss: 2.2513781671296855
Validation loss: 2.594288948091314

Epoch: 5| Step: 4
Training loss: 1.9535779504076851
Validation loss: 2.620330790465546

Epoch: 5| Step: 5
Training loss: 2.5096475417564106
Validation loss: 2.621290007216055

Epoch: 5| Step: 6
Training loss: 2.745429662767401
Validation loss: 2.624302714697561

Epoch: 5| Step: 7
Training loss: 2.4103856402625565
Validation loss: 2.598479650495439

Epoch: 5| Step: 8
Training loss: 2.850020987450136
Validation loss: 2.6043369860583416

Epoch: 5| Step: 9
Training loss: 3.0487183301218397
Validation loss: 2.602877287510065

Epoch: 5| Step: 10
Training loss: 2.901494555276104
Validation loss: 2.616266559248304

Epoch: 5| Step: 11
Training loss: 3.621885211130383
Validation loss: 2.5836395356510726

Epoch: 15| Step: 0
Training loss: 2.2389873569228675
Validation loss: 2.5720905368915608

Epoch: 5| Step: 1
Training loss: 2.6929617983222305
Validation loss: 2.6231308140393734

Epoch: 5| Step: 2
Training loss: 2.0454543913253573
Validation loss: 2.56836809318813

Epoch: 5| Step: 3
Training loss: 2.7397454410838424
Validation loss: 2.6307683040164953

Epoch: 5| Step: 4
Training loss: 3.0362666196592056
Validation loss: 2.640574426561721

Epoch: 5| Step: 5
Training loss: 3.0398828335820345
Validation loss: 2.6349365239276197

Epoch: 5| Step: 6
Training loss: 3.0875030023351737
Validation loss: 2.6050452441498377

Epoch: 5| Step: 7
Training loss: 2.135954279020942
Validation loss: 2.61164643262374

Epoch: 5| Step: 8
Training loss: 2.7943392718852422
Validation loss: 2.6034052320553442

Epoch: 5| Step: 9
Training loss: 2.5712636561719573
Validation loss: 2.627645729777166

Epoch: 5| Step: 10
Training loss: 2.725496362398555
Validation loss: 2.6287246951271257

Epoch: 5| Step: 11
Training loss: 1.3085175904843365
Validation loss: 2.6117114991363066

Epoch: 16| Step: 0
Training loss: 3.0390055437806285
Validation loss: 2.601728443584895

Epoch: 5| Step: 1
Training loss: 3.016168733111449
Validation loss: 2.6033102280262623

Epoch: 5| Step: 2
Training loss: 2.0511745112149193
Validation loss: 2.5868611064524583

Epoch: 5| Step: 3
Training loss: 2.3065804676347876
Validation loss: 2.641912864821019

Epoch: 5| Step: 4
Training loss: 2.3677856898114693
Validation loss: 2.607297771038774

Epoch: 5| Step: 5
Training loss: 2.821249512962668
Validation loss: 2.6053523848368885

Epoch: 5| Step: 6
Training loss: 2.455036948988434
Validation loss: 2.588804018067042

Epoch: 5| Step: 7
Training loss: 2.5355828018946003
Validation loss: 2.616021138390901

Epoch: 5| Step: 8
Training loss: 2.420291900054563
Validation loss: 2.6067877485327946

Epoch: 5| Step: 9
Training loss: 2.955044238796954
Validation loss: 2.6515634893783795

Epoch: 5| Step: 10
Training loss: 2.885333853037018
Validation loss: 2.6377110777968364

Epoch: 5| Step: 11
Training loss: 1.4532754471534541
Validation loss: 2.6096751712371877

Epoch: 17| Step: 0
Training loss: 2.097868214274698
Validation loss: 2.6122073070403284

Epoch: 5| Step: 1
Training loss: 2.0371540829076538
Validation loss: 2.5651246484755266

Epoch: 5| Step: 2
Training loss: 2.929401515989627
Validation loss: 2.579564087856072

Epoch: 5| Step: 3
Training loss: 2.8578732408478853
Validation loss: 2.5833620613305595

Epoch: 5| Step: 4
Training loss: 3.054661743367675
Validation loss: 2.593706111460042

Epoch: 5| Step: 5
Training loss: 3.1726142510417312
Validation loss: 2.59724894607336

Epoch: 5| Step: 6
Training loss: 2.2160722934760293
Validation loss: 2.6150640727083756

Epoch: 5| Step: 7
Training loss: 2.266898487895973
Validation loss: 2.5904014259316686

Epoch: 5| Step: 8
Training loss: 2.6609830985695497
Validation loss: 2.5917273605288584

Epoch: 5| Step: 9
Training loss: 2.240374214044948
Validation loss: 2.5866615802941832

Epoch: 5| Step: 10
Training loss: 2.8153364501503484
Validation loss: 2.5932260466678994

Epoch: 5| Step: 11
Training loss: 2.8528895804306695
Validation loss: 2.577950731803269

Epoch: 18| Step: 0
Training loss: 2.420472852838748
Validation loss: 2.606199216462235

Epoch: 5| Step: 1
Training loss: 2.4222554554054483
Validation loss: 2.6047689631461024

Epoch: 5| Step: 2
Training loss: 2.519635906559425
Validation loss: 2.5933836904256253

Epoch: 5| Step: 3
Training loss: 2.6907789941686002
Validation loss: 2.5792286504642243

Epoch: 5| Step: 4
Training loss: 3.1733866880510186
Validation loss: 2.551921544818007

Epoch: 5| Step: 5
Training loss: 2.5612894315649086
Validation loss: 2.5945681962841367

Epoch: 5| Step: 6
Training loss: 2.5659836140954595
Validation loss: 2.5894355279586687

Epoch: 5| Step: 7
Training loss: 2.303977210296401
Validation loss: 2.6052899277843893

Epoch: 5| Step: 8
Training loss: 2.9335001233394915
Validation loss: 2.5632804364458224

Epoch: 5| Step: 9
Training loss: 2.743666290883197
Validation loss: 2.582196917583834

Epoch: 5| Step: 10
Training loss: 1.533681612611997
Validation loss: 2.6005213031479326

Epoch: 5| Step: 11
Training loss: 3.696393167498618
Validation loss: 2.566638668922169

Epoch: 19| Step: 0
Training loss: 2.889540515262463
Validation loss: 2.58560376736501

Epoch: 5| Step: 1
Training loss: 3.2861844697834295
Validation loss: 2.60126384437515

Epoch: 5| Step: 2
Training loss: 2.5007100050745548
Validation loss: 2.62248459899036

Epoch: 5| Step: 3
Training loss: 2.595945417291763
Validation loss: 2.6030176539763397

Epoch: 5| Step: 4
Training loss: 2.4714085231601004
Validation loss: 2.575431572756245

Epoch: 5| Step: 5
Training loss: 2.2581196612335366
Validation loss: 2.566854997997685

Epoch: 5| Step: 6
Training loss: 2.255323681660266
Validation loss: 2.5661014335223227

Epoch: 5| Step: 7
Training loss: 2.518677654126611
Validation loss: 2.5259601317680263

Epoch: 5| Step: 8
Training loss: 2.8270141780512583
Validation loss: 2.5601276837298506

Epoch: 5| Step: 9
Training loss: 2.015492871115968
Validation loss: 2.566695562319742

Epoch: 5| Step: 10
Training loss: 2.4051529997062246
Validation loss: 2.557301761480375

Epoch: 5| Step: 11
Training loss: 2.249300742104127
Validation loss: 2.572576825996919

Epoch: 20| Step: 0
Training loss: 2.3740866059122245
Validation loss: 2.575062738351797

Epoch: 5| Step: 1
Training loss: 2.6206784779254906
Validation loss: 2.585819691167069

Epoch: 5| Step: 2
Training loss: 2.5839388865693294
Validation loss: 2.5564177328292947

Epoch: 5| Step: 3
Training loss: 2.1559065393209003
Validation loss: 2.5901592210177813

Epoch: 5| Step: 4
Training loss: 2.8710460840537295
Validation loss: 2.559974484223373

Epoch: 5| Step: 5
Training loss: 2.7751017989998155
Validation loss: 2.574914258467655

Epoch: 5| Step: 6
Training loss: 2.3716149550711614
Validation loss: 2.53853471405701

Epoch: 5| Step: 7
Training loss: 2.369238339615921
Validation loss: 2.5527500540289045

Epoch: 5| Step: 8
Training loss: 2.2948650466700604
Validation loss: 2.5810426597974088

Epoch: 5| Step: 9
Training loss: 2.934255878277166
Validation loss: 2.5717644537539983

Epoch: 5| Step: 10
Training loss: 2.7135552072217695
Validation loss: 2.578784133961356

Epoch: 5| Step: 11
Training loss: 2.162054128380377
Validation loss: 2.574621399650878

Epoch: 21| Step: 0
Training loss: 2.599516742984762
Validation loss: 2.5598046017155403

Epoch: 5| Step: 1
Training loss: 2.5853244942324967
Validation loss: 2.563659572305396

Epoch: 5| Step: 2
Training loss: 2.5946420261680645
Validation loss: 2.556018980106263

Epoch: 5| Step: 3
Training loss: 2.29219814264262
Validation loss: 2.5815971921504475

Epoch: 5| Step: 4
Training loss: 2.7547748900176274
Validation loss: 2.553012368695592

Epoch: 5| Step: 5
Training loss: 1.9472122414635915
Validation loss: 2.555795205813127

Epoch: 5| Step: 6
Training loss: 1.7821113779131073
Validation loss: 2.543108446509999

Epoch: 5| Step: 7
Training loss: 3.0671221049367756
Validation loss: 2.5537021342624815

Epoch: 5| Step: 8
Training loss: 3.2082934851875953
Validation loss: 2.5492676961215452

Epoch: 5| Step: 9
Training loss: 2.2847968968250134
Validation loss: 2.546843066337109

Epoch: 5| Step: 10
Training loss: 2.6282508339167108
Validation loss: 2.543643719251673

Epoch: 5| Step: 11
Training loss: 1.0662983710529756
Validation loss: 2.5170833514796143

Epoch: 22| Step: 0
Training loss: 2.3136511334647696
Validation loss: 2.566312301441257

Epoch: 5| Step: 1
Training loss: 3.6360792341422443
Validation loss: 2.492699876370546

Epoch: 5| Step: 2
Training loss: 2.3444512907513797
Validation loss: 2.5876486419209015

Epoch: 5| Step: 3
Training loss: 2.177763605990761
Validation loss: 2.5600365373368392

Epoch: 5| Step: 4
Training loss: 2.4053944639732654
Validation loss: 2.544839037437258

Epoch: 5| Step: 5
Training loss: 2.404934907694552
Validation loss: 2.5752587926006156

Epoch: 5| Step: 6
Training loss: 1.8636961660918916
Validation loss: 2.5797794197044635

Epoch: 5| Step: 7
Training loss: 2.8406208974139275
Validation loss: 2.5506030454207194

Epoch: 5| Step: 8
Training loss: 2.653060434227531
Validation loss: 2.5241450409284503

Epoch: 5| Step: 9
Training loss: 2.6447261586339326
Validation loss: 2.5488419572593717

Epoch: 5| Step: 10
Training loss: 2.2063191303088603
Validation loss: 2.54580370677144

Epoch: 5| Step: 11
Training loss: 1.8734733724460575
Validation loss: 2.557935044621908

Epoch: 23| Step: 0
Training loss: 2.7308554532417575
Validation loss: 2.6029118617415308

Epoch: 5| Step: 1
Training loss: 2.4736477519720106
Validation loss: 2.579499573758504

Epoch: 5| Step: 2
Training loss: 2.283957977429439
Validation loss: 2.5984862070112085

Epoch: 5| Step: 3
Training loss: 2.7323080915819538
Validation loss: 2.595943859792548

Epoch: 5| Step: 4
Training loss: 3.1557007868871003
Validation loss: 2.571608702576428

Epoch: 5| Step: 5
Training loss: 2.303918535646711
Validation loss: 2.614752252347682

Epoch: 5| Step: 6
Training loss: 2.6771354422835176
Validation loss: 2.5963939840974346

Epoch: 5| Step: 7
Training loss: 1.7496151500963448
Validation loss: 2.5535056893000414

Epoch: 5| Step: 8
Training loss: 2.6647418545914214
Validation loss: 2.576499453471702

Epoch: 5| Step: 9
Training loss: 2.0693092074429815
Validation loss: 2.5459017112797704

Epoch: 5| Step: 10
Training loss: 2.9409657587978453
Validation loss: 2.500966099989403

Epoch: 5| Step: 11
Training loss: 0.7161968744757831
Validation loss: 2.550332018641948

Epoch: 24| Step: 0
Training loss: 2.3399491071464875
Validation loss: 2.5722219723661763

Epoch: 5| Step: 1
Training loss: 2.37399180244888
Validation loss: 2.5726597743932618

Epoch: 5| Step: 2
Training loss: 2.4272929961930174
Validation loss: 2.5371249900535076

Epoch: 5| Step: 3
Training loss: 2.4543912498765765
Validation loss: 2.5597618329253744

Epoch: 5| Step: 4
Training loss: 2.465556529826485
Validation loss: 2.5340682086667803

Epoch: 5| Step: 5
Training loss: 2.4115011212787083
Validation loss: 2.5538620290801037

Epoch: 5| Step: 6
Training loss: 2.681114417429466
Validation loss: 2.5941869873168417

Epoch: 5| Step: 7
Training loss: 2.755595150615242
Validation loss: 2.528682811923706

Epoch: 5| Step: 8
Training loss: 2.4357205277783653
Validation loss: 2.546395691623892

Epoch: 5| Step: 9
Training loss: 2.1387270567581376
Validation loss: 2.540725089334704

Epoch: 5| Step: 10
Training loss: 2.367956458361574
Validation loss: 2.5436628208014684

Epoch: 5| Step: 11
Training loss: 4.484428378860771
Validation loss: 2.5304625271324848

Epoch: 25| Step: 0
Training loss: 2.4446272697377727
Validation loss: 2.5283244459448238

Epoch: 5| Step: 1
Training loss: 2.6668961744091435
Validation loss: 2.5785721034758105

Epoch: 5| Step: 2
Training loss: 2.6366691076055995
Validation loss: 2.5435485725726723

Epoch: 5| Step: 3
Training loss: 2.227720902917411
Validation loss: 2.5765912435488683

Epoch: 5| Step: 4
Training loss: 2.4421194270843056
Validation loss: 2.577584566442758

Epoch: 5| Step: 5
Training loss: 2.937117044362992
Validation loss: 2.5853964286604345

Epoch: 5| Step: 6
Training loss: 2.1453376740758845
Validation loss: 2.5942506153845715

Epoch: 5| Step: 7
Training loss: 2.540009119663237
Validation loss: 2.6245730332893484

Epoch: 5| Step: 8
Training loss: 2.830551539617786
Validation loss: 2.628726756603364

Epoch: 5| Step: 9
Training loss: 2.279238924860472
Validation loss: 2.5699688083553105

Epoch: 5| Step: 10
Training loss: 2.1301090307492805
Validation loss: 2.566712324915026

Epoch: 5| Step: 11
Training loss: 2.2661583634379863
Validation loss: 2.5547036336686832

Epoch: 26| Step: 0
Training loss: 2.6984962125662912
Validation loss: 2.5594706151457505

Epoch: 5| Step: 1
Training loss: 2.429570235093482
Validation loss: 2.5576170981651

Epoch: 5| Step: 2
Training loss: 2.524288730719768
Validation loss: 2.5150833494507587

Epoch: 5| Step: 3
Training loss: 2.2392808103648942
Validation loss: 2.5210324962745396

Epoch: 5| Step: 4
Training loss: 1.963645493842583
Validation loss: 2.527294549556471

Epoch: 5| Step: 5
Training loss: 2.1438137167311617
Validation loss: 2.5586255525354846

Epoch: 5| Step: 6
Training loss: 2.797141462025391
Validation loss: 2.564275111237097

Epoch: 5| Step: 7
Training loss: 2.647891548171659
Validation loss: 2.5573821210434677

Epoch: 5| Step: 8
Training loss: 3.020637733879377
Validation loss: 2.5416978393790144

Epoch: 5| Step: 9
Training loss: 2.355110508134105
Validation loss: 2.525582019371278

Epoch: 5| Step: 10
Training loss: 2.416471396701786
Validation loss: 2.5648352480408647

Epoch: 5| Step: 11
Training loss: 2.7135668049903
Validation loss: 2.561159729329469

Epoch: 27| Step: 0
Training loss: 2.2341584854327157
Validation loss: 2.5439365340439553

Epoch: 5| Step: 1
Training loss: 1.9231389549227602
Validation loss: 2.5821920547774497

Epoch: 5| Step: 2
Training loss: 2.6356238684539863
Validation loss: 2.5219732234692005

Epoch: 5| Step: 3
Training loss: 2.0080741978953194
Validation loss: 2.5920040581537984

Epoch: 5| Step: 4
Training loss: 2.0223946848304535
Validation loss: 2.580568015375661

Epoch: 5| Step: 5
Training loss: 2.670021886843009
Validation loss: 2.5598485883438737

Epoch: 5| Step: 6
Training loss: 2.837166343935297
Validation loss: 2.5625176622976085

Epoch: 5| Step: 7
Training loss: 2.420039114833018
Validation loss: 2.5613472291715755

Epoch: 5| Step: 8
Training loss: 2.8483929302601934
Validation loss: 2.5666118870396804

Epoch: 5| Step: 9
Training loss: 2.5482816029851945
Validation loss: 2.531960832997099

Epoch: 5| Step: 10
Training loss: 2.6168780243507404
Validation loss: 2.57430829059817

Epoch: 5| Step: 11
Training loss: 3.628970372482458
Validation loss: 2.5352099412464772

Epoch: 28| Step: 0
Training loss: 2.401434501458435
Validation loss: 2.512982400129201

Epoch: 5| Step: 1
Training loss: 2.8715192207066447
Validation loss: 2.51186434500305

Epoch: 5| Step: 2
Training loss: 2.6649117556449697
Validation loss: 2.5322739449219216

Epoch: 5| Step: 3
Training loss: 2.501462794550083
Validation loss: 2.552380067091904

Epoch: 5| Step: 4
Training loss: 2.4975931025383553
Validation loss: 2.516380445412585

Epoch: 5| Step: 5
Training loss: 2.647020709318135
Validation loss: 2.578628960877008

Epoch: 5| Step: 6
Training loss: 2.373631635289091
Validation loss: 2.583787506439081

Epoch: 5| Step: 7
Training loss: 2.679225247831803
Validation loss: 2.5503587553004303

Epoch: 5| Step: 8
Training loss: 2.390541424256527
Validation loss: 2.55512652187782

Epoch: 5| Step: 9
Training loss: 2.223845527402597
Validation loss: 2.581042890729826

Epoch: 5| Step: 10
Training loss: 1.91743446257993
Validation loss: 2.5718226803308935

Epoch: 5| Step: 11
Training loss: 2.3317620459084187
Validation loss: 2.5405732262572873

Epoch: 29| Step: 0
Training loss: 2.3880277000558707
Validation loss: 2.5644583507134993

Epoch: 5| Step: 1
Training loss: 2.269937869494662
Validation loss: 2.584681756335253

Epoch: 5| Step: 2
Training loss: 1.7245701821043817
Validation loss: 2.6167881940959723

Epoch: 5| Step: 3
Training loss: 2.239312857921616
Validation loss: 2.642896168345798

Epoch: 5| Step: 4
Training loss: 2.8958175622158406
Validation loss: 2.6516845850356097

Epoch: 5| Step: 5
Training loss: 2.6860381297844156
Validation loss: 2.67929486511336

Epoch: 5| Step: 6
Training loss: 2.7420176048576206
Validation loss: 2.6408493428233037

Epoch: 5| Step: 7
Training loss: 2.3187835485288355
Validation loss: 2.636218315954259

Epoch: 5| Step: 8
Training loss: 3.2994763565754033
Validation loss: 2.5797811448436834

Epoch: 5| Step: 9
Training loss: 2.3101066369878622
Validation loss: 2.569844273798138

Epoch: 5| Step: 10
Training loss: 2.478294561100353
Validation loss: 2.5190852379128597

Epoch: 5| Step: 11
Training loss: 1.368668544209328
Validation loss: 2.550836267505974

Epoch: 30| Step: 0
Training loss: 2.3438706430538416
Validation loss: 2.5141148644923614

Epoch: 5| Step: 1
Training loss: 2.9266178580046955
Validation loss: 2.4919758052064704

Epoch: 5| Step: 2
Training loss: 2.5231870166715455
Validation loss: 2.5052206444916947

Epoch: 5| Step: 3
Training loss: 2.8629071874734104
Validation loss: 2.5427513127260912

Epoch: 5| Step: 4
Training loss: 2.9893629322928987
Validation loss: 2.5792895259056325

Epoch: 5| Step: 5
Training loss: 2.1939050907620703
Validation loss: 2.4916318714514882

Epoch: 5| Step: 6
Training loss: 2.1832322041432635
Validation loss: 2.5502591535924193

Epoch: 5| Step: 7
Training loss: 2.7201693984182875
Validation loss: 2.567895964962478

Epoch: 5| Step: 8
Training loss: 1.9669589418160927
Validation loss: 2.5462613760997272

Epoch: 5| Step: 9
Training loss: 2.184303564123288
Validation loss: 2.507995939428418

Epoch: 5| Step: 10
Training loss: 1.6705684369434246
Validation loss: 2.5357977668214424

Epoch: 5| Step: 11
Training loss: 3.510666669476378
Validation loss: 2.5378023825565394

Epoch: 31| Step: 0
Training loss: 3.0745914528980736
Validation loss: 2.5732080156927415

Epoch: 5| Step: 1
Training loss: 2.823953069956138
Validation loss: 2.5681790790200556

Epoch: 5| Step: 2
Training loss: 2.0629402615528147
Validation loss: 2.5883947608345608

Epoch: 5| Step: 3
Training loss: 2.6319012522333676
Validation loss: 2.57552660615825

Epoch: 5| Step: 4
Training loss: 2.3197583908026322
Validation loss: 2.610017423297561

Epoch: 5| Step: 5
Training loss: 2.52950217102404
Validation loss: 2.5755355662254606

Epoch: 5| Step: 6
Training loss: 2.1366032598830373
Validation loss: 2.5914590860277764

Epoch: 5| Step: 7
Training loss: 2.6026407476030924
Validation loss: 2.5459746269021553

Epoch: 5| Step: 8
Training loss: 2.1911824429984463
Validation loss: 2.5318467414011585

Epoch: 5| Step: 9
Training loss: 1.7800434108326832
Validation loss: 2.5439133030103407

Epoch: 5| Step: 10
Training loss: 2.6352190287870565
Validation loss: 2.526039042258456

Epoch: 5| Step: 11
Training loss: 3.06966760283496
Validation loss: 2.5542235580215196

Epoch: 32| Step: 0
Training loss: 2.0721122548319517
Validation loss: 2.5037865057137774

Epoch: 5| Step: 1
Training loss: 3.0604007298985336
Validation loss: 2.475960579136688

Epoch: 5| Step: 2
Training loss: 2.0878104612914057
Validation loss: 2.5163990551619584

Epoch: 5| Step: 3
Training loss: 2.3059047781745674
Validation loss: 2.514932671442657

Epoch: 5| Step: 4
Training loss: 3.175022912130511
Validation loss: 2.5140099287019106

Epoch: 5| Step: 5
Training loss: 2.6773513085887797
Validation loss: 2.5392517371450123

Epoch: 5| Step: 6
Training loss: 1.9834204352777534
Validation loss: 2.5556175957511305

Epoch: 5| Step: 7
Training loss: 2.319462989941108
Validation loss: 2.4741278071664063

Epoch: 5| Step: 8
Training loss: 2.681594125854368
Validation loss: 2.5359194820921145

Epoch: 5| Step: 9
Training loss: 1.9629920439828559
Validation loss: 2.5495104347833912

Epoch: 5| Step: 10
Training loss: 2.6574691667320147
Validation loss: 2.562462248175192

Epoch: 5| Step: 11
Training loss: 2.1032690897267634
Validation loss: 2.4945695010967173

Epoch: 33| Step: 0
Training loss: 2.6623869070471637
Validation loss: 2.5068322203841054

Epoch: 5| Step: 1
Training loss: 2.4875733522881123
Validation loss: 2.5402916969989544

Epoch: 5| Step: 2
Training loss: 2.3619336534269793
Validation loss: 2.5408464199987364

Epoch: 5| Step: 3
Training loss: 2.1351520157237105
Validation loss: 2.5722590788900606

Epoch: 5| Step: 4
Training loss: 2.445075075365995
Validation loss: 2.512602912003498

Epoch: 5| Step: 5
Training loss: 2.2846591506595426
Validation loss: 2.5248658239010067

Epoch: 5| Step: 6
Training loss: 2.820812064860265
Validation loss: 2.541502119949891

Epoch: 5| Step: 7
Training loss: 2.6586670593323922
Validation loss: 2.5188499456096065

Epoch: 5| Step: 8
Training loss: 2.492990681244854
Validation loss: 2.5486230214736008

Epoch: 5| Step: 9
Training loss: 2.142923054362649
Validation loss: 2.464817556815365

Epoch: 5| Step: 10
Training loss: 2.659584286407853
Validation loss: 2.5451170582259337

Epoch: 5| Step: 11
Training loss: 3.018607764516373
Validation loss: 2.557701009450031

Epoch: 34| Step: 0
Training loss: 2.3096444309592195
Validation loss: 2.5179267564965198

Epoch: 5| Step: 1
Training loss: 1.8530914818239668
Validation loss: 2.532490779392971

Epoch: 5| Step: 2
Training loss: 2.7173839952121788
Validation loss: 2.5399473047359704

Epoch: 5| Step: 3
Training loss: 1.8776883244447422
Validation loss: 2.5220962558135676

Epoch: 5| Step: 4
Training loss: 2.6959488711786657
Validation loss: 2.5080959104468143

Epoch: 5| Step: 5
Training loss: 2.815200357031793
Validation loss: 2.537554135394981

Epoch: 5| Step: 6
Training loss: 2.3836150271886094
Validation loss: 2.5385234358337305

Epoch: 5| Step: 7
Training loss: 2.4442461997860314
Validation loss: 2.463448838601397

Epoch: 5| Step: 8
Training loss: 2.6209914163320116
Validation loss: 2.515914209299342

Epoch: 5| Step: 9
Training loss: 2.8832471566377667
Validation loss: 2.5393742550901948

Epoch: 5| Step: 10
Training loss: 1.9338357793206267
Validation loss: 2.5087367857043485

Epoch: 5| Step: 11
Training loss: 2.0183532939189526
Validation loss: 2.4890102155086757

Epoch: 35| Step: 0
Training loss: 2.4059477777307388
Validation loss: 2.4855413757867693

Epoch: 5| Step: 1
Training loss: 2.0797223140516747
Validation loss: 2.509029237846074

Epoch: 5| Step: 2
Training loss: 2.496753778487059
Validation loss: 2.5026675456764793

Epoch: 5| Step: 3
Training loss: 2.8033420236326574
Validation loss: 2.5075311235529156

Epoch: 5| Step: 4
Training loss: 2.8387900894136098
Validation loss: 2.509868112096868

Epoch: 5| Step: 5
Training loss: 1.608000974294263
Validation loss: 2.507489533191767

Epoch: 5| Step: 6
Training loss: 2.2862591030300448
Validation loss: 2.4778361530179716

Epoch: 5| Step: 7
Training loss: 2.561433895987875
Validation loss: 2.541352034986401

Epoch: 5| Step: 8
Training loss: 2.2675371190979026
Validation loss: 2.5244251361655694

Epoch: 5| Step: 9
Training loss: 2.731591513645152
Validation loss: 2.4806915743810225

Epoch: 5| Step: 10
Training loss: 2.4654140870523125
Validation loss: 2.4979420536290005

Epoch: 5| Step: 11
Training loss: 1.6100524661596034
Validation loss: 2.5166334693710724

Epoch: 36| Step: 0
Training loss: 2.1214528491129663
Validation loss: 2.5026210317265054

Epoch: 5| Step: 1
Training loss: 2.829830266762316
Validation loss: 2.5006734517126277

Epoch: 5| Step: 2
Training loss: 1.9583498230368412
Validation loss: 2.546888335803482

Epoch: 5| Step: 3
Training loss: 2.41879263354833
Validation loss: 2.572576015073461

Epoch: 5| Step: 4
Training loss: 2.4390169949535743
Validation loss: 2.560155260995599

Epoch: 5| Step: 5
Training loss: 2.452770231798641
Validation loss: 2.5351545728649514

Epoch: 5| Step: 6
Training loss: 1.9791955109217687
Validation loss: 2.5363262476332253

Epoch: 5| Step: 7
Training loss: 3.033258146534928
Validation loss: 2.5802542977415706

Epoch: 5| Step: 8
Training loss: 1.8073516601220547
Validation loss: 2.5423177695508388

Epoch: 5| Step: 9
Training loss: 2.0377059457991993
Validation loss: 2.513018914783648

Epoch: 5| Step: 10
Training loss: 2.9159080245343723
Validation loss: 2.547546177365382

Epoch: 5| Step: 11
Training loss: 2.5645605966865257
Validation loss: 2.55098551019491

Epoch: 37| Step: 0
Training loss: 2.927970036952646
Validation loss: 2.544965566522104

Epoch: 5| Step: 1
Training loss: 2.9299809423354155
Validation loss: 2.512072568408373

Epoch: 5| Step: 2
Training loss: 1.9757007635276613
Validation loss: 2.5548076465286003

Epoch: 5| Step: 3
Training loss: 2.334665111403253
Validation loss: 2.495511308910274

Epoch: 5| Step: 4
Training loss: 2.2611551323723478
Validation loss: 2.4568913414385074

Epoch: 5| Step: 5
Training loss: 2.4059626420086433
Validation loss: 2.497915388260218

Epoch: 5| Step: 6
Training loss: 2.6031730180320904
Validation loss: 2.5234360355337517

Epoch: 5| Step: 7
Training loss: 1.7296270041151236
Validation loss: 2.5395793643030617

Epoch: 5| Step: 8
Training loss: 2.4472265582912835
Validation loss: 2.4798896153524375

Epoch: 5| Step: 9
Training loss: 2.595606403830746
Validation loss: 2.4774971871852465

Epoch: 5| Step: 10
Training loss: 2.325550166020186
Validation loss: 2.544392239587099

Epoch: 5| Step: 11
Training loss: 1.867459265431909
Validation loss: 2.558735128675367

Epoch: 38| Step: 0
Training loss: 2.4197794061799835
Validation loss: 2.5525200736103084

Epoch: 5| Step: 1
Training loss: 2.104155348442029
Validation loss: 2.5012835724182247

Epoch: 5| Step: 2
Training loss: 2.508713985045854
Validation loss: 2.5646457023587623

Epoch: 5| Step: 3
Training loss: 2.9191166714819112
Validation loss: 2.5384005970056824

Epoch: 5| Step: 4
Training loss: 2.7277659735992885
Validation loss: 2.4743451040333913

Epoch: 5| Step: 5
Training loss: 2.4497484428337746
Validation loss: 2.5357441350330063

Epoch: 5| Step: 6
Training loss: 2.637739241176686
Validation loss: 2.525454491606494

Epoch: 5| Step: 7
Training loss: 2.2926902796860493
Validation loss: 2.523178524274543

Epoch: 5| Step: 8
Training loss: 2.010198222202877
Validation loss: 2.479631141353847

Epoch: 5| Step: 9
Training loss: 2.1816435756680472
Validation loss: 2.5308732588349354

Epoch: 5| Step: 10
Training loss: 2.015435498223041
Validation loss: 2.565478737425981

Epoch: 5| Step: 11
Training loss: 1.7174880510161639
Validation loss: 2.600718165517095

Epoch: 39| Step: 0
Training loss: 3.124430490097543
Validation loss: 2.538682574677947

Epoch: 5| Step: 1
Training loss: 2.5862386015340775
Validation loss: 2.531095963174968

Epoch: 5| Step: 2
Training loss: 2.171841847557787
Validation loss: 2.5515849359899887

Epoch: 5| Step: 3
Training loss: 2.2009851330779755
Validation loss: 2.5267922194177475

Epoch: 5| Step: 4
Training loss: 2.5516056054813943
Validation loss: 2.5141612290176174

Epoch: 5| Step: 5
Training loss: 2.120562464036227
Validation loss: 2.510197647058894

Epoch: 5| Step: 6
Training loss: 2.122023685959512
Validation loss: 2.5231920010692703

Epoch: 5| Step: 7
Training loss: 2.5481510827023386
Validation loss: 2.522194090505198

Epoch: 5| Step: 8
Training loss: 2.227872443097042
Validation loss: 2.534260423534289

Epoch: 5| Step: 9
Training loss: 1.850238439298319
Validation loss: 2.51642216122056

Epoch: 5| Step: 10
Training loss: 2.3891235822774095
Validation loss: 2.542564781905289

Epoch: 5| Step: 11
Training loss: 3.6912513660049884
Validation loss: 2.532753548866622

Epoch: 40| Step: 0
Training loss: 2.013085710105983
Validation loss: 2.5955114167056106

Epoch: 5| Step: 1
Training loss: 1.9006184424726567
Validation loss: 2.581736597359128

Epoch: 5| Step: 2
Training loss: 2.275472772122295
Validation loss: 2.531714063263106

Epoch: 5| Step: 3
Training loss: 2.883611635510775
Validation loss: 2.595995251033208

Epoch: 5| Step: 4
Training loss: 2.654714522019347
Validation loss: 2.5624761774149794

Epoch: 5| Step: 5
Training loss: 2.506501517672244
Validation loss: 2.531494177904968

Epoch: 5| Step: 6
Training loss: 2.1732965660885686
Validation loss: 2.512206481597415

Epoch: 5| Step: 7
Training loss: 2.281065528413371
Validation loss: 2.5823298256165277

Epoch: 5| Step: 8
Training loss: 2.6354949597777484
Validation loss: 2.51171316934285

Epoch: 5| Step: 9
Training loss: 2.321452467659166
Validation loss: 2.461031069313879

Epoch: 5| Step: 10
Training loss: 2.2066140109614962
Validation loss: 2.512055421436781

Epoch: 5| Step: 11
Training loss: 2.426483396676541
Validation loss: 2.496417331566304

Epoch: 41| Step: 0
Training loss: 2.1422184491860774
Validation loss: 2.5046186777592165

Epoch: 5| Step: 1
Training loss: 2.9596741731553284
Validation loss: 2.5748098405818616

Epoch: 5| Step: 2
Training loss: 2.1039521765839972
Validation loss: 2.582058239371115

Epoch: 5| Step: 3
Training loss: 2.617745957646233
Validation loss: 2.5036507712730076

Epoch: 5| Step: 4
Training loss: 2.2961114146152437
Validation loss: 2.5510732650097925

Epoch: 5| Step: 5
Training loss: 2.2581007618346316
Validation loss: 2.4921123967668164

Epoch: 5| Step: 6
Training loss: 2.438986105153199
Validation loss: 2.486326388957538

Epoch: 5| Step: 7
Training loss: 2.07353242198358
Validation loss: 2.54422366132057

Epoch: 5| Step: 8
Training loss: 2.566665055740974
Validation loss: 2.563565106512733

Epoch: 5| Step: 9
Training loss: 2.9940769216152128
Validation loss: 2.5586063491472255

Epoch: 5| Step: 10
Training loss: 1.9281235507854537
Validation loss: 2.5483530276526936

Epoch: 5| Step: 11
Training loss: 2.8364452401451006
Validation loss: 2.5227539979220484

Epoch: 42| Step: 0
Training loss: 2.493908900502163
Validation loss: 2.5136922397297417

Epoch: 5| Step: 1
Training loss: 2.328294376638115
Validation loss: 2.459397329530406

Epoch: 5| Step: 2
Training loss: 2.0458996028487135
Validation loss: 2.5139299530436237

Epoch: 5| Step: 3
Training loss: 2.613968968242977
Validation loss: 2.4770520365229527

Epoch: 5| Step: 4
Training loss: 2.7551088561552586
Validation loss: 2.5007651826961466

Epoch: 5| Step: 5
Training loss: 2.406508196564948
Validation loss: 2.5250516478603835

Epoch: 5| Step: 6
Training loss: 2.584893329861779
Validation loss: 2.505538590856139

Epoch: 5| Step: 7
Training loss: 1.7727322289368677
Validation loss: 2.4944582950681395

Epoch: 5| Step: 8
Training loss: 2.29441047327213
Validation loss: 2.482964749206491

Epoch: 5| Step: 9
Training loss: 3.058871396691365
Validation loss: 2.4982599441453583

Epoch: 5| Step: 10
Training loss: 1.6164397939130244
Validation loss: 2.494169579091163

Epoch: 5| Step: 11
Training loss: 1.1256331145795242
Validation loss: 2.502408439108938

Epoch: 43| Step: 0
Training loss: 2.360426510562779
Validation loss: 2.5823769542361035

Epoch: 5| Step: 1
Training loss: 2.2039748913049544
Validation loss: 2.5076687931071384

Epoch: 5| Step: 2
Training loss: 2.2777923089884564
Validation loss: 2.5730302466420873

Epoch: 5| Step: 3
Training loss: 1.9654536428795133
Validation loss: 2.5791744485243666

Epoch: 5| Step: 4
Training loss: 3.1124059578656538
Validation loss: 2.611228029838283

Epoch: 5| Step: 5
Training loss: 2.8613109601127635
Validation loss: 2.5537689571949804

Epoch: 5| Step: 6
Training loss: 2.1322361652982327
Validation loss: 2.5748697710901283

Epoch: 5| Step: 7
Training loss: 2.6222772555673663
Validation loss: 2.6190984515370244

Epoch: 5| Step: 8
Training loss: 2.1626731185856043
Validation loss: 2.5674233533140356

Epoch: 5| Step: 9
Training loss: 2.05621768265115
Validation loss: 2.572914109376777

Epoch: 5| Step: 10
Training loss: 2.5078248591133345
Validation loss: 2.519245772243348

Epoch: 5| Step: 11
Training loss: 1.9252223815284333
Validation loss: 2.501985083680396

Epoch: 44| Step: 0
Training loss: 2.2748732604889974
Validation loss: 2.4887314593270986

Epoch: 5| Step: 1
Training loss: 2.307704592941057
Validation loss: 2.532582683754275

Epoch: 5| Step: 2
Training loss: 1.935073194080517
Validation loss: 2.4637584886577244

Epoch: 5| Step: 3
Training loss: 2.5197793527917023
Validation loss: 2.4528298230773897

Epoch: 5| Step: 4
Training loss: 2.738971443642996
Validation loss: 2.522886080179783

Epoch: 5| Step: 5
Training loss: 2.3947471035968593
Validation loss: 2.532638112284721

Epoch: 5| Step: 6
Training loss: 2.3955181633235405
Validation loss: 2.514550992688724

Epoch: 5| Step: 7
Training loss: 2.3832319046881354
Validation loss: 2.461559322048898

Epoch: 5| Step: 8
Training loss: 2.6507878409971846
Validation loss: 2.5543978232308446

Epoch: 5| Step: 9
Training loss: 2.2651432972224748
Validation loss: 2.514556752727846

Epoch: 5| Step: 10
Training loss: 2.7506102838449777
Validation loss: 2.486473037320403

Epoch: 5| Step: 11
Training loss: 2.4192251167590544
Validation loss: 2.529500615813766

Epoch: 45| Step: 0
Training loss: 2.276015664889794
Validation loss: 2.5008008786715923

Epoch: 5| Step: 1
Training loss: 2.7174358480368586
Validation loss: 2.5283153342832434

Epoch: 5| Step: 2
Training loss: 1.9007886605014428
Validation loss: 2.4810071546094434

Epoch: 5| Step: 3
Training loss: 1.5514123819033883
Validation loss: 2.5234454954983203

Epoch: 5| Step: 4
Training loss: 2.0232913874007563
Validation loss: 2.4798940197990658

Epoch: 5| Step: 5
Training loss: 3.074351830128595
Validation loss: 2.5643162454767743

Epoch: 5| Step: 6
Training loss: 2.4242212559216525
Validation loss: 2.557783865452808

Epoch: 5| Step: 7
Training loss: 2.1006670891387977
Validation loss: 2.5416132512238243

Epoch: 5| Step: 8
Training loss: 1.8241331419369968
Validation loss: 2.564812183059993

Epoch: 5| Step: 9
Training loss: 2.9251375801791055
Validation loss: 2.4919110327173266

Epoch: 5| Step: 10
Training loss: 2.6344405667255764
Validation loss: 2.4987278522860366

Epoch: 5| Step: 11
Training loss: 2.293283574133736
Validation loss: 2.498118200966512

Epoch: 46| Step: 0
Training loss: 2.740043649813057
Validation loss: 2.473444997166035

Epoch: 5| Step: 1
Training loss: 2.4336173605959894
Validation loss: 2.49873788684697

Epoch: 5| Step: 2
Training loss: 2.1247768284910147
Validation loss: 2.506577759205522

Epoch: 5| Step: 3
Training loss: 2.2305072306772544
Validation loss: 2.5294483272027337

Epoch: 5| Step: 4
Training loss: 2.268993740807849
Validation loss: 2.481090701968768

Epoch: 5| Step: 5
Training loss: 1.964819966773306
Validation loss: 2.4994262791993553

Epoch: 5| Step: 6
Training loss: 2.7698514723636496
Validation loss: 2.525825162176065

Epoch: 5| Step: 7
Training loss: 2.152480327059954
Validation loss: 2.43823383158482

Epoch: 5| Step: 8
Training loss: 2.3689206265718483
Validation loss: 2.524885972441516

Epoch: 5| Step: 9
Training loss: 2.241148811094265
Validation loss: 2.499535469766527

Epoch: 5| Step: 10
Training loss: 2.416642276596991
Validation loss: 2.5299979673033177

Epoch: 5| Step: 11
Training loss: 2.527923564642637
Validation loss: 2.55534444561254

Epoch: 47| Step: 0
Training loss: 2.2330484787444385
Validation loss: 2.504255951788175

Epoch: 5| Step: 1
Training loss: 2.0456970552737195
Validation loss: 2.4928559031778157

Epoch: 5| Step: 2
Training loss: 2.560985862177531
Validation loss: 2.4869812704080734

Epoch: 5| Step: 3
Training loss: 2.4749430948516586
Validation loss: 2.503245023881147

Epoch: 5| Step: 4
Training loss: 2.308532094374175
Validation loss: 2.548921952158819

Epoch: 5| Step: 5
Training loss: 2.6154689327517726
Validation loss: 2.5149864231359977

Epoch: 5| Step: 6
Training loss: 2.0864730318960727
Validation loss: 2.489395443092283

Epoch: 5| Step: 7
Training loss: 2.3405725939273596
Validation loss: 2.4885431747676794

Epoch: 5| Step: 8
Training loss: 2.5726483986390405
Validation loss: 2.4979538053901984

Epoch: 5| Step: 9
Training loss: 2.4237880903283657
Validation loss: 2.514276597267864

Epoch: 5| Step: 10
Training loss: 2.4412844696189717
Validation loss: 2.5142267064883006

Epoch: 5| Step: 11
Training loss: 1.6051231439236753
Validation loss: 2.506967669638015

Epoch: 48| Step: 0
Training loss: 2.732065587950182
Validation loss: 2.5699898073721608

Epoch: 5| Step: 1
Training loss: 2.797454092076907
Validation loss: 2.5649772005883533

Epoch: 5| Step: 2
Training loss: 1.5823243423044682
Validation loss: 2.59290747957555

Epoch: 5| Step: 3
Training loss: 2.5352322371605114
Validation loss: 2.6133047881156877

Epoch: 5| Step: 4
Training loss: 2.243687676119377
Validation loss: 2.6187898352118895

Epoch: 5| Step: 5
Training loss: 2.0305745102043655
Validation loss: 2.590732101815671

Epoch: 5| Step: 6
Training loss: 2.8942996201391615
Validation loss: 2.5938833999033295

Epoch: 5| Step: 7
Training loss: 2.5430986924965833
Validation loss: 2.5383577278335916

Epoch: 5| Step: 8
Training loss: 2.34644254517298
Validation loss: 2.5210493299986014

Epoch: 5| Step: 9
Training loss: 1.9297790505626489
Validation loss: 2.5129145499304695

Epoch: 5| Step: 10
Training loss: 2.478040188159446
Validation loss: 2.541672039547437

Epoch: 5| Step: 11
Training loss: 2.0539106053378364
Validation loss: 2.5203292253305474

Epoch: 49| Step: 0
Training loss: 2.6487771325659226
Validation loss: 2.529744933122183

Epoch: 5| Step: 1
Training loss: 2.4647944183974815
Validation loss: 2.477112377104493

Epoch: 5| Step: 2
Training loss: 2.2114595801023063
Validation loss: 2.5336410391008775

Epoch: 5| Step: 3
Training loss: 2.1086880165673154
Validation loss: 2.512503027400127

Epoch: 5| Step: 4
Training loss: 2.5646606268392267
Validation loss: 2.520796244850235

Epoch: 5| Step: 5
Training loss: 2.650817791692254
Validation loss: 2.5300059754441806

Epoch: 5| Step: 6
Training loss: 2.483114246543876
Validation loss: 2.507295010454468

Epoch: 5| Step: 7
Training loss: 2.2755341709683528
Validation loss: 2.483914306599403

Epoch: 5| Step: 8
Training loss: 2.0992266638847616
Validation loss: 2.4975114078980343

Epoch: 5| Step: 9
Training loss: 1.9701178506755723
Validation loss: 2.5193692926600724

Epoch: 5| Step: 10
Training loss: 2.5614255187632113
Validation loss: 2.527064788060542

Epoch: 5| Step: 11
Training loss: 1.6417137529749677
Validation loss: 2.5920236158234595

Epoch: 50| Step: 0
Training loss: 2.6999410940738144
Validation loss: 2.5686656928787874

Epoch: 5| Step: 1
Training loss: 1.9132878818607308
Validation loss: 2.530048956680075

Epoch: 5| Step: 2
Training loss: 2.5083461680881296
Validation loss: 2.486345725085866

Epoch: 5| Step: 3
Training loss: 2.2882223312487233
Validation loss: 2.5512135496188115

Epoch: 5| Step: 4
Training loss: 2.3797302322408243
Validation loss: 2.519195684122217

Epoch: 5| Step: 5
Training loss: 1.8554364974581732
Validation loss: 2.4885446996871288

Epoch: 5| Step: 6
Training loss: 2.757657746465842
Validation loss: 2.4808918909917077

Epoch: 5| Step: 7
Training loss: 1.9202969903529108
Validation loss: 2.493652766028312

Epoch: 5| Step: 8
Training loss: 2.0956381639294106
Validation loss: 2.4971238957159643

Epoch: 5| Step: 9
Training loss: 2.6746946927114412
Validation loss: 2.4861424035376736

Epoch: 5| Step: 10
Training loss: 2.4196537783732706
Validation loss: 2.5045221833810194

Epoch: 5| Step: 11
Training loss: 1.7026733359492763
Validation loss: 2.5212453762876357

Epoch: 51| Step: 0
Training loss: 2.1606540761618267
Validation loss: 2.5290531703824497

Epoch: 5| Step: 1
Training loss: 2.379300290000217
Validation loss: 2.59183007539797

Epoch: 5| Step: 2
Training loss: 1.5804422569600063
Validation loss: 2.5924003452373094

Epoch: 5| Step: 3
Training loss: 2.6118863749478898
Validation loss: 2.5779802378076315

Epoch: 5| Step: 4
Training loss: 2.8053663701981635
Validation loss: 2.6551985286403417

Epoch: 5| Step: 5
Training loss: 2.527215638959846
Validation loss: 2.67381792644732

Epoch: 5| Step: 6
Training loss: 2.2911027272245033
Validation loss: 2.638396984118937

Epoch: 5| Step: 7
Training loss: 2.3016074078458892
Validation loss: 2.604284143977014

Epoch: 5| Step: 8
Training loss: 2.015882135593977
Validation loss: 2.526794829938667

Epoch: 5| Step: 9
Training loss: 2.255666907881193
Validation loss: 2.610089967432792

Epoch: 5| Step: 10
Training loss: 2.76222450988537
Validation loss: 2.493781338481255

Epoch: 5| Step: 11
Training loss: 2.338694702669094
Validation loss: 2.520017024088682

Epoch: 52| Step: 0
Training loss: 2.8762729977745596
Validation loss: 2.507266419910531

Epoch: 5| Step: 1
Training loss: 2.3124760806934406
Validation loss: 2.511957539884445

Epoch: 5| Step: 2
Training loss: 2.161952563546186
Validation loss: 2.5308725366035763

Epoch: 5| Step: 3
Training loss: 2.240060681474824
Validation loss: 2.5370265760216393

Epoch: 5| Step: 4
Training loss: 2.7723016696503984
Validation loss: 2.5288233486819736

Epoch: 5| Step: 5
Training loss: 2.352557304568128
Validation loss: 2.5238641943059235

Epoch: 5| Step: 6
Training loss: 2.4211232649169516
Validation loss: 2.4969759134931806

Epoch: 5| Step: 7
Training loss: 2.2837554550732135
Validation loss: 2.5081937248617434

Epoch: 5| Step: 8
Training loss: 2.5762098192452956
Validation loss: 2.4873171804648795

Epoch: 5| Step: 9
Training loss: 2.0149570511625763
Validation loss: 2.54693894218263

Epoch: 5| Step: 10
Training loss: 2.07866552680186
Validation loss: 2.5187636356915464

Epoch: 5| Step: 11
Training loss: 0.9272603962434495
Validation loss: 2.519148584133325

Epoch: 53| Step: 0
Training loss: 2.351368943673289
Validation loss: 2.5545629379594015

Epoch: 5| Step: 1
Training loss: 2.5759860326731867
Validation loss: 2.551379092356947

Epoch: 5| Step: 2
Training loss: 1.683666466649437
Validation loss: 2.5086008062890106

Epoch: 5| Step: 3
Training loss: 2.332935662668892
Validation loss: 2.55897549797657

Epoch: 5| Step: 4
Training loss: 2.040863878367598
Validation loss: 2.534543622197207

Epoch: 5| Step: 5
Training loss: 2.106031466503488
Validation loss: 2.551809235210526

Epoch: 5| Step: 6
Training loss: 2.869665421180072
Validation loss: 2.523869338744856

Epoch: 5| Step: 7
Training loss: 2.362820868929484
Validation loss: 2.601063954542124

Epoch: 5| Step: 8
Training loss: 2.5220703578757835
Validation loss: 2.5148043310736488

Epoch: 5| Step: 9
Training loss: 2.316797953483036
Validation loss: 2.502403637608785

Epoch: 5| Step: 10
Training loss: 1.9109716878657153
Validation loss: 2.5059618910337313

Epoch: 5| Step: 11
Training loss: 2.3426028686865425
Validation loss: 2.496973892436988

Epoch: 54| Step: 0
Training loss: 2.2891626954527373
Validation loss: 2.4516214026917433

Epoch: 5| Step: 1
Training loss: 2.001159451096328
Validation loss: 2.505578584070617

Epoch: 5| Step: 2
Training loss: 2.8425385965563597
Validation loss: 2.502823169399888

Epoch: 5| Step: 3
Training loss: 2.9249862996620086
Validation loss: 2.445452490101284

Epoch: 5| Step: 4
Training loss: 2.3855395111924786
Validation loss: 2.4794004087025243

Epoch: 5| Step: 5
Training loss: 1.6592581440212901
Validation loss: 2.420174812027175

Epoch: 5| Step: 6
Training loss: 2.255173246068136
Validation loss: 2.4673784284779954

Epoch: 5| Step: 7
Training loss: 2.1622972691053532
Validation loss: 2.506806489706853

Epoch: 5| Step: 8
Training loss: 2.1653865798563934
Validation loss: 2.517412762751445

Epoch: 5| Step: 9
Training loss: 2.664921060076491
Validation loss: 2.5298876844386853

Epoch: 5| Step: 10
Training loss: 1.7002292478484358
Validation loss: 2.512487002318562

Epoch: 5| Step: 11
Training loss: 2.457093448791676
Validation loss: 2.4940916617697346

Epoch: 55| Step: 0
Training loss: 2.7911652831201725
Validation loss: 2.4473821719326083

Epoch: 5| Step: 1
Training loss: 2.5193576959968227
Validation loss: 2.4602237130480464

Epoch: 5| Step: 2
Training loss: 2.394048197128061
Validation loss: 2.483876892154394

Epoch: 5| Step: 3
Training loss: 2.0366965412294262
Validation loss: 2.4984749513466844

Epoch: 5| Step: 4
Training loss: 2.504552320424676
Validation loss: 2.534788213738846

Epoch: 5| Step: 5
Training loss: 1.8841994626096998
Validation loss: 2.502080806399511

Epoch: 5| Step: 6
Training loss: 1.9818966024010038
Validation loss: 2.4726001960141932

Epoch: 5| Step: 7
Training loss: 2.7427003386357196
Validation loss: 2.4704742566882665

Epoch: 5| Step: 8
Training loss: 2.0826120908321184
Validation loss: 2.449147768426881

Epoch: 5| Step: 9
Training loss: 1.838223077621257
Validation loss: 2.4958859886023954

Epoch: 5| Step: 10
Training loss: 2.308743286453507
Validation loss: 2.510023467478529

Epoch: 5| Step: 11
Training loss: 3.0349985128333077
Validation loss: 2.536844726730227

Epoch: 56| Step: 0
Training loss: 2.589123379734593
Validation loss: 2.4870751300824963

Epoch: 5| Step: 1
Training loss: 2.15105254114341
Validation loss: 2.4733336747581403

Epoch: 5| Step: 2
Training loss: 1.9985779236468184
Validation loss: 2.5155057365468587

Epoch: 5| Step: 3
Training loss: 2.4276332205017486
Validation loss: 2.5452597865357505

Epoch: 5| Step: 4
Training loss: 2.2695920742373863
Validation loss: 2.5258804833548405

Epoch: 5| Step: 5
Training loss: 2.071359276199721
Validation loss: 2.57372128624853

Epoch: 5| Step: 6
Training loss: 2.6046882615663254
Validation loss: 2.542398305764023

Epoch: 5| Step: 7
Training loss: 2.871598927176212
Validation loss: 2.5112863171364306

Epoch: 5| Step: 8
Training loss: 2.305172006142985
Validation loss: 2.5075871890253723

Epoch: 5| Step: 9
Training loss: 2.4090623150497725
Validation loss: 2.476810912179812

Epoch: 5| Step: 10
Training loss: 2.56316757810473
Validation loss: 2.5139109298507907

Epoch: 5| Step: 11
Training loss: 1.1967364039241453
Validation loss: 2.5743880189728663

Epoch: 57| Step: 0
Training loss: 2.4355694877596514
Validation loss: 2.6035283806906415

Epoch: 5| Step: 1
Training loss: 2.482422355213614
Validation loss: 2.6177766127409265

Epoch: 5| Step: 2
Training loss: 2.5362601911058977
Validation loss: 2.5995668464619235

Epoch: 5| Step: 3
Training loss: 2.531489043074751
Validation loss: 2.615012856774608

Epoch: 5| Step: 4
Training loss: 2.385913469534561
Validation loss: 2.516318286904668

Epoch: 5| Step: 5
Training loss: 2.575156057128751
Validation loss: 2.5224655373836944

Epoch: 5| Step: 6
Training loss: 2.219522153788064
Validation loss: 2.4831218717990478

Epoch: 5| Step: 7
Training loss: 2.2755162544114196
Validation loss: 2.532015453188516

Epoch: 5| Step: 8
Training loss: 2.2922785433401343
Validation loss: 2.4716676460293323

Epoch: 5| Step: 9
Training loss: 2.003698624531144
Validation loss: 2.4968713415801007

Epoch: 5| Step: 10
Training loss: 2.1864939964939536
Validation loss: 2.497759132624882

Epoch: 5| Step: 11
Training loss: 1.2224842474610982
Validation loss: 2.4951151928081865

Epoch: 58| Step: 0
Training loss: 2.789256027730768
Validation loss: 2.494546999046819

Epoch: 5| Step: 1
Training loss: 2.4573308765042396
Validation loss: 2.5044389297973635

Epoch: 5| Step: 2
Training loss: 2.1271305623230328
Validation loss: 2.4972123976011957

Epoch: 5| Step: 3
Training loss: 2.1270405564846815
Validation loss: 2.539308937046531

Epoch: 5| Step: 4
Training loss: 2.695510635833334
Validation loss: 2.552882502761881

Epoch: 5| Step: 5
Training loss: 1.588659346760673
Validation loss: 2.4520732828116323

Epoch: 5| Step: 6
Training loss: 2.1083007337540236
Validation loss: 2.5380546290976613

Epoch: 5| Step: 7
Training loss: 2.137291644911601
Validation loss: 2.5496706645509657

Epoch: 5| Step: 8
Training loss: 2.6294730087087475
Validation loss: 2.5590735648061926

Epoch: 5| Step: 9
Training loss: 2.1082396666134344
Validation loss: 2.5707037994070094

Epoch: 5| Step: 10
Training loss: 1.8579928606551106
Validation loss: 2.521590715446581

Epoch: 5| Step: 11
Training loss: 2.949308320763167
Validation loss: 2.5338328257044607

Epoch: 59| Step: 0
Training loss: 1.9005307560504259
Validation loss: 2.520725205889925

Epoch: 5| Step: 1
Training loss: 1.8919281054863966
Validation loss: 2.5042182541503974

Epoch: 5| Step: 2
Training loss: 3.1766507880930486
Validation loss: 2.4985112446360236

Epoch: 5| Step: 3
Training loss: 2.9185754433821613
Validation loss: 2.4745333046926796

Epoch: 5| Step: 4
Training loss: 2.23435984786438
Validation loss: 2.4505214319556083

Epoch: 5| Step: 5
Training loss: 2.1482123239596818
Validation loss: 2.529319195544561

Epoch: 5| Step: 6
Training loss: 1.864508202884355
Validation loss: 2.561595392664801

Epoch: 5| Step: 7
Training loss: 2.0195682013136076
Validation loss: 2.4864631250593927

Epoch: 5| Step: 8
Training loss: 1.8742893143695722
Validation loss: 2.5217491186238816

Epoch: 5| Step: 9
Training loss: 2.472306020318979
Validation loss: 2.478155299799606

Epoch: 5| Step: 10
Training loss: 2.386289367510907
Validation loss: 2.5106947113062947

Epoch: 5| Step: 11
Training loss: 2.3973878433676723
Validation loss: 2.500320684210363

Epoch: 60| Step: 0
Training loss: 1.7337059586369263
Validation loss: 2.5602718838965584

Epoch: 5| Step: 1
Training loss: 2.2128353532856284
Validation loss: 2.631375740502142

Epoch: 5| Step: 2
Training loss: 2.5169945063328343
Validation loss: 2.576053951206885

Epoch: 5| Step: 3
Training loss: 2.616764774629578
Validation loss: 2.673824814654378

Epoch: 5| Step: 4
Training loss: 2.488143174489079
Validation loss: 2.6523144982082156

Epoch: 5| Step: 5
Training loss: 2.050379657479836
Validation loss: 2.648565308029182

Epoch: 5| Step: 6
Training loss: 2.5112940309043386
Validation loss: 2.580524995941347

Epoch: 5| Step: 7
Training loss: 2.2416284375907565
Validation loss: 2.5500757742201157

Epoch: 5| Step: 8
Training loss: 2.474224539371483
Validation loss: 2.5409055857541927

Epoch: 5| Step: 9
Training loss: 2.1340853627229124
Validation loss: 2.5053613078044523

Epoch: 5| Step: 10
Training loss: 2.138270398782466
Validation loss: 2.5146034982363146

Epoch: 5| Step: 11
Training loss: 1.314624429454355
Validation loss: 2.5044481203927034

Epoch: 61| Step: 0
Training loss: 2.8816037835900663
Validation loss: 2.544268520566318

Epoch: 5| Step: 1
Training loss: 2.340518809457492
Validation loss: 2.5064803612958935

Epoch: 5| Step: 2
Training loss: 2.1533275093771453
Validation loss: 2.476016023433801

Epoch: 5| Step: 3
Training loss: 2.2774726216149803
Validation loss: 2.480448512998515

Epoch: 5| Step: 4
Training loss: 2.214856452165406
Validation loss: 2.4991664351147014

Epoch: 5| Step: 5
Training loss: 2.366292752919023
Validation loss: 2.516757560082274

Epoch: 5| Step: 6
Training loss: 2.0909255605735035
Validation loss: 2.4741943862465496

Epoch: 5| Step: 7
Training loss: 2.3377343860961886
Validation loss: 2.5137570951372092

Epoch: 5| Step: 8
Training loss: 2.4147064436520833
Validation loss: 2.5894019285596195

Epoch: 5| Step: 9
Training loss: 2.2279033705818354
Validation loss: 2.5824800910133057

Epoch: 5| Step: 10
Training loss: 2.172088722306716
Validation loss: 2.591198853887978

Epoch: 5| Step: 11
Training loss: 2.3517942599534303
Validation loss: 2.605399802390426

Epoch: 62| Step: 0
Training loss: 2.1819420096631155
Validation loss: 2.5086068888711917

Epoch: 5| Step: 1
Training loss: 2.491640706602202
Validation loss: 2.537698972351916

Epoch: 5| Step: 2
Training loss: 1.6722242044132238
Validation loss: 2.5021008267507105

Epoch: 5| Step: 3
Training loss: 2.4792840967229197
Validation loss: 2.483961522784643

Epoch: 5| Step: 4
Training loss: 2.7461145869586416
Validation loss: 2.455255122191419

Epoch: 5| Step: 5
Training loss: 2.273729443239606
Validation loss: 2.532574770056828

Epoch: 5| Step: 6
Training loss: 2.6905565844620134
Validation loss: 2.4589100635340055

Epoch: 5| Step: 7
Training loss: 1.9024747768138646
Validation loss: 2.494165578232908

Epoch: 5| Step: 8
Training loss: 1.7967159698435626
Validation loss: 2.530221543736298

Epoch: 5| Step: 9
Training loss: 2.3072395290112766
Validation loss: 2.5439134123517255

Epoch: 5| Step: 10
Training loss: 2.285004230887672
Validation loss: 2.4412957738676084

Epoch: 5| Step: 11
Training loss: 0.5995552461030845
Validation loss: 2.5129680542353015

Epoch: 63| Step: 0
Training loss: 2.046858925792681
Validation loss: 2.430366609283384

Epoch: 5| Step: 1
Training loss: 2.1196222136030887
Validation loss: 2.5410654159386428

Epoch: 5| Step: 2
Training loss: 1.8784545863137116
Validation loss: 2.5238510635404974

Epoch: 5| Step: 3
Training loss: 1.3707637987598964
Validation loss: 2.565722373914279

Epoch: 5| Step: 4
Training loss: 3.39124640470568
Validation loss: 2.57397304630024

Epoch: 5| Step: 5
Training loss: 1.8546129039748667
Validation loss: 2.532748359716796

Epoch: 5| Step: 6
Training loss: 1.8680615155181286
Validation loss: 2.5394289075127685

Epoch: 5| Step: 7
Training loss: 2.573772663833707
Validation loss: 2.500286256772982

Epoch: 5| Step: 8
Training loss: 2.7414854188816906
Validation loss: 2.473926119678309

Epoch: 5| Step: 9
Training loss: 2.1611900683996463
Validation loss: 2.537498947356308

Epoch: 5| Step: 10
Training loss: 2.1124446432772257
Validation loss: 2.460161351117567

Epoch: 5| Step: 11
Training loss: 2.656990935264576
Validation loss: 2.4583175478175194

Epoch: 64| Step: 0
Training loss: 2.5998994477708726
Validation loss: 2.5295416754007563

Epoch: 5| Step: 1
Training loss: 2.2436984085484726
Validation loss: 2.5529552501338113

Epoch: 5| Step: 2
Training loss: 2.140272459529227
Validation loss: 2.559420720376332

Epoch: 5| Step: 3
Training loss: 2.4139665998156716
Validation loss: 2.620148038546249

Epoch: 5| Step: 4
Training loss: 2.005416211999297
Validation loss: 2.557045306415658

Epoch: 5| Step: 5
Training loss: 2.000126834662324
Validation loss: 2.5203747286192346

Epoch: 5| Step: 6
Training loss: 2.129269742119253
Validation loss: 2.535062426695664

Epoch: 5| Step: 7
Training loss: 2.621506773560668
Validation loss: 2.547290545772939

Epoch: 5| Step: 8
Training loss: 2.007965319565768
Validation loss: 2.5046937986450577

Epoch: 5| Step: 9
Training loss: 2.522244008801548
Validation loss: 2.4963059233194116

Epoch: 5| Step: 10
Training loss: 1.5655073597581812
Validation loss: 2.4962430938156532

Epoch: 5| Step: 11
Training loss: 2.8754560689341293
Validation loss: 2.5310187862116784

Epoch: 65| Step: 0
Training loss: 2.5962515108915
Validation loss: 2.5566691840713553

Epoch: 5| Step: 1
Training loss: 2.374613379079584
Validation loss: 2.5443621996141625

Epoch: 5| Step: 2
Training loss: 2.669733538957936
Validation loss: 2.5039240320202123

Epoch: 5| Step: 3
Training loss: 1.7468452628509976
Validation loss: 2.5430046856397373

Epoch: 5| Step: 4
Training loss: 2.3624358879957224
Validation loss: 2.429646958792812

Epoch: 5| Step: 5
Training loss: 1.763603335851576
Validation loss: 2.5010684233704783

Epoch: 5| Step: 6
Training loss: 1.9472920713474937
Validation loss: 2.497610921550839

Epoch: 5| Step: 7
Training loss: 2.0526708417038284
Validation loss: 2.4921925543690993

Epoch: 5| Step: 8
Training loss: 1.6237713497129704
Validation loss: 2.5584732609690306

Epoch: 5| Step: 9
Training loss: 2.805676384223944
Validation loss: 2.5297002757870803

Epoch: 5| Step: 10
Training loss: 2.605199156486601
Validation loss: 2.503956556682706

Epoch: 5| Step: 11
Training loss: 1.4164168848226562
Validation loss: 2.583732825328118

Epoch: 66| Step: 0
Training loss: 2.2421001988870537
Validation loss: 2.4838534533472383

Epoch: 5| Step: 1
Training loss: 2.452927308104587
Validation loss: 2.5357650041624904

Epoch: 5| Step: 2
Training loss: 1.8448934080765498
Validation loss: 2.4869663151646977

Epoch: 5| Step: 3
Training loss: 2.1973310537133535
Validation loss: 2.4959026536140483

Epoch: 5| Step: 4
Training loss: 2.2574844914069447
Validation loss: 2.4991037192647574

Epoch: 5| Step: 5
Training loss: 2.3904692156528364
Validation loss: 2.4683595541742536

Epoch: 5| Step: 6
Training loss: 2.4566525893754805
Validation loss: 2.4632504850951253

Epoch: 5| Step: 7
Training loss: 2.4503235583839706
Validation loss: 2.48056190295782

Epoch: 5| Step: 8
Training loss: 2.296874792397418
Validation loss: 2.536178390647635

Epoch: 5| Step: 9
Training loss: 1.9040408231301766
Validation loss: 2.5434281168179242

Epoch: 5| Step: 10
Training loss: 2.3267021183420877
Validation loss: 2.4834886585267446

Epoch: 5| Step: 11
Training loss: 1.6377911025019554
Validation loss: 2.5370571844710463

Epoch: 67| Step: 0
Training loss: 1.6905389901386347
Validation loss: 2.557692431624461

Epoch: 5| Step: 1
Training loss: 2.7785361261468204
Validation loss: 2.490252079121605

Epoch: 5| Step: 2
Training loss: 2.394526669869702
Validation loss: 2.570241086483733

Epoch: 5| Step: 3
Training loss: 2.431715728948097
Validation loss: 2.5809908014753344

Epoch: 5| Step: 4
Training loss: 2.263705789017415
Validation loss: 2.5572412696943196

Epoch: 5| Step: 5
Training loss: 2.0485276400987456
Validation loss: 2.558861118159424

Epoch: 5| Step: 6
Training loss: 2.353803916147517
Validation loss: 2.5491048104857144

Epoch: 5| Step: 7
Training loss: 1.9596356329595672
Validation loss: 2.5007602648265213

Epoch: 5| Step: 8
Training loss: 2.0352097868513117
Validation loss: 2.5667994104671927

Epoch: 5| Step: 9
Training loss: 2.4005854925605723
Validation loss: 2.5582631797884696

Epoch: 5| Step: 10
Training loss: 2.2273466101513995
Validation loss: 2.527579200779065

Epoch: 5| Step: 11
Training loss: 2.2269560884309785
Validation loss: 2.5392937735841703

Epoch: 68| Step: 0
Training loss: 2.090887361722678
Validation loss: 2.4931718960898075

Epoch: 5| Step: 1
Training loss: 2.280020290920249
Validation loss: 2.434510957759699

Epoch: 5| Step: 2
Training loss: 2.58817454957823
Validation loss: 2.5272140508956484

Epoch: 5| Step: 3
Training loss: 2.5498419020766634
Validation loss: 2.5061778705837203

Epoch: 5| Step: 4
Training loss: 2.2740759723154698
Validation loss: 2.4788801457757548

Epoch: 5| Step: 5
Training loss: 2.1632161051762933
Validation loss: 2.5084402857333674

Epoch: 5| Step: 6
Training loss: 1.9715242971751088
Validation loss: 2.5311065641037582

Epoch: 5| Step: 7
Training loss: 2.002777436048126
Validation loss: 2.519096991599385

Epoch: 5| Step: 8
Training loss: 2.6868617164796342
Validation loss: 2.4908417722657554

Epoch: 5| Step: 9
Training loss: 2.171670149329265
Validation loss: 2.581923559023545

Epoch: 5| Step: 10
Training loss: 1.7413740097764894
Validation loss: 2.535005170163532

Epoch: 5| Step: 11
Training loss: 2.180085176676241
Validation loss: 2.6190329957941874

Epoch: 69| Step: 0
Training loss: 2.488748790945682
Validation loss: 2.637415935508502

Epoch: 5| Step: 1
Training loss: 2.5276420216791577
Validation loss: 2.564526388608849

Epoch: 5| Step: 2
Training loss: 2.01074977612094
Validation loss: 2.592554414338109

Epoch: 5| Step: 3
Training loss: 1.8225494523527646
Validation loss: 2.4777021904453345

Epoch: 5| Step: 4
Training loss: 2.028135053377553
Validation loss: 2.4765842849944573

Epoch: 5| Step: 5
Training loss: 2.082757247111801
Validation loss: 2.5438619823316744

Epoch: 5| Step: 6
Training loss: 2.255216485435312
Validation loss: 2.5063916020492187

Epoch: 5| Step: 7
Training loss: 2.18728287845465
Validation loss: 2.5555466540038756

Epoch: 5| Step: 8
Training loss: 2.6067050820111044
Validation loss: 2.514009557260987

Epoch: 5| Step: 9
Training loss: 2.300044979816631
Validation loss: 2.5551778262515503

Epoch: 5| Step: 10
Training loss: 1.9957270873373338
Validation loss: 2.4870878358969435

Epoch: 5| Step: 11
Training loss: 1.661125779627602
Validation loss: 2.497138813995258

Epoch: 70| Step: 0
Training loss: 2.4723646525336136
Validation loss: 2.455489721723476

Epoch: 5| Step: 1
Training loss: 2.068642687823408
Validation loss: 2.558509336054566

Epoch: 5| Step: 2
Training loss: 1.8049876306168104
Validation loss: 2.499561950930006

Epoch: 5| Step: 3
Training loss: 2.3839562844614295
Validation loss: 2.54601558859129

Epoch: 5| Step: 4
Training loss: 2.646052814501507
Validation loss: 2.55255145366367

Epoch: 5| Step: 5
Training loss: 1.8725237070984255
Validation loss: 2.5094055907085955

Epoch: 5| Step: 6
Training loss: 2.5117402973111043
Validation loss: 2.500239321062074

Epoch: 5| Step: 7
Training loss: 2.1728792133072097
Validation loss: 2.5377416021211667

Epoch: 5| Step: 8
Training loss: 2.3637391206439524
Validation loss: 2.4971541837079276

Epoch: 5| Step: 9
Training loss: 2.2447263585715125
Validation loss: 2.4906271192221756

Epoch: 5| Step: 10
Training loss: 1.9861368482948045
Validation loss: 2.5227772426641994

Epoch: 5| Step: 11
Training loss: 1.082687839746931
Validation loss: 2.4696551406003744

Epoch: 71| Step: 0
Training loss: 2.1618340100661886
Validation loss: 2.4991993774477295

Epoch: 5| Step: 1
Training loss: 1.9684073134798257
Validation loss: 2.526301853636196

Epoch: 5| Step: 2
Training loss: 2.337508983900788
Validation loss: 2.4866557738199364

Epoch: 5| Step: 3
Training loss: 2.01521060439345
Validation loss: 2.511899817996604

Epoch: 5| Step: 4
Training loss: 2.583746128531528
Validation loss: 2.5236827939768234

Epoch: 5| Step: 5
Training loss: 2.1071712709039803
Validation loss: 2.5374898960432266

Epoch: 5| Step: 6
Training loss: 2.0336303848325676
Validation loss: 2.528950411953362

Epoch: 5| Step: 7
Training loss: 1.9709234804447464
Validation loss: 2.507154875635807

Epoch: 5| Step: 8
Training loss: 2.3832056940574784
Validation loss: 2.548516748733174

Epoch: 5| Step: 9
Training loss: 2.524347194472216
Validation loss: 2.509551494087549

Epoch: 5| Step: 10
Training loss: 1.7329809411393695
Validation loss: 2.514941732838902

Epoch: 5| Step: 11
Training loss: 2.0596578261990386
Validation loss: 2.520203643106597

Epoch: 72| Step: 0
Training loss: 2.5172544142521187
Validation loss: 2.535497896109959

Epoch: 5| Step: 1
Training loss: 2.172461780347989
Validation loss: 2.522520794406267

Epoch: 5| Step: 2
Training loss: 2.3517241058075724
Validation loss: 2.5342414510326274

Epoch: 5| Step: 3
Training loss: 2.09216932156381
Validation loss: 2.542095493401572

Epoch: 5| Step: 4
Training loss: 2.3395468088788176
Validation loss: 2.5029760488641095

Epoch: 5| Step: 5
Training loss: 2.1875415253103827
Validation loss: 2.5311177105341267

Epoch: 5| Step: 6
Training loss: 1.752487186270762
Validation loss: 2.489514423092349

Epoch: 5| Step: 7
Training loss: 2.108972581695124
Validation loss: 2.5224555657073964

Epoch: 5| Step: 8
Training loss: 2.1971865220136206
Validation loss: 2.4712703772363835

Epoch: 5| Step: 9
Training loss: 2.563917558793772
Validation loss: 2.527233439754727

Epoch: 5| Step: 10
Training loss: 2.263080088399708
Validation loss: 2.4638798859891824

Epoch: 5| Step: 11
Training loss: 1.3688655038113566
Validation loss: 2.500210542555214

Epoch: 73| Step: 0
Training loss: 1.6834352777160853
Validation loss: 2.48661227624009

Epoch: 5| Step: 1
Training loss: 1.7868239878430932
Validation loss: 2.5323196278300326

Epoch: 5| Step: 2
Training loss: 1.8650726727601028
Validation loss: 2.5228077011034404

Epoch: 5| Step: 3
Training loss: 2.042287213226831
Validation loss: 2.53177935947996

Epoch: 5| Step: 4
Training loss: 2.0910578258295813
Validation loss: 2.524845639788845

Epoch: 5| Step: 5
Training loss: 2.103000985240116
Validation loss: 2.563216861225022

Epoch: 5| Step: 6
Training loss: 2.279728316633882
Validation loss: 2.5591069839989427

Epoch: 5| Step: 7
Training loss: 2.2446048478867584
Validation loss: 2.5257484514927144

Epoch: 5| Step: 8
Training loss: 2.0881328103297068
Validation loss: 2.5352324174078746

Epoch: 5| Step: 9
Training loss: 2.888303081913871
Validation loss: 2.5312655001036233

Epoch: 5| Step: 10
Training loss: 2.479386894211007
Validation loss: 2.4803736390629783

Epoch: 5| Step: 11
Training loss: 2.4712311071234216
Validation loss: 2.446180500355102

Epoch: 74| Step: 0
Training loss: 2.1145517757171897
Validation loss: 2.506557974756393

Epoch: 5| Step: 1
Training loss: 2.1845943226217432
Validation loss: 2.5651702652885047

Epoch: 5| Step: 2
Training loss: 1.773755486165999
Validation loss: 2.4968620594375235

Epoch: 5| Step: 3
Training loss: 2.1335301571688814
Validation loss: 2.486686003550582

Epoch: 5| Step: 4
Training loss: 2.2235538969582507
Validation loss: 2.5468691609321548

Epoch: 5| Step: 5
Training loss: 2.140140562165012
Validation loss: 2.545931128284814

Epoch: 5| Step: 6
Training loss: 1.9657613685741997
Validation loss: 2.502876891413941

Epoch: 5| Step: 7
Training loss: 2.993223961982209
Validation loss: 2.501874987503523

Epoch: 5| Step: 8
Training loss: 1.5706747216135244
Validation loss: 2.525124595104879

Epoch: 5| Step: 9
Training loss: 1.8339200237062765
Validation loss: 2.5351975706521275

Epoch: 5| Step: 10
Training loss: 2.4388507132799786
Validation loss: 2.520805616200134

Epoch: 5| Step: 11
Training loss: 2.452902619797009
Validation loss: 2.5674620246493145

Epoch: 75| Step: 0
Training loss: 2.4981692286420634
Validation loss: 2.613322943339162

Epoch: 5| Step: 1
Training loss: 2.12313603948284
Validation loss: 2.6255642988293277

Epoch: 5| Step: 2
Training loss: 2.333785785222927
Validation loss: 2.546011210739793

Epoch: 5| Step: 3
Training loss: 1.8853285191059472
Validation loss: 2.542865862427682

Epoch: 5| Step: 4
Training loss: 1.344408317589333
Validation loss: 2.495802375291526

Epoch: 5| Step: 5
Training loss: 2.4451192468688907
Validation loss: 2.570855115296401

Epoch: 5| Step: 6
Training loss: 2.5102641163506862
Validation loss: 2.529846328106698

Epoch: 5| Step: 7
Training loss: 2.0919955290168555
Validation loss: 2.5229674492998

Epoch: 5| Step: 8
Training loss: 2.3735280746043554
Validation loss: 2.5359699019208883

Epoch: 5| Step: 9
Training loss: 2.0028663599203727
Validation loss: 2.5595375067665436

Epoch: 5| Step: 10
Training loss: 2.249796328333286
Validation loss: 2.583371605640877

Epoch: 5| Step: 11
Training loss: 1.4578783778835316
Validation loss: 2.5521363168523346

Epoch: 76| Step: 0
Training loss: 2.085125368589231
Validation loss: 2.4913865359875986

Epoch: 5| Step: 1
Training loss: 2.288923656432072
Validation loss: 2.577896921106776

Epoch: 5| Step: 2
Training loss: 1.8954278770859356
Validation loss: 2.5596309724053037

Epoch: 5| Step: 3
Training loss: 2.37270605834491
Validation loss: 2.5432920899823896

Epoch: 5| Step: 4
Training loss: 2.5653321037421715
Validation loss: 2.527549558393262

Epoch: 5| Step: 5
Training loss: 2.069390779122278
Validation loss: 2.547417428853191

Epoch: 5| Step: 6
Training loss: 2.1130534558735494
Validation loss: 2.5893986752491434

Epoch: 5| Step: 7
Training loss: 2.1225529212779333
Validation loss: 2.586580283037135

Epoch: 5| Step: 8
Training loss: 2.384303392607423
Validation loss: 2.4611195572616547

Epoch: 5| Step: 9
Training loss: 2.1422053163150667
Validation loss: 2.5765624233513416

Epoch: 5| Step: 10
Training loss: 1.8467417867417721
Validation loss: 2.5090361607478373

Epoch: 5| Step: 11
Training loss: 2.3518006467153776
Validation loss: 2.4692785023300163

Epoch: 77| Step: 0
Training loss: 2.50999845025976
Validation loss: 2.538272652651104

Epoch: 5| Step: 1
Training loss: 2.0867524001858477
Validation loss: 2.571337664538807

Epoch: 5| Step: 2
Training loss: 2.209095541452902
Validation loss: 2.5976507851296975

Epoch: 5| Step: 3
Training loss: 2.0969482591000603
Validation loss: 2.591641357938171

Epoch: 5| Step: 4
Training loss: 2.370119400557784
Validation loss: 2.6178622310729986

Epoch: 5| Step: 5
Training loss: 2.6434309458017187
Validation loss: 2.565353750618356

Epoch: 5| Step: 6
Training loss: 2.258753596916776
Validation loss: 2.4932047602410736

Epoch: 5| Step: 7
Training loss: 1.816236524958549
Validation loss: 2.46240383644621

Epoch: 5| Step: 8
Training loss: 1.7349167398708383
Validation loss: 2.4966583488981104

Epoch: 5| Step: 9
Training loss: 2.076429090957693
Validation loss: 2.494213683697081

Epoch: 5| Step: 10
Training loss: 1.8049487300576148
Validation loss: 2.493871572267073

Epoch: 5| Step: 11
Training loss: 2.336599096807769
Validation loss: 2.5392668891218126

Epoch: 78| Step: 0
Training loss: 2.046055520520936
Validation loss: 2.569997232846305

Epoch: 5| Step: 1
Training loss: 2.4627940123422833
Validation loss: 2.5053075557947193

Epoch: 5| Step: 2
Training loss: 1.9885878410860023
Validation loss: 2.519792425926402

Epoch: 5| Step: 3
Training loss: 2.002688151079657
Validation loss: 2.530999175152091

Epoch: 5| Step: 4
Training loss: 2.1603607577597344
Validation loss: 2.5867152893110847

Epoch: 5| Step: 5
Training loss: 2.0860237932393515
Validation loss: 2.50745628576185

Epoch: 5| Step: 6
Training loss: 2.9781850162314902
Validation loss: 2.485220473354148

Epoch: 5| Step: 7
Training loss: 2.2455358724640107
Validation loss: 2.5579665097069206

Epoch: 5| Step: 8
Training loss: 1.9737036011395852
Validation loss: 2.599979866237202

Epoch: 5| Step: 9
Training loss: 1.2897901388726263
Validation loss: 2.508933564436314

Epoch: 5| Step: 10
Training loss: 2.155403302683003
Validation loss: 2.5061511937465193

Epoch: 5| Step: 11
Training loss: 2.3557158130236626
Validation loss: 2.555592014189739

Epoch: 79| Step: 0
Training loss: 2.129540809062977
Validation loss: 2.5898423614421513

Epoch: 5| Step: 1
Training loss: 2.507895780232272
Validation loss: 2.5589425545667455

Epoch: 5| Step: 2
Training loss: 1.6206883670468715
Validation loss: 2.562356948736354

Epoch: 5| Step: 3
Training loss: 1.834969837761977
Validation loss: 2.5831366407721443

Epoch: 5| Step: 4
Training loss: 1.254506760592316
Validation loss: 2.531179415342692

Epoch: 5| Step: 5
Training loss: 2.056280526627389
Validation loss: 2.5264651595697365

Epoch: 5| Step: 6
Training loss: 1.9544015603598364
Validation loss: 2.587621922008547

Epoch: 5| Step: 7
Training loss: 2.9656117767585863
Validation loss: 2.601197989495459

Epoch: 5| Step: 8
Training loss: 1.9831739380307762
Validation loss: 2.514010999557884

Epoch: 5| Step: 9
Training loss: 2.5062480098878184
Validation loss: 2.5390602972559053

Epoch: 5| Step: 10
Training loss: 1.9251628138069041
Validation loss: 2.508978848760827

Epoch: 5| Step: 11
Training loss: 2.7099480925934323
Validation loss: 2.5544422763016548

Epoch: 80| Step: 0
Training loss: 2.3530058122620656
Validation loss: 2.567963505588612

Epoch: 5| Step: 1
Training loss: 2.1584855805340215
Validation loss: 2.6172908591742106

Epoch: 5| Step: 2
Training loss: 2.240581615246108
Validation loss: 2.6712543220229197

Epoch: 5| Step: 3
Training loss: 1.947803664032118
Validation loss: 2.5938354424494174

Epoch: 5| Step: 4
Training loss: 2.227419076085377
Validation loss: 2.666168450713363

Epoch: 5| Step: 5
Training loss: 2.228132798447411
Validation loss: 2.57848087513333

Epoch: 5| Step: 6
Training loss: 1.9422110840768787
Validation loss: 2.604166531880693

Epoch: 5| Step: 7
Training loss: 2.6011838895214066
Validation loss: 2.524148838811034

Epoch: 5| Step: 8
Training loss: 2.6034589390689864
Validation loss: 2.56837066918659

Epoch: 5| Step: 9
Training loss: 2.704183646816397
Validation loss: 2.6357837818355283

Epoch: 5| Step: 10
Training loss: 1.8209742706131873
Validation loss: 2.651619450398338

Epoch: 5| Step: 11
Training loss: 2.479541611300938
Validation loss: 2.680227938799138

Epoch: 81| Step: 0
Training loss: 2.3068474427352053
Validation loss: 2.728808788441577

Epoch: 5| Step: 1
Training loss: 2.395976242004957
Validation loss: 2.7202749250819824

Epoch: 5| Step: 2
Training loss: 2.4281235349987034
Validation loss: 2.634912085698235

Epoch: 5| Step: 3
Training loss: 1.6790405446939982
Validation loss: 2.5553277211861203

Epoch: 5| Step: 4
Training loss: 1.9903668031069133
Validation loss: 2.5131785341632735

Epoch: 5| Step: 5
Training loss: 1.6616040188844994
Validation loss: 2.5299507425121965

Epoch: 5| Step: 6
Training loss: 2.4200459125987037
Validation loss: 2.5709842086325825

Epoch: 5| Step: 7
Training loss: 1.989121774657782
Validation loss: 2.498383003071521

Epoch: 5| Step: 8
Training loss: 2.0877147632613173
Validation loss: 2.498749857500666

Epoch: 5| Step: 9
Training loss: 2.6234690425173914
Validation loss: 2.5138007849475197

Epoch: 5| Step: 10
Training loss: 2.152771839694239
Validation loss: 2.5170659347469195

Epoch: 5| Step: 11
Training loss: 1.0763717438074099
Validation loss: 2.5280853944245205

Epoch: 82| Step: 0
Training loss: 2.5545841861097704
Validation loss: 2.4717185003457876

Epoch: 5| Step: 1
Training loss: 1.5561159558765358
Validation loss: 2.5204904746092733

Epoch: 5| Step: 2
Training loss: 2.685560369284279
Validation loss: 2.483792866575474

Epoch: 5| Step: 3
Training loss: 1.998179918858325
Validation loss: 2.4512942907964037

Epoch: 5| Step: 4
Training loss: 1.6773919321148383
Validation loss: 2.5348408076156703

Epoch: 5| Step: 5
Training loss: 1.6849372618906522
Validation loss: 2.603773603657409

Epoch: 5| Step: 6
Training loss: 2.870813555896183
Validation loss: 2.6127941892247137

Epoch: 5| Step: 7
Training loss: 2.440995473255053
Validation loss: 2.598499805516249

Epoch: 5| Step: 8
Training loss: 1.9982600392042063
Validation loss: 2.605827611852484

Epoch: 5| Step: 9
Training loss: 2.356079427277264
Validation loss: 2.6030722238381516

Epoch: 5| Step: 10
Training loss: 2.4209660947269844
Validation loss: 2.5360430639282914

Epoch: 5| Step: 11
Training loss: 1.7003539053599697
Validation loss: 2.4915464328114005

Epoch: 83| Step: 0
Training loss: 1.9379703196997706
Validation loss: 2.403247442048817

Epoch: 5| Step: 1
Training loss: 1.7052515734777278
Validation loss: 2.498913425510071

Epoch: 5| Step: 2
Training loss: 2.1657934874680196
Validation loss: 2.4678254347831725

Epoch: 5| Step: 3
Training loss: 2.7355471469258577
Validation loss: 2.476953814504981

Epoch: 5| Step: 4
Training loss: 2.0800667775878865
Validation loss: 2.5453096076350974

Epoch: 5| Step: 5
Training loss: 1.9659364972030904
Validation loss: 2.482169393830144

Epoch: 5| Step: 6
Training loss: 1.5958997402202184
Validation loss: 2.5126822656974

Epoch: 5| Step: 7
Training loss: 2.4110535075176744
Validation loss: 2.5544528250664884

Epoch: 5| Step: 8
Training loss: 2.3924716972502633
Validation loss: 2.488531127072787

Epoch: 5| Step: 9
Training loss: 1.7792670606508358
Validation loss: 2.532597257837211

Epoch: 5| Step: 10
Training loss: 2.0746628452909786
Validation loss: 2.5280020758973927

Epoch: 5| Step: 11
Training loss: 2.569664870650419
Validation loss: 2.569348453040326

Epoch: 84| Step: 0
Training loss: 1.813128987057762
Validation loss: 2.537070509231374

Epoch: 5| Step: 1
Training loss: 1.8617661432083972
Validation loss: 2.4423131982399324

Epoch: 5| Step: 2
Training loss: 2.569386973611802
Validation loss: 2.530521382146351

Epoch: 5| Step: 3
Training loss: 2.385449860409885
Validation loss: 2.5344733605228105

Epoch: 5| Step: 4
Training loss: 2.1037153257253927
Validation loss: 2.4846812405365664

Epoch: 5| Step: 5
Training loss: 2.055982406503828
Validation loss: 2.5134296394379216

Epoch: 5| Step: 6
Training loss: 2.0121304285232506
Validation loss: 2.5401992131380293

Epoch: 5| Step: 7
Training loss: 1.8285534348517891
Validation loss: 2.502324386713907

Epoch: 5| Step: 8
Training loss: 2.0699718267025484
Validation loss: 2.4846508504763167

Epoch: 5| Step: 9
Training loss: 2.6991376630028214
Validation loss: 2.4636362889662657

Epoch: 5| Step: 10
Training loss: 1.7513364048729894
Validation loss: 2.52408703297329

Epoch: 5| Step: 11
Training loss: 1.1828298590128314
Validation loss: 2.557497969241562

Epoch: 85| Step: 0
Training loss: 2.027158872079682
Validation loss: 2.598501575572256

Epoch: 5| Step: 1
Training loss: 2.1540775135512664
Validation loss: 2.5894591025222438

Epoch: 5| Step: 2
Training loss: 1.571327223234364
Validation loss: 2.5746712564285565

Epoch: 5| Step: 3
Training loss: 2.8195950343146334
Validation loss: 2.630730168663312

Epoch: 5| Step: 4
Training loss: 2.3463797502608315
Validation loss: 2.600469116994495

Epoch: 5| Step: 5
Training loss: 2.226463556600932
Validation loss: 2.5455309904244263

Epoch: 5| Step: 6
Training loss: 1.7030774731085458
Validation loss: 2.5063019716196693

Epoch: 5| Step: 7
Training loss: 2.0694693521910885
Validation loss: 2.5684746661979907

Epoch: 5| Step: 8
Training loss: 2.1824673116886206
Validation loss: 2.523050280486641

Epoch: 5| Step: 9
Training loss: 1.9168878372404325
Validation loss: 2.5278201511578673

Epoch: 5| Step: 10
Training loss: 1.9685284323369747
Validation loss: 2.5267926400892224

Epoch: 5| Step: 11
Training loss: 1.849790022506639
Validation loss: 2.502038061371358

Epoch: 86| Step: 0
Training loss: 2.0244150046729597
Validation loss: 2.5533533783257396

Epoch: 5| Step: 1
Training loss: 1.7078650072965935
Validation loss: 2.4808851398196667

Epoch: 5| Step: 2
Training loss: 2.4113592425448442
Validation loss: 2.617546592104624

Epoch: 5| Step: 3
Training loss: 1.921206164086433
Validation loss: 2.498409615735411

Epoch: 5| Step: 4
Training loss: 1.9788812598854202
Validation loss: 2.476427565949103

Epoch: 5| Step: 5
Training loss: 1.785714627674615
Validation loss: 2.508454051603333

Epoch: 5| Step: 6
Training loss: 2.864244993631816
Validation loss: 2.5397575209674885

Epoch: 5| Step: 7
Training loss: 2.388490808818622
Validation loss: 2.558622527991983

Epoch: 5| Step: 8
Training loss: 1.696280559019957
Validation loss: 2.5307985970775464

Epoch: 5| Step: 9
Training loss: 2.1609063113838065
Validation loss: 2.5512078411912142

Epoch: 5| Step: 10
Training loss: 1.7345974753716067
Validation loss: 2.464532559474561

Epoch: 5| Step: 11
Training loss: 2.213384130519287
Validation loss: 2.593683996471466

Epoch: 87| Step: 0
Training loss: 2.2163586691750155
Validation loss: 2.587210703846838

Epoch: 5| Step: 1
Training loss: 2.20746558312688
Validation loss: 2.596416604003292

Epoch: 5| Step: 2
Training loss: 1.7955023788823063
Validation loss: 2.6492818051117015

Epoch: 5| Step: 3
Training loss: 2.3103369829512923
Validation loss: 2.653219562518277

Epoch: 5| Step: 4
Training loss: 1.421857309755381
Validation loss: 2.5763691558379236

Epoch: 5| Step: 5
Training loss: 2.184684139964483
Validation loss: 2.627938242085271

Epoch: 5| Step: 6
Training loss: 1.935527474222427
Validation loss: 2.540934636406033

Epoch: 5| Step: 7
Training loss: 1.643737601461899
Validation loss: 2.5714401044284196

Epoch: 5| Step: 8
Training loss: 1.660287362699452
Validation loss: 2.527514137998256

Epoch: 5| Step: 9
Training loss: 2.62639526343103
Validation loss: 2.5319329113702542

Epoch: 5| Step: 10
Training loss: 2.345522502770894
Validation loss: 2.4914369977774418

Epoch: 5| Step: 11
Training loss: 2.433008898266044
Validation loss: 2.5097505581375072

Epoch: 88| Step: 0
Training loss: 1.9197791852733326
Validation loss: 2.5012781571305154

Epoch: 5| Step: 1
Training loss: 2.0884059059622153
Validation loss: 2.5044455262444787

Epoch: 5| Step: 2
Training loss: 2.1799515321575735
Validation loss: 2.56391870954421

Epoch: 5| Step: 3
Training loss: 2.7155109271814926
Validation loss: 2.5184566601494067

Epoch: 5| Step: 4
Training loss: 1.685808110685634
Validation loss: 2.4865741872678613

Epoch: 5| Step: 5
Training loss: 1.788205470408136
Validation loss: 2.5504944519855597

Epoch: 5| Step: 6
Training loss: 2.3176483375127757
Validation loss: 2.5087199406390295

Epoch: 5| Step: 7
Training loss: 2.135800347323389
Validation loss: 2.5234608644204948

Epoch: 5| Step: 8
Training loss: 1.8574619228726803
Validation loss: 2.5628433423961234

Epoch: 5| Step: 9
Training loss: 2.577010775145747
Validation loss: 2.5648038982076664

Epoch: 5| Step: 10
Training loss: 1.6814615506515693
Validation loss: 2.5784086707138636

Epoch: 5| Step: 11
Training loss: 1.246598861825767
Validation loss: 2.5573622673736125

Epoch: 89| Step: 0
Training loss: 2.0085286447781945
Validation loss: 2.5545581625455

Epoch: 5| Step: 1
Training loss: 1.8179781767203627
Validation loss: 2.5643019155881572

Epoch: 5| Step: 2
Training loss: 1.9144391370510205
Validation loss: 2.524618600691447

Epoch: 5| Step: 3
Training loss: 1.8564539813341459
Validation loss: 2.5383339800200346

Epoch: 5| Step: 4
Training loss: 2.835995003613804
Validation loss: 2.4936256046229737

Epoch: 5| Step: 5
Training loss: 2.0412596342253053
Validation loss: 2.5431498020175516

Epoch: 5| Step: 6
Training loss: 2.3097800677741627
Validation loss: 2.5070992522082722

Epoch: 5| Step: 7
Training loss: 2.1177926975701826
Validation loss: 2.513589841368081

Epoch: 5| Step: 8
Training loss: 2.168790534352493
Validation loss: 2.457046508741682

Epoch: 5| Step: 9
Training loss: 1.9610791402173338
Validation loss: 2.534770793246211

Epoch: 5| Step: 10
Training loss: 1.7378566266174966
Validation loss: 2.5121112633466063

Epoch: 5| Step: 11
Training loss: 2.3999927957744553
Validation loss: 2.5621094173402894

Epoch: 90| Step: 0
Training loss: 1.806697106380619
Validation loss: 2.5494158772349813

Epoch: 5| Step: 1
Training loss: 2.036193349107582
Validation loss: 2.6349200483180786

Epoch: 5| Step: 2
Training loss: 1.7214868429956993
Validation loss: 2.592862345002701

Epoch: 5| Step: 3
Training loss: 2.240030454019883
Validation loss: 2.616102808034581

Epoch: 5| Step: 4
Training loss: 2.0247598105316684
Validation loss: 2.5342763814933753

Epoch: 5| Step: 5
Training loss: 2.4059886047271006
Validation loss: 2.5521623222946683

Epoch: 5| Step: 6
Training loss: 2.573389038296685
Validation loss: 2.592840077225697

Epoch: 5| Step: 7
Training loss: 2.2373814130503944
Validation loss: 2.53367124931633

Epoch: 5| Step: 8
Training loss: 2.497261263841902
Validation loss: 2.560249117316547

Epoch: 5| Step: 9
Training loss: 1.4612467229462125
Validation loss: 2.5188950910972387

Epoch: 5| Step: 10
Training loss: 1.7739245044337202
Validation loss: 2.563456130173408

Epoch: 5| Step: 11
Training loss: 1.7505277791481797
Validation loss: 2.4903526766732176

Epoch: 91| Step: 0
Training loss: 2.3735975843113204
Validation loss: 2.532708207182962

Epoch: 5| Step: 1
Training loss: 2.2813400877840135
Validation loss: 2.5482706134974986

Epoch: 5| Step: 2
Training loss: 2.4401724421429316
Validation loss: 2.5198350215607808

Epoch: 5| Step: 3
Training loss: 1.7123153921153647
Validation loss: 2.562750966878025

Epoch: 5| Step: 4
Training loss: 1.8065458035716175
Validation loss: 2.551622054523775

Epoch: 5| Step: 5
Training loss: 1.902493762734173
Validation loss: 2.6063932945079347

Epoch: 5| Step: 6
Training loss: 2.548909971596573
Validation loss: 2.6408858913376942

Epoch: 5| Step: 7
Training loss: 1.5526978302499777
Validation loss: 2.5919180992387507

Epoch: 5| Step: 8
Training loss: 1.7521905812548846
Validation loss: 2.5634787442637044

Epoch: 5| Step: 9
Training loss: 1.652596312355046
Validation loss: 2.5554918584164614

Epoch: 5| Step: 10
Training loss: 2.0750842111803536
Validation loss: 2.5625379606086907

Epoch: 5| Step: 11
Training loss: 2.5409430010399077
Validation loss: 2.5373268572612244

Epoch: 92| Step: 0
Training loss: 1.7397491086751171
Validation loss: 2.4532937358320375

Epoch: 5| Step: 1
Training loss: 1.6200942301718844
Validation loss: 2.54067289096916

Epoch: 5| Step: 2
Training loss: 1.7741824698591717
Validation loss: 2.5081138469398323

Epoch: 5| Step: 3
Training loss: 1.7649927273133088
Validation loss: 2.573403485507062

Epoch: 5| Step: 4
Training loss: 2.0216751966849453
Validation loss: 2.6129195034693207

Epoch: 5| Step: 5
Training loss: 1.8419677396221124
Validation loss: 2.6194146582124747

Epoch: 5| Step: 6
Training loss: 2.5741544724168692
Validation loss: 2.6037651680748573

Epoch: 5| Step: 7
Training loss: 1.7407856591421096
Validation loss: 2.607066795374298

Epoch: 5| Step: 8
Training loss: 1.8603906502209269
Validation loss: 2.5436236646180275

Epoch: 5| Step: 9
Training loss: 2.2143859928470877
Validation loss: 2.553099505212774

Epoch: 5| Step: 10
Training loss: 2.8183030342926267
Validation loss: 2.5770037977752906

Epoch: 5| Step: 11
Training loss: 2.7283140311454557
Validation loss: 2.5880620302261015

Epoch: 93| Step: 0
Training loss: 2.6925262645407377
Validation loss: 2.558045729946684

Epoch: 5| Step: 1
Training loss: 1.8067834746101
Validation loss: 2.5937357676165353

Epoch: 5| Step: 2
Training loss: 2.148477893796405
Validation loss: 2.5803216765828343

Epoch: 5| Step: 3
Training loss: 1.4880804291851146
Validation loss: 2.5896804627677774

Epoch: 5| Step: 4
Training loss: 1.7910793879649556
Validation loss: 2.5829027006687904

Epoch: 5| Step: 5
Training loss: 2.566916312012286
Validation loss: 2.6850378915900075

Epoch: 5| Step: 6
Training loss: 2.087037671453352
Validation loss: 2.6715143715121283

Epoch: 5| Step: 7
Training loss: 1.7848440352189776
Validation loss: 2.7007521171937006

Epoch: 5| Step: 8
Training loss: 2.2584270973963605
Validation loss: 2.612849820974641

Epoch: 5| Step: 9
Training loss: 2.010500878133442
Validation loss: 2.557837268147825

Epoch: 5| Step: 10
Training loss: 1.5115523530131725
Validation loss: 2.498250991240725

Epoch: 5| Step: 11
Training loss: 1.5640160644223313
Validation loss: 2.5900580968134137

Epoch: 94| Step: 0
Training loss: 1.911142667921382
Validation loss: 2.5589707502075094

Epoch: 5| Step: 1
Training loss: 1.3881903778028482
Validation loss: 2.6028219922111306

Epoch: 5| Step: 2
Training loss: 2.1654828089593408
Validation loss: 2.537332256297449

Epoch: 5| Step: 3
Training loss: 2.151156172271656
Validation loss: 2.509268297529372

Epoch: 5| Step: 4
Training loss: 2.255988522750662
Validation loss: 2.544233165033931

Epoch: 5| Step: 5
Training loss: 2.20906348723415
Validation loss: 2.539181627266627

Epoch: 5| Step: 6
Training loss: 2.4543489937877387
Validation loss: 2.5308595893939456

Epoch: 5| Step: 7
Training loss: 1.7871699421942824
Validation loss: 2.602141021005572

Epoch: 5| Step: 8
Training loss: 1.6954318940622666
Validation loss: 2.6001658045952305

Epoch: 5| Step: 9
Training loss: 2.6208186680353633
Validation loss: 2.6993681686419735

Epoch: 5| Step: 10
Training loss: 1.954259131168321
Validation loss: 2.7132986854427252

Epoch: 5| Step: 11
Training loss: 2.032694493708939
Validation loss: 2.672344389614673

Epoch: 95| Step: 0
Training loss: 1.9229381071020246
Validation loss: 2.6288080334088573

Epoch: 5| Step: 1
Training loss: 2.317829691820701
Validation loss: 2.5619160037091397

Epoch: 5| Step: 2
Training loss: 2.5253986497177703
Validation loss: 2.597216962416882

Epoch: 5| Step: 3
Training loss: 1.5285875178255577
Validation loss: 2.5508963640223463

Epoch: 5| Step: 4
Training loss: 1.746128022201056
Validation loss: 2.5442540543366388

Epoch: 5| Step: 5
Training loss: 1.9254600148651762
Validation loss: 2.5611663658682415

Epoch: 5| Step: 6
Training loss: 1.7370725394054136
Validation loss: 2.5849395239941915

Epoch: 5| Step: 7
Training loss: 2.1701452378921884
Validation loss: 2.519102153660786

Epoch: 5| Step: 8
Training loss: 2.252927147674121
Validation loss: 2.5893845110242926

Epoch: 5| Step: 9
Training loss: 1.4789512728182106
Validation loss: 2.540387536588308

Epoch: 5| Step: 10
Training loss: 2.4163870375640606
Validation loss: 2.5852311543979525

Epoch: 5| Step: 11
Training loss: 1.7417705361940719
Validation loss: 2.60426057391922

Epoch: 96| Step: 0
Training loss: 1.5867859022767712
Validation loss: 2.5365794438163607

Epoch: 5| Step: 1
Training loss: 1.6392589876790438
Validation loss: 2.664472766507978

Epoch: 5| Step: 2
Training loss: 3.0120548600042616
Validation loss: 2.5583145455178964

Epoch: 5| Step: 3
Training loss: 1.9867492649436542
Validation loss: 2.571574329431373

Epoch: 5| Step: 4
Training loss: 1.9564859997438273
Validation loss: 2.6559879360698178

Epoch: 5| Step: 5
Training loss: 1.9635014281125627
Validation loss: 2.5846553824139633

Epoch: 5| Step: 6
Training loss: 2.143234110780547
Validation loss: 2.5130905352530375

Epoch: 5| Step: 7
Training loss: 1.9631605579516407
Validation loss: 2.573693811884963

Epoch: 5| Step: 8
Training loss: 1.8858547088225237
Validation loss: 2.5967516019402512

Epoch: 5| Step: 9
Training loss: 2.165346501485751
Validation loss: 2.5412201013571596

Epoch: 5| Step: 10
Training loss: 1.714675790820805
Validation loss: 2.5715022015058726

Epoch: 5| Step: 11
Training loss: 1.4923034143613445
Validation loss: 2.5312721267172655

Epoch: 97| Step: 0
Training loss: 2.077082551773011
Validation loss: 2.6058327812797697

Epoch: 5| Step: 1
Training loss: 2.284423501977941
Validation loss: 2.6207124913187996

Epoch: 5| Step: 2
Training loss: 1.9280902259695656
Validation loss: 2.671113004091588

Epoch: 5| Step: 3
Training loss: 1.8001384125580637
Validation loss: 2.7014767945202736

Epoch: 5| Step: 4
Training loss: 2.6149143652816527
Validation loss: 2.6978350753425846

Epoch: 5| Step: 5
Training loss: 1.647551673692383
Validation loss: 2.6291406988885755

Epoch: 5| Step: 6
Training loss: 2.3927743262984533
Validation loss: 2.6137062909329933

Epoch: 5| Step: 7
Training loss: 2.114072415370202
Validation loss: 2.6307357498496415

Epoch: 5| Step: 8
Training loss: 1.902255641768962
Validation loss: 2.558170405883595

Epoch: 5| Step: 9
Training loss: 2.012192279675514
Validation loss: 2.5711981804039232

Epoch: 5| Step: 10
Training loss: 1.430175697897104
Validation loss: 2.57515189469728

Epoch: 5| Step: 11
Training loss: 1.6559935317212628
Validation loss: 2.5678658865874464

Epoch: 98| Step: 0
Training loss: 1.9679296086058287
Validation loss: 2.5552679990843568

Epoch: 5| Step: 1
Training loss: 1.8265582813119587
Validation loss: 2.5458493771232202

Epoch: 5| Step: 2
Training loss: 2.2529799542980835
Validation loss: 2.5560994946476474

Epoch: 5| Step: 3
Training loss: 1.1089494453134676
Validation loss: 2.560603777662716

Epoch: 5| Step: 4
Training loss: 2.8238298879183352
Validation loss: 2.550101535776492

Epoch: 5| Step: 5
Training loss: 1.670959079161479
Validation loss: 2.5371822418172187

Epoch: 5| Step: 6
Training loss: 1.8320419864299273
Validation loss: 2.525909299757938

Epoch: 5| Step: 7
Training loss: 2.3392035574926417
Validation loss: 2.642435476471125

Epoch: 5| Step: 8
Training loss: 2.3937029004754597
Validation loss: 2.6355024249682595

Epoch: 5| Step: 9
Training loss: 1.839031193935896
Validation loss: 2.638384348058223

Epoch: 5| Step: 10
Training loss: 1.5666612526955634
Validation loss: 2.5871894241536575

Epoch: 5| Step: 11
Training loss: 2.0994285896005205
Validation loss: 2.590322098396857

Epoch: 99| Step: 0
Training loss: 1.713329089427892
Validation loss: 2.5025873583898384

Epoch: 5| Step: 1
Training loss: 1.999801625904117
Validation loss: 2.535829870917591

Epoch: 5| Step: 2
Training loss: 2.196055873570003
Validation loss: 2.555619803659939

Epoch: 5| Step: 3
Training loss: 1.9563002753576717
Validation loss: 2.5980933756154334

Epoch: 5| Step: 4
Training loss: 2.305449382476999
Validation loss: 2.586078985671195

Epoch: 5| Step: 5
Training loss: 2.3460196123531043
Validation loss: 2.563456128235768

Epoch: 5| Step: 6
Training loss: 1.7627523904366813
Validation loss: 2.5259682569291284

Epoch: 5| Step: 7
Training loss: 1.92180912556216
Validation loss: 2.484800530224318

Epoch: 5| Step: 8
Training loss: 2.2824655717005973
Validation loss: 2.516549266409484

Epoch: 5| Step: 9
Training loss: 1.5240791730064553
Validation loss: 2.652440772999785

Epoch: 5| Step: 10
Training loss: 2.1991071926842882
Validation loss: 2.583270596439731

Epoch: 5| Step: 11
Training loss: 1.9626945739313468
Validation loss: 2.7475737178158677

Epoch: 100| Step: 0
Training loss: 2.1928051514140217
Validation loss: 2.7522816223934536

Epoch: 5| Step: 1
Training loss: 2.5452529328871436
Validation loss: 2.714647607098546

Epoch: 5| Step: 2
Training loss: 2.245614440196664
Validation loss: 2.641868362538748

Epoch: 5| Step: 3
Training loss: 1.8252885773222078
Validation loss: 2.536670998359905

Epoch: 5| Step: 4
Training loss: 1.7785198638081283
Validation loss: 2.51246377308351

Epoch: 5| Step: 5
Training loss: 1.474280233470682
Validation loss: 2.5172472475689536

Epoch: 5| Step: 6
Training loss: 1.9552631728851972
Validation loss: 2.531010899024053

Epoch: 5| Step: 7
Training loss: 2.276632783599468
Validation loss: 2.483659309289104

Epoch: 5| Step: 8
Training loss: 2.0067052496984905
Validation loss: 2.5910905087697316

Epoch: 5| Step: 9
Training loss: 1.9806224755812472
Validation loss: 2.5443037350471993

Epoch: 5| Step: 10
Training loss: 2.4793975679809526
Validation loss: 2.5367419099352606

Epoch: 5| Step: 11
Training loss: 2.2692476971975917
Validation loss: 2.5864274865926746

Epoch: 101| Step: 0
Training loss: 1.478792071481613
Validation loss: 2.5785489937824404

Epoch: 5| Step: 1
Training loss: 1.8876800299675605
Validation loss: 2.5752966307179026

Epoch: 5| Step: 2
Training loss: 1.674485637203389
Validation loss: 2.5838860194872586

Epoch: 5| Step: 3
Training loss: 2.3965987820974695
Validation loss: 2.571724018070128

Epoch: 5| Step: 4
Training loss: 1.4462414204994989
Validation loss: 2.5345603975404525

Epoch: 5| Step: 5
Training loss: 2.194370379854585
Validation loss: 2.565377407076129

Epoch: 5| Step: 6
Training loss: 2.5600447638889507
Validation loss: 2.5266127907507965

Epoch: 5| Step: 7
Training loss: 2.0222542738674205
Validation loss: 2.4799929225023347

Epoch: 5| Step: 8
Training loss: 1.6765233955195755
Validation loss: 2.5522549798554235

Epoch: 5| Step: 9
Training loss: 1.9234870414644443
Validation loss: 2.485830968000374

Epoch: 5| Step: 10
Training loss: 2.0235951483742802
Validation loss: 2.5061697803574456

Epoch: 5| Step: 11
Training loss: 1.8916803362292263
Validation loss: 2.4888380576470177

Epoch: 102| Step: 0
Training loss: 1.9185830431938518
Validation loss: 2.545366714334168

Epoch: 5| Step: 1
Training loss: 1.8985817936820697
Validation loss: 2.5299049461486383

Epoch: 5| Step: 2
Training loss: 1.9712066460814772
Validation loss: 2.5291652296607907

Epoch: 5| Step: 3
Training loss: 1.998295653844075
Validation loss: 2.589799323451298

Epoch: 5| Step: 4
Training loss: 1.8575338015041527
Validation loss: 2.575518972912391

Epoch: 5| Step: 5
Training loss: 2.2733533915793585
Validation loss: 2.5536418567501764

Epoch: 5| Step: 6
Training loss: 2.0797164674227555
Validation loss: 2.557090375841983

Epoch: 5| Step: 7
Training loss: 2.1612431307981903
Validation loss: 2.5777523079649285

Epoch: 5| Step: 8
Training loss: 2.0388741241784363
Validation loss: 2.540919856016977

Epoch: 5| Step: 9
Training loss: 2.1296258952465887
Validation loss: 2.5648532815741207

Epoch: 5| Step: 10
Training loss: 1.3630422038277423
Validation loss: 2.5111856483150032

Epoch: 5| Step: 11
Training loss: 1.4949274123313308
Validation loss: 2.54481950750644

Epoch: 103| Step: 0
Training loss: 1.8728309801279328
Validation loss: 2.5197794631803374

Epoch: 5| Step: 1
Training loss: 2.401139120136371
Validation loss: 2.5962993280606756

Epoch: 5| Step: 2
Training loss: 2.000836078409422
Validation loss: 2.499060915364936

Epoch: 5| Step: 3
Training loss: 2.0924496384625253
Validation loss: 2.606998880772411

Epoch: 5| Step: 4
Training loss: 1.9868254662525366
Validation loss: 2.6482663094586045

Epoch: 5| Step: 5
Training loss: 2.2269986980213456
Validation loss: 2.5415790235281768

Epoch: 5| Step: 6
Training loss: 1.5276137013424482
Validation loss: 2.5176126355907593

Epoch: 5| Step: 7
Training loss: 1.9560933254499575
Validation loss: 2.575781321426744

Epoch: 5| Step: 8
Training loss: 1.6338898239484718
Validation loss: 2.589915927132444

Epoch: 5| Step: 9
Training loss: 1.5316490898881028
Validation loss: 2.5677496859694173

Epoch: 5| Step: 10
Training loss: 1.9747959731744171
Validation loss: 2.5297229069287104

Epoch: 5| Step: 11
Training loss: 1.7023419321093365
Validation loss: 2.515969701019249

Epoch: 104| Step: 0
Training loss: 1.5815256323339721
Validation loss: 2.524776827672085

Epoch: 5| Step: 1
Training loss: 1.9001188015186428
Validation loss: 2.5616723871839393

Epoch: 5| Step: 2
Training loss: 2.1548575729071704
Validation loss: 2.592299300793675

Epoch: 5| Step: 3
Training loss: 1.9615694524724758
Validation loss: 2.5558044449457085

Epoch: 5| Step: 4
Training loss: 1.7972287700533143
Validation loss: 2.627861563580297

Epoch: 5| Step: 5
Training loss: 1.9838147311114709
Validation loss: 2.5904064037157943

Epoch: 5| Step: 6
Training loss: 2.0432485822782147
Validation loss: 2.593726020150616

Epoch: 5| Step: 7
Training loss: 2.644120109750152
Validation loss: 2.6174344453979566

Epoch: 5| Step: 8
Training loss: 1.257848229700456
Validation loss: 2.5528202679676584

Epoch: 5| Step: 9
Training loss: 2.1156229805197158
Validation loss: 2.562745388811182

Epoch: 5| Step: 10
Training loss: 1.846908321176846
Validation loss: 2.573421746587721

Epoch: 5| Step: 11
Training loss: 1.4691884624114382
Validation loss: 2.5905582867274224

Epoch: 105| Step: 0
Training loss: 1.714041624402846
Validation loss: 2.6522192871974406

Epoch: 5| Step: 1
Training loss: 1.6502669609734264
Validation loss: 2.555378807706322

Epoch: 5| Step: 2
Training loss: 2.1123853889389097
Validation loss: 2.6165116533500665

Epoch: 5| Step: 3
Training loss: 1.84611831112738
Validation loss: 2.52716473393009

Epoch: 5| Step: 4
Training loss: 1.5283685158632332
Validation loss: 2.5723983664743777

Epoch: 5| Step: 5
Training loss: 1.6214828575750246
Validation loss: 2.600579325158669

Epoch: 5| Step: 6
Training loss: 1.8209150896842283
Validation loss: 2.5248189831361425

Epoch: 5| Step: 7
Training loss: 2.511408334300545
Validation loss: 2.5735978538831414

Epoch: 5| Step: 8
Training loss: 2.2778029853955983
Validation loss: 2.580102943996019

Epoch: 5| Step: 9
Training loss: 1.572135057418232
Validation loss: 2.5931643089023666

Epoch: 5| Step: 10
Training loss: 2.0490336210546674
Validation loss: 2.6101709472948844

Epoch: 5| Step: 11
Training loss: 1.8061259428406364
Validation loss: 2.6170860346773255

Epoch: 106| Step: 0
Training loss: 1.906670320791909
Validation loss: 2.7043797992851495

Epoch: 5| Step: 1
Training loss: 1.4622994668530338
Validation loss: 2.752802905099434

Epoch: 5| Step: 2
Training loss: 1.6818462604971847
Validation loss: 2.7332876532118044

Epoch: 5| Step: 3
Training loss: 2.817688881365654
Validation loss: 2.645983644155717

Epoch: 5| Step: 4
Training loss: 1.7870888297145522
Validation loss: 2.601760283962176

Epoch: 5| Step: 5
Training loss: 1.6729926535837845
Validation loss: 2.6028468042516733

Epoch: 5| Step: 6
Training loss: 2.2478769670668863
Validation loss: 2.620945122300158

Epoch: 5| Step: 7
Training loss: 2.065497560941521
Validation loss: 2.485479896894362

Epoch: 5| Step: 8
Training loss: 2.2792050327602964
Validation loss: 2.566830151530459

Epoch: 5| Step: 9
Training loss: 1.7092350541594423
Validation loss: 2.5755138467836005

Epoch: 5| Step: 10
Training loss: 2.0955807098159065
Validation loss: 2.5486685399633906

Epoch: 5| Step: 11
Training loss: 1.9472998460155946
Validation loss: 2.498486485894673

Epoch: 107| Step: 0
Training loss: 1.884994445509278
Validation loss: 2.5585712266857614

Epoch: 5| Step: 1
Training loss: 2.180992036884503
Validation loss: 2.6019654444023135

Epoch: 5| Step: 2
Training loss: 2.093344008525834
Validation loss: 2.5742333063959566

Epoch: 5| Step: 3
Training loss: 1.8305793653890785
Validation loss: 2.623767783068517

Epoch: 5| Step: 4
Training loss: 1.841777587012936
Validation loss: 2.6495369061212086

Epoch: 5| Step: 5
Training loss: 1.4007583199287483
Validation loss: 2.615211910258626

Epoch: 5| Step: 6
Training loss: 1.9203079161500036
Validation loss: 2.6307351494384195

Epoch: 5| Step: 7
Training loss: 2.1693721043889695
Validation loss: 2.5720798441755455

Epoch: 5| Step: 8
Training loss: 1.8471801660605418
Validation loss: 2.5870543197448317

Epoch: 5| Step: 9
Training loss: 1.7672962617332868
Validation loss: 2.5780646037724235

Epoch: 5| Step: 10
Training loss: 2.158549423397744
Validation loss: 2.626796482336774

Epoch: 5| Step: 11
Training loss: 1.51370416422214
Validation loss: 2.53374176847717

Epoch: 108| Step: 0
Training loss: 2.3685534473691816
Validation loss: 2.557247776553499

Epoch: 5| Step: 1
Training loss: 1.622915251130975
Validation loss: 2.573478661806127

Epoch: 5| Step: 2
Training loss: 1.652518910171415
Validation loss: 2.6098991103726803

Epoch: 5| Step: 3
Training loss: 1.4749575980605885
Validation loss: 2.6611653009233858

Epoch: 5| Step: 4
Training loss: 2.176868105627462
Validation loss: 2.650488270455676

Epoch: 5| Step: 5
Training loss: 2.0305817898807987
Validation loss: 2.7708701361934462

Epoch: 5| Step: 6
Training loss: 2.0641790549140473
Validation loss: 2.7207253321252294

Epoch: 5| Step: 7
Training loss: 2.1027381756624344
Validation loss: 2.673191515844411

Epoch: 5| Step: 8
Training loss: 2.212775770339653
Validation loss: 2.619120848806479

Epoch: 5| Step: 9
Training loss: 1.6601912909904883
Validation loss: 2.505660071193751

Epoch: 5| Step: 10
Training loss: 2.3765429453951326
Validation loss: 2.6150022768858023

Epoch: 5| Step: 11
Training loss: 2.529712445499544
Validation loss: 2.6474500632687157

Epoch: 109| Step: 0
Training loss: 1.9003847912094103
Validation loss: 2.5790609105931606

Epoch: 5| Step: 1
Training loss: 1.8530873647023451
Validation loss: 2.504468238833275

Epoch: 5| Step: 2
Training loss: 2.415153775265399
Validation loss: 2.563770752510806

Epoch: 5| Step: 3
Training loss: 1.6202962729249375
Validation loss: 2.6594036006622255

Epoch: 5| Step: 4
Training loss: 1.802090249755758
Validation loss: 2.527401022873841

Epoch: 5| Step: 5
Training loss: 2.031315846476306
Validation loss: 2.762286468239347

Epoch: 5| Step: 6
Training loss: 2.0524372499192167
Validation loss: 2.851382416216484

Epoch: 5| Step: 7
Training loss: 2.163933374842404
Validation loss: 2.76269260126338

Epoch: 5| Step: 8
Training loss: 2.403804576807658
Validation loss: 2.685796234576113

Epoch: 5| Step: 9
Training loss: 1.9656784074620395
Validation loss: 2.591265867638298

Epoch: 5| Step: 10
Training loss: 1.667356570822551
Validation loss: 2.558889124469946

Epoch: 5| Step: 11
Training loss: 1.6996736465677862
Validation loss: 2.6378566707182824

Epoch: 110| Step: 0
Training loss: 1.8389823824820137
Validation loss: 2.6115618429730514

Epoch: 5| Step: 1
Training loss: 1.654149144589933
Validation loss: 2.6075815540048914

Epoch: 5| Step: 2
Training loss: 1.9138341027833852
Validation loss: 2.608960996362093

Epoch: 5| Step: 3
Training loss: 1.9231609601218997
Validation loss: 2.622436766824278

Epoch: 5| Step: 4
Training loss: 2.1437804639781506
Validation loss: 2.566576936059509

Epoch: 5| Step: 5
Training loss: 1.8353760855176022
Validation loss: 2.6032681911571336

Epoch: 5| Step: 6
Training loss: 2.0541552880560734
Validation loss: 2.5031181003572303

Epoch: 5| Step: 7
Training loss: 2.1333140248179845
Validation loss: 2.6593508142909807

Epoch: 5| Step: 8
Training loss: 1.5838332474529333
Validation loss: 2.758346938092966

Epoch: 5| Step: 9
Training loss: 2.6198074208892503
Validation loss: 2.748013519467863

Epoch: 5| Step: 10
Training loss: 2.011175641569546
Validation loss: 2.7831970892946707

Epoch: 5| Step: 11
Training loss: 1.1159502127080052
Validation loss: 2.777922472099241

Epoch: 111| Step: 0
Training loss: 1.8978923752783372
Validation loss: 2.7427797936734373

Epoch: 5| Step: 1
Training loss: 2.25306514073192
Validation loss: 2.6391444523073866

Epoch: 5| Step: 2
Training loss: 1.7676836013937083
Validation loss: 2.6600872745991615

Epoch: 5| Step: 3
Training loss: 1.831041406201833
Validation loss: 2.5359323897577624

Epoch: 5| Step: 4
Training loss: 1.4704044844325508
Validation loss: 2.5197319483109926

Epoch: 5| Step: 5
Training loss: 2.5590931645227437
Validation loss: 2.595606700444779

Epoch: 5| Step: 6
Training loss: 1.9295457795646598
Validation loss: 2.5172222607053745

Epoch: 5| Step: 7
Training loss: 2.3305788357521315
Validation loss: 2.542637504102677

Epoch: 5| Step: 8
Training loss: 1.8111274389234355
Validation loss: 2.5215137813871533

Epoch: 5| Step: 9
Training loss: 1.8993933512286627
Validation loss: 2.6067233403643404

Epoch: 5| Step: 10
Training loss: 1.8270622489985662
Validation loss: 2.558102579510203

Epoch: 5| Step: 11
Training loss: 1.797164893607616
Validation loss: 2.53804042492079

Epoch: 112| Step: 0
Training loss: 1.8479208242662775
Validation loss: 2.571858120102336

Epoch: 5| Step: 1
Training loss: 2.400421514847776
Validation loss: 2.577975575133836

Epoch: 5| Step: 2
Training loss: 1.8811253629946836
Validation loss: 2.6406535009768457

Epoch: 5| Step: 3
Training loss: 1.6858808025340295
Validation loss: 2.7039574644067415

Epoch: 5| Step: 4
Training loss: 1.6042078268872502
Validation loss: 2.5843833909365546

Epoch: 5| Step: 5
Training loss: 1.7423777112917143
Validation loss: 2.6617499276990593

Epoch: 5| Step: 6
Training loss: 1.7427841328129525
Validation loss: 2.650967150367249

Epoch: 5| Step: 7
Training loss: 1.611716113918144
Validation loss: 2.610357255759395

Epoch: 5| Step: 8
Training loss: 2.257477309745574
Validation loss: 2.526293072856305

Epoch: 5| Step: 9
Training loss: 1.822302389642865
Validation loss: 2.5746381241482927

Epoch: 5| Step: 10
Training loss: 1.6673122427266267
Validation loss: 2.6395375233995315

Epoch: 5| Step: 11
Training loss: 1.600489112480907
Validation loss: 2.5200348501091545

Epoch: 113| Step: 0
Training loss: 1.4858027769160616
Validation loss: 2.5433572139427123

Epoch: 5| Step: 1
Training loss: 2.0543676787391885
Validation loss: 2.5236753070214633

Epoch: 5| Step: 2
Training loss: 1.7134786051206763
Validation loss: 2.494561825214532

Epoch: 5| Step: 3
Training loss: 1.8168262283293117
Validation loss: 2.563800183410612

Epoch: 5| Step: 4
Training loss: 1.9420691112670585
Validation loss: 2.5722030404176452

Epoch: 5| Step: 5
Training loss: 1.9769047376752
Validation loss: 2.62207747303928

Epoch: 5| Step: 6
Training loss: 2.02393137674513
Validation loss: 2.617626944699919

Epoch: 5| Step: 7
Training loss: 1.7002715258576955
Validation loss: 2.5812899034570074

Epoch: 5| Step: 8
Training loss: 1.8806898252572894
Validation loss: 2.588963040007136

Epoch: 5| Step: 9
Training loss: 2.215174197888226
Validation loss: 2.557605865247596

Epoch: 5| Step: 10
Training loss: 1.6080170615273222
Validation loss: 2.5234667891464895

Epoch: 5| Step: 11
Training loss: 1.3584889999466592
Validation loss: 2.587033630119326

Epoch: 114| Step: 0
Training loss: 1.475958968246084
Validation loss: 2.5930558466921085

Epoch: 5| Step: 1
Training loss: 2.0068832206260705
Validation loss: 2.619798278547454

Epoch: 5| Step: 2
Training loss: 1.694510063436414
Validation loss: 2.6065317070293132

Epoch: 5| Step: 3
Training loss: 2.202994051890194
Validation loss: 2.563955304688601

Epoch: 5| Step: 4
Training loss: 2.004769479527794
Validation loss: 2.603477433867241

Epoch: 5| Step: 5
Training loss: 1.964165572418482
Validation loss: 2.593657480451162

Epoch: 5| Step: 6
Training loss: 1.6682330241552228
Validation loss: 2.571001967201484

Epoch: 5| Step: 7
Training loss: 1.7762878635137274
Validation loss: 2.6053743474006246

Epoch: 5| Step: 8
Training loss: 1.9197715475346306
Validation loss: 2.5781668303207663

Epoch: 5| Step: 9
Training loss: 1.6394982237903668
Validation loss: 2.59715145818477

Epoch: 5| Step: 10
Training loss: 1.9137216692720513
Validation loss: 2.697491156899727

Epoch: 5| Step: 11
Training loss: 1.7496028858293577
Validation loss: 2.6750110455163147

Epoch: 115| Step: 0
Training loss: 1.8230332110252343
Validation loss: 2.6591746591367986

Epoch: 5| Step: 1
Training loss: 2.12011640031221
Validation loss: 2.551679257433039

Epoch: 5| Step: 2
Training loss: 1.7275289877020386
Validation loss: 2.5875926449602122

Epoch: 5| Step: 3
Training loss: 2.1104674724502406
Validation loss: 2.497058309924784

Epoch: 5| Step: 4
Training loss: 1.9349201623577357
Validation loss: 2.5434615619160392

Epoch: 5| Step: 5
Training loss: 1.888124814732734
Validation loss: 2.54890706024129

Epoch: 5| Step: 6
Training loss: 1.6956438716368352
Validation loss: 2.571121919335264

Epoch: 5| Step: 7
Training loss: 1.5707495541411802
Validation loss: 2.594080766016825

Epoch: 5| Step: 8
Training loss: 1.6322520631206583
Validation loss: 2.5813639245435653

Epoch: 5| Step: 9
Training loss: 2.1137794006215946
Validation loss: 2.597512583954539

Epoch: 5| Step: 10
Training loss: 2.2271328379663387
Validation loss: 2.6134071718905902

Epoch: 5| Step: 11
Training loss: 1.3781551228040283
Validation loss: 2.626161186033473

Epoch: 116| Step: 0
Training loss: 2.6920465557556232
Validation loss: 2.7429693000580677

Epoch: 5| Step: 1
Training loss: 1.872582784842111
Validation loss: 2.7477066997126296

Epoch: 5| Step: 2
Training loss: 2.0880415802100387
Validation loss: 2.680751478093572

Epoch: 5| Step: 3
Training loss: 1.536581140125444
Validation loss: 2.7313822617503174

Epoch: 5| Step: 4
Training loss: 1.4422896657942061
Validation loss: 2.6070826430033027

Epoch: 5| Step: 5
Training loss: 2.1013721252207533
Validation loss: 2.571339549877606

Epoch: 5| Step: 6
Training loss: 1.3412432243268457
Validation loss: 2.563447501850407

Epoch: 5| Step: 7
Training loss: 2.0250739472627473
Validation loss: 2.5841216658539023

Epoch: 5| Step: 8
Training loss: 1.7574859315789346
Validation loss: 2.6011757243335567

Epoch: 5| Step: 9
Training loss: 1.8604662602027437
Validation loss: 2.6202224177611635

Epoch: 5| Step: 10
Training loss: 1.9366690792040262
Validation loss: 2.633740896261444

Epoch: 5| Step: 11
Training loss: 2.3035658353651036
Validation loss: 2.5775898233444856

Epoch: 117| Step: 0
Training loss: 2.2446685780871216
Validation loss: 2.600537183025012

Epoch: 5| Step: 1
Training loss: 1.4165990009229477
Validation loss: 2.5544805024849544

Epoch: 5| Step: 2
Training loss: 1.901963714927388
Validation loss: 2.6467920854080518

Epoch: 5| Step: 3
Training loss: 1.9721400425882427
Validation loss: 2.681450992926181

Epoch: 5| Step: 4
Training loss: 2.0486395997331317
Validation loss: 2.66179619129605

Epoch: 5| Step: 5
Training loss: 1.7637950900645227
Validation loss: 2.6546496825118755

Epoch: 5| Step: 6
Training loss: 1.6294719345002837
Validation loss: 2.6302331577048594

Epoch: 5| Step: 7
Training loss: 1.9734038796358604
Validation loss: 2.572937657712079

Epoch: 5| Step: 8
Training loss: 1.9175096261430653
Validation loss: 2.5748163474123085

Epoch: 5| Step: 9
Training loss: 2.2216542538035937
Validation loss: 2.575592008532293

Epoch: 5| Step: 10
Training loss: 1.5431044120543058
Validation loss: 2.5768568137266774

Epoch: 5| Step: 11
Training loss: 1.3979600485576407
Validation loss: 2.55702272284174

Epoch: 118| Step: 0
Training loss: 1.3835139677544126
Validation loss: 2.5445476304626897

Epoch: 5| Step: 1
Training loss: 1.9515061650570975
Validation loss: 2.610150368592617

Epoch: 5| Step: 2
Training loss: 1.687555382844076
Validation loss: 2.5524890784722096

Epoch: 5| Step: 3
Training loss: 2.115221976316963
Validation loss: 2.5515751092602708

Epoch: 5| Step: 4
Training loss: 1.9793422286485913
Validation loss: 2.6060298675770945

Epoch: 5| Step: 5
Training loss: 1.353239881823346
Validation loss: 2.6447778809348277

Epoch: 5| Step: 6
Training loss: 1.6985854097620736
Validation loss: 2.6592915679897513

Epoch: 5| Step: 7
Training loss: 1.8182862755723292
Validation loss: 2.6064449999682706

Epoch: 5| Step: 8
Training loss: 1.6868687614673248
Validation loss: 2.5546252002955216

Epoch: 5| Step: 9
Training loss: 2.2467205732011735
Validation loss: 2.576203734321633

Epoch: 5| Step: 10
Training loss: 1.5170036416660724
Validation loss: 2.520446997323538

Epoch: 5| Step: 11
Training loss: 1.0115154165129283
Validation loss: 2.5618363389411667

Epoch: 119| Step: 0
Training loss: 1.804793383642169
Validation loss: 2.5644942447632233

Epoch: 5| Step: 1
Training loss: 1.5624574273985392
Validation loss: 2.454286952112265

Epoch: 5| Step: 2
Training loss: 1.708370285875076
Validation loss: 2.619557938409926

Epoch: 5| Step: 3
Training loss: 1.6232539112602664
Validation loss: 2.5247593184288872

Epoch: 5| Step: 4
Training loss: 1.6104599341945753
Validation loss: 2.59343470529952

Epoch: 5| Step: 5
Training loss: 2.0012884757961538
Validation loss: 2.5998568743045434

Epoch: 5| Step: 6
Training loss: 1.6888806381916377
Validation loss: 2.605996546935016

Epoch: 5| Step: 7
Training loss: 2.4894347099941156
Validation loss: 2.5503653342516572

Epoch: 5| Step: 8
Training loss: 1.7152760857879628
Validation loss: 2.4789165095467527

Epoch: 5| Step: 9
Training loss: 1.6565001676670477
Validation loss: 2.557692010209151

Epoch: 5| Step: 10
Training loss: 1.7008112318193807
Validation loss: 2.6111715722073168

Epoch: 5| Step: 11
Training loss: 1.3574936662529704
Validation loss: 2.625275502809409

Epoch: 120| Step: 0
Training loss: 1.3962535320568574
Validation loss: 2.587529390662661

Epoch: 5| Step: 1
Training loss: 1.545438079822768
Validation loss: 2.5399753162168355

Epoch: 5| Step: 2
Training loss: 2.6167560278663733
Validation loss: 2.5677169750653692

Epoch: 5| Step: 3
Training loss: 1.5758541878958183
Validation loss: 2.568193259626739

Epoch: 5| Step: 4
Training loss: 1.4097903297312373
Validation loss: 2.5241097341216356

Epoch: 5| Step: 5
Training loss: 1.9056443675036954
Validation loss: 2.511792563010869

Epoch: 5| Step: 6
Training loss: 1.8663584891875284
Validation loss: 2.5646192037355107

Epoch: 5| Step: 7
Training loss: 1.605077765532746
Validation loss: 2.583073417729418

Epoch: 5| Step: 8
Training loss: 1.7806877453488432
Validation loss: 2.541365661672234

Epoch: 5| Step: 9
Training loss: 1.9053651600887505
Validation loss: 2.5360215957966323

Epoch: 5| Step: 10
Training loss: 1.7571375928748976
Validation loss: 2.5401753026436995

Epoch: 5| Step: 11
Training loss: 1.9739558707216012
Validation loss: 2.6067261033058395

Epoch: 121| Step: 0
Training loss: 1.5116109489230125
Validation loss: 2.5906810260538524

Epoch: 5| Step: 1
Training loss: 1.2612126519351066
Validation loss: 2.568184115349235

Epoch: 5| Step: 2
Training loss: 1.7311917897708418
Validation loss: 2.630328658470776

Epoch: 5| Step: 3
Training loss: 2.0331144725809622
Validation loss: 2.616738279895455

Epoch: 5| Step: 4
Training loss: 2.1814707909359097
Validation loss: 2.5901816805950197

Epoch: 5| Step: 5
Training loss: 1.361644385228291
Validation loss: 2.525047308412532

Epoch: 5| Step: 6
Training loss: 1.5898415005454756
Validation loss: 2.6244627463333097

Epoch: 5| Step: 7
Training loss: 1.7203277282318021
Validation loss: 2.6028319269790297

Epoch: 5| Step: 8
Training loss: 1.8524454964922357
Validation loss: 2.5423946289200523

Epoch: 5| Step: 9
Training loss: 1.1158277866908457
Validation loss: 2.5491164744688857

Epoch: 5| Step: 10
Training loss: 2.212170045031798
Validation loss: 2.5652748451314826

Epoch: 5| Step: 11
Training loss: 1.408781020356915
Validation loss: 2.5257601761383714

Epoch: 122| Step: 0
Training loss: 1.524978171645736
Validation loss: 2.569804778192536

Epoch: 5| Step: 1
Training loss: 1.3526838645130068
Validation loss: 2.621199501962817

Epoch: 5| Step: 2
Training loss: 1.6704476226021507
Validation loss: 2.635675441466414

Epoch: 5| Step: 3
Training loss: 1.8790422735326249
Validation loss: 2.658799656911068

Epoch: 5| Step: 4
Training loss: 1.6644106934946263
Validation loss: 2.6329397365112546

Epoch: 5| Step: 5
Training loss: 1.5547782833104875
Validation loss: 2.6283649418207653

Epoch: 5| Step: 6
Training loss: 1.96659872805173
Validation loss: 2.6587062250290074

Epoch: 5| Step: 7
Training loss: 1.561568554768591
Validation loss: 2.5452097429625122

Epoch: 5| Step: 8
Training loss: 1.3587390245066284
Validation loss: 2.5584311513704336

Epoch: 5| Step: 9
Training loss: 1.6079077096521395
Validation loss: 2.560197295673856

Epoch: 5| Step: 10
Training loss: 2.5718649955545656
Validation loss: 2.5691179941619136

Epoch: 5| Step: 11
Training loss: 1.7257620910990201
Validation loss: 2.5552921921075975

Epoch: 123| Step: 0
Training loss: 2.5525094643173585
Validation loss: 2.5309679714117106

Epoch: 5| Step: 1
Training loss: 1.2481688438359524
Validation loss: 2.6278205545560325

Epoch: 5| Step: 2
Training loss: 1.9448035620019288
Validation loss: 2.675127447960399

Epoch: 5| Step: 3
Training loss: 1.3322854792272525
Validation loss: 2.6361449721716035

Epoch: 5| Step: 4
Training loss: 1.5950019257632502
Validation loss: 2.6248576640337404

Epoch: 5| Step: 5
Training loss: 1.6021091923737065
Validation loss: 2.5465754701436456

Epoch: 5| Step: 6
Training loss: 1.4321143393128493
Validation loss: 2.58173213578564

Epoch: 5| Step: 7
Training loss: 1.9381694252509978
Validation loss: 2.5620339132561383

Epoch: 5| Step: 8
Training loss: 1.5636240158742762
Validation loss: 2.5799251975999873

Epoch: 5| Step: 9
Training loss: 1.7879927989592825
Validation loss: 2.5362459651287605

Epoch: 5| Step: 10
Training loss: 1.8829649550893734
Validation loss: 2.482174144422228

Epoch: 5| Step: 11
Training loss: 2.2812224085981256
Validation loss: 2.5649510965648976

Epoch: 124| Step: 0
Training loss: 1.1406642959305522
Validation loss: 2.6395353781587443

Epoch: 5| Step: 1
Training loss: 1.8208113220187987
Validation loss: 2.6978201106306687

Epoch: 5| Step: 2
Training loss: 1.9093819201354945
Validation loss: 2.8119714134256855

Epoch: 5| Step: 3
Training loss: 2.2171746692460954
Validation loss: 2.8251880760377097

Epoch: 5| Step: 4
Training loss: 2.125913199381605
Validation loss: 2.804655976326404

Epoch: 5| Step: 5
Training loss: 1.765060199434964
Validation loss: 2.6857588065938462

Epoch: 5| Step: 6
Training loss: 1.407046410427569
Validation loss: 2.6136821977142315

Epoch: 5| Step: 7
Training loss: 1.6575046321752387
Validation loss: 2.6209028338408635

Epoch: 5| Step: 8
Training loss: 1.6683447099209492
Validation loss: 2.600023761588725

Epoch: 5| Step: 9
Training loss: 1.9691219886665223
Validation loss: 2.6119076169762945

Epoch: 5| Step: 10
Training loss: 1.8672101007474364
Validation loss: 2.6119522684118874

Epoch: 5| Step: 11
Training loss: 1.5617492398009352
Validation loss: 2.5972648268337117

Epoch: 125| Step: 0
Training loss: 1.9267864582853775
Validation loss: 2.6253557493957103

Epoch: 5| Step: 1
Training loss: 1.8736740510192509
Validation loss: 2.6068985812769085

Epoch: 5| Step: 2
Training loss: 1.5742929597311557
Validation loss: 2.5728827498719156

Epoch: 5| Step: 3
Training loss: 1.52026090779443
Validation loss: 2.650320023580466

Epoch: 5| Step: 4
Training loss: 1.611588076805912
Validation loss: 2.6614295612031635

Epoch: 5| Step: 5
Training loss: 1.5182150506944099
Validation loss: 2.7158004502136297

Epoch: 5| Step: 6
Training loss: 1.6421551789243582
Validation loss: 2.778279926026627

Epoch: 5| Step: 7
Training loss: 1.699865950179876
Validation loss: 2.6816008384959336

Epoch: 5| Step: 8
Training loss: 1.7433034290839082
Validation loss: 2.6580975558516586

Epoch: 5| Step: 9
Training loss: 2.174876053884902
Validation loss: 2.5969819305108577

Epoch: 5| Step: 10
Training loss: 2.050936796556451
Validation loss: 2.5774136708297357

Epoch: 5| Step: 11
Training loss: 1.9926269644917864
Validation loss: 2.507751402699907

Epoch: 126| Step: 0
Training loss: 1.5070221563987403
Validation loss: 2.5628507032997994

Epoch: 5| Step: 1
Training loss: 1.6264221130823007
Validation loss: 2.55058537851344

Epoch: 5| Step: 2
Training loss: 1.460800409259718
Validation loss: 2.540321085114437

Epoch: 5| Step: 3
Training loss: 1.121413022611252
Validation loss: 2.5863549393999645

Epoch: 5| Step: 4
Training loss: 1.695165531098933
Validation loss: 2.6375454922831123

Epoch: 5| Step: 5
Training loss: 1.5652038068573473
Validation loss: 2.6114903782168146

Epoch: 5| Step: 6
Training loss: 1.8670426316504583
Validation loss: 2.6875211101264744

Epoch: 5| Step: 7
Training loss: 1.6400952164991365
Validation loss: 2.7144548681918437

Epoch: 5| Step: 8
Training loss: 2.453914636733022
Validation loss: 2.605615282870973

Epoch: 5| Step: 9
Training loss: 2.0332042976251423
Validation loss: 2.6736310092521354

Epoch: 5| Step: 10
Training loss: 1.9108352546443783
Validation loss: 2.6006785925492557

Epoch: 5| Step: 11
Training loss: 0.9096528654539101
Validation loss: 2.5456251498405797

Epoch: 127| Step: 0
Training loss: 2.261991336188686
Validation loss: 2.507404072303089

Epoch: 5| Step: 1
Training loss: 1.674274612043073
Validation loss: 2.5533259707619447

Epoch: 5| Step: 2
Training loss: 1.3146981950365215
Validation loss: 2.5352672636846605

Epoch: 5| Step: 3
Training loss: 1.972903154992224
Validation loss: 2.6314664393768683

Epoch: 5| Step: 4
Training loss: 1.578833694716226
Validation loss: 2.5955518836820755

Epoch: 5| Step: 5
Training loss: 1.7561607908351107
Validation loss: 2.5737311249174093

Epoch: 5| Step: 6
Training loss: 1.2763031620233047
Validation loss: 2.5990924966211044

Epoch: 5| Step: 7
Training loss: 1.4538715044776076
Validation loss: 2.6221901599244837

Epoch: 5| Step: 8
Training loss: 1.868831724593416
Validation loss: 2.703712590617647

Epoch: 5| Step: 9
Training loss: 1.282110065127387
Validation loss: 2.6996825648249185

Epoch: 5| Step: 10
Training loss: 1.923533026820006
Validation loss: 2.670170338735795

Epoch: 5| Step: 11
Training loss: 1.2254993180141163
Validation loss: 2.580325312857324

Epoch: 128| Step: 0
Training loss: 1.373920450370371
Validation loss: 2.574006565362016

Epoch: 5| Step: 1
Training loss: 2.4207861636934376
Validation loss: 2.585980202743895

Epoch: 5| Step: 2
Training loss: 1.55837812342338
Validation loss: 2.5955860828182975

Epoch: 5| Step: 3
Training loss: 1.491271771562221
Validation loss: 2.505716358919356

Epoch: 5| Step: 4
Training loss: 1.718627647900052
Validation loss: 2.542612252978505

Epoch: 5| Step: 5
Training loss: 1.6427765317059346
Validation loss: 2.5758774892615075

Epoch: 5| Step: 6
Training loss: 1.62705694739731
Validation loss: 2.6256816902266773

Epoch: 5| Step: 7
Training loss: 2.170260700791362
Validation loss: 2.612786330270078

Epoch: 5| Step: 8
Training loss: 1.3915151254679656
Validation loss: 2.6826071149398327

Epoch: 5| Step: 9
Training loss: 1.2445791001828443
Validation loss: 2.6023268507560777

Epoch: 5| Step: 10
Training loss: 1.8248862244139124
Validation loss: 2.5974817661970833

Epoch: 5| Step: 11
Training loss: 2.1248958786531604
Validation loss: 2.629252078023686

Epoch: 129| Step: 0
Training loss: 1.7019916228010885
Validation loss: 2.5416105269397073

Epoch: 5| Step: 1
Training loss: 1.8876934179779035
Validation loss: 2.5827711529354014

Epoch: 5| Step: 2
Training loss: 1.493666310539677
Validation loss: 2.555110643595242

Epoch: 5| Step: 3
Training loss: 1.7014040870593201
Validation loss: 2.544224407093937

Epoch: 5| Step: 4
Training loss: 1.528033244804904
Validation loss: 2.645451181452655

Epoch: 5| Step: 5
Training loss: 1.8026945000203007
Validation loss: 2.628777525850343

Epoch: 5| Step: 6
Training loss: 1.6875156825714421
Validation loss: 2.6070567357569745

Epoch: 5| Step: 7
Training loss: 1.4954116900001522
Validation loss: 2.5418038344240332

Epoch: 5| Step: 8
Training loss: 2.2675079939426883
Validation loss: 2.6392990748578997

Epoch: 5| Step: 9
Training loss: 1.3152309344036803
Validation loss: 2.6264469457922974

Epoch: 5| Step: 10
Training loss: 0.9474034474580518
Validation loss: 2.669389479566689

Epoch: 5| Step: 11
Training loss: 1.3100331147936983
Validation loss: 2.6254015948378533

Epoch: 130| Step: 0
Training loss: 1.6449735141929307
Validation loss: 2.6915046219918044

Epoch: 5| Step: 1
Training loss: 1.228405873258581
Validation loss: 2.6796278432539236

Epoch: 5| Step: 2
Training loss: 1.666478011262337
Validation loss: 2.6631623776950777

Epoch: 5| Step: 3
Training loss: 1.5944892814230511
Validation loss: 2.660209453571673

Epoch: 5| Step: 4
Training loss: 1.7467241962558497
Validation loss: 2.6622583054220654

Epoch: 5| Step: 5
Training loss: 1.3307174512891178
Validation loss: 2.599234932582613

Epoch: 5| Step: 6
Training loss: 1.3542889564267258
Validation loss: 2.568487104713605

Epoch: 5| Step: 7
Training loss: 1.4319218753516534
Validation loss: 2.590554831627864

Epoch: 5| Step: 8
Training loss: 2.233163358378665
Validation loss: 2.58243323739885

Epoch: 5| Step: 9
Training loss: 1.8110591817924764
Validation loss: 2.531148453233636

Epoch: 5| Step: 10
Training loss: 1.7409908821003046
Validation loss: 2.564016571811389

Epoch: 5| Step: 11
Training loss: 1.040951381511771
Validation loss: 2.632361847958752

Epoch: 131| Step: 0
Training loss: 1.292754740449428
Validation loss: 2.569776983622485

Epoch: 5| Step: 1
Training loss: 1.9386836097511249
Validation loss: 2.538099918324526

Epoch: 5| Step: 2
Training loss: 2.208405679441396
Validation loss: 2.5891646026449218

Epoch: 5| Step: 3
Training loss: 1.2048206517990152
Validation loss: 2.619766149276523

Epoch: 5| Step: 4
Training loss: 1.7133395260329094
Validation loss: 2.585484029879552

Epoch: 5| Step: 5
Training loss: 1.7135680717435837
Validation loss: 2.6206258592119727

Epoch: 5| Step: 6
Training loss: 1.3733277989865487
Validation loss: 2.587949164346259

Epoch: 5| Step: 7
Training loss: 1.601997130430702
Validation loss: 2.612163489022561

Epoch: 5| Step: 8
Training loss: 1.3180968524790804
Validation loss: 2.6731265336261876

Epoch: 5| Step: 9
Training loss: 1.293351131264312
Validation loss: 2.57077461656839

Epoch: 5| Step: 10
Training loss: 1.94272585563496
Validation loss: 2.7723379149267418

Epoch: 5| Step: 11
Training loss: 1.6966682322157036
Validation loss: 2.6621560988007387

Epoch: 132| Step: 0
Training loss: 1.5253329492037184
Validation loss: 2.6386090206902275

Epoch: 5| Step: 1
Training loss: 1.7822969271212306
Validation loss: 2.5942980673666973

Epoch: 5| Step: 2
Training loss: 1.4100366684359393
Validation loss: 2.621644820126133

Epoch: 5| Step: 3
Training loss: 1.4890805798740894
Validation loss: 2.635158994891715

Epoch: 5| Step: 4
Training loss: 1.555183293251088
Validation loss: 2.609131489506134

Epoch: 5| Step: 5
Training loss: 1.3801935255108027
Validation loss: 2.5956652207736934

Epoch: 5| Step: 6
Training loss: 1.9227386022955821
Validation loss: 2.6719362277921954

Epoch: 5| Step: 7
Training loss: 1.7891522514119083
Validation loss: 2.6243615017269963

Epoch: 5| Step: 8
Training loss: 1.5782278801648817
Validation loss: 2.6867356729006837

Epoch: 5| Step: 9
Training loss: 1.6074272888018264
Validation loss: 2.6740253859641423

Epoch: 5| Step: 10
Training loss: 1.7370129019126868
Validation loss: 2.6461563770446683

Epoch: 5| Step: 11
Training loss: 1.263139049332982
Validation loss: 2.7048966072592546

Epoch: 133| Step: 0
Training loss: 1.4062163454903007
Validation loss: 2.6476699744700194

Epoch: 5| Step: 1
Training loss: 1.028284722533751
Validation loss: 2.669549722135925

Epoch: 5| Step: 2
Training loss: 1.5673875279816138
Validation loss: 2.6126216784041008

Epoch: 5| Step: 3
Training loss: 1.5823966652155221
Validation loss: 2.5553122912311936

Epoch: 5| Step: 4
Training loss: 2.1168557220292987
Validation loss: 2.6042914907421624

Epoch: 5| Step: 5
Training loss: 1.635634470567117
Validation loss: 2.611276714053782

Epoch: 5| Step: 6
Training loss: 1.6328814916317416
Validation loss: 2.588880080597846

Epoch: 5| Step: 7
Training loss: 1.5133229499550305
Validation loss: 2.5583842961043093

Epoch: 5| Step: 8
Training loss: 1.724023669830476
Validation loss: 2.5484503922876027

Epoch: 5| Step: 9
Training loss: 1.6744855660118005
Validation loss: 2.6068696007451257

Epoch: 5| Step: 10
Training loss: 1.6169781388106648
Validation loss: 2.552920797050086

Epoch: 5| Step: 11
Training loss: 1.622346986511876
Validation loss: 2.652383716939449

Epoch: 134| Step: 0
Training loss: 1.5196276636598447
Validation loss: 2.5828449546465704

Epoch: 5| Step: 1
Training loss: 1.239580357438477
Validation loss: 2.7011932019145477

Epoch: 5| Step: 2
Training loss: 2.699134483070941
Validation loss: 2.7259712653033352

Epoch: 5| Step: 3
Training loss: 1.5602396828582774
Validation loss: 2.6875400909863796

Epoch: 5| Step: 4
Training loss: 1.413596524340961
Validation loss: 2.641397491112604

Epoch: 5| Step: 5
Training loss: 1.488689616890103
Validation loss: 2.701939203295309

Epoch: 5| Step: 6
Training loss: 1.4459209089479483
Validation loss: 2.60505897239226

Epoch: 5| Step: 7
Training loss: 1.304402485856276
Validation loss: 2.5700706341081343

Epoch: 5| Step: 8
Training loss: 1.7438465652253055
Validation loss: 2.620490643870404

Epoch: 5| Step: 9
Training loss: 1.7075436170153926
Validation loss: 2.592407009096426

Epoch: 5| Step: 10
Training loss: 1.2859876082937183
Validation loss: 2.6510072842050247

Epoch: 5| Step: 11
Training loss: 0.5579146411888424
Validation loss: 2.638246232270018

Epoch: 135| Step: 0
Training loss: 1.6797742244599159
Validation loss: 2.613647515099751

Epoch: 5| Step: 1
Training loss: 1.4333823565298223
Validation loss: 2.577782929971861

Epoch: 5| Step: 2
Training loss: 1.8667970512471472
Validation loss: 2.650541698073599

Epoch: 5| Step: 3
Training loss: 1.1859539910377372
Validation loss: 2.552742950028112

Epoch: 5| Step: 4
Training loss: 1.330046307467501
Validation loss: 2.5658772318637313

Epoch: 5| Step: 5
Training loss: 1.3835756599023394
Validation loss: 2.6464271980293357

Epoch: 5| Step: 6
Training loss: 1.8453293840764808
Validation loss: 2.6559181080831493

Epoch: 5| Step: 7
Training loss: 1.7585764263423376
Validation loss: 2.6915237297768555

Epoch: 5| Step: 8
Training loss: 1.1375113015085039
Validation loss: 2.546439673853631

Epoch: 5| Step: 9
Training loss: 1.5176320109380204
Validation loss: 2.5586999322732127

Epoch: 5| Step: 10
Training loss: 1.7488479909648262
Validation loss: 2.6518313962222737

Epoch: 5| Step: 11
Training loss: 1.2361211377474193
Validation loss: 2.6146633179020027

Epoch: 136| Step: 0
Training loss: 1.0250121371783434
Validation loss: 2.6061942231013435

Epoch: 5| Step: 1
Training loss: 1.8304739313381975
Validation loss: 2.70625555347698

Epoch: 5| Step: 2
Training loss: 1.7604517133786826
Validation loss: 2.577023484705154

Epoch: 5| Step: 3
Training loss: 1.337234447535007
Validation loss: 2.532482271122988

Epoch: 5| Step: 4
Training loss: 1.9198831300134278
Validation loss: 2.5788088922190697

Epoch: 5| Step: 5
Training loss: 1.3990891712365405
Validation loss: 2.6704008225829887

Epoch: 5| Step: 6
Training loss: 1.955566711044764
Validation loss: 2.580227997917566

Epoch: 5| Step: 7
Training loss: 1.0674986780770401
Validation loss: 2.6413994129464378

Epoch: 5| Step: 8
Training loss: 1.3288247901488457
Validation loss: 2.641020611654523

Epoch: 5| Step: 9
Training loss: 1.4107413306584213
Validation loss: 2.698676813525259

Epoch: 5| Step: 10
Training loss: 1.5891632948334398
Validation loss: 2.6614340160824157

Epoch: 5| Step: 11
Training loss: 1.4239246560695267
Validation loss: 2.607501078532585

Epoch: 137| Step: 0
Training loss: 1.6198974607535235
Validation loss: 2.744356103946572

Epoch: 5| Step: 1
Training loss: 1.9579229398298001
Validation loss: 2.71911054537119

Epoch: 5| Step: 2
Training loss: 1.5218856341168672
Validation loss: 2.7336512743172294

Epoch: 5| Step: 3
Training loss: 1.61287279477176
Validation loss: 2.679855712118974

Epoch: 5| Step: 4
Training loss: 2.269261250546085
Validation loss: 2.666055170867464

Epoch: 5| Step: 5
Training loss: 1.6005811708669109
Validation loss: 2.6480186228678324

Epoch: 5| Step: 6
Training loss: 1.5751082035014061
Validation loss: 2.589711507620978

Epoch: 5| Step: 7
Training loss: 1.013410295608888
Validation loss: 2.594502341838703

Epoch: 5| Step: 8
Training loss: 1.892072265543346
Validation loss: 2.6495225009832626

Epoch: 5| Step: 9
Training loss: 0.9698281902369814
Validation loss: 2.7114756487013705

Epoch: 5| Step: 10
Training loss: 1.348135688749976
Validation loss: 2.595456496501763

Epoch: 5| Step: 11
Training loss: 0.5440468821729761
Validation loss: 2.6457581784745745

Epoch: 138| Step: 0
Training loss: 1.4612581441764898
Validation loss: 2.574679063885886

Epoch: 5| Step: 1
Training loss: 1.107063894927932
Validation loss: 2.6017690830479627

Epoch: 5| Step: 2
Training loss: 2.2595831979560095
Validation loss: 2.5866272381988367

Epoch: 5| Step: 3
Training loss: 1.2037975363688904
Validation loss: 2.6153056026043706

Epoch: 5| Step: 4
Training loss: 1.069792349622311
Validation loss: 2.627989758017946

Epoch: 5| Step: 5
Training loss: 1.6807922988192263
Validation loss: 2.7480826955058975

Epoch: 5| Step: 6
Training loss: 1.2189913290683954
Validation loss: 2.723228792096823

Epoch: 5| Step: 7
Training loss: 1.4615178714877142
Validation loss: 2.737212890072885

Epoch: 5| Step: 8
Training loss: 1.6196127135439413
Validation loss: 2.67238777846884

Epoch: 5| Step: 9
Training loss: 1.3996210045082493
Validation loss: 2.676057601728817

Epoch: 5| Step: 10
Training loss: 1.8288805451800858
Validation loss: 2.593310338027062

Epoch: 5| Step: 11
Training loss: 1.917532752800521
Validation loss: 2.611425911045662

Epoch: 139| Step: 0
Training loss: 2.3822434042804166
Validation loss: 2.5256398671244495

Epoch: 5| Step: 1
Training loss: 1.476865787743739
Validation loss: 2.686491784524393

Epoch: 5| Step: 2
Training loss: 1.565987928283076
Validation loss: 2.636012685924919

Epoch: 5| Step: 3
Training loss: 1.2518693297815298
Validation loss: 2.6464224344772815

Epoch: 5| Step: 4
Training loss: 1.3554980360049966
Validation loss: 2.6103296646472667

Epoch: 5| Step: 5
Training loss: 1.640510627756338
Validation loss: 2.63335708887113

Epoch: 5| Step: 6
Training loss: 1.3959341819353126
Validation loss: 2.629967455015927

Epoch: 5| Step: 7
Training loss: 1.2704622581577862
Validation loss: 2.69206668924385

Epoch: 5| Step: 8
Training loss: 1.5640755148850127
Validation loss: 2.798516777274539

Epoch: 5| Step: 9
Training loss: 2.000813437980847
Validation loss: 2.826909055002185

Epoch: 5| Step: 10
Training loss: 1.245717915745917
Validation loss: 2.754752492183051

Epoch: 5| Step: 11
Training loss: 1.2700999702695688
Validation loss: 2.718378695714275

Epoch: 140| Step: 0
Training loss: 1.8067769427034468
Validation loss: 2.7359444537347644

Epoch: 5| Step: 1
Training loss: 1.159294759024905
Validation loss: 2.5619249086217546

Epoch: 5| Step: 2
Training loss: 1.4055776896302472
Validation loss: 2.61545151788831

Epoch: 5| Step: 3
Training loss: 2.2047812005995264
Validation loss: 2.6353912477938577

Epoch: 5| Step: 4
Training loss: 1.3596184172776515
Validation loss: 2.5388353529831327

Epoch: 5| Step: 5
Training loss: 1.486657886792816
Validation loss: 2.6520781704766745

Epoch: 5| Step: 6
Training loss: 1.1575176404099021
Validation loss: 2.5796321316897575

Epoch: 5| Step: 7
Training loss: 0.9766175216433401
Validation loss: 2.6845282121957936

Epoch: 5| Step: 8
Training loss: 1.4874826927139884
Validation loss: 2.615971323479032

Epoch: 5| Step: 9
Training loss: 1.3589502306730776
Validation loss: 2.554577526638027

Epoch: 5| Step: 10
Training loss: 1.8351486134441275
Validation loss: 2.5716879854309584

Epoch: 5| Step: 11
Training loss: 2.5815981503139853
Validation loss: 2.595156477866656

Epoch: 141| Step: 0
Training loss: 1.6068692746499975
Validation loss: 2.683798318068756

Epoch: 5| Step: 1
Training loss: 0.7804272706519305
Validation loss: 2.676634548039287

Epoch: 5| Step: 2
Training loss: 1.4142057230375444
Validation loss: 2.6256722089105144

Epoch: 5| Step: 3
Training loss: 1.2986473932937934
Validation loss: 2.747986782693935

Epoch: 5| Step: 4
Training loss: 1.4274008553141997
Validation loss: 2.6763027824531354

Epoch: 5| Step: 5
Training loss: 1.5019006608349565
Validation loss: 2.712261008795936

Epoch: 5| Step: 6
Training loss: 1.7356735042488378
Validation loss: 2.6216526525255848

Epoch: 5| Step: 7
Training loss: 1.3111409917127663
Validation loss: 2.658573125818462

Epoch: 5| Step: 8
Training loss: 2.3402823672326654
Validation loss: 2.611178051200961

Epoch: 5| Step: 9
Training loss: 1.6366399413734758
Validation loss: 2.6720678137201594

Epoch: 5| Step: 10
Training loss: 0.6668308448295367
Validation loss: 2.6093069436950107

Epoch: 5| Step: 11
Training loss: 1.08706814752521
Validation loss: 2.6516168129100928

Epoch: 142| Step: 0
Training loss: 1.4427431104671036
Validation loss: 2.6867282225011175

Epoch: 5| Step: 1
Training loss: 2.444009842192566
Validation loss: 2.688996404810458

Epoch: 5| Step: 2
Training loss: 1.222227076077697
Validation loss: 2.720702124543199

Epoch: 5| Step: 3
Training loss: 1.298643354309136
Validation loss: 2.838467295427742

Epoch: 5| Step: 4
Training loss: 1.8235397218687823
Validation loss: 2.8213745047911494

Epoch: 5| Step: 5
Training loss: 1.4928125001277688
Validation loss: 2.845999195037106

Epoch: 5| Step: 6
Training loss: 1.533621838973613
Validation loss: 2.7489207996746674

Epoch: 5| Step: 7
Training loss: 1.6639061796167025
Validation loss: 2.6898870771369685

Epoch: 5| Step: 8
Training loss: 1.310481835924561
Validation loss: 2.6845780390201197

Epoch: 5| Step: 9
Training loss: 1.3388866865545357
Validation loss: 2.633806318396991

Epoch: 5| Step: 10
Training loss: 1.3612708102930855
Validation loss: 2.6550517614590805

Epoch: 5| Step: 11
Training loss: 0.593231426454638
Validation loss: 2.7067578734121334

Epoch: 143| Step: 0
Training loss: 1.2039450290778986
Validation loss: 2.6799263138747222

Epoch: 5| Step: 1
Training loss: 1.6265627609091484
Validation loss: 2.68016570692763

Epoch: 5| Step: 2
Training loss: 1.2331233861867221
Validation loss: 2.6337973868342583

Epoch: 5| Step: 3
Training loss: 2.258299778293696
Validation loss: 2.718637317938555

Epoch: 5| Step: 4
Training loss: 1.1242973464520565
Validation loss: 2.668628266690153

Epoch: 5| Step: 5
Training loss: 1.3164097817031168
Validation loss: 2.6976207045500042

Epoch: 5| Step: 6
Training loss: 1.522628569412526
Validation loss: 2.7671674209633066

Epoch: 5| Step: 7
Training loss: 1.1454918381405619
Validation loss: 2.798110092494875

Epoch: 5| Step: 8
Training loss: 1.3146610634015694
Validation loss: 2.6607511194153832

Epoch: 5| Step: 9
Training loss: 1.6263692662269424
Validation loss: 2.6518254998057245

Epoch: 5| Step: 10
Training loss: 1.4966903572643053
Validation loss: 2.7331239072499596

Epoch: 5| Step: 11
Training loss: 1.7364901455270902
Validation loss: 2.59036961467394

Epoch: 144| Step: 0
Training loss: 1.0961683513026559
Validation loss: 2.647662616750972

Epoch: 5| Step: 1
Training loss: 1.1691520081133853
Validation loss: 2.580055046122709

Epoch: 5| Step: 2
Training loss: 1.5601716813960884
Validation loss: 2.6111668318412433

Epoch: 5| Step: 3
Training loss: 1.042398075180004
Validation loss: 2.661966735645622

Epoch: 5| Step: 4
Training loss: 1.3639915386675838
Validation loss: 2.6345559789200887

Epoch: 5| Step: 5
Training loss: 2.326745565473938
Validation loss: 2.615604498846303

Epoch: 5| Step: 6
Training loss: 1.1309497645594035
Validation loss: 2.70034709777435

Epoch: 5| Step: 7
Training loss: 1.6615194311437826
Validation loss: 2.74779782118966

Epoch: 5| Step: 8
Training loss: 1.2993183788240146
Validation loss: 2.6320045053903423

Epoch: 5| Step: 9
Training loss: 1.7345910152595385
Validation loss: 2.636943142608638

Epoch: 5| Step: 10
Training loss: 1.4141155254053697
Validation loss: 2.6714634550491194

Epoch: 5| Step: 11
Training loss: 1.205920501533825
Validation loss: 2.6050942631767557

Epoch: 145| Step: 0
Training loss: 1.5075197874576691
Validation loss: 2.671472734802533

Epoch: 5| Step: 1
Training loss: 1.278722503083078
Validation loss: 2.7028805469678954

Epoch: 5| Step: 2
Training loss: 1.4549370409266178
Validation loss: 2.682789944535597

Epoch: 5| Step: 3
Training loss: 1.5628660154800633
Validation loss: 2.612029280836267

Epoch: 5| Step: 4
Training loss: 1.338644709003952
Validation loss: 2.6638574530632035

Epoch: 5| Step: 5
Training loss: 1.8922302115271645
Validation loss: 2.7496910282885083

Epoch: 5| Step: 6
Training loss: 1.3756356070706195
Validation loss: 2.705078451842875

Epoch: 5| Step: 7
Training loss: 1.0687051663280738
Validation loss: 2.6728917840011053

Epoch: 5| Step: 8
Training loss: 1.8488181334160476
Validation loss: 2.6261026019529763

Epoch: 5| Step: 9
Training loss: 1.4466759925899133
Validation loss: 2.7531645982357627

Epoch: 5| Step: 10
Training loss: 1.5126403049936425
Validation loss: 2.6945179085914144

Epoch: 5| Step: 11
Training loss: 1.9702564107487837
Validation loss: 2.6800397561692484

Epoch: 146| Step: 0
Training loss: 1.6616375227616764
Validation loss: 2.6548378986926315

Epoch: 5| Step: 1
Training loss: 0.9948239778926742
Validation loss: 2.6635093599482853

Epoch: 5| Step: 2
Training loss: 1.473072347367645
Validation loss: 2.712522387888292

Epoch: 5| Step: 3
Training loss: 1.4114920927657968
Validation loss: 2.7356956471620233

Epoch: 5| Step: 4
Training loss: 1.3446360040228411
Validation loss: 2.7015022338769934

Epoch: 5| Step: 5
Training loss: 1.132631642604101
Validation loss: 2.69976832328937

Epoch: 5| Step: 6
Training loss: 1.294998742033005
Validation loss: 2.7421285653732297

Epoch: 5| Step: 7
Training loss: 2.036055294912304
Validation loss: 2.7437972137861157

Epoch: 5| Step: 8
Training loss: 1.7349541874094738
Validation loss: 2.7111259929929483

Epoch: 5| Step: 9
Training loss: 1.4852688156243428
Validation loss: 2.6840387500134555

Epoch: 5| Step: 10
Training loss: 1.2888110291232275
Validation loss: 2.74106839158967

Epoch: 5| Step: 11
Training loss: 0.7784790872669485
Validation loss: 2.685281538368824

Epoch: 147| Step: 0
Training loss: 1.4754757388740283
Validation loss: 2.6443303255866475

Epoch: 5| Step: 1
Training loss: 1.5703396771105187
Validation loss: 2.6783670632798797

Epoch: 5| Step: 2
Training loss: 1.375753846293637
Validation loss: 2.6339384552167497

Epoch: 5| Step: 3
Training loss: 1.0900095604993474
Validation loss: 2.6711026687227712

Epoch: 5| Step: 4
Training loss: 1.1096949586050955
Validation loss: 2.625663124824086

Epoch: 5| Step: 5
Training loss: 1.101902307354839
Validation loss: 2.715686895867164

Epoch: 5| Step: 6
Training loss: 1.4934994188121766
Validation loss: 2.615161312603062

Epoch: 5| Step: 7
Training loss: 1.5163718674155449
Validation loss: 2.7551690779679596

Epoch: 5| Step: 8
Training loss: 1.5635942061015609
Validation loss: 2.778182656398227

Epoch: 5| Step: 9
Training loss: 1.2593626812126504
Validation loss: 2.663084049967913

Epoch: 5| Step: 10
Training loss: 1.2183241466970811
Validation loss: 2.7040832967107975

Epoch: 5| Step: 11
Training loss: 3.8096875933225576
Validation loss: 2.6716973095082697

Epoch: 148| Step: 0
Training loss: 1.3979248300570786
Validation loss: 2.6857793090110236

Epoch: 5| Step: 1
Training loss: 1.3681890252590891
Validation loss: 2.5579714593447145

Epoch: 5| Step: 2
Training loss: 0.9197999909925367
Validation loss: 2.680280354779131

Epoch: 5| Step: 3
Training loss: 0.8191332742618629
Validation loss: 2.6499655749826045

Epoch: 5| Step: 4
Training loss: 1.1201841272840662
Validation loss: 2.603722882922427

Epoch: 5| Step: 5
Training loss: 1.3701204067418078
Validation loss: 2.639977339974843

Epoch: 5| Step: 6
Training loss: 1.1217897494342377
Validation loss: 2.601260821671151

Epoch: 5| Step: 7
Training loss: 1.3295952680899497
Validation loss: 2.728027351032997

Epoch: 5| Step: 8
Training loss: 1.7264235082408137
Validation loss: 2.6606531785364846

Epoch: 5| Step: 9
Training loss: 1.510351227844509
Validation loss: 2.7073641889271074

Epoch: 5| Step: 10
Training loss: 2.2385999309566027
Validation loss: 2.741353414393632

Epoch: 5| Step: 11
Training loss: 1.19101235804324
Validation loss: 2.7021745653616023

Epoch: 149| Step: 0
Training loss: 1.5081099775113913
Validation loss: 2.6289606490229414

Epoch: 5| Step: 1
Training loss: 1.1420568075698396
Validation loss: 2.74767040790999

Epoch: 5| Step: 2
Training loss: 0.8528212596964826
Validation loss: 2.600815216053501

Epoch: 5| Step: 3
Training loss: 2.0360133732954195
Validation loss: 2.6785473302483767

Epoch: 5| Step: 4
Training loss: 1.3430103661711583
Validation loss: 2.6694917330013994

Epoch: 5| Step: 5
Training loss: 1.4376752995291464
Validation loss: 2.606747978077228

Epoch: 5| Step: 6
Training loss: 1.2826997881682107
Validation loss: 2.661147009202145

Epoch: 5| Step: 7
Training loss: 1.4497232304532377
Validation loss: 2.632547801037517

Epoch: 5| Step: 8
Training loss: 1.4329734520486146
Validation loss: 2.725478061394113

Epoch: 5| Step: 9
Training loss: 1.2969883788771286
Validation loss: 2.7453042166448696

Epoch: 5| Step: 10
Training loss: 1.4880338848726855
Validation loss: 2.774399621843789

Epoch: 5| Step: 11
Training loss: 0.8850034684582001
Validation loss: 2.654247677393648

Epoch: 150| Step: 0
Training loss: 1.7068746743748402
Validation loss: 2.685542561845495

Epoch: 5| Step: 1
Training loss: 0.7945842353910364
Validation loss: 2.6388890468586212

Epoch: 5| Step: 2
Training loss: 1.1727834613477006
Validation loss: 2.6188455634028096

Epoch: 5| Step: 3
Training loss: 1.1036972571588188
Validation loss: 2.6773397468838995

Epoch: 5| Step: 4
Training loss: 1.4276320059380365
Validation loss: 2.6368284000155837

Epoch: 5| Step: 5
Training loss: 1.4261765859500477
Validation loss: 2.652065286827168

Epoch: 5| Step: 6
Training loss: 1.010526801854778
Validation loss: 2.7338644949878477

Epoch: 5| Step: 7
Training loss: 1.9383207244113068
Validation loss: 2.736332830061533

Epoch: 5| Step: 8
Training loss: 1.69568879482398
Validation loss: 2.780431226873916

Epoch: 5| Step: 9
Training loss: 1.289081827654584
Validation loss: 2.7713530574099283

Epoch: 5| Step: 10
Training loss: 1.6768367262207098
Validation loss: 2.686468532661719

Epoch: 5| Step: 11
Training loss: 0.8517779856328624
Validation loss: 2.6854757329592136

Epoch: 151| Step: 0
Training loss: 1.1658090379667958
Validation loss: 2.7197812159929318

Epoch: 5| Step: 1
Training loss: 1.4376953655668379
Validation loss: 2.6982430931970636

Epoch: 5| Step: 2
Training loss: 1.2914640770234866
Validation loss: 2.648064723078716

Epoch: 5| Step: 3
Training loss: 1.3974992385616514
Validation loss: 2.6569133865130725

Epoch: 5| Step: 4
Training loss: 1.4875141880416618
Validation loss: 2.728803149369897

Epoch: 5| Step: 5
Training loss: 1.4053197963084934
Validation loss: 2.780983972863784

Epoch: 5| Step: 6
Training loss: 1.5252483853536531
Validation loss: 2.786925083653419

Epoch: 5| Step: 7
Training loss: 1.365959531544854
Validation loss: 2.7332974953938165

Epoch: 5| Step: 8
Training loss: 1.2002129922034892
Validation loss: 2.6475209738597316

Epoch: 5| Step: 9
Training loss: 1.0435151229917736
Validation loss: 2.7382813733473172

Epoch: 5| Step: 10
Training loss: 1.8669928924147376
Validation loss: 2.78159414798161

Epoch: 5| Step: 11
Training loss: 1.322197465816222
Validation loss: 2.752546778393136

Epoch: 152| Step: 0
Training loss: 2.1013930014854183
Validation loss: 2.7164791240394357

Epoch: 5| Step: 1
Training loss: 1.3007665868167533
Validation loss: 2.7373974036234454

Epoch: 5| Step: 2
Training loss: 0.9644106305920505
Validation loss: 2.72174264182364

Epoch: 5| Step: 3
Training loss: 1.2587365020361598
Validation loss: 2.635387708230926

Epoch: 5| Step: 4
Training loss: 1.3440653408777068
Validation loss: 2.7722576120995472

Epoch: 5| Step: 5
Training loss: 1.2014587555980432
Validation loss: 2.7052038317322076

Epoch: 5| Step: 6
Training loss: 1.344332103177873
Validation loss: 2.733429085742651

Epoch: 5| Step: 7
Training loss: 1.0663134076851508
Validation loss: 2.7050634794607675

Epoch: 5| Step: 8
Training loss: 1.1913697284041131
Validation loss: 2.738715086203258

Epoch: 5| Step: 9
Training loss: 1.1577854786549842
Validation loss: 2.7140713734208113

Epoch: 5| Step: 10
Training loss: 1.3817395287840462
Validation loss: 2.7365943330838194

Epoch: 5| Step: 11
Training loss: 0.5621938932181471
Validation loss: 2.7798931798377784

Epoch: 153| Step: 0
Training loss: 1.5382587638517293
Validation loss: 2.8125613382503127

Epoch: 5| Step: 1
Training loss: 1.5501933869345954
Validation loss: 2.6985411320180273

Epoch: 5| Step: 2
Training loss: 0.952110438444477
Validation loss: 2.643847340925346

Epoch: 5| Step: 3
Training loss: 1.0445901219305005
Validation loss: 2.714827909354781

Epoch: 5| Step: 4
Training loss: 1.0255042022291634
Validation loss: 2.5807367437631883

Epoch: 5| Step: 5
Training loss: 1.1432192837484212
Validation loss: 2.7145946434138652

Epoch: 5| Step: 6
Training loss: 1.5272744399634992
Validation loss: 2.5922909505020946

Epoch: 5| Step: 7
Training loss: 1.0421196842577363
Validation loss: 2.7122893576862825

Epoch: 5| Step: 8
Training loss: 2.10919392126413
Validation loss: 2.756831833172764

Epoch: 5| Step: 9
Training loss: 0.8322234312373253
Validation loss: 2.7429805742684557

Epoch: 5| Step: 10
Training loss: 1.3904081882808559
Validation loss: 2.7030234639349784

Epoch: 5| Step: 11
Training loss: 1.5203579024526734
Validation loss: 2.8325124467720473

Epoch: 154| Step: 0
Training loss: 1.4626590968266198
Validation loss: 2.837117775339958

Epoch: 5| Step: 1
Training loss: 1.9672196510602415
Validation loss: 2.8315183012755587

Epoch: 5| Step: 2
Training loss: 1.4690790822274533
Validation loss: 2.830737317777454

Epoch: 5| Step: 3
Training loss: 1.0699820460836458
Validation loss: 2.7600205743064286

Epoch: 5| Step: 4
Training loss: 0.8958555521907998
Validation loss: 2.6590562544992298

Epoch: 5| Step: 5
Training loss: 1.0333232268997974
Validation loss: 2.67051461371741

Epoch: 5| Step: 6
Training loss: 1.295183940623191
Validation loss: 2.631678549283915

Epoch: 5| Step: 7
Training loss: 1.656480737124522
Validation loss: 2.671217024990415

Epoch: 5| Step: 8
Training loss: 1.2538432167823528
Validation loss: 2.716040410196136

Epoch: 5| Step: 9
Training loss: 1.5638749748561107
Validation loss: 2.6430491130870837

Epoch: 5| Step: 10
Training loss: 1.4575452128181334
Validation loss: 2.7145047605087145

Epoch: 5| Step: 11
Training loss: 1.3504502675836214
Validation loss: 2.7422879337419754

Epoch: 155| Step: 0
Training loss: 1.5255050323213277
Validation loss: 2.8429840963839963

Epoch: 5| Step: 1
Training loss: 1.2772919530603257
Validation loss: 2.906263915408055

Epoch: 5| Step: 2
Training loss: 1.3050024143649748
Validation loss: 2.920603194854338

Epoch: 5| Step: 3
Training loss: 1.3546058920596553
Validation loss: 2.871044160237309

Epoch: 5| Step: 4
Training loss: 1.0314266169189483
Validation loss: 2.67317137769464

Epoch: 5| Step: 5
Training loss: 1.4779229733755828
Validation loss: 2.6803351380563876

Epoch: 5| Step: 6
Training loss: 1.1004027626307984
Validation loss: 2.7139792147521957

Epoch: 5| Step: 7
Training loss: 1.2444764167693745
Validation loss: 2.629550161570042

Epoch: 5| Step: 8
Training loss: 1.1796598115412664
Validation loss: 2.6671552967882883

Epoch: 5| Step: 9
Training loss: 1.9135342861719171
Validation loss: 2.650669222877106

Epoch: 5| Step: 10
Training loss: 1.159217223256267
Validation loss: 2.699000668583208

Epoch: 5| Step: 11
Training loss: 2.5181927578071566
Validation loss: 2.7482078882840106

Epoch: 156| Step: 0
Training loss: 0.8434276318193663
Validation loss: 2.6679774573255233

Epoch: 5| Step: 1
Training loss: 1.6036688374819374
Validation loss: 2.7812110240934143

Epoch: 5| Step: 2
Training loss: 2.1913198634237423
Validation loss: 2.7097466864677213

Epoch: 5| Step: 3
Training loss: 1.4818017439028888
Validation loss: 2.7057695150197074

Epoch: 5| Step: 4
Training loss: 1.3706465641244037
Validation loss: 2.684508484736336

Epoch: 5| Step: 5
Training loss: 1.3679652590355809
Validation loss: 2.6037221160374764

Epoch: 5| Step: 6
Training loss: 1.0225798529523562
Validation loss: 2.7230522637630177

Epoch: 5| Step: 7
Training loss: 1.4238977820752543
Validation loss: 2.843103852415957

Epoch: 5| Step: 8
Training loss: 1.742375043003534
Validation loss: 2.822887801741842

Epoch: 5| Step: 9
Training loss: 1.6564782902993054
Validation loss: 2.8409088250362386

Epoch: 5| Step: 10
Training loss: 1.1940469462368324
Validation loss: 2.7798484742769487

Epoch: 5| Step: 11
Training loss: 0.7124305808397872
Validation loss: 2.6499968638941365

Epoch: 157| Step: 0
Training loss: 1.5400209492336034
Validation loss: 2.7011335935199243

Epoch: 5| Step: 1
Training loss: 1.1911992628054262
Validation loss: 2.668038642381126

Epoch: 5| Step: 2
Training loss: 1.3540731055387787
Validation loss: 2.6411360485026294

Epoch: 5| Step: 3
Training loss: 1.131856949407934
Validation loss: 2.67475061546509

Epoch: 5| Step: 4
Training loss: 1.033768785668091
Validation loss: 2.6631447823204613

Epoch: 5| Step: 5
Training loss: 1.28977169988589
Validation loss: 2.6922000144509703

Epoch: 5| Step: 6
Training loss: 1.1486694205563464
Validation loss: 2.6751124973349865

Epoch: 5| Step: 7
Training loss: 1.2453660903178527
Validation loss: 2.7322137847477257

Epoch: 5| Step: 8
Training loss: 2.0437624029780617
Validation loss: 2.7133952532688794

Epoch: 5| Step: 9
Training loss: 1.5121373427496634
Validation loss: 2.7888421969845023

Epoch: 5| Step: 10
Training loss: 1.3715630839292927
Validation loss: 2.8677367672594283

Epoch: 5| Step: 11
Training loss: 1.588960669451488
Validation loss: 2.8075055033266656

Epoch: 158| Step: 0
Training loss: 1.3353229469981582
Validation loss: 2.7114600997979625

Epoch: 5| Step: 1
Training loss: 1.2622261090192664
Validation loss: 2.6989871715642653

Epoch: 5| Step: 2
Training loss: 1.390185340215961
Validation loss: 2.714757154076191

Epoch: 5| Step: 3
Training loss: 1.4888544855998425
Validation loss: 2.7139019071086055

Epoch: 5| Step: 4
Training loss: 0.8394042528498731
Validation loss: 2.6668685536157297

Epoch: 5| Step: 5
Training loss: 1.1755981809729865
Validation loss: 2.6602960849480928

Epoch: 5| Step: 6
Training loss: 1.1489170656145196
Validation loss: 2.65343903673866

Epoch: 5| Step: 7
Training loss: 1.0223762309520217
Validation loss: 2.765623965505633

Epoch: 5| Step: 8
Training loss: 1.271090445018896
Validation loss: 2.634489949449805

Epoch: 5| Step: 9
Training loss: 1.1077477784613405
Validation loss: 2.704087929296929

Epoch: 5| Step: 10
Training loss: 1.7978020971518756
Validation loss: 2.7720177647733326

Epoch: 5| Step: 11
Training loss: 0.33103251875298706
Validation loss: 2.7223740389934155

Epoch: 159| Step: 0
Training loss: 0.9368619655035776
Validation loss: 2.7405942688237177

Epoch: 5| Step: 1
Training loss: 1.112968963190305
Validation loss: 2.743932098393782

Epoch: 5| Step: 2
Training loss: 1.8937453065316736
Validation loss: 2.751031595423756

Epoch: 5| Step: 3
Training loss: 1.1411464492097438
Validation loss: 2.6515561724354813

Epoch: 5| Step: 4
Training loss: 1.0809835601812834
Validation loss: 2.6882977188878567

Epoch: 5| Step: 5
Training loss: 1.1535105859198795
Validation loss: 2.633893623959193

Epoch: 5| Step: 6
Training loss: 1.1355485693699465
Validation loss: 2.6476469285323807

Epoch: 5| Step: 7
Training loss: 1.4330486539792118
Validation loss: 2.714189574100365

Epoch: 5| Step: 8
Training loss: 1.4391628267685748
Validation loss: 2.6860853286548134

Epoch: 5| Step: 9
Training loss: 0.8915247471488088
Validation loss: 2.708977106804736

Epoch: 5| Step: 10
Training loss: 1.4609212619470664
Validation loss: 2.65962774149316

Epoch: 5| Step: 11
Training loss: 1.4904690578951059
Validation loss: 2.656892799689326

Epoch: 160| Step: 0
Training loss: 1.4853879183019918
Validation loss: 2.6526073199381432

Epoch: 5| Step: 1
Training loss: 1.0985111694809877
Validation loss: 2.6845723218414235

Epoch: 5| Step: 2
Training loss: 0.8830932238370119
Validation loss: 2.6186724061023745

Epoch: 5| Step: 3
Training loss: 1.0836700808614945
Validation loss: 2.622784610683188

Epoch: 5| Step: 4
Training loss: 1.4316244709930201
Validation loss: 2.7213436814004264

Epoch: 5| Step: 5
Training loss: 1.3191898245273865
Validation loss: 2.718351901347839

Epoch: 5| Step: 6
Training loss: 1.2394918787368188
Validation loss: 2.7970391834452606

Epoch: 5| Step: 7
Training loss: 0.9622195305840472
Validation loss: 2.684785540313689

Epoch: 5| Step: 8
Training loss: 1.076644544423377
Validation loss: 2.6278181426853062

Epoch: 5| Step: 9
Training loss: 1.0651996759373354
Validation loss: 2.670863579168667

Epoch: 5| Step: 10
Training loss: 1.9267539146604327
Validation loss: 2.6933554690127304

Epoch: 5| Step: 11
Training loss: 1.798508805254204
Validation loss: 2.807730639832992

Epoch: 161| Step: 0
Training loss: 1.4489410216528882
Validation loss: 2.719745439136317

Epoch: 5| Step: 1
Training loss: 1.0279150705024893
Validation loss: 2.734372235251346

Epoch: 5| Step: 2
Training loss: 1.145945225656566
Validation loss: 2.786023611698017

Epoch: 5| Step: 3
Training loss: 1.158518293191033
Validation loss: 2.766502090427113

Epoch: 5| Step: 4
Training loss: 1.2008231300292904
Validation loss: 2.752775785400751

Epoch: 5| Step: 5
Training loss: 1.7645679786971884
Validation loss: 2.735097869508595

Epoch: 5| Step: 6
Training loss: 0.6183769980236968
Validation loss: 2.7374963583261547

Epoch: 5| Step: 7
Training loss: 1.6244463344173914
Validation loss: 2.612696028538664

Epoch: 5| Step: 8
Training loss: 1.4777522062576545
Validation loss: 2.6787105814801078

Epoch: 5| Step: 9
Training loss: 1.2806576080415597
Validation loss: 2.736210528507698

Epoch: 5| Step: 10
Training loss: 1.1782226056613903
Validation loss: 2.6845756781413312

Epoch: 5| Step: 11
Training loss: 1.0812733884718382
Validation loss: 2.701374646729226

Epoch: 162| Step: 0
Training loss: 0.9614528421649507
Validation loss: 2.713588905777507

Epoch: 5| Step: 1
Training loss: 1.6087826129301945
Validation loss: 2.7025862838693566

Epoch: 5| Step: 2
Training loss: 1.9431431328929574
Validation loss: 2.6209645587674633

Epoch: 5| Step: 3
Training loss: 1.2709455857442964
Validation loss: 2.707990420469407

Epoch: 5| Step: 4
Training loss: 1.5153888636421138
Validation loss: 2.7071572219873956

Epoch: 5| Step: 5
Training loss: 1.1739339415829322
Validation loss: 2.660779625089453

Epoch: 5| Step: 6
Training loss: 1.3164326922650318
Validation loss: 2.7830359728851937

Epoch: 5| Step: 7
Training loss: 0.8251876559833408
Validation loss: 2.6650651161911783

Epoch: 5| Step: 8
Training loss: 0.8537540757401727
Validation loss: 2.702614344613659

Epoch: 5| Step: 9
Training loss: 1.3700951311398446
Validation loss: 2.8042844413654913

Epoch: 5| Step: 10
Training loss: 0.9620488880765449
Validation loss: 2.85351635608494

Epoch: 5| Step: 11
Training loss: 0.1543112518759118
Validation loss: 2.6630661929529005

Epoch: 163| Step: 0
Training loss: 1.196396529372553
Validation loss: 2.780182042264967

Epoch: 5| Step: 1
Training loss: 1.017899416760316
Validation loss: 2.716598909406788

Epoch: 5| Step: 2
Training loss: 1.6691527262864334
Validation loss: 2.641445664408211

Epoch: 5| Step: 3
Training loss: 1.2449943451963639
Validation loss: 2.627731196669665

Epoch: 5| Step: 4
Training loss: 1.0063867464205656
Validation loss: 2.685534372011615

Epoch: 5| Step: 5
Training loss: 1.31799704764966
Validation loss: 2.6979284151231413

Epoch: 5| Step: 6
Training loss: 1.7828183547650154
Validation loss: 2.6796688601899317

Epoch: 5| Step: 7
Training loss: 1.2365150732162118
Validation loss: 2.727004681194434

Epoch: 5| Step: 8
Training loss: 1.237622829082817
Validation loss: 2.54761986868815

Epoch: 5| Step: 9
Training loss: 0.6277194464664428
Validation loss: 2.6703339681698024

Epoch: 5| Step: 10
Training loss: 1.2711255201461888
Validation loss: 2.5729687578639857

Epoch: 5| Step: 11
Training loss: 1.4629215904391284
Validation loss: 2.6448857996203436

Epoch: 164| Step: 0
Training loss: 1.037097593193877
Validation loss: 2.6234701633597317

Epoch: 5| Step: 1
Training loss: 1.0726263832551923
Validation loss: 2.652317198675237

Epoch: 5| Step: 2
Training loss: 1.1721029949923583
Validation loss: 2.702649561648479

Epoch: 5| Step: 3
Training loss: 1.7368000706463997
Validation loss: 2.7206773576431367

Epoch: 5| Step: 4
Training loss: 0.5987916272133538
Validation loss: 2.6518671752768697

Epoch: 5| Step: 5
Training loss: 1.0543760616928028
Validation loss: 2.7635783400955813

Epoch: 5| Step: 6
Training loss: 1.3671982247068197
Validation loss: 2.8227094712647967

Epoch: 5| Step: 7
Training loss: 1.1765241335506413
Validation loss: 2.882722675747012

Epoch: 5| Step: 8
Training loss: 1.5425575191215997
Validation loss: 2.7635430403695334

Epoch: 5| Step: 9
Training loss: 1.0775005909681359
Validation loss: 2.787509920618625

Epoch: 5| Step: 10
Training loss: 1.2678995768163874
Validation loss: 2.661064030402907

Epoch: 5| Step: 11
Training loss: 0.54285616359228
Validation loss: 2.7804991497947866

Epoch: 165| Step: 0
Training loss: 1.3775606154520714
Validation loss: 2.747229115759602

Epoch: 5| Step: 1
Training loss: 1.2638945818110283
Validation loss: 2.7401651023397937

Epoch: 5| Step: 2
Training loss: 1.1889370705495943
Validation loss: 2.6588915985092907

Epoch: 5| Step: 3
Training loss: 1.8567052957133516
Validation loss: 2.701416677551602

Epoch: 5| Step: 4
Training loss: 1.00186121111904
Validation loss: 2.70056645726676

Epoch: 5| Step: 5
Training loss: 0.7661193497309845
Validation loss: 2.762119988876175

Epoch: 5| Step: 6
Training loss: 1.2288450154291999
Validation loss: 2.8127005611540503

Epoch: 5| Step: 7
Training loss: 1.3354031570552651
Validation loss: 2.8671384628773016

Epoch: 5| Step: 8
Training loss: 1.6223485295812137
Validation loss: 2.767015504508793

Epoch: 5| Step: 9
Training loss: 1.3660683110946858
Validation loss: 2.7136850898801264

Epoch: 5| Step: 10
Training loss: 0.9743085255437495
Validation loss: 2.677372504299656

Epoch: 5| Step: 11
Training loss: 2.0596303917490766
Validation loss: 2.6245409208343897

Epoch: 166| Step: 0
Training loss: 1.0586878886013533
Validation loss: 2.6167890406702616

Epoch: 5| Step: 1
Training loss: 0.9783059083895292
Validation loss: 2.660476542052727

Epoch: 5| Step: 2
Training loss: 1.296807344809082
Validation loss: 2.6873983208694714

Epoch: 5| Step: 3
Training loss: 1.1464586921167734
Validation loss: 2.7315189413931185

Epoch: 5| Step: 4
Training loss: 1.0985357487504237
Validation loss: 2.697380599348222

Epoch: 5| Step: 5
Training loss: 0.8914053325999401
Validation loss: 2.737945985971374

Epoch: 5| Step: 6
Training loss: 1.4802816066373081
Validation loss: 2.7524963521399077

Epoch: 5| Step: 7
Training loss: 0.8017367733089472
Validation loss: 2.813898374694856

Epoch: 5| Step: 8
Training loss: 1.2333557653105482
Validation loss: 2.6592209040295742

Epoch: 5| Step: 9
Training loss: 1.8244457552899076
Validation loss: 2.6758883638127697

Epoch: 5| Step: 10
Training loss: 1.186422813136129
Validation loss: 2.616417920661899

Epoch: 5| Step: 11
Training loss: 0.7686502283372777
Validation loss: 2.7266069206401236

Epoch: 167| Step: 0
Training loss: 1.1260531052894471
Validation loss: 2.7018037591584396

Epoch: 5| Step: 1
Training loss: 0.961685323870299
Validation loss: 2.6742408903830452

Epoch: 5| Step: 2
Training loss: 1.2896937818584517
Validation loss: 2.600481845607513

Epoch: 5| Step: 3
Training loss: 0.8637791919329741
Validation loss: 2.6182541756428033

Epoch: 5| Step: 4
Training loss: 1.111084172134199
Validation loss: 2.743364253694539

Epoch: 5| Step: 5
Training loss: 1.3910561653963402
Validation loss: 2.8701594106141184

Epoch: 5| Step: 6
Training loss: 1.0015303108172602
Validation loss: 2.7830217518741702

Epoch: 5| Step: 7
Training loss: 2.0820650309099937
Validation loss: 2.8034008797613184

Epoch: 5| Step: 8
Training loss: 1.2374449110774002
Validation loss: 2.801463031297254

Epoch: 5| Step: 9
Training loss: 1.2458489156575694
Validation loss: 2.712225619881602

Epoch: 5| Step: 10
Training loss: 0.7898469934293144
Validation loss: 2.7319810833068945

Epoch: 5| Step: 11
Training loss: 0.8083960987249857
Validation loss: 2.7015822166251433

Epoch: 168| Step: 0
Training loss: 1.3081980548258068
Validation loss: 2.7135245138981974

Epoch: 5| Step: 1
Training loss: 1.3727320694107545
Validation loss: 2.6760993712724734

Epoch: 5| Step: 2
Training loss: 1.547380307056655
Validation loss: 2.6750436179149295

Epoch: 5| Step: 3
Training loss: 1.1934931254003132
Validation loss: 2.6788773197018485

Epoch: 5| Step: 4
Training loss: 0.8472486298168153
Validation loss: 2.699608801755797

Epoch: 5| Step: 5
Training loss: 1.2595527883130748
Validation loss: 2.6927862703320047

Epoch: 5| Step: 6
Training loss: 0.9690212669814188
Validation loss: 2.6929999451231783

Epoch: 5| Step: 7
Training loss: 1.1702813565804915
Validation loss: 2.831963254616566

Epoch: 5| Step: 8
Training loss: 1.6626968869524805
Validation loss: 2.6757090779244903

Epoch: 5| Step: 9
Training loss: 1.085841716686177
Validation loss: 2.764332244660854

Epoch: 5| Step: 10
Training loss: 1.368110475981511
Validation loss: 2.7267518401328155

Epoch: 5| Step: 11
Training loss: 0.6115228020010771
Validation loss: 2.6969824515014493

Epoch: 169| Step: 0
Training loss: 1.220466383293298
Validation loss: 2.6603305440259635

Epoch: 5| Step: 1
Training loss: 0.8993858639483111
Validation loss: 2.698202723111998

Epoch: 5| Step: 2
Training loss: 1.1805763180471496
Validation loss: 2.625948806375785

Epoch: 5| Step: 3
Training loss: 1.192388911001245
Validation loss: 2.701242357255279

Epoch: 5| Step: 4
Training loss: 1.1321457577874947
Validation loss: 2.700699241481122

Epoch: 5| Step: 5
Training loss: 0.7794652388886317
Validation loss: 2.669685993318439

Epoch: 5| Step: 6
Training loss: 1.5193752806964145
Validation loss: 2.7904841791543027

Epoch: 5| Step: 7
Training loss: 0.7092157832199407
Validation loss: 2.6963809857880823

Epoch: 5| Step: 8
Training loss: 1.9568366222340416
Validation loss: 2.6656670683701114

Epoch: 5| Step: 9
Training loss: 1.010373786462095
Validation loss: 2.743783390418396

Epoch: 5| Step: 10
Training loss: 0.8544913155687516
Validation loss: 2.7002617329435363

Epoch: 5| Step: 11
Training loss: 0.6302250605063103
Validation loss: 2.680454426149666

Epoch: 170| Step: 0
Training loss: 1.7151208188843028
Validation loss: 2.6844309241820254

Epoch: 5| Step: 1
Training loss: 1.2140708500833948
Validation loss: 2.700189264163095

Epoch: 5| Step: 2
Training loss: 1.1251322880426142
Validation loss: 2.649758143754419

Epoch: 5| Step: 3
Training loss: 1.1549688922937005
Validation loss: 2.684187712776848

Epoch: 5| Step: 4
Training loss: 1.135174570900605
Validation loss: 2.685237342335838

Epoch: 5| Step: 5
Training loss: 0.777515871554468
Validation loss: 2.7322117050013808

Epoch: 5| Step: 6
Training loss: 0.9411446932159651
Validation loss: 2.6664902298395017

Epoch: 5| Step: 7
Training loss: 1.0514994155983746
Validation loss: 2.7480999061006166

Epoch: 5| Step: 8
Training loss: 1.226698460909776
Validation loss: 2.754748334265205

Epoch: 5| Step: 9
Training loss: 0.7970203192357126
Validation loss: 2.719352392349483

Epoch: 5| Step: 10
Training loss: 1.2399260851149403
Validation loss: 2.725265529656326

Epoch: 5| Step: 11
Training loss: 0.6631275326880898
Validation loss: 2.7194251102876787

Epoch: 171| Step: 0
Training loss: 1.1535273793232337
Validation loss: 2.725380879215652

Epoch: 5| Step: 1
Training loss: 0.8547809222001128
Validation loss: 2.8100945888835476

Epoch: 5| Step: 2
Training loss: 1.2720280435697673
Validation loss: 2.758874629221287

Epoch: 5| Step: 3
Training loss: 0.794740023420461
Validation loss: 2.745437218010255

Epoch: 5| Step: 4
Training loss: 0.9652805343576372
Validation loss: 2.6586492361712475

Epoch: 5| Step: 5
Training loss: 1.0183008596379761
Validation loss: 2.771725831144882

Epoch: 5| Step: 6
Training loss: 0.9113230286940925
Validation loss: 2.717233920235525

Epoch: 5| Step: 7
Training loss: 1.1633340489258701
Validation loss: 2.7294191736272246

Epoch: 5| Step: 8
Training loss: 1.1201276171729997
Validation loss: 2.6852708265439675

Epoch: 5| Step: 9
Training loss: 1.1633551579881158
Validation loss: 2.6583666838723348

Epoch: 5| Step: 10
Training loss: 1.1523995078869993
Validation loss: 2.603879639384375

Epoch: 5| Step: 11
Training loss: 3.6739004189873268
Validation loss: 2.65922193135266

Epoch: 172| Step: 0
Training loss: 1.4308221202419116
Validation loss: 2.9550850803640487

Epoch: 5| Step: 1
Training loss: 1.5263951470467856
Validation loss: 3.0643870774285973

Epoch: 5| Step: 2
Training loss: 1.22060380455323
Validation loss: 3.0390075508648144

Epoch: 5| Step: 3
Training loss: 1.1444112565085323
Validation loss: 3.001497457879497

Epoch: 5| Step: 4
Training loss: 1.1191398793695706
Validation loss: 2.740209632375738

Epoch: 5| Step: 5
Training loss: 1.158870819772228
Validation loss: 2.637011137398153

Epoch: 5| Step: 6
Training loss: 1.4131631256723804
Validation loss: 2.7461228095552386

Epoch: 5| Step: 7
Training loss: 1.4280815067805286
Validation loss: 2.7692972971280874

Epoch: 5| Step: 8
Training loss: 1.2401011958668113
Validation loss: 2.687148394613052

Epoch: 5| Step: 9
Training loss: 1.9885897593796513
Validation loss: 2.7535167084914245

Epoch: 5| Step: 10
Training loss: 0.9694650226262279
Validation loss: 2.725292649726267

Epoch: 5| Step: 11
Training loss: 1.2383078683585451
Validation loss: 2.6509732585442243

Epoch: 173| Step: 0
Training loss: 1.0921864914787123
Validation loss: 2.752458531843722

Epoch: 5| Step: 1
Training loss: 1.3412369582936665
Validation loss: 2.6826671201773173

Epoch: 5| Step: 2
Training loss: 0.7858927674200133
Validation loss: 2.797770632049901

Epoch: 5| Step: 3
Training loss: 1.0671174189734065
Validation loss: 2.738752011742804

Epoch: 5| Step: 4
Training loss: 0.943177389278647
Validation loss: 2.6984068058332027

Epoch: 5| Step: 5
Training loss: 1.880176772876855
Validation loss: 2.7401243383963862

Epoch: 5| Step: 6
Training loss: 0.831731966305317
Validation loss: 2.743404705157065

Epoch: 5| Step: 7
Training loss: 0.9250199934370942
Validation loss: 2.6785722901327778

Epoch: 5| Step: 8
Training loss: 1.0081812457519177
Validation loss: 2.7558596615754

Epoch: 5| Step: 9
Training loss: 1.0761277316086801
Validation loss: 2.6588580398954798

Epoch: 5| Step: 10
Training loss: 1.2599304091445471
Validation loss: 2.6791875537831342

Epoch: 5| Step: 11
Training loss: 0.8247721111667325
Validation loss: 2.647997336630716

Epoch: 174| Step: 0
Training loss: 1.8697308572074096
Validation loss: 2.63811633711345

Epoch: 5| Step: 1
Training loss: 1.0745432970315503
Validation loss: 2.6764899250501024

Epoch: 5| Step: 2
Training loss: 0.8721224949721339
Validation loss: 2.65690933347139

Epoch: 5| Step: 3
Training loss: 1.2269682000663258
Validation loss: 2.735651183455886

Epoch: 5| Step: 4
Training loss: 1.0187706576634186
Validation loss: 2.688667949197203

Epoch: 5| Step: 5
Training loss: 1.1442267628052791
Validation loss: 2.736478813645581

Epoch: 5| Step: 6
Training loss: 1.231934754941486
Validation loss: 2.724048643396035

Epoch: 5| Step: 7
Training loss: 0.900735420854429
Validation loss: 2.722692882523093

Epoch: 5| Step: 8
Training loss: 0.8139146813380501
Validation loss: 2.712738384372071

Epoch: 5| Step: 9
Training loss: 0.9134554028787617
Validation loss: 2.7305482116982924

Epoch: 5| Step: 10
Training loss: 1.1532783985193134
Validation loss: 2.6231464282828365

Epoch: 5| Step: 11
Training loss: 0.45015982862464865
Validation loss: 2.6765001319794006

Epoch: 175| Step: 0
Training loss: 1.7998869489560216
Validation loss: 2.6840572780508443

Epoch: 5| Step: 1
Training loss: 1.0542503863979154
Validation loss: 2.6138215392684865

Epoch: 5| Step: 2
Training loss: 1.2679572574379048
Validation loss: 2.6598658764996412

Epoch: 5| Step: 3
Training loss: 1.080032099317437
Validation loss: 2.6875073077967446

Epoch: 5| Step: 4
Training loss: 1.160377250198275
Validation loss: 2.7783698302707283

Epoch: 5| Step: 5
Training loss: 0.9858211007303829
Validation loss: 2.7148594515046827

Epoch: 5| Step: 6
Training loss: 1.0684224167657579
Validation loss: 2.763306186237441

Epoch: 5| Step: 7
Training loss: 1.3714283591934449
Validation loss: 2.72014130329913

Epoch: 5| Step: 8
Training loss: 1.1493526108486622
Validation loss: 2.8226585352276277

Epoch: 5| Step: 9
Training loss: 0.8118842065537298
Validation loss: 2.6993105183158757

Epoch: 5| Step: 10
Training loss: 0.8106933829023742
Validation loss: 2.71448259764451

Epoch: 5| Step: 11
Training loss: 0.9377410260948018
Validation loss: 2.676863610618007

Epoch: 176| Step: 0
Training loss: 1.1902563330312184
Validation loss: 2.585604420519247

Epoch: 5| Step: 1
Training loss: 1.0644096715614595
Validation loss: 2.657430351019886

Epoch: 5| Step: 2
Training loss: 0.8210257925844524
Validation loss: 2.7641833367897815

Epoch: 5| Step: 3
Training loss: 0.7643539231795133
Validation loss: 2.740767365704933

Epoch: 5| Step: 4
Training loss: 0.9281943375603591
Validation loss: 2.836856470710756

Epoch: 5| Step: 5
Training loss: 1.2172057810280992
Validation loss: 2.7310050179421324

Epoch: 5| Step: 6
Training loss: 1.1752950987659863
Validation loss: 2.786296423845755

Epoch: 5| Step: 7
Training loss: 1.1611668972341667
Validation loss: 2.693333082322032

Epoch: 5| Step: 8
Training loss: 0.8397560606133322
Validation loss: 2.7212648161071686

Epoch: 5| Step: 9
Training loss: 1.8331590771946185
Validation loss: 2.6010602212248415

Epoch: 5| Step: 10
Training loss: 0.9716599658900777
Validation loss: 2.752873523324628

Epoch: 5| Step: 11
Training loss: 0.6502367587987142
Validation loss: 2.7034239667965942

Epoch: 177| Step: 0
Training loss: 0.988328442558766
Validation loss: 2.6214992249360543

Epoch: 5| Step: 1
Training loss: 1.3657189902078075
Validation loss: 2.5853353761675066

Epoch: 5| Step: 2
Training loss: 0.8709967862890018
Validation loss: 2.6327242624229044

Epoch: 5| Step: 3
Training loss: 1.7745376737007588
Validation loss: 2.66145501382301

Epoch: 5| Step: 4
Training loss: 1.0785487903882633
Validation loss: 2.679128271532782

Epoch: 5| Step: 5
Training loss: 0.8966624762450178
Validation loss: 2.697508966479927

Epoch: 5| Step: 6
Training loss: 0.9434022439571313
Validation loss: 2.7828817295756787

Epoch: 5| Step: 7
Training loss: 0.9905247911376918
Validation loss: 2.719835996223934

Epoch: 5| Step: 8
Training loss: 1.2586423138768659
Validation loss: 2.767334770535701

Epoch: 5| Step: 9
Training loss: 0.9383174193666272
Validation loss: 2.718988813676092

Epoch: 5| Step: 10
Training loss: 0.8939742973951076
Validation loss: 2.5989377524886743

Epoch: 5| Step: 11
Training loss: 0.5671017815837882
Validation loss: 2.646310877068965

Epoch: 178| Step: 0
Training loss: 1.0124526731003007
Validation loss: 2.7259191539222405

Epoch: 5| Step: 1
Training loss: 1.3942509644662175
Validation loss: 2.6581339419534658

Epoch: 5| Step: 2
Training loss: 0.8741711028258934
Validation loss: 2.7038243221556133

Epoch: 5| Step: 3
Training loss: 1.743357654581796
Validation loss: 2.6737137875238086

Epoch: 5| Step: 4
Training loss: 0.9797519632209328
Validation loss: 2.6686251360220936

Epoch: 5| Step: 5
Training loss: 1.1527031806698724
Validation loss: 2.8366568417571365

Epoch: 5| Step: 6
Training loss: 0.9581652715074201
Validation loss: 2.702895560844969

Epoch: 5| Step: 7
Training loss: 1.1934431330729451
Validation loss: 2.746292150501262

Epoch: 5| Step: 8
Training loss: 1.091756038550363
Validation loss: 2.725851984728969

Epoch: 5| Step: 9
Training loss: 0.9110244735629576
Validation loss: 2.713584011184362

Epoch: 5| Step: 10
Training loss: 0.7185442256762102
Validation loss: 2.6927359460906586

Epoch: 5| Step: 11
Training loss: 0.47480416715680523
Validation loss: 2.5987964393682925

Epoch: 179| Step: 0
Training loss: 0.7723652506711678
Validation loss: 2.635540010684471

Epoch: 5| Step: 1
Training loss: 1.0973597767607508
Validation loss: 2.6625745128598397

Epoch: 5| Step: 2
Training loss: 1.084436545700437
Validation loss: 2.6850574357207813

Epoch: 5| Step: 3
Training loss: 0.8594471294303873
Validation loss: 2.594696220858963

Epoch: 5| Step: 4
Training loss: 1.0299521862894803
Validation loss: 2.75470289967849

Epoch: 5| Step: 5
Training loss: 1.205491648844047
Validation loss: 2.790175193711916

Epoch: 5| Step: 6
Training loss: 1.27439063039701
Validation loss: 2.7646128783459525

Epoch: 5| Step: 7
Training loss: 0.9192658371109672
Validation loss: 2.843642945422934

Epoch: 5| Step: 8
Training loss: 0.7827041063625259
Validation loss: 2.6939551690571544

Epoch: 5| Step: 9
Training loss: 1.712574841611165
Validation loss: 2.7756996242275607

Epoch: 5| Step: 10
Training loss: 1.2476483635602396
Validation loss: 2.7017527020381094

Epoch: 5| Step: 11
Training loss: 0.7043396524734695
Validation loss: 2.7132954195917387

Epoch: 180| Step: 0
Training loss: 1.0080101351682575
Validation loss: 2.607086727781699

Epoch: 5| Step: 1
Training loss: 0.6732911112344917
Validation loss: 2.6244978310860763

Epoch: 5| Step: 2
Training loss: 1.048198034736583
Validation loss: 2.586680030052906

Epoch: 5| Step: 3
Training loss: 0.8817754072028269
Validation loss: 2.6766780714747718

Epoch: 5| Step: 4
Training loss: 0.8007369982890291
Validation loss: 2.778087940119062

Epoch: 5| Step: 5
Training loss: 1.0750370307576875
Validation loss: 2.77370416496494

Epoch: 5| Step: 6
Training loss: 0.900917312919882
Validation loss: 2.797313485324104

Epoch: 5| Step: 7
Training loss: 1.159977035295143
Validation loss: 2.7425064633193887

Epoch: 5| Step: 8
Training loss: 0.7873801246109303
Validation loss: 2.7315571898105575

Epoch: 5| Step: 9
Training loss: 1.6609661684764945
Validation loss: 2.755980671232587

Epoch: 5| Step: 10
Training loss: 1.3100468552924065
Validation loss: 2.766723303377929

Epoch: 5| Step: 11
Training loss: 0.5507123647048098
Validation loss: 2.7982547311969195

Epoch: 181| Step: 0
Training loss: 0.5744025526608991
Validation loss: 2.7337565676379576

Epoch: 5| Step: 1
Training loss: 0.7908070230344847
Validation loss: 2.7177337504687644

Epoch: 5| Step: 2
Training loss: 1.1847164255775318
Validation loss: 2.6976570620638234

Epoch: 5| Step: 3
Training loss: 0.9912678519008818
Validation loss: 2.619641958905137

Epoch: 5| Step: 4
Training loss: 0.8266339103556531
Validation loss: 2.657467398570618

Epoch: 5| Step: 5
Training loss: 0.9215733956112965
Validation loss: 2.700143772435847

Epoch: 5| Step: 6
Training loss: 0.9276374204066524
Validation loss: 2.7001269073743313

Epoch: 5| Step: 7
Training loss: 1.208581860514023
Validation loss: 2.7480377580301227

Epoch: 5| Step: 8
Training loss: 1.6959493820761076
Validation loss: 2.717252878167031

Epoch: 5| Step: 9
Training loss: 0.8424345641377574
Validation loss: 2.7323708737394243

Epoch: 5| Step: 10
Training loss: 0.8867428814129331
Validation loss: 2.696119532263359

Epoch: 5| Step: 11
Training loss: 1.3013491836990267
Validation loss: 2.7795578706051876

Epoch: 182| Step: 0
Training loss: 1.7598160240077632
Validation loss: 2.670684725936234

Epoch: 5| Step: 1
Training loss: 1.1281667220835636
Validation loss: 2.702426805531327

Epoch: 5| Step: 2
Training loss: 1.1352525936652358
Validation loss: 2.6853718056691367

Epoch: 5| Step: 3
Training loss: 1.1153995104384584
Validation loss: 2.6460175575239453

Epoch: 5| Step: 4
Training loss: 0.9916236055999804
Validation loss: 2.6685365414327635

Epoch: 5| Step: 5
Training loss: 0.8308802779150435
Validation loss: 2.675992317878158

Epoch: 5| Step: 6
Training loss: 1.1910664558511095
Validation loss: 2.7378095691300777

Epoch: 5| Step: 7
Training loss: 0.8005532288971599
Validation loss: 2.7256554494823453

Epoch: 5| Step: 8
Training loss: 0.7964229049273316
Validation loss: 2.7300892476571974

Epoch: 5| Step: 9
Training loss: 0.9907877502565066
Validation loss: 2.7067115488484896

Epoch: 5| Step: 10
Training loss: 1.2027871289133223
Validation loss: 2.73153185033934

Epoch: 5| Step: 11
Training loss: 0.9592194123490316
Validation loss: 2.72256024053183

Epoch: 183| Step: 0
Training loss: 1.9267093673624853
Validation loss: 2.6678926374191443

Epoch: 5| Step: 1
Training loss: 0.8381027984523263
Validation loss: 2.6646420285697436

Epoch: 5| Step: 2
Training loss: 0.8840313826876451
Validation loss: 2.651929614208736

Epoch: 5| Step: 3
Training loss: 1.3145024600697013
Validation loss: 2.706858638161136

Epoch: 5| Step: 4
Training loss: 1.0747873916634618
Validation loss: 2.6475590962414457

Epoch: 5| Step: 5
Training loss: 0.8608470100714719
Validation loss: 2.643363552091145

Epoch: 5| Step: 6
Training loss: 0.8203390207998983
Validation loss: 2.7309169046777995

Epoch: 5| Step: 7
Training loss: 0.8768990888705911
Validation loss: 2.7054208292817226

Epoch: 5| Step: 8
Training loss: 0.8336327412289181
Validation loss: 2.78324771599993

Epoch: 5| Step: 9
Training loss: 1.046972298726591
Validation loss: 2.718412078669565

Epoch: 5| Step: 10
Training loss: 0.7709611494614251
Validation loss: 2.690379839814419

Epoch: 5| Step: 11
Training loss: 1.19741934805346
Validation loss: 2.6840676116509767

Epoch: 184| Step: 0
Training loss: 0.9261694629369094
Validation loss: 2.6316432148631557

Epoch: 5| Step: 1
Training loss: 1.2571427831015007
Validation loss: 2.5961605804624095

Epoch: 5| Step: 2
Training loss: 1.1608910080237405
Validation loss: 2.7092701917687134

Epoch: 5| Step: 3
Training loss: 1.2547375071668074
Validation loss: 2.659946076711802

Epoch: 5| Step: 4
Training loss: 0.9514433925606315
Validation loss: 2.7223797826085203

Epoch: 5| Step: 5
Training loss: 1.0516556855810815
Validation loss: 2.7309001932834542

Epoch: 5| Step: 6
Training loss: 1.766012773720326
Validation loss: 2.7330340303462806

Epoch: 5| Step: 7
Training loss: 1.1136065626845788
Validation loss: 2.903082914769386

Epoch: 5| Step: 8
Training loss: 1.0224229865695906
Validation loss: 2.8438310087633747

Epoch: 5| Step: 9
Training loss: 0.7423690975280215
Validation loss: 2.7817442915511523

Epoch: 5| Step: 10
Training loss: 1.076602801051669
Validation loss: 2.748589486290917

Epoch: 5| Step: 11
Training loss: 0.5881182714598309
Validation loss: 2.7423986877093482

Epoch: 185| Step: 0
Training loss: 0.8360753881512367
Validation loss: 2.6843713210424482

Epoch: 5| Step: 1
Training loss: 1.1781975640329547
Validation loss: 2.7208351820685825

Epoch: 5| Step: 2
Training loss: 1.0702952362673064
Validation loss: 2.7451564804552704

Epoch: 5| Step: 3
Training loss: 1.2342271354091983
Validation loss: 2.690958775756766

Epoch: 5| Step: 4
Training loss: 1.731066116317661
Validation loss: 2.6688573873743726

Epoch: 5| Step: 5
Training loss: 0.8135984405036579
Validation loss: 2.6595784968250955

Epoch: 5| Step: 6
Training loss: 0.8597642537183628
Validation loss: 2.9196614399145417

Epoch: 5| Step: 7
Training loss: 1.545464537328151
Validation loss: 2.978839817435199

Epoch: 5| Step: 8
Training loss: 1.3910128877565169
Validation loss: 3.003471687013043

Epoch: 5| Step: 9
Training loss: 1.409817134416122
Validation loss: 2.9031641721734642

Epoch: 5| Step: 10
Training loss: 0.9556840406084183
Validation loss: 2.7448689210408266

Epoch: 5| Step: 11
Training loss: 0.6392181346874497
Validation loss: 2.702999137785371

Epoch: 186| Step: 0
Training loss: 1.2857034092397677
Validation loss: 2.6316317448997752

Epoch: 5| Step: 1
Training loss: 0.8031101136367926
Validation loss: 2.6587820775007476

Epoch: 5| Step: 2
Training loss: 1.8494292255069675
Validation loss: 2.6923547336727065

Epoch: 5| Step: 3
Training loss: 0.8914819242299814
Validation loss: 2.7045314525630837

Epoch: 5| Step: 4
Training loss: 0.9714788027957499
Validation loss: 2.686905588166839

Epoch: 5| Step: 5
Training loss: 0.8928454977366026
Validation loss: 2.7038591192855845

Epoch: 5| Step: 6
Training loss: 1.0128787544987812
Validation loss: 2.6318267123804384

Epoch: 5| Step: 7
Training loss: 0.9748736311864653
Validation loss: 2.704969140897433

Epoch: 5| Step: 8
Training loss: 0.7726159404426538
Validation loss: 2.6260823258900685

Epoch: 5| Step: 9
Training loss: 1.21460562086295
Validation loss: 2.7464622188855943

Epoch: 5| Step: 10
Training loss: 1.0271600479250276
Validation loss: 2.6928838172167024

Epoch: 5| Step: 11
Training loss: 0.49455253109332936
Validation loss: 2.6633826327048116

Epoch: 187| Step: 0
Training loss: 1.5952698435670862
Validation loss: 2.7022322906067715

Epoch: 5| Step: 1
Training loss: 1.303915834934485
Validation loss: 2.6726759961054927

Epoch: 5| Step: 2
Training loss: 0.48046445456965053
Validation loss: 2.6772442941232306

Epoch: 5| Step: 3
Training loss: 0.9276861559734697
Validation loss: 2.6978159680714846

Epoch: 5| Step: 4
Training loss: 1.2335642312826236
Validation loss: 2.7126055229627677

Epoch: 5| Step: 5
Training loss: 1.0277354722867158
Validation loss: 2.648724186927369

Epoch: 5| Step: 6
Training loss: 0.7055399431064043
Validation loss: 2.7066644784334417

Epoch: 5| Step: 7
Training loss: 0.5586216526131798
Validation loss: 2.778469227854344

Epoch: 5| Step: 8
Training loss: 0.8489059517893416
Validation loss: 2.715539428714776

Epoch: 5| Step: 9
Training loss: 1.098611273660392
Validation loss: 2.7166972321466107

Epoch: 5| Step: 10
Training loss: 1.2574979969410651
Validation loss: 2.730040364275616

Epoch: 5| Step: 11
Training loss: 0.4199259203338939
Validation loss: 2.727818617816611

Epoch: 188| Step: 0
Training loss: 0.877303701218716
Validation loss: 2.670343908456692

Epoch: 5| Step: 1
Training loss: 0.6705902146759484
Validation loss: 2.6905413429644014

Epoch: 5| Step: 2
Training loss: 0.6494073853113614
Validation loss: 2.6810319195307684

Epoch: 5| Step: 3
Training loss: 1.883917393325155
Validation loss: 2.661036867984427

Epoch: 5| Step: 4
Training loss: 0.6138746949919244
Validation loss: 2.6698868495054837

Epoch: 5| Step: 5
Training loss: 0.6632851482586831
Validation loss: 2.6589151513070473

Epoch: 5| Step: 6
Training loss: 0.8477460752085283
Validation loss: 2.688455180895927

Epoch: 5| Step: 7
Training loss: 0.8943657867788816
Validation loss: 2.6994907703968454

Epoch: 5| Step: 8
Training loss: 0.9569770330525224
Validation loss: 2.680903519367911

Epoch: 5| Step: 9
Training loss: 0.850782439596222
Validation loss: 2.690277564241813

Epoch: 5| Step: 10
Training loss: 1.1095970898610013
Validation loss: 2.6524130204021965

Epoch: 5| Step: 11
Training loss: 0.9720019242302956
Validation loss: 2.579943391341534

Epoch: 189| Step: 0
Training loss: 1.0844491323146526
Validation loss: 2.684812621570173

Epoch: 5| Step: 1
Training loss: 0.9456856046469441
Validation loss: 2.554233522354358

Epoch: 5| Step: 2
Training loss: 0.7684533562562041
Validation loss: 2.6393284972473277

Epoch: 5| Step: 3
Training loss: 0.8425031562315911
Validation loss: 2.75455886286588

Epoch: 5| Step: 4
Training loss: 1.0416772396822627
Validation loss: 2.713071671979482

Epoch: 5| Step: 5
Training loss: 0.7361945883683889
Validation loss: 2.658255063422394

Epoch: 5| Step: 6
Training loss: 0.918093603855494
Validation loss: 2.660254265188048

Epoch: 5| Step: 7
Training loss: 1.8090543551779763
Validation loss: 2.66310044832453

Epoch: 5| Step: 8
Training loss: 0.7653356511394391
Validation loss: 2.813131621750685

Epoch: 5| Step: 9
Training loss: 0.7121800473916702
Validation loss: 2.762798546068818

Epoch: 5| Step: 10
Training loss: 1.1190122627288646
Validation loss: 2.7952758721272017

Epoch: 5| Step: 11
Training loss: 0.531948023712936
Validation loss: 2.7372456731478407

Epoch: 190| Step: 0
Training loss: 0.7581283854812294
Validation loss: 2.7602489036588054

Epoch: 5| Step: 1
Training loss: 1.1578661989843066
Validation loss: 2.6908872387226834

Epoch: 5| Step: 2
Training loss: 0.6306354609549006
Validation loss: 2.6754860893866454

Epoch: 5| Step: 3
Training loss: 0.703622154799344
Validation loss: 2.6318367226150654

Epoch: 5| Step: 4
Training loss: 1.027109039531748
Validation loss: 2.733104665037816

Epoch: 5| Step: 5
Training loss: 0.8320580061787818
Validation loss: 2.7605180157943745

Epoch: 5| Step: 6
Training loss: 0.8861326389594242
Validation loss: 2.593989376527488

Epoch: 5| Step: 7
Training loss: 1.788029068230514
Validation loss: 2.749709442712409

Epoch: 5| Step: 8
Training loss: 1.0468128242817865
Validation loss: 2.746005715722176

Epoch: 5| Step: 9
Training loss: 0.5394274264214807
Validation loss: 2.7343696012897785

Epoch: 5| Step: 10
Training loss: 0.8470233716881572
Validation loss: 2.6433373352367644

Epoch: 5| Step: 11
Training loss: 0.5898956124450532
Validation loss: 2.725385497470512

Epoch: 191| Step: 0
Training loss: 0.6920539494622463
Validation loss: 2.674472895500064

Epoch: 5| Step: 1
Training loss: 0.9772541496011146
Validation loss: 2.7257130346183955

Epoch: 5| Step: 2
Training loss: 1.7526126160401436
Validation loss: 2.6986007130088177

Epoch: 5| Step: 3
Training loss: 0.9621877213242744
Validation loss: 2.7474880377798607

Epoch: 5| Step: 4
Training loss: 0.8886910572706508
Validation loss: 2.6844450050732185

Epoch: 5| Step: 5
Training loss: 0.9502405702764871
Validation loss: 2.6943860585702444

Epoch: 5| Step: 6
Training loss: 0.8230807144892213
Validation loss: 2.678954347609041

Epoch: 5| Step: 7
Training loss: 0.8377029813494162
Validation loss: 2.6338637071139623

Epoch: 5| Step: 8
Training loss: 0.9464293258849065
Validation loss: 2.683598573431412

Epoch: 5| Step: 9
Training loss: 1.1272914649645014
Validation loss: 2.6159441371546888

Epoch: 5| Step: 10
Training loss: 0.9977765995763022
Validation loss: 2.6582121987880507

Epoch: 5| Step: 11
Training loss: 0.7520190717835366
Validation loss: 2.7418890099580198

Epoch: 192| Step: 0
Training loss: 1.2927048059374902
Validation loss: 2.6856053830333555

Epoch: 5| Step: 1
Training loss: 0.8494251972380027
Validation loss: 2.755815029350733

Epoch: 5| Step: 2
Training loss: 0.5560736194385084
Validation loss: 2.7909389989864044

Epoch: 5| Step: 3
Training loss: 1.7211098855916347
Validation loss: 2.7316722518738894

Epoch: 5| Step: 4
Training loss: 0.765795124382046
Validation loss: 2.7998777499077905

Epoch: 5| Step: 5
Training loss: 0.7549186194688282
Validation loss: 2.7772675444301513

Epoch: 5| Step: 6
Training loss: 1.0055718761042294
Validation loss: 2.7683023758278242

Epoch: 5| Step: 7
Training loss: 0.7647186286056015
Validation loss: 2.613235370592483

Epoch: 5| Step: 8
Training loss: 1.2360257566941082
Validation loss: 2.6577153259310546

Epoch: 5| Step: 9
Training loss: 0.631426340910172
Validation loss: 2.6365934780173292

Epoch: 5| Step: 10
Training loss: 0.9658719040347234
Validation loss: 2.680917266764609

Epoch: 5| Step: 11
Training loss: 0.8426193149421839
Validation loss: 2.57695184661061

Epoch: 193| Step: 0
Training loss: 0.43115014910544397
Validation loss: 2.6692040498644296

Epoch: 5| Step: 1
Training loss: 0.7974560433115415
Validation loss: 2.750661593384979

Epoch: 5| Step: 2
Training loss: 1.1585591944494926
Validation loss: 2.800796459091085

Epoch: 5| Step: 3
Training loss: 1.037788240768907
Validation loss: 2.861879915709591

Epoch: 5| Step: 4
Training loss: 1.0380736500110626
Validation loss: 2.701051172854438

Epoch: 5| Step: 5
Training loss: 1.1542520014113669
Validation loss: 2.7786552991530056

Epoch: 5| Step: 6
Training loss: 0.7254106969731988
Validation loss: 2.689992101291667

Epoch: 5| Step: 7
Training loss: 0.9468652882093672
Validation loss: 2.7130167331958726

Epoch: 5| Step: 8
Training loss: 0.7343744318533789
Validation loss: 2.7716163315296023

Epoch: 5| Step: 9
Training loss: 1.5984220651308336
Validation loss: 2.7069142964517945

Epoch: 5| Step: 10
Training loss: 0.744250872597713
Validation loss: 2.680969194974195

Epoch: 5| Step: 11
Training loss: 0.9558802319844049
Validation loss: 2.72737979389764

Epoch: 194| Step: 0
Training loss: 0.8963941142201768
Validation loss: 2.820729651909904

Epoch: 5| Step: 1
Training loss: 0.6951990356448501
Validation loss: 2.9375873951728333

Epoch: 5| Step: 2
Training loss: 0.9591100109335569
Validation loss: 2.8280384514142414

Epoch: 5| Step: 3
Training loss: 0.9944064940830527
Validation loss: 2.829720501959163

Epoch: 5| Step: 4
Training loss: 1.1811020814026727
Validation loss: 2.791148231297938

Epoch: 5| Step: 5
Training loss: 1.0256876778614359
Validation loss: 2.6309848595938363

Epoch: 5| Step: 6
Training loss: 1.6620116871906028
Validation loss: 2.715697855350729

Epoch: 5| Step: 7
Training loss: 1.0574150702458713
Validation loss: 2.7143070266718694

Epoch: 5| Step: 8
Training loss: 0.983273389303859
Validation loss: 2.66807828485658

Epoch: 5| Step: 9
Training loss: 1.0200824635961134
Validation loss: 2.684924281228898

Epoch: 5| Step: 10
Training loss: 0.6702765368437694
Validation loss: 2.723191163592481

Epoch: 5| Step: 11
Training loss: 1.403393280956748
Validation loss: 2.7001791394228203

Epoch: 195| Step: 0
Training loss: 1.5659567171256326
Validation loss: 2.941843075546285

Epoch: 5| Step: 1
Training loss: 1.6851502766368474
Validation loss: 3.1124584430131508

Epoch: 5| Step: 2
Training loss: 1.4705270608631984
Validation loss: 3.0897251882846284

Epoch: 5| Step: 3
Training loss: 1.1657656300981931
Validation loss: 2.9718458697699432

Epoch: 5| Step: 4
Training loss: 0.9013010581443414
Validation loss: 2.7501763807433086

Epoch: 5| Step: 5
Training loss: 0.8453584457574829
Validation loss: 2.629192028789846

Epoch: 5| Step: 6
Training loss: 0.7869564693534755
Validation loss: 2.7636696931181115

Epoch: 5| Step: 7
Training loss: 1.375921677414618
Validation loss: 2.725579172816459

Epoch: 5| Step: 8
Training loss: 1.3209702698555192
Validation loss: 2.7303122174058845

Epoch: 5| Step: 9
Training loss: 0.9606173222271596
Validation loss: 2.6949120523532057

Epoch: 5| Step: 10
Training loss: 1.288985094000525
Validation loss: 2.6331065774920996

Epoch: 5| Step: 11
Training loss: 0.6645801097668125
Validation loss: 2.7138602691485336

Epoch: 196| Step: 0
Training loss: 1.1864590348712476
Validation loss: 2.853382007378317

Epoch: 5| Step: 1
Training loss: 1.086920807604155
Validation loss: 2.926440424018511

Epoch: 5| Step: 2
Training loss: 0.9769118027640155
Validation loss: 2.9427439167043117

Epoch: 5| Step: 3
Training loss: 1.126584949878167
Validation loss: 2.8587967213169754

Epoch: 5| Step: 4
Training loss: 1.0017567343584262
Validation loss: 2.8618905270948014

Epoch: 5| Step: 5
Training loss: 0.9460673825458733
Validation loss: 2.671205217316007

Epoch: 5| Step: 6
Training loss: 0.6699068607171477
Validation loss: 2.7301432170377455

Epoch: 5| Step: 7
Training loss: 1.0097781389003355
Validation loss: 2.6191964557186407

Epoch: 5| Step: 8
Training loss: 1.791959989918511
Validation loss: 2.729523847711386

Epoch: 5| Step: 9
Training loss: 0.8712580230868889
Validation loss: 2.7045258987781975

Epoch: 5| Step: 10
Training loss: 0.8058156743591789
Validation loss: 2.6652279632295923

Epoch: 5| Step: 11
Training loss: 0.7395585329079466
Validation loss: 2.6177528036529574

Epoch: 197| Step: 0
Training loss: 0.9271543275603044
Validation loss: 2.6175031784752436

Epoch: 5| Step: 1
Training loss: 0.7735954662805549
Validation loss: 2.736155803808111

Epoch: 5| Step: 2
Training loss: 1.1486119767082876
Validation loss: 2.7103598086330702

Epoch: 5| Step: 3
Training loss: 0.6214236217177944
Validation loss: 2.807757784211788

Epoch: 5| Step: 4
Training loss: 1.0286400452784974
Validation loss: 2.8934976274089403

Epoch: 5| Step: 5
Training loss: 0.962876108922893
Validation loss: 2.8382247724583185

Epoch: 5| Step: 6
Training loss: 1.5514083862597337
Validation loss: 2.7482451164282953

Epoch: 5| Step: 7
Training loss: 0.9409020367606311
Validation loss: 2.6478747742463153

Epoch: 5| Step: 8
Training loss: 0.6888572560203642
Validation loss: 2.671769569503063

Epoch: 5| Step: 9
Training loss: 0.9499270461329404
Validation loss: 2.6393645361222355

Epoch: 5| Step: 10
Training loss: 1.1313633034800823
Validation loss: 2.6218361520901396

Epoch: 5| Step: 11
Training loss: 1.0313215519906795
Validation loss: 2.6976787702819256

Epoch: 198| Step: 0
Training loss: 1.0053732280514014
Validation loss: 2.6549232834737584

Epoch: 5| Step: 1
Training loss: 1.0709367031765664
Validation loss: 2.609403587230399

Epoch: 5| Step: 2
Training loss: 0.4435644305766204
Validation loss: 2.8294675812132213

Epoch: 5| Step: 3
Training loss: 1.1969856071658536
Validation loss: 2.8197772151227687

Epoch: 5| Step: 4
Training loss: 1.373437166702178
Validation loss: 2.8787542688633767

Epoch: 5| Step: 5
Training loss: 0.9199535907048522
Validation loss: 2.789872907480664

Epoch: 5| Step: 6
Training loss: 0.6973446499363355
Validation loss: 2.725757126516005

Epoch: 5| Step: 7
Training loss: 1.0131933593279372
Validation loss: 2.6219966222162747

Epoch: 5| Step: 8
Training loss: 1.6399001200429986
Validation loss: 2.6615943419808494

Epoch: 5| Step: 9
Training loss: 0.9864178607268821
Validation loss: 2.5380588523688674

Epoch: 5| Step: 10
Training loss: 0.9454982669618762
Validation loss: 2.6836166084719

Epoch: 5| Step: 11
Training loss: 0.5634030140390236
Validation loss: 2.6135880271678835

Epoch: 199| Step: 0
Training loss: 0.8212953038834633
Validation loss: 2.6549418575460315

Epoch: 5| Step: 1
Training loss: 0.7740782578504148
Validation loss: 2.750961012971803

Epoch: 5| Step: 2
Training loss: 0.8952591112872147
Validation loss: 2.7180118088446985

Epoch: 5| Step: 3
Training loss: 1.6727223610853
Validation loss: 2.6714982404784577

Epoch: 5| Step: 4
Training loss: 0.4987501228303686
Validation loss: 2.7372493858526012

Epoch: 5| Step: 5
Training loss: 0.7819644712733446
Validation loss: 2.72944913135251

Epoch: 5| Step: 6
Training loss: 1.0272560227218246
Validation loss: 2.6824530889338303

Epoch: 5| Step: 7
Training loss: 0.6964630294840788
Validation loss: 2.6633354828276414

Epoch: 5| Step: 8
Training loss: 0.8778789026085908
Validation loss: 2.7498004075069495

Epoch: 5| Step: 9
Training loss: 1.0394844403113859
Validation loss: 2.71257512285946

Epoch: 5| Step: 10
Training loss: 0.7926697566654218
Validation loss: 2.7037908950325416

Epoch: 5| Step: 11
Training loss: 0.48551726247110943
Validation loss: 2.639589226938687

Epoch: 200| Step: 0
Training loss: 0.7299498076362808
Validation loss: 2.729594507727831

Epoch: 5| Step: 1
Training loss: 0.9614549809676745
Validation loss: 2.6413016609126014

Epoch: 5| Step: 2
Training loss: 1.7171590898157743
Validation loss: 2.7225845998843776

Epoch: 5| Step: 3
Training loss: 0.61650475028065
Validation loss: 2.659961314254664

Epoch: 5| Step: 4
Training loss: 0.8148602536103788
Validation loss: 2.573428141120055

Epoch: 5| Step: 5
Training loss: 0.7375666071022073
Validation loss: 2.605828359056472

Epoch: 5| Step: 6
Training loss: 0.9977232227235341
Validation loss: 2.655070966956284

Epoch: 5| Step: 7
Training loss: 0.6775618011890443
Validation loss: 2.675661976330134

Epoch: 5| Step: 8
Training loss: 0.9710808984054914
Validation loss: 2.7662751462735495

Epoch: 5| Step: 9
Training loss: 0.765340557588758
Validation loss: 2.6807419729115276

Epoch: 5| Step: 10
Training loss: 0.9718744897381096
Validation loss: 2.622172297193954

Epoch: 5| Step: 11
Training loss: 0.9267430841945776
Validation loss: 2.6837977184239996

Epoch: 201| Step: 0
Training loss: 1.24717187430568
Validation loss: 2.712594737758509

Epoch: 5| Step: 1
Training loss: 0.8661346229902815
Validation loss: 2.674829641455331

Epoch: 5| Step: 2
Training loss: 0.8188152272690239
Validation loss: 2.6435430005306904

Epoch: 5| Step: 3
Training loss: 0.596848034873732
Validation loss: 2.6376149083970053

Epoch: 5| Step: 4
Training loss: 0.7747294107405068
Validation loss: 2.6786617692214616

Epoch: 5| Step: 5
Training loss: 0.4420649584487861
Validation loss: 2.6726344183794266

Epoch: 5| Step: 6
Training loss: 0.8408902767194922
Validation loss: 2.7279478013387775

Epoch: 5| Step: 7
Training loss: 1.0951867612315849
Validation loss: 2.745480131974169

Epoch: 5| Step: 8
Training loss: 0.6396124210846597
Validation loss: 2.680248401983308

Epoch: 5| Step: 9
Training loss: 0.7112292016177955
Validation loss: 2.6374251674443707

Epoch: 5| Step: 10
Training loss: 1.5374219642002156
Validation loss: 2.7392245022612145

Epoch: 5| Step: 11
Training loss: 0.7648565756917677
Validation loss: 2.6991821154083318

Epoch: 202| Step: 0
Training loss: 0.5782916627826146
Validation loss: 2.6962329380154033

Epoch: 5| Step: 1
Training loss: 0.8485424489680249
Validation loss: 2.676227653002694

Epoch: 5| Step: 2
Training loss: 0.7370018747738061
Validation loss: 2.719865255968612

Epoch: 5| Step: 3
Training loss: 0.8031547540875088
Validation loss: 2.6542025304424377

Epoch: 5| Step: 4
Training loss: 0.8141808729451838
Validation loss: 2.6595375435714375

Epoch: 5| Step: 5
Training loss: 0.7825211673835151
Validation loss: 2.7503160670741007

Epoch: 5| Step: 6
Training loss: 0.5969597491668265
Validation loss: 2.715789745368661

Epoch: 5| Step: 7
Training loss: 1.7737153629633633
Validation loss: 2.6512664719591035

Epoch: 5| Step: 8
Training loss: 0.760679817826004
Validation loss: 2.615525533105825

Epoch: 5| Step: 9
Training loss: 0.7729441292571702
Validation loss: 2.5539711464063823

Epoch: 5| Step: 10
Training loss: 0.9517361261725854
Validation loss: 2.646152821848094

Epoch: 5| Step: 11
Training loss: 0.49909793424604926
Validation loss: 2.6682837594919544

Epoch: 203| Step: 0
Training loss: 0.5745828991981214
Validation loss: 2.6434583830768617

Epoch: 5| Step: 1
Training loss: 0.54876518567391
Validation loss: 2.624241431697466

Epoch: 5| Step: 2
Training loss: 0.596924127683974
Validation loss: 2.6372392041864754

Epoch: 5| Step: 3
Training loss: 0.9523722693637846
Validation loss: 2.677245882247535

Epoch: 5| Step: 4
Training loss: 0.9674647942872506
Validation loss: 2.6875358106016365

Epoch: 5| Step: 5
Training loss: 1.587693918954672
Validation loss: 2.7211676951986834

Epoch: 5| Step: 6
Training loss: 0.8443870258957308
Validation loss: 2.621214794200838

Epoch: 5| Step: 7
Training loss: 1.0702103057857013
Validation loss: 2.65744947764644

Epoch: 5| Step: 8
Training loss: 0.7535623744544647
Validation loss: 2.6303503105192734

Epoch: 5| Step: 9
Training loss: 1.2350858741896957
Validation loss: 2.616520776802119

Epoch: 5| Step: 10
Training loss: 0.4269930891509583
Validation loss: 2.6177067123015414

Epoch: 5| Step: 11
Training loss: 0.781728216674749
Validation loss: 2.722022429311942

Epoch: 204| Step: 0
Training loss: 0.7282189795621362
Validation loss: 2.6842504713004707

Epoch: 5| Step: 1
Training loss: 0.5796063235220954
Validation loss: 2.6245359699400397

Epoch: 5| Step: 2
Training loss: 0.893361421957202
Validation loss: 2.6285771489389638

Epoch: 5| Step: 3
Training loss: 0.5289521731298021
Validation loss: 2.673743525992568

Epoch: 5| Step: 4
Training loss: 0.8063555714885297
Validation loss: 2.636113368108654

Epoch: 5| Step: 5
Training loss: 0.9097523263669336
Validation loss: 2.732212352195343

Epoch: 5| Step: 6
Training loss: 0.7418849529186833
Validation loss: 2.7287838766896244

Epoch: 5| Step: 7
Training loss: 1.1449147906518604
Validation loss: 2.7160298928337254

Epoch: 5| Step: 8
Training loss: 0.7144547534921982
Validation loss: 2.7622345312794065

Epoch: 5| Step: 9
Training loss: 1.6649140520794963
Validation loss: 2.655913354072908

Epoch: 5| Step: 10
Training loss: 0.8871612117106816
Validation loss: 2.6411999033365245

Epoch: 5| Step: 11
Training loss: 0.8426871139501717
Validation loss: 2.7276796422401355

Epoch: 205| Step: 0
Training loss: 0.9270080935918072
Validation loss: 2.623868497820252

Epoch: 5| Step: 1
Training loss: 0.5764184456515117
Validation loss: 2.6832127566721686

Epoch: 5| Step: 2
Training loss: 0.8076889209187245
Validation loss: 2.6742324560543937

Epoch: 5| Step: 3
Training loss: 0.8182748828324817
Validation loss: 2.6292771979422027

Epoch: 5| Step: 4
Training loss: 0.6360225030198906
Validation loss: 2.664343309192371

Epoch: 5| Step: 5
Training loss: 0.7469422473719897
Validation loss: 2.801793329247125

Epoch: 5| Step: 6
Training loss: 0.9440326065437107
Validation loss: 2.6419040095470265

Epoch: 5| Step: 7
Training loss: 0.6870577430085013
Validation loss: 2.6659206238379687

Epoch: 5| Step: 8
Training loss: 0.7031991919475443
Validation loss: 2.722273848545796

Epoch: 5| Step: 9
Training loss: 1.7682495865089884
Validation loss: 2.755877881581623

Epoch: 5| Step: 10
Training loss: 0.7864355037651444
Validation loss: 2.783101754824263

Epoch: 5| Step: 11
Training loss: 0.2582936998056423
Validation loss: 2.7153225629733244

Epoch: 206| Step: 0
Training loss: 0.7718692640330823
Validation loss: 2.684350152838822

Epoch: 5| Step: 1
Training loss: 0.7827467504365053
Validation loss: 2.757147679149991

Epoch: 5| Step: 2
Training loss: 0.6826744219316487
Validation loss: 2.6653642727408005

Epoch: 5| Step: 3
Training loss: 1.7291915003207408
Validation loss: 2.6229676788334557

Epoch: 5| Step: 4
Training loss: 0.9943075283520184
Validation loss: 2.7564925690392843

Epoch: 5| Step: 5
Training loss: 0.856779618300336
Validation loss: 2.726595968571169

Epoch: 5| Step: 6
Training loss: 0.7293759091199163
Validation loss: 2.722744242022982

Epoch: 5| Step: 7
Training loss: 0.5744753672894071
Validation loss: 2.651498104490662

Epoch: 5| Step: 8
Training loss: 0.4174936035945442
Validation loss: 2.7351243218544483

Epoch: 5| Step: 9
Training loss: 0.7680412623029934
Validation loss: 2.7362632952536017

Epoch: 5| Step: 10
Training loss: 0.901940887487105
Validation loss: 2.7300727713554194

Epoch: 5| Step: 11
Training loss: 0.7001592821031299
Validation loss: 2.7071524331921237

Epoch: 207| Step: 0
Training loss: 0.8716654932574609
Validation loss: 2.825181080421583

Epoch: 5| Step: 1
Training loss: 0.6156259894968203
Validation loss: 2.7264220047598533

Epoch: 5| Step: 2
Training loss: 0.7903164634740959
Validation loss: 2.6431353785720817

Epoch: 5| Step: 3
Training loss: 0.8023895488322715
Validation loss: 2.7739290079497474

Epoch: 5| Step: 4
Training loss: 0.7484408703053193
Validation loss: 2.647533607587793

Epoch: 5| Step: 5
Training loss: 0.5639553845425603
Validation loss: 2.644692303830727

Epoch: 5| Step: 6
Training loss: 1.6445005146697351
Validation loss: 2.713703177557865

Epoch: 5| Step: 7
Training loss: 0.9644895204495837
Validation loss: 2.7444308488352913

Epoch: 5| Step: 8
Training loss: 0.9024616841454021
Validation loss: 2.7704061319873126

Epoch: 5| Step: 9
Training loss: 0.7022533524060787
Validation loss: 2.809855588401439

Epoch: 5| Step: 10
Training loss: 0.5523749756788225
Validation loss: 2.7918027422369924

Epoch: 5| Step: 11
Training loss: 0.9441875352991428
Validation loss: 2.721084593542908

Epoch: 208| Step: 0
Training loss: 0.6963023522862261
Validation loss: 2.6542834238773985

Epoch: 5| Step: 1
Training loss: 1.050580994764063
Validation loss: 2.690095561119316

Epoch: 5| Step: 2
Training loss: 0.7381912257292912
Validation loss: 2.666701682923808

Epoch: 5| Step: 3
Training loss: 0.7582524389220826
Validation loss: 2.6756274715145736

Epoch: 5| Step: 4
Training loss: 0.5411192316217962
Validation loss: 2.7034508539973205

Epoch: 5| Step: 5
Training loss: 1.4757791691811364
Validation loss: 2.7431005024882618

Epoch: 5| Step: 6
Training loss: 0.720927092531217
Validation loss: 2.8314738740191174

Epoch: 5| Step: 7
Training loss: 0.9755964459988344
Validation loss: 2.7817430487804997

Epoch: 5| Step: 8
Training loss: 0.8614088440179126
Validation loss: 2.649727337533208

Epoch: 5| Step: 9
Training loss: 0.6882733850105535
Validation loss: 2.6944938964555183

Epoch: 5| Step: 10
Training loss: 1.0163288318608996
Validation loss: 2.7204382357387664

Epoch: 5| Step: 11
Training loss: 0.9883920961722412
Validation loss: 2.623542202982008

Epoch: 209| Step: 0
Training loss: 0.7383149558148947
Validation loss: 2.7014652294256156

Epoch: 5| Step: 1
Training loss: 0.7449134558135388
Validation loss: 2.6794508114930538

Epoch: 5| Step: 2
Training loss: 0.5849432329609596
Validation loss: 2.6545326889788337

Epoch: 5| Step: 3
Training loss: 0.7141956246987919
Validation loss: 2.7606067927880478

Epoch: 5| Step: 4
Training loss: 0.931192734256891
Validation loss: 2.681584679227675

Epoch: 5| Step: 5
Training loss: 0.6478774168222264
Validation loss: 2.7803745320623907

Epoch: 5| Step: 6
Training loss: 1.0054446059664919
Validation loss: 2.6980042179488026

Epoch: 5| Step: 7
Training loss: 1.5980436792670396
Validation loss: 2.7272513939343415

Epoch: 5| Step: 8
Training loss: 0.8467970330077798
Validation loss: 2.661163453091949

Epoch: 5| Step: 9
Training loss: 0.6159862465344882
Validation loss: 2.7483049753641122

Epoch: 5| Step: 10
Training loss: 0.7258723272659026
Validation loss: 2.690024731408911

Epoch: 5| Step: 11
Training loss: 0.48163039420122095
Validation loss: 2.7437629485060113

Epoch: 210| Step: 0
Training loss: 1.0731194437246387
Validation loss: 2.708572721294249

Epoch: 5| Step: 1
Training loss: 0.5707215710217076
Validation loss: 2.762546003542629

Epoch: 5| Step: 2
Training loss: 1.56161496846635
Validation loss: 2.696658807180368

Epoch: 5| Step: 3
Training loss: 0.9586539699600571
Validation loss: 2.7261550110598125

Epoch: 5| Step: 4
Training loss: 0.5005441922847804
Validation loss: 2.703633229395256

Epoch: 5| Step: 5
Training loss: 0.806464963540964
Validation loss: 2.6900023963981363

Epoch: 5| Step: 6
Training loss: 0.6064463444945175
Validation loss: 2.6849248658222216

Epoch: 5| Step: 7
Training loss: 0.7011376375217986
Validation loss: 2.7318517014152817

Epoch: 5| Step: 8
Training loss: 0.5772080237390695
Validation loss: 2.6902093943682392

Epoch: 5| Step: 9
Training loss: 1.0351903369977313
Validation loss: 2.6136610556272926

Epoch: 5| Step: 10
Training loss: 0.5411488062679317
Validation loss: 2.6604477269433917

Epoch: 5| Step: 11
Training loss: 0.6387403725572276
Validation loss: 2.7671147373368328

Epoch: 211| Step: 0
Training loss: 0.6823117905966256
Validation loss: 2.7640123406964876

Epoch: 5| Step: 1
Training loss: 0.7277624414573645
Validation loss: 2.820300531053727

Epoch: 5| Step: 2
Training loss: 0.9424532058594104
Validation loss: 2.720970916531165

Epoch: 5| Step: 3
Training loss: 0.8168641043113687
Validation loss: 2.6982907044536675

Epoch: 5| Step: 4
Training loss: 0.6908330750627882
Validation loss: 2.6302807989933585

Epoch: 5| Step: 5
Training loss: 0.8267110593730419
Validation loss: 2.7127406932759173

Epoch: 5| Step: 6
Training loss: 0.5606813169875581
Validation loss: 2.6892803434906214

Epoch: 5| Step: 7
Training loss: 0.6970672325179531
Validation loss: 2.7095710982620793

Epoch: 5| Step: 8
Training loss: 0.5891868773675917
Validation loss: 2.595917477833403

Epoch: 5| Step: 9
Training loss: 0.6031860636894716
Validation loss: 2.6724495149250433

Epoch: 5| Step: 10
Training loss: 1.6106927162178608
Validation loss: 2.6406889950975088

Epoch: 5| Step: 11
Training loss: 0.6840746250881655
Validation loss: 2.7637421759660437

Epoch: 212| Step: 0
Training loss: 0.7926367454603062
Validation loss: 2.7686119401092615

Epoch: 5| Step: 1
Training loss: 1.7194230582462129
Validation loss: 2.7136521100335336

Epoch: 5| Step: 2
Training loss: 0.5917146329734017
Validation loss: 2.77423052128642

Epoch: 5| Step: 3
Training loss: 0.5993534001504807
Validation loss: 2.812394419207177

Epoch: 5| Step: 4
Training loss: 0.8377848738512611
Validation loss: 2.7643334485412057

Epoch: 5| Step: 5
Training loss: 0.8551728943247527
Validation loss: 2.7116365731493417

Epoch: 5| Step: 6
Training loss: 0.7943615262309263
Validation loss: 2.6910182339142543

Epoch: 5| Step: 7
Training loss: 0.8987371525489506
Validation loss: 2.732434039830725

Epoch: 5| Step: 8
Training loss: 0.7891595988442183
Validation loss: 2.724210615613612

Epoch: 5| Step: 9
Training loss: 0.9608714073216216
Validation loss: 2.6225581505604088

Epoch: 5| Step: 10
Training loss: 0.7344821689407115
Validation loss: 2.669974835607025

Epoch: 5| Step: 11
Training loss: 0.37036551244958305
Validation loss: 2.683609700976872

Epoch: 213| Step: 0
Training loss: 0.7365318846135989
Validation loss: 2.7616043031135913

Epoch: 5| Step: 1
Training loss: 0.8890953312662984
Validation loss: 2.7342702100746945

Epoch: 5| Step: 2
Training loss: 0.6211772838535038
Validation loss: 2.7441099443451424

Epoch: 5| Step: 3
Training loss: 0.7062052121772495
Validation loss: 2.8020820877658577

Epoch: 5| Step: 4
Training loss: 0.9991545977962538
Validation loss: 2.8035396770317065

Epoch: 5| Step: 5
Training loss: 0.9091907996329354
Validation loss: 2.6825916801492555

Epoch: 5| Step: 6
Training loss: 1.5673848660179306
Validation loss: 2.7036685103188836

Epoch: 5| Step: 7
Training loss: 0.6929435665195023
Validation loss: 2.6820019290816624

Epoch: 5| Step: 8
Training loss: 0.7684041788354937
Validation loss: 2.7537912728045955

Epoch: 5| Step: 9
Training loss: 0.6499748390169677
Validation loss: 2.7132058835841453

Epoch: 5| Step: 10
Training loss: 0.5312468023764922
Validation loss: 2.831134803342803

Epoch: 5| Step: 11
Training loss: 0.9860909658412952
Validation loss: 2.857558967880781

Epoch: 214| Step: 0
Training loss: 0.9238347704529416
Validation loss: 2.871002801332621

Epoch: 5| Step: 1
Training loss: 0.9252825331288175
Validation loss: 2.7341465300524126

Epoch: 5| Step: 2
Training loss: 1.0182803727304668
Validation loss: 2.761583327624621

Epoch: 5| Step: 3
Training loss: 0.8663272543032537
Validation loss: 2.6972630579275796

Epoch: 5| Step: 4
Training loss: 0.9093054859557627
Validation loss: 2.6908685380519586

Epoch: 5| Step: 5
Training loss: 1.520862927431945
Validation loss: 2.7253468489606494

Epoch: 5| Step: 6
Training loss: 0.5643542245988784
Validation loss: 2.7198140703844524

Epoch: 5| Step: 7
Training loss: 0.5283227663106573
Validation loss: 2.748717175007693

Epoch: 5| Step: 8
Training loss: 0.5634142016408765
Validation loss: 2.799344604570186

Epoch: 5| Step: 9
Training loss: 0.7911872583375805
Validation loss: 2.718784554945196

Epoch: 5| Step: 10
Training loss: 0.4699606995942252
Validation loss: 2.730306767000712

Epoch: 5| Step: 11
Training loss: 0.19677747627045591
Validation loss: 2.76733568951779

Epoch: 215| Step: 0
Training loss: 0.7305047745414804
Validation loss: 2.6956344485926222

Epoch: 5| Step: 1
Training loss: 0.5014009221389166
Validation loss: 2.6527707632137405

Epoch: 5| Step: 2
Training loss: 0.9610724625751758
Validation loss: 2.763151564218365

Epoch: 5| Step: 3
Training loss: 0.8631852040436034
Validation loss: 2.7303170165186543

Epoch: 5| Step: 4
Training loss: 0.640006348161208
Validation loss: 2.669621638374554

Epoch: 5| Step: 5
Training loss: 0.5683526631906104
Validation loss: 2.7361722979398087

Epoch: 5| Step: 6
Training loss: 0.7641889377816645
Validation loss: 2.7968955616399414

Epoch: 5| Step: 7
Training loss: 1.0691083831441308
Validation loss: 2.802512938361541

Epoch: 5| Step: 8
Training loss: 1.406760483380852
Validation loss: 2.7941797045483066

Epoch: 5| Step: 9
Training loss: 0.4991260281272061
Validation loss: 2.777280739714648

Epoch: 5| Step: 10
Training loss: 0.6301588060027823
Validation loss: 2.8183976679910407

Epoch: 5| Step: 11
Training loss: 1.264301832856824
Validation loss: 2.738361069064185

Epoch: 216| Step: 0
Training loss: 1.094189255929868
Validation loss: 2.809611221526571

Epoch: 5| Step: 1
Training loss: 0.4305612696589781
Validation loss: 2.8209374775296143

Epoch: 5| Step: 2
Training loss: 0.5500396714208156
Validation loss: 2.6835006594071

Epoch: 5| Step: 3
Training loss: 0.9079460190300936
Validation loss: 2.767582855902563

Epoch: 5| Step: 4
Training loss: 0.6733557773223554
Validation loss: 2.7184185432579704

Epoch: 5| Step: 5
Training loss: 0.8091979786883917
Validation loss: 2.616971871522354

Epoch: 5| Step: 6
Training loss: 0.7945168327891465
Validation loss: 2.6343793838060257

Epoch: 5| Step: 7
Training loss: 0.6229037416407913
Validation loss: 2.639255973871549

Epoch: 5| Step: 8
Training loss: 0.8011214859329319
Validation loss: 2.7603249456654178

Epoch: 5| Step: 9
Training loss: 0.6598485873038491
Validation loss: 2.7679860207735496

Epoch: 5| Step: 10
Training loss: 1.4143384801150778
Validation loss: 2.787720012535324

Epoch: 5| Step: 11
Training loss: 0.8672420725104112
Validation loss: 2.7669907267113754

Epoch: 217| Step: 0
Training loss: 1.1574847870850717
Validation loss: 2.7575421511488356

Epoch: 5| Step: 1
Training loss: 0.44073886549912383
Validation loss: 2.7022050273278735

Epoch: 5| Step: 2
Training loss: 0.6357623212822667
Validation loss: 2.679373367774157

Epoch: 5| Step: 3
Training loss: 0.729248251210948
Validation loss: 2.663817166007183

Epoch: 5| Step: 4
Training loss: 0.6603821136709553
Validation loss: 2.688376481530196

Epoch: 5| Step: 5
Training loss: 0.7852207745660966
Validation loss: 2.6638331831962834

Epoch: 5| Step: 6
Training loss: 0.6618400408524115
Validation loss: 2.662038640299758

Epoch: 5| Step: 7
Training loss: 1.5509592717994762
Validation loss: 2.6230447389958957

Epoch: 5| Step: 8
Training loss: 0.6243449831860237
Validation loss: 2.6330361125100437

Epoch: 5| Step: 9
Training loss: 0.5761549607719907
Validation loss: 2.749244101991843

Epoch: 5| Step: 10
Training loss: 0.7865520615125648
Validation loss: 2.766653261286266

Epoch: 5| Step: 11
Training loss: 0.4680626279892137
Validation loss: 2.797896793481422

Epoch: 218| Step: 0
Training loss: 0.7250849147923041
Validation loss: 2.702771819751633

Epoch: 5| Step: 1
Training loss: 0.6187670570488548
Validation loss: 2.640661901483263

Epoch: 5| Step: 2
Training loss: 0.6849175197131719
Validation loss: 2.658866207283597

Epoch: 5| Step: 3
Training loss: 0.5905854065556678
Validation loss: 2.658074812416429

Epoch: 5| Step: 4
Training loss: 0.6831956412601795
Validation loss: 2.6848128102758797

Epoch: 5| Step: 5
Training loss: 1.112654285233644
Validation loss: 2.6230650915600733

Epoch: 5| Step: 6
Training loss: 1.0483155090037763
Validation loss: 2.6058546139911827

Epoch: 5| Step: 7
Training loss: 1.4308308683154571
Validation loss: 2.720051563506977

Epoch: 5| Step: 8
Training loss: 0.6320635283989972
Validation loss: 2.6899816048771945

Epoch: 5| Step: 9
Training loss: 0.6102419335138078
Validation loss: 2.7694039864796243

Epoch: 5| Step: 10
Training loss: 0.6877887509590543
Validation loss: 2.823532066738896

Epoch: 5| Step: 11
Training loss: 0.43722806721877155
Validation loss: 2.711590441840133

Epoch: 219| Step: 0
Training loss: 0.6392700007669805
Validation loss: 2.756968962680192

Epoch: 5| Step: 1
Training loss: 0.5949933435564597
Validation loss: 2.6639586434951217

Epoch: 5| Step: 2
Training loss: 0.7233964994935929
Validation loss: 2.594990420274809

Epoch: 5| Step: 3
Training loss: 1.5076959594595505
Validation loss: 2.6463377101371246

Epoch: 5| Step: 4
Training loss: 0.703314056411034
Validation loss: 2.7001551114079514

Epoch: 5| Step: 5
Training loss: 0.7020768936910846
Validation loss: 2.649469772711157

Epoch: 5| Step: 6
Training loss: 0.49637892929170396
Validation loss: 2.7023195856577606

Epoch: 5| Step: 7
Training loss: 0.5314325692115077
Validation loss: 2.7176091917491254

Epoch: 5| Step: 8
Training loss: 0.9803757946434822
Validation loss: 2.8496457734462233

Epoch: 5| Step: 9
Training loss: 0.5194530571627561
Validation loss: 2.798511477454075

Epoch: 5| Step: 10
Training loss: 0.9313771577082323
Validation loss: 2.7261150342703244

Epoch: 5| Step: 11
Training loss: 0.1223064656038522
Validation loss: 2.7309558053812193

Epoch: 220| Step: 0
Training loss: 0.8217278758599662
Validation loss: 2.694094300596603

Epoch: 5| Step: 1
Training loss: 0.5428139445319141
Validation loss: 2.7370254822407634

Epoch: 5| Step: 2
Training loss: 0.520818478054546
Validation loss: 2.6983164462864293

Epoch: 5| Step: 3
Training loss: 0.7585124293385841
Validation loss: 2.673327517778614

Epoch: 5| Step: 4
Training loss: 0.6111132454353206
Validation loss: 2.740430375818367

Epoch: 5| Step: 5
Training loss: 0.6301010345248285
Validation loss: 2.6905909624357736

Epoch: 5| Step: 6
Training loss: 0.47063757412287205
Validation loss: 2.7074797617929938

Epoch: 5| Step: 7
Training loss: 0.8566060627628578
Validation loss: 2.7744547165001654

Epoch: 5| Step: 8
Training loss: 0.7281947106647831
Validation loss: 2.8310551717388663

Epoch: 5| Step: 9
Training loss: 1.4425657823924498
Validation loss: 2.7539438989108396

Epoch: 5| Step: 10
Training loss: 0.9513414924924853
Validation loss: 2.628319522252521

Epoch: 5| Step: 11
Training loss: 0.4273599178735732
Validation loss: 2.7497342624294303

Epoch: 221| Step: 0
Training loss: 0.8005798458734037
Validation loss: 2.7329069047474244

Epoch: 5| Step: 1
Training loss: 0.6806893473981811
Validation loss: 2.6875319589888123

Epoch: 5| Step: 2
Training loss: 0.6840116694748809
Validation loss: 2.6126487415048336

Epoch: 5| Step: 3
Training loss: 1.4079259845748557
Validation loss: 2.7248338868901283

Epoch: 5| Step: 4
Training loss: 0.4875753717355446
Validation loss: 2.6645021607176727

Epoch: 5| Step: 5
Training loss: 0.6937968418700454
Validation loss: 2.7146946854684915

Epoch: 5| Step: 6
Training loss: 0.4972154596500496
Validation loss: 2.7772468410490805

Epoch: 5| Step: 7
Training loss: 0.6192013202363609
Validation loss: 2.7958915835611995

Epoch: 5| Step: 8
Training loss: 0.7217689634447453
Validation loss: 2.7215467004641893

Epoch: 5| Step: 9
Training loss: 0.9293675553332149
Validation loss: 2.7573927865234857

Epoch: 5| Step: 10
Training loss: 0.8381213601849039
Validation loss: 2.7260443332607087

Epoch: 5| Step: 11
Training loss: 0.663552166682536
Validation loss: 2.7140264547879354

Epoch: 222| Step: 0
Training loss: 0.5281600285938824
Validation loss: 2.643866984767889

Epoch: 5| Step: 1
Training loss: 0.7730132972244734
Validation loss: 2.7566940265686974

Epoch: 5| Step: 2
Training loss: 0.5481615192683528
Validation loss: 2.685738533348024

Epoch: 5| Step: 3
Training loss: 0.6298918730801221
Validation loss: 2.669777048383251

Epoch: 5| Step: 4
Training loss: 0.5474470416458139
Validation loss: 2.700030155661041

Epoch: 5| Step: 5
Training loss: 1.1070729400602508
Validation loss: 2.712802783925375

Epoch: 5| Step: 6
Training loss: 0.788247849330515
Validation loss: 2.750761046006323

Epoch: 5| Step: 7
Training loss: 0.8014616889840395
Validation loss: 2.77641424263764

Epoch: 5| Step: 8
Training loss: 0.6662011657195026
Validation loss: 2.792531478548457

Epoch: 5| Step: 9
Training loss: 0.9740371706193134
Validation loss: 2.766505078016739

Epoch: 5| Step: 10
Training loss: 1.5140445767218689
Validation loss: 2.7195197948523955

Epoch: 5| Step: 11
Training loss: 0.5138507720053586
Validation loss: 2.664930345836939

Epoch: 223| Step: 0
Training loss: 1.4226787936138585
Validation loss: 2.7573699632131707

Epoch: 5| Step: 1
Training loss: 0.5852718896010919
Validation loss: 2.7264449486809963

Epoch: 5| Step: 2
Training loss: 0.6958084266644108
Validation loss: 2.7042119150730546

Epoch: 5| Step: 3
Training loss: 0.8486889995064746
Validation loss: 2.7005089134509936

Epoch: 5| Step: 4
Training loss: 0.47537709375964077
Validation loss: 2.753542237088485

Epoch: 5| Step: 5
Training loss: 0.5610055143727887
Validation loss: 2.7151780066787734

Epoch: 5| Step: 6
Training loss: 0.975237321092085
Validation loss: 2.766332805168168

Epoch: 5| Step: 7
Training loss: 0.532901776572781
Validation loss: 2.7966119830813927

Epoch: 5| Step: 8
Training loss: 0.8965532529878608
Validation loss: 2.7455439299764373

Epoch: 5| Step: 9
Training loss: 0.5605603259662547
Validation loss: 2.668367559917162

Epoch: 5| Step: 10
Training loss: 0.5923179120521646
Validation loss: 2.7378704109303795

Epoch: 5| Step: 11
Training loss: 0.7246920391958843
Validation loss: 2.765594776800213

Epoch: 224| Step: 0
Training loss: 0.9326086553213278
Validation loss: 2.697453176730173

Epoch: 5| Step: 1
Training loss: 0.6664504703997156
Validation loss: 2.7254884165483473

Epoch: 5| Step: 2
Training loss: 0.5305998133240971
Validation loss: 2.6866793192663345

Epoch: 5| Step: 3
Training loss: 1.452778600607826
Validation loss: 2.6715002075922043

Epoch: 5| Step: 4
Training loss: 0.7614513221205722
Validation loss: 2.6528743555858787

Epoch: 5| Step: 5
Training loss: 0.6178422906974239
Validation loss: 2.7728380477750396

Epoch: 5| Step: 6
Training loss: 0.9367076704501068
Validation loss: 2.6863290986157375

Epoch: 5| Step: 7
Training loss: 0.7612494172092455
Validation loss: 2.6501407941267794

Epoch: 5| Step: 8
Training loss: 0.4477153998637206
Validation loss: 2.6197093637227464

Epoch: 5| Step: 9
Training loss: 0.5140708273355196
Validation loss: 2.7984864868727017

Epoch: 5| Step: 10
Training loss: 0.541990317951449
Validation loss: 2.7601725536346846

Epoch: 5| Step: 11
Training loss: 0.9201661451769277
Validation loss: 2.7458080361975665

Epoch: 225| Step: 0
Training loss: 0.6501194156479502
Validation loss: 2.7759828018522383

Epoch: 5| Step: 1
Training loss: 0.62700954670612
Validation loss: 2.7755579225755147

Epoch: 5| Step: 2
Training loss: 1.5622969686205663
Validation loss: 2.659987270162233

Epoch: 5| Step: 3
Training loss: 0.7710817855942558
Validation loss: 2.6666671795149153

Epoch: 5| Step: 4
Training loss: 0.9481025380822731
Validation loss: 2.630029054077531

Epoch: 5| Step: 5
Training loss: 0.7148426660414852
Validation loss: 2.6241977275533666

Epoch: 5| Step: 6
Training loss: 0.7701505695860253
Validation loss: 2.6704845640141945

Epoch: 5| Step: 7
Training loss: 0.5806197646431648
Validation loss: 2.7201594539552394

Epoch: 5| Step: 8
Training loss: 0.4561082208160196
Validation loss: 2.7073824362505117

Epoch: 5| Step: 9
Training loss: 0.7552660996717143
Validation loss: 2.689483391234339

Epoch: 5| Step: 10
Training loss: 0.5887966335156335
Validation loss: 2.664871137842303

Epoch: 5| Step: 11
Training loss: 0.40611358332885317
Validation loss: 2.6924182039503024

Epoch: 226| Step: 0
Training loss: 1.0628608763939755
Validation loss: 2.6917809242665722

Epoch: 5| Step: 1
Training loss: 0.5913416052375567
Validation loss: 2.7515585485397867

Epoch: 5| Step: 2
Training loss: 0.5909646102359261
Validation loss: 2.6480607484044327

Epoch: 5| Step: 3
Training loss: 0.4549812737740467
Validation loss: 2.7009147692695636

Epoch: 5| Step: 4
Training loss: 0.5093257657929817
Validation loss: 2.6609528516295584

Epoch: 5| Step: 5
Training loss: 0.5441703947074893
Validation loss: 2.6530416709954983

Epoch: 5| Step: 6
Training loss: 1.5155547607506177
Validation loss: 2.650801991918309

Epoch: 5| Step: 7
Training loss: 0.6761878449720932
Validation loss: 2.7193539631885497

Epoch: 5| Step: 8
Training loss: 0.6168041487319862
Validation loss: 2.7208483370376513

Epoch: 5| Step: 9
Training loss: 0.608920808402232
Validation loss: 2.655572124076597

Epoch: 5| Step: 10
Training loss: 0.5337454305180727
Validation loss: 2.7820424743928682

Epoch: 5| Step: 11
Training loss: 0.7345231495215621
Validation loss: 2.708966187973231

Epoch: 227| Step: 0
Training loss: 0.7764760067088992
Validation loss: 2.85733627639605

Epoch: 5| Step: 1
Training loss: 0.5172854765778871
Validation loss: 2.7285093408911356

Epoch: 5| Step: 2
Training loss: 0.49932629676004525
Validation loss: 2.7850984100998724

Epoch: 5| Step: 3
Training loss: 0.4720948408238843
Validation loss: 2.658439945207715

Epoch: 5| Step: 4
Training loss: 0.8563486738500162
Validation loss: 2.691529221809736

Epoch: 5| Step: 5
Training loss: 0.8597942370065201
Validation loss: 2.668284042442418

Epoch: 5| Step: 6
Training loss: 0.5170096388329665
Validation loss: 2.683645600507921

Epoch: 5| Step: 7
Training loss: 0.7489760084193245
Validation loss: 2.6551452489796477

Epoch: 5| Step: 8
Training loss: 0.6449406104136205
Validation loss: 2.783712382879638

Epoch: 5| Step: 9
Training loss: 0.631936727087759
Validation loss: 2.7374264321101975

Epoch: 5| Step: 10
Training loss: 1.387553476901116
Validation loss: 2.795804307183381

Epoch: 5| Step: 11
Training loss: 1.1124697756144113
Validation loss: 2.709023333954417

Epoch: 228| Step: 0
Training loss: 0.4960291512550122
Validation loss: 2.6823177904258078

Epoch: 5| Step: 1
Training loss: 0.5617672598190102
Validation loss: 2.7085681312214307

Epoch: 5| Step: 2
Training loss: 0.5824811080193876
Validation loss: 2.7559475955590065

Epoch: 5| Step: 3
Training loss: 0.6432645430212593
Validation loss: 2.74430504212434

Epoch: 5| Step: 4
Training loss: 1.5678815101793113
Validation loss: 2.679465958507938

Epoch: 5| Step: 5
Training loss: 0.9251425427073859
Validation loss: 2.7665111824566653

Epoch: 5| Step: 6
Training loss: 0.6450716007767134
Validation loss: 2.7794319990332577

Epoch: 5| Step: 7
Training loss: 0.5252971920617372
Validation loss: 2.6569701583585363

Epoch: 5| Step: 8
Training loss: 0.7630539757796663
Validation loss: 2.7097643238489946

Epoch: 5| Step: 9
Training loss: 0.7103593592495114
Validation loss: 2.873064564491168

Epoch: 5| Step: 10
Training loss: 0.5690320939765808
Validation loss: 2.8041033300263263

Epoch: 5| Step: 11
Training loss: 0.5238240081830153
Validation loss: 2.7995331278486995

Epoch: 229| Step: 0
Training loss: 0.6171343333848411
Validation loss: 2.7573832176889943

Epoch: 5| Step: 1
Training loss: 1.4623231079848962
Validation loss: 2.782528097822566

Epoch: 5| Step: 2
Training loss: 0.528727883672248
Validation loss: 2.7862424136965993

Epoch: 5| Step: 3
Training loss: 0.7634616181869333
Validation loss: 2.725235463973026

Epoch: 5| Step: 4
Training loss: 0.8741243272230826
Validation loss: 2.7027779431706223

Epoch: 5| Step: 5
Training loss: 0.9188122060048857
Validation loss: 2.618785135189755

Epoch: 5| Step: 6
Training loss: 0.8457483715613393
Validation loss: 2.666770887697599

Epoch: 5| Step: 7
Training loss: 0.6809301089007787
Validation loss: 2.6983609490358846

Epoch: 5| Step: 8
Training loss: 0.7990601069862479
Validation loss: 2.71398177150383

Epoch: 5| Step: 9
Training loss: 0.5605342212272227
Validation loss: 2.5547799959849136

Epoch: 5| Step: 10
Training loss: 0.8003238395057386
Validation loss: 2.7760855413026997

Epoch: 5| Step: 11
Training loss: 0.36714626648885335
Validation loss: 2.7526312724174042

Epoch: 230| Step: 0
Training loss: 0.6562149855945673
Validation loss: 2.8021535167389704

Epoch: 5| Step: 1
Training loss: 1.4880904428313968
Validation loss: 2.70068188698682

Epoch: 5| Step: 2
Training loss: 0.5538403664214209
Validation loss: 2.679096772205223

Epoch: 5| Step: 3
Training loss: 0.5396261447384488
Validation loss: 2.765106662661217

Epoch: 5| Step: 4
Training loss: 0.6615482529523787
Validation loss: 2.6989394216833116

Epoch: 5| Step: 5
Training loss: 0.6296455113726167
Validation loss: 2.662816204553009

Epoch: 5| Step: 6
Training loss: 0.803676636938459
Validation loss: 2.735882421694733

Epoch: 5| Step: 7
Training loss: 0.815453114430038
Validation loss: 2.6087440177058046

Epoch: 5| Step: 8
Training loss: 0.61951233208384
Validation loss: 2.6718336589210128

Epoch: 5| Step: 9
Training loss: 0.8233309117627794
Validation loss: 2.689227969944874

Epoch: 5| Step: 10
Training loss: 0.8515286570132283
Validation loss: 2.7685176068692767

Epoch: 5| Step: 11
Training loss: 0.8412485128902538
Validation loss: 2.7554758491276847

Epoch: 231| Step: 0
Training loss: 0.7933356277315102
Validation loss: 2.67415272330951

Epoch: 5| Step: 1
Training loss: 0.6365020945020856
Validation loss: 2.685089223996494

Epoch: 5| Step: 2
Training loss: 1.020811833265532
Validation loss: 2.6949631469179027

Epoch: 5| Step: 3
Training loss: 0.8694446160685648
Validation loss: 2.6255235339146243

Epoch: 5| Step: 4
Training loss: 0.8203266324233706
Validation loss: 2.633943018823615

Epoch: 5| Step: 5
Training loss: 0.4796920639467107
Validation loss: 2.713513084353833

Epoch: 5| Step: 6
Training loss: 1.4090249550953386
Validation loss: 2.6680727184883692

Epoch: 5| Step: 7
Training loss: 0.6009696417042142
Validation loss: 2.7736010919598066

Epoch: 5| Step: 8
Training loss: 0.7111199951693118
Validation loss: 2.779019911855207

Epoch: 5| Step: 9
Training loss: 0.7043436932989631
Validation loss: 2.8740528557555347

Epoch: 5| Step: 10
Training loss: 0.7022543709205737
Validation loss: 2.7767923579459968

Epoch: 5| Step: 11
Training loss: 0.7159410403500042
Validation loss: 2.659136176526762

Epoch: 232| Step: 0
Training loss: 0.805603025031637
Validation loss: 2.6576223343879968

Epoch: 5| Step: 1
Training loss: 0.9557182803387179
Validation loss: 2.7010827958908097

Epoch: 5| Step: 2
Training loss: 0.7695001896045592
Validation loss: 2.654588991567385

Epoch: 5| Step: 3
Training loss: 0.7661453736332168
Validation loss: 2.6636690835583368

Epoch: 5| Step: 4
Training loss: 1.4216787181818975
Validation loss: 2.685851670973013

Epoch: 5| Step: 5
Training loss: 0.7980539165677244
Validation loss: 2.7334146775134274

Epoch: 5| Step: 6
Training loss: 0.6115450733101452
Validation loss: 2.8380437198378137

Epoch: 5| Step: 7
Training loss: 0.8336013521886391
Validation loss: 2.721645609141912

Epoch: 5| Step: 8
Training loss: 0.7511719845014424
Validation loss: 2.704010303960045

Epoch: 5| Step: 9
Training loss: 0.9337838270706449
Validation loss: 2.7280751634890996

Epoch: 5| Step: 10
Training loss: 0.5685029782441166
Validation loss: 2.697670790368621

Epoch: 5| Step: 11
Training loss: 0.3573449891156062
Validation loss: 2.6574360013608103

Epoch: 233| Step: 0
Training loss: 0.8823882239664393
Validation loss: 2.715315666622739

Epoch: 5| Step: 1
Training loss: 0.6938568694478152
Validation loss: 2.7235313041904425

Epoch: 5| Step: 2
Training loss: 1.436753618274631
Validation loss: 2.772485197023156

Epoch: 5| Step: 3
Training loss: 0.650446159122612
Validation loss: 2.7574616155837774

Epoch: 5| Step: 4
Training loss: 0.5282397252810849
Validation loss: 2.753721980429846

Epoch: 5| Step: 5
Training loss: 0.720629928717586
Validation loss: 2.8184092819719275

Epoch: 5| Step: 6
Training loss: 0.531064674364909
Validation loss: 2.7595633117427147

Epoch: 5| Step: 7
Training loss: 0.8750075612422673
Validation loss: 2.7901436805360085

Epoch: 5| Step: 8
Training loss: 0.5854569308144442
Validation loss: 2.7509559212586097

Epoch: 5| Step: 9
Training loss: 0.6318468095884672
Validation loss: 2.6471465423745473

Epoch: 5| Step: 10
Training loss: 0.7464566371840607
Validation loss: 2.640179432854488

Epoch: 5| Step: 11
Training loss: 1.5875567358496596
Validation loss: 2.6879191330536862

Epoch: 234| Step: 0
Training loss: 0.5136834785108148
Validation loss: 2.6559717593601895

Epoch: 5| Step: 1
Training loss: 0.46050712731009724
Validation loss: 2.707240277798616

Epoch: 5| Step: 2
Training loss: 0.6673723424861088
Validation loss: 2.8172417052758423

Epoch: 5| Step: 3
Training loss: 1.48208811424127
Validation loss: 2.6994372517263847

Epoch: 5| Step: 4
Training loss: 0.731971500527224
Validation loss: 2.7796299123418566

Epoch: 5| Step: 5
Training loss: 0.9132230767877036
Validation loss: 2.774129353225811

Epoch: 5| Step: 6
Training loss: 0.5031733839096929
Validation loss: 2.719925622601009

Epoch: 5| Step: 7
Training loss: 0.5806685759634883
Validation loss: 2.6728814480771317

Epoch: 5| Step: 8
Training loss: 0.44608619469759975
Validation loss: 2.737193130395624

Epoch: 5| Step: 9
Training loss: 0.6665030119613964
Validation loss: 2.7254727070240294

Epoch: 5| Step: 10
Training loss: 1.0222007908739865
Validation loss: 2.673217008837278

Epoch: 5| Step: 11
Training loss: 0.7174473443464614
Validation loss: 2.6855933944834547

Epoch: 235| Step: 0
Training loss: 0.9027646226821084
Validation loss: 2.7762419871089103

Epoch: 5| Step: 1
Training loss: 0.7244258349982439
Validation loss: 2.677620601300627

Epoch: 5| Step: 2
Training loss: 0.5732195458172946
Validation loss: 2.742201421979466

Epoch: 5| Step: 3
Training loss: 0.693177685640015
Validation loss: 2.7283701001122993

Epoch: 5| Step: 4
Training loss: 0.5427334227470543
Validation loss: 2.7240992315745807

Epoch: 5| Step: 5
Training loss: 0.5273027757338286
Validation loss: 2.700532905210749

Epoch: 5| Step: 6
Training loss: 1.3698462655483927
Validation loss: 2.7011870234155007

Epoch: 5| Step: 7
Training loss: 0.5582773339480918
Validation loss: 2.7186129086010826

Epoch: 5| Step: 8
Training loss: 0.5356629471929647
Validation loss: 2.6927425645513035

Epoch: 5| Step: 9
Training loss: 0.6773833099393325
Validation loss: 2.7103468831486426

Epoch: 5| Step: 10
Training loss: 0.49464758398070807
Validation loss: 2.8126303536618575

Epoch: 5| Step: 11
Training loss: 0.5799899564070753
Validation loss: 2.739525063092033

Epoch: 236| Step: 0
Training loss: 1.477343640259366
Validation loss: 2.7660660436939555

Epoch: 5| Step: 1
Training loss: 0.6537374809627354
Validation loss: 2.7132688496243413

Epoch: 5| Step: 2
Training loss: 0.49767391227388297
Validation loss: 2.7334033002466014

Epoch: 5| Step: 3
Training loss: 0.4269747673615207
Validation loss: 2.824205580557988

Epoch: 5| Step: 4
Training loss: 0.9643805005651557
Validation loss: 2.7757498687393207

Epoch: 5| Step: 5
Training loss: 0.6026848071144086
Validation loss: 2.768710364035787

Epoch: 5| Step: 6
Training loss: 0.5124564931592318
Validation loss: 2.74724731525995

Epoch: 5| Step: 7
Training loss: 0.6014478995415019
Validation loss: 2.734980300028054

Epoch: 5| Step: 8
Training loss: 0.5790054730467975
Validation loss: 2.740262793395633

Epoch: 5| Step: 9
Training loss: 0.40523293534084365
Validation loss: 2.8175206336343668

Epoch: 5| Step: 10
Training loss: 0.5837778855469791
Validation loss: 2.6838570085763767

Epoch: 5| Step: 11
Training loss: 0.4688768850892222
Validation loss: 2.738268663102633

Epoch: 237| Step: 0
Training loss: 0.5410515122612742
Validation loss: 2.747486678274276

Epoch: 5| Step: 1
Training loss: 0.4719094611209529
Validation loss: 2.7599758419992915

Epoch: 5| Step: 2
Training loss: 0.5789202041076777
Validation loss: 2.816633784061746

Epoch: 5| Step: 3
Training loss: 0.550948043350192
Validation loss: 2.7014631370391307

Epoch: 5| Step: 4
Training loss: 0.6984799707117403
Validation loss: 2.7351415522439346

Epoch: 5| Step: 5
Training loss: 0.9233572729796702
Validation loss: 2.690131211614172

Epoch: 5| Step: 6
Training loss: 0.4794833304836099
Validation loss: 2.7644768395187644

Epoch: 5| Step: 7
Training loss: 0.5420109651079266
Validation loss: 2.648619395173464

Epoch: 5| Step: 8
Training loss: 1.4228118492977901
Validation loss: 2.633441336797111

Epoch: 5| Step: 9
Training loss: 0.5132777221186849
Validation loss: 2.685029877807803

Epoch: 5| Step: 10
Training loss: 0.3106912241443749
Validation loss: 2.786539257811512

Epoch: 5| Step: 11
Training loss: 0.6330645965652932
Validation loss: 2.7382655231715316

Epoch: 238| Step: 0
Training loss: 0.5007839315881212
Validation loss: 2.6649896233412105

Epoch: 5| Step: 1
Training loss: 0.9456101571561423
Validation loss: 2.721746036235013

Epoch: 5| Step: 2
Training loss: 1.4599375847317089
Validation loss: 2.7680382410037363

Epoch: 5| Step: 3
Training loss: 0.47379974884076465
Validation loss: 2.754347648147215

Epoch: 5| Step: 4
Training loss: 0.6224325613466942
Validation loss: 2.7640819483465098

Epoch: 5| Step: 5
Training loss: 0.6661840768374159
Validation loss: 2.7597233795366662

Epoch: 5| Step: 6
Training loss: 0.5744142783332219
Validation loss: 2.7497420551240648

Epoch: 5| Step: 7
Training loss: 0.5429484686048189
Validation loss: 2.654544570814283

Epoch: 5| Step: 8
Training loss: 0.4246456506248348
Validation loss: 2.666487949810009

Epoch: 5| Step: 9
Training loss: 0.5840747469888061
Validation loss: 2.6346514323387105

Epoch: 5| Step: 10
Training loss: 0.4261123874450533
Validation loss: 2.7198357387250955

Epoch: 5| Step: 11
Training loss: 0.8433999642397226
Validation loss: 2.7467482443919895

Epoch: 239| Step: 0
Training loss: 0.472536765514996
Validation loss: 2.7434515978345972

Epoch: 5| Step: 1
Training loss: 0.6006019155966551
Validation loss: 2.782682624911955

Epoch: 5| Step: 2
Training loss: 0.748875649406242
Validation loss: 2.7722528605072974

Epoch: 5| Step: 3
Training loss: 0.6632581888779647
Validation loss: 2.77602144857825

Epoch: 5| Step: 4
Training loss: 0.6057763087612528
Validation loss: 2.710860145923687

Epoch: 5| Step: 5
Training loss: 0.5709633966762543
Validation loss: 2.6028918859141736

Epoch: 5| Step: 6
Training loss: 0.7025465599256013
Validation loss: 2.6935865469166735

Epoch: 5| Step: 7
Training loss: 1.5048809905539344
Validation loss: 2.608472009228461

Epoch: 5| Step: 8
Training loss: 1.0000474441717664
Validation loss: 2.614902721264713

Epoch: 5| Step: 9
Training loss: 0.5337791824403509
Validation loss: 2.657979185456773

Epoch: 5| Step: 10
Training loss: 0.4284131312656958
Validation loss: 2.7559041272627183

Epoch: 5| Step: 11
Training loss: 0.7042170203750323
Validation loss: 2.7427999422967275

Epoch: 240| Step: 0
Training loss: 0.8686094911414701
Validation loss: 2.690963457701708

Epoch: 5| Step: 1
Training loss: 1.3752206711990274
Validation loss: 2.7828050473724018

Epoch: 5| Step: 2
Training loss: 0.8286685599218251
Validation loss: 2.8354708144833345

Epoch: 5| Step: 3
Training loss: 0.6415863964314722
Validation loss: 2.6647311925439388

Epoch: 5| Step: 4
Training loss: 0.46827772508935883
Validation loss: 2.6549095567617043

Epoch: 5| Step: 5
Training loss: 0.6954212960839007
Validation loss: 2.5975226193429286

Epoch: 5| Step: 6
Training loss: 0.932153588553189
Validation loss: 2.652371207438295

Epoch: 5| Step: 7
Training loss: 0.6068711068355565
Validation loss: 2.6025790003323896

Epoch: 5| Step: 8
Training loss: 0.4480778511334654
Validation loss: 2.65835771150881

Epoch: 5| Step: 9
Training loss: 0.5565046445493367
Validation loss: 2.6668529793106055

Epoch: 5| Step: 10
Training loss: 0.4992418800213251
Validation loss: 2.7392431375492374

Epoch: 5| Step: 11
Training loss: 0.7460151351334264
Validation loss: 2.6985603114610752

Epoch: 241| Step: 0
Training loss: 1.0334122848087672
Validation loss: 2.7931173360643613

Epoch: 5| Step: 1
Training loss: 0.8383207484287227
Validation loss: 2.806822726421868

Epoch: 5| Step: 2
Training loss: 0.598531219673624
Validation loss: 2.7917406952470247

Epoch: 5| Step: 3
Training loss: 0.6276675043291258
Validation loss: 2.6577503230712165

Epoch: 5| Step: 4
Training loss: 0.6910680169858822
Validation loss: 2.702976898957878

Epoch: 5| Step: 5
Training loss: 0.6088843693569349
Validation loss: 2.5608730704888263

Epoch: 5| Step: 6
Training loss: 0.5308638178826828
Validation loss: 2.6631858293100263

Epoch: 5| Step: 7
Training loss: 1.4483837590952338
Validation loss: 2.615386593799576

Epoch: 5| Step: 8
Training loss: 0.5408291271479153
Validation loss: 2.6591284881567963

Epoch: 5| Step: 9
Training loss: 0.5482892142995028
Validation loss: 2.6706568634860597

Epoch: 5| Step: 10
Training loss: 0.6417987119958352
Validation loss: 2.6704439379741496

Epoch: 5| Step: 11
Training loss: 0.6484301003642884
Validation loss: 2.7059765183460707

Epoch: 242| Step: 0
Training loss: 0.637132521909933
Validation loss: 2.6975037480936064

Epoch: 5| Step: 1
Training loss: 1.3315037552669227
Validation loss: 2.747557621150039

Epoch: 5| Step: 2
Training loss: 0.6085313189587838
Validation loss: 2.6893298883397923

Epoch: 5| Step: 3
Training loss: 0.6149252463088287
Validation loss: 2.7063718545891984

Epoch: 5| Step: 4
Training loss: 0.6025801633792696
Validation loss: 2.680307325889133

Epoch: 5| Step: 5
Training loss: 0.6028143997122898
Validation loss: 2.709167987639724

Epoch: 5| Step: 6
Training loss: 0.944196373173932
Validation loss: 2.718226766113188

Epoch: 5| Step: 7
Training loss: 0.5805634545843937
Validation loss: 2.7008798091502695

Epoch: 5| Step: 8
Training loss: 0.5105812008678661
Validation loss: 2.7017036552611278

Epoch: 5| Step: 9
Training loss: 0.62507643232294
Validation loss: 2.7420672746261614

Epoch: 5| Step: 10
Training loss: 0.43210597435401593
Validation loss: 2.6392515662469505

Epoch: 5| Step: 11
Training loss: 0.6371622705633067
Validation loss: 2.667635739098539

Epoch: 243| Step: 0
Training loss: 0.4628601064158231
Validation loss: 2.6773522807195844

Epoch: 5| Step: 1
Training loss: 0.363234527208473
Validation loss: 2.7092647686995464

Epoch: 5| Step: 2
Training loss: 0.8043123500348665
Validation loss: 2.7729195303631067

Epoch: 5| Step: 3
Training loss: 0.42733552705151606
Validation loss: 2.7174226308516567

Epoch: 5| Step: 4
Training loss: 0.7952471168487388
Validation loss: 2.7962735095831333

Epoch: 5| Step: 5
Training loss: 0.5699908250773009
Validation loss: 2.7333652121344114

Epoch: 5| Step: 6
Training loss: 0.427973188507473
Validation loss: 2.761389558516789

Epoch: 5| Step: 7
Training loss: 0.5151912714560872
Validation loss: 2.7512297589962658

Epoch: 5| Step: 8
Training loss: 1.408032918900152
Validation loss: 2.7725430474523933

Epoch: 5| Step: 9
Training loss: 0.7441091055214635
Validation loss: 2.8455075013682922

Epoch: 5| Step: 10
Training loss: 0.7296374073029094
Validation loss: 2.773839124514412

Epoch: 5| Step: 11
Training loss: 0.3040210698199868
Validation loss: 2.800239326120681

Epoch: 244| Step: 0
Training loss: 0.4066924107068814
Validation loss: 2.694130230035907

Epoch: 5| Step: 1
Training loss: 0.528883093097374
Validation loss: 2.632740414063683

Epoch: 5| Step: 2
Training loss: 0.5955851954061904
Validation loss: 2.67886899824136

Epoch: 5| Step: 3
Training loss: 0.6415236380764396
Validation loss: 2.7337631849015462

Epoch: 5| Step: 4
Training loss: 1.2833797153331659
Validation loss: 2.686634615621367

Epoch: 5| Step: 5
Training loss: 0.5386177384335654
Validation loss: 2.7329036059859675

Epoch: 5| Step: 6
Training loss: 0.4465757988937605
Validation loss: 2.7321625578075346

Epoch: 5| Step: 7
Training loss: 0.46480027965235216
Validation loss: 2.8001783175113575

Epoch: 5| Step: 8
Training loss: 0.9091706731330946
Validation loss: 2.698258092379834

Epoch: 5| Step: 9
Training loss: 0.4724323120528763
Validation loss: 2.768919891185477

Epoch: 5| Step: 10
Training loss: 0.6632000202812243
Validation loss: 2.6977200246210886

Epoch: 5| Step: 11
Training loss: 0.36115048139889416
Validation loss: 2.6655215540316015

Epoch: 245| Step: 0
Training loss: 0.5478979896823926
Validation loss: 2.72957609226239

Epoch: 5| Step: 1
Training loss: 0.41320917983008637
Validation loss: 2.696988344960105

Epoch: 5| Step: 2
Training loss: 0.5283067176183801
Validation loss: 2.6875803218341816

Epoch: 5| Step: 3
Training loss: 0.6806585018855765
Validation loss: 2.6904296505761303

Epoch: 5| Step: 4
Training loss: 0.48256545304787
Validation loss: 2.723113427985755

Epoch: 5| Step: 5
Training loss: 1.458212529583087
Validation loss: 2.7886969347250545

Epoch: 5| Step: 6
Training loss: 0.7602679398943595
Validation loss: 2.7540352901590746

Epoch: 5| Step: 7
Training loss: 0.431080191116611
Validation loss: 2.7425964065085164

Epoch: 5| Step: 8
Training loss: 0.7069645423401413
Validation loss: 2.6874427197879998

Epoch: 5| Step: 9
Training loss: 0.6589734242178926
Validation loss: 2.6690890825623703

Epoch: 5| Step: 10
Training loss: 0.45124606558756786
Validation loss: 2.7168536350547203

Epoch: 5| Step: 11
Training loss: 0.3817197422884435
Validation loss: 2.6408541089046524

Epoch: 246| Step: 0
Training loss: 0.9000490413655792
Validation loss: 2.6288386124123555

Epoch: 5| Step: 1
Training loss: 0.6161754616078817
Validation loss: 2.711140792655756

Epoch: 5| Step: 2
Training loss: 0.5121046169359673
Validation loss: 2.706128592407167

Epoch: 5| Step: 3
Training loss: 0.8413261283335769
Validation loss: 2.7362510167470417

Epoch: 5| Step: 4
Training loss: 0.3848790422768096
Validation loss: 2.789004416978479

Epoch: 5| Step: 5
Training loss: 0.465203106243369
Validation loss: 2.8621831456190936

Epoch: 5| Step: 6
Training loss: 0.5156478876756222
Validation loss: 2.7131769419650364

Epoch: 5| Step: 7
Training loss: 0.40433758148339716
Validation loss: 2.7532462156516795

Epoch: 5| Step: 8
Training loss: 0.47111882258510196
Validation loss: 2.7483495723155165

Epoch: 5| Step: 9
Training loss: 0.6888950455832273
Validation loss: 2.6567323022434044

Epoch: 5| Step: 10
Training loss: 1.3522519684867333
Validation loss: 2.682852608009335

Epoch: 5| Step: 11
Training loss: 0.6468256484661863
Validation loss: 2.724032050327211

Epoch: 247| Step: 0
Training loss: 0.4867899590045198
Validation loss: 2.7985984706251377

Epoch: 5| Step: 1
Training loss: 0.6426543216690304
Validation loss: 2.7688288548982367

Epoch: 5| Step: 2
Training loss: 0.5064801269993301
Validation loss: 2.737481839048625

Epoch: 5| Step: 3
Training loss: 0.5265642692468278
Validation loss: 2.7728285286583874

Epoch: 5| Step: 4
Training loss: 0.6021152532975355
Validation loss: 2.6388098461599503

Epoch: 5| Step: 5
Training loss: 0.7143664408093428
Validation loss: 2.7454278716507448

Epoch: 5| Step: 6
Training loss: 0.6872913304012325
Validation loss: 2.7051157263610985

Epoch: 5| Step: 7
Training loss: 0.6939745685606422
Validation loss: 2.7014798871174825

Epoch: 5| Step: 8
Training loss: 0.4791827786542526
Validation loss: 2.6992633077989376

Epoch: 5| Step: 9
Training loss: 1.3283625670741712
Validation loss: 2.7658758893770923

Epoch: 5| Step: 10
Training loss: 0.696924975874068
Validation loss: 2.7832325359374392

Epoch: 5| Step: 11
Training loss: 0.3781546187031874
Validation loss: 2.847460746595053

Epoch: 248| Step: 0
Training loss: 0.5328136600694305
Validation loss: 2.7946655845472406

Epoch: 5| Step: 1
Training loss: 0.49051544217543813
Validation loss: 2.6953623559735975

Epoch: 5| Step: 2
Training loss: 0.6353142582859189
Validation loss: 2.7747567025773403

Epoch: 5| Step: 3
Training loss: 0.5020936999167523
Validation loss: 2.741306819219643

Epoch: 5| Step: 4
Training loss: 0.32151946181099916
Validation loss: 2.6718593767984653

Epoch: 5| Step: 5
Training loss: 0.900562989789099
Validation loss: 2.7145751015183848

Epoch: 5| Step: 6
Training loss: 1.3547729993192394
Validation loss: 2.7395092309906612

Epoch: 5| Step: 7
Training loss: 0.41544065904858135
Validation loss: 2.7302734421572836

Epoch: 5| Step: 8
Training loss: 0.3742836826191583
Validation loss: 2.7056495439393276

Epoch: 5| Step: 9
Training loss: 0.42839789638100756
Validation loss: 2.76914114776074

Epoch: 5| Step: 10
Training loss: 0.5579189946859884
Validation loss: 2.7503440146859686

Epoch: 5| Step: 11
Training loss: 0.19325680372282755
Validation loss: 2.745134089185029

Epoch: 249| Step: 0
Training loss: 0.3240508253630298
Validation loss: 2.721796784005251

Epoch: 5| Step: 1
Training loss: 0.5100667948084527
Validation loss: 2.723012126503349

Epoch: 5| Step: 2
Training loss: 0.49322216333763375
Validation loss: 2.7573674124668326

Epoch: 5| Step: 3
Training loss: 0.5296324338393507
Validation loss: 2.731533597833922

Epoch: 5| Step: 4
Training loss: 0.3771318199886369
Validation loss: 2.6942758934867728

Epoch: 5| Step: 5
Training loss: 0.5705318812824239
Validation loss: 2.6644742578506264

Epoch: 5| Step: 6
Training loss: 0.4013961261795651
Validation loss: 2.6704621176547745

Epoch: 5| Step: 7
Training loss: 0.535840953883458
Validation loss: 2.691476393746655

Epoch: 5| Step: 8
Training loss: 0.6025563736813763
Validation loss: 2.7141740078036714

Epoch: 5| Step: 9
Training loss: 0.7847728647265529
Validation loss: 2.80000837898136

Epoch: 5| Step: 10
Training loss: 0.7629299608784502
Validation loss: 2.73431766268242

Epoch: 5| Step: 11
Training loss: 2.8306817568704536
Validation loss: 2.7706353856609254

Epoch: 250| Step: 0
Training loss: 0.6373013130680852
Validation loss: 2.729317880522999

Epoch: 5| Step: 1
Training loss: 0.5411430511794718
Validation loss: 2.8240595729179954

Epoch: 5| Step: 2
Training loss: 0.7927434065516622
Validation loss: 2.7729320853616946

Epoch: 5| Step: 3
Training loss: 0.5665241250341257
Validation loss: 2.7161871095314725

Epoch: 5| Step: 4
Training loss: 0.8579466306676153
Validation loss: 2.7277523348466186

Epoch: 5| Step: 5
Training loss: 0.47844975855077054
Validation loss: 2.7374696422153577

Epoch: 5| Step: 6
Training loss: 0.6319561332511253
Validation loss: 2.7297991912648034

Epoch: 5| Step: 7
Training loss: 0.6390446965878526
Validation loss: 2.730817737024553

Epoch: 5| Step: 8
Training loss: 1.3172657591535364
Validation loss: 2.7056117076669164

Epoch: 5| Step: 9
Training loss: 0.5656479330313909
Validation loss: 2.7427126299231275

Epoch: 5| Step: 10
Training loss: 0.5107001146890434
Validation loss: 2.7082900679629325

Epoch: 5| Step: 11
Training loss: 0.28966482660146653
Validation loss: 2.745208803844467

Epoch: 251| Step: 0
Training loss: 0.6513847566033871
Validation loss: 2.7156311247258684

Epoch: 5| Step: 1
Training loss: 0.6328769933543721
Validation loss: 2.6621528989499588

Epoch: 5| Step: 2
Training loss: 0.5375073155193626
Validation loss: 2.624283302953942

Epoch: 5| Step: 3
Training loss: 0.5178433872143591
Validation loss: 2.7389225265562187

Epoch: 5| Step: 4
Training loss: 0.29721585582711396
Validation loss: 2.7641445407225316

Epoch: 5| Step: 5
Training loss: 0.37136678188274136
Validation loss: 2.752676362264103

Epoch: 5| Step: 6
Training loss: 0.7909086932208218
Validation loss: 2.6928984810389576

Epoch: 5| Step: 7
Training loss: 0.4156875928913954
Validation loss: 2.6873053435868166

Epoch: 5| Step: 8
Training loss: 0.6625848373938481
Validation loss: 2.777942308613004

Epoch: 5| Step: 9
Training loss: 0.48925861960095135
Validation loss: 2.7487251585178614

Epoch: 5| Step: 10
Training loss: 0.6791313351371315
Validation loss: 2.7152374841969253

Epoch: 5| Step: 11
Training loss: 2.7557799546161448
Validation loss: 2.682982307085697

Epoch: 252| Step: 0
Training loss: 0.8168138280611525
Validation loss: 2.829882316405892

Epoch: 5| Step: 1
Training loss: 0.8653487566911618
Validation loss: 2.9046165805125574

Epoch: 5| Step: 2
Training loss: 1.2876701464769345
Validation loss: 2.9002526281475505

Epoch: 5| Step: 3
Training loss: 0.5802717560005798
Validation loss: 2.7791358649125923

Epoch: 5| Step: 4
Training loss: 0.7195068189551008
Validation loss: 2.7255743872300857

Epoch: 5| Step: 5
Training loss: 0.46905172491944847
Validation loss: 2.7052481330486997

Epoch: 5| Step: 6
Training loss: 0.7601136339715118
Validation loss: 2.665765193965908

Epoch: 5| Step: 7
Training loss: 0.8748167731678178
Validation loss: 2.611392141892285

Epoch: 5| Step: 8
Training loss: 0.8629619991957753
Validation loss: 2.5974492040739596

Epoch: 5| Step: 9
Training loss: 0.6929093310697487
Validation loss: 2.6543119466137113

Epoch: 5| Step: 10
Training loss: 0.5732678435268995
Validation loss: 2.7418360000328246

Epoch: 5| Step: 11
Training loss: 0.5072778675100759
Validation loss: 2.8000239683442363

Epoch: 253| Step: 0
Training loss: 0.9381570103296842
Validation loss: 2.9232673591431766

Epoch: 5| Step: 1
Training loss: 0.5411495772799184
Validation loss: 2.830113707556326

Epoch: 5| Step: 2
Training loss: 0.5171517109084778
Validation loss: 2.6715764460785496

Epoch: 5| Step: 3
Training loss: 0.7905306989800053
Validation loss: 2.7458559189206686

Epoch: 5| Step: 4
Training loss: 0.626323038703638
Validation loss: 2.6567473712586387

Epoch: 5| Step: 5
Training loss: 1.3409442885970897
Validation loss: 2.7300685904052506

Epoch: 5| Step: 6
Training loss: 0.6677006412088818
Validation loss: 2.7638881675095206

Epoch: 5| Step: 7
Training loss: 0.5012562586329422
Validation loss: 2.660373486552051

Epoch: 5| Step: 8
Training loss: 0.6129499864976083
Validation loss: 2.770121688568361

Epoch: 5| Step: 9
Training loss: 0.5299937316685797
Validation loss: 2.823870080272178

Epoch: 5| Step: 10
Training loss: 0.4802936296845116
Validation loss: 2.834249806960116

Epoch: 5| Step: 11
Training loss: 0.5789455570359161
Validation loss: 2.777222311921256

Epoch: 254| Step: 0
Training loss: 0.4741789667576718
Validation loss: 2.6782058330460736

Epoch: 5| Step: 1
Training loss: 0.7624902583891392
Validation loss: 2.7236367188347357

Epoch: 5| Step: 2
Training loss: 0.5948689107180449
Validation loss: 2.6844679747153983

Epoch: 5| Step: 3
Training loss: 0.8459718202492461
Validation loss: 2.6743545924180183

Epoch: 5| Step: 4
Training loss: 0.3114574087356741
Validation loss: 2.7365542782819037

Epoch: 5| Step: 5
Training loss: 0.5620952315469776
Validation loss: 2.7642479681395273

Epoch: 5| Step: 6
Training loss: 1.2538502523212138
Validation loss: 2.7791705126261563

Epoch: 5| Step: 7
Training loss: 0.6420139746571052
Validation loss: 2.7884719893127277

Epoch: 5| Step: 8
Training loss: 0.5180658309890185
Validation loss: 2.776204361481066

Epoch: 5| Step: 9
Training loss: 0.36119161553124896
Validation loss: 2.74802800117596

Epoch: 5| Step: 10
Training loss: 0.5338283408516394
Validation loss: 2.6795074506203926

Epoch: 5| Step: 11
Training loss: 0.2922839744944186
Validation loss: 2.705256791991154

Epoch: 255| Step: 0
Training loss: 0.4723023437411559
Validation loss: 2.658819612483391

Epoch: 5| Step: 1
Training loss: 0.6079797666596155
Validation loss: 2.732935492029116

Epoch: 5| Step: 2
Training loss: 0.5313010752191906
Validation loss: 2.631425762120405

Epoch: 5| Step: 3
Training loss: 0.5393636940117063
Validation loss: 2.68006880913836

Epoch: 5| Step: 4
Training loss: 0.40167747810792637
Validation loss: 2.628272077865203

Epoch: 5| Step: 5
Training loss: 0.5454736192847057
Validation loss: 2.7625571654951284

Epoch: 5| Step: 6
Training loss: 0.9806127860364422
Validation loss: 2.693344023957926

Epoch: 5| Step: 7
Training loss: 1.2083083128256997
Validation loss: 2.7533943620384496

Epoch: 5| Step: 8
Training loss: 0.5424185235943141
Validation loss: 2.6757066999385164

Epoch: 5| Step: 9
Training loss: 0.5854581779704386
Validation loss: 2.7188710225964656

Epoch: 5| Step: 10
Training loss: 0.44910207145338904
Validation loss: 2.776493119299806

Epoch: 5| Step: 11
Training loss: 0.35027591737201375
Validation loss: 2.705844048174465

Epoch: 256| Step: 0
Training loss: 0.49872501057330276
Validation loss: 2.678523822126733

Epoch: 5| Step: 1
Training loss: 0.4933536882593779
Validation loss: 2.7142109963702303

Epoch: 5| Step: 2
Training loss: 0.40613018616581775
Validation loss: 2.7182697515070333

Epoch: 5| Step: 3
Training loss: 0.48217594194682667
Validation loss: 2.6930467268755516

Epoch: 5| Step: 4
Training loss: 0.403188466835075
Validation loss: 2.7227730965409216

Epoch: 5| Step: 5
Training loss: 0.80817679006926
Validation loss: 2.6978478711364717

Epoch: 5| Step: 6
Training loss: 0.5587021782484551
Validation loss: 2.6111738434711587

Epoch: 5| Step: 7
Training loss: 1.224958646815882
Validation loss: 2.705828819361208

Epoch: 5| Step: 8
Training loss: 0.4479965999902129
Validation loss: 2.717667184978529

Epoch: 5| Step: 9
Training loss: 0.7404314246895631
Validation loss: 2.72537380419441

Epoch: 5| Step: 10
Training loss: 0.40983859886105656
Validation loss: 2.7698001381317847

Epoch: 5| Step: 11
Training loss: 0.6633021995012797
Validation loss: 2.71669489918024

Epoch: 257| Step: 0
Training loss: 0.6221076079825782
Validation loss: 2.7001183147615793

Epoch: 5| Step: 1
Training loss: 0.45678908298214904
Validation loss: 2.7026509914923014

Epoch: 5| Step: 2
Training loss: 0.6470508916803466
Validation loss: 2.642681066251852

Epoch: 5| Step: 3
Training loss: 0.4921763585358518
Validation loss: 2.654989347310795

Epoch: 5| Step: 4
Training loss: 0.4178101604170765
Validation loss: 2.7042760842046785

Epoch: 5| Step: 5
Training loss: 0.7631033808264752
Validation loss: 2.7260830484081344

Epoch: 5| Step: 6
Training loss: 0.4781021044117329
Validation loss: 2.7900951407901755

Epoch: 5| Step: 7
Training loss: 0.38526276359481015
Validation loss: 2.7473152160869465

Epoch: 5| Step: 8
Training loss: 0.47991357688430264
Validation loss: 2.7447008205969223

Epoch: 5| Step: 9
Training loss: 0.6853358495503122
Validation loss: 2.8132647569563636

Epoch: 5| Step: 10
Training loss: 1.3251853273447047
Validation loss: 2.8151572249238415

Epoch: 5| Step: 11
Training loss: 0.8477229782068233
Validation loss: 2.7889216340267415

Epoch: 258| Step: 0
Training loss: 0.48780242330344925
Validation loss: 2.751149963034553

Epoch: 5| Step: 1
Training loss: 0.5733435831937247
Validation loss: 2.642394723704881

Epoch: 5| Step: 2
Training loss: 0.9315969588884843
Validation loss: 2.7022335975167513

Epoch: 5| Step: 3
Training loss: 0.5097488166698062
Validation loss: 2.6069550361806537

Epoch: 5| Step: 4
Training loss: 0.37255215420538523
Validation loss: 2.6892381119041695

Epoch: 5| Step: 5
Training loss: 1.2534507328115758
Validation loss: 2.6250003670888975

Epoch: 5| Step: 6
Training loss: 0.4633483394272788
Validation loss: 2.7472366335094094

Epoch: 5| Step: 7
Training loss: 0.5816327977726623
Validation loss: 2.7096539407683813

Epoch: 5| Step: 8
Training loss: 0.5697648541303928
Validation loss: 2.7841215418614857

Epoch: 5| Step: 9
Training loss: 0.5024747698413958
Validation loss: 2.754075285501228

Epoch: 5| Step: 10
Training loss: 0.46513870242038435
Validation loss: 2.6965979749511026

Epoch: 5| Step: 11
Training loss: 0.31229083690740905
Validation loss: 2.836005151395374

Epoch: 259| Step: 0
Training loss: 0.3572091475340686
Validation loss: 2.7282602586166798

Epoch: 5| Step: 1
Training loss: 0.5245894382122587
Validation loss: 2.7443683860083454

Epoch: 5| Step: 2
Training loss: 0.4989455548629823
Validation loss: 2.6761737767613085

Epoch: 5| Step: 3
Training loss: 0.5404413528755025
Validation loss: 2.667572517070721

Epoch: 5| Step: 4
Training loss: 0.49195994308954427
Validation loss: 2.679616828928183

Epoch: 5| Step: 5
Training loss: 0.4182513342366938
Validation loss: 2.721215244866219

Epoch: 5| Step: 6
Training loss: 0.7099843605092041
Validation loss: 2.699866773267754

Epoch: 5| Step: 7
Training loss: 0.38771710466687753
Validation loss: 2.74489481597631

Epoch: 5| Step: 8
Training loss: 0.5429604618894468
Validation loss: 2.7352217534842285

Epoch: 5| Step: 9
Training loss: 1.3013493211055946
Validation loss: 2.693715190736301

Epoch: 5| Step: 10
Training loss: 0.5927975946622768
Validation loss: 2.7530484967205457

Epoch: 5| Step: 11
Training loss: 0.41156639016180424
Validation loss: 2.7344556687580996

Epoch: 260| Step: 0
Training loss: 0.5999560022116986
Validation loss: 2.7861925545023514

Epoch: 5| Step: 1
Training loss: 0.5534156402113477
Validation loss: 2.7181864150667026

Epoch: 5| Step: 2
Training loss: 1.2061563425813955
Validation loss: 2.699797311139093

Epoch: 5| Step: 3
Training loss: 0.44692340401948494
Validation loss: 2.662161532007947

Epoch: 5| Step: 4
Training loss: 0.5690464441924233
Validation loss: 2.6572053761953716

Epoch: 5| Step: 5
Training loss: 0.48519881241453366
Validation loss: 2.6886422849496774

Epoch: 5| Step: 6
Training loss: 0.46419332182327827
Validation loss: 2.777507517833361

Epoch: 5| Step: 7
Training loss: 0.7650042372318179
Validation loss: 2.761716196076086

Epoch: 5| Step: 8
Training loss: 0.8160401760149707
Validation loss: 2.7214642053773566

Epoch: 5| Step: 9
Training loss: 0.4480521769654743
Validation loss: 2.6837922586893446

Epoch: 5| Step: 10
Training loss: 0.6392148011280724
Validation loss: 2.6661820281733357

Epoch: 5| Step: 11
Training loss: 0.2231392724149969
Validation loss: 2.7255528173617787

Epoch: 261| Step: 0
Training loss: 0.5440638907741802
Validation loss: 2.7152255185511085

Epoch: 5| Step: 1
Training loss: 0.621294600921668
Validation loss: 2.6867445523449436

Epoch: 5| Step: 2
Training loss: 1.254636082718006
Validation loss: 2.7064185465187256

Epoch: 5| Step: 3
Training loss: 0.6970684723791032
Validation loss: 2.7277675359513824

Epoch: 5| Step: 4
Training loss: 0.6646407582895644
Validation loss: 2.743695441321271

Epoch: 5| Step: 5
Training loss: 0.7135043076436623
Validation loss: 2.833533789518555

Epoch: 5| Step: 6
Training loss: 0.44130871125515353
Validation loss: 2.7600692290455586

Epoch: 5| Step: 7
Training loss: 0.5340783617622844
Validation loss: 2.7311688181948064

Epoch: 5| Step: 8
Training loss: 0.39559671792037165
Validation loss: 2.6172156128393573

Epoch: 5| Step: 9
Training loss: 0.6209798504498258
Validation loss: 2.6388361512876255

Epoch: 5| Step: 10
Training loss: 0.7107001107411843
Validation loss: 2.653470099373238

Epoch: 5| Step: 11
Training loss: 0.6449839071735417
Validation loss: 2.681297208019185

Epoch: 262| Step: 0
Training loss: 0.4775859131093002
Validation loss: 2.749246129106215

Epoch: 5| Step: 1
Training loss: 0.8722560296083953
Validation loss: 2.87913422563957

Epoch: 5| Step: 2
Training loss: 0.857304593278867
Validation loss: 2.8730973533830975

Epoch: 5| Step: 3
Training loss: 0.5754567250122564
Validation loss: 2.8712550492076905

Epoch: 5| Step: 4
Training loss: 1.20673383980681
Validation loss: 2.717901119258081

Epoch: 5| Step: 5
Training loss: 0.43743744471059515
Validation loss: 2.7271776316119514

Epoch: 5| Step: 6
Training loss: 0.749785790052506
Validation loss: 2.6085362180794043

Epoch: 5| Step: 7
Training loss: 0.9263661786113524
Validation loss: 2.6641980488171484

Epoch: 5| Step: 8
Training loss: 0.6048935157289597
Validation loss: 2.6795132564618465

Epoch: 5| Step: 9
Training loss: 0.42960537212287736
Validation loss: 2.7462457874331188

Epoch: 5| Step: 10
Training loss: 0.6479171595515332
Validation loss: 2.8149751933028506

Epoch: 5| Step: 11
Training loss: 0.8024350093063372
Validation loss: 2.798758023846693

Epoch: 263| Step: 0
Training loss: 0.5425954399888877
Validation loss: 2.817462451499011

Epoch: 5| Step: 1
Training loss: 0.5259771087111036
Validation loss: 2.740944322449919

Epoch: 5| Step: 2
Training loss: 0.7400473808894291
Validation loss: 2.698228495237844

Epoch: 5| Step: 3
Training loss: 0.42992980367429473
Validation loss: 2.685277444906694

Epoch: 5| Step: 4
Training loss: 0.6215979011469526
Validation loss: 2.706968382912272

Epoch: 5| Step: 5
Training loss: 0.5047652736769461
Validation loss: 2.67132029807867

Epoch: 5| Step: 6
Training loss: 0.5452636412672375
Validation loss: 2.633210198374466

Epoch: 5| Step: 7
Training loss: 0.315898935962188
Validation loss: 2.72366558031076

Epoch: 5| Step: 8
Training loss: 0.49662420493215176
Validation loss: 2.6876452151698995

Epoch: 5| Step: 9
Training loss: 0.6539119670075653
Validation loss: 2.654766416433844

Epoch: 5| Step: 10
Training loss: 1.2437583539672625
Validation loss: 2.7419047123800735

Epoch: 5| Step: 11
Training loss: 0.3214607939293256
Validation loss: 2.7087966553203002

Epoch: 264| Step: 0
Training loss: 0.40238976446926333
Validation loss: 2.7363828498837286

Epoch: 5| Step: 1
Training loss: 0.5744280271573992
Validation loss: 2.680156481365208

Epoch: 5| Step: 2
Training loss: 0.3225757955779774
Validation loss: 2.734322745414252

Epoch: 5| Step: 3
Training loss: 0.4272168481898996
Validation loss: 2.7789148821914296

Epoch: 5| Step: 4
Training loss: 0.40834887882082016
Validation loss: 2.669838607073788

Epoch: 5| Step: 5
Training loss: 0.5731497954950514
Validation loss: 2.708143914763613

Epoch: 5| Step: 6
Training loss: 0.5998731399574067
Validation loss: 2.7338507522113042

Epoch: 5| Step: 7
Training loss: 0.6430787800008994
Validation loss: 2.6838314908002037

Epoch: 5| Step: 8
Training loss: 0.7674468415952534
Validation loss: 2.743833104253064

Epoch: 5| Step: 9
Training loss: 1.2593351353093414
Validation loss: 2.7262672803722623

Epoch: 5| Step: 10
Training loss: 0.3929183396755184
Validation loss: 2.672470097144052

Epoch: 5| Step: 11
Training loss: 0.3221210386582598
Validation loss: 2.668313552894123

Epoch: 265| Step: 0
Training loss: 0.40699227086022505
Validation loss: 2.7058534725200643

Epoch: 5| Step: 1
Training loss: 0.7685931146459712
Validation loss: 2.8437157723180007

Epoch: 5| Step: 2
Training loss: 0.6533023848875044
Validation loss: 2.8676993374880304

Epoch: 5| Step: 3
Training loss: 0.5038113763491677
Validation loss: 2.8134609064410045

Epoch: 5| Step: 4
Training loss: 0.5048652808209452
Validation loss: 2.7610604501149267

Epoch: 5| Step: 5
Training loss: 0.5496622717588935
Validation loss: 2.737582176896928

Epoch: 5| Step: 6
Training loss: 0.28945815870924885
Validation loss: 2.7181127210561784

Epoch: 5| Step: 7
Training loss: 0.34321424609079554
Validation loss: 2.6541503461598492

Epoch: 5| Step: 8
Training loss: 1.235656555884252
Validation loss: 2.64752766407726

Epoch: 5| Step: 9
Training loss: 0.6366114145623628
Validation loss: 2.6452503550801167

Epoch: 5| Step: 10
Training loss: 0.563637536920238
Validation loss: 2.6907234802270676

Epoch: 5| Step: 11
Training loss: 0.24335768470973157
Validation loss: 2.6980609775423363

Epoch: 266| Step: 0
Training loss: 1.2612208278522348
Validation loss: 2.709210775752199

Epoch: 5| Step: 1
Training loss: 0.7284349084887398
Validation loss: 2.774384712046982

Epoch: 5| Step: 2
Training loss: 0.3751188526952795
Validation loss: 2.6871677940034417

Epoch: 5| Step: 3
Training loss: 0.5798366313673133
Validation loss: 2.7343477211454355

Epoch: 5| Step: 4
Training loss: 0.6277798582167272
Validation loss: 2.7364391710074876

Epoch: 5| Step: 5
Training loss: 0.480188629245386
Validation loss: 2.6743456885519064

Epoch: 5| Step: 6
Training loss: 0.3973594929722442
Validation loss: 2.6686542983692476

Epoch: 5| Step: 7
Training loss: 0.5741092032433934
Validation loss: 2.6784545872197065

Epoch: 5| Step: 8
Training loss: 0.4778358301837716
Validation loss: 2.6894463839385288

Epoch: 5| Step: 9
Training loss: 0.5338121785345026
Validation loss: 2.727955823782077

Epoch: 5| Step: 10
Training loss: 0.36494001470458204
Validation loss: 2.729688941447142

Epoch: 5| Step: 11
Training loss: 0.3673018216665653
Validation loss: 2.718319537260113

Epoch: 267| Step: 0
Training loss: 0.5257694622832664
Validation loss: 2.6480768646494313

Epoch: 5| Step: 1
Training loss: 0.411204026096112
Validation loss: 2.666511904924475

Epoch: 5| Step: 2
Training loss: 0.34922285397569525
Validation loss: 2.6941622246802877

Epoch: 5| Step: 3
Training loss: 0.4275780483575463
Validation loss: 2.7417902500239038

Epoch: 5| Step: 4
Training loss: 0.36431344351496614
Validation loss: 2.768696069443325

Epoch: 5| Step: 5
Training loss: 0.7362961901309064
Validation loss: 2.678574778690968

Epoch: 5| Step: 6
Training loss: 0.5956905676346798
Validation loss: 2.659695619500442

Epoch: 5| Step: 7
Training loss: 0.27767505468297754
Validation loss: 2.706146888442455

Epoch: 5| Step: 8
Training loss: 1.2502108396100209
Validation loss: 2.7051098542814245

Epoch: 5| Step: 9
Training loss: 0.5597549320325672
Validation loss: 2.841453281531136

Epoch: 5| Step: 10
Training loss: 0.4716184430216328
Validation loss: 2.735630691669979

Epoch: 5| Step: 11
Training loss: 0.6118015004356918
Validation loss: 2.810880063798787

Epoch: 268| Step: 0
Training loss: 0.7758785221394188
Validation loss: 2.797560982430105

Epoch: 5| Step: 1
Training loss: 0.49443979969533813
Validation loss: 2.707794740504545

Epoch: 5| Step: 2
Training loss: 0.3951994647631515
Validation loss: 2.6399040027887324

Epoch: 5| Step: 3
Training loss: 0.33797038245016287
Validation loss: 2.6873886506722116

Epoch: 5| Step: 4
Training loss: 0.6980430265639688
Validation loss: 2.65243379180689

Epoch: 5| Step: 5
Training loss: 0.4979578275173911
Validation loss: 2.7040036524603606

Epoch: 5| Step: 6
Training loss: 0.5145154053593948
Validation loss: 2.6386454458769637

Epoch: 5| Step: 7
Training loss: 1.2185429128135135
Validation loss: 2.6821562069264413

Epoch: 5| Step: 8
Training loss: 0.49908618569823604
Validation loss: 2.801999485552902

Epoch: 5| Step: 9
Training loss: 0.41460827180562193
Validation loss: 2.7586833778325834

Epoch: 5| Step: 10
Training loss: 0.340629753902054
Validation loss: 2.8131099993092437

Epoch: 5| Step: 11
Training loss: 0.7526032250914354
Validation loss: 2.8498747337987367

Epoch: 269| Step: 0
Training loss: 1.1292997420230706
Validation loss: 2.7108443809442084

Epoch: 5| Step: 1
Training loss: 0.5319892564240871
Validation loss: 2.710368808604328

Epoch: 5| Step: 2
Training loss: 0.44789467432309904
Validation loss: 2.608346751719888

Epoch: 5| Step: 3
Training loss: 0.5612500926911888
Validation loss: 2.746205130028072

Epoch: 5| Step: 4
Training loss: 0.8069802739900773
Validation loss: 2.6617120234944966

Epoch: 5| Step: 5
Training loss: 0.6267686138607232
Validation loss: 2.705814570724229

Epoch: 5| Step: 6
Training loss: 0.5347794925961976
Validation loss: 2.6470071987029713

Epoch: 5| Step: 7
Training loss: 0.5233760342165229
Validation loss: 2.81727840906693

Epoch: 5| Step: 8
Training loss: 0.5668307325160857
Validation loss: 2.723388668227299

Epoch: 5| Step: 9
Training loss: 0.5379376769696584
Validation loss: 2.809224991122674

Epoch: 5| Step: 10
Training loss: 0.5500648384456299
Validation loss: 2.8128068226770853

Epoch: 5| Step: 11
Training loss: 0.4991282373557894
Validation loss: 2.722247712887467

Epoch: 270| Step: 0
Training loss: 0.5420276802057601
Validation loss: 2.6795194052272175

Epoch: 5| Step: 1
Training loss: 0.7626078576270149
Validation loss: 2.709070957434806

Epoch: 5| Step: 2
Training loss: 0.5582223471127526
Validation loss: 2.57972733381953

Epoch: 5| Step: 3
Training loss: 0.46429304952905354
Validation loss: 2.6720318664546503

Epoch: 5| Step: 4
Training loss: 0.4380439374215278
Validation loss: 2.6872560035481645

Epoch: 5| Step: 5
Training loss: 0.4545155268808718
Validation loss: 2.718806394087147

Epoch: 5| Step: 6
Training loss: 1.1653728406673969
Validation loss: 2.673522322420334

Epoch: 5| Step: 7
Training loss: 0.44030343760470364
Validation loss: 2.7332168378854416

Epoch: 5| Step: 8
Training loss: 0.5771907009909637
Validation loss: 2.832928990982822

Epoch: 5| Step: 9
Training loss: 0.7222081625213829
Validation loss: 2.774661439713888

Epoch: 5| Step: 10
Training loss: 0.49407355414998727
Validation loss: 2.7292392056170067

Epoch: 5| Step: 11
Training loss: 0.6242770543757322
Validation loss: 2.749940102098285

Epoch: 271| Step: 0
Training loss: 0.46418099480001623
Validation loss: 2.651657955929419

Epoch: 5| Step: 1
Training loss: 0.4370909720220944
Validation loss: 2.743118573657331

Epoch: 5| Step: 2
Training loss: 0.5314248302232075
Validation loss: 2.6867246248566103

Epoch: 5| Step: 3
Training loss: 0.525631618888993
Validation loss: 2.6589669413224133

Epoch: 5| Step: 4
Training loss: 1.1762926377322651
Validation loss: 2.7444076317683326

Epoch: 5| Step: 5
Training loss: 0.8073019867924446
Validation loss: 2.7370665101047136

Epoch: 5| Step: 6
Training loss: 0.5096804375922259
Validation loss: 2.8276872629821344

Epoch: 5| Step: 7
Training loss: 0.5306151748394619
Validation loss: 2.773872828457992

Epoch: 5| Step: 8
Training loss: 0.5205471174275903
Validation loss: 2.7610596153946005

Epoch: 5| Step: 9
Training loss: 0.6461501164970597
Validation loss: 2.7740089687396323

Epoch: 5| Step: 10
Training loss: 0.5087812719645582
Validation loss: 2.646473237749715

Epoch: 5| Step: 11
Training loss: 0.33078176225380207
Validation loss: 2.6914466445172573

Epoch: 272| Step: 0
Training loss: 0.7689097261805677
Validation loss: 2.7159974791309565

Epoch: 5| Step: 1
Training loss: 0.5678414675724603
Validation loss: 2.6496336663499402

Epoch: 5| Step: 2
Training loss: 0.5584566975235922
Validation loss: 2.679128086134645

Epoch: 5| Step: 3
Training loss: 0.8528725582458528
Validation loss: 2.693414840145579

Epoch: 5| Step: 4
Training loss: 1.124087864597835
Validation loss: 2.757640058765426

Epoch: 5| Step: 5
Training loss: 0.6149108520496896
Validation loss: 2.847920001338931

Epoch: 5| Step: 6
Training loss: 0.7190444177428783
Validation loss: 2.816025086040093

Epoch: 5| Step: 7
Training loss: 0.40261409528497316
Validation loss: 2.803894919188939

Epoch: 5| Step: 8
Training loss: 0.430920098764629
Validation loss: 2.693517066667578

Epoch: 5| Step: 9
Training loss: 0.5234981046294375
Validation loss: 2.68664680289229

Epoch: 5| Step: 10
Training loss: 0.6541658640409109
Validation loss: 2.666815508970188

Epoch: 5| Step: 11
Training loss: 0.32925118460836755
Validation loss: 2.6213782734516906

Epoch: 273| Step: 0
Training loss: 0.7682547656605682
Validation loss: 2.689243771141465

Epoch: 5| Step: 1
Training loss: 0.4647888984694634
Validation loss: 2.715148085407214

Epoch: 5| Step: 2
Training loss: 0.5697103744576661
Validation loss: 2.7032495701481793

Epoch: 5| Step: 3
Training loss: 0.6017928735113938
Validation loss: 2.773690386780947

Epoch: 5| Step: 4
Training loss: 1.1679209313443497
Validation loss: 2.7229814704610593

Epoch: 5| Step: 5
Training loss: 0.4769970522935425
Validation loss: 2.7060493130529

Epoch: 5| Step: 6
Training loss: 0.5453607576107511
Validation loss: 2.693681108946506

Epoch: 5| Step: 7
Training loss: 0.6091626115064722
Validation loss: 2.714670937798929

Epoch: 5| Step: 8
Training loss: 0.4205407306492284
Validation loss: 2.714332678828941

Epoch: 5| Step: 9
Training loss: 0.37662788551559645
Validation loss: 2.7647710548625017

Epoch: 5| Step: 10
Training loss: 0.5094783163313814
Validation loss: 2.628758158487456

Epoch: 5| Step: 11
Training loss: 0.35679020330189937
Validation loss: 2.6858701532163662

Epoch: 274| Step: 0
Training loss: 0.530170522014835
Validation loss: 2.7964133906414927

Epoch: 5| Step: 1
Training loss: 0.3715003145570822
Validation loss: 2.7091399471072624

Epoch: 5| Step: 2
Training loss: 0.6512033236391838
Validation loss: 2.7746335383319063

Epoch: 5| Step: 3
Training loss: 0.6633585620839654
Validation loss: 2.699109658126725

Epoch: 5| Step: 4
Training loss: 0.5859307097995227
Validation loss: 2.739568338002599

Epoch: 5| Step: 5
Training loss: 0.37519064666531676
Validation loss: 2.6901505165624675

Epoch: 5| Step: 6
Training loss: 1.2702792267705725
Validation loss: 2.6153775841397637

Epoch: 5| Step: 7
Training loss: 0.4374580192860307
Validation loss: 2.5964901479441966

Epoch: 5| Step: 8
Training loss: 0.6106435580835315
Validation loss: 2.7740720855695105

Epoch: 5| Step: 9
Training loss: 0.5011995351031158
Validation loss: 2.6797893604904375

Epoch: 5| Step: 10
Training loss: 0.4557256553151325
Validation loss: 2.6816139414349496

Epoch: 5| Step: 11
Training loss: 0.7075916408862355
Validation loss: 2.772901771633421

Epoch: 275| Step: 0
Training loss: 0.3934893305348717
Validation loss: 2.764390975442554

Epoch: 5| Step: 1
Training loss: 0.6278536974547193
Validation loss: 2.777089611217121

Epoch: 5| Step: 2
Training loss: 0.7075123704293854
Validation loss: 2.8005161771805938

Epoch: 5| Step: 3
Training loss: 0.418084440530704
Validation loss: 2.6725039383240987

Epoch: 5| Step: 4
Training loss: 0.4803589020740913
Validation loss: 2.7075739871970512

Epoch: 5| Step: 5
Training loss: 0.49836340924579786
Validation loss: 2.739779627890557

Epoch: 5| Step: 6
Training loss: 0.6200040939411237
Validation loss: 2.618362466669076

Epoch: 5| Step: 7
Training loss: 0.3914249621275609
Validation loss: 2.6984112751357725

Epoch: 5| Step: 8
Training loss: 1.0661845553170914
Validation loss: 2.8107661412898755

Epoch: 5| Step: 9
Training loss: 0.3847961026431527
Validation loss: 2.6854979909435848

Epoch: 5| Step: 10
Training loss: 0.5009000842517973
Validation loss: 2.789519585091623

Epoch: 5| Step: 11
Training loss: 0.33367865775039807
Validation loss: 2.8050530283126225

Epoch: 276| Step: 0
Training loss: 1.1536814538466709
Validation loss: 2.775006583781637

Epoch: 5| Step: 1
Training loss: 0.6257108936930174
Validation loss: 2.7212540396685356

Epoch: 5| Step: 2
Training loss: 0.4429920876627354
Validation loss: 2.720251993028249

Epoch: 5| Step: 3
Training loss: 0.40771548333945906
Validation loss: 2.733325497080068

Epoch: 5| Step: 4
Training loss: 0.5682273527886251
Validation loss: 2.7289647556676577

Epoch: 5| Step: 5
Training loss: 0.667620964305217
Validation loss: 2.788325296917872

Epoch: 5| Step: 6
Training loss: 0.41415490612830075
Validation loss: 2.7158184689347844

Epoch: 5| Step: 7
Training loss: 0.40127124242912093
Validation loss: 2.7473823269817905

Epoch: 5| Step: 8
Training loss: 0.5531955049052178
Validation loss: 2.7422996056111963

Epoch: 5| Step: 9
Training loss: 0.4518439996144712
Validation loss: 2.6876241189550614

Epoch: 5| Step: 10
Training loss: 0.3143606464567514
Validation loss: 2.6793217423282356

Epoch: 5| Step: 11
Training loss: 0.3599767208520002
Validation loss: 2.74021558150184

Epoch: 277| Step: 0
Training loss: 0.4385376783568667
Validation loss: 2.7180876162476992

Epoch: 5| Step: 1
Training loss: 0.42421309395351253
Validation loss: 2.743342649885127

Epoch: 5| Step: 2
Training loss: 0.388119674314366
Validation loss: 2.653948832400394

Epoch: 5| Step: 3
Training loss: 0.38765414617567995
Validation loss: 2.7747823329134347

Epoch: 5| Step: 4
Training loss: 0.7316881904680255
Validation loss: 2.712777091667753

Epoch: 5| Step: 5
Training loss: 0.36785353458423187
Validation loss: 2.7143117991845642

Epoch: 5| Step: 6
Training loss: 0.517240248465124
Validation loss: 2.7397482946841745

Epoch: 5| Step: 7
Training loss: 0.31809118008664605
Validation loss: 2.81113307725565

Epoch: 5| Step: 8
Training loss: 1.2399022896785594
Validation loss: 2.7130561999625766

Epoch: 5| Step: 9
Training loss: 0.43447928171728684
Validation loss: 2.7185880605474138

Epoch: 5| Step: 10
Training loss: 0.5090002986967038
Validation loss: 2.7346170372789262

Epoch: 5| Step: 11
Training loss: 0.25414260720418985
Validation loss: 2.6667794164027723

Epoch: 278| Step: 0
Training loss: 1.197867013759158
Validation loss: 2.7279800493783566

Epoch: 5| Step: 1
Training loss: 0.48814529051962235
Validation loss: 2.7311748579412667

Epoch: 5| Step: 2
Training loss: 0.4066119049219894
Validation loss: 2.7459496740219866

Epoch: 5| Step: 3
Training loss: 0.487988269646358
Validation loss: 2.695141354715653

Epoch: 5| Step: 4
Training loss: 0.39054980507942116
Validation loss: 2.7166293595586115

Epoch: 5| Step: 5
Training loss: 0.3994139878848876
Validation loss: 2.7196644345029783

Epoch: 5| Step: 6
Training loss: 0.39030727816678135
Validation loss: 2.7566970932567907

Epoch: 5| Step: 7
Training loss: 0.7368127255256185
Validation loss: 2.6595878124443377

Epoch: 5| Step: 8
Training loss: 0.5351370926372604
Validation loss: 2.716324828050974

Epoch: 5| Step: 9
Training loss: 0.3817449007511883
Validation loss: 2.7293131924866616

Epoch: 5| Step: 10
Training loss: 0.4133949296505632
Validation loss: 2.7026870938792222

Epoch: 5| Step: 11
Training loss: 0.5275813662343141
Validation loss: 2.7022950656869393

Epoch: 279| Step: 0
Training loss: 0.4238378637926501
Validation loss: 2.702806979602415

Epoch: 5| Step: 1
Training loss: 1.0835539642048826
Validation loss: 2.8200150330291622

Epoch: 5| Step: 2
Training loss: 0.5943721473136019
Validation loss: 2.8052431723188587

Epoch: 5| Step: 3
Training loss: 0.5896964741940252
Validation loss: 2.7456683882594883

Epoch: 5| Step: 4
Training loss: 0.3584738919608722
Validation loss: 2.7565543859426036

Epoch: 5| Step: 5
Training loss: 0.42450206983441335
Validation loss: 2.7327731499547987

Epoch: 5| Step: 6
Training loss: 0.4344013185555291
Validation loss: 2.7435592669071327

Epoch: 5| Step: 7
Training loss: 0.4797694692254243
Validation loss: 2.6876829624735463

Epoch: 5| Step: 8
Training loss: 0.4041425069326006
Validation loss: 2.6936755420103675

Epoch: 5| Step: 9
Training loss: 0.7493220682674742
Validation loss: 2.697233545626823

Epoch: 5| Step: 10
Training loss: 0.43474470775425644
Validation loss: 2.658762596165098

Epoch: 5| Step: 11
Training loss: 0.2178954907158169
Validation loss: 2.6429320758797568

Epoch: 280| Step: 0
Training loss: 0.6038273126846202
Validation loss: 2.7253316088382964

Epoch: 5| Step: 1
Training loss: 0.4389005280797671
Validation loss: 2.7683482941443907

Epoch: 5| Step: 2
Training loss: 0.4836197163600602
Validation loss: 2.6531234104674435

Epoch: 5| Step: 3
Training loss: 0.3462533828074331
Validation loss: 2.7203586978338294

Epoch: 5| Step: 4
Training loss: 0.6006535685847398
Validation loss: 2.7339493302124342

Epoch: 5| Step: 5
Training loss: 0.445114660653428
Validation loss: 2.7290593822640097

Epoch: 5| Step: 6
Training loss: 1.1810627178299533
Validation loss: 2.743840631307481

Epoch: 5| Step: 7
Training loss: 0.517839560069297
Validation loss: 2.7450865648050544

Epoch: 5| Step: 8
Training loss: 0.4840845806338662
Validation loss: 2.7581583946241213

Epoch: 5| Step: 9
Training loss: 0.4518349798902573
Validation loss: 2.7741955719558513

Epoch: 5| Step: 10
Training loss: 0.503911129240322
Validation loss: 2.775746905415621

Epoch: 5| Step: 11
Training loss: 0.4839987370143522
Validation loss: 2.766679990020139

Epoch: 281| Step: 0
Training loss: 0.42102916130182616
Validation loss: 2.7997287597579503

Epoch: 5| Step: 1
Training loss: 0.39441335446253656
Validation loss: 2.755430379668356

Epoch: 5| Step: 2
Training loss: 0.39357270987541704
Validation loss: 2.766043525393111

Epoch: 5| Step: 3
Training loss: 0.4995733616475095
Validation loss: 2.7151309513244413

Epoch: 5| Step: 4
Training loss: 0.5659828445072247
Validation loss: 2.659323761383261

Epoch: 5| Step: 5
Training loss: 0.5355475450062195
Validation loss: 2.665434561393014

Epoch: 5| Step: 6
Training loss: 0.6170483927351035
Validation loss: 2.7109606262745025

Epoch: 5| Step: 7
Training loss: 0.3846586436923078
Validation loss: 2.688710830777961

Epoch: 5| Step: 8
Training loss: 0.5268877106170765
Validation loss: 2.662744455204189

Epoch: 5| Step: 9
Training loss: 0.42603514914280255
Validation loss: 2.7863659899850313

Epoch: 5| Step: 10
Training loss: 1.2240133827761892
Validation loss: 2.765715710720232

Epoch: 5| Step: 11
Training loss: 0.5802860336965245
Validation loss: 2.7747143094316837

Epoch: 282| Step: 0
Training loss: 0.4384868765044868
Validation loss: 2.736904514696897

Epoch: 5| Step: 1
Training loss: 0.3901835044718594
Validation loss: 2.7044600422148273

Epoch: 5| Step: 2
Training loss: 1.114013698627205
Validation loss: 2.7005527620748633

Epoch: 5| Step: 3
Training loss: 0.7881365716071094
Validation loss: 2.6772210435787094

Epoch: 5| Step: 4
Training loss: 0.4997767009405238
Validation loss: 2.7019108156666922

Epoch: 5| Step: 5
Training loss: 0.4086053500160853
Validation loss: 2.720064532353589

Epoch: 5| Step: 6
Training loss: 0.5289007020374787
Validation loss: 2.7652671388467955

Epoch: 5| Step: 7
Training loss: 0.3794205508153045
Validation loss: 2.7703314747369423

Epoch: 5| Step: 8
Training loss: 0.4006060137244485
Validation loss: 2.7813460122727274

Epoch: 5| Step: 9
Training loss: 0.5079224394119999
Validation loss: 2.709656316458766

Epoch: 5| Step: 10
Training loss: 0.480362143746274
Validation loss: 2.773643493166168

Epoch: 5| Step: 11
Training loss: 0.3584465389558727
Validation loss: 2.7235376982678354

Epoch: 283| Step: 0
Training loss: 0.33947626612265835
Validation loss: 2.6886518656569733

Epoch: 5| Step: 1
Training loss: 0.3968785022971543
Validation loss: 2.728390151251538

Epoch: 5| Step: 2
Training loss: 0.4712856850659178
Validation loss: 2.6624329058531706

Epoch: 5| Step: 3
Training loss: 0.3861553635135955
Validation loss: 2.727390302094878

Epoch: 5| Step: 4
Training loss: 0.6516036672416957
Validation loss: 2.717182160442269

Epoch: 5| Step: 5
Training loss: 1.0220361098462774
Validation loss: 2.802564299027588

Epoch: 5| Step: 6
Training loss: 0.42769167961342724
Validation loss: 2.7644524504250314

Epoch: 5| Step: 7
Training loss: 0.5716622462347339
Validation loss: 2.791183982702776

Epoch: 5| Step: 8
Training loss: 0.516438997647144
Validation loss: 2.7866634153792207

Epoch: 5| Step: 9
Training loss: 0.4946734906331702
Validation loss: 2.7685608843016976

Epoch: 5| Step: 10
Training loss: 0.41501233183106895
Validation loss: 2.684622936026733

Epoch: 5| Step: 11
Training loss: 0.3522239079480608
Validation loss: 2.7874286221943656

Epoch: 284| Step: 0
Training loss: 0.4244252757712223
Validation loss: 2.740586479116383

Epoch: 5| Step: 1
Training loss: 0.5082257863181409
Validation loss: 2.8069630054785297

Epoch: 5| Step: 2
Training loss: 0.3838581285138516
Validation loss: 2.843055137166701

Epoch: 5| Step: 3
Training loss: 0.36450399716334947
Validation loss: 2.7792301094004754

Epoch: 5| Step: 4
Training loss: 0.5288613980770454
Validation loss: 2.7612737200852027

Epoch: 5| Step: 5
Training loss: 0.43353133568590685
Validation loss: 2.7409564675781812

Epoch: 5| Step: 6
Training loss: 1.133151878294848
Validation loss: 2.7743493886855304

Epoch: 5| Step: 7
Training loss: 0.8356517053643673
Validation loss: 2.7192808816798784

Epoch: 5| Step: 8
Training loss: 0.532763848642539
Validation loss: 2.7036012880411704

Epoch: 5| Step: 9
Training loss: 0.4607109871035465
Validation loss: 2.6906717790354064

Epoch: 5| Step: 10
Training loss: 0.3954903116004058
Validation loss: 2.826459253582388

Epoch: 5| Step: 11
Training loss: 0.6523630516257647
Validation loss: 2.837278607703925

Epoch: 285| Step: 0
Training loss: 0.6000955207606684
Validation loss: 2.867676349373312

Epoch: 5| Step: 1
Training loss: 0.44862940732587847
Validation loss: 2.717009632254866

Epoch: 5| Step: 2
Training loss: 0.5649179307021529
Validation loss: 2.7564107233879067

Epoch: 5| Step: 3
Training loss: 0.522253462336683
Validation loss: 2.703543276021421

Epoch: 5| Step: 4
Training loss: 1.0903220272331304
Validation loss: 2.6855183362889403

Epoch: 5| Step: 5
Training loss: 0.5272028134241272
Validation loss: 2.7058724422661555

Epoch: 5| Step: 6
Training loss: 0.4776613355870624
Validation loss: 2.8942602513790123

Epoch: 5| Step: 7
Training loss: 0.5323865457569453
Validation loss: 2.7539518203752604

Epoch: 5| Step: 8
Training loss: 0.3779733913494631
Validation loss: 2.84329574226568

Epoch: 5| Step: 9
Training loss: 0.6849743226382998
Validation loss: 2.773339573380514

Epoch: 5| Step: 10
Training loss: 0.43685685296086013
Validation loss: 2.704861823476214

Epoch: 5| Step: 11
Training loss: 0.3164641009531978
Validation loss: 2.7694861942387234

Epoch: 286| Step: 0
Training loss: 0.6152630269478455
Validation loss: 2.774513322521971

Epoch: 5| Step: 1
Training loss: 0.44324818027593993
Validation loss: 2.694712563793752

Epoch: 5| Step: 2
Training loss: 1.1124683825682644
Validation loss: 2.7913377814833344

Epoch: 5| Step: 3
Training loss: 0.46050117337101193
Validation loss: 2.8269202544915046

Epoch: 5| Step: 4
Training loss: 0.5339615566510109
Validation loss: 2.8850695175134367

Epoch: 5| Step: 5
Training loss: 0.6826366809250015
Validation loss: 2.8414208476912046

Epoch: 5| Step: 6
Training loss: 0.5364155119561071
Validation loss: 2.7981722680652927

Epoch: 5| Step: 7
Training loss: 0.4663235007894159
Validation loss: 2.682516060242181

Epoch: 5| Step: 8
Training loss: 0.5694184807800101
Validation loss: 2.711653996746504

Epoch: 5| Step: 9
Training loss: 0.6566497629631566
Validation loss: 2.6484163671680028

Epoch: 5| Step: 10
Training loss: 0.46433355077125477
Validation loss: 2.6781101014217317

Epoch: 5| Step: 11
Training loss: 0.24615190969197492
Validation loss: 2.7295289430094094

Epoch: 287| Step: 0
Training loss: 0.41266399504829515
Validation loss: 2.7394202815995845

Epoch: 5| Step: 1
Training loss: 0.33524967349830903
Validation loss: 2.7329506170501383

Epoch: 5| Step: 2
Training loss: 0.6137837337771681
Validation loss: 2.726618907385064

Epoch: 5| Step: 3
Training loss: 0.4213368727817281
Validation loss: 2.7478786689053454

Epoch: 5| Step: 4
Training loss: 0.5913711376172909
Validation loss: 2.7451653066367006

Epoch: 5| Step: 5
Training loss: 1.0758194528083667
Validation loss: 2.685617275355653

Epoch: 5| Step: 6
Training loss: 0.45428722236855107
Validation loss: 2.679284843094865

Epoch: 5| Step: 7
Training loss: 0.34328043901558647
Validation loss: 2.7525702209448677

Epoch: 5| Step: 8
Training loss: 0.4222106657865713
Validation loss: 2.6620522985312687

Epoch: 5| Step: 9
Training loss: 0.3010199206768715
Validation loss: 2.693669851516555

Epoch: 5| Step: 10
Training loss: 0.44813872163373103
Validation loss: 2.695465669564412

Epoch: 5| Step: 11
Training loss: 0.25494744953792015
Validation loss: 2.7466917331969145

Epoch: 288| Step: 0
Training loss: 0.6624152678160063
Validation loss: 2.683217888080307

Epoch: 5| Step: 1
Training loss: 0.3558804778992908
Validation loss: 2.7359156745869417

Epoch: 5| Step: 2
Training loss: 0.4023698594593609
Validation loss: 2.6841778811228694

Epoch: 5| Step: 3
Training loss: 0.43228608629539167
Validation loss: 2.679399569420788

Epoch: 5| Step: 4
Training loss: 0.4127536095219346
Validation loss: 2.705477306599552

Epoch: 5| Step: 5
Training loss: 0.6927285131703569
Validation loss: 2.713837493371644

Epoch: 5| Step: 6
Training loss: 0.3761234541455871
Validation loss: 2.6939409350578103

Epoch: 5| Step: 7
Training loss: 0.4257602861475601
Validation loss: 2.614214036451749

Epoch: 5| Step: 8
Training loss: 0.45628243422512954
Validation loss: 2.6850483083611802

Epoch: 5| Step: 9
Training loss: 1.1352133204270733
Validation loss: 2.7326596919836086

Epoch: 5| Step: 10
Training loss: 0.3124757995771644
Validation loss: 2.736288469287255

Epoch: 5| Step: 11
Training loss: 0.5842339228098083
Validation loss: 2.8027503497192376

Epoch: 289| Step: 0
Training loss: 0.5720880382600907
Validation loss: 2.776914936339153

Epoch: 5| Step: 1
Training loss: 0.36607626918423436
Validation loss: 2.7329728736880496

Epoch: 5| Step: 2
Training loss: 0.4419397657646801
Validation loss: 2.71268635386547

Epoch: 5| Step: 3
Training loss: 0.35995978998424577
Validation loss: 2.700520822910663

Epoch: 5| Step: 4
Training loss: 0.4075488454996829
Validation loss: 2.7036535374774098

Epoch: 5| Step: 5
Training loss: 1.1305261097811279
Validation loss: 2.7134055080898047

Epoch: 5| Step: 6
Training loss: 0.59160268386125
Validation loss: 2.713857186998974

Epoch: 5| Step: 7
Training loss: 0.36528386071478286
Validation loss: 2.701843685698443

Epoch: 5| Step: 8
Training loss: 0.4557565535536086
Validation loss: 2.771965528125881

Epoch: 5| Step: 9
Training loss: 0.508367733755491
Validation loss: 2.8075963080915205

Epoch: 5| Step: 10
Training loss: 0.7978213058206852
Validation loss: 2.7503262889799434

Epoch: 5| Step: 11
Training loss: 0.28294542360765734
Validation loss: 2.734914101635467

Epoch: 290| Step: 0
Training loss: 0.43171494478474026
Validation loss: 2.7221130821727497

Epoch: 5| Step: 1
Training loss: 0.25916736231390597
Validation loss: 2.7597978846056463

Epoch: 5| Step: 2
Training loss: 0.49888414801705233
Validation loss: 2.7453984103278737

Epoch: 5| Step: 3
Training loss: 0.4146796072386295
Validation loss: 2.679652209183921

Epoch: 5| Step: 4
Training loss: 0.3996515290967825
Validation loss: 2.7714489824124438

Epoch: 5| Step: 5
Training loss: 1.1469466724919712
Validation loss: 2.6574934760283053

Epoch: 5| Step: 6
Training loss: 0.36780026216979894
Validation loss: 2.661863336647279

Epoch: 5| Step: 7
Training loss: 0.38602161185882133
Validation loss: 2.682056677194307

Epoch: 5| Step: 8
Training loss: 0.6878311053493321
Validation loss: 2.7067346304862347

Epoch: 5| Step: 9
Training loss: 0.4950843664723684
Validation loss: 2.6892941127099075

Epoch: 5| Step: 10
Training loss: 0.3094488802269372
Validation loss: 2.72121303806894

Epoch: 5| Step: 11
Training loss: 0.4875027057376992
Validation loss: 2.7207426354468867

Epoch: 291| Step: 0
Training loss: 0.38307041121579155
Validation loss: 2.722601595840401

Epoch: 5| Step: 1
Training loss: 1.084121722893439
Validation loss: 2.848916969952137

Epoch: 5| Step: 2
Training loss: 0.46857258300190446
Validation loss: 2.764325057304561

Epoch: 5| Step: 3
Training loss: 0.5294127953198319
Validation loss: 2.7780849488943256

Epoch: 5| Step: 4
Training loss: 0.5307774124703017
Validation loss: 2.7589715497811924

Epoch: 5| Step: 5
Training loss: 0.47962204054733903
Validation loss: 2.7029023308449993

Epoch: 5| Step: 6
Training loss: 0.6411200448207468
Validation loss: 2.7631732180775224

Epoch: 5| Step: 7
Training loss: 0.4804374560577821
Validation loss: 2.6411142366284976

Epoch: 5| Step: 8
Training loss: 0.5005470501890631
Validation loss: 2.785626404302373

Epoch: 5| Step: 9
Training loss: 0.3349213423834824
Validation loss: 2.697172575350857

Epoch: 5| Step: 10
Training loss: 0.354212521875633
Validation loss: 2.7092572372521495

Epoch: 5| Step: 11
Training loss: 0.19625125350065878
Validation loss: 2.7182011433959996

Epoch: 292| Step: 0
Training loss: 0.30474854126832246
Validation loss: 2.752072665828925

Epoch: 5| Step: 1
Training loss: 0.6334238043171614
Validation loss: 2.766525520655823

Epoch: 5| Step: 2
Training loss: 0.3599355306781801
Validation loss: 2.744710422787733

Epoch: 5| Step: 3
Training loss: 0.3765815524271379
Validation loss: 2.769295747444119

Epoch: 5| Step: 4
Training loss: 0.35474151586531644
Validation loss: 2.7799502811228267

Epoch: 5| Step: 5
Training loss: 0.2723197708034756
Validation loss: 2.701398448769184

Epoch: 5| Step: 6
Training loss: 0.6957062452911366
Validation loss: 2.769720285382219

Epoch: 5| Step: 7
Training loss: 1.106410457806181
Validation loss: 2.6664933890928317

Epoch: 5| Step: 8
Training loss: 0.27226378715256067
Validation loss: 2.690035171337947

Epoch: 5| Step: 9
Training loss: 0.4922824344207884
Validation loss: 2.7475341231749724

Epoch: 5| Step: 10
Training loss: 0.3496371956097194
Validation loss: 2.8162449558188616

Epoch: 5| Step: 11
Training loss: 0.650472504098447
Validation loss: 2.7749534224991588

Epoch: 293| Step: 0
Training loss: 0.44575018872477956
Validation loss: 2.6791391617968388

Epoch: 5| Step: 1
Training loss: 0.6220876071508028
Validation loss: 2.649206348098799

Epoch: 5| Step: 2
Training loss: 0.565794252395293
Validation loss: 2.6725662240814936

Epoch: 5| Step: 3
Training loss: 0.42155453201466686
Validation loss: 2.688523404486638

Epoch: 5| Step: 4
Training loss: 0.40199333041740987
Validation loss: 2.7348563506289394

Epoch: 5| Step: 5
Training loss: 0.5059839632825239
Validation loss: 2.7747322606324705

Epoch: 5| Step: 6
Training loss: 0.3380134116868142
Validation loss: 2.7631458945679035

Epoch: 5| Step: 7
Training loss: 0.2692053247869269
Validation loss: 2.783953891796187

Epoch: 5| Step: 8
Training loss: 1.0536166936465734
Validation loss: 2.7555472785035366

Epoch: 5| Step: 9
Training loss: 0.37461201146762296
Validation loss: 2.7138871225030052

Epoch: 5| Step: 10
Training loss: 0.41320485236401344
Validation loss: 2.711130540261151

Epoch: 5| Step: 11
Training loss: 0.17198720433980305
Validation loss: 2.686701813164035

Epoch: 294| Step: 0
Training loss: 0.42823107720928366
Validation loss: 2.6776091965813182

Epoch: 5| Step: 1
Training loss: 0.37804458409352537
Validation loss: 2.674043021194111

Epoch: 5| Step: 2
Training loss: 0.42817592039585667
Validation loss: 2.664877357669867

Epoch: 5| Step: 3
Training loss: 0.34910950541437286
Validation loss: 2.6837992952673315

Epoch: 5| Step: 4
Training loss: 1.020361960177626
Validation loss: 2.667895914166145

Epoch: 5| Step: 5
Training loss: 0.5060618521898347
Validation loss: 2.70666357004896

Epoch: 5| Step: 6
Training loss: 0.5539784264719226
Validation loss: 2.7200812628413367

Epoch: 5| Step: 7
Training loss: 0.41360363636083086
Validation loss: 2.7339225867070867

Epoch: 5| Step: 8
Training loss: 0.6430263637162975
Validation loss: 2.7759634058204927

Epoch: 5| Step: 9
Training loss: 0.5681423808629598
Validation loss: 2.7614869016370887

Epoch: 5| Step: 10
Training loss: 0.6951668833294261
Validation loss: 2.708420573565653

Epoch: 5| Step: 11
Training loss: 0.48021011834905797
Validation loss: 2.6486247923876123

Epoch: 295| Step: 0
Training loss: 0.6446452878001211
Validation loss: 2.6726769736537586

Epoch: 5| Step: 1
Training loss: 0.4051553209369922
Validation loss: 2.7224360704899837

Epoch: 5| Step: 2
Training loss: 0.30992582587418027
Validation loss: 2.674580176853216

Epoch: 5| Step: 3
Training loss: 0.44446975872679256
Validation loss: 2.765598623864787

Epoch: 5| Step: 4
Training loss: 0.6806569475324761
Validation loss: 2.7073659942177524

Epoch: 5| Step: 5
Training loss: 1.0362563136038427
Validation loss: 2.8089206383298375

Epoch: 5| Step: 6
Training loss: 0.34486820671771423
Validation loss: 2.745856736555686

Epoch: 5| Step: 7
Training loss: 0.4281266386460179
Validation loss: 2.7344778677346437

Epoch: 5| Step: 8
Training loss: 0.5223485237471711
Validation loss: 2.786498910246031

Epoch: 5| Step: 9
Training loss: 0.3845400076143634
Validation loss: 2.7750527670428506

Epoch: 5| Step: 10
Training loss: 0.34940640188981
Validation loss: 2.7303469971383323

Epoch: 5| Step: 11
Training loss: 0.48204634409415237
Validation loss: 2.635620606237616

Epoch: 296| Step: 0
Training loss: 0.33313764351331454
Validation loss: 2.7643049721383215

Epoch: 5| Step: 1
Training loss: 1.0789182205143828
Validation loss: 2.755936019339933

Epoch: 5| Step: 2
Training loss: 0.5253439957017547
Validation loss: 2.6927786263908184

Epoch: 5| Step: 3
Training loss: 0.3674424686293851
Validation loss: 2.7029955213697585

Epoch: 5| Step: 4
Training loss: 0.4557464342024897
Validation loss: 2.7587758183794375

Epoch: 5| Step: 5
Training loss: 0.47914815086028634
Validation loss: 2.629616451078051

Epoch: 5| Step: 6
Training loss: 0.5041353754573935
Validation loss: 2.701865073491785

Epoch: 5| Step: 7
Training loss: 0.49917864392144107
Validation loss: 2.69802807733764

Epoch: 5| Step: 8
Training loss: 0.5668122250708442
Validation loss: 2.741375041127043

Epoch: 5| Step: 9
Training loss: 0.3937188650870289
Validation loss: 2.733245667257387

Epoch: 5| Step: 10
Training loss: 0.4274488916018389
Validation loss: 2.843317390205642

Epoch: 5| Step: 11
Training loss: 0.723868636651215
Validation loss: 2.777269915937516

Epoch: 297| Step: 0
Training loss: 0.3293958078648619
Validation loss: 2.741018203575397

Epoch: 5| Step: 1
Training loss: 0.3948882914072588
Validation loss: 2.6907616975258253

Epoch: 5| Step: 2
Training loss: 0.646235276834793
Validation loss: 2.644121248137891

Epoch: 5| Step: 3
Training loss: 0.34803376435355243
Validation loss: 2.657474093653336

Epoch: 5| Step: 4
Training loss: 0.5278578618704904
Validation loss: 2.6441702847576747

Epoch: 5| Step: 5
Training loss: 0.4699117410507285
Validation loss: 2.7216505275624683

Epoch: 5| Step: 6
Training loss: 0.6969955733472017
Validation loss: 2.7706000880016286

Epoch: 5| Step: 7
Training loss: 1.1636946948356757
Validation loss: 2.7612533213116373

Epoch: 5| Step: 8
Training loss: 0.6819559368137196
Validation loss: 2.8218382726330216

Epoch: 5| Step: 9
Training loss: 0.376697493134996
Validation loss: 2.7845100127487825

Epoch: 5| Step: 10
Training loss: 0.3132031279116921
Validation loss: 2.705269075303452

Epoch: 5| Step: 11
Training loss: 0.7550164779229124
Validation loss: 2.7634893817655057

Epoch: 298| Step: 0
Training loss: 0.5637681758513446
Validation loss: 2.66916196771693

Epoch: 5| Step: 1
Training loss: 0.4146068521598626
Validation loss: 2.6754642159534336

Epoch: 5| Step: 2
Training loss: 0.403869642742238
Validation loss: 2.8109280502502596

Epoch: 5| Step: 3
Training loss: 1.0761523236335107
Validation loss: 2.8176947691491634

Epoch: 5| Step: 4
Training loss: 0.5124441930578273
Validation loss: 2.8201752697077147

Epoch: 5| Step: 5
Training loss: 0.40426867842826886
Validation loss: 2.727306741685393

Epoch: 5| Step: 6
Training loss: 0.5067644895788396
Validation loss: 2.724829045308227

Epoch: 5| Step: 7
Training loss: 0.5747434074667568
Validation loss: 2.7679921309197573

Epoch: 5| Step: 8
Training loss: 0.6817610014072231
Validation loss: 2.7088222991490802

Epoch: 5| Step: 9
Training loss: 0.4673382640224569
Validation loss: 2.7180189742999574

Epoch: 5| Step: 10
Training loss: 0.6030081927389794
Validation loss: 2.6631047306812863

Epoch: 5| Step: 11
Training loss: 0.31044011710169517
Validation loss: 2.7217684027451834

Epoch: 299| Step: 0
Training loss: 1.1451730328377694
Validation loss: 2.746453577725377

Epoch: 5| Step: 1
Training loss: 0.3466374546169986
Validation loss: 2.6983443323812057

Epoch: 5| Step: 2
Training loss: 0.38536257836846743
Validation loss: 2.6887097740799852

Epoch: 5| Step: 3
Training loss: 0.39962278103085597
Validation loss: 2.827417070784319

Epoch: 5| Step: 4
Training loss: 0.45069311592730443
Validation loss: 2.749295541815141

Epoch: 5| Step: 5
Training loss: 0.3886922706351721
Validation loss: 2.7638682409108415

Epoch: 5| Step: 6
Training loss: 0.4244107930478361
Validation loss: 2.770363025021663

Epoch: 5| Step: 7
Training loss: 0.699229021902662
Validation loss: 2.706841158006851

Epoch: 5| Step: 8
Training loss: 0.431701880203767
Validation loss: 2.620506137372459

Epoch: 5| Step: 9
Training loss: 0.43377808784985034
Validation loss: 2.6726421236514017

Epoch: 5| Step: 10
Training loss: 0.48905916426133456
Validation loss: 2.7459926649926647

Epoch: 5| Step: 11
Training loss: 0.32355076561926965
Validation loss: 2.661695008227525

Epoch: 300| Step: 0
Training loss: 0.40704433105301696
Validation loss: 2.728614060800111

Epoch: 5| Step: 1
Training loss: 0.3879937049377176
Validation loss: 2.6494719136576697

Epoch: 5| Step: 2
Training loss: 0.5380944114613202
Validation loss: 2.647284460242316

Epoch: 5| Step: 3
Training loss: 0.41812261084656616
Validation loss: 2.688495289046469

Epoch: 5| Step: 4
Training loss: 0.4549403493681678
Validation loss: 2.654510564298165

Epoch: 5| Step: 5
Training loss: 0.4321559919069234
Validation loss: 2.620134381780369

Epoch: 5| Step: 6
Training loss: 0.7442587611022647
Validation loss: 2.6723837860694326

Epoch: 5| Step: 7
Training loss: 0.40145045249790884
Validation loss: 2.6877424034685697

Epoch: 5| Step: 8
Training loss: 0.3987496406230682
Validation loss: 2.639070391826676

Epoch: 5| Step: 9
Training loss: 1.0293937507223287
Validation loss: 2.7287105416954365

Epoch: 5| Step: 10
Training loss: 0.3878688856104571
Validation loss: 2.654620785442763

Epoch: 5| Step: 11
Training loss: 0.41652995091854683
Validation loss: 2.714391221494174

Epoch: 301| Step: 0
Training loss: 0.55055375507506
Validation loss: 2.6660851661639184

Epoch: 5| Step: 1
Training loss: 0.43256031635616793
Validation loss: 2.7861929912733374

Epoch: 5| Step: 2
Training loss: 0.5650800767208503
Validation loss: 2.722034812145232

Epoch: 5| Step: 3
Training loss: 0.37738534133453966
Validation loss: 2.6918451350917056

Epoch: 5| Step: 4
Training loss: 1.074193003952833
Validation loss: 2.7216639340915108

Epoch: 5| Step: 5
Training loss: 0.43422143197509677
Validation loss: 2.706215222159467

Epoch: 5| Step: 6
Training loss: 0.4135571580991221
Validation loss: 2.733242970422828

Epoch: 5| Step: 7
Training loss: 0.6511125195413502
Validation loss: 2.7632142495720147

Epoch: 5| Step: 8
Training loss: 0.5366409478580194
Validation loss: 2.6727315485283514

Epoch: 5| Step: 9
Training loss: 0.33638886137023427
Validation loss: 2.704262466575436

Epoch: 5| Step: 10
Training loss: 0.43675517645128153
Validation loss: 2.7120610234963465

Epoch: 5| Step: 11
Training loss: 0.42076572529809547
Validation loss: 2.738853449223571

Epoch: 302| Step: 0
Training loss: 0.7859722850223035
Validation loss: 2.6864131903482455

Epoch: 5| Step: 1
Training loss: 0.5460495304655794
Validation loss: 2.7073498988350044

Epoch: 5| Step: 2
Training loss: 0.6927251359627413
Validation loss: 2.6586560216907076

Epoch: 5| Step: 3
Training loss: 0.5214245651178924
Validation loss: 2.7753597707910296

Epoch: 5| Step: 4
Training loss: 0.5007686666969802
Validation loss: 2.8235114070505865

Epoch: 5| Step: 5
Training loss: 0.5928914237082994
Validation loss: 2.818870106906187

Epoch: 5| Step: 6
Training loss: 0.3387714547580754
Validation loss: 2.7817952875232486

Epoch: 5| Step: 7
Training loss: 0.38678320915846015
Validation loss: 2.7353478399558058

Epoch: 5| Step: 8
Training loss: 0.3931007133344468
Validation loss: 2.703305368892264

Epoch: 5| Step: 9
Training loss: 1.0180171085561325
Validation loss: 2.717712037954051

Epoch: 5| Step: 10
Training loss: 0.4076236462961019
Validation loss: 2.625740930651941

Epoch: 5| Step: 11
Training loss: 0.5060603504754786
Validation loss: 2.7719648364567533

Epoch: 303| Step: 0
Training loss: 0.4902218060952953
Validation loss: 2.7050329486916818

Epoch: 5| Step: 1
Training loss: 0.4843216682114697
Validation loss: 2.724117344919039

Epoch: 5| Step: 2
Training loss: 0.7023134422340057
Validation loss: 2.8339059206730735

Epoch: 5| Step: 3
Training loss: 1.0516402693356017
Validation loss: 2.8305849087105877

Epoch: 5| Step: 4
Training loss: 0.4863605565054212
Validation loss: 2.81003094484728

Epoch: 5| Step: 5
Training loss: 0.6345367723350064
Validation loss: 2.7554903925626277

Epoch: 5| Step: 6
Training loss: 0.33642921390636976
Validation loss: 2.7103836930361087

Epoch: 5| Step: 7
Training loss: 0.477265933197966
Validation loss: 2.7266627842514857

Epoch: 5| Step: 8
Training loss: 0.4072533834210301
Validation loss: 2.7018653235114036

Epoch: 5| Step: 9
Training loss: 0.46044732555594853
Validation loss: 2.685491358327684

Epoch: 5| Step: 10
Training loss: 0.5712735948343429
Validation loss: 2.7054790305326843

Epoch: 5| Step: 11
Training loss: 0.3095013273854671
Validation loss: 2.6987771493265553

Epoch: 304| Step: 0
Training loss: 0.4745390726147475
Validation loss: 2.7050536337063966

Epoch: 5| Step: 1
Training loss: 0.5708972859118159
Validation loss: 2.6922706356485144

Epoch: 5| Step: 2
Training loss: 0.3662012734727473
Validation loss: 2.8047698990841066

Epoch: 5| Step: 3
Training loss: 0.3311818984040826
Validation loss: 2.7137230295697448

Epoch: 5| Step: 4
Training loss: 0.5465953384314395
Validation loss: 2.73768414759105

Epoch: 5| Step: 5
Training loss: 0.2642962656851343
Validation loss: 2.6981716931458632

Epoch: 5| Step: 6
Training loss: 0.5000840354871702
Validation loss: 2.770542593213161

Epoch: 5| Step: 7
Training loss: 0.3529504821595988
Validation loss: 2.6528496294931685

Epoch: 5| Step: 8
Training loss: 0.49269002661322714
Validation loss: 2.687817972431423

Epoch: 5| Step: 9
Training loss: 1.1520519857068066
Validation loss: 2.692424365675273

Epoch: 5| Step: 10
Training loss: 0.3836314142075647
Validation loss: 2.692967479245504

Epoch: 5| Step: 11
Training loss: 0.6857622683112932
Validation loss: 2.699042892800006

Epoch: 305| Step: 0
Training loss: 0.295175493843859
Validation loss: 2.6519642475528182

Epoch: 5| Step: 1
Training loss: 0.3753735350847956
Validation loss: 2.704939762253885

Epoch: 5| Step: 2
Training loss: 0.49734315709765753
Validation loss: 2.6032621122399795

Epoch: 5| Step: 3
Training loss: 0.5472943197020763
Validation loss: 2.7512705750413144

Epoch: 5| Step: 4
Training loss: 0.29018788741950835
Validation loss: 2.6608177665850854

Epoch: 5| Step: 5
Training loss: 0.3397923573187368
Validation loss: 2.6334575161041744

Epoch: 5| Step: 6
Training loss: 0.42994120650559087
Validation loss: 2.780202293222688

Epoch: 5| Step: 7
Training loss: 1.0827605065747843
Validation loss: 2.739549144681425

Epoch: 5| Step: 8
Training loss: 0.39838652191161733
Validation loss: 2.761305069864254

Epoch: 5| Step: 9
Training loss: 0.4195137347040579
Validation loss: 2.7436222948957836

Epoch: 5| Step: 10
Training loss: 0.4639530945584759
Validation loss: 2.6991191611938703

Epoch: 5| Step: 11
Training loss: 0.5203654826455594
Validation loss: 2.7080648044587323

Epoch: 306| Step: 0
Training loss: 0.4003263468435809
Validation loss: 2.755091354011676

Epoch: 5| Step: 1
Training loss: 0.48676865323399804
Validation loss: 2.7008087105311795

Epoch: 5| Step: 2
Training loss: 0.9858224611228324
Validation loss: 2.6860052062135877

Epoch: 5| Step: 3
Training loss: 0.3869964296264959
Validation loss: 2.72372994763184

Epoch: 5| Step: 4
Training loss: 0.4057071066047076
Validation loss: 2.662402865678182

Epoch: 5| Step: 5
Training loss: 0.4895608994910577
Validation loss: 2.721072768609548

Epoch: 5| Step: 6
Training loss: 0.40297153715994305
Validation loss: 2.6679586156203006

Epoch: 5| Step: 7
Training loss: 0.3000552220978552
Validation loss: 2.6388797296956263

Epoch: 5| Step: 8
Training loss: 0.407349602203999
Validation loss: 2.693475338562774

Epoch: 5| Step: 9
Training loss: 0.5699510081886914
Validation loss: 2.6366039524283904

Epoch: 5| Step: 10
Training loss: 0.558955468923893
Validation loss: 2.7358651632916224

Epoch: 5| Step: 11
Training loss: 0.3508884219485928
Validation loss: 2.7444484370625584

Epoch: 307| Step: 0
Training loss: 0.41869624276777023
Validation loss: 2.7201970257937598

Epoch: 5| Step: 1
Training loss: 0.4545247065078697
Validation loss: 2.711207291208227

Epoch: 5| Step: 2
Training loss: 0.5956953204534854
Validation loss: 2.7729388115502798

Epoch: 5| Step: 3
Training loss: 0.4243316647647127
Validation loss: 2.6932559437263777

Epoch: 5| Step: 4
Training loss: 0.4577138644778302
Validation loss: 2.6475847384874425

Epoch: 5| Step: 5
Training loss: 0.47941080556487564
Validation loss: 2.7104304771208327

Epoch: 5| Step: 6
Training loss: 0.49151671582588524
Validation loss: 2.6442719299051656

Epoch: 5| Step: 7
Training loss: 0.3076407408401416
Validation loss: 2.7014586801401963

Epoch: 5| Step: 8
Training loss: 0.3312554102581776
Validation loss: 2.7081091561827164

Epoch: 5| Step: 9
Training loss: 0.386815203573567
Validation loss: 2.825407078060128

Epoch: 5| Step: 10
Training loss: 1.0480816278372236
Validation loss: 2.7283012926719166

Epoch: 5| Step: 11
Training loss: 0.4931802274868502
Validation loss: 2.780299393935011

Epoch: 308| Step: 0
Training loss: 0.40450532119183896
Validation loss: 2.795862518978761

Epoch: 5| Step: 1
Training loss: 0.40954093191031976
Validation loss: 2.6823377636155143

Epoch: 5| Step: 2
Training loss: 0.5657913026756785
Validation loss: 2.765890500243246

Epoch: 5| Step: 3
Training loss: 0.7059386436314669
Validation loss: 2.69426060666092

Epoch: 5| Step: 4
Training loss: 0.5174891269389292
Validation loss: 2.6356959414868313

Epoch: 5| Step: 5
Training loss: 1.06221419585648
Validation loss: 2.689952374607505

Epoch: 5| Step: 6
Training loss: 0.37910839469684504
Validation loss: 2.6748270342811287

Epoch: 5| Step: 7
Training loss: 0.45613236347818975
Validation loss: 2.726282617291353

Epoch: 5| Step: 8
Training loss: 0.5127283576125153
Validation loss: 2.7301837897965284

Epoch: 5| Step: 9
Training loss: 0.4837284849493307
Validation loss: 2.805553139763181

Epoch: 5| Step: 10
Training loss: 0.43640099158637685
Validation loss: 2.7473281755598764

Epoch: 5| Step: 11
Training loss: 0.3971082167352434
Validation loss: 2.7175911264134593

Epoch: 309| Step: 0
Training loss: 0.5914900837467701
Validation loss: 2.6850301830423278

Epoch: 5| Step: 1
Training loss: 0.4051666854532526
Validation loss: 2.6448417342320965

Epoch: 5| Step: 2
Training loss: 0.41284195929850626
Validation loss: 2.687186435400991

Epoch: 5| Step: 3
Training loss: 0.5478540104286053
Validation loss: 2.7549269495866118

Epoch: 5| Step: 4
Training loss: 0.5993390545692183
Validation loss: 2.777447276057073

Epoch: 5| Step: 5
Training loss: 0.4888176070281738
Validation loss: 2.7732661127138027

Epoch: 5| Step: 6
Training loss: 0.5193555147484384
Validation loss: 2.7845342618389655

Epoch: 5| Step: 7
Training loss: 1.0455821010365158
Validation loss: 2.764928719324359

Epoch: 5| Step: 8
Training loss: 0.40110384058695947
Validation loss: 2.6926970318692973

Epoch: 5| Step: 9
Training loss: 0.4030080884507501
Validation loss: 2.6887344068580203

Epoch: 5| Step: 10
Training loss: 0.40268520569373467
Validation loss: 2.750373428450612

Epoch: 5| Step: 11
Training loss: 0.46763898792775005
Validation loss: 2.643815289736541

Epoch: 310| Step: 0
Training loss: 0.380277296457171
Validation loss: 2.6975265181554633

Epoch: 5| Step: 1
Training loss: 0.4384271640606064
Validation loss: 2.717139552700409

Epoch: 5| Step: 2
Training loss: 0.3970075265881981
Validation loss: 2.748315446929223

Epoch: 5| Step: 3
Training loss: 0.3772247403209358
Validation loss: 2.717111216025064

Epoch: 5| Step: 4
Training loss: 0.554451099578568
Validation loss: 2.728106647151522

Epoch: 5| Step: 5
Training loss: 1.06653110765318
Validation loss: 2.7442809045307213

Epoch: 5| Step: 6
Training loss: 0.4647131183337671
Validation loss: 2.666029709998851

Epoch: 5| Step: 7
Training loss: 0.3570701035408299
Validation loss: 2.7566921851127506

Epoch: 5| Step: 8
Training loss: 0.5818760043994992
Validation loss: 2.68959399269724

Epoch: 5| Step: 9
Training loss: 0.41483131145788177
Validation loss: 2.7403346809414364

Epoch: 5| Step: 10
Training loss: 0.611443359434269
Validation loss: 2.700670141925599

Epoch: 5| Step: 11
Training loss: 0.8355303334243495
Validation loss: 2.7274375921237266

Epoch: 311| Step: 0
Training loss: 0.3206762481467097
Validation loss: 2.7315611029967846

Epoch: 5| Step: 1
Training loss: 0.5768948690230886
Validation loss: 2.6794170654675127

Epoch: 5| Step: 2
Training loss: 0.4711328657874686
Validation loss: 2.7269798549625635

Epoch: 5| Step: 3
Training loss: 0.6192999794156641
Validation loss: 2.6419761255837844

Epoch: 5| Step: 4
Training loss: 0.519786198522923
Validation loss: 2.7445191109903995

Epoch: 5| Step: 5
Training loss: 0.39439059101245294
Validation loss: 2.726626995675583

Epoch: 5| Step: 6
Training loss: 0.9693842011733831
Validation loss: 2.711178980469204

Epoch: 5| Step: 7
Training loss: 0.43983317577599673
Validation loss: 2.7090556532529466

Epoch: 5| Step: 8
Training loss: 0.36119039849027423
Validation loss: 2.6696800154013554

Epoch: 5| Step: 9
Training loss: 0.30586825731809497
Validation loss: 2.748646446383417

Epoch: 5| Step: 10
Training loss: 0.4470921642317739
Validation loss: 2.6675388069809824

Epoch: 5| Step: 11
Training loss: 0.24704179863120102
Validation loss: 2.6658593249586717

Epoch: 312| Step: 0
Training loss: 0.30827064741475824
Validation loss: 2.735772015780798

Epoch: 5| Step: 1
Training loss: 1.0131315286886065
Validation loss: 2.720493353291923

Epoch: 5| Step: 2
Training loss: 0.3527899823972872
Validation loss: 2.683541594937366

Epoch: 5| Step: 3
Training loss: 0.4199942947749516
Validation loss: 2.675674447482879

Epoch: 5| Step: 4
Training loss: 0.2627348178811017
Validation loss: 2.7033630883648554

Epoch: 5| Step: 5
Training loss: 0.2877725869046199
Validation loss: 2.718025439823328

Epoch: 5| Step: 6
Training loss: 0.4459565841985986
Validation loss: 2.652645586430559

Epoch: 5| Step: 7
Training loss: 0.29869939487205693
Validation loss: 2.648799443901848

Epoch: 5| Step: 8
Training loss: 0.5462944218710563
Validation loss: 2.691624710525646

Epoch: 5| Step: 9
Training loss: 0.5699309287551536
Validation loss: 2.613836464208098

Epoch: 5| Step: 10
Training loss: 0.4357504604072349
Validation loss: 2.684142854753302

Epoch: 5| Step: 11
Training loss: 0.552347890576675
Validation loss: 2.681135855722291

Epoch: 313| Step: 0
Training loss: 0.31674662284360433
Validation loss: 2.756290516515892

Epoch: 5| Step: 1
Training loss: 0.3374207377077877
Validation loss: 2.6752169568623163

Epoch: 5| Step: 2
Training loss: 0.3860029473970478
Validation loss: 2.7458309700820163

Epoch: 5| Step: 3
Training loss: 0.4632958517620032
Validation loss: 2.657718919859183

Epoch: 5| Step: 4
Training loss: 0.9976169384266307
Validation loss: 2.6705876347982342

Epoch: 5| Step: 5
Training loss: 0.30786557538750325
Validation loss: 2.7304424071780744

Epoch: 5| Step: 6
Training loss: 0.38332453368632596
Validation loss: 2.7278102326118763

Epoch: 5| Step: 7
Training loss: 0.41042210273563534
Validation loss: 2.719743689546471

Epoch: 5| Step: 8
Training loss: 0.4724882788945174
Validation loss: 2.7349172090910545

Epoch: 5| Step: 9
Training loss: 0.3357869742514875
Validation loss: 2.7038179586155593

Epoch: 5| Step: 10
Training loss: 0.34328425890958636
Validation loss: 2.714776606838655

Epoch: 5| Step: 11
Training loss: 1.0353502775485448
Validation loss: 2.715213968113124

Epoch: 314| Step: 0
Training loss: 0.45630294283608247
Validation loss: 2.6529490735692045

Epoch: 5| Step: 1
Training loss: 0.4168305094768309
Validation loss: 2.6887070658276824

Epoch: 5| Step: 2
Training loss: 0.3677865478318159
Validation loss: 2.6893029190629587

Epoch: 5| Step: 3
Training loss: 0.35743525745790955
Validation loss: 2.6833592237878117

Epoch: 5| Step: 4
Training loss: 0.2861170064576999
Validation loss: 2.7807274338213763

Epoch: 5| Step: 5
Training loss: 0.46808589940077716
Validation loss: 2.738838491004079

Epoch: 5| Step: 6
Training loss: 0.35749313811405864
Validation loss: 2.7911203665952775

Epoch: 5| Step: 7
Training loss: 0.3015421618387745
Validation loss: 2.743538908416206

Epoch: 5| Step: 8
Training loss: 0.5695006457819974
Validation loss: 2.714086285129847

Epoch: 5| Step: 9
Training loss: 1.0184853988297498
Validation loss: 2.726089913875752

Epoch: 5| Step: 10
Training loss: 0.48849604650516043
Validation loss: 2.6792940290196507

Epoch: 5| Step: 11
Training loss: 0.6278639977060944
Validation loss: 2.667850363298368

Epoch: 315| Step: 0
Training loss: 0.5127914483900167
Validation loss: 2.7435628171807434

Epoch: 5| Step: 1
Training loss: 0.4217377898704907
Validation loss: 2.7817273569676537

Epoch: 5| Step: 2
Training loss: 0.4221693883832737
Validation loss: 2.713333562435809

Epoch: 5| Step: 3
Training loss: 0.3702395395440735
Validation loss: 2.7501726565924502

Epoch: 5| Step: 4
Training loss: 0.3597984100214956
Validation loss: 2.693373490357197

Epoch: 5| Step: 5
Training loss: 0.3430322827211292
Validation loss: 2.606899530140944

Epoch: 5| Step: 6
Training loss: 0.525964416522318
Validation loss: 2.645016631787416

Epoch: 5| Step: 7
Training loss: 1.1185836071540864
Validation loss: 2.6568342463908543

Epoch: 5| Step: 8
Training loss: 0.33803785567288724
Validation loss: 2.706150306087021

Epoch: 5| Step: 9
Training loss: 0.42110158527282415
Validation loss: 2.6720963864136786

Epoch: 5| Step: 10
Training loss: 0.617497547353283
Validation loss: 2.7638908775733513

Epoch: 5| Step: 11
Training loss: 0.24227842039426253
Validation loss: 2.726209419073226

Epoch: 316| Step: 0
Training loss: 0.4683400427715544
Validation loss: 2.761015785027091

Epoch: 5| Step: 1
Training loss: 0.5167818962573396
Validation loss: 2.7849930175485977

Epoch: 5| Step: 2
Training loss: 0.4245878170264596
Validation loss: 2.732547952516827

Epoch: 5| Step: 3
Training loss: 0.40849620391384595
Validation loss: 2.7130622928464083

Epoch: 5| Step: 4
Training loss: 0.3269866087618426
Validation loss: 2.6954597543490366

Epoch: 5| Step: 5
Training loss: 0.39251059335639327
Validation loss: 2.7359245523654363

Epoch: 5| Step: 6
Training loss: 0.44417933125121406
Validation loss: 2.7334605949615054

Epoch: 5| Step: 7
Training loss: 1.010816075669601
Validation loss: 2.738616271663563

Epoch: 5| Step: 8
Training loss: 0.627354193537566
Validation loss: 2.8044296613670703

Epoch: 5| Step: 9
Training loss: 0.34104542552870504
Validation loss: 2.7214237015645684

Epoch: 5| Step: 10
Training loss: 0.6716893183491104
Validation loss: 2.8234040319376352

Epoch: 5| Step: 11
Training loss: 0.21347877208128116
Validation loss: 2.7525734095206915

Epoch: 317| Step: 0
Training loss: 0.530387121557874
Validation loss: 2.6932584371594848

Epoch: 5| Step: 1
Training loss: 0.4391304187576059
Validation loss: 2.707305578705133

Epoch: 5| Step: 2
Training loss: 0.553828528026467
Validation loss: 2.749564634886653

Epoch: 5| Step: 3
Training loss: 0.42308563026724894
Validation loss: 2.7072785353088324

Epoch: 5| Step: 4
Training loss: 0.9553831272640521
Validation loss: 2.6979082848751306

Epoch: 5| Step: 5
Training loss: 0.5153253435948296
Validation loss: 2.7156815093891544

Epoch: 5| Step: 6
Training loss: 0.3932119917329343
Validation loss: 2.755412728144193

Epoch: 5| Step: 7
Training loss: 0.4660582024947941
Validation loss: 2.779488634440464

Epoch: 5| Step: 8
Training loss: 0.5273709325495666
Validation loss: 2.7842759484034736

Epoch: 5| Step: 9
Training loss: 0.5006690615291098
Validation loss: 2.7114028348065684

Epoch: 5| Step: 10
Training loss: 0.40950046975245097
Validation loss: 2.7485286721379927

Epoch: 5| Step: 11
Training loss: 0.5480905647291849
Validation loss: 2.774242005053342

Epoch: 318| Step: 0
Training loss: 0.47992914804433673
Validation loss: 2.8180330069456456

Epoch: 5| Step: 1
Training loss: 0.633502960285475
Validation loss: 2.8138070354332774

Epoch: 5| Step: 2
Training loss: 0.913206726897348
Validation loss: 2.786671337412003

Epoch: 5| Step: 3
Training loss: 0.46705103383384267
Validation loss: 2.734173080618382

Epoch: 5| Step: 4
Training loss: 0.32623165976103624
Validation loss: 2.6499050616706183

Epoch: 5| Step: 5
Training loss: 0.41075022241095327
Validation loss: 2.7328886079305033

Epoch: 5| Step: 6
Training loss: 0.3552662618540527
Validation loss: 2.7007996327248454

Epoch: 5| Step: 7
Training loss: 0.40651410028066354
Validation loss: 2.6525183326670114

Epoch: 5| Step: 8
Training loss: 0.45505263293990156
Validation loss: 2.6796592733158837

Epoch: 5| Step: 9
Training loss: 0.3980929436945369
Validation loss: 2.6710444194875818

Epoch: 5| Step: 10
Training loss: 0.2925643800529601
Validation loss: 2.689681612982427

Epoch: 5| Step: 11
Training loss: 0.5642992489693657
Validation loss: 2.740340680547969

Epoch: 319| Step: 0
Training loss: 0.47707519156437106
Validation loss: 2.787936338563279

Epoch: 5| Step: 1
Training loss: 0.5912312741368788
Validation loss: 2.7963664908565917

Epoch: 5| Step: 2
Training loss: 0.5074714689268253
Validation loss: 2.767257585720342

Epoch: 5| Step: 3
Training loss: 0.36894564045477
Validation loss: 2.722659479081854

Epoch: 5| Step: 4
Training loss: 0.40414577000792484
Validation loss: 2.6806728453223037

Epoch: 5| Step: 5
Training loss: 0.9716910356788646
Validation loss: 2.7646026338039142

Epoch: 5| Step: 6
Training loss: 0.35210427818223594
Validation loss: 2.67886294625386

Epoch: 5| Step: 7
Training loss: 0.43905494452658206
Validation loss: 2.6579810242895254

Epoch: 5| Step: 8
Training loss: 0.461483647991878
Validation loss: 2.693376583037939

Epoch: 5| Step: 9
Training loss: 0.30561706376644315
Validation loss: 2.7013320047904674

Epoch: 5| Step: 10
Training loss: 0.6020279606982502
Validation loss: 2.8088517192139313

Epoch: 5| Step: 11
Training loss: 0.13083542419567976
Validation loss: 2.8349080770156787

Epoch: 320| Step: 0
Training loss: 0.30472996000174174
Validation loss: 2.8085813420374897

Epoch: 5| Step: 1
Training loss: 0.5031221188290952
Validation loss: 2.75623882519222

Epoch: 5| Step: 2
Training loss: 1.0393847202527784
Validation loss: 2.7982202292563025

Epoch: 5| Step: 3
Training loss: 0.3186098529287711
Validation loss: 2.7163743861380016

Epoch: 5| Step: 4
Training loss: 0.4402015585798535
Validation loss: 2.685714709037068

Epoch: 5| Step: 5
Training loss: 0.4365357262846604
Validation loss: 2.708600611825178

Epoch: 5| Step: 6
Training loss: 0.5914517142030824
Validation loss: 2.716383799548919

Epoch: 5| Step: 7
Training loss: 0.3609460614993143
Validation loss: 2.6985817989016776

Epoch: 5| Step: 8
Training loss: 0.41558668920874053
Validation loss: 2.723739879058899

Epoch: 5| Step: 9
Training loss: 0.49087814980009475
Validation loss: 2.731228778590811

Epoch: 5| Step: 10
Training loss: 0.5531666551411624
Validation loss: 2.7788183891013367

Epoch: 5| Step: 11
Training loss: 0.47460306422429543
Validation loss: 2.7538189163969595

Epoch: 321| Step: 0
Training loss: 0.31293762082691273
Validation loss: 2.7578132780684546

Epoch: 5| Step: 1
Training loss: 0.9345368924438581
Validation loss: 2.721000317409618

Epoch: 5| Step: 2
Training loss: 0.43441200373171784
Validation loss: 2.701960053544635

Epoch: 5| Step: 3
Training loss: 0.3191219978079238
Validation loss: 2.7227655221911515

Epoch: 5| Step: 4
Training loss: 0.438708084935447
Validation loss: 2.7412574582013676

Epoch: 5| Step: 5
Training loss: 0.39188177115082856
Validation loss: 2.697867626250159

Epoch: 5| Step: 6
Training loss: 0.3809990651151746
Validation loss: 2.701006097457624

Epoch: 5| Step: 7
Training loss: 0.3847937791467223
Validation loss: 2.742197793866985

Epoch: 5| Step: 8
Training loss: 0.3885475611644406
Validation loss: 2.739387898067717

Epoch: 5| Step: 9
Training loss: 0.6354524623189511
Validation loss: 2.8005985393719954

Epoch: 5| Step: 10
Training loss: 0.30823741330486254
Validation loss: 2.8570124866765503

Epoch: 5| Step: 11
Training loss: 0.5747743889577472
Validation loss: 2.7474608836977716

Epoch: 322| Step: 0
Training loss: 0.3640644490922481
Validation loss: 2.745418993846189

Epoch: 5| Step: 1
Training loss: 0.34016596109584046
Validation loss: 2.7147379463490977

Epoch: 5| Step: 2
Training loss: 0.30217591735907
Validation loss: 2.720258980943436

Epoch: 5| Step: 3
Training loss: 0.44309670485750124
Validation loss: 2.68834510349725

Epoch: 5| Step: 4
Training loss: 0.943717525251862
Validation loss: 2.760099676513206

Epoch: 5| Step: 5
Training loss: 0.2606518335273527
Validation loss: 2.767704668474529

Epoch: 5| Step: 6
Training loss: 0.6083637062311457
Validation loss: 2.7211476967102604

Epoch: 5| Step: 7
Training loss: 0.6175324164310487
Validation loss: 2.764817053385808

Epoch: 5| Step: 8
Training loss: 0.2404272034405973
Validation loss: 2.715071123879376

Epoch: 5| Step: 9
Training loss: 0.32637651385639604
Validation loss: 2.7929528687210103

Epoch: 5| Step: 10
Training loss: 0.5346031393523397
Validation loss: 2.7871938263596463

Epoch: 5| Step: 11
Training loss: 0.4120208138860987
Validation loss: 2.800706842020218

Epoch: 323| Step: 0
Training loss: 0.4465433310418119
Validation loss: 2.6962694247740853

Epoch: 5| Step: 1
Training loss: 0.4526571291834991
Validation loss: 2.7212257111574747

Epoch: 5| Step: 2
Training loss: 0.33420839660145196
Validation loss: 2.6892302473176835

Epoch: 5| Step: 3
Training loss: 0.5949941449718743
Validation loss: 2.685713680751229

Epoch: 5| Step: 4
Training loss: 0.984070564302392
Validation loss: 2.7026871177708887

Epoch: 5| Step: 5
Training loss: 0.34840966143397656
Validation loss: 2.7779672408393523

Epoch: 5| Step: 6
Training loss: 0.5594710283593658
Validation loss: 2.8420759380829534

Epoch: 5| Step: 7
Training loss: 0.5748398205269519
Validation loss: 2.804294523231153

Epoch: 5| Step: 8
Training loss: 0.5845279778962783
Validation loss: 2.763803437137778

Epoch: 5| Step: 9
Training loss: 0.42223865235858415
Validation loss: 2.754651174956715

Epoch: 5| Step: 10
Training loss: 0.4627675564855035
Validation loss: 2.7268385688177803

Epoch: 5| Step: 11
Training loss: 0.1957701661488029
Validation loss: 2.6039987484518266

Epoch: 324| Step: 0
Training loss: 0.7489325954452071
Validation loss: 2.7088238870964596

Epoch: 5| Step: 1
Training loss: 0.7069359393712596
Validation loss: 2.6172541367886835

Epoch: 5| Step: 2
Training loss: 0.6414304647393462
Validation loss: 2.693488302595969

Epoch: 5| Step: 3
Training loss: 0.4948022807806517
Validation loss: 2.738783329143238

Epoch: 5| Step: 4
Training loss: 0.9547167759478756
Validation loss: 2.7574963969330755

Epoch: 5| Step: 5
Training loss: 0.7306292352480216
Validation loss: 2.8166673021673203

Epoch: 5| Step: 6
Training loss: 0.5895297244022142
Validation loss: 2.7594112808590014

Epoch: 5| Step: 7
Training loss: 0.4322947555646116
Validation loss: 2.661262642496067

Epoch: 5| Step: 8
Training loss: 0.539046218183899
Validation loss: 2.64216521449422

Epoch: 5| Step: 9
Training loss: 0.6703054592234076
Validation loss: 2.575010742239165

Epoch: 5| Step: 10
Training loss: 0.5662672727363031
Validation loss: 2.6545051042039804

Epoch: 5| Step: 11
Training loss: 0.3437511379049714
Validation loss: 2.6621649799990776

Epoch: 325| Step: 0
Training loss: 0.3804544888747335
Validation loss: 2.7266085419506516

Epoch: 5| Step: 1
Training loss: 0.3306059595333019
Validation loss: 2.6894611699268633

Epoch: 5| Step: 2
Training loss: 0.49639911714927953
Validation loss: 2.702143448656277

Epoch: 5| Step: 3
Training loss: 0.32888639757131743
Validation loss: 2.6806182431240875

Epoch: 5| Step: 4
Training loss: 0.4475320247560599
Validation loss: 2.670248365589998

Epoch: 5| Step: 5
Training loss: 0.32889234418309593
Validation loss: 2.7447521247886817

Epoch: 5| Step: 6
Training loss: 0.45753421983783527
Validation loss: 2.66245041451823

Epoch: 5| Step: 7
Training loss: 0.4957305600004527
Validation loss: 2.6718443112163195

Epoch: 5| Step: 8
Training loss: 0.6197688288180887
Validation loss: 2.6887519530025137

Epoch: 5| Step: 9
Training loss: 0.9751122654568785
Validation loss: 2.6530861131673675

Epoch: 5| Step: 10
Training loss: 0.5120582328068243
Validation loss: 2.652202484458897

Epoch: 5| Step: 11
Training loss: 0.2796268781037028
Validation loss: 2.761566247825645

Epoch: 326| Step: 0
Training loss: 0.5074700594747193
Validation loss: 2.7391511240155437

Epoch: 5| Step: 1
Training loss: 0.42108229938289293
Validation loss: 2.7128579101347623

Epoch: 5| Step: 2
Training loss: 0.37713365728337295
Validation loss: 2.6217362156094537

Epoch: 5| Step: 3
Training loss: 1.0352912670828722
Validation loss: 2.6830574769531674

Epoch: 5| Step: 4
Training loss: 0.48833517158322887
Validation loss: 2.6711899620952892

Epoch: 5| Step: 5
Training loss: 0.3915997740592928
Validation loss: 2.7222136909054915

Epoch: 5| Step: 6
Training loss: 0.464395772025275
Validation loss: 2.659198627831751

Epoch: 5| Step: 7
Training loss: 0.3958261409741872
Validation loss: 2.643996394514202

Epoch: 5| Step: 8
Training loss: 0.34007302585164256
Validation loss: 2.7681493858307733

Epoch: 5| Step: 9
Training loss: 0.4022673562124298
Validation loss: 2.7155134020088147

Epoch: 5| Step: 10
Training loss: 0.4239578927371323
Validation loss: 2.62499298745687

Epoch: 5| Step: 11
Training loss: 0.21928451152614115
Validation loss: 2.6806970090526447

Epoch: 327| Step: 0
Training loss: 0.3369469446915184
Validation loss: 2.765722467030449

Epoch: 5| Step: 1
Training loss: 0.3747517439526168
Validation loss: 2.7983551548596806

Epoch: 5| Step: 2
Training loss: 0.3807250348383117
Validation loss: 2.729854108896922

Epoch: 5| Step: 3
Training loss: 0.9361278028411817
Validation loss: 2.727483424443159

Epoch: 5| Step: 4
Training loss: 0.4371311812974174
Validation loss: 2.651396610853131

Epoch: 5| Step: 5
Training loss: 0.5228327488782974
Validation loss: 2.656592907930675

Epoch: 5| Step: 6
Training loss: 0.47592079233460766
Validation loss: 2.6957886058825156

Epoch: 5| Step: 7
Training loss: 0.6018913163046248
Validation loss: 2.7428929434970257

Epoch: 5| Step: 8
Training loss: 0.400439933904018
Validation loss: 2.6307310862745976

Epoch: 5| Step: 9
Training loss: 0.4025405661653423
Validation loss: 2.719343991998187

Epoch: 5| Step: 10
Training loss: 0.34617040056600357
Validation loss: 2.7148454807925484

Epoch: 5| Step: 11
Training loss: 0.4370660673476209
Validation loss: 2.791166032315984

Epoch: 328| Step: 0
Training loss: 0.436724878721959
Validation loss: 2.6534481006111506

Epoch: 5| Step: 1
Training loss: 0.35367077115448897
Validation loss: 2.7381448698160957

Epoch: 5| Step: 2
Training loss: 0.36030981550846075
Validation loss: 2.703441456184907

Epoch: 5| Step: 3
Training loss: 0.4029103890705467
Validation loss: 2.7018475389699153

Epoch: 5| Step: 4
Training loss: 0.36317756157522674
Validation loss: 2.670141382688877

Epoch: 5| Step: 5
Training loss: 0.37349825408762394
Validation loss: 2.7431111786161626

Epoch: 5| Step: 6
Training loss: 1.0354355920997516
Validation loss: 2.7402798972197084

Epoch: 5| Step: 7
Training loss: 0.3938606341413719
Validation loss: 2.738833558110679

Epoch: 5| Step: 8
Training loss: 0.3521469662043704
Validation loss: 2.7083974512775653

Epoch: 5| Step: 9
Training loss: 0.6019389473287036
Validation loss: 2.6735556077907034

Epoch: 5| Step: 10
Training loss: 0.3480285515548306
Validation loss: 2.6994184281227604

Epoch: 5| Step: 11
Training loss: 0.3299842339780954
Validation loss: 2.7261753189933153

Epoch: 329| Step: 0
Training loss: 0.24734227286673086
Validation loss: 2.7167972187158114

Epoch: 5| Step: 1
Training loss: 0.3555163886038956
Validation loss: 2.7183265246612613

Epoch: 5| Step: 2
Training loss: 0.3897550241111038
Validation loss: 2.7112155225738657

Epoch: 5| Step: 3
Training loss: 0.9509846779223772
Validation loss: 2.693432068114648

Epoch: 5| Step: 4
Training loss: 0.3724501465713022
Validation loss: 2.709838761791715

Epoch: 5| Step: 5
Training loss: 0.41588848481532487
Validation loss: 2.7349253872579973

Epoch: 5| Step: 6
Training loss: 0.5799327372731459
Validation loss: 2.666880820039809

Epoch: 5| Step: 7
Training loss: 0.42951235235945584
Validation loss: 2.677069999176739

Epoch: 5| Step: 8
Training loss: 0.43221141652470846
Validation loss: 2.7200645360057476

Epoch: 5| Step: 9
Training loss: 0.3700353285316092
Validation loss: 2.7343823805209873

Epoch: 5| Step: 10
Training loss: 0.3185845965033523
Validation loss: 2.718603736772422

Epoch: 5| Step: 11
Training loss: 0.35311484406644666
Validation loss: 2.7768741251752154

Epoch: 330| Step: 0
Training loss: 0.31761206929947333
Validation loss: 2.7509457414151104

Epoch: 5| Step: 1
Training loss: 0.38020291607624906
Validation loss: 2.7616816387353884

Epoch: 5| Step: 2
Training loss: 0.5391222049986509
Validation loss: 2.8316279928808226

Epoch: 5| Step: 3
Training loss: 0.4807289008501116
Validation loss: 2.758179579845319

Epoch: 5| Step: 4
Training loss: 0.4870041434534745
Validation loss: 2.724096022433146

Epoch: 5| Step: 5
Training loss: 0.9855103681397305
Validation loss: 2.6936265510010444

Epoch: 5| Step: 6
Training loss: 0.41347076311040154
Validation loss: 2.723269801649721

Epoch: 5| Step: 7
Training loss: 0.5225132425811215
Validation loss: 2.7401566298411795

Epoch: 5| Step: 8
Training loss: 0.31503024955101
Validation loss: 2.782043179625083

Epoch: 5| Step: 9
Training loss: 0.33272854010111536
Validation loss: 2.741707164722318

Epoch: 5| Step: 10
Training loss: 0.36472546213978263
Validation loss: 2.6424677173287057

Epoch: 5| Step: 11
Training loss: 0.39200816366638114
Validation loss: 2.749642786031745

Epoch: 331| Step: 0
Training loss: 0.42917519286244643
Validation loss: 2.67055598451531

Epoch: 5| Step: 1
Training loss: 0.35204604062342176
Validation loss: 2.788923828210944

Epoch: 5| Step: 2
Training loss: 0.3779059311450524
Validation loss: 2.761215284571678

Epoch: 5| Step: 3
Training loss: 0.5039572874733569
Validation loss: 2.7718785198121942

Epoch: 5| Step: 4
Training loss: 0.944085546551265
Validation loss: 2.7244711892146047

Epoch: 5| Step: 5
Training loss: 0.4728815786926069
Validation loss: 2.727156784743143

Epoch: 5| Step: 6
Training loss: 0.5972353880808575
Validation loss: 2.707577003118989

Epoch: 5| Step: 7
Training loss: 0.3501935479055307
Validation loss: 2.670581750035227

Epoch: 5| Step: 8
Training loss: 0.4750918381149483
Validation loss: 2.6857764165633107

Epoch: 5| Step: 9
Training loss: 0.3605072388193367
Validation loss: 2.659880274173208

Epoch: 5| Step: 10
Training loss: 0.283797410079518
Validation loss: 2.73870823243463

Epoch: 5| Step: 11
Training loss: 0.1828112667400789
Validation loss: 2.7866334675924733

Epoch: 332| Step: 0
Training loss: 0.4108732949347147
Validation loss: 2.7210713046361437

Epoch: 5| Step: 1
Training loss: 0.344452952010487
Validation loss: 2.736571231038339

Epoch: 5| Step: 2
Training loss: 0.3153052069630587
Validation loss: 2.7454043554471057

Epoch: 5| Step: 3
Training loss: 0.42607767828079596
Validation loss: 2.8369512786437623

Epoch: 5| Step: 4
Training loss: 0.3683176099900791
Validation loss: 2.779793093417779

Epoch: 5| Step: 5
Training loss: 0.3239997790749409
Validation loss: 2.6928636492582765

Epoch: 5| Step: 6
Training loss: 0.43371302021045
Validation loss: 2.750816931904369

Epoch: 5| Step: 7
Training loss: 0.4611193572960957
Validation loss: 2.714109000256209

Epoch: 5| Step: 8
Training loss: 0.37619830441744306
Validation loss: 2.7325635104841894

Epoch: 5| Step: 9
Training loss: 0.9426051060482227
Validation loss: 2.7126761475953853

Epoch: 5| Step: 10
Training loss: 0.5183014332081908
Validation loss: 2.7788144745398897

Epoch: 5| Step: 11
Training loss: 0.31918934715144354
Validation loss: 2.6941911179844666

Epoch: 333| Step: 0
Training loss: 0.47057670066788426
Validation loss: 2.7430919123036235

Epoch: 5| Step: 1
Training loss: 0.2806366484333589
Validation loss: 2.728720706194731

Epoch: 5| Step: 2
Training loss: 0.8797209629991622
Validation loss: 2.760560770891819

Epoch: 5| Step: 3
Training loss: 0.49075414452184885
Validation loss: 2.7414631951165753

Epoch: 5| Step: 4
Training loss: 0.35212885484288287
Validation loss: 2.709902394438502

Epoch: 5| Step: 5
Training loss: 0.33125132794383916
Validation loss: 2.6952029514625138

Epoch: 5| Step: 6
Training loss: 0.44559371166950074
Validation loss: 2.688539211671623

Epoch: 5| Step: 7
Training loss: 0.32321698185587294
Validation loss: 2.6466781751705173

Epoch: 5| Step: 8
Training loss: 0.3555388748251267
Validation loss: 2.7682189271342157

Epoch: 5| Step: 9
Training loss: 0.49272226619040443
Validation loss: 2.6544866692862223

Epoch: 5| Step: 10
Training loss: 0.40732370219704345
Validation loss: 2.7163465662826733

Epoch: 5| Step: 11
Training loss: 0.41656785230353144
Validation loss: 2.670536155701862

Epoch: 334| Step: 0
Training loss: 0.3485582309308937
Validation loss: 2.722554161606096

Epoch: 5| Step: 1
Training loss: 0.37313985414825923
Validation loss: 2.7350098445164224

Epoch: 5| Step: 2
Training loss: 0.4216922434801101
Validation loss: 2.6725621483145243

Epoch: 5| Step: 3
Training loss: 0.43704250802633055
Validation loss: 2.762775932817627

Epoch: 5| Step: 4
Training loss: 0.9268465632721337
Validation loss: 2.799126828517659

Epoch: 5| Step: 5
Training loss: 0.44562429254162716
Validation loss: 2.677004053497998

Epoch: 5| Step: 6
Training loss: 0.34786340349574835
Validation loss: 2.7255163308010504

Epoch: 5| Step: 7
Training loss: 0.481383437693664
Validation loss: 2.6837148736219403

Epoch: 5| Step: 8
Training loss: 0.3247701483166714
Validation loss: 2.688500754010482

Epoch: 5| Step: 9
Training loss: 0.41096108807648646
Validation loss: 2.6831473803406904

Epoch: 5| Step: 10
Training loss: 0.3861778792544056
Validation loss: 2.672168563123162

Epoch: 5| Step: 11
Training loss: 0.43287566581342196
Validation loss: 2.745364718663378

Epoch: 335| Step: 0
Training loss: 0.3141375077289096
Validation loss: 2.708872768282244

Epoch: 5| Step: 1
Training loss: 0.9366537725391472
Validation loss: 2.7590247993688934

Epoch: 5| Step: 2
Training loss: 0.35734649029987503
Validation loss: 2.7310350928587694

Epoch: 5| Step: 3
Training loss: 0.5206397141739166
Validation loss: 2.744828389819095

Epoch: 5| Step: 4
Training loss: 0.34050519743774355
Validation loss: 2.7632356045466855

Epoch: 5| Step: 5
Training loss: 0.4357679344924972
Validation loss: 2.721886400563146

Epoch: 5| Step: 6
Training loss: 0.4059680914272639
Validation loss: 2.707573260733601

Epoch: 5| Step: 7
Training loss: 0.3984236060319255
Validation loss: 2.6789734744535956

Epoch: 5| Step: 8
Training loss: 0.38476754202582997
Validation loss: 2.716417576383438

Epoch: 5| Step: 9
Training loss: 0.3675640083221068
Validation loss: 2.7217400759378245

Epoch: 5| Step: 10
Training loss: 0.4033543939484239
Validation loss: 2.737979046901411

Epoch: 5| Step: 11
Training loss: 0.3123761408442699
Validation loss: 2.704762365317681

Epoch: 336| Step: 0
Training loss: 0.3269204099414752
Validation loss: 2.7421749219759906

Epoch: 5| Step: 1
Training loss: 0.4604080036119318
Validation loss: 2.6683454829357762

Epoch: 5| Step: 2
Training loss: 0.9150670392330503
Validation loss: 2.66111198207157

Epoch: 5| Step: 3
Training loss: 0.4018532068089249
Validation loss: 2.645487700186753

Epoch: 5| Step: 4
Training loss: 0.332799158142302
Validation loss: 2.721072808768408

Epoch: 5| Step: 5
Training loss: 0.2702257083187936
Validation loss: 2.788205129878206

Epoch: 5| Step: 6
Training loss: 0.4040550393214562
Validation loss: 2.7552926598079344

Epoch: 5| Step: 7
Training loss: 0.3851389937181525
Validation loss: 2.7957734828309446

Epoch: 5| Step: 8
Training loss: 0.3325583033426856
Validation loss: 2.7202860596299594

Epoch: 5| Step: 9
Training loss: 0.5119616681740591
Validation loss: 2.699591177141825

Epoch: 5| Step: 10
Training loss: 0.5885640339834933
Validation loss: 2.6443106720373843

Epoch: 5| Step: 11
Training loss: 0.3365483386036556
Validation loss: 2.686465263776849

Epoch: 337| Step: 0
Training loss: 0.4501964709749025
Validation loss: 2.631792000879776

Epoch: 5| Step: 1
Training loss: 0.4344442806293724
Validation loss: 2.69239879257963

Epoch: 5| Step: 2
Training loss: 0.33778146954142063
Validation loss: 2.7193036739692413

Epoch: 5| Step: 3
Training loss: 0.28680372512106017
Validation loss: 2.8201249325304194

Epoch: 5| Step: 4
Training loss: 0.6234011225974506
Validation loss: 2.806686071825638

Epoch: 5| Step: 5
Training loss: 0.4702467070783141
Validation loss: 2.6945760411858464

Epoch: 5| Step: 6
Training loss: 0.3901036789215801
Validation loss: 2.694221924630948

Epoch: 5| Step: 7
Training loss: 0.32525967485125906
Validation loss: 2.6678796830583558

Epoch: 5| Step: 8
Training loss: 0.6657614572551201
Validation loss: 2.630047260048361

Epoch: 5| Step: 9
Training loss: 0.969468773020738
Validation loss: 2.683586590723578

Epoch: 5| Step: 10
Training loss: 0.24479901610495008
Validation loss: 2.5987310991858315

Epoch: 5| Step: 11
Training loss: 0.3590217388246951
Validation loss: 2.7099885883008916

Epoch: 338| Step: 0
Training loss: 0.2671213358108769
Validation loss: 2.6854946561418207

Epoch: 5| Step: 1
Training loss: 0.6136634267593356
Validation loss: 2.746173345606948

Epoch: 5| Step: 2
Training loss: 0.4589369242063347
Validation loss: 2.778460153503022

Epoch: 5| Step: 3
Training loss: 0.41110747705534517
Validation loss: 2.6839928476008073

Epoch: 5| Step: 4
Training loss: 0.3170975092368707
Validation loss: 2.6492932342824957

Epoch: 5| Step: 5
Training loss: 0.39240071097794654
Validation loss: 2.760765909498518

Epoch: 5| Step: 6
Training loss: 0.4605215749998519
Validation loss: 2.7305504054937977

Epoch: 5| Step: 7
Training loss: 0.35953870444794817
Validation loss: 2.7388776001918984

Epoch: 5| Step: 8
Training loss: 0.3501718141976931
Validation loss: 2.6927387831028153

Epoch: 5| Step: 9
Training loss: 0.3009758480788855
Validation loss: 2.7353821743322806

Epoch: 5| Step: 10
Training loss: 0.8977850493746686
Validation loss: 2.738059299269665

Epoch: 5| Step: 11
Training loss: 0.3468615632418841
Validation loss: 2.721142209695135

Epoch: 339| Step: 0
Training loss: 0.9155120441429956
Validation loss: 2.745849605757137

Epoch: 5| Step: 1
Training loss: 0.4723573322722012
Validation loss: 2.7241337843067908

Epoch: 5| Step: 2
Training loss: 0.42580555487741206
Validation loss: 2.7703916560965256

Epoch: 5| Step: 3
Training loss: 0.5975123712224589
Validation loss: 2.6887780447832865

Epoch: 5| Step: 4
Training loss: 0.5104641275981842
Validation loss: 2.678782667126098

Epoch: 5| Step: 5
Training loss: 0.2486007618829334
Validation loss: 2.6219937711752523

Epoch: 5| Step: 6
Training loss: 0.32694607069638637
Validation loss: 2.6968073104491026

Epoch: 5| Step: 7
Training loss: 0.3419634385936166
Validation loss: 2.687353936003862

Epoch: 5| Step: 8
Training loss: 0.5083577969662749
Validation loss: 2.7227646684336424

Epoch: 5| Step: 9
Training loss: 0.35610102918482045
Validation loss: 2.7510806763519384

Epoch: 5| Step: 10
Training loss: 0.4367017275200199
Validation loss: 2.6832083027796596

Epoch: 5| Step: 11
Training loss: 0.23748922825528843
Validation loss: 2.688059131359587

Epoch: 340| Step: 0
Training loss: 0.45634248788961196
Validation loss: 2.654474012514605

Epoch: 5| Step: 1
Training loss: 0.3500636362228656
Validation loss: 2.6785244285153618

Epoch: 5| Step: 2
Training loss: 0.4373989669761442
Validation loss: 2.6580978548356256

Epoch: 5| Step: 3
Training loss: 0.4514543383987381
Validation loss: 2.7140862521880176

Epoch: 5| Step: 4
Training loss: 0.838673685868773
Validation loss: 2.7026303266836202

Epoch: 5| Step: 5
Training loss: 0.520604165840701
Validation loss: 2.7761838398229135

Epoch: 5| Step: 6
Training loss: 0.6091331099657822
Validation loss: 2.844058526598046

Epoch: 5| Step: 7
Training loss: 0.5470834334848645
Validation loss: 2.8316143246390255

Epoch: 5| Step: 8
Training loss: 0.4059209958569179
Validation loss: 2.7474802459235743

Epoch: 5| Step: 9
Training loss: 0.3790667872174658
Validation loss: 2.639409238698768

Epoch: 5| Step: 10
Training loss: 0.5810022154124005
Validation loss: 2.5811642621004656

Epoch: 5| Step: 11
Training loss: 0.3936194279053126
Validation loss: 2.654355379479258

Epoch: 341| Step: 0
Training loss: 0.5535502528609976
Validation loss: 2.6642425789476913

Epoch: 5| Step: 1
Training loss: 0.3507957043462781
Validation loss: 2.7108739502830113

Epoch: 5| Step: 2
Training loss: 0.478070608797649
Validation loss: 2.70298763800798

Epoch: 5| Step: 3
Training loss: 0.5556642234010916
Validation loss: 2.7098476883419473

Epoch: 5| Step: 4
Training loss: 0.8546014160098097
Validation loss: 2.7183246608687783

Epoch: 5| Step: 5
Training loss: 0.33563260725127014
Validation loss: 2.645092264656227

Epoch: 5| Step: 6
Training loss: 0.488604431011198
Validation loss: 2.6373439358464212

Epoch: 5| Step: 7
Training loss: 0.35679592499127255
Validation loss: 2.7143075061194595

Epoch: 5| Step: 8
Training loss: 0.39322444037150783
Validation loss: 2.6806398076788156

Epoch: 5| Step: 9
Training loss: 0.4738591233544413
Validation loss: 2.699275894406629

Epoch: 5| Step: 10
Training loss: 0.43847370783974704
Validation loss: 2.6602616665007193

Epoch: 5| Step: 11
Training loss: 0.262197171102215
Validation loss: 2.722121245891302

Epoch: 342| Step: 0
Training loss: 0.4754233268329228
Validation loss: 2.711764661084687

Epoch: 5| Step: 1
Training loss: 0.553203424185101
Validation loss: 2.7892796443464736

Epoch: 5| Step: 2
Training loss: 0.47247623136571765
Validation loss: 2.709921559457239

Epoch: 5| Step: 3
Training loss: 0.31658527819521504
Validation loss: 2.746908523707975

Epoch: 5| Step: 4
Training loss: 0.4812426808035983
Validation loss: 2.6921658931845918

Epoch: 5| Step: 5
Training loss: 0.9697046805656794
Validation loss: 2.6418810477397

Epoch: 5| Step: 6
Training loss: 0.3428631526556545
Validation loss: 2.734931591243079

Epoch: 5| Step: 7
Training loss: 0.4847656336068914
Validation loss: 2.78851201175021

Epoch: 5| Step: 8
Training loss: 0.39015140434192297
Validation loss: 2.7059467853539996

Epoch: 5| Step: 9
Training loss: 0.46161274023791715
Validation loss: 2.7685597755524416

Epoch: 5| Step: 10
Training loss: 0.46196283643460334
Validation loss: 2.7287016841334797

Epoch: 5| Step: 11
Training loss: 0.5349701606593287
Validation loss: 2.714508744022833

Epoch: 343| Step: 0
Training loss: 0.5791605104032315
Validation loss: 2.7884096936382035

Epoch: 5| Step: 1
Training loss: 0.543544710803131
Validation loss: 2.7426082726604473

Epoch: 5| Step: 2
Training loss: 0.34743821883054327
Validation loss: 2.709205402065864

Epoch: 5| Step: 3
Training loss: 0.4792988031748046
Validation loss: 2.686843658853673

Epoch: 5| Step: 4
Training loss: 0.45417771880091523
Validation loss: 2.6810469427483454

Epoch: 5| Step: 5
Training loss: 0.5747967101517958
Validation loss: 2.7105819219769938

Epoch: 5| Step: 6
Training loss: 0.46841609506391774
Validation loss: 2.6564488168248346

Epoch: 5| Step: 7
Training loss: 0.3206205050207271
Validation loss: 2.7094962569942598

Epoch: 5| Step: 8
Training loss: 0.9014060692961392
Validation loss: 2.8168253946066244

Epoch: 5| Step: 9
Training loss: 0.6488091885756246
Validation loss: 2.745705980078808

Epoch: 5| Step: 10
Training loss: 0.44554271101406306
Validation loss: 2.6867289582983216

Epoch: 5| Step: 11
Training loss: 0.17425262395560595
Validation loss: 2.696159907748638

Epoch: 344| Step: 0
Training loss: 0.5258030460368829
Validation loss: 2.6804787753006725

Epoch: 5| Step: 1
Training loss: 0.9124558176814556
Validation loss: 2.652759978155322

Epoch: 5| Step: 2
Training loss: 0.31436943930908673
Validation loss: 2.656768632259827

Epoch: 5| Step: 3
Training loss: 0.30365925683415956
Validation loss: 2.708713230974338

Epoch: 5| Step: 4
Training loss: 0.2942198804893391
Validation loss: 2.6815934219892124

Epoch: 5| Step: 5
Training loss: 0.49242673842146545
Validation loss: 2.838179589139772

Epoch: 5| Step: 6
Training loss: 0.5237493582382459
Validation loss: 2.7826705369502784

Epoch: 5| Step: 7
Training loss: 0.5189118959969155
Validation loss: 2.746069418309646

Epoch: 5| Step: 8
Training loss: 0.36594472746060075
Validation loss: 2.7131263753147445

Epoch: 5| Step: 9
Training loss: 0.6247663061022102
Validation loss: 2.5992116148514115

Epoch: 5| Step: 10
Training loss: 0.39831150157042544
Validation loss: 2.742884486667991

Epoch: 5| Step: 11
Training loss: 0.3397497507519681
Validation loss: 2.750324372826989

Epoch: 345| Step: 0
Training loss: 0.3240366734703744
Validation loss: 2.6691351054349597

Epoch: 5| Step: 1
Training loss: 0.8312683548012274
Validation loss: 2.7145021072691495

Epoch: 5| Step: 2
Training loss: 0.3803595956183444
Validation loss: 2.7419751402961303

Epoch: 5| Step: 3
Training loss: 0.40179387265959676
Validation loss: 2.6965892661008466

Epoch: 5| Step: 4
Training loss: 0.29795909253829517
Validation loss: 2.768590791658601

Epoch: 5| Step: 5
Training loss: 0.38231848935332285
Validation loss: 2.697142513263723

Epoch: 5| Step: 6
Training loss: 0.5529210614468378
Validation loss: 2.7376092711142075

Epoch: 5| Step: 7
Training loss: 0.1738481670783989
Validation loss: 2.6902984753301973

Epoch: 5| Step: 8
Training loss: 0.3432384282291875
Validation loss: 2.692433766890752

Epoch: 5| Step: 9
Training loss: 0.4295990939660881
Validation loss: 2.6848993729951296

Epoch: 5| Step: 10
Training loss: 0.445911372862244
Validation loss: 2.700263419738114

Epoch: 5| Step: 11
Training loss: 0.360799825924474
Validation loss: 2.7158701833905625

Epoch: 346| Step: 0
Training loss: 0.3118882867891632
Validation loss: 2.7386728461126046

Epoch: 5| Step: 1
Training loss: 0.35982075288527265
Validation loss: 2.6982804032338277

Epoch: 5| Step: 2
Training loss: 0.3765472440676244
Validation loss: 2.641016158075819

Epoch: 5| Step: 3
Training loss: 0.34289554040514153
Validation loss: 2.6815390089489646

Epoch: 5| Step: 4
Training loss: 0.34094351916152826
Validation loss: 2.6869539511948513

Epoch: 5| Step: 5
Training loss: 0.42329476896420176
Validation loss: 2.656554769347611

Epoch: 5| Step: 6
Training loss: 0.621502507854567
Validation loss: 2.711690788890537

Epoch: 5| Step: 7
Training loss: 0.3633111100589421
Validation loss: 2.652085802497124

Epoch: 5| Step: 8
Training loss: 0.3602768942121052
Validation loss: 2.7204042239923902

Epoch: 5| Step: 9
Training loss: 0.44279585328508037
Validation loss: 2.752640211770988

Epoch: 5| Step: 10
Training loss: 0.9335824175669587
Validation loss: 2.6887150206182953

Epoch: 5| Step: 11
Training loss: 0.5555065716235438
Validation loss: 2.726054766434848

Epoch: 347| Step: 0
Training loss: 0.5413270460270255
Validation loss: 2.6419947775184642

Epoch: 5| Step: 1
Training loss: 0.5437693559555824
Validation loss: 2.6618925226916668

Epoch: 5| Step: 2
Training loss: 1.0294268705157288
Validation loss: 2.6426864718348804

Epoch: 5| Step: 3
Training loss: 0.46829307856877106
Validation loss: 2.6554050747302984

Epoch: 5| Step: 4
Training loss: 0.4316429207166838
Validation loss: 2.7858971586246635

Epoch: 5| Step: 5
Training loss: 0.44318055231073633
Validation loss: 2.7143949874176

Epoch: 5| Step: 6
Training loss: 0.4486826475810675
Validation loss: 2.749261034313052

Epoch: 5| Step: 7
Training loss: 0.5496649013903101
Validation loss: 2.849851762251515

Epoch: 5| Step: 8
Training loss: 0.4705734865839226
Validation loss: 2.7345430377008415

Epoch: 5| Step: 9
Training loss: 0.3362174531011231
Validation loss: 2.7087472611562946

Epoch: 5| Step: 10
Training loss: 0.4367425014745222
Validation loss: 2.714133409837677

Epoch: 5| Step: 11
Training loss: 0.2905413455954978
Validation loss: 2.657742724137198

Epoch: 348| Step: 0
Training loss: 0.34006403218397246
Validation loss: 2.66622436227945

Epoch: 5| Step: 1
Training loss: 0.44304482817576435
Validation loss: 2.706799936251261

Epoch: 5| Step: 2
Training loss: 0.4495014130651818
Validation loss: 2.681599953109846

Epoch: 5| Step: 3
Training loss: 0.5005061448793728
Validation loss: 2.6967635556412506

Epoch: 5| Step: 4
Training loss: 0.2616919176381596
Validation loss: 2.6739703210954042

Epoch: 5| Step: 5
Training loss: 0.38257844737566904
Validation loss: 2.7427438894232816

Epoch: 5| Step: 6
Training loss: 0.35770386375178
Validation loss: 2.7286363473489343

Epoch: 5| Step: 7
Training loss: 0.332230665124391
Validation loss: 2.6595676123753917

Epoch: 5| Step: 8
Training loss: 0.49577530079183707
Validation loss: 2.787360579449496

Epoch: 5| Step: 9
Training loss: 0.37917980662134065
Validation loss: 2.7262851169568507

Epoch: 5| Step: 10
Training loss: 0.8570456407115996
Validation loss: 2.764167394349496

Epoch: 5| Step: 11
Training loss: 0.3826807145584523
Validation loss: 2.6739134235026163

Epoch: 349| Step: 0
Training loss: 0.37243926410798184
Validation loss: 2.725051643453837

Epoch: 5| Step: 1
Training loss: 0.3464429772556702
Validation loss: 2.675762115187342

Epoch: 5| Step: 2
Training loss: 0.5901328382628034
Validation loss: 2.723641690193809

Epoch: 5| Step: 3
Training loss: 0.8785346708018433
Validation loss: 2.725822982403018

Epoch: 5| Step: 4
Training loss: 0.3912702571633848
Validation loss: 2.759769436994918

Epoch: 5| Step: 5
Training loss: 0.38959043831219786
Validation loss: 2.8296161921374003

Epoch: 5| Step: 6
Training loss: 0.3453921519627326
Validation loss: 2.6802551328208253

Epoch: 5| Step: 7
Training loss: 0.3744296465174125
Validation loss: 2.715173663760939

Epoch: 5| Step: 8
Training loss: 0.38647287432244376
Validation loss: 2.7284680478192533

Epoch: 5| Step: 9
Training loss: 0.31540390476166363
Validation loss: 2.6957666723941007

Epoch: 5| Step: 10
Training loss: 0.5492928868662919
Validation loss: 2.7409839796646307

Epoch: 5| Step: 11
Training loss: 0.5552383964610862
Validation loss: 2.697977885849047

Epoch: 350| Step: 0
Training loss: 0.4682151285965977
Validation loss: 2.7149999120793056

Epoch: 5| Step: 1
Training loss: 0.461268903918675
Validation loss: 2.682920827809548

Epoch: 5| Step: 2
Training loss: 0.4616186314196975
Validation loss: 2.8175579807737763

Epoch: 5| Step: 3
Training loss: 0.864326569144422
Validation loss: 2.71307016890373

Epoch: 5| Step: 4
Training loss: 0.32375200985317787
Validation loss: 2.702309667411502

Epoch: 5| Step: 5
Training loss: 0.4133543400592106
Validation loss: 2.722094550404272

Epoch: 5| Step: 6
Training loss: 0.4056708168639255
Validation loss: 2.73882673546921

Epoch: 5| Step: 7
Training loss: 0.546945431124872
Validation loss: 2.6678777393402724

Epoch: 5| Step: 8
Training loss: 0.5391586604941414
Validation loss: 2.6451448924094794

Epoch: 5| Step: 9
Training loss: 0.4167410565568269
Validation loss: 2.7526981851382084

Epoch: 5| Step: 10
Training loss: 0.27969482721288924
Validation loss: 2.669205298510922

Epoch: 5| Step: 11
Training loss: 0.2911520772456639
Validation loss: 2.6690084164032837

Testing loss: 2.84316259960304
