Epoch: 1| Step: 0
Training loss: 9.052529789692034
Validation loss: 8.129506431321309

Epoch: 5| Step: 1
Training loss: 7.556328895983641
Validation loss: 8.099502110190688

Epoch: 5| Step: 2
Training loss: 8.255629035185724
Validation loss: 8.07147411296614

Epoch: 5| Step: 3
Training loss: 8.083309317746487
Validation loss: 8.043492576038757

Epoch: 5| Step: 4
Training loss: 8.371009901003301
Validation loss: 8.01894463104454

Epoch: 5| Step: 5
Training loss: 8.452532904402089
Validation loss: 7.994382117568004

Epoch: 5| Step: 6
Training loss: 6.776955928204936
Validation loss: 7.971069855943791

Epoch: 5| Step: 7
Training loss: 8.203518870752536
Validation loss: 7.950735776269612

Epoch: 5| Step: 8
Training loss: 7.886398059509001
Validation loss: 7.928216346111239

Epoch: 5| Step: 9
Training loss: 8.98170816398355
Validation loss: 7.904041137529701

Epoch: 5| Step: 10
Training loss: 7.722178327159706
Validation loss: 7.880845922547636

Epoch: 5| Step: 11
Training loss: 5.169255541211113
Validation loss: 7.855695385147809

Epoch: 2| Step: 0
Training loss: 7.636031628694568
Validation loss: 7.833431726879335

Epoch: 5| Step: 1
Training loss: 7.590806932338169
Validation loss: 7.808269769443106

Epoch: 5| Step: 2
Training loss: 8.07075964546602
Validation loss: 7.7837559291902165

Epoch: 5| Step: 3
Training loss: 8.335592446876808
Validation loss: 7.7587355634070425

Epoch: 5| Step: 4
Training loss: 7.821395326507645
Validation loss: 7.730528150333149

Epoch: 5| Step: 5
Training loss: 8.68677149949696
Validation loss: 7.703477099601351

Epoch: 5| Step: 6
Training loss: 7.819372465511189
Validation loss: 7.675907056973006

Epoch: 5| Step: 7
Training loss: 6.681712275357572
Validation loss: 7.642428683854041

Epoch: 5| Step: 8
Training loss: 7.270641801674179
Validation loss: 7.612114697055794

Epoch: 5| Step: 9
Training loss: 6.940606049121471
Validation loss: 7.580743060835844

Epoch: 5| Step: 10
Training loss: 8.586660339084608
Validation loss: 7.549834456323625

Epoch: 5| Step: 11
Training loss: 8.099232352344611
Validation loss: 7.513912732863499

Epoch: 3| Step: 0
Training loss: 7.563815420205434
Validation loss: 7.478497920692405

Epoch: 5| Step: 1
Training loss: 7.8051078308985025
Validation loss: 7.44090139790758

Epoch: 5| Step: 2
Training loss: 6.600476346021154
Validation loss: 7.4004264717244

Epoch: 5| Step: 3
Training loss: 7.801201546874121
Validation loss: 7.365284603530637

Epoch: 5| Step: 4
Training loss: 7.567910268933098
Validation loss: 7.324562915090923

Epoch: 5| Step: 5
Training loss: 7.35495270444807
Validation loss: 7.2778025312059365

Epoch: 5| Step: 6
Training loss: 7.028092009999968
Validation loss: 7.230090977248936

Epoch: 5| Step: 7
Training loss: 8.030028729037037
Validation loss: 7.185092390099543

Epoch: 5| Step: 8
Training loss: 7.179088679631944
Validation loss: 7.1400563064371

Epoch: 5| Step: 9
Training loss: 7.03070039084584
Validation loss: 7.084881699318559

Epoch: 5| Step: 10
Training loss: 6.846642566602586
Validation loss: 7.034539522754885

Epoch: 5| Step: 11
Training loss: 7.508150376925034
Validation loss: 6.978098701260078

Epoch: 4| Step: 0
Training loss: 7.310795772880246
Validation loss: 6.9176999166772815

Epoch: 5| Step: 1
Training loss: 6.856560688055939
Validation loss: 6.856583394348708

Epoch: 5| Step: 2
Training loss: 7.036261777205513
Validation loss: 6.794243664953426

Epoch: 5| Step: 3
Training loss: 7.07649424379549
Validation loss: 6.730473048082759

Epoch: 5| Step: 4
Training loss: 6.7568017104431926
Validation loss: 6.661046003197231

Epoch: 5| Step: 5
Training loss: 7.3617294659597805
Validation loss: 6.59115439818474

Epoch: 5| Step: 6
Training loss: 6.761792936750017
Validation loss: 6.518793386215609

Epoch: 5| Step: 7
Training loss: 6.063613632011881
Validation loss: 6.438086226847456

Epoch: 5| Step: 8
Training loss: 6.222502989716538
Validation loss: 6.355747059717156

Epoch: 5| Step: 9
Training loss: 6.424718519642758
Validation loss: 6.267656562958657

Epoch: 5| Step: 10
Training loss: 5.328337276402792
Validation loss: 6.178167362740019

Epoch: 5| Step: 11
Training loss: 6.722095596900359
Validation loss: 6.092126411574591

Epoch: 5| Step: 0
Training loss: 5.535796113002747
Validation loss: 5.994826848390573

Epoch: 5| Step: 1
Training loss: 7.106444977003736
Validation loss: 5.891066854214678

Epoch: 5| Step: 2
Training loss: 5.76674899591907
Validation loss: 5.782272440908672

Epoch: 5| Step: 3
Training loss: 5.877965625019937
Validation loss: 5.680479460592346

Epoch: 5| Step: 4
Training loss: 5.697889626652114
Validation loss: 5.568615812375333

Epoch: 5| Step: 5
Training loss: 5.4916002114210825
Validation loss: 5.453718661371912

Epoch: 5| Step: 6
Training loss: 5.569804678048533
Validation loss: 5.328302046741935

Epoch: 5| Step: 7
Training loss: 5.516948076582914
Validation loss: 5.1842472725207225

Epoch: 5| Step: 8
Training loss: 3.7995718965812504
Validation loss: 5.059155226566602

Epoch: 5| Step: 9
Training loss: 4.816789573148508
Validation loss: 4.934541427514678

Epoch: 5| Step: 10
Training loss: 4.6763284437936345
Validation loss: 4.786918180816903

Epoch: 5| Step: 11
Training loss: 6.642356736515792
Validation loss: 4.63011131857242

Epoch: 6| Step: 0
Training loss: 4.932456615661294
Validation loss: 4.4801983051887015

Epoch: 5| Step: 1
Training loss: 4.351666379061957
Validation loss: 4.312278566803

Epoch: 5| Step: 2
Training loss: 4.384101773243215
Validation loss: 4.141637344883385

Epoch: 5| Step: 3
Training loss: 3.7405640459312908
Validation loss: 3.983303404672999

Epoch: 5| Step: 4
Training loss: 4.5025013223717085
Validation loss: 3.8219766821114196

Epoch: 5| Step: 5
Training loss: 2.85397529424548
Validation loss: 3.6449192190877753

Epoch: 5| Step: 6
Training loss: 4.228908261577551
Validation loss: 3.490582207394962

Epoch: 5| Step: 7
Training loss: 3.0590547138769315
Validation loss: 3.332547063282943

Epoch: 5| Step: 8
Training loss: 3.7034450988202305
Validation loss: 3.207780354805295

Epoch: 5| Step: 9
Training loss: 3.1335734444461774
Validation loss: 3.069336202898377

Epoch: 5| Step: 10
Training loss: 3.2575750836189545
Validation loss: 2.953460391743684

Epoch: 5| Step: 11
Training loss: 2.065040988284416
Validation loss: 2.883910269062646

Epoch: 7| Step: 0
Training loss: 3.4218212106039188
Validation loss: 2.8140064620122525

Epoch: 5| Step: 1
Training loss: 3.013615388272873
Validation loss: 2.7676520345578197

Epoch: 5| Step: 2
Training loss: 3.1348139964141826
Validation loss: 2.7780686303031423

Epoch: 5| Step: 3
Training loss: 2.656651186098237
Validation loss: 2.7306479930484437

Epoch: 5| Step: 4
Training loss: 2.4611488857006294
Validation loss: 2.8077948419507104

Epoch: 5| Step: 5
Training loss: 3.6604285205062195
Validation loss: 2.7992096468094028

Epoch: 5| Step: 6
Training loss: 2.3521097249886602
Validation loss: 2.8459544458118993

Epoch: 5| Step: 7
Training loss: 2.9661902384438608
Validation loss: 2.8462243930355546

Epoch: 5| Step: 8
Training loss: 2.838101992838335
Validation loss: 2.8763219586030058

Epoch: 5| Step: 9
Training loss: 2.482533474146189
Validation loss: 2.9122595642781595

Epoch: 5| Step: 10
Training loss: 3.319523975762064
Validation loss: 2.923976985290709

Epoch: 5| Step: 11
Training loss: 2.5874948105322355
Validation loss: 2.91565310487493

Epoch: 8| Step: 0
Training loss: 3.899707778350932
Validation loss: 2.9103495625374114

Epoch: 5| Step: 1
Training loss: 3.1269055469522176
Validation loss: 2.8778049186081702

Epoch: 5| Step: 2
Training loss: 2.6836212023534447
Validation loss: 2.878866556861012

Epoch: 5| Step: 3
Training loss: 2.2783902153871223
Validation loss: 2.857594086574062

Epoch: 5| Step: 4
Training loss: 2.743479975662584
Validation loss: 2.8257770469042955

Epoch: 5| Step: 5
Training loss: 2.2420440521608476
Validation loss: 2.7956452854113305

Epoch: 5| Step: 6
Training loss: 2.705386940856309
Validation loss: 2.7701296462522733

Epoch: 5| Step: 7
Training loss: 3.4669418433598302
Validation loss: 2.7839047052966106

Epoch: 5| Step: 8
Training loss: 2.911500351567929
Validation loss: 2.739025814683341

Epoch: 5| Step: 9
Training loss: 2.953347495441911
Validation loss: 2.757886419125111

Epoch: 5| Step: 10
Training loss: 2.4920918317746734
Validation loss: 2.7411627960598333

Epoch: 5| Step: 11
Training loss: 1.8259186431417695
Validation loss: 2.7327930815442842

Epoch: 9| Step: 0
Training loss: 3.4865449041934795
Validation loss: 2.724765903438506

Epoch: 5| Step: 1
Training loss: 2.726315987272436
Validation loss: 2.7031625697294235

Epoch: 5| Step: 2
Training loss: 3.2156729202481227
Validation loss: 2.746637289664036

Epoch: 5| Step: 3
Training loss: 2.9290503864532336
Validation loss: 2.748844167534152

Epoch: 5| Step: 4
Training loss: 2.551572247665857
Validation loss: 2.712314307394764

Epoch: 5| Step: 5
Training loss: 2.8245122606656596
Validation loss: 2.7049469917178017

Epoch: 5| Step: 6
Training loss: 2.4533239393296276
Validation loss: 2.7023849650321794

Epoch: 5| Step: 7
Training loss: 2.5750309729333667
Validation loss: 2.712479811328112

Epoch: 5| Step: 8
Training loss: 3.120283611318605
Validation loss: 2.715453707374229

Epoch: 5| Step: 9
Training loss: 2.3443391186686946
Validation loss: 2.724697695887791

Epoch: 5| Step: 10
Training loss: 1.9398818603410048
Validation loss: 2.7049212872774917

Epoch: 5| Step: 11
Training loss: 3.245922758921531
Validation loss: 2.698287972682974

Epoch: 10| Step: 0
Training loss: 2.662561704251936
Validation loss: 2.716434146480768

Epoch: 5| Step: 1
Training loss: 1.9004078126230077
Validation loss: 2.6847808115186598

Epoch: 5| Step: 2
Training loss: 3.145745653021073
Validation loss: 2.7254214481482304

Epoch: 5| Step: 3
Training loss: 2.529806502560852
Validation loss: 2.687518803582465

Epoch: 5| Step: 4
Training loss: 2.6506777490477553
Validation loss: 2.7155214886239767

Epoch: 5| Step: 5
Training loss: 2.0982869654535077
Validation loss: 2.717931216730867

Epoch: 5| Step: 6
Training loss: 3.479529051648319
Validation loss: 2.7129980678900645

Epoch: 5| Step: 7
Training loss: 2.8167012519142673
Validation loss: 2.703772641841234

Epoch: 5| Step: 8
Training loss: 2.614401629898469
Validation loss: 2.6946156029287645

Epoch: 5| Step: 9
Training loss: 3.221658818182255
Validation loss: 2.7232203471602463

Epoch: 5| Step: 10
Training loss: 3.0684373871169712
Validation loss: 2.6835611444127747

Epoch: 5| Step: 11
Training loss: 2.4938836618804294
Validation loss: 2.6789900017469064

Epoch: 11| Step: 0
Training loss: 2.9236231179694303
Validation loss: 2.718242605224494

Epoch: 5| Step: 1
Training loss: 2.178013093500915
Validation loss: 2.7147141240411585

Epoch: 5| Step: 2
Training loss: 2.6930378479222674
Validation loss: 2.691324052815063

Epoch: 5| Step: 3
Training loss: 3.3116786586299254
Validation loss: 2.687994157471154

Epoch: 5| Step: 4
Training loss: 2.226896562110563
Validation loss: 2.6920283557792817

Epoch: 5| Step: 5
Training loss: 3.2823507733210193
Validation loss: 2.688951469994472

Epoch: 5| Step: 6
Training loss: 2.321765585948804
Validation loss: 2.6937901274840965

Epoch: 5| Step: 7
Training loss: 2.8826705773627297
Validation loss: 2.687417513298584

Epoch: 5| Step: 8
Training loss: 2.555008241076532
Validation loss: 2.674136753071485

Epoch: 5| Step: 9
Training loss: 2.505625403906851
Validation loss: 2.644107395841903

Epoch: 5| Step: 10
Training loss: 3.1754485046314964
Validation loss: 2.676852228651349

Epoch: 5| Step: 11
Training loss: 2.031620989445886
Validation loss: 2.679768549042838

Epoch: 12| Step: 0
Training loss: 2.682527866272113
Validation loss: 2.667947131432838

Epoch: 5| Step: 1
Training loss: 3.0551966562361197
Validation loss: 2.666356617565936

Epoch: 5| Step: 2
Training loss: 3.2931729182146956
Validation loss: 2.6683161347871636

Epoch: 5| Step: 3
Training loss: 2.792522090595676
Validation loss: 2.6650679323378372

Epoch: 5| Step: 4
Training loss: 2.9208894587270056
Validation loss: 2.6865875632147276

Epoch: 5| Step: 5
Training loss: 2.918408790918545
Validation loss: 2.640289654025835

Epoch: 5| Step: 6
Training loss: 1.835385113667541
Validation loss: 2.6836291907282486

Epoch: 5| Step: 7
Training loss: 2.4038455393863774
Validation loss: 2.6471313699196304

Epoch: 5| Step: 8
Training loss: 2.716936580924484
Validation loss: 2.658909479824374

Epoch: 5| Step: 9
Training loss: 3.0980586094887146
Validation loss: 2.6078457643746504

Epoch: 5| Step: 10
Training loss: 1.8952754810362884
Validation loss: 2.618856165698165

Epoch: 5| Step: 11
Training loss: 2.6590851855568394
Validation loss: 2.6319214042039807

Epoch: 13| Step: 0
Training loss: 2.3366562365935377
Validation loss: 2.6339965293528795

Epoch: 5| Step: 1
Training loss: 3.5128051299469267
Validation loss: 2.64127008282136

Epoch: 5| Step: 2
Training loss: 2.338037981760881
Validation loss: 2.656095156176764

Epoch: 5| Step: 3
Training loss: 3.053604285143873
Validation loss: 2.6626250527196254

Epoch: 5| Step: 4
Training loss: 3.079004152489068
Validation loss: 2.661977584162683

Epoch: 5| Step: 5
Training loss: 2.3436049352893082
Validation loss: 2.6224871180435865

Epoch: 5| Step: 6
Training loss: 3.0666578444754817
Validation loss: 2.6514439093423574

Epoch: 5| Step: 7
Training loss: 2.810427007710345
Validation loss: 2.6418067274258212

Epoch: 5| Step: 8
Training loss: 3.0002040793623133
Validation loss: 2.6369347434408654

Epoch: 5| Step: 9
Training loss: 1.993924330022632
Validation loss: 2.653026925420888

Epoch: 5| Step: 10
Training loss: 2.2210822943393023
Validation loss: 2.61885670434673

Epoch: 5| Step: 11
Training loss: 2.0074460181250293
Validation loss: 2.65313478564647

Epoch: 14| Step: 0
Training loss: 2.905566719703143
Validation loss: 2.630389580603533

Epoch: 5| Step: 1
Training loss: 2.542526370711651
Validation loss: 2.630086126730353

Epoch: 5| Step: 2
Training loss: 2.148061379541353
Validation loss: 2.6131886616466953

Epoch: 5| Step: 3
Training loss: 2.7227509973314192
Validation loss: 2.66372292182486

Epoch: 5| Step: 4
Training loss: 1.754955088592319
Validation loss: 2.591131432012413

Epoch: 5| Step: 5
Training loss: 3.0511110252101905
Validation loss: 2.613993807488841

Epoch: 5| Step: 6
Training loss: 2.7441922328888264
Validation loss: 2.653950552373607

Epoch: 5| Step: 7
Training loss: 2.8481495119990092
Validation loss: 2.651295147052341

Epoch: 5| Step: 8
Training loss: 2.87453158335936
Validation loss: 2.6260864000294557

Epoch: 5| Step: 9
Training loss: 2.0927562348000968
Validation loss: 2.6271210306010593

Epoch: 5| Step: 10
Training loss: 3.0699493737038224
Validation loss: 2.6137660232179294

Epoch: 5| Step: 11
Training loss: 4.401353645176914
Validation loss: 2.599649720866461

Epoch: 15| Step: 0
Training loss: 2.714110877924116
Validation loss: 2.625710898216109

Epoch: 5| Step: 1
Training loss: 2.751306656874132
Validation loss: 2.6031060742090566

Epoch: 5| Step: 2
Training loss: 3.7030673123143805
Validation loss: 2.6068483595827088

Epoch: 5| Step: 3
Training loss: 2.2359253099963614
Validation loss: 2.6646272688984833

Epoch: 5| Step: 4
Training loss: 1.7137826056408008
Validation loss: 2.626129806055258

Epoch: 5| Step: 5
Training loss: 2.2810286323058127
Validation loss: 2.6422188630471273

Epoch: 5| Step: 6
Training loss: 2.5920781641936554
Validation loss: 2.6031871301289686

Epoch: 5| Step: 7
Training loss: 2.3852576545678073
Validation loss: 2.5693815607389108

Epoch: 5| Step: 8
Training loss: 2.9552565859240483
Validation loss: 2.6648815644793817

Epoch: 5| Step: 9
Training loss: 3.4430240980684945
Validation loss: 2.6135357180229066

Epoch: 5| Step: 10
Training loss: 2.3854621538603373
Validation loss: 2.601505866976028

Epoch: 5| Step: 11
Training loss: 1.701487672840161
Validation loss: 2.5922243848019417

Epoch: 16| Step: 0
Training loss: 3.002689110027792
Validation loss: 2.590212926544271

Epoch: 5| Step: 1
Training loss: 2.6168502362566683
Validation loss: 2.6001206412814257

Epoch: 5| Step: 2
Training loss: 2.633410830101839
Validation loss: 2.605542274821727

Epoch: 5| Step: 3
Training loss: 1.8618537344843396
Validation loss: 2.6185174665795405

Epoch: 5| Step: 4
Training loss: 2.2225472636394774
Validation loss: 2.6174978195613705

Epoch: 5| Step: 5
Training loss: 2.7615131911377646
Validation loss: 2.6074117748431584

Epoch: 5| Step: 6
Training loss: 2.5694206568902733
Validation loss: 2.6208077856030583

Epoch: 5| Step: 7
Training loss: 2.0518052224115553
Validation loss: 2.610269762387518

Epoch: 5| Step: 8
Training loss: 2.8475306604893227
Validation loss: 2.5939238482357165

Epoch: 5| Step: 9
Training loss: 2.9002318059421115
Validation loss: 2.62499462043877

Epoch: 5| Step: 10
Training loss: 3.6735804716169365
Validation loss: 2.587950216123059

Epoch: 5| Step: 11
Training loss: 2.08685111279796
Validation loss: 2.5898862560038722

Epoch: 17| Step: 0
Training loss: 2.305513912677669
Validation loss: 2.616373506806062

Epoch: 5| Step: 1
Training loss: 2.58556619150819
Validation loss: 2.620906639337398

Epoch: 5| Step: 2
Training loss: 2.4279164424765423
Validation loss: 2.5663132401503215

Epoch: 5| Step: 3
Training loss: 2.80850121951845
Validation loss: 2.5984394527664234

Epoch: 5| Step: 4
Training loss: 2.451397135441219
Validation loss: 2.5682431154807728

Epoch: 5| Step: 5
Training loss: 2.8048015773174684
Validation loss: 2.558913232789508

Epoch: 5| Step: 6
Training loss: 2.924058068049803
Validation loss: 2.5907044090613764

Epoch: 5| Step: 7
Training loss: 1.7934133605874563
Validation loss: 2.592738161008695

Epoch: 5| Step: 8
Training loss: 2.363009653169381
Validation loss: 2.6177883350510336

Epoch: 5| Step: 9
Training loss: 3.2552251627169126
Validation loss: 2.57902260577264

Epoch: 5| Step: 10
Training loss: 3.1381590922224043
Validation loss: 2.569915280862978

Epoch: 5| Step: 11
Training loss: 1.75921622283155
Validation loss: 2.591507716124044

Epoch: 18| Step: 0
Training loss: 2.104691908845199
Validation loss: 2.566893223159957

Epoch: 5| Step: 1
Training loss: 2.696050747373975
Validation loss: 2.5980607217425344

Epoch: 5| Step: 2
Training loss: 3.2717557606652563
Validation loss: 2.581048912285319

Epoch: 5| Step: 3
Training loss: 2.3164422738424615
Validation loss: 2.5783753668468483

Epoch: 5| Step: 4
Training loss: 2.4552482600655043
Validation loss: 2.574606822298166

Epoch: 5| Step: 5
Training loss: 3.2229700663967016
Validation loss: 2.5845104209725234

Epoch: 5| Step: 6
Training loss: 2.5012311764856676
Validation loss: 2.604459648181751

Epoch: 5| Step: 7
Training loss: 2.3012853306633274
Validation loss: 2.5573265296025443

Epoch: 5| Step: 8
Training loss: 2.624613143025694
Validation loss: 2.6041610921164295

Epoch: 5| Step: 9
Training loss: 2.2711302070329134
Validation loss: 2.61008230205648

Epoch: 5| Step: 10
Training loss: 2.81127250163706
Validation loss: 2.6067250514829383

Epoch: 5| Step: 11
Training loss: 3.542648957108336
Validation loss: 2.593795856392191

Epoch: 19| Step: 0
Training loss: 2.295324204261184
Validation loss: 2.562073447228619

Epoch: 5| Step: 1
Training loss: 2.9462398617245915
Validation loss: 2.5627383338378134

Epoch: 5| Step: 2
Training loss: 2.7248874536073338
Validation loss: 2.5498408969162147

Epoch: 5| Step: 3
Training loss: 1.9213934194212894
Validation loss: 2.5494783276149677

Epoch: 5| Step: 4
Training loss: 2.9225154725538913
Validation loss: 2.587648315601797

Epoch: 5| Step: 5
Training loss: 2.9338898896590435
Validation loss: 2.6035330700987416

Epoch: 5| Step: 6
Training loss: 3.237221170444193
Validation loss: 2.5538796791552976

Epoch: 5| Step: 7
Training loss: 2.2436029837640357
Validation loss: 2.613682034279429

Epoch: 5| Step: 8
Training loss: 2.557788518328321
Validation loss: 2.5659582055660692

Epoch: 5| Step: 9
Training loss: 2.4535936041655013
Validation loss: 2.5722241544361517

Epoch: 5| Step: 10
Training loss: 2.245477794278351
Validation loss: 2.5730034289744292

Epoch: 5| Step: 11
Training loss: 3.3281714207810142
Validation loss: 2.5729348932359395

Epoch: 20| Step: 0
Training loss: 2.780304994661968
Validation loss: 2.582418719530041

Epoch: 5| Step: 1
Training loss: 3.1061419830883463
Validation loss: 2.588609266006095

Epoch: 5| Step: 2
Training loss: 2.1049595714320217
Validation loss: 2.58475749050223

Epoch: 5| Step: 3
Training loss: 2.8216888366326978
Validation loss: 2.5531513950472955

Epoch: 5| Step: 4
Training loss: 2.397616168122482
Validation loss: 2.6039877575771126

Epoch: 5| Step: 5
Training loss: 2.065897945774955
Validation loss: 2.597233596874314

Epoch: 5| Step: 6
Training loss: 2.1989068306427657
Validation loss: 2.571330117374669

Epoch: 5| Step: 7
Training loss: 2.4373828175082535
Validation loss: 2.551068899731795

Epoch: 5| Step: 8
Training loss: 2.96377017319602
Validation loss: 2.564115861891077

Epoch: 5| Step: 9
Training loss: 2.3897829255678116
Validation loss: 2.5637170529864024

Epoch: 5| Step: 10
Training loss: 3.4783014984453136
Validation loss: 2.5675262221520536

Epoch: 5| Step: 11
Training loss: 0.4819910079010437
Validation loss: 2.56771795194938

Epoch: 21| Step: 0
Training loss: 1.9630521034131319
Validation loss: 2.5836305498582823

Epoch: 5| Step: 1
Training loss: 2.8196458530574047
Validation loss: 2.5603253025973505

Epoch: 5| Step: 2
Training loss: 2.7599921325903174
Validation loss: 2.56695871972533

Epoch: 5| Step: 3
Training loss: 2.108183121387519
Validation loss: 2.5715307925452127

Epoch: 5| Step: 4
Training loss: 2.6318951828326993
Validation loss: 2.591634833936642

Epoch: 5| Step: 5
Training loss: 1.7341906475344195
Validation loss: 2.565485370536533

Epoch: 5| Step: 6
Training loss: 2.3952104062732826
Validation loss: 2.554477815256823

Epoch: 5| Step: 7
Training loss: 3.3696189651375783
Validation loss: 2.5805316365719753

Epoch: 5| Step: 8
Training loss: 2.80213859153821
Validation loss: 2.510133677212024

Epoch: 5| Step: 9
Training loss: 3.027980338815128
Validation loss: 2.573495689032233

Epoch: 5| Step: 10
Training loss: 2.555698766243169
Validation loss: 2.533019848195717

Epoch: 5| Step: 11
Training loss: 2.4438019495757017
Validation loss: 2.5791063810604657

Epoch: 22| Step: 0
Training loss: 2.4939775406132862
Validation loss: 2.5578239350557515

Epoch: 5| Step: 1
Training loss: 3.17683391321583
Validation loss: 2.583473491455676

Epoch: 5| Step: 2
Training loss: 2.621106575537967
Validation loss: 2.5562477441356504

Epoch: 5| Step: 3
Training loss: 2.0365801788588276
Validation loss: 2.5638719235670933

Epoch: 5| Step: 4
Training loss: 2.3025163154148256
Validation loss: 2.646572972089759

Epoch: 5| Step: 5
Training loss: 2.77345924906195
Validation loss: 2.6199457276221927

Epoch: 5| Step: 6
Training loss: 2.908444632192236
Validation loss: 2.637258582719904

Epoch: 5| Step: 7
Training loss: 2.874165953026566
Validation loss: 2.5937122472443783

Epoch: 5| Step: 8
Training loss: 2.5519207545804967
Validation loss: 2.608240052059351

Epoch: 5| Step: 9
Training loss: 2.2830936872296697
Validation loss: 2.5699403313656646

Epoch: 5| Step: 10
Training loss: 2.2531532867814676
Validation loss: 2.6390730983174255

Epoch: 5| Step: 11
Training loss: 3.012339803781244
Validation loss: 2.606011528125285

Epoch: 23| Step: 0
Training loss: 2.2247539469937583
Validation loss: 2.584758236110504

Epoch: 5| Step: 1
Training loss: 2.3665093687554304
Validation loss: 2.5365214225761235

Epoch: 5| Step: 2
Training loss: 2.9146309060465008
Validation loss: 2.6009676447000745

Epoch: 5| Step: 3
Training loss: 2.3492243602750396
Validation loss: 2.5643326982131023

Epoch: 5| Step: 4
Training loss: 3.285232452343392
Validation loss: 2.564152367051645

Epoch: 5| Step: 5
Training loss: 1.8534763279759765
Validation loss: 2.5627474626595497

Epoch: 5| Step: 6
Training loss: 2.5525273981221166
Validation loss: 2.5950787637464807

Epoch: 5| Step: 7
Training loss: 3.1731578318633202
Validation loss: 2.577386869864035

Epoch: 5| Step: 8
Training loss: 2.4461973496717837
Validation loss: 2.5777962985643157

Epoch: 5| Step: 9
Training loss: 2.692528035505826
Validation loss: 2.5866575976791215

Epoch: 5| Step: 10
Training loss: 2.617668995762167
Validation loss: 2.5670481846211115

Epoch: 5| Step: 11
Training loss: 2.7252307689139736
Validation loss: 2.5189007544384117

Epoch: 24| Step: 0
Training loss: 2.5507468532328614
Validation loss: 2.541954287425856

Epoch: 5| Step: 1
Training loss: 2.416455413091301
Validation loss: 2.5623238627057483

Epoch: 5| Step: 2
Training loss: 2.2071199382415645
Validation loss: 2.5461465772930905

Epoch: 5| Step: 3
Training loss: 3.2512442334515192
Validation loss: 2.574901773838477

Epoch: 5| Step: 4
Training loss: 2.0708794735143914
Validation loss: 2.5893309149218475

Epoch: 5| Step: 5
Training loss: 2.7406190043506697
Validation loss: 2.573092575597853

Epoch: 5| Step: 6
Training loss: 2.2489585585518235
Validation loss: 2.5776249525848596

Epoch: 5| Step: 7
Training loss: 2.3602291354782587
Validation loss: 2.588219322586781

Epoch: 5| Step: 8
Training loss: 2.6455312441284202
Validation loss: 2.594002033535786

Epoch: 5| Step: 9
Training loss: 3.287153038600748
Validation loss: 2.5773891362108876

Epoch: 5| Step: 10
Training loss: 2.3844310828896464
Validation loss: 2.5531894285056183

Epoch: 5| Step: 11
Training loss: 2.6253535622953503
Validation loss: 2.5886818114220906

Epoch: 25| Step: 0
Training loss: 2.3024875291782765
Validation loss: 2.602418924675664

Epoch: 5| Step: 1
Training loss: 3.3172867934845565
Validation loss: 2.5895837218871764

Epoch: 5| Step: 2
Training loss: 2.1335916179030336
Validation loss: 2.556056209142168

Epoch: 5| Step: 3
Training loss: 2.0624334151183827
Validation loss: 2.563317800298273

Epoch: 5| Step: 4
Training loss: 2.39704780204384
Validation loss: 2.568102948788922

Epoch: 5| Step: 5
Training loss: 2.4992751978193226
Validation loss: 2.580293067451475

Epoch: 5| Step: 6
Training loss: 2.689842711178958
Validation loss: 2.554633067073181

Epoch: 5| Step: 7
Training loss: 2.635176505704512
Validation loss: 2.5917828158716194

Epoch: 5| Step: 8
Training loss: 2.6715258989315656
Validation loss: 2.5142584597706445

Epoch: 5| Step: 9
Training loss: 2.875202171846651
Validation loss: 2.5510895422517237

Epoch: 5| Step: 10
Training loss: 2.6421151555656643
Validation loss: 2.554366839210486

Epoch: 5| Step: 11
Training loss: 2.1231187459086023
Validation loss: 2.597024061482505

Epoch: 26| Step: 0
Training loss: 2.691010245324587
Validation loss: 2.561318411980052

Epoch: 5| Step: 1
Training loss: 3.3333379904396585
Validation loss: 2.548143492204205

Epoch: 5| Step: 2
Training loss: 2.191950494158468
Validation loss: 2.555803461564653

Epoch: 5| Step: 3
Training loss: 2.0878762368686887
Validation loss: 2.5804324988416347

Epoch: 5| Step: 4
Training loss: 2.3798627762543934
Validation loss: 2.5496163388147366

Epoch: 5| Step: 5
Training loss: 2.843428541186757
Validation loss: 2.557802034145748

Epoch: 5| Step: 6
Training loss: 2.3343672051357056
Validation loss: 2.5605707892477927

Epoch: 5| Step: 7
Training loss: 2.3247434905281334
Validation loss: 2.5938737985259115

Epoch: 5| Step: 8
Training loss: 2.782676502398058
Validation loss: 2.578882699462329

Epoch: 5| Step: 9
Training loss: 2.5018716481720245
Validation loss: 2.5459629797402825

Epoch: 5| Step: 10
Training loss: 2.5537210205345873
Validation loss: 2.5864579290747405

Epoch: 5| Step: 11
Training loss: 2.2100862947074513
Validation loss: 2.559175734783898

Epoch: 27| Step: 0
Training loss: 2.265378004619692
Validation loss: 2.5557636673529616

Epoch: 5| Step: 1
Training loss: 2.3503170327141736
Validation loss: 2.609625159053338

Epoch: 5| Step: 2
Training loss: 2.315902372111065
Validation loss: 2.604006818951777

Epoch: 5| Step: 3
Training loss: 2.1078785427144946
Validation loss: 2.6129051055636214

Epoch: 5| Step: 4
Training loss: 2.531473314771874
Validation loss: 2.6678426143976286

Epoch: 5| Step: 5
Training loss: 2.9784397403243137
Validation loss: 2.6999944445470474

Epoch: 5| Step: 6
Training loss: 2.4959143632356375
Validation loss: 2.643245262259851

Epoch: 5| Step: 7
Training loss: 3.1480829309012086
Validation loss: 2.6630418599193475

Epoch: 5| Step: 8
Training loss: 3.153532009868945
Validation loss: 2.6204726254984587

Epoch: 5| Step: 9
Training loss: 2.571342006997409
Validation loss: 2.605639877685568

Epoch: 5| Step: 10
Training loss: 2.9048217217110444
Validation loss: 2.5857003939779064

Epoch: 5| Step: 11
Training loss: 1.6494077024004081
Validation loss: 2.5619309615405492

Epoch: 28| Step: 0
Training loss: 2.056529216882502
Validation loss: 2.5976351361862697

Epoch: 5| Step: 1
Training loss: 2.7326007427271244
Validation loss: 2.538271294587301

Epoch: 5| Step: 2
Training loss: 2.238536454010213
Validation loss: 2.5657082570886165

Epoch: 5| Step: 3
Training loss: 2.5797570813578394
Validation loss: 2.6097202148811003

Epoch: 5| Step: 4
Training loss: 2.792879543347017
Validation loss: 2.6021074176851635

Epoch: 5| Step: 5
Training loss: 3.6526735207909433
Validation loss: 2.5886919961691017

Epoch: 5| Step: 6
Training loss: 2.566294582033579
Validation loss: 2.5783205247197984

Epoch: 5| Step: 7
Training loss: 2.7742408126344795
Validation loss: 2.5989862732286877

Epoch: 5| Step: 8
Training loss: 2.749440916623579
Validation loss: 2.620160216590599

Epoch: 5| Step: 9
Training loss: 2.0133014860013283
Validation loss: 2.5505915167649387

Epoch: 5| Step: 10
Training loss: 2.223218903616105
Validation loss: 2.5234878267322496

Epoch: 5| Step: 11
Training loss: 2.7259169199563646
Validation loss: 2.5305661035041753

Epoch: 29| Step: 0
Training loss: 2.266520671724126
Validation loss: 2.540671463807775

Epoch: 5| Step: 1
Training loss: 1.9089475212497324
Validation loss: 2.572782282595268

Epoch: 5| Step: 2
Training loss: 2.88921276339263
Validation loss: 2.540294753144168

Epoch: 5| Step: 3
Training loss: 2.9374516259938157
Validation loss: 2.5114279539617033

Epoch: 5| Step: 4
Training loss: 2.5500739666552024
Validation loss: 2.525452170786176

Epoch: 5| Step: 5
Training loss: 2.0745172375643004
Validation loss: 2.5614598671493707

Epoch: 5| Step: 6
Training loss: 2.621470394446823
Validation loss: 2.5592667915034606

Epoch: 5| Step: 7
Training loss: 2.3594312850604737
Validation loss: 2.5868365097469614

Epoch: 5| Step: 8
Training loss: 2.575955674684534
Validation loss: 2.625664857650995

Epoch: 5| Step: 9
Training loss: 3.3258260747654624
Validation loss: 2.5731596922031787

Epoch: 5| Step: 10
Training loss: 2.2304051485363443
Validation loss: 2.5852944649263603

Epoch: 5| Step: 11
Training loss: 2.1870433875770017
Validation loss: 2.54667403787608

Epoch: 30| Step: 0
Training loss: 2.542154817658311
Validation loss: 2.5699286362651406

Epoch: 5| Step: 1
Training loss: 2.2667178970980078
Validation loss: 2.5536972249758816

Epoch: 5| Step: 2
Training loss: 2.9715447371695416
Validation loss: 2.5862429842723924

Epoch: 5| Step: 3
Training loss: 2.3902540729457282
Validation loss: 2.5858383255733237

Epoch: 5| Step: 4
Training loss: 3.5561566010396906
Validation loss: 2.5498733072971387

Epoch: 5| Step: 5
Training loss: 2.376802663813292
Validation loss: 2.569038976145465

Epoch: 5| Step: 6
Training loss: 2.2974597420138436
Validation loss: 2.57260861013358

Epoch: 5| Step: 7
Training loss: 2.385790755300257
Validation loss: 2.5488565689390095

Epoch: 5| Step: 8
Training loss: 2.647320987459687
Validation loss: 2.5591764024466293

Epoch: 5| Step: 9
Training loss: 2.248046768944122
Validation loss: 2.546069277138237

Epoch: 5| Step: 10
Training loss: 1.9639464010977712
Validation loss: 2.571662107905733

Epoch: 5| Step: 11
Training loss: 2.4122322329225554
Validation loss: 2.558892311750344

Epoch: 31| Step: 0
Training loss: 2.0833507028491414
Validation loss: 2.547273592972282

Epoch: 5| Step: 1
Training loss: 3.261423282603487
Validation loss: 2.554184614297891

Epoch: 5| Step: 2
Training loss: 2.7089797104490754
Validation loss: 2.542968525376239

Epoch: 5| Step: 3
Training loss: 2.0417632125552165
Validation loss: 2.5496848117287274

Epoch: 5| Step: 4
Training loss: 3.068942553040031
Validation loss: 2.5274574651198507

Epoch: 5| Step: 5
Training loss: 2.562581316890504
Validation loss: 2.617504146266594

Epoch: 5| Step: 6
Training loss: 2.583932427700862
Validation loss: 2.540192373210966

Epoch: 5| Step: 7
Training loss: 2.3416740887977925
Validation loss: 2.525895035148552

Epoch: 5| Step: 8
Training loss: 2.882445438659359
Validation loss: 2.53605970400458

Epoch: 5| Step: 9
Training loss: 2.312984312737386
Validation loss: 2.5571021199469945

Epoch: 5| Step: 10
Training loss: 2.1038038362719207
Validation loss: 2.532101742960679

Epoch: 5| Step: 11
Training loss: 1.579038299067079
Validation loss: 2.58367429810927

Epoch: 32| Step: 0
Training loss: 2.4901926313903235
Validation loss: 2.5541437583371036

Epoch: 5| Step: 1
Training loss: 2.3121360286175947
Validation loss: 2.5660245428628667

Epoch: 5| Step: 2
Training loss: 2.6264121480613767
Validation loss: 2.580830304845409

Epoch: 5| Step: 3
Training loss: 2.717067329333476
Validation loss: 2.5984571020717797

Epoch: 5| Step: 4
Training loss: 2.2128240401914296
Validation loss: 2.580933799804124

Epoch: 5| Step: 5
Training loss: 1.5102300682122891
Validation loss: 2.565290110604956

Epoch: 5| Step: 6
Training loss: 2.5017370864780375
Validation loss: 2.591125895872361

Epoch: 5| Step: 7
Training loss: 3.0044830522495682
Validation loss: 2.6183172719678534

Epoch: 5| Step: 8
Training loss: 3.2896661272475307
Validation loss: 2.569512409880724

Epoch: 5| Step: 9
Training loss: 2.42642247667401
Validation loss: 2.529924720792638

Epoch: 5| Step: 10
Training loss: 2.240853899937856
Validation loss: 2.612139526089729

Epoch: 5| Step: 11
Training loss: 1.8985844308013662
Validation loss: 2.548845897627213

Epoch: 33| Step: 0
Training loss: 2.851415008493008
Validation loss: 2.5371410317975154

Epoch: 5| Step: 1
Training loss: 2.0748268284981317
Validation loss: 2.5418567912069623

Epoch: 5| Step: 2
Training loss: 2.5834639321406976
Validation loss: 2.5790382039478668

Epoch: 5| Step: 3
Training loss: 2.145358455913116
Validation loss: 2.538393032140483

Epoch: 5| Step: 4
Training loss: 2.1398541252828975
Validation loss: 2.508712618900479

Epoch: 5| Step: 5
Training loss: 1.9548350058198358
Validation loss: 2.578119524554979

Epoch: 5| Step: 6
Training loss: 3.1619560105547175
Validation loss: 2.5323951116847514

Epoch: 5| Step: 7
Training loss: 2.7433576994223667
Validation loss: 2.5387347533142113

Epoch: 5| Step: 8
Training loss: 2.6625019771944682
Validation loss: 2.550273725989812

Epoch: 5| Step: 9
Training loss: 2.183157179426293
Validation loss: 2.565524835834471

Epoch: 5| Step: 10
Training loss: 2.857419038094542
Validation loss: 2.552418814556451

Epoch: 5| Step: 11
Training loss: 2.707131652291206
Validation loss: 2.562078953088513

Epoch: 34| Step: 0
Training loss: 3.1092667297222376
Validation loss: 2.6038612962335654

Epoch: 5| Step: 1
Training loss: 2.9469374972660973
Validation loss: 2.555198353933096

Epoch: 5| Step: 2
Training loss: 2.114922807876535
Validation loss: 2.5916748248111916

Epoch: 5| Step: 3
Training loss: 2.197609673585212
Validation loss: 2.5633163314878877

Epoch: 5| Step: 4
Training loss: 2.701660641618992
Validation loss: 2.5911930533600134

Epoch: 5| Step: 5
Training loss: 2.0263411848858763
Validation loss: 2.581421199567728

Epoch: 5| Step: 6
Training loss: 1.8789797191570914
Validation loss: 2.5823667022669263

Epoch: 5| Step: 7
Training loss: 2.720307441194006
Validation loss: 2.5993095911034136

Epoch: 5| Step: 8
Training loss: 1.9906884032112633
Validation loss: 2.5293515743197954

Epoch: 5| Step: 9
Training loss: 2.9182445799183205
Validation loss: 2.587494372854702

Epoch: 5| Step: 10
Training loss: 2.32110725945875
Validation loss: 2.574577121361851

Epoch: 5| Step: 11
Training loss: 3.2133131311765584
Validation loss: 2.544112601121721

Epoch: 35| Step: 0
Training loss: 2.3909450142288247
Validation loss: 2.6074808102160967

Epoch: 5| Step: 1
Training loss: 2.33197941554752
Validation loss: 2.571048152043618

Epoch: 5| Step: 2
Training loss: 3.1970964968439466
Validation loss: 2.5711856197765504

Epoch: 5| Step: 3
Training loss: 2.3635297155995767
Validation loss: 2.641578411910455

Epoch: 5| Step: 4
Training loss: 1.6861245943326744
Validation loss: 2.578599269669719

Epoch: 5| Step: 5
Training loss: 2.2295340000664696
Validation loss: 2.599052818634702

Epoch: 5| Step: 6
Training loss: 2.6894058744203977
Validation loss: 2.63947551018319

Epoch: 5| Step: 7
Training loss: 2.2509316528871413
Validation loss: 2.5872184293074443

Epoch: 5| Step: 8
Training loss: 3.104694466662258
Validation loss: 2.536354937525023

Epoch: 5| Step: 9
Training loss: 3.009862107321585
Validation loss: 2.4935028208621097

Epoch: 5| Step: 10
Training loss: 1.8377141918502273
Validation loss: 2.551824176371604

Epoch: 5| Step: 11
Training loss: 2.4509193563902345
Validation loss: 2.567345318206685

Epoch: 36| Step: 0
Training loss: 2.0032862843824453
Validation loss: 2.531967548030821

Epoch: 5| Step: 1
Training loss: 2.505859375
Validation loss: 2.6171609165492713

Epoch: 5| Step: 2
Training loss: 2.2531643973833204
Validation loss: 2.572120444203457

Epoch: 5| Step: 3
Training loss: 2.132252490403238
Validation loss: 2.5316429382636985

Epoch: 5| Step: 4
Training loss: 2.7243988283904494
Validation loss: 2.5328959521681624

Epoch: 5| Step: 5
Training loss: 2.647336297670061
Validation loss: 2.5499458833948396

Epoch: 5| Step: 6
Training loss: 2.484539866225292
Validation loss: 2.546665998281105

Epoch: 5| Step: 7
Training loss: 2.930481337762054
Validation loss: 2.558821324912139

Epoch: 5| Step: 8
Training loss: 2.344815024947747
Validation loss: 2.542916695354507

Epoch: 5| Step: 9
Training loss: 2.2580467023454465
Validation loss: 2.557657220873556

Epoch: 5| Step: 10
Training loss: 2.839436539913646
Validation loss: 2.529487636054364

Epoch: 5| Step: 11
Training loss: 3.19054999940544
Validation loss: 2.529250430511632

Epoch: 37| Step: 0
Training loss: 2.4135626117937328
Validation loss: 2.568812940650941

Epoch: 5| Step: 1
Training loss: 2.698434718604938
Validation loss: 2.55830086543535

Epoch: 5| Step: 2
Training loss: 2.2680998866440336
Validation loss: 2.500757321250495

Epoch: 5| Step: 3
Training loss: 2.5940880612592685
Validation loss: 2.5313425007939534

Epoch: 5| Step: 4
Training loss: 3.194513421534837
Validation loss: 2.5038963988175316

Epoch: 5| Step: 5
Training loss: 1.7649802997343391
Validation loss: 2.512791022563276

Epoch: 5| Step: 6
Training loss: 2.4601665924232825
Validation loss: 2.4867326917226538

Epoch: 5| Step: 7
Training loss: 1.7211544211451837
Validation loss: 2.5162266274453358

Epoch: 5| Step: 8
Training loss: 2.96057513191176
Validation loss: 2.5207675749238496

Epoch: 5| Step: 9
Training loss: 2.250733361997614
Validation loss: 2.4965353840225877

Epoch: 5| Step: 10
Training loss: 2.2611129555576226
Validation loss: 2.5723407399364753

Epoch: 5| Step: 11
Training loss: 3.591186670740128
Validation loss: 2.538330510582067

Epoch: 38| Step: 0
Training loss: 3.0291778718163056
Validation loss: 2.5211807745843964

Epoch: 5| Step: 1
Training loss: 2.409818505065466
Validation loss: 2.518450214792366

Epoch: 5| Step: 2
Training loss: 2.46303408490044
Validation loss: 2.538976665904439

Epoch: 5| Step: 3
Training loss: 2.12541564915457
Validation loss: 2.555367086781581

Epoch: 5| Step: 4
Training loss: 2.514291255731173
Validation loss: 2.543050437509815

Epoch: 5| Step: 5
Training loss: 2.281359317198297
Validation loss: 2.6169422395332895

Epoch: 5| Step: 6
Training loss: 2.2627509467966207
Validation loss: 2.540513593304245

Epoch: 5| Step: 7
Training loss: 2.170757307989921
Validation loss: 2.520565922532952

Epoch: 5| Step: 8
Training loss: 2.7114322441761844
Validation loss: 2.617777140227035

Epoch: 5| Step: 9
Training loss: 2.4255997103026625
Validation loss: 2.5522378109221666

Epoch: 5| Step: 10
Training loss: 2.7306845911202635
Validation loss: 2.5797934036959624

Epoch: 5| Step: 11
Training loss: 1.775488117424261
Validation loss: 2.575142344997057

Epoch: 39| Step: 0
Training loss: 1.6789845969769903
Validation loss: 2.5377150261259396

Epoch: 5| Step: 1
Training loss: 2.6881488637745226
Validation loss: 2.559837551494797

Epoch: 5| Step: 2
Training loss: 1.848001137415218
Validation loss: 2.6038596309223982

Epoch: 5| Step: 3
Training loss: 2.639346744459279
Validation loss: 2.5753263715739125

Epoch: 5| Step: 4
Training loss: 2.769304919982205
Validation loss: 2.5694046620276256

Epoch: 5| Step: 5
Training loss: 2.9509453374129815
Validation loss: 2.661597232715147

Epoch: 5| Step: 6
Training loss: 2.9246396943236905
Validation loss: 2.6600743905279987

Epoch: 5| Step: 7
Training loss: 2.524452406925903
Validation loss: 2.5951269585270524

Epoch: 5| Step: 8
Training loss: 2.642801324704131
Validation loss: 2.606638884404449

Epoch: 5| Step: 9
Training loss: 2.2839450332387505
Validation loss: 2.5449001831473033

Epoch: 5| Step: 10
Training loss: 2.174333566751701
Validation loss: 2.548787547600904

Epoch: 5| Step: 11
Training loss: 2.6313116397116443
Validation loss: 2.5341510455032563

Epoch: 40| Step: 0
Training loss: 2.490784444455737
Validation loss: 2.539032976027768

Epoch: 5| Step: 1
Training loss: 2.379334960793006
Validation loss: 2.5620124050609845

Epoch: 5| Step: 2
Training loss: 1.9037445989019932
Validation loss: 2.5238550468614482

Epoch: 5| Step: 3
Training loss: 2.619331415496898
Validation loss: 2.5539556810277246

Epoch: 5| Step: 4
Training loss: 3.009441618216673
Validation loss: 2.574085488774991

Epoch: 5| Step: 5
Training loss: 2.3561427731994926
Validation loss: 2.587726976510589

Epoch: 5| Step: 6
Training loss: 2.40088272947822
Validation loss: 2.5398201618959066

Epoch: 5| Step: 7
Training loss: 2.36384885923165
Validation loss: 2.4934876417877896

Epoch: 5| Step: 8
Training loss: 2.9202355666050868
Validation loss: 2.559941867997842

Epoch: 5| Step: 9
Training loss: 2.377080207129475
Validation loss: 2.5448333517952704

Epoch: 5| Step: 10
Training loss: 2.1478199574121684
Validation loss: 2.552415333127332

Epoch: 5| Step: 11
Training loss: 2.6676327227078542
Validation loss: 2.5563202364101048

Epoch: 41| Step: 0
Training loss: 2.483806329097067
Validation loss: 2.5752424482444645

Epoch: 5| Step: 1
Training loss: 2.2961117261226405
Validation loss: 2.585534973931681

Epoch: 5| Step: 2
Training loss: 2.0065137172888843
Validation loss: 2.5396139005887326

Epoch: 5| Step: 3
Training loss: 3.1749293462145878
Validation loss: 2.6079108895250376

Epoch: 5| Step: 4
Training loss: 2.1950457536451724
Validation loss: 2.5945253132629014

Epoch: 5| Step: 5
Training loss: 3.194801047134849
Validation loss: 2.5500557467968012

Epoch: 5| Step: 6
Training loss: 2.41799014672101
Validation loss: 2.486503556927913

Epoch: 5| Step: 7
Training loss: 1.9665535678778883
Validation loss: 2.5692577961554126

Epoch: 5| Step: 8
Training loss: 2.4599770261110447
Validation loss: 2.519931974259201

Epoch: 5| Step: 9
Training loss: 2.4183564252778407
Validation loss: 2.5584805218440527

Epoch: 5| Step: 10
Training loss: 2.0495843791655264
Validation loss: 2.546052987309948

Epoch: 5| Step: 11
Training loss: 2.927610754822179
Validation loss: 2.527798552276378

Epoch: 42| Step: 0
Training loss: 1.8718118902148937
Validation loss: 2.5318761647614973

Epoch: 5| Step: 1
Training loss: 2.464561095557948
Validation loss: 2.5228992986566894

Epoch: 5| Step: 2
Training loss: 2.3371223838274506
Validation loss: 2.5701999388438606

Epoch: 5| Step: 3
Training loss: 2.4819729306745217
Validation loss: 2.521838229579793

Epoch: 5| Step: 4
Training loss: 2.5241999463414357
Validation loss: 2.602155888866566

Epoch: 5| Step: 5
Training loss: 1.9785524385572832
Validation loss: 2.5830081317134628

Epoch: 5| Step: 6
Training loss: 2.5710052206074705
Validation loss: 2.515602463173071

Epoch: 5| Step: 7
Training loss: 2.7880449763026554
Validation loss: 2.531091253381179

Epoch: 5| Step: 8
Training loss: 2.511191969904072
Validation loss: 2.5406637923128392

Epoch: 5| Step: 9
Training loss: 2.822903950980476
Validation loss: 2.56398364280367

Epoch: 5| Step: 10
Training loss: 2.273959699610814
Validation loss: 2.5704196571344657

Epoch: 5| Step: 11
Training loss: 2.4880314436578423
Validation loss: 2.5359623885642337

Epoch: 43| Step: 0
Training loss: 1.7068343059838866
Validation loss: 2.549616151791627

Epoch: 5| Step: 1
Training loss: 2.286727182720081
Validation loss: 2.5553970634740644

Epoch: 5| Step: 2
Training loss: 3.056561063760877
Validation loss: 2.5980237734286646

Epoch: 5| Step: 3
Training loss: 2.62719834328296
Validation loss: 2.5852086518119126

Epoch: 5| Step: 4
Training loss: 2.4247696835975274
Validation loss: 2.669078396939398

Epoch: 5| Step: 5
Training loss: 2.3668203541280017
Validation loss: 2.6728160271810313

Epoch: 5| Step: 6
Training loss: 2.7111138278221456
Validation loss: 2.6579045098323695

Epoch: 5| Step: 7
Training loss: 2.1539247663530143
Validation loss: 2.6788087039637976

Epoch: 5| Step: 8
Training loss: 2.7127203012474936
Validation loss: 2.5525605916743994

Epoch: 5| Step: 9
Training loss: 2.097063545584919
Validation loss: 2.594603865228633

Epoch: 5| Step: 10
Training loss: 2.5555870035788897
Validation loss: 2.5376816383897096

Epoch: 5| Step: 11
Training loss: 1.8709960784585573
Validation loss: 2.5659881030514544

Epoch: 44| Step: 0
Training loss: 2.453121403977012
Validation loss: 2.584233689817289

Epoch: 5| Step: 1
Training loss: 2.1588324962551417
Validation loss: 2.5019846231034806

Epoch: 5| Step: 2
Training loss: 2.5962099107302032
Validation loss: 2.5757166855842226

Epoch: 5| Step: 3
Training loss: 2.495003571135081
Validation loss: 2.5610781733582404

Epoch: 5| Step: 4
Training loss: 2.584871285515607
Validation loss: 2.5439016659361076

Epoch: 5| Step: 5
Training loss: 2.6072409120548166
Validation loss: 2.5842134658166223

Epoch: 5| Step: 6
Training loss: 2.51063079764941
Validation loss: 2.5459711073968823

Epoch: 5| Step: 7
Training loss: 2.2757571207660288
Validation loss: 2.500149003197905

Epoch: 5| Step: 8
Training loss: 2.199765396614007
Validation loss: 2.6021583378846915

Epoch: 5| Step: 9
Training loss: 2.527172241995082
Validation loss: 2.5681953484165247

Epoch: 5| Step: 10
Training loss: 2.567582277578701
Validation loss: 2.512321858551398

Epoch: 5| Step: 11
Training loss: 2.62362544083495
Validation loss: 2.5190243785330177

Epoch: 45| Step: 0
Training loss: 2.0655520427706593
Validation loss: 2.49891742870526

Epoch: 5| Step: 1
Training loss: 3.0523008891782957
Validation loss: 2.6237353313545477

Epoch: 5| Step: 2
Training loss: 2.179362939440758
Validation loss: 2.5605371680173916

Epoch: 5| Step: 3
Training loss: 2.622820721589193
Validation loss: 2.674621323197196

Epoch: 5| Step: 4
Training loss: 2.2249113686728528
Validation loss: 2.6781289560948296

Epoch: 5| Step: 5
Training loss: 2.23403053029235
Validation loss: 2.7495607906788844

Epoch: 5| Step: 6
Training loss: 2.8873569469603435
Validation loss: 2.6387379014728563

Epoch: 5| Step: 7
Training loss: 2.5807330262700283
Validation loss: 2.670706048948696

Epoch: 5| Step: 8
Training loss: 2.874621822528764
Validation loss: 2.6262611962185223

Epoch: 5| Step: 9
Training loss: 1.777584386611752
Validation loss: 2.5770893309381298

Epoch: 5| Step: 10
Training loss: 2.677250412849311
Validation loss: 2.579128128024717

Epoch: 5| Step: 11
Training loss: 1.3157406717586198
Validation loss: 2.5938820977640797

Epoch: 46| Step: 0
Training loss: 2.2513934165265304
Validation loss: 2.5661805671543676

Epoch: 5| Step: 1
Training loss: 2.3828304102490314
Validation loss: 2.553530237479842

Epoch: 5| Step: 2
Training loss: 2.2739962910309055
Validation loss: 2.569748577957114

Epoch: 5| Step: 3
Training loss: 2.8014422585022465
Validation loss: 2.5163879974976022

Epoch: 5| Step: 4
Training loss: 2.5577808748689193
Validation loss: 2.5502895350575847

Epoch: 5| Step: 5
Training loss: 2.232493855808599
Validation loss: 2.5344075614383414

Epoch: 5| Step: 6
Training loss: 2.575734828059748
Validation loss: 2.5606920291854096

Epoch: 5| Step: 7
Training loss: 2.6679141484449795
Validation loss: 2.525650829216779

Epoch: 5| Step: 8
Training loss: 2.622272800462447
Validation loss: 2.540767879464588

Epoch: 5| Step: 9
Training loss: 2.423294832517578
Validation loss: 2.5783705276559212

Epoch: 5| Step: 10
Training loss: 2.039705489348001
Validation loss: 2.5070076281674063

Epoch: 5| Step: 11
Training loss: 2.036823783012874
Validation loss: 2.560510093411207

Epoch: 47| Step: 0
Training loss: 2.5038326448997688
Validation loss: 2.5667600421723313

Epoch: 5| Step: 1
Training loss: 2.9468732589117836
Validation loss: 2.5539706193559093

Epoch: 5| Step: 2
Training loss: 2.37981348637229
Validation loss: 2.622573063659617

Epoch: 5| Step: 3
Training loss: 2.2259031155967217
Validation loss: 2.551761234484078

Epoch: 5| Step: 4
Training loss: 2.3181514245011052
Validation loss: 2.555045677297453

Epoch: 5| Step: 5
Training loss: 2.64994683482263
Validation loss: 2.607766468456277

Epoch: 5| Step: 6
Training loss: 2.852601413378392
Validation loss: 2.555967331159638

Epoch: 5| Step: 7
Training loss: 1.9450717761762775
Validation loss: 2.5657140029480403

Epoch: 5| Step: 8
Training loss: 2.174685080519102
Validation loss: 2.5627757404805904

Epoch: 5| Step: 9
Training loss: 2.0400242200049457
Validation loss: 2.532555365213002

Epoch: 5| Step: 10
Training loss: 2.0097588630762706
Validation loss: 2.538426844917203

Epoch: 5| Step: 11
Training loss: 2.6854029613428256
Validation loss: 2.6242664424813222

Epoch: 48| Step: 0
Training loss: 2.7655645676384233
Validation loss: 2.5149234836117347

Epoch: 5| Step: 1
Training loss: 1.8144129819504804
Validation loss: 2.558183888617246

Epoch: 5| Step: 2
Training loss: 2.7900238517370632
Validation loss: 2.5517875863328694

Epoch: 5| Step: 3
Training loss: 2.2279299100880925
Validation loss: 2.5560405892587945

Epoch: 5| Step: 4
Training loss: 2.579027237664377
Validation loss: 2.541830684237102

Epoch: 5| Step: 5
Training loss: 2.429969599498332
Validation loss: 2.4681829372653397

Epoch: 5| Step: 6
Training loss: 2.834102488816214
Validation loss: 2.5650501161615655

Epoch: 5| Step: 7
Training loss: 1.90067062589103
Validation loss: 2.527909704376621

Epoch: 5| Step: 8
Training loss: 2.3953546349887445
Validation loss: 2.5503631140035843

Epoch: 5| Step: 9
Training loss: 2.475917888709575
Validation loss: 2.545578519354831

Epoch: 5| Step: 10
Training loss: 1.8301519910303123
Validation loss: 2.5411389980913572

Epoch: 5| Step: 11
Training loss: 2.405789219718626
Validation loss: 2.605513279204056

Epoch: 49| Step: 0
Training loss: 2.957551414062195
Validation loss: 2.5881772747470504

Epoch: 5| Step: 1
Training loss: 2.884865791994037
Validation loss: 2.5161352686553955

Epoch: 5| Step: 2
Training loss: 2.448015468037424
Validation loss: 2.5503141862567418

Epoch: 5| Step: 3
Training loss: 2.955693172734216
Validation loss: 2.590471827323821

Epoch: 5| Step: 4
Training loss: 1.6373436219770219
Validation loss: 2.5610539768086262

Epoch: 5| Step: 5
Training loss: 2.237984895643275
Validation loss: 2.5442722415562264

Epoch: 5| Step: 6
Training loss: 2.3417789563534646
Validation loss: 2.52571099597858

Epoch: 5| Step: 7
Training loss: 2.1443468024974655
Validation loss: 2.591131635208464

Epoch: 5| Step: 8
Training loss: 1.7537122589422436
Validation loss: 2.549240016663444

Epoch: 5| Step: 9
Training loss: 2.036656857023116
Validation loss: 2.5158610736656515

Epoch: 5| Step: 10
Training loss: 2.289985756975549
Validation loss: 2.5417254544062193

Epoch: 5| Step: 11
Training loss: 4.293647136316767
Validation loss: 2.5680073002419834

Epoch: 50| Step: 0
Training loss: 1.8037399512716223
Validation loss: 2.4926478400238286

Epoch: 5| Step: 1
Training loss: 2.918856606997321
Validation loss: 2.595650554935035

Epoch: 5| Step: 2
Training loss: 2.437621676024564
Validation loss: 2.5472095051404886

Epoch: 5| Step: 3
Training loss: 2.551905899626892
Validation loss: 2.480102940616136

Epoch: 5| Step: 4
Training loss: 2.716224900896418
Validation loss: 2.5460446102007848

Epoch: 5| Step: 5
Training loss: 2.802309946494921
Validation loss: 2.548764372475315

Epoch: 5| Step: 6
Training loss: 1.6996877439610594
Validation loss: 2.4730997918147066

Epoch: 5| Step: 7
Training loss: 1.9813711303842576
Validation loss: 2.5775782612297697

Epoch: 5| Step: 8
Training loss: 2.4562352381449504
Validation loss: 2.5724256345530443

Epoch: 5| Step: 9
Training loss: 2.2478896946978533
Validation loss: 2.4955832526981365

Epoch: 5| Step: 10
Training loss: 1.900339061198256
Validation loss: 2.5868941282658975

Epoch: 5| Step: 11
Training loss: 3.5918153282135408
Validation loss: 2.4948446882715265

Epoch: 51| Step: 0
Training loss: 1.8852352525746088
Validation loss: 2.6021357335316404

Epoch: 5| Step: 1
Training loss: 2.3742966865383077
Validation loss: 2.58999361781214

Epoch: 5| Step: 2
Training loss: 2.516759012645902
Validation loss: 2.535522536358471

Epoch: 5| Step: 3
Training loss: 2.5893316668862907
Validation loss: 2.5030162239172498

Epoch: 5| Step: 4
Training loss: 2.3283997443996722
Validation loss: 2.5431905826472643

Epoch: 5| Step: 5
Training loss: 2.224604016331891
Validation loss: 2.5296767215919327

Epoch: 5| Step: 6
Training loss: 2.084347694138047
Validation loss: 2.5447454832968663

Epoch: 5| Step: 7
Training loss: 2.4558154859909385
Validation loss: 2.5209456542241675

Epoch: 5| Step: 8
Training loss: 2.8262933521750404
Validation loss: 2.560707771993879

Epoch: 5| Step: 9
Training loss: 2.872897664856306
Validation loss: 2.5577039107954342

Epoch: 5| Step: 10
Training loss: 2.3367808168892608
Validation loss: 2.5757776883792673

Epoch: 5| Step: 11
Training loss: 1.632415431170355
Validation loss: 2.5942604336354314

Epoch: 52| Step: 0
Training loss: 2.0696610487443237
Validation loss: 2.590518330386162

Epoch: 5| Step: 1
Training loss: 3.1489386147905836
Validation loss: 2.527173826154636

Epoch: 5| Step: 2
Training loss: 2.978768720035743
Validation loss: 2.5171265632425124

Epoch: 5| Step: 3
Training loss: 1.79727055715387
Validation loss: 2.490609926316146

Epoch: 5| Step: 4
Training loss: 1.847445002086959
Validation loss: 2.51705437483219

Epoch: 5| Step: 5
Training loss: 2.1440727146685425
Validation loss: 2.517501869358807

Epoch: 5| Step: 6
Training loss: 2.829388583828807
Validation loss: 2.577582766606638

Epoch: 5| Step: 7
Training loss: 2.6056832335349958
Validation loss: 2.5466336758105252

Epoch: 5| Step: 8
Training loss: 1.8128638724400046
Validation loss: 2.5244416993508034

Epoch: 5| Step: 9
Training loss: 2.6887996103985046
Validation loss: 2.5758127921968033

Epoch: 5| Step: 10
Training loss: 1.8001994684748124
Validation loss: 2.536188355372447

Epoch: 5| Step: 11
Training loss: 2.5741525273929375
Validation loss: 2.5265831724133876

Epoch: 53| Step: 0
Training loss: 2.4718898652180727
Validation loss: 2.5246650261155508

Epoch: 5| Step: 1
Training loss: 2.4807668912236207
Validation loss: 2.557921948942961

Epoch: 5| Step: 2
Training loss: 1.9704419086743474
Validation loss: 2.59405523442149

Epoch: 5| Step: 3
Training loss: 2.6063507280164044
Validation loss: 2.545257967744696

Epoch: 5| Step: 4
Training loss: 2.4800286811277625
Validation loss: 2.4625426875285665

Epoch: 5| Step: 5
Training loss: 2.681993387667863
Validation loss: 2.545792566109343

Epoch: 5| Step: 6
Training loss: 1.7755824490060674
Validation loss: 2.528038943397422

Epoch: 5| Step: 7
Training loss: 2.806634508735507
Validation loss: 2.5372702861030927

Epoch: 5| Step: 8
Training loss: 1.9476707289639938
Validation loss: 2.511559192104233

Epoch: 5| Step: 9
Training loss: 2.5622272811539
Validation loss: 2.5556614464841307

Epoch: 5| Step: 10
Training loss: 2.026536255183459
Validation loss: 2.57443183167535

Epoch: 5| Step: 11
Training loss: 0.7512824300027853
Validation loss: 2.6672350357250396

Epoch: 54| Step: 0
Training loss: 2.1315135982973605
Validation loss: 2.588011874831283

Epoch: 5| Step: 1
Training loss: 1.9119311864352801
Validation loss: 2.569430345777259

Epoch: 5| Step: 2
Training loss: 2.804522666231545
Validation loss: 2.5940291587709856

Epoch: 5| Step: 3
Training loss: 1.9776156789749157
Validation loss: 2.558104028013896

Epoch: 5| Step: 4
Training loss: 2.61853684898498
Validation loss: 2.5749245478245064

Epoch: 5| Step: 5
Training loss: 2.272047214198812
Validation loss: 2.563671038320059

Epoch: 5| Step: 6
Training loss: 2.8554665791181044
Validation loss: 2.5790089989406932

Epoch: 5| Step: 7
Training loss: 1.8756336413053816
Validation loss: 2.520848078461286

Epoch: 5| Step: 8
Training loss: 2.6955332790012303
Validation loss: 2.5960091935946696

Epoch: 5| Step: 9
Training loss: 2.0320904680222904
Validation loss: 2.550241729710453

Epoch: 5| Step: 10
Training loss: 2.2283250759012656
Validation loss: 2.5862845795846976

Epoch: 5| Step: 11
Training loss: 4.1072098862764195
Validation loss: 2.5050387724967775

Epoch: 55| Step: 0
Training loss: 1.9440974841812533
Validation loss: 2.5114224557253446

Epoch: 5| Step: 1
Training loss: 2.5065662935972783
Validation loss: 2.472384361035287

Epoch: 5| Step: 2
Training loss: 2.84667533232943
Validation loss: 2.528665086153688

Epoch: 5| Step: 3
Training loss: 2.0903163482498286
Validation loss: 2.590970311697663

Epoch: 5| Step: 4
Training loss: 2.4108314001306597
Validation loss: 2.5009314748842484

Epoch: 5| Step: 5
Training loss: 2.9030677025995217
Validation loss: 2.520783437019638

Epoch: 5| Step: 6
Training loss: 2.051153472544687
Validation loss: 2.536565963738366

Epoch: 5| Step: 7
Training loss: 2.1295749559003205
Validation loss: 2.5303438197223374

Epoch: 5| Step: 8
Training loss: 2.341350293310227
Validation loss: 2.582804107806231

Epoch: 5| Step: 9
Training loss: 2.230358969530485
Validation loss: 2.5793269158982146

Epoch: 5| Step: 10
Training loss: 2.4842707774055532
Validation loss: 2.568973594487998

Epoch: 5| Step: 11
Training loss: 1.9667520830495666
Validation loss: 2.5254053369631007

Epoch: 56| Step: 0
Training loss: 1.6205625835834885
Validation loss: 2.612947538667246

Epoch: 5| Step: 1
Training loss: 2.1937626156349106
Validation loss: 2.5395806473448403

Epoch: 5| Step: 2
Training loss: 2.243590869414218
Validation loss: 2.558848027219938

Epoch: 5| Step: 3
Training loss: 1.8530510821725528
Validation loss: 2.6217722272830697

Epoch: 5| Step: 4
Training loss: 2.427447595944079
Validation loss: 2.630597398642891

Epoch: 5| Step: 5
Training loss: 2.3669763854911303
Validation loss: 2.606575625437297

Epoch: 5| Step: 6
Training loss: 2.847335064727226
Validation loss: 2.5622198680562858

Epoch: 5| Step: 7
Training loss: 2.4617900037849685
Validation loss: 2.5384391841204246

Epoch: 5| Step: 8
Training loss: 2.8853027835410896
Validation loss: 2.568117261336324

Epoch: 5| Step: 9
Training loss: 2.241950364814854
Validation loss: 2.5840970892049566

Epoch: 5| Step: 10
Training loss: 2.548842623731512
Validation loss: 2.5310215670331044

Epoch: 5| Step: 11
Training loss: 1.574582647098184
Validation loss: 2.5446324138697944

Epoch: 57| Step: 0
Training loss: 2.08096074107514
Validation loss: 2.53517756676002

Epoch: 5| Step: 1
Training loss: 2.1694755198127713
Validation loss: 2.5639043948694358

Epoch: 5| Step: 2
Training loss: 2.4289700838070822
Validation loss: 2.5163744289940824

Epoch: 5| Step: 3
Training loss: 2.9476708802831495
Validation loss: 2.551950584903568

Epoch: 5| Step: 4
Training loss: 2.4130717099185994
Validation loss: 2.507254707836372

Epoch: 5| Step: 5
Training loss: 1.9779928708656749
Validation loss: 2.5557190526328495

Epoch: 5| Step: 6
Training loss: 2.3118290314405976
Validation loss: 2.604553504186787

Epoch: 5| Step: 7
Training loss: 1.9879974582394906
Validation loss: 2.570682777239627

Epoch: 5| Step: 8
Training loss: 2.9287809469791664
Validation loss: 2.5296059516578753

Epoch: 5| Step: 9
Training loss: 2.2128094946996146
Validation loss: 2.543326866845584

Epoch: 5| Step: 10
Training loss: 2.380068740813705
Validation loss: 2.5402523206929164

Epoch: 5| Step: 11
Training loss: 3.0794628353610825
Validation loss: 2.6286794934058584

Epoch: 58| Step: 0
Training loss: 2.275373964698932
Validation loss: 2.560541501634878

Epoch: 5| Step: 1
Training loss: 1.9301759047716884
Validation loss: 2.5344166355185944

Epoch: 5| Step: 2
Training loss: 2.939069774888408
Validation loss: 2.477152327968822

Epoch: 5| Step: 3
Training loss: 2.2421460297368125
Validation loss: 2.519215669015506

Epoch: 5| Step: 4
Training loss: 1.8576784488193223
Validation loss: 2.4808832237808383

Epoch: 5| Step: 5
Training loss: 2.1021251279861857
Validation loss: 2.5141737485572406

Epoch: 5| Step: 6
Training loss: 2.401388831426962
Validation loss: 2.5324737000613915

Epoch: 5| Step: 7
Training loss: 2.542681465387245
Validation loss: 2.4916160450506215

Epoch: 5| Step: 8
Training loss: 2.864298599426185
Validation loss: 2.535196802630976

Epoch: 5| Step: 9
Training loss: 2.4701462672242576
Validation loss: 2.530261064364452

Epoch: 5| Step: 10
Training loss: 2.393760569576504
Validation loss: 2.5377143802189237

Epoch: 5| Step: 11
Training loss: 1.5910978502529598
Validation loss: 2.530271980916346

Epoch: 59| Step: 0
Training loss: 2.3027267132373597
Validation loss: 2.4831963108223882

Epoch: 5| Step: 1
Training loss: 2.862921178225047
Validation loss: 2.5341212977038583

Epoch: 5| Step: 2
Training loss: 2.3002682487958785
Validation loss: 2.5878587214584665

Epoch: 5| Step: 3
Training loss: 2.2888418878998995
Validation loss: 2.572894309921019

Epoch: 5| Step: 4
Training loss: 1.6952499167145973
Validation loss: 2.5401802673943945

Epoch: 5| Step: 5
Training loss: 2.3299686377383364
Validation loss: 2.5802711031540837

Epoch: 5| Step: 6
Training loss: 2.685949721205926
Validation loss: 2.5623568246742296

Epoch: 5| Step: 7
Training loss: 2.1013214086486314
Validation loss: 2.515073810635665

Epoch: 5| Step: 8
Training loss: 2.159368167761498
Validation loss: 2.582639706203405

Epoch: 5| Step: 9
Training loss: 2.339198359415285
Validation loss: 2.5420909407615992

Epoch: 5| Step: 10
Training loss: 2.496282865855211
Validation loss: 2.601592431263771

Epoch: 5| Step: 11
Training loss: 2.4008436031666984
Validation loss: 2.6707846032059863

Epoch: 60| Step: 0
Training loss: 2.553714765323374
Validation loss: 2.5533123184211632

Epoch: 5| Step: 1
Training loss: 2.314914370903749
Validation loss: 2.5729290862819725

Epoch: 5| Step: 2
Training loss: 1.6197232623442128
Validation loss: 2.5094560484190573

Epoch: 5| Step: 3
Training loss: 3.1992806043223014
Validation loss: 2.601359721272184

Epoch: 5| Step: 4
Training loss: 2.4635238377985824
Validation loss: 2.60537910783816

Epoch: 5| Step: 5
Training loss: 2.463462575620079
Validation loss: 2.536657048822066

Epoch: 5| Step: 6
Training loss: 1.983728378553049
Validation loss: 2.5622142384301707

Epoch: 5| Step: 7
Training loss: 2.062968692122232
Validation loss: 2.5831064668118686

Epoch: 5| Step: 8
Training loss: 2.394160131473653
Validation loss: 2.603759861007333

Epoch: 5| Step: 9
Training loss: 2.0518757542478934
Validation loss: 2.5862323558310596

Epoch: 5| Step: 10
Training loss: 1.8649522498105646
Validation loss: 2.482408489008123

Epoch: 5| Step: 11
Training loss: 2.5529413350974632
Validation loss: 2.5226778632961273

Epoch: 61| Step: 0
Training loss: 2.6727812719109707
Validation loss: 2.4940852968376737

Epoch: 5| Step: 1
Training loss: 2.3197849072028283
Validation loss: 2.5041256201982653

Epoch: 5| Step: 2
Training loss: 2.282453036874921
Validation loss: 2.5837839000282288

Epoch: 5| Step: 3
Training loss: 2.3376195458834585
Validation loss: 2.605117423388011

Epoch: 5| Step: 4
Training loss: 2.4510652678510265
Validation loss: 2.593210505101518

Epoch: 5| Step: 5
Training loss: 1.7890045289887981
Validation loss: 2.586290661916392

Epoch: 5| Step: 6
Training loss: 2.342263627803268
Validation loss: 2.5738172647364115

Epoch: 5| Step: 7
Training loss: 2.112690672085132
Validation loss: 2.6089007047458823

Epoch: 5| Step: 8
Training loss: 2.2885063459205446
Validation loss: 2.5298235684848134

Epoch: 5| Step: 9
Training loss: 2.061115609455712
Validation loss: 2.573144089278433

Epoch: 5| Step: 10
Training loss: 3.0591773868443273
Validation loss: 2.532192694391783

Epoch: 5| Step: 11
Training loss: 2.502323596693353
Validation loss: 2.5446651658137522

Epoch: 62| Step: 0
Training loss: 2.0384307701213786
Validation loss: 2.5544813813751626

Epoch: 5| Step: 1
Training loss: 2.2419860962054634
Validation loss: 2.5852819497306023

Epoch: 5| Step: 2
Training loss: 2.4014490958288452
Validation loss: 2.5248749519455282

Epoch: 5| Step: 3
Training loss: 2.605908678423556
Validation loss: 2.5717268804182964

Epoch: 5| Step: 4
Training loss: 2.4580462228822477
Validation loss: 2.591825556458623

Epoch: 5| Step: 5
Training loss: 1.8340349444322706
Validation loss: 2.561702883416192

Epoch: 5| Step: 6
Training loss: 2.237415512450471
Validation loss: 2.522762586255082

Epoch: 5| Step: 7
Training loss: 2.780313912925434
Validation loss: 2.536548978424784

Epoch: 5| Step: 8
Training loss: 2.350297454513965
Validation loss: 2.487432685497159

Epoch: 5| Step: 9
Training loss: 2.4401263246510676
Validation loss: 2.5847473094687707

Epoch: 5| Step: 10
Training loss: 2.077323816497184
Validation loss: 2.490146829898813

Epoch: 5| Step: 11
Training loss: 0.9694693570972658
Validation loss: 2.5040219122030227

Epoch: 63| Step: 0
Training loss: 2.420597354682789
Validation loss: 2.5110847024867557

Epoch: 5| Step: 1
Training loss: 2.5247030480141333
Validation loss: 2.587114559865129

Epoch: 5| Step: 2
Training loss: 2.345811877878114
Validation loss: 2.600214130497131

Epoch: 5| Step: 3
Training loss: 2.295508049307877
Validation loss: 2.567842338165504

Epoch: 5| Step: 4
Training loss: 2.0649009370480167
Validation loss: 2.536757192427123

Epoch: 5| Step: 5
Training loss: 2.67463282979757
Validation loss: 2.5683693193018335

Epoch: 5| Step: 6
Training loss: 2.1410294867618225
Validation loss: 2.528084380613735

Epoch: 5| Step: 7
Training loss: 1.9634013711876932
Validation loss: 2.587793934293331

Epoch: 5| Step: 8
Training loss: 2.279958699170201
Validation loss: 2.540935099696828

Epoch: 5| Step: 9
Training loss: 2.1812993041316733
Validation loss: 2.5916869641599827

Epoch: 5| Step: 10
Training loss: 2.4769866291373663
Validation loss: 2.5593823447954662

Epoch: 5| Step: 11
Training loss: 2.2944915238118093
Validation loss: 2.574123166615051

Epoch: 64| Step: 0
Training loss: 2.1506188987816115
Validation loss: 2.564289956520054

Epoch: 5| Step: 1
Training loss: 2.2486983878895956
Validation loss: 2.5990955008250576

Epoch: 5| Step: 2
Training loss: 2.527391766382408
Validation loss: 2.5303412874567734

Epoch: 5| Step: 3
Training loss: 2.701040004068185
Validation loss: 2.507282989470033

Epoch: 5| Step: 4
Training loss: 2.7185709225662937
Validation loss: 2.542035526859244

Epoch: 5| Step: 5
Training loss: 2.280532305969766
Validation loss: 2.521937256004825

Epoch: 5| Step: 6
Training loss: 2.1260236630634575
Validation loss: 2.509759612515344

Epoch: 5| Step: 7
Training loss: 1.3671044024690895
Validation loss: 2.600106779986927

Epoch: 5| Step: 8
Training loss: 2.517237460435638
Validation loss: 2.582994786249497

Epoch: 5| Step: 9
Training loss: 2.2814984121022412
Validation loss: 2.5023689966658083

Epoch: 5| Step: 10
Training loss: 2.3585932364878643
Validation loss: 2.5843344192055677

Epoch: 5| Step: 11
Training loss: 1.6205909776628784
Validation loss: 2.575692796253801

Epoch: 65| Step: 0
Training loss: 2.226964439118448
Validation loss: 2.4768972280953436

Epoch: 5| Step: 1
Training loss: 2.2053274414109874
Validation loss: 2.543992019781006

Epoch: 5| Step: 2
Training loss: 2.50210006246657
Validation loss: 2.5875837266432398

Epoch: 5| Step: 3
Training loss: 2.3944491050283454
Validation loss: 2.509720952567834

Epoch: 5| Step: 4
Training loss: 2.7661175477819038
Validation loss: 2.5498979547284186

Epoch: 5| Step: 5
Training loss: 2.554894768475723
Validation loss: 2.5003130239975557

Epoch: 5| Step: 6
Training loss: 2.283864130384807
Validation loss: 2.5809812271916397

Epoch: 5| Step: 7
Training loss: 2.3963415076862398
Validation loss: 2.5116892744186794

Epoch: 5| Step: 8
Training loss: 2.4868268084500436
Validation loss: 2.5742067173708927

Epoch: 5| Step: 9
Training loss: 2.094539778057809
Validation loss: 2.6002765642918173

Epoch: 5| Step: 10
Training loss: 2.113680140842736
Validation loss: 2.6295940487584426

Epoch: 5| Step: 11
Training loss: 1.0785537088503083
Validation loss: 2.6268096506487146

Epoch: 66| Step: 0
Training loss: 2.2000737264590633
Validation loss: 2.539467060430526

Epoch: 5| Step: 1
Training loss: 2.69302988007886
Validation loss: 2.6094273392535365

Epoch: 5| Step: 2
Training loss: 1.8816057825614343
Validation loss: 2.502663369856248

Epoch: 5| Step: 3
Training loss: 2.1074132768881597
Validation loss: 2.5558328112450477

Epoch: 5| Step: 4
Training loss: 2.224171743643226
Validation loss: 2.561792353481754

Epoch: 5| Step: 5
Training loss: 1.7555588580689305
Validation loss: 2.4988376617448433

Epoch: 5| Step: 6
Training loss: 2.377855291123171
Validation loss: 2.5815851477350806

Epoch: 5| Step: 7
Training loss: 3.117904083567776
Validation loss: 2.5482960736395204

Epoch: 5| Step: 8
Training loss: 1.8859501570408825
Validation loss: 2.6386167876740325

Epoch: 5| Step: 9
Training loss: 2.5397664664134885
Validation loss: 2.5455483177668086

Epoch: 5| Step: 10
Training loss: 2.506130331707023
Validation loss: 2.4936814568834853

Epoch: 5| Step: 11
Training loss: 1.908630448190377
Validation loss: 2.5250058767357353

Epoch: 67| Step: 0
Training loss: 2.070475215635481
Validation loss: 2.569866802682517

Epoch: 5| Step: 1
Training loss: 2.1949180167144413
Validation loss: 2.5624109888511875

Epoch: 5| Step: 2
Training loss: 2.1843771305537714
Validation loss: 2.5579993491804514

Epoch: 5| Step: 3
Training loss: 1.8087923999554163
Validation loss: 2.515557353371879

Epoch: 5| Step: 4
Training loss: 2.7029060760223134
Validation loss: 2.5792802823133982

Epoch: 5| Step: 5
Training loss: 2.3873779585238912
Validation loss: 2.657705764526057

Epoch: 5| Step: 6
Training loss: 2.716673485526984
Validation loss: 2.585978539363058

Epoch: 5| Step: 7
Training loss: 2.1042267315541037
Validation loss: 2.6240205451240493

Epoch: 5| Step: 8
Training loss: 2.616602043601135
Validation loss: 2.5450617394862163

Epoch: 5| Step: 9
Training loss: 1.9422631320359665
Validation loss: 2.5366892595283392

Epoch: 5| Step: 10
Training loss: 2.118404925217334
Validation loss: 2.542238426519019

Epoch: 5| Step: 11
Training loss: 2.5674425236435447
Validation loss: 2.5449224449112187

Epoch: 68| Step: 0
Training loss: 2.982301001357058
Validation loss: 2.5540349751096305

Epoch: 5| Step: 1
Training loss: 2.1019659966750126
Validation loss: 2.5525389141425494

Epoch: 5| Step: 2
Training loss: 2.206646857081503
Validation loss: 2.5931062359060877

Epoch: 5| Step: 3
Training loss: 2.6316772186602466
Validation loss: 2.5234700565973993

Epoch: 5| Step: 4
Training loss: 2.189405211061364
Validation loss: 2.5520239038100287

Epoch: 5| Step: 5
Training loss: 2.257148407417082
Validation loss: 2.5690537358978904

Epoch: 5| Step: 6
Training loss: 2.1764068525955578
Validation loss: 2.545696399292142

Epoch: 5| Step: 7
Training loss: 2.19464861514214
Validation loss: 2.5353146754814677

Epoch: 5| Step: 8
Training loss: 1.9618986289602636
Validation loss: 2.478263373197725

Epoch: 5| Step: 9
Training loss: 2.368518417431745
Validation loss: 2.5577954782064443

Epoch: 5| Step: 10
Training loss: 1.7240441369162092
Validation loss: 2.552228539416645

Epoch: 5| Step: 11
Training loss: 2.8541849697296535
Validation loss: 2.5341954421262347

Epoch: 69| Step: 0
Training loss: 2.6763842272249105
Validation loss: 2.6941292492098743

Epoch: 5| Step: 1
Training loss: 2.3038003539503626
Validation loss: 2.713811580293708

Epoch: 5| Step: 2
Training loss: 1.8752825841947411
Validation loss: 2.8147395824505335

Epoch: 5| Step: 3
Training loss: 2.2927264681810495
Validation loss: 2.8534990815421364

Epoch: 5| Step: 4
Training loss: 2.7617578571146004
Validation loss: 2.8673395745383834

Epoch: 5| Step: 5
Training loss: 2.2090803238514853
Validation loss: 2.8501986860988415

Epoch: 5| Step: 6
Training loss: 2.682766049604475
Validation loss: 2.761184644332907

Epoch: 5| Step: 7
Training loss: 2.259923456296764
Validation loss: 2.6546794848576476

Epoch: 5| Step: 8
Training loss: 2.591993081572212
Validation loss: 2.518841967075093

Epoch: 5| Step: 9
Training loss: 2.5390261603469204
Validation loss: 2.557206415955409

Epoch: 5| Step: 10
Training loss: 2.4502488301872494
Validation loss: 2.547805467946257

Epoch: 5| Step: 11
Training loss: 2.253394321635811
Validation loss: 2.5590966543357148

Epoch: 70| Step: 0
Training loss: 1.8549884375240129
Validation loss: 2.5548511612135516

Epoch: 5| Step: 1
Training loss: 2.275859368630604
Validation loss: 2.535010146999178

Epoch: 5| Step: 2
Training loss: 2.5485211066886992
Validation loss: 2.5729962631351158

Epoch: 5| Step: 3
Training loss: 2.4919067990063515
Validation loss: 2.5537477800618222

Epoch: 5| Step: 4
Training loss: 2.5757266824742993
Validation loss: 2.5523745286337256

Epoch: 5| Step: 5
Training loss: 2.018636302285417
Validation loss: 2.554088191703618

Epoch: 5| Step: 6
Training loss: 1.9543412960843893
Validation loss: 2.5726492018168203

Epoch: 5| Step: 7
Training loss: 2.0641031681417745
Validation loss: 2.490866634911603

Epoch: 5| Step: 8
Training loss: 2.5274060107526206
Validation loss: 2.584033880050285

Epoch: 5| Step: 9
Training loss: 2.2804755372498238
Validation loss: 2.5415537345269477

Epoch: 5| Step: 10
Training loss: 2.498528810589582
Validation loss: 2.6022157316729153

Epoch: 5| Step: 11
Training loss: 2.000413017542421
Validation loss: 2.592322240006037

Epoch: 71| Step: 0
Training loss: 2.1324950041270796
Validation loss: 2.6495021716834426

Epoch: 5| Step: 1
Training loss: 2.301842229538923
Validation loss: 2.5766726979011954

Epoch: 5| Step: 2
Training loss: 1.3577862367186146
Validation loss: 2.5619601944941306

Epoch: 5| Step: 3
Training loss: 2.565059686007236
Validation loss: 2.6150806506224717

Epoch: 5| Step: 4
Training loss: 2.648259429796734
Validation loss: 2.6421105647151393

Epoch: 5| Step: 5
Training loss: 2.561814844598288
Validation loss: 2.484735012960329

Epoch: 5| Step: 6
Training loss: 1.8458589679783604
Validation loss: 2.6006646654715713

Epoch: 5| Step: 7
Training loss: 2.5586298117389483
Validation loss: 2.502514996694877

Epoch: 5| Step: 8
Training loss: 2.001223428372283
Validation loss: 2.613701642582001

Epoch: 5| Step: 9
Training loss: 2.3026647969768264
Validation loss: 2.636065042723161

Epoch: 5| Step: 10
Training loss: 2.0456293407082944
Validation loss: 2.5659408495724008

Epoch: 5| Step: 11
Training loss: 2.583021565564757
Validation loss: 2.62011955337901

Epoch: 72| Step: 0
Training loss: 2.1077777608012243
Validation loss: 2.526385059153393

Epoch: 5| Step: 1
Training loss: 1.8337347573737022
Validation loss: 2.581026873593254

Epoch: 5| Step: 2
Training loss: 2.2317186050505797
Validation loss: 2.558370732884194

Epoch: 5| Step: 3
Training loss: 2.3495639152917325
Validation loss: 2.522926408721066

Epoch: 5| Step: 4
Training loss: 2.2585663378492606
Validation loss: 2.5642310320173194

Epoch: 5| Step: 5
Training loss: 2.8685287955442766
Validation loss: 2.5282986550246456

Epoch: 5| Step: 6
Training loss: 2.6824340091207004
Validation loss: 2.56312063113695

Epoch: 5| Step: 7
Training loss: 2.133094852747498
Validation loss: 2.576946054491034

Epoch: 5| Step: 8
Training loss: 2.2370582954406233
Validation loss: 2.5881148062478148

Epoch: 5| Step: 9
Training loss: 2.1552745437100693
Validation loss: 2.53171216411111

Epoch: 5| Step: 10
Training loss: 1.9849212375264036
Validation loss: 2.5743504260456147

Epoch: 5| Step: 11
Training loss: 2.117876792270686
Validation loss: 2.532440203996017

Epoch: 73| Step: 0
Training loss: 1.980614952093213
Validation loss: 2.6525870629660564

Epoch: 5| Step: 1
Training loss: 2.011400512412132
Validation loss: 2.646253212080063

Epoch: 5| Step: 2
Training loss: 2.5265853663762137
Validation loss: 2.580337869418504

Epoch: 5| Step: 3
Training loss: 2.020210904357141
Validation loss: 2.6317499697580664

Epoch: 5| Step: 4
Training loss: 2.4962790454746795
Validation loss: 2.6208400423502805

Epoch: 5| Step: 5
Training loss: 1.7299081139610892
Validation loss: 2.6469443546713314

Epoch: 5| Step: 6
Training loss: 2.3726681756406642
Validation loss: 2.616757428717134

Epoch: 5| Step: 7
Training loss: 2.498016428817833
Validation loss: 2.66427767305075

Epoch: 5| Step: 8
Training loss: 2.470498443689495
Validation loss: 2.627247385705486

Epoch: 5| Step: 9
Training loss: 2.4618847189655972
Validation loss: 2.5308743343312514

Epoch: 5| Step: 10
Training loss: 2.004237573311771
Validation loss: 2.499339632396319

Epoch: 5| Step: 11
Training loss: 2.46913337145203
Validation loss: 2.5119008264750775

Epoch: 74| Step: 0
Training loss: 2.349758736420564
Validation loss: 2.5341686486191812

Epoch: 5| Step: 1
Training loss: 2.61202721949323
Validation loss: 2.472190694587092

Epoch: 5| Step: 2
Training loss: 1.625832051221745
Validation loss: 2.570368409635739

Epoch: 5| Step: 3
Training loss: 1.8566866762440197
Validation loss: 2.5577887552441263

Epoch: 5| Step: 4
Training loss: 2.2387415760420666
Validation loss: 2.5023775596847564

Epoch: 5| Step: 5
Training loss: 3.0743636178342806
Validation loss: 2.588120133881246

Epoch: 5| Step: 6
Training loss: 1.8725554743495856
Validation loss: 2.5442035292616216

Epoch: 5| Step: 7
Training loss: 2.158855688250243
Validation loss: 2.5450977333966054

Epoch: 5| Step: 8
Training loss: 2.092924154446565
Validation loss: 2.540483521154342

Epoch: 5| Step: 9
Training loss: 1.9853872285670566
Validation loss: 2.5839322700735132

Epoch: 5| Step: 10
Training loss: 2.1279617314160264
Validation loss: 2.6287199788564344

Epoch: 5| Step: 11
Training loss: 2.5582440086286384
Validation loss: 2.559942011579995

Epoch: 75| Step: 0
Training loss: 1.8190209386835718
Validation loss: 2.5903957693471873

Epoch: 5| Step: 1
Training loss: 2.5146304231757663
Validation loss: 2.6057293335993794

Epoch: 5| Step: 2
Training loss: 2.7156496457297377
Validation loss: 2.553108878612008

Epoch: 5| Step: 3
Training loss: 1.5984690494351004
Validation loss: 2.5412705821567148

Epoch: 5| Step: 4
Training loss: 2.707922234268049
Validation loss: 2.6052036732008257

Epoch: 5| Step: 5
Training loss: 1.6796850869804616
Validation loss: 2.5452137660388825

Epoch: 5| Step: 6
Training loss: 2.507319797114529
Validation loss: 2.5509198877923787

Epoch: 5| Step: 7
Training loss: 2.016037181730867
Validation loss: 2.553897867843457

Epoch: 5| Step: 8
Training loss: 2.1801841470829135
Validation loss: 2.5485120282559452

Epoch: 5| Step: 9
Training loss: 2.303604026470848
Validation loss: 2.5825889512197784

Epoch: 5| Step: 10
Training loss: 2.0916990796904864
Validation loss: 2.5576265559947977

Epoch: 5| Step: 11
Training loss: 2.1019431978312784
Validation loss: 2.5515649865989616

Epoch: 76| Step: 0
Training loss: 2.284045453182171
Validation loss: 2.6489860544218047

Epoch: 5| Step: 1
Training loss: 2.308905514290197
Validation loss: 2.560492768384031

Epoch: 5| Step: 2
Training loss: 2.331722168751525
Validation loss: 2.6114200641479197

Epoch: 5| Step: 3
Training loss: 1.7728571677468676
Validation loss: 2.607067180230099

Epoch: 5| Step: 4
Training loss: 2.2549082943355008
Validation loss: 2.5544783869249836

Epoch: 5| Step: 5
Training loss: 2.2008153834893487
Validation loss: 2.6081732382915725

Epoch: 5| Step: 6
Training loss: 2.059343523586686
Validation loss: 2.5325740012402935

Epoch: 5| Step: 7
Training loss: 2.0801146884623893
Validation loss: 2.6216328535993463

Epoch: 5| Step: 8
Training loss: 1.8873955754578997
Validation loss: 2.59080895513544

Epoch: 5| Step: 9
Training loss: 3.0808827396056793
Validation loss: 2.58994018774058

Epoch: 5| Step: 10
Training loss: 2.2758971866052744
Validation loss: 2.5174186740885633

Epoch: 5| Step: 11
Training loss: 2.5548035014935877
Validation loss: 2.608491576719513

Epoch: 77| Step: 0
Training loss: 2.511150194902942
Validation loss: 2.649177804141309

Epoch: 5| Step: 1
Training loss: 2.2076565287166843
Validation loss: 2.6200177200703365

Epoch: 5| Step: 2
Training loss: 1.9938729729590983
Validation loss: 2.6113757497914127

Epoch: 5| Step: 3
Training loss: 2.5143100310827946
Validation loss: 2.67409377523475

Epoch: 5| Step: 4
Training loss: 2.3594459371450025
Validation loss: 2.6497623614457684

Epoch: 5| Step: 5
Training loss: 1.9486021851763942
Validation loss: 2.676967252201136

Epoch: 5| Step: 6
Training loss: 2.322088416086171
Validation loss: 2.5598197698045246

Epoch: 5| Step: 7
Training loss: 1.8066817985173123
Validation loss: 2.5505020666467413

Epoch: 5| Step: 8
Training loss: 2.5795796307678054
Validation loss: 2.5015982049303656

Epoch: 5| Step: 9
Training loss: 2.5144900966531947
Validation loss: 2.5595507164372013

Epoch: 5| Step: 10
Training loss: 2.030013896725448
Validation loss: 2.599557602364696

Epoch: 5| Step: 11
Training loss: 1.5574438303559281
Validation loss: 2.6093165568128533

Epoch: 78| Step: 0
Training loss: 2.4062122490633957
Validation loss: 2.5482608831417686

Epoch: 5| Step: 1
Training loss: 2.103250272514374
Validation loss: 2.492020612368645

Epoch: 5| Step: 2
Training loss: 2.6903283074138673
Validation loss: 2.554599006045606

Epoch: 5| Step: 3
Training loss: 1.7637600121595807
Validation loss: 2.5330678628707886

Epoch: 5| Step: 4
Training loss: 1.6655585499403553
Validation loss: 2.6224346568401007

Epoch: 5| Step: 5
Training loss: 2.3091841973757026
Validation loss: 2.568388832609903

Epoch: 5| Step: 6
Training loss: 1.8622698007965608
Validation loss: 2.6244007251541883

Epoch: 5| Step: 7
Training loss: 2.179687390617997
Validation loss: 2.580671978935014

Epoch: 5| Step: 8
Training loss: 2.61006685324803
Validation loss: 2.596217188510722

Epoch: 5| Step: 9
Training loss: 2.026304474744933
Validation loss: 2.5691483594799154

Epoch: 5| Step: 10
Training loss: 2.3968970107518945
Validation loss: 2.594937454859063

Epoch: 5| Step: 11
Training loss: 1.3303519483850732
Validation loss: 2.496618415721083

Epoch: 79| Step: 0
Training loss: 2.2357953232320873
Validation loss: 2.55501112992736

Epoch: 5| Step: 1
Training loss: 1.6597071141078963
Validation loss: 2.613113922555505

Epoch: 5| Step: 2
Training loss: 2.281349493496034
Validation loss: 2.5419902725788943

Epoch: 5| Step: 3
Training loss: 2.3152397010243804
Validation loss: 2.5877857690837183

Epoch: 5| Step: 4
Training loss: 2.690114545971375
Validation loss: 2.5729058390298163

Epoch: 5| Step: 5
Training loss: 1.5977889847587148
Validation loss: 2.5409513128666243

Epoch: 5| Step: 6
Training loss: 2.8384776443587527
Validation loss: 2.554653206380237

Epoch: 5| Step: 7
Training loss: 2.5176226343403556
Validation loss: 2.5419510378726775

Epoch: 5| Step: 8
Training loss: 1.8278794082915053
Validation loss: 2.5747812955995055

Epoch: 5| Step: 9
Training loss: 2.215606827116608
Validation loss: 2.549007330546832

Epoch: 5| Step: 10
Training loss: 2.2177650522050856
Validation loss: 2.5730484949283183

Epoch: 5| Step: 11
Training loss: 1.8305335195807242
Validation loss: 2.564339878577185

Epoch: 80| Step: 0
Training loss: 2.4174084237554174
Validation loss: 2.586813245387812

Epoch: 5| Step: 1
Training loss: 1.7304226630211312
Validation loss: 2.657259801516304

Epoch: 5| Step: 2
Training loss: 2.5085081282467434
Validation loss: 2.821224670978154

Epoch: 5| Step: 3
Training loss: 2.592487533524648
Validation loss: 2.8344781446773415

Epoch: 5| Step: 4
Training loss: 2.360045483037739
Validation loss: 2.822057805665163

Epoch: 5| Step: 5
Training loss: 1.8725651508400516
Validation loss: 2.763382571908718

Epoch: 5| Step: 6
Training loss: 1.989022826752782
Validation loss: 2.7258789805222308

Epoch: 5| Step: 7
Training loss: 1.4461887487103342
Validation loss: 2.667916758651132

Epoch: 5| Step: 8
Training loss: 2.256712543278546
Validation loss: 2.6009999374344175

Epoch: 5| Step: 9
Training loss: 2.175571506876012
Validation loss: 2.5682439935292702

Epoch: 5| Step: 10
Training loss: 2.596905271351422
Validation loss: 2.5822870894362393

Epoch: 5| Step: 11
Training loss: 2.0684045601178718
Validation loss: 2.5325521565545994

Epoch: 81| Step: 0
Training loss: 2.3254558444509255
Validation loss: 2.638657926329163

Epoch: 5| Step: 1
Training loss: 1.8393867070781118
Validation loss: 2.586066969812242

Epoch: 5| Step: 2
Training loss: 2.3365976682952216
Validation loss: 2.5632944620030877

Epoch: 5| Step: 3
Training loss: 2.227600284121429
Validation loss: 2.617562285201108

Epoch: 5| Step: 4
Training loss: 2.4171030593257408
Validation loss: 2.6347538651113673

Epoch: 5| Step: 5
Training loss: 2.381245983050305
Validation loss: 2.5920816632524866

Epoch: 5| Step: 6
Training loss: 2.6204079016354247
Validation loss: 2.5360942725522864

Epoch: 5| Step: 7
Training loss: 1.944910337249557
Validation loss: 2.519659132755393

Epoch: 5| Step: 8
Training loss: 2.0479371321759294
Validation loss: 2.5362634185741872

Epoch: 5| Step: 9
Training loss: 1.9499185716304617
Validation loss: 2.578097634218418

Epoch: 5| Step: 10
Training loss: 2.465211481149143
Validation loss: 2.6212569828816648

Epoch: 5| Step: 11
Training loss: 3.4790274464664117
Validation loss: 2.6855007024321496

Epoch: 82| Step: 0
Training loss: 2.1895362096398348
Validation loss: 2.6367485364950447

Epoch: 5| Step: 1
Training loss: 2.0377059457991993
Validation loss: 2.625904506433857

Epoch: 5| Step: 2
Training loss: 1.5200547441863685
Validation loss: 2.6097018119076365

Epoch: 5| Step: 3
Training loss: 1.860328237632649
Validation loss: 2.54084729578551

Epoch: 5| Step: 4
Training loss: 2.061657935976967
Validation loss: 2.584633101583192

Epoch: 5| Step: 5
Training loss: 2.2103736616787586
Validation loss: 2.4894055990729207

Epoch: 5| Step: 6
Training loss: 2.649780293119911
Validation loss: 2.529926075483601

Epoch: 5| Step: 7
Training loss: 1.53014364951964
Validation loss: 2.575892165478995

Epoch: 5| Step: 8
Training loss: 2.144897874299454
Validation loss: 2.5588164215647953

Epoch: 5| Step: 9
Training loss: 2.4104440971622707
Validation loss: 2.572303182742421

Epoch: 5| Step: 10
Training loss: 2.7168846308166947
Validation loss: 2.513779332359554

Epoch: 5| Step: 11
Training loss: 2.43412018251508
Validation loss: 2.5362195340541014

Epoch: 83| Step: 0
Training loss: 1.7220301452638713
Validation loss: 2.515161270143227

Epoch: 5| Step: 1
Training loss: 2.3739268237359643
Validation loss: 2.582707245903856

Epoch: 5| Step: 2
Training loss: 1.6843376197984363
Validation loss: 2.6110728368986367

Epoch: 5| Step: 3
Training loss: 2.2957900203027664
Validation loss: 2.614515027576242

Epoch: 5| Step: 4
Training loss: 2.219537407216303
Validation loss: 2.578526621660588

Epoch: 5| Step: 5
Training loss: 2.2788170159844094
Validation loss: 2.5558996134525085

Epoch: 5| Step: 6
Training loss: 2.242018211433705
Validation loss: 2.5784383641159354

Epoch: 5| Step: 7
Training loss: 1.8986051508969555
Validation loss: 2.60849410738178

Epoch: 5| Step: 8
Training loss: 2.0330022443317084
Validation loss: 2.565315692267792

Epoch: 5| Step: 9
Training loss: 1.7555403202069135
Validation loss: 2.6267544790649517

Epoch: 5| Step: 10
Training loss: 2.677703211719191
Validation loss: 2.5909027036662162

Epoch: 5| Step: 11
Training loss: 3.4741555100302484
Validation loss: 2.574818751057938

Epoch: 84| Step: 0
Training loss: 2.193622087623975
Validation loss: 2.627983350712657

Epoch: 5| Step: 1
Training loss: 2.1088629206988156
Validation loss: 2.610273149527818

Epoch: 5| Step: 2
Training loss: 2.104452195639447
Validation loss: 2.595741174101831

Epoch: 5| Step: 3
Training loss: 1.8249515474759228
Validation loss: 2.599672320086541

Epoch: 5| Step: 4
Training loss: 2.4709612443911295
Validation loss: 2.5162612315832282

Epoch: 5| Step: 5
Training loss: 2.096384924116045
Validation loss: 2.5860342044170004

Epoch: 5| Step: 6
Training loss: 2.524071203445631
Validation loss: 2.5793745576971987

Epoch: 5| Step: 7
Training loss: 2.460452464912152
Validation loss: 2.5759083128853706

Epoch: 5| Step: 8
Training loss: 2.004740699305987
Validation loss: 2.5051596088918675

Epoch: 5| Step: 9
Training loss: 1.8682044543831586
Validation loss: 2.5551692418994567

Epoch: 5| Step: 10
Training loss: 1.8878669483129553
Validation loss: 2.587205620081846

Epoch: 5| Step: 11
Training loss: 2.002676008016453
Validation loss: 2.5611458317176945

Epoch: 85| Step: 0
Training loss: 2.2595104973606794
Validation loss: 2.549996579080668

Epoch: 5| Step: 1
Training loss: 2.084969628202028
Validation loss: 2.5569495900097907

Epoch: 5| Step: 2
Training loss: 1.5041069392271773
Validation loss: 2.4848493527060587

Epoch: 5| Step: 3
Training loss: 2.2887781376674226
Validation loss: 2.547105458916117

Epoch: 5| Step: 4
Training loss: 2.7514272800646813
Validation loss: 2.563839229058267

Epoch: 5| Step: 5
Training loss: 1.8968321994936423
Validation loss: 2.5644022192530436

Epoch: 5| Step: 6
Training loss: 2.2532147647579106
Validation loss: 2.5760208058595575

Epoch: 5| Step: 7
Training loss: 2.278984094126534
Validation loss: 2.524843912524968

Epoch: 5| Step: 8
Training loss: 2.3416553546817824
Validation loss: 2.607135005414677

Epoch: 5| Step: 9
Training loss: 1.6793568130377223
Validation loss: 2.6051099340461006

Epoch: 5| Step: 10
Training loss: 1.6728993780336188
Validation loss: 2.551809461002564

Epoch: 5| Step: 11
Training loss: 1.1191326893363662
Validation loss: 2.5761266072470135

Epoch: 86| Step: 0
Training loss: 1.61173260784987
Validation loss: 2.5493539143630444

Epoch: 5| Step: 1
Training loss: 2.0715873967434226
Validation loss: 2.6377776894669367

Epoch: 5| Step: 2
Training loss: 2.064812144493324
Validation loss: 2.6060992864367023

Epoch: 5| Step: 3
Training loss: 2.67145039714876
Validation loss: 2.624875031630069

Epoch: 5| Step: 4
Training loss: 2.4512510492068724
Validation loss: 2.5553510855915578

Epoch: 5| Step: 5
Training loss: 1.8464063485487645
Validation loss: 2.5617244368669683

Epoch: 5| Step: 6
Training loss: 1.8073445366446887
Validation loss: 2.5531964242657246

Epoch: 5| Step: 7
Training loss: 2.3137671633124515
Validation loss: 2.5165644603358284

Epoch: 5| Step: 8
Training loss: 2.2870532907699763
Validation loss: 2.544953305803486

Epoch: 5| Step: 9
Training loss: 2.2550362278297134
Validation loss: 2.5526762111490697

Epoch: 5| Step: 10
Training loss: 1.600973179017713
Validation loss: 2.600632708543499

Epoch: 5| Step: 11
Training loss: 1.1469342520476937
Validation loss: 2.628675623579371

Epoch: 87| Step: 0
Training loss: 2.2340486728348634
Validation loss: 2.5974511316528686

Epoch: 5| Step: 1
Training loss: 2.4408329404980607
Validation loss: 2.531698116620291

Epoch: 5| Step: 2
Training loss: 2.112707148220175
Validation loss: 2.587031633338993

Epoch: 5| Step: 3
Training loss: 1.9605616479086405
Validation loss: 2.578410207982855

Epoch: 5| Step: 4
Training loss: 1.9047479183387421
Validation loss: 2.593885345451344

Epoch: 5| Step: 5
Training loss: 1.604832358354679
Validation loss: 2.514624900337358

Epoch: 5| Step: 6
Training loss: 1.4793115285223695
Validation loss: 2.64559233060955

Epoch: 5| Step: 7
Training loss: 1.810983352146482
Validation loss: 2.556306619491237

Epoch: 5| Step: 8
Training loss: 2.8721408725075306
Validation loss: 2.6171605616459463

Epoch: 5| Step: 9
Training loss: 2.3739610708526944
Validation loss: 2.6267634099928627

Epoch: 5| Step: 10
Training loss: 2.1552221087283927
Validation loss: 2.5407563257313512

Epoch: 5| Step: 11
Training loss: 1.806319650541299
Validation loss: 2.6199106312026053

Epoch: 88| Step: 0
Training loss: 2.0785831720753594
Validation loss: 2.5339442149226383

Epoch: 5| Step: 1
Training loss: 1.9787919208377873
Validation loss: 2.5562899110751593

Epoch: 5| Step: 2
Training loss: 2.4812419016823624
Validation loss: 2.5974054430583746

Epoch: 5| Step: 3
Training loss: 1.827436072800893
Validation loss: 2.550568451507327

Epoch: 5| Step: 4
Training loss: 2.1838206273991023
Validation loss: 2.4613417802988953

Epoch: 5| Step: 5
Training loss: 2.4741629639706306
Validation loss: 2.5669225118330052

Epoch: 5| Step: 6
Training loss: 2.0575650447979084
Validation loss: 2.5902406053770664

Epoch: 5| Step: 7
Training loss: 1.669145584366901
Validation loss: 2.563190568744002

Epoch: 5| Step: 8
Training loss: 2.1260754724780706
Validation loss: 2.572756597556488

Epoch: 5| Step: 9
Training loss: 1.848646612261951
Validation loss: 2.5584467916046956

Epoch: 5| Step: 10
Training loss: 2.331600385827703
Validation loss: 2.5858842473534964

Epoch: 5| Step: 11
Training loss: 2.4075502127761683
Validation loss: 2.595246408054659

Epoch: 89| Step: 0
Training loss: 1.3158064927707043
Validation loss: 2.6283606179812167

Epoch: 5| Step: 1
Training loss: 2.1460007043643587
Validation loss: 2.6880786960235135

Epoch: 5| Step: 2
Training loss: 1.7350299045503041
Validation loss: 2.713447566728562

Epoch: 5| Step: 3
Training loss: 2.004340230784731
Validation loss: 2.655002746215425

Epoch: 5| Step: 4
Training loss: 2.434608505077982
Validation loss: 2.6098300323890147

Epoch: 5| Step: 5
Training loss: 1.7700394664825652
Validation loss: 2.5912551409542637

Epoch: 5| Step: 6
Training loss: 2.0481924229019377
Validation loss: 2.5864937905195813

Epoch: 5| Step: 7
Training loss: 2.7580418477856647
Validation loss: 2.547869759130703

Epoch: 5| Step: 8
Training loss: 2.0490347846203063
Validation loss: 2.5356467878925546

Epoch: 5| Step: 9
Training loss: 2.2217072671708475
Validation loss: 2.5780328907551646

Epoch: 5| Step: 10
Training loss: 2.1284087273435817
Validation loss: 2.588814102562964

Epoch: 5| Step: 11
Training loss: 1.4533045668044442
Validation loss: 2.580452996934541

Epoch: 90| Step: 0
Training loss: 1.4472332537656305
Validation loss: 2.545306325287937

Epoch: 5| Step: 1
Training loss: 2.5106045875545693
Validation loss: 2.535752898756319

Epoch: 5| Step: 2
Training loss: 2.022182473058676
Validation loss: 2.6228603998339697

Epoch: 5| Step: 3
Training loss: 1.940746110709049
Validation loss: 2.570733508382769

Epoch: 5| Step: 4
Training loss: 1.7882871321901812
Validation loss: 2.588486282605554

Epoch: 5| Step: 5
Training loss: 2.3367054165045555
Validation loss: 2.6038980281870567

Epoch: 5| Step: 6
Training loss: 1.2579117256026233
Validation loss: 2.6169621764401363

Epoch: 5| Step: 7
Training loss: 2.7118531365534193
Validation loss: 2.753491100285583

Epoch: 5| Step: 8
Training loss: 2.50549399372417
Validation loss: 2.684305240167272

Epoch: 5| Step: 9
Training loss: 2.0880214839283124
Validation loss: 2.7452439810738967

Epoch: 5| Step: 10
Training loss: 2.349228419799998
Validation loss: 2.684450837242

Epoch: 5| Step: 11
Training loss: 2.5215658799641765
Validation loss: 2.644870039530018

Epoch: 91| Step: 0
Training loss: 2.0712531489991197
Validation loss: 2.590468280072082

Epoch: 5| Step: 1
Training loss: 2.34723637994814
Validation loss: 2.5600361143671715

Epoch: 5| Step: 2
Training loss: 2.0056328130173418
Validation loss: 2.6014361116945883

Epoch: 5| Step: 3
Training loss: 2.6038067276480157
Validation loss: 2.5930541686948985

Epoch: 5| Step: 4
Training loss: 1.8114831637201065
Validation loss: 2.5835913918923428

Epoch: 5| Step: 5
Training loss: 2.3278966190022716
Validation loss: 2.574621395792405

Epoch: 5| Step: 6
Training loss: 2.0132505640275205
Validation loss: 2.599888878978639

Epoch: 5| Step: 7
Training loss: 2.285560819889415
Validation loss: 2.531380080973995

Epoch: 5| Step: 8
Training loss: 1.8062535216617241
Validation loss: 2.5597076456795964

Epoch: 5| Step: 9
Training loss: 1.7006191752935813
Validation loss: 2.5982825229387863

Epoch: 5| Step: 10
Training loss: 1.6821663950603003
Validation loss: 2.5681022254229227

Epoch: 5| Step: 11
Training loss: 2.195332265744537
Validation loss: 2.5896918749497075

Epoch: 92| Step: 0
Training loss: 1.8771011659351637
Validation loss: 2.5011982867289997

Epoch: 5| Step: 1
Training loss: 2.3528624328592196
Validation loss: 2.5844059968048168

Epoch: 5| Step: 2
Training loss: 2.0737024731561835
Validation loss: 2.588744120416944

Epoch: 5| Step: 3
Training loss: 2.4145124195164174
Validation loss: 2.5630668966744032

Epoch: 5| Step: 4
Training loss: 1.8006001213815188
Validation loss: 2.5862674329786874

Epoch: 5| Step: 5
Training loss: 1.5914232810246327
Validation loss: 2.5822387242606064

Epoch: 5| Step: 6
Training loss: 2.094041263191985
Validation loss: 2.618852220663047

Epoch: 5| Step: 7
Training loss: 1.922327128005702
Validation loss: 2.60749156539689

Epoch: 5| Step: 8
Training loss: 1.7916429725085663
Validation loss: 2.6130032051702794

Epoch: 5| Step: 9
Training loss: 2.30282714242741
Validation loss: 2.5217927743647226

Epoch: 5| Step: 10
Training loss: 2.483863729974584
Validation loss: 2.6395302822639897

Epoch: 5| Step: 11
Training loss: 1.1678921983822979
Validation loss: 2.5863180927281193

Epoch: 93| Step: 0
Training loss: 1.9200720044383188
Validation loss: 2.562105978158819

Epoch: 5| Step: 1
Training loss: 1.391022443232421
Validation loss: 2.6306259553931284

Epoch: 5| Step: 2
Training loss: 1.9238591690269704
Validation loss: 2.512721658927573

Epoch: 5| Step: 3
Training loss: 1.457042295194186
Validation loss: 2.6068952964517567

Epoch: 5| Step: 4
Training loss: 2.390629986527173
Validation loss: 2.5841650059914154

Epoch: 5| Step: 5
Training loss: 2.3950457619135705
Validation loss: 2.635921099539589

Epoch: 5| Step: 6
Training loss: 1.9299912927856104
Validation loss: 2.576192125496795

Epoch: 5| Step: 7
Training loss: 2.4212500965786012
Validation loss: 2.5231209508173422

Epoch: 5| Step: 8
Training loss: 2.060867588341086
Validation loss: 2.5351126010234757

Epoch: 5| Step: 9
Training loss: 2.2325712806454447
Validation loss: 2.6026520686041485

Epoch: 5| Step: 10
Training loss: 1.761516280286075
Validation loss: 2.5621999006626135

Epoch: 5| Step: 11
Training loss: 3.4831420359185485
Validation loss: 2.5849906017531064

Epoch: 94| Step: 0
Training loss: 1.4369738901430182
Validation loss: 2.541579621549426

Epoch: 5| Step: 1
Training loss: 1.6467675161303148
Validation loss: 2.5940204617230784

Epoch: 5| Step: 2
Training loss: 2.6032301681174914
Validation loss: 2.689335798568412

Epoch: 5| Step: 3
Training loss: 2.084356616166469
Validation loss: 2.656031670666886

Epoch: 5| Step: 4
Training loss: 1.7959283076380128
Validation loss: 2.6864487584359944

Epoch: 5| Step: 5
Training loss: 2.161574934300044
Validation loss: 2.665163146536722

Epoch: 5| Step: 6
Training loss: 1.954777316218604
Validation loss: 2.6360442252450573

Epoch: 5| Step: 7
Training loss: 2.0980834525923293
Validation loss: 2.6124502057101515

Epoch: 5| Step: 8
Training loss: 2.2725206341871567
Validation loss: 2.5798263580978715

Epoch: 5| Step: 9
Training loss: 2.8320194638763367
Validation loss: 2.572165241759228

Epoch: 5| Step: 10
Training loss: 1.9010475959859552
Validation loss: 2.5860826119296823

Epoch: 5| Step: 11
Training loss: 1.190831730634404
Validation loss: 2.621630830121717

Epoch: 95| Step: 0
Training loss: 2.298518416836511
Validation loss: 2.6359930099313584

Epoch: 5| Step: 1
Training loss: 1.898866958079819
Validation loss: 2.6377403126446137

Epoch: 5| Step: 2
Training loss: 1.902025074674183
Validation loss: 2.647304284969882

Epoch: 5| Step: 3
Training loss: 1.9215689934983577
Validation loss: 2.5756122867301627

Epoch: 5| Step: 4
Training loss: 2.2867938051199563
Validation loss: 2.5360388999749848

Epoch: 5| Step: 5
Training loss: 1.4590408334698175
Validation loss: 2.53487257112377

Epoch: 5| Step: 6
Training loss: 1.6909695737775794
Validation loss: 2.5985684430468154

Epoch: 5| Step: 7
Training loss: 1.7543757092862111
Validation loss: 2.6165626083526474

Epoch: 5| Step: 8
Training loss: 2.369788525477972
Validation loss: 2.626236348171904

Epoch: 5| Step: 9
Training loss: 2.143135547717669
Validation loss: 2.6152717562969854

Epoch: 5| Step: 10
Training loss: 2.241998857278388
Validation loss: 2.620974299688473

Epoch: 5| Step: 11
Training loss: 2.1555630239158496
Validation loss: 2.633394344946923

Epoch: 96| Step: 0
Training loss: 1.8532926949955786
Validation loss: 2.6569286377095342

Epoch: 5| Step: 1
Training loss: 1.6969152512527201
Validation loss: 2.6544815047917862

Epoch: 5| Step: 2
Training loss: 1.684274133270118
Validation loss: 2.742777227547478

Epoch: 5| Step: 3
Training loss: 2.6564383944851926
Validation loss: 2.6979080197601983

Epoch: 5| Step: 4
Training loss: 1.9681546961220888
Validation loss: 2.6058820885612035

Epoch: 5| Step: 5
Training loss: 2.271621450681815
Validation loss: 2.6327264358535283

Epoch: 5| Step: 6
Training loss: 2.586993045256371
Validation loss: 2.6341640501080748

Epoch: 5| Step: 7
Training loss: 2.0199624639743874
Validation loss: 2.640914716759604

Epoch: 5| Step: 8
Training loss: 1.9215054660732276
Validation loss: 2.558928728379344

Epoch: 5| Step: 9
Training loss: 1.6699811244514622
Validation loss: 2.5848685914499487

Epoch: 5| Step: 10
Training loss: 1.789787978290352
Validation loss: 2.6546327941179446

Epoch: 5| Step: 11
Training loss: 0.9753736965801872
Validation loss: 2.503234892300964

Epoch: 97| Step: 0
Training loss: 1.7103156087419502
Validation loss: 2.5822384511171284

Epoch: 5| Step: 1
Training loss: 2.113392035494342
Validation loss: 2.5867145135434475

Epoch: 5| Step: 2
Training loss: 1.8543061478975404
Validation loss: 2.5937827770812514

Epoch: 5| Step: 3
Training loss: 1.9126346790040643
Validation loss: 2.518793002850855

Epoch: 5| Step: 4
Training loss: 2.3308960469491877
Validation loss: 2.5629001591865626

Epoch: 5| Step: 5
Training loss: 2.303152213071717
Validation loss: 2.5878077578922474

Epoch: 5| Step: 6
Training loss: 1.4052302583869676
Validation loss: 2.593035699160703

Epoch: 5| Step: 7
Training loss: 1.9906132480627765
Validation loss: 2.646851153605959

Epoch: 5| Step: 8
Training loss: 2.445227185793341
Validation loss: 2.686189705408847

Epoch: 5| Step: 9
Training loss: 2.04877401304108
Validation loss: 2.6524598326115045

Epoch: 5| Step: 10
Training loss: 1.6132307067786236
Validation loss: 2.6275569406177786

Epoch: 5| Step: 11
Training loss: 1.5403886687286688
Validation loss: 2.615259973326174

Epoch: 98| Step: 0
Training loss: 1.8488548858788474
Validation loss: 2.57139919618386

Epoch: 5| Step: 1
Training loss: 1.9751845068396954
Validation loss: 2.5600721441474548

Epoch: 5| Step: 2
Training loss: 2.1598557992767558
Validation loss: 2.583444202002647

Epoch: 5| Step: 3
Training loss: 1.6031495953136201
Validation loss: 2.5195327877069555

Epoch: 5| Step: 4
Training loss: 2.3702596237330047
Validation loss: 2.6300840682081508

Epoch: 5| Step: 5
Training loss: 2.1167313763596756
Validation loss: 2.5376727286557483

Epoch: 5| Step: 6
Training loss: 1.950892889565913
Validation loss: 2.514348659979536

Epoch: 5| Step: 7
Training loss: 2.5181994799679086
Validation loss: 2.5418968265841646

Epoch: 5| Step: 8
Training loss: 2.0030825225087407
Validation loss: 2.5570046030022273

Epoch: 5| Step: 9
Training loss: 1.6531366560584537
Validation loss: 2.5838258886427083

Epoch: 5| Step: 10
Training loss: 1.7974137535148837
Validation loss: 2.5627696449794057

Epoch: 5| Step: 11
Training loss: 1.2268243983867164
Validation loss: 2.6180855609906866

Epoch: 99| Step: 0
Training loss: 1.6033467843938194
Validation loss: 2.6246462538192414

Epoch: 5| Step: 1
Training loss: 1.9867298241418034
Validation loss: 2.6288092388903963

Epoch: 5| Step: 2
Training loss: 1.877876237335742
Validation loss: 2.5327978150594874

Epoch: 5| Step: 3
Training loss: 2.569108860909339
Validation loss: 2.5784240318041833

Epoch: 5| Step: 4
Training loss: 2.0520868704776647
Validation loss: 2.566950085760611

Epoch: 5| Step: 5
Training loss: 1.9473333318297428
Validation loss: 2.53460755212206

Epoch: 5| Step: 6
Training loss: 1.6630877294883548
Validation loss: 2.5554426167993607

Epoch: 5| Step: 7
Training loss: 1.9185481235532056
Validation loss: 2.5871074331112034

Epoch: 5| Step: 8
Training loss: 2.2856426014899194
Validation loss: 2.6007444071048464

Epoch: 5| Step: 9
Training loss: 1.8883813833849852
Validation loss: 2.547238435148223

Epoch: 5| Step: 10
Training loss: 1.8119440870479455
Validation loss: 2.5984459042484906

Epoch: 5| Step: 11
Training loss: 1.0995385806126756
Validation loss: 2.6498862198629114

Epoch: 100| Step: 0
Training loss: 1.663475112045496
Validation loss: 2.6468885988128594

Epoch: 5| Step: 1
Training loss: 1.8930281821448869
Validation loss: 2.615065812558558

Epoch: 5| Step: 2
Training loss: 2.062132369135627
Validation loss: 2.6527123267708115

Epoch: 5| Step: 3
Training loss: 1.8529260177953937
Validation loss: 2.699252303669858

Epoch: 5| Step: 4
Training loss: 2.0604388023347124
Validation loss: 2.6820148059708666

Epoch: 5| Step: 5
Training loss: 2.144399058674821
Validation loss: 2.7244197364722704

Epoch: 5| Step: 6
Training loss: 2.0757747352851053
Validation loss: 2.584051179875293

Epoch: 5| Step: 7
Training loss: 1.4872060180716722
Validation loss: 2.643461212846743

Epoch: 5| Step: 8
Training loss: 2.2681948063930784
Validation loss: 2.586957789783901

Epoch: 5| Step: 9
Training loss: 1.9448277125996423
Validation loss: 2.6035325168329693

Epoch: 5| Step: 10
Training loss: 1.7135026071226414
Validation loss: 2.635854753764413

Epoch: 5| Step: 11
Training loss: 2.7965261572124858
Validation loss: 2.591342220180464

Epoch: 101| Step: 0
Training loss: 1.735403357458961
Validation loss: 2.6494027238400015

Epoch: 5| Step: 1
Training loss: 2.7643159688657732
Validation loss: 2.595925173555885

Epoch: 5| Step: 2
Training loss: 2.0540053246864605
Validation loss: 2.6050575499971687

Epoch: 5| Step: 3
Training loss: 2.2496424496857768
Validation loss: 2.5767646013201926

Epoch: 5| Step: 4
Training loss: 1.6549297324761538
Validation loss: 2.638564406210502

Epoch: 5| Step: 5
Training loss: 1.6634326154603822
Validation loss: 2.570658358076065

Epoch: 5| Step: 6
Training loss: 2.0275509531789373
Validation loss: 2.6013773221237795

Epoch: 5| Step: 7
Training loss: 2.2737676112083824
Validation loss: 2.6314714300837285

Epoch: 5| Step: 8
Training loss: 2.1906865479969304
Validation loss: 2.6898514547984624

Epoch: 5| Step: 9
Training loss: 2.103602217199822
Validation loss: 2.713494054531587

Epoch: 5| Step: 10
Training loss: 1.8326262786779592
Validation loss: 2.6971002298296614

Epoch: 5| Step: 11
Training loss: 0.8471165006542457
Validation loss: 2.7298487776663647

Epoch: 102| Step: 0
Training loss: 1.752119551869035
Validation loss: 2.6384062653347553

Epoch: 5| Step: 1
Training loss: 2.071509709671766
Validation loss: 2.6696823708474064

Epoch: 5| Step: 2
Training loss: 2.019383556049135
Validation loss: 2.689603244984559

Epoch: 5| Step: 3
Training loss: 2.7300219081516612
Validation loss: 2.6588515724719946

Epoch: 5| Step: 4
Training loss: 1.4353798697765314
Validation loss: 2.600163978363601

Epoch: 5| Step: 5
Training loss: 2.397300226920008
Validation loss: 2.5747535065227254

Epoch: 5| Step: 6
Training loss: 1.7495298435252884
Validation loss: 2.6229145947408536

Epoch: 5| Step: 7
Training loss: 1.9963272465789144
Validation loss: 2.5769480436663463

Epoch: 5| Step: 8
Training loss: 1.8525926645554793
Validation loss: 2.645949797933063

Epoch: 5| Step: 9
Training loss: 1.9465309831067628
Validation loss: 2.656293348818838

Epoch: 5| Step: 10
Training loss: 1.510644180876834
Validation loss: 2.6244788106585126

Epoch: 5| Step: 11
Training loss: 1.281154722067167
Validation loss: 2.6210777255694575

Epoch: 103| Step: 0
Training loss: 2.0157626792549634
Validation loss: 2.545330757401916

Epoch: 5| Step: 1
Training loss: 1.3970276102765908
Validation loss: 2.6605830809409605

Epoch: 5| Step: 2
Training loss: 2.0609833892271343
Validation loss: 2.7502671567154433

Epoch: 5| Step: 3
Training loss: 2.9061886360499147
Validation loss: 2.8052524433334423

Epoch: 5| Step: 4
Training loss: 2.5990335355490686
Validation loss: 2.763368548135123

Epoch: 5| Step: 5
Training loss: 1.998867369850438
Validation loss: 2.668183231994633

Epoch: 5| Step: 6
Training loss: 1.943835329593075
Validation loss: 2.6369371375548805

Epoch: 5| Step: 7
Training loss: 1.7559329007956306
Validation loss: 2.575419528435824

Epoch: 5| Step: 8
Training loss: 1.4279703135783957
Validation loss: 2.552007718166252

Epoch: 5| Step: 9
Training loss: 2.024438794394875
Validation loss: 2.535400586533053

Epoch: 5| Step: 10
Training loss: 1.8731154826052603
Validation loss: 2.569815559621471

Epoch: 5| Step: 11
Training loss: 1.7577891030343942
Validation loss: 2.568563308645272

Epoch: 104| Step: 0
Training loss: 1.6398112140715466
Validation loss: 2.602572442676265

Epoch: 5| Step: 1
Training loss: 1.4764640815672845
Validation loss: 2.585511782390212

Epoch: 5| Step: 2
Training loss: 1.5211362232299224
Validation loss: 2.549834647770272

Epoch: 5| Step: 3
Training loss: 2.6113849140118
Validation loss: 2.5886053631401666

Epoch: 5| Step: 4
Training loss: 1.555366252930677
Validation loss: 2.489669632047749

Epoch: 5| Step: 5
Training loss: 2.119582169761611
Validation loss: 2.5574355748558695

Epoch: 5| Step: 6
Training loss: 1.9998015066829988
Validation loss: 2.6197216044790745

Epoch: 5| Step: 7
Training loss: 2.3865705028887767
Validation loss: 2.6252179395939215

Epoch: 5| Step: 8
Training loss: 2.366432296090721
Validation loss: 2.56205131898082

Epoch: 5| Step: 9
Training loss: 1.5564468626956924
Validation loss: 2.582733489710991

Epoch: 5| Step: 10
Training loss: 1.7105320140805487
Validation loss: 2.522720632699272

Epoch: 5| Step: 11
Training loss: 0.9737637201304865
Validation loss: 2.6014652520410015

Epoch: 105| Step: 0
Training loss: 1.6018405579887698
Validation loss: 2.617761596419143

Epoch: 5| Step: 1
Training loss: 1.7147695746922271
Validation loss: 2.584978999723407

Epoch: 5| Step: 2
Training loss: 1.5452581104855072
Validation loss: 2.5985779735575685

Epoch: 5| Step: 3
Training loss: 2.769757819760954
Validation loss: 2.6253036103947403

Epoch: 5| Step: 4
Training loss: 1.8465491560903962
Validation loss: 2.6673088132551515

Epoch: 5| Step: 5
Training loss: 1.6237346417623573
Validation loss: 2.5885360411973664

Epoch: 5| Step: 6
Training loss: 1.899149066709032
Validation loss: 2.603148667043599

Epoch: 5| Step: 7
Training loss: 1.6433655147741557
Validation loss: 2.579901784279875

Epoch: 5| Step: 8
Training loss: 2.04505863114975
Validation loss: 2.538271482446314

Epoch: 5| Step: 9
Training loss: 1.8272673722606645
Validation loss: 2.658840371201034

Epoch: 5| Step: 10
Training loss: 2.4244616077960486
Validation loss: 2.5708461466448806

Epoch: 5| Step: 11
Training loss: 1.971010454483989
Validation loss: 2.597253279633446

Epoch: 106| Step: 0
Training loss: 2.601166382838379
Validation loss: 2.6121182098855362

Epoch: 5| Step: 1
Training loss: 1.2317772099637019
Validation loss: 2.581266592956118

Epoch: 5| Step: 2
Training loss: 2.123532293251548
Validation loss: 2.6557694280883863

Epoch: 5| Step: 3
Training loss: 1.8271552880391686
Validation loss: 2.5601313583875935

Epoch: 5| Step: 4
Training loss: 1.9965386240199234
Validation loss: 2.6234531727016526

Epoch: 5| Step: 5
Training loss: 1.408616300329387
Validation loss: 2.621752770279682

Epoch: 5| Step: 6
Training loss: 1.9704569123093816
Validation loss: 2.694753273708989

Epoch: 5| Step: 7
Training loss: 2.221436284743565
Validation loss: 2.64822320811974

Epoch: 5| Step: 8
Training loss: 1.7517235306723995
Validation loss: 2.5544502894779595

Epoch: 5| Step: 9
Training loss: 1.805784940412988
Validation loss: 2.598226426345434

Epoch: 5| Step: 10
Training loss: 1.9358502409129998
Validation loss: 2.5943585183724327

Epoch: 5| Step: 11
Training loss: 1.4634956361674942
Validation loss: 2.626919880672012

Epoch: 107| Step: 0
Training loss: 1.3659497571057941
Validation loss: 2.608660164111679

Epoch: 5| Step: 1
Training loss: 2.021131814628445
Validation loss: 2.6418830726283007

Epoch: 5| Step: 2
Training loss: 1.5540303130415214
Validation loss: 2.5680817854138724

Epoch: 5| Step: 3
Training loss: 1.9405010116208867
Validation loss: 2.587874183842477

Epoch: 5| Step: 4
Training loss: 2.124059581229834
Validation loss: 2.624036581869913

Epoch: 5| Step: 5
Training loss: 1.9023001350557194
Validation loss: 2.6728343208118335

Epoch: 5| Step: 6
Training loss: 2.0520868704776647
Validation loss: 2.6646811176299816

Epoch: 5| Step: 7
Training loss: 1.347652800182405
Validation loss: 2.6261256582186165

Epoch: 5| Step: 8
Training loss: 1.8114936928993328
Validation loss: 2.5780925132168875

Epoch: 5| Step: 9
Training loss: 2.0939064536782372
Validation loss: 2.5768806460048306

Epoch: 5| Step: 10
Training loss: 2.170719195957357
Validation loss: 2.601838485772499

Epoch: 5| Step: 11
Training loss: 1.8485987640485684
Validation loss: 2.59398156783105

Epoch: 108| Step: 0
Training loss: 1.7995921282131226
Validation loss: 2.69133469440806

Epoch: 5| Step: 1
Training loss: 2.0114577633346418
Validation loss: 2.611398342636968

Epoch: 5| Step: 2
Training loss: 1.6061235192519405
Validation loss: 2.581105511141265

Epoch: 5| Step: 3
Training loss: 1.444964887727005
Validation loss: 2.563671069319691

Epoch: 5| Step: 4
Training loss: 1.7139982254927184
Validation loss: 2.6969977634169835

Epoch: 5| Step: 5
Training loss: 2.396079130970799
Validation loss: 2.627506363292675

Epoch: 5| Step: 6
Training loss: 1.7109167367729143
Validation loss: 2.606818162842202

Epoch: 5| Step: 7
Training loss: 2.3632218282496
Validation loss: 2.55667257228287

Epoch: 5| Step: 8
Training loss: 1.56323568190962
Validation loss: 2.60702020072939

Epoch: 5| Step: 9
Training loss: 2.156864355166577
Validation loss: 2.6453922096736555

Epoch: 5| Step: 10
Training loss: 1.766610334805818
Validation loss: 2.5490741011802305

Epoch: 5| Step: 11
Training loss: 1.3092085120209072
Validation loss: 2.575215128982828

Epoch: 109| Step: 0
Training loss: 2.405834310716625
Validation loss: 2.5956899596206444

Epoch: 5| Step: 1
Training loss: 1.5173396999653512
Validation loss: 2.6168295392495113

Epoch: 5| Step: 2
Training loss: 1.9468142063697103
Validation loss: 2.612929243966817

Epoch: 5| Step: 3
Training loss: 1.4691419687140723
Validation loss: 2.578154581073637

Epoch: 5| Step: 4
Training loss: 1.3242935114548837
Validation loss: 2.610199704684346

Epoch: 5| Step: 5
Training loss: 2.072384125308238
Validation loss: 2.6118924794339033

Epoch: 5| Step: 6
Training loss: 1.406226391064298
Validation loss: 2.7160635423980213

Epoch: 5| Step: 7
Training loss: 1.9001696184640244
Validation loss: 2.6600131772666216

Epoch: 5| Step: 8
Training loss: 1.8637426672726636
Validation loss: 2.73139059416347

Epoch: 5| Step: 9
Training loss: 2.10604459853375
Validation loss: 2.7578490689800574

Epoch: 5| Step: 10
Training loss: 2.2228817146601854
Validation loss: 2.6426546621880793

Epoch: 5| Step: 11
Training loss: 2.654339810347648
Validation loss: 2.6551754928619204

Epoch: 110| Step: 0
Training loss: 1.2378008659757938
Validation loss: 2.569281472731133

Epoch: 5| Step: 1
Training loss: 1.9779143403562414
Validation loss: 2.669984079606982

Epoch: 5| Step: 2
Training loss: 1.9537074326889237
Validation loss: 2.5604382687602265

Epoch: 5| Step: 3
Training loss: 1.650204258615826
Validation loss: 2.7439070162093144

Epoch: 5| Step: 4
Training loss: 2.2596629654390297
Validation loss: 2.705294031003252

Epoch: 5| Step: 5
Training loss: 1.672910850707982
Validation loss: 2.624712080530235

Epoch: 5| Step: 6
Training loss: 2.0663754437463253
Validation loss: 2.574945354036145

Epoch: 5| Step: 7
Training loss: 2.7326024877204507
Validation loss: 2.632828785046963

Epoch: 5| Step: 8
Training loss: 1.5377705374784918
Validation loss: 2.5762399351641228

Epoch: 5| Step: 9
Training loss: 1.9711331672371042
Validation loss: 2.639843334097489

Epoch: 5| Step: 10
Training loss: 1.860639510810913
Validation loss: 2.6981976901552636

Epoch: 5| Step: 11
Training loss: 2.2050024379448594
Validation loss: 2.664028044447044

Epoch: 111| Step: 0
Training loss: 1.7616303753731246
Validation loss: 2.7719014781158893

Epoch: 5| Step: 1
Training loss: 2.406282499019575
Validation loss: 2.7028053109349095

Epoch: 5| Step: 2
Training loss: 2.1329897852285087
Validation loss: 2.739696363769293

Epoch: 5| Step: 3
Training loss: 2.029635682887208
Validation loss: 2.6368485218655735

Epoch: 5| Step: 4
Training loss: 1.404953422453106
Validation loss: 2.5634540975888167

Epoch: 5| Step: 5
Training loss: 1.9786690203446187
Validation loss: 2.5927755831166577

Epoch: 5| Step: 6
Training loss: 1.6133266193208153
Validation loss: 2.620592936440886

Epoch: 5| Step: 7
Training loss: 1.6689105267412332
Validation loss: 2.5847475016366293

Epoch: 5| Step: 8
Training loss: 2.0574392016340144
Validation loss: 2.629274003416738

Epoch: 5| Step: 9
Training loss: 1.8489130435465144
Validation loss: 2.620980936380846

Epoch: 5| Step: 10
Training loss: 1.7491518417585545
Validation loss: 2.6531415066394657

Epoch: 5| Step: 11
Training loss: 1.8105068428691928
Validation loss: 2.568774747922662

Epoch: 112| Step: 0
Training loss: 1.5703956999492024
Validation loss: 2.673665994986346

Epoch: 5| Step: 1
Training loss: 2.0537088478502206
Validation loss: 2.6356144266728334

Epoch: 5| Step: 2
Training loss: 1.7342890125300754
Validation loss: 2.688066393288675

Epoch: 5| Step: 3
Training loss: 1.7269408903139405
Validation loss: 2.696226125477939

Epoch: 5| Step: 4
Training loss: 1.803758588573499
Validation loss: 2.7728673107035617

Epoch: 5| Step: 5
Training loss: 2.117411246213073
Validation loss: 2.768165283805757

Epoch: 5| Step: 6
Training loss: 1.8872199804495908
Validation loss: 2.7979326361803802

Epoch: 5| Step: 7
Training loss: 2.5804590930117044
Validation loss: 2.6409268479438412

Epoch: 5| Step: 8
Training loss: 1.5301477006914712
Validation loss: 2.7025654972642896

Epoch: 5| Step: 9
Training loss: 1.7058767783865076
Validation loss: 2.5865689108956817

Epoch: 5| Step: 10
Training loss: 1.9305542763660806
Validation loss: 2.5768262539623996

Epoch: 5| Step: 11
Training loss: 0.9674608204915051
Validation loss: 2.5660644141018945

Epoch: 113| Step: 0
Training loss: 1.8052750328789067
Validation loss: 2.6037609445503955

Epoch: 5| Step: 1
Training loss: 1.8751792186280456
Validation loss: 2.65255706483637

Epoch: 5| Step: 2
Training loss: 2.1959228753129083
Validation loss: 2.6085157483474735

Epoch: 5| Step: 3
Training loss: 1.9227296743125846
Validation loss: 2.6186935342848017

Epoch: 5| Step: 4
Training loss: 1.5420366393163356
Validation loss: 2.662189425531073

Epoch: 5| Step: 5
Training loss: 1.7352339533514693
Validation loss: 2.5532004162759714

Epoch: 5| Step: 6
Training loss: 1.6349778852221228
Validation loss: 2.6598863245341744

Epoch: 5| Step: 7
Training loss: 1.8698723296579853
Validation loss: 2.620459736202035

Epoch: 5| Step: 8
Training loss: 1.616985437420799
Validation loss: 2.669321637794393

Epoch: 5| Step: 9
Training loss: 2.0448189229471696
Validation loss: 2.718519756462617

Epoch: 5| Step: 10
Training loss: 2.671060627645205
Validation loss: 2.697744678234123

Epoch: 5| Step: 11
Training loss: 0.613031907631132
Validation loss: 2.656208077268194

Epoch: 114| Step: 0
Training loss: 1.6572641111041588
Validation loss: 2.650599749492151

Epoch: 5| Step: 1
Training loss: 1.4560200554703093
Validation loss: 2.675862621545862

Epoch: 5| Step: 2
Training loss: 1.5419432503663888
Validation loss: 2.685646216202405

Epoch: 5| Step: 3
Training loss: 1.9037653254532696
Validation loss: 2.7164279825333932

Epoch: 5| Step: 4
Training loss: 1.8151230083638803
Validation loss: 2.621252158428923

Epoch: 5| Step: 5
Training loss: 1.5340165039925366
Validation loss: 2.574605350281916

Epoch: 5| Step: 6
Training loss: 1.4440197911372423
Validation loss: 2.594682162125947

Epoch: 5| Step: 7
Training loss: 2.569063573107851
Validation loss: 2.643620825002312

Epoch: 5| Step: 8
Training loss: 1.96985619363813
Validation loss: 2.5874892282184963

Epoch: 5| Step: 9
Training loss: 1.9921097684168905
Validation loss: 2.581066857553542

Epoch: 5| Step: 10
Training loss: 1.474300609877206
Validation loss: 2.6070630878001575

Epoch: 5| Step: 11
Training loss: 1.4769128454446967
Validation loss: 2.651854880612727

Epoch: 115| Step: 0
Training loss: 2.080762981447175
Validation loss: 2.5979043292374913

Epoch: 5| Step: 1
Training loss: 1.631336475871782
Validation loss: 2.6380416527868316

Epoch: 5| Step: 2
Training loss: 1.7025298732427745
Validation loss: 2.5983268923758134

Epoch: 5| Step: 3
Training loss: 2.598953359187583
Validation loss: 2.6115067772061296

Epoch: 5| Step: 4
Training loss: 1.755089511490544
Validation loss: 2.6458848975756335

Epoch: 5| Step: 5
Training loss: 1.819979592198406
Validation loss: 2.6560750978519088

Epoch: 5| Step: 6
Training loss: 1.326510087091001
Validation loss: 2.6415763284978713

Epoch: 5| Step: 7
Training loss: 1.8349298836931258
Validation loss: 2.6378614026640963

Epoch: 5| Step: 8
Training loss: 1.7179126433699252
Validation loss: 2.6551274863608407

Epoch: 5| Step: 9
Training loss: 1.4892823064071803
Validation loss: 2.650870999061951

Epoch: 5| Step: 10
Training loss: 1.5715541959684651
Validation loss: 2.7292195465458873

Epoch: 5| Step: 11
Training loss: 2.0330727248649625
Validation loss: 2.7584313696950202

Epoch: 116| Step: 0
Training loss: 1.9651380436094774
Validation loss: 2.7157480869704944

Epoch: 5| Step: 1
Training loss: 1.6133742040128423
Validation loss: 2.6334997877998814

Epoch: 5| Step: 2
Training loss: 1.949772146557754
Validation loss: 2.617212433957185

Epoch: 5| Step: 3
Training loss: 1.789988049302086
Validation loss: 2.569989888546122

Epoch: 5| Step: 4
Training loss: 1.7448779488101442
Validation loss: 2.574242919283578

Epoch: 5| Step: 5
Training loss: 1.5315665871457258
Validation loss: 2.606950307200533

Epoch: 5| Step: 6
Training loss: 1.9122907262258784
Validation loss: 2.5662099104145484

Epoch: 5| Step: 7
Training loss: 1.4592443436288667
Validation loss: 2.6539064671805774

Epoch: 5| Step: 8
Training loss: 2.4481038989164934
Validation loss: 2.594885213833083

Epoch: 5| Step: 9
Training loss: 1.7450940985024772
Validation loss: 2.604219826473609

Epoch: 5| Step: 10
Training loss: 1.7916120994006006
Validation loss: 2.6051850019038367

Epoch: 5| Step: 11
Training loss: 1.6937078801509788
Validation loss: 2.6073705127624476

Epoch: 117| Step: 0
Training loss: 1.2274535034758711
Validation loss: 2.616674864557711

Epoch: 5| Step: 1
Training loss: 2.143738980723718
Validation loss: 2.7155387555976853

Epoch: 5| Step: 2
Training loss: 1.7597740926761105
Validation loss: 2.663530111952926

Epoch: 5| Step: 3
Training loss: 1.4792784080027594
Validation loss: 2.7060222864706405

Epoch: 5| Step: 4
Training loss: 2.0578683809355724
Validation loss: 2.6093502157713204

Epoch: 5| Step: 5
Training loss: 1.8298527956473447
Validation loss: 2.6583399796975815

Epoch: 5| Step: 6
Training loss: 1.7540605303020826
Validation loss: 2.6345505679669863

Epoch: 5| Step: 7
Training loss: 2.150742504631372
Validation loss: 2.5771844439046863

Epoch: 5| Step: 8
Training loss: 1.667060336668088
Validation loss: 2.5876191501857515

Epoch: 5| Step: 9
Training loss: 1.9455330964907833
Validation loss: 2.686509774257795

Epoch: 5| Step: 10
Training loss: 1.5395519427178064
Validation loss: 2.636568742417412

Epoch: 5| Step: 11
Training loss: 1.3631975645596504
Validation loss: 2.6389794837447607

Epoch: 118| Step: 0
Training loss: 1.6866872030950477
Validation loss: 2.6524671508068516

Epoch: 5| Step: 1
Training loss: 2.218732162188969
Validation loss: 2.607310203418278

Epoch: 5| Step: 2
Training loss: 1.6561798944571073
Validation loss: 2.6124394329174656

Epoch: 5| Step: 3
Training loss: 1.6363145424722374
Validation loss: 2.6576120699078185

Epoch: 5| Step: 4
Training loss: 1.7679832710751981
Validation loss: 2.694948800284183

Epoch: 5| Step: 5
Training loss: 1.402142013447944
Validation loss: 2.707513858845407

Epoch: 5| Step: 6
Training loss: 1.5003934979876816
Validation loss: 2.5843766256663243

Epoch: 5| Step: 7
Training loss: 1.3426790627346437
Validation loss: 2.7315714132700837

Epoch: 5| Step: 8
Training loss: 1.3185312568798901
Validation loss: 2.607922536190522

Epoch: 5| Step: 9
Training loss: 2.2482086043922895
Validation loss: 2.634483686160733

Epoch: 5| Step: 10
Training loss: 2.1201797117680545
Validation loss: 2.663698743968208

Epoch: 5| Step: 11
Training loss: 1.1807058120300173
Validation loss: 2.6859856560343736

Epoch: 119| Step: 0
Training loss: 2.0181808236187635
Validation loss: 2.5876025671755816

Epoch: 5| Step: 1
Training loss: 1.5265409501271694
Validation loss: 2.6146882151405193

Epoch: 5| Step: 2
Training loss: 1.4663368854975414
Validation loss: 2.523333123157531

Epoch: 5| Step: 3
Training loss: 1.688999639959393
Validation loss: 2.633422777059226

Epoch: 5| Step: 4
Training loss: 1.3947705830164496
Validation loss: 2.6125742892603934

Epoch: 5| Step: 5
Training loss: 1.9951449712983746
Validation loss: 2.5696173387787393

Epoch: 5| Step: 6
Training loss: 1.6086297392929851
Validation loss: 2.624916219131191

Epoch: 5| Step: 7
Training loss: 1.8712612387728018
Validation loss: 2.6130997158038656

Epoch: 5| Step: 8
Training loss: 1.5945652391323992
Validation loss: 2.619287925255343

Epoch: 5| Step: 9
Training loss: 2.337047198496793
Validation loss: 2.663922157953859

Epoch: 5| Step: 10
Training loss: 1.048968541923682
Validation loss: 2.635660753267691

Epoch: 5| Step: 11
Training loss: 2.183208943480572
Validation loss: 2.679988076838261

Epoch: 120| Step: 0
Training loss: 1.7095999170488079
Validation loss: 2.700491737986395

Epoch: 5| Step: 1
Training loss: 1.4667232408593993
Validation loss: 2.600181912055479

Epoch: 5| Step: 2
Training loss: 1.192259386127662
Validation loss: 2.593990762865448

Epoch: 5| Step: 3
Training loss: 1.2337901021359103
Validation loss: 2.6330579007540256

Epoch: 5| Step: 4
Training loss: 1.3500312995814387
Validation loss: 2.551410120447298

Epoch: 5| Step: 5
Training loss: 1.6817689995053255
Validation loss: 2.5730447865966983

Epoch: 5| Step: 6
Training loss: 2.300477608558281
Validation loss: 2.6015777091039003

Epoch: 5| Step: 7
Training loss: 1.5662660607369225
Validation loss: 2.6136915476882523

Epoch: 5| Step: 8
Training loss: 1.928141975018976
Validation loss: 2.6537429272699224

Epoch: 5| Step: 9
Training loss: 1.5345846961280614
Validation loss: 2.6189202034082024

Epoch: 5| Step: 10
Training loss: 1.7473873663146167
Validation loss: 2.5338266978223913

Epoch: 5| Step: 11
Training loss: 2.5529206024865125
Validation loss: 2.564845980642191

Epoch: 121| Step: 0
Training loss: 1.8544967514713127
Validation loss: 2.590710693831775

Epoch: 5| Step: 1
Training loss: 1.6051200246645425
Validation loss: 2.562798812160462

Epoch: 5| Step: 2
Training loss: 1.2882872128507679
Validation loss: 2.588382345064291

Epoch: 5| Step: 3
Training loss: 1.7425752216888712
Validation loss: 2.579984772480771

Epoch: 5| Step: 4
Training loss: 1.0775561836269516
Validation loss: 2.6826381323790254

Epoch: 5| Step: 5
Training loss: 1.907030977454629
Validation loss: 2.669744527080361

Epoch: 5| Step: 6
Training loss: 1.6301610125253925
Validation loss: 2.6573447944556965

Epoch: 5| Step: 7
Training loss: 1.3826844323116518
Validation loss: 2.692657264849919

Epoch: 5| Step: 8
Training loss: 1.7586728851395443
Validation loss: 2.7652496614809183

Epoch: 5| Step: 9
Training loss: 1.674130780734348
Validation loss: 2.7598072362931756

Epoch: 5| Step: 10
Training loss: 2.4049304465151757
Validation loss: 2.646585576561192

Epoch: 5| Step: 11
Training loss: 2.147896549440212
Validation loss: 2.6595310665945067

Epoch: 122| Step: 0
Training loss: 2.1057341625963595
Validation loss: 2.6866031969073423

Epoch: 5| Step: 1
Training loss: 1.5265537570168086
Validation loss: 2.7355253688038235

Epoch: 5| Step: 2
Training loss: 1.6171348673783432
Validation loss: 2.657339945800317

Epoch: 5| Step: 3
Training loss: 1.9293245290785137
Validation loss: 2.657955706590178

Epoch: 5| Step: 4
Training loss: 2.194549319286927
Validation loss: 2.7334100673728416

Epoch: 5| Step: 5
Training loss: 1.65069172838061
Validation loss: 2.6207226766767775

Epoch: 5| Step: 6
Training loss: 1.3009018484119623
Validation loss: 2.6462762917407945

Epoch: 5| Step: 7
Training loss: 1.5499333674967481
Validation loss: 2.6213858982173908

Epoch: 5| Step: 8
Training loss: 1.667284072324188
Validation loss: 2.6729394863182323

Epoch: 5| Step: 9
Training loss: 1.4905395995174004
Validation loss: 2.6325725895122645

Epoch: 5| Step: 10
Training loss: 1.463491889224761
Validation loss: 2.6849968475273562

Epoch: 5| Step: 11
Training loss: 2.069125774633442
Validation loss: 2.648619458934918

Epoch: 123| Step: 0
Training loss: 1.6401437689404517
Validation loss: 2.6263256888336635

Epoch: 5| Step: 1
Training loss: 1.4342033067389837
Validation loss: 2.624878305308813

Epoch: 5| Step: 2
Training loss: 1.6867741330530563
Validation loss: 2.5926709324269583

Epoch: 5| Step: 3
Training loss: 1.8187467201439298
Validation loss: 2.6097068309132694

Epoch: 5| Step: 4
Training loss: 1.5220297544781591
Validation loss: 2.5035194737006066

Epoch: 5| Step: 5
Training loss: 1.4373192051515762
Validation loss: 2.579277089414883

Epoch: 5| Step: 6
Training loss: 1.6807206635860483
Validation loss: 2.580032594651088

Epoch: 5| Step: 7
Training loss: 2.696040312315657
Validation loss: 2.550424643373555

Epoch: 5| Step: 8
Training loss: 1.6039023821561604
Validation loss: 2.5978910067610808

Epoch: 5| Step: 9
Training loss: 1.7452953313872719
Validation loss: 2.581887649490371

Epoch: 5| Step: 10
Training loss: 1.5102717450651921
Validation loss: 2.68715645568213

Epoch: 5| Step: 11
Training loss: 1.6678653300829185
Validation loss: 2.796107892020837

Epoch: 124| Step: 0
Training loss: 1.796219415902043
Validation loss: 2.847724163709018

Epoch: 5| Step: 1
Training loss: 1.7853294639108637
Validation loss: 2.827811439793034

Epoch: 5| Step: 2
Training loss: 1.7395965743179607
Validation loss: 2.8774116048926235

Epoch: 5| Step: 3
Training loss: 2.3408608494743044
Validation loss: 2.7832689136961353

Epoch: 5| Step: 4
Training loss: 1.705893479991859
Validation loss: 2.6527945426147093

Epoch: 5| Step: 5
Training loss: 1.2315747331439053
Validation loss: 2.668250996603801

Epoch: 5| Step: 6
Training loss: 1.6484784306511326
Validation loss: 2.599072369129481

Epoch: 5| Step: 7
Training loss: 1.7136569076173143
Validation loss: 2.5694696267643806

Epoch: 5| Step: 8
Training loss: 1.607637671334465
Validation loss: 2.5722181218771207

Epoch: 5| Step: 9
Training loss: 1.7751664795508193
Validation loss: 2.5852646965674233

Epoch: 5| Step: 10
Training loss: 1.4682108924525068
Validation loss: 2.5577708777488257

Epoch: 5| Step: 11
Training loss: 1.2496666940729955
Validation loss: 2.61497767895374

Epoch: 125| Step: 0
Training loss: 1.8005690708233166
Validation loss: 2.636229997712449

Epoch: 5| Step: 1
Training loss: 1.1973024147940314
Validation loss: 2.543363611804353

Epoch: 5| Step: 2
Training loss: 1.7062418004771647
Validation loss: 2.6192451890463904

Epoch: 5| Step: 3
Training loss: 1.6902631107900066
Validation loss: 2.563067633089106

Epoch: 5| Step: 4
Training loss: 1.6397387336010074
Validation loss: 2.6036568498667725

Epoch: 5| Step: 5
Training loss: 1.476598345609046
Validation loss: 2.709083370131724

Epoch: 5| Step: 6
Training loss: 1.6439046141572167
Validation loss: 2.823923277534731

Epoch: 5| Step: 7
Training loss: 2.1161995585108815
Validation loss: 2.8698161061256497

Epoch: 5| Step: 8
Training loss: 1.8464208751369444
Validation loss: 2.83150933729156

Epoch: 5| Step: 9
Training loss: 1.6661685278649578
Validation loss: 2.7175046655602575

Epoch: 5| Step: 10
Training loss: 2.3247834873907354
Validation loss: 2.6072280830822567

Epoch: 5| Step: 11
Training loss: 1.1465827340820072
Validation loss: 2.543837540016111

Epoch: 126| Step: 0
Training loss: 1.215556043223396
Validation loss: 2.624003728393391

Epoch: 5| Step: 1
Training loss: 1.350161625759043
Validation loss: 2.56964023691826

Epoch: 5| Step: 2
Training loss: 1.19484112988326
Validation loss: 2.692100265633498

Epoch: 5| Step: 3
Training loss: 1.769059680477578
Validation loss: 2.5971328016743733

Epoch: 5| Step: 4
Training loss: 1.7492824854618196
Validation loss: 2.6007154534892902

Epoch: 5| Step: 5
Training loss: 1.7808801367391025
Validation loss: 2.6568071678582115

Epoch: 5| Step: 6
Training loss: 1.8120684932201359
Validation loss: 2.61381459175034

Epoch: 5| Step: 7
Training loss: 1.4965913507815454
Validation loss: 2.6162065138333865

Epoch: 5| Step: 8
Training loss: 1.4193500275054896
Validation loss: 2.6927933073870554

Epoch: 5| Step: 9
Training loss: 1.8589709828714598
Validation loss: 2.719632918859093

Epoch: 5| Step: 10
Training loss: 1.9683514146138523
Validation loss: 2.655325380850544

Epoch: 5| Step: 11
Training loss: 1.5141656673150272
Validation loss: 2.743930175965412

Epoch: 127| Step: 0
Training loss: 1.9437643118083063
Validation loss: 2.664596090268837

Epoch: 5| Step: 1
Training loss: 1.575124096901269
Validation loss: 2.681204324835653

Epoch: 5| Step: 2
Training loss: 1.778304224082908
Validation loss: 2.680408606896384

Epoch: 5| Step: 3
Training loss: 1.2541150546094482
Validation loss: 2.6899697466216166

Epoch: 5| Step: 4
Training loss: 1.1486036738367988
Validation loss: 2.7123605252809733

Epoch: 5| Step: 5
Training loss: 1.4382237809866574
Validation loss: 2.624260578766647

Epoch: 5| Step: 6
Training loss: 1.711340103508031
Validation loss: 2.641643406788644

Epoch: 5| Step: 7
Training loss: 1.5975970045077876
Validation loss: 2.5300283054388024

Epoch: 5| Step: 8
Training loss: 1.5503129612391993
Validation loss: 2.6951868368884173

Epoch: 5| Step: 9
Training loss: 1.7212831729747904
Validation loss: 2.6240116483979334

Epoch: 5| Step: 10
Training loss: 2.412483661971829
Validation loss: 2.5966265824688235

Epoch: 5| Step: 11
Training loss: 0.5984222141235924
Validation loss: 2.5804095617272775

Epoch: 128| Step: 0
Training loss: 1.716340335210576
Validation loss: 2.688850939339908

Epoch: 5| Step: 1
Training loss: 1.8383082889200888
Validation loss: 2.785837126795949

Epoch: 5| Step: 2
Training loss: 1.7891305968805329
Validation loss: 2.7568904318644614

Epoch: 5| Step: 3
Training loss: 1.3001851958628643
Validation loss: 2.7073157171570834

Epoch: 5| Step: 4
Training loss: 1.9825211523594426
Validation loss: 2.652811809696535

Epoch: 5| Step: 5
Training loss: 1.1102453766494413
Validation loss: 2.6520092528056165

Epoch: 5| Step: 6
Training loss: 1.3599840312609295
Validation loss: 2.5502473117540094

Epoch: 5| Step: 7
Training loss: 1.593643708518029
Validation loss: 2.5931319185895454

Epoch: 5| Step: 8
Training loss: 1.843304725802087
Validation loss: 2.567302673102861

Epoch: 5| Step: 9
Training loss: 1.7665156590803959
Validation loss: 2.518673118320352

Epoch: 5| Step: 10
Training loss: 1.4108221114617938
Validation loss: 2.5849875773138136

Epoch: 5| Step: 11
Training loss: 1.3686891864522523
Validation loss: 2.626723673465314

Epoch: 129| Step: 0
Training loss: 1.3898418664517433
Validation loss: 2.6033217559924164

Epoch: 5| Step: 1
Training loss: 1.3834163834257296
Validation loss: 2.5951582865684357

Epoch: 5| Step: 2
Training loss: 2.1307675125922363
Validation loss: 2.57399794731908

Epoch: 5| Step: 3
Training loss: 1.7210821801557326
Validation loss: 2.6113415881551454

Epoch: 5| Step: 4
Training loss: 1.44957496398691
Validation loss: 2.610017073132102

Epoch: 5| Step: 5
Training loss: 1.853496909172665
Validation loss: 2.656983853861189

Epoch: 5| Step: 6
Training loss: 1.7019837081434253
Validation loss: 2.6683043775669173

Epoch: 5| Step: 7
Training loss: 1.324702351804765
Validation loss: 2.67506928265059

Epoch: 5| Step: 8
Training loss: 1.663069737837646
Validation loss: 2.67770128626173

Epoch: 5| Step: 9
Training loss: 1.658392114731683
Validation loss: 2.539630435123978

Epoch: 5| Step: 10
Training loss: 1.6091792163461578
Validation loss: 2.664380292312266

Epoch: 5| Step: 11
Training loss: 1.4460751557558689
Validation loss: 2.6270508399383767

Epoch: 130| Step: 0
Training loss: 1.3779350080596917
Validation loss: 2.6552794235328503

Epoch: 5| Step: 1
Training loss: 1.4453844207190094
Validation loss: 2.6788365539402155

Epoch: 5| Step: 2
Training loss: 1.3888157422619423
Validation loss: 2.622632563694929

Epoch: 5| Step: 3
Training loss: 1.6208129639640882
Validation loss: 2.6362752301223846

Epoch: 5| Step: 4
Training loss: 1.5223537404882574
Validation loss: 2.603116637571778

Epoch: 5| Step: 5
Training loss: 1.3658095909384078
Validation loss: 2.5822139719582142

Epoch: 5| Step: 6
Training loss: 1.4713755738268017
Validation loss: 2.556391308243435

Epoch: 5| Step: 7
Training loss: 2.0063010140941646
Validation loss: 2.61687018145681

Epoch: 5| Step: 8
Training loss: 1.4372793940565591
Validation loss: 2.637192087896866

Epoch: 5| Step: 9
Training loss: 1.586231899654206
Validation loss: 2.7019470897160627

Epoch: 5| Step: 10
Training loss: 2.0904335972135377
Validation loss: 2.674030044618459

Epoch: 5| Step: 11
Training loss: 0.7832671255850573
Validation loss: 2.6783133005470336

Epoch: 131| Step: 0
Training loss: 1.3759549899335808
Validation loss: 2.677431059245719

Epoch: 5| Step: 1
Training loss: 1.110902406376969
Validation loss: 2.667590172616098

Epoch: 5| Step: 2
Training loss: 1.4957562656083268
Validation loss: 2.614319428325907

Epoch: 5| Step: 3
Training loss: 2.2799906978082793
Validation loss: 2.5104020713181376

Epoch: 5| Step: 4
Training loss: 1.508839390973909
Validation loss: 2.5724446189277246

Epoch: 5| Step: 5
Training loss: 1.3627555729960794
Validation loss: 2.547933487253091

Epoch: 5| Step: 6
Training loss: 1.4900722990480633
Validation loss: 2.6512188180867033

Epoch: 5| Step: 7
Training loss: 1.655771510264841
Validation loss: 2.6167207975518703

Epoch: 5| Step: 8
Training loss: 1.2763811503247122
Validation loss: 2.579021055387061

Epoch: 5| Step: 9
Training loss: 1.8806635199088557
Validation loss: 2.584481754427502

Epoch: 5| Step: 10
Training loss: 1.8335896515119832
Validation loss: 2.640046737301142

Epoch: 5| Step: 11
Training loss: 0.9236939153305872
Validation loss: 2.659518549623804

Epoch: 132| Step: 0
Training loss: 1.8475337885140093
Validation loss: 2.7890849998556755

Epoch: 5| Step: 1
Training loss: 2.2122525998174734
Validation loss: 2.7317158330151083

Epoch: 5| Step: 2
Training loss: 1.4490793166214144
Validation loss: 2.683989838489251

Epoch: 5| Step: 3
Training loss: 1.2306865196679384
Validation loss: 2.657223672618741

Epoch: 5| Step: 4
Training loss: 1.798483816655736
Validation loss: 2.569790053679588

Epoch: 5| Step: 5
Training loss: 1.2718820726352655
Validation loss: 2.5979068032949058

Epoch: 5| Step: 6
Training loss: 1.5210298733458036
Validation loss: 2.6247141848987776

Epoch: 5| Step: 7
Training loss: 1.441806727241086
Validation loss: 2.5652402864282244

Epoch: 5| Step: 8
Training loss: 1.5747227015935417
Validation loss: 2.5785413116946323

Epoch: 5| Step: 9
Training loss: 1.0449371621983377
Validation loss: 2.575034861652713

Epoch: 5| Step: 10
Training loss: 1.3003056203618457
Validation loss: 2.628703384923304

Epoch: 5| Step: 11
Training loss: 2.6556674093988617
Validation loss: 2.5793838741272155

Epoch: 133| Step: 0
Training loss: 1.3167482831663835
Validation loss: 2.603488602418117

Epoch: 5| Step: 1
Training loss: 1.5477403474438045
Validation loss: 2.6596533495554517

Epoch: 5| Step: 2
Training loss: 1.4431338824514666
Validation loss: 2.641931786054346

Epoch: 5| Step: 3
Training loss: 1.2614124977526957
Validation loss: 2.673524072532179

Epoch: 5| Step: 4
Training loss: 1.8080000428140686
Validation loss: 2.6608948618111627

Epoch: 5| Step: 5
Training loss: 1.1038095268536487
Validation loss: 2.655801058210935

Epoch: 5| Step: 6
Training loss: 1.4388272336484926
Validation loss: 2.630212362053433

Epoch: 5| Step: 7
Training loss: 1.6095475780213229
Validation loss: 2.6029369935113764

Epoch: 5| Step: 8
Training loss: 1.5672250638588427
Validation loss: 2.6265719017784903

Epoch: 5| Step: 9
Training loss: 2.001698726214148
Validation loss: 2.616818826244242

Epoch: 5| Step: 10
Training loss: 1.66247346613081
Validation loss: 2.5554312460376836

Epoch: 5| Step: 11
Training loss: 1.5932619432127102
Validation loss: 2.5355322725013347

Epoch: 134| Step: 0
Training loss: 1.143205310801456
Validation loss: 2.6639268417348645

Epoch: 5| Step: 1
Training loss: 1.9315784162758334
Validation loss: 2.6056212952970963

Epoch: 5| Step: 2
Training loss: 1.5402484332997546
Validation loss: 2.5734158210636475

Epoch: 5| Step: 3
Training loss: 1.4276277473596288
Validation loss: 2.6039864223409954

Epoch: 5| Step: 4
Training loss: 1.6361180480021271
Validation loss: 2.6345037882115125

Epoch: 5| Step: 5
Training loss: 1.4840052093866842
Validation loss: 2.6699213168876863

Epoch: 5| Step: 6
Training loss: 1.3393071826849021
Validation loss: 2.619196834999344

Epoch: 5| Step: 7
Training loss: 1.2124644834684788
Validation loss: 2.6526994087522295

Epoch: 5| Step: 8
Training loss: 1.3478829455788435
Validation loss: 2.643010384410896

Epoch: 5| Step: 9
Training loss: 1.3568537339591495
Validation loss: 2.7196786178846497

Epoch: 5| Step: 10
Training loss: 1.687944848095216
Validation loss: 2.6144860554769065

Epoch: 5| Step: 11
Training loss: 1.371473515184259
Validation loss: 2.694807537893757

Epoch: 135| Step: 0
Training loss: 1.6018623629580195
Validation loss: 2.7759942908953215

Epoch: 5| Step: 1
Training loss: 1.2912550342088704
Validation loss: 2.6111294983042828

Epoch: 5| Step: 2
Training loss: 1.4693770997532583
Validation loss: 2.7058556569663454

Epoch: 5| Step: 3
Training loss: 1.0461154288794094
Validation loss: 2.5783187138386054

Epoch: 5| Step: 4
Training loss: 1.6100111509612232
Validation loss: 2.5540192456248434

Epoch: 5| Step: 5
Training loss: 1.5002906835551415
Validation loss: 2.656866196610547

Epoch: 5| Step: 6
Training loss: 1.5137965390952424
Validation loss: 2.623517344329308

Epoch: 5| Step: 7
Training loss: 1.2939595462807922
Validation loss: 2.545848358680185

Epoch: 5| Step: 8
Training loss: 2.314058757936078
Validation loss: 2.605624812388381

Epoch: 5| Step: 9
Training loss: 1.5245351895993684
Validation loss: 2.6899723317331743

Epoch: 5| Step: 10
Training loss: 1.200972675460503
Validation loss: 2.6048907697417403

Epoch: 5| Step: 11
Training loss: 1.30526277571152
Validation loss: 2.6479095337834444

Epoch: 136| Step: 0
Training loss: 1.992004984554504
Validation loss: 2.707167581168415

Epoch: 5| Step: 1
Training loss: 1.9355182972789389
Validation loss: 2.624740731590139

Epoch: 5| Step: 2
Training loss: 1.4304072335066726
Validation loss: 2.668532524658081

Epoch: 5| Step: 3
Training loss: 1.3318478186709974
Validation loss: 2.5462601315373723

Epoch: 5| Step: 4
Training loss: 1.5900932697314685
Validation loss: 2.5881024255990956

Epoch: 5| Step: 5
Training loss: 1.2855907505723403
Validation loss: 2.591212218439007

Epoch: 5| Step: 6
Training loss: 0.8736770369663682
Validation loss: 2.5286750215573734

Epoch: 5| Step: 7
Training loss: 1.4375741359003775
Validation loss: 2.6477001705449563

Epoch: 5| Step: 8
Training loss: 1.6468656738712082
Validation loss: 2.629333404708907

Epoch: 5| Step: 9
Training loss: 1.5681345245205873
Validation loss: 2.6154445405157127

Epoch: 5| Step: 10
Training loss: 1.3879956021857605
Validation loss: 2.608319703016732

Epoch: 5| Step: 11
Training loss: 1.914299775033322
Validation loss: 2.652296471303135

Epoch: 137| Step: 0
Training loss: 1.237650617430875
Validation loss: 2.591440451787995

Epoch: 5| Step: 1
Training loss: 1.5433085007176792
Validation loss: 2.6130026691168626

Epoch: 5| Step: 2
Training loss: 1.2084204817728503
Validation loss: 2.5520083293143583

Epoch: 5| Step: 3
Training loss: 1.5264919862108888
Validation loss: 2.6023076568271866

Epoch: 5| Step: 4
Training loss: 1.712596280809307
Validation loss: 2.5336974638849763

Epoch: 5| Step: 5
Training loss: 1.2253998026140869
Validation loss: 2.562969691952296

Epoch: 5| Step: 6
Training loss: 1.6074297361309142
Validation loss: 2.5954730389002525

Epoch: 5| Step: 7
Training loss: 1.441821278934242
Validation loss: 2.6156846737330723

Epoch: 5| Step: 8
Training loss: 1.4953794841053405
Validation loss: 2.6298447134131657

Epoch: 5| Step: 9
Training loss: 1.1008844114741374
Validation loss: 2.5664113439996137

Epoch: 5| Step: 10
Training loss: 1.9916001594750257
Validation loss: 2.562541075509081

Epoch: 5| Step: 11
Training loss: 1.8823707663870148
Validation loss: 2.705637159548587

Epoch: 138| Step: 0
Training loss: 1.5455861743164498
Validation loss: 2.6083203276308957

Epoch: 5| Step: 1
Training loss: 0.9670598144553131
Validation loss: 2.6384550486002922

Epoch: 5| Step: 2
Training loss: 1.5193085887333988
Validation loss: 2.5657699005059924

Epoch: 5| Step: 3
Training loss: 1.2225457772263337
Validation loss: 2.605771769184822

Epoch: 5| Step: 4
Training loss: 1.5650418015768728
Validation loss: 2.6211044057372694

Epoch: 5| Step: 5
Training loss: 1.434921024422158
Validation loss: 2.5852882169424376

Epoch: 5| Step: 6
Training loss: 1.3571781515967272
Validation loss: 2.6368102408654295

Epoch: 5| Step: 7
Training loss: 2.335693959072288
Validation loss: 2.635131761482544

Epoch: 5| Step: 8
Training loss: 1.0773424266118254
Validation loss: 2.575735792260866

Epoch: 5| Step: 9
Training loss: 1.346783164449299
Validation loss: 2.635934048906474

Epoch: 5| Step: 10
Training loss: 1.3279784177784393
Validation loss: 2.599285580374332

Epoch: 5| Step: 11
Training loss: 0.4172701478736932
Validation loss: 2.5629236328591793

Epoch: 139| Step: 0
Training loss: 1.3607687546606086
Validation loss: 2.6556710753016626

Epoch: 5| Step: 1
Training loss: 1.0893027217171567
Validation loss: 2.608693945781638

Epoch: 5| Step: 2
Training loss: 1.620325701668058
Validation loss: 2.5708141165952307

Epoch: 5| Step: 3
Training loss: 1.5631041312550116
Validation loss: 2.637119080093344

Epoch: 5| Step: 4
Training loss: 1.3681581375897762
Validation loss: 2.6389962878596833

Epoch: 5| Step: 5
Training loss: 1.5427149310369086
Validation loss: 2.630650218191104

Epoch: 5| Step: 6
Training loss: 1.2931205913898143
Validation loss: 2.5384800560797487

Epoch: 5| Step: 7
Training loss: 1.0570811483330274
Validation loss: 2.612910333225379

Epoch: 5| Step: 8
Training loss: 1.432247267526213
Validation loss: 2.5802956007449147

Epoch: 5| Step: 9
Training loss: 1.1739367341178846
Validation loss: 2.6437418260440464

Epoch: 5| Step: 10
Training loss: 1.2496170410989549
Validation loss: 2.646810660242694

Epoch: 5| Step: 11
Training loss: 3.694019954518037
Validation loss: 2.624315361780107

Epoch: 140| Step: 0
Training loss: 1.7098083950913343
Validation loss: 2.6753049811784955

Epoch: 5| Step: 1
Training loss: 1.7811344845441826
Validation loss: 2.674663133741618

Epoch: 5| Step: 2
Training loss: 1.7200239835220297
Validation loss: 2.7675982725585175

Epoch: 5| Step: 3
Training loss: 1.4812012322361225
Validation loss: 2.711471721182819

Epoch: 5| Step: 4
Training loss: 1.424000754441908
Validation loss: 2.67402039666268

Epoch: 5| Step: 5
Training loss: 1.537124420441376
Validation loss: 2.621520680859344

Epoch: 5| Step: 6
Training loss: 1.6639105499094522
Validation loss: 2.6203578402911467

Epoch: 5| Step: 7
Training loss: 1.1933057307846189
Validation loss: 2.551673335922748

Epoch: 5| Step: 8
Training loss: 1.74532579435717
Validation loss: 2.6623530417466243

Epoch: 5| Step: 9
Training loss: 1.2298984719839885
Validation loss: 2.649608780665263

Epoch: 5| Step: 10
Training loss: 1.3406321705446347
Validation loss: 2.5812813520644204

Epoch: 5| Step: 11
Training loss: 0.7481934724989513
Validation loss: 2.529565230853394

Epoch: 141| Step: 0
Training loss: 1.4361701287088453
Validation loss: 2.6419645256346005

Epoch: 5| Step: 1
Training loss: 1.3019498324302519
Validation loss: 2.5857112435955507

Epoch: 5| Step: 2
Training loss: 1.1962749122249854
Validation loss: 2.7604248418626947

Epoch: 5| Step: 3
Training loss: 1.7391253875576254
Validation loss: 2.748696907123987

Epoch: 5| Step: 4
Training loss: 1.2352186289796956
Validation loss: 2.7088030200000603

Epoch: 5| Step: 5
Training loss: 1.3388808101570366
Validation loss: 2.6536422457435225

Epoch: 5| Step: 6
Training loss: 1.4354417412076057
Validation loss: 2.614636414332292

Epoch: 5| Step: 7
Training loss: 1.5762394130753594
Validation loss: 2.685012675473859

Epoch: 5| Step: 8
Training loss: 1.89075330819054
Validation loss: 2.6201345410212475

Epoch: 5| Step: 9
Training loss: 1.2545822080372544
Validation loss: 2.5890846194709645

Epoch: 5| Step: 10
Training loss: 1.3457570722643215
Validation loss: 2.6011570489478752

Epoch: 5| Step: 11
Training loss: 0.9701233020556749
Validation loss: 2.649883505671852

Epoch: 142| Step: 0
Training loss: 1.0113946697551026
Validation loss: 2.659563862197777

Epoch: 5| Step: 1
Training loss: 1.1061411723255348
Validation loss: 2.5494284671863676

Epoch: 5| Step: 2
Training loss: 1.591067955829206
Validation loss: 2.5710104484590612

Epoch: 5| Step: 3
Training loss: 1.518173748943915
Validation loss: 2.677052057333399

Epoch: 5| Step: 4
Training loss: 1.7450965577001811
Validation loss: 2.7229191686438283

Epoch: 5| Step: 5
Training loss: 1.664418213842323
Validation loss: 2.6221964828851974

Epoch: 5| Step: 6
Training loss: 1.5492215324373022
Validation loss: 2.6644189620352674

Epoch: 5| Step: 7
Training loss: 1.286531587849686
Validation loss: 2.6580049663738414

Epoch: 5| Step: 8
Training loss: 1.4659874278852638
Validation loss: 2.673230806911169

Epoch: 5| Step: 9
Training loss: 1.8493187423250546
Validation loss: 2.5540374488773545

Epoch: 5| Step: 10
Training loss: 1.1449306168835809
Validation loss: 2.6091971117857

Epoch: 5| Step: 11
Training loss: 1.1678376905721943
Validation loss: 2.608286647764766

Epoch: 143| Step: 0
Training loss: 1.3213159032606137
Validation loss: 2.6448950505543136

Epoch: 5| Step: 1
Training loss: 2.4292044696080186
Validation loss: 2.612421737377787

Epoch: 5| Step: 2
Training loss: 1.3855509824345087
Validation loss: 2.536176753358131

Epoch: 5| Step: 3
Training loss: 1.425705999191408
Validation loss: 2.6031833483387423

Epoch: 5| Step: 4
Training loss: 0.9759746155290954
Validation loss: 2.606959768962807

Epoch: 5| Step: 5
Training loss: 1.5158575607105713
Validation loss: 2.52745141021642

Epoch: 5| Step: 6
Training loss: 1.2009853311225722
Validation loss: 2.6447101158759634

Epoch: 5| Step: 7
Training loss: 1.5920737932537183
Validation loss: 2.6584532220905506

Epoch: 5| Step: 8
Training loss: 1.6468692931450946
Validation loss: 2.6967665136625056

Epoch: 5| Step: 9
Training loss: 1.4161489700146088
Validation loss: 2.7303641230557436

Epoch: 5| Step: 10
Training loss: 1.0070544208379386
Validation loss: 2.6917270972984464

Epoch: 5| Step: 11
Training loss: 0.48276050744457283
Validation loss: 2.640001407704797

Epoch: 144| Step: 0
Training loss: 1.0270729433247323
Validation loss: 2.6048518017088056

Epoch: 5| Step: 1
Training loss: 1.1895579024144711
Validation loss: 2.622755354954876

Epoch: 5| Step: 2
Training loss: 1.4728335165090096
Validation loss: 2.602228495644187

Epoch: 5| Step: 3
Training loss: 1.6019306783119753
Validation loss: 2.6843610478232147

Epoch: 5| Step: 4
Training loss: 2.107236102721939
Validation loss: 2.5916199957968047

Epoch: 5| Step: 5
Training loss: 1.3753504739939226
Validation loss: 2.6279981801040266

Epoch: 5| Step: 6
Training loss: 1.3956605415243237
Validation loss: 2.638830135483343

Epoch: 5| Step: 7
Training loss: 1.1714538834824437
Validation loss: 2.5939825520574473

Epoch: 5| Step: 8
Training loss: 1.2602420822588
Validation loss: 2.6457073426974547

Epoch: 5| Step: 9
Training loss: 1.0486179475091282
Validation loss: 2.7107356763132517

Epoch: 5| Step: 10
Training loss: 1.2685242400358747
Validation loss: 2.6318944317056485

Epoch: 5| Step: 11
Training loss: 0.9040523387919401
Validation loss: 2.648857777274893

Epoch: 145| Step: 0
Training loss: 1.522736608225597
Validation loss: 2.690857143334168

Epoch: 5| Step: 1
Training loss: 1.2695573070492971
Validation loss: 2.657000364643589

Epoch: 5| Step: 2
Training loss: 1.4069029245947988
Validation loss: 2.649047905000957

Epoch: 5| Step: 3
Training loss: 1.0913911724209626
Validation loss: 2.5348702040605193

Epoch: 5| Step: 4
Training loss: 1.2575345413439087
Validation loss: 2.5948663515246073

Epoch: 5| Step: 5
Training loss: 1.1069286398488618
Validation loss: 2.5887830124117324

Epoch: 5| Step: 6
Training loss: 1.8143518130101701
Validation loss: 2.6240454065813203

Epoch: 5| Step: 7
Training loss: 1.228404902819256
Validation loss: 2.5909445424065276

Epoch: 5| Step: 8
Training loss: 1.1941514204072006
Validation loss: 2.6229171133811113

Epoch: 5| Step: 9
Training loss: 1.4259683564622294
Validation loss: 2.538435215857996

Epoch: 5| Step: 10
Training loss: 1.1850426998573635
Validation loss: 2.587709436371603

Epoch: 5| Step: 11
Training loss: 1.6603002149205308
Validation loss: 2.6241895601542495

Epoch: 146| Step: 0
Training loss: 1.257965552454239
Validation loss: 2.6327296884494786

Epoch: 5| Step: 1
Training loss: 1.2113645723402067
Validation loss: 2.6176738040487058

Epoch: 5| Step: 2
Training loss: 1.099310609060595
Validation loss: 2.600988338067881

Epoch: 5| Step: 3
Training loss: 1.345858760077835
Validation loss: 2.546077384946859

Epoch: 5| Step: 4
Training loss: 1.5076106435428889
Validation loss: 2.6247736061198075

Epoch: 5| Step: 5
Training loss: 1.1353817447343162
Validation loss: 2.5928617358213937

Epoch: 5| Step: 6
Training loss: 0.876828531025034
Validation loss: 2.589015642262788

Epoch: 5| Step: 7
Training loss: 1.6156537435251017
Validation loss: 2.718649332513999

Epoch: 5| Step: 8
Training loss: 1.8676389523533867
Validation loss: 2.7129318311073436

Epoch: 5| Step: 9
Training loss: 1.1958744996768498
Validation loss: 2.7060250398022903

Epoch: 5| Step: 10
Training loss: 1.3864926006038532
Validation loss: 2.645330483919418

Epoch: 5| Step: 11
Training loss: 1.9255863733326923
Validation loss: 2.6308358882166245

Epoch: 147| Step: 0
Training loss: 1.360685571768778
Validation loss: 2.652119652818306

Epoch: 5| Step: 1
Training loss: 1.8921095639093308
Validation loss: 2.5614080428535657

Epoch: 5| Step: 2
Training loss: 1.4676102619241769
Validation loss: 2.6427621300413864

Epoch: 5| Step: 3
Training loss: 0.992660349713276
Validation loss: 2.5914706168788433

Epoch: 5| Step: 4
Training loss: 1.2050694197923018
Validation loss: 2.5547316427820905

Epoch: 5| Step: 5
Training loss: 1.3930559234813045
Validation loss: 2.6846151467293

Epoch: 5| Step: 6
Training loss: 1.926482655153822
Validation loss: 2.6447984944501206

Epoch: 5| Step: 7
Training loss: 1.3415310303422332
Validation loss: 2.677674774908982

Epoch: 5| Step: 8
Training loss: 0.9774368034480808
Validation loss: 2.7557539889315326

Epoch: 5| Step: 9
Training loss: 1.673812670285821
Validation loss: 2.68839216579035

Epoch: 5| Step: 10
Training loss: 1.2727414902908556
Validation loss: 2.7007065393106147

Epoch: 5| Step: 11
Training loss: 0.4113439167465478
Validation loss: 2.654502656700954

Epoch: 148| Step: 0
Training loss: 1.0596497958559152
Validation loss: 2.6866588015318946

Epoch: 5| Step: 1
Training loss: 1.0888506558792697
Validation loss: 2.5692898572063694

Epoch: 5| Step: 2
Training loss: 1.3462819043756007
Validation loss: 2.6376191737533956

Epoch: 5| Step: 3
Training loss: 1.1476265775559384
Validation loss: 2.6446505678832968

Epoch: 5| Step: 4
Training loss: 1.5736956993473317
Validation loss: 2.615112883044189

Epoch: 5| Step: 5
Training loss: 1.0368614115867987
Validation loss: 2.6040304618819943

Epoch: 5| Step: 6
Training loss: 1.830200907721642
Validation loss: 2.622741707977761

Epoch: 5| Step: 7
Training loss: 1.3493569520323776
Validation loss: 2.5638740042535324

Epoch: 5| Step: 8
Training loss: 1.261426342601316
Validation loss: 2.580309106467967

Epoch: 5| Step: 9
Training loss: 1.4135080167194236
Validation loss: 2.5835697863151577

Epoch: 5| Step: 10
Training loss: 1.039770931729369
Validation loss: 2.541169549188009

Epoch: 5| Step: 11
Training loss: 1.3503914318573351
Validation loss: 2.5935370614454762

Epoch: 149| Step: 0
Training loss: 1.189925978305813
Validation loss: 2.616088104876866

Epoch: 5| Step: 1
Training loss: 1.8673347830044396
Validation loss: 2.6165405916306477

Epoch: 5| Step: 2
Training loss: 1.117563357850652
Validation loss: 2.669328744151559

Epoch: 5| Step: 3
Training loss: 0.683816186954763
Validation loss: 2.6173953528922564

Epoch: 5| Step: 4
Training loss: 1.4632695806051228
Validation loss: 2.6535497928169605

Epoch: 5| Step: 5
Training loss: 1.1513473081935237
Validation loss: 2.6629491774877874

Epoch: 5| Step: 6
Training loss: 1.5023380178261843
Validation loss: 2.746929032622861

Epoch: 5| Step: 7
Training loss: 1.4506572976516896
Validation loss: 2.6839401247391472

Epoch: 5| Step: 8
Training loss: 1.119777265352601
Validation loss: 2.537674639005559

Epoch: 5| Step: 9
Training loss: 1.2580459567622586
Validation loss: 2.6455829581995

Epoch: 5| Step: 10
Training loss: 1.2377128379511646
Validation loss: 2.6580900214445844

Epoch: 5| Step: 11
Training loss: 0.7660672603713543
Validation loss: 2.722263557797123

Epoch: 150| Step: 0
Training loss: 1.0149485756385868
Validation loss: 2.5865062998516675

Epoch: 5| Step: 1
Training loss: 1.3594380068153473
Validation loss: 2.613647370667079

Epoch: 5| Step: 2
Training loss: 1.340685966190284
Validation loss: 2.585916632407699

Epoch: 5| Step: 3
Training loss: 1.2549933833825517
Validation loss: 2.650756327194035

Epoch: 5| Step: 4
Training loss: 1.4174679378805835
Validation loss: 2.56640327720528

Epoch: 5| Step: 5
Training loss: 1.9016709910328826
Validation loss: 2.5995108960512687

Epoch: 5| Step: 6
Training loss: 1.2691737684041584
Validation loss: 2.6781706339844145

Epoch: 5| Step: 7
Training loss: 1.2229924333920035
Validation loss: 2.6589372617544225

Epoch: 5| Step: 8
Training loss: 1.3935106747686847
Validation loss: 2.6141685344246333

Epoch: 5| Step: 9
Training loss: 0.9778550101402947
Validation loss: 2.730963760786918

Epoch: 5| Step: 10
Training loss: 0.8840067389908851
Validation loss: 2.660755442888936

Epoch: 5| Step: 11
Training loss: 1.586993162091144
Validation loss: 2.6361116666450446

Epoch: 151| Step: 0
Training loss: 1.4214471865090252
Validation loss: 2.57064332156798

Epoch: 5| Step: 1
Training loss: 1.7880582031232506
Validation loss: 2.698777143805106

Epoch: 5| Step: 2
Training loss: 1.168514213645324
Validation loss: 2.571035053607458

Epoch: 5| Step: 3
Training loss: 1.3222589985668756
Validation loss: 2.592314338148586

Epoch: 5| Step: 4
Training loss: 0.9904076238456632
Validation loss: 2.633788187443851

Epoch: 5| Step: 5
Training loss: 1.1742380350017831
Validation loss: 2.5291910274553695

Epoch: 5| Step: 6
Training loss: 0.9885039851272823
Validation loss: 2.63550639408139

Epoch: 5| Step: 7
Training loss: 1.0802401374590913
Validation loss: 2.611488320252405

Epoch: 5| Step: 8
Training loss: 0.9908117533441357
Validation loss: 2.5667524370398835

Epoch: 5| Step: 9
Training loss: 1.3756615174510418
Validation loss: 2.6030818294503666

Epoch: 5| Step: 10
Training loss: 1.2130603026600573
Validation loss: 2.596984531680166

Epoch: 5| Step: 11
Training loss: 1.5525008115904524
Validation loss: 2.639037492120519

Epoch: 152| Step: 0
Training loss: 1.0047339207676516
Validation loss: 2.595057119826224

Epoch: 5| Step: 1
Training loss: 1.1732301632992284
Validation loss: 2.5947639597594336

Epoch: 5| Step: 2
Training loss: 1.08010064044683
Validation loss: 2.6074177564571777

Epoch: 5| Step: 3
Training loss: 1.5271497051947514
Validation loss: 2.688540911363399

Epoch: 5| Step: 4
Training loss: 1.5196626503426862
Validation loss: 2.5793928053900466

Epoch: 5| Step: 5
Training loss: 1.1120691493818615
Validation loss: 2.6265760451282816

Epoch: 5| Step: 6
Training loss: 1.0239125088553247
Validation loss: 2.612889920572627

Epoch: 5| Step: 7
Training loss: 1.2841411628311237
Validation loss: 2.759077086590678

Epoch: 5| Step: 8
Training loss: 1.2775448048865985
Validation loss: 2.6430172589426895

Epoch: 5| Step: 9
Training loss: 1.7913177135630303
Validation loss: 2.7294978469853652

Epoch: 5| Step: 10
Training loss: 1.0278156197658013
Validation loss: 2.7715371225224423

Epoch: 5| Step: 11
Training loss: 1.2467258488450237
Validation loss: 2.781709893740047

Epoch: 153| Step: 0
Training loss: 1.427994022164535
Validation loss: 2.7026468122294394

Epoch: 5| Step: 1
Training loss: 1.138025535498128
Validation loss: 2.7506213533804496

Epoch: 5| Step: 2
Training loss: 1.0446759941797992
Validation loss: 2.658458834757922

Epoch: 5| Step: 3
Training loss: 1.0799653199597077
Validation loss: 2.6643947345677796

Epoch: 5| Step: 4
Training loss: 1.2269769442194576
Validation loss: 2.6257714224164883

Epoch: 5| Step: 5
Training loss: 1.841782894465762
Validation loss: 2.5883435506756163

Epoch: 5| Step: 6
Training loss: 1.2767683593911938
Validation loss: 2.7065902284655947

Epoch: 5| Step: 7
Training loss: 1.4521732289725562
Validation loss: 2.6099214647859355

Epoch: 5| Step: 8
Training loss: 1.0749667805706575
Validation loss: 2.7530243527926146

Epoch: 5| Step: 9
Training loss: 1.2408918905606334
Validation loss: 2.75778964053902

Epoch: 5| Step: 10
Training loss: 1.2805802059950038
Validation loss: 2.6656895662860682

Epoch: 5| Step: 11
Training loss: 0.4655697226515256
Validation loss: 2.596850713439558

Epoch: 154| Step: 0
Training loss: 1.1559872199774355
Validation loss: 2.57359209474525

Epoch: 5| Step: 1
Training loss: 1.7983281106434035
Validation loss: 2.6089891197883754

Epoch: 5| Step: 2
Training loss: 1.2007711595000867
Validation loss: 2.530517896108428

Epoch: 5| Step: 3
Training loss: 1.2382500581392812
Validation loss: 2.5712944984016377

Epoch: 5| Step: 4
Training loss: 1.5129265112921237
Validation loss: 2.59299254177113

Epoch: 5| Step: 5
Training loss: 0.9409507187516909
Validation loss: 2.659030664970478

Epoch: 5| Step: 6
Training loss: 1.1995454026470944
Validation loss: 2.6039039377560305

Epoch: 5| Step: 7
Training loss: 1.0227401920427381
Validation loss: 2.6033352414729425

Epoch: 5| Step: 8
Training loss: 0.9660823763480627
Validation loss: 2.76687883522004

Epoch: 5| Step: 9
Training loss: 1.2660572114615463
Validation loss: 2.697520983092607

Epoch: 5| Step: 10
Training loss: 1.3618179819146496
Validation loss: 2.666215971520771

Epoch: 5| Step: 11
Training loss: 0.45199069738204245
Validation loss: 2.6160863960850977

Epoch: 155| Step: 0
Training loss: 1.2804000640564044
Validation loss: 2.6231855827766197

Epoch: 5| Step: 1
Training loss: 1.14594673404765
Validation loss: 2.6061371189557585

Epoch: 5| Step: 2
Training loss: 1.3318797274236678
Validation loss: 2.5625935882442645

Epoch: 5| Step: 3
Training loss: 1.0694840280767826
Validation loss: 2.6132321773648615

Epoch: 5| Step: 4
Training loss: 1.465649924645848
Validation loss: 2.633709800846743

Epoch: 5| Step: 5
Training loss: 1.4097908793592315
Validation loss: 2.596376311202328

Epoch: 5| Step: 6
Training loss: 1.8471915243302122
Validation loss: 2.616278400336861

Epoch: 5| Step: 7
Training loss: 0.8996541285843113
Validation loss: 2.6024915393834736

Epoch: 5| Step: 8
Training loss: 1.0089427908415025
Validation loss: 2.7373038745687936

Epoch: 5| Step: 9
Training loss: 0.9660122548563995
Validation loss: 2.7024113663081657

Epoch: 5| Step: 10
Training loss: 0.7714939937716234
Validation loss: 2.680180321725076

Epoch: 5| Step: 11
Training loss: 1.5549972455653485
Validation loss: 2.7121136557209966

Epoch: 156| Step: 0
Training loss: 1.1490290668718606
Validation loss: 2.787831202960512

Epoch: 5| Step: 1
Training loss: 1.323386411795484
Validation loss: 2.7477276582091594

Epoch: 5| Step: 2
Training loss: 1.014234970778775
Validation loss: 2.657332446628929

Epoch: 5| Step: 3
Training loss: 1.3596158307597417
Validation loss: 2.6106418305995245

Epoch: 5| Step: 4
Training loss: 1.3497193839565917
Validation loss: 2.639426939610794

Epoch: 5| Step: 5
Training loss: 1.6436424481267011
Validation loss: 2.5984852436058463

Epoch: 5| Step: 6
Training loss: 0.7364040912327002
Validation loss: 2.6112304342062487

Epoch: 5| Step: 7
Training loss: 0.8441457526718936
Validation loss: 2.655140996812209

Epoch: 5| Step: 8
Training loss: 1.0170649957208389
Validation loss: 2.5953244099735113

Epoch: 5| Step: 9
Training loss: 1.8263083014297827
Validation loss: 2.6059555331035194

Epoch: 5| Step: 10
Training loss: 1.0958723457750716
Validation loss: 2.570113331847675

Epoch: 5| Step: 11
Training loss: 0.7687253265763261
Validation loss: 2.6134195333937695

Epoch: 157| Step: 0
Training loss: 1.08035330000445
Validation loss: 2.638735108049669

Epoch: 5| Step: 1
Training loss: 0.809785011453239
Validation loss: 2.6336878671183497

Epoch: 5| Step: 2
Training loss: 1.9115400859871323
Validation loss: 2.684750285059238

Epoch: 5| Step: 3
Training loss: 1.1470787678073566
Validation loss: 2.692762124700558

Epoch: 5| Step: 4
Training loss: 1.4150796677770499
Validation loss: 2.639629232694514

Epoch: 5| Step: 5
Training loss: 1.0494463073786184
Validation loss: 2.6878569720744543

Epoch: 5| Step: 6
Training loss: 1.1068942850114087
Validation loss: 2.6257368521931572

Epoch: 5| Step: 7
Training loss: 1.0605758747330027
Validation loss: 2.6755276302236215

Epoch: 5| Step: 8
Training loss: 1.0178888765326362
Validation loss: 2.5426784179711337

Epoch: 5| Step: 9
Training loss: 1.443457407841944
Validation loss: 2.585700190355044

Epoch: 5| Step: 10
Training loss: 1.3749349318627353
Validation loss: 2.6515686520632675

Epoch: 5| Step: 11
Training loss: 0.47547491450079077
Validation loss: 2.63509018701446

Epoch: 158| Step: 0
Training loss: 1.0337598486988162
Validation loss: 2.703694606956643

Epoch: 5| Step: 1
Training loss: 1.0634332933547281
Validation loss: 2.648474438915134

Epoch: 5| Step: 2
Training loss: 1.8012870690517535
Validation loss: 2.6349883780684586

Epoch: 5| Step: 3
Training loss: 1.491529629271409
Validation loss: 2.7112354770738674

Epoch: 5| Step: 4
Training loss: 1.1181191247963755
Validation loss: 2.592314575741159

Epoch: 5| Step: 5
Training loss: 1.1856487299545746
Validation loss: 2.638730040727283

Epoch: 5| Step: 6
Training loss: 1.0611867642743003
Validation loss: 2.6486953639824935

Epoch: 5| Step: 7
Training loss: 1.3131775242624153
Validation loss: 2.6787277223008092

Epoch: 5| Step: 8
Training loss: 0.9916167833032786
Validation loss: 2.6663550900188704

Epoch: 5| Step: 9
Training loss: 0.9682056374210611
Validation loss: 2.6367808920990266

Epoch: 5| Step: 10
Training loss: 1.016572363706217
Validation loss: 2.672059593739637

Epoch: 5| Step: 11
Training loss: 0.5966265665685522
Validation loss: 2.6368095024409097

Epoch: 159| Step: 0
Training loss: 1.026632084222771
Validation loss: 2.7030989033756825

Epoch: 5| Step: 1
Training loss: 1.0718996295379188
Validation loss: 2.7191285585978644

Epoch: 5| Step: 2
Training loss: 1.5208318875798013
Validation loss: 2.67357124708988

Epoch: 5| Step: 3
Training loss: 1.311494851102622
Validation loss: 2.7065375402163165

Epoch: 5| Step: 4
Training loss: 1.5908813839518536
Validation loss: 2.6358161360911017

Epoch: 5| Step: 5
Training loss: 0.9339916386914164
Validation loss: 2.694428034341355

Epoch: 5| Step: 6
Training loss: 0.9871387134655887
Validation loss: 2.543602336624799

Epoch: 5| Step: 7
Training loss: 0.9391150867635066
Validation loss: 2.598368630688434

Epoch: 5| Step: 8
Training loss: 1.1187524571738083
Validation loss: 2.5877285811835966

Epoch: 5| Step: 9
Training loss: 1.1201700798390946
Validation loss: 2.6140644912575333

Epoch: 5| Step: 10
Training loss: 1.3260630140161982
Validation loss: 2.598253522772352

Epoch: 5| Step: 11
Training loss: 0.5993471846028353
Validation loss: 2.6255989375368776

Epoch: 160| Step: 0
Training loss: 1.04437492530407
Validation loss: 2.6361238086270915

Epoch: 5| Step: 1
Training loss: 0.9806714399341757
Validation loss: 2.6170747305644597

Epoch: 5| Step: 2
Training loss: 1.1172230854902616
Validation loss: 2.685441008359581

Epoch: 5| Step: 3
Training loss: 1.0654136313846592
Validation loss: 2.787512725322056

Epoch: 5| Step: 4
Training loss: 1.2504355625418433
Validation loss: 2.713327195569094

Epoch: 5| Step: 5
Training loss: 1.2623748962813273
Validation loss: 2.670595788633005

Epoch: 5| Step: 6
Training loss: 1.613573985292265
Validation loss: 2.705850109570746

Epoch: 5| Step: 7
Training loss: 1.1396050269219877
Validation loss: 2.6093625774582763

Epoch: 5| Step: 8
Training loss: 1.117254561965721
Validation loss: 2.680234350934876

Epoch: 5| Step: 9
Training loss: 1.150941571102353
Validation loss: 2.654851702483505

Epoch: 5| Step: 10
Training loss: 0.9528532109707439
Validation loss: 2.6387665997718983

Epoch: 5| Step: 11
Training loss: 0.7845208932830793
Validation loss: 2.705710293823646

Epoch: 161| Step: 0
Training loss: 0.9175018421747075
Validation loss: 2.6413450331590878

Epoch: 5| Step: 1
Training loss: 1.6096813317760021
Validation loss: 2.673534301931572

Epoch: 5| Step: 2
Training loss: 1.203560787394832
Validation loss: 2.6382959052347097

Epoch: 5| Step: 3
Training loss: 0.9848578343692337
Validation loss: 2.581271838510665

Epoch: 5| Step: 4
Training loss: 1.132362592079004
Validation loss: 2.6773759531088612

Epoch: 5| Step: 5
Training loss: 1.4134056715551762
Validation loss: 2.6137152721470205

Epoch: 5| Step: 6
Training loss: 0.7325723315515643
Validation loss: 2.7145742195680986

Epoch: 5| Step: 7
Training loss: 1.3032599765755024
Validation loss: 2.6927741034694543

Epoch: 5| Step: 8
Training loss: 0.9331387165080915
Validation loss: 2.763513035247872

Epoch: 5| Step: 9
Training loss: 1.0987207538587873
Validation loss: 2.723493636094963

Epoch: 5| Step: 10
Training loss: 1.6287038114707253
Validation loss: 2.6866735289105823

Epoch: 5| Step: 11
Training loss: 0.4754534150959233
Validation loss: 2.6870556508375083

Epoch: 162| Step: 0
Training loss: 0.9047330130030945
Validation loss: 2.6681222308327612

Epoch: 5| Step: 1
Training loss: 1.2176284520184788
Validation loss: 2.6201435760295255

Epoch: 5| Step: 2
Training loss: 1.3735350694598711
Validation loss: 2.6265195202719642

Epoch: 5| Step: 3
Training loss: 0.8509534355069568
Validation loss: 2.6304438960781282

Epoch: 5| Step: 4
Training loss: 1.140425364124683
Validation loss: 2.6175020702588268

Epoch: 5| Step: 5
Training loss: 0.7656903141733824
Validation loss: 2.6800494158160255

Epoch: 5| Step: 6
Training loss: 1.0361729649162184
Validation loss: 2.6254123522814803

Epoch: 5| Step: 7
Training loss: 1.5616210754291475
Validation loss: 2.6961114703583267

Epoch: 5| Step: 8
Training loss: 1.001851037608085
Validation loss: 2.5788527761957587

Epoch: 5| Step: 9
Training loss: 1.0235095399151999
Validation loss: 2.6627840160763543

Epoch: 5| Step: 10
Training loss: 1.0930537051053657
Validation loss: 2.6871512467666046

Epoch: 5| Step: 11
Training loss: 0.8959442040492305
Validation loss: 2.6298962222197844

Epoch: 163| Step: 0
Training loss: 1.241925961773969
Validation loss: 2.604176293673205

Epoch: 5| Step: 1
Training loss: 0.6967244759748026
Validation loss: 2.5891845999707375

Epoch: 5| Step: 2
Training loss: 1.132227937553746
Validation loss: 2.6109707877203783

Epoch: 5| Step: 3
Training loss: 1.2214102444114336
Validation loss: 2.623273898838507

Epoch: 5| Step: 4
Training loss: 1.1969496541856517
Validation loss: 2.6271611732811553

Epoch: 5| Step: 5
Training loss: 0.9561969779779281
Validation loss: 2.5863625713928142

Epoch: 5| Step: 6
Training loss: 1.0113531210511488
Validation loss: 2.6559146594628773

Epoch: 5| Step: 7
Training loss: 1.0152060011230166
Validation loss: 2.616296705791099

Epoch: 5| Step: 8
Training loss: 0.9522636148286171
Validation loss: 2.584745284018676

Epoch: 5| Step: 9
Training loss: 1.1652734589424065
Validation loss: 2.6029657659412972

Epoch: 5| Step: 10
Training loss: 1.57713982074852
Validation loss: 2.669864708810056

Epoch: 5| Step: 11
Training loss: 1.577445233175727
Validation loss: 2.716860000970281

Epoch: 164| Step: 0
Training loss: 0.7739147678879226
Validation loss: 2.660709803380266

Epoch: 5| Step: 1
Training loss: 0.7507427828934418
Validation loss: 2.5970498010506686

Epoch: 5| Step: 2
Training loss: 0.9005706673301483
Validation loss: 2.599949012769923

Epoch: 5| Step: 3
Training loss: 1.3304611752395803
Validation loss: 2.5886831468772593

Epoch: 5| Step: 4
Training loss: 1.2644021991212204
Validation loss: 2.6454557589956487

Epoch: 5| Step: 5
Training loss: 0.7232692283872393
Validation loss: 2.6405701565737316

Epoch: 5| Step: 6
Training loss: 1.3227219575985507
Validation loss: 2.6266195470699203

Epoch: 5| Step: 7
Training loss: 0.846368400258418
Validation loss: 2.5675982528416816

Epoch: 5| Step: 8
Training loss: 1.812563270253785
Validation loss: 2.647065237565778

Epoch: 5| Step: 9
Training loss: 0.7932040612365433
Validation loss: 2.586551681679668

Epoch: 5| Step: 10
Training loss: 1.2266621154375923
Validation loss: 2.7071418757951524

Epoch: 5| Step: 11
Training loss: 0.8286065554865703
Validation loss: 2.76802803426118

Epoch: 165| Step: 0
Training loss: 1.265151182421061
Validation loss: 2.6200781388133056

Epoch: 5| Step: 1
Training loss: 0.9957849959023635
Validation loss: 2.6920080227323737

Epoch: 5| Step: 2
Training loss: 1.1438513288794772
Validation loss: 2.705854449096267

Epoch: 5| Step: 3
Training loss: 0.7386336116472743
Validation loss: 2.615321060350803

Epoch: 5| Step: 4
Training loss: 0.8229673748247496
Validation loss: 2.664151366421275

Epoch: 5| Step: 5
Training loss: 1.0563198314809794
Validation loss: 2.6418173428613607

Epoch: 5| Step: 6
Training loss: 1.26308232842669
Validation loss: 2.640551763568564

Epoch: 5| Step: 7
Training loss: 1.6773592404066469
Validation loss: 2.534922545426656

Epoch: 5| Step: 8
Training loss: 0.7868813688521911
Validation loss: 2.5432899338676176

Epoch: 5| Step: 9
Training loss: 0.984525941447888
Validation loss: 2.5323288820001726

Epoch: 5| Step: 10
Training loss: 1.2518477611273224
Validation loss: 2.582759752483034

Epoch: 5| Step: 11
Training loss: 1.7176489337608132
Validation loss: 2.6431461427675402

Epoch: 166| Step: 0
Training loss: 1.0563501321855806
Validation loss: 2.6638251578320835

Epoch: 5| Step: 1
Training loss: 1.2491576217381588
Validation loss: 2.6872966896453985

Epoch: 5| Step: 2
Training loss: 1.0494939583744876
Validation loss: 2.6680248956464814

Epoch: 5| Step: 3
Training loss: 0.6871058678117326
Validation loss: 2.6160641968799356

Epoch: 5| Step: 4
Training loss: 1.075500722085949
Validation loss: 2.6798318429223857

Epoch: 5| Step: 5
Training loss: 0.8928854181717121
Validation loss: 2.666878305669595

Epoch: 5| Step: 6
Training loss: 0.9393642010705753
Validation loss: 2.6331795984573545

Epoch: 5| Step: 7
Training loss: 1.1687502080743777
Validation loss: 2.685000895169119

Epoch: 5| Step: 8
Training loss: 0.9934170531082351
Validation loss: 2.6850519156513135

Epoch: 5| Step: 9
Training loss: 1.1558420131626055
Validation loss: 2.687690166280605

Epoch: 5| Step: 10
Training loss: 1.7963875814375136
Validation loss: 2.684818815550556

Epoch: 5| Step: 11
Training loss: 1.067606491566228
Validation loss: 2.579442679704516

Epoch: 167| Step: 0
Training loss: 0.7717143428264978
Validation loss: 2.752259189830962

Epoch: 5| Step: 1
Training loss: 1.3167292258132337
Validation loss: 2.7409670795709973

Epoch: 5| Step: 2
Training loss: 0.8305581174837177
Validation loss: 2.6038058844832443

Epoch: 5| Step: 3
Training loss: 1.2227553062409624
Validation loss: 2.63327385306081

Epoch: 5| Step: 4
Training loss: 0.9196923813996567
Validation loss: 2.58770289861812

Epoch: 5| Step: 5
Training loss: 0.9334778015406892
Validation loss: 2.5262834544658768

Epoch: 5| Step: 6
Training loss: 1.0338753314538314
Validation loss: 2.6216885516709714

Epoch: 5| Step: 7
Training loss: 0.9815562323145767
Validation loss: 2.5648488080612664

Epoch: 5| Step: 8
Training loss: 1.7442588637920795
Validation loss: 2.6703484061267373

Epoch: 5| Step: 9
Training loss: 0.9855120313656093
Validation loss: 2.662829418578546

Epoch: 5| Step: 10
Training loss: 1.1898215839728332
Validation loss: 2.6891887666920917

Epoch: 5| Step: 11
Training loss: 1.6758402922928595
Validation loss: 2.668293353729754

Epoch: 168| Step: 0
Training loss: 0.7191263954789593
Validation loss: 2.7056504361419855

Epoch: 5| Step: 1
Training loss: 0.861223625366138
Validation loss: 2.611481328486898

Epoch: 5| Step: 2
Training loss: 0.9357138466807993
Validation loss: 2.611257199770076

Epoch: 5| Step: 3
Training loss: 0.8848756296516912
Validation loss: 2.746062939228186

Epoch: 5| Step: 4
Training loss: 1.7436226719682038
Validation loss: 2.6896959950977113

Epoch: 5| Step: 5
Training loss: 1.1382170565483931
Validation loss: 2.6756008523613093

Epoch: 5| Step: 6
Training loss: 1.1171065614631406
Validation loss: 2.6453319222131007

Epoch: 5| Step: 7
Training loss: 1.0358977343261524
Validation loss: 2.702430863826775

Epoch: 5| Step: 8
Training loss: 1.0639828264205713
Validation loss: 2.660849019354909

Epoch: 5| Step: 9
Training loss: 1.0385640605219895
Validation loss: 2.649272018282562

Epoch: 5| Step: 10
Training loss: 1.0018372942801193
Validation loss: 2.6582084653839497

Epoch: 5| Step: 11
Training loss: 1.099373394052483
Validation loss: 2.6560270889097213

Epoch: 169| Step: 0
Training loss: 1.1796348509503007
Validation loss: 2.6872205662910105

Epoch: 5| Step: 1
Training loss: 0.7359842969914088
Validation loss: 2.6732522489692325

Epoch: 5| Step: 2
Training loss: 0.8650521114396138
Validation loss: 2.7118367985548195

Epoch: 5| Step: 3
Training loss: 0.9860788162447354
Validation loss: 2.6852647297929355

Epoch: 5| Step: 4
Training loss: 1.2179862343522332
Validation loss: 2.742121417634128

Epoch: 5| Step: 5
Training loss: 0.6494497877347498
Validation loss: 2.6966820780094056

Epoch: 5| Step: 6
Training loss: 0.7850462423663357
Validation loss: 2.6660772221008653

Epoch: 5| Step: 7
Training loss: 1.1853867348823532
Validation loss: 2.7571840948131174

Epoch: 5| Step: 8
Training loss: 1.1082708747493217
Validation loss: 2.66158726722666

Epoch: 5| Step: 9
Training loss: 1.74679885725609
Validation loss: 2.6084566232429607

Epoch: 5| Step: 10
Training loss: 0.8536353823798075
Validation loss: 2.6220953023182614

Epoch: 5| Step: 11
Training loss: 0.6679470884145869
Validation loss: 2.5931612327019895

Epoch: 170| Step: 0
Training loss: 1.0413056447340545
Validation loss: 2.630346526238983

Epoch: 5| Step: 1
Training loss: 1.1116340095569284
Validation loss: 2.5874801444552644

Epoch: 5| Step: 2
Training loss: 1.0238654719661409
Validation loss: 2.6404944957559486

Epoch: 5| Step: 3
Training loss: 1.2815969044053865
Validation loss: 2.651605262628822

Epoch: 5| Step: 4
Training loss: 0.91304729196293
Validation loss: 2.6738505579636898

Epoch: 5| Step: 5
Training loss: 0.9599472153576405
Validation loss: 2.6228778791299248

Epoch: 5| Step: 6
Training loss: 0.8907299314556661
Validation loss: 2.6618967566101506

Epoch: 5| Step: 7
Training loss: 1.0059345106191262
Validation loss: 2.5948232207542157

Epoch: 5| Step: 8
Training loss: 1.8094925758228486
Validation loss: 2.663823140299455

Epoch: 5| Step: 9
Training loss: 0.886493032353834
Validation loss: 2.6257140384339706

Epoch: 5| Step: 10
Training loss: 1.0345759078543
Validation loss: 2.541190416763698

Epoch: 5| Step: 11
Training loss: 1.2343528842152012
Validation loss: 2.589492797087297

Epoch: 171| Step: 0
Training loss: 1.137834453669566
Validation loss: 2.5712915003506986

Epoch: 5| Step: 1
Training loss: 1.0591709491834245
Validation loss: 2.5731452050171306

Epoch: 5| Step: 2
Training loss: 1.0584335487456407
Validation loss: 2.563452462219301

Epoch: 5| Step: 3
Training loss: 1.013064046034503
Validation loss: 2.70037006458821

Epoch: 5| Step: 4
Training loss: 0.7724761382679859
Validation loss: 2.7055544070120203

Epoch: 5| Step: 5
Training loss: 1.094686379830944
Validation loss: 2.741435995852822

Epoch: 5| Step: 6
Training loss: 1.0902589943490084
Validation loss: 2.677894930636821

Epoch: 5| Step: 7
Training loss: 0.9402562632150538
Validation loss: 2.7015245252933133

Epoch: 5| Step: 8
Training loss: 0.7927666016533242
Validation loss: 2.6416851075147503

Epoch: 5| Step: 9
Training loss: 0.864113867890102
Validation loss: 2.5919787015667803

Epoch: 5| Step: 10
Training loss: 1.5550182508274604
Validation loss: 2.703028612862276

Epoch: 5| Step: 11
Training loss: 0.6779645149782675
Validation loss: 2.6956727049807787

Epoch: 172| Step: 0
Training loss: 0.8035411632227357
Validation loss: 2.6738108227329977

Epoch: 5| Step: 1
Training loss: 1.2055832655798921
Validation loss: 2.7443720601187076

Epoch: 5| Step: 2
Training loss: 1.0319427128830478
Validation loss: 2.683240431358104

Epoch: 5| Step: 3
Training loss: 0.9392487428528306
Validation loss: 2.750927606105725

Epoch: 5| Step: 4
Training loss: 1.6399742652455631
Validation loss: 2.67005540931966

Epoch: 5| Step: 5
Training loss: 1.026693798476636
Validation loss: 2.65618040704254

Epoch: 5| Step: 6
Training loss: 0.6109827302936406
Validation loss: 2.688347217179466

Epoch: 5| Step: 7
Training loss: 0.9650554965175021
Validation loss: 2.749730342590911

Epoch: 5| Step: 8
Training loss: 0.8659501742285874
Validation loss: 2.656631001093867

Epoch: 5| Step: 9
Training loss: 0.5740270489257514
Validation loss: 2.719664211688512

Epoch: 5| Step: 10
Training loss: 1.1783361716193548
Validation loss: 2.708974671844949

Epoch: 5| Step: 11
Training loss: 0.6765108304633468
Validation loss: 2.6400463854743745

Epoch: 173| Step: 0
Training loss: 1.0597603763685166
Validation loss: 2.699459670595844

Epoch: 5| Step: 1
Training loss: 0.9058684499531957
Validation loss: 2.7297832190550713

Epoch: 5| Step: 2
Training loss: 0.7301353060728558
Validation loss: 2.6410063105246238

Epoch: 5| Step: 3
Training loss: 0.7824337955048623
Validation loss: 2.651169435960772

Epoch: 5| Step: 4
Training loss: 1.6443874994003707
Validation loss: 2.662263148851319

Epoch: 5| Step: 5
Training loss: 0.9298943361635157
Validation loss: 2.6832980530257755

Epoch: 5| Step: 6
Training loss: 1.0508818737761279
Validation loss: 2.6498819461354

Epoch: 5| Step: 7
Training loss: 0.9027861134233947
Validation loss: 2.67105776388885

Epoch: 5| Step: 8
Training loss: 1.0716943660931488
Validation loss: 2.74489324527719

Epoch: 5| Step: 9
Training loss: 1.2378756945050609
Validation loss: 2.7341298565648553

Epoch: 5| Step: 10
Training loss: 0.7365757857084639
Validation loss: 2.7387764483413406

Epoch: 5| Step: 11
Training loss: 1.6364674523202904
Validation loss: 2.7143537449646837

Epoch: 174| Step: 0
Training loss: 1.15997842267127
Validation loss: 2.703208903662452

Epoch: 5| Step: 1
Training loss: 0.9569241210767628
Validation loss: 2.7383818904940758

Epoch: 5| Step: 2
Training loss: 0.670438828379614
Validation loss: 2.7569900921828165

Epoch: 5| Step: 3
Training loss: 0.9574440202210229
Validation loss: 2.641111959140997

Epoch: 5| Step: 4
Training loss: 0.8075142625310909
Validation loss: 2.7193149622739057

Epoch: 5| Step: 5
Training loss: 0.7575161541264399
Validation loss: 2.605659153818842

Epoch: 5| Step: 6
Training loss: 0.7380969105026237
Validation loss: 2.602711627098773

Epoch: 5| Step: 7
Training loss: 1.04792857886964
Validation loss: 2.7039188861964982

Epoch: 5| Step: 8
Training loss: 0.8415619772460764
Validation loss: 2.6676638509509174

Epoch: 5| Step: 9
Training loss: 0.79823803733753
Validation loss: 2.6830257719801898

Epoch: 5| Step: 10
Training loss: 1.8239442671911157
Validation loss: 2.7747696681415244

Epoch: 5| Step: 11
Training loss: 1.0306841135740266
Validation loss: 2.680565948636381

Epoch: 175| Step: 0
Training loss: 0.6553129590732784
Validation loss: 2.6766584271909455

Epoch: 5| Step: 1
Training loss: 1.2601122002373002
Validation loss: 2.705494472444906

Epoch: 5| Step: 2
Training loss: 0.758477381414885
Validation loss: 2.5734086911152922

Epoch: 5| Step: 3
Training loss: 0.8964150262741802
Validation loss: 2.6588421384493874

Epoch: 5| Step: 4
Training loss: 0.9858315908191423
Validation loss: 2.661751693015636

Epoch: 5| Step: 5
Training loss: 1.6960258565182293
Validation loss: 2.689363303123981

Epoch: 5| Step: 6
Training loss: 0.7647484413123606
Validation loss: 2.55857640228991

Epoch: 5| Step: 7
Training loss: 0.9137681340350311
Validation loss: 2.7248929476635504

Epoch: 5| Step: 8
Training loss: 0.9569213181241734
Validation loss: 2.759566105251186

Epoch: 5| Step: 9
Training loss: 1.0082961703511402
Validation loss: 2.6536297009956966

Epoch: 5| Step: 10
Training loss: 0.7379396243610434
Validation loss: 2.7274023837399017

Epoch: 5| Step: 11
Training loss: 1.0784909829623592
Validation loss: 2.7280538282399838

Epoch: 176| Step: 0
Training loss: 1.0044714972827524
Validation loss: 2.6089040708170077

Epoch: 5| Step: 1
Training loss: 0.8858952332225117
Validation loss: 2.7250647489047144

Epoch: 5| Step: 2
Training loss: 0.941022422705801
Validation loss: 2.703093251095171

Epoch: 5| Step: 3
Training loss: 0.9915246326177984
Validation loss: 2.727874218082332

Epoch: 5| Step: 4
Training loss: 0.7397327182681042
Validation loss: 2.6950390147167136

Epoch: 5| Step: 5
Training loss: 0.8149063349651835
Validation loss: 2.7015512843107885

Epoch: 5| Step: 6
Training loss: 0.8522220821938641
Validation loss: 2.733015005592526

Epoch: 5| Step: 7
Training loss: 0.8266068704446488
Validation loss: 2.6601038968260293

Epoch: 5| Step: 8
Training loss: 1.044083874234471
Validation loss: 2.651052078996057

Epoch: 5| Step: 9
Training loss: 0.85662825923819
Validation loss: 2.7315255277091244

Epoch: 5| Step: 10
Training loss: 1.7722210850540918
Validation loss: 2.6630780217932375

Epoch: 5| Step: 11
Training loss: 1.381435333522252
Validation loss: 2.674326844352024

Epoch: 177| Step: 0
Training loss: 0.6987034694485579
Validation loss: 2.810712140110711

Epoch: 5| Step: 1
Training loss: 1.105988073860697
Validation loss: 2.6463367754139466

Epoch: 5| Step: 2
Training loss: 0.9900895112444817
Validation loss: 2.788799907528999

Epoch: 5| Step: 3
Training loss: 1.6124929206160457
Validation loss: 2.6834374335533955

Epoch: 5| Step: 4
Training loss: 0.9321247818117729
Validation loss: 2.7536980408222376

Epoch: 5| Step: 5
Training loss: 1.110798473216578
Validation loss: 2.694320370798653

Epoch: 5| Step: 6
Training loss: 0.9209502803250953
Validation loss: 2.613612584965863

Epoch: 5| Step: 7
Training loss: 1.2292214990228463
Validation loss: 2.800991424662274

Epoch: 5| Step: 8
Training loss: 0.8105148492943645
Validation loss: 2.6807258344063443

Epoch: 5| Step: 9
Training loss: 0.8470513783019394
Validation loss: 2.733106976727432

Epoch: 5| Step: 10
Training loss: 0.8401739491575462
Validation loss: 2.6981896013236373

Epoch: 5| Step: 11
Training loss: 0.7414589367748212
Validation loss: 2.656972566199771

Epoch: 178| Step: 0
Training loss: 0.7627171941883485
Validation loss: 2.7475307425450053

Epoch: 5| Step: 1
Training loss: 0.942624581903826
Validation loss: 2.758122971504665

Epoch: 5| Step: 2
Training loss: 0.8642358119772163
Validation loss: 2.6493051396163096

Epoch: 5| Step: 3
Training loss: 0.7790907584832919
Validation loss: 2.642749898270648

Epoch: 5| Step: 4
Training loss: 0.8699281703411147
Validation loss: 2.5766787412357637

Epoch: 5| Step: 5
Training loss: 0.7516073249249836
Validation loss: 2.5958673383609163

Epoch: 5| Step: 6
Training loss: 1.6954939784643621
Validation loss: 2.647276786235419

Epoch: 5| Step: 7
Training loss: 1.2029588262562634
Validation loss: 2.6469015883514366

Epoch: 5| Step: 8
Training loss: 0.6696002510685604
Validation loss: 2.6412169754134953

Epoch: 5| Step: 9
Training loss: 0.9272962961372018
Validation loss: 2.6485186088992827

Epoch: 5| Step: 10
Training loss: 1.0390077734281002
Validation loss: 2.6801814559160166

Epoch: 5| Step: 11
Training loss: 0.5925011551519794
Validation loss: 2.661609109139962

Epoch: 179| Step: 0
Training loss: 0.9489171369189698
Validation loss: 2.6936476794972815

Epoch: 5| Step: 1
Training loss: 0.659360801399272
Validation loss: 2.7351396345331036

Epoch: 5| Step: 2
Training loss: 0.5030608663495705
Validation loss: 2.637087937870025

Epoch: 5| Step: 3
Training loss: 1.1660842236351188
Validation loss: 2.6008538759785766

Epoch: 5| Step: 4
Training loss: 0.6347282516041014
Validation loss: 2.719976126762415

Epoch: 5| Step: 5
Training loss: 1.6610100917796666
Validation loss: 2.6437133508461175

Epoch: 5| Step: 6
Training loss: 1.0606925400655844
Validation loss: 2.776330279197651

Epoch: 5| Step: 7
Training loss: 1.2162597352409643
Validation loss: 2.731010837980872

Epoch: 5| Step: 8
Training loss: 0.9449342648788693
Validation loss: 2.639470606120243

Epoch: 5| Step: 9
Training loss: 0.8171070504203343
Validation loss: 2.694423304034626

Epoch: 5| Step: 10
Training loss: 0.7595466749378534
Validation loss: 2.7094141979674617

Epoch: 5| Step: 11
Training loss: 0.5291615837583948
Validation loss: 2.6065060992088744

Epoch: 180| Step: 0
Training loss: 0.7534284906153246
Validation loss: 2.633977198479026

Epoch: 5| Step: 1
Training loss: 0.7745648269809209
Validation loss: 2.650305135421557

Epoch: 5| Step: 2
Training loss: 0.6650480922360436
Validation loss: 2.726959611307308

Epoch: 5| Step: 3
Training loss: 1.0164049528261743
Validation loss: 2.683884199139631

Epoch: 5| Step: 4
Training loss: 1.1667167561995402
Validation loss: 2.6892380675758933

Epoch: 5| Step: 5
Training loss: 0.8763426289051498
Validation loss: 2.673768879968091

Epoch: 5| Step: 6
Training loss: 0.7573592413373906
Validation loss: 2.7234106856612996

Epoch: 5| Step: 7
Training loss: 0.8484243261954914
Validation loss: 2.664106292215521

Epoch: 5| Step: 8
Training loss: 1.5648598207818838
Validation loss: 2.6998423046107676

Epoch: 5| Step: 9
Training loss: 0.9979143745273926
Validation loss: 2.6470929561624024

Epoch: 5| Step: 10
Training loss: 0.9249207565799643
Validation loss: 2.6393008815383157

Epoch: 5| Step: 11
Training loss: 0.5645691115592821
Validation loss: 2.626003255314781

Epoch: 181| Step: 0
Training loss: 1.2715404867280997
Validation loss: 2.611955364317881

Epoch: 5| Step: 1
Training loss: 0.8511347965254294
Validation loss: 2.5884524060727827

Epoch: 5| Step: 2
Training loss: 1.171961310704994
Validation loss: 2.624923988785814

Epoch: 5| Step: 3
Training loss: 0.8379840576435303
Validation loss: 2.6212322806804065

Epoch: 5| Step: 4
Training loss: 0.7373900509358926
Validation loss: 2.675379104281262

Epoch: 5| Step: 5
Training loss: 0.684871917326385
Validation loss: 2.6866815562778266

Epoch: 5| Step: 6
Training loss: 1.12644468371305
Validation loss: 2.704168922960215

Epoch: 5| Step: 7
Training loss: 1.7169780266743782
Validation loss: 2.759453055896749

Epoch: 5| Step: 8
Training loss: 0.8865983183828696
Validation loss: 2.6658062117869292

Epoch: 5| Step: 9
Training loss: 0.5771390136362469
Validation loss: 2.7238302559340277

Epoch: 5| Step: 10
Training loss: 0.7192684045557721
Validation loss: 2.663862838049799

Epoch: 5| Step: 11
Training loss: 0.6830063612335905
Validation loss: 2.6736164589755473

Epoch: 182| Step: 0
Training loss: 0.8330038770468657
Validation loss: 2.6424832549056325

Epoch: 5| Step: 1
Training loss: 0.7831024333506377
Validation loss: 2.729441648321335

Epoch: 5| Step: 2
Training loss: 0.7096958426317341
Validation loss: 2.688432701668512

Epoch: 5| Step: 3
Training loss: 0.5834298451375581
Validation loss: 2.628839515568321

Epoch: 5| Step: 4
Training loss: 0.5530669219566312
Validation loss: 2.677236294118249

Epoch: 5| Step: 5
Training loss: 1.1597478899269456
Validation loss: 2.663847906245807

Epoch: 5| Step: 6
Training loss: 0.6647526016241827
Validation loss: 2.7383544048671875

Epoch: 5| Step: 7
Training loss: 1.557306278972476
Validation loss: 2.6760250750827086

Epoch: 5| Step: 8
Training loss: 1.0821968254901473
Validation loss: 2.6590323667126055

Epoch: 5| Step: 9
Training loss: 1.0086061176986683
Validation loss: 2.6675224657015413

Epoch: 5| Step: 10
Training loss: 0.9888059708273803
Validation loss: 2.72094822948194

Epoch: 5| Step: 11
Training loss: 0.8856676905215367
Validation loss: 2.6590698309154104

Epoch: 183| Step: 0
Training loss: 0.9875867612364716
Validation loss: 2.728814955366536

Epoch: 5| Step: 1
Training loss: 1.1105111979504374
Validation loss: 2.6838826260475765

Epoch: 5| Step: 2
Training loss: 0.8023004031706549
Validation loss: 2.677636450589156

Epoch: 5| Step: 3
Training loss: 0.7099713897985102
Validation loss: 2.7336328135000856

Epoch: 5| Step: 4
Training loss: 1.5212104364671581
Validation loss: 2.727678611564502

Epoch: 5| Step: 5
Training loss: 0.8124067913290889
Validation loss: 2.7673672398544937

Epoch: 5| Step: 6
Training loss: 0.8752132564612944
Validation loss: 2.7186130438031064

Epoch: 5| Step: 7
Training loss: 0.8688244876900346
Validation loss: 2.731854175984843

Epoch: 5| Step: 8
Training loss: 0.7037174060449065
Validation loss: 2.7659306186700614

Epoch: 5| Step: 9
Training loss: 1.0453139095553488
Validation loss: 2.7051028914987634

Epoch: 5| Step: 10
Training loss: 1.0424741222179472
Validation loss: 2.60595997798344

Epoch: 5| Step: 11
Training loss: 0.5679834177675991
Validation loss: 2.584590753254276

Epoch: 184| Step: 0
Training loss: 1.6480192404105316
Validation loss: 2.6520491461237206

Epoch: 5| Step: 1
Training loss: 0.8729639205949243
Validation loss: 2.6431084039972452

Epoch: 5| Step: 2
Training loss: 0.9851279633565437
Validation loss: 2.6419054948286

Epoch: 5| Step: 3
Training loss: 1.0826181961266839
Validation loss: 2.6199337040421944

Epoch: 5| Step: 4
Training loss: 0.8572408011369271
Validation loss: 2.7491632113204227

Epoch: 5| Step: 5
Training loss: 0.9899034417391325
Validation loss: 2.696297271248106

Epoch: 5| Step: 6
Training loss: 0.7887608168596318
Validation loss: 2.6979879139117435

Epoch: 5| Step: 7
Training loss: 0.7600591724976316
Validation loss: 2.6553784380410175

Epoch: 5| Step: 8
Training loss: 0.808070580227804
Validation loss: 2.7211621863197704

Epoch: 5| Step: 9
Training loss: 0.7943391280699923
Validation loss: 2.7192869423505597

Epoch: 5| Step: 10
Training loss: 0.49851928446553
Validation loss: 2.783748365389466

Epoch: 5| Step: 11
Training loss: 0.3439647047391198
Validation loss: 2.752780144779519

Epoch: 185| Step: 0
Training loss: 0.7457363610831556
Validation loss: 2.7110036022910933

Epoch: 5| Step: 1
Training loss: 1.0099847729167717
Validation loss: 2.7113255123259026

Epoch: 5| Step: 2
Training loss: 1.5835443489939627
Validation loss: 2.6487704417538196

Epoch: 5| Step: 3
Training loss: 0.9946425394388901
Validation loss: 2.701460493054594

Epoch: 5| Step: 4
Training loss: 0.9594408180448317
Validation loss: 2.6832297391520763

Epoch: 5| Step: 5
Training loss: 0.8604929501490204
Validation loss: 2.6456614022950133

Epoch: 5| Step: 6
Training loss: 0.8223033905417736
Validation loss: 2.6397766879970406

Epoch: 5| Step: 7
Training loss: 0.8843854883333624
Validation loss: 2.682017793222536

Epoch: 5| Step: 8
Training loss: 0.9152708299502095
Validation loss: 2.7617854497427783

Epoch: 5| Step: 9
Training loss: 0.7868088368542597
Validation loss: 2.778116622099743

Epoch: 5| Step: 10
Training loss: 0.9842269120011927
Validation loss: 2.777382773023714

Epoch: 5| Step: 11
Training loss: 0.8117340585772215
Validation loss: 2.714452167327283

Epoch: 186| Step: 0
Training loss: 1.4536391958451684
Validation loss: 2.702442516688346

Epoch: 5| Step: 1
Training loss: 0.6476263695094757
Validation loss: 2.683687244546843

Epoch: 5| Step: 2
Training loss: 1.0127922460501773
Validation loss: 2.5893991759062693

Epoch: 5| Step: 3
Training loss: 1.0301539636555033
Validation loss: 2.6295698215494303

Epoch: 5| Step: 4
Training loss: 1.0978631744286447
Validation loss: 2.697981378277535

Epoch: 5| Step: 5
Training loss: 0.7533378632656836
Validation loss: 2.74053763073073

Epoch: 5| Step: 6
Training loss: 0.6646299518230699
Validation loss: 2.685046532462719

Epoch: 5| Step: 7
Training loss: 0.6173667647373813
Validation loss: 2.6987680370793488

Epoch: 5| Step: 8
Training loss: 1.2053577957958894
Validation loss: 2.73140611326067

Epoch: 5| Step: 9
Training loss: 1.0573266811241762
Validation loss: 2.802194814107014

Epoch: 5| Step: 10
Training loss: 0.7110961066424707
Validation loss: 2.831932641428253

Epoch: 5| Step: 11
Training loss: 0.6849525244473263
Validation loss: 2.6729756369345665

Epoch: 187| Step: 0
Training loss: 0.5526482343105892
Validation loss: 2.703387804431165

Epoch: 5| Step: 1
Training loss: 0.9545282758677986
Validation loss: 2.6522138074038573

Epoch: 5| Step: 2
Training loss: 0.8411655404033141
Validation loss: 2.6628413044303088

Epoch: 5| Step: 3
Training loss: 1.1214281175003313
Validation loss: 2.6608351533403476

Epoch: 5| Step: 4
Training loss: 0.7485038616409527
Validation loss: 2.741061396925865

Epoch: 5| Step: 5
Training loss: 1.5648077135512224
Validation loss: 2.733779544481713

Epoch: 5| Step: 6
Training loss: 0.7393699974090746
Validation loss: 2.6589250296709084

Epoch: 5| Step: 7
Training loss: 0.9532982403013762
Validation loss: 2.6996928238973528

Epoch: 5| Step: 8
Training loss: 0.7029605249253129
Validation loss: 2.7078810069580115

Epoch: 5| Step: 9
Training loss: 0.933847400891116
Validation loss: 2.6643365213787997

Epoch: 5| Step: 10
Training loss: 0.9879369927713488
Validation loss: 2.717958039001956

Epoch: 5| Step: 11
Training loss: 0.528032629975374
Validation loss: 2.687635558797763

Epoch: 188| Step: 0
Training loss: 0.6468751078066529
Validation loss: 2.7474217032469572

Epoch: 5| Step: 1
Training loss: 0.7675497423510641
Validation loss: 2.740756959540212

Epoch: 5| Step: 2
Training loss: 0.7233049934595623
Validation loss: 2.6933835484722577

Epoch: 5| Step: 3
Training loss: 0.9318581253253433
Validation loss: 2.65040175328534

Epoch: 5| Step: 4
Training loss: 0.5835444601914331
Validation loss: 2.6984776143249394

Epoch: 5| Step: 5
Training loss: 0.7518861022408583
Validation loss: 2.7268383611618696

Epoch: 5| Step: 6
Training loss: 0.7274813430727213
Validation loss: 2.679787262300517

Epoch: 5| Step: 7
Training loss: 1.6479364148808153
Validation loss: 2.649692766805427

Epoch: 5| Step: 8
Training loss: 1.1866207381175655
Validation loss: 2.6863762295086038

Epoch: 5| Step: 9
Training loss: 0.7684144954953411
Validation loss: 2.7042069153418278

Epoch: 5| Step: 10
Training loss: 0.5638252647045094
Validation loss: 2.6970568039055545

Epoch: 5| Step: 11
Training loss: 1.0920848705441513
Validation loss: 2.7146828473388176

Epoch: 189| Step: 0
Training loss: 1.0279227246210478
Validation loss: 2.717792422737411

Epoch: 5| Step: 1
Training loss: 0.8547308888135626
Validation loss: 2.7240414664503194

Epoch: 5| Step: 2
Training loss: 0.7576762991353186
Validation loss: 2.765150902408771

Epoch: 5| Step: 3
Training loss: 0.8060090777001916
Validation loss: 2.654698369357748

Epoch: 5| Step: 4
Training loss: 0.6597350769017551
Validation loss: 2.6408950359105474

Epoch: 5| Step: 5
Training loss: 0.8209068688180432
Validation loss: 2.798200580870444

Epoch: 5| Step: 6
Training loss: 1.0345388046516564
Validation loss: 2.7441357849006005

Epoch: 5| Step: 7
Training loss: 1.1720057096700278
Validation loss: 2.7833058906009396

Epoch: 5| Step: 8
Training loss: 0.8179979277237103
Validation loss: 2.7663921272889063

Epoch: 5| Step: 9
Training loss: 0.5720050205363842
Validation loss: 2.7318058660180347

Epoch: 5| Step: 10
Training loss: 0.7643466319748785
Validation loss: 2.6660853561951554

Epoch: 5| Step: 11
Training loss: 3.0861392957161664
Validation loss: 2.630831156850484

Epoch: 190| Step: 0
Training loss: 0.9047039590501225
Validation loss: 2.6609833972293018

Epoch: 5| Step: 1
Training loss: 0.6505977770398871
Validation loss: 2.7529640118932206

Epoch: 5| Step: 2
Training loss: 0.6505482800458109
Validation loss: 2.6885360302891277

Epoch: 5| Step: 3
Training loss: 1.042958348826004
Validation loss: 2.65654881984382

Epoch: 5| Step: 4
Training loss: 0.5455985294663421
Validation loss: 2.71044501852522

Epoch: 5| Step: 5
Training loss: 0.7803088431984948
Validation loss: 2.725868224147412

Epoch: 5| Step: 6
Training loss: 1.1772602702251989
Validation loss: 2.675258033999183

Epoch: 5| Step: 7
Training loss: 1.5054285840871027
Validation loss: 2.7657928559537646

Epoch: 5| Step: 8
Training loss: 0.7410029947655377
Validation loss: 2.8079912284811885

Epoch: 5| Step: 9
Training loss: 0.7440386124020364
Validation loss: 2.67324479443614

Epoch: 5| Step: 10
Training loss: 0.8378084938326326
Validation loss: 2.628293771423856

Epoch: 5| Step: 11
Training loss: 0.5566454970832561
Validation loss: 2.6718272823958236

Epoch: 191| Step: 0
Training loss: 0.7928667801562169
Validation loss: 2.6877059672777217

Epoch: 5| Step: 1
Training loss: 0.7849532287173572
Validation loss: 2.6869040759994176

Epoch: 5| Step: 2
Training loss: 1.4767614159996043
Validation loss: 2.655182249844763

Epoch: 5| Step: 3
Training loss: 1.0318745542510264
Validation loss: 2.5954721432710115

Epoch: 5| Step: 4
Training loss: 0.7132822293695785
Validation loss: 2.767469103812147

Epoch: 5| Step: 5
Training loss: 0.8826857281700653
Validation loss: 2.7255041915897715

Epoch: 5| Step: 6
Training loss: 0.7821309272891465
Validation loss: 2.705824138356305

Epoch: 5| Step: 7
Training loss: 0.9537516550672177
Validation loss: 2.7093696897778066

Epoch: 5| Step: 8
Training loss: 0.7084959675573845
Validation loss: 2.786762945810201

Epoch: 5| Step: 9
Training loss: 0.608030915426431
Validation loss: 2.8614633157189346

Epoch: 5| Step: 10
Training loss: 0.7498847157566999
Validation loss: 2.7546660509174203

Epoch: 5| Step: 11
Training loss: 0.9865682177518419
Validation loss: 2.7364643906167005

Epoch: 192| Step: 0
Training loss: 0.8044951125589804
Validation loss: 2.6706807551689256

Epoch: 5| Step: 1
Training loss: 0.733959729895958
Validation loss: 2.712552010349594

Epoch: 5| Step: 2
Training loss: 0.7128646218770015
Validation loss: 2.7119891923592485

Epoch: 5| Step: 3
Training loss: 1.0025276782431574
Validation loss: 2.70865694949161

Epoch: 5| Step: 4
Training loss: 0.8562921193476682
Validation loss: 2.6833111476770837

Epoch: 5| Step: 5
Training loss: 0.6816827274644043
Validation loss: 2.7061996797401373

Epoch: 5| Step: 6
Training loss: 0.7219560272188185
Validation loss: 2.7584373911642257

Epoch: 5| Step: 7
Training loss: 0.8653475857417164
Validation loss: 2.7547465996939797

Epoch: 5| Step: 8
Training loss: 1.6002208020920108
Validation loss: 2.6994821923192536

Epoch: 5| Step: 9
Training loss: 0.5034913417503573
Validation loss: 2.6832699050475415

Epoch: 5| Step: 10
Training loss: 0.9512266734668071
Validation loss: 2.8114668962014444

Epoch: 5| Step: 11
Training loss: 0.4845338991468552
Validation loss: 2.816379086684874

Epoch: 193| Step: 0
Training loss: 0.8179546803136076
Validation loss: 2.825749416451494

Epoch: 5| Step: 1
Training loss: 1.0576968739817827
Validation loss: 2.695005556034785

Epoch: 5| Step: 2
Training loss: 0.7608300135088465
Validation loss: 2.629751782718628

Epoch: 5| Step: 3
Training loss: 1.007323094495404
Validation loss: 2.6926086943519207

Epoch: 5| Step: 4
Training loss: 0.9460273435866905
Validation loss: 2.6392760847416104

Epoch: 5| Step: 5
Training loss: 1.0042065123148776
Validation loss: 2.6724954297461117

Epoch: 5| Step: 6
Training loss: 0.7011062038770144
Validation loss: 2.6704167630826574

Epoch: 5| Step: 7
Training loss: 1.4374606914950774
Validation loss: 2.673497047853597

Epoch: 5| Step: 8
Training loss: 0.9164607871657885
Validation loss: 2.6810922230950474

Epoch: 5| Step: 9
Training loss: 0.8271666685795238
Validation loss: 2.75207222183799

Epoch: 5| Step: 10
Training loss: 0.6330506147575241
Validation loss: 2.8057553057069367

Epoch: 5| Step: 11
Training loss: 0.5927951563669438
Validation loss: 2.7909321684624997

Epoch: 194| Step: 0
Training loss: 0.8007107215154005
Validation loss: 2.765238237367057

Epoch: 5| Step: 1
Training loss: 1.1082845889871709
Validation loss: 2.725696688581597

Epoch: 5| Step: 2
Training loss: 1.5749160320363393
Validation loss: 2.656551478611774

Epoch: 5| Step: 3
Training loss: 0.7689434071837703
Validation loss: 2.549325945532574

Epoch: 5| Step: 4
Training loss: 1.125873967944977
Validation loss: 2.6890978646635886

Epoch: 5| Step: 5
Training loss: 0.8722200510749872
Validation loss: 2.672789590024443

Epoch: 5| Step: 6
Training loss: 0.9479347304135645
Validation loss: 2.7013621673526305

Epoch: 5| Step: 7
Training loss: 0.8765393748777403
Validation loss: 2.686256653363423

Epoch: 5| Step: 8
Training loss: 0.6630162467907779
Validation loss: 2.7364390838801778

Epoch: 5| Step: 9
Training loss: 0.7640745462353411
Validation loss: 2.7630738059433004

Epoch: 5| Step: 10
Training loss: 0.6911057072259882
Validation loss: 2.7847977951959137

Epoch: 5| Step: 11
Training loss: 0.8177261269611634
Validation loss: 2.8518722609797247

Epoch: 195| Step: 0
Training loss: 1.4266481037506848
Validation loss: 2.724517058673739

Epoch: 5| Step: 1
Training loss: 0.9163762015305045
Validation loss: 2.639813405653068

Epoch: 5| Step: 2
Training loss: 0.7556683991545123
Validation loss: 2.687896004414434

Epoch: 5| Step: 3
Training loss: 0.6356596768652865
Validation loss: 2.6867936632945923

Epoch: 5| Step: 4
Training loss: 0.6865063118460402
Validation loss: 2.6734122711542976

Epoch: 5| Step: 5
Training loss: 0.7576809011812503
Validation loss: 2.691315710780726

Epoch: 5| Step: 6
Training loss: 0.9344196257890691
Validation loss: 2.6158164423344257

Epoch: 5| Step: 7
Training loss: 0.9856169601238304
Validation loss: 2.6468553721763435

Epoch: 5| Step: 8
Training loss: 0.8438743217147974
Validation loss: 2.654494883805585

Epoch: 5| Step: 9
Training loss: 0.6642744287141604
Validation loss: 2.634530598248752

Epoch: 5| Step: 10
Training loss: 0.9869869939783914
Validation loss: 2.617151279103928

Epoch: 5| Step: 11
Training loss: 0.4464808413014451
Validation loss: 2.5876738374705646

Epoch: 196| Step: 0
Training loss: 1.515048045035493
Validation loss: 2.6990550608486608

Epoch: 5| Step: 1
Training loss: 0.605622622718515
Validation loss: 2.7141067272880575

Epoch: 5| Step: 2
Training loss: 0.5768907362175134
Validation loss: 2.7542252682719286

Epoch: 5| Step: 3
Training loss: 0.8306401762139237
Validation loss: 2.6336765852274957

Epoch: 5| Step: 4
Training loss: 0.7876265651176969
Validation loss: 2.682099312610286

Epoch: 5| Step: 5
Training loss: 0.9766201154878933
Validation loss: 2.732056843077149

Epoch: 5| Step: 6
Training loss: 0.803543499809418
Validation loss: 2.665821281680926

Epoch: 5| Step: 7
Training loss: 0.7590242902515265
Validation loss: 2.678233672600121

Epoch: 5| Step: 8
Training loss: 0.5662666411828207
Validation loss: 2.73965332294791

Epoch: 5| Step: 9
Training loss: 0.5935277020771099
Validation loss: 2.695696378635967

Epoch: 5| Step: 10
Training loss: 0.7340892885272376
Validation loss: 2.6551827137787236

Epoch: 5| Step: 11
Training loss: 0.4482272941425538
Validation loss: 2.7051437939179515

Epoch: 197| Step: 0
Training loss: 0.5993799771051537
Validation loss: 2.7066671356856906

Epoch: 5| Step: 1
Training loss: 0.5971366768075185
Validation loss: 2.69518503818341

Epoch: 5| Step: 2
Training loss: 0.8986051320134695
Validation loss: 2.6637506572818648

Epoch: 5| Step: 3
Training loss: 0.7881122570535353
Validation loss: 2.651324481280619

Epoch: 5| Step: 4
Training loss: 0.8563489870645521
Validation loss: 2.7127867738983125

Epoch: 5| Step: 5
Training loss: 0.720076704840239
Validation loss: 2.6201030300960264

Epoch: 5| Step: 6
Training loss: 0.7362775304598439
Validation loss: 2.718065895595212

Epoch: 5| Step: 7
Training loss: 0.6754276475086306
Validation loss: 2.6415272286815883

Epoch: 5| Step: 8
Training loss: 0.6200370676742396
Validation loss: 2.6338619136765518

Epoch: 5| Step: 9
Training loss: 1.5867815449477343
Validation loss: 2.7220597345705424

Epoch: 5| Step: 10
Training loss: 0.7465381596949803
Validation loss: 2.6398283906150946

Epoch: 5| Step: 11
Training loss: 0.7884420845179677
Validation loss: 2.698458831885391

Epoch: 198| Step: 0
Training loss: 0.8439858424865965
Validation loss: 2.7620446292994605

Epoch: 5| Step: 1
Training loss: 0.45277201946116463
Validation loss: 2.8301851767017476

Epoch: 5| Step: 2
Training loss: 0.8188284756274182
Validation loss: 2.758389471141649

Epoch: 5| Step: 3
Training loss: 0.9833767991777475
Validation loss: 2.7295554329466176

Epoch: 5| Step: 4
Training loss: 0.5848002778350077
Validation loss: 2.6415462354129753

Epoch: 5| Step: 5
Training loss: 0.7351593536408733
Validation loss: 2.660965466385032

Epoch: 5| Step: 6
Training loss: 1.0091551479267076
Validation loss: 2.678805318187937

Epoch: 5| Step: 7
Training loss: 0.6853016906665101
Validation loss: 2.605271407722216

Epoch: 5| Step: 8
Training loss: 1.556407111636512
Validation loss: 2.608220250346425

Epoch: 5| Step: 9
Training loss: 0.7749225347012114
Validation loss: 2.65307549039898

Epoch: 5| Step: 10
Training loss: 0.5920556135442568
Validation loss: 2.670476218261061

Epoch: 5| Step: 11
Training loss: 1.011551301862965
Validation loss: 2.687045576430015

Epoch: 199| Step: 0
Training loss: 0.8279883433894392
Validation loss: 2.744458452781863

Epoch: 5| Step: 1
Training loss: 0.6532478007174821
Validation loss: 2.675522621445779

Epoch: 5| Step: 2
Training loss: 0.8288287645197805
Validation loss: 2.666817289558971

Epoch: 5| Step: 3
Training loss: 0.7543171370721947
Validation loss: 2.737745115550114

Epoch: 5| Step: 4
Training loss: 1.2069024569738078
Validation loss: 2.736463530242326

Epoch: 5| Step: 5
Training loss: 1.481430345332682
Validation loss: 2.6704107217002817

Epoch: 5| Step: 6
Training loss: 0.6410949890362757
Validation loss: 2.6848051861847653

Epoch: 5| Step: 7
Training loss: 0.8220288803452179
Validation loss: 2.7112084508924563

Epoch: 5| Step: 8
Training loss: 0.9699028907420514
Validation loss: 2.6611046391200253

Epoch: 5| Step: 9
Training loss: 0.5653093964431957
Validation loss: 2.7245119722336293

Epoch: 5| Step: 10
Training loss: 0.709645743105354
Validation loss: 2.74201303997598

Epoch: 5| Step: 11
Training loss: 1.5075778284431873
Validation loss: 2.7784143379449335

Epoch: 200| Step: 0
Training loss: 0.6493036850365699
Validation loss: 2.6847055936965964

Epoch: 5| Step: 1
Training loss: 0.7606101551973863
Validation loss: 2.697547984369645

Epoch: 5| Step: 2
Training loss: 0.502373545283641
Validation loss: 2.640212687067342

Epoch: 5| Step: 3
Training loss: 0.933537054535031
Validation loss: 2.6540074175415027

Epoch: 5| Step: 4
Training loss: 0.6984344644501879
Validation loss: 2.601476643074443

Epoch: 5| Step: 5
Training loss: 1.5565458146805262
Validation loss: 2.6655520826818604

Epoch: 5| Step: 6
Training loss: 0.7854024776185553
Validation loss: 2.59580667756561

Epoch: 5| Step: 7
Training loss: 0.9165929345619591
Validation loss: 2.655002925814916

Epoch: 5| Step: 8
Training loss: 0.6855210302105593
Validation loss: 2.6176241268504254

Epoch: 5| Step: 9
Training loss: 0.5675623440632533
Validation loss: 2.6191559861519966

Epoch: 5| Step: 10
Training loss: 0.6219711823579991
Validation loss: 2.7095254010815886

Epoch: 5| Step: 11
Training loss: 1.2267460776795551
Validation loss: 2.698357830774821

Epoch: 201| Step: 0
Training loss: 0.5125566858250956
Validation loss: 2.630513025645166

Epoch: 5| Step: 1
Training loss: 0.7471411577928021
Validation loss: 2.6893429942542237

Epoch: 5| Step: 2
Training loss: 0.5209407187066646
Validation loss: 2.612033479581627

Epoch: 5| Step: 3
Training loss: 0.6831182515473265
Validation loss: 2.7043507577003374

Epoch: 5| Step: 4
Training loss: 0.7018871643629204
Validation loss: 2.6271488424044698

Epoch: 5| Step: 5
Training loss: 0.8248932595993016
Validation loss: 2.649767212719783

Epoch: 5| Step: 6
Training loss: 0.7886321149895994
Validation loss: 2.6990096641045733

Epoch: 5| Step: 7
Training loss: 0.8831460035867658
Validation loss: 2.7249627853763005

Epoch: 5| Step: 8
Training loss: 0.6566168804062457
Validation loss: 2.631245804433732

Epoch: 5| Step: 9
Training loss: 0.7230351459988292
Validation loss: 2.6613567069123136

Epoch: 5| Step: 10
Training loss: 1.5278855555501416
Validation loss: 2.7029807506138828

Epoch: 5| Step: 11
Training loss: 0.4419874230640905
Validation loss: 2.761408859053404

Epoch: 202| Step: 0
Training loss: 1.4821940411578778
Validation loss: 2.7759874754883342

Epoch: 5| Step: 1
Training loss: 0.8909375495602886
Validation loss: 2.8706700641692002

Epoch: 5| Step: 2
Training loss: 0.7077209312374021
Validation loss: 2.823005436748468

Epoch: 5| Step: 3
Training loss: 0.7494548564800619
Validation loss: 2.730640724307406

Epoch: 5| Step: 4
Training loss: 0.845473436699678
Validation loss: 2.738529852494248

Epoch: 5| Step: 5
Training loss: 0.6841014829343802
Validation loss: 2.726602370035311

Epoch: 5| Step: 6
Training loss: 0.7401150327918805
Validation loss: 2.694326469180763

Epoch: 5| Step: 7
Training loss: 0.9815314563504577
Validation loss: 2.659682572923902

Epoch: 5| Step: 8
Training loss: 0.38407933563753005
Validation loss: 2.6382701614112216

Epoch: 5| Step: 9
Training loss: 0.529170820139807
Validation loss: 2.751876071909796

Epoch: 5| Step: 10
Training loss: 0.7836713651667425
Validation loss: 2.8126054178897286

Epoch: 5| Step: 11
Training loss: 0.8056682794633957
Validation loss: 2.7882371067590537

Epoch: 203| Step: 0
Training loss: 0.7745819871824762
Validation loss: 2.6388612307945105

Epoch: 5| Step: 1
Training loss: 0.7277606805786216
Validation loss: 2.6862932275507205

Epoch: 5| Step: 2
Training loss: 0.9193174478240962
Validation loss: 2.7275287588370825

Epoch: 5| Step: 3
Training loss: 0.668701171875
Validation loss: 2.731446021703547

Epoch: 5| Step: 4
Training loss: 0.7472671548655234
Validation loss: 2.6222589653434802

Epoch: 5| Step: 5
Training loss: 0.8528440788463819
Validation loss: 2.665412855184848

Epoch: 5| Step: 6
Training loss: 0.6015391902618509
Validation loss: 2.664982168061632

Epoch: 5| Step: 7
Training loss: 0.7219552428989824
Validation loss: 2.683948839470833

Epoch: 5| Step: 8
Training loss: 0.7057090535881405
Validation loss: 2.726995355446384

Epoch: 5| Step: 9
Training loss: 0.783982571617375
Validation loss: 2.754917440700508

Epoch: 5| Step: 10
Training loss: 1.402195574654509
Validation loss: 2.6809601203938547

Epoch: 5| Step: 11
Training loss: 0.4354003180700252
Validation loss: 2.6988866061582297

Epoch: 204| Step: 0
Training loss: 0.8386352715857539
Validation loss: 2.698028673819658

Epoch: 5| Step: 1
Training loss: 1.4375597070650503
Validation loss: 2.7353668412210053

Epoch: 5| Step: 2
Training loss: 0.8326914142807833
Validation loss: 2.6714934509780615

Epoch: 5| Step: 3
Training loss: 0.5290918833036311
Validation loss: 2.7148045671960706

Epoch: 5| Step: 4
Training loss: 0.7723559900263542
Validation loss: 2.7156887504958296

Epoch: 5| Step: 5
Training loss: 0.5616788964067334
Validation loss: 2.68980374032729

Epoch: 5| Step: 6
Training loss: 0.8386032168779963
Validation loss: 2.807499187256494

Epoch: 5| Step: 7
Training loss: 0.796123748902895
Validation loss: 2.732865427303318

Epoch: 5| Step: 8
Training loss: 0.592377079232554
Validation loss: 2.698935325011149

Epoch: 5| Step: 9
Training loss: 0.5306734996148874
Validation loss: 2.6915630152815626

Epoch: 5| Step: 10
Training loss: 0.6251037988299831
Validation loss: 2.6784331237569696

Epoch: 5| Step: 11
Training loss: 0.8347239018439392
Validation loss: 2.6980201868254543

Epoch: 205| Step: 0
Training loss: 0.5652510075735216
Validation loss: 2.6721787902763845

Epoch: 5| Step: 1
Training loss: 0.7818437227599597
Validation loss: 2.793034241093005

Epoch: 5| Step: 2
Training loss: 0.7063435534739524
Validation loss: 2.6873903880573113

Epoch: 5| Step: 3
Training loss: 1.4126611583899966
Validation loss: 2.7388397205989183

Epoch: 5| Step: 4
Training loss: 0.6731375652546612
Validation loss: 2.7842095555318274

Epoch: 5| Step: 5
Training loss: 0.908524027910277
Validation loss: 2.7837560664354792

Epoch: 5| Step: 6
Training loss: 0.9492535996809616
Validation loss: 2.698362771394578

Epoch: 5| Step: 7
Training loss: 0.5302881059672683
Validation loss: 2.6712023685905235

Epoch: 5| Step: 8
Training loss: 0.6517526381175471
Validation loss: 2.708158327219372

Epoch: 5| Step: 9
Training loss: 0.8461173719100883
Validation loss: 2.639120361705645

Epoch: 5| Step: 10
Training loss: 0.7111994082755212
Validation loss: 2.6378356715471334

Epoch: 5| Step: 11
Training loss: 0.9988024216359411
Validation loss: 2.587573103708998

Epoch: 206| Step: 0
Training loss: 1.6216429733683524
Validation loss: 2.6509150204388727

Epoch: 5| Step: 1
Training loss: 0.7474033386349851
Validation loss: 2.721494053556548

Epoch: 5| Step: 2
Training loss: 0.8456673911916927
Validation loss: 2.805518385879079

Epoch: 5| Step: 3
Training loss: 0.6397933446385365
Validation loss: 2.7439166610025283

Epoch: 5| Step: 4
Training loss: 0.8478822538686156
Validation loss: 2.6705734957219014

Epoch: 5| Step: 5
Training loss: 0.7725815323206651
Validation loss: 2.816699770633202

Epoch: 5| Step: 6
Training loss: 0.6767492252482111
Validation loss: 2.786342608939501

Epoch: 5| Step: 7
Training loss: 0.5401484290746607
Validation loss: 2.6151278651919405

Epoch: 5| Step: 8
Training loss: 0.7991323101772064
Validation loss: 2.6719328333077836

Epoch: 5| Step: 9
Training loss: 0.8441021149203782
Validation loss: 2.7062500436091255

Epoch: 5| Step: 10
Training loss: 0.5388355053626729
Validation loss: 2.615158300264314

Epoch: 5| Step: 11
Training loss: 0.5535892574893538
Validation loss: 2.7458588294831503

Epoch: 207| Step: 0
Training loss: 0.6138282329010113
Validation loss: 2.7283663061449146

Epoch: 5| Step: 1
Training loss: 1.4459365734578022
Validation loss: 2.820949271217568

Epoch: 5| Step: 2
Training loss: 0.7813694671840182
Validation loss: 2.83789451758128

Epoch: 5| Step: 3
Training loss: 0.585647867462645
Validation loss: 2.7291032089737675

Epoch: 5| Step: 4
Training loss: 0.6084248887583579
Validation loss: 2.750623552835863

Epoch: 5| Step: 5
Training loss: 0.9037893696146512
Validation loss: 2.7166945444814155

Epoch: 5| Step: 6
Training loss: 0.8059642255714586
Validation loss: 2.7693309846039154

Epoch: 5| Step: 7
Training loss: 0.6082881135550877
Validation loss: 2.7311973018203375

Epoch: 5| Step: 8
Training loss: 0.5180656296475241
Validation loss: 2.6975911409232207

Epoch: 5| Step: 9
Training loss: 0.7103872160712827
Validation loss: 2.723520430941652

Epoch: 5| Step: 10
Training loss: 0.7147600302110867
Validation loss: 2.7150468855498326

Epoch: 5| Step: 11
Training loss: 0.7269253798760004
Validation loss: 2.691726215243176

Epoch: 208| Step: 0
Training loss: 0.6235364467335657
Validation loss: 2.6598451071113156

Epoch: 5| Step: 1
Training loss: 0.7051701578112293
Validation loss: 2.6855762087058004

Epoch: 5| Step: 2
Training loss: 0.6679056818227949
Validation loss: 2.6751128612607897

Epoch: 5| Step: 3
Training loss: 0.9098301577580477
Validation loss: 2.743673329596396

Epoch: 5| Step: 4
Training loss: 0.4548982256468363
Validation loss: 2.7078924566058222

Epoch: 5| Step: 5
Training loss: 0.8002940486879725
Validation loss: 2.7502175194515335

Epoch: 5| Step: 6
Training loss: 0.9131501690309058
Validation loss: 2.6982182269160613

Epoch: 5| Step: 7
Training loss: 1.4403449392441894
Validation loss: 2.640271665420115

Epoch: 5| Step: 8
Training loss: 0.5492887362822758
Validation loss: 2.6710935940946534

Epoch: 5| Step: 9
Training loss: 0.605101172326572
Validation loss: 2.792821347630716

Epoch: 5| Step: 10
Training loss: 0.5737315595900534
Validation loss: 2.7230078362104537

Epoch: 5| Step: 11
Training loss: 0.7758427606112998
Validation loss: 2.7461881408820306

Epoch: 209| Step: 0
Training loss: 0.47831640962353456
Validation loss: 2.7321732657681803

Epoch: 5| Step: 1
Training loss: 0.7657144455335121
Validation loss: 2.77816988733886

Epoch: 5| Step: 2
Training loss: 0.5712792811412238
Validation loss: 2.759444693019709

Epoch: 5| Step: 3
Training loss: 0.6042359383651057
Validation loss: 2.688013024119536

Epoch: 5| Step: 4
Training loss: 0.7427032686322103
Validation loss: 2.732185213548417

Epoch: 5| Step: 5
Training loss: 0.6978946274271416
Validation loss: 2.7394046193322525

Epoch: 5| Step: 6
Training loss: 0.865154426273782
Validation loss: 2.693180951540356

Epoch: 5| Step: 7
Training loss: 0.4381651590310954
Validation loss: 2.714792883234076

Epoch: 5| Step: 8
Training loss: 1.4480187725409859
Validation loss: 2.6345672231090433

Epoch: 5| Step: 9
Training loss: 0.8739250596585152
Validation loss: 2.6681979347638483

Epoch: 5| Step: 10
Training loss: 0.5080282486585653
Validation loss: 2.827276661127761

Epoch: 5| Step: 11
Training loss: 0.28714217433292455
Validation loss: 2.6568116211404122

Epoch: 210| Step: 0
Training loss: 0.8135963525761604
Validation loss: 2.7435900695869946

Epoch: 5| Step: 1
Training loss: 0.5667391883734249
Validation loss: 2.6951203356070974

Epoch: 5| Step: 2
Training loss: 0.8384894518657928
Validation loss: 2.7230158732076863

Epoch: 5| Step: 3
Training loss: 0.7468167940706374
Validation loss: 2.7450415420920917

Epoch: 5| Step: 4
Training loss: 0.5048388936108205
Validation loss: 2.6832842734000373

Epoch: 5| Step: 5
Training loss: 0.5897439025848308
Validation loss: 2.6180726865033135

Epoch: 5| Step: 6
Training loss: 0.6814773276525617
Validation loss: 2.7209694634557935

Epoch: 5| Step: 7
Training loss: 1.4996917725820342
Validation loss: 2.7448388999817506

Epoch: 5| Step: 8
Training loss: 0.5006740318413552
Validation loss: 2.687735506576857

Epoch: 5| Step: 9
Training loss: 0.4573951967507594
Validation loss: 2.716038780748288

Epoch: 5| Step: 10
Training loss: 0.7441590474569179
Validation loss: 2.7559867521245818

Epoch: 5| Step: 11
Training loss: 0.6553549339224539
Validation loss: 2.753520262161357

Epoch: 211| Step: 0
Training loss: 0.8290461329610661
Validation loss: 2.692103350551688

Epoch: 5| Step: 1
Training loss: 0.6119088044535754
Validation loss: 2.811936505700577

Epoch: 5| Step: 2
Training loss: 0.6014333313820581
Validation loss: 2.738933338660471

Epoch: 5| Step: 3
Training loss: 0.5858456857589979
Validation loss: 2.7358027699700207

Epoch: 5| Step: 4
Training loss: 0.8776199761993836
Validation loss: 2.6899411181915234

Epoch: 5| Step: 5
Training loss: 0.6863797120109885
Validation loss: 2.6755912471983745

Epoch: 5| Step: 6
Training loss: 0.6527549224486747
Validation loss: 2.606193247298403

Epoch: 5| Step: 7
Training loss: 0.8335891251583206
Validation loss: 2.6587575707494464

Epoch: 5| Step: 8
Training loss: 0.45677642565109056
Validation loss: 2.6725374594044538

Epoch: 5| Step: 9
Training loss: 1.5331311251505912
Validation loss: 2.6279256880422737

Epoch: 5| Step: 10
Training loss: 0.6156679835538648
Validation loss: 2.7317211824213654

Epoch: 5| Step: 11
Training loss: 0.7716741787137671
Validation loss: 2.7410763248940095

Epoch: 212| Step: 0
Training loss: 0.4584749844600226
Validation loss: 2.7096009454668555

Epoch: 5| Step: 1
Training loss: 0.47316388384880925
Validation loss: 2.7509925308278675

Epoch: 5| Step: 2
Training loss: 1.404945022349047
Validation loss: 2.7059801234353844

Epoch: 5| Step: 3
Training loss: 0.7743232356297233
Validation loss: 2.6929340575377374

Epoch: 5| Step: 4
Training loss: 0.7957063220731903
Validation loss: 2.713466216128732

Epoch: 5| Step: 5
Training loss: 0.7907131794242293
Validation loss: 2.694692409522263

Epoch: 5| Step: 6
Training loss: 0.5961364920754867
Validation loss: 2.6517131507111165

Epoch: 5| Step: 7
Training loss: 0.5877677307440032
Validation loss: 2.731344534622255

Epoch: 5| Step: 8
Training loss: 0.8277905346558072
Validation loss: 2.662608047018291

Epoch: 5| Step: 9
Training loss: 0.7518533219330226
Validation loss: 2.750263454359845

Epoch: 5| Step: 10
Training loss: 0.7111078414576915
Validation loss: 2.7421531964916044

Epoch: 5| Step: 11
Training loss: 0.498130581871166
Validation loss: 2.71247869430472

Epoch: 213| Step: 0
Training loss: 1.3316297625241043
Validation loss: 2.7250325009977194

Epoch: 5| Step: 1
Training loss: 0.8284311628297151
Validation loss: 2.7536977846860697

Epoch: 5| Step: 2
Training loss: 0.941153654661684
Validation loss: 2.7681999755258087

Epoch: 5| Step: 3
Training loss: 0.6169361858305616
Validation loss: 2.792999039776932

Epoch: 5| Step: 4
Training loss: 0.6250540471550063
Validation loss: 2.7432701350167608

Epoch: 5| Step: 5
Training loss: 0.5815639027655982
Validation loss: 2.7132111468285283

Epoch: 5| Step: 6
Training loss: 0.45707281852852155
Validation loss: 2.6465227525469217

Epoch: 5| Step: 7
Training loss: 0.7146906037256978
Validation loss: 2.6859752521447064

Epoch: 5| Step: 8
Training loss: 0.6939316657775453
Validation loss: 2.740493530141683

Epoch: 5| Step: 9
Training loss: 0.7164849374336528
Validation loss: 2.7320637371664986

Epoch: 5| Step: 10
Training loss: 0.8337584285510226
Validation loss: 2.753660814246812

Epoch: 5| Step: 11
Training loss: 0.711712006621757
Validation loss: 2.781286371543316

Epoch: 214| Step: 0
Training loss: 0.5979886595374738
Validation loss: 2.763733078421566

Epoch: 5| Step: 1
Training loss: 1.491130754254901
Validation loss: 2.72707231741347

Epoch: 5| Step: 2
Training loss: 0.6163885280831941
Validation loss: 2.7730824596978625

Epoch: 5| Step: 3
Training loss: 0.6730022732241415
Validation loss: 2.849121156511085

Epoch: 5| Step: 4
Training loss: 0.6383730221238354
Validation loss: 2.7785382749028575

Epoch: 5| Step: 5
Training loss: 0.6280606431397412
Validation loss: 2.8224405659065432

Epoch: 5| Step: 6
Training loss: 0.4216489892892973
Validation loss: 2.7482603090099205

Epoch: 5| Step: 7
Training loss: 0.7903667284429978
Validation loss: 2.7455328906255567

Epoch: 5| Step: 8
Training loss: 0.6717448662993647
Validation loss: 2.663662840397171

Epoch: 5| Step: 9
Training loss: 0.8923114403252597
Validation loss: 2.658586704701802

Epoch: 5| Step: 10
Training loss: 0.7176832908022585
Validation loss: 2.7014902496825606

Epoch: 5| Step: 11
Training loss: 0.26676085188420756
Validation loss: 2.6880167900419187

Epoch: 215| Step: 0
Training loss: 0.9571242306753401
Validation loss: 2.8232603579446334

Epoch: 5| Step: 1
Training loss: 0.6511880379486132
Validation loss: 2.724124430496954

Epoch: 5| Step: 2
Training loss: 0.6321469562934872
Validation loss: 2.705179517844906

Epoch: 5| Step: 3
Training loss: 0.5687798848527444
Validation loss: 2.6560379916086956

Epoch: 5| Step: 4
Training loss: 1.4400692246275386
Validation loss: 2.6578702622464268

Epoch: 5| Step: 5
Training loss: 0.534900464932733
Validation loss: 2.702169466275767

Epoch: 5| Step: 6
Training loss: 0.40199134726487973
Validation loss: 2.649403443756365

Epoch: 5| Step: 7
Training loss: 0.8063433009137781
Validation loss: 2.7447982488815073

Epoch: 5| Step: 8
Training loss: 0.7402770098081243
Validation loss: 2.741557201897962

Epoch: 5| Step: 9
Training loss: 0.5633022891703919
Validation loss: 2.642047062771116

Epoch: 5| Step: 10
Training loss: 0.5926925377732731
Validation loss: 2.6580646636726137

Epoch: 5| Step: 11
Training loss: 0.30599131752767245
Validation loss: 2.691351802812241

Epoch: 216| Step: 0
Training loss: 0.8481956207401602
Validation loss: 2.6422530766370342

Epoch: 5| Step: 1
Training loss: 0.4567109314089087
Validation loss: 2.6484700578847025

Epoch: 5| Step: 2
Training loss: 1.4031362180537514
Validation loss: 2.6712399968108884

Epoch: 5| Step: 3
Training loss: 0.6508743732406151
Validation loss: 2.611588827665925

Epoch: 5| Step: 4
Training loss: 0.597538855498336
Validation loss: 2.7531074465633356

Epoch: 5| Step: 5
Training loss: 0.8028155283501432
Validation loss: 2.7584248548250767

Epoch: 5| Step: 6
Training loss: 0.8599220961948824
Validation loss: 2.781351505527476

Epoch: 5| Step: 7
Training loss: 0.5923448801394634
Validation loss: 2.7747654883065884

Epoch: 5| Step: 8
Training loss: 0.5917335703010967
Validation loss: 2.7563829868553786

Epoch: 5| Step: 9
Training loss: 0.5761547280039213
Validation loss: 2.6563558594796124

Epoch: 5| Step: 10
Training loss: 0.6595796629039873
Validation loss: 2.6452226096643767

Epoch: 5| Step: 11
Training loss: 0.4469670794395172
Validation loss: 2.805404776801005

Epoch: 217| Step: 0
Training loss: 0.9165004593993189
Validation loss: 2.721051659570199

Epoch: 5| Step: 1
Training loss: 0.6992689146662128
Validation loss: 2.721853151463655

Epoch: 5| Step: 2
Training loss: 0.44050029180259437
Validation loss: 2.797012844276237

Epoch: 5| Step: 3
Training loss: 0.7723098009023281
Validation loss: 2.7707904128763516

Epoch: 5| Step: 4
Training loss: 0.48696164152328864
Validation loss: 2.797441297346462

Epoch: 5| Step: 5
Training loss: 1.4643663772934805
Validation loss: 2.799316576590567

Epoch: 5| Step: 6
Training loss: 0.5918354991231164
Validation loss: 2.806808215371527

Epoch: 5| Step: 7
Training loss: 0.5395369998328325
Validation loss: 2.7502267574252524

Epoch: 5| Step: 8
Training loss: 0.6639978040707712
Validation loss: 2.743896201980811

Epoch: 5| Step: 9
Training loss: 0.7345100846737622
Validation loss: 2.7565043141053187

Epoch: 5| Step: 10
Training loss: 0.7099575792991416
Validation loss: 2.7585473923059194

Epoch: 5| Step: 11
Training loss: 0.298752793933461
Validation loss: 2.725891165441041

Epoch: 218| Step: 0
Training loss: 0.5686878421898548
Validation loss: 2.808778044941599

Epoch: 5| Step: 1
Training loss: 0.9116575768091414
Validation loss: 2.864257736197383

Epoch: 5| Step: 2
Training loss: 0.6156613760333435
Validation loss: 2.6819664705540744

Epoch: 5| Step: 3
Training loss: 0.5684374463971046
Validation loss: 2.7318973069540977

Epoch: 5| Step: 4
Training loss: 0.924296254433572
Validation loss: 2.697180140542754

Epoch: 5| Step: 5
Training loss: 1.5020423336844324
Validation loss: 2.728045154260992

Epoch: 5| Step: 6
Training loss: 0.48842426494451896
Validation loss: 2.782208770341578

Epoch: 5| Step: 7
Training loss: 0.723443216255954
Validation loss: 2.7537862837252844

Epoch: 5| Step: 8
Training loss: 0.5886500070379269
Validation loss: 2.740381644277811

Epoch: 5| Step: 9
Training loss: 0.5551572341974641
Validation loss: 2.6510676749302036

Epoch: 5| Step: 10
Training loss: 0.6575713479018118
Validation loss: 2.645175733220937

Epoch: 5| Step: 11
Training loss: 0.13293103930615224
Validation loss: 2.679583173969422

Epoch: 219| Step: 0
Training loss: 0.49444459152874326
Validation loss: 2.764811538058801

Epoch: 5| Step: 1
Training loss: 0.6507285903928927
Validation loss: 2.76719116865504

Epoch: 5| Step: 2
Training loss: 0.797614409034
Validation loss: 2.6551744826802834

Epoch: 5| Step: 3
Training loss: 0.40440173793286277
Validation loss: 2.6961404569948786

Epoch: 5| Step: 4
Training loss: 0.521029127194552
Validation loss: 2.6480920560712957

Epoch: 5| Step: 5
Training loss: 0.7363743856049
Validation loss: 2.658710525672807

Epoch: 5| Step: 6
Training loss: 0.6981731460689826
Validation loss: 2.6969998298006588

Epoch: 5| Step: 7
Training loss: 0.6630225846556382
Validation loss: 2.7280501612841364

Epoch: 5| Step: 8
Training loss: 0.5824341627496725
Validation loss: 2.776854570805759

Epoch: 5| Step: 9
Training loss: 1.4887569598364354
Validation loss: 2.715550747299993

Epoch: 5| Step: 10
Training loss: 0.7860547139486683
Validation loss: 2.7845336517791126

Epoch: 5| Step: 11
Training loss: 0.4702567837432194
Validation loss: 2.794473696997542

Epoch: 220| Step: 0
Training loss: 0.5674421374613309
Validation loss: 2.819359446613536

Epoch: 5| Step: 1
Training loss: 0.6102008114610876
Validation loss: 2.702950414998987

Epoch: 5| Step: 2
Training loss: 0.662062494199269
Validation loss: 2.7244882244488733

Epoch: 5| Step: 3
Training loss: 0.5483878327836159
Validation loss: 2.7045473424957365

Epoch: 5| Step: 4
Training loss: 0.7041067475063184
Validation loss: 2.7536614527919836

Epoch: 5| Step: 5
Training loss: 0.5557193560987123
Validation loss: 2.763619401521226

Epoch: 5| Step: 6
Training loss: 0.6300594584850714
Validation loss: 2.6852792243519112

Epoch: 5| Step: 7
Training loss: 0.6404198341274753
Validation loss: 2.7986579944468812

Epoch: 5| Step: 8
Training loss: 0.7134903566795469
Validation loss: 2.7643743406314107

Epoch: 5| Step: 9
Training loss: 1.419857228314737
Validation loss: 2.7770583501971706

Epoch: 5| Step: 10
Training loss: 0.8123599078374085
Validation loss: 2.6659985701279787

Epoch: 5| Step: 11
Training loss: 0.45808821503157704
Validation loss: 2.715909010650268

Epoch: 221| Step: 0
Training loss: 0.5543308185832699
Validation loss: 2.762743431113646

Epoch: 5| Step: 1
Training loss: 0.5159843233188952
Validation loss: 2.760781517148979

Epoch: 5| Step: 2
Training loss: 0.6925158890646883
Validation loss: 2.726411769748475

Epoch: 5| Step: 3
Training loss: 0.4652686220979482
Validation loss: 2.766558882804565

Epoch: 5| Step: 4
Training loss: 0.6548833240082674
Validation loss: 2.6700167933244296

Epoch: 5| Step: 5
Training loss: 0.5833728101406025
Validation loss: 2.74751500357875

Epoch: 5| Step: 6
Training loss: 0.7490162357943999
Validation loss: 2.785900888507304

Epoch: 5| Step: 7
Training loss: 0.7146662924371755
Validation loss: 2.7139992477609916

Epoch: 5| Step: 8
Training loss: 0.6091403264779718
Validation loss: 2.6529084748188136

Epoch: 5| Step: 9
Training loss: 0.5376744297793109
Validation loss: 2.7725317572989807

Epoch: 5| Step: 10
Training loss: 1.4959660966162776
Validation loss: 2.7262027033079304

Epoch: 5| Step: 11
Training loss: 0.41450629652760473
Validation loss: 2.700176464748538

Epoch: 222| Step: 0
Training loss: 1.3340693121437044
Validation loss: 2.6321464133683805

Epoch: 5| Step: 1
Training loss: 0.6766646680269963
Validation loss: 2.7061696224889182

Epoch: 5| Step: 2
Training loss: 0.47744960766164063
Validation loss: 2.703199146701798

Epoch: 5| Step: 3
Training loss: 0.567253268713715
Validation loss: 2.6651789916324886

Epoch: 5| Step: 4
Training loss: 0.5967593225758538
Validation loss: 2.7071332118734492

Epoch: 5| Step: 5
Training loss: 0.6582273937245131
Validation loss: 2.760489877893561

Epoch: 5| Step: 6
Training loss: 0.8552418586457197
Validation loss: 2.691437014702455

Epoch: 5| Step: 7
Training loss: 0.7008000187396456
Validation loss: 2.720101645337545

Epoch: 5| Step: 8
Training loss: 0.5454604519267783
Validation loss: 2.759720258616612

Epoch: 5| Step: 9
Training loss: 0.6937056200764617
Validation loss: 2.7771805448370968

Epoch: 5| Step: 10
Training loss: 0.6389873087328608
Validation loss: 2.6881851904891096

Epoch: 5| Step: 11
Training loss: 0.379855059318447
Validation loss: 2.7379173911378216

Epoch: 223| Step: 0
Training loss: 0.6009398371372808
Validation loss: 2.670109137419089

Epoch: 5| Step: 1
Training loss: 0.5062865291179185
Validation loss: 2.6033034508862856

Epoch: 5| Step: 2
Training loss: 0.8134093331242601
Validation loss: 2.757739090415243

Epoch: 5| Step: 3
Training loss: 0.5429090288649167
Validation loss: 2.707534585445966

Epoch: 5| Step: 4
Training loss: 0.4713805140372832
Validation loss: 2.753693462835595

Epoch: 5| Step: 5
Training loss: 0.5495922972541237
Validation loss: 2.7648593036594624

Epoch: 5| Step: 6
Training loss: 0.4395781614653206
Validation loss: 2.750635666061255

Epoch: 5| Step: 7
Training loss: 0.50610177849022
Validation loss: 2.685264030589414

Epoch: 5| Step: 8
Training loss: 0.518777170963404
Validation loss: 2.6766058140932008

Epoch: 5| Step: 9
Training loss: 0.6320717090157243
Validation loss: 2.7071074034239366

Epoch: 5| Step: 10
Training loss: 1.5616208464184735
Validation loss: 2.7237439238346433

Epoch: 5| Step: 11
Training loss: 0.7732439665979864
Validation loss: 2.7184752365646325

Epoch: 224| Step: 0
Training loss: 0.4874646491902824
Validation loss: 2.7182055180233493

Epoch: 5| Step: 1
Training loss: 1.4386699725181726
Validation loss: 2.673442700409044

Epoch: 5| Step: 2
Training loss: 0.5511961652457631
Validation loss: 2.6917096554322093

Epoch: 5| Step: 3
Training loss: 0.5454666531909601
Validation loss: 2.745346579053404

Epoch: 5| Step: 4
Training loss: 0.3887472031790164
Validation loss: 2.7748880953749904

Epoch: 5| Step: 5
Training loss: 0.7923355205020506
Validation loss: 2.6975506616501175

Epoch: 5| Step: 6
Training loss: 0.9456669481835289
Validation loss: 2.697954760593041

Epoch: 5| Step: 7
Training loss: 0.6593124142996689
Validation loss: 2.6233629124822615

Epoch: 5| Step: 8
Training loss: 0.6259582326410268
Validation loss: 2.6700303363326787

Epoch: 5| Step: 9
Training loss: 0.38077583374879886
Validation loss: 2.681128152629201

Epoch: 5| Step: 10
Training loss: 0.8814454085225096
Validation loss: 2.71219225967493

Epoch: 5| Step: 11
Training loss: 0.6167220763065314
Validation loss: 2.681190947569274

Epoch: 225| Step: 0
Training loss: 0.694575444157433
Validation loss: 2.634287322045803

Epoch: 5| Step: 1
Training loss: 0.583406066333812
Validation loss: 2.72337927902884

Epoch: 5| Step: 2
Training loss: 0.46763761774500956
Validation loss: 2.726490897884411

Epoch: 5| Step: 3
Training loss: 1.4199186847131458
Validation loss: 2.770900464977558

Epoch: 5| Step: 4
Training loss: 0.5450116428828969
Validation loss: 2.7568013676309033

Epoch: 5| Step: 5
Training loss: 0.6633413999712381
Validation loss: 2.745539074259558

Epoch: 5| Step: 6
Training loss: 0.8860006239266707
Validation loss: 2.71920162045382

Epoch: 5| Step: 7
Training loss: 0.5121279529079512
Validation loss: 2.65923226433297

Epoch: 5| Step: 8
Training loss: 0.5336099267520941
Validation loss: 2.7385794222843196

Epoch: 5| Step: 9
Training loss: 0.7393657650858563
Validation loss: 2.705085198017885

Epoch: 5| Step: 10
Training loss: 0.8728057733229437
Validation loss: 2.6877423147626796

Epoch: 5| Step: 11
Training loss: 0.5592025160584855
Validation loss: 2.7265698342648212

Epoch: 226| Step: 0
Training loss: 0.8005393802742073
Validation loss: 2.7376964886141586

Epoch: 5| Step: 1
Training loss: 0.7438369091129478
Validation loss: 2.6699426701816527

Epoch: 5| Step: 2
Training loss: 0.5794546456514391
Validation loss: 2.7696373994945724

Epoch: 5| Step: 3
Training loss: 0.6596565160879565
Validation loss: 2.7646514522455656

Epoch: 5| Step: 4
Training loss: 0.4567603261936044
Validation loss: 2.8178198023175427

Epoch: 5| Step: 5
Training loss: 1.3443121067092478
Validation loss: 2.7479245163808077

Epoch: 5| Step: 6
Training loss: 0.793054848492677
Validation loss: 2.6808925436329303

Epoch: 5| Step: 7
Training loss: 0.5198169009008736
Validation loss: 2.6694234528368423

Epoch: 5| Step: 8
Training loss: 0.5506460957377578
Validation loss: 2.713693557168685

Epoch: 5| Step: 9
Training loss: 0.5645204919655256
Validation loss: 2.7811514733396856

Epoch: 5| Step: 10
Training loss: 0.3871464724043878
Validation loss: 2.70613673459866

Epoch: 5| Step: 11
Training loss: 0.7824476217832079
Validation loss: 2.5925424821365493

Epoch: 227| Step: 0
Training loss: 0.45320299726910857
Validation loss: 2.7161191766490873

Epoch: 5| Step: 1
Training loss: 0.6434237588653706
Validation loss: 2.7223121246805424

Epoch: 5| Step: 2
Training loss: 0.5422374273612789
Validation loss: 2.700723794332055

Epoch: 5| Step: 3
Training loss: 1.4278116896709063
Validation loss: 2.7696838085803175

Epoch: 5| Step: 4
Training loss: 0.5140838131645998
Validation loss: 2.7217047628254307

Epoch: 5| Step: 5
Training loss: 0.6299967581423349
Validation loss: 2.692487041054948

Epoch: 5| Step: 6
Training loss: 0.6939583568597807
Validation loss: 2.6588530856487433

Epoch: 5| Step: 7
Training loss: 0.5439719941805169
Validation loss: 2.836404320623687

Epoch: 5| Step: 8
Training loss: 0.47773513981031956
Validation loss: 2.7302509470212817

Epoch: 5| Step: 9
Training loss: 0.7457212946473142
Validation loss: 2.6801502580771612

Epoch: 5| Step: 10
Training loss: 0.4938853211209067
Validation loss: 2.7962423955319142

Epoch: 5| Step: 11
Training loss: 0.23247516245612218
Validation loss: 2.7291390815583223

Epoch: 228| Step: 0
Training loss: 0.7504569092387694
Validation loss: 2.7800477747734273

Epoch: 5| Step: 1
Training loss: 0.5074199626554732
Validation loss: 2.7588075566304884

Epoch: 5| Step: 2
Training loss: 1.2925177764407987
Validation loss: 2.756798785728771

Epoch: 5| Step: 3
Training loss: 0.6572466502867869
Validation loss: 2.7847919127722287

Epoch: 5| Step: 4
Training loss: 0.43893222029904266
Validation loss: 2.787322733250446

Epoch: 5| Step: 5
Training loss: 0.5255918720070508
Validation loss: 2.8048158632194484

Epoch: 5| Step: 6
Training loss: 0.525658578151688
Validation loss: 2.8214116301496444

Epoch: 5| Step: 7
Training loss: 0.3518498200305383
Validation loss: 2.7281023102494424

Epoch: 5| Step: 8
Training loss: 0.40951353306235827
Validation loss: 2.7789058736422496

Epoch: 5| Step: 9
Training loss: 0.6978297155693572
Validation loss: 2.6319145573071285

Epoch: 5| Step: 10
Training loss: 0.785487660168437
Validation loss: 2.81581321818255

Epoch: 5| Step: 11
Training loss: 0.3662429388687061
Validation loss: 2.6933008214806704

Epoch: 229| Step: 0
Training loss: 0.6091179427801362
Validation loss: 2.6769734828888687

Epoch: 5| Step: 1
Training loss: 0.7983251354484168
Validation loss: 2.6832184434269197

Epoch: 5| Step: 2
Training loss: 0.7261079576422698
Validation loss: 2.732145930388521

Epoch: 5| Step: 3
Training loss: 1.305627997848261
Validation loss: 2.7553358366992793

Epoch: 5| Step: 4
Training loss: 0.6364839741171917
Validation loss: 2.810165291005335

Epoch: 5| Step: 5
Training loss: 0.4396940461019173
Validation loss: 2.7948125590821817

Epoch: 5| Step: 6
Training loss: 0.6691616181990356
Validation loss: 2.7645648605450095

Epoch: 5| Step: 7
Training loss: 0.5501141668083862
Validation loss: 2.698203010288471

Epoch: 5| Step: 8
Training loss: 0.7541180644172462
Validation loss: 2.7303182317589116

Epoch: 5| Step: 9
Training loss: 0.716998412360611
Validation loss: 2.718162400043989

Epoch: 5| Step: 10
Training loss: 0.5485422604918994
Validation loss: 2.6925368792453037

Epoch: 5| Step: 11
Training loss: 0.1777666293210829
Validation loss: 2.706636320207883

Epoch: 230| Step: 0
Training loss: 0.5616815758979878
Validation loss: 2.70775609589604

Epoch: 5| Step: 1
Training loss: 0.610142005041007
Validation loss: 2.7640173238969523

Epoch: 5| Step: 2
Training loss: 0.6200377886546442
Validation loss: 2.6911913781839893

Epoch: 5| Step: 3
Training loss: 0.7152981173967983
Validation loss: 2.7013193468580337

Epoch: 5| Step: 4
Training loss: 1.436490741204638
Validation loss: 2.7354566305823953

Epoch: 5| Step: 5
Training loss: 0.635694862397349
Validation loss: 2.7940093816126614

Epoch: 5| Step: 6
Training loss: 0.63526258528672
Validation loss: 2.795680229544891

Epoch: 5| Step: 7
Training loss: 0.6216294479563841
Validation loss: 2.6846617378624265

Epoch: 5| Step: 8
Training loss: 0.5103712321190699
Validation loss: 2.6600990942791274

Epoch: 5| Step: 9
Training loss: 0.5926753407588421
Validation loss: 2.802986181557842

Epoch: 5| Step: 10
Training loss: 0.48152206459075597
Validation loss: 2.747062222925076

Epoch: 5| Step: 11
Training loss: 1.0535252701852116
Validation loss: 2.616087747929344

Epoch: 231| Step: 0
Training loss: 0.5487790883377239
Validation loss: 2.6497512004825703

Epoch: 5| Step: 1
Training loss: 0.5770231004351746
Validation loss: 2.675022999792363

Epoch: 5| Step: 2
Training loss: 0.6466399175684526
Validation loss: 2.7502317619919956

Epoch: 5| Step: 3
Training loss: 0.6875757045679408
Validation loss: 2.7670629538293143

Epoch: 5| Step: 4
Training loss: 0.4144731500589503
Validation loss: 2.692130216128185

Epoch: 5| Step: 5
Training loss: 0.5076230209150439
Validation loss: 2.720794143121897

Epoch: 5| Step: 6
Training loss: 0.37657801093608684
Validation loss: 2.750429784539982

Epoch: 5| Step: 7
Training loss: 1.3915407830065811
Validation loss: 2.763855448850151

Epoch: 5| Step: 8
Training loss: 0.6864929192435558
Validation loss: 2.7241883603205936

Epoch: 5| Step: 9
Training loss: 0.41852436391947195
Validation loss: 2.747059673456428

Epoch: 5| Step: 10
Training loss: 0.5203251330242483
Validation loss: 2.750550399233229

Epoch: 5| Step: 11
Training loss: 0.9167765891029505
Validation loss: 2.6385201034739065

Epoch: 232| Step: 0
Training loss: 0.450563937717895
Validation loss: 2.6588484452373184

Epoch: 5| Step: 1
Training loss: 0.6052915252218315
Validation loss: 2.6674514090197894

Epoch: 5| Step: 2
Training loss: 0.6509735885630014
Validation loss: 2.7077854091303863

Epoch: 5| Step: 3
Training loss: 0.510847150181183
Validation loss: 2.78574621899261

Epoch: 5| Step: 4
Training loss: 0.3940496054164913
Validation loss: 2.7320934513651878

Epoch: 5| Step: 5
Training loss: 0.7495143430583129
Validation loss: 2.7509850955641664

Epoch: 5| Step: 6
Training loss: 0.6220009134767331
Validation loss: 2.6510820304530776

Epoch: 5| Step: 7
Training loss: 1.2491108115909828
Validation loss: 2.6547597369745817

Epoch: 5| Step: 8
Training loss: 0.5951076345299838
Validation loss: 2.65001915184034

Epoch: 5| Step: 9
Training loss: 0.8939043538647395
Validation loss: 2.6888322226595496

Epoch: 5| Step: 10
Training loss: 0.7571497112925315
Validation loss: 2.622291988424203

Epoch: 5| Step: 11
Training loss: 0.5892201847533383
Validation loss: 2.6388449716817504

Epoch: 233| Step: 0
Training loss: 0.6517607773715387
Validation loss: 2.739433757097588

Epoch: 5| Step: 1
Training loss: 0.5768102180914466
Validation loss: 2.762611421147619

Epoch: 5| Step: 2
Training loss: 1.3402396637543428
Validation loss: 2.762107559165381

Epoch: 5| Step: 3
Training loss: 0.8278701318053124
Validation loss: 2.7987571542264233

Epoch: 5| Step: 4
Training loss: 0.6198024641961063
Validation loss: 2.7452796210352153

Epoch: 5| Step: 5
Training loss: 0.46262029810249994
Validation loss: 2.6749922635658785

Epoch: 5| Step: 6
Training loss: 0.48957394191851816
Validation loss: 2.7276283920598217

Epoch: 5| Step: 7
Training loss: 0.6823795325119446
Validation loss: 2.689006689875263

Epoch: 5| Step: 8
Training loss: 0.532042445262469
Validation loss: 2.713297393015619

Epoch: 5| Step: 9
Training loss: 0.5292958051945197
Validation loss: 2.703207926130505

Epoch: 5| Step: 10
Training loss: 0.6065201521196271
Validation loss: 2.7804136554647023

Epoch: 5| Step: 11
Training loss: 0.6151846729365915
Validation loss: 2.729777563800515

Epoch: 234| Step: 0
Training loss: 0.35990638423015253
Validation loss: 2.7124864621857365

Epoch: 5| Step: 1
Training loss: 0.44094780940298856
Validation loss: 2.7513352280928283

Epoch: 5| Step: 2
Training loss: 1.5205950702774473
Validation loss: 2.888003877544706

Epoch: 5| Step: 3
Training loss: 0.46228299720592314
Validation loss: 2.780424570617082

Epoch: 5| Step: 4
Training loss: 0.5789364198141101
Validation loss: 2.7460482988353907

Epoch: 5| Step: 5
Training loss: 0.7955049443070301
Validation loss: 2.7541467512009925

Epoch: 5| Step: 6
Training loss: 0.8552800148874135
Validation loss: 2.7043304070996395

Epoch: 5| Step: 7
Training loss: 0.562902253750213
Validation loss: 2.657291985878999

Epoch: 5| Step: 8
Training loss: 0.504727367326378
Validation loss: 2.7219766273022947

Epoch: 5| Step: 9
Training loss: 0.6035985056437732
Validation loss: 2.7232586209353244

Epoch: 5| Step: 10
Training loss: 0.5299780147419058
Validation loss: 2.7691057341925456

Epoch: 5| Step: 11
Training loss: 0.5303874306014362
Validation loss: 2.7215835888297732

Epoch: 235| Step: 0
Training loss: 0.6106887252337766
Validation loss: 2.642040719636793

Epoch: 5| Step: 1
Training loss: 0.5588533558503378
Validation loss: 2.690392530753562

Epoch: 5| Step: 2
Training loss: 0.524315908328392
Validation loss: 2.663563044798782

Epoch: 5| Step: 3
Training loss: 0.5433175592629044
Validation loss: 2.74477357997159

Epoch: 5| Step: 4
Training loss: 1.2898664337326238
Validation loss: 2.778773594749082

Epoch: 5| Step: 5
Training loss: 0.6156020261863792
Validation loss: 2.710105515481038

Epoch: 5| Step: 6
Training loss: 0.5799539863486916
Validation loss: 2.771212054784202

Epoch: 5| Step: 7
Training loss: 0.5583139799331802
Validation loss: 2.7264296163186965

Epoch: 5| Step: 8
Training loss: 0.6845116692210843
Validation loss: 2.6600198248612044

Epoch: 5| Step: 9
Training loss: 0.6343820205074504
Validation loss: 2.783528141430172

Epoch: 5| Step: 10
Training loss: 0.4660245819382148
Validation loss: 2.6853879051552445

Epoch: 5| Step: 11
Training loss: 0.454264408568526
Validation loss: 2.64911813157716

Epoch: 236| Step: 0
Training loss: 0.5578425231034543
Validation loss: 2.721953474184394

Epoch: 5| Step: 1
Training loss: 0.474135126599625
Validation loss: 2.775048235024409

Epoch: 5| Step: 2
Training loss: 0.49752629318437275
Validation loss: 2.7416688876060915

Epoch: 5| Step: 3
Training loss: 0.5139447201937569
Validation loss: 2.7643815530148332

Epoch: 5| Step: 4
Training loss: 0.7019612536333856
Validation loss: 2.7743839601098617

Epoch: 5| Step: 5
Training loss: 0.6932635388832041
Validation loss: 2.7974090812131243

Epoch: 5| Step: 6
Training loss: 0.43144112719210687
Validation loss: 2.79026043878977

Epoch: 5| Step: 7
Training loss: 0.4789702610717042
Validation loss: 2.7232002579553303

Epoch: 5| Step: 8
Training loss: 0.39535389483694555
Validation loss: 2.781134231529658

Epoch: 5| Step: 9
Training loss: 1.3259912291966003
Validation loss: 2.682913703764762

Epoch: 5| Step: 10
Training loss: 0.5648222247780091
Validation loss: 2.791096687251995

Epoch: 5| Step: 11
Training loss: 0.5827109956686196
Validation loss: 2.7750051339419874

Epoch: 237| Step: 0
Training loss: 0.6862713281690618
Validation loss: 2.7365614950141834

Epoch: 5| Step: 1
Training loss: 0.37866450984742434
Validation loss: 2.799735689460621

Epoch: 5| Step: 2
Training loss: 0.4292086273655009
Validation loss: 2.7459850081740482

Epoch: 5| Step: 3
Training loss: 0.5414423447504152
Validation loss: 2.6809354643557013

Epoch: 5| Step: 4
Training loss: 0.5395647556342181
Validation loss: 2.76296038595959

Epoch: 5| Step: 5
Training loss: 0.588213480253923
Validation loss: 2.7243339262612065

Epoch: 5| Step: 6
Training loss: 0.8898106248164234
Validation loss: 2.7265566595355626

Epoch: 5| Step: 7
Training loss: 0.48973644851816667
Validation loss: 2.69687363752358

Epoch: 5| Step: 8
Training loss: 1.3101861175790401
Validation loss: 2.730647199963525

Epoch: 5| Step: 9
Training loss: 0.5238613860560226
Validation loss: 2.7230402503733115

Epoch: 5| Step: 10
Training loss: 0.4703591700618931
Validation loss: 2.7441212609310393

Epoch: 5| Step: 11
Training loss: 0.4133773569374961
Validation loss: 2.727564808739599

Epoch: 238| Step: 0
Training loss: 0.6936808740698259
Validation loss: 2.6740227408553676

Epoch: 5| Step: 1
Training loss: 0.5071093753291065
Validation loss: 2.738274451377508

Epoch: 5| Step: 2
Training loss: 0.6492416038117169
Validation loss: 2.7131512752193014

Epoch: 5| Step: 3
Training loss: 0.5254697208355872
Validation loss: 2.722805294589342

Epoch: 5| Step: 4
Training loss: 0.5710353972842256
Validation loss: 2.7396344892031133

Epoch: 5| Step: 5
Training loss: 0.5497809992780814
Validation loss: 2.6834468477438094

Epoch: 5| Step: 6
Training loss: 0.6173421448706264
Validation loss: 2.751635715218893

Epoch: 5| Step: 7
Training loss: 1.2469829866308675
Validation loss: 2.683517269875249

Epoch: 5| Step: 8
Training loss: 0.4541911211196214
Validation loss: 2.707370375344921

Epoch: 5| Step: 9
Training loss: 0.559106764600288
Validation loss: 2.7524333649439408

Epoch: 5| Step: 10
Training loss: 0.5447694025055043
Validation loss: 2.7578872944286457

Epoch: 5| Step: 11
Training loss: 0.21240332592265732
Validation loss: 2.722044753406524

Epoch: 239| Step: 0
Training loss: 0.4529065888285858
Validation loss: 2.7034037304832297

Epoch: 5| Step: 1
Training loss: 0.3883965825620982
Validation loss: 2.738427082555484

Epoch: 5| Step: 2
Training loss: 0.3514861977744676
Validation loss: 2.7480567077012554

Epoch: 5| Step: 3
Training loss: 0.6759005975900947
Validation loss: 2.687559663125101

Epoch: 5| Step: 4
Training loss: 0.7581858550929561
Validation loss: 2.7156277683977033

Epoch: 5| Step: 5
Training loss: 1.3599196471991934
Validation loss: 2.6371341557054877

Epoch: 5| Step: 6
Training loss: 0.4913009197111196
Validation loss: 2.729080906216976

Epoch: 5| Step: 7
Training loss: 0.376777370769865
Validation loss: 2.659981563618952

Epoch: 5| Step: 8
Training loss: 0.6229588078647208
Validation loss: 2.6975449240911877

Epoch: 5| Step: 9
Training loss: 0.45346385519043564
Validation loss: 2.742778859219943

Epoch: 5| Step: 10
Training loss: 0.4528728967670959
Validation loss: 2.7546869204025253

Epoch: 5| Step: 11
Training loss: 0.5265133005583291
Validation loss: 2.720287078499079

Epoch: 240| Step: 0
Training loss: 1.2795315359834758
Validation loss: 2.78040719924802

Epoch: 5| Step: 1
Training loss: 0.5792940022660353
Validation loss: 2.756465409959123

Epoch: 5| Step: 2
Training loss: 0.6253731567306848
Validation loss: 2.8086052064480698

Epoch: 5| Step: 3
Training loss: 0.6179520181544067
Validation loss: 2.7493275195848703

Epoch: 5| Step: 4
Training loss: 0.4676587754680683
Validation loss: 2.802187248817893

Epoch: 5| Step: 5
Training loss: 0.8470081717312007
Validation loss: 2.7410090269846807

Epoch: 5| Step: 6
Training loss: 0.6789460797143952
Validation loss: 2.7344326303857547

Epoch: 5| Step: 7
Training loss: 0.851840157695411
Validation loss: 2.808980435000083

Epoch: 5| Step: 8
Training loss: 0.692650532043799
Validation loss: 2.744202369004362

Epoch: 5| Step: 9
Training loss: 0.44198406850898797
Validation loss: 2.84948964485125

Epoch: 5| Step: 10
Training loss: 0.6355957706448743
Validation loss: 2.7555845733258937

Epoch: 5| Step: 11
Training loss: 0.41310565080792444
Validation loss: 2.7928895739023285

Epoch: 241| Step: 0
Training loss: 0.605945940554037
Validation loss: 2.8262549939309

Epoch: 5| Step: 1
Training loss: 0.5033361181546323
Validation loss: 2.77811647906604

Epoch: 5| Step: 2
Training loss: 0.6064295375080684
Validation loss: 2.7724793726787524

Epoch: 5| Step: 3
Training loss: 0.3898619064659217
Validation loss: 2.759937551893036

Epoch: 5| Step: 4
Training loss: 0.5915321286682796
Validation loss: 2.6669063286572348

Epoch: 5| Step: 5
Training loss: 0.4391058163979375
Validation loss: 2.720035910234933

Epoch: 5| Step: 6
Training loss: 0.5170082842054295
Validation loss: 2.6734243867880654

Epoch: 5| Step: 7
Training loss: 0.598598510356825
Validation loss: 2.692029791264448

Epoch: 5| Step: 8
Training loss: 0.498914732916182
Validation loss: 2.6614580260175216

Epoch: 5| Step: 9
Training loss: 0.7842078862993033
Validation loss: 2.628721959086505

Epoch: 5| Step: 10
Training loss: 1.2470701691127806
Validation loss: 2.6287955439829505

Epoch: 5| Step: 11
Training loss: 0.6514034461319994
Validation loss: 2.670814653252924

Epoch: 242| Step: 0
Training loss: 1.4148404842277933
Validation loss: 2.7855214115431

Epoch: 5| Step: 1
Training loss: 0.8827994691680363
Validation loss: 2.9138533898154817

Epoch: 5| Step: 2
Training loss: 0.8632949897052473
Validation loss: 2.8093498195613082

Epoch: 5| Step: 3
Training loss: 0.47517828732498074
Validation loss: 2.817354537319527

Epoch: 5| Step: 4
Training loss: 0.6401071548909482
Validation loss: 2.680740827840539

Epoch: 5| Step: 5
Training loss: 0.8511125618312492
Validation loss: 2.6543723295189525

Epoch: 5| Step: 6
Training loss: 0.5985433937983474
Validation loss: 2.791260199823576

Epoch: 5| Step: 7
Training loss: 0.6663787612522662
Validation loss: 2.74181486968879

Epoch: 5| Step: 8
Training loss: 0.591103805750904
Validation loss: 2.6744269143373387

Epoch: 5| Step: 9
Training loss: 0.5191635896010877
Validation loss: 2.7122356154104073

Epoch: 5| Step: 10
Training loss: 0.6305231668843054
Validation loss: 2.773605971972852

Epoch: 5| Step: 11
Training loss: 0.5783315495794237
Validation loss: 2.797576379474778

Epoch: 243| Step: 0
Training loss: 0.6057326203300002
Validation loss: 2.8184266834676754

Epoch: 5| Step: 1
Training loss: 1.3859100992790592
Validation loss: 2.8366858665796735

Epoch: 5| Step: 2
Training loss: 0.33152793434449046
Validation loss: 2.7645704338579615

Epoch: 5| Step: 3
Training loss: 0.4071561171528313
Validation loss: 2.7000516203667027

Epoch: 5| Step: 4
Training loss: 0.470003708510276
Validation loss: 2.651723355607016

Epoch: 5| Step: 5
Training loss: 0.4611702993845208
Validation loss: 2.670868559489487

Epoch: 5| Step: 6
Training loss: 0.5863678686813861
Validation loss: 2.643163822412439

Epoch: 5| Step: 7
Training loss: 0.47855349021103594
Validation loss: 2.714413074024651

Epoch: 5| Step: 8
Training loss: 0.723692650837024
Validation loss: 2.7339150941183217

Epoch: 5| Step: 9
Training loss: 0.5621687920655826
Validation loss: 2.6719678301235685

Epoch: 5| Step: 10
Training loss: 0.6337643046899649
Validation loss: 2.7012746832262815

Epoch: 5| Step: 11
Training loss: 0.26325567387265403
Validation loss: 2.798933844866787

Epoch: 244| Step: 0
Training loss: 0.4846948060125151
Validation loss: 2.773241675542272

Epoch: 5| Step: 1
Training loss: 0.43725083272101106
Validation loss: 2.769553284407225

Epoch: 5| Step: 2
Training loss: 0.5666757402909064
Validation loss: 2.7868562657839515

Epoch: 5| Step: 3
Training loss: 0.6739053654283484
Validation loss: 2.8369813229350904

Epoch: 5| Step: 4
Training loss: 0.6691062566568154
Validation loss: 2.805274374224967

Epoch: 5| Step: 5
Training loss: 0.36610671531261757
Validation loss: 2.657640818575887

Epoch: 5| Step: 6
Training loss: 0.4223777812607665
Validation loss: 2.723100404345945

Epoch: 5| Step: 7
Training loss: 0.48415575910856173
Validation loss: 2.756295385729514

Epoch: 5| Step: 8
Training loss: 0.5322956005431329
Validation loss: 2.73169283517643

Epoch: 5| Step: 9
Training loss: 1.3231724118913117
Validation loss: 2.7508003305706787

Epoch: 5| Step: 10
Training loss: 0.5131271723284255
Validation loss: 2.776984086425053

Epoch: 5| Step: 11
Training loss: 0.5184065037728517
Validation loss: 2.747971751278187

Epoch: 245| Step: 0
Training loss: 0.6663379504498804
Validation loss: 2.7386439904421285

Epoch: 5| Step: 1
Training loss: 0.5174731454008895
Validation loss: 2.750990826388425

Epoch: 5| Step: 2
Training loss: 0.49852602480484653
Validation loss: 2.835987948835044

Epoch: 5| Step: 3
Training loss: 0.7054564710458839
Validation loss: 2.838481431141124

Epoch: 5| Step: 4
Training loss: 0.3702712732214184
Validation loss: 2.802278498880824

Epoch: 5| Step: 5
Training loss: 1.3064148027778597
Validation loss: 2.8022552825091114

Epoch: 5| Step: 6
Training loss: 0.5682647206774067
Validation loss: 2.76514514344971

Epoch: 5| Step: 7
Training loss: 0.6075638485546154
Validation loss: 2.7725606759084704

Epoch: 5| Step: 8
Training loss: 0.6179039092835881
Validation loss: 2.7529480730434948

Epoch: 5| Step: 9
Training loss: 0.49535686101727644
Validation loss: 2.74315255727287

Epoch: 5| Step: 10
Training loss: 0.45391347948314853
Validation loss: 2.784132281911925

Epoch: 5| Step: 11
Training loss: 0.6133409701870498
Validation loss: 2.767812941018076

Epoch: 246| Step: 0
Training loss: 0.4904185097475295
Validation loss: 2.926341031709197

Epoch: 5| Step: 1
Training loss: 0.4792240737305893
Validation loss: 2.809978870417614

Epoch: 5| Step: 2
Training loss: 0.6761817847660102
Validation loss: 2.7850401623659056

Epoch: 5| Step: 3
Training loss: 0.5743864683847248
Validation loss: 2.7124264280827677

Epoch: 5| Step: 4
Training loss: 1.260070905733924
Validation loss: 2.7669662843807

Epoch: 5| Step: 5
Training loss: 0.4757851999804765
Validation loss: 2.73095771147962

Epoch: 5| Step: 6
Training loss: 0.5338540488142178
Validation loss: 2.685268055631531

Epoch: 5| Step: 7
Training loss: 0.37648597984502286
Validation loss: 2.7850308847056056

Epoch: 5| Step: 8
Training loss: 0.3138006798592783
Validation loss: 2.7033933348313592

Epoch: 5| Step: 9
Training loss: 0.7731465264347993
Validation loss: 2.8047167494018184

Epoch: 5| Step: 10
Training loss: 0.47250275444560025
Validation loss: 2.7914669027072874

Epoch: 5| Step: 11
Training loss: 0.6991807298606154
Validation loss: 2.8347661215010898

Epoch: 247| Step: 0
Training loss: 0.413671668955866
Validation loss: 2.8315425126615392

Epoch: 5| Step: 1
Training loss: 0.43895985363934015
Validation loss: 2.765086924478262

Epoch: 5| Step: 2
Training loss: 0.6484608933239079
Validation loss: 2.7708870313694716

Epoch: 5| Step: 3
Training loss: 0.49813503906204204
Validation loss: 2.8255823623825513

Epoch: 5| Step: 4
Training loss: 0.4141690459013565
Validation loss: 2.7601683354988196

Epoch: 5| Step: 5
Training loss: 0.6671280059375054
Validation loss: 2.722063471637341

Epoch: 5| Step: 6
Training loss: 0.4050052720774604
Validation loss: 2.673401101163893

Epoch: 5| Step: 7
Training loss: 0.6269046847920658
Validation loss: 2.732430640518566

Epoch: 5| Step: 8
Training loss: 0.6828594296387736
Validation loss: 2.801421205411667

Epoch: 5| Step: 9
Training loss: 1.3459100439611658
Validation loss: 2.7353574241349303

Epoch: 5| Step: 10
Training loss: 0.823845982437168
Validation loss: 2.7896587293738118

Epoch: 5| Step: 11
Training loss: 0.401075252348648
Validation loss: 2.7442462760524937

Epoch: 248| Step: 0
Training loss: 0.5650697395865983
Validation loss: 2.7308540963691335

Epoch: 5| Step: 1
Training loss: 0.8195610964624958
Validation loss: 2.703853689037585

Epoch: 5| Step: 2
Training loss: 0.6735996245904746
Validation loss: 2.7361557856547085

Epoch: 5| Step: 3
Training loss: 0.4517980746458282
Validation loss: 2.6506625855622

Epoch: 5| Step: 4
Training loss: 0.41012097161572225
Validation loss: 2.6387701724492247

Epoch: 5| Step: 5
Training loss: 0.47707854925141835
Validation loss: 2.724651975310072

Epoch: 5| Step: 6
Training loss: 0.5904422275373736
Validation loss: 2.6653712610640343

Epoch: 5| Step: 7
Training loss: 0.42311531985548345
Validation loss: 2.7779117116163445

Epoch: 5| Step: 8
Training loss: 0.5847253086051925
Validation loss: 2.7489031063505567

Epoch: 5| Step: 9
Training loss: 1.2077317658715814
Validation loss: 2.7261808396058242

Epoch: 5| Step: 10
Training loss: 0.50344312810327
Validation loss: 2.7612623298891257

Epoch: 5| Step: 11
Training loss: 0.7941861508778948
Validation loss: 2.8011041168726383

Epoch: 249| Step: 0
Training loss: 0.4979537128755157
Validation loss: 2.707258687412307

Epoch: 5| Step: 1
Training loss: 0.33034055762101217
Validation loss: 2.7570172352847644

Epoch: 5| Step: 2
Training loss: 0.7636020560190449
Validation loss: 2.7222422463357456

Epoch: 5| Step: 3
Training loss: 0.4515852747523058
Validation loss: 2.6892977253867536

Epoch: 5| Step: 4
Training loss: 0.5834003194313103
Validation loss: 2.8013707191934216

Epoch: 5| Step: 5
Training loss: 0.49276537501164935
Validation loss: 2.710023313612089

Epoch: 5| Step: 6
Training loss: 1.1990604855359186
Validation loss: 2.7622862956152625

Epoch: 5| Step: 7
Training loss: 0.46707272858141147
Validation loss: 2.766963598870569

Epoch: 5| Step: 8
Training loss: 0.41990785797145125
Validation loss: 2.791516760222177

Epoch: 5| Step: 9
Training loss: 0.4982206452848133
Validation loss: 2.7014776219098855

Epoch: 5| Step: 10
Training loss: 0.5536382449166241
Validation loss: 2.7301524119573117

Epoch: 5| Step: 11
Training loss: 0.47346521932199337
Validation loss: 2.7746346016901158

Epoch: 250| Step: 0
Training loss: 0.48246786539266107
Validation loss: 2.697682342270542

Epoch: 5| Step: 1
Training loss: 0.41187453245330347
Validation loss: 2.744662326441193

Epoch: 5| Step: 2
Training loss: 0.45893025180600194
Validation loss: 2.629257016259304

Epoch: 5| Step: 3
Training loss: 0.5019272378265036
Validation loss: 2.7167630224360733

Epoch: 5| Step: 4
Training loss: 0.4832270925463221
Validation loss: 2.7022743503657947

Epoch: 5| Step: 5
Training loss: 0.5539621526704355
Validation loss: 2.6932330859191467

Epoch: 5| Step: 6
Training loss: 0.5192288544067983
Validation loss: 2.7198465299143777

Epoch: 5| Step: 7
Training loss: 0.7478330620355059
Validation loss: 2.7371031421249064

Epoch: 5| Step: 8
Training loss: 0.5481665210808738
Validation loss: 2.6904939674964856

Epoch: 5| Step: 9
Training loss: 0.512833291515059
Validation loss: 2.7353957895691345

Epoch: 5| Step: 10
Training loss: 1.1655130245637997
Validation loss: 2.7131540066705493

Epoch: 5| Step: 11
Training loss: 0.8494707717964068
Validation loss: 2.7763401154960348

Epoch: 251| Step: 0
Training loss: 0.45725077060261193
Validation loss: 2.6581049407458037

Epoch: 5| Step: 1
Training loss: 0.5485957186453625
Validation loss: 2.6881810737324865

Epoch: 5| Step: 2
Training loss: 0.7650592426348815
Validation loss: 2.6632706331321376

Epoch: 5| Step: 3
Training loss: 0.6347666109517583
Validation loss: 2.6993275172856404

Epoch: 5| Step: 4
Training loss: 0.5538254069529188
Validation loss: 2.660035730470927

Epoch: 5| Step: 5
Training loss: 0.4563693282444421
Validation loss: 2.7078646559992636

Epoch: 5| Step: 6
Training loss: 0.7124417916998668
Validation loss: 2.721654816344938

Epoch: 5| Step: 7
Training loss: 1.2426895950239096
Validation loss: 2.6952400418921942

Epoch: 5| Step: 8
Training loss: 0.3791149194045721
Validation loss: 2.7629277893469197

Epoch: 5| Step: 9
Training loss: 0.3255128656047987
Validation loss: 2.667260414323216

Epoch: 5| Step: 10
Training loss: 0.378766338826894
Validation loss: 2.6695053772886164

Epoch: 5| Step: 11
Training loss: 0.579314786051496
Validation loss: 2.69151737037263

Epoch: 252| Step: 0
Training loss: 0.7610708758198806
Validation loss: 2.6521679328845997

Epoch: 5| Step: 1
Training loss: 0.581127078892236
Validation loss: 2.7200074302522768

Epoch: 5| Step: 2
Training loss: 0.62504415356122
Validation loss: 2.7316656040886267

Epoch: 5| Step: 3
Training loss: 0.6413133226327478
Validation loss: 2.6833255861498277

Epoch: 5| Step: 4
Training loss: 0.432799875509082
Validation loss: 2.675803135691889

Epoch: 5| Step: 5
Training loss: 0.434902467125039
Validation loss: 2.740325538313352

Epoch: 5| Step: 6
Training loss: 0.6077741968790196
Validation loss: 2.8179598159584964

Epoch: 5| Step: 7
Training loss: 0.579143220326274
Validation loss: 2.731310480468033

Epoch: 5| Step: 8
Training loss: 0.5106300537251497
Validation loss: 2.7290883829571233

Epoch: 5| Step: 9
Training loss: 1.3966640543552875
Validation loss: 2.722519829651281

Epoch: 5| Step: 10
Training loss: 0.7229507258707528
Validation loss: 2.6490911054219892

Epoch: 5| Step: 11
Training loss: 0.5338949947717023
Validation loss: 2.6599500691058586

Epoch: 253| Step: 0
Training loss: 0.5946171100791474
Validation loss: 2.706106034223877

Epoch: 5| Step: 1
Training loss: 0.5626140055096004
Validation loss: 2.738854497456549

Epoch: 5| Step: 2
Training loss: 0.4521315635350278
Validation loss: 2.731792856545249

Epoch: 5| Step: 3
Training loss: 0.4004810138183461
Validation loss: 2.717663076327812

Epoch: 5| Step: 4
Training loss: 0.6556586825843522
Validation loss: 2.7532677796369165

Epoch: 5| Step: 5
Training loss: 1.290051260232833
Validation loss: 2.792860615021902

Epoch: 5| Step: 6
Training loss: 0.4756316020121392
Validation loss: 2.8239022759577557

Epoch: 5| Step: 7
Training loss: 0.6736727770428047
Validation loss: 2.7521255724310407

Epoch: 5| Step: 8
Training loss: 0.46753780666007044
Validation loss: 2.7007800204394057

Epoch: 5| Step: 9
Training loss: 0.48799022394006975
Validation loss: 2.719402377464886

Epoch: 5| Step: 10
Training loss: 0.4666479184295863
Validation loss: 2.723994400096847

Epoch: 5| Step: 11
Training loss: 0.36842575688693036
Validation loss: 2.7022257321516445

Epoch: 254| Step: 0
Training loss: 0.5303627346435782
Validation loss: 2.6943072688167646

Epoch: 5| Step: 1
Training loss: 0.4749629740338415
Validation loss: 2.6938033923989093

Epoch: 5| Step: 2
Training loss: 0.5181988718452673
Validation loss: 2.7360294804415077

Epoch: 5| Step: 3
Training loss: 1.2167321152698236
Validation loss: 2.718859863984602

Epoch: 5| Step: 4
Training loss: 0.28733865834009015
Validation loss: 2.7214835627455027

Epoch: 5| Step: 5
Training loss: 0.4276518894596255
Validation loss: 2.7254514024316507

Epoch: 5| Step: 6
Training loss: 0.4340465174973944
Validation loss: 2.849826908153484

Epoch: 5| Step: 7
Training loss: 0.4732620203614597
Validation loss: 2.7192792560003936

Epoch: 5| Step: 8
Training loss: 0.42602846860456867
Validation loss: 2.818438790784868

Epoch: 5| Step: 9
Training loss: 0.4165290207798551
Validation loss: 2.814962171184072

Epoch: 5| Step: 10
Training loss: 0.7914108984190283
Validation loss: 2.722020465863116

Epoch: 5| Step: 11
Training loss: 0.31413104462263103
Validation loss: 2.799486440013338

Epoch: 255| Step: 0
Training loss: 0.5653860968091791
Validation loss: 2.7115316775046847

Epoch: 5| Step: 1
Training loss: 0.5065422015444474
Validation loss: 2.7172359657462155

Epoch: 5| Step: 2
Training loss: 0.5636956435259376
Validation loss: 2.855738298780826

Epoch: 5| Step: 3
Training loss: 0.46009423011216327
Validation loss: 2.72830480454229

Epoch: 5| Step: 4
Training loss: 1.254638173047004
Validation loss: 2.740581676237867

Epoch: 5| Step: 5
Training loss: 0.43424823269679336
Validation loss: 2.7185063855873426

Epoch: 5| Step: 6
Training loss: 0.563844504460058
Validation loss: 2.8312418431605946

Epoch: 5| Step: 7
Training loss: 0.5020969644914779
Validation loss: 2.734558026682361

Epoch: 5| Step: 8
Training loss: 0.40097446208836673
Validation loss: 2.783435384417573

Epoch: 5| Step: 9
Training loss: 0.5583581227402864
Validation loss: 2.7596961334615284

Epoch: 5| Step: 10
Training loss: 0.37616663500343855
Validation loss: 2.724351921360098

Epoch: 5| Step: 11
Training loss: 0.3882080454292853
Validation loss: 2.746255362518034

Epoch: 256| Step: 0
Training loss: 1.3488037973304094
Validation loss: 2.668834488102352

Epoch: 5| Step: 1
Training loss: 0.45937846694987433
Validation loss: 2.670198755016193

Epoch: 5| Step: 2
Training loss: 0.6465623699057196
Validation loss: 2.70918469008129

Epoch: 5| Step: 3
Training loss: 0.42114795626094953
Validation loss: 2.770041644257302

Epoch: 5| Step: 4
Training loss: 0.441460766421795
Validation loss: 2.755638122688853

Epoch: 5| Step: 5
Training loss: 0.5723404819104667
Validation loss: 2.747286093209053

Epoch: 5| Step: 6
Training loss: 0.5379690330608774
Validation loss: 2.801627417466661

Epoch: 5| Step: 7
Training loss: 0.4235749433360602
Validation loss: 2.8230369420253134

Epoch: 5| Step: 8
Training loss: 0.4358093257872158
Validation loss: 2.83307361931799

Epoch: 5| Step: 9
Training loss: 0.6762292732898306
Validation loss: 2.7454493287895962

Epoch: 5| Step: 10
Training loss: 0.4716015389666065
Validation loss: 2.600809333842917

Epoch: 5| Step: 11
Training loss: 0.7461539438941129
Validation loss: 2.733389180812719

Epoch: 257| Step: 0
Training loss: 0.5801530783166137
Validation loss: 2.6938863805306537

Epoch: 5| Step: 1
Training loss: 0.3324722278799231
Validation loss: 2.7999717113507723

Epoch: 5| Step: 2
Training loss: 0.6505743231262032
Validation loss: 2.7769990395022415

Epoch: 5| Step: 3
Training loss: 0.6394863942602571
Validation loss: 2.73674979853389

Epoch: 5| Step: 4
Training loss: 1.2186809911508605
Validation loss: 2.699920776464689

Epoch: 5| Step: 5
Training loss: 0.3602993728350608
Validation loss: 2.7316621129038916

Epoch: 5| Step: 6
Training loss: 0.561153867428119
Validation loss: 2.730806699985156

Epoch: 5| Step: 7
Training loss: 0.4350864217401728
Validation loss: 2.634310902501672

Epoch: 5| Step: 8
Training loss: 0.5197819269933072
Validation loss: 2.7279660129429604

Epoch: 5| Step: 9
Training loss: 0.6026683897339121
Validation loss: 2.6819821422958112

Epoch: 5| Step: 10
Training loss: 0.5541527010178509
Validation loss: 2.682231351797725

Epoch: 5| Step: 11
Training loss: 0.5763093428765741
Validation loss: 2.755470033895354

Epoch: 258| Step: 0
Training loss: 0.6572286257208397
Validation loss: 2.637720625058117

Epoch: 5| Step: 1
Training loss: 0.5160521558584431
Validation loss: 2.7952565104586693

Epoch: 5| Step: 2
Training loss: 1.2323056512309456
Validation loss: 2.7572376635520444

Epoch: 5| Step: 3
Training loss: 0.4615937749640435
Validation loss: 2.7419870308743928

Epoch: 5| Step: 4
Training loss: 0.41736452154514103
Validation loss: 2.762488211668475

Epoch: 5| Step: 5
Training loss: 0.7161764427348165
Validation loss: 2.767963186113632

Epoch: 5| Step: 6
Training loss: 0.5683800867246115
Validation loss: 2.6841675886582697

Epoch: 5| Step: 7
Training loss: 0.6038936184330695
Validation loss: 2.735893754157317

Epoch: 5| Step: 8
Training loss: 0.5032518854726538
Validation loss: 2.729318138947128

Epoch: 5| Step: 9
Training loss: 0.5084413009904751
Validation loss: 2.7693561127332185

Epoch: 5| Step: 10
Training loss: 0.47376659902717394
Validation loss: 2.754259426836373

Epoch: 5| Step: 11
Training loss: 0.2451393451782485
Validation loss: 2.702203564161385

Epoch: 259| Step: 0
Training loss: 1.197062538932099
Validation loss: 2.7727972195982176

Epoch: 5| Step: 1
Training loss: 0.4621331661030127
Validation loss: 2.7487773633806056

Epoch: 5| Step: 2
Training loss: 0.672631791187393
Validation loss: 2.750321947383587

Epoch: 5| Step: 3
Training loss: 0.3133286575824958
Validation loss: 2.7351485547826715

Epoch: 5| Step: 4
Training loss: 0.42377907605412135
Validation loss: 2.752698356559141

Epoch: 5| Step: 5
Training loss: 0.5012828938828399
Validation loss: 2.7226212297227854

Epoch: 5| Step: 6
Training loss: 0.5573851842640644
Validation loss: 2.6081204129923816

Epoch: 5| Step: 7
Training loss: 0.478087439962863
Validation loss: 2.689007846203724

Epoch: 5| Step: 8
Training loss: 0.5663869657193324
Validation loss: 2.701912944473432

Epoch: 5| Step: 9
Training loss: 0.46099966244261126
Validation loss: 2.6947969468788426

Epoch: 5| Step: 10
Training loss: 0.5096859047477077
Validation loss: 2.7196458604802776

Epoch: 5| Step: 11
Training loss: 0.4366544147251682
Validation loss: 2.7031343713498703

Epoch: 260| Step: 0
Training loss: 0.48477923537827755
Validation loss: 2.7228368027018894

Epoch: 5| Step: 1
Training loss: 0.5923083773319864
Validation loss: 2.7628062084275795

Epoch: 5| Step: 2
Training loss: 0.5443702010809282
Validation loss: 2.782646360869393

Epoch: 5| Step: 3
Training loss: 0.4563865679317305
Validation loss: 2.7750996117856186

Epoch: 5| Step: 4
Training loss: 0.7033377007790267
Validation loss: 2.7468344682893626

Epoch: 5| Step: 5
Training loss: 1.1972247018712192
Validation loss: 2.6945965096952924

Epoch: 5| Step: 6
Training loss: 0.4975639395384514
Validation loss: 2.7541109734952833

Epoch: 5| Step: 7
Training loss: 0.49145630610350965
Validation loss: 2.6371795816728674

Epoch: 5| Step: 8
Training loss: 0.47692664882896596
Validation loss: 2.7061163166672797

Epoch: 5| Step: 9
Training loss: 0.38709368014733425
Validation loss: 2.7515834851595664

Epoch: 5| Step: 10
Training loss: 0.38994388326368795
Validation loss: 2.7339134517052375

Epoch: 5| Step: 11
Training loss: 0.4755919689132834
Validation loss: 2.708779072150032

Epoch: 261| Step: 0
Training loss: 0.48239039885968144
Validation loss: 2.8172173498303335

Epoch: 5| Step: 1
Training loss: 1.1440896494024193
Validation loss: 2.782693902440194

Epoch: 5| Step: 2
Training loss: 0.5346655440602127
Validation loss: 2.741542345395634

Epoch: 5| Step: 3
Training loss: 0.5717543573751404
Validation loss: 2.7495516769223567

Epoch: 5| Step: 4
Training loss: 0.5287553050629539
Validation loss: 2.7171886425809264

Epoch: 5| Step: 5
Training loss: 0.45876807127863223
Validation loss: 2.6859544812298664

Epoch: 5| Step: 6
Training loss: 0.4073136051380149
Validation loss: 2.7165229854930133

Epoch: 5| Step: 7
Training loss: 0.3945072280066918
Validation loss: 2.726687642516557

Epoch: 5| Step: 8
Training loss: 0.47468012215742855
Validation loss: 2.694455874037561

Epoch: 5| Step: 9
Training loss: 0.7691416262362945
Validation loss: 2.725077420485186

Epoch: 5| Step: 10
Training loss: 0.5032183068988979
Validation loss: 2.759242115010753

Epoch: 5| Step: 11
Training loss: 0.48752685252841615
Validation loss: 2.737205464559323

Epoch: 262| Step: 0
Training loss: 0.3919912097806574
Validation loss: 2.751416975596163

Epoch: 5| Step: 1
Training loss: 0.4727412848786356
Validation loss: 2.776228436216391

Epoch: 5| Step: 2
Training loss: 0.5276144392614567
Validation loss: 2.7605870044383023

Epoch: 5| Step: 3
Training loss: 0.48461986320691564
Validation loss: 2.7260911929498146

Epoch: 5| Step: 4
Training loss: 0.37067027775517175
Validation loss: 2.7278402189321413

Epoch: 5| Step: 5
Training loss: 0.4296452414800152
Validation loss: 2.6773659721426646

Epoch: 5| Step: 6
Training loss: 0.5053073418990358
Validation loss: 2.7852495560391897

Epoch: 5| Step: 7
Training loss: 0.475670902879364
Validation loss: 2.7862567733641246

Epoch: 5| Step: 8
Training loss: 0.5827146524717012
Validation loss: 2.6939310191521635

Epoch: 5| Step: 9
Training loss: 0.5118581567398871
Validation loss: 2.749392623006619

Epoch: 5| Step: 10
Training loss: 1.1445963453718089
Validation loss: 2.766322832736038

Epoch: 5| Step: 11
Training loss: 0.562251221426065
Validation loss: 2.701241584957725

Epoch: 263| Step: 0
Training loss: 0.46946759927077014
Validation loss: 2.801772934739973

Epoch: 5| Step: 1
Training loss: 0.45582940951907025
Validation loss: 2.853149959835248

Epoch: 5| Step: 2
Training loss: 0.39453423376182595
Validation loss: 2.7844863057321807

Epoch: 5| Step: 3
Training loss: 0.5421329899630762
Validation loss: 2.782042311921624

Epoch: 5| Step: 4
Training loss: 1.115151370512079
Validation loss: 2.8508796814986166

Epoch: 5| Step: 5
Training loss: 0.49562654497403685
Validation loss: 2.661527103996257

Epoch: 5| Step: 6
Training loss: 0.35834901973116046
Validation loss: 2.7282258346117993

Epoch: 5| Step: 7
Training loss: 0.5601686803484
Validation loss: 2.7432744913948057

Epoch: 5| Step: 8
Training loss: 0.6045875289249115
Validation loss: 2.7308398655357458

Epoch: 5| Step: 9
Training loss: 0.5772780064793351
Validation loss: 2.793761425862569

Epoch: 5| Step: 10
Training loss: 0.4793092180448859
Validation loss: 2.7549738588898722

Epoch: 5| Step: 11
Training loss: 0.4516324091455864
Validation loss: 2.7380627913680056

Epoch: 264| Step: 0
Training loss: 0.6636974453280173
Validation loss: 2.878972280945037

Epoch: 5| Step: 1
Training loss: 0.6297368316636546
Validation loss: 2.861817544822898

Epoch: 5| Step: 2
Training loss: 0.6040024753513518
Validation loss: 2.7763396020342497

Epoch: 5| Step: 3
Training loss: 1.1960006428464864
Validation loss: 2.79671377466759

Epoch: 5| Step: 4
Training loss: 0.45424202008079695
Validation loss: 2.793633473929607

Epoch: 5| Step: 5
Training loss: 0.4495300209683618
Validation loss: 2.7697261711220578

Epoch: 5| Step: 6
Training loss: 0.39825053596819715
Validation loss: 2.7192395087479273

Epoch: 5| Step: 7
Training loss: 0.5522984379550299
Validation loss: 2.792006768438393

Epoch: 5| Step: 8
Training loss: 0.6088486623610408
Validation loss: 2.7974484351300304

Epoch: 5| Step: 9
Training loss: 0.5266241462007017
Validation loss: 2.7370815397088193

Epoch: 5| Step: 10
Training loss: 0.4062121080186723
Validation loss: 2.90657363306526

Epoch: 5| Step: 11
Training loss: 0.5224615649638463
Validation loss: 2.8229651229941233

Epoch: 265| Step: 0
Training loss: 0.40896143589342476
Validation loss: 2.806688213188287

Epoch: 5| Step: 1
Training loss: 0.5851643356762842
Validation loss: 2.7695942177942916

Epoch: 5| Step: 2
Training loss: 1.1476573759713566
Validation loss: 2.7550630056396437

Epoch: 5| Step: 3
Training loss: 0.42491353712196894
Validation loss: 2.7958810841044808

Epoch: 5| Step: 4
Training loss: 0.7013325626640413
Validation loss: 2.6632288824609875

Epoch: 5| Step: 5
Training loss: 0.4020204448767593
Validation loss: 2.7572833698197354

Epoch: 5| Step: 6
Training loss: 0.44678069566813833
Validation loss: 2.704759647428927

Epoch: 5| Step: 7
Training loss: 0.5215224920050964
Validation loss: 2.742964421675123

Epoch: 5| Step: 8
Training loss: 0.7362469696733841
Validation loss: 2.780030304568624

Epoch: 5| Step: 9
Training loss: 0.46824412069178584
Validation loss: 2.841935368295149

Epoch: 5| Step: 10
Training loss: 0.44138486354634987
Validation loss: 2.7269613508031116

Epoch: 5| Step: 11
Training loss: 0.5569577301001957
Validation loss: 2.8167385129305282

Epoch: 266| Step: 0
Training loss: 0.4829937097917791
Validation loss: 2.7527296109278065

Epoch: 5| Step: 1
Training loss: 0.3776633928702213
Validation loss: 2.7558140812933765

Epoch: 5| Step: 2
Training loss: 0.4820952912361195
Validation loss: 2.748415277220273

Epoch: 5| Step: 3
Training loss: 0.3614217688382343
Validation loss: 2.7038098388342746

Epoch: 5| Step: 4
Training loss: 0.4869498755745788
Validation loss: 2.7905466136339347

Epoch: 5| Step: 5
Training loss: 0.7063963341813321
Validation loss: 2.7933717094628814

Epoch: 5| Step: 6
Training loss: 0.5270646380952568
Validation loss: 2.792374500999507

Epoch: 5| Step: 7
Training loss: 0.4300902473203416
Validation loss: 2.7764225150423427

Epoch: 5| Step: 8
Training loss: 0.512988459022269
Validation loss: 2.8337689350035706

Epoch: 5| Step: 9
Training loss: 0.4776961803373807
Validation loss: 2.8261942973518335

Epoch: 5| Step: 10
Training loss: 1.1695151410111462
Validation loss: 2.795446695369366

Epoch: 5| Step: 11
Training loss: 0.45815043882282164
Validation loss: 2.7532720859190993

Epoch: 267| Step: 0
Training loss: 0.6208063816347814
Validation loss: 2.7304450722151197

Epoch: 5| Step: 1
Training loss: 0.43752392635315085
Validation loss: 2.706721474820979

Epoch: 5| Step: 2
Training loss: 0.5893004991484916
Validation loss: 2.739845917208391

Epoch: 5| Step: 3
Training loss: 1.1897670788774544
Validation loss: 2.741289388405815

Epoch: 5| Step: 4
Training loss: 0.37640879172943204
Validation loss: 2.7294699352360494

Epoch: 5| Step: 5
Training loss: 0.6047708488409249
Validation loss: 2.6467994680665665

Epoch: 5| Step: 6
Training loss: 0.5747240658733521
Validation loss: 2.7386277360958915

Epoch: 5| Step: 7
Training loss: 0.3899147251935773
Validation loss: 2.853400354931458

Epoch: 5| Step: 8
Training loss: 0.3794609414281855
Validation loss: 2.7167655198906626

Epoch: 5| Step: 9
Training loss: 0.5251547698817552
Validation loss: 2.7923322543673073

Epoch: 5| Step: 10
Training loss: 0.5370245294314115
Validation loss: 2.8321670745199503

Epoch: 5| Step: 11
Training loss: 0.45543080690401594
Validation loss: 2.7112797494513363

Epoch: 268| Step: 0
Training loss: 0.4579837361658908
Validation loss: 2.7692199194872544

Epoch: 5| Step: 1
Training loss: 0.6062961708263147
Validation loss: 2.698582321636665

Epoch: 5| Step: 2
Training loss: 0.662946458846803
Validation loss: 2.677194813189613

Epoch: 5| Step: 3
Training loss: 0.5549127363214807
Validation loss: 2.7932013141401186

Epoch: 5| Step: 4
Training loss: 0.534891940371701
Validation loss: 2.6737941296731225

Epoch: 5| Step: 5
Training loss: 0.49193042520411445
Validation loss: 2.7462478601687255

Epoch: 5| Step: 6
Training loss: 0.4535892016175886
Validation loss: 2.7683181473267435

Epoch: 5| Step: 7
Training loss: 0.7737770491202878
Validation loss: 2.8549558089232825

Epoch: 5| Step: 8
Training loss: 0.4548819123026227
Validation loss: 2.8197294532518145

Epoch: 5| Step: 9
Training loss: 1.193376556622425
Validation loss: 2.839461729860827

Epoch: 5| Step: 10
Training loss: 0.6352102512427836
Validation loss: 2.8355169238365363

Epoch: 5| Step: 11
Training loss: 0.2178581312590429
Validation loss: 2.810764264572796

Epoch: 269| Step: 0
Training loss: 1.1950829478728444
Validation loss: 2.777648744500209

Epoch: 5| Step: 1
Training loss: 0.620281191787667
Validation loss: 2.7689442839818694

Epoch: 5| Step: 2
Training loss: 0.7044472024598201
Validation loss: 2.747177821665094

Epoch: 5| Step: 3
Training loss: 0.43504991105274604
Validation loss: 2.744009859673263

Epoch: 5| Step: 4
Training loss: 0.4864639337722379
Validation loss: 2.770675200536703

Epoch: 5| Step: 5
Training loss: 0.4945060675357752
Validation loss: 2.8557943061988915

Epoch: 5| Step: 6
Training loss: 0.4184041295836557
Validation loss: 2.7800042044712994

Epoch: 5| Step: 7
Training loss: 0.5431437038980628
Validation loss: 2.6767859435989494

Epoch: 5| Step: 8
Training loss: 0.32682695677591744
Validation loss: 2.782911672222623

Epoch: 5| Step: 9
Training loss: 0.5948171562260292
Validation loss: 2.7055034353595957

Epoch: 5| Step: 10
Training loss: 0.57923306134894
Validation loss: 2.7641553188601278

Epoch: 5| Step: 11
Training loss: 0.5414990905602621
Validation loss: 2.8004040395342944

Epoch: 270| Step: 0
Training loss: 1.1316256389474957
Validation loss: 2.7432651123179426

Epoch: 5| Step: 1
Training loss: 0.5241578113594287
Validation loss: 2.762277988068437

Epoch: 5| Step: 2
Training loss: 0.6884903710245335
Validation loss: 2.6890741772484024

Epoch: 5| Step: 3
Training loss: 0.45622962357469593
Validation loss: 2.7700456859766627

Epoch: 5| Step: 4
Training loss: 0.5637327038465202
Validation loss: 2.777424674770991

Epoch: 5| Step: 5
Training loss: 0.5678583407753565
Validation loss: 2.7306659283477126

Epoch: 5| Step: 6
Training loss: 0.5485525559376674
Validation loss: 2.704021588143156

Epoch: 5| Step: 7
Training loss: 0.3991291363612597
Validation loss: 2.7197460308553842

Epoch: 5| Step: 8
Training loss: 0.522913969901782
Validation loss: 2.701217669367514

Epoch: 5| Step: 9
Training loss: 0.39258099075713776
Validation loss: 2.730993988934698

Epoch: 5| Step: 10
Training loss: 0.35816883767533453
Validation loss: 2.7365636513178218

Epoch: 5| Step: 11
Training loss: 0.3945892215854706
Validation loss: 2.706183322293579

Epoch: 271| Step: 0
Training loss: 0.4474046316232818
Validation loss: 2.726532863976895

Epoch: 5| Step: 1
Training loss: 0.29442835561163755
Validation loss: 2.7265402639041594

Epoch: 5| Step: 2
Training loss: 0.3370342316758677
Validation loss: 2.790517205024962

Epoch: 5| Step: 3
Training loss: 0.4781534809780053
Validation loss: 2.777576259747282

Epoch: 5| Step: 4
Training loss: 0.45797592735327824
Validation loss: 2.7343980479404393

Epoch: 5| Step: 5
Training loss: 0.4884928740622974
Validation loss: 2.6954531462457307

Epoch: 5| Step: 6
Training loss: 0.4686631440120258
Validation loss: 2.7408792177010914

Epoch: 5| Step: 7
Training loss: 0.5175855528100564
Validation loss: 2.7241390537878574

Epoch: 5| Step: 8
Training loss: 0.711957556046128
Validation loss: 2.7175335373281495

Epoch: 5| Step: 9
Training loss: 0.34015991587453
Validation loss: 2.709529877708819

Epoch: 5| Step: 10
Training loss: 0.37555907218335005
Validation loss: 2.7163297871918264

Epoch: 5| Step: 11
Training loss: 2.4794021836510223
Validation loss: 2.7311271634038374

Epoch: 272| Step: 0
Training loss: 0.407103558815225
Validation loss: 2.7256293644732015

Epoch: 5| Step: 1
Training loss: 0.5024537732796055
Validation loss: 2.695063324250966

Epoch: 5| Step: 2
Training loss: 0.6944136649834104
Validation loss: 2.7406684602360234

Epoch: 5| Step: 3
Training loss: 0.3914707945335351
Validation loss: 2.7110374754720845

Epoch: 5| Step: 4
Training loss: 0.5751443785313027
Validation loss: 2.753278252171512

Epoch: 5| Step: 5
Training loss: 0.44649425772662077
Validation loss: 2.817471927355165

Epoch: 5| Step: 6
Training loss: 1.107556800763473
Validation loss: 2.6904654849533096

Epoch: 5| Step: 7
Training loss: 0.32907976027357216
Validation loss: 2.7661648329408686

Epoch: 5| Step: 8
Training loss: 0.5883132581374632
Validation loss: 2.7155287795438525

Epoch: 5| Step: 9
Training loss: 0.4649987483264115
Validation loss: 2.7457494506314397

Epoch: 5| Step: 10
Training loss: 0.5414678012929635
Validation loss: 2.733237693051545

Epoch: 5| Step: 11
Training loss: 0.4604667425613475
Validation loss: 2.6841830958084967

Epoch: 273| Step: 0
Training loss: 0.4261717624122198
Validation loss: 2.664981176507877

Epoch: 5| Step: 1
Training loss: 0.5368195462703212
Validation loss: 2.7194035829704646

Epoch: 5| Step: 2
Training loss: 0.39133585146394917
Validation loss: 2.628807791556695

Epoch: 5| Step: 3
Training loss: 1.1184009284461756
Validation loss: 2.634908372062854

Epoch: 5| Step: 4
Training loss: 0.29608927449087474
Validation loss: 2.6497620015363683

Epoch: 5| Step: 5
Training loss: 0.4724122513172025
Validation loss: 2.6706727429422563

Epoch: 5| Step: 6
Training loss: 0.4186687490293527
Validation loss: 2.65562274108896

Epoch: 5| Step: 7
Training loss: 0.4830231722353551
Validation loss: 2.7219359413329314

Epoch: 5| Step: 8
Training loss: 0.37938773641307144
Validation loss: 2.7172947840307264

Epoch: 5| Step: 9
Training loss: 0.41134259451170835
Validation loss: 2.7458061548797237

Epoch: 5| Step: 10
Training loss: 0.6631257350029499
Validation loss: 2.7491881624402645

Epoch: 5| Step: 11
Training loss: 0.49471111311134636
Validation loss: 2.7354421004783256

Epoch: 274| Step: 0
Training loss: 0.3031707694706811
Validation loss: 2.6998094978649343

Epoch: 5| Step: 1
Training loss: 0.6107805865214158
Validation loss: 2.7026555346414325

Epoch: 5| Step: 2
Training loss: 0.4689274769814762
Validation loss: 2.6808537835880806

Epoch: 5| Step: 3
Training loss: 0.6770876126276404
Validation loss: 2.6860153621907457

Epoch: 5| Step: 4
Training loss: 0.45882994306045977
Validation loss: 2.6759519536497725

Epoch: 5| Step: 5
Training loss: 0.6973937314955985
Validation loss: 2.6440219698677048

Epoch: 5| Step: 6
Training loss: 0.4462373899767185
Validation loss: 2.7513724464172538

Epoch: 5| Step: 7
Training loss: 0.5020974986925939
Validation loss: 2.6804247361930478

Epoch: 5| Step: 8
Training loss: 1.1107214158196852
Validation loss: 2.7593902886997856

Epoch: 5| Step: 9
Training loss: 0.412795774307265
Validation loss: 2.785336613889713

Epoch: 5| Step: 10
Training loss: 0.4021541741412657
Validation loss: 2.6750962171749255

Epoch: 5| Step: 11
Training loss: 0.1839521440593072
Validation loss: 2.7646456563134523

Epoch: 275| Step: 0
Training loss: 0.4716999057519789
Validation loss: 2.7304960221296133

Epoch: 5| Step: 1
Training loss: 0.43727063229140467
Validation loss: 2.735112423233762

Epoch: 5| Step: 2
Training loss: 0.6543756921467586
Validation loss: 2.682636403025512

Epoch: 5| Step: 3
Training loss: 0.40537005272503945
Validation loss: 2.69076727602831

Epoch: 5| Step: 4
Training loss: 0.41295542357379983
Validation loss: 2.7383975060091355

Epoch: 5| Step: 5
Training loss: 0.4673569643020247
Validation loss: 2.6651148316452824

Epoch: 5| Step: 6
Training loss: 0.3881561461527536
Validation loss: 2.7538605922945254

Epoch: 5| Step: 7
Training loss: 1.1050765349348703
Validation loss: 2.8529617186247846

Epoch: 5| Step: 8
Training loss: 0.4693095364489114
Validation loss: 2.8295025675723156

Epoch: 5| Step: 9
Training loss: 0.463434423049312
Validation loss: 2.7711052271208523

Epoch: 5| Step: 10
Training loss: 0.501421873634407
Validation loss: 2.8463402084934386

Epoch: 5| Step: 11
Training loss: 0.33662877927571677
Validation loss: 2.755439893994875

Epoch: 276| Step: 0
Training loss: 0.5320492790405132
Validation loss: 2.829635108056899

Epoch: 5| Step: 1
Training loss: 0.6323823997802066
Validation loss: 2.8038394393181707

Epoch: 5| Step: 2
Training loss: 1.136659653428518
Validation loss: 2.6999618861663675

Epoch: 5| Step: 3
Training loss: 0.45739892695171386
Validation loss: 2.7855744763457757

Epoch: 5| Step: 4
Training loss: 0.3526084916071666
Validation loss: 2.671909674109024

Epoch: 5| Step: 5
Training loss: 0.44484989498330557
Validation loss: 2.7035702906410197

Epoch: 5| Step: 6
Training loss: 0.36536609090148264
Validation loss: 2.749172093294617

Epoch: 5| Step: 7
Training loss: 0.5426579141412816
Validation loss: 2.749743467705661

Epoch: 5| Step: 8
Training loss: 0.36511436571504335
Validation loss: 2.664067537782144

Epoch: 5| Step: 9
Training loss: 0.5009516957080795
Validation loss: 2.6962667241150378

Epoch: 5| Step: 10
Training loss: 0.428535564588103
Validation loss: 2.7265504437811274

Epoch: 5| Step: 11
Training loss: 0.5154787491970142
Validation loss: 2.759041527643088

Epoch: 277| Step: 0
Training loss: 0.4455312559656653
Validation loss: 2.7279483621458396

Epoch: 5| Step: 1
Training loss: 0.5355395037632786
Validation loss: 2.686086519526101

Epoch: 5| Step: 2
Training loss: 0.33945205740985746
Validation loss: 2.7496024407940047

Epoch: 5| Step: 3
Training loss: 0.5060645905986587
Validation loss: 2.7317592934557755

Epoch: 5| Step: 4
Training loss: 0.49644534350022984
Validation loss: 2.7622394457591937

Epoch: 5| Step: 5
Training loss: 0.6111591824736571
Validation loss: 2.740825539461187

Epoch: 5| Step: 6
Training loss: 0.47321340337192913
Validation loss: 2.742347864749211

Epoch: 5| Step: 7
Training loss: 0.5466850768406617
Validation loss: 2.8160153001677584

Epoch: 5| Step: 8
Training loss: 1.1218270485493718
Validation loss: 2.7673756613535674

Epoch: 5| Step: 9
Training loss: 0.5718381932405188
Validation loss: 2.8321512446797286

Epoch: 5| Step: 10
Training loss: 0.4458788232085996
Validation loss: 2.74141178588946

Epoch: 5| Step: 11
Training loss: 0.3808696452003197
Validation loss: 2.723514014938522

Epoch: 278| Step: 0
Training loss: 1.1337086257198612
Validation loss: 2.834605651241264

Epoch: 5| Step: 1
Training loss: 0.4434346878683054
Validation loss: 2.8029370348739278

Epoch: 5| Step: 2
Training loss: 0.5244565694335861
Validation loss: 2.704149537162035

Epoch: 5| Step: 3
Training loss: 0.49907209304733435
Validation loss: 2.730314167614972

Epoch: 5| Step: 4
Training loss: 0.39757125785595454
Validation loss: 2.6639502754327227

Epoch: 5| Step: 5
Training loss: 0.38123185943220095
Validation loss: 2.7223964131156833

Epoch: 5| Step: 6
Training loss: 0.6699284144491093
Validation loss: 2.750255748026137

Epoch: 5| Step: 7
Training loss: 0.34719512661541174
Validation loss: 2.705043002014196

Epoch: 5| Step: 8
Training loss: 0.4303371373633144
Validation loss: 2.7549538533903157

Epoch: 5| Step: 9
Training loss: 0.5472189775145886
Validation loss: 2.7401854442053364

Epoch: 5| Step: 10
Training loss: 0.34639984441537863
Validation loss: 2.759639225049673

Epoch: 5| Step: 11
Training loss: 0.7083827637273397
Validation loss: 2.7708285673478135

Epoch: 279| Step: 0
Training loss: 0.3734460662114681
Validation loss: 2.783194904872958

Epoch: 5| Step: 1
Training loss: 0.4717180066704619
Validation loss: 2.7121188093678175

Epoch: 5| Step: 2
Training loss: 0.29077677557780884
Validation loss: 2.773474493362071

Epoch: 5| Step: 3
Training loss: 0.5001231876255596
Validation loss: 2.7209376562447147

Epoch: 5| Step: 4
Training loss: 0.7194124568994409
Validation loss: 2.732268406609847

Epoch: 5| Step: 5
Training loss: 0.6155043478919877
Validation loss: 2.732924841579566

Epoch: 5| Step: 6
Training loss: 1.164031777200485
Validation loss: 2.743507697804954

Epoch: 5| Step: 7
Training loss: 0.36270304781009466
Validation loss: 2.7360023778415687

Epoch: 5| Step: 8
Training loss: 0.5088403423335554
Validation loss: 2.77204362828691

Epoch: 5| Step: 9
Training loss: 0.42307023875918265
Validation loss: 2.829544992999313

Epoch: 5| Step: 10
Training loss: 0.5494908577155881
Validation loss: 2.8500149468537503

Epoch: 5| Step: 11
Training loss: 0.730025417002975
Validation loss: 2.810959941809063

Epoch: 280| Step: 0
Training loss: 0.480098752477996
Validation loss: 2.741602897820362

Epoch: 5| Step: 1
Training loss: 1.2068021982875345
Validation loss: 2.7041584567771704

Epoch: 5| Step: 2
Training loss: 0.6018722034203196
Validation loss: 2.7295099120227095

Epoch: 5| Step: 3
Training loss: 0.47643856876057755
Validation loss: 2.646354013307974

Epoch: 5| Step: 4
Training loss: 0.5233305921553643
Validation loss: 2.7893801026579337

Epoch: 5| Step: 5
Training loss: 0.5259124546808179
Validation loss: 2.8388044124871685

Epoch: 5| Step: 6
Training loss: 0.43780556294120837
Validation loss: 2.7609248407315103

Epoch: 5| Step: 7
Training loss: 0.44727117210180023
Validation loss: 2.7936328765247405

Epoch: 5| Step: 8
Training loss: 0.35052673562547043
Validation loss: 2.719892009859864

Epoch: 5| Step: 9
Training loss: 0.5180919471938068
Validation loss: 2.8507827877264598

Epoch: 5| Step: 10
Training loss: 0.4798807717801192
Validation loss: 2.615678555309854

Epoch: 5| Step: 11
Training loss: 0.8329629830107288
Validation loss: 2.812397531126249

Epoch: 281| Step: 0
Training loss: 0.526063084559769
Validation loss: 2.72169332018375

Epoch: 5| Step: 1
Training loss: 0.4139336079491247
Validation loss: 2.775739149938743

Epoch: 5| Step: 2
Training loss: 0.3821571150559453
Validation loss: 2.7342564148392965

Epoch: 5| Step: 3
Training loss: 0.4619182884877873
Validation loss: 2.660103538315829

Epoch: 5| Step: 4
Training loss: 0.5677542594974971
Validation loss: 2.7543838050839464

Epoch: 5| Step: 5
Training loss: 0.45398792772900254
Validation loss: 2.676455562672567

Epoch: 5| Step: 6
Training loss: 0.4860711395390543
Validation loss: 2.6974461205280647

Epoch: 5| Step: 7
Training loss: 0.5205805514756792
Validation loss: 2.6966134695618433

Epoch: 5| Step: 8
Training loss: 0.49400047154153104
Validation loss: 2.7737158550575023

Epoch: 5| Step: 9
Training loss: 1.0925597117362082
Validation loss: 2.719315963241054

Epoch: 5| Step: 10
Training loss: 0.4118025482719079
Validation loss: 2.7364062693599207

Epoch: 5| Step: 11
Training loss: 0.6188342663190887
Validation loss: 2.7276435592562134

Epoch: 282| Step: 0
Training loss: 0.3282118409907943
Validation loss: 2.7696131239941155

Epoch: 5| Step: 1
Training loss: 0.5811426689151596
Validation loss: 2.726970438056867

Epoch: 5| Step: 2
Training loss: 0.4055146016856262
Validation loss: 2.662474590651881

Epoch: 5| Step: 3
Training loss: 0.4965585498640695
Validation loss: 2.8062360237866697

Epoch: 5| Step: 4
Training loss: 0.6507415970059369
Validation loss: 2.7032665884462146

Epoch: 5| Step: 5
Training loss: 0.5172424379425615
Validation loss: 2.709370052768718

Epoch: 5| Step: 6
Training loss: 0.4300373387204728
Validation loss: 2.751621259718646

Epoch: 5| Step: 7
Training loss: 0.38254868895615546
Validation loss: 2.714290853500879

Epoch: 5| Step: 8
Training loss: 0.29162744559248954
Validation loss: 2.7005777944641287

Epoch: 5| Step: 9
Training loss: 1.1397237483149785
Validation loss: 2.7031481306376346

Epoch: 5| Step: 10
Training loss: 0.4303817342607461
Validation loss: 2.8041306795661205

Epoch: 5| Step: 11
Training loss: 0.32107263017608695
Validation loss: 2.7497383665124357

Epoch: 283| Step: 0
Training loss: 0.4673331464242403
Validation loss: 2.785547850455348

Epoch: 5| Step: 1
Training loss: 0.4410821349249441
Validation loss: 2.8000846574678264

Epoch: 5| Step: 2
Training loss: 0.5465202816011923
Validation loss: 2.7587794697012424

Epoch: 5| Step: 3
Training loss: 0.33873351481045294
Validation loss: 2.7617222787276066

Epoch: 5| Step: 4
Training loss: 0.45776943355749006
Validation loss: 2.7146724875607253

Epoch: 5| Step: 5
Training loss: 0.700651501708183
Validation loss: 2.7702034733907923

Epoch: 5| Step: 6
Training loss: 0.3743495664729832
Validation loss: 2.677418110221779

Epoch: 5| Step: 7
Training loss: 0.385290765389101
Validation loss: 2.659777352437051

Epoch: 5| Step: 8
Training loss: 0.5704832213422701
Validation loss: 2.6884340097440997

Epoch: 5| Step: 9
Training loss: 0.43350614057853465
Validation loss: 2.6995017698738715

Epoch: 5| Step: 10
Training loss: 1.0867972503983945
Validation loss: 2.65006771945797

Epoch: 5| Step: 11
Training loss: 0.28147776970483634
Validation loss: 2.793020903271583

Epoch: 284| Step: 0
Training loss: 0.5164176166339578
Validation loss: 2.7960546451892037

Epoch: 5| Step: 1
Training loss: 0.731412716229628
Validation loss: 2.801964680500596

Epoch: 5| Step: 2
Training loss: 1.0676243570690052
Validation loss: 2.769485128903756

Epoch: 5| Step: 3
Training loss: 0.6303939519707659
Validation loss: 2.7533259977650157

Epoch: 5| Step: 4
Training loss: 0.650606274294099
Validation loss: 2.693858686144182

Epoch: 5| Step: 5
Training loss: 0.41193680969490665
Validation loss: 2.7280814413152346

Epoch: 5| Step: 6
Training loss: 0.5418192269597089
Validation loss: 2.7205691079794994

Epoch: 5| Step: 7
Training loss: 0.6504302141667287
Validation loss: 2.6693870940902427

Epoch: 5| Step: 8
Training loss: 0.526466006484859
Validation loss: 2.748218996414028

Epoch: 5| Step: 9
Training loss: 0.5094330385995818
Validation loss: 2.7017056518599585

Epoch: 5| Step: 10
Training loss: 0.505838460011193
Validation loss: 2.840590727249272

Epoch: 5| Step: 11
Training loss: 0.5676425726597606
Validation loss: 2.739829307411488

Epoch: 285| Step: 0
Training loss: 0.47781579360176046
Validation loss: 2.771078691637903

Epoch: 5| Step: 1
Training loss: 1.0680679956071881
Validation loss: 2.7112219237120656

Epoch: 5| Step: 2
Training loss: 0.5014030024683968
Validation loss: 2.696299596073033

Epoch: 5| Step: 3
Training loss: 0.5366712690781954
Validation loss: 2.7454737021590607

Epoch: 5| Step: 4
Training loss: 0.4098136379161568
Validation loss: 2.7044211718011466

Epoch: 5| Step: 5
Training loss: 0.6783483840489564
Validation loss: 2.6849561228798806

Epoch: 5| Step: 6
Training loss: 0.43517701734644054
Validation loss: 2.7653653261795768

Epoch: 5| Step: 7
Training loss: 0.40817236898540055
Validation loss: 2.736140275343641

Epoch: 5| Step: 8
Training loss: 0.4578087054671482
Validation loss: 2.764540055393052

Epoch: 5| Step: 9
Training loss: 0.4316793398518725
Validation loss: 2.790063370351859

Epoch: 5| Step: 10
Training loss: 0.3505792218683484
Validation loss: 2.7280879266877363

Epoch: 5| Step: 11
Training loss: 0.46943290556445944
Validation loss: 2.7120004268599485

Epoch: 286| Step: 0
Training loss: 0.4239119697294596
Validation loss: 2.673597513029409

Epoch: 5| Step: 1
Training loss: 0.4787357991555117
Validation loss: 2.736630350685851

Epoch: 5| Step: 2
Training loss: 0.415811282553038
Validation loss: 2.8344446111316235

Epoch: 5| Step: 3
Training loss: 0.4563061104852101
Validation loss: 2.7262682642114293

Epoch: 5| Step: 4
Training loss: 0.44099631727609906
Validation loss: 2.727538840328817

Epoch: 5| Step: 5
Training loss: 0.5995767690137085
Validation loss: 2.7848212783923625

Epoch: 5| Step: 6
Training loss: 0.4217849388065825
Validation loss: 2.761425400207445

Epoch: 5| Step: 7
Training loss: 0.4063889375934903
Validation loss: 2.748998235538435

Epoch: 5| Step: 8
Training loss: 0.41785416859661656
Validation loss: 2.746307006629729

Epoch: 5| Step: 9
Training loss: 1.070976886453554
Validation loss: 2.7152738381433377

Epoch: 5| Step: 10
Training loss: 0.4234353632010848
Validation loss: 2.800140821940424

Epoch: 5| Step: 11
Training loss: 1.0560489485767983
Validation loss: 2.803906894392179

Epoch: 287| Step: 0
Training loss: 0.3965008924830183
Validation loss: 2.7708522621502536

Epoch: 5| Step: 1
Training loss: 1.0916491359050495
Validation loss: 2.7852054643317787

Epoch: 5| Step: 2
Training loss: 0.3919557030790511
Validation loss: 2.716656083152688

Epoch: 5| Step: 3
Training loss: 0.3870648463378434
Validation loss: 2.810839784657954

Epoch: 5| Step: 4
Training loss: 0.4592384122342872
Validation loss: 2.7530141084286184

Epoch: 5| Step: 5
Training loss: 0.47020300734408865
Validation loss: 2.7699810679680463

Epoch: 5| Step: 6
Training loss: 0.4655326098749795
Validation loss: 2.75461869639825

Epoch: 5| Step: 7
Training loss: 0.6349671733436176
Validation loss: 2.8236526301745895

Epoch: 5| Step: 8
Training loss: 0.48456849571050425
Validation loss: 2.7294847591801776

Epoch: 5| Step: 9
Training loss: 0.5412238095754764
Validation loss: 2.7937368763865025

Epoch: 5| Step: 10
Training loss: 0.3543782116645183
Validation loss: 2.8177522819227083

Epoch: 5| Step: 11
Training loss: 0.48871495631018985
Validation loss: 2.7755957180254685

Epoch: 288| Step: 0
Training loss: 0.6317258853966987
Validation loss: 2.8502563376620427

Epoch: 5| Step: 1
Training loss: 0.4416939970623341
Validation loss: 2.7086938997041665

Epoch: 5| Step: 2
Training loss: 0.39918543234272175
Validation loss: 2.741348906386828

Epoch: 5| Step: 3
Training loss: 0.3440518029686967
Validation loss: 2.7903011360496714

Epoch: 5| Step: 4
Training loss: 0.4590184949813788
Validation loss: 2.7301727520136447

Epoch: 5| Step: 5
Training loss: 0.5907857837518172
Validation loss: 2.813743828425396

Epoch: 5| Step: 6
Training loss: 0.33571810544443986
Validation loss: 2.787753548658957

Epoch: 5| Step: 7
Training loss: 1.105235530124351
Validation loss: 2.9020409372596228

Epoch: 5| Step: 8
Training loss: 0.4564820764089749
Validation loss: 2.779522033992929

Epoch: 5| Step: 9
Training loss: 0.542173310679572
Validation loss: 2.7916958876167017

Epoch: 5| Step: 10
Training loss: 0.49384670034945555
Validation loss: 2.7565839226384763

Epoch: 5| Step: 11
Training loss: 0.24645054399128874
Validation loss: 2.7438878568573677

Epoch: 289| Step: 0
Training loss: 0.42363003087482565
Validation loss: 2.6963135560334877

Epoch: 5| Step: 1
Training loss: 0.5034446672228932
Validation loss: 2.7076912461163563

Epoch: 5| Step: 2
Training loss: 1.0440913527337508
Validation loss: 2.7420510043437405

Epoch: 5| Step: 3
Training loss: 0.4480953266848458
Validation loss: 2.67254324321655

Epoch: 5| Step: 4
Training loss: 0.4671786833731775
Validation loss: 2.737968234656984

Epoch: 5| Step: 5
Training loss: 0.6421001244943947
Validation loss: 2.811859047228246

Epoch: 5| Step: 6
Training loss: 0.5449607315702927
Validation loss: 2.74472286975402

Epoch: 5| Step: 7
Training loss: 0.33142566431598625
Validation loss: 2.6900188780882055

Epoch: 5| Step: 8
Training loss: 0.3758020764010318
Validation loss: 2.694531516479467

Epoch: 5| Step: 9
Training loss: 0.477217458697624
Validation loss: 2.6578417197625996

Epoch: 5| Step: 10
Training loss: 0.4317345840582266
Validation loss: 2.7240692405417444

Epoch: 5| Step: 11
Training loss: 0.6154580814611651
Validation loss: 2.730027784868707

Epoch: 290| Step: 0
Training loss: 0.6098888382699212
Validation loss: 2.7415516905073454

Epoch: 5| Step: 1
Training loss: 0.2676812272629462
Validation loss: 2.7351061470173823

Epoch: 5| Step: 2
Training loss: 0.590193310160519
Validation loss: 2.809629844306193

Epoch: 5| Step: 3
Training loss: 1.0847144615187696
Validation loss: 2.8107359793611715

Epoch: 5| Step: 4
Training loss: 0.317190657914701
Validation loss: 2.711539133025511

Epoch: 5| Step: 5
Training loss: 0.5643107092686673
Validation loss: 2.7294164711920277

Epoch: 5| Step: 6
Training loss: 0.42966147257264997
Validation loss: 2.8103570969029783

Epoch: 5| Step: 7
Training loss: 0.4493392119395709
Validation loss: 2.8071575286090797

Epoch: 5| Step: 8
Training loss: 0.44602861880954414
Validation loss: 2.756475295520469

Epoch: 5| Step: 9
Training loss: 0.4097042135907444
Validation loss: 2.7737095086040506

Epoch: 5| Step: 10
Training loss: 0.44360630368336496
Validation loss: 2.813261236380736

Epoch: 5| Step: 11
Training loss: 0.1230763596827881
Validation loss: 2.6667139352145663

Epoch: 291| Step: 0
Training loss: 0.40491129309906826
Validation loss: 2.7974188931104855

Epoch: 5| Step: 1
Training loss: 0.42949530030944433
Validation loss: 2.825212731974127

Epoch: 5| Step: 2
Training loss: 0.4836862959303942
Validation loss: 2.7182613861831144

Epoch: 5| Step: 3
Training loss: 0.405939497028751
Validation loss: 2.7214141376707617

Epoch: 5| Step: 4
Training loss: 0.49096289680104205
Validation loss: 2.767423325263027

Epoch: 5| Step: 5
Training loss: 0.27321329461691757
Validation loss: 2.776621385249388

Epoch: 5| Step: 6
Training loss: 0.3649464660734747
Validation loss: 2.724401650662693

Epoch: 5| Step: 7
Training loss: 0.5858504167058299
Validation loss: 2.7619036154449055

Epoch: 5| Step: 8
Training loss: 1.0449502245898712
Validation loss: 2.7859249578975613

Epoch: 5| Step: 9
Training loss: 0.5516113356888859
Validation loss: 2.8265084130219154

Epoch: 5| Step: 10
Training loss: 0.3680282666128437
Validation loss: 2.7775444498348096

Epoch: 5| Step: 11
Training loss: 0.5541955351181956
Validation loss: 2.7942891767645732

Epoch: 292| Step: 0
Training loss: 0.46501627693606107
Validation loss: 2.7954897584645115

Epoch: 5| Step: 1
Training loss: 0.5877244023647431
Validation loss: 2.757619431377202

Epoch: 5| Step: 2
Training loss: 0.3753343323607613
Validation loss: 2.7183590750427564

Epoch: 5| Step: 3
Training loss: 0.39449948475686814
Validation loss: 2.7042197030268675

Epoch: 5| Step: 4
Training loss: 1.014130769615166
Validation loss: 2.6771539884117166

Epoch: 5| Step: 5
Training loss: 0.42610520104414656
Validation loss: 2.7761721100258483

Epoch: 5| Step: 6
Training loss: 0.36475222172625893
Validation loss: 2.6822919543121087

Epoch: 5| Step: 7
Training loss: 0.3576024959261089
Validation loss: 2.792145585974936

Epoch: 5| Step: 8
Training loss: 0.45827889299745783
Validation loss: 2.810695920822358

Epoch: 5| Step: 9
Training loss: 0.6266995686743996
Validation loss: 2.732193219913605

Epoch: 5| Step: 10
Training loss: 0.39411774295739993
Validation loss: 2.7630746975800884

Epoch: 5| Step: 11
Training loss: 0.3606814603390765
Validation loss: 2.6890051936667723

Epoch: 293| Step: 0
Training loss: 0.4835123871870386
Validation loss: 2.6395877629348052

Epoch: 5| Step: 1
Training loss: 0.31411164264612806
Validation loss: 2.6781665834383386

Epoch: 5| Step: 2
Training loss: 0.44047459882985
Validation loss: 2.7268198396482433

Epoch: 5| Step: 3
Training loss: 0.4140209321083805
Validation loss: 2.71760749927134

Epoch: 5| Step: 4
Training loss: 0.32982253161353675
Validation loss: 2.702425099869102

Epoch: 5| Step: 5
Training loss: 0.5003552366990386
Validation loss: 2.724284192075863

Epoch: 5| Step: 6
Training loss: 1.0498946182410982
Validation loss: 2.801729764340348

Epoch: 5| Step: 7
Training loss: 0.4751357938508386
Validation loss: 2.7763407953407615

Epoch: 5| Step: 8
Training loss: 0.49832112858200023
Validation loss: 2.7357916441068952

Epoch: 5| Step: 9
Training loss: 0.5612322508420408
Validation loss: 2.7744961110700377

Epoch: 5| Step: 10
Training loss: 0.587010913544342
Validation loss: 2.6959334538148885

Epoch: 5| Step: 11
Training loss: 0.324423885943133
Validation loss: 2.7182447979875914

Epoch: 294| Step: 0
Training loss: 0.3875521532463739
Validation loss: 2.7250976343775197

Epoch: 5| Step: 1
Training loss: 0.38591878204669294
Validation loss: 2.7792787138005304

Epoch: 5| Step: 2
Training loss: 0.554226374696046
Validation loss: 2.7587926021767024

Epoch: 5| Step: 3
Training loss: 0.5010489547210013
Validation loss: 2.7431475162516343

Epoch: 5| Step: 4
Training loss: 1.0358502059221144
Validation loss: 2.826860601852514

Epoch: 5| Step: 5
Training loss: 0.5256658350882104
Validation loss: 2.8583292273407594

Epoch: 5| Step: 6
Training loss: 0.49754917484012234
Validation loss: 2.781725528512151

Epoch: 5| Step: 7
Training loss: 0.4778349414193422
Validation loss: 2.7902506978476405

Epoch: 5| Step: 8
Training loss: 0.41058011632724506
Validation loss: 2.7973782177241855

Epoch: 5| Step: 9
Training loss: 0.481911578540348
Validation loss: 2.7294337503527535

Epoch: 5| Step: 10
Training loss: 0.3515641318389319
Validation loss: 2.7033170584068413

Epoch: 5| Step: 11
Training loss: 0.4893141845389573
Validation loss: 2.706976100548852

Epoch: 295| Step: 0
Training loss: 0.40427923855115677
Validation loss: 2.7547624560144146

Epoch: 5| Step: 1
Training loss: 0.3681267231186854
Validation loss: 2.7463570654395784

Epoch: 5| Step: 2
Training loss: 0.43812499363310153
Validation loss: 2.7489437690244007

Epoch: 5| Step: 3
Training loss: 0.5037836029071616
Validation loss: 2.811280243895936

Epoch: 5| Step: 4
Training loss: 0.45082671929488893
Validation loss: 2.685588141846767

Epoch: 5| Step: 5
Training loss: 0.519274626717698
Validation loss: 2.742860586477854

Epoch: 5| Step: 6
Training loss: 0.7696907923725196
Validation loss: 2.7440913982207005

Epoch: 5| Step: 7
Training loss: 0.4261366384678735
Validation loss: 2.678517895458784

Epoch: 5| Step: 8
Training loss: 0.5145695316404625
Validation loss: 2.65983973266487

Epoch: 5| Step: 9
Training loss: 1.0964681365275355
Validation loss: 2.6138558243160084

Epoch: 5| Step: 10
Training loss: 0.27829881551609054
Validation loss: 2.7577956165809128

Epoch: 5| Step: 11
Training loss: 0.6793850192793731
Validation loss: 2.852865390031713

Epoch: 296| Step: 0
Training loss: 0.3795359383580497
Validation loss: 2.7557874850875455

Epoch: 5| Step: 1
Training loss: 0.4976968619934254
Validation loss: 2.7528790950467834

Epoch: 5| Step: 2
Training loss: 0.3600650878850331
Validation loss: 2.7578103242888976

Epoch: 5| Step: 3
Training loss: 0.5501002978859605
Validation loss: 2.7393166783354843

Epoch: 5| Step: 4
Training loss: 0.3311244812259664
Validation loss: 2.664381334424198

Epoch: 5| Step: 5
Training loss: 0.4171118464077849
Validation loss: 2.683126702309966

Epoch: 5| Step: 6
Training loss: 0.32216210292021585
Validation loss: 2.66427008900516

Epoch: 5| Step: 7
Training loss: 0.5706201011221805
Validation loss: 2.7249746171253237

Epoch: 5| Step: 8
Training loss: 0.9562968647761151
Validation loss: 2.669978693943762

Epoch: 5| Step: 9
Training loss: 0.4699976212360165
Validation loss: 2.7703699654264895

Epoch: 5| Step: 10
Training loss: 0.4635528302366436
Validation loss: 2.733398710075711

Epoch: 5| Step: 11
Training loss: 0.8272516215525528
Validation loss: 2.7158527466063656

Epoch: 297| Step: 0
Training loss: 0.5004063385663376
Validation loss: 2.763835176960901

Epoch: 5| Step: 1
Training loss: 0.382225715741529
Validation loss: 2.687091840755296

Epoch: 5| Step: 2
Training loss: 1.1089768030889684
Validation loss: 2.6860418134120376

Epoch: 5| Step: 3
Training loss: 0.335140080273095
Validation loss: 2.672656853928619

Epoch: 5| Step: 4
Training loss: 0.4285060592877284
Validation loss: 2.674432129463317

Epoch: 5| Step: 5
Training loss: 0.4443242668882862
Validation loss: 2.660082462685972

Epoch: 5| Step: 6
Training loss: 0.5806151450627638
Validation loss: 2.654657872202888

Epoch: 5| Step: 7
Training loss: 0.4372585515930345
Validation loss: 2.8446261135795967

Epoch: 5| Step: 8
Training loss: 0.538657049759308
Validation loss: 2.794295131628661

Epoch: 5| Step: 9
Training loss: 0.3775698109048242
Validation loss: 2.7328033071966393

Epoch: 5| Step: 10
Training loss: 0.4781322266774279
Validation loss: 2.7275369318411893

Epoch: 5| Step: 11
Training loss: 0.8351278573215561
Validation loss: 2.7648409146835737

Epoch: 298| Step: 0
Training loss: 0.47230360574135416
Validation loss: 2.736008067430998

Epoch: 5| Step: 1
Training loss: 0.609684938692298
Validation loss: 2.8218585942897936

Epoch: 5| Step: 2
Training loss: 0.53261908659196
Validation loss: 2.8068642523862826

Epoch: 5| Step: 3
Training loss: 0.5598882334585193
Validation loss: 2.944565162993077

Epoch: 5| Step: 4
Training loss: 0.4276262608286254
Validation loss: 2.81665959235061

Epoch: 5| Step: 5
Training loss: 0.34851061391744576
Validation loss: 2.7650101906839843

Epoch: 5| Step: 6
Training loss: 0.44714880338020513
Validation loss: 2.7186203593187983

Epoch: 5| Step: 7
Training loss: 0.576414981568058
Validation loss: 2.8036131363989516

Epoch: 5| Step: 8
Training loss: 0.664749911686668
Validation loss: 2.726067929013227

Epoch: 5| Step: 9
Training loss: 0.5314515797260582
Validation loss: 2.7166845653583995

Epoch: 5| Step: 10
Training loss: 1.0689947550745762
Validation loss: 2.774101532436638

Epoch: 5| Step: 11
Training loss: 0.35170385909619295
Validation loss: 2.8355716963313684

Epoch: 299| Step: 0
Training loss: 0.45019759634766754
Validation loss: 2.7996662674709154

Epoch: 5| Step: 1
Training loss: 0.4660523354587126
Validation loss: 2.8240852517866246

Epoch: 5| Step: 2
Training loss: 0.3154359468482691
Validation loss: 2.766331110180439

Epoch: 5| Step: 3
Training loss: 0.45774697235164513
Validation loss: 2.826179520201871

Epoch: 5| Step: 4
Training loss: 0.3928109991853702
Validation loss: 2.7089529477996166

Epoch: 5| Step: 5
Training loss: 0.5173419341502211
Validation loss: 2.793376766537089

Epoch: 5| Step: 6
Training loss: 0.608097326427254
Validation loss: 2.8665556458295924

Epoch: 5| Step: 7
Training loss: 0.7814285455767492
Validation loss: 2.7131113320074984

Epoch: 5| Step: 8
Training loss: 0.3639777490095033
Validation loss: 2.7356865090025173

Epoch: 5| Step: 9
Training loss: 0.3490553894104215
Validation loss: 2.8170108895667427

Epoch: 5| Step: 10
Training loss: 0.45330609616098416
Validation loss: 2.786087707874674

Epoch: 5| Step: 11
Training loss: 2.1998733440700513
Validation loss: 2.752948184908055

Epoch: 300| Step: 0
Training loss: 0.50655176211348
Validation loss: 2.805061276464094

Epoch: 5| Step: 1
Training loss: 0.4635231589433679
Validation loss: 2.798893670652038

Epoch: 5| Step: 2
Training loss: 0.4608411041585278
Validation loss: 2.8224818972887524

Epoch: 5| Step: 3
Training loss: 0.3846844427760447
Validation loss: 2.6996311952819214

Epoch: 5| Step: 4
Training loss: 0.5006334940824338
Validation loss: 2.7539288711520595

Epoch: 5| Step: 5
Training loss: 0.5365771344188145
Validation loss: 2.7390170630171555

Epoch: 5| Step: 6
Training loss: 0.54162546759206
Validation loss: 2.7427490724425208

Epoch: 5| Step: 7
Training loss: 0.4405165288532507
Validation loss: 2.7787737520489486

Epoch: 5| Step: 8
Training loss: 0.48480639167174455
Validation loss: 2.7503014240374895

Epoch: 5| Step: 9
Training loss: 1.0471911735777595
Validation loss: 2.7465900969210275

Epoch: 5| Step: 10
Training loss: 0.4827544575588645
Validation loss: 2.780084858841035

Epoch: 5| Step: 11
Training loss: 0.2795155609402031
Validation loss: 2.7315998490567432

Testing loss: 2.681837174237684
