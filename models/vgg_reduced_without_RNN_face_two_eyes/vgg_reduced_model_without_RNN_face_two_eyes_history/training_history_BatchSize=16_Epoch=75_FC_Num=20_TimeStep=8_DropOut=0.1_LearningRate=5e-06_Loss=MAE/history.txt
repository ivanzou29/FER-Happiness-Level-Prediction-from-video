Epoch: 1| Step: 0
Training loss: 6.342294692993164
Validation loss: 6.477086623509725

Epoch: 6| Step: 1
Training loss: 6.905127048492432
Validation loss: 6.4507096608479815

Epoch: 6| Step: 2
Training loss: 7.999534606933594
Validation loss: 6.427798430124919

Epoch: 6| Step: 3
Training loss: 6.455226421356201
Validation loss: 6.400954167048137

Epoch: 6| Step: 4
Training loss: 6.933778285980225
Validation loss: 6.375196536382039

Epoch: 6| Step: 5
Training loss: 6.213984966278076
Validation loss: 6.351224501927693

Epoch: 6| Step: 6
Training loss: 6.759824752807617
Validation loss: 6.324236790339152

Epoch: 6| Step: 7
Training loss: 5.794029235839844
Validation loss: 6.2980531056722

Epoch: 6| Step: 8
Training loss: 4.978128433227539
Validation loss: 6.2691545486450195

Epoch: 6| Step: 9
Training loss: 5.245035171508789
Validation loss: 6.240635236104329

Epoch: 6| Step: 10
Training loss: 6.544082164764404
Validation loss: 6.214839935302734

Epoch: 6| Step: 11
Training loss: 5.811243057250977
Validation loss: 6.188000917434692

Epoch: 6| Step: 12
Training loss: 6.3856306076049805
Validation loss: 6.155333121617635

Epoch: 6| Step: 13
Training loss: 6.860445976257324
Validation loss: 6.126908461252849

Epoch: 2| Step: 0
Training loss: 6.10098123550415
Validation loss: 6.095581769943237

Epoch: 6| Step: 1
Training loss: 5.603054523468018
Validation loss: 6.0661461353302

Epoch: 6| Step: 2
Training loss: 6.117739200592041
Validation loss: 6.0302734375

Epoch: 6| Step: 3
Training loss: 6.092299461364746
Validation loss: 5.994818449020386

Epoch: 6| Step: 4
Training loss: 6.232444763183594
Validation loss: 5.961675484975179

Epoch: 6| Step: 5
Training loss: 6.322160243988037
Validation loss: 5.925992647806804

Epoch: 6| Step: 6
Training loss: 7.064824104309082
Validation loss: 5.882581313451131

Epoch: 6| Step: 7
Training loss: 6.0695977210998535
Validation loss: 5.848330656687419

Epoch: 6| Step: 8
Training loss: 5.123251914978027
Validation loss: 5.80728022257487

Epoch: 6| Step: 9
Training loss: 4.809377193450928
Validation loss: 5.767138957977295

Epoch: 6| Step: 10
Training loss: 6.550906181335449
Validation loss: 5.720196564992269

Epoch: 6| Step: 11
Training loss: 5.758419036865234
Validation loss: 5.678061405817668

Epoch: 6| Step: 12
Training loss: 5.422746658325195
Validation loss: 5.6333803335825605

Epoch: 6| Step: 13
Training loss: 5.568508625030518
Validation loss: 5.57942549387614

Epoch: 3| Step: 0
Training loss: 6.49407434463501
Validation loss: 5.525608936945598

Epoch: 6| Step: 1
Training loss: 4.9275803565979
Validation loss: 5.472209533055623

Epoch: 6| Step: 2
Training loss: 4.776362895965576
Validation loss: 5.41254997253418

Epoch: 6| Step: 3
Training loss: 5.2407145500183105
Validation loss: 5.3455400466918945

Epoch: 6| Step: 4
Training loss: 5.963776111602783
Validation loss: 5.281676371892293

Epoch: 6| Step: 5
Training loss: 5.85816764831543
Validation loss: 5.2195658683776855

Epoch: 6| Step: 6
Training loss: 4.750690460205078
Validation loss: 5.14616584777832

Epoch: 6| Step: 7
Training loss: 5.434145927429199
Validation loss: 5.0767600536346436

Epoch: 6| Step: 8
Training loss: 4.977999687194824
Validation loss: 5.002464135487874

Epoch: 6| Step: 9
Training loss: 5.165014743804932
Validation loss: 4.915848255157471

Epoch: 6| Step: 10
Training loss: 4.776644706726074
Validation loss: 4.826692422231038

Epoch: 6| Step: 11
Training loss: 3.979167938232422
Validation loss: 4.7362139622370405

Epoch: 6| Step: 12
Training loss: 4.952606201171875
Validation loss: 4.646636565526326

Epoch: 6| Step: 13
Training loss: 4.845949172973633
Validation loss: 4.546573559443156

Epoch: 4| Step: 0
Training loss: 4.023303508758545
Validation loss: 4.443167686462402

Epoch: 6| Step: 1
Training loss: 3.9584102630615234
Validation loss: 4.356159051259358

Epoch: 6| Step: 2
Training loss: 4.751511573791504
Validation loss: 4.227554599444072

Epoch: 6| Step: 3
Training loss: 5.289081573486328
Validation loss: 4.114565372467041

Epoch: 6| Step: 4
Training loss: 4.723383903503418
Validation loss: 4.020675182342529

Epoch: 6| Step: 5
Training loss: 3.9895567893981934
Validation loss: 3.8895950317382812

Epoch: 6| Step: 6
Training loss: 4.169379234313965
Validation loss: 3.7931341330210366

Epoch: 6| Step: 7
Training loss: 3.6125378608703613
Validation loss: 3.6731720765431723

Epoch: 6| Step: 8
Training loss: 3.6282148361206055
Validation loss: 3.5761566162109375

Epoch: 6| Step: 9
Training loss: 3.0114097595214844
Validation loss: 3.4691340128580728

Epoch: 6| Step: 10
Training loss: 3.6015219688415527
Validation loss: 3.339552640914917

Epoch: 6| Step: 11
Training loss: 3.5296993255615234
Validation loss: 3.233502507209778

Epoch: 6| Step: 12
Training loss: 2.5232009887695312
Validation loss: 3.1251365343729653

Epoch: 6| Step: 13
Training loss: 2.1749162673950195
Validation loss: 3.004142920176188

Epoch: 5| Step: 0
Training loss: 2.5555191040039062
Validation loss: 2.9046820799509683

Epoch: 6| Step: 1
Training loss: 2.8446974754333496
Validation loss: 2.797473390897115

Epoch: 6| Step: 2
Training loss: 3.248760461807251
Validation loss: 2.6988266706466675

Epoch: 6| Step: 3
Training loss: 3.465524196624756
Validation loss: 2.610080679257711

Epoch: 6| Step: 4
Training loss: 2.816983461380005
Validation loss: 2.5377303759256997

Epoch: 6| Step: 5
Training loss: 2.240065097808838
Validation loss: 2.439513603846232

Epoch: 6| Step: 6
Training loss: 2.1283721923828125
Validation loss: 2.373112360636393

Epoch: 6| Step: 7
Training loss: 1.8804835081100464
Validation loss: 2.3508736888567605

Epoch: 6| Step: 8
Training loss: 1.7052463293075562
Validation loss: 2.295103430747986

Epoch: 6| Step: 9
Training loss: 2.0479471683502197
Validation loss: 2.291443149248759

Epoch: 6| Step: 10
Training loss: 2.082637310028076
Validation loss: 2.2595603267351785

Epoch: 6| Step: 11
Training loss: 2.187906503677368
Validation loss: 2.2978272239367166

Epoch: 6| Step: 12
Training loss: 2.4590046405792236
Validation loss: 2.2542490363121033

Epoch: 6| Step: 13
Training loss: 1.4461174011230469
Validation loss: 2.2643250624338784

Epoch: 6| Step: 0
Training loss: 2.749530792236328
Validation loss: 2.290447552998861

Epoch: 6| Step: 1
Training loss: 2.17710018157959
Validation loss: 2.2480918963750205

Epoch: 6| Step: 2
Training loss: 1.7908899784088135
Validation loss: 2.2584392428398132

Epoch: 6| Step: 3
Training loss: 1.8556839227676392
Validation loss: 2.228685816129049

Epoch: 6| Step: 4
Training loss: 2.1731367111206055
Validation loss: 2.2389492988586426

Epoch: 6| Step: 5
Training loss: 2.218405246734619
Validation loss: 2.252441684405009

Epoch: 6| Step: 6
Training loss: 2.1766600608825684
Validation loss: 2.2883657813072205

Epoch: 6| Step: 7
Training loss: 1.7062137126922607
Validation loss: 2.3024639089902244

Epoch: 6| Step: 8
Training loss: 1.6977078914642334
Validation loss: 2.277881383895874

Epoch: 6| Step: 9
Training loss: 2.700747489929199
Validation loss: 2.256708105405172

Epoch: 6| Step: 10
Training loss: 2.477379322052002
Validation loss: 2.2644919753074646

Epoch: 6| Step: 11
Training loss: 2.3512156009674072
Validation loss: 2.2236921389897666

Epoch: 6| Step: 12
Training loss: 2.741652727127075
Validation loss: 2.2177740136782327

Epoch: 6| Step: 13
Training loss: 3.193294048309326
Validation loss: 2.2040419379870095

Epoch: 7| Step: 0
Training loss: 2.096942901611328
Validation loss: 2.2135106523831687

Epoch: 6| Step: 1
Training loss: 2.1134510040283203
Validation loss: 2.248957892258962

Epoch: 6| Step: 2
Training loss: 1.7001582384109497
Validation loss: 2.2310370802879333

Epoch: 6| Step: 3
Training loss: 2.1628661155700684
Validation loss: 2.216893951098124

Epoch: 6| Step: 4
Training loss: 2.0832340717315674
Validation loss: 2.254668037096659

Epoch: 6| Step: 5
Training loss: 2.5169572830200195
Validation loss: 2.2442787289619446

Epoch: 6| Step: 6
Training loss: 2.3787035942077637
Validation loss: 2.228934566179911

Epoch: 6| Step: 7
Training loss: 2.009746789932251
Validation loss: 2.2546513080596924

Epoch: 6| Step: 8
Training loss: 2.2721900939941406
Validation loss: 2.230760633945465

Epoch: 6| Step: 9
Training loss: 2.4767236709594727
Validation loss: 2.25685316324234

Epoch: 6| Step: 10
Training loss: 2.8740086555480957
Validation loss: 2.2221189538637796

Epoch: 6| Step: 11
Training loss: 2.4605777263641357
Validation loss: 2.2395787040392556

Epoch: 6| Step: 12
Training loss: 2.3005642890930176
Validation loss: 2.244273543357849

Epoch: 6| Step: 13
Training loss: 2.1013076305389404
Validation loss: 2.21498175462087

Epoch: 8| Step: 0
Training loss: 2.100897789001465
Validation loss: 2.205538193384806

Epoch: 6| Step: 1
Training loss: 2.375701665878296
Validation loss: 2.212811509768168

Epoch: 6| Step: 2
Training loss: 2.0227248668670654
Validation loss: 2.2328786849975586

Epoch: 6| Step: 3
Training loss: 2.230295419692993
Validation loss: 2.206149081389109

Epoch: 6| Step: 4
Training loss: 2.4227728843688965
Validation loss: 2.2205647428830466

Epoch: 6| Step: 5
Training loss: 2.670504331588745
Validation loss: 2.220601042111715

Epoch: 6| Step: 6
Training loss: 1.8343818187713623
Validation loss: 2.2394397854804993

Epoch: 6| Step: 7
Training loss: 2.1210100650787354
Validation loss: 2.1917902628580728

Epoch: 6| Step: 8
Training loss: 1.7515579462051392
Validation loss: 2.181909441947937

Epoch: 6| Step: 9
Training loss: 2.4191536903381348
Validation loss: 2.208205223083496

Epoch: 6| Step: 10
Training loss: 2.0903522968292236
Validation loss: 2.2071369091669717

Epoch: 6| Step: 11
Training loss: 1.924189567565918
Validation loss: 2.1887863874435425

Epoch: 6| Step: 12
Training loss: 2.2494943141937256
Validation loss: 2.2183706760406494

Epoch: 6| Step: 13
Training loss: 2.400404453277588
Validation loss: 2.173989415168762

Epoch: 9| Step: 0
Training loss: 2.4017064571380615
Validation loss: 2.1475683053334556

Epoch: 6| Step: 1
Training loss: 2.101358413696289
Validation loss: 2.1647316416104636

Epoch: 6| Step: 2
Training loss: 1.6980242729187012
Validation loss: 2.1706115007400513

Epoch: 6| Step: 3
Training loss: 1.9882961511611938
Validation loss: 2.203398605187734

Epoch: 6| Step: 4
Training loss: 2.1774537563323975
Validation loss: 2.199363648891449

Epoch: 6| Step: 5
Training loss: 2.1436898708343506
Validation loss: 2.1655052105585733

Epoch: 6| Step: 6
Training loss: 2.0194873809814453
Validation loss: 2.2057395776112876

Epoch: 6| Step: 7
Training loss: 2.3679518699645996
Validation loss: 2.1728116075197854

Epoch: 6| Step: 8
Training loss: 2.0894384384155273
Validation loss: 2.184119701385498

Epoch: 6| Step: 9
Training loss: 2.6067304611206055
Validation loss: 2.2122324109077454

Epoch: 6| Step: 10
Training loss: 1.8287938833236694
Validation loss: 2.1409472823143005

Epoch: 6| Step: 11
Training loss: 2.242183208465576
Validation loss: 2.1359675327936807

Epoch: 6| Step: 12
Training loss: 2.4610090255737305
Validation loss: 2.147058884302775

Epoch: 6| Step: 13
Training loss: 2.119297981262207
Validation loss: 2.150110125541687

Epoch: 10| Step: 0
Training loss: 2.6709766387939453
Validation loss: 2.2027896444002786

Epoch: 6| Step: 1
Training loss: 2.335465908050537
Validation loss: 2.1989125410715737

Epoch: 6| Step: 2
Training loss: 2.279646635055542
Validation loss: 2.1544967889785767

Epoch: 6| Step: 3
Training loss: 1.9230870008468628
Validation loss: 2.192331612110138

Epoch: 6| Step: 4
Training loss: 2.1259565353393555
Validation loss: 2.1536117593447366

Epoch: 6| Step: 5
Training loss: 2.3986501693725586
Validation loss: 2.1606107155481973

Epoch: 6| Step: 6
Training loss: 1.939489483833313
Validation loss: 2.181340972582499

Epoch: 6| Step: 7
Training loss: 1.8509950637817383
Validation loss: 2.1707294384638467

Epoch: 6| Step: 8
Training loss: 1.863021731376648
Validation loss: 2.1707537174224854

Epoch: 6| Step: 9
Training loss: 2.471877098083496
Validation loss: 2.154069185256958

Epoch: 6| Step: 10
Training loss: 2.0613551139831543
Validation loss: 2.1854891379674277

Epoch: 6| Step: 11
Training loss: 2.0687472820281982
Validation loss: 2.154056191444397

Epoch: 6| Step: 12
Training loss: 2.024864673614502
Validation loss: 2.17078298330307

Epoch: 6| Step: 13
Training loss: 2.2678558826446533
Validation loss: 2.1417924960454306

Epoch: 11| Step: 0
Training loss: 2.3202593326568604
Validation loss: 2.131451884905497

Epoch: 6| Step: 1
Training loss: 2.3682312965393066
Validation loss: 2.137024998664856

Epoch: 6| Step: 2
Training loss: 2.2165727615356445
Validation loss: 2.132964769999186

Epoch: 6| Step: 3
Training loss: 2.2424376010894775
Validation loss: 2.1430829763412476

Epoch: 6| Step: 4
Training loss: 1.9058116674423218
Validation loss: 2.1537577311197915

Epoch: 6| Step: 5
Training loss: 2.3889033794403076
Validation loss: 2.156103332837423

Epoch: 6| Step: 6
Training loss: 1.751986026763916
Validation loss: 2.1388779083887735

Epoch: 6| Step: 7
Training loss: 1.2569659948349
Validation loss: 2.147383471330007

Epoch: 6| Step: 8
Training loss: 2.613884925842285
Validation loss: 2.1500044663747153

Epoch: 6| Step: 9
Training loss: 2.181692123413086
Validation loss: 2.124510705471039

Epoch: 6| Step: 10
Training loss: 2.431894540786743
Validation loss: 2.126836617787679

Epoch: 6| Step: 11
Training loss: 2.3427677154541016
Validation loss: 2.1539859771728516

Epoch: 6| Step: 12
Training loss: 1.9702870845794678
Validation loss: 2.178478221098582

Epoch: 6| Step: 13
Training loss: 1.7007770538330078
Validation loss: 2.120527664820353

Epoch: 12| Step: 0
Training loss: 1.9739022254943848
Validation loss: 2.113648255666097

Epoch: 6| Step: 1
Training loss: 3.079216241836548
Validation loss: 2.1324282685915628

Epoch: 6| Step: 2
Training loss: 1.750045657157898
Validation loss: 2.1531654596328735

Epoch: 6| Step: 3
Training loss: 2.366931676864624
Validation loss: 2.1199417312939963

Epoch: 6| Step: 4
Training loss: 1.7338299751281738
Validation loss: 2.169202665487925

Epoch: 6| Step: 5
Training loss: 2.2069053649902344
Validation loss: 2.110269606113434

Epoch: 6| Step: 6
Training loss: 1.9992051124572754
Validation loss: 2.098887582619985

Epoch: 6| Step: 7
Training loss: 2.2711029052734375
Validation loss: 2.1149272521336875

Epoch: 6| Step: 8
Training loss: 2.1011507511138916
Validation loss: 2.1014235814412436

Epoch: 6| Step: 9
Training loss: 1.9512193202972412
Validation loss: 2.076954940954844

Epoch: 6| Step: 10
Training loss: 2.025543212890625
Validation loss: 2.149273951848348

Epoch: 6| Step: 11
Training loss: 1.7189812660217285
Validation loss: 2.154650608698527

Epoch: 6| Step: 12
Training loss: 2.024942398071289
Validation loss: 2.104126294453939

Epoch: 6| Step: 13
Training loss: 1.9822776317596436
Validation loss: 2.095839182535807

Epoch: 13| Step: 0
Training loss: 1.723195195198059
Validation loss: 2.1445369521776834

Epoch: 6| Step: 1
Training loss: 2.374936580657959
Validation loss: 2.1314249436060586

Epoch: 6| Step: 2
Training loss: 2.2109005451202393
Validation loss: 2.1017908453941345

Epoch: 6| Step: 3
Training loss: 1.50547194480896
Validation loss: 2.1143935521443686

Epoch: 6| Step: 4
Training loss: 2.3519744873046875
Validation loss: 2.0713016589482627

Epoch: 6| Step: 5
Training loss: 1.9619951248168945
Validation loss: 2.104018747806549

Epoch: 6| Step: 6
Training loss: 2.078373432159424
Validation loss: 2.1524749795595803

Epoch: 6| Step: 7
Training loss: 2.01377272605896
Validation loss: 2.1328455209732056

Epoch: 6| Step: 8
Training loss: 2.0844624042510986
Validation loss: 2.078588048617045

Epoch: 6| Step: 9
Training loss: 2.1613054275512695
Validation loss: 2.111501157283783

Epoch: 6| Step: 10
Training loss: 2.697783946990967
Validation loss: 2.0977273980776467

Epoch: 6| Step: 11
Training loss: 1.8998541831970215
Validation loss: 2.1366207003593445

Epoch: 6| Step: 12
Training loss: 1.9976129531860352
Validation loss: 2.0776119232177734

Epoch: 6| Step: 13
Training loss: 2.726848602294922
Validation loss: 2.1298722624778748

Epoch: 14| Step: 0
Training loss: 2.0161526203155518
Validation loss: 2.1128579576810202

Epoch: 6| Step: 1
Training loss: 2.0918383598327637
Validation loss: 2.102916181087494

Epoch: 6| Step: 2
Training loss: 2.7013657093048096
Validation loss: 2.079400281111399

Epoch: 6| Step: 3
Training loss: 2.654938220977783
Validation loss: 2.1216596762339273

Epoch: 6| Step: 4
Training loss: 1.1136524677276611
Validation loss: 2.0891718665758767

Epoch: 6| Step: 5
Training loss: 1.8304485082626343
Validation loss: 2.094888230164846

Epoch: 6| Step: 6
Training loss: 2.2427921295166016
Validation loss: 2.0967060327529907

Epoch: 6| Step: 7
Training loss: 1.5933588743209839
Validation loss: 2.0812485615412393

Epoch: 6| Step: 8
Training loss: 2.3123393058776855
Validation loss: 2.0876675844192505

Epoch: 6| Step: 9
Training loss: 2.3885505199432373
Validation loss: 2.1333072980244956

Epoch: 6| Step: 10
Training loss: 2.2969157695770264
Validation loss: 2.0915894905726113

Epoch: 6| Step: 11
Training loss: 1.75521981716156
Validation loss: 2.0920834143956504

Epoch: 6| Step: 12
Training loss: 1.949118733406067
Validation loss: 2.0936622619628906

Epoch: 6| Step: 13
Training loss: 2.692047119140625
Validation loss: 2.0882033109664917

Epoch: 15| Step: 0
Training loss: 2.099673271179199
Validation loss: 2.1207934617996216

Epoch: 6| Step: 1
Training loss: 2.4833011627197266
Validation loss: 2.109605610370636

Epoch: 6| Step: 2
Training loss: 1.9779436588287354
Validation loss: 2.0913438399632773

Epoch: 6| Step: 3
Training loss: 2.5216028690338135
Validation loss: 2.0977482000986734

Epoch: 6| Step: 4
Training loss: 2.124232530593872
Validation loss: 2.1220978101094565

Epoch: 6| Step: 5
Training loss: 2.157278060913086
Validation loss: 2.0988179445266724

Epoch: 6| Step: 6
Training loss: 1.5722103118896484
Validation loss: 2.085515300432841

Epoch: 6| Step: 7
Training loss: 1.9152660369873047
Validation loss: 2.121778647104899

Epoch: 6| Step: 8
Training loss: 2.0582566261291504
Validation loss: 2.115365743637085

Epoch: 6| Step: 9
Training loss: 1.8302817344665527
Validation loss: 2.1519347031911216

Epoch: 6| Step: 10
Training loss: 2.0666849613189697
Validation loss: 2.0787307818730674

Epoch: 6| Step: 11
Training loss: 2.4125876426696777
Validation loss: 2.075701733430227

Epoch: 6| Step: 12
Training loss: 2.3144004344940186
Validation loss: 2.1070313851038613

Epoch: 6| Step: 13
Training loss: 1.8908138275146484
Validation loss: 2.095423956712087

Epoch: 16| Step: 0
Training loss: 1.987896203994751
Validation loss: 2.0808092753092446

Epoch: 6| Step: 1
Training loss: 1.6978132724761963
Validation loss: 2.114778677622477

Epoch: 6| Step: 2
Training loss: 2.6491928100585938
Validation loss: 2.0880242387453714

Epoch: 6| Step: 3
Training loss: 2.125495672225952
Validation loss: 2.103305677572886

Epoch: 6| Step: 4
Training loss: 2.1712589263916016
Validation loss: 2.062594254811605

Epoch: 6| Step: 5
Training loss: 1.681296706199646
Validation loss: 2.1048892537752786

Epoch: 6| Step: 6
Training loss: 1.5974807739257812
Validation loss: 2.109632670879364

Epoch: 6| Step: 7
Training loss: 2.551466226577759
Validation loss: 2.106622358163198

Epoch: 6| Step: 8
Training loss: 2.0116539001464844
Validation loss: 2.1281218926111856

Epoch: 6| Step: 9
Training loss: 2.05022931098938
Validation loss: 2.1342833638191223

Epoch: 6| Step: 10
Training loss: 1.9598418474197388
Validation loss: 2.0762534538904824

Epoch: 6| Step: 11
Training loss: 2.4759228229522705
Validation loss: 2.1043214201927185

Epoch: 6| Step: 12
Training loss: 2.5291974544525146
Validation loss: 2.116747419039408

Epoch: 6| Step: 13
Training loss: 1.6108360290527344
Validation loss: 2.087652067343394

Epoch: 17| Step: 0
Training loss: 2.2662670612335205
Validation loss: 2.084846238295237

Epoch: 6| Step: 1
Training loss: 1.628820538520813
Validation loss: 2.0734100341796875

Epoch: 6| Step: 2
Training loss: 2.428048849105835
Validation loss: 2.065871020158132

Epoch: 6| Step: 3
Training loss: 1.9820232391357422
Validation loss: 2.044267733891805

Epoch: 6| Step: 4
Training loss: 1.6770367622375488
Validation loss: 2.069624185562134

Epoch: 6| Step: 5
Training loss: 1.4675236940383911
Validation loss: 2.08154159784317

Epoch: 6| Step: 6
Training loss: 2.2855734825134277
Validation loss: 2.0907122095425925

Epoch: 6| Step: 7
Training loss: 2.3411080837249756
Validation loss: 2.1377369165420532

Epoch: 6| Step: 8
Training loss: 2.1530556678771973
Validation loss: 2.1265242298444114

Epoch: 6| Step: 9
Training loss: 2.1129562854766846
Validation loss: 2.1260737975438437

Epoch: 6| Step: 10
Training loss: 1.7941722869873047
Validation loss: 2.133187731107076

Epoch: 6| Step: 11
Training loss: 3.089733123779297
Validation loss: 2.1145049730936685

Epoch: 6| Step: 12
Training loss: 1.7420563697814941
Validation loss: 2.0881670117378235

Epoch: 6| Step: 13
Training loss: 2.540153980255127
Validation loss: 2.1209694345792136

Epoch: 18| Step: 0
Training loss: 1.8703323602676392
Validation loss: 2.1128938595453897

Epoch: 6| Step: 1
Training loss: 2.341657876968384
Validation loss: 2.0755640864372253

Epoch: 6| Step: 2
Training loss: 2.4438047409057617
Validation loss: 2.054336210091909

Epoch: 6| Step: 3
Training loss: 1.7472600936889648
Validation loss: 2.102242330710093

Epoch: 6| Step: 4
Training loss: 1.6119533777236938
Validation loss: 2.1107994516690574

Epoch: 6| Step: 5
Training loss: 2.331388473510742
Validation loss: 2.108924369017283

Epoch: 6| Step: 6
Training loss: 2.1123692989349365
Validation loss: 2.0979119340578714

Epoch: 6| Step: 7
Training loss: 1.642737865447998
Validation loss: 2.1198218862215676

Epoch: 6| Step: 8
Training loss: 2.5872201919555664
Validation loss: 2.0875725150108337

Epoch: 6| Step: 9
Training loss: 2.1043128967285156
Validation loss: 2.055664598941803

Epoch: 6| Step: 10
Training loss: 2.178553581237793
Validation loss: 2.091358164946238

Epoch: 6| Step: 11
Training loss: 2.0517985820770264
Validation loss: 2.0592702428499856

Epoch: 6| Step: 12
Training loss: 1.5978047847747803
Validation loss: 2.082450826962789

Epoch: 6| Step: 13
Training loss: 2.7740824222564697
Validation loss: 2.040545642375946

Epoch: 19| Step: 0
Training loss: 1.8546953201293945
Validation loss: 2.072339653968811

Epoch: 6| Step: 1
Training loss: 2.467521905899048
Validation loss: 2.0804561773935952

Epoch: 6| Step: 2
Training loss: 1.8503153324127197
Validation loss: 2.099937677383423

Epoch: 6| Step: 3
Training loss: 2.2408640384674072
Validation loss: 2.075539251168569

Epoch: 6| Step: 4
Training loss: 2.0292654037475586
Validation loss: 2.0880565444628396

Epoch: 6| Step: 5
Training loss: 1.6131560802459717
Validation loss: 2.0489755272865295

Epoch: 6| Step: 6
Training loss: 1.5189011096954346
Validation loss: 2.0872398018836975

Epoch: 6| Step: 7
Training loss: 2.0951457023620605
Validation loss: 2.1127415895462036

Epoch: 6| Step: 8
Training loss: 2.696545362472534
Validation loss: 2.0746292074521384

Epoch: 6| Step: 9
Training loss: 2.46476411819458
Validation loss: 2.077275296052297

Epoch: 6| Step: 10
Training loss: 2.3231258392333984
Validation loss: 2.108069817225138

Epoch: 6| Step: 11
Training loss: 2.0465431213378906
Validation loss: 2.0926296512285867

Epoch: 6| Step: 12
Training loss: 1.994621753692627
Validation loss: 2.0964763164520264

Epoch: 6| Step: 13
Training loss: 1.4789093732833862
Validation loss: 2.060102343559265

Epoch: 20| Step: 0
Training loss: 1.735327959060669
Validation loss: 2.0698854128519693

Epoch: 6| Step: 1
Training loss: 2.347846269607544
Validation loss: 2.0544132788976035

Epoch: 6| Step: 2
Training loss: 2.811675548553467
Validation loss: 2.0876351992289224

Epoch: 6| Step: 3
Training loss: 1.4477717876434326
Validation loss: 2.072431047757467

Epoch: 6| Step: 4
Training loss: 1.4897208213806152
Validation loss: 2.028650641441345

Epoch: 6| Step: 5
Training loss: 2.363908290863037
Validation loss: 2.0895802974700928

Epoch: 6| Step: 6
Training loss: 1.840717077255249
Validation loss: 2.0352958043416343

Epoch: 6| Step: 7
Training loss: 1.3940703868865967
Validation loss: 2.0541099309921265

Epoch: 6| Step: 8
Training loss: 1.9719085693359375
Validation loss: 2.0962629119555154

Epoch: 6| Step: 9
Training loss: 2.8097710609436035
Validation loss: 2.029857854048411

Epoch: 6| Step: 10
Training loss: 2.338944911956787
Validation loss: 2.117945452531179

Epoch: 6| Step: 11
Training loss: 1.4714772701263428
Validation loss: 2.0349040627479553

Epoch: 6| Step: 12
Training loss: 1.7497994899749756
Validation loss: 2.0490815838178

Epoch: 6| Step: 13
Training loss: 2.7514114379882812
Validation loss: 2.065979023774465

Epoch: 21| Step: 0
Training loss: 1.8504458665847778
Validation loss: 2.0344871481259665

Epoch: 6| Step: 1
Training loss: 2.5679893493652344
Validation loss: 2.088123937447866

Epoch: 6| Step: 2
Training loss: 1.2569599151611328
Validation loss: 2.0630817810694375

Epoch: 6| Step: 3
Training loss: 1.8888797760009766
Validation loss: 2.082339962323507

Epoch: 6| Step: 4
Training loss: 2.009396553039551
Validation loss: 2.080270747343699

Epoch: 6| Step: 5
Training loss: 2.3000717163085938
Validation loss: 2.0701164603233337

Epoch: 6| Step: 6
Training loss: 1.862055778503418
Validation loss: 2.074116865793864

Epoch: 6| Step: 7
Training loss: 2.124224901199341
Validation loss: 2.059501906236013

Epoch: 6| Step: 8
Training loss: 2.6101365089416504
Validation loss: 2.06013415257136

Epoch: 6| Step: 9
Training loss: 1.575627326965332
Validation loss: 2.0785851081212363

Epoch: 6| Step: 10
Training loss: 1.7715712785720825
Validation loss: 2.0774475733439126

Epoch: 6| Step: 11
Training loss: 2.874565601348877
Validation loss: 2.0747681856155396

Epoch: 6| Step: 12
Training loss: 1.838263750076294
Validation loss: 2.046205004056295

Epoch: 6| Step: 13
Training loss: 2.003558874130249
Validation loss: 2.0773650805155435

Epoch: 22| Step: 0
Training loss: 1.5096384286880493
Validation loss: 2.047482748826345

Epoch: 6| Step: 1
Training loss: 2.548135757446289
Validation loss: 2.065759023030599

Epoch: 6| Step: 2
Training loss: 2.2170159816741943
Validation loss: 2.0284035205841064

Epoch: 6| Step: 3
Training loss: 2.6419148445129395
Validation loss: 2.104333480199178

Epoch: 6| Step: 4
Training loss: 3.0310006141662598
Validation loss: 2.048864265282949

Epoch: 6| Step: 5
Training loss: 1.7813594341278076
Validation loss: 2.0324110984802246

Epoch: 6| Step: 6
Training loss: 1.8567428588867188
Validation loss: 2.0851808389027915

Epoch: 6| Step: 7
Training loss: 2.2989141941070557
Validation loss: 2.057934363683065

Epoch: 6| Step: 8
Training loss: 1.5224037170410156
Validation loss: 2.0571917295455933

Epoch: 6| Step: 9
Training loss: 1.5420479774475098
Validation loss: 2.0858944257100425

Epoch: 6| Step: 10
Training loss: 2.45184326171875
Validation loss: 2.104763845602671

Epoch: 6| Step: 11
Training loss: 1.6168185472488403
Validation loss: 2.080291748046875

Epoch: 6| Step: 12
Training loss: 2.1204094886779785
Validation loss: 2.0757670601209006

Epoch: 6| Step: 13
Training loss: 1.708371639251709
Validation loss: 2.115878959496816

Epoch: 23| Step: 0
Training loss: 2.15321946144104
Validation loss: 2.086699346701304

Epoch: 6| Step: 1
Training loss: 1.8221043348312378
Validation loss: 2.0927117268244424

Epoch: 6| Step: 2
Training loss: 2.21354341506958
Validation loss: 2.0759594241778054

Epoch: 6| Step: 3
Training loss: 1.72842538356781
Validation loss: 2.0524197816848755

Epoch: 6| Step: 4
Training loss: 1.7086617946624756
Validation loss: 2.06939826409022

Epoch: 6| Step: 5
Training loss: 1.7141120433807373
Validation loss: 2.062274714310964

Epoch: 6| Step: 6
Training loss: 2.1461997032165527
Validation loss: 2.1107556025187173

Epoch: 6| Step: 7
Training loss: 2.7080745697021484
Validation loss: 2.061503787835439

Epoch: 6| Step: 8
Training loss: 2.1877119541168213
Validation loss: 2.0444429914156594

Epoch: 6| Step: 9
Training loss: 2.3734912872314453
Validation loss: 2.064480106035868

Epoch: 6| Step: 10
Training loss: 1.541212797164917
Validation loss: 2.0207048853238425

Epoch: 6| Step: 11
Training loss: 1.7948005199432373
Validation loss: 2.0800029635429382

Epoch: 6| Step: 12
Training loss: 2.034797430038452
Validation loss: 2.0390137831370034

Epoch: 6| Step: 13
Training loss: 2.268507957458496
Validation loss: 2.068944752216339

Epoch: 24| Step: 0
Training loss: 2.1490330696105957
Validation loss: 2.071540097395579

Epoch: 6| Step: 1
Training loss: 2.048374891281128
Validation loss: 2.08323868115743

Epoch: 6| Step: 2
Training loss: 2.2496132850646973
Validation loss: 2.022033234437307

Epoch: 6| Step: 3
Training loss: 1.067665457725525
Validation loss: 2.058298945426941

Epoch: 6| Step: 4
Training loss: 2.115382432937622
Validation loss: 2.0629024704297385

Epoch: 6| Step: 5
Training loss: 1.9764169454574585
Validation loss: 2.1135095357894897

Epoch: 6| Step: 6
Training loss: 3.021491765975952
Validation loss: 2.0680178801218667

Epoch: 6| Step: 7
Training loss: 1.8194559812545776
Validation loss: 2.0646501779556274

Epoch: 6| Step: 8
Training loss: 1.2974159717559814
Validation loss: 2.1070663134256997

Epoch: 6| Step: 9
Training loss: 2.353661060333252
Validation loss: 2.05256058772405

Epoch: 6| Step: 10
Training loss: 2.4890875816345215
Validation loss: 2.077877859274546

Epoch: 6| Step: 11
Training loss: 2.7315549850463867
Validation loss: 2.0958123008410134

Epoch: 6| Step: 12
Training loss: 1.4482263326644897
Validation loss: 2.0625654458999634

Epoch: 6| Step: 13
Training loss: 1.7246438264846802
Validation loss: 2.019335389137268

Epoch: 25| Step: 0
Training loss: 3.0162649154663086
Validation loss: 2.0802470048268638

Epoch: 6| Step: 1
Training loss: 1.3412489891052246
Validation loss: 2.048889676729838

Epoch: 6| Step: 2
Training loss: 1.9269696474075317
Validation loss: 2.0587783455848694

Epoch: 6| Step: 3
Training loss: 2.175403594970703
Validation loss: 2.0731341441472373

Epoch: 6| Step: 4
Training loss: 2.9023783206939697
Validation loss: 2.042224705219269

Epoch: 6| Step: 5
Training loss: 1.8946837186813354
Validation loss: 2.0196640491485596

Epoch: 6| Step: 6
Training loss: 2.3693647384643555
Validation loss: 2.0365094343821206

Epoch: 6| Step: 7
Training loss: 1.6895723342895508
Validation loss: 2.0313401222229004

Epoch: 6| Step: 8
Training loss: 1.4463874101638794
Validation loss: 2.0509331226348877

Epoch: 6| Step: 9
Training loss: 1.9022396802902222
Validation loss: 2.0321726202964783

Epoch: 6| Step: 10
Training loss: 1.7288403511047363
Validation loss: 2.0367425680160522

Epoch: 6| Step: 11
Training loss: 2.0228517055511475
Validation loss: 2.0811725656191506

Epoch: 6| Step: 12
Training loss: 1.455979585647583
Validation loss: 2.0841270287831626

Epoch: 6| Step: 13
Training loss: 2.5533413887023926
Validation loss: 2.0876934130986533

Epoch: 26| Step: 0
Training loss: 2.406994342803955
Validation loss: 2.1069793105125427

Epoch: 6| Step: 1
Training loss: 1.6339664459228516
Validation loss: 2.0609489480654397

Epoch: 6| Step: 2
Training loss: 1.8633346557617188
Validation loss: 2.035228351751963

Epoch: 6| Step: 3
Training loss: 2.3834798336029053
Validation loss: 2.0489744345347085

Epoch: 6| Step: 4
Training loss: 1.6097166538238525
Validation loss: 2.06989993651708

Epoch: 6| Step: 5
Training loss: 2.0140600204467773
Validation loss: 2.080864985783895

Epoch: 6| Step: 6
Training loss: 1.785846471786499
Validation loss: 2.072077969710032

Epoch: 6| Step: 7
Training loss: 1.5850567817687988
Validation loss: 2.072906712690989

Epoch: 6| Step: 8
Training loss: 2.0734457969665527
Validation loss: 2.0536293387413025

Epoch: 6| Step: 9
Training loss: 2.101508617401123
Validation loss: 2.046973486741384

Epoch: 6| Step: 10
Training loss: 2.3217499256134033
Validation loss: 2.0644333958625793

Epoch: 6| Step: 11
Training loss: 2.22695255279541
Validation loss: 2.080568174521128

Epoch: 6| Step: 12
Training loss: 2.0696194171905518
Validation loss: 2.0301025112469993

Epoch: 6| Step: 13
Training loss: 2.233635663986206
Validation loss: 2.054512540499369

Epoch: 27| Step: 0
Training loss: 2.7634904384613037
Validation loss: 2.0819358229637146

Epoch: 6| Step: 1
Training loss: 2.3951592445373535
Validation loss: 2.0524835189183555

Epoch: 6| Step: 2
Training loss: 1.6586389541625977
Validation loss: 2.004781107107798

Epoch: 6| Step: 3
Training loss: 1.4166643619537354
Validation loss: 2.04294361670812

Epoch: 6| Step: 4
Training loss: 1.588439702987671
Validation loss: 2.040373682975769

Epoch: 6| Step: 5
Training loss: 2.309687614440918
Validation loss: 2.012707690397898

Epoch: 6| Step: 6
Training loss: 2.1838088035583496
Validation loss: 2.0170871814092

Epoch: 6| Step: 7
Training loss: 2.2302772998809814
Validation loss: 2.0582624475161233

Epoch: 6| Step: 8
Training loss: 1.3619494438171387
Validation loss: 2.0200173060099282

Epoch: 6| Step: 9
Training loss: 1.3708961009979248
Validation loss: 2.0579697489738464

Epoch: 6| Step: 10
Training loss: 2.4997987747192383
Validation loss: 2.0545335014661155

Epoch: 6| Step: 11
Training loss: 2.009688377380371
Validation loss: 2.021502375602722

Epoch: 6| Step: 12
Training loss: 2.1071207523345947
Validation loss: 2.0639665921529136

Epoch: 6| Step: 13
Training loss: 2.132101535797119
Validation loss: 2.047451674938202

Epoch: 28| Step: 0
Training loss: 2.040870189666748
Validation loss: 2.0971996188163757

Epoch: 6| Step: 1
Training loss: 1.5006790161132812
Validation loss: 2.0941216746966043

Epoch: 6| Step: 2
Training loss: 2.103740930557251
Validation loss: 2.093834141890208

Epoch: 6| Step: 3
Training loss: 3.2754368782043457
Validation loss: 2.1470910708109536

Epoch: 6| Step: 4
Training loss: 1.7222604751586914
Validation loss: 2.1328317523002625

Epoch: 6| Step: 5
Training loss: 2.1114501953125
Validation loss: 2.157224118709564

Epoch: 6| Step: 6
Training loss: 1.708823800086975
Validation loss: 2.1454330881436667

Epoch: 6| Step: 7
Training loss: 1.9108679294586182
Validation loss: 2.1175949374834695

Epoch: 6| Step: 8
Training loss: 1.6350959539413452
Validation loss: 2.1022759874661765

Epoch: 6| Step: 9
Training loss: 1.9105619192123413
Validation loss: 2.077381730079651

Epoch: 6| Step: 10
Training loss: 2.2900853157043457
Validation loss: 2.0894778966903687

Epoch: 6| Step: 11
Training loss: 1.8519184589385986
Validation loss: 2.081397831439972

Epoch: 6| Step: 12
Training loss: 2.0923948287963867
Validation loss: 2.050476610660553

Epoch: 6| Step: 13
Training loss: 2.1171889305114746
Validation loss: 2.0514604846636453

Epoch: 29| Step: 0
Training loss: 1.7654426097869873
Validation loss: 2.0948463877042136

Epoch: 6| Step: 1
Training loss: 2.6520347595214844
Validation loss: 2.0447970231374106

Epoch: 6| Step: 2
Training loss: 2.2652459144592285
Validation loss: 2.0568886399269104

Epoch: 6| Step: 3
Training loss: 1.8337409496307373
Validation loss: 2.0755889614423118

Epoch: 6| Step: 4
Training loss: 2.091710329055786
Validation loss: 2.0596313079198203

Epoch: 6| Step: 5
Training loss: 1.5397264957427979
Validation loss: 2.0754753152529397

Epoch: 6| Step: 6
Training loss: 2.4293417930603027
Validation loss: 2.092844287554423

Epoch: 6| Step: 7
Training loss: 2.5081849098205566
Validation loss: 2.066260496775309

Epoch: 6| Step: 8
Training loss: 2.2068631649017334
Validation loss: 2.098193864027659

Epoch: 6| Step: 9
Training loss: 2.3644847869873047
Validation loss: 2.056183139483134

Epoch: 6| Step: 10
Training loss: 2.0235342979431152
Validation loss: 2.0372373263041177

Epoch: 6| Step: 11
Training loss: 1.82626473903656
Validation loss: 2.0490914384524026

Epoch: 6| Step: 12
Training loss: 1.579184651374817
Validation loss: 2.0489573876063027

Epoch: 6| Step: 13
Training loss: 1.9327659606933594
Validation loss: 2.0174708167711892

Epoch: 30| Step: 0
Training loss: 1.7335824966430664
Validation loss: 2.028572062651316

Epoch: 6| Step: 1
Training loss: 1.857290506362915
Validation loss: 2.053840935230255

Epoch: 6| Step: 2
Training loss: 1.7943408489227295
Validation loss: 2.0651513735453286

Epoch: 6| Step: 3
Training loss: 1.997768759727478
Validation loss: 2.1443857749303183

Epoch: 6| Step: 4
Training loss: 1.6366701126098633
Validation loss: 2.1147331595420837

Epoch: 6| Step: 5
Training loss: 2.3147048950195312
Validation loss: 2.1358919938405356

Epoch: 6| Step: 6
Training loss: 1.6486854553222656
Validation loss: 2.1884745558102927

Epoch: 6| Step: 7
Training loss: 1.9732162952423096
Validation loss: 2.145657539367676

Epoch: 6| Step: 8
Training loss: 2.293972969055176
Validation loss: 2.16630748907725

Epoch: 6| Step: 9
Training loss: 2.441682815551758
Validation loss: 2.1306440234184265

Epoch: 6| Step: 10
Training loss: 1.6984277963638306
Validation loss: 2.110204736391703

Epoch: 6| Step: 11
Training loss: 3.0721874237060547
Validation loss: 2.1141074895858765

Epoch: 6| Step: 12
Training loss: 1.9630253314971924
Validation loss: 2.0809430480003357

Epoch: 6| Step: 13
Training loss: 1.993806004524231
Validation loss: 2.109466016292572

Epoch: 31| Step: 0
Training loss: 2.195333957672119
Validation loss: 2.0625105102856955

Epoch: 6| Step: 1
Training loss: 2.2054450511932373
Validation loss: 2.081653594970703

Epoch: 6| Step: 2
Training loss: 2.268705129623413
Validation loss: 2.0224449634552

Epoch: 6| Step: 3
Training loss: 1.6882001161575317
Validation loss: 2.0032241344451904

Epoch: 6| Step: 4
Training loss: 1.5286353826522827
Validation loss: 2.031028469403585

Epoch: 6| Step: 5
Training loss: 2.270083427429199
Validation loss: 2.0470824241638184

Epoch: 6| Step: 6
Training loss: 2.078979015350342
Validation loss: 2.034101208051046

Epoch: 6| Step: 7
Training loss: 1.777328610420227
Validation loss: 2.02711155017217

Epoch: 6| Step: 8
Training loss: 1.5359466075897217
Validation loss: 2.024831016858419

Epoch: 6| Step: 9
Training loss: 1.840285301208496
Validation loss: 2.054484009742737

Epoch: 6| Step: 10
Training loss: 2.000960350036621
Validation loss: 2.0544225772221885

Epoch: 6| Step: 11
Training loss: 2.227044105529785
Validation loss: 2.0222869515419006

Epoch: 6| Step: 12
Training loss: 1.873129963874817
Validation loss: 2.073725640773773

Epoch: 6| Step: 13
Training loss: 2.570096969604492
Validation loss: 2.060674011707306

Epoch: 32| Step: 0
Training loss: 1.6887531280517578
Validation loss: 2.0646697282791138

Epoch: 6| Step: 1
Training loss: 1.6018627882003784
Validation loss: 2.0430960655212402

Epoch: 6| Step: 2
Training loss: 1.7018202543258667
Validation loss: 2.0631446043650308

Epoch: 6| Step: 3
Training loss: 2.0774483680725098
Validation loss: 2.0693198839823403

Epoch: 6| Step: 4
Training loss: 2.4731364250183105
Validation loss: 2.0469510157903037

Epoch: 6| Step: 5
Training loss: 2.182229995727539
Validation loss: 2.0707430044809976

Epoch: 6| Step: 6
Training loss: 1.8087115287780762
Validation loss: 2.0735093355178833

Epoch: 6| Step: 7
Training loss: 2.3371524810791016
Validation loss: 2.0660526951154075

Epoch: 6| Step: 8
Training loss: 2.277340888977051
Validation loss: 2.0790582497914634

Epoch: 6| Step: 9
Training loss: 1.7856013774871826
Validation loss: 2.0557178457578025

Epoch: 6| Step: 10
Training loss: 1.8922823667526245
Validation loss: 2.055770754814148

Epoch: 6| Step: 11
Training loss: 1.9178698062896729
Validation loss: 2.076572914918264

Epoch: 6| Step: 12
Training loss: 1.8550083637237549
Validation loss: 2.0738777120908103

Epoch: 6| Step: 13
Training loss: 2.254873037338257
Validation loss: 2.021897077560425

Epoch: 33| Step: 0
Training loss: 1.7741789817810059
Validation loss: 2.0510856906572976

Epoch: 6| Step: 1
Training loss: 1.90171217918396
Validation loss: 2.0529565612475076

Epoch: 6| Step: 2
Training loss: 2.046157121658325
Validation loss: 2.0603817303975425

Epoch: 6| Step: 3
Training loss: 1.9215641021728516
Validation loss: 2.0281633138656616

Epoch: 6| Step: 4
Training loss: 2.4439520835876465
Validation loss: 2.0579872131347656

Epoch: 6| Step: 5
Training loss: 1.4521515369415283
Validation loss: 2.0290361245473227

Epoch: 6| Step: 6
Training loss: 1.8891493082046509
Validation loss: 2.039299170176188

Epoch: 6| Step: 7
Training loss: 2.3596744537353516
Validation loss: 2.0113954544067383

Epoch: 6| Step: 8
Training loss: 1.7137540578842163
Validation loss: 2.0153885881106057

Epoch: 6| Step: 9
Training loss: 1.6138572692871094
Validation loss: 2.019612888495127

Epoch: 6| Step: 10
Training loss: 2.2533395290374756
Validation loss: 2.0487616260846457

Epoch: 6| Step: 11
Training loss: 2.2406210899353027
Validation loss: 2.0398569107055664

Epoch: 6| Step: 12
Training loss: 2.0119950771331787
Validation loss: 2.0387057264645896

Epoch: 6| Step: 13
Training loss: 2.3491005897521973
Validation loss: 2.022039850552877

Epoch: 34| Step: 0
Training loss: 2.7612881660461426
Validation loss: 2.0485218167304993

Epoch: 6| Step: 1
Training loss: 2.2039713859558105
Validation loss: 2.0554272135098777

Epoch: 6| Step: 2
Training loss: 1.7919633388519287
Validation loss: 2.0912505388259888

Epoch: 6| Step: 3
Training loss: 1.747422218322754
Validation loss: 2.08051989475886

Epoch: 6| Step: 4
Training loss: 2.2172672748565674
Validation loss: 2.088137209415436

Epoch: 6| Step: 5
Training loss: 1.6832908391952515
Validation loss: 2.079025685787201

Epoch: 6| Step: 6
Training loss: 2.080747127532959
Validation loss: 2.0784728725751243

Epoch: 6| Step: 7
Training loss: 1.7067046165466309
Validation loss: 2.0968043406804404

Epoch: 6| Step: 8
Training loss: 2.5422496795654297
Validation loss: 2.0903903047243753

Epoch: 6| Step: 9
Training loss: 1.461111307144165
Validation loss: 2.0530279874801636

Epoch: 6| Step: 10
Training loss: 1.9558690786361694
Validation loss: 2.074023505051931

Epoch: 6| Step: 11
Training loss: 2.0163309574127197
Validation loss: 2.057055870691935

Epoch: 6| Step: 12
Training loss: 1.5103378295898438
Validation loss: 2.0526543855667114

Epoch: 6| Step: 13
Training loss: 1.7579922676086426
Validation loss: 2.0655229687690735

Epoch: 35| Step: 0
Training loss: 1.9092077016830444
Validation loss: 2.014096279939016

Epoch: 6| Step: 1
Training loss: 2.2455554008483887
Validation loss: 2.050826291243235

Epoch: 6| Step: 2
Training loss: 2.1815381050109863
Validation loss: 2.0048957467079163

Epoch: 6| Step: 3
Training loss: 1.7687426805496216
Validation loss: 1.9989941914876301

Epoch: 6| Step: 4
Training loss: 1.932261347770691
Validation loss: 2.0645503799120584

Epoch: 6| Step: 5
Training loss: 1.8411781787872314
Validation loss: 1.9828027288119

Epoch: 6| Step: 6
Training loss: 2.5839500427246094
Validation loss: 1.9813519914944966

Epoch: 6| Step: 7
Training loss: 1.731241226196289
Validation loss: 2.043310364087423

Epoch: 6| Step: 8
Training loss: 1.9684664011001587
Validation loss: 2.013903717199961

Epoch: 6| Step: 9
Training loss: 2.5576367378234863
Validation loss: 2.011851131916046

Epoch: 6| Step: 10
Training loss: 2.0567519664764404
Validation loss: 2.010536034901937

Epoch: 6| Step: 11
Training loss: 1.6800391674041748
Validation loss: 2.0063564777374268

Epoch: 6| Step: 12
Training loss: 1.7512458562850952
Validation loss: 2.0114819208780923

Epoch: 6| Step: 13
Training loss: 1.7297813892364502
Validation loss: 2.0204007228215537

Epoch: 36| Step: 0
Training loss: 1.863804817199707
Validation loss: 2.049653649330139

Epoch: 6| Step: 1
Training loss: 2.1960747241973877
Validation loss: 2.0620922247568765

Epoch: 6| Step: 2
Training loss: 2.0829782485961914
Validation loss: 2.042927006880442

Epoch: 6| Step: 3
Training loss: 2.4591002464294434
Validation loss: 2.037139336268107

Epoch: 6| Step: 4
Training loss: 2.1502327919006348
Validation loss: 2.0968567530314126

Epoch: 6| Step: 5
Training loss: 1.8010706901550293
Validation loss: 2.045009136199951

Epoch: 6| Step: 6
Training loss: 1.2575308084487915
Validation loss: 2.136064807573954

Epoch: 6| Step: 7
Training loss: 1.8563604354858398
Validation loss: 2.100329260031382

Epoch: 6| Step: 8
Training loss: 2.244616746902466
Validation loss: 2.095492124557495

Epoch: 6| Step: 9
Training loss: 1.996762990951538
Validation loss: 2.1038154562314353

Epoch: 6| Step: 10
Training loss: 2.06573224067688
Validation loss: 2.0736820499102273

Epoch: 6| Step: 11
Training loss: 2.240262746810913
Validation loss: 2.077489117781321

Epoch: 6| Step: 12
Training loss: 1.326799988746643
Validation loss: 2.0738232731819153

Epoch: 6| Step: 13
Training loss: 2.096956968307495
Validation loss: 2.0519263545672097

Epoch: 37| Step: 0
Training loss: 2.0639684200286865
Validation loss: 2.0212793350219727

Epoch: 6| Step: 1
Training loss: 2.6075520515441895
Validation loss: 2.047045111656189

Epoch: 6| Step: 2
Training loss: 1.993819236755371
Validation loss: 2.029618422190348

Epoch: 6| Step: 3
Training loss: 2.2634902000427246
Validation loss: 2.015825569629669

Epoch: 6| Step: 4
Training loss: 1.4624965190887451
Validation loss: 2.0559755762418113

Epoch: 6| Step: 5
Training loss: 1.2628545761108398
Validation loss: 2.0250136852264404

Epoch: 6| Step: 6
Training loss: 2.1711649894714355
Validation loss: 2.010344167550405

Epoch: 6| Step: 7
Training loss: 2.5555152893066406
Validation loss: 1.9924618601799011

Epoch: 6| Step: 8
Training loss: 2.5428268909454346
Validation loss: 2.0313026110331216

Epoch: 6| Step: 9
Training loss: 1.247658133506775
Validation loss: 2.041189690430959

Epoch: 6| Step: 10
Training loss: 2.001573085784912
Validation loss: 1.989505151907603

Epoch: 6| Step: 11
Training loss: 2.1999621391296387
Validation loss: 2.000606119632721

Epoch: 6| Step: 12
Training loss: 1.2469968795776367
Validation loss: 2.05455489953359

Epoch: 6| Step: 13
Training loss: 1.8368444442749023
Validation loss: 2.0008280674616494

Epoch: 38| Step: 0
Training loss: 3.0396459102630615
Validation loss: 2.022846241792043

Epoch: 6| Step: 1
Training loss: 1.5849173069000244
Validation loss: 2.0271644393603006

Epoch: 6| Step: 2
Training loss: 1.7483725547790527
Validation loss: 2.0376282135645547

Epoch: 6| Step: 3
Training loss: 2.706447124481201
Validation loss: 2.031067887941996

Epoch: 6| Step: 4
Training loss: 2.1738977432250977
Validation loss: 2.0041635433832803

Epoch: 6| Step: 5
Training loss: 2.001596450805664
Validation loss: 2.0125483870506287

Epoch: 6| Step: 6
Training loss: 1.8394858837127686
Validation loss: 2.0494744777679443

Epoch: 6| Step: 7
Training loss: 1.6300832033157349
Validation loss: 2.029689530531565

Epoch: 6| Step: 8
Training loss: 1.4956257343292236
Validation loss: 2.0376229286193848

Epoch: 6| Step: 9
Training loss: 1.6579926013946533
Validation loss: 2.0491918524106345

Epoch: 6| Step: 10
Training loss: 2.4969658851623535
Validation loss: 2.0344931284586587

Epoch: 6| Step: 11
Training loss: 1.3936254978179932
Validation loss: 2.039627651373545

Epoch: 6| Step: 12
Training loss: 1.7153888940811157
Validation loss: 2.0206072529157004

Epoch: 6| Step: 13
Training loss: 1.8620426654815674
Validation loss: 2.0873270829518638

Epoch: 39| Step: 0
Training loss: 2.1855742931365967
Validation loss: 2.0566739042599997

Epoch: 6| Step: 1
Training loss: 2.330658435821533
Validation loss: 2.0434961318969727

Epoch: 6| Step: 2
Training loss: 1.4803454875946045
Validation loss: 2.0401195883750916

Epoch: 6| Step: 3
Training loss: 1.7312902212142944
Validation loss: 2.0726539492607117

Epoch: 6| Step: 4
Training loss: 1.7807115316390991
Validation loss: 2.0256104469299316

Epoch: 6| Step: 5
Training loss: 2.411522388458252
Validation loss: 2.0241793394088745

Epoch: 6| Step: 6
Training loss: 2.1113121509552
Validation loss: 2.064356247584025

Epoch: 6| Step: 7
Training loss: 1.7700023651123047
Validation loss: 1.9855157136917114

Epoch: 6| Step: 8
Training loss: 2.11281156539917
Validation loss: 2.076520621776581

Epoch: 6| Step: 9
Training loss: 1.6260554790496826
Validation loss: 2.002525349458059

Epoch: 6| Step: 10
Training loss: 1.9610306024551392
Validation loss: 2.058320184548696

Epoch: 6| Step: 11
Training loss: 2.307056427001953
Validation loss: 1.9943675597508748

Epoch: 6| Step: 12
Training loss: 1.5236356258392334
Validation loss: 2.019163191318512

Epoch: 6| Step: 13
Training loss: 2.090818405151367
Validation loss: 1.9973939061164856

Epoch: 40| Step: 0
Training loss: 2.1070711612701416
Validation loss: 2.0039515495300293

Epoch: 6| Step: 1
Training loss: 2.11470890045166
Validation loss: 2.026426692803701

Epoch: 6| Step: 2
Training loss: 2.2493720054626465
Validation loss: 2.02176425854365

Epoch: 6| Step: 3
Training loss: 1.8294448852539062
Validation loss: 2.0293832619984946

Epoch: 6| Step: 4
Training loss: 1.8173677921295166
Validation loss: 2.0137204925219216

Epoch: 6| Step: 5
Training loss: 2.2523863315582275
Validation loss: 2.069426735242208

Epoch: 6| Step: 6
Training loss: 1.9058082103729248
Validation loss: 2.048954447110494

Epoch: 6| Step: 7
Training loss: 1.7642133235931396
Validation loss: 2.019782861073812

Epoch: 6| Step: 8
Training loss: 2.1464762687683105
Validation loss: 1.9928676287333171

Epoch: 6| Step: 9
Training loss: 1.8063733577728271
Validation loss: 1.995400865872701

Epoch: 6| Step: 10
Training loss: 1.9449034929275513
Validation loss: 2.0210604071617126

Epoch: 6| Step: 11
Training loss: 1.66940176486969
Validation loss: 2.0205907424290976

Epoch: 6| Step: 12
Training loss: 1.862280011177063
Validation loss: 2.0192726453145347

Epoch: 6| Step: 13
Training loss: 1.787868857383728
Validation loss: 2.0316941340764365

Epoch: 41| Step: 0
Training loss: 1.837475061416626
Validation loss: 2.104572574297587

Epoch: 6| Step: 1
Training loss: 2.1609373092651367
Validation loss: 2.0957654317220054

Epoch: 6| Step: 2
Training loss: 3.0100183486938477
Validation loss: 2.0696116288503013

Epoch: 6| Step: 3
Training loss: 2.279785633087158
Validation loss: 2.0554071068763733

Epoch: 6| Step: 4
Training loss: 1.9207457304000854
Validation loss: 2.02679580450058

Epoch: 6| Step: 5
Training loss: 1.1013075113296509
Validation loss: 2.0834766228993735

Epoch: 6| Step: 6
Training loss: 1.2651011943817139
Validation loss: 2.003520985444387

Epoch: 6| Step: 7
Training loss: 1.8760570287704468
Validation loss: 2.0533868273099265

Epoch: 6| Step: 8
Training loss: 2.03969669342041
Validation loss: 2.063017110029856

Epoch: 6| Step: 9
Training loss: 1.8946900367736816
Validation loss: 2.0458435813585916

Epoch: 6| Step: 10
Training loss: 1.4738380908966064
Validation loss: 2.0540133913358054

Epoch: 6| Step: 11
Training loss: 2.1704039573669434
Validation loss: 2.0291635394096375

Epoch: 6| Step: 12
Training loss: 2.551395893096924
Validation loss: 2.1053427259127298

Epoch: 6| Step: 13
Training loss: 1.4650163650512695
Validation loss: 2.0928277174631753

Epoch: 42| Step: 0
Training loss: 2.630915403366089
Validation loss: 2.0925958355267844

Epoch: 6| Step: 1
Training loss: 2.1690680980682373
Validation loss: 2.0621411005655923

Epoch: 6| Step: 2
Training loss: 2.2510604858398438
Validation loss: 2.028522570927938

Epoch: 6| Step: 3
Training loss: 1.9723451137542725
Validation loss: 2.046070098876953

Epoch: 6| Step: 4
Training loss: 1.956309199333191
Validation loss: 2.045510152975718

Epoch: 6| Step: 5
Training loss: 1.5978808403015137
Validation loss: 2.0406468709309897

Epoch: 6| Step: 6
Training loss: 1.603410005569458
Validation loss: 1.9936208923657734

Epoch: 6| Step: 7
Training loss: 2.108535051345825
Validation loss: 2.0233665307362876

Epoch: 6| Step: 8
Training loss: 1.6840134859085083
Validation loss: 2.0047301650047302

Epoch: 6| Step: 9
Training loss: 2.364363431930542
Validation loss: 2.0163065989812217

Epoch: 6| Step: 10
Training loss: 1.8330278396606445
Validation loss: 2.056392808755239

Epoch: 6| Step: 11
Training loss: 1.9396741390228271
Validation loss: 2.043268322944641

Epoch: 6| Step: 12
Training loss: 1.4055683612823486
Validation loss: 2.002321779727936

Epoch: 6| Step: 13
Training loss: 2.0427236557006836
Validation loss: 2.064290781815847

Epoch: 43| Step: 0
Training loss: 1.7932546138763428
Validation loss: 2.056130131085714

Epoch: 6| Step: 1
Training loss: 2.662809133529663
Validation loss: 2.064995050430298

Epoch: 6| Step: 2
Training loss: 1.3017258644104004
Validation loss: 2.0628228783607483

Epoch: 6| Step: 3
Training loss: 2.1234264373779297
Validation loss: 2.0552848974863687

Epoch: 6| Step: 4
Training loss: 1.5594956874847412
Validation loss: 2.025493939717611

Epoch: 6| Step: 5
Training loss: 2.025773763656616
Validation loss: 2.0407989025115967

Epoch: 6| Step: 6
Training loss: 2.3721909523010254
Validation loss: 2.0157606403032937

Epoch: 6| Step: 7
Training loss: 1.8247448205947876
Validation loss: 2.0659128427505493

Epoch: 6| Step: 8
Training loss: 1.4653078317642212
Validation loss: 2.0089284578959146

Epoch: 6| Step: 9
Training loss: 1.4763262271881104
Validation loss: 2.0645491083463035

Epoch: 6| Step: 10
Training loss: 1.8201260566711426
Validation loss: 2.067793846130371

Epoch: 6| Step: 11
Training loss: 2.5306291580200195
Validation loss: 2.055255194505056

Epoch: 6| Step: 12
Training loss: 1.265758752822876
Validation loss: 2.083672285079956

Epoch: 6| Step: 13
Training loss: 2.9032387733459473
Validation loss: 2.070310890674591

Epoch: 44| Step: 0
Training loss: 2.1877923011779785
Validation loss: 2.0363858938217163

Epoch: 6| Step: 1
Training loss: 2.2267603874206543
Validation loss: 2.0680497686068215

Epoch: 6| Step: 2
Training loss: 1.8994100093841553
Validation loss: 2.037694235642751

Epoch: 6| Step: 3
Training loss: 2.099297523498535
Validation loss: 2.0040653546651206

Epoch: 6| Step: 4
Training loss: 1.2304526567459106
Validation loss: 2.0032882690429688

Epoch: 6| Step: 5
Training loss: 1.8641211986541748
Validation loss: 2.0080560644467673

Epoch: 6| Step: 6
Training loss: 2.206815242767334
Validation loss: 2.021621306737264

Epoch: 6| Step: 7
Training loss: 1.0458167791366577
Validation loss: 2.00924160083135

Epoch: 6| Step: 8
Training loss: 2.4938130378723145
Validation loss: 2.0041579604148865

Epoch: 6| Step: 9
Training loss: 1.9382723569869995
Validation loss: 1.9971436063448589

Epoch: 6| Step: 10
Training loss: 2.0895347595214844
Validation loss: 2.0155407985051474

Epoch: 6| Step: 11
Training loss: 1.474008560180664
Validation loss: 1.9979647397994995

Epoch: 6| Step: 12
Training loss: 2.070652961730957
Validation loss: 2.0335363348325095

Epoch: 6| Step: 13
Training loss: 2.536341667175293
Validation loss: 2.0365721782048545

Epoch: 45| Step: 0
Training loss: 1.181692361831665
Validation loss: 2.0274911522865295

Epoch: 6| Step: 1
Training loss: 2.509262800216675
Validation loss: 2.0804226994514465

Epoch: 6| Step: 2
Training loss: 1.8830045461654663
Validation loss: 2.0334388415018716

Epoch: 6| Step: 3
Training loss: 1.6199870109558105
Validation loss: 2.0770896275838218

Epoch: 6| Step: 4
Training loss: 1.3550338745117188
Validation loss: 2.083326001962026

Epoch: 6| Step: 5
Training loss: 1.4699251651763916
Validation loss: 2.124288578828176

Epoch: 6| Step: 6
Training loss: 2.3162617683410645
Validation loss: 2.1190484166145325

Epoch: 6| Step: 7
Training loss: 2.3378243446350098
Validation loss: 2.107907215754191

Epoch: 6| Step: 8
Training loss: 2.9030721187591553
Validation loss: 2.1656383872032166

Epoch: 6| Step: 9
Training loss: 1.5566954612731934
Validation loss: 2.127805233001709

Epoch: 6| Step: 10
Training loss: 1.9855382442474365
Validation loss: 2.0794026056925454

Epoch: 6| Step: 11
Training loss: 2.0601377487182617
Validation loss: 2.077204624811808

Epoch: 6| Step: 12
Training loss: 2.2524640560150146
Validation loss: 2.021355370680491

Epoch: 6| Step: 13
Training loss: 1.8165714740753174
Validation loss: 2.0642595688501992

Epoch: 46| Step: 0
Training loss: 1.3880559206008911
Validation loss: 2.0276578466097512

Epoch: 6| Step: 1
Training loss: 1.995814561843872
Validation loss: 2.012596825758616

Epoch: 6| Step: 2
Training loss: 1.7741988897323608
Validation loss: 2.0270757476488748

Epoch: 6| Step: 3
Training loss: 1.688899278640747
Validation loss: 2.0086292028427124

Epoch: 6| Step: 4
Training loss: 2.2524473667144775
Validation loss: 2.022715071837107

Epoch: 6| Step: 5
Training loss: 2.059835910797119
Validation loss: 2.032544036706289

Epoch: 6| Step: 6
Training loss: 2.157424211502075
Validation loss: 2.0342023173967996

Epoch: 6| Step: 7
Training loss: 2.4099185466766357
Validation loss: 1.9893631140391033

Epoch: 6| Step: 8
Training loss: 2.1811137199401855
Validation loss: 2.0419766306877136

Epoch: 6| Step: 9
Training loss: 1.9144070148468018
Validation loss: 2.0016238490740457

Epoch: 6| Step: 10
Training loss: 1.6894733905792236
Validation loss: 2.0225750207901

Epoch: 6| Step: 11
Training loss: 1.9376623630523682
Validation loss: 1.9902806878089905

Epoch: 6| Step: 12
Training loss: 2.2773685455322266
Validation loss: 2.0001247326533

Epoch: 6| Step: 13
Training loss: 1.2125524282455444
Validation loss: 2.0171881914138794

Epoch: 47| Step: 0
Training loss: 1.910257339477539
Validation loss: 2.0223854581514993

Epoch: 6| Step: 1
Training loss: 1.6494568586349487
Validation loss: 2.061881979306539

Epoch: 6| Step: 2
Training loss: 2.5206103324890137
Validation loss: 2.041013260682424

Epoch: 6| Step: 3
Training loss: 1.7918920516967773
Validation loss: 2.0700791279474893

Epoch: 6| Step: 4
Training loss: 2.0235280990600586
Validation loss: 2.066912531852722

Epoch: 6| Step: 5
Training loss: 2.022918701171875
Validation loss: 2.0797305504480996

Epoch: 6| Step: 6
Training loss: 1.8944592475891113
Validation loss: 2.1162471572558084

Epoch: 6| Step: 7
Training loss: 2.445272922515869
Validation loss: 2.0981191396713257

Epoch: 6| Step: 8
Training loss: 1.8638023138046265
Validation loss: 2.154478589693705

Epoch: 6| Step: 9
Training loss: 1.6387884616851807
Validation loss: 2.0985096295674643

Epoch: 6| Step: 10
Training loss: 1.7452512979507446
Validation loss: 2.0952253341674805

Epoch: 6| Step: 11
Training loss: 1.3593778610229492
Validation loss: 2.0358266035715737

Epoch: 6| Step: 12
Training loss: 2.128232955932617
Validation loss: 2.062604010105133

Epoch: 6| Step: 13
Training loss: 1.9221994876861572
Validation loss: 2.003730515638987

Epoch: 48| Step: 0
Training loss: 1.8972690105438232
Validation loss: 2.023909409840902

Epoch: 6| Step: 1
Training loss: 1.8242201805114746
Validation loss: 1.9985949397087097

Epoch: 6| Step: 2
Training loss: 1.8051331043243408
Validation loss: 1.9989743034044902

Epoch: 6| Step: 3
Training loss: 1.327315092086792
Validation loss: 1.994647483030955

Epoch: 6| Step: 4
Training loss: 1.9402081966400146
Validation loss: 2.0323991179466248

Epoch: 6| Step: 5
Training loss: 2.5997202396392822
Validation loss: 1.9995814164479573

Epoch: 6| Step: 6
Training loss: 2.0284574031829834
Validation loss: 2.0625381469726562

Epoch: 6| Step: 7
Training loss: 1.6912908554077148
Validation loss: 2.027788837750753

Epoch: 6| Step: 8
Training loss: 2.2736308574676514
Validation loss: 2.008656998475393

Epoch: 6| Step: 9
Training loss: 1.3330618143081665
Validation loss: 2.0039446353912354

Epoch: 6| Step: 10
Training loss: 1.4517570734024048
Validation loss: 2.0087541739145913

Epoch: 6| Step: 11
Training loss: 1.9607503414154053
Validation loss: 1.9849627415339153

Epoch: 6| Step: 12
Training loss: 1.9921451807022095
Validation loss: 2.005015254020691

Epoch: 6| Step: 13
Training loss: 2.349057674407959
Validation loss: 2.0832683642705283

Epoch: 49| Step: 0
Training loss: 2.467472553253174
Validation loss: 2.0566657980283103

Epoch: 6| Step: 1
Training loss: 1.9301153421401978
Validation loss: 2.0632543762524924

Epoch: 6| Step: 2
Training loss: 2.1569314002990723
Validation loss: 2.177446722984314

Epoch: 6| Step: 3
Training loss: 1.4395074844360352
Validation loss: 2.163406252861023

Epoch: 6| Step: 4
Training loss: 2.6674671173095703
Validation loss: 2.2374447186787925

Epoch: 6| Step: 5
Training loss: 2.4713973999023438
Validation loss: 2.1978007555007935

Epoch: 6| Step: 6
Training loss: 2.0708181858062744
Validation loss: 2.141295611858368

Epoch: 6| Step: 7
Training loss: 1.8974378108978271
Validation loss: 2.152567426363627

Epoch: 6| Step: 8
Training loss: 1.4929463863372803
Validation loss: 2.1179009278615317

Epoch: 6| Step: 9
Training loss: 1.2640070915222168
Validation loss: 2.0985180536905923

Epoch: 6| Step: 10
Training loss: 1.5588688850402832
Validation loss: 2.1075769861539206

Epoch: 6| Step: 11
Training loss: 1.9440134763717651
Validation loss: 2.05541338523229

Epoch: 6| Step: 12
Training loss: 1.931208848953247
Validation loss: 2.042266607284546

Epoch: 6| Step: 13
Training loss: 1.9932692050933838
Validation loss: 2.0273733337720237

Epoch: 50| Step: 0
Training loss: 2.508845090866089
Validation loss: 1.9953816731770833

Epoch: 6| Step: 1
Training loss: 1.7450191974639893
Validation loss: 1.9976208209991455

Epoch: 6| Step: 2
Training loss: 1.3397479057312012
Validation loss: 2.012909193833669

Epoch: 6| Step: 3
Training loss: 2.0836234092712402
Validation loss: 2.034582535425822

Epoch: 6| Step: 4
Training loss: 1.9619001150131226
Validation loss: 2.03783126672109

Epoch: 6| Step: 5
Training loss: 1.4959664344787598
Validation loss: 2.0310088793436685

Epoch: 6| Step: 6
Training loss: 1.5898677110671997
Validation loss: 2.0360829830169678

Epoch: 6| Step: 7
Training loss: 1.82723867893219
Validation loss: 1.9889069000879924

Epoch: 6| Step: 8
Training loss: 1.6988458633422852
Validation loss: 2.012249211470286

Epoch: 6| Step: 9
Training loss: 2.351152181625366
Validation loss: 2.045469125111898

Epoch: 6| Step: 10
Training loss: 1.5683645009994507
Validation loss: 2.0397987961769104

Epoch: 6| Step: 11
Training loss: 2.831265449523926
Validation loss: 2.0796515941619873

Epoch: 6| Step: 12
Training loss: 1.6692721843719482
Validation loss: 2.0649897257486978

Epoch: 6| Step: 13
Training loss: 2.396963357925415
Validation loss: 2.071153183778127

Epoch: 51| Step: 0
Training loss: 2.138861656188965
Validation loss: 2.0850020249684653

Epoch: 6| Step: 1
Training loss: 1.668468952178955
Validation loss: 2.0588137110074363

Epoch: 6| Step: 2
Training loss: 2.1958587169647217
Validation loss: 2.0774019360542297

Epoch: 6| Step: 3
Training loss: 1.2690997123718262
Validation loss: 2.0873572627703347

Epoch: 6| Step: 4
Training loss: 2.13173246383667
Validation loss: 2.0535476406415305

Epoch: 6| Step: 5
Training loss: 2.3059749603271484
Validation loss: 2.07603919506073

Epoch: 6| Step: 6
Training loss: 1.6540474891662598
Validation loss: 2.0493651628494263

Epoch: 6| Step: 7
Training loss: 1.7347652912139893
Validation loss: 2.0224621097246804

Epoch: 6| Step: 8
Training loss: 1.7902324199676514
Validation loss: 2.013216257095337

Epoch: 6| Step: 9
Training loss: 1.8367689847946167
Validation loss: 2.021898011366526

Epoch: 6| Step: 10
Training loss: 1.647972822189331
Validation loss: 2.014672597249349

Epoch: 6| Step: 11
Training loss: 1.3856137990951538
Validation loss: 2.048826495806376

Epoch: 6| Step: 12
Training loss: 2.24297833442688
Validation loss: 2.030909538269043

Epoch: 6| Step: 13
Training loss: 1.953704833984375
Validation loss: 2.0109020868937173

Epoch: 52| Step: 0
Training loss: 1.5714547634124756
Validation loss: 2.0292165875434875

Epoch: 6| Step: 1
Training loss: 2.30118989944458
Validation loss: 2.028440793355306

Epoch: 6| Step: 2
Training loss: 2.380969524383545
Validation loss: 1.998181939125061

Epoch: 6| Step: 3
Training loss: 2.701169967651367
Validation loss: 2.010639031728109

Epoch: 6| Step: 4
Training loss: 1.697089672088623
Validation loss: 2.0156651735305786

Epoch: 6| Step: 5
Training loss: 1.47658109664917
Validation loss: 2.027694821357727

Epoch: 6| Step: 6
Training loss: 1.5541801452636719
Validation loss: 2.038660407066345

Epoch: 6| Step: 7
Training loss: 2.3741722106933594
Validation loss: 2.0515575210253396

Epoch: 6| Step: 8
Training loss: 1.742351770401001
Validation loss: 2.043043851852417

Epoch: 6| Step: 9
Training loss: 1.6137341260910034
Validation loss: 2.049557010332743

Epoch: 6| Step: 10
Training loss: 1.7646310329437256
Validation loss: 2.057418862978617

Epoch: 6| Step: 11
Training loss: 1.5662938356399536
Validation loss: 2.096632401148478

Epoch: 6| Step: 12
Training loss: 1.6403687000274658
Validation loss: 2.068143665790558

Epoch: 6| Step: 13
Training loss: 1.8684812784194946
Validation loss: 2.1582874854405723

Epoch: 53| Step: 0
Training loss: 1.9861912727355957
Validation loss: 2.1365453004837036

Epoch: 6| Step: 1
Training loss: 1.6462068557739258
Validation loss: 2.110062519709269

Epoch: 6| Step: 2
Training loss: 1.9685554504394531
Validation loss: 2.0988974571228027

Epoch: 6| Step: 3
Training loss: 1.4956368207931519
Validation loss: 2.097279191017151

Epoch: 6| Step: 4
Training loss: 2.1864633560180664
Validation loss: 2.1044581135114035

Epoch: 6| Step: 5
Training loss: 2.2533299922943115
Validation loss: 2.026751478513082

Epoch: 6| Step: 6
Training loss: 1.563420057296753
Validation loss: 2.026264250278473

Epoch: 6| Step: 7
Training loss: 2.0963492393493652
Validation loss: 2.029732565085093

Epoch: 6| Step: 8
Training loss: 1.9608030319213867
Validation loss: 1.9984317620595295

Epoch: 6| Step: 9
Training loss: 1.8183037042617798
Validation loss: 2.042775253454844

Epoch: 6| Step: 10
Training loss: 1.8047070503234863
Validation loss: 2.031075676282247

Epoch: 6| Step: 11
Training loss: 2.817169189453125
Validation loss: 2.002670109272003

Epoch: 6| Step: 12
Training loss: 1.5362281799316406
Validation loss: 2.0536587039629617

Epoch: 6| Step: 13
Training loss: 1.6276276111602783
Validation loss: 2.0220873753229776

Epoch: 54| Step: 0
Training loss: 2.3423895835876465
Validation loss: 2.02190633614858

Epoch: 6| Step: 1
Training loss: 2.072444200515747
Validation loss: 2.02837473154068

Epoch: 6| Step: 2
Training loss: 1.8466893434524536
Validation loss: 2.0865262150764465

Epoch: 6| Step: 3
Training loss: 1.860905408859253
Validation loss: 2.048088332017263

Epoch: 6| Step: 4
Training loss: 2.3777384757995605
Validation loss: 2.012869576613108

Epoch: 6| Step: 5
Training loss: 1.5223724842071533
Validation loss: 2.038081427415212

Epoch: 6| Step: 6
Training loss: 2.340193033218384
Validation loss: 2.046147127946218

Epoch: 6| Step: 7
Training loss: 1.8841732740402222
Validation loss: 2.0266059239705405

Epoch: 6| Step: 8
Training loss: 1.8128739595413208
Validation loss: 2.056017895539602

Epoch: 6| Step: 9
Training loss: 1.2005680799484253
Validation loss: 2.0288009643554688

Epoch: 6| Step: 10
Training loss: 1.7318024635314941
Validation loss: 2.0435460408528647

Epoch: 6| Step: 11
Training loss: 1.8509058952331543
Validation loss: 1.9643862048784893

Epoch: 6| Step: 12
Training loss: 1.931581974029541
Validation loss: 2.0290104945500693

Epoch: 6| Step: 13
Training loss: 1.9225962162017822
Validation loss: 2.0305031538009644

Epoch: 55| Step: 0
Training loss: 1.4723933935165405
Validation loss: 2.0560929775238037

Epoch: 6| Step: 1
Training loss: 2.045152187347412
Validation loss: 2.070183753967285

Epoch: 6| Step: 2
Training loss: 1.624117374420166
Validation loss: 2.045152167479197

Epoch: 6| Step: 3
Training loss: 1.9019019603729248
Validation loss: 2.0867133736610413

Epoch: 6| Step: 4
Training loss: 2.0874874591827393
Validation loss: 2.1336244344711304

Epoch: 6| Step: 5
Training loss: 2.7173657417297363
Validation loss: 2.153447608153025

Epoch: 6| Step: 6
Training loss: 1.5328240394592285
Validation loss: 2.1328267057736716

Epoch: 6| Step: 7
Training loss: 1.6058201789855957
Validation loss: 2.115671396255493

Epoch: 6| Step: 8
Training loss: 2.035837411880493
Validation loss: 2.1089072227478027

Epoch: 6| Step: 9
Training loss: 1.3722996711730957
Validation loss: 2.083773056666056

Epoch: 6| Step: 10
Training loss: 2.599529266357422
Validation loss: 2.0094199180603027

Epoch: 6| Step: 11
Training loss: 1.730414628982544
Validation loss: 1.9982107480367024

Epoch: 6| Step: 12
Training loss: 1.4782874584197998
Validation loss: 2.049279034137726

Epoch: 6| Step: 13
Training loss: 2.0141451358795166
Validation loss: 2.036230504512787

Epoch: 56| Step: 0
Training loss: 2.1011977195739746
Validation loss: 2.0132875045140586

Epoch: 6| Step: 1
Training loss: 1.9530247449874878
Validation loss: 2.011588672796885

Epoch: 6| Step: 2
Training loss: 2.2804274559020996
Validation loss: 2.0130219062169394

Epoch: 6| Step: 3
Training loss: 1.8300504684448242
Validation loss: 2.005094031492869

Epoch: 6| Step: 4
Training loss: 1.5799260139465332
Validation loss: 2.0320907632509866

Epoch: 6| Step: 5
Training loss: 1.7958757877349854
Validation loss: 2.035767833391825

Epoch: 6| Step: 6
Training loss: 1.8949997425079346
Validation loss: 2.079587399959564

Epoch: 6| Step: 7
Training loss: 1.8479032516479492
Validation loss: 2.07417223850886

Epoch: 6| Step: 8
Training loss: 2.028103828430176
Validation loss: 2.099773565928141

Epoch: 6| Step: 9
Training loss: 1.3193531036376953
Validation loss: 2.1082468231519065

Epoch: 6| Step: 10
Training loss: 1.0289862155914307
Validation loss: 2.0779600739479065

Epoch: 6| Step: 11
Training loss: 1.944527506828308
Validation loss: 2.0852206548055015

Epoch: 6| Step: 12
Training loss: 1.8807611465454102
Validation loss: 2.099761962890625

Epoch: 6| Step: 13
Training loss: 2.1098499298095703
Validation loss: 2.079339027404785

Epoch: 57| Step: 0
Training loss: 1.5130239725112915
Validation loss: 2.00821590423584

Epoch: 6| Step: 1
Training loss: 2.1807892322540283
Validation loss: 2.002958834171295

Epoch: 6| Step: 2
Training loss: 1.8222999572753906
Validation loss: 2.0324612855911255

Epoch: 6| Step: 3
Training loss: 1.7802157402038574
Validation loss: 1.9704349438349407

Epoch: 6| Step: 4
Training loss: 1.9744539260864258
Validation loss: 2.027708411216736

Epoch: 6| Step: 5
Training loss: 1.6156879663467407
Validation loss: 1.9778825243314107

Epoch: 6| Step: 6
Training loss: 2.346619129180908
Validation loss: 2.0337186257044473

Epoch: 6| Step: 7
Training loss: 2.2666358947753906
Validation loss: 1.963398516178131

Epoch: 6| Step: 8
Training loss: 1.424659252166748
Validation loss: 2.02048130830129

Epoch: 6| Step: 9
Training loss: 1.6140055656433105
Validation loss: 1.9998987913131714

Epoch: 6| Step: 10
Training loss: 2.011495351791382
Validation loss: 2.0133959452311196

Epoch: 6| Step: 11
Training loss: 1.6082992553710938
Validation loss: 2.0245267152786255

Epoch: 6| Step: 12
Training loss: 1.938797116279602
Validation loss: 2.031044284502665

Epoch: 6| Step: 13
Training loss: 2.078303337097168
Validation loss: 1.9695321520169575

Epoch: 58| Step: 0
Training loss: 1.9317578077316284
Validation loss: 2.0012581944465637

Epoch: 6| Step: 1
Training loss: 1.9221454858779907
Validation loss: 1.9962597091992695

Epoch: 6| Step: 2
Training loss: 2.0573720932006836
Validation loss: 2.038011988004049

Epoch: 6| Step: 3
Training loss: 1.5734364986419678
Validation loss: 2.108584463596344

Epoch: 6| Step: 4
Training loss: 1.938896894454956
Validation loss: 2.083303948243459

Epoch: 6| Step: 5
Training loss: 2.111029624938965
Validation loss: 2.0982195337613425

Epoch: 6| Step: 6
Training loss: 1.532973289489746
Validation loss: 2.086871067682902

Epoch: 6| Step: 7
Training loss: 2.1845972537994385
Validation loss: 2.1429309844970703

Epoch: 6| Step: 8
Training loss: 1.8133950233459473
Validation loss: 2.0822413762410483

Epoch: 6| Step: 9
Training loss: 1.611922264099121
Validation loss: 2.1200754245122275

Epoch: 6| Step: 10
Training loss: 2.20624041557312
Validation loss: 2.079389810562134

Epoch: 6| Step: 11
Training loss: 1.7763581275939941
Validation loss: 2.041034698486328

Epoch: 6| Step: 12
Training loss: 1.6676545143127441
Validation loss: 2.0368322928746543

Epoch: 6| Step: 13
Training loss: 1.5366758108139038
Validation loss: 2.034234861532847

Epoch: 59| Step: 0
Training loss: 1.8325477838516235
Validation loss: 2.0098033944765725

Epoch: 6| Step: 1
Training loss: 1.7214295864105225
Validation loss: 2.074591636657715

Epoch: 6| Step: 2
Training loss: 1.4831321239471436
Validation loss: 2.0386502146720886

Epoch: 6| Step: 3
Training loss: 1.747952938079834
Validation loss: 2.0295704007148743

Epoch: 6| Step: 4
Training loss: 1.8349292278289795
Validation loss: 1.997903843720754

Epoch: 6| Step: 5
Training loss: 1.835839867591858
Validation loss: 2.0376028418540955

Epoch: 6| Step: 6
Training loss: 2.3833727836608887
Validation loss: 2.038353979587555

Epoch: 6| Step: 7
Training loss: 2.193667411804199
Validation loss: 2.0192193190256753

Epoch: 6| Step: 8
Training loss: 1.842367172241211
Validation loss: 2.0528794328371682

Epoch: 6| Step: 9
Training loss: 1.4387836456298828
Validation loss: 2.019826114177704

Epoch: 6| Step: 10
Training loss: 1.699878215789795
Validation loss: 2.0712533990542092

Epoch: 6| Step: 11
Training loss: 1.4738932847976685
Validation loss: 2.04748797416687

Epoch: 6| Step: 12
Training loss: 2.1837635040283203
Validation loss: 2.077536424001058

Epoch: 6| Step: 13
Training loss: 1.8495738506317139
Validation loss: 2.0696097016334534

Epoch: 60| Step: 0
Training loss: 2.838589906692505
Validation loss: 2.0479343930880227

Epoch: 6| Step: 1
Training loss: 1.468252420425415
Validation loss: 2.0619622071584067

Epoch: 6| Step: 2
Training loss: 2.0756452083587646
Validation loss: 2.008466641108195

Epoch: 6| Step: 3
Training loss: 1.5293833017349243
Validation loss: 2.0481437047322593

Epoch: 6| Step: 4
Training loss: 1.3975484371185303
Validation loss: 2.0532661080360413

Epoch: 6| Step: 5
Training loss: 2.1353964805603027
Validation loss: 2.055830637613932

Epoch: 6| Step: 6
Training loss: 1.6364467144012451
Validation loss: 2.0566159884134927

Epoch: 6| Step: 7
Training loss: 1.1779844760894775
Validation loss: 2.077802817026774

Epoch: 6| Step: 8
Training loss: 1.8088620901107788
Validation loss: 2.059198796749115

Epoch: 6| Step: 9
Training loss: 1.8027653694152832
Validation loss: 2.0619752009709678

Epoch: 6| Step: 10
Training loss: 1.5786809921264648
Validation loss: 2.0446293155352273

Epoch: 6| Step: 11
Training loss: 1.8705793619155884
Validation loss: 2.0907891392707825

Epoch: 6| Step: 12
Training loss: 1.6712062358856201
Validation loss: 2.0683342814445496

Epoch: 6| Step: 13
Training loss: 2.393819808959961
Validation loss: 2.0849497318267822

Epoch: 61| Step: 0
Training loss: 1.5524625778198242
Validation loss: 2.0186701019605002

Epoch: 6| Step: 1
Training loss: 1.6286544799804688
Validation loss: 2.017420212427775

Epoch: 6| Step: 2
Training loss: 1.8609517812728882
Validation loss: 1.998472770055135

Epoch: 6| Step: 3
Training loss: 1.7634615898132324
Validation loss: 1.9585269490877788

Epoch: 6| Step: 4
Training loss: 1.363331913948059
Validation loss: 2.004869282245636

Epoch: 6| Step: 5
Training loss: 1.407787561416626
Validation loss: 2.0374593138694763

Epoch: 6| Step: 6
Training loss: 1.9690150022506714
Validation loss: 2.00226624806722

Epoch: 6| Step: 7
Training loss: 2.321357488632202
Validation loss: 1.988179584344228

Epoch: 6| Step: 8
Training loss: 1.9543070793151855
Validation loss: 2.0337822437286377

Epoch: 6| Step: 9
Training loss: 1.5880513191223145
Validation loss: 1.9893987973531086

Epoch: 6| Step: 10
Training loss: 2.1529641151428223
Validation loss: 2.033474564552307

Epoch: 6| Step: 11
Training loss: 1.817873239517212
Validation loss: 2.0291191935539246

Epoch: 6| Step: 12
Training loss: 2.2475037574768066
Validation loss: 2.0604702631632485

Epoch: 6| Step: 13
Training loss: 1.870248794555664
Validation loss: 2.086437483628591

Epoch: 62| Step: 0
Training loss: 1.5982165336608887
Validation loss: 2.10112992922465

Epoch: 6| Step: 1
Training loss: 2.1442081928253174
Validation loss: 2.147295117378235

Epoch: 6| Step: 2
Training loss: 2.8499598503112793
Validation loss: 2.1840186516443887

Epoch: 6| Step: 3
Training loss: 2.2618865966796875
Validation loss: 2.126083413759867

Epoch: 6| Step: 4
Training loss: 2.0876545906066895
Validation loss: 2.126193106174469

Epoch: 6| Step: 5
Training loss: 1.6703147888183594
Validation loss: 2.115617275238037

Epoch: 6| Step: 6
Training loss: 1.4810469150543213
Validation loss: 2.046126127243042

Epoch: 6| Step: 7
Training loss: 1.7691582441329956
Validation loss: 2.003164450327555

Epoch: 6| Step: 8
Training loss: 1.4567358493804932
Validation loss: 2.0340506633122764

Epoch: 6| Step: 9
Training loss: 1.7840837240219116
Validation loss: 2.0094555219014487

Epoch: 6| Step: 10
Training loss: 1.6385473012924194
Validation loss: 2.0188772678375244

Epoch: 6| Step: 11
Training loss: 1.9247764348983765
Validation loss: 2.003483692804972

Epoch: 6| Step: 12
Training loss: 1.9742262363433838
Validation loss: 1.94944429397583

Epoch: 6| Step: 13
Training loss: 1.6160821914672852
Validation loss: 2.009546081225077

Epoch: 63| Step: 0
Training loss: 1.8218293190002441
Validation loss: 2.021634558836619

Epoch: 6| Step: 1
Training loss: 1.3070545196533203
Validation loss: 2.047565758228302

Epoch: 6| Step: 2
Training loss: 2.103705644607544
Validation loss: 2.072918434937795

Epoch: 6| Step: 3
Training loss: 1.2749955654144287
Validation loss: 2.0150057474772134

Epoch: 6| Step: 4
Training loss: 2.031489849090576
Validation loss: 2.038984696070353

Epoch: 6| Step: 5
Training loss: 1.6677165031433105
Validation loss: 2.0707329312960305

Epoch: 6| Step: 6
Training loss: 1.9110311269760132
Validation loss: 2.124150534470876

Epoch: 6| Step: 7
Training loss: 2.1201233863830566
Validation loss: 2.0961802999178567

Epoch: 6| Step: 8
Training loss: 1.5254805088043213
Validation loss: 2.082870066165924

Epoch: 6| Step: 9
Training loss: 1.6973204612731934
Validation loss: 2.085861245791117

Epoch: 6| Step: 10
Training loss: 2.176736831665039
Validation loss: 2.088804046312968

Epoch: 6| Step: 11
Training loss: 2.1019458770751953
Validation loss: 2.065186699231466

Epoch: 6| Step: 12
Training loss: 1.3095051050186157
Validation loss: 2.049231012662252

Epoch: 6| Step: 13
Training loss: 1.6205058097839355
Validation loss: 2.004083275794983

Epoch: 64| Step: 0
Training loss: 1.632692813873291
Validation loss: 2.03782057762146

Epoch: 6| Step: 1
Training loss: 2.1243653297424316
Validation loss: 2.042047103246053

Epoch: 6| Step: 2
Training loss: 1.966804027557373
Validation loss: 2.025626003742218

Epoch: 6| Step: 3
Training loss: 1.7837414741516113
Validation loss: 2.022088328997294

Epoch: 6| Step: 4
Training loss: 1.7215309143066406
Validation loss: 2.058447321256002

Epoch: 6| Step: 5
Training loss: 1.4088939428329468
Validation loss: 2.100211958090464

Epoch: 6| Step: 6
Training loss: 1.791139841079712
Validation loss: 2.038433869679769

Epoch: 6| Step: 7
Training loss: 1.1177335977554321
Validation loss: 2.0367844303448996

Epoch: 6| Step: 8
Training loss: 1.6411259174346924
Validation loss: 2.062133232752482

Epoch: 6| Step: 9
Training loss: 2.494546413421631
Validation loss: 2.068280518054962

Epoch: 6| Step: 10
Training loss: 2.073617935180664
Validation loss: 2.0939826369285583

Epoch: 6| Step: 11
Training loss: 1.3353939056396484
Validation loss: 2.1159716844558716

Epoch: 6| Step: 12
Training loss: 2.1399598121643066
Validation loss: 2.058290958404541

Epoch: 6| Step: 13
Training loss: 1.176081895828247
Validation loss: 2.1096931099891663

Epoch: 65| Step: 0
Training loss: 1.323488473892212
Validation loss: 2.1513757904370627

Epoch: 6| Step: 1
Training loss: 1.931691288948059
Validation loss: 2.1183396180470786

Epoch: 6| Step: 2
Training loss: 2.0423521995544434
Validation loss: 2.0946792364120483

Epoch: 6| Step: 3
Training loss: 1.961054801940918
Validation loss: 2.1260244051615396

Epoch: 6| Step: 4
Training loss: 1.466996192932129
Validation loss: 2.094227214654287

Epoch: 6| Step: 5
Training loss: 1.4739428758621216
Validation loss: 2.1701342463493347

Epoch: 6| Step: 6
Training loss: 1.3991646766662598
Validation loss: 2.1030932466189065

Epoch: 6| Step: 7
Training loss: 1.771527886390686
Validation loss: 2.143550157546997

Epoch: 6| Step: 8
Training loss: 1.490950584411621
Validation loss: 2.073033034801483

Epoch: 6| Step: 9
Training loss: 1.7893259525299072
Validation loss: 2.0700519680976868

Epoch: 6| Step: 10
Training loss: 1.3324532508850098
Validation loss: 2.019851783911387

Epoch: 6| Step: 11
Training loss: 2.3355600833892822
Validation loss: 2.018474042415619

Epoch: 6| Step: 12
Training loss: 2.0740392208099365
Validation loss: 2.0200027028719583

Epoch: 6| Step: 13
Training loss: 1.9690816402435303
Validation loss: 1.9344142079353333

Epoch: 66| Step: 0
Training loss: 1.704865574836731
Validation loss: 2.00212824344635

Epoch: 6| Step: 1
Training loss: 1.842044711112976
Validation loss: 2.019121785958608

Epoch: 6| Step: 2
Training loss: 1.6861772537231445
Validation loss: 2.0504053036371865

Epoch: 6| Step: 3
Training loss: 2.394303321838379
Validation loss: 2.0599611004193625

Epoch: 6| Step: 4
Training loss: 1.773693323135376
Validation loss: 2.023153603076935

Epoch: 6| Step: 5
Training loss: 1.8668417930603027
Validation loss: 2.092015286286672

Epoch: 6| Step: 6
Training loss: 1.667231559753418
Validation loss: 1.9948137601216633

Epoch: 6| Step: 7
Training loss: 1.3894160985946655
Validation loss: 2.047924737135569

Epoch: 6| Step: 8
Training loss: 1.464455246925354
Validation loss: 1.9915114442507427

Epoch: 6| Step: 9
Training loss: 1.3736214637756348
Validation loss: 2.0328868428866067

Epoch: 6| Step: 10
Training loss: 1.7407336235046387
Validation loss: 2.130207637945811

Epoch: 6| Step: 11
Training loss: 1.6425793170928955
Validation loss: 2.185289661089579

Epoch: 6| Step: 12
Training loss: 2.017953395843506
Validation loss: 2.2051305174827576

Epoch: 6| Step: 13
Training loss: 2.444308042526245
Validation loss: 2.189116438229879

Epoch: 67| Step: 0
Training loss: 2.0589981079101562
Validation loss: 2.1578289270401

Epoch: 6| Step: 1
Training loss: 2.139390230178833
Validation loss: 2.07856418689092

Epoch: 6| Step: 2
Training loss: 1.6180893182754517
Validation loss: 2.058443029721578

Epoch: 6| Step: 3
Training loss: 1.7406904697418213
Validation loss: 1.979729692141215

Epoch: 6| Step: 4
Training loss: 1.6490751504898071
Validation loss: 2.0485334197680154

Epoch: 6| Step: 5
Training loss: 1.8872992992401123
Validation loss: 2.0254023472468057

Epoch: 6| Step: 6
Training loss: 1.8530523777008057
Validation loss: 2.0281723737716675

Epoch: 6| Step: 7
Training loss: 1.2372913360595703
Validation loss: 1.9947335918744404

Epoch: 6| Step: 8
Training loss: 1.4426096677780151
Validation loss: 2.0578264594078064

Epoch: 6| Step: 9
Training loss: 1.8821254968643188
Validation loss: 2.0150365432103476

Epoch: 6| Step: 10
Training loss: 1.916520118713379
Validation loss: 2.0980862975120544

Epoch: 6| Step: 11
Training loss: 1.451862096786499
Validation loss: 2.041508217652639

Epoch: 6| Step: 12
Training loss: 2.0806493759155273
Validation loss: 2.095170279343923

Epoch: 6| Step: 13
Training loss: 2.3096532821655273
Validation loss: 2.0386195381482444

Epoch: 68| Step: 0
Training loss: 1.87845778465271
Validation loss: 2.032485624154409

Epoch: 6| Step: 1
Training loss: 1.1971917152404785
Validation loss: 2.0714722275733948

Epoch: 6| Step: 2
Training loss: 1.9862430095672607
Validation loss: 2.068600296974182

Epoch: 6| Step: 3
Training loss: 1.8117530345916748
Validation loss: 2.064670125643412

Epoch: 6| Step: 4
Training loss: 1.1585313081741333
Validation loss: 2.020022531350454

Epoch: 6| Step: 5
Training loss: 1.4563055038452148
Validation loss: 2.0330360531806946

Epoch: 6| Step: 6
Training loss: 1.9745888710021973
Validation loss: 2.0955434242884317

Epoch: 6| Step: 7
Training loss: 1.4128167629241943
Validation loss: 2.0900196035703025

Epoch: 6| Step: 8
Training loss: 1.6853513717651367
Validation loss: 2.0861580967903137

Epoch: 6| Step: 9
Training loss: 1.5805039405822754
Validation loss: 2.0526060263315835

Epoch: 6| Step: 10
Training loss: 1.9636882543563843
Validation loss: 2.0982755223910012

Epoch: 6| Step: 11
Training loss: 1.6450650691986084
Validation loss: 2.125794231891632

Epoch: 6| Step: 12
Training loss: 2.4680652618408203
Validation loss: 2.1408517559369407

Epoch: 6| Step: 13
Training loss: 1.991990566253662
Validation loss: 2.135615507761637

Epoch: 69| Step: 0
Training loss: 1.6849792003631592
Validation loss: 2.1558194955190024

Epoch: 6| Step: 1
Training loss: 1.1408967971801758
Validation loss: 2.041967531045278

Epoch: 6| Step: 2
Training loss: 1.7572979927062988
Validation loss: 2.050429880619049

Epoch: 6| Step: 3
Training loss: 2.1476454734802246
Validation loss: 2.0710259675979614

Epoch: 6| Step: 4
Training loss: 1.5531359910964966
Validation loss: 2.0028142730394998

Epoch: 6| Step: 5
Training loss: 1.3065948486328125
Validation loss: 2.0516815980275473

Epoch: 6| Step: 6
Training loss: 1.9778246879577637
Validation loss: 2.03080290555954

Epoch: 6| Step: 7
Training loss: 2.2394473552703857
Validation loss: 2.020008126894633

Epoch: 6| Step: 8
Training loss: 1.7485332489013672
Validation loss: 2.012891471385956

Epoch: 6| Step: 9
Training loss: 1.6999757289886475
Validation loss: 2.045080840587616

Epoch: 6| Step: 10
Training loss: 2.336792230606079
Validation loss: 2.0327633817990622

Epoch: 6| Step: 11
Training loss: 1.5723505020141602
Validation loss: 2.0791647831598916

Epoch: 6| Step: 12
Training loss: 1.5445696115493774
Validation loss: 2.115980406602224

Epoch: 6| Step: 13
Training loss: 1.7709702253341675
Validation loss: 2.0595710476239524

Epoch: 70| Step: 0
Training loss: 1.8887362480163574
Validation loss: 2.124339004357656

Epoch: 6| Step: 1
Training loss: 1.6530635356903076
Validation loss: 2.1102968653043113

Epoch: 6| Step: 2
Training loss: 1.608349323272705
Validation loss: 2.1536226073900857

Epoch: 6| Step: 3
Training loss: 2.347054958343506
Validation loss: 2.200490136941274

Epoch: 6| Step: 4
Training loss: 2.247197389602661
Validation loss: 2.209390620390574

Epoch: 6| Step: 5
Training loss: 1.7942943572998047
Validation loss: 2.1113837560017905

Epoch: 6| Step: 6
Training loss: 2.510207176208496
Validation loss: 2.116198162237803

Epoch: 6| Step: 7
Training loss: 1.1824926137924194
Validation loss: 2.0982930660247803

Epoch: 6| Step: 8
Training loss: 2.278942346572876
Validation loss: 2.0353317856788635

Epoch: 6| Step: 9
Training loss: 1.2312726974487305
Validation loss: 2.0017846624056497

Epoch: 6| Step: 10
Training loss: 1.3959307670593262
Validation loss: 2.032294193903605

Epoch: 6| Step: 11
Training loss: 1.599400520324707
Validation loss: 1.9861457347869873

Epoch: 6| Step: 12
Training loss: 1.2907497882843018
Validation loss: 1.9830273787180583

Epoch: 6| Step: 13
Training loss: 1.3229913711547852
Validation loss: 2.024350166320801

Epoch: 71| Step: 0
Training loss: 1.2823160886764526
Validation loss: 2.018127163251241

Epoch: 6| Step: 1
Training loss: 1.9227564334869385
Validation loss: 2.064139266808828

Epoch: 6| Step: 2
Training loss: 2.0242698192596436
Validation loss: 2.0151307781537375

Epoch: 6| Step: 3
Training loss: 1.8414283990859985
Validation loss: 2.085534373919169

Epoch: 6| Step: 4
Training loss: 1.9395567178726196
Validation loss: 2.0901047190030417

Epoch: 6| Step: 5
Training loss: 1.5230815410614014
Validation loss: 2.073923567930857

Epoch: 6| Step: 6
Training loss: 2.0897610187530518
Validation loss: 2.076010843118032

Epoch: 6| Step: 7
Training loss: 1.5353485345840454
Validation loss: 2.0785730878512063

Epoch: 6| Step: 8
Training loss: 2.1489481925964355
Validation loss: 2.0874505639076233

Epoch: 6| Step: 9
Training loss: 1.2578693628311157
Validation loss: 2.1092278361320496

Epoch: 6| Step: 10
Training loss: 1.6155141592025757
Validation loss: 2.086849351723989

Epoch: 6| Step: 11
Training loss: 1.5122828483581543
Validation loss: 2.157902777194977

Epoch: 6| Step: 12
Training loss: 1.61289381980896
Validation loss: 2.1427687605222068

Epoch: 6| Step: 13
Training loss: 1.539742112159729
Validation loss: 2.2390517393747964

Epoch: 72| Step: 0
Training loss: 1.7809159755706787
Validation loss: 2.1837374369303384

Epoch: 6| Step: 1
Training loss: 1.8815624713897705
Validation loss: 2.0996882716814675

Epoch: 6| Step: 2
Training loss: 1.3709441423416138
Validation loss: 2.0473756194114685

Epoch: 6| Step: 3
Training loss: 2.433140754699707
Validation loss: 2.0512278079986572

Epoch: 6| Step: 4
Training loss: 1.3026996850967407
Validation loss: 2.014959673086802

Epoch: 6| Step: 5
Training loss: 1.9950333833694458
Validation loss: 1.9923533002535503

Epoch: 6| Step: 6
Training loss: 2.4267358779907227
Validation loss: 2.0660834511121116

Epoch: 6| Step: 7
Training loss: 2.1027464866638184
Validation loss: 1.9793344537417095

Epoch: 6| Step: 8
Training loss: 1.8214173316955566
Validation loss: 2.0522021055221558

Epoch: 6| Step: 9
Training loss: 1.249471664428711
Validation loss: 2.02541983127594

Epoch: 6| Step: 10
Training loss: 1.5711565017700195
Validation loss: 2.0749632120132446

Epoch: 6| Step: 11
Training loss: 1.5275336503982544
Validation loss: 2.0118712981541953

Epoch: 6| Step: 12
Training loss: 1.1778472661972046
Validation loss: 2.1287450591723123

Epoch: 6| Step: 13
Training loss: 1.8070273399353027
Validation loss: 2.0950068632761636

Epoch: 73| Step: 0
Training loss: 1.013424277305603
Validation loss: 2.1420246958732605

Epoch: 6| Step: 1
Training loss: 1.4923880100250244
Validation loss: 2.065728406111399

Epoch: 6| Step: 2
Training loss: 2.0365819931030273
Validation loss: 2.099521279335022

Epoch: 6| Step: 3
Training loss: 1.9984126091003418
Validation loss: 2.092330356438955

Epoch: 6| Step: 4
Training loss: 1.608527660369873
Validation loss: 2.124047100543976

Epoch: 6| Step: 5
Training loss: 1.4377168416976929
Validation loss: 2.015527884165446

Epoch: 6| Step: 6
Training loss: 1.8408596515655518
Validation loss: 2.0093634923299155

Epoch: 6| Step: 7
Training loss: 1.6956762075424194
Validation loss: 2.0562145511309304

Epoch: 6| Step: 8
Training loss: 1.9988384246826172
Validation loss: 2.0440318981806436

Epoch: 6| Step: 9
Training loss: 1.753138780593872
Validation loss: 2.0744016766548157

Epoch: 6| Step: 10
Training loss: 1.5672825574874878
Validation loss: 2.0532615383466086

Epoch: 6| Step: 11
Training loss: 1.4686291217803955
Validation loss: 2.075386424859365

Epoch: 6| Step: 12
Training loss: 1.3763773441314697
Validation loss: 2.0865025321642556

Epoch: 6| Step: 13
Training loss: 1.898474931716919
Validation loss: 2.079135298728943

Epoch: 74| Step: 0
Training loss: 1.3513684272766113
Validation loss: 2.078252911567688

Epoch: 6| Step: 1
Training loss: 1.7786669731140137
Validation loss: 2.0158856908480325

Epoch: 6| Step: 2
Training loss: 2.2374777793884277
Validation loss: 2.147646129131317

Epoch: 6| Step: 3
Training loss: 1.4649696350097656
Validation loss: 2.06857967376709

Epoch: 6| Step: 4
Training loss: 1.7048757076263428
Validation loss: 2.077631870905558

Epoch: 6| Step: 5
Training loss: 1.5959084033966064
Validation loss: 2.0784699122111

Epoch: 6| Step: 6
Training loss: 1.5195441246032715
Validation loss: 2.159643530845642

Epoch: 6| Step: 7
Training loss: 2.220179557800293
Validation loss: 2.084727923075358

Epoch: 6| Step: 8
Training loss: 1.342606544494629
Validation loss: 2.127301057179769

Epoch: 6| Step: 9
Training loss: 1.4813060760498047
Validation loss: 2.064206838607788

Epoch: 6| Step: 10
Training loss: 1.3895726203918457
Validation loss: 2.0979930758476257

Epoch: 6| Step: 11
Training loss: 1.5426852703094482
Validation loss: 2.090965727965037

Epoch: 6| Step: 12
Training loss: 1.7971004247665405
Validation loss: 2.0216026306152344

Epoch: 6| Step: 13
Training loss: 1.97684907913208
Validation loss: 2.034499724706014

Epoch: 75| Step: 0
Training loss: 1.7675191164016724
Validation loss: 2.055469552675883

Epoch: 6| Step: 1
Training loss: 1.9846863746643066
Validation loss: 2.011835296948751

Epoch: 6| Step: 2
Training loss: 1.7437442541122437
Validation loss: 1.9834537108739216

Epoch: 6| Step: 3
Training loss: 1.9692285060882568
Validation loss: 1.9945437113444011

Epoch: 6| Step: 4
Training loss: 1.7487976551055908
Validation loss: 2.0122018853823342

Epoch: 6| Step: 5
Training loss: 2.248422145843506
Validation loss: 2.085939586162567

Epoch: 6| Step: 6
Training loss: 1.810248851776123
Validation loss: 2.062972684701284

Epoch: 6| Step: 7
Training loss: 1.4975931644439697
Validation loss: 2.055419623851776

Epoch: 6| Step: 8
Training loss: 1.428282380104065
Validation loss: 2.0181750655174255

Epoch: 6| Step: 9
Training loss: 1.5357770919799805
Validation loss: 2.0521594683329263

Epoch: 6| Step: 10
Training loss: 1.3662750720977783
Validation loss: 2.091576417287191

Epoch: 6| Step: 11
Training loss: 1.2743146419525146
Validation loss: 2.0798579454421997

Epoch: 6| Step: 12
Training loss: 1.7918187379837036
Validation loss: 2.125363012154897

Epoch: 6| Step: 13
Training loss: 1.0733312368392944
Validation loss: 2.064701239267985

Testing loss: 1.9796814352488346
