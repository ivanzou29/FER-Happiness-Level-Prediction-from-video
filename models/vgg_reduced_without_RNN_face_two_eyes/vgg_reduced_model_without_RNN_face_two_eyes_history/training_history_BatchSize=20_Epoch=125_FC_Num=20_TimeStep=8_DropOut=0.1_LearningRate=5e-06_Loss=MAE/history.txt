Epoch: 1| Step: 0
Training loss: 3.3143115043640137
Validation loss: 3.0260849793752036

Epoch: 5| Step: 1
Training loss: 2.9610793590545654
Validation loss: 3.0100748042265573

Epoch: 5| Step: 2
Training loss: 3.3831424713134766
Validation loss: 2.989503135283788

Epoch: 5| Step: 3
Training loss: 3.0442569255828857
Validation loss: 2.9732674658298492

Epoch: 5| Step: 4
Training loss: 3.3020095825195312
Validation loss: 2.9566313326358795

Epoch: 5| Step: 5
Training loss: 2.8382277488708496
Validation loss: 2.9407457212607064

Epoch: 5| Step: 6
Training loss: 2.414226531982422
Validation loss: 2.9266733527183533

Epoch: 5| Step: 7
Training loss: 3.4303183555603027
Validation loss: 2.914380500713984

Epoch: 5| Step: 8
Training loss: 3.278350830078125
Validation loss: 2.8980694512526193

Epoch: 5| Step: 9
Training loss: 3.4498400688171387
Validation loss: 2.8848978082338967

Epoch: 5| Step: 10
Training loss: 3.1624109745025635
Validation loss: 2.8703043858210244

Epoch: 5| Step: 11
Training loss: 3.008030414581299
Validation loss: 2.8573414584000907

Epoch: 2| Step: 0
Training loss: 3.367776870727539
Validation loss: 2.8422132432460785

Epoch: 5| Step: 1
Training loss: 3.5368010997772217
Validation loss: 2.8284613490104675

Epoch: 5| Step: 2
Training loss: 2.0711724758148193
Validation loss: 2.8140520652135215

Epoch: 5| Step: 3
Training loss: 2.593320369720459
Validation loss: 2.8006937305132547

Epoch: 5| Step: 4
Training loss: 2.9477028846740723
Validation loss: 2.7863023380438485

Epoch: 5| Step: 5
Training loss: 3.166874408721924
Validation loss: 2.7721559007962546

Epoch: 5| Step: 6
Training loss: 3.6405138969421387
Validation loss: 2.7585687587658563

Epoch: 5| Step: 7
Training loss: 2.816969394683838
Validation loss: 2.738891770442327

Epoch: 5| Step: 8
Training loss: 2.976957321166992
Validation loss: 2.723080019156138

Epoch: 5| Step: 9
Training loss: 2.6358046531677246
Validation loss: 2.711749722560247

Epoch: 5| Step: 10
Training loss: 2.6303412914276123
Validation loss: 2.6942316393057504

Epoch: 5| Step: 11
Training loss: 3.884716272354126
Validation loss: 2.67843363682429

Epoch: 3| Step: 0
Training loss: 2.474536895751953
Validation loss: 2.659764528274536

Epoch: 5| Step: 1
Training loss: 2.8933379650115967
Validation loss: 2.6401253044605255

Epoch: 5| Step: 2
Training loss: 3.113245964050293
Validation loss: 2.6250819762547812

Epoch: 5| Step: 3
Training loss: 2.799592971801758
Validation loss: 2.604271580775579

Epoch: 5| Step: 4
Training loss: 2.9310622215270996
Validation loss: 2.5801632404327393

Epoch: 5| Step: 5
Training loss: 2.899357318878174
Validation loss: 2.5597735891739526

Epoch: 5| Step: 6
Training loss: 2.449532985687256
Validation loss: 2.535130669673284

Epoch: 5| Step: 7
Training loss: 2.6372575759887695
Validation loss: 2.5086958607037864

Epoch: 5| Step: 8
Training loss: 3.1634507179260254
Validation loss: 2.4840841392676034

Epoch: 5| Step: 9
Training loss: 1.948158860206604
Validation loss: 2.458263635635376

Epoch: 5| Step: 10
Training loss: 2.4278900623321533
Validation loss: 2.4295601348082223

Epoch: 5| Step: 11
Training loss: 2.7692317962646484
Validation loss: 2.4045834143956504

Epoch: 4| Step: 0
Training loss: 2.4596054553985596
Validation loss: 2.378075033426285

Epoch: 5| Step: 1
Training loss: 2.5445470809936523
Validation loss: 2.34783968826135

Epoch: 5| Step: 2
Training loss: 2.0549702644348145
Validation loss: 2.3253905226786933

Epoch: 5| Step: 3
Training loss: 2.495208740234375
Validation loss: 2.292266607284546

Epoch: 5| Step: 4
Training loss: 2.2334330081939697
Validation loss: 2.2607001860936484

Epoch: 5| Step: 5
Training loss: 2.4692840576171875
Validation loss: 2.2368473460276923

Epoch: 5| Step: 6
Training loss: 2.2673230171203613
Validation loss: 2.2000825603803

Epoch: 5| Step: 7
Training loss: 1.9733622074127197
Validation loss: 2.162374049425125

Epoch: 5| Step: 8
Training loss: 2.844198703765869
Validation loss: 2.1386530150969825

Epoch: 5| Step: 9
Training loss: 2.15897274017334
Validation loss: 2.10150816043218

Epoch: 5| Step: 10
Training loss: 2.1455650329589844
Validation loss: 2.087328235308329

Epoch: 5| Step: 11
Training loss: 1.6904386281967163
Validation loss: 2.0622729857762656

Epoch: 5| Step: 0
Training loss: 2.252575635910034
Validation loss: 2.0414243787527084

Epoch: 5| Step: 1
Training loss: 2.2223477363586426
Validation loss: 2.0321180125077567

Epoch: 5| Step: 2
Training loss: 2.1843924522399902
Validation loss: 2.019642705718676

Epoch: 5| Step: 3
Training loss: 2.117189645767212
Validation loss: 1.994463950395584

Epoch: 5| Step: 4
Training loss: 2.412022113800049
Validation loss: 1.995777462919553

Epoch: 5| Step: 5
Training loss: 2.1516494750976562
Validation loss: 1.9850034415721893

Epoch: 5| Step: 6
Training loss: 1.890420913696289
Validation loss: 1.9882526050011318

Epoch: 5| Step: 7
Training loss: 2.157623767852783
Validation loss: 1.9723754078149796

Epoch: 5| Step: 8
Training loss: 1.9241063594818115
Validation loss: 1.9661004543304443

Epoch: 5| Step: 9
Training loss: 1.7926998138427734
Validation loss: 1.9735598663489025

Epoch: 5| Step: 10
Training loss: 1.6381504535675049
Validation loss: 1.966544712583224

Epoch: 5| Step: 11
Training loss: 2.390895128250122
Validation loss: 1.985285148024559

Epoch: 6| Step: 0
Training loss: 2.2610981464385986
Validation loss: 1.9991403420766194

Epoch: 5| Step: 1
Training loss: 2.494666576385498
Validation loss: 2.027370194594065

Epoch: 5| Step: 2
Training loss: 1.8040540218353271
Validation loss: 2.040003776550293

Epoch: 5| Step: 3
Training loss: 1.8635637760162354
Validation loss: 2.043358643849691

Epoch: 5| Step: 4
Training loss: 2.4884355068206787
Validation loss: 2.0424333860476813

Epoch: 5| Step: 5
Training loss: 2.194342851638794
Validation loss: 2.035997197031975

Epoch: 5| Step: 6
Training loss: 1.777627944946289
Validation loss: 2.024768809477488

Epoch: 5| Step: 7
Training loss: 2.1178629398345947
Validation loss: 2.0138555814822516

Epoch: 5| Step: 8
Training loss: 2.1370983123779297
Validation loss: 1.998802254597346

Epoch: 5| Step: 9
Training loss: 2.1048359870910645
Validation loss: 1.989573096235593

Epoch: 5| Step: 10
Training loss: 2.1556570529937744
Validation loss: 1.9864087949196498

Epoch: 5| Step: 11
Training loss: 1.4911595582962036
Validation loss: 1.986120730638504

Epoch: 7| Step: 0
Training loss: 2.2327888011932373
Validation loss: 1.9702817151943843

Epoch: 5| Step: 1
Training loss: 2.3048899173736572
Validation loss: 1.9594312409559886

Epoch: 5| Step: 2
Training loss: 2.0146842002868652
Validation loss: 1.9717808465162914

Epoch: 5| Step: 3
Training loss: 2.435764789581299
Validation loss: 1.9624933550755184

Epoch: 5| Step: 4
Training loss: 1.7992722988128662
Validation loss: 1.9653303821881611

Epoch: 5| Step: 5
Training loss: 1.611109972000122
Validation loss: 1.96603820224603

Epoch: 5| Step: 6
Training loss: 2.335952043533325
Validation loss: 1.9692612042029698

Epoch: 5| Step: 7
Training loss: 1.9890661239624023
Validation loss: 1.9690689394871395

Epoch: 5| Step: 8
Training loss: 1.3721811771392822
Validation loss: 1.9747323095798492

Epoch: 5| Step: 9
Training loss: 1.8841979503631592
Validation loss: 1.9755566914876301

Epoch: 5| Step: 10
Training loss: 2.685243606567383
Validation loss: 1.9555029223362606

Epoch: 5| Step: 11
Training loss: 3.107990264892578
Validation loss: 1.9579631785551708

Epoch: 8| Step: 0
Training loss: 2.36218523979187
Validation loss: 1.9577639351288478

Epoch: 5| Step: 1
Training loss: 2.067415237426758
Validation loss: 1.9550554851690929

Epoch: 5| Step: 2
Training loss: 2.193527936935425
Validation loss: 1.9697242230176926

Epoch: 5| Step: 3
Training loss: 2.133056640625
Validation loss: 1.9598664542039235

Epoch: 5| Step: 4
Training loss: 1.8177709579467773
Validation loss: 1.9506752093633015

Epoch: 5| Step: 5
Training loss: 1.9419078826904297
Validation loss: 1.9464906752109528

Epoch: 5| Step: 6
Training loss: 1.8887805938720703
Validation loss: 1.9662014096975327

Epoch: 5| Step: 7
Training loss: 2.255434513092041
Validation loss: 1.9649829119443893

Epoch: 5| Step: 8
Training loss: 1.7277637720108032
Validation loss: 1.9532764752705891

Epoch: 5| Step: 9
Training loss: 1.9889549016952515
Validation loss: 1.951443577806155

Epoch: 5| Step: 10
Training loss: 2.184915065765381
Validation loss: 1.9492076486349106

Epoch: 5| Step: 11
Training loss: 2.72023344039917
Validation loss: 1.9609181384245555

Epoch: 9| Step: 0
Training loss: 2.356703281402588
Validation loss: 1.9511890957752864

Epoch: 5| Step: 1
Training loss: 1.545462965965271
Validation loss: 1.9533849308888118

Epoch: 5| Step: 2
Training loss: 2.2058982849121094
Validation loss: 1.9604322910308838

Epoch: 5| Step: 3
Training loss: 1.6994520425796509
Validation loss: 1.9639426122109096

Epoch: 5| Step: 4
Training loss: 2.0441017150878906
Validation loss: 1.9653498530387878

Epoch: 5| Step: 5
Training loss: 2.819150924682617
Validation loss: 1.9693596561749775

Epoch: 5| Step: 6
Training loss: 1.6422332525253296
Validation loss: 1.9537222236394882

Epoch: 5| Step: 7
Training loss: 2.248913526535034
Validation loss: 1.970916618903478

Epoch: 5| Step: 8
Training loss: 2.368542194366455
Validation loss: 1.942857523759206

Epoch: 5| Step: 9
Training loss: 1.741891860961914
Validation loss: 1.9608763406674068

Epoch: 5| Step: 10
Training loss: 2.1765081882476807
Validation loss: 1.9536212037007015

Epoch: 5| Step: 11
Training loss: 0.6992025375366211
Validation loss: 1.9604399154583614

Epoch: 10| Step: 0
Training loss: 1.7282123565673828
Validation loss: 1.9620557775100071

Epoch: 5| Step: 1
Training loss: 1.9976780414581299
Validation loss: 1.965714345375697

Epoch: 5| Step: 2
Training loss: 2.500241279602051
Validation loss: 1.9753426263729732

Epoch: 5| Step: 3
Training loss: 1.8647339344024658
Validation loss: 1.9701135754585266

Epoch: 5| Step: 4
Training loss: 2.039438009262085
Validation loss: 1.955906718969345

Epoch: 5| Step: 5
Training loss: 2.1510956287384033
Validation loss: 1.9654847582181294

Epoch: 5| Step: 6
Training loss: 1.7797253131866455
Validation loss: 1.9890678077936172

Epoch: 5| Step: 7
Training loss: 2.287379503250122
Validation loss: 1.9808747867743175

Epoch: 5| Step: 8
Training loss: 2.197732448577881
Validation loss: 1.9717875023682911

Epoch: 5| Step: 9
Training loss: 1.93313467502594
Validation loss: 1.9684588213761647

Epoch: 5| Step: 10
Training loss: 1.9628593921661377
Validation loss: 1.9519285758336384

Epoch: 5| Step: 11
Training loss: 2.0233774185180664
Validation loss: 1.9641973376274109

Epoch: 11| Step: 0
Training loss: 2.1961491107940674
Validation loss: 1.9506787012020748

Epoch: 5| Step: 1
Training loss: 1.6454960107803345
Validation loss: 1.953669548034668

Epoch: 5| Step: 2
Training loss: 1.9472711086273193
Validation loss: 1.960257391134898

Epoch: 5| Step: 3
Training loss: 2.2486746311187744
Validation loss: 1.9532583504915237

Epoch: 5| Step: 4
Training loss: 2.054257869720459
Validation loss: 1.942238062620163

Epoch: 5| Step: 5
Training loss: 2.2074592113494873
Validation loss: 1.9422744512557983

Epoch: 5| Step: 6
Training loss: 2.4624783992767334
Validation loss: 1.9368588080008824

Epoch: 5| Step: 7
Training loss: 2.477163791656494
Validation loss: 1.9331190784772236

Epoch: 5| Step: 8
Training loss: 1.6708084344863892
Validation loss: 1.9311475455760956

Epoch: 5| Step: 9
Training loss: 1.9145534038543701
Validation loss: 1.915883998076121

Epoch: 5| Step: 10
Training loss: 1.9744278192520142
Validation loss: 1.9451330850521724

Epoch: 5| Step: 11
Training loss: 0.9221692681312561
Validation loss: 1.9484041929244995

Epoch: 12| Step: 0
Training loss: 2.088789463043213
Validation loss: 1.9467433243989944

Epoch: 5| Step: 1
Training loss: 2.3893489837646484
Validation loss: 1.933074802160263

Epoch: 5| Step: 2
Training loss: 1.7944656610488892
Validation loss: 1.946054607629776

Epoch: 5| Step: 3
Training loss: 2.6664669513702393
Validation loss: 1.9457857956488926

Epoch: 5| Step: 4
Training loss: 1.907414436340332
Validation loss: 1.9474115073680878

Epoch: 5| Step: 5
Training loss: 2.3578388690948486
Validation loss: 1.9431104113658269

Epoch: 5| Step: 6
Training loss: 1.9126684665679932
Validation loss: 1.9562587042649586

Epoch: 5| Step: 7
Training loss: 1.9875233173370361
Validation loss: 1.9615247199932735

Epoch: 5| Step: 8
Training loss: 1.3522253036499023
Validation loss: 1.9485732813676198

Epoch: 5| Step: 9
Training loss: 2.3277182579040527
Validation loss: 1.9548861980438232

Epoch: 5| Step: 10
Training loss: 2.186014175415039
Validation loss: 1.9396859606107075

Epoch: 5| Step: 11
Training loss: 0.5973010063171387
Validation loss: 1.965093066294988

Epoch: 13| Step: 0
Training loss: 1.7700750827789307
Validation loss: 1.9459225436051686

Epoch: 5| Step: 1
Training loss: 1.7524974346160889
Validation loss: 1.9531953086455662

Epoch: 5| Step: 2
Training loss: 2.0382142066955566
Validation loss: 1.9495615263779957

Epoch: 5| Step: 3
Training loss: 1.8228925466537476
Validation loss: 1.9564526031414669

Epoch: 5| Step: 4
Training loss: 2.04106068611145
Validation loss: 1.9508600483338039

Epoch: 5| Step: 5
Training loss: 1.7343486547470093
Validation loss: 1.9709743161996205

Epoch: 5| Step: 6
Training loss: 2.0856571197509766
Validation loss: 1.9622822205225627

Epoch: 5| Step: 7
Training loss: 2.7110073566436768
Validation loss: 1.9351143687963486

Epoch: 5| Step: 8
Training loss: 2.380795478820801
Validation loss: 1.954757849375407

Epoch: 5| Step: 9
Training loss: 2.056304931640625
Validation loss: 1.9610431889692943

Epoch: 5| Step: 10
Training loss: 1.7124437093734741
Validation loss: 1.9538697053988774

Epoch: 5| Step: 11
Training loss: 2.7442989349365234
Validation loss: 1.9417637089888256

Epoch: 14| Step: 0
Training loss: 1.3741579055786133
Validation loss: 1.9576625227928162

Epoch: 5| Step: 1
Training loss: 1.4095509052276611
Validation loss: 1.9353464245796204

Epoch: 5| Step: 2
Training loss: 2.9774563312530518
Validation loss: 1.9352842221657436

Epoch: 5| Step: 3
Training loss: 2.17681884765625
Validation loss: 1.9370469848314922

Epoch: 5| Step: 4
Training loss: 1.2728846073150635
Validation loss: 1.9420872380336125

Epoch: 5| Step: 5
Training loss: 2.0093579292297363
Validation loss: 1.9375188996394475

Epoch: 5| Step: 6
Training loss: 2.4834256172180176
Validation loss: 1.9347658107678096

Epoch: 5| Step: 7
Training loss: 1.9076359272003174
Validation loss: 1.9371827592452366

Epoch: 5| Step: 8
Training loss: 2.1988556385040283
Validation loss: 1.9255525320768356

Epoch: 5| Step: 9
Training loss: 1.7974056005477905
Validation loss: 1.9309135029713314

Epoch: 5| Step: 10
Training loss: 2.6662888526916504
Validation loss: 1.9398871809244156

Epoch: 5| Step: 11
Training loss: 1.9361889362335205
Validation loss: 1.9302149166663487

Epoch: 15| Step: 0
Training loss: 2.469301223754883
Validation loss: 1.9432205855846405

Epoch: 5| Step: 1
Training loss: 1.6717958450317383
Validation loss: 1.9478607525428135

Epoch: 5| Step: 2
Training loss: 1.8761122226715088
Validation loss: 1.913423905769984

Epoch: 5| Step: 3
Training loss: 1.9648739099502563
Validation loss: 1.9253418544928234

Epoch: 5| Step: 4
Training loss: 1.844240427017212
Validation loss: 1.9263179302215576

Epoch: 5| Step: 5
Training loss: 1.5082823038101196
Validation loss: 1.924726535876592

Epoch: 5| Step: 6
Training loss: 2.1856155395507812
Validation loss: 1.9318301975727081

Epoch: 5| Step: 7
Training loss: 2.031933546066284
Validation loss: 1.9400035291910172

Epoch: 5| Step: 8
Training loss: 2.078819751739502
Validation loss: 1.9384478032588959

Epoch: 5| Step: 9
Training loss: 1.8766978979110718
Validation loss: 1.9396801094214122

Epoch: 5| Step: 10
Training loss: 2.37864351272583
Validation loss: 1.9315884311993916

Epoch: 5| Step: 11
Training loss: 2.850334882736206
Validation loss: 1.9409784426291783

Epoch: 16| Step: 0
Training loss: 1.9276151657104492
Validation loss: 1.9497338831424713

Epoch: 5| Step: 1
Training loss: 1.8383147716522217
Validation loss: 1.9425686448812485

Epoch: 5| Step: 2
Training loss: 1.6589176654815674
Validation loss: 1.9329635848601658

Epoch: 5| Step: 3
Training loss: 2.2143120765686035
Validation loss: 1.9583959480126698

Epoch: 5| Step: 4
Training loss: 2.312256336212158
Validation loss: 2.011091023683548

Epoch: 5| Step: 5
Training loss: 2.1753122806549072
Validation loss: 1.9727602104345958

Epoch: 5| Step: 6
Training loss: 2.1164402961730957
Validation loss: 1.9839681188265483

Epoch: 5| Step: 7
Training loss: 2.0136752128601074
Validation loss: 1.983937382698059

Epoch: 5| Step: 8
Training loss: 1.9790420532226562
Validation loss: 1.973421533902486

Epoch: 5| Step: 9
Training loss: 1.7040475606918335
Validation loss: 1.9780228684345882

Epoch: 5| Step: 10
Training loss: 2.4546847343444824
Validation loss: 1.970791071653366

Epoch: 5| Step: 11
Training loss: 0.9353326559066772
Validation loss: 1.9563163965940475

Epoch: 17| Step: 0
Training loss: 1.8304309844970703
Validation loss: 1.9717250516017277

Epoch: 5| Step: 1
Training loss: 1.6579082012176514
Validation loss: 1.9510513991117477

Epoch: 5| Step: 2
Training loss: 2.5096981525421143
Validation loss: 1.9403343697388966

Epoch: 5| Step: 3
Training loss: 1.923709511756897
Validation loss: 1.9483741223812103

Epoch: 5| Step: 4
Training loss: 1.966281533241272
Validation loss: 1.9196867694457371

Epoch: 5| Step: 5
Training loss: 2.624119997024536
Validation loss: 1.9088093390067418

Epoch: 5| Step: 6
Training loss: 2.0307674407958984
Validation loss: 1.9196612139542897

Epoch: 5| Step: 7
Training loss: 1.9968019723892212
Validation loss: 1.9365662336349487

Epoch: 5| Step: 8
Training loss: 1.7832765579223633
Validation loss: 1.9323907146851222

Epoch: 5| Step: 9
Training loss: 1.7664384841918945
Validation loss: 1.9202267279227574

Epoch: 5| Step: 10
Training loss: 1.8374077081680298
Validation loss: 1.9343179762363434

Epoch: 5| Step: 11
Training loss: 2.1436078548431396
Validation loss: 1.9106808702150981

Epoch: 18| Step: 0
Training loss: 1.8667070865631104
Validation loss: 1.9198895295461018

Epoch: 5| Step: 1
Training loss: 1.8160476684570312
Validation loss: 1.9363738149404526

Epoch: 5| Step: 2
Training loss: 1.668499231338501
Validation loss: 1.9204447468121846

Epoch: 5| Step: 3
Training loss: 2.358752727508545
Validation loss: 1.950560172398885

Epoch: 5| Step: 4
Training loss: 2.0024030208587646
Validation loss: 1.9431331753730774

Epoch: 5| Step: 5
Training loss: 2.4945476055145264
Validation loss: 1.9516466856002808

Epoch: 5| Step: 6
Training loss: 2.379086971282959
Validation loss: 1.9313054531812668

Epoch: 5| Step: 7
Training loss: 1.3061587810516357
Validation loss: 1.953473890821139

Epoch: 5| Step: 8
Training loss: 2.2049572467803955
Validation loss: 1.9589802374442418

Epoch: 5| Step: 9
Training loss: 2.275116443634033
Validation loss: 1.9295613517363865

Epoch: 5| Step: 10
Training loss: 1.6288334131240845
Validation loss: 1.9289958228667576

Epoch: 5| Step: 11
Training loss: 2.4152984619140625
Validation loss: 1.9382783969243367

Epoch: 19| Step: 0
Training loss: 2.1062188148498535
Validation loss: 1.9098580280939739

Epoch: 5| Step: 1
Training loss: 1.9186818599700928
Validation loss: 1.9136663327614467

Epoch: 5| Step: 2
Training loss: 1.4550050497055054
Validation loss: 1.9359292089939117

Epoch: 5| Step: 3
Training loss: 2.3483803272247314
Validation loss: 1.9336891770362854

Epoch: 5| Step: 4
Training loss: 1.8537991046905518
Validation loss: 1.9243012766043346

Epoch: 5| Step: 5
Training loss: 2.1642842292785645
Validation loss: 1.9272449413935344

Epoch: 5| Step: 6
Training loss: 1.963595986366272
Validation loss: 1.9296615769465764

Epoch: 5| Step: 7
Training loss: 2.0417110919952393
Validation loss: 1.9224494496981304

Epoch: 5| Step: 8
Training loss: 2.1318860054016113
Validation loss: 1.9222390353679657

Epoch: 5| Step: 9
Training loss: 1.8039162158966064
Validation loss: 1.940921242038409

Epoch: 5| Step: 10
Training loss: 2.0745580196380615
Validation loss: 1.9375225454568863

Epoch: 5| Step: 11
Training loss: 1.4268381595611572
Validation loss: 1.9349266688028972

Epoch: 20| Step: 0
Training loss: 2.1165854930877686
Validation loss: 1.9443908383448918

Epoch: 5| Step: 1
Training loss: 1.861140251159668
Validation loss: 1.9339307149251301

Epoch: 5| Step: 2
Training loss: 1.881282091140747
Validation loss: 1.9546177486578624

Epoch: 5| Step: 3
Training loss: 2.02994441986084
Validation loss: 1.930126965045929

Epoch: 5| Step: 4
Training loss: 1.4518226385116577
Validation loss: 1.9150369117657344

Epoch: 5| Step: 5
Training loss: 1.8759273290634155
Validation loss: 1.9251481145620346

Epoch: 5| Step: 6
Training loss: 2.2456181049346924
Validation loss: 1.9452771842479706

Epoch: 5| Step: 7
Training loss: 1.6181625127792358
Validation loss: 1.9226732850074768

Epoch: 5| Step: 8
Training loss: 1.6995235681533813
Validation loss: 1.9242062171300252

Epoch: 5| Step: 9
Training loss: 2.3658642768859863
Validation loss: 1.94379723072052

Epoch: 5| Step: 10
Training loss: 2.361572742462158
Validation loss: 1.9309345930814743

Epoch: 5| Step: 11
Training loss: 3.2266790866851807
Validation loss: 1.951243778069814

Epoch: 21| Step: 0
Training loss: 2.0783400535583496
Validation loss: 1.9543734242518742

Epoch: 5| Step: 1
Training loss: 1.6826438903808594
Validation loss: 1.9309557974338531

Epoch: 5| Step: 2
Training loss: 2.1731953620910645
Validation loss: 1.9482855126261711

Epoch: 5| Step: 3
Training loss: 1.7336227893829346
Validation loss: 1.9330224593480427

Epoch: 5| Step: 4
Training loss: 2.49190616607666
Validation loss: 1.9254401872555416

Epoch: 5| Step: 5
Training loss: 1.9473775625228882
Validation loss: 1.9138140777746837

Epoch: 5| Step: 6
Training loss: 1.3696959018707275
Validation loss: 1.9345929423967998

Epoch: 5| Step: 7
Training loss: 2.054483413696289
Validation loss: 1.91568357249101

Epoch: 5| Step: 8
Training loss: 1.9435360431671143
Validation loss: 1.9358079532782237

Epoch: 5| Step: 9
Training loss: 2.114504337310791
Validation loss: 1.91640871266524

Epoch: 5| Step: 10
Training loss: 2.17600679397583
Validation loss: 1.907327766219775

Epoch: 5| Step: 11
Training loss: 0.8743528127670288
Validation loss: 1.9243115385373433

Epoch: 22| Step: 0
Training loss: 2.3379225730895996
Validation loss: 1.9230766197045643

Epoch: 5| Step: 1
Training loss: 2.109379529953003
Validation loss: 1.9380979786316554

Epoch: 5| Step: 2
Training loss: 1.450119137763977
Validation loss: 1.9351488103469212

Epoch: 5| Step: 3
Training loss: 2.5486528873443604
Validation loss: 1.931798239549001

Epoch: 5| Step: 4
Training loss: 2.602214813232422
Validation loss: 1.911421646674474

Epoch: 5| Step: 5
Training loss: 1.5051555633544922
Validation loss: 1.9333786120017369

Epoch: 5| Step: 6
Training loss: 1.6278736591339111
Validation loss: 1.9333185752232869

Epoch: 5| Step: 7
Training loss: 2.2140965461730957
Validation loss: 1.9367454797029495

Epoch: 5| Step: 8
Training loss: 1.949605941772461
Validation loss: 1.9650418510039647

Epoch: 5| Step: 9
Training loss: 1.7342455387115479
Validation loss: 1.9571022192637126

Epoch: 5| Step: 10
Training loss: 1.918717622756958
Validation loss: 1.9241332858800888

Epoch: 5| Step: 11
Training loss: 0.24073660373687744
Validation loss: 1.9527970453103383

Epoch: 23| Step: 0
Training loss: 2.1285228729248047
Validation loss: 1.9543433139721553

Epoch: 5| Step: 1
Training loss: 1.9268900156021118
Validation loss: 1.9624328414599101

Epoch: 5| Step: 2
Training loss: 2.509398937225342
Validation loss: 1.9374237060546875

Epoch: 5| Step: 3
Training loss: 1.7265408039093018
Validation loss: 1.9356025358041127

Epoch: 5| Step: 4
Training loss: 1.9682385921478271
Validation loss: 1.9227498074372609

Epoch: 5| Step: 5
Training loss: 1.8805186748504639
Validation loss: 1.9441507458686829

Epoch: 5| Step: 6
Training loss: 1.586431860923767
Validation loss: 1.9400295317173004

Epoch: 5| Step: 7
Training loss: 1.9580501317977905
Validation loss: 1.9549725006024044

Epoch: 5| Step: 8
Training loss: 1.845890760421753
Validation loss: 1.9314398517211278

Epoch: 5| Step: 9
Training loss: 1.8655202388763428
Validation loss: 1.9319394926230113

Epoch: 5| Step: 10
Training loss: 2.1545333862304688
Validation loss: 1.9437225411335628

Epoch: 5| Step: 11
Training loss: 1.7129005193710327
Validation loss: 1.9330256084601085

Epoch: 24| Step: 0
Training loss: 1.8841636180877686
Validation loss: 1.9252896159887314

Epoch: 5| Step: 1
Training loss: 1.7989715337753296
Validation loss: 1.9431566546360652

Epoch: 5| Step: 2
Training loss: 1.6043046712875366
Validation loss: 1.939510593811671

Epoch: 5| Step: 3
Training loss: 2.1156742572784424
Validation loss: 1.931707834204038

Epoch: 5| Step: 4
Training loss: 2.1736578941345215
Validation loss: 1.9338517040014267

Epoch: 5| Step: 5
Training loss: 1.6639865636825562
Validation loss: 1.9351563056310017

Epoch: 5| Step: 6
Training loss: 2.2778127193450928
Validation loss: 1.9589811265468597

Epoch: 5| Step: 7
Training loss: 2.0563526153564453
Validation loss: 1.9532327701648076

Epoch: 5| Step: 8
Training loss: 1.9245965480804443
Validation loss: 1.9556159029404323

Epoch: 5| Step: 9
Training loss: 2.0143189430236816
Validation loss: 1.9824901074171066

Epoch: 5| Step: 10
Training loss: 1.9236910343170166
Validation loss: 1.9866090814272563

Epoch: 5| Step: 11
Training loss: 1.5241332054138184
Validation loss: 1.9700554112593334

Epoch: 25| Step: 0
Training loss: 1.744421362876892
Validation loss: 1.9505187968413036

Epoch: 5| Step: 1
Training loss: 2.2972702980041504
Validation loss: 1.9719423403342564

Epoch: 5| Step: 2
Training loss: 1.4900171756744385
Validation loss: 1.940177008509636

Epoch: 5| Step: 3
Training loss: 1.4790652990341187
Validation loss: 1.9366284708182018

Epoch: 5| Step: 4
Training loss: 1.9107252359390259
Validation loss: 1.9320453504721324

Epoch: 5| Step: 5
Training loss: 2.31097149848938
Validation loss: 1.9530657976865768

Epoch: 5| Step: 6
Training loss: 1.6220048666000366
Validation loss: 1.9064978063106537

Epoch: 5| Step: 7
Training loss: 2.422377586364746
Validation loss: 1.929002155860265

Epoch: 5| Step: 8
Training loss: 2.3814761638641357
Validation loss: 1.932460089524587

Epoch: 5| Step: 9
Training loss: 1.6217552423477173
Validation loss: 1.9440925121307373

Epoch: 5| Step: 10
Training loss: 1.8611290454864502
Validation loss: 1.9343145688374836

Epoch: 5| Step: 11
Training loss: 2.629633665084839
Validation loss: 1.9330944418907166

Epoch: 26| Step: 0
Training loss: 2.070446491241455
Validation loss: 1.9401333232720692

Epoch: 5| Step: 1
Training loss: 1.7889041900634766
Validation loss: 1.9251108815272648

Epoch: 5| Step: 2
Training loss: 1.270366907119751
Validation loss: 1.9411255816618602

Epoch: 5| Step: 3
Training loss: 1.8812793493270874
Validation loss: 1.9443703591823578

Epoch: 5| Step: 4
Training loss: 1.5177009105682373
Validation loss: 1.930140455563863

Epoch: 5| Step: 5
Training loss: 2.346754550933838
Validation loss: 1.9628295997778575

Epoch: 5| Step: 6
Training loss: 1.9304145574569702
Validation loss: 1.9621742218732834

Epoch: 5| Step: 7
Training loss: 1.9120814800262451
Validation loss: 1.9519008348385494

Epoch: 5| Step: 8
Training loss: 2.0745246410369873
Validation loss: 1.9399422109127045

Epoch: 5| Step: 9
Training loss: 2.177891254425049
Validation loss: 1.9524177759885788

Epoch: 5| Step: 10
Training loss: 2.04356050491333
Validation loss: 1.942549819747607

Epoch: 5| Step: 11
Training loss: 2.605618715286255
Validation loss: 1.9316220879554749

Epoch: 27| Step: 0
Training loss: 2.159464120864868
Validation loss: 1.9351697067419689

Epoch: 5| Step: 1
Training loss: 2.1569628715515137
Validation loss: 1.9219560772180557

Epoch: 5| Step: 2
Training loss: 2.042294979095459
Validation loss: 1.9392962257067363

Epoch: 5| Step: 3
Training loss: 1.6945993900299072
Validation loss: 1.9489500969648361

Epoch: 5| Step: 4
Training loss: 2.0585789680480957
Validation loss: 1.9230331579844158

Epoch: 5| Step: 5
Training loss: 2.132514715194702
Validation loss: 1.9268758843342464

Epoch: 5| Step: 6
Training loss: 1.357269525527954
Validation loss: 1.9484895169734955

Epoch: 5| Step: 7
Training loss: 2.1842567920684814
Validation loss: 1.9364475309848785

Epoch: 5| Step: 8
Training loss: 1.7497364282608032
Validation loss: 1.9138429313898087

Epoch: 5| Step: 9
Training loss: 1.9444290399551392
Validation loss: 1.9494673659404118

Epoch: 5| Step: 10
Training loss: 1.6354057788848877
Validation loss: 1.9153751383225124

Epoch: 5| Step: 11
Training loss: 1.8698190450668335
Validation loss: 1.960276837150256

Epoch: 28| Step: 0
Training loss: 1.7107642889022827
Validation loss: 1.9711256176233292

Epoch: 5| Step: 1
Training loss: 1.9576175212860107
Validation loss: 1.9730971107880275

Epoch: 5| Step: 2
Training loss: 1.7935302257537842
Validation loss: 1.9851221193869908

Epoch: 5| Step: 3
Training loss: 2.043348789215088
Validation loss: 2.0049749116102853

Epoch: 5| Step: 4
Training loss: 1.735129714012146
Validation loss: 1.9914784729480743

Epoch: 5| Step: 5
Training loss: 2.3460793495178223
Validation loss: 1.9956338107585907

Epoch: 5| Step: 6
Training loss: 1.5782086849212646
Validation loss: 1.9919163882732391

Epoch: 5| Step: 7
Training loss: 1.8793922662734985
Validation loss: 1.9804671208063762

Epoch: 5| Step: 8
Training loss: 1.939628005027771
Validation loss: 1.9917792230844498

Epoch: 5| Step: 9
Training loss: 1.7047004699707031
Validation loss: 1.9517520268758137

Epoch: 5| Step: 10
Training loss: 2.2660458087921143
Validation loss: 1.9412219325701396

Epoch: 5| Step: 11
Training loss: 2.3064985275268555
Validation loss: 1.9163008481264114

Epoch: 29| Step: 0
Training loss: 2.008171558380127
Validation loss: 1.9154266715049744

Epoch: 5| Step: 1
Training loss: 2.0089316368103027
Validation loss: 1.9220944841702778

Epoch: 5| Step: 2
Training loss: 1.2376705408096313
Validation loss: 1.9061328272024791

Epoch: 5| Step: 3
Training loss: 2.257946491241455
Validation loss: 1.9225105494260788

Epoch: 5| Step: 4
Training loss: 2.1929054260253906
Validation loss: 1.9136859675248463

Epoch: 5| Step: 5
Training loss: 1.634821891784668
Validation loss: 1.933098167181015

Epoch: 5| Step: 6
Training loss: 1.7779827117919922
Validation loss: 1.925931344429652

Epoch: 5| Step: 7
Training loss: 2.342221260070801
Validation loss: 1.9036769717931747

Epoch: 5| Step: 8
Training loss: 1.9371557235717773
Validation loss: 1.9131829937299092

Epoch: 5| Step: 9
Training loss: 2.0944290161132812
Validation loss: 1.9147150218486786

Epoch: 5| Step: 10
Training loss: 1.9407310485839844
Validation loss: 1.9294457634290059

Epoch: 5| Step: 11
Training loss: 1.2728087902069092
Validation loss: 1.9533736358086269

Epoch: 30| Step: 0
Training loss: 1.4858815670013428
Validation loss: 1.934049665927887

Epoch: 5| Step: 1
Training loss: 1.6657860279083252
Validation loss: 1.9215699682633083

Epoch: 5| Step: 2
Training loss: 1.950277328491211
Validation loss: 1.9258073965708415

Epoch: 5| Step: 3
Training loss: 1.8618866205215454
Validation loss: 1.9430813789367676

Epoch: 5| Step: 4
Training loss: 2.158635377883911
Validation loss: 1.9306592295567195

Epoch: 5| Step: 5
Training loss: 2.062199831008911
Validation loss: 1.9021416405836742

Epoch: 5| Step: 6
Training loss: 1.8214857578277588
Validation loss: 1.9241597602764766

Epoch: 5| Step: 7
Training loss: 2.1584010124206543
Validation loss: 1.9289657175540924

Epoch: 5| Step: 8
Training loss: 2.2443413734436035
Validation loss: 1.9383356670538585

Epoch: 5| Step: 9
Training loss: 1.9501965045928955
Validation loss: 1.9247192243734996

Epoch: 5| Step: 10
Training loss: 1.7835086584091187
Validation loss: 1.9481074313322704

Epoch: 5| Step: 11
Training loss: 0.9657883644104004
Validation loss: 1.965920776128769

Epoch: 31| Step: 0
Training loss: 2.4260077476501465
Validation loss: 1.9688871800899506

Epoch: 5| Step: 1
Training loss: 1.8506386280059814
Validation loss: 1.939090073108673

Epoch: 5| Step: 2
Training loss: 1.9871410131454468
Validation loss: 1.9655074526866276

Epoch: 5| Step: 3
Training loss: 1.7815430164337158
Validation loss: 1.9539000938336055

Epoch: 5| Step: 4
Training loss: 2.067875385284424
Validation loss: 1.9289110203584034

Epoch: 5| Step: 5
Training loss: 1.5462433099746704
Validation loss: 1.93536273141702

Epoch: 5| Step: 6
Training loss: 2.104153633117676
Validation loss: 1.91647103925546

Epoch: 5| Step: 7
Training loss: 1.9140825271606445
Validation loss: 1.9098358402649562

Epoch: 5| Step: 8
Training loss: 1.8683621883392334
Validation loss: 1.8846752295891445

Epoch: 5| Step: 9
Training loss: 1.6766401529312134
Validation loss: 1.9231071869532268

Epoch: 5| Step: 10
Training loss: 1.822217583656311
Validation loss: 1.9260206073522568

Epoch: 5| Step: 11
Training loss: 1.6780099868774414
Validation loss: 1.9347579777240753

Epoch: 32| Step: 0
Training loss: 2.8161323070526123
Validation loss: 1.9352268129587173

Epoch: 5| Step: 1
Training loss: 2.231206178665161
Validation loss: 1.9285288353761036

Epoch: 5| Step: 2
Training loss: 1.771112084388733
Validation loss: 1.9186727106571198

Epoch: 5| Step: 3
Training loss: 1.2417232990264893
Validation loss: 1.935788666208585

Epoch: 5| Step: 4
Training loss: 1.5418819189071655
Validation loss: 1.9142090678215027

Epoch: 5| Step: 5
Training loss: 1.9162609577178955
Validation loss: 1.9039040803909302

Epoch: 5| Step: 6
Training loss: 1.7890536785125732
Validation loss: 1.929849882920583

Epoch: 5| Step: 7
Training loss: 2.1266441345214844
Validation loss: 1.9364978869756062

Epoch: 5| Step: 8
Training loss: 1.2737946510314941
Validation loss: 1.9178514530261357

Epoch: 5| Step: 9
Training loss: 2.2379310131073
Validation loss: 1.9577612330516179

Epoch: 5| Step: 10
Training loss: 1.697094202041626
Validation loss: 1.9580994347731273

Epoch: 5| Step: 11
Training loss: 1.4904298782348633
Validation loss: 1.9752613206704457

Epoch: 33| Step: 0
Training loss: 1.7371761798858643
Validation loss: 1.9813686708609264

Epoch: 5| Step: 1
Training loss: 2.1680164337158203
Validation loss: 1.9881075024604797

Epoch: 5| Step: 2
Training loss: 1.7627828121185303
Validation loss: 1.9649618218342464

Epoch: 5| Step: 3
Training loss: 2.2337934970855713
Validation loss: 1.992799202601115

Epoch: 5| Step: 4
Training loss: 1.485347867012024
Validation loss: 1.9845551401376724

Epoch: 5| Step: 5
Training loss: 1.8739843368530273
Validation loss: 1.9534825930992763

Epoch: 5| Step: 6
Training loss: 1.9333209991455078
Validation loss: 1.944854329029719

Epoch: 5| Step: 7
Training loss: 1.519317865371704
Validation loss: 1.943911482890447

Epoch: 5| Step: 8
Training loss: 1.697157621383667
Validation loss: 1.9472032884756725

Epoch: 5| Step: 9
Training loss: 1.9748115539550781
Validation loss: 1.9427541395028431

Epoch: 5| Step: 10
Training loss: 2.482074737548828
Validation loss: 1.950665185848872

Epoch: 5| Step: 11
Training loss: 2.1175694465637207
Validation loss: 1.9439635177453358

Epoch: 34| Step: 0
Training loss: 1.8875945806503296
Validation loss: 1.927337497472763

Epoch: 5| Step: 1
Training loss: 1.6857798099517822
Validation loss: 1.9202909469604492

Epoch: 5| Step: 2
Training loss: 1.7585684061050415
Validation loss: 1.9118820130825043

Epoch: 5| Step: 3
Training loss: 1.7838376760482788
Validation loss: 1.8932058761517208

Epoch: 5| Step: 4
Training loss: 2.0791633129119873
Validation loss: 1.875302031636238

Epoch: 5| Step: 5
Training loss: 1.866329550743103
Validation loss: 1.9189323981602986

Epoch: 5| Step: 6
Training loss: 2.2504382133483887
Validation loss: 1.917619948585828

Epoch: 5| Step: 7
Training loss: 2.5109026432037354
Validation loss: 1.910531813899676

Epoch: 5| Step: 8
Training loss: 1.9319976568222046
Validation loss: 1.9300660292307537

Epoch: 5| Step: 9
Training loss: 1.7498232126235962
Validation loss: 1.911948099732399

Epoch: 5| Step: 10
Training loss: 1.4557527303695679
Validation loss: 1.91173554956913

Epoch: 5| Step: 11
Training loss: 1.3362138271331787
Validation loss: 1.9015333006779354

Epoch: 35| Step: 0
Training loss: 1.4514578580856323
Validation loss: 1.9212910185257595

Epoch: 5| Step: 1
Training loss: 1.4777584075927734
Validation loss: 1.9138387491305668

Epoch: 5| Step: 2
Training loss: 2.0131993293762207
Validation loss: 1.9408423354228337

Epoch: 5| Step: 3
Training loss: 1.697705864906311
Validation loss: 1.934210826953252

Epoch: 5| Step: 4
Training loss: 1.7261264324188232
Validation loss: 1.9633287092049916

Epoch: 5| Step: 5
Training loss: 2.15490460395813
Validation loss: 1.977705289920171

Epoch: 5| Step: 6
Training loss: 1.8836605548858643
Validation loss: 1.959463283419609

Epoch: 5| Step: 7
Training loss: 1.9220263957977295
Validation loss: 1.9600431273380916

Epoch: 5| Step: 8
Training loss: 2.095611572265625
Validation loss: 1.9824973543485005

Epoch: 5| Step: 9
Training loss: 2.0409865379333496
Validation loss: 1.9539723992347717

Epoch: 5| Step: 10
Training loss: 2.296476125717163
Validation loss: 1.9513923078775406

Epoch: 5| Step: 11
Training loss: 1.203322172164917
Validation loss: 1.9455391416947048

Epoch: 36| Step: 0
Training loss: 1.7872211933135986
Validation loss: 1.941706657409668

Epoch: 5| Step: 1
Training loss: 2.5593137741088867
Validation loss: 1.9507103910048802

Epoch: 5| Step: 2
Training loss: 1.6870912313461304
Validation loss: 1.9235060115655263

Epoch: 5| Step: 3
Training loss: 1.9708564281463623
Validation loss: 1.913505772749583

Epoch: 5| Step: 4
Training loss: 2.258756160736084
Validation loss: 1.9226436018943787

Epoch: 5| Step: 5
Training loss: 1.8341262340545654
Validation loss: 1.9028053631385167

Epoch: 5| Step: 6
Training loss: 1.6607692241668701
Validation loss: 1.8940649578968685

Epoch: 5| Step: 7
Training loss: 1.7136554718017578
Validation loss: 1.9096621870994568

Epoch: 5| Step: 8
Training loss: 2.0227391719818115
Validation loss: 1.9148257225751877

Epoch: 5| Step: 9
Training loss: 1.1097160577774048
Validation loss: 1.9351448516050975

Epoch: 5| Step: 10
Training loss: 2.089390277862549
Validation loss: 1.9334473063548405

Epoch: 5| Step: 11
Training loss: 1.7375448942184448
Validation loss: 1.9336534837881725

Epoch: 37| Step: 0
Training loss: 1.7573814392089844
Validation loss: 1.900429680943489

Epoch: 5| Step: 1
Training loss: 2.0401711463928223
Validation loss: 1.9204308191935222

Epoch: 5| Step: 2
Training loss: 1.7483203411102295
Validation loss: 1.9428642342487972

Epoch: 5| Step: 3
Training loss: 2.5712597370147705
Validation loss: 1.9377630452315013

Epoch: 5| Step: 4
Training loss: 1.8611621856689453
Validation loss: 1.9570925136407216

Epoch: 5| Step: 5
Training loss: 1.8986122608184814
Validation loss: 1.931826114654541

Epoch: 5| Step: 6
Training loss: 1.5615025758743286
Validation loss: 1.949421614408493

Epoch: 5| Step: 7
Training loss: 1.6738758087158203
Validation loss: 1.96587469180425

Epoch: 5| Step: 8
Training loss: 2.230668306350708
Validation loss: 1.9320730914672215

Epoch: 5| Step: 9
Training loss: 1.4464142322540283
Validation loss: 1.9143282175064087

Epoch: 5| Step: 10
Training loss: 1.5863730907440186
Validation loss: 1.9232650448878605

Epoch: 5| Step: 11
Training loss: 1.5334616899490356
Validation loss: 1.936375081539154

Epoch: 38| Step: 0
Training loss: 1.7600746154785156
Validation loss: 1.9154377778371174

Epoch: 5| Step: 1
Training loss: 2.2131645679473877
Validation loss: 1.9283687472343445

Epoch: 5| Step: 2
Training loss: 1.8081581592559814
Validation loss: 1.8911748280127842

Epoch: 5| Step: 3
Training loss: 1.7693958282470703
Validation loss: 1.888947069644928

Epoch: 5| Step: 4
Training loss: 1.9957599639892578
Validation loss: 1.8974646230538685

Epoch: 5| Step: 5
Training loss: 1.7928836345672607
Validation loss: 1.9146880010763805

Epoch: 5| Step: 6
Training loss: 2.0605628490448
Validation loss: 1.8893910696109135

Epoch: 5| Step: 7
Training loss: 1.668553113937378
Validation loss: 1.9167089064915974

Epoch: 5| Step: 8
Training loss: 1.995687484741211
Validation loss: 1.9196245620648067

Epoch: 5| Step: 9
Training loss: 1.9706112146377563
Validation loss: 1.8931687573591869

Epoch: 5| Step: 10
Training loss: 1.6146503686904907
Validation loss: 1.9102697521448135

Epoch: 5| Step: 11
Training loss: 1.2175729274749756
Validation loss: 1.9396682679653168

Epoch: 39| Step: 0
Training loss: 1.6372861862182617
Validation loss: 1.9424803008635838

Epoch: 5| Step: 1
Training loss: 1.5595897436141968
Validation loss: 1.9475218256314595

Epoch: 5| Step: 2
Training loss: 1.682178258895874
Validation loss: 1.9412879546483357

Epoch: 5| Step: 3
Training loss: 1.7183609008789062
Validation loss: 1.9386979987223942

Epoch: 5| Step: 4
Training loss: 1.985325813293457
Validation loss: 1.9223402738571167

Epoch: 5| Step: 5
Training loss: 2.1219429969787598
Validation loss: 1.9187454332907994

Epoch: 5| Step: 6
Training loss: 2.0579123497009277
Validation loss: 1.961976448694865

Epoch: 5| Step: 7
Training loss: 1.8176953792572021
Validation loss: 1.9339534093936284

Epoch: 5| Step: 8
Training loss: 1.5524653196334839
Validation loss: 1.928570995728175

Epoch: 5| Step: 9
Training loss: 1.7296979427337646
Validation loss: 1.9285686661799748

Epoch: 5| Step: 10
Training loss: 2.439213752746582
Validation loss: 1.946269194285075

Epoch: 5| Step: 11
Training loss: 2.188802719116211
Validation loss: 1.9405868103106816

Epoch: 40| Step: 0
Training loss: 2.095444440841675
Validation loss: 1.9268615047136943

Epoch: 5| Step: 1
Training loss: 1.9122463464736938
Validation loss: 1.9340678105751674

Epoch: 5| Step: 2
Training loss: 1.9478962421417236
Validation loss: 1.9531864722569783

Epoch: 5| Step: 3
Training loss: 1.739595651626587
Validation loss: 1.9694169114033382

Epoch: 5| Step: 4
Training loss: 1.8648322820663452
Validation loss: 1.9383392632007599

Epoch: 5| Step: 5
Training loss: 1.920474648475647
Validation loss: 1.9142121225595474

Epoch: 5| Step: 6
Training loss: 1.9675648212432861
Validation loss: 1.906546766559283

Epoch: 5| Step: 7
Training loss: 1.5869745016098022
Validation loss: 1.9115228950977325

Epoch: 5| Step: 8
Training loss: 1.8208370208740234
Validation loss: 1.904273842771848

Epoch: 5| Step: 9
Training loss: 1.9311916828155518
Validation loss: 1.9240292062362034

Epoch: 5| Step: 10
Training loss: 1.759158730506897
Validation loss: 1.9128946711619694

Epoch: 5| Step: 11
Training loss: 1.0590131282806396
Validation loss: 1.9127904524405797

Epoch: 41| Step: 0
Training loss: 1.5798771381378174
Validation loss: 1.938858648141225

Epoch: 5| Step: 1
Training loss: 1.9409549236297607
Validation loss: 1.977368175983429

Epoch: 5| Step: 2
Training loss: 1.494214415550232
Validation loss: 1.9624011268218358

Epoch: 5| Step: 3
Training loss: 1.949004888534546
Validation loss: 1.9744114677111309

Epoch: 5| Step: 4
Training loss: 2.943610906600952
Validation loss: 1.9443912853797276

Epoch: 5| Step: 5
Training loss: 1.8075282573699951
Validation loss: 1.9707423100868862

Epoch: 5| Step: 6
Training loss: 1.7776302099227905
Validation loss: 1.9478838195403416

Epoch: 5| Step: 7
Training loss: 1.4373892545700073
Validation loss: 1.9141729672749836

Epoch: 5| Step: 8
Training loss: 2.653193950653076
Validation loss: 1.9213631252447765

Epoch: 5| Step: 9
Training loss: 1.7974885702133179
Validation loss: 1.9051592946052551

Epoch: 5| Step: 10
Training loss: 1.2226923704147339
Validation loss: 1.9118678371111553

Epoch: 5| Step: 11
Training loss: 0.6593794822692871
Validation loss: 1.8936478743950527

Epoch: 42| Step: 0
Training loss: 1.8990399837493896
Validation loss: 1.90872460603714

Epoch: 5| Step: 1
Training loss: 1.7569080591201782
Validation loss: 1.9069940050443013

Epoch: 5| Step: 2
Training loss: 1.3851505517959595
Validation loss: 1.9200985531012218

Epoch: 5| Step: 3
Training loss: 1.3534023761749268
Validation loss: 1.9348707646131516

Epoch: 5| Step: 4
Training loss: 2.1307380199432373
Validation loss: 1.923908198873202

Epoch: 5| Step: 5
Training loss: 2.658186197280884
Validation loss: 1.9479840646187465

Epoch: 5| Step: 6
Training loss: 1.6142762899398804
Validation loss: 1.912983496983846

Epoch: 5| Step: 7
Training loss: 2.095790386199951
Validation loss: 1.9222218543291092

Epoch: 5| Step: 8
Training loss: 1.6884119510650635
Validation loss: 1.9072861621777217

Epoch: 5| Step: 9
Training loss: 1.7471917867660522
Validation loss: 1.9330293983221054

Epoch: 5| Step: 10
Training loss: 1.5760862827301025
Validation loss: 1.9298962950706482

Epoch: 5| Step: 11
Training loss: 2.598170757293701
Validation loss: 1.8989128867785137

Epoch: 43| Step: 0
Training loss: 1.8474756479263306
Validation loss: 1.8944025337696075

Epoch: 5| Step: 1
Training loss: 2.2153313159942627
Validation loss: 1.9076272944609325

Epoch: 5| Step: 2
Training loss: 2.2092182636260986
Validation loss: 1.8995344191789627

Epoch: 5| Step: 3
Training loss: 1.4380098581314087
Validation loss: 1.8881769329309464

Epoch: 5| Step: 4
Training loss: 2.1702136993408203
Validation loss: 1.8773059000571568

Epoch: 5| Step: 5
Training loss: 1.4840927124023438
Validation loss: 1.8971696148316066

Epoch: 5| Step: 6
Training loss: 1.6960750818252563
Validation loss: 1.8902755031983058

Epoch: 5| Step: 7
Training loss: 1.635144829750061
Validation loss: 1.9110109905401866

Epoch: 5| Step: 8
Training loss: 2.044752836227417
Validation loss: 1.9031336257855098

Epoch: 5| Step: 9
Training loss: 2.133767604827881
Validation loss: 1.9008829196294148

Epoch: 5| Step: 10
Training loss: 1.3776476383209229
Validation loss: 1.906888817747434

Epoch: 5| Step: 11
Training loss: 1.7326984405517578
Validation loss: 1.888605664173762

Epoch: 44| Step: 0
Training loss: 1.306605339050293
Validation loss: 1.9328583379586537

Epoch: 5| Step: 1
Training loss: 1.60709547996521
Validation loss: 1.9467042833566666

Epoch: 5| Step: 2
Training loss: 1.3116209506988525
Validation loss: 1.9845157365004222

Epoch: 5| Step: 3
Training loss: 1.731676697731018
Validation loss: 2.028479516506195

Epoch: 5| Step: 4
Training loss: 2.0648903846740723
Validation loss: 2.022880976398786

Epoch: 5| Step: 5
Training loss: 2.86183762550354
Validation loss: 2.041141693790754

Epoch: 5| Step: 6
Training loss: 1.924401044845581
Validation loss: 2.02635025481383

Epoch: 5| Step: 7
Training loss: 2.0151679515838623
Validation loss: 2.00675039490064

Epoch: 5| Step: 8
Training loss: 2.340371608734131
Validation loss: 1.9961699644724529

Epoch: 5| Step: 9
Training loss: 1.8759174346923828
Validation loss: 1.9584855039914448

Epoch: 5| Step: 10
Training loss: 1.896223783493042
Validation loss: 1.9142751793066661

Epoch: 5| Step: 11
Training loss: 1.5501347780227661
Validation loss: 1.9004388103882472

Epoch: 45| Step: 0
Training loss: 1.6369775533676147
Validation loss: 1.9105237623055775

Epoch: 5| Step: 1
Training loss: 2.1500542163848877
Validation loss: 1.8874779393275578

Epoch: 5| Step: 2
Training loss: 1.8071311712265015
Validation loss: 1.8845899899800618

Epoch: 5| Step: 3
Training loss: 1.5254569053649902
Validation loss: 1.9047058473030727

Epoch: 5| Step: 4
Training loss: 1.6187465190887451
Validation loss: 1.8994585474332173

Epoch: 5| Step: 5
Training loss: 1.607400894165039
Validation loss: 1.894703318675359

Epoch: 5| Step: 6
Training loss: 2.117281675338745
Validation loss: 1.90571528673172

Epoch: 5| Step: 7
Training loss: 2.4849305152893066
Validation loss: 1.9307090292374294

Epoch: 5| Step: 8
Training loss: 1.8278605937957764
Validation loss: 1.898428589105606

Epoch: 5| Step: 9
Training loss: 1.3179924488067627
Validation loss: 1.906493956844012

Epoch: 5| Step: 10
Training loss: 2.1351263523101807
Validation loss: 1.9121532291173935

Epoch: 5| Step: 11
Training loss: 1.960450530052185
Validation loss: 1.9486494561036427

Epoch: 46| Step: 0
Training loss: 1.7035471200942993
Validation loss: 1.9507555117209752

Epoch: 5| Step: 1
Training loss: 1.9546512365341187
Validation loss: 1.951468139886856

Epoch: 5| Step: 2
Training loss: 2.0544536113739014
Validation loss: 1.9603837877511978

Epoch: 5| Step: 3
Training loss: 2.0453405380249023
Validation loss: 1.94916333258152

Epoch: 5| Step: 4
Training loss: 1.5628407001495361
Validation loss: 1.9488566915194194

Epoch: 5| Step: 5
Training loss: 1.818902611732483
Validation loss: 1.9722347458203633

Epoch: 5| Step: 6
Training loss: 1.6817293167114258
Validation loss: 1.9424137771129608

Epoch: 5| Step: 7
Training loss: 1.9452276229858398
Validation loss: 1.9573693474133809

Epoch: 5| Step: 8
Training loss: 1.7364925146102905
Validation loss: 1.9417549272378285

Epoch: 5| Step: 9
Training loss: 1.644301176071167
Validation loss: 1.935088997085889

Epoch: 5| Step: 10
Training loss: 1.7719818353652954
Validation loss: 1.8965420971314113

Epoch: 5| Step: 11
Training loss: 2.318300724029541
Validation loss: 1.8921151906251907

Epoch: 47| Step: 0
Training loss: 1.498032569885254
Validation loss: 1.9027617573738098

Epoch: 5| Step: 1
Training loss: 1.363092303276062
Validation loss: 1.8910890122254689

Epoch: 5| Step: 2
Training loss: 2.257377862930298
Validation loss: 1.9210723340511322

Epoch: 5| Step: 3
Training loss: 1.661028265953064
Validation loss: 1.9114679992198944

Epoch: 5| Step: 4
Training loss: 1.7715480327606201
Validation loss: 1.9057237654924393

Epoch: 5| Step: 5
Training loss: 2.338975429534912
Validation loss: 1.9205481559038162

Epoch: 5| Step: 6
Training loss: 1.8449329137802124
Validation loss: 1.904332349697749

Epoch: 5| Step: 7
Training loss: 2.195189952850342
Validation loss: 1.905577505628268

Epoch: 5| Step: 8
Training loss: 1.7861000299453735
Validation loss: 1.9154404451449711

Epoch: 5| Step: 9
Training loss: 2.028494358062744
Validation loss: 1.876768598953883

Epoch: 5| Step: 10
Training loss: 1.841891884803772
Validation loss: 1.891234318415324

Epoch: 5| Step: 11
Training loss: 1.633154273033142
Validation loss: 1.8812779237826665

Epoch: 48| Step: 0
Training loss: 1.514234185218811
Validation loss: 1.888178398211797

Epoch: 5| Step: 1
Training loss: 1.1561250686645508
Validation loss: 1.9256005932887394

Epoch: 5| Step: 2
Training loss: 1.5441968441009521
Validation loss: 1.9237616211175919

Epoch: 5| Step: 3
Training loss: 1.8133128881454468
Validation loss: 1.9110334763924282

Epoch: 5| Step: 4
Training loss: 2.2839713096618652
Validation loss: 1.9426275740067165

Epoch: 5| Step: 5
Training loss: 2.1504299640655518
Validation loss: 1.9505889266729355

Epoch: 5| Step: 6
Training loss: 2.1323764324188232
Validation loss: 1.9470411986112595

Epoch: 5| Step: 7
Training loss: 1.961663842201233
Validation loss: 1.9454785486062367

Epoch: 5| Step: 8
Training loss: 1.810400366783142
Validation loss: 1.9686531523863475

Epoch: 5| Step: 9
Training loss: 1.6365875005722046
Validation loss: 1.9351734568675358

Epoch: 5| Step: 10
Training loss: 1.7206335067749023
Validation loss: 1.9187222222487132

Epoch: 5| Step: 11
Training loss: 1.9173202514648438
Validation loss: 1.9035835713148117

Epoch: 49| Step: 0
Training loss: 2.363964319229126
Validation loss: 1.9123250991106033

Epoch: 5| Step: 1
Training loss: 1.4839190244674683
Validation loss: 1.9171848992506664

Epoch: 5| Step: 2
Training loss: 2.081679105758667
Validation loss: 1.8960188378890355

Epoch: 5| Step: 3
Training loss: 1.41413414478302
Validation loss: 1.9149672786394756

Epoch: 5| Step: 4
Training loss: 1.5463967323303223
Validation loss: 1.915677547454834

Epoch: 5| Step: 5
Training loss: 1.554693579673767
Validation loss: 1.916933958729108

Epoch: 5| Step: 6
Training loss: 1.902793288230896
Validation loss: 1.9007701228062313

Epoch: 5| Step: 7
Training loss: 1.4028198719024658
Validation loss: 1.909314711888631

Epoch: 5| Step: 8
Training loss: 2.330071210861206
Validation loss: 1.9185517330964406

Epoch: 5| Step: 9
Training loss: 2.1993846893310547
Validation loss: 1.9087772766749065

Epoch: 5| Step: 10
Training loss: 1.2831896543502808
Validation loss: 1.9306451578934987

Epoch: 5| Step: 11
Training loss: 1.5396074056625366
Validation loss: 1.920144572854042

Epoch: 50| Step: 0
Training loss: 1.9724338054656982
Validation loss: 1.9007061173518498

Epoch: 5| Step: 1
Training loss: 1.514483094215393
Validation loss: 1.941170612970988

Epoch: 5| Step: 2
Training loss: 1.824014663696289
Validation loss: 1.941704049706459

Epoch: 5| Step: 3
Training loss: 1.690434455871582
Validation loss: 1.9372546672821045

Epoch: 5| Step: 4
Training loss: 1.5092668533325195
Validation loss: 1.9574892322222393

Epoch: 5| Step: 5
Training loss: 2.044334650039673
Validation loss: 1.9337538878122966

Epoch: 5| Step: 6
Training loss: 2.0947883129119873
Validation loss: 1.9823089092969894

Epoch: 5| Step: 7
Training loss: 1.8069366216659546
Validation loss: 1.9607528795798619

Epoch: 5| Step: 8
Training loss: 1.2590452432632446
Validation loss: 1.9338596413532894

Epoch: 5| Step: 9
Training loss: 2.5863330364227295
Validation loss: 1.9450858136018117

Epoch: 5| Step: 10
Training loss: 1.705924391746521
Validation loss: 1.929094557960828

Epoch: 5| Step: 11
Training loss: 1.194873571395874
Validation loss: 1.9318140596151352

Epoch: 51| Step: 0
Training loss: 1.8905941247940063
Validation loss: 1.9233061919609706

Epoch: 5| Step: 1
Training loss: 1.7557523250579834
Validation loss: 1.9049117118120193

Epoch: 5| Step: 2
Training loss: 1.144850492477417
Validation loss: 1.8807382583618164

Epoch: 5| Step: 3
Training loss: 1.152409315109253
Validation loss: 1.8866854061683018

Epoch: 5| Step: 4
Training loss: 1.5129693746566772
Validation loss: 1.8882756282885869

Epoch: 5| Step: 5
Training loss: 1.9491952657699585
Validation loss: 1.9003428469101589

Epoch: 5| Step: 6
Training loss: 2.2259325981140137
Validation loss: 1.8861715545256932

Epoch: 5| Step: 7
Training loss: 2.2927558422088623
Validation loss: 1.8640501499176025

Epoch: 5| Step: 8
Training loss: 1.5831167697906494
Validation loss: 1.9192551523447037

Epoch: 5| Step: 9
Training loss: 1.9447921514511108
Validation loss: 1.8880558361609776

Epoch: 5| Step: 10
Training loss: 2.095322608947754
Validation loss: 1.8987580339113872

Epoch: 5| Step: 11
Training loss: 2.4844813346862793
Validation loss: 1.9283495446046193

Epoch: 52| Step: 0
Training loss: 2.454319715499878
Validation loss: 1.9541644006967545

Epoch: 5| Step: 1
Training loss: 1.182637095451355
Validation loss: 1.9646595120429993

Epoch: 5| Step: 2
Training loss: 1.5509989261627197
Validation loss: 1.956023280819257

Epoch: 5| Step: 3
Training loss: 1.9677693843841553
Validation loss: 1.990147332350413

Epoch: 5| Step: 4
Training loss: 1.4568365812301636
Validation loss: 1.9958473394314449

Epoch: 5| Step: 5
Training loss: 2.396710157394409
Validation loss: 1.9670615543921788

Epoch: 5| Step: 6
Training loss: 1.8979690074920654
Validation loss: 1.9894465059041977

Epoch: 5| Step: 7
Training loss: 1.4322102069854736
Validation loss: 1.971833159526189

Epoch: 5| Step: 8
Training loss: 1.970054268836975
Validation loss: 1.9377884616454442

Epoch: 5| Step: 9
Training loss: 1.752772569656372
Validation loss: 1.893708695967992

Epoch: 5| Step: 10
Training loss: 1.531460165977478
Validation loss: 1.9098447759946187

Epoch: 5| Step: 11
Training loss: 2.2213354110717773
Validation loss: 1.8919856150945027

Epoch: 53| Step: 0
Training loss: 1.960754632949829
Validation loss: 1.9026250541210175

Epoch: 5| Step: 1
Training loss: 1.7134822607040405
Validation loss: 1.8974470098813374

Epoch: 5| Step: 2
Training loss: 2.058032512664795
Validation loss: 1.9285394897063572

Epoch: 5| Step: 3
Training loss: 1.6599414348602295
Validation loss: 1.8908882439136505

Epoch: 5| Step: 4
Training loss: 2.1809773445129395
Validation loss: 1.8722635606924694

Epoch: 5| Step: 5
Training loss: 1.197762131690979
Validation loss: 1.8999821941057842

Epoch: 5| Step: 6
Training loss: 1.187811255455017
Validation loss: 1.9188053260246913

Epoch: 5| Step: 7
Training loss: 1.408638596534729
Validation loss: 1.8901827732721965

Epoch: 5| Step: 8
Training loss: 2.1809325218200684
Validation loss: 1.9017463972171147

Epoch: 5| Step: 9
Training loss: 2.238504648208618
Validation loss: 1.9206870098908742

Epoch: 5| Step: 10
Training loss: 1.5352647304534912
Validation loss: 1.944763387242953

Epoch: 5| Step: 11
Training loss: 3.879910945892334
Validation loss: 1.9208103915055592

Epoch: 54| Step: 0
Training loss: 2.3005447387695312
Validation loss: 1.9054683695236843

Epoch: 5| Step: 1
Training loss: 1.6278297901153564
Validation loss: 1.8868315021197002

Epoch: 5| Step: 2
Training loss: 1.58748459815979
Validation loss: 1.8805811057488124

Epoch: 5| Step: 3
Training loss: 1.8684051036834717
Validation loss: 1.8577700903018315

Epoch: 5| Step: 4
Training loss: 1.0445411205291748
Validation loss: 1.885807454586029

Epoch: 5| Step: 5
Training loss: 2.058201313018799
Validation loss: 1.90281742811203

Epoch: 5| Step: 6
Training loss: 2.102233409881592
Validation loss: 1.8882660965124767

Epoch: 5| Step: 7
Training loss: 2.0197365283966064
Validation loss: 1.8926312774419785

Epoch: 5| Step: 8
Training loss: 1.506568193435669
Validation loss: 1.9088225762049358

Epoch: 5| Step: 9
Training loss: 1.52231764793396
Validation loss: 1.8865147928396861

Epoch: 5| Step: 10
Training loss: 1.8683220148086548
Validation loss: 1.8930313934882481

Epoch: 5| Step: 11
Training loss: 0.9927557706832886
Validation loss: 1.883571873108546

Epoch: 55| Step: 0
Training loss: 2.3271915912628174
Validation loss: 1.9169939011335373

Epoch: 5| Step: 1
Training loss: 1.644336462020874
Validation loss: 1.939097985625267

Epoch: 5| Step: 2
Training loss: 1.9469687938690186
Validation loss: 1.9688613911469777

Epoch: 5| Step: 3
Training loss: 1.6873658895492554
Validation loss: 2.011228024959564

Epoch: 5| Step: 4
Training loss: 1.3498504161834717
Validation loss: 2.0337399542331696

Epoch: 5| Step: 5
Training loss: 2.325232744216919
Validation loss: 2.0541732162237167

Epoch: 5| Step: 6
Training loss: 1.6518418788909912
Validation loss: 1.9928625673055649

Epoch: 5| Step: 7
Training loss: 1.5876238346099854
Validation loss: 1.9890347023804982

Epoch: 5| Step: 8
Training loss: 1.5147854089736938
Validation loss: 1.9558958758910496

Epoch: 5| Step: 9
Training loss: 1.5836232900619507
Validation loss: 1.935055802265803

Epoch: 5| Step: 10
Training loss: 2.424528121948242
Validation loss: 1.9074930648008983

Epoch: 5| Step: 11
Training loss: 0.9975781440734863
Validation loss: 1.9107313454151154

Epoch: 56| Step: 0
Training loss: 2.1081621646881104
Validation loss: 1.903356636563937

Epoch: 5| Step: 1
Training loss: 1.9071365594863892
Validation loss: 1.906251793106397

Epoch: 5| Step: 2
Training loss: 2.6445343494415283
Validation loss: 1.8785062283277512

Epoch: 5| Step: 3
Training loss: 1.6048091650009155
Validation loss: 1.89800563454628

Epoch: 5| Step: 4
Training loss: 1.7672840356826782
Validation loss: 1.896515741944313

Epoch: 5| Step: 5
Training loss: 1.8276020288467407
Validation loss: 1.9027696549892426

Epoch: 5| Step: 6
Training loss: 1.598478078842163
Validation loss: 1.9022136529286702

Epoch: 5| Step: 7
Training loss: 1.2944447994232178
Validation loss: 1.868902603785197

Epoch: 5| Step: 8
Training loss: 1.9963550567626953
Validation loss: 1.8929990530014038

Epoch: 5| Step: 9
Training loss: 1.1761035919189453
Validation loss: 1.8866338034470875

Epoch: 5| Step: 10
Training loss: 1.9477592706680298
Validation loss: 1.9117211451133092

Epoch: 5| Step: 11
Training loss: 1.0299490690231323
Validation loss: 1.9044736127058666

Epoch: 57| Step: 0
Training loss: 2.216155529022217
Validation loss: 1.9361603061358135

Epoch: 5| Step: 1
Training loss: 1.7450653314590454
Validation loss: 1.9487321376800537

Epoch: 5| Step: 2
Training loss: 1.6399418115615845
Validation loss: 1.956782152255376

Epoch: 5| Step: 3
Training loss: 1.6495250463485718
Validation loss: 1.9163654645284016

Epoch: 5| Step: 4
Training loss: 1.9109504222869873
Validation loss: 1.9250560849905014

Epoch: 5| Step: 5
Training loss: 1.4101568460464478
Validation loss: 1.9115411986907322

Epoch: 5| Step: 6
Training loss: 1.405875563621521
Validation loss: 1.9325403521458309

Epoch: 5| Step: 7
Training loss: 1.8696845769882202
Validation loss: 1.926485722263654

Epoch: 5| Step: 8
Training loss: 1.5314910411834717
Validation loss: 1.9002832770347595

Epoch: 5| Step: 9
Training loss: 1.7913272380828857
Validation loss: 1.9154375543196995

Epoch: 5| Step: 10
Training loss: 1.6259502172470093
Validation loss: 1.9225773960351944

Epoch: 5| Step: 11
Training loss: 2.265720844268799
Validation loss: 1.9143526156743367

Epoch: 58| Step: 0
Training loss: 1.9964090585708618
Validation loss: 1.9353123853604

Epoch: 5| Step: 1
Training loss: 1.9790699481964111
Validation loss: 1.9729065597057343

Epoch: 5| Step: 2
Training loss: 2.044513702392578
Validation loss: 1.9865827808777492

Epoch: 5| Step: 3
Training loss: 1.3464677333831787
Validation loss: 1.9467785209417343

Epoch: 5| Step: 4
Training loss: 2.257472515106201
Validation loss: 1.9565624346335728

Epoch: 5| Step: 5
Training loss: 1.7378839254379272
Validation loss: 1.9656738936901093

Epoch: 5| Step: 6
Training loss: 1.543442726135254
Validation loss: 1.9592794328927994

Epoch: 5| Step: 7
Training loss: 1.8382713794708252
Validation loss: 1.9269748280445735

Epoch: 5| Step: 8
Training loss: 1.383301019668579
Validation loss: 1.9044131139914195

Epoch: 5| Step: 9
Training loss: 1.2749178409576416
Validation loss: 1.9124712347984314

Epoch: 5| Step: 10
Training loss: 1.52864670753479
Validation loss: 1.8997734189033508

Epoch: 5| Step: 11
Training loss: 2.203803300857544
Validation loss: 1.9150770157575607

Epoch: 59| Step: 0
Training loss: 1.6613657474517822
Validation loss: 1.8919690599044163

Epoch: 5| Step: 1
Training loss: 1.9427436590194702
Validation loss: 1.9199836701154709

Epoch: 5| Step: 2
Training loss: 1.9679629802703857
Validation loss: 1.8922507564226787

Epoch: 5| Step: 3
Training loss: 1.4209545850753784
Validation loss: 1.9300157576799393

Epoch: 5| Step: 4
Training loss: 1.3487738370895386
Validation loss: 1.9238906651735306

Epoch: 5| Step: 5
Training loss: 1.3968546390533447
Validation loss: 1.9169482737779617

Epoch: 5| Step: 6
Training loss: 1.6076570749282837
Validation loss: 1.9086019198099773

Epoch: 5| Step: 7
Training loss: 1.9339221715927124
Validation loss: 1.9256841590007145

Epoch: 5| Step: 8
Training loss: 1.646324872970581
Validation loss: 1.9426150818665822

Epoch: 5| Step: 9
Training loss: 2.3730907440185547
Validation loss: 1.9631481071313222

Epoch: 5| Step: 10
Training loss: 1.7254425287246704
Validation loss: 1.9664999544620514

Epoch: 5| Step: 11
Training loss: 2.1338729858398438
Validation loss: 1.963894451657931

Epoch: 60| Step: 0
Training loss: 1.5642868280410767
Validation loss: 1.9378000597159069

Epoch: 5| Step: 1
Training loss: 2.0833067893981934
Validation loss: 1.9055340389410655

Epoch: 5| Step: 2
Training loss: 2.0090348720550537
Validation loss: 1.919475977619489

Epoch: 5| Step: 3
Training loss: 1.539767861366272
Validation loss: 1.9018838554620743

Epoch: 5| Step: 4
Training loss: 1.808490514755249
Validation loss: 1.901609127720197

Epoch: 5| Step: 5
Training loss: 2.1099660396575928
Validation loss: 1.9228851248820622

Epoch: 5| Step: 6
Training loss: 0.887275218963623
Validation loss: 1.914464071393013

Epoch: 5| Step: 7
Training loss: 1.9983813762664795
Validation loss: 1.8913445721069972

Epoch: 5| Step: 8
Training loss: 1.6551129817962646
Validation loss: 1.9098843038082123

Epoch: 5| Step: 9
Training loss: 1.5521800518035889
Validation loss: 1.8902472953001659

Epoch: 5| Step: 10
Training loss: 1.7975155115127563
Validation loss: 1.921403576930364

Epoch: 5| Step: 11
Training loss: 1.4821621179580688
Validation loss: 1.8985997140407562

Epoch: 61| Step: 0
Training loss: 2.0738444328308105
Validation loss: 1.8949026217063267

Epoch: 5| Step: 1
Training loss: 1.4400641918182373
Validation loss: 1.9163912534713745

Epoch: 5| Step: 2
Training loss: 1.3551032543182373
Validation loss: 1.9079982936382294

Epoch: 5| Step: 3
Training loss: 2.752678394317627
Validation loss: 1.9135450174411137

Epoch: 5| Step: 4
Training loss: 1.3801803588867188
Validation loss: 1.9177584548791249

Epoch: 5| Step: 5
Training loss: 1.608191728591919
Validation loss: 1.9024830361207326

Epoch: 5| Step: 6
Training loss: 1.4219282865524292
Validation loss: 1.9208017736673355

Epoch: 5| Step: 7
Training loss: 1.8850809335708618
Validation loss: 1.905460039774577

Epoch: 5| Step: 8
Training loss: 1.8234007358551025
Validation loss: 1.8940504391988118

Epoch: 5| Step: 9
Training loss: 1.2338368892669678
Validation loss: 1.8862490952014923

Epoch: 5| Step: 10
Training loss: 1.5824400186538696
Validation loss: 1.9054626127084096

Epoch: 5| Step: 11
Training loss: 1.8692452907562256
Validation loss: 1.9055098642905552

Epoch: 62| Step: 0
Training loss: 1.4613392353057861
Validation loss: 1.9011306415001552

Epoch: 5| Step: 1
Training loss: 1.6356357336044312
Validation loss: 1.9170857965946198

Epoch: 5| Step: 2
Training loss: 2.2704968452453613
Validation loss: 1.918528214097023

Epoch: 5| Step: 3
Training loss: 2.1593756675720215
Validation loss: 1.9625483800967534

Epoch: 5| Step: 4
Training loss: 1.4595187902450562
Validation loss: 1.9532690346240997

Epoch: 5| Step: 5
Training loss: 1.4880995750427246
Validation loss: 1.9342450102170308

Epoch: 5| Step: 6
Training loss: 1.5018727779388428
Validation loss: 1.9611153999964397

Epoch: 5| Step: 7
Training loss: 1.8156216144561768
Validation loss: 1.9564711550871532

Epoch: 5| Step: 8
Training loss: 1.4540578126907349
Validation loss: 1.9363852093617122

Epoch: 5| Step: 9
Training loss: 1.976770043373108
Validation loss: 1.9108345955610275

Epoch: 5| Step: 10
Training loss: 1.4907329082489014
Validation loss: 1.917390947540601

Epoch: 5| Step: 11
Training loss: 1.7810876369476318
Validation loss: 1.9193192968765895

Epoch: 63| Step: 0
Training loss: 2.0655438899993896
Validation loss: 1.9082588007052739

Epoch: 5| Step: 1
Training loss: 1.6872053146362305
Validation loss: 1.8708738287289937

Epoch: 5| Step: 2
Training loss: 1.6567426919937134
Validation loss: 1.9038774073123932

Epoch: 5| Step: 3
Training loss: 1.1989418268203735
Validation loss: 1.9103519320487976

Epoch: 5| Step: 4
Training loss: 1.3309096097946167
Validation loss: 1.9026025136311848

Epoch: 5| Step: 5
Training loss: 1.4889456033706665
Validation loss: 1.9071650058031082

Epoch: 5| Step: 6
Training loss: 2.127089738845825
Validation loss: 1.9008314609527588

Epoch: 5| Step: 7
Training loss: 1.808436632156372
Validation loss: 1.9250513315200806

Epoch: 5| Step: 8
Training loss: 1.5150808095932007
Validation loss: 1.9074144313732784

Epoch: 5| Step: 9
Training loss: 1.791790246963501
Validation loss: 1.9598414202531178

Epoch: 5| Step: 10
Training loss: 2.2060353755950928
Validation loss: 1.9289903690417607

Epoch: 5| Step: 11
Training loss: 0.5017787218093872
Validation loss: 1.9510140866041183

Epoch: 64| Step: 0
Training loss: 1.449851393699646
Validation loss: 1.9442351857821147

Epoch: 5| Step: 1
Training loss: 2.1767964363098145
Validation loss: 1.9175680081049602

Epoch: 5| Step: 2
Training loss: 1.6497433185577393
Validation loss: 1.9086120426654816

Epoch: 5| Step: 3
Training loss: 1.3991349935531616
Validation loss: 1.9242863555749257

Epoch: 5| Step: 4
Training loss: 1.9174003601074219
Validation loss: 1.9041960487763088

Epoch: 5| Step: 5
Training loss: 1.5167783498764038
Validation loss: 1.9000953137874603

Epoch: 5| Step: 6
Training loss: 2.2758281230926514
Validation loss: 1.9340148121118546

Epoch: 5| Step: 7
Training loss: 1.3913090229034424
Validation loss: 1.9086730380853016

Epoch: 5| Step: 8
Training loss: 1.609626054763794
Validation loss: 1.9270626952250798

Epoch: 5| Step: 9
Training loss: 1.9919427633285522
Validation loss: 1.9074437568585079

Epoch: 5| Step: 10
Training loss: 1.8305017948150635
Validation loss: 1.8747882843017578

Epoch: 5| Step: 11
Training loss: 1.2006020545959473
Validation loss: 1.9138739009698231

Epoch: 65| Step: 0
Training loss: 1.538146734237671
Validation loss: 1.8923770487308502

Epoch: 5| Step: 1
Training loss: 1.0890085697174072
Validation loss: 1.947662353515625

Epoch: 5| Step: 2
Training loss: 2.0535454750061035
Validation loss: 1.9160288621981938

Epoch: 5| Step: 3
Training loss: 1.593184232711792
Validation loss: 1.9563868393500645

Epoch: 5| Step: 4
Training loss: 2.0295498371124268
Validation loss: 1.9632634470860164

Epoch: 5| Step: 5
Training loss: 1.9497277736663818
Validation loss: 1.960946465531985

Epoch: 5| Step: 6
Training loss: 1.8066341876983643
Validation loss: 2.0161333779493966

Epoch: 5| Step: 7
Training loss: 1.618739366531372
Validation loss: 1.9773752590020497

Epoch: 5| Step: 8
Training loss: 1.870139718055725
Validation loss: 1.9222742915153503

Epoch: 5| Step: 9
Training loss: 1.3310438394546509
Validation loss: 1.9423119326432545

Epoch: 5| Step: 10
Training loss: 1.986415147781372
Validation loss: 1.9378565748532612

Epoch: 5| Step: 11
Training loss: 1.122013807296753
Validation loss: 1.8839794496695201

Epoch: 66| Step: 0
Training loss: 2.1645073890686035
Validation loss: 1.8625915000836055

Epoch: 5| Step: 1
Training loss: 1.5532536506652832
Validation loss: 1.908155192931493

Epoch: 5| Step: 2
Training loss: 1.3230922222137451
Validation loss: 1.880651871363322

Epoch: 5| Step: 3
Training loss: 2.0025992393493652
Validation loss: 1.9104056109984715

Epoch: 5| Step: 4
Training loss: 1.7889190912246704
Validation loss: 1.9181078275044758

Epoch: 5| Step: 5
Training loss: 1.4498106241226196
Validation loss: 1.9067836503187816

Epoch: 5| Step: 6
Training loss: 1.015409231185913
Validation loss: 1.9177297453085582

Epoch: 5| Step: 7
Training loss: 1.3804223537445068
Validation loss: 1.9320073078076045

Epoch: 5| Step: 8
Training loss: 1.3914988040924072
Validation loss: 1.9352181355158489

Epoch: 5| Step: 9
Training loss: 1.5192997455596924
Validation loss: 1.9223399261633556

Epoch: 5| Step: 10
Training loss: 2.3541526794433594
Validation loss: 1.9462616244951885

Epoch: 5| Step: 11
Training loss: 1.9207855463027954
Validation loss: 1.9218209733565648

Epoch: 67| Step: 0
Training loss: 1.415743112564087
Validation loss: 1.970910981297493

Epoch: 5| Step: 1
Training loss: 1.5665475130081177
Validation loss: 1.9508274793624878

Epoch: 5| Step: 2
Training loss: 1.537262201309204
Validation loss: 1.9483935832977295

Epoch: 5| Step: 3
Training loss: 1.7487633228302002
Validation loss: 1.9150026539961498

Epoch: 5| Step: 4
Training loss: 1.348548412322998
Validation loss: 1.9136107315619786

Epoch: 5| Step: 5
Training loss: 1.9629065990447998
Validation loss: 1.9272166440884273

Epoch: 5| Step: 6
Training loss: 1.416075587272644
Validation loss: 1.8997217069069545

Epoch: 5| Step: 7
Training loss: 1.6875784397125244
Validation loss: 1.9216216107209523

Epoch: 5| Step: 8
Training loss: 1.8073982000350952
Validation loss: 1.9111881256103516

Epoch: 5| Step: 9
Training loss: 1.9951789379119873
Validation loss: 1.907074158390363

Epoch: 5| Step: 10
Training loss: 1.5727018117904663
Validation loss: 1.889264737566312

Epoch: 5| Step: 11
Training loss: 2.296229600906372
Validation loss: 1.9120280345280964

Epoch: 68| Step: 0
Training loss: 1.8346989154815674
Validation loss: 1.8986945450305939

Epoch: 5| Step: 1
Training loss: 0.9838230013847351
Validation loss: 1.9025195688009262

Epoch: 5| Step: 2
Training loss: 1.94796621799469
Validation loss: 1.9200608332951863

Epoch: 5| Step: 3
Training loss: 2.0283682346343994
Validation loss: 1.8883047997951508

Epoch: 5| Step: 4
Training loss: 0.9138447046279907
Validation loss: 1.9119960963726044

Epoch: 5| Step: 5
Training loss: 1.4985120296478271
Validation loss: 1.9043951878945033

Epoch: 5| Step: 6
Training loss: 0.7837553024291992
Validation loss: 1.9204746385415394

Epoch: 5| Step: 7
Training loss: 2.2484230995178223
Validation loss: 1.9055252919594448

Epoch: 5| Step: 8
Training loss: 1.9643990993499756
Validation loss: 1.9467667043209076

Epoch: 5| Step: 9
Training loss: 2.0136072635650635
Validation loss: 1.9390805512666702

Epoch: 5| Step: 10
Training loss: 2.029658079147339
Validation loss: 1.9284849713246028

Epoch: 5| Step: 11
Training loss: 0.5802624821662903
Validation loss: 1.9583460142215092

Epoch: 69| Step: 0
Training loss: 1.2224606275558472
Validation loss: 1.9122129728396733

Epoch: 5| Step: 1
Training loss: 1.3111670017242432
Validation loss: 1.905265857776006

Epoch: 5| Step: 2
Training loss: 1.5508754253387451
Validation loss: 1.8687149633963902

Epoch: 5| Step: 3
Training loss: 1.2051299810409546
Validation loss: 1.8953343629837036

Epoch: 5| Step: 4
Training loss: 1.7915769815444946
Validation loss: 1.894596482316653

Epoch: 5| Step: 5
Training loss: 1.4865537881851196
Validation loss: 1.8863868862390518

Epoch: 5| Step: 6
Training loss: 1.6495161056518555
Validation loss: 1.9144049485524495

Epoch: 5| Step: 7
Training loss: 1.926580786705017
Validation loss: 1.849402313431104

Epoch: 5| Step: 8
Training loss: 1.8949925899505615
Validation loss: 1.8910512675841649

Epoch: 5| Step: 9
Training loss: 2.4638166427612305
Validation loss: 1.8868185579776764

Epoch: 5| Step: 10
Training loss: 1.4145548343658447
Validation loss: 1.9061245620250702

Epoch: 5| Step: 11
Training loss: 1.5223674774169922
Validation loss: 1.8883170982201893

Epoch: 70| Step: 0
Training loss: 1.38918137550354
Validation loss: 1.9059521853923798

Epoch: 5| Step: 1
Training loss: 1.324887990951538
Validation loss: 1.9118315229813259

Epoch: 5| Step: 2
Training loss: 1.2508327960968018
Validation loss: 1.8924515148003895

Epoch: 5| Step: 3
Training loss: 1.6018768548965454
Validation loss: 1.9092605312665303

Epoch: 5| Step: 4
Training loss: 2.0011982917785645
Validation loss: 1.9144922544558842

Epoch: 5| Step: 5
Training loss: 1.8340266942977905
Validation loss: 1.9161444505055745

Epoch: 5| Step: 6
Training loss: 1.492422342300415
Validation loss: 1.9261432488759358

Epoch: 5| Step: 7
Training loss: 2.0046486854553223
Validation loss: 1.885041818022728

Epoch: 5| Step: 8
Training loss: 1.113869071006775
Validation loss: 1.9580452144145966

Epoch: 5| Step: 9
Training loss: 1.521842360496521
Validation loss: 1.9087059944868088

Epoch: 5| Step: 10
Training loss: 2.065502882003784
Validation loss: 1.9199689030647278

Epoch: 5| Step: 11
Training loss: 1.241591453552246
Validation loss: 1.9474659115076065

Epoch: 71| Step: 0
Training loss: 1.3873558044433594
Validation loss: 1.8893605371316273

Epoch: 5| Step: 1
Training loss: 1.263734221458435
Validation loss: 1.8988166948159535

Epoch: 5| Step: 2
Training loss: 1.528723120689392
Validation loss: 1.8994583288828533

Epoch: 5| Step: 3
Training loss: 1.6227128505706787
Validation loss: 1.8808567623297374

Epoch: 5| Step: 4
Training loss: 1.799506425857544
Validation loss: 1.864418124159177

Epoch: 5| Step: 5
Training loss: 1.4924993515014648
Validation loss: 1.884685496489207

Epoch: 5| Step: 6
Training loss: 2.1317763328552246
Validation loss: 1.9109577784935634

Epoch: 5| Step: 7
Training loss: 2.258025884628296
Validation loss: 1.8890161166588466

Epoch: 5| Step: 8
Training loss: 1.6799978017807007
Validation loss: 1.9100789378086727

Epoch: 5| Step: 9
Training loss: 1.2612611055374146
Validation loss: 1.9543037513891857

Epoch: 5| Step: 10
Training loss: 1.215387225151062
Validation loss: 1.9443223377068837

Epoch: 5| Step: 11
Training loss: 1.191243290901184
Validation loss: 1.9484789123137791

Epoch: 72| Step: 0
Training loss: 1.1246511936187744
Validation loss: 1.9349619696537654

Epoch: 5| Step: 1
Training loss: 1.6595373153686523
Validation loss: 1.9234028855959575

Epoch: 5| Step: 2
Training loss: 1.1159929037094116
Validation loss: 1.907536695400874

Epoch: 5| Step: 3
Training loss: 1.2043672800064087
Validation loss: 1.9114266534646351

Epoch: 5| Step: 4
Training loss: 1.3770883083343506
Validation loss: 1.8570628265539806

Epoch: 5| Step: 5
Training loss: 1.9641988277435303
Validation loss: 1.8752258270978928

Epoch: 5| Step: 6
Training loss: 2.077805995941162
Validation loss: 1.9042546848456066

Epoch: 5| Step: 7
Training loss: 1.7905746698379517
Validation loss: 1.8893804103136063

Epoch: 5| Step: 8
Training loss: 1.6680068969726562
Validation loss: 1.9087075144052505

Epoch: 5| Step: 9
Training loss: 1.5130901336669922
Validation loss: 1.9037013550599415

Epoch: 5| Step: 10
Training loss: 1.7058134078979492
Validation loss: 1.8863156338532765

Epoch: 5| Step: 11
Training loss: 2.8043041229248047
Validation loss: 1.9277230550845463

Epoch: 73| Step: 0
Training loss: 1.3880351781845093
Validation loss: 1.9382921705643337

Epoch: 5| Step: 1
Training loss: 1.645066499710083
Validation loss: 1.9369967530171077

Epoch: 5| Step: 2
Training loss: 1.6495472192764282
Validation loss: 1.9343139827251434

Epoch: 5| Step: 3
Training loss: 1.2093865871429443
Validation loss: 1.9637580464283626

Epoch: 5| Step: 4
Training loss: 1.6669981479644775
Validation loss: 1.9279099603494008

Epoch: 5| Step: 5
Training loss: 1.3441234827041626
Validation loss: 1.9810311198234558

Epoch: 5| Step: 6
Training loss: 1.4625558853149414
Validation loss: 1.8890276650587718

Epoch: 5| Step: 7
Training loss: 1.2226979732513428
Validation loss: 1.9013315439224243

Epoch: 5| Step: 8
Training loss: 2.136834144592285
Validation loss: 1.8919165631135304

Epoch: 5| Step: 9
Training loss: 1.6736339330673218
Validation loss: 1.8960486402114232

Epoch: 5| Step: 10
Training loss: 2.058346748352051
Validation loss: 1.928637410203616

Epoch: 5| Step: 11
Training loss: 1.7277005910873413
Validation loss: 1.898333306113879

Epoch: 74| Step: 0
Training loss: 1.8743202686309814
Validation loss: 1.906100129087766

Epoch: 5| Step: 1
Training loss: 1.9112945795059204
Validation loss: 1.922812670469284

Epoch: 5| Step: 2
Training loss: 1.6365687847137451
Validation loss: 1.8922396798928578

Epoch: 5| Step: 3
Training loss: 1.3393638134002686
Validation loss: 1.8919626375039418

Epoch: 5| Step: 4
Training loss: 1.4194471836090088
Validation loss: 1.9164244681596756

Epoch: 5| Step: 5
Training loss: 1.5721079111099243
Validation loss: 1.862999493877093

Epoch: 5| Step: 6
Training loss: 1.4570496082305908
Validation loss: 1.9058051804701488

Epoch: 5| Step: 7
Training loss: 1.281420111656189
Validation loss: 1.9102837443351746

Epoch: 5| Step: 8
Training loss: 1.4599100351333618
Validation loss: 1.9374010612567265

Epoch: 5| Step: 9
Training loss: 2.049755573272705
Validation loss: 1.921597143014272

Epoch: 5| Step: 10
Training loss: 1.881761908531189
Validation loss: 1.9446394095818202

Epoch: 5| Step: 11
Training loss: 0.7222439050674438
Validation loss: 1.9897425721089046

Epoch: 75| Step: 0
Training loss: 1.7274024486541748
Validation loss: 1.9353891462087631

Epoch: 5| Step: 1
Training loss: 2.009821891784668
Validation loss: 1.8965155730644863

Epoch: 5| Step: 2
Training loss: 0.9449513554573059
Validation loss: 1.9332769761482875

Epoch: 5| Step: 3
Training loss: 1.5286074876785278
Validation loss: 1.908423165480296

Epoch: 5| Step: 4
Training loss: 1.5580580234527588
Validation loss: 1.901812916000684

Epoch: 5| Step: 5
Training loss: 1.9753738641738892
Validation loss: 1.9058151841163635

Epoch: 5| Step: 6
Training loss: 1.688055396080017
Validation loss: 1.910152902205785

Epoch: 5| Step: 7
Training loss: 1.521310567855835
Validation loss: 1.9040263791879017

Epoch: 5| Step: 8
Training loss: 1.332223653793335
Validation loss: 1.8934535483519237

Epoch: 5| Step: 9
Training loss: 1.5480130910873413
Validation loss: 1.8962538838386536

Epoch: 5| Step: 10
Training loss: 1.303572416305542
Validation loss: 1.9246351271867752

Epoch: 5| Step: 11
Training loss: 1.179608941078186
Validation loss: 1.9089673658212025

Epoch: 76| Step: 0
Training loss: 1.6020853519439697
Validation loss: 1.940492292245229

Epoch: 5| Step: 1
Training loss: 1.6337049007415771
Validation loss: 1.895282119512558

Epoch: 5| Step: 2
Training loss: 1.7340209484100342
Validation loss: 1.9483983516693115

Epoch: 5| Step: 3
Training loss: 1.8270914554595947
Validation loss: 1.93449301024278

Epoch: 5| Step: 4
Training loss: 0.884703516960144
Validation loss: 1.9140016535917919

Epoch: 5| Step: 5
Training loss: 1.6118247509002686
Validation loss: 1.9488824357589085

Epoch: 5| Step: 6
Training loss: 1.6632635593414307
Validation loss: 1.918948769569397

Epoch: 5| Step: 7
Training loss: 1.5403329133987427
Validation loss: 1.917828028400739

Epoch: 5| Step: 8
Training loss: 1.396512746810913
Validation loss: 1.867597982287407

Epoch: 5| Step: 9
Training loss: 1.488940954208374
Validation loss: 1.9034200360377629

Epoch: 5| Step: 10
Training loss: 1.4934730529785156
Validation loss: 1.887190580368042

Epoch: 5| Step: 11
Training loss: 1.4661482572555542
Validation loss: 1.932274654507637

Epoch: 77| Step: 0
Training loss: 1.4723173379898071
Validation loss: 1.9055608063936234

Epoch: 5| Step: 1
Training loss: 1.3678202629089355
Validation loss: 1.8876545478900273

Epoch: 5| Step: 2
Training loss: 1.2400963306427002
Validation loss: 1.8879549304644268

Epoch: 5| Step: 3
Training loss: 1.8838403224945068
Validation loss: 1.9356680462757747

Epoch: 5| Step: 4
Training loss: 1.738946557044983
Validation loss: 1.9100679208834965

Epoch: 5| Step: 5
Training loss: 1.606850028038025
Validation loss: 1.86216539144516

Epoch: 5| Step: 6
Training loss: 1.6595176458358765
Validation loss: 1.859215905268987

Epoch: 5| Step: 7
Training loss: 1.2545400857925415
Validation loss: 1.8861062278350194

Epoch: 5| Step: 8
Training loss: 1.416569709777832
Validation loss: 1.906126320362091

Epoch: 5| Step: 9
Training loss: 1.7290964126586914
Validation loss: 1.9073730011781056

Epoch: 5| Step: 10
Training loss: 1.8073270320892334
Validation loss: 1.9082909276088078

Epoch: 5| Step: 11
Training loss: 0.8771829009056091
Validation loss: 1.9406107167402904

Epoch: 78| Step: 0
Training loss: 1.439658761024475
Validation loss: 1.9239593197902043

Epoch: 5| Step: 1
Training loss: 1.1258991956710815
Validation loss: 1.935041790207227

Epoch: 5| Step: 2
Training loss: 1.7335822582244873
Validation loss: 1.9473630090554555

Epoch: 5| Step: 3
Training loss: 1.6608936786651611
Validation loss: 1.8970238268375397

Epoch: 5| Step: 4
Training loss: 2.044238567352295
Validation loss: 1.9095028539498646

Epoch: 5| Step: 5
Training loss: 1.3646135330200195
Validation loss: 1.9003427525361378

Epoch: 5| Step: 6
Training loss: 1.9590717554092407
Validation loss: 1.895720213651657

Epoch: 5| Step: 7
Training loss: 1.4176251888275146
Validation loss: 1.8526417414347331

Epoch: 5| Step: 8
Training loss: 1.3821637630462646
Validation loss: 1.8830071190992992

Epoch: 5| Step: 9
Training loss: 1.3385257720947266
Validation loss: 1.8618421604235966

Epoch: 5| Step: 10
Training loss: 1.3608850240707397
Validation loss: 1.8894085139036179

Epoch: 5| Step: 11
Training loss: 2.1022448539733887
Validation loss: 1.8927056789398193

Epoch: 79| Step: 0
Training loss: 2.0163638591766357
Validation loss: 1.9407623956600826

Epoch: 5| Step: 1
Training loss: 1.5467150211334229
Validation loss: 1.9295508861541748

Epoch: 5| Step: 2
Training loss: 1.0195953845977783
Validation loss: 1.9915620187918346

Epoch: 5| Step: 3
Training loss: 2.0314018726348877
Validation loss: 1.9635397146145503

Epoch: 5| Step: 4
Training loss: 1.725115180015564
Validation loss: 1.9828604211409886

Epoch: 5| Step: 5
Training loss: 1.4447593688964844
Validation loss: 1.9207423776388168

Epoch: 5| Step: 6
Training loss: 1.3815793991088867
Validation loss: 1.8682763079802196

Epoch: 5| Step: 7
Training loss: 1.8176543712615967
Validation loss: 1.8672410150369008

Epoch: 5| Step: 8
Training loss: 1.334419846534729
Validation loss: 1.8880231380462646

Epoch: 5| Step: 9
Training loss: 1.738141417503357
Validation loss: 1.8729119896888733

Epoch: 5| Step: 10
Training loss: 1.2056922912597656
Validation loss: 1.8826921085516612

Epoch: 5| Step: 11
Training loss: 1.11588454246521
Validation loss: 1.8832651575406392

Epoch: 80| Step: 0
Training loss: 1.910555124282837
Validation loss: 1.8828567415475845

Epoch: 5| Step: 1
Training loss: 1.1909111738204956
Validation loss: 1.8925852328538895

Epoch: 5| Step: 2
Training loss: 1.5473642349243164
Validation loss: 1.876055618127187

Epoch: 5| Step: 3
Training loss: 1.2202914953231812
Validation loss: 1.8913948734601338

Epoch: 5| Step: 4
Training loss: 1.8068645000457764
Validation loss: 1.9365287224451702

Epoch: 5| Step: 5
Training loss: 1.2620974779129028
Validation loss: 1.9279177139202754

Epoch: 5| Step: 6
Training loss: 1.4899461269378662
Validation loss: 1.9472636928160985

Epoch: 5| Step: 7
Training loss: 1.5303213596343994
Validation loss: 1.9522244036197662

Epoch: 5| Step: 8
Training loss: 1.64300537109375
Validation loss: 1.9271709869305294

Epoch: 5| Step: 9
Training loss: 1.5736628770828247
Validation loss: 1.9003315766652424

Epoch: 5| Step: 10
Training loss: 1.1330211162567139
Validation loss: 1.9130897770325344

Epoch: 5| Step: 11
Training loss: 2.2775425910949707
Validation loss: 1.8951153010129929

Epoch: 81| Step: 0
Training loss: 1.3403565883636475
Validation loss: 1.884425272544225

Epoch: 5| Step: 1
Training loss: 1.5998730659484863
Validation loss: 1.8904022723436356

Epoch: 5| Step: 2
Training loss: 1.82756769657135
Validation loss: 1.8797857612371445

Epoch: 5| Step: 3
Training loss: 1.4337313175201416
Validation loss: 1.8722130010525386

Epoch: 5| Step: 4
Training loss: 1.6190201044082642
Validation loss: 1.8836414813995361

Epoch: 5| Step: 5
Training loss: 1.4246175289154053
Validation loss: 1.9062478641668956

Epoch: 5| Step: 6
Training loss: 1.3044984340667725
Validation loss: 1.8950658688942592

Epoch: 5| Step: 7
Training loss: 1.7814462184906006
Validation loss: 1.8856985767682393

Epoch: 5| Step: 8
Training loss: 1.288235068321228
Validation loss: 1.9021150569121044

Epoch: 5| Step: 9
Training loss: 1.5675451755523682
Validation loss: 1.9324897527694702

Epoch: 5| Step: 10
Training loss: 1.1218852996826172
Validation loss: 1.957915872335434

Epoch: 5| Step: 11
Training loss: 1.316923975944519
Validation loss: 1.908735677599907

Epoch: 82| Step: 0
Training loss: 1.250970721244812
Validation loss: 1.9247562636931737

Epoch: 5| Step: 1
Training loss: 1.3954194784164429
Validation loss: 1.90768696864446

Epoch: 5| Step: 2
Training loss: 1.1995351314544678
Validation loss: 1.9279175053040187

Epoch: 5| Step: 3
Training loss: 1.743133544921875
Validation loss: 1.8911862174669902

Epoch: 5| Step: 4
Training loss: 1.4864734411239624
Validation loss: 1.8878270536661148

Epoch: 5| Step: 5
Training loss: 1.8619940280914307
Validation loss: 1.9011559436718624

Epoch: 5| Step: 6
Training loss: 1.1903557777404785
Validation loss: 1.8399305194616318

Epoch: 5| Step: 7
Training loss: 0.7574748992919922
Validation loss: 1.8898065934578578

Epoch: 5| Step: 8
Training loss: 1.7162967920303345
Validation loss: 1.8912639915943146

Epoch: 5| Step: 9
Training loss: 1.0548957586288452
Validation loss: 1.8950485040744145

Epoch: 5| Step: 10
Training loss: 1.9459221363067627
Validation loss: 1.8607345273097355

Epoch: 5| Step: 11
Training loss: 2.5598061084747314
Validation loss: 1.8543963382641475

Epoch: 83| Step: 0
Training loss: 2.1997599601745605
Validation loss: 1.9005666275819142

Epoch: 5| Step: 1
Training loss: 1.5877922773361206
Validation loss: 1.8928559670845668

Epoch: 5| Step: 2
Training loss: 0.8938918113708496
Validation loss: 1.9063909302155178

Epoch: 5| Step: 3
Training loss: 2.125397205352783
Validation loss: 1.898241639137268

Epoch: 5| Step: 4
Training loss: 1.196312427520752
Validation loss: 1.8876526355743408

Epoch: 5| Step: 5
Training loss: 1.113936185836792
Validation loss: 1.8756384005149205

Epoch: 5| Step: 6
Training loss: 1.116875410079956
Validation loss: 1.8413841277360916

Epoch: 5| Step: 7
Training loss: 1.0994539260864258
Validation loss: 1.906557410955429

Epoch: 5| Step: 8
Training loss: 1.2188775539398193
Validation loss: 1.8958101272583008

Epoch: 5| Step: 9
Training loss: 1.1151411533355713
Validation loss: 1.8701175302267075

Epoch: 5| Step: 10
Training loss: 1.891227126121521
Validation loss: 1.897008294860522

Epoch: 5| Step: 11
Training loss: 0.6903853416442871
Validation loss: 1.8867481648921967

Epoch: 84| Step: 0
Training loss: 1.3695176839828491
Validation loss: 1.8813067823648453

Epoch: 5| Step: 1
Training loss: 1.7088422775268555
Validation loss: 1.8881759097178776

Epoch: 5| Step: 2
Training loss: 1.5331671237945557
Validation loss: 1.866437589128812

Epoch: 5| Step: 3
Training loss: 1.9862390756607056
Validation loss: 1.8776812106370926

Epoch: 5| Step: 4
Training loss: 1.6405109167099
Validation loss: 1.886250267426173

Epoch: 5| Step: 5
Training loss: 1.7058961391448975
Validation loss: 1.866336817542712

Epoch: 5| Step: 6
Training loss: 0.6985101699829102
Validation loss: 1.8783041040102642

Epoch: 5| Step: 7
Training loss: 1.377947449684143
Validation loss: 1.9179026782512665

Epoch: 5| Step: 8
Training loss: 1.4287065267562866
Validation loss: 1.9032310495773952

Epoch: 5| Step: 9
Training loss: 1.010061264038086
Validation loss: 1.9061399747927983

Epoch: 5| Step: 10
Training loss: 1.3063597679138184
Validation loss: 1.8891900777816772

Epoch: 5| Step: 11
Training loss: 3.5983617305755615
Validation loss: 1.8985306024551392

Epoch: 85| Step: 0
Training loss: 1.5814168453216553
Validation loss: 1.854998141527176

Epoch: 5| Step: 1
Training loss: 1.084484338760376
Validation loss: 1.889232650399208

Epoch: 5| Step: 2
Training loss: 1.968501091003418
Validation loss: 1.8583814452091854

Epoch: 5| Step: 3
Training loss: 1.015974998474121
Validation loss: 1.8801947236061096

Epoch: 5| Step: 4
Training loss: 1.3918983936309814
Validation loss: 1.8734217782815297

Epoch: 5| Step: 5
Training loss: 1.5722415447235107
Validation loss: 1.8611722340186436

Epoch: 5| Step: 6
Training loss: 1.270220160484314
Validation loss: 1.9152767211198807

Epoch: 5| Step: 7
Training loss: 1.7947988510131836
Validation loss: 1.883436957995097

Epoch: 5| Step: 8
Training loss: 1.563279390335083
Validation loss: 1.908103217681249

Epoch: 5| Step: 9
Training loss: 1.195476770401001
Validation loss: 1.8889698485533397

Epoch: 5| Step: 10
Training loss: 1.470069169998169
Validation loss: 1.8692642102638881

Epoch: 5| Step: 11
Training loss: 0.47007620334625244
Validation loss: 1.8901886095603306

Epoch: 86| Step: 0
Training loss: 1.6694749593734741
Validation loss: 1.8634948531786601

Epoch: 5| Step: 1
Training loss: 1.4080302715301514
Validation loss: 1.9044801344474156

Epoch: 5| Step: 2
Training loss: 2.2295048236846924
Validation loss: 1.9181381712357204

Epoch: 5| Step: 3
Training loss: 1.5056352615356445
Validation loss: 1.9109348903099697

Epoch: 5| Step: 4
Training loss: 0.9114359021186829
Validation loss: 1.899305244286855

Epoch: 5| Step: 5
Training loss: 1.4760684967041016
Validation loss: 1.8753760953744252

Epoch: 5| Step: 6
Training loss: 0.9959294199943542
Validation loss: 1.8899989426136017

Epoch: 5| Step: 7
Training loss: 1.535553216934204
Validation loss: 1.888166422645251

Epoch: 5| Step: 8
Training loss: 1.1155197620391846
Validation loss: 1.8717296123504639

Epoch: 5| Step: 9
Training loss: 1.2184782028198242
Validation loss: 1.887500951687495

Epoch: 5| Step: 10
Training loss: 1.4204347133636475
Validation loss: 1.8555218329032261

Epoch: 5| Step: 11
Training loss: 1.9434938430786133
Validation loss: 1.8686823447545369

Epoch: 87| Step: 0
Training loss: 1.4047902822494507
Validation loss: 1.9159242709477742

Epoch: 5| Step: 1
Training loss: 1.6953332424163818
Validation loss: 1.9321878651777904

Epoch: 5| Step: 2
Training loss: 1.7976877689361572
Validation loss: 1.917280559738477

Epoch: 5| Step: 3
Training loss: 0.7452369928359985
Validation loss: 1.8993822981913884

Epoch: 5| Step: 4
Training loss: 1.6411129236221313
Validation loss: 1.8935985664526622

Epoch: 5| Step: 5
Training loss: 1.3437714576721191
Validation loss: 1.8659431437651317

Epoch: 5| Step: 6
Training loss: 1.4988815784454346
Validation loss: 1.8769272913535435

Epoch: 5| Step: 7
Training loss: 1.3807798624038696
Validation loss: 1.8879987746477127

Epoch: 5| Step: 8
Training loss: 1.0995187759399414
Validation loss: 1.8695651988188426

Epoch: 5| Step: 9
Training loss: 1.8340685367584229
Validation loss: 1.8658029188712437

Epoch: 5| Step: 10
Training loss: 0.9769496917724609
Validation loss: 1.9013546109199524

Epoch: 5| Step: 11
Training loss: 1.7147035598754883
Validation loss: 1.9211265047391255

Epoch: 88| Step: 0
Training loss: 0.9905169606208801
Validation loss: 1.9409813582897186

Epoch: 5| Step: 1
Training loss: 1.3572596311569214
Validation loss: 1.9684349695841472

Epoch: 5| Step: 2
Training loss: 1.7612674236297607
Validation loss: 1.9255692561467488

Epoch: 5| Step: 3
Training loss: 1.1431410312652588
Validation loss: 1.9373835076888402

Epoch: 5| Step: 4
Training loss: 1.4306775331497192
Validation loss: 1.8782657186190288

Epoch: 5| Step: 5
Training loss: 1.6282840967178345
Validation loss: 1.8686413417259853

Epoch: 5| Step: 6
Training loss: 1.5820591449737549
Validation loss: 1.8530022650957108

Epoch: 5| Step: 7
Training loss: 1.7779006958007812
Validation loss: 1.8686591982841492

Epoch: 5| Step: 8
Training loss: 1.346677541732788
Validation loss: 1.8517542978127797

Epoch: 5| Step: 9
Training loss: 1.4370452165603638
Validation loss: 1.8688171704610188

Epoch: 5| Step: 10
Training loss: 1.2669925689697266
Validation loss: 1.8613576740026474

Epoch: 5| Step: 11
Training loss: 2.7017745971679688
Validation loss: 1.8713878641525905

Epoch: 89| Step: 0
Training loss: 1.3462576866149902
Validation loss: 1.8663040101528168

Epoch: 5| Step: 1
Training loss: 1.7170864343643188
Validation loss: 1.8851505319277446

Epoch: 5| Step: 2
Training loss: 1.4831531047821045
Validation loss: 1.884858752290408

Epoch: 5| Step: 3
Training loss: 1.3134098052978516
Validation loss: 1.9016651660203934

Epoch: 5| Step: 4
Training loss: 1.56365168094635
Validation loss: 1.8699316928784053

Epoch: 5| Step: 5
Training loss: 1.2828543186187744
Validation loss: 1.9502914349238079

Epoch: 5| Step: 6
Training loss: 1.480095386505127
Validation loss: 1.9571583569049835

Epoch: 5| Step: 7
Training loss: 1.4992504119873047
Validation loss: 1.9150555084149044

Epoch: 5| Step: 8
Training loss: 1.6051527261734009
Validation loss: 1.911411573489507

Epoch: 5| Step: 9
Training loss: 0.9560089111328125
Validation loss: 1.87898255387942

Epoch: 5| Step: 10
Training loss: 0.7966720461845398
Validation loss: 1.8689185082912445

Epoch: 5| Step: 11
Training loss: 2.7118496894836426
Validation loss: 1.8716143518686295

Epoch: 90| Step: 0
Training loss: 1.1743396520614624
Validation loss: 1.901842365662257

Epoch: 5| Step: 1
Training loss: 0.981889545917511
Validation loss: 1.861448938647906

Epoch: 5| Step: 2
Training loss: 1.5578601360321045
Validation loss: 1.9055117170015972

Epoch: 5| Step: 3
Training loss: 1.912438988685608
Validation loss: 1.8472196410099666

Epoch: 5| Step: 4
Training loss: 1.7252857685089111
Validation loss: 1.8724392304817836

Epoch: 5| Step: 5
Training loss: 1.1508055925369263
Validation loss: 1.874938557545344

Epoch: 5| Step: 6
Training loss: 1.5161077976226807
Validation loss: 1.9007211526234944

Epoch: 5| Step: 7
Training loss: 1.2457109689712524
Validation loss: 1.9028607110182445

Epoch: 5| Step: 8
Training loss: 1.2317523956298828
Validation loss: 1.9011022100845973

Epoch: 5| Step: 9
Training loss: 1.381361722946167
Validation loss: 1.934016560514768

Epoch: 5| Step: 10
Training loss: 0.9984787702560425
Validation loss: 1.8749275207519531

Epoch: 5| Step: 11
Training loss: 2.177999496459961
Validation loss: 1.9532596568266551

Epoch: 91| Step: 0
Training loss: 1.001403570175171
Validation loss: 1.8987135539452236

Epoch: 5| Step: 1
Training loss: 1.9364980459213257
Validation loss: 1.9116468926270802

Epoch: 5| Step: 2
Training loss: 1.2773343324661255
Validation loss: 1.90572027862072

Epoch: 5| Step: 3
Training loss: 0.6021296381950378
Validation loss: 1.8909393846988678

Epoch: 5| Step: 4
Training loss: 1.1683279275894165
Validation loss: 1.8932936191558838

Epoch: 5| Step: 5
Training loss: 1.6895904541015625
Validation loss: 1.9102788617213566

Epoch: 5| Step: 6
Training loss: 1.807122826576233
Validation loss: 1.9008541703224182

Epoch: 5| Step: 7
Training loss: 1.8677688837051392
Validation loss: 1.9091572264830272

Epoch: 5| Step: 8
Training loss: 1.1138843297958374
Validation loss: 1.8939090718825657

Epoch: 5| Step: 9
Training loss: 1.1295255422592163
Validation loss: 1.85291684170564

Epoch: 5| Step: 10
Training loss: 1.1776130199432373
Validation loss: 1.8858058899641037

Epoch: 5| Step: 11
Training loss: 1.2743072509765625
Validation loss: 1.8869259059429169

Epoch: 92| Step: 0
Training loss: 1.8318449258804321
Validation loss: 1.8902310182650883

Epoch: 5| Step: 1
Training loss: 1.3315569162368774
Validation loss: 1.8982478628555934

Epoch: 5| Step: 2
Training loss: 1.4972198009490967
Validation loss: 1.8851407567660015

Epoch: 5| Step: 3
Training loss: 0.6094145774841309
Validation loss: 1.878204549352328

Epoch: 5| Step: 4
Training loss: 0.9214340448379517
Validation loss: 1.9159232477347057

Epoch: 5| Step: 5
Training loss: 1.672824501991272
Validation loss: 1.8789545843998592

Epoch: 5| Step: 6
Training loss: 1.7040830850601196
Validation loss: 1.8750554025173187

Epoch: 5| Step: 7
Training loss: 1.0088233947753906
Validation loss: 1.8704610417286556

Epoch: 5| Step: 8
Training loss: 1.3713985681533813
Validation loss: 1.8710990697145462

Epoch: 5| Step: 9
Training loss: 1.2098816633224487
Validation loss: 1.893518974383672

Epoch: 5| Step: 10
Training loss: 1.6387102603912354
Validation loss: 1.9076443016529083

Epoch: 5| Step: 11
Training loss: 0.20075857639312744
Validation loss: 1.863723819454511

Epoch: 93| Step: 0
Training loss: 1.2541637420654297
Validation loss: 1.8767147759596507

Epoch: 5| Step: 1
Training loss: 1.764096975326538
Validation loss: 1.8925697108109791

Epoch: 5| Step: 2
Training loss: 1.7126731872558594
Validation loss: 1.864604189991951

Epoch: 5| Step: 3
Training loss: 1.2107324600219727
Validation loss: 1.8932416041692097

Epoch: 5| Step: 4
Training loss: 1.294895887374878
Validation loss: 1.8572632869084675

Epoch: 5| Step: 5
Training loss: 2.084961414337158
Validation loss: 1.8642940272887547

Epoch: 5| Step: 6
Training loss: 1.1074187755584717
Validation loss: 1.8762717346350353

Epoch: 5| Step: 7
Training loss: 1.4694850444793701
Validation loss: 1.8790268898010254

Epoch: 5| Step: 8
Training loss: 1.207558512687683
Validation loss: 1.9162359188000362

Epoch: 5| Step: 9
Training loss: 0.7369595766067505
Validation loss: 1.9532163441181183

Epoch: 5| Step: 10
Training loss: 1.1476227045059204
Validation loss: 1.9520328789949417

Epoch: 5| Step: 11
Training loss: 0.443098247051239
Validation loss: 1.931058297554652

Epoch: 94| Step: 0
Training loss: 1.0966341495513916
Validation loss: 1.9199207375446956

Epoch: 5| Step: 1
Training loss: 1.323311448097229
Validation loss: 1.9365365306536357

Epoch: 5| Step: 2
Training loss: 1.414353370666504
Validation loss: 1.8876000146071117

Epoch: 5| Step: 3
Training loss: 1.1973092555999756
Validation loss: 1.8709433128436406

Epoch: 5| Step: 4
Training loss: 1.6513311862945557
Validation loss: 1.8331490904092789

Epoch: 5| Step: 5
Training loss: 1.031561255455017
Validation loss: 1.8555468022823334

Epoch: 5| Step: 6
Training loss: 0.8451412320137024
Validation loss: 1.8792147090037663

Epoch: 5| Step: 7
Training loss: 1.7236188650131226
Validation loss: 1.8686174700657527

Epoch: 5| Step: 8
Training loss: 0.9823368787765503
Validation loss: 1.868902365366618

Epoch: 5| Step: 9
Training loss: 1.3662415742874146
Validation loss: 1.8965106556812923

Epoch: 5| Step: 10
Training loss: 1.8959472179412842
Validation loss: 1.8926383058230083

Epoch: 5| Step: 11
Training loss: 1.5207419395446777
Validation loss: 1.868331864476204

Epoch: 95| Step: 0
Training loss: 1.1877648830413818
Validation loss: 1.9605433543523152

Epoch: 5| Step: 1
Training loss: 1.869593620300293
Validation loss: 2.007050628463427

Epoch: 5| Step: 2
Training loss: 1.070378303527832
Validation loss: 1.972763826449712

Epoch: 5| Step: 3
Training loss: 0.9148498773574829
Validation loss: 1.8987168222665787

Epoch: 5| Step: 4
Training loss: 1.7392202615737915
Validation loss: 1.9100577980279922

Epoch: 5| Step: 5
Training loss: 1.0714457035064697
Validation loss: 1.8804839948813121

Epoch: 5| Step: 6
Training loss: 1.5247738361358643
Validation loss: 1.8447746088107426

Epoch: 5| Step: 7
Training loss: 1.2480254173278809
Validation loss: 1.8735201557477315

Epoch: 5| Step: 8
Training loss: 1.5354903936386108
Validation loss: 1.8699353486299515

Epoch: 5| Step: 9
Training loss: 1.659947156906128
Validation loss: 1.8647796859343846

Epoch: 5| Step: 10
Training loss: 1.2089451551437378
Validation loss: 1.8795143614212673

Epoch: 5| Step: 11
Training loss: 0.7337520122528076
Validation loss: 1.8525793105363846

Epoch: 96| Step: 0
Training loss: 1.5011106729507446
Validation loss: 1.9146510312954585

Epoch: 5| Step: 1
Training loss: 1.0322461128234863
Validation loss: 1.8914896696805954

Epoch: 5| Step: 2
Training loss: 1.331666350364685
Validation loss: 1.912506436308225

Epoch: 5| Step: 3
Training loss: 1.9393116235733032
Validation loss: 1.9008075594902039

Epoch: 5| Step: 4
Training loss: 1.6532037258148193
Validation loss: 1.9198582818110783

Epoch: 5| Step: 5
Training loss: 1.0499804019927979
Validation loss: 1.8991030951340993

Epoch: 5| Step: 6
Training loss: 1.2609102725982666
Validation loss: 1.9461211661497753

Epoch: 5| Step: 7
Training loss: 0.8731613159179688
Validation loss: 1.9093342969814937

Epoch: 5| Step: 8
Training loss: 0.9218495488166809
Validation loss: 1.9397805829842885

Epoch: 5| Step: 9
Training loss: 1.1594740152359009
Validation loss: 1.8636337220668793

Epoch: 5| Step: 10
Training loss: 1.448761224746704
Validation loss: 1.8197010705868404

Epoch: 5| Step: 11
Training loss: 1.3785642385482788
Validation loss: 1.8755130569140117

Epoch: 97| Step: 0
Training loss: 1.3281819820404053
Validation loss: 1.8789777358373005

Epoch: 5| Step: 1
Training loss: 1.050299048423767
Validation loss: 1.8806293507417042

Epoch: 5| Step: 2
Training loss: 0.9682647585868835
Validation loss: 1.9098986933628719

Epoch: 5| Step: 3
Training loss: 0.8173050880432129
Validation loss: 1.946552996834119

Epoch: 5| Step: 4
Training loss: 1.1465795040130615
Validation loss: 1.951966514190038

Epoch: 5| Step: 5
Training loss: 1.6058241128921509
Validation loss: 1.9459644208351772

Epoch: 5| Step: 6
Training loss: 1.5997247695922852
Validation loss: 1.9342475533485413

Epoch: 5| Step: 7
Training loss: 0.981315016746521
Validation loss: 1.9528273443380992

Epoch: 5| Step: 8
Training loss: 0.9188602566719055
Validation loss: 1.9159916092952092

Epoch: 5| Step: 9
Training loss: 1.5754644870758057
Validation loss: 1.9177302022775014

Epoch: 5| Step: 10
Training loss: 2.5917341709136963
Validation loss: 1.880776196718216

Epoch: 5| Step: 11
Training loss: 0.3924172520637512
Validation loss: 1.8735336015621822

Epoch: 98| Step: 0
Training loss: 1.199699878692627
Validation loss: 1.8769654383261998

Epoch: 5| Step: 1
Training loss: 0.9804019927978516
Validation loss: 1.9061778088410695

Epoch: 5| Step: 2
Training loss: 1.5963103771209717
Validation loss: 1.8818889210621517

Epoch: 5| Step: 3
Training loss: 1.3486018180847168
Validation loss: 1.9136449346939723

Epoch: 5| Step: 4
Training loss: 1.1171488761901855
Validation loss: 1.9350876410802205

Epoch: 5| Step: 5
Training loss: 0.7445884346961975
Validation loss: 1.9145640979210536

Epoch: 5| Step: 6
Training loss: 1.2522937059402466
Validation loss: 1.9079953879117966

Epoch: 5| Step: 7
Training loss: 1.5329290628433228
Validation loss: 1.9474968711535137

Epoch: 5| Step: 8
Training loss: 1.8127886056900024
Validation loss: 1.8858622858921688

Epoch: 5| Step: 9
Training loss: 1.4203240871429443
Validation loss: 1.9166102856397629

Epoch: 5| Step: 10
Training loss: 1.1843135356903076
Validation loss: 1.87133785088857

Epoch: 5| Step: 11
Training loss: 1.1365642547607422
Validation loss: 1.8781899809837341

Epoch: 99| Step: 0
Training loss: 1.3954217433929443
Validation loss: 1.8853121101856232

Epoch: 5| Step: 1
Training loss: 1.0847111940383911
Validation loss: 1.902906248966853

Epoch: 5| Step: 2
Training loss: 1.033410906791687
Validation loss: 1.901731014251709

Epoch: 5| Step: 3
Training loss: 1.0510671138763428
Validation loss: 1.9094827423493068

Epoch: 5| Step: 4
Training loss: 0.9929755926132202
Validation loss: 1.917878543337186

Epoch: 5| Step: 5
Training loss: 1.6419836282730103
Validation loss: 1.9361073325077693

Epoch: 5| Step: 6
Training loss: 1.6280062198638916
Validation loss: 1.9667981763680775

Epoch: 5| Step: 7
Training loss: 1.0183862447738647
Validation loss: 1.8978979339202244

Epoch: 5| Step: 8
Training loss: 1.4030790328979492
Validation loss: 1.908287098010381

Epoch: 5| Step: 9
Training loss: 1.4200968742370605
Validation loss: 1.913875659306844

Epoch: 5| Step: 10
Training loss: 1.1507949829101562
Validation loss: 1.8807627459367116

Epoch: 5| Step: 11
Training loss: 0.8157434463500977
Validation loss: 1.8706801235675812

Epoch: 100| Step: 0
Training loss: 1.7163217067718506
Validation loss: 1.892726644873619

Epoch: 5| Step: 1
Training loss: 1.2442550659179688
Validation loss: 1.9053099155426025

Epoch: 5| Step: 2
Training loss: 0.9213430285453796
Validation loss: 1.9318141639232635

Epoch: 5| Step: 3
Training loss: 1.3461081981658936
Validation loss: 1.903755282362302

Epoch: 5| Step: 4
Training loss: 1.270405650138855
Validation loss: 1.8917368749777477

Epoch: 5| Step: 5
Training loss: 1.2858771085739136
Validation loss: 1.948235809803009

Epoch: 5| Step: 6
Training loss: 0.9379032254219055
Validation loss: 1.947464590271314

Epoch: 5| Step: 7
Training loss: 1.1117334365844727
Validation loss: 1.978611797094345

Epoch: 5| Step: 8
Training loss: 1.9509670734405518
Validation loss: 1.9214906146128972

Epoch: 5| Step: 9
Training loss: 1.1039154529571533
Validation loss: 1.9076201220353444

Epoch: 5| Step: 10
Training loss: 0.7153359651565552
Validation loss: 1.8910115510225296

Epoch: 5| Step: 11
Training loss: 1.4243148565292358
Validation loss: 1.878725787003835

Epoch: 101| Step: 0
Training loss: 1.3415333032608032
Validation loss: 1.9188580612341564

Epoch: 5| Step: 1
Training loss: 1.1078325510025024
Validation loss: 1.9365230798721313

Epoch: 5| Step: 2
Training loss: 1.405475378036499
Validation loss: 1.8997700214385986

Epoch: 5| Step: 3
Training loss: 1.3398903608322144
Validation loss: 1.8965464731057484

Epoch: 5| Step: 4
Training loss: 1.2322604656219482
Validation loss: 1.919096867243449

Epoch: 5| Step: 5
Training loss: 1.7995010614395142
Validation loss: 1.8917792687813442

Epoch: 5| Step: 6
Training loss: 0.8482924699783325
Validation loss: 1.939298336704572

Epoch: 5| Step: 7
Training loss: 0.9166545867919922
Validation loss: 1.9531390964984894

Epoch: 5| Step: 8
Training loss: 0.8923540115356445
Validation loss: 1.932902490099271

Epoch: 5| Step: 9
Training loss: 1.6086609363555908
Validation loss: 1.928124229113261

Epoch: 5| Step: 10
Training loss: 1.2380266189575195
Validation loss: 1.9541307389736176

Epoch: 5| Step: 11
Training loss: 1.6557834148406982
Validation loss: 1.9529549777507782

Epoch: 102| Step: 0
Training loss: 1.30523681640625
Validation loss: 1.9035132477680843

Epoch: 5| Step: 1
Training loss: 0.9816594123840332
Validation loss: 1.883614147702853

Epoch: 5| Step: 2
Training loss: 1.019094705581665
Validation loss: 1.8940499424934387

Epoch: 5| Step: 3
Training loss: 1.1435565948486328
Validation loss: 1.900451938311259

Epoch: 5| Step: 4
Training loss: 1.2727172374725342
Validation loss: 1.9178477277358372

Epoch: 5| Step: 5
Training loss: 1.4550377130508423
Validation loss: 1.9387827416261036

Epoch: 5| Step: 6
Training loss: 1.579184651374817
Validation loss: 1.9191862841447194

Epoch: 5| Step: 7
Training loss: 1.137041449546814
Validation loss: 1.9451606770356495

Epoch: 5| Step: 8
Training loss: 1.6985347270965576
Validation loss: 1.945988729596138

Epoch: 5| Step: 9
Training loss: 1.3589372634887695
Validation loss: 1.9644820739825566

Epoch: 5| Step: 10
Training loss: 0.839235782623291
Validation loss: 1.9746665507555008

Epoch: 5| Step: 11
Training loss: 1.9420443773269653
Validation loss: 1.9445033719142277

Epoch: 103| Step: 0
Training loss: 1.0129539966583252
Validation loss: 2.000578741232554

Epoch: 5| Step: 1
Training loss: 1.502797245979309
Validation loss: 1.9514307777086894

Epoch: 5| Step: 2
Training loss: 0.8331281542778015
Validation loss: 1.9352872967720032

Epoch: 5| Step: 3
Training loss: 1.7376739978790283
Validation loss: 1.9602147092421849

Epoch: 5| Step: 4
Training loss: 0.7685672044754028
Validation loss: 1.9101348370313644

Epoch: 5| Step: 5
Training loss: 0.7949717044830322
Validation loss: 1.907805581887563

Epoch: 5| Step: 6
Training loss: 1.0905842781066895
Validation loss: 1.8918273200591404

Epoch: 5| Step: 7
Training loss: 1.2241472005844116
Validation loss: 1.8793497929970424

Epoch: 5| Step: 8
Training loss: 1.7163845300674438
Validation loss: 1.922489772240321

Epoch: 5| Step: 9
Training loss: 1.4560267925262451
Validation loss: 1.9408965806166332

Epoch: 5| Step: 10
Training loss: 0.9215818643569946
Validation loss: 1.9109069108963013

Epoch: 5| Step: 11
Training loss: 1.6812548637390137
Validation loss: 1.9553877959648769

Epoch: 104| Step: 0
Training loss: 1.3269166946411133
Validation loss: 1.9170732448498409

Epoch: 5| Step: 1
Training loss: 1.3072900772094727
Validation loss: 1.906578466296196

Epoch: 5| Step: 2
Training loss: 1.0733590126037598
Validation loss: 1.898056800166766

Epoch: 5| Step: 3
Training loss: 1.218555212020874
Validation loss: 1.959425797065099

Epoch: 5| Step: 4
Training loss: 1.259966492652893
Validation loss: 1.9122799634933472

Epoch: 5| Step: 5
Training loss: 0.9951542019844055
Validation loss: 1.8855941394964855

Epoch: 5| Step: 6
Training loss: 0.8762556314468384
Validation loss: 1.8390349249045055

Epoch: 5| Step: 7
Training loss: 1.5107322931289673
Validation loss: 1.9264018336931865

Epoch: 5| Step: 8
Training loss: 1.569080114364624
Validation loss: 1.8605779459079106

Epoch: 5| Step: 9
Training loss: 0.7477889657020569
Validation loss: 1.8541991263628006

Epoch: 5| Step: 10
Training loss: 1.2425353527069092
Validation loss: 1.8908114284276962

Epoch: 5| Step: 11
Training loss: 1.5793886184692383
Validation loss: 1.891092946132024

Epoch: 105| Step: 0
Training loss: 0.8784656524658203
Validation loss: 1.9148881981770198

Epoch: 5| Step: 1
Training loss: 1.0075972080230713
Validation loss: 1.9103723019361496

Epoch: 5| Step: 2
Training loss: 1.5686190128326416
Validation loss: 1.8727450172106426

Epoch: 5| Step: 3
Training loss: 1.4200401306152344
Validation loss: 1.906358112891515

Epoch: 5| Step: 4
Training loss: 1.1657941341400146
Validation loss: 1.92654088139534

Epoch: 5| Step: 5
Training loss: 0.7583723068237305
Validation loss: 1.9387151102224986

Epoch: 5| Step: 6
Training loss: 1.1883118152618408
Validation loss: 1.885816365480423

Epoch: 5| Step: 7
Training loss: 1.2946321964263916
Validation loss: 1.8726570804913838

Epoch: 5| Step: 8
Training loss: 1.1401569843292236
Validation loss: 1.8799944669008255

Epoch: 5| Step: 9
Training loss: 1.6666021347045898
Validation loss: 1.8858362038930256

Epoch: 5| Step: 10
Training loss: 0.8543099164962769
Validation loss: 1.8689681837956111

Epoch: 5| Step: 11
Training loss: 1.7998077869415283
Validation loss: 1.8541427006324132

Epoch: 106| Step: 0
Training loss: 0.9893361926078796
Validation loss: 1.8944850862026215

Epoch: 5| Step: 1
Training loss: 1.2857067584991455
Validation loss: 1.8753118564685185

Epoch: 5| Step: 2
Training loss: 0.8486318588256836
Validation loss: 1.873871813217799

Epoch: 5| Step: 3
Training loss: 1.1902577877044678
Validation loss: 1.8939268638690312

Epoch: 5| Step: 4
Training loss: 1.418583631515503
Validation loss: 1.8938490847746532

Epoch: 5| Step: 5
Training loss: 1.2645885944366455
Validation loss: 1.9065432796875637

Epoch: 5| Step: 6
Training loss: 1.2597837448120117
Validation loss: 1.87860669195652

Epoch: 5| Step: 7
Training loss: 1.1000803709030151
Validation loss: 1.9296038895845413

Epoch: 5| Step: 8
Training loss: 1.3265026807785034
Validation loss: 1.844699611266454

Epoch: 5| Step: 9
Training loss: 0.6607412099838257
Validation loss: 1.9346817831198375

Epoch: 5| Step: 10
Training loss: 1.4596664905548096
Validation loss: 1.8756581842899323

Epoch: 5| Step: 11
Training loss: 1.1980888843536377
Validation loss: 1.916173170010249

Epoch: 107| Step: 0
Training loss: 0.9742177724838257
Validation loss: 1.9022714893023174

Epoch: 5| Step: 1
Training loss: 1.0447965860366821
Validation loss: 1.8800999174515407

Epoch: 5| Step: 2
Training loss: 1.0037089586257935
Validation loss: 1.8599663476149242

Epoch: 5| Step: 3
Training loss: 1.4442428350448608
Validation loss: 1.8796367049217224

Epoch: 5| Step: 4
Training loss: 1.5984405279159546
Validation loss: 1.876313254237175

Epoch: 5| Step: 5
Training loss: 1.1341632604599
Validation loss: 1.8973217556873958

Epoch: 5| Step: 6
Training loss: 1.1861963272094727
Validation loss: 1.8997525970141094

Epoch: 5| Step: 7
Training loss: 0.8704907298088074
Validation loss: 1.9057717074950535

Epoch: 5| Step: 8
Training loss: 0.7851690053939819
Validation loss: 1.9449319342772167

Epoch: 5| Step: 9
Training loss: 1.447808861732483
Validation loss: 1.9155306269725163

Epoch: 5| Step: 10
Training loss: 1.381412148475647
Validation loss: 1.901080886522929

Epoch: 5| Step: 11
Training loss: 1.386945366859436
Validation loss: 1.8697874198357265

Epoch: 108| Step: 0
Training loss: 1.2788965702056885
Validation loss: 1.9120306919018428

Epoch: 5| Step: 1
Training loss: 0.8825027346611023
Validation loss: 1.8644745300213497

Epoch: 5| Step: 2
Training loss: 1.2499897480010986
Validation loss: 1.896497666835785

Epoch: 5| Step: 3
Training loss: 1.1385016441345215
Validation loss: 1.8927309960126877

Epoch: 5| Step: 4
Training loss: 1.3596675395965576
Validation loss: 1.9282723665237427

Epoch: 5| Step: 5
Training loss: 1.3842313289642334
Validation loss: 1.927198588848114

Epoch: 5| Step: 6
Training loss: 0.867914080619812
Validation loss: 1.8630764832099278

Epoch: 5| Step: 7
Training loss: 0.7557544112205505
Validation loss: 1.9140001485745113

Epoch: 5| Step: 8
Training loss: 0.9402502179145813
Validation loss: 1.9075080851713817

Epoch: 5| Step: 9
Training loss: 1.030111312866211
Validation loss: 1.8793510496616364

Epoch: 5| Step: 10
Training loss: 1.5298163890838623
Validation loss: 1.9117222676674526

Epoch: 5| Step: 11
Training loss: 1.127837896347046
Validation loss: 1.9274777919054031

Epoch: 109| Step: 0
Training loss: 1.0988153219223022
Validation loss: 1.8698426634073257

Epoch: 5| Step: 1
Training loss: 1.2782213687896729
Validation loss: 1.9125776439905167

Epoch: 5| Step: 2
Training loss: 0.8875687718391418
Validation loss: 1.9189475079377492

Epoch: 5| Step: 3
Training loss: 0.9444296956062317
Validation loss: 1.9110331684350967

Epoch: 5| Step: 4
Training loss: 1.2964292764663696
Validation loss: 1.9412531505028408

Epoch: 5| Step: 5
Training loss: 1.1103456020355225
Validation loss: 1.9196440428495407

Epoch: 5| Step: 6
Training loss: 0.8931976556777954
Validation loss: 1.8863179435332615

Epoch: 5| Step: 7
Training loss: 1.2461196184158325
Validation loss: 1.9154570400714874

Epoch: 5| Step: 8
Training loss: 1.2600947618484497
Validation loss: 1.8644098440806072

Epoch: 5| Step: 9
Training loss: 1.1136478185653687
Validation loss: 1.8869100312391918

Epoch: 5| Step: 10
Training loss: 1.0041568279266357
Validation loss: 1.8568574736515682

Epoch: 5| Step: 11
Training loss: 2.5829551219940186
Validation loss: 1.887332354982694

Epoch: 110| Step: 0
Training loss: 1.3170347213745117
Validation loss: 1.8957028836011887

Epoch: 5| Step: 1
Training loss: 1.4187284708023071
Validation loss: 1.9131805499394734

Epoch: 5| Step: 2
Training loss: 1.4328796863555908
Validation loss: 1.9161210904518764

Epoch: 5| Step: 3
Training loss: 1.1952893733978271
Validation loss: 1.9451946318149567

Epoch: 5| Step: 4
Training loss: 1.0289623737335205
Validation loss: 1.8879685997962952

Epoch: 5| Step: 5
Training loss: 1.1543222665786743
Validation loss: 1.8991518169641495

Epoch: 5| Step: 6
Training loss: 1.0994102954864502
Validation loss: 1.8975316087404888

Epoch: 5| Step: 7
Training loss: 1.0207087993621826
Validation loss: 1.8914076834917068

Epoch: 5| Step: 8
Training loss: 1.020256757736206
Validation loss: 1.9194728483756383

Epoch: 5| Step: 9
Training loss: 0.9070693850517273
Validation loss: 1.905719369649887

Epoch: 5| Step: 10
Training loss: 0.8415395617485046
Validation loss: 1.9027147243420284

Epoch: 5| Step: 11
Training loss: 1.3732397556304932
Validation loss: 1.9029767612616222

Epoch: 111| Step: 0
Training loss: 0.9582441449165344
Validation loss: 1.9178255200386047

Epoch: 5| Step: 1
Training loss: 0.7382584810256958
Validation loss: 1.933010106285413

Epoch: 5| Step: 2
Training loss: 1.0673755407333374
Validation loss: 1.899917721748352

Epoch: 5| Step: 3
Training loss: 1.01168954372406
Validation loss: 1.9089155395825703

Epoch: 5| Step: 4
Training loss: 0.8858400583267212
Validation loss: 1.941360354423523

Epoch: 5| Step: 5
Training loss: 1.5893431901931763
Validation loss: 1.9377343853314717

Epoch: 5| Step: 6
Training loss: 1.2181227207183838
Validation loss: 1.9058840225140254

Epoch: 5| Step: 7
Training loss: 0.9708583950996399
Validation loss: 1.928507849574089

Epoch: 5| Step: 8
Training loss: 1.433702826499939
Validation loss: 1.9134067644675572

Epoch: 5| Step: 9
Training loss: 1.7553859949111938
Validation loss: 1.8877192338307698

Epoch: 5| Step: 10
Training loss: 0.8249553442001343
Validation loss: 1.8889760226011276

Epoch: 5| Step: 11
Training loss: 0.43713515996932983
Validation loss: 1.8855896145105362

Epoch: 112| Step: 0
Training loss: 1.021754264831543
Validation loss: 1.9314155280590057

Epoch: 5| Step: 1
Training loss: 0.8441327810287476
Validation loss: 1.9155328373114269

Epoch: 5| Step: 2
Training loss: 0.7289785146713257
Validation loss: 1.8988277316093445

Epoch: 5| Step: 3
Training loss: 1.2147499322891235
Validation loss: 1.888918697834015

Epoch: 5| Step: 4
Training loss: 1.1575199365615845
Validation loss: 1.9569354206323624

Epoch: 5| Step: 5
Training loss: 1.3240139484405518
Validation loss: 1.8778868516286213

Epoch: 5| Step: 6
Training loss: 1.7778393030166626
Validation loss: 1.9017471075057983

Epoch: 5| Step: 7
Training loss: 1.0553691387176514
Validation loss: 1.9509560316801071

Epoch: 5| Step: 8
Training loss: 0.8956835865974426
Validation loss: 1.899896278977394

Epoch: 5| Step: 9
Training loss: 0.8553903698921204
Validation loss: 1.9164620538552601

Epoch: 5| Step: 10
Training loss: 1.2495367527008057
Validation loss: 1.9089991947015126

Epoch: 5| Step: 11
Training loss: 1.4664092063903809
Validation loss: 1.9162328839302063

Epoch: 113| Step: 0
Training loss: 0.6797931790351868
Validation loss: 1.8854772448539734

Epoch: 5| Step: 1
Training loss: 1.162083625793457
Validation loss: 1.8869139303763707

Epoch: 5| Step: 2
Training loss: 1.097255825996399
Validation loss: 1.9160981327295303

Epoch: 5| Step: 3
Training loss: 0.9261616468429565
Validation loss: 1.9024391969045003

Epoch: 5| Step: 4
Training loss: 0.7927088737487793
Validation loss: 1.9385747462511063

Epoch: 5| Step: 5
Training loss: 0.8626867532730103
Validation loss: 1.8739310105641682

Epoch: 5| Step: 6
Training loss: 1.6124159097671509
Validation loss: 1.887851133942604

Epoch: 5| Step: 7
Training loss: 0.9864103198051453
Validation loss: 1.9416425426801045

Epoch: 5| Step: 8
Training loss: 1.2630608081817627
Validation loss: 1.8742709457874298

Epoch: 5| Step: 9
Training loss: 1.0500121116638184
Validation loss: 1.9334426025549571

Epoch: 5| Step: 10
Training loss: 1.1376651525497437
Validation loss: 1.9200502385695775

Epoch: 5| Step: 11
Training loss: 1.9610836505889893
Validation loss: 1.900621806581815

Epoch: 114| Step: 0
Training loss: 0.642691433429718
Validation loss: 1.9097164620955784

Epoch: 5| Step: 1
Training loss: 1.2970997095108032
Validation loss: 1.9225431581338246

Epoch: 5| Step: 2
Training loss: 1.1165828704833984
Validation loss: 1.909199133515358

Epoch: 5| Step: 3
Training loss: 1.3592045307159424
Validation loss: 1.8865896910429

Epoch: 5| Step: 4
Training loss: 1.0844037532806396
Validation loss: 1.868109370271365

Epoch: 5| Step: 5
Training loss: 0.6204510927200317
Validation loss: 1.905513420701027

Epoch: 5| Step: 6
Training loss: 1.319413423538208
Validation loss: 1.925718829035759

Epoch: 5| Step: 7
Training loss: 1.271109938621521
Validation loss: 1.9080285926659901

Epoch: 5| Step: 8
Training loss: 1.0294029712677002
Validation loss: 1.9144055843353271

Epoch: 5| Step: 9
Training loss: 1.4683613777160645
Validation loss: 1.9538335154453914

Epoch: 5| Step: 10
Training loss: 0.6976917386054993
Validation loss: 1.8885506788889568

Epoch: 5| Step: 11
Training loss: 1.0205364227294922
Validation loss: 1.8747647156318028

Epoch: 115| Step: 0
Training loss: 0.9645069241523743
Validation loss: 1.917165274421374

Epoch: 5| Step: 1
Training loss: 1.2060940265655518
Validation loss: 1.900002474586169

Epoch: 5| Step: 2
Training loss: 1.284147024154663
Validation loss: 1.9373661031325657

Epoch: 5| Step: 3
Training loss: 1.6905479431152344
Validation loss: 1.9225704818964005

Epoch: 5| Step: 4
Training loss: 1.4586087465286255
Validation loss: 1.930020699898402

Epoch: 5| Step: 5
Training loss: 1.1767078638076782
Validation loss: 1.8719497472047806

Epoch: 5| Step: 6
Training loss: 1.3034741878509521
Validation loss: 1.9082298278808594

Epoch: 5| Step: 7
Training loss: 0.6532449126243591
Validation loss: 1.8844746003548305

Epoch: 5| Step: 8
Training loss: 1.0506492853164673
Validation loss: 1.9602738618850708

Epoch: 5| Step: 9
Training loss: 1.188442587852478
Validation loss: 1.9678460756937664

Epoch: 5| Step: 10
Training loss: 0.7908774614334106
Validation loss: 1.9385239879290264

Epoch: 5| Step: 11
Training loss: 2.332980155944824
Validation loss: 1.9310757567485173

Epoch: 116| Step: 0
Training loss: 0.7395229339599609
Validation loss: 1.8744933505853016

Epoch: 5| Step: 1
Training loss: 1.439380407333374
Validation loss: 1.9010841498772304

Epoch: 5| Step: 2
Training loss: 0.9669408798217773
Validation loss: 1.9003158807754517

Epoch: 5| Step: 3
Training loss: 1.4699351787567139
Validation loss: 1.8682008783022563

Epoch: 5| Step: 4
Training loss: 1.1961491107940674
Validation loss: 1.937153846025467

Epoch: 5| Step: 5
Training loss: 1.1397366523742676
Validation loss: 1.8950078984101613

Epoch: 5| Step: 6
Training loss: 0.973270058631897
Validation loss: 1.9108184427022934

Epoch: 5| Step: 7
Training loss: 1.1139925718307495
Validation loss: 1.8747448176145554

Epoch: 5| Step: 8
Training loss: 0.9220120310783386
Validation loss: 1.9037237962086995

Epoch: 5| Step: 9
Training loss: 1.3358153104782104
Validation loss: 1.9259616086880367

Epoch: 5| Step: 10
Training loss: 0.7758935689926147
Validation loss: 1.8997021367152531

Epoch: 5| Step: 11
Training loss: 0.5926733016967773
Validation loss: 1.9201419651508331

Epoch: 117| Step: 0
Training loss: 1.047480583190918
Validation loss: 1.940560296177864

Epoch: 5| Step: 1
Training loss: 1.2524632215499878
Validation loss: 1.8820971846580505

Epoch: 5| Step: 2
Training loss: 1.7240016460418701
Validation loss: 1.8531222293774288

Epoch: 5| Step: 3
Training loss: 1.0081181526184082
Validation loss: 1.897061511874199

Epoch: 5| Step: 4
Training loss: 0.5833934545516968
Validation loss: 1.9359266608953476

Epoch: 5| Step: 5
Training loss: 0.9229400753974915
Validation loss: 1.9262927621603012

Epoch: 5| Step: 6
Training loss: 0.9043512344360352
Validation loss: 1.877981960773468

Epoch: 5| Step: 7
Training loss: 1.1877202987670898
Validation loss: 1.9002431531747181

Epoch: 5| Step: 8
Training loss: 1.1851907968521118
Validation loss: 1.8932798504829407

Epoch: 5| Step: 9
Training loss: 1.0865135192871094
Validation loss: 1.8872644950946171

Epoch: 5| Step: 10
Training loss: 1.1308671236038208
Validation loss: 1.852404996752739

Epoch: 5| Step: 11
Training loss: 0.5781031847000122
Validation loss: 1.8670691053072612

Epoch: 118| Step: 0
Training loss: 1.037683367729187
Validation loss: 1.8970204889774323

Epoch: 5| Step: 1
Training loss: 1.0434128046035767
Validation loss: 1.9047000110149384

Epoch: 5| Step: 2
Training loss: 0.8761585354804993
Validation loss: 1.9287046144406002

Epoch: 5| Step: 3
Training loss: 1.1150476932525635
Validation loss: 1.9252177228530247

Epoch: 5| Step: 4
Training loss: 1.2173573970794678
Validation loss: 1.9246183931827545

Epoch: 5| Step: 5
Training loss: 1.0232789516448975
Validation loss: 1.9237599770228069

Epoch: 5| Step: 6
Training loss: 1.4575269222259521
Validation loss: 1.9501068741083145

Epoch: 5| Step: 7
Training loss: 1.0691297054290771
Validation loss: 1.903638665874799

Epoch: 5| Step: 8
Training loss: 1.1009432077407837
Validation loss: 1.8941030750672023

Epoch: 5| Step: 9
Training loss: 1.4446685314178467
Validation loss: 1.8996339589357376

Epoch: 5| Step: 10
Training loss: 0.7425971031188965
Validation loss: 1.8805863956610362

Epoch: 5| Step: 11
Training loss: 1.272339105606079
Validation loss: 1.8741170465946198

Epoch: 119| Step: 0
Training loss: 1.4295361042022705
Validation loss: 1.912149464090665

Epoch: 5| Step: 1
Training loss: 0.8934528231620789
Validation loss: 1.8966706146796544

Epoch: 5| Step: 2
Training loss: 1.1338441371917725
Validation loss: 1.9067589342594147

Epoch: 5| Step: 3
Training loss: 1.1878442764282227
Validation loss: 1.8959935158491135

Epoch: 5| Step: 4
Training loss: 0.8454422950744629
Validation loss: 1.9097398767868679

Epoch: 5| Step: 5
Training loss: 0.9489909410476685
Validation loss: 1.9476644645134609

Epoch: 5| Step: 6
Training loss: 1.2703555822372437
Validation loss: 1.9502564420302708

Epoch: 5| Step: 7
Training loss: 1.6955493688583374
Validation loss: 1.9678106059630711

Epoch: 5| Step: 8
Training loss: 1.0026085376739502
Validation loss: 1.9775971174240112

Epoch: 5| Step: 9
Training loss: 1.4913643598556519
Validation loss: 1.9635042001803715

Epoch: 5| Step: 10
Training loss: 0.5596368908882141
Validation loss: 1.928331250945727

Epoch: 5| Step: 11
Training loss: 0.450120210647583
Validation loss: 1.9420555730660756

Epoch: 120| Step: 0
Training loss: 1.2246555089950562
Validation loss: 1.920401801665624

Epoch: 5| Step: 1
Training loss: 0.8734714388847351
Validation loss: 1.9234121193488438

Epoch: 5| Step: 2
Training loss: 1.062011957168579
Validation loss: 1.8594870567321777

Epoch: 5| Step: 3
Training loss: 1.227344274520874
Validation loss: 1.9173665195703506

Epoch: 5| Step: 4
Training loss: 0.7831791639328003
Validation loss: 1.959105869134267

Epoch: 5| Step: 5
Training loss: 1.226157784461975
Validation loss: 1.9440089613199234

Epoch: 5| Step: 6
Training loss: 1.071001648902893
Validation loss: 1.927482878168424

Epoch: 5| Step: 7
Training loss: 1.1678783893585205
Validation loss: 1.938588097691536

Epoch: 5| Step: 8
Training loss: 0.8475080728530884
Validation loss: 1.944463978211085

Epoch: 5| Step: 9
Training loss: 1.1551945209503174
Validation loss: 1.9289795806010563

Epoch: 5| Step: 10
Training loss: 0.6635710597038269
Validation loss: 1.9526802400747936

Epoch: 5| Step: 11
Training loss: 1.2141878604888916
Validation loss: 1.9282357543706894

Epoch: 121| Step: 0
Training loss: 1.1246263980865479
Validation loss: 1.8882229924201965

Epoch: 5| Step: 1
Training loss: 0.6884884238243103
Validation loss: 1.9148468673229218

Epoch: 5| Step: 2
Training loss: 0.5767291784286499
Validation loss: 1.9174568504095078

Epoch: 5| Step: 3
Training loss: 0.7450909614562988
Validation loss: 1.8976701746384304

Epoch: 5| Step: 4
Training loss: 1.6092727184295654
Validation loss: 1.9628227005402248

Epoch: 5| Step: 5
Training loss: 0.883797287940979
Validation loss: 1.9660733789205551

Epoch: 5| Step: 6
Training loss: 0.8613065481185913
Validation loss: 1.8734557280937831

Epoch: 5| Step: 7
Training loss: 1.1179957389831543
Validation loss: 1.916878675421079

Epoch: 5| Step: 8
Training loss: 0.8135797381401062
Validation loss: 1.8819805731376011

Epoch: 5| Step: 9
Training loss: 1.3417987823486328
Validation loss: 1.9060306896766026

Epoch: 5| Step: 10
Training loss: 1.2962678670883179
Validation loss: 1.873307704925537

Epoch: 5| Step: 11
Training loss: 0.8895959854125977
Validation loss: 1.9256725956996281

Epoch: 122| Step: 0
Training loss: 0.7702934145927429
Validation loss: 1.8840129375457764

Epoch: 5| Step: 1
Training loss: 0.9676674008369446
Validation loss: 1.8892221450805664

Epoch: 5| Step: 2
Training loss: 1.2682372331619263
Validation loss: 1.9190736214319866

Epoch: 5| Step: 3
Training loss: 1.0222537517547607
Validation loss: 1.936318611105283

Epoch: 5| Step: 4
Training loss: 1.1920403242111206
Validation loss: 1.8931437333424885

Epoch: 5| Step: 5
Training loss: 0.7730754613876343
Validation loss: 1.8886823952198029

Epoch: 5| Step: 6
Training loss: 0.7072044610977173
Validation loss: 1.874429389834404

Epoch: 5| Step: 7
Training loss: 1.185961365699768
Validation loss: 1.8899232844511669

Epoch: 5| Step: 8
Training loss: 0.7663496136665344
Validation loss: 1.8402785062789917

Epoch: 5| Step: 9
Training loss: 1.1034125089645386
Validation loss: 1.9342344999313354

Epoch: 5| Step: 10
Training loss: 1.592397928237915
Validation loss: 1.919801061352094

Epoch: 5| Step: 11
Training loss: 0.44870397448539734
Validation loss: 1.9039332121610641

Epoch: 123| Step: 0
Training loss: 0.8517230749130249
Validation loss: 1.8886658698320389

Epoch: 5| Step: 1
Training loss: 1.178649663925171
Validation loss: 1.8993745297193527

Epoch: 5| Step: 2
Training loss: 0.9787334203720093
Validation loss: 1.9591088195641835

Epoch: 5| Step: 3
Training loss: 1.0293970108032227
Validation loss: 1.9191395143667858

Epoch: 5| Step: 4
Training loss: 1.3501826524734497
Validation loss: 1.8775242517391841

Epoch: 5| Step: 5
Training loss: 1.044953465461731
Validation loss: 1.8459203938643138

Epoch: 5| Step: 6
Training loss: 0.9728839993476868
Validation loss: 1.8688342074553173

Epoch: 5| Step: 7
Training loss: 0.7871630787849426
Validation loss: 1.8819159865379333

Epoch: 5| Step: 8
Training loss: 0.9130517840385437
Validation loss: 1.8876992215712864

Epoch: 5| Step: 9
Training loss: 0.9010376930236816
Validation loss: 1.883243848880132

Epoch: 5| Step: 10
Training loss: 0.6909375190734863
Validation loss: 1.8739127020041149

Epoch: 5| Step: 11
Training loss: 1.0026659965515137
Validation loss: 1.8711128234863281

Epoch: 124| Step: 0
Training loss: 0.7541602253913879
Validation loss: 1.967427025238673

Epoch: 5| Step: 1
Training loss: 0.9108831286430359
Validation loss: 1.874380464355151

Epoch: 5| Step: 2
Training loss: 0.6554514169692993
Validation loss: 1.9439538419246674

Epoch: 5| Step: 3
Training loss: 0.6631768345832825
Validation loss: 1.8539052257935207

Epoch: 5| Step: 4
Training loss: 1.389212727546692
Validation loss: 1.883380686243375

Epoch: 5| Step: 5
Training loss: 0.8743265271186829
Validation loss: 1.9063441902399063

Epoch: 5| Step: 6
Training loss: 0.6682817339897156
Validation loss: 1.8802372366189957

Epoch: 5| Step: 7
Training loss: 1.3277225494384766
Validation loss: 1.872852956255277

Epoch: 5| Step: 8
Training loss: 1.3577607870101929
Validation loss: 1.8458639333645503

Epoch: 5| Step: 9
Training loss: 1.3654468059539795
Validation loss: 1.861831118663152

Epoch: 5| Step: 10
Training loss: 1.1679341793060303
Validation loss: 1.949682464202245

Epoch: 5| Step: 11
Training loss: 0.28083670139312744
Validation loss: 1.906490683555603

Epoch: 125| Step: 0
Training loss: 1.1345735788345337
Validation loss: 1.9538562794526417

Epoch: 5| Step: 1
Training loss: 1.1420061588287354
Validation loss: 1.898484821120898

Epoch: 5| Step: 2
Training loss: 0.6688190698623657
Validation loss: 1.9250137507915497

Epoch: 5| Step: 3
Training loss: 1.1273373365402222
Validation loss: 1.8607102086146672

Epoch: 5| Step: 4
Training loss: 0.7612704634666443
Validation loss: 1.8731749852498372

Epoch: 5| Step: 5
Training loss: 1.025625467300415
Validation loss: 1.8802901705106099

Epoch: 5| Step: 6
Training loss: 1.120560884475708
Validation loss: 1.8713694512844086

Epoch: 5| Step: 7
Training loss: 1.3124549388885498
Validation loss: 1.8894055237372716

Epoch: 5| Step: 8
Training loss: 0.6785829067230225
Validation loss: 1.8675219664971034

Epoch: 5| Step: 9
Training loss: 0.847698986530304
Validation loss: 1.8417464395364125

Epoch: 5| Step: 10
Training loss: 0.970981776714325
Validation loss: 1.8948180377483368

Epoch: 5| Step: 11
Training loss: 1.3939679861068726
Validation loss: 1.909028301636378

Testing loss: 1.8266936720704003
