Epoch: 1| Step: 0
Training loss: 8.646063695083075
Validation loss: 8.064432627173836

Epoch: 6| Step: 1
Training loss: 7.565602572509096
Validation loss: 8.03674429291816

Epoch: 6| Step: 2
Training loss: 8.195011798880406
Validation loss: 8.010426243915628

Epoch: 6| Step: 3
Training loss: 8.276382340048814
Validation loss: 7.981643637576615

Epoch: 6| Step: 4
Training loss: 8.48277961807497
Validation loss: 7.953762386139918

Epoch: 6| Step: 5
Training loss: 8.375903635951765
Validation loss: 7.928165102987442

Epoch: 6| Step: 6
Training loss: 7.819804690524516
Validation loss: 7.902038296779788

Epoch: 6| Step: 7
Training loss: 9.248844383841877
Validation loss: 7.87252033895266

Epoch: 6| Step: 8
Training loss: 7.685235907384264
Validation loss: 7.843307624490509

Epoch: 6| Step: 9
Training loss: 7.462548398574995
Validation loss: 7.815314434459605

Epoch: 6| Step: 10
Training loss: 7.888520033664946
Validation loss: 7.7832659008473195

Epoch: 6| Step: 11
Training loss: 8.232477711480277
Validation loss: 7.754708941187448

Epoch: 6| Step: 12
Training loss: 7.577783698822025
Validation loss: 7.726797297670538

Epoch: 6| Step: 13
Training loss: 5.989219835833659
Validation loss: 7.694536622463498

Epoch: 2| Step: 0
Training loss: 8.113287832508163
Validation loss: 7.664364040507629

Epoch: 6| Step: 1
Training loss: 8.335752619200958
Validation loss: 7.631362178560134

Epoch: 6| Step: 2
Training loss: 6.843732720618883
Validation loss: 7.597941640218895

Epoch: 6| Step: 3
Training loss: 7.592577431654159
Validation loss: 7.565756398819034

Epoch: 6| Step: 4
Training loss: 7.721381476334153
Validation loss: 7.530966936756713

Epoch: 6| Step: 5
Training loss: 7.95453024330171
Validation loss: 7.496856200096704

Epoch: 6| Step: 6
Training loss: 7.526671478071722
Validation loss: 7.457912951792675

Epoch: 6| Step: 7
Training loss: 7.882204181650617
Validation loss: 7.420713570720921

Epoch: 6| Step: 8
Training loss: 7.891972734530836
Validation loss: 7.380297724672185

Epoch: 6| Step: 9
Training loss: 6.219867241721375
Validation loss: 7.340050294307074

Epoch: 6| Step: 10
Training loss: 8.110624771982398
Validation loss: 7.29639593889359

Epoch: 6| Step: 11
Training loss: 6.902327169971597
Validation loss: 7.257606243355009

Epoch: 6| Step: 12
Training loss: 6.811841460429863
Validation loss: 7.209014184215439

Epoch: 6| Step: 13
Training loss: 7.288827252450456
Validation loss: 7.1635757552720705

Epoch: 3| Step: 0
Training loss: 7.557254706164644
Validation loss: 7.1185825737926205

Epoch: 6| Step: 1
Training loss: 7.086765968485897
Validation loss: 7.065875481753771

Epoch: 6| Step: 2
Training loss: 6.687622069198415
Validation loss: 7.015667955568662

Epoch: 6| Step: 3
Training loss: 6.8016267850130845
Validation loss: 6.961708833863411

Epoch: 6| Step: 4
Training loss: 6.067300370763137
Validation loss: 6.904211189281477

Epoch: 6| Step: 5
Training loss: 6.6097091698544945
Validation loss: 6.846901085445659

Epoch: 6| Step: 6
Training loss: 7.273471065980551
Validation loss: 6.78903215794428

Epoch: 6| Step: 7
Training loss: 7.030425027558095
Validation loss: 6.72369013890927

Epoch: 6| Step: 8
Training loss: 7.36446572245382
Validation loss: 6.6600814084260245

Epoch: 6| Step: 9
Training loss: 6.938065239501436
Validation loss: 6.596566127700383

Epoch: 6| Step: 10
Training loss: 6.904940796086592
Validation loss: 6.517560175969191

Epoch: 6| Step: 11
Training loss: 6.560525942397389
Validation loss: 6.449053818649919

Epoch: 6| Step: 12
Training loss: 6.203871828566673
Validation loss: 6.37064197652915

Epoch: 6| Step: 13
Training loss: 6.429945874498059
Validation loss: 6.288729641084694

Epoch: 4| Step: 0
Training loss: 6.790695994778876
Validation loss: 6.207646487685704

Epoch: 6| Step: 1
Training loss: 4.849552542898469
Validation loss: 6.11840478210934

Epoch: 6| Step: 2
Training loss: 7.240502285895004
Validation loss: 6.033684379242405

Epoch: 6| Step: 3
Training loss: 6.593783554787252
Validation loss: 5.929339372269101

Epoch: 6| Step: 4
Training loss: 6.551451474174027
Validation loss: 5.8340623763320725

Epoch: 6| Step: 5
Training loss: 4.975116801208686
Validation loss: 5.740393976565102

Epoch: 6| Step: 6
Training loss: 4.928906652450848
Validation loss: 5.630329574234705

Epoch: 6| Step: 7
Training loss: 5.836792093029857
Validation loss: 5.529836183022023

Epoch: 6| Step: 8
Training loss: 4.600522816013856
Validation loss: 5.410052423135042

Epoch: 6| Step: 9
Training loss: 4.660433330116727
Validation loss: 5.298119292870212

Epoch: 6| Step: 10
Training loss: 5.909495597266431
Validation loss: 5.182811625352827

Epoch: 6| Step: 11
Training loss: 5.4851376255959625
Validation loss: 5.058850044032277

Epoch: 6| Step: 12
Training loss: 4.97701051812328
Validation loss: 4.944848463194223

Epoch: 6| Step: 13
Training loss: 5.0198546071673835
Validation loss: 4.801009625640884

Epoch: 5| Step: 0
Training loss: 4.332664120180088
Validation loss: 4.668230861822545

Epoch: 6| Step: 1
Training loss: 5.150827967187275
Validation loss: 4.523876671782713

Epoch: 6| Step: 2
Training loss: 5.401088477740831
Validation loss: 4.381859334020723

Epoch: 6| Step: 3
Training loss: 4.856870146716949
Validation loss: 4.247032644280674

Epoch: 6| Step: 4
Training loss: 4.270174276471679
Validation loss: 4.089944638450402

Epoch: 6| Step: 5
Training loss: 3.960731154866224
Validation loss: 3.9397552127283615

Epoch: 6| Step: 6
Training loss: 3.9136943225195897
Validation loss: 3.8011979139013254

Epoch: 6| Step: 7
Training loss: 3.571370241506263
Validation loss: 3.6433458543604775

Epoch: 6| Step: 8
Training loss: 3.4856176512587553
Validation loss: 3.4831937831930073

Epoch: 6| Step: 9
Training loss: 2.927444942487627
Validation loss: 3.3537863679673006

Epoch: 6| Step: 10
Training loss: 3.847949579356647
Validation loss: 3.2408483964709434

Epoch: 6| Step: 11
Training loss: 3.256278209600696
Validation loss: 3.113229021234973

Epoch: 6| Step: 12
Training loss: 3.071599714764158
Validation loss: 2.9810972605137964

Epoch: 6| Step: 13
Training loss: 2.0559753327281487
Validation loss: 2.9007382237039367

Epoch: 6| Step: 0
Training loss: 3.0247235384627897
Validation loss: 2.8185947361354082

Epoch: 6| Step: 1
Training loss: 2.387454554739429
Validation loss: 2.78175585143433

Epoch: 6| Step: 2
Training loss: 2.705226632458931
Validation loss: 2.761603166390781

Epoch: 6| Step: 3
Training loss: 2.901710492511035
Validation loss: 2.7223385771929034

Epoch: 6| Step: 4
Training loss: 1.8002654886489273
Validation loss: 2.725973450027405

Epoch: 6| Step: 5
Training loss: 2.678894815451136
Validation loss: 2.7473627651930372

Epoch: 6| Step: 6
Training loss: 3.178778291097099
Validation loss: 2.7329066375751574

Epoch: 6| Step: 7
Training loss: 3.2023204258192433
Validation loss: 2.796527578133211

Epoch: 6| Step: 8
Training loss: 3.2465680415104097
Validation loss: 2.7482706759196245

Epoch: 6| Step: 9
Training loss: 2.5985154645443846
Validation loss: 2.795169644288585

Epoch: 6| Step: 10
Training loss: 3.358745143306218
Validation loss: 2.8215551201376043

Epoch: 6| Step: 11
Training loss: 3.0305132412969704
Validation loss: 2.834618302753439

Epoch: 6| Step: 12
Training loss: 3.1617815249474504
Validation loss: 2.856808606816358

Epoch: 6| Step: 13
Training loss: 2.852056591130553
Validation loss: 2.8273701652760868

Epoch: 7| Step: 0
Training loss: 3.285398785033071
Validation loss: 2.8510223155723278

Epoch: 6| Step: 1
Training loss: 3.6563504197113867
Validation loss: 2.836122056684836

Epoch: 6| Step: 2
Training loss: 2.9309290988849304
Validation loss: 2.8275295354288223

Epoch: 6| Step: 3
Training loss: 2.6332474980267726
Validation loss: 2.805085744538889

Epoch: 6| Step: 4
Training loss: 2.60976365901129
Validation loss: 2.771298797251216

Epoch: 6| Step: 5
Training loss: 3.7437841397927536
Validation loss: 2.7239478982077596

Epoch: 6| Step: 6
Training loss: 3.0354666729126314
Validation loss: 2.7118082690961423

Epoch: 6| Step: 7
Training loss: 1.6976539861082034
Validation loss: 2.7276821661191057

Epoch: 6| Step: 8
Training loss: 3.2101117114061672
Validation loss: 2.711157057901319

Epoch: 6| Step: 9
Training loss: 3.1437089496457853
Validation loss: 2.7111350655366016

Epoch: 6| Step: 10
Training loss: 2.0812260715151525
Validation loss: 2.7027095629791877

Epoch: 6| Step: 11
Training loss: 2.192857666246326
Validation loss: 2.6750396220520054

Epoch: 6| Step: 12
Training loss: 3.26373572204342
Validation loss: 2.685334049923993

Epoch: 6| Step: 13
Training loss: 2.3561468208043665
Validation loss: 2.6817819993811565

Epoch: 8| Step: 0
Training loss: 2.316729621123306
Validation loss: 2.685061997539062

Epoch: 6| Step: 1
Training loss: 2.8570370313936926
Validation loss: 2.687834341853915

Epoch: 6| Step: 2
Training loss: 2.479897741239916
Validation loss: 2.68664664389609

Epoch: 6| Step: 3
Training loss: 2.5316964214988107
Validation loss: 2.6727609782815476

Epoch: 6| Step: 4
Training loss: 2.159503638138812
Validation loss: 2.7061463745105683

Epoch: 6| Step: 5
Training loss: 3.56745432299836
Validation loss: 2.712564850250248

Epoch: 6| Step: 6
Training loss: 3.1982438275282052
Validation loss: 2.7104886111172837

Epoch: 6| Step: 7
Training loss: 3.321759651313037
Validation loss: 2.666845633541248

Epoch: 6| Step: 8
Training loss: 2.990188289314604
Validation loss: 2.6788340433749873

Epoch: 6| Step: 9
Training loss: 2.4763988356557802
Validation loss: 2.6965776800445345

Epoch: 6| Step: 10
Training loss: 2.0190847113467623
Validation loss: 2.702348263080494

Epoch: 6| Step: 11
Training loss: 3.4391580917612603
Validation loss: 2.6637281206134333

Epoch: 6| Step: 12
Training loss: 2.294567584021888
Validation loss: 2.6969857444730607

Epoch: 6| Step: 13
Training loss: 3.169122412953803
Validation loss: 2.6761173157908966

Epoch: 9| Step: 0
Training loss: 2.8687452195736483
Validation loss: 2.6836517342527233

Epoch: 6| Step: 1
Training loss: 3.5387043550674364
Validation loss: 2.697022003729045

Epoch: 6| Step: 2
Training loss: 1.6770946273265466
Validation loss: 2.7030230082121753

Epoch: 6| Step: 3
Training loss: 1.9284597344322905
Validation loss: 2.659631872565396

Epoch: 6| Step: 4
Training loss: 2.714881512495912
Validation loss: 2.687073695947849

Epoch: 6| Step: 5
Training loss: 3.4531412944150337
Validation loss: 2.6620155293675416

Epoch: 6| Step: 6
Training loss: 2.801922383466171
Validation loss: 2.6888896690801882

Epoch: 6| Step: 7
Training loss: 2.6970956404902324
Validation loss: 2.6804386194667242

Epoch: 6| Step: 8
Training loss: 2.147743695679334
Validation loss: 2.6732003120692744

Epoch: 6| Step: 9
Training loss: 3.274492553534715
Validation loss: 2.694278581392917

Epoch: 6| Step: 10
Training loss: 2.726772442361683
Validation loss: 2.6859390841677824

Epoch: 6| Step: 11
Training loss: 3.042833670481484
Validation loss: 2.6682734168873052

Epoch: 6| Step: 12
Training loss: 2.5972257558579868
Validation loss: 2.6739468786164924

Epoch: 6| Step: 13
Training loss: 3.0259198390229014
Validation loss: 2.6928759780336864

Epoch: 10| Step: 0
Training loss: 2.5692113123341054
Validation loss: 2.6575910586250147

Epoch: 6| Step: 1
Training loss: 2.7661035845621083
Validation loss: 2.651464864431501

Epoch: 6| Step: 2
Training loss: 2.752960085827867
Validation loss: 2.645272598521461

Epoch: 6| Step: 3
Training loss: 2.7571086904016817
Validation loss: 2.6249478047343633

Epoch: 6| Step: 4
Training loss: 3.3187158672639323
Validation loss: 2.679195881669942

Epoch: 6| Step: 5
Training loss: 2.6044599647659874
Validation loss: 2.626201067248792

Epoch: 6| Step: 6
Training loss: 3.0100327261226085
Validation loss: 2.650041032869324

Epoch: 6| Step: 7
Training loss: 2.5720414952539365
Validation loss: 2.6167320804154275

Epoch: 6| Step: 8
Training loss: 2.967230799611662
Validation loss: 2.64129502262438

Epoch: 6| Step: 9
Training loss: 2.5040477409199196
Validation loss: 2.635957433734105

Epoch: 6| Step: 10
Training loss: 2.9842168156908033
Validation loss: 2.6549401587946186

Epoch: 6| Step: 11
Training loss: 2.6001485928842847
Validation loss: 2.6475574002573907

Epoch: 6| Step: 12
Training loss: 2.883168102961831
Validation loss: 2.647716007588236

Epoch: 6| Step: 13
Training loss: 2.356560247015752
Validation loss: 2.6183249511762647

Epoch: 11| Step: 0
Training loss: 2.7063186390125424
Validation loss: 2.6477535268578607

Epoch: 6| Step: 1
Training loss: 2.554958130853623
Validation loss: 2.6194920049318293

Epoch: 6| Step: 2
Training loss: 3.050332010677889
Validation loss: 2.636991796602044

Epoch: 6| Step: 3
Training loss: 3.4793517164407537
Validation loss: 2.642813774253824

Epoch: 6| Step: 4
Training loss: 2.8994125823611077
Validation loss: 2.6125947195887926

Epoch: 6| Step: 5
Training loss: 2.4879711682528836
Validation loss: 2.63392247498725

Epoch: 6| Step: 6
Training loss: 2.707852589904244
Validation loss: 2.624863545337673

Epoch: 6| Step: 7
Training loss: 2.1500338085976214
Validation loss: 2.6073635213849107

Epoch: 6| Step: 8
Training loss: 3.651049706000793
Validation loss: 2.6392932219576433

Epoch: 6| Step: 9
Training loss: 2.7658403388204085
Validation loss: 2.634554187839282

Epoch: 6| Step: 10
Training loss: 2.838356688652186
Validation loss: 2.6553861746799883

Epoch: 6| Step: 11
Training loss: 2.1146764750395493
Validation loss: 2.6313251101057116

Epoch: 6| Step: 12
Training loss: 2.4678763280205214
Validation loss: 2.6250143807637922

Epoch: 6| Step: 13
Training loss: 2.2951229965062434
Validation loss: 2.662284474014758

Epoch: 12| Step: 0
Training loss: 3.1205864829481325
Validation loss: 2.600339982227904

Epoch: 6| Step: 1
Training loss: 2.4425186918669892
Validation loss: 2.622047322869227

Epoch: 6| Step: 2
Training loss: 2.230464367436314
Validation loss: 2.6082564981455736

Epoch: 6| Step: 3
Training loss: 2.558259199561513
Validation loss: 2.578282206973074

Epoch: 6| Step: 4
Training loss: 3.1507910930953678
Validation loss: 2.621788633952679

Epoch: 6| Step: 5
Training loss: 3.0375360808564698
Validation loss: 2.6088615567150963

Epoch: 6| Step: 6
Training loss: 2.889605368099528
Validation loss: 2.6371303660919536

Epoch: 6| Step: 7
Training loss: 3.4793866634293322
Validation loss: 2.6164283372583284

Epoch: 6| Step: 8
Training loss: 3.3604689125560823
Validation loss: 2.601911832555006

Epoch: 6| Step: 9
Training loss: 2.5010693170580556
Validation loss: 2.614640388524823

Epoch: 6| Step: 10
Training loss: 3.130638528841457
Validation loss: 2.6149614878797505

Epoch: 6| Step: 11
Training loss: 1.9201576809905334
Validation loss: 2.615400131020977

Epoch: 6| Step: 12
Training loss: 1.9029385931117306
Validation loss: 2.634457452584082

Epoch: 6| Step: 13
Training loss: 1.9594256283487224
Validation loss: 2.6154504201972846

Epoch: 13| Step: 0
Training loss: 2.480990617776618
Validation loss: 2.620560995081951

Epoch: 6| Step: 1
Training loss: 2.8855815707204915
Validation loss: 2.6088702080958774

Epoch: 6| Step: 2
Training loss: 2.7895910793327
Validation loss: 2.6331709439470496

Epoch: 6| Step: 3
Training loss: 3.1383961222305476
Validation loss: 2.623977976855845

Epoch: 6| Step: 4
Training loss: 3.1059729592643976
Validation loss: 2.6688639161620324

Epoch: 6| Step: 5
Training loss: 1.826014612943708
Validation loss: 2.608892978758515

Epoch: 6| Step: 6
Training loss: 2.452519822035701
Validation loss: 2.647957352256394

Epoch: 6| Step: 7
Training loss: 2.600198840827528
Validation loss: 2.630489724595555

Epoch: 6| Step: 8
Training loss: 3.2665208381748414
Validation loss: 2.611196921225911

Epoch: 6| Step: 9
Training loss: 1.997018857260407
Validation loss: 2.632994210663412

Epoch: 6| Step: 10
Training loss: 2.4346677513531
Validation loss: 2.612555980538902

Epoch: 6| Step: 11
Training loss: 3.1213534632634854
Validation loss: 2.6048993160879297

Epoch: 6| Step: 12
Training loss: 2.5583314251556075
Validation loss: 2.602139994052992

Epoch: 6| Step: 13
Training loss: 2.6558463294775847
Validation loss: 2.599924345016166

Epoch: 14| Step: 0
Training loss: 2.416729191815307
Validation loss: 2.62515633738164

Epoch: 6| Step: 1
Training loss: 3.0348154708848076
Validation loss: 2.5902444444158723

Epoch: 6| Step: 2
Training loss: 2.359327404224239
Validation loss: 2.5577864210399053

Epoch: 6| Step: 3
Training loss: 3.0260802554867055
Validation loss: 2.5976424214465883

Epoch: 6| Step: 4
Training loss: 3.520443746166366
Validation loss: 2.626050905248987

Epoch: 6| Step: 5
Training loss: 2.6607971763683023
Validation loss: 2.556793122859136

Epoch: 6| Step: 6
Training loss: 3.0585519683049798
Validation loss: 2.6265204053142175

Epoch: 6| Step: 7
Training loss: 2.212513931144347
Validation loss: 2.5782583953563902

Epoch: 6| Step: 8
Training loss: 2.4076261672317227
Validation loss: 2.607253546645037

Epoch: 6| Step: 9
Training loss: 2.424658867349458
Validation loss: 2.6179549880630355

Epoch: 6| Step: 10
Training loss: 2.2884564427403515
Validation loss: 2.6098050583523515

Epoch: 6| Step: 11
Training loss: 3.2168560196350118
Validation loss: 2.610427339678655

Epoch: 6| Step: 12
Training loss: 2.831935275852224
Validation loss: 2.587207993018712

Epoch: 6| Step: 13
Training loss: 2.252939000170393
Validation loss: 2.602143720094621

Epoch: 15| Step: 0
Training loss: 2.6641489501529514
Validation loss: 2.5629881417144893

Epoch: 6| Step: 1
Training loss: 2.8634705942787884
Validation loss: 2.5985261841957583

Epoch: 6| Step: 2
Training loss: 2.3118370755548305
Validation loss: 2.600608948775164

Epoch: 6| Step: 3
Training loss: 3.124987792944908
Validation loss: 2.603366260865749

Epoch: 6| Step: 4
Training loss: 2.7120055807219394
Validation loss: 2.5879940602486444

Epoch: 6| Step: 5
Training loss: 2.1037586181609162
Validation loss: 2.604067462303139

Epoch: 6| Step: 6
Training loss: 2.689498335846845
Validation loss: 2.6157473421216677

Epoch: 6| Step: 7
Training loss: 3.2193167474534983
Validation loss: 2.586889631425527

Epoch: 6| Step: 8
Training loss: 3.0130803732345557
Validation loss: 2.578823988976843

Epoch: 6| Step: 9
Training loss: 2.6958030364875776
Validation loss: 2.5604615050554953

Epoch: 6| Step: 10
Training loss: 2.6931904718386592
Validation loss: 2.5841454772629953

Epoch: 6| Step: 11
Training loss: 1.92105581301183
Validation loss: 2.58399413999143

Epoch: 6| Step: 12
Training loss: 2.47386980935713
Validation loss: 2.6366545643470434

Epoch: 6| Step: 13
Training loss: 2.7330634759258596
Validation loss: 2.5904066299784816

Epoch: 16| Step: 0
Training loss: 2.5021735279640756
Validation loss: 2.610901544042929

Epoch: 6| Step: 1
Training loss: 3.320932272119662
Validation loss: 2.5823014926351577

Epoch: 6| Step: 2
Training loss: 2.5562483659286688
Validation loss: 2.5809638836952384

Epoch: 6| Step: 3
Training loss: 1.8566311377522307
Validation loss: 2.5814290770450463

Epoch: 6| Step: 4
Training loss: 1.647875938764234
Validation loss: 2.6193951761119028

Epoch: 6| Step: 5
Training loss: 2.266149315509533
Validation loss: 2.5833284290841423

Epoch: 6| Step: 6
Training loss: 2.649973196217997
Validation loss: 2.6081527999906484

Epoch: 6| Step: 7
Training loss: 1.923403434544722
Validation loss: 2.5987802086426517

Epoch: 6| Step: 8
Training loss: 2.775284359083442
Validation loss: 2.5818270680947855

Epoch: 6| Step: 9
Training loss: 3.215655867388596
Validation loss: 2.558640822737106

Epoch: 6| Step: 10
Training loss: 3.160086839665726
Validation loss: 2.6280803771885712

Epoch: 6| Step: 11
Training loss: 2.869046390821868
Validation loss: 2.59393441643868

Epoch: 6| Step: 12
Training loss: 3.1188899006932713
Validation loss: 2.620690259277859

Epoch: 6| Step: 13
Training loss: 2.879567374478353
Validation loss: 2.583278352911197

Epoch: 17| Step: 0
Training loss: 2.2974794591539607
Validation loss: 2.62013669077216

Epoch: 6| Step: 1
Training loss: 2.660474044033704
Validation loss: 2.580987439414332

Epoch: 6| Step: 2
Training loss: 2.294424709279325
Validation loss: 2.5240753595917926

Epoch: 6| Step: 3
Training loss: 2.790483897914748
Validation loss: 2.5860542662842776

Epoch: 6| Step: 4
Training loss: 2.7815459018988196
Validation loss: 2.5585336304413047

Epoch: 6| Step: 5
Training loss: 2.340074327217637
Validation loss: 2.612087583462857

Epoch: 6| Step: 6
Training loss: 1.994086284438812
Validation loss: 2.5841533118375177

Epoch: 6| Step: 7
Training loss: 2.793675302620576
Validation loss: 2.6098488322263345

Epoch: 6| Step: 8
Training loss: 2.671220219561701
Validation loss: 2.6113889311941603

Epoch: 6| Step: 9
Training loss: 2.7414125396230213
Validation loss: 2.550734328207888

Epoch: 6| Step: 10
Training loss: 2.920838687327689
Validation loss: 2.5306487448606747

Epoch: 6| Step: 11
Training loss: 2.2522157778922445
Validation loss: 2.615017605364284

Epoch: 6| Step: 12
Training loss: 3.7894880861990234
Validation loss: 2.553879698604349

Epoch: 6| Step: 13
Training loss: 2.6655244367799913
Validation loss: 2.577430647007335

Epoch: 18| Step: 0
Training loss: 2.0432044744802544
Validation loss: 2.6237873122112747

Epoch: 6| Step: 1
Training loss: 2.904067666014183
Validation loss: 2.5879061332573845

Epoch: 6| Step: 2
Training loss: 2.1269906761420616
Validation loss: 2.6233785101972398

Epoch: 6| Step: 3
Training loss: 2.3842106953777416
Validation loss: 2.6320455775517786

Epoch: 6| Step: 4
Training loss: 2.4978310713261953
Validation loss: 2.657144852045173

Epoch: 6| Step: 5
Training loss: 3.590916851987891
Validation loss: 2.5902095822063553

Epoch: 6| Step: 6
Training loss: 3.4139659876679516
Validation loss: 2.6171585612808523

Epoch: 6| Step: 7
Training loss: 2.232641868398157
Validation loss: 2.604231480109791

Epoch: 6| Step: 8
Training loss: 3.0069791357688564
Validation loss: 2.6064223984889887

Epoch: 6| Step: 9
Training loss: 2.178482542971818
Validation loss: 2.5919036574933836

Epoch: 6| Step: 10
Training loss: 1.7056495084920265
Validation loss: 2.5921158296082827

Epoch: 6| Step: 11
Training loss: 2.877322709946323
Validation loss: 2.624964940881484

Epoch: 6| Step: 12
Training loss: 2.912934849574602
Validation loss: 2.593342025108122

Epoch: 6| Step: 13
Training loss: 2.7965287148692712
Validation loss: 2.550999599456257

Epoch: 19| Step: 0
Training loss: 2.7186677416053633
Validation loss: 2.6149789781862096

Epoch: 6| Step: 1
Training loss: 2.522035853137885
Validation loss: 2.5768125333700502

Epoch: 6| Step: 2
Training loss: 2.697336073058329
Validation loss: 2.595774676138321

Epoch: 6| Step: 3
Training loss: 2.772200015515726
Validation loss: 2.5313618325226654

Epoch: 6| Step: 4
Training loss: 2.8580290748286514
Validation loss: 2.5749857275607413

Epoch: 6| Step: 5
Training loss: 3.20123771334446
Validation loss: 2.555256281539053

Epoch: 6| Step: 6
Training loss: 3.2721585709217753
Validation loss: 2.579345275618901

Epoch: 6| Step: 7
Training loss: 2.202381306111861
Validation loss: 2.5891093367839173

Epoch: 6| Step: 8
Training loss: 2.156584782802438
Validation loss: 2.561264841394476

Epoch: 6| Step: 9
Training loss: 3.226698015890919
Validation loss: 2.571970388529256

Epoch: 6| Step: 10
Training loss: 2.2279292680069958
Validation loss: 2.5616661048529497

Epoch: 6| Step: 11
Training loss: 2.4037557778608893
Validation loss: 2.6263270581025164

Epoch: 6| Step: 12
Training loss: 1.8198295902288584
Validation loss: 2.6238690467980046

Epoch: 6| Step: 13
Training loss: 2.4613035868269275
Validation loss: 2.609815921954443

Epoch: 20| Step: 0
Training loss: 2.0170416769659054
Validation loss: 2.6404242204105906

Epoch: 6| Step: 1
Training loss: 3.2071992595493817
Validation loss: 2.6002473380355724

Epoch: 6| Step: 2
Training loss: 2.404696966577726
Validation loss: 2.578447279390098

Epoch: 6| Step: 3
Training loss: 2.7808969680810756
Validation loss: 2.579933410790629

Epoch: 6| Step: 4
Training loss: 2.442239701487445
Validation loss: 2.5649926227515545

Epoch: 6| Step: 5
Training loss: 2.3312729412514805
Validation loss: 2.558326796565781

Epoch: 6| Step: 6
Training loss: 2.3938323801073236
Validation loss: 2.6158201754788886

Epoch: 6| Step: 7
Training loss: 3.243671858770608
Validation loss: 2.5914349316418646

Epoch: 6| Step: 8
Training loss: 1.9660904495489253
Validation loss: 2.569783195870279

Epoch: 6| Step: 9
Training loss: 2.484129887611143
Validation loss: 2.5791238333412063

Epoch: 6| Step: 10
Training loss: 2.8954496792751976
Validation loss: 2.59563922635993

Epoch: 6| Step: 11
Training loss: 2.572959951018651
Validation loss: 2.5607610400052936

Epoch: 6| Step: 12
Training loss: 2.813552744190526
Validation loss: 2.5733209567768878

Epoch: 6| Step: 13
Training loss: 2.912229559789395
Validation loss: 2.5992984409038438

Epoch: 21| Step: 0
Training loss: 2.495870422019778
Validation loss: 2.5453565630797774

Epoch: 6| Step: 1
Training loss: 2.4311907371221526
Validation loss: 2.591778752968625

Epoch: 6| Step: 2
Training loss: 1.525030467244963
Validation loss: 2.589940671032599

Epoch: 6| Step: 3
Training loss: 2.786875831961481
Validation loss: 2.5585944411104546

Epoch: 6| Step: 4
Training loss: 2.8611048067716833
Validation loss: 2.578719561827584

Epoch: 6| Step: 5
Training loss: 2.8199838039934124
Validation loss: 2.5800412387410656

Epoch: 6| Step: 6
Training loss: 2.9613315450922575
Validation loss: 2.5837000976182543

Epoch: 6| Step: 7
Training loss: 2.609345395953886
Validation loss: 2.597875531341773

Epoch: 6| Step: 8
Training loss: 2.4601099954219925
Validation loss: 2.5924951666232365

Epoch: 6| Step: 9
Training loss: 2.0396511353655074
Validation loss: 2.555906325837052

Epoch: 6| Step: 10
Training loss: 2.6295277737973004
Validation loss: 2.5788040653983084

Epoch: 6| Step: 11
Training loss: 2.920268713723373
Validation loss: 2.530386757923315

Epoch: 6| Step: 12
Training loss: 2.6777060609485
Validation loss: 2.532504088952999

Epoch: 6| Step: 13
Training loss: 2.6657959788182577
Validation loss: 2.6057574156569916

Epoch: 22| Step: 0
Training loss: 2.86995187486447
Validation loss: 2.587675158089897

Epoch: 6| Step: 1
Training loss: 3.2768948671567033
Validation loss: 2.600693749525461

Epoch: 6| Step: 2
Training loss: 2.1582974650619575
Validation loss: 2.5795240594208066

Epoch: 6| Step: 3
Training loss: 2.2935981471548854
Validation loss: 2.597881733757122

Epoch: 6| Step: 4
Training loss: 1.6450717789778968
Validation loss: 2.5781080303211636

Epoch: 6| Step: 5
Training loss: 2.78716258243492
Validation loss: 2.5877136246712316

Epoch: 6| Step: 6
Training loss: 2.5360087179641817
Validation loss: 2.6270876560483174

Epoch: 6| Step: 7
Training loss: 2.4916469262743473
Validation loss: 2.5868794549432232

Epoch: 6| Step: 8
Training loss: 3.361814385041604
Validation loss: 2.629152805052024

Epoch: 6| Step: 9
Training loss: 2.313201179394066
Validation loss: 2.6047528611685618

Epoch: 6| Step: 10
Training loss: 2.1755918903236857
Validation loss: 2.595876258833995

Epoch: 6| Step: 11
Training loss: 2.850167045382511
Validation loss: 2.572259692950639

Epoch: 6| Step: 12
Training loss: 2.661217297254087
Validation loss: 2.5633476220052223

Epoch: 6| Step: 13
Training loss: 2.5573418036762465
Validation loss: 2.5434710919113654

Epoch: 23| Step: 0
Training loss: 2.700948467380228
Validation loss: 2.592161228199326

Epoch: 6| Step: 1
Training loss: 3.3182478645183906
Validation loss: 2.529821078893322

Epoch: 6| Step: 2
Training loss: 2.273588929261993
Validation loss: 2.5544336253097435

Epoch: 6| Step: 3
Training loss: 2.169030391805558
Validation loss: 2.590128426994655

Epoch: 6| Step: 4
Training loss: 3.013053786158842
Validation loss: 2.5832725384439446

Epoch: 6| Step: 5
Training loss: 2.409985108072324
Validation loss: 2.579246046070094

Epoch: 6| Step: 6
Training loss: 2.1657668470466995
Validation loss: 2.56153980346369

Epoch: 6| Step: 7
Training loss: 2.91545844711396
Validation loss: 2.5715306341576794

Epoch: 6| Step: 8
Training loss: 3.4235519410944506
Validation loss: 2.5861514061605404

Epoch: 6| Step: 9
Training loss: 2.0717261903926842
Validation loss: 2.571446486504026

Epoch: 6| Step: 10
Training loss: 1.7039213506072326
Validation loss: 2.542537748393526

Epoch: 6| Step: 11
Training loss: 2.8003851319156876
Validation loss: 2.5753503221640592

Epoch: 6| Step: 12
Training loss: 2.396004601590382
Validation loss: 2.5794690106428217

Epoch: 6| Step: 13
Training loss: 2.425255071851969
Validation loss: 2.5688042201053545

Epoch: 24| Step: 0
Training loss: 2.387409316332953
Validation loss: 2.5838892758939482

Epoch: 6| Step: 1
Training loss: 2.440927492120475
Validation loss: 2.577980330290332

Epoch: 6| Step: 2
Training loss: 2.4601280213205614
Validation loss: 2.5822366160538555

Epoch: 6| Step: 3
Training loss: 2.2870034601329654
Validation loss: 2.5474851692574125

Epoch: 6| Step: 4
Training loss: 3.061113627625631
Validation loss: 2.5990540532059754

Epoch: 6| Step: 5
Training loss: 2.9505906305814267
Validation loss: 2.6029389322923473

Epoch: 6| Step: 6
Training loss: 2.6703720773621
Validation loss: 2.637807776586188

Epoch: 6| Step: 7
Training loss: 2.9121283691114295
Validation loss: 2.6179864982808576

Epoch: 6| Step: 8
Training loss: 2.188628641246538
Validation loss: 2.571830216392929

Epoch: 6| Step: 9
Training loss: 2.558454436957506
Validation loss: 2.574791450450065

Epoch: 6| Step: 10
Training loss: 2.5738453804117385
Validation loss: 2.5298622000337625

Epoch: 6| Step: 11
Training loss: 2.4856204383967464
Validation loss: 2.573530723614185

Epoch: 6| Step: 12
Training loss: 2.2763332526428117
Validation loss: 2.595852042223118

Epoch: 6| Step: 13
Training loss: 2.8544813293605493
Validation loss: 2.548273556766853

Epoch: 25| Step: 0
Training loss: 2.4654361357593624
Validation loss: 2.5718051862298954

Epoch: 6| Step: 1
Training loss: 2.514123124742451
Validation loss: 2.5520851109297396

Epoch: 6| Step: 2
Training loss: 2.7104412581090314
Validation loss: 2.540044913357913

Epoch: 6| Step: 3
Training loss: 3.029014628362737
Validation loss: 2.540774021884793

Epoch: 6| Step: 4
Training loss: 2.867172532211442
Validation loss: 2.5472965788680137

Epoch: 6| Step: 5
Training loss: 1.8914789210291267
Validation loss: 2.5447440876978114

Epoch: 6| Step: 6
Training loss: 2.4169971196288063
Validation loss: 2.573573261656762

Epoch: 6| Step: 7
Training loss: 2.5258914129396297
Validation loss: 2.5824348569016777

Epoch: 6| Step: 8
Training loss: 3.1835600494286065
Validation loss: 2.5534650422862932

Epoch: 6| Step: 9
Training loss: 2.797714618839895
Validation loss: 2.5707915380492268

Epoch: 6| Step: 10
Training loss: 1.8386165470367533
Validation loss: 2.6081501871064905

Epoch: 6| Step: 11
Training loss: 2.375779475744878
Validation loss: 2.588610125633591

Epoch: 6| Step: 12
Training loss: 2.3909718380318137
Validation loss: 2.587669860252458

Epoch: 6| Step: 13
Training loss: 2.7045055237831974
Validation loss: 2.5643525986386813

Epoch: 26| Step: 0
Training loss: 2.3084934684028124
Validation loss: 2.5408115564023848

Epoch: 6| Step: 1
Training loss: 2.3254225234168846
Validation loss: 2.5470115531401754

Epoch: 6| Step: 2
Training loss: 1.8840981047532956
Validation loss: 2.5689087718893004

Epoch: 6| Step: 3
Training loss: 1.8134143759110841
Validation loss: 2.5804158677216367

Epoch: 6| Step: 4
Training loss: 3.2087353210945655
Validation loss: 2.5432060197418367

Epoch: 6| Step: 5
Training loss: 3.416490193593408
Validation loss: 2.5075835047161017

Epoch: 6| Step: 6
Training loss: 2.4538468191874023
Validation loss: 2.5454032873952177

Epoch: 6| Step: 7
Training loss: 2.5879770401256046
Validation loss: 2.503494141497854

Epoch: 6| Step: 8
Training loss: 2.433531832328289
Validation loss: 2.6098531410584114

Epoch: 6| Step: 9
Training loss: 1.833803015568588
Validation loss: 2.5984230535047885

Epoch: 6| Step: 10
Training loss: 2.4684976376341976
Validation loss: 2.613345462331392

Epoch: 6| Step: 11
Training loss: 2.6498456154243204
Validation loss: 2.539841916691738

Epoch: 6| Step: 12
Training loss: 3.2259006514177373
Validation loss: 2.5775963212301924

Epoch: 6| Step: 13
Training loss: 2.718868033817556
Validation loss: 2.563990926818743

Epoch: 27| Step: 0
Training loss: 2.17075203604835
Validation loss: 2.561129661055234

Epoch: 6| Step: 1
Training loss: 2.272719227169708
Validation loss: 2.5920065876667078

Epoch: 6| Step: 2
Training loss: 2.9796909502286493
Validation loss: 2.574055907251158

Epoch: 6| Step: 3
Training loss: 2.7756929924137443
Validation loss: 2.6711084556416527

Epoch: 6| Step: 4
Training loss: 2.654998933465029
Validation loss: 2.6678866834106003

Epoch: 6| Step: 5
Training loss: 2.0250448669361
Validation loss: 2.6389292251002674

Epoch: 6| Step: 6
Training loss: 2.802100218163047
Validation loss: 2.65582057997298

Epoch: 6| Step: 7
Training loss: 2.306484336629492
Validation loss: 2.6275132727174326

Epoch: 6| Step: 8
Training loss: 2.0461238035927605
Validation loss: 2.567643191199278

Epoch: 6| Step: 9
Training loss: 2.42890343480332
Validation loss: 2.575265412093206

Epoch: 6| Step: 10
Training loss: 3.102642188491075
Validation loss: 2.5711979833597964

Epoch: 6| Step: 11
Training loss: 1.8165854088811817
Validation loss: 2.595612389686742

Epoch: 6| Step: 12
Training loss: 3.319739581775671
Validation loss: 2.5510673888220596

Epoch: 6| Step: 13
Training loss: 2.452914283595335
Validation loss: 2.551611087209547

Epoch: 28| Step: 0
Training loss: 2.2062292211488863
Validation loss: 2.5528171003461098

Epoch: 6| Step: 1
Training loss: 2.1119552090403517
Validation loss: 2.5575373596962896

Epoch: 6| Step: 2
Training loss: 2.2520772034605474
Validation loss: 2.5931707141297973

Epoch: 6| Step: 3
Training loss: 3.480447514358968
Validation loss: 2.534062820317257

Epoch: 6| Step: 4
Training loss: 2.573519390311083
Validation loss: 2.578961824182143

Epoch: 6| Step: 5
Training loss: 2.717121030884007
Validation loss: 2.5511936479444546

Epoch: 6| Step: 6
Training loss: 3.1587826982020224
Validation loss: 2.563254175621597

Epoch: 6| Step: 7
Training loss: 2.116146718640854
Validation loss: 2.563567931469404

Epoch: 6| Step: 8
Training loss: 2.634494685557361
Validation loss: 2.656330616045549

Epoch: 6| Step: 9
Training loss: 2.5475582774256376
Validation loss: 2.614840252982883

Epoch: 6| Step: 10
Training loss: 2.3216645382855208
Validation loss: 2.6271909849499875

Epoch: 6| Step: 11
Training loss: 2.8775175930250967
Validation loss: 2.6368921444240523

Epoch: 6| Step: 12
Training loss: 2.5584551824655466
Validation loss: 2.544502744904453

Epoch: 6| Step: 13
Training loss: 2.2296295992545097
Validation loss: 2.541732948773065

Epoch: 29| Step: 0
Training loss: 2.852820884315354
Validation loss: 2.5817317048268613

Epoch: 6| Step: 1
Training loss: 1.6624670842863174
Validation loss: 2.568921919837296

Epoch: 6| Step: 2
Training loss: 2.284564393172741
Validation loss: 2.594135401331391

Epoch: 6| Step: 3
Training loss: 2.2061637321226524
Validation loss: 2.554631146072864

Epoch: 6| Step: 4
Training loss: 1.878058037857401
Validation loss: 2.5795837745015042

Epoch: 6| Step: 5
Training loss: 2.6444521825963916
Validation loss: 2.5298311471946184

Epoch: 6| Step: 6
Training loss: 2.8156429954910585
Validation loss: 2.5438704603511235

Epoch: 6| Step: 7
Training loss: 2.5113098855898253
Validation loss: 2.5687129677781644

Epoch: 6| Step: 8
Training loss: 2.8061834824458822
Validation loss: 2.5418048232213057

Epoch: 6| Step: 9
Training loss: 2.7351115079531034
Validation loss: 2.5660552041678275

Epoch: 6| Step: 10
Training loss: 3.471044657770244
Validation loss: 2.575111446623136

Epoch: 6| Step: 11
Training loss: 1.9306340540867812
Validation loss: 2.5973273123991865

Epoch: 6| Step: 12
Training loss: 2.61710314258872
Validation loss: 2.575226450965594

Epoch: 6| Step: 13
Training loss: 2.898250604654955
Validation loss: 2.5790520590697126

Epoch: 30| Step: 0
Training loss: 1.9277289331546796
Validation loss: 2.600416394965996

Epoch: 6| Step: 1
Training loss: 2.6925431772097763
Validation loss: 2.560135440472165

Epoch: 6| Step: 2
Training loss: 2.6388477009910742
Validation loss: 2.5229940900780012

Epoch: 6| Step: 3
Training loss: 2.473901034578372
Validation loss: 2.573139479612389

Epoch: 6| Step: 4
Training loss: 2.60013199617875
Validation loss: 2.5597309565232687

Epoch: 6| Step: 5
Training loss: 2.591381600291172
Validation loss: 2.541640771410828

Epoch: 6| Step: 6
Training loss: 2.003635916219717
Validation loss: 2.5449703013842573

Epoch: 6| Step: 7
Training loss: 2.6625676142027674
Validation loss: 2.5971731554134854

Epoch: 6| Step: 8
Training loss: 2.398288585500765
Validation loss: 2.57488779607459

Epoch: 6| Step: 9
Training loss: 3.6501037582908604
Validation loss: 2.5867825958689505

Epoch: 6| Step: 10
Training loss: 1.8689549592062473
Validation loss: 2.5865303735203873

Epoch: 6| Step: 11
Training loss: 2.460430565347157
Validation loss: 2.5732485882693363

Epoch: 6| Step: 12
Training loss: 2.4654197926576966
Validation loss: 2.5357864450847356

Epoch: 6| Step: 13
Training loss: 2.705323488420923
Validation loss: 2.5658735538199275

Epoch: 31| Step: 0
Training loss: 3.0772576828731384
Validation loss: 2.5613101274622982

Epoch: 6| Step: 1
Training loss: 2.4158794392448106
Validation loss: 2.6028699520196295

Epoch: 6| Step: 2
Training loss: 2.4485101724342826
Validation loss: 2.637968363464468

Epoch: 6| Step: 3
Training loss: 2.4516523277888607
Validation loss: 2.597543607865257

Epoch: 6| Step: 4
Training loss: 3.2599733353910945
Validation loss: 2.700826406280696

Epoch: 6| Step: 5
Training loss: 2.0397972449352797
Validation loss: 2.6359232288781533

Epoch: 6| Step: 6
Training loss: 2.6032483020169908
Validation loss: 2.6602310491306977

Epoch: 6| Step: 7
Training loss: 2.9820555616251734
Validation loss: 2.5941782678217487

Epoch: 6| Step: 8
Training loss: 2.1916841001022735
Validation loss: 2.575721097796663

Epoch: 6| Step: 9
Training loss: 2.5910237703694237
Validation loss: 2.5018039155610916

Epoch: 6| Step: 10
Training loss: 2.394173674776217
Validation loss: 2.5452552122347423

Epoch: 6| Step: 11
Training loss: 2.1572882322698197
Validation loss: 2.5454083141498547

Epoch: 6| Step: 12
Training loss: 2.197360783529729
Validation loss: 2.5857541421690313

Epoch: 6| Step: 13
Training loss: 2.442336151031178
Validation loss: 2.565297220520497

Epoch: 32| Step: 0
Training loss: 2.264766346245983
Validation loss: 2.5430859891759257

Epoch: 6| Step: 1
Training loss: 2.6120538723050353
Validation loss: 2.545015978884795

Epoch: 6| Step: 2
Training loss: 2.4408696675963455
Validation loss: 2.532729466101113

Epoch: 6| Step: 3
Training loss: 3.4847262765668146
Validation loss: 2.5312890807223547

Epoch: 6| Step: 4
Training loss: 2.5373909010711904
Validation loss: 2.5819839881038034

Epoch: 6| Step: 5
Training loss: 2.8765408906223398
Validation loss: 2.5552779671197494

Epoch: 6| Step: 6
Training loss: 2.6905041249911212
Validation loss: 2.5402419964834735

Epoch: 6| Step: 7
Training loss: 2.3152319776671617
Validation loss: 2.601468623914294

Epoch: 6| Step: 8
Training loss: 2.1522687563145917
Validation loss: 2.562367148948594

Epoch: 6| Step: 9
Training loss: 2.2526598149888124
Validation loss: 2.5593288501309557

Epoch: 6| Step: 10
Training loss: 2.0273121149612128
Validation loss: 2.5485004472627995

Epoch: 6| Step: 11
Training loss: 3.078922536323409
Validation loss: 2.5721734913145706

Epoch: 6| Step: 12
Training loss: 2.547053980242956
Validation loss: 2.5525302625375956

Epoch: 6| Step: 13
Training loss: 1.4398706211143055
Validation loss: 2.5878679689579225

Epoch: 33| Step: 0
Training loss: 1.713856545439716
Validation loss: 2.593952814468601

Epoch: 6| Step: 1
Training loss: 2.7024109178341744
Validation loss: 2.598027727148952

Epoch: 6| Step: 2
Training loss: 2.2232033537236435
Validation loss: 2.5542168451040235

Epoch: 6| Step: 3
Training loss: 3.4915492351392334
Validation loss: 2.577982835028882

Epoch: 6| Step: 4
Training loss: 2.500094316610768
Validation loss: 2.567245957615853

Epoch: 6| Step: 5
Training loss: 2.008382634656539
Validation loss: 2.5770743338803737

Epoch: 6| Step: 6
Training loss: 2.371255030166688
Validation loss: 2.558361689403171

Epoch: 6| Step: 7
Training loss: 2.9125219778123967
Validation loss: 2.564295116707884

Epoch: 6| Step: 8
Training loss: 2.188542907607973
Validation loss: 2.568971850490319

Epoch: 6| Step: 9
Training loss: 2.5688646871019984
Validation loss: 2.6112825042079675

Epoch: 6| Step: 10
Training loss: 2.0447777639944094
Validation loss: 2.5928052460849957

Epoch: 6| Step: 11
Training loss: 2.817993394084522
Validation loss: 2.508592098191584

Epoch: 6| Step: 12
Training loss: 2.216246145796934
Validation loss: 2.556773711437523

Epoch: 6| Step: 13
Training loss: 2.5472889195257324
Validation loss: 2.5763055565705013

Epoch: 34| Step: 0
Training loss: 2.6266785658971865
Validation loss: 2.5433111082416677

Epoch: 6| Step: 1
Training loss: 2.9362194435475195
Validation loss: 2.5275543298111103

Epoch: 6| Step: 2
Training loss: 2.3079268110164466
Validation loss: 2.5318770868108698

Epoch: 6| Step: 3
Training loss: 1.6865230840827292
Validation loss: 2.5633024804482947

Epoch: 6| Step: 4
Training loss: 2.298952369929952
Validation loss: 2.5961203563917494

Epoch: 6| Step: 5
Training loss: 2.0968555932774287
Validation loss: 2.5996247827774046

Epoch: 6| Step: 6
Training loss: 2.4197106319219923
Validation loss: 2.5855850678734384

Epoch: 6| Step: 7
Training loss: 2.3792159156133583
Validation loss: 2.622486659689721

Epoch: 6| Step: 8
Training loss: 3.067877893775788
Validation loss: 2.561095542910966

Epoch: 6| Step: 9
Training loss: 3.212872518471016
Validation loss: 2.5667926530344185

Epoch: 6| Step: 10
Training loss: 2.626962291602269
Validation loss: 2.51841691483307

Epoch: 6| Step: 11
Training loss: 2.2773288837556156
Validation loss: 2.5446154941117003

Epoch: 6| Step: 12
Training loss: 2.1062305891008495
Validation loss: 2.5287875297176363

Epoch: 6| Step: 13
Training loss: 2.436160575435084
Validation loss: 2.559501017292643

Epoch: 35| Step: 0
Training loss: 2.094599764883217
Validation loss: 2.5302321502917304

Epoch: 6| Step: 1
Training loss: 2.0892273751522232
Validation loss: 2.554711313554714

Epoch: 6| Step: 2
Training loss: 2.8500102795867246
Validation loss: 2.5479683898599896

Epoch: 6| Step: 3
Training loss: 3.2076232586768185
Validation loss: 2.553685247366199

Epoch: 6| Step: 4
Training loss: 2.5229909401336705
Validation loss: 2.5325768372307405

Epoch: 6| Step: 5
Training loss: 2.5158678020564427
Validation loss: 2.5672500593441923

Epoch: 6| Step: 6
Training loss: 2.220988903596752
Validation loss: 2.6474284872807625

Epoch: 6| Step: 7
Training loss: 2.6296139992989156
Validation loss: 2.6474688473682635

Epoch: 6| Step: 8
Training loss: 2.1765792725540494
Validation loss: 2.649566964690155

Epoch: 6| Step: 9
Training loss: 2.4621817213683737
Validation loss: 2.6446739620316144

Epoch: 6| Step: 10
Training loss: 2.1954304402121374
Validation loss: 2.569701441951579

Epoch: 6| Step: 11
Training loss: 3.581863782123285
Validation loss: 2.6090422854103235

Epoch: 6| Step: 12
Training loss: 2.426600024737021
Validation loss: 2.566093150896804

Epoch: 6| Step: 13
Training loss: 1.8166255695465756
Validation loss: 2.5573097404468013

Epoch: 36| Step: 0
Training loss: 2.7965878813432936
Validation loss: 2.5476555437564503

Epoch: 6| Step: 1
Training loss: 2.0222824511565785
Validation loss: 2.5571100101837474

Epoch: 6| Step: 2
Training loss: 2.383068433681025
Validation loss: 2.5702616909767855

Epoch: 6| Step: 3
Training loss: 2.2677042923556763
Validation loss: 2.5688667598773685

Epoch: 6| Step: 4
Training loss: 2.873661558989721
Validation loss: 2.589542607309171

Epoch: 6| Step: 5
Training loss: 2.889693981455047
Validation loss: 2.6433616316853223

Epoch: 6| Step: 6
Training loss: 2.131535521592256
Validation loss: 2.551927481323496

Epoch: 6| Step: 7
Training loss: 2.4490829503134166
Validation loss: 2.5937481998912277

Epoch: 6| Step: 8
Training loss: 2.671072499184258
Validation loss: 2.607625409015389

Epoch: 6| Step: 9
Training loss: 2.7198550729849544
Validation loss: 2.534225065575978

Epoch: 6| Step: 10
Training loss: 2.3676654597533586
Validation loss: 2.5219293581411484

Epoch: 6| Step: 11
Training loss: 2.6356324621415608
Validation loss: 2.5730341268026433

Epoch: 6| Step: 12
Training loss: 2.3238469700025934
Validation loss: 2.6425195627802665

Epoch: 6| Step: 13
Training loss: 2.372697115267678
Validation loss: 2.6616256770746096

Epoch: 37| Step: 0
Training loss: 1.4184995556233315
Validation loss: 2.677736111229265

Epoch: 6| Step: 1
Training loss: 3.401041230478692
Validation loss: 2.6686068321497176

Epoch: 6| Step: 2
Training loss: 2.9650338454992475
Validation loss: 2.6732837614218257

Epoch: 6| Step: 3
Training loss: 3.0492991658464788
Validation loss: 2.678403541208134

Epoch: 6| Step: 4
Training loss: 2.3965563028822254
Validation loss: 2.688555909249261

Epoch: 6| Step: 5
Training loss: 2.781839201162693
Validation loss: 2.591202078101807

Epoch: 6| Step: 6
Training loss: 2.329917883019436
Validation loss: 2.611116852032548

Epoch: 6| Step: 7
Training loss: 2.6963808457870604
Validation loss: 2.569055437304823

Epoch: 6| Step: 8
Training loss: 2.1687152299100045
Validation loss: 2.5491613879049897

Epoch: 6| Step: 9
Training loss: 2.2871654578547664
Validation loss: 2.5535537583828725

Epoch: 6| Step: 10
Training loss: 2.4073460052137
Validation loss: 2.526657962666653

Epoch: 6| Step: 11
Training loss: 1.9922806063567782
Validation loss: 2.554491438035398

Epoch: 6| Step: 12
Training loss: 2.392121687967388
Validation loss: 2.5239674392601006

Epoch: 6| Step: 13
Training loss: 2.5929626740616896
Validation loss: 2.552958261935385

Epoch: 38| Step: 0
Training loss: 2.4860661346894624
Validation loss: 2.5202569749284893

Epoch: 6| Step: 1
Training loss: 1.8330991841113433
Validation loss: 2.54081867225882

Epoch: 6| Step: 2
Training loss: 2.3835949222908153
Validation loss: 2.5765463725784956

Epoch: 6| Step: 3
Training loss: 1.612835764858511
Validation loss: 2.5883756900333923

Epoch: 6| Step: 4
Training loss: 3.2035359933068643
Validation loss: 2.5778522077407815

Epoch: 6| Step: 5
Training loss: 2.694194617165277
Validation loss: 2.6782796588813826

Epoch: 6| Step: 6
Training loss: 1.67273162572185
Validation loss: 2.6829088976157545

Epoch: 6| Step: 7
Training loss: 3.155568719740916
Validation loss: 2.7061687231156073

Epoch: 6| Step: 8
Training loss: 3.216580150277493
Validation loss: 2.699456402722327

Epoch: 6| Step: 9
Training loss: 2.9913725776600386
Validation loss: 2.671148874465843

Epoch: 6| Step: 10
Training loss: 2.9716114910121787
Validation loss: 2.667621193360915

Epoch: 6| Step: 11
Training loss: 1.9507437265841074
Validation loss: 2.642690509098997

Epoch: 6| Step: 12
Training loss: 1.8090977800638723
Validation loss: 2.5915814415349008

Epoch: 6| Step: 13
Training loss: 2.106062711544577
Validation loss: 2.597324352047012

Epoch: 39| Step: 0
Training loss: 2.710923252562975
Validation loss: 2.5154682687148036

Epoch: 6| Step: 1
Training loss: 1.7305164201426408
Validation loss: 2.5848645138359587

Epoch: 6| Step: 2
Training loss: 2.0820628552068805
Validation loss: 2.560740727609034

Epoch: 6| Step: 3
Training loss: 2.2194485706370033
Validation loss: 2.621843013939633

Epoch: 6| Step: 4
Training loss: 2.3741327007198736
Validation loss: 2.5201271476155576

Epoch: 6| Step: 5
Training loss: 1.892970120330705
Validation loss: 2.5526481522404847

Epoch: 6| Step: 6
Training loss: 2.8800669262315335
Validation loss: 2.587691527571247

Epoch: 6| Step: 7
Training loss: 2.0542734403374303
Validation loss: 2.5558817927050637

Epoch: 6| Step: 8
Training loss: 2.5286432666287553
Validation loss: 2.5579322639317477

Epoch: 6| Step: 9
Training loss: 2.303748815725584
Validation loss: 2.541410485369748

Epoch: 6| Step: 10
Training loss: 2.6390416742455094
Validation loss: 2.545995338038621

Epoch: 6| Step: 11
Training loss: 2.8976738841532543
Validation loss: 2.5572112796577042

Epoch: 6| Step: 12
Training loss: 2.6122734738205278
Validation loss: 2.5500542391824172

Epoch: 6| Step: 13
Training loss: 3.4734716498669167
Validation loss: 2.558786104460338

Epoch: 40| Step: 0
Training loss: 2.966348419550035
Validation loss: 2.5622038321190295

Epoch: 6| Step: 1
Training loss: 3.1078515082472093
Validation loss: 2.5533785018295556

Epoch: 6| Step: 2
Training loss: 2.3614894663527135
Validation loss: 2.5506213665286457

Epoch: 6| Step: 3
Training loss: 2.701464721957689
Validation loss: 2.587961547647462

Epoch: 6| Step: 4
Training loss: 1.9341104452872104
Validation loss: 2.637900171159542

Epoch: 6| Step: 5
Training loss: 1.9138991305639037
Validation loss: 2.5767954933643855

Epoch: 6| Step: 6
Training loss: 3.3851066721303864
Validation loss: 2.6869625914515267

Epoch: 6| Step: 7
Training loss: 2.823718183590667
Validation loss: 2.603296750048107

Epoch: 6| Step: 8
Training loss: 2.206485430985965
Validation loss: 2.6430836128535957

Epoch: 6| Step: 9
Training loss: 1.9930038873736975
Validation loss: 2.6545810168432875

Epoch: 6| Step: 10
Training loss: 2.428303511451068
Validation loss: 2.6505408173043423

Epoch: 6| Step: 11
Training loss: 2.2073721563315623
Validation loss: 2.6128917683253707

Epoch: 6| Step: 12
Training loss: 1.711125890384498
Validation loss: 2.540935228714502

Epoch: 6| Step: 13
Training loss: 1.963549815463722
Validation loss: 2.556995574114881

Epoch: 41| Step: 0
Training loss: 2.6124893151753783
Validation loss: 2.5302290250629156

Epoch: 6| Step: 1
Training loss: 2.4651592554486457
Validation loss: 2.525824867199946

Epoch: 6| Step: 2
Training loss: 2.606521233731759
Validation loss: 2.5438016669097685

Epoch: 6| Step: 3
Training loss: 2.626039934794546
Validation loss: 2.5759160915257824

Epoch: 6| Step: 4
Training loss: 2.0454063679579684
Validation loss: 2.530152981873658

Epoch: 6| Step: 5
Training loss: 2.4246589656802287
Validation loss: 2.570671906702187

Epoch: 6| Step: 6
Training loss: 2.4125563975645092
Validation loss: 2.5690327466305862

Epoch: 6| Step: 7
Training loss: 1.7097036014468752
Validation loss: 2.6237444221154993

Epoch: 6| Step: 8
Training loss: 3.109040668858359
Validation loss: 2.5980903281929026

Epoch: 6| Step: 9
Training loss: 2.6153614563153935
Validation loss: 2.575898459392921

Epoch: 6| Step: 10
Training loss: 2.2214298451550976
Validation loss: 2.6278801814963306

Epoch: 6| Step: 11
Training loss: 2.6219841117115625
Validation loss: 2.645650622049058

Epoch: 6| Step: 12
Training loss: 2.0594326676903627
Validation loss: 2.5672014960079483

Epoch: 6| Step: 13
Training loss: 2.762800336711107
Validation loss: 2.572179593496723

Epoch: 42| Step: 0
Training loss: 1.9920869689708227
Validation loss: 2.595343456508564

Epoch: 6| Step: 1
Training loss: 2.751028908802645
Validation loss: 2.6072117943492765

Epoch: 6| Step: 2
Training loss: 2.9312329907930343
Validation loss: 2.584778363609276

Epoch: 6| Step: 3
Training loss: 2.1365780409208246
Validation loss: 2.635498201418235

Epoch: 6| Step: 4
Training loss: 2.7353026642083758
Validation loss: 2.6719568102471665

Epoch: 6| Step: 5
Training loss: 2.1548960761128217
Validation loss: 2.6163402495512926

Epoch: 6| Step: 6
Training loss: 3.056308170069263
Validation loss: 2.601824971534443

Epoch: 6| Step: 7
Training loss: 1.814007559641739
Validation loss: 2.6253071408496536

Epoch: 6| Step: 8
Training loss: 2.4478941138561052
Validation loss: 2.6254508827141976

Epoch: 6| Step: 9
Training loss: 2.24109391715198
Validation loss: 2.6513632608645725

Epoch: 6| Step: 10
Training loss: 2.165712244167293
Validation loss: 2.651399769357433

Epoch: 6| Step: 11
Training loss: 3.0278113613152113
Validation loss: 2.602445175834465

Epoch: 6| Step: 12
Training loss: 2.220445978714832
Validation loss: 2.580295111796375

Epoch: 6| Step: 13
Training loss: 2.3273305881687665
Validation loss: 2.4777823892425976

Epoch: 43| Step: 0
Training loss: 1.8022702364569265
Validation loss: 2.5362423146173567

Epoch: 6| Step: 1
Training loss: 2.576783634687611
Validation loss: 2.5715267324129303

Epoch: 6| Step: 2
Training loss: 2.4511002853091464
Validation loss: 2.519797282996561

Epoch: 6| Step: 3
Training loss: 3.0021855023003106
Validation loss: 2.571658770346576

Epoch: 6| Step: 4
Training loss: 2.553344373488234
Validation loss: 2.54779781793202

Epoch: 6| Step: 5
Training loss: 2.6363624614605334
Validation loss: 2.556401508943139

Epoch: 6| Step: 6
Training loss: 2.338746694116993
Validation loss: 2.5440878410219034

Epoch: 6| Step: 7
Training loss: 2.354028973448907
Validation loss: 2.599867840611408

Epoch: 6| Step: 8
Training loss: 1.9775841526495268
Validation loss: 2.5878263645470967

Epoch: 6| Step: 9
Training loss: 2.7263193104017156
Validation loss: 2.60013172109434

Epoch: 6| Step: 10
Training loss: 1.8333692402646777
Validation loss: 2.578295769478452

Epoch: 6| Step: 11
Training loss: 2.7793299015573294
Validation loss: 2.5453091197716375

Epoch: 6| Step: 12
Training loss: 2.296920464513365
Validation loss: 2.615586522775299

Epoch: 6| Step: 13
Training loss: 2.749171392277355
Validation loss: 2.582683032745468

Epoch: 44| Step: 0
Training loss: 2.5303196080190316
Validation loss: 2.652922472133868

Epoch: 6| Step: 1
Training loss: 2.1213475421515176
Validation loss: 2.6378968722160585

Epoch: 6| Step: 2
Training loss: 1.861196187037537
Validation loss: 2.70253718605536

Epoch: 6| Step: 3
Training loss: 3.0553981412933484
Validation loss: 2.573124561842556

Epoch: 6| Step: 4
Training loss: 2.0036505523009955
Validation loss: 2.6411325843422055

Epoch: 6| Step: 5
Training loss: 2.2807662660018093
Validation loss: 2.620399834260415

Epoch: 6| Step: 6
Training loss: 1.9532125224530565
Validation loss: 2.63802257561634

Epoch: 6| Step: 7
Training loss: 1.8288642497171388
Validation loss: 2.5984289334710895

Epoch: 6| Step: 8
Training loss: 2.4066506584811544
Validation loss: 2.617404530195069

Epoch: 6| Step: 9
Training loss: 3.525092639111609
Validation loss: 2.6220990606208416

Epoch: 6| Step: 10
Training loss: 2.796461191945828
Validation loss: 2.5688250101465684

Epoch: 6| Step: 11
Training loss: 2.2962843985517085
Validation loss: 2.660678836468104

Epoch: 6| Step: 12
Training loss: 2.28883876292989
Validation loss: 2.5740396208659257

Epoch: 6| Step: 13
Training loss: 2.320193406462033
Validation loss: 2.560589504590274

Epoch: 45| Step: 0
Training loss: 1.8472630927297813
Validation loss: 2.531295964329972

Epoch: 6| Step: 1
Training loss: 2.3233329046496194
Validation loss: 2.5144172754794485

Epoch: 6| Step: 2
Training loss: 2.610848108081997
Validation loss: 2.6339095685333405

Epoch: 6| Step: 3
Training loss: 2.8750864098873357
Validation loss: 2.6240238009396846

Epoch: 6| Step: 4
Training loss: 2.35544972072019
Validation loss: 2.5871623999965467

Epoch: 6| Step: 5
Training loss: 3.3537391405928596
Validation loss: 2.5251300753083927

Epoch: 6| Step: 6
Training loss: 2.166755625536922
Validation loss: 2.5434195748310837

Epoch: 6| Step: 7
Training loss: 2.6720002797520657
Validation loss: 2.611849481488865

Epoch: 6| Step: 8
Training loss: 2.4424512412007964
Validation loss: 2.5865257185783066

Epoch: 6| Step: 9
Training loss: 2.0764491846125384
Validation loss: 2.579620590281856

Epoch: 6| Step: 10
Training loss: 2.095540434112054
Validation loss: 2.612269959976529

Epoch: 6| Step: 11
Training loss: 2.296799120006439
Validation loss: 2.672646201154887

Epoch: 6| Step: 12
Training loss: 2.658527430162011
Validation loss: 2.749114291291645

Epoch: 6| Step: 13
Training loss: 2.3415784821473355
Validation loss: 2.6154380151172014

Epoch: 46| Step: 0
Training loss: 2.3707317346168737
Validation loss: 2.6286181763933154

Epoch: 6| Step: 1
Training loss: 3.236133337058244
Validation loss: 2.683807438574955

Epoch: 6| Step: 2
Training loss: 2.3450696154836947
Validation loss: 2.6441793052626967

Epoch: 6| Step: 3
Training loss: 1.9801248406058027
Validation loss: 2.610041946181249

Epoch: 6| Step: 4
Training loss: 2.3061218970471895
Validation loss: 2.5619385266995387

Epoch: 6| Step: 5
Training loss: 2.279829863508014
Validation loss: 2.6025056857127273

Epoch: 6| Step: 6
Training loss: 2.09603756869477
Validation loss: 2.5674772384263593

Epoch: 6| Step: 7
Training loss: 2.1449563416348436
Validation loss: 2.5724396411424637

Epoch: 6| Step: 8
Training loss: 2.1275868098011292
Validation loss: 2.520864255310909

Epoch: 6| Step: 9
Training loss: 2.162222069316326
Validation loss: 2.526013298793005

Epoch: 6| Step: 10
Training loss: 2.4165204321804334
Validation loss: 2.5636646136382004

Epoch: 6| Step: 11
Training loss: 2.445897334061328
Validation loss: 2.5661957769151504

Epoch: 6| Step: 12
Training loss: 3.2949974173505328
Validation loss: 2.586194904343436

Epoch: 6| Step: 13
Training loss: 2.2305204849790403
Validation loss: 2.5239999024330197

Epoch: 47| Step: 0
Training loss: 2.3589331611068034
Validation loss: 2.567823942624049

Epoch: 6| Step: 1
Training loss: 2.2518690611342507
Validation loss: 2.58138225823121

Epoch: 6| Step: 2
Training loss: 2.1078168977842835
Validation loss: 2.5781989886523484

Epoch: 6| Step: 3
Training loss: 2.35851671384316
Validation loss: 2.579295715242416

Epoch: 6| Step: 4
Training loss: 1.8914979542966464
Validation loss: 2.6051168742720243

Epoch: 6| Step: 5
Training loss: 2.750223844261132
Validation loss: 2.5623828426964153

Epoch: 6| Step: 6
Training loss: 2.12038144116918
Validation loss: 2.6456815771200453

Epoch: 6| Step: 7
Training loss: 2.726019950161179
Validation loss: 2.633740285219713

Epoch: 6| Step: 8
Training loss: 2.5086325377225074
Validation loss: 2.6628790396062074

Epoch: 6| Step: 9
Training loss: 2.400729994222064
Validation loss: 2.6150078878411387

Epoch: 6| Step: 10
Training loss: 2.2750330828262917
Validation loss: 2.6297198203887273

Epoch: 6| Step: 11
Training loss: 2.724582335635318
Validation loss: 2.6153426695156328

Epoch: 6| Step: 12
Training loss: 2.5818050129587564
Validation loss: 2.657593495807769

Epoch: 6| Step: 13
Training loss: 2.319703712617423
Validation loss: 2.568453950675725

Epoch: 48| Step: 0
Training loss: 2.9831796219366815
Validation loss: 2.613062432692811

Epoch: 6| Step: 1
Training loss: 2.5430961612126586
Validation loss: 2.5816145121521243

Epoch: 6| Step: 2
Training loss: 1.7264772972384081
Validation loss: 2.518511867072894

Epoch: 6| Step: 3
Training loss: 1.8869420268943367
Validation loss: 2.5608620952733463

Epoch: 6| Step: 4
Training loss: 2.8898957853435623
Validation loss: 2.564041681881236

Epoch: 6| Step: 5
Training loss: 3.0465209755262297
Validation loss: 2.6010882276574683

Epoch: 6| Step: 6
Training loss: 2.446421606314473
Validation loss: 2.572219357741839

Epoch: 6| Step: 7
Training loss: 2.075351097093814
Validation loss: 2.5713978401623425

Epoch: 6| Step: 8
Training loss: 3.1157894967290787
Validation loss: 2.5238079039336263

Epoch: 6| Step: 9
Training loss: 2.272118569268814
Validation loss: 2.5676497684219677

Epoch: 6| Step: 10
Training loss: 2.326319461627923
Validation loss: 2.5596507133926956

Epoch: 6| Step: 11
Training loss: 2.0213585266155376
Validation loss: 2.585254037205947

Epoch: 6| Step: 12
Training loss: 1.8327928598950032
Validation loss: 2.6147631599826258

Epoch: 6| Step: 13
Training loss: 2.0472241751760585
Validation loss: 2.5729017270126793

Epoch: 49| Step: 0
Training loss: 1.8245752545782101
Validation loss: 2.583790989811948

Epoch: 6| Step: 1
Training loss: 2.504022033204468
Validation loss: 2.603785331780592

Epoch: 6| Step: 2
Training loss: 2.771231276156811
Validation loss: 2.624315308784378

Epoch: 6| Step: 3
Training loss: 2.8627569491407256
Validation loss: 2.7071852720479623

Epoch: 6| Step: 4
Training loss: 2.1178865862154974
Validation loss: 2.682671452767171

Epoch: 6| Step: 5
Training loss: 2.6278899497065233
Validation loss: 2.685496315220088

Epoch: 6| Step: 6
Training loss: 2.4867770500671593
Validation loss: 2.607724564374226

Epoch: 6| Step: 7
Training loss: 1.949608345314263
Validation loss: 2.5654140588589027

Epoch: 6| Step: 8
Training loss: 2.3365634857702173
Validation loss: 2.5976864767586623

Epoch: 6| Step: 9
Training loss: 2.5742311607605797
Validation loss: 2.5860491187831514

Epoch: 6| Step: 10
Training loss: 1.7944697328418697
Validation loss: 2.5853123672763823

Epoch: 6| Step: 11
Training loss: 1.9273232250566519
Validation loss: 2.6354493276107647

Epoch: 6| Step: 12
Training loss: 2.5046748322221863
Validation loss: 2.5248720246796728

Epoch: 6| Step: 13
Training loss: 3.2187701474642503
Validation loss: 2.538686010373507

Epoch: 50| Step: 0
Training loss: 2.277895512161379
Validation loss: 2.5608072660116457

Epoch: 6| Step: 1
Training loss: 2.5998217741695853
Validation loss: 2.5971907655122206

Epoch: 6| Step: 2
Training loss: 2.0891509146515608
Validation loss: 2.585409504288541

Epoch: 6| Step: 3
Training loss: 2.4669642689888667
Validation loss: 2.5996849303200937

Epoch: 6| Step: 4
Training loss: 2.196186584008696
Validation loss: 2.615318731913703

Epoch: 6| Step: 5
Training loss: 2.7061695747670766
Validation loss: 2.5892565921342134

Epoch: 6| Step: 6
Training loss: 2.998628302740779
Validation loss: 2.650467476308041

Epoch: 6| Step: 7
Training loss: 1.8675860374680415
Validation loss: 2.6241245777933746

Epoch: 6| Step: 8
Training loss: 2.8052765379125457
Validation loss: 2.613532631591003

Epoch: 6| Step: 9
Training loss: 2.248911912399836
Validation loss: 2.5499720786940876

Epoch: 6| Step: 10
Training loss: 1.9570761426090095
Validation loss: 2.559569148151085

Epoch: 6| Step: 11
Training loss: 2.4013376005319444
Validation loss: 2.554465545749479

Epoch: 6| Step: 12
Training loss: 2.827898385257814
Validation loss: 2.5694457721420387

Epoch: 6| Step: 13
Training loss: 2.0529193885536903
Validation loss: 2.5372242224906087

Epoch: 51| Step: 0
Training loss: 2.0237848285696365
Validation loss: 2.5655167817413402

Epoch: 6| Step: 1
Training loss: 2.667201008508282
Validation loss: 2.5338363150228815

Epoch: 6| Step: 2
Training loss: 2.342558697888221
Validation loss: 2.564326511500759

Epoch: 6| Step: 3
Training loss: 2.151469806123283
Validation loss: 2.54229977544825

Epoch: 6| Step: 4
Training loss: 2.1997919504453463
Validation loss: 2.568574667683613

Epoch: 6| Step: 5
Training loss: 2.12064015296224
Validation loss: 2.5773038307745524

Epoch: 6| Step: 6
Training loss: 2.2151261945128966
Validation loss: 2.6343240445640297

Epoch: 6| Step: 7
Training loss: 2.4612178582242756
Validation loss: 2.594024107516856

Epoch: 6| Step: 8
Training loss: 2.9876140173698253
Validation loss: 2.6390485704083364

Epoch: 6| Step: 9
Training loss: 3.0524325816514515
Validation loss: 2.607134772983069

Epoch: 6| Step: 10
Training loss: 2.026269293569104
Validation loss: 2.500207161267509

Epoch: 6| Step: 11
Training loss: 2.294029289517584
Validation loss: 2.6037151530170184

Epoch: 6| Step: 12
Training loss: 2.6451701937689958
Validation loss: 2.5486845285395257

Epoch: 6| Step: 13
Training loss: 1.725335630300861
Validation loss: 2.6085463557736777

Epoch: 52| Step: 0
Training loss: 2.328434251561073
Validation loss: 2.637953503506707

Epoch: 6| Step: 1
Training loss: 1.5852798827320205
Validation loss: 2.6398033278231314

Epoch: 6| Step: 2
Training loss: 1.782763858435847
Validation loss: 2.6866219586974425

Epoch: 6| Step: 3
Training loss: 2.2672959052681896
Validation loss: 2.7404695293502908

Epoch: 6| Step: 4
Training loss: 2.2717916817059525
Validation loss: 2.654215538457269

Epoch: 6| Step: 5
Training loss: 2.5666437837480656
Validation loss: 2.693396155180226

Epoch: 6| Step: 6
Training loss: 2.0900338059753074
Validation loss: 2.6252824843257785

Epoch: 6| Step: 7
Training loss: 2.6572116681753646
Validation loss: 2.602425173521397

Epoch: 6| Step: 8
Training loss: 2.6794542038682883
Validation loss: 2.644336079054314

Epoch: 6| Step: 9
Training loss: 1.868202348666751
Validation loss: 2.5815034712633205

Epoch: 6| Step: 10
Training loss: 2.637654998708496
Validation loss: 2.5881683085469933

Epoch: 6| Step: 11
Training loss: 2.6810034365093056
Validation loss: 2.5512014201683733

Epoch: 6| Step: 12
Training loss: 3.2846695293333776
Validation loss: 2.58033729962953

Epoch: 6| Step: 13
Training loss: 2.0635436914142944
Validation loss: 2.600581804311144

Epoch: 53| Step: 0
Training loss: 1.684385180044463
Validation loss: 2.56004962219882

Epoch: 6| Step: 1
Training loss: 3.0785207736027083
Validation loss: 2.5778615951841903

Epoch: 6| Step: 2
Training loss: 1.8336623359013708
Validation loss: 2.5485376341088384

Epoch: 6| Step: 3
Training loss: 2.2178256836233667
Validation loss: 2.536924700516824

Epoch: 6| Step: 4
Training loss: 1.8243733571310772
Validation loss: 2.5330638979590496

Epoch: 6| Step: 5
Training loss: 2.7832946119832025
Validation loss: 2.5503442612929383

Epoch: 6| Step: 6
Training loss: 1.9400662070706203
Validation loss: 2.527444875778235

Epoch: 6| Step: 7
Training loss: 1.976803127915591
Validation loss: 2.530944876471096

Epoch: 6| Step: 8
Training loss: 2.346963739050826
Validation loss: 2.591172251095439

Epoch: 6| Step: 9
Training loss: 2.573163616566119
Validation loss: 2.568731043700034

Epoch: 6| Step: 10
Training loss: 2.6008520674181024
Validation loss: 2.5544025133861883

Epoch: 6| Step: 11
Training loss: 2.631089640100539
Validation loss: 2.6078108403356963

Epoch: 6| Step: 12
Training loss: 2.207160014219436
Validation loss: 2.618381497381051

Epoch: 6| Step: 13
Training loss: 2.5359456342471494
Validation loss: 2.60694899634554

Epoch: 54| Step: 0
Training loss: 2.6711781803342416
Validation loss: 2.6430325790487266

Epoch: 6| Step: 1
Training loss: 2.6391950719678094
Validation loss: 2.6533507138390675

Epoch: 6| Step: 2
Training loss: 1.8954222795939055
Validation loss: 2.7048949986431063

Epoch: 6| Step: 3
Training loss: 2.4479322933482828
Validation loss: 2.693809746406414

Epoch: 6| Step: 4
Training loss: 3.1889187516406605
Validation loss: 2.6534630759625473

Epoch: 6| Step: 5
Training loss: 1.9647360557937947
Validation loss: 2.6122782197841397

Epoch: 6| Step: 6
Training loss: 1.8705777470170808
Validation loss: 2.6812269795221684

Epoch: 6| Step: 7
Training loss: 2.200195529224912
Validation loss: 2.6261323121549327

Epoch: 6| Step: 8
Training loss: 2.6433551827193553
Validation loss: 2.6388859712573427

Epoch: 6| Step: 9
Training loss: 1.7430984100031663
Validation loss: 2.65773030340289

Epoch: 6| Step: 10
Training loss: 2.6630942635148998
Validation loss: 2.641577659776138

Epoch: 6| Step: 11
Training loss: 2.6221985172917237
Validation loss: 2.565871494113095

Epoch: 6| Step: 12
Training loss: 2.342960682518309
Validation loss: 2.5502415661053632

Epoch: 6| Step: 13
Training loss: 1.8888342076533517
Validation loss: 2.54504352082699

Epoch: 55| Step: 0
Training loss: 2.7471563201686626
Validation loss: 2.59499601899162

Epoch: 6| Step: 1
Training loss: 1.850179550118253
Validation loss: 2.6311180782395915

Epoch: 6| Step: 2
Training loss: 2.2632250472369995
Validation loss: 2.536795565663262

Epoch: 6| Step: 3
Training loss: 2.881456505911374
Validation loss: 2.613314169850769

Epoch: 6| Step: 4
Training loss: 2.9338406434783884
Validation loss: 2.5483112615008285

Epoch: 6| Step: 5
Training loss: 2.4973204557932367
Validation loss: 2.5506515275217105

Epoch: 6| Step: 6
Training loss: 1.9632628737901563
Validation loss: 2.6004348311798116

Epoch: 6| Step: 7
Training loss: 2.039506067430169
Validation loss: 2.570227377118752

Epoch: 6| Step: 8
Training loss: 2.528841167622437
Validation loss: 2.6289114949673333

Epoch: 6| Step: 9
Training loss: 1.9052745637250004
Validation loss: 2.66744586368864

Epoch: 6| Step: 10
Training loss: 2.106260699236491
Validation loss: 2.675674948703939

Epoch: 6| Step: 11
Training loss: 2.687826979506891
Validation loss: 2.6827963542507933

Epoch: 6| Step: 12
Training loss: 2.1442246070186393
Validation loss: 2.644962067214881

Epoch: 6| Step: 13
Training loss: 2.267190326712573
Validation loss: 2.647826943026658

Epoch: 56| Step: 0
Training loss: 1.8838647458390516
Validation loss: 2.6241174606970623

Epoch: 6| Step: 1
Training loss: 2.1769034814846973
Validation loss: 2.617263489184658

Epoch: 6| Step: 2
Training loss: 2.0749652905606037
Validation loss: 2.546548865408151

Epoch: 6| Step: 3
Training loss: 2.1516741422389876
Validation loss: 2.6437807807302853

Epoch: 6| Step: 4
Training loss: 2.4381959361826877
Validation loss: 2.6024961886712417

Epoch: 6| Step: 5
Training loss: 3.122296957190234
Validation loss: 2.6161851168510872

Epoch: 6| Step: 6
Training loss: 2.6172031686797763
Validation loss: 2.678126222305286

Epoch: 6| Step: 7
Training loss: 2.3850262473719397
Validation loss: 2.644246020728812

Epoch: 6| Step: 8
Training loss: 3.13633640187015
Validation loss: 2.608150217577458

Epoch: 6| Step: 9
Training loss: 2.4537674372437746
Validation loss: 2.671728022289883

Epoch: 6| Step: 10
Training loss: 2.297467628890196
Validation loss: 2.636822568003399

Epoch: 6| Step: 11
Training loss: 1.9079679658547801
Validation loss: 2.559197538540145

Epoch: 6| Step: 12
Training loss: 1.9977488365394318
Validation loss: 2.6234739954251958

Epoch: 6| Step: 13
Training loss: 2.0663831741977146
Validation loss: 2.61267796021331

Epoch: 57| Step: 0
Training loss: 2.270153072086357
Validation loss: 2.5324342571134126

Epoch: 6| Step: 1
Training loss: 2.1363576413039125
Validation loss: 2.548809494788434

Epoch: 6| Step: 2
Training loss: 2.709114627140808
Validation loss: 2.5325336105862815

Epoch: 6| Step: 3
Training loss: 2.0108754584901836
Validation loss: 2.609662609277796

Epoch: 6| Step: 4
Training loss: 2.3882160890404496
Validation loss: 2.580768316737342

Epoch: 6| Step: 5
Training loss: 2.2807507948551553
Validation loss: 2.551951600911302

Epoch: 6| Step: 6
Training loss: 2.360784854662721
Validation loss: 2.50112231811825

Epoch: 6| Step: 7
Training loss: 2.2571079514444756
Validation loss: 2.640653064586172

Epoch: 6| Step: 8
Training loss: 1.8833085035977273
Validation loss: 2.56816562555159

Epoch: 6| Step: 9
Training loss: 2.4041451500029516
Validation loss: 2.5336242968795597

Epoch: 6| Step: 10
Training loss: 2.4497788076395515
Validation loss: 2.5984686095148803

Epoch: 6| Step: 11
Training loss: 2.8633330419834095
Validation loss: 2.569905868258543

Epoch: 6| Step: 12
Training loss: 1.947819331656094
Validation loss: 2.5856816990271008

Epoch: 6| Step: 13
Training loss: 2.419274884820399
Validation loss: 2.5795219258885416

Epoch: 58| Step: 0
Training loss: 2.0324102755891373
Validation loss: 2.5403304157211126

Epoch: 6| Step: 1
Training loss: 2.620231657197113
Validation loss: 2.556862701259622

Epoch: 6| Step: 2
Training loss: 2.0601201053901717
Validation loss: 2.5654735680021883

Epoch: 6| Step: 3
Training loss: 1.8420938068406516
Validation loss: 2.62824789327656

Epoch: 6| Step: 4
Training loss: 1.9262828367133944
Validation loss: 2.6579041958763665

Epoch: 6| Step: 5
Training loss: 2.170808818578653
Validation loss: 2.638612345097631

Epoch: 6| Step: 6
Training loss: 2.6290925230603834
Validation loss: 2.669609328726333

Epoch: 6| Step: 7
Training loss: 2.74872984597319
Validation loss: 2.671257319448532

Epoch: 6| Step: 8
Training loss: 2.019493235483006
Validation loss: 2.764572216165857

Epoch: 6| Step: 9
Training loss: 2.4924190019094103
Validation loss: 2.5872946843559377

Epoch: 6| Step: 10
Training loss: 2.3272645115368675
Validation loss: 2.5932789723387315

Epoch: 6| Step: 11
Training loss: 2.9776548448811426
Validation loss: 2.6352979811730566

Epoch: 6| Step: 12
Training loss: 2.1057256708171948
Validation loss: 2.6267965920099496

Epoch: 6| Step: 13
Training loss: 1.9595462073280039
Validation loss: 2.592545011124125

Epoch: 59| Step: 0
Training loss: 2.0560001488177173
Validation loss: 2.63616009103846

Epoch: 6| Step: 1
Training loss: 1.872197218022716
Validation loss: 2.609792390436881

Epoch: 6| Step: 2
Training loss: 2.6678881430562007
Validation loss: 2.6036105566705783

Epoch: 6| Step: 3
Training loss: 2.2305200574221473
Validation loss: 2.565159309427053

Epoch: 6| Step: 4
Training loss: 2.0539724752110384
Validation loss: 2.6139190914189707

Epoch: 6| Step: 5
Training loss: 2.2992304965933372
Validation loss: 2.597618481354308

Epoch: 6| Step: 6
Training loss: 1.9187781341180017
Validation loss: 2.6038025461585046

Epoch: 6| Step: 7
Training loss: 2.6385985052947247
Validation loss: 2.6178307648968335

Epoch: 6| Step: 8
Training loss: 2.3022524626270604
Validation loss: 2.7009440169880503

Epoch: 6| Step: 9
Training loss: 2.0502096487632273
Validation loss: 2.640391202128331

Epoch: 6| Step: 10
Training loss: 2.613244208970017
Validation loss: 2.6014051265677085

Epoch: 6| Step: 11
Training loss: 2.4154115135932384
Validation loss: 2.6402857334909626

Epoch: 6| Step: 12
Training loss: 2.7852873911753577
Validation loss: 2.608146591529842

Epoch: 6| Step: 13
Training loss: 2.238543270412869
Validation loss: 2.70374501197744

Epoch: 60| Step: 0
Training loss: 2.1862013095256083
Validation loss: 2.6550069106754997

Epoch: 6| Step: 1
Training loss: 2.7333522082661785
Validation loss: 2.5878283453590862

Epoch: 6| Step: 2
Training loss: 2.210726778482389
Validation loss: 2.6513126337235957

Epoch: 6| Step: 3
Training loss: 1.8903976177589623
Validation loss: 2.5426422862771236

Epoch: 6| Step: 4
Training loss: 2.1211539974753975
Validation loss: 2.634428386818508

Epoch: 6| Step: 5
Training loss: 2.105943049581891
Validation loss: 2.5873711675246365

Epoch: 6| Step: 6
Training loss: 2.5675172766946455
Validation loss: 2.6242237608501098

Epoch: 6| Step: 7
Training loss: 2.3037793455360913
Validation loss: 2.5264639249156615

Epoch: 6| Step: 8
Training loss: 1.6842512718717946
Validation loss: 2.5552213618468227

Epoch: 6| Step: 9
Training loss: 2.6598696113122027
Validation loss: 2.6374121086337308

Epoch: 6| Step: 10
Training loss: 2.74086153408105
Validation loss: 2.6421162384186796

Epoch: 6| Step: 11
Training loss: 2.313903588834334
Validation loss: 2.583183735443449

Epoch: 6| Step: 12
Training loss: 2.481203273842494
Validation loss: 2.6772555779486167

Epoch: 6| Step: 13
Training loss: 1.7392633642571766
Validation loss: 2.6457699119796376

Epoch: 61| Step: 0
Training loss: 2.2255381586989684
Validation loss: 2.57032165216519

Epoch: 6| Step: 1
Training loss: 2.405436985342601
Validation loss: 2.6406193719988256

Epoch: 6| Step: 2
Training loss: 2.476580213609759
Validation loss: 2.5933004319041473

Epoch: 6| Step: 3
Training loss: 2.74320308648039
Validation loss: 2.6233801915185904

Epoch: 6| Step: 4
Training loss: 1.7839881196973575
Validation loss: 2.58318935782683

Epoch: 6| Step: 5
Training loss: 1.9494757167559045
Validation loss: 2.5913286512025238

Epoch: 6| Step: 6
Training loss: 2.530681781805393
Validation loss: 2.6208921867599484

Epoch: 6| Step: 7
Training loss: 2.322293036758686
Validation loss: 2.6306954313652886

Epoch: 6| Step: 8
Training loss: 2.510079853261839
Validation loss: 2.586762372594497

Epoch: 6| Step: 9
Training loss: 1.7940736910549542
Validation loss: 2.64972291733408

Epoch: 6| Step: 10
Training loss: 2.4042226995310627
Validation loss: 2.6003973473852664

Epoch: 6| Step: 11
Training loss: 1.8617293895012417
Validation loss: 2.7112177136921343

Epoch: 6| Step: 12
Training loss: 2.817079587912377
Validation loss: 2.691187162668252

Epoch: 6| Step: 13
Training loss: 2.373175572802595
Validation loss: 2.693391271839846

Epoch: 62| Step: 0
Training loss: 1.5973368654249196
Validation loss: 2.6501075482887

Epoch: 6| Step: 1
Training loss: 2.079787772245473
Validation loss: 2.67377925333074

Epoch: 6| Step: 2
Training loss: 1.9134347937373366
Validation loss: 2.6392241755745136

Epoch: 6| Step: 3
Training loss: 2.595306664723836
Validation loss: 2.6002426388813644

Epoch: 6| Step: 4
Training loss: 2.1439910931046358
Validation loss: 2.6805567244514545

Epoch: 6| Step: 5
Training loss: 2.098244696399645
Validation loss: 2.6729141207588976

Epoch: 6| Step: 6
Training loss: 2.180765193194889
Validation loss: 2.5770980485040127

Epoch: 6| Step: 7
Training loss: 2.7618887281109035
Validation loss: 2.619929775796594

Epoch: 6| Step: 8
Training loss: 2.4360151414322346
Validation loss: 2.6349595669872032

Epoch: 6| Step: 9
Training loss: 2.19335100506946
Validation loss: 2.581135165821389

Epoch: 6| Step: 10
Training loss: 2.9252438631044715
Validation loss: 2.6317380076573897

Epoch: 6| Step: 11
Training loss: 2.9617224787610894
Validation loss: 2.5739284847622734

Epoch: 6| Step: 12
Training loss: 2.3457346333619684
Validation loss: 2.6023952003018835

Epoch: 6| Step: 13
Training loss: 2.1550320488832333
Validation loss: 2.6239051957837147

Epoch: 63| Step: 0
Training loss: 2.348830959027165
Validation loss: 2.6309936458965706

Epoch: 6| Step: 1
Training loss: 1.8656067481497984
Validation loss: 2.649150471101326

Epoch: 6| Step: 2
Training loss: 2.954739245481581
Validation loss: 2.708121545776071

Epoch: 6| Step: 3
Training loss: 2.1217383991030836
Validation loss: 2.7713829274660564

Epoch: 6| Step: 4
Training loss: 2.4169066627861064
Validation loss: 2.7773877447536277

Epoch: 6| Step: 5
Training loss: 2.1077271983628494
Validation loss: 2.772927594658928

Epoch: 6| Step: 6
Training loss: 1.8722404518082625
Validation loss: 2.796518455809594

Epoch: 6| Step: 7
Training loss: 2.9153287452901835
Validation loss: 2.8000393518452773

Epoch: 6| Step: 8
Training loss: 1.5705453121251722
Validation loss: 2.6319687243045973

Epoch: 6| Step: 9
Training loss: 1.7709151155623184
Validation loss: 2.6043339077971552

Epoch: 6| Step: 10
Training loss: 2.5543285432664686
Validation loss: 2.6375608554707597

Epoch: 6| Step: 11
Training loss: 2.6187403385102486
Validation loss: 2.5991064015461207

Epoch: 6| Step: 12
Training loss: 1.8388204462286761
Validation loss: 2.6030135284650657

Epoch: 6| Step: 13
Training loss: 2.316082833727669
Validation loss: 2.608978759162541

Epoch: 64| Step: 0
Training loss: 2.340035712466824
Validation loss: 2.574552384146415

Epoch: 6| Step: 1
Training loss: 2.092982137138154
Validation loss: 2.590215342749023

Epoch: 6| Step: 2
Training loss: 2.165044788839969
Validation loss: 2.5673111820591044

Epoch: 6| Step: 3
Training loss: 2.0100223240158286
Validation loss: 2.6371012017069675

Epoch: 6| Step: 4
Training loss: 2.0361688770786883
Validation loss: 2.503488332197182

Epoch: 6| Step: 5
Training loss: 2.206682403811823
Validation loss: 2.542401212850497

Epoch: 6| Step: 6
Training loss: 2.240899011517872
Validation loss: 2.564714018040589

Epoch: 6| Step: 7
Training loss: 2.338240798819523
Validation loss: 2.6026566259993027

Epoch: 6| Step: 8
Training loss: 3.13626463988906
Validation loss: 2.5777489127766433

Epoch: 6| Step: 9
Training loss: 1.318704788734707
Validation loss: 2.7006323388872553

Epoch: 6| Step: 10
Training loss: 2.1989882570294053
Validation loss: 2.7034328483847547

Epoch: 6| Step: 11
Training loss: 2.632823276214732
Validation loss: 2.7877898175350517

Epoch: 6| Step: 12
Training loss: 2.5446156971182323
Validation loss: 2.842762478687511

Epoch: 6| Step: 13
Training loss: 2.1383069706890114
Validation loss: 2.6907216508484795

Epoch: 65| Step: 0
Training loss: 1.7691955921733127
Validation loss: 2.632804681934253

Epoch: 6| Step: 1
Training loss: 2.627920433546973
Validation loss: 2.6662627872947904

Epoch: 6| Step: 2
Training loss: 2.1507918341307297
Validation loss: 2.649037356041129

Epoch: 6| Step: 3
Training loss: 1.8547294991164016
Validation loss: 2.59152749987101

Epoch: 6| Step: 4
Training loss: 2.0623090251013907
Validation loss: 2.6415201509520503

Epoch: 6| Step: 5
Training loss: 2.84341998857807
Validation loss: 2.5953141517335343

Epoch: 6| Step: 6
Training loss: 2.1916118668158524
Validation loss: 2.5749612373224524

Epoch: 6| Step: 7
Training loss: 2.2048047743547676
Validation loss: 2.618797088175419

Epoch: 6| Step: 8
Training loss: 2.4605092478320403
Validation loss: 2.5072567681510827

Epoch: 6| Step: 9
Training loss: 2.698604088673399
Validation loss: 2.6271197298106603

Epoch: 6| Step: 10
Training loss: 2.029977253001885
Validation loss: 2.6725475513306653

Epoch: 6| Step: 11
Training loss: 2.950536330009273
Validation loss: 2.497582792908792

Epoch: 6| Step: 12
Training loss: 1.898813971721965
Validation loss: 2.570518323083946

Epoch: 6| Step: 13
Training loss: 2.0640521133704413
Validation loss: 2.601956708976531

Epoch: 66| Step: 0
Training loss: 2.5681486442184904
Validation loss: 2.6532923968749875

Epoch: 6| Step: 1
Training loss: 1.4883639094909535
Validation loss: 2.620116505034504

Epoch: 6| Step: 2
Training loss: 2.4669898796538865
Validation loss: 2.6686146867859444

Epoch: 6| Step: 3
Training loss: 2.0064604841913987
Validation loss: 2.7012619183754176

Epoch: 6| Step: 4
Training loss: 3.0728913559383106
Validation loss: 2.6272639699289773

Epoch: 6| Step: 5
Training loss: 2.1505706739451305
Validation loss: 2.6567264466178986

Epoch: 6| Step: 6
Training loss: 2.35492331799109
Validation loss: 2.670292450703278

Epoch: 6| Step: 7
Training loss: 2.0114743575003255
Validation loss: 2.6460985416248457

Epoch: 6| Step: 8
Training loss: 2.4995577421010724
Validation loss: 2.737207337271388

Epoch: 6| Step: 9
Training loss: 2.648064781226337
Validation loss: 2.67107799607576

Epoch: 6| Step: 10
Training loss: 1.72638373506731
Validation loss: 2.592069226817128

Epoch: 6| Step: 11
Training loss: 1.8285525873397102
Validation loss: 2.551652729271271

Epoch: 6| Step: 12
Training loss: 2.0716635847899925
Validation loss: 2.6355123138159366

Epoch: 6| Step: 13
Training loss: 2.1814766927274483
Validation loss: 2.531578278152765

Epoch: 67| Step: 0
Training loss: 2.5648311153383023
Validation loss: 2.584075657007612

Epoch: 6| Step: 1
Training loss: 2.3752240527026305
Validation loss: 2.587381564760756

Epoch: 6| Step: 2
Training loss: 2.227940183360479
Validation loss: 2.590175340846787

Epoch: 6| Step: 3
Training loss: 2.2303404762808565
Validation loss: 2.654297660956642

Epoch: 6| Step: 4
Training loss: 1.3278322682622794
Validation loss: 2.6913294382119908

Epoch: 6| Step: 5
Training loss: 2.194292476344191
Validation loss: 2.636736095983646

Epoch: 6| Step: 6
Training loss: 1.7869823639975526
Validation loss: 2.6092881970615487

Epoch: 6| Step: 7
Training loss: 3.55054395027501
Validation loss: 2.644269974469044

Epoch: 6| Step: 8
Training loss: 1.8625949579392451
Validation loss: 2.5964830545760944

Epoch: 6| Step: 9
Training loss: 2.202643808612647
Validation loss: 2.635603529948429

Epoch: 6| Step: 10
Training loss: 2.134277399604638
Validation loss: 2.689777688042377

Epoch: 6| Step: 11
Training loss: 2.4043900869167376
Validation loss: 2.631419144220508

Epoch: 6| Step: 12
Training loss: 1.9399702260593656
Validation loss: 2.670569694042199

Epoch: 6| Step: 13
Training loss: 2.0654419233532364
Validation loss: 2.5537956073016472

Epoch: 68| Step: 0
Training loss: 1.6642486038374062
Validation loss: 2.600226822153585

Epoch: 6| Step: 1
Training loss: 1.92467846352521
Validation loss: 2.6024817750886906

Epoch: 6| Step: 2
Training loss: 2.348481552106794
Validation loss: 2.625653306711161

Epoch: 6| Step: 3
Training loss: 2.478122640947756
Validation loss: 2.5597380663562572

Epoch: 6| Step: 4
Training loss: 2.8402275655132576
Validation loss: 2.638542437537606

Epoch: 6| Step: 5
Training loss: 1.4028788531224234
Validation loss: 2.590523271515166

Epoch: 6| Step: 6
Training loss: 2.0789660135915993
Validation loss: 2.6301201506584286

Epoch: 6| Step: 7
Training loss: 2.2096358602534973
Validation loss: 2.61861520418775

Epoch: 6| Step: 8
Training loss: 1.6551612298343705
Validation loss: 2.6462656453901

Epoch: 6| Step: 9
Training loss: 2.777565218952064
Validation loss: 2.627973492126281

Epoch: 6| Step: 10
Training loss: 1.9675001991204013
Validation loss: 2.6290284686234573

Epoch: 6| Step: 11
Training loss: 2.5648543544414117
Validation loss: 2.6404823099141033

Epoch: 6| Step: 12
Training loss: 2.4494398099438657
Validation loss: 2.5998449603340688

Epoch: 6| Step: 13
Training loss: 2.013573837483747
Validation loss: 2.645239640757393

Epoch: 69| Step: 0
Training loss: 1.965678710688854
Validation loss: 2.650787736064225

Epoch: 6| Step: 1
Training loss: 1.8689060362927439
Validation loss: 2.6378894759396485

Epoch: 6| Step: 2
Training loss: 2.2605766087447483
Validation loss: 2.6032057909508577

Epoch: 6| Step: 3
Training loss: 1.8180845321290198
Validation loss: 2.656563190621211

Epoch: 6| Step: 4
Training loss: 1.7759906690627347
Validation loss: 2.5865861246344317

Epoch: 6| Step: 5
Training loss: 2.768129066435014
Validation loss: 2.59774359458222

Epoch: 6| Step: 6
Training loss: 2.3971048933686676
Validation loss: 2.5686113009168503

Epoch: 6| Step: 7
Training loss: 2.243178092304841
Validation loss: 2.6339006146909294

Epoch: 6| Step: 8
Training loss: 2.5147772835619437
Validation loss: 2.5985984680513403

Epoch: 6| Step: 9
Training loss: 2.2292971231190726
Validation loss: 2.5246412714834423

Epoch: 6| Step: 10
Training loss: 1.644565609099575
Validation loss: 2.5960623150817543

Epoch: 6| Step: 11
Training loss: 2.069252059266302
Validation loss: 2.5582677269474923

Epoch: 6| Step: 12
Training loss: 2.981340233418914
Validation loss: 2.6258624491706177

Epoch: 6| Step: 13
Training loss: 2.228961281509891
Validation loss: 2.681005133567846

Epoch: 70| Step: 0
Training loss: 1.8978789964015883
Validation loss: 2.6396233353648473

Epoch: 6| Step: 1
Training loss: 2.262601742643408
Validation loss: 2.680609586123948

Epoch: 6| Step: 2
Training loss: 2.384439082053251
Validation loss: 2.6166473894158346

Epoch: 6| Step: 3
Training loss: 2.225019167699654
Validation loss: 2.641903945623497

Epoch: 6| Step: 4
Training loss: 1.8787709780275024
Validation loss: 2.643159782112858

Epoch: 6| Step: 5
Training loss: 1.8551904088103448
Validation loss: 2.59987413761967

Epoch: 6| Step: 6
Training loss: 1.8858425720141379
Validation loss: 2.6079556379582276

Epoch: 6| Step: 7
Training loss: 2.0729134973345222
Validation loss: 2.6232758188021994

Epoch: 6| Step: 8
Training loss: 2.2513815558934662
Validation loss: 2.6157676071492686

Epoch: 6| Step: 9
Training loss: 2.8348428594510775
Validation loss: 2.601356070483975

Epoch: 6| Step: 10
Training loss: 1.8088960662684304
Validation loss: 2.620623535488213

Epoch: 6| Step: 11
Training loss: 1.9230007193212408
Validation loss: 2.601912260171319

Epoch: 6| Step: 12
Training loss: 2.729977455744738
Validation loss: 2.6354607790746907

Epoch: 6| Step: 13
Training loss: 2.13831165363187
Validation loss: 2.656792544139304

Epoch: 71| Step: 0
Training loss: 2.050922381676503
Validation loss: 2.7019328463454606

Epoch: 6| Step: 1
Training loss: 2.203942329898418
Validation loss: 2.7405559979128737

Epoch: 6| Step: 2
Training loss: 1.7673575753720165
Validation loss: 2.6484238315705935

Epoch: 6| Step: 3
Training loss: 1.475825211459356
Validation loss: 2.6524466268506943

Epoch: 6| Step: 4
Training loss: 1.9808162106020124
Validation loss: 2.7572274888864334

Epoch: 6| Step: 5
Training loss: 2.0412868483815516
Validation loss: 2.6681367477762423

Epoch: 6| Step: 6
Training loss: 2.461642403540062
Validation loss: 2.7325619745046716

Epoch: 6| Step: 7
Training loss: 2.3066220197968965
Validation loss: 2.6634350482446454

Epoch: 6| Step: 8
Training loss: 1.7174237769924616
Validation loss: 2.548564296041825

Epoch: 6| Step: 9
Training loss: 2.6068623946220537
Validation loss: 2.6338348365835245

Epoch: 6| Step: 10
Training loss: 3.2163251613191974
Validation loss: 2.6519989478707084

Epoch: 6| Step: 11
Training loss: 2.3616564501117625
Validation loss: 2.570744038601986

Epoch: 6| Step: 12
Training loss: 2.311043461039774
Validation loss: 2.595052690724431

Epoch: 6| Step: 13
Training loss: 1.6990125509093754
Validation loss: 2.5745060345076505

Epoch: 72| Step: 0
Training loss: 2.890383158696637
Validation loss: 2.5701394375529047

Epoch: 6| Step: 1
Training loss: 1.8622221105758119
Validation loss: 2.668086409126998

Epoch: 6| Step: 2
Training loss: 1.5366953349111354
Validation loss: 2.5914078827558513

Epoch: 6| Step: 3
Training loss: 1.6925587592919797
Validation loss: 2.648307414503204

Epoch: 6| Step: 4
Training loss: 2.7028674405384825
Validation loss: 2.6440444340442038

Epoch: 6| Step: 5
Training loss: 1.86247866317509
Validation loss: 2.6960691265380823

Epoch: 6| Step: 6
Training loss: 2.030529657428639
Validation loss: 2.706376716342949

Epoch: 6| Step: 7
Training loss: 2.258286475883745
Validation loss: 2.673339531606717

Epoch: 6| Step: 8
Training loss: 2.264291304984976
Validation loss: 2.574727681028514

Epoch: 6| Step: 9
Training loss: 1.8823763393602775
Validation loss: 2.6428199238285908

Epoch: 6| Step: 10
Training loss: 1.8775855992457753
Validation loss: 2.5969818157533284

Epoch: 6| Step: 11
Training loss: 2.2088855077068223
Validation loss: 2.543930004852377

Epoch: 6| Step: 12
Training loss: 2.5533826569589775
Validation loss: 2.597054066090454

Epoch: 6| Step: 13
Training loss: 1.5808572816752418
Validation loss: 2.6185926470524787

Epoch: 73| Step: 0
Training loss: 1.9592753505159515
Validation loss: 2.565492541866184

Epoch: 6| Step: 1
Training loss: 2.057670951035859
Validation loss: 2.6036873465337695

Epoch: 6| Step: 2
Training loss: 1.6761977738473408
Validation loss: 2.6382284330654526

Epoch: 6| Step: 3
Training loss: 2.9698229005460766
Validation loss: 2.63268983821214

Epoch: 6| Step: 4
Training loss: 2.3515877453028713
Validation loss: 2.6243471968782206

Epoch: 6| Step: 5
Training loss: 2.0559773041107023
Validation loss: 2.601159661218478

Epoch: 6| Step: 6
Training loss: 2.188296036975042
Validation loss: 2.6672686975116786

Epoch: 6| Step: 7
Training loss: 2.3605919535219795
Validation loss: 2.646963664029452

Epoch: 6| Step: 8
Training loss: 1.8589669428980167
Validation loss: 2.661419001597839

Epoch: 6| Step: 9
Training loss: 2.247479404444205
Validation loss: 2.7742224070651043

Epoch: 6| Step: 10
Training loss: 1.8239145944326516
Validation loss: 2.7312907090052105

Epoch: 6| Step: 11
Training loss: 1.8975929925017248
Validation loss: 2.761293946021952

Epoch: 6| Step: 12
Training loss: 1.902003138321976
Validation loss: 2.7747414116187348

Epoch: 6| Step: 13
Training loss: 2.563006281267165
Validation loss: 2.6908615439566397

Epoch: 74| Step: 0
Training loss: 2.3512721088349506
Validation loss: 2.5883490467106305

Epoch: 6| Step: 1
Training loss: 2.065285275869035
Validation loss: 2.5640244950122746

Epoch: 6| Step: 2
Training loss: 1.7790741597886897
Validation loss: 2.6281516969997814

Epoch: 6| Step: 3
Training loss: 1.681916642880203
Validation loss: 2.5059509260619754

Epoch: 6| Step: 4
Training loss: 1.7167910422789143
Validation loss: 2.6219906283962082

Epoch: 6| Step: 5
Training loss: 1.6742434971093407
Validation loss: 2.57072263805985

Epoch: 6| Step: 6
Training loss: 2.5697544036955167
Validation loss: 2.536359770711715

Epoch: 6| Step: 7
Training loss: 1.8653521595459996
Validation loss: 2.665879741927359

Epoch: 6| Step: 8
Training loss: 2.1228905473723905
Validation loss: 2.5713761900809304

Epoch: 6| Step: 9
Training loss: 1.9175199461375751
Validation loss: 2.679166826650596

Epoch: 6| Step: 10
Training loss: 2.6491691006479985
Validation loss: 2.7221613999360206

Epoch: 6| Step: 11
Training loss: 2.363984008212146
Validation loss: 2.621970320534835

Epoch: 6| Step: 12
Training loss: 2.695742896173162
Validation loss: 2.7152558158079563

Epoch: 6| Step: 13
Training loss: 2.493598371212586
Validation loss: 2.7314717602122776

Epoch: 75| Step: 0
Training loss: 2.309101597522964
Validation loss: 2.716494066415063

Epoch: 6| Step: 1
Training loss: 2.5595744110039678
Validation loss: 2.6955253553882654

Epoch: 6| Step: 2
Training loss: 2.020063378123504
Validation loss: 2.6738225371639324

Epoch: 6| Step: 3
Training loss: 1.4866107366216517
Validation loss: 2.6352186668913764

Epoch: 6| Step: 4
Training loss: 1.8208567579262631
Validation loss: 2.551509400792651

Epoch: 6| Step: 5
Training loss: 2.8976719094493792
Validation loss: 2.6882873978526494

Epoch: 6| Step: 6
Training loss: 1.9221565846658073
Validation loss: 2.534271164102431

Epoch: 6| Step: 7
Training loss: 1.8837157809181377
Validation loss: 2.5177417324146196

Epoch: 6| Step: 8
Training loss: 2.2213637309671617
Validation loss: 2.612263213687032

Epoch: 6| Step: 9
Training loss: 2.4224234667519444
Validation loss: 2.575369531849915

Epoch: 6| Step: 10
Training loss: 1.6684770368002408
Validation loss: 2.638325640036025

Epoch: 6| Step: 11
Training loss: 2.4123795948717146
Validation loss: 2.6736286349912652

Epoch: 6| Step: 12
Training loss: 2.337749174168277
Validation loss: 2.700967894543517

Epoch: 6| Step: 13
Training loss: 1.7483482058498288
Validation loss: 2.7610470801676272

Epoch: 76| Step: 0
Training loss: 1.8435790419119154
Validation loss: 2.66594578019201

Epoch: 6| Step: 1
Training loss: 2.547103029118057
Validation loss: 2.779060544948018

Epoch: 6| Step: 2
Training loss: 2.1096415033469653
Validation loss: 2.746035868729733

Epoch: 6| Step: 3
Training loss: 2.13666965351501
Validation loss: 2.682325734536319

Epoch: 6| Step: 4
Training loss: 2.5405249506733636
Validation loss: 2.6473208823893097

Epoch: 6| Step: 5
Training loss: 1.8594183395848478
Validation loss: 2.6327982674807338

Epoch: 6| Step: 6
Training loss: 1.774004404481841
Validation loss: 2.623964635324779

Epoch: 6| Step: 7
Training loss: 1.9004401801333766
Validation loss: 2.5575460137845267

Epoch: 6| Step: 8
Training loss: 2.1943554947392823
Validation loss: 2.6057799771560397

Epoch: 6| Step: 9
Training loss: 2.314339498957914
Validation loss: 2.589614911755122

Epoch: 6| Step: 10
Training loss: 2.2288273585785294
Validation loss: 2.6294839195044597

Epoch: 6| Step: 11
Training loss: 1.91616979322897
Validation loss: 2.632696283116713

Epoch: 6| Step: 12
Training loss: 2.4118157953299475
Validation loss: 2.5759270286324085

Epoch: 6| Step: 13
Training loss: 2.625668849202078
Validation loss: 2.6567398965890603

Epoch: 77| Step: 0
Training loss: 3.0090087097285325
Validation loss: 2.771065957957374

Epoch: 6| Step: 1
Training loss: 1.8949324035666586
Validation loss: 2.7512269317477913

Epoch: 6| Step: 2
Training loss: 2.406418732511119
Validation loss: 2.653812314627202

Epoch: 6| Step: 3
Training loss: 2.5187216707439695
Validation loss: 2.6730275781999606

Epoch: 6| Step: 4
Training loss: 2.0794767414836794
Validation loss: 2.6841322031525667

Epoch: 6| Step: 5
Training loss: 2.1807517458160803
Validation loss: 2.6031104934245435

Epoch: 6| Step: 6
Training loss: 1.7552186944884012
Validation loss: 2.5566972454767263

Epoch: 6| Step: 7
Training loss: 2.5315544981359714
Validation loss: 2.5771559926806806

Epoch: 6| Step: 8
Training loss: 2.298793277136041
Validation loss: 2.55631854984361

Epoch: 6| Step: 9
Training loss: 1.9729122184641508
Validation loss: 2.6087781181580922

Epoch: 6| Step: 10
Training loss: 1.3895314235037282
Validation loss: 2.642802422311715

Epoch: 6| Step: 11
Training loss: 2.2515858253896206
Validation loss: 2.62296864460858

Epoch: 6| Step: 12
Training loss: 2.0254793800617117
Validation loss: 2.6350038579566313

Epoch: 6| Step: 13
Training loss: 1.3183294448280778
Validation loss: 2.6710716512189325

Epoch: 78| Step: 0
Training loss: 2.149539734122865
Validation loss: 2.6947217727009924

Epoch: 6| Step: 1
Training loss: 1.8043559376707632
Validation loss: 2.7147093961481166

Epoch: 6| Step: 2
Training loss: 2.4870477850004185
Validation loss: 2.7069820970235203

Epoch: 6| Step: 3
Training loss: 1.742473630117269
Validation loss: 2.6509354175992796

Epoch: 6| Step: 4
Training loss: 2.052039931817825
Validation loss: 2.7091124783246516

Epoch: 6| Step: 5
Training loss: 2.206891350827378
Validation loss: 2.6380983864072127

Epoch: 6| Step: 6
Training loss: 2.7157420037703286
Validation loss: 2.6670588463249802

Epoch: 6| Step: 7
Training loss: 1.9991863503016476
Validation loss: 2.6283937798344366

Epoch: 6| Step: 8
Training loss: 2.2995998283228243
Validation loss: 2.6390138033252564

Epoch: 6| Step: 9
Training loss: 2.3559118458264043
Validation loss: 2.6202014478740763

Epoch: 6| Step: 10
Training loss: 1.8298308410006774
Validation loss: 2.60255234591474

Epoch: 6| Step: 11
Training loss: 1.3493717497821374
Validation loss: 2.5969519633224216

Epoch: 6| Step: 12
Training loss: 2.425858107868075
Validation loss: 2.577871522098653

Epoch: 6| Step: 13
Training loss: 1.7111072194824442
Validation loss: 2.561639757674814

Epoch: 79| Step: 0
Training loss: 1.9624728692967528
Validation loss: 2.641347316087122

Epoch: 6| Step: 1
Training loss: 1.929592609002934
Validation loss: 2.6025570638009006

Epoch: 6| Step: 2
Training loss: 1.73295645223362
Validation loss: 2.621510987442063

Epoch: 6| Step: 3
Training loss: 1.8988834061508435
Validation loss: 2.637390299861476

Epoch: 6| Step: 4
Training loss: 1.8681587661851544
Validation loss: 2.7693815132557535

Epoch: 6| Step: 5
Training loss: 1.859745918270472
Validation loss: 2.6686638317148685

Epoch: 6| Step: 6
Training loss: 2.038556032385196
Validation loss: 2.7556404154752916

Epoch: 6| Step: 7
Training loss: 2.852055420795854
Validation loss: 2.6960251902526897

Epoch: 6| Step: 8
Training loss: 1.7824541004151186
Validation loss: 2.6740163658352656

Epoch: 6| Step: 9
Training loss: 2.1936607799156387
Validation loss: 2.6582020337515746

Epoch: 6| Step: 10
Training loss: 2.704688441443321
Validation loss: 2.6512762739074773

Epoch: 6| Step: 11
Training loss: 1.7472926723843776
Validation loss: 2.621632080585605

Epoch: 6| Step: 12
Training loss: 2.5727543232675454
Validation loss: 2.5968445238634894

Epoch: 6| Step: 13
Training loss: 1.6655999902847978
Validation loss: 2.6253586478684667

Epoch: 80| Step: 0
Training loss: 1.4364587910600486
Validation loss: 2.636563354434175

Epoch: 6| Step: 1
Training loss: 2.3130197714139107
Validation loss: 2.6519892759542616

Epoch: 6| Step: 2
Training loss: 2.014980005964942
Validation loss: 2.5699836110855396

Epoch: 6| Step: 3
Training loss: 1.576941017707269
Validation loss: 2.5896998270050666

Epoch: 6| Step: 4
Training loss: 2.705478767995548
Validation loss: 2.581545677830604

Epoch: 6| Step: 5
Training loss: 2.047547906820521
Validation loss: 2.5709448194107862

Epoch: 6| Step: 6
Training loss: 2.788363585535061
Validation loss: 2.657295365420082

Epoch: 6| Step: 7
Training loss: 2.0893725282846725
Validation loss: 2.565650770682891

Epoch: 6| Step: 8
Training loss: 2.3941792514079463
Validation loss: 2.671544744295957

Epoch: 6| Step: 9
Training loss: 1.7085355158310878
Validation loss: 2.6569717324289073

Epoch: 6| Step: 10
Training loss: 1.8015348301637726
Validation loss: 2.8060540117388793

Epoch: 6| Step: 11
Training loss: 2.0190120893005923
Validation loss: 2.7912983770031916

Epoch: 6| Step: 12
Training loss: 2.601657075279814
Validation loss: 2.779662804496556

Epoch: 6| Step: 13
Training loss: 1.5738359842603622
Validation loss: 2.7634502560168244

Epoch: 81| Step: 0
Training loss: 1.5220338272466085
Validation loss: 2.788464450918982

Epoch: 6| Step: 1
Training loss: 2.9951339039617464
Validation loss: 2.6678700165843177

Epoch: 6| Step: 2
Training loss: 1.7471531463995584
Validation loss: 2.6288329553991017

Epoch: 6| Step: 3
Training loss: 1.9908463694849685
Validation loss: 2.675031303507812

Epoch: 6| Step: 4
Training loss: 1.2888345227796951
Validation loss: 2.6430912426572633

Epoch: 6| Step: 5
Training loss: 2.0679073542238484
Validation loss: 2.623694549381692

Epoch: 6| Step: 6
Training loss: 2.412728048822171
Validation loss: 2.5650703440855214

Epoch: 6| Step: 7
Training loss: 2.2786281621338595
Validation loss: 2.6064849351215487

Epoch: 6| Step: 8
Training loss: 2.2743246438452465
Validation loss: 2.5406478001821533

Epoch: 6| Step: 9
Training loss: 1.7250438242334956
Validation loss: 2.5602294042242058

Epoch: 6| Step: 10
Training loss: 1.9420797304312216
Validation loss: 2.612966597411578

Epoch: 6| Step: 11
Training loss: 2.2515452694680307
Validation loss: 2.5525346914780283

Epoch: 6| Step: 12
Training loss: 1.89837972922002
Validation loss: 2.6144733988433075

Epoch: 6| Step: 13
Training loss: 2.0460716010399125
Validation loss: 2.695513790556932

Epoch: 82| Step: 0
Training loss: 1.5294024161877309
Validation loss: 2.652637838053443

Epoch: 6| Step: 1
Training loss: 1.7877538300735785
Validation loss: 2.7053680080979197

Epoch: 6| Step: 2
Training loss: 2.3387814563815303
Validation loss: 2.6952529826941363

Epoch: 6| Step: 3
Training loss: 1.7184048392769355
Validation loss: 2.670904492656718

Epoch: 6| Step: 4
Training loss: 2.3220314312038886
Validation loss: 2.6964494159437757

Epoch: 6| Step: 5
Training loss: 2.2966313654600072
Validation loss: 2.7843059795257936

Epoch: 6| Step: 6
Training loss: 1.7592556602969176
Validation loss: 2.6345384262756752

Epoch: 6| Step: 7
Training loss: 1.4127700547506299
Validation loss: 2.662652829459805

Epoch: 6| Step: 8
Training loss: 1.543093442103631
Validation loss: 2.6633105368070256

Epoch: 6| Step: 9
Training loss: 1.76306872018741
Validation loss: 2.6844120619631573

Epoch: 6| Step: 10
Training loss: 2.5165972045339644
Validation loss: 2.7096981766615458

Epoch: 6| Step: 11
Training loss: 1.7304956162823448
Validation loss: 2.650880884917064

Epoch: 6| Step: 12
Training loss: 2.705012549972331
Validation loss: 2.6488257829627373

Epoch: 6| Step: 13
Training loss: 2.191873809927255
Validation loss: 2.672691904451085

Epoch: 83| Step: 0
Training loss: 2.2702108340724956
Validation loss: 2.6139350077170405

Epoch: 6| Step: 1
Training loss: 1.7838337546709864
Validation loss: 2.655230292769075

Epoch: 6| Step: 2
Training loss: 2.013845915354145
Validation loss: 2.5627308098036052

Epoch: 6| Step: 3
Training loss: 1.8154149785915696
Validation loss: 2.5819395571311246

Epoch: 6| Step: 4
Training loss: 1.6961046468910952
Validation loss: 2.5827930767408245

Epoch: 6| Step: 5
Training loss: 1.6546705380183653
Validation loss: 2.6159614765862544

Epoch: 6| Step: 6
Training loss: 1.4013165295313565
Validation loss: 2.63860097507989

Epoch: 6| Step: 7
Training loss: 2.145192306719003
Validation loss: 2.6632651052063028

Epoch: 6| Step: 8
Training loss: 2.133231879841905
Validation loss: 2.6861013129142286

Epoch: 6| Step: 9
Training loss: 3.0226493024906427
Validation loss: 2.7030635525402382

Epoch: 6| Step: 10
Training loss: 1.4878413634133565
Validation loss: 2.638107883313793

Epoch: 6| Step: 11
Training loss: 1.958877758346231
Validation loss: 2.6354417209163086

Epoch: 6| Step: 12
Training loss: 2.4789563471808105
Validation loss: 2.638823201103694

Epoch: 6| Step: 13
Training loss: 1.8967242261111634
Validation loss: 2.640857483149625

Epoch: 84| Step: 0
Training loss: 2.091866058430796
Validation loss: 2.6247094462823437

Epoch: 6| Step: 1
Training loss: 2.4125894045693483
Validation loss: 2.6702119734316336

Epoch: 6| Step: 2
Training loss: 2.1829657291268307
Validation loss: 2.6096918214501743

Epoch: 6| Step: 3
Training loss: 1.6889808656230887
Validation loss: 2.643018281288154

Epoch: 6| Step: 4
Training loss: 1.6575020430194123
Validation loss: 2.7016675323784596

Epoch: 6| Step: 5
Training loss: 1.4117049908455674
Validation loss: 2.668898450726407

Epoch: 6| Step: 6
Training loss: 1.804037133809494
Validation loss: 2.6981060791294755

Epoch: 6| Step: 7
Training loss: 2.0898330260384896
Validation loss: 2.719263693266704

Epoch: 6| Step: 8
Training loss: 1.9343416867445835
Validation loss: 2.6200398857778895

Epoch: 6| Step: 9
Training loss: 2.3517172119346466
Validation loss: 2.7349655095028838

Epoch: 6| Step: 10
Training loss: 1.6186238420143377
Validation loss: 2.682031464532728

Epoch: 6| Step: 11
Training loss: 2.318809561979811
Validation loss: 2.7010159506102607

Epoch: 6| Step: 12
Training loss: 2.442545730178342
Validation loss: 2.6424907586240782

Epoch: 6| Step: 13
Training loss: 1.5971095261921031
Validation loss: 2.6776097345408676

Epoch: 85| Step: 0
Training loss: 1.538328741376036
Validation loss: 2.698840072869677

Epoch: 6| Step: 1
Training loss: 2.4696031858640537
Validation loss: 2.645407219362857

Epoch: 6| Step: 2
Training loss: 1.6676216568383986
Validation loss: 2.5780773736427163

Epoch: 6| Step: 3
Training loss: 1.5511125263589003
Validation loss: 2.612188394875466

Epoch: 6| Step: 4
Training loss: 1.9394963961688492
Validation loss: 2.6038652220144383

Epoch: 6| Step: 5
Training loss: 1.9387460823929519
Validation loss: 2.6694183060760874

Epoch: 6| Step: 6
Training loss: 2.359284253933157
Validation loss: 2.676133730799392

Epoch: 6| Step: 7
Training loss: 2.059070394445568
Validation loss: 2.5872166476923333

Epoch: 6| Step: 8
Training loss: 1.668307124886964
Validation loss: 2.605481713456709

Epoch: 6| Step: 9
Training loss: 1.8304736057140567
Validation loss: 2.598757586374077

Epoch: 6| Step: 10
Training loss: 1.8087631376958546
Validation loss: 2.6330047597594604

Epoch: 6| Step: 11
Training loss: 1.916010398740961
Validation loss: 2.7001170509774357

Epoch: 6| Step: 12
Training loss: 2.0567734721606294
Validation loss: 2.8937327750388855

Epoch: 6| Step: 13
Training loss: 2.9343181178030586
Validation loss: 2.831609290246892

Epoch: 86| Step: 0
Training loss: 1.7814953283719233
Validation loss: 2.9497822810505823

Epoch: 6| Step: 1
Training loss: 2.332110890828908
Validation loss: 2.908938692117608

Epoch: 6| Step: 2
Training loss: 2.3767424766715974
Validation loss: 2.7737134482777672

Epoch: 6| Step: 3
Training loss: 1.9359799236486177
Validation loss: 2.671785899678815

Epoch: 6| Step: 4
Training loss: 1.6282811417637726
Validation loss: 2.649797418636455

Epoch: 6| Step: 5
Training loss: 2.485077092991598
Validation loss: 2.570764488357701

Epoch: 6| Step: 6
Training loss: 2.422571586598341
Validation loss: 2.6918740126719665

Epoch: 6| Step: 7
Training loss: 1.806105085849376
Validation loss: 2.7068644917672486

Epoch: 6| Step: 8
Training loss: 2.104613404644143
Validation loss: 2.618925149745965

Epoch: 6| Step: 9
Training loss: 2.3457312792661456
Validation loss: 2.6129376119452314

Epoch: 6| Step: 10
Training loss: 1.8966763337374453
Validation loss: 2.5701824646186715

Epoch: 6| Step: 11
Training loss: 1.8583481461600315
Validation loss: 2.5913327224784046

Epoch: 6| Step: 12
Training loss: 1.3296240481019725
Validation loss: 2.674595405308506

Epoch: 6| Step: 13
Training loss: 1.4365163837936528
Validation loss: 2.614475921815687

Epoch: 87| Step: 0
Training loss: 2.4478569077576684
Validation loss: 2.7135971903230485

Epoch: 6| Step: 1
Training loss: 1.761328948006572
Validation loss: 2.7026508040321007

Epoch: 6| Step: 2
Training loss: 2.074301278004512
Validation loss: 2.7589490959990113

Epoch: 6| Step: 3
Training loss: 2.204397064262959
Validation loss: 2.734302032950355

Epoch: 6| Step: 4
Training loss: 1.727538786478921
Validation loss: 2.6776790970267994

Epoch: 6| Step: 5
Training loss: 2.1492141706944126
Validation loss: 2.7580045825896207

Epoch: 6| Step: 6
Training loss: 1.3975042713625467
Validation loss: 2.675703848580183

Epoch: 6| Step: 7
Training loss: 2.103072861001064
Validation loss: 2.6591568543211164

Epoch: 6| Step: 8
Training loss: 1.3391884405141974
Validation loss: 2.6259950613758396

Epoch: 6| Step: 9
Training loss: 1.9815987216903759
Validation loss: 2.6559201952069085

Epoch: 6| Step: 10
Training loss: 1.3854312561337758
Validation loss: 2.5980811973747593

Epoch: 6| Step: 11
Training loss: 1.8856248547456285
Validation loss: 2.649502550375256

Epoch: 6| Step: 12
Training loss: 2.14325046335596
Validation loss: 2.5809298045015217

Epoch: 6| Step: 13
Training loss: 2.0659322212970017
Validation loss: 2.558988926001803

Epoch: 88| Step: 0
Training loss: 1.830339183121138
Validation loss: 2.6689683448159665

Epoch: 6| Step: 1
Training loss: 2.254204107268586
Validation loss: 2.622913121429867

Epoch: 6| Step: 2
Training loss: 2.6040283980220105
Validation loss: 2.656860984394966

Epoch: 6| Step: 3
Training loss: 1.9525709663418316
Validation loss: 2.6477088038276286

Epoch: 6| Step: 4
Training loss: 1.7722246501205752
Validation loss: 2.635415455412052

Epoch: 6| Step: 5
Training loss: 2.0626133974286596
Validation loss: 2.5534674387973966

Epoch: 6| Step: 6
Training loss: 1.7675153352323063
Validation loss: 2.573328229803582

Epoch: 6| Step: 7
Training loss: 1.6284158457866595
Validation loss: 2.6110836685939014

Epoch: 6| Step: 8
Training loss: 2.055765543627831
Validation loss: 2.569030550249299

Epoch: 6| Step: 9
Training loss: 1.7867108343605402
Validation loss: 2.7069639754456567

Epoch: 6| Step: 10
Training loss: 2.0524202899578974
Validation loss: 2.717678063368938

Epoch: 6| Step: 11
Training loss: 1.4858954422671677
Validation loss: 2.713300761379594

Epoch: 6| Step: 12
Training loss: 1.7248707764363256
Validation loss: 2.6524127694664537

Epoch: 6| Step: 13
Training loss: 1.7621903221837023
Validation loss: 2.70693922597444

Epoch: 89| Step: 0
Training loss: 2.1765512305938066
Validation loss: 2.6843788593991316

Epoch: 6| Step: 1
Training loss: 1.6796788415020294
Validation loss: 2.704223541892074

Epoch: 6| Step: 2
Training loss: 2.1736925602102697
Validation loss: 2.630447366761821

Epoch: 6| Step: 3
Training loss: 2.421378103165127
Validation loss: 2.521474620072347

Epoch: 6| Step: 4
Training loss: 2.1434361175207854
Validation loss: 2.6435420610614604

Epoch: 6| Step: 5
Training loss: 1.8598874451821912
Validation loss: 2.5924708801100635

Epoch: 6| Step: 6
Training loss: 1.9770446912917132
Validation loss: 2.603462754800448

Epoch: 6| Step: 7
Training loss: 1.582290289122547
Validation loss: 2.641662927879632

Epoch: 6| Step: 8
Training loss: 1.3383312529994684
Validation loss: 2.5774793490727417

Epoch: 6| Step: 9
Training loss: 1.5981992064767032
Validation loss: 2.644406562243553

Epoch: 6| Step: 10
Training loss: 2.069208044876928
Validation loss: 2.656455611704548

Epoch: 6| Step: 11
Training loss: 1.8362726433216752
Validation loss: 2.5839338963259437

Epoch: 6| Step: 12
Training loss: 2.178563310040751
Validation loss: 2.641521895941328

Epoch: 6| Step: 13
Training loss: 1.7704674810328072
Validation loss: 2.6672023195474415

Epoch: 90| Step: 0
Training loss: 1.6870906474616845
Validation loss: 2.7859380551243325

Epoch: 6| Step: 1
Training loss: 1.673648499651143
Validation loss: 2.684872651516539

Epoch: 6| Step: 2
Training loss: 2.020097487146218
Validation loss: 2.6808963492017686

Epoch: 6| Step: 3
Training loss: 1.3763833456551184
Validation loss: 2.781905307791799

Epoch: 6| Step: 4
Training loss: 1.5876731958302415
Validation loss: 2.7474801772249755

Epoch: 6| Step: 5
Training loss: 2.544140523790158
Validation loss: 2.639939604824584

Epoch: 6| Step: 6
Training loss: 1.5286492819370792
Validation loss: 2.7512478598170813

Epoch: 6| Step: 7
Training loss: 1.4074626356623192
Validation loss: 2.5945555803260296

Epoch: 6| Step: 8
Training loss: 2.272373855161617
Validation loss: 2.6902586654704552

Epoch: 6| Step: 9
Training loss: 2.819192849027417
Validation loss: 2.5843147802813276

Epoch: 6| Step: 10
Training loss: 1.9120018902533855
Validation loss: 2.6233948235129585

Epoch: 6| Step: 11
Training loss: 2.1791424907366848
Validation loss: 2.6459494788041114

Epoch: 6| Step: 12
Training loss: 1.5987920850712956
Validation loss: 2.5530897426777743

Epoch: 6| Step: 13
Training loss: 1.9125198064040265
Validation loss: 2.622881215901025

Epoch: 91| Step: 0
Training loss: 1.5413210799385741
Validation loss: 2.702375848408019

Epoch: 6| Step: 1
Training loss: 1.730850831985483
Validation loss: 2.622883124789735

Epoch: 6| Step: 2
Training loss: 1.8152762887383194
Validation loss: 2.580206706837488

Epoch: 6| Step: 3
Training loss: 1.956906495524649
Validation loss: 2.614082643104861

Epoch: 6| Step: 4
Training loss: 1.5496496112158722
Validation loss: 2.57419267022791

Epoch: 6| Step: 5
Training loss: 2.092967670094381
Validation loss: 2.684796933049355

Epoch: 6| Step: 6
Training loss: 2.0096299076503255
Validation loss: 2.5690243091133507

Epoch: 6| Step: 7
Training loss: 1.3105671137740775
Validation loss: 2.6341090269056857

Epoch: 6| Step: 8
Training loss: 1.3540690558050552
Validation loss: 2.5897815787024503

Epoch: 6| Step: 9
Training loss: 2.0164256317023037
Validation loss: 2.657645221868015

Epoch: 6| Step: 10
Training loss: 1.9440511267850127
Validation loss: 2.6724993476355396

Epoch: 6| Step: 11
Training loss: 2.014972551599031
Validation loss: 2.636298387715559

Epoch: 6| Step: 12
Training loss: 2.0258376567150553
Validation loss: 2.6701709749244866

Epoch: 6| Step: 13
Training loss: 2.357435123687657
Validation loss: 2.6055478260826663

Epoch: 92| Step: 0
Training loss: 1.894570010073866
Validation loss: 2.745284256475925

Epoch: 6| Step: 1
Training loss: 1.7354463584652657
Validation loss: 2.912042007673404

Epoch: 6| Step: 2
Training loss: 2.143474047280145
Validation loss: 2.9111635721998677

Epoch: 6| Step: 3
Training loss: 1.7942356130154193
Validation loss: 2.8728585214980327

Epoch: 6| Step: 4
Training loss: 2.1539469042992976
Validation loss: 2.7663616916214053

Epoch: 6| Step: 5
Training loss: 1.8769648111954098
Validation loss: 2.683849235563204

Epoch: 6| Step: 6
Training loss: 1.7412169622722464
Validation loss: 2.645998601682894

Epoch: 6| Step: 7
Training loss: 2.6149025123177694
Validation loss: 2.664723826013486

Epoch: 6| Step: 8
Training loss: 2.4639887226020054
Validation loss: 2.701180421967867

Epoch: 6| Step: 9
Training loss: 1.989456638742786
Validation loss: 2.6657698335167046

Epoch: 6| Step: 10
Training loss: 1.836748698780185
Validation loss: 2.6567179847301428

Epoch: 6| Step: 11
Training loss: 2.2325862313391145
Validation loss: 2.652701726847454

Epoch: 6| Step: 12
Training loss: 1.5102078085128512
Validation loss: 2.62543990975255

Epoch: 6| Step: 13
Training loss: 1.2652823843920407
Validation loss: 2.601156651760302

Epoch: 93| Step: 0
Training loss: 1.9791840669636696
Validation loss: 2.7317159239296465

Epoch: 6| Step: 1
Training loss: 2.0608545155046554
Validation loss: 2.590650253571614

Epoch: 6| Step: 2
Training loss: 2.038246429953039
Validation loss: 2.766888159384612

Epoch: 6| Step: 3
Training loss: 1.652792723060091
Validation loss: 2.734627078108133

Epoch: 6| Step: 4
Training loss: 1.9087203856283679
Validation loss: 2.734114629065615

Epoch: 6| Step: 5
Training loss: 1.1016410637293246
Validation loss: 2.7098673559761686

Epoch: 6| Step: 6
Training loss: 1.6406614027071917
Validation loss: 2.6130986475381768

Epoch: 6| Step: 7
Training loss: 2.5375149280127784
Validation loss: 2.611414905780942

Epoch: 6| Step: 8
Training loss: 2.3389660649115065
Validation loss: 2.589847961698534

Epoch: 6| Step: 9
Training loss: 1.4171305719652856
Validation loss: 2.6321539503291285

Epoch: 6| Step: 10
Training loss: 1.9613364372388775
Validation loss: 2.645524627718474

Epoch: 6| Step: 11
Training loss: 1.9934379692214625
Validation loss: 2.607305257906348

Epoch: 6| Step: 12
Training loss: 2.1230068957539787
Validation loss: 2.6818180493225943

Epoch: 6| Step: 13
Training loss: 2.0459657935660562
Validation loss: 2.6272002187848824

Epoch: 94| Step: 0
Training loss: 2.214955160578381
Validation loss: 2.759672825236874

Epoch: 6| Step: 1
Training loss: 1.5852012992612918
Validation loss: 2.7001178898211258

Epoch: 6| Step: 2
Training loss: 1.6205008652027695
Validation loss: 2.745815865360282

Epoch: 6| Step: 3
Training loss: 1.722912274147102
Validation loss: 2.7776840867030717

Epoch: 6| Step: 4
Training loss: 2.0569469951871686
Validation loss: 2.776393708218574

Epoch: 6| Step: 5
Training loss: 1.7787926437831438
Validation loss: 2.718892791622957

Epoch: 6| Step: 6
Training loss: 1.566817916846754
Validation loss: 2.6225365175141784

Epoch: 6| Step: 7
Training loss: 1.586375885305292
Validation loss: 2.587643800876787

Epoch: 6| Step: 8
Training loss: 1.6470482925070358
Validation loss: 2.6165799930415563

Epoch: 6| Step: 9
Training loss: 1.8578203898936885
Validation loss: 2.6144899653041986

Epoch: 6| Step: 10
Training loss: 1.5975964075646962
Validation loss: 2.6187245121142664

Epoch: 6| Step: 11
Training loss: 2.971025418085835
Validation loss: 2.5478088835415265

Epoch: 6| Step: 12
Training loss: 1.2607375070261928
Validation loss: 2.5371499394831822

Epoch: 6| Step: 13
Training loss: 2.2008652156132014
Validation loss: 2.635781739069969

Epoch: 95| Step: 0
Training loss: 1.7441506721916311
Validation loss: 2.6088380013577672

Epoch: 6| Step: 1
Training loss: 1.7098203870349686
Validation loss: 2.6100721512975937

Epoch: 6| Step: 2
Training loss: 1.3687105687005188
Validation loss: 2.6270054770621796

Epoch: 6| Step: 3
Training loss: 1.1780075844454165
Validation loss: 2.6095057852552346

Epoch: 6| Step: 4
Training loss: 1.6147182613312339
Validation loss: 2.6991223374633067

Epoch: 6| Step: 5
Training loss: 1.9101196160733311
Validation loss: 2.7211820459766716

Epoch: 6| Step: 6
Training loss: 1.5090448749055674
Validation loss: 2.708458623677928

Epoch: 6| Step: 7
Training loss: 2.294315598939126
Validation loss: 2.6521885882215415

Epoch: 6| Step: 8
Training loss: 2.4287474552441597
Validation loss: 2.6992050737328017

Epoch: 6| Step: 9
Training loss: 2.0061283395546767
Validation loss: 2.6211303162617954

Epoch: 6| Step: 10
Training loss: 1.8506996301034018
Validation loss: 2.6948225820031495

Epoch: 6| Step: 11
Training loss: 1.6662228311211016
Validation loss: 2.590664357192024

Epoch: 6| Step: 12
Training loss: 1.705280374983204
Validation loss: 2.6610850739936325

Epoch: 6| Step: 13
Training loss: 1.7954353204187359
Validation loss: 2.6317011962068446

Epoch: 96| Step: 0
Training loss: 1.8913043354345165
Validation loss: 2.645289467810646

Epoch: 6| Step: 1
Training loss: 1.6556290236150941
Validation loss: 2.550728423977025

Epoch: 6| Step: 2
Training loss: 1.5783488804106198
Validation loss: 2.6040575742123724

Epoch: 6| Step: 3
Training loss: 1.4143295457441465
Validation loss: 2.558582583492848

Epoch: 6| Step: 4
Training loss: 1.3319195563508495
Validation loss: 2.6124647354106507

Epoch: 6| Step: 5
Training loss: 2.3454494164419515
Validation loss: 2.629907743192034

Epoch: 6| Step: 6
Training loss: 1.4015329721459746
Validation loss: 2.681054088427299

Epoch: 6| Step: 7
Training loss: 1.7419063871612908
Validation loss: 2.690170757482574

Epoch: 6| Step: 8
Training loss: 1.2087248244716187
Validation loss: 2.617787428082329

Epoch: 6| Step: 9
Training loss: 2.0973453682062897
Validation loss: 2.5982862124555384

Epoch: 6| Step: 10
Training loss: 1.8300080993348038
Validation loss: 2.62693264373018

Epoch: 6| Step: 11
Training loss: 1.5007502745768384
Validation loss: 2.660776866007433

Epoch: 6| Step: 12
Training loss: 2.0026692221549465
Validation loss: 2.714577180138672

Epoch: 6| Step: 13
Training loss: 2.023333101267333
Validation loss: 2.675472759646389

Epoch: 97| Step: 0
Training loss: 2.131239426214663
Validation loss: 2.6652019521310404

Epoch: 6| Step: 1
Training loss: 1.665122397566303
Validation loss: 2.6257536426906216

Epoch: 6| Step: 2
Training loss: 2.4154853454726477
Validation loss: 2.6129785960231176

Epoch: 6| Step: 3
Training loss: 1.8628963176810693
Validation loss: 2.6240174104512257

Epoch: 6| Step: 4
Training loss: 1.6092269977551195
Validation loss: 2.623341354235061

Epoch: 6| Step: 5
Training loss: 1.8076124392158057
Validation loss: 2.700274013225445

Epoch: 6| Step: 6
Training loss: 1.3732834418193927
Validation loss: 2.6653401582260625

Epoch: 6| Step: 7
Training loss: 2.2860918265428416
Validation loss: 2.616279664750077

Epoch: 6| Step: 8
Training loss: 1.464443141835054
Validation loss: 2.6652033610642825

Epoch: 6| Step: 9
Training loss: 1.9728320959294148
Validation loss: 2.6870884839012157

Epoch: 6| Step: 10
Training loss: 1.642322352540987
Validation loss: 2.6069470986531322

Epoch: 6| Step: 11
Training loss: 1.0198275548421387
Validation loss: 2.6647435247264633

Epoch: 6| Step: 12
Training loss: 1.2756984275008578
Validation loss: 2.6654209167659673

Epoch: 6| Step: 13
Training loss: 1.7234110659857271
Validation loss: 2.5563068992916698

Epoch: 98| Step: 0
Training loss: 1.5868525378698455
Validation loss: 2.7518215215660256

Epoch: 6| Step: 1
Training loss: 1.277030603130237
Validation loss: 2.597115107031403

Epoch: 6| Step: 2
Training loss: 1.7829111618571547
Validation loss: 2.5748395542663305

Epoch: 6| Step: 3
Training loss: 1.7334574428777623
Validation loss: 2.6730906526268905

Epoch: 6| Step: 4
Training loss: 1.903241331556997
Validation loss: 2.586704981567645

Epoch: 6| Step: 5
Training loss: 1.485831098627937
Validation loss: 2.63842087047601

Epoch: 6| Step: 6
Training loss: 1.578715147961183
Validation loss: 2.738410355321919

Epoch: 6| Step: 7
Training loss: 2.096435418933595
Validation loss: 2.638601155795787

Epoch: 6| Step: 8
Training loss: 1.8124998026880617
Validation loss: 2.628364072517931

Epoch: 6| Step: 9
Training loss: 2.5933977370449304
Validation loss: 2.6602831272036362

Epoch: 6| Step: 10
Training loss: 1.2500022888162639
Validation loss: 2.5758806651627246

Epoch: 6| Step: 11
Training loss: 1.7546168461720433
Validation loss: 2.6867975233605446

Epoch: 6| Step: 12
Training loss: 1.9269597469257038
Validation loss: 2.760034834646534

Epoch: 6| Step: 13
Training loss: 1.8675609518417315
Validation loss: 2.709239240894812

Epoch: 99| Step: 0
Training loss: 1.3507996098432804
Validation loss: 2.749108191584531

Epoch: 6| Step: 1
Training loss: 1.830626251960032
Validation loss: 2.6402583573097758

Epoch: 6| Step: 2
Training loss: 1.9553347484901284
Validation loss: 2.652038736460363

Epoch: 6| Step: 3
Training loss: 1.224937188231423
Validation loss: 2.688696188453981

Epoch: 6| Step: 4
Training loss: 1.6325210968336843
Validation loss: 2.6193954188331436

Epoch: 6| Step: 5
Training loss: 2.489961880005273
Validation loss: 2.590703952753475

Epoch: 6| Step: 6
Training loss: 1.4665927871967874
Validation loss: 2.633230574228566

Epoch: 6| Step: 7
Training loss: 1.8860856093660074
Validation loss: 2.832544691525024

Epoch: 6| Step: 8
Training loss: 1.9996338747598668
Validation loss: 2.704230374691305

Epoch: 6| Step: 9
Training loss: 2.0644177855152903
Validation loss: 2.765661357920827

Epoch: 6| Step: 10
Training loss: 1.7849217100097858
Validation loss: 2.6098665699523247

Epoch: 6| Step: 11
Training loss: 1.2303221115655414
Validation loss: 2.606736347124075

Epoch: 6| Step: 12
Training loss: 1.7697536842382207
Validation loss: 2.549264298068256

Epoch: 6| Step: 13
Training loss: 1.6282667922002314
Validation loss: 2.6588043796063823

Epoch: 100| Step: 0
Training loss: 1.5430350373913846
Validation loss: 2.658273412413794

Epoch: 6| Step: 1
Training loss: 1.8907535603847976
Validation loss: 2.686001278436451

Epoch: 6| Step: 2
Training loss: 1.8013895790505965
Validation loss: 2.556891514275593

Epoch: 6| Step: 3
Training loss: 1.5540921398767464
Validation loss: 2.6290169362407405

Epoch: 6| Step: 4
Training loss: 1.6144732858214481
Validation loss: 2.6726667930099954

Epoch: 6| Step: 5
Training loss: 1.2498436353158595
Validation loss: 2.6182256357232294

Epoch: 6| Step: 6
Training loss: 1.7758298357901223
Validation loss: 2.764193557728825

Epoch: 6| Step: 7
Training loss: 1.8817079715345628
Validation loss: 2.703522404911759

Epoch: 6| Step: 8
Training loss: 2.3839397828158413
Validation loss: 2.706064937099033

Epoch: 6| Step: 9
Training loss: 1.7168403420354157
Validation loss: 2.7270824953043453

Epoch: 6| Step: 10
Training loss: 1.5650748590231438
Validation loss: 2.7039717154819924

Epoch: 6| Step: 11
Training loss: 1.6838705096487587
Validation loss: 2.6663994704930705

Epoch: 6| Step: 12
Training loss: 1.5178432944812066
Validation loss: 2.665667038556613

Epoch: 6| Step: 13
Training loss: 2.023103075117842
Validation loss: 2.586877504126194

Testing loss: 2.223026500087283
