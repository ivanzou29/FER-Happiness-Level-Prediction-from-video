Epoch: 1| Step: 0
Training loss: 7.984410762786865
Validation loss: 8.003571391105652

Epoch: 5| Step: 1
Training loss: 8.718132019042969
Validation loss: 7.966339310010274

Epoch: 5| Step: 2
Training loss: 8.318939208984375
Validation loss: 7.933294177055359

Epoch: 5| Step: 3
Training loss: 7.498593807220459
Validation loss: 7.898442169030507

Epoch: 5| Step: 4
Training loss: 8.132762908935547
Validation loss: 7.865852256615956

Epoch: 5| Step: 5
Training loss: 7.9675188064575195
Validation loss: 7.833015163739522

Epoch: 5| Step: 6
Training loss: 6.64876651763916
Validation loss: 7.800040066242218

Epoch: 5| Step: 7
Training loss: 8.305299758911133
Validation loss: 7.774342497189839

Epoch: 5| Step: 8
Training loss: 8.398323059082031
Validation loss: 7.741510768731435

Epoch: 5| Step: 9
Training loss: 7.8105645179748535
Validation loss: 7.710535883903503

Epoch: 5| Step: 10
Training loss: 7.300413608551025
Validation loss: 7.683727363745372

Epoch: 5| Step: 11
Training loss: 7.006704330444336
Validation loss: 7.649243772029877

Epoch: 2| Step: 0
Training loss: 7.7096357345581055
Validation loss: 7.619789739449819

Epoch: 5| Step: 1
Training loss: 6.890869140625
Validation loss: 7.586352586746216

Epoch: 5| Step: 2
Training loss: 7.3001813888549805
Validation loss: 7.556513647238414

Epoch: 5| Step: 3
Training loss: 8.021520614624023
Validation loss: 7.523346563180287

Epoch: 5| Step: 4
Training loss: 8.12569522857666
Validation loss: 7.488838354746501

Epoch: 5| Step: 5
Training loss: 7.545785427093506
Validation loss: 7.452578902244568

Epoch: 5| Step: 6
Training loss: 8.003393173217773
Validation loss: 7.4155568679173784

Epoch: 5| Step: 7
Training loss: 6.9167938232421875
Validation loss: 7.3798442880312605

Epoch: 5| Step: 8
Training loss: 7.777870178222656
Validation loss: 7.3379250566164655

Epoch: 5| Step: 9
Training loss: 8.349504470825195
Validation loss: 7.299398799737294

Epoch: 5| Step: 10
Training loss: 6.458314418792725
Validation loss: 7.255643467108409

Epoch: 5| Step: 11
Training loss: 5.114384651184082
Validation loss: 7.21064817905426

Epoch: 3| Step: 0
Training loss: 6.791490077972412
Validation loss: 7.167134761810303

Epoch: 5| Step: 1
Training loss: 6.595438480377197
Validation loss: 7.120946268240611

Epoch: 5| Step: 2
Training loss: 6.80429220199585
Validation loss: 7.071047782897949

Epoch: 5| Step: 3
Training loss: 7.029491424560547
Validation loss: 7.0182316700617475

Epoch: 5| Step: 4
Training loss: 7.8800811767578125
Validation loss: 6.964576363563538

Epoch: 5| Step: 5
Training loss: 7.72018575668335
Validation loss: 6.904998918374379

Epoch: 5| Step: 6
Training loss: 6.8508124351501465
Validation loss: 6.849610487620036

Epoch: 5| Step: 7
Training loss: 6.883971214294434
Validation loss: 6.795641660690308

Epoch: 5| Step: 8
Training loss: 7.244575500488281
Validation loss: 6.728208303451538

Epoch: 5| Step: 9
Training loss: 6.842665672302246
Validation loss: 6.666176537672679

Epoch: 5| Step: 10
Training loss: 6.056225776672363
Validation loss: 6.595281779766083

Epoch: 5| Step: 11
Training loss: 6.276124477386475
Validation loss: 6.527613520622253

Epoch: 4| Step: 0
Training loss: 6.414756774902344
Validation loss: 6.450105369091034

Epoch: 5| Step: 1
Training loss: 6.720292568206787
Validation loss: 6.374786337216695

Epoch: 5| Step: 2
Training loss: 6.58486270904541
Validation loss: 6.295956353346507

Epoch: 5| Step: 3
Training loss: 6.6502532958984375
Validation loss: 6.207218825817108

Epoch: 5| Step: 4
Training loss: 5.934757709503174
Validation loss: 6.113888641198476

Epoch: 5| Step: 5
Training loss: 6.484004020690918
Validation loss: 6.024787545204163

Epoch: 5| Step: 6
Training loss: 5.963571071624756
Validation loss: 5.92211252450943

Epoch: 5| Step: 7
Training loss: 5.984930992126465
Validation loss: 5.812635083993276

Epoch: 5| Step: 8
Training loss: 4.7848100662231445
Validation loss: 5.691580494244893

Epoch: 5| Step: 9
Training loss: 5.067595481872559
Validation loss: 5.5813936193784075

Epoch: 5| Step: 10
Training loss: 5.7209343910217285
Validation loss: 5.4475545684496565

Epoch: 5| Step: 11
Training loss: 7.214723110198975
Validation loss: 5.320081492265065

Epoch: 5| Step: 0
Training loss: 5.635870456695557
Validation loss: 5.17185366153717

Epoch: 5| Step: 1
Training loss: 4.465710639953613
Validation loss: 5.028325100739797

Epoch: 5| Step: 2
Training loss: 5.000189781188965
Validation loss: 4.868832508722941

Epoch: 5| Step: 3
Training loss: 5.121917724609375
Validation loss: 4.709207057952881

Epoch: 5| Step: 4
Training loss: 4.97043514251709
Validation loss: 4.535853525002797

Epoch: 5| Step: 5
Training loss: 4.7424750328063965
Validation loss: 4.371361841758092

Epoch: 5| Step: 6
Training loss: 4.980117321014404
Validation loss: 4.179216901461284

Epoch: 5| Step: 7
Training loss: 3.01021409034729
Validation loss: 4.004204213619232

Epoch: 5| Step: 8
Training loss: 3.439945697784424
Validation loss: 3.850902189811071

Epoch: 5| Step: 9
Training loss: 3.852457046508789
Validation loss: 3.6735407610734305

Epoch: 5| Step: 10
Training loss: 3.9724953174591064
Validation loss: 3.5141219198703766

Epoch: 5| Step: 11
Training loss: 1.2937471866607666
Validation loss: 3.360507676998774

Epoch: 6| Step: 0
Training loss: 3.1582112312316895
Validation loss: 3.200958331425985

Epoch: 5| Step: 1
Training loss: 2.3363170623779297
Validation loss: 3.0382182598114014

Epoch: 5| Step: 2
Training loss: 2.801727771759033
Validation loss: 2.8836622734864554

Epoch: 5| Step: 3
Training loss: 2.9311816692352295
Validation loss: 2.750097006559372

Epoch: 5| Step: 4
Training loss: 2.7713217735290527
Validation loss: 2.6122191548347473

Epoch: 5| Step: 5
Training loss: 2.4209132194519043
Validation loss: 2.451174130042394

Epoch: 5| Step: 6
Training loss: 2.5721254348754883
Validation loss: 2.353736932078997

Epoch: 5| Step: 7
Training loss: 3.3439788818359375
Validation loss: 2.2815089225769043

Epoch: 5| Step: 8
Training loss: 2.158904552459717
Validation loss: 2.268142595887184

Epoch: 5| Step: 9
Training loss: 2.522670269012451
Validation loss: 2.205192039410273

Epoch: 5| Step: 10
Training loss: 1.8330256938934326
Validation loss: 2.221653347214063

Epoch: 5| Step: 11
Training loss: 1.6891076564788818
Validation loss: 2.2548296501239142

Epoch: 7| Step: 0
Training loss: 1.9968525171279907
Validation loss: 2.2389157116413116

Epoch: 5| Step: 1
Training loss: 2.4300708770751953
Validation loss: 2.2564171105623245

Epoch: 5| Step: 2
Training loss: 1.975293517112732
Validation loss: 2.2772517005602517

Epoch: 5| Step: 3
Training loss: 3.1560404300689697
Validation loss: 2.298618127902349

Epoch: 5| Step: 4
Training loss: 2.953627109527588
Validation loss: 2.269672448436419

Epoch: 5| Step: 5
Training loss: 2.742152690887451
Validation loss: 2.263849586248398

Epoch: 5| Step: 6
Training loss: 2.306356191635132
Validation loss: 2.2544789165258408

Epoch: 5| Step: 7
Training loss: 3.088364362716675
Validation loss: 2.2208452175060907

Epoch: 5| Step: 8
Training loss: 1.9539191722869873
Validation loss: 2.2226266860961914

Epoch: 5| Step: 9
Training loss: 2.263000011444092
Validation loss: 2.2272026936213174

Epoch: 5| Step: 10
Training loss: 2.0527305603027344
Validation loss: 2.196907381216685

Epoch: 5| Step: 11
Training loss: 2.0830745697021484
Validation loss: 2.2099344581365585

Epoch: 8| Step: 0
Training loss: 2.098026752471924
Validation loss: 2.182032957673073

Epoch: 5| Step: 1
Training loss: 2.3810997009277344
Validation loss: 2.1933943827946982

Epoch: 5| Step: 2
Training loss: 1.7991832494735718
Validation loss: 2.236903806527456

Epoch: 5| Step: 3
Training loss: 2.474907636642456
Validation loss: 2.233551641305288

Epoch: 5| Step: 4
Training loss: 2.172922372817993
Validation loss: 2.243031074603399

Epoch: 5| Step: 5
Training loss: 2.75974440574646
Validation loss: 2.265278915564219

Epoch: 5| Step: 6
Training loss: 2.2172346115112305
Validation loss: 2.2712318996588388

Epoch: 5| Step: 7
Training loss: 2.1970767974853516
Validation loss: 2.2851746529340744

Epoch: 5| Step: 8
Training loss: 2.3106002807617188
Validation loss: 2.2867923080921173

Epoch: 5| Step: 9
Training loss: 2.8390936851501465
Validation loss: 2.3059336791435876

Epoch: 5| Step: 10
Training loss: 2.2654995918273926
Validation loss: 2.3051737944285073

Epoch: 5| Step: 11
Training loss: 1.569300651550293
Validation loss: 2.3057085474332175

Epoch: 9| Step: 0
Training loss: 2.8319361209869385
Validation loss: 2.285252094268799

Epoch: 5| Step: 1
Training loss: 2.828390598297119
Validation loss: 2.301263009508451

Epoch: 5| Step: 2
Training loss: 1.7883554697036743
Validation loss: 2.2676091293493905

Epoch: 5| Step: 3
Training loss: 1.6684414148330688
Validation loss: 2.269758721192678

Epoch: 5| Step: 4
Training loss: 2.3434994220733643
Validation loss: 2.2443951765696206

Epoch: 5| Step: 5
Training loss: 2.529010534286499
Validation loss: 2.2131136606136956

Epoch: 5| Step: 6
Training loss: 2.6364009380340576
Validation loss: 2.2235921720663705

Epoch: 5| Step: 7
Training loss: 1.8996025323867798
Validation loss: 2.2129117846488953

Epoch: 5| Step: 8
Training loss: 2.3075127601623535
Validation loss: 2.2050731678803763

Epoch: 5| Step: 9
Training loss: 1.9522708654403687
Validation loss: 2.215330829222997

Epoch: 5| Step: 10
Training loss: 1.976945161819458
Validation loss: 2.165624260902405

Epoch: 5| Step: 11
Training loss: 2.9119601249694824
Validation loss: 2.1730636060237885

Epoch: 10| Step: 0
Training loss: 2.2349116802215576
Validation loss: 2.189692954222361

Epoch: 5| Step: 1
Training loss: 2.122305393218994
Validation loss: 2.173651695251465

Epoch: 5| Step: 2
Training loss: 1.9409284591674805
Validation loss: 2.150906374057134

Epoch: 5| Step: 3
Training loss: 2.1757640838623047
Validation loss: 2.1585855235656104

Epoch: 5| Step: 4
Training loss: 2.1219990253448486
Validation loss: 2.1517890989780426

Epoch: 5| Step: 5
Training loss: 2.008667469024658
Validation loss: 2.1373112201690674

Epoch: 5| Step: 6
Training loss: 1.8732335567474365
Validation loss: 2.1640462279319763

Epoch: 5| Step: 7
Training loss: 2.1421539783477783
Validation loss: 2.1429365972677865

Epoch: 5| Step: 8
Training loss: 2.530226945877075
Validation loss: 2.147705987095833

Epoch: 5| Step: 9
Training loss: 3.1462833881378174
Validation loss: 2.1521318604548774

Epoch: 5| Step: 10
Training loss: 2.2342193126678467
Validation loss: 2.1542796144882836

Epoch: 5| Step: 11
Training loss: 2.4235177040100098
Validation loss: 2.1451977441708245

Epoch: 11| Step: 0
Training loss: 2.430401086807251
Validation loss: 2.150395020842552

Epoch: 5| Step: 1
Training loss: 2.3008270263671875
Validation loss: 2.165881097316742

Epoch: 5| Step: 2
Training loss: 1.7230325937271118
Validation loss: 2.122087905804316

Epoch: 5| Step: 3
Training loss: 2.567042827606201
Validation loss: 2.139673868815104

Epoch: 5| Step: 4
Training loss: 2.1790761947631836
Validation loss: 2.1460679918527603

Epoch: 5| Step: 5
Training loss: 2.0554938316345215
Validation loss: 2.136844038963318

Epoch: 5| Step: 6
Training loss: 1.8712310791015625
Validation loss: 2.123252342144648

Epoch: 5| Step: 7
Training loss: 2.4531593322753906
Validation loss: 2.152589256564776

Epoch: 5| Step: 8
Training loss: 2.5530154705047607
Validation loss: 2.142296681801478

Epoch: 5| Step: 9
Training loss: 2.282409191131592
Validation loss: 2.1389121462901435

Epoch: 5| Step: 10
Training loss: 1.8946897983551025
Validation loss: 2.1536569744348526

Epoch: 5| Step: 11
Training loss: 2.9853219985961914
Validation loss: 2.1434448758761087

Epoch: 12| Step: 0
Training loss: 2.310940742492676
Validation loss: 2.0937321931123734

Epoch: 5| Step: 1
Training loss: 2.070350408554077
Validation loss: 2.0965345054864883

Epoch: 5| Step: 2
Training loss: 1.8340988159179688
Validation loss: 2.102011203765869

Epoch: 5| Step: 3
Training loss: 2.58433198928833
Validation loss: 2.1123974670966468

Epoch: 5| Step: 4
Training loss: 2.1946065425872803
Validation loss: 2.110294202963511

Epoch: 5| Step: 5
Training loss: 1.8099725246429443
Validation loss: 2.1289734641710916

Epoch: 5| Step: 6
Training loss: 2.1803479194641113
Validation loss: 2.123121256629626

Epoch: 5| Step: 7
Training loss: 2.0157387256622314
Validation loss: 2.1373867144187293

Epoch: 5| Step: 8
Training loss: 2.2158055305480957
Validation loss: 2.132722189029058

Epoch: 5| Step: 9
Training loss: 2.6055665016174316
Validation loss: 2.123657296101252

Epoch: 5| Step: 10
Training loss: 2.5754125118255615
Validation loss: 2.1118760655323663

Epoch: 5| Step: 11
Training loss: 2.6569864749908447
Validation loss: 2.1135688523451486

Epoch: 13| Step: 0
Training loss: 2.2215564250946045
Validation loss: 2.1050316989421844

Epoch: 5| Step: 1
Training loss: 2.0600314140319824
Validation loss: 2.098570838570595

Epoch: 5| Step: 2
Training loss: 1.5554956197738647
Validation loss: 2.1074955463409424

Epoch: 5| Step: 3
Training loss: 1.960569977760315
Validation loss: 2.1036252677440643

Epoch: 5| Step: 4
Training loss: 1.993138074874878
Validation loss: 2.121060937643051

Epoch: 5| Step: 5
Training loss: 2.5599331855773926
Validation loss: 2.120071073373159

Epoch: 5| Step: 6
Training loss: 2.913735866546631
Validation loss: 2.109565774599711

Epoch: 5| Step: 7
Training loss: 1.8365951776504517
Validation loss: 2.1109168430169425

Epoch: 5| Step: 8
Training loss: 1.9837076663970947
Validation loss: 2.096203406651815

Epoch: 5| Step: 9
Training loss: 2.4636688232421875
Validation loss: 2.1243093013763428

Epoch: 5| Step: 10
Training loss: 2.2828266620635986
Validation loss: 2.1452298363049827

Epoch: 5| Step: 11
Training loss: 2.227890968322754
Validation loss: 2.1371672997872033

Epoch: 14| Step: 0
Training loss: 2.5735909938812256
Validation loss: 2.139193132519722

Epoch: 5| Step: 1
Training loss: 2.404475212097168
Validation loss: 2.1429600914319358

Epoch: 5| Step: 2
Training loss: 2.226196765899658
Validation loss: 2.1706443578004837

Epoch: 5| Step: 3
Training loss: 2.352959156036377
Validation loss: 2.1383468260367713

Epoch: 5| Step: 4
Training loss: 2.346742630004883
Validation loss: 2.1910380770762763

Epoch: 5| Step: 5
Training loss: 1.9453976154327393
Validation loss: 2.1648998856544495

Epoch: 5| Step: 6
Training loss: 2.6374096870422363
Validation loss: 2.1565927118062973

Epoch: 5| Step: 7
Training loss: 1.7797441482543945
Validation loss: 2.165239284435908

Epoch: 5| Step: 8
Training loss: 1.759399652481079
Validation loss: 2.143228148420652

Epoch: 5| Step: 9
Training loss: 2.053593873977661
Validation loss: 2.1070850590864816

Epoch: 5| Step: 10
Training loss: 2.054192543029785
Validation loss: 2.1131621599197388

Epoch: 5| Step: 11
Training loss: 1.805312991142273
Validation loss: 2.0908302863438926

Epoch: 15| Step: 0
Training loss: 1.6979154348373413
Validation loss: 2.1085379471381507

Epoch: 5| Step: 1
Training loss: 1.9087787866592407
Validation loss: 2.1011758744716644

Epoch: 5| Step: 2
Training loss: 2.056671619415283
Validation loss: 2.10579422612985

Epoch: 5| Step: 3
Training loss: 2.0800724029541016
Validation loss: 2.0618315587441125

Epoch: 5| Step: 4
Training loss: 2.2368640899658203
Validation loss: 2.0656008472045264

Epoch: 5| Step: 5
Training loss: 2.350113868713379
Validation loss: 2.1079242825508118

Epoch: 5| Step: 6
Training loss: 2.642714023590088
Validation loss: 2.1004444460074105

Epoch: 5| Step: 7
Training loss: 1.9506572484970093
Validation loss: 2.105272024869919

Epoch: 5| Step: 8
Training loss: 2.467937707901001
Validation loss: 2.114514241615931

Epoch: 5| Step: 9
Training loss: 2.3746771812438965
Validation loss: 2.145638177792231

Epoch: 5| Step: 10
Training loss: 1.9839988946914673
Validation loss: 2.094820807377497

Epoch: 5| Step: 11
Training loss: 2.151538372039795
Validation loss: 2.099039077758789

Epoch: 16| Step: 0
Training loss: 1.473776936531067
Validation loss: 2.078559473156929

Epoch: 5| Step: 1
Training loss: 1.5588876008987427
Validation loss: 2.0863445103168488

Epoch: 5| Step: 2
Training loss: 2.7094292640686035
Validation loss: 2.071426267425219

Epoch: 5| Step: 3
Training loss: 1.661462426185608
Validation loss: 2.0984546840190887

Epoch: 5| Step: 4
Training loss: 2.231698513031006
Validation loss: 2.134272734324137

Epoch: 5| Step: 5
Training loss: 2.452619791030884
Validation loss: 2.122962007919947

Epoch: 5| Step: 6
Training loss: 2.7756457328796387
Validation loss: 2.179251382748286

Epoch: 5| Step: 7
Training loss: 2.699767589569092
Validation loss: 2.1304622987906137

Epoch: 5| Step: 8
Training loss: 2.525000810623169
Validation loss: 2.1664588302373886

Epoch: 5| Step: 9
Training loss: 1.703789472579956
Validation loss: 2.1240656475226083

Epoch: 5| Step: 10
Training loss: 2.158311128616333
Validation loss: 2.125669946273168

Epoch: 5| Step: 11
Training loss: 1.8616589307785034
Validation loss: 2.105067566037178

Epoch: 17| Step: 0
Training loss: 2.6769676208496094
Validation loss: 2.1077091842889786

Epoch: 5| Step: 1
Training loss: 1.9825607538223267
Validation loss: 2.0791055262088776

Epoch: 5| Step: 2
Training loss: 2.230193614959717
Validation loss: 2.0628661264975867

Epoch: 5| Step: 3
Training loss: 2.2119839191436768
Validation loss: 2.0765846023956933

Epoch: 5| Step: 4
Training loss: 1.800665259361267
Validation loss: 2.1061430474122367

Epoch: 5| Step: 5
Training loss: 1.896731972694397
Validation loss: 2.094172497590383

Epoch: 5| Step: 6
Training loss: 1.6709086894989014
Validation loss: 2.066098675131798

Epoch: 5| Step: 7
Training loss: 1.7985798120498657
Validation loss: 2.10441584388415

Epoch: 5| Step: 8
Training loss: 2.6423115730285645
Validation loss: 2.1180857568979263

Epoch: 5| Step: 9
Training loss: 2.369530200958252
Validation loss: 2.1004293660322824

Epoch: 5| Step: 10
Training loss: 2.0092380046844482
Validation loss: 2.062338506182035

Epoch: 5| Step: 11
Training loss: 3.9071435928344727
Validation loss: 2.1021883686383567

Epoch: 18| Step: 0
Training loss: 1.9547637701034546
Validation loss: 2.0597287813822427

Epoch: 5| Step: 1
Training loss: 2.355032205581665
Validation loss: 2.067692369222641

Epoch: 5| Step: 2
Training loss: 2.0115389823913574
Validation loss: 2.041056364774704

Epoch: 5| Step: 3
Training loss: 1.8336900472640991
Validation loss: 2.1082181533177695

Epoch: 5| Step: 4
Training loss: 1.8129945993423462
Validation loss: 2.079836000998815

Epoch: 5| Step: 5
Training loss: 2.2006540298461914
Validation loss: 2.093764215707779

Epoch: 5| Step: 6
Training loss: 2.1083385944366455
Validation loss: 2.067580675085386

Epoch: 5| Step: 7
Training loss: 2.4566168785095215
Validation loss: 2.07408677538236

Epoch: 5| Step: 8
Training loss: 1.6327180862426758
Validation loss: 2.0547680159409842

Epoch: 5| Step: 9
Training loss: 1.9832464456558228
Validation loss: 2.0931339065233865

Epoch: 5| Step: 10
Training loss: 2.2744789123535156
Validation loss: 2.070517137646675

Epoch: 5| Step: 11
Training loss: 3.4734292030334473
Validation loss: 2.0717999239762626

Epoch: 19| Step: 0
Training loss: 2.129065990447998
Validation loss: 2.0447160800298056

Epoch: 5| Step: 1
Training loss: 2.530954122543335
Validation loss: 2.0760578413804374

Epoch: 5| Step: 2
Training loss: 2.246884822845459
Validation loss: 2.0682544708251953

Epoch: 5| Step: 3
Training loss: 1.612213134765625
Validation loss: 2.0858131796121597

Epoch: 5| Step: 4
Training loss: 2.116258382797241
Validation loss: 2.0830904642740884

Epoch: 5| Step: 5
Training loss: 1.5986156463623047
Validation loss: 2.0506455103556314

Epoch: 5| Step: 6
Training loss: 1.8182668685913086
Validation loss: 2.0462641219298043

Epoch: 5| Step: 7
Training loss: 2.1730563640594482
Validation loss: 2.0719632357358932

Epoch: 5| Step: 8
Training loss: 2.453862428665161
Validation loss: 2.0646342039108276

Epoch: 5| Step: 9
Training loss: 2.7260918617248535
Validation loss: 2.081717699766159

Epoch: 5| Step: 10
Training loss: 2.0170884132385254
Validation loss: 2.0969591587781906

Epoch: 5| Step: 11
Training loss: 0.7010698318481445
Validation loss: 2.0445157885551453

Epoch: 20| Step: 0
Training loss: 2.015585422515869
Validation loss: 2.103861153125763

Epoch: 5| Step: 1
Training loss: 2.1557953357696533
Validation loss: 2.0820319453875222

Epoch: 5| Step: 2
Training loss: 2.358912706375122
Validation loss: 2.053437406818072

Epoch: 5| Step: 3
Training loss: 2.1979846954345703
Validation loss: 2.0756329049666724

Epoch: 5| Step: 4
Training loss: 2.0457470417022705
Validation loss: 2.0570646872123084

Epoch: 5| Step: 5
Training loss: 2.2303733825683594
Validation loss: 2.071669340133667

Epoch: 5| Step: 6
Training loss: 2.2153260707855225
Validation loss: 2.020792712767919

Epoch: 5| Step: 7
Training loss: 2.6212620735168457
Validation loss: 2.051981752117475

Epoch: 5| Step: 8
Training loss: 1.8882194757461548
Validation loss: 2.039854278167089

Epoch: 5| Step: 9
Training loss: 1.6799862384796143
Validation loss: 2.0525846978028617

Epoch: 5| Step: 10
Training loss: 1.808193564414978
Validation loss: 2.01794026295344

Epoch: 5| Step: 11
Training loss: 0.8299302458763123
Validation loss: 2.015718460083008

Epoch: 21| Step: 0
Training loss: 1.755603551864624
Validation loss: 2.0497555484374366

Epoch: 5| Step: 1
Training loss: 2.0860226154327393
Validation loss: 2.0510418911774955

Epoch: 5| Step: 2
Training loss: 2.472461462020874
Validation loss: 2.027529070774714

Epoch: 5| Step: 3
Training loss: 2.506349802017212
Validation loss: 2.054471398393313

Epoch: 5| Step: 4
Training loss: 1.809827446937561
Validation loss: 2.0368679761886597

Epoch: 5| Step: 5
Training loss: 1.6273199319839478
Validation loss: 2.0331899424393973

Epoch: 5| Step: 6
Training loss: 2.060896396636963
Validation loss: 2.0741010904312134

Epoch: 5| Step: 7
Training loss: 2.0587923526763916
Validation loss: 2.0614801148573556

Epoch: 5| Step: 8
Training loss: 2.0261948108673096
Validation loss: 2.041376401980718

Epoch: 5| Step: 9
Training loss: 2.6205217838287354
Validation loss: 2.0306931336720786

Epoch: 5| Step: 10
Training loss: 1.9797226190567017
Validation loss: 2.055982917547226

Epoch: 5| Step: 11
Training loss: 1.0373947620391846
Validation loss: 2.0486236065626144

Epoch: 22| Step: 0
Training loss: 2.0415194034576416
Validation loss: 2.043562447031339

Epoch: 5| Step: 1
Training loss: 1.9274089336395264
Validation loss: 2.0424791822830834

Epoch: 5| Step: 2
Training loss: 2.4837265014648438
Validation loss: 2.0286594331264496

Epoch: 5| Step: 3
Training loss: 2.0035102367401123
Validation loss: 2.0108490735292435

Epoch: 5| Step: 4
Training loss: 1.851983666419983
Validation loss: 2.0394646525382996

Epoch: 5| Step: 5
Training loss: 2.205657720565796
Validation loss: 2.015616074204445

Epoch: 5| Step: 6
Training loss: 1.8532154560089111
Validation loss: 2.066546469926834

Epoch: 5| Step: 7
Training loss: 2.0494871139526367
Validation loss: 2.024665633837382

Epoch: 5| Step: 8
Training loss: 2.588317394256592
Validation loss: 2.04441799223423

Epoch: 5| Step: 9
Training loss: 2.4767587184906006
Validation loss: 2.0462110141913095

Epoch: 5| Step: 10
Training loss: 1.7831493616104126
Validation loss: 2.0655321180820465

Epoch: 5| Step: 11
Training loss: 1.5305205583572388
Validation loss: 2.0546452005704245

Epoch: 23| Step: 0
Training loss: 1.359296202659607
Validation loss: 2.0104930301507316

Epoch: 5| Step: 1
Training loss: 2.280998468399048
Validation loss: 2.0644572327534356

Epoch: 5| Step: 2
Training loss: 2.175114870071411
Validation loss: 2.0490201065937677

Epoch: 5| Step: 3
Training loss: 1.5509065389633179
Validation loss: 2.0416093468666077

Epoch: 5| Step: 4
Training loss: 2.0119946002960205
Validation loss: 2.039596368869146

Epoch: 5| Step: 5
Training loss: 2.2280101776123047
Validation loss: 2.085992599527041

Epoch: 5| Step: 6
Training loss: 1.820671796798706
Validation loss: 2.027323062221209

Epoch: 5| Step: 7
Training loss: 2.173309564590454
Validation loss: 2.044197921951612

Epoch: 5| Step: 8
Training loss: 2.0781829357147217
Validation loss: 2.030026132861773

Epoch: 5| Step: 9
Training loss: 2.663811683654785
Validation loss: 2.048409635821978

Epoch: 5| Step: 10
Training loss: 2.2192068099975586
Validation loss: 2.0186982651551566

Epoch: 5| Step: 11
Training loss: 1.2531788349151611
Validation loss: 2.0603365500768027

Epoch: 24| Step: 0
Training loss: 1.5104900598526
Validation loss: 2.0176036010185876

Epoch: 5| Step: 1
Training loss: 1.7160351276397705
Validation loss: 2.0315228601296744

Epoch: 5| Step: 2
Training loss: 2.150905132293701
Validation loss: 2.0538969933986664

Epoch: 5| Step: 3
Training loss: 1.3414820432662964
Validation loss: 2.058740278085073

Epoch: 5| Step: 4
Training loss: 2.58420991897583
Validation loss: 2.0502231071392694

Epoch: 5| Step: 5
Training loss: 2.425201654434204
Validation loss: 2.0906092325846353

Epoch: 5| Step: 6
Training loss: 2.1713178157806396
Validation loss: 2.0865898032983146

Epoch: 5| Step: 7
Training loss: 2.3250625133514404
Validation loss: 2.102635453144709

Epoch: 5| Step: 8
Training loss: 2.1449341773986816
Validation loss: 2.0548586398363113

Epoch: 5| Step: 9
Training loss: 2.253364324569702
Validation loss: 2.0465694069862366

Epoch: 5| Step: 10
Training loss: 2.3903770446777344
Validation loss: 2.0235154926776886

Epoch: 5| Step: 11
Training loss: 3.318030834197998
Validation loss: 2.0534347842137017

Epoch: 25| Step: 0
Training loss: 2.246584892272949
Validation loss: 2.060248613357544

Epoch: 5| Step: 1
Training loss: 2.3116908073425293
Validation loss: 2.0327967355648675

Epoch: 5| Step: 2
Training loss: 2.2114217281341553
Validation loss: 2.1053927143414817

Epoch: 5| Step: 3
Training loss: 1.772559404373169
Validation loss: 2.0732676635185876

Epoch: 5| Step: 4
Training loss: 1.6372216939926147
Validation loss: 2.0703631937503815

Epoch: 5| Step: 5
Training loss: 2.2948877811431885
Validation loss: 2.0976798286040625

Epoch: 5| Step: 6
Training loss: 1.830255150794983
Validation loss: 2.0988244464000068

Epoch: 5| Step: 7
Training loss: 1.754137635231018
Validation loss: 2.065104047457377

Epoch: 5| Step: 8
Training loss: 2.2377986907958984
Validation loss: 2.0361505448818207

Epoch: 5| Step: 9
Training loss: 2.3220767974853516
Validation loss: 2.0525238464275994

Epoch: 5| Step: 10
Training loss: 2.1548001766204834
Validation loss: 2.041305656234423

Epoch: 5| Step: 11
Training loss: 3.3553707599639893
Validation loss: 2.0612010111411414

Epoch: 26| Step: 0
Training loss: 1.8464736938476562
Validation loss: 2.0403337130943933

Epoch: 5| Step: 1
Training loss: 2.0960936546325684
Validation loss: 2.0589571992556253

Epoch: 5| Step: 2
Training loss: 2.05936861038208
Validation loss: 2.0818702777226767

Epoch: 5| Step: 3
Training loss: 2.1902880668640137
Validation loss: 2.053365185856819

Epoch: 5| Step: 4
Training loss: 2.4541494846343994
Validation loss: 2.037367800871531

Epoch: 5| Step: 5
Training loss: 1.601332426071167
Validation loss: 2.036177391807238

Epoch: 5| Step: 6
Training loss: 2.276243209838867
Validation loss: 2.065241793791453

Epoch: 5| Step: 7
Training loss: 2.0708255767822266
Validation loss: 2.082650492588679

Epoch: 5| Step: 8
Training loss: 1.7454954385757446
Validation loss: 2.0308583080768585

Epoch: 5| Step: 9
Training loss: 2.0834403038024902
Validation loss: 1.9947968969742458

Epoch: 5| Step: 10
Training loss: 2.15270733833313
Validation loss: 2.073006878296534

Epoch: 5| Step: 11
Training loss: 2.180799961090088
Validation loss: 2.0346820702155433

Epoch: 27| Step: 0
Training loss: 1.9454872608184814
Validation loss: 2.0128191858530045

Epoch: 5| Step: 1
Training loss: 1.823148488998413
Validation loss: 2.039041295647621

Epoch: 5| Step: 2
Training loss: 1.9779945611953735
Validation loss: 2.049255629380544

Epoch: 5| Step: 3
Training loss: 2.1357593536376953
Validation loss: 2.0836067150036492

Epoch: 5| Step: 4
Training loss: 2.72041654586792
Validation loss: 2.00015626847744

Epoch: 5| Step: 5
Training loss: 1.638939619064331
Validation loss: 2.062873512506485

Epoch: 5| Step: 6
Training loss: 1.4286688566207886
Validation loss: 2.0174252738555274

Epoch: 5| Step: 7
Training loss: 2.607273578643799
Validation loss: 2.0830324540535607

Epoch: 5| Step: 8
Training loss: 2.1042048931121826
Validation loss: 2.0545680026213327

Epoch: 5| Step: 9
Training loss: 1.9212195873260498
Validation loss: 2.070598522822062

Epoch: 5| Step: 10
Training loss: 2.6324286460876465
Validation loss: 2.0658611953258514

Epoch: 5| Step: 11
Training loss: 1.412842035293579
Validation loss: 2.0427270332972207

Epoch: 28| Step: 0
Training loss: 1.674149513244629
Validation loss: 2.0309333304564157

Epoch: 5| Step: 1
Training loss: 2.412579298019409
Validation loss: 2.0430174668629966

Epoch: 5| Step: 2
Training loss: 1.5283746719360352
Validation loss: 2.04548508922259

Epoch: 5| Step: 3
Training loss: 2.7178587913513184
Validation loss: 2.0328152924776077

Epoch: 5| Step: 4
Training loss: 2.59824800491333
Validation loss: 2.0618296563625336

Epoch: 5| Step: 5
Training loss: 1.5989081859588623
Validation loss: 2.0338179618120193

Epoch: 5| Step: 6
Training loss: 1.7452472448349
Validation loss: 2.0745820701122284

Epoch: 5| Step: 7
Training loss: 2.1464619636535645
Validation loss: 2.084365094701449

Epoch: 5| Step: 8
Training loss: 1.9892966747283936
Validation loss: 2.039786070585251

Epoch: 5| Step: 9
Training loss: 2.2279551029205322
Validation loss: 2.0786179850498834

Epoch: 5| Step: 10
Training loss: 1.9303245544433594
Validation loss: 2.083436533808708

Epoch: 5| Step: 11
Training loss: 2.354104995727539
Validation loss: 2.018759856621424

Epoch: 29| Step: 0
Training loss: 1.8361408710479736
Validation loss: 2.0326330959796906

Epoch: 5| Step: 1
Training loss: 2.068570852279663
Validation loss: 2.0675374219814935

Epoch: 5| Step: 2
Training loss: 2.3184492588043213
Validation loss: 2.0573201129833856

Epoch: 5| Step: 3
Training loss: 1.4249088764190674
Validation loss: 2.009021153052648

Epoch: 5| Step: 4
Training loss: 2.295821189880371
Validation loss: 2.0477234572172165

Epoch: 5| Step: 5
Training loss: 2.448493242263794
Validation loss: 2.0534127602974572

Epoch: 5| Step: 6
Training loss: 1.980952262878418
Validation loss: 2.0631210654973984

Epoch: 5| Step: 7
Training loss: 1.977280855178833
Validation loss: 2.0642466843128204

Epoch: 5| Step: 8
Training loss: 1.89374577999115
Validation loss: 2.06988758345445

Epoch: 5| Step: 9
Training loss: 2.134335994720459
Validation loss: 2.0424052675565085

Epoch: 5| Step: 10
Training loss: 2.180872917175293
Validation loss: 2.0236217975616455

Epoch: 5| Step: 11
Training loss: 0.8610200881958008
Validation loss: 2.0879645397265754

Epoch: 30| Step: 0
Training loss: 2.0883948802948
Validation loss: 2.0301487346490226

Epoch: 5| Step: 1
Training loss: 2.3900229930877686
Validation loss: 2.061849594116211

Epoch: 5| Step: 2
Training loss: 1.903246283531189
Validation loss: 2.061962768435478

Epoch: 5| Step: 3
Training loss: 2.0439085960388184
Validation loss: 2.06951567530632

Epoch: 5| Step: 4
Training loss: 1.9954487085342407
Validation loss: 2.071192041039467

Epoch: 5| Step: 5
Training loss: 1.7808414697647095
Validation loss: 2.078460971514384

Epoch: 5| Step: 6
Training loss: 1.921147108078003
Validation loss: 2.0860144893328347

Epoch: 5| Step: 7
Training loss: 2.262655019760132
Validation loss: 2.114764158924421

Epoch: 5| Step: 8
Training loss: 2.354321241378784
Validation loss: 2.1187395453453064

Epoch: 5| Step: 9
Training loss: 2.106549024581909
Validation loss: 2.0404176910718284

Epoch: 5| Step: 10
Training loss: 1.8695513010025024
Validation loss: 2.069991037249565

Epoch: 5| Step: 11
Training loss: 1.0852537155151367
Validation loss: 2.061603511373202

Epoch: 31| Step: 0
Training loss: 2.3173301219940186
Validation loss: 2.0491362512111664

Epoch: 5| Step: 1
Training loss: 2.629814624786377
Validation loss: 2.0172792424758277

Epoch: 5| Step: 2
Training loss: 2.543588161468506
Validation loss: 2.027785067756971

Epoch: 5| Step: 3
Training loss: 2.009915590286255
Validation loss: 2.050722454984983

Epoch: 5| Step: 4
Training loss: 1.9008338451385498
Validation loss: 2.065909375747045

Epoch: 5| Step: 5
Training loss: 1.900014877319336
Validation loss: 2.0421983947356543

Epoch: 5| Step: 6
Training loss: 2.113800525665283
Validation loss: 2.0546620885531106

Epoch: 5| Step: 7
Training loss: 1.1352742910385132
Validation loss: 2.0272201150655746

Epoch: 5| Step: 8
Training loss: 1.5178077220916748
Validation loss: 2.0371457835038504

Epoch: 5| Step: 9
Training loss: 1.7269504070281982
Validation loss: 2.050848603248596

Epoch: 5| Step: 10
Training loss: 2.021181344985962
Validation loss: 2.0625333935022354

Epoch: 5| Step: 11
Training loss: 1.715099811553955
Validation loss: 2.0647142032782235

Epoch: 32| Step: 0
Training loss: 2.2073731422424316
Validation loss: 2.067534923553467

Epoch: 5| Step: 1
Training loss: 1.7222576141357422
Validation loss: 2.0296139121055603

Epoch: 5| Step: 2
Training loss: 1.8826885223388672
Validation loss: 2.0390469829241433

Epoch: 5| Step: 3
Training loss: 1.737187385559082
Validation loss: 2.0584258139133453

Epoch: 5| Step: 4
Training loss: 1.4966849088668823
Validation loss: 2.063841929038366

Epoch: 5| Step: 5
Training loss: 2.2730724811553955
Validation loss: 2.0490510712067285

Epoch: 5| Step: 6
Training loss: 1.9554767608642578
Validation loss: 2.0511214584112167

Epoch: 5| Step: 7
Training loss: 2.7031044960021973
Validation loss: 2.056441759069761

Epoch: 5| Step: 8
Training loss: 1.8233438730239868
Validation loss: 2.0614389528830848

Epoch: 5| Step: 9
Training loss: 2.0595650672912598
Validation loss: 2.0771837731202445

Epoch: 5| Step: 10
Training loss: 2.0958569049835205
Validation loss: 2.035423199335734

Epoch: 5| Step: 11
Training loss: 1.7808314561843872
Validation loss: 2.054104899366697

Epoch: 33| Step: 0
Training loss: 2.1554949283599854
Validation loss: 2.0332575937112174

Epoch: 5| Step: 1
Training loss: 2.134997844696045
Validation loss: 2.0851232409477234

Epoch: 5| Step: 2
Training loss: 2.0446057319641113
Validation loss: 2.028819595774015

Epoch: 5| Step: 3
Training loss: 2.7079875469207764
Validation loss: 2.0648488998413086

Epoch: 5| Step: 4
Training loss: 2.2626733779907227
Validation loss: 2.009299710392952

Epoch: 5| Step: 5
Training loss: 1.497134804725647
Validation loss: 1.9999846617380779

Epoch: 5| Step: 6
Training loss: 1.8719981908798218
Validation loss: 2.043404142061869

Epoch: 5| Step: 7
Training loss: 2.0014595985412598
Validation loss: 2.0382387737433114

Epoch: 5| Step: 8
Training loss: 2.013469696044922
Validation loss: 2.0493677208820977

Epoch: 5| Step: 9
Training loss: 1.3651010990142822
Validation loss: 2.0059594760338464

Epoch: 5| Step: 10
Training loss: 1.984281301498413
Validation loss: 2.063888341188431

Epoch: 5| Step: 11
Training loss: 2.8068950176239014
Validation loss: 2.0402746150890985

Epoch: 34| Step: 0
Training loss: 1.8888700008392334
Validation loss: 2.0524197667837143

Epoch: 5| Step: 1
Training loss: 2.074429512023926
Validation loss: 2.04922778904438

Epoch: 5| Step: 2
Training loss: 2.3677620887756348
Validation loss: 2.0335159649451575

Epoch: 5| Step: 3
Training loss: 2.1934101581573486
Validation loss: 2.090028499563535

Epoch: 5| Step: 4
Training loss: 2.0204885005950928
Validation loss: 2.098863646388054

Epoch: 5| Step: 5
Training loss: 2.1182496547698975
Validation loss: 2.124212165673574

Epoch: 5| Step: 6
Training loss: 1.7298208475112915
Validation loss: 2.066364660859108

Epoch: 5| Step: 7
Training loss: 2.295621156692505
Validation loss: 2.112591336170832

Epoch: 5| Step: 8
Training loss: 1.8993442058563232
Validation loss: 2.091687629620234

Epoch: 5| Step: 9
Training loss: 1.6403329372406006
Validation loss: 2.093243792653084

Epoch: 5| Step: 10
Training loss: 2.3954038619995117
Validation loss: 2.0451536426941552

Epoch: 5| Step: 11
Training loss: 1.6863300800323486
Validation loss: 2.0515825549761453

Epoch: 35| Step: 0
Training loss: 1.5997045040130615
Validation loss: 2.0862344801425934

Epoch: 5| Step: 1
Training loss: 2.2149853706359863
Validation loss: 2.127522553006808

Epoch: 5| Step: 2
Training loss: 1.8328701257705688
Validation loss: 2.128606761495272

Epoch: 5| Step: 3
Training loss: 1.9229837656021118
Validation loss: 2.1117682605981827

Epoch: 5| Step: 4
Training loss: 2.7104790210723877
Validation loss: 2.1041773855686188

Epoch: 5| Step: 5
Training loss: 2.0197396278381348
Validation loss: 2.103504786888758

Epoch: 5| Step: 6
Training loss: 1.5061103105545044
Validation loss: 2.1069990545511246

Epoch: 5| Step: 7
Training loss: 2.3477389812469482
Validation loss: 2.129658361275991

Epoch: 5| Step: 8
Training loss: 1.8010272979736328
Validation loss: 2.0661285320917764

Epoch: 5| Step: 9
Training loss: 1.92949640750885
Validation loss: 2.0599471728006997

Epoch: 5| Step: 10
Training loss: 2.139586925506592
Validation loss: 2.050026367108027

Epoch: 5| Step: 11
Training loss: 1.9238955974578857
Validation loss: 2.045125881830851

Epoch: 36| Step: 0
Training loss: 2.1323676109313965
Validation loss: 2.0921131720145545

Epoch: 5| Step: 1
Training loss: 2.0473380088806152
Validation loss: 2.0853892316420874

Epoch: 5| Step: 2
Training loss: 2.5157670974731445
Validation loss: 2.0495312561591468

Epoch: 5| Step: 3
Training loss: 1.5078223943710327
Validation loss: 2.0785631438096366

Epoch: 5| Step: 4
Training loss: 2.624009370803833
Validation loss: 2.0435273895661035

Epoch: 5| Step: 5
Training loss: 2.228987455368042
Validation loss: 2.064334069689115

Epoch: 5| Step: 6
Training loss: 1.820810079574585
Validation loss: 2.0256438752015433

Epoch: 5| Step: 7
Training loss: 1.2480531930923462
Validation loss: 2.054206202427546

Epoch: 5| Step: 8
Training loss: 1.7831144332885742
Validation loss: 2.094714899857839

Epoch: 5| Step: 9
Training loss: 2.028149127960205
Validation loss: 2.109342704216639

Epoch: 5| Step: 10
Training loss: 2.3120455741882324
Validation loss: 2.135583539803823

Epoch: 5| Step: 11
Training loss: 2.105491876602173
Validation loss: 2.0756442745526633

Epoch: 37| Step: 0
Training loss: 1.8494179248809814
Validation loss: 2.0370646019776664

Epoch: 5| Step: 1
Training loss: 2.3836236000061035
Validation loss: 2.04362960656484

Epoch: 5| Step: 2
Training loss: 2.525416851043701
Validation loss: 2.0558760662873587

Epoch: 5| Step: 3
Training loss: 2.196627140045166
Validation loss: 2.0391355752944946

Epoch: 5| Step: 4
Training loss: 2.1609246730804443
Validation loss: 2.0248171339432397

Epoch: 5| Step: 5
Training loss: 1.8359348773956299
Validation loss: 2.061004007856051

Epoch: 5| Step: 6
Training loss: 1.9947789907455444
Validation loss: 2.06148553888003

Epoch: 5| Step: 7
Training loss: 1.896893858909607
Validation loss: 2.0540067156155906

Epoch: 5| Step: 8
Training loss: 1.372369647026062
Validation loss: 2.087883790334066

Epoch: 5| Step: 9
Training loss: 2.0156242847442627
Validation loss: 2.039183631539345

Epoch: 5| Step: 10
Training loss: 1.9130970239639282
Validation loss: 2.0827178359031677

Epoch: 5| Step: 11
Training loss: 0.6001862287521362
Validation loss: 2.0170997629563012

Epoch: 38| Step: 0
Training loss: 0.9431778192520142
Validation loss: 2.032958452900251

Epoch: 5| Step: 1
Training loss: 1.8966633081436157
Validation loss: 2.044673110047976

Epoch: 5| Step: 2
Training loss: 2.542526960372925
Validation loss: 2.0650668938954673

Epoch: 5| Step: 3
Training loss: 2.052478313446045
Validation loss: 2.0400245736042657

Epoch: 5| Step: 4
Training loss: 1.9330638647079468
Validation loss: 2.047031437357267

Epoch: 5| Step: 5
Training loss: 1.4375747442245483
Validation loss: 2.0757474402586618

Epoch: 5| Step: 6
Training loss: 1.7479503154754639
Validation loss: 2.0737098306417465

Epoch: 5| Step: 7
Training loss: 1.8361480236053467
Validation loss: 2.0114742616812387

Epoch: 5| Step: 8
Training loss: 2.1694822311401367
Validation loss: 2.054875522851944

Epoch: 5| Step: 9
Training loss: 2.3220760822296143
Validation loss: 2.0991225987672806

Epoch: 5| Step: 10
Training loss: 2.3718814849853516
Validation loss: 2.0425169865290322

Epoch: 5| Step: 11
Training loss: 3.602081298828125
Validation loss: 2.045287032922109

Epoch: 39| Step: 0
Training loss: 1.8659851551055908
Validation loss: 2.0904843360185623

Epoch: 5| Step: 1
Training loss: 1.697361707687378
Validation loss: 2.1099558075269065

Epoch: 5| Step: 2
Training loss: 1.533235788345337
Validation loss: 2.0683507472276688

Epoch: 5| Step: 3
Training loss: 2.0802085399627686
Validation loss: 2.0610149651765823

Epoch: 5| Step: 4
Training loss: 2.561077117919922
Validation loss: 2.045485203464826

Epoch: 5| Step: 5
Training loss: 2.0682644844055176
Validation loss: 2.1094603141148887

Epoch: 5| Step: 6
Training loss: 1.7018400430679321
Validation loss: 2.0827618638674417

Epoch: 5| Step: 7
Training loss: 1.7811540365219116
Validation loss: 2.069592927893003

Epoch: 5| Step: 8
Training loss: 2.0726780891418457
Validation loss: 2.084785223007202

Epoch: 5| Step: 9
Training loss: 2.113804340362549
Validation loss: 2.103272875150045

Epoch: 5| Step: 10
Training loss: 2.287379264831543
Validation loss: 2.067624017596245

Epoch: 5| Step: 11
Training loss: 2.2130446434020996
Validation loss: 2.1003408332665763

Epoch: 40| Step: 0
Training loss: 1.7015907764434814
Validation loss: 2.067567224303881

Epoch: 5| Step: 1
Training loss: 2.669978618621826
Validation loss: 2.0527843286593757

Epoch: 5| Step: 2
Training loss: 1.9262893199920654
Validation loss: 2.070505599180857

Epoch: 5| Step: 3
Training loss: 1.5583562850952148
Validation loss: 2.0861854553222656

Epoch: 5| Step: 4
Training loss: 1.7064626216888428
Validation loss: 2.1369792173306146

Epoch: 5| Step: 5
Training loss: 2.4898104667663574
Validation loss: 2.0800983210404715

Epoch: 5| Step: 6
Training loss: 1.510089635848999
Validation loss: 2.069771279891332

Epoch: 5| Step: 7
Training loss: 1.9315770864486694
Validation loss: 2.0344506601492562

Epoch: 5| Step: 8
Training loss: 1.3486838340759277
Validation loss: 2.0972516189018884

Epoch: 5| Step: 9
Training loss: 2.5324904918670654
Validation loss: 2.089671259125074

Epoch: 5| Step: 10
Training loss: 2.281264066696167
Validation loss: 2.1243030776580176

Epoch: 5| Step: 11
Training loss: 2.3237547874450684
Validation loss: 2.1076482832431793

Epoch: 41| Step: 0
Training loss: 1.4683736562728882
Validation loss: 2.0976065397262573

Epoch: 5| Step: 1
Training loss: 2.4090678691864014
Validation loss: 2.123753090699514

Epoch: 5| Step: 2
Training loss: 2.341292142868042
Validation loss: 2.0551843096812568

Epoch: 5| Step: 3
Training loss: 2.0309340953826904
Validation loss: 2.0921051700909934

Epoch: 5| Step: 4
Training loss: 1.6527923345565796
Validation loss: 2.058925782640775

Epoch: 5| Step: 5
Training loss: 2.1121935844421387
Validation loss: 2.097247749567032

Epoch: 5| Step: 6
Training loss: 1.379804253578186
Validation loss: 2.0922034680843353

Epoch: 5| Step: 7
Training loss: 2.1076934337615967
Validation loss: 2.0497211863597236

Epoch: 5| Step: 8
Training loss: 1.8602653741836548
Validation loss: 2.034366190433502

Epoch: 5| Step: 9
Training loss: 1.9563249349594116
Validation loss: 2.1041296223799386

Epoch: 5| Step: 10
Training loss: 2.3585426807403564
Validation loss: 2.08768492937088

Epoch: 5| Step: 11
Training loss: 3.093916654586792
Validation loss: 2.0251248478889465

Epoch: 42| Step: 0
Training loss: 1.911090612411499
Validation loss: 2.1199760486682258

Epoch: 5| Step: 1
Training loss: 1.795690894126892
Validation loss: 2.088971267143885

Epoch: 5| Step: 2
Training loss: 2.079692840576172
Validation loss: 2.1204868157704673

Epoch: 5| Step: 3
Training loss: 2.3146491050720215
Validation loss: 2.118564779559771

Epoch: 5| Step: 4
Training loss: 1.990612268447876
Validation loss: 2.134639581044515

Epoch: 5| Step: 5
Training loss: 2.159554958343506
Validation loss: 2.1731022149324417

Epoch: 5| Step: 6
Training loss: 1.7130781412124634
Validation loss: 2.053113450606664

Epoch: 5| Step: 7
Training loss: 2.276752233505249
Validation loss: 2.063985745112101

Epoch: 5| Step: 8
Training loss: 1.668180227279663
Validation loss: 2.0748422890901566

Epoch: 5| Step: 9
Training loss: 1.9075450897216797
Validation loss: 2.067245547970136

Epoch: 5| Step: 10
Training loss: 1.792676568031311
Validation loss: 2.060618966817856

Epoch: 5| Step: 11
Training loss: 1.697365641593933
Validation loss: 2.0958008418480554

Epoch: 43| Step: 0
Training loss: 2.3841335773468018
Validation loss: 2.0418832302093506

Epoch: 5| Step: 1
Training loss: 2.375710964202881
Validation loss: 2.0508614033460617

Epoch: 5| Step: 2
Training loss: 1.8239418268203735
Validation loss: 2.032201111316681

Epoch: 5| Step: 3
Training loss: 2.060577869415283
Validation loss: 2.0532606343428292

Epoch: 5| Step: 4
Training loss: 1.4950672388076782
Validation loss: 2.021735663215319

Epoch: 5| Step: 5
Training loss: 1.5357340574264526
Validation loss: 2.0567402690649033

Epoch: 5| Step: 6
Training loss: 1.7320365905761719
Validation loss: 2.028524378935496

Epoch: 5| Step: 7
Training loss: 2.078503370285034
Validation loss: 2.110664203763008

Epoch: 5| Step: 8
Training loss: 1.9598186016082764
Validation loss: 2.0738876909017563

Epoch: 5| Step: 9
Training loss: 2.344809055328369
Validation loss: 2.1191621919473014

Epoch: 5| Step: 10
Training loss: 1.740867257118225
Validation loss: 2.065733219186465

Epoch: 5| Step: 11
Training loss: 1.8878462314605713
Validation loss: 2.1213934123516083

Epoch: 44| Step: 0
Training loss: 2.3985495567321777
Validation loss: 2.107126305500666

Epoch: 5| Step: 1
Training loss: 1.8483108282089233
Validation loss: 2.1206177870432534

Epoch: 5| Step: 2
Training loss: 1.8050801753997803
Validation loss: 2.1389190206925073

Epoch: 5| Step: 3
Training loss: 1.6693134307861328
Validation loss: 2.0775505105654397

Epoch: 5| Step: 4
Training loss: 2.1172244548797607
Validation loss: 2.0537003775437674

Epoch: 5| Step: 5
Training loss: 1.827975869178772
Validation loss: 2.0697122861941657

Epoch: 5| Step: 6
Training loss: 2.3889319896698
Validation loss: 2.038360928495725

Epoch: 5| Step: 7
Training loss: 2.533507823944092
Validation loss: 2.056634709239006

Epoch: 5| Step: 8
Training loss: 1.2711231708526611
Validation loss: 2.0241097609202066

Epoch: 5| Step: 9
Training loss: 2.006380558013916
Validation loss: 2.0425369441509247

Epoch: 5| Step: 10
Training loss: 2.015272617340088
Validation loss: 2.0526695301135383

Epoch: 5| Step: 11
Training loss: 1.2824628353118896
Validation loss: 2.0325027058521905

Epoch: 45| Step: 0
Training loss: 2.137485980987549
Validation loss: 2.0423873563607535

Epoch: 5| Step: 1
Training loss: 1.6030546426773071
Validation loss: 2.13925372560819

Epoch: 5| Step: 2
Training loss: 1.9044952392578125
Validation loss: 2.161547303199768

Epoch: 5| Step: 3
Training loss: 2.6818504333496094
Validation loss: 2.180931806564331

Epoch: 5| Step: 4
Training loss: 1.7594865560531616
Validation loss: 2.207816556096077

Epoch: 5| Step: 5
Training loss: 1.6404755115509033
Validation loss: 2.1818320751190186

Epoch: 5| Step: 6
Training loss: 2.0950980186462402
Validation loss: 2.1528014093637466

Epoch: 5| Step: 7
Training loss: 2.198629140853882
Validation loss: 2.1481802264849343

Epoch: 5| Step: 8
Training loss: 2.162572145462036
Validation loss: 2.1249500811100006

Epoch: 5| Step: 9
Training loss: 1.4398540258407593
Validation loss: 2.0950537472963333

Epoch: 5| Step: 10
Training loss: 2.2199251651763916
Validation loss: 2.09330586095651

Epoch: 5| Step: 11
Training loss: 2.1152777671813965
Validation loss: 2.085243210196495

Epoch: 46| Step: 0
Training loss: 1.8702884912490845
Validation loss: 2.0547470351060233

Epoch: 5| Step: 1
Training loss: 2.0885488986968994
Validation loss: 2.080336794257164

Epoch: 5| Step: 2
Training loss: 1.746978521347046
Validation loss: 2.0562691191832223

Epoch: 5| Step: 3
Training loss: 1.9768383502960205
Validation loss: 2.0587305476268134

Epoch: 5| Step: 4
Training loss: 1.7109375
Validation loss: 2.0774412552515664

Epoch: 5| Step: 5
Training loss: 2.0436134338378906
Validation loss: 2.0498961011568704

Epoch: 5| Step: 6
Training loss: 2.1032004356384277
Validation loss: 2.0752142320076623

Epoch: 5| Step: 7
Training loss: 1.2218173742294312
Validation loss: 2.0705863585074744

Epoch: 5| Step: 8
Training loss: 2.130028486251831
Validation loss: 2.028202032049497

Epoch: 5| Step: 9
Training loss: 2.0837254524230957
Validation loss: 2.0722518960634866

Epoch: 5| Step: 10
Training loss: 2.457150936126709
Validation loss: 2.0184134244918823

Epoch: 5| Step: 11
Training loss: 2.684793472290039
Validation loss: 2.1011115113894143

Epoch: 47| Step: 0
Training loss: 1.2793420553207397
Validation loss: 2.0430331925551095

Epoch: 5| Step: 1
Training loss: 2.083578586578369
Validation loss: 2.089706465601921

Epoch: 5| Step: 2
Training loss: 2.356611728668213
Validation loss: 2.0511925468842187

Epoch: 5| Step: 3
Training loss: 1.5940849781036377
Validation loss: 2.0611667931079865

Epoch: 5| Step: 4
Training loss: 1.6185319423675537
Validation loss: 2.0882411996523538

Epoch: 5| Step: 5
Training loss: 1.8576829433441162
Validation loss: 2.0782746771971383

Epoch: 5| Step: 6
Training loss: 2.124758720397949
Validation loss: 2.069880669315656

Epoch: 5| Step: 7
Training loss: 2.4063289165496826
Validation loss: 2.09375753502051

Epoch: 5| Step: 8
Training loss: 2.048548460006714
Validation loss: 2.0488515943288803

Epoch: 5| Step: 9
Training loss: 2.1835274696350098
Validation loss: 2.073413074016571

Epoch: 5| Step: 10
Training loss: 1.72412109375
Validation loss: 2.0518789688746133

Epoch: 5| Step: 11
Training loss: 2.4171886444091797
Validation loss: 2.030231018861135

Epoch: 48| Step: 0
Training loss: 2.050956964492798
Validation loss: 2.0279781272013984

Epoch: 5| Step: 1
Training loss: 1.9746897220611572
Validation loss: 2.0612180878718696

Epoch: 5| Step: 2
Training loss: 1.491703748703003
Validation loss: 2.023663361867269

Epoch: 5| Step: 3
Training loss: 1.94496750831604
Validation loss: 2.002212777733803

Epoch: 5| Step: 4
Training loss: 2.1256988048553467
Validation loss: 2.011095608274142

Epoch: 5| Step: 5
Training loss: 2.1397392749786377
Validation loss: 2.0373547126849494

Epoch: 5| Step: 6
Training loss: 1.7988382577896118
Validation loss: 2.0021873861551285

Epoch: 5| Step: 7
Training loss: 1.7292015552520752
Validation loss: 2.090203190843264

Epoch: 5| Step: 8
Training loss: 2.515742063522339
Validation loss: 2.0816717445850372

Epoch: 5| Step: 9
Training loss: 1.651288390159607
Validation loss: 2.1312485138575235

Epoch: 5| Step: 10
Training loss: 2.108372211456299
Validation loss: 2.0855485101540885

Epoch: 5| Step: 11
Training loss: 2.4277191162109375
Validation loss: 2.0935274809598923

Epoch: 49| Step: 0
Training loss: 1.949014663696289
Validation loss: 2.0453822215398154

Epoch: 5| Step: 1
Training loss: 1.9641075134277344
Validation loss: 2.115329126516978

Epoch: 5| Step: 2
Training loss: 1.9742317199707031
Validation loss: 2.0806172837813697

Epoch: 5| Step: 3
Training loss: 1.9862709045410156
Validation loss: 2.04820017516613

Epoch: 5| Step: 4
Training loss: 1.442901372909546
Validation loss: 2.053817167878151

Epoch: 5| Step: 5
Training loss: 1.9860957860946655
Validation loss: 2.031076749165853

Epoch: 5| Step: 6
Training loss: 1.6251819133758545
Validation loss: 2.028224249680837

Epoch: 5| Step: 7
Training loss: 1.7556883096694946
Validation loss: 2.071602741877238

Epoch: 5| Step: 8
Training loss: 2.3834357261657715
Validation loss: 2.0609056701262793

Epoch: 5| Step: 9
Training loss: 2.0655269622802734
Validation loss: 2.0289788991212845

Epoch: 5| Step: 10
Training loss: 2.1070590019226074
Validation loss: 2.0294764240582785

Epoch: 5| Step: 11
Training loss: 2.2034664154052734
Validation loss: 2.0560198624928794

Epoch: 50| Step: 0
Training loss: 1.8175729513168335
Validation loss: 2.047672907511393

Epoch: 5| Step: 1
Training loss: 1.5649911165237427
Validation loss: 2.0590402086575827

Epoch: 5| Step: 2
Training loss: 1.8548864126205444
Validation loss: 2.073134442170461

Epoch: 5| Step: 3
Training loss: 2.3400206565856934
Validation loss: 2.0675484289725623

Epoch: 5| Step: 4
Training loss: 1.709754228591919
Validation loss: 2.0631558100382485

Epoch: 5| Step: 5
Training loss: 2.076847553253174
Validation loss: 2.0640592078367868

Epoch: 5| Step: 6
Training loss: 1.478615164756775
Validation loss: 2.0484729508558908

Epoch: 5| Step: 7
Training loss: 2.320136547088623
Validation loss: 2.0889958292245865

Epoch: 5| Step: 8
Training loss: 2.096989631652832
Validation loss: 2.0673940181732178

Epoch: 5| Step: 9
Training loss: 1.7384192943572998
Validation loss: 2.0848480562369027

Epoch: 5| Step: 10
Training loss: 2.1998825073242188
Validation loss: 2.1241845736900964

Epoch: 5| Step: 11
Training loss: 1.0596706867218018
Validation loss: 2.0969083358844123

Epoch: 51| Step: 0
Training loss: 2.0937182903289795
Validation loss: 2.128015528122584

Epoch: 5| Step: 1
Training loss: 1.622892141342163
Validation loss: 2.1130279997984567

Epoch: 5| Step: 2
Training loss: 2.440431833267212
Validation loss: 2.069560612241427

Epoch: 5| Step: 3
Training loss: 1.4029757976531982
Validation loss: 2.0941227227449417

Epoch: 5| Step: 4
Training loss: 1.8324146270751953
Validation loss: 2.0543425579865775

Epoch: 5| Step: 5
Training loss: 2.250028133392334
Validation loss: 2.0645779818296432

Epoch: 5| Step: 6
Training loss: 1.7850427627563477
Validation loss: 2.0624085714419684

Epoch: 5| Step: 7
Training loss: 2.190264940261841
Validation loss: 2.0693086137374244

Epoch: 5| Step: 8
Training loss: 1.3026578426361084
Validation loss: 2.025122125943502

Epoch: 5| Step: 9
Training loss: 1.9206712245941162
Validation loss: 2.0665772507588067

Epoch: 5| Step: 10
Training loss: 2.419823408126831
Validation loss: 2.0716597686211267

Epoch: 5| Step: 11
Training loss: 1.136626958847046
Validation loss: 2.0686186651388803

Epoch: 52| Step: 0
Training loss: 1.9116853475570679
Validation loss: 2.0486829429864883

Epoch: 5| Step: 1
Training loss: 1.736405611038208
Validation loss: 2.0889177173376083

Epoch: 5| Step: 2
Training loss: 2.6747689247131348
Validation loss: 2.0534607966740928

Epoch: 5| Step: 3
Training loss: 1.2312781810760498
Validation loss: 2.052475392818451

Epoch: 5| Step: 4
Training loss: 2.192760944366455
Validation loss: 2.113294318318367

Epoch: 5| Step: 5
Training loss: 2.028379440307617
Validation loss: 2.1385998278856277

Epoch: 5| Step: 6
Training loss: 1.6986061334609985
Validation loss: 2.102897524833679

Epoch: 5| Step: 7
Training loss: 2.1592233180999756
Validation loss: 2.058680976430575

Epoch: 5| Step: 8
Training loss: 1.8046693801879883
Validation loss: 2.089876373608907

Epoch: 5| Step: 9
Training loss: 1.5440810918807983
Validation loss: 2.106761554876963

Epoch: 5| Step: 10
Training loss: 2.114452838897705
Validation loss: 2.072965065638224

Epoch: 5| Step: 11
Training loss: 2.4259755611419678
Validation loss: 2.083313678701719

Epoch: 53| Step: 0
Training loss: 2.550565719604492
Validation loss: 2.058234045902888

Epoch: 5| Step: 1
Training loss: 1.999413251876831
Validation loss: 2.0891630003849664

Epoch: 5| Step: 2
Training loss: 1.8472912311553955
Validation loss: 2.085455968976021

Epoch: 5| Step: 3
Training loss: 2.1606743335723877
Validation loss: 2.015349561969439

Epoch: 5| Step: 4
Training loss: 1.9931046962738037
Validation loss: 2.1013323962688446

Epoch: 5| Step: 5
Training loss: 1.8720028400421143
Validation loss: 2.0375282019376755

Epoch: 5| Step: 6
Training loss: 2.477877140045166
Validation loss: 2.1451667050520578

Epoch: 5| Step: 7
Training loss: 1.039474606513977
Validation loss: 2.1258543531099954

Epoch: 5| Step: 8
Training loss: 1.696637749671936
Validation loss: 2.077926809589068

Epoch: 5| Step: 9
Training loss: 1.8211206197738647
Validation loss: 2.0764297594626746

Epoch: 5| Step: 10
Training loss: 1.8331912755966187
Validation loss: 2.0585606147845588

Epoch: 5| Step: 11
Training loss: 0.9231531620025635
Validation loss: 2.0828596651554108

Epoch: 54| Step: 0
Training loss: 2.239321231842041
Validation loss: 2.0451601147651672

Epoch: 5| Step: 1
Training loss: 1.9596433639526367
Validation loss: 2.05758968492349

Epoch: 5| Step: 2
Training loss: 2.045468330383301
Validation loss: 2.0930250684420266

Epoch: 5| Step: 3
Training loss: 1.9438823461532593
Validation loss: 2.0917818496624627

Epoch: 5| Step: 4
Training loss: 1.8236936330795288
Validation loss: 2.1021994998057685

Epoch: 5| Step: 5
Training loss: 1.3541858196258545
Validation loss: 2.128030389547348

Epoch: 5| Step: 6
Training loss: 1.8978999853134155
Validation loss: 2.1344785491625466

Epoch: 5| Step: 7
Training loss: 2.4473752975463867
Validation loss: 2.138173997402191

Epoch: 5| Step: 8
Training loss: 1.8429844379425049
Validation loss: 2.0908881525198617

Epoch: 5| Step: 9
Training loss: 1.789706826210022
Validation loss: 2.1036384056011834

Epoch: 5| Step: 10
Training loss: 2.013018846511841
Validation loss: 2.042140300075213

Epoch: 5| Step: 11
Training loss: 1.3493096828460693
Validation loss: 2.054412618279457

Epoch: 55| Step: 0
Training loss: 1.3467094898223877
Validation loss: 2.067189872264862

Epoch: 5| Step: 1
Training loss: 1.5508791208267212
Validation loss: 2.05191762248675

Epoch: 5| Step: 2
Training loss: 1.9412082433700562
Validation loss: 2.0634260723988214

Epoch: 5| Step: 3
Training loss: 1.5389565229415894
Validation loss: 2.053522383173307

Epoch: 5| Step: 4
Training loss: 1.7914955615997314
Validation loss: 2.03642039000988

Epoch: 5| Step: 5
Training loss: 2.6513636112213135
Validation loss: 2.043949748078982

Epoch: 5| Step: 6
Training loss: 2.1254703998565674
Validation loss: 2.148333723346392

Epoch: 5| Step: 7
Training loss: 2.1105763912200928
Validation loss: 2.155715212225914

Epoch: 5| Step: 8
Training loss: 1.6257445812225342
Validation loss: 2.155774454275767

Epoch: 5| Step: 9
Training loss: 2.499843120574951
Validation loss: 2.141758754849434

Epoch: 5| Step: 10
Training loss: 2.0973665714263916
Validation loss: 2.0638824899991355

Epoch: 5| Step: 11
Training loss: 0.8525081872940063
Validation loss: 2.0665099124113717

Epoch: 56| Step: 0
Training loss: 2.5679335594177246
Validation loss: 2.06717412173748

Epoch: 5| Step: 1
Training loss: 1.7771599292755127
Validation loss: 2.072416956226031

Epoch: 5| Step: 2
Training loss: 2.1779391765594482
Validation loss: 2.070814018448194

Epoch: 5| Step: 3
Training loss: 2.016386032104492
Validation loss: 2.1006287982066474

Epoch: 5| Step: 4
Training loss: 1.6073201894760132
Validation loss: 2.0692208806673684

Epoch: 5| Step: 5
Training loss: 1.4905636310577393
Validation loss: 2.1227378050486245

Epoch: 5| Step: 6
Training loss: 2.0645384788513184
Validation loss: 2.1267320762077966

Epoch: 5| Step: 7
Training loss: 1.3486883640289307
Validation loss: 2.139319807291031

Epoch: 5| Step: 8
Training loss: 2.142411708831787
Validation loss: 2.1689778019984565

Epoch: 5| Step: 9
Training loss: 1.850549340248108
Validation loss: 2.0987646679083505

Epoch: 5| Step: 10
Training loss: 1.7614885568618774
Validation loss: 2.081435357530912

Epoch: 5| Step: 11
Training loss: 0.7917337417602539
Validation loss: 2.1319022476673126

Epoch: 57| Step: 0
Training loss: 1.7111175060272217
Validation loss: 2.067516659696897

Epoch: 5| Step: 1
Training loss: 1.7515720129013062
Validation loss: 2.0050162424643836

Epoch: 5| Step: 2
Training loss: 1.8084293603897095
Validation loss: 2.1102043638626733

Epoch: 5| Step: 3
Training loss: 2.653980255126953
Validation loss: 2.1121676017840705

Epoch: 5| Step: 4
Training loss: 2.133009433746338
Validation loss: 2.1685220102469125

Epoch: 5| Step: 5
Training loss: 2.1105473041534424
Validation loss: 2.169698695341746

Epoch: 5| Step: 6
Training loss: 1.7258682250976562
Validation loss: 2.116001089413961

Epoch: 5| Step: 7
Training loss: 1.4267690181732178
Validation loss: 2.1374792953332267

Epoch: 5| Step: 8
Training loss: 1.9544057846069336
Validation loss: 2.0349789013465247

Epoch: 5| Step: 9
Training loss: 1.9284636974334717
Validation loss: 2.0907450864712396

Epoch: 5| Step: 10
Training loss: 1.7286971807479858
Validation loss: 2.1103361497322717

Epoch: 5| Step: 11
Training loss: 1.16292405128479
Validation loss: 2.1179379721482596

Epoch: 58| Step: 0
Training loss: 2.0750021934509277
Validation loss: 2.184593121210734

Epoch: 5| Step: 1
Training loss: 1.2253477573394775
Validation loss: 2.1931954622268677

Epoch: 5| Step: 2
Training loss: 2.184105157852173
Validation loss: 2.154046341776848

Epoch: 5| Step: 3
Training loss: 1.8427057266235352
Validation loss: 2.201377749443054

Epoch: 5| Step: 4
Training loss: 2.550020217895508
Validation loss: 2.2228960196177163

Epoch: 5| Step: 5
Training loss: 1.5935720205307007
Validation loss: 2.1336231331030526

Epoch: 5| Step: 6
Training loss: 1.7803678512573242
Validation loss: 2.169571121533712

Epoch: 5| Step: 7
Training loss: 1.341396450996399
Validation loss: 2.1345498710870743

Epoch: 5| Step: 8
Training loss: 2.0849850177764893
Validation loss: 2.0656330486138663

Epoch: 5| Step: 9
Training loss: 2.2603471279144287
Validation loss: 2.0852350145578384

Epoch: 5| Step: 10
Training loss: 2.274839162826538
Validation loss: 2.0867963979641595

Epoch: 5| Step: 11
Training loss: 0.7717714309692383
Validation loss: 2.135767941673597

Epoch: 59| Step: 0
Training loss: 1.888562560081482
Validation loss: 2.1698751201232276

Epoch: 5| Step: 1
Training loss: 2.6376614570617676
Validation loss: 2.1364505141973495

Epoch: 5| Step: 2
Training loss: 1.8380495309829712
Validation loss: 2.1115207970142365

Epoch: 5| Step: 3
Training loss: 2.0533859729766846
Validation loss: 2.158442477385203

Epoch: 5| Step: 4
Training loss: 1.826414704322815
Validation loss: 2.0856477270523706

Epoch: 5| Step: 5
Training loss: 1.894927740097046
Validation loss: 2.0951869636774063

Epoch: 5| Step: 6
Training loss: 2.2323436737060547
Validation loss: 2.0991606364647546

Epoch: 5| Step: 7
Training loss: 1.8839571475982666
Validation loss: 2.0854012171427407

Epoch: 5| Step: 8
Training loss: 1.6108951568603516
Validation loss: 2.1135401129722595

Epoch: 5| Step: 9
Training loss: 2.2074246406555176
Validation loss: 2.1201702604691186

Epoch: 5| Step: 10
Training loss: 1.3759140968322754
Validation loss: 2.076583375533422

Epoch: 5| Step: 11
Training loss: 0.5766364336013794
Validation loss: 2.1528572738170624

Epoch: 60| Step: 0
Training loss: 2.0017709732055664
Validation loss: 2.0450292577346167

Epoch: 5| Step: 1
Training loss: 1.7871294021606445
Validation loss: 2.1240676045417786

Epoch: 5| Step: 2
Training loss: 1.3008708953857422
Validation loss: 2.0619489004214606

Epoch: 5| Step: 3
Training loss: 2.5266592502593994
Validation loss: 2.0622655550638833

Epoch: 5| Step: 4
Training loss: 1.8348640203475952
Validation loss: 2.0243888398011527

Epoch: 5| Step: 5
Training loss: 1.7902151346206665
Validation loss: 2.070726831754049

Epoch: 5| Step: 6
Training loss: 1.8179523944854736
Validation loss: 2.069200952847799

Epoch: 5| Step: 7
Training loss: 1.8068478107452393
Validation loss: 2.05191736916701

Epoch: 5| Step: 8
Training loss: 1.9088188409805298
Validation loss: 2.0809643069903054

Epoch: 5| Step: 9
Training loss: 1.4640083312988281
Validation loss: 2.086328168710073

Epoch: 5| Step: 10
Training loss: 2.3093221187591553
Validation loss: 2.0924661656220755

Epoch: 5| Step: 11
Training loss: 2.149667739868164
Validation loss: 2.0626361270745597

Epoch: 61| Step: 0
Training loss: 1.6100761890411377
Validation loss: 2.086039180556933

Epoch: 5| Step: 1
Training loss: 1.8307908773422241
Validation loss: 2.133662164211273

Epoch: 5| Step: 2
Training loss: 2.271510601043701
Validation loss: 2.0921361396710076

Epoch: 5| Step: 3
Training loss: 2.138247489929199
Validation loss: 2.09523976345857

Epoch: 5| Step: 4
Training loss: 2.0082600116729736
Validation loss: 2.0756046970685325

Epoch: 5| Step: 5
Training loss: 1.6679401397705078
Validation loss: 2.1001411279042563

Epoch: 5| Step: 6
Training loss: 2.0852198600769043
Validation loss: 2.1217207113901773

Epoch: 5| Step: 7
Training loss: 1.8732986450195312
Validation loss: 2.1063193579514823

Epoch: 5| Step: 8
Training loss: 1.2895433902740479
Validation loss: 2.097383494178454

Epoch: 5| Step: 9
Training loss: 1.6736812591552734
Validation loss: 2.0403040995200477

Epoch: 5| Step: 10
Training loss: 1.906943678855896
Validation loss: 2.0657944281895957

Epoch: 5| Step: 11
Training loss: 0.4992549419403076
Validation loss: 2.0808637688557305

Epoch: 62| Step: 0
Training loss: 1.2762935161590576
Validation loss: 2.1191202302773795

Epoch: 5| Step: 1
Training loss: 1.8784139156341553
Validation loss: 2.027712052067121

Epoch: 5| Step: 2
Training loss: 2.254648208618164
Validation loss: 2.0905360678831735

Epoch: 5| Step: 3
Training loss: 2.181563377380371
Validation loss: 2.1068925907214484

Epoch: 5| Step: 4
Training loss: 1.6040115356445312
Validation loss: 2.0993313093980155

Epoch: 5| Step: 5
Training loss: 2.438723087310791
Validation loss: 2.125428020954132

Epoch: 5| Step: 6
Training loss: 1.5223257541656494
Validation loss: 2.1004501034816108

Epoch: 5| Step: 7
Training loss: 1.8711754083633423
Validation loss: 2.0802672455708184

Epoch: 5| Step: 8
Training loss: 1.9201492071151733
Validation loss: 2.111236164967219

Epoch: 5| Step: 9
Training loss: 2.0186991691589355
Validation loss: 2.100440805157026

Epoch: 5| Step: 10
Training loss: 1.4674102067947388
Validation loss: 2.1259022106726966

Epoch: 5| Step: 11
Training loss: 1.3134973049163818
Validation loss: 2.1294781267642975

Epoch: 63| Step: 0
Training loss: 1.8737941980361938
Validation loss: 2.1420626640319824

Epoch: 5| Step: 1
Training loss: 1.7780824899673462
Validation loss: 2.0553173075119653

Epoch: 5| Step: 2
Training loss: 1.7788349390029907
Validation loss: 2.0847232590119043

Epoch: 5| Step: 3
Training loss: 1.463191032409668
Validation loss: 2.0761951555808387

Epoch: 5| Step: 4
Training loss: 1.9865341186523438
Validation loss: 2.1568667143583298

Epoch: 5| Step: 5
Training loss: 2.3938355445861816
Validation loss: 2.1032046476999917

Epoch: 5| Step: 6
Training loss: 1.8857886791229248
Validation loss: 2.0898030946652093

Epoch: 5| Step: 7
Training loss: 1.7585489749908447
Validation loss: 2.093706672390302

Epoch: 5| Step: 8
Training loss: 1.9704570770263672
Validation loss: 2.098931069175402

Epoch: 5| Step: 9
Training loss: 1.8608005046844482
Validation loss: 2.0940232475598655

Epoch: 5| Step: 10
Training loss: 1.7133104801177979
Validation loss: 2.1147704174121222

Epoch: 5| Step: 11
Training loss: 3.5080103874206543
Validation loss: 2.1454662481943765

Epoch: 64| Step: 0
Training loss: 1.870409369468689
Validation loss: 2.190895269314448

Epoch: 5| Step: 1
Training loss: 2.1673741340637207
Validation loss: 2.184348846475283

Epoch: 5| Step: 2
Training loss: 1.7001785039901733
Validation loss: 2.2597104708353677

Epoch: 5| Step: 3
Training loss: 1.7795207500457764
Validation loss: 2.2825867931048074

Epoch: 5| Step: 4
Training loss: 2.1154608726501465
Validation loss: 2.1496256788571677

Epoch: 5| Step: 5
Training loss: 1.4585046768188477
Validation loss: 2.1655433177948

Epoch: 5| Step: 6
Training loss: 1.5615365505218506
Validation loss: 2.1386291633049646

Epoch: 5| Step: 7
Training loss: 1.8737659454345703
Validation loss: 2.1261082539955773

Epoch: 5| Step: 8
Training loss: 2.342806100845337
Validation loss: 2.1014610677957535

Epoch: 5| Step: 9
Training loss: 1.313974142074585
Validation loss: 2.1317764023939767

Epoch: 5| Step: 10
Training loss: 2.418487310409546
Validation loss: 2.066291486223539

Epoch: 5| Step: 11
Training loss: 1.707771897315979
Validation loss: 2.071119954188665

Epoch: 65| Step: 0
Training loss: 2.6049323081970215
Validation loss: 2.1362985322872796

Epoch: 5| Step: 1
Training loss: 1.8766777515411377
Validation loss: 2.1025474270184836

Epoch: 5| Step: 2
Training loss: 1.6439259052276611
Validation loss: 2.056663195292155

Epoch: 5| Step: 3
Training loss: 1.4897459745407104
Validation loss: 2.0817003597815833

Epoch: 5| Step: 4
Training loss: 1.7384929656982422
Validation loss: 2.064024974902471

Epoch: 5| Step: 5
Training loss: 2.15549373626709
Validation loss: 2.086203177769979

Epoch: 5| Step: 6
Training loss: 1.572816252708435
Validation loss: 2.06691575050354

Epoch: 5| Step: 7
Training loss: 1.7680962085723877
Validation loss: 2.1065519601106644

Epoch: 5| Step: 8
Training loss: 1.929795265197754
Validation loss: 2.1750782628854117

Epoch: 5| Step: 9
Training loss: 1.9021466970443726
Validation loss: 2.147316887974739

Epoch: 5| Step: 10
Training loss: 1.7034480571746826
Validation loss: 2.147987728317579

Epoch: 5| Step: 11
Training loss: 2.550360679626465
Validation loss: 2.1680590311686196

Epoch: 66| Step: 0
Training loss: 1.9277222156524658
Validation loss: 2.1647602369387946

Epoch: 5| Step: 1
Training loss: 1.7394682168960571
Validation loss: 2.1589019298553467

Epoch: 5| Step: 2
Training loss: 1.9494287967681885
Validation loss: 2.1860772520303726

Epoch: 5| Step: 3
Training loss: 1.9785239696502686
Validation loss: 2.1496552328268685

Epoch: 5| Step: 4
Training loss: 1.9140644073486328
Validation loss: 2.111412286758423

Epoch: 5| Step: 5
Training loss: 2.385887622833252
Validation loss: 2.100514074166616

Epoch: 5| Step: 6
Training loss: 2.217620849609375
Validation loss: 2.0685479988654456

Epoch: 5| Step: 7
Training loss: 1.4538853168487549
Validation loss: 2.047280415892601

Epoch: 5| Step: 8
Training loss: 1.9672447443008423
Validation loss: 2.0610031684239707

Epoch: 5| Step: 9
Training loss: 1.689260482788086
Validation loss: 2.0670905659596124

Epoch: 5| Step: 10
Training loss: 1.7264091968536377
Validation loss: 2.064544747273127

Epoch: 5| Step: 11
Training loss: 1.2852637767791748
Validation loss: 2.039275030295054

Epoch: 67| Step: 0
Training loss: 1.8782932758331299
Validation loss: 2.1584063867727914

Epoch: 5| Step: 1
Training loss: 1.7409656047821045
Validation loss: 2.0482168992360434

Epoch: 5| Step: 2
Training loss: 1.5412185192108154
Validation loss: 2.0769662807385125

Epoch: 5| Step: 3
Training loss: 1.405120611190796
Validation loss: 2.1134229054053626

Epoch: 5| Step: 4
Training loss: 1.9193203449249268
Validation loss: 2.084951877593994

Epoch: 5| Step: 5
Training loss: 1.5971983671188354
Validation loss: 2.0664744128783545

Epoch: 5| Step: 6
Training loss: 1.8841663599014282
Validation loss: 2.1258838325738907

Epoch: 5| Step: 7
Training loss: 2.079585075378418
Validation loss: 2.165105884273847

Epoch: 5| Step: 8
Training loss: 2.1569628715515137
Validation loss: 2.1811028718948364

Epoch: 5| Step: 9
Training loss: 1.9674224853515625
Validation loss: 2.230854998032252

Epoch: 5| Step: 10
Training loss: 2.381119966506958
Validation loss: 2.2049595564603806

Epoch: 5| Step: 11
Training loss: 1.8867106437683105
Validation loss: 2.1676393300294876

Epoch: 68| Step: 0
Training loss: 1.9447228908538818
Validation loss: 2.161280632019043

Epoch: 5| Step: 1
Training loss: 1.7493493556976318
Validation loss: 2.130890121062597

Epoch: 5| Step: 2
Training loss: 1.5569102764129639
Validation loss: 2.090274547537168

Epoch: 5| Step: 3
Training loss: 1.813854455947876
Validation loss: 2.0937930891911187

Epoch: 5| Step: 4
Training loss: 2.088156223297119
Validation loss: 2.0983480364084244

Epoch: 5| Step: 5
Training loss: 1.4144953489303589
Validation loss: 2.0821172893047333

Epoch: 5| Step: 6
Training loss: 1.860520601272583
Validation loss: 2.10409610470136

Epoch: 5| Step: 7
Training loss: 1.5005073547363281
Validation loss: 2.0231888790925345

Epoch: 5| Step: 8
Training loss: 2.219230890274048
Validation loss: 2.0600088437398276

Epoch: 5| Step: 9
Training loss: 2.1958210468292236
Validation loss: 2.0956019461154938

Epoch: 5| Step: 10
Training loss: 1.9395885467529297
Validation loss: 2.132785285512606

Epoch: 5| Step: 11
Training loss: 2.0369720458984375
Validation loss: 2.0841564734776816

Epoch: 69| Step: 0
Training loss: 1.8179603815078735
Validation loss: 2.081480542818705

Epoch: 5| Step: 1
Training loss: 1.7246373891830444
Validation loss: 2.0818327019611993

Epoch: 5| Step: 2
Training loss: 2.4569101333618164
Validation loss: 2.0790438055992126

Epoch: 5| Step: 3
Training loss: 1.4981615543365479
Validation loss: 2.1157431999842324

Epoch: 5| Step: 4
Training loss: 1.8384367227554321
Validation loss: 2.0807878375053406

Epoch: 5| Step: 5
Training loss: 1.7354824542999268
Validation loss: 2.0937758485476174

Epoch: 5| Step: 6
Training loss: 1.6663219928741455
Validation loss: 2.122432142496109

Epoch: 5| Step: 7
Training loss: 1.8535579442977905
Validation loss: 2.1066838254531226

Epoch: 5| Step: 8
Training loss: 1.6618502140045166
Validation loss: 2.10624390343825

Epoch: 5| Step: 9
Training loss: 2.098144054412842
Validation loss: 2.1580469956000647

Epoch: 5| Step: 10
Training loss: 1.562516689300537
Validation loss: 2.081929494937261

Epoch: 5| Step: 11
Training loss: 2.1229312419891357
Validation loss: 2.0689052442709603

Epoch: 70| Step: 0
Training loss: 1.4723132848739624
Validation loss: 2.044187054038048

Epoch: 5| Step: 1
Training loss: 2.443511486053467
Validation loss: 2.0988147308429084

Epoch: 5| Step: 2
Training loss: 1.3790401220321655
Validation loss: 2.101524035135905

Epoch: 5| Step: 3
Training loss: 1.7322146892547607
Validation loss: 2.0624093363682428

Epoch: 5| Step: 4
Training loss: 1.3622934818267822
Validation loss: 2.047144586841265

Epoch: 5| Step: 5
Training loss: 2.2166354656219482
Validation loss: 2.065216307838758

Epoch: 5| Step: 6
Training loss: 1.894665002822876
Validation loss: 2.028841187556585

Epoch: 5| Step: 7
Training loss: 1.932868242263794
Validation loss: 2.087605362137159

Epoch: 5| Step: 8
Training loss: 1.8372255563735962
Validation loss: 2.0837280551592507

Epoch: 5| Step: 9
Training loss: 1.8521196842193604
Validation loss: 2.081403856476148

Epoch: 5| Step: 10
Training loss: 1.778607964515686
Validation loss: 2.064948797225952

Epoch: 5| Step: 11
Training loss: 1.6604520082473755
Validation loss: 2.0851575434207916

Epoch: 71| Step: 0
Training loss: 1.1686785221099854
Validation loss: 2.1415185928344727

Epoch: 5| Step: 1
Training loss: 1.7581450939178467
Validation loss: 2.15138412018617

Epoch: 5| Step: 2
Training loss: 2.758361577987671
Validation loss: 2.182350049416224

Epoch: 5| Step: 3
Training loss: 1.8055288791656494
Validation loss: 2.217227523525556

Epoch: 5| Step: 4
Training loss: 1.6486470699310303
Validation loss: 2.1321121553579965

Epoch: 5| Step: 5
Training loss: 1.5924776792526245
Validation loss: 2.2016663451989493

Epoch: 5| Step: 6
Training loss: 1.7642873525619507
Validation loss: 2.177001640200615

Epoch: 5| Step: 7
Training loss: 1.7371256351470947
Validation loss: 2.1144605775674186

Epoch: 5| Step: 8
Training loss: 2.073456287384033
Validation loss: 2.03338360786438

Epoch: 5| Step: 9
Training loss: 1.4919872283935547
Validation loss: 2.098757321635882

Epoch: 5| Step: 10
Training loss: 2.172081470489502
Validation loss: 2.0460512886444726

Epoch: 5| Step: 11
Training loss: 1.873239517211914
Validation loss: 2.102750241756439

Epoch: 72| Step: 0
Training loss: 1.7030353546142578
Validation loss: 2.0734548370043435

Epoch: 5| Step: 1
Training loss: 1.6440794467926025
Validation loss: 2.086661716302236

Epoch: 5| Step: 2
Training loss: 1.734523057937622
Validation loss: 2.1283770203590393

Epoch: 5| Step: 3
Training loss: 1.7725422382354736
Validation loss: 2.119787355264028

Epoch: 5| Step: 4
Training loss: 1.751794457435608
Validation loss: 2.1418981750806174

Epoch: 5| Step: 5
Training loss: 1.8278230428695679
Validation loss: 2.132740333676338

Epoch: 5| Step: 6
Training loss: 1.512230634689331
Validation loss: 2.152829354008039

Epoch: 5| Step: 7
Training loss: 1.5828111171722412
Validation loss: 2.125579128662745

Epoch: 5| Step: 8
Training loss: 1.735925316810608
Validation loss: 2.137029399474462

Epoch: 5| Step: 9
Training loss: 1.9900366067886353
Validation loss: 2.126384899020195

Epoch: 5| Step: 10
Training loss: 2.4263627529144287
Validation loss: 2.0700590362151465

Epoch: 5| Step: 11
Training loss: 1.8058853149414062
Validation loss: 2.1199108163515725

Epoch: 73| Step: 0
Training loss: 1.9433517456054688
Validation loss: 2.114384094874064

Epoch: 5| Step: 1
Training loss: 1.7593393325805664
Validation loss: 2.079744120438894

Epoch: 5| Step: 2
Training loss: 1.7314932346343994
Validation loss: 2.1228891809781394

Epoch: 5| Step: 3
Training loss: 2.4369311332702637
Validation loss: 2.0761514057715735

Epoch: 5| Step: 4
Training loss: 1.8137657642364502
Validation loss: 2.067483509580294

Epoch: 5| Step: 5
Training loss: 1.7462307214736938
Validation loss: 2.0652631719907126

Epoch: 5| Step: 6
Training loss: 1.4375956058502197
Validation loss: 2.0548066794872284

Epoch: 5| Step: 7
Training loss: 1.5368160009384155
Validation loss: 2.0738235414028168

Epoch: 5| Step: 8
Training loss: 1.9487920999526978
Validation loss: 2.066680128375689

Epoch: 5| Step: 9
Training loss: 1.7233127355575562
Validation loss: 2.079950367410978

Epoch: 5| Step: 10
Training loss: 1.9398488998413086
Validation loss: 2.115292116999626

Epoch: 5| Step: 11
Training loss: 1.8645172119140625
Validation loss: 2.1570019274950027

Epoch: 74| Step: 0
Training loss: 1.5141541957855225
Validation loss: 2.106548155347506

Epoch: 5| Step: 1
Training loss: 1.327672004699707
Validation loss: 2.117651472489039

Epoch: 5| Step: 2
Training loss: 1.8494999408721924
Validation loss: 2.035630335410436

Epoch: 5| Step: 3
Training loss: 1.9601167440414429
Validation loss: 2.086876153945923

Epoch: 5| Step: 4
Training loss: 1.9836585521697998
Validation loss: 2.0901131133238473

Epoch: 5| Step: 5
Training loss: 1.67209792137146
Validation loss: 2.100044618050257

Epoch: 5| Step: 6
Training loss: 2.1069822311401367
Validation loss: 2.135528475046158

Epoch: 5| Step: 7
Training loss: 1.804154634475708
Validation loss: 2.116167535384496

Epoch: 5| Step: 8
Training loss: 1.7320410013198853
Validation loss: 2.12954980134964

Epoch: 5| Step: 9
Training loss: 2.0113120079040527
Validation loss: 2.073636924227079

Epoch: 5| Step: 10
Training loss: 1.2611398696899414
Validation loss: 2.1117928673823676

Epoch: 5| Step: 11
Training loss: 1.937491536140442
Validation loss: 2.1551560362180076

Epoch: 75| Step: 0
Training loss: 1.4848792552947998
Validation loss: 2.1499208013216653

Epoch: 5| Step: 1
Training loss: 1.7949053049087524
Validation loss: 2.152594635883967

Epoch: 5| Step: 2
Training loss: 2.0862393379211426
Validation loss: 2.1099294225374856

Epoch: 5| Step: 3
Training loss: 1.592950463294983
Validation loss: 2.119241257508596

Epoch: 5| Step: 4
Training loss: 1.3060693740844727
Validation loss: 2.0721649527549744

Epoch: 5| Step: 5
Training loss: 2.084541082382202
Validation loss: 2.0884156922499337

Epoch: 5| Step: 6
Training loss: 1.844976782798767
Validation loss: 2.04525134464105

Epoch: 5| Step: 7
Training loss: 1.617702841758728
Validation loss: 2.070194512605667

Epoch: 5| Step: 8
Training loss: 2.139331340789795
Validation loss: 2.0595000187555947

Epoch: 5| Step: 9
Training loss: 1.8941770792007446
Validation loss: 2.124826709429423

Epoch: 5| Step: 10
Training loss: 1.4717328548431396
Validation loss: 2.0975105613470078

Epoch: 5| Step: 11
Training loss: 2.4243688583374023
Validation loss: 2.122319464882215

Epoch: 76| Step: 0
Training loss: 1.27254319190979
Validation loss: 2.1020074784755707

Epoch: 5| Step: 1
Training loss: 2.286757230758667
Validation loss: 2.1131163587172828

Epoch: 5| Step: 2
Training loss: 1.6001657247543335
Validation loss: 2.114573443929354

Epoch: 5| Step: 3
Training loss: 1.6066585779190063
Validation loss: 2.04706579943498

Epoch: 5| Step: 4
Training loss: 2.0843117237091064
Validation loss: 2.0855090568463006

Epoch: 5| Step: 5
Training loss: 1.875306487083435
Validation loss: 2.0641988962888718

Epoch: 5| Step: 6
Training loss: 1.8601436614990234
Validation loss: 2.0507411460081735

Epoch: 5| Step: 7
Training loss: 1.7290141582489014
Validation loss: 2.061294292410215

Epoch: 5| Step: 8
Training loss: 1.9299800395965576
Validation loss: 2.1082638998826346

Epoch: 5| Step: 9
Training loss: 1.7878707647323608
Validation loss: 2.0733525256315866

Epoch: 5| Step: 10
Training loss: 1.773748755455017
Validation loss: 2.058984269698461

Epoch: 5| Step: 11
Training loss: 1.5258840322494507
Validation loss: 2.0521173626184464

Epoch: 77| Step: 0
Training loss: 1.354473352432251
Validation loss: 2.109915499885877

Epoch: 5| Step: 1
Training loss: 2.0253472328186035
Validation loss: 2.093270465731621

Epoch: 5| Step: 2
Training loss: 1.656484603881836
Validation loss: 2.136854271094004

Epoch: 5| Step: 3
Training loss: 2.0161001682281494
Validation loss: 2.1246657272179923

Epoch: 5| Step: 4
Training loss: 1.8643772602081299
Validation loss: 2.1868245800336203

Epoch: 5| Step: 5
Training loss: 1.8575938940048218
Validation loss: 2.1795412798722587

Epoch: 5| Step: 6
Training loss: 1.432348608970642
Validation loss: 2.126754249135653

Epoch: 5| Step: 7
Training loss: 1.7824052572250366
Validation loss: 2.1272726356983185

Epoch: 5| Step: 8
Training loss: 1.900223731994629
Validation loss: 2.0963739156723022

Epoch: 5| Step: 9
Training loss: 1.2405707836151123
Validation loss: 2.079120253523191

Epoch: 5| Step: 10
Training loss: 2.2875189781188965
Validation loss: 2.091779420773188

Epoch: 5| Step: 11
Training loss: 1.8639121055603027
Validation loss: 2.074748078982035

Epoch: 78| Step: 0
Training loss: 1.9297780990600586
Validation loss: 2.1175372252861657

Epoch: 5| Step: 1
Training loss: 2.648650646209717
Validation loss: 2.1244176725546517

Epoch: 5| Step: 2
Training loss: 1.9823949337005615
Validation loss: 2.111292893687884

Epoch: 5| Step: 3
Training loss: 1.8590885400772095
Validation loss: 2.109519451856613

Epoch: 5| Step: 4
Training loss: 1.4847071170806885
Validation loss: 2.1319501250982285

Epoch: 5| Step: 5
Training loss: 1.8259462118148804
Validation loss: 2.086669613917669

Epoch: 5| Step: 6
Training loss: 1.5614322423934937
Validation loss: 2.1220931112766266

Epoch: 5| Step: 7
Training loss: 1.8189852237701416
Validation loss: 2.076591948668162

Epoch: 5| Step: 8
Training loss: 1.5334827899932861
Validation loss: 2.132035553455353

Epoch: 5| Step: 9
Training loss: 1.5432045459747314
Validation loss: 2.116216113169988

Epoch: 5| Step: 10
Training loss: 1.7655420303344727
Validation loss: 2.123719722032547

Epoch: 5| Step: 11
Training loss: 0.8642909526824951
Validation loss: 2.1039299964904785

Epoch: 79| Step: 0
Training loss: 1.4323562383651733
Validation loss: 2.2003272275129953

Epoch: 5| Step: 1
Training loss: 2.0112338066101074
Validation loss: 2.2722188532352448

Epoch: 5| Step: 2
Training loss: 1.5012608766555786
Validation loss: 2.1029847264289856

Epoch: 5| Step: 3
Training loss: 1.6430680751800537
Validation loss: 2.103127350409826

Epoch: 5| Step: 4
Training loss: 1.6342289447784424
Validation loss: 2.1303056677182517

Epoch: 5| Step: 5
Training loss: 2.2952587604522705
Validation loss: 2.0992833574612937

Epoch: 5| Step: 6
Training loss: 1.6744823455810547
Validation loss: 2.085367033878962

Epoch: 5| Step: 7
Training loss: 1.7907936573028564
Validation loss: 2.1588392655054727

Epoch: 5| Step: 8
Training loss: 2.6401705741882324
Validation loss: 2.121271471182505

Epoch: 5| Step: 9
Training loss: 1.502673625946045
Validation loss: 2.128248249491056

Epoch: 5| Step: 10
Training loss: 1.3786265850067139
Validation loss: 2.1440188785394034

Epoch: 5| Step: 11
Training loss: 1.6622289419174194
Validation loss: 2.148048351208369

Epoch: 80| Step: 0
Training loss: 2.0533366203308105
Validation loss: 2.168914407491684

Epoch: 5| Step: 1
Training loss: 1.2418932914733887
Validation loss: 2.1887519359588623

Epoch: 5| Step: 2
Training loss: 1.0102078914642334
Validation loss: 2.1776349345842996

Epoch: 5| Step: 3
Training loss: 1.3794091939926147
Validation loss: 2.1222015718619027

Epoch: 5| Step: 4
Training loss: 2.667710542678833
Validation loss: 2.162634735306104

Epoch: 5| Step: 5
Training loss: 1.6940689086914062
Validation loss: 2.172528068224589

Epoch: 5| Step: 6
Training loss: 2.143303394317627
Validation loss: 2.1475839813550315

Epoch: 5| Step: 7
Training loss: 1.5110042095184326
Validation loss: 2.045237143834432

Epoch: 5| Step: 8
Training loss: 1.575101613998413
Validation loss: 2.077431564529737

Epoch: 5| Step: 9
Training loss: 1.9832448959350586
Validation loss: 2.0901604096094766

Epoch: 5| Step: 10
Training loss: 1.9542690515518188
Validation loss: 2.1093420634667077

Epoch: 5| Step: 11
Training loss: 1.0261768102645874
Validation loss: 2.1402595539887748

Epoch: 81| Step: 0
Training loss: 1.7513017654418945
Validation loss: 2.1441348095734916

Epoch: 5| Step: 1
Training loss: 2.238677978515625
Validation loss: 2.124763066569964

Epoch: 5| Step: 2
Training loss: 1.9232642650604248
Validation loss: 2.153044189016024

Epoch: 5| Step: 3
Training loss: 2.0070624351501465
Validation loss: 2.2490858882665634

Epoch: 5| Step: 4
Training loss: 1.5330665111541748
Validation loss: 2.2263050377368927

Epoch: 5| Step: 5
Training loss: 1.634666085243225
Validation loss: 2.1896965901056924

Epoch: 5| Step: 6
Training loss: 1.1939775943756104
Validation loss: 2.200832555691401

Epoch: 5| Step: 7
Training loss: 1.6717866659164429
Validation loss: 2.179132724801699

Epoch: 5| Step: 8
Training loss: 2.1977505683898926
Validation loss: 2.1301044623057046

Epoch: 5| Step: 9
Training loss: 1.9609874486923218
Validation loss: 2.067601020137469

Epoch: 5| Step: 10
Training loss: 2.043732166290283
Validation loss: 2.082861656943957

Epoch: 5| Step: 11
Training loss: 0.44527125358581543
Validation loss: 2.121193160613378

Epoch: 82| Step: 0
Training loss: 2.125171422958374
Validation loss: 2.029264504710833

Epoch: 5| Step: 1
Training loss: 1.1519105434417725
Validation loss: 2.118826245268186

Epoch: 5| Step: 2
Training loss: 1.8497340679168701
Validation loss: 2.08885749677817

Epoch: 5| Step: 3
Training loss: 1.6128517389297485
Validation loss: 2.0917379707098007

Epoch: 5| Step: 4
Training loss: 2.1593360900878906
Validation loss: 2.0876503040393195

Epoch: 5| Step: 5
Training loss: 1.8808326721191406
Validation loss: 2.0866291324297586

Epoch: 5| Step: 6
Training loss: 1.870011329650879
Validation loss: 2.1220329453547797

Epoch: 5| Step: 7
Training loss: 1.6466203927993774
Validation loss: 2.170041024684906

Epoch: 5| Step: 8
Training loss: 2.101943016052246
Validation loss: 2.1492065687974296

Epoch: 5| Step: 9
Training loss: 1.9083629846572876
Validation loss: 2.125959098339081

Epoch: 5| Step: 10
Training loss: 1.4459419250488281
Validation loss: 2.186596175034841

Epoch: 5| Step: 11
Training loss: 0.7607634663581848
Validation loss: 2.1825584520896277

Epoch: 83| Step: 0
Training loss: 1.91162109375
Validation loss: 2.1443437337875366

Epoch: 5| Step: 1
Training loss: 1.265596628189087
Validation loss: 2.1128321141004562

Epoch: 5| Step: 2
Training loss: 1.3909486532211304
Validation loss: 2.153374214967092

Epoch: 5| Step: 3
Training loss: 1.6116193532943726
Validation loss: 2.1154491305351257

Epoch: 5| Step: 4
Training loss: 1.6654613018035889
Validation loss: 2.1111837377150855

Epoch: 5| Step: 5
Training loss: 1.748888611793518
Validation loss: 2.078129917383194

Epoch: 5| Step: 6
Training loss: 2.470959186553955
Validation loss: 2.1041579643885293

Epoch: 5| Step: 7
Training loss: 2.335212230682373
Validation loss: 2.150776520371437

Epoch: 5| Step: 8
Training loss: 1.1573336124420166
Validation loss: 2.1063139041264853

Epoch: 5| Step: 9
Training loss: 1.6773955821990967
Validation loss: 2.103697861234347

Epoch: 5| Step: 10
Training loss: 2.0425021648406982
Validation loss: 2.1637189586957297

Epoch: 5| Step: 11
Training loss: 3.091726064682007
Validation loss: 2.0801786333322525

Epoch: 84| Step: 0
Training loss: 1.2025740146636963
Validation loss: 2.119828373193741

Epoch: 5| Step: 1
Training loss: 1.8579683303833008
Validation loss: 2.122316360473633

Epoch: 5| Step: 2
Training loss: 1.7568851709365845
Validation loss: 2.1074162820974984

Epoch: 5| Step: 3
Training loss: 1.8711860179901123
Validation loss: 2.1732755651076636

Epoch: 5| Step: 4
Training loss: 1.6626222133636475
Validation loss: 2.184966559211413

Epoch: 5| Step: 5
Training loss: 1.7435353994369507
Validation loss: 2.2352627913157144

Epoch: 5| Step: 6
Training loss: 2.682241916656494
Validation loss: 2.2307481169700623

Epoch: 5| Step: 7
Training loss: 1.6699453592300415
Validation loss: 2.180890033642451

Epoch: 5| Step: 8
Training loss: 2.0763490200042725
Validation loss: 2.1624538203080497

Epoch: 5| Step: 9
Training loss: 1.6004902124404907
Validation loss: 2.16623392701149

Epoch: 5| Step: 10
Training loss: 1.3681538105010986
Validation loss: 2.0985110054413476

Epoch: 5| Step: 11
Training loss: 0.8656530380249023
Validation loss: 2.1556097070376077

Epoch: 85| Step: 0
Training loss: 2.0956645011901855
Validation loss: 2.166130264600118

Epoch: 5| Step: 1
Training loss: 1.2044823169708252
Validation loss: 2.1610975712537766

Epoch: 5| Step: 2
Training loss: 1.5006494522094727
Validation loss: 2.141005123655001

Epoch: 5| Step: 3
Training loss: 1.6648505926132202
Validation loss: 2.124344984690348

Epoch: 5| Step: 4
Training loss: 1.7288833856582642
Validation loss: 2.118663489818573

Epoch: 5| Step: 5
Training loss: 2.243173360824585
Validation loss: 2.130476509531339

Epoch: 5| Step: 6
Training loss: 1.7873642444610596
Validation loss: 2.1201620250940323

Epoch: 5| Step: 7
Training loss: 1.957750678062439
Validation loss: 2.094484438498815

Epoch: 5| Step: 8
Training loss: 1.7939784526824951
Validation loss: 2.159397160013517

Epoch: 5| Step: 9
Training loss: 1.1544195413589478
Validation loss: 2.0829419841368995

Epoch: 5| Step: 10
Training loss: 1.3218826055526733
Validation loss: 2.1886440316836038

Epoch: 5| Step: 11
Training loss: 2.0931146144866943
Validation loss: 2.0799287607272468

Epoch: 86| Step: 0
Training loss: 1.729488730430603
Validation loss: 2.1206809331973395

Epoch: 5| Step: 1
Training loss: 1.7456668615341187
Validation loss: 2.128811463713646

Epoch: 5| Step: 2
Training loss: 1.4550578594207764
Validation loss: 2.0445790688196817

Epoch: 5| Step: 3
Training loss: 1.9245319366455078
Validation loss: 2.1095733443895974

Epoch: 5| Step: 4
Training loss: 1.6649891138076782
Validation loss: 2.133083830277125

Epoch: 5| Step: 5
Training loss: 2.2066004276275635
Validation loss: 2.0884776959816613

Epoch: 5| Step: 6
Training loss: 1.6439085006713867
Validation loss: 2.0973366697629294

Epoch: 5| Step: 7
Training loss: 1.2496436834335327
Validation loss: 2.1184840003649392

Epoch: 5| Step: 8
Training loss: 1.456661343574524
Validation loss: 2.2061583747466407

Epoch: 5| Step: 9
Training loss: 1.7252132892608643
Validation loss: 2.1961524287859597

Epoch: 5| Step: 10
Training loss: 2.164947748184204
Validation loss: 2.247580344478289

Epoch: 5| Step: 11
Training loss: 1.700831651687622
Validation loss: 2.17324161529541

Epoch: 87| Step: 0
Training loss: 1.354709267616272
Validation loss: 2.2340440104405084

Epoch: 5| Step: 1
Training loss: 1.9842811822891235
Validation loss: 2.148804778854052

Epoch: 5| Step: 2
Training loss: 2.059021472930908
Validation loss: 2.1671469509601593

Epoch: 5| Step: 3
Training loss: 1.3861802816390991
Validation loss: 2.145140747229258

Epoch: 5| Step: 4
Training loss: 1.5370994806289673
Validation loss: 2.1451966017484665

Epoch: 5| Step: 5
Training loss: 1.4141966104507446
Validation loss: 2.131640762090683

Epoch: 5| Step: 6
Training loss: 2.211434841156006
Validation loss: 2.0903040568033853

Epoch: 5| Step: 7
Training loss: 1.6764495372772217
Validation loss: 2.101238638162613

Epoch: 5| Step: 8
Training loss: 1.942035436630249
Validation loss: 2.092413862546285

Epoch: 5| Step: 9
Training loss: 1.4043060541152954
Validation loss: 2.0607109467188516

Epoch: 5| Step: 10
Training loss: 1.7554636001586914
Validation loss: 2.1381539156039557

Epoch: 5| Step: 11
Training loss: 0.8070670962333679
Validation loss: 2.1316718260447183

Epoch: 88| Step: 0
Training loss: 2.2598774433135986
Validation loss: 2.161368747552236

Epoch: 5| Step: 1
Training loss: 1.9011768102645874
Validation loss: 2.2477128009001413

Epoch: 5| Step: 2
Training loss: 1.3729629516601562
Validation loss: 2.2828732828299203

Epoch: 5| Step: 3
Training loss: 2.3852875232696533
Validation loss: 2.3143524726231894

Epoch: 5| Step: 4
Training loss: 1.8782289028167725
Validation loss: 2.2979077994823456

Epoch: 5| Step: 5
Training loss: 1.7100183963775635
Validation loss: 2.2339417735735574

Epoch: 5| Step: 6
Training loss: 1.396225929260254
Validation loss: 2.226813852787018

Epoch: 5| Step: 7
Training loss: 1.3003385066986084
Validation loss: 2.1504317869742713

Epoch: 5| Step: 8
Training loss: 1.7922662496566772
Validation loss: 2.1007157365481057

Epoch: 5| Step: 9
Training loss: 1.5306298732757568
Validation loss: 2.0697265962759652

Epoch: 5| Step: 10
Training loss: 1.9968475103378296
Validation loss: 2.084209163983663

Epoch: 5| Step: 11
Training loss: 1.4886550903320312
Validation loss: 2.100078667203585

Epoch: 89| Step: 0
Training loss: 2.0797557830810547
Validation loss: 2.1230373680591583

Epoch: 5| Step: 1
Training loss: 1.8536689281463623
Validation loss: 2.0649033735195794

Epoch: 5| Step: 2
Training loss: 1.3774935007095337
Validation loss: 2.11151792605718

Epoch: 5| Step: 3
Training loss: 1.6967573165893555
Validation loss: 2.115080247322718

Epoch: 5| Step: 4
Training loss: 1.0105617046356201
Validation loss: 2.1041210343440375

Epoch: 5| Step: 5
Training loss: 2.3203682899475098
Validation loss: 2.0905719995498657

Epoch: 5| Step: 6
Training loss: 1.6736557483673096
Validation loss: 2.130420987804731

Epoch: 5| Step: 7
Training loss: 1.432753086090088
Validation loss: 2.168224016825358

Epoch: 5| Step: 8
Training loss: 1.6351861953735352
Validation loss: 2.1233565906683602

Epoch: 5| Step: 9
Training loss: 2.3095524311065674
Validation loss: 2.120105723539988

Epoch: 5| Step: 10
Training loss: 1.3149003982543945
Validation loss: 2.156657228867213

Epoch: 5| Step: 11
Training loss: 0.36855900287628174
Validation loss: 2.1523383458455405

Epoch: 90| Step: 0
Training loss: 1.9309632778167725
Validation loss: 2.117418423295021

Epoch: 5| Step: 1
Training loss: 1.2331833839416504
Validation loss: 2.15472603837649

Epoch: 5| Step: 2
Training loss: 1.5680254697799683
Validation loss: 2.1368693510691323

Epoch: 5| Step: 3
Training loss: 1.860437035560608
Validation loss: 2.1844231287638345

Epoch: 5| Step: 4
Training loss: 1.9729945659637451
Validation loss: 2.150712475180626

Epoch: 5| Step: 5
Training loss: 1.8456203937530518
Validation loss: 2.117495576540629

Epoch: 5| Step: 6
Training loss: 1.9423468112945557
Validation loss: 2.0482280204693475

Epoch: 5| Step: 7
Training loss: 1.5301343202590942
Validation loss: 2.095872605840365

Epoch: 5| Step: 8
Training loss: 1.478271722793579
Validation loss: 2.088888888557752

Epoch: 5| Step: 9
Training loss: 1.4533430337905884
Validation loss: 2.117417812347412

Epoch: 5| Step: 10
Training loss: 1.3481870889663696
Validation loss: 2.1284273068110147

Epoch: 5| Step: 11
Training loss: 1.9690015316009521
Validation loss: 2.111223225792249

Epoch: 91| Step: 0
Training loss: 1.8175468444824219
Validation loss: 2.090905790527662

Epoch: 5| Step: 1
Training loss: 1.9912128448486328
Validation loss: 2.0990966260433197

Epoch: 5| Step: 2
Training loss: 2.03615403175354
Validation loss: 2.0882382094860077

Epoch: 5| Step: 3
Training loss: 1.4191322326660156
Validation loss: 2.0792745550473533

Epoch: 5| Step: 4
Training loss: 1.5412667989730835
Validation loss: 2.064000576734543

Epoch: 5| Step: 5
Training loss: 1.5631332397460938
Validation loss: 2.1161633481582007

Epoch: 5| Step: 6
Training loss: 1.633683443069458
Validation loss: 2.0767477999130883

Epoch: 5| Step: 7
Training loss: 1.8786563873291016
Validation loss: 2.1260542074839273

Epoch: 5| Step: 8
Training loss: 1.7884992361068726
Validation loss: 2.133322844902674

Epoch: 5| Step: 9
Training loss: 1.1528877019882202
Validation loss: 2.07877080142498

Epoch: 5| Step: 10
Training loss: 1.506247639656067
Validation loss: 2.098006700476011

Epoch: 5| Step: 11
Training loss: 1.7140264511108398
Validation loss: 2.1121086279551187

Epoch: 92| Step: 0
Training loss: 1.8056094646453857
Validation loss: 2.188989594578743

Epoch: 5| Step: 1
Training loss: 1.1470606327056885
Validation loss: 2.1550757586956024

Epoch: 5| Step: 2
Training loss: 1.6511354446411133
Validation loss: 2.167321110765139

Epoch: 5| Step: 3
Training loss: 1.316541075706482
Validation loss: 2.157498151063919

Epoch: 5| Step: 4
Training loss: 2.0489277839660645
Validation loss: 2.1300937136014304

Epoch: 5| Step: 5
Training loss: 1.409021258354187
Validation loss: 2.1201922545830407

Epoch: 5| Step: 6
Training loss: 1.3410546779632568
Validation loss: 2.1106702586015067

Epoch: 5| Step: 7
Training loss: 1.3723523616790771
Validation loss: 2.1650545448064804

Epoch: 5| Step: 8
Training loss: 2.0684421062469482
Validation loss: 2.1380865623553595

Epoch: 5| Step: 9
Training loss: 1.5194933414459229
Validation loss: 2.152520472804705

Epoch: 5| Step: 10
Training loss: 2.0912604331970215
Validation loss: 2.111797774831454

Epoch: 5| Step: 11
Training loss: 1.888486385345459
Validation loss: 2.1340205371379852

Epoch: 93| Step: 0
Training loss: 2.291194438934326
Validation loss: 2.1012008438507714

Epoch: 5| Step: 1
Training loss: 1.4810527563095093
Validation loss: 2.035011480251948

Epoch: 5| Step: 2
Training loss: 1.4174778461456299
Validation loss: 2.0627927780151367

Epoch: 5| Step: 3
Training loss: 2.0081162452697754
Validation loss: 2.081445266803106

Epoch: 5| Step: 4
Training loss: 1.4782583713531494
Validation loss: 2.1321932673454285

Epoch: 5| Step: 5
Training loss: 1.7037433385849
Validation loss: 2.0904556264479957

Epoch: 5| Step: 6
Training loss: 1.5862195491790771
Validation loss: 2.095920910437902

Epoch: 5| Step: 7
Training loss: 1.7711267471313477
Validation loss: 2.1967226713895798

Epoch: 5| Step: 8
Training loss: 1.6695104837417603
Validation loss: 2.133181720972061

Epoch: 5| Step: 9
Training loss: 1.9798004627227783
Validation loss: 2.2247002174456916

Epoch: 5| Step: 10
Training loss: 1.4542770385742188
Validation loss: 2.1459465672572455

Epoch: 5| Step: 11
Training loss: 1.7450037002563477
Validation loss: 2.136023923754692

Epoch: 94| Step: 0
Training loss: 1.049100637435913
Validation loss: 2.1599062979221344

Epoch: 5| Step: 1
Training loss: 1.0402545928955078
Validation loss: 2.1558629820744195

Epoch: 5| Step: 2
Training loss: 2.188938617706299
Validation loss: 2.1444822400808334

Epoch: 5| Step: 3
Training loss: 1.422680139541626
Validation loss: 2.1014149685700736

Epoch: 5| Step: 4
Training loss: 1.8647916316986084
Validation loss: 2.0747584849596024

Epoch: 5| Step: 5
Training loss: 1.7585086822509766
Validation loss: 2.0713619788487754

Epoch: 5| Step: 6
Training loss: 0.894203782081604
Validation loss: 2.0959055771430335

Epoch: 5| Step: 7
Training loss: 2.309018611907959
Validation loss: 2.0848742624123893

Epoch: 5| Step: 8
Training loss: 1.9165865182876587
Validation loss: 2.1185842752456665

Epoch: 5| Step: 9
Training loss: 1.8854907751083374
Validation loss: 2.157376597325007

Epoch: 5| Step: 10
Training loss: 1.7151321172714233
Validation loss: 2.0654415686925254

Epoch: 5| Step: 11
Training loss: 0.3957240581512451
Validation loss: 2.125388890504837

Epoch: 95| Step: 0
Training loss: 1.3315757513046265
Validation loss: 2.093261271715164

Epoch: 5| Step: 1
Training loss: 1.598740816116333
Validation loss: 2.170616790652275

Epoch: 5| Step: 2
Training loss: 1.2397899627685547
Validation loss: 2.085346649090449

Epoch: 5| Step: 3
Training loss: 1.7602951526641846
Validation loss: 2.034893731276194

Epoch: 5| Step: 4
Training loss: 2.0511934757232666
Validation loss: 2.087276592850685

Epoch: 5| Step: 5
Training loss: 1.7147926092147827
Validation loss: 2.125395511587461

Epoch: 5| Step: 6
Training loss: 1.8394333124160767
Validation loss: 2.0915959775447845

Epoch: 5| Step: 7
Training loss: 1.157111644744873
Validation loss: 2.1225090622901917

Epoch: 5| Step: 8
Training loss: 1.9102007150650024
Validation loss: 2.189599553743998

Epoch: 5| Step: 9
Training loss: 1.5211864709854126
Validation loss: 2.1477824548880258

Epoch: 5| Step: 10
Training loss: 1.944284200668335
Validation loss: 2.1929747611284256

Epoch: 5| Step: 11
Training loss: 2.3222451210021973
Validation loss: 2.2373169710238776

Epoch: 96| Step: 0
Training loss: 1.3162480592727661
Validation loss: 2.1376855621735253

Epoch: 5| Step: 1
Training loss: 1.0287214517593384
Validation loss: 2.0500718851884208

Epoch: 5| Step: 2
Training loss: 1.674517273902893
Validation loss: 2.0754391252994537

Epoch: 5| Step: 3
Training loss: 1.6515653133392334
Validation loss: 2.0964168856541314

Epoch: 5| Step: 4
Training loss: 1.6533348560333252
Validation loss: 2.055473248163859

Epoch: 5| Step: 5
Training loss: 2.102318286895752
Validation loss: 2.0965421199798584

Epoch: 5| Step: 6
Training loss: 1.8148472309112549
Validation loss: 2.117757032314936

Epoch: 5| Step: 7
Training loss: 1.468330979347229
Validation loss: 2.1157075613737106

Epoch: 5| Step: 8
Training loss: 1.965890645980835
Validation loss: 2.0715914269288382

Epoch: 5| Step: 9
Training loss: 1.40288507938385
Validation loss: 2.098065306742986

Epoch: 5| Step: 10
Training loss: 1.5143953561782837
Validation loss: 2.087673952182134

Epoch: 5| Step: 11
Training loss: 2.040558338165283
Validation loss: 2.1332121988137565

Epoch: 97| Step: 0
Training loss: 1.34427011013031
Validation loss: 2.2039477080106735

Epoch: 5| Step: 1
Training loss: 1.6749423742294312
Validation loss: 2.1958660235007605

Epoch: 5| Step: 2
Training loss: 1.9174846410751343
Validation loss: 2.273768494526545

Epoch: 5| Step: 3
Training loss: 1.8339160680770874
Validation loss: 2.266390641530355

Epoch: 5| Step: 4
Training loss: 1.3873097896575928
Validation loss: 2.263165613015493

Epoch: 5| Step: 5
Training loss: 1.4427133798599243
Validation loss: 2.1538128604491553

Epoch: 5| Step: 6
Training loss: 1.4598405361175537
Validation loss: 2.1621568302313485

Epoch: 5| Step: 7
Training loss: 1.6814578771591187
Validation loss: 2.0824898878733316

Epoch: 5| Step: 8
Training loss: 1.6565030813217163
Validation loss: 2.0624824663003287

Epoch: 5| Step: 9
Training loss: 2.3181004524230957
Validation loss: 2.0998622278372445

Epoch: 5| Step: 10
Training loss: 1.7249456644058228
Validation loss: 2.0842260221640267

Epoch: 5| Step: 11
Training loss: 1.8626911640167236
Validation loss: 2.0597707579533258

Epoch: 98| Step: 0
Training loss: 1.166799545288086
Validation loss: 2.0424841940402985

Epoch: 5| Step: 1
Training loss: 1.0395762920379639
Validation loss: 2.1201552053292594

Epoch: 5| Step: 2
Training loss: 1.2605854272842407
Validation loss: 2.0618340919415155

Epoch: 5| Step: 3
Training loss: 1.503820776939392
Validation loss: 2.1141063421964645

Epoch: 5| Step: 4
Training loss: 1.1583127975463867
Validation loss: 2.147626673181852

Epoch: 5| Step: 5
Training loss: 1.9143966436386108
Validation loss: 2.215233768026034

Epoch: 5| Step: 6
Training loss: 1.7247731685638428
Validation loss: 2.208926717440287

Epoch: 5| Step: 7
Training loss: 1.2596843242645264
Validation loss: 2.1704974472522736

Epoch: 5| Step: 8
Training loss: 1.5231064558029175
Validation loss: 2.1494299372037253

Epoch: 5| Step: 9
Training loss: 2.712844133377075
Validation loss: 2.1478028694788613

Epoch: 5| Step: 10
Training loss: 1.7809947729110718
Validation loss: 2.118436887860298

Epoch: 5| Step: 11
Training loss: 2.1096384525299072
Validation loss: 2.043136179447174

Epoch: 99| Step: 0
Training loss: 1.415527105331421
Validation loss: 2.097318187355995

Epoch: 5| Step: 1
Training loss: 1.6429065465927124
Validation loss: 2.037937824924787

Epoch: 5| Step: 2
Training loss: 1.812429428100586
Validation loss: 2.036802033583323

Epoch: 5| Step: 3
Training loss: 1.7774966955184937
Validation loss: 2.0869165509939194

Epoch: 5| Step: 4
Training loss: 1.4717137813568115
Validation loss: 2.0641897718111673

Epoch: 5| Step: 5
Training loss: 1.5492074489593506
Validation loss: 2.101334830125173

Epoch: 5| Step: 6
Training loss: 1.9340721368789673
Validation loss: 2.0698134352763495

Epoch: 5| Step: 7
Training loss: 1.7173330783843994
Validation loss: 2.0821905632813773

Epoch: 5| Step: 8
Training loss: 1.117638349533081
Validation loss: 2.076522315541903

Epoch: 5| Step: 9
Training loss: 1.7160637378692627
Validation loss: 2.112400601307551

Epoch: 5| Step: 10
Training loss: 1.9426143169403076
Validation loss: 2.1345941523710885

Epoch: 5| Step: 11
Training loss: 1.0694605112075806
Validation loss: 2.203694760799408

Epoch: 100| Step: 0
Training loss: 1.479220986366272
Validation loss: 2.2270478904247284

Epoch: 5| Step: 1
Training loss: 2.1065940856933594
Validation loss: 2.205271934469541

Epoch: 5| Step: 2
Training loss: 1.7480881214141846
Validation loss: 2.2236018081506095

Epoch: 5| Step: 3
Training loss: 1.7512775659561157
Validation loss: 2.140073001384735

Epoch: 5| Step: 4
Training loss: 1.7566537857055664
Validation loss: 2.107511262098948

Epoch: 5| Step: 5
Training loss: 1.8906456232070923
Validation loss: 2.09559266269207

Epoch: 5| Step: 6
Training loss: 1.0880497694015503
Validation loss: 2.0478869577248893

Epoch: 5| Step: 7
Training loss: 1.5762220621109009
Validation loss: 2.1012698958317437

Epoch: 5| Step: 8
Training loss: 1.2854276895523071
Validation loss: 2.085048114260038

Epoch: 5| Step: 9
Training loss: 1.4292534589767456
Validation loss: 2.039515639344851

Epoch: 5| Step: 10
Training loss: 1.8906034231185913
Validation loss: 2.08291890223821

Epoch: 5| Step: 11
Training loss: 1.0673707723617554
Validation loss: 2.1033686250448227

Epoch: 101| Step: 0
Training loss: 1.310159683227539
Validation loss: 2.0987846901019416

Epoch: 5| Step: 1
Training loss: 1.9087622165679932
Validation loss: 2.1098458021879196

Epoch: 5| Step: 2
Training loss: 1.9656562805175781
Validation loss: 2.1122892250617347

Epoch: 5| Step: 3
Training loss: 1.4272242784500122
Validation loss: 2.099654292066892

Epoch: 5| Step: 4
Training loss: 1.4159438610076904
Validation loss: 2.1294357677300773

Epoch: 5| Step: 5
Training loss: 1.5432751178741455
Validation loss: 2.1493559181690216

Epoch: 5| Step: 6
Training loss: 1.5159832239151
Validation loss: 2.076248680551847

Epoch: 5| Step: 7
Training loss: 1.2459341287612915
Validation loss: 2.0610215415557227

Epoch: 5| Step: 8
Training loss: 1.3062537908554077
Validation loss: 2.1781465808550515

Epoch: 5| Step: 9
Training loss: 1.5364354848861694
Validation loss: 2.098653828104337

Epoch: 5| Step: 10
Training loss: 2.206169605255127
Validation loss: 2.199555218219757

Epoch: 5| Step: 11
Training loss: 1.1500390768051147
Validation loss: 2.1783385972181954

Epoch: 102| Step: 0
Training loss: 1.7500593662261963
Validation loss: 2.2389347702264786

Epoch: 5| Step: 1
Training loss: 1.443503499031067
Validation loss: 2.1503548473119736

Epoch: 5| Step: 2
Training loss: 1.1614477634429932
Validation loss: 2.2041741013526917

Epoch: 5| Step: 3
Training loss: 1.3363018035888672
Validation loss: 2.2450721164544425

Epoch: 5| Step: 4
Training loss: 2.0539822578430176
Validation loss: 2.1499373614788055

Epoch: 5| Step: 5
Training loss: 1.5508270263671875
Validation loss: 2.1160328884919486

Epoch: 5| Step: 6
Training loss: 1.8862642049789429
Validation loss: 2.1639335304498672

Epoch: 5| Step: 7
Training loss: 1.4874035120010376
Validation loss: 2.1138823181390762

Epoch: 5| Step: 8
Training loss: 1.5874801874160767
Validation loss: 2.0383038073778152

Epoch: 5| Step: 9
Training loss: 1.3051283359527588
Validation loss: 2.082422137260437

Epoch: 5| Step: 10
Training loss: 1.9816672801971436
Validation loss: 2.0648553669452667

Epoch: 5| Step: 11
Training loss: 0.9825599193572998
Validation loss: 2.1008392572402954

Epoch: 103| Step: 0
Training loss: 1.6215507984161377
Validation loss: 2.113036980231603

Epoch: 5| Step: 1
Training loss: 1.0911319255828857
Validation loss: 2.0594847798347473

Epoch: 5| Step: 2
Training loss: 2.0166194438934326
Validation loss: 2.13624236981074

Epoch: 5| Step: 3
Training loss: 1.5920438766479492
Validation loss: 2.11310975253582

Epoch: 5| Step: 4
Training loss: 1.9048385620117188
Validation loss: 2.07457572221756

Epoch: 5| Step: 5
Training loss: 1.4863154888153076
Validation loss: 2.1408258428176246

Epoch: 5| Step: 6
Training loss: 1.7350616455078125
Validation loss: 2.170141542951266

Epoch: 5| Step: 7
Training loss: 1.3681081533432007
Validation loss: 2.1600403835376105

Epoch: 5| Step: 8
Training loss: 1.5001763105392456
Validation loss: 2.2260979215304055

Epoch: 5| Step: 9
Training loss: 1.2581347227096558
Validation loss: 2.0999250958363214

Epoch: 5| Step: 10
Training loss: 1.7418839931488037
Validation loss: 2.1856162349383035

Epoch: 5| Step: 11
Training loss: 2.1171069145202637
Validation loss: 2.140000805258751

Epoch: 104| Step: 0
Training loss: 1.6298863887786865
Validation loss: 2.144238273302714

Epoch: 5| Step: 1
Training loss: 2.397136926651001
Validation loss: 2.0523300419251123

Epoch: 5| Step: 2
Training loss: 1.3206150531768799
Validation loss: 2.099228948354721

Epoch: 5| Step: 3
Training loss: 1.3355591297149658
Validation loss: 2.11204140384992

Epoch: 5| Step: 4
Training loss: 1.8187415599822998
Validation loss: 2.090528200070063

Epoch: 5| Step: 5
Training loss: 1.3709373474121094
Validation loss: 2.1018528789281845

Epoch: 5| Step: 6
Training loss: 0.8647216558456421
Validation loss: 2.1229631503423056

Epoch: 5| Step: 7
Training loss: 1.651739478111267
Validation loss: 2.1557337939739227

Epoch: 5| Step: 8
Training loss: 2.6736226081848145
Validation loss: 2.168221046527227

Epoch: 5| Step: 9
Training loss: 1.6337473392486572
Validation loss: 2.1352702726920447

Epoch: 5| Step: 10
Training loss: 1.1391507387161255
Validation loss: 2.205746521552404

Epoch: 5| Step: 11
Training loss: 1.5586652755737305
Validation loss: 2.1501765747865043

Epoch: 105| Step: 0
Training loss: 1.1365755796432495
Validation loss: 2.107626428206762

Epoch: 5| Step: 1
Training loss: 1.6428836584091187
Validation loss: 2.056915154059728

Epoch: 5| Step: 2
Training loss: 1.4425883293151855
Validation loss: 2.0703360736370087

Epoch: 5| Step: 3
Training loss: 1.345994234085083
Validation loss: 2.0757534255584082

Epoch: 5| Step: 4
Training loss: 1.8168375492095947
Validation loss: 2.08072093129158

Epoch: 5| Step: 5
Training loss: 1.408395767211914
Validation loss: 2.084471399585406

Epoch: 5| Step: 6
Training loss: 1.3227450847625732
Validation loss: 2.0456955581903458

Epoch: 5| Step: 7
Training loss: 1.2527177333831787
Validation loss: 2.116923620303472

Epoch: 5| Step: 8
Training loss: 1.6863737106323242
Validation loss: 2.1087850828965506

Epoch: 5| Step: 9
Training loss: 2.5252413749694824
Validation loss: 2.0629669576883316

Epoch: 5| Step: 10
Training loss: 1.7144228219985962
Validation loss: 2.0936206579208374

Epoch: 5| Step: 11
Training loss: 0.739499568939209
Validation loss: 2.1205343951781592

Epoch: 106| Step: 0
Training loss: 1.5625663995742798
Validation loss: 2.1198378056287766

Epoch: 5| Step: 1
Training loss: 1.5344451665878296
Validation loss: 2.1338614324728646

Epoch: 5| Step: 2
Training loss: 1.7233364582061768
Validation loss: 2.1879058380921683

Epoch: 5| Step: 3
Training loss: 1.6041914224624634
Validation loss: 2.1690490792195

Epoch: 5| Step: 4
Training loss: 1.6066604852676392
Validation loss: 2.0613499532143273

Epoch: 5| Step: 5
Training loss: 1.7184242010116577
Validation loss: 2.034333889683088

Epoch: 5| Step: 6
Training loss: 0.7509190440177917
Validation loss: 2.0334245612223945

Epoch: 5| Step: 7
Training loss: 1.4570063352584839
Validation loss: 2.0570303797721863

Epoch: 5| Step: 8
Training loss: 1.468280553817749
Validation loss: 2.0568479895591736

Epoch: 5| Step: 9
Training loss: 2.0424246788024902
Validation loss: 2.067038282752037

Epoch: 5| Step: 10
Training loss: 1.49374258518219
Validation loss: 2.1645000129938126

Epoch: 5| Step: 11
Training loss: 1.8220610618591309
Validation loss: 2.1209829648335776

Epoch: 107| Step: 0
Training loss: 1.0423965454101562
Validation loss: 2.0597460766633353

Epoch: 5| Step: 1
Training loss: 1.1667602062225342
Validation loss: 2.1672265032927194

Epoch: 5| Step: 2
Training loss: 1.5682353973388672
Validation loss: 2.2074357668558755

Epoch: 5| Step: 3
Training loss: 1.687882423400879
Validation loss: 2.1960199177265167

Epoch: 5| Step: 4
Training loss: 1.4381221532821655
Validation loss: 2.0973383635282516

Epoch: 5| Step: 5
Training loss: 1.9263298511505127
Validation loss: 2.1491467903057733

Epoch: 5| Step: 6
Training loss: 2.176908016204834
Validation loss: 2.0487530132134757

Epoch: 5| Step: 7
Training loss: 1.6369447708129883
Validation loss: 2.170973002910614

Epoch: 5| Step: 8
Training loss: 1.1048269271850586
Validation loss: 2.126204272111257

Epoch: 5| Step: 9
Training loss: 1.5428440570831299
Validation loss: 2.1293381303548813

Epoch: 5| Step: 10
Training loss: 1.4310836791992188
Validation loss: 2.163267811139425

Epoch: 5| Step: 11
Training loss: 2.2451701164245605
Validation loss: 2.1262075006961823

Epoch: 108| Step: 0
Training loss: 1.3829206228256226
Validation loss: 2.129847447077433

Epoch: 5| Step: 1
Training loss: 2.029218912124634
Validation loss: 2.1280108590920768

Epoch: 5| Step: 2
Training loss: 1.69430410861969
Validation loss: 2.1262793888648353

Epoch: 5| Step: 3
Training loss: 1.7817986011505127
Validation loss: 2.1196037232875824

Epoch: 5| Step: 4
Training loss: 1.169097900390625
Validation loss: 2.0972365190585456

Epoch: 5| Step: 5
Training loss: 1.7253601551055908
Validation loss: 2.0873902092377343

Epoch: 5| Step: 6
Training loss: 1.2085870504379272
Validation loss: 2.073798576990763

Epoch: 5| Step: 7
Training loss: 1.3785778284072876
Validation loss: 2.091484636068344

Epoch: 5| Step: 8
Training loss: 1.9933574199676514
Validation loss: 2.1188962012529373

Epoch: 5| Step: 9
Training loss: 1.6783530712127686
Validation loss: 2.0599238872528076

Epoch: 5| Step: 10
Training loss: 0.878430962562561
Validation loss: 2.1356472174326577

Epoch: 5| Step: 11
Training loss: 0.6109719276428223
Validation loss: 2.1256412118673325

Epoch: 109| Step: 0
Training loss: 1.491957664489746
Validation loss: 2.162323842446009

Epoch: 5| Step: 1
Training loss: 0.9795879125595093
Validation loss: 2.100915804505348

Epoch: 5| Step: 2
Training loss: 1.7362596988677979
Validation loss: 2.1706308275461197

Epoch: 5| Step: 3
Training loss: 1.8491226434707642
Validation loss: 2.1052270233631134

Epoch: 5| Step: 4
Training loss: 1.8770294189453125
Validation loss: 2.08997251590093

Epoch: 5| Step: 5
Training loss: 0.818191409111023
Validation loss: 2.1424376368522644

Epoch: 5| Step: 6
Training loss: 1.400323510169983
Validation loss: 2.123235513766607

Epoch: 5| Step: 7
Training loss: 1.2970564365386963
Validation loss: 2.0339400519927344

Epoch: 5| Step: 8
Training loss: 1.969560980796814
Validation loss: 2.1068227738142014

Epoch: 5| Step: 9
Training loss: 1.305681824684143
Validation loss: 2.1498097578684487

Epoch: 5| Step: 10
Training loss: 1.5041481256484985
Validation loss: 2.0782152314980826

Epoch: 5| Step: 11
Training loss: 2.3926968574523926
Validation loss: 2.070869187513987

Epoch: 110| Step: 0
Training loss: 1.0675047636032104
Validation loss: 2.118882417678833

Epoch: 5| Step: 1
Training loss: 1.5578380823135376
Validation loss: 2.0691962788502374

Epoch: 5| Step: 2
Training loss: 1.5626165866851807
Validation loss: 2.0058831026156745

Epoch: 5| Step: 3
Training loss: 1.1528637409210205
Validation loss: 2.1240601539611816

Epoch: 5| Step: 4
Training loss: 1.3718219995498657
Validation loss: 2.0046342660983405

Epoch: 5| Step: 5
Training loss: 1.480960726737976
Validation loss: 2.096434305111567

Epoch: 5| Step: 6
Training loss: 1.2839064598083496
Validation loss: 2.141494482755661

Epoch: 5| Step: 7
Training loss: 1.4949051141738892
Validation loss: 2.0636080553134284

Epoch: 5| Step: 8
Training loss: 1.7795603275299072
Validation loss: 2.0641582012176514

Epoch: 5| Step: 9
Training loss: 2.0432326793670654
Validation loss: 2.028284475207329

Epoch: 5| Step: 10
Training loss: 1.6417394876480103
Validation loss: 2.0279049376646676

Epoch: 5| Step: 11
Training loss: 0.30336129665374756
Validation loss: 2.0834221293528876

Epoch: 111| Step: 0
Training loss: 1.7637847661972046
Validation loss: 2.094534789522489

Epoch: 5| Step: 1
Training loss: 1.531834363937378
Validation loss: 2.150054842233658

Epoch: 5| Step: 2
Training loss: 2.0434165000915527
Validation loss: 2.195168510079384

Epoch: 5| Step: 3
Training loss: 1.249126672744751
Validation loss: 2.15596013267835

Epoch: 5| Step: 4
Training loss: 1.201885461807251
Validation loss: 2.1297992716232934

Epoch: 5| Step: 5
Training loss: 1.5598962306976318
Validation loss: 2.0940510034561157

Epoch: 5| Step: 6
Training loss: 1.6931530237197876
Validation loss: 2.061349262793859

Epoch: 5| Step: 7
Training loss: 1.4288098812103271
Validation loss: 2.1206558694442115

Epoch: 5| Step: 8
Training loss: 1.262779712677002
Validation loss: 2.0505327035983405

Epoch: 5| Step: 9
Training loss: 1.1282994747161865
Validation loss: 2.135836362838745

Epoch: 5| Step: 10
Training loss: 1.3840563297271729
Validation loss: 2.184598152836164

Epoch: 5| Step: 11
Training loss: 1.3081691265106201
Validation loss: 2.1576188455025354

Epoch: 112| Step: 0
Training loss: 1.3898704051971436
Validation loss: 2.131118983030319

Epoch: 5| Step: 1
Training loss: 1.5274978876113892
Validation loss: 2.1862538357575736

Epoch: 5| Step: 2
Training loss: 1.2352015972137451
Validation loss: 2.1340649177630744

Epoch: 5| Step: 3
Training loss: 1.412978172302246
Validation loss: 2.1191617945830026

Epoch: 5| Step: 4
Training loss: 1.539598822593689
Validation loss: 2.1324459413687387

Epoch: 5| Step: 5
Training loss: 1.4815800189971924
Validation loss: 2.0825726240873337

Epoch: 5| Step: 6
Training loss: 1.172868013381958
Validation loss: 2.0690144995848336

Epoch: 5| Step: 7
Training loss: 1.75554621219635
Validation loss: 1.981501926978429

Epoch: 5| Step: 8
Training loss: 1.6761627197265625
Validation loss: 2.0259340554475784

Epoch: 5| Step: 9
Training loss: 1.530949354171753
Validation loss: 2.0271110832691193

Epoch: 5| Step: 10
Training loss: 1.5246124267578125
Validation loss: 2.1222259451945624

Epoch: 5| Step: 11
Training loss: 1.0349133014678955
Validation loss: 2.135813350478808

Epoch: 113| Step: 0
Training loss: 1.379314661026001
Validation loss: 2.072106177608172

Epoch: 5| Step: 1
Training loss: 1.5367701053619385
Validation loss: 2.1702067951361337

Epoch: 5| Step: 2
Training loss: 1.6327540874481201
Validation loss: 2.1044400533040366

Epoch: 5| Step: 3
Training loss: 1.2202160358428955
Validation loss: 2.0482060313224792

Epoch: 5| Step: 4
Training loss: 1.1927155256271362
Validation loss: 2.049961576859156

Epoch: 5| Step: 5
Training loss: 1.5359516143798828
Validation loss: 2.095969100793203

Epoch: 5| Step: 6
Training loss: 1.2970974445343018
Validation loss: 2.138356998562813

Epoch: 5| Step: 7
Training loss: 1.7622110843658447
Validation loss: 2.147577648361524

Epoch: 5| Step: 8
Training loss: 1.0216333866119385
Validation loss: 2.1936733971039453

Epoch: 5| Step: 9
Training loss: 1.5611330270767212
Validation loss: 2.155843118826548

Epoch: 5| Step: 10
Training loss: 1.7945188283920288
Validation loss: 2.2410582502683005

Epoch: 5| Step: 11
Training loss: 0.9726828336715698
Validation loss: 2.174232706427574

Epoch: 114| Step: 0
Training loss: 1.09345543384552
Validation loss: 2.138595993320147

Epoch: 5| Step: 1
Training loss: 1.8029203414916992
Validation loss: 2.202489743630091

Epoch: 5| Step: 2
Training loss: 1.5725988149642944
Validation loss: 2.253917167584101

Epoch: 5| Step: 3
Training loss: 1.0307713747024536
Validation loss: 2.1650704592466354

Epoch: 5| Step: 4
Training loss: 1.645247459411621
Validation loss: 2.175787781675657

Epoch: 5| Step: 5
Training loss: 1.40142023563385
Validation loss: 2.117346247037252

Epoch: 5| Step: 6
Training loss: 1.8144404888153076
Validation loss: 2.0742669999599457

Epoch: 5| Step: 7
Training loss: 1.1901178359985352
Validation loss: 2.0677825113137565

Epoch: 5| Step: 8
Training loss: 1.8803634643554688
Validation loss: 2.073869456847509

Epoch: 5| Step: 9
Training loss: 1.739050269126892
Validation loss: 2.0710556507110596

Epoch: 5| Step: 10
Training loss: 1.7313886880874634
Validation loss: 2.051227221886317

Epoch: 5| Step: 11
Training loss: 1.0438258647918701
Validation loss: 2.0933476040760675

Epoch: 115| Step: 0
Training loss: 1.6099773645401
Validation loss: 2.132106825709343

Epoch: 5| Step: 1
Training loss: 1.1812102794647217
Validation loss: 2.190921609600385

Epoch: 5| Step: 2
Training loss: 1.6464086771011353
Validation loss: 2.1246505876382193

Epoch: 5| Step: 3
Training loss: 1.1904717683792114
Validation loss: 2.220843364795049

Epoch: 5| Step: 4
Training loss: 1.5786936283111572
Validation loss: 2.307262048125267

Epoch: 5| Step: 5
Training loss: 1.2624400854110718
Validation loss: 2.243988280495008

Epoch: 5| Step: 6
Training loss: 1.3825092315673828
Validation loss: 2.2396374543507895

Epoch: 5| Step: 7
Training loss: 1.3708107471466064
Validation loss: 2.125258758664131

Epoch: 5| Step: 8
Training loss: 1.7126796245574951
Validation loss: 2.140771523118019

Epoch: 5| Step: 9
Training loss: 1.5348838567733765
Validation loss: 2.097165673971176

Epoch: 5| Step: 10
Training loss: 1.9218385219573975
Validation loss: 2.127020056049029

Epoch: 5| Step: 11
Training loss: 1.6392714977264404
Validation loss: 2.077368532617887

Epoch: 116| Step: 0
Training loss: 1.2845414876937866
Validation loss: 2.1014424562454224

Epoch: 5| Step: 1
Training loss: 1.1551034450531006
Validation loss: 2.1572991808255515

Epoch: 5| Step: 2
Training loss: 1.1942899227142334
Validation loss: 2.1253968278566995

Epoch: 5| Step: 3
Training loss: 1.4697777032852173
Validation loss: 2.102219065030416

Epoch: 5| Step: 4
Training loss: 1.4747145175933838
Validation loss: 2.1204364647467933

Epoch: 5| Step: 5
Training loss: 1.5215551853179932
Validation loss: 2.035181204477946

Epoch: 5| Step: 6
Training loss: 1.317551851272583
Validation loss: 2.171694094936053

Epoch: 5| Step: 7
Training loss: 1.7316879034042358
Validation loss: 2.088240002592405

Epoch: 5| Step: 8
Training loss: 1.6538629531860352
Validation loss: 2.0557682116826377

Epoch: 5| Step: 9
Training loss: 1.517571210861206
Validation loss: 2.0735029876232147

Epoch: 5| Step: 10
Training loss: 1.19110107421875
Validation loss: 2.129181827108065

Epoch: 5| Step: 11
Training loss: 0.504923939704895
Validation loss: 2.150181919336319

Epoch: 117| Step: 0
Training loss: 1.6341346502304077
Validation loss: 2.2207623620827994

Epoch: 5| Step: 1
Training loss: 1.2319334745407104
Validation loss: 2.25655934214592

Epoch: 5| Step: 2
Training loss: 1.0146915912628174
Validation loss: 2.250031833847364

Epoch: 5| Step: 3
Training loss: 1.8652054071426392
Validation loss: 2.189968387285868

Epoch: 5| Step: 4
Training loss: 1.2447583675384521
Validation loss: 2.148657197753588

Epoch: 5| Step: 5
Training loss: 1.7018320560455322
Validation loss: 2.17193869749705

Epoch: 5| Step: 6
Training loss: 1.7184473276138306
Validation loss: 2.0783262699842453

Epoch: 5| Step: 7
Training loss: 1.3016083240509033
Validation loss: 2.125121057033539

Epoch: 5| Step: 8
Training loss: 1.3286452293395996
Validation loss: 2.1353268772363663

Epoch: 5| Step: 9
Training loss: 1.245956301689148
Validation loss: 2.0819332003593445

Epoch: 5| Step: 10
Training loss: 1.34759521484375
Validation loss: 2.085733105738958

Epoch: 5| Step: 11
Training loss: 1.5012489557266235
Validation loss: 2.053004269798597

Epoch: 118| Step: 0
Training loss: 1.8077094554901123
Validation loss: 2.083941489458084

Epoch: 5| Step: 1
Training loss: 1.4620437622070312
Validation loss: 2.1435409684975943

Epoch: 5| Step: 2
Training loss: 1.42044997215271
Validation loss: 2.166115641593933

Epoch: 5| Step: 3
Training loss: 1.2538388967514038
Validation loss: 2.159906973441442

Epoch: 5| Step: 4
Training loss: 1.2882674932479858
Validation loss: 2.1824720948934555

Epoch: 5| Step: 5
Training loss: 1.1388393640518188
Validation loss: 2.1699141760667167

Epoch: 5| Step: 6
Training loss: 0.915192723274231
Validation loss: 2.199599956472715

Epoch: 5| Step: 7
Training loss: 1.830360770225525
Validation loss: 2.175945982336998

Epoch: 5| Step: 8
Training loss: 0.945779025554657
Validation loss: 2.193326731522878

Epoch: 5| Step: 9
Training loss: 1.8226261138916016
Validation loss: 2.2603828608989716

Epoch: 5| Step: 10
Training loss: 1.329610824584961
Validation loss: 2.152227212985357

Epoch: 5| Step: 11
Training loss: 1.2846962213516235
Validation loss: 2.13891830543677

Epoch: 119| Step: 0
Training loss: 1.5692393779754639
Validation loss: 2.063493311405182

Epoch: 5| Step: 1
Training loss: 1.2411413192749023
Validation loss: 2.039974336822828

Epoch: 5| Step: 2
Training loss: 1.5074217319488525
Validation loss: 2.0953923910856247

Epoch: 5| Step: 3
Training loss: 1.1321420669555664
Validation loss: 2.096706986427307

Epoch: 5| Step: 4
Training loss: 0.9883871078491211
Validation loss: 2.091281553109487

Epoch: 5| Step: 5
Training loss: 1.3316552639007568
Validation loss: 2.169300079345703

Epoch: 5| Step: 6
Training loss: 1.4614803791046143
Validation loss: 2.153464754422506

Epoch: 5| Step: 7
Training loss: 1.3254196643829346
Validation loss: 2.238559052348137

Epoch: 5| Step: 8
Training loss: 1.4167656898498535
Validation loss: 2.2838906745115914

Epoch: 5| Step: 9
Training loss: 2.160313367843628
Validation loss: 2.2207271258036294

Epoch: 5| Step: 10
Training loss: 1.8367122411727905
Validation loss: 2.1729454497496286

Epoch: 5| Step: 11
Training loss: 1.3410584926605225
Validation loss: 2.1411071568727493

Epoch: 120| Step: 0
Training loss: 1.4423139095306396
Validation loss: 2.0808162043492

Epoch: 5| Step: 1
Training loss: 1.2268551588058472
Validation loss: 2.0013155539830527

Epoch: 5| Step: 2
Training loss: 1.6891508102416992
Validation loss: 2.0409087985754013

Epoch: 5| Step: 3
Training loss: 1.0054000616073608
Validation loss: 2.070196901758512

Epoch: 5| Step: 4
Training loss: 1.7637039422988892
Validation loss: 2.0391940673192344

Epoch: 5| Step: 5
Training loss: 1.2148351669311523
Validation loss: 2.0653218080600104

Epoch: 5| Step: 6
Training loss: 1.5770587921142578
Validation loss: 2.1471068362394967

Epoch: 5| Step: 7
Training loss: 1.4840872287750244
Validation loss: 2.1672183672587075

Epoch: 5| Step: 8
Training loss: 1.7081167697906494
Validation loss: 2.2046088675657907

Epoch: 5| Step: 9
Training loss: 1.496147871017456
Validation loss: 2.227152014772097

Epoch: 5| Step: 10
Training loss: 0.998191237449646
Validation loss: 2.2414487103621163

Epoch: 5| Step: 11
Training loss: 1.5993282794952393
Validation loss: 2.224841753641764

Epoch: 121| Step: 0
Training loss: 1.575158715248108
Validation loss: 2.247955550750097

Epoch: 5| Step: 1
Training loss: 1.737043023109436
Validation loss: 2.1104931284983954

Epoch: 5| Step: 2
Training loss: 1.1307151317596436
Validation loss: 2.1021190732717514

Epoch: 5| Step: 3
Training loss: 1.127089500427246
Validation loss: 2.0906061232089996

Epoch: 5| Step: 4
Training loss: 1.598650336265564
Validation loss: 2.086276034514109

Epoch: 5| Step: 5
Training loss: 1.150668740272522
Validation loss: 2.066068852941195

Epoch: 5| Step: 6
Training loss: 1.3324952125549316
Validation loss: 2.0827550192674003

Epoch: 5| Step: 7
Training loss: 1.1507782936096191
Validation loss: 2.095294957359632

Epoch: 5| Step: 8
Training loss: 1.3772499561309814
Validation loss: 2.0816613783439

Epoch: 5| Step: 9
Training loss: 1.1308116912841797
Validation loss: 2.142796834309896

Epoch: 5| Step: 10
Training loss: 1.75148606300354
Validation loss: 2.184161146481832

Epoch: 5| Step: 11
Training loss: 3.0322742462158203
Validation loss: 2.219773923357328

Epoch: 122| Step: 0
Training loss: 1.428543210029602
Validation loss: 2.187714139620463

Epoch: 5| Step: 1
Training loss: 1.416020393371582
Validation loss: 2.137473260362943

Epoch: 5| Step: 2
Training loss: 0.799893856048584
Validation loss: 2.098115344842275

Epoch: 5| Step: 3
Training loss: 1.376600980758667
Validation loss: 2.131770213445028

Epoch: 5| Step: 4
Training loss: 1.5061204433441162
Validation loss: 2.0764804681142173

Epoch: 5| Step: 5
Training loss: 1.0599932670593262
Validation loss: 2.107360621293386

Epoch: 5| Step: 6
Training loss: 1.8002983331680298
Validation loss: 2.0645354787508645

Epoch: 5| Step: 7
Training loss: 1.1490709781646729
Validation loss: 2.0389786859353385

Epoch: 5| Step: 8
Training loss: 1.9227555990219116
Validation loss: 2.091238538424174

Epoch: 5| Step: 9
Training loss: 1.7637630701065063
Validation loss: 2.116968264182409

Epoch: 5| Step: 10
Training loss: 1.0868852138519287
Validation loss: 2.186509132385254

Epoch: 5| Step: 11
Training loss: 0.9460635781288147
Validation loss: 2.202686736981074

Epoch: 123| Step: 0
Training loss: 1.322938323020935
Validation loss: 2.1866650134325027

Epoch: 5| Step: 1
Training loss: 1.9044853448867798
Validation loss: 2.265408525864283

Epoch: 5| Step: 2
Training loss: 1.341783881187439
Validation loss: 2.2845818201700845

Epoch: 5| Step: 3
Training loss: 1.3846173286437988
Validation loss: 2.257813344399134

Epoch: 5| Step: 4
Training loss: 0.9303987622261047
Validation loss: 2.186853970090548

Epoch: 5| Step: 5
Training loss: 1.2617212533950806
Validation loss: 2.118186672528585

Epoch: 5| Step: 6
Training loss: 1.6201868057250977
Validation loss: 2.132062554359436

Epoch: 5| Step: 7
Training loss: 1.2447761297225952
Validation loss: 2.022095109025637

Epoch: 5| Step: 8
Training loss: 1.2057878971099854
Validation loss: 2.1234006037314734

Epoch: 5| Step: 9
Training loss: 1.4496190547943115
Validation loss: 2.120646600921949

Epoch: 5| Step: 10
Training loss: 1.392564058303833
Validation loss: 2.0860239615043006

Epoch: 5| Step: 11
Training loss: 0.7708218097686768
Validation loss: 2.1167891373236976

Epoch: 124| Step: 0
Training loss: 1.109470009803772
Validation loss: 2.137607683738073

Epoch: 5| Step: 1
Training loss: 1.3407922983169556
Validation loss: 2.1591317703326545

Epoch: 5| Step: 2
Training loss: 1.007359266281128
Validation loss: 2.1794088383515677

Epoch: 5| Step: 3
Training loss: 1.139171838760376
Validation loss: 2.3259834249814353

Epoch: 5| Step: 4
Training loss: 1.9284963607788086
Validation loss: 2.243464320898056

Epoch: 5| Step: 5
Training loss: 1.2737510204315186
Validation loss: 2.235013951857885

Epoch: 5| Step: 6
Training loss: 1.770861268043518
Validation loss: 2.202373370528221

Epoch: 5| Step: 7
Training loss: 1.6748638153076172
Validation loss: 2.110532527168592

Epoch: 5| Step: 8
Training loss: 1.47133469581604
Validation loss: 2.1099355767170587

Epoch: 5| Step: 9
Training loss: 1.2059158086776733
Validation loss: 2.064351816972097

Epoch: 5| Step: 10
Training loss: 1.406386375427246
Validation loss: 2.0166484167178473

Epoch: 5| Step: 11
Training loss: 1.325195074081421
Validation loss: 2.1257957071065903

Epoch: 125| Step: 0
Training loss: 1.1900709867477417
Validation loss: 2.082234894235929

Epoch: 5| Step: 1
Training loss: 1.5209203958511353
Validation loss: 2.1571307679017386

Epoch: 5| Step: 2
Training loss: 1.2600033283233643
Validation loss: 2.144558529059092

Epoch: 5| Step: 3
Training loss: 1.530884027481079
Validation loss: 2.1648104041814804

Epoch: 5| Step: 4
Training loss: 1.2840006351470947
Validation loss: 2.160049483180046

Epoch: 5| Step: 5
Training loss: 1.455082654953003
Validation loss: 2.1994277437527976

Epoch: 5| Step: 6
Training loss: 1.0318721532821655
Validation loss: 2.2590907414754233

Epoch: 5| Step: 7
Training loss: 1.4502484798431396
Validation loss: 2.2110168735186257

Epoch: 5| Step: 8
Training loss: 1.1305930614471436
Validation loss: 2.245245029528936

Epoch: 5| Step: 9
Training loss: 1.8956019878387451
Validation loss: 2.1550531586011252

Epoch: 5| Step: 10
Training loss: 1.293609380722046
Validation loss: 2.1003845185041428

Epoch: 5| Step: 11
Training loss: 0.9708657264709473
Validation loss: 2.074322685599327

Epoch: 126| Step: 0
Training loss: 1.7624839544296265
Validation loss: 2.0611123541990914

Epoch: 5| Step: 1
Training loss: 1.5482590198516846
Validation loss: 2.068670004606247

Epoch: 5| Step: 2
Training loss: 1.6625341176986694
Validation loss: 2.1085952123006186

Epoch: 5| Step: 3
Training loss: 1.4092049598693848
Validation loss: 2.063256005446116

Epoch: 5| Step: 4
Training loss: 1.2413933277130127
Validation loss: 2.042017469803492

Epoch: 5| Step: 5
Training loss: 1.376813292503357
Validation loss: 2.0082791994015374

Epoch: 5| Step: 6
Training loss: 1.4540950059890747
Validation loss: 2.064599931240082

Epoch: 5| Step: 7
Training loss: 1.0478111505508423
Validation loss: 2.1689670781294503

Epoch: 5| Step: 8
Training loss: 1.1488323211669922
Validation loss: 2.166336933771769

Epoch: 5| Step: 9
Training loss: 0.8123809695243835
Validation loss: 2.2290053566296897

Epoch: 5| Step: 10
Training loss: 1.2352479696273804
Validation loss: 2.237702339887619

Epoch: 5| Step: 11
Training loss: 0.4429662227630615
Validation loss: 2.230148653189341

Epoch: 127| Step: 0
Training loss: 1.3873875141143799
Validation loss: 2.2442888766527176

Epoch: 5| Step: 1
Training loss: 1.5150020122528076
Validation loss: 2.1516202489535012

Epoch: 5| Step: 2
Training loss: 1.4575703144073486
Validation loss: 2.0816538482904434

Epoch: 5| Step: 3
Training loss: 1.7257721424102783
Validation loss: 2.0959967275460563

Epoch: 5| Step: 4
Training loss: 1.4798866510391235
Validation loss: 2.0488702009121575

Epoch: 5| Step: 5
Training loss: 1.029295563697815
Validation loss: 2.121712123354276

Epoch: 5| Step: 6
Training loss: 1.1220347881317139
Validation loss: 2.080496067802111

Epoch: 5| Step: 7
Training loss: 1.5449368953704834
Validation loss: 2.1164645006259284

Epoch: 5| Step: 8
Training loss: 1.5536651611328125
Validation loss: 2.0614736825227737

Epoch: 5| Step: 9
Training loss: 0.9687126874923706
Validation loss: 2.076764608422915

Epoch: 5| Step: 10
Training loss: 1.2214577198028564
Validation loss: 2.1446644167105355

Epoch: 5| Step: 11
Training loss: 1.4581456184387207
Validation loss: 2.1210768024126687

Epoch: 128| Step: 0
Training loss: 1.8001600503921509
Validation loss: 2.1882364004850388

Epoch: 5| Step: 1
Training loss: 1.3813793659210205
Validation loss: 2.173528586824735

Epoch: 5| Step: 2
Training loss: 1.6404603719711304
Validation loss: 2.1481997470060983

Epoch: 5| Step: 3
Training loss: 0.7850330471992493
Validation loss: 2.1056892424821854

Epoch: 5| Step: 4
Training loss: 1.47853684425354
Validation loss: 2.1175189365943274

Epoch: 5| Step: 5
Training loss: 1.0251227617263794
Validation loss: 2.052936941385269

Epoch: 5| Step: 6
Training loss: 1.406214714050293
Validation loss: 2.130738581220309

Epoch: 5| Step: 7
Training loss: 1.0770998001098633
Validation loss: 2.1125409255425134

Epoch: 5| Step: 8
Training loss: 1.7840131521224976
Validation loss: 2.13967564702034

Epoch: 5| Step: 9
Training loss: 0.899919867515564
Validation loss: 2.09797336657842

Epoch: 5| Step: 10
Training loss: 1.1620169878005981
Validation loss: 2.146714280049006

Epoch: 5| Step: 11
Training loss: 0.6321357488632202
Validation loss: 2.117501919468244

Epoch: 129| Step: 0
Training loss: 1.072800636291504
Validation loss: 2.151511028409004

Epoch: 5| Step: 1
Training loss: 1.0702555179595947
Validation loss: 2.2139090100924173

Epoch: 5| Step: 2
Training loss: 1.1188831329345703
Validation loss: 2.1974564542373023

Epoch: 5| Step: 3
Training loss: 1.4094517230987549
Validation loss: 2.1641110678513846

Epoch: 5| Step: 4
Training loss: 1.439887285232544
Validation loss: 2.118855188290278

Epoch: 5| Step: 5
Training loss: 1.250856637954712
Validation loss: 2.0678036312262216

Epoch: 5| Step: 6
Training loss: 1.3884299993515015
Validation loss: 2.1455893168846765

Epoch: 5| Step: 7
Training loss: 1.299745798110962
Validation loss: 2.1399885515371957

Epoch: 5| Step: 8
Training loss: 1.3175371885299683
Validation loss: 2.1300113052129745

Epoch: 5| Step: 9
Training loss: 1.1535577774047852
Validation loss: 2.151454364260038

Epoch: 5| Step: 10
Training loss: 1.2411829233169556
Validation loss: 2.1658245027065277

Epoch: 5| Step: 11
Training loss: 1.6116187572479248
Validation loss: 2.219270557165146

Epoch: 130| Step: 0
Training loss: 1.5040940046310425
Validation loss: 2.1870540380477905

Epoch: 5| Step: 1
Training loss: 1.7296737432479858
Validation loss: 2.0893136113882065

Epoch: 5| Step: 2
Training loss: 1.135746955871582
Validation loss: 2.1486250857512155

Epoch: 5| Step: 3
Training loss: 0.7642189860343933
Validation loss: 2.166873514652252

Epoch: 5| Step: 4
Training loss: 1.7859140634536743
Validation loss: 2.0760621080795922

Epoch: 5| Step: 5
Training loss: 1.4759927988052368
Validation loss: 2.1414112647374473

Epoch: 5| Step: 6
Training loss: 1.4511587619781494
Validation loss: 2.0653482228517532

Epoch: 5| Step: 7
Training loss: 0.9296326637268066
Validation loss: 2.188530961672465

Epoch: 5| Step: 8
Training loss: 1.3661645650863647
Validation loss: 2.1915522317091622

Epoch: 5| Step: 9
Training loss: 1.122815728187561
Validation loss: 2.22438116868337

Epoch: 5| Step: 10
Training loss: 0.8595808148384094
Validation loss: 2.1699192573626838

Epoch: 5| Step: 11
Training loss: 1.4921057224273682
Validation loss: 2.2736836473147073

Epoch: 131| Step: 0
Training loss: 1.7529780864715576
Validation loss: 2.290257046620051

Epoch: 5| Step: 1
Training loss: 1.5965759754180908
Validation loss: 2.2876238226890564

Epoch: 5| Step: 2
Training loss: 1.3061504364013672
Validation loss: 2.3134772380193076

Epoch: 5| Step: 3
Training loss: 1.2659635543823242
Validation loss: 2.1996212551991143

Epoch: 5| Step: 4
Training loss: 1.171500325202942
Validation loss: 2.1721493303775787

Epoch: 5| Step: 5
Training loss: 1.2503869533538818
Validation loss: 2.1357896576325097

Epoch: 5| Step: 6
Training loss: 1.3133065700531006
Validation loss: 2.124674300352732

Epoch: 5| Step: 7
Training loss: 1.3741042613983154
Validation loss: 2.0416580537954965

Epoch: 5| Step: 8
Training loss: 1.1470032930374146
Validation loss: 2.0664245635271072

Epoch: 5| Step: 9
Training loss: 1.1325069665908813
Validation loss: 2.0701396415630975

Epoch: 5| Step: 10
Training loss: 1.5174872875213623
Validation loss: 2.151093691587448

Epoch: 5| Step: 11
Training loss: 1.321038842201233
Validation loss: 2.154935359954834

Epoch: 132| Step: 0
Training loss: 1.7389580011367798
Validation loss: 2.239687060316404

Epoch: 5| Step: 1
Training loss: 1.3983395099639893
Validation loss: 2.2512222776810327

Epoch: 5| Step: 2
Training loss: 1.5006766319274902
Validation loss: 2.1877614011367164

Epoch: 5| Step: 3
Training loss: 1.5606460571289062
Validation loss: 2.1662770907084146

Epoch: 5| Step: 4
Training loss: 1.1691006422042847
Validation loss: 2.062881752848625

Epoch: 5| Step: 5
Training loss: 0.725898265838623
Validation loss: 2.1654420097668967

Epoch: 5| Step: 6
Training loss: 0.8458982706069946
Validation loss: 2.158618996540705

Epoch: 5| Step: 7
Training loss: 1.5469214916229248
Validation loss: 2.1159918010234833

Epoch: 5| Step: 8
Training loss: 1.290888786315918
Validation loss: 2.1101477344830832

Epoch: 5| Step: 9
Training loss: 0.8395625948905945
Validation loss: 2.11382723848025

Epoch: 5| Step: 10
Training loss: 1.040755033493042
Validation loss: 2.0851049423217773

Epoch: 5| Step: 11
Training loss: 0.4017658829689026
Validation loss: 2.1861822456121445

Epoch: 133| Step: 0
Training loss: 1.0396326780319214
Validation loss: 2.1621826936801276

Epoch: 5| Step: 1
Training loss: 0.8619257807731628
Validation loss: 2.2404662470022836

Epoch: 5| Step: 2
Training loss: 0.9156616926193237
Validation loss: 2.1481411457061768

Epoch: 5| Step: 3
Training loss: 1.2049553394317627
Validation loss: 2.170795460542043

Epoch: 5| Step: 4
Training loss: 1.456703543663025
Validation loss: 2.190571447213491

Epoch: 5| Step: 5
Training loss: 1.3543715476989746
Validation loss: 2.1006109714508057

Epoch: 5| Step: 6
Training loss: 1.1000854969024658
Validation loss: 2.0347554981708527

Epoch: 5| Step: 7
Training loss: 1.4771499633789062
Validation loss: 2.111661563316981

Epoch: 5| Step: 8
Training loss: 1.459307312965393
Validation loss: 2.0943041890859604

Epoch: 5| Step: 9
Training loss: 1.7788703441619873
Validation loss: 2.0686771472295127

Epoch: 5| Step: 10
Training loss: 0.9270375967025757
Validation loss: 2.141980359951655

Epoch: 5| Step: 11
Training loss: 0.8021048307418823
Validation loss: 2.0966943403085074

Epoch: 134| Step: 0
Training loss: 0.9625817537307739
Validation loss: 2.2890356481075287

Epoch: 5| Step: 1
Training loss: 1.5987515449523926
Validation loss: 2.3749190072218576

Epoch: 5| Step: 2
Training loss: 1.287050724029541
Validation loss: 2.490538736184438

Epoch: 5| Step: 3
Training loss: 1.7473599910736084
Validation loss: 2.493307054042816

Epoch: 5| Step: 4
Training loss: 1.322812795639038
Validation loss: 2.428705374399821

Epoch: 5| Step: 5
Training loss: 1.8577877283096313
Validation loss: 2.3392174442609153

Epoch: 5| Step: 6
Training loss: 1.2765144109725952
Validation loss: 2.2772821485996246

Epoch: 5| Step: 7
Training loss: 1.0809268951416016
Validation loss: 2.163773958881696

Epoch: 5| Step: 8
Training loss: 1.0678174495697021
Validation loss: 2.082590321699778

Epoch: 5| Step: 9
Training loss: 1.5338075160980225
Validation loss: 2.1107636193434396

Epoch: 5| Step: 10
Training loss: 1.4595080614089966
Validation loss: 2.0823833644390106

Epoch: 5| Step: 11
Training loss: 0.9060607552528381
Validation loss: 2.1065911799669266

Epoch: 135| Step: 0
Training loss: 1.9397541284561157
Validation loss: 2.0944297512372336

Epoch: 5| Step: 1
Training loss: 1.6834089756011963
Validation loss: 2.142247900366783

Epoch: 5| Step: 2
Training loss: 1.4784129858016968
Validation loss: 2.0899731715520224

Epoch: 5| Step: 3
Training loss: 1.375412106513977
Validation loss: 2.0739156305789948

Epoch: 5| Step: 4
Training loss: 1.0862362384796143
Validation loss: 2.133347600698471

Epoch: 5| Step: 5
Training loss: 0.9510875940322876
Validation loss: 2.14659953614076

Epoch: 5| Step: 6
Training loss: 1.0131018161773682
Validation loss: 2.1441818674405417

Epoch: 5| Step: 7
Training loss: 1.4963619709014893
Validation loss: 2.226188917954763

Epoch: 5| Step: 8
Training loss: 1.3377939462661743
Validation loss: 2.2592313239971795

Epoch: 5| Step: 9
Training loss: 0.986467182636261
Validation loss: 2.238459532459577

Epoch: 5| Step: 10
Training loss: 1.035057544708252
Validation loss: 2.1857047329346337

Epoch: 5| Step: 11
Training loss: 0.5694854259490967
Validation loss: 2.1304976046085358

Epoch: 136| Step: 0
Training loss: 1.8597053289413452
Validation loss: 2.1990076849857965

Epoch: 5| Step: 1
Training loss: 1.5334094762802124
Validation loss: 2.2501593033472695

Epoch: 5| Step: 2
Training loss: 1.2372545003890991
Validation loss: 2.155584235986074

Epoch: 5| Step: 3
Training loss: 1.079396367073059
Validation loss: 2.173056130607923

Epoch: 5| Step: 4
Training loss: 0.8832386136054993
Validation loss: 2.1481390645106635

Epoch: 5| Step: 5
Training loss: 0.7016462087631226
Validation loss: 2.1286252389351525

Epoch: 5| Step: 6
Training loss: 1.1242740154266357
Validation loss: 2.139935533205668

Epoch: 5| Step: 7
Training loss: 1.2820578813552856
Validation loss: 2.1596296032269797

Epoch: 5| Step: 8
Training loss: 1.146728754043579
Validation loss: 2.0934789031744003

Epoch: 5| Step: 9
Training loss: 1.2001011371612549
Validation loss: 2.122681051492691

Epoch: 5| Step: 10
Training loss: 1.4548768997192383
Validation loss: 2.074269011616707

Epoch: 5| Step: 11
Training loss: 1.2346959114074707
Validation loss: 2.2066004226605096

Epoch: 137| Step: 0
Training loss: 1.1905181407928467
Validation loss: 2.1570054988066354

Epoch: 5| Step: 1
Training loss: 1.0214684009552002
Validation loss: 2.092829485734304

Epoch: 5| Step: 2
Training loss: 1.6108920574188232
Validation loss: 2.148327127099037

Epoch: 5| Step: 3
Training loss: 1.2082868814468384
Validation loss: 2.0662110447883606

Epoch: 5| Step: 4
Training loss: 1.1303582191467285
Validation loss: 2.099428912003835

Epoch: 5| Step: 5
Training loss: 1.146034598350525
Validation loss: 2.069522812962532

Epoch: 5| Step: 6
Training loss: 1.0854077339172363
Validation loss: 2.120774651567141

Epoch: 5| Step: 7
Training loss: 1.0605998039245605
Validation loss: 2.1983743657668433

Epoch: 5| Step: 8
Training loss: 1.939687728881836
Validation loss: 2.2248818476994834

Epoch: 5| Step: 9
Training loss: 1.3151906728744507
Validation loss: 2.3174668351809182

Epoch: 5| Step: 10
Training loss: 1.638282060623169
Validation loss: 2.331281761328379

Epoch: 5| Step: 11
Training loss: 0.41758012771606445
Validation loss: 2.302347496151924

Epoch: 138| Step: 0
Training loss: 1.0458177328109741
Validation loss: 2.2763700087865195

Epoch: 5| Step: 1
Training loss: 1.0269782543182373
Validation loss: 2.2016362051169076

Epoch: 5| Step: 2
Training loss: 1.7830150127410889
Validation loss: 2.1686156690120697

Epoch: 5| Step: 3
Training loss: 1.4999759197235107
Validation loss: 2.2326002617677054

Epoch: 5| Step: 4
Training loss: 0.8875690698623657
Validation loss: 2.1020306845506034

Epoch: 5| Step: 5
Training loss: 1.3742282390594482
Validation loss: 2.1104230880737305

Epoch: 5| Step: 6
Training loss: 1.0425368547439575
Validation loss: 2.125547597805659

Epoch: 5| Step: 7
Training loss: 1.089730143547058
Validation loss: 2.139891410867373

Epoch: 5| Step: 8
Training loss: 1.4415342807769775
Validation loss: 2.1006122728188834

Epoch: 5| Step: 9
Training loss: 0.8126524090766907
Validation loss: 2.226104900240898

Epoch: 5| Step: 10
Training loss: 0.8239712715148926
Validation loss: 2.1833721548318863

Epoch: 5| Step: 11
Training loss: 3.1923158168792725
Validation loss: 2.1611037254333496

Epoch: 139| Step: 0
Training loss: 1.9142811298370361
Validation loss: 2.198116719722748

Epoch: 5| Step: 1
Training loss: 0.9231314659118652
Validation loss: 2.181876281897227

Epoch: 5| Step: 2
Training loss: 1.082274079322815
Validation loss: 2.1405088851849237

Epoch: 5| Step: 3
Training loss: 1.2100331783294678
Validation loss: 2.0867606898148856

Epoch: 5| Step: 4
Training loss: 1.3531219959259033
Validation loss: 2.1136891593535743

Epoch: 5| Step: 5
Training loss: 1.1350290775299072
Validation loss: 2.2271347840627036

Epoch: 5| Step: 6
Training loss: 1.0067636966705322
Validation loss: 2.13184783856074

Epoch: 5| Step: 7
Training loss: 1.04347825050354
Validation loss: 2.08363871773084

Epoch: 5| Step: 8
Training loss: 1.0112384557724
Validation loss: 2.1397368212540946

Epoch: 5| Step: 9
Training loss: 1.0446436405181885
Validation loss: 2.2207593570152917

Epoch: 5| Step: 10
Training loss: 1.4163628816604614
Validation loss: 2.2447066654761634

Epoch: 5| Step: 11
Training loss: 0.5804200172424316
Validation loss: 2.172906811038653

Epoch: 140| Step: 0
Training loss: 0.9494675397872925
Validation loss: 2.2433596005042395

Epoch: 5| Step: 1
Training loss: 1.207734227180481
Validation loss: 2.172093778848648

Epoch: 5| Step: 2
Training loss: 0.9340336918830872
Validation loss: 2.1186914344628653

Epoch: 5| Step: 3
Training loss: 1.3044477701187134
Validation loss: 2.0889455725749335

Epoch: 5| Step: 4
Training loss: 0.9549862742424011
Validation loss: 2.081482102473577

Epoch: 5| Step: 5
Training loss: 2.044257879257202
Validation loss: 2.152054195602735

Epoch: 5| Step: 6
Training loss: 1.3958723545074463
Validation loss: 2.0615887194871902

Epoch: 5| Step: 7
Training loss: 0.8165528178215027
Validation loss: 2.1171650687853494

Epoch: 5| Step: 8
Training loss: 0.9984661340713501
Validation loss: 2.0975585182507834

Epoch: 5| Step: 9
Training loss: 1.0998115539550781
Validation loss: 2.1601859082778296

Epoch: 5| Step: 10
Training loss: 1.5115772485733032
Validation loss: 2.182566314935684

Epoch: 5| Step: 11
Training loss: 0.5890024304389954
Validation loss: 2.1330621441205344

Epoch: 141| Step: 0
Training loss: 1.1135002374649048
Validation loss: 2.236356740196546

Epoch: 5| Step: 1
Training loss: 0.9857123494148254
Validation loss: 2.1779235303401947

Epoch: 5| Step: 2
Training loss: 1.4574893712997437
Validation loss: 2.2382795015970864

Epoch: 5| Step: 3
Training loss: 1.4225609302520752
Validation loss: 2.248465970158577

Epoch: 5| Step: 4
Training loss: 1.20695960521698
Validation loss: 2.1787753850221634

Epoch: 5| Step: 5
Training loss: 0.9199151992797852
Validation loss: 2.183396349350611

Epoch: 5| Step: 6
Training loss: 1.1052221059799194
Validation loss: 2.193973789612452

Epoch: 5| Step: 7
Training loss: 0.7851823568344116
Validation loss: 2.166444847981135

Epoch: 5| Step: 8
Training loss: 1.2202506065368652
Validation loss: 2.177410140633583

Epoch: 5| Step: 9
Training loss: 1.1340900659561157
Validation loss: 2.1640416185061135

Epoch: 5| Step: 10
Training loss: 1.3734855651855469
Validation loss: 2.1014895091454187

Epoch: 5| Step: 11
Training loss: 0.7666031718254089
Validation loss: 2.0945118268330893

Epoch: 142| Step: 0
Training loss: 0.6590548753738403
Validation loss: 2.103621701399485

Epoch: 5| Step: 1
Training loss: 1.0508508682250977
Validation loss: 2.1838593184947968

Epoch: 5| Step: 2
Training loss: 1.228175401687622
Validation loss: 2.140428349375725

Epoch: 5| Step: 3
Training loss: 0.8929033279418945
Validation loss: 2.233799288670222

Epoch: 5| Step: 4
Training loss: 1.0857725143432617
Validation loss: 2.2572595526774726

Epoch: 5| Step: 5
Training loss: 1.2724672555923462
Validation loss: 2.2501473327477775

Epoch: 5| Step: 6
Training loss: 1.2625197172164917
Validation loss: 2.248777618010839

Epoch: 5| Step: 7
Training loss: 1.2094290256500244
Validation loss: 2.2054244677225747

Epoch: 5| Step: 8
Training loss: 1.4172203540802002
Validation loss: 2.1070644756158194

Epoch: 5| Step: 9
Training loss: 1.2808351516723633
Validation loss: 2.15345461666584

Epoch: 5| Step: 10
Training loss: 1.660433053970337
Validation loss: 2.1285159091154733

Epoch: 5| Step: 11
Training loss: 1.304294228553772
Validation loss: 2.1240345438321433

Epoch: 143| Step: 0
Training loss: 1.8063914775848389
Validation loss: 2.1591528058052063

Epoch: 5| Step: 1
Training loss: 1.093419075012207
Validation loss: 2.1646555910507836

Epoch: 5| Step: 2
Training loss: 1.1815799474716187
Validation loss: 2.232137680053711

Epoch: 5| Step: 3
Training loss: 1.4539453983306885
Validation loss: 2.222135936220487

Epoch: 5| Step: 4
Training loss: 1.2556276321411133
Validation loss: 2.2931872258583703

Epoch: 5| Step: 5
Training loss: 1.3654969930648804
Validation loss: 2.280015846093496

Epoch: 5| Step: 6
Training loss: 0.9377975463867188
Validation loss: 2.22602549691995

Epoch: 5| Step: 7
Training loss: 1.0941749811172485
Validation loss: 2.213691850503286

Epoch: 5| Step: 8
Training loss: 0.6757599115371704
Validation loss: 2.156529575586319

Epoch: 5| Step: 9
Training loss: 1.2046254873275757
Validation loss: 2.076146905620893

Epoch: 5| Step: 10
Training loss: 1.7234904766082764
Validation loss: 2.1527521312236786

Epoch: 5| Step: 11
Training loss: 0.40004658699035645
Validation loss: 2.0948876589536667

Epoch: 144| Step: 0
Training loss: 1.626011848449707
Validation loss: 2.177537510792414

Epoch: 5| Step: 1
Training loss: 0.9496203660964966
Validation loss: 2.0782777766386666

Epoch: 5| Step: 2
Training loss: 1.3721030950546265
Validation loss: 2.1456689536571503

Epoch: 5| Step: 3
Training loss: 0.9689236879348755
Validation loss: 2.2092698514461517

Epoch: 5| Step: 4
Training loss: 0.786347508430481
Validation loss: 2.1806879540284476

Epoch: 5| Step: 5
Training loss: 0.7335078120231628
Validation loss: 2.2488941848278046

Epoch: 5| Step: 6
Training loss: 1.6609894037246704
Validation loss: 2.2963167478640876

Epoch: 5| Step: 7
Training loss: 1.1813329458236694
Validation loss: 2.324684133132299

Epoch: 5| Step: 8
Training loss: 1.5724208354949951
Validation loss: 2.302506456772486

Epoch: 5| Step: 9
Training loss: 0.7328580021858215
Validation loss: 2.2071040719747543

Epoch: 5| Step: 10
Training loss: 1.1868740320205688
Validation loss: 2.149395525455475

Epoch: 5| Step: 11
Training loss: 0.8657875657081604
Validation loss: 2.1714303692181907

Epoch: 145| Step: 0
Training loss: 1.216200351715088
Validation loss: 2.160374919573466

Epoch: 5| Step: 1
Training loss: 1.4335721731185913
Validation loss: 2.19866510728995

Epoch: 5| Step: 2
Training loss: 1.1328576803207397
Validation loss: 2.1026707092920938

Epoch: 5| Step: 3
Training loss: 1.313047170639038
Validation loss: 2.1608361353476844

Epoch: 5| Step: 4
Training loss: 0.9498631358146667
Validation loss: 2.17644831041495

Epoch: 5| Step: 5
Training loss: 1.1899124383926392
Validation loss: 2.2171557943026223

Epoch: 5| Step: 6
Training loss: 0.760819137096405
Validation loss: 2.2759671757618585

Epoch: 5| Step: 7
Training loss: 1.3510284423828125
Validation loss: 2.285025025407473

Epoch: 5| Step: 8
Training loss: 1.1996855735778809
Validation loss: 2.296564827362696

Epoch: 5| Step: 9
Training loss: 1.102378487586975
Validation loss: 2.2892477810382843

Epoch: 5| Step: 10
Training loss: 1.4017126560211182
Validation loss: 2.2698735843102136

Epoch: 5| Step: 11
Training loss: 1.0386399030685425
Validation loss: 2.2119786590337753

Epoch: 146| Step: 0
Training loss: 1.0642361640930176
Validation loss: 2.14876618484656

Epoch: 5| Step: 1
Training loss: 0.920839786529541
Validation loss: 2.1559916585683823

Epoch: 5| Step: 2
Training loss: 0.9871776700019836
Validation loss: 2.2335619578758874

Epoch: 5| Step: 3
Training loss: 1.1035195589065552
Validation loss: 2.2041561007499695

Epoch: 5| Step: 4
Training loss: 1.6439720392227173
Validation loss: 2.1719619234402976

Epoch: 5| Step: 5
Training loss: 0.9345897436141968
Validation loss: 2.2221456319093704

Epoch: 5| Step: 6
Training loss: 1.28499174118042
Validation loss: 2.2222218414147696

Epoch: 5| Step: 7
Training loss: 0.8945305943489075
Validation loss: 2.2007583677768707

Epoch: 5| Step: 8
Training loss: 1.271828293800354
Validation loss: 2.1909822672605515

Epoch: 5| Step: 9
Training loss: 1.0816917419433594
Validation loss: 2.165010541677475

Epoch: 5| Step: 10
Training loss: 1.0598793029785156
Validation loss: 2.232919176419576

Epoch: 5| Step: 11
Training loss: 0.5263126492500305
Validation loss: 2.2260157614946365

Epoch: 147| Step: 0
Training loss: 1.091323971748352
Validation loss: 2.247583791613579

Epoch: 5| Step: 1
Training loss: 0.807625412940979
Validation loss: 2.20610119899114

Epoch: 5| Step: 2
Training loss: 1.2368838787078857
Validation loss: 2.1686284095048904

Epoch: 5| Step: 3
Training loss: 1.5120484828948975
Validation loss: 2.1326233744621277

Epoch: 5| Step: 4
Training loss: 1.530164122581482
Validation loss: 2.0898509522279105

Epoch: 5| Step: 5
Training loss: 1.0376590490341187
Validation loss: 2.1487296322981515

Epoch: 5| Step: 6
Training loss: 1.1673479080200195
Validation loss: 2.1292930245399475

Epoch: 5| Step: 7
Training loss: 1.3095977306365967
Validation loss: 2.1583974162737527

Epoch: 5| Step: 8
Training loss: 1.249145746231079
Validation loss: 2.238581284880638

Epoch: 5| Step: 9
Training loss: 0.6125313639640808
Validation loss: 2.246650849779447

Epoch: 5| Step: 10
Training loss: 0.6862646341323853
Validation loss: 2.2255184004704156

Epoch: 5| Step: 11
Training loss: 1.0462594032287598
Validation loss: 2.2323289612929025

Epoch: 148| Step: 0
Training loss: 1.287720799446106
Validation loss: 2.2596525649229684

Epoch: 5| Step: 1
Training loss: 0.8676702380180359
Validation loss: 2.248569533228874

Epoch: 5| Step: 2
Training loss: 0.8986877202987671
Validation loss: 2.1577317317326865

Epoch: 5| Step: 3
Training loss: 1.3339380025863647
Validation loss: 2.160254329442978

Epoch: 5| Step: 4
Training loss: 0.7450917959213257
Validation loss: 2.1306443264087043

Epoch: 5| Step: 5
Training loss: 1.3365365266799927
Validation loss: 2.1472019453843436

Epoch: 5| Step: 6
Training loss: 1.2647641897201538
Validation loss: 2.21209380030632

Epoch: 5| Step: 7
Training loss: 0.9616511464118958
Validation loss: 2.2652933498223624

Epoch: 5| Step: 8
Training loss: 1.5258104801177979
Validation loss: 2.27539133032163

Epoch: 5| Step: 9
Training loss: 1.0290675163269043
Validation loss: 2.2560437321662903

Epoch: 5| Step: 10
Training loss: 0.9126618504524231
Validation loss: 2.2370938062667847

Epoch: 5| Step: 11
Training loss: 1.976150393486023
Validation loss: 2.185385743776957

Epoch: 149| Step: 0
Training loss: 0.7459523677825928
Validation loss: 2.1791758934656777

Epoch: 5| Step: 1
Training loss: 1.7207374572753906
Validation loss: 2.1232373962799707

Epoch: 5| Step: 2
Training loss: 1.6315968036651611
Validation loss: 2.1408371726671853

Epoch: 5| Step: 3
Training loss: 1.4307886362075806
Validation loss: 2.1958821018536887

Epoch: 5| Step: 4
Training loss: 1.1539521217346191
Validation loss: 2.1345459818840027

Epoch: 5| Step: 5
Training loss: 0.774454653263092
Validation loss: 2.190997769435247

Epoch: 5| Step: 6
Training loss: 1.0181045532226562
Validation loss: 2.197199741999308

Epoch: 5| Step: 7
Training loss: 0.7853286862373352
Validation loss: 2.1531756222248077

Epoch: 5| Step: 8
Training loss: 0.9246894121170044
Validation loss: 2.195534368356069

Epoch: 5| Step: 9
Training loss: 0.8119271993637085
Validation loss: 2.1474134425322213

Epoch: 5| Step: 10
Training loss: 0.6824299693107605
Validation loss: 2.182837635278702

Epoch: 5| Step: 11
Training loss: 1.602613091468811
Validation loss: 2.194602459669113

Epoch: 150| Step: 0
Training loss: 1.1430360078811646
Validation loss: 2.1549978057543435

Epoch: 5| Step: 1
Training loss: 0.6045206785202026
Validation loss: 2.1555012464523315

Epoch: 5| Step: 2
Training loss: 1.1285924911499023
Validation loss: 2.1701811403036118

Epoch: 5| Step: 3
Training loss: 1.3167970180511475
Validation loss: 2.2020623038212457

Epoch: 5| Step: 4
Training loss: 0.6620485186576843
Validation loss: 2.189197614789009

Epoch: 5| Step: 5
Training loss: 1.1889543533325195
Validation loss: 2.2097691148519516

Epoch: 5| Step: 6
Training loss: 1.4635412693023682
Validation loss: 2.2507076313098273

Epoch: 5| Step: 7
Training loss: 0.668533205986023
Validation loss: 2.266239732503891

Epoch: 5| Step: 8
Training loss: 1.1308319568634033
Validation loss: 2.2242342034975686

Epoch: 5| Step: 9
Training loss: 0.9860041737556458
Validation loss: 2.215800086657206

Epoch: 5| Step: 10
Training loss: 1.2583192586898804
Validation loss: 2.216630980372429

Epoch: 5| Step: 11
Training loss: 0.6347283720970154
Validation loss: 2.2239367614189782

Epoch: 151| Step: 0
Training loss: 0.602367103099823
Validation loss: 2.2097749511400857

Epoch: 5| Step: 1
Training loss: 1.2925293445587158
Validation loss: 2.1660062223672867

Epoch: 5| Step: 2
Training loss: 0.66917884349823
Validation loss: 2.194057211279869

Epoch: 5| Step: 3
Training loss: 1.4235856533050537
Validation loss: 2.1269124497969947

Epoch: 5| Step: 4
Training loss: 0.952501654624939
Validation loss: 2.158763587474823

Epoch: 5| Step: 5
Training loss: 0.5487130880355835
Validation loss: 2.1439895381530127

Epoch: 5| Step: 6
Training loss: 1.4602277278900146
Validation loss: 2.169454743464788

Epoch: 5| Step: 7
Training loss: 1.6266090869903564
Validation loss: 2.2180735766887665

Epoch: 5| Step: 8
Training loss: 0.8823685646057129
Validation loss: 2.1626472026109695

Epoch: 5| Step: 9
Training loss: 1.1812442541122437
Validation loss: 2.229522183537483

Epoch: 5| Step: 10
Training loss: 0.9800639152526855
Validation loss: 2.1600947181383767

Epoch: 5| Step: 11
Training loss: 0.5914813280105591
Validation loss: 2.1942960619926453

Epoch: 152| Step: 0
Training loss: 0.9866169691085815
Validation loss: 2.2047494649887085

Epoch: 5| Step: 1
Training loss: 0.8516178131103516
Validation loss: 2.254648049672445

Epoch: 5| Step: 2
Training loss: 0.7206846475601196
Validation loss: 2.2289752264817557

Epoch: 5| Step: 3
Training loss: 1.185857892036438
Validation loss: 2.2368819564580917

Epoch: 5| Step: 4
Training loss: 1.5547969341278076
Validation loss: 2.1581831723451614

Epoch: 5| Step: 5
Training loss: 1.2699216604232788
Validation loss: 2.2670172105232873

Epoch: 5| Step: 6
Training loss: 1.0631093978881836
Validation loss: 2.1481990615526834

Epoch: 5| Step: 7
Training loss: 1.0506799221038818
Validation loss: 2.206149081389109

Epoch: 5| Step: 8
Training loss: 1.0696160793304443
Validation loss: 2.245127707719803

Epoch: 5| Step: 9
Training loss: 0.9583961367607117
Validation loss: 2.1915338784456253

Epoch: 5| Step: 10
Training loss: 0.9819944500923157
Validation loss: 2.2392596205075583

Epoch: 5| Step: 11
Training loss: 0.339430570602417
Validation loss: 2.273652950922648

Epoch: 153| Step: 0
Training loss: 1.000154733657837
Validation loss: 2.187575896581014

Epoch: 5| Step: 1
Training loss: 1.4349377155303955
Validation loss: 2.1995869328578315

Epoch: 5| Step: 2
Training loss: 0.7433909177780151
Validation loss: 2.143002539873123

Epoch: 5| Step: 3
Training loss: 0.9134069681167603
Validation loss: 2.2123970836400986

Epoch: 5| Step: 4
Training loss: 0.8896383047103882
Validation loss: 2.20613061885039

Epoch: 5| Step: 5
Training loss: 0.9669343829154968
Validation loss: 2.208751857280731

Epoch: 5| Step: 6
Training loss: 1.3426414728164673
Validation loss: 2.3142244021097818

Epoch: 5| Step: 7
Training loss: 0.9068266749382019
Validation loss: 2.2814601361751556

Epoch: 5| Step: 8
Training loss: 1.126274824142456
Validation loss: 2.2280828058719635

Epoch: 5| Step: 9
Training loss: 1.379328727722168
Validation loss: 2.2189873854319253

Epoch: 5| Step: 10
Training loss: 1.299290657043457
Validation loss: 2.197492385903994

Epoch: 5| Step: 11
Training loss: 0.30662035942077637
Validation loss: 2.2153817117214203

Epoch: 154| Step: 0
Training loss: 0.7753075361251831
Validation loss: 2.177105128765106

Epoch: 5| Step: 1
Training loss: 0.872076690196991
Validation loss: 2.174149443705877

Epoch: 5| Step: 2
Training loss: 1.1341300010681152
Validation loss: 2.1384793519973755

Epoch: 5| Step: 3
Training loss: 0.8817518949508667
Validation loss: 2.2400643676519394

Epoch: 5| Step: 4
Training loss: 1.330955147743225
Validation loss: 2.1846943795681

Epoch: 5| Step: 5
Training loss: 1.1489115953445435
Validation loss: 2.2349132696787515

Epoch: 5| Step: 6
Training loss: 0.9110552072525024
Validation loss: 2.258816967407862

Epoch: 5| Step: 7
Training loss: 0.9047799110412598
Validation loss: 2.246438667178154

Epoch: 5| Step: 8
Training loss: 1.4483985900878906
Validation loss: 2.1858220597108207

Epoch: 5| Step: 9
Training loss: 1.1120860576629639
Validation loss: 2.217033197482427

Epoch: 5| Step: 10
Training loss: 0.9632737040519714
Validation loss: 2.225459406773249

Epoch: 5| Step: 11
Training loss: 0.2164602279663086
Validation loss: 2.2385676304499307

Epoch: 155| Step: 0
Training loss: 1.3198264837265015
Validation loss: 2.1544867157936096

Epoch: 5| Step: 1
Training loss: 1.3241926431655884
Validation loss: 2.1831771532694497

Epoch: 5| Step: 2
Training loss: 0.9402607083320618
Validation loss: 2.1652260025342307

Epoch: 5| Step: 3
Training loss: 1.2086448669433594
Validation loss: 2.154770721991857

Epoch: 5| Step: 4
Training loss: 0.9227355718612671
Validation loss: 2.1453772137562432

Epoch: 5| Step: 5
Training loss: 1.058242917060852
Validation loss: 2.1748896737893424

Epoch: 5| Step: 6
Training loss: 1.0602673292160034
Validation loss: 2.2949794083833694

Epoch: 5| Step: 7
Training loss: 1.353659987449646
Validation loss: 2.340060273806254

Epoch: 5| Step: 8
Training loss: 1.317170262336731
Validation loss: 2.3006496032079062

Epoch: 5| Step: 9
Training loss: 1.2221190929412842
Validation loss: 2.3150067826112113

Epoch: 5| Step: 10
Training loss: 1.1361939907073975
Validation loss: 2.2118629962205887

Epoch: 5| Step: 11
Training loss: 1.7808890342712402
Validation loss: 2.228512172897657

Epoch: 156| Step: 0
Training loss: 1.1201874017715454
Validation loss: 2.200836107134819

Epoch: 5| Step: 1
Training loss: 1.3417354822158813
Validation loss: 2.195976664622625

Epoch: 5| Step: 2
Training loss: 0.8189516067504883
Validation loss: 2.197914262612661

Epoch: 5| Step: 3
Training loss: 1.0310673713684082
Validation loss: 2.17341556151708

Epoch: 5| Step: 4
Training loss: 1.1542202234268188
Validation loss: 2.1834113597869873

Epoch: 5| Step: 5
Training loss: 1.0730302333831787
Validation loss: 2.201432009538015

Epoch: 5| Step: 6
Training loss: 0.7938464879989624
Validation loss: 2.243968819578489

Epoch: 5| Step: 7
Training loss: 1.0604058504104614
Validation loss: 2.1495500902334848

Epoch: 5| Step: 8
Training loss: 1.3347910642623901
Validation loss: 2.276122957468033

Epoch: 5| Step: 9
Training loss: 0.7444819808006287
Validation loss: 2.220848595102628

Epoch: 5| Step: 10
Training loss: 0.8749321103096008
Validation loss: 2.2100213170051575

Epoch: 5| Step: 11
Training loss: 0.5704210996627808
Validation loss: 2.2320348421732583

Epoch: 157| Step: 0
Training loss: 1.2968204021453857
Validation loss: 2.2510324716567993

Epoch: 5| Step: 1
Training loss: 1.0277092456817627
Validation loss: 2.1949076652526855

Epoch: 5| Step: 2
Training loss: 0.7652862668037415
Validation loss: 2.279959241549174

Epoch: 5| Step: 3
Training loss: 1.4547654390335083
Validation loss: 2.245680496096611

Epoch: 5| Step: 4
Training loss: 1.1679728031158447
Validation loss: 2.210988849401474

Epoch: 5| Step: 5
Training loss: 0.5729952454566956
Validation loss: 2.196402678887049

Epoch: 5| Step: 6
Training loss: 1.1996169090270996
Validation loss: 2.1715500752131143

Epoch: 5| Step: 7
Training loss: 1.3591245412826538
Validation loss: 2.154465635617574

Epoch: 5| Step: 8
Training loss: 0.7205243110656738
Validation loss: 2.139636521538099

Epoch: 5| Step: 9
Training loss: 1.0683472156524658
Validation loss: 2.207481602827708

Epoch: 5| Step: 10
Training loss: 0.5637084245681763
Validation loss: 2.181287174423536

Epoch: 5| Step: 11
Training loss: 0.5954029560089111
Validation loss: 2.0877352257569632

Epoch: 158| Step: 0
Training loss: 0.6161765456199646
Validation loss: 2.1797989209493003

Epoch: 5| Step: 1
Training loss: 1.339320421218872
Validation loss: 2.1536651949087777

Epoch: 5| Step: 2
Training loss: 1.1167809963226318
Validation loss: 2.166675408681234

Epoch: 5| Step: 3
Training loss: 1.1295411586761475
Validation loss: 2.156073212623596

Epoch: 5| Step: 4
Training loss: 1.1413322687149048
Validation loss: 2.114733631412188

Epoch: 5| Step: 5
Training loss: 1.0770269632339478
Validation loss: 2.1542946497599282

Epoch: 5| Step: 6
Training loss: 0.865777850151062
Validation loss: 2.2085176010926566

Epoch: 5| Step: 7
Training loss: 1.0114543437957764
Validation loss: 2.2438176572322845

Epoch: 5| Step: 8
Training loss: 0.7105852365493774
Validation loss: 2.2905139923095703

Epoch: 5| Step: 9
Training loss: 1.4250301122665405
Validation loss: 2.2883079051971436

Epoch: 5| Step: 10
Training loss: 0.9491176605224609
Validation loss: 2.315632313489914

Epoch: 5| Step: 11
Training loss: 0.9138591289520264
Validation loss: 2.2023040801286697

Epoch: 159| Step: 0
Training loss: 0.9366397857666016
Validation loss: 2.315142661333084

Epoch: 5| Step: 1
Training loss: 1.785333275794983
Validation loss: 2.2704664170742035

Epoch: 5| Step: 2
Training loss: 0.8311630487442017
Validation loss: 2.2527146438757577

Epoch: 5| Step: 3
Training loss: 0.8165155649185181
Validation loss: 2.2340383330980935

Epoch: 5| Step: 4
Training loss: 0.6614636182785034
Validation loss: 2.1881232957045236

Epoch: 5| Step: 5
Training loss: 1.3189783096313477
Validation loss: 2.266946425040563

Epoch: 5| Step: 6
Training loss: 0.8479402661323547
Validation loss: 2.2109683801730475

Epoch: 5| Step: 7
Training loss: 0.5136155486106873
Validation loss: 2.165795480211576

Epoch: 5| Step: 8
Training loss: 1.3042614459991455
Validation loss: 2.16873366634051

Epoch: 5| Step: 9
Training loss: 0.9593410491943359
Validation loss: 2.193259874979655

Epoch: 5| Step: 10
Training loss: 1.206275463104248
Validation loss: 2.1493619630734124

Epoch: 5| Step: 11
Training loss: 0.8713483214378357
Validation loss: 2.182741795976957

Epoch: 160| Step: 0
Training loss: 0.6688477396965027
Validation loss: 2.151088292400042

Epoch: 5| Step: 1
Training loss: 0.9255338907241821
Validation loss: 2.1601872543493905

Epoch: 5| Step: 2
Training loss: 0.7100828289985657
Validation loss: 2.2085187981526055

Epoch: 5| Step: 3
Training loss: 1.157717227935791
Validation loss: 2.2815621395905814

Epoch: 5| Step: 4
Training loss: 0.8944673538208008
Validation loss: 2.2741927405198417

Epoch: 5| Step: 5
Training loss: 0.966767430305481
Validation loss: 2.2253122131029763

Epoch: 5| Step: 6
Training loss: 1.6680551767349243
Validation loss: 2.2048450311024985

Epoch: 5| Step: 7
Training loss: 1.0416176319122314
Validation loss: 2.157781481742859

Epoch: 5| Step: 8
Training loss: 1.0087946653366089
Validation loss: 2.1748709927002587

Epoch: 5| Step: 9
Training loss: 1.0593467950820923
Validation loss: 2.132616862654686

Epoch: 5| Step: 10
Training loss: 1.0166728496551514
Validation loss: 2.2276973177989325

Epoch: 5| Step: 11
Training loss: 0.7273386716842651
Validation loss: 2.1934674630562463

Epoch: 161| Step: 0
Training loss: 0.7952637672424316
Validation loss: 2.1954135646422706

Epoch: 5| Step: 1
Training loss: 1.4509179592132568
Validation loss: 2.3666761020819345

Epoch: 5| Step: 2
Training loss: 1.422600507736206
Validation loss: 2.2940651774406433

Epoch: 5| Step: 3
Training loss: 0.8706790208816528
Validation loss: 2.259643773237864

Epoch: 5| Step: 4
Training loss: 0.967879593372345
Validation loss: 2.1806192894776664

Epoch: 5| Step: 5
Training loss: 1.098044514656067
Validation loss: 2.2170726458231607

Epoch: 5| Step: 6
Training loss: 0.5753077268600464
Validation loss: 2.1890995651483536

Epoch: 5| Step: 7
Training loss: 0.9030715823173523
Validation loss: 2.1568003445863724

Epoch: 5| Step: 8
Training loss: 1.1644483804702759
Validation loss: 2.0869616170724234

Epoch: 5| Step: 9
Training loss: 0.9767786860466003
Validation loss: 2.1391183535257974

Epoch: 5| Step: 10
Training loss: 1.2803102731704712
Validation loss: 2.1480694860219955

Epoch: 5| Step: 11
Training loss: 0.4581053853034973
Validation loss: 2.2107672691345215

Epoch: 162| Step: 0
Training loss: 0.8643785715103149
Validation loss: 2.2096724609533944

Epoch: 5| Step: 1
Training loss: 1.0902212858200073
Validation loss: 2.175758813818296

Epoch: 5| Step: 2
Training loss: 0.983525276184082
Validation loss: 2.1880075534184775

Epoch: 5| Step: 3
Training loss: 0.9638866186141968
Validation loss: 2.2768635849157968

Epoch: 5| Step: 4
Training loss: 0.9787029027938843
Validation loss: 2.2372685968875885

Epoch: 5| Step: 5
Training loss: 1.500797986984253
Validation loss: 2.2338486860195794

Epoch: 5| Step: 6
Training loss: 1.1895406246185303
Validation loss: 2.2059776534636817

Epoch: 5| Step: 7
Training loss: 0.7871028184890747
Validation loss: 2.2289625306924186

Epoch: 5| Step: 8
Training loss: 0.8132947683334351
Validation loss: 2.2216049830118814

Epoch: 5| Step: 9
Training loss: 0.8914029002189636
Validation loss: 2.180194154381752

Epoch: 5| Step: 10
Training loss: 0.5403048992156982
Validation loss: 2.221659849087397

Epoch: 5| Step: 11
Training loss: 1.9909741878509521
Validation loss: 2.169691120584806

Epoch: 163| Step: 0
Training loss: 0.6554566621780396
Validation loss: 2.1908087134361267

Epoch: 5| Step: 1
Training loss: 0.48365291953086853
Validation loss: 2.187631741166115

Epoch: 5| Step: 2
Training loss: 0.828413188457489
Validation loss: 2.270416021347046

Epoch: 5| Step: 3
Training loss: 0.9195652008056641
Validation loss: 2.187556435664495

Epoch: 5| Step: 4
Training loss: 0.8886683583259583
Validation loss: 2.177332803606987

Epoch: 5| Step: 5
Training loss: 1.3330044746398926
Validation loss: 2.2367387861013412

Epoch: 5| Step: 6
Training loss: 1.0464661121368408
Validation loss: 2.154906392097473

Epoch: 5| Step: 7
Training loss: 1.0770187377929688
Validation loss: 2.146360009908676

Epoch: 5| Step: 8
Training loss: 1.2022844552993774
Validation loss: 2.201349208752314

Epoch: 5| Step: 9
Training loss: 1.1344959735870361
Validation loss: 2.222015435496966

Epoch: 5| Step: 10
Training loss: 1.1124131679534912
Validation loss: 2.1999419579903283

Epoch: 5| Step: 11
Training loss: 0.947395920753479
Validation loss: 2.26449778676033

Epoch: 164| Step: 0
Training loss: 0.991032600402832
Validation loss: 2.24053301413854

Epoch: 5| Step: 1
Training loss: 0.9155876040458679
Validation loss: 2.1739209393660226

Epoch: 5| Step: 2
Training loss: 1.1573231220245361
Validation loss: 2.203885853290558

Epoch: 5| Step: 3
Training loss: 0.9128146171569824
Validation loss: 2.1832288950681686

Epoch: 5| Step: 4
Training loss: 1.0385420322418213
Validation loss: 2.1712312002976737

Epoch: 5| Step: 5
Training loss: 1.1615192890167236
Validation loss: 2.1934980899095535

Epoch: 5| Step: 6
Training loss: 0.9514363408088684
Validation loss: 2.246887654066086

Epoch: 5| Step: 7
Training loss: 0.8627995252609253
Validation loss: 2.1734751164913177

Epoch: 5| Step: 8
Training loss: 0.967181384563446
Validation loss: 2.2808786183595657

Epoch: 5| Step: 9
Training loss: 1.0134265422821045
Validation loss: 2.276391496260961

Epoch: 5| Step: 10
Training loss: 0.9936993718147278
Validation loss: 2.1883151481548944

Epoch: 5| Step: 11
Training loss: 1.0178356170654297
Validation loss: 2.2320995132128396

Epoch: 165| Step: 0
Training loss: 0.7891343832015991
Validation loss: 2.1631524860858917

Epoch: 5| Step: 1
Training loss: 0.9024381637573242
Validation loss: 2.158836305141449

Epoch: 5| Step: 2
Training loss: 0.7597521543502808
Validation loss: 2.07607630888621

Epoch: 5| Step: 3
Training loss: 0.6932969093322754
Validation loss: 2.157376289367676

Epoch: 5| Step: 4
Training loss: 1.0016560554504395
Validation loss: 2.1624256471792855

Epoch: 5| Step: 5
Training loss: 0.9336115121841431
Validation loss: 2.233288809657097

Epoch: 5| Step: 6
Training loss: 1.4585397243499756
Validation loss: 2.3102232913176217

Epoch: 5| Step: 7
Training loss: 0.9925848245620728
Validation loss: 2.2504119674364724

Epoch: 5| Step: 8
Training loss: 0.6231358051300049
Validation loss: 2.2282522519429526

Epoch: 5| Step: 9
Training loss: 1.1838037967681885
Validation loss: 2.287758638461431

Epoch: 5| Step: 10
Training loss: 1.3269968032836914
Validation loss: 2.240637704730034

Epoch: 5| Step: 11
Training loss: 1.240849494934082
Validation loss: 2.2239941159884133

Epoch: 166| Step: 0
Training loss: 1.0282847881317139
Validation loss: 2.3210615515708923

Epoch: 5| Step: 1
Training loss: 0.9343029260635376
Validation loss: 2.2710394312938056

Epoch: 5| Step: 2
Training loss: 0.5574843287467957
Validation loss: 2.2347860634326935

Epoch: 5| Step: 3
Training loss: 0.7266200184822083
Validation loss: 2.2098560482263565

Epoch: 5| Step: 4
Training loss: 0.9394820332527161
Validation loss: 2.227633292476336

Epoch: 5| Step: 5
Training loss: 0.9256796836853027
Validation loss: 2.1423355539639792

Epoch: 5| Step: 6
Training loss: 0.9616254568099976
Validation loss: 2.1326860139767327

Epoch: 5| Step: 7
Training loss: 0.8602613210678101
Validation loss: 2.201654702425003

Epoch: 5| Step: 8
Training loss: 1.0097808837890625
Validation loss: 2.3002032538255057

Epoch: 5| Step: 9
Training loss: 1.1106542348861694
Validation loss: 2.1849986761808395

Epoch: 5| Step: 10
Training loss: 1.3422373533248901
Validation loss: 2.203073963522911

Epoch: 5| Step: 11
Training loss: 2.5862298011779785
Validation loss: 2.230038379629453

Epoch: 167| Step: 0
Training loss: 0.878619372844696
Validation loss: 2.160608450571696

Epoch: 5| Step: 1
Training loss: 0.9577631950378418
Validation loss: 2.161502033472061

Epoch: 5| Step: 2
Training loss: 1.1151669025421143
Validation loss: 2.207546571890513

Epoch: 5| Step: 3
Training loss: 0.6956679821014404
Validation loss: 2.2609639763832092

Epoch: 5| Step: 4
Training loss: 0.9223345518112183
Validation loss: 2.189753303925196

Epoch: 5| Step: 5
Training loss: 0.8360850214958191
Validation loss: 2.2433933218320212

Epoch: 5| Step: 6
Training loss: 1.1468814611434937
Validation loss: 2.22697647412618

Epoch: 5| Step: 7
Training loss: 0.5793249011039734
Validation loss: 2.2827936311562858

Epoch: 5| Step: 8
Training loss: 0.909568190574646
Validation loss: 2.2148283819357553

Epoch: 5| Step: 9
Training loss: 0.8452728390693665
Validation loss: 2.2447956701119742

Epoch: 5| Step: 10
Training loss: 1.1134799718856812
Validation loss: 2.2588995893796286

Epoch: 5| Step: 11
Training loss: 1.4670957326889038
Validation loss: 2.218654448787371

Epoch: 168| Step: 0
Training loss: 0.7722879648208618
Validation loss: 2.223304882645607

Epoch: 5| Step: 1
Training loss: 1.0515458583831787
Validation loss: 2.2385438978672028

Epoch: 5| Step: 2
Training loss: 0.3849528431892395
Validation loss: 2.249881053964297

Epoch: 5| Step: 3
Training loss: 0.8263788223266602
Validation loss: 2.214636663595835

Epoch: 5| Step: 4
Training loss: 1.2347713708877563
Validation loss: 2.2533591985702515

Epoch: 5| Step: 5
Training loss: 0.7972897291183472
Validation loss: 2.2684247692426047

Epoch: 5| Step: 6
Training loss: 0.8636029958724976
Validation loss: 2.2868995368480682

Epoch: 5| Step: 7
Training loss: 1.1111940145492554
Validation loss: 2.3270488729079566

Epoch: 5| Step: 8
Training loss: 0.8296457529067993
Validation loss: 2.238795205950737

Epoch: 5| Step: 9
Training loss: 0.7222225666046143
Validation loss: 2.2029390136400857

Epoch: 5| Step: 10
Training loss: 1.3170868158340454
Validation loss: 2.2562532822291055

Epoch: 5| Step: 11
Training loss: 1.2127323150634766
Validation loss: 2.259010454018911

Epoch: 169| Step: 0
Training loss: 1.0688318014144897
Validation loss: 2.2721560845772424

Epoch: 5| Step: 1
Training loss: 0.8161606788635254
Validation loss: 2.2600849171479545

Epoch: 5| Step: 2
Training loss: 0.9227645993232727
Validation loss: 2.351031949122747

Epoch: 5| Step: 3
Training loss: 1.2130694389343262
Validation loss: 2.278404782215754

Epoch: 5| Step: 4
Training loss: 1.340866208076477
Validation loss: 2.2373971144358316

Epoch: 5| Step: 5
Training loss: 0.673758864402771
Validation loss: 2.2467363327741623

Epoch: 5| Step: 6
Training loss: 1.1114736795425415
Validation loss: 2.2265690664450326

Epoch: 5| Step: 7
Training loss: 0.8292912244796753
Validation loss: 2.1636485854784646

Epoch: 5| Step: 8
Training loss: 0.6857874989509583
Validation loss: 2.220050737261772

Epoch: 5| Step: 9
Training loss: 0.9713181257247925
Validation loss: 2.1450272599856057

Epoch: 5| Step: 10
Training loss: 0.9406558275222778
Validation loss: 2.1704354683558145

Epoch: 5| Step: 11
Training loss: 0.0608668327331543
Validation loss: 2.1824368635813394

Epoch: 170| Step: 0
Training loss: 1.3894758224487305
Validation loss: 2.2720098942518234

Epoch: 5| Step: 1
Training loss: 0.7611205577850342
Validation loss: 2.2438159584999084

Epoch: 5| Step: 2
Training loss: 0.5853472948074341
Validation loss: 2.232626661658287

Epoch: 5| Step: 3
Training loss: 0.543098509311676
Validation loss: 2.2482346991697946

Epoch: 5| Step: 4
Training loss: 1.2912776470184326
Validation loss: 2.197228158513705

Epoch: 5| Step: 5
Training loss: 0.7035612463951111
Validation loss: 2.2518457770347595

Epoch: 5| Step: 6
Training loss: 1.2379417419433594
Validation loss: 2.258830408255259

Epoch: 5| Step: 7
Training loss: 0.9962584376335144
Validation loss: 2.1811171422402063

Epoch: 5| Step: 8
Training loss: 0.48341622948646545
Validation loss: 2.195418377717336

Epoch: 5| Step: 9
Training loss: 0.985923171043396
Validation loss: 2.192318578561147

Epoch: 5| Step: 10
Training loss: 0.9300346374511719
Validation loss: 2.1648970594008765

Epoch: 5| Step: 11
Training loss: 1.8409290313720703
Validation loss: 2.1895035207271576

Epoch: 171| Step: 0
Training loss: 0.9609848260879517
Validation loss: 2.177980666359266

Epoch: 5| Step: 1
Training loss: 0.8571078181266785
Validation loss: 2.134086271127065

Epoch: 5| Step: 2
Training loss: 1.1423145532608032
Validation loss: 2.17356176674366

Epoch: 5| Step: 3
Training loss: 0.8848817944526672
Validation loss: 2.1538695891698203

Epoch: 5| Step: 4
Training loss: 0.8720879554748535
Validation loss: 2.22680010398229

Epoch: 5| Step: 5
Training loss: 0.9943362474441528
Validation loss: 2.279332379500071

Epoch: 5| Step: 6
Training loss: 1.2301487922668457
Validation loss: 2.314865216612816

Epoch: 5| Step: 7
Training loss: 1.1602249145507812
Validation loss: 2.3345308899879456

Epoch: 5| Step: 8
Training loss: 0.918897271156311
Validation loss: 2.347527871529261

Epoch: 5| Step: 9
Training loss: 0.8691468238830566
Validation loss: 2.296927824616432

Epoch: 5| Step: 10
Training loss: 1.0285543203353882
Validation loss: 2.240603889028231

Epoch: 5| Step: 11
Training loss: 0.9647104740142822
Validation loss: 2.1610782047112784

Epoch: 172| Step: 0
Training loss: 1.0836231708526611
Validation loss: 2.2382493813832602

Epoch: 5| Step: 1
Training loss: 1.2471024990081787
Validation loss: 2.1649618446826935

Epoch: 5| Step: 2
Training loss: 1.1554559469223022
Validation loss: 2.1173086712757745

Epoch: 5| Step: 3
Training loss: 0.8968292474746704
Validation loss: 2.167298585176468

Epoch: 5| Step: 4
Training loss: 0.7846484184265137
Validation loss: 2.1902278512716293

Epoch: 5| Step: 5
Training loss: 0.8551228642463684
Validation loss: 2.2283523430426917

Epoch: 5| Step: 6
Training loss: 1.341893196105957
Validation loss: 2.2366457680861154

Epoch: 5| Step: 7
Training loss: 0.5637553930282593
Validation loss: 2.300656884908676

Epoch: 5| Step: 8
Training loss: 0.9833186268806458
Validation loss: 2.3555657267570496

Epoch: 5| Step: 9
Training loss: 0.5348020195960999
Validation loss: 2.3283086121082306

Epoch: 5| Step: 10
Training loss: 1.2839279174804688
Validation loss: 2.2922978500525155

Epoch: 5| Step: 11
Training loss: 1.1570712327957153
Validation loss: 2.2523172994454703

Epoch: 173| Step: 0
Training loss: 0.7241069674491882
Validation loss: 2.193609649936358

Epoch: 5| Step: 1
Training loss: 1.1752707958221436
Validation loss: 2.166852295398712

Epoch: 5| Step: 2
Training loss: 1.2720999717712402
Validation loss: 2.214367836713791

Epoch: 5| Step: 3
Training loss: 0.9261863827705383
Validation loss: 2.181529939174652

Epoch: 5| Step: 4
Training loss: 0.7385274767875671
Validation loss: 2.2083071569601693

Epoch: 5| Step: 5
Training loss: 1.053844928741455
Validation loss: 2.210090031226476

Epoch: 5| Step: 6
Training loss: 1.1288515329360962
Validation loss: 2.3414994875590005

Epoch: 5| Step: 7
Training loss: 0.9663463830947876
Validation loss: 2.2891391615072885

Epoch: 5| Step: 8
Training loss: 0.699678897857666
Validation loss: 2.2976322223742804

Epoch: 5| Step: 9
Training loss: 1.1526210308074951
Validation loss: 2.273810178041458

Epoch: 5| Step: 10
Training loss: 1.0211782455444336
Validation loss: 2.1804760793844857

Epoch: 5| Step: 11
Training loss: 1.8087636232376099
Validation loss: 2.1133954524993896

Epoch: 174| Step: 0
Training loss: 1.2779439687728882
Validation loss: 2.1944855749607086

Epoch: 5| Step: 1
Training loss: 0.5850967168807983
Validation loss: 2.1642961303393045

Epoch: 5| Step: 2
Training loss: 0.9650541543960571
Validation loss: 2.2287648618221283

Epoch: 5| Step: 3
Training loss: 0.7679477334022522
Validation loss: 2.210490266482035

Epoch: 5| Step: 4
Training loss: 0.9475520849227905
Validation loss: 2.360394020875295

Epoch: 5| Step: 5
Training loss: 0.9641070365905762
Validation loss: 2.3563504219055176

Epoch: 5| Step: 6
Training loss: 0.646370530128479
Validation loss: 2.275323197245598

Epoch: 5| Step: 7
Training loss: 0.8384787440299988
Validation loss: 2.3370456049839654

Epoch: 5| Step: 8
Training loss: 0.8894411325454712
Validation loss: 2.260906254251798

Epoch: 5| Step: 9
Training loss: 0.7293819189071655
Validation loss: 2.2936558524767556

Epoch: 5| Step: 10
Training loss: 1.2010974884033203
Validation loss: 2.2275337477525077

Epoch: 5| Step: 11
Training loss: 0.623537540435791
Validation loss: 2.196492870648702

Epoch: 175| Step: 0
Training loss: 0.6241840124130249
Validation loss: 2.191409627596537

Epoch: 5| Step: 1
Training loss: 0.9681549072265625
Validation loss: 2.242655316988627

Epoch: 5| Step: 2
Training loss: 0.7996401786804199
Validation loss: 2.205655038356781

Epoch: 5| Step: 3
Training loss: 0.5223336815834045
Validation loss: 2.239929268757502

Epoch: 5| Step: 4
Training loss: 0.7727305293083191
Validation loss: 2.2283534606297812

Epoch: 5| Step: 5
Training loss: 0.9689613580703735
Validation loss: 2.269624784588814

Epoch: 5| Step: 6
Training loss: 1.2989965677261353
Validation loss: 2.199137508869171

Epoch: 5| Step: 7
Training loss: 1.0235192775726318
Validation loss: 2.273912400007248

Epoch: 5| Step: 8
Training loss: 0.9272820353507996
Validation loss: 2.216374625762304

Epoch: 5| Step: 9
Training loss: 0.900922417640686
Validation loss: 2.2116934657096863

Epoch: 5| Step: 10
Training loss: 0.45088642835617065
Validation loss: 2.1929827431837716

Epoch: 5| Step: 11
Training loss: 1.5187989473342896
Validation loss: 2.177006483078003

Epoch: 176| Step: 0
Training loss: 1.1494662761688232
Validation loss: 2.180199126402537

Epoch: 5| Step: 1
Training loss: 0.9221017956733704
Validation loss: 2.107745662331581

Epoch: 5| Step: 2
Training loss: 1.133183240890503
Validation loss: 2.259810835123062

Epoch: 5| Step: 3
Training loss: 1.0123459100723267
Validation loss: 2.1965423822402954

Epoch: 5| Step: 4
Training loss: 0.614915668964386
Validation loss: 2.1821452577908835

Epoch: 5| Step: 5
Training loss: 1.1985557079315186
Validation loss: 2.3293880422910056

Epoch: 5| Step: 6
Training loss: 1.2240452766418457
Validation loss: 2.3426528175671897

Epoch: 5| Step: 7
Training loss: 1.1705020666122437
Validation loss: 2.415082405010859

Epoch: 5| Step: 8
Training loss: 0.8469295501708984
Validation loss: 2.3752874732017517

Epoch: 5| Step: 9
Training loss: 1.1705539226531982
Validation loss: 2.3501758178075156

Epoch: 5| Step: 10
Training loss: 0.757790744304657
Validation loss: 2.269019444783529

Epoch: 5| Step: 11
Training loss: 0.6041754484176636
Validation loss: 2.250637630621592

Epoch: 177| Step: 0
Training loss: 0.7650616765022278
Validation loss: 2.1432334582010903

Epoch: 5| Step: 1
Training loss: 1.2099428176879883
Validation loss: 2.197464421391487

Epoch: 5| Step: 2
Training loss: 1.0995266437530518
Validation loss: 2.182959109544754

Epoch: 5| Step: 3
Training loss: 1.4780091047286987
Validation loss: 2.157049765189489

Epoch: 5| Step: 4
Training loss: 1.3124672174453735
Validation loss: 2.2177400290966034

Epoch: 5| Step: 5
Training loss: 1.1802418231964111
Validation loss: 2.2083853284517923

Epoch: 5| Step: 6
Training loss: 1.0208075046539307
Validation loss: 2.3087164958318076

Epoch: 5| Step: 7
Training loss: 0.6090334057807922
Validation loss: 2.2672460625569024

Epoch: 5| Step: 8
Training loss: 0.7297229766845703
Validation loss: 2.311433603366216

Epoch: 5| Step: 9
Training loss: 0.6468919515609741
Validation loss: 2.273661643266678

Epoch: 5| Step: 10
Training loss: 0.9659576416015625
Validation loss: 2.309939672549566

Epoch: 5| Step: 11
Training loss: 0.2417140007019043
Validation loss: 2.2839880337317786

Epoch: 178| Step: 0
Training loss: 0.5561509132385254
Validation loss: 2.2713667849699655

Epoch: 5| Step: 1
Training loss: 0.8720029592514038
Validation loss: 2.2300915718078613

Epoch: 5| Step: 2
Training loss: 0.723137378692627
Validation loss: 2.2059730887413025

Epoch: 5| Step: 3
Training loss: 0.5932396054267883
Validation loss: 2.2145715951919556

Epoch: 5| Step: 4
Training loss: 0.8465835452079773
Validation loss: 2.23148279885451

Epoch: 5| Step: 5
Training loss: 0.970795750617981
Validation loss: 2.1838808904091516

Epoch: 5| Step: 6
Training loss: 1.0199272632598877
Validation loss: 2.204843526085218

Epoch: 5| Step: 7
Training loss: 1.4805487394332886
Validation loss: 2.2794273595015206

Epoch: 5| Step: 8
Training loss: 0.9813318252563477
Validation loss: 2.37880868713061

Epoch: 5| Step: 9
Training loss: 1.406448245048523
Validation loss: 2.4076217959324517

Epoch: 5| Step: 10
Training loss: 0.7444748282432556
Validation loss: 2.3872033655643463

Epoch: 5| Step: 11
Training loss: 1.584039330482483
Validation loss: 2.2841191639502845

Epoch: 179| Step: 0
Training loss: 0.670000433921814
Validation loss: 2.2439780135949454

Epoch: 5| Step: 1
Training loss: 1.0983167886734009
Validation loss: 2.1567529092232385

Epoch: 5| Step: 2
Training loss: 0.8244279623031616
Validation loss: 2.1611411223808923

Epoch: 5| Step: 3
Training loss: 0.9571136236190796
Validation loss: 2.2184795439243317

Epoch: 5| Step: 4
Training loss: 0.7714117765426636
Validation loss: 2.1267999708652496

Epoch: 5| Step: 5
Training loss: 0.613006055355072
Validation loss: 2.17344298462073

Epoch: 5| Step: 6
Training loss: 0.7795020341873169
Validation loss: 2.1749163369337716

Epoch: 5| Step: 7
Training loss: 0.9562432169914246
Validation loss: 2.2442172517379126

Epoch: 5| Step: 8
Training loss: 1.4753472805023193
Validation loss: 2.277050882577896

Epoch: 5| Step: 9
Training loss: 0.8981998562812805
Validation loss: 2.2625107218821845

Epoch: 5| Step: 10
Training loss: 0.687965989112854
Validation loss: 2.287894199291865

Epoch: 5| Step: 11
Training loss: 0.4182485342025757
Validation loss: 2.2738405913114548

Epoch: 180| Step: 0
Training loss: 1.2815074920654297
Validation loss: 2.2342625508705773

Epoch: 5| Step: 1
Training loss: 0.5867279767990112
Validation loss: 2.174302399158478

Epoch: 5| Step: 2
Training loss: 0.9523053169250488
Validation loss: 2.1920318752527237

Epoch: 5| Step: 3
Training loss: 0.48801493644714355
Validation loss: 2.180812284350395

Epoch: 5| Step: 4
Training loss: 1.551159143447876
Validation loss: 2.2236621330181756

Epoch: 5| Step: 5
Training loss: 0.900902271270752
Validation loss: 2.1533218224843345

Epoch: 5| Step: 6
Training loss: 0.5902347564697266
Validation loss: 2.1683688263098397

Epoch: 5| Step: 7
Training loss: 0.8628878593444824
Validation loss: 2.1833830376466117

Epoch: 5| Step: 8
Training loss: 0.5628827810287476
Validation loss: 2.1983066896597543

Epoch: 5| Step: 9
Training loss: 0.9220961332321167
Validation loss: 2.1337264577547708

Epoch: 5| Step: 10
Training loss: 0.6881939172744751
Validation loss: 2.229896972576777

Epoch: 5| Step: 11
Training loss: 0.5273889899253845
Validation loss: 2.3069061636924744

Epoch: 181| Step: 0
Training loss: 1.1316436529159546
Validation loss: 2.262878268957138

Epoch: 5| Step: 1
Training loss: 0.7295035123825073
Validation loss: 2.2084873418013253

Epoch: 5| Step: 2
Training loss: 0.8073498010635376
Validation loss: 2.201803425947825

Epoch: 5| Step: 3
Training loss: 0.7707414031028748
Validation loss: 2.217386315266291

Epoch: 5| Step: 4
Training loss: 1.1004021167755127
Validation loss: 2.3025716890891395

Epoch: 5| Step: 5
Training loss: 0.861506462097168
Validation loss: 2.2031806657711663

Epoch: 5| Step: 6
Training loss: 0.475947767496109
Validation loss: 2.2193494389454522

Epoch: 5| Step: 7
Training loss: 0.5856366157531738
Validation loss: 2.318457136551539

Epoch: 5| Step: 8
Training loss: 0.8111961483955383
Validation loss: 2.309925466775894

Epoch: 5| Step: 9
Training loss: 0.7888469696044922
Validation loss: 2.262697756290436

Epoch: 5| Step: 10
Training loss: 1.4462566375732422
Validation loss: 2.2930269141991935

Epoch: 5| Step: 11
Training loss: 1.3502055406570435
Validation loss: 2.339022989074389

Epoch: 182| Step: 0
Training loss: 0.9268595576286316
Validation loss: 2.2915423760811486

Epoch: 5| Step: 1
Training loss: 0.943867027759552
Validation loss: 2.173075099786123

Epoch: 5| Step: 2
Training loss: 1.2152388095855713
Validation loss: 2.223799447218577

Epoch: 5| Step: 3
Training loss: 0.8753007054328918
Validation loss: 2.184322069088618

Epoch: 5| Step: 4
Training loss: 1.0285265445709229
Validation loss: 2.202697361509005

Epoch: 5| Step: 5
Training loss: 0.9399328231811523
Validation loss: 2.245861291885376

Epoch: 5| Step: 6
Training loss: 0.5506063103675842
Validation loss: 2.273612762490908

Epoch: 5| Step: 7
Training loss: 0.6758518218994141
Validation loss: 2.3695485293865204

Epoch: 5| Step: 8
Training loss: 0.46270933747291565
Validation loss: 2.28133096297582

Epoch: 5| Step: 9
Training loss: 0.8378745913505554
Validation loss: 2.3103554248809814

Epoch: 5| Step: 10
Training loss: 1.174682855606079
Validation loss: 2.2606678009033203

Epoch: 5| Step: 11
Training loss: 1.6078695058822632
Validation loss: 2.2305608640114465

Epoch: 183| Step: 0
Training loss: 0.8406865000724792
Validation loss: 2.2126440604527793

Epoch: 5| Step: 1
Training loss: 0.9295059442520142
Validation loss: 2.1908499201138816

Epoch: 5| Step: 2
Training loss: 1.5601410865783691
Validation loss: 2.2299872040748596

Epoch: 5| Step: 3
Training loss: 1.4055445194244385
Validation loss: 2.1770914793014526

Epoch: 5| Step: 4
Training loss: 0.6729857325553894
Validation loss: 2.2091723680496216

Epoch: 5| Step: 5
Training loss: 0.5848230123519897
Validation loss: 2.2318763732910156

Epoch: 5| Step: 6
Training loss: 1.2137647867202759
Validation loss: 2.2164043287436166

Epoch: 5| Step: 7
Training loss: 0.6362050771713257
Validation loss: 2.321664740641912

Epoch: 5| Step: 8
Training loss: 0.7030075788497925
Validation loss: 2.3463655412197113

Epoch: 5| Step: 9
Training loss: 0.8374046087265015
Validation loss: 2.3216328422228494

Epoch: 5| Step: 10
Training loss: 1.0512008666992188
Validation loss: 2.2967577626307807

Epoch: 5| Step: 11
Training loss: 1.3251445293426514
Validation loss: 2.2650196701288223

Epoch: 184| Step: 0
Training loss: 1.4117482900619507
Validation loss: 2.1925244331359863

Epoch: 5| Step: 1
Training loss: 0.777801513671875
Validation loss: 2.2400765120983124

Epoch: 5| Step: 2
Training loss: 0.6467994451522827
Validation loss: 2.224383612473806

Epoch: 5| Step: 3
Training loss: 1.510010004043579
Validation loss: 2.179694483677546

Epoch: 5| Step: 4
Training loss: 1.035657286643982
Validation loss: 2.191852882504463

Epoch: 5| Step: 5
Training loss: 0.40126484632492065
Validation loss: 2.2115229020516076

Epoch: 5| Step: 6
Training loss: 0.806435763835907
Validation loss: 2.271258140603701

Epoch: 5| Step: 7
Training loss: 0.8542216420173645
Validation loss: 2.3182833939790726

Epoch: 5| Step: 8
Training loss: 1.0588973760604858
Validation loss: 2.368727599581083

Epoch: 5| Step: 9
Training loss: 0.5055285692214966
Validation loss: 2.299583504597346

Epoch: 5| Step: 10
Training loss: 0.7981604337692261
Validation loss: 2.2637063761552176

Epoch: 5| Step: 11
Training loss: 0.15416991710662842
Validation loss: 2.1933994640906653

Epoch: 185| Step: 0
Training loss: 0.7259233593940735
Validation loss: 2.279727498690287

Epoch: 5| Step: 1
Training loss: 1.1972250938415527
Validation loss: 2.2381942868232727

Epoch: 5| Step: 2
Training loss: 0.6113011240959167
Validation loss: 2.2573650976022086

Epoch: 5| Step: 3
Training loss: 0.4894011914730072
Validation loss: 2.299341623981794

Epoch: 5| Step: 4
Training loss: 1.0683414936065674
Validation loss: 2.308780332406362

Epoch: 5| Step: 5
Training loss: 0.6196486353874207
Validation loss: 2.1587426960468292

Epoch: 5| Step: 6
Training loss: 0.7857123017311096
Validation loss: 2.146874040365219

Epoch: 5| Step: 7
Training loss: 0.7563575506210327
Validation loss: 2.2268866101900735

Epoch: 5| Step: 8
Training loss: 0.9490882754325867
Validation loss: 2.173115462064743

Epoch: 5| Step: 9
Training loss: 0.6567378640174866
Validation loss: 2.185570369164149

Epoch: 5| Step: 10
Training loss: 0.8177433013916016
Validation loss: 2.184393271803856

Epoch: 5| Step: 11
Training loss: 0.43262189626693726
Validation loss: 2.202527195215225

Epoch: 186| Step: 0
Training loss: 0.713788628578186
Validation loss: 2.2005652536948523

Epoch: 5| Step: 1
Training loss: 0.9926891326904297
Validation loss: 2.2557569096485772

Epoch: 5| Step: 2
Training loss: 1.1104400157928467
Validation loss: 2.327835996945699

Epoch: 5| Step: 3
Training loss: 0.6561208963394165
Validation loss: 2.1903671671946845

Epoch: 5| Step: 4
Training loss: 0.5140827894210815
Validation loss: 2.207623446981112

Epoch: 5| Step: 5
Training loss: 0.7124729156494141
Validation loss: 2.184504290421804

Epoch: 5| Step: 6
Training loss: 1.0995113849639893
Validation loss: 2.1871389597654343

Epoch: 5| Step: 7
Training loss: 0.7583953142166138
Validation loss: 2.2207165509462357

Epoch: 5| Step: 8
Training loss: 0.9308622479438782
Validation loss: 2.216681038339933

Epoch: 5| Step: 9
Training loss: 0.853140652179718
Validation loss: 2.2255151718854904

Epoch: 5| Step: 10
Training loss: 0.7586331367492676
Validation loss: 2.23552413781484

Epoch: 5| Step: 11
Training loss: 0.42199423909187317
Validation loss: 2.2635177671909332

Epoch: 187| Step: 0
Training loss: 1.0406944751739502
Validation loss: 2.216822773218155

Epoch: 5| Step: 1
Training loss: 1.0268518924713135
Validation loss: 2.1611524323622384

Epoch: 5| Step: 2
Training loss: 0.6155441403388977
Validation loss: 2.268936057885488

Epoch: 5| Step: 3
Training loss: 0.6320396661758423
Validation loss: 2.2014571328957877

Epoch: 5| Step: 4
Training loss: 0.3379027247428894
Validation loss: 2.2472325613101325

Epoch: 5| Step: 5
Training loss: 1.0612729787826538
Validation loss: 2.223347802956899

Epoch: 5| Step: 6
Training loss: 0.6488909125328064
Validation loss: 2.25990429520607

Epoch: 5| Step: 7
Training loss: 0.9489531517028809
Validation loss: 2.3458401262760162

Epoch: 5| Step: 8
Training loss: 0.49751338362693787
Validation loss: 2.31906388203303

Epoch: 5| Step: 9
Training loss: 1.0335745811462402
Validation loss: 2.2105244298775992

Epoch: 5| Step: 10
Training loss: 0.68525230884552
Validation loss: 2.305340732137362

Epoch: 5| Step: 11
Training loss: 0.5185520648956299
Validation loss: 2.2797311743100486

Epoch: 188| Step: 0
Training loss: 0.30912914872169495
Validation loss: 2.2173599302768707

Epoch: 5| Step: 1
Training loss: 0.6657313108444214
Validation loss: 2.247778137524923

Epoch: 5| Step: 2
Training loss: 1.124186396598816
Validation loss: 2.219916671514511

Epoch: 5| Step: 3
Training loss: 0.9753463864326477
Validation loss: 2.211866090695063

Epoch: 5| Step: 4
Training loss: 0.9108973741531372
Validation loss: 2.219583253065745

Epoch: 5| Step: 5
Training loss: 0.5434325933456421
Validation loss: 2.2787290811538696

Epoch: 5| Step: 6
Training loss: 0.5502130389213562
Validation loss: 2.1712996810674667

Epoch: 5| Step: 7
Training loss: 0.8687236905097961
Validation loss: 2.2431163440148034

Epoch: 5| Step: 8
Training loss: 0.8887581825256348
Validation loss: 2.2568692515293756

Epoch: 5| Step: 9
Training loss: 0.7929996252059937
Validation loss: 2.2618893881638846

Epoch: 5| Step: 10
Training loss: 0.9702577590942383
Validation loss: 2.3121223797400794

Epoch: 5| Step: 11
Training loss: 0.6261200308799744
Validation loss: 2.2735384702682495

Epoch: 189| Step: 0
Training loss: 0.86578369140625
Validation loss: 2.287754714488983

Epoch: 5| Step: 1
Training loss: 0.6977840662002563
Validation loss: 2.2612317701180777

Epoch: 5| Step: 2
Training loss: 0.8533014059066772
Validation loss: 2.2471591383218765

Epoch: 5| Step: 3
Training loss: 0.6797666549682617
Validation loss: 2.27015420794487

Epoch: 5| Step: 4
Training loss: 0.5870113372802734
Validation loss: 2.2192535549402237

Epoch: 5| Step: 5
Training loss: 0.540446400642395
Validation loss: 2.198019494613012

Epoch: 5| Step: 6
Training loss: 0.9007035493850708
Validation loss: 2.2162816673517227

Epoch: 5| Step: 7
Training loss: 1.437753438949585
Validation loss: 2.237350026766459

Epoch: 5| Step: 8
Training loss: 0.8312410116195679
Validation loss: 2.251455177863439

Epoch: 5| Step: 9
Training loss: 0.5550233125686646
Validation loss: 2.2590612272421517

Epoch: 5| Step: 10
Training loss: 0.7082192301750183
Validation loss: 2.258449286222458

Epoch: 5| Step: 11
Training loss: 0.4612797498703003
Validation loss: 2.2374775807062783

Epoch: 190| Step: 0
Training loss: 0.8742138147354126
Validation loss: 2.234371284643809

Epoch: 5| Step: 1
Training loss: 0.5199562311172485
Validation loss: 2.2467064261436462

Epoch: 5| Step: 2
Training loss: 1.0648678541183472
Validation loss: 2.182198236385981

Epoch: 5| Step: 3
Training loss: 1.1633169651031494
Validation loss: 2.2256796459356942

Epoch: 5| Step: 4
Training loss: 0.746425986289978
Validation loss: 2.2579931815465293

Epoch: 5| Step: 5
Training loss: 0.6211785078048706
Validation loss: 2.210123231013616

Epoch: 5| Step: 6
Training loss: 0.8207263946533203
Validation loss: 2.227016101280848

Epoch: 5| Step: 7
Training loss: 0.40945982933044434
Validation loss: 2.2337374289830527

Epoch: 5| Step: 8
Training loss: 0.9836294054985046
Validation loss: 2.2226185897986093

Epoch: 5| Step: 9
Training loss: 0.6400139927864075
Validation loss: 2.1813121239344277

Epoch: 5| Step: 10
Training loss: 0.4870685935020447
Validation loss: 2.277123918135961

Epoch: 5| Step: 11
Training loss: 0.6466636657714844
Validation loss: 2.2082353780666986

Epoch: 191| Step: 0
Training loss: 0.5433675050735474
Validation loss: 2.245335121949514

Epoch: 5| Step: 1
Training loss: 0.8785764575004578
Validation loss: 2.2525691340367

Epoch: 5| Step: 2
Training loss: 1.1328002214431763
Validation loss: 2.3080316881338754

Epoch: 5| Step: 3
Training loss: 0.8916195631027222
Validation loss: 2.3666829615831375

Epoch: 5| Step: 4
Training loss: 1.174960732460022
Validation loss: 2.257094914714495

Epoch: 5| Step: 5
Training loss: 0.31537652015686035
Validation loss: 2.314091523488363

Epoch: 5| Step: 6
Training loss: 1.0298528671264648
Validation loss: 2.2725718021392822

Epoch: 5| Step: 7
Training loss: 0.6440527439117432
Validation loss: 2.242676392197609

Epoch: 5| Step: 8
Training loss: 0.8301385641098022
Validation loss: 2.225689952572187

Epoch: 5| Step: 9
Training loss: 0.45540064573287964
Validation loss: 2.2349894990523658

Epoch: 5| Step: 10
Training loss: 1.177983283996582
Validation loss: 2.2310910820961

Epoch: 5| Step: 11
Training loss: 1.5060806274414062
Validation loss: 2.2576695680618286

Epoch: 192| Step: 0
Training loss: 0.848935604095459
Validation loss: 2.289621978998184

Epoch: 5| Step: 1
Training loss: 0.47212299704551697
Validation loss: 2.222043047348658

Epoch: 5| Step: 2
Training loss: 0.6253447532653809
Validation loss: 2.3210384100675583

Epoch: 5| Step: 3
Training loss: 0.9678837656974792
Validation loss: 2.248484661181768

Epoch: 5| Step: 4
Training loss: 0.7557539939880371
Validation loss: 2.2377878626187644

Epoch: 5| Step: 5
Training loss: 0.9992473721504211
Validation loss: 2.3307589292526245

Epoch: 5| Step: 6
Training loss: 1.0944130420684814
Validation loss: 2.35401780406634

Epoch: 5| Step: 7
Training loss: 0.7715926766395569
Validation loss: 2.2249766141176224

Epoch: 5| Step: 8
Training loss: 0.5261768102645874
Validation loss: 2.3106781442960105

Epoch: 5| Step: 9
Training loss: 0.8499940037727356
Validation loss: 2.2557607094446817

Epoch: 5| Step: 10
Training loss: 0.45187482237815857
Validation loss: 2.2080074548721313

Epoch: 5| Step: 11
Training loss: 0.6141146421432495
Validation loss: 2.281094864010811

Epoch: 193| Step: 0
Training loss: 0.734994113445282
Validation loss: 2.2656997740268707

Epoch: 5| Step: 1
Training loss: 0.7151311635971069
Validation loss: 2.2698905219634375

Epoch: 5| Step: 2
Training loss: 0.8386987447738647
Validation loss: 2.334485560655594

Epoch: 5| Step: 3
Training loss: 0.7204968929290771
Validation loss: 2.3317194133996964

Epoch: 5| Step: 4
Training loss: 0.9203661680221558
Validation loss: 2.17859415213267

Epoch: 5| Step: 5
Training loss: 0.3591982424259186
Validation loss: 2.283781518538793

Epoch: 5| Step: 6
Training loss: 1.2207554578781128
Validation loss: 2.282398208975792

Epoch: 5| Step: 7
Training loss: 0.8560771942138672
Validation loss: 2.2612291475137076

Epoch: 5| Step: 8
Training loss: 0.43570050597190857
Validation loss: 2.2742527375618615

Epoch: 5| Step: 9
Training loss: 0.7965835332870483
Validation loss: 2.191549609104792

Epoch: 5| Step: 10
Training loss: 0.878251850605011
Validation loss: 2.1888269980748496

Epoch: 5| Step: 11
Training loss: 1.412795901298523
Validation loss: 2.1997523804505668

Epoch: 194| Step: 0
Training loss: 1.2429382801055908
Validation loss: 2.1963624407847724

Epoch: 5| Step: 1
Training loss: 0.692409098148346
Validation loss: 2.187280168135961

Epoch: 5| Step: 2
Training loss: 0.6975702047348022
Validation loss: 2.2886966864267984

Epoch: 5| Step: 3
Training loss: 0.6761978268623352
Validation loss: 2.334012577931086

Epoch: 5| Step: 4
Training loss: 1.307431936264038
Validation loss: 2.377933924396833

Epoch: 5| Step: 5
Training loss: 0.731045126914978
Validation loss: 2.3031475444634757

Epoch: 5| Step: 6
Training loss: 0.7269219160079956
Validation loss: 2.257914940516154

Epoch: 5| Step: 7
Training loss: 0.6817378401756287
Validation loss: 2.2616370220979056

Epoch: 5| Step: 8
Training loss: 0.6306474208831787
Validation loss: 2.2854678680499396

Epoch: 5| Step: 9
Training loss: 0.44003456830978394
Validation loss: 2.222548325856527

Epoch: 5| Step: 10
Training loss: 0.5971872806549072
Validation loss: 2.210051645835241

Epoch: 5| Step: 11
Training loss: 0.4139798879623413
Validation loss: 2.2310032546520233

Epoch: 195| Step: 0
Training loss: 0.46569663286209106
Validation loss: 2.1913956304391227

Epoch: 5| Step: 1
Training loss: 0.4387508034706116
Validation loss: 2.289556230107943

Epoch: 5| Step: 2
Training loss: 0.8798681497573853
Validation loss: 2.2466774185498557

Epoch: 5| Step: 3
Training loss: 0.8693858981132507
Validation loss: 2.3038096725940704

Epoch: 5| Step: 4
Training loss: 0.49038976430892944
Validation loss: 2.3245588541030884

Epoch: 5| Step: 5
Training loss: 0.6610773205757141
Validation loss: 2.3056948681672416

Epoch: 5| Step: 6
Training loss: 0.7855481505393982
Validation loss: 2.2190729628006616

Epoch: 5| Step: 7
Training loss: 0.9015819430351257
Validation loss: 2.2829527656237283

Epoch: 5| Step: 8
Training loss: 1.0060043334960938
Validation loss: 2.217274402578672

Epoch: 5| Step: 9
Training loss: 1.3316431045532227
Validation loss: 2.268281822403272

Epoch: 5| Step: 10
Training loss: 0.5000211000442505
Validation loss: 2.1727678080399833

Epoch: 5| Step: 11
Training loss: 0.28699538111686707
Validation loss: 2.1976502388715744

Epoch: 196| Step: 0
Training loss: 0.7894645929336548
Validation loss: 2.192053327957789

Epoch: 5| Step: 1
Training loss: 0.6640911102294922
Validation loss: 2.236835648616155

Epoch: 5| Step: 2
Training loss: 0.5047444105148315
Validation loss: 2.259622941414515

Epoch: 5| Step: 3
Training loss: 0.9451228380203247
Validation loss: 2.3179333060979843

Epoch: 5| Step: 4
Training loss: 1.0064812898635864
Validation loss: 2.379449645678202

Epoch: 5| Step: 5
Training loss: 0.7068549990653992
Validation loss: 2.3287636588017144

Epoch: 5| Step: 6
Training loss: 0.5272356867790222
Validation loss: 2.345409572124481

Epoch: 5| Step: 7
Training loss: 0.9752397537231445
Validation loss: 2.2814844896396003

Epoch: 5| Step: 8
Training loss: 0.8034855127334595
Validation loss: 2.2720386385917664

Epoch: 5| Step: 9
Training loss: 0.5328707695007324
Validation loss: 2.2574032843112946

Epoch: 5| Step: 10
Training loss: 0.8449894189834595
Validation loss: 2.2501613398392997

Epoch: 5| Step: 11
Training loss: 0.5277091264724731
Validation loss: 2.2485378036896386

Epoch: 197| Step: 0
Training loss: 0.6747869253158569
Validation loss: 2.234915181994438

Epoch: 5| Step: 1
Training loss: 0.7167174816131592
Validation loss: 2.330952296654383

Epoch: 5| Step: 2
Training loss: 0.7511361837387085
Validation loss: 2.4087087213993073

Epoch: 5| Step: 3
Training loss: 1.2192119359970093
Validation loss: 2.368750269214312

Epoch: 5| Step: 4
Training loss: 0.9423457384109497
Validation loss: 2.348351796468099

Epoch: 5| Step: 5
Training loss: 0.4259556233882904
Validation loss: 2.2348523437976837

Epoch: 5| Step: 6
Training loss: 0.5792814493179321
Validation loss: 2.2437719206015267

Epoch: 5| Step: 7
Training loss: 1.2166789770126343
Validation loss: 2.196970800558726

Epoch: 5| Step: 8
Training loss: 0.6594468951225281
Validation loss: 2.2214336643616357

Epoch: 5| Step: 9
Training loss: 0.4246719777584076
Validation loss: 2.179625779390335

Epoch: 5| Step: 10
Training loss: 1.1786696910858154
Validation loss: 2.24768927693367

Epoch: 5| Step: 11
Training loss: 0.3528521656990051
Validation loss: 2.2419561247030892

Epoch: 198| Step: 0
Training loss: 0.8341226577758789
Validation loss: 2.180336818099022

Epoch: 5| Step: 1
Training loss: 0.3429863154888153
Validation loss: 2.2352602084477744

Epoch: 5| Step: 2
Training loss: 0.6982152462005615
Validation loss: 2.2534417510032654

Epoch: 5| Step: 3
Training loss: 0.7182217240333557
Validation loss: 2.2729620039463043

Epoch: 5| Step: 4
Training loss: 0.92139732837677
Validation loss: 2.1666459490855536

Epoch: 5| Step: 5
Training loss: 0.8921495676040649
Validation loss: 2.256650616725286

Epoch: 5| Step: 6
Training loss: 0.8459946513175964
Validation loss: 2.207953989505768

Epoch: 5| Step: 7
Training loss: 0.5775376558303833
Validation loss: 2.1921265920003257

Epoch: 5| Step: 8
Training loss: 0.8464496731758118
Validation loss: 2.2518263260523477

Epoch: 5| Step: 9
Training loss: 0.5991023778915405
Validation loss: 2.276811882853508

Epoch: 5| Step: 10
Training loss: 0.8136356472969055
Validation loss: 2.260346601406733

Epoch: 5| Step: 11
Training loss: 0.8748753070831299
Validation loss: 2.293415610988935

Epoch: 199| Step: 0
Training loss: 0.4586847722530365
Validation loss: 2.2926453252633414

Epoch: 5| Step: 1
Training loss: 0.4250747561454773
Validation loss: 2.2500744511683783

Epoch: 5| Step: 2
Training loss: 0.7946465611457825
Validation loss: 2.2289396276076636

Epoch: 5| Step: 3
Training loss: 0.7650385499000549
Validation loss: 2.2709450125694275

Epoch: 5| Step: 4
Training loss: 1.121416449546814
Validation loss: 2.2699225644270578

Epoch: 5| Step: 5
Training loss: 0.5294836163520813
Validation loss: 2.2217575907707214

Epoch: 5| Step: 6
Training loss: 0.42651495337486267
Validation loss: 2.285412515203158

Epoch: 5| Step: 7
Training loss: 0.933996856212616
Validation loss: 2.2830802649259567

Epoch: 5| Step: 8
Training loss: 0.7027661204338074
Validation loss: 2.3513262271881104

Epoch: 5| Step: 9
Training loss: 0.8212209939956665
Validation loss: 2.2980177799860635

Epoch: 5| Step: 10
Training loss: 0.7106568217277527
Validation loss: 2.385535180568695

Epoch: 5| Step: 11
Training loss: 0.894800066947937
Validation loss: 2.250608811775843

Epoch: 200| Step: 0
Training loss: 0.6324546933174133
Validation loss: 2.3282854755719504

Epoch: 5| Step: 1
Training loss: 0.5932737588882446
Validation loss: 2.291750659545263

Epoch: 5| Step: 2
Training loss: 1.0186372995376587
Validation loss: 2.2189102321863174

Epoch: 5| Step: 3
Training loss: 0.7116596102714539
Validation loss: 2.1906349460283914

Epoch: 5| Step: 4
Training loss: 0.5510886907577515
Validation loss: 2.157198632756869

Epoch: 5| Step: 5
Training loss: 0.6772834658622742
Validation loss: 2.2850069602330527

Epoch: 5| Step: 6
Training loss: 0.7893407940864563
Validation loss: 2.226235647996267

Epoch: 5| Step: 7
Training loss: 0.7442017793655396
Validation loss: 2.258531262477239

Epoch: 5| Step: 8
Training loss: 1.0675837993621826
Validation loss: 2.3162789791822433

Epoch: 5| Step: 9
Training loss: 0.8861238360404968
Validation loss: 2.3213912149270377

Epoch: 5| Step: 10
Training loss: 0.6960160732269287
Validation loss: 2.234237531820933

Epoch: 5| Step: 11
Training loss: 0.4607558846473694
Validation loss: 2.206044480204582

Epoch: 201| Step: 0
Training loss: 0.7628933191299438
Validation loss: 2.1915924002726874

Epoch: 5| Step: 1
Training loss: 0.9930262565612793
Validation loss: 2.2332523663838706

Epoch: 5| Step: 2
Training loss: 1.0679495334625244
Validation loss: 2.192801520228386

Epoch: 5| Step: 3
Training loss: 0.6152303218841553
Validation loss: 2.2046145697434745

Epoch: 5| Step: 4
Training loss: 0.661843478679657
Validation loss: 2.2182058493296304

Epoch: 5| Step: 5
Training loss: 0.7034492492675781
Validation loss: 2.268598814805349

Epoch: 5| Step: 6
Training loss: 0.5989581346511841
Validation loss: 2.255749821662903

Epoch: 5| Step: 7
Training loss: 0.49756836891174316
Validation loss: 2.3262732525666556

Epoch: 5| Step: 8
Training loss: 0.7743369340896606
Validation loss: 2.2772918194532394

Epoch: 5| Step: 9
Training loss: 0.9403669238090515
Validation loss: 2.304046402374903

Epoch: 5| Step: 10
Training loss: 0.6687344312667847
Validation loss: 2.2540195981661477

Epoch: 5| Step: 11
Training loss: 0.5266241431236267
Validation loss: 2.2319200138250985

Epoch: 202| Step: 0
Training loss: 0.47502046823501587
Validation loss: 2.2747467160224915

Epoch: 5| Step: 1
Training loss: 0.47927695512771606
Validation loss: 2.390109365185102

Epoch: 5| Step: 2
Training loss: 0.4383886754512787
Validation loss: 2.315990681449572

Epoch: 5| Step: 3
Training loss: 0.8329280018806458
Validation loss: 2.295509566863378

Epoch: 5| Step: 4
Training loss: 0.9465044736862183
Validation loss: 2.2461802264054618

Epoch: 5| Step: 5
Training loss: 0.8018625378608704
Validation loss: 2.2691974341869354

Epoch: 5| Step: 6
Training loss: 0.6664679646492004
Validation loss: 2.3494062622388205

Epoch: 5| Step: 7
Training loss: 1.1125879287719727
Validation loss: 2.2509047985076904

Epoch: 5| Step: 8
Training loss: 0.5593779683113098
Validation loss: 2.3102537989616394

Epoch: 5| Step: 9
Training loss: 0.9537068605422974
Validation loss: 2.355336437622706

Epoch: 5| Step: 10
Training loss: 0.5649169683456421
Validation loss: 2.3247812489668527

Epoch: 5| Step: 11
Training loss: 0.8865388631820679
Validation loss: 2.324479023615519

Epoch: 203| Step: 0
Training loss: 0.5542014241218567
Validation loss: 2.2973044912020364

Epoch: 5| Step: 1
Training loss: 0.8388752937316895
Validation loss: 2.2447564204533896

Epoch: 5| Step: 2
Training loss: 0.8090316653251648
Validation loss: 2.2800121009349823

Epoch: 5| Step: 3
Training loss: 0.7158306837081909
Validation loss: 2.2361192802588143

Epoch: 5| Step: 4
Training loss: 0.8974035382270813
Validation loss: 2.277757247289022

Epoch: 5| Step: 5
Training loss: 0.7670134902000427
Validation loss: 2.2161038468281427

Epoch: 5| Step: 6
Training loss: 0.7077499628067017
Validation loss: 2.2447971204916635

Epoch: 5| Step: 7
Training loss: 0.48196691274642944
Validation loss: 2.290052741765976

Epoch: 5| Step: 8
Training loss: 0.5133731961250305
Validation loss: 2.258434772491455

Epoch: 5| Step: 9
Training loss: 0.7069587707519531
Validation loss: 2.2399297952651978

Epoch: 5| Step: 10
Training loss: 0.45193034410476685
Validation loss: 2.2963314602772393

Epoch: 5| Step: 11
Training loss: 1.1154969930648804
Validation loss: 2.3012765993674598

Epoch: 204| Step: 0
Training loss: 0.7481991052627563
Validation loss: 2.1707683006922402

Epoch: 5| Step: 1
Training loss: 1.206268072128296
Validation loss: 2.1888049046198526

Epoch: 5| Step: 2
Training loss: 0.6309190988540649
Validation loss: 2.2660279969374337

Epoch: 5| Step: 3
Training loss: 0.6354057192802429
Validation loss: 2.1979678322871528

Epoch: 5| Step: 4
Training loss: 0.3983781039714813
Validation loss: 2.276215727130572

Epoch: 5| Step: 5
Training loss: 0.7416173815727234
Validation loss: 2.240249822537104

Epoch: 5| Step: 6
Training loss: 0.8870668411254883
Validation loss: 2.288265218337377

Epoch: 5| Step: 7
Training loss: 0.4011901319026947
Validation loss: 2.2875353594621024

Epoch: 5| Step: 8
Training loss: 0.7377984523773193
Validation loss: 2.2754233479499817

Epoch: 5| Step: 9
Training loss: 0.7197486758232117
Validation loss: 2.331249848008156

Epoch: 5| Step: 10
Training loss: 0.5572434663772583
Validation loss: 2.246184771259626

Epoch: 5| Step: 11
Training loss: 0.26446768641471863
Validation loss: 2.2527123192946115

Epoch: 205| Step: 0
Training loss: 0.8204900026321411
Validation loss: 2.2726233998934426

Epoch: 5| Step: 1
Training loss: 0.5852450132369995
Validation loss: 2.2924415369828544

Epoch: 5| Step: 2
Training loss: 0.6421523094177246
Validation loss: 2.3395140767097473

Epoch: 5| Step: 3
Training loss: 0.6989601850509644
Validation loss: 2.3266195356845856

Epoch: 5| Step: 4
Training loss: 0.5205861330032349
Validation loss: 2.3057523717482886

Epoch: 5| Step: 5
Training loss: 0.6293143033981323
Validation loss: 2.288838346799215

Epoch: 5| Step: 6
Training loss: 0.7914365530014038
Validation loss: 2.246841092904409

Epoch: 5| Step: 7
Training loss: 0.9107924699783325
Validation loss: 2.2416088630755744

Epoch: 5| Step: 8
Training loss: 0.628871738910675
Validation loss: 2.2098221331834793

Epoch: 5| Step: 9
Training loss: 0.7168883085250854
Validation loss: 2.3312511245409646

Epoch: 5| Step: 10
Training loss: 0.6419459581375122
Validation loss: 2.240771859884262

Epoch: 5| Step: 11
Training loss: 0.2557937502861023
Validation loss: 2.3117988804976144

Epoch: 206| Step: 0
Training loss: 0.9721019864082336
Validation loss: 2.262519637743632

Epoch: 5| Step: 1
Training loss: 0.8581578135490417
Validation loss: 2.293985595305761

Epoch: 5| Step: 2
Training loss: 0.4309267997741699
Validation loss: 2.313991670807203

Epoch: 5| Step: 3
Training loss: 0.702330470085144
Validation loss: 2.3678714285294213

Epoch: 5| Step: 4
Training loss: 0.9836869239807129
Validation loss: 2.300389369328817

Epoch: 5| Step: 5
Training loss: 0.5619430541992188
Validation loss: 2.256959319114685

Epoch: 5| Step: 6
Training loss: 0.5506945848464966
Validation loss: 2.2583001454671225

Epoch: 5| Step: 7
Training loss: 0.6633750796318054
Validation loss: 2.2572147895892463

Epoch: 5| Step: 8
Training loss: 0.7112377882003784
Validation loss: 2.2794268429279327

Epoch: 5| Step: 9
Training loss: 0.6051412224769592
Validation loss: 2.2342168937126794

Epoch: 5| Step: 10
Training loss: 0.42715516686439514
Validation loss: 2.181619639197985

Epoch: 5| Step: 11
Training loss: 0.11496162414550781
Validation loss: 2.2724828322728476

Epoch: 207| Step: 0
Training loss: 0.5142104625701904
Validation loss: 2.3048978745937347

Epoch: 5| Step: 1
Training loss: 1.129578948020935
Validation loss: 2.2642666002114615

Epoch: 5| Step: 2
Training loss: 0.757529079914093
Validation loss: 2.2276954501867294

Epoch: 5| Step: 3
Training loss: 0.4083313047885895
Validation loss: 2.212382743755976

Epoch: 5| Step: 4
Training loss: 0.6370193362236023
Validation loss: 2.256252035498619

Epoch: 5| Step: 5
Training loss: 0.5421614646911621
Validation loss: 2.237805644671122

Epoch: 5| Step: 6
Training loss: 0.7688549160957336
Validation loss: 2.296924610932668

Epoch: 5| Step: 7
Training loss: 0.6824985146522522
Validation loss: 2.2449424167474112

Epoch: 5| Step: 8
Training loss: 0.7657306790351868
Validation loss: 2.2386834720770517

Epoch: 5| Step: 9
Training loss: 0.826930046081543
Validation loss: 2.26362407207489

Epoch: 5| Step: 10
Training loss: 0.6437867879867554
Validation loss: 2.2396409859259925

Epoch: 5| Step: 11
Training loss: 0.542593777179718
Validation loss: 2.282865216334661

Epoch: 208| Step: 0
Training loss: 0.8952953219413757
Validation loss: 2.310804853836695

Epoch: 5| Step: 1
Training loss: 0.5854649543762207
Validation loss: 2.2814601560433707

Epoch: 5| Step: 2
Training loss: 0.47522082924842834
Validation loss: 2.289041335384051

Epoch: 5| Step: 3
Training loss: 0.5963021516799927
Validation loss: 2.2028283129135766

Epoch: 5| Step: 4
Training loss: 0.9426838159561157
Validation loss: 2.217998151977857

Epoch: 5| Step: 5
Training loss: 0.6951109170913696
Validation loss: 2.2243076860904694

Epoch: 5| Step: 6
Training loss: 0.3744182586669922
Validation loss: 2.241124004125595

Epoch: 5| Step: 7
Training loss: 0.4316643178462982
Validation loss: 2.228313540418943

Epoch: 5| Step: 8
Training loss: 1.0390278100967407
Validation loss: 2.235932856798172

Epoch: 5| Step: 9
Training loss: 0.8727663159370422
Validation loss: 2.2950921654701233

Epoch: 5| Step: 10
Training loss: 0.6133291125297546
Validation loss: 2.3490893840789795

Epoch: 5| Step: 11
Training loss: 0.1961207091808319
Validation loss: 2.3406567374865213

Epoch: 209| Step: 0
Training loss: 0.4997451901435852
Validation loss: 2.311151012778282

Epoch: 5| Step: 1
Training loss: 0.43266114592552185
Validation loss: 2.2812060614426932

Epoch: 5| Step: 2
Training loss: 0.5183324813842773
Validation loss: 2.274210572242737

Epoch: 5| Step: 3
Training loss: 0.6142968535423279
Validation loss: 2.2231976091861725

Epoch: 5| Step: 4
Training loss: 0.6335428953170776
Validation loss: 2.2326201101144156

Epoch: 5| Step: 5
Training loss: 0.5772363543510437
Validation loss: 2.2494613428910575

Epoch: 5| Step: 6
Training loss: 1.08977210521698
Validation loss: 2.2640226085980735

Epoch: 5| Step: 7
Training loss: 0.7860514521598816
Validation loss: 2.267435679833094

Epoch: 5| Step: 8
Training loss: 0.9894863367080688
Validation loss: 2.313027878602346

Epoch: 5| Step: 9
Training loss: 0.5738715529441833
Validation loss: 2.3243970473607383

Epoch: 5| Step: 10
Training loss: 0.2994305193424225
Validation loss: 2.230792313814163

Epoch: 5| Step: 11
Training loss: 0.568334698677063
Validation loss: 2.2575181225935617

Epoch: 210| Step: 0
Training loss: 0.5527983903884888
Validation loss: 2.2596791287263236

Epoch: 5| Step: 1
Training loss: 0.8487117886543274
Validation loss: 2.2512709150711694

Epoch: 5| Step: 2
Training loss: 0.5769230127334595
Validation loss: 2.182873770594597

Epoch: 5| Step: 3
Training loss: 0.7215370535850525
Validation loss: 2.2908924420674643

Epoch: 5| Step: 4
Training loss: 0.6793083548545837
Validation loss: 2.3188515305519104

Epoch: 5| Step: 5
Training loss: 0.6024196743965149
Validation loss: 2.2741324255863824

Epoch: 5| Step: 6
Training loss: 0.8855635523796082
Validation loss: 2.2971370120843253

Epoch: 5| Step: 7
Training loss: 0.5513495802879333
Validation loss: 2.2526580542325974

Epoch: 5| Step: 8
Training loss: 0.7930177450180054
Validation loss: 2.306816875934601

Epoch: 5| Step: 9
Training loss: 0.5140098333358765
Validation loss: 2.2591151197751365

Epoch: 5| Step: 10
Training loss: 0.5555217862129211
Validation loss: 2.2758609553178153

Epoch: 5| Step: 11
Training loss: 0.2988726496696472
Validation loss: 2.31103208164374

Epoch: 211| Step: 0
Training loss: 0.7712852358818054
Validation loss: 2.3296582102775574

Epoch: 5| Step: 1
Training loss: 0.6648649573326111
Validation loss: 2.3480411171913147

Epoch: 5| Step: 2
Training loss: 0.6323617100715637
Validation loss: 2.341749240954717

Epoch: 5| Step: 3
Training loss: 0.606674313545227
Validation loss: 2.307707687218984

Epoch: 5| Step: 4
Training loss: 0.5371219515800476
Validation loss: 2.2430642942587533

Epoch: 5| Step: 5
Training loss: 0.6322418451309204
Validation loss: 2.248606617252032

Epoch: 5| Step: 6
Training loss: 0.479818195104599
Validation loss: 2.2054314812024436

Epoch: 5| Step: 7
Training loss: 0.7820971012115479
Validation loss: 2.2230626046657562

Epoch: 5| Step: 8
Training loss: 1.059571623802185
Validation loss: 2.271276871363322

Epoch: 5| Step: 9
Training loss: 0.6048111915588379
Validation loss: 2.263038605451584

Epoch: 5| Step: 10
Training loss: 0.5533580780029297
Validation loss: 2.262369672457377

Epoch: 5| Step: 11
Training loss: 1.51712167263031
Validation loss: 2.3024286727110543

Epoch: 212| Step: 0
Training loss: 0.9159095883369446
Validation loss: 2.2910909156004586

Epoch: 5| Step: 1
Training loss: 1.1994062662124634
Validation loss: 2.258361349503199

Epoch: 5| Step: 2
Training loss: 0.5326129198074341
Validation loss: 2.289364049832026

Epoch: 5| Step: 3
Training loss: 0.5051124691963196
Validation loss: 2.249159276485443

Epoch: 5| Step: 4
Training loss: 0.45910701155662537
Validation loss: 2.203139841556549

Epoch: 5| Step: 5
Training loss: 0.5410206913948059
Validation loss: 2.2180999716122947

Epoch: 5| Step: 6
Training loss: 0.42449188232421875
Validation loss: 2.221841797232628

Epoch: 5| Step: 7
Training loss: 0.566575825214386
Validation loss: 2.208097666501999

Epoch: 5| Step: 8
Training loss: 0.419058620929718
Validation loss: 2.272428015867869

Epoch: 5| Step: 9
Training loss: 0.767363429069519
Validation loss: 2.308590809504191

Epoch: 5| Step: 10
Training loss: 0.5561619997024536
Validation loss: 2.2725197275479636

Epoch: 5| Step: 11
Training loss: 1.4039477109909058
Validation loss: 2.2968786458174386

Epoch: 213| Step: 0
Training loss: 0.9805628061294556
Validation loss: 2.1969660371541977

Epoch: 5| Step: 1
Training loss: 0.36372071504592896
Validation loss: 2.2667042315006256

Epoch: 5| Step: 2
Training loss: 0.44393864274024963
Validation loss: 2.263263906041781

Epoch: 5| Step: 3
Training loss: 0.841569721698761
Validation loss: 2.2569325069586434

Epoch: 5| Step: 4
Training loss: 0.41299739480018616
Validation loss: 2.290276716152827

Epoch: 5| Step: 5
Training loss: 0.42405223846435547
Validation loss: 2.2980058739582696

Epoch: 5| Step: 6
Training loss: 0.5192769169807434
Validation loss: 2.2334460765123367

Epoch: 5| Step: 7
Training loss: 0.43746882677078247
Validation loss: 2.3381055841843286

Epoch: 5| Step: 8
Training loss: 0.8521803021430969
Validation loss: 2.277507329980532

Epoch: 5| Step: 9
Training loss: 0.6679254770278931
Validation loss: 2.2590445478757224

Epoch: 5| Step: 10
Training loss: 1.0432684421539307
Validation loss: 2.2875064810117087

Epoch: 5| Step: 11
Training loss: 0.7167943120002747
Validation loss: 2.2594408243894577

Epoch: 214| Step: 0
Training loss: 0.6821776032447815
Validation loss: 2.3391467283169427

Epoch: 5| Step: 1
Training loss: 0.49670878052711487
Validation loss: 2.236338978012403

Epoch: 5| Step: 2
Training loss: 0.9293359518051147
Validation loss: 2.2060433725516

Epoch: 5| Step: 3
Training loss: 0.5723191499710083
Validation loss: 2.2144253800312677

Epoch: 5| Step: 4
Training loss: 0.31962817907333374
Validation loss: 2.199144517381986

Epoch: 5| Step: 5
Training loss: 0.46230489015579224
Validation loss: 2.265418733159701

Epoch: 5| Step: 6
Training loss: 0.9832401275634766
Validation loss: 2.309961646795273

Epoch: 5| Step: 7
Training loss: 0.8867892026901245
Validation loss: 2.273613621791204

Epoch: 5| Step: 8
Training loss: 0.5713539123535156
Validation loss: 2.2892341017723083

Epoch: 5| Step: 9
Training loss: 0.6862389445304871
Validation loss: 2.2618892590204873

Epoch: 5| Step: 10
Training loss: 0.47961539030075073
Validation loss: 2.2463010350863137

Epoch: 5| Step: 11
Training loss: 0.8054310083389282
Validation loss: 2.2106208304564157

Epoch: 215| Step: 0
Training loss: 0.7205275893211365
Validation loss: 2.241919994354248

Epoch: 5| Step: 1
Training loss: 0.9452948570251465
Validation loss: 2.3295363088448844

Epoch: 5| Step: 2
Training loss: 0.5108257532119751
Validation loss: 2.290128449598948

Epoch: 5| Step: 3
Training loss: 0.38294726610183716
Validation loss: 2.2884512742360434

Epoch: 5| Step: 4
Training loss: 0.5258393287658691
Validation loss: 2.2217860519886017

Epoch: 5| Step: 5
Training loss: 0.46154481172561646
Validation loss: 2.163298487663269

Epoch: 5| Step: 6
Training loss: 0.8840587735176086
Validation loss: 2.2164018750190735

Epoch: 5| Step: 7
Training loss: 0.832379937171936
Validation loss: 2.1869027813275657

Epoch: 5| Step: 8
Training loss: 1.2095340490341187
Validation loss: 2.1839224845170975

Epoch: 5| Step: 9
Training loss: 0.5690933465957642
Validation loss: 2.2137536108493805

Epoch: 5| Step: 10
Training loss: 0.721739649772644
Validation loss: 2.281359617908796

Epoch: 5| Step: 11
Training loss: 0.27110588550567627
Validation loss: 2.2907182772954306

Epoch: 216| Step: 0
Training loss: 0.8011552691459656
Validation loss: 2.425103942553202

Epoch: 5| Step: 1
Training loss: 1.1449387073516846
Validation loss: 2.490210254987081

Epoch: 5| Step: 2
Training loss: 1.5591684579849243
Validation loss: 2.5608262717723846

Epoch: 5| Step: 3
Training loss: 0.9937940835952759
Validation loss: 2.4711797485748925

Epoch: 5| Step: 4
Training loss: 0.7064218521118164
Validation loss: 2.400844613711039

Epoch: 5| Step: 5
Training loss: 0.5865129828453064
Validation loss: 2.2392167250315347

Epoch: 5| Step: 6
Training loss: 0.5043192505836487
Validation loss: 2.2190904368956885

Epoch: 5| Step: 7
Training loss: 0.5660213232040405
Validation loss: 2.2599130670229592

Epoch: 5| Step: 8
Training loss: 1.4572985172271729
Validation loss: 2.1520997236172357

Epoch: 5| Step: 9
Training loss: 0.9611199498176575
Validation loss: 2.2060333589712777

Epoch: 5| Step: 10
Training loss: 1.235643744468689
Validation loss: 2.22922890384992

Epoch: 5| Step: 11
Training loss: 0.6647905707359314
Validation loss: 2.213415185610453

Epoch: 217| Step: 0
Training loss: 0.3609031140804291
Validation loss: 2.2810734510421753

Epoch: 5| Step: 1
Training loss: 0.7226907014846802
Validation loss: 2.347738822301229

Epoch: 5| Step: 2
Training loss: 0.6005536317825317
Validation loss: 2.359830617904663

Epoch: 5| Step: 3
Training loss: 1.4574579000473022
Validation loss: 2.3930684030056

Epoch: 5| Step: 4
Training loss: 0.7740648984909058
Validation loss: 2.4020109325647354

Epoch: 5| Step: 5
Training loss: 1.2268190383911133
Validation loss: 2.3807390133539834

Epoch: 5| Step: 6
Training loss: 0.4988919794559479
Validation loss: 2.306228737036387

Epoch: 5| Step: 7
Training loss: 0.5432499647140503
Validation loss: 2.2409414251645408

Epoch: 5| Step: 8
Training loss: 0.6563272476196289
Validation loss: 2.2227824131647744

Epoch: 5| Step: 9
Training loss: 0.9510065913200378
Validation loss: 2.2444882889588675

Epoch: 5| Step: 10
Training loss: 0.8571977615356445
Validation loss: 2.24030930797259

Epoch: 5| Step: 11
Training loss: 0.6376679539680481
Validation loss: 2.239957864085833

Epoch: 218| Step: 0
Training loss: 0.38013216853141785
Validation loss: 2.2180823336044946

Epoch: 5| Step: 1
Training loss: 0.5804393887519836
Validation loss: 2.308466523885727

Epoch: 5| Step: 2
Training loss: 0.9139382243156433
Validation loss: 2.368138834834099

Epoch: 5| Step: 3
Training loss: 0.9634674191474915
Validation loss: 2.3616186579068503

Epoch: 5| Step: 4
Training loss: 0.6431412696838379
Validation loss: 2.3721706867218018

Epoch: 5| Step: 5
Training loss: 0.6709433197975159
Validation loss: 2.3414619465668998

Epoch: 5| Step: 6
Training loss: 0.44245558977127075
Validation loss: 2.2808213333288827

Epoch: 5| Step: 7
Training loss: 0.4726167321205139
Validation loss: 2.216503153244654

Epoch: 5| Step: 8
Training loss: 0.6626132726669312
Validation loss: 2.243044674396515

Epoch: 5| Step: 9
Training loss: 0.9050191640853882
Validation loss: 2.201932340860367

Epoch: 5| Step: 10
Training loss: 0.6163660287857056
Validation loss: 2.226835086941719

Epoch: 5| Step: 11
Training loss: 1.577039361000061
Validation loss: 2.271932522455851

Epoch: 219| Step: 0
Training loss: 0.422954261302948
Validation loss: 2.210198014974594

Epoch: 5| Step: 1
Training loss: 0.6783010363578796
Validation loss: 2.274863044420878

Epoch: 5| Step: 2
Training loss: 0.5992170572280884
Validation loss: 2.332481265068054

Epoch: 5| Step: 3
Training loss: 0.9677473902702332
Validation loss: 2.2836920469999313

Epoch: 5| Step: 4
Training loss: 0.7402394413948059
Validation loss: 2.341650744279226

Epoch: 5| Step: 5
Training loss: 0.4777940809726715
Validation loss: 2.2835554579893746

Epoch: 5| Step: 6
Training loss: 0.5067914724349976
Validation loss: 2.3065359791119895

Epoch: 5| Step: 7
Training loss: 0.49614888429641724
Validation loss: 2.2351332356532416

Epoch: 5| Step: 8
Training loss: 1.0790753364562988
Validation loss: 2.236975078781446

Epoch: 5| Step: 9
Training loss: 0.7999328374862671
Validation loss: 2.2140129605929055

Epoch: 5| Step: 10
Training loss: 0.6217647790908813
Validation loss: 2.2786895483732224

Epoch: 5| Step: 11
Training loss: 0.6746105551719666
Validation loss: 2.204761415719986

Epoch: 220| Step: 0
Training loss: 0.46077069640159607
Validation loss: 2.3276623686154685

Epoch: 5| Step: 1
Training loss: 0.4916510581970215
Validation loss: 2.304011176029841

Epoch: 5| Step: 2
Training loss: 0.4019733965396881
Validation loss: 2.314932703971863

Epoch: 5| Step: 3
Training loss: 0.4138549864292145
Validation loss: 2.327518259485563

Epoch: 5| Step: 4
Training loss: 0.8368045091629028
Validation loss: 2.347647120555242

Epoch: 5| Step: 5
Training loss: 0.9372296333312988
Validation loss: 2.3069032728672028

Epoch: 5| Step: 6
Training loss: 0.439323753118515
Validation loss: 2.228653848171234

Epoch: 5| Step: 7
Training loss: 0.6079875230789185
Validation loss: 2.225743383169174

Epoch: 5| Step: 8
Training loss: 1.0064042806625366
Validation loss: 2.1979374388853707

Epoch: 5| Step: 9
Training loss: 0.7417271733283997
Validation loss: 2.2382332434256873

Epoch: 5| Step: 10
Training loss: 0.9684373736381531
Validation loss: 2.192251702149709

Epoch: 5| Step: 11
Training loss: 1.1167182922363281
Validation loss: 2.197764570514361

Epoch: 221| Step: 0
Training loss: 0.5800290107727051
Validation loss: 2.3495080371697745

Epoch: 5| Step: 1
Training loss: 1.1459006071090698
Validation loss: 2.2713080743948617

Epoch: 5| Step: 2
Training loss: 0.6417280435562134
Validation loss: 2.3404762049516044

Epoch: 5| Step: 3
Training loss: 0.6703560948371887
Validation loss: 2.3456380466620126

Epoch: 5| Step: 4
Training loss: 0.5498831868171692
Validation loss: 2.2956697891155877

Epoch: 5| Step: 5
Training loss: 1.1436104774475098
Validation loss: 2.274284909168879

Epoch: 5| Step: 6
Training loss: 0.6416305303573608
Validation loss: 2.3078513940175376

Epoch: 5| Step: 7
Training loss: 0.47758203744888306
Validation loss: 2.213399509588877

Epoch: 5| Step: 8
Training loss: 0.4934360086917877
Validation loss: 2.2789802650610604

Epoch: 5| Step: 9
Training loss: 0.42200803756713867
Validation loss: 2.274813085794449

Epoch: 5| Step: 10
Training loss: 0.4220584034919739
Validation loss: 2.3319115936756134

Epoch: 5| Step: 11
Training loss: 0.42655494809150696
Validation loss: 2.269400954246521

Epoch: 222| Step: 0
Training loss: 0.6455529928207397
Validation loss: 2.2659135361512504

Epoch: 5| Step: 1
Training loss: 0.8415663838386536
Validation loss: 2.2154933561881385

Epoch: 5| Step: 2
Training loss: 0.5191339254379272
Validation loss: 2.2111765245596566

Epoch: 5| Step: 3
Training loss: 0.5779799818992615
Validation loss: 2.2266638576984406

Epoch: 5| Step: 4
Training loss: 0.5094107389450073
Validation loss: 2.2518374919891357

Epoch: 5| Step: 5
Training loss: 0.42876896262168884
Validation loss: 2.2195725639661155

Epoch: 5| Step: 6
Training loss: 0.2798808515071869
Validation loss: 2.245988746484121

Epoch: 5| Step: 7
Training loss: 0.39322465658187866
Validation loss: 2.2757467230161033

Epoch: 5| Step: 8
Training loss: 0.7170027494430542
Validation loss: 2.277020215988159

Epoch: 5| Step: 9
Training loss: 0.8104171752929688
Validation loss: 2.2383258442083993

Epoch: 5| Step: 10
Training loss: 1.0310677289962769
Validation loss: 2.2633749693632126

Epoch: 5| Step: 11
Training loss: 0.7610103487968445
Validation loss: 2.229939421017965

Epoch: 223| Step: 0
Training loss: 0.6838290691375732
Validation loss: 2.2829839090506234

Epoch: 5| Step: 1
Training loss: 0.5279303193092346
Validation loss: 2.1559170335531235

Epoch: 5| Step: 2
Training loss: 1.0641635656356812
Validation loss: 2.2281405131022134

Epoch: 5| Step: 3
Training loss: 0.7644976377487183
Validation loss: 2.2739892999331155

Epoch: 5| Step: 4
Training loss: 0.5203405618667603
Validation loss: 2.271910011768341

Epoch: 5| Step: 5
Training loss: 1.016470193862915
Validation loss: 2.2807739476362863

Epoch: 5| Step: 6
Training loss: 0.3506507873535156
Validation loss: 2.3366124282280603

Epoch: 5| Step: 7
Training loss: 0.436739981174469
Validation loss: 2.308223217725754

Epoch: 5| Step: 8
Training loss: 0.5773357152938843
Validation loss: 2.376872410376867

Epoch: 5| Step: 9
Training loss: 0.7876278162002563
Validation loss: 2.3211504022280374

Epoch: 5| Step: 10
Training loss: 0.30948418378829956
Validation loss: 2.301454504330953

Epoch: 5| Step: 11
Training loss: 0.3188372850418091
Validation loss: 2.237955013910929

Epoch: 224| Step: 0
Training loss: 0.461092084646225
Validation loss: 2.251773715019226

Epoch: 5| Step: 1
Training loss: 0.9244614839553833
Validation loss: 2.2835511763890586

Epoch: 5| Step: 2
Training loss: 0.5230074524879456
Validation loss: 2.3355942567189536

Epoch: 5| Step: 3
Training loss: 0.4007568359375
Validation loss: 2.26160129904747

Epoch: 5| Step: 4
Training loss: 0.5249611735343933
Validation loss: 2.2697222232818604

Epoch: 5| Step: 5
Training loss: 0.9252119064331055
Validation loss: 2.2999543249607086

Epoch: 5| Step: 6
Training loss: 0.5343319177627563
Validation loss: 2.2824783821900687

Epoch: 5| Step: 7
Training loss: 0.4704524576663971
Validation loss: 2.26980784535408

Epoch: 5| Step: 8
Training loss: 0.5542875528335571
Validation loss: 2.2912145455678306

Epoch: 5| Step: 9
Training loss: 0.5636366605758667
Validation loss: 2.2622588525215783

Epoch: 5| Step: 10
Training loss: 0.6984175443649292
Validation loss: 2.2921463747819266

Epoch: 5| Step: 11
Training loss: 0.6903014779090881
Validation loss: 2.2496569206317267

Epoch: 225| Step: 0
Training loss: 0.6157808899879456
Validation loss: 2.2740581333637238

Epoch: 5| Step: 1
Training loss: 0.6119892001152039
Validation loss: 2.290308872858683

Epoch: 5| Step: 2
Training loss: 0.590251088142395
Validation loss: 2.276426131526629

Epoch: 5| Step: 3
Training loss: 0.5127528309822083
Validation loss: 2.294641966621081

Epoch: 5| Step: 4
Training loss: 0.5740705728530884
Validation loss: 2.258153090874354

Epoch: 5| Step: 5
Training loss: 0.34343498945236206
Validation loss: 2.340468446413676

Epoch: 5| Step: 6
Training loss: 0.9203998446464539
Validation loss: 2.307879701256752

Epoch: 5| Step: 7
Training loss: 0.28954988718032837
Validation loss: 2.2631685733795166

Epoch: 5| Step: 8
Training loss: 0.655718207359314
Validation loss: 2.263941243290901

Epoch: 5| Step: 9
Training loss: 0.712382972240448
Validation loss: 2.2978039483229318

Epoch: 5| Step: 10
Training loss: 0.5058995485305786
Validation loss: 2.2575996269782386

Epoch: 5| Step: 11
Training loss: 0.47198212146759033
Validation loss: 2.2309444745381675

Epoch: 226| Step: 0
Training loss: 0.52933269739151
Validation loss: 2.2774883111317954

Epoch: 5| Step: 1
Training loss: 0.4590916037559509
Validation loss: 2.2997480233510337

Epoch: 5| Step: 2
Training loss: 0.9543708562850952
Validation loss: 2.357169429461161

Epoch: 5| Step: 3
Training loss: 0.6566952466964722
Validation loss: 2.3375812272230783

Epoch: 5| Step: 4
Training loss: 0.43001213669776917
Validation loss: 2.3431744376818338

Epoch: 5| Step: 5
Training loss: 0.5390833616256714
Validation loss: 2.280210236708323

Epoch: 5| Step: 6
Training loss: 1.1742002964019775
Validation loss: 2.2799702286720276

Epoch: 5| Step: 7
Training loss: 0.6564799547195435
Validation loss: 2.215333973368009

Epoch: 5| Step: 8
Training loss: 0.5770586729049683
Validation loss: 2.236997385819753

Epoch: 5| Step: 9
Training loss: 0.5640507936477661
Validation loss: 2.276028662919998

Epoch: 5| Step: 10
Training loss: 0.7023094892501831
Validation loss: 2.298488656679789

Epoch: 5| Step: 11
Training loss: 1.1707890033721924
Validation loss: 2.334688365459442

Epoch: 227| Step: 0
Training loss: 0.5486515760421753
Validation loss: 2.2984163562456765

Epoch: 5| Step: 1
Training loss: 0.7228390574455261
Validation loss: 2.3562813848257065

Epoch: 5| Step: 2
Training loss: 0.7500158548355103
Validation loss: 2.260724052786827

Epoch: 5| Step: 3
Training loss: 0.5364125370979309
Validation loss: 2.2371837000052133

Epoch: 5| Step: 4
Training loss: 0.5704128742218018
Validation loss: 2.1982856889565787

Epoch: 5| Step: 5
Training loss: 0.5148380994796753
Validation loss: 2.19614947338899

Epoch: 5| Step: 6
Training loss: 0.5587645769119263
Validation loss: 2.179733380675316

Epoch: 5| Step: 7
Training loss: 0.63337641954422
Validation loss: 2.2333865761756897

Epoch: 5| Step: 8
Training loss: 0.7999452948570251
Validation loss: 2.2616064697504044

Epoch: 5| Step: 9
Training loss: 0.7878297567367554
Validation loss: 2.29437118768692

Epoch: 5| Step: 10
Training loss: 0.5164657831192017
Validation loss: 2.3014700512091317

Epoch: 5| Step: 11
Training loss: 1.3201971054077148
Validation loss: 2.291511987646421

Epoch: 228| Step: 0
Training loss: 0.4937070906162262
Validation loss: 2.262472371260325

Epoch: 5| Step: 1
Training loss: 1.2888809442520142
Validation loss: 2.259625658392906

Epoch: 5| Step: 2
Training loss: 0.39452964067459106
Validation loss: 2.262364168961843

Epoch: 5| Step: 3
Training loss: 0.5059510469436646
Validation loss: 2.2187387545903525

Epoch: 5| Step: 4
Training loss: 0.609167218208313
Validation loss: 2.276242713133494

Epoch: 5| Step: 5
Training loss: 0.43020638823509216
Validation loss: 2.2639826089143753

Epoch: 5| Step: 6
Training loss: 0.5391391515731812
Validation loss: 2.231351683537165

Epoch: 5| Step: 7
Training loss: 0.6693984270095825
Validation loss: 2.2668805023034415

Epoch: 5| Step: 8
Training loss: 0.4504227638244629
Validation loss: 2.373857701818148

Epoch: 5| Step: 9
Training loss: 0.7155710458755493
Validation loss: 2.333648224671682

Epoch: 5| Step: 10
Training loss: 0.3685399889945984
Validation loss: 2.3306292990843454

Epoch: 5| Step: 11
Training loss: 1.0375735759735107
Validation loss: 2.340160528818766

Epoch: 229| Step: 0
Training loss: 0.5719196200370789
Validation loss: 2.2939281165599823

Epoch: 5| Step: 1
Training loss: 0.8283944129943848
Validation loss: 2.2836614648501077

Epoch: 5| Step: 2
Training loss: 0.4239254891872406
Validation loss: 2.2383658289909363

Epoch: 5| Step: 3
Training loss: 0.697614312171936
Validation loss: 2.2730438311894736

Epoch: 5| Step: 4
Training loss: 0.3752496838569641
Validation loss: 2.3329471051692963

Epoch: 5| Step: 5
Training loss: 0.7103495597839355
Validation loss: 2.295621628562609

Epoch: 5| Step: 6
Training loss: 0.9750066995620728
Validation loss: 2.344045768181483

Epoch: 5| Step: 7
Training loss: 0.6499546766281128
Validation loss: 2.355965316295624

Epoch: 5| Step: 8
Training loss: 0.8352430462837219
Validation loss: 2.3211769759655

Epoch: 5| Step: 9
Training loss: 0.4069580137729645
Validation loss: 2.319552610317866

Epoch: 5| Step: 10
Training loss: 0.514346718788147
Validation loss: 2.2446521669626236

Epoch: 5| Step: 11
Training loss: 0.5880224704742432
Validation loss: 2.256419991453489

Epoch: 230| Step: 0
Training loss: 0.46574145555496216
Validation loss: 2.2084058622519174

Epoch: 5| Step: 1
Training loss: 0.6295552253723145
Validation loss: 2.253252853949865

Epoch: 5| Step: 2
Training loss: 0.44570302963256836
Validation loss: 2.3038832495609918

Epoch: 5| Step: 3
Training loss: 0.5413902401924133
Validation loss: 2.30116398135821

Epoch: 5| Step: 4
Training loss: 0.6454352736473083
Validation loss: 2.322499096393585

Epoch: 5| Step: 5
Training loss: 0.67142254114151
Validation loss: 2.308693508307139

Epoch: 5| Step: 6
Training loss: 0.5492977499961853
Validation loss: 2.3351522584756217

Epoch: 5| Step: 7
Training loss: 0.39251708984375
Validation loss: 2.316903313000997

Epoch: 5| Step: 8
Training loss: 0.5893235802650452
Validation loss: 2.3339944928884506

Epoch: 5| Step: 9
Training loss: 1.1417940855026245
Validation loss: 2.2375166018803916

Epoch: 5| Step: 10
Training loss: 0.5116696357727051
Validation loss: 2.298346961537997

Epoch: 5| Step: 11
Training loss: 0.2954126000404358
Validation loss: 2.258441001176834

Epoch: 231| Step: 0
Training loss: 0.9393281936645508
Validation loss: 2.225360780954361

Epoch: 5| Step: 1
Training loss: 0.664895236492157
Validation loss: 2.299785226583481

Epoch: 5| Step: 2
Training loss: 0.6407378911972046
Validation loss: 2.297245298822721

Epoch: 5| Step: 3
Training loss: 0.9844373464584351
Validation loss: 2.2433197100957236

Epoch: 5| Step: 4
Training loss: 0.5067855715751648
Validation loss: 2.350059727827708

Epoch: 5| Step: 5
Training loss: 0.47904863953590393
Validation loss: 2.315655842423439

Epoch: 5| Step: 6
Training loss: 0.5596266388893127
Validation loss: 2.297849625349045

Epoch: 5| Step: 7
Training loss: 0.3057423532009125
Validation loss: 2.2946877678235373

Epoch: 5| Step: 8
Training loss: 0.29966112971305847
Validation loss: 2.2371382961670556

Epoch: 5| Step: 9
Training loss: 0.41610080003738403
Validation loss: 2.292902891834577

Epoch: 5| Step: 10
Training loss: 0.39810711145401
Validation loss: 2.208495313922564

Epoch: 5| Step: 11
Training loss: 0.11582550406455994
Validation loss: 2.294071247180303

Epoch: 232| Step: 0
Training loss: 0.2588232457637787
Validation loss: 2.246274769306183

Epoch: 5| Step: 1
Training loss: 0.513803243637085
Validation loss: 2.2320038825273514

Epoch: 5| Step: 2
Training loss: 0.44105881452560425
Validation loss: 2.2731582472721734

Epoch: 5| Step: 3
Training loss: 0.5965335965156555
Validation loss: 2.2804375489552817

Epoch: 5| Step: 4
Training loss: 0.6685910224914551
Validation loss: 2.1895854075749717

Epoch: 5| Step: 5
Training loss: 0.4495578408241272
Validation loss: 2.237584744890531

Epoch: 5| Step: 6
Training loss: 0.6642394065856934
Validation loss: 2.2298545241355896

Epoch: 5| Step: 7
Training loss: 0.6089296340942383
Validation loss: 2.241773267587026

Epoch: 5| Step: 8
Training loss: 0.631841242313385
Validation loss: 2.219548890988032

Epoch: 5| Step: 9
Training loss: 0.3781302869319916
Validation loss: 2.2611128638188043

Epoch: 5| Step: 10
Training loss: 1.1614692211151123
Validation loss: 2.262875904639562

Epoch: 5| Step: 11
Training loss: 0.3783949613571167
Validation loss: 2.3192133406798043

Epoch: 233| Step: 0
Training loss: 0.8265472650527954
Validation loss: 2.2442167500654855

Epoch: 5| Step: 1
Training loss: 0.5468735694885254
Validation loss: 2.307525326808294

Epoch: 5| Step: 2
Training loss: 0.3595796227455139
Validation loss: 2.31413596868515

Epoch: 5| Step: 3
Training loss: 0.4980162978172302
Validation loss: 2.2021387616793313

Epoch: 5| Step: 4
Training loss: 0.5506445169448853
Validation loss: 2.233116696278254

Epoch: 5| Step: 5
Training loss: 0.46378293633461
Validation loss: 2.2904597371816635

Epoch: 5| Step: 6
Training loss: 0.7625160813331604
Validation loss: 2.3114210764567056

Epoch: 5| Step: 7
Training loss: 0.6453384160995483
Validation loss: 2.269614259401957

Epoch: 5| Step: 8
Training loss: 0.47001418471336365
Validation loss: 2.228374660015106

Epoch: 5| Step: 9
Training loss: 0.4953957200050354
Validation loss: 2.3189585308233895

Epoch: 5| Step: 10
Training loss: 0.3218271732330322
Validation loss: 2.1972872813542685

Epoch: 5| Step: 11
Training loss: 0.34625697135925293
Validation loss: 2.1936972041924796

Epoch: 234| Step: 0
Training loss: 0.43335962295532227
Validation loss: 2.2951381454865136

Epoch: 5| Step: 1
Training loss: 0.7288446426391602
Validation loss: 2.2487286428610482

Epoch: 5| Step: 2
Training loss: 0.5317172408103943
Validation loss: 2.2252958516279855

Epoch: 5| Step: 3
Training loss: 0.39055222272872925
Validation loss: 2.243980978926023

Epoch: 5| Step: 4
Training loss: 0.44830626249313354
Validation loss: 2.275290717681249

Epoch: 5| Step: 5
Training loss: 0.5357893705368042
Validation loss: 2.241830348968506

Epoch: 5| Step: 6
Training loss: 0.7408870458602905
Validation loss: 2.255178521076838

Epoch: 5| Step: 7
Training loss: 0.518633246421814
Validation loss: 2.297634462515513

Epoch: 5| Step: 8
Training loss: 0.7103812098503113
Validation loss: 2.2406476736068726

Epoch: 5| Step: 9
Training loss: 0.497545063495636
Validation loss: 2.2394713759422302

Epoch: 5| Step: 10
Training loss: 0.49490609765052795
Validation loss: 2.2657734205325446

Epoch: 5| Step: 11
Training loss: 0.8707304000854492
Validation loss: 2.263725757598877

Epoch: 235| Step: 0
Training loss: 0.6204083561897278
Validation loss: 2.2979283978541694

Epoch: 5| Step: 1
Training loss: 0.4260096549987793
Validation loss: 2.3199381977319717

Epoch: 5| Step: 2
Training loss: 0.9741663932800293
Validation loss: 2.238349050283432

Epoch: 5| Step: 3
Training loss: 0.7296983003616333
Validation loss: 2.254606068134308

Epoch: 5| Step: 4
Training loss: 0.30248865485191345
Validation loss: 2.241340051094691

Epoch: 5| Step: 5
Training loss: 0.34152060747146606
Validation loss: 2.222655937075615

Epoch: 5| Step: 6
Training loss: 0.5857101678848267
Validation loss: 2.2673750122388205

Epoch: 5| Step: 7
Training loss: 0.5370599031448364
Validation loss: 2.3039753337701163

Epoch: 5| Step: 8
Training loss: 0.5765715837478638
Validation loss: 2.2878325134515762

Epoch: 5| Step: 9
Training loss: 0.7641345262527466
Validation loss: 2.2227722307046256

Epoch: 5| Step: 10
Training loss: 0.6054560542106628
Validation loss: 2.231607442100843

Epoch: 5| Step: 11
Training loss: 0.3358624577522278
Validation loss: 2.225977599620819

Epoch: 236| Step: 0
Training loss: 0.4485398232936859
Validation loss: 2.2495093743006387

Epoch: 5| Step: 1
Training loss: 0.3310740888118744
Validation loss: 2.3033201595147452

Epoch: 5| Step: 2
Training loss: 0.5540575385093689
Validation loss: 2.3414187928040824

Epoch: 5| Step: 3
Training loss: 0.8398518562316895
Validation loss: 2.280004988114039

Epoch: 5| Step: 4
Training loss: 0.4929218292236328
Validation loss: 2.2829436461130777

Epoch: 5| Step: 5
Training loss: 0.46368342638015747
Validation loss: 2.2634471307198205

Epoch: 5| Step: 6
Training loss: 0.7069342732429504
Validation loss: 2.271050880352656

Epoch: 5| Step: 7
Training loss: 0.853816032409668
Validation loss: 2.225868821144104

Epoch: 5| Step: 8
Training loss: 0.5232991576194763
Validation loss: 2.19757508734862

Epoch: 5| Step: 9
Training loss: 0.6349276304244995
Validation loss: 2.2389665693044662

Epoch: 5| Step: 10
Training loss: 0.4028603434562683
Validation loss: 2.2050971339146295

Epoch: 5| Step: 11
Training loss: 0.11810347437858582
Validation loss: 2.2723463823397956

Epoch: 237| Step: 0
Training loss: 0.4457674026489258
Validation loss: 2.174183244506518

Epoch: 5| Step: 1
Training loss: 0.7178192734718323
Validation loss: 2.2253546019395194

Epoch: 5| Step: 2
Training loss: 0.5868818759918213
Validation loss: 2.167352626721064

Epoch: 5| Step: 3
Training loss: 0.6466019153594971
Validation loss: 2.2436816692352295

Epoch: 5| Step: 4
Training loss: 0.638611912727356
Validation loss: 2.2150547057390213

Epoch: 5| Step: 5
Training loss: 0.38845521211624146
Validation loss: 2.2470571299393973

Epoch: 5| Step: 6
Training loss: 0.5158270597457886
Validation loss: 2.241504599650701

Epoch: 5| Step: 7
Training loss: 0.3220868706703186
Validation loss: 2.2677586873372397

Epoch: 5| Step: 8
Training loss: 0.58283531665802
Validation loss: 2.231958578030268

Epoch: 5| Step: 9
Training loss: 0.6186898946762085
Validation loss: 2.2966419458389282

Epoch: 5| Step: 10
Training loss: 0.8000942468643188
Validation loss: 2.290322552124659

Epoch: 5| Step: 11
Training loss: 0.14711786806583405
Validation loss: 2.283250778913498

Epoch: 238| Step: 0
Training loss: 0.4327392578125
Validation loss: 2.3064654767513275

Epoch: 5| Step: 1
Training loss: 0.6455535888671875
Validation loss: 2.3381536503632865

Epoch: 5| Step: 2
Training loss: 0.4092372953891754
Validation loss: 2.306377420822779

Epoch: 5| Step: 3
Training loss: 0.6722269058227539
Validation loss: 2.335040604074796

Epoch: 5| Step: 4
Training loss: 0.4748605787754059
Validation loss: 2.2926157216231027

Epoch: 5| Step: 5
Training loss: 0.8742691874504089
Validation loss: 2.290772279103597

Epoch: 5| Step: 6
Training loss: 0.6288672089576721
Validation loss: 2.260100245475769

Epoch: 5| Step: 7
Training loss: 0.5683584809303284
Validation loss: 2.292920226852099

Epoch: 5| Step: 8
Training loss: 0.7403455972671509
Validation loss: 2.314249744017919

Epoch: 5| Step: 9
Training loss: 0.3261115849018097
Validation loss: 2.2294436196486154

Epoch: 5| Step: 10
Training loss: 0.33593863248825073
Validation loss: 2.286857088406881

Epoch: 5| Step: 11
Training loss: 1.4012477397918701
Validation loss: 2.2649573485056558

Epoch: 239| Step: 0
Training loss: 0.4165875017642975
Validation loss: 2.236118699113528

Epoch: 5| Step: 1
Training loss: 0.3277348577976227
Validation loss: 2.307632346947988

Epoch: 5| Step: 2
Training loss: 0.37406080961227417
Validation loss: 2.2485292057196298

Epoch: 5| Step: 3
Training loss: 0.5811878442764282
Validation loss: 2.2488117118676505

Epoch: 5| Step: 4
Training loss: 1.1065975427627563
Validation loss: 2.243841310342153

Epoch: 5| Step: 5
Training loss: 0.4745570123195648
Validation loss: 2.2775745193163552

Epoch: 5| Step: 6
Training loss: 0.4733457565307617
Validation loss: 2.235001027584076

Epoch: 5| Step: 7
Training loss: 0.48952120542526245
Validation loss: 2.2843355536460876

Epoch: 5| Step: 8
Training loss: 0.5579419136047363
Validation loss: 2.2459866801897683

Epoch: 5| Step: 9
Training loss: 0.42243486642837524
Validation loss: 2.2801248927911124

Epoch: 5| Step: 10
Training loss: 0.8409444093704224
Validation loss: 2.243631283442179

Epoch: 5| Step: 11
Training loss: 0.2660553455352783
Validation loss: 2.324944923321406

Epoch: 240| Step: 0
Training loss: 0.5446285009384155
Validation loss: 2.292458802461624

Epoch: 5| Step: 1
Training loss: 0.4988184869289398
Validation loss: 2.3083744943141937

Epoch: 5| Step: 2
Training loss: 0.5386645793914795
Validation loss: 2.3217136015494666

Epoch: 5| Step: 3
Training loss: 0.4520401954650879
Validation loss: 2.3100425700346627

Epoch: 5| Step: 4
Training loss: 0.326584130525589
Validation loss: 2.2885112116734185

Epoch: 5| Step: 5
Training loss: 1.0501199960708618
Validation loss: 2.3194104631741843

Epoch: 5| Step: 6
Training loss: 0.4630138874053955
Validation loss: 2.2924604763587317

Epoch: 5| Step: 7
Training loss: 0.4273029863834381
Validation loss: 2.330994119246801

Epoch: 5| Step: 8
Training loss: 0.5698673129081726
Validation loss: 2.304637978474299

Epoch: 5| Step: 9
Training loss: 0.4648033678531647
Validation loss: 2.26749786734581

Epoch: 5| Step: 10
Training loss: 0.34079471230506897
Validation loss: 2.26049151023229

Epoch: 5| Step: 11
Training loss: 1.2728149890899658
Validation loss: 2.3137506196896234

Epoch: 241| Step: 0
Training loss: 0.399862676858902
Validation loss: 2.252767935395241

Epoch: 5| Step: 1
Training loss: 0.9067496061325073
Validation loss: 2.173891693353653

Epoch: 5| Step: 2
Training loss: 0.4965237081050873
Validation loss: 2.240398327509562

Epoch: 5| Step: 3
Training loss: 0.5213918685913086
Validation loss: 2.257072558005651

Epoch: 5| Step: 4
Training loss: 0.6978325843811035
Validation loss: 2.2572917441527047

Epoch: 5| Step: 5
Training loss: 0.7251834869384766
Validation loss: 2.3589667280515036

Epoch: 5| Step: 6
Training loss: 0.7602220773696899
Validation loss: 2.374043087164561

Epoch: 5| Step: 7
Training loss: 0.6247867941856384
Validation loss: 2.3357782065868378

Epoch: 5| Step: 8
Training loss: 1.1401746273040771
Validation loss: 2.3191147098938623

Epoch: 5| Step: 9
Training loss: 0.454679399728775
Validation loss: 2.312113439043363

Epoch: 5| Step: 10
Training loss: 0.412283718585968
Validation loss: 2.279791379968325

Epoch: 5| Step: 11
Training loss: 1.3924144506454468
Validation loss: 2.265820393959681

Epoch: 242| Step: 0
Training loss: 0.30591392517089844
Validation loss: 2.2460144658883414

Epoch: 5| Step: 1
Training loss: 0.3695327639579773
Validation loss: 2.240613346298536

Epoch: 5| Step: 2
Training loss: 0.6139523983001709
Validation loss: 2.2461204826831818

Epoch: 5| Step: 3
Training loss: 0.40817251801490784
Validation loss: 2.291600118080775

Epoch: 5| Step: 4
Training loss: 1.1731549501419067
Validation loss: 2.226458857456843

Epoch: 5| Step: 5
Training loss: 0.46808329224586487
Validation loss: 2.2810507814089456

Epoch: 5| Step: 6
Training loss: 0.5277544260025024
Validation loss: 2.2270758748054504

Epoch: 5| Step: 7
Training loss: 0.4743724763393402
Validation loss: 2.188909803827604

Epoch: 5| Step: 8
Training loss: 0.6255422830581665
Validation loss: 2.2595736384391785

Epoch: 5| Step: 9
Training loss: 0.5685420036315918
Validation loss: 2.2312337855497995

Epoch: 5| Step: 10
Training loss: 0.4326959550380707
Validation loss: 2.2579645415147147

Epoch: 5| Step: 11
Training loss: 0.5399948358535767
Validation loss: 2.2636746962865195

Epoch: 243| Step: 0
Training loss: 0.3344460725784302
Validation loss: 2.2369787295659385

Epoch: 5| Step: 1
Training loss: 0.885766863822937
Validation loss: 2.2274502217769623

Epoch: 5| Step: 2
Training loss: 0.48046478629112244
Validation loss: 2.2112853725751243

Epoch: 5| Step: 3
Training loss: 0.3753274083137512
Validation loss: 2.2726629227399826

Epoch: 5| Step: 4
Training loss: 0.4547427296638489
Validation loss: 2.2473526298999786

Epoch: 5| Step: 5
Training loss: 0.5841682553291321
Validation loss: 2.2466101348400116

Epoch: 5| Step: 6
Training loss: 0.525753915309906
Validation loss: 2.2400852938493094

Epoch: 5| Step: 7
Training loss: 0.46924179792404175
Validation loss: 2.283504510919253

Epoch: 5| Step: 8
Training loss: 0.4504917562007904
Validation loss: 2.2532413552204766

Epoch: 5| Step: 9
Training loss: 0.4740815758705139
Validation loss: 2.1803395996491113

Epoch: 5| Step: 10
Training loss: 0.5435841679573059
Validation loss: 2.2444465458393097

Epoch: 5| Step: 11
Training loss: 0.4262748956680298
Validation loss: 2.234383742014567

Epoch: 244| Step: 0
Training loss: 0.6517226099967957
Validation loss: 2.226593777537346

Epoch: 5| Step: 1
Training loss: 0.5967315435409546
Validation loss: 2.2021975616614022

Epoch: 5| Step: 2
Training loss: 0.3543638586997986
Validation loss: 2.278132607539495

Epoch: 5| Step: 3
Training loss: 0.32818353176116943
Validation loss: 2.364290604988734

Epoch: 5| Step: 4
Training loss: 0.30056101083755493
Validation loss: 2.3702668050924935

Epoch: 5| Step: 5
Training loss: 0.4650346338748932
Validation loss: 2.2149398177862167

Epoch: 5| Step: 6
Training loss: 0.7720824480056763
Validation loss: 2.2261639883120856

Epoch: 5| Step: 7
Training loss: 0.589465320110321
Validation loss: 2.2782398760318756

Epoch: 5| Step: 8
Training loss: 0.5118568539619446
Validation loss: 2.2327267676591873

Epoch: 5| Step: 9
Training loss: 0.8771321177482605
Validation loss: 2.258740171790123

Epoch: 5| Step: 10
Training loss: 0.41119688749313354
Validation loss: 2.2652796506881714

Epoch: 5| Step: 11
Training loss: 0.9969819784164429
Validation loss: 2.2375787496566772

Epoch: 245| Step: 0
Training loss: 0.7070779204368591
Validation loss: 2.253700544436773

Epoch: 5| Step: 1
Training loss: 0.28305572271347046
Validation loss: 2.2817030201355615

Epoch: 5| Step: 2
Training loss: 0.4013463854789734
Validation loss: 2.289996018012365

Epoch: 5| Step: 3
Training loss: 0.7313065528869629
Validation loss: 2.300263245900472

Epoch: 5| Step: 4
Training loss: 0.5578157305717468
Validation loss: 2.281353419025739

Epoch: 5| Step: 5
Training loss: 0.45239466428756714
Validation loss: 2.2314553558826447

Epoch: 5| Step: 6
Training loss: 0.37753477692604065
Validation loss: 2.28537987669309

Epoch: 5| Step: 7
Training loss: 0.4254564642906189
Validation loss: 2.1980290710926056

Epoch: 5| Step: 8
Training loss: 0.48733872175216675
Validation loss: 2.1639974613984427

Epoch: 5| Step: 9
Training loss: 0.8558098673820496
Validation loss: 2.2618070542812347

Epoch: 5| Step: 10
Training loss: 0.43056172132492065
Validation loss: 2.278956408301989

Epoch: 5| Step: 11
Training loss: 0.8765966296195984
Validation loss: 2.2781905929247537

Epoch: 246| Step: 0
Training loss: 0.37258172035217285
Validation loss: 2.2700237333774567

Epoch: 5| Step: 1
Training loss: 0.5330671072006226
Validation loss: 2.310446411371231

Epoch: 5| Step: 2
Training loss: 0.48217159509658813
Validation loss: 2.3041463494300842

Epoch: 5| Step: 3
Training loss: 0.2990082800388336
Validation loss: 2.2925532708565393

Epoch: 5| Step: 4
Training loss: 0.5370542407035828
Validation loss: 2.2367820938428244

Epoch: 5| Step: 5
Training loss: 0.5565682053565979
Validation loss: 2.1860389908154807

Epoch: 5| Step: 6
Training loss: 0.5841307044029236
Validation loss: 2.2041664520899453

Epoch: 5| Step: 7
Training loss: 0.8295102119445801
Validation loss: 2.156977425018946

Epoch: 5| Step: 8
Training loss: 0.4360201954841614
Validation loss: 2.129720389842987

Epoch: 5| Step: 9
Training loss: 0.6759936213493347
Validation loss: 2.2159470518430076

Epoch: 5| Step: 10
Training loss: 0.9715667963027954
Validation loss: 2.2800509333610535

Epoch: 5| Step: 11
Training loss: 0.442568302154541
Validation loss: 2.265892873207728

Epoch: 247| Step: 0
Training loss: 0.6020157933235168
Validation loss: 2.27094175418218

Epoch: 5| Step: 1
Training loss: 0.4138372540473938
Validation loss: 2.262294272581736

Epoch: 5| Step: 2
Training loss: 0.4695506691932678
Validation loss: 2.248758773008982

Epoch: 5| Step: 3
Training loss: 0.7466622591018677
Validation loss: 2.2265505492687225

Epoch: 5| Step: 4
Training loss: 0.5504364967346191
Validation loss: 2.1789027055104575

Epoch: 5| Step: 5
Training loss: 0.5781998634338379
Validation loss: 2.2322495778401694

Epoch: 5| Step: 6
Training loss: 0.6501835584640503
Validation loss: 2.189105063676834

Epoch: 5| Step: 7
Training loss: 0.5658565759658813
Validation loss: 2.193353921175003

Epoch: 5| Step: 8
Training loss: 0.39022356271743774
Validation loss: 2.2295554876327515

Epoch: 5| Step: 9
Training loss: 0.6826281547546387
Validation loss: 2.3169872164726257

Epoch: 5| Step: 10
Training loss: 0.4784625172615051
Validation loss: 2.2482373267412186

Epoch: 5| Step: 11
Training loss: 0.44556641578674316
Validation loss: 2.1989159137010574

Epoch: 248| Step: 0
Training loss: 0.3471275866031647
Validation loss: 2.2528570542732873

Epoch: 5| Step: 1
Training loss: 0.5084382891654968
Validation loss: 2.187152778108915

Epoch: 5| Step: 2
Training loss: 0.5267294049263
Validation loss: 2.2538422296444574

Epoch: 5| Step: 3
Training loss: 0.5457558035850525
Validation loss: 2.234768678744634

Epoch: 5| Step: 4
Training loss: 1.1038119792938232
Validation loss: 2.1803202778100967

Epoch: 5| Step: 5
Training loss: 0.4422380328178406
Validation loss: 2.193899840116501

Epoch: 5| Step: 6
Training loss: 0.5612356066703796
Validation loss: 2.198214521010717

Epoch: 5| Step: 7
Training loss: 0.4183596670627594
Validation loss: 2.2200428446133933

Epoch: 5| Step: 8
Training loss: 0.7845512628555298
Validation loss: 2.272035777568817

Epoch: 5| Step: 9
Training loss: 0.42694950103759766
Validation loss: 2.3326015770435333

Epoch: 5| Step: 10
Training loss: 0.7463257908821106
Validation loss: 2.336843897898992

Epoch: 5| Step: 11
Training loss: 0.5067813396453857
Validation loss: 2.31820214788119

Epoch: 249| Step: 0
Training loss: 0.5244194269180298
Validation loss: 2.241083855430285

Epoch: 5| Step: 1
Training loss: 0.44488564133644104
Validation loss: 2.2881520142157874

Epoch: 5| Step: 2
Training loss: 0.5140184760093689
Validation loss: 2.2407556076844535

Epoch: 5| Step: 3
Training loss: 1.1532063484191895
Validation loss: 2.244369308153788

Epoch: 5| Step: 4
Training loss: 0.47557973861694336
Validation loss: 2.2210057377815247

Epoch: 5| Step: 5
Training loss: 0.5052393078804016
Validation loss: 2.190418099363645

Epoch: 5| Step: 6
Training loss: 0.6119775772094727
Validation loss: 2.2762675434350967

Epoch: 5| Step: 7
Training loss: 0.4336634576320648
Validation loss: 2.312425230940183

Epoch: 5| Step: 8
Training loss: 0.8263328671455383
Validation loss: 2.348238855600357

Epoch: 5| Step: 9
Training loss: 0.5010015368461609
Validation loss: 2.3230841706196466

Epoch: 5| Step: 10
Training loss: 0.8091548085212708
Validation loss: 2.32894895474116

Epoch: 5| Step: 11
Training loss: 0.4012868404388428
Validation loss: 2.2576427310705185

Epoch: 250| Step: 0
Training loss: 0.5291295051574707
Validation loss: 2.2749861677487693

Epoch: 5| Step: 1
Training loss: 0.35616374015808105
Validation loss: 2.237854480743408

Epoch: 5| Step: 2
Training loss: 0.48977622389793396
Validation loss: 2.211512967944145

Epoch: 5| Step: 3
Training loss: 0.3908554017543793
Validation loss: 2.2555300196011863

Epoch: 5| Step: 4
Training loss: 0.9440287351608276
Validation loss: 2.250347206989924

Epoch: 5| Step: 5
Training loss: 0.5557281970977783
Validation loss: 2.2769983808199563

Epoch: 5| Step: 6
Training loss: 0.5823771357536316
Validation loss: 2.2779413610696793

Epoch: 5| Step: 7
Training loss: 0.5409188270568848
Validation loss: 2.373561754822731

Epoch: 5| Step: 8
Training loss: 0.7650402784347534
Validation loss: 2.3160133262475333

Epoch: 5| Step: 9
Training loss: 0.33550360798835754
Validation loss: 2.302243987719218

Epoch: 5| Step: 10
Training loss: 0.46324968338012695
Validation loss: 2.303084601958593

Epoch: 5| Step: 11
Training loss: 0.4647793769836426
Validation loss: 2.219395066301028

Epoch: 251| Step: 0
Training loss: 0.48467594385147095
Validation loss: 2.2273842791716256

Epoch: 5| Step: 1
Training loss: 0.5382229089736938
Validation loss: 2.1920905063549676

Epoch: 5| Step: 2
Training loss: 0.32148629426956177
Validation loss: 2.205374519030253

Epoch: 5| Step: 3
Training loss: 0.6611076593399048
Validation loss: 2.247520719965299

Epoch: 5| Step: 4
Training loss: 0.3176972270011902
Validation loss: 2.2436063637336097

Epoch: 5| Step: 5
Training loss: 0.337649405002594
Validation loss: 2.3190464079380035

Epoch: 5| Step: 6
Training loss: 0.5233405828475952
Validation loss: 2.3135044276714325

Epoch: 5| Step: 7
Training loss: 0.6510920524597168
Validation loss: 2.260364751021067

Epoch: 5| Step: 8
Training loss: 0.6895000338554382
Validation loss: 2.3020890255769095

Epoch: 5| Step: 9
Training loss: 0.4722224771976471
Validation loss: 2.2429592609405518

Epoch: 5| Step: 10
Training loss: 0.6477250456809998
Validation loss: 2.214575390021006

Epoch: 5| Step: 11
Training loss: 0.8457997441291809
Validation loss: 2.259374479452769

Epoch: 252| Step: 0
Training loss: 0.7125512957572937
Validation loss: 2.2503752211729684

Epoch: 5| Step: 1
Training loss: 0.21558837592601776
Validation loss: 2.2490763564904532

Epoch: 5| Step: 2
Training loss: 0.5452890396118164
Validation loss: 2.275207648674647

Epoch: 5| Step: 3
Training loss: 0.439441055059433
Validation loss: 2.274185359477997

Epoch: 5| Step: 4
Training loss: 0.4365641474723816
Validation loss: 2.2536494930585227

Epoch: 5| Step: 5
Training loss: 0.333012193441391
Validation loss: 2.314864605665207

Epoch: 5| Step: 6
Training loss: 0.5484902858734131
Validation loss: 2.2414911637703576

Epoch: 5| Step: 7
Training loss: 0.7822768092155457
Validation loss: 2.253049294153849

Epoch: 5| Step: 8
Training loss: 0.6051170229911804
Validation loss: 2.252340088287989

Epoch: 5| Step: 9
Training loss: 0.8082222938537598
Validation loss: 2.1794910629590354

Epoch: 5| Step: 10
Training loss: 0.3753594756126404
Validation loss: 2.2801863153775535

Epoch: 5| Step: 11
Training loss: 0.15606826543807983
Validation loss: 2.260666439930598

Epoch: 253| Step: 0
Training loss: 0.7383073568344116
Validation loss: 2.3043633153041205

Epoch: 5| Step: 1
Training loss: 0.8034526705741882
Validation loss: 2.3401033331950507

Epoch: 5| Step: 2
Training loss: 0.5043388605117798
Validation loss: 2.3034488012393317

Epoch: 5| Step: 3
Training loss: 0.5108808279037476
Validation loss: 2.3132492899894714

Epoch: 5| Step: 4
Training loss: 0.48019084334373474
Validation loss: 2.259315013885498

Epoch: 5| Step: 5
Training loss: 0.572475254535675
Validation loss: 2.2298418382803598

Epoch: 5| Step: 6
Training loss: 0.7506391406059265
Validation loss: 2.2626981337865195

Epoch: 5| Step: 7
Training loss: 0.2741518020629883
Validation loss: 2.2377687891324363

Epoch: 5| Step: 8
Training loss: 0.4411045014858246
Validation loss: 2.236544132232666

Epoch: 5| Step: 9
Training loss: 0.3260859251022339
Validation loss: 2.2338170409202576

Epoch: 5| Step: 10
Training loss: 0.5155186057090759
Validation loss: 2.2502743701140084

Epoch: 5| Step: 11
Training loss: 0.39928650856018066
Validation loss: 2.2810387512048087

Epoch: 254| Step: 0
Training loss: 0.7107356190681458
Validation loss: 2.2723005215326944

Epoch: 5| Step: 1
Training loss: 0.501231849193573
Validation loss: 2.3173511028289795

Epoch: 5| Step: 2
Training loss: 0.527288556098938
Validation loss: 2.2923259337743125

Epoch: 5| Step: 3
Training loss: 0.7398406863212585
Validation loss: 2.310931553443273

Epoch: 5| Step: 4
Training loss: 0.2842389941215515
Validation loss: 2.2121892273426056

Epoch: 5| Step: 5
Training loss: 0.556282639503479
Validation loss: 2.207833538452784

Epoch: 5| Step: 6
Training loss: 0.7022216320037842
Validation loss: 2.257081607977549

Epoch: 5| Step: 7
Training loss: 0.6394095420837402
Validation loss: 2.200686454772949

Epoch: 5| Step: 8
Training loss: 0.34088432788848877
Validation loss: 2.1857645312945047

Epoch: 5| Step: 9
Training loss: 0.4627005159854889
Validation loss: 2.184909130136172

Epoch: 5| Step: 10
Training loss: 0.5756651163101196
Validation loss: 2.3146215776602426

Epoch: 5| Step: 11
Training loss: 0.3388279676437378
Validation loss: 2.2703507294257483

Epoch: 255| Step: 0
Training loss: 0.538974404335022
Validation loss: 2.326409270366033

Epoch: 5| Step: 1
Training loss: 0.8219842910766602
Validation loss: 2.2547248949607215

Epoch: 5| Step: 2
Training loss: 0.46913331747055054
Validation loss: 2.200104519724846

Epoch: 5| Step: 3
Training loss: 0.6092363595962524
Validation loss: 2.2095212936401367

Epoch: 5| Step: 4
Training loss: 0.4142712950706482
Validation loss: 2.224698483943939

Epoch: 5| Step: 5
Training loss: 0.43244409561157227
Validation loss: 2.2107555866241455

Epoch: 5| Step: 6
Training loss: 0.47955578565597534
Validation loss: 2.223314414421717

Epoch: 5| Step: 7
Training loss: 0.5406976938247681
Validation loss: 2.244634985923767

Epoch: 5| Step: 8
Training loss: 0.32576441764831543
Validation loss: 2.2032338927189508

Epoch: 5| Step: 9
Training loss: 0.25573164224624634
Validation loss: 2.2644401689370475

Epoch: 5| Step: 10
Training loss: 0.7990471720695496
Validation loss: 2.197856515645981

Epoch: 5| Step: 11
Training loss: 0.367973268032074
Validation loss: 2.260388672351837

Epoch: 256| Step: 0
Training loss: 0.645933985710144
Validation loss: 2.2486445804437003

Epoch: 5| Step: 1
Training loss: 0.3446422219276428
Validation loss: 2.1810896396636963

Epoch: 5| Step: 2
Training loss: 0.37301382422447205
Validation loss: 2.2502478609482446

Epoch: 5| Step: 3
Training loss: 0.5387977361679077
Validation loss: 2.2950790027777352

Epoch: 5| Step: 4
Training loss: 0.7002583742141724
Validation loss: 2.2521558900674186

Epoch: 5| Step: 5
Training loss: 0.3122081458568573
Validation loss: 2.2058565616607666

Epoch: 5| Step: 6
Training loss: 0.27538779377937317
Validation loss: 2.2805212438106537

Epoch: 5| Step: 7
Training loss: 0.4779239296913147
Validation loss: 2.270785560210546

Epoch: 5| Step: 8
Training loss: 0.752649188041687
Validation loss: 2.260964666803678

Epoch: 5| Step: 9
Training loss: 0.592503011226654
Validation loss: 2.2694051216046014

Epoch: 5| Step: 10
Training loss: 0.5547114610671997
Validation loss: 2.2501720090707145

Epoch: 5| Step: 11
Training loss: 0.6293666958808899
Validation loss: 2.280000160137812

Epoch: 257| Step: 0
Training loss: 0.5489727258682251
Validation loss: 2.2579188148180642

Epoch: 5| Step: 1
Training loss: 0.7969245314598083
Validation loss: 2.2390228509902954

Epoch: 5| Step: 2
Training loss: 0.2872334122657776
Validation loss: 2.2290495932102203

Epoch: 5| Step: 3
Training loss: 0.5051102638244629
Validation loss: 2.2036768098672233

Epoch: 5| Step: 4
Training loss: 0.791175127029419
Validation loss: 2.2113648603359857

Epoch: 5| Step: 5
Training loss: 0.36813274025917053
Validation loss: 2.177847703297933

Epoch: 5| Step: 6
Training loss: 0.3137713074684143
Validation loss: 2.2558179795742035

Epoch: 5| Step: 7
Training loss: 0.4187238812446594
Validation loss: 2.3073025743166604

Epoch: 5| Step: 8
Training loss: 0.374936044216156
Validation loss: 2.2429409126440683

Epoch: 5| Step: 9
Training loss: 0.5497907400131226
Validation loss: 2.255948821703593

Epoch: 5| Step: 10
Training loss: 0.35063958168029785
Validation loss: 2.2639207591613135

Epoch: 5| Step: 11
Training loss: 1.2473417520523071
Validation loss: 2.2608494659264884

Epoch: 258| Step: 0
Training loss: 0.34157782793045044
Validation loss: 2.2529164950052896

Epoch: 5| Step: 1
Training loss: 0.4952358305454254
Validation loss: 2.2623057663440704

Epoch: 5| Step: 2
Training loss: 0.2999277710914612
Validation loss: 2.2344370434681573

Epoch: 5| Step: 3
Training loss: 0.8097187280654907
Validation loss: 2.3050636698802314

Epoch: 5| Step: 4
Training loss: 0.6027170419692993
Validation loss: 2.253751258055369

Epoch: 5| Step: 5
Training loss: 0.45576056838035583
Validation loss: 2.3060487111409507

Epoch: 5| Step: 6
Training loss: 0.32523298263549805
Validation loss: 2.256424526373545

Epoch: 5| Step: 7
Training loss: 0.44030624628067017
Validation loss: 2.2428263823191323

Epoch: 5| Step: 8
Training loss: 0.4667210578918457
Validation loss: 2.228721708059311

Epoch: 5| Step: 9
Training loss: 0.7869902849197388
Validation loss: 2.2503359566132226

Epoch: 5| Step: 10
Training loss: 0.42607927322387695
Validation loss: 2.231795057654381

Epoch: 5| Step: 11
Training loss: 0.3645464777946472
Validation loss: 2.2312508622805276

Epoch: 259| Step: 0
Training loss: 0.4833550453186035
Validation loss: 2.23555263876915

Epoch: 5| Step: 1
Training loss: 0.9167799949645996
Validation loss: 2.211608275771141

Epoch: 5| Step: 2
Training loss: 0.46758216619491577
Validation loss: 2.2709520856539407

Epoch: 5| Step: 3
Training loss: 0.6193119287490845
Validation loss: 2.2862199346224465

Epoch: 5| Step: 4
Training loss: 0.32930469512939453
Validation loss: 2.306178147594134

Epoch: 5| Step: 5
Training loss: 0.5176960825920105
Validation loss: 2.341085155804952

Epoch: 5| Step: 6
Training loss: 0.26228541135787964
Validation loss: 2.2864008794228234

Epoch: 5| Step: 7
Training loss: 0.5779288411140442
Validation loss: 2.2563231686751046

Epoch: 5| Step: 8
Training loss: 0.6352584958076477
Validation loss: 2.25175404548645

Epoch: 5| Step: 9
Training loss: 0.44151076674461365
Validation loss: 2.2963944474856057

Epoch: 5| Step: 10
Training loss: 0.259838730096817
Validation loss: 2.2902353356281915

Epoch: 5| Step: 11
Training loss: 0.26639705896377563
Validation loss: 2.3402116000652313

Epoch: 260| Step: 0
Training loss: 0.417583167552948
Validation loss: 2.345162699619929

Epoch: 5| Step: 1
Training loss: 0.3994295001029968
Validation loss: 2.306537240743637

Epoch: 5| Step: 2
Training loss: 0.6232855916023254
Validation loss: 2.282327185074488

Epoch: 5| Step: 3
Training loss: 0.6975351572036743
Validation loss: 2.2707594633102417

Epoch: 5| Step: 4
Training loss: 0.3002321422100067
Validation loss: 2.2647459705670676

Epoch: 5| Step: 5
Training loss: 0.5572448968887329
Validation loss: 2.2469026943047843

Epoch: 5| Step: 6
Training loss: 0.685651957988739
Validation loss: 2.286023288965225

Epoch: 5| Step: 7
Training loss: 0.4850861430168152
Validation loss: 2.2415942400693893

Epoch: 5| Step: 8
Training loss: 0.5578133463859558
Validation loss: 2.2654766043027244

Epoch: 5| Step: 9
Training loss: 0.2005416452884674
Validation loss: 2.2276398837566376

Epoch: 5| Step: 10
Training loss: 0.6168527603149414
Validation loss: 2.2959739416837692

Epoch: 5| Step: 11
Training loss: 0.821621835231781
Validation loss: 2.2653373728195825

Epoch: 261| Step: 0
Training loss: 0.3431982398033142
Validation loss: 2.303172821799914

Epoch: 5| Step: 1
Training loss: 0.5491971373558044
Validation loss: 2.21222056945165

Epoch: 5| Step: 2
Training loss: 0.5508731603622437
Validation loss: 2.220868388811747

Epoch: 5| Step: 3
Training loss: 0.4213995337486267
Validation loss: 2.2410368621349335

Epoch: 5| Step: 4
Training loss: 0.46279317140579224
Validation loss: 2.2329923510551453

Epoch: 5| Step: 5
Training loss: 0.3111604154109955
Validation loss: 2.253934850295385

Epoch: 5| Step: 6
Training loss: 0.711885392665863
Validation loss: 2.2463883558909097

Epoch: 5| Step: 7
Training loss: 0.3503345549106598
Validation loss: 2.2986201643943787

Epoch: 5| Step: 8
Training loss: 0.749001145362854
Validation loss: 2.2586826980113983

Epoch: 5| Step: 9
Training loss: 0.48546743392944336
Validation loss: 2.2935036023457847

Epoch: 5| Step: 10
Training loss: 0.4587944447994232
Validation loss: 2.2648561348517737

Epoch: 5| Step: 11
Training loss: 0.24615097045898438
Validation loss: 2.254759654402733

Epoch: 262| Step: 0
Training loss: 0.45003795623779297
Validation loss: 2.2651868760585785

Epoch: 5| Step: 1
Training loss: 0.39044392108917236
Validation loss: 2.259343763192495

Epoch: 5| Step: 2
Training loss: 0.5387384295463562
Validation loss: 2.2392492989699044

Epoch: 5| Step: 3
Training loss: 0.29573294520378113
Validation loss: 2.2609867999951043

Epoch: 5| Step: 4
Training loss: 0.6129342913627625
Validation loss: 2.2486318250497184

Epoch: 5| Step: 5
Training loss: 0.6258641481399536
Validation loss: 2.2601726154486337

Epoch: 5| Step: 6
Training loss: 0.44865065813064575
Validation loss: 2.21992098291715

Epoch: 5| Step: 7
Training loss: 0.3158847689628601
Validation loss: 2.2710003157456717

Epoch: 5| Step: 8
Training loss: 0.35351163148880005
Validation loss: 2.267047623793284

Epoch: 5| Step: 9
Training loss: 0.561562180519104
Validation loss: 2.293495242794355

Epoch: 5| Step: 10
Training loss: 0.4918646216392517
Validation loss: 2.2354943255583444

Epoch: 5| Step: 11
Training loss: 0.452759325504303
Validation loss: 2.311167726914088

Epoch: 263| Step: 0
Training loss: 0.6160775423049927
Validation loss: 2.2248416195313134

Epoch: 5| Step: 1
Training loss: 0.2996695637702942
Validation loss: 2.287981539964676

Epoch: 5| Step: 2
Training loss: 0.6631709337234497
Validation loss: 2.2423065503438315

Epoch: 5| Step: 3
Training loss: 0.41271597146987915
Validation loss: 2.2371034175157547

Epoch: 5| Step: 4
Training loss: 0.49917706847190857
Validation loss: 2.2955744763215384

Epoch: 5| Step: 5
Training loss: 0.6610783338546753
Validation loss: 2.2639461954434714

Epoch: 5| Step: 6
Training loss: 0.48423147201538086
Validation loss: 2.2123468269904456

Epoch: 5| Step: 7
Training loss: 0.5985690355300903
Validation loss: 2.242973347504934

Epoch: 5| Step: 8
Training loss: 0.7950233221054077
Validation loss: 2.246474569042524

Epoch: 5| Step: 9
Training loss: 0.28963929414749146
Validation loss: 2.2121440917253494

Epoch: 5| Step: 10
Training loss: 0.37128743529319763
Validation loss: 2.238687833150228

Epoch: 5| Step: 11
Training loss: 0.27402687072753906
Validation loss: 2.2475610772768655

Epoch: 264| Step: 0
Training loss: 0.690093994140625
Validation loss: 2.2763217290242515

Epoch: 5| Step: 1
Training loss: 0.3548930883407593
Validation loss: 2.2637780209382377

Epoch: 5| Step: 2
Training loss: 0.3175894320011139
Validation loss: 2.2694063832362494

Epoch: 5| Step: 3
Training loss: 0.35442429780960083
Validation loss: 2.297556589047114

Epoch: 5| Step: 4
Training loss: 0.5754775404930115
Validation loss: 2.276293605566025

Epoch: 5| Step: 5
Training loss: 0.6282566785812378
Validation loss: 2.2419249763091407

Epoch: 5| Step: 6
Training loss: 0.5558578372001648
Validation loss: 2.261605699857076

Epoch: 5| Step: 7
Training loss: 0.45077723264694214
Validation loss: 2.2164128621419272

Epoch: 5| Step: 8
Training loss: 0.5490375757217407
Validation loss: 2.249856024980545

Epoch: 5| Step: 9
Training loss: 0.37180909514427185
Validation loss: 2.248910774787267

Epoch: 5| Step: 10
Training loss: 0.4113657474517822
Validation loss: 2.3155702700217566

Epoch: 5| Step: 11
Training loss: 0.28481367230415344
Validation loss: 2.2663712551196418

Epoch: 265| Step: 0
Training loss: 0.40026241540908813
Validation loss: 2.315204918384552

Epoch: 5| Step: 1
Training loss: 0.5498465895652771
Validation loss: 2.2372970581054688

Epoch: 5| Step: 2
Training loss: 0.4961276054382324
Validation loss: 2.191221743822098

Epoch: 5| Step: 3
Training loss: 1.2312285900115967
Validation loss: 2.2528477112452188

Epoch: 5| Step: 4
Training loss: 0.3472835421562195
Validation loss: 2.2904665718475976

Epoch: 5| Step: 5
Training loss: 0.5318509936332703
Validation loss: 2.213445688287417

Epoch: 5| Step: 6
Training loss: 0.45587748289108276
Validation loss: 2.252667079369227

Epoch: 5| Step: 7
Training loss: 0.5176874399185181
Validation loss: 2.2476293643315635

Epoch: 5| Step: 8
Training loss: 0.24191828072071075
Validation loss: 2.277845472097397

Epoch: 5| Step: 9
Training loss: 0.49490705132484436
Validation loss: 2.320639411608378

Epoch: 5| Step: 10
Training loss: 0.39090579748153687
Validation loss: 2.3346484949191413

Epoch: 5| Step: 11
Training loss: 0.22773587703704834
Validation loss: 2.280484368403753

Epoch: 266| Step: 0
Training loss: 0.6781115531921387
Validation loss: 2.275761197010676

Epoch: 5| Step: 1
Training loss: 0.5122814178466797
Validation loss: 2.305035392443339

Epoch: 5| Step: 2
Training loss: 0.8400386571884155
Validation loss: 2.230858877301216

Epoch: 5| Step: 3
Training loss: 0.5095783472061157
Validation loss: 2.2769083778063455

Epoch: 5| Step: 4
Training loss: 0.4377974569797516
Validation loss: 2.3015208144982657

Epoch: 5| Step: 5
Training loss: 0.5615840554237366
Validation loss: 2.24686931570371

Epoch: 5| Step: 6
Training loss: 0.5473166108131409
Validation loss: 2.318078637123108

Epoch: 5| Step: 7
Training loss: 0.4655199944972992
Validation loss: 2.3467256476481757

Epoch: 5| Step: 8
Training loss: 0.7463744282722473
Validation loss: 2.348755975564321

Epoch: 5| Step: 9
Training loss: 0.43883925676345825
Validation loss: 2.361714228987694

Epoch: 5| Step: 10
Training loss: 0.3879357874393463
Validation loss: 2.302276685833931

Epoch: 5| Step: 11
Training loss: 0.35317277908325195
Validation loss: 2.2398373583952584

Epoch: 267| Step: 0
Training loss: 0.610737681388855
Validation loss: 2.2332632144292197

Epoch: 5| Step: 1
Training loss: 0.4602380394935608
Validation loss: 2.2274252672990165

Epoch: 5| Step: 2
Training loss: 0.6200172901153564
Validation loss: 2.2804987033208213

Epoch: 5| Step: 3
Training loss: 0.7497454881668091
Validation loss: 2.228593200445175

Epoch: 5| Step: 4
Training loss: 0.2707241475582123
Validation loss: 2.2930118640263877

Epoch: 5| Step: 5
Training loss: 0.7316269874572754
Validation loss: 2.2753352721532187

Epoch: 5| Step: 6
Training loss: 0.7014702558517456
Validation loss: 2.3880096475283303

Epoch: 5| Step: 7
Training loss: 0.7591551542282104
Validation loss: 2.341216951608658

Epoch: 5| Step: 8
Training loss: 0.2824363708496094
Validation loss: 2.271399031082789

Epoch: 5| Step: 9
Training loss: 0.5743427872657776
Validation loss: 2.25786222020785

Epoch: 5| Step: 10
Training loss: 0.6355611681938171
Validation loss: 2.2616318265597024

Epoch: 5| Step: 11
Training loss: 0.1910930871963501
Validation loss: 2.2730999439954758

Epoch: 268| Step: 0
Training loss: 0.7299927473068237
Validation loss: 2.253461331129074

Epoch: 5| Step: 1
Training loss: 0.4393821656703949
Validation loss: 2.280117611090342

Epoch: 5| Step: 2
Training loss: 0.4476366639137268
Validation loss: 2.2093732208013535

Epoch: 5| Step: 3
Training loss: 0.6687506437301636
Validation loss: 2.2197711765766144

Epoch: 5| Step: 4
Training loss: 0.6534014344215393
Validation loss: 2.260563870271047

Epoch: 5| Step: 5
Training loss: 0.3015885353088379
Validation loss: 2.2582866748174033

Epoch: 5| Step: 6
Training loss: 0.44923996925354004
Validation loss: 2.2406191527843475

Epoch: 5| Step: 7
Training loss: 0.44781237840652466
Validation loss: 2.288294424613317

Epoch: 5| Step: 8
Training loss: 0.4565053880214691
Validation loss: 2.2553957800070443

Epoch: 5| Step: 9
Training loss: 0.7924258708953857
Validation loss: 2.212581917643547

Epoch: 5| Step: 10
Training loss: 0.36642342805862427
Validation loss: 2.1852596551179886

Epoch: 5| Step: 11
Training loss: 0.4400908946990967
Validation loss: 2.1922933757305145

Epoch: 269| Step: 0
Training loss: 0.4816862642765045
Validation loss: 2.2292696883281073

Epoch: 5| Step: 1
Training loss: 0.2706924080848694
Validation loss: 2.2629326482613883

Epoch: 5| Step: 2
Training loss: 0.8148056268692017
Validation loss: 2.2484272519747415

Epoch: 5| Step: 3
Training loss: 0.3231448233127594
Validation loss: 2.2581652899583182

Epoch: 5| Step: 4
Training loss: 0.19605594873428345
Validation loss: 2.191044971346855

Epoch: 5| Step: 5
Training loss: 0.6598766446113586
Validation loss: 2.2715251594781876

Epoch: 5| Step: 6
Training loss: 0.40862029790878296
Validation loss: 2.238251735766729

Epoch: 5| Step: 7
Training loss: 0.41200289130210876
Validation loss: 2.3207865804433823

Epoch: 5| Step: 8
Training loss: 0.5150493383407593
Validation loss: 2.3121345241864524

Epoch: 5| Step: 9
Training loss: 0.43916958570480347
Validation loss: 2.2596441358327866

Epoch: 5| Step: 10
Training loss: 0.32954055070877075
Validation loss: 2.262720435857773

Epoch: 5| Step: 11
Training loss: 0.3104625940322876
Validation loss: 2.256646434466044

Epoch: 270| Step: 0
Training loss: 0.7513232231140137
Validation loss: 2.290854940811793

Epoch: 5| Step: 1
Training loss: 0.33282050490379333
Validation loss: 2.2302637646595636

Epoch: 5| Step: 2
Training loss: 0.5633869767189026
Validation loss: 2.2449910591046014

Epoch: 5| Step: 3
Training loss: 0.5729886293411255
Validation loss: 2.288975844780604

Epoch: 5| Step: 4
Training loss: 0.39301061630249023
Validation loss: 2.257265955209732

Epoch: 5| Step: 5
Training loss: 0.32647648453712463
Validation loss: 2.253839353720347

Epoch: 5| Step: 6
Training loss: 0.24650391936302185
Validation loss: 2.253056287765503

Epoch: 5| Step: 7
Training loss: 0.375210702419281
Validation loss: 2.2870061000188193

Epoch: 5| Step: 8
Training loss: 0.5975321531295776
Validation loss: 2.2772569259007773

Epoch: 5| Step: 9
Training loss: 0.5455933809280396
Validation loss: 2.295521875222524

Epoch: 5| Step: 10
Training loss: 0.4316747188568115
Validation loss: 2.273546094695727

Epoch: 5| Step: 11
Training loss: 0.5192168354988098
Validation loss: 2.309365207950274

Epoch: 271| Step: 0
Training loss: 0.7335903644561768
Validation loss: 2.252923538287481

Epoch: 5| Step: 1
Training loss: 0.3281513750553131
Validation loss: 2.256808196504911

Epoch: 5| Step: 2
Training loss: 0.4595843255519867
Validation loss: 2.2802374263604483

Epoch: 5| Step: 3
Training loss: 0.3448599874973297
Validation loss: 2.222610294818878

Epoch: 5| Step: 4
Training loss: 0.32066863775253296
Validation loss: 2.2533826927344003

Epoch: 5| Step: 5
Training loss: 0.4634600281715393
Validation loss: 2.333451787630717

Epoch: 5| Step: 6
Training loss: 0.3830769956111908
Validation loss: 2.2145384897788367

Epoch: 5| Step: 7
Training loss: 0.4309457838535309
Validation loss: 2.26567550500234

Epoch: 5| Step: 8
Training loss: 0.27650952339172363
Validation loss: 2.270661935210228

Epoch: 5| Step: 9
Training loss: 0.7900897860527039
Validation loss: 2.276158317923546

Epoch: 5| Step: 10
Training loss: 0.3388294279575348
Validation loss: 2.269139657417933

Epoch: 5| Step: 11
Training loss: 0.5702975988388062
Validation loss: 2.1803274005651474

Epoch: 272| Step: 0
Training loss: 0.4024590849876404
Validation loss: 2.2115852534770966

Epoch: 5| Step: 1
Training loss: 0.4453641474246979
Validation loss: 2.233549584945043

Epoch: 5| Step: 2
Training loss: 0.35876068472862244
Validation loss: 2.226111024618149

Epoch: 5| Step: 3
Training loss: 0.42242366075515747
Validation loss: 2.2160939276218414

Epoch: 5| Step: 4
Training loss: 0.47055014967918396
Validation loss: 2.243294815222422

Epoch: 5| Step: 5
Training loss: 0.5921499133110046
Validation loss: 2.2039145827293396

Epoch: 5| Step: 6
Training loss: 0.4582732319831848
Validation loss: 2.2782373329003653

Epoch: 5| Step: 7
Training loss: 0.2242782860994339
Validation loss: 2.2760246843099594

Epoch: 5| Step: 8
Training loss: 0.26875773072242737
Validation loss: 2.265298843383789

Epoch: 5| Step: 9
Training loss: 0.6309140920639038
Validation loss: 2.256517211596171

Epoch: 5| Step: 10
Training loss: 0.7365272641181946
Validation loss: 2.243404428164164

Epoch: 5| Step: 11
Training loss: 0.3438042998313904
Validation loss: 2.23408933977286

Epoch: 273| Step: 0
Training loss: 0.41177335381507874
Validation loss: 2.225537826617559

Epoch: 5| Step: 1
Training loss: 0.5730931162834167
Validation loss: 2.2501556078592935

Epoch: 5| Step: 2
Training loss: 0.3501644730567932
Validation loss: 2.221187472343445

Epoch: 5| Step: 3
Training loss: 0.3889494240283966
Validation loss: 2.2373111148675284

Epoch: 5| Step: 4
Training loss: 0.47006601095199585
Validation loss: 2.286052793264389

Epoch: 5| Step: 5
Training loss: 0.5447124242782593
Validation loss: 2.3074044038852057

Epoch: 5| Step: 6
Training loss: 0.4807190001010895
Validation loss: 2.305634712179502

Epoch: 5| Step: 7
Training loss: 0.3488299250602722
Validation loss: 2.2344591915607452

Epoch: 5| Step: 8
Training loss: 0.7731139659881592
Validation loss: 2.2339013566573462

Epoch: 5| Step: 9
Training loss: 0.3296888768672943
Validation loss: 2.222202936808268

Epoch: 5| Step: 10
Training loss: 0.7302314043045044
Validation loss: 2.203916758298874

Epoch: 5| Step: 11
Training loss: 0.360090434551239
Validation loss: 2.2657351245482764

Epoch: 274| Step: 0
Training loss: 0.3145011067390442
Validation loss: 2.291263312101364

Epoch: 5| Step: 1
Training loss: 0.4656509757041931
Validation loss: 2.310407261053721

Epoch: 5| Step: 2
Training loss: 0.6538895964622498
Validation loss: 2.320193126797676

Epoch: 5| Step: 3
Training loss: 0.7738205194473267
Validation loss: 2.310800721247991

Epoch: 5| Step: 4
Training loss: 0.9091687202453613
Validation loss: 2.2949845790863037

Epoch: 5| Step: 5
Training loss: 0.24890002608299255
Validation loss: 2.198264921704928

Epoch: 5| Step: 6
Training loss: 0.609104335308075
Validation loss: 2.2195226599772773

Epoch: 5| Step: 7
Training loss: 0.6439954042434692
Validation loss: 2.234749287366867

Epoch: 5| Step: 8
Training loss: 0.49814844131469727
Validation loss: 2.20493050913016

Epoch: 5| Step: 9
Training loss: 0.402976930141449
Validation loss: 2.275156448284785

Epoch: 5| Step: 10
Training loss: 0.8521862030029297
Validation loss: 2.258607188860575

Epoch: 5| Step: 11
Training loss: 0.685921311378479
Validation loss: 2.300313820441564

Epoch: 275| Step: 0
Training loss: 0.3215603828430176
Validation loss: 2.341172327597936

Epoch: 5| Step: 1
Training loss: 0.5352035760879517
Validation loss: 2.3536741187175116

Epoch: 5| Step: 2
Training loss: 0.82188880443573
Validation loss: 2.245906800031662

Epoch: 5| Step: 3
Training loss: 0.36076825857162476
Validation loss: 2.244493822256724

Epoch: 5| Step: 4
Training loss: 0.464061439037323
Validation loss: 2.1928974191347756

Epoch: 5| Step: 5
Training loss: 0.47319841384887695
Validation loss: 2.2310714572668076

Epoch: 5| Step: 6
Training loss: 0.39115726947784424
Validation loss: 2.2575864841540656

Epoch: 5| Step: 7
Training loss: 0.4687364995479584
Validation loss: 2.2363363603750863

Epoch: 5| Step: 8
Training loss: 0.34059861302375793
Validation loss: 2.2066323260466256

Epoch: 5| Step: 9
Training loss: 0.642687201499939
Validation loss: 2.215416898330053

Epoch: 5| Step: 10
Training loss: 0.6485897302627563
Validation loss: 2.267073472340902

Epoch: 5| Step: 11
Training loss: 0.2622135877609253
Validation loss: 2.264576479792595

Epoch: 276| Step: 0
Training loss: 0.7655231356620789
Validation loss: 2.2481548289457955

Epoch: 5| Step: 1
Training loss: 0.4529467523097992
Validation loss: 2.292608916759491

Epoch: 5| Step: 2
Training loss: 0.4648994505405426
Validation loss: 2.273626377185186

Epoch: 5| Step: 3
Training loss: 0.3938333988189697
Validation loss: 2.26773069302241

Epoch: 5| Step: 4
Training loss: 0.38656964898109436
Validation loss: 2.233754580219587

Epoch: 5| Step: 5
Training loss: 0.35381650924682617
Validation loss: 2.272862821817398

Epoch: 5| Step: 6
Training loss: 0.3344314694404602
Validation loss: 2.300832822918892

Epoch: 5| Step: 7
Training loss: 0.2946781516075134
Validation loss: 2.297429551680883

Epoch: 5| Step: 8
Training loss: 0.39515137672424316
Validation loss: 2.2836115459601083

Epoch: 5| Step: 9
Training loss: 0.9901456832885742
Validation loss: 2.2286556363105774

Epoch: 5| Step: 10
Training loss: 0.4223771095275879
Validation loss: 2.270364065965017

Epoch: 5| Step: 11
Training loss: 0.4892690181732178
Validation loss: 2.299068053563436

Epoch: 277| Step: 0
Training loss: 0.5523587465286255
Validation loss: 2.3175613979498544

Epoch: 5| Step: 1
Training loss: 0.5555523633956909
Validation loss: 2.271806389093399

Epoch: 5| Step: 2
Training loss: 0.5581282377243042
Validation loss: 2.259993930657705

Epoch: 5| Step: 3
Training loss: 0.6651725769042969
Validation loss: 2.248785530527433

Epoch: 5| Step: 4
Training loss: 0.4790123999118805
Validation loss: 2.26054414610068

Epoch: 5| Step: 5
Training loss: 0.42967891693115234
Validation loss: 2.274351343512535

Epoch: 5| Step: 6
Training loss: 0.21422412991523743
Validation loss: 2.2504723370075226

Epoch: 5| Step: 7
Training loss: 0.3911725580692291
Validation loss: 2.2880662232637405

Epoch: 5| Step: 8
Training loss: 0.30258291959762573
Validation loss: 2.2454466621081033

Epoch: 5| Step: 9
Training loss: 0.3571323752403259
Validation loss: 2.2201983431975045

Epoch: 5| Step: 10
Training loss: 0.33647599816322327
Validation loss: 2.2635370592276254

Epoch: 5| Step: 11
Training loss: 0.2515749931335449
Validation loss: 2.228901118040085

Epoch: 278| Step: 0
Training loss: 0.4581514298915863
Validation loss: 2.1977999409039817

Epoch: 5| Step: 1
Training loss: 0.5980977416038513
Validation loss: 2.240684151649475

Epoch: 5| Step: 2
Training loss: 0.5871460437774658
Validation loss: 2.2241697311401367

Epoch: 5| Step: 3
Training loss: 0.4946090579032898
Validation loss: 2.24587482213974

Epoch: 5| Step: 4
Training loss: 0.34201088547706604
Validation loss: 2.247735251983007

Epoch: 5| Step: 5
Training loss: 0.628290593624115
Validation loss: 2.2484531005223594

Epoch: 5| Step: 6
Training loss: 0.47926226258277893
Validation loss: 2.286250799894333

Epoch: 5| Step: 7
Training loss: 0.451768159866333
Validation loss: 2.319107413291931

Epoch: 5| Step: 8
Training loss: 0.7761291265487671
Validation loss: 2.307052438457807

Epoch: 5| Step: 9
Training loss: 0.44334179162979126
Validation loss: 2.288489749034246

Epoch: 5| Step: 10
Training loss: 0.4470491409301758
Validation loss: 2.196082611878713

Epoch: 5| Step: 11
Training loss: 0.20309382677078247
Validation loss: 2.2590089539686837

Epoch: 279| Step: 0
Training loss: 0.7878880500793457
Validation loss: 2.213638201355934

Epoch: 5| Step: 1
Training loss: 0.41492795944213867
Validation loss: 2.200599730014801

Epoch: 5| Step: 2
Training loss: 0.5245910882949829
Validation loss: 2.2273047119379044

Epoch: 5| Step: 3
Training loss: 0.6419157981872559
Validation loss: 2.2418459008137384

Epoch: 5| Step: 4
Training loss: 0.6115638017654419
Validation loss: 2.207748959461848

Epoch: 5| Step: 5
Training loss: 0.29713740944862366
Validation loss: 2.306520084540049

Epoch: 5| Step: 6
Training loss: 0.31978535652160645
Validation loss: 2.2372784415880838

Epoch: 5| Step: 7
Training loss: 0.44117483496665955
Validation loss: 2.309159571925799

Epoch: 5| Step: 8
Training loss: 0.45678919553756714
Validation loss: 2.397118717432022

Epoch: 5| Step: 9
Training loss: 0.5746127963066101
Validation loss: 2.3513517479101815

Epoch: 5| Step: 10
Training loss: 0.5635785460472107
Validation loss: 2.3002593715985618

Epoch: 5| Step: 11
Training loss: 0.37213683128356934
Validation loss: 2.291181266307831

Epoch: 280| Step: 0
Training loss: 0.31222572922706604
Validation loss: 2.293265958627065

Epoch: 5| Step: 1
Training loss: 0.4490906298160553
Validation loss: 2.241650859514872

Epoch: 5| Step: 2
Training loss: 0.3640851378440857
Validation loss: 2.2827457189559937

Epoch: 5| Step: 3
Training loss: 0.6063711643218994
Validation loss: 2.2442029118537903

Epoch: 5| Step: 4
Training loss: 0.4619383215904236
Validation loss: 2.273458316922188

Epoch: 5| Step: 5
Training loss: 0.4598632752895355
Validation loss: 2.3451922784248986

Epoch: 5| Step: 6
Training loss: 0.19523373246192932
Validation loss: 2.260769098997116

Epoch: 5| Step: 7
Training loss: 0.3408650755882263
Validation loss: 2.255947773655256

Epoch: 5| Step: 8
Training loss: 0.5037589073181152
Validation loss: 2.2721252838770547

Epoch: 5| Step: 9
Training loss: 0.7841020822525024
Validation loss: 2.2375388691822686

Epoch: 5| Step: 10
Training loss: 0.39963477849960327
Validation loss: 2.295903593301773

Epoch: 5| Step: 11
Training loss: 0.39178740978240967
Validation loss: 2.3205772191286087

Epoch: 281| Step: 0
Training loss: 0.8105133175849915
Validation loss: 2.3440455198287964

Epoch: 5| Step: 1
Training loss: 0.7924872636795044
Validation loss: 2.3422500590483346

Epoch: 5| Step: 2
Training loss: 0.40989741683006287
Validation loss: 2.372399866580963

Epoch: 5| Step: 3
Training loss: 0.30598148703575134
Validation loss: 2.3150201936562858

Epoch: 5| Step: 4
Training loss: 0.4384312033653259
Validation loss: 2.254467616478602

Epoch: 5| Step: 5
Training loss: 0.42188435792922974
Validation loss: 2.2649712413549423

Epoch: 5| Step: 6
Training loss: 0.6422810554504395
Validation loss: 2.2393141289552054

Epoch: 5| Step: 7
Training loss: 0.6627904176712036
Validation loss: 2.2616703460613885

Epoch: 5| Step: 8
Training loss: 0.9589751958847046
Validation loss: 2.2778554558753967

Epoch: 5| Step: 9
Training loss: 0.47199997305870056
Validation loss: 2.2614576121171317

Epoch: 5| Step: 10
Training loss: 0.3941778540611267
Validation loss: 2.2812393804391227

Epoch: 5| Step: 11
Training loss: 0.6175274848937988
Validation loss: 2.284755046168963

Epoch: 282| Step: 0
Training loss: 0.217009499669075
Validation loss: 2.2812444617350898

Epoch: 5| Step: 1
Training loss: 0.4196792542934418
Validation loss: 2.3264302959044776

Epoch: 5| Step: 2
Training loss: 0.3644205629825592
Validation loss: 2.268153816461563

Epoch: 5| Step: 3
Training loss: 0.4732268750667572
Validation loss: 2.269619718194008

Epoch: 5| Step: 4
Training loss: 0.6924288868904114
Validation loss: 2.3161258697509766

Epoch: 5| Step: 5
Training loss: 0.402715265750885
Validation loss: 2.245439350605011

Epoch: 5| Step: 6
Training loss: 0.43369635939598083
Validation loss: 2.2764423886934915

Epoch: 5| Step: 7
Training loss: 0.5839542746543884
Validation loss: 2.2638109028339386

Epoch: 5| Step: 8
Training loss: 0.6384193301200867
Validation loss: 2.261758009592692

Epoch: 5| Step: 9
Training loss: 0.2800964117050171
Validation loss: 2.277708262205124

Epoch: 5| Step: 10
Training loss: 0.5732090473175049
Validation loss: 2.328449005881945

Epoch: 5| Step: 11
Training loss: 0.4428504705429077
Validation loss: 2.3403606762488685

Epoch: 283| Step: 0
Training loss: 0.7082996368408203
Validation loss: 2.347726116577784

Epoch: 5| Step: 1
Training loss: 0.43146267533302307
Validation loss: 2.331199119488398

Epoch: 5| Step: 2
Training loss: 0.39300045371055603
Validation loss: 2.2976078540086746

Epoch: 5| Step: 3
Training loss: 0.43170976638793945
Validation loss: 2.3053073585033417

Epoch: 5| Step: 4
Training loss: 0.3831803798675537
Validation loss: 2.2895828088124595

Epoch: 5| Step: 5
Training loss: 0.4078589379787445
Validation loss: 2.274336129426956

Epoch: 5| Step: 6
Training loss: 0.756289541721344
Validation loss: 2.265379637479782

Epoch: 5| Step: 7
Training loss: 0.4618402421474457
Validation loss: 2.2989567716916404

Epoch: 5| Step: 8
Training loss: 0.3667053282260895
Validation loss: 2.342425455649694

Epoch: 5| Step: 9
Training loss: 0.6072467565536499
Validation loss: 2.33228866259257

Epoch: 5| Step: 10
Training loss: 0.46818241477012634
Validation loss: 2.332104355096817

Epoch: 5| Step: 11
Training loss: 0.775351345539093
Validation loss: 2.2968454559644065

Epoch: 284| Step: 0
Training loss: 0.518500030040741
Validation loss: 2.1942629714806876

Epoch: 5| Step: 1
Training loss: 0.6259980201721191
Validation loss: 2.225157002607981

Epoch: 5| Step: 2
Training loss: 0.717087984085083
Validation loss: 2.239442909757296

Epoch: 5| Step: 3
Training loss: 0.37820330262184143
Validation loss: 2.1892928729454675

Epoch: 5| Step: 4
Training loss: 0.6595315337181091
Validation loss: 2.2187099854151406

Epoch: 5| Step: 5
Training loss: 0.3322126865386963
Validation loss: 2.295637831091881

Epoch: 5| Step: 6
Training loss: 0.7738033533096313
Validation loss: 2.2902879863977432

Epoch: 5| Step: 7
Training loss: 0.5696578025817871
Validation loss: 2.2722336798906326

Epoch: 5| Step: 8
Training loss: 0.4177318215370178
Validation loss: 2.2941995710134506

Epoch: 5| Step: 9
Training loss: 0.38435205817222595
Validation loss: 2.2751689851284027

Epoch: 5| Step: 10
Training loss: 0.41725021600723267
Validation loss: 2.2439817587534585

Epoch: 5| Step: 11
Training loss: 0.8218040466308594
Validation loss: 2.2604787945747375

Epoch: 285| Step: 0
Training loss: 0.4763452410697937
Validation loss: 2.23889023065567

Epoch: 5| Step: 1
Training loss: 0.8901866674423218
Validation loss: 2.253308594226837

Epoch: 5| Step: 2
Training loss: 0.7218579053878784
Validation loss: 2.2312987049420676

Epoch: 5| Step: 3
Training loss: 0.47462520003318787
Validation loss: 2.2182578841845193

Epoch: 5| Step: 4
Training loss: 0.3979434370994568
Validation loss: 2.2316825538873672

Epoch: 5| Step: 5
Training loss: 0.5457741022109985
Validation loss: 2.3180593649546304

Epoch: 5| Step: 6
Training loss: 0.5965539216995239
Validation loss: 2.2784856458504996

Epoch: 5| Step: 7
Training loss: 0.41290274262428284
Validation loss: 2.3064622481664023

Epoch: 5| Step: 8
Training loss: 0.4142557978630066
Validation loss: 2.292210429906845

Epoch: 5| Step: 9
Training loss: 0.24273428320884705
Validation loss: 2.2848533540964127

Epoch: 5| Step: 10
Training loss: 0.3077266216278076
Validation loss: 2.2391772816578546

Epoch: 5| Step: 11
Training loss: 0.38326144218444824
Validation loss: 2.225226809581121

Epoch: 286| Step: 0
Training loss: 0.47096481919288635
Validation loss: 2.2177681674559913

Epoch: 5| Step: 1
Training loss: 0.34716659784317017
Validation loss: 2.29964479804039

Epoch: 5| Step: 2
Training loss: 0.28439101576805115
Validation loss: 2.2933972775936127

Epoch: 5| Step: 3
Training loss: 0.46197929978370667
Validation loss: 2.2684108714262643

Epoch: 5| Step: 4
Training loss: 0.3767114281654358
Validation loss: 2.289983203013738

Epoch: 5| Step: 5
Training loss: 0.37195885181427
Validation loss: 2.3762477238972983

Epoch: 5| Step: 6
Training loss: 0.80302494764328
Validation loss: 2.325238769253095

Epoch: 5| Step: 7
Training loss: 0.39702120423316956
Validation loss: 2.320894345641136

Epoch: 5| Step: 8
Training loss: 0.5721210241317749
Validation loss: 2.290968880057335

Epoch: 5| Step: 9
Training loss: 0.39213627576828003
Validation loss: 2.277582347393036

Epoch: 5| Step: 10
Training loss: 0.5632858276367188
Validation loss: 2.2675649921099343

Epoch: 5| Step: 11
Training loss: 1.1550655364990234
Validation loss: 2.217221478621165

Epoch: 287| Step: 0
Training loss: 0.45459070801734924
Validation loss: 2.312764883041382

Epoch: 5| Step: 1
Training loss: 0.19794915616512299
Validation loss: 2.2821159909168878

Epoch: 5| Step: 2
Training loss: 0.3268231451511383
Validation loss: 2.3214694062868753

Epoch: 5| Step: 3
Training loss: 0.7545398473739624
Validation loss: 2.239172786474228

Epoch: 5| Step: 4
Training loss: 0.4281162619590759
Validation loss: 2.28665063281854

Epoch: 5| Step: 5
Training loss: 0.7741808891296387
Validation loss: 2.325706193844477

Epoch: 5| Step: 6
Training loss: 0.2363557070493698
Validation loss: 2.2858717938264212

Epoch: 5| Step: 7
Training loss: 0.23400595784187317
Validation loss: 2.2807654788096747

Epoch: 5| Step: 8
Training loss: 0.31577879190444946
Validation loss: 2.278296331564585

Epoch: 5| Step: 9
Training loss: 0.4927210211753845
Validation loss: 2.300026908516884

Epoch: 5| Step: 10
Training loss: 0.43374770879745483
Validation loss: 2.350444714228312

Epoch: 5| Step: 11
Training loss: 0.7835813760757446
Validation loss: 2.2751229405403137

Epoch: 288| Step: 0
Training loss: 0.4035974442958832
Validation loss: 2.2384670873483024

Epoch: 5| Step: 1
Training loss: 0.40128397941589355
Validation loss: 2.217289765675863

Epoch: 5| Step: 2
Training loss: 0.47424229979515076
Validation loss: 2.2577453603347144

Epoch: 5| Step: 3
Training loss: 0.5987385511398315
Validation loss: 2.2081799805164337

Epoch: 5| Step: 4
Training loss: 0.6091090440750122
Validation loss: 2.2122334440549216

Epoch: 5| Step: 5
Training loss: 0.2262585163116455
Validation loss: 2.236478100220362

Epoch: 5| Step: 6
Training loss: 0.2591429650783539
Validation loss: 2.2346868316332498

Epoch: 5| Step: 7
Training loss: 0.7062100172042847
Validation loss: 2.2470975716908774

Epoch: 5| Step: 8
Training loss: 0.7561413049697876
Validation loss: 2.309170742829641

Epoch: 5| Step: 9
Training loss: 0.47965821623802185
Validation loss: 2.257256716489792

Epoch: 5| Step: 10
Training loss: 0.49916720390319824
Validation loss: 2.1966303288936615

Epoch: 5| Step: 11
Training loss: 0.3739643692970276
Validation loss: 2.2126415173212686

Epoch: 289| Step: 0
Training loss: 0.5315172672271729
Validation loss: 2.243655929962794

Epoch: 5| Step: 1
Training loss: 0.5719283223152161
Validation loss: 2.2444625546534858

Epoch: 5| Step: 2
Training loss: 0.3883083462715149
Validation loss: 2.2225145995616913

Epoch: 5| Step: 3
Training loss: 0.27090704441070557
Validation loss: 2.277294079462687

Epoch: 5| Step: 4
Training loss: 1.1053378582000732
Validation loss: 2.2677266001701355

Epoch: 5| Step: 5
Training loss: 0.806073784828186
Validation loss: 2.2799610793590546

Epoch: 5| Step: 6
Training loss: 0.3808595538139343
Validation loss: 2.2600731750329337

Epoch: 5| Step: 7
Training loss: 0.3017786741256714
Validation loss: 2.2663139005502067

Epoch: 5| Step: 8
Training loss: 0.28867393732070923
Validation loss: 2.1758572359879813

Epoch: 5| Step: 9
Training loss: 0.30285510420799255
Validation loss: 2.230603198210398

Epoch: 5| Step: 10
Training loss: 0.29515260457992554
Validation loss: 2.2457310408353806

Epoch: 5| Step: 11
Training loss: 0.36944580078125
Validation loss: 2.2317489981651306

Epoch: 290| Step: 0
Training loss: 0.30603379011154175
Validation loss: 2.2244213422139487

Epoch: 5| Step: 1
Training loss: 0.41638025641441345
Validation loss: 2.204529936114947

Epoch: 5| Step: 2
Training loss: 0.4582829475402832
Validation loss: 2.2378860165675483

Epoch: 5| Step: 3
Training loss: 0.48257794976234436
Validation loss: 2.3725678424040475

Epoch: 5| Step: 4
Training loss: 0.2324092835187912
Validation loss: 2.3426579236984253

Epoch: 5| Step: 5
Training loss: 1.1301862001419067
Validation loss: 2.3239582777023315

Epoch: 5| Step: 6
Training loss: 0.44069987535476685
Validation loss: 2.260094781716665

Epoch: 5| Step: 7
Training loss: 0.1788540482521057
Validation loss: 2.3134686052799225

Epoch: 5| Step: 8
Training loss: 0.5608973503112793
Validation loss: 2.241610070069631

Epoch: 5| Step: 9
Training loss: 0.360804945230484
Validation loss: 2.245398243268331

Epoch: 5| Step: 10
Training loss: 0.29329434037208557
Validation loss: 2.2647822250922522

Epoch: 5| Step: 11
Training loss: 0.08303868770599365
Validation loss: 2.3006093204021454

Epoch: 291| Step: 0
Training loss: 0.3009466230869293
Validation loss: 2.2741879423459372

Epoch: 5| Step: 1
Training loss: 0.8515260815620422
Validation loss: 2.2887480556964874

Epoch: 5| Step: 2
Training loss: 0.42558297514915466
Validation loss: 2.2564156452814736

Epoch: 5| Step: 3
Training loss: 0.46549978852272034
Validation loss: 2.288289964199066

Epoch: 5| Step: 4
Training loss: 0.2975878417491913
Validation loss: 2.222218245267868

Epoch: 5| Step: 5
Training loss: 0.4486016631126404
Validation loss: 2.2395387291908264

Epoch: 5| Step: 6
Training loss: 0.6194931864738464
Validation loss: 2.25155316789945

Epoch: 5| Step: 7
Training loss: 0.31840866804122925
Validation loss: 2.2383103171984353

Epoch: 5| Step: 8
Training loss: 0.3117407560348511
Validation loss: 2.178803652524948

Epoch: 5| Step: 9
Training loss: 0.5107290744781494
Validation loss: 2.305018832286199

Epoch: 5| Step: 10
Training loss: 0.6455961465835571
Validation loss: 2.325144906838735

Epoch: 5| Step: 11
Training loss: 0.2613046169281006
Validation loss: 2.3054843048254647

Epoch: 292| Step: 0
Training loss: 0.4893724322319031
Validation loss: 2.3250127335389457

Epoch: 5| Step: 1
Training loss: 0.7735038995742798
Validation loss: 2.3399685074885688

Epoch: 5| Step: 2
Training loss: 0.48958534002304077
Validation loss: 2.313488483428955

Epoch: 5| Step: 3
Training loss: 0.7800443768501282
Validation loss: 2.2972725679477057

Epoch: 5| Step: 4
Training loss: 0.26027363538742065
Validation loss: 2.3271247943242392

Epoch: 5| Step: 5
Training loss: 0.2656378149986267
Validation loss: 2.260819733142853

Epoch: 5| Step: 6
Training loss: 0.40539422631263733
Validation loss: 2.2448530991872153

Epoch: 5| Step: 7
Training loss: 0.5282026529312134
Validation loss: 2.2497119853893914

Epoch: 5| Step: 8
Training loss: 0.6374402046203613
Validation loss: 2.2364997267723083

Epoch: 5| Step: 9
Training loss: 0.781044602394104
Validation loss: 2.282794257005056

Epoch: 5| Step: 10
Training loss: 0.37294453382492065
Validation loss: 2.317898948987325

Epoch: 5| Step: 11
Training loss: 0.20283669233322144
Validation loss: 2.3067547182242074

Epoch: 293| Step: 0
Training loss: 0.3783439099788666
Validation loss: 2.2722116708755493

Epoch: 5| Step: 1
Training loss: 0.6980317831039429
Validation loss: 2.2748895386854806

Epoch: 5| Step: 2
Training loss: 0.43809443712234497
Validation loss: 2.3070030411084494

Epoch: 5| Step: 3
Training loss: 0.4168551564216614
Validation loss: 2.2475278079509735

Epoch: 5| Step: 4
Training loss: 0.45795512199401855
Validation loss: 2.2322967698176703

Epoch: 5| Step: 5
Training loss: 0.4294669032096863
Validation loss: 2.218065783381462

Epoch: 5| Step: 6
Training loss: 0.23560543358325958
Validation loss: 2.2785601119200387

Epoch: 5| Step: 7
Training loss: 0.5318011045455933
Validation loss: 2.2743393381436667

Epoch: 5| Step: 8
Training loss: 0.40631598234176636
Validation loss: 2.2511328160762787

Epoch: 5| Step: 9
Training loss: 0.2652296721935272
Validation loss: 2.2546088695526123

Epoch: 5| Step: 10
Training loss: 0.6084533929824829
Validation loss: 2.264203722278277

Epoch: 5| Step: 11
Training loss: 0.3727588653564453
Validation loss: 2.263872663180033

Epoch: 294| Step: 0
Training loss: 0.3279661238193512
Validation loss: 2.262794335683187

Epoch: 5| Step: 1
Training loss: 0.2830098569393158
Validation loss: 2.2899753749370575

Epoch: 5| Step: 2
Training loss: 0.29972654581069946
Validation loss: 2.2732773969570794

Epoch: 5| Step: 3
Training loss: 0.3512936532497406
Validation loss: 2.273084968328476

Epoch: 5| Step: 4
Training loss: 0.43020743131637573
Validation loss: 2.249151552716891

Epoch: 5| Step: 5
Training loss: 0.36065301299095154
Validation loss: 2.235198199748993

Epoch: 5| Step: 6
Training loss: 0.8630478978157043
Validation loss: 2.2371876090765

Epoch: 5| Step: 7
Training loss: 0.6710566878318787
Validation loss: 2.2100372115770974

Epoch: 5| Step: 8
Training loss: 0.43473538756370544
Validation loss: 2.263923058907191

Epoch: 5| Step: 9
Training loss: 0.45353737473487854
Validation loss: 2.203189899524053

Epoch: 5| Step: 10
Training loss: 0.5522707104682922
Validation loss: 2.283205986022949

Epoch: 5| Step: 11
Training loss: 0.4063781499862671
Validation loss: 2.2903412878513336

Epoch: 295| Step: 0
Training loss: 0.5041636228561401
Validation loss: 2.3427332739035287

Epoch: 5| Step: 1
Training loss: 0.6582180261611938
Validation loss: 2.296730160713196

Epoch: 5| Step: 2
Training loss: 0.5784686803817749
Validation loss: 2.2432605226834617

Epoch: 5| Step: 3
Training loss: 0.45789289474487305
Validation loss: 2.2663134088118873

Epoch: 5| Step: 4
Training loss: 0.3290553689002991
Validation loss: 2.2538481603066125

Epoch: 5| Step: 5
Training loss: 0.46642178297042847
Validation loss: 2.2554720640182495

Epoch: 5| Step: 6
Training loss: 0.4963838458061218
Validation loss: 2.266430914402008

Epoch: 5| Step: 7
Training loss: 0.645810604095459
Validation loss: 2.2388818860054016

Epoch: 5| Step: 8
Training loss: 0.1932791769504547
Validation loss: 2.261984626452128

Epoch: 5| Step: 9
Training loss: 0.48347124457359314
Validation loss: 2.2862813671429953

Epoch: 5| Step: 10
Training loss: 0.23475170135498047
Validation loss: 2.30197944243749

Epoch: 5| Step: 11
Training loss: 0.2724348306655884
Validation loss: 2.3085088382164636

Epoch: 296| Step: 0
Training loss: 0.31957513093948364
Validation loss: 2.264953295389811

Epoch: 5| Step: 1
Training loss: 0.3764156997203827
Validation loss: 2.27522603670756

Epoch: 5| Step: 2
Training loss: 0.3755839467048645
Validation loss: 2.26019050180912

Epoch: 5| Step: 3
Training loss: 0.9095214605331421
Validation loss: 2.2599620819091797

Epoch: 5| Step: 4
Training loss: 0.3347952365875244
Validation loss: 2.2542608976364136

Epoch: 5| Step: 5
Training loss: 0.3678503632545471
Validation loss: 2.2605111797650657

Epoch: 5| Step: 6
Training loss: 0.478740930557251
Validation loss: 2.315071771542231

Epoch: 5| Step: 7
Training loss: 0.25524550676345825
Validation loss: 2.3306037286917367

Epoch: 5| Step: 8
Training loss: 0.4931618571281433
Validation loss: 2.3334423998991647

Epoch: 5| Step: 9
Training loss: 0.5672475695610046
Validation loss: 2.3690928717454276

Epoch: 5| Step: 10
Training loss: 0.7315179705619812
Validation loss: 2.3060009876887

Epoch: 5| Step: 11
Training loss: 0.2314479947090149
Validation loss: 2.3207072814305625

Epoch: 297| Step: 0
Training loss: 0.7648423910140991
Validation loss: 2.268175572156906

Epoch: 5| Step: 1
Training loss: 0.399946004152298
Validation loss: 2.244370619455973

Epoch: 5| Step: 2
Training loss: 0.2801295816898346
Validation loss: 2.2474935750166574

Epoch: 5| Step: 3
Training loss: 0.3296632468700409
Validation loss: 2.208448608716329

Epoch: 5| Step: 4
Training loss: 0.33581751585006714
Validation loss: 2.174285054206848

Epoch: 5| Step: 5
Training loss: 0.3395596146583557
Validation loss: 2.2695196121931076

Epoch: 5| Step: 6
Training loss: 0.35937249660491943
Validation loss: 2.2173651258150735

Epoch: 5| Step: 7
Training loss: 0.39027753472328186
Validation loss: 2.2316334545612335

Epoch: 5| Step: 8
Training loss: 0.8708195686340332
Validation loss: 2.2776306867599487

Epoch: 5| Step: 9
Training loss: 0.407108873128891
Validation loss: 2.310919205347697

Epoch: 5| Step: 10
Training loss: 0.28426799178123474
Validation loss: 2.213948587576548

Epoch: 5| Step: 11
Training loss: 0.404079794883728
Validation loss: 2.2029697000980377

Epoch: 298| Step: 0
Training loss: 0.4750114381313324
Validation loss: 2.227357412377993

Epoch: 5| Step: 1
Training loss: 0.2778889238834381
Validation loss: 2.284015645583471

Epoch: 5| Step: 2
Training loss: 0.19948320090770721
Validation loss: 2.262279083331426

Epoch: 5| Step: 3
Training loss: 0.4551011919975281
Validation loss: 2.247081200281779

Epoch: 5| Step: 4
Training loss: 0.4322654604911804
Validation loss: 2.323906809091568

Epoch: 5| Step: 5
Training loss: 0.2966364026069641
Validation loss: 2.2572377721468606

Epoch: 5| Step: 6
Training loss: 0.45949435234069824
Validation loss: 2.308419610063235

Epoch: 5| Step: 7
Training loss: 0.32001930475234985
Validation loss: 2.318118413289388

Epoch: 5| Step: 8
Training loss: 0.6595619320869446
Validation loss: 2.2463999589284263

Epoch: 5| Step: 9
Training loss: 0.7294217348098755
Validation loss: 2.2619101206461587

Epoch: 5| Step: 10
Training loss: 0.427335262298584
Validation loss: 2.2859585732221603

Epoch: 5| Step: 11
Training loss: 0.412835955619812
Validation loss: 2.221693659822146

Epoch: 299| Step: 0
Training loss: 0.34415847063064575
Validation loss: 2.2855691015720367

Epoch: 5| Step: 1
Training loss: 0.4304439425468445
Validation loss: 2.309199035167694

Epoch: 5| Step: 2
Training loss: 0.4097927510738373
Validation loss: 2.264452874660492

Epoch: 5| Step: 3
Training loss: 0.3889164328575134
Validation loss: 2.281353915731112

Epoch: 5| Step: 4
Training loss: 0.8074743151664734
Validation loss: 2.3096939424673715

Epoch: 5| Step: 5
Training loss: 0.20634910464286804
Validation loss: 2.247768998146057

Epoch: 5| Step: 6
Training loss: 0.43330448865890503
Validation loss: 2.2528685331344604

Epoch: 5| Step: 7
Training loss: 0.3589511811733246
Validation loss: 2.2858309149742126

Epoch: 5| Step: 8
Training loss: 0.4084169864654541
Validation loss: 2.2673439929882684

Epoch: 5| Step: 9
Training loss: 0.5018445253372192
Validation loss: 2.298766240477562

Epoch: 5| Step: 10
Training loss: 0.3965650796890259
Validation loss: 2.2952347298463187

Epoch: 5| Step: 11
Training loss: 0.61192786693573
Validation loss: 2.26761523882548

Epoch: 300| Step: 0
Training loss: 0.3552328646183014
Validation loss: 2.240206023057302

Epoch: 5| Step: 1
Training loss: 0.5664958357810974
Validation loss: 2.2643040915330253

Epoch: 5| Step: 2
Training loss: 0.42436033487319946
Validation loss: 2.2928242484728494

Epoch: 5| Step: 3
Training loss: 0.3052923083305359
Validation loss: 2.2562570621569953

Epoch: 5| Step: 4
Training loss: 0.30412977933883667
Validation loss: 2.2872897585233054

Epoch: 5| Step: 5
Training loss: 0.49966558814048767
Validation loss: 2.3026656806468964

Epoch: 5| Step: 6
Training loss: 0.6179291605949402
Validation loss: 2.279901256163915

Epoch: 5| Step: 7
Training loss: 0.5952540636062622
Validation loss: 2.2364419052998223

Epoch: 5| Step: 8
Training loss: 0.36247748136520386
Validation loss: 2.2258903781572976

Epoch: 5| Step: 9
Training loss: 0.17465341091156006
Validation loss: 2.2196882913510003

Epoch: 5| Step: 10
Training loss: 0.5566249489784241
Validation loss: 2.27875188489755

Epoch: 5| Step: 11
Training loss: 0.31062448024749756
Validation loss: 2.2907912135124207

Epoch: 301| Step: 0
Training loss: 0.2692292034626007
Validation loss: 2.240943044424057

Epoch: 5| Step: 1
Training loss: 0.609624981880188
Validation loss: 2.244154671827952

Epoch: 5| Step: 2
Training loss: 0.2862205505371094
Validation loss: 2.269325057665507

Epoch: 5| Step: 3
Training loss: 0.28554266691207886
Validation loss: 2.2399820586045585

Epoch: 5| Step: 4
Training loss: 0.5813113451004028
Validation loss: 2.336663395166397

Epoch: 5| Step: 5
Training loss: 0.8096324801445007
Validation loss: 2.264539380868276

Epoch: 5| Step: 6
Training loss: 0.36042317748069763
Validation loss: 2.3186913480361304

Epoch: 5| Step: 7
Training loss: 0.5347915887832642
Validation loss: 2.3167486786842346

Epoch: 5| Step: 8
Training loss: 0.43695011734962463
Validation loss: 2.3404974242051444

Epoch: 5| Step: 9
Training loss: 0.22843065857887268
Validation loss: 2.265250196059545

Epoch: 5| Step: 10
Training loss: 0.2814544439315796
Validation loss: 2.2750874757766724

Epoch: 5| Step: 11
Training loss: 0.2627021074295044
Validation loss: 2.2734273870786033

Epoch: 302| Step: 0
Training loss: 0.9476396441459656
Validation loss: 2.2496005296707153

Epoch: 5| Step: 1
Training loss: 0.29654085636138916
Validation loss: 2.311651219924291

Epoch: 5| Step: 2
Training loss: 0.4548409581184387
Validation loss: 2.2826434274514518

Epoch: 5| Step: 3
Training loss: 0.3113061487674713
Validation loss: 2.2997646729151406

Epoch: 5| Step: 4
Training loss: 0.39824455976486206
Validation loss: 2.297774831453959

Epoch: 5| Step: 5
Training loss: 0.3402193486690521
Validation loss: 2.2933013091484704

Epoch: 5| Step: 6
Training loss: 0.5851565599441528
Validation loss: 2.2639766136805215

Epoch: 5| Step: 7
Training loss: 0.5455499887466431
Validation loss: 2.198543687661489

Epoch: 5| Step: 8
Training loss: 0.2955983281135559
Validation loss: 2.2290433843930564

Epoch: 5| Step: 9
Training loss: 0.26894283294677734
Validation loss: 2.2408094058434167

Epoch: 5| Step: 10
Training loss: 0.29305458068847656
Validation loss: 2.260926455259323

Epoch: 5| Step: 11
Training loss: 0.17114321887493134
Validation loss: 2.317271649837494

Epoch: 303| Step: 0
Training loss: 0.28681445121765137
Validation loss: 2.289292573928833

Epoch: 5| Step: 1
Training loss: 0.44021645188331604
Validation loss: 2.348527933160464

Epoch: 5| Step: 2
Training loss: 0.4232570230960846
Validation loss: 2.3115869760513306

Epoch: 5| Step: 3
Training loss: 0.44099074602127075
Validation loss: 2.2777334302663803

Epoch: 5| Step: 4
Training loss: 0.5078790187835693
Validation loss: 2.2786305795113244

Epoch: 5| Step: 5
Training loss: 0.4215150773525238
Validation loss: 2.2038192451000214

Epoch: 5| Step: 6
Training loss: 0.5180904865264893
Validation loss: 2.2648736238479614

Epoch: 5| Step: 7
Training loss: 0.318347305059433
Validation loss: 2.264412904779116

Epoch: 5| Step: 8
Training loss: 0.31674233078956604
Validation loss: 2.2124706705411277

Epoch: 5| Step: 9
Training loss: 0.5087665319442749
Validation loss: 2.2277116626501083

Epoch: 5| Step: 10
Training loss: 0.9332337379455566
Validation loss: 2.261781632900238

Epoch: 5| Step: 11
Training loss: 0.1871323585510254
Validation loss: 2.279698744416237

Epoch: 304| Step: 0
Training loss: 0.4403873085975647
Validation loss: 2.284711961944898

Epoch: 5| Step: 1
Training loss: 0.6193618774414062
Validation loss: 2.3102629284063974

Epoch: 5| Step: 2
Training loss: 0.4842756390571594
Validation loss: 2.2241440614064536

Epoch: 5| Step: 3
Training loss: 0.6278844475746155
Validation loss: 2.255071689685186

Epoch: 5| Step: 4
Training loss: 0.37903016805648804
Validation loss: 2.224667718013128

Epoch: 5| Step: 5
Training loss: 0.24699345231056213
Validation loss: 2.2541380673646927

Epoch: 5| Step: 6
Training loss: 0.3789970278739929
Validation loss: 2.235391855239868

Epoch: 5| Step: 7
Training loss: 0.24336346983909607
Validation loss: 2.2337032357851663

Epoch: 5| Step: 8
Training loss: 0.2562156021595001
Validation loss: 2.24759042263031

Epoch: 5| Step: 9
Training loss: 0.3512357771396637
Validation loss: 2.2678606857856116

Epoch: 5| Step: 10
Training loss: 0.27574801445007324
Validation loss: 2.217116206884384

Epoch: 5| Step: 11
Training loss: 2.0878820419311523
Validation loss: 2.294463351368904

Epoch: 305| Step: 0
Training loss: 0.3406060039997101
Validation loss: 2.2500899036725364

Epoch: 5| Step: 1
Training loss: 0.3543750047683716
Validation loss: 2.2857385079065957

Epoch: 5| Step: 2
Training loss: 0.40912169218063354
Validation loss: 2.3040427466233573

Epoch: 5| Step: 3
Training loss: 0.277776300907135
Validation loss: 2.270231639345487

Epoch: 5| Step: 4
Training loss: 0.4070042073726654
Validation loss: 2.276398152112961

Epoch: 5| Step: 5
Training loss: 0.5179668068885803
Validation loss: 2.2682726085186005

Epoch: 5| Step: 6
Training loss: 0.2848248779773712
Validation loss: 2.285273532072703

Epoch: 5| Step: 7
Training loss: 0.21775205433368683
Validation loss: 2.3344084868828454

Epoch: 5| Step: 8
Training loss: 0.3468765616416931
Validation loss: 2.322045942147573

Epoch: 5| Step: 9
Training loss: 0.9646833539009094
Validation loss: 2.304927105704943

Epoch: 5| Step: 10
Training loss: 0.2828909158706665
Validation loss: 2.341899404923121

Epoch: 5| Step: 11
Training loss: 0.3174007534980774
Validation loss: 2.3126485546429953

Epoch: 306| Step: 0
Training loss: 0.7703460454940796
Validation loss: 2.237104654312134

Epoch: 5| Step: 1
Training loss: 0.440357506275177
Validation loss: 2.3136001924673715

Epoch: 5| Step: 2
Training loss: 0.29871249198913574
Validation loss: 2.3084369202454886

Epoch: 5| Step: 3
Training loss: 0.2741018235683441
Validation loss: 2.3035571724176407

Epoch: 5| Step: 4
Training loss: 0.5433242917060852
Validation loss: 2.320029338200887

Epoch: 5| Step: 5
Training loss: 0.2831577658653259
Validation loss: 2.280349204937617

Epoch: 5| Step: 6
Training loss: 0.26275962591171265
Validation loss: 2.2470059394836426

Epoch: 5| Step: 7
Training loss: 0.4331989288330078
Validation loss: 2.2438543885946274

Epoch: 5| Step: 8
Training loss: 0.5098256468772888
Validation loss: 2.3122192323207855

Epoch: 5| Step: 9
Training loss: 0.47051143646240234
Validation loss: 2.255599627892176

Epoch: 5| Step: 10
Training loss: 0.41006678342819214
Validation loss: 2.2371650834878287

Epoch: 5| Step: 11
Training loss: 0.3246966004371643
Validation loss: 2.2978432873884835

Epoch: 307| Step: 0
Training loss: 0.4958365857601166
Validation loss: 2.244527588287989

Epoch: 5| Step: 1
Training loss: 0.5825267434120178
Validation loss: 2.320418437321981

Epoch: 5| Step: 2
Training loss: 0.8113589286804199
Validation loss: 2.311257839202881

Epoch: 5| Step: 3
Training loss: 0.6138941049575806
Validation loss: 2.2900428771972656

Epoch: 5| Step: 4
Training loss: 0.4843122065067291
Validation loss: 2.2322148183981576

Epoch: 5| Step: 5
Training loss: 0.25486892461776733
Validation loss: 2.285500928759575

Epoch: 5| Step: 6
Training loss: 0.3056007921695709
Validation loss: 2.2812806020180383

Epoch: 5| Step: 7
Training loss: 0.2363308221101761
Validation loss: 2.2395891497532525

Epoch: 5| Step: 8
Training loss: 0.38976532220840454
Validation loss: 2.2915965219338736

Epoch: 5| Step: 9
Training loss: 0.3707010746002197
Validation loss: 2.3161354859670005

Epoch: 5| Step: 10
Training loss: 0.4406959116458893
Validation loss: 2.2806922495365143

Epoch: 5| Step: 11
Training loss: 0.21937543153762817
Validation loss: 2.3057474891344705

Epoch: 308| Step: 0
Training loss: 0.42081156373023987
Validation loss: 2.2574711591005325

Epoch: 5| Step: 1
Training loss: 0.5294401049613953
Validation loss: 2.2266561637322106

Epoch: 5| Step: 2
Training loss: 0.4643462300300598
Validation loss: 2.2502996226151786

Epoch: 5| Step: 3
Training loss: 0.9180394411087036
Validation loss: 2.192339743177096

Epoch: 5| Step: 4
Training loss: 0.3309938311576843
Validation loss: 2.2785319288571677

Epoch: 5| Step: 5
Training loss: 0.2966096103191376
Validation loss: 2.2730472683906555

Epoch: 5| Step: 6
Training loss: 0.42014846205711365
Validation loss: 2.2837531566619873

Epoch: 5| Step: 7
Training loss: 0.28453391790390015
Validation loss: 2.253499294320742

Epoch: 5| Step: 8
Training loss: 0.383525550365448
Validation loss: 2.263131539026896

Epoch: 5| Step: 9
Training loss: 0.4763241708278656
Validation loss: 2.2293116599321365

Epoch: 5| Step: 10
Training loss: 0.3151036202907562
Validation loss: 2.281959444284439

Epoch: 5| Step: 11
Training loss: 0.14932197332382202
Validation loss: 2.2048169473807016

Epoch: 309| Step: 0
Training loss: 0.4750902056694031
Validation loss: 2.2082301576932273

Epoch: 5| Step: 1
Training loss: 0.43881359696388245
Validation loss: 2.1992263396581015

Epoch: 5| Step: 2
Training loss: 0.6660221219062805
Validation loss: 2.2104546328385672

Epoch: 5| Step: 3
Training loss: 0.6645992994308472
Validation loss: 2.2412786235411963

Epoch: 5| Step: 4
Training loss: 0.2628754675388336
Validation loss: 2.2539502878983817

Epoch: 5| Step: 5
Training loss: 0.4268511235713959
Validation loss: 2.201681151986122

Epoch: 5| Step: 6
Training loss: 0.30716851353645325
Validation loss: 2.252511034409205

Epoch: 5| Step: 7
Training loss: 0.259274423122406
Validation loss: 2.2512100537618003

Epoch: 5| Step: 8
Training loss: 0.34341490268707275
Validation loss: 2.254925305644671

Epoch: 5| Step: 9
Training loss: 0.333489328622818
Validation loss: 2.2469999492168427

Epoch: 5| Step: 10
Training loss: 0.2855597138404846
Validation loss: 2.3046774566173553

Epoch: 5| Step: 11
Training loss: 0.4946504533290863
Validation loss: 2.306180626153946

Epoch: 310| Step: 0
Training loss: 0.29464444518089294
Validation loss: 2.239832282066345

Epoch: 5| Step: 1
Training loss: 0.3658062815666199
Validation loss: 2.2455188830693564

Epoch: 5| Step: 2
Training loss: 0.7840941548347473
Validation loss: 2.2722728699445724

Epoch: 5| Step: 3
Training loss: 0.583297610282898
Validation loss: 2.251044084628423

Epoch: 5| Step: 4
Training loss: 0.5218408107757568
Validation loss: 2.2408761084079742

Epoch: 5| Step: 5
Training loss: 0.2052893191576004
Validation loss: 2.288526773452759

Epoch: 5| Step: 6
Training loss: 0.3310732841491699
Validation loss: 2.3080045580863953

Epoch: 5| Step: 7
Training loss: 0.30014315247535706
Validation loss: 2.367693523565928

Epoch: 5| Step: 8
Training loss: 0.3795345723628998
Validation loss: 2.358849585056305

Epoch: 5| Step: 9
Training loss: 0.35559916496276855
Validation loss: 2.3089854617913566

Epoch: 5| Step: 10
Training loss: 0.27863407135009766
Validation loss: 2.3498831490675607

Epoch: 5| Step: 11
Training loss: 0.3242291212081909
Validation loss: 2.2579702933629355

Epoch: 311| Step: 0
Training loss: 0.2796332836151123
Validation loss: 2.2734985599915185

Epoch: 5| Step: 1
Training loss: 0.32416754961013794
Validation loss: 2.2634180982907615

Epoch: 5| Step: 2
Training loss: 0.2650620937347412
Validation loss: 2.2534975757201514

Epoch: 5| Step: 3
Training loss: 0.5570046305656433
Validation loss: 2.2690518697102866

Epoch: 5| Step: 4
Training loss: 0.4648805260658264
Validation loss: 2.283788710832596

Epoch: 5| Step: 5
Training loss: 0.27568405866622925
Validation loss: 2.2674553096294403

Epoch: 5| Step: 6
Training loss: 0.710663914680481
Validation loss: 2.2786226073900857

Epoch: 5| Step: 7
Training loss: 0.30656367540359497
Validation loss: 2.323503404855728

Epoch: 5| Step: 8
Training loss: 0.29341188073158264
Validation loss: 2.290792559583982

Epoch: 5| Step: 9
Training loss: 0.41169819235801697
Validation loss: 2.2339641004800797

Epoch: 5| Step: 10
Training loss: 0.42412877082824707
Validation loss: 2.2827080885569253

Epoch: 5| Step: 11
Training loss: 0.4117448329925537
Validation loss: 2.243457148472468

Epoch: 312| Step: 0
Training loss: 0.9783397912979126
Validation loss: 2.2586572964986167

Epoch: 5| Step: 1
Training loss: 0.39343056082725525
Validation loss: 2.309633473555247

Epoch: 5| Step: 2
Training loss: 0.4789535105228424
Validation loss: 2.25630255540212

Epoch: 5| Step: 3
Training loss: 0.43830808997154236
Validation loss: 2.2270220617453256

Epoch: 5| Step: 4
Training loss: 0.5306662321090698
Validation loss: 2.287510802348455

Epoch: 5| Step: 5
Training loss: 0.23442089557647705
Validation loss: 2.2728239595890045

Epoch: 5| Step: 6
Training loss: 0.3666941523551941
Validation loss: 2.246152420838674

Epoch: 5| Step: 7
Training loss: 0.4528142511844635
Validation loss: 2.2282961010932922

Epoch: 5| Step: 8
Training loss: 0.3265659213066101
Validation loss: 2.2632673382759094

Epoch: 5| Step: 9
Training loss: 0.3083597719669342
Validation loss: 2.234374771515528

Epoch: 5| Step: 10
Training loss: 0.29363399744033813
Validation loss: 2.251342703898748

Epoch: 5| Step: 11
Training loss: 0.2851749062538147
Validation loss: 2.2325872033834457

Epoch: 313| Step: 0
Training loss: 0.40450459718704224
Validation loss: 2.2615784207979837

Epoch: 5| Step: 1
Training loss: 0.4504943788051605
Validation loss: 2.3116790552934012

Epoch: 5| Step: 2
Training loss: 0.38657599687576294
Validation loss: 2.2912966261307397

Epoch: 5| Step: 3
Training loss: 0.41991525888442993
Validation loss: 2.2548854698737464

Epoch: 5| Step: 4
Training loss: 0.4299483895301819
Validation loss: 2.275092234214147

Epoch: 5| Step: 5
Training loss: 0.40198031067848206
Validation loss: 2.259588191906611

Epoch: 5| Step: 6
Training loss: 0.2584797739982605
Validation loss: 2.2297057807445526

Epoch: 5| Step: 7
Training loss: 0.5446547269821167
Validation loss: 2.2464402119318643

Epoch: 5| Step: 8
Training loss: 0.3122990131378174
Validation loss: 2.287686506907145

Epoch: 5| Step: 9
Training loss: 0.7703948616981506
Validation loss: 2.241996705532074

Epoch: 5| Step: 10
Training loss: 0.2574397921562195
Validation loss: 2.240927735964457

Epoch: 5| Step: 11
Training loss: 0.17905724048614502
Validation loss: 2.244287679592768

Epoch: 314| Step: 0
Training loss: 0.21184667944908142
Validation loss: 2.2257600675026574

Epoch: 5| Step: 1
Training loss: 0.29115623235702515
Validation loss: 2.2000885903835297

Epoch: 5| Step: 2
Training loss: 0.4488042891025543
Validation loss: 2.2302818397680917

Epoch: 5| Step: 3
Training loss: 0.31713464856147766
Validation loss: 2.2539987365404763

Epoch: 5| Step: 4
Training loss: 0.7540407180786133
Validation loss: 2.2457580665747323

Epoch: 5| Step: 5
Training loss: 0.36205944418907166
Validation loss: 2.2370923906564713

Epoch: 5| Step: 6
Training loss: 0.2849322259426117
Validation loss: 2.262580990791321

Epoch: 5| Step: 7
Training loss: 0.2505980432033539
Validation loss: 2.24978443980217

Epoch: 5| Step: 8
Training loss: 0.6087805032730103
Validation loss: 2.249073634545008

Epoch: 5| Step: 9
Training loss: 0.3338099420070648
Validation loss: 2.270140290260315

Epoch: 5| Step: 10
Training loss: 0.5104129314422607
Validation loss: 2.2650746206442514

Epoch: 5| Step: 11
Training loss: 0.3992350101470947
Validation loss: 2.264848212401072

Epoch: 315| Step: 0
Training loss: 0.2765715718269348
Validation loss: 2.268698051571846

Epoch: 5| Step: 1
Training loss: 0.4736195206642151
Validation loss: 2.1860927740732827

Epoch: 5| Step: 2
Training loss: 0.800438404083252
Validation loss: 2.192753255367279

Epoch: 5| Step: 3
Training loss: 0.19673468172550201
Validation loss: 2.1540605227152505

Epoch: 5| Step: 4
Training loss: 0.2864178717136383
Validation loss: 2.245126356681188

Epoch: 5| Step: 5
Training loss: 0.2296483963727951
Validation loss: 2.2466832250356674

Epoch: 5| Step: 6
Training loss: 0.36232882738113403
Validation loss: 2.286692430575689

Epoch: 5| Step: 7
Training loss: 0.22703687846660614
Validation loss: 2.274073605736097

Epoch: 5| Step: 8
Training loss: 0.35148972272872925
Validation loss: 2.236704930663109

Epoch: 5| Step: 9
Training loss: 0.4949219822883606
Validation loss: 2.302072753508886

Epoch: 5| Step: 10
Training loss: 0.30360138416290283
Validation loss: 2.213438535730044

Epoch: 5| Step: 11
Training loss: 1.4950023889541626
Validation loss: 2.2833644350369773

Epoch: 316| Step: 0
Training loss: 0.29580822587013245
Validation loss: 2.240148330728213

Epoch: 5| Step: 1
Training loss: 0.27387872338294983
Validation loss: 2.194584682583809

Epoch: 5| Step: 2
Training loss: 0.30407285690307617
Validation loss: 2.2542395194371543

Epoch: 5| Step: 3
Training loss: 0.26627328991889954
Validation loss: 2.2810952564080558

Epoch: 5| Step: 4
Training loss: 0.42561984062194824
Validation loss: 2.292756070693334

Epoch: 5| Step: 5
Training loss: 0.2547869384288788
Validation loss: 2.289794445037842

Epoch: 5| Step: 6
Training loss: 0.36376404762268066
Validation loss: 2.24664169549942

Epoch: 5| Step: 7
Training loss: 0.7268930077552795
Validation loss: 2.251680463552475

Epoch: 5| Step: 8
Training loss: 0.41673144698143005
Validation loss: 2.306680644551913

Epoch: 5| Step: 9
Training loss: 0.5869282484054565
Validation loss: 2.237292543053627

Epoch: 5| Step: 10
Training loss: 0.34078121185302734
Validation loss: 2.2108991841475167

Epoch: 5| Step: 11
Training loss: 0.0876692533493042
Validation loss: 2.207735518614451

Epoch: 317| Step: 0
Training loss: 0.4221409857273102
Validation loss: 2.2336105704307556

Epoch: 5| Step: 1
Training loss: 0.5682783722877502
Validation loss: 2.256943389773369

Epoch: 5| Step: 2
Training loss: 0.24128380417823792
Validation loss: 2.221540858348211

Epoch: 5| Step: 3
Training loss: 0.5282581448554993
Validation loss: 2.271628906329473

Epoch: 5| Step: 4
Training loss: 0.30805495381355286
Validation loss: 2.2799628376960754

Epoch: 5| Step: 5
Training loss: 0.21970172226428986
Validation loss: 2.296050637960434

Epoch: 5| Step: 6
Training loss: 0.5139139890670776
Validation loss: 2.2888392508029938

Epoch: 5| Step: 7
Training loss: 0.334242045879364
Validation loss: 2.2848990758260093

Epoch: 5| Step: 8
Training loss: 0.44086402654647827
Validation loss: 2.240536833802859

Epoch: 5| Step: 9
Training loss: 0.5949808955192566
Validation loss: 2.1880213816960654

Epoch: 5| Step: 10
Training loss: 0.172608882188797
Validation loss: 2.2492862343788147

Epoch: 5| Step: 11
Training loss: 0.44839751720428467
Validation loss: 2.251503606637319

Epoch: 318| Step: 0
Training loss: 0.29175883531570435
Validation loss: 2.3057641088962555

Epoch: 5| Step: 1
Training loss: 0.4511205554008484
Validation loss: 2.25513864060243

Epoch: 5| Step: 2
Training loss: 0.35093432664871216
Validation loss: 2.1999150017897287

Epoch: 5| Step: 3
Training loss: 0.2577332854270935
Validation loss: 2.298900897304217

Epoch: 5| Step: 4
Training loss: 0.3045944273471832
Validation loss: 2.243925631046295

Epoch: 5| Step: 5
Training loss: 0.33686357736587524
Validation loss: 2.261344244082769

Epoch: 5| Step: 6
Training loss: 0.4090992510318756
Validation loss: 2.2574079583088555

Epoch: 5| Step: 7
Training loss: 0.7083393931388855
Validation loss: 2.272012079755465

Epoch: 5| Step: 8
Training loss: 0.30722561478614807
Validation loss: 2.2922721405824027

Epoch: 5| Step: 9
Training loss: 0.4659431576728821
Validation loss: 2.28181654214859

Epoch: 5| Step: 10
Training loss: 0.41824203729629517
Validation loss: 2.271643564105034

Epoch: 5| Step: 11
Training loss: 0.30242177844047546
Validation loss: 2.2332125504811606

Epoch: 319| Step: 0
Training loss: 0.5813835263252258
Validation loss: 2.2185171941916146

Epoch: 5| Step: 1
Training loss: 0.45099860429763794
Validation loss: 2.2001923074324927

Epoch: 5| Step: 2
Training loss: 0.27208226919174194
Validation loss: 2.2357336978117623

Epoch: 5| Step: 3
Training loss: 0.31182482838630676
Validation loss: 2.235910271604856

Epoch: 5| Step: 4
Training loss: 0.4355061948299408
Validation loss: 2.234354943037033

Epoch: 5| Step: 5
Training loss: 0.2679212987422943
Validation loss: 2.304956376552582

Epoch: 5| Step: 6
Training loss: 0.34542739391326904
Validation loss: 2.3033918042977652

Epoch: 5| Step: 7
Training loss: 0.4103512763977051
Validation loss: 2.327796717484792

Epoch: 5| Step: 8
Training loss: 0.413627952337265
Validation loss: 2.264533797899882

Epoch: 5| Step: 9
Training loss: 0.4746888279914856
Validation loss: 2.2846552381912866

Epoch: 5| Step: 10
Training loss: 0.4197731912136078
Validation loss: 2.324088434378306

Epoch: 5| Step: 11
Training loss: 0.2280919849872589
Validation loss: 2.253811130921046

Epoch: 320| Step: 0
Training loss: 0.4163743853569031
Validation loss: 2.248679538567861

Epoch: 5| Step: 1
Training loss: 0.6086957454681396
Validation loss: 2.2684186001618705

Epoch: 5| Step: 2
Training loss: 0.3525765538215637
Validation loss: 2.286669005950292

Epoch: 5| Step: 3
Training loss: 0.35343214869499207
Validation loss: 2.34470434486866

Epoch: 5| Step: 4
Training loss: 0.2647906243801117
Validation loss: 2.279154767592748

Epoch: 5| Step: 5
Training loss: 0.5705854296684265
Validation loss: 2.2648372252782187

Epoch: 5| Step: 6
Training loss: 0.34171581268310547
Validation loss: 2.2762622386217117

Epoch: 5| Step: 7
Training loss: 0.38143712282180786
Validation loss: 2.322367340326309

Epoch: 5| Step: 8
Training loss: 0.35311946272850037
Validation loss: 2.228226532538732

Epoch: 5| Step: 9
Training loss: 0.3343369960784912
Validation loss: 2.2529963701963425

Epoch: 5| Step: 10
Training loss: 0.3942492604255676
Validation loss: 2.2778641978899636

Epoch: 5| Step: 11
Training loss: 0.13002634048461914
Validation loss: 2.2537173132101693

Epoch: 321| Step: 0
Training loss: 0.34782758355140686
Validation loss: 2.331773986419042

Epoch: 5| Step: 1
Training loss: 0.20140966773033142
Validation loss: 2.26821306347847

Epoch: 5| Step: 2
Training loss: 0.42306891083717346
Validation loss: 2.3589134414990744

Epoch: 5| Step: 3
Training loss: 0.2736063599586487
Validation loss: 2.3184786339600882

Epoch: 5| Step: 4
Training loss: 0.39952152967453003
Validation loss: 2.3230998118718467

Epoch: 5| Step: 5
Training loss: 0.43277621269226074
Validation loss: 2.3060409228006997

Epoch: 5| Step: 6
Training loss: 0.6999919414520264
Validation loss: 2.2657464047273

Epoch: 5| Step: 7
Training loss: 0.26090094447135925
Validation loss: 2.3007409373919168

Epoch: 5| Step: 8
Training loss: 0.7963106036186218
Validation loss: 2.2614471167325974

Epoch: 5| Step: 9
Training loss: 0.42519131302833557
Validation loss: 2.2702001879612603

Epoch: 5| Step: 10
Training loss: 0.3836042284965515
Validation loss: 2.2917811969916024

Epoch: 5| Step: 11
Training loss: 0.19881141185760498
Validation loss: 2.2699141999085746

Epoch: 322| Step: 0
Training loss: 0.45567965507507324
Validation loss: 2.3188658406337104

Epoch: 5| Step: 1
Training loss: 0.26019567251205444
Validation loss: 2.300333241621653

Epoch: 5| Step: 2
Training loss: 0.423412024974823
Validation loss: 2.270408421754837

Epoch: 5| Step: 3
Training loss: 0.37340062856674194
Validation loss: 2.2744164764881134

Epoch: 5| Step: 4
Training loss: 0.3659629821777344
Validation loss: 2.2380956361691156

Epoch: 5| Step: 5
Training loss: 0.7414354681968689
Validation loss: 2.2657067080338797

Epoch: 5| Step: 6
Training loss: 0.45122575759887695
Validation loss: 2.2526379277308783

Epoch: 5| Step: 7
Training loss: 0.3626473546028137
Validation loss: 2.25297083457311

Epoch: 5| Step: 8
Training loss: 0.233618825674057
Validation loss: 2.3049461940924325

Epoch: 5| Step: 9
Training loss: 0.3218933343887329
Validation loss: 2.249427154660225

Epoch: 5| Step: 10
Training loss: 0.3455621004104614
Validation loss: 2.274250174562136

Epoch: 5| Step: 11
Training loss: 0.35846513509750366
Validation loss: 2.2651063799858093

Epoch: 323| Step: 0
Training loss: 0.3287998139858246
Validation loss: 2.2366164873043695

Epoch: 5| Step: 1
Training loss: 0.2386670559644699
Validation loss: 2.2391054133574166

Epoch: 5| Step: 2
Training loss: 0.39034944772720337
Validation loss: 2.2740580340226493

Epoch: 5| Step: 3
Training loss: 0.42870086431503296
Validation loss: 2.295236259698868

Epoch: 5| Step: 4
Training loss: 0.32425108551979065
Validation loss: 2.3226652642091117

Epoch: 5| Step: 5
Training loss: 0.5368282794952393
Validation loss: 2.237286681930224

Epoch: 5| Step: 6
Training loss: 0.3932568430900574
Validation loss: 2.287469079097112

Epoch: 5| Step: 7
Training loss: 0.4171801507472992
Validation loss: 2.2123661190271378

Epoch: 5| Step: 8
Training loss: 0.7128640413284302
Validation loss: 2.2859216580788293

Epoch: 5| Step: 9
Training loss: 0.30415740609169006
Validation loss: 2.232696001728376

Epoch: 5| Step: 10
Training loss: 0.2760331630706787
Validation loss: 2.2492184937000275

Epoch: 5| Step: 11
Training loss: 0.26347437500953674
Validation loss: 2.2349639733632407

Epoch: 324| Step: 0
Training loss: 0.28925496339797974
Validation loss: 2.269469161828359

Epoch: 5| Step: 1
Training loss: 0.6869216561317444
Validation loss: 2.3220516443252563

Epoch: 5| Step: 2
Training loss: 0.2957856357097626
Validation loss: 2.242196351289749

Epoch: 5| Step: 3
Training loss: 0.5339747667312622
Validation loss: 2.307300259669622

Epoch: 5| Step: 4
Training loss: 0.3250802159309387
Validation loss: 2.283072749773661

Epoch: 5| Step: 5
Training loss: 0.3868812918663025
Validation loss: 2.222187106808027

Epoch: 5| Step: 6
Training loss: 0.40665531158447266
Validation loss: 2.2497936884562173

Epoch: 5| Step: 7
Training loss: 0.6082295775413513
Validation loss: 2.260330706834793

Epoch: 5| Step: 8
Training loss: 0.3847273886203766
Validation loss: 2.250540643930435

Epoch: 5| Step: 9
Training loss: 0.4613771438598633
Validation loss: 2.2884255747000375

Epoch: 5| Step: 10
Training loss: 0.30754026770591736
Validation loss: 2.2305971533060074

Epoch: 5| Step: 11
Training loss: 0.17834413051605225
Validation loss: 2.30499475200971

Epoch: 325| Step: 0
Training loss: 0.5925813913345337
Validation loss: 2.2835070490837097

Epoch: 5| Step: 1
Training loss: 0.22082439064979553
Validation loss: 2.2700201918681464

Epoch: 5| Step: 2
Training loss: 0.2752600312232971
Validation loss: 2.2766323685646057

Epoch: 5| Step: 3
Training loss: 0.24986350536346436
Validation loss: 2.3015682895978293

Epoch: 5| Step: 4
Training loss: 0.3087615966796875
Validation loss: 2.2051862378915152

Epoch: 5| Step: 5
Training loss: 0.2586589455604553
Validation loss: 2.2516344437996545

Epoch: 5| Step: 6
Training loss: 0.7454598546028137
Validation loss: 2.2364945262670517

Epoch: 5| Step: 7
Training loss: 0.5735594034194946
Validation loss: 2.235042085250219

Epoch: 5| Step: 8
Training loss: 0.2952568829059601
Validation loss: 2.270909935235977

Epoch: 5| Step: 9
Training loss: 0.4838716387748718
Validation loss: 2.2206441909074783

Epoch: 5| Step: 10
Training loss: 0.3153288960456848
Validation loss: 2.2399037877718606

Epoch: 5| Step: 11
Training loss: 0.15543803572654724
Validation loss: 2.254346931974093

Epoch: 326| Step: 0
Training loss: 0.4072585105895996
Validation loss: 2.268428842226664

Epoch: 5| Step: 1
Training loss: 0.37805992364883423
Validation loss: 2.26043002307415

Epoch: 5| Step: 2
Training loss: 0.323419451713562
Validation loss: 2.280387739340464

Epoch: 5| Step: 3
Training loss: 0.20183734595775604
Validation loss: 2.2840080509583154

Epoch: 5| Step: 4
Training loss: 0.23507925868034363
Validation loss: 2.323717027902603

Epoch: 5| Step: 5
Training loss: 0.5015334486961365
Validation loss: 2.2827900846799216

Epoch: 5| Step: 6
Training loss: 0.5970853567123413
Validation loss: 2.318011373281479

Epoch: 5| Step: 7
Training loss: 0.32209160923957825
Validation loss: 2.28408815463384

Epoch: 5| Step: 8
Training loss: 0.38598236441612244
Validation loss: 2.3081214825312295

Epoch: 5| Step: 9
Training loss: 0.2601606249809265
Validation loss: 2.2814051459232965

Epoch: 5| Step: 10
Training loss: 0.5409091711044312
Validation loss: 2.2560873329639435

Epoch: 5| Step: 11
Training loss: 0.3460541367530823
Validation loss: 2.30794358253479

Epoch: 327| Step: 0
Training loss: 0.4185643196105957
Validation loss: 2.2927605410416922

Epoch: 5| Step: 1
Training loss: 0.3110906779766083
Validation loss: 2.2705183575550714

Epoch: 5| Step: 2
Training loss: 0.19987165927886963
Validation loss: 2.243182192246119

Epoch: 5| Step: 3
Training loss: 0.24875763058662415
Validation loss: 2.261765326062838

Epoch: 5| Step: 4
Training loss: 0.20063647627830505
Validation loss: 2.2168358117341995

Epoch: 5| Step: 5
Training loss: 0.8534448742866516
Validation loss: 2.273264318704605

Epoch: 5| Step: 6
Training loss: 0.23051658272743225
Validation loss: 2.236594721674919

Epoch: 5| Step: 7
Training loss: 0.496478796005249
Validation loss: 2.2509335776170096

Epoch: 5| Step: 8
Training loss: 0.37625232338905334
Validation loss: 2.316071018576622

Epoch: 5| Step: 9
Training loss: 0.6562531590461731
Validation loss: 2.226043631633123

Epoch: 5| Step: 10
Training loss: 0.32125043869018555
Validation loss: 2.2762243449687958

Epoch: 5| Step: 11
Training loss: 0.5439521074295044
Validation loss: 2.287690689166387

Epoch: 328| Step: 0
Training loss: 0.1719028651714325
Validation loss: 2.2637860576311746

Epoch: 5| Step: 1
Training loss: 0.5392581820487976
Validation loss: 2.2643744548161826

Epoch: 5| Step: 2
Training loss: 0.22924017906188965
Validation loss: 2.287155012289683

Epoch: 5| Step: 3
Training loss: 0.433338463306427
Validation loss: 2.2975124567747116

Epoch: 5| Step: 4
Training loss: 0.28775614500045776
Validation loss: 2.268756474057833

Epoch: 5| Step: 5
Training loss: 0.3182137906551361
Validation loss: 2.30341300368309

Epoch: 5| Step: 6
Training loss: 0.21511287987232208
Validation loss: 2.2941101690133414

Epoch: 5| Step: 7
Training loss: 0.6989098787307739
Validation loss: 2.3100564628839493

Epoch: 5| Step: 8
Training loss: 0.5271767377853394
Validation loss: 2.3257348040739694

Epoch: 5| Step: 9
Training loss: 0.3136230409145355
Validation loss: 2.332918201883634

Epoch: 5| Step: 10
Training loss: 0.7283059358596802
Validation loss: 2.2976926118135452

Epoch: 5| Step: 11
Training loss: 0.32795053720474243
Validation loss: 2.2713939547538757

Epoch: 329| Step: 0
Training loss: 0.2721075415611267
Validation loss: 2.270026614268621

Epoch: 5| Step: 1
Training loss: 0.38994234800338745
Validation loss: 2.2993875642617545

Epoch: 5| Step: 2
Training loss: 0.43817853927612305
Validation loss: 2.2818022121985755

Epoch: 5| Step: 3
Training loss: 0.2824777066707611
Validation loss: 2.3030796945095062

Epoch: 5| Step: 4
Training loss: 0.6387006640434265
Validation loss: 2.33089479804039

Epoch: 5| Step: 5
Training loss: 0.6984513401985168
Validation loss: 2.296040048201879

Epoch: 5| Step: 6
Training loss: 0.5161591172218323
Validation loss: 2.253233775496483

Epoch: 5| Step: 7
Training loss: 0.3646140694618225
Validation loss: 2.3262943029403687

Epoch: 5| Step: 8
Training loss: 0.25260987877845764
Validation loss: 2.280928115049998

Epoch: 5| Step: 9
Training loss: 0.232059046626091
Validation loss: 2.2843563159306846

Epoch: 5| Step: 10
Training loss: 0.274599552154541
Validation loss: 2.269336089491844

Epoch: 5| Step: 11
Training loss: 0.19943726062774658
Validation loss: 2.2696613868077598

Epoch: 330| Step: 0
Training loss: 0.35674184560775757
Validation loss: 2.199380243817965

Epoch: 5| Step: 1
Training loss: 0.48820486664772034
Validation loss: 2.268521969517072

Epoch: 5| Step: 2
Training loss: 0.4946432113647461
Validation loss: 2.2329525450865426

Epoch: 5| Step: 3
Training loss: 0.30775943398475647
Validation loss: 2.23387477795283

Epoch: 5| Step: 4
Training loss: 0.29034510254859924
Validation loss: 2.2187301317850747

Epoch: 5| Step: 5
Training loss: 0.2589636743068695
Validation loss: 2.253094583749771

Epoch: 5| Step: 6
Training loss: 0.8440566062927246
Validation loss: 2.2284359137217202

Epoch: 5| Step: 7
Training loss: 0.37328481674194336
Validation loss: 2.2051414946715036

Epoch: 5| Step: 8
Training loss: 0.37323832511901855
Validation loss: 2.2047393868366876

Epoch: 5| Step: 9
Training loss: 0.22824616730213165
Validation loss: 2.2189101179440818

Epoch: 5| Step: 10
Training loss: 0.26590755581855774
Validation loss: 2.250357379515966

Epoch: 5| Step: 11
Training loss: 0.4756524860858917
Validation loss: 2.2040855338176093

Epoch: 331| Step: 0
Training loss: 0.3067512810230255
Validation loss: 2.2158494740724564

Epoch: 5| Step: 1
Training loss: 0.21857500076293945
Validation loss: 2.2536413272221885

Epoch: 5| Step: 2
Training loss: 0.6277753114700317
Validation loss: 2.2627243101596832

Epoch: 5| Step: 3
Training loss: 0.560189962387085
Validation loss: 2.2552419702212014

Epoch: 5| Step: 4
Training loss: 0.42275270819664
Validation loss: 2.2233585317929587

Epoch: 5| Step: 5
Training loss: 0.3210398256778717
Validation loss: 2.241832986474037

Epoch: 5| Step: 6
Training loss: 0.2991925776004791
Validation loss: 2.275847241282463

Epoch: 5| Step: 7
Training loss: 0.653509259223938
Validation loss: 2.3166849116484323

Epoch: 5| Step: 8
Training loss: 0.44964703917503357
Validation loss: 2.2635090400775275

Epoch: 5| Step: 9
Training loss: 0.2884102761745453
Validation loss: 2.354350298643112

Epoch: 5| Step: 10
Training loss: 0.3313570022583008
Validation loss: 2.3001674115657806

Epoch: 5| Step: 11
Training loss: 0.7123459577560425
Validation loss: 2.3180574625730515

Epoch: 332| Step: 0
Training loss: 0.3569275438785553
Validation loss: 2.299888014793396

Epoch: 5| Step: 1
Training loss: 0.4223196506500244
Validation loss: 2.29887031018734

Epoch: 5| Step: 2
Training loss: 0.3635734021663666
Validation loss: 2.2514715492725372

Epoch: 5| Step: 3
Training loss: 0.32510629296302795
Validation loss: 2.236350099245707

Epoch: 5| Step: 4
Training loss: 0.5091512799263
Validation loss: 2.296086291472117

Epoch: 5| Step: 5
Training loss: 0.544599175453186
Validation loss: 2.2118116120497384

Epoch: 5| Step: 6
Training loss: 0.5979000329971313
Validation loss: 2.25667675336202

Epoch: 5| Step: 7
Training loss: 0.4507365822792053
Validation loss: 2.3279610872268677

Epoch: 5| Step: 8
Training loss: 0.35061126947402954
Validation loss: 2.3309347927570343

Epoch: 5| Step: 9
Training loss: 0.3900455832481384
Validation loss: 2.3194350004196167

Epoch: 5| Step: 10
Training loss: 0.5010027885437012
Validation loss: 2.284171293179194

Epoch: 5| Step: 11
Training loss: 0.20312488079071045
Validation loss: 2.335703338185946

Epoch: 333| Step: 0
Training loss: 0.5234562158584595
Validation loss: 2.246523608764013

Epoch: 5| Step: 1
Training loss: 0.256045401096344
Validation loss: 2.2644489109516144

Epoch: 5| Step: 2
Training loss: 0.3772509694099426
Validation loss: 2.2474799752235413

Epoch: 5| Step: 3
Training loss: 0.9212902784347534
Validation loss: 2.1990182052055993

Epoch: 5| Step: 4
Training loss: 0.3011423647403717
Validation loss: 2.2420942982037864

Epoch: 5| Step: 5
Training loss: 0.33101555705070496
Validation loss: 2.1985772252082825

Epoch: 5| Step: 6
Training loss: 0.33599644899368286
Validation loss: 2.2505225936571756

Epoch: 5| Step: 7
Training loss: 0.23510682582855225
Validation loss: 2.2732664942741394

Epoch: 5| Step: 8
Training loss: 0.4692050814628601
Validation loss: 2.249519467353821

Epoch: 5| Step: 9
Training loss: 0.46443289518356323
Validation loss: 2.1963606774806976

Epoch: 5| Step: 10
Training loss: 0.5304401516914368
Validation loss: 2.263492817680041

Epoch: 5| Step: 11
Training loss: 0.317619651556015
Validation loss: 2.2802787770827613

Epoch: 334| Step: 0
Training loss: 0.6304467916488647
Validation loss: 2.2362440129121146

Epoch: 5| Step: 1
Training loss: 0.520785927772522
Validation loss: 2.1902098059654236

Epoch: 5| Step: 2
Training loss: 0.6185668706893921
Validation loss: 2.202453777194023

Epoch: 5| Step: 3
Training loss: 0.48949185013771057
Validation loss: 2.1996496816476188

Epoch: 5| Step: 4
Training loss: 0.3267957270145416
Validation loss: 2.2159170111020408

Epoch: 5| Step: 5
Training loss: 0.2811340391635895
Validation loss: 2.248588045438131

Epoch: 5| Step: 6
Training loss: 0.28454214334487915
Validation loss: 2.292603994409243

Epoch: 5| Step: 7
Training loss: 0.714168131351471
Validation loss: 2.281697074572245

Epoch: 5| Step: 8
Training loss: 0.5124581456184387
Validation loss: 2.283047085007032

Epoch: 5| Step: 9
Training loss: 0.37182196974754333
Validation loss: 2.283128470182419

Epoch: 5| Step: 10
Training loss: 0.26955288648605347
Validation loss: 2.3004968762397766

Epoch: 5| Step: 11
Training loss: 0.28453314304351807
Validation loss: 2.28476815422376

Epoch: 335| Step: 0
Training loss: 0.5010074973106384
Validation loss: 2.2514004160960517

Epoch: 5| Step: 1
Training loss: 0.6397889256477356
Validation loss: 2.2278929948806763

Epoch: 5| Step: 2
Training loss: 0.40599745512008667
Validation loss: 2.2512501627206802

Epoch: 5| Step: 3
Training loss: 0.5162642598152161
Validation loss: 2.2268594106038413

Epoch: 5| Step: 4
Training loss: 0.328471839427948
Validation loss: 2.2464680274327598

Epoch: 5| Step: 5
Training loss: 0.4483144283294678
Validation loss: 2.321310520172119

Epoch: 5| Step: 6
Training loss: 0.5869508981704712
Validation loss: 2.3114232271909714

Epoch: 5| Step: 7
Training loss: 0.5758091807365417
Validation loss: 2.38933797677358

Epoch: 5| Step: 8
Training loss: 0.3301948606967926
Validation loss: 2.3216876834630966

Epoch: 5| Step: 9
Training loss: 0.26730066537857056
Validation loss: 2.3119864811499915

Epoch: 5| Step: 10
Training loss: 0.3036682605743408
Validation loss: 2.2547486424446106

Epoch: 5| Step: 11
Training loss: 0.5888939499855042
Validation loss: 2.2556420415639877

Epoch: 336| Step: 0
Training loss: 0.2554872930049896
Validation loss: 2.230958009759585

Epoch: 5| Step: 1
Training loss: 0.31906041502952576
Validation loss: 2.2812926967938743

Epoch: 5| Step: 2
Training loss: 0.4533255994319916
Validation loss: 2.2356104205052056

Epoch: 5| Step: 3
Training loss: 0.3844246566295624
Validation loss: 2.24907478193442

Epoch: 5| Step: 4
Training loss: 0.3499686121940613
Validation loss: 2.2683177391688027

Epoch: 5| Step: 5
Training loss: 0.6976287961006165
Validation loss: 2.27266688644886

Epoch: 5| Step: 6
Training loss: 0.3206615447998047
Validation loss: 2.3207459648450217

Epoch: 5| Step: 7
Training loss: 0.4241037964820862
Validation loss: 2.2663883368174234

Epoch: 5| Step: 8
Training loss: 0.4471455514431
Validation loss: 2.2309108773867288

Epoch: 5| Step: 9
Training loss: 0.47696152329444885
Validation loss: 2.2397249241669974

Epoch: 5| Step: 10
Training loss: 0.2377985715866089
Validation loss: 2.2114208539326987

Epoch: 5| Step: 11
Training loss: 0.2595924735069275
Validation loss: 2.2751787255207696

Epoch: 337| Step: 0
Training loss: 0.2100430428981781
Validation loss: 2.232476611932119

Epoch: 5| Step: 1
Training loss: 0.5291454792022705
Validation loss: 2.255800952514013

Epoch: 5| Step: 2
Training loss: 0.30483704805374146
Validation loss: 2.2458433906237283

Epoch: 5| Step: 3
Training loss: 0.4775305688381195
Validation loss: 2.228796044985453

Epoch: 5| Step: 4
Training loss: 0.2611546516418457
Validation loss: 2.2387896130482354

Epoch: 5| Step: 5
Training loss: 0.20458917319774628
Validation loss: 2.2028439193964005

Epoch: 5| Step: 6
Training loss: 0.403474897146225
Validation loss: 2.245976597070694

Epoch: 5| Step: 7
Training loss: 0.22832973301410675
Validation loss: 2.1927886505921683

Epoch: 5| Step: 8
Training loss: 0.3940606713294983
Validation loss: 2.2630862345298133

Epoch: 5| Step: 9
Training loss: 0.24745087325572968
Validation loss: 2.2589691430330276

Epoch: 5| Step: 10
Training loss: 0.2847119867801666
Validation loss: 2.2492439846197763

Epoch: 5| Step: 11
Training loss: 2.440256118774414
Validation loss: 2.279845337073008

Epoch: 338| Step: 0
Training loss: 0.4350448548793793
Validation loss: 2.2575056751569114

Epoch: 5| Step: 1
Training loss: 0.2683146893978119
Validation loss: 2.2791772733132043

Epoch: 5| Step: 2
Training loss: 0.3474832773208618
Validation loss: 2.2722664376099906

Epoch: 5| Step: 3
Training loss: 0.38961759209632874
Validation loss: 2.2596515317757926

Epoch: 5| Step: 4
Training loss: 0.2735966145992279
Validation loss: 2.2450419068336487

Epoch: 5| Step: 5
Training loss: 0.3558043837547302
Validation loss: 2.2854102651278176

Epoch: 5| Step: 6
Training loss: 0.5921870470046997
Validation loss: 2.2451063096523285

Epoch: 5| Step: 7
Training loss: 0.3370431363582611
Validation loss: 2.2261295119921365

Epoch: 5| Step: 8
Training loss: 0.27550429105758667
Validation loss: 2.284310003121694

Epoch: 5| Step: 9
Training loss: 0.48132163286209106
Validation loss: 2.270222693681717

Epoch: 5| Step: 10
Training loss: 0.7346939444541931
Validation loss: 2.329432482520739

Epoch: 5| Step: 11
Training loss: 0.2530555725097656
Validation loss: 2.353749563296636

Epoch: 339| Step: 0
Training loss: 0.41443443298339844
Validation loss: 2.3082740555206933

Epoch: 5| Step: 1
Training loss: 0.2769138813018799
Validation loss: 2.281547407309214

Epoch: 5| Step: 2
Training loss: 0.43923965096473694
Validation loss: 2.285750781496366

Epoch: 5| Step: 3
Training loss: 0.25960177183151245
Validation loss: 2.2002044866482415

Epoch: 5| Step: 4
Training loss: 0.5028846859931946
Validation loss: 2.2514432271321616

Epoch: 5| Step: 5
Training loss: 0.5956622362136841
Validation loss: 2.2928825269142785

Epoch: 5| Step: 6
Training loss: 0.2625565528869629
Validation loss: 2.25151435037454

Epoch: 5| Step: 7
Training loss: 0.310813844203949
Validation loss: 2.3294847110907235

Epoch: 5| Step: 8
Training loss: 0.3326186537742615
Validation loss: 2.2657129814227424

Epoch: 5| Step: 9
Training loss: 0.4630887508392334
Validation loss: 2.3531875163316727

Epoch: 5| Step: 10
Training loss: 0.310234010219574
Validation loss: 2.323852260907491

Epoch: 5| Step: 11
Training loss: 0.2373628169298172
Validation loss: 2.2587961554527283

Epoch: 340| Step: 0
Training loss: 0.6881102323532104
Validation loss: 2.262473940849304

Epoch: 5| Step: 1
Training loss: 0.4047113358974457
Validation loss: 2.238772680362066

Epoch: 5| Step: 2
Training loss: 0.2249734103679657
Validation loss: 2.239902228116989

Epoch: 5| Step: 3
Training loss: 0.2904641628265381
Validation loss: 2.2960600604613624

Epoch: 5| Step: 4
Training loss: 0.35155051946640015
Validation loss: 2.273813625176748

Epoch: 5| Step: 5
Training loss: 0.2910333275794983
Validation loss: 2.2758437345425286

Epoch: 5| Step: 6
Training loss: 0.2877426743507385
Validation loss: 2.2402730733156204

Epoch: 5| Step: 7
Training loss: 0.3605404794216156
Validation loss: 2.2602318624655404

Epoch: 5| Step: 8
Training loss: 0.3248479664325714
Validation loss: 2.238740106423696

Epoch: 5| Step: 9
Training loss: 0.7205837965011597
Validation loss: 2.268972635269165

Epoch: 5| Step: 10
Training loss: 0.2632680833339691
Validation loss: 2.2611837834119797

Epoch: 5| Step: 11
Training loss: 0.1987491250038147
Validation loss: 2.1871811052163443

Epoch: 341| Step: 0
Training loss: 0.2910154461860657
Validation loss: 2.2066136598587036

Epoch: 5| Step: 1
Training loss: 0.5277802348136902
Validation loss: 2.2364162504673004

Epoch: 5| Step: 2
Training loss: 0.21532464027404785
Validation loss: 2.218205804626147

Epoch: 5| Step: 3
Training loss: 0.2083824872970581
Validation loss: 2.2446261197328568

Epoch: 5| Step: 4
Training loss: 0.3253687918186188
Validation loss: 2.2685470233360925

Epoch: 5| Step: 5
Training loss: 0.6204537749290466
Validation loss: 2.2623767654101052

Epoch: 5| Step: 6
Training loss: 0.41914016008377075
Validation loss: 2.317352960507075

Epoch: 5| Step: 7
Training loss: 0.43333712220191956
Validation loss: 2.334613412618637

Epoch: 5| Step: 8
Training loss: 0.29502853751182556
Validation loss: 2.2878536581993103

Epoch: 5| Step: 9
Training loss: 0.41269588470458984
Validation loss: 2.301409423351288

Epoch: 5| Step: 10
Training loss: 0.3456692695617676
Validation loss: 2.2291452785333

Epoch: 5| Step: 11
Training loss: 1.2027761936187744
Validation loss: 2.299786110719045

Epoch: 342| Step: 0
Training loss: 0.42303380370140076
Validation loss: 2.306846578915914

Epoch: 5| Step: 1
Training loss: 0.27998146414756775
Validation loss: 2.321843385696411

Epoch: 5| Step: 2
Training loss: 0.38981708884239197
Validation loss: 2.2881468335787454

Epoch: 5| Step: 3
Training loss: 0.5513953566551208
Validation loss: 2.3347038527329764

Epoch: 5| Step: 4
Training loss: 0.2912381887435913
Validation loss: 2.266877909501394

Epoch: 5| Step: 5
Training loss: 0.2699320912361145
Validation loss: 2.2837583124637604

Epoch: 5| Step: 6
Training loss: 0.571721613407135
Validation loss: 2.282518411676089

Epoch: 5| Step: 7
Training loss: 0.3004165589809418
Validation loss: 2.278699810306231

Epoch: 5| Step: 8
Training loss: 0.30212968587875366
Validation loss: 2.32364813486735

Epoch: 5| Step: 9
Training loss: 0.288300096988678
Validation loss: 2.329340641697248

Epoch: 5| Step: 10
Training loss: 0.6292928457260132
Validation loss: 2.2801901598771415

Epoch: 5| Step: 11
Training loss: 0.34842991828918457
Validation loss: 2.3168728947639465

Epoch: 343| Step: 0
Training loss: 0.5416768789291382
Validation loss: 2.314886192480723

Epoch: 5| Step: 1
Training loss: 0.38154691457748413
Validation loss: 2.256879230340322

Epoch: 5| Step: 2
Training loss: 0.4065542221069336
Validation loss: 2.224209815263748

Epoch: 5| Step: 3
Training loss: 0.2564115822315216
Validation loss: 2.2632964054743447

Epoch: 5| Step: 4
Training loss: 0.47991833090782166
Validation loss: 2.28106556336085

Epoch: 5| Step: 5
Training loss: 0.2771858274936676
Validation loss: 2.2586267391840615

Epoch: 5| Step: 6
Training loss: 0.20642726123332977
Validation loss: 2.2865863343079886

Epoch: 5| Step: 7
Training loss: 0.4676890969276428
Validation loss: 2.31853020687898

Epoch: 5| Step: 8
Training loss: 0.35126808285713196
Validation loss: 2.339203953742981

Epoch: 5| Step: 9
Training loss: 0.7276955842971802
Validation loss: 2.289862106243769

Epoch: 5| Step: 10
Training loss: 0.3808159828186035
Validation loss: 2.2732923279205957

Epoch: 5| Step: 11
Training loss: 0.19736212491989136
Validation loss: 2.2687977900107703

Epoch: 344| Step: 0
Training loss: 0.3685859739780426
Validation loss: 2.255139037966728

Epoch: 5| Step: 1
Training loss: 0.20861497521400452
Validation loss: 2.237755080064138

Epoch: 5| Step: 2
Training loss: 0.5563507676124573
Validation loss: 2.2460603415966034

Epoch: 5| Step: 3
Training loss: 0.8419693112373352
Validation loss: 2.231448476513227

Epoch: 5| Step: 4
Training loss: 0.40829071402549744
Validation loss: 2.206028620402018

Epoch: 5| Step: 5
Training loss: 0.5146339535713196
Validation loss: 2.2582614024480185

Epoch: 5| Step: 6
Training loss: 0.42927879095077515
Validation loss: 2.3115515212217965

Epoch: 5| Step: 7
Training loss: 0.3991711139678955
Validation loss: 2.3137558499972024

Epoch: 5| Step: 8
Training loss: 0.2732764780521393
Validation loss: 2.3004044592380524

Epoch: 5| Step: 9
Training loss: 0.2768454849720001
Validation loss: 2.2460237642129264

Epoch: 5| Step: 10
Training loss: 0.18451710045337677
Validation loss: 2.262146070599556

Epoch: 5| Step: 11
Training loss: 0.1556103229522705
Validation loss: 2.2031912306944528

Epoch: 345| Step: 0
Training loss: 0.20958980917930603
Validation loss: 2.266501466433207

Epoch: 5| Step: 1
Training loss: 0.2834938168525696
Validation loss: 2.2550582935412726

Epoch: 5| Step: 2
Training loss: 0.3291786015033722
Validation loss: 2.3154046336809793

Epoch: 5| Step: 3
Training loss: 0.35584309697151184
Validation loss: 2.2621958007415137

Epoch: 5| Step: 4
Training loss: 0.21949942409992218
Validation loss: 2.246020962794622

Epoch: 5| Step: 5
Training loss: 0.4975809156894684
Validation loss: 2.266291449467341

Epoch: 5| Step: 6
Training loss: 0.4371677339076996
Validation loss: 2.2784423579772315

Epoch: 5| Step: 7
Training loss: 0.4184134602546692
Validation loss: 2.286959787209829

Epoch: 5| Step: 8
Training loss: 0.401130735874176
Validation loss: 2.295515795548757

Epoch: 5| Step: 9
Training loss: 0.7544189691543579
Validation loss: 2.2821088333924613

Epoch: 5| Step: 10
Training loss: 0.5522756576538086
Validation loss: 2.30133048693339

Epoch: 5| Step: 11
Training loss: 0.37998417019844055
Validation loss: 2.3209664622942605

Epoch: 346| Step: 0
Training loss: 0.6511731147766113
Validation loss: 2.2534457246462503

Epoch: 5| Step: 1
Training loss: 0.36740806698799133
Validation loss: 2.287294844786326

Epoch: 5| Step: 2
Training loss: 0.32733088731765747
Validation loss: 2.21925288438797

Epoch: 5| Step: 3
Training loss: 0.49784785509109497
Validation loss: 2.2542562782764435

Epoch: 5| Step: 4
Training loss: 0.3129681944847107
Validation loss: 2.270113537708918

Epoch: 5| Step: 5
Training loss: 0.23234395682811737
Validation loss: 2.329266905784607

Epoch: 5| Step: 6
Training loss: 0.20833826065063477
Validation loss: 2.299625794092814

Epoch: 5| Step: 7
Training loss: 0.2495633065700531
Validation loss: 2.2590766797463098

Epoch: 5| Step: 8
Training loss: 0.3436339497566223
Validation loss: 2.28840105732282

Epoch: 5| Step: 9
Training loss: 0.606429934501648
Validation loss: 2.3575797577699027

Epoch: 5| Step: 10
Training loss: 0.25580403208732605
Validation loss: 2.2535061041514077

Epoch: 5| Step: 11
Training loss: 0.31830114126205444
Validation loss: 2.3154328564802804

Epoch: 347| Step: 0
Training loss: 0.2884153425693512
Validation loss: 2.300456648071607

Epoch: 5| Step: 1
Training loss: 0.5250247120857239
Validation loss: 2.2859355409940085

Epoch: 5| Step: 2
Training loss: 0.3573484718799591
Validation loss: 2.259444087743759

Epoch: 5| Step: 3
Training loss: 0.4446779787540436
Validation loss: 2.266668677330017

Epoch: 5| Step: 4
Training loss: 0.4921647906303406
Validation loss: 2.3124462962150574

Epoch: 5| Step: 5
Training loss: 0.37445297837257385
Validation loss: 2.3204278548558555

Epoch: 5| Step: 6
Training loss: 0.30373841524124146
Validation loss: 2.3197006036837897

Epoch: 5| Step: 7
Training loss: 0.31214389204978943
Validation loss: 2.322387511531512

Epoch: 5| Step: 8
Training loss: 0.41665396094322205
Validation loss: 2.329552580912908

Epoch: 5| Step: 9
Training loss: 0.35246169567108154
Validation loss: 2.3238694171110788

Epoch: 5| Step: 10
Training loss: 0.6234265565872192
Validation loss: 2.319735417763392

Epoch: 5| Step: 11
Training loss: 0.3989151418209076
Validation loss: 2.3004122277100882

Epoch: 348| Step: 0
Training loss: 0.3619959056377411
Validation loss: 2.278996010621389

Epoch: 5| Step: 1
Training loss: 0.255425363779068
Validation loss: 2.273323426644007

Epoch: 5| Step: 2
Training loss: 0.2815512716770172
Validation loss: 2.2281521757443747

Epoch: 5| Step: 3
Training loss: 0.3219528794288635
Validation loss: 2.2821042438348136

Epoch: 5| Step: 4
Training loss: 0.25576767325401306
Validation loss: 2.268867721160253

Epoch: 5| Step: 5
Training loss: 0.4119759500026703
Validation loss: 2.3231589694817862

Epoch: 5| Step: 6
Training loss: 0.7355579137802124
Validation loss: 2.3007968813180923

Epoch: 5| Step: 7
Training loss: 0.4837356507778168
Validation loss: 2.2850287556648254

Epoch: 5| Step: 8
Training loss: 0.18692129850387573
Validation loss: 2.306156853834788

Epoch: 5| Step: 9
Training loss: 0.4266245365142822
Validation loss: 2.297964553038279

Epoch: 5| Step: 10
Training loss: 0.2733619213104248
Validation loss: 2.2480684220790863

Epoch: 5| Step: 11
Training loss: 0.20903047919273376
Validation loss: 2.2247701783974967

Epoch: 349| Step: 0
Training loss: 0.5252412557601929
Validation loss: 2.2456556856632233

Epoch: 5| Step: 1
Training loss: 0.30745500326156616
Validation loss: 2.2894672652085624

Epoch: 5| Step: 2
Training loss: 0.4029603898525238
Validation loss: 2.2455233136812844

Epoch: 5| Step: 3
Training loss: 0.3294796347618103
Validation loss: 2.276379426320394

Epoch: 5| Step: 4
Training loss: 0.4083912968635559
Validation loss: 2.2830907305081687

Epoch: 5| Step: 5
Training loss: 0.22016778588294983
Validation loss: 2.234748621781667

Epoch: 5| Step: 6
Training loss: 0.19065748155117035
Validation loss: 2.2500311533610025

Epoch: 5| Step: 7
Training loss: 0.6790949702262878
Validation loss: 2.252364546060562

Epoch: 5| Step: 8
Training loss: 0.4127568304538727
Validation loss: 2.2595839301745095

Epoch: 5| Step: 9
Training loss: 0.16985729336738586
Validation loss: 2.2716342508792877

Epoch: 5| Step: 10
Training loss: 0.3128888010978699
Validation loss: 2.29523965716362

Epoch: 5| Step: 11
Training loss: 0.22663867473602295
Validation loss: 2.295248622695605

Epoch: 350| Step: 0
Training loss: 0.2176530361175537
Validation loss: 2.260471075773239

Epoch: 5| Step: 1
Training loss: 0.28211545944213867
Validation loss: 2.2932099401950836

Epoch: 5| Step: 2
Training loss: 0.2620331645011902
Validation loss: 2.3198316941658654

Epoch: 5| Step: 3
Training loss: 0.3458072543144226
Validation loss: 2.2681992848714194

Epoch: 5| Step: 4
Training loss: 0.2233239710330963
Validation loss: 2.290990889072418

Epoch: 5| Step: 5
Training loss: 0.2782619893550873
Validation loss: 2.293298582235972

Epoch: 5| Step: 6
Training loss: 0.253178209066391
Validation loss: 2.3015315532684326

Epoch: 5| Step: 7
Training loss: 0.7432467937469482
Validation loss: 2.3000558813412986

Epoch: 5| Step: 8
Training loss: 0.42354145646095276
Validation loss: 2.363115350405375

Epoch: 5| Step: 9
Training loss: 0.4059370160102844
Validation loss: 2.259483575820923

Epoch: 5| Step: 10
Training loss: 0.41593605279922485
Validation loss: 2.252962206800779

Epoch: 5| Step: 11
Training loss: 0.27345985174179077
Validation loss: 2.278362681468328

Epoch: 351| Step: 0
Training loss: 0.2959950566291809
Validation loss: 2.283462882041931

Epoch: 5| Step: 1
Training loss: 0.33315110206604004
Validation loss: 2.2568360467751822

Epoch: 5| Step: 2
Training loss: 0.396660715341568
Validation loss: 2.2316659539937973

Epoch: 5| Step: 3
Training loss: 0.3264678120613098
Validation loss: 2.274918566147486

Epoch: 5| Step: 4
Training loss: 0.42028895020484924
Validation loss: 2.2647717793782554

Epoch: 5| Step: 5
Training loss: 0.3630584478378296
Validation loss: 2.2633856435616813

Epoch: 5| Step: 6
Training loss: 0.2410292625427246
Validation loss: 2.2428357203801474

Epoch: 5| Step: 7
Training loss: 0.43961596488952637
Validation loss: 2.2726512253284454

Epoch: 5| Step: 8
Training loss: 0.1857323944568634
Validation loss: 2.2360172321399054

Epoch: 5| Step: 9
Training loss: 0.27629685401916504
Validation loss: 2.2551312148571014

Epoch: 5| Step: 10
Training loss: 0.7209847569465637
Validation loss: 2.2509659826755524

Epoch: 5| Step: 11
Training loss: 0.6167680025100708
Validation loss: 2.229450469215711

Epoch: 352| Step: 0
Training loss: 0.32273069024086
Validation loss: 2.259322077035904

Epoch: 5| Step: 1
Training loss: 0.3644743859767914
Validation loss: 2.2564892768859863

Epoch: 5| Step: 2
Training loss: 0.4078901708126068
Validation loss: 2.253400683403015

Epoch: 5| Step: 3
Training loss: 0.2682148814201355
Validation loss: 2.2526347587505975

Epoch: 5| Step: 4
Training loss: 0.4745458662509918
Validation loss: 2.277644713719686

Epoch: 5| Step: 5
Training loss: 0.33915743231773376
Validation loss: 2.316744382182757

Epoch: 5| Step: 6
Training loss: 0.24787597358226776
Validation loss: 2.237769285837809

Epoch: 5| Step: 7
Training loss: 0.4160047471523285
Validation loss: 2.218504394094149

Epoch: 5| Step: 8
Training loss: 0.3386020064353943
Validation loss: 2.198619619011879

Epoch: 5| Step: 9
Training loss: 0.458568274974823
Validation loss: 2.2388087809085846

Epoch: 5| Step: 10
Training loss: 0.34708723425865173
Validation loss: 2.251677672068278

Epoch: 5| Step: 11
Training loss: 2.083277940750122
Validation loss: 2.276284486055374

Epoch: 353| Step: 0
Training loss: 0.3156358599662781
Validation loss: 2.3040223171313605

Epoch: 5| Step: 1
Training loss: 0.6888700127601624
Validation loss: 2.3649898966153464

Epoch: 5| Step: 2
Training loss: 0.4508032202720642
Validation loss: 2.3948132495085397

Epoch: 5| Step: 3
Training loss: 0.9546350240707397
Validation loss: 2.353994940718015

Epoch: 5| Step: 4
Training loss: 0.4159221649169922
Validation loss: 2.2978845040003457

Epoch: 5| Step: 5
Training loss: 0.29768678545951843
Validation loss: 2.2367625584204993

Epoch: 5| Step: 6
Training loss: 0.43994688987731934
Validation loss: 2.234492927789688

Epoch: 5| Step: 7
Training loss: 0.5068893432617188
Validation loss: 2.2612856924533844

Epoch: 5| Step: 8
Training loss: 0.5572129487991333
Validation loss: 2.209731419881185

Epoch: 5| Step: 9
Training loss: 0.45371299982070923
Validation loss: 2.184301753838857

Epoch: 5| Step: 10
Training loss: 0.5092583298683167
Validation loss: 2.2509461641311646

Epoch: 5| Step: 11
Training loss: 0.3576124906539917
Validation loss: 2.2608900368213654

Epoch: 354| Step: 0
Training loss: 0.5120670199394226
Validation loss: 2.314233273267746

Epoch: 5| Step: 1
Training loss: 0.919353187084198
Validation loss: 2.3108910620212555

Epoch: 5| Step: 2
Training loss: 0.4661130905151367
Validation loss: 2.269751658042272

Epoch: 5| Step: 3
Training loss: 0.6726049184799194
Validation loss: 2.2856282244126

Epoch: 5| Step: 4
Training loss: 0.41974878311157227
Validation loss: 2.243119016289711

Epoch: 5| Step: 5
Training loss: 0.2388472855091095
Validation loss: 2.2258914361397424

Epoch: 5| Step: 6
Training loss: 0.29540571570396423
Validation loss: 2.206398199001948

Epoch: 5| Step: 7
Training loss: 0.28283947706222534
Validation loss: 2.2313865423202515

Epoch: 5| Step: 8
Training loss: 0.2451775074005127
Validation loss: 2.2276408125956855

Epoch: 5| Step: 9
Training loss: 0.3055238723754883
Validation loss: 2.1972831885019937

Epoch: 5| Step: 10
Training loss: 0.2275633066892624
Validation loss: 2.2680469850699105

Epoch: 5| Step: 11
Training loss: 0.12501507997512817
Validation loss: 2.2432273427645364

Epoch: 355| Step: 0
Training loss: 0.4568300247192383
Validation loss: 2.3037411918242774

Epoch: 5| Step: 1
Training loss: 0.21050360798835754
Validation loss: 2.2855869034926095

Epoch: 5| Step: 2
Training loss: 0.43787845969200134
Validation loss: 2.3099443862835565

Epoch: 5| Step: 3
Training loss: 0.5771983861923218
Validation loss: 2.2855299512545266

Epoch: 5| Step: 4
Training loss: 0.23024415969848633
Validation loss: 2.2421394288539886

Epoch: 5| Step: 5
Training loss: 0.36528247594833374
Validation loss: 2.225800077120463

Epoch: 5| Step: 6
Training loss: 0.5478758215904236
Validation loss: 2.267340287566185

Epoch: 5| Step: 7
Training loss: 0.21838729083538055
Validation loss: 2.260702520608902

Epoch: 5| Step: 8
Training loss: 0.3658791482448578
Validation loss: 2.2389175444841385

Epoch: 5| Step: 9
Training loss: 0.4146137833595276
Validation loss: 2.237429449955622

Epoch: 5| Step: 10
Training loss: 0.25340786576271057
Validation loss: 2.294063940644264

Epoch: 5| Step: 11
Training loss: 0.15507009625434875
Validation loss: 2.2249822914600372

Epoch: 356| Step: 0
Training loss: 0.27988868951797485
Validation loss: 2.2676688035329184

Epoch: 5| Step: 1
Training loss: 0.4083021283149719
Validation loss: 2.2604428827762604

Epoch: 5| Step: 2
Training loss: 0.7496494054794312
Validation loss: 2.2914641300837197

Epoch: 5| Step: 3
Training loss: 0.35265859961509705
Validation loss: 2.2005548775196075

Epoch: 5| Step: 4
Training loss: 0.4243372082710266
Validation loss: 2.276368568340937

Epoch: 5| Step: 5
Training loss: 0.27660512924194336
Validation loss: 2.238270953297615

Epoch: 5| Step: 6
Training loss: 0.22755417227745056
Validation loss: 2.3194159269332886

Epoch: 5| Step: 7
Training loss: 0.4834180772304535
Validation loss: 2.232902576526006

Epoch: 5| Step: 8
Training loss: 0.32563185691833496
Validation loss: 2.2729472567637763

Epoch: 5| Step: 9
Training loss: 0.30017194151878357
Validation loss: 2.2183804512023926

Epoch: 5| Step: 10
Training loss: 0.3131045401096344
Validation loss: 2.253679245710373

Epoch: 5| Step: 11
Training loss: 0.3406223654747009
Validation loss: 2.319453169902166

Epoch: 357| Step: 0
Training loss: 0.2703326642513275
Validation loss: 2.2265494416157403

Epoch: 5| Step: 1
Training loss: 0.36931705474853516
Validation loss: 2.279598653316498

Epoch: 5| Step: 2
Training loss: 0.5974903702735901
Validation loss: 2.2652390897274017

Epoch: 5| Step: 3
Training loss: 0.3246987760066986
Validation loss: 2.3486352960268655

Epoch: 5| Step: 4
Training loss: 0.5704579949378967
Validation loss: 2.255275492866834

Epoch: 5| Step: 5
Training loss: 0.619279682636261
Validation loss: 2.289969185988108

Epoch: 5| Step: 6
Training loss: 0.30544513463974
Validation loss: 2.255954921245575

Epoch: 5| Step: 7
Training loss: 0.3015882074832916
Validation loss: 2.264878978331884

Epoch: 5| Step: 8
Training loss: 0.3225611448287964
Validation loss: 2.30047315855821

Epoch: 5| Step: 9
Training loss: 0.3176134526729584
Validation loss: 2.27293395002683

Epoch: 5| Step: 10
Training loss: 0.4286758303642273
Validation loss: 2.2903357644875846

Epoch: 5| Step: 11
Training loss: 0.3685004711151123
Validation loss: 2.1849823345740638

Epoch: 358| Step: 0
Training loss: 0.22221994400024414
Validation loss: 2.232696682214737

Epoch: 5| Step: 1
Training loss: 0.30179503560066223
Validation loss: 2.2591575235128403

Epoch: 5| Step: 2
Training loss: 0.6258090734481812
Validation loss: 2.2777690241734185

Epoch: 5| Step: 3
Training loss: 0.234166219830513
Validation loss: 2.2985602964957557

Epoch: 5| Step: 4
Training loss: 0.3309139609336853
Validation loss: 2.2652816275755563

Epoch: 5| Step: 5
Training loss: 0.3106635808944702
Validation loss: 2.2309749821821847

Epoch: 5| Step: 6
Training loss: 0.2663514018058777
Validation loss: 2.3017500092585883

Epoch: 5| Step: 7
Training loss: 0.37669119238853455
Validation loss: 2.211858332157135

Epoch: 5| Step: 8
Training loss: 0.21237266063690186
Validation loss: 2.2543027698993683

Epoch: 5| Step: 9
Training loss: 0.49110302329063416
Validation loss: 2.2380754550298056

Epoch: 5| Step: 10
Training loss: 0.5859909057617188
Validation loss: 2.278194551666578

Epoch: 5| Step: 11
Training loss: 0.226096510887146
Validation loss: 2.289979875087738

Epoch: 359| Step: 0
Training loss: 0.44287651777267456
Validation loss: 2.2822366853555045

Epoch: 5| Step: 1
Training loss: 0.3484581410884857
Validation loss: 2.294286221265793

Epoch: 5| Step: 2
Training loss: 0.5014163851737976
Validation loss: 2.314816176891327

Epoch: 5| Step: 3
Training loss: 0.6372929811477661
Validation loss: 2.2898732920487723

Epoch: 5| Step: 4
Training loss: 0.37745028734207153
Validation loss: 2.2779175639152527

Epoch: 5| Step: 5
Training loss: 0.4413389265537262
Validation loss: 2.250103712081909

Epoch: 5| Step: 6
Training loss: 0.31018877029418945
Validation loss: 2.2160372187693915

Epoch: 5| Step: 7
Training loss: 0.3661991059780121
Validation loss: 2.2723608911037445

Epoch: 5| Step: 8
Training loss: 0.1875426024198532
Validation loss: 2.268467823664347

Epoch: 5| Step: 9
Training loss: 0.23080043494701385
Validation loss: 2.3250568211078644

Epoch: 5| Step: 10
Training loss: 0.2679113447666168
Validation loss: 2.2872782051563263

Epoch: 5| Step: 11
Training loss: 0.796475350856781
Validation loss: 2.3571115831534066

Epoch: 360| Step: 0
Training loss: 0.3600185513496399
Validation loss: 2.3185171484947205

Epoch: 5| Step: 1
Training loss: 0.27213746309280396
Validation loss: 2.25616463025411

Epoch: 5| Step: 2
Training loss: 0.28077828884124756
Validation loss: 2.230939264098803

Epoch: 5| Step: 3
Training loss: 0.4560241103172302
Validation loss: 2.301145702600479

Epoch: 5| Step: 4
Training loss: 0.5567943453788757
Validation loss: 2.2864417135715485

Epoch: 5| Step: 5
Training loss: 0.4474733769893646
Validation loss: 2.25155338148276

Epoch: 5| Step: 6
Training loss: 0.30342045426368713
Validation loss: 2.2293886045614877

Epoch: 5| Step: 7
Training loss: 0.31390079855918884
Validation loss: 2.25653512775898

Epoch: 5| Step: 8
Training loss: 0.34647336602211
Validation loss: 2.2438039829333625

Epoch: 5| Step: 9
Training loss: 0.7112144231796265
Validation loss: 2.2393281807502112

Epoch: 5| Step: 10
Training loss: 0.32168078422546387
Validation loss: 2.295071631669998

Epoch: 5| Step: 11
Training loss: 0.3236386775970459
Validation loss: 2.272160624464353

Epoch: 361| Step: 0
Training loss: 0.2799991965293884
Validation loss: 2.2672505478064218

Epoch: 5| Step: 1
Training loss: 0.49044060707092285
Validation loss: 2.2737273275852203

Epoch: 5| Step: 2
Training loss: 0.3313957154750824
Validation loss: 2.3042115916808448

Epoch: 5| Step: 3
Training loss: 0.17724570631980896
Validation loss: 2.2793701738119125

Epoch: 5| Step: 4
Training loss: 0.19856499135494232
Validation loss: 2.292405148347219

Epoch: 5| Step: 5
Training loss: 0.2357577085494995
Validation loss: 2.2675276497999826

Epoch: 5| Step: 6
Training loss: 0.5234988331794739
Validation loss: 2.2724693516890206

Epoch: 5| Step: 7
Training loss: 0.443439781665802
Validation loss: 2.340746651093165

Epoch: 5| Step: 8
Training loss: 0.6783052682876587
Validation loss: 2.3061140974362693

Epoch: 5| Step: 9
Training loss: 0.3567790389060974
Validation loss: 2.2541956702868142

Epoch: 5| Step: 10
Training loss: 0.4890156388282776
Validation loss: 2.2368401885032654

Epoch: 5| Step: 11
Training loss: 0.20006966590881348
Validation loss: 2.2629291812578836

Epoch: 362| Step: 0
Training loss: 0.5018206834793091
Validation loss: 2.201093335946401

Epoch: 5| Step: 1
Training loss: 0.41175633668899536
Validation loss: 2.213811084628105

Epoch: 5| Step: 2
Training loss: 0.4117102026939392
Validation loss: 2.2586481670538583

Epoch: 5| Step: 3
Training loss: 0.5739057064056396
Validation loss: 2.3056156088908515

Epoch: 5| Step: 4
Training loss: 0.36121436953544617
Validation loss: 2.281017392873764

Epoch: 5| Step: 5
Training loss: 0.2965211868286133
Validation loss: 2.222105552752813

Epoch: 5| Step: 6
Training loss: 0.2681483328342438
Validation loss: 2.2282391438881555

Epoch: 5| Step: 7
Training loss: 0.4962826669216156
Validation loss: 2.243298292160034

Epoch: 5| Step: 8
Training loss: 0.3135708272457123
Validation loss: 2.1985867669185004

Epoch: 5| Step: 9
Training loss: 0.3215206265449524
Validation loss: 2.297357216477394

Epoch: 5| Step: 10
Training loss: 0.4168485701084137
Validation loss: 2.2341492623090744

Epoch: 5| Step: 11
Training loss: 0.2417672574520111
Validation loss: 2.2497620284557343

Epoch: 363| Step: 0
Training loss: 0.24356050789356232
Validation loss: 2.2729334433873496

Epoch: 5| Step: 1
Training loss: 0.25045666098594666
Validation loss: 2.3322046597798667

Epoch: 5| Step: 2
Training loss: 0.4216441512107849
Validation loss: 2.2587760041157403

Epoch: 5| Step: 3
Training loss: 0.26663750410079956
Validation loss: 2.294717142979304

Epoch: 5| Step: 4
Training loss: 0.3581734895706177
Validation loss: 2.234798640012741

Epoch: 5| Step: 5
Training loss: 0.7892082929611206
Validation loss: 2.259497821331024

Epoch: 5| Step: 6
Training loss: 0.40590518712997437
Validation loss: 2.2448691924413047

Epoch: 5| Step: 7
Training loss: 0.296315461397171
Validation loss: 2.217086007197698

Epoch: 5| Step: 8
Training loss: 0.21322563290596008
Validation loss: 2.2098853488763175

Epoch: 5| Step: 9
Training loss: 0.20466700196266174
Validation loss: 2.2559879422187805

Epoch: 5| Step: 10
Training loss: 0.6240493059158325
Validation loss: 2.252998302380244

Epoch: 5| Step: 11
Training loss: 0.35899436473846436
Validation loss: 2.27079384525617

Epoch: 364| Step: 0
Training loss: 0.3749317526817322
Validation loss: 2.190528611342112

Epoch: 5| Step: 1
Training loss: 0.32817918062210083
Validation loss: 2.239323382576307

Epoch: 5| Step: 2
Training loss: 0.64678555727005
Validation loss: 2.248991181453069

Epoch: 5| Step: 3
Training loss: 0.4381895959377289
Validation loss: 2.259433021148046

Epoch: 5| Step: 4
Training loss: 0.43591195344924927
Validation loss: 2.2498767524957657

Epoch: 5| Step: 5
Training loss: 0.2193300426006317
Validation loss: 2.2382762332757316

Epoch: 5| Step: 6
Training loss: 0.23475384712219238
Validation loss: 2.259195258220037

Epoch: 5| Step: 7
Training loss: 0.2345307320356369
Validation loss: 2.3246779094139733

Epoch: 5| Step: 8
Training loss: 0.3070550560951233
Validation loss: 2.266518697142601

Epoch: 5| Step: 9
Training loss: 0.519904375076294
Validation loss: 2.2785607824722924

Epoch: 5| Step: 10
Training loss: 0.2703234553337097
Validation loss: 2.300765340526899

Epoch: 5| Step: 11
Training loss: 0.1795511543750763
Validation loss: 2.231562912464142

Epoch: 365| Step: 0
Training loss: 0.3751358091831207
Validation loss: 2.209204057852427

Epoch: 5| Step: 1
Training loss: 0.3633067011833191
Validation loss: 2.251304085055987

Epoch: 5| Step: 2
Training loss: 0.2704666256904602
Validation loss: 2.2259760995705924

Epoch: 5| Step: 3
Training loss: 0.6839879751205444
Validation loss: 2.215958615144094

Epoch: 5| Step: 4
Training loss: 0.29917261004447937
Validation loss: 2.280972490708033

Epoch: 5| Step: 5
Training loss: 0.436490535736084
Validation loss: 2.2737210243940353

Epoch: 5| Step: 6
Training loss: 0.43219271302223206
Validation loss: 2.213857044776281

Epoch: 5| Step: 7
Training loss: 0.5662185549736023
Validation loss: 2.253166457017263

Epoch: 5| Step: 8
Training loss: 0.2561904191970825
Validation loss: 2.218291699886322

Epoch: 5| Step: 9
Training loss: 0.2423592358827591
Validation loss: 2.2142996042966843

Epoch: 5| Step: 10
Training loss: 0.22683969140052795
Validation loss: 2.2574097166458764

Epoch: 5| Step: 11
Training loss: 0.3647339344024658
Validation loss: 2.2323874284823737

Epoch: 366| Step: 0
Training loss: 0.4962936341762543
Validation loss: 2.2677351534366608

Epoch: 5| Step: 1
Training loss: 0.4116242825984955
Validation loss: 2.1987892438968024

Epoch: 5| Step: 2
Training loss: 0.3263480067253113
Validation loss: 2.246949334939321

Epoch: 5| Step: 3
Training loss: 0.1826719492673874
Validation loss: 2.251480460166931

Epoch: 5| Step: 4
Training loss: 0.18505370616912842
Validation loss: 2.292487939198812

Epoch: 5| Step: 5
Training loss: 0.6185163259506226
Validation loss: 2.2794108390808105

Epoch: 5| Step: 6
Training loss: 0.2603134512901306
Validation loss: 2.2695405731598535

Epoch: 5| Step: 7
Training loss: 0.4808107912540436
Validation loss: 2.2708170811335244

Epoch: 5| Step: 8
Training loss: 0.5023832321166992
Validation loss: 2.2779076447089515

Epoch: 5| Step: 9
Training loss: 0.2845962643623352
Validation loss: 2.2994757890701294

Epoch: 5| Step: 10
Training loss: 0.1512306034564972
Validation loss: 2.270731270313263

Epoch: 5| Step: 11
Training loss: 0.3219965398311615
Validation loss: 2.2469019095102944

Epoch: 367| Step: 0
Training loss: 0.42278534173965454
Validation loss: 2.2713824758927026

Epoch: 5| Step: 1
Training loss: 0.41988644003868103
Validation loss: 2.2510090271631875

Epoch: 5| Step: 2
Training loss: 0.7343993186950684
Validation loss: 2.255674252907435

Epoch: 5| Step: 3
Training loss: 0.25369852781295776
Validation loss: 2.2542407711346946

Epoch: 5| Step: 4
Training loss: 0.4298873543739319
Validation loss: 2.2625747124354043

Epoch: 5| Step: 5
Training loss: 0.24666957557201385
Validation loss: 2.295298010110855

Epoch: 5| Step: 6
Training loss: 0.27032792568206787
Validation loss: 2.254963626464208

Epoch: 5| Step: 7
Training loss: 0.14387835562229156
Validation loss: 2.244777093331019

Epoch: 5| Step: 8
Training loss: 0.33329227566719055
Validation loss: 2.288938581943512

Epoch: 5| Step: 9
Training loss: 0.532133936882019
Validation loss: 2.2581080893675485

Epoch: 5| Step: 10
Training loss: 0.31771984696388245
Validation loss: 2.2658862123886743

Epoch: 5| Step: 11
Training loss: 0.22539466619491577
Validation loss: 2.267079641421636

Epoch: 368| Step: 0
Training loss: 0.24736201763153076
Validation loss: 2.221932977437973

Epoch: 5| Step: 1
Training loss: 0.360666424036026
Validation loss: 2.241438756386439

Epoch: 5| Step: 2
Training loss: 0.3080833852291107
Validation loss: 2.2352855106194816

Epoch: 5| Step: 3
Training loss: 0.26485997438430786
Validation loss: 2.2542351881663003

Epoch: 5| Step: 4
Training loss: 0.5935791730880737
Validation loss: 2.237786869208018

Epoch: 5| Step: 5
Training loss: 0.31944015622138977
Validation loss: 2.274632533391317

Epoch: 5| Step: 6
Training loss: 0.4123522639274597
Validation loss: 2.271726210912069

Epoch: 5| Step: 7
Training loss: 0.4991862177848816
Validation loss: 2.228362947702408

Epoch: 5| Step: 8
Training loss: 0.5151727795600891
Validation loss: 2.290447880824407

Epoch: 5| Step: 9
Training loss: 0.32770127058029175
Validation loss: 2.2545570582151413

Epoch: 5| Step: 10
Training loss: 0.2979753315448761
Validation loss: 2.2348946233590445

Epoch: 5| Step: 11
Training loss: 0.7340883612632751
Validation loss: 2.2024118353923163

Epoch: 369| Step: 0
Training loss: 0.5013913512229919
Validation loss: 2.2307965755462646

Epoch: 5| Step: 1
Training loss: 0.794587254524231
Validation loss: 2.2252461910247803

Epoch: 5| Step: 2
Training loss: 0.6063719391822815
Validation loss: 2.1986630906661353

Epoch: 5| Step: 3
Training loss: 0.3952646255493164
Validation loss: 2.203180511792501

Epoch: 5| Step: 4
Training loss: 0.23241272568702698
Validation loss: 2.2368058959643045

Epoch: 5| Step: 5
Training loss: 0.2857738435268402
Validation loss: 2.2696030338605246

Epoch: 5| Step: 6
Training loss: 0.3670380711555481
Validation loss: 2.2838364938894906

Epoch: 5| Step: 7
Training loss: 0.37133991718292236
Validation loss: 2.255990505218506

Epoch: 5| Step: 8
Training loss: 0.2899278402328491
Validation loss: 2.285811945796013

Epoch: 5| Step: 9
Training loss: 0.3257715106010437
Validation loss: 2.250751798351606

Epoch: 5| Step: 10
Training loss: 0.3038504719734192
Validation loss: 2.2469845761855445

Epoch: 5| Step: 11
Training loss: 0.3896520733833313
Validation loss: 2.2828000088532767

Epoch: 370| Step: 0
Training loss: 0.32407674193382263
Validation loss: 2.2558112690846124

Epoch: 5| Step: 1
Training loss: 0.44262656569480896
Validation loss: 2.2678400675455728

Epoch: 5| Step: 2
Training loss: 0.2870684564113617
Validation loss: 2.2243034640947976

Epoch: 5| Step: 3
Training loss: 0.18647675216197968
Validation loss: 2.2787898580233255

Epoch: 5| Step: 4
Training loss: 0.39093923568725586
Validation loss: 2.349599967400233

Epoch: 5| Step: 5
Training loss: 0.4679899215698242
Validation loss: 2.2984128842751184

Epoch: 5| Step: 6
Training loss: 0.3593062460422516
Validation loss: 2.346440404653549

Epoch: 5| Step: 7
Training loss: 0.4401540160179138
Validation loss: 2.2902208467324576

Epoch: 5| Step: 8
Training loss: 0.585395336151123
Validation loss: 2.3028301298618317

Epoch: 5| Step: 9
Training loss: 0.6857036352157593
Validation loss: 2.271784166495005

Epoch: 5| Step: 10
Training loss: 0.2541554868221283
Validation loss: 2.2625679671764374

Epoch: 5| Step: 11
Training loss: 0.32241392135620117
Validation loss: 2.235300193230311

Epoch: 371| Step: 0
Training loss: 0.44804635643959045
Validation loss: 2.253607233365377

Epoch: 5| Step: 1
Training loss: 0.3013102114200592
Validation loss: 2.288720428943634

Epoch: 5| Step: 2
Training loss: 0.5898104906082153
Validation loss: 2.3116120199362435

Epoch: 5| Step: 3
Training loss: 0.3635161817073822
Validation loss: 2.3401536345481873

Epoch: 5| Step: 4
Training loss: 0.48512038588523865
Validation loss: 2.323516329129537

Epoch: 5| Step: 5
Training loss: 0.2949768900871277
Validation loss: 2.2881126503149667

Epoch: 5| Step: 6
Training loss: 0.6280630826950073
Validation loss: 2.2799506982167563

Epoch: 5| Step: 7
Training loss: 0.31269824504852295
Validation loss: 2.274154802163442

Epoch: 5| Step: 8
Training loss: 0.3501083254814148
Validation loss: 2.308242589235306

Epoch: 5| Step: 9
Training loss: 0.34096628427505493
Validation loss: 2.229214832186699

Epoch: 5| Step: 10
Training loss: 0.3198556900024414
Validation loss: 2.2446702271699905

Epoch: 5| Step: 11
Training loss: 0.17298352718353271
Validation loss: 2.2652036249637604

Epoch: 372| Step: 0
Training loss: 0.2715941369533539
Validation loss: 2.26820536951224

Epoch: 5| Step: 1
Training loss: 0.28743138909339905
Validation loss: 2.2672181675831475

Epoch: 5| Step: 2
Training loss: 0.3906610608100891
Validation loss: 2.243902027606964

Epoch: 5| Step: 3
Training loss: 0.3759196400642395
Validation loss: 2.3087081015110016

Epoch: 5| Step: 4
Training loss: 0.30398648977279663
Validation loss: 2.2699448565642038

Epoch: 5| Step: 5
Training loss: 0.4352772831916809
Validation loss: 2.280517578125

Epoch: 5| Step: 6
Training loss: 0.21895603835582733
Validation loss: 2.293624152739843

Epoch: 5| Step: 7
Training loss: 0.35731661319732666
Validation loss: 2.2515009691317878

Epoch: 5| Step: 8
Training loss: 0.6161863803863525
Validation loss: 2.255617847045263

Epoch: 5| Step: 9
Training loss: 0.20790445804595947
Validation loss: 2.248331675926844

Epoch: 5| Step: 10
Training loss: 0.4327061176300049
Validation loss: 2.224174772699674

Epoch: 5| Step: 11
Training loss: 1.0867232084274292
Validation loss: 2.2363548825184503

Epoch: 373| Step: 0
Training loss: 0.37927356362342834
Validation loss: 2.2487890422344208

Epoch: 5| Step: 1
Training loss: 0.28373172879219055
Validation loss: 2.2397902508576712

Epoch: 5| Step: 2
Training loss: 0.2603101432323456
Validation loss: 2.302016238371531

Epoch: 5| Step: 3
Training loss: 0.2707257568836212
Validation loss: 2.2759893238544464

Epoch: 5| Step: 4
Training loss: 0.4192887246608734
Validation loss: 2.2843258331219354

Epoch: 5| Step: 5
Training loss: 0.2638927400112152
Validation loss: 2.3054764767487845

Epoch: 5| Step: 6
Training loss: 0.2655329704284668
Validation loss: 2.3167898853619895

Epoch: 5| Step: 7
Training loss: 0.6802951097488403
Validation loss: 2.284919559955597

Epoch: 5| Step: 8
Training loss: 0.6669089198112488
Validation loss: 2.287548214197159

Epoch: 5| Step: 9
Training loss: 0.3210206925868988
Validation loss: 2.231374427676201

Epoch: 5| Step: 10
Training loss: 0.3565470576286316
Validation loss: 2.231391062339147

Epoch: 5| Step: 11
Training loss: 1.0194059610366821
Validation loss: 2.2096724212169647

Epoch: 374| Step: 0
Training loss: 0.5340584516525269
Validation loss: 2.286424254377683

Epoch: 5| Step: 1
Training loss: 0.3395804762840271
Validation loss: 2.260659158229828

Epoch: 5| Step: 2
Training loss: 0.42783984541893005
Validation loss: 2.2544732143481574

Epoch: 5| Step: 3
Training loss: 0.3779573440551758
Validation loss: 2.3248083194096885

Epoch: 5| Step: 4
Training loss: 0.2933221459388733
Validation loss: 2.2464317977428436

Epoch: 5| Step: 5
Training loss: 0.25862693786621094
Validation loss: 2.347676545381546

Epoch: 5| Step: 6
Training loss: 0.3930279314517975
Validation loss: 2.255962088704109

Epoch: 5| Step: 7
Training loss: 0.4159201979637146
Validation loss: 2.2536413172880807

Epoch: 5| Step: 8
Training loss: 0.23988628387451172
Validation loss: 2.232415050268173

Epoch: 5| Step: 9
Training loss: 0.4381940960884094
Validation loss: 2.223874439795812

Epoch: 5| Step: 10
Training loss: 0.648855447769165
Validation loss: 2.231910228729248

Epoch: 5| Step: 11
Training loss: 0.25384125113487244
Validation loss: 2.2195786784092584

Epoch: 375| Step: 0
Training loss: 0.2786710858345032
Validation loss: 2.238226999839147

Epoch: 5| Step: 1
Training loss: 0.39264559745788574
Validation loss: 2.222497453292211

Epoch: 5| Step: 2
Training loss: 0.41644057631492615
Validation loss: 2.201117460926374

Epoch: 5| Step: 3
Training loss: 0.18994873762130737
Validation loss: 2.2121848464012146

Epoch: 5| Step: 4
Training loss: 0.6033731698989868
Validation loss: 2.230510964989662

Epoch: 5| Step: 5
Training loss: 0.42132243514060974
Validation loss: 2.2268501967191696

Epoch: 5| Step: 6
Training loss: 0.20856447517871857
Validation loss: 2.246774156888326

Epoch: 5| Step: 7
Training loss: 0.2912326157093048
Validation loss: 2.2490226129690805

Epoch: 5| Step: 8
Training loss: 0.31970536708831787
Validation loss: 2.2594457070032754

Epoch: 5| Step: 9
Training loss: 0.3914701044559479
Validation loss: 2.2127523571252823

Epoch: 5| Step: 10
Training loss: 0.364427387714386
Validation loss: 2.271632303794225

Epoch: 5| Step: 11
Training loss: 0.2765095829963684
Validation loss: 2.2477238128582635

Epoch: 376| Step: 0
Training loss: 0.22503510117530823
Validation loss: 2.2603527506192527

Epoch: 5| Step: 1
Training loss: 0.2688124477863312
Validation loss: 2.2373007585604987

Epoch: 5| Step: 2
Training loss: 0.20883984863758087
Validation loss: 2.2053279230992

Epoch: 5| Step: 3
Training loss: 0.4089861810207367
Validation loss: 2.248878245552381

Epoch: 5| Step: 4
Training loss: 0.37267929315567017
Validation loss: 2.242448369661967

Epoch: 5| Step: 5
Training loss: 0.1857321560382843
Validation loss: 2.26924566924572

Epoch: 5| Step: 6
Training loss: 0.22632703185081482
Validation loss: 2.2809968491395316

Epoch: 5| Step: 7
Training loss: 0.6031398773193359
Validation loss: 2.220730056365331

Epoch: 5| Step: 8
Training loss: 0.26501959562301636
Validation loss: 2.245522772272428

Epoch: 5| Step: 9
Training loss: 0.6657121777534485
Validation loss: 2.254158799846967

Epoch: 5| Step: 10
Training loss: 0.17805136740207672
Validation loss: 2.248776763677597

Epoch: 5| Step: 11
Training loss: 0.656662106513977
Validation loss: 2.241674775878588

Epoch: 377| Step: 0
Training loss: 0.4493038058280945
Validation loss: 2.2813661893208823

Epoch: 5| Step: 1
Training loss: 0.30941909551620483
Validation loss: 2.2471038003762565

Epoch: 5| Step: 2
Training loss: 0.2659938335418701
Validation loss: 2.2421933909257254

Epoch: 5| Step: 3
Training loss: 0.2207188904285431
Validation loss: 2.237727398673693

Epoch: 5| Step: 4
Training loss: 0.8520489931106567
Validation loss: 2.246520514289538

Epoch: 5| Step: 5
Training loss: 0.3544197082519531
Validation loss: 2.2613635460535684

Epoch: 5| Step: 6
Training loss: 0.2893454134464264
Validation loss: 2.2831388960282006

Epoch: 5| Step: 7
Training loss: 0.4257025122642517
Validation loss: 2.2198373178641

Epoch: 5| Step: 8
Training loss: 0.2887531518936157
Validation loss: 2.3021137515703836

Epoch: 5| Step: 9
Training loss: 0.27199047803878784
Validation loss: 2.28450915714105

Epoch: 5| Step: 10
Training loss: 0.3170197606086731
Validation loss: 2.302633598446846

Epoch: 5| Step: 11
Training loss: 0.14605310559272766
Validation loss: 2.223546028137207

Epoch: 378| Step: 0
Training loss: 0.7658802270889282
Validation loss: 2.2619461715221405

Epoch: 5| Step: 1
Training loss: 0.4143753945827484
Validation loss: 2.2280873705943427

Epoch: 5| Step: 2
Training loss: 0.2698170244693756
Validation loss: 2.2487396399180093

Epoch: 5| Step: 3
Training loss: 0.2811684012413025
Validation loss: 2.223817318677902

Epoch: 5| Step: 4
Training loss: 0.2627355456352234
Validation loss: 2.2301012128591537

Epoch: 5| Step: 5
Training loss: 0.3515947163105011
Validation loss: 2.3150174766778946

Epoch: 5| Step: 6
Training loss: 0.37980756163597107
Validation loss: 2.282264550526937

Epoch: 5| Step: 7
Training loss: 0.40840035676956177
Validation loss: 2.309213489294052

Epoch: 5| Step: 8
Training loss: 0.25751012563705444
Validation loss: 2.2861420810222626

Epoch: 5| Step: 9
Training loss: 0.2395607978105545
Validation loss: 2.2361412892738977

Epoch: 5| Step: 10
Training loss: 0.3572882413864136
Validation loss: 2.2427595307429633

Epoch: 5| Step: 11
Training loss: 0.3091258108615875
Validation loss: 2.2212378084659576

Epoch: 379| Step: 0
Training loss: 0.4315146505832672
Validation loss: 2.284814099470774

Epoch: 5| Step: 1
Training loss: 0.2892785370349884
Validation loss: 2.213093767563502

Epoch: 5| Step: 2
Training loss: 0.28290969133377075
Validation loss: 2.253706216812134

Epoch: 5| Step: 3
Training loss: 0.28284746408462524
Validation loss: 2.262258470058441

Epoch: 5| Step: 4
Training loss: 0.26561158895492554
Validation loss: 2.2722585449616113

Epoch: 5| Step: 5
Training loss: 0.22786584496498108
Validation loss: 2.2590482334295907

Epoch: 5| Step: 6
Training loss: 0.843551516532898
Validation loss: 2.349604537089666

Epoch: 5| Step: 7
Training loss: 0.4612881541252136
Validation loss: 2.3294282456239066

Epoch: 5| Step: 8
Training loss: 0.24610741436481476
Validation loss: 2.2880763113498688

Epoch: 5| Step: 9
Training loss: 0.38259226083755493
Validation loss: 2.2974692285060883

Epoch: 5| Step: 10
Training loss: 0.4725278317928314
Validation loss: 2.284327690800031

Epoch: 5| Step: 11
Training loss: 0.23560965061187744
Validation loss: 2.311246315638224

Epoch: 380| Step: 0
Training loss: 0.40921133756637573
Validation loss: 2.2809701363245645

Epoch: 5| Step: 1
Training loss: 0.5675064325332642
Validation loss: 2.2376792629559836

Epoch: 5| Step: 2
Training loss: 0.411399781703949
Validation loss: 2.270396759112676

Epoch: 5| Step: 3
Training loss: 0.16324244439601898
Validation loss: 2.302212009827296

Epoch: 5| Step: 4
Training loss: 0.294140100479126
Validation loss: 2.2760796000560126

Epoch: 5| Step: 5
Training loss: 0.19344978034496307
Validation loss: 2.2499502201875052

Epoch: 5| Step: 6
Training loss: 0.24021437764167786
Validation loss: 2.2879807402690253

Epoch: 5| Step: 7
Training loss: 0.5238510370254517
Validation loss: 2.2882834325234094

Epoch: 5| Step: 8
Training loss: 0.4888559877872467
Validation loss: 2.294519623120626

Epoch: 5| Step: 9
Training loss: 0.313223659992218
Validation loss: 2.2965441048145294

Epoch: 5| Step: 10
Training loss: 0.3014363944530487
Validation loss: 2.3234855830669403

Epoch: 5| Step: 11
Training loss: 0.12500864267349243
Validation loss: 2.262317736943563

Epoch: 381| Step: 0
Training loss: 0.25900977849960327
Validation loss: 2.276973972717921

Epoch: 5| Step: 1
Training loss: 0.6714271306991577
Validation loss: 2.2766091972589493

Epoch: 5| Step: 2
Training loss: 0.4250575602054596
Validation loss: 2.220836410919825

Epoch: 5| Step: 3
Training loss: 0.28780069947242737
Validation loss: 2.2846099932988486

Epoch: 5| Step: 4
Training loss: 0.2137824296951294
Validation loss: 2.285761445760727

Epoch: 5| Step: 5
Training loss: 0.410764217376709
Validation loss: 2.230658690134684

Epoch: 5| Step: 6
Training loss: 0.31468456983566284
Validation loss: 2.2877884258826575

Epoch: 5| Step: 7
Training loss: 0.3247143030166626
Validation loss: 2.2942330489555993

Epoch: 5| Step: 8
Training loss: 0.32455378770828247
Validation loss: 2.2922840466101966

Epoch: 5| Step: 9
Training loss: 0.18186362087726593
Validation loss: 2.273467540740967

Epoch: 5| Step: 10
Training loss: 0.35607975721359253
Validation loss: 2.2331391175587973

Epoch: 5| Step: 11
Training loss: 0.2368224561214447
Validation loss: 2.25957527756691

Epoch: 382| Step: 0
Training loss: 0.4084237217903137
Validation loss: 2.248685747385025

Epoch: 5| Step: 1
Training loss: 0.2944040894508362
Validation loss: 2.233505000670751

Epoch: 5| Step: 2
Training loss: 0.3698961138725281
Validation loss: 2.2925582379102707

Epoch: 5| Step: 3
Training loss: 0.6749520301818848
Validation loss: 2.2374380826950073

Epoch: 5| Step: 4
Training loss: 0.22671589255332947
Validation loss: 2.272445152203242

Epoch: 5| Step: 5
Training loss: 0.2058805525302887
Validation loss: 2.273260682821274

Epoch: 5| Step: 6
Training loss: 0.4314795434474945
Validation loss: 2.2495824297269187

Epoch: 5| Step: 7
Training loss: 0.41226881742477417
Validation loss: 2.235911692182223

Epoch: 5| Step: 8
Training loss: 0.22441542148590088
Validation loss: 2.2584334264198938

Epoch: 5| Step: 9
Training loss: 0.28692445158958435
Validation loss: 2.2725760638713837

Epoch: 5| Step: 10
Training loss: 0.36739015579223633
Validation loss: 2.267977386713028

Epoch: 5| Step: 11
Training loss: 0.3167431354522705
Validation loss: 2.2200642029444375

Epoch: 383| Step: 0
Training loss: 0.6701725721359253
Validation loss: 2.2286899387836456

Epoch: 5| Step: 1
Training loss: 0.28294411301612854
Validation loss: 2.2635205388069153

Epoch: 5| Step: 2
Training loss: 0.47877568006515503
Validation loss: 2.2497250139713287

Epoch: 5| Step: 3
Training loss: 0.18873640894889832
Validation loss: 2.208199789126714

Epoch: 5| Step: 4
Training loss: 0.4490888714790344
Validation loss: 2.2536520113547645

Epoch: 5| Step: 5
Training loss: 0.4652950167655945
Validation loss: 2.248876065015793

Epoch: 5| Step: 6
Training loss: 0.22285957634449005
Validation loss: 2.2332201351722083

Epoch: 5| Step: 7
Training loss: 0.3371783196926117
Validation loss: 2.2148188004891076

Epoch: 5| Step: 8
Training loss: 0.2324032038450241
Validation loss: 2.2052486538887024

Epoch: 5| Step: 9
Training loss: 0.2305893898010254
Validation loss: 2.303734317421913

Epoch: 5| Step: 10
Training loss: 0.3440364897251129
Validation loss: 2.2260144452253976

Epoch: 5| Step: 11
Training loss: 0.26733699440956116
Validation loss: 2.243065059185028

Epoch: 384| Step: 0
Training loss: 0.28386014699935913
Validation loss: 2.369791825612386

Epoch: 5| Step: 1
Training loss: 0.27204886078834534
Validation loss: 2.2648566315571466

Epoch: 5| Step: 2
Training loss: 0.7820492386817932
Validation loss: 2.262703532973925

Epoch: 5| Step: 3
Training loss: 0.294466108083725
Validation loss: 2.251901869972547

Epoch: 5| Step: 4
Training loss: 0.33106523752212524
Validation loss: 2.2237340907255807

Epoch: 5| Step: 5
Training loss: 0.40400180220603943
Validation loss: 2.1998775800069175

Epoch: 5| Step: 6
Training loss: 0.36400938034057617
Validation loss: 2.2377414852380753

Epoch: 5| Step: 7
Training loss: 0.3499165177345276
Validation loss: 2.2452188233534494

Epoch: 5| Step: 8
Training loss: 0.35440924763679504
Validation loss: 2.2315062284469604

Epoch: 5| Step: 9
Training loss: 0.2699206471443176
Validation loss: 2.266027589639028

Epoch: 5| Step: 10
Training loss: 0.3831576406955719
Validation loss: 2.2913138369719186

Epoch: 5| Step: 11
Training loss: 0.3735290765762329
Validation loss: 2.2796182135740914

Epoch: 385| Step: 0
Training loss: 0.28806376457214355
Validation loss: 2.3059393018484116

Epoch: 5| Step: 1
Training loss: 0.31056034564971924
Validation loss: 2.279037202397982

Epoch: 5| Step: 2
Training loss: 0.22226019203662872
Validation loss: 2.2721811880668006

Epoch: 5| Step: 3
Training loss: 0.30401811003685
Validation loss: 2.2410324116547904

Epoch: 5| Step: 4
Training loss: 0.4105711579322815
Validation loss: 2.256253490845362

Epoch: 5| Step: 5
Training loss: 0.14955013990402222
Validation loss: 2.247211903333664

Epoch: 5| Step: 6
Training loss: 0.7462705373764038
Validation loss: 2.273128201564153

Epoch: 5| Step: 7
Training loss: 0.3986279368400574
Validation loss: 2.3186047673225403

Epoch: 5| Step: 8
Training loss: 0.42500972747802734
Validation loss: 2.31939002374808

Epoch: 5| Step: 9
Training loss: 0.226420596241951
Validation loss: 2.281900311509768

Epoch: 5| Step: 10
Training loss: 0.28122633695602417
Validation loss: 2.3340603659550347

Epoch: 5| Step: 11
Training loss: 0.3016842007637024
Validation loss: 2.2606663207213082

Epoch: 386| Step: 0
Training loss: 0.32244494557380676
Validation loss: 2.33412437637647

Epoch: 5| Step: 1
Training loss: 0.3892023265361786
Validation loss: 2.2481093357006707

Epoch: 5| Step: 2
Training loss: 0.28459861874580383
Validation loss: 2.266167571147283

Epoch: 5| Step: 3
Training loss: 0.8382018804550171
Validation loss: 2.2710840751727424

Epoch: 5| Step: 4
Training loss: 0.2931925356388092
Validation loss: 2.268051897486051

Epoch: 5| Step: 5
Training loss: 0.16313305497169495
Validation loss: 2.3132513016462326

Epoch: 5| Step: 6
Training loss: 0.2046477496623993
Validation loss: 2.272224376598994

Epoch: 5| Step: 7
Training loss: 0.24552083015441895
Validation loss: 2.1927397747834525

Epoch: 5| Step: 8
Training loss: 0.2071012258529663
Validation loss: 2.263275384902954

Epoch: 5| Step: 9
Training loss: 0.32575175166130066
Validation loss: 2.255747452378273

Epoch: 5| Step: 10
Training loss: 0.22870893776416779
Validation loss: 2.2115060538053513

Epoch: 5| Step: 11
Training loss: 0.29855167865753174
Validation loss: 2.2805126359065375

Epoch: 387| Step: 0
Training loss: 0.3128910958766937
Validation loss: 2.2835527062416077

Epoch: 5| Step: 1
Training loss: 0.26121363043785095
Validation loss: 2.3294053028027215

Epoch: 5| Step: 2
Training loss: 0.26302796602249146
Validation loss: 2.3181821405887604

Epoch: 5| Step: 3
Training loss: 0.24809043109416962
Validation loss: 2.2508117804924646

Epoch: 5| Step: 4
Training loss: 0.662412703037262
Validation loss: 2.2511286586523056

Epoch: 5| Step: 5
Training loss: 0.4998399615287781
Validation loss: 2.262865275144577

Epoch: 5| Step: 6
Training loss: 0.268754243850708
Validation loss: 2.208246429761251

Epoch: 5| Step: 7
Training loss: 0.2928552031517029
Validation loss: 2.211864709854126

Epoch: 5| Step: 8
Training loss: 0.4148241877555847
Validation loss: 2.233007694284121

Epoch: 5| Step: 9
Training loss: 0.26577553153038025
Validation loss: 2.2715271761020026

Epoch: 5| Step: 10
Training loss: 0.34833088517189026
Validation loss: 2.2354758232831955

Epoch: 5| Step: 11
Training loss: 0.2141733169555664
Validation loss: 2.2284548779328666

Epoch: 388| Step: 0
Training loss: 0.12141890823841095
Validation loss: 2.257813940445582

Epoch: 5| Step: 1
Training loss: 0.6064549088478088
Validation loss: 2.244886353611946

Epoch: 5| Step: 2
Training loss: 0.22873751819133759
Validation loss: 2.253558188676834

Epoch: 5| Step: 3
Training loss: 0.1442103087902069
Validation loss: 2.261638010541598

Epoch: 5| Step: 4
Training loss: 0.3828037977218628
Validation loss: 2.2272822558879852

Epoch: 5| Step: 5
Training loss: 0.3740798234939575
Validation loss: 2.331904316941897

Epoch: 5| Step: 6
Training loss: 0.2725468575954437
Validation loss: 2.3048601746559143

Epoch: 5| Step: 7
Training loss: 0.31269946694374084
Validation loss: 2.3312847018241882

Epoch: 5| Step: 8
Training loss: 0.6037941575050354
Validation loss: 2.3165163894494376

Epoch: 5| Step: 9
Training loss: 0.45510387420654297
Validation loss: 2.310511589050293

Epoch: 5| Step: 10
Training loss: 0.4293270707130432
Validation loss: 2.3320344388484955

Epoch: 5| Step: 11
Training loss: 0.2743794918060303
Validation loss: 2.2990278800328574

Epoch: 389| Step: 0
Training loss: 0.45688581466674805
Validation loss: 2.202901691198349

Epoch: 5| Step: 1
Training loss: 0.34212905168533325
Validation loss: 2.210337375601133

Epoch: 5| Step: 2
Training loss: 0.4664468765258789
Validation loss: 2.22469170888265

Epoch: 5| Step: 3
Training loss: 0.36500805616378784
Validation loss: 2.266922583182653

Epoch: 5| Step: 4
Training loss: 0.3037481904029846
Validation loss: 2.2420164148012796

Epoch: 5| Step: 5
Training loss: 0.29497867822647095
Validation loss: 2.246124496062597

Epoch: 5| Step: 6
Training loss: 0.40586328506469727
Validation loss: 2.295014197627703

Epoch: 5| Step: 7
Training loss: 0.7445828318595886
Validation loss: 2.297013446688652

Epoch: 5| Step: 8
Training loss: 0.4465292990207672
Validation loss: 2.2917431692282357

Epoch: 5| Step: 9
Training loss: 0.6568695902824402
Validation loss: 2.299635728200277

Epoch: 5| Step: 10
Training loss: 0.2357594519853592
Validation loss: 2.2700812816619873

Epoch: 5| Step: 11
Training loss: 0.08745777606964111
Validation loss: 2.243872880935669

Epoch: 390| Step: 0
Training loss: 0.2443849742412567
Validation loss: 2.249608894189199

Epoch: 5| Step: 1
Training loss: 0.40367382764816284
Validation loss: 2.219474211335182

Epoch: 5| Step: 2
Training loss: 0.4470767080783844
Validation loss: 2.189599558711052

Epoch: 5| Step: 3
Training loss: 0.44810208678245544
Validation loss: 2.1751302977403006

Epoch: 5| Step: 4
Training loss: 0.36525845527648926
Validation loss: 2.174805387854576

Epoch: 5| Step: 5
Training loss: 0.6155649423599243
Validation loss: 2.2588836749394736

Epoch: 5| Step: 6
Training loss: 0.550024688243866
Validation loss: 2.222117771704992

Epoch: 5| Step: 7
Training loss: 0.42050838470458984
Validation loss: 2.3368423084417977

Epoch: 5| Step: 8
Training loss: 0.3686390221118927
Validation loss: 2.2844423900047937

Epoch: 5| Step: 9
Training loss: 0.39945048093795776
Validation loss: 2.3108697136243186

Epoch: 5| Step: 10
Training loss: 0.5276630520820618
Validation loss: 2.2499492516120276

Epoch: 5| Step: 11
Training loss: 0.2302979826927185
Validation loss: 2.2234072337547937

Epoch: 391| Step: 0
Training loss: 0.3615199327468872
Validation loss: 2.2010675172011056

Epoch: 5| Step: 1
Training loss: 0.449817955493927
Validation loss: 2.246956249078115

Epoch: 5| Step: 2
Training loss: 0.5203980207443237
Validation loss: 2.224816749493281

Epoch: 5| Step: 3
Training loss: 0.31779634952545166
Validation loss: 2.2064249962568283

Epoch: 5| Step: 4
Training loss: 0.2175459861755371
Validation loss: 2.201102281610171

Epoch: 5| Step: 5
Training loss: 0.2512144446372986
Validation loss: 2.2076644798119864

Epoch: 5| Step: 6
Training loss: 0.37762507796287537
Validation loss: 2.2600682179133096

Epoch: 5| Step: 7
Training loss: 0.3032921254634857
Validation loss: 2.2469633917013803

Epoch: 5| Step: 8
Training loss: 0.2697235345840454
Validation loss: 2.188590496778488

Epoch: 5| Step: 9
Training loss: 0.6344512104988098
Validation loss: 2.2233465015888214

Epoch: 5| Step: 10
Training loss: 0.2351999282836914
Validation loss: 2.2178518076737723

Epoch: 5| Step: 11
Training loss: 0.2550758123397827
Validation loss: 2.2569299787282944

Epoch: 392| Step: 0
Training loss: 0.4522538185119629
Validation loss: 2.246181547641754

Epoch: 5| Step: 1
Training loss: 0.24822783470153809
Validation loss: 2.25874732931455

Epoch: 5| Step: 2
Training loss: 0.23745779693126678
Validation loss: 2.2182935376962027

Epoch: 5| Step: 3
Training loss: 0.49174198508262634
Validation loss: 2.274701808889707

Epoch: 5| Step: 4
Training loss: 0.19669875502586365
Validation loss: 2.2741394340991974

Epoch: 5| Step: 5
Training loss: 0.4407983422279358
Validation loss: 2.244338591893514

Epoch: 5| Step: 6
Training loss: 0.22392074763774872
Validation loss: 2.2303774704535804

Epoch: 5| Step: 7
Training loss: 0.35011017322540283
Validation loss: 2.2553518315156302

Epoch: 5| Step: 8
Training loss: 0.2842431664466858
Validation loss: 2.236368417739868

Epoch: 5| Step: 9
Training loss: 0.18873149156570435
Validation loss: 2.2195026924212775

Epoch: 5| Step: 10
Training loss: 0.6003314256668091
Validation loss: 2.259012599786123

Epoch: 5| Step: 11
Training loss: 0.25738000869750977
Validation loss: 2.2903583546479545

Epoch: 393| Step: 0
Training loss: 0.46996253728866577
Validation loss: 2.2488321661949158

Epoch: 5| Step: 1
Training loss: 0.26123204827308655
Validation loss: 2.2486066023508706

Epoch: 5| Step: 2
Training loss: 0.39895379543304443
Validation loss: 2.217466652393341

Epoch: 5| Step: 3
Training loss: 0.31698235869407654
Validation loss: 2.198682129383087

Epoch: 5| Step: 4
Training loss: 0.6189766526222229
Validation loss: 2.2425050139427185

Epoch: 5| Step: 5
Training loss: 0.24248722195625305
Validation loss: 2.213207334280014

Epoch: 5| Step: 6
Training loss: 0.24947519600391388
Validation loss: 2.2003729939460754

Epoch: 5| Step: 7
Training loss: 0.19255998730659485
Validation loss: 2.1827942927678428

Epoch: 5| Step: 8
Training loss: 0.18856020271778107
Validation loss: 2.221622953812281

Epoch: 5| Step: 9
Training loss: 0.26494258642196655
Validation loss: 2.2051926851272583

Epoch: 5| Step: 10
Training loss: 0.26761674880981445
Validation loss: 2.2104787826538086

Epoch: 5| Step: 11
Training loss: 0.7076876759529114
Validation loss: 2.267036497592926

Epoch: 394| Step: 0
Training loss: 0.27724409103393555
Validation loss: 2.181402971347173

Epoch: 5| Step: 1
Training loss: 0.515555739402771
Validation loss: 2.2345265646775565

Epoch: 5| Step: 2
Training loss: 0.37338438630104065
Validation loss: 2.2121577709913254

Epoch: 5| Step: 3
Training loss: 0.3332359790802002
Validation loss: 2.227164844671885

Epoch: 5| Step: 4
Training loss: 0.2867867350578308
Validation loss: 2.2032589515050254

Epoch: 5| Step: 5
Training loss: 0.23304620385169983
Validation loss: 2.2655951529741287

Epoch: 5| Step: 6
Training loss: 0.746419370174408
Validation loss: 2.198314368724823

Epoch: 5| Step: 7
Training loss: 0.4584791660308838
Validation loss: 2.2701752483844757

Epoch: 5| Step: 8
Training loss: 0.4046265482902527
Validation loss: 2.2291666169961295

Epoch: 5| Step: 9
Training loss: 0.2638401985168457
Validation loss: 2.2302447706460953

Epoch: 5| Step: 10
Training loss: 0.254041850566864
Validation loss: 2.2487196723620095

Epoch: 5| Step: 11
Training loss: 0.09044486284255981
Validation loss: 2.2357977827390036

Epoch: 395| Step: 0
Training loss: 0.314279168844223
Validation loss: 2.2083931465943656

Epoch: 5| Step: 1
Training loss: 0.2373611479997635
Validation loss: 2.194015478094419

Epoch: 5| Step: 2
Training loss: 0.27622100710868835
Validation loss: 2.2565178026755652

Epoch: 5| Step: 3
Training loss: 0.36037030816078186
Validation loss: 2.1760961711406708

Epoch: 5| Step: 4
Training loss: 0.25085538625717163
Validation loss: 2.2551921804745994

Epoch: 5| Step: 5
Training loss: 0.25097203254699707
Validation loss: 2.2357294062773385

Epoch: 5| Step: 6
Training loss: 0.46157416701316833
Validation loss: 2.2485440373420715

Epoch: 5| Step: 7
Training loss: 0.5188506841659546
Validation loss: 2.235260317722956

Epoch: 5| Step: 8
Training loss: 0.5107814073562622
Validation loss: 2.2480391561985016

Epoch: 5| Step: 9
Training loss: 0.629426896572113
Validation loss: 2.2211356858412423

Epoch: 5| Step: 10
Training loss: 0.24221265316009521
Validation loss: 2.2111724068721137

Epoch: 5| Step: 11
Training loss: 0.30907416343688965
Validation loss: 2.240058427055677

Epoch: 396| Step: 0
Training loss: 0.20567746460437775
Validation loss: 2.204483767350515

Epoch: 5| Step: 1
Training loss: 0.22995348274707794
Validation loss: 2.245142161846161

Epoch: 5| Step: 2
Training loss: 0.5889899730682373
Validation loss: 2.286235307653745

Epoch: 5| Step: 3
Training loss: 0.24779930710792542
Validation loss: 2.318814734617869

Epoch: 5| Step: 4
Training loss: 0.22231324017047882
Validation loss: 2.2609773129224777

Epoch: 5| Step: 5
Training loss: 0.23024316132068634
Validation loss: 2.245397925376892

Epoch: 5| Step: 6
Training loss: 0.7603873610496521
Validation loss: 2.2828335662682853

Epoch: 5| Step: 7
Training loss: 0.32065898180007935
Validation loss: 2.2573259423176446

Epoch: 5| Step: 8
Training loss: 0.3111301362514496
Validation loss: 2.2417460878690085

Epoch: 5| Step: 9
Training loss: 0.2542380690574646
Validation loss: 2.26707432170709

Epoch: 5| Step: 10
Training loss: 0.15864071249961853
Validation loss: 2.241970181465149

Epoch: 5| Step: 11
Training loss: 0.2197430282831192
Validation loss: 2.2851640482743583

Epoch: 397| Step: 0
Training loss: 0.27009445428848267
Validation loss: 2.253675108154615

Epoch: 5| Step: 1
Training loss: 0.18729554116725922
Validation loss: 2.2548999339342117

Epoch: 5| Step: 2
Training loss: 0.28559863567352295
Validation loss: 2.2296352038780847

Epoch: 5| Step: 3
Training loss: 0.2632148861885071
Validation loss: 2.2694438993930817

Epoch: 5| Step: 4
Training loss: 0.20586831867694855
Validation loss: 2.290808310111364

Epoch: 5| Step: 5
Training loss: 0.7384265661239624
Validation loss: 2.287194609642029

Epoch: 5| Step: 6
Training loss: 0.360462486743927
Validation loss: 2.265598644812902

Epoch: 5| Step: 7
Training loss: 0.2488488256931305
Validation loss: 2.270532031853994

Epoch: 5| Step: 8
Training loss: 0.4190307557582855
Validation loss: 2.259777396917343

Epoch: 5| Step: 9
Training loss: 0.4367339015007019
Validation loss: 2.296357368429502

Epoch: 5| Step: 10
Training loss: 0.22105559706687927
Validation loss: 2.2402350405852

Epoch: 5| Step: 11
Training loss: 0.22652006149291992
Validation loss: 2.2907004257043204

Epoch: 398| Step: 0
Training loss: 0.20800809562206268
Validation loss: 2.3339308897654214

Epoch: 5| Step: 1
Training loss: 0.2557207942008972
Validation loss: 2.255827248096466

Epoch: 5| Step: 2
Training loss: 0.27013829350471497
Validation loss: 2.244854673743248

Epoch: 5| Step: 3
Training loss: 0.3690606951713562
Validation loss: 2.209032158056895

Epoch: 5| Step: 4
Training loss: 0.7405909299850464
Validation loss: 2.274880121151606

Epoch: 5| Step: 5
Training loss: 0.3127613067626953
Validation loss: 2.2916219830513

Epoch: 5| Step: 6
Training loss: 0.2681676745414734
Validation loss: 2.305029700199763

Epoch: 5| Step: 7
Training loss: 0.45949339866638184
Validation loss: 2.2704417407512665

Epoch: 5| Step: 8
Training loss: 0.34784525632858276
Validation loss: 2.3042326668898263

Epoch: 5| Step: 9
Training loss: 0.23417384922504425
Validation loss: 2.290263752142588

Epoch: 5| Step: 10
Training loss: 0.3576928973197937
Validation loss: 2.232500582933426

Epoch: 5| Step: 11
Training loss: 0.41197532415390015
Validation loss: 2.2843788663546243

Epoch: 399| Step: 0
Training loss: 0.1761135756969452
Validation loss: 2.260965089003245

Epoch: 5| Step: 1
Training loss: 0.5828580856323242
Validation loss: 2.242648412783941

Epoch: 5| Step: 2
Training loss: 0.2378208339214325
Validation loss: 2.215186357498169

Epoch: 5| Step: 3
Training loss: 0.23750463128089905
Validation loss: 2.224972407023112

Epoch: 5| Step: 4
Training loss: 0.3276682496070862
Validation loss: 2.2389330764611564

Epoch: 5| Step: 5
Training loss: 0.292366087436676
Validation loss: 2.212861036260923

Epoch: 5| Step: 6
Training loss: 0.25373849272727966
Validation loss: 2.243514264623324

Epoch: 5| Step: 7
Training loss: 0.17529325187206268
Validation loss: 2.256713350613912

Epoch: 5| Step: 8
Training loss: 0.2646334171295166
Validation loss: 2.2059002965688705

Epoch: 5| Step: 9
Training loss: 0.7622389793395996
Validation loss: 2.2231721927722297

Epoch: 5| Step: 10
Training loss: 0.3162597715854645
Validation loss: 2.194454158345858

Epoch: 5| Step: 11
Training loss: 0.199720561504364
Validation loss: 2.2408258070548377

Epoch: 400| Step: 0
Training loss: 0.2666521966457367
Validation loss: 2.2583954433600106

Epoch: 5| Step: 1
Training loss: 0.3353254795074463
Validation loss: 2.2214254836241403

Epoch: 5| Step: 2
Training loss: 0.2736054062843323
Validation loss: 2.2216489215691886

Epoch: 5| Step: 3
Training loss: 0.3174355626106262
Validation loss: 2.226437211036682

Epoch: 5| Step: 4
Training loss: 0.39408382773399353
Validation loss: 2.211365501085917

Epoch: 5| Step: 5
Training loss: 0.29584258794784546
Validation loss: 2.253943304220835

Epoch: 5| Step: 6
Training loss: 0.1912340223789215
Validation loss: 2.253196527560552

Epoch: 5| Step: 7
Training loss: 0.2868638336658478
Validation loss: 2.2008244891961417

Epoch: 5| Step: 8
Training loss: 0.3823976218700409
Validation loss: 2.209337224562963

Epoch: 5| Step: 9
Training loss: 0.4044491648674011
Validation loss: 2.2037973006566367

Epoch: 5| Step: 10
Training loss: 0.6115486025810242
Validation loss: 2.28719229499499

Epoch: 5| Step: 11
Training loss: 0.25967735052108765
Validation loss: 2.2774163832267127

Epoch: 401| Step: 0
Training loss: 0.3912719190120697
Validation loss: 2.3010475039482117

Epoch: 5| Step: 1
Training loss: 0.5128991007804871
Validation loss: 2.2830838362375894

Epoch: 5| Step: 2
Training loss: 0.6753438711166382
Validation loss: 2.370914419492086

Epoch: 5| Step: 3
Training loss: 0.28548893332481384
Validation loss: 2.2968282302220664

Epoch: 5| Step: 4
Training loss: 0.20839539170265198
Validation loss: 2.2458722988764444

Epoch: 5| Step: 5
Training loss: 0.29731133580207825
Validation loss: 2.2473770876725516

Epoch: 5| Step: 6
Training loss: 0.2605322301387787
Validation loss: 2.247553288936615

Epoch: 5| Step: 7
Training loss: 0.40553244948387146
Validation loss: 2.264876812696457

Epoch: 5| Step: 8
Training loss: 0.40717262029647827
Validation loss: 2.2170279224713645

Epoch: 5| Step: 9
Training loss: 0.3553902804851532
Validation loss: 2.2499148547649384

Epoch: 5| Step: 10
Training loss: 0.295053094625473
Validation loss: 2.2600165605545044

Epoch: 5| Step: 11
Training loss: 0.4889291822910309
Validation loss: 2.274171382188797

Epoch: 402| Step: 0
Training loss: 0.5854031443595886
Validation loss: 2.3070783962806067

Epoch: 5| Step: 1
Training loss: 0.3017418682575226
Validation loss: 2.217895964781443

Epoch: 5| Step: 2
Training loss: 0.2833086848258972
Validation loss: 2.2649467090765634

Epoch: 5| Step: 3
Training loss: 0.29756543040275574
Validation loss: 2.263579785823822

Epoch: 5| Step: 4
Training loss: 0.24601741135120392
Validation loss: 2.2628493209679923

Epoch: 5| Step: 5
Training loss: 0.30493029952049255
Validation loss: 2.2397628923257193

Epoch: 5| Step: 6
Training loss: 0.2627094089984894
Validation loss: 2.2905988097190857

Epoch: 5| Step: 7
Training loss: 0.3523513376712799
Validation loss: 2.272295296192169

Epoch: 5| Step: 8
Training loss: 0.3881937563419342
Validation loss: 2.229604254166285

Epoch: 5| Step: 9
Training loss: 0.30196747183799744
Validation loss: 2.2350337704022727

Epoch: 5| Step: 10
Training loss: 0.26885706186294556
Validation loss: 2.2463868260383606

Epoch: 5| Step: 11
Training loss: 0.17751926183700562
Validation loss: 2.2464634279410043

Epoch: 403| Step: 0
Training loss: 0.22909760475158691
Validation loss: 2.252785156170527

Epoch: 5| Step: 1
Training loss: 0.4882664680480957
Validation loss: 2.3098038733005524

Epoch: 5| Step: 2
Training loss: 0.21717894077301025
Validation loss: 2.30981774131457

Epoch: 5| Step: 3
Training loss: 0.3921149671077728
Validation loss: 2.258025194207827

Epoch: 5| Step: 4
Training loss: 0.5721736550331116
Validation loss: 2.222101221481959

Epoch: 5| Step: 5
Training loss: 0.3300510346889496
Validation loss: 2.2330470234155655

Epoch: 5| Step: 6
Training loss: 0.33959636092185974
Validation loss: 2.252074340979258

Epoch: 5| Step: 7
Training loss: 0.5990040302276611
Validation loss: 2.299517944455147

Epoch: 5| Step: 8
Training loss: 0.2897354066371918
Validation loss: 2.2561163306236267

Epoch: 5| Step: 9
Training loss: 0.26981478929519653
Validation loss: 2.245019872983297

Epoch: 5| Step: 10
Training loss: 0.25444871187210083
Validation loss: 2.2955270608266196

Epoch: 5| Step: 11
Training loss: 0.11927193403244019
Validation loss: 2.2477015554904938

Epoch: 404| Step: 0
Training loss: 0.41481709480285645
Validation loss: 2.2760706742604575

Epoch: 5| Step: 1
Training loss: 0.3597487211227417
Validation loss: 2.2807003259658813

Epoch: 5| Step: 2
Training loss: 0.26265284419059753
Validation loss: 2.331333210070928

Epoch: 5| Step: 3
Training loss: 0.26157447695732117
Validation loss: 2.256125713388125

Epoch: 5| Step: 4
Training loss: 0.414114385843277
Validation loss: 2.2835744321346283

Epoch: 5| Step: 5
Training loss: 0.29327768087387085
Validation loss: 2.221588929494222

Epoch: 5| Step: 6
Training loss: 0.903265655040741
Validation loss: 2.2435112992922464

Epoch: 5| Step: 7
Training loss: 0.23660893738269806
Validation loss: 2.2365028659502664

Epoch: 5| Step: 8
Training loss: 0.354796439409256
Validation loss: 2.2250592758258185

Epoch: 5| Step: 9
Training loss: 0.33516138792037964
Validation loss: 2.245504160722097

Epoch: 5| Step: 10
Training loss: 0.2416985034942627
Validation loss: 2.2581505527098975

Epoch: 5| Step: 11
Training loss: 0.2688363790512085
Validation loss: 2.242114692926407

Epoch: 405| Step: 0
Training loss: 0.3194049000740051
Validation loss: 2.2477905998627343

Epoch: 5| Step: 1
Training loss: 0.32446208596229553
Validation loss: 2.2701035340627036

Epoch: 5| Step: 2
Training loss: 0.655014157295227
Validation loss: 2.181368872523308

Epoch: 5| Step: 3
Training loss: 0.2067054808139801
Validation loss: 2.238703896601995

Epoch: 5| Step: 4
Training loss: 0.32044723629951477
Validation loss: 2.2401972164710364

Epoch: 5| Step: 5
Training loss: 0.22154423594474792
Validation loss: 2.2302884459495544

Epoch: 5| Step: 6
Training loss: 0.4296794831752777
Validation loss: 2.2503240406513214

Epoch: 5| Step: 7
Training loss: 0.6047235727310181
Validation loss: 2.251332715153694

Epoch: 5| Step: 8
Training loss: 0.3119560778141022
Validation loss: 2.3048740526040397

Epoch: 5| Step: 9
Training loss: 0.2135283201932907
Validation loss: 2.262689953049024

Epoch: 5| Step: 10
Training loss: 0.2679956555366516
Validation loss: 2.254336287577947

Epoch: 5| Step: 11
Training loss: 0.25110679864883423
Validation loss: 2.2589220901330314

Epoch: 406| Step: 0
Training loss: 0.3257642388343811
Validation loss: 2.256084362665812

Epoch: 5| Step: 1
Training loss: 0.8954059481620789
Validation loss: 2.237142950296402

Epoch: 5| Step: 2
Training loss: 0.5413578748703003
Validation loss: 2.1935993432998657

Epoch: 5| Step: 3
Training loss: 0.4161859452724457
Validation loss: 2.22512179116408

Epoch: 5| Step: 4
Training loss: 0.3459502160549164
Validation loss: 2.2502491176128387

Epoch: 5| Step: 5
Training loss: 0.4279076159000397
Validation loss: 2.225594346721967

Epoch: 5| Step: 6
Training loss: 0.3159610331058502
Validation loss: 2.2886694173018136

Epoch: 5| Step: 7
Training loss: 0.5092464685440063
Validation loss: 2.263598288098971

Epoch: 5| Step: 8
Training loss: 0.34653663635253906
Validation loss: 2.2502720952033997

Epoch: 5| Step: 9
Training loss: 0.4917519986629486
Validation loss: 2.2958759516477585

Epoch: 5| Step: 10
Training loss: 0.3457079827785492
Validation loss: 2.2830970535675683

Epoch: 5| Step: 11
Training loss: 0.23260498046875
Validation loss: 2.237151856223742

Epoch: 407| Step: 0
Training loss: 0.5514501333236694
Validation loss: 2.2208712001641593

Epoch: 5| Step: 1
Training loss: 0.4572278559207916
Validation loss: 2.2306826213995614

Epoch: 5| Step: 2
Training loss: 0.46857577562332153
Validation loss: 2.194505582253138

Epoch: 5| Step: 3
Training loss: 0.4500373899936676
Validation loss: 2.220472743113836

Epoch: 5| Step: 4
Training loss: 0.24275580048561096
Validation loss: 2.19783353805542

Epoch: 5| Step: 5
Training loss: 0.7031458020210266
Validation loss: 2.2223190863927207

Epoch: 5| Step: 6
Training loss: 0.3340666890144348
Validation loss: 2.2908194959163666

Epoch: 5| Step: 7
Training loss: 0.5008171796798706
Validation loss: 2.2817193418741226

Epoch: 5| Step: 8
Training loss: 0.5827245712280273
Validation loss: 2.311735679705938

Epoch: 5| Step: 9
Training loss: 0.4612174928188324
Validation loss: 2.314183682203293

Epoch: 5| Step: 10
Training loss: 0.2576114535331726
Validation loss: 2.292176475127538

Epoch: 5| Step: 11
Training loss: 0.3518410921096802
Validation loss: 2.2504585832357407

Epoch: 408| Step: 0
Training loss: 0.2580033242702484
Validation loss: 2.2935096671183905

Epoch: 5| Step: 1
Training loss: 0.44697895646095276
Validation loss: 2.2610008219877877

Epoch: 5| Step: 2
Training loss: 0.3985903561115265
Validation loss: 2.2542123099168143

Epoch: 5| Step: 3
Training loss: 0.2886177897453308
Validation loss: 2.187812184294065

Epoch: 5| Step: 4
Training loss: 0.2757748067378998
Validation loss: 2.227595955133438

Epoch: 5| Step: 5
Training loss: 0.19785843789577484
Validation loss: 2.25100314617157

Epoch: 5| Step: 6
Training loss: 0.6206320524215698
Validation loss: 2.2258478105068207

Epoch: 5| Step: 7
Training loss: 0.3163868486881256
Validation loss: 2.2463306188583374

Epoch: 5| Step: 8
Training loss: 0.25596296787261963
Validation loss: 2.211696833372116

Epoch: 5| Step: 9
Training loss: 0.4090602397918701
Validation loss: 2.2175291379292807

Epoch: 5| Step: 10
Training loss: 0.41830572485923767
Validation loss: 2.198679511745771

Epoch: 5| Step: 11
Training loss: 0.2374323606491089
Validation loss: 2.200162490208944

Epoch: 409| Step: 0
Training loss: 0.23787622153759003
Validation loss: 2.2572488139073053

Epoch: 5| Step: 1
Training loss: 0.36507508158683777
Validation loss: 2.3134171664714813

Epoch: 5| Step: 2
Training loss: 0.3667791485786438
Validation loss: 2.3177835643291473

Epoch: 5| Step: 3
Training loss: 0.3199117183685303
Validation loss: 2.3153437972068787

Epoch: 5| Step: 4
Training loss: 0.5692192316055298
Validation loss: 2.2851636558771133

Epoch: 5| Step: 5
Training loss: 0.2512213885784149
Validation loss: 2.267337510983149

Epoch: 5| Step: 6
Training loss: 0.46803203225135803
Validation loss: 2.237906356652578

Epoch: 5| Step: 7
Training loss: 0.7641476392745972
Validation loss: 2.244264384110769

Epoch: 5| Step: 8
Training loss: 0.42283740639686584
Validation loss: 2.235927015542984

Epoch: 5| Step: 9
Training loss: 0.2407456934452057
Validation loss: 2.2236915826797485

Epoch: 5| Step: 10
Training loss: 0.317832350730896
Validation loss: 2.2151176234086356

Epoch: 5| Step: 11
Training loss: 0.23010414838790894
Validation loss: 2.2486751079559326

Epoch: 410| Step: 0
Training loss: 0.2549489438533783
Validation loss: 2.278126006325086

Epoch: 5| Step: 1
Training loss: 0.6223739981651306
Validation loss: 2.303073396285375

Epoch: 5| Step: 2
Training loss: 0.3050867021083832
Validation loss: 2.235735779007276

Epoch: 5| Step: 3
Training loss: 0.5026298761367798
Validation loss: 2.2840016980965934

Epoch: 5| Step: 4
Training loss: 0.3017471134662628
Validation loss: 2.2451041291157403

Epoch: 5| Step: 5
Training loss: 0.27843865752220154
Validation loss: 2.2506495912869773

Epoch: 5| Step: 6
Training loss: 0.33982178568840027
Validation loss: 2.2710505624612174

Epoch: 5| Step: 7
Training loss: 0.30601173639297485
Validation loss: 2.2352931946516037

Epoch: 5| Step: 8
Training loss: 0.34654751420021057
Validation loss: 2.20245989660422

Epoch: 5| Step: 9
Training loss: 0.294210284948349
Validation loss: 2.25111186504364

Epoch: 5| Step: 10
Training loss: 0.2623983323574066
Validation loss: 2.271244247754415

Epoch: 5| Step: 11
Training loss: 0.18294620513916016
Validation loss: 2.2662141223748526

Epoch: 411| Step: 0
Training loss: 0.4681774079799652
Validation loss: 2.2038257072369256

Epoch: 5| Step: 1
Training loss: 0.311343789100647
Validation loss: 2.2566192547480264

Epoch: 5| Step: 2
Training loss: 0.24620933830738068
Validation loss: 2.219361792008082

Epoch: 5| Step: 3
Training loss: 0.726702094078064
Validation loss: 2.243188440799713

Epoch: 5| Step: 4
Training loss: 0.2507692575454712
Validation loss: 2.212845722834269

Epoch: 5| Step: 5
Training loss: 0.21908137202262878
Validation loss: 2.21512234210968

Epoch: 5| Step: 6
Training loss: 0.3307687044143677
Validation loss: 2.2056577652692795

Epoch: 5| Step: 7
Training loss: 0.35282236337661743
Validation loss: 2.222694178422292

Epoch: 5| Step: 8
Training loss: 0.25960391759872437
Validation loss: 2.227649211883545

Epoch: 5| Step: 9
Training loss: 0.2287633866071701
Validation loss: 2.2967697282632193

Epoch: 5| Step: 10
Training loss: 0.40450263023376465
Validation loss: 2.2569200297196708

Epoch: 5| Step: 11
Training loss: 0.30764007568359375
Validation loss: 2.2424946427345276

Epoch: 412| Step: 0
Training loss: 0.4854089319705963
Validation loss: 2.2432816276947656

Epoch: 5| Step: 1
Training loss: 0.23651981353759766
Validation loss: 2.2404529054959617

Epoch: 5| Step: 2
Training loss: 0.29356420040130615
Validation loss: 2.282516732811928

Epoch: 5| Step: 3
Training loss: 0.3548457622528076
Validation loss: 2.300148884455363

Epoch: 5| Step: 4
Training loss: 0.624253511428833
Validation loss: 2.3024340867996216

Epoch: 5| Step: 5
Training loss: 0.38347116112709045
Validation loss: 2.301749666531881

Epoch: 5| Step: 6
Training loss: 0.21003615856170654
Validation loss: 2.260458916425705

Epoch: 5| Step: 7
Training loss: 0.37027549743652344
Validation loss: 2.2869273324807486

Epoch: 5| Step: 8
Training loss: 0.2337038218975067
Validation loss: 2.272123008966446

Epoch: 5| Step: 9
Training loss: 0.2326217144727707
Validation loss: 2.2118083983659744

Epoch: 5| Step: 10
Training loss: 0.34669703245162964
Validation loss: 2.227091506123543

Epoch: 5| Step: 11
Training loss: 0.3025747537612915
Validation loss: 2.237588087717692

Epoch: 413| Step: 0
Training loss: 0.2768980860710144
Validation loss: 2.2535665233929953

Epoch: 5| Step: 1
Training loss: 0.1578749120235443
Validation loss: 2.3084700455268226

Epoch: 5| Step: 2
Training loss: 0.3911691904067993
Validation loss: 2.2670834561189017

Epoch: 5| Step: 3
Training loss: 0.33042603731155396
Validation loss: 2.2405413389205933

Epoch: 5| Step: 4
Training loss: 0.4120541512966156
Validation loss: 2.299493134021759

Epoch: 5| Step: 5
Training loss: 0.38941800594329834
Validation loss: 2.2509371042251587

Epoch: 5| Step: 6
Training loss: 0.33608779311180115
Validation loss: 2.215044821302096

Epoch: 5| Step: 7
Training loss: 0.24415627121925354
Validation loss: 2.2240819533665976

Epoch: 5| Step: 8
Training loss: 0.23875665664672852
Validation loss: 2.2629582782586417

Epoch: 5| Step: 9
Training loss: 0.24792465567588806
Validation loss: 2.2187238385279975

Epoch: 5| Step: 10
Training loss: 0.4045891761779785
Validation loss: 2.206112672885259

Epoch: 5| Step: 11
Training loss: 2.0458807945251465
Validation loss: 2.2042873402436576

Epoch: 414| Step: 0
Training loss: 0.33369022607803345
Validation loss: 2.225834717353185

Epoch: 5| Step: 1
Training loss: 0.24384769797325134
Validation loss: 2.2217046668132148

Epoch: 5| Step: 2
Training loss: 0.4373089671134949
Validation loss: 2.2647421061992645

Epoch: 5| Step: 3
Training loss: 0.29952019453048706
Validation loss: 2.242572382092476

Epoch: 5| Step: 4
Training loss: 0.20705941319465637
Validation loss: 2.2539543161789575

Epoch: 5| Step: 5
Training loss: 0.10879367589950562
Validation loss: 2.251337175567945

Epoch: 5| Step: 6
Training loss: 0.23110775649547577
Validation loss: 2.2471067110697427

Epoch: 5| Step: 7
Training loss: 0.38071173429489136
Validation loss: 2.228434224923452

Epoch: 5| Step: 8
Training loss: 0.6343640089035034
Validation loss: 2.24341090520223

Epoch: 5| Step: 9
Training loss: 0.2859014570713043
Validation loss: 2.251947651306788

Epoch: 5| Step: 10
Training loss: 0.40717658400535583
Validation loss: 2.2485332985719046

Epoch: 5| Step: 11
Training loss: 0.3758822977542877
Validation loss: 2.2181758483250937

Epoch: 415| Step: 0
Training loss: 0.32266926765441895
Validation loss: 2.255481868982315

Epoch: 5| Step: 1
Training loss: 0.29428738355636597
Validation loss: 2.19189582268397

Epoch: 5| Step: 2
Training loss: 0.2014102041721344
Validation loss: 2.220204090078672

Epoch: 5| Step: 3
Training loss: 0.3220915198326111
Validation loss: 2.261003320415815

Epoch: 5| Step: 4
Training loss: 0.23304195702075958
Validation loss: 2.219539319475492

Epoch: 5| Step: 5
Training loss: 0.3827630579471588
Validation loss: 2.2128124435742698

Epoch: 5| Step: 6
Training loss: 0.37344565987586975
Validation loss: 2.240681901574135

Epoch: 5| Step: 7
Training loss: 0.33895134925842285
Validation loss: 2.2640773952007294

Epoch: 5| Step: 8
Training loss: 0.23069851100444794
Validation loss: 2.2750110576550164

Epoch: 5| Step: 9
Training loss: 0.6337088346481323
Validation loss: 2.218562424182892

Epoch: 5| Step: 10
Training loss: 0.1970478594303131
Validation loss: 2.2635463575522103

Epoch: 5| Step: 11
Training loss: 0.3772156238555908
Validation loss: 2.2813481291135154

Epoch: 416| Step: 0
Training loss: 0.2942217290401459
Validation loss: 2.252203772465388

Epoch: 5| Step: 1
Training loss: 0.38716214895248413
Validation loss: 2.280791054169337

Epoch: 5| Step: 2
Training loss: 0.27169230580329895
Validation loss: 2.2401104271411896

Epoch: 5| Step: 3
Training loss: 0.333173543214798
Validation loss: 2.2571897208690643

Epoch: 5| Step: 4
Training loss: 0.296845018863678
Validation loss: 2.313106288512548

Epoch: 5| Step: 5
Training loss: 0.5579503774642944
Validation loss: 2.280494968096415

Epoch: 5| Step: 6
Training loss: 0.2982463240623474
Validation loss: 2.263722295562426

Epoch: 5| Step: 7
Training loss: 0.22333817183971405
Validation loss: 2.262079576651255

Epoch: 5| Step: 8
Training loss: 0.18360108137130737
Validation loss: 2.2528774787982306

Epoch: 5| Step: 9
Training loss: 0.24877090752124786
Validation loss: 2.2728440264860788

Epoch: 5| Step: 10
Training loss: 0.38591450452804565
Validation loss: 2.290155991911888

Epoch: 5| Step: 11
Training loss: 0.0993877425789833
Validation loss: 2.2466806968053183

Epoch: 417| Step: 0
Training loss: 0.20809383690357208
Validation loss: 2.2785031497478485

Epoch: 5| Step: 1
Training loss: 0.43440064787864685
Validation loss: 2.2807138760884604

Epoch: 5| Step: 2
Training loss: 0.21000578999519348
Validation loss: 2.253905196984609

Epoch: 5| Step: 3
Training loss: 0.36669519543647766
Validation loss: 2.299862638115883

Epoch: 5| Step: 4
Training loss: 0.22783081233501434
Validation loss: 2.2394525160392127

Epoch: 5| Step: 5
Training loss: 0.20566372573375702
Validation loss: 2.25087038675944

Epoch: 5| Step: 6
Training loss: 0.22891481220722198
Validation loss: 2.2266399562358856

Epoch: 5| Step: 7
Training loss: 0.6431462168693542
Validation loss: 2.2250167528788247

Epoch: 5| Step: 8
Training loss: 0.2849717140197754
Validation loss: 2.247797509034475

Epoch: 5| Step: 9
Training loss: 0.305675745010376
Validation loss: 2.255703498919805

Epoch: 5| Step: 10
Training loss: 0.31120115518569946
Validation loss: 2.264692336320877

Epoch: 5| Step: 11
Training loss: 0.7229636907577515
Validation loss: 2.242065812150637

Epoch: 418| Step: 0
Training loss: 0.20149917900562286
Validation loss: 2.251940151055654

Epoch: 5| Step: 1
Training loss: 0.32016611099243164
Validation loss: 2.2553048729896545

Epoch: 5| Step: 2
Training loss: 0.4714816212654114
Validation loss: 2.2263644436995187

Epoch: 5| Step: 3
Training loss: 0.2628317177295685
Validation loss: 2.268078754345576

Epoch: 5| Step: 4
Training loss: 0.40221133828163147
Validation loss: 2.252182289958

Epoch: 5| Step: 5
Training loss: 0.20968766510486603
Validation loss: 2.209785873691241

Epoch: 5| Step: 6
Training loss: 0.5573607683181763
Validation loss: 2.2714537978172302

Epoch: 5| Step: 7
Training loss: 0.2064872682094574
Validation loss: 2.223007077972094

Epoch: 5| Step: 8
Training loss: 0.25600534677505493
Validation loss: 2.2595511823892593

Epoch: 5| Step: 9
Training loss: 0.46283164620399475
Validation loss: 2.229410300652186

Epoch: 5| Step: 10
Training loss: 0.2349560260772705
Validation loss: 2.27299565076828

Epoch: 5| Step: 11
Training loss: 0.3092024326324463
Validation loss: 2.296064997712771

Epoch: 419| Step: 0
Training loss: 0.22692561149597168
Validation loss: 2.225802352031072

Epoch: 5| Step: 1
Training loss: 0.21695561707019806
Validation loss: 2.256655067205429

Epoch: 5| Step: 2
Training loss: 0.6019108891487122
Validation loss: 2.2398848036924996

Epoch: 5| Step: 3
Training loss: 0.20278260111808777
Validation loss: 2.240716060002645

Epoch: 5| Step: 4
Training loss: 0.23272518813610077
Validation loss: 2.28027351697286

Epoch: 5| Step: 5
Training loss: 0.25020360946655273
Validation loss: 2.245271439353625

Epoch: 5| Step: 6
Training loss: 0.608208417892456
Validation loss: 2.231229245662689

Epoch: 5| Step: 7
Training loss: 0.37868592143058777
Validation loss: 2.216082622607549

Epoch: 5| Step: 8
Training loss: 0.2647424638271332
Validation loss: 2.228687107563019

Epoch: 5| Step: 9
Training loss: 0.30249613523483276
Validation loss: 2.239480644464493

Epoch: 5| Step: 10
Training loss: 0.20761699974536896
Validation loss: 2.2656835168600082

Epoch: 5| Step: 11
Training loss: 0.11268210411071777
Validation loss: 2.2522928218046823

Epoch: 420| Step: 0
Training loss: 0.29414984583854675
Validation loss: 2.2211301922798157

Epoch: 5| Step: 1
Training loss: 0.2932285666465759
Validation loss: 2.2309856514135995

Epoch: 5| Step: 2
Training loss: 0.49418196082115173
Validation loss: 2.249435245990753

Epoch: 5| Step: 3
Training loss: 0.18369217216968536
Validation loss: 2.1817499697208405

Epoch: 5| Step: 4
Training loss: 0.24505099654197693
Validation loss: 2.2438160876433053

Epoch: 5| Step: 5
Training loss: 0.22630491852760315
Validation loss: 2.2231410642464957

Epoch: 5| Step: 6
Training loss: 0.3051150143146515
Validation loss: 2.1931942999362946

Epoch: 5| Step: 7
Training loss: 0.25929883122444153
Validation loss: 2.2198332796494165

Epoch: 5| Step: 8
Training loss: 0.24772238731384277
Validation loss: 2.2427014807860055

Epoch: 5| Step: 9
Training loss: 0.48835062980651855
Validation loss: 2.251770635445913

Epoch: 5| Step: 10
Training loss: 0.16518065333366394
Validation loss: 2.2103143632411957

Epoch: 5| Step: 11
Training loss: 0.40142330527305603
Validation loss: 2.1908095479011536

Epoch: 421| Step: 0
Training loss: 0.5266979932785034
Validation loss: 2.1876582403977713

Epoch: 5| Step: 1
Training loss: 0.19224673509597778
Validation loss: 2.220788220564524

Epoch: 5| Step: 2
Training loss: 0.2662533223628998
Validation loss: 2.169676090280215

Epoch: 5| Step: 3
Training loss: 0.2364419400691986
Validation loss: 2.209220811724663

Epoch: 5| Step: 4
Training loss: 0.30513420701026917
Validation loss: 2.2422340164581933

Epoch: 5| Step: 5
Training loss: 0.3990684151649475
Validation loss: 2.2317712604999542

Epoch: 5| Step: 6
Training loss: 0.30514898896217346
Validation loss: 2.235897699991862

Epoch: 5| Step: 7
Training loss: 0.39000993967056274
Validation loss: 2.2564933399359384

Epoch: 5| Step: 8
Training loss: 0.2806907296180725
Validation loss: 2.221359739700953

Epoch: 5| Step: 9
Training loss: 0.2362760603427887
Validation loss: 2.222335467735926

Epoch: 5| Step: 10
Training loss: 0.2236528843641281
Validation loss: 2.2331365744272866

Epoch: 5| Step: 11
Training loss: 0.23158347606658936
Validation loss: 2.197702780365944

Epoch: 422| Step: 0
Training loss: 0.23227977752685547
Validation loss: 2.1858093390862146

Epoch: 5| Step: 1
Training loss: 0.3389700651168823
Validation loss: 2.2622765600681305

Epoch: 5| Step: 2
Training loss: 0.3597099184989929
Validation loss: 2.25022491812706

Epoch: 5| Step: 3
Training loss: 0.17491453886032104
Validation loss: 2.2388673524061837

Epoch: 5| Step: 4
Training loss: 0.2818662226200104
Validation loss: 2.2244285196065903

Epoch: 5| Step: 5
Training loss: 0.4509955942630768
Validation loss: 2.2603704233964286

Epoch: 5| Step: 6
Training loss: 0.5660218000411987
Validation loss: 2.2122763444979987

Epoch: 5| Step: 7
Training loss: 0.5843213796615601
Validation loss: 2.1877077420552573

Epoch: 5| Step: 8
Training loss: 0.26223981380462646
Validation loss: 2.2053574273983636

Epoch: 5| Step: 9
Training loss: 0.241409033536911
Validation loss: 2.2456706960995994

Epoch: 5| Step: 10
Training loss: 0.19508934020996094
Validation loss: 2.257281849781672

Epoch: 5| Step: 11
Training loss: 0.12706243991851807
Validation loss: 2.2996729662021003

Epoch: 423| Step: 0
Training loss: 0.2130572348833084
Validation loss: 2.2583138744036355

Epoch: 5| Step: 1
Training loss: 0.4976130425930023
Validation loss: 2.254456097880999

Epoch: 5| Step: 2
Training loss: 0.2652592658996582
Validation loss: 2.2317133446534476

Epoch: 5| Step: 3
Training loss: 0.25054627656936646
Validation loss: 2.2381599148114524

Epoch: 5| Step: 4
Training loss: 0.15500085055828094
Validation loss: 2.232852960626284

Epoch: 5| Step: 5
Training loss: 0.3075847327709198
Validation loss: 2.280175586541494

Epoch: 5| Step: 6
Training loss: 0.5168940424919128
Validation loss: 2.2265729705492654

Epoch: 5| Step: 7
Training loss: 0.25222641229629517
Validation loss: 2.2751979430516562

Epoch: 5| Step: 8
Training loss: 0.5772446990013123
Validation loss: 2.2782900631427765

Epoch: 5| Step: 9
Training loss: 0.22976312041282654
Validation loss: 2.243804703156153

Epoch: 5| Step: 10
Training loss: 0.2148233950138092
Validation loss: 2.2591197391351066

Epoch: 5| Step: 11
Training loss: 0.7087187767028809
Validation loss: 2.265033637483915

Epoch: 424| Step: 0
Training loss: 0.220524862408638
Validation loss: 2.204694534341494

Epoch: 5| Step: 1
Training loss: 0.7637133598327637
Validation loss: 2.2293126036723456

Epoch: 5| Step: 2
Training loss: 0.2452818602323532
Validation loss: 2.2415254960457482

Epoch: 5| Step: 3
Training loss: 0.3951888978481293
Validation loss: 2.2055099109808602

Epoch: 5| Step: 4
Training loss: 0.19683924317359924
Validation loss: 2.199666519959768

Epoch: 5| Step: 5
Training loss: 0.2903900742530823
Validation loss: 2.227235068877538

Epoch: 5| Step: 6
Training loss: 0.22487135231494904
Validation loss: 2.3196040938297906

Epoch: 5| Step: 7
Training loss: 0.5436550974845886
Validation loss: 2.335031121969223

Epoch: 5| Step: 8
Training loss: 0.4015291631221771
Validation loss: 2.2511627276738486

Epoch: 5| Step: 9
Training loss: 0.32779309153556824
Validation loss: 2.2725013941526413

Epoch: 5| Step: 10
Training loss: 0.19089199602603912
Validation loss: 2.2330776850382485

Epoch: 5| Step: 11
Training loss: 0.19637376070022583
Validation loss: 2.2790884375572205

Epoch: 425| Step: 0
Training loss: 0.19981038570404053
Validation loss: 2.299441566069921

Epoch: 5| Step: 1
Training loss: 0.2463769167661667
Validation loss: 2.233669549226761

Epoch: 5| Step: 2
Training loss: 0.19357314705848694
Validation loss: 2.27054696281751

Epoch: 5| Step: 3
Training loss: 0.2877265512943268
Validation loss: 2.2752876232067742

Epoch: 5| Step: 4
Training loss: 0.2594526410102844
Validation loss: 2.3009899655977883

Epoch: 5| Step: 5
Training loss: 0.2781657874584198
Validation loss: 2.263937974969546

Epoch: 5| Step: 6
Training loss: 0.4123353064060211
Validation loss: 2.2834398448467255

Epoch: 5| Step: 7
Training loss: 0.5171698927879333
Validation loss: 2.3537754019101462

Epoch: 5| Step: 8
Training loss: 0.4192662835121155
Validation loss: 2.2543049106995263

Epoch: 5| Step: 9
Training loss: 0.5519230365753174
Validation loss: 2.2724921107292175

Epoch: 5| Step: 10
Training loss: 0.2722816467285156
Validation loss: 2.2385655492544174

Epoch: 5| Step: 11
Training loss: 0.2316625714302063
Validation loss: 2.2792649368445077

Epoch: 426| Step: 0
Training loss: 0.5226982831954956
Validation loss: 2.258315106232961

Epoch: 5| Step: 1
Training loss: 0.3110421299934387
Validation loss: 2.2726350327332816

Epoch: 5| Step: 2
Training loss: 0.5158230066299438
Validation loss: 2.28971920410792

Epoch: 5| Step: 3
Training loss: 0.29459840059280396
Validation loss: 2.237729921936989

Epoch: 5| Step: 4
Training loss: 0.29980775713920593
Validation loss: 2.2478770365317664

Epoch: 5| Step: 5
Training loss: 0.3983948826789856
Validation loss: 2.300577849149704

Epoch: 5| Step: 6
Training loss: 0.30280500650405884
Validation loss: 2.268689274787903

Epoch: 5| Step: 7
Training loss: 0.3239167630672455
Validation loss: 2.3264463742574057

Epoch: 5| Step: 8
Training loss: 0.20499148964881897
Validation loss: 2.237365166346232

Epoch: 5| Step: 9
Training loss: 0.25390878319740295
Validation loss: 2.2114924490451813

Epoch: 5| Step: 10
Training loss: 0.196682408452034
Validation loss: 2.257671440641085

Epoch: 5| Step: 11
Training loss: 0.12614265084266663
Validation loss: 2.2525067875782647

Epoch: 427| Step: 0
Training loss: 0.329721063375473
Validation loss: 2.2247463961442313

Epoch: 5| Step: 1
Training loss: 0.2248549461364746
Validation loss: 2.259243463476499

Epoch: 5| Step: 2
Training loss: 0.2937304377555847
Validation loss: 2.27024840315183

Epoch: 5| Step: 3
Training loss: 0.569089949131012
Validation loss: 2.2405781745910645

Epoch: 5| Step: 4
Training loss: 0.3490316867828369
Validation loss: 2.273021345337232

Epoch: 5| Step: 5
Training loss: 0.349472314119339
Validation loss: 2.239253963033358

Epoch: 5| Step: 6
Training loss: 0.303999125957489
Validation loss: 2.249762420852979

Epoch: 5| Step: 7
Training loss: 0.32270580530166626
Validation loss: 2.245954712231954

Epoch: 5| Step: 8
Training loss: 0.21028141677379608
Validation loss: 2.236660639444987

Epoch: 5| Step: 9
Training loss: 0.27711743116378784
Validation loss: 2.2504045267899833

Epoch: 5| Step: 10
Training loss: 0.3504502773284912
Validation loss: 2.247158651550611

Epoch: 5| Step: 11
Training loss: 0.36101406812667847
Validation loss: 2.2435995439688363

Epoch: 428| Step: 0
Training loss: 0.33314499258995056
Validation loss: 2.260580117503802

Epoch: 5| Step: 1
Training loss: 0.20405399799346924
Validation loss: 2.267567286888758

Epoch: 5| Step: 2
Training loss: 0.6424369812011719
Validation loss: 2.32073442141215

Epoch: 5| Step: 3
Training loss: 0.3782985806465149
Validation loss: 2.262021174033483

Epoch: 5| Step: 4
Training loss: 0.3423496186733246
Validation loss: 2.303288072347641

Epoch: 5| Step: 5
Training loss: 0.32774731516838074
Validation loss: 2.2238250573476157

Epoch: 5| Step: 6
Training loss: 0.33555513620376587
Validation loss: 2.2589612205823264

Epoch: 5| Step: 7
Training loss: 0.30076780915260315
Validation loss: 2.2316601425409317

Epoch: 5| Step: 8
Training loss: 0.2492411583662033
Validation loss: 2.210017517209053

Epoch: 5| Step: 9
Training loss: 0.15200890600681305
Validation loss: 2.212467978398005

Epoch: 5| Step: 10
Training loss: 0.3648267388343811
Validation loss: 2.273894543449084

Epoch: 5| Step: 11
Training loss: 0.08097025752067566
Validation loss: 2.232655391097069

Epoch: 429| Step: 0
Training loss: 0.6235100626945496
Validation loss: 2.255334402124087

Epoch: 5| Step: 1
Training loss: 0.22693932056427002
Validation loss: 2.2839314689238868

Epoch: 5| Step: 2
Training loss: 0.29396647214889526
Validation loss: 2.286590650677681

Epoch: 5| Step: 3
Training loss: 0.19745317101478577
Validation loss: 2.2888612349828086

Epoch: 5| Step: 4
Training loss: 0.42231112718582153
Validation loss: 2.25416491429011

Epoch: 5| Step: 5
Training loss: 0.2739546298980713
Validation loss: 2.2519985089699426

Epoch: 5| Step: 6
Training loss: 0.16670982539653778
Validation loss: 2.260227064291636

Epoch: 5| Step: 7
Training loss: 0.422616571187973
Validation loss: 2.22916841506958

Epoch: 5| Step: 8
Training loss: 0.332831472158432
Validation loss: 2.241893450419108

Epoch: 5| Step: 9
Training loss: 0.43340569734573364
Validation loss: 2.2761403024196625

Epoch: 5| Step: 10
Training loss: 0.26046818494796753
Validation loss: 2.2795811692873635

Epoch: 5| Step: 11
Training loss: 0.35036516189575195
Validation loss: 2.2629045446713767

Epoch: 430| Step: 0
Training loss: 0.39860793948173523
Validation loss: 2.2624714970588684

Epoch: 5| Step: 1
Training loss: 0.3338271677494049
Validation loss: 2.3040213783582053

Epoch: 5| Step: 2
Training loss: 0.32293254137039185
Validation loss: 2.244711289803187

Epoch: 5| Step: 3
Training loss: 0.20863571763038635
Validation loss: 2.2884425868590674

Epoch: 5| Step: 4
Training loss: 0.24396295845508575
Validation loss: 2.2474734286467233

Epoch: 5| Step: 5
Training loss: 0.21889562904834747
Validation loss: 2.268031736214956

Epoch: 5| Step: 6
Training loss: 0.2047874480485916
Validation loss: 2.264236549536387

Epoch: 5| Step: 7
Training loss: 0.4047195315361023
Validation loss: 2.269986405968666

Epoch: 5| Step: 8
Training loss: 0.3241080939769745
Validation loss: 2.247194508711497

Epoch: 5| Step: 9
Training loss: 0.2582929730415344
Validation loss: 2.2848472793896994

Epoch: 5| Step: 10
Training loss: 0.21381919085979462
Validation loss: 2.2553434471289315

Epoch: 5| Step: 11
Training loss: 2.1352477073669434
Validation loss: 2.2978176375230155

Epoch: 431| Step: 0
Training loss: 0.27757853269577026
Validation loss: 2.270629271864891

Epoch: 5| Step: 1
Training loss: 0.3170340955257416
Validation loss: 2.2838920752207437

Epoch: 5| Step: 2
Training loss: 0.19716867804527283
Validation loss: 2.250402107834816

Epoch: 5| Step: 3
Training loss: 0.29775387048721313
Validation loss: 2.3154539366563163

Epoch: 5| Step: 4
Training loss: 0.6695123910903931
Validation loss: 2.2736611664295197

Epoch: 5| Step: 5
Training loss: 0.3041691184043884
Validation loss: 2.2455197175343833

Epoch: 5| Step: 6
Training loss: 0.27349987626075745
Validation loss: 2.2192560185988746

Epoch: 5| Step: 7
Training loss: 0.38585901260375977
Validation loss: 2.200420712431272

Epoch: 5| Step: 8
Training loss: 0.7832963466644287
Validation loss: 2.2322211265563965

Epoch: 5| Step: 9
Training loss: 0.34109172224998474
Validation loss: 2.2512956957022348

Epoch: 5| Step: 10
Training loss: 0.3152817189693451
Validation loss: 2.2758299708366394

Epoch: 5| Step: 11
Training loss: 0.6690013408660889
Validation loss: 2.3141622145970664

Epoch: 432| Step: 0
Training loss: 0.2817043662071228
Validation loss: 2.3134012669324875

Epoch: 5| Step: 1
Training loss: 0.2037345916032791
Validation loss: 2.2653065671523414

Epoch: 5| Step: 2
Training loss: 0.4176368713378906
Validation loss: 2.2475416908661523

Epoch: 5| Step: 3
Training loss: 0.7907068133354187
Validation loss: 2.297355736295382

Epoch: 5| Step: 4
Training loss: 0.2516900300979614
Validation loss: 2.248404567440351

Epoch: 5| Step: 5
Training loss: 0.24624690413475037
Validation loss: 2.2688973049322763

Epoch: 5| Step: 6
Training loss: 0.41155806183815
Validation loss: 2.2417212973038354

Epoch: 5| Step: 7
Training loss: 0.2879977226257324
Validation loss: 2.265271087487539

Epoch: 5| Step: 8
Training loss: 0.28736811876296997
Validation loss: 2.238959421714147

Epoch: 5| Step: 9
Training loss: 0.19339363276958466
Validation loss: 2.2279289960861206

Epoch: 5| Step: 10
Training loss: 0.4490489959716797
Validation loss: 2.260824903845787

Epoch: 5| Step: 11
Training loss: 0.252699613571167
Validation loss: 2.290277158220609

Epoch: 433| Step: 0
Training loss: 0.7302241325378418
Validation loss: 2.2596540500720343

Epoch: 5| Step: 1
Training loss: 0.34009045362472534
Validation loss: 2.2884176870187125

Epoch: 5| Step: 2
Training loss: 0.3103220462799072
Validation loss: 2.277330130338669

Epoch: 5| Step: 3
Training loss: 0.23610389232635498
Validation loss: 2.216839457551638

Epoch: 5| Step: 4
Training loss: 0.26506972312927246
Validation loss: 2.2532871067523956

Epoch: 5| Step: 5
Training loss: 0.21122822165489197
Validation loss: 2.2161109000444412

Epoch: 5| Step: 6
Training loss: 0.3573377728462219
Validation loss: 2.2784020602703094

Epoch: 5| Step: 7
Training loss: 0.35185280442237854
Validation loss: 2.2863898078600564

Epoch: 5| Step: 8
Training loss: 0.24098515510559082
Validation loss: 2.2783693075180054

Epoch: 5| Step: 9
Training loss: 0.4069283604621887
Validation loss: 2.2348364194234214

Epoch: 5| Step: 10
Training loss: 0.24210350215435028
Validation loss: 2.3347137918074927

Epoch: 5| Step: 11
Training loss: 0.243583083152771
Validation loss: 2.2960019012292228

Epoch: 434| Step: 0
Training loss: 0.30491387844085693
Validation loss: 2.342870737115542

Epoch: 5| Step: 1
Training loss: 0.34036868810653687
Validation loss: 2.26964279015859

Epoch: 5| Step: 2
Training loss: 0.2666134238243103
Validation loss: 2.3724864522616067

Epoch: 5| Step: 3
Training loss: 0.2106734812259674
Validation loss: 2.293387159705162

Epoch: 5| Step: 4
Training loss: 0.24705061316490173
Validation loss: 2.322644909222921

Epoch: 5| Step: 5
Training loss: 0.24341830611228943
Validation loss: 2.3276293774445853

Epoch: 5| Step: 6
Training loss: 0.2628823518753052
Validation loss: 2.2792137563228607

Epoch: 5| Step: 7
Training loss: 0.2535104751586914
Validation loss: 2.258064935604731

Epoch: 5| Step: 8
Training loss: 0.623923122882843
Validation loss: 2.2517635027567544

Epoch: 5| Step: 9
Training loss: 0.4552384316921234
Validation loss: 2.2710853219032288

Epoch: 5| Step: 10
Training loss: 0.2586096227169037
Validation loss: 2.2631839215755463

Epoch: 5| Step: 11
Training loss: 0.17219315469264984
Validation loss: 2.265710403521856

Epoch: 435| Step: 0
Training loss: 0.31435543298721313
Validation loss: 2.3042186399300895

Epoch: 5| Step: 1
Training loss: 0.20695798099040985
Validation loss: 2.246181070804596

Epoch: 5| Step: 2
Training loss: 0.32105979323387146
Validation loss: 2.2481545756260553

Epoch: 5| Step: 3
Training loss: 0.19780460000038147
Validation loss: 2.200371414422989

Epoch: 5| Step: 4
Training loss: 0.2784135937690735
Validation loss: 2.2450323899586997

Epoch: 5| Step: 5
Training loss: 0.39474034309387207
Validation loss: 2.221822520097097

Epoch: 5| Step: 6
Training loss: 0.5868657827377319
Validation loss: 2.197055141131083

Epoch: 5| Step: 7
Training loss: 0.1933518350124359
Validation loss: 2.237800106406212

Epoch: 5| Step: 8
Training loss: 0.25457802414894104
Validation loss: 2.2618188162644706

Epoch: 5| Step: 9
Training loss: 0.35571080446243286
Validation loss: 2.2801100413004556

Epoch: 5| Step: 10
Training loss: 0.7036300897598267
Validation loss: 2.2634602139393487

Epoch: 5| Step: 11
Training loss: 0.3144068717956543
Validation loss: 2.2559059957663217

Epoch: 436| Step: 0
Training loss: 0.382649302482605
Validation loss: 2.258143121997515

Epoch: 5| Step: 1
Training loss: 0.6338375210762024
Validation loss: 2.257139265537262

Epoch: 5| Step: 2
Training loss: 0.3647763431072235
Validation loss: 2.2428553948799768

Epoch: 5| Step: 3
Training loss: 0.5175876617431641
Validation loss: 2.2008964320023856

Epoch: 5| Step: 4
Training loss: 0.3951728641986847
Validation loss: 2.165929223100344

Epoch: 5| Step: 5
Training loss: 0.40842992067337036
Validation loss: 2.224824825922648

Epoch: 5| Step: 6
Training loss: 0.20531825721263885
Validation loss: 2.245318576693535

Epoch: 5| Step: 7
Training loss: 0.16493093967437744
Validation loss: 2.2702432374159494

Epoch: 5| Step: 8
Training loss: 0.31803926825523376
Validation loss: 2.27182374894619

Epoch: 5| Step: 9
Training loss: 0.28184249997138977
Validation loss: 2.2203043897946677

Epoch: 5| Step: 10
Training loss: 0.28226393461227417
Validation loss: 2.24589437743028

Epoch: 5| Step: 11
Training loss: 0.17998582124710083
Validation loss: 2.2523198227087655

Epoch: 437| Step: 0
Training loss: 0.25806039571762085
Validation loss: 2.254463324944178

Epoch: 5| Step: 1
Training loss: 0.31563884019851685
Validation loss: 2.2478366096814475

Epoch: 5| Step: 2
Training loss: 0.25777846574783325
Validation loss: 2.185750881830851

Epoch: 5| Step: 3
Training loss: 0.28713491559028625
Validation loss: 2.206372315684954

Epoch: 5| Step: 4
Training loss: 0.16576437652111053
Validation loss: 2.2557126879692078

Epoch: 5| Step: 5
Training loss: 0.3028930723667145
Validation loss: 2.187095065911611

Epoch: 5| Step: 6
Training loss: 0.6310210227966309
Validation loss: 2.228733013073603

Epoch: 5| Step: 7
Training loss: 0.47067779302597046
Validation loss: 2.2097292840480804

Epoch: 5| Step: 8
Training loss: 0.19808556139469147
Validation loss: 2.198142558336258

Epoch: 5| Step: 9
Training loss: 0.30599141120910645
Validation loss: 2.248543530702591

Epoch: 5| Step: 10
Training loss: 0.3456435203552246
Validation loss: 2.2216299176216125

Epoch: 5| Step: 11
Training loss: 0.20107483863830566
Validation loss: 2.180088087916374

Epoch: 438| Step: 0
Training loss: 0.281665176153183
Validation loss: 2.2631228864192963

Epoch: 5| Step: 1
Training loss: 0.1903623640537262
Validation loss: 2.2281842480103173

Epoch: 5| Step: 2
Training loss: 0.246901273727417
Validation loss: 2.2313642104466758

Epoch: 5| Step: 3
Training loss: 0.2880312204360962
Validation loss: 2.211109936237335

Epoch: 5| Step: 4
Training loss: 0.38167256116867065
Validation loss: 2.2470691005388894

Epoch: 5| Step: 5
Training loss: 0.3774438500404358
Validation loss: 2.3050191501776376

Epoch: 5| Step: 6
Training loss: 0.8695539236068726
Validation loss: 2.229091410835584

Epoch: 5| Step: 7
Training loss: 0.408381849527359
Validation loss: 2.2506304581960044

Epoch: 5| Step: 8
Training loss: 0.2736165225505829
Validation loss: 2.2595075269540152

Epoch: 5| Step: 9
Training loss: 0.276899516582489
Validation loss: 2.206795503695806

Epoch: 5| Step: 10
Training loss: 0.23650173842906952
Validation loss: 2.2429522027571998

Epoch: 5| Step: 11
Training loss: 0.2298741638660431
Validation loss: 2.1994143625100455

Epoch: 439| Step: 0
Training loss: 0.5676202774047852
Validation loss: 2.2041830718517303

Epoch: 5| Step: 1
Training loss: 0.3806096017360687
Validation loss: 2.20534839729468

Epoch: 5| Step: 2
Training loss: 0.3299880027770996
Validation loss: 2.2500324050585427

Epoch: 5| Step: 3
Training loss: 0.49236422777175903
Validation loss: 2.2360238234202066

Epoch: 5| Step: 4
Training loss: 0.34706276655197144
Validation loss: 2.2850499798854194

Epoch: 5| Step: 5
Training loss: 0.4496811032295227
Validation loss: 2.2987528145313263

Epoch: 5| Step: 6
Training loss: 0.3960363566875458
Validation loss: 2.3444733917713165

Epoch: 5| Step: 7
Training loss: 0.35815590620040894
Validation loss: 2.3014696637789407

Epoch: 5| Step: 8
Training loss: 0.20547592639923096
Validation loss: 2.240136524041494

Epoch: 5| Step: 9
Training loss: 0.24705930054187775
Validation loss: 2.2244988083839417

Epoch: 5| Step: 10
Training loss: 0.24010738730430603
Validation loss: 2.1654059241215386

Epoch: 5| Step: 11
Training loss: 0.31213533878326416
Validation loss: 2.2373778025309243

Epoch: 440| Step: 0
Training loss: 0.63312828540802
Validation loss: 2.227122515439987

Epoch: 5| Step: 1
Training loss: 0.33168715238571167
Validation loss: 2.2062779565652213

Epoch: 5| Step: 2
Training loss: 0.16890418529510498
Validation loss: 2.250118484099706

Epoch: 5| Step: 3
Training loss: 0.22343221306800842
Validation loss: 2.2271577417850494

Epoch: 5| Step: 4
Training loss: 0.2637103199958801
Validation loss: 2.287331447005272

Epoch: 5| Step: 5
Training loss: 0.23633447289466858
Validation loss: 2.299551139275233

Epoch: 5| Step: 6
Training loss: 0.3924666941165924
Validation loss: 2.3376034796237946

Epoch: 5| Step: 7
Training loss: 0.2339390218257904
Validation loss: 2.279798944791158

Epoch: 5| Step: 8
Training loss: 0.5828865170478821
Validation loss: 2.2624135861794152

Epoch: 5| Step: 9
Training loss: 0.22889895737171173
Validation loss: 2.250922034184138

Epoch: 5| Step: 10
Training loss: 0.5501531958580017
Validation loss: 2.248860463500023

Epoch: 5| Step: 11
Training loss: 0.583094596862793
Validation loss: 2.208819940686226

Epoch: 441| Step: 0
Training loss: 0.2787591516971588
Validation loss: 2.2816152572631836

Epoch: 5| Step: 1
Training loss: 0.3969041109085083
Validation loss: 2.209683880209923

Epoch: 5| Step: 2
Training loss: 0.21809951961040497
Validation loss: 2.2342119812965393

Epoch: 5| Step: 3
Training loss: 0.1968078464269638
Validation loss: 2.224355826775233

Epoch: 5| Step: 4
Training loss: 0.341759592294693
Validation loss: 2.2281707177559533

Epoch: 5| Step: 5
Training loss: 0.26204124093055725
Validation loss: 2.268484195073446

Epoch: 5| Step: 6
Training loss: 0.2584892511367798
Validation loss: 2.2563453714052835

Epoch: 5| Step: 7
Training loss: 0.32184237241744995
Validation loss: 2.1959140449762344

Epoch: 5| Step: 8
Training loss: 0.7409237623214722
Validation loss: 2.181069403886795

Epoch: 5| Step: 9
Training loss: 0.20656585693359375
Validation loss: 2.242145578066508

Epoch: 5| Step: 10
Training loss: 0.3067352771759033
Validation loss: 2.214550664027532

Epoch: 5| Step: 11
Training loss: 0.1921931505203247
Validation loss: 2.249909743666649

Epoch: 442| Step: 0
Training loss: 0.4128316044807434
Validation loss: 2.221010128657023

Epoch: 5| Step: 1
Training loss: 0.22424693405628204
Validation loss: 2.2391186952590942

Epoch: 5| Step: 2
Training loss: 0.21371972560882568
Validation loss: 2.2181990643342337

Epoch: 5| Step: 3
Training loss: 0.2521917223930359
Validation loss: 2.2470765908559165

Epoch: 5| Step: 4
Training loss: 0.23982658982276917
Validation loss: 2.2489956418673196

Epoch: 5| Step: 5
Training loss: 0.5453077554702759
Validation loss: 2.2379700442155204

Epoch: 5| Step: 6
Training loss: 0.28736528754234314
Validation loss: 2.2317958573500314

Epoch: 5| Step: 7
Training loss: 0.3947138786315918
Validation loss: 2.239694277445475

Epoch: 5| Step: 8
Training loss: 0.3530779480934143
Validation loss: 2.2579738795757294

Epoch: 5| Step: 9
Training loss: 0.2789134681224823
Validation loss: 2.229236364364624

Epoch: 5| Step: 10
Training loss: 0.1677713245153427
Validation loss: 2.2850972612698874

Epoch: 5| Step: 11
Training loss: 0.13925212621688843
Validation loss: 2.241121922930082

Epoch: 443| Step: 0
Training loss: 0.3836335241794586
Validation loss: 2.247502495845159

Epoch: 5| Step: 1
Training loss: 0.3426418602466583
Validation loss: 2.2065859188636145

Epoch: 5| Step: 2
Training loss: 0.525279700756073
Validation loss: 2.242421751221021

Epoch: 5| Step: 3
Training loss: 0.43619871139526367
Validation loss: 2.219908058643341

Epoch: 5| Step: 4
Training loss: 0.21252202987670898
Validation loss: 2.2338728109995523

Epoch: 5| Step: 5
Training loss: 0.20935563743114471
Validation loss: 2.241024245818456

Epoch: 5| Step: 6
Training loss: 0.377179354429245
Validation loss: 2.2260709007581077

Epoch: 5| Step: 7
Training loss: 0.3006790280342102
Validation loss: 2.2009652853012085

Epoch: 5| Step: 8
Training loss: 0.2535483241081238
Validation loss: 2.1949967245260873

Epoch: 5| Step: 9
Training loss: 0.17543241381645203
Validation loss: 2.2486393650372825

Epoch: 5| Step: 10
Training loss: 0.3094671070575714
Validation loss: 2.2220706393321357

Epoch: 5| Step: 11
Training loss: 0.581572949886322
Validation loss: 2.1935352782408395

Epoch: 444| Step: 0
Training loss: 0.2652292549610138
Validation loss: 2.2215309937795005

Epoch: 5| Step: 1
Training loss: 0.26565733551979065
Validation loss: 2.2451965113480887

Epoch: 5| Step: 2
Training loss: 0.25697770714759827
Validation loss: 2.260569989681244

Epoch: 5| Step: 3
Training loss: 0.2065260410308838
Validation loss: 2.2859775920708976

Epoch: 5| Step: 4
Training loss: 0.26747944951057434
Validation loss: 2.241447081168493

Epoch: 5| Step: 5
Training loss: 0.4251484274864197
Validation loss: 2.2651345233122506

Epoch: 5| Step: 6
Training loss: 0.29143649339675903
Validation loss: 2.238576963543892

Epoch: 5| Step: 7
Training loss: 0.4090493619441986
Validation loss: 2.2196650306383767

Epoch: 5| Step: 8
Training loss: 0.2073327600955963
Validation loss: 2.213230927785238

Epoch: 5| Step: 9
Training loss: 0.48868972063064575
Validation loss: 2.1956891814867654

Epoch: 5| Step: 10
Training loss: 0.5271100401878357
Validation loss: 2.2373639593521752

Epoch: 5| Step: 11
Training loss: 0.1952958106994629
Validation loss: 2.268308386206627

Epoch: 445| Step: 0
Training loss: 0.22994820773601532
Validation loss: 2.2440654883782067

Epoch: 5| Step: 1
Training loss: 0.21581856906414032
Validation loss: 2.254743347565333

Epoch: 5| Step: 2
Training loss: 0.2656816840171814
Validation loss: 2.203446313738823

Epoch: 5| Step: 3
Training loss: 0.24135486781597137
Validation loss: 2.2653604050477347

Epoch: 5| Step: 4
Training loss: 0.19267423450946808
Validation loss: 2.2611259470383325

Epoch: 5| Step: 5
Training loss: 0.2221212387084961
Validation loss: 2.2394444743792215

Epoch: 5| Step: 6
Training loss: 0.3171215355396271
Validation loss: 2.275339365005493

Epoch: 5| Step: 7
Training loss: 0.4229651987552643
Validation loss: 2.259329547484716

Epoch: 5| Step: 8
Training loss: 0.3659486174583435
Validation loss: 2.26279416680336

Epoch: 5| Step: 9
Training loss: 0.5615752339363098
Validation loss: 2.290245989958445

Epoch: 5| Step: 10
Training loss: 0.3436022102832794
Validation loss: 2.24535342057546

Epoch: 5| Step: 11
Training loss: 0.12423229217529297
Validation loss: 2.2466827829678855

Epoch: 446| Step: 0
Training loss: 0.18708749115467072
Validation loss: 2.278495197494825

Epoch: 5| Step: 1
Training loss: 0.1519041210412979
Validation loss: 2.331853171189626

Epoch: 5| Step: 2
Training loss: 0.2191571742296219
Validation loss: 2.281419098377228

Epoch: 5| Step: 3
Training loss: 0.21019677817821503
Validation loss: 2.287643442551295

Epoch: 5| Step: 4
Training loss: 0.2537998557090759
Validation loss: 2.2981489400068917

Epoch: 5| Step: 5
Training loss: 0.3561379015445709
Validation loss: 2.2711016734441123

Epoch: 5| Step: 6
Training loss: 0.1925976276397705
Validation loss: 2.247140094637871

Epoch: 5| Step: 7
Training loss: 0.6764393448829651
Validation loss: 2.2386574745178223

Epoch: 5| Step: 8
Training loss: 0.22678621113300323
Validation loss: 2.2724298437436423

Epoch: 5| Step: 9
Training loss: 0.25790461897850037
Validation loss: 2.2772979736328125

Epoch: 5| Step: 10
Training loss: 0.34249386191368103
Validation loss: 2.2997115651766458

Epoch: 5| Step: 11
Training loss: 0.6443157196044922
Validation loss: 2.3245575626691184

Epoch: 447| Step: 0
Training loss: 0.30452072620391846
Validation loss: 2.2647679497798285

Epoch: 5| Step: 1
Training loss: 0.22329477965831757
Validation loss: 2.276048461596171

Epoch: 5| Step: 2
Training loss: 0.21791592240333557
Validation loss: 2.269581973552704

Epoch: 5| Step: 3
Training loss: 0.1890469193458557
Validation loss: 2.2333685557047525

Epoch: 5| Step: 4
Training loss: 0.6086438298225403
Validation loss: 2.2546152770519257

Epoch: 5| Step: 5
Training loss: 0.2809737026691437
Validation loss: 2.230623339613279

Epoch: 5| Step: 6
Training loss: 0.4086357057094574
Validation loss: 2.275493154923121

Epoch: 5| Step: 7
Training loss: 0.24812142550945282
Validation loss: 2.2474522590637207

Epoch: 5| Step: 8
Training loss: 0.296227365732193
Validation loss: 2.2347903748353324

Epoch: 5| Step: 9
Training loss: 0.48012128472328186
Validation loss: 2.239971160888672

Epoch: 5| Step: 10
Training loss: 0.356875479221344
Validation loss: 2.196820264061292

Epoch: 5| Step: 11
Training loss: 0.17118388414382935
Validation loss: 2.240884785850843

Epoch: 448| Step: 0
Training loss: 0.45164769887924194
Validation loss: 2.2117512176434198

Epoch: 5| Step: 1
Training loss: 0.37972453236579895
Validation loss: 2.2399140000343323

Epoch: 5| Step: 2
Training loss: 0.2622143626213074
Validation loss: 2.240202168623606

Epoch: 5| Step: 3
Training loss: 0.23016193509101868
Validation loss: 2.2409070829550424

Epoch: 5| Step: 4
Training loss: 0.3745630383491516
Validation loss: 2.2573395570119223

Epoch: 5| Step: 5
Training loss: 0.191847026348114
Validation loss: 2.2278464436531067

Epoch: 5| Step: 6
Training loss: 0.24344567954540253
Validation loss: 2.2738380134105682

Epoch: 5| Step: 7
Training loss: 0.13662542402744293
Validation loss: 2.2675668597221375

Epoch: 5| Step: 8
Training loss: 0.3126652240753174
Validation loss: 2.202834645907084

Epoch: 5| Step: 9
Training loss: 0.6027811765670776
Validation loss: 2.2194028943777084

Epoch: 5| Step: 10
Training loss: 0.26379528641700745
Validation loss: 2.2674461752176285

Epoch: 5| Step: 11
Training loss: 0.29060935974121094
Validation loss: 2.2474181751410165

Epoch: 449| Step: 0
Training loss: 0.259602814912796
Validation loss: 2.265096068382263

Epoch: 5| Step: 1
Training loss: 0.31582680344581604
Validation loss: 2.2683228154977164

Epoch: 5| Step: 2
Training loss: 0.3683689534664154
Validation loss: 2.347798893849055

Epoch: 5| Step: 3
Training loss: 0.2946721613407135
Validation loss: 2.311335335175196

Epoch: 5| Step: 4
Training loss: 0.5470895767211914
Validation loss: 2.3168371319770813

Epoch: 5| Step: 5
Training loss: 0.2837475836277008
Validation loss: 2.254815086722374

Epoch: 5| Step: 6
Training loss: 0.2069559395313263
Validation loss: 2.245076129833857

Epoch: 5| Step: 7
Training loss: 0.26402148604393005
Validation loss: 2.2210163871447244

Epoch: 5| Step: 8
Training loss: 0.2626328468322754
Validation loss: 2.252833823362986

Epoch: 5| Step: 9
Training loss: 0.3289344310760498
Validation loss: 2.3419908434152603

Epoch: 5| Step: 10
Training loss: 0.6617823839187622
Validation loss: 2.2902890145778656

Epoch: 5| Step: 11
Training loss: 0.34595823287963867
Validation loss: 2.3344521522521973

Epoch: 450| Step: 0
Training loss: 0.3561890721321106
Validation loss: 2.3346146444479623

Epoch: 5| Step: 1
Training loss: 0.4945950508117676
Validation loss: 2.3292883733908334

Epoch: 5| Step: 2
Training loss: 0.2518985867500305
Validation loss: 2.302608907222748

Epoch: 5| Step: 3
Training loss: 0.3163352608680725
Validation loss: 2.285362496972084

Epoch: 5| Step: 4
Training loss: 0.3849605917930603
Validation loss: 2.291181802749634

Epoch: 5| Step: 5
Training loss: 0.5531952977180481
Validation loss: 2.274612138668696

Epoch: 5| Step: 6
Training loss: 0.29526710510253906
Validation loss: 2.251149147748947

Epoch: 5| Step: 7
Training loss: 0.3637113869190216
Validation loss: 2.265086203813553

Epoch: 5| Step: 8
Training loss: 0.15907159447669983
Validation loss: 2.2624469896157584

Epoch: 5| Step: 9
Training loss: 0.26729387044906616
Validation loss: 2.2540129919846854

Epoch: 5| Step: 10
Training loss: 0.29756268858909607
Validation loss: 2.24212213853995

Epoch: 5| Step: 11
Training loss: 0.18990007042884827
Validation loss: 2.290683537721634

Testing loss: 2.155509206030866
