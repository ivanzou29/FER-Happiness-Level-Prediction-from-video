Epoch: 1| Step: 0
Training loss: 6.015437294149424
Validation loss: 5.50496383119228

Epoch: 6| Step: 1
Training loss: 5.4845038504829144
Validation loss: 5.476314232496044

Epoch: 6| Step: 2
Training loss: 5.482366558213093
Validation loss: 5.449235084354252

Epoch: 6| Step: 3
Training loss: 5.76035835369963
Validation loss: 5.42354816634149

Epoch: 6| Step: 4
Training loss: 5.055885420623633
Validation loss: 5.400782736810198

Epoch: 6| Step: 5
Training loss: 5.741974246677855
Validation loss: 5.378240717297414

Epoch: 6| Step: 6
Training loss: 5.545375223630012
Validation loss: 5.357687785574529

Epoch: 6| Step: 7
Training loss: 5.44419291081748
Validation loss: 5.336561249393302

Epoch: 6| Step: 8
Training loss: 5.234581604481356
Validation loss: 5.314460482411757

Epoch: 6| Step: 9
Training loss: 5.459870721313558
Validation loss: 5.2946385226059265

Epoch: 6| Step: 10
Training loss: 5.979669458956649
Validation loss: 5.274024640587637

Epoch: 6| Step: 11
Training loss: 5.184470153634389
Validation loss: 5.252832919958292

Epoch: 6| Step: 12
Training loss: 5.03596986008064
Validation loss: 5.23368829426432

Epoch: 6| Step: 13
Training loss: 5.088864844948847
Validation loss: 5.21042128355159

Epoch: 2| Step: 0
Training loss: 4.210730269787798
Validation loss: 5.189943833338156

Epoch: 6| Step: 1
Training loss: 5.305891886242698
Validation loss: 5.1664630890803895

Epoch: 6| Step: 2
Training loss: 5.513798484199911
Validation loss: 5.140098258785041

Epoch: 6| Step: 3
Training loss: 5.335623646745246
Validation loss: 5.118349272490841

Epoch: 6| Step: 4
Training loss: 6.040864702689605
Validation loss: 5.093892850218468

Epoch: 6| Step: 5
Training loss: 5.501386641053802
Validation loss: 5.065892185865614

Epoch: 6| Step: 6
Training loss: 4.206059335635637
Validation loss: 5.039439610606379

Epoch: 6| Step: 7
Training loss: 5.048375901531507
Validation loss: 5.012217852863683

Epoch: 6| Step: 8
Training loss: 5.668396442663584
Validation loss: 4.981633946368844

Epoch: 6| Step: 9
Training loss: 5.161349647319465
Validation loss: 4.950482551096256

Epoch: 6| Step: 10
Training loss: 4.374779177951153
Validation loss: 4.9208954658860184

Epoch: 6| Step: 11
Training loss: 5.05479070213183
Validation loss: 4.889043420218177

Epoch: 6| Step: 12
Training loss: 4.3879268949360055
Validation loss: 4.854295535143806

Epoch: 6| Step: 13
Training loss: 5.628168697071049
Validation loss: 4.820729242298437

Epoch: 3| Step: 0
Training loss: 5.369382895134277
Validation loss: 4.7840123393559875

Epoch: 6| Step: 1
Training loss: 4.918627245678777
Validation loss: 4.744768507643067

Epoch: 6| Step: 2
Training loss: 4.682630731047932
Validation loss: 4.706803751363908

Epoch: 6| Step: 3
Training loss: 4.875031691228121
Validation loss: 4.666298863131012

Epoch: 6| Step: 4
Training loss: 4.996053473315467
Validation loss: 4.615561158520644

Epoch: 6| Step: 5
Training loss: 5.307735325990877
Validation loss: 4.572870496141699

Epoch: 6| Step: 6
Training loss: 5.21508953072491
Validation loss: 4.526134435875749

Epoch: 6| Step: 7
Training loss: 4.758088503193655
Validation loss: 4.473640966501655

Epoch: 6| Step: 8
Training loss: 4.4773866650387255
Validation loss: 4.42401190032876

Epoch: 6| Step: 9
Training loss: 4.275179603774705
Validation loss: 4.365485699706044

Epoch: 6| Step: 10
Training loss: 3.4565505216160064
Validation loss: 4.308645709806112

Epoch: 6| Step: 11
Training loss: 3.198254264051627
Validation loss: 4.251078880101685

Epoch: 6| Step: 12
Training loss: 4.2603127514292
Validation loss: 4.194427302131121

Epoch: 6| Step: 13
Training loss: 4.285660525393491
Validation loss: 4.132640851884528

Epoch: 4| Step: 0
Training loss: 4.178989016914404
Validation loss: 4.069071789901734

Epoch: 6| Step: 1
Training loss: 4.197050448547333
Validation loss: 3.9940314864813566

Epoch: 6| Step: 2
Training loss: 4.023805353329653
Validation loss: 3.9299039686278237

Epoch: 6| Step: 3
Training loss: 4.829808012817262
Validation loss: 3.849138777877444

Epoch: 6| Step: 4
Training loss: 3.3511436218429598
Validation loss: 3.76686862865479

Epoch: 6| Step: 5
Training loss: 4.051493126936931
Validation loss: 3.6944029900528417

Epoch: 6| Step: 6
Training loss: 3.6438571187888855
Validation loss: 3.610880550131859

Epoch: 6| Step: 7
Training loss: 2.8991171973001784
Validation loss: 3.531956379774812

Epoch: 6| Step: 8
Training loss: 3.594471469275089
Validation loss: 3.4312353674664045

Epoch: 6| Step: 9
Training loss: 3.39078292830466
Validation loss: 3.3544285160631526

Epoch: 6| Step: 10
Training loss: 3.7020287802560032
Validation loss: 3.2572264902791512

Epoch: 6| Step: 11
Training loss: 3.4459762106952705
Validation loss: 3.1597745497472935

Epoch: 6| Step: 12
Training loss: 2.9306251754646793
Validation loss: 3.06994924426706

Epoch: 6| Step: 13
Training loss: 2.5037661794443475
Validation loss: 2.9827120743223796

Epoch: 5| Step: 0
Training loss: 3.1144654284628577
Validation loss: 2.9011650721237943

Epoch: 6| Step: 1
Training loss: 2.5000179290128584
Validation loss: 2.8199488862457804

Epoch: 6| Step: 2
Training loss: 2.815411057213767
Validation loss: 2.7398033102122317

Epoch: 6| Step: 3
Training loss: 2.938487110264801
Validation loss: 2.675865212861124

Epoch: 6| Step: 4
Training loss: 3.0461966517507855
Validation loss: 2.6155977345712467

Epoch: 6| Step: 5
Training loss: 2.372834272240796
Validation loss: 2.582519454316544

Epoch: 6| Step: 6
Training loss: 1.8819532531056662
Validation loss: 2.54233567756167

Epoch: 6| Step: 7
Training loss: 2.9319029709086135
Validation loss: 2.5218865083528774

Epoch: 6| Step: 8
Training loss: 3.0692820287880376
Validation loss: 2.5335409370067685

Epoch: 6| Step: 9
Training loss: 2.2215445743599025
Validation loss: 2.54498230049259

Epoch: 6| Step: 10
Training loss: 2.2951969582474696
Validation loss: 2.5384593853759823

Epoch: 6| Step: 11
Training loss: 2.4454460716938717
Validation loss: 2.5878675159886066

Epoch: 6| Step: 12
Training loss: 3.4280305305198597
Validation loss: 2.6038635586133525

Epoch: 6| Step: 13
Training loss: 2.6045652364263754
Validation loss: 2.616209631285057

Epoch: 6| Step: 0
Training loss: 2.2451331165838786
Validation loss: 2.617658066080352

Epoch: 6| Step: 1
Training loss: 2.6330086383149065
Validation loss: 2.620580206950008

Epoch: 6| Step: 2
Training loss: 3.110678088237376
Validation loss: 2.645328140588087

Epoch: 6| Step: 3
Training loss: 2.7430519415164967
Validation loss: 2.6380848451601153

Epoch: 6| Step: 4
Training loss: 3.312321784065716
Validation loss: 2.6737885046123324

Epoch: 6| Step: 5
Training loss: 2.3622484709038027
Validation loss: 2.638713603862732

Epoch: 6| Step: 6
Training loss: 2.4588108137839635
Validation loss: 2.62898326078909

Epoch: 6| Step: 7
Training loss: 2.6349691279881133
Validation loss: 2.637953978002344

Epoch: 6| Step: 8
Training loss: 2.676415138619601
Validation loss: 2.5874572160657463

Epoch: 6| Step: 9
Training loss: 2.2037461940410115
Validation loss: 2.5939409882728417

Epoch: 6| Step: 10
Training loss: 2.552824408440022
Validation loss: 2.5887667419295

Epoch: 6| Step: 11
Training loss: 2.1088593029193
Validation loss: 2.561792997195765

Epoch: 6| Step: 12
Training loss: 3.0593659849881543
Validation loss: 2.5346783783719173

Epoch: 6| Step: 13
Training loss: 2.5681492012389424
Validation loss: 2.5374664924551498

Epoch: 7| Step: 0
Training loss: 2.885300800370416
Validation loss: 2.5349710060783974

Epoch: 6| Step: 1
Training loss: 2.625834559427514
Validation loss: 2.5311931713616573

Epoch: 6| Step: 2
Training loss: 2.594341716143907
Validation loss: 2.521415112620442

Epoch: 6| Step: 3
Training loss: 1.9478175568143952
Validation loss: 2.5138990748593093

Epoch: 6| Step: 4
Training loss: 2.9346673171883118
Validation loss: 2.5363890046365096

Epoch: 6| Step: 5
Training loss: 2.914745261052604
Validation loss: 2.519750809282401

Epoch: 6| Step: 6
Training loss: 3.044069847518658
Validation loss: 2.5338957503155095

Epoch: 6| Step: 7
Training loss: 2.4952138863356006
Validation loss: 2.5268855360026756

Epoch: 6| Step: 8
Training loss: 2.4741373311924004
Validation loss: 2.5274730022383345

Epoch: 6| Step: 9
Training loss: 2.584755065352183
Validation loss: 2.52316328355901

Epoch: 6| Step: 10
Training loss: 2.3212927600412283
Validation loss: 2.5337223490464167

Epoch: 6| Step: 11
Training loss: 2.3738176514766582
Validation loss: 2.5289442290309188

Epoch: 6| Step: 12
Training loss: 2.8383666004942474
Validation loss: 2.538191691993048

Epoch: 6| Step: 13
Training loss: 1.8084406283259093
Validation loss: 2.5374130603698215

Epoch: 8| Step: 0
Training loss: 1.9998265429618676
Validation loss: 2.517621403241523

Epoch: 6| Step: 1
Training loss: 2.8053936507675
Validation loss: 2.52611271604266

Epoch: 6| Step: 2
Training loss: 2.7390156630381224
Validation loss: 2.5164072546196485

Epoch: 6| Step: 3
Training loss: 3.056310666346141
Validation loss: 2.526165600649874

Epoch: 6| Step: 4
Training loss: 2.85396426706059
Validation loss: 2.521143142851539

Epoch: 6| Step: 5
Training loss: 2.4588071291113796
Validation loss: 2.5165168966060465

Epoch: 6| Step: 6
Training loss: 2.5144343431312675
Validation loss: 2.519121382147828

Epoch: 6| Step: 7
Training loss: 2.394422419752339
Validation loss: 2.499034806534115

Epoch: 6| Step: 8
Training loss: 1.8190511500049218
Validation loss: 2.5159810132198235

Epoch: 6| Step: 9
Training loss: 2.9149185027938067
Validation loss: 2.504748396709272

Epoch: 6| Step: 10
Training loss: 2.832154832971673
Validation loss: 2.510243110408446

Epoch: 6| Step: 11
Training loss: 2.286547323825382
Validation loss: 2.5104134481786673

Epoch: 6| Step: 12
Training loss: 3.189242914938183
Validation loss: 2.53323174438153

Epoch: 6| Step: 13
Training loss: 2.16316220943408
Validation loss: 2.5119937016520537

Epoch: 9| Step: 0
Training loss: 2.1683171172809916
Validation loss: 2.5197611701405624

Epoch: 6| Step: 1
Training loss: 2.927797730353947
Validation loss: 2.4998463821897987

Epoch: 6| Step: 2
Training loss: 2.827754549665132
Validation loss: 2.505243064549739

Epoch: 6| Step: 3
Training loss: 2.628990228680502
Validation loss: 2.5006338428613324

Epoch: 6| Step: 4
Training loss: 2.2409606128926893
Validation loss: 2.503420413170902

Epoch: 6| Step: 5
Training loss: 2.7335576170882447
Validation loss: 2.4935189799011024

Epoch: 6| Step: 6
Training loss: 2.5678849743070606
Validation loss: 2.5135903670052127

Epoch: 6| Step: 7
Training loss: 1.973880440845133
Validation loss: 2.4992972339876585

Epoch: 6| Step: 8
Training loss: 2.283152688206015
Validation loss: 2.498863613617491

Epoch: 6| Step: 9
Training loss: 2.8051742938828736
Validation loss: 2.500767248357402

Epoch: 6| Step: 10
Training loss: 2.6981460493414104
Validation loss: 2.5123575129047873

Epoch: 6| Step: 11
Training loss: 2.478030182033473
Validation loss: 2.5227555336646272

Epoch: 6| Step: 12
Training loss: 3.093164870289801
Validation loss: 2.493620951539399

Epoch: 6| Step: 13
Training loss: 2.1458546041773863
Validation loss: 2.5088330467073767

Epoch: 10| Step: 0
Training loss: 2.591949389411002
Validation loss: 2.4897668257465666

Epoch: 6| Step: 1
Training loss: 2.2195119489712094
Validation loss: 2.4996514713211933

Epoch: 6| Step: 2
Training loss: 2.711455809545252
Validation loss: 2.4894367770760555

Epoch: 6| Step: 3
Training loss: 2.842077916461782
Validation loss: 2.5096204188751985

Epoch: 6| Step: 4
Training loss: 2.4541171066210867
Validation loss: 2.492046675096471

Epoch: 6| Step: 5
Training loss: 3.2262824354939323
Validation loss: 2.4972928012336038

Epoch: 6| Step: 6
Training loss: 2.8687645007994926
Validation loss: 2.494009231057784

Epoch: 6| Step: 7
Training loss: 2.5225741678152707
Validation loss: 2.5126755445908344

Epoch: 6| Step: 8
Training loss: 2.02199169924699
Validation loss: 2.512229713211503

Epoch: 6| Step: 9
Training loss: 1.685655362736585
Validation loss: 2.516479583969688

Epoch: 6| Step: 10
Training loss: 1.9472258935852316
Validation loss: 2.4955980806708453

Epoch: 6| Step: 11
Training loss: 2.5969185835833866
Validation loss: 2.5077370447075102

Epoch: 6| Step: 12
Training loss: 3.1918829908508104
Validation loss: 2.508008796718042

Epoch: 6| Step: 13
Training loss: 2.521832123761812
Validation loss: 2.5032642352764474

Epoch: 11| Step: 0
Training loss: 2.301671424251264
Validation loss: 2.495358545383715

Epoch: 6| Step: 1
Training loss: 2.380034281059017
Validation loss: 2.503098617967123

Epoch: 6| Step: 2
Training loss: 2.4846626930883984
Validation loss: 2.4967675292145612

Epoch: 6| Step: 3
Training loss: 2.676758881338714
Validation loss: 2.5044721022534837

Epoch: 6| Step: 4
Training loss: 1.8530690305340594
Validation loss: 2.482623012346722

Epoch: 6| Step: 5
Training loss: 2.527456195576224
Validation loss: 2.4946589477745182

Epoch: 6| Step: 6
Training loss: 2.9054272215076287
Validation loss: 2.4961083003313034

Epoch: 6| Step: 7
Training loss: 2.830653961970094
Validation loss: 2.482997488400821

Epoch: 6| Step: 8
Training loss: 2.642354725983021
Validation loss: 2.484158104599516

Epoch: 6| Step: 9
Training loss: 2.827438355439176
Validation loss: 2.485154835247783

Epoch: 6| Step: 10
Training loss: 2.196330747297838
Validation loss: 2.4964648047085864

Epoch: 6| Step: 11
Training loss: 2.5940687604157002
Validation loss: 2.505287229970329

Epoch: 6| Step: 12
Training loss: 2.5321239328532332
Validation loss: 2.4729936479018226

Epoch: 6| Step: 13
Training loss: 2.7911693832297075
Validation loss: 2.4963435932022784

Epoch: 12| Step: 0
Training loss: 2.207696810942438
Validation loss: 2.502911811096992

Epoch: 6| Step: 1
Training loss: 2.7144602113577183
Validation loss: 2.47385562616608

Epoch: 6| Step: 2
Training loss: 2.63690293410524
Validation loss: 2.491139046890189

Epoch: 6| Step: 3
Training loss: 1.89227506653881
Validation loss: 2.488798238483804

Epoch: 6| Step: 4
Training loss: 2.8842465521914256
Validation loss: 2.491963184111271

Epoch: 6| Step: 5
Training loss: 3.172797458853115
Validation loss: 2.476395305521348

Epoch: 6| Step: 6
Training loss: 2.8483929302601934
Validation loss: 2.4956810201574613

Epoch: 6| Step: 7
Training loss: 2.5354991146109422
Validation loss: 2.4948556184369908

Epoch: 6| Step: 8
Training loss: 2.4446494083979546
Validation loss: 2.509741305816028

Epoch: 6| Step: 9
Training loss: 2.715859202655521
Validation loss: 2.492463019915187

Epoch: 6| Step: 10
Training loss: 1.752068795390677
Validation loss: 2.496784160490965

Epoch: 6| Step: 11
Training loss: 2.39854883190304
Validation loss: 2.4981174851718797

Epoch: 6| Step: 12
Training loss: 2.2467059288027835
Validation loss: 2.4940012646692042

Epoch: 6| Step: 13
Training loss: 2.6038201877255895
Validation loss: 2.500803039640173

Epoch: 13| Step: 0
Training loss: 2.590955308717941
Validation loss: 2.4862630615351575

Epoch: 6| Step: 1
Training loss: 2.5004474239516195
Validation loss: 2.487316054183535

Epoch: 6| Step: 2
Training loss: 2.7135726917174825
Validation loss: 2.497834618890987

Epoch: 6| Step: 3
Training loss: 2.3379390650983694
Validation loss: 2.506410470266194

Epoch: 6| Step: 4
Training loss: 1.9108826673848824
Validation loss: 2.493482327097933

Epoch: 6| Step: 5
Training loss: 2.491646352151415
Validation loss: 2.5030108917554106

Epoch: 6| Step: 6
Training loss: 2.63997592510459
Validation loss: 2.4782231937178425

Epoch: 6| Step: 7
Training loss: 1.6575594350247742
Validation loss: 2.490961823768017

Epoch: 6| Step: 8
Training loss: 2.677618801925564
Validation loss: 2.4815265632707506

Epoch: 6| Step: 9
Training loss: 2.653216525993944
Validation loss: 2.4772682187249075

Epoch: 6| Step: 10
Training loss: 3.335158674820505
Validation loss: 2.4921331768433346

Epoch: 6| Step: 11
Training loss: 2.1095373020603785
Validation loss: 2.479227086674641

Epoch: 6| Step: 12
Training loss: 2.269686721492793
Validation loss: 2.4751360422372315

Epoch: 6| Step: 13
Training loss: 3.1850103491311086
Validation loss: 2.4972693312146212

Epoch: 14| Step: 0
Training loss: 2.8403403833065486
Validation loss: 2.475520110148597

Epoch: 6| Step: 1
Training loss: 2.935688515378662
Validation loss: 2.482849852543252

Epoch: 6| Step: 2
Training loss: 2.907905353291467
Validation loss: 2.4823811685549617

Epoch: 6| Step: 3
Training loss: 1.5786283842167264
Validation loss: 2.473734495510495

Epoch: 6| Step: 4
Training loss: 1.836789716601412
Validation loss: 2.4650996781133756

Epoch: 6| Step: 5
Training loss: 2.8169962229352987
Validation loss: 2.4814373458099888

Epoch: 6| Step: 6
Training loss: 1.8633340952035147
Validation loss: 2.489183917918628

Epoch: 6| Step: 7
Training loss: 3.2391142837794082
Validation loss: 2.4848821670155354

Epoch: 6| Step: 8
Training loss: 3.2724851256193515
Validation loss: 2.487855276937875

Epoch: 6| Step: 9
Training loss: 2.518200616105981
Validation loss: 2.470465470495354

Epoch: 6| Step: 10
Training loss: 2.3712284860554993
Validation loss: 2.4573820558110304

Epoch: 6| Step: 11
Training loss: 1.9365528621929293
Validation loss: 2.4713561711572867

Epoch: 6| Step: 12
Training loss: 2.293609061835503
Validation loss: 2.4819231070002323

Epoch: 6| Step: 13
Training loss: 2.1179518780235047
Validation loss: 2.4803044382375816

Epoch: 15| Step: 0
Training loss: 2.000337214651709
Validation loss: 2.4829378829803277

Epoch: 6| Step: 1
Training loss: 3.192435239943086
Validation loss: 2.4780472918429437

Epoch: 6| Step: 2
Training loss: 2.6570094201061303
Validation loss: 2.4857579666547664

Epoch: 6| Step: 3
Training loss: 1.9636134396765865
Validation loss: 2.4909302859827407

Epoch: 6| Step: 4
Training loss: 3.0280631705665266
Validation loss: 2.4928521652161573

Epoch: 6| Step: 5
Training loss: 2.9536051687796716
Validation loss: 2.5059889266593225

Epoch: 6| Step: 6
Training loss: 1.96815499896739
Validation loss: 2.4822683779613453

Epoch: 6| Step: 7
Training loss: 2.0858965808983947
Validation loss: 2.4939327686102

Epoch: 6| Step: 8
Training loss: 2.271818548075717
Validation loss: 2.496098207440921

Epoch: 6| Step: 9
Training loss: 2.369324276843318
Validation loss: 2.4930785209662956

Epoch: 6| Step: 10
Training loss: 2.5101337088728317
Validation loss: 2.498611207497537

Epoch: 6| Step: 11
Training loss: 3.1787881915055425
Validation loss: 2.50289871329616

Epoch: 6| Step: 12
Training loss: 1.8954634742326923
Validation loss: 2.503012217355321

Epoch: 6| Step: 13
Training loss: 2.706936216681668
Validation loss: 2.4949666056822166

Epoch: 16| Step: 0
Training loss: 1.8093884824998272
Validation loss: 2.4845793058251964

Epoch: 6| Step: 1
Training loss: 2.6966743014415773
Validation loss: 2.4841204658809497

Epoch: 6| Step: 2
Training loss: 2.932069669533292
Validation loss: 2.476292287563989

Epoch: 6| Step: 3
Training loss: 2.1623085157698023
Validation loss: 2.4614591499765286

Epoch: 6| Step: 4
Training loss: 2.7816801274337535
Validation loss: 2.4927233176784633

Epoch: 6| Step: 5
Training loss: 2.2162411972189506
Validation loss: 2.474164104269758

Epoch: 6| Step: 6
Training loss: 2.497437403508272
Validation loss: 2.4905650439159532

Epoch: 6| Step: 7
Training loss: 2.485151253593001
Validation loss: 2.4815835365050996

Epoch: 6| Step: 8
Training loss: 2.2054656020279517
Validation loss: 2.4818508913163995

Epoch: 6| Step: 9
Training loss: 2.388860213184008
Validation loss: 2.4830619252999653

Epoch: 6| Step: 10
Training loss: 2.3139734471280504
Validation loss: 2.4880861438412056

Epoch: 6| Step: 11
Training loss: 2.79060675774194
Validation loss: 2.47631613291163

Epoch: 6| Step: 12
Training loss: 2.3540320118791205
Validation loss: 2.4717539446188925

Epoch: 6| Step: 13
Training loss: 3.112390330883539
Validation loss: 2.4696842148241007

Epoch: 17| Step: 0
Training loss: 2.612643998115448
Validation loss: 2.4809655520523

Epoch: 6| Step: 1
Training loss: 2.3390645304271622
Validation loss: 2.477477777986407

Epoch: 6| Step: 2
Training loss: 2.9388786489608365
Validation loss: 2.4564953954027033

Epoch: 6| Step: 3
Training loss: 1.9015698121681772
Validation loss: 2.4639685881204993

Epoch: 6| Step: 4
Training loss: 2.4969097111166736
Validation loss: 2.460965837587963

Epoch: 6| Step: 5
Training loss: 2.6805496830675524
Validation loss: 2.4619560919037355

Epoch: 6| Step: 6
Training loss: 2.123315030931834
Validation loss: 2.477567787590302

Epoch: 6| Step: 7
Training loss: 2.3935385508559484
Validation loss: 2.472277925223358

Epoch: 6| Step: 8
Training loss: 2.585123631308172
Validation loss: 2.4602675883462948

Epoch: 6| Step: 9
Training loss: 2.3315128536176832
Validation loss: 2.473018947072659

Epoch: 6| Step: 10
Training loss: 2.904406875753939
Validation loss: 2.462166082911443

Epoch: 6| Step: 11
Training loss: 2.6744793251480803
Validation loss: 2.4798464657828707

Epoch: 6| Step: 12
Training loss: 2.6990183246579855
Validation loss: 2.473806667029014

Epoch: 6| Step: 13
Training loss: 2.0896819720530995
Validation loss: 2.465894020917742

Epoch: 18| Step: 0
Training loss: 2.726026422217229
Validation loss: 2.4808194130363996

Epoch: 6| Step: 1
Training loss: 2.5805784631193034
Validation loss: 2.48018033811451

Epoch: 6| Step: 2
Training loss: 2.354200942428565
Validation loss: 2.4833253766472185

Epoch: 6| Step: 3
Training loss: 1.7494939344834648
Validation loss: 2.4688953324688887

Epoch: 6| Step: 4
Training loss: 2.831608602621906
Validation loss: 2.4620965317287213

Epoch: 6| Step: 5
Training loss: 2.1920086853662766
Validation loss: 2.457570852148908

Epoch: 6| Step: 6
Training loss: 2.733684081934223
Validation loss: 2.474522758479434

Epoch: 6| Step: 7
Training loss: 2.2598464410651498
Validation loss: 2.4662364928282816

Epoch: 6| Step: 8
Training loss: 2.931763912609988
Validation loss: 2.483912066947789

Epoch: 6| Step: 9
Training loss: 2.4984650668209296
Validation loss: 2.464359386993492

Epoch: 6| Step: 10
Training loss: 2.049567395596992
Validation loss: 2.4832368558879327

Epoch: 6| Step: 11
Training loss: 2.606828189082944
Validation loss: 2.4715326939459765

Epoch: 6| Step: 12
Training loss: 2.8054283247531293
Validation loss: 2.457369119594019

Epoch: 6| Step: 13
Training loss: 2.3305708563262826
Validation loss: 2.4835761683312625

Epoch: 19| Step: 0
Training loss: 2.457714089025816
Validation loss: 2.4747517059831026

Epoch: 6| Step: 1
Training loss: 2.2769063068156954
Validation loss: 2.4752633972524603

Epoch: 6| Step: 2
Training loss: 2.6183932587168224
Validation loss: 2.4549781457274005

Epoch: 6| Step: 3
Training loss: 2.3310598014580477
Validation loss: 2.478909348242365

Epoch: 6| Step: 4
Training loss: 3.101025282603276
Validation loss: 2.4655089853484418

Epoch: 6| Step: 5
Training loss: 2.213270917303471
Validation loss: 2.4805913939906405

Epoch: 6| Step: 6
Training loss: 1.9561470760289577
Validation loss: 2.467625615440583

Epoch: 6| Step: 7
Training loss: 2.3953194993247173
Validation loss: 2.471752047625653

Epoch: 6| Step: 8
Training loss: 2.477106943063429
Validation loss: 2.4728660715439426

Epoch: 6| Step: 9
Training loss: 2.693891864059161
Validation loss: 2.4559446842340766

Epoch: 6| Step: 10
Training loss: 2.3872177676206974
Validation loss: 2.459846771567275

Epoch: 6| Step: 11
Training loss: 2.8281535784715848
Validation loss: 2.4744729935564975

Epoch: 6| Step: 12
Training loss: 2.2927273000937585
Validation loss: 2.4768231853385627

Epoch: 6| Step: 13
Training loss: 2.7205026173423903
Validation loss: 2.472321289258778

Epoch: 20| Step: 0
Training loss: 2.7898121742548994
Validation loss: 2.47058358487525

Epoch: 6| Step: 1
Training loss: 2.9352492779957564
Validation loss: 2.4601657121431337

Epoch: 6| Step: 2
Training loss: 2.500371428554406
Validation loss: 2.4688594970885935

Epoch: 6| Step: 3
Training loss: 2.572123252039381
Validation loss: 2.476842196582053

Epoch: 6| Step: 4
Training loss: 2.274936876364457
Validation loss: 2.471682058810741

Epoch: 6| Step: 5
Training loss: 2.5049739947463463
Validation loss: 2.459011830163241

Epoch: 6| Step: 6
Training loss: 2.664401930499097
Validation loss: 2.46122044142731

Epoch: 6| Step: 7
Training loss: 2.306981693798731
Validation loss: 2.456635120280742

Epoch: 6| Step: 8
Training loss: 2.780112816284755
Validation loss: 2.45694256629055

Epoch: 6| Step: 9
Training loss: 2.178205526387615
Validation loss: 2.4637880477664083

Epoch: 6| Step: 10
Training loss: 2.497395493895528
Validation loss: 2.4473600417563817

Epoch: 6| Step: 11
Training loss: 1.9930190800405705
Validation loss: 2.462567874211856

Epoch: 6| Step: 12
Training loss: 2.0090330696175447
Validation loss: 2.46559238903815

Epoch: 6| Step: 13
Training loss: 2.6248019007456467
Validation loss: 2.4670810128074194

Epoch: 21| Step: 0
Training loss: 2.2181670806668072
Validation loss: 2.4805731643767515

Epoch: 6| Step: 1
Training loss: 2.4300433815117484
Validation loss: 2.452457045471565

Epoch: 6| Step: 2
Training loss: 2.112450963641879
Validation loss: 2.470285316493053

Epoch: 6| Step: 3
Training loss: 2.1030968946191564
Validation loss: 2.458598321975677

Epoch: 6| Step: 4
Training loss: 2.5616427592657476
Validation loss: 2.467497834008531

Epoch: 6| Step: 5
Training loss: 3.3417212490529593
Validation loss: 2.4787325492343357

Epoch: 6| Step: 6
Training loss: 2.071005075600454
Validation loss: 2.48345147967649

Epoch: 6| Step: 7
Training loss: 2.8946748973296583
Validation loss: 2.4882910871485953

Epoch: 6| Step: 8
Training loss: 2.5955027896908
Validation loss: 2.4758628153663964

Epoch: 6| Step: 9
Training loss: 2.7361822640794937
Validation loss: 2.517218541167633

Epoch: 6| Step: 10
Training loss: 3.115021911837936
Validation loss: 2.509450819011019

Epoch: 6| Step: 11
Training loss: 1.9235768420322488
Validation loss: 2.478132013324628

Epoch: 6| Step: 12
Training loss: 2.295497455247363
Validation loss: 2.4670673865372175

Epoch: 6| Step: 13
Training loss: 2.0969314317457686
Validation loss: 2.474486289994003

Epoch: 22| Step: 0
Training loss: 3.1253777847817727
Validation loss: 2.4710990256857115

Epoch: 6| Step: 1
Training loss: 2.2574502726978536
Validation loss: 2.4708233026319135

Epoch: 6| Step: 2
Training loss: 1.951879791048676
Validation loss: 2.458393344038926

Epoch: 6| Step: 3
Training loss: 2.951483537739515
Validation loss: 2.4683184186118634

Epoch: 6| Step: 4
Training loss: 2.215637818206596
Validation loss: 2.4588103451197747

Epoch: 6| Step: 5
Training loss: 2.1337291717853586
Validation loss: 2.462354399480165

Epoch: 6| Step: 6
Training loss: 2.66404656995558
Validation loss: 2.467131925427661

Epoch: 6| Step: 7
Training loss: 2.2854325086751053
Validation loss: 2.4692351592863067

Epoch: 6| Step: 8
Training loss: 2.5294282739155305
Validation loss: 2.4720387343084873

Epoch: 6| Step: 9
Training loss: 2.114746262861486
Validation loss: 2.467633328814942

Epoch: 6| Step: 10
Training loss: 2.9812474664641355
Validation loss: 2.468402443737604

Epoch: 6| Step: 11
Training loss: 2.349101353342151
Validation loss: 2.469773092619709

Epoch: 6| Step: 12
Training loss: 2.717531830180996
Validation loss: 2.4562796619232343

Epoch: 6| Step: 13
Training loss: 2.2978586179768437
Validation loss: 2.4615086291374557

Epoch: 23| Step: 0
Training loss: 2.8141219654398153
Validation loss: 2.457525206676215

Epoch: 6| Step: 1
Training loss: 2.5642586232646862
Validation loss: 2.4694753458497134

Epoch: 6| Step: 2
Training loss: 1.7992304746483483
Validation loss: 2.4633160273400434

Epoch: 6| Step: 3
Training loss: 2.5175875951383175
Validation loss: 2.4792446850807566

Epoch: 6| Step: 4
Training loss: 1.823433227011047
Validation loss: 2.484954166680469

Epoch: 6| Step: 5
Training loss: 2.9824079651873565
Validation loss: 2.5027976594738095

Epoch: 6| Step: 6
Training loss: 2.888570354294911
Validation loss: 2.5048259805499526

Epoch: 6| Step: 7
Training loss: 2.6936663479661025
Validation loss: 2.4904887310100654

Epoch: 6| Step: 8
Training loss: 2.712492922584688
Validation loss: 2.480474661271869

Epoch: 6| Step: 9
Training loss: 2.3223311252195655
Validation loss: 2.473046326766503

Epoch: 6| Step: 10
Training loss: 2.2959165065351286
Validation loss: 2.484547447121566

Epoch: 6| Step: 11
Training loss: 2.675004877103834
Validation loss: 2.476948544551615

Epoch: 6| Step: 12
Training loss: 2.054791698061951
Validation loss: 2.4682214710389045

Epoch: 6| Step: 13
Training loss: 2.2606824961747156
Validation loss: 2.4735771019313746

Epoch: 24| Step: 0
Training loss: 2.3114332883376814
Validation loss: 2.473757674796606

Epoch: 6| Step: 1
Training loss: 1.8875203769417594
Validation loss: 2.482094027492079

Epoch: 6| Step: 2
Training loss: 2.6457412183050484
Validation loss: 2.4730347177490573

Epoch: 6| Step: 3
Training loss: 3.032688075033306
Validation loss: 2.460457697522725

Epoch: 6| Step: 4
Training loss: 2.555347602326028
Validation loss: 2.488470225042538

Epoch: 6| Step: 5
Training loss: 2.2919767921298027
Validation loss: 2.4743349825931387

Epoch: 6| Step: 6
Training loss: 2.484271833089111
Validation loss: 2.4790116884105533

Epoch: 6| Step: 7
Training loss: 2.133625252937053
Validation loss: 2.48496161838674

Epoch: 6| Step: 8
Training loss: 2.119052867566544
Validation loss: 2.4919954582691393

Epoch: 6| Step: 9
Training loss: 2.5744507472338367
Validation loss: 2.487510653653486

Epoch: 6| Step: 10
Training loss: 2.5646689934967464
Validation loss: 2.4611691643398332

Epoch: 6| Step: 11
Training loss: 2.6275942562484738
Validation loss: 2.500590922136083

Epoch: 6| Step: 12
Training loss: 2.448637922369439
Validation loss: 2.46200113875143

Epoch: 6| Step: 13
Training loss: 2.7323581778114354
Validation loss: 2.4535492775130594

Epoch: 25| Step: 0
Training loss: 3.11550406601037
Validation loss: 2.4691033251342493

Epoch: 6| Step: 1
Training loss: 2.4175740106214483
Validation loss: 2.4710897954795987

Epoch: 6| Step: 2
Training loss: 2.1324328409511497
Validation loss: 2.4478026722006563

Epoch: 6| Step: 3
Training loss: 2.235875406209453
Validation loss: 2.465749712144209

Epoch: 6| Step: 4
Training loss: 2.6396517794154297
Validation loss: 2.457879773557325

Epoch: 6| Step: 5
Training loss: 2.1383226919566005
Validation loss: 2.44981089141108

Epoch: 6| Step: 6
Training loss: 3.0824081132470647
Validation loss: 2.4789894238326267

Epoch: 6| Step: 7
Training loss: 2.5970331577656416
Validation loss: 2.4723942734883697

Epoch: 6| Step: 8
Training loss: 2.7384629563407885
Validation loss: 2.4600878182168264

Epoch: 6| Step: 9
Training loss: 1.776964956308333
Validation loss: 2.468743408773774

Epoch: 6| Step: 10
Training loss: 2.2157233642781438
Validation loss: 2.4580422622434823

Epoch: 6| Step: 11
Training loss: 2.5840525600118998
Validation loss: 2.462225795783232

Epoch: 6| Step: 12
Training loss: 2.4938753445514026
Validation loss: 2.467576275039212

Epoch: 6| Step: 13
Training loss: 2.2633127976030405
Validation loss: 2.464700975832272

Epoch: 26| Step: 0
Training loss: 2.651224925683859
Validation loss: 2.4563147829942578

Epoch: 6| Step: 1
Training loss: 1.9637780759711723
Validation loss: 2.443639375828339

Epoch: 6| Step: 2
Training loss: 2.434798871453984
Validation loss: 2.4624833434004705

Epoch: 6| Step: 3
Training loss: 2.785535789192725
Validation loss: 2.4827225665830746

Epoch: 6| Step: 4
Training loss: 2.0637640114209828
Validation loss: 2.5158669333685024

Epoch: 6| Step: 5
Training loss: 2.333197476201202
Validation loss: 2.5037268992447212

Epoch: 6| Step: 6
Training loss: 2.877781393309899
Validation loss: 2.5104094356153084

Epoch: 6| Step: 7
Training loss: 1.4964423109738083
Validation loss: 2.5170356791527144

Epoch: 6| Step: 8
Training loss: 2.7626461214801465
Validation loss: 2.5379832081726486

Epoch: 6| Step: 9
Training loss: 2.5816397088722085
Validation loss: 2.5194606564117135

Epoch: 6| Step: 10
Training loss: 2.490926393582976
Validation loss: 2.517488709354684

Epoch: 6| Step: 11
Training loss: 2.5624964644244854
Validation loss: 2.501583805664625

Epoch: 6| Step: 12
Training loss: 2.9308584899372248
Validation loss: 2.470865268940471

Epoch: 6| Step: 13
Training loss: 2.576904285309835
Validation loss: 2.4831912021371734

Epoch: 27| Step: 0
Training loss: 2.5974989305628022
Validation loss: 2.4737251626943277

Epoch: 6| Step: 1
Training loss: 2.5157434660697726
Validation loss: 2.4705172784238782

Epoch: 6| Step: 2
Training loss: 2.2045733513537313
Validation loss: 2.466285908368826

Epoch: 6| Step: 3
Training loss: 2.473274045303882
Validation loss: 2.464319881784155

Epoch: 6| Step: 4
Training loss: 2.6731025597462352
Validation loss: 2.463920795282349

Epoch: 6| Step: 5
Training loss: 2.227056722835886
Validation loss: 2.4636685188866965

Epoch: 6| Step: 6
Training loss: 2.6415623011465437
Validation loss: 2.4515513983710773

Epoch: 6| Step: 7
Training loss: 2.391882472209757
Validation loss: 2.4632128818040493

Epoch: 6| Step: 8
Training loss: 2.6881645622969694
Validation loss: 2.4541058047594815

Epoch: 6| Step: 9
Training loss: 2.1900090678127455
Validation loss: 2.457030603098418

Epoch: 6| Step: 10
Training loss: 1.8892541124017188
Validation loss: 2.4404945807589256

Epoch: 6| Step: 11
Training loss: 2.3806442651747806
Validation loss: 2.4689022129955225

Epoch: 6| Step: 12
Training loss: 2.3472875727698526
Validation loss: 2.4474213011015182

Epoch: 6| Step: 13
Training loss: 2.948145467732821
Validation loss: 2.4642966459754483

Epoch: 28| Step: 0
Training loss: 2.6089270658405703
Validation loss: 2.4648579125015115

Epoch: 6| Step: 1
Training loss: 2.8347093008584734
Validation loss: 2.453706222975402

Epoch: 6| Step: 2
Training loss: 2.179355500344334
Validation loss: 2.450216589975037

Epoch: 6| Step: 3
Training loss: 2.4323071650161734
Validation loss: 2.468111301647177

Epoch: 6| Step: 4
Training loss: 2.2807004083662914
Validation loss: 2.483693635221324

Epoch: 6| Step: 5
Training loss: 1.9722317380481567
Validation loss: 2.462352947097948

Epoch: 6| Step: 6
Training loss: 2.31266340760945
Validation loss: 2.4534763400451194

Epoch: 6| Step: 7
Training loss: 2.2192878608495032
Validation loss: 2.4537436318764274

Epoch: 6| Step: 8
Training loss: 2.3367932643507303
Validation loss: 2.464136988599041

Epoch: 6| Step: 9
Training loss: 2.459346971752018
Validation loss: 2.4729855093710773

Epoch: 6| Step: 10
Training loss: 2.2247827745332494
Validation loss: 2.4629412854334043

Epoch: 6| Step: 11
Training loss: 2.7709852095738885
Validation loss: 2.4722189534150227

Epoch: 6| Step: 12
Training loss: 2.745625397638526
Validation loss: 2.465859970932113

Epoch: 6| Step: 13
Training loss: 2.8503012180094633
Validation loss: 2.4727524612615572

Epoch: 29| Step: 0
Training loss: 2.750376415500416
Validation loss: 2.4516290691698996

Epoch: 6| Step: 1
Training loss: 3.2266866369128615
Validation loss: 2.4580294062893917

Epoch: 6| Step: 2
Training loss: 3.041297541825699
Validation loss: 2.479049492853208

Epoch: 6| Step: 3
Training loss: 2.613712930877104
Validation loss: 2.46708397643069

Epoch: 6| Step: 4
Training loss: 2.0210434584817265
Validation loss: 2.4554543339703314

Epoch: 6| Step: 5
Training loss: 2.2256657450930533
Validation loss: 2.450783448263408

Epoch: 6| Step: 6
Training loss: 1.8891145962456626
Validation loss: 2.455573235122572

Epoch: 6| Step: 7
Training loss: 2.01975743338691
Validation loss: 2.4590962379226675

Epoch: 6| Step: 8
Training loss: 2.861520597995315
Validation loss: 2.4453476323375627

Epoch: 6| Step: 9
Training loss: 2.2775656852085415
Validation loss: 2.4506526158917254

Epoch: 6| Step: 10
Training loss: 2.1955586902868016
Validation loss: 2.4778726924750853

Epoch: 6| Step: 11
Training loss: 2.2586068732593927
Validation loss: 2.456894822772957

Epoch: 6| Step: 12
Training loss: 2.1084598392735265
Validation loss: 2.466445954270779

Epoch: 6| Step: 13
Training loss: 2.473344607605991
Validation loss: 2.4669975305871414

Epoch: 30| Step: 0
Training loss: 2.5945630924759997
Validation loss: 2.4522198669571313

Epoch: 6| Step: 1
Training loss: 2.84277008276597
Validation loss: 2.4589941192749

Epoch: 6| Step: 2
Training loss: 2.277986255915762
Validation loss: 2.479023509874437

Epoch: 6| Step: 3
Training loss: 2.125308743655701
Validation loss: 2.4775593433143976

Epoch: 6| Step: 4
Training loss: 2.176576534097287
Validation loss: 2.4941485909434586

Epoch: 6| Step: 5
Training loss: 2.0457096422436525
Validation loss: 2.5010873972821477

Epoch: 6| Step: 6
Training loss: 2.050784156433952
Validation loss: 2.4956829706113512

Epoch: 6| Step: 7
Training loss: 3.1802778516098154
Validation loss: 2.4819323849742325

Epoch: 6| Step: 8
Training loss: 1.7004615185271972
Validation loss: 2.4906809367779204

Epoch: 6| Step: 9
Training loss: 2.212459296590245
Validation loss: 2.483385956823239

Epoch: 6| Step: 10
Training loss: 3.397105128995317
Validation loss: 2.4735388845267807

Epoch: 6| Step: 11
Training loss: 2.7041643382700657
Validation loss: 2.477308223216596

Epoch: 6| Step: 12
Training loss: 2.2082439500485505
Validation loss: 2.4582369402936792

Epoch: 6| Step: 13
Training loss: 2.2486178073334364
Validation loss: 2.460060270069944

Epoch: 31| Step: 0
Training loss: 2.140355225430543
Validation loss: 2.4693239888765546

Epoch: 6| Step: 1
Training loss: 2.004435865229263
Validation loss: 2.456195990540524

Epoch: 6| Step: 2
Training loss: 2.6285060901103257
Validation loss: 2.4578725226676488

Epoch: 6| Step: 3
Training loss: 2.6715399995008693
Validation loss: 2.462930685549946

Epoch: 6| Step: 4
Training loss: 1.9936156894323638
Validation loss: 2.457100693894354

Epoch: 6| Step: 5
Training loss: 2.0616830305942124
Validation loss: 2.469608728934616

Epoch: 6| Step: 6
Training loss: 2.4013618261301475
Validation loss: 2.452791049523435

Epoch: 6| Step: 7
Training loss: 2.4014896021881347
Validation loss: 2.4575104279036557

Epoch: 6| Step: 8
Training loss: 3.0352164204842538
Validation loss: 2.480380303515603

Epoch: 6| Step: 9
Training loss: 2.6596182616666115
Validation loss: 2.4788116927556416

Epoch: 6| Step: 10
Training loss: 2.3239635167106116
Validation loss: 2.4651196179824857

Epoch: 6| Step: 11
Training loss: 2.6153919038627875
Validation loss: 2.4560161327169774

Epoch: 6| Step: 12
Training loss: 2.329706768363005
Validation loss: 2.4675859290237057

Epoch: 6| Step: 13
Training loss: 2.607515140537037
Validation loss: 2.4662879626289094

Epoch: 32| Step: 0
Training loss: 1.8673506789150327
Validation loss: 2.471088790446364

Epoch: 6| Step: 1
Training loss: 2.671051255340261
Validation loss: 2.4749611893253576

Epoch: 6| Step: 2
Training loss: 2.079983446715584
Validation loss: 2.463714623109345

Epoch: 6| Step: 3
Training loss: 2.5055977141373535
Validation loss: 2.4684337461689068

Epoch: 6| Step: 4
Training loss: 3.4232821423628965
Validation loss: 2.4603430297409656

Epoch: 6| Step: 5
Training loss: 2.2783337072313063
Validation loss: 2.472655189357247

Epoch: 6| Step: 6
Training loss: 2.508031342366844
Validation loss: 2.4632756826892566

Epoch: 6| Step: 7
Training loss: 2.6086230993547734
Validation loss: 2.482921695088519

Epoch: 6| Step: 8
Training loss: 2.2288416925675416
Validation loss: 2.4693828367203703

Epoch: 6| Step: 9
Training loss: 2.6764795436351756
Validation loss: 2.4716601060131596

Epoch: 6| Step: 10
Training loss: 2.054368839283692
Validation loss: 2.503678587721806

Epoch: 6| Step: 11
Training loss: 2.457415188386279
Validation loss: 2.4989242782487877

Epoch: 6| Step: 12
Training loss: 1.2624309879741062
Validation loss: 2.4748803010246005

Epoch: 6| Step: 13
Training loss: 2.6739600896489004
Validation loss: 2.4907378761052335

Epoch: 33| Step: 0
Training loss: 2.5371165169019956
Validation loss: 2.483406181888403

Epoch: 6| Step: 1
Training loss: 2.566022080651274
Validation loss: 2.4707877686165944

Epoch: 6| Step: 2
Training loss: 2.6585421377547833
Validation loss: 2.456412637258744

Epoch: 6| Step: 3
Training loss: 2.529110699138595
Validation loss: 2.449487317543709

Epoch: 6| Step: 4
Training loss: 2.391357708512776
Validation loss: 2.4548979910370834

Epoch: 6| Step: 5
Training loss: 2.2321681081161038
Validation loss: 2.449018033131689

Epoch: 6| Step: 6
Training loss: 2.187657595815845
Validation loss: 2.4797188093247566

Epoch: 6| Step: 7
Training loss: 1.8310493489505508
Validation loss: 2.4609946753909178

Epoch: 6| Step: 8
Training loss: 2.274615110599415
Validation loss: 2.457166303148389

Epoch: 6| Step: 9
Training loss: 2.8508788242927445
Validation loss: 2.452448676761877

Epoch: 6| Step: 10
Training loss: 2.289528861076157
Validation loss: 2.480080529618

Epoch: 6| Step: 11
Training loss: 2.232422942981481
Validation loss: 2.4643480514818865

Epoch: 6| Step: 12
Training loss: 2.89316294834963
Validation loss: 2.470698123167903

Epoch: 6| Step: 13
Training loss: 2.383035217882944
Validation loss: 2.4739286936272724

Epoch: 34| Step: 0
Training loss: 2.732867539267613
Validation loss: 2.4746334774265666

Epoch: 6| Step: 1
Training loss: 2.392281251511667
Validation loss: 2.47800871041845

Epoch: 6| Step: 2
Training loss: 2.170595519450277
Validation loss: 2.464239821325891

Epoch: 6| Step: 3
Training loss: 2.38239372200507
Validation loss: 2.4572638405106613

Epoch: 6| Step: 4
Training loss: 3.0613217325400592
Validation loss: 2.470911665045212

Epoch: 6| Step: 5
Training loss: 2.2679583931324085
Validation loss: 2.45513410967206

Epoch: 6| Step: 6
Training loss: 2.3863599042326573
Validation loss: 2.460290668393433

Epoch: 6| Step: 7
Training loss: 2.304578358280392
Validation loss: 2.4545047710613486

Epoch: 6| Step: 8
Training loss: 2.468107308860236
Validation loss: 2.472094752803291

Epoch: 6| Step: 9
Training loss: 2.3175327077324956
Validation loss: 2.4513310799943233

Epoch: 6| Step: 10
Training loss: 1.9690218540991784
Validation loss: 2.4487116692817534

Epoch: 6| Step: 11
Training loss: 2.0000950075471633
Validation loss: 2.4563679813202364

Epoch: 6| Step: 12
Training loss: 2.8213128933637868
Validation loss: 2.460153711228218

Epoch: 6| Step: 13
Training loss: 2.1877598199494286
Validation loss: 2.4707026746746954

Epoch: 35| Step: 0
Training loss: 2.0482268783100515
Validation loss: 2.4574390875458563

Epoch: 6| Step: 1
Training loss: 2.5131898075410115
Validation loss: 2.457232444300721

Epoch: 6| Step: 2
Training loss: 2.7585057584070833
Validation loss: 2.4896356159503616

Epoch: 6| Step: 3
Training loss: 2.607521540990785
Validation loss: 2.475399044889987

Epoch: 6| Step: 4
Training loss: 2.2695980620275433
Validation loss: 2.4721055384280066

Epoch: 6| Step: 5
Training loss: 2.3820398297379
Validation loss: 2.491294342044513

Epoch: 6| Step: 6
Training loss: 2.3518296403689862
Validation loss: 2.4789548404073876

Epoch: 6| Step: 7
Training loss: 2.66887634835891
Validation loss: 2.4802444156316885

Epoch: 6| Step: 8
Training loss: 2.9364336391428707
Validation loss: 2.4858535429537656

Epoch: 6| Step: 9
Training loss: 2.2693484523253122
Validation loss: 2.480083862240371

Epoch: 6| Step: 10
Training loss: 2.3465692475897937
Validation loss: 2.5011169004954668

Epoch: 6| Step: 11
Training loss: 1.9669586993925334
Validation loss: 2.478902303133697

Epoch: 6| Step: 12
Training loss: 2.5951098818291087
Validation loss: 2.4765175174514877

Epoch: 6| Step: 13
Training loss: 1.950110955627349
Validation loss: 2.4831910261133765

Epoch: 36| Step: 0
Training loss: 2.4429385816213673
Validation loss: 2.482036377562599

Epoch: 6| Step: 1
Training loss: 1.4668899283118815
Validation loss: 2.4418985831706284

Epoch: 6| Step: 2
Training loss: 2.6575378886094043
Validation loss: 2.4717787259688686

Epoch: 6| Step: 3
Training loss: 2.29346914208999
Validation loss: 2.451864886756102

Epoch: 6| Step: 4
Training loss: 2.879628312179993
Validation loss: 2.4634569461333555

Epoch: 6| Step: 5
Training loss: 2.749097155705631
Validation loss: 2.4676810578019324

Epoch: 6| Step: 6
Training loss: 2.0093251033775577
Validation loss: 2.4579125760886082

Epoch: 6| Step: 7
Training loss: 2.138105036896857
Validation loss: 2.4636749462719223

Epoch: 6| Step: 8
Training loss: 2.7872268234987807
Validation loss: 2.4616705070246976

Epoch: 6| Step: 9
Training loss: 2.2811181017225626
Validation loss: 2.4524547203827742

Epoch: 6| Step: 10
Training loss: 1.8758016144307612
Validation loss: 2.4590180192483415

Epoch: 6| Step: 11
Training loss: 2.981369182515579
Validation loss: 2.45582671526261

Epoch: 6| Step: 12
Training loss: 2.7740122884520817
Validation loss: 2.470174193526921

Epoch: 6| Step: 13
Training loss: 2.520384272991903
Validation loss: 2.4598812197875035

Epoch: 37| Step: 0
Training loss: 2.10461838912492
Validation loss: 2.4699942113316875

Epoch: 6| Step: 1
Training loss: 1.9517093868884605
Validation loss: 2.475527205011916

Epoch: 6| Step: 2
Training loss: 2.912786045680767
Validation loss: 2.4676919271284175

Epoch: 6| Step: 3
Training loss: 2.517009851496274
Validation loss: 2.4767953500479374

Epoch: 6| Step: 4
Training loss: 2.7662290786248502
Validation loss: 2.498333454967629

Epoch: 6| Step: 5
Training loss: 2.6433883744322353
Validation loss: 2.537542927195684

Epoch: 6| Step: 6
Training loss: 2.2212529638267413
Validation loss: 2.52785983901448

Epoch: 6| Step: 7
Training loss: 2.2364171439365053
Validation loss: 2.536608263998474

Epoch: 6| Step: 8
Training loss: 2.061696907670747
Validation loss: 2.501320633164979

Epoch: 6| Step: 9
Training loss: 2.939989374362143
Validation loss: 2.5046743245451544

Epoch: 6| Step: 10
Training loss: 2.4263609655712406
Validation loss: 2.5011613055912476

Epoch: 6| Step: 11
Training loss: 2.0652482189784482
Validation loss: 2.4733989096462827

Epoch: 6| Step: 12
Training loss: 2.616249121216081
Validation loss: 2.4805815263076627

Epoch: 6| Step: 13
Training loss: 2.1790453330616133
Validation loss: 2.4672619966836393

Epoch: 38| Step: 0
Training loss: 2.353276942642836
Validation loss: 2.45234032653265

Epoch: 6| Step: 1
Training loss: 2.652740763416555
Validation loss: 2.456414125506436

Epoch: 6| Step: 2
Training loss: 2.3696322768270126
Validation loss: 2.4629663409887406

Epoch: 6| Step: 3
Training loss: 2.2555872104826755
Validation loss: 2.479804467189

Epoch: 6| Step: 4
Training loss: 2.5534401744603965
Validation loss: 2.450564560751737

Epoch: 6| Step: 5
Training loss: 2.3655926962981293
Validation loss: 2.455081086927037

Epoch: 6| Step: 6
Training loss: 2.1957931263938453
Validation loss: 2.459509928975437

Epoch: 6| Step: 7
Training loss: 2.3326364112208156
Validation loss: 2.4615780597185473

Epoch: 6| Step: 8
Training loss: 2.131274217037312
Validation loss: 2.463452800629177

Epoch: 6| Step: 9
Training loss: 2.47885064640675
Validation loss: 2.434508533920631

Epoch: 6| Step: 10
Training loss: 2.406147942298447
Validation loss: 2.4421231206640117

Epoch: 6| Step: 11
Training loss: 2.707753358999639
Validation loss: 2.46752802065393

Epoch: 6| Step: 12
Training loss: 3.0285539730679467
Validation loss: 2.4758564517203228

Epoch: 6| Step: 13
Training loss: 1.5773672418606868
Validation loss: 2.4609852458217594

Epoch: 39| Step: 0
Training loss: 2.3669375045255396
Validation loss: 2.466439715353646

Epoch: 6| Step: 1
Training loss: 2.6468337162766105
Validation loss: 2.470701597110241

Epoch: 6| Step: 2
Training loss: 2.4746706502624765
Validation loss: 2.475486497555967

Epoch: 6| Step: 3
Training loss: 2.540355928068343
Validation loss: 2.4603900845540108

Epoch: 6| Step: 4
Training loss: 2.718916789233334
Validation loss: 2.467936836592624

Epoch: 6| Step: 5
Training loss: 1.996050571041819
Validation loss: 2.4647906540009923

Epoch: 6| Step: 6
Training loss: 3.158997803158674
Validation loss: 2.4661129415883933

Epoch: 6| Step: 7
Training loss: 2.035196080614311
Validation loss: 2.44899010896587

Epoch: 6| Step: 8
Training loss: 2.2098166923967613
Validation loss: 2.460492096815186

Epoch: 6| Step: 9
Training loss: 1.9949312949719158
Validation loss: 2.4745149702306737

Epoch: 6| Step: 10
Training loss: 1.8856203028968417
Validation loss: 2.474728487836827

Epoch: 6| Step: 11
Training loss: 2.32112153716196
Validation loss: 2.4800524184496493

Epoch: 6| Step: 12
Training loss: 2.4395490983297754
Validation loss: 2.487649730668

Epoch: 6| Step: 13
Training loss: 2.6137153937713746
Validation loss: 2.4725007002739194

Epoch: 40| Step: 0
Training loss: 2.0032803336869542
Validation loss: 2.479111796394306

Epoch: 6| Step: 1
Training loss: 2.3425979834779214
Validation loss: 2.4748726182646754

Epoch: 6| Step: 2
Training loss: 2.6540908115951587
Validation loss: 2.4724949788658757

Epoch: 6| Step: 3
Training loss: 2.821988186514802
Validation loss: 2.473945052797242

Epoch: 6| Step: 4
Training loss: 2.184372764662662
Validation loss: 2.4914599784766747

Epoch: 6| Step: 5
Training loss: 2.43126212854964
Validation loss: 2.4647215476880002

Epoch: 6| Step: 6
Training loss: 2.0794757096049854
Validation loss: 2.4602964666357665

Epoch: 6| Step: 7
Training loss: 2.0370560051134454
Validation loss: 2.4619698594441073

Epoch: 6| Step: 8
Training loss: 2.622279164895729
Validation loss: 2.4721621662041406

Epoch: 6| Step: 9
Training loss: 2.7944197293607007
Validation loss: 2.479216412170722

Epoch: 6| Step: 10
Training loss: 2.5356715638151988
Validation loss: 2.4625833648925703

Epoch: 6| Step: 11
Training loss: 1.816284044318172
Validation loss: 2.451903393370579

Epoch: 6| Step: 12
Training loss: 2.7973230099022377
Validation loss: 2.446587600816375

Epoch: 6| Step: 13
Training loss: 2.19132421547378
Validation loss: 2.449705409160399

Epoch: 41| Step: 0
Training loss: 2.522280590242792
Validation loss: 2.450195588200172

Epoch: 6| Step: 1
Training loss: 2.090767629459455
Validation loss: 2.474209258086717

Epoch: 6| Step: 2
Training loss: 3.175880796554452
Validation loss: 2.4695236989555216

Epoch: 6| Step: 3
Training loss: 2.1866228797451788
Validation loss: 2.44561780297273

Epoch: 6| Step: 4
Training loss: 3.0541239264925095
Validation loss: 2.4560369552872148

Epoch: 6| Step: 5
Training loss: 2.319965169579389
Validation loss: 2.455900780245982

Epoch: 6| Step: 6
Training loss: 1.8783081117757148
Validation loss: 2.4812148206188342

Epoch: 6| Step: 7
Training loss: 2.15675104926391
Validation loss: 2.4753859138815155

Epoch: 6| Step: 8
Training loss: 1.2493678878879446
Validation loss: 2.4932405405533533

Epoch: 6| Step: 9
Training loss: 2.6698881201574185
Validation loss: 2.4971979491775387

Epoch: 6| Step: 10
Training loss: 2.635383957570661
Validation loss: 2.51401970864266

Epoch: 6| Step: 11
Training loss: 2.381729029734815
Validation loss: 2.5147512430947128

Epoch: 6| Step: 12
Training loss: 2.235084047721342
Validation loss: 2.4995900612742847

Epoch: 6| Step: 13
Training loss: 2.440603774365529
Validation loss: 2.496459456564

Epoch: 42| Step: 0
Training loss: 1.9892890938952479
Validation loss: 2.486459605218386

Epoch: 6| Step: 1
Training loss: 2.013276262021797
Validation loss: 2.477670303455306

Epoch: 6| Step: 2
Training loss: 1.6295432622175825
Validation loss: 2.475663496278488

Epoch: 6| Step: 3
Training loss: 3.053626146838103
Validation loss: 2.4721662488832568

Epoch: 6| Step: 4
Training loss: 2.147350244240946
Validation loss: 2.4671448426668987

Epoch: 6| Step: 5
Training loss: 2.287946201018744
Validation loss: 2.4677793147735794

Epoch: 6| Step: 6
Training loss: 3.406367308670213
Validation loss: 2.474817007858698

Epoch: 6| Step: 7
Training loss: 2.4946323946534377
Validation loss: 2.47588492349266

Epoch: 6| Step: 8
Training loss: 2.4029613662388996
Validation loss: 2.466984081036034

Epoch: 6| Step: 9
Training loss: 2.3066720467800543
Validation loss: 2.443094769285361

Epoch: 6| Step: 10
Training loss: 2.4434471937905213
Validation loss: 2.4398542918802937

Epoch: 6| Step: 11
Training loss: 2.2689027424828487
Validation loss: 2.451608436077929

Epoch: 6| Step: 12
Training loss: 2.4511721668015265
Validation loss: 2.4494947554778816

Epoch: 6| Step: 13
Training loss: 2.0289262831576194
Validation loss: 2.462429542953568

Epoch: 43| Step: 0
Training loss: 3.185886348596239
Validation loss: 2.4471027455035443

Epoch: 6| Step: 1
Training loss: 2.073362241872594
Validation loss: 2.455438256183114

Epoch: 6| Step: 2
Training loss: 1.8113481215705307
Validation loss: 2.466650766458901

Epoch: 6| Step: 3
Training loss: 2.5263137723262163
Validation loss: 2.4643542594143306

Epoch: 6| Step: 4
Training loss: 1.9527055824081605
Validation loss: 2.466508966851975

Epoch: 6| Step: 5
Training loss: 2.463353209649794
Validation loss: 2.4658211182445053

Epoch: 6| Step: 6
Training loss: 2.1193776644141846
Validation loss: 2.49008704852952

Epoch: 6| Step: 7
Training loss: 2.7008399787059156
Validation loss: 2.490388130976317

Epoch: 6| Step: 8
Training loss: 1.9750545614890656
Validation loss: 2.4935890171288086

Epoch: 6| Step: 9
Training loss: 2.419075806431701
Validation loss: 2.5047925708520262

Epoch: 6| Step: 10
Training loss: 1.7932138046979036
Validation loss: 2.5067763044682128

Epoch: 6| Step: 11
Training loss: 2.683033980579147
Validation loss: 2.543935971721895

Epoch: 6| Step: 12
Training loss: 2.796718230728842
Validation loss: 2.5393865916458345

Epoch: 6| Step: 13
Training loss: 2.5390027787447638
Validation loss: 2.517217680838758

Epoch: 44| Step: 0
Training loss: 1.9301066078627507
Validation loss: 2.4923628822089605

Epoch: 6| Step: 1
Training loss: 1.8887820759037097
Validation loss: 2.471976083713357

Epoch: 6| Step: 2
Training loss: 2.125390746150463
Validation loss: 2.4688305258192758

Epoch: 6| Step: 3
Training loss: 2.146444499068016
Validation loss: 2.4828352005058636

Epoch: 6| Step: 4
Training loss: 1.7023109100241374
Validation loss: 2.4801765089517995

Epoch: 6| Step: 5
Training loss: 2.646301668624026
Validation loss: 2.482791179855927

Epoch: 6| Step: 6
Training loss: 2.82462359596147
Validation loss: 2.4891929692846597

Epoch: 6| Step: 7
Training loss: 2.5504729711180647
Validation loss: 2.4832416884475452

Epoch: 6| Step: 8
Training loss: 2.5056376786552317
Validation loss: 2.4780492000524226

Epoch: 6| Step: 9
Training loss: 2.71592521807793
Validation loss: 2.4604959889114184

Epoch: 6| Step: 10
Training loss: 2.1985783838870097
Validation loss: 2.461761159157263

Epoch: 6| Step: 11
Training loss: 2.2175228325013463
Validation loss: 2.4584657315523155

Epoch: 6| Step: 12
Training loss: 3.005190967705775
Validation loss: 2.450843114196741

Epoch: 6| Step: 13
Training loss: 2.501731463700148
Validation loss: 2.448220974019126

Epoch: 45| Step: 0
Training loss: 2.1578622954504554
Validation loss: 2.469112289178412

Epoch: 6| Step: 1
Training loss: 1.483690927385273
Validation loss: 2.447902587417263

Epoch: 6| Step: 2
Training loss: 2.8084798267163595
Validation loss: 2.450769901624304

Epoch: 6| Step: 3
Training loss: 2.792740306981874
Validation loss: 2.468513686704357

Epoch: 6| Step: 4
Training loss: 2.263397489807943
Validation loss: 2.4476234152164547

Epoch: 6| Step: 5
Training loss: 2.3252160248841247
Validation loss: 2.457349327050188

Epoch: 6| Step: 6
Training loss: 2.6196983932565328
Validation loss: 2.443680012148707

Epoch: 6| Step: 7
Training loss: 2.700475551969895
Validation loss: 2.444685606788534

Epoch: 6| Step: 8
Training loss: 2.1360919039882007
Validation loss: 2.4704572834243144

Epoch: 6| Step: 9
Training loss: 2.8193674802584736
Validation loss: 2.468681414975374

Epoch: 6| Step: 10
Training loss: 1.640042882916906
Validation loss: 2.4809964637398005

Epoch: 6| Step: 11
Training loss: 2.272046689520881
Validation loss: 2.500335877426081

Epoch: 6| Step: 12
Training loss: 2.836975075989761
Validation loss: 2.4970130719907146

Epoch: 6| Step: 13
Training loss: 2.307007323598626
Validation loss: 2.5033852228034768

Epoch: 46| Step: 0
Training loss: 2.1251692984964112
Validation loss: 2.5041193720138106

Epoch: 6| Step: 1
Training loss: 2.9313598742358935
Validation loss: 2.501351706340079

Epoch: 6| Step: 2
Training loss: 2.8238042207994494
Validation loss: 2.481884297635523

Epoch: 6| Step: 3
Training loss: 2.05691488815573
Validation loss: 2.481558044427032

Epoch: 6| Step: 4
Training loss: 2.822078923052474
Validation loss: 2.4474207328400563

Epoch: 6| Step: 5
Training loss: 2.4472095090334043
Validation loss: 2.4477365359863086

Epoch: 6| Step: 6
Training loss: 1.8609429808567155
Validation loss: 2.4595353587639126

Epoch: 6| Step: 7
Training loss: 2.3351674931837167
Validation loss: 2.4473218371000827

Epoch: 6| Step: 8
Training loss: 2.255176311967444
Validation loss: 2.443005872443781

Epoch: 6| Step: 9
Training loss: 1.8940885990209544
Validation loss: 2.4623714326321156

Epoch: 6| Step: 10
Training loss: 2.3308959446629514
Validation loss: 2.4667812496927763

Epoch: 6| Step: 11
Training loss: 2.3497449371221655
Validation loss: 2.475381242564638

Epoch: 6| Step: 12
Training loss: 2.8453396556549237
Validation loss: 2.4520744293319154

Epoch: 6| Step: 13
Training loss: 1.9529786322108889
Validation loss: 2.4766921401564286

Epoch: 47| Step: 0
Training loss: 2.0123753337275745
Validation loss: 2.4792835037097665

Epoch: 6| Step: 1
Training loss: 1.9386302973516045
Validation loss: 2.4717339939645946

Epoch: 6| Step: 2
Training loss: 2.589981098474292
Validation loss: 2.482604957710302

Epoch: 6| Step: 3
Training loss: 2.558493855397247
Validation loss: 2.4855946999604575

Epoch: 6| Step: 4
Training loss: 2.6999804778629537
Validation loss: 2.494998530423758

Epoch: 6| Step: 5
Training loss: 2.738033963736072
Validation loss: 2.476338509780369

Epoch: 6| Step: 6
Training loss: 1.8116157611034123
Validation loss: 2.486112470881009

Epoch: 6| Step: 7
Training loss: 2.9363612138741932
Validation loss: 2.455760956953205

Epoch: 6| Step: 8
Training loss: 2.016799348086744
Validation loss: 2.461930025364957

Epoch: 6| Step: 9
Training loss: 2.159287897277164
Validation loss: 2.4643715770445156

Epoch: 6| Step: 10
Training loss: 2.1209889872551475
Validation loss: 2.4524337215716105

Epoch: 6| Step: 11
Training loss: 2.602497654454826
Validation loss: 2.460398507004104

Epoch: 6| Step: 12
Training loss: 2.310025102223002
Validation loss: 2.453716603597751

Epoch: 6| Step: 13
Training loss: 2.2398022448576427
Validation loss: 2.465650471796279

Epoch: 48| Step: 0
Training loss: 2.27777168872712
Validation loss: 2.4650002906933266

Epoch: 6| Step: 1
Training loss: 2.790033251656532
Validation loss: 2.4450603188509312

Epoch: 6| Step: 2
Training loss: 2.065089132311157
Validation loss: 2.4602858957352423

Epoch: 6| Step: 3
Training loss: 2.3564625125641436
Validation loss: 2.460252583776843

Epoch: 6| Step: 4
Training loss: 1.6726963485622273
Validation loss: 2.448996793920086

Epoch: 6| Step: 5
Training loss: 1.735353898114987
Validation loss: 2.4676411307317028

Epoch: 6| Step: 6
Training loss: 2.3009075654722446
Validation loss: 2.4776472570010686

Epoch: 6| Step: 7
Training loss: 2.6293419849525526
Validation loss: 2.4563189405451955

Epoch: 6| Step: 8
Training loss: 2.26907317747066
Validation loss: 2.4702418202007177

Epoch: 6| Step: 9
Training loss: 2.000469629462872
Validation loss: 2.4739666881754827

Epoch: 6| Step: 10
Training loss: 2.739214989638537
Validation loss: 2.4290200284621886

Epoch: 6| Step: 11
Training loss: 2.5467686543173254
Validation loss: 2.4527673966862635

Epoch: 6| Step: 12
Training loss: 2.8013247251267908
Validation loss: 2.4505832568226666

Epoch: 6| Step: 13
Training loss: 2.3705408498047995
Validation loss: 2.495204681634175

Epoch: 49| Step: 0
Training loss: 2.863305230970517
Validation loss: 2.4879331559854116

Epoch: 6| Step: 1
Training loss: 2.076431042921262
Validation loss: 2.4809370905362527

Epoch: 6| Step: 2
Training loss: 2.3170706453909475
Validation loss: 2.468803574185989

Epoch: 6| Step: 3
Training loss: 2.2911806689405902
Validation loss: 2.485213388175683

Epoch: 6| Step: 4
Training loss: 2.50043464696982
Validation loss: 2.458675729754363

Epoch: 6| Step: 5
Training loss: 1.8673914714158035
Validation loss: 2.479919116382967

Epoch: 6| Step: 6
Training loss: 2.405539667881201
Validation loss: 2.45462458428933

Epoch: 6| Step: 7
Training loss: 2.215985792562063
Validation loss: 2.464574896915429

Epoch: 6| Step: 8
Training loss: 2.4132122036092136
Validation loss: 2.475048496914321

Epoch: 6| Step: 9
Training loss: 2.9611275242041857
Validation loss: 2.473738037473679

Epoch: 6| Step: 10
Training loss: 2.2572926909604734
Validation loss: 2.491047820828884

Epoch: 6| Step: 11
Training loss: 2.4028129305561943
Validation loss: 2.4689244478294317

Epoch: 6| Step: 12
Training loss: 2.091646988714092
Validation loss: 2.4681104966503296

Epoch: 6| Step: 13
Training loss: 1.98785869552507
Validation loss: 2.473998129005927

Epoch: 50| Step: 0
Training loss: 2.3839691856684206
Validation loss: 2.483996908339513

Epoch: 6| Step: 1
Training loss: 2.491585685749369
Validation loss: 2.4780893843578085

Epoch: 6| Step: 2
Training loss: 2.506791331745486
Validation loss: 2.475681874399492

Epoch: 6| Step: 3
Training loss: 1.8242248927141627
Validation loss: 2.4929466087978316

Epoch: 6| Step: 4
Training loss: 2.176294235489831
Validation loss: 2.4758745395189212

Epoch: 6| Step: 5
Training loss: 1.89550309571235
Validation loss: 2.5019896378286055

Epoch: 6| Step: 6
Training loss: 1.979834400438221
Validation loss: 2.5055969529022555

Epoch: 6| Step: 7
Training loss: 2.433635876629265
Validation loss: 2.500939447002677

Epoch: 6| Step: 8
Training loss: 2.349430372311727
Validation loss: 2.5047241002020635

Epoch: 6| Step: 9
Training loss: 2.4165114539277712
Validation loss: 2.496635732378475

Epoch: 6| Step: 10
Training loss: 2.7635409159011672
Validation loss: 2.5151354232386813

Epoch: 6| Step: 11
Training loss: 2.7480398474890153
Validation loss: 2.4926285786881133

Epoch: 6| Step: 12
Training loss: 2.4574985272081995
Validation loss: 2.5048705023251765

Epoch: 6| Step: 13
Training loss: 2.127257774540561
Validation loss: 2.483346466268679

Epoch: 51| Step: 0
Training loss: 2.086052023497681
Validation loss: 2.486128574063744

Epoch: 6| Step: 1
Training loss: 2.1873559086890397
Validation loss: 2.468506265833331

Epoch: 6| Step: 2
Training loss: 2.6642345026150225
Validation loss: 2.455573235122572

Epoch: 6| Step: 3
Training loss: 1.8569416183390575
Validation loss: 2.4695269010079732

Epoch: 6| Step: 4
Training loss: 1.9167766401281265
Validation loss: 2.4540011224358107

Epoch: 6| Step: 5
Training loss: 2.154731547546512
Validation loss: 2.4459237176765067

Epoch: 6| Step: 6
Training loss: 2.495321282626314
Validation loss: 2.450992102445415

Epoch: 6| Step: 7
Training loss: 2.1450110282703365
Validation loss: 2.4505171956526173

Epoch: 6| Step: 8
Training loss: 2.5203931650117197
Validation loss: 2.4635965826407342

Epoch: 6| Step: 9
Training loss: 2.6682584501962054
Validation loss: 2.467329590442165

Epoch: 6| Step: 10
Training loss: 2.117831762056535
Validation loss: 2.4709535655273758

Epoch: 6| Step: 11
Training loss: 1.9021529899062477
Validation loss: 2.4673044986697703

Epoch: 6| Step: 12
Training loss: 2.943009262677003
Validation loss: 2.4420834672718783

Epoch: 6| Step: 13
Training loss: 2.7681318225892793
Validation loss: 2.4851956241753954

Epoch: 52| Step: 0
Training loss: 1.8943696572515698
Validation loss: 2.477179048409178

Epoch: 6| Step: 1
Training loss: 2.1281262009851143
Validation loss: 2.4913205160448086

Epoch: 6| Step: 2
Training loss: 1.9103171313975558
Validation loss: 2.492037929084513

Epoch: 6| Step: 3
Training loss: 2.0473660178590403
Validation loss: 2.4995443803139072

Epoch: 6| Step: 4
Training loss: 2.7804121834343265
Validation loss: 2.51654459255139

Epoch: 6| Step: 5
Training loss: 2.4006436915267106
Validation loss: 2.511584272883175

Epoch: 6| Step: 6
Training loss: 2.680922065367614
Validation loss: 2.5188562400757486

Epoch: 6| Step: 7
Training loss: 2.5497212799935323
Validation loss: 2.5205333993670522

Epoch: 6| Step: 8
Training loss: 3.0294741118162802
Validation loss: 2.512847646698257

Epoch: 6| Step: 9
Training loss: 2.3020902837818107
Validation loss: 2.500431913577177

Epoch: 6| Step: 10
Training loss: 2.1094098123574105
Validation loss: 2.4753960751692277

Epoch: 6| Step: 11
Training loss: 2.1428024466663866
Validation loss: 2.4806184818601555

Epoch: 6| Step: 12
Training loss: 2.419116806092876
Validation loss: 2.456684324579775

Epoch: 6| Step: 13
Training loss: 2.0386233971425907
Validation loss: 2.454830241125368

Epoch: 53| Step: 0
Training loss: 1.8231660799427218
Validation loss: 2.444982634406643

Epoch: 6| Step: 1
Training loss: 2.369933194695698
Validation loss: 2.4599541369610827

Epoch: 6| Step: 2
Training loss: 2.541697851104374
Validation loss: 2.4410303747112323

Epoch: 6| Step: 3
Training loss: 1.7235628886533814
Validation loss: 2.454481231874654

Epoch: 6| Step: 4
Training loss: 2.0240947583825877
Validation loss: 2.4630191617172055

Epoch: 6| Step: 5
Training loss: 2.118560908609032
Validation loss: 2.4614887084464323

Epoch: 6| Step: 6
Training loss: 2.370149477820058
Validation loss: 2.4709277949253763

Epoch: 6| Step: 7
Training loss: 1.8845088171060618
Validation loss: 2.4644223682747506

Epoch: 6| Step: 8
Training loss: 2.9631751470178567
Validation loss: 2.454867462936546

Epoch: 6| Step: 9
Training loss: 2.4153261303304228
Validation loss: 2.449564396806163

Epoch: 6| Step: 10
Training loss: 2.9051962962447746
Validation loss: 2.45156099389514

Epoch: 6| Step: 11
Training loss: 2.1759504324372436
Validation loss: 2.454359549783081

Epoch: 6| Step: 12
Training loss: 2.596053238356609
Validation loss: 2.4676026362053762

Epoch: 6| Step: 13
Training loss: 2.2801789160013413
Validation loss: 2.4706181568115637

Epoch: 54| Step: 0
Training loss: 3.0909233666666593
Validation loss: 2.5062436339185727

Epoch: 6| Step: 1
Training loss: 2.0139975668277836
Validation loss: 2.547057459249633

Epoch: 6| Step: 2
Training loss: 2.4324737959858806
Validation loss: 2.5682176364713865

Epoch: 6| Step: 3
Training loss: 3.1330733725743753
Validation loss: 2.6056634314540834

Epoch: 6| Step: 4
Training loss: 1.92942233715554
Validation loss: 2.60574293624124

Epoch: 6| Step: 5
Training loss: 3.0781535035958196
Validation loss: 2.655849950247869

Epoch: 6| Step: 6
Training loss: 2.0527484287176505
Validation loss: 2.6186905222157075

Epoch: 6| Step: 7
Training loss: 2.0966601288677875
Validation loss: 2.6005000406925487

Epoch: 6| Step: 8
Training loss: 2.036214425260372
Validation loss: 2.5935018030016583

Epoch: 6| Step: 9
Training loss: 2.229376690914453
Validation loss: 2.5381453515584598

Epoch: 6| Step: 10
Training loss: 2.3082669667459412
Validation loss: 2.507647975385297

Epoch: 6| Step: 11
Training loss: 2.0205257483193777
Validation loss: 2.495284361691592

Epoch: 6| Step: 12
Training loss: 2.1492598745667895
Validation loss: 2.4557921697167457

Epoch: 6| Step: 13
Training loss: 1.7865059923167053
Validation loss: 2.4518945041658324

Epoch: 55| Step: 0
Training loss: 2.836060072086434
Validation loss: 2.4495527332789178

Epoch: 6| Step: 1
Training loss: 1.923052977266147
Validation loss: 2.463513627541294

Epoch: 6| Step: 2
Training loss: 2.3407423939824246
Validation loss: 2.434188614950598

Epoch: 6| Step: 3
Training loss: 2.848129421529546
Validation loss: 2.460990937475274

Epoch: 6| Step: 4
Training loss: 2.934187624537874
Validation loss: 2.448743474944169

Epoch: 6| Step: 5
Training loss: 2.387172225102287
Validation loss: 2.4572370854345396

Epoch: 6| Step: 6
Training loss: 2.183617770859604
Validation loss: 2.4369148464945076

Epoch: 6| Step: 7
Training loss: 1.9540742322239204
Validation loss: 2.446669741190331

Epoch: 6| Step: 8
Training loss: 1.8799936554172676
Validation loss: 2.4372150384989206

Epoch: 6| Step: 9
Training loss: 2.3982307270396626
Validation loss: 2.46518658542467

Epoch: 6| Step: 10
Training loss: 2.2151630043690447
Validation loss: 2.457147285216113

Epoch: 6| Step: 11
Training loss: 1.9221650191648163
Validation loss: 2.4557949527951126

Epoch: 6| Step: 12
Training loss: 1.9816689851499727
Validation loss: 2.4647059253461623

Epoch: 6| Step: 13
Training loss: 2.3460639212405074
Validation loss: 2.4688523589212994

Epoch: 56| Step: 0
Training loss: 2.8367331993766705
Validation loss: 2.470129215294344

Epoch: 6| Step: 1
Training loss: 2.133284408286477
Validation loss: 2.484247272334995

Epoch: 6| Step: 2
Training loss: 1.7301972393650162
Validation loss: 2.495256549205542

Epoch: 6| Step: 3
Training loss: 2.633065321920813
Validation loss: 2.4915817385545225

Epoch: 6| Step: 4
Training loss: 1.9684896145547386
Validation loss: 2.483981583192731

Epoch: 6| Step: 5
Training loss: 2.0826852426193017
Validation loss: 2.482139893530357

Epoch: 6| Step: 6
Training loss: 2.1646229813450626
Validation loss: 2.4692668132404614

Epoch: 6| Step: 7
Training loss: 2.405100461166228
Validation loss: 2.4648408884716

Epoch: 6| Step: 8
Training loss: 2.367908632326455
Validation loss: 2.471288237313683

Epoch: 6| Step: 9
Training loss: 2.050598950230761
Validation loss: 2.4641712559010207

Epoch: 6| Step: 10
Training loss: 2.137033387054984
Validation loss: 2.4583597397328925

Epoch: 6| Step: 11
Training loss: 2.1877364984461223
Validation loss: 2.462892609488817

Epoch: 6| Step: 12
Training loss: 2.4257129407715605
Validation loss: 2.4679229413279673

Epoch: 6| Step: 13
Training loss: 2.8567300873003405
Validation loss: 2.474387608812618

Epoch: 57| Step: 0
Training loss: 1.647800195808274
Validation loss: 2.4727835720360707

Epoch: 6| Step: 1
Training loss: 2.415166608540553
Validation loss: 2.485049198246953

Epoch: 6| Step: 2
Training loss: 2.9080250559360983
Validation loss: 2.489090880100282

Epoch: 6| Step: 3
Training loss: 2.5832610786751973
Validation loss: 2.4871095926060915

Epoch: 6| Step: 4
Training loss: 1.870033935606144
Validation loss: 2.5045732947680235

Epoch: 6| Step: 5
Training loss: 2.816299584600283
Validation loss: 2.501535738679353

Epoch: 6| Step: 6
Training loss: 2.6726617379844453
Validation loss: 2.5049113826597202

Epoch: 6| Step: 7
Training loss: 2.402491222290136
Validation loss: 2.492291008883478

Epoch: 6| Step: 8
Training loss: 2.5896300721087315
Validation loss: 2.4622749529146857

Epoch: 6| Step: 9
Training loss: 1.9774297085891293
Validation loss: 2.4516477409149227

Epoch: 6| Step: 10
Training loss: 2.3118047957990298
Validation loss: 2.4486900785188803

Epoch: 6| Step: 11
Training loss: 1.8227903340478282
Validation loss: 2.448798622711826

Epoch: 6| Step: 12
Training loss: 1.921702617574758
Validation loss: 2.4347466299000584

Epoch: 6| Step: 13
Training loss: 2.0563272525456076
Validation loss: 2.479487940596952

Epoch: 58| Step: 0
Training loss: 2.6603307456707492
Validation loss: 2.461711023258636

Epoch: 6| Step: 1
Training loss: 1.6567677822122917
Validation loss: 2.4401098608861793

Epoch: 6| Step: 2
Training loss: 2.0926959672723577
Validation loss: 2.452020432911381

Epoch: 6| Step: 3
Training loss: 2.7417519595745365
Validation loss: 2.4749212271745122

Epoch: 6| Step: 4
Training loss: 2.388858117292281
Validation loss: 2.490834082901877

Epoch: 6| Step: 5
Training loss: 2.8413538636650757
Validation loss: 2.4914366289521377

Epoch: 6| Step: 6
Training loss: 1.8945440862161798
Validation loss: 2.4940524761541973

Epoch: 6| Step: 7
Training loss: 1.8939105403320622
Validation loss: 2.497454221253083

Epoch: 6| Step: 8
Training loss: 2.474798109509301
Validation loss: 2.4886251757855766

Epoch: 6| Step: 9
Training loss: 2.6685709908906023
Validation loss: 2.495025915777022

Epoch: 6| Step: 10
Training loss: 2.388282376065424
Validation loss: 2.458694501521019

Epoch: 6| Step: 11
Training loss: 2.176749269204298
Validation loss: 2.4850309453683823

Epoch: 6| Step: 12
Training loss: 1.6838996060634914
Validation loss: 2.4495987544120745

Epoch: 6| Step: 13
Training loss: 2.290018031953007
Validation loss: 2.465484181272073

Epoch: 59| Step: 0
Training loss: 1.7721879228656328
Validation loss: 2.46389399153697

Epoch: 6| Step: 1
Training loss: 1.7194665282225927
Validation loss: 2.4830383127672198

Epoch: 6| Step: 2
Training loss: 3.0593207848394686
Validation loss: 2.4625894965934334

Epoch: 6| Step: 3
Training loss: 2.480977356198112
Validation loss: 2.462246404457159

Epoch: 6| Step: 4
Training loss: 2.635656252941
Validation loss: 2.4628807509343105

Epoch: 6| Step: 5
Training loss: 2.2789135817395776
Validation loss: 2.4821208748361885

Epoch: 6| Step: 6
Training loss: 2.645627852343043
Validation loss: 2.457057028889424

Epoch: 6| Step: 7
Training loss: 1.9590707837841044
Validation loss: 2.462385786864325

Epoch: 6| Step: 8
Training loss: 1.733036865348543
Validation loss: 2.473344366617948

Epoch: 6| Step: 9
Training loss: 2.0458820060124765
Validation loss: 2.4594828994393274

Epoch: 6| Step: 10
Training loss: 2.2631294976510796
Validation loss: 2.4664101356634434

Epoch: 6| Step: 11
Training loss: 2.3800457009167175
Validation loss: 2.4881287532529908

Epoch: 6| Step: 12
Training loss: 2.3433727723768967
Validation loss: 2.49437787175521

Epoch: 6| Step: 13
Training loss: 2.1618149306197534
Validation loss: 2.490099336041923

Epoch: 60| Step: 0
Training loss: 2.630437577835884
Validation loss: 2.480057249203162

Epoch: 6| Step: 1
Training loss: 2.25904458823407
Validation loss: 2.4810132487849317

Epoch: 6| Step: 2
Training loss: 2.38162992555412
Validation loss: 2.4678063178479133

Epoch: 6| Step: 3
Training loss: 2.0629981624208624
Validation loss: 2.442223707546137

Epoch: 6| Step: 4
Training loss: 2.68067197815885
Validation loss: 2.4694345305860876

Epoch: 6| Step: 5
Training loss: 2.464306272495991
Validation loss: 2.4717967069615288

Epoch: 6| Step: 6
Training loss: 2.1977308535262035
Validation loss: 2.461325478624242

Epoch: 6| Step: 7
Training loss: 2.308545003979864
Validation loss: 2.4481157641236204

Epoch: 6| Step: 8
Training loss: 1.6352626541737496
Validation loss: 2.4611396181777216

Epoch: 6| Step: 9
Training loss: 2.116912936604751
Validation loss: 2.4441651403884292

Epoch: 6| Step: 10
Training loss: 2.127937754545287
Validation loss: 2.434876489137453

Epoch: 6| Step: 11
Training loss: 2.306872763972412
Validation loss: 2.4488644057130977

Epoch: 6| Step: 12
Training loss: 1.9618818585196027
Validation loss: 2.4469792349916055

Epoch: 6| Step: 13
Training loss: 2.6511631446291073
Validation loss: 2.464549341770838

Epoch: 61| Step: 0
Training loss: 2.178413374212749
Validation loss: 2.4848695498688698

Epoch: 6| Step: 1
Training loss: 2.754007021095119
Validation loss: 2.51217020821531

Epoch: 6| Step: 2
Training loss: 2.667368965255437
Validation loss: 2.4856588377298756

Epoch: 6| Step: 3
Training loss: 2.2885254109401
Validation loss: 2.4920195121312503

Epoch: 6| Step: 4
Training loss: 2.2106257242423206
Validation loss: 2.4558961770368546

Epoch: 6| Step: 5
Training loss: 2.0904348517875104
Validation loss: 2.4530224788810955

Epoch: 6| Step: 6
Training loss: 2.9164974890190787
Validation loss: 2.4643918775379934

Epoch: 6| Step: 7
Training loss: 2.062709219753562
Validation loss: 2.4800521540797824

Epoch: 6| Step: 8
Training loss: 2.697831013816037
Validation loss: 2.460593257018143

Epoch: 6| Step: 9
Training loss: 1.7156887883346905
Validation loss: 2.4694190426542577

Epoch: 6| Step: 10
Training loss: 2.4095759009925466
Validation loss: 2.4886261497859086

Epoch: 6| Step: 11
Training loss: 1.6671403529643007
Validation loss: 2.462511243649292

Epoch: 6| Step: 12
Training loss: 1.9196793334131472
Validation loss: 2.4439663985523636

Epoch: 6| Step: 13
Training loss: 1.7771203875358739
Validation loss: 2.4721741570456732

Epoch: 62| Step: 0
Training loss: 1.6095376534348946
Validation loss: 2.470235409902053

Epoch: 6| Step: 1
Training loss: 1.9380395199630787
Validation loss: 2.480818548093319

Epoch: 6| Step: 2
Training loss: 1.95897488197164
Validation loss: 2.509782249306566

Epoch: 6| Step: 3
Training loss: 2.1271586953716946
Validation loss: 2.5200213761406975

Epoch: 6| Step: 4
Training loss: 2.2918773438686415
Validation loss: 2.5320307857862576

Epoch: 6| Step: 5
Training loss: 2.1782720748744255
Validation loss: 2.5116105123071772

Epoch: 6| Step: 6
Training loss: 2.2069097164754123
Validation loss: 2.5003800182795954

Epoch: 6| Step: 7
Training loss: 2.3831320626519106
Validation loss: 2.502321008282556

Epoch: 6| Step: 8
Training loss: 1.841520351391709
Validation loss: 2.4812128828140745

Epoch: 6| Step: 9
Training loss: 2.6510572951380156
Validation loss: 2.489762037771928

Epoch: 6| Step: 10
Training loss: 1.7688265780528962
Validation loss: 2.476863036587643

Epoch: 6| Step: 11
Training loss: 2.445382699172086
Validation loss: 2.4598048111256454

Epoch: 6| Step: 12
Training loss: 3.089035603662308
Validation loss: 2.4686513792531772

Epoch: 6| Step: 13
Training loss: 2.519274794663701
Validation loss: 2.449724176671405

Epoch: 63| Step: 0
Training loss: 2.4236060078399277
Validation loss: 2.449827208880906

Epoch: 6| Step: 1
Training loss: 1.9977988408906289
Validation loss: 2.4498267384981083

Epoch: 6| Step: 2
Training loss: 2.0673165002133667
Validation loss: 2.465523893461413

Epoch: 6| Step: 3
Training loss: 2.4357971699088146
Validation loss: 2.475929259521196

Epoch: 6| Step: 4
Training loss: 2.264201907755413
Validation loss: 2.4904191809999965

Epoch: 6| Step: 5
Training loss: 1.8847183142540087
Validation loss: 2.4943916674408917

Epoch: 6| Step: 6
Training loss: 2.1757605395880915
Validation loss: 2.4874915322522266

Epoch: 6| Step: 7
Training loss: 3.0069719998039526
Validation loss: 2.4937915084685933

Epoch: 6| Step: 8
Training loss: 1.6516843521654592
Validation loss: 2.4722477242467704

Epoch: 6| Step: 9
Training loss: 2.0511098834528108
Validation loss: 2.483231879301814

Epoch: 6| Step: 10
Training loss: 2.8996405148494606
Validation loss: 2.4685140730397648

Epoch: 6| Step: 11
Training loss: 2.0826781450623644
Validation loss: 2.4827507675559466

Epoch: 6| Step: 12
Training loss: 2.3652436486967248
Validation loss: 2.4646907543291317

Epoch: 6| Step: 13
Training loss: 1.6244265938491407
Validation loss: 2.4767540136630575

Epoch: 64| Step: 0
Training loss: 2.155163034879074
Validation loss: 2.4518455197748836

Epoch: 6| Step: 1
Training loss: 1.472092983683182
Validation loss: 2.4514440053615822

Epoch: 6| Step: 2
Training loss: 1.8736783137741895
Validation loss: 2.4621901457591147

Epoch: 6| Step: 3
Training loss: 1.9631460450655707
Validation loss: 2.4424814526918674

Epoch: 6| Step: 4
Training loss: 2.3371054494864034
Validation loss: 2.4485381183021357

Epoch: 6| Step: 5
Training loss: 2.525496738030701
Validation loss: 2.457119000621113

Epoch: 6| Step: 6
Training loss: 1.8048778615189507
Validation loss: 2.4424936217814017

Epoch: 6| Step: 7
Training loss: 1.7924891809113053
Validation loss: 2.4629574675114934

Epoch: 6| Step: 8
Training loss: 2.7829465513589993
Validation loss: 2.4529376434246557

Epoch: 6| Step: 9
Training loss: 3.0586459763161638
Validation loss: 2.46750277791226

Epoch: 6| Step: 10
Training loss: 2.560165923970174
Validation loss: 2.4621385176701795

Epoch: 6| Step: 11
Training loss: 2.7049935117633166
Validation loss: 2.455127765130405

Epoch: 6| Step: 12
Training loss: 1.6810527132700153
Validation loss: 2.4761773179935176

Epoch: 6| Step: 13
Training loss: 1.9603303372073142
Validation loss: 2.4573266721536173

Epoch: 65| Step: 0
Training loss: 2.272542770872922
Validation loss: 2.4656758946595945

Epoch: 6| Step: 1
Training loss: 2.2536067664511017
Validation loss: 2.480685343259514

Epoch: 6| Step: 2
Training loss: 3.138006988537059
Validation loss: 2.489398204565383

Epoch: 6| Step: 3
Training loss: 2.356000495470186
Validation loss: 2.4874314194878773

Epoch: 6| Step: 4
Training loss: 2.298932250588923
Validation loss: 2.508043993508269

Epoch: 6| Step: 5
Training loss: 2.0401421388960657
Validation loss: 2.492889823528895

Epoch: 6| Step: 6
Training loss: 1.7579861703487116
Validation loss: 2.4907149984260344

Epoch: 6| Step: 7
Training loss: 2.1126105465828773
Validation loss: 2.4574793905750285

Epoch: 6| Step: 8
Training loss: 2.090653820437908
Validation loss: 2.4450817791498616

Epoch: 6| Step: 9
Training loss: 2.3454618178988103
Validation loss: 2.4634367024573116

Epoch: 6| Step: 10
Training loss: 2.249508698123786
Validation loss: 2.458289523192302

Epoch: 6| Step: 11
Training loss: 1.8332246256879596
Validation loss: 2.465660512045567

Epoch: 6| Step: 12
Training loss: 2.0947306599610274
Validation loss: 2.4732325375994857

Epoch: 6| Step: 13
Training loss: 1.9927043169628877
Validation loss: 2.4441204476454663

Epoch: 66| Step: 0
Training loss: 1.8944548601303577
Validation loss: 2.4548706598259518

Epoch: 6| Step: 1
Training loss: 2.692110232563381
Validation loss: 2.470539442427826

Epoch: 6| Step: 2
Training loss: 1.8740652933460897
Validation loss: 2.4868533969786744

Epoch: 6| Step: 3
Training loss: 1.8558660142153922
Validation loss: 2.498335204536224

Epoch: 6| Step: 4
Training loss: 2.7520066656098483
Validation loss: 2.4760943270101055

Epoch: 6| Step: 5
Training loss: 2.1498241042110005
Validation loss: 2.4680586865009957

Epoch: 6| Step: 6
Training loss: 1.9147584233908697
Validation loss: 2.4732565650782115

Epoch: 6| Step: 7
Training loss: 2.099937292706804
Validation loss: 2.46733925344435

Epoch: 6| Step: 8
Training loss: 2.5200633825172525
Validation loss: 2.457146864749961

Epoch: 6| Step: 9
Training loss: 1.8690681722504214
Validation loss: 2.4671859937699083

Epoch: 6| Step: 10
Training loss: 2.148101558429761
Validation loss: 2.4311993015890403

Epoch: 6| Step: 11
Training loss: 2.8646020692154806
Validation loss: 2.4614633149817564

Epoch: 6| Step: 12
Training loss: 2.4062567376376855
Validation loss: 2.4493883430135046

Epoch: 6| Step: 13
Training loss: 1.8748454348116819
Validation loss: 2.4428254501365836

Epoch: 67| Step: 0
Training loss: 2.738101098940877
Validation loss: 2.466520767686931

Epoch: 6| Step: 1
Training loss: 1.6314968667732384
Validation loss: 2.4783027423231108

Epoch: 6| Step: 2
Training loss: 2.096436783641514
Validation loss: 2.491408526297042

Epoch: 6| Step: 3
Training loss: 2.512453817066464
Validation loss: 2.4931492877885515

Epoch: 6| Step: 4
Training loss: 2.224852859260883
Validation loss: 2.497528714386275

Epoch: 6| Step: 5
Training loss: 2.522694575779727
Validation loss: 2.503484998985792

Epoch: 6| Step: 6
Training loss: 1.994026262999956
Validation loss: 2.510348075045718

Epoch: 6| Step: 7
Training loss: 2.2784251660264414
Validation loss: 2.4815678281638385

Epoch: 6| Step: 8
Training loss: 1.9059783241664587
Validation loss: 2.493610338651911

Epoch: 6| Step: 9
Training loss: 2.7240137467786685
Validation loss: 2.4707541318511046

Epoch: 6| Step: 10
Training loss: 1.5146938491792106
Validation loss: 2.4559537124859117

Epoch: 6| Step: 11
Training loss: 1.9033577662345564
Validation loss: 2.4808750410570877

Epoch: 6| Step: 12
Training loss: 2.245098284840499
Validation loss: 2.420058522896077

Epoch: 6| Step: 13
Training loss: 2.358000702421878
Validation loss: 2.43607968740617

Epoch: 68| Step: 0
Training loss: 1.7239488522671298
Validation loss: 2.483939078611318

Epoch: 6| Step: 1
Training loss: 1.7616339618723147
Validation loss: 2.4744027123469565

Epoch: 6| Step: 2
Training loss: 2.7711603836897183
Validation loss: 2.4797480860429477

Epoch: 6| Step: 3
Training loss: 2.036189250941428
Validation loss: 2.480344433810612

Epoch: 6| Step: 4
Training loss: 1.7699267890574024
Validation loss: 2.488054793197089

Epoch: 6| Step: 5
Training loss: 2.330161618369981
Validation loss: 2.4934199523499556

Epoch: 6| Step: 6
Training loss: 2.1942389092853425
Validation loss: 2.5158684891094194

Epoch: 6| Step: 7
Training loss: 1.8721638528282047
Validation loss: 2.5219450199155347

Epoch: 6| Step: 8
Training loss: 2.142526158247697
Validation loss: 2.5348873769758726

Epoch: 6| Step: 9
Training loss: 2.1758445853803536
Validation loss: 2.528835510829544

Epoch: 6| Step: 10
Training loss: 2.3236826045875527
Validation loss: 2.5220535624778555

Epoch: 6| Step: 11
Training loss: 2.0984522838171173
Validation loss: 2.506794351456473

Epoch: 6| Step: 12
Training loss: 2.8492266559412696
Validation loss: 2.5037778681605354

Epoch: 6| Step: 13
Training loss: 2.3288989732712446
Validation loss: 2.4866982399552784

Epoch: 69| Step: 0
Training loss: 2.236943189504116
Validation loss: 2.485796939337481

Epoch: 6| Step: 1
Training loss: 2.161703428290649
Validation loss: 2.4391701999747757

Epoch: 6| Step: 2
Training loss: 2.0084348671389747
Validation loss: 2.4521924653855165

Epoch: 6| Step: 3
Training loss: 2.1653042202027484
Validation loss: 2.4543902946703446

Epoch: 6| Step: 4
Training loss: 2.032672794593456
Validation loss: 2.4346961335620056

Epoch: 6| Step: 5
Training loss: 1.9747891518758287
Validation loss: 2.448260024860022

Epoch: 6| Step: 6
Training loss: 2.196277772731099
Validation loss: 2.440637883646064

Epoch: 6| Step: 7
Training loss: 2.2588004620334914
Validation loss: 2.4672109095836063

Epoch: 6| Step: 8
Training loss: 2.146642538531374
Validation loss: 2.455072039280776

Epoch: 6| Step: 9
Training loss: 2.3037257369901374
Validation loss: 2.438224000267854

Epoch: 6| Step: 10
Training loss: 2.7343226836513055
Validation loss: 2.4542653699195878

Epoch: 6| Step: 11
Training loss: 2.538311186919489
Validation loss: 2.4867282973911276

Epoch: 6| Step: 12
Training loss: 1.9530201998250512
Validation loss: 2.483865041796302

Epoch: 6| Step: 13
Training loss: 1.5841506889510086
Validation loss: 2.4862406860862434

Epoch: 70| Step: 0
Training loss: 2.6895863618447065
Validation loss: 2.509892956463638

Epoch: 6| Step: 1
Training loss: 2.2148661402086964
Validation loss: 2.5158499386131905

Epoch: 6| Step: 2
Training loss: 1.8530158925864886
Validation loss: 2.527356139383112

Epoch: 6| Step: 3
Training loss: 2.226576848569447
Validation loss: 2.473177830232495

Epoch: 6| Step: 4
Training loss: 1.6707984096209934
Validation loss: 2.495107536521208

Epoch: 6| Step: 5
Training loss: 2.275316019431422
Validation loss: 2.47199546176428

Epoch: 6| Step: 6
Training loss: 2.127674215246109
Validation loss: 2.4870980652087216

Epoch: 6| Step: 7
Training loss: 1.9115352216704047
Validation loss: 2.4587909924429394

Epoch: 6| Step: 8
Training loss: 2.204914853967071
Validation loss: 2.4580516384392097

Epoch: 6| Step: 9
Training loss: 2.0575104673543474
Validation loss: 2.453938926229035

Epoch: 6| Step: 10
Training loss: 2.383089543480755
Validation loss: 2.4597047493436865

Epoch: 6| Step: 11
Training loss: 2.151926654480451
Validation loss: 2.453530458282897

Epoch: 6| Step: 12
Training loss: 2.5595833531716634
Validation loss: 2.449973655740699

Epoch: 6| Step: 13
Training loss: 1.7355550926781522
Validation loss: 2.4639464133910134

Epoch: 71| Step: 0
Training loss: 2.2327277240182264
Validation loss: 2.4568345921610257

Epoch: 6| Step: 1
Training loss: 2.404427767304228
Validation loss: 2.4703223295617427

Epoch: 6| Step: 2
Training loss: 1.7170834871677896
Validation loss: 2.477868522979015

Epoch: 6| Step: 3
Training loss: 2.283795752189702
Validation loss: 2.479043778544716

Epoch: 6| Step: 4
Training loss: 2.706419420115013
Validation loss: 2.490826911990313

Epoch: 6| Step: 5
Training loss: 2.812424891846506
Validation loss: 2.497785318424718

Epoch: 6| Step: 6
Training loss: 1.6130960649144037
Validation loss: 2.493510406380634

Epoch: 6| Step: 7
Training loss: 2.2351661828576046
Validation loss: 2.521870034743553

Epoch: 6| Step: 8
Training loss: 1.539020131104035
Validation loss: 2.4691095372042224

Epoch: 6| Step: 9
Training loss: 1.8222611111404103
Validation loss: 2.4648545512321944

Epoch: 6| Step: 10
Training loss: 2.6691396888832877
Validation loss: 2.47654166548797

Epoch: 6| Step: 11
Training loss: 1.9031235743424912
Validation loss: 2.4699553110607666

Epoch: 6| Step: 12
Training loss: 1.985445049465951
Validation loss: 2.454370494294732

Epoch: 6| Step: 13
Training loss: 1.9229082880908723
Validation loss: 2.4494813882692097

Epoch: 72| Step: 0
Training loss: 2.0692466439338246
Validation loss: 2.463384648830852

Epoch: 6| Step: 1
Training loss: 2.173263215921226
Validation loss: 2.441767665306106

Epoch: 6| Step: 2
Training loss: 1.9180875846268868
Validation loss: 2.4358417543554327

Epoch: 6| Step: 3
Training loss: 1.9291503405721238
Validation loss: 2.4596287552417047

Epoch: 6| Step: 4
Training loss: 2.0332766472883024
Validation loss: 2.447046877498914

Epoch: 6| Step: 5
Training loss: 2.618663405850796
Validation loss: 2.4274569184330104

Epoch: 6| Step: 6
Training loss: 2.3405968372805046
Validation loss: 2.4224240900881036

Epoch: 6| Step: 7
Training loss: 2.0992677774443202
Validation loss: 2.4332336681892692

Epoch: 6| Step: 8
Training loss: 1.8950267025920735
Validation loss: 2.452840379535542

Epoch: 6| Step: 9
Training loss: 2.0765643462093233
Validation loss: 2.4576267476994738

Epoch: 6| Step: 10
Training loss: 2.419548245974775
Validation loss: 2.4747612436647173

Epoch: 6| Step: 11
Training loss: 2.2147546175021446
Validation loss: 2.4666743344969606

Epoch: 6| Step: 12
Training loss: 1.727173019798487
Validation loss: 2.5144741830047237

Epoch: 6| Step: 13
Training loss: 2.245841103317984
Validation loss: 2.5232382145502514

Epoch: 73| Step: 0
Training loss: 1.4865551648571445
Validation loss: 2.542768916859476

Epoch: 6| Step: 1
Training loss: 2.5286643868632273
Validation loss: 2.5974852082581243

Epoch: 6| Step: 2
Training loss: 2.152804953564261
Validation loss: 2.6062249912004316

Epoch: 6| Step: 3
Training loss: 1.8291525276118443
Validation loss: 2.576729969252141

Epoch: 6| Step: 4
Training loss: 2.582452829083412
Validation loss: 2.5457512730444143

Epoch: 6| Step: 5
Training loss: 2.4800312767825288
Validation loss: 2.527315983725389

Epoch: 6| Step: 6
Training loss: 2.477334753505572
Validation loss: 2.4765723836964315

Epoch: 6| Step: 7
Training loss: 1.6208103161953298
Validation loss: 2.4682594487965575

Epoch: 6| Step: 8
Training loss: 2.167361392612908
Validation loss: 2.45637496164454

Epoch: 6| Step: 9
Training loss: 1.7564469522294415
Validation loss: 2.4280199909455593

Epoch: 6| Step: 10
Training loss: 2.616268076171252
Validation loss: 2.44192794718969

Epoch: 6| Step: 11
Training loss: 2.333187155458962
Validation loss: 2.460112704968496

Epoch: 6| Step: 12
Training loss: 1.6238029913004455
Validation loss: 2.4657469322440515

Epoch: 6| Step: 13
Training loss: 2.151824722433935
Validation loss: 2.438838851876933

Epoch: 74| Step: 0
Training loss: 1.5319564124099372
Validation loss: 2.4605522782704017

Epoch: 6| Step: 1
Training loss: 2.2856876635704078
Validation loss: 2.463879839622378

Epoch: 6| Step: 2
Training loss: 2.1027591517485904
Validation loss: 2.4756593551633923

Epoch: 6| Step: 3
Training loss: 2.1806055685518566
Validation loss: 2.5150455415620576

Epoch: 6| Step: 4
Training loss: 1.932367726051779
Validation loss: 2.5161795468928574

Epoch: 6| Step: 5
Training loss: 2.209929866799921
Validation loss: 2.526026520568954

Epoch: 6| Step: 6
Training loss: 2.08548323010269
Validation loss: 2.534167111952982

Epoch: 6| Step: 7
Training loss: 1.9501249542304788
Validation loss: 2.5078469786051456

Epoch: 6| Step: 8
Training loss: 2.420979881994019
Validation loss: 2.466219542763689

Epoch: 6| Step: 9
Training loss: 1.5130133396122873
Validation loss: 2.4946980601504585

Epoch: 6| Step: 10
Training loss: 2.1966890519564
Validation loss: 2.5045011372126056

Epoch: 6| Step: 11
Training loss: 2.524475451079013
Validation loss: 2.4570498483476517

Epoch: 6| Step: 12
Training loss: 2.4180192341256435
Validation loss: 2.4874280088476795

Epoch: 6| Step: 13
Training loss: 2.122063234320052
Validation loss: 2.4728341262098614

Epoch: 75| Step: 0
Training loss: 1.5592188907986004
Validation loss: 2.47526503470022

Epoch: 6| Step: 1
Training loss: 1.6560580304293495
Validation loss: 2.4502540035017244

Epoch: 6| Step: 2
Training loss: 2.7160245893317563
Validation loss: 2.4764062810137206

Epoch: 6| Step: 3
Training loss: 2.3257755995769243
Validation loss: 2.4397968165166555

Epoch: 6| Step: 4
Training loss: 2.289579573938571
Validation loss: 2.4664374598342076

Epoch: 6| Step: 5
Training loss: 2.358081488310248
Validation loss: 2.4724434373825233

Epoch: 6| Step: 6
Training loss: 1.892979755440466
Validation loss: 2.4298878676048616

Epoch: 6| Step: 7
Training loss: 1.504782206089124
Validation loss: 2.4478396193912197

Epoch: 6| Step: 8
Training loss: 1.7356700014702986
Validation loss: 2.481531671379712

Epoch: 6| Step: 9
Training loss: 2.332927078121186
Validation loss: 2.4765359453929685

Epoch: 6| Step: 10
Training loss: 2.4693861515968383
Validation loss: 2.4545388814354343

Epoch: 6| Step: 11
Training loss: 2.3001680188382925
Validation loss: 2.4600184101873492

Epoch: 6| Step: 12
Training loss: 2.1477328167835075
Validation loss: 2.4878041335464633

Epoch: 6| Step: 13
Training loss: 1.8098951893171815
Validation loss: 2.477199340191443

Epoch: 76| Step: 0
Training loss: 1.8878843130980574
Validation loss: 2.458598742193603

Epoch: 6| Step: 1
Training loss: 2.0889757296703118
Validation loss: 2.4814341190930884

Epoch: 6| Step: 2
Training loss: 1.822809561353146
Validation loss: 2.5101379197566733

Epoch: 6| Step: 3
Training loss: 2.2488349441337467
Validation loss: 2.550314361542917

Epoch: 6| Step: 4
Training loss: 2.3897771391450444
Validation loss: 2.5059951582900166

Epoch: 6| Step: 5
Training loss: 2.4451324104074708
Validation loss: 2.500991068535676

Epoch: 6| Step: 6
Training loss: 1.3616888589034992
Validation loss: 2.4746569774678817

Epoch: 6| Step: 7
Training loss: 1.9433418311472554
Validation loss: 2.465749373721749

Epoch: 6| Step: 8
Training loss: 2.135007853259042
Validation loss: 2.491362719246746

Epoch: 6| Step: 9
Training loss: 1.5234040085461225
Validation loss: 2.449624789953965

Epoch: 6| Step: 10
Training loss: 2.3707732686332257
Validation loss: 2.4717355372925107

Epoch: 6| Step: 11
Training loss: 2.3210657611752827
Validation loss: 2.455239132113574

Epoch: 6| Step: 12
Training loss: 2.824989393096186
Validation loss: 2.452921800235979

Epoch: 6| Step: 13
Training loss: 1.905733882887444
Validation loss: 2.4647199999681506

Epoch: 77| Step: 0
Training loss: 2.129676385572039
Validation loss: 2.45712681166531

Epoch: 6| Step: 1
Training loss: 1.8679650894186608
Validation loss: 2.4783579257889943

Epoch: 6| Step: 2
Training loss: 2.0833410898700007
Validation loss: 2.5064540364583707

Epoch: 6| Step: 3
Training loss: 2.026723660286724
Validation loss: 2.532092978370337

Epoch: 6| Step: 4
Training loss: 2.9232817338705237
Validation loss: 2.5517345164136245

Epoch: 6| Step: 5
Training loss: 2.120421020159528
Validation loss: 2.584375730035472

Epoch: 6| Step: 6
Training loss: 1.8164661684715688
Validation loss: 2.599277978682242

Epoch: 6| Step: 7
Training loss: 2.3148863568023526
Validation loss: 2.6346721703290727

Epoch: 6| Step: 8
Training loss: 1.8799925140475309
Validation loss: 2.6258315479833825

Epoch: 6| Step: 9
Training loss: 2.1672936290451075
Validation loss: 2.556967989967243

Epoch: 6| Step: 10
Training loss: 1.8068585568514108
Validation loss: 2.541572496097547

Epoch: 6| Step: 11
Training loss: 1.918082736914817
Validation loss: 2.5045645766337805

Epoch: 6| Step: 12
Training loss: 2.038266549106745
Validation loss: 2.4928194398796553

Epoch: 6| Step: 13
Training loss: 1.7835979045563883
Validation loss: 2.462713273005825

Epoch: 78| Step: 0
Training loss: 2.1846817390628943
Validation loss: 2.4572406996912153

Epoch: 6| Step: 1
Training loss: 1.7858415285825227
Validation loss: 2.445620597629369

Epoch: 6| Step: 2
Training loss: 2.2885266610997683
Validation loss: 2.426394030439314

Epoch: 6| Step: 3
Training loss: 2.06033789854105
Validation loss: 2.4514881026303295

Epoch: 6| Step: 4
Training loss: 1.397927004590683
Validation loss: 2.4523818070722796

Epoch: 6| Step: 5
Training loss: 2.0156901740840953
Validation loss: 2.411999706910402

Epoch: 6| Step: 6
Training loss: 1.8139125975610226
Validation loss: 2.427835492549664

Epoch: 6| Step: 7
Training loss: 2.4193342109539127
Validation loss: 2.44360812979471

Epoch: 6| Step: 8
Training loss: 1.9893357154450118
Validation loss: 2.4652612557253044

Epoch: 6| Step: 9
Training loss: 1.8492047069614252
Validation loss: 2.4770262611900553

Epoch: 6| Step: 10
Training loss: 2.687762846402144
Validation loss: 2.500795222009702

Epoch: 6| Step: 11
Training loss: 1.6664758652508296
Validation loss: 2.5388905784894393

Epoch: 6| Step: 12
Training loss: 2.6075363534092073
Validation loss: 2.498959579138838

Epoch: 6| Step: 13
Training loss: 1.7417751217647426
Validation loss: 2.513372490874649

Epoch: 79| Step: 0
Training loss: 2.6012759122424036
Validation loss: 2.545464872260841

Epoch: 6| Step: 1
Training loss: 2.1790721393844117
Validation loss: 2.5384567085818897

Epoch: 6| Step: 2
Training loss: 1.5975795438302114
Validation loss: 2.4746810714022227

Epoch: 6| Step: 3
Training loss: 2.004463341446016
Validation loss: 2.4596855571772918

Epoch: 6| Step: 4
Training loss: 1.9928372389448399
Validation loss: 2.4505306220729013

Epoch: 6| Step: 5
Training loss: 1.704839840523425
Validation loss: 2.470563455888378

Epoch: 6| Step: 6
Training loss: 1.5599191331688855
Validation loss: 2.4541815165236134

Epoch: 6| Step: 7
Training loss: 2.5056017106178263
Validation loss: 2.462108143902934

Epoch: 6| Step: 8
Training loss: 1.958702789789364
Validation loss: 2.447278013855106

Epoch: 6| Step: 9
Training loss: 2.1847558384005508
Validation loss: 2.4468313665547323

Epoch: 6| Step: 10
Training loss: 2.718449981622209
Validation loss: 2.4479809745836723

Epoch: 6| Step: 11
Training loss: 1.8345794199909675
Validation loss: 2.531829485082758

Epoch: 6| Step: 12
Training loss: 1.808380180256014
Validation loss: 2.5276043544800397

Epoch: 6| Step: 13
Training loss: 1.8273470274727448
Validation loss: 2.5699589417538595

Epoch: 80| Step: 0
Training loss: 1.2510577018444917
Validation loss: 2.5924273416164763

Epoch: 6| Step: 1
Training loss: 2.6957916276192853
Validation loss: 2.5728042258791355

Epoch: 6| Step: 2
Training loss: 2.5113944738668876
Validation loss: 2.554536245303347

Epoch: 6| Step: 3
Training loss: 2.186297276783444
Validation loss: 2.5473623297081875

Epoch: 6| Step: 4
Training loss: 1.925779021534588
Validation loss: 2.5213826240478623

Epoch: 6| Step: 5
Training loss: 1.6546788951156541
Validation loss: 2.443559255741299

Epoch: 6| Step: 6
Training loss: 1.549999587766531
Validation loss: 2.4849835336294412

Epoch: 6| Step: 7
Training loss: 1.8077492111852163
Validation loss: 2.47432558780393

Epoch: 6| Step: 8
Training loss: 1.9635813849873271
Validation loss: 2.4596325840823474

Epoch: 6| Step: 9
Training loss: 2.005895151861136
Validation loss: 2.4626277467669

Epoch: 6| Step: 10
Training loss: 2.566077363701068
Validation loss: 2.438719664384508

Epoch: 6| Step: 11
Training loss: 1.5020543970856046
Validation loss: 2.4695252758461925

Epoch: 6| Step: 12
Training loss: 2.6179485068681236
Validation loss: 2.4633907462756426

Epoch: 6| Step: 13
Training loss: 2.0679679983013015
Validation loss: 2.437931870242666

Epoch: 81| Step: 0
Training loss: 1.9048904198195722
Validation loss: 2.4781248056572815

Epoch: 6| Step: 1
Training loss: 1.8122943235311282
Validation loss: 2.4868142810639933

Epoch: 6| Step: 2
Training loss: 1.8829214610628038
Validation loss: 2.4600999648244626

Epoch: 6| Step: 3
Training loss: 2.181742803217948
Validation loss: 2.488329429299762

Epoch: 6| Step: 4
Training loss: 2.222896730523655
Validation loss: 2.5131434013770098

Epoch: 6| Step: 5
Training loss: 2.1359098531723912
Validation loss: 2.516056584521961

Epoch: 6| Step: 6
Training loss: 2.2378517258030497
Validation loss: 2.532485362189801

Epoch: 6| Step: 7
Training loss: 1.543215652219537
Validation loss: 2.4985164691086315

Epoch: 6| Step: 8
Training loss: 1.7714954783839254
Validation loss: 2.4925245258447224

Epoch: 6| Step: 9
Training loss: 2.2517864764471462
Validation loss: 2.465560011013262

Epoch: 6| Step: 10
Training loss: 1.8838685425819872
Validation loss: 2.4921790335101828

Epoch: 6| Step: 11
Training loss: 1.9208733033871352
Validation loss: 2.5114362843601863

Epoch: 6| Step: 12
Training loss: 2.0889777840418646
Validation loss: 2.492494633961229

Epoch: 6| Step: 13
Training loss: 1.9844263625819256
Validation loss: 2.5021240588920093

Epoch: 82| Step: 0
Training loss: 2.0794808689933353
Validation loss: 2.5017121492029992

Epoch: 6| Step: 1
Training loss: 1.9829970253649403
Validation loss: 2.5174038365271674

Epoch: 6| Step: 2
Training loss: 2.1087885288592223
Validation loss: 2.4910648651544425

Epoch: 6| Step: 3
Training loss: 2.164448066819798
Validation loss: 2.4765736352006336

Epoch: 6| Step: 4
Training loss: 2.5692691250577657
Validation loss: 2.4773816539984868

Epoch: 6| Step: 5
Training loss: 2.2308056471708193
Validation loss: 2.4599196009174578

Epoch: 6| Step: 6
Training loss: 1.665090180896025
Validation loss: 2.4717339939645946

Epoch: 6| Step: 7
Training loss: 1.88879747574705
Validation loss: 2.473390684088394

Epoch: 6| Step: 8
Training loss: 1.9436626868554245
Validation loss: 2.4666870286032374

Epoch: 6| Step: 9
Training loss: 2.013011924128456
Validation loss: 2.466634560281564

Epoch: 6| Step: 10
Training loss: 1.4933922183540989
Validation loss: 2.4712151319802858

Epoch: 6| Step: 11
Training loss: 1.682724730629905
Validation loss: 2.483874256524459

Epoch: 6| Step: 12
Training loss: 1.7727269837350321
Validation loss: 2.468195245277205

Epoch: 6| Step: 13
Training loss: 1.9175545114977643
Validation loss: 2.51774828217178

Epoch: 83| Step: 0
Training loss: 2.312880819770531
Validation loss: 2.5500703982689825

Epoch: 6| Step: 1
Training loss: 1.8400697346616972
Validation loss: 2.600874831889065

Epoch: 6| Step: 2
Training loss: 2.516677920419487
Validation loss: 2.6481728960786213

Epoch: 6| Step: 3
Training loss: 1.4129308735433115
Validation loss: 2.6153519983598787

Epoch: 6| Step: 4
Training loss: 2.1071395897089493
Validation loss: 2.557420860699356

Epoch: 6| Step: 5
Training loss: 2.0989786025615484
Validation loss: 2.5573291244923015

Epoch: 6| Step: 6
Training loss: 2.5902949841984357
Validation loss: 2.4724454624189853

Epoch: 6| Step: 7
Training loss: 2.024978345590358
Validation loss: 2.445539015088591

Epoch: 6| Step: 8
Training loss: 2.007744576459306
Validation loss: 2.4661064158226385

Epoch: 6| Step: 9
Training loss: 1.7852471994149155
Validation loss: 2.496553692059051

Epoch: 6| Step: 10
Training loss: 1.4996775439488934
Validation loss: 2.4918754007520785

Epoch: 6| Step: 11
Training loss: 1.595143924067283
Validation loss: 2.4640545193597974

Epoch: 6| Step: 12
Training loss: 1.8363176966705594
Validation loss: 2.471126876900066

Epoch: 6| Step: 13
Training loss: 1.8851878903797101
Validation loss: 2.5205371987503016

Epoch: 84| Step: 0
Training loss: 2.182254715077846
Validation loss: 2.52369302847503

Epoch: 6| Step: 1
Training loss: 1.6812200607413534
Validation loss: 2.5077015821541337

Epoch: 6| Step: 2
Training loss: 2.368619882034441
Validation loss: 2.5629642500222847

Epoch: 6| Step: 3
Training loss: 2.094365271508991
Validation loss: 2.5466019809789593

Epoch: 6| Step: 4
Training loss: 1.5191434939164379
Validation loss: 2.507667624467008

Epoch: 6| Step: 5
Training loss: 1.612487967394506
Validation loss: 2.47962146615824

Epoch: 6| Step: 6
Training loss: 2.1958337348295807
Validation loss: 2.4767653485486756

Epoch: 6| Step: 7
Training loss: 1.8777835529221027
Validation loss: 2.470597441050175

Epoch: 6| Step: 8
Training loss: 2.2908877233785834
Validation loss: 2.498334600139939

Epoch: 6| Step: 9
Training loss: 1.9129543288383002
Validation loss: 2.503722447449885

Epoch: 6| Step: 10
Training loss: 2.1535543647601605
Validation loss: 2.4940010734755655

Epoch: 6| Step: 11
Training loss: 1.7524054208176636
Validation loss: 2.497536796805342

Epoch: 6| Step: 12
Training loss: 1.5894055711668977
Validation loss: 2.502622246387498

Epoch: 6| Step: 13
Training loss: 1.9154250919648272
Validation loss: 2.5431012706535463

Epoch: 85| Step: 0
Training loss: 1.5222264097593925
Validation loss: 2.498261053563685

Epoch: 6| Step: 1
Training loss: 1.8843244125129852
Validation loss: 2.502040920062198

Epoch: 6| Step: 2
Training loss: 1.9573569264748365
Validation loss: 2.4950354396619434

Epoch: 6| Step: 3
Training loss: 1.5838693748713224
Validation loss: 2.5052110403658276

Epoch: 6| Step: 4
Training loss: 2.7107837644404085
Validation loss: 2.510935406623669

Epoch: 6| Step: 5
Training loss: 1.7547060495892433
Validation loss: 2.482121611252985

Epoch: 6| Step: 6
Training loss: 1.7887071814700362
Validation loss: 2.4508940479739896

Epoch: 6| Step: 7
Training loss: 1.4772061352959531
Validation loss: 2.522152828589058

Epoch: 6| Step: 8
Training loss: 1.7317193121643724
Validation loss: 2.5209432267965344

Epoch: 6| Step: 9
Training loss: 2.279214865705455
Validation loss: 2.5040459080637594

Epoch: 6| Step: 10
Training loss: 1.9926566973900859
Validation loss: 2.5460651725015055

Epoch: 6| Step: 11
Training loss: 1.9018760905292456
Validation loss: 2.5731811747836777

Epoch: 6| Step: 12
Training loss: 1.9734258076011064
Validation loss: 2.6112421174247684

Epoch: 6| Step: 13
Training loss: 2.0613958697873436
Validation loss: 2.589663001073072

Epoch: 86| Step: 0
Training loss: 1.2979831327479778
Validation loss: 2.599694292423622

Epoch: 6| Step: 1
Training loss: 1.685566041203133
Validation loss: 2.551176288853829

Epoch: 6| Step: 2
Training loss: 1.8210932813044027
Validation loss: 2.5442556630010618

Epoch: 6| Step: 3
Training loss: 1.9368272659411994
Validation loss: 2.4908004376674833

Epoch: 6| Step: 4
Training loss: 1.9524906196320064
Validation loss: 2.5120081045208322

Epoch: 6| Step: 5
Training loss: 1.9708344460202625
Validation loss: 2.4910581894076937

Epoch: 6| Step: 6
Training loss: 1.397441232090497
Validation loss: 2.579014048788188

Epoch: 6| Step: 7
Training loss: 1.9795813142860803
Validation loss: 2.561705008521592

Epoch: 6| Step: 8
Training loss: 2.3858221339705623
Validation loss: 2.5269734004660807

Epoch: 6| Step: 9
Training loss: 1.903237385555561
Validation loss: 2.560364608814829

Epoch: 6| Step: 10
Training loss: 1.9111465976005455
Validation loss: 2.491231378172115

Epoch: 6| Step: 11
Training loss: 1.621838428474545
Validation loss: 2.503870003170593

Epoch: 6| Step: 12
Training loss: 1.5829632309808106
Validation loss: 2.4828003105438916

Epoch: 6| Step: 13
Training loss: 2.6719426375187996
Validation loss: 2.4676888515164466

Epoch: 87| Step: 0
Training loss: 1.6171870577161986
Validation loss: 2.4821764096550165

Epoch: 6| Step: 1
Training loss: 1.7924871857635996
Validation loss: 2.479062844888745

Epoch: 6| Step: 2
Training loss: 1.7991683919785557
Validation loss: 2.4890472335011995

Epoch: 6| Step: 3
Training loss: 1.5812201033468654
Validation loss: 2.4599897386238676

Epoch: 6| Step: 4
Training loss: 2.021059973942863
Validation loss: 2.5292318799715034

Epoch: 6| Step: 5
Training loss: 2.272287608881857
Validation loss: 2.526914549304285

Epoch: 6| Step: 6
Training loss: 2.1947748469314896
Validation loss: 2.596013119769729

Epoch: 6| Step: 7
Training loss: 1.7564173608500928
Validation loss: 2.583363630260705

Epoch: 6| Step: 8
Training loss: 1.988883716012963
Validation loss: 2.579085061462146

Epoch: 6| Step: 9
Training loss: 2.18191928159678
Validation loss: 2.539017818742477

Epoch: 6| Step: 10
Training loss: 1.8051199787028582
Validation loss: 2.5276720717153203

Epoch: 6| Step: 11
Training loss: 1.9517220302887408
Validation loss: 2.545053482068291

Epoch: 6| Step: 12
Training loss: 1.946689654447527
Validation loss: 2.492511692306658

Epoch: 6| Step: 13
Training loss: 1.276987101842973
Validation loss: 2.4664673372440453

Epoch: 88| Step: 0
Training loss: 1.8141728278099136
Validation loss: 2.485994718681571

Epoch: 6| Step: 1
Training loss: 1.4821943628681893
Validation loss: 2.4951016280652745

Epoch: 6| Step: 2
Training loss: 1.739272617146424
Validation loss: 2.4834409993362527

Epoch: 6| Step: 3
Training loss: 1.84238603216153
Validation loss: 2.530737397208722

Epoch: 6| Step: 4
Training loss: 1.6526817174541362
Validation loss: 2.5266810967914854

Epoch: 6| Step: 5
Training loss: 1.920139800982252
Validation loss: 2.503383294223711

Epoch: 6| Step: 6
Training loss: 1.7819056057316944
Validation loss: 2.4840019753753353

Epoch: 6| Step: 7
Training loss: 1.466447364421795
Validation loss: 2.5441170017639814

Epoch: 6| Step: 8
Training loss: 1.1070228140219494
Validation loss: 2.5578376875973072

Epoch: 6| Step: 9
Training loss: 1.8744916862655492
Validation loss: 2.575819822930265

Epoch: 6| Step: 10
Training loss: 2.0335748133032308
Validation loss: 2.638168832908379

Epoch: 6| Step: 11
Training loss: 2.6111902558617075
Validation loss: 2.6066619260879818

Epoch: 6| Step: 12
Training loss: 2.5420416154133685
Validation loss: 2.645460317754958

Epoch: 6| Step: 13
Training loss: 1.560047055292815
Validation loss: 2.5747953240983126

Epoch: 89| Step: 0
Training loss: 1.7379524520059084
Validation loss: 2.5591413615631984

Epoch: 6| Step: 1
Training loss: 2.560287637048585
Validation loss: 2.522038972763736

Epoch: 6| Step: 2
Training loss: 1.6513604017915728
Validation loss: 2.4901807592267367

Epoch: 6| Step: 3
Training loss: 2.100675601366792
Validation loss: 2.515611115411387

Epoch: 6| Step: 4
Training loss: 1.6188229017890028
Validation loss: 2.4903667659099082

Epoch: 6| Step: 5
Training loss: 1.8240598164169912
Validation loss: 2.52427087964345

Epoch: 6| Step: 6
Training loss: 1.84287059954338
Validation loss: 2.560519406704545

Epoch: 6| Step: 7
Training loss: 1.5385702672463935
Validation loss: 2.5549285806029114

Epoch: 6| Step: 8
Training loss: 1.6565344224387881
Validation loss: 2.570324264855017

Epoch: 6| Step: 9
Training loss: 1.6480614834445653
Validation loss: 2.5656377453628765

Epoch: 6| Step: 10
Training loss: 2.7548609167808973
Validation loss: 2.5362259420874196

Epoch: 6| Step: 11
Training loss: 1.3749514918007082
Validation loss: 2.496140361702896

Epoch: 6| Step: 12
Training loss: 1.559857995832661
Validation loss: 2.499439685337751

Epoch: 6| Step: 13
Training loss: 1.4664085067056922
Validation loss: 2.539702224347675

Epoch: 90| Step: 0
Training loss: 1.561079829450511
Validation loss: 2.4935712291341865

Epoch: 6| Step: 1
Training loss: 1.8706656904093415
Validation loss: 2.5154763250862646

Epoch: 6| Step: 2
Training loss: 1.264799343222605
Validation loss: 2.5130627617113612

Epoch: 6| Step: 3
Training loss: 1.725270335810715
Validation loss: 2.502335300087892

Epoch: 6| Step: 4
Training loss: 2.0001614028653307
Validation loss: 2.523587296235377

Epoch: 6| Step: 5
Training loss: 1.7038536263043857
Validation loss: 2.5445354770449216

Epoch: 6| Step: 6
Training loss: 2.5373144147685145
Validation loss: 2.548172961299774

Epoch: 6| Step: 7
Training loss: 1.3785604416136226
Validation loss: 2.582949861142013

Epoch: 6| Step: 8
Training loss: 1.3602194081760877
Validation loss: 2.5693891851537307

Epoch: 6| Step: 9
Training loss: 2.0484210283561386
Validation loss: 2.645008684539479

Epoch: 6| Step: 10
Training loss: 1.9943342423107266
Validation loss: 2.6188239072750905

Epoch: 6| Step: 11
Training loss: 1.7845571501802686
Validation loss: 2.628429624704208

Epoch: 6| Step: 12
Training loss: 1.6057063388676298
Validation loss: 2.523973122707043

Epoch: 6| Step: 13
Training loss: 1.8679183742570131
Validation loss: 2.530711709387758

Epoch: 91| Step: 0
Training loss: 2.4024352513697274
Validation loss: 2.5159319103985784

Epoch: 6| Step: 1
Training loss: 1.4213094739456074
Validation loss: 2.5701050215660586

Epoch: 6| Step: 2
Training loss: 1.9890574081367711
Validation loss: 2.5328441278238873

Epoch: 6| Step: 3
Training loss: 1.7237543943928673
Validation loss: 2.518518351716408

Epoch: 6| Step: 4
Training loss: 2.140168969801057
Validation loss: 2.5661821040062684

Epoch: 6| Step: 5
Training loss: 1.5591619311610283
Validation loss: 2.514128972690708

Epoch: 6| Step: 6
Training loss: 2.1028223055121824
Validation loss: 2.5217225237843603

Epoch: 6| Step: 7
Training loss: 1.771058962042382
Validation loss: 2.5779664732620127

Epoch: 6| Step: 8
Training loss: 1.484701421885575
Validation loss: 2.5434869178738997

Epoch: 6| Step: 9
Training loss: 0.9442781195944209
Validation loss: 2.548098467259158

Epoch: 6| Step: 10
Training loss: 1.8394564405189846
Validation loss: 2.583855058428572

Epoch: 6| Step: 11
Training loss: 1.8206426623948149
Validation loss: 2.5447146062208725

Epoch: 6| Step: 12
Training loss: 1.2991734095935328
Validation loss: 2.62147280457873

Epoch: 6| Step: 13
Training loss: 1.9859055151115728
Validation loss: 2.606424578606492

Epoch: 92| Step: 0
Training loss: 2.1432790522526917
Validation loss: 2.573913054387685

Epoch: 6| Step: 1
Training loss: 1.6969334460567596
Validation loss: 2.542410762449875

Epoch: 6| Step: 2
Training loss: 1.484578811306008
Validation loss: 2.5074699223325463

Epoch: 6| Step: 3
Training loss: 1.4193265944793203
Validation loss: 2.4953721127110473

Epoch: 6| Step: 4
Training loss: 1.0879148415518891
Validation loss: 2.537249280573077

Epoch: 6| Step: 5
Training loss: 2.3152147802325334
Validation loss: 2.5301867712763437

Epoch: 6| Step: 6
Training loss: 1.861795917021077
Validation loss: 2.530146676248433

Epoch: 6| Step: 7
Training loss: 1.5576347900161331
Validation loss: 2.5292322098997233

Epoch: 6| Step: 8
Training loss: 2.346650528617479
Validation loss: 2.5047005491021896

Epoch: 6| Step: 9
Training loss: 1.8041597065193002
Validation loss: 2.5724773932904204

Epoch: 6| Step: 10
Training loss: 1.6440453615729171
Validation loss: 2.559392114379449

Epoch: 6| Step: 11
Training loss: 1.370341689735185
Validation loss: 2.6664392602834828

Epoch: 6| Step: 12
Training loss: 1.160002264727651
Validation loss: 2.7120103572846483

Epoch: 6| Step: 13
Training loss: 2.392298791889105
Validation loss: 2.769239775291155

Epoch: 93| Step: 0
Training loss: 2.5781141801086878
Validation loss: 2.7588550156893343

Epoch: 6| Step: 1
Training loss: 1.6900056674117365
Validation loss: 2.6955251858595477

Epoch: 6| Step: 2
Training loss: 1.6347431650749538
Validation loss: 2.6027193905191357

Epoch: 6| Step: 3
Training loss: 1.7895713648841802
Validation loss: 2.5534448352509633

Epoch: 6| Step: 4
Training loss: 1.9666033955541908
Validation loss: 2.505624135195579

Epoch: 6| Step: 5
Training loss: 1.660777184544848
Validation loss: 2.5495543476952207

Epoch: 6| Step: 6
Training loss: 1.8635609414852508
Validation loss: 2.4821686774384677

Epoch: 6| Step: 7
Training loss: 1.78679409894035
Validation loss: 2.5127692431018356

Epoch: 6| Step: 8
Training loss: 1.6197199504059088
Validation loss: 2.4967273829258154

Epoch: 6| Step: 9
Training loss: 1.978890536939042
Validation loss: 2.471850994779634

Epoch: 6| Step: 10
Training loss: 1.5287547898548912
Validation loss: 2.4835680084798457

Epoch: 6| Step: 11
Training loss: 1.6723603586881397
Validation loss: 2.5719250584146054

Epoch: 6| Step: 12
Training loss: 2.115763054855333
Validation loss: 2.605101247297709

Epoch: 6| Step: 13
Training loss: 1.6972544574260406
Validation loss: 2.655342320957181

Epoch: 94| Step: 0
Training loss: 1.9813258857514344
Validation loss: 2.725741243601847

Epoch: 6| Step: 1
Training loss: 1.9984849913727618
Validation loss: 2.6765004029264476

Epoch: 6| Step: 2
Training loss: 1.6391408837906711
Validation loss: 2.6648556301478776

Epoch: 6| Step: 3
Training loss: 1.4302309598010432
Validation loss: 2.6711968645170154

Epoch: 6| Step: 4
Training loss: 1.78234147210894
Validation loss: 2.627048071902683

Epoch: 6| Step: 5
Training loss: 1.4396427604160722
Validation loss: 2.4879746979339665

Epoch: 6| Step: 6
Training loss: 1.8350661137491597
Validation loss: 2.5770804321675684

Epoch: 6| Step: 7
Training loss: 1.4298107323405298
Validation loss: 2.500326612118274

Epoch: 6| Step: 8
Training loss: 1.8389283837068893
Validation loss: 2.515882743442069

Epoch: 6| Step: 9
Training loss: 2.173277038750054
Validation loss: 2.5343016843151287

Epoch: 6| Step: 10
Training loss: 1.8906958700721568
Validation loss: 2.474094159597201

Epoch: 6| Step: 11
Training loss: 1.644470648657018
Validation loss: 2.492504047950409

Epoch: 6| Step: 12
Training loss: 1.3493704687893204
Validation loss: 2.5212171961135432

Epoch: 6| Step: 13
Training loss: 1.8220990627170215
Validation loss: 2.534018411569967

Epoch: 95| Step: 0
Training loss: 1.6395835840918977
Validation loss: 2.492133320346042

Epoch: 6| Step: 1
Training loss: 1.3697287348032825
Validation loss: 2.527514758999248

Epoch: 6| Step: 2
Training loss: 1.6774190799621802
Validation loss: 2.5340995604404593

Epoch: 6| Step: 3
Training loss: 2.053232584417881
Validation loss: 2.6245945057194877

Epoch: 6| Step: 4
Training loss: 2.4233416638587513
Validation loss: 2.6924481195465186

Epoch: 6| Step: 5
Training loss: 1.7896199919469418
Validation loss: 2.678479306892395

Epoch: 6| Step: 6
Training loss: 1.6612239500921058
Validation loss: 2.6715205740136714

Epoch: 6| Step: 7
Training loss: 1.748288066570137
Validation loss: 2.592968727319466

Epoch: 6| Step: 8
Training loss: 1.0779489566983542
Validation loss: 2.5307788567389324

Epoch: 6| Step: 9
Training loss: 1.6940704577452066
Validation loss: 2.5525064364186187

Epoch: 6| Step: 10
Training loss: 1.583697611748456
Validation loss: 2.5247438118269505

Epoch: 6| Step: 11
Training loss: 1.7194934970813722
Validation loss: 2.5133746805592887

Epoch: 6| Step: 12
Training loss: 1.6077018855444571
Validation loss: 2.5617983175246524

Epoch: 6| Step: 13
Training loss: 1.7332079285715636
Validation loss: 2.5920198330758177

Epoch: 96| Step: 0
Training loss: 1.6061429652312906
Validation loss: 2.5681080278182526

Epoch: 6| Step: 1
Training loss: 1.7827808427465672
Validation loss: 2.5513273300121533

Epoch: 6| Step: 2
Training loss: 1.667224012009029
Validation loss: 2.587283641719703

Epoch: 6| Step: 3
Training loss: 1.3099277358470884
Validation loss: 2.6219958265772316

Epoch: 6| Step: 4
Training loss: 1.777451731996235
Validation loss: 2.641857995486248

Epoch: 6| Step: 5
Training loss: 1.7807232261871777
Validation loss: 2.625757736256644

Epoch: 6| Step: 6
Training loss: 1.5407727029499716
Validation loss: 2.581383281896749

Epoch: 6| Step: 7
Training loss: 1.8982442121654883
Validation loss: 2.608169825571137

Epoch: 6| Step: 8
Training loss: 1.150643856758126
Validation loss: 2.5409080175690226

Epoch: 6| Step: 9
Training loss: 1.2207769020673993
Validation loss: 2.5750061127673436

Epoch: 6| Step: 10
Training loss: 2.192540057348137
Validation loss: 2.507822054550651

Epoch: 6| Step: 11
Training loss: 1.1693927670163304
Validation loss: 2.5880336198947034

Epoch: 6| Step: 12
Training loss: 2.145661158891789
Validation loss: 2.5324458056642203

Epoch: 6| Step: 13
Training loss: 1.7258532694290314
Validation loss: 2.5485660345149035

Epoch: 97| Step: 0
Training loss: 1.566086353542198
Validation loss: 2.5858172785385247

Epoch: 6| Step: 1
Training loss: 1.276207374660489
Validation loss: 2.5952170026596146

Epoch: 6| Step: 2
Training loss: 2.3354929625418004
Validation loss: 2.6500536283428797

Epoch: 6| Step: 3
Training loss: 1.181856750395798
Validation loss: 2.685403656810876

Epoch: 6| Step: 4
Training loss: 1.5675810786546667
Validation loss: 2.7020180554373776

Epoch: 6| Step: 5
Training loss: 1.6281133318169945
Validation loss: 2.752107953854978

Epoch: 6| Step: 6
Training loss: 1.762643575569508
Validation loss: 2.6961266287832144

Epoch: 6| Step: 7
Training loss: 1.6974554625161604
Validation loss: 2.661872754364368

Epoch: 6| Step: 8
Training loss: 1.5090391871456037
Validation loss: 2.596061863542215

Epoch: 6| Step: 9
Training loss: 2.0188542011401975
Validation loss: 2.646302029004047

Epoch: 6| Step: 10
Training loss: 1.561472745815723
Validation loss: 2.596900175961818

Epoch: 6| Step: 11
Training loss: 1.8629856474933222
Validation loss: 2.6012447953618936

Epoch: 6| Step: 12
Training loss: 1.5646807901411142
Validation loss: 2.6321142612138027

Epoch: 6| Step: 13
Training loss: 1.4591200023765862
Validation loss: 2.62030611744488

Epoch: 98| Step: 0
Training loss: 1.9189368638490858
Validation loss: 2.622186901832124

Epoch: 6| Step: 1
Training loss: 1.6239450404822313
Validation loss: 2.5919557056566886

Epoch: 6| Step: 2
Training loss: 1.8251801597819381
Validation loss: 2.6070892769545257

Epoch: 6| Step: 3
Training loss: 1.3416139791738475
Validation loss: 2.712077125717641

Epoch: 6| Step: 4
Training loss: 1.4794130612607344
Validation loss: 2.7169731150618985

Epoch: 6| Step: 5
Training loss: 1.3975086217351564
Validation loss: 2.7539714688273205

Epoch: 6| Step: 6
Training loss: 1.456894528107949
Validation loss: 2.6654905368033726

Epoch: 6| Step: 7
Training loss: 1.4767853906723039
Validation loss: 2.637343600609288

Epoch: 6| Step: 8
Training loss: 1.6879908942659483
Validation loss: 2.656299859869247

Epoch: 6| Step: 9
Training loss: 1.6194986975895167
Validation loss: 2.588660152392067

Epoch: 6| Step: 10
Training loss: 2.429627052855396
Validation loss: 2.561560264649408

Epoch: 6| Step: 11
Training loss: 1.452556211660901
Validation loss: 2.571403789653143

Epoch: 6| Step: 12
Training loss: 1.7961511231924727
Validation loss: 2.590738378849952

Epoch: 6| Step: 13
Training loss: 1.5041689952856974
Validation loss: 2.576927831877516

Epoch: 99| Step: 0
Training loss: 1.461412974619171
Validation loss: 2.5316737491398937

Epoch: 6| Step: 1
Training loss: 1.7456527938296391
Validation loss: 2.592468013842

Epoch: 6| Step: 2
Training loss: 1.4643564456378035
Validation loss: 2.607105997027808

Epoch: 6| Step: 3
Training loss: 1.4747219825847104
Validation loss: 2.6809969743376953

Epoch: 6| Step: 4
Training loss: 1.3440848088669177
Validation loss: 2.6458106052493813

Epoch: 6| Step: 5
Training loss: 1.6950096879530332
Validation loss: 2.7404472647218254

Epoch: 6| Step: 6
Training loss: 2.2369048195423726
Validation loss: 2.721591845389332

Epoch: 6| Step: 7
Training loss: 1.9009914722522254
Validation loss: 2.729474863214624

Epoch: 6| Step: 8
Training loss: 1.6641102098959466
Validation loss: 2.6578517647036346

Epoch: 6| Step: 9
Training loss: 1.4927825540146684
Validation loss: 2.616326975387966

Epoch: 6| Step: 10
Training loss: 1.2101411231162487
Validation loss: 2.6693280965974084

Epoch: 6| Step: 11
Training loss: 1.2381514231497066
Validation loss: 2.656724326474447

Epoch: 6| Step: 12
Training loss: 1.6478635683760592
Validation loss: 2.6514741785838805

Epoch: 6| Step: 13
Training loss: 1.369493033729487
Validation loss: 2.610280563163383

Epoch: 100| Step: 0
Training loss: 1.1351869624919528
Validation loss: 2.5857355628634817

Epoch: 6| Step: 1
Training loss: 1.53199625320574
Validation loss: 2.570942964694471

Epoch: 6| Step: 2
Training loss: 2.285556438649663
Validation loss: 2.5661112762430562

Epoch: 6| Step: 3
Training loss: 1.2709389731269893
Validation loss: 2.6426953357642042

Epoch: 6| Step: 4
Training loss: 1.3004009618832455
Validation loss: 2.60996807614774

Epoch: 6| Step: 5
Training loss: 1.7296436142286136
Validation loss: 2.620675468137788

Epoch: 6| Step: 6
Training loss: 1.7248228120332119
Validation loss: 2.6823588588162646

Epoch: 6| Step: 7
Training loss: 1.1059087949090403
Validation loss: 2.708977378170601

Epoch: 6| Step: 8
Training loss: 1.5928499260738307
Validation loss: 2.680526053530387

Epoch: 6| Step: 9
Training loss: 1.2403008871190808
Validation loss: 2.7478461934486695

Epoch: 6| Step: 10
Training loss: 1.7620308001247817
Validation loss: 2.6876283215782166

Epoch: 6| Step: 11
Training loss: 1.434414496116981
Validation loss: 2.673355094134583

Epoch: 6| Step: 12
Training loss: 1.5421733109614724
Validation loss: 2.7050456021002933

Epoch: 6| Step: 13
Training loss: 1.5454034452609027
Validation loss: 2.635732629303328

Epoch: 101| Step: 0
Training loss: 1.558792751677363
Validation loss: 2.6192922299377703

Epoch: 6| Step: 1
Training loss: 2.029969031562798
Validation loss: 2.63521945099862

Epoch: 6| Step: 2
Training loss: 1.393786961018352
Validation loss: 2.5508494268227677

Epoch: 6| Step: 3
Training loss: 1.926205478081901
Validation loss: 2.66116707409376

Epoch: 6| Step: 4
Training loss: 1.2478310364058853
Validation loss: 2.6217317671634253

Epoch: 6| Step: 5
Training loss: 1.4179130101873734
Validation loss: 2.610475182594123

Epoch: 6| Step: 6
Training loss: 1.5469435089045176
Validation loss: 2.660830180374063

Epoch: 6| Step: 7
Training loss: 1.1988811701191338
Validation loss: 2.68897725690003

Epoch: 6| Step: 8
Training loss: 0.8312691076850381
Validation loss: 2.8018917505128202

Epoch: 6| Step: 9
Training loss: 1.5353393445501173
Validation loss: 2.761145381589018

Epoch: 6| Step: 10
Training loss: 2.085579030528003
Validation loss: 2.8579501995368704

Epoch: 6| Step: 11
Training loss: 1.2820514405384944
Validation loss: 2.7683762481076206

Epoch: 6| Step: 12
Training loss: 1.2877706817228112
Validation loss: 2.8151967294857014

Epoch: 6| Step: 13
Training loss: 2.2032465258689644
Validation loss: 2.782618967959242

Epoch: 102| Step: 0
Training loss: 1.1265823574141414
Validation loss: 2.724432228737571

Epoch: 6| Step: 1
Training loss: 1.5366953349111354
Validation loss: 2.6659673479154935

Epoch: 6| Step: 2
Training loss: 1.0575604903503733
Validation loss: 2.666323227423018

Epoch: 6| Step: 3
Training loss: 1.5140113499113943
Validation loss: 2.668804553484596

Epoch: 6| Step: 4
Training loss: 1.2773628816717584
Validation loss: 2.6207580351411144

Epoch: 6| Step: 5
Training loss: 1.562721618194453
Validation loss: 2.712694813285198

Epoch: 6| Step: 6
Training loss: 1.5143533464710737
Validation loss: 2.665216801802692

Epoch: 6| Step: 7
Training loss: 1.5950729264954073
Validation loss: 2.606381768692758

Epoch: 6| Step: 8
Training loss: 1.527120744664144
Validation loss: 2.7146394282234803

Epoch: 6| Step: 9
Training loss: 2.4353763425788375
Validation loss: 2.6040803716984655

Epoch: 6| Step: 10
Training loss: 1.0059826821605558
Validation loss: 2.6838928603828998

Epoch: 6| Step: 11
Training loss: 1.1264583883443662
Validation loss: 2.6570428375616597

Epoch: 6| Step: 12
Training loss: 1.6457646834465822
Validation loss: 2.688786206263972

Epoch: 6| Step: 13
Training loss: 1.2188148481282726
Validation loss: 2.6212096930081827

Epoch: 103| Step: 0
Training loss: 1.0295111706365274
Validation loss: 2.670435288911376

Epoch: 6| Step: 1
Training loss: 1.534522083326173
Validation loss: 2.6464816423052464

Epoch: 6| Step: 2
Training loss: 1.478352990017977
Validation loss: 2.600395238619255

Epoch: 6| Step: 3
Training loss: 1.2499103513995091
Validation loss: 2.6905642347160605

Epoch: 6| Step: 4
Training loss: 1.1191665087198206
Validation loss: 2.74058638124649

Epoch: 6| Step: 5
Training loss: 1.668378935859778
Validation loss: 2.7152341127475537

Epoch: 6| Step: 6
Training loss: 1.2617773745118015
Validation loss: 2.75386822180498

Epoch: 6| Step: 7
Training loss: 2.2079979863848695
Validation loss: 2.792690364595342

Epoch: 6| Step: 8
Training loss: 1.1768059811685816
Validation loss: 2.7894173760556864

Epoch: 6| Step: 9
Training loss: 1.7546526503732625
Validation loss: 2.809307207612795

Epoch: 6| Step: 10
Training loss: 1.7107952180689905
Validation loss: 2.8398680967942758

Epoch: 6| Step: 11
Training loss: 1.244143978575494
Validation loss: 2.7929361194758537

Epoch: 6| Step: 12
Training loss: 1.7004209277806839
Validation loss: 2.773650026013925

Epoch: 6| Step: 13
Training loss: 1.3551270331768726
Validation loss: 2.6744599061524372

Epoch: 104| Step: 0
Training loss: 1.5306943547029666
Validation loss: 2.6022068176615316

Epoch: 6| Step: 1
Training loss: 1.3987016907804806
Validation loss: 2.6288550165482896

Epoch: 6| Step: 2
Training loss: 1.746317189916672
Validation loss: 2.631403499786291

Epoch: 6| Step: 3
Training loss: 1.3352648731596817
Validation loss: 2.63792535747791

Epoch: 6| Step: 4
Training loss: 1.8652325215754861
Validation loss: 2.6407083501960003

Epoch: 6| Step: 5
Training loss: 1.632306618328871
Validation loss: 2.680093539868765

Epoch: 6| Step: 6
Training loss: 1.8210494223837084
Validation loss: 2.7662740401992982

Epoch: 6| Step: 7
Training loss: 2.0421255205901776
Validation loss: 2.806656297866926

Epoch: 6| Step: 8
Training loss: 0.9223391770565014
Validation loss: 2.912747431546926

Epoch: 6| Step: 9
Training loss: 1.1618189344581427
Validation loss: 2.9041404587937323

Epoch: 6| Step: 10
Training loss: 1.248749823049966
Validation loss: 2.8805744336264874

Epoch: 6| Step: 11
Training loss: 1.8941067249476582
Validation loss: 2.835034495507698

Epoch: 6| Step: 12
Training loss: 1.1864458725933307
Validation loss: 2.6711909736582093

Epoch: 6| Step: 13
Training loss: 1.3910142161001446
Validation loss: 2.6161018055491803

Epoch: 105| Step: 0
Training loss: 1.3854873132499976
Validation loss: 2.6210108676167447

Epoch: 6| Step: 1
Training loss: 1.300538232228901
Validation loss: 2.6838701560217015

Epoch: 6| Step: 2
Training loss: 1.292391922082571
Validation loss: 2.6864617434348483

Epoch: 6| Step: 3
Training loss: 2.3470716208674682
Validation loss: 2.6603192742986383

Epoch: 6| Step: 4
Training loss: 1.344259919402217
Validation loss: 2.653919798560301

Epoch: 6| Step: 5
Training loss: 1.3642820603243986
Validation loss: 2.5880803260610925

Epoch: 6| Step: 6
Training loss: 0.9788880391417313
Validation loss: 2.6768523956515358

Epoch: 6| Step: 7
Training loss: 1.4208246061144676
Validation loss: 2.616526293380873

Epoch: 6| Step: 8
Training loss: 1.7383730746243682
Validation loss: 2.7441454107892174

Epoch: 6| Step: 9
Training loss: 1.8748718217906342
Validation loss: 2.6823669324271484

Epoch: 6| Step: 10
Training loss: 1.1980408092801695
Validation loss: 2.7479559063851244

Epoch: 6| Step: 11
Training loss: 0.9746775631949982
Validation loss: 2.842596148360858

Epoch: 6| Step: 12
Training loss: 1.5629605949545289
Validation loss: 2.8428270847505126

Epoch: 6| Step: 13
Training loss: 1.4174088983341766
Validation loss: 2.871098524855192

Epoch: 106| Step: 0
Training loss: 1.180158558957783
Validation loss: 2.8564214547837365

Epoch: 6| Step: 1
Training loss: 1.488572700378088
Validation loss: 2.8299954097112985

Epoch: 6| Step: 2
Training loss: 1.316577209781639
Validation loss: 2.8183536366461346

Epoch: 6| Step: 3
Training loss: 0.8766916815617982
Validation loss: 2.7450530466398235

Epoch: 6| Step: 4
Training loss: 1.6236679780020626
Validation loss: 2.750853203862844

Epoch: 6| Step: 5
Training loss: 1.4172741578513255
Validation loss: 2.740004450314103

Epoch: 6| Step: 6
Training loss: 2.1551233195270716
Validation loss: 2.764415253678121

Epoch: 6| Step: 7
Training loss: 1.5734666111364053
Validation loss: 2.6628657661371844

Epoch: 6| Step: 8
Training loss: 1.1775742353943135
Validation loss: 2.6705152535440075

Epoch: 6| Step: 9
Training loss: 1.5685083453923443
Validation loss: 2.600669233989092

Epoch: 6| Step: 10
Training loss: 1.6529821150239683
Validation loss: 2.692868983618658

Epoch: 6| Step: 11
Training loss: 1.2878899992830506
Validation loss: 2.646228975967215

Epoch: 6| Step: 12
Training loss: 1.492435215066317
Validation loss: 2.691477929181829

Epoch: 6| Step: 13
Training loss: 1.2233155639217157
Validation loss: 2.7046368143704824

Epoch: 107| Step: 0
Training loss: 1.687973944901334
Validation loss: 2.724758830466304

Epoch: 6| Step: 1
Training loss: 1.3153120524957846
Validation loss: 2.756923110670113

Epoch: 6| Step: 2
Training loss: 1.3318437461103854
Validation loss: 2.7313666370432514

Epoch: 6| Step: 3
Training loss: 1.173328058292351
Validation loss: 2.7968342243539674

Epoch: 6| Step: 4
Training loss: 0.8525941531634761
Validation loss: 2.7846057663494874

Epoch: 6| Step: 5
Training loss: 1.0144721897876448
Validation loss: 2.7526179192715863

Epoch: 6| Step: 6
Training loss: 1.3457495428088448
Validation loss: 2.701748639047077

Epoch: 6| Step: 7
Training loss: 1.2715916273409607
Validation loss: 2.7272342848958364

Epoch: 6| Step: 8
Training loss: 1.2369068111205315
Validation loss: 2.7518237164521695

Epoch: 6| Step: 9
Training loss: 1.5570651328711107
Validation loss: 2.6153811925654216

Epoch: 6| Step: 10
Training loss: 1.5496609963121648
Validation loss: 2.6925610711702164

Epoch: 6| Step: 11
Training loss: 1.5941113828946265
Validation loss: 2.7173782922184424

Epoch: 6| Step: 12
Training loss: 2.2281139657067017
Validation loss: 2.6546402784626575

Epoch: 6| Step: 13
Training loss: 0.9819587844660048
Validation loss: 2.644958401492895

Epoch: 108| Step: 0
Training loss: 1.6093354451772197
Validation loss: 2.7045364957718867

Epoch: 6| Step: 1
Training loss: 1.3510680865447438
Validation loss: 2.772270107386603

Epoch: 6| Step: 2
Training loss: 1.1891545765098883
Validation loss: 2.7716855528786914

Epoch: 6| Step: 3
Training loss: 1.5126819154405944
Validation loss: 2.7433093204428443

Epoch: 6| Step: 4
Training loss: 1.4935215284483585
Validation loss: 2.7941856738668105

Epoch: 6| Step: 5
Training loss: 1.056441931808177
Validation loss: 2.755011514846175

Epoch: 6| Step: 6
Training loss: 1.4044964771844475
Validation loss: 2.7007489796237865

Epoch: 6| Step: 7
Training loss: 1.4968317268503695
Validation loss: 2.6835453005012084

Epoch: 6| Step: 8
Training loss: 2.2222444122584086
Validation loss: 2.7099932254551744

Epoch: 6| Step: 9
Training loss: 0.80257980454933
Validation loss: 2.6184067803936983

Epoch: 6| Step: 10
Training loss: 1.1941012060605443
Validation loss: 2.7316826344601925

Epoch: 6| Step: 11
Training loss: 1.5869368237550359
Validation loss: 2.735935950011013

Epoch: 6| Step: 12
Training loss: 1.1089699771453039
Validation loss: 2.755799463865855

Epoch: 6| Step: 13
Training loss: 1.086175137871423
Validation loss: 2.7595509065150052

Epoch: 109| Step: 0
Training loss: 1.3866878022514966
Validation loss: 2.709608560282698

Epoch: 6| Step: 1
Training loss: 1.1309509240286868
Validation loss: 2.748891896183086

Epoch: 6| Step: 2
Training loss: 1.2346190199305977
Validation loss: 2.687633806786239

Epoch: 6| Step: 3
Training loss: 1.243951133298739
Validation loss: 2.6956691192735924

Epoch: 6| Step: 4
Training loss: 1.4349711191281633
Validation loss: 2.626971654814798

Epoch: 6| Step: 5
Training loss: 1.034611396629146
Validation loss: 2.619006535385385

Epoch: 6| Step: 6
Training loss: 1.6265250898854076
Validation loss: 2.648270173164904

Epoch: 6| Step: 7
Training loss: 1.4776188538280466
Validation loss: 2.7032921947009787

Epoch: 6| Step: 8
Training loss: 1.2426506474619379
Validation loss: 2.7138308604672186

Epoch: 6| Step: 9
Training loss: 1.423746240090085
Validation loss: 2.7627422157532098

Epoch: 6| Step: 10
Training loss: 1.9690888128443198
Validation loss: 2.7727512710582594

Epoch: 6| Step: 11
Training loss: 1.3279135142970104
Validation loss: 2.8498110613741745

Epoch: 6| Step: 12
Training loss: 1.2560785793427995
Validation loss: 2.854199796795285

Epoch: 6| Step: 13
Training loss: 1.4006533835112729
Validation loss: 2.86132656960993

Epoch: 110| Step: 0
Training loss: 2.281417631496206
Validation loss: 2.794038922349378

Epoch: 6| Step: 1
Training loss: 1.3431334744590362
Validation loss: 2.8021884789764178

Epoch: 6| Step: 2
Training loss: 1.2765460308604777
Validation loss: 2.720164022642557

Epoch: 6| Step: 3
Training loss: 1.1009841374598048
Validation loss: 2.764640517938181

Epoch: 6| Step: 4
Training loss: 1.3735937383359045
Validation loss: 2.7277826532094585

Epoch: 6| Step: 5
Training loss: 1.7055362815610071
Validation loss: 2.7144941731524668

Epoch: 6| Step: 6
Training loss: 1.3882240399544383
Validation loss: 2.7329300904752483

Epoch: 6| Step: 7
Training loss: 1.23248996939456
Validation loss: 2.661508090654596

Epoch: 6| Step: 8
Training loss: 1.2742047952885376
Validation loss: 2.751698287452545

Epoch: 6| Step: 9
Training loss: 1.5034970209760112
Validation loss: 2.7639321931378404

Epoch: 6| Step: 10
Training loss: 1.1359233892054974
Validation loss: 2.8438120545264467

Epoch: 6| Step: 11
Training loss: 1.4139642417870075
Validation loss: 2.9003953927254584

Epoch: 6| Step: 12
Training loss: 1.1047599326293862
Validation loss: 2.8288501069879226

Epoch: 6| Step: 13
Training loss: 1.1462717200231705
Validation loss: 2.7653475404918244

Epoch: 111| Step: 0
Training loss: 1.1492083810303488
Validation loss: 2.7652645846076163

Epoch: 6| Step: 1
Training loss: 1.8455995237954215
Validation loss: 2.7718843364594177

Epoch: 6| Step: 2
Training loss: 1.0710230786626758
Validation loss: 2.66454554678396

Epoch: 6| Step: 3
Training loss: 1.0150146998200715
Validation loss: 2.719894153812183

Epoch: 6| Step: 4
Training loss: 1.2894449302507704
Validation loss: 2.7167155374527105

Epoch: 6| Step: 5
Training loss: 1.3481208774324995
Validation loss: 2.6978770710949656

Epoch: 6| Step: 6
Training loss: 1.4592129733793031
Validation loss: 2.7318482122865735

Epoch: 6| Step: 7
Training loss: 1.2041656155345162
Validation loss: 2.700033268311487

Epoch: 6| Step: 8
Training loss: 1.4269848067898985
Validation loss: 2.7428049839567716

Epoch: 6| Step: 9
Training loss: 0.9401720115858181
Validation loss: 2.710914032731003

Epoch: 6| Step: 10
Training loss: 1.506853421221681
Validation loss: 2.8582099667350334

Epoch: 6| Step: 11
Training loss: 1.986721963763591
Validation loss: 2.9056202879657094

Epoch: 6| Step: 12
Training loss: 1.4568096738985348
Validation loss: 2.9757709401844163

Epoch: 6| Step: 13
Training loss: 1.422024226479915
Validation loss: 3.0056416922460274

Epoch: 112| Step: 0
Training loss: 1.3354680535977548
Validation loss: 2.9885306858850695

Epoch: 6| Step: 1
Training loss: 1.3750532313359976
Validation loss: 2.928813264743929

Epoch: 6| Step: 2
Training loss: 1.2048109552874475
Validation loss: 2.7879192812448452

Epoch: 6| Step: 3
Training loss: 0.8530680794643466
Validation loss: 2.759038593181317

Epoch: 6| Step: 4
Training loss: 1.1128688115197776
Validation loss: 2.761847622970156

Epoch: 6| Step: 5
Training loss: 1.2388294823453811
Validation loss: 2.70447868012657

Epoch: 6| Step: 6
Training loss: 1.4418000301056815
Validation loss: 2.6984937828745816

Epoch: 6| Step: 7
Training loss: 1.2492348236328614
Validation loss: 2.7067349534589393

Epoch: 6| Step: 8
Training loss: 1.3855449597991019
Validation loss: 2.73213934193209

Epoch: 6| Step: 9
Training loss: 0.8388039828238208
Validation loss: 2.7375324148642433

Epoch: 6| Step: 10
Training loss: 1.5171023375380701
Validation loss: 2.731080313735584

Epoch: 6| Step: 11
Training loss: 1.3443751544322728
Validation loss: 2.809997816005777

Epoch: 6| Step: 12
Training loss: 2.121691315780698
Validation loss: 2.7908205391731165

Epoch: 6| Step: 13
Training loss: 1.5502256844404865
Validation loss: 2.8969172546311794

Epoch: 113| Step: 0
Training loss: 2.0463263089277484
Validation loss: 2.8269004770137762

Epoch: 6| Step: 1
Training loss: 1.5859603504357531
Validation loss: 2.7802937467472213

Epoch: 6| Step: 2
Training loss: 1.2403899808573133
Validation loss: 2.7442459104348274

Epoch: 6| Step: 3
Training loss: 0.915847795480444
Validation loss: 2.7169179407199504

Epoch: 6| Step: 4
Training loss: 1.1809690474379375
Validation loss: 2.6884011229048217

Epoch: 6| Step: 5
Training loss: 0.7914287477328816
Validation loss: 2.7684303107740473

Epoch: 6| Step: 6
Training loss: 1.4315292086058016
Validation loss: 2.7851571345673416

Epoch: 6| Step: 7
Training loss: 1.3524866197245033
Validation loss: 2.684480508574526

Epoch: 6| Step: 8
Training loss: 1.2539008309790904
Validation loss: 2.6937810997816154

Epoch: 6| Step: 9
Training loss: 1.02741864877803
Validation loss: 2.7385613356723457

Epoch: 6| Step: 10
Training loss: 1.4120318337410052
Validation loss: 2.758483358454099

Epoch: 6| Step: 11
Training loss: 0.8955599271529814
Validation loss: 2.7964091703325034

Epoch: 6| Step: 12
Training loss: 1.7126262117084639
Validation loss: 2.8697783140413025

Epoch: 6| Step: 13
Training loss: 0.8399934147394996
Validation loss: 2.8124379186489565

Epoch: 114| Step: 0
Training loss: 1.1482227150540478
Validation loss: 2.843867247124195

Epoch: 6| Step: 1
Training loss: 1.101742668838987
Validation loss: 2.7634389251195706

Epoch: 6| Step: 2
Training loss: 1.3189806117324
Validation loss: 2.823122591810513

Epoch: 6| Step: 3
Training loss: 1.1250340138697548
Validation loss: 2.792642783325648

Epoch: 6| Step: 4
Training loss: 1.5268656965449334
Validation loss: 2.6705586274780115

Epoch: 6| Step: 5
Training loss: 2.0175833245032226
Validation loss: 2.739334049172616

Epoch: 6| Step: 6
Training loss: 0.9293629055608708
Validation loss: 2.7757038294979455

Epoch: 6| Step: 7
Training loss: 1.5289218876447832
Validation loss: 2.715006651896553

Epoch: 6| Step: 8
Training loss: 1.1375222004830485
Validation loss: 2.8021376556084827

Epoch: 6| Step: 9
Training loss: 0.9964448197969351
Validation loss: 2.7066502819089955

Epoch: 6| Step: 10
Training loss: 1.219620125053463
Validation loss: 2.7043018462059036

Epoch: 6| Step: 11
Training loss: 1.1041494524111706
Validation loss: 2.716566795042352

Epoch: 6| Step: 12
Training loss: 1.2204724879775937
Validation loss: 2.7789573792708726

Epoch: 6| Step: 13
Training loss: 1.2060320523875427
Validation loss: 2.8061873128072987

Epoch: 115| Step: 0
Training loss: 1.412705333942619
Validation loss: 2.806097655490531

Epoch: 6| Step: 1
Training loss: 1.3157134001474313
Validation loss: 2.8010632715684145

Epoch: 6| Step: 2
Training loss: 1.398517798137644
Validation loss: 2.737481320112762

Epoch: 6| Step: 3
Training loss: 0.9577525631943241
Validation loss: 2.6714532604842187

Epoch: 6| Step: 4
Training loss: 0.7560066257141049
Validation loss: 2.778340335677701

Epoch: 6| Step: 5
Training loss: 1.276170897914021
Validation loss: 2.699174784013823

Epoch: 6| Step: 6
Training loss: 1.1844158276287204
Validation loss: 2.793852083530083

Epoch: 6| Step: 7
Training loss: 1.1824658247382414
Validation loss: 2.801603585810884

Epoch: 6| Step: 8
Training loss: 1.3806952091599467
Validation loss: 2.8443536781400938

Epoch: 6| Step: 9
Training loss: 0.9519932390541936
Validation loss: 2.9041029406378436

Epoch: 6| Step: 10
Training loss: 2.03072150764544
Validation loss: 2.857227470927501

Epoch: 6| Step: 11
Training loss: 1.3201528599402412
Validation loss: 2.9117570472479812

Epoch: 6| Step: 12
Training loss: 1.365018289953528
Validation loss: 2.819175653115373

Epoch: 6| Step: 13
Training loss: 1.077474480789227
Validation loss: 2.812871639987734

Epoch: 116| Step: 0
Training loss: 1.2142227891838369
Validation loss: 2.800197411003993

Epoch: 6| Step: 1
Training loss: 0.8692795546002566
Validation loss: 2.764669810142536

Epoch: 6| Step: 2
Training loss: 1.5750978348636284
Validation loss: 2.7728860871090295

Epoch: 6| Step: 3
Training loss: 1.1852707769169635
Validation loss: 2.81758382995781

Epoch: 6| Step: 4
Training loss: 1.06056913067981
Validation loss: 2.758400397815587

Epoch: 6| Step: 5
Training loss: 1.1826227819560853
Validation loss: 2.775949463496978

Epoch: 6| Step: 6
Training loss: 1.361794740676192
Validation loss: 2.8674280549047664

Epoch: 6| Step: 7
Training loss: 1.183108038118212
Validation loss: 2.848232048857358

Epoch: 6| Step: 8
Training loss: 1.3329643941103158
Validation loss: 2.815953134037479

Epoch: 6| Step: 9
Training loss: 1.407161036070368
Validation loss: 2.9118709419693283

Epoch: 6| Step: 10
Training loss: 0.6305204727152494
Validation loss: 2.9465667994939126

Epoch: 6| Step: 11
Training loss: 0.917665601955821
Validation loss: 2.8773790412400606

Epoch: 6| Step: 12
Training loss: 0.9864549007711874
Validation loss: 2.8056334703996977

Epoch: 6| Step: 13
Training loss: 2.0249570347501766
Validation loss: 2.7994673807058708

Epoch: 117| Step: 0
Training loss: 1.2754982965653132
Validation loss: 2.6514729047274814

Epoch: 6| Step: 1
Training loss: 1.3061691824995192
Validation loss: 2.7993804819618755

Epoch: 6| Step: 2
Training loss: 1.8916821637408099
Validation loss: 2.842668781911637

Epoch: 6| Step: 3
Training loss: 1.0844383595010143
Validation loss: 2.8375897179086316

Epoch: 6| Step: 4
Training loss: 1.3826234332645604
Validation loss: 2.773728118140867

Epoch: 6| Step: 5
Training loss: 1.2006034684720348
Validation loss: 2.7669144621916497

Epoch: 6| Step: 6
Training loss: 1.2243524552626346
Validation loss: 2.781491058418439

Epoch: 6| Step: 7
Training loss: 0.9245804995309576
Validation loss: 2.704600142976832

Epoch: 6| Step: 8
Training loss: 0.655684977207234
Validation loss: 2.7708729093397504

Epoch: 6| Step: 9
Training loss: 1.1657297879895934
Validation loss: 2.744618047812536

Epoch: 6| Step: 10
Training loss: 0.9260678712779573
Validation loss: 2.7504545760859056

Epoch: 6| Step: 11
Training loss: 1.2274367017410739
Validation loss: 2.7615113492980323

Epoch: 6| Step: 12
Training loss: 1.4758751293591668
Validation loss: 2.843586019182718

Epoch: 6| Step: 13
Training loss: 1.336712707113478
Validation loss: 2.7989952816575325

Epoch: 118| Step: 0
Training loss: 1.001898989042196
Validation loss: 2.8610181134941772

Epoch: 6| Step: 1
Training loss: 0.9076443173331221
Validation loss: 2.8413083490079982

Epoch: 6| Step: 2
Training loss: 1.1123493778404148
Validation loss: 2.8077612338501012

Epoch: 6| Step: 3
Training loss: 1.0579983208540227
Validation loss: 2.7763223035048794

Epoch: 6| Step: 4
Training loss: 1.242043636796299
Validation loss: 2.7186023920555

Epoch: 6| Step: 5
Training loss: 1.5121814108511353
Validation loss: 2.7199329711097504

Epoch: 6| Step: 6
Training loss: 0.7859594307905481
Validation loss: 2.786003736449194

Epoch: 6| Step: 7
Training loss: 1.4442271513396874
Validation loss: 2.798998035811371

Epoch: 6| Step: 8
Training loss: 2.1852869010439493
Validation loss: 2.7460975411806303

Epoch: 6| Step: 9
Training loss: 1.088645358219517
Validation loss: 2.7859890955670283

Epoch: 6| Step: 10
Training loss: 0.9849545422826168
Validation loss: 2.7816891127134635

Epoch: 6| Step: 11
Training loss: 1.2539829218825542
Validation loss: 2.7722704513914147

Epoch: 6| Step: 12
Training loss: 0.9376627780742365
Validation loss: 2.812945365964661

Epoch: 6| Step: 13
Training loss: 0.9668817039804753
Validation loss: 2.922631531282604

Epoch: 119| Step: 0
Training loss: 1.0325717547331956
Validation loss: 2.8848641666497814

Epoch: 6| Step: 1
Training loss: 1.6388226008973374
Validation loss: 3.0050123912240556

Epoch: 6| Step: 2
Training loss: 1.1843679684553547
Validation loss: 2.9159578324876634

Epoch: 6| Step: 3
Training loss: 0.8886513508533103
Validation loss: 2.8958782951834716

Epoch: 6| Step: 4
Training loss: 0.8626569328726879
Validation loss: 2.7426127858415086

Epoch: 6| Step: 5
Training loss: 1.8502691073194548
Validation loss: 2.769191590192295

Epoch: 6| Step: 6
Training loss: 1.1800863842136908
Validation loss: 2.7669543216336994

Epoch: 6| Step: 7
Training loss: 1.6535813046177819
Validation loss: 2.7495770418137817

Epoch: 6| Step: 8
Training loss: 1.3929005981136202
Validation loss: 2.714897861444584

Epoch: 6| Step: 9
Training loss: 1.1364408592514759
Validation loss: 2.771064731907343

Epoch: 6| Step: 10
Training loss: 1.2550382169094774
Validation loss: 2.7128612717206995

Epoch: 6| Step: 11
Training loss: 0.8672032397792095
Validation loss: 2.860089544570631

Epoch: 6| Step: 12
Training loss: 0.9768325737387943
Validation loss: 2.8802000233057226

Epoch: 6| Step: 13
Training loss: 1.691568274369207
Validation loss: 2.9720651286986772

Epoch: 120| Step: 0
Training loss: 1.2240895410647326
Validation loss: 2.897031828782164

Epoch: 6| Step: 1
Training loss: 1.488801159496153
Validation loss: 2.811511395803928

Epoch: 6| Step: 2
Training loss: 2.1072485483924646
Validation loss: 2.8019304954699535

Epoch: 6| Step: 3
Training loss: 1.2664568486774719
Validation loss: 2.762006975715294

Epoch: 6| Step: 4
Training loss: 0.7967245670516966
Validation loss: 2.7435282647306214

Epoch: 6| Step: 5
Training loss: 1.1822661958659175
Validation loss: 2.733752901063812

Epoch: 6| Step: 6
Training loss: 0.9737385010438221
Validation loss: 2.7238270938881732

Epoch: 6| Step: 7
Training loss: 1.188925189036479
Validation loss: 2.7749814459607163

Epoch: 6| Step: 8
Training loss: 0.8506227610136076
Validation loss: 2.768240035362594

Epoch: 6| Step: 9
Training loss: 1.084298413125305
Validation loss: 2.753921025374075

Epoch: 6| Step: 10
Training loss: 1.0656503087055977
Validation loss: 2.7994525476417356

Epoch: 6| Step: 11
Training loss: 0.8597288270291585
Validation loss: 2.8368945647996067

Epoch: 6| Step: 12
Training loss: 0.9790764151569651
Validation loss: 2.851110399890665

Epoch: 6| Step: 13
Training loss: 1.1714205560094304
Validation loss: 2.865578694664508

Epoch: 121| Step: 0
Training loss: 0.8825774428452858
Validation loss: 2.7801510643566316

Epoch: 6| Step: 1
Training loss: 0.9569022578288249
Validation loss: 2.916350338448696

Epoch: 6| Step: 2
Training loss: 1.1481866367929263
Validation loss: 2.866785061039977

Epoch: 6| Step: 3
Training loss: 0.983044588131349
Validation loss: 2.762374044800606

Epoch: 6| Step: 4
Training loss: 1.6103582249047292
Validation loss: 2.874999744304701

Epoch: 6| Step: 5
Training loss: 1.2307092825108907
Validation loss: 2.793088697867774

Epoch: 6| Step: 6
Training loss: 1.9012918246733141
Validation loss: 2.7594293424123393

Epoch: 6| Step: 7
Training loss: 0.709981548109853
Validation loss: 2.7518979372294115

Epoch: 6| Step: 8
Training loss: 1.1655732662389555
Validation loss: 2.78917663939051

Epoch: 6| Step: 9
Training loss: 1.077060948378462
Validation loss: 2.7910527413037864

Epoch: 6| Step: 10
Training loss: 0.9480876069814328
Validation loss: 2.7610658757908966

Epoch: 6| Step: 11
Training loss: 1.0902754499460519
Validation loss: 2.8191485693412073

Epoch: 6| Step: 12
Training loss: 0.9658139867932224
Validation loss: 2.8595133193839173

Epoch: 6| Step: 13
Training loss: 1.1086549168084714
Validation loss: 2.865227204989715

Epoch: 122| Step: 0
Training loss: 1.0345962449147785
Validation loss: 2.8736845545363736

Epoch: 6| Step: 1
Training loss: 1.0474612174673024
Validation loss: 2.8399458092457888

Epoch: 6| Step: 2
Training loss: 1.0264709013741198
Validation loss: 2.861808602847946

Epoch: 6| Step: 3
Training loss: 1.1865017359126495
Validation loss: 2.8452281254382594

Epoch: 6| Step: 4
Training loss: 1.0351971888094234
Validation loss: 2.7012103434977317

Epoch: 6| Step: 5
Training loss: 1.3137236295425383
Validation loss: 2.744100542782596

Epoch: 6| Step: 6
Training loss: 1.2586917528845583
Validation loss: 2.8359274395500647

Epoch: 6| Step: 7
Training loss: 0.8695047708679895
Validation loss: 2.8038787525834357

Epoch: 6| Step: 8
Training loss: 2.021671658745892
Validation loss: 2.7993081021347916

Epoch: 6| Step: 9
Training loss: 0.9127334648793228
Validation loss: 2.867747350044657

Epoch: 6| Step: 10
Training loss: 0.8749901907234758
Validation loss: 2.9495953249985076

Epoch: 6| Step: 11
Training loss: 1.5536649015021444
Validation loss: 2.9639792943257848

Epoch: 6| Step: 12
Training loss: 1.0507965654015725
Validation loss: 2.880142588264573

Epoch: 6| Step: 13
Training loss: 0.8444344958303518
Validation loss: 2.9233118831872646

Epoch: 123| Step: 0
Training loss: 0.7027060638204101
Validation loss: 2.8573632589548144

Epoch: 6| Step: 1
Training loss: 1.8236332020999704
Validation loss: 2.8773499159307097

Epoch: 6| Step: 2
Training loss: 0.9110972243183735
Validation loss: 2.886197261138477

Epoch: 6| Step: 3
Training loss: 0.8320453624692611
Validation loss: 2.8138900571266086

Epoch: 6| Step: 4
Training loss: 1.2210568335206846
Validation loss: 2.8399701411732723

Epoch: 6| Step: 5
Training loss: 1.0156119712580782
Validation loss: 2.803315063293046

Epoch: 6| Step: 6
Training loss: 1.2399337764714655
Validation loss: 2.8012615591840837

Epoch: 6| Step: 7
Training loss: 1.2373433216208396
Validation loss: 2.822170853481057

Epoch: 6| Step: 8
Training loss: 1.152953629824298
Validation loss: 2.8714716725299176

Epoch: 6| Step: 9
Training loss: 0.7802050659627368
Validation loss: 2.87379231173315

Epoch: 6| Step: 10
Training loss: 1.1437066658857737
Validation loss: 2.907931999854465

Epoch: 6| Step: 11
Training loss: 1.3221238030652478
Validation loss: 2.849442384501392

Epoch: 6| Step: 12
Training loss: 1.0235826229258733
Validation loss: 2.871508454628481

Epoch: 6| Step: 13
Training loss: 0.8494273725226872
Validation loss: 2.898627330667832

Epoch: 124| Step: 0
Training loss: 0.8071216322149348
Validation loss: 2.8228403106910736

Epoch: 6| Step: 1
Training loss: 0.8872192247609899
Validation loss: 2.72473683850967

Epoch: 6| Step: 2
Training loss: 0.7703547065732215
Validation loss: 2.77820145766753

Epoch: 6| Step: 3
Training loss: 0.9609844227321248
Validation loss: 2.773235446214178

Epoch: 6| Step: 4
Training loss: 1.1814721862289355
Validation loss: 2.7600884344381043

Epoch: 6| Step: 5
Training loss: 1.0084882141733367
Validation loss: 2.773837494996614

Epoch: 6| Step: 6
Training loss: 0.9548362628516506
Validation loss: 2.796444353589096

Epoch: 6| Step: 7
Training loss: 1.2223763434935868
Validation loss: 2.8677423617645044

Epoch: 6| Step: 8
Training loss: 1.2857931582160997
Validation loss: 2.8667542756540176

Epoch: 6| Step: 9
Training loss: 0.9241612098046591
Validation loss: 2.8740037352923262

Epoch: 6| Step: 10
Training loss: 0.8133500860656817
Validation loss: 2.9521349772959216

Epoch: 6| Step: 11
Training loss: 2.043292222389911
Validation loss: 2.943780286326725

Epoch: 6| Step: 12
Training loss: 0.9076961948393606
Validation loss: 2.9647120671437057

Epoch: 6| Step: 13
Training loss: 1.0675009115067817
Validation loss: 2.941464339548548

Epoch: 125| Step: 0
Training loss: 1.1345743618901258
Validation loss: 2.969793029395926

Epoch: 6| Step: 1
Training loss: 1.090886645917032
Validation loss: 2.834862595535667

Epoch: 6| Step: 2
Training loss: 1.0614148376557704
Validation loss: 2.8099924423867315

Epoch: 6| Step: 3
Training loss: 0.957689891640671
Validation loss: 2.8206329586323347

Epoch: 6| Step: 4
Training loss: 1.872011345943074
Validation loss: 2.7855040915746794

Epoch: 6| Step: 5
Training loss: 1.1031501637471344
Validation loss: 2.7445754099325597

Epoch: 6| Step: 6
Training loss: 0.8871705168965928
Validation loss: 2.720929992812633

Epoch: 6| Step: 7
Training loss: 0.48267331694279253
Validation loss: 2.742995922765646

Epoch: 6| Step: 8
Training loss: 1.0692760712051992
Validation loss: 2.7501560369207976

Epoch: 6| Step: 9
Training loss: 0.9347196995715455
Validation loss: 2.7696700032228976

Epoch: 6| Step: 10
Training loss: 1.0269284877673017
Validation loss: 2.7913984530454172

Epoch: 6| Step: 11
Training loss: 1.1577660184479852
Validation loss: 2.727022483813197

Epoch: 6| Step: 12
Training loss: 1.122958662466269
Validation loss: 2.865757057866119

Epoch: 6| Step: 13
Training loss: 1.2495115279405873
Validation loss: 2.8289561165698105

Epoch: 126| Step: 0
Training loss: 0.7670736815014402
Validation loss: 2.8774190207365353

Epoch: 6| Step: 1
Training loss: 0.8239463609162396
Validation loss: 2.8533704904858292

Epoch: 6| Step: 2
Training loss: 0.9065142607979534
Validation loss: 2.9203306934707753

Epoch: 6| Step: 3
Training loss: 0.9995044135873584
Validation loss: 2.9117625196459658

Epoch: 6| Step: 4
Training loss: 1.0627083293648316
Validation loss: 2.9052448243513957

Epoch: 6| Step: 5
Training loss: 1.2629044574200663
Validation loss: 2.85174759216198

Epoch: 6| Step: 6
Training loss: 1.0639420428553026
Validation loss: 2.9818313437017707

Epoch: 6| Step: 7
Training loss: 0.9119919368446017
Validation loss: 2.873335619156261

Epoch: 6| Step: 8
Training loss: 0.7526602850630231
Validation loss: 2.9585851553177718

Epoch: 6| Step: 9
Training loss: 1.1885298228809067
Validation loss: 2.887139461351796

Epoch: 6| Step: 10
Training loss: 0.9690554967760666
Validation loss: 2.9521617630415844

Epoch: 6| Step: 11
Training loss: 0.5987382954546495
Validation loss: 2.8688184099760163

Epoch: 6| Step: 12
Training loss: 1.1707714225084724
Validation loss: 2.8628015328832825

Epoch: 6| Step: 13
Training loss: 2.0192470682625165
Validation loss: 2.900798593379032

Epoch: 127| Step: 0
Training loss: 2.0377987274046143
Validation loss: 2.824841133084251

Epoch: 6| Step: 1
Training loss: 1.3289741045780532
Validation loss: 2.7935407715236806

Epoch: 6| Step: 2
Training loss: 0.7204200581576854
Validation loss: 2.8816127468761987

Epoch: 6| Step: 3
Training loss: 0.9129215520893156
Validation loss: 2.896402280248152

Epoch: 6| Step: 4
Training loss: 0.8937632833173965
Validation loss: 2.870647079080545

Epoch: 6| Step: 5
Training loss: 0.4751622311969244
Validation loss: 2.9140370003928586

Epoch: 6| Step: 6
Training loss: 0.8962239737037052
Validation loss: 2.977463273046897

Epoch: 6| Step: 7
Training loss: 1.2406360846728122
Validation loss: 2.979568605496376

Epoch: 6| Step: 8
Training loss: 1.1081250092946937
Validation loss: 2.930335879315829

Epoch: 6| Step: 9
Training loss: 1.0148726978240652
Validation loss: 2.8582447646258906

Epoch: 6| Step: 10
Training loss: 0.8646254624975891
Validation loss: 2.7810755471369446

Epoch: 6| Step: 11
Training loss: 1.034867847501309
Validation loss: 2.8102781773957033

Epoch: 6| Step: 12
Training loss: 1.3323416250414817
Validation loss: 2.869515218187112

Epoch: 6| Step: 13
Training loss: 0.9205296608322925
Validation loss: 2.779132980264532

Epoch: 128| Step: 0
Training loss: 0.8449714437997873
Validation loss: 2.787777445261708

Epoch: 6| Step: 1
Training loss: 0.8838728891314297
Validation loss: 2.7494316958817904

Epoch: 6| Step: 2
Training loss: 1.0732850612029026
Validation loss: 2.8429620230982064

Epoch: 6| Step: 3
Training loss: 0.8283570162523595
Validation loss: 2.885893721455849

Epoch: 6| Step: 4
Training loss: 0.96991828490694
Validation loss: 2.907676059774929

Epoch: 6| Step: 5
Training loss: 1.1572316616284017
Validation loss: 3.1023829069334607

Epoch: 6| Step: 6
Training loss: 0.776460385276786
Validation loss: 2.994645545822433

Epoch: 6| Step: 7
Training loss: 1.2513688222160873
Validation loss: 3.0345309221702825

Epoch: 6| Step: 8
Training loss: 1.0785707851343032
Validation loss: 3.0241871905653106

Epoch: 6| Step: 9
Training loss: 0.6444509745226804
Validation loss: 2.9488343247229585

Epoch: 6| Step: 10
Training loss: 1.1288689735884496
Validation loss: 2.91726323339159

Epoch: 6| Step: 11
Training loss: 1.8236960207380801
Validation loss: 2.8815266843883296

Epoch: 6| Step: 12
Training loss: 1.0177299986569723
Validation loss: 2.8251883925014627

Epoch: 6| Step: 13
Training loss: 1.12632562101903
Validation loss: 2.8280174839103402

Epoch: 129| Step: 0
Training loss: 0.9774247902037071
Validation loss: 2.85134715482091

Epoch: 6| Step: 1
Training loss: 1.1432045808666966
Validation loss: 2.7824011145720573

Epoch: 6| Step: 2
Training loss: 1.066708141255712
Validation loss: 2.831623744366119

Epoch: 6| Step: 3
Training loss: 0.9468792943573817
Validation loss: 2.810723895413524

Epoch: 6| Step: 4
Training loss: 1.7987362717031035
Validation loss: 2.890820099716122

Epoch: 6| Step: 5
Training loss: 1.0103416939413297
Validation loss: 2.8764414490897967

Epoch: 6| Step: 6
Training loss: 0.8099975562941811
Validation loss: 2.8938823046281543

Epoch: 6| Step: 7
Training loss: 1.0791211709014572
Validation loss: 2.9022663665764785

Epoch: 6| Step: 8
Training loss: 1.0644803384924435
Validation loss: 2.923051294736959

Epoch: 6| Step: 9
Training loss: 0.6895128175651998
Validation loss: 2.9550608592212884

Epoch: 6| Step: 10
Training loss: 0.7430460331109574
Validation loss: 2.945306199502994

Epoch: 6| Step: 11
Training loss: 0.6893463916670016
Validation loss: 2.9408502614748455

Epoch: 6| Step: 12
Training loss: 1.105129985327339
Validation loss: 2.9302630321190213

Epoch: 6| Step: 13
Training loss: 0.7388968348573811
Validation loss: 2.898628674120708

Epoch: 130| Step: 0
Training loss: 0.8474458002521942
Validation loss: 2.8442667257608427

Epoch: 6| Step: 1
Training loss: 0.9748136806971267
Validation loss: 2.817901087647401

Epoch: 6| Step: 2
Training loss: 0.8775299146503567
Validation loss: 2.823897502210684

Epoch: 6| Step: 3
Training loss: 0.7363571444593443
Validation loss: 2.8129170002685435

Epoch: 6| Step: 4
Training loss: 1.0395190734471225
Validation loss: 2.8238670372824726

Epoch: 6| Step: 5
Training loss: 1.1190168435445798
Validation loss: 2.8541416297055786

Epoch: 6| Step: 6
Training loss: 0.9538540787610182
Validation loss: 2.8374426344395673

Epoch: 6| Step: 7
Training loss: 1.9311727761442787
Validation loss: 2.813038739069315

Epoch: 6| Step: 8
Training loss: 1.286240372617112
Validation loss: 2.810342483917651

Epoch: 6| Step: 9
Training loss: 0.6414309293619862
Validation loss: 2.8985673407496457

Epoch: 6| Step: 10
Training loss: 0.7813581391832674
Validation loss: 2.9087042683108937

Epoch: 6| Step: 11
Training loss: 0.713606300118352
Validation loss: 2.8847365329440318

Epoch: 6| Step: 12
Training loss: 1.1533920433742355
Validation loss: 2.947289097892397

Epoch: 6| Step: 13
Training loss: 0.6924321812083604
Validation loss: 2.935120640256842

Epoch: 131| Step: 0
Training loss: 0.7959924186029209
Validation loss: 2.8071988195990647

Epoch: 6| Step: 1
Training loss: 1.2984499273153036
Validation loss: 2.8209224192884363

Epoch: 6| Step: 2
Training loss: 0.7916705775582603
Validation loss: 2.7704148275256717

Epoch: 6| Step: 3
Training loss: 1.8991077637029286
Validation loss: 2.8363593482207032

Epoch: 6| Step: 4
Training loss: 0.7590551511205408
Validation loss: 2.882414779175296

Epoch: 6| Step: 5
Training loss: 1.224520398669043
Validation loss: 2.8457740804518084

Epoch: 6| Step: 6
Training loss: 0.8576322744906385
Validation loss: 2.836183451486422

Epoch: 6| Step: 7
Training loss: 1.0043462835359638
Validation loss: 2.9884771012761817

Epoch: 6| Step: 8
Training loss: 1.0695876291265785
Validation loss: 2.945291642200336

Epoch: 6| Step: 9
Training loss: 0.798060115605408
Validation loss: 2.9638881961218293

Epoch: 6| Step: 10
Training loss: 0.9505551197017065
Validation loss: 2.9910092602893283

Epoch: 6| Step: 11
Training loss: 0.8124424107022618
Validation loss: 2.9764859647748363

Epoch: 6| Step: 12
Training loss: 1.1877939964565356
Validation loss: 2.915092715691331

Epoch: 6| Step: 13
Training loss: 0.9016936962062597
Validation loss: 2.9053388965402287

Epoch: 132| Step: 0
Training loss: 0.8564025102661417
Validation loss: 2.9111121193040392

Epoch: 6| Step: 1
Training loss: 1.075907209082429
Validation loss: 2.844512739350912

Epoch: 6| Step: 2
Training loss: 0.955789500037672
Validation loss: 2.8465256332493203

Epoch: 6| Step: 3
Training loss: 0.9445995448106344
Validation loss: 2.855566591046883

Epoch: 6| Step: 4
Training loss: 0.8010513222405555
Validation loss: 2.835569786984341

Epoch: 6| Step: 5
Training loss: 0.7621358658621488
Validation loss: 2.881480756222878

Epoch: 6| Step: 6
Training loss: 0.6912129449828682
Validation loss: 2.9244392417204716

Epoch: 6| Step: 7
Training loss: 0.726258655306113
Validation loss: 2.9699677630001116

Epoch: 6| Step: 8
Training loss: 0.9490656474152026
Validation loss: 3.0366487307041514

Epoch: 6| Step: 9
Training loss: 2.0021803415264863
Validation loss: 3.0573479009825517

Epoch: 6| Step: 10
Training loss: 0.8265499755833526
Validation loss: 2.990914348661094

Epoch: 6| Step: 11
Training loss: 1.3576708229170533
Validation loss: 2.9754822139859045

Epoch: 6| Step: 12
Training loss: 0.8173824478932505
Validation loss: 2.8987056748638196

Epoch: 6| Step: 13
Training loss: 1.3415744824855138
Validation loss: 2.8304379245231757

Epoch: 133| Step: 0
Training loss: 0.9359156572598408
Validation loss: 2.829505021692055

Epoch: 6| Step: 1
Training loss: 1.0345475044350552
Validation loss: 2.8249740751309105

Epoch: 6| Step: 2
Training loss: 1.8639990745427533
Validation loss: 2.853636467315979

Epoch: 6| Step: 3
Training loss: 1.2856512073150819
Validation loss: 2.8267228108654305

Epoch: 6| Step: 4
Training loss: 0.8033264649626497
Validation loss: 2.7363015790074168

Epoch: 6| Step: 5
Training loss: 0.635843904623177
Validation loss: 2.814837409880598

Epoch: 6| Step: 6
Training loss: 1.1628731405617894
Validation loss: 2.9464080419004097

Epoch: 6| Step: 7
Training loss: 1.0985110609620226
Validation loss: 3.10014501765697

Epoch: 6| Step: 8
Training loss: 0.9541877075163104
Validation loss: 3.0783859374696645

Epoch: 6| Step: 9
Training loss: 1.2586441607712655
Validation loss: 3.164757722055625

Epoch: 6| Step: 10
Training loss: 0.9783396914880423
Validation loss: 3.0836619167687846

Epoch: 6| Step: 11
Training loss: 0.9330086570513926
Validation loss: 3.0016695780919127

Epoch: 6| Step: 12
Training loss: 0.8137833656701611
Validation loss: 2.8305172155086162

Epoch: 6| Step: 13
Training loss: 0.9681461051674627
Validation loss: 2.8934031839626164

Epoch: 134| Step: 0
Training loss: 0.6697246828495058
Validation loss: 2.7782114983084885

Epoch: 6| Step: 1
Training loss: 1.0182876309962734
Validation loss: 2.7885837874273136

Epoch: 6| Step: 2
Training loss: 1.3020940347867531
Validation loss: 2.7600114392997193

Epoch: 6| Step: 3
Training loss: 0.6875224760022876
Validation loss: 2.8148758284249396

Epoch: 6| Step: 4
Training loss: 1.064679546947911
Validation loss: 2.773003614988927

Epoch: 6| Step: 5
Training loss: 1.8324145991681655
Validation loss: 2.857437658711783

Epoch: 6| Step: 6
Training loss: 0.8681376295496163
Validation loss: 2.9587559375775885

Epoch: 6| Step: 7
Training loss: 1.0487578242377222
Validation loss: 2.9388822996149386

Epoch: 6| Step: 8
Training loss: 0.8896618704927993
Validation loss: 3.0056707510160163

Epoch: 6| Step: 9
Training loss: 1.0177895002428077
Validation loss: 3.1066964911460473

Epoch: 6| Step: 10
Training loss: 1.0683504484316289
Validation loss: 3.0560476229595297

Epoch: 6| Step: 11
Training loss: 0.727295782390289
Validation loss: 2.9436581769419154

Epoch: 6| Step: 12
Training loss: 0.6745443104002465
Validation loss: 2.990315142835768

Epoch: 6| Step: 13
Training loss: 1.2898977636884377
Validation loss: 2.9499991018218488

Epoch: 135| Step: 0
Training loss: 0.9939670673552449
Validation loss: 2.922487830426865

Epoch: 6| Step: 1
Training loss: 1.2052619089117047
Validation loss: 2.8803259404172943

Epoch: 6| Step: 2
Training loss: 0.6339712953657904
Validation loss: 2.812307082730058

Epoch: 6| Step: 3
Training loss: 1.012734628500918
Validation loss: 2.773648127764792

Epoch: 6| Step: 4
Training loss: 0.9819583899176031
Validation loss: 2.829456388295712

Epoch: 6| Step: 5
Training loss: 1.065948611704523
Validation loss: 2.8995324300500567

Epoch: 6| Step: 6
Training loss: 0.6432848351568388
Validation loss: 2.837873262342218

Epoch: 6| Step: 7
Training loss: 1.8841123407364166
Validation loss: 2.8186602274378463

Epoch: 6| Step: 8
Training loss: 0.6404339109923111
Validation loss: 2.990924472357319

Epoch: 6| Step: 9
Training loss: 0.9212083507424366
Validation loss: 2.9530298665111596

Epoch: 6| Step: 10
Training loss: 0.7748031889292998
Validation loss: 3.0374400589500827

Epoch: 6| Step: 11
Training loss: 1.1483739718557888
Validation loss: 2.988214469612271

Epoch: 6| Step: 12
Training loss: 1.1068588521028295
Validation loss: 2.993322928912539

Epoch: 6| Step: 13
Training loss: 0.6007916850162272
Validation loss: 2.9866550783020522

Epoch: 136| Step: 0
Training loss: 0.559013422458531
Validation loss: 2.8562127990859887

Epoch: 6| Step: 1
Training loss: 0.6395911271141257
Validation loss: 2.84810518721218

Epoch: 6| Step: 2
Training loss: 0.9669527178687436
Validation loss: 2.8154074581669915

Epoch: 6| Step: 3
Training loss: 1.9311077127230443
Validation loss: 2.883780602032473

Epoch: 6| Step: 4
Training loss: 0.8684157188075289
Validation loss: 2.8874206790790686

Epoch: 6| Step: 5
Training loss: 0.8317642858188228
Validation loss: 2.8090078926613815

Epoch: 6| Step: 6
Training loss: 1.1796877526289309
Validation loss: 2.8183716482704617

Epoch: 6| Step: 7
Training loss: 0.971458801006543
Validation loss: 2.886940341509234

Epoch: 6| Step: 8
Training loss: 0.7473839992600899
Validation loss: 2.9222418134956873

Epoch: 6| Step: 9
Training loss: 1.3798548215711974
Validation loss: 3.0502592805187074

Epoch: 6| Step: 10
Training loss: 0.9321517981490356
Validation loss: 3.161119689065669

Epoch: 6| Step: 11
Training loss: 0.8208159218956962
Validation loss: 3.098183791019801

Epoch: 6| Step: 12
Training loss: 1.0240706021660935
Validation loss: 3.0624254567941764

Epoch: 6| Step: 13
Training loss: 0.9589798688297102
Validation loss: 3.0339983511568005

Epoch: 137| Step: 0
Training loss: 0.6089578814857765
Validation loss: 2.9700644410759987

Epoch: 6| Step: 1
Training loss: 1.8504607065147265
Validation loss: 2.9449008751828143

Epoch: 6| Step: 2
Training loss: 0.9632399352929234
Validation loss: 2.801645979849354

Epoch: 6| Step: 3
Training loss: 0.9315461244778619
Validation loss: 2.964054557160906

Epoch: 6| Step: 4
Training loss: 1.028836692133054
Validation loss: 2.875354482386208

Epoch: 6| Step: 5
Training loss: 1.104887684944014
Validation loss: 2.856596174902339

Epoch: 6| Step: 6
Training loss: 0.884094118191359
Validation loss: 2.868560642372957

Epoch: 6| Step: 7
Training loss: 0.7998155679300366
Validation loss: 2.9015427755309555

Epoch: 6| Step: 8
Training loss: 0.9764603828445021
Validation loss: 2.880942643680954

Epoch: 6| Step: 9
Training loss: 0.9678809359345174
Validation loss: 2.896257717038321

Epoch: 6| Step: 10
Training loss: 0.5841106928847324
Validation loss: 2.971983022561748

Epoch: 6| Step: 11
Training loss: 0.8820034809995368
Validation loss: 2.9687009037709777

Epoch: 6| Step: 12
Training loss: 1.141782356349999
Validation loss: 2.9911862151373536

Epoch: 6| Step: 13
Training loss: 0.9312928068320067
Validation loss: 2.9361531978114273

Epoch: 138| Step: 0
Training loss: 1.046651901841553
Validation loss: 2.9469888437933913

Epoch: 6| Step: 1
Training loss: 0.6305704547668813
Validation loss: 2.900789388009418

Epoch: 6| Step: 2
Training loss: 0.8071423464265888
Validation loss: 2.8084846372812957

Epoch: 6| Step: 3
Training loss: 0.6476579369314792
Validation loss: 2.8562038882572756

Epoch: 6| Step: 4
Training loss: 0.866023476667863
Validation loss: 2.8593481024361216

Epoch: 6| Step: 5
Training loss: 0.6356105170011219
Validation loss: 2.8594930377770282

Epoch: 6| Step: 6
Training loss: 0.9173412369615859
Validation loss: 2.8046406606519274

Epoch: 6| Step: 7
Training loss: 0.8669959191750973
Validation loss: 2.8515480494024192

Epoch: 6| Step: 8
Training loss: 0.856423041685922
Validation loss: 2.796085082732889

Epoch: 6| Step: 9
Training loss: 2.0285330574965856
Validation loss: 2.838949014442135

Epoch: 6| Step: 10
Training loss: 1.0146660018443345
Validation loss: 2.958593415303191

Epoch: 6| Step: 11
Training loss: 0.8549825950434904
Validation loss: 2.9388432914651563

Epoch: 6| Step: 12
Training loss: 0.6208737301537969
Validation loss: 2.9535560629695325

Epoch: 6| Step: 13
Training loss: 0.8167137041623891
Validation loss: 2.9263753792812466

Epoch: 139| Step: 0
Training loss: 0.8407114204314389
Validation loss: 2.9294289979270838

Epoch: 6| Step: 1
Training loss: 0.652009638581967
Validation loss: 2.9423151389331923

Epoch: 6| Step: 2
Training loss: 1.3119790087683767
Validation loss: 2.9943019743011274

Epoch: 6| Step: 3
Training loss: 0.877818948213463
Validation loss: 3.0151512814889547

Epoch: 6| Step: 4
Training loss: 1.794186645954099
Validation loss: 2.8219499985707746

Epoch: 6| Step: 5
Training loss: 0.7511412361867336
Validation loss: 2.919319095717397

Epoch: 6| Step: 6
Training loss: 0.7684064283445619
Validation loss: 2.908106931893577

Epoch: 6| Step: 7
Training loss: 0.6011323009847975
Validation loss: 2.8583418294559766

Epoch: 6| Step: 8
Training loss: 0.7469380579548864
Validation loss: 2.9053801872238734

Epoch: 6| Step: 9
Training loss: 0.8218106349790744
Validation loss: 2.8587781773134724

Epoch: 6| Step: 10
Training loss: 0.7823723170278183
Validation loss: 2.951066202711841

Epoch: 6| Step: 11
Training loss: 1.1094013801984246
Validation loss: 2.9618588425758454

Epoch: 6| Step: 12
Training loss: 0.7852481769247914
Validation loss: 2.9271672780951916

Epoch: 6| Step: 13
Training loss: 0.7270027385591877
Validation loss: 2.946385357692607

Epoch: 140| Step: 0
Training loss: 0.6743180636110041
Validation loss: 3.0021775740250956

Epoch: 6| Step: 1
Training loss: 1.7584701325171708
Validation loss: 3.022491149258335

Epoch: 6| Step: 2
Training loss: 0.8562069499199104
Validation loss: 2.9973087292611087

Epoch: 6| Step: 3
Training loss: 1.0804438325404326
Validation loss: 2.9766883723360036

Epoch: 6| Step: 4
Training loss: 0.6939694366857079
Validation loss: 2.9494985687697293

Epoch: 6| Step: 5
Training loss: 0.7982003653005263
Validation loss: 2.99836220009779

Epoch: 6| Step: 6
Training loss: 0.6390007875300346
Validation loss: 2.9072985927964448

Epoch: 6| Step: 7
Training loss: 0.6725819882328348
Validation loss: 2.912294071104736

Epoch: 6| Step: 8
Training loss: 0.9082722299187962
Validation loss: 2.867386176132004

Epoch: 6| Step: 9
Training loss: 0.677682044567626
Validation loss: 2.959962253115085

Epoch: 6| Step: 10
Training loss: 1.060277240682969
Validation loss: 2.9144969272053056

Epoch: 6| Step: 11
Training loss: 0.8759895927625313
Validation loss: 2.973292198780438

Epoch: 6| Step: 12
Training loss: 0.6385307039333113
Validation loss: 2.8587033398390806

Epoch: 6| Step: 13
Training loss: 0.7983256580830655
Validation loss: 2.8773523465035993

Epoch: 141| Step: 0
Training loss: 0.8106444518403241
Validation loss: 2.898658229926441

Epoch: 6| Step: 1
Training loss: 0.9473585574782692
Validation loss: 2.826147775782344

Epoch: 6| Step: 2
Training loss: 0.7112964101442566
Validation loss: 2.9401848339618537

Epoch: 6| Step: 3
Training loss: 0.8961307268570303
Validation loss: 2.964467034345182

Epoch: 6| Step: 4
Training loss: 0.5949170789318666
Validation loss: 2.9931271690264674

Epoch: 6| Step: 5
Training loss: 0.8516908951303466
Validation loss: 2.935401193773377

Epoch: 6| Step: 6
Training loss: 1.110578502053057
Validation loss: 2.9906934123782825

Epoch: 6| Step: 7
Training loss: 1.7526876383417056
Validation loss: 2.9783364230586247

Epoch: 6| Step: 8
Training loss: 0.8364463398328121
Validation loss: 3.0026916244134756

Epoch: 6| Step: 9
Training loss: 1.0712760987101615
Validation loss: 2.8991692399944373

Epoch: 6| Step: 10
Training loss: 0.8775074997062478
Validation loss: 2.9498520463813716

Epoch: 6| Step: 11
Training loss: 0.6637417411290384
Validation loss: 2.898437691934447

Epoch: 6| Step: 12
Training loss: 0.8594536485229152
Validation loss: 2.8652875046332005

Epoch: 6| Step: 13
Training loss: 0.7229279703214784
Validation loss: 2.8976564683157298

Epoch: 142| Step: 0
Training loss: 0.6529125543435237
Validation loss: 2.9492826004358554

Epoch: 6| Step: 1
Training loss: 0.6445977841339469
Validation loss: 2.9148695495494312

Epoch: 6| Step: 2
Training loss: 1.0071804223209908
Validation loss: 2.826074752773294

Epoch: 6| Step: 3
Training loss: 1.282489456222649
Validation loss: 2.9206632661669776

Epoch: 6| Step: 4
Training loss: 1.7069202098914265
Validation loss: 2.917398774135143

Epoch: 6| Step: 5
Training loss: 0.6155487468374865
Validation loss: 2.955858691006099

Epoch: 6| Step: 6
Training loss: 0.6993211000005581
Validation loss: 3.0085837031939375

Epoch: 6| Step: 7
Training loss: 0.7879407103642484
Validation loss: 2.966355157599208

Epoch: 6| Step: 8
Training loss: 0.9202145315463461
Validation loss: 2.9598119470211146

Epoch: 6| Step: 9
Training loss: 0.7428335489990706
Validation loss: 2.9974805265912408

Epoch: 6| Step: 10
Training loss: 0.8481462881611409
Validation loss: 2.938386837354419

Epoch: 6| Step: 11
Training loss: 0.6660379982152131
Validation loss: 2.952476174530016

Epoch: 6| Step: 12
Training loss: 0.596275729777834
Validation loss: 2.8914815166427275

Epoch: 6| Step: 13
Training loss: 0.9115461289037853
Validation loss: 2.9374668714670795

Epoch: 143| Step: 0
Training loss: 0.6495294683494846
Validation loss: 2.9008202779363423

Epoch: 6| Step: 1
Training loss: 0.7375740822260131
Validation loss: 2.9711078582944954

Epoch: 6| Step: 2
Training loss: 0.9807657042895938
Validation loss: 3.039257837602821

Epoch: 6| Step: 3
Training loss: 0.6507859045551444
Validation loss: 2.9243795638929644

Epoch: 6| Step: 4
Training loss: 0.903032741652195
Validation loss: 2.9200948504497535

Epoch: 6| Step: 5
Training loss: 0.5814201167564095
Validation loss: 3.007477897759429

Epoch: 6| Step: 6
Training loss: 0.883725732041192
Validation loss: 2.940341576090455

Epoch: 6| Step: 7
Training loss: 1.0357607821659038
Validation loss: 3.0014182553043027

Epoch: 6| Step: 8
Training loss: 0.5490582075477733
Validation loss: 2.9258829734920564

Epoch: 6| Step: 9
Training loss: 0.8515762188007612
Validation loss: 2.9699611000442006

Epoch: 6| Step: 10
Training loss: 0.9987053238827363
Validation loss: 2.9462691557062826

Epoch: 6| Step: 11
Training loss: 1.76622539203453
Validation loss: 2.9303451274715044

Epoch: 6| Step: 12
Training loss: 0.7164036558347635
Validation loss: 2.9822289704876406

Epoch: 6| Step: 13
Training loss: 0.6712204605933938
Validation loss: 2.960102215110378

Epoch: 144| Step: 0
Training loss: 0.5331911917109153
Validation loss: 2.9333690518314177

Epoch: 6| Step: 1
Training loss: 0.656555967302972
Validation loss: 2.915948688601583

Epoch: 6| Step: 2
Training loss: 0.8527971818609893
Validation loss: 2.9155930632177403

Epoch: 6| Step: 3
Training loss: 0.7754336328373914
Validation loss: 2.8867536860147043

Epoch: 6| Step: 4
Training loss: 0.7373990232230976
Validation loss: 2.9870208542211487

Epoch: 6| Step: 5
Training loss: 0.9089573507385982
Validation loss: 2.970696543950222

Epoch: 6| Step: 6
Training loss: 0.8306690939744822
Validation loss: 2.9542354399975537

Epoch: 6| Step: 7
Training loss: 0.49418071538962854
Validation loss: 2.920732393756281

Epoch: 6| Step: 8
Training loss: 0.8396927808759511
Validation loss: 2.8522483662761573

Epoch: 6| Step: 9
Training loss: 0.8245087606035189
Validation loss: 2.9508027730151274

Epoch: 6| Step: 10
Training loss: 1.6018736746340123
Validation loss: 3.002318056254545

Epoch: 6| Step: 11
Training loss: 1.0460550883686368
Validation loss: 2.953468800603126

Epoch: 6| Step: 12
Training loss: 0.7481321679634754
Validation loss: 3.0097714208918007

Epoch: 6| Step: 13
Training loss: 0.791292382321039
Validation loss: 3.032125195924598

Epoch: 145| Step: 0
Training loss: 0.5474028900543372
Validation loss: 2.916461587689658

Epoch: 6| Step: 1
Training loss: 1.1077948048285398
Validation loss: 2.81834505024224

Epoch: 6| Step: 2
Training loss: 0.5942734870104727
Validation loss: 2.969082127781828

Epoch: 6| Step: 3
Training loss: 1.7311849726504211
Validation loss: 2.887782133721786

Epoch: 6| Step: 4
Training loss: 0.7487314144878353
Validation loss: 2.9469365129357996

Epoch: 6| Step: 5
Training loss: 0.7090657925686943
Validation loss: 2.9140082414772785

Epoch: 6| Step: 6
Training loss: 0.7096381417785023
Validation loss: 2.9982587078859386

Epoch: 6| Step: 7
Training loss: 0.9292280841138564
Validation loss: 3.0135728511170363

Epoch: 6| Step: 8
Training loss: 0.5454766242388566
Validation loss: 2.9989522720351625

Epoch: 6| Step: 9
Training loss: 0.762977694354107
Validation loss: 2.986258932392764

Epoch: 6| Step: 10
Training loss: 0.8668809984875593
Validation loss: 2.943090678444453

Epoch: 6| Step: 11
Training loss: 0.6523740612914273
Validation loss: 2.9916787109203393

Epoch: 6| Step: 12
Training loss: 0.7392230208359613
Validation loss: 3.0107306258393804

Epoch: 6| Step: 13
Training loss: 0.92276165236622
Validation loss: 2.9480998428281713

Epoch: 146| Step: 0
Training loss: 0.7692394187330917
Validation loss: 3.0555094517976906

Epoch: 6| Step: 1
Training loss: 0.8922892631042966
Validation loss: 2.95534024585673

Epoch: 6| Step: 2
Training loss: 0.6405433509712041
Validation loss: 2.9537384230356833

Epoch: 6| Step: 3
Training loss: 0.5109902649211553
Validation loss: 2.9548533661548215

Epoch: 6| Step: 4
Training loss: 1.0010075261979217
Validation loss: 2.9938990360081053

Epoch: 6| Step: 5
Training loss: 0.5470642852178798
Validation loss: 3.038581005875334

Epoch: 6| Step: 6
Training loss: 1.8807325468945892
Validation loss: 2.982471025149775

Epoch: 6| Step: 7
Training loss: 0.7252101001829392
Validation loss: 3.004276591779618

Epoch: 6| Step: 8
Training loss: 0.4965045759771941
Validation loss: 3.0145449507843938

Epoch: 6| Step: 9
Training loss: 1.0252254680051003
Validation loss: 3.020983269138469

Epoch: 6| Step: 10
Training loss: 0.9591724343434403
Validation loss: 2.9464220002886887

Epoch: 6| Step: 11
Training loss: 0.559834442913042
Validation loss: 2.994286925309719

Epoch: 6| Step: 12
Training loss: 0.5171118597399441
Validation loss: 2.987970393349506

Epoch: 6| Step: 13
Training loss: 0.459466640258711
Validation loss: 3.0168435858031453

Epoch: 147| Step: 0
Training loss: 0.6960251617035199
Validation loss: 3.0258198239308474

Epoch: 6| Step: 1
Training loss: 0.6502503023187213
Validation loss: 2.901160716565298

Epoch: 6| Step: 2
Training loss: 0.8518560760926199
Validation loss: 2.985093328229957

Epoch: 6| Step: 3
Training loss: 0.9455524486839851
Validation loss: 3.0018866222844145

Epoch: 6| Step: 4
Training loss: 0.5687533975856032
Validation loss: 2.980315844878708

Epoch: 6| Step: 5
Training loss: 1.6465744410234062
Validation loss: 2.9773335496962465

Epoch: 6| Step: 6
Training loss: 0.7724381357871429
Validation loss: 2.9112580332270537

Epoch: 6| Step: 7
Training loss: 0.7096758116444503
Validation loss: 2.9158826773423003

Epoch: 6| Step: 8
Training loss: 0.770971702494265
Validation loss: 2.974505296816256

Epoch: 6| Step: 9
Training loss: 0.9090963913470471
Validation loss: 2.9675276598970957

Epoch: 6| Step: 10
Training loss: 0.5132137329659091
Validation loss: 2.979215946101158

Epoch: 6| Step: 11
Training loss: 0.5221571279627162
Validation loss: 2.9330569003360862

Epoch: 6| Step: 12
Training loss: 1.0936125532709255
Validation loss: 3.001363298808278

Epoch: 6| Step: 13
Training loss: 0.8462703995943517
Validation loss: 2.891427652080012

Epoch: 148| Step: 0
Training loss: 0.6894134855897487
Validation loss: 2.984160796728453

Epoch: 6| Step: 1
Training loss: 1.009087044945144
Validation loss: 2.9677928920993986

Epoch: 6| Step: 2
Training loss: 0.8093532367858622
Validation loss: 2.93298067949662

Epoch: 6| Step: 3
Training loss: 0.7623348776458768
Validation loss: 2.944716281058636

Epoch: 6| Step: 4
Training loss: 0.889043977407042
Validation loss: 2.907901308458508

Epoch: 6| Step: 5
Training loss: 0.5827186161134597
Validation loss: 2.985814171943502

Epoch: 6| Step: 6
Training loss: 0.5379492279685401
Validation loss: 2.9365517323446646

Epoch: 6| Step: 7
Training loss: 0.5367536164221
Validation loss: 3.018418265281196

Epoch: 6| Step: 8
Training loss: 1.0043977358131304
Validation loss: 2.97876582527946

Epoch: 6| Step: 9
Training loss: 0.7633318131721829
Validation loss: 3.036073118260834

Epoch: 6| Step: 10
Training loss: 0.7075487634952758
Validation loss: 2.955138473751755

Epoch: 6| Step: 11
Training loss: 0.7791712380001449
Validation loss: 2.9788808663313278

Epoch: 6| Step: 12
Training loss: 0.6821333189420845
Validation loss: 2.9540256156301474

Epoch: 6| Step: 13
Training loss: 1.6710510362585098
Validation loss: 2.933538890991097

Epoch: 149| Step: 0
Training loss: 0.8294625905978852
Validation loss: 2.9052958409062675

Epoch: 6| Step: 1
Training loss: 0.7341011835512494
Validation loss: 2.8710826363207875

Epoch: 6| Step: 2
Training loss: 0.6347291671846919
Validation loss: 2.960157212751978

Epoch: 6| Step: 3
Training loss: 0.7353892525668515
Validation loss: 2.998019644316396

Epoch: 6| Step: 4
Training loss: 0.7376950070817602
Validation loss: 2.921336880938408

Epoch: 6| Step: 5
Training loss: 0.66543341104615
Validation loss: 2.9615600253605323

Epoch: 6| Step: 6
Training loss: 0.8917821427614274
Validation loss: 3.068846283727484

Epoch: 6| Step: 7
Training loss: 0.6546366478373764
Validation loss: 2.9944396146532064

Epoch: 6| Step: 8
Training loss: 0.6474066664100615
Validation loss: 3.0116335291500453

Epoch: 6| Step: 9
Training loss: 0.44710117965138196
Validation loss: 3.003875414785557

Epoch: 6| Step: 10
Training loss: 1.2175841991284064
Validation loss: 2.9314906831467815

Epoch: 6| Step: 11
Training loss: 0.6688802422945592
Validation loss: 2.965800751173692

Epoch: 6| Step: 12
Training loss: 1.691354940222033
Validation loss: 3.0212638328992094

Epoch: 6| Step: 13
Training loss: 0.4113314730805931
Validation loss: 3.0227113717578535

Epoch: 150| Step: 0
Training loss: 0.4932126918271537
Validation loss: 2.922681387805352

Epoch: 6| Step: 1
Training loss: 0.7930508650934042
Validation loss: 2.924950325916316

Epoch: 6| Step: 2
Training loss: 0.7642889237304651
Validation loss: 3.0537697404454245

Epoch: 6| Step: 3
Training loss: 0.9832968484176863
Validation loss: 3.056663777971584

Epoch: 6| Step: 4
Training loss: 1.7089967912495392
Validation loss: 2.996846342828205

Epoch: 6| Step: 5
Training loss: 0.6377148004565552
Validation loss: 2.9741182278719673

Epoch: 6| Step: 6
Training loss: 0.7422465652252724
Validation loss: 3.010597478767052

Epoch: 6| Step: 7
Training loss: 0.7506529032454466
Validation loss: 2.970557268396385

Epoch: 6| Step: 8
Training loss: 0.7835229995750203
Validation loss: 3.02237285101514

Epoch: 6| Step: 9
Training loss: 0.5059716236371464
Validation loss: 2.9350468151901405

Epoch: 6| Step: 10
Training loss: 0.6253982228967825
Validation loss: 2.906604458102374

Epoch: 6| Step: 11
Training loss: 0.8855248366458622
Validation loss: 2.9335894154983513

Epoch: 6| Step: 12
Training loss: 0.41468709944222026
Validation loss: 3.02986944687426

Epoch: 6| Step: 13
Training loss: 0.807009559480188
Validation loss: 3.0331774086403476

Epoch: 151| Step: 0
Training loss: 0.7679919808833363
Validation loss: 3.0053289291188223

Epoch: 6| Step: 1
Training loss: 0.6791775204272952
Validation loss: 3.057348381872472

Epoch: 6| Step: 2
Training loss: 0.8216221482079288
Validation loss: 3.022775385311412

Epoch: 6| Step: 3
Training loss: 0.9424654435215162
Validation loss: 3.017266638686084

Epoch: 6| Step: 4
Training loss: 0.5697144285733549
Validation loss: 2.9834971310138414

Epoch: 6| Step: 5
Training loss: 0.6145551534970302
Validation loss: 2.911755123035772

Epoch: 6| Step: 6
Training loss: 0.8192606767500583
Validation loss: 2.946917904986127

Epoch: 6| Step: 7
Training loss: 0.7011029307863361
Validation loss: 2.9648795747665777

Epoch: 6| Step: 8
Training loss: 0.761425411766856
Validation loss: 3.0089202426343964

Epoch: 6| Step: 9
Training loss: 0.5588934834477656
Validation loss: 2.957606190430073

Epoch: 6| Step: 10
Training loss: 0.9480113761175017
Validation loss: 2.9001488307602243

Epoch: 6| Step: 11
Training loss: 1.723754947646954
Validation loss: 2.9149813733124654

Epoch: 6| Step: 12
Training loss: 0.7989114284216987
Validation loss: 3.0174925165470756

Epoch: 6| Step: 13
Training loss: 0.5923547161418476
Validation loss: 3.005471339801849

Epoch: 152| Step: 0
Training loss: 0.666554923428068
Validation loss: 2.963704208091057

Epoch: 6| Step: 1
Training loss: 0.6223943276699694
Validation loss: 2.9885047845613344

Epoch: 6| Step: 2
Training loss: 0.8022000653093074
Validation loss: 2.9974723605084543

Epoch: 6| Step: 3
Training loss: 0.43984505024746584
Validation loss: 2.985003473438519

Epoch: 6| Step: 4
Training loss: 0.4458739438976189
Validation loss: 3.0205936906842767

Epoch: 6| Step: 5
Training loss: 0.569953805657793
Validation loss: 2.9927370581004635

Epoch: 6| Step: 6
Training loss: 0.4784545548063456
Validation loss: 2.9147660511505307

Epoch: 6| Step: 7
Training loss: 0.582607086840911
Validation loss: 2.981316162270906

Epoch: 6| Step: 8
Training loss: 0.5418666934880365
Validation loss: 3.0200162944606745

Epoch: 6| Step: 9
Training loss: 0.6000285469655074
Validation loss: 2.950249121001729

Epoch: 6| Step: 10
Training loss: 1.7304829409600828
Validation loss: 3.0179061431539775

Epoch: 6| Step: 11
Training loss: 1.0886494098011201
Validation loss: 3.0458924755263537

Epoch: 6| Step: 12
Training loss: 0.802866829666788
Validation loss: 3.0059840469994556

Epoch: 6| Step: 13
Training loss: 0.8128231579684235
Validation loss: 3.052544846430499

Epoch: 153| Step: 0
Training loss: 0.41600233603014153
Validation loss: 3.0344266468685364

Epoch: 6| Step: 1
Training loss: 0.5090806824567303
Validation loss: 2.935878684994488

Epoch: 6| Step: 2
Training loss: 0.6404549442766024
Validation loss: 2.981582813359668

Epoch: 6| Step: 3
Training loss: 1.6249265654183636
Validation loss: 2.8932323484406144

Epoch: 6| Step: 4
Training loss: 0.3879557582724835
Validation loss: 2.94813171968226

Epoch: 6| Step: 5
Training loss: 0.8351101212211717
Validation loss: 2.973718641323438

Epoch: 6| Step: 6
Training loss: 1.2599198594416934
Validation loss: 2.9524337390093556

Epoch: 6| Step: 7
Training loss: 0.4267785876910952
Validation loss: 3.0295864403801906

Epoch: 6| Step: 8
Training loss: 0.9325687415836597
Validation loss: 2.9752725257321058

Epoch: 6| Step: 9
Training loss: 0.56498972588034
Validation loss: 2.9527603543248877

Epoch: 6| Step: 10
Training loss: 0.5978369346207446
Validation loss: 3.043093142172627

Epoch: 6| Step: 11
Training loss: 0.49788259152872294
Validation loss: 2.9353115370700213

Epoch: 6| Step: 12
Training loss: 0.5968483844035677
Validation loss: 2.989507512494618

Epoch: 6| Step: 13
Training loss: 0.5749838007842673
Validation loss: 3.0693896251825348

Epoch: 154| Step: 0
Training loss: 0.7286643932306482
Validation loss: 3.0771320503595114

Epoch: 6| Step: 1
Training loss: 0.5758988072794483
Validation loss: 3.0766926900796996

Epoch: 6| Step: 2
Training loss: 0.6130442313172152
Validation loss: 2.962884335059621

Epoch: 6| Step: 3
Training loss: 1.6958804256014728
Validation loss: 2.947722416241372

Epoch: 6| Step: 4
Training loss: 0.508576273581264
Validation loss: 2.9527188649186327

Epoch: 6| Step: 5
Training loss: 0.7022962136141696
Validation loss: 2.9447406109024006

Epoch: 6| Step: 6
Training loss: 0.8508254895298613
Validation loss: 2.9852376360207935

Epoch: 6| Step: 7
Training loss: 0.7017338023230852
Validation loss: 3.060579086747667

Epoch: 6| Step: 8
Training loss: 0.825930981879146
Validation loss: 2.9698917134342375

Epoch: 6| Step: 9
Training loss: 0.6467011886243631
Validation loss: 3.01941025636704

Epoch: 6| Step: 10
Training loss: 0.5097131811767056
Validation loss: 2.9584554235132283

Epoch: 6| Step: 11
Training loss: 0.6770861381081418
Validation loss: 2.85491712593544

Epoch: 6| Step: 12
Training loss: 0.8716341403803053
Validation loss: 2.9658662811089833

Epoch: 6| Step: 13
Training loss: 0.9155907855623046
Validation loss: 2.926706626969761

Epoch: 155| Step: 0
Training loss: 0.7218776323014524
Validation loss: 2.8878295991059253

Epoch: 6| Step: 1
Training loss: 0.5298526000237449
Validation loss: 2.9057744638664222

Epoch: 6| Step: 2
Training loss: 0.6212482859935181
Validation loss: 2.9483124879481455

Epoch: 6| Step: 3
Training loss: 0.6943305722229196
Validation loss: 3.0543856654596646

Epoch: 6| Step: 4
Training loss: 0.7174151505997689
Validation loss: 3.050581804660191

Epoch: 6| Step: 5
Training loss: 0.80012038338415
Validation loss: 2.9913544852360032

Epoch: 6| Step: 6
Training loss: 0.8922839191132184
Validation loss: 3.0827778023650487

Epoch: 6| Step: 7
Training loss: 0.6850385601787745
Validation loss: 3.0236888981407235

Epoch: 6| Step: 8
Training loss: 1.768194438909789
Validation loss: 2.9951495457093156

Epoch: 6| Step: 9
Training loss: 0.9828298036540938
Validation loss: 2.987683484496121

Epoch: 6| Step: 10
Training loss: 1.0506304664628456
Validation loss: 2.9864862773125904

Epoch: 6| Step: 11
Training loss: 0.7457048291226354
Validation loss: 2.924641813860269

Epoch: 6| Step: 12
Training loss: 0.3601023114375196
Validation loss: 2.9362114589517017

Epoch: 6| Step: 13
Training loss: 0.5012616987599312
Validation loss: 2.890769370657923

Epoch: 156| Step: 0
Training loss: 0.7159758394949362
Validation loss: 2.998331440396124

Epoch: 6| Step: 1
Training loss: 0.6520098442697693
Validation loss: 3.092616981569653

Epoch: 6| Step: 2
Training loss: 0.7425587578846087
Validation loss: 3.041977975321268

Epoch: 6| Step: 3
Training loss: 0.610470715908442
Validation loss: 3.1092558667029753

Epoch: 6| Step: 4
Training loss: 0.6033188582452528
Validation loss: 3.0290063111592223

Epoch: 6| Step: 5
Training loss: 0.8683951963791724
Validation loss: 3.063729123880064

Epoch: 6| Step: 6
Training loss: 0.7642038741113641
Validation loss: 2.997211604197254

Epoch: 6| Step: 7
Training loss: 1.5990686865219668
Validation loss: 3.0330802530692513

Epoch: 6| Step: 8
Training loss: 0.5657378363420589
Validation loss: 3.0002117876954304

Epoch: 6| Step: 9
Training loss: 1.024194452039743
Validation loss: 3.01306536528117

Epoch: 6| Step: 10
Training loss: 0.9122876926244674
Validation loss: 2.994569977004735

Epoch: 6| Step: 11
Training loss: 0.5958618452901964
Validation loss: 3.002991813699322

Epoch: 6| Step: 12
Training loss: 0.7564163718583545
Validation loss: 2.9721629819185273

Epoch: 6| Step: 13
Training loss: 0.5683015879195202
Validation loss: 2.972379373295735

Epoch: 157| Step: 0
Training loss: 0.6855745445818895
Validation loss: 3.028956617360152

Epoch: 6| Step: 1
Training loss: 0.6209375436952727
Validation loss: 2.9193069814212937

Epoch: 6| Step: 2
Training loss: 0.8326735904925969
Validation loss: 3.0888627106847895

Epoch: 6| Step: 3
Training loss: 0.588167853907209
Validation loss: 3.0461295104326767

Epoch: 6| Step: 4
Training loss: 0.8499759277974188
Validation loss: 2.972133943151883

Epoch: 6| Step: 5
Training loss: 0.607885790723427
Validation loss: 2.9494174780848073

Epoch: 6| Step: 6
Training loss: 0.7639917352588863
Validation loss: 3.095324594036612

Epoch: 6| Step: 7
Training loss: 0.5685355316572888
Validation loss: 3.0908504088886537

Epoch: 6| Step: 8
Training loss: 0.5547796360917007
Validation loss: 3.152398860155021

Epoch: 6| Step: 9
Training loss: 0.5569861159691647
Validation loss: 3.083846311597329

Epoch: 6| Step: 10
Training loss: 0.5265407806807217
Validation loss: 2.9979142382313477

Epoch: 6| Step: 11
Training loss: 0.540433522311806
Validation loss: 3.0931755971222796

Epoch: 6| Step: 12
Training loss: 1.6258885815160873
Validation loss: 2.9459863460213134

Epoch: 6| Step: 13
Training loss: 0.5480401841487287
Validation loss: 2.9551606066971923

Epoch: 158| Step: 0
Training loss: 0.7140740591904084
Validation loss: 2.9881725283190477

Epoch: 6| Step: 1
Training loss: 0.8675591299699063
Validation loss: 3.0094624539321297

Epoch: 6| Step: 2
Training loss: 1.5765318429951038
Validation loss: 3.0298858273380365

Epoch: 6| Step: 3
Training loss: 0.7221147725267677
Validation loss: 2.9743416311486097

Epoch: 6| Step: 4
Training loss: 0.5626708142218487
Validation loss: 3.048463827749776

Epoch: 6| Step: 5
Training loss: 0.6842371065752911
Validation loss: 3.102541316656667

Epoch: 6| Step: 6
Training loss: 0.7838719050194689
Validation loss: 2.9761466255590596

Epoch: 6| Step: 7
Training loss: 0.5321567874632215
Validation loss: 2.9483710613895333

Epoch: 6| Step: 8
Training loss: 0.37966020038561266
Validation loss: 2.905382580670483

Epoch: 6| Step: 9
Training loss: 0.7516055802590343
Validation loss: 2.8997187151912382

Epoch: 6| Step: 10
Training loss: 0.6274995413242807
Validation loss: 3.0405217502441055

Epoch: 6| Step: 11
Training loss: 0.9297027586638447
Validation loss: 2.9786296218152537

Epoch: 6| Step: 12
Training loss: 0.7718515801834347
Validation loss: 2.9084675303397645

Epoch: 6| Step: 13
Training loss: 0.6680880657510762
Validation loss: 3.0056150393692147

Epoch: 159| Step: 0
Training loss: 0.5875039587496226
Validation loss: 2.9940208482434776

Epoch: 6| Step: 1
Training loss: 0.7822932335185594
Validation loss: 2.976917796318877

Epoch: 6| Step: 2
Training loss: 0.48360575844394516
Validation loss: 3.0583668929570615

Epoch: 6| Step: 3
Training loss: 1.6576171127073007
Validation loss: 3.039980660594527

Epoch: 6| Step: 4
Training loss: 0.6581278907951488
Validation loss: 3.042352211569686

Epoch: 6| Step: 5
Training loss: 0.574584584897536
Validation loss: 3.0261182835520786

Epoch: 6| Step: 6
Training loss: 0.6137067448587722
Validation loss: 2.989168122773941

Epoch: 6| Step: 7
Training loss: 0.5760152312887531
Validation loss: 3.0442803967110574

Epoch: 6| Step: 8
Training loss: 0.45138671845949474
Validation loss: 3.032593865091066

Epoch: 6| Step: 9
Training loss: 0.8439430439836223
Validation loss: 2.9218798958640466

Epoch: 6| Step: 10
Training loss: 0.6158769914777986
Validation loss: 3.0078149308364095

Epoch: 6| Step: 11
Training loss: 0.6489853440526963
Validation loss: 2.9910610459072258

Epoch: 6| Step: 12
Training loss: 0.6502398066882209
Validation loss: 2.940498431485493

Epoch: 6| Step: 13
Training loss: 0.44630558976637386
Validation loss: 2.974434065751003

Epoch: 160| Step: 0
Training loss: 0.6744831163641757
Validation loss: 2.9383612648481483

Epoch: 6| Step: 1
Training loss: 0.5276686056338021
Validation loss: 2.9717777138666617

Epoch: 6| Step: 2
Training loss: 0.2920251017617753
Validation loss: 3.0125118387287775

Epoch: 6| Step: 3
Training loss: 0.7502809634049444
Validation loss: 3.0115373806698993

Epoch: 6| Step: 4
Training loss: 0.5597814457874448
Validation loss: 3.0173630260192703

Epoch: 6| Step: 5
Training loss: 0.5245027378345378
Validation loss: 3.048577848430157

Epoch: 6| Step: 6
Training loss: 0.4872306201734961
Validation loss: 2.9898650848501984

Epoch: 6| Step: 7
Training loss: 0.5566846595880997
Validation loss: 3.0346076171635255

Epoch: 6| Step: 8
Training loss: 0.7971008952975076
Validation loss: 2.90684425950704

Epoch: 6| Step: 9
Training loss: 0.5804903511556461
Validation loss: 2.939813136024919

Epoch: 6| Step: 10
Training loss: 1.5951194863123588
Validation loss: 2.918216053101892

Epoch: 6| Step: 11
Training loss: 0.6288233163303549
Validation loss: 2.974803201059214

Epoch: 6| Step: 12
Training loss: 1.1853991546856972
Validation loss: 2.9717873679049225

Epoch: 6| Step: 13
Training loss: 0.6016363123407408
Validation loss: 3.0211719630070406

Epoch: 161| Step: 0
Training loss: 0.8418921750815249
Validation loss: 3.059420217790982

Epoch: 6| Step: 1
Training loss: 0.6932956720020929
Validation loss: 3.1954408602748505

Epoch: 6| Step: 2
Training loss: 0.5949434533216573
Validation loss: 3.1599699074684495

Epoch: 6| Step: 3
Training loss: 0.8399798970428195
Validation loss: 3.137634751667151

Epoch: 6| Step: 4
Training loss: 0.6348545657716952
Validation loss: 3.0480153093696116

Epoch: 6| Step: 5
Training loss: 0.5307253603163901
Validation loss: 3.002930759336699

Epoch: 6| Step: 6
Training loss: 0.5540154375032458
Validation loss: 2.920789003421252

Epoch: 6| Step: 7
Training loss: 0.6338740969188639
Validation loss: 2.996468372622992

Epoch: 6| Step: 8
Training loss: 1.5392270072891334
Validation loss: 2.949775693738692

Epoch: 6| Step: 9
Training loss: 0.5974281723550577
Validation loss: 2.9338247019496264

Epoch: 6| Step: 10
Training loss: 0.5874487397983251
Validation loss: 2.9767943765028932

Epoch: 6| Step: 11
Training loss: 0.5721745597588649
Validation loss: 3.0184994506060323

Epoch: 6| Step: 12
Training loss: 0.7419315499121846
Validation loss: 2.9427178486808043

Epoch: 6| Step: 13
Training loss: 0.7488824147109027
Validation loss: 2.923790166349814

Epoch: 162| Step: 0
Training loss: 0.7189019084120288
Validation loss: 2.938402564808562

Epoch: 6| Step: 1
Training loss: 0.7572266978887792
Validation loss: 2.9727953470163575

Epoch: 6| Step: 2
Training loss: 0.52956788842134
Validation loss: 2.957269448177498

Epoch: 6| Step: 3
Training loss: 0.6585551602426207
Validation loss: 2.954249576612153

Epoch: 6| Step: 4
Training loss: 0.9095641408116625
Validation loss: 3.00211753552182

Epoch: 6| Step: 5
Training loss: 0.6475764152917556
Validation loss: 3.0071840496691578

Epoch: 6| Step: 6
Training loss: 0.4754487766128576
Validation loss: 3.111196447708261

Epoch: 6| Step: 7
Training loss: 0.48216167954383066
Validation loss: 3.0259375671935103

Epoch: 6| Step: 8
Training loss: 0.518534399522941
Validation loss: 2.928706609339673

Epoch: 6| Step: 9
Training loss: 0.5257095446728235
Validation loss: 2.964882161423952

Epoch: 6| Step: 10
Training loss: 1.641852655218785
Validation loss: 2.9227982828569483

Epoch: 6| Step: 11
Training loss: 0.73528610687941
Validation loss: 2.849779730087021

Epoch: 6| Step: 12
Training loss: 0.5857908701214837
Validation loss: 2.8589402443261815

Epoch: 6| Step: 13
Training loss: 0.5509978335228921
Validation loss: 2.9379168005065788

Epoch: 163| Step: 0
Training loss: 0.5182897318300381
Validation loss: 3.011623672983489

Epoch: 6| Step: 1
Training loss: 0.6500571830978792
Validation loss: 3.0152594125677363

Epoch: 6| Step: 2
Training loss: 0.4322364802543521
Validation loss: 3.0555537980007164

Epoch: 6| Step: 3
Training loss: 0.5784554181654602
Validation loss: 3.0336604022362477

Epoch: 6| Step: 4
Training loss: 0.5640508676951541
Validation loss: 3.0937499486236053

Epoch: 6| Step: 5
Training loss: 0.44046148959289516
Validation loss: 3.026045943151572

Epoch: 6| Step: 6
Training loss: 0.5828380497299902
Validation loss: 2.9964027958268

Epoch: 6| Step: 7
Training loss: 0.8159482848712224
Validation loss: 3.017395646093108

Epoch: 6| Step: 8
Training loss: 0.7675679524065504
Validation loss: 2.9591698784588294

Epoch: 6| Step: 9
Training loss: 1.4569016467995586
Validation loss: 3.0634892611067635

Epoch: 6| Step: 10
Training loss: 0.4704577015897389
Validation loss: 3.06987756134978

Epoch: 6| Step: 11
Training loss: 0.4916577894680978
Validation loss: 2.958525091770915

Epoch: 6| Step: 12
Training loss: 0.5398350307792804
Validation loss: 2.911815318887722

Epoch: 6| Step: 13
Training loss: 0.7633827227921257
Validation loss: 3.08521801250862

Epoch: 164| Step: 0
Training loss: 0.6413066772785482
Validation loss: 3.0617930446188515

Epoch: 6| Step: 1
Training loss: 0.4928374464727518
Validation loss: 3.0234466473739205

Epoch: 6| Step: 2
Training loss: 0.703860301085639
Validation loss: 2.9615653252280385

Epoch: 6| Step: 3
Training loss: 0.5138879183883209
Validation loss: 2.9961668003134094

Epoch: 6| Step: 4
Training loss: 0.6578504030448373
Validation loss: 3.0829371292281387

Epoch: 6| Step: 5
Training loss: 0.41575711237225205
Validation loss: 2.935301803677136

Epoch: 6| Step: 6
Training loss: 0.40427042925305884
Validation loss: 2.994011610967172

Epoch: 6| Step: 7
Training loss: 0.523597408180583
Validation loss: 3.0161593265239315

Epoch: 6| Step: 8
Training loss: 0.6380779059178733
Validation loss: 3.0397534079465793

Epoch: 6| Step: 9
Training loss: 0.4779281123563675
Validation loss: 3.0084150231031805

Epoch: 6| Step: 10
Training loss: 0.8933501462872551
Validation loss: 2.987099035108897

Epoch: 6| Step: 11
Training loss: 0.5650365645468463
Validation loss: 2.937164341572516

Epoch: 6| Step: 12
Training loss: 0.7618488689694862
Validation loss: 2.9272498675086878

Epoch: 6| Step: 13
Training loss: 1.574254870887746
Validation loss: 3.0174621230526513

Epoch: 165| Step: 0
Training loss: 1.4880571171555332
Validation loss: 2.984273605887768

Epoch: 6| Step: 1
Training loss: 0.6034035192766947
Validation loss: 2.9731986327586406

Epoch: 6| Step: 2
Training loss: 0.5495742396204127
Validation loss: 2.978962288806371

Epoch: 6| Step: 3
Training loss: 0.5966058613608483
Validation loss: 3.0738876015774803

Epoch: 6| Step: 4
Training loss: 0.7176626106908879
Validation loss: 2.97449180419104

Epoch: 6| Step: 5
Training loss: 0.4518400916390657
Validation loss: 2.9673626652995306

Epoch: 6| Step: 6
Training loss: 0.8375960679254353
Validation loss: 2.968887225543281

Epoch: 6| Step: 7
Training loss: 0.5777443328473834
Validation loss: 3.0267437871554823

Epoch: 6| Step: 8
Training loss: 0.6951436255610471
Validation loss: 2.94152880409529

Epoch: 6| Step: 9
Training loss: 0.5305324645396179
Validation loss: 2.9271905863560232

Epoch: 6| Step: 10
Training loss: 0.7005636611004533
Validation loss: 2.8308667965688126

Epoch: 6| Step: 11
Training loss: 0.760101283439433
Validation loss: 2.898817368229422

Epoch: 6| Step: 12
Training loss: 0.6849895069961468
Validation loss: 2.961834130118896

Epoch: 6| Step: 13
Training loss: 0.5638473586535865
Validation loss: 2.908137634783337

Epoch: 166| Step: 0
Training loss: 0.5389047474783515
Validation loss: 3.0047548812529064

Epoch: 6| Step: 1
Training loss: 0.503113559332193
Validation loss: 3.020401526972865

Epoch: 6| Step: 2
Training loss: 0.9079644658702007
Validation loss: 3.119710756673927

Epoch: 6| Step: 3
Training loss: 0.6102030581056026
Validation loss: 3.0299617743520173

Epoch: 6| Step: 4
Training loss: 0.6623882505348081
Validation loss: 3.04154762052521

Epoch: 6| Step: 5
Training loss: 0.7140261450930665
Validation loss: 3.0821563476135077

Epoch: 6| Step: 6
Training loss: 0.7931422903402234
Validation loss: 2.9902458165782697

Epoch: 6| Step: 7
Training loss: 0.6216037983165836
Validation loss: 2.9577245130582512

Epoch: 6| Step: 8
Training loss: 1.5166694738900053
Validation loss: 2.972810598368995

Epoch: 6| Step: 9
Training loss: 0.5249481890862177
Validation loss: 2.9486992317369043

Epoch: 6| Step: 10
Training loss: 0.5858493484308523
Validation loss: 2.9574602253491933

Epoch: 6| Step: 11
Training loss: 0.6145245771824162
Validation loss: 3.0034215277262755

Epoch: 6| Step: 12
Training loss: 0.7214676851449866
Validation loss: 2.885127129929865

Epoch: 6| Step: 13
Training loss: 0.45530956751730645
Validation loss: 2.9443301342621773

Epoch: 167| Step: 0
Training loss: 0.38512210501152605
Validation loss: 2.995584404002615

Epoch: 6| Step: 1
Training loss: 0.7845880530632897
Validation loss: 3.058527881210237

Epoch: 6| Step: 2
Training loss: 1.492496158971908
Validation loss: 3.1278959715716574

Epoch: 6| Step: 3
Training loss: 0.4981735218065026
Validation loss: 3.1354003517174203

Epoch: 6| Step: 4
Training loss: 0.5431798071912916
Validation loss: 3.100723236328124

Epoch: 6| Step: 5
Training loss: 1.0511315765084397
Validation loss: 3.1502192703506937

Epoch: 6| Step: 6
Training loss: 0.7086311910846342
Validation loss: 2.978194622815095

Epoch: 6| Step: 7
Training loss: 0.60710489030143
Validation loss: 2.961519732639949

Epoch: 6| Step: 8
Training loss: 0.5763138935472307
Validation loss: 2.984401389865801

Epoch: 6| Step: 9
Training loss: 0.5958174548889952
Validation loss: 2.9748103006506277

Epoch: 6| Step: 10
Training loss: 0.592368979312964
Validation loss: 2.9016078188795653

Epoch: 6| Step: 11
Training loss: 0.6375772737904735
Validation loss: 2.899997603207179

Epoch: 6| Step: 12
Training loss: 0.38596316418278515
Validation loss: 2.886066106613246

Epoch: 6| Step: 13
Training loss: 0.5946994518496237
Validation loss: 2.9759054585175697

Epoch: 168| Step: 0
Training loss: 0.4921716203095803
Validation loss: 2.996578755883788

Epoch: 6| Step: 1
Training loss: 0.5048484274040362
Validation loss: 2.931409717863641

Epoch: 6| Step: 2
Training loss: 0.8937187669538542
Validation loss: 2.9486295738925934

Epoch: 6| Step: 3
Training loss: 0.5892330317459562
Validation loss: 3.028958414642174

Epoch: 6| Step: 4
Training loss: 0.4350341036461628
Validation loss: 2.9934105560548194

Epoch: 6| Step: 5
Training loss: 0.6922646490291857
Validation loss: 2.9328531751892752

Epoch: 6| Step: 6
Training loss: 0.4825077057751835
Validation loss: 2.94783873617914

Epoch: 6| Step: 7
Training loss: 0.5277071230704184
Validation loss: 2.984120223269748

Epoch: 6| Step: 8
Training loss: 0.5995608133041593
Validation loss: 2.9734750857226993

Epoch: 6| Step: 9
Training loss: 0.45051578195492625
Validation loss: 3.0088547391243265

Epoch: 6| Step: 10
Training loss: 1.5890208371082364
Validation loss: 3.0166576244858025

Epoch: 6| Step: 11
Training loss: 0.7013349635625913
Validation loss: 3.02268386372034

Epoch: 6| Step: 12
Training loss: 0.5421577269544849
Validation loss: 3.124675911946337

Epoch: 6| Step: 13
Training loss: 0.5802953037390756
Validation loss: 3.01297530280254

Epoch: 169| Step: 0
Training loss: 0.6711892465273342
Validation loss: 3.0562983279577494

Epoch: 6| Step: 1
Training loss: 0.5459511719483662
Validation loss: 2.9562699729239355

Epoch: 6| Step: 2
Training loss: 0.43190991731144796
Validation loss: 3.0172742902592575

Epoch: 6| Step: 3
Training loss: 0.813567121028561
Validation loss: 3.07679416397141

Epoch: 6| Step: 4
Training loss: 0.48428194628845955
Validation loss: 3.0017781948132547

Epoch: 6| Step: 5
Training loss: 0.47367205899634696
Validation loss: 2.9398864764615324

Epoch: 6| Step: 6
Training loss: 0.6541365925341002
Validation loss: 2.9604905595534943

Epoch: 6| Step: 7
Training loss: 0.6577775977654612
Validation loss: 2.9097663908413014

Epoch: 6| Step: 8
Training loss: 0.5147821589257928
Validation loss: 2.966178784453932

Epoch: 6| Step: 9
Training loss: 0.4638219550314951
Validation loss: 3.040731708762124

Epoch: 6| Step: 10
Training loss: 0.5467873639324533
Validation loss: 3.1059738931936307

Epoch: 6| Step: 11
Training loss: 0.5974876564937549
Validation loss: 3.016481254914374

Epoch: 6| Step: 12
Training loss: 0.3545011408912583
Validation loss: 2.994214081283072

Epoch: 6| Step: 13
Training loss: 1.4603067760326778
Validation loss: 3.0596506916084447

Epoch: 170| Step: 0
Training loss: 0.4804778214505441
Validation loss: 3.078493473828579

Epoch: 6| Step: 1
Training loss: 0.3778802607741435
Validation loss: 3.031462180193502

Epoch: 6| Step: 2
Training loss: 0.5230726992077331
Validation loss: 3.1738574342597015

Epoch: 6| Step: 3
Training loss: 0.5733187622706406
Validation loss: 3.046283397134072

Epoch: 6| Step: 4
Training loss: 0.7240335073251888
Validation loss: 2.9927687648926002

Epoch: 6| Step: 5
Training loss: 0.6106609079351102
Validation loss: 3.00959005303768

Epoch: 6| Step: 6
Training loss: 0.5239611042270489
Validation loss: 3.0536417231997572

Epoch: 6| Step: 7
Training loss: 0.8313730349588465
Validation loss: 2.9788467039780997

Epoch: 6| Step: 8
Training loss: 1.4669009805401299
Validation loss: 3.006529061100068

Epoch: 6| Step: 9
Training loss: 0.42158083019743825
Validation loss: 3.003640614948179

Epoch: 6| Step: 10
Training loss: 0.5881767210478902
Validation loss: 2.99400461663124

Epoch: 6| Step: 11
Training loss: 0.665674787996493
Validation loss: 2.97238839705955

Epoch: 6| Step: 12
Training loss: 0.4937630367972324
Validation loss: 3.0189118862512463

Epoch: 6| Step: 13
Training loss: 0.5701135784896154
Validation loss: 3.036391063924347

Epoch: 171| Step: 0
Training loss: 1.5287551797450003
Validation loss: 2.9642691811490636

Epoch: 6| Step: 1
Training loss: 0.43479409617299836
Validation loss: 2.941317208653425

Epoch: 6| Step: 2
Training loss: 0.3779670440584867
Validation loss: 2.9537755259776226

Epoch: 6| Step: 3
Training loss: 0.6624269877093741
Validation loss: 2.983446932251286

Epoch: 6| Step: 4
Training loss: 0.9355623566495321
Validation loss: 2.957000799454826

Epoch: 6| Step: 5
Training loss: 0.45710587503608824
Validation loss: 2.9975123953118894

Epoch: 6| Step: 6
Training loss: 0.5986850336145288
Validation loss: 3.021048549132775

Epoch: 6| Step: 7
Training loss: 0.574809749890769
Validation loss: 2.999009896184356

Epoch: 6| Step: 8
Training loss: 0.5387327318898067
Validation loss: 3.0208784341185826

Epoch: 6| Step: 9
Training loss: 0.43145665179332787
Validation loss: 2.9937690691781946

Epoch: 6| Step: 10
Training loss: 0.7418757536835284
Validation loss: 3.040744293266916

Epoch: 6| Step: 11
Training loss: 0.5160667088048116
Validation loss: 3.0873448635359106

Epoch: 6| Step: 12
Training loss: 0.5033346675177233
Validation loss: 3.0631723379542755

Epoch: 6| Step: 13
Training loss: 0.5489808545448273
Validation loss: 3.1129717639112684

Epoch: 172| Step: 0
Training loss: 0.8876358196940515
Validation loss: 3.0621788284672604

Epoch: 6| Step: 1
Training loss: 1.4731201736312869
Validation loss: 2.9963866964707653

Epoch: 6| Step: 2
Training loss: 0.4728628920624204
Validation loss: 3.0199425184072033

Epoch: 6| Step: 3
Training loss: 0.5400004588672667
Validation loss: 3.0427743950062482

Epoch: 6| Step: 4
Training loss: 0.6691190173863124
Validation loss: 3.0761110717577163

Epoch: 6| Step: 5
Training loss: 0.8082555533541932
Validation loss: 3.132374099409606

Epoch: 6| Step: 6
Training loss: 0.5016578072761552
Validation loss: 3.048108547287007

Epoch: 6| Step: 7
Training loss: 0.5509799301331221
Validation loss: 3.032748857892023

Epoch: 6| Step: 8
Training loss: 0.5535598898709057
Validation loss: 3.0133733166796106

Epoch: 6| Step: 9
Training loss: 0.528872893731132
Validation loss: 3.062925451919341

Epoch: 6| Step: 10
Training loss: 0.6475430949977793
Validation loss: 2.9584779077224783

Epoch: 6| Step: 11
Training loss: 0.5659157042832444
Validation loss: 2.9781237601897734

Epoch: 6| Step: 12
Training loss: 0.6452842244379857
Validation loss: 2.9586307394050557

Epoch: 6| Step: 13
Training loss: 0.5901072841830167
Validation loss: 3.095378305941441

Epoch: 173| Step: 0
Training loss: 0.45962020985750385
Validation loss: 2.986979255354774

Epoch: 6| Step: 1
Training loss: 0.7714569086907611
Validation loss: 3.085970000405729

Epoch: 6| Step: 2
Training loss: 0.6039282613397208
Validation loss: 3.0312986337227628

Epoch: 6| Step: 3
Training loss: 0.46615687593419464
Validation loss: 3.075270140549038

Epoch: 6| Step: 4
Training loss: 0.5721778151287843
Validation loss: 3.115580451261674

Epoch: 6| Step: 5
Training loss: 0.42830964165166174
Validation loss: 3.0424489404494373

Epoch: 6| Step: 6
Training loss: 0.5232924359989208
Validation loss: 3.101232990021948

Epoch: 6| Step: 7
Training loss: 0.6477625907961045
Validation loss: 3.01898010672162

Epoch: 6| Step: 8
Training loss: 0.7578255563771358
Validation loss: 3.0126657675145023

Epoch: 6| Step: 9
Training loss: 1.4470683386798608
Validation loss: 2.997406315170684

Epoch: 6| Step: 10
Training loss: 0.7821984446754686
Validation loss: 3.0220311563376523

Epoch: 6| Step: 11
Training loss: 0.4008505993605324
Validation loss: 3.073108399869823

Epoch: 6| Step: 12
Training loss: 0.39705438464671294
Validation loss: 3.0597533280756877

Epoch: 6| Step: 13
Training loss: 0.6780459872153279
Validation loss: 2.9766394337401203

Epoch: 174| Step: 0
Training loss: 1.5458472334381617
Validation loss: 3.0131526556607295

Epoch: 6| Step: 1
Training loss: 0.46940795498296994
Validation loss: 3.05649411111351

Epoch: 6| Step: 2
Training loss: 0.6350367979215914
Validation loss: 3.0855229867925713

Epoch: 6| Step: 3
Training loss: 0.9357105024431845
Validation loss: 3.119592387479783

Epoch: 6| Step: 4
Training loss: 0.4523107183910755
Validation loss: 3.054725536164913

Epoch: 6| Step: 5
Training loss: 0.5426769982173798
Validation loss: 3.077796983104267

Epoch: 6| Step: 6
Training loss: 0.46024899867610386
Validation loss: 3.065088605341576

Epoch: 6| Step: 7
Training loss: 0.4019436189140947
Validation loss: 2.975444840851295

Epoch: 6| Step: 8
Training loss: 0.5773642664091492
Validation loss: 2.971275366435607

Epoch: 6| Step: 9
Training loss: 0.7706516842271219
Validation loss: 2.944578273199007

Epoch: 6| Step: 10
Training loss: 0.5464105541222264
Validation loss: 2.9752731133766743

Epoch: 6| Step: 11
Training loss: 0.3675866291225867
Validation loss: 3.007414675078548

Epoch: 6| Step: 12
Training loss: 0.5084396890734983
Validation loss: 2.963150391898003

Epoch: 6| Step: 13
Training loss: 0.4874392917931263
Validation loss: 2.995139343425212

Epoch: 175| Step: 0
Training loss: 0.665105875162924
Validation loss: 3.0715912800102054

Epoch: 6| Step: 1
Training loss: 0.6240406541434284
Validation loss: 2.930476890179088

Epoch: 6| Step: 2
Training loss: 0.6011512638794864
Validation loss: 2.918848043969258

Epoch: 6| Step: 3
Training loss: 0.38754823138419475
Validation loss: 3.0016922284114056

Epoch: 6| Step: 4
Training loss: 0.600339960108643
Validation loss: 2.9007044698367275

Epoch: 6| Step: 5
Training loss: 0.5563101607375188
Validation loss: 2.8675705933576965

Epoch: 6| Step: 6
Training loss: 0.9277889837957545
Validation loss: 2.9325829740093745

Epoch: 6| Step: 7
Training loss: 1.4733980369744313
Validation loss: 2.9124640272917803

Epoch: 6| Step: 8
Training loss: 0.5294953709545
Validation loss: 2.959370113531239

Epoch: 6| Step: 9
Training loss: 0.5951858275603423
Validation loss: 2.9755745730941023

Epoch: 6| Step: 10
Training loss: 0.4200616293490763
Validation loss: 3.0341929932789466

Epoch: 6| Step: 11
Training loss: 0.6385859860404913
Validation loss: 3.147877431170982

Epoch: 6| Step: 12
Training loss: 0.6596453343030014
Validation loss: 3.144872586065396

Epoch: 6| Step: 13
Training loss: 0.669699762742079
Validation loss: 3.11942614333628

Epoch: 176| Step: 0
Training loss: 0.6262962013227491
Validation loss: 3.078718654231901

Epoch: 6| Step: 1
Training loss: 0.8741110645886992
Validation loss: 3.0170013370302327

Epoch: 6| Step: 2
Training loss: 0.5533136897257974
Validation loss: 3.0263872633189464

Epoch: 6| Step: 3
Training loss: 0.47550966877137446
Validation loss: 3.0193225941485635

Epoch: 6| Step: 4
Training loss: 0.43053276846003835
Validation loss: 2.974854894780447

Epoch: 6| Step: 5
Training loss: 0.4094433720108945
Validation loss: 3.035924028048333

Epoch: 6| Step: 6
Training loss: 0.34871903323030323
Validation loss: 3.087390438509158

Epoch: 6| Step: 7
Training loss: 0.6383490256811741
Validation loss: 3.018313249015303

Epoch: 6| Step: 8
Training loss: 0.33046628486669793
Validation loss: 3.1111448353309514

Epoch: 6| Step: 9
Training loss: 0.45494311708110535
Validation loss: 3.0165648502920432

Epoch: 6| Step: 10
Training loss: 0.5928831800153476
Validation loss: 2.9974309729740467

Epoch: 6| Step: 11
Training loss: 1.4847495158705828
Validation loss: 2.9853672954330692

Epoch: 6| Step: 12
Training loss: 0.5407175833746768
Validation loss: 3.043685848178845

Epoch: 6| Step: 13
Training loss: 0.5050500707070573
Validation loss: 3.040731682626027

Epoch: 177| Step: 0
Training loss: 0.6842611052615789
Validation loss: 3.0407802039038887

Epoch: 6| Step: 1
Training loss: 0.35896076294926726
Validation loss: 3.079255098321383

Epoch: 6| Step: 2
Training loss: 0.43430129736377826
Validation loss: 3.0123658958966644

Epoch: 6| Step: 3
Training loss: 0.6020478111620777
Validation loss: 3.038187379859098

Epoch: 6| Step: 4
Training loss: 0.5713764873678059
Validation loss: 2.9062636316998365

Epoch: 6| Step: 5
Training loss: 0.37141611252249046
Validation loss: 2.979344887282198

Epoch: 6| Step: 6
Training loss: 0.8647693219503467
Validation loss: 2.9706680794044207

Epoch: 6| Step: 7
Training loss: 0.6482062099641307
Validation loss: 3.000358387944786

Epoch: 6| Step: 8
Training loss: 1.5149059359617056
Validation loss: 2.892326981148627

Epoch: 6| Step: 9
Training loss: 0.46239402948818137
Validation loss: 3.0218646338941526

Epoch: 6| Step: 10
Training loss: 0.45375963689485554
Validation loss: 2.9826139010615136

Epoch: 6| Step: 11
Training loss: 0.4713074852464554
Validation loss: 3.0537328504803534

Epoch: 6| Step: 12
Training loss: 0.6972846020592459
Validation loss: 2.9838351948186514

Epoch: 6| Step: 13
Training loss: 0.5505242255282906
Validation loss: 3.0048212543670556

Epoch: 178| Step: 0
Training loss: 0.6906863198308654
Validation loss: 2.999734032285208

Epoch: 6| Step: 1
Training loss: 0.8245227126676584
Validation loss: 3.038690513197007

Epoch: 6| Step: 2
Training loss: 0.41660322858760734
Validation loss: 2.928541605329019

Epoch: 6| Step: 3
Training loss: 0.6804447778624589
Validation loss: 2.9684967200670354

Epoch: 6| Step: 4
Training loss: 0.43106304552957164
Validation loss: 2.992518075555373

Epoch: 6| Step: 5
Training loss: 0.5633787602480472
Validation loss: 2.9801901924214955

Epoch: 6| Step: 6
Training loss: 0.4599955195488623
Validation loss: 2.9425696326232464

Epoch: 6| Step: 7
Training loss: 0.4454372298249343
Validation loss: 3.0000502396721367

Epoch: 6| Step: 8
Training loss: 0.36024357694820475
Validation loss: 3.108137411602498

Epoch: 6| Step: 9
Training loss: 0.5961091455793768
Validation loss: 3.034641308921847

Epoch: 6| Step: 10
Training loss: 0.43430889710696674
Validation loss: 3.0599478253215335

Epoch: 6| Step: 11
Training loss: 1.449362775941058
Validation loss: 3.0690207833897403

Epoch: 6| Step: 12
Training loss: 0.4018162167036503
Validation loss: 3.019344559294095

Epoch: 6| Step: 13
Training loss: 0.4367615052723774
Validation loss: 3.105901276159424

Epoch: 179| Step: 0
Training loss: 0.6335963821826827
Validation loss: 3.185143266466913

Epoch: 6| Step: 1
Training loss: 0.5595685815701168
Validation loss: 3.185133504330203

Epoch: 6| Step: 2
Training loss: 0.3859077967282905
Validation loss: 3.0707815004595584

Epoch: 6| Step: 3
Training loss: 1.4411266024618101
Validation loss: 3.0655037169294213

Epoch: 6| Step: 4
Training loss: 0.9530089886212424
Validation loss: 3.0102693110286087

Epoch: 6| Step: 5
Training loss: 0.4708764164829645
Validation loss: 2.9713839307403713

Epoch: 6| Step: 6
Training loss: 0.4915844689641858
Validation loss: 2.9875088892422723

Epoch: 6| Step: 7
Training loss: 0.640192490627981
Validation loss: 2.9634791112285552

Epoch: 6| Step: 8
Training loss: 0.6734408827694504
Validation loss: 3.0142016963876093

Epoch: 6| Step: 9
Training loss: 0.39903573396756364
Validation loss: 3.0339977094012545

Epoch: 6| Step: 10
Training loss: 0.3923896033239152
Validation loss: 3.028017883715778

Epoch: 6| Step: 11
Training loss: 0.5215218634114137
Validation loss: 3.103588387476796

Epoch: 6| Step: 12
Training loss: 0.49963097067083934
Validation loss: 3.067479853171399

Epoch: 6| Step: 13
Training loss: 0.5878769882496219
Validation loss: 3.1378119350352174

Epoch: 180| Step: 0
Training loss: 0.4578610248041913
Validation loss: 2.960602405009029

Epoch: 6| Step: 1
Training loss: 0.43014228335319343
Validation loss: 3.0814712460457763

Epoch: 6| Step: 2
Training loss: 0.4118471441270169
Validation loss: 3.0172850827636473

Epoch: 6| Step: 3
Training loss: 0.7672773941733035
Validation loss: 3.067859630815267

Epoch: 6| Step: 4
Training loss: 0.5703847395203101
Validation loss: 2.997836021273537

Epoch: 6| Step: 5
Training loss: 0.7101217347539881
Validation loss: 3.035939210952431

Epoch: 6| Step: 6
Training loss: 0.4597430837026985
Validation loss: 3.002300387143893

Epoch: 6| Step: 7
Training loss: 0.4921193151322481
Validation loss: 3.065566117514789

Epoch: 6| Step: 8
Training loss: 1.365468934174043
Validation loss: 3.010726375994066

Epoch: 6| Step: 9
Training loss: 0.5277451859276752
Validation loss: 3.016801186367143

Epoch: 6| Step: 10
Training loss: 0.5230665173307363
Validation loss: 3.046633014687873

Epoch: 6| Step: 11
Training loss: 0.4803354031743005
Validation loss: 3.1092653111418764

Epoch: 6| Step: 12
Training loss: 0.6722227128301184
Validation loss: 3.059812014899483

Epoch: 6| Step: 13
Training loss: 0.5676113069080178
Validation loss: 3.042866918568181

Epoch: 181| Step: 0
Training loss: 0.5139754526013572
Validation loss: 3.0219714596753637

Epoch: 6| Step: 1
Training loss: 0.4418862695079722
Validation loss: 2.9640759934470298

Epoch: 6| Step: 2
Training loss: 0.769872676800646
Validation loss: 3.03040359583067

Epoch: 6| Step: 3
Training loss: 0.3587711070161786
Validation loss: 2.9868775704934136

Epoch: 6| Step: 4
Training loss: 0.8309750726130847
Validation loss: 2.9598757837410674

Epoch: 6| Step: 5
Training loss: 0.5301173421229729
Validation loss: 2.991087164224038

Epoch: 6| Step: 6
Training loss: 0.4731067528223183
Validation loss: 3.0227155061581

Epoch: 6| Step: 7
Training loss: 0.7432500360914235
Validation loss: 2.981742216858565

Epoch: 6| Step: 8
Training loss: 0.33481452344404383
Validation loss: 2.997148628989076

Epoch: 6| Step: 9
Training loss: 1.4254029490637752
Validation loss: 3.1358801075730343

Epoch: 6| Step: 10
Training loss: 0.46475161112095165
Validation loss: 3.103892388910158

Epoch: 6| Step: 11
Training loss: 0.46703980321572247
Validation loss: 3.042018103654987

Epoch: 6| Step: 12
Training loss: 0.38979417183684534
Validation loss: 3.1073782306565705

Epoch: 6| Step: 13
Training loss: 0.4511580196746745
Validation loss: 3.0422052315964403

Epoch: 182| Step: 0
Training loss: 0.428966576341252
Validation loss: 2.98971646817706

Epoch: 6| Step: 1
Training loss: 0.4935720889756637
Validation loss: 3.010864268535617

Epoch: 6| Step: 2
Training loss: 0.6078654935431925
Validation loss: 2.9951244313115453

Epoch: 6| Step: 3
Training loss: 0.5608886049260129
Validation loss: 2.984107533131505

Epoch: 6| Step: 4
Training loss: 0.5541976323714217
Validation loss: 3.0466789639000105

Epoch: 6| Step: 5
Training loss: 0.437685790803114
Validation loss: 3.028054588294465

Epoch: 6| Step: 6
Training loss: 1.430664562446585
Validation loss: 3.079372056572918

Epoch: 6| Step: 7
Training loss: 0.5535422308644597
Validation loss: 3.0654192135718907

Epoch: 6| Step: 8
Training loss: 0.9378919735683928
Validation loss: 3.060555703727162

Epoch: 6| Step: 9
Training loss: 0.49749524852266436
Validation loss: 3.004349826691146

Epoch: 6| Step: 10
Training loss: 0.5374859963300583
Validation loss: 3.0533164769613856

Epoch: 6| Step: 11
Training loss: 0.3976313719995893
Validation loss: 3.050773421964155

Epoch: 6| Step: 12
Training loss: 0.47291705919941257
Validation loss: 3.03327863525148

Epoch: 6| Step: 13
Training loss: 0.5106173010704453
Validation loss: 3.0042387104963506

Epoch: 183| Step: 0
Training loss: 0.6573427276204408
Validation loss: 2.9791678759876987

Epoch: 6| Step: 1
Training loss: 0.7868703853238557
Validation loss: 3.030147771578732

Epoch: 6| Step: 2
Training loss: 0.47094405407005824
Validation loss: 3.0466307582937233

Epoch: 6| Step: 3
Training loss: 0.538007533181994
Validation loss: 3.0585409511460266

Epoch: 6| Step: 4
Training loss: 0.5442148085480747
Validation loss: 3.093847716358483

Epoch: 6| Step: 5
Training loss: 0.4588710563862223
Validation loss: 3.086966080002549

Epoch: 6| Step: 6
Training loss: 0.5013047420546801
Validation loss: 3.011986838884041

Epoch: 6| Step: 7
Training loss: 0.3532487483640231
Validation loss: 3.077129351444631

Epoch: 6| Step: 8
Training loss: 0.4410582664560088
Validation loss: 3.0911068655427174

Epoch: 6| Step: 9
Training loss: 0.5741600992780379
Validation loss: 2.981171744630435

Epoch: 6| Step: 10
Training loss: 0.5556338122669917
Validation loss: 2.964770236169846

Epoch: 6| Step: 11
Training loss: 0.37537857655572127
Validation loss: 3.0575250128229507

Epoch: 6| Step: 12
Training loss: 0.5788258093829953
Validation loss: 3.0133749122690823

Epoch: 6| Step: 13
Training loss: 1.4740559126654391
Validation loss: 3.020504707789519

Epoch: 184| Step: 0
Training loss: 0.6871418887237192
Validation loss: 2.9596233420818687

Epoch: 6| Step: 1
Training loss: 0.4744189158882783
Validation loss: 2.9950415907802244

Epoch: 6| Step: 2
Training loss: 0.4721245415331589
Validation loss: 3.051752578120511

Epoch: 6| Step: 3
Training loss: 0.5248795757235065
Validation loss: 2.9762732364410223

Epoch: 6| Step: 4
Training loss: 1.3377586578106087
Validation loss: 3.0285782198302837

Epoch: 6| Step: 5
Training loss: 0.7992621550794625
Validation loss: 3.078378386161789

Epoch: 6| Step: 6
Training loss: 0.542170919555079
Validation loss: 3.034032298521973

Epoch: 6| Step: 7
Training loss: 0.6228381438079323
Validation loss: 3.0702794196989394

Epoch: 6| Step: 8
Training loss: 0.5603972976438345
Validation loss: 3.011403503939251

Epoch: 6| Step: 9
Training loss: 0.5501864854065938
Validation loss: 3.036956017844898

Epoch: 6| Step: 10
Training loss: 0.3792065678900397
Validation loss: 3.0539798681182266

Epoch: 6| Step: 11
Training loss: 0.6232408323306106
Validation loss: 3.0032355159519386

Epoch: 6| Step: 12
Training loss: 0.5257513233300577
Validation loss: 3.025485899812154

Epoch: 6| Step: 13
Training loss: 0.5555226124162105
Validation loss: 3.0026771071155394

Epoch: 185| Step: 0
Training loss: 0.5763323285669747
Validation loss: 3.0175438608407292

Epoch: 6| Step: 1
Training loss: 0.5858853634844919
Validation loss: 3.0606198410687635

Epoch: 6| Step: 2
Training loss: 0.35684743694615917
Validation loss: 3.1277432925587614

Epoch: 6| Step: 3
Training loss: 1.3805798108643557
Validation loss: 3.1263684519001824

Epoch: 6| Step: 4
Training loss: 0.5511466903934605
Validation loss: 3.130659344891505

Epoch: 6| Step: 5
Training loss: 0.4978031684158925
Validation loss: 3.107666415205697

Epoch: 6| Step: 6
Training loss: 0.6481844626640505
Validation loss: 3.0720939612522753

Epoch: 6| Step: 7
Training loss: 0.8299160428844592
Validation loss: 3.0589739294047926

Epoch: 6| Step: 8
Training loss: 0.4586483963441276
Validation loss: 2.9845494191061865

Epoch: 6| Step: 9
Training loss: 0.47845611202184235
Validation loss: 3.004762815952199

Epoch: 6| Step: 10
Training loss: 0.4440037250480673
Validation loss: 3.0420805679961487

Epoch: 6| Step: 11
Training loss: 0.6828501771705846
Validation loss: 3.0153520028995926

Epoch: 6| Step: 12
Training loss: 0.54587299649321
Validation loss: 3.0202560180077

Epoch: 6| Step: 13
Training loss: 0.4555904140872288
Validation loss: 2.969860953213281

Epoch: 186| Step: 0
Training loss: 0.5407424677863453
Validation loss: 3.1316034103617962

Epoch: 6| Step: 1
Training loss: 1.3736565702703405
Validation loss: 3.134353664499262

Epoch: 6| Step: 2
Training loss: 0.7138063584906781
Validation loss: 3.1642913735581133

Epoch: 6| Step: 3
Training loss: 0.5399965128079598
Validation loss: 3.1003177428709883

Epoch: 6| Step: 4
Training loss: 0.446878924052476
Validation loss: 3.0863340871425256

Epoch: 6| Step: 5
Training loss: 0.47097963307925206
Validation loss: 2.9971154438365013

Epoch: 6| Step: 6
Training loss: 0.8192851581683251
Validation loss: 3.0582340267665153

Epoch: 6| Step: 7
Training loss: 0.3936458131915159
Validation loss: 2.988131437514785

Epoch: 6| Step: 8
Training loss: 0.7928574958515732
Validation loss: 2.99688195740572

Epoch: 6| Step: 9
Training loss: 0.5213561739836878
Validation loss: 3.0225297483500557

Epoch: 6| Step: 10
Training loss: 0.5552047681664185
Validation loss: 3.000227998970559

Epoch: 6| Step: 11
Training loss: 0.3172687619037069
Validation loss: 3.07943564716893

Epoch: 6| Step: 12
Training loss: 0.5679615634216932
Validation loss: 3.081824479058719

Epoch: 6| Step: 13
Training loss: 0.4192074575762291
Validation loss: 3.2015860481444975

Epoch: 187| Step: 0
Training loss: 0.5021428443600165
Validation loss: 3.1349893365340966

Epoch: 6| Step: 1
Training loss: 0.6264781162583448
Validation loss: 3.1418643106744537

Epoch: 6| Step: 2
Training loss: 1.2973035081468256
Validation loss: 3.1263247924301902

Epoch: 6| Step: 3
Training loss: 0.6182995206356889
Validation loss: 3.081926054744706

Epoch: 6| Step: 4
Training loss: 0.4611221202368506
Validation loss: 2.9800183517095795

Epoch: 6| Step: 5
Training loss: 0.5430562339945417
Validation loss: 3.0467147524174067

Epoch: 6| Step: 6
Training loss: 0.5968334792709634
Validation loss: 2.969574194824008

Epoch: 6| Step: 7
Training loss: 0.7304017551319557
Validation loss: 2.993946405072498

Epoch: 6| Step: 8
Training loss: 0.38577646996467296
Validation loss: 2.966073606625954

Epoch: 6| Step: 9
Training loss: 0.3656917706678478
Validation loss: 3.0328733678858244

Epoch: 6| Step: 10
Training loss: 0.4248812025593288
Validation loss: 3.073812791581925

Epoch: 6| Step: 11
Training loss: 0.4886130769455249
Validation loss: 3.0740955656092765

Epoch: 6| Step: 12
Training loss: 0.7758245527123636
Validation loss: 3.044785289951311

Epoch: 6| Step: 13
Training loss: 0.5643357943649993
Validation loss: 3.028451932482296

Epoch: 188| Step: 0
Training loss: 0.5605258206656805
Validation loss: 3.1205542029997257

Epoch: 6| Step: 1
Training loss: 0.47531235990202453
Validation loss: 3.0267640311451385

Epoch: 6| Step: 2
Training loss: 0.46750171072029817
Validation loss: 2.964286433508168

Epoch: 6| Step: 3
Training loss: 0.5278598661608734
Validation loss: 3.101366807223419

Epoch: 6| Step: 4
Training loss: 0.7071655314527263
Validation loss: 3.051347133825575

Epoch: 6| Step: 5
Training loss: 1.3659456553114258
Validation loss: 3.0886401353206083

Epoch: 6| Step: 6
Training loss: 0.6141663985163373
Validation loss: 3.0676188992911837

Epoch: 6| Step: 7
Training loss: 0.5904076514389227
Validation loss: 3.017383517313943

Epoch: 6| Step: 8
Training loss: 0.650540171433277
Validation loss: 3.1072110261000576

Epoch: 6| Step: 9
Training loss: 0.5379056819007908
Validation loss: 3.089670079137361

Epoch: 6| Step: 10
Training loss: 0.40166718346745867
Validation loss: 3.060238606618323

Epoch: 6| Step: 11
Training loss: 0.7539317862973993
Validation loss: 3.0447899881820066

Epoch: 6| Step: 12
Training loss: 0.5077394873142618
Validation loss: 3.0381806834075755

Epoch: 6| Step: 13
Training loss: 0.52067531731795
Validation loss: 3.035879460550754

Epoch: 189| Step: 0
Training loss: 0.6669126047044621
Validation loss: 2.9324060872838085

Epoch: 6| Step: 1
Training loss: 1.3048684457262965
Validation loss: 2.96317300140352

Epoch: 6| Step: 2
Training loss: 0.4912974469128438
Validation loss: 3.0195237883837103

Epoch: 6| Step: 3
Training loss: 0.6817488707367652
Validation loss: 3.0433573574679182

Epoch: 6| Step: 4
Training loss: 0.5477222147135699
Validation loss: 2.9651432145790313

Epoch: 6| Step: 5
Training loss: 0.5496282209623418
Validation loss: 3.028747023348645

Epoch: 6| Step: 6
Training loss: 0.5874762104168867
Validation loss: 3.067109641617131

Epoch: 6| Step: 7
Training loss: 0.4314404191602669
Validation loss: 3.0586664768502736

Epoch: 6| Step: 8
Training loss: 0.5223544859061019
Validation loss: 2.9737598778313545

Epoch: 6| Step: 9
Training loss: 0.465550998593303
Validation loss: 2.983324142171955

Epoch: 6| Step: 10
Training loss: 0.40521787699204315
Validation loss: 2.989403474472605

Epoch: 6| Step: 11
Training loss: 0.33950784678934876
Validation loss: 3.022441387780912

Epoch: 6| Step: 12
Training loss: 0.3753961219345438
Validation loss: 3.07919027158562

Epoch: 6| Step: 13
Training loss: 0.70876920603408
Validation loss: 3.0436786938303886

Epoch: 190| Step: 0
Training loss: 0.3072650407581415
Validation loss: 3.0136710838766785

Epoch: 6| Step: 1
Training loss: 0.29347717673010076
Validation loss: 3.1035813328049136

Epoch: 6| Step: 2
Training loss: 0.5415546472577737
Validation loss: 3.0182932379797975

Epoch: 6| Step: 3
Training loss: 1.361851333055384
Validation loss: 3.1195501235071257

Epoch: 6| Step: 4
Training loss: 0.602688416900143
Validation loss: 3.0355284473692894

Epoch: 6| Step: 5
Training loss: 0.41930020468370466
Validation loss: 3.048853337902318

Epoch: 6| Step: 6
Training loss: 0.39927741886834794
Validation loss: 3.0395778163539995

Epoch: 6| Step: 7
Training loss: 0.7069886336997891
Validation loss: 3.148123095190388

Epoch: 6| Step: 8
Training loss: 0.488186682126463
Validation loss: 3.151281872045553

Epoch: 6| Step: 9
Training loss: 0.5334240522069521
Validation loss: 3.075878117174253

Epoch: 6| Step: 10
Training loss: 0.2556972863835818
Validation loss: 2.9881137377094458

Epoch: 6| Step: 11
Training loss: 0.595296452023125
Validation loss: 2.9786929618698768

Epoch: 6| Step: 12
Training loss: 0.5628070787828502
Validation loss: 3.02323597475428

Epoch: 6| Step: 13
Training loss: 0.6007123612492434
Validation loss: 3.100036963375769

Epoch: 191| Step: 0
Training loss: 0.3165078647534294
Validation loss: 3.0202288757314677

Epoch: 6| Step: 1
Training loss: 0.8199089510890946
Validation loss: 2.9884642567830086

Epoch: 6| Step: 2
Training loss: 0.5386423325546288
Validation loss: 3.0246126977868695

Epoch: 6| Step: 3
Training loss: 0.41462336647257025
Validation loss: 3.087808934867815

Epoch: 6| Step: 4
Training loss: 0.3579624236741297
Validation loss: 3.0195339345981758

Epoch: 6| Step: 5
Training loss: 0.6003562425982871
Validation loss: 3.0675185856752245

Epoch: 6| Step: 6
Training loss: 1.3357366667475974
Validation loss: 2.968240379628702

Epoch: 6| Step: 7
Training loss: 0.36437802210449327
Validation loss: 2.942639879538893

Epoch: 6| Step: 8
Training loss: 0.5008513533967804
Validation loss: 2.9822377645826923

Epoch: 6| Step: 9
Training loss: 0.36373882804179036
Validation loss: 3.0248716043383634

Epoch: 6| Step: 10
Training loss: 0.46587069256968533
Validation loss: 3.0128298044711785

Epoch: 6| Step: 11
Training loss: 0.5531057720829402
Validation loss: 2.9964444097417196

Epoch: 6| Step: 12
Training loss: 0.4791342803818642
Validation loss: 3.024565152106053

Epoch: 6| Step: 13
Training loss: 0.49648905946215866
Validation loss: 2.967035608352877

Epoch: 192| Step: 0
Training loss: 0.2099889248669333
Validation loss: 2.95988046907385

Epoch: 6| Step: 1
Training loss: 0.5261604313501589
Validation loss: 2.9881712118263137

Epoch: 6| Step: 2
Training loss: 1.350745731590597
Validation loss: 3.05349868314898

Epoch: 6| Step: 3
Training loss: 0.402530515710531
Validation loss: 2.971747628366217

Epoch: 6| Step: 4
Training loss: 0.5357375781354329
Validation loss: 3.000714243529971

Epoch: 6| Step: 5
Training loss: 0.5776885421348977
Validation loss: 3.1003343150647886

Epoch: 6| Step: 6
Training loss: 0.40068185030962095
Validation loss: 3.039802036343967

Epoch: 6| Step: 7
Training loss: 0.49953629926385384
Validation loss: 3.073982627166818

Epoch: 6| Step: 8
Training loss: 0.7814936067340413
Validation loss: 3.0346015937238664

Epoch: 6| Step: 9
Training loss: 0.5751996388296948
Validation loss: 3.0399988296155183

Epoch: 6| Step: 10
Training loss: 0.43356489824410144
Validation loss: 3.0658172171264946

Epoch: 6| Step: 11
Training loss: 0.4932880510133841
Validation loss: 3.067182425651686

Epoch: 6| Step: 12
Training loss: 0.4634431366375121
Validation loss: 3.006260022882261

Epoch: 6| Step: 13
Training loss: 0.5559388136781178
Validation loss: 2.9577017409888504

Epoch: 193| Step: 0
Training loss: 0.6200043342807996
Validation loss: 3.0432334592154464

Epoch: 6| Step: 1
Training loss: 0.5389875829855261
Validation loss: 3.102867486109025

Epoch: 6| Step: 2
Training loss: 0.5052939535782167
Validation loss: 3.0744367083556448

Epoch: 6| Step: 3
Training loss: 0.5578724665959278
Validation loss: 3.0671727479880175

Epoch: 6| Step: 4
Training loss: 0.43939495125480166
Validation loss: 3.1389945306883225

Epoch: 6| Step: 5
Training loss: 0.5398270534025658
Validation loss: 3.080827988205568

Epoch: 6| Step: 6
Training loss: 0.4754767948689794
Validation loss: 3.062154114582057

Epoch: 6| Step: 7
Training loss: 0.4693743680093831
Validation loss: 3.0279254838416065

Epoch: 6| Step: 8
Training loss: 1.3271591713803186
Validation loss: 3.0667895164623356

Epoch: 6| Step: 9
Training loss: 0.6064906203196432
Validation loss: 2.959315826350768

Epoch: 6| Step: 10
Training loss: 0.6285997200534693
Validation loss: 3.0238266069396675

Epoch: 6| Step: 11
Training loss: 0.8262767319387481
Validation loss: 2.906338461346555

Epoch: 6| Step: 12
Training loss: 0.4662833481590526
Validation loss: 3.0146579806126623

Epoch: 6| Step: 13
Training loss: 0.6326480698945813
Validation loss: 3.05114116165682

Epoch: 194| Step: 0
Training loss: 0.5409435127757145
Validation loss: 3.0615834921301186

Epoch: 6| Step: 1
Training loss: 0.7565344819242498
Validation loss: 3.1363796052371242

Epoch: 6| Step: 2
Training loss: 0.4359259388528882
Validation loss: 2.9831801014624024

Epoch: 6| Step: 3
Training loss: 0.44643197807647095
Validation loss: 3.070449631906968

Epoch: 6| Step: 4
Training loss: 0.7768683968936254
Validation loss: 3.047462445873417

Epoch: 6| Step: 5
Training loss: 0.5341824212431476
Validation loss: 2.9909616587111594

Epoch: 6| Step: 6
Training loss: 1.294918975136388
Validation loss: 3.01134295660937

Epoch: 6| Step: 7
Training loss: 0.6110909827727378
Validation loss: 3.058567363678788

Epoch: 6| Step: 8
Training loss: 0.39018604410765423
Validation loss: 3.083284497948265

Epoch: 6| Step: 9
Training loss: 0.4364081108799317
Validation loss: 3.1075936714922356

Epoch: 6| Step: 10
Training loss: 0.5923984101679176
Validation loss: 3.1023380261236073

Epoch: 6| Step: 11
Training loss: 0.47046227842483274
Validation loss: 3.0723696378031

Epoch: 6| Step: 12
Training loss: 0.3986823881461149
Validation loss: 3.1271300876348995

Epoch: 6| Step: 13
Training loss: 0.4918717476568825
Validation loss: 3.1070423162153107

Epoch: 195| Step: 0
Training loss: 0.5735146234189459
Validation loss: 3.112312105423548

Epoch: 6| Step: 1
Training loss: 0.5012593502970527
Validation loss: 3.0919997019617513

Epoch: 6| Step: 2
Training loss: 0.5646077244640657
Validation loss: 3.0215818508200702

Epoch: 6| Step: 3
Training loss: 0.3437422079590326
Validation loss: 2.9569786130922755

Epoch: 6| Step: 4
Training loss: 0.5544153002312099
Validation loss: 3.011844340475293

Epoch: 6| Step: 5
Training loss: 0.6010020729479847
Validation loss: 2.8867675061339146

Epoch: 6| Step: 6
Training loss: 0.43018255325858423
Validation loss: 2.945139494519115

Epoch: 6| Step: 7
Training loss: 1.3009282850955817
Validation loss: 3.0201626043986196

Epoch: 6| Step: 8
Training loss: 0.5058429671170893
Validation loss: 2.979074294429966

Epoch: 6| Step: 9
Training loss: 0.7845425461026334
Validation loss: 2.9501923762381255

Epoch: 6| Step: 10
Training loss: 0.5420798840756331
Validation loss: 2.984584860887624

Epoch: 6| Step: 11
Training loss: 0.44813847224947867
Validation loss: 2.999195838808253

Epoch: 6| Step: 12
Training loss: 0.5958032742723104
Validation loss: 3.029566792363503

Epoch: 6| Step: 13
Training loss: 0.47955085721767104
Validation loss: 3.07513618271061

Epoch: 196| Step: 0
Training loss: 0.5833097407701745
Validation loss: 3.019908333707191

Epoch: 6| Step: 1
Training loss: 0.30611286791012515
Validation loss: 3.0519795882957776

Epoch: 6| Step: 2
Training loss: 0.4017018132180013
Validation loss: 3.1025723751826417

Epoch: 6| Step: 3
Training loss: 1.2991521674899453
Validation loss: 3.049326622739424

Epoch: 6| Step: 4
Training loss: 0.4042146755819747
Validation loss: 3.0097884256306693

Epoch: 6| Step: 5
Training loss: 0.4248227871952312
Validation loss: 3.109877259856975

Epoch: 6| Step: 6
Training loss: 0.2955286340128799
Validation loss: 3.0659692278730133

Epoch: 6| Step: 7
Training loss: 0.5584959197907061
Validation loss: 3.0236087720989744

Epoch: 6| Step: 8
Training loss: 0.48533912811623214
Validation loss: 3.0374927798003526

Epoch: 6| Step: 9
Training loss: 0.723439055537947
Validation loss: 3.004550753910423

Epoch: 6| Step: 10
Training loss: 0.4554324264830088
Validation loss: 2.9718780300955263

Epoch: 6| Step: 11
Training loss: 0.4810666651595634
Validation loss: 3.0789288215161537

Epoch: 6| Step: 12
Training loss: 0.5793572773120875
Validation loss: 3.097180734498134

Epoch: 6| Step: 13
Training loss: 0.5331129899187088
Validation loss: 3.128009319929351

Epoch: 197| Step: 0
Training loss: 0.5435399406096703
Validation loss: 3.133673849946958

Epoch: 6| Step: 1
Training loss: 0.26733491801617076
Validation loss: 2.9917264471926153

Epoch: 6| Step: 2
Training loss: 0.6180415461472875
Validation loss: 3.0077991171535

Epoch: 6| Step: 3
Training loss: 0.4324210520997527
Validation loss: 3.054101912231386

Epoch: 6| Step: 4
Training loss: 0.6099445175907032
Validation loss: 2.931940390831367

Epoch: 6| Step: 5
Training loss: 0.5178248842884488
Validation loss: 3.0571819894452372

Epoch: 6| Step: 6
Training loss: 0.6193650377475131
Validation loss: 3.034471694028995

Epoch: 6| Step: 7
Training loss: 0.5628579378399066
Validation loss: 3.1332587592570844

Epoch: 6| Step: 8
Training loss: 0.4578019840738275
Validation loss: 3.101023386135856

Epoch: 6| Step: 9
Training loss: 0.7026275994701175
Validation loss: 3.1895694746484216

Epoch: 6| Step: 10
Training loss: 0.557759121603523
Validation loss: 3.1353237396021534

Epoch: 6| Step: 11
Training loss: 1.2667926535358134
Validation loss: 3.096381086527097

Epoch: 6| Step: 12
Training loss: 0.3902469713165624
Validation loss: 3.058048568343222

Epoch: 6| Step: 13
Training loss: 0.372897492702563
Validation loss: 3.0596000279504416

Epoch: 198| Step: 0
Training loss: 0.5374839447639891
Validation loss: 3.0523006157894343

Epoch: 6| Step: 1
Training loss: 0.7632386132224008
Validation loss: 3.0043333731298283

Epoch: 6| Step: 2
Training loss: 0.6470473681802642
Validation loss: 3.025748172431139

Epoch: 6| Step: 3
Training loss: 0.4149971974519525
Validation loss: 3.0602661861006895

Epoch: 6| Step: 4
Training loss: 1.2619314575413396
Validation loss: 3.075970458849136

Epoch: 6| Step: 5
Training loss: 0.38937324232681364
Validation loss: 3.0607806848584582

Epoch: 6| Step: 6
Training loss: 0.48168601930518656
Validation loss: 3.1511717378026707

Epoch: 6| Step: 7
Training loss: 0.4393226599414605
Validation loss: 3.191897730684459

Epoch: 6| Step: 8
Training loss: 0.5196732922032349
Validation loss: 3.196519407679941

Epoch: 6| Step: 9
Training loss: 0.580404478804582
Validation loss: 3.1589070457483532

Epoch: 6| Step: 10
Training loss: 0.45463483118666403
Validation loss: 3.180565765083137

Epoch: 6| Step: 11
Training loss: 0.42632517937524633
Validation loss: 3.0342854380199102

Epoch: 6| Step: 12
Training loss: 0.6354967572334326
Validation loss: 3.060938118971405

Epoch: 6| Step: 13
Training loss: 0.4592494280452832
Validation loss: 3.0678658480055225

Epoch: 199| Step: 0
Training loss: 0.5145849083736063
Validation loss: 2.9412708023314864

Epoch: 6| Step: 1
Training loss: 0.5108973192753539
Validation loss: 2.98954215115528

Epoch: 6| Step: 2
Training loss: 0.493870521877516
Validation loss: 3.0127808594266345

Epoch: 6| Step: 3
Training loss: 0.4737863665339007
Validation loss: 2.9773127427192763

Epoch: 6| Step: 4
Training loss: 0.518864425999901
Validation loss: 3.064998249999351

Epoch: 6| Step: 5
Training loss: 0.3877631063306108
Validation loss: 3.005152542592486

Epoch: 6| Step: 6
Training loss: 0.7960870250234424
Validation loss: 2.9946762239624105

Epoch: 6| Step: 7
Training loss: 0.39820335090305986
Validation loss: 3.1272905728776585

Epoch: 6| Step: 8
Training loss: 1.2548472358618146
Validation loss: 3.0903179513746446

Epoch: 6| Step: 9
Training loss: 0.623795588629591
Validation loss: 3.118178016638543

Epoch: 6| Step: 10
Training loss: 0.5436925112270481
Validation loss: 3.071571868345058

Epoch: 6| Step: 11
Training loss: 0.4186484968232473
Validation loss: 3.0326611881549037

Epoch: 6| Step: 12
Training loss: 0.46663330915417245
Validation loss: 3.004857805900342

Epoch: 6| Step: 13
Training loss: 0.5878582308642784
Validation loss: 2.989170395957195

Epoch: 200| Step: 0
Training loss: 0.4335790064599048
Validation loss: 2.945440193464012

Epoch: 6| Step: 1
Training loss: 0.5006791509137654
Validation loss: 2.9936496757628586

Epoch: 6| Step: 2
Training loss: 0.48600882653768934
Validation loss: 3.038632699995304

Epoch: 6| Step: 3
Training loss: 0.49710574520308043
Validation loss: 3.0607657160578916

Epoch: 6| Step: 4
Training loss: 0.5842452216240667
Validation loss: 3.1975449005306915

Epoch: 6| Step: 5
Training loss: 0.6459893120303747
Validation loss: 3.081545483269751

Epoch: 6| Step: 6
Training loss: 0.5771176867353206
Validation loss: 3.116539233623305

Epoch: 6| Step: 7
Training loss: 0.40411571922229467
Validation loss: 3.1349312901914606

Epoch: 6| Step: 8
Training loss: 0.707295026101705
Validation loss: 3.109246537256139

Epoch: 6| Step: 9
Training loss: 0.3742453810547591
Validation loss: 3.062073269132515

Epoch: 6| Step: 10
Training loss: 0.46846622778489827
Validation loss: 3.0391517763337004

Epoch: 6| Step: 11
Training loss: 0.546439406076506
Validation loss: 3.1011720631001105

Epoch: 6| Step: 12
Training loss: 1.314994938409151
Validation loss: 3.011536905659496

Epoch: 6| Step: 13
Training loss: 0.5606034944762219
Validation loss: 3.0568911383756667

Epoch: 201| Step: 0
Training loss: 0.33078287719773214
Validation loss: 3.0988259594424576

Epoch: 6| Step: 1
Training loss: 1.2704266955483507
Validation loss: 3.1449189952046988

Epoch: 6| Step: 2
Training loss: 0.5603889216204763
Validation loss: 3.1828927296068272

Epoch: 6| Step: 3
Training loss: 0.6216436387042116
Validation loss: 3.1535746500479886

Epoch: 6| Step: 4
Training loss: 0.39939115500572603
Validation loss: 3.103788664330275

Epoch: 6| Step: 5
Training loss: 0.3283602348169346
Validation loss: 3.131942184195557

Epoch: 6| Step: 6
Training loss: 0.37538621802626043
Validation loss: 3.0533177523513886

Epoch: 6| Step: 7
Training loss: 0.7596324029147147
Validation loss: 3.017140431022976

Epoch: 6| Step: 8
Training loss: 0.5560532532684513
Validation loss: 3.016751291517691

Epoch: 6| Step: 9
Training loss: 0.44926107456013725
Validation loss: 2.9825897202875598

Epoch: 6| Step: 10
Training loss: 0.5249537810916401
Validation loss: 3.000530474174456

Epoch: 6| Step: 11
Training loss: 0.4680014355282897
Validation loss: 2.909645407812699

Epoch: 6| Step: 12
Training loss: 0.5378982022596005
Validation loss: 2.9435411788188013

Epoch: 6| Step: 13
Training loss: 0.42110519464400953
Validation loss: 2.9548999894888257

Epoch: 202| Step: 0
Training loss: 0.5518174940931666
Validation loss: 3.153780206935551

Epoch: 6| Step: 1
Training loss: 0.6774847356899604
Validation loss: 3.1571694724965216

Epoch: 6| Step: 2
Training loss: 0.4970039967965309
Validation loss: 3.0563298434051993

Epoch: 6| Step: 3
Training loss: 0.3254401056006974
Validation loss: 3.081290087848568

Epoch: 6| Step: 4
Training loss: 0.49049475392813285
Validation loss: 2.9775790850655204

Epoch: 6| Step: 5
Training loss: 1.3066311366901389
Validation loss: 3.0199855711047

Epoch: 6| Step: 6
Training loss: 0.4585801637576856
Validation loss: 3.0417295519106817

Epoch: 6| Step: 7
Training loss: 0.6263184231366786
Validation loss: 3.078700584647995

Epoch: 6| Step: 8
Training loss: 0.5278018233471216
Validation loss: 3.121261305721708

Epoch: 6| Step: 9
Training loss: 0.42599870221070163
Validation loss: 3.10200642084129

Epoch: 6| Step: 10
Training loss: 0.5373435602301473
Validation loss: 3.1841386200056427

Epoch: 6| Step: 11
Training loss: 0.3387935899299813
Validation loss: 3.1244516400189095

Epoch: 6| Step: 12
Training loss: 0.4982422688483004
Validation loss: 3.1595107001930214

Epoch: 6| Step: 13
Training loss: 0.39086780631262336
Validation loss: 3.1310093765037164

Epoch: 203| Step: 0
Training loss: 0.3939679723226479
Validation loss: 3.1112754036650583

Epoch: 6| Step: 1
Training loss: 0.42872782958516853
Validation loss: 3.074409604964488

Epoch: 6| Step: 2
Training loss: 0.5154331023582673
Validation loss: 3.1080400294447204

Epoch: 6| Step: 3
Training loss: 0.5063833814505042
Validation loss: 3.0881671303172915

Epoch: 6| Step: 4
Training loss: 0.3950429185656289
Validation loss: 3.045468454035896

Epoch: 6| Step: 5
Training loss: 1.1952355553289373
Validation loss: 3.021404571893092

Epoch: 6| Step: 6
Training loss: 0.4119186321527808
Validation loss: 3.074802419212597

Epoch: 6| Step: 7
Training loss: 0.4026983605755234
Validation loss: 3.1283398900262256

Epoch: 6| Step: 8
Training loss: 0.3731862152465928
Validation loss: 3.0899559286774996

Epoch: 6| Step: 9
Training loss: 0.6570249704611992
Validation loss: 3.0201187384759582

Epoch: 6| Step: 10
Training loss: 0.49812231053544087
Validation loss: 3.107988633141174

Epoch: 6| Step: 11
Training loss: 0.3618533261055999
Validation loss: 3.075856697850217

Epoch: 6| Step: 12
Training loss: 0.7181531667207015
Validation loss: 3.036871243511378

Epoch: 6| Step: 13
Training loss: 0.4001586986676852
Validation loss: 2.9997017367761956

Epoch: 204| Step: 0
Training loss: 0.4683298453215812
Validation loss: 2.980331557729818

Epoch: 6| Step: 1
Training loss: 0.45611186353229305
Validation loss: 3.0523942305152305

Epoch: 6| Step: 2
Training loss: 0.49874510346784023
Validation loss: 3.0509161078831557

Epoch: 6| Step: 3
Training loss: 0.5194320297145946
Validation loss: 3.0262528092503787

Epoch: 6| Step: 4
Training loss: 0.6402271942983503
Validation loss: 2.983212522550437

Epoch: 6| Step: 5
Training loss: 0.36181269964257773
Validation loss: 3.0849033602720874

Epoch: 6| Step: 6
Training loss: 0.33517484813387133
Validation loss: 3.0607628728862846

Epoch: 6| Step: 7
Training loss: 0.3134811377265723
Validation loss: 3.145269852924104

Epoch: 6| Step: 8
Training loss: 0.474565668801618
Validation loss: 3.10032334384663

Epoch: 6| Step: 9
Training loss: 0.578724473015408
Validation loss: 3.079764070144446

Epoch: 6| Step: 10
Training loss: 0.4185427352046033
Validation loss: 3.0567116433567847

Epoch: 6| Step: 11
Training loss: 0.37366063622081414
Validation loss: 2.989735301516057

Epoch: 6| Step: 12
Training loss: 0.4403448255705968
Validation loss: 3.0416386790272574

Epoch: 6| Step: 13
Training loss: 1.18761538898613
Validation loss: 3.079522824025642

Epoch: 205| Step: 0
Training loss: 0.30904097683658854
Validation loss: 3.0732636185811884

Epoch: 6| Step: 1
Training loss: 0.4623892116595284
Validation loss: 3.0516111032444058

Epoch: 6| Step: 2
Training loss: 0.5508220468116024
Validation loss: 3.10170846078364

Epoch: 6| Step: 3
Training loss: 0.46460201485312314
Validation loss: 3.0900165109285873

Epoch: 6| Step: 4
Training loss: 0.41010142368636016
Validation loss: 3.096919930725893

Epoch: 6| Step: 5
Training loss: 0.4212353590336802
Validation loss: 3.034527779428176

Epoch: 6| Step: 6
Training loss: 0.37967179819300395
Validation loss: 3.0607314290497474

Epoch: 6| Step: 7
Training loss: 0.4881102300599981
Validation loss: 3.0744661120982473

Epoch: 6| Step: 8
Training loss: 0.6670163598434888
Validation loss: 3.0198896885402857

Epoch: 6| Step: 9
Training loss: 0.44892628312679284
Validation loss: 3.0124718449755554

Epoch: 6| Step: 10
Training loss: 0.362257036638333
Validation loss: 3.022641362159909

Epoch: 6| Step: 11
Training loss: 0.4444204396811885
Validation loss: 3.0549400986138457

Epoch: 6| Step: 12
Training loss: 1.1608297018161848
Validation loss: 3.0330637064421895

Epoch: 6| Step: 13
Training loss: 0.48543090478810924
Validation loss: 3.121766591982122

Epoch: 206| Step: 0
Training loss: 1.1796147911452224
Validation loss: 3.1391551309010235

Epoch: 6| Step: 1
Training loss: 0.7448015456889387
Validation loss: 3.1180847457353895

Epoch: 6| Step: 2
Training loss: 0.6462609633985961
Validation loss: 3.128697903126103

Epoch: 6| Step: 3
Training loss: 0.39871688472079186
Validation loss: 3.0769700725341007

Epoch: 6| Step: 4
Training loss: 0.477930793714159
Validation loss: 3.093671161918661

Epoch: 6| Step: 5
Training loss: 0.5612552964570187
Validation loss: 3.0763709012996596

Epoch: 6| Step: 6
Training loss: 0.5487007998001641
Validation loss: 2.934501402559442

Epoch: 6| Step: 7
Training loss: 0.36503101746178057
Validation loss: 3.0641962141850314

Epoch: 6| Step: 8
Training loss: 0.502077584477775
Validation loss: 3.0920116280094034

Epoch: 6| Step: 9
Training loss: 0.5484028318919124
Validation loss: 3.0179115349894805

Epoch: 6| Step: 10
Training loss: 0.5768404169348516
Validation loss: 3.111964107886661

Epoch: 6| Step: 11
Training loss: 0.304274646108721
Validation loss: 3.052679274947096

Epoch: 6| Step: 12
Training loss: 0.30041613030264525
Validation loss: 3.066947309378684

Epoch: 6| Step: 13
Training loss: 0.42895664134470785
Validation loss: 3.072132790796569

Epoch: 207| Step: 0
Training loss: 0.4150013985093234
Validation loss: 3.0228870689227825

Epoch: 6| Step: 1
Training loss: 0.477322987855696
Validation loss: 3.065366739690317

Epoch: 6| Step: 2
Training loss: 0.424052095784551
Validation loss: 3.0892691739114935

Epoch: 6| Step: 3
Training loss: 0.4868086620085975
Validation loss: 3.0887247495546695

Epoch: 6| Step: 4
Training loss: 0.6616542005525667
Validation loss: 3.118853500677183

Epoch: 6| Step: 5
Training loss: 0.3717244059712446
Validation loss: 3.132116340286348

Epoch: 6| Step: 6
Training loss: 0.5540379226491892
Validation loss: 3.0837215918016025

Epoch: 6| Step: 7
Training loss: 0.46026882873470665
Validation loss: 3.0712118991200974

Epoch: 6| Step: 8
Training loss: 0.5591359474804104
Validation loss: 3.1525462234056825

Epoch: 6| Step: 9
Training loss: 0.4851422079022947
Validation loss: 3.2692985254346256

Epoch: 6| Step: 10
Training loss: 0.19369681612833675
Validation loss: 3.194001150240897

Epoch: 6| Step: 11
Training loss: 0.4030732143762638
Validation loss: 3.1013452820579146

Epoch: 6| Step: 12
Training loss: 1.2858849404626538
Validation loss: 3.1425175823973155

Epoch: 6| Step: 13
Training loss: 0.491248066827984
Validation loss: 3.0711951439046596

Epoch: 208| Step: 0
Training loss: 0.31777990295922937
Validation loss: 3.0625792901810116

Epoch: 6| Step: 1
Training loss: 0.424667125659487
Validation loss: 3.059794742727007

Epoch: 6| Step: 2
Training loss: 0.4962846583891961
Validation loss: 3.0673922045026605

Epoch: 6| Step: 3
Training loss: 0.3450640574362938
Validation loss: 3.0146711089337552

Epoch: 6| Step: 4
Training loss: 0.4144918986312209
Validation loss: 3.013403092086069

Epoch: 6| Step: 5
Training loss: 0.6750851171303817
Validation loss: 3.1505819610620427

Epoch: 6| Step: 6
Training loss: 0.37577925620075525
Validation loss: 3.0108056306624755

Epoch: 6| Step: 7
Training loss: 0.4697946035232717
Validation loss: 3.082684465815077

Epoch: 6| Step: 8
Training loss: 0.43117767639736215
Validation loss: 3.0596754841566454

Epoch: 6| Step: 9
Training loss: 0.6892534999004468
Validation loss: 2.9746747776788953

Epoch: 6| Step: 10
Training loss: 0.3404065656661399
Validation loss: 3.0505722697209663

Epoch: 6| Step: 11
Training loss: 0.4141694776425571
Validation loss: 3.0555942682260664

Epoch: 6| Step: 12
Training loss: 0.5260280443700175
Validation loss: 3.0395452643858905

Epoch: 6| Step: 13
Training loss: 1.1459810624114077
Validation loss: 3.0511216003498216

Epoch: 209| Step: 0
Training loss: 0.36990036060968473
Validation loss: 2.972816934140164

Epoch: 6| Step: 1
Training loss: 0.49338428377048066
Validation loss: 3.0450920039508547

Epoch: 6| Step: 2
Training loss: 0.7207981863622468
Validation loss: 2.9835833153513485

Epoch: 6| Step: 3
Training loss: 0.38441794318384076
Validation loss: 3.0094735451286736

Epoch: 6| Step: 4
Training loss: 1.2075483085019945
Validation loss: 3.006219298271388

Epoch: 6| Step: 5
Training loss: 0.3270089606550583
Validation loss: 3.0286075308628124

Epoch: 6| Step: 6
Training loss: 0.5045050087369175
Validation loss: 2.9712321562572925

Epoch: 6| Step: 7
Training loss: 0.3819106631319376
Validation loss: 3.0241603463650764

Epoch: 6| Step: 8
Training loss: 0.4869261286067168
Validation loss: 3.059614482958137

Epoch: 6| Step: 9
Training loss: 0.4046540824613496
Validation loss: 3.0228570583012813

Epoch: 6| Step: 10
Training loss: 0.5152806374789546
Validation loss: 3.0609276296739787

Epoch: 6| Step: 11
Training loss: 0.515671092198514
Validation loss: 3.0482542910025665

Epoch: 6| Step: 12
Training loss: 0.5871257685785621
Validation loss: 2.9767631870275735

Epoch: 6| Step: 13
Training loss: 0.6298571204335132
Validation loss: 3.1135859130969026

Epoch: 210| Step: 0
Training loss: 0.3147879529784859
Validation loss: 3.109408571710613

Epoch: 6| Step: 1
Training loss: 0.37779471971624456
Validation loss: 3.168700008762941

Epoch: 6| Step: 2
Training loss: 0.6330287234281384
Validation loss: 3.145478112752556

Epoch: 6| Step: 3
Training loss: 0.5109402507742932
Validation loss: 3.1334756987945047

Epoch: 6| Step: 4
Training loss: 0.3887717918899456
Validation loss: 3.111919135415147

Epoch: 6| Step: 5
Training loss: 0.3797887572914523
Validation loss: 3.0568056949653943

Epoch: 6| Step: 6
Training loss: 0.43303806335194106
Validation loss: 3.029067876290159

Epoch: 6| Step: 7
Training loss: 0.5352994351371038
Validation loss: 2.9921325864475636

Epoch: 6| Step: 8
Training loss: 0.40468830933361055
Validation loss: 3.0203317861636894

Epoch: 6| Step: 9
Training loss: 0.2890115899283144
Validation loss: 3.0266910760024075

Epoch: 6| Step: 10
Training loss: 1.183539713516777
Validation loss: 3.014639289791825

Epoch: 6| Step: 11
Training loss: 0.327347891059848
Validation loss: 3.0456079570988304

Epoch: 6| Step: 12
Training loss: 0.7312244443421869
Validation loss: 3.0450087088975564

Epoch: 6| Step: 13
Training loss: 0.6267003295443484
Validation loss: 3.15566079459714

Epoch: 211| Step: 0
Training loss: 0.3597045714091315
Validation loss: 3.0849534409284907

Epoch: 6| Step: 1
Training loss: 0.4782153686192505
Validation loss: 3.0181016124315017

Epoch: 6| Step: 2
Training loss: 0.5653702304393476
Validation loss: 3.0785771278317635

Epoch: 6| Step: 3
Training loss: 0.6755951421176242
Validation loss: 3.070621827569916

Epoch: 6| Step: 4
Training loss: 0.37401979210573594
Validation loss: 3.0422480998561388

Epoch: 6| Step: 5
Training loss: 0.2845015914768564
Validation loss: 3.057444181434401

Epoch: 6| Step: 6
Training loss: 0.2459480217472743
Validation loss: 3.1502200524100155

Epoch: 6| Step: 7
Training loss: 0.29862480477174597
Validation loss: 3.0751013193780317

Epoch: 6| Step: 8
Training loss: 0.2566636816899836
Validation loss: 3.0969574353704274

Epoch: 6| Step: 9
Training loss: 1.2340664055328507
Validation loss: 3.1097989711819225

Epoch: 6| Step: 10
Training loss: 0.5032086237722607
Validation loss: 3.1036812618252356

Epoch: 6| Step: 11
Training loss: 0.33037734154034903
Validation loss: 3.1499550114804804

Epoch: 6| Step: 12
Training loss: 0.4725323033769823
Validation loss: 3.0513603256764723

Epoch: 6| Step: 13
Training loss: 0.436149812769344
Validation loss: 3.0738838656454317

Epoch: 212| Step: 0
Training loss: 0.3562420199989536
Validation loss: 3.108018282008069

Epoch: 6| Step: 1
Training loss: 0.3570283067444201
Validation loss: 3.050107861263631

Epoch: 6| Step: 2
Training loss: 0.4759204166124123
Validation loss: 3.1272963161398786

Epoch: 6| Step: 3
Training loss: 0.45036415359772436
Validation loss: 3.118423267952199

Epoch: 6| Step: 4
Training loss: 0.2970945650592898
Validation loss: 3.0978887341661054

Epoch: 6| Step: 5
Training loss: 0.5394244982660028
Validation loss: 3.032816243026077

Epoch: 6| Step: 6
Training loss: 0.4666025722998913
Validation loss: 3.082011227206262

Epoch: 6| Step: 7
Training loss: 0.4965100231493889
Validation loss: 3.0452539810552577

Epoch: 6| Step: 8
Training loss: 0.352243875782633
Validation loss: 3.1153246700071984

Epoch: 6| Step: 9
Training loss: 0.3796286235105075
Validation loss: 3.0834168259597163

Epoch: 6| Step: 10
Training loss: 0.41649403174659033
Validation loss: 3.10966768915966

Epoch: 6| Step: 11
Training loss: 0.44696817960491375
Validation loss: 3.055789784402976

Epoch: 6| Step: 12
Training loss: 0.6973787744860632
Validation loss: 3.1226636290811003

Epoch: 6| Step: 13
Training loss: 1.1542588694039375
Validation loss: 3.0486622059990554

Epoch: 213| Step: 0
Training loss: 1.0857339572199975
Validation loss: 3.043163210099521

Epoch: 6| Step: 1
Training loss: 0.4484375006645814
Validation loss: 3.1225604007845957

Epoch: 6| Step: 2
Training loss: 0.513961913172771
Validation loss: 3.1161126599763556

Epoch: 6| Step: 3
Training loss: 0.45703010884982065
Validation loss: 3.0712633545269123

Epoch: 6| Step: 4
Training loss: 0.46263973663965235
Validation loss: 3.105075157062691

Epoch: 6| Step: 5
Training loss: 0.47969060393581087
Validation loss: 3.0983169191064874

Epoch: 6| Step: 6
Training loss: 0.46094997841706387
Validation loss: 3.0359716314339877

Epoch: 6| Step: 7
Training loss: 0.3696297125259535
Validation loss: 3.0893644080834854

Epoch: 6| Step: 8
Training loss: 0.36479062136695123
Validation loss: 3.013414564374079

Epoch: 6| Step: 9
Training loss: 0.4833572832564477
Validation loss: 3.048764182737216

Epoch: 6| Step: 10
Training loss: 0.3614027204064947
Validation loss: 3.0108022123942653

Epoch: 6| Step: 11
Training loss: 0.32740495787789115
Validation loss: 3.1063986867399382

Epoch: 6| Step: 12
Training loss: 0.6238734582948066
Validation loss: 3.05960057342367

Epoch: 6| Step: 13
Training loss: 0.35645751932223263
Validation loss: 3.1056706968658503

Epoch: 214| Step: 0
Training loss: 0.36622806763320875
Validation loss: 3.1120015780654118

Epoch: 6| Step: 1
Training loss: 0.6933005724405094
Validation loss: 3.1561538127683018

Epoch: 6| Step: 2
Training loss: 0.4285282101865164
Validation loss: 3.1046473922404236

Epoch: 6| Step: 3
Training loss: 0.48129756122742423
Validation loss: 3.131800335042479

Epoch: 6| Step: 4
Training loss: 0.4412372400583964
Validation loss: 3.1062066758919165

Epoch: 6| Step: 5
Training loss: 0.47609803751513186
Validation loss: 3.0413465766922214

Epoch: 6| Step: 6
Training loss: 1.271935448862
Validation loss: 3.1433140770358414

Epoch: 6| Step: 7
Training loss: 0.35681490614309125
Validation loss: 3.096365571168131

Epoch: 6| Step: 8
Training loss: 0.3624447246041304
Validation loss: 3.211825616905634

Epoch: 6| Step: 9
Training loss: 0.4300947859999066
Validation loss: 3.2503804815539272

Epoch: 6| Step: 10
Training loss: 0.382013928229373
Validation loss: 3.2101371244057466

Epoch: 6| Step: 11
Training loss: 0.4931666610196083
Validation loss: 3.235283409235227

Epoch: 6| Step: 12
Training loss: 0.3314988973593462
Validation loss: 3.123260547993567

Epoch: 6| Step: 13
Training loss: 0.5337747158072471
Validation loss: 3.0844545688433977

Epoch: 215| Step: 0
Training loss: 0.29598302859548
Validation loss: 3.0037480888514074

Epoch: 6| Step: 1
Training loss: 0.4323176429787856
Validation loss: 3.0400550352519002

Epoch: 6| Step: 2
Training loss: 0.49183602877884086
Validation loss: 3.0716277873213755

Epoch: 6| Step: 3
Training loss: 0.47619783801677873
Validation loss: 3.058995453953262

Epoch: 6| Step: 4
Training loss: 0.4785890639645791
Validation loss: 3.05241823583138

Epoch: 6| Step: 5
Training loss: 0.4142567880519806
Validation loss: 3.05381067672453

Epoch: 6| Step: 6
Training loss: 0.33173511987616633
Validation loss: 3.082156321828683

Epoch: 6| Step: 7
Training loss: 0.4948444856927894
Validation loss: 3.1814115132299445

Epoch: 6| Step: 8
Training loss: 1.2358001015315683
Validation loss: 3.192844199214003

Epoch: 6| Step: 9
Training loss: 0.5279806741190387
Validation loss: 3.1729634363973367

Epoch: 6| Step: 10
Training loss: 0.5935822802121079
Validation loss: 3.2187650488838067

Epoch: 6| Step: 11
Training loss: 0.44387812242346997
Validation loss: 3.1669841824678486

Epoch: 6| Step: 12
Training loss: 0.4208991809670239
Validation loss: 3.1459574559126566

Epoch: 6| Step: 13
Training loss: 0.4885930553513076
Validation loss: 3.1007683391435212

Epoch: 216| Step: 0
Training loss: 0.5113081413076737
Validation loss: 3.0173149051696315

Epoch: 6| Step: 1
Training loss: 0.4038226529940863
Validation loss: 3.0490356087978783

Epoch: 6| Step: 2
Training loss: 0.29705724643561904
Validation loss: 3.0259465888226766

Epoch: 6| Step: 3
Training loss: 0.38300888707206193
Validation loss: 3.098940262087322

Epoch: 6| Step: 4
Training loss: 0.42943022568545597
Validation loss: 3.0744741512263922

Epoch: 6| Step: 5
Training loss: 0.35481098646977066
Validation loss: 3.1299339635421455

Epoch: 6| Step: 6
Training loss: 0.4416851243024981
Validation loss: 3.1593099434603844

Epoch: 6| Step: 7
Training loss: 0.6324741730675436
Validation loss: 3.1252586512018534

Epoch: 6| Step: 8
Training loss: 1.0890711845588037
Validation loss: 3.0624128705560114

Epoch: 6| Step: 9
Training loss: 0.4945081467376866
Validation loss: 3.0192065539363204

Epoch: 6| Step: 10
Training loss: 0.36559893523338743
Validation loss: 3.0640555213590677

Epoch: 6| Step: 11
Training loss: 0.38634044754849584
Validation loss: 3.067454398266275

Epoch: 6| Step: 12
Training loss: 0.4171146329186472
Validation loss: 3.0110131083169027

Epoch: 6| Step: 13
Training loss: 0.4679177047834603
Validation loss: 3.0393536321187113

Epoch: 217| Step: 0
Training loss: 0.46770105618236696
Validation loss: 3.061601143580405

Epoch: 6| Step: 1
Training loss: 0.38794385116513636
Validation loss: 3.11017658374243

Epoch: 6| Step: 2
Training loss: 0.47809035418777
Validation loss: 2.9906529408328555

Epoch: 6| Step: 3
Training loss: 0.573936496833856
Validation loss: 3.036599227402076

Epoch: 6| Step: 4
Training loss: 0.45184451078175025
Validation loss: 3.0928308939116196

Epoch: 6| Step: 5
Training loss: 0.2567195846349019
Validation loss: 3.09030506726811

Epoch: 6| Step: 6
Training loss: 0.40216091779525026
Validation loss: 3.0926081030332537

Epoch: 6| Step: 7
Training loss: 0.556060220726361
Validation loss: 3.059761561701058

Epoch: 6| Step: 8
Training loss: 0.5208595046779482
Validation loss: 3.1669192004314155

Epoch: 6| Step: 9
Training loss: 0.45429745622435347
Validation loss: 3.1271420576023234

Epoch: 6| Step: 10
Training loss: 0.33534442314142243
Validation loss: 3.053842777357999

Epoch: 6| Step: 11
Training loss: 0.3564573521083137
Validation loss: 3.093711955546212

Epoch: 6| Step: 12
Training loss: 0.4223864598611979
Validation loss: 3.062126954382602

Epoch: 6| Step: 13
Training loss: 1.0931932394670798
Validation loss: 3.081545895908694

Epoch: 218| Step: 0
Training loss: 0.46484661902816526
Validation loss: 3.104331842077304

Epoch: 6| Step: 1
Training loss: 0.3500942192813391
Validation loss: 3.1618240790091354

Epoch: 6| Step: 2
Training loss: 0.41928542054510237
Validation loss: 3.0288745578370238

Epoch: 6| Step: 3
Training loss: 0.38574104791786773
Validation loss: 3.0938300690741523

Epoch: 6| Step: 4
Training loss: 0.3658179450582222
Validation loss: 3.1020439408471723

Epoch: 6| Step: 5
Training loss: 1.0842833510483862
Validation loss: 3.0801712825139145

Epoch: 6| Step: 6
Training loss: 0.44274920854546207
Validation loss: 3.052104511556393

Epoch: 6| Step: 7
Training loss: 0.5687959966819119
Validation loss: 3.078244408681226

Epoch: 6| Step: 8
Training loss: 0.36185071115891704
Validation loss: 3.097736320727494

Epoch: 6| Step: 9
Training loss: 0.5884363423405471
Validation loss: 3.0726887936343377

Epoch: 6| Step: 10
Training loss: 0.5436258525091746
Validation loss: 3.1167770153712877

Epoch: 6| Step: 11
Training loss: 0.38115875997183696
Validation loss: 3.0889267877004065

Epoch: 6| Step: 12
Training loss: 0.4527022593102894
Validation loss: 3.0619832855074054

Epoch: 6| Step: 13
Training loss: 0.4230981508636549
Validation loss: 3.0314727911072317

Epoch: 219| Step: 0
Training loss: 0.31398246324141793
Validation loss: 3.099906652337187

Epoch: 6| Step: 1
Training loss: 0.4521914434887146
Validation loss: 3.1640626381454124

Epoch: 6| Step: 2
Training loss: 0.28571588652026086
Validation loss: 3.109889794550748

Epoch: 6| Step: 3
Training loss: 0.4719350530292949
Validation loss: 3.1632424190515516

Epoch: 6| Step: 4
Training loss: 1.1327215223940157
Validation loss: 3.143363631605753

Epoch: 6| Step: 5
Training loss: 0.3914050515284055
Validation loss: 3.1079802204314393

Epoch: 6| Step: 6
Training loss: 0.434258132416996
Validation loss: 3.1180769719721977

Epoch: 6| Step: 7
Training loss: 0.49591337514272266
Validation loss: 3.0777422155428935

Epoch: 6| Step: 8
Training loss: 0.41974263468875517
Validation loss: 3.063185439962223

Epoch: 6| Step: 9
Training loss: 0.4495176896273244
Validation loss: 3.115640637286146

Epoch: 6| Step: 10
Training loss: 0.3757076143697376
Validation loss: 3.0727800026369456

Epoch: 6| Step: 11
Training loss: 0.4483048472105627
Validation loss: 3.0131813914327488

Epoch: 6| Step: 12
Training loss: 0.583206781783396
Validation loss: 3.008565595401486

Epoch: 6| Step: 13
Training loss: 0.3201550585239147
Validation loss: 3.1096510261433727

Epoch: 220| Step: 0
Training loss: 1.0408933757407381
Validation loss: 3.003246577220361

Epoch: 6| Step: 1
Training loss: 0.3938765428440841
Validation loss: 3.0428837252985943

Epoch: 6| Step: 2
Training loss: 0.33790028288164176
Validation loss: 3.120698027654962

Epoch: 6| Step: 3
Training loss: 0.38644154564450156
Validation loss: 3.058868798579737

Epoch: 6| Step: 4
Training loss: 0.6458083937556963
Validation loss: 3.1275615620417714

Epoch: 6| Step: 5
Training loss: 0.3279782830061889
Validation loss: 3.0659842619918147

Epoch: 6| Step: 6
Training loss: 0.41935080798166674
Validation loss: 3.108580610821607

Epoch: 6| Step: 7
Training loss: 0.5927969159625213
Validation loss: 3.0485030560375175

Epoch: 6| Step: 8
Training loss: 0.3877297681588212
Validation loss: 3.0698515179541106

Epoch: 6| Step: 9
Training loss: 0.4129269521678774
Validation loss: 3.0841173429615565

Epoch: 6| Step: 10
Training loss: 0.5338315509254663
Validation loss: 2.98778734301695

Epoch: 6| Step: 11
Training loss: 0.30017961052735576
Validation loss: 3.04829038691593

Epoch: 6| Step: 12
Training loss: 0.5588575420532492
Validation loss: 3.0573955737018714

Epoch: 6| Step: 13
Training loss: 0.42612787888489645
Validation loss: 3.1332871100553654

Epoch: 221| Step: 0
Training loss: 0.3251587787073402
Validation loss: 3.0885779693339837

Epoch: 6| Step: 1
Training loss: 0.356799809005498
Validation loss: 3.1046464579121573

Epoch: 6| Step: 2
Training loss: 0.4186733937293779
Validation loss: 3.123971515528914

Epoch: 6| Step: 3
Training loss: 0.3405065212332488
Validation loss: 3.115250753042762

Epoch: 6| Step: 4
Training loss: 0.2831890760422939
Validation loss: 3.157674285516521

Epoch: 6| Step: 5
Training loss: 0.3433926198442905
Validation loss: 3.13243935408851

Epoch: 6| Step: 6
Training loss: 0.3231383787960342
Validation loss: 3.113858847842318

Epoch: 6| Step: 7
Training loss: 0.4510953929198645
Validation loss: 3.0968762538585315

Epoch: 6| Step: 8
Training loss: 0.5879756574506306
Validation loss: 3.0903814967510113

Epoch: 6| Step: 9
Training loss: 0.34928666036947437
Validation loss: 3.029435811073526

Epoch: 6| Step: 10
Training loss: 1.0719080260947065
Validation loss: 3.169083204438446

Epoch: 6| Step: 11
Training loss: 0.41827288819121317
Validation loss: 3.1026521909663214

Epoch: 6| Step: 12
Training loss: 0.3524994656207045
Validation loss: 3.164274031236082

Epoch: 6| Step: 13
Training loss: 0.4212782135522868
Validation loss: 3.074421133951683

Epoch: 222| Step: 0
Training loss: 0.2819460758713771
Validation loss: 3.149393786776626

Epoch: 6| Step: 1
Training loss: 0.40411667793217165
Validation loss: 3.0749066951210993

Epoch: 6| Step: 2
Training loss: 0.37175234526950723
Validation loss: 3.0729995371533403

Epoch: 6| Step: 3
Training loss: 0.3509683781063897
Validation loss: 3.055871381235835

Epoch: 6| Step: 4
Training loss: 0.40511489892529634
Validation loss: 3.0180077503122527

Epoch: 6| Step: 5
Training loss: 0.7105008974975673
Validation loss: 3.022312792966716

Epoch: 6| Step: 6
Training loss: 0.4412472193687077
Validation loss: 3.0140897964182822

Epoch: 6| Step: 7
Training loss: 0.3717449096928914
Validation loss: 3.0411780413419103

Epoch: 6| Step: 8
Training loss: 0.3003684964605029
Validation loss: 3.105651005608991

Epoch: 6| Step: 9
Training loss: 0.3708884223280859
Validation loss: 3.0802627859676632

Epoch: 6| Step: 10
Training loss: 1.0520354659770668
Validation loss: 3.109566214606902

Epoch: 6| Step: 11
Training loss: 0.3534219522876234
Validation loss: 3.1167337697671016

Epoch: 6| Step: 12
Training loss: 0.4250179763806875
Validation loss: 3.130146252380958

Epoch: 6| Step: 13
Training loss: 0.3777822951303087
Validation loss: 3.045537227809122

Epoch: 223| Step: 0
Training loss: 0.6130440854762249
Validation loss: 3.0921386478440196

Epoch: 6| Step: 1
Training loss: 0.5990458272525159
Validation loss: 3.0218330219960072

Epoch: 6| Step: 2
Training loss: 0.30989835909073277
Validation loss: 3.0270667952321832

Epoch: 6| Step: 3
Training loss: 1.0650328571104526
Validation loss: 3.114599442626391

Epoch: 6| Step: 4
Training loss: 0.3214972033438361
Validation loss: 3.058452786461042

Epoch: 6| Step: 5
Training loss: 0.36484245447096253
Validation loss: 3.0428377971294305

Epoch: 6| Step: 6
Training loss: 0.45374515452044023
Validation loss: 3.0590204726406305

Epoch: 6| Step: 7
Training loss: 0.4358017009205163
Validation loss: 3.1033540127068973

Epoch: 6| Step: 8
Training loss: 0.42266471558164664
Validation loss: 3.110966030969079

Epoch: 6| Step: 9
Training loss: 0.42973939408867695
Validation loss: 3.0212390934078233

Epoch: 6| Step: 10
Training loss: 0.4745611001411931
Validation loss: 3.075235692220766

Epoch: 6| Step: 11
Training loss: 0.4311830330421159
Validation loss: 3.1353199247895045

Epoch: 6| Step: 12
Training loss: 0.37468334577483
Validation loss: 3.053505085739915

Epoch: 6| Step: 13
Training loss: 0.5089007527772145
Validation loss: 3.1053363635877034

Epoch: 224| Step: 0
Training loss: 0.5507844965412961
Validation loss: 3.0202099825634035

Epoch: 6| Step: 1
Training loss: 0.27940483940919547
Validation loss: 3.0083395095789975

Epoch: 6| Step: 2
Training loss: 0.335867464172671
Validation loss: 3.0567679706732758

Epoch: 6| Step: 3
Training loss: 1.0915251856164203
Validation loss: 3.065492219217257

Epoch: 6| Step: 4
Training loss: 0.49905702959381565
Validation loss: 3.1111870857642656

Epoch: 6| Step: 5
Training loss: 0.5076287744189676
Validation loss: 3.0484185897837626

Epoch: 6| Step: 6
Training loss: 0.4419051869830583
Validation loss: 3.169309333226807

Epoch: 6| Step: 7
Training loss: 0.3341342188337218
Validation loss: 3.125243202918373

Epoch: 6| Step: 8
Training loss: 0.5352867134506247
Validation loss: 3.196469695102486

Epoch: 6| Step: 9
Training loss: 0.49792607656336546
Validation loss: 3.130135944225503

Epoch: 6| Step: 10
Training loss: 0.46653365051747625
Validation loss: 3.126983801274094

Epoch: 6| Step: 11
Training loss: 0.4206806159129925
Validation loss: 3.0974795662711654

Epoch: 6| Step: 12
Training loss: 0.5311600384555513
Validation loss: 2.9803606366188724

Epoch: 6| Step: 13
Training loss: 0.48765383273976726
Validation loss: 3.022822499051792

Epoch: 225| Step: 0
Training loss: 0.5529217082437938
Validation loss: 3.059830299920192

Epoch: 6| Step: 1
Training loss: 0.41405641803233345
Validation loss: 3.0252608420615883

Epoch: 6| Step: 2
Training loss: 0.3429437632571903
Validation loss: 3.0209241436868615

Epoch: 6| Step: 3
Training loss: 0.3458635313664527
Validation loss: 3.05618334062375

Epoch: 6| Step: 4
Training loss: 0.348003364180878
Validation loss: 3.123307659942028

Epoch: 6| Step: 5
Training loss: 0.39836267628922445
Validation loss: 3.1664089215105236

Epoch: 6| Step: 6
Training loss: 0.5641207392840399
Validation loss: 3.156235081099197

Epoch: 6| Step: 7
Training loss: 0.39315245261108334
Validation loss: 3.0893424005555095

Epoch: 6| Step: 8
Training loss: 0.3054097247841857
Validation loss: 3.0458586342556995

Epoch: 6| Step: 9
Training loss: 1.095291849287235
Validation loss: 3.098672181496607

Epoch: 6| Step: 10
Training loss: 0.3621462658111466
Validation loss: 3.054510048007221

Epoch: 6| Step: 11
Training loss: 0.44917234098121195
Validation loss: 2.9939083665387343

Epoch: 6| Step: 12
Training loss: 0.41856584057920954
Validation loss: 3.018575170705198

Epoch: 6| Step: 13
Training loss: 0.326402251610341
Validation loss: 3.1457561879246088

Epoch: 226| Step: 0
Training loss: 0.34083116617928355
Validation loss: 3.0346486155188734

Epoch: 6| Step: 1
Training loss: 0.4311875774982304
Validation loss: 3.0207139002549717

Epoch: 6| Step: 2
Training loss: 0.38149443279368933
Validation loss: 3.038508648322995

Epoch: 6| Step: 3
Training loss: 0.4171033795874899
Validation loss: 3.114688965059777

Epoch: 6| Step: 4
Training loss: 0.35494218328616867
Validation loss: 3.1045671925739313

Epoch: 6| Step: 5
Training loss: 0.3964469591347671
Validation loss: 3.0831292746438406

Epoch: 6| Step: 6
Training loss: 0.511092086178186
Validation loss: 3.080435761737776

Epoch: 6| Step: 7
Training loss: 0.4703111718244587
Validation loss: 3.0498287522857472

Epoch: 6| Step: 8
Training loss: 0.6327516738480607
Validation loss: 3.0402932833276224

Epoch: 6| Step: 9
Training loss: 1.0080487469701083
Validation loss: 3.0933531946607924

Epoch: 6| Step: 10
Training loss: 0.5177055633849476
Validation loss: 3.1189950086107885

Epoch: 6| Step: 11
Training loss: 0.43821218969878883
Validation loss: 3.116224211805302

Epoch: 6| Step: 12
Training loss: 0.41252052443912923
Validation loss: 3.096026369822044

Epoch: 6| Step: 13
Training loss: 0.40737297664396194
Validation loss: 3.0921807210500005

Epoch: 227| Step: 0
Training loss: 0.5918915424230552
Validation loss: 3.129310064336016

Epoch: 6| Step: 1
Training loss: 0.35253291243580576
Validation loss: 3.147757760528224

Epoch: 6| Step: 2
Training loss: 0.2908940029100814
Validation loss: 3.0445481895449955

Epoch: 6| Step: 3
Training loss: 1.0257775149019548
Validation loss: 3.0655872846869956

Epoch: 6| Step: 4
Training loss: 0.32071441927872785
Validation loss: 3.1156989983813923

Epoch: 6| Step: 5
Training loss: 0.356416654087917
Validation loss: 3.1489753863173346

Epoch: 6| Step: 6
Training loss: 0.5195365274491119
Validation loss: 3.1360555021230474

Epoch: 6| Step: 7
Training loss: 0.42051640496021997
Validation loss: 3.180750876032429

Epoch: 6| Step: 8
Training loss: 0.33523286063910807
Validation loss: 3.18763772504875

Epoch: 6| Step: 9
Training loss: 0.36236839042865093
Validation loss: 3.1497527625933235

Epoch: 6| Step: 10
Training loss: 0.424939364427375
Validation loss: 3.1330956436528083

Epoch: 6| Step: 11
Training loss: 0.31841006197282223
Validation loss: 3.141032153002558

Epoch: 6| Step: 12
Training loss: 0.39311724031974477
Validation loss: 3.118005324999634

Epoch: 6| Step: 13
Training loss: 0.5181018986170737
Validation loss: 3.0328592505463843

Epoch: 228| Step: 0
Training loss: 0.4601977927038548
Validation loss: 3.0388955770771906

Epoch: 6| Step: 1
Training loss: 0.41218869860563767
Validation loss: 3.0893087265476367

Epoch: 6| Step: 2
Training loss: 0.6062204432410501
Validation loss: 3.0136557492286014

Epoch: 6| Step: 3
Training loss: 0.42529160228908275
Validation loss: 3.1007051732322775

Epoch: 6| Step: 4
Training loss: 0.4633578103733226
Validation loss: 3.074950386825649

Epoch: 6| Step: 5
Training loss: 0.5158992384847103
Validation loss: 3.13574581171771

Epoch: 6| Step: 6
Training loss: 0.33953132738234526
Validation loss: 3.0394334084600527

Epoch: 6| Step: 7
Training loss: 0.3928039243030594
Validation loss: 3.0301860502089673

Epoch: 6| Step: 8
Training loss: 1.031546174491936
Validation loss: 3.0312964707840173

Epoch: 6| Step: 9
Training loss: 0.6451533003425751
Validation loss: 3.0054192736203746

Epoch: 6| Step: 10
Training loss: 0.46328789125670994
Validation loss: 3.056330519475594

Epoch: 6| Step: 11
Training loss: 0.3488444586130429
Validation loss: 3.063112638788838

Epoch: 6| Step: 12
Training loss: 0.3426515085228879
Validation loss: 3.040786175901005

Epoch: 6| Step: 13
Training loss: 0.32671180168582503
Validation loss: 3.1287935246970773

Epoch: 229| Step: 0
Training loss: 0.38391990469658727
Validation loss: 3.209100350845716

Epoch: 6| Step: 1
Training loss: 0.33440399578972024
Validation loss: 3.114841276138659

Epoch: 6| Step: 2
Training loss: 0.3532191134257482
Validation loss: 3.1135457499683534

Epoch: 6| Step: 3
Training loss: 0.37517039083691134
Validation loss: 3.140631199667712

Epoch: 6| Step: 4
Training loss: 0.31858066754610714
Validation loss: 3.1174645296805097

Epoch: 6| Step: 5
Training loss: 0.44389039223103005
Validation loss: 3.114731397054409

Epoch: 6| Step: 6
Training loss: 0.46701408663544214
Validation loss: 3.041288082304045

Epoch: 6| Step: 7
Training loss: 0.5079799962742247
Validation loss: 3.0915538943785417

Epoch: 6| Step: 8
Training loss: 0.3935255319099183
Validation loss: 3.0741085564310535

Epoch: 6| Step: 9
Training loss: 0.32731894988660853
Validation loss: 3.0758210287896155

Epoch: 6| Step: 10
Training loss: 0.5428960188859696
Validation loss: 3.0860424941345586

Epoch: 6| Step: 11
Training loss: 1.0608029556919365
Validation loss: 3.0457847535677094

Epoch: 6| Step: 12
Training loss: 0.3110619837331445
Validation loss: 3.0986377625055668

Epoch: 6| Step: 13
Training loss: 0.45633215295247925
Validation loss: 3.1003109883628768

Epoch: 230| Step: 0
Training loss: 0.41494784081960584
Validation loss: 3.0847029393434204

Epoch: 6| Step: 1
Training loss: 0.2532073452134966
Validation loss: 3.085065552701817

Epoch: 6| Step: 2
Training loss: 0.496093029111804
Validation loss: 3.067063972575453

Epoch: 6| Step: 3
Training loss: 0.5656226690254866
Validation loss: 3.0546423607082205

Epoch: 6| Step: 4
Training loss: 1.0384643668763858
Validation loss: 3.085691392315773

Epoch: 6| Step: 5
Training loss: 0.3037756700618393
Validation loss: 3.135722697753911

Epoch: 6| Step: 6
Training loss: 0.22746914292762885
Validation loss: 3.1406520380529552

Epoch: 6| Step: 7
Training loss: 0.4119085934648066
Validation loss: 3.1740973819079015

Epoch: 6| Step: 8
Training loss: 0.47628854475460164
Validation loss: 3.2053712489582664

Epoch: 6| Step: 9
Training loss: 0.4522836701283504
Validation loss: 3.167189697104271

Epoch: 6| Step: 10
Training loss: 0.37566630455316685
Validation loss: 3.2145494748942927

Epoch: 6| Step: 11
Training loss: 0.4419228223311628
Validation loss: 3.1171177957464824

Epoch: 6| Step: 12
Training loss: 0.33092755152344117
Validation loss: 3.144085168888536

Epoch: 6| Step: 13
Training loss: 0.45042655119987973
Validation loss: 3.1369943715414803

Epoch: 231| Step: 0
Training loss: 0.4180924241529457
Validation loss: 3.1558830375239144

Epoch: 6| Step: 1
Training loss: 0.3622631450187296
Validation loss: 3.1511342479041438

Epoch: 6| Step: 2
Training loss: 0.3917150166610945
Validation loss: 3.1060077959140098

Epoch: 6| Step: 3
Training loss: 1.0725393032884103
Validation loss: 3.081089070768595

Epoch: 6| Step: 4
Training loss: 0.43803788226404616
Validation loss: 3.1099046802325705

Epoch: 6| Step: 5
Training loss: 0.35867841215663665
Validation loss: 3.0850987191791925

Epoch: 6| Step: 6
Training loss: 0.3309101137891605
Validation loss: 3.1552505295556594

Epoch: 6| Step: 7
Training loss: 0.3640390920685894
Validation loss: 3.1491173451149828

Epoch: 6| Step: 8
Training loss: 0.4384604878017254
Validation loss: 3.14887978450231

Epoch: 6| Step: 9
Training loss: 0.40206601454771473
Validation loss: 3.1338897654027926

Epoch: 6| Step: 10
Training loss: 0.28248775499947554
Validation loss: 3.1152726668313417

Epoch: 6| Step: 11
Training loss: 0.3824130913541049
Validation loss: 3.076444964523306

Epoch: 6| Step: 12
Training loss: 0.3413466294560162
Validation loss: 3.131703764827862

Epoch: 6| Step: 13
Training loss: 0.4363070299313583
Validation loss: 3.0235910171318494

Epoch: 232| Step: 0
Training loss: 0.4609305656040808
Validation loss: 3.072367723647532

Epoch: 6| Step: 1
Training loss: 0.5638534898352764
Validation loss: 3.0994953406160906

Epoch: 6| Step: 2
Training loss: 0.35540326531841676
Validation loss: 3.017921627373634

Epoch: 6| Step: 3
Training loss: 0.36998088007575175
Validation loss: 3.0778463660316255

Epoch: 6| Step: 4
Training loss: 0.547738293040818
Validation loss: 3.090383952646859

Epoch: 6| Step: 5
Training loss: 0.5016363309430785
Validation loss: 3.140699584986271

Epoch: 6| Step: 6
Training loss: 0.3661033777590125
Validation loss: 3.1124849725077075

Epoch: 6| Step: 7
Training loss: 0.4157256965266167
Validation loss: 3.1562739959912527

Epoch: 6| Step: 8
Training loss: 0.4536249099735561
Validation loss: 3.207589277876819

Epoch: 6| Step: 9
Training loss: 1.060974653040126
Validation loss: 3.2146338405502157

Epoch: 6| Step: 10
Training loss: 0.4317327375213538
Validation loss: 3.166591873456857

Epoch: 6| Step: 11
Training loss: 0.2960811340543101
Validation loss: 3.1158400756920788

Epoch: 6| Step: 12
Training loss: 0.25873056866296956
Validation loss: 3.15908608000648

Epoch: 6| Step: 13
Training loss: 0.38224259597763044
Validation loss: 3.0837387557302143

Epoch: 233| Step: 0
Training loss: 0.3080977546221919
Validation loss: 3.094986870634613

Epoch: 6| Step: 1
Training loss: 0.32678571491851927
Validation loss: 3.082351777493029

Epoch: 6| Step: 2
Training loss: 0.3725754320331693
Validation loss: 3.0988672622420546

Epoch: 6| Step: 3
Training loss: 0.3582325689263863
Validation loss: 3.0863437562228095

Epoch: 6| Step: 4
Training loss: 0.40816070482244016
Validation loss: 3.0783893968660605

Epoch: 6| Step: 5
Training loss: 0.45010312143899084
Validation loss: 3.045556029095853

Epoch: 6| Step: 6
Training loss: 0.38713921702327103
Validation loss: 3.1336466756006573

Epoch: 6| Step: 7
Training loss: 0.32978523396724635
Validation loss: 3.057244416911

Epoch: 6| Step: 8
Training loss: 0.40230115646529857
Validation loss: 3.107035729796144

Epoch: 6| Step: 9
Training loss: 0.4233807078771617
Validation loss: 3.0583614197791738

Epoch: 6| Step: 10
Training loss: 1.0208406188601065
Validation loss: 3.073810089752617

Epoch: 6| Step: 11
Training loss: 0.5434831885446149
Validation loss: 3.1010461949238612

Epoch: 6| Step: 12
Training loss: 0.45500932427168905
Validation loss: 3.1575325729973374

Epoch: 6| Step: 13
Training loss: 0.3703350140773518
Validation loss: 3.1457236736123373

Epoch: 234| Step: 0
Training loss: 0.3902541498284916
Validation loss: 3.0512770975553956

Epoch: 6| Step: 1
Training loss: 0.3992876445051918
Validation loss: 3.1552908166981144

Epoch: 6| Step: 2
Training loss: 0.45065477801911097
Validation loss: 3.0836027560357464

Epoch: 6| Step: 3
Training loss: 0.4619092557951379
Validation loss: 3.104440258864185

Epoch: 6| Step: 4
Training loss: 0.37608876721481216
Validation loss: 3.1466486971013405

Epoch: 6| Step: 5
Training loss: 0.27068309407071434
Validation loss: 3.0788331613010063

Epoch: 6| Step: 6
Training loss: 0.30122098114203666
Validation loss: 3.1505109902344435

Epoch: 6| Step: 7
Training loss: 0.5078923969504876
Validation loss: 3.1835149400313663

Epoch: 6| Step: 8
Training loss: 0.3803590079702526
Validation loss: 3.1023215030592017

Epoch: 6| Step: 9
Training loss: 0.9934987692285372
Validation loss: 3.211445108527316

Epoch: 6| Step: 10
Training loss: 0.5802578631570491
Validation loss: 3.064078488617013

Epoch: 6| Step: 11
Training loss: 0.6015144923486571
Validation loss: 3.1251139429300454

Epoch: 6| Step: 12
Training loss: 0.4372528604290653
Validation loss: 3.1011920518751706

Epoch: 6| Step: 13
Training loss: 0.5004681541303553
Validation loss: 3.1637140780785544

Epoch: 235| Step: 0
Training loss: 0.48059421544889935
Validation loss: 3.1286887713608635

Epoch: 6| Step: 1
Training loss: 0.2862658403003417
Validation loss: 3.2122989933049033

Epoch: 6| Step: 2
Training loss: 0.258226149509208
Validation loss: 3.2158600261918546

Epoch: 6| Step: 3
Training loss: 1.0290227014541673
Validation loss: 3.131951420661805

Epoch: 6| Step: 4
Training loss: 0.49699161408677706
Validation loss: 3.308345528651388

Epoch: 6| Step: 5
Training loss: 0.43901893358850336
Validation loss: 3.1394539289800565

Epoch: 6| Step: 6
Training loss: 0.4439976672656837
Validation loss: 3.092197915127617

Epoch: 6| Step: 7
Training loss: 0.3672839910462855
Validation loss: 3.0934809943491315

Epoch: 6| Step: 8
Training loss: 0.4726342125160995
Validation loss: 3.0236235437316217

Epoch: 6| Step: 9
Training loss: 0.44661743971316237
Validation loss: 3.050052844043147

Epoch: 6| Step: 10
Training loss: 0.3868697671120377
Validation loss: 3.090314363889299

Epoch: 6| Step: 11
Training loss: 0.40405446769596115
Validation loss: 3.057455423487106

Epoch: 6| Step: 12
Training loss: 0.25725610978977725
Validation loss: 3.0521211762843405

Epoch: 6| Step: 13
Training loss: 0.41206688684494547
Validation loss: 3.1161391966158947

Epoch: 236| Step: 0
Training loss: 0.6106826982599272
Validation loss: 3.0919177605457278

Epoch: 6| Step: 1
Training loss: 0.4112588141172201
Validation loss: 3.096193292843121

Epoch: 6| Step: 2
Training loss: 0.39718445855513634
Validation loss: 3.1409963764621964

Epoch: 6| Step: 3
Training loss: 0.9651182456035251
Validation loss: 3.1171219260346477

Epoch: 6| Step: 4
Training loss: 0.2802674827873526
Validation loss: 3.078346928633771

Epoch: 6| Step: 5
Training loss: 0.40867665764415356
Validation loss: 3.0653078610591273

Epoch: 6| Step: 6
Training loss: 0.36395666442310864
Validation loss: 3.1201139908735906

Epoch: 6| Step: 7
Training loss: 0.4592528349436402
Validation loss: 3.1932108713319773

Epoch: 6| Step: 8
Training loss: 0.43191121108286984
Validation loss: 3.2070357972769923

Epoch: 6| Step: 9
Training loss: 0.3695952829767988
Validation loss: 3.105922872100322

Epoch: 6| Step: 10
Training loss: 0.4847074413808921
Validation loss: 3.1797948220876386

Epoch: 6| Step: 11
Training loss: 0.5067371426472321
Validation loss: 3.1451212643410553

Epoch: 6| Step: 12
Training loss: 0.4642855714965433
Validation loss: 3.069344559698954

Epoch: 6| Step: 13
Training loss: 0.42565767437269675
Validation loss: 3.1791440857118243

Epoch: 237| Step: 0
Training loss: 0.4462543699440579
Validation loss: 3.1225358021182488

Epoch: 6| Step: 1
Training loss: 0.42412024420385896
Validation loss: 3.159576035821949

Epoch: 6| Step: 2
Training loss: 0.49400535812831203
Validation loss: 3.193342202983264

Epoch: 6| Step: 3
Training loss: 0.4842140176350408
Validation loss: 3.179222991531069

Epoch: 6| Step: 4
Training loss: 0.5204906926014597
Validation loss: 3.2118762918650194

Epoch: 6| Step: 5
Training loss: 0.3909569664857083
Validation loss: 3.1849109257329804

Epoch: 6| Step: 6
Training loss: 0.40390116911594015
Validation loss: 3.1664204543584384

Epoch: 6| Step: 7
Training loss: 0.2421495346337399
Validation loss: 3.1896966832254456

Epoch: 6| Step: 8
Training loss: 0.4847314200064541
Validation loss: 3.133452758305526

Epoch: 6| Step: 9
Training loss: 0.9802732234695423
Validation loss: 3.1575855413283205

Epoch: 6| Step: 10
Training loss: 0.34569213332466325
Validation loss: 3.093422406766686

Epoch: 6| Step: 11
Training loss: 0.4609439493794949
Validation loss: 3.1256444902224914

Epoch: 6| Step: 12
Training loss: 0.4564641547894625
Validation loss: 3.099926123712988

Epoch: 6| Step: 13
Training loss: 0.45568213265532903
Validation loss: 3.1177124116877066

Epoch: 238| Step: 0
Training loss: 0.3161097538432772
Validation loss: 3.0791166099295997

Epoch: 6| Step: 1
Training loss: 0.356440713931167
Validation loss: 3.160258036492169

Epoch: 6| Step: 2
Training loss: 0.9081924273773532
Validation loss: 3.0644759077429145

Epoch: 6| Step: 3
Training loss: 0.35155455262420127
Validation loss: 3.175412339996472

Epoch: 6| Step: 4
Training loss: 0.5511991390024998
Validation loss: 3.117215531684444

Epoch: 6| Step: 5
Training loss: 0.4565502961738602
Validation loss: 3.144057869672233

Epoch: 6| Step: 6
Training loss: 0.40740384787070577
Validation loss: 3.1016080326097986

Epoch: 6| Step: 7
Training loss: 0.48226075049303213
Validation loss: 3.160070618552614

Epoch: 6| Step: 8
Training loss: 0.3005133959589802
Validation loss: 3.0691179017429078

Epoch: 6| Step: 9
Training loss: 0.3909394333850308
Validation loss: 3.1281794205084688

Epoch: 6| Step: 10
Training loss: 0.4947969804444997
Validation loss: 3.1674749865268126

Epoch: 6| Step: 11
Training loss: 0.6241915003399224
Validation loss: 3.127187878519193

Epoch: 6| Step: 12
Training loss: 0.5022948471162729
Validation loss: 3.159676004893872

Epoch: 6| Step: 13
Training loss: 0.4851560909006838
Validation loss: 3.163360065619252

Epoch: 239| Step: 0
Training loss: 0.6523643992919149
Validation loss: 3.1448643351992573

Epoch: 6| Step: 1
Training loss: 0.3160660174239903
Validation loss: 3.1652326892451432

Epoch: 6| Step: 2
Training loss: 0.5205142251598414
Validation loss: 3.1765126367180807

Epoch: 6| Step: 3
Training loss: 0.5803266307648987
Validation loss: 3.124900930741657

Epoch: 6| Step: 4
Training loss: 0.9393683889007926
Validation loss: 3.0775263893283067

Epoch: 6| Step: 5
Training loss: 0.48338678519336753
Validation loss: 3.0738267014406824

Epoch: 6| Step: 6
Training loss: 0.4255392629335836
Validation loss: 3.074132081958625

Epoch: 6| Step: 7
Training loss: 0.5572083907134363
Validation loss: 3.117827398386863

Epoch: 6| Step: 8
Training loss: 0.32343347657506927
Validation loss: 3.0908521958926887

Epoch: 6| Step: 9
Training loss: 0.34568922370504346
Validation loss: 3.108859046544068

Epoch: 6| Step: 10
Training loss: 0.4800009271990245
Validation loss: 3.171205622255145

Epoch: 6| Step: 11
Training loss: 0.3970477231454124
Validation loss: 3.2364071959323177

Epoch: 6| Step: 12
Training loss: 0.45883315821634024
Validation loss: 3.2329106601902327

Epoch: 6| Step: 13
Training loss: 0.43161708025346057
Validation loss: 3.1404179746802146

Epoch: 240| Step: 0
Training loss: 0.35839679520150164
Validation loss: 3.1479262196370423

Epoch: 6| Step: 1
Training loss: 0.3745104455242373
Validation loss: 3.152747032717687

Epoch: 6| Step: 2
Training loss: 0.38679245525771333
Validation loss: 3.1596436589759533

Epoch: 6| Step: 3
Training loss: 1.000917907484979
Validation loss: 3.1012930316597025

Epoch: 6| Step: 4
Training loss: 0.27717872868092003
Validation loss: 3.030728770534247

Epoch: 6| Step: 5
Training loss: 0.5243227859708603
Validation loss: 3.082620117247982

Epoch: 6| Step: 6
Training loss: 0.4057439807085754
Validation loss: 3.0435192571617478

Epoch: 6| Step: 7
Training loss: 0.5517578125
Validation loss: 3.0391083413975815

Epoch: 6| Step: 8
Training loss: 0.4914966154476763
Validation loss: 3.0640345900096215

Epoch: 6| Step: 9
Training loss: 0.4473197271283687
Validation loss: 3.13480722750334

Epoch: 6| Step: 10
Training loss: 0.36315160919761513
Validation loss: 2.995698334928881

Epoch: 6| Step: 11
Training loss: 0.5089033880671561
Validation loss: 3.073889023557344

Epoch: 6| Step: 12
Training loss: 0.47858851909113975
Validation loss: 3.113233360901808

Epoch: 6| Step: 13
Training loss: 0.6767017291722134
Validation loss: 3.1147291517198092

Epoch: 241| Step: 0
Training loss: 0.38465912792527834
Validation loss: 3.0921074973678917

Epoch: 6| Step: 1
Training loss: 0.4096117310689961
Validation loss: 3.1321864085160818

Epoch: 6| Step: 2
Training loss: 0.3406445506373491
Validation loss: 3.1081172501537533

Epoch: 6| Step: 3
Training loss: 0.38492911878412456
Validation loss: 3.118429715637773

Epoch: 6| Step: 4
Training loss: 0.3896261031937118
Validation loss: 3.119940820523969

Epoch: 6| Step: 5
Training loss: 0.9939296775902966
Validation loss: 3.1558144020162118

Epoch: 6| Step: 6
Training loss: 0.6216996794040952
Validation loss: 3.055599548042418

Epoch: 6| Step: 7
Training loss: 0.38421996874652814
Validation loss: 3.071721343410916

Epoch: 6| Step: 8
Training loss: 0.5437015555714014
Validation loss: 3.0927917846096946

Epoch: 6| Step: 9
Training loss: 0.422658069909879
Validation loss: 3.109440954585553

Epoch: 6| Step: 10
Training loss: 0.2831986788696654
Validation loss: 3.1321064953397766

Epoch: 6| Step: 11
Training loss: 0.19664924939126535
Validation loss: 3.0460128607767523

Epoch: 6| Step: 12
Training loss: 0.4098114017194349
Validation loss: 3.281451458271778

Epoch: 6| Step: 13
Training loss: 0.407986505882487
Validation loss: 3.213106052709125

Epoch: 242| Step: 0
Training loss: 0.39511650413495575
Validation loss: 3.2030404056450337

Epoch: 6| Step: 1
Training loss: 0.3805041294763581
Validation loss: 3.105476478551049

Epoch: 6| Step: 2
Training loss: 0.3129564289899662
Validation loss: 3.146616823426659

Epoch: 6| Step: 3
Training loss: 0.469904796388294
Validation loss: 3.156814549885078

Epoch: 6| Step: 4
Training loss: 0.9323786725126499
Validation loss: 3.0894002680562243

Epoch: 6| Step: 5
Training loss: 0.5600488291041338
Validation loss: 3.0822061505991547

Epoch: 6| Step: 6
Training loss: 0.4524899505057802
Validation loss: 3.1247138464566895

Epoch: 6| Step: 7
Training loss: 0.3068120076580997
Validation loss: 3.1042448499080324

Epoch: 6| Step: 8
Training loss: 0.39717316578376505
Validation loss: 3.116185077307694

Epoch: 6| Step: 9
Training loss: 0.3889798999719738
Validation loss: 3.1872302171816957

Epoch: 6| Step: 10
Training loss: 0.2571500590570402
Validation loss: 3.275150952245485

Epoch: 6| Step: 11
Training loss: 0.44728176637533246
Validation loss: 3.15501297733965

Epoch: 6| Step: 12
Training loss: 0.4078203807083979
Validation loss: 3.208500601796724

Epoch: 6| Step: 13
Training loss: 0.4459313392614584
Validation loss: 3.1987426055707453

Epoch: 243| Step: 0
Training loss: 0.44867652012544174
Validation loss: 3.226694321421923

Epoch: 6| Step: 1
Training loss: 0.3360997739577448
Validation loss: 3.1295046192506266

Epoch: 6| Step: 2
Training loss: 0.6213164020412346
Validation loss: 3.1548718883985187

Epoch: 6| Step: 3
Training loss: 0.3997015256709915
Validation loss: 3.070686168758905

Epoch: 6| Step: 4
Training loss: 0.8953859335724276
Validation loss: 3.1729443506113073

Epoch: 6| Step: 5
Training loss: 0.4240433107109144
Validation loss: 3.1638755586131397

Epoch: 6| Step: 6
Training loss: 0.3250209810747162
Validation loss: 3.139487470156

Epoch: 6| Step: 7
Training loss: 0.19916179254152783
Validation loss: 3.1053002653661186

Epoch: 6| Step: 8
Training loss: 0.35655191995903274
Validation loss: 3.1127609909509415

Epoch: 6| Step: 9
Training loss: 0.452856642083299
Validation loss: 3.091061769588808

Epoch: 6| Step: 10
Training loss: 0.27570179343070916
Validation loss: 3.101217357992122

Epoch: 6| Step: 11
Training loss: 0.4639354776006642
Validation loss: 3.1542448718623484

Epoch: 6| Step: 12
Training loss: 0.32716460686195725
Validation loss: 3.11371372462617

Epoch: 6| Step: 13
Training loss: 0.5016643717809425
Validation loss: 3.205376319256117

Epoch: 244| Step: 0
Training loss: 0.37005876467545745
Validation loss: 3.093713445479606

Epoch: 6| Step: 1
Training loss: 0.44287661177826143
Validation loss: 3.1514064525123966

Epoch: 6| Step: 2
Training loss: 0.29234828095260973
Validation loss: 3.121905078558478

Epoch: 6| Step: 3
Training loss: 0.30491588053967295
Validation loss: 3.107522268729546

Epoch: 6| Step: 4
Training loss: 0.4135109628990763
Validation loss: 3.0133733166796106

Epoch: 6| Step: 5
Training loss: 0.5130715579082448
Validation loss: 3.1089604674908

Epoch: 6| Step: 6
Training loss: 0.41788970342403625
Validation loss: 3.118826694093391

Epoch: 6| Step: 7
Training loss: 0.3745420361598128
Validation loss: 3.1998173080388246

Epoch: 6| Step: 8
Training loss: 0.41355508627205273
Validation loss: 3.1539107614881345

Epoch: 6| Step: 9
Training loss: 0.9297843690301323
Validation loss: 3.181776455609742

Epoch: 6| Step: 10
Training loss: 0.48449164185927307
Validation loss: 3.1260536452083705

Epoch: 6| Step: 11
Training loss: 0.5832001386439521
Validation loss: 3.1655696215089635

Epoch: 6| Step: 12
Training loss: 0.36526152565961506
Validation loss: 3.266382692281434

Epoch: 6| Step: 13
Training loss: 0.3550903066427727
Validation loss: 3.1770020312970275

Epoch: 245| Step: 0
Training loss: 0.6096206561135799
Validation loss: 3.2095441184944975

Epoch: 6| Step: 1
Training loss: 0.3891088435136432
Validation loss: 3.135185668310452

Epoch: 6| Step: 2
Training loss: 0.43173851870858376
Validation loss: 3.1422122721025167

Epoch: 6| Step: 3
Training loss: 0.36705414399791925
Validation loss: 3.1408826681182567

Epoch: 6| Step: 4
Training loss: 0.40897611957660074
Validation loss: 3.176639805253559

Epoch: 6| Step: 5
Training loss: 0.2611458899933234
Validation loss: 3.0805198273699945

Epoch: 6| Step: 6
Training loss: 0.9252590203411125
Validation loss: 3.124587260646228

Epoch: 6| Step: 7
Training loss: 0.342469224399865
Validation loss: 3.1131319132255006

Epoch: 6| Step: 8
Training loss: 0.3538255123649256
Validation loss: 3.0444278638470204

Epoch: 6| Step: 9
Training loss: 0.42385296375250525
Validation loss: 3.029925184679625

Epoch: 6| Step: 10
Training loss: 0.5648044957704704
Validation loss: 3.0897375989604834

Epoch: 6| Step: 11
Training loss: 0.2432199283754127
Validation loss: 3.1263255296257193

Epoch: 6| Step: 12
Training loss: 0.4227950694910052
Validation loss: 3.123907979262804

Epoch: 6| Step: 13
Training loss: 0.3994915054716818
Validation loss: 3.202805020857124

Epoch: 246| Step: 0
Training loss: 0.36730739989674266
Validation loss: 3.1571549984559373

Epoch: 6| Step: 1
Training loss: 0.3739757856088289
Validation loss: 3.156567057179612

Epoch: 6| Step: 2
Training loss: 0.3738287077672994
Validation loss: 3.0966562434439546

Epoch: 6| Step: 3
Training loss: 0.3264940463877129
Validation loss: 3.0729187572062653

Epoch: 6| Step: 4
Training loss: 0.3261984511644172
Validation loss: 3.0347832999253

Epoch: 6| Step: 5
Training loss: 0.4354010881104144
Validation loss: 3.0502576521144964

Epoch: 6| Step: 6
Training loss: 0.5148881212948707
Validation loss: 3.0392467047428284

Epoch: 6| Step: 7
Training loss: 1.05921737488487
Validation loss: 2.9966681309895518

Epoch: 6| Step: 8
Training loss: 0.3937850164556186
Validation loss: 3.1399879758446683

Epoch: 6| Step: 9
Training loss: 0.2887668257306956
Validation loss: 3.118363377745621

Epoch: 6| Step: 10
Training loss: 0.5081658527801058
Validation loss: 3.1965428154600612

Epoch: 6| Step: 11
Training loss: 0.4175083262646906
Validation loss: 3.2167214603072636

Epoch: 6| Step: 12
Training loss: 0.6221275602674697
Validation loss: 3.165210983250819

Epoch: 6| Step: 13
Training loss: 0.5260722337157416
Validation loss: 3.2014610000142154

Epoch: 247| Step: 0
Training loss: 0.4357417060032078
Validation loss: 3.1660712753196276

Epoch: 6| Step: 1
Training loss: 0.4282305900508627
Validation loss: 3.1315452314676704

Epoch: 6| Step: 2
Training loss: 0.42933505082058393
Validation loss: 3.0762853918373803

Epoch: 6| Step: 3
Training loss: 0.27412410091630174
Validation loss: 3.05662225589778

Epoch: 6| Step: 4
Training loss: 0.33687916450544997
Validation loss: 3.081864720347191

Epoch: 6| Step: 5
Training loss: 0.9629962545957845
Validation loss: 3.1453104195080197

Epoch: 6| Step: 6
Training loss: 0.3893471798517995
Validation loss: 3.140515149980506

Epoch: 6| Step: 7
Training loss: 0.36719829462295317
Validation loss: 3.1113836168160645

Epoch: 6| Step: 8
Training loss: 0.338184614672925
Validation loss: 3.129721685696741

Epoch: 6| Step: 9
Training loss: 0.5528073212169152
Validation loss: 3.2308004778619006

Epoch: 6| Step: 10
Training loss: 0.36258959813902464
Validation loss: 3.1606325750126283

Epoch: 6| Step: 11
Training loss: 0.33530180689176664
Validation loss: 3.1827025868797043

Epoch: 6| Step: 12
Training loss: 0.39427779337267355
Validation loss: 3.145525776226453

Epoch: 6| Step: 13
Training loss: 0.26865747045452965
Validation loss: 3.0987138069340205

Epoch: 248| Step: 0
Training loss: 0.37038794203749853
Validation loss: 3.041619004350803

Epoch: 6| Step: 1
Training loss: 0.34876169766185827
Validation loss: 3.052766213603896

Epoch: 6| Step: 2
Training loss: 0.2720365466369644
Validation loss: 3.1531021485321347

Epoch: 6| Step: 3
Training loss: 0.2933801178894155
Validation loss: 3.0613932004379283

Epoch: 6| Step: 4
Training loss: 0.38545167824091214
Validation loss: 3.1045962213550706

Epoch: 6| Step: 5
Training loss: 0.8191513199078475
Validation loss: 3.1361106831073795

Epoch: 6| Step: 6
Training loss: 0.5003623245657882
Validation loss: 3.142254762389621

Epoch: 6| Step: 7
Training loss: 0.22150848096020745
Validation loss: 3.1004617372803356

Epoch: 6| Step: 8
Training loss: 0.31370930335562464
Validation loss: 3.1046534845657865

Epoch: 6| Step: 9
Training loss: 0.5624285758554972
Validation loss: 3.139947125360232

Epoch: 6| Step: 10
Training loss: 0.513175463407884
Validation loss: 3.1377249972659507

Epoch: 6| Step: 11
Training loss: 0.4010911535306078
Validation loss: 3.116598189888551

Epoch: 6| Step: 12
Training loss: 0.36665028983447645
Validation loss: 3.0883667088444904

Epoch: 6| Step: 13
Training loss: 0.4497163587300785
Validation loss: 3.0538005402971273

Epoch: 249| Step: 0
Training loss: 0.24507023639039943
Validation loss: 3.088464453998798

Epoch: 6| Step: 1
Training loss: 0.375488261407621
Validation loss: 3.147909860121822

Epoch: 6| Step: 2
Training loss: 0.484765372326191
Validation loss: 3.1153209072360184

Epoch: 6| Step: 3
Training loss: 0.4969475975023069
Validation loss: 3.154594150703199

Epoch: 6| Step: 4
Training loss: 0.33010858474227345
Validation loss: 3.0984726383629724

Epoch: 6| Step: 5
Training loss: 0.3848650460153156
Validation loss: 3.084217090938323

Epoch: 6| Step: 6
Training loss: 0.5955627776365566
Validation loss: 3.1975291179875143

Epoch: 6| Step: 7
Training loss: 0.4179011316952303
Validation loss: 3.1132807011685593

Epoch: 6| Step: 8
Training loss: 0.39750258768786856
Validation loss: 3.124680184847488

Epoch: 6| Step: 9
Training loss: 0.2818541660348783
Validation loss: 3.1043228434418184

Epoch: 6| Step: 10
Training loss: 0.9032220240551665
Validation loss: 3.108036897107258

Epoch: 6| Step: 11
Training loss: 0.3846713497635988
Validation loss: 3.0645758671327084

Epoch: 6| Step: 12
Training loss: 0.41957528648628073
Validation loss: 3.0992589895541602

Epoch: 6| Step: 13
Training loss: 0.4230234796566051
Validation loss: 3.0333537899277725

Epoch: 250| Step: 0
Training loss: 0.4067475316711916
Validation loss: 3.113198745508622

Epoch: 6| Step: 1
Training loss: 0.2897538089271449
Validation loss: 3.0528995520482227

Epoch: 6| Step: 2
Training loss: 0.47304997714826535
Validation loss: 3.0712654634427214

Epoch: 6| Step: 3
Training loss: 0.4129370382706786
Validation loss: 3.1187727617084255

Epoch: 6| Step: 4
Training loss: 0.35231762427595636
Validation loss: 3.0099730555277824

Epoch: 6| Step: 5
Training loss: 0.3788716998521332
Validation loss: 3.0374571835151896

Epoch: 6| Step: 6
Training loss: 0.43298417277625817
Validation loss: 3.1029699608884167

Epoch: 6| Step: 7
Training loss: 0.9102734338855076
Validation loss: 3.0138392588391163

Epoch: 6| Step: 8
Training loss: 0.31227239426296893
Validation loss: 3.169312730991299

Epoch: 6| Step: 9
Training loss: 0.5807292636021646
Validation loss: 3.0120074063320215

Epoch: 6| Step: 10
Training loss: 0.5946131004504484
Validation loss: 3.1158015102636245

Epoch: 6| Step: 11
Training loss: 0.333948378826061
Validation loss: 3.076709751152605

Epoch: 6| Step: 12
Training loss: 0.3999584936422546
Validation loss: 3.1588817992525726

Epoch: 6| Step: 13
Training loss: 0.4366270791404796
Validation loss: 3.0710045420427687

Epoch: 251| Step: 0
Training loss: 0.35922293970453156
Validation loss: 3.124863761475237

Epoch: 6| Step: 1
Training loss: 0.362368616597277
Validation loss: 3.0757637713956862

Epoch: 6| Step: 2
Training loss: 0.328783056606075
Validation loss: 3.0847521601890247

Epoch: 6| Step: 3
Training loss: 0.428774262011515
Validation loss: 3.0970576294375887

Epoch: 6| Step: 4
Training loss: 0.3281331061315609
Validation loss: 3.0919408164271855

Epoch: 6| Step: 5
Training loss: 0.41768882861304957
Validation loss: 3.0620291990287005

Epoch: 6| Step: 6
Training loss: 0.3050456631786894
Validation loss: 3.117933102879238

Epoch: 6| Step: 7
Training loss: 0.49424747020573756
Validation loss: 3.1414943143550396

Epoch: 6| Step: 8
Training loss: 0.4390656522047168
Validation loss: 3.1143024704941933

Epoch: 6| Step: 9
Training loss: 0.3067481708845153
Validation loss: 3.2245451475817686

Epoch: 6| Step: 10
Training loss: 0.45616336483341724
Validation loss: 3.2831170598235504

Epoch: 6| Step: 11
Training loss: 0.3191034596536562
Validation loss: 3.1933394902939134

Epoch: 6| Step: 12
Training loss: 0.8473280170097818
Validation loss: 3.1427844769883326

Epoch: 6| Step: 13
Training loss: 0.29918441226832965
Validation loss: 3.088139581265639

Epoch: 252| Step: 0
Training loss: 0.2796713312899179
Validation loss: 3.1591874104345967

Epoch: 6| Step: 1
Training loss: 0.41412144367361736
Validation loss: 3.0983147003519167

Epoch: 6| Step: 2
Training loss: 0.8715301925673008
Validation loss: 3.107571856997026

Epoch: 6| Step: 3
Training loss: 0.6136196684894217
Validation loss: 3.10528252960972

Epoch: 6| Step: 4
Training loss: 0.2717285430442063
Validation loss: 3.0900758189145163

Epoch: 6| Step: 5
Training loss: 0.3446866733717496
Validation loss: 3.150572640477637

Epoch: 6| Step: 6
Training loss: 0.3095762089790495
Validation loss: 3.178251937486741

Epoch: 6| Step: 7
Training loss: 0.5329884806223776
Validation loss: 3.151347453935575

Epoch: 6| Step: 8
Training loss: 0.6276099071530346
Validation loss: 3.1338725211161953

Epoch: 6| Step: 9
Training loss: 0.5304897141281882
Validation loss: 3.2034556210470853

Epoch: 6| Step: 10
Training loss: 0.31599557386238014
Validation loss: 3.108362758350611

Epoch: 6| Step: 11
Training loss: 0.329723427157346
Validation loss: 3.1130491750157896

Epoch: 6| Step: 12
Training loss: 0.23288651512330455
Validation loss: 3.091582158485459

Epoch: 6| Step: 13
Training loss: 0.485156889468154
Validation loss: 3.089699865206932

Epoch: 253| Step: 0
Training loss: 0.35453960007055413
Validation loss: 3.080240416701032

Epoch: 6| Step: 1
Training loss: 0.40268039508113007
Validation loss: 3.0508180063323405

Epoch: 6| Step: 2
Training loss: 0.7948587753408518
Validation loss: 3.0321884930975407

Epoch: 6| Step: 3
Training loss: 0.452495927528897
Validation loss: 3.0577442196002895

Epoch: 6| Step: 4
Training loss: 0.35150772303769445
Validation loss: 3.140998527114395

Epoch: 6| Step: 5
Training loss: 0.4358778068390844
Validation loss: 3.1924550804935112

Epoch: 6| Step: 6
Training loss: 0.367243965352533
Validation loss: 3.1194796822802324

Epoch: 6| Step: 7
Training loss: 0.30268317989501403
Validation loss: 3.1226272476041808

Epoch: 6| Step: 8
Training loss: 0.35975966391662445
Validation loss: 3.1523660235935727

Epoch: 6| Step: 9
Training loss: 0.4785569776455793
Validation loss: 3.1299649152932356

Epoch: 6| Step: 10
Training loss: 0.36591565243649876
Validation loss: 3.005062203295068

Epoch: 6| Step: 11
Training loss: 0.332660863476141
Validation loss: 3.0851813762173244

Epoch: 6| Step: 12
Training loss: 0.4927776371266249
Validation loss: 3.029731540579525

Epoch: 6| Step: 13
Training loss: 0.6237751402595121
Validation loss: 2.975704373125872

Epoch: 254| Step: 0
Training loss: 0.39327428782032847
Validation loss: 3.0755217076019585

Epoch: 6| Step: 1
Training loss: 0.32457194565828
Validation loss: 3.0854308022212416

Epoch: 6| Step: 2
Training loss: 0.30244064848290353
Validation loss: 3.130191953153908

Epoch: 6| Step: 3
Training loss: 0.4760264524314371
Validation loss: 3.158255717213746

Epoch: 6| Step: 4
Training loss: 0.27642677392662085
Validation loss: 3.1529015130751437

Epoch: 6| Step: 5
Training loss: 0.37283319075309834
Validation loss: 3.176965671716062

Epoch: 6| Step: 6
Training loss: 0.4323385129004106
Validation loss: 3.131376271801425

Epoch: 6| Step: 7
Training loss: 0.814066550451588
Validation loss: 3.154953970636323

Epoch: 6| Step: 8
Training loss: 0.31542792777406176
Validation loss: 3.1054000878890644

Epoch: 6| Step: 9
Training loss: 0.3686672990809622
Validation loss: 3.100245826470037

Epoch: 6| Step: 10
Training loss: 0.4218457176501151
Validation loss: 3.1699451908704286

Epoch: 6| Step: 11
Training loss: 0.4559896941505296
Validation loss: 3.0667973813587883

Epoch: 6| Step: 12
Training loss: 0.5224843813190798
Validation loss: 3.074223700539183

Epoch: 6| Step: 13
Training loss: 0.31592050401003463
Validation loss: 3.1404990681820624

Epoch: 255| Step: 0
Training loss: 0.3618372449137778
Validation loss: 3.1018258470633477

Epoch: 6| Step: 1
Training loss: 0.3079600769478424
Validation loss: 3.179260725144007

Epoch: 6| Step: 2
Training loss: 0.45051192860999867
Validation loss: 3.2055818889057113

Epoch: 6| Step: 3
Training loss: 0.4739586879044209
Validation loss: 3.1523388843270355

Epoch: 6| Step: 4
Training loss: 0.280406747409214
Validation loss: 3.178007064526602

Epoch: 6| Step: 5
Training loss: 0.3399097115530752
Validation loss: 3.17471122780145

Epoch: 6| Step: 6
Training loss: 0.3273837709202339
Validation loss: 3.090567547836624

Epoch: 6| Step: 7
Training loss: 0.29242922376957864
Validation loss: 3.1166864819500244

Epoch: 6| Step: 8
Training loss: 0.38950335638781713
Validation loss: 3.1185225939612873

Epoch: 6| Step: 9
Training loss: 0.507120306249518
Validation loss: 3.15734985123429

Epoch: 6| Step: 10
Training loss: 0.3353125170114874
Validation loss: 3.158925549653744

Epoch: 6| Step: 11
Training loss: 0.3564257472691124
Validation loss: 3.1408752291111717

Epoch: 6| Step: 12
Training loss: 0.8868692413207635
Validation loss: 3.1200372835931223

Epoch: 6| Step: 13
Training loss: 0.3320372861425711
Validation loss: 3.202062961080883

Epoch: 256| Step: 0
Training loss: 0.4017768866462364
Validation loss: 3.2844424748045586

Epoch: 6| Step: 1
Training loss: 0.4955976513776941
Validation loss: 3.1377163730092232

Epoch: 6| Step: 2
Training loss: 0.3560107155336419
Validation loss: 3.129630790319819

Epoch: 6| Step: 3
Training loss: 0.40586684571660947
Validation loss: 3.129483338411974

Epoch: 6| Step: 4
Training loss: 0.29880528580893956
Validation loss: 3.0548088849626165

Epoch: 6| Step: 5
Training loss: 0.3770663827525169
Validation loss: 3.048562102815773

Epoch: 6| Step: 6
Training loss: 0.2880402350947249
Validation loss: 3.104388598161477

Epoch: 6| Step: 7
Training loss: 0.9124566342226095
Validation loss: 3.0597896779361404

Epoch: 6| Step: 8
Training loss: 0.5097101992587489
Validation loss: 3.0774212208551925

Epoch: 6| Step: 9
Training loss: 0.3584443980170997
Validation loss: 3.125300748976088

Epoch: 6| Step: 10
Training loss: 0.2264110124507029
Validation loss: 3.1671126369517015

Epoch: 6| Step: 11
Training loss: 0.34568443894397466
Validation loss: 3.147307894547829

Epoch: 6| Step: 12
Training loss: 0.3878728042304351
Validation loss: 3.0998383925983046

Epoch: 6| Step: 13
Training loss: 0.26492202524795705
Validation loss: 3.1092841615938305

Epoch: 257| Step: 0
Training loss: 0.8260030371030526
Validation loss: 3.1399289778555777

Epoch: 6| Step: 1
Training loss: 0.48143214271592494
Validation loss: 3.1420625651375125

Epoch: 6| Step: 2
Training loss: 0.2969529902762228
Validation loss: 3.08600206267345

Epoch: 6| Step: 3
Training loss: 0.4126471856539772
Validation loss: 3.1024906233513407

Epoch: 6| Step: 4
Training loss: 0.39975334251490274
Validation loss: 3.1533103195288845

Epoch: 6| Step: 5
Training loss: 0.37132799886536416
Validation loss: 3.121402679037512

Epoch: 6| Step: 6
Training loss: 0.4420769078018139
Validation loss: 3.1839164960340995

Epoch: 6| Step: 7
Training loss: 0.40128104591884317
Validation loss: 3.173651412348118

Epoch: 6| Step: 8
Training loss: 0.3645342475908484
Validation loss: 3.2405300208617356

Epoch: 6| Step: 9
Training loss: 0.42549879872279145
Validation loss: 3.1609273063380905

Epoch: 6| Step: 10
Training loss: 0.5353248776030913
Validation loss: 3.2345476334797594

Epoch: 6| Step: 11
Training loss: 0.44599998677899466
Validation loss: 3.190763822070548

Epoch: 6| Step: 12
Training loss: 0.3658959420026313
Validation loss: 3.2250813924883257

Epoch: 6| Step: 13
Training loss: 0.44826829954729197
Validation loss: 3.1559105870015065

Epoch: 258| Step: 0
Training loss: 0.44712070965968076
Validation loss: 3.1095888712826567

Epoch: 6| Step: 1
Training loss: 0.35611971262966396
Validation loss: 3.1542694248071896

Epoch: 6| Step: 2
Training loss: 0.2639833659039595
Validation loss: 3.1925761375419506

Epoch: 6| Step: 3
Training loss: 0.3467668020912289
Validation loss: 3.103976088099122

Epoch: 6| Step: 4
Training loss: 0.28332729905845955
Validation loss: 3.198612116805542

Epoch: 6| Step: 5
Training loss: 0.4592984200568571
Validation loss: 3.1634571893587946

Epoch: 6| Step: 6
Training loss: 0.5413598022793961
Validation loss: 3.090439576236411

Epoch: 6| Step: 7
Training loss: 0.3266433232507797
Validation loss: 3.1591973470816312

Epoch: 6| Step: 8
Training loss: 0.7934546274002048
Validation loss: 3.1550033927613086

Epoch: 6| Step: 9
Training loss: 0.2508496212080311
Validation loss: 3.117244531911244

Epoch: 6| Step: 10
Training loss: 0.36281703699710366
Validation loss: 3.1760300354678397

Epoch: 6| Step: 11
Training loss: 0.5497848480060039
Validation loss: 3.187781838815977

Epoch: 6| Step: 12
Training loss: 0.31831214414015285
Validation loss: 3.1405797926652474

Epoch: 6| Step: 13
Training loss: 0.2907967480398947
Validation loss: 3.147389908921312

Epoch: 259| Step: 0
Training loss: 0.4187928569270615
Validation loss: 3.096769920437182

Epoch: 6| Step: 1
Training loss: 0.3534952547727434
Validation loss: 3.153766246526508

Epoch: 6| Step: 2
Training loss: 0.5290980229447694
Validation loss: 3.145480424567717

Epoch: 6| Step: 3
Training loss: 0.23967088347061472
Validation loss: 3.1832200156675894

Epoch: 6| Step: 4
Training loss: 0.40402238161343146
Validation loss: 3.14590174030091

Epoch: 6| Step: 5
Training loss: 0.339767425560407
Validation loss: 3.220418651841948

Epoch: 6| Step: 6
Training loss: 0.3632231019767024
Validation loss: 3.2045620431681767

Epoch: 6| Step: 7
Training loss: 0.39167001178341043
Validation loss: 3.112240095917609

Epoch: 6| Step: 8
Training loss: 0.3849890394322659
Validation loss: 3.2186039024207846

Epoch: 6| Step: 9
Training loss: 0.83333467642358
Validation loss: 3.1386196382959324

Epoch: 6| Step: 10
Training loss: 0.3396096354909828
Validation loss: 3.090566364962544

Epoch: 6| Step: 11
Training loss: 0.28664012111433423
Validation loss: 3.12898684178389

Epoch: 6| Step: 12
Training loss: 0.28530879708735685
Validation loss: 3.071461004104976

Epoch: 6| Step: 13
Training loss: 0.667413871473344
Validation loss: 3.119872820801168

Epoch: 260| Step: 0
Training loss: 0.3776102810945609
Validation loss: 3.1013891009873404

Epoch: 6| Step: 1
Training loss: 0.31012484826311415
Validation loss: 3.1746371039306904

Epoch: 6| Step: 2
Training loss: 0.3114504235304107
Validation loss: 3.1465493623102687

Epoch: 6| Step: 3
Training loss: 0.4456033258932081
Validation loss: 3.178188123548119

Epoch: 6| Step: 4
Training loss: 0.34720717582950694
Validation loss: 3.2498882103302815

Epoch: 6| Step: 5
Training loss: 0.5763786849940519
Validation loss: 3.265121250753919

Epoch: 6| Step: 6
Training loss: 0.3213034281664117
Validation loss: 3.1826262269579875

Epoch: 6| Step: 7
Training loss: 0.3369706590080649
Validation loss: 3.2049517501039837

Epoch: 6| Step: 8
Training loss: 0.35158676487577994
Validation loss: 3.0798269043209925

Epoch: 6| Step: 9
Training loss: 0.33719216630763194
Validation loss: 3.0635685127134393

Epoch: 6| Step: 10
Training loss: 0.36965271080696976
Validation loss: 3.021722377748161

Epoch: 6| Step: 11
Training loss: 0.7769321137699506
Validation loss: 3.1457899271684098

Epoch: 6| Step: 12
Training loss: 0.27962372068624936
Validation loss: 3.101512328798269

Epoch: 6| Step: 13
Training loss: 0.356652750768018
Validation loss: 3.105962929102605

Epoch: 261| Step: 0
Training loss: 0.41205466390895035
Validation loss: 3.166643811862855

Epoch: 6| Step: 1
Training loss: 0.48366186497305264
Validation loss: 3.167585231333812

Epoch: 6| Step: 2
Training loss: 0.36743143785033855
Validation loss: 3.1662802125794784

Epoch: 6| Step: 3
Training loss: 0.4515189450124062
Validation loss: 3.21315251513057

Epoch: 6| Step: 4
Training loss: 0.3365473755897806
Validation loss: 3.0959904582495117

Epoch: 6| Step: 5
Training loss: 0.4250649016976708
Validation loss: 3.086560974234008

Epoch: 6| Step: 6
Training loss: 0.33930130121452085
Validation loss: 3.087528285516036

Epoch: 6| Step: 7
Training loss: 0.3433224772134302
Validation loss: 3.0480374849213847

Epoch: 6| Step: 8
Training loss: 0.8465877777865619
Validation loss: 3.0094632197541573

Epoch: 6| Step: 9
Training loss: 0.5498249328029753
Validation loss: 3.049774902667359

Epoch: 6| Step: 10
Training loss: 0.3909321912226662
Validation loss: 3.045662741486915

Epoch: 6| Step: 11
Training loss: 0.3158588147683262
Validation loss: 3.1574151938218002

Epoch: 6| Step: 12
Training loss: 0.5316431610248742
Validation loss: 3.1185281240142997

Epoch: 6| Step: 13
Training loss: 0.40222399512682366
Validation loss: 3.1600677138328717

Epoch: 262| Step: 0
Training loss: 0.38519352390147554
Validation loss: 3.0911711788450673

Epoch: 6| Step: 1
Training loss: 0.4323251052547488
Validation loss: 3.161394616144274

Epoch: 6| Step: 2
Training loss: 0.367011007544063
Validation loss: 3.2133923603574774

Epoch: 6| Step: 3
Training loss: 0.35337121659012094
Validation loss: 3.094488498899975

Epoch: 6| Step: 4
Training loss: 0.2914594300044716
Validation loss: 3.140036304774245

Epoch: 6| Step: 5
Training loss: 0.5253050213246819
Validation loss: 3.1437616832154562

Epoch: 6| Step: 6
Training loss: 0.29784982399354953
Validation loss: 3.1890416998327407

Epoch: 6| Step: 7
Training loss: 0.7507955385053215
Validation loss: 3.1609775778894287

Epoch: 6| Step: 8
Training loss: 0.43565618742703
Validation loss: 3.138333245181344

Epoch: 6| Step: 9
Training loss: 0.39585371550569803
Validation loss: 3.121663423126811

Epoch: 6| Step: 10
Training loss: 0.40529079170298626
Validation loss: 3.1435654951978123

Epoch: 6| Step: 11
Training loss: 0.31523753593590137
Validation loss: 3.18191582707443

Epoch: 6| Step: 12
Training loss: 0.5014829103062473
Validation loss: 3.1380193855419485

Epoch: 6| Step: 13
Training loss: 0.34623597454075306
Validation loss: 3.162689049037141

Epoch: 263| Step: 0
Training loss: 0.31835726871846853
Validation loss: 3.1433355297095784

Epoch: 6| Step: 1
Training loss: 0.3832354641799856
Validation loss: 3.156852412883458

Epoch: 6| Step: 2
Training loss: 0.27019515715458514
Validation loss: 3.073530107895879

Epoch: 6| Step: 3
Training loss: 0.3703069276028275
Validation loss: 3.1440248954416603

Epoch: 6| Step: 4
Training loss: 0.429584733638214
Validation loss: 3.0294673436380584

Epoch: 6| Step: 5
Training loss: 0.34407275393362075
Validation loss: 3.1507554021434525

Epoch: 6| Step: 6
Training loss: 0.9051933047353383
Validation loss: 3.073866582052949

Epoch: 6| Step: 7
Training loss: 0.30944549739906957
Validation loss: 3.1241534803154107

Epoch: 6| Step: 8
Training loss: 0.2453281361158541
Validation loss: 3.132716417622894

Epoch: 6| Step: 9
Training loss: 0.518004878468536
Validation loss: 3.13159726895486

Epoch: 6| Step: 10
Training loss: 0.36522970349593314
Validation loss: 3.1585835306582712

Epoch: 6| Step: 11
Training loss: 0.588218369485902
Validation loss: 3.104453327503328

Epoch: 6| Step: 12
Training loss: 0.354847459391561
Validation loss: 3.067095494003728

Epoch: 6| Step: 13
Training loss: 0.43332304537310334
Validation loss: 3.1158804770575443

Epoch: 264| Step: 0
Training loss: 0.45681322228044097
Validation loss: 3.048272436780588

Epoch: 6| Step: 1
Training loss: 0.26137169558836676
Validation loss: 3.010498934526967

Epoch: 6| Step: 2
Training loss: 0.8341423796231296
Validation loss: 3.061991967342479

Epoch: 6| Step: 3
Training loss: 0.6202967106037166
Validation loss: 3.1191871112503717

Epoch: 6| Step: 4
Training loss: 0.26744083028664595
Validation loss: 3.1106684053772886

Epoch: 6| Step: 5
Training loss: 0.35052057150972216
Validation loss: 3.1339348790508055

Epoch: 6| Step: 6
Training loss: 0.314845545174377
Validation loss: 3.215966178210891

Epoch: 6| Step: 7
Training loss: 0.40340160446571327
Validation loss: 3.2490891378395004

Epoch: 6| Step: 8
Training loss: 0.3752214254876566
Validation loss: 3.1989649608712756

Epoch: 6| Step: 9
Training loss: 0.4199865956665174
Validation loss: 3.125781876979423

Epoch: 6| Step: 10
Training loss: 0.29143943904433717
Validation loss: 3.072056605784451

Epoch: 6| Step: 11
Training loss: 0.41699129412731806
Validation loss: 3.061224963956913

Epoch: 6| Step: 12
Training loss: 0.519220847424918
Validation loss: 3.012906260552678

Epoch: 6| Step: 13
Training loss: 0.49923461208306236
Validation loss: 2.9683944489236325

Epoch: 265| Step: 0
Training loss: 0.3707135712545573
Validation loss: 3.079946440544795

Epoch: 6| Step: 1
Training loss: 0.2746303968129349
Validation loss: 3.0471771481670378

Epoch: 6| Step: 2
Training loss: 0.30837078731537054
Validation loss: 3.019820685947375

Epoch: 6| Step: 3
Training loss: 0.29898635564566184
Validation loss: 3.122159837082173

Epoch: 6| Step: 4
Training loss: 0.3413054830384833
Validation loss: 3.1152483167505753

Epoch: 6| Step: 5
Training loss: 0.39331899547441646
Validation loss: 3.1977218088102233

Epoch: 6| Step: 6
Training loss: 0.2761505140274571
Validation loss: 3.106861920019383

Epoch: 6| Step: 7
Training loss: 0.3082765083315686
Validation loss: 3.1004770527141043

Epoch: 6| Step: 8
Training loss: 0.34299481408005184
Validation loss: 3.155858069028197

Epoch: 6| Step: 9
Training loss: 0.506796686493821
Validation loss: 3.122564358441219

Epoch: 6| Step: 10
Training loss: 0.3527659270072415
Validation loss: 3.1552021943808515

Epoch: 6| Step: 11
Training loss: 0.7900343471617434
Validation loss: 3.059836052926127

Epoch: 6| Step: 12
Training loss: 0.32771557286813036
Validation loss: 3.049899186620499

Epoch: 6| Step: 13
Training loss: 0.25497956467537236
Validation loss: 3.1350878715266988

Epoch: 266| Step: 0
Training loss: 0.37462489918353276
Validation loss: 3.138860418721345

Epoch: 6| Step: 1
Training loss: 0.3115706213731517
Validation loss: 3.1112645221155186

Epoch: 6| Step: 2
Training loss: 0.33705601673267754
Validation loss: 3.1206325147230025

Epoch: 6| Step: 3
Training loss: 0.42712597711622713
Validation loss: 3.1827470211184608

Epoch: 6| Step: 4
Training loss: 0.7830432909499379
Validation loss: 3.0881527703565297

Epoch: 6| Step: 5
Training loss: 0.3769773959711798
Validation loss: 3.0751300319067427

Epoch: 6| Step: 6
Training loss: 0.23660362358637776
Validation loss: 3.108473591201093

Epoch: 6| Step: 7
Training loss: 0.434216679049588
Validation loss: 3.057670730061917

Epoch: 6| Step: 8
Training loss: 0.32214445668362024
Validation loss: 3.077248927890443

Epoch: 6| Step: 9
Training loss: 0.3147773966194094
Validation loss: 3.113495746340709

Epoch: 6| Step: 10
Training loss: 0.3108764195473061
Validation loss: 3.1210200587912142

Epoch: 6| Step: 11
Training loss: 0.3856962152441268
Validation loss: 3.1623894432153508

Epoch: 6| Step: 12
Training loss: 0.37030282309720813
Validation loss: 3.0986424047315815

Epoch: 6| Step: 13
Training loss: 0.47651215584411466
Validation loss: 3.073614918317207

Epoch: 267| Step: 0
Training loss: 0.3720627431024455
Validation loss: 3.0820281556939473

Epoch: 6| Step: 1
Training loss: 0.3726414379639007
Validation loss: 3.0784661092730237

Epoch: 6| Step: 2
Training loss: 0.3982360554999914
Validation loss: 3.1041689281754077

Epoch: 6| Step: 3
Training loss: 0.4647464971025596
Validation loss: 3.137971987944317

Epoch: 6| Step: 4
Training loss: 0.2947890380409685
Validation loss: 3.02230048670439

Epoch: 6| Step: 5
Training loss: 0.4177541805927928
Validation loss: 3.1151747678915642

Epoch: 6| Step: 6
Training loss: 0.3595652076901712
Validation loss: 3.054231055094031

Epoch: 6| Step: 7
Training loss: 0.4077524499053609
Validation loss: 3.0640815621444

Epoch: 6| Step: 8
Training loss: 0.328141836461042
Validation loss: 3.1645533177097276

Epoch: 6| Step: 9
Training loss: 0.3726242427555901
Validation loss: 3.041297358907051

Epoch: 6| Step: 10
Training loss: 0.4600537767281582
Validation loss: 3.1481552060573805

Epoch: 6| Step: 11
Training loss: 0.7606993284872157
Validation loss: 3.1979839471124256

Epoch: 6| Step: 12
Training loss: 0.43971693809341467
Validation loss: 3.213024602722803

Epoch: 6| Step: 13
Training loss: 0.40456285803331277
Validation loss: 3.1280039400245

Epoch: 268| Step: 0
Training loss: 0.3405062149008623
Validation loss: 3.09276511188491

Epoch: 6| Step: 1
Training loss: 0.38762798733684156
Validation loss: 3.163371672389604

Epoch: 6| Step: 2
Training loss: 0.3303896771063549
Validation loss: 3.1396162016594533

Epoch: 6| Step: 3
Training loss: 0.7643544300521162
Validation loss: 3.154006437584938

Epoch: 6| Step: 4
Training loss: 0.3432453417500132
Validation loss: 3.1602075774586957

Epoch: 6| Step: 5
Training loss: 0.33732875788894023
Validation loss: 3.074217819349446

Epoch: 6| Step: 6
Training loss: 0.3106023151165886
Validation loss: 3.1492907280638893

Epoch: 6| Step: 7
Training loss: 0.3123840116778596
Validation loss: 3.079051180176398

Epoch: 6| Step: 8
Training loss: 0.334034408480172
Validation loss: 3.1529536265898983

Epoch: 6| Step: 9
Training loss: 0.3500787897493146
Validation loss: 3.077071911776211

Epoch: 6| Step: 10
Training loss: 0.5391874030438025
Validation loss: 3.0612751464101695

Epoch: 6| Step: 11
Training loss: 0.2808936696343506
Validation loss: 3.083592781973301

Epoch: 6| Step: 12
Training loss: 0.4539605362645981
Validation loss: 3.0243972713803746

Epoch: 6| Step: 13
Training loss: 0.31588665955947104
Validation loss: 3.080514177488413

Epoch: 269| Step: 0
Training loss: 0.27931146650278904
Validation loss: 3.108379645594901

Epoch: 6| Step: 1
Training loss: 0.4107657672029045
Validation loss: 3.086864206743574

Epoch: 6| Step: 2
Training loss: 0.4471308742582028
Validation loss: 3.1326489235401964

Epoch: 6| Step: 3
Training loss: 0.3223383619123499
Validation loss: 3.1005539619619267

Epoch: 6| Step: 4
Training loss: 0.2316544227929421
Validation loss: 3.1820438286420067

Epoch: 6| Step: 5
Training loss: 0.37850730579788505
Validation loss: 3.1599713410112074

Epoch: 6| Step: 6
Training loss: 0.3021344547204904
Validation loss: 3.1281999099506725

Epoch: 6| Step: 7
Training loss: 0.27982528425386444
Validation loss: 3.088386008514561

Epoch: 6| Step: 8
Training loss: 0.2956820159190678
Validation loss: 3.0315715317761502

Epoch: 6| Step: 9
Training loss: 0.34751848641629074
Validation loss: 3.14044109204571

Epoch: 6| Step: 10
Training loss: 0.4238729321399265
Validation loss: 3.159109186548318

Epoch: 6| Step: 11
Training loss: 0.376405585111456
Validation loss: 3.104693967508185

Epoch: 6| Step: 12
Training loss: 0.33758140482917076
Validation loss: 3.0779468594558277

Epoch: 6| Step: 13
Training loss: 0.759128803798292
Validation loss: 3.1410006145107086

Epoch: 270| Step: 0
Training loss: 0.43893870444541955
Validation loss: 3.1215489468948765

Epoch: 6| Step: 1
Training loss: 0.4198702758314333
Validation loss: 3.0795517662996303

Epoch: 6| Step: 2
Training loss: 0.23058771845203954
Validation loss: 3.132375697810284

Epoch: 6| Step: 3
Training loss: 0.39311911661933985
Validation loss: 3.1825260673308424

Epoch: 6| Step: 4
Training loss: 0.4468576994794862
Validation loss: 3.1779912849836527

Epoch: 6| Step: 5
Training loss: 0.3857891199074777
Validation loss: 3.2153372712166237

Epoch: 6| Step: 6
Training loss: 0.49743957893041646
Validation loss: 3.192392558692392

Epoch: 6| Step: 7
Training loss: 0.31609489286086956
Validation loss: 3.213039233201962

Epoch: 6| Step: 8
Training loss: 0.34192486137874867
Validation loss: 3.1301377722752517

Epoch: 6| Step: 9
Training loss: 0.35522347676204746
Validation loss: 3.1317656711062343

Epoch: 6| Step: 10
Training loss: 0.28961263320855907
Validation loss: 3.1282362393198726

Epoch: 6| Step: 11
Training loss: 0.7544377484334222
Validation loss: 3.098658331874049

Epoch: 6| Step: 12
Training loss: 0.3355734871202225
Validation loss: 3.0720814016910305

Epoch: 6| Step: 13
Training loss: 0.3923879703773255
Validation loss: 3.058476952100564

Epoch: 271| Step: 0
Training loss: 0.40252627704570126
Validation loss: 3.0971858279528055

Epoch: 6| Step: 1
Training loss: 0.4923577695331727
Validation loss: 3.0115250435698355

Epoch: 6| Step: 2
Training loss: 0.2674550518259096
Validation loss: 3.106970824045002

Epoch: 6| Step: 3
Training loss: 0.3626054199439642
Validation loss: 3.0564938641010277

Epoch: 6| Step: 4
Training loss: 0.3642123810200219
Validation loss: 3.1355519735515753

Epoch: 6| Step: 5
Training loss: 0.36205371482406823
Validation loss: 3.127345171561273

Epoch: 6| Step: 6
Training loss: 0.8363530204734371
Validation loss: 3.1532918582820546

Epoch: 6| Step: 7
Training loss: 0.19152768817551732
Validation loss: 3.1568259919095314

Epoch: 6| Step: 8
Training loss: 0.3692741959727659
Validation loss: 3.1628109564210645

Epoch: 6| Step: 9
Training loss: 0.3837765990119023
Validation loss: 3.1396187456070734

Epoch: 6| Step: 10
Training loss: 0.3777917417971646
Validation loss: 3.132738982976626

Epoch: 6| Step: 11
Training loss: 0.4306443398040231
Validation loss: 3.1641988842616384

Epoch: 6| Step: 12
Training loss: 0.4590037564994497
Validation loss: 3.1011103917917624

Epoch: 6| Step: 13
Training loss: 0.23123349182385047
Validation loss: 3.122313018201144

Epoch: 272| Step: 0
Training loss: 0.28846490793827817
Validation loss: 3.1319198287894987

Epoch: 6| Step: 1
Training loss: 0.36508612250317884
Validation loss: 3.128416126993533

Epoch: 6| Step: 2
Training loss: 0.2728324736005054
Validation loss: 3.11850095785319

Epoch: 6| Step: 3
Training loss: 0.32946053688155397
Validation loss: 3.1275206635969313

Epoch: 6| Step: 4
Training loss: 0.3959507098926067
Validation loss: 3.0787790445931686

Epoch: 6| Step: 5
Training loss: 0.3265414171851106
Validation loss: 3.129224769740274

Epoch: 6| Step: 6
Training loss: 0.4649445400440902
Validation loss: 3.1617803184447353

Epoch: 6| Step: 7
Training loss: 0.7423607874902207
Validation loss: 3.1285169266359745

Epoch: 6| Step: 8
Training loss: 0.37731595934144085
Validation loss: 3.1194087171862854

Epoch: 6| Step: 9
Training loss: 0.31190115054546075
Validation loss: 3.11960968522751

Epoch: 6| Step: 10
Training loss: 0.47597426710174046
Validation loss: 3.1282931460151877

Epoch: 6| Step: 11
Training loss: 0.39256789540489956
Validation loss: 3.096901351452194

Epoch: 6| Step: 12
Training loss: 0.2840187954408535
Validation loss: 3.1090338310535146

Epoch: 6| Step: 13
Training loss: 0.38597827881268437
Validation loss: 3.1531620972400956

Epoch: 273| Step: 0
Training loss: 0.45509305610229256
Validation loss: 3.165821267935333

Epoch: 6| Step: 1
Training loss: 0.48564957003009357
Validation loss: 3.0936183194994094

Epoch: 6| Step: 2
Training loss: 0.41520992576700805
Validation loss: 3.0654103081122916

Epoch: 6| Step: 3
Training loss: 0.2702770695040515
Validation loss: 3.114894115715972

Epoch: 6| Step: 4
Training loss: 0.25869082619647743
Validation loss: 3.109627028176211

Epoch: 6| Step: 5
Training loss: 0.23128800337628994
Validation loss: 3.0837330344312917

Epoch: 6| Step: 6
Training loss: 0.8603810057435314
Validation loss: 3.0753123540845637

Epoch: 6| Step: 7
Training loss: 0.402185205128487
Validation loss: 3.133872191445086

Epoch: 6| Step: 8
Training loss: 0.37648712765141945
Validation loss: 3.1173462281570905

Epoch: 6| Step: 9
Training loss: 0.4804831712000669
Validation loss: 3.13690781647032

Epoch: 6| Step: 10
Training loss: 0.3884586727113983
Validation loss: 3.1589462421999865

Epoch: 6| Step: 11
Training loss: 0.3418155665055197
Validation loss: 3.1381171036300377

Epoch: 6| Step: 12
Training loss: 0.3708318087014278
Validation loss: 3.215199978800129

Epoch: 6| Step: 13
Training loss: 0.37632483663264615
Validation loss: 3.069355356832857

Epoch: 274| Step: 0
Training loss: 0.30332656284040643
Validation loss: 3.178455210847574

Epoch: 6| Step: 1
Training loss: 0.2731102620170484
Validation loss: 3.181076783546381

Epoch: 6| Step: 2
Training loss: 0.4418568631972917
Validation loss: 3.1194328055009426

Epoch: 6| Step: 3
Training loss: 0.26629705120793284
Validation loss: 3.056393672891951

Epoch: 6| Step: 4
Training loss: 0.3263699164467664
Validation loss: 3.104056200626389

Epoch: 6| Step: 5
Training loss: 0.35551936449488325
Validation loss: 3.064807619297903

Epoch: 6| Step: 6
Training loss: 0.3630482736703828
Validation loss: 3.1084463499521107

Epoch: 6| Step: 7
Training loss: 0.3472562481844675
Validation loss: 3.176460321762321

Epoch: 6| Step: 8
Training loss: 0.3403519743627155
Validation loss: 3.203024017478957

Epoch: 6| Step: 9
Training loss: 0.34895497885083365
Validation loss: 3.18308996415345

Epoch: 6| Step: 10
Training loss: 0.34595949828408007
Validation loss: 3.1154401784937082

Epoch: 6| Step: 11
Training loss: 0.34633177371763135
Validation loss: 3.1408519757747304

Epoch: 6| Step: 12
Training loss: 0.3382543028919388
Validation loss: 3.0880992287314046

Epoch: 6| Step: 13
Training loss: 0.7405656863255189
Validation loss: 3.0994163281602747

Epoch: 275| Step: 0
Training loss: 0.332027996271684
Validation loss: 3.183648431538478

Epoch: 6| Step: 1
Training loss: 0.3178276348730045
Validation loss: 3.18012326415498

Epoch: 6| Step: 2
Training loss: 0.7619896822603813
Validation loss: 3.200659955536599

Epoch: 6| Step: 3
Training loss: 0.3886038562547982
Validation loss: 3.2439393607491573

Epoch: 6| Step: 4
Training loss: 0.363245952080884
Validation loss: 3.1661261590813976

Epoch: 6| Step: 5
Training loss: 0.3668074974983793
Validation loss: 3.1928727738731433

Epoch: 6| Step: 6
Training loss: 0.3823675177404202
Validation loss: 3.1264547395222677

Epoch: 6| Step: 7
Training loss: 0.3382101808033582
Validation loss: 3.184810401267665

Epoch: 6| Step: 8
Training loss: 0.23850579703531316
Validation loss: 3.1163975121729526

Epoch: 6| Step: 9
Training loss: 0.6350092963041326
Validation loss: 3.1052770591449352

Epoch: 6| Step: 10
Training loss: 0.3317770377476759
Validation loss: 3.176026607355532

Epoch: 6| Step: 11
Training loss: 0.2998266926496202
Validation loss: 3.1015174151393965

Epoch: 6| Step: 12
Training loss: 0.4705166269175852
Validation loss: 3.1763101022461746

Epoch: 6| Step: 13
Training loss: 0.2531746668420067
Validation loss: 3.1411164312051865

Epoch: 276| Step: 0
Training loss: 0.3751081866926683
Validation loss: 3.1519269703172177

Epoch: 6| Step: 1
Training loss: 0.3035085807385426
Validation loss: 3.160453515203649

Epoch: 6| Step: 2
Training loss: 0.3659915521251266
Validation loss: 3.210518363333747

Epoch: 6| Step: 3
Training loss: 0.35469793228738355
Validation loss: 3.1377937498540156

Epoch: 6| Step: 4
Training loss: 0.33037050829549947
Validation loss: 3.114659290386909

Epoch: 6| Step: 5
Training loss: 0.30437497469923475
Validation loss: 3.142321999565812

Epoch: 6| Step: 6
Training loss: 0.34684460438046466
Validation loss: 3.175440070424723

Epoch: 6| Step: 7
Training loss: 0.3980327495131303
Validation loss: 3.179753808182297

Epoch: 6| Step: 8
Training loss: 0.3675276824035904
Validation loss: 3.185168092724514

Epoch: 6| Step: 9
Training loss: 0.5635966366407619
Validation loss: 3.1484718415538504

Epoch: 6| Step: 10
Training loss: 0.27825750344947914
Validation loss: 3.1194979869617754

Epoch: 6| Step: 11
Training loss: 0.44286106691291993
Validation loss: 3.1609356786999534

Epoch: 6| Step: 12
Training loss: 0.30385810500112154
Validation loss: 3.1674259346339264

Epoch: 6| Step: 13
Training loss: 0.7295911280115605
Validation loss: 3.2478231328905616

Epoch: 277| Step: 0
Training loss: 0.6991000794024471
Validation loss: 3.2280228260435475

Epoch: 6| Step: 1
Training loss: 0.3143006778594125
Validation loss: 3.177962820340562

Epoch: 6| Step: 2
Training loss: 0.3324616727752497
Validation loss: 3.1483627575505184

Epoch: 6| Step: 3
Training loss: 0.5987168419562298
Validation loss: 3.198982897686633

Epoch: 6| Step: 4
Training loss: 0.2779810393577526
Validation loss: 3.0848749319245763

Epoch: 6| Step: 5
Training loss: 0.3613228668655102
Validation loss: 3.124783800911572

Epoch: 6| Step: 6
Training loss: 0.2815100209635948
Validation loss: 3.1520610747189113

Epoch: 6| Step: 7
Training loss: 0.3263808854228797
Validation loss: 3.1822839706669144

Epoch: 6| Step: 8
Training loss: 0.4112331965529705
Validation loss: 3.1005478231335193

Epoch: 6| Step: 9
Training loss: 0.270659118642427
Validation loss: 3.2099654434895104

Epoch: 6| Step: 10
Training loss: 0.3134718089471167
Validation loss: 3.217610722365456

Epoch: 6| Step: 11
Training loss: 0.35437787527435033
Validation loss: 3.2470083038604542

Epoch: 6| Step: 12
Training loss: 0.3593682205555878
Validation loss: 3.2509177697181384

Epoch: 6| Step: 13
Training loss: 0.44910736361603537
Validation loss: 3.216602460849615

Epoch: 278| Step: 0
Training loss: 0.36389528699439916
Validation loss: 3.1244502410507815

Epoch: 6| Step: 1
Training loss: 0.48585487227462726
Validation loss: 3.070023553014445

Epoch: 6| Step: 2
Training loss: 0.6554936182626562
Validation loss: 3.1003593333983708

Epoch: 6| Step: 3
Training loss: 0.328931305988812
Validation loss: 3.118438087415157

Epoch: 6| Step: 4
Training loss: 0.21693956988706387
Validation loss: 3.1556720771080995

Epoch: 6| Step: 5
Training loss: 0.4330618749309295
Validation loss: 3.1554972692115237

Epoch: 6| Step: 6
Training loss: 0.23656425816828716
Validation loss: 3.1586269455230855

Epoch: 6| Step: 7
Training loss: 0.3234100597369883
Validation loss: 3.1513607945952162

Epoch: 6| Step: 8
Training loss: 0.36144621697748336
Validation loss: 3.1728464777983905

Epoch: 6| Step: 9
Training loss: 0.5623210516374018
Validation loss: 3.118831344491603

Epoch: 6| Step: 10
Training loss: 0.32873208787659985
Validation loss: 3.159469875743652

Epoch: 6| Step: 11
Training loss: 0.3573726766109829
Validation loss: 3.2241538219108947

Epoch: 6| Step: 12
Training loss: 0.41113384545710685
Validation loss: 3.102405193395729

Epoch: 6| Step: 13
Training loss: 0.3687438447082933
Validation loss: 3.0799691215841607

Epoch: 279| Step: 0
Training loss: 0.43927757995552985
Validation loss: 3.0666362570899643

Epoch: 6| Step: 1
Training loss: 0.3006512125487549
Validation loss: 3.1527593717630635

Epoch: 6| Step: 2
Training loss: 0.6585445706976153
Validation loss: 3.23772862239619

Epoch: 6| Step: 3
Training loss: 0.4892185218247619
Validation loss: 3.1591141549987647

Epoch: 6| Step: 4
Training loss: 0.5003594060445803
Validation loss: 3.1509151380792715

Epoch: 6| Step: 5
Training loss: 0.3501287364065777
Validation loss: 3.2235363184367762

Epoch: 6| Step: 6
Training loss: 0.29591432535052226
Validation loss: 3.1872138349942

Epoch: 6| Step: 7
Training loss: 0.3397124135339949
Validation loss: 3.148798692303285

Epoch: 6| Step: 8
Training loss: 0.3285099337489669
Validation loss: 3.212056734498902

Epoch: 6| Step: 9
Training loss: 0.4131634867136585
Validation loss: 3.160405661945802

Epoch: 6| Step: 10
Training loss: 0.352736948538313
Validation loss: 3.2169126927136706

Epoch: 6| Step: 11
Training loss: 0.3245333214089007
Validation loss: 3.167016942745685

Epoch: 6| Step: 12
Training loss: 0.4226664430866392
Validation loss: 3.1618667079024814

Epoch: 6| Step: 13
Training loss: 0.26059801780754854
Validation loss: 3.148436237899742

Epoch: 280| Step: 0
Training loss: 0.33757222338838816
Validation loss: 3.183969649451377

Epoch: 6| Step: 1
Training loss: 0.512310297677506
Validation loss: 3.1381833531674546

Epoch: 6| Step: 2
Training loss: 0.22498853442330843
Validation loss: 3.1811830220044777

Epoch: 6| Step: 3
Training loss: 0.7622158678069211
Validation loss: 3.1918176069167186

Epoch: 6| Step: 4
Training loss: 0.19778040955573345
Validation loss: 3.2074919418903716

Epoch: 6| Step: 5
Training loss: 0.33776158421103103
Validation loss: 3.1587081753842954

Epoch: 6| Step: 6
Training loss: 0.26728874764418187
Validation loss: 3.1826557922987218

Epoch: 6| Step: 7
Training loss: 0.2721316354053879
Validation loss: 3.1749099718681433

Epoch: 6| Step: 8
Training loss: 0.26606988115491603
Validation loss: 3.2142407951546583

Epoch: 6| Step: 9
Training loss: 0.3491500522367659
Validation loss: 3.1711672915733753

Epoch: 6| Step: 10
Training loss: 0.44379947682032234
Validation loss: 3.182999281973143

Epoch: 6| Step: 11
Training loss: 0.2605145778970147
Validation loss: 3.180032847252829

Epoch: 6| Step: 12
Training loss: 0.3880469315561277
Validation loss: 3.140760643403736

Epoch: 6| Step: 13
Training loss: 0.301782588497155
Validation loss: 3.077577713337136

Epoch: 281| Step: 0
Training loss: 0.47855794291314974
Validation loss: 3.058039446507929

Epoch: 6| Step: 1
Training loss: 0.5032114073201014
Validation loss: 3.0468538332472903

Epoch: 6| Step: 2
Training loss: 0.32179981436872257
Validation loss: 3.0347192974255917

Epoch: 6| Step: 3
Training loss: 0.5954659912397811
Validation loss: 3.108478666151647

Epoch: 6| Step: 4
Training loss: 0.3943763277663234
Validation loss: 3.10719657511177

Epoch: 6| Step: 5
Training loss: 0.2775935404797242
Validation loss: 3.225380398496666

Epoch: 6| Step: 6
Training loss: 0.47018736761989555
Validation loss: 3.1485426690369205

Epoch: 6| Step: 7
Training loss: 0.27760973788188475
Validation loss: 3.2731972593341783

Epoch: 6| Step: 8
Training loss: 0.40199850139528376
Validation loss: 3.2595135511512687

Epoch: 6| Step: 9
Training loss: 0.3742656670389075
Validation loss: 3.204960391811075

Epoch: 6| Step: 10
Training loss: 0.38897099318876155
Validation loss: 3.1438742383672587

Epoch: 6| Step: 11
Training loss: 0.3963485635502592
Validation loss: 3.093717221686889

Epoch: 6| Step: 12
Training loss: 0.43757843268202656
Validation loss: 3.086486278299712

Epoch: 6| Step: 13
Training loss: 0.3178952350033749
Validation loss: 3.189770332567215

Epoch: 282| Step: 0
Training loss: 0.263483460536099
Validation loss: 3.1196983760753825

Epoch: 6| Step: 1
Training loss: 0.37070790359102285
Validation loss: 3.1305722846488986

Epoch: 6| Step: 2
Training loss: 0.34273075587925034
Validation loss: 3.217021848574158

Epoch: 6| Step: 3
Training loss: 0.3864642760581616
Validation loss: 3.185991216870542

Epoch: 6| Step: 4
Training loss: 0.43387199615564087
Validation loss: 3.173654479925285

Epoch: 6| Step: 5
Training loss: 0.2670732175683812
Validation loss: 3.1828607444746067

Epoch: 6| Step: 6
Training loss: 0.35826702983067854
Validation loss: 3.1510770979641625

Epoch: 6| Step: 7
Training loss: 0.3624763596159635
Validation loss: 3.144803520720258

Epoch: 6| Step: 8
Training loss: 0.6473072266547577
Validation loss: 3.1461543788835327

Epoch: 6| Step: 9
Training loss: 0.27889717952821025
Validation loss: 3.161144879977739

Epoch: 6| Step: 10
Training loss: 0.3055489661609212
Validation loss: 3.050900257116028

Epoch: 6| Step: 11
Training loss: 0.3585887476420495
Validation loss: 3.08873596781033

Epoch: 6| Step: 12
Training loss: 0.3822098289261426
Validation loss: 3.13647439716693

Epoch: 6| Step: 13
Training loss: 0.39609117224943613
Validation loss: 3.107869868630439

Epoch: 283| Step: 0
Training loss: 0.6251588619514176
Validation loss: 3.116871103085808

Epoch: 6| Step: 1
Training loss: 0.28801145722279214
Validation loss: 3.0842064360190093

Epoch: 6| Step: 2
Training loss: 0.33946338282495386
Validation loss: 3.1536756031616844

Epoch: 6| Step: 3
Training loss: 0.347437972220635
Validation loss: 3.0365858798232583

Epoch: 6| Step: 4
Training loss: 0.2261406407506164
Validation loss: 3.1312383817760483

Epoch: 6| Step: 5
Training loss: 0.28923199813399475
Validation loss: 3.154494751194705

Epoch: 6| Step: 6
Training loss: 0.3282559337958501
Validation loss: 3.1967485243115528

Epoch: 6| Step: 7
Training loss: 0.25513699890509145
Validation loss: 3.1599428963833387

Epoch: 6| Step: 8
Training loss: 0.44934816569506464
Validation loss: 3.2096347192398564

Epoch: 6| Step: 9
Training loss: 0.3230903706911174
Validation loss: 3.1412363801603482

Epoch: 6| Step: 10
Training loss: 0.34434060814643863
Validation loss: 3.1965320501400947

Epoch: 6| Step: 11
Training loss: 0.3119383652594246
Validation loss: 3.1898650825852872

Epoch: 6| Step: 12
Training loss: 0.29055959057761616
Validation loss: 3.1396760155241306

Epoch: 6| Step: 13
Training loss: 0.43616493062417383
Validation loss: 3.214698142380835

Epoch: 284| Step: 0
Training loss: 0.489304013079136
Validation loss: 3.223731657984051

Epoch: 6| Step: 1
Training loss: 0.31678290377476187
Validation loss: 3.157435896266299

Epoch: 6| Step: 2
Training loss: 0.3479377378528372
Validation loss: 3.1192569985653242

Epoch: 6| Step: 3
Training loss: 0.6663966724919456
Validation loss: 3.230058194217878

Epoch: 6| Step: 4
Training loss: 0.3713317910721105
Validation loss: 3.1795403323846068

Epoch: 6| Step: 5
Training loss: 0.3344871684914811
Validation loss: 3.178183284938993

Epoch: 6| Step: 6
Training loss: 0.3164864426702805
Validation loss: 3.1227905219119134

Epoch: 6| Step: 7
Training loss: 0.38260247833657685
Validation loss: 3.144078672707629

Epoch: 6| Step: 8
Training loss: 0.3266323060621174
Validation loss: 3.179917548228331

Epoch: 6| Step: 9
Training loss: 0.23086583149461304
Validation loss: 3.1668064479762394

Epoch: 6| Step: 10
Training loss: 0.2877683019924179
Validation loss: 3.1941134838835703

Epoch: 6| Step: 11
Training loss: 0.2995695876021847
Validation loss: 3.1917189931605634

Epoch: 6| Step: 12
Training loss: 0.4246258238525304
Validation loss: 3.1884726492685918

Epoch: 6| Step: 13
Training loss: 0.3424839307850985
Validation loss: 3.170812106134557

Epoch: 285| Step: 0
Training loss: 0.28474723536762764
Validation loss: 3.149640909546701

Epoch: 6| Step: 1
Training loss: 0.3772612977229009
Validation loss: 3.2018621917255965

Epoch: 6| Step: 2
Training loss: 0.42544374300692817
Validation loss: 3.1847046830879724

Epoch: 6| Step: 3
Training loss: 0.3311193397429884
Validation loss: 3.1150611885106665

Epoch: 6| Step: 4
Training loss: 0.36944283119166527
Validation loss: 3.10689266676872

Epoch: 6| Step: 5
Training loss: 0.39447593301166767
Validation loss: 3.1174455502427025

Epoch: 6| Step: 6
Training loss: 0.35081992668909634
Validation loss: 3.1356871394265

Epoch: 6| Step: 7
Training loss: 0.2627706313376811
Validation loss: 3.1570511610017946

Epoch: 6| Step: 8
Training loss: 0.4147155578021313
Validation loss: 3.101024142160169

Epoch: 6| Step: 9
Training loss: 0.24901223998980374
Validation loss: 3.128007751056047

Epoch: 6| Step: 10
Training loss: 0.32161278923656533
Validation loss: 3.1275761222164333

Epoch: 6| Step: 11
Training loss: 0.43160149237226253
Validation loss: 3.0816464234246506

Epoch: 6| Step: 12
Training loss: 0.6667092702087504
Validation loss: 3.066762902643349

Epoch: 6| Step: 13
Training loss: 0.2656541696127535
Validation loss: 3.0304348691885523

Epoch: 286| Step: 0
Training loss: 0.5101172451279526
Validation loss: 3.099970078067552

Epoch: 6| Step: 1
Training loss: 0.3540900605696048
Validation loss: 3.0867919833372777

Epoch: 6| Step: 2
Training loss: 0.3281198909906734
Validation loss: 3.1160595222586083

Epoch: 6| Step: 3
Training loss: 0.4967424251821668
Validation loss: 3.1021311740674693

Epoch: 6| Step: 4
Training loss: 0.3891640044324814
Validation loss: 3.1352224490485687

Epoch: 6| Step: 5
Training loss: 0.348879547856948
Validation loss: 3.124888379964563

Epoch: 6| Step: 6
Training loss: 0.2828414449053097
Validation loss: 3.112650029908498

Epoch: 6| Step: 7
Training loss: 0.28214388101514426
Validation loss: 3.0552300949353484

Epoch: 6| Step: 8
Training loss: 0.3415353482929224
Validation loss: 3.0454985288897123

Epoch: 6| Step: 9
Training loss: 0.43544138499038465
Validation loss: 3.069171541451622

Epoch: 6| Step: 10
Training loss: 0.36970351964014475
Validation loss: 3.145651393117472

Epoch: 6| Step: 11
Training loss: 0.6674362201437283
Validation loss: 3.127513485032488

Epoch: 6| Step: 12
Training loss: 0.42421567575032765
Validation loss: 3.2418446922613806

Epoch: 6| Step: 13
Training loss: 0.3045034953348964
Validation loss: 3.096876600299092

Epoch: 287| Step: 0
Training loss: 0.6155467617839966
Validation loss: 3.1368927295743934

Epoch: 6| Step: 1
Training loss: 0.33113452770080987
Validation loss: 3.155730428200672

Epoch: 6| Step: 2
Training loss: 0.205387336498588
Validation loss: 3.172258864352782

Epoch: 6| Step: 3
Training loss: 0.20742316308492656
Validation loss: 3.0911284105837757

Epoch: 6| Step: 4
Training loss: 0.29981167067555614
Validation loss: 3.1277093967561376

Epoch: 6| Step: 5
Training loss: 0.43841521719701587
Validation loss: 3.1257774911718212

Epoch: 6| Step: 6
Training loss: 0.27640461752470386
Validation loss: 3.1496410609408314

Epoch: 6| Step: 7
Training loss: 0.4339039698023324
Validation loss: 3.156982299153316

Epoch: 6| Step: 8
Training loss: 0.4688441340976243
Validation loss: 3.120882908045802

Epoch: 6| Step: 9
Training loss: 0.3788820042669096
Validation loss: 3.1561608884210957

Epoch: 6| Step: 10
Training loss: 0.35983174779821525
Validation loss: 3.1532533854524325

Epoch: 6| Step: 11
Training loss: 0.43909473640233904
Validation loss: 3.22654092333509

Epoch: 6| Step: 12
Training loss: 0.4651805875419145
Validation loss: 3.138587303264514

Epoch: 6| Step: 13
Training loss: 0.2866204178914253
Validation loss: 3.1792843224855356

Epoch: 288| Step: 0
Training loss: 0.3634980897918841
Validation loss: 3.153880548707116

Epoch: 6| Step: 1
Training loss: 0.3581616193546789
Validation loss: 3.265212743311539

Epoch: 6| Step: 2
Training loss: 0.44201943334195437
Validation loss: 3.1738770904676357

Epoch: 6| Step: 3
Training loss: 0.3335029076345106
Validation loss: 3.140615776390082

Epoch: 6| Step: 4
Training loss: 0.46809468556993195
Validation loss: 3.1134527487047814

Epoch: 6| Step: 5
Training loss: 0.3387514845790919
Validation loss: 3.12564977884085

Epoch: 6| Step: 6
Training loss: 0.7210643659000304
Validation loss: 3.134918988715842

Epoch: 6| Step: 7
Training loss: 0.4116309222476788
Validation loss: 3.1323483853437386

Epoch: 6| Step: 8
Training loss: 0.29917275745112076
Validation loss: 3.2457563620481

Epoch: 6| Step: 9
Training loss: 0.3991223601490797
Validation loss: 3.169236412059935

Epoch: 6| Step: 10
Training loss: 0.4424865129538322
Validation loss: 3.1821166061640507

Epoch: 6| Step: 11
Training loss: 0.371259391357625
Validation loss: 3.177309864077038

Epoch: 6| Step: 12
Training loss: 0.3509977891518176
Validation loss: 3.224461571155507

Epoch: 6| Step: 13
Training loss: 0.36514880968119506
Validation loss: 3.090451662598269

Epoch: 289| Step: 0
Training loss: 0.3605159394950588
Validation loss: 3.129397261276082

Epoch: 6| Step: 1
Training loss: 0.31361598779418326
Validation loss: 3.1362914621352465

Epoch: 6| Step: 2
Training loss: 0.37088737772622365
Validation loss: 3.1977436669158994

Epoch: 6| Step: 3
Training loss: 0.4186886799453028
Validation loss: 3.132108804337755

Epoch: 6| Step: 4
Training loss: 0.5589999609266483
Validation loss: 3.1195973042278475

Epoch: 6| Step: 5
Training loss: 0.5232843488144152
Validation loss: 3.1011461031268492

Epoch: 6| Step: 6
Training loss: 0.49701982702699776
Validation loss: 2.974766934772884

Epoch: 6| Step: 7
Training loss: 0.4099079288635283
Validation loss: 3.162487137055907

Epoch: 6| Step: 8
Training loss: 0.3230118867499786
Validation loss: 3.1370683588434023

Epoch: 6| Step: 9
Training loss: 0.3737471035299689
Validation loss: 3.2360577467491844

Epoch: 6| Step: 10
Training loss: 0.3335365505449603
Validation loss: 3.257934507041514

Epoch: 6| Step: 11
Training loss: 0.3112291722050722
Validation loss: 3.2272923762414862

Epoch: 6| Step: 12
Training loss: 0.8486065086792131
Validation loss: 3.168103874890171

Epoch: 6| Step: 13
Training loss: 0.2435831342418569
Validation loss: 3.192072636521198

Epoch: 290| Step: 0
Training loss: 0.27816465609433166
Validation loss: 3.0955093852649367

Epoch: 6| Step: 1
Training loss: 0.6726186983302126
Validation loss: 3.096286158005994

Epoch: 6| Step: 2
Training loss: 0.44408112649959236
Validation loss: 3.0642944450457286

Epoch: 6| Step: 3
Training loss: 0.47368593213015286
Validation loss: 3.0714046486844895

Epoch: 6| Step: 4
Training loss: 0.38547154843443754
Validation loss: 3.1703023159263983

Epoch: 6| Step: 5
Training loss: 0.3426138133964846
Validation loss: 3.1216873540225065

Epoch: 6| Step: 6
Training loss: 0.39213196942644984
Validation loss: 3.153455183008389

Epoch: 6| Step: 7
Training loss: 0.37161280821617076
Validation loss: 3.2881684647451004

Epoch: 6| Step: 8
Training loss: 0.6348590019209769
Validation loss: 3.278811393276448

Epoch: 6| Step: 9
Training loss: 0.3496595591750669
Validation loss: 3.2378729488838203

Epoch: 6| Step: 10
Training loss: 0.3461160833416365
Validation loss: 3.1902334547767452

Epoch: 6| Step: 11
Training loss: 0.22940418098066462
Validation loss: 3.1627360887823337

Epoch: 6| Step: 12
Training loss: 0.48766480252271854
Validation loss: 3.1648587704486246

Epoch: 6| Step: 13
Training loss: 0.3816259640988549
Validation loss: 3.1427756137408505

Epoch: 291| Step: 0
Training loss: 0.4455614398018505
Validation loss: 3.117696556394498

Epoch: 6| Step: 1
Training loss: 0.383992653153094
Validation loss: 3.084680821267223

Epoch: 6| Step: 2
Training loss: 0.4116268677945684
Validation loss: 3.1274456118441996

Epoch: 6| Step: 3
Training loss: 0.3432166556980673
Validation loss: 3.1632724984499307

Epoch: 6| Step: 4
Training loss: 0.6618350875894965
Validation loss: 3.201824575545026

Epoch: 6| Step: 5
Training loss: 0.48840292368298066
Validation loss: 3.1720504837476478

Epoch: 6| Step: 6
Training loss: 0.3747730959429316
Validation loss: 3.1951778044598447

Epoch: 6| Step: 7
Training loss: 0.381264182905696
Validation loss: 3.1996875585573474

Epoch: 6| Step: 8
Training loss: 0.3277984083727028
Validation loss: 3.182840556971604

Epoch: 6| Step: 9
Training loss: 0.4171716987103417
Validation loss: 3.1486746270402666

Epoch: 6| Step: 10
Training loss: 0.42089744620859193
Validation loss: 3.0730901033412588

Epoch: 6| Step: 11
Training loss: 0.30600178741575057
Validation loss: 3.1221046004382815

Epoch: 6| Step: 12
Training loss: 0.23572681316819694
Validation loss: 3.113773806356018

Epoch: 6| Step: 13
Training loss: 0.4565948620031328
Validation loss: 3.0909132748123316

Epoch: 292| Step: 0
Training loss: 0.491186698785748
Validation loss: 3.167678161162958

Epoch: 6| Step: 1
Training loss: 0.2802299306244297
Validation loss: 3.1638862215395

Epoch: 6| Step: 2
Training loss: 0.7312063481270248
Validation loss: 3.200684444176168

Epoch: 6| Step: 3
Training loss: 0.277562874209438
Validation loss: 3.1826085537948154

Epoch: 6| Step: 4
Training loss: 0.3979421228817614
Validation loss: 3.1330567072105358

Epoch: 6| Step: 5
Training loss: 0.32250844881538276
Validation loss: 3.23152224035183

Epoch: 6| Step: 6
Training loss: 0.47150643841462647
Validation loss: 3.208216037505183

Epoch: 6| Step: 7
Training loss: 0.45004806261886315
Validation loss: 3.1323977835647248

Epoch: 6| Step: 8
Training loss: 0.3406044787603568
Validation loss: 3.1566428264239996

Epoch: 6| Step: 9
Training loss: 0.32140113012364996
Validation loss: 3.107053852007083

Epoch: 6| Step: 10
Training loss: 0.34434020785725433
Validation loss: 3.1737670391757704

Epoch: 6| Step: 11
Training loss: 0.40052253597114235
Validation loss: 3.168829208778497

Epoch: 6| Step: 12
Training loss: 0.5410048831465474
Validation loss: 3.082221221548552

Epoch: 6| Step: 13
Training loss: 0.3114224452560476
Validation loss: 3.174958732917511

Epoch: 293| Step: 0
Training loss: 0.4931238743487566
Validation loss: 3.1593570964040567

Epoch: 6| Step: 1
Training loss: 0.32828520088414737
Validation loss: 3.236871661822674

Epoch: 6| Step: 2
Training loss: 0.633895606444539
Validation loss: 3.3088386742239027

Epoch: 6| Step: 3
Training loss: 0.5244540691210964
Validation loss: 3.28097143050365

Epoch: 6| Step: 4
Training loss: 0.39066858048520864
Validation loss: 3.121402004330905

Epoch: 6| Step: 5
Training loss: 0.4107833246735149
Validation loss: 3.0939693565823863

Epoch: 6| Step: 6
Training loss: 0.3947417198264601
Validation loss: 3.150322803225295

Epoch: 6| Step: 7
Training loss: 0.7704478580177463
Validation loss: 3.1617870296102444

Epoch: 6| Step: 8
Training loss: 0.47911070586731513
Validation loss: 3.14779689383396

Epoch: 6| Step: 9
Training loss: 0.3053238166343866
Validation loss: 3.1488726924885615

Epoch: 6| Step: 10
Training loss: 0.3566453764182182
Validation loss: 3.2069936201061657

Epoch: 6| Step: 11
Training loss: 0.31135123823993877
Validation loss: 3.242598002846603

Epoch: 6| Step: 12
Training loss: 0.42722917795754045
Validation loss: 3.1941539028744383

Epoch: 6| Step: 13
Training loss: 0.4524431524607379
Validation loss: 3.2243613554568538

Epoch: 294| Step: 0
Training loss: 0.4483206021735982
Validation loss: 3.207141448407092

Epoch: 6| Step: 1
Training loss: 0.29429896678743195
Validation loss: 3.2056632800837175

Epoch: 6| Step: 2
Training loss: 0.5107924544213228
Validation loss: 3.0369500514003054

Epoch: 6| Step: 3
Training loss: 0.6041869593095318
Validation loss: 3.0439108751878448

Epoch: 6| Step: 4
Training loss: 0.4846612484412422
Validation loss: 3.105010543064108

Epoch: 6| Step: 5
Training loss: 0.42552299716855313
Validation loss: 3.0860608297563514

Epoch: 6| Step: 6
Training loss: 0.2539974049018843
Validation loss: 3.1902391096366225

Epoch: 6| Step: 7
Training loss: 0.4188409599752612
Validation loss: 3.1832471288289947

Epoch: 6| Step: 8
Training loss: 0.36886281453749775
Validation loss: 3.255227970318374

Epoch: 6| Step: 9
Training loss: 0.42566157767799406
Validation loss: 3.342886352712258

Epoch: 6| Step: 10
Training loss: 0.4803019753657537
Validation loss: 3.298341036442697

Epoch: 6| Step: 11
Training loss: 0.25907860159446205
Validation loss: 3.3084420593870227

Epoch: 6| Step: 12
Training loss: 0.37471291361216263
Validation loss: 3.1386710900632315

Epoch: 6| Step: 13
Training loss: 0.6544940480587433
Validation loss: 3.230698859842223

Epoch: 295| Step: 0
Training loss: 0.3257757282475229
Validation loss: 3.1618037446234664

Epoch: 6| Step: 1
Training loss: 0.30048772187625666
Validation loss: 3.165036074456383

Epoch: 6| Step: 2
Training loss: 0.2938538976318974
Validation loss: 3.148309381621735

Epoch: 6| Step: 3
Training loss: 0.6610876205978847
Validation loss: 3.1554007190190694

Epoch: 6| Step: 4
Training loss: 0.36765608411818435
Validation loss: 3.168409323954098

Epoch: 6| Step: 5
Training loss: 0.3506952609418842
Validation loss: 3.1232517438455334

Epoch: 6| Step: 6
Training loss: 0.42068415805348963
Validation loss: 3.170668875347274

Epoch: 6| Step: 7
Training loss: 0.3459995529083715
Validation loss: 3.144016010413524

Epoch: 6| Step: 8
Training loss: 0.3705646557757279
Validation loss: 3.157739180956804

Epoch: 6| Step: 9
Training loss: 0.3681750106195555
Validation loss: 3.0701594812054975

Epoch: 6| Step: 10
Training loss: 0.3858803031020676
Validation loss: 3.155019576953538

Epoch: 6| Step: 11
Training loss: 0.2457466932886314
Validation loss: 3.1780946258123706

Epoch: 6| Step: 12
Training loss: 0.3398895342449012
Validation loss: 3.104558207419998

Epoch: 6| Step: 13
Training loss: 0.3495946486797326
Validation loss: 2.97648069147475

Epoch: 296| Step: 0
Training loss: 0.38274429647929015
Validation loss: 3.080676033462564

Epoch: 6| Step: 1
Training loss: 0.32531243583539315
Validation loss: 3.1240210589278288

Epoch: 6| Step: 2
Training loss: 0.44124117439888705
Validation loss: 3.151596743451701

Epoch: 6| Step: 3
Training loss: 0.5079437086350886
Validation loss: 3.2046222815905505

Epoch: 6| Step: 4
Training loss: 0.3995564586994796
Validation loss: 3.19989786481783

Epoch: 6| Step: 5
Training loss: 0.33984160148555315
Validation loss: 3.2242682600213928

Epoch: 6| Step: 6
Training loss: 0.36332308620620013
Validation loss: 3.136280654710786

Epoch: 6| Step: 7
Training loss: 0.25930280255113597
Validation loss: 3.1591122430896443

Epoch: 6| Step: 8
Training loss: 0.35309480943157096
Validation loss: 3.2000261591299064

Epoch: 6| Step: 9
Training loss: 0.37333404512564605
Validation loss: 3.1495697913492946

Epoch: 6| Step: 10
Training loss: 0.4685932056135098
Validation loss: 3.1422888427254976

Epoch: 6| Step: 11
Training loss: 0.2718812799276537
Validation loss: 3.1270668951047664

Epoch: 6| Step: 12
Training loss: 0.670299501448646
Validation loss: 3.183647245804054

Epoch: 6| Step: 13
Training loss: 0.4153550504668763
Validation loss: 3.2019281151569547

Epoch: 297| Step: 0
Training loss: 0.6708288698067661
Validation loss: 3.176700448066389

Epoch: 6| Step: 1
Training loss: 0.4487708803063547
Validation loss: 3.2223191950080006

Epoch: 6| Step: 2
Training loss: 0.4299162169272539
Validation loss: 3.2279606053805576

Epoch: 6| Step: 3
Training loss: 0.25633948903470316
Validation loss: 3.255345570023778

Epoch: 6| Step: 4
Training loss: 0.24822887742130675
Validation loss: 3.155711855192666

Epoch: 6| Step: 5
Training loss: 0.22757390782815912
Validation loss: 3.0886299974098326

Epoch: 6| Step: 6
Training loss: 0.37345683953552766
Validation loss: 3.1246578410706087

Epoch: 6| Step: 7
Training loss: 0.3839675449474441
Validation loss: 3.0700312672492145

Epoch: 6| Step: 8
Training loss: 0.3301973409758506
Validation loss: 3.1213414074446932

Epoch: 6| Step: 9
Training loss: 0.3232624934983905
Validation loss: 3.1109697606885445

Epoch: 6| Step: 10
Training loss: 0.43823641719431367
Validation loss: 3.1515296915414712

Epoch: 6| Step: 11
Training loss: 0.39039280666179144
Validation loss: 3.134307948340091

Epoch: 6| Step: 12
Training loss: 0.32390939362284427
Validation loss: 3.2309371688591217

Epoch: 6| Step: 13
Training loss: 0.38752602597482205
Validation loss: 3.1863282112987363

Epoch: 298| Step: 0
Training loss: 0.3555955136818012
Validation loss: 3.1682646550884312

Epoch: 6| Step: 1
Training loss: 0.1915698033880623
Validation loss: 3.0828006172498976

Epoch: 6| Step: 2
Training loss: 0.34572743475835455
Validation loss: 3.0735069397640657

Epoch: 6| Step: 3
Training loss: 0.38156555436994927
Validation loss: 3.1026471833290956

Epoch: 6| Step: 4
Training loss: 0.3097171375092966
Validation loss: 3.1658051640669047

Epoch: 6| Step: 5
Training loss: 0.3518737474829164
Validation loss: 3.0928453220870247

Epoch: 6| Step: 6
Training loss: 0.34094484125515023
Validation loss: 3.080238739644508

Epoch: 6| Step: 7
Training loss: 0.36853061712652696
Validation loss: 3.160701784781919

Epoch: 6| Step: 8
Training loss: 0.3432831086050705
Validation loss: 3.163176260955355

Epoch: 6| Step: 9
Training loss: 0.506849579085444
Validation loss: 3.2087013644554934

Epoch: 6| Step: 10
Training loss: 0.35379011341236666
Validation loss: 3.167862908805621

Epoch: 6| Step: 11
Training loss: 0.39673899475342983
Validation loss: 3.2028269311184823

Epoch: 6| Step: 12
Training loss: 0.7160742336662642
Validation loss: 3.1485003267114076

Epoch: 6| Step: 13
Training loss: 0.30052075934230127
Validation loss: 3.091421966088609

Epoch: 299| Step: 0
Training loss: 0.3056972351598698
Validation loss: 3.1182076960552387

Epoch: 6| Step: 1
Training loss: 0.4072152737669718
Validation loss: 3.093184229947271

Epoch: 6| Step: 2
Training loss: 0.40136440303978266
Validation loss: 3.008218343197842

Epoch: 6| Step: 3
Training loss: 0.39126521099247363
Validation loss: 3.103377854314354

Epoch: 6| Step: 4
Training loss: 0.20688715004464106
Validation loss: 3.1628320883991208

Epoch: 6| Step: 5
Training loss: 0.27105676470162776
Validation loss: 3.1284504088896075

Epoch: 6| Step: 6
Training loss: 0.26551311604920563
Validation loss: 3.1637633382394745

Epoch: 6| Step: 7
Training loss: 0.487788142122173
Validation loss: 3.1947538016436186

Epoch: 6| Step: 8
Training loss: 0.5669229978368342
Validation loss: 3.146554742077975

Epoch: 6| Step: 9
Training loss: 0.3943180603539847
Validation loss: 3.1780102529350365

Epoch: 6| Step: 10
Training loss: 0.2562609571347292
Validation loss: 3.1090441452692614

Epoch: 6| Step: 11
Training loss: 0.6298530275858203
Validation loss: 3.158242040806059

Epoch: 6| Step: 12
Training loss: 0.2880013293146211
Validation loss: 3.160681242022178

Epoch: 6| Step: 13
Training loss: 0.3632821113822323
Validation loss: 3.1795665271188067

Epoch: 300| Step: 0
Training loss: 0.3219398354534677
Validation loss: 3.1454186618839195

Epoch: 6| Step: 1
Training loss: 0.30366710824957005
Validation loss: 3.180913165633641

Epoch: 6| Step: 2
Training loss: 0.34616260919931136
Validation loss: 3.16973688381432

Epoch: 6| Step: 3
Training loss: 0.28921676076558384
Validation loss: 3.143092652110979

Epoch: 6| Step: 4
Training loss: 0.3099665467608643
Validation loss: 3.1871467095353183

Epoch: 6| Step: 5
Training loss: 0.5917454561865684
Validation loss: 3.240788291905232

Epoch: 6| Step: 6
Training loss: 0.38003360530680813
Validation loss: 3.135230775985546

Epoch: 6| Step: 7
Training loss: 0.2176512987240498
Validation loss: 3.1810554604794743

Epoch: 6| Step: 8
Training loss: 0.37185308167433595
Validation loss: 3.167839376910012

Epoch: 6| Step: 9
Training loss: 0.27468570825819155
Validation loss: 3.1016785914605056

Epoch: 6| Step: 10
Training loss: 0.3201919189139262
Validation loss: 3.1415815335956356

Epoch: 6| Step: 11
Training loss: 0.262912901208053
Validation loss: 3.1352768589081252

Epoch: 6| Step: 12
Training loss: 0.272775666502141
Validation loss: 3.1509138013049465

Epoch: 6| Step: 13
Training loss: 0.2915917013536055
Validation loss: 3.110184607224405

Epoch: 301| Step: 0
Training loss: 0.3358044138924733
Validation loss: 3.1460316239740176

Epoch: 6| Step: 1
Training loss: 0.2732997819954079
Validation loss: 3.1664555797158758

Epoch: 6| Step: 2
Training loss: 0.42287277626582775
Validation loss: 3.189878411641535

Epoch: 6| Step: 3
Training loss: 0.6209137853769674
Validation loss: 3.1874283427243415

Epoch: 6| Step: 4
Training loss: 0.266797004576801
Validation loss: 3.0976370209156805

Epoch: 6| Step: 5
Training loss: 0.30413730781210135
Validation loss: 3.1342300924144753

Epoch: 6| Step: 6
Training loss: 0.25713583259221784
Validation loss: 3.1853456384903627

Epoch: 6| Step: 7
Training loss: 0.4162809036570737
Validation loss: 3.1281083987186435

Epoch: 6| Step: 8
Training loss: 0.29059323116707014
Validation loss: 3.181175077664034

Epoch: 6| Step: 9
Training loss: 0.4776700236163049
Validation loss: 3.1874620896621892

Epoch: 6| Step: 10
Training loss: 0.4347006784411854
Validation loss: 3.1502049031295822

Epoch: 6| Step: 11
Training loss: 0.35193916911273204
Validation loss: 3.18155430410681

Epoch: 6| Step: 12
Training loss: 0.32584433185001915
Validation loss: 3.1980147869618345

Epoch: 6| Step: 13
Training loss: 0.4072297459759222
Validation loss: 3.227728275171892

Epoch: 302| Step: 0
Training loss: 0.22539494012837305
Validation loss: 3.141743930369124

Epoch: 6| Step: 1
Training loss: 0.34904034087454616
Validation loss: 3.207288799096701

Epoch: 6| Step: 2
Training loss: 0.3504704574767861
Validation loss: 3.1776197803970105

Epoch: 6| Step: 3
Training loss: 0.3204815116286849
Validation loss: 3.136300331037229

Epoch: 6| Step: 4
Training loss: 0.36180798395936037
Validation loss: 3.1692072982918464

Epoch: 6| Step: 5
Training loss: 0.2731181323237717
Validation loss: 3.1656004382251033

Epoch: 6| Step: 6
Training loss: 0.3396045456835365
Validation loss: 3.139969879196252

Epoch: 6| Step: 7
Training loss: 0.5405628499376053
Validation loss: 3.0705984692624746

Epoch: 6| Step: 8
Training loss: 0.2454027738724514
Validation loss: 3.1370655721593237

Epoch: 6| Step: 9
Training loss: 0.2141160344614641
Validation loss: 3.1277108450850513

Epoch: 6| Step: 10
Training loss: 0.31524166018400396
Validation loss: 3.1847314841576675

Epoch: 6| Step: 11
Training loss: 0.6246799841806039
Validation loss: 3.1419592659550015

Epoch: 6| Step: 12
Training loss: 0.3642576488668366
Validation loss: 3.225715840166845

Epoch: 6| Step: 13
Training loss: 0.3939900794099444
Validation loss: 3.164779807833544

Epoch: 303| Step: 0
Training loss: 0.5419764610964478
Validation loss: 3.1558958301814437

Epoch: 6| Step: 1
Training loss: 0.31671487803037834
Validation loss: 3.125340455900979

Epoch: 6| Step: 2
Training loss: 0.32045870444828883
Validation loss: 3.153925439402811

Epoch: 6| Step: 3
Training loss: 0.3763608479621644
Validation loss: 3.1818973194948756

Epoch: 6| Step: 4
Training loss: 0.3160608784983075
Validation loss: 3.135265464981224

Epoch: 6| Step: 5
Training loss: 0.38866453307612
Validation loss: 3.1611517810458656

Epoch: 6| Step: 6
Training loss: 0.36773531205118903
Validation loss: 3.131655802163982

Epoch: 6| Step: 7
Training loss: 0.3196496618182862
Validation loss: 3.167832741285251

Epoch: 6| Step: 8
Training loss: 0.3442660273198688
Validation loss: 3.1654370999343113

Epoch: 6| Step: 9
Training loss: 0.18586976917412903
Validation loss: 3.21360321645461

Epoch: 6| Step: 10
Training loss: 0.30433397079222047
Validation loss: 3.082715208796942

Epoch: 6| Step: 11
Training loss: 0.41301421857285636
Validation loss: 3.226509087638485

Epoch: 6| Step: 12
Training loss: 0.3698984672447597
Validation loss: 3.1763827109006884

Epoch: 6| Step: 13
Training loss: 0.30774957139475745
Validation loss: 3.16837582557862

Epoch: 304| Step: 0
Training loss: 0.32272311018983624
Validation loss: 3.1769268852027985

Epoch: 6| Step: 1
Training loss: 0.3447175929818073
Validation loss: 3.155204574634777

Epoch: 6| Step: 2
Training loss: 0.25191231330528113
Validation loss: 3.131855933570922

Epoch: 6| Step: 3
Training loss: 0.3078916143030255
Validation loss: 3.1440715319485397

Epoch: 6| Step: 4
Training loss: 0.4135862886903684
Validation loss: 3.085983160139852

Epoch: 6| Step: 5
Training loss: 0.6639874584208542
Validation loss: 3.042705702440447

Epoch: 6| Step: 6
Training loss: 0.3842971777250738
Validation loss: 3.1417729950845943

Epoch: 6| Step: 7
Training loss: 0.2879502057517407
Validation loss: 3.18079970994554

Epoch: 6| Step: 8
Training loss: 0.2626344404634523
Validation loss: 3.109462206462654

Epoch: 6| Step: 9
Training loss: 0.43576169382819957
Validation loss: 3.1864097326304517

Epoch: 6| Step: 10
Training loss: 0.4795761501040546
Validation loss: 3.0952943742617087

Epoch: 6| Step: 11
Training loss: 0.3278439998856653
Validation loss: 3.199793241198989

Epoch: 6| Step: 12
Training loss: 0.4476623940836764
Validation loss: 3.1159083164562262

Epoch: 6| Step: 13
Training loss: 0.2683550838477194
Validation loss: 3.048859026905207

Epoch: 305| Step: 0
Training loss: 0.38645766336155046
Validation loss: 3.1215630004690955

Epoch: 6| Step: 1
Training loss: 0.33594198002156733
Validation loss: 3.153512201646383

Epoch: 6| Step: 2
Training loss: 0.30572504282330376
Validation loss: 3.0705510662341977

Epoch: 6| Step: 3
Training loss: 0.34959289043072256
Validation loss: 3.1280530702169504

Epoch: 6| Step: 4
Training loss: 0.4321986772494483
Validation loss: 3.1764674897878296

Epoch: 6| Step: 5
Training loss: 0.41110573722503135
Validation loss: 3.1766236624120157

Epoch: 6| Step: 6
Training loss: 0.4599060058188744
Validation loss: 3.182674707480337

Epoch: 6| Step: 7
Training loss: 0.2745928334752333
Validation loss: 3.1441046573507236

Epoch: 6| Step: 8
Training loss: 0.3782873506617386
Validation loss: 3.0676445212255183

Epoch: 6| Step: 9
Training loss: 0.3999047471417877
Validation loss: 3.010393707997423

Epoch: 6| Step: 10
Training loss: 0.735334702661968
Validation loss: 3.0743259538880907

Epoch: 6| Step: 11
Training loss: 0.3551918460379356
Validation loss: 3.0579027196705835

Epoch: 6| Step: 12
Training loss: 0.2221406940863382
Validation loss: 3.1156872777858737

Epoch: 6| Step: 13
Training loss: 0.26214333156523834
Validation loss: 3.155808496598256

Epoch: 306| Step: 0
Training loss: 0.520839048990041
Validation loss: 3.216529759440205

Epoch: 6| Step: 1
Training loss: 0.42209096961285864
Validation loss: 3.1820437287403522

Epoch: 6| Step: 2
Training loss: 0.4226091143542799
Validation loss: 3.1707396456244523

Epoch: 6| Step: 3
Training loss: 0.3951050202574772
Validation loss: 3.1391248773706883

Epoch: 6| Step: 4
Training loss: 0.35010790311110945
Validation loss: 3.0799756110658305

Epoch: 6| Step: 5
Training loss: 0.46953916876235646
Validation loss: 3.017652854282168

Epoch: 6| Step: 6
Training loss: 0.4811820031716848
Validation loss: 2.9839952104051073

Epoch: 6| Step: 7
Training loss: 0.43980522461338384
Validation loss: 2.9923558864241486

Epoch: 6| Step: 8
Training loss: 0.31321611607272
Validation loss: 2.991273200814838

Epoch: 6| Step: 9
Training loss: 0.380405566473826
Validation loss: 3.0998188053008544

Epoch: 6| Step: 10
Training loss: 0.42291886496638087
Validation loss: 3.121187325651548

Epoch: 6| Step: 11
Training loss: 0.6099710483794036
Validation loss: 3.1665962278328643

Epoch: 6| Step: 12
Training loss: 0.49060448889165814
Validation loss: 3.26996281858376

Epoch: 6| Step: 13
Training loss: 0.4892988054534969
Validation loss: 3.2547987942248366

Epoch: 307| Step: 0
Training loss: 0.6492152777440098
Validation loss: 3.2154929585930163

Epoch: 6| Step: 1
Training loss: 0.4032309851198509
Validation loss: 3.2508794010486697

Epoch: 6| Step: 2
Training loss: 0.34151571426289207
Validation loss: 3.1840075764118643

Epoch: 6| Step: 3
Training loss: 0.25388884851539767
Validation loss: 3.1621072638388568

Epoch: 6| Step: 4
Training loss: 0.2679672613742063
Validation loss: 3.093957707789018

Epoch: 6| Step: 5
Training loss: 0.27360978829493854
Validation loss: 3.1271732275891173

Epoch: 6| Step: 6
Training loss: 0.36080108558312785
Validation loss: 3.1576926959737572

Epoch: 6| Step: 7
Training loss: 0.5380185287539475
Validation loss: 3.082976311986021

Epoch: 6| Step: 8
Training loss: 0.21381750357091378
Validation loss: 3.185599901423412

Epoch: 6| Step: 9
Training loss: 0.3720325440789234
Validation loss: 3.1679924565379567

Epoch: 6| Step: 10
Training loss: 0.376166991521999
Validation loss: 3.196208215847412

Epoch: 6| Step: 11
Training loss: 0.4140891300490957
Validation loss: 3.246447994092743

Epoch: 6| Step: 12
Training loss: 0.39635585712702304
Validation loss: 3.225842855155791

Epoch: 6| Step: 13
Training loss: 0.4365120871346205
Validation loss: 3.188465969346556

Epoch: 308| Step: 0
Training loss: 0.384393231029336
Validation loss: 3.1702437692771555

Epoch: 6| Step: 1
Training loss: 0.3895163252351104
Validation loss: 3.1063172146991334

Epoch: 6| Step: 2
Training loss: 0.2874817282634009
Validation loss: 3.0766232049447773

Epoch: 6| Step: 3
Training loss: 0.3472075191669691
Validation loss: 3.104935996624006

Epoch: 6| Step: 4
Training loss: 0.30197580111732336
Validation loss: 3.135817610915568

Epoch: 6| Step: 5
Training loss: 0.37846187213818283
Validation loss: 3.1450883012594923

Epoch: 6| Step: 6
Training loss: 0.18867172257000628
Validation loss: 3.16347315444758

Epoch: 6| Step: 7
Training loss: 0.32715382358045847
Validation loss: 3.1361345417719333

Epoch: 6| Step: 8
Training loss: 0.5703187968285329
Validation loss: 3.0971918194869983

Epoch: 6| Step: 9
Training loss: 0.31602974849492477
Validation loss: 3.2173360292850504

Epoch: 6| Step: 10
Training loss: 0.2429768404579578
Validation loss: 3.1497589632184266

Epoch: 6| Step: 11
Training loss: 0.4449793422651061
Validation loss: 3.243960282719568

Epoch: 6| Step: 12
Training loss: 0.4204499760819972
Validation loss: 3.109323114572465

Epoch: 6| Step: 13
Training loss: 0.45326921207047854
Validation loss: 3.22660583762559

Epoch: 309| Step: 0
Training loss: 0.2513447150534752
Validation loss: 3.221622012862176

Epoch: 6| Step: 1
Training loss: 0.3952003319868245
Validation loss: 3.190077792726862

Epoch: 6| Step: 2
Training loss: 0.3421582083162197
Validation loss: 3.1262414246626724

Epoch: 6| Step: 3
Training loss: 0.373444270627242
Validation loss: 3.152468364132313

Epoch: 6| Step: 4
Training loss: 0.6283189625913795
Validation loss: 3.0601791358905492

Epoch: 6| Step: 5
Training loss: 0.33658487574968554
Validation loss: 3.0675366628352863

Epoch: 6| Step: 6
Training loss: 0.38169751011783654
Validation loss: 3.0789670615396556

Epoch: 6| Step: 7
Training loss: 0.2353311031201993
Validation loss: 3.142161055367766

Epoch: 6| Step: 8
Training loss: 0.26901877791245477
Validation loss: 3.116406463192065

Epoch: 6| Step: 9
Training loss: 0.3407836719481096
Validation loss: 3.1519200931762383

Epoch: 6| Step: 10
Training loss: 0.3095670633717135
Validation loss: 3.145063411313945

Epoch: 6| Step: 11
Training loss: 0.34296679137763364
Validation loss: 3.1503359337963035

Epoch: 6| Step: 12
Training loss: 0.29690644449047565
Validation loss: 3.1613780749386233

Epoch: 6| Step: 13
Training loss: 0.5015186849214877
Validation loss: 3.1126484469105677

Epoch: 310| Step: 0
Training loss: 0.3507365697429307
Validation loss: 3.0923215606038803

Epoch: 6| Step: 1
Training loss: 0.3680144392995457
Validation loss: 3.159278323300809

Epoch: 6| Step: 2
Training loss: 0.3924820625859398
Validation loss: 3.119512622986861

Epoch: 6| Step: 3
Training loss: 0.33269185937708784
Validation loss: 3.152335972482887

Epoch: 6| Step: 4
Training loss: 0.26423883588480185
Validation loss: 3.0946462983347676

Epoch: 6| Step: 5
Training loss: 0.2727939662340191
Validation loss: 3.128160899868045

Epoch: 6| Step: 6
Training loss: 0.31914367487557854
Validation loss: 3.188725279629106

Epoch: 6| Step: 7
Training loss: 0.341166432561982
Validation loss: 3.240966983850238

Epoch: 6| Step: 8
Training loss: 0.3066163266024769
Validation loss: 3.166032380442727

Epoch: 6| Step: 9
Training loss: 0.2640286892344487
Validation loss: 3.212024761429129

Epoch: 6| Step: 10
Training loss: 0.4958679406192707
Validation loss: 3.147057646596869

Epoch: 6| Step: 11
Training loss: 0.4892545993113128
Validation loss: 3.1786382070132473

Epoch: 6| Step: 12
Training loss: 0.3250109863258326
Validation loss: 3.103456650676365

Epoch: 6| Step: 13
Training loss: 0.34132221505812876
Validation loss: 3.125979689572983

Epoch: 311| Step: 0
Training loss: 0.44394376446529143
Validation loss: 3.1361782990793152

Epoch: 6| Step: 1
Training loss: 0.5839375250660269
Validation loss: 3.1412722678153604

Epoch: 6| Step: 2
Training loss: 0.4033766515513
Validation loss: 3.1376847631960008

Epoch: 6| Step: 3
Training loss: 0.3831132174760136
Validation loss: 3.1767615650435106

Epoch: 6| Step: 4
Training loss: 0.3860418966155063
Validation loss: 3.196565054557054

Epoch: 6| Step: 5
Training loss: 0.24061921162269323
Validation loss: 3.162200844729609

Epoch: 6| Step: 6
Training loss: 0.23372331458014592
Validation loss: 3.1609096815639126

Epoch: 6| Step: 7
Training loss: 0.28879379980638453
Validation loss: 3.183580769081409

Epoch: 6| Step: 8
Training loss: 0.2439552137138497
Validation loss: 3.1259971934969184

Epoch: 6| Step: 9
Training loss: 0.3119167965534465
Validation loss: 3.2169565679598433

Epoch: 6| Step: 10
Training loss: 0.3357469994431498
Validation loss: 3.110298543545046

Epoch: 6| Step: 11
Training loss: 0.28840797657583617
Validation loss: 3.148707363278656

Epoch: 6| Step: 12
Training loss: 0.2816106814737413
Validation loss: 3.1478687842358872

Epoch: 6| Step: 13
Training loss: 0.4127726166984951
Validation loss: 3.201415273999436

Epoch: 312| Step: 0
Training loss: 0.3159594265416127
Validation loss: 3.188340394177938

Epoch: 6| Step: 1
Training loss: 0.3040054218316953
Validation loss: 3.246982494113209

Epoch: 6| Step: 2
Training loss: 0.3793198009912805
Validation loss: 3.1372148336073535

Epoch: 6| Step: 3
Training loss: 0.2620648757068132
Validation loss: 3.202395435147888

Epoch: 6| Step: 4
Training loss: 0.3815521590622542
Validation loss: 3.1838776693917636

Epoch: 6| Step: 5
Training loss: 0.22324861398760049
Validation loss: 3.1384695320605362

Epoch: 6| Step: 6
Training loss: 0.35729392424482814
Validation loss: 3.240116140988046

Epoch: 6| Step: 7
Training loss: 0.34000493754279815
Validation loss: 3.0969394465418394

Epoch: 6| Step: 8
Training loss: 0.36062921511667567
Validation loss: 3.0894578000625463

Epoch: 6| Step: 9
Training loss: 0.3435200984473558
Validation loss: 3.1414734942058598

Epoch: 6| Step: 10
Training loss: 0.39348955775054034
Validation loss: 3.1994982897330706

Epoch: 6| Step: 11
Training loss: 0.5471919639836674
Validation loss: 3.170728516987108

Epoch: 6| Step: 12
Training loss: 0.2792443979754962
Validation loss: 3.1438560629737906

Epoch: 6| Step: 13
Training loss: 0.2628951181421715
Validation loss: 3.0766659811094215

Epoch: 313| Step: 0
Training loss: 0.39001569911952566
Validation loss: 3.12766716623924

Epoch: 6| Step: 1
Training loss: 0.22125364526881533
Validation loss: 3.13111581622726

Epoch: 6| Step: 2
Training loss: 0.19629779245881368
Validation loss: 3.113077792831065

Epoch: 6| Step: 3
Training loss: 0.281062832118528
Validation loss: 3.1535774851458345

Epoch: 6| Step: 4
Training loss: 0.255485888148347
Validation loss: 3.1397864770676596

Epoch: 6| Step: 5
Training loss: 0.24509887322933752
Validation loss: 3.157893014441684

Epoch: 6| Step: 6
Training loss: 0.24868289625868378
Validation loss: 3.194684502431896

Epoch: 6| Step: 7
Training loss: 0.3374913673709696
Validation loss: 3.2612966907804966

Epoch: 6| Step: 8
Training loss: 0.29737677332143725
Validation loss: 3.2044262235666934

Epoch: 6| Step: 9
Training loss: 0.5674546634529166
Validation loss: 3.1322944828008525

Epoch: 6| Step: 10
Training loss: 0.31826976380856536
Validation loss: 3.1960472996855653

Epoch: 6| Step: 11
Training loss: 0.2968587368977817
Validation loss: 3.1586663467326015

Epoch: 6| Step: 12
Training loss: 0.43029977351631943
Validation loss: 3.162434539821079

Epoch: 6| Step: 13
Training loss: 0.2903182102458928
Validation loss: 3.200433012355216

Epoch: 314| Step: 0
Training loss: 0.16592172323181012
Validation loss: 3.2209651941414275

Epoch: 6| Step: 1
Training loss: 0.27402968994316024
Validation loss: 3.225061740333542

Epoch: 6| Step: 2
Training loss: 0.34256048733447625
Validation loss: 3.2223779916564816

Epoch: 6| Step: 3
Training loss: 0.4591416109914093
Validation loss: 3.186730360474618

Epoch: 6| Step: 4
Training loss: 0.39941230904117325
Validation loss: 3.27359923674064

Epoch: 6| Step: 5
Training loss: 0.3140857991548299
Validation loss: 3.1992412934306658

Epoch: 6| Step: 6
Training loss: 0.34147190449115444
Validation loss: 3.1411345971501663

Epoch: 6| Step: 7
Training loss: 0.30588659893690556
Validation loss: 3.12621601605365

Epoch: 6| Step: 8
Training loss: 0.5602632396466469
Validation loss: 3.165702991083453

Epoch: 6| Step: 9
Training loss: 0.3197476826882817
Validation loss: 3.138176148344793

Epoch: 6| Step: 10
Training loss: 0.37371610360189844
Validation loss: 3.172022673578351

Epoch: 6| Step: 11
Training loss: 0.5630478045849029
Validation loss: 3.215621291820488

Epoch: 6| Step: 12
Training loss: 0.4616668555825096
Validation loss: 3.313141754651098

Epoch: 6| Step: 13
Training loss: 0.36561654235969426
Validation loss: 3.228335283784633

Epoch: 315| Step: 0
Training loss: 0.5576759748318579
Validation loss: 3.0960722790420467

Epoch: 6| Step: 1
Training loss: 0.4812361164072038
Validation loss: 3.1862572884130196

Epoch: 6| Step: 2
Training loss: 0.43732629461095196
Validation loss: 3.136312304015123

Epoch: 6| Step: 3
Training loss: 0.3609201963826503
Validation loss: 3.173382305427211

Epoch: 6| Step: 4
Training loss: 0.4076698141301429
Validation loss: 3.094351751714932

Epoch: 6| Step: 5
Training loss: 0.4812530845691862
Validation loss: 3.1060992546524657

Epoch: 6| Step: 6
Training loss: 0.28399864801064906
Validation loss: 3.2033801093508623

Epoch: 6| Step: 7
Training loss: 0.26330938500192336
Validation loss: 3.191100860390039

Epoch: 6| Step: 8
Training loss: 0.37950366400908786
Validation loss: 3.1644932583179406

Epoch: 6| Step: 9
Training loss: 0.41666553219005
Validation loss: 3.2075652817395772

Epoch: 6| Step: 10
Training loss: 0.2598460223614123
Validation loss: 3.2447187845159116

Epoch: 6| Step: 11
Training loss: 0.348081114826221
Validation loss: 3.2356247875303694

Epoch: 6| Step: 12
Training loss: 0.29140657368659895
Validation loss: 3.2120960555569176

Epoch: 6| Step: 13
Training loss: 0.27546670552672664
Validation loss: 3.215889681397973

Epoch: 316| Step: 0
Training loss: 0.4662155617787033
Validation loss: 3.2251120471464825

Epoch: 6| Step: 1
Training loss: 0.3313104772241541
Validation loss: 3.1793799599174584

Epoch: 6| Step: 2
Training loss: 0.36328721810637643
Validation loss: 3.120677081492951

Epoch: 6| Step: 3
Training loss: 0.37751404136160405
Validation loss: 3.1175361635893877

Epoch: 6| Step: 4
Training loss: 0.5022876975199219
Validation loss: 3.0901851987841815

Epoch: 6| Step: 5
Training loss: 0.598970426907284
Validation loss: 3.12545704360415

Epoch: 6| Step: 6
Training loss: 0.29979231122345035
Validation loss: 3.126805470570628

Epoch: 6| Step: 7
Training loss: 0.34493402824721386
Validation loss: 3.197594757942749

Epoch: 6| Step: 8
Training loss: 0.5101748172483211
Validation loss: 3.1552879327653414

Epoch: 6| Step: 9
Training loss: 0.45401643344780784
Validation loss: 3.015998474607242

Epoch: 6| Step: 10
Training loss: 0.4732534403295554
Validation loss: 3.1776040114360162

Epoch: 6| Step: 11
Training loss: 0.4518710906834423
Validation loss: 3.1355773698720975

Epoch: 6| Step: 12
Training loss: 0.4009501757442871
Validation loss: 3.14339217569474

Epoch: 6| Step: 13
Training loss: 0.2968849255759749
Validation loss: 3.109512594427846

Epoch: 317| Step: 0
Training loss: 0.40641660208535685
Validation loss: 3.042339124331398

Epoch: 6| Step: 1
Training loss: 0.450322065073118
Validation loss: 3.1355306577185886

Epoch: 6| Step: 2
Training loss: 0.5973731972602739
Validation loss: 3.0973856592511044

Epoch: 6| Step: 3
Training loss: 0.5121896629916237
Validation loss: 3.047107772412685

Epoch: 6| Step: 4
Training loss: 0.36403258368566854
Validation loss: 3.1460155324825303

Epoch: 6| Step: 5
Training loss: 0.2876234836347746
Validation loss: 3.2069092145368523

Epoch: 6| Step: 6
Training loss: 0.393482059564198
Validation loss: 3.210207891060469

Epoch: 6| Step: 7
Training loss: 0.3319656531666987
Validation loss: 3.2682682637868847

Epoch: 6| Step: 8
Training loss: 0.3538274496235869
Validation loss: 3.139626314155466

Epoch: 6| Step: 9
Training loss: 0.409291582126111
Validation loss: 3.143397838972989

Epoch: 6| Step: 10
Training loss: 0.6131505644715346
Validation loss: 3.13116814004439

Epoch: 6| Step: 11
Training loss: 0.3336966317973083
Validation loss: 3.1858753289952086

Epoch: 6| Step: 12
Training loss: 0.4253721459108303
Validation loss: 3.1852119935576666

Epoch: 6| Step: 13
Training loss: 0.28569013443480973
Validation loss: 3.201270557532686

Epoch: 318| Step: 0
Training loss: 0.2802058015352096
Validation loss: 3.1827125999317376

Epoch: 6| Step: 1
Training loss: 0.23863322417972563
Validation loss: 3.2024864366627805

Epoch: 6| Step: 2
Training loss: 0.4280369354781722
Validation loss: 3.2867104644707226

Epoch: 6| Step: 3
Training loss: 0.4833353020638896
Validation loss: 3.234908485336674

Epoch: 6| Step: 4
Training loss: 0.4702026428984823
Validation loss: 3.268123808399926

Epoch: 6| Step: 5
Training loss: 0.5182844704363193
Validation loss: 3.198594451218962

Epoch: 6| Step: 6
Training loss: 0.3597165019309993
Validation loss: 3.1268508008027753

Epoch: 6| Step: 7
Training loss: 0.27146521850621547
Validation loss: 3.150590146505174

Epoch: 6| Step: 8
Training loss: 0.4655432686983724
Validation loss: 3.1100716505352435

Epoch: 6| Step: 9
Training loss: 0.4792673862031792
Validation loss: 3.118775564737471

Epoch: 6| Step: 10
Training loss: 0.5606648125009271
Validation loss: 3.1964181418830986

Epoch: 6| Step: 11
Training loss: 0.2712514550525999
Validation loss: 3.1131139412743325

Epoch: 6| Step: 12
Training loss: 0.5902326198832019
Validation loss: 3.1894281327560443

Epoch: 6| Step: 13
Training loss: 0.3069176606944098
Validation loss: 3.2252112785151614

Epoch: 319| Step: 0
Training loss: 0.32685296679138404
Validation loss: 3.2318822865578287

Epoch: 6| Step: 1
Training loss: 0.40752019747312357
Validation loss: 3.2685031284641957

Epoch: 6| Step: 2
Training loss: 0.30631453797480285
Validation loss: 3.24366236466037

Epoch: 6| Step: 3
Training loss: 0.29520237448678743
Validation loss: 3.1847572119742193

Epoch: 6| Step: 4
Training loss: 0.35927368892170053
Validation loss: 3.127606106306751

Epoch: 6| Step: 5
Training loss: 0.7282871982517334
Validation loss: 3.0734971397986075

Epoch: 6| Step: 6
Training loss: 0.4249431866650902
Validation loss: 3.0748784328094008

Epoch: 6| Step: 7
Training loss: 0.5351664966799595
Validation loss: 3.096489345379241

Epoch: 6| Step: 8
Training loss: 0.4342287585850727
Validation loss: 3.161407977252519

Epoch: 6| Step: 9
Training loss: 0.4981607493946451
Validation loss: 3.1083894122862876

Epoch: 6| Step: 10
Training loss: 0.37731149665935443
Validation loss: 3.147007190563196

Epoch: 6| Step: 11
Training loss: 0.3868444989680426
Validation loss: 3.31997123610051

Epoch: 6| Step: 12
Training loss: 0.5539943501256677
Validation loss: 3.3254882085997677

Epoch: 6| Step: 13
Training loss: 0.45427477414664713
Validation loss: 3.366679519842811

Epoch: 320| Step: 0
Training loss: 0.32679114117609104
Validation loss: 3.3054761253736875

Epoch: 6| Step: 1
Training loss: 0.3439447978079225
Validation loss: 3.292144491225246

Epoch: 6| Step: 2
Training loss: 0.5539964750380904
Validation loss: 3.167432909834334

Epoch: 6| Step: 3
Training loss: 0.45868271999568777
Validation loss: 3.1137559402023247

Epoch: 6| Step: 4
Training loss: 0.4094884795232355
Validation loss: 3.1456270634476216

Epoch: 6| Step: 5
Training loss: 0.4128568839413203
Validation loss: 3.1793243175796575

Epoch: 6| Step: 6
Training loss: 0.5181825958745009
Validation loss: 3.184748253427347

Epoch: 6| Step: 7
Training loss: 0.33943783426031277
Validation loss: 3.1453746478097697

Epoch: 6| Step: 8
Training loss: 0.24647113837053103
Validation loss: 3.1482018318668707

Epoch: 6| Step: 9
Training loss: 0.33827910389560834
Validation loss: 3.160733415844907

Epoch: 6| Step: 10
Training loss: 0.45033761710880843
Validation loss: 3.211172449530004

Epoch: 6| Step: 11
Training loss: 0.3412034905706789
Validation loss: 3.253596968528393

Epoch: 6| Step: 12
Training loss: 0.34310102974871387
Validation loss: 3.1971222867315716

Epoch: 6| Step: 13
Training loss: 0.3332422052431935
Validation loss: 3.1811235513894314

Epoch: 321| Step: 0
Training loss: 0.29176571844362276
Validation loss: 3.162250015370173

Epoch: 6| Step: 1
Training loss: 0.30518728005680407
Validation loss: 3.096159962862075

Epoch: 6| Step: 2
Training loss: 0.4555731769806847
Validation loss: 3.089685988226654

Epoch: 6| Step: 3
Training loss: 0.30263438880912263
Validation loss: 3.1411675258202223

Epoch: 6| Step: 4
Training loss: 0.3109751692914283
Validation loss: 3.118703105627468

Epoch: 6| Step: 5
Training loss: 0.27550350067386176
Validation loss: 3.101371458177052

Epoch: 6| Step: 6
Training loss: 0.6747685600800813
Validation loss: 3.13213580172628

Epoch: 6| Step: 7
Training loss: 0.3045144078513556
Validation loss: 3.2253891333084197

Epoch: 6| Step: 8
Training loss: 0.26191439361892693
Validation loss: 3.184692804701896

Epoch: 6| Step: 9
Training loss: 0.3590740104404033
Validation loss: 3.1287111117518926

Epoch: 6| Step: 10
Training loss: 0.31537255634883693
Validation loss: 3.166694607527757

Epoch: 6| Step: 11
Training loss: 0.27831276331250243
Validation loss: 3.1774663266994603

Epoch: 6| Step: 12
Training loss: 0.35609653078460574
Validation loss: 3.146282016680666

Epoch: 6| Step: 13
Training loss: 0.35339427150726094
Validation loss: 3.127232428106917

Epoch: 322| Step: 0
Training loss: 0.37121146493380724
Validation loss: 3.18067701784298

Epoch: 6| Step: 1
Training loss: 0.27561688428508685
Validation loss: 3.200328431063884

Epoch: 6| Step: 2
Training loss: 0.5731638606301265
Validation loss: 3.2132516706412817

Epoch: 6| Step: 3
Training loss: 0.27928222937965497
Validation loss: 3.2194979517756854

Epoch: 6| Step: 4
Training loss: 0.22542227550927654
Validation loss: 3.2531847755004595

Epoch: 6| Step: 5
Training loss: 0.27292899123360037
Validation loss: 3.18219281598205

Epoch: 6| Step: 6
Training loss: 0.2686220674083991
Validation loss: 3.155556630938829

Epoch: 6| Step: 7
Training loss: 0.3720492059122682
Validation loss: 3.1830769936640206

Epoch: 6| Step: 8
Training loss: 0.2400327161752356
Validation loss: 3.147858016559419

Epoch: 6| Step: 9
Training loss: 0.36055640211154544
Validation loss: 3.1552884868836335

Epoch: 6| Step: 10
Training loss: 0.3042178569245712
Validation loss: 3.186800188023248

Epoch: 6| Step: 11
Training loss: 0.39270803095690404
Validation loss: 3.1640547010537565

Epoch: 6| Step: 12
Training loss: 0.22019335859757175
Validation loss: 3.1971542161885598

Epoch: 6| Step: 13
Training loss: 0.41008748885932106
Validation loss: 3.1015047825488358

Epoch: 323| Step: 0
Training loss: 0.34179195945474844
Validation loss: 3.1462199160956645

Epoch: 6| Step: 1
Training loss: 0.2946725511450605
Validation loss: 3.122851777796935

Epoch: 6| Step: 2
Training loss: 0.3088357073439071
Validation loss: 3.208947845331554

Epoch: 6| Step: 3
Training loss: 0.36897912100258445
Validation loss: 3.1324298907220736

Epoch: 6| Step: 4
Training loss: 0.25759329290973054
Validation loss: 3.27326850788724

Epoch: 6| Step: 5
Training loss: 0.30803497039910444
Validation loss: 3.1520642893725

Epoch: 6| Step: 6
Training loss: 0.22682058498849855
Validation loss: 3.2254665259104267

Epoch: 6| Step: 7
Training loss: 0.38987920137412246
Validation loss: 3.2027475770480556

Epoch: 6| Step: 8
Training loss: 0.3082430331424381
Validation loss: 3.2038913709407715

Epoch: 6| Step: 9
Training loss: 0.31720268419875036
Validation loss: 3.2351815267000856

Epoch: 6| Step: 10
Training loss: 0.3751193293810537
Validation loss: 3.165658455684773

Epoch: 6| Step: 11
Training loss: 0.2567142444849076
Validation loss: 3.226622179909566

Epoch: 6| Step: 12
Training loss: 0.35780301643697177
Validation loss: 3.1740329461153545

Epoch: 6| Step: 13
Training loss: 0.6327718321365818
Validation loss: 3.25042746251421

Epoch: 324| Step: 0
Training loss: 0.26583800470698254
Validation loss: 3.2496796841372575

Epoch: 6| Step: 1
Training loss: 0.3811210711368327
Validation loss: 3.1950819061319358

Epoch: 6| Step: 2
Training loss: 0.2771964151955011
Validation loss: 3.156945520193738

Epoch: 6| Step: 3
Training loss: 0.2764152242477024
Validation loss: 3.1913930518361067

Epoch: 6| Step: 4
Training loss: 0.3071512356693364
Validation loss: 3.2352156598561717

Epoch: 6| Step: 5
Training loss: 0.4221768712047755
Validation loss: 3.1335675858798866

Epoch: 6| Step: 6
Training loss: 0.4145930867349764
Validation loss: 3.187722391585732

Epoch: 6| Step: 7
Training loss: 0.5299838629551171
Validation loss: 3.186244792253048

Epoch: 6| Step: 8
Training loss: 0.2000880628662619
Validation loss: 3.1971478775517777

Epoch: 6| Step: 9
Training loss: 0.3302899194684589
Validation loss: 3.2093665866066745

Epoch: 6| Step: 10
Training loss: 0.2292739154817061
Validation loss: 3.208136952983191

Epoch: 6| Step: 11
Training loss: 0.21944490818653387
Validation loss: 3.136098899419582

Epoch: 6| Step: 12
Training loss: 0.34669456987271147
Validation loss: 3.141999167057949

Epoch: 6| Step: 13
Training loss: 0.2663088578550556
Validation loss: 3.117230930519786

Epoch: 325| Step: 0
Training loss: 0.2870270617557939
Validation loss: 3.0957888682591976

Epoch: 6| Step: 1
Training loss: 0.27192808159220755
Validation loss: 3.1629973074577644

Epoch: 6| Step: 2
Training loss: 0.4200629418757731
Validation loss: 3.1782192805136473

Epoch: 6| Step: 3
Training loss: 0.5258100175852223
Validation loss: 3.142919154814574

Epoch: 6| Step: 4
Training loss: 0.23124348012651258
Validation loss: 3.186468792827824

Epoch: 6| Step: 5
Training loss: 0.31842239317844095
Validation loss: 3.1090866926451275

Epoch: 6| Step: 6
Training loss: 0.2683908968740493
Validation loss: 3.12992498773099

Epoch: 6| Step: 7
Training loss: 0.47208311468401587
Validation loss: 3.163038978334079

Epoch: 6| Step: 8
Training loss: 0.20669039071111706
Validation loss: 3.183772344591949

Epoch: 6| Step: 9
Training loss: 0.2351217612135241
Validation loss: 3.1479970215278827

Epoch: 6| Step: 10
Training loss: 0.3902772881756325
Validation loss: 3.1690212998882648

Epoch: 6| Step: 11
Training loss: 0.34226372579619296
Validation loss: 3.1733079000730733

Epoch: 6| Step: 12
Training loss: 0.41223296350725397
Validation loss: 3.213742604869721

Epoch: 6| Step: 13
Training loss: 0.21830380437238403
Validation loss: 3.176027733378231

Epoch: 326| Step: 0
Training loss: 0.317619001096953
Validation loss: 3.2040324220616294

Epoch: 6| Step: 1
Training loss: 0.31560236453103085
Validation loss: 3.1077741019291967

Epoch: 6| Step: 2
Training loss: 0.3060097491606184
Validation loss: 3.1065488716299567

Epoch: 6| Step: 3
Training loss: 0.3114825254738929
Validation loss: 3.1002136807989142

Epoch: 6| Step: 4
Training loss: 0.4189431428297365
Validation loss: 3.1350823073100327

Epoch: 6| Step: 5
Training loss: 0.23768086699048388
Validation loss: 3.183429674784461

Epoch: 6| Step: 6
Training loss: 0.31481691014160296
Validation loss: 3.2108992847355853

Epoch: 6| Step: 7
Training loss: 0.4526782299705802
Validation loss: 3.257075188964822

Epoch: 6| Step: 8
Training loss: 0.4482856180929572
Validation loss: 3.1812786773008632

Epoch: 6| Step: 9
Training loss: 0.3349413073601483
Validation loss: 3.182287454472245

Epoch: 6| Step: 10
Training loss: 0.4046669339878785
Validation loss: 3.25278861889841

Epoch: 6| Step: 11
Training loss: 0.3758579215586789
Validation loss: 3.1747492653671436

Epoch: 6| Step: 12
Training loss: 0.36226170534239127
Validation loss: 3.1485169608136023

Epoch: 6| Step: 13
Training loss: 0.3877392607025022
Validation loss: 3.1497895246154846

Epoch: 327| Step: 0
Training loss: 0.3627838297908373
Validation loss: 3.0561556332821342

Epoch: 6| Step: 1
Training loss: 0.4864697537385176
Validation loss: 3.0592359028706233

Epoch: 6| Step: 2
Training loss: 0.3505782442656728
Validation loss: 3.2168805517397403

Epoch: 6| Step: 3
Training loss: 0.3567631180014861
Validation loss: 3.15285173031586

Epoch: 6| Step: 4
Training loss: 0.38328744658582464
Validation loss: 3.1680591976425982

Epoch: 6| Step: 5
Training loss: 0.3355115363415918
Validation loss: 3.1569263123942903

Epoch: 6| Step: 6
Training loss: 0.2817514902386861
Validation loss: 3.155574537460414

Epoch: 6| Step: 7
Training loss: 0.33730978462154004
Validation loss: 3.173039427745432

Epoch: 6| Step: 8
Training loss: 0.5448537531011858
Validation loss: 3.252264407727483

Epoch: 6| Step: 9
Training loss: 0.48812296018284157
Validation loss: 3.210436222644798

Epoch: 6| Step: 10
Training loss: 0.35401800719491466
Validation loss: 3.091934904679099

Epoch: 6| Step: 11
Training loss: 0.34651328378042895
Validation loss: 3.1314974567147797

Epoch: 6| Step: 12
Training loss: 0.3211299769066739
Validation loss: 3.156966980932348

Epoch: 6| Step: 13
Training loss: 0.40210794742464967
Validation loss: 3.1580289605125205

Epoch: 328| Step: 0
Training loss: 0.41780680790221547
Validation loss: 3.1200917672249555

Epoch: 6| Step: 1
Training loss: 0.3211683608939027
Validation loss: 3.184896852249311

Epoch: 6| Step: 2
Training loss: 0.2763420740585988
Validation loss: 3.1026508718197032

Epoch: 6| Step: 3
Training loss: 0.39227397011041937
Validation loss: 3.231375133912482

Epoch: 6| Step: 4
Training loss: 0.42491830643706985
Validation loss: 3.220871704452028

Epoch: 6| Step: 5
Training loss: 0.29451720156164923
Validation loss: 3.1516741199361573

Epoch: 6| Step: 6
Training loss: 0.3797142615914401
Validation loss: 3.125016555742278

Epoch: 6| Step: 7
Training loss: 0.3067467742686582
Validation loss: 3.165426316699547

Epoch: 6| Step: 8
Training loss: 0.42113261777736904
Validation loss: 3.1553262674467613

Epoch: 6| Step: 9
Training loss: 0.29001422094960183
Validation loss: 3.1568198869841533

Epoch: 6| Step: 10
Training loss: 0.2578045670415912
Validation loss: 3.1001948841426086

Epoch: 6| Step: 11
Training loss: 0.3040412627445706
Validation loss: 3.138963503405555

Epoch: 6| Step: 12
Training loss: 0.3569325918034843
Validation loss: 3.109061782882331

Epoch: 6| Step: 13
Training loss: 0.5549689639924679
Validation loss: 3.129233798353731

Epoch: 329| Step: 0
Training loss: 0.37665559955320166
Validation loss: 3.1045229961174123

Epoch: 6| Step: 1
Training loss: 0.23020442255216705
Validation loss: 3.170034479039969

Epoch: 6| Step: 2
Training loss: 0.2715027754880622
Validation loss: 3.150657546325486

Epoch: 6| Step: 3
Training loss: 0.29261577959782453
Validation loss: 3.189812413582659

Epoch: 6| Step: 4
Training loss: 0.3922890505076303
Validation loss: 3.143533211040499

Epoch: 6| Step: 5
Training loss: 0.3497209104645586
Validation loss: 3.1429207225660276

Epoch: 6| Step: 6
Training loss: 0.42500689725328
Validation loss: 3.1255766400147666

Epoch: 6| Step: 7
Training loss: 0.17532643182071403
Validation loss: 3.07895032271505

Epoch: 6| Step: 8
Training loss: 0.3363776760838326
Validation loss: 3.185520405116561

Epoch: 6| Step: 9
Training loss: 0.6264397726892149
Validation loss: 3.1316502826039443

Epoch: 6| Step: 10
Training loss: 0.3176839485607858
Validation loss: 3.1550606730935122

Epoch: 6| Step: 11
Training loss: 0.3657600780944645
Validation loss: 3.106542245790975

Epoch: 6| Step: 12
Training loss: 0.3377115293175473
Validation loss: 3.2093028713244496

Epoch: 6| Step: 13
Training loss: 0.36526966434472213
Validation loss: 3.166580780437321

Epoch: 330| Step: 0
Training loss: 0.39316746141278736
Validation loss: 3.2195518260342424

Epoch: 6| Step: 1
Training loss: 0.24664475804546243
Validation loss: 3.248500967330832

Epoch: 6| Step: 2
Training loss: 0.5812256890001734
Validation loss: 3.2571295518651167

Epoch: 6| Step: 3
Training loss: 0.4953974846456872
Validation loss: 3.190564035498886

Epoch: 6| Step: 4
Training loss: 0.285561613127846
Validation loss: 3.153086471196198

Epoch: 6| Step: 5
Training loss: 0.19661781906261136
Validation loss: 3.1952160958294904

Epoch: 6| Step: 6
Training loss: 0.3115046624053631
Validation loss: 3.1410340000123207

Epoch: 6| Step: 7
Training loss: 0.25015551975007844
Validation loss: 3.145729901127071

Epoch: 6| Step: 8
Training loss: 0.3199243519818712
Validation loss: 3.0682945964991966

Epoch: 6| Step: 9
Training loss: 0.3028146821839997
Validation loss: 3.028996865726905

Epoch: 6| Step: 10
Training loss: 0.3520888944145292
Validation loss: 3.14489236025831

Epoch: 6| Step: 11
Training loss: 0.28348251241910893
Validation loss: 3.1136251951218585

Epoch: 6| Step: 12
Training loss: 0.21923041382672645
Validation loss: 3.1597183860969777

Epoch: 6| Step: 13
Training loss: 0.3611874693239974
Validation loss: 3.1477527615289635

Epoch: 331| Step: 0
Training loss: 0.4762201799483502
Validation loss: 3.1849428278943352

Epoch: 6| Step: 1
Training loss: 0.4440321334345758
Validation loss: 3.1981070189510703

Epoch: 6| Step: 2
Training loss: 0.4146966037455255
Validation loss: 3.1826397111846183

Epoch: 6| Step: 3
Training loss: 0.24130528261328243
Validation loss: 3.150824273967524

Epoch: 6| Step: 4
Training loss: 0.20335511780897986
Validation loss: 3.1139406329992405

Epoch: 6| Step: 5
Training loss: 0.3975099725491953
Validation loss: 3.10493289954863

Epoch: 6| Step: 6
Training loss: 0.46446799470216016
Validation loss: 3.128080401132831

Epoch: 6| Step: 7
Training loss: 0.43753651057894544
Validation loss: 3.0706673142902763

Epoch: 6| Step: 8
Training loss: 0.37302248810151906
Validation loss: 3.1222836450694462

Epoch: 6| Step: 9
Training loss: 0.3122758419034678
Validation loss: 3.167065536742782

Epoch: 6| Step: 10
Training loss: 0.3122393236114126
Validation loss: 3.2342588001453985

Epoch: 6| Step: 11
Training loss: 0.4122450365712733
Validation loss: 3.1930825956362185

Epoch: 6| Step: 12
Training loss: 0.36491512686799554
Validation loss: 3.1874375181369725

Epoch: 6| Step: 13
Training loss: 0.258019335458407
Validation loss: 3.22563978399131

Epoch: 332| Step: 0
Training loss: 0.25680080507135905
Validation loss: 3.222364229785428

Epoch: 6| Step: 1
Training loss: 0.38938179549017077
Validation loss: 3.1563221762685543

Epoch: 6| Step: 2
Training loss: 0.3065129396933809
Validation loss: 3.1210359353959967

Epoch: 6| Step: 3
Training loss: 0.35966944035216863
Validation loss: 3.246988784416651

Epoch: 6| Step: 4
Training loss: 0.282250215271833
Validation loss: 3.1252608762569687

Epoch: 6| Step: 5
Training loss: 0.32828320367840924
Validation loss: 3.1279357598855486

Epoch: 6| Step: 6
Training loss: 0.33834836527515605
Validation loss: 3.1602270167930113

Epoch: 6| Step: 7
Training loss: 0.27929292689380614
Validation loss: 3.1632876982041807

Epoch: 6| Step: 8
Training loss: 0.3869904613600771
Validation loss: 3.135386791065792

Epoch: 6| Step: 9
Training loss: 0.35330825329598137
Validation loss: 3.1273652852880027

Epoch: 6| Step: 10
Training loss: 0.3607176701631092
Validation loss: 3.1735922763932414

Epoch: 6| Step: 11
Training loss: 0.32302585288933744
Validation loss: 3.162891777308162

Epoch: 6| Step: 12
Training loss: 0.5638601759186264
Validation loss: 3.1494160686161248

Epoch: 6| Step: 13
Training loss: 0.3896148973145886
Validation loss: 3.182868484856147

Epoch: 333| Step: 0
Training loss: 0.2658295124600501
Validation loss: 3.1553395283171626

Epoch: 6| Step: 1
Training loss: 0.30395699006364035
Validation loss: 3.1501029053283514

Epoch: 6| Step: 2
Training loss: 0.3804336907685055
Validation loss: 3.107964353845483

Epoch: 6| Step: 3
Training loss: 0.32158592678181536
Validation loss: 3.1250796625791835

Epoch: 6| Step: 4
Training loss: 0.34340390208520666
Validation loss: 3.2107290678291704

Epoch: 6| Step: 5
Training loss: 0.3904535107884529
Validation loss: 3.1865758241756024

Epoch: 6| Step: 6
Training loss: 0.5550116008542747
Validation loss: 3.127973299162127

Epoch: 6| Step: 7
Training loss: 0.1779326705598809
Validation loss: 3.202476808045602

Epoch: 6| Step: 8
Training loss: 0.2233988525071936
Validation loss: 3.1917765109596403

Epoch: 6| Step: 9
Training loss: 0.25633637903022066
Validation loss: 3.1783044855028515

Epoch: 6| Step: 10
Training loss: 0.3395719208389085
Validation loss: 3.167397406406187

Epoch: 6| Step: 11
Training loss: 0.25387913485774954
Validation loss: 3.164853924016357

Epoch: 6| Step: 12
Training loss: 0.2636883200709323
Validation loss: 3.1262306460483478

Epoch: 6| Step: 13
Training loss: 0.43711420487777164
Validation loss: 3.178216392380811

Epoch: 334| Step: 0
Training loss: 0.34662629911865045
Validation loss: 3.133704498471942

Epoch: 6| Step: 1
Training loss: 0.29811697219340616
Validation loss: 3.1676469130594755

Epoch: 6| Step: 2
Training loss: 0.2427258660501299
Validation loss: 3.1673993384050956

Epoch: 6| Step: 3
Training loss: 0.2759086660352152
Validation loss: 3.1399915571969923

Epoch: 6| Step: 4
Training loss: 0.24821537782457234
Validation loss: 3.1322520857503693

Epoch: 6| Step: 5
Training loss: 0.36206958062392947
Validation loss: 3.2120775857915973

Epoch: 6| Step: 6
Training loss: 0.512238042454486
Validation loss: 3.1511626963846053

Epoch: 6| Step: 7
Training loss: 0.3565117342998638
Validation loss: 3.1929410981319615

Epoch: 6| Step: 8
Training loss: 0.33124607596682276
Validation loss: 3.1342379021826066

Epoch: 6| Step: 9
Training loss: 0.3148490711264185
Validation loss: 3.1135943489471676

Epoch: 6| Step: 10
Training loss: 0.30066584565381144
Validation loss: 3.1309336976518356

Epoch: 6| Step: 11
Training loss: 0.34541101560736504
Validation loss: 3.208419245440746

Epoch: 6| Step: 12
Training loss: 0.33873000652530466
Validation loss: 3.216997613995503

Epoch: 6| Step: 13
Training loss: 0.2663676454870469
Validation loss: 3.194439856668762

Epoch: 335| Step: 0
Training loss: 0.33327354948051374
Validation loss: 3.261501598934187

Epoch: 6| Step: 1
Training loss: 0.3496408075449025
Validation loss: 3.200447389997938

Epoch: 6| Step: 2
Training loss: 0.355473046748424
Validation loss: 3.236197629180443

Epoch: 6| Step: 3
Training loss: 0.5666371368212479
Validation loss: 3.2314517683124353

Epoch: 6| Step: 4
Training loss: 0.34535719379467505
Validation loss: 3.210786814375339

Epoch: 6| Step: 5
Training loss: 0.466666518648442
Validation loss: 3.077603523502658

Epoch: 6| Step: 6
Training loss: 0.31320247373182564
Validation loss: 3.0878564461528204

Epoch: 6| Step: 7
Training loss: 0.31047937871270503
Validation loss: 3.08553178268974

Epoch: 6| Step: 8
Training loss: 0.3429849520877371
Validation loss: 3.130791929727835

Epoch: 6| Step: 9
Training loss: 0.3734205681062767
Validation loss: 3.1283125296219207

Epoch: 6| Step: 10
Training loss: 0.42434146223287994
Validation loss: 3.160679657936017

Epoch: 6| Step: 11
Training loss: 0.37737057355550924
Validation loss: 3.14219761534937

Epoch: 6| Step: 12
Training loss: 0.5404527400772888
Validation loss: 3.1561576401696474

Epoch: 6| Step: 13
Training loss: 0.3987058595962052
Validation loss: 3.1043554073703894

Epoch: 336| Step: 0
Training loss: 0.3233294182020929
Validation loss: 3.067465227961651

Epoch: 6| Step: 1
Training loss: 0.2779036230222423
Validation loss: 3.062252553687483

Epoch: 6| Step: 2
Training loss: 0.4065015270948172
Validation loss: 3.0476481964570783

Epoch: 6| Step: 3
Training loss: 0.6025753659482306
Validation loss: 3.0769847042227148

Epoch: 6| Step: 4
Training loss: 0.43671900999986146
Validation loss: 3.0424926542069612

Epoch: 6| Step: 5
Training loss: 0.24522208442768978
Validation loss: 3.1084288622483434

Epoch: 6| Step: 6
Training loss: 0.2333042641112677
Validation loss: 3.1516575907538376

Epoch: 6| Step: 7
Training loss: 0.2947814809344756
Validation loss: 3.1471313973168225

Epoch: 6| Step: 8
Training loss: 0.44765358969012775
Validation loss: 3.206469828584406

Epoch: 6| Step: 9
Training loss: 0.4157728104449823
Validation loss: 3.2500156622289187

Epoch: 6| Step: 10
Training loss: 0.42409939149355524
Validation loss: 3.105643315876995

Epoch: 6| Step: 11
Training loss: 0.3731644330361802
Validation loss: 3.142778306855782

Epoch: 6| Step: 12
Training loss: 0.24902061012009344
Validation loss: 3.1506392839417345

Epoch: 6| Step: 13
Training loss: 0.23291645801264152
Validation loss: 3.11933204351753

Epoch: 337| Step: 0
Training loss: 0.2670356932706228
Validation loss: 3.0822608001665808

Epoch: 6| Step: 1
Training loss: 0.40605991758324206
Validation loss: 3.127083134931795

Epoch: 6| Step: 2
Training loss: 0.4657443642431428
Validation loss: 3.1180174701821937

Epoch: 6| Step: 3
Training loss: 0.4718520834707522
Validation loss: 3.090266350333317

Epoch: 6| Step: 4
Training loss: 0.3537323640329532
Validation loss: 3.1914744437942226

Epoch: 6| Step: 5
Training loss: 0.492415647762383
Validation loss: 3.1727866380130267

Epoch: 6| Step: 6
Training loss: 0.34125867705090346
Validation loss: 3.217581811658655

Epoch: 6| Step: 7
Training loss: 0.48123128594512155
Validation loss: 3.2294515463570503

Epoch: 6| Step: 8
Training loss: 0.41362357717657244
Validation loss: 3.2319181389733784

Epoch: 6| Step: 9
Training loss: 0.398466894524058
Validation loss: 3.1528653166760026

Epoch: 6| Step: 10
Training loss: 0.32619046826390774
Validation loss: 3.184286180330054

Epoch: 6| Step: 11
Training loss: 0.2958944087493888
Validation loss: 3.1140847631036035

Epoch: 6| Step: 12
Training loss: 0.42969710599392147
Validation loss: 3.082430647260386

Epoch: 6| Step: 13
Training loss: 0.3849421062537635
Validation loss: 3.088949106926939

Epoch: 338| Step: 0
Training loss: 0.24649056730638355
Validation loss: 3.1440497683314166

Epoch: 6| Step: 1
Training loss: 0.317773619442485
Validation loss: 3.1690894236660885

Epoch: 6| Step: 2
Training loss: 0.1952109645135569
Validation loss: 3.201769707997649

Epoch: 6| Step: 3
Training loss: 0.20420849203017827
Validation loss: 3.252120328925332

Epoch: 6| Step: 4
Training loss: 0.45092654473313565
Validation loss: 3.2559242905688297

Epoch: 6| Step: 5
Training loss: 0.3081340504491322
Validation loss: 3.2501843595789186

Epoch: 6| Step: 6
Training loss: 0.3474867975690949
Validation loss: 3.2628409337865234

Epoch: 6| Step: 7
Training loss: 0.2904433698067181
Validation loss: 3.1808973880148397

Epoch: 6| Step: 8
Training loss: 0.3843888698959738
Validation loss: 3.1182923490181462

Epoch: 6| Step: 9
Training loss: 0.47865853802987796
Validation loss: 3.1127354212409233

Epoch: 6| Step: 10
Training loss: 0.43847544102854563
Validation loss: 3.150000740232835

Epoch: 6| Step: 11
Training loss: 0.3197378842837427
Validation loss: 3.1790670903428127

Epoch: 6| Step: 12
Training loss: 0.29408681511558643
Validation loss: 3.2132321563662933

Epoch: 6| Step: 13
Training loss: 0.4524841380632276
Validation loss: 3.222448427839718

Epoch: 339| Step: 0
Training loss: 0.3359008591652569
Validation loss: 3.24645842253143

Epoch: 6| Step: 1
Training loss: 0.3067620152542949
Validation loss: 3.284741508923704

Epoch: 6| Step: 2
Training loss: 0.4233694451178574
Validation loss: 3.315899394213671

Epoch: 6| Step: 3
Training loss: 0.4308251838571239
Validation loss: 3.2454745623658785

Epoch: 6| Step: 4
Training loss: 0.2950846746928264
Validation loss: 3.191359819613771

Epoch: 6| Step: 5
Training loss: 0.4661166929659212
Validation loss: 3.153861208847571

Epoch: 6| Step: 6
Training loss: 0.3651699070463886
Validation loss: 3.1875231124937566

Epoch: 6| Step: 7
Training loss: 0.3325147810497251
Validation loss: 3.16203178890205

Epoch: 6| Step: 8
Training loss: 0.35632075393503215
Validation loss: 3.1447014361781642

Epoch: 6| Step: 9
Training loss: 0.31255704835875464
Validation loss: 3.2007548673692514

Epoch: 6| Step: 10
Training loss: 0.23689906457285173
Validation loss: 3.152899219304522

Epoch: 6| Step: 11
Training loss: 0.22656541033223862
Validation loss: 3.24702303820928

Epoch: 6| Step: 12
Training loss: 0.4174336011133084
Validation loss: 3.14820107455009

Epoch: 6| Step: 13
Training loss: 0.2508837754729979
Validation loss: 3.1734072863018423

Epoch: 340| Step: 0
Training loss: 0.3552135138073294
Validation loss: 3.203123312848895

Epoch: 6| Step: 1
Training loss: 0.29827612962918926
Validation loss: 3.177984583030454

Epoch: 6| Step: 2
Training loss: 0.2715463773333353
Validation loss: 3.1981102370204137

Epoch: 6| Step: 3
Training loss: 0.21532881338608623
Validation loss: 3.1635818053508484

Epoch: 6| Step: 4
Training loss: 0.2918432487396076
Validation loss: 3.165534938222772

Epoch: 6| Step: 5
Training loss: 0.3333547803813812
Validation loss: 3.16754705755921

Epoch: 6| Step: 6
Training loss: 0.17398732642354145
Validation loss: 3.178589639922784

Epoch: 6| Step: 7
Training loss: 0.3509976299503386
Validation loss: 3.187127047891574

Epoch: 6| Step: 8
Training loss: 0.483918359301334
Validation loss: 3.2175822809502885

Epoch: 6| Step: 9
Training loss: 0.2861193630976476
Validation loss: 3.2030336072335532

Epoch: 6| Step: 10
Training loss: 0.2976243950726715
Validation loss: 3.1983133664351917

Epoch: 6| Step: 11
Training loss: 0.4338508393647402
Validation loss: 3.2585206455202798

Epoch: 6| Step: 12
Training loss: 0.276629993586711
Validation loss: 3.190027905026222

Epoch: 6| Step: 13
Training loss: 0.6074491047045555
Validation loss: 3.183191997243203

Epoch: 341| Step: 0
Training loss: 0.24574311572305704
Validation loss: 3.1828310062530245

Epoch: 6| Step: 1
Training loss: 0.2766622309635574
Validation loss: 3.220357610715706

Epoch: 6| Step: 2
Training loss: 0.2513839443404306
Validation loss: 3.179376010493423

Epoch: 6| Step: 3
Training loss: 0.3743672197835828
Validation loss: 3.191995031797515

Epoch: 6| Step: 4
Training loss: 0.27578512302521185
Validation loss: 3.2710150811953573

Epoch: 6| Step: 5
Training loss: 0.2734554557354392
Validation loss: 3.1468187813912754

Epoch: 6| Step: 6
Training loss: 0.43939966512392953
Validation loss: 3.1017150841373686

Epoch: 6| Step: 7
Training loss: 0.30133278552113874
Validation loss: 3.122564269362186

Epoch: 6| Step: 8
Training loss: 0.3583407238634304
Validation loss: 3.1427340282131135

Epoch: 6| Step: 9
Training loss: 0.46397270207222724
Validation loss: 3.0975059803147325

Epoch: 6| Step: 10
Training loss: 0.5346766919682944
Validation loss: 3.117526068661296

Epoch: 6| Step: 11
Training loss: 0.2729207605802292
Validation loss: 3.13250465814884

Epoch: 6| Step: 12
Training loss: 0.30604714467698985
Validation loss: 3.10009722044479

Epoch: 6| Step: 13
Training loss: 0.43127505326405896
Validation loss: 3.1446161041499887

Epoch: 342| Step: 0
Training loss: 0.3665980010146725
Validation loss: 3.1361797878433313

Epoch: 6| Step: 1
Training loss: 0.32321269428046545
Validation loss: 3.1455030878460457

Epoch: 6| Step: 2
Training loss: 0.31173039082372184
Validation loss: 3.1585701450217867

Epoch: 6| Step: 3
Training loss: 0.35025208284846515
Validation loss: 3.141990491298644

Epoch: 6| Step: 4
Training loss: 0.26465174542713993
Validation loss: 3.1567162650890226

Epoch: 6| Step: 5
Training loss: 0.26371178501576664
Validation loss: 3.1348340241921235

Epoch: 6| Step: 6
Training loss: 0.3623381648058844
Validation loss: 3.1143073190378825

Epoch: 6| Step: 7
Training loss: 0.574175800611634
Validation loss: 3.158842331543608

Epoch: 6| Step: 8
Training loss: 0.2856792722262895
Validation loss: 3.1342718414846287

Epoch: 6| Step: 9
Training loss: 0.46313631000170813
Validation loss: 3.2238844871794066

Epoch: 6| Step: 10
Training loss: 0.5167922189146683
Validation loss: 3.1478352061313375

Epoch: 6| Step: 11
Training loss: 0.3461818290214281
Validation loss: 3.1603000955493195

Epoch: 6| Step: 12
Training loss: 0.3005534337287246
Validation loss: 3.20642567352231

Epoch: 6| Step: 13
Training loss: 0.4877559430157716
Validation loss: 3.235709168590396

Epoch: 343| Step: 0
Training loss: 0.19704253735379842
Validation loss: 3.2323864215546907

Epoch: 6| Step: 1
Training loss: 0.38717493450966983
Validation loss: 3.0951554673383086

Epoch: 6| Step: 2
Training loss: 0.3562412252516678
Validation loss: 3.172277465743099

Epoch: 6| Step: 3
Training loss: 0.2837904791589861
Validation loss: 3.149749104029551

Epoch: 6| Step: 4
Training loss: 0.3990184998358476
Validation loss: 3.2044867001469455

Epoch: 6| Step: 5
Training loss: 0.3679872285451147
Validation loss: 3.1508135542256746

Epoch: 6| Step: 6
Training loss: 0.33272692784656543
Validation loss: 3.1789912805804663

Epoch: 6| Step: 7
Training loss: 0.40188285205936014
Validation loss: 3.149423474832511

Epoch: 6| Step: 8
Training loss: 0.30144365864599476
Validation loss: 3.135385701141713

Epoch: 6| Step: 9
Training loss: 0.28634147716995284
Validation loss: 3.145098295085758

Epoch: 6| Step: 10
Training loss: 0.5059247361305522
Validation loss: 3.1722403630637803

Epoch: 6| Step: 11
Training loss: 0.21916962294041237
Validation loss: 3.2375684198246466

Epoch: 6| Step: 12
Training loss: 0.43094065600727105
Validation loss: 3.2094356492752407

Epoch: 6| Step: 13
Training loss: 0.42506225494615524
Validation loss: 3.2309740156496245

Epoch: 344| Step: 0
Training loss: 0.4764060248214575
Validation loss: 3.2013854474766115

Epoch: 6| Step: 1
Training loss: 0.3191793682062711
Validation loss: 3.1523460315694516

Epoch: 6| Step: 2
Training loss: 0.307096300683803
Validation loss: 3.2492140895659967

Epoch: 6| Step: 3
Training loss: 0.27356113635954993
Validation loss: 3.1855172865955472

Epoch: 6| Step: 4
Training loss: 0.3873663594924654
Validation loss: 3.194817266039323

Epoch: 6| Step: 5
Training loss: 0.43627618875020796
Validation loss: 3.141817995536603

Epoch: 6| Step: 6
Training loss: 0.29397758991035866
Validation loss: 3.187158865532124

Epoch: 6| Step: 7
Training loss: 0.2712027646613075
Validation loss: 3.201303537922304

Epoch: 6| Step: 8
Training loss: 0.3470087021394755
Validation loss: 3.181903526164793

Epoch: 6| Step: 9
Training loss: 0.40833262164514506
Validation loss: 3.232321586474508

Epoch: 6| Step: 10
Training loss: 0.26791921163262855
Validation loss: 3.1491514647467604

Epoch: 6| Step: 11
Training loss: 0.2850417991779698
Validation loss: 3.144106995452533

Epoch: 6| Step: 12
Training loss: 0.39774426758361947
Validation loss: 3.17221531036776

Epoch: 6| Step: 13
Training loss: 0.26261309219791823
Validation loss: 3.149272949842529

Epoch: 345| Step: 0
Training loss: 0.38601875530889146
Validation loss: 3.1284737798075595

Epoch: 6| Step: 1
Training loss: 0.46842396841933714
Validation loss: 3.1435209558673396

Epoch: 6| Step: 2
Training loss: 0.33191227744853596
Validation loss: 3.1814443497663443

Epoch: 6| Step: 3
Training loss: 0.26422535766785255
Validation loss: 3.1975120864234103

Epoch: 6| Step: 4
Training loss: 0.2800185609736704
Validation loss: 3.2173705370233154

Epoch: 6| Step: 5
Training loss: 0.46322507083432557
Validation loss: 3.1695795005540144

Epoch: 6| Step: 6
Training loss: 0.27986283746796387
Validation loss: 3.130268132320383

Epoch: 6| Step: 7
Training loss: 0.4345482981388545
Validation loss: 3.188800932745248

Epoch: 6| Step: 8
Training loss: 0.4097159792896815
Validation loss: 3.0962535092114862

Epoch: 6| Step: 9
Training loss: 0.2836331621217011
Validation loss: 3.13182021714902

Epoch: 6| Step: 10
Training loss: 0.4144690874569047
Validation loss: 3.1516356273583854

Epoch: 6| Step: 11
Training loss: 0.47596503154951897
Validation loss: 3.1338073596794644

Epoch: 6| Step: 12
Training loss: 0.23893417735312827
Validation loss: 3.1310120797392824

Epoch: 6| Step: 13
Training loss: 0.3177342743002303
Validation loss: 3.1035333644519203

Epoch: 346| Step: 0
Training loss: 0.3363622154122643
Validation loss: 3.135319405163502

Epoch: 6| Step: 1
Training loss: 0.501509087829171
Validation loss: 3.198751649149303

Epoch: 6| Step: 2
Training loss: 0.3533796923723576
Validation loss: 3.1624584009301895

Epoch: 6| Step: 3
Training loss: 0.39110531840511015
Validation loss: 3.0616149142367637

Epoch: 6| Step: 4
Training loss: 0.2563758616598037
Validation loss: 3.0910462403851184

Epoch: 6| Step: 5
Training loss: 0.2646587271291233
Validation loss: 3.069554462637982

Epoch: 6| Step: 6
Training loss: 0.24700595183286572
Validation loss: 3.1046099804929375

Epoch: 6| Step: 7
Training loss: 0.37257851163684497
Validation loss: 3.069312957797402

Epoch: 6| Step: 8
Training loss: 0.3037762096462884
Validation loss: 3.103018827949402

Epoch: 6| Step: 9
Training loss: 0.3121078176065674
Validation loss: 3.0991902026884346

Epoch: 6| Step: 10
Training loss: 0.2677275664969612
Validation loss: 3.1391036237748033

Epoch: 6| Step: 11
Training loss: 0.38095917005605945
Validation loss: 3.1523003998666677

Epoch: 6| Step: 12
Training loss: 0.20966711554955564
Validation loss: 3.2155193918258633

Epoch: 6| Step: 13
Training loss: 0.4361631199256808
Validation loss: 3.2128809533558202

Epoch: 347| Step: 0
Training loss: 0.31613483090347316
Validation loss: 3.206882350994739

Epoch: 6| Step: 1
Training loss: 0.3240141625252471
Validation loss: 3.14730545781962

Epoch: 6| Step: 2
Training loss: 0.3170849972734307
Validation loss: 3.1403191767089598

Epoch: 6| Step: 3
Training loss: 0.3391183257839978
Validation loss: 3.1455515594266896

Epoch: 6| Step: 4
Training loss: 0.3495705439138078
Validation loss: 3.1626440565749516

Epoch: 6| Step: 5
Training loss: 0.24421072907068087
Validation loss: 3.161457109948581

Epoch: 6| Step: 6
Training loss: 0.2731935093719916
Validation loss: 3.218701778902483

Epoch: 6| Step: 7
Training loss: 0.3976134773738632
Validation loss: 3.051777903579699

Epoch: 6| Step: 8
Training loss: 0.2661354965596452
Validation loss: 3.1162957084599525

Epoch: 6| Step: 9
Training loss: 0.3346011618016578
Validation loss: 3.1606234349352587

Epoch: 6| Step: 10
Training loss: 0.28011606031347186
Validation loss: 3.171014076993235

Epoch: 6| Step: 11
Training loss: 0.592692789187912
Validation loss: 3.1610318587018233

Epoch: 6| Step: 12
Training loss: 0.3270495592688498
Validation loss: 3.1546618176681234

Epoch: 6| Step: 13
Training loss: 0.21004377992996257
Validation loss: 3.145663949477826

Epoch: 348| Step: 0
Training loss: 0.2921350952317148
Validation loss: 3.1676605864947556

Epoch: 6| Step: 1
Training loss: 0.3516850469838242
Validation loss: 3.1697627960170642

Epoch: 6| Step: 2
Training loss: 0.3266908320462638
Validation loss: 3.2412695998641174

Epoch: 6| Step: 3
Training loss: 0.2449204464616745
Validation loss: 3.232451710174339

Epoch: 6| Step: 4
Training loss: 0.272933208835413
Validation loss: 3.149318978700324

Epoch: 6| Step: 5
Training loss: 0.39767617061459726
Validation loss: 3.132840531398971

Epoch: 6| Step: 6
Training loss: 0.2190642483868666
Validation loss: 3.1540213796261485

Epoch: 6| Step: 7
Training loss: 0.23237591777967062
Validation loss: 3.147365643191677

Epoch: 6| Step: 8
Training loss: 0.31973158098965
Validation loss: 3.115330027165105

Epoch: 6| Step: 9
Training loss: 0.2743298139924824
Validation loss: 3.2136605651391847

Epoch: 6| Step: 10
Training loss: 0.2914327537817699
Validation loss: 3.077884206373896

Epoch: 6| Step: 11
Training loss: 0.2824751739016267
Validation loss: 3.1411170384251004

Epoch: 6| Step: 12
Training loss: 0.30458465698953036
Validation loss: 3.211423071462385

Epoch: 6| Step: 13
Training loss: 0.3809859041187136
Validation loss: 3.2266301724508657

Epoch: 349| Step: 0
Training loss: 0.45865947505853855
Validation loss: 3.2469779171143296

Epoch: 6| Step: 1
Training loss: 0.3176542090084408
Validation loss: 3.251257457536384

Epoch: 6| Step: 2
Training loss: 0.26915579366916553
Validation loss: 3.207319636200756

Epoch: 6| Step: 3
Training loss: 0.22861595885522798
Validation loss: 3.14395903441585

Epoch: 6| Step: 4
Training loss: 0.3133712900769141
Validation loss: 3.0812460217762943

Epoch: 6| Step: 5
Training loss: 0.26901274024917554
Validation loss: 3.160408088573532

Epoch: 6| Step: 6
Training loss: 0.34434559549428595
Validation loss: 3.081682154002935

Epoch: 6| Step: 7
Training loss: 0.36958927561911775
Validation loss: 3.150670782703897

Epoch: 6| Step: 8
Training loss: 0.3736839446890637
Validation loss: 3.1712288535052977

Epoch: 6| Step: 9
Training loss: 0.34581056638639335
Validation loss: 3.155833415120495

Epoch: 6| Step: 10
Training loss: 0.5187612291062891
Validation loss: 3.224407495486617

Epoch: 6| Step: 11
Training loss: 0.22195174206387122
Validation loss: 3.1486708915033805

Epoch: 6| Step: 12
Training loss: 0.21231089410070647
Validation loss: 3.177088644721589

Epoch: 6| Step: 13
Training loss: 0.44384732052294096
Validation loss: 3.177184710943672

Epoch: 350| Step: 0
Training loss: 0.3403622628881758
Validation loss: 3.18257195236804

Epoch: 6| Step: 1
Training loss: 0.30052600285377284
Validation loss: 3.147604908748937

Epoch: 6| Step: 2
Training loss: 0.3339300167174131
Validation loss: 3.121333527216959

Epoch: 6| Step: 3
Training loss: 0.2800007068037581
Validation loss: 3.2173975723549586

Epoch: 6| Step: 4
Training loss: 0.3248137105214924
Validation loss: 3.1926671575698693

Epoch: 6| Step: 5
Training loss: 0.525308368582651
Validation loss: 3.1690571111346055

Epoch: 6| Step: 6
Training loss: 0.30617806601877945
Validation loss: 3.1221691024880194

Epoch: 6| Step: 7
Training loss: 0.30398197897636153
Validation loss: 3.0817962544002904

Epoch: 6| Step: 8
Training loss: 0.3154581015812779
Validation loss: 3.0751189966101444

Epoch: 6| Step: 9
Training loss: 0.22751272646708964
Validation loss: 3.14138852987009

Epoch: 6| Step: 10
Training loss: 0.28313061015989666
Validation loss: 3.1455676532916814

Epoch: 6| Step: 11
Training loss: 0.24892606140336457
Validation loss: 3.1558969633867955

Epoch: 6| Step: 12
Training loss: 0.2812183415290926
Validation loss: 3.161211200001868

Epoch: 6| Step: 13
Training loss: 0.3149858192059906
Validation loss: 3.1325349375609974

Epoch: 351| Step: 0
Training loss: 0.22842185223863262
Validation loss: 3.1927086776724916

Epoch: 6| Step: 1
Training loss: 0.2559783600642638
Validation loss: 3.114408001169535

Epoch: 6| Step: 2
Training loss: 0.2141424610987499
Validation loss: 3.152571936584988

Epoch: 6| Step: 3
Training loss: 0.29656278354964855
Validation loss: 3.1702889296330903

Epoch: 6| Step: 4
Training loss: 0.2597254098151485
Validation loss: 3.1961413165866817

Epoch: 6| Step: 5
Training loss: 0.43797423001037744
Validation loss: 3.1132881805840555

Epoch: 6| Step: 6
Training loss: 0.37774831278668425
Validation loss: 3.1757632447029884

Epoch: 6| Step: 7
Training loss: 0.2684091485742271
Validation loss: 3.1507273157284805

Epoch: 6| Step: 8
Training loss: 0.34442326330403455
Validation loss: 3.2135280977742724

Epoch: 6| Step: 9
Training loss: 0.3278264776764556
Validation loss: 3.246236921168281

Epoch: 6| Step: 10
Training loss: 0.3964033560822032
Validation loss: 3.1799466264192233

Epoch: 6| Step: 11
Training loss: 0.3129738314859318
Validation loss: 3.2165595937772764

Epoch: 6| Step: 12
Training loss: 0.310058305394797
Validation loss: 3.1708195876944347

Epoch: 6| Step: 13
Training loss: 0.25799698442352753
Validation loss: 3.0973185755667796

Epoch: 352| Step: 0
Training loss: 0.37528414689832074
Validation loss: 3.1474952644593297

Epoch: 6| Step: 1
Training loss: 0.25663401277289244
Validation loss: 3.1525630504364432

Epoch: 6| Step: 2
Training loss: 0.3203381086207578
Validation loss: 3.209624777796241

Epoch: 6| Step: 3
Training loss: 0.4313880733928654
Validation loss: 3.2142300520220033

Epoch: 6| Step: 4
Training loss: 0.3110706063613674
Validation loss: 3.197244795178152

Epoch: 6| Step: 5
Training loss: 0.38756543729838167
Validation loss: 3.264727771893197

Epoch: 6| Step: 6
Training loss: 0.25858388000276417
Validation loss: 3.1465563585322025

Epoch: 6| Step: 7
Training loss: 0.2681286987858742
Validation loss: 3.202660205892779

Epoch: 6| Step: 8
Training loss: 0.3778913808723983
Validation loss: 3.214911112923564

Epoch: 6| Step: 9
Training loss: 0.3520903545258913
Validation loss: 3.2293543279119206

Epoch: 6| Step: 10
Training loss: 0.3381310197643374
Validation loss: 3.1462310430142297

Epoch: 6| Step: 11
Training loss: 0.3454303419552791
Validation loss: 3.204876292256918

Epoch: 6| Step: 12
Training loss: 0.3127339441094919
Validation loss: 3.1570625266495895

Epoch: 6| Step: 13
Training loss: 0.2353157871011683
Validation loss: 3.1734656368518985

Epoch: 353| Step: 0
Training loss: 0.25942005030507204
Validation loss: 3.196206450450975

Epoch: 6| Step: 1
Training loss: 0.5143507905641956
Validation loss: 3.2100777445694386

Epoch: 6| Step: 2
Training loss: 0.27295450058741727
Validation loss: 3.115574354795109

Epoch: 6| Step: 3
Training loss: 0.3312996264836721
Validation loss: 3.1394377025165157

Epoch: 6| Step: 4
Training loss: 0.26679382099062465
Validation loss: 3.1603475606291163

Epoch: 6| Step: 5
Training loss: 0.2512288884645014
Validation loss: 3.15624196772293

Epoch: 6| Step: 6
Training loss: 0.3276410848721751
Validation loss: 3.262959890971151

Epoch: 6| Step: 7
Training loss: 0.2126323988724371
Validation loss: 3.241527358414758

Epoch: 6| Step: 8
Training loss: 0.29902368267704577
Validation loss: 3.1741254117579327

Epoch: 6| Step: 9
Training loss: 0.2498430265901648
Validation loss: 3.2411006591891933

Epoch: 6| Step: 10
Training loss: 0.2973156219023412
Validation loss: 3.1408309489425257

Epoch: 6| Step: 11
Training loss: 0.313820184156574
Validation loss: 3.112403059730289

Epoch: 6| Step: 12
Training loss: 0.3329653223399218
Validation loss: 3.090810567429674

Epoch: 6| Step: 13
Training loss: 0.4357176304851859
Validation loss: 3.1318699535825814

Epoch: 354| Step: 0
Training loss: 0.3090338164655096
Validation loss: 3.15401634015979

Epoch: 6| Step: 1
Training loss: 0.3117907701438043
Validation loss: 3.162709139013911

Epoch: 6| Step: 2
Training loss: 0.3694123978248047
Validation loss: 3.230544741688899

Epoch: 6| Step: 3
Training loss: 0.33667864107012935
Validation loss: 3.140662349649646

Epoch: 6| Step: 4
Training loss: 0.3692844655578953
Validation loss: 3.198505581403113

Epoch: 6| Step: 5
Training loss: 0.3002400421393889
Validation loss: 3.1773833253070247

Epoch: 6| Step: 6
Training loss: 0.3429301085894813
Validation loss: 3.1718216063166222

Epoch: 6| Step: 7
Training loss: 0.39926566279435804
Validation loss: 3.178198325862599

Epoch: 6| Step: 8
Training loss: 0.21002594584592718
Validation loss: 3.170570819496333

Epoch: 6| Step: 9
Training loss: 0.24655851497499912
Validation loss: 3.1671149078817407

Epoch: 6| Step: 10
Training loss: 0.22093419831977504
Validation loss: 3.1832045116289684

Epoch: 6| Step: 11
Training loss: 0.2856568945140973
Validation loss: 3.078770293936712

Epoch: 6| Step: 12
Training loss: 0.37885020519944296
Validation loss: 3.114297456071333

Epoch: 6| Step: 13
Training loss: 0.3260441375776918
Validation loss: 3.140262336098732

Epoch: 355| Step: 0
Training loss: 0.21131700356035868
Validation loss: 3.1068674580378834

Epoch: 6| Step: 1
Training loss: 0.31853408933990984
Validation loss: 3.1401761494974836

Epoch: 6| Step: 2
Training loss: 0.37631372963945664
Validation loss: 3.1368902594207926

Epoch: 6| Step: 3
Training loss: 0.29289051282813894
Validation loss: 3.170377130227229

Epoch: 6| Step: 4
Training loss: 0.5209899158343884
Validation loss: 3.139683001749704

Epoch: 6| Step: 5
Training loss: 0.45637685436226244
Validation loss: 3.2007049474481555

Epoch: 6| Step: 6
Training loss: 0.25092279474251505
Validation loss: 3.1951306951234857

Epoch: 6| Step: 7
Training loss: 0.31141577028995
Validation loss: 3.205350062712503

Epoch: 6| Step: 8
Training loss: 0.23803012935479298
Validation loss: 3.2293761318729723

Epoch: 6| Step: 9
Training loss: 0.26318349466693547
Validation loss: 3.2218263239471923

Epoch: 6| Step: 10
Training loss: 0.26715453931720595
Validation loss: 3.185727118829379

Epoch: 6| Step: 11
Training loss: 0.42778995448936175
Validation loss: 3.262481813392276

Epoch: 6| Step: 12
Training loss: 0.32508167652701125
Validation loss: 3.2241761848333534

Epoch: 6| Step: 13
Training loss: 0.1747532081456187
Validation loss: 3.236137241772838

Epoch: 356| Step: 0
Training loss: 0.2799253395498577
Validation loss: 3.1534540111228067

Epoch: 6| Step: 1
Training loss: 0.24208418118962535
Validation loss: 3.1199694005981766

Epoch: 6| Step: 2
Training loss: 0.11383540166244807
Validation loss: 3.1387377963277654

Epoch: 6| Step: 3
Training loss: 0.32250414026914714
Validation loss: 3.118083777202016

Epoch: 6| Step: 4
Training loss: 0.28719668455660824
Validation loss: 3.1304082547460714

Epoch: 6| Step: 5
Training loss: 0.3998553536070416
Validation loss: 3.1769647211332

Epoch: 6| Step: 6
Training loss: 0.38139384010813604
Validation loss: 3.153185902496637

Epoch: 6| Step: 7
Training loss: 0.32930344182499904
Validation loss: 3.167743428688277

Epoch: 6| Step: 8
Training loss: 0.339860543022483
Validation loss: 3.096227989267413

Epoch: 6| Step: 9
Training loss: 0.3631026946946707
Validation loss: 3.1635231845698093

Epoch: 6| Step: 10
Training loss: 0.3965352594204626
Validation loss: 3.1750031754084853

Epoch: 6| Step: 11
Training loss: 0.40765987185546704
Validation loss: 3.1852907365881116

Epoch: 6| Step: 12
Training loss: 0.36145672958120845
Validation loss: 3.218222108779595

Epoch: 6| Step: 13
Training loss: 0.26010365111931755
Validation loss: 3.093539567977033

Epoch: 357| Step: 0
Training loss: 0.3530190494560194
Validation loss: 3.145791215593609

Epoch: 6| Step: 1
Training loss: 0.27741082146081386
Validation loss: 3.159279543336702

Epoch: 6| Step: 2
Training loss: 0.2700437427999718
Validation loss: 3.1342342381866697

Epoch: 6| Step: 3
Training loss: 0.49806247761539996
Validation loss: 3.177714129920561

Epoch: 6| Step: 4
Training loss: 0.2711129563753352
Validation loss: 3.129146025412216

Epoch: 6| Step: 5
Training loss: 0.42984659544135734
Validation loss: 3.155565546434851

Epoch: 6| Step: 6
Training loss: 0.40261801843473244
Validation loss: 3.1801913125492396

Epoch: 6| Step: 7
Training loss: 0.36473624791921677
Validation loss: 3.2404418535509802

Epoch: 6| Step: 8
Training loss: 0.42340157838598386
Validation loss: 3.229692641870705

Epoch: 6| Step: 9
Training loss: 0.27310822961330167
Validation loss: 3.1929932301759463

Epoch: 6| Step: 10
Training loss: 0.3247754935462202
Validation loss: 3.2072703264267175

Epoch: 6| Step: 11
Training loss: 0.34450184357070945
Validation loss: 3.1602775635321105

Epoch: 6| Step: 12
Training loss: 0.30094122657568
Validation loss: 3.1202016358347073

Epoch: 6| Step: 13
Training loss: 0.3132075881925462
Validation loss: 3.0964186490303716

Epoch: 358| Step: 0
Training loss: 0.47699583395052353
Validation loss: 3.059615288176684

Epoch: 6| Step: 1
Training loss: 0.5039586476134064
Validation loss: 3.1168339273038685

Epoch: 6| Step: 2
Training loss: 0.4325405078727022
Validation loss: 3.1158096978052128

Epoch: 6| Step: 3
Training loss: 0.3452780205786808
Validation loss: 3.1633605178318813

Epoch: 6| Step: 4
Training loss: 0.36123511689622784
Validation loss: 3.2054125301232412

Epoch: 6| Step: 5
Training loss: 0.43109804461705353
Validation loss: 3.1976007353120974

Epoch: 6| Step: 6
Training loss: 0.35074688290674416
Validation loss: 3.1316981057792876

Epoch: 6| Step: 7
Training loss: 0.36403986979209885
Validation loss: 3.1072881778940857

Epoch: 6| Step: 8
Training loss: 0.3995932850810018
Validation loss: 3.1134905136533195

Epoch: 6| Step: 9
Training loss: 0.3629930645224971
Validation loss: 3.0987236297375826

Epoch: 6| Step: 10
Training loss: 0.26202447314930527
Validation loss: 3.1272894928382304

Epoch: 6| Step: 11
Training loss: 0.31547955806709327
Validation loss: 3.1000554469492556

Epoch: 6| Step: 12
Training loss: 0.25591865609912323
Validation loss: 3.1237832052850614

Epoch: 6| Step: 13
Training loss: 0.4248154386716477
Validation loss: 3.1898466584990173

Epoch: 359| Step: 0
Training loss: 0.42256175763590126
Validation loss: 3.162082759186743

Epoch: 6| Step: 1
Training loss: 0.3396608693686784
Validation loss: 3.2299823510127736

Epoch: 6| Step: 2
Training loss: 0.4692002835801756
Validation loss: 3.1756985924581036

Epoch: 6| Step: 3
Training loss: 0.4715440132455982
Validation loss: 3.172492419755606

Epoch: 6| Step: 4
Training loss: 0.16123331576906144
Validation loss: 3.2007871081977006

Epoch: 6| Step: 5
Training loss: 0.288441325665497
Validation loss: 3.0771110917382294

Epoch: 6| Step: 6
Training loss: 0.46642761309338954
Validation loss: 3.058575327668751

Epoch: 6| Step: 7
Training loss: 0.3145923661625677
Validation loss: 3.089284930713406

Epoch: 6| Step: 8
Training loss: 0.24229053643559706
Validation loss: 3.0861511929077357

Epoch: 6| Step: 9
Training loss: 0.46065214990652215
Validation loss: 3.0497114102312004

Epoch: 6| Step: 10
Training loss: 0.36272373283265325
Validation loss: 3.189121195583038

Epoch: 6| Step: 11
Training loss: 0.29685356665086654
Validation loss: 3.1559238957809006

Epoch: 6| Step: 12
Training loss: 0.3003908695572154
Validation loss: 3.2189147437937375

Epoch: 6| Step: 13
Training loss: 0.3633449867695342
Validation loss: 3.1925370490389597

Epoch: 360| Step: 0
Training loss: 0.3260675137708173
Validation loss: 3.1734671394270006

Epoch: 6| Step: 1
Training loss: 0.2752840228080218
Validation loss: 3.1906959742499135

Epoch: 6| Step: 2
Training loss: 0.39416819571480083
Validation loss: 3.206564791509131

Epoch: 6| Step: 3
Training loss: 0.2673548999425459
Validation loss: 3.1005790810496694

Epoch: 6| Step: 4
Training loss: 0.28532808169364654
Validation loss: 3.158843633514144

Epoch: 6| Step: 5
Training loss: 0.2514955076021191
Validation loss: 3.073538304614977

Epoch: 6| Step: 6
Training loss: 0.29375542879160876
Validation loss: 3.080218292381915

Epoch: 6| Step: 7
Training loss: 0.2103024654771987
Validation loss: 3.1321289889673873

Epoch: 6| Step: 8
Training loss: 0.3261424182679342
Validation loss: 3.1242163120523223

Epoch: 6| Step: 9
Training loss: 0.339433817429603
Validation loss: 3.16637882798377

Epoch: 6| Step: 10
Training loss: 0.2667403785459431
Validation loss: 3.086000929554807

Epoch: 6| Step: 11
Training loss: 0.2639476323135185
Validation loss: 3.200738976506447

Epoch: 6| Step: 12
Training loss: 0.4105012078842439
Validation loss: 3.1653598150889257

Epoch: 6| Step: 13
Training loss: 0.18489830704946064
Validation loss: 3.1519293341339787

Epoch: 361| Step: 0
Training loss: 0.37170159600576924
Validation loss: 3.1985855935428344

Epoch: 6| Step: 1
Training loss: 0.41401645116438907
Validation loss: 3.165973353196876

Epoch: 6| Step: 2
Training loss: 0.4398664946290717
Validation loss: 3.113778732291794

Epoch: 6| Step: 3
Training loss: 0.32762647405261497
Validation loss: 3.1115066403671565

Epoch: 6| Step: 4
Training loss: 0.3369573261291846
Validation loss: 3.1686885469134536

Epoch: 6| Step: 5
Training loss: 0.42113868601009463
Validation loss: 3.1972454538798467

Epoch: 6| Step: 6
Training loss: 0.2744494920984768
Validation loss: 3.150680210200111

Epoch: 6| Step: 7
Training loss: 0.36900928724174875
Validation loss: 3.127228463651362

Epoch: 6| Step: 8
Training loss: 0.3450639926606575
Validation loss: 3.1521190766507567

Epoch: 6| Step: 9
Training loss: 0.41131989850315753
Validation loss: 3.20172294387194

Epoch: 6| Step: 10
Training loss: 0.18221266715008122
Validation loss: 3.195952335083394

Epoch: 6| Step: 11
Training loss: 0.35058651129800494
Validation loss: 3.186656466298823

Epoch: 6| Step: 12
Training loss: 0.24876316905506027
Validation loss: 3.202761807824189

Epoch: 6| Step: 13
Training loss: 0.2577649853010438
Validation loss: 3.1153344531909974

Epoch: 362| Step: 0
Training loss: 0.31362946961199106
Validation loss: 3.1189480608453577

Epoch: 6| Step: 1
Training loss: 0.2147437556522446
Validation loss: 3.1816942910230273

Epoch: 6| Step: 2
Training loss: 0.34987757960081006
Validation loss: 3.1214824843429794

Epoch: 6| Step: 3
Training loss: 0.3074141301460369
Validation loss: 3.19291461487693

Epoch: 6| Step: 4
Training loss: 0.3014628873365539
Validation loss: 3.1829060504082274

Epoch: 6| Step: 5
Training loss: 0.2730160189590664
Validation loss: 3.2427763499916025

Epoch: 6| Step: 6
Training loss: 0.4191995840564695
Validation loss: 3.2484017868488646

Epoch: 6| Step: 7
Training loss: 0.19438669126620928
Validation loss: 3.2207088003885462

Epoch: 6| Step: 8
Training loss: 0.3884573492992234
Validation loss: 3.182215242774095

Epoch: 6| Step: 9
Training loss: 0.22040460027707134
Validation loss: 3.203323134830474

Epoch: 6| Step: 10
Training loss: 0.35967074539973
Validation loss: 3.0910107080394855

Epoch: 6| Step: 11
Training loss: 0.3884513267578887
Validation loss: 3.2542860428474123

Epoch: 6| Step: 12
Training loss: 0.4520028129042811
Validation loss: 3.1602882511719086

Epoch: 6| Step: 13
Training loss: 0.37544569709101355
Validation loss: 3.193666414982373

Epoch: 363| Step: 0
Training loss: 0.23803259429562057
Validation loss: 3.2104948037202554

Epoch: 6| Step: 1
Training loss: 0.30979694530416807
Validation loss: 3.2299948501939535

Epoch: 6| Step: 2
Training loss: 0.25420628939748274
Validation loss: 3.2236071730715707

Epoch: 6| Step: 3
Training loss: 0.27378496164523625
Validation loss: 3.2133593803816867

Epoch: 6| Step: 4
Training loss: 0.5197121441492243
Validation loss: 3.2329477057278218

Epoch: 6| Step: 5
Training loss: 0.2555036911707119
Validation loss: 3.155133506279716

Epoch: 6| Step: 6
Training loss: 0.25226705052790244
Validation loss: 3.1695928773067266

Epoch: 6| Step: 7
Training loss: 0.25062037028462425
Validation loss: 3.192325019332747

Epoch: 6| Step: 8
Training loss: 0.38413568427970163
Validation loss: 3.1952290046061207

Epoch: 6| Step: 9
Training loss: 0.464238758843625
Validation loss: 3.1558844099670185

Epoch: 6| Step: 10
Training loss: 0.4600853883231812
Validation loss: 3.20624981558578

Epoch: 6| Step: 11
Training loss: 0.29781044848236826
Validation loss: 3.1974530375802117

Epoch: 6| Step: 12
Training loss: 0.34111337167567757
Validation loss: 3.202657178505282

Epoch: 6| Step: 13
Training loss: 0.26593787335594854
Validation loss: 3.21105502641341

Epoch: 364| Step: 0
Training loss: 0.3893236417561629
Validation loss: 3.228855725156221

Epoch: 6| Step: 1
Training loss: 0.3711788280737494
Validation loss: 3.126961918726574

Epoch: 6| Step: 2
Training loss: 0.2976784124659193
Validation loss: 3.14837304389295

Epoch: 6| Step: 3
Training loss: 0.23498520888287064
Validation loss: 3.118883148184754

Epoch: 6| Step: 4
Training loss: 0.38745136417223097
Validation loss: 3.1273927937446175

Epoch: 6| Step: 5
Training loss: 0.4483270668663695
Validation loss: 3.080935529610276

Epoch: 6| Step: 6
Training loss: 0.2926570887637606
Validation loss: 3.186745897236533

Epoch: 6| Step: 7
Training loss: 0.3974142211153041
Validation loss: 3.1405255885546186

Epoch: 6| Step: 8
Training loss: 0.2625497748095553
Validation loss: 3.1719902280726724

Epoch: 6| Step: 9
Training loss: 0.21486112350963033
Validation loss: 3.136589380164114

Epoch: 6| Step: 10
Training loss: 0.27674796356788967
Validation loss: 3.06732588987132

Epoch: 6| Step: 11
Training loss: 0.26788874507855187
Validation loss: 3.120116066770795

Epoch: 6| Step: 12
Training loss: 0.22246726699411967
Validation loss: 3.0878130014094407

Epoch: 6| Step: 13
Training loss: 0.23561989457445318
Validation loss: 3.128071928129837

Epoch: 365| Step: 0
Training loss: 0.2605286341605976
Validation loss: 3.123015880132702

Epoch: 6| Step: 1
Training loss: 0.2579763787503075
Validation loss: 3.1214560313189676

Epoch: 6| Step: 2
Training loss: 0.2648260076875834
Validation loss: 3.1609273440514816

Epoch: 6| Step: 3
Training loss: 0.3414891410779547
Validation loss: 3.2284219970173353

Epoch: 6| Step: 4
Training loss: 0.23020829014468472
Validation loss: 3.1992745307279393

Epoch: 6| Step: 5
Training loss: 0.31898201277524096
Validation loss: 3.117286814395842

Epoch: 6| Step: 6
Training loss: 0.3451069794177615
Validation loss: 3.1236484275078853

Epoch: 6| Step: 7
Training loss: 0.32582839423450083
Validation loss: 3.0774905459405715

Epoch: 6| Step: 8
Training loss: 0.25566300289205496
Validation loss: 3.0960336984012873

Epoch: 6| Step: 9
Training loss: 0.4298743448632371
Validation loss: 3.1126684130513067

Epoch: 6| Step: 10
Training loss: 0.2896156045487074
Validation loss: 3.1377528581389185

Epoch: 6| Step: 11
Training loss: 0.2845229864203584
Validation loss: 3.1713994739286737

Epoch: 6| Step: 12
Training loss: 0.4150702610631528
Validation loss: 3.141710021194568

Epoch: 6| Step: 13
Training loss: 0.460240596948701
Validation loss: 3.1216438836690132

Epoch: 366| Step: 0
Training loss: 0.386301779162067
Validation loss: 3.1284021042052936

Epoch: 6| Step: 1
Training loss: 0.28506359789887187
Validation loss: 3.1285807630362776

Epoch: 6| Step: 2
Training loss: 0.32750691373821916
Validation loss: 3.1478352692484113

Epoch: 6| Step: 3
Training loss: 0.19053395668961517
Validation loss: 3.143625651049689

Epoch: 6| Step: 4
Training loss: 0.29599453212385246
Validation loss: 3.1047065615248823

Epoch: 6| Step: 5
Training loss: 0.35575350161080366
Validation loss: 3.182128544116169

Epoch: 6| Step: 6
Training loss: 0.428072825962974
Validation loss: 3.1150183910727063

Epoch: 6| Step: 7
Training loss: 0.3102831530451633
Validation loss: 3.156604960911662

Epoch: 6| Step: 8
Training loss: 0.24896138483967883
Validation loss: 3.1621029409806893

Epoch: 6| Step: 9
Training loss: 0.31337750732642194
Validation loss: 3.190508513483453

Epoch: 6| Step: 10
Training loss: 0.3442444929279432
Validation loss: 3.166523507713682

Epoch: 6| Step: 11
Training loss: 0.318472906358615
Validation loss: 3.1685823033768763

Epoch: 6| Step: 12
Training loss: 0.38691588877478467
Validation loss: 3.1435850248031314

Epoch: 6| Step: 13
Training loss: 0.16222455632241256
Validation loss: 3.1121747113751055

Epoch: 367| Step: 0
Training loss: 0.28252165787308836
Validation loss: 3.1010553055782486

Epoch: 6| Step: 1
Training loss: 0.39745075859513795
Validation loss: 3.1190283366362657

Epoch: 6| Step: 2
Training loss: 0.3121174616714942
Validation loss: 3.07113270242799

Epoch: 6| Step: 3
Training loss: 0.26174495338103737
Validation loss: 3.1187873374319537

Epoch: 6| Step: 4
Training loss: 0.2690872460570408
Validation loss: 3.1675716579313375

Epoch: 6| Step: 5
Training loss: 0.17566962406582817
Validation loss: 3.1537895432396064

Epoch: 6| Step: 6
Training loss: 0.34534455146313386
Validation loss: 3.2088774719201023

Epoch: 6| Step: 7
Training loss: 0.5243684830561844
Validation loss: 3.1747223549943486

Epoch: 6| Step: 8
Training loss: 0.2974349563483455
Validation loss: 3.2714570578578095

Epoch: 6| Step: 9
Training loss: 0.30593087735669594
Validation loss: 3.23048471602923

Epoch: 6| Step: 10
Training loss: 0.310556879422246
Validation loss: 3.1832992074212423

Epoch: 6| Step: 11
Training loss: 0.23171164081803342
Validation loss: 3.198070712940547

Epoch: 6| Step: 12
Training loss: 0.24928057241616725
Validation loss: 3.164781044582327

Epoch: 6| Step: 13
Training loss: 0.26930835740344206
Validation loss: 3.1595880840925976

Epoch: 368| Step: 0
Training loss: 0.28856400731539733
Validation loss: 3.0722482546998156

Epoch: 6| Step: 1
Training loss: 0.2813198347281748
Validation loss: 3.090448422429302

Epoch: 6| Step: 2
Training loss: 0.2712913073672743
Validation loss: 3.093285843680587

Epoch: 6| Step: 3
Training loss: 0.35272279637999104
Validation loss: 3.150054566854319

Epoch: 6| Step: 4
Training loss: 0.4252078894251977
Validation loss: 3.1209398978917298

Epoch: 6| Step: 5
Training loss: 0.295146477670281
Validation loss: 3.126640448741619

Epoch: 6| Step: 6
Training loss: 0.23902790155807158
Validation loss: 3.1055162086299264

Epoch: 6| Step: 7
Training loss: 0.41338505297659206
Validation loss: 3.1533051655124877

Epoch: 6| Step: 8
Training loss: 0.35193271217889943
Validation loss: 3.187383288073068

Epoch: 6| Step: 9
Training loss: 0.2907755456700066
Validation loss: 3.1813084924862656

Epoch: 6| Step: 10
Training loss: 0.2605031235547889
Validation loss: 3.218604396255105

Epoch: 6| Step: 11
Training loss: 0.3011055721224732
Validation loss: 3.1517621732496726

Epoch: 6| Step: 12
Training loss: 0.35740161275494436
Validation loss: 3.1270214028084995

Epoch: 6| Step: 13
Training loss: 0.20070718594099646
Validation loss: 3.1372330348103574

Epoch: 369| Step: 0
Training loss: 0.20947952970596287
Validation loss: 3.182591866892602

Epoch: 6| Step: 1
Training loss: 0.28770121084720196
Validation loss: 3.1739059297855103

Epoch: 6| Step: 2
Training loss: 0.36847457136256967
Validation loss: 3.131603384984106

Epoch: 6| Step: 3
Training loss: 0.3300640735231153
Validation loss: 3.2131539249460044

Epoch: 6| Step: 4
Training loss: 0.18995149678785017
Validation loss: 3.1976305971375627

Epoch: 6| Step: 5
Training loss: 0.3353397129566975
Validation loss: 3.2058087774700885

Epoch: 6| Step: 6
Training loss: 0.2196224644226364
Validation loss: 3.189921014419777

Epoch: 6| Step: 7
Training loss: 0.34428242069006215
Validation loss: 3.186165898199465

Epoch: 6| Step: 8
Training loss: 0.3391465456467088
Validation loss: 3.1161285998397985

Epoch: 6| Step: 9
Training loss: 0.259241794943753
Validation loss: 3.209445541780338

Epoch: 6| Step: 10
Training loss: 0.24611829453638837
Validation loss: 3.1462772300409783

Epoch: 6| Step: 11
Training loss: 0.39541153854539274
Validation loss: 3.1612327700510283

Epoch: 6| Step: 12
Training loss: 0.24577982119407454
Validation loss: 3.1202772820780216

Epoch: 6| Step: 13
Training loss: 0.2565398159058439
Validation loss: 3.1542310268902485

Epoch: 370| Step: 0
Training loss: 0.2070286048864136
Validation loss: 3.0925599452021593

Epoch: 6| Step: 1
Training loss: 0.2852881270336178
Validation loss: 3.1758602518825843

Epoch: 6| Step: 2
Training loss: 0.28194503206015387
Validation loss: 3.245417310589199

Epoch: 6| Step: 3
Training loss: 0.3441605283976444
Validation loss: 3.1105923210636437

Epoch: 6| Step: 4
Training loss: 0.3514732353478457
Validation loss: 3.127362820315182

Epoch: 6| Step: 5
Training loss: 0.32613526784173846
Validation loss: 3.1456558143768345

Epoch: 6| Step: 6
Training loss: 0.22486282644140537
Validation loss: 3.1522168492801153

Epoch: 6| Step: 7
Training loss: 0.323347771679031
Validation loss: 3.096938509888131

Epoch: 6| Step: 8
Training loss: 0.2516390891207392
Validation loss: 3.1360785566156446

Epoch: 6| Step: 9
Training loss: 0.4249491303517709
Validation loss: 3.1386953217303812

Epoch: 6| Step: 10
Training loss: 0.34339457256635963
Validation loss: 3.1296320853975064

Epoch: 6| Step: 11
Training loss: 0.21468100886408692
Validation loss: 3.1958850325904153

Epoch: 6| Step: 12
Training loss: 0.19243222294380302
Validation loss: 3.2011136943253984

Epoch: 6| Step: 13
Training loss: 0.27523287861244283
Validation loss: 3.180217195796936

Epoch: 371| Step: 0
Training loss: 0.45831792617679906
Validation loss: 3.123526734525669

Epoch: 6| Step: 1
Training loss: 0.23169022490651223
Validation loss: 3.1844762160238136

Epoch: 6| Step: 2
Training loss: 0.33153067609557707
Validation loss: 3.1222005384815215

Epoch: 6| Step: 3
Training loss: 0.3153186283706933
Validation loss: 3.1130044735129787

Epoch: 6| Step: 4
Training loss: 0.3172497044720487
Validation loss: 3.1516410740929994

Epoch: 6| Step: 5
Training loss: 0.3234220390494487
Validation loss: 3.0515663351388724

Epoch: 6| Step: 6
Training loss: 0.2754251715452587
Validation loss: 3.1329914019738907

Epoch: 6| Step: 7
Training loss: 0.3104042109394913
Validation loss: 3.146345265314908

Epoch: 6| Step: 8
Training loss: 0.3150001766756864
Validation loss: 3.101777409587562

Epoch: 6| Step: 9
Training loss: 0.31770714254104
Validation loss: 3.145774175496102

Epoch: 6| Step: 10
Training loss: 0.2869895373557347
Validation loss: 3.137141077755984

Epoch: 6| Step: 11
Training loss: 0.23765534133035174
Validation loss: 3.190679983474173

Epoch: 6| Step: 12
Training loss: 0.3208769732475164
Validation loss: 3.1949407832309915

Epoch: 6| Step: 13
Training loss: 0.4801289667284952
Validation loss: 3.178450935227108

Epoch: 372| Step: 0
Training loss: 0.3348176833352022
Validation loss: 3.182831143583822

Epoch: 6| Step: 1
Training loss: 0.22390542218520476
Validation loss: 3.277686991125761

Epoch: 6| Step: 2
Training loss: 0.2811578758678636
Validation loss: 3.1397145661330628

Epoch: 6| Step: 3
Training loss: 0.3903000815426397
Validation loss: 3.1857130738980426

Epoch: 6| Step: 4
Training loss: 0.35262566979380827
Validation loss: 3.1079626789634314

Epoch: 6| Step: 5
Training loss: 0.2659739558315855
Validation loss: 3.2147361888791046

Epoch: 6| Step: 6
Training loss: 0.20361986767112508
Validation loss: 3.1480322640933505

Epoch: 6| Step: 7
Training loss: 0.30480526824469545
Validation loss: 3.1106069989916603

Epoch: 6| Step: 8
Training loss: 0.3502053343939304
Validation loss: 3.179496471968368

Epoch: 6| Step: 9
Training loss: 0.3300601232010064
Validation loss: 3.187987171916289

Epoch: 6| Step: 10
Training loss: 0.27715164569828604
Validation loss: 3.1362748012015684

Epoch: 6| Step: 11
Training loss: 0.23088092638814384
Validation loss: 3.169734965776379

Epoch: 6| Step: 12
Training loss: 0.31369643061804875
Validation loss: 3.1204752271382303

Epoch: 6| Step: 13
Training loss: 0.4042566988973257
Validation loss: 3.158956104131778

Epoch: 373| Step: 0
Training loss: 0.2593346225379396
Validation loss: 3.1574481414780915

Epoch: 6| Step: 1
Training loss: 0.2951155651762405
Validation loss: 3.1503247583089804

Epoch: 6| Step: 2
Training loss: 0.25302022248894956
Validation loss: 3.152531476046446

Epoch: 6| Step: 3
Training loss: 0.2583932548804795
Validation loss: 3.1459798631373252

Epoch: 6| Step: 4
Training loss: 0.28380095423483565
Validation loss: 3.115650904122745

Epoch: 6| Step: 5
Training loss: 0.2869313525033875
Validation loss: 3.0594397455208657

Epoch: 6| Step: 6
Training loss: 0.34580468447878526
Validation loss: 3.0444997544226147

Epoch: 6| Step: 7
Training loss: 0.448550182898942
Validation loss: 3.076210640153398

Epoch: 6| Step: 8
Training loss: 0.24069647037230452
Validation loss: 3.1934476476634317

Epoch: 6| Step: 9
Training loss: 0.339015653336042
Validation loss: 3.168398237297718

Epoch: 6| Step: 10
Training loss: 0.29983478109315204
Validation loss: 3.1772338873206305

Epoch: 6| Step: 11
Training loss: 0.20159855749251845
Validation loss: 3.1554626767014353

Epoch: 6| Step: 12
Training loss: 0.24988410915976353
Validation loss: 3.167660197618054

Epoch: 6| Step: 13
Training loss: 0.38466131665070064
Validation loss: 3.167264653931484

Epoch: 374| Step: 0
Training loss: 0.25010662487293733
Validation loss: 3.1606596430647023

Epoch: 6| Step: 1
Training loss: 0.2321536977301328
Validation loss: 3.0988940747862292

Epoch: 6| Step: 2
Training loss: 0.23192069569913484
Validation loss: 3.0617752774708085

Epoch: 6| Step: 3
Training loss: 0.4129911273344974
Validation loss: 3.0902107107669012

Epoch: 6| Step: 4
Training loss: 0.347253201480221
Validation loss: 3.1539336665645967

Epoch: 6| Step: 5
Training loss: 0.2705031852464118
Validation loss: 3.090991360479824

Epoch: 6| Step: 6
Training loss: 0.28863741574815865
Validation loss: 3.085260347522957

Epoch: 6| Step: 7
Training loss: 0.35567413935874587
Validation loss: 3.158469713197193

Epoch: 6| Step: 8
Training loss: 0.26571179823051694
Validation loss: 3.148268336191768

Epoch: 6| Step: 9
Training loss: 0.3793654264973522
Validation loss: 3.2387202095360674

Epoch: 6| Step: 10
Training loss: 0.3926917144267523
Validation loss: 3.265888477264488

Epoch: 6| Step: 11
Training loss: 0.30029800534870493
Validation loss: 3.2619657807448825

Epoch: 6| Step: 12
Training loss: 0.22589390857846012
Validation loss: 3.13716950113333

Epoch: 6| Step: 13
Training loss: 0.24217670170491412
Validation loss: 3.1385180489636593

Epoch: 375| Step: 0
Training loss: 0.26316091691026
Validation loss: 3.0977417724399956

Epoch: 6| Step: 1
Training loss: 0.34791574544651405
Validation loss: 3.1321169365643344

Epoch: 6| Step: 2
Training loss: 0.3604290473149271
Validation loss: 3.1188125644847755

Epoch: 6| Step: 3
Training loss: 0.39128530007916784
Validation loss: 3.1031499814926016

Epoch: 6| Step: 4
Training loss: 0.4120583163627197
Validation loss: 3.2146317020781554

Epoch: 6| Step: 5
Training loss: 0.309836528884376
Validation loss: 3.2316157539204027

Epoch: 6| Step: 6
Training loss: 0.38774085558076293
Validation loss: 3.1564375566710994

Epoch: 6| Step: 7
Training loss: 0.3920629736789376
Validation loss: 3.2393799786459203

Epoch: 6| Step: 8
Training loss: 0.19399096670946103
Validation loss: 3.191094933106947

Epoch: 6| Step: 9
Training loss: 0.36380230032773964
Validation loss: 3.146534523701434

Epoch: 6| Step: 10
Training loss: 0.2867555838891798
Validation loss: 3.1830893025224483

Epoch: 6| Step: 11
Training loss: 0.4630971842043254
Validation loss: 3.1154063784191464

Epoch: 6| Step: 12
Training loss: 0.19731745652723984
Validation loss: 3.0526882826306454

Epoch: 6| Step: 13
Training loss: 0.3260348369057744
Validation loss: 3.1261050495728977

Epoch: 376| Step: 0
Training loss: 0.37735367282117727
Validation loss: 3.076941893746231

Epoch: 6| Step: 1
Training loss: 0.4554441069124659
Validation loss: 3.082315848409188

Epoch: 6| Step: 2
Training loss: 0.25224559280280784
Validation loss: 3.1618751029116177

Epoch: 6| Step: 3
Training loss: 0.2750496884452249
Validation loss: 3.150896372742506

Epoch: 6| Step: 4
Training loss: 0.2884083382442761
Validation loss: 3.162149084673198

Epoch: 6| Step: 5
Training loss: 0.3944613706437492
Validation loss: 3.215429611868754

Epoch: 6| Step: 6
Training loss: 0.39254381020349455
Validation loss: 3.1626299342627116

Epoch: 6| Step: 7
Training loss: 0.2263109767660286
Validation loss: 3.1659379338108624

Epoch: 6| Step: 8
Training loss: 0.3590015461232249
Validation loss: 3.1312015542389853

Epoch: 6| Step: 9
Training loss: 0.3095474716087578
Validation loss: 3.034580812765263

Epoch: 6| Step: 10
Training loss: 0.2873664405787535
Validation loss: 3.036886042226587

Epoch: 6| Step: 11
Training loss: 0.44422587614083076
Validation loss: 3.062554598989807

Epoch: 6| Step: 12
Training loss: 0.34429274324344744
Validation loss: 3.1234792187824154

Epoch: 6| Step: 13
Training loss: 0.2972860627536174
Validation loss: 3.087513658748175

Epoch: 377| Step: 0
Training loss: 0.271712570887936
Validation loss: 3.1742717413328845

Epoch: 6| Step: 1
Training loss: 0.3725727723549642
Validation loss: 3.181556758317774

Epoch: 6| Step: 2
Training loss: 0.34169918299061824
Validation loss: 3.1882535255707967

Epoch: 6| Step: 3
Training loss: 0.3456435502439266
Validation loss: 3.1685558673447534

Epoch: 6| Step: 4
Training loss: 0.26537204366322886
Validation loss: 3.206947390613402

Epoch: 6| Step: 5
Training loss: 0.2682247562724846
Validation loss: 3.23244068336201

Epoch: 6| Step: 6
Training loss: 0.27092185163352067
Validation loss: 3.1374176374266045

Epoch: 6| Step: 7
Training loss: 0.33037930353503125
Validation loss: 3.1683371847437996

Epoch: 6| Step: 8
Training loss: 0.2299403501859155
Validation loss: 3.119720997378805

Epoch: 6| Step: 9
Training loss: 0.30415476172590744
Validation loss: 3.202180180339452

Epoch: 6| Step: 10
Training loss: 0.3124381957926808
Validation loss: 3.1558603732395554

Epoch: 6| Step: 11
Training loss: 0.273306460997961
Validation loss: 3.128144424281626

Epoch: 6| Step: 12
Training loss: 0.3688930508790206
Validation loss: 3.103072368256159

Epoch: 6| Step: 13
Training loss: 0.38477453231183295
Validation loss: 3.098390804008792

Epoch: 378| Step: 0
Training loss: 0.3956590904746713
Validation loss: 3.15541589372653

Epoch: 6| Step: 1
Training loss: 0.3673858715459328
Validation loss: 3.189025763063782

Epoch: 6| Step: 2
Training loss: 0.1758829352527909
Validation loss: 3.2242161776587324

Epoch: 6| Step: 3
Training loss: 0.2745874610502832
Validation loss: 3.1945178249242163

Epoch: 6| Step: 4
Training loss: 0.2489829460584215
Validation loss: 3.1892316265947995

Epoch: 6| Step: 5
Training loss: 0.30310331444005745
Validation loss: 3.16987289231039

Epoch: 6| Step: 6
Training loss: 0.23869266325826666
Validation loss: 3.1947527381922454

Epoch: 6| Step: 7
Training loss: 0.2249612042968143
Validation loss: 3.1692022829731816

Epoch: 6| Step: 8
Training loss: 0.20268821521565797
Validation loss: 3.204722717776095

Epoch: 6| Step: 9
Training loss: 0.28216236532734756
Validation loss: 3.2061017230810513

Epoch: 6| Step: 10
Training loss: 0.2783651483126028
Validation loss: 3.173647743772347

Epoch: 6| Step: 11
Training loss: 0.1930524239230834
Validation loss: 3.119456880891338

Epoch: 6| Step: 12
Training loss: 0.42878176857832356
Validation loss: 3.136205318452435

Epoch: 6| Step: 13
Training loss: 0.22798662005815787
Validation loss: 3.0875553574020294

Epoch: 379| Step: 0
Training loss: 0.19853851645760126
Validation loss: 3.149399843011343

Epoch: 6| Step: 1
Training loss: 0.3583836357531847
Validation loss: 3.1660573942083277

Epoch: 6| Step: 2
Training loss: 0.47308894127084383
Validation loss: 3.2066553153381028

Epoch: 6| Step: 3
Training loss: 0.22696967368270823
Validation loss: 3.126399743989454

Epoch: 6| Step: 4
Training loss: 0.3693090589436924
Validation loss: 3.208119612341892

Epoch: 6| Step: 5
Training loss: 0.4529301454608374
Validation loss: 3.2564172844557744

Epoch: 6| Step: 6
Training loss: 0.41697975158015077
Validation loss: 3.1671724584768373

Epoch: 6| Step: 7
Training loss: 0.2645641065855605
Validation loss: 3.176310127266672

Epoch: 6| Step: 8
Training loss: 0.245561736139909
Validation loss: 3.180221887620633

Epoch: 6| Step: 9
Training loss: 0.2917039271237445
Validation loss: 3.1542821358256647

Epoch: 6| Step: 10
Training loss: 0.43881243307734974
Validation loss: 3.058772588952258

Epoch: 6| Step: 11
Training loss: 0.2684920636767652
Validation loss: 3.143592482678651

Epoch: 6| Step: 12
Training loss: 0.3290338757917677
Validation loss: 3.1412644375865115

Epoch: 6| Step: 13
Training loss: 0.3310761121270745
Validation loss: 3.094727551183345

Epoch: 380| Step: 0
Training loss: 0.3061596445189606
Validation loss: 3.1483175729734407

Epoch: 6| Step: 1
Training loss: 0.32799393443134023
Validation loss: 3.1763765309730068

Epoch: 6| Step: 2
Training loss: 0.43730022774007166
Validation loss: 3.1979206760310945

Epoch: 6| Step: 3
Training loss: 0.4224165337127689
Validation loss: 3.2380882484830757

Epoch: 6| Step: 4
Training loss: 0.5249951089903658
Validation loss: 3.2116071833387783

Epoch: 6| Step: 5
Training loss: 0.4306201177134802
Validation loss: 3.160680336830183

Epoch: 6| Step: 6
Training loss: 0.35073840722892174
Validation loss: 3.1659094047259937

Epoch: 6| Step: 7
Training loss: 0.36600531336570274
Validation loss: 3.1328917229355278

Epoch: 6| Step: 8
Training loss: 0.3096594336231807
Validation loss: 3.0724948184013905

Epoch: 6| Step: 9
Training loss: 0.39145636780174153
Validation loss: 3.151904750353007

Epoch: 6| Step: 10
Training loss: 0.3335562633562506
Validation loss: 3.1392009283683353

Epoch: 6| Step: 11
Training loss: 0.31912450761379774
Validation loss: 3.148390221378826

Epoch: 6| Step: 12
Training loss: 0.35989808285677694
Validation loss: 3.2091090556754946

Epoch: 6| Step: 13
Training loss: 0.3059062790258349
Validation loss: 3.231279547412984

Epoch: 381| Step: 0
Training loss: 0.23490524710141333
Validation loss: 3.26497192179907

Epoch: 6| Step: 1
Training loss: 0.5113182539019866
Validation loss: 3.2059216827588406

Epoch: 6| Step: 2
Training loss: 0.3623883749660461
Validation loss: 3.2306158731117263

Epoch: 6| Step: 3
Training loss: 0.3232791914028521
Validation loss: 3.1615466252692244

Epoch: 6| Step: 4
Training loss: 0.39961662845237245
Validation loss: 3.1165689668964744

Epoch: 6| Step: 5
Training loss: 0.3378321867225308
Validation loss: 3.0885171916092693

Epoch: 6| Step: 6
Training loss: 0.24377413899153547
Validation loss: 3.2054376580675674

Epoch: 6| Step: 7
Training loss: 0.2957680166138642
Validation loss: 3.0651610484499465

Epoch: 6| Step: 8
Training loss: 0.18662969947667288
Validation loss: 3.150371074517311

Epoch: 6| Step: 9
Training loss: 0.35299192807583774
Validation loss: 3.0509402941456205

Epoch: 6| Step: 10
Training loss: 0.2209827963570294
Validation loss: 3.088678165054848

Epoch: 6| Step: 11
Training loss: 0.2903229194594486
Validation loss: 3.1443707980018742

Epoch: 6| Step: 12
Training loss: 0.20721660270090353
Validation loss: 3.16682058930669

Epoch: 6| Step: 13
Training loss: 0.44500986490137817
Validation loss: 3.1165851849259147

Epoch: 382| Step: 0
Training loss: 0.28615743121063436
Validation loss: 3.1170089020392364

Epoch: 6| Step: 1
Training loss: 0.23458650899931746
Validation loss: 3.127400518939725

Epoch: 6| Step: 2
Training loss: 0.27301794289042886
Validation loss: 3.1136409052406675

Epoch: 6| Step: 3
Training loss: 0.3408870139884778
Validation loss: 3.160581493333465

Epoch: 6| Step: 4
Training loss: 0.310772783654121
Validation loss: 3.17139842144043

Epoch: 6| Step: 5
Training loss: 0.34725829718531775
Validation loss: 3.1539994956850474

Epoch: 6| Step: 6
Training loss: 0.2781671738527572
Validation loss: 3.218461983643126

Epoch: 6| Step: 7
Training loss: 0.266831630604458
Validation loss: 3.1597268874211974

Epoch: 6| Step: 8
Training loss: 0.23096635408517513
Validation loss: 3.1304578676376535

Epoch: 6| Step: 9
Training loss: 0.35055207112837244
Validation loss: 3.17692440865346

Epoch: 6| Step: 10
Training loss: 0.26496388402934506
Validation loss: 3.1204286327345714

Epoch: 6| Step: 11
Training loss: 0.35264522401730725
Validation loss: 3.1843805070354647

Epoch: 6| Step: 12
Training loss: 0.40213837057503615
Validation loss: 3.1235575971084995

Epoch: 6| Step: 13
Training loss: 0.3500620080310679
Validation loss: 3.1158092386913006

Epoch: 383| Step: 0
Training loss: 0.23057256397133882
Validation loss: 3.138070340643196

Epoch: 6| Step: 1
Training loss: 0.2993348630905533
Validation loss: 3.1696052385294293

Epoch: 6| Step: 2
Training loss: 0.41104168459619456
Validation loss: 3.132748787882931

Epoch: 6| Step: 3
Training loss: 0.3574934715728617
Validation loss: 3.128895658363198

Epoch: 6| Step: 4
Training loss: 0.27375230378875515
Validation loss: 3.0985795930287

Epoch: 6| Step: 5
Training loss: 0.2923233170456245
Validation loss: 3.1150236977318206

Epoch: 6| Step: 6
Training loss: 0.2609323101327074
Validation loss: 3.058914083349442

Epoch: 6| Step: 7
Training loss: 0.2543231182942609
Validation loss: 3.149203615082043

Epoch: 6| Step: 8
Training loss: 0.3382755027969962
Validation loss: 3.1051009818102164

Epoch: 6| Step: 9
Training loss: 0.4051694070053064
Validation loss: 3.0882699513471943

Epoch: 6| Step: 10
Training loss: 0.23414272083392007
Validation loss: 3.065780737832635

Epoch: 6| Step: 11
Training loss: 0.27993834131705914
Validation loss: 3.176934239792486

Epoch: 6| Step: 12
Training loss: 0.23859703526361664
Validation loss: 3.181041020172558

Epoch: 6| Step: 13
Training loss: 0.29842941013575847
Validation loss: 3.186506141353004

Epoch: 384| Step: 0
Training loss: 0.36666231947547095
Validation loss: 3.1472146157508263

Epoch: 6| Step: 1
Training loss: 0.3331083218763517
Validation loss: 3.149915627454648

Epoch: 6| Step: 2
Training loss: 0.2991642152775255
Validation loss: 3.1906110628118194

Epoch: 6| Step: 3
Training loss: 0.23775510075208842
Validation loss: 3.2168811323059145

Epoch: 6| Step: 4
Training loss: 0.31312051202599633
Validation loss: 3.132457050253319

Epoch: 6| Step: 5
Training loss: 0.34977831035528295
Validation loss: 3.147405235877862

Epoch: 6| Step: 6
Training loss: 0.34404423432194536
Validation loss: 3.1743252440206664

Epoch: 6| Step: 7
Training loss: 0.3378671075652044
Validation loss: 3.1245521478808875

Epoch: 6| Step: 8
Training loss: 0.5358140063570012
Validation loss: 3.1679404649831944

Epoch: 6| Step: 9
Training loss: 0.36927369156535217
Validation loss: 3.1993231812613

Epoch: 6| Step: 10
Training loss: 0.31173846916220316
Validation loss: 3.134941842423428

Epoch: 6| Step: 11
Training loss: 0.3178525529602003
Validation loss: 3.117817036757747

Epoch: 6| Step: 12
Training loss: 0.34430610583772053
Validation loss: 3.148129418936556

Epoch: 6| Step: 13
Training loss: 0.3586200579797686
Validation loss: 3.163844411107719

Epoch: 385| Step: 0
Training loss: 0.2920749636283956
Validation loss: 3.1451142522924576

Epoch: 6| Step: 1
Training loss: 0.3432585063583238
Validation loss: 3.145389997219577

Epoch: 6| Step: 2
Training loss: 0.41082674354248705
Validation loss: 3.0566773628732724

Epoch: 6| Step: 3
Training loss: 0.3019066477509289
Validation loss: 3.109753213496781

Epoch: 6| Step: 4
Training loss: 0.5077384601316566
Validation loss: 3.1197177493976893

Epoch: 6| Step: 5
Training loss: 0.2708203820041824
Validation loss: 3.039238539747951

Epoch: 6| Step: 6
Training loss: 0.34323634437770206
Validation loss: 3.164208654473887

Epoch: 6| Step: 7
Training loss: 0.3242065703161023
Validation loss: 3.103749091375748

Epoch: 6| Step: 8
Training loss: 0.33618659387733396
Validation loss: 3.1322931634518585

Epoch: 6| Step: 9
Training loss: 0.24675123999766224
Validation loss: 3.1849089170214744

Epoch: 6| Step: 10
Training loss: 0.2169765209238752
Validation loss: 3.2338389568285533

Epoch: 6| Step: 11
Training loss: 0.31592564521908406
Validation loss: 3.155336682209124

Epoch: 6| Step: 12
Training loss: 0.31211046736696746
Validation loss: 3.1266588767170878

Epoch: 6| Step: 13
Training loss: 0.3436607331631063
Validation loss: 3.1600779872236204

Epoch: 386| Step: 0
Training loss: 0.28800267454898903
Validation loss: 3.147591135565493

Epoch: 6| Step: 1
Training loss: 0.28247737629359615
Validation loss: 3.1391678145119357

Epoch: 6| Step: 2
Training loss: 0.4919955015354823
Validation loss: 3.1572410676770266

Epoch: 6| Step: 3
Training loss: 0.2558787971870802
Validation loss: 3.138256451425916

Epoch: 6| Step: 4
Training loss: 0.3124891279236697
Validation loss: 3.153347896968392

Epoch: 6| Step: 5
Training loss: 0.25134607862214114
Validation loss: 3.190184877373713

Epoch: 6| Step: 6
Training loss: 0.34777206463474786
Validation loss: 3.166436046852625

Epoch: 6| Step: 7
Training loss: 0.23454759918196644
Validation loss: 3.1731518835862818

Epoch: 6| Step: 8
Training loss: 0.2708992999997535
Validation loss: 3.1761509428725194

Epoch: 6| Step: 9
Training loss: 0.30164700544594897
Validation loss: 3.132027709278907

Epoch: 6| Step: 10
Training loss: 0.32683650845942475
Validation loss: 3.231349359161584

Epoch: 6| Step: 11
Training loss: 0.42587632683854343
Validation loss: 3.115841414760881

Epoch: 6| Step: 12
Training loss: 0.26537395282310555
Validation loss: 3.131743834659524

Epoch: 6| Step: 13
Training loss: 0.331839472419003
Validation loss: 3.102875490072048

Epoch: 387| Step: 0
Training loss: 0.35289300707911886
Validation loss: 3.063373804319719

Epoch: 6| Step: 1
Training loss: 0.258436142296321
Validation loss: 3.117655834431916

Epoch: 6| Step: 2
Training loss: 0.25986692418150853
Validation loss: 3.2719300895456844

Epoch: 6| Step: 3
Training loss: 0.27452436789156826
Validation loss: 3.2500467786112273

Epoch: 6| Step: 4
Training loss: 0.32060556263592566
Validation loss: 3.2011496182549126

Epoch: 6| Step: 5
Training loss: 0.5593207370289206
Validation loss: 3.230750702404857

Epoch: 6| Step: 6
Training loss: 0.41299816308294235
Validation loss: 3.22649703063308

Epoch: 6| Step: 7
Training loss: 0.27363021054279896
Validation loss: 3.139093015910754

Epoch: 6| Step: 8
Training loss: 0.43757584459377713
Validation loss: 3.1076123019217143

Epoch: 6| Step: 9
Training loss: 0.37793230947920614
Validation loss: 3.135459688383641

Epoch: 6| Step: 10
Training loss: 0.5293030685681794
Validation loss: 3.1000149931596357

Epoch: 6| Step: 11
Training loss: 0.393692333297747
Validation loss: 3.0278740924911065

Epoch: 6| Step: 12
Training loss: 0.3811594832169765
Validation loss: 3.1512435890424078

Epoch: 6| Step: 13
Training loss: 0.30385564073778953
Validation loss: 3.181438516903119

Epoch: 388| Step: 0
Training loss: 0.26051663705119815
Validation loss: 3.2704190439316125

Epoch: 6| Step: 1
Training loss: 0.44199962736131315
Validation loss: 3.234124608567874

Epoch: 6| Step: 2
Training loss: 0.4763166856760782
Validation loss: 3.2304551948038487

Epoch: 6| Step: 3
Training loss: 0.3064846200818033
Validation loss: 3.218475614043573

Epoch: 6| Step: 4
Training loss: 0.38470311310581684
Validation loss: 3.187363852292237

Epoch: 6| Step: 5
Training loss: 0.340008531281081
Validation loss: 3.105301218692147

Epoch: 6| Step: 6
Training loss: 0.2308391245885566
Validation loss: 3.1001993253676265

Epoch: 6| Step: 7
Training loss: 0.273175468233981
Validation loss: 3.0565543945629363

Epoch: 6| Step: 8
Training loss: 0.4035758993622148
Validation loss: 3.0881158793626815

Epoch: 6| Step: 9
Training loss: 0.3140678177568393
Validation loss: 3.037061167965065

Epoch: 6| Step: 10
Training loss: 0.2726010334975214
Validation loss: 3.1162677067553126

Epoch: 6| Step: 11
Training loss: 0.35592711941768
Validation loss: 3.084699654490646

Epoch: 6| Step: 12
Training loss: 0.43044505530083
Validation loss: 3.118711756979499

Epoch: 6| Step: 13
Training loss: 0.24182103487759152
Validation loss: 3.14942025748341

Epoch: 389| Step: 0
Training loss: 0.3866220218409311
Validation loss: 3.1830840843712394

Epoch: 6| Step: 1
Training loss: 0.40097903303378435
Validation loss: 3.1734962266364954

Epoch: 6| Step: 2
Training loss: 0.3514336879834871
Validation loss: 3.130488357247713

Epoch: 6| Step: 3
Training loss: 0.353197049074115
Validation loss: 3.128121203338626

Epoch: 6| Step: 4
Training loss: 0.2578988364182693
Validation loss: 3.1496618523322897

Epoch: 6| Step: 5
Training loss: 0.3579800942070812
Validation loss: 3.1022158302173266

Epoch: 6| Step: 6
Training loss: 0.33025172707584727
Validation loss: 3.1629553973341302

Epoch: 6| Step: 7
Training loss: 0.4709762160923299
Validation loss: 3.15505516928969

Epoch: 6| Step: 8
Training loss: 0.19360954785179565
Validation loss: 3.140008995666901

Epoch: 6| Step: 9
Training loss: 0.37943286284803746
Validation loss: 3.16382215552489

Epoch: 6| Step: 10
Training loss: 0.4016148900392958
Validation loss: 3.1974144623076963

Epoch: 6| Step: 11
Training loss: 0.23694935635601846
Validation loss: 3.2089165409322664

Epoch: 6| Step: 12
Training loss: 0.3378074962693552
Validation loss: 3.1822462229545825

Epoch: 6| Step: 13
Training loss: 0.44596958202717213
Validation loss: 3.1732199938219035

Epoch: 390| Step: 0
Training loss: 0.28108448880573833
Validation loss: 3.150169255992469

Epoch: 6| Step: 1
Training loss: 0.3199312453242627
Validation loss: 3.1281728277827803

Epoch: 6| Step: 2
Training loss: 0.332042716333204
Validation loss: 3.183184251406715

Epoch: 6| Step: 3
Training loss: 0.2630360602072368
Validation loss: 3.076371598799096

Epoch: 6| Step: 4
Training loss: 0.2195743372571547
Validation loss: 3.0938639507436756

Epoch: 6| Step: 5
Training loss: 0.35162787359441944
Validation loss: 3.104319732954354

Epoch: 6| Step: 6
Training loss: 0.25367868936524485
Validation loss: 3.168524101175694

Epoch: 6| Step: 7
Training loss: 0.2717722183276077
Validation loss: 3.1736263457493044

Epoch: 6| Step: 8
Training loss: 0.24859951812219067
Validation loss: 3.1509620509322547

Epoch: 6| Step: 9
Training loss: 0.31426632705448465
Validation loss: 3.220261141907195

Epoch: 6| Step: 10
Training loss: 0.3841248807227275
Validation loss: 3.17846908782174

Epoch: 6| Step: 11
Training loss: 0.31856829569160156
Validation loss: 3.1428395651144116

Epoch: 6| Step: 12
Training loss: 0.34743554900092166
Validation loss: 3.17109294702445

Epoch: 6| Step: 13
Training loss: 0.24021127636279174
Validation loss: 3.188691284364866

Epoch: 391| Step: 0
Training loss: 0.2675993416721075
Validation loss: 3.10458674351347

Epoch: 6| Step: 1
Training loss: 0.258756570755646
Validation loss: 3.0791821157216717

Epoch: 6| Step: 2
Training loss: 0.31741742458880623
Validation loss: 3.11815362552816

Epoch: 6| Step: 3
Training loss: 0.3239180077766375
Validation loss: 3.108053952326914

Epoch: 6| Step: 4
Training loss: 0.3635628132103156
Validation loss: 3.1361394705971666

Epoch: 6| Step: 5
Training loss: 0.26248478164155403
Validation loss: 3.1669907571352383

Epoch: 6| Step: 6
Training loss: 0.37398779876078925
Validation loss: 3.221517070988109

Epoch: 6| Step: 7
Training loss: 0.3252853406402823
Validation loss: 3.1802964810648953

Epoch: 6| Step: 8
Training loss: 0.27893922487973943
Validation loss: 3.160447932780003

Epoch: 6| Step: 9
Training loss: 0.2221698551307493
Validation loss: 3.1152575070470028

Epoch: 6| Step: 10
Training loss: 0.23005561653747872
Validation loss: 3.185542559001968

Epoch: 6| Step: 11
Training loss: 0.30639445391586306
Validation loss: 3.187696313734193

Epoch: 6| Step: 12
Training loss: 0.2852100817935832
Validation loss: 3.1518380832168007

Epoch: 6| Step: 13
Training loss: 0.2682466439537586
Validation loss: 3.2079961814263083

Epoch: 392| Step: 0
Training loss: 0.20709299570282705
Validation loss: 3.1620277675428463

Epoch: 6| Step: 1
Training loss: 0.32339420950317116
Validation loss: 3.141307269585172

Epoch: 6| Step: 2
Training loss: 0.2387461972682749
Validation loss: 3.137848444380954

Epoch: 6| Step: 3
Training loss: 0.29418348884076656
Validation loss: 3.0482802190962537

Epoch: 6| Step: 4
Training loss: 0.2667289541311643
Validation loss: 3.1487442889432464

Epoch: 6| Step: 5
Training loss: 0.4433474602127593
Validation loss: 3.1032615767301706

Epoch: 6| Step: 6
Training loss: 0.345674481255905
Validation loss: 3.2200877856990067

Epoch: 6| Step: 7
Training loss: 0.3784041076090421
Validation loss: 3.2107449835047235

Epoch: 6| Step: 8
Training loss: 0.2575214361323591
Validation loss: 3.191326624399527

Epoch: 6| Step: 9
Training loss: 0.19473117145681587
Validation loss: 3.2225421677250576

Epoch: 6| Step: 10
Training loss: 0.36659826522100364
Validation loss: 3.1933554428651885

Epoch: 6| Step: 11
Training loss: 0.3090070299024796
Validation loss: 3.1657987877658864

Epoch: 6| Step: 12
Training loss: 0.2897100669852493
Validation loss: 3.1977199821169693

Epoch: 6| Step: 13
Training loss: 0.33284922428516334
Validation loss: 3.1291514985944033

Epoch: 393| Step: 0
Training loss: 0.3088666095875382
Validation loss: 3.091744373266957

Epoch: 6| Step: 1
Training loss: 0.26310393307996394
Validation loss: 3.154909636165156

Epoch: 6| Step: 2
Training loss: 0.32759905853089627
Validation loss: 3.1695343677009267

Epoch: 6| Step: 3
Training loss: 0.28505983421000897
Validation loss: 3.102383829135075

Epoch: 6| Step: 4
Training loss: 0.20849468221789647
Validation loss: 3.173086051068222

Epoch: 6| Step: 5
Training loss: 0.2923235082015568
Validation loss: 3.1733262949619725

Epoch: 6| Step: 6
Training loss: 0.31408685475900017
Validation loss: 3.1710404549388715

Epoch: 6| Step: 7
Training loss: 0.4409973985472003
Validation loss: 3.155840126341211

Epoch: 6| Step: 8
Training loss: 0.1564443095314365
Validation loss: 3.124157652178404

Epoch: 6| Step: 9
Training loss: 0.3080022067549843
Validation loss: 3.1247692150092132

Epoch: 6| Step: 10
Training loss: 0.35695256758120575
Validation loss: 3.074772954069214

Epoch: 6| Step: 11
Training loss: 0.37920010370371804
Validation loss: 3.105780845330265

Epoch: 6| Step: 12
Training loss: 0.5038231182278466
Validation loss: 3.1243864601567597

Epoch: 6| Step: 13
Training loss: 0.27704109548769074
Validation loss: 3.149941399952605

Epoch: 394| Step: 0
Training loss: 0.25787485697932305
Validation loss: 3.113019382594967

Epoch: 6| Step: 1
Training loss: 0.39845814370923327
Validation loss: 3.2198377703242795

Epoch: 6| Step: 2
Training loss: 0.4028357673240574
Validation loss: 3.204772537915987

Epoch: 6| Step: 3
Training loss: 0.29742303257349445
Validation loss: 3.2309667225765817

Epoch: 6| Step: 4
Training loss: 0.34031059821572146
Validation loss: 3.1274649308228404

Epoch: 6| Step: 5
Training loss: 0.32196434271749746
Validation loss: 3.151112797882688

Epoch: 6| Step: 6
Training loss: 0.2899768261652762
Validation loss: 3.083297372728574

Epoch: 6| Step: 7
Training loss: 0.40561632105942486
Validation loss: 3.15690605974523

Epoch: 6| Step: 8
Training loss: 0.3251198345948769
Validation loss: 3.1116334007486

Epoch: 6| Step: 9
Training loss: 0.37077544766020254
Validation loss: 3.2059818832399603

Epoch: 6| Step: 10
Training loss: 0.3395029419931631
Validation loss: 3.195707413349135

Epoch: 6| Step: 11
Training loss: 0.287585376419051
Validation loss: 3.179394520251661

Epoch: 6| Step: 12
Training loss: 0.27863058898201165
Validation loss: 3.195096991872156

Epoch: 6| Step: 13
Training loss: 0.38422111284011123
Validation loss: 3.1932531434412037

Epoch: 395| Step: 0
Training loss: 0.3532497396677385
Validation loss: 3.227395578985698

Epoch: 6| Step: 1
Training loss: 0.5003725690360938
Validation loss: 3.181660720202839

Epoch: 6| Step: 2
Training loss: 0.4168933152632093
Validation loss: 3.168567856388551

Epoch: 6| Step: 3
Training loss: 0.4076718427630216
Validation loss: 3.110827670544807

Epoch: 6| Step: 4
Training loss: 0.3116716851291087
Validation loss: 3.119035012390607

Epoch: 6| Step: 5
Training loss: 0.2865499508896125
Validation loss: 3.1421475112472255

Epoch: 6| Step: 6
Training loss: 0.31759374798286105
Validation loss: 3.082694069001669

Epoch: 6| Step: 7
Training loss: 0.25262615593179066
Validation loss: 3.1003631655945467

Epoch: 6| Step: 8
Training loss: 0.48949960912585605
Validation loss: 3.114921721551022

Epoch: 6| Step: 9
Training loss: 0.33491695993962245
Validation loss: 3.1701206310276158

Epoch: 6| Step: 10
Training loss: 0.21692620964530743
Validation loss: 3.161589207629588

Epoch: 6| Step: 11
Training loss: 0.26452677559039917
Validation loss: 3.262763148933432

Epoch: 6| Step: 12
Training loss: 0.3147014798162607
Validation loss: 3.182989943958744

Epoch: 6| Step: 13
Training loss: 0.38946597767764274
Validation loss: 3.268898815027872

Epoch: 396| Step: 0
Training loss: 0.2747981821034408
Validation loss: 3.1829385219688713

Epoch: 6| Step: 1
Training loss: 0.2208805721219127
Validation loss: 3.163684938611608

Epoch: 6| Step: 2
Training loss: 0.31085712601739024
Validation loss: 3.1378948687627557

Epoch: 6| Step: 3
Training loss: 0.43648906120104775
Validation loss: 3.178937718924801

Epoch: 6| Step: 4
Training loss: 0.2788180668652872
Validation loss: 3.141011835823482

Epoch: 6| Step: 5
Training loss: 0.2656027279660585
Validation loss: 3.1244508387917858

Epoch: 6| Step: 6
Training loss: 0.27593237434715795
Validation loss: 3.1230791037373495

Epoch: 6| Step: 7
Training loss: 0.28359665987397725
Validation loss: 3.1032149031345244

Epoch: 6| Step: 8
Training loss: 0.29292616216743667
Validation loss: 3.145379284223755

Epoch: 6| Step: 9
Training loss: 0.23130038910963757
Validation loss: 3.142727478663605

Epoch: 6| Step: 10
Training loss: 0.2610236374082825
Validation loss: 3.1405452256327386

Epoch: 6| Step: 11
Training loss: 0.2676889510256789
Validation loss: 3.1909499104775616

Epoch: 6| Step: 12
Training loss: 0.3608534091572765
Validation loss: 3.2001170603878135

Epoch: 6| Step: 13
Training loss: 0.267168385675254
Validation loss: 3.1835571661409316

Epoch: 397| Step: 0
Training loss: 0.2863683414709162
Validation loss: 3.1422082380245606

Epoch: 6| Step: 1
Training loss: 0.2779011028760705
Validation loss: 3.139263307038966

Epoch: 6| Step: 2
Training loss: 0.25541928713658946
Validation loss: 3.0982839069524677

Epoch: 6| Step: 3
Training loss: 0.2892659991726629
Validation loss: 3.1574433591810904

Epoch: 6| Step: 4
Training loss: 0.32318040885515575
Validation loss: 3.1497918206506768

Epoch: 6| Step: 5
Training loss: 0.32562767818469807
Validation loss: 3.131429847532058

Epoch: 6| Step: 6
Training loss: 0.3522468898966194
Validation loss: 3.146271774020633

Epoch: 6| Step: 7
Training loss: 0.32164584585774925
Validation loss: 3.1103769985019265

Epoch: 6| Step: 8
Training loss: 0.23577453467208187
Validation loss: 3.14030452377385

Epoch: 6| Step: 9
Training loss: 0.34119547659876326
Validation loss: 3.199207509276873

Epoch: 6| Step: 10
Training loss: 0.25013723183176645
Validation loss: 3.1827152592532304

Epoch: 6| Step: 11
Training loss: 0.28464993506443736
Validation loss: 3.167231011715191

Epoch: 6| Step: 12
Training loss: 0.29409342737963506
Validation loss: 3.1738976479765273

Epoch: 6| Step: 13
Training loss: 0.23043502948865505
Validation loss: 3.121620461617061

Epoch: 398| Step: 0
Training loss: 0.2776577206617229
Validation loss: 3.1703579160678244

Epoch: 6| Step: 1
Training loss: 0.28161816871203965
Validation loss: 3.1955548033678776

Epoch: 6| Step: 2
Training loss: 0.229968740889099
Validation loss: 3.1338488607862023

Epoch: 6| Step: 3
Training loss: 0.4451867310789002
Validation loss: 3.219445286193802

Epoch: 6| Step: 4
Training loss: 0.33688964755286843
Validation loss: 3.1866313773027444

Epoch: 6| Step: 5
Training loss: 0.38477414504169316
Validation loss: 3.1745843324877896

Epoch: 6| Step: 6
Training loss: 0.2919440086192919
Validation loss: 3.186493496525715

Epoch: 6| Step: 7
Training loss: 0.30813766528905034
Validation loss: 3.1957516916350075

Epoch: 6| Step: 8
Training loss: 0.33223637247375404
Validation loss: 3.1586764233997915

Epoch: 6| Step: 9
Training loss: 0.282893610224529
Validation loss: 3.1279163993515877

Epoch: 6| Step: 10
Training loss: 0.3717653922426294
Validation loss: 3.154649586833121

Epoch: 6| Step: 11
Training loss: 0.20115942129456477
Validation loss: 3.151031901867241

Epoch: 6| Step: 12
Training loss: 0.2984558978576289
Validation loss: 3.105362621229316

Epoch: 6| Step: 13
Training loss: 0.2868124535885389
Validation loss: 3.1433138558083313

Epoch: 399| Step: 0
Training loss: 0.28047745619413367
Validation loss: 3.145812979794441

Epoch: 6| Step: 1
Training loss: 0.36566002669836056
Validation loss: 3.186725347795302

Epoch: 6| Step: 2
Training loss: 0.20166981745523202
Validation loss: 3.1178787089726487

Epoch: 6| Step: 3
Training loss: 0.440969757722324
Validation loss: 3.19337271435797

Epoch: 6| Step: 4
Training loss: 0.26474048097768366
Validation loss: 3.1518710387436557

Epoch: 6| Step: 5
Training loss: 0.2610699882629739
Validation loss: 3.1904427775556314

Epoch: 6| Step: 6
Training loss: 0.23721328984653867
Validation loss: 3.22472444387141

Epoch: 6| Step: 7
Training loss: 0.469621039769094
Validation loss: 3.204360859959193

Epoch: 6| Step: 8
Training loss: 0.36896278497489965
Validation loss: 3.1304282345493104

Epoch: 6| Step: 9
Training loss: 0.3614243250448787
Validation loss: 3.1895941044986644

Epoch: 6| Step: 10
Training loss: 0.40523519680277426
Validation loss: 3.1677252898953587

Epoch: 6| Step: 11
Training loss: 0.3178473022745506
Validation loss: 3.1882030235364733

Epoch: 6| Step: 12
Training loss: 0.3280384994204379
Validation loss: 3.2634431038559724

Epoch: 6| Step: 13
Training loss: 0.24665361630599458
Validation loss: 3.193952872743758

Epoch: 400| Step: 0
Training loss: 0.26887394741549286
Validation loss: 3.1553225020042657

Epoch: 6| Step: 1
Training loss: 0.34322670640000963
Validation loss: 3.1873085986745964

Epoch: 6| Step: 2
Training loss: 0.19136581188360785
Validation loss: 3.1801459304546422

Epoch: 6| Step: 3
Training loss: 0.3215879539966066
Validation loss: 3.250179126889389

Epoch: 6| Step: 4
Training loss: 0.39837329945651667
Validation loss: 3.23648201686484

Epoch: 6| Step: 5
Training loss: 0.3392739836199378
Validation loss: 3.1599822308849568

Epoch: 6| Step: 6
Training loss: 0.33327887010685897
Validation loss: 3.1935809603931973

Epoch: 6| Step: 7
Training loss: 0.324892194914475
Validation loss: 3.2305399445972665

Epoch: 6| Step: 8
Training loss: 0.2772281298271252
Validation loss: 3.140762579136058

Epoch: 6| Step: 9
Training loss: 0.2219969877509074
Validation loss: 3.1333944108434593

Epoch: 6| Step: 10
Training loss: 0.26174654741842973
Validation loss: 3.1357783281129983

Epoch: 6| Step: 11
Training loss: 0.3286926491104285
Validation loss: 3.1508715791221498

Epoch: 6| Step: 12
Training loss: 0.3563532671247538
Validation loss: 3.1580945155322424

Epoch: 6| Step: 13
Training loss: 0.26540351497238496
Validation loss: 3.056531097757295

Epoch: 401| Step: 0
Training loss: 0.3879053618214177
Validation loss: 3.217485444876534

Epoch: 6| Step: 1
Training loss: 0.3325612942409039
Validation loss: 3.1286350724858814

Epoch: 6| Step: 2
Training loss: 0.2531004222664387
Validation loss: 3.2590443624789827

Epoch: 6| Step: 3
Training loss: 0.2634489883460985
Validation loss: 3.232625589549379

Epoch: 6| Step: 4
Training loss: 0.3912258867139541
Validation loss: 3.2799347921030377

Epoch: 6| Step: 5
Training loss: 0.29356737648753334
Validation loss: 3.160092221536021

Epoch: 6| Step: 6
Training loss: 0.36208682437540946
Validation loss: 3.0943403355107844

Epoch: 6| Step: 7
Training loss: 0.3475598405181654
Validation loss: 3.1507895797063212

Epoch: 6| Step: 8
Training loss: 0.3492181069626318
Validation loss: 3.137785999591557

Epoch: 6| Step: 9
Training loss: 0.30703351794077416
Validation loss: 3.1161540269411887

Epoch: 6| Step: 10
Training loss: 0.20768637737851253
Validation loss: 3.153151511467441

Epoch: 6| Step: 11
Training loss: 0.4213694262796531
Validation loss: 3.1754888358476747

Epoch: 6| Step: 12
Training loss: 0.31086575432784713
Validation loss: 3.1960458823241864

Epoch: 6| Step: 13
Training loss: 0.30049904056164234
Validation loss: 3.171283873548924

Epoch: 402| Step: 0
Training loss: 0.3020354539921033
Validation loss: 3.218806145928319

Epoch: 6| Step: 1
Training loss: 0.3682906846273131
Validation loss: 3.203533289249416

Epoch: 6| Step: 2
Training loss: 0.35347745489099947
Validation loss: 3.129485712832528

Epoch: 6| Step: 3
Training loss: 0.27082104227101694
Validation loss: 3.149263322559406

Epoch: 6| Step: 4
Training loss: 0.21597985804488137
Validation loss: 3.093260292829683

Epoch: 6| Step: 5
Training loss: 0.27226690677904825
Validation loss: 3.1386355904596686

Epoch: 6| Step: 6
Training loss: 0.2452618449448945
Validation loss: 3.141131168905361

Epoch: 6| Step: 7
Training loss: 0.2714948583541071
Validation loss: 3.1398283167796155

Epoch: 6| Step: 8
Training loss: 0.3373959398559013
Validation loss: 3.1633932151459434

Epoch: 6| Step: 9
Training loss: 0.3625685561236066
Validation loss: 3.1893972597137172

Epoch: 6| Step: 10
Training loss: 0.32679019500741197
Validation loss: 3.168449268203202

Epoch: 6| Step: 11
Training loss: 0.35309342732690335
Validation loss: 3.1864683189539074

Epoch: 6| Step: 12
Training loss: 0.35738189140098553
Validation loss: 3.1773925547388044

Epoch: 6| Step: 13
Training loss: 0.3937948549546738
Validation loss: 3.208903464320617

Epoch: 403| Step: 0
Training loss: 0.29673549235247404
Validation loss: 3.1845381071366474

Epoch: 6| Step: 1
Training loss: 0.2640843026905881
Validation loss: 3.1839654311567114

Epoch: 6| Step: 2
Training loss: 0.23960173664038803
Validation loss: 3.262141491568893

Epoch: 6| Step: 3
Training loss: 0.2214050187808244
Validation loss: 3.2055300979514256

Epoch: 6| Step: 4
Training loss: 0.2582038163768844
Validation loss: 3.1990690402011634

Epoch: 6| Step: 5
Training loss: 0.29322216517941474
Validation loss: 3.1550284813725358

Epoch: 6| Step: 6
Training loss: 0.24003029505437035
Validation loss: 3.1620871951711766

Epoch: 6| Step: 7
Training loss: 0.2972540944654001
Validation loss: 3.1427851091733605

Epoch: 6| Step: 8
Training loss: 0.3307349312147249
Validation loss: 3.156495238996404

Epoch: 6| Step: 9
Training loss: 0.304875816934546
Validation loss: 3.1311590408646826

Epoch: 6| Step: 10
Training loss: 0.36362391892184276
Validation loss: 3.1671580050575057

Epoch: 6| Step: 11
Training loss: 0.27812235970261856
Validation loss: 3.1827364276227743

Epoch: 6| Step: 12
Training loss: 0.24269232127508905
Validation loss: 3.2370393501429953

Epoch: 6| Step: 13
Training loss: 0.38048155212796403
Validation loss: 3.1660676105113454

Epoch: 404| Step: 0
Training loss: 0.22132006644333888
Validation loss: 3.160157758903379

Epoch: 6| Step: 1
Training loss: 0.28738362973693155
Validation loss: 3.2246540450805425

Epoch: 6| Step: 2
Training loss: 0.29127979449516356
Validation loss: 3.1865262931634017

Epoch: 6| Step: 3
Training loss: 0.2637332703495899
Validation loss: 3.203907990317565

Epoch: 6| Step: 4
Training loss: 0.3413391317914088
Validation loss: 3.175007418125728

Epoch: 6| Step: 5
Training loss: 0.3145250273769783
Validation loss: 3.100662677446007

Epoch: 6| Step: 6
Training loss: 0.2515594008355535
Validation loss: 3.1534998403452077

Epoch: 6| Step: 7
Training loss: 0.23744282410695586
Validation loss: 3.0638075911049136

Epoch: 6| Step: 8
Training loss: 0.3602975737696748
Validation loss: 3.090315636868447

Epoch: 6| Step: 9
Training loss: 0.287552899697657
Validation loss: 3.1454965314294694

Epoch: 6| Step: 10
Training loss: 0.3089595750966822
Validation loss: 3.1515646802585455

Epoch: 6| Step: 11
Training loss: 0.26951405567112807
Validation loss: 3.190298111398286

Epoch: 6| Step: 12
Training loss: 0.24717844982675916
Validation loss: 3.1925149499139374

Epoch: 6| Step: 13
Training loss: 0.3825459622836271
Validation loss: 3.114033594171172

Epoch: 405| Step: 0
Training loss: 0.27094999728919966
Validation loss: 3.170781716032293

Epoch: 6| Step: 1
Training loss: 0.25134001661347805
Validation loss: 3.0834596238606005

Epoch: 6| Step: 2
Training loss: 0.21453158501517636
Validation loss: 3.098234535555246

Epoch: 6| Step: 3
Training loss: 0.1973746347913208
Validation loss: 3.089325409247529

Epoch: 6| Step: 4
Training loss: 0.27364375645972705
Validation loss: 3.0959379762922747

Epoch: 6| Step: 5
Training loss: 0.24375233863051024
Validation loss: 3.089340021006272

Epoch: 6| Step: 6
Training loss: 0.1960902179536703
Validation loss: 3.124824989504523

Epoch: 6| Step: 7
Training loss: 0.2510592402378806
Validation loss: 3.1030354497460015

Epoch: 6| Step: 8
Training loss: 0.303403177137154
Validation loss: 3.10995776978796

Epoch: 6| Step: 9
Training loss: 0.25551310979463293
Validation loss: 3.141618637878098

Epoch: 6| Step: 10
Training loss: 0.2705581976173321
Validation loss: 3.14446642317203

Epoch: 6| Step: 11
Training loss: 0.2757346527241746
Validation loss: 3.1108507395585296

Epoch: 6| Step: 12
Training loss: 0.15933470403591765
Validation loss: 3.121153600546201

Epoch: 6| Step: 13
Training loss: 0.18461743515183357
Validation loss: 3.178449835066526

Epoch: 406| Step: 0
Training loss: 0.18347474563280564
Validation loss: 3.1594232652991523

Epoch: 6| Step: 1
Training loss: 0.19736448020514258
Validation loss: 3.1762793018641355

Epoch: 6| Step: 2
Training loss: 0.3647431522848261
Validation loss: 3.179345302304358

Epoch: 6| Step: 3
Training loss: 0.3209114870748662
Validation loss: 3.1542214147401193

Epoch: 6| Step: 4
Training loss: 0.377265958487655
Validation loss: 3.2037116033064272

Epoch: 6| Step: 5
Training loss: 0.29000819648883114
Validation loss: 3.1707342442298985

Epoch: 6| Step: 6
Training loss: 0.25225470480581375
Validation loss: 3.16267722617065

Epoch: 6| Step: 7
Training loss: 0.3074401830628649
Validation loss: 3.114435917524367

Epoch: 6| Step: 8
Training loss: 0.2074602648308087
Validation loss: 3.1093167758007874

Epoch: 6| Step: 9
Training loss: 0.38962367464316816
Validation loss: 3.0179404690337672

Epoch: 6| Step: 10
Training loss: 0.27885655727128866
Validation loss: 3.0914680850747542

Epoch: 6| Step: 11
Training loss: 0.3026159731760672
Validation loss: 3.0735657906144174

Epoch: 6| Step: 12
Training loss: 0.23200476909536927
Validation loss: 3.180613021433242

Epoch: 6| Step: 13
Training loss: 0.2553212863059275
Validation loss: 3.1444685209031764

Epoch: 407| Step: 0
Training loss: 0.36750732858967017
Validation loss: 3.2162606078554994

Epoch: 6| Step: 1
Training loss: 0.1589584568464
Validation loss: 3.177230197868098

Epoch: 6| Step: 2
Training loss: 0.24765024990190096
Validation loss: 3.155737127048601

Epoch: 6| Step: 3
Training loss: 0.36930879667668376
Validation loss: 3.123176360492702

Epoch: 6| Step: 4
Training loss: 0.2592844414323207
Validation loss: 3.131784817522553

Epoch: 6| Step: 5
Training loss: 0.16377099570505016
Validation loss: 3.159597428387783

Epoch: 6| Step: 6
Training loss: 0.22825336894403833
Validation loss: 3.0978209815333644

Epoch: 6| Step: 7
Training loss: 0.30934580173846715
Validation loss: 3.086148823773678

Epoch: 6| Step: 8
Training loss: 0.4262843178612893
Validation loss: 3.160873187157746

Epoch: 6| Step: 9
Training loss: 0.29367615806498687
Validation loss: 3.0681521359687274

Epoch: 6| Step: 10
Training loss: 0.2982003592966782
Validation loss: 3.1369013687629717

Epoch: 6| Step: 11
Training loss: 0.26775320965849303
Validation loss: 3.103913806797587

Epoch: 6| Step: 12
Training loss: 0.33973904893220896
Validation loss: 3.164374768581554

Epoch: 6| Step: 13
Training loss: 0.3010687630524397
Validation loss: 3.1967193317019693

Epoch: 408| Step: 0
Training loss: 0.2895196187070569
Validation loss: 3.204888058640162

Epoch: 6| Step: 1
Training loss: 0.2718766486457736
Validation loss: 3.1169511009070967

Epoch: 6| Step: 2
Training loss: 0.31985103116229274
Validation loss: 3.1536820165740873

Epoch: 6| Step: 3
Training loss: 0.37986745533632565
Validation loss: 3.0873107944847313

Epoch: 6| Step: 4
Training loss: 0.24964242934218206
Validation loss: 3.1182883604535396

Epoch: 6| Step: 5
Training loss: 0.39985252135219906
Validation loss: 3.103105944126469

Epoch: 6| Step: 6
Training loss: 0.2344461015299479
Validation loss: 3.1162607190411555

Epoch: 6| Step: 7
Training loss: 0.28288555097519996
Validation loss: 3.121707771514015

Epoch: 6| Step: 8
Training loss: 0.2956036777145927
Validation loss: 3.134279080638215

Epoch: 6| Step: 9
Training loss: 0.26703793929701874
Validation loss: 3.184379596101678

Epoch: 6| Step: 10
Training loss: 0.3787984596385775
Validation loss: 3.17382055037157

Epoch: 6| Step: 11
Training loss: 0.2503896002071554
Validation loss: 3.2015267951777777

Epoch: 6| Step: 12
Training loss: 0.38203721461096174
Validation loss: 3.245756007013279

Epoch: 6| Step: 13
Training loss: 0.37180499131108385
Validation loss: 3.2654744407102507

Epoch: 409| Step: 0
Training loss: 0.3912552898402818
Validation loss: 3.1801336226989614

Epoch: 6| Step: 1
Training loss: 0.3416680992588775
Validation loss: 3.140328021582295

Epoch: 6| Step: 2
Training loss: 0.4293533065957328
Validation loss: 3.1200918309032586

Epoch: 6| Step: 3
Training loss: 0.21858853102828235
Validation loss: 3.0655688719774967

Epoch: 6| Step: 4
Training loss: 0.3616253841515461
Validation loss: 3.139703200966632

Epoch: 6| Step: 5
Training loss: 0.2681799892910914
Validation loss: 3.1150570299776574

Epoch: 6| Step: 6
Training loss: 0.19522259550366344
Validation loss: 3.131774222932892

Epoch: 6| Step: 7
Training loss: 0.35845878155429134
Validation loss: 3.1881291385661914

Epoch: 6| Step: 8
Training loss: 0.3122126927487416
Validation loss: 3.1761486909140837

Epoch: 6| Step: 9
Training loss: 0.2850525027150664
Validation loss: 3.1550933052892067

Epoch: 6| Step: 10
Training loss: 0.35416338255238494
Validation loss: 3.1470433785812935

Epoch: 6| Step: 11
Training loss: 0.3138942846863138
Validation loss: 3.123060222038168

Epoch: 6| Step: 12
Training loss: 0.24155489533311583
Validation loss: 3.1694457549964397

Epoch: 6| Step: 13
Training loss: 0.3267928625120843
Validation loss: 3.1455352633570435

Epoch: 410| Step: 0
Training loss: 0.21034507210156897
Validation loss: 3.118064737813825

Epoch: 6| Step: 1
Training loss: 0.30516843252870784
Validation loss: 3.102883647689916

Epoch: 6| Step: 2
Training loss: 0.3542314942250232
Validation loss: 3.1167551759061998

Epoch: 6| Step: 3
Training loss: 0.39065807202528163
Validation loss: 3.0803556798980165

Epoch: 6| Step: 4
Training loss: 0.3111358431700225
Validation loss: 3.1537924285425567

Epoch: 6| Step: 5
Training loss: 0.34417799834392265
Validation loss: 3.1534955938931533

Epoch: 6| Step: 6
Training loss: 0.4010187943446835
Validation loss: 3.232230170981693

Epoch: 6| Step: 7
Training loss: 0.22377778231103881
Validation loss: 3.2633555555967013

Epoch: 6| Step: 8
Training loss: 0.2874150886781738
Validation loss: 3.22209216180573

Epoch: 6| Step: 9
Training loss: 0.31547504724846376
Validation loss: 3.178604291385769

Epoch: 6| Step: 10
Training loss: 0.29490803060815657
Validation loss: 3.1475018040876845

Epoch: 6| Step: 11
Training loss: 0.336404763770818
Validation loss: 3.1348658655604633

Epoch: 6| Step: 12
Training loss: 0.37382872769776554
Validation loss: 3.1302130324105755

Epoch: 6| Step: 13
Training loss: 0.26122389455348366
Validation loss: 3.129265226868294

Epoch: 411| Step: 0
Training loss: 0.250081689720405
Validation loss: 3.0770506815554337

Epoch: 6| Step: 1
Training loss: 0.25301926547324166
Validation loss: 3.1564871821657627

Epoch: 6| Step: 2
Training loss: 0.3363097590129366
Validation loss: 3.1200200136879563

Epoch: 6| Step: 3
Training loss: 0.28625933352916594
Validation loss: 3.14671435029733

Epoch: 6| Step: 4
Training loss: 0.3233948200280156
Validation loss: 3.1789484438279962

Epoch: 6| Step: 5
Training loss: 0.28564335749458364
Validation loss: 3.222470426500199

Epoch: 6| Step: 6
Training loss: 0.1964985692564247
Validation loss: 3.1993321114167017

Epoch: 6| Step: 7
Training loss: 0.26954952122775444
Validation loss: 3.2070071133918403

Epoch: 6| Step: 8
Training loss: 0.2628534117798161
Validation loss: 3.2177740796502903

Epoch: 6| Step: 9
Training loss: 0.16990742128658506
Validation loss: 3.1345600001315077

Epoch: 6| Step: 10
Training loss: 0.2701747510233099
Validation loss: 3.165701459718815

Epoch: 6| Step: 11
Training loss: 0.2582047686041201
Validation loss: 3.090073491367578

Epoch: 6| Step: 12
Training loss: 0.2855435184641557
Validation loss: 3.1543656946947842

Epoch: 6| Step: 13
Training loss: 0.2240113216007287
Validation loss: 3.168690465584802

Epoch: 412| Step: 0
Training loss: 0.2809872989838626
Validation loss: 3.153920021811356

Epoch: 6| Step: 1
Training loss: 0.22452843907879072
Validation loss: 3.1259701049572737

Epoch: 6| Step: 2
Training loss: 0.22576756617384583
Validation loss: 3.158997803158674

Epoch: 6| Step: 3
Training loss: 0.3412682068687236
Validation loss: 3.1358347938190203

Epoch: 6| Step: 4
Training loss: 0.26050122159902095
Validation loss: 3.1805159280817215

Epoch: 6| Step: 5
Training loss: 0.3171751546101506
Validation loss: 3.1456267855375333

Epoch: 6| Step: 6
Training loss: 0.38544906875224705
Validation loss: 3.1075620238011075

Epoch: 6| Step: 7
Training loss: 0.2530048803548571
Validation loss: 3.1189919382357862

Epoch: 6| Step: 8
Training loss: 0.2802169556809689
Validation loss: 3.0884401370124146

Epoch: 6| Step: 9
Training loss: 0.2846913009163703
Validation loss: 3.178615267437511

Epoch: 6| Step: 10
Training loss: 0.2852821072354424
Validation loss: 3.1753579546176542

Epoch: 6| Step: 11
Training loss: 0.21913091668640308
Validation loss: 3.1205777094567377

Epoch: 6| Step: 12
Training loss: 0.3055332623041212
Validation loss: 3.16329071302279

Epoch: 6| Step: 13
Training loss: 0.279619177672845
Validation loss: 3.1379746725187996

Epoch: 413| Step: 0
Training loss: 0.25252236519804117
Validation loss: 3.128538976124837

Epoch: 6| Step: 1
Training loss: 0.33956807015447793
Validation loss: 3.1423785879493327

Epoch: 6| Step: 2
Training loss: 0.370142591102857
Validation loss: 3.108542722308941

Epoch: 6| Step: 3
Training loss: 0.36701813302081865
Validation loss: 3.107326823406634

Epoch: 6| Step: 4
Training loss: 0.21487808820104182
Validation loss: 3.1223996406046246

Epoch: 6| Step: 5
Training loss: 0.26873566511647295
Validation loss: 3.1501278942121047

Epoch: 6| Step: 6
Training loss: 0.2332744668177516
Validation loss: 3.0756973142752386

Epoch: 6| Step: 7
Training loss: 0.21770744863509855
Validation loss: 3.0884397252945943

Epoch: 6| Step: 8
Training loss: 0.25000976007006404
Validation loss: 3.097099622990416

Epoch: 6| Step: 9
Training loss: 0.2365781155424933
Validation loss: 3.1242698325028577

Epoch: 6| Step: 10
Training loss: 0.20456518784857108
Validation loss: 3.1522778358800623

Epoch: 6| Step: 11
Training loss: 0.24150780698940177
Validation loss: 3.124148405389199

Epoch: 6| Step: 12
Training loss: 0.2844430941494935
Validation loss: 3.1937044383044597

Epoch: 6| Step: 13
Training loss: 0.2540886297314094
Validation loss: 3.239220912731996

Epoch: 414| Step: 0
Training loss: 0.16645740743514054
Validation loss: 3.1778035249163508

Epoch: 6| Step: 1
Training loss: 0.3091659552487999
Validation loss: 3.1543054854174115

Epoch: 6| Step: 2
Training loss: 0.27137806409479165
Validation loss: 3.1902669602980502

Epoch: 6| Step: 3
Training loss: 0.36438554666740275
Validation loss: 3.128688060123509

Epoch: 6| Step: 4
Training loss: 0.28605705534254394
Validation loss: 3.1337642349713124

Epoch: 6| Step: 5
Training loss: 0.3435629205546755
Validation loss: 3.1455586589283038

Epoch: 6| Step: 6
Training loss: 0.3505326764551375
Validation loss: 3.173114427968806

Epoch: 6| Step: 7
Training loss: 0.23544848492198303
Validation loss: 3.143662017036014

Epoch: 6| Step: 8
Training loss: 0.2809140662793691
Validation loss: 3.152276764401821

Epoch: 6| Step: 9
Training loss: 0.2552946570755526
Validation loss: 3.207202456105929

Epoch: 6| Step: 10
Training loss: 0.25440722706575136
Validation loss: 3.183742090681436

Epoch: 6| Step: 11
Training loss: 0.26511648532948123
Validation loss: 3.2149623448810236

Epoch: 6| Step: 12
Training loss: 0.22561280391942543
Validation loss: 3.1458365375089854

Epoch: 6| Step: 13
Training loss: 0.3038978982478987
Validation loss: 3.242839432094441

Epoch: 415| Step: 0
Training loss: 0.3404822873019193
Validation loss: 3.1429817884052897

Epoch: 6| Step: 1
Training loss: 0.3233386008314498
Validation loss: 3.1104660292581734

Epoch: 6| Step: 2
Training loss: 0.3447973486652078
Validation loss: 3.1237922623467007

Epoch: 6| Step: 3
Training loss: 0.29006758784011816
Validation loss: 3.0978207378161833

Epoch: 6| Step: 4
Training loss: 0.34464314778045324
Validation loss: 3.124800650278106

Epoch: 6| Step: 5
Training loss: 0.25640999172346807
Validation loss: 3.079323162666874

Epoch: 6| Step: 6
Training loss: 0.18862875293590453
Validation loss: 3.179928244834839

Epoch: 6| Step: 7
Training loss: 0.1899113373871409
Validation loss: 3.087493298274912

Epoch: 6| Step: 8
Training loss: 0.2438531174542781
Validation loss: 3.2038421076248444

Epoch: 6| Step: 9
Training loss: 0.2827889142818417
Validation loss: 3.08289065705837

Epoch: 6| Step: 10
Training loss: 0.2716306525597684
Validation loss: 3.1315910133358256

Epoch: 6| Step: 11
Training loss: 0.3761759043761959
Validation loss: 3.0694009011595376

Epoch: 6| Step: 12
Training loss: 0.30057207488278853
Validation loss: 3.054930928474928

Epoch: 6| Step: 13
Training loss: 0.29932132237739234
Validation loss: 3.0707810604938

Epoch: 416| Step: 0
Training loss: 0.33816568942459146
Validation loss: 3.0480650705089953

Epoch: 6| Step: 1
Training loss: 0.352227292406473
Validation loss: 3.045625166209009

Epoch: 6| Step: 2
Training loss: 0.32359536690448465
Validation loss: 3.0702652090376334

Epoch: 6| Step: 3
Training loss: 0.24721180780640511
Validation loss: 3.1326074192213444

Epoch: 6| Step: 4
Training loss: 0.2167189604133184
Validation loss: 3.144417707395465

Epoch: 6| Step: 5
Training loss: 0.2525501717869898
Validation loss: 3.1844093572967456

Epoch: 6| Step: 6
Training loss: 0.4075751516457822
Validation loss: 3.2085643701637867

Epoch: 6| Step: 7
Training loss: 0.291439400697188
Validation loss: 3.2207443577039587

Epoch: 6| Step: 8
Training loss: 0.19066808401289018
Validation loss: 3.1522328460861546

Epoch: 6| Step: 9
Training loss: 0.32080982723865453
Validation loss: 3.123903883387098

Epoch: 6| Step: 10
Training loss: 0.41146235725592034
Validation loss: 3.1245786255623273

Epoch: 6| Step: 11
Training loss: 0.2589919392673543
Validation loss: 3.104109735841567

Epoch: 6| Step: 12
Training loss: 0.349256401251154
Validation loss: 3.131638253735953

Epoch: 6| Step: 13
Training loss: 0.20552434060464608
Validation loss: 3.185955895306394

Epoch: 417| Step: 0
Training loss: 0.30065553688509533
Validation loss: 3.2760960382863007

Epoch: 6| Step: 1
Training loss: 0.23911440697172343
Validation loss: 3.1674946321614064

Epoch: 6| Step: 2
Training loss: 0.30723160086621304
Validation loss: 3.219002760064422

Epoch: 6| Step: 3
Training loss: 0.31276891581950944
Validation loss: 3.247192882241769

Epoch: 6| Step: 4
Training loss: 0.5227825850315162
Validation loss: 3.202753507579709

Epoch: 6| Step: 5
Training loss: 0.2415835479459262
Validation loss: 3.191285621732139

Epoch: 6| Step: 6
Training loss: 0.3677751424611137
Validation loss: 3.131425127016586

Epoch: 6| Step: 7
Training loss: 0.33884991648522267
Validation loss: 3.1654007204922934

Epoch: 6| Step: 8
Training loss: 0.36684478836829
Validation loss: 3.0908579425821143

Epoch: 6| Step: 9
Training loss: 0.41656727996281534
Validation loss: 3.093507108561909

Epoch: 6| Step: 10
Training loss: 0.24545511000219922
Validation loss: 3.184249766654048

Epoch: 6| Step: 11
Training loss: 0.39752384222250803
Validation loss: 3.2482666871025794

Epoch: 6| Step: 12
Training loss: 0.32743464234530995
Validation loss: 3.186998277957971

Epoch: 6| Step: 13
Training loss: 0.2693530889835692
Validation loss: 3.213055607387039

Epoch: 418| Step: 0
Training loss: 0.20554870021796987
Validation loss: 3.1988036616521107

Epoch: 6| Step: 1
Training loss: 0.4304862141744536
Validation loss: 3.1726187975489832

Epoch: 6| Step: 2
Training loss: 0.30363168939765295
Validation loss: 3.197775950530344

Epoch: 6| Step: 3
Training loss: 0.3226635527996642
Validation loss: 3.1653161598978055

Epoch: 6| Step: 4
Training loss: 0.3223758624561927
Validation loss: 3.1464010867353536

Epoch: 6| Step: 5
Training loss: 0.2776338644883978
Validation loss: 3.131768449818051

Epoch: 6| Step: 6
Training loss: 0.31319776359645124
Validation loss: 3.220958162153072

Epoch: 6| Step: 7
Training loss: 0.35898004473211204
Validation loss: 3.1225296937799643

Epoch: 6| Step: 8
Training loss: 0.17133004862813928
Validation loss: 3.1616427489806957

Epoch: 6| Step: 9
Training loss: 0.1791341180031358
Validation loss: 3.158001656004987

Epoch: 6| Step: 10
Training loss: 0.24326255060066712
Validation loss: 3.1046390344721044

Epoch: 6| Step: 11
Training loss: 0.3081749718285198
Validation loss: 3.1179920837655835

Epoch: 6| Step: 12
Training loss: 0.34107759268810584
Validation loss: 3.1679646358314324

Epoch: 6| Step: 13
Training loss: 0.34257442859495385
Validation loss: 3.146511160643573

Epoch: 419| Step: 0
Training loss: 0.39245689000445705
Validation loss: 3.11803686669254

Epoch: 6| Step: 1
Training loss: 0.23919533672906396
Validation loss: 3.12018351357516

Epoch: 6| Step: 2
Training loss: 0.2771109826530926
Validation loss: 3.0854059848089634

Epoch: 6| Step: 3
Training loss: 0.2924896136909622
Validation loss: 3.0862317423836023

Epoch: 6| Step: 4
Training loss: 0.23530693739133293
Validation loss: 3.133320615789969

Epoch: 6| Step: 5
Training loss: 0.2379591202744319
Validation loss: 3.0705628426486076

Epoch: 6| Step: 6
Training loss: 0.3421574244063142
Validation loss: 3.1555037796633756

Epoch: 6| Step: 7
Training loss: 0.34480277237576923
Validation loss: 3.0974366157087267

Epoch: 6| Step: 8
Training loss: 0.2484609946651565
Validation loss: 3.1913510539193286

Epoch: 6| Step: 9
Training loss: 0.32805201309079474
Validation loss: 3.1938436998332014

Epoch: 6| Step: 10
Training loss: 0.23190289745984055
Validation loss: 3.278443719857204

Epoch: 6| Step: 11
Training loss: 0.306546846859242
Validation loss: 3.1883996180177956

Epoch: 6| Step: 12
Training loss: 0.2832230922631694
Validation loss: 3.219138581853483

Epoch: 6| Step: 13
Training loss: 0.29137321878131806
Validation loss: 3.2315750226690967

Epoch: 420| Step: 0
Training loss: 0.3826496984778452
Validation loss: 3.1970817436917955

Epoch: 6| Step: 1
Training loss: 0.24422027814390673
Validation loss: 3.1417157507450955

Epoch: 6| Step: 2
Training loss: 0.3176613744312061
Validation loss: 3.1252427451902904

Epoch: 6| Step: 3
Training loss: 0.2268675197860432
Validation loss: 3.183949431538574

Epoch: 6| Step: 4
Training loss: 0.18732828980032212
Validation loss: 3.176300819627953

Epoch: 6| Step: 5
Training loss: 0.3325825322051608
Validation loss: 3.1007409917554014

Epoch: 6| Step: 6
Training loss: 0.21300192207266172
Validation loss: 3.1505922779961204

Epoch: 6| Step: 7
Training loss: 0.285178222854808
Validation loss: 3.1922823988466633

Epoch: 6| Step: 8
Training loss: 0.34897483483010067
Validation loss: 3.2043609219628677

Epoch: 6| Step: 9
Training loss: 0.33558798505948584
Validation loss: 3.24345745661366

Epoch: 6| Step: 10
Training loss: 0.2581469216401663
Validation loss: 3.2042722554826484

Epoch: 6| Step: 11
Training loss: 0.28137493007969167
Validation loss: 3.1998042935885724

Epoch: 6| Step: 12
Training loss: 0.36312050493251896
Validation loss: 3.2078467202347167

Epoch: 6| Step: 13
Training loss: 0.147954632247739
Validation loss: 3.1278291992408436

Epoch: 421| Step: 0
Training loss: 0.3121474303724692
Validation loss: 3.1878106458294755

Epoch: 6| Step: 1
Training loss: 0.3334374662504742
Validation loss: 3.177539471677

Epoch: 6| Step: 2
Training loss: 0.35262707486061146
Validation loss: 3.100483806860439

Epoch: 6| Step: 3
Training loss: 0.27934366114429665
Validation loss: 3.198651919921533

Epoch: 6| Step: 4
Training loss: 0.3954991280814975
Validation loss: 3.1879457149662147

Epoch: 6| Step: 5
Training loss: 0.2697561403889061
Validation loss: 3.1679593739525664

Epoch: 6| Step: 6
Training loss: 0.28690504731205735
Validation loss: 3.204146158841451

Epoch: 6| Step: 7
Training loss: 0.24904488115920412
Validation loss: 3.1952548717472284

Epoch: 6| Step: 8
Training loss: 0.21759441527057166
Validation loss: 3.065754374484196

Epoch: 6| Step: 9
Training loss: 0.2136599438001928
Validation loss: 3.102239834279428

Epoch: 6| Step: 10
Training loss: 0.414062032159505
Validation loss: 3.0734912313610616

Epoch: 6| Step: 11
Training loss: 0.42612578075445956
Validation loss: 3.086156755215333

Epoch: 6| Step: 12
Training loss: 0.3591574756917051
Validation loss: 3.09256744903306

Epoch: 6| Step: 13
Training loss: 0.24514557571464596
Validation loss: 3.1744667326277116

Epoch: 422| Step: 0
Training loss: 0.28124503290240727
Validation loss: 3.189376166700613

Epoch: 6| Step: 1
Training loss: 0.31068648792793424
Validation loss: 3.180754786271043

Epoch: 6| Step: 2
Training loss: 0.2440199820938077
Validation loss: 3.1748038363995836

Epoch: 6| Step: 3
Training loss: 0.3198289477748539
Validation loss: 3.1510259874862796

Epoch: 6| Step: 4
Training loss: 0.45273867943258667
Validation loss: 3.1583639814421383

Epoch: 6| Step: 5
Training loss: 0.35513541553641914
Validation loss: 3.0532304649918136

Epoch: 6| Step: 6
Training loss: 0.19332175418657657
Validation loss: 3.140628770411618

Epoch: 6| Step: 7
Training loss: 0.22144606963771946
Validation loss: 3.07320838879737

Epoch: 6| Step: 8
Training loss: 0.26757720612973784
Validation loss: 3.060690001107202

Epoch: 6| Step: 9
Training loss: 0.33724642958988577
Validation loss: 3.070445645901723

Epoch: 6| Step: 10
Training loss: 0.35206092893919344
Validation loss: 3.0356199744077377

Epoch: 6| Step: 11
Training loss: 0.24287934084128407
Validation loss: 3.087307242117743

Epoch: 6| Step: 12
Training loss: 0.22028232225743477
Validation loss: 3.1811374042323157

Epoch: 6| Step: 13
Training loss: 0.3740154494585453
Validation loss: 3.091294685428487

Epoch: 423| Step: 0
Training loss: 0.35178586433897074
Validation loss: 3.1977386590742967

Epoch: 6| Step: 1
Training loss: 0.26062733553107525
Validation loss: 3.167614109118582

Epoch: 6| Step: 2
Training loss: 0.31937254249687314
Validation loss: 3.0890502682464422

Epoch: 6| Step: 3
Training loss: 0.308734644341951
Validation loss: 3.1409898485912118

Epoch: 6| Step: 4
Training loss: 0.3360389733645088
Validation loss: 3.1013882297398054

Epoch: 6| Step: 5
Training loss: 0.2951740929545135
Validation loss: 3.097055461102414

Epoch: 6| Step: 6
Training loss: 0.17590490865949918
Validation loss: 3.135104957032329

Epoch: 6| Step: 7
Training loss: 0.30143755365094793
Validation loss: 3.089285355181244

Epoch: 6| Step: 8
Training loss: 0.3228360531791991
Validation loss: 3.1378108712810016

Epoch: 6| Step: 9
Training loss: 0.3697422916957808
Validation loss: 3.141496414070809

Epoch: 6| Step: 10
Training loss: 0.36060512481344126
Validation loss: 3.1825077068877814

Epoch: 6| Step: 11
Training loss: 0.18498566733075694
Validation loss: 3.11079494444116

Epoch: 6| Step: 12
Training loss: 0.40295822478885795
Validation loss: 3.137396511584973

Epoch: 6| Step: 13
Training loss: 0.3137419578387833
Validation loss: 3.1266921230518903

Epoch: 424| Step: 0
Training loss: 0.21368767332988806
Validation loss: 3.132635985211282

Epoch: 6| Step: 1
Training loss: 0.33201260233854135
Validation loss: 3.10292251453862

Epoch: 6| Step: 2
Training loss: 0.3426233925049296
Validation loss: 3.1400280665096973

Epoch: 6| Step: 3
Training loss: 0.2937140965333066
Validation loss: 3.0912653389218647

Epoch: 6| Step: 4
Training loss: 0.2837007819775066
Validation loss: 3.121997866219071

Epoch: 6| Step: 5
Training loss: 0.26151917093000276
Validation loss: 3.0808174892393367

Epoch: 6| Step: 6
Training loss: 0.24500709888333283
Validation loss: 3.1103794833237095

Epoch: 6| Step: 7
Training loss: 0.20253396243936717
Validation loss: 3.109884146917198

Epoch: 6| Step: 8
Training loss: 0.22537687448112426
Validation loss: 3.0685598921823236

Epoch: 6| Step: 9
Training loss: 0.32612286273684377
Validation loss: 3.088605681726793

Epoch: 6| Step: 10
Training loss: 0.2377732129673268
Validation loss: 3.0821251478182647

Epoch: 6| Step: 11
Training loss: 0.30857512260906816
Validation loss: 3.186124280362645

Epoch: 6| Step: 12
Training loss: 0.30069001783475646
Validation loss: 3.092493514946172

Epoch: 6| Step: 13
Training loss: 0.2655761758026162
Validation loss: 3.136625523684175

Epoch: 425| Step: 0
Training loss: 0.19489243156961655
Validation loss: 3.2104474364301137

Epoch: 6| Step: 1
Training loss: 0.3615962090765095
Validation loss: 3.1456093150495072

Epoch: 6| Step: 2
Training loss: 0.2698007148835712
Validation loss: 3.1825768592185764

Epoch: 6| Step: 3
Training loss: 0.2177261506475428
Validation loss: 3.14964538828665

Epoch: 6| Step: 4
Training loss: 0.4134509230472504
Validation loss: 3.224378349951675

Epoch: 6| Step: 5
Training loss: 0.25110659959883025
Validation loss: 3.0993504038462545

Epoch: 6| Step: 6
Training loss: 0.1673519264043783
Validation loss: 3.1166347437428974

Epoch: 6| Step: 7
Training loss: 0.264622873570724
Validation loss: 3.121083590188994

Epoch: 6| Step: 8
Training loss: 0.36820817678034595
Validation loss: 3.0835000757718745

Epoch: 6| Step: 9
Training loss: 0.1424441949635972
Validation loss: 3.172272367595122

Epoch: 6| Step: 10
Training loss: 0.3795737453272877
Validation loss: 3.1090510852985176

Epoch: 6| Step: 11
Training loss: 0.28648018175670764
Validation loss: 3.15007097830354

Epoch: 6| Step: 12
Training loss: 0.2990672083835809
Validation loss: 3.166017495087517

Epoch: 6| Step: 13
Training loss: 0.3585175360510029
Validation loss: 3.155907401448067

Epoch: 426| Step: 0
Training loss: 0.300999067134774
Validation loss: 3.1254325567330694

Epoch: 6| Step: 1
Training loss: 0.2730827482613225
Validation loss: 3.161024203127263

Epoch: 6| Step: 2
Training loss: 0.33882456354754725
Validation loss: 3.128367300999122

Epoch: 6| Step: 3
Training loss: 0.28610810052703367
Validation loss: 3.1558643898662617

Epoch: 6| Step: 4
Training loss: 0.3492637929520619
Validation loss: 3.1381315768421842

Epoch: 6| Step: 5
Training loss: 0.23293637781868265
Validation loss: 3.163165909691603

Epoch: 6| Step: 6
Training loss: 0.2861662705164504
Validation loss: 3.130552661171942

Epoch: 6| Step: 7
Training loss: 0.38580371993650964
Validation loss: 3.1885718619109005

Epoch: 6| Step: 8
Training loss: 0.2053440821756275
Validation loss: 3.1433905323308386

Epoch: 6| Step: 9
Training loss: 0.26306378923400664
Validation loss: 3.1694554714226886

Epoch: 6| Step: 10
Training loss: 0.3151874616049146
Validation loss: 3.188757392857783

Epoch: 6| Step: 11
Training loss: 0.20193459077119078
Validation loss: 3.128064242702473

Epoch: 6| Step: 12
Training loss: 0.2699452275554345
Validation loss: 3.1505056172223815

Epoch: 6| Step: 13
Training loss: 0.2657206026703797
Validation loss: 3.1448164342608527

Epoch: 427| Step: 0
Training loss: 0.3049208896473458
Validation loss: 3.1427286039732754

Epoch: 6| Step: 1
Training loss: 0.36216947186473947
Validation loss: 3.1188297518902566

Epoch: 6| Step: 2
Training loss: 0.16931189748094272
Validation loss: 3.1601332265599105

Epoch: 6| Step: 3
Training loss: 0.25680788416368655
Validation loss: 3.050506644563056

Epoch: 6| Step: 4
Training loss: 0.24876463662509388
Validation loss: 3.0467464061238103

Epoch: 6| Step: 5
Training loss: 0.36400558698081625
Validation loss: 3.013766781920947

Epoch: 6| Step: 6
Training loss: 0.3079784028520918
Validation loss: 3.067662811373316

Epoch: 6| Step: 7
Training loss: 0.34374693305641446
Validation loss: 3.1462119213614366

Epoch: 6| Step: 8
Training loss: 0.24416645676329338
Validation loss: 3.130285904230494

Epoch: 6| Step: 9
Training loss: 0.19647682281601883
Validation loss: 3.1469310125412484

Epoch: 6| Step: 10
Training loss: 0.21137908349359216
Validation loss: 3.193872439730513

Epoch: 6| Step: 11
Training loss: 0.2526971934117777
Validation loss: 3.2158903115681357

Epoch: 6| Step: 12
Training loss: 0.4528733738694463
Validation loss: 3.23047788926984

Epoch: 6| Step: 13
Training loss: 0.3464207286501744
Validation loss: 3.161503828665077

Epoch: 428| Step: 0
Training loss: 0.21208621648603657
Validation loss: 3.18572840357578

Epoch: 6| Step: 1
Training loss: 0.2563514781848647
Validation loss: 3.135257987298128

Epoch: 6| Step: 2
Training loss: 0.26916253397980394
Validation loss: 3.1697665443055842

Epoch: 6| Step: 3
Training loss: 0.3007652228903303
Validation loss: 3.1498201298701285

Epoch: 6| Step: 4
Training loss: 0.2700654554719594
Validation loss: 3.1654655077448

Epoch: 6| Step: 5
Training loss: 0.3033708587995692
Validation loss: 3.195973683093324

Epoch: 6| Step: 6
Training loss: 0.36535352915407165
Validation loss: 3.2089200701223013

Epoch: 6| Step: 7
Training loss: 0.37544569709101355
Validation loss: 3.180894945787358

Epoch: 6| Step: 8
Training loss: 0.24449856268473935
Validation loss: 3.205956412513457

Epoch: 6| Step: 9
Training loss: 0.36419652673844705
Validation loss: 3.2241829756377434

Epoch: 6| Step: 10
Training loss: 0.32933936880027925
Validation loss: 3.180814101377823

Epoch: 6| Step: 11
Training loss: 0.3243996448746559
Validation loss: 3.1303982457560364

Epoch: 6| Step: 12
Training loss: 0.5136006236972765
Validation loss: 3.073795210257748

Epoch: 6| Step: 13
Training loss: 0.2799241817378256
Validation loss: 3.1200848262821976

Epoch: 429| Step: 0
Training loss: 0.34170267169316515
Validation loss: 3.119212373287722

Epoch: 6| Step: 1
Training loss: 0.3557205775365706
Validation loss: 3.1339710912225227

Epoch: 6| Step: 2
Training loss: 0.17054669831459446
Validation loss: 3.11603841739407

Epoch: 6| Step: 3
Training loss: 0.314103328840766
Validation loss: 3.0870821218290425

Epoch: 6| Step: 4
Training loss: 0.27106153368189434
Validation loss: 3.1379049108259123

Epoch: 6| Step: 5
Training loss: 0.17984150423624698
Validation loss: 3.179799995650556

Epoch: 6| Step: 6
Training loss: 0.2702892811676163
Validation loss: 3.1369699113939307

Epoch: 6| Step: 7
Training loss: 0.31815217887552566
Validation loss: 3.1968830604488896

Epoch: 6| Step: 8
Training loss: 0.3123478399813302
Validation loss: 3.1956751088377424

Epoch: 6| Step: 9
Training loss: 0.20731262663365
Validation loss: 3.146874935348394

Epoch: 6| Step: 10
Training loss: 0.2958665459194219
Validation loss: 3.1713579379668198

Epoch: 6| Step: 11
Training loss: 0.32045303146224785
Validation loss: 3.1856020344367972

Epoch: 6| Step: 12
Training loss: 0.3276150009757283
Validation loss: 3.2374622151294474

Epoch: 6| Step: 13
Training loss: 0.2320883144503876
Validation loss: 3.110132173139819

Epoch: 430| Step: 0
Training loss: 0.3949138561306273
Validation loss: 3.139340544495152

Epoch: 6| Step: 1
Training loss: 0.3023416001590915
Validation loss: 3.1006231671198266

Epoch: 6| Step: 2
Training loss: 0.2640219166284772
Validation loss: 3.1238749449818206

Epoch: 6| Step: 3
Training loss: 0.27289436075671536
Validation loss: 3.1062271695542085

Epoch: 6| Step: 4
Training loss: 0.29588718204053344
Validation loss: 3.1271683608729597

Epoch: 6| Step: 5
Training loss: 0.27446744949308943
Validation loss: 3.130757356164658

Epoch: 6| Step: 6
Training loss: 0.23741579790487527
Validation loss: 3.1051839062074293

Epoch: 6| Step: 7
Training loss: 0.2915683080947195
Validation loss: 3.1858811849169704

Epoch: 6| Step: 8
Training loss: 0.2512898104475819
Validation loss: 3.0966777242114754

Epoch: 6| Step: 9
Training loss: 0.24757061690227797
Validation loss: 3.1166822363384656

Epoch: 6| Step: 10
Training loss: 0.2881688661344292
Validation loss: 3.1135860151950756

Epoch: 6| Step: 11
Training loss: 0.4082776599351002
Validation loss: 3.106712850246498

Epoch: 6| Step: 12
Training loss: 0.3104387610954965
Validation loss: 3.1760610759805554

Epoch: 6| Step: 13
Training loss: 0.2470515323180858
Validation loss: 3.1358614296676226

Epoch: 431| Step: 0
Training loss: 0.28309650387210394
Validation loss: 3.1679894838230838

Epoch: 6| Step: 1
Training loss: 0.2867299251821224
Validation loss: 3.0746937327879595

Epoch: 6| Step: 2
Training loss: 0.26237238211413916
Validation loss: 3.171275766579003

Epoch: 6| Step: 3
Training loss: 0.3072232100103164
Validation loss: 3.1733588144604323

Epoch: 6| Step: 4
Training loss: 0.2665314075542409
Validation loss: 3.1506838929066885

Epoch: 6| Step: 5
Training loss: 0.3347167746156425
Validation loss: 3.1510510068812803

Epoch: 6| Step: 6
Training loss: 0.38108914609085515
Validation loss: 3.1978973156139547

Epoch: 6| Step: 7
Training loss: 0.3133155432978876
Validation loss: 3.177682067653168

Epoch: 6| Step: 8
Training loss: 0.29311176623990703
Validation loss: 3.116374853993993

Epoch: 6| Step: 9
Training loss: 0.2628555659911737
Validation loss: 3.181663842503883

Epoch: 6| Step: 10
Training loss: 0.21321417344129848
Validation loss: 3.1350965410382248

Epoch: 6| Step: 11
Training loss: 0.34114213630866713
Validation loss: 3.1316328483435183

Epoch: 6| Step: 12
Training loss: 0.2953453560368648
Validation loss: 3.1471352356908153

Epoch: 6| Step: 13
Training loss: 0.35935327215439244
Validation loss: 3.083743304412999

Epoch: 432| Step: 0
Training loss: 0.2401090465609688
Validation loss: 3.1034895053770284

Epoch: 6| Step: 1
Training loss: 0.19986554409488128
Validation loss: 3.1612253286520966

Epoch: 6| Step: 2
Training loss: 0.20547079005515909
Validation loss: 3.1447963057933723

Epoch: 6| Step: 3
Training loss: 0.330448304213451
Validation loss: 3.205445753017055

Epoch: 6| Step: 4
Training loss: 0.5100168654046723
Validation loss: 3.2226999854000407

Epoch: 6| Step: 5
Training loss: 0.37910574154562426
Validation loss: 3.1975382644157286

Epoch: 6| Step: 6
Training loss: 0.34079287618038523
Validation loss: 3.183155652192043

Epoch: 6| Step: 7
Training loss: 0.2825528011517995
Validation loss: 3.0815472498798364

Epoch: 6| Step: 8
Training loss: 0.34485362361571065
Validation loss: 3.0690188283026805

Epoch: 6| Step: 9
Training loss: 0.3102724074003584
Validation loss: 3.03200942289403

Epoch: 6| Step: 10
Training loss: 0.4726496609315228
Validation loss: 3.0896336692641824

Epoch: 6| Step: 11
Training loss: 0.4345093416454269
Validation loss: 3.0541161980997646

Epoch: 6| Step: 12
Training loss: 0.2422510340632128
Validation loss: 3.1111229946462045

Epoch: 6| Step: 13
Training loss: 0.3664434279916012
Validation loss: 3.138223530196847

Epoch: 433| Step: 0
Training loss: 0.27271992669453254
Validation loss: 3.2089134575314797

Epoch: 6| Step: 1
Training loss: 0.41749449589236276
Validation loss: 3.208796682381054

Epoch: 6| Step: 2
Training loss: 0.4548602257866369
Validation loss: 3.3008031599833725

Epoch: 6| Step: 3
Training loss: 0.44222804176845354
Validation loss: 3.187787211325044

Epoch: 6| Step: 4
Training loss: 0.30184300772432204
Validation loss: 3.1633186627668524

Epoch: 6| Step: 5
Training loss: 0.38537245788997854
Validation loss: 3.114892521101575

Epoch: 6| Step: 6
Training loss: 0.2285149077053713
Validation loss: 3.0641104298081294

Epoch: 6| Step: 7
Training loss: 0.30415133226401686
Validation loss: 3.0411950011323032

Epoch: 6| Step: 8
Training loss: 0.3800541116434601
Validation loss: 3.063356539258205

Epoch: 6| Step: 9
Training loss: 0.33650817747935213
Validation loss: 3.052237631550553

Epoch: 6| Step: 10
Training loss: 0.3744965790196362
Validation loss: 3.0546307570706865

Epoch: 6| Step: 11
Training loss: 0.36485166438991995
Validation loss: 3.07606469669025

Epoch: 6| Step: 12
Training loss: 0.20114479067799051
Validation loss: 3.0650198165103593

Epoch: 6| Step: 13
Training loss: 0.30076952081575226
Validation loss: 3.1260468827513095

Epoch: 434| Step: 0
Training loss: 0.30135842469406193
Validation loss: 3.157004250525279

Epoch: 6| Step: 1
Training loss: 0.3273186425934154
Validation loss: 3.1336682451780695

Epoch: 6| Step: 2
Training loss: 0.2629923647716861
Validation loss: 3.1446758102770365

Epoch: 6| Step: 3
Training loss: 0.21452840723986788
Validation loss: 3.0684713808204145

Epoch: 6| Step: 4
Training loss: 0.26524599468414234
Validation loss: 3.131382477090492

Epoch: 6| Step: 5
Training loss: 0.3643488016083442
Validation loss: 3.110038635385989

Epoch: 6| Step: 6
Training loss: 0.24815738649183705
Validation loss: 3.1516909137992055

Epoch: 6| Step: 7
Training loss: 0.25184117276995616
Validation loss: 3.163962958383088

Epoch: 6| Step: 8
Training loss: 0.25391038744563177
Validation loss: 3.160549219545733

Epoch: 6| Step: 9
Training loss: 0.2937374584077354
Validation loss: 3.1492874853439847

Epoch: 6| Step: 10
Training loss: 0.26351737688230364
Validation loss: 3.1843987131780067

Epoch: 6| Step: 11
Training loss: 0.25411126589591987
Validation loss: 3.104738660677866

Epoch: 6| Step: 12
Training loss: 0.38242016364270903
Validation loss: 3.131989292426094

Epoch: 6| Step: 13
Training loss: 0.24356468167941817
Validation loss: 3.1504729627336934

Epoch: 435| Step: 0
Training loss: 0.37539052496838304
Validation loss: 3.1258535491023878

Epoch: 6| Step: 1
Training loss: 0.2460556909104966
Validation loss: 3.097879832257643

Epoch: 6| Step: 2
Training loss: 0.3418451656560183
Validation loss: 3.1392147763377283

Epoch: 6| Step: 3
Training loss: 0.28358330037435076
Validation loss: 3.0713226882557443

Epoch: 6| Step: 4
Training loss: 0.2694120973015087
Validation loss: 3.1205551198312698

Epoch: 6| Step: 5
Training loss: 0.3871345404058145
Validation loss: 3.124089617046595

Epoch: 6| Step: 6
Training loss: 0.297762723087179
Validation loss: 3.1227288194536187

Epoch: 6| Step: 7
Training loss: 0.28418789356876434
Validation loss: 3.1814548788692454

Epoch: 6| Step: 8
Training loss: 0.32983373589721626
Validation loss: 3.127975090365078

Epoch: 6| Step: 9
Training loss: 0.2932283014699166
Validation loss: 3.1469852073385605

Epoch: 6| Step: 10
Training loss: 0.28063494930174376
Validation loss: 3.123922009504409

Epoch: 6| Step: 11
Training loss: 0.19861114631350932
Validation loss: 3.0807404871281445

Epoch: 6| Step: 12
Training loss: 0.30071758240464475
Validation loss: 3.159431729686232

Epoch: 6| Step: 13
Training loss: 0.3214595539434914
Validation loss: 3.0770688641379507

Epoch: 436| Step: 0
Training loss: 0.3464323424069445
Validation loss: 3.095988045305472

Epoch: 6| Step: 1
Training loss: 0.2179248095559805
Validation loss: 3.098687326244493

Epoch: 6| Step: 2
Training loss: 0.327059355037067
Validation loss: 3.1302245272420106

Epoch: 6| Step: 3
Training loss: 0.23515247297580474
Validation loss: 3.158362081660243

Epoch: 6| Step: 4
Training loss: 0.4151942423017941
Validation loss: 3.1260362305806293

Epoch: 6| Step: 5
Training loss: 0.269784725252107
Validation loss: 3.1510465679708566

Epoch: 6| Step: 6
Training loss: 0.316000548805895
Validation loss: 3.1414211396486897

Epoch: 6| Step: 7
Training loss: 0.2449852029555411
Validation loss: 3.18238807111812

Epoch: 6| Step: 8
Training loss: 0.3079126059703608
Validation loss: 3.1177563447035057

Epoch: 6| Step: 9
Training loss: 0.23657371433944321
Validation loss: 3.1733419411773567

Epoch: 6| Step: 10
Training loss: 0.30533057597600544
Validation loss: 3.1019298294307758

Epoch: 6| Step: 11
Training loss: 0.26829999463866544
Validation loss: 3.178754627495929

Epoch: 6| Step: 12
Training loss: 0.27734983464403384
Validation loss: 3.15178799368615

Epoch: 6| Step: 13
Training loss: 0.36318984984066216
Validation loss: 3.225990103010939

Epoch: 437| Step: 0
Training loss: 0.33155203625691276
Validation loss: 3.1396005582347484

Epoch: 6| Step: 1
Training loss: 0.2390193295612864
Validation loss: 3.141374925496598

Epoch: 6| Step: 2
Training loss: 0.2862297909278614
Validation loss: 3.122945186254882

Epoch: 6| Step: 3
Training loss: 0.20263071625792992
Validation loss: 3.145351554071007

Epoch: 6| Step: 4
Training loss: 0.28725414129713134
Validation loss: 3.1262761879827856

Epoch: 6| Step: 5
Training loss: 0.25990615714648174
Validation loss: 3.1271927579117182

Epoch: 6| Step: 6
Training loss: 0.2457058741138263
Validation loss: 3.141764192222655

Epoch: 6| Step: 7
Training loss: 0.22116042334885438
Validation loss: 3.112482508517017

Epoch: 6| Step: 8
Training loss: 0.29527448581065874
Validation loss: 3.1265728997510815

Epoch: 6| Step: 9
Training loss: 0.30459812271691217
Validation loss: 3.174230205400361

Epoch: 6| Step: 10
Training loss: 0.3278451702722393
Validation loss: 3.133150318732629

Epoch: 6| Step: 11
Training loss: 0.1922022267258523
Validation loss: 3.1733198335972177

Epoch: 6| Step: 12
Training loss: 0.22301100193562026
Validation loss: 3.097452536222632

Epoch: 6| Step: 13
Training loss: 0.20884632292467886
Validation loss: 3.1716465108220655

Epoch: 438| Step: 0
Training loss: 0.18315209367322388
Validation loss: 3.140740868501274

Epoch: 6| Step: 1
Training loss: 0.3121794248420544
Validation loss: 3.107435353088241

Epoch: 6| Step: 2
Training loss: 0.23845878616050942
Validation loss: 3.1831834649629553

Epoch: 6| Step: 3
Training loss: 0.2813004607391788
Validation loss: 3.112008620033649

Epoch: 6| Step: 4
Training loss: 0.24290806727022196
Validation loss: 3.118215839048905

Epoch: 6| Step: 5
Training loss: 0.2056671946577789
Validation loss: 3.166449957676997

Epoch: 6| Step: 6
Training loss: 0.37013204338434574
Validation loss: 3.1375305278149055

Epoch: 6| Step: 7
Training loss: 0.31390790882878034
Validation loss: 3.1595027768198882

Epoch: 6| Step: 8
Training loss: 0.3508456551233452
Validation loss: 3.183282193343992

Epoch: 6| Step: 9
Training loss: 0.27713487039469303
Validation loss: 3.174933851859607

Epoch: 6| Step: 10
Training loss: 0.2307452305324616
Validation loss: 3.174790168696936

Epoch: 6| Step: 11
Training loss: 0.19344345345525704
Validation loss: 3.141051761612409

Epoch: 6| Step: 12
Training loss: 0.19836698090078025
Validation loss: 3.1069370853081315

Epoch: 6| Step: 13
Training loss: 0.2966222565584756
Validation loss: 3.155168026834288

Epoch: 439| Step: 0
Training loss: 0.2847111245579625
Validation loss: 3.1362100571133413

Epoch: 6| Step: 1
Training loss: 0.35786718758527625
Validation loss: 3.1018266157027274

Epoch: 6| Step: 2
Training loss: 0.2934163552527891
Validation loss: 3.2125360449761486

Epoch: 6| Step: 3
Training loss: 0.24587377677558903
Validation loss: 3.177202132875368

Epoch: 6| Step: 4
Training loss: 0.20000329461960367
Validation loss: 3.214635843048774

Epoch: 6| Step: 5
Training loss: 0.23055704494474635
Validation loss: 3.1876833993845617

Epoch: 6| Step: 6
Training loss: 0.2900809826082145
Validation loss: 3.206782118753849

Epoch: 6| Step: 7
Training loss: 0.3270613141555035
Validation loss: 3.1485210372910974

Epoch: 6| Step: 8
Training loss: 0.27343717302575316
Validation loss: 3.1863176733577205

Epoch: 6| Step: 9
Training loss: 0.2939996384006988
Validation loss: 3.159042885288279

Epoch: 6| Step: 10
Training loss: 0.33299523830446015
Validation loss: 3.2112916007093752

Epoch: 6| Step: 11
Training loss: 0.24157972368175604
Validation loss: 3.1857452299638185

Epoch: 6| Step: 12
Training loss: 0.3367764952282281
Validation loss: 3.2019564722395875

Epoch: 6| Step: 13
Training loss: 0.20105469633450368
Validation loss: 3.1966107256439407

Epoch: 440| Step: 0
Training loss: 0.46888896153938087
Validation loss: 3.155720379902116

Epoch: 6| Step: 1
Training loss: 0.21562698819446302
Validation loss: 3.2516620738669815

Epoch: 6| Step: 2
Training loss: 0.34212082905747837
Validation loss: 3.126901226260313

Epoch: 6| Step: 3
Training loss: 0.3034703813803034
Validation loss: 3.089707761811073

Epoch: 6| Step: 4
Training loss: 0.2545060775374042
Validation loss: 3.136791350338831

Epoch: 6| Step: 5
Training loss: 0.35984882962363973
Validation loss: 3.121944383188139

Epoch: 6| Step: 6
Training loss: 0.3777687065042062
Validation loss: 3.1393493794681704

Epoch: 6| Step: 7
Training loss: 0.31465540475075443
Validation loss: 3.1135860534818898

Epoch: 6| Step: 8
Training loss: 0.23259191944345525
Validation loss: 3.1693464451434243

Epoch: 6| Step: 9
Training loss: 0.26590668944702345
Validation loss: 3.1423938887673963

Epoch: 6| Step: 10
Training loss: 0.30235328067868855
Validation loss: 3.1624654184996355

Epoch: 6| Step: 11
Training loss: 0.29802696191503386
Validation loss: 3.1656713343622003

Epoch: 6| Step: 12
Training loss: 0.3020317537843279
Validation loss: 3.1724988076538696

Epoch: 6| Step: 13
Training loss: 0.18073726923549438
Validation loss: 3.201503448661612

Epoch: 441| Step: 0
Training loss: 0.33022366086041555
Validation loss: 3.1427078425771913

Epoch: 6| Step: 1
Training loss: 0.1788903570820387
Validation loss: 3.150678356233184

Epoch: 6| Step: 2
Training loss: 0.2696663338321601
Validation loss: 3.0681826813586355

Epoch: 6| Step: 3
Training loss: 0.3497607367001215
Validation loss: 3.070323099598533

Epoch: 6| Step: 4
Training loss: 0.1889182336380763
Validation loss: 3.1451711947288046

Epoch: 6| Step: 5
Training loss: 0.22107539387180072
Validation loss: 3.122001913683881

Epoch: 6| Step: 6
Training loss: 0.268157582159571
Validation loss: 3.134201471222882

Epoch: 6| Step: 7
Training loss: 0.17973716712844962
Validation loss: 3.1426084970192383

Epoch: 6| Step: 8
Training loss: 0.32112722756016726
Validation loss: 3.1302715597680435

Epoch: 6| Step: 9
Training loss: 0.21987972431518285
Validation loss: 3.148081390965402

Epoch: 6| Step: 10
Training loss: 0.2820894376797663
Validation loss: 3.1705351632107477

Epoch: 6| Step: 11
Training loss: 0.3380643364998712
Validation loss: 3.1771564829592323

Epoch: 6| Step: 12
Training loss: 0.28174128274624505
Validation loss: 3.150366193184318

Epoch: 6| Step: 13
Training loss: 0.3229931105094491
Validation loss: 3.1242049159444587

Epoch: 442| Step: 0
Training loss: 0.30383908919750063
Validation loss: 3.081267513253747

Epoch: 6| Step: 1
Training loss: 0.326797775679516
Validation loss: 3.0906670490691988

Epoch: 6| Step: 2
Training loss: 0.31333212926858167
Validation loss: 3.1008306644007546

Epoch: 6| Step: 3
Training loss: 0.2656820740810894
Validation loss: 3.154139237849422

Epoch: 6| Step: 4
Training loss: 0.2438870600959721
Validation loss: 3.138600293023511

Epoch: 6| Step: 5
Training loss: 0.38040016073049043
Validation loss: 3.161130713256981

Epoch: 6| Step: 6
Training loss: 0.308926873336302
Validation loss: 3.12910860814577

Epoch: 6| Step: 7
Training loss: 0.31323527619510105
Validation loss: 3.1756846533266923

Epoch: 6| Step: 8
Training loss: 0.2502005934623233
Validation loss: 3.1893080277151333

Epoch: 6| Step: 9
Training loss: 0.24853218091821314
Validation loss: 3.177016877693586

Epoch: 6| Step: 10
Training loss: 0.22395970469801604
Validation loss: 3.1153041341498815

Epoch: 6| Step: 11
Training loss: 0.2159904999978365
Validation loss: 3.1215453825725166

Epoch: 6| Step: 12
Training loss: 0.23308946596917227
Validation loss: 3.1563478838658092

Epoch: 6| Step: 13
Training loss: 0.2673176520945692
Validation loss: 3.128302494873272

Epoch: 443| Step: 0
Training loss: 0.38688813940608363
Validation loss: 3.1307886297713265

Epoch: 6| Step: 1
Training loss: 0.23673879393770766
Validation loss: 3.101962085418384

Epoch: 6| Step: 2
Training loss: 0.3536738889724086
Validation loss: 3.133448636862125

Epoch: 6| Step: 3
Training loss: 0.25294552020739436
Validation loss: 3.2073048557374975

Epoch: 6| Step: 4
Training loss: 0.26826383619719135
Validation loss: 3.1713068912161027

Epoch: 6| Step: 5
Training loss: 0.26404806075035026
Validation loss: 3.2204361236796557

Epoch: 6| Step: 6
Training loss: 0.2274429789677546
Validation loss: 3.1246848265340814

Epoch: 6| Step: 7
Training loss: 0.2427040406012574
Validation loss: 3.2181610259899744

Epoch: 6| Step: 8
Training loss: 0.29334857478877335
Validation loss: 3.206411359864801

Epoch: 6| Step: 9
Training loss: 0.3058126776893734
Validation loss: 3.203222716787089

Epoch: 6| Step: 10
Training loss: 0.23148399544825418
Validation loss: 3.178266778044708

Epoch: 6| Step: 11
Training loss: 0.29033341546984526
Validation loss: 3.2486003649583117

Epoch: 6| Step: 12
Training loss: 0.45662596249106924
Validation loss: 3.2002301043987216

Epoch: 6| Step: 13
Training loss: 0.3280628690479519
Validation loss: 3.1856645772470147

Epoch: 444| Step: 0
Training loss: 0.23479552689475824
Validation loss: 3.168831704194282

Epoch: 6| Step: 1
Training loss: 0.4156585378667774
Validation loss: 3.175127826330238

Epoch: 6| Step: 2
Training loss: 0.2609369928960384
Validation loss: 3.134710002021443

Epoch: 6| Step: 3
Training loss: 0.2693012610804002
Validation loss: 3.111932542949098

Epoch: 6| Step: 4
Training loss: 0.259745274370437
Validation loss: 3.0980671004450935

Epoch: 6| Step: 5
Training loss: 0.2606570072554101
Validation loss: 3.1372309069089854

Epoch: 6| Step: 6
Training loss: 0.14581441898530262
Validation loss: 3.1363905010069653

Epoch: 6| Step: 7
Training loss: 0.2727167302906287
Validation loss: 3.1436405160292407

Epoch: 6| Step: 8
Training loss: 0.24030830052232227
Validation loss: 3.093470152968298

Epoch: 6| Step: 9
Training loss: 0.38756751349112684
Validation loss: 3.131234917315657

Epoch: 6| Step: 10
Training loss: 0.3705613181612802
Validation loss: 3.108101486545656

Epoch: 6| Step: 11
Training loss: 0.32343000965382945
Validation loss: 3.140420454712248

Epoch: 6| Step: 12
Training loss: 0.2957612024718525
Validation loss: 3.069245933760989

Epoch: 6| Step: 13
Training loss: 0.2559150169381079
Validation loss: 3.0525677571026124

Epoch: 445| Step: 0
Training loss: 0.2286685529701497
Validation loss: 3.102974481379977

Epoch: 6| Step: 1
Training loss: 0.31317230860876116
Validation loss: 3.0957632225452714

Epoch: 6| Step: 2
Training loss: 0.25569269706239056
Validation loss: 3.110098047070406

Epoch: 6| Step: 3
Training loss: 0.4078907843974704
Validation loss: 3.0842264960964902

Epoch: 6| Step: 4
Training loss: 0.2939894760261036
Validation loss: 3.1166394484108335

Epoch: 6| Step: 5
Training loss: 0.22644848256559774
Validation loss: 3.076298360494834

Epoch: 6| Step: 6
Training loss: 0.4120062025469016
Validation loss: 3.1713552691217117

Epoch: 6| Step: 7
Training loss: 0.2793463816481993
Validation loss: 3.184362363181904

Epoch: 6| Step: 8
Training loss: 0.2867619884640549
Validation loss: 3.179950237744524

Epoch: 6| Step: 9
Training loss: 0.3120604762037111
Validation loss: 3.1482536571457915

Epoch: 6| Step: 10
Training loss: 0.29663565674972225
Validation loss: 3.1933186473057447

Epoch: 6| Step: 11
Training loss: 0.2504778408083239
Validation loss: 3.1131579647119927

Epoch: 6| Step: 12
Training loss: 0.29268726813832363
Validation loss: 3.133783965137838

Epoch: 6| Step: 13
Training loss: 0.28104505754399484
Validation loss: 3.117703770307997

Epoch: 446| Step: 0
Training loss: 0.20956626881078325
Validation loss: 3.1184343666279832

Epoch: 6| Step: 1
Training loss: 0.34405705436395345
Validation loss: 3.12322346098819

Epoch: 6| Step: 2
Training loss: 0.37924676518956085
Validation loss: 3.1437940155851165

Epoch: 6| Step: 3
Training loss: 0.2627352007110806
Validation loss: 3.1094053129574806

Epoch: 6| Step: 4
Training loss: 0.27469518793954434
Validation loss: 3.153207640861368

Epoch: 6| Step: 5
Training loss: 0.4012508177229015
Validation loss: 3.123227087009855

Epoch: 6| Step: 6
Training loss: 0.24353181078432753
Validation loss: 3.0982182535308644

Epoch: 6| Step: 7
Training loss: 0.22933312443102935
Validation loss: 3.130941490259384

Epoch: 6| Step: 8
Training loss: 0.2452182941201616
Validation loss: 3.0948272396591023

Epoch: 6| Step: 9
Training loss: 0.24927162069989925
Validation loss: 3.080814793553045

Epoch: 6| Step: 10
Training loss: 0.2961950043441815
Validation loss: 3.1247791212223306

Epoch: 6| Step: 11
Training loss: 0.23057699086292346
Validation loss: 3.0907137450156297

Epoch: 6| Step: 12
Training loss: 0.2870613369360646
Validation loss: 3.1157659924080976

Epoch: 6| Step: 13
Training loss: 0.2208689851292693
Validation loss: 3.1449599327280406

Epoch: 447| Step: 0
Training loss: 0.2900881870167452
Validation loss: 3.158593456624637

Epoch: 6| Step: 1
Training loss: 0.2510387180413737
Validation loss: 3.1453691017906027

Epoch: 6| Step: 2
Training loss: 0.38927284820350955
Validation loss: 3.1722865722425615

Epoch: 6| Step: 3
Training loss: 0.28834661554235846
Validation loss: 3.1654027792434447

Epoch: 6| Step: 4
Training loss: 0.22611218951310091
Validation loss: 3.125366901475652

Epoch: 6| Step: 5
Training loss: 0.38160251595054595
Validation loss: 3.137622289820022

Epoch: 6| Step: 6
Training loss: 0.25775956564116775
Validation loss: 3.097181260522808

Epoch: 6| Step: 7
Training loss: 0.27083296806359725
Validation loss: 3.1252886066681076

Epoch: 6| Step: 8
Training loss: 0.2895249842559162
Validation loss: 3.1060838262165116

Epoch: 6| Step: 9
Training loss: 0.1869206816997032
Validation loss: 3.158673272085979

Epoch: 6| Step: 10
Training loss: 0.24333898541557614
Validation loss: 3.107166432435829

Epoch: 6| Step: 11
Training loss: 0.23490264626129304
Validation loss: 3.2348169832575233

Epoch: 6| Step: 12
Training loss: 0.18137591567554331
Validation loss: 3.2133246935402466

Epoch: 6| Step: 13
Training loss: 0.2705342662009045
Validation loss: 3.1406556819093963

Epoch: 448| Step: 0
Training loss: 0.2275139790736042
Validation loss: 3.181013550930267

Epoch: 6| Step: 1
Training loss: 0.3372783294964112
Validation loss: 3.1536766867646957

Epoch: 6| Step: 2
Training loss: 0.22041306804310548
Validation loss: 3.1772736455898087

Epoch: 6| Step: 3
Training loss: 0.270682048114702
Validation loss: 3.125137656676761

Epoch: 6| Step: 4
Training loss: 0.4216622769965363
Validation loss: 3.135158976022863

Epoch: 6| Step: 5
Training loss: 0.3055109609527736
Validation loss: 3.137383149543354

Epoch: 6| Step: 6
Training loss: 0.29567902994693823
Validation loss: 3.127455293583368

Epoch: 6| Step: 7
Training loss: 0.2884763755100396
Validation loss: 3.1212156651525307

Epoch: 6| Step: 8
Training loss: 0.27373700768631914
Validation loss: 3.1258309848918615

Epoch: 6| Step: 9
Training loss: 0.20907213917279885
Validation loss: 3.12757680829629

Epoch: 6| Step: 10
Training loss: 0.18183832791864304
Validation loss: 3.147597069024962

Epoch: 6| Step: 11
Training loss: 0.2720226741799673
Validation loss: 3.1700263814099148

Epoch: 6| Step: 12
Training loss: 0.2512804855526712
Validation loss: 3.1902185204179956

Epoch: 6| Step: 13
Training loss: 0.3115936128506805
Validation loss: 3.229964610950144

Epoch: 449| Step: 0
Training loss: 0.33395676749717657
Validation loss: 3.2084470869102977

Epoch: 6| Step: 1
Training loss: 0.2872953137204774
Validation loss: 3.2237834893279724

Epoch: 6| Step: 2
Training loss: 0.3348188627235553
Validation loss: 3.115538081847816

Epoch: 6| Step: 3
Training loss: 0.35176508682583263
Validation loss: 3.1363964556558823

Epoch: 6| Step: 4
Training loss: 0.4538636927917872
Validation loss: 3.1057837496450924

Epoch: 6| Step: 5
Training loss: 0.31658899657665035
Validation loss: 3.0815422337361467

Epoch: 6| Step: 6
Training loss: 0.32929940318882667
Validation loss: 3.1153763024218324

Epoch: 6| Step: 7
Training loss: 0.25450893180140377
Validation loss: 3.158627360672491

Epoch: 6| Step: 8
Training loss: 0.21886081953859485
Validation loss: 3.197797733708825

Epoch: 6| Step: 9
Training loss: 0.3374160896294608
Validation loss: 3.189709277981391

Epoch: 6| Step: 10
Training loss: 0.20509059504788466
Validation loss: 3.2419075350933393

Epoch: 6| Step: 11
Training loss: 0.22393927751836998
Validation loss: 3.2669224937328676

Epoch: 6| Step: 12
Training loss: 0.29857904363055
Validation loss: 3.218118945237262

Epoch: 6| Step: 13
Training loss: 0.3390142687759738
Validation loss: 3.1061001629576666

Epoch: 450| Step: 0
Training loss: 0.2203821701110221
Validation loss: 3.2145201658090157

Epoch: 6| Step: 1
Training loss: 0.28914839525148517
Validation loss: 3.1438042915970024

Epoch: 6| Step: 2
Training loss: 0.2370347736778195
Validation loss: 3.1656000114376006

Epoch: 6| Step: 3
Training loss: 0.2636906369916238
Validation loss: 3.1166927547348955

Epoch: 6| Step: 4
Training loss: 0.220122848884734
Validation loss: 3.192229981341258

Epoch: 6| Step: 5
Training loss: 0.32924019811112637
Validation loss: 3.1530854125951424

Epoch: 6| Step: 6
Training loss: 0.44833068971256296
Validation loss: 3.142885624975308

Epoch: 6| Step: 7
Training loss: 0.26530330475777364
Validation loss: 3.1930346091465913

Epoch: 6| Step: 8
Training loss: 0.24310447544947103
Validation loss: 3.1834793163866055

Epoch: 6| Step: 9
Training loss: 0.241756678985537
Validation loss: 3.1984246354806434

Epoch: 6| Step: 10
Training loss: 0.20886610374362144
Validation loss: 3.133903750956723

Epoch: 6| Step: 11
Training loss: 0.2495191688694417
Validation loss: 3.17909001415899

Epoch: 6| Step: 12
Training loss: 0.32717165508724705
Validation loss: 3.229115065295666

Epoch: 6| Step: 13
Training loss: 0.28641834268883315
Validation loss: 3.183798816527819

Epoch: 451| Step: 0
Training loss: 0.3258085454396754
Validation loss: 3.12805269547115

Epoch: 6| Step: 1
Training loss: 0.24834954576220367
Validation loss: 3.1192849224793844

Epoch: 6| Step: 2
Training loss: 0.2559158757847729
Validation loss: 3.1014812468448087

Epoch: 6| Step: 3
Training loss: 0.37492779195495973
Validation loss: 3.0836236834210826

Epoch: 6| Step: 4
Training loss: 0.4966086021373877
Validation loss: 3.065882495120634

Epoch: 6| Step: 5
Training loss: 0.3150191691598343
Validation loss: 3.1184256380516078

Epoch: 6| Step: 6
Training loss: 0.25623339331710016
Validation loss: 3.1850079162954406

Epoch: 6| Step: 7
Training loss: 0.30220530639937243
Validation loss: 3.1766498499248716

Epoch: 6| Step: 8
Training loss: 0.38609081883168844
Validation loss: 3.1572998994883337

Epoch: 6| Step: 9
Training loss: 0.45849965249529934
Validation loss: 3.185778770215684

Epoch: 6| Step: 10
Training loss: 0.24398558462125866
Validation loss: 3.12130327917907

Epoch: 6| Step: 11
Training loss: 0.24763642541618433
Validation loss: 3.095959308024175

Epoch: 6| Step: 12
Training loss: 0.3150089635027822
Validation loss: 3.129484506576322

Epoch: 6| Step: 13
Training loss: 0.4731256030442944
Validation loss: 3.046946415512541

Epoch: 452| Step: 0
Training loss: 0.28442702393926145
Validation loss: 3.0738733817426644

Epoch: 6| Step: 1
Training loss: 0.22736381363574948
Validation loss: 3.171544876833984

Epoch: 6| Step: 2
Training loss: 0.25569546523423686
Validation loss: 3.1479469213708593

Epoch: 6| Step: 3
Training loss: 0.19737577667772047
Validation loss: 3.2072310391269343

Epoch: 6| Step: 4
Training loss: 0.3458688845036944
Validation loss: 3.2430327634988445

Epoch: 6| Step: 5
Training loss: 0.2368674862231065
Validation loss: 3.232466855077119

Epoch: 6| Step: 6
Training loss: 0.38125925834545604
Validation loss: 3.196608177328845

Epoch: 6| Step: 7
Training loss: 0.3000915596240594
Validation loss: 3.130733164597157

Epoch: 6| Step: 8
Training loss: 0.20092070742216772
Validation loss: 3.0514134962011594

Epoch: 6| Step: 9
Training loss: 0.2731031007956656
Validation loss: 3.084375660647264

Epoch: 6| Step: 10
Training loss: 0.3211490128753947
Validation loss: 3.1291234214493366

Epoch: 6| Step: 11
Training loss: 0.3264551588625116
Validation loss: 3.099361340045924

Epoch: 6| Step: 12
Training loss: 0.31436424894890336
Validation loss: 3.1722890398864703

Epoch: 6| Step: 13
Training loss: 0.230934295180387
Validation loss: 3.1591022810181375

Epoch: 453| Step: 0
Training loss: 0.168875542053917
Validation loss: 3.1751208930641215

Epoch: 6| Step: 1
Training loss: 0.3366679522793525
Validation loss: 3.1316021287882023

Epoch: 6| Step: 2
Training loss: 0.2695156037585334
Validation loss: 3.159711104619143

Epoch: 6| Step: 3
Training loss: 0.2793425142572614
Validation loss: 3.178558461584805

Epoch: 6| Step: 4
Training loss: 0.2550601123332573
Validation loss: 3.1531263449104903

Epoch: 6| Step: 5
Training loss: 0.1609964660840147
Validation loss: 3.1250814045793756

Epoch: 6| Step: 6
Training loss: 0.3724340028030484
Validation loss: 3.174556106415245

Epoch: 6| Step: 7
Training loss: 0.3004252568831976
Validation loss: 3.1904505057697317

Epoch: 6| Step: 8
Training loss: 0.4083771038275625
Validation loss: 3.187022865337869

Epoch: 6| Step: 9
Training loss: 0.30190463645258275
Validation loss: 3.1669453991807646

Epoch: 6| Step: 10
Training loss: 0.25018406588836983
Validation loss: 3.137813290054946

Epoch: 6| Step: 11
Training loss: 0.21298429195930518
Validation loss: 3.1609723106651066

Epoch: 6| Step: 12
Training loss: 0.2549301921903433
Validation loss: 3.1618417866587327

Epoch: 6| Step: 13
Training loss: 0.2722054928198767
Validation loss: 3.1467018865241467

Epoch: 454| Step: 0
Training loss: 0.30184814187533676
Validation loss: 3.1037821734273243

Epoch: 6| Step: 1
Training loss: 0.1913547446571499
Validation loss: 3.0895620700741557

Epoch: 6| Step: 2
Training loss: 0.2703032012398478
Validation loss: 3.119239737079191

Epoch: 6| Step: 3
Training loss: 0.3912031282434906
Validation loss: 3.084592025320677

Epoch: 6| Step: 4
Training loss: 0.26227499082930905
Validation loss: 3.1299269936429295

Epoch: 6| Step: 5
Training loss: 0.2168438491106391
Validation loss: 3.085376324712932

Epoch: 6| Step: 6
Training loss: 0.3053700309517777
Validation loss: 3.1163188007511096

Epoch: 6| Step: 7
Training loss: 0.17495948714251108
Validation loss: 3.1488789453235806

Epoch: 6| Step: 8
Training loss: 0.2936892106687704
Validation loss: 3.1124409331675302

Epoch: 6| Step: 9
Training loss: 0.30646312946289633
Validation loss: 3.1689858644121456

Epoch: 6| Step: 10
Training loss: 0.23603992386320716
Validation loss: 3.1256769464340097

Epoch: 6| Step: 11
Training loss: 0.43519251139860465
Validation loss: 3.04951633829232

Epoch: 6| Step: 12
Training loss: 0.3118660934720705
Validation loss: 3.0881614172226213

Epoch: 6| Step: 13
Training loss: 0.2986617279524283
Validation loss: 3.0610717894568458

Epoch: 455| Step: 0
Training loss: 0.2511049825248439
Validation loss: 3.0575270467390028

Epoch: 6| Step: 1
Training loss: 0.3401130836723793
Validation loss: 3.1299122158817774

Epoch: 6| Step: 2
Training loss: 0.27004051471873186
Validation loss: 3.1383219509826605

Epoch: 6| Step: 3
Training loss: 0.39913406444331484
Validation loss: 3.140230422909774

Epoch: 6| Step: 4
Training loss: 0.28038684530997626
Validation loss: 3.0989100134579264

Epoch: 6| Step: 5
Training loss: 0.14515545444455297
Validation loss: 3.126590349517227

Epoch: 6| Step: 6
Training loss: 0.2322172498319586
Validation loss: 3.0668536011761898

Epoch: 6| Step: 7
Training loss: 0.21906725833421217
Validation loss: 3.109173562123929

Epoch: 6| Step: 8
Training loss: 0.2635313719345782
Validation loss: 3.081575296291141

Epoch: 6| Step: 9
Training loss: 0.2273634695565655
Validation loss: 3.1093000597844713

Epoch: 6| Step: 10
Training loss: 0.2966612246948266
Validation loss: 3.0978922230915513

Epoch: 6| Step: 11
Training loss: 0.22205558701192657
Validation loss: 3.1244142746369366

Epoch: 6| Step: 12
Training loss: 0.36755859615002207
Validation loss: 3.191615495860864

Epoch: 6| Step: 13
Training loss: 0.23592240209461846
Validation loss: 3.1382353945411263

Epoch: 456| Step: 0
Training loss: 0.19859448028358148
Validation loss: 3.1289244360361526

Epoch: 6| Step: 1
Training loss: 0.41606612637741525
Validation loss: 3.1514355920303267

Epoch: 6| Step: 2
Training loss: 0.2720542798928889
Validation loss: 3.1919842262420093

Epoch: 6| Step: 3
Training loss: 0.22905335370339688
Validation loss: 3.1535969905499246

Epoch: 6| Step: 4
Training loss: 0.18719710282418117
Validation loss: 3.139006949110908

Epoch: 6| Step: 5
Training loss: 0.2394615940382319
Validation loss: 3.1330095516139997

Epoch: 6| Step: 6
Training loss: 0.3317566353091949
Validation loss: 3.1640723083092896

Epoch: 6| Step: 7
Training loss: 0.24679636185687204
Validation loss: 3.133442740018293

Epoch: 6| Step: 8
Training loss: 0.2839157609285986
Validation loss: 3.1104202941614467

Epoch: 6| Step: 9
Training loss: 0.22080798738405027
Validation loss: 3.164014563177732

Epoch: 6| Step: 10
Training loss: 0.29014172005620065
Validation loss: 3.160726916165038

Epoch: 6| Step: 11
Training loss: 0.3460379665359898
Validation loss: 3.167876430785956

Epoch: 6| Step: 12
Training loss: 0.2871495173411537
Validation loss: 3.1442162018274487

Epoch: 6| Step: 13
Training loss: 0.1793789391134964
Validation loss: 3.1212701154841587

Epoch: 457| Step: 0
Training loss: 0.3745751358312042
Validation loss: 3.093997778426698

Epoch: 6| Step: 1
Training loss: 0.27976020315584255
Validation loss: 3.083792476147612

Epoch: 6| Step: 2
Training loss: 0.404967705180771
Validation loss: 3.1034403768435253

Epoch: 6| Step: 3
Training loss: 0.28205112429518
Validation loss: 3.089253944403716

Epoch: 6| Step: 4
Training loss: 0.28213849393055945
Validation loss: 3.1344475161885095

Epoch: 6| Step: 5
Training loss: 0.3098873957385559
Validation loss: 3.184204479839275

Epoch: 6| Step: 6
Training loss: 0.25746601114206497
Validation loss: 3.1194737590304262

Epoch: 6| Step: 7
Training loss: 0.35604214795286365
Validation loss: 3.133749817669537

Epoch: 6| Step: 8
Training loss: 0.2952868748198861
Validation loss: 3.167723696787561

Epoch: 6| Step: 9
Training loss: 0.3589778862201751
Validation loss: 3.1460044426940215

Epoch: 6| Step: 10
Training loss: 0.2228875381090171
Validation loss: 3.100843062665343

Epoch: 6| Step: 11
Training loss: 0.3293569688729467
Validation loss: 3.085986817042306

Epoch: 6| Step: 12
Training loss: 0.2809302313588864
Validation loss: 3.045329636143424

Epoch: 6| Step: 13
Training loss: 0.3936534028925046
Validation loss: 3.086992751344195

Epoch: 458| Step: 0
Training loss: 0.4324689658557445
Validation loss: 3.0899003992622553

Epoch: 6| Step: 1
Training loss: 0.30233731226018434
Validation loss: 3.147431483433229

Epoch: 6| Step: 2
Training loss: 0.29007158193444305
Validation loss: 3.1943935450124608

Epoch: 6| Step: 3
Training loss: 0.3580319144152982
Validation loss: 3.161480073471776

Epoch: 6| Step: 4
Training loss: 0.3035596366403275
Validation loss: 3.195024273719971

Epoch: 6| Step: 5
Training loss: 0.26779093946025095
Validation loss: 3.2171834571717874

Epoch: 6| Step: 6
Training loss: 0.3616908546715376
Validation loss: 3.175259943456038

Epoch: 6| Step: 7
Training loss: 0.2301365025394748
Validation loss: 3.127964190688697

Epoch: 6| Step: 8
Training loss: 0.1820903154248605
Validation loss: 3.1111413484950754

Epoch: 6| Step: 9
Training loss: 0.4403481080146376
Validation loss: 3.0389348046574503

Epoch: 6| Step: 10
Training loss: 0.3129498819728543
Validation loss: 3.0434576448982282

Epoch: 6| Step: 11
Training loss: 0.28912193099791483
Validation loss: 3.097083982928361

Epoch: 6| Step: 12
Training loss: 0.36179482502481136
Validation loss: 3.0682387268577096

Epoch: 6| Step: 13
Training loss: 0.2802902110327432
Validation loss: 3.0867478992601973

Epoch: 459| Step: 0
Training loss: 0.2738690377008188
Validation loss: 3.1518935678209847

Epoch: 6| Step: 1
Training loss: 0.46865168176164274
Validation loss: 3.169134776011553

Epoch: 6| Step: 2
Training loss: 0.31519066461475553
Validation loss: 3.1806159011431823

Epoch: 6| Step: 3
Training loss: 0.2900066678744016
Validation loss: 3.1627665813203265

Epoch: 6| Step: 4
Training loss: 0.3328208510376442
Validation loss: 3.052923188946859

Epoch: 6| Step: 5
Training loss: 0.2707023884816905
Validation loss: 3.1153842104730103

Epoch: 6| Step: 6
Training loss: 0.2667640917227928
Validation loss: 3.136775578815

Epoch: 6| Step: 7
Training loss: 0.314965369917102
Validation loss: 3.1072633560191947

Epoch: 6| Step: 8
Training loss: 0.3590373235762045
Validation loss: 3.059670756834511

Epoch: 6| Step: 9
Training loss: 0.360262231686634
Validation loss: 3.1122931711705797

Epoch: 6| Step: 10
Training loss: 0.3882483086533806
Validation loss: 3.1231931676391875

Epoch: 6| Step: 11
Training loss: 0.2395167292742968
Validation loss: 3.11609392734462

Epoch: 6| Step: 12
Training loss: 0.2977056927805232
Validation loss: 3.1817186321439674

Epoch: 6| Step: 13
Training loss: 0.30203646537434
Validation loss: 3.1911726344316382

Epoch: 460| Step: 0
Training loss: 0.32696240957697636
Validation loss: 3.201705605725017

Epoch: 6| Step: 1
Training loss: 0.23413972967089292
Validation loss: 3.1589696642377207

Epoch: 6| Step: 2
Training loss: 0.22647507394809865
Validation loss: 3.2078285480735174

Epoch: 6| Step: 3
Training loss: 0.3256362812043003
Validation loss: 3.1926330175845625

Epoch: 6| Step: 4
Training loss: 0.3167373431958056
Validation loss: 3.240350464804385

Epoch: 6| Step: 5
Training loss: 0.21736484737827783
Validation loss: 3.1274552427606683

Epoch: 6| Step: 6
Training loss: 0.2520819046568516
Validation loss: 3.0788837924084365

Epoch: 6| Step: 7
Training loss: 0.2189087121676639
Validation loss: 3.078068301845363

Epoch: 6| Step: 8
Training loss: 0.23265029998252068
Validation loss: 3.0417085322455697

Epoch: 6| Step: 9
Training loss: 0.40365152867718923
Validation loss: 3.0702862273330576

Epoch: 6| Step: 10
Training loss: 0.20685018863157617
Validation loss: 3.1292218744831852

Epoch: 6| Step: 11
Training loss: 0.2433812500504303
Validation loss: 3.09744099033029

Epoch: 6| Step: 12
Training loss: 0.3235626245888582
Validation loss: 3.166020281390359

Epoch: 6| Step: 13
Training loss: 0.3200856661682178
Validation loss: 3.139942759338359

Epoch: 461| Step: 0
Training loss: 0.3003575325386321
Validation loss: 3.126340311630416

Epoch: 6| Step: 1
Training loss: 0.25982184984746987
Validation loss: 3.119084787077986

Epoch: 6| Step: 2
Training loss: 0.24041022090986924
Validation loss: 3.1065142712918394

Epoch: 6| Step: 3
Training loss: 0.2689841841431937
Validation loss: 3.0625053457615707

Epoch: 6| Step: 4
Training loss: 0.33704472095306426
Validation loss: 3.002964885887887

Epoch: 6| Step: 5
Training loss: 0.45712339662370305
Validation loss: 3.090423208141223

Epoch: 6| Step: 6
Training loss: 0.3921462193074945
Validation loss: 3.0676743139033276

Epoch: 6| Step: 7
Training loss: 0.28771554444566766
Validation loss: 3.0504704315848383

Epoch: 6| Step: 8
Training loss: 0.28104224744123585
Validation loss: 3.168254822131675

Epoch: 6| Step: 9
Training loss: 0.30136587868268455
Validation loss: 3.1617153048624194

Epoch: 6| Step: 10
Training loss: 0.3818290495190256
Validation loss: 3.2480160697780636

Epoch: 6| Step: 11
Training loss: 0.32742358351752987
Validation loss: 3.249556596781887

Epoch: 6| Step: 12
Training loss: 0.3442628892259976
Validation loss: 3.167554985899904

Epoch: 6| Step: 13
Training loss: 0.33509861643974304
Validation loss: 3.1787236882904786

Epoch: 462| Step: 0
Training loss: 0.270294380683224
Validation loss: 3.1449936173399022

Epoch: 6| Step: 1
Training loss: 0.2940996594924149
Validation loss: 3.0866704400357388

Epoch: 6| Step: 2
Training loss: 0.5337042776442056
Validation loss: 3.0892156001838313

Epoch: 6| Step: 3
Training loss: 0.3011111889764193
Validation loss: 3.0952416494195396

Epoch: 6| Step: 4
Training loss: 0.19753642426883247
Validation loss: 3.064147065153305

Epoch: 6| Step: 5
Training loss: 0.2241884682971812
Validation loss: 3.1493047713998763

Epoch: 6| Step: 6
Training loss: 0.14536151315756116
Validation loss: 3.1609397391617606

Epoch: 6| Step: 7
Training loss: 0.2846283795160723
Validation loss: 3.203164486525384

Epoch: 6| Step: 8
Training loss: 0.37784786472189197
Validation loss: 3.218085272830194

Epoch: 6| Step: 9
Training loss: 0.3486277475710406
Validation loss: 3.1616942785327904

Epoch: 6| Step: 10
Training loss: 0.3135263041073191
Validation loss: 3.181694078708685

Epoch: 6| Step: 11
Training loss: 0.25730014232363957
Validation loss: 3.1434771996426596

Epoch: 6| Step: 12
Training loss: 0.27756013622449915
Validation loss: 3.174368693948906

Epoch: 6| Step: 13
Training loss: 0.28240497849864016
Validation loss: 3.068077069559146

Epoch: 463| Step: 0
Training loss: 0.33752688636357203
Validation loss: 3.1418650442238483

Epoch: 6| Step: 1
Training loss: 0.2135972797657463
Validation loss: 3.0903012225991673

Epoch: 6| Step: 2
Training loss: 0.23446733722111152
Validation loss: 3.1452766119521436

Epoch: 6| Step: 3
Training loss: 0.3080692058327918
Validation loss: 3.0898235077643017

Epoch: 6| Step: 4
Training loss: 0.3197901816856541
Validation loss: 3.127680061598947

Epoch: 6| Step: 5
Training loss: 0.3031257929250827
Validation loss: 3.131109318520248

Epoch: 6| Step: 6
Training loss: 0.30053197761821215
Validation loss: 3.1527156177186955

Epoch: 6| Step: 7
Training loss: 0.2838976925834079
Validation loss: 3.174956480113455

Epoch: 6| Step: 8
Training loss: 0.2536109674500217
Validation loss: 3.1005272534841852

Epoch: 6| Step: 9
Training loss: 0.3130783451371024
Validation loss: 3.1573188910615806

Epoch: 6| Step: 10
Training loss: 0.3250682227348462
Validation loss: 3.145283952113806

Epoch: 6| Step: 11
Training loss: 0.28647530534346655
Validation loss: 3.134725530413533

Epoch: 6| Step: 12
Training loss: 0.2122470507253983
Validation loss: 3.07152773400272

Epoch: 6| Step: 13
Training loss: 0.28077079426568285
Validation loss: 3.1012402422319787

Epoch: 464| Step: 0
Training loss: 0.2681063151573726
Validation loss: 3.1228015796169246

Epoch: 6| Step: 1
Training loss: 0.36036620071576725
Validation loss: 3.0792301730643192

Epoch: 6| Step: 2
Training loss: 0.39233542764299717
Validation loss: 3.1196348801553317

Epoch: 6| Step: 3
Training loss: 0.25071326965462665
Validation loss: 3.2143279751517357

Epoch: 6| Step: 4
Training loss: 0.3977033358653424
Validation loss: 3.255580781101871

Epoch: 6| Step: 5
Training loss: 0.3757131867817457
Validation loss: 3.2936247220907

Epoch: 6| Step: 6
Training loss: 0.2296196766061319
Validation loss: 3.2104331902126813

Epoch: 6| Step: 7
Training loss: 0.31288261831947584
Validation loss: 3.2188971279060645

Epoch: 6| Step: 8
Training loss: 0.3205353961537699
Validation loss: 3.1919246705423663

Epoch: 6| Step: 9
Training loss: 0.24445007549077175
Validation loss: 3.1759029175872633

Epoch: 6| Step: 10
Training loss: 0.29332106704604705
Validation loss: 3.1609256092350093

Epoch: 6| Step: 11
Training loss: 0.4227229004097307
Validation loss: 3.1442753468514213

Epoch: 6| Step: 12
Training loss: 0.21876319777321462
Validation loss: 3.2067505949487787

Epoch: 6| Step: 13
Training loss: 0.28747659670901127
Validation loss: 3.2039160519245105

Epoch: 465| Step: 0
Training loss: 0.17523034977637275
Validation loss: 3.186138074048143

Epoch: 6| Step: 1
Training loss: 0.33245667523088024
Validation loss: 3.1336415146039207

Epoch: 6| Step: 2
Training loss: 0.2170326651821589
Validation loss: 3.1362716843935017

Epoch: 6| Step: 3
Training loss: 0.2777927954243493
Validation loss: 3.221460182873423

Epoch: 6| Step: 4
Training loss: 0.31449134073177804
Validation loss: 3.151426879204003

Epoch: 6| Step: 5
Training loss: 0.20063276180808723
Validation loss: 3.1257585240721544

Epoch: 6| Step: 6
Training loss: 0.31358194213973883
Validation loss: 3.118205109152956

Epoch: 6| Step: 7
Training loss: 0.2557028808732445
Validation loss: 3.059930631831993

Epoch: 6| Step: 8
Training loss: 0.3017685280289237
Validation loss: 3.0946091508967597

Epoch: 6| Step: 9
Training loss: 0.3112088232111032
Validation loss: 3.15771168518459

Epoch: 6| Step: 10
Training loss: 0.262346709997531
Validation loss: 3.0466433706025913

Epoch: 6| Step: 11
Training loss: 0.23441157055690218
Validation loss: 3.130911741177722

Epoch: 6| Step: 12
Training loss: 0.2849463905559028
Validation loss: 3.116516640226063

Epoch: 6| Step: 13
Training loss: 0.1904771207764733
Validation loss: 3.1441952101315636

Epoch: 466| Step: 0
Training loss: 0.3131480173875642
Validation loss: 3.2097984948296814

Epoch: 6| Step: 1
Training loss: 0.34335206580600924
Validation loss: 3.234951797138022

Epoch: 6| Step: 2
Training loss: 0.28268091133210577
Validation loss: 3.207335457291736

Epoch: 6| Step: 3
Training loss: 0.4034083087977058
Validation loss: 3.2249614631952648

Epoch: 6| Step: 4
Training loss: 0.2297656925257091
Validation loss: 3.157470240630161

Epoch: 6| Step: 5
Training loss: 0.2412172463398974
Validation loss: 3.1757927363001457

Epoch: 6| Step: 6
Training loss: 0.18282689583983566
Validation loss: 3.1703138596788913

Epoch: 6| Step: 7
Training loss: 0.2739027289008108
Validation loss: 3.119120432757088

Epoch: 6| Step: 8
Training loss: 0.25419679304233944
Validation loss: 3.2023505538467356

Epoch: 6| Step: 9
Training loss: 0.19366147303066725
Validation loss: 3.09531310439485

Epoch: 6| Step: 10
Training loss: 0.3348898409025024
Validation loss: 3.113464082066272

Epoch: 6| Step: 11
Training loss: 0.22244223967387766
Validation loss: 3.11510848824391

Epoch: 6| Step: 12
Training loss: 0.2813270251446734
Validation loss: 3.177200682093604

Epoch: 6| Step: 13
Training loss: 0.2558841693308658
Validation loss: 3.208587405230467

Epoch: 467| Step: 0
Training loss: 0.2086077442546893
Validation loss: 3.191102939917423

Epoch: 6| Step: 1
Training loss: 0.2849257988080352
Validation loss: 3.096776708331954

Epoch: 6| Step: 2
Training loss: 0.30546526797132023
Validation loss: 3.102882469510953

Epoch: 6| Step: 3
Training loss: 0.3227377698503218
Validation loss: 3.092493720535239

Epoch: 6| Step: 4
Training loss: 0.3212033885136937
Validation loss: 3.081497404007151

Epoch: 6| Step: 5
Training loss: 0.23448594964033073
Validation loss: 3.0900272101116766

Epoch: 6| Step: 6
Training loss: 0.3273907916698032
Validation loss: 3.0589636022441877

Epoch: 6| Step: 7
Training loss: 0.36715661588607246
Validation loss: 3.0294169884420077

Epoch: 6| Step: 8
Training loss: 0.4327223673592367
Validation loss: 2.9863990989818587

Epoch: 6| Step: 9
Training loss: 0.26253954441938426
Validation loss: 3.087054241295801

Epoch: 6| Step: 10
Training loss: 0.18697129651847083
Validation loss: 3.0872756825040226

Epoch: 6| Step: 11
Training loss: 0.2984546496671542
Validation loss: 3.095360975481262

Epoch: 6| Step: 12
Training loss: 0.3212063343711491
Validation loss: 3.165699344677093

Epoch: 6| Step: 13
Training loss: 0.2875753500922937
Validation loss: 3.2051940438281914

Epoch: 468| Step: 0
Training loss: 0.2734940334188796
Validation loss: 3.163183459083603

Epoch: 6| Step: 1
Training loss: 0.2121647964348537
Validation loss: 3.1743118371379526

Epoch: 6| Step: 2
Training loss: 0.28060081847150337
Validation loss: 3.264657797549431

Epoch: 6| Step: 3
Training loss: 0.25909042085996287
Validation loss: 3.168383501014538

Epoch: 6| Step: 4
Training loss: 0.27144984842205894
Validation loss: 3.1615015788422522

Epoch: 6| Step: 5
Training loss: 0.30303288171043086
Validation loss: 3.2089793599345513

Epoch: 6| Step: 6
Training loss: 0.23442351315999022
Validation loss: 3.1688006931842203

Epoch: 6| Step: 7
Training loss: 0.30985855498077236
Validation loss: 3.1260616152282688

Epoch: 6| Step: 8
Training loss: 0.27602347577934155
Validation loss: 3.136690322538136

Epoch: 6| Step: 9
Training loss: 0.32401170209220764
Validation loss: 3.0580558579954555

Epoch: 6| Step: 10
Training loss: 0.21827146435854813
Validation loss: 3.101018273356426

Epoch: 6| Step: 11
Training loss: 0.3993535823780268
Validation loss: 3.207847153788771

Epoch: 6| Step: 12
Training loss: 0.32675513923677896
Validation loss: 3.187795563003296

Epoch: 6| Step: 13
Training loss: 0.2877824898563734
Validation loss: 3.1879274667571798

Epoch: 469| Step: 0
Training loss: 0.40754103924917134
Validation loss: 3.19284287999447

Epoch: 6| Step: 1
Training loss: 0.2110914180945883
Validation loss: 3.1996620377252336

Epoch: 6| Step: 2
Training loss: 0.3755210395879439
Validation loss: 3.1519638897808946

Epoch: 6| Step: 3
Training loss: 0.20831108371815127
Validation loss: 3.1337605831016737

Epoch: 6| Step: 4
Training loss: 0.30907303976325834
Validation loss: 3.1672882340076867

Epoch: 6| Step: 5
Training loss: 0.28584076751257353
Validation loss: 3.0655655601408576

Epoch: 6| Step: 6
Training loss: 0.19390249557610595
Validation loss: 3.078996667225591

Epoch: 6| Step: 7
Training loss: 0.27423980718986474
Validation loss: 3.1334159060683633

Epoch: 6| Step: 8
Training loss: 0.208259797032382
Validation loss: 3.0716164677727216

Epoch: 6| Step: 9
Training loss: 0.26523173896929114
Validation loss: 3.1743831771261575

Epoch: 6| Step: 10
Training loss: 0.2641811397771473
Validation loss: 3.1987927176060587

Epoch: 6| Step: 11
Training loss: 0.2264162446547998
Validation loss: 3.1107226187863573

Epoch: 6| Step: 12
Training loss: 0.30956211741096673
Validation loss: 3.1233194664437303

Epoch: 6| Step: 13
Training loss: 0.211928283636132
Validation loss: 3.153483408938154

Epoch: 470| Step: 0
Training loss: 0.28083557484342536
Validation loss: 3.0891964986420812

Epoch: 6| Step: 1
Training loss: 0.2262165206697101
Validation loss: 3.122817778002482

Epoch: 6| Step: 2
Training loss: 0.3754599055765767
Validation loss: 3.10763753018388

Epoch: 6| Step: 3
Training loss: 0.407668425150458
Validation loss: 3.1017257301559877

Epoch: 6| Step: 4
Training loss: 0.3111413507912367
Validation loss: 3.12469928566155

Epoch: 6| Step: 5
Training loss: 0.26135216846110165
Validation loss: 3.142799358590156

Epoch: 6| Step: 6
Training loss: 0.23011005095911458
Validation loss: 3.13625207123752

Epoch: 6| Step: 7
Training loss: 0.2546561391513989
Validation loss: 3.1534701276616013

Epoch: 6| Step: 8
Training loss: 0.2233538491044872
Validation loss: 3.092492191466226

Epoch: 6| Step: 9
Training loss: 0.23106455971272133
Validation loss: 3.115696371135306

Epoch: 6| Step: 10
Training loss: 0.2940136649417208
Validation loss: 3.1216960607496804

Epoch: 6| Step: 11
Training loss: 0.23212174664129467
Validation loss: 3.085843434892013

Epoch: 6| Step: 12
Training loss: 0.23324470564658895
Validation loss: 3.065957083880122

Epoch: 6| Step: 13
Training loss: 0.22388324291915884
Validation loss: 3.105012616261412

Epoch: 471| Step: 0
Training loss: 0.2456275065490723
Validation loss: 3.1913698304058147

Epoch: 6| Step: 1
Training loss: 0.2938366812789156
Validation loss: 3.1193967557594418

Epoch: 6| Step: 2
Training loss: 0.2977498115215458
Validation loss: 3.218317934931526

Epoch: 6| Step: 3
Training loss: 0.2798084562229697
Validation loss: 3.200783061041834

Epoch: 6| Step: 4
Training loss: 0.23119678916120553
Validation loss: 3.1611496063939653

Epoch: 6| Step: 5
Training loss: 0.4097834391399095
Validation loss: 3.1419272688248925

Epoch: 6| Step: 6
Training loss: 0.24972697339858752
Validation loss: 3.106347276071444

Epoch: 6| Step: 7
Training loss: 0.2304942391734853
Validation loss: 3.0731885154004415

Epoch: 6| Step: 8
Training loss: 0.3550185402206135
Validation loss: 3.0912196411131116

Epoch: 6| Step: 9
Training loss: 0.23169917256074182
Validation loss: 3.109967633740292

Epoch: 6| Step: 10
Training loss: 0.2350605554502793
Validation loss: 3.0911406870764058

Epoch: 6| Step: 11
Training loss: 0.24682252694446852
Validation loss: 3.0560106954778545

Epoch: 6| Step: 12
Training loss: 0.28607682341041435
Validation loss: 3.1455887368881803

Epoch: 6| Step: 13
Training loss: 0.32607461998415854
Validation loss: 3.129697168709517

Epoch: 472| Step: 0
Training loss: 0.21550713337633426
Validation loss: 3.1764985260257736

Epoch: 6| Step: 1
Training loss: 0.2689574117716143
Validation loss: 3.1178582026823625

Epoch: 6| Step: 2
Training loss: 0.21550135107900242
Validation loss: 3.166077651071872

Epoch: 6| Step: 3
Training loss: 0.3451749247087756
Validation loss: 3.134810320415726

Epoch: 6| Step: 4
Training loss: 0.25670103874568506
Validation loss: 3.14698356585095

Epoch: 6| Step: 5
Training loss: 0.21013704056142996
Validation loss: 3.136709248871624

Epoch: 6| Step: 6
Training loss: 0.3803214553744057
Validation loss: 3.093976690033995

Epoch: 6| Step: 7
Training loss: 0.29394789786485026
Validation loss: 3.118994651886877

Epoch: 6| Step: 8
Training loss: 0.37649832847497733
Validation loss: 3.2166854508663523

Epoch: 6| Step: 9
Training loss: 0.2314939809885945
Validation loss: 3.216944734548665

Epoch: 6| Step: 10
Training loss: 0.3470546789732417
Validation loss: 3.1799632959626813

Epoch: 6| Step: 11
Training loss: 0.390788883163659
Validation loss: 3.2198408432636687

Epoch: 6| Step: 12
Training loss: 0.3498711698008309
Validation loss: 3.103937528887737

Epoch: 6| Step: 13
Training loss: 0.17047894901007055
Validation loss: 3.1252504757000263

Epoch: 473| Step: 0
Training loss: 0.33963302129821066
Validation loss: 3.0676958551244833

Epoch: 6| Step: 1
Training loss: 0.2842593654869552
Validation loss: 3.085241929866782

Epoch: 6| Step: 2
Training loss: 0.3980758371944353
Validation loss: 3.055964418472075

Epoch: 6| Step: 3
Training loss: 0.21663269493426981
Validation loss: 3.088579165835188

Epoch: 6| Step: 4
Training loss: 0.26559975448016804
Validation loss: 3.1479717632717357

Epoch: 6| Step: 5
Training loss: 0.26412967922093583
Validation loss: 3.166310470190358

Epoch: 6| Step: 6
Training loss: 0.3054440715216339
Validation loss: 3.140197535029562

Epoch: 6| Step: 7
Training loss: 0.46023078664514955
Validation loss: 3.2092789994355204

Epoch: 6| Step: 8
Training loss: 0.3877029802539426
Validation loss: 3.165148186933338

Epoch: 6| Step: 9
Training loss: 0.38396459549868145
Validation loss: 3.1015604501200196

Epoch: 6| Step: 10
Training loss: 0.27442788194496853
Validation loss: 3.1051719539694846

Epoch: 6| Step: 11
Training loss: 0.33199657932351956
Validation loss: 3.0767565685237335

Epoch: 6| Step: 12
Training loss: 0.5292280088999498
Validation loss: 3.0477885384701313

Epoch: 6| Step: 13
Training loss: 0.4623420619643718
Validation loss: 3.046024014565942

Epoch: 474| Step: 0
Training loss: 0.2862448359111082
Validation loss: 3.086566947770822

Epoch: 6| Step: 1
Training loss: 0.2674141959476146
Validation loss: 3.107999922501585

Epoch: 6| Step: 2
Training loss: 0.24593514675192385
Validation loss: 3.1517088359800205

Epoch: 6| Step: 3
Training loss: 0.2694958373316241
Validation loss: 3.1489626917344617

Epoch: 6| Step: 4
Training loss: 0.3983005213424485
Validation loss: 3.197742486408039

Epoch: 6| Step: 5
Training loss: 0.40762112391224875
Validation loss: 3.1857570794795294

Epoch: 6| Step: 6
Training loss: 0.3350558132677776
Validation loss: 3.1200484656783725

Epoch: 6| Step: 7
Training loss: 0.25090258803209253
Validation loss: 3.106913820969483

Epoch: 6| Step: 8
Training loss: 0.3194601768038112
Validation loss: 3.0864968609773573

Epoch: 6| Step: 9
Training loss: 0.4755462065908699
Validation loss: 3.00886885683606

Epoch: 6| Step: 10
Training loss: 0.48367988792982514
Validation loss: 3.055203822631489

Epoch: 6| Step: 11
Training loss: 0.2700686832550871
Validation loss: 3.142547259545668

Epoch: 6| Step: 12
Training loss: 0.3541808850108377
Validation loss: 3.157660291987136

Epoch: 6| Step: 13
Training loss: 0.3423082286769519
Validation loss: 3.151893693892593

Epoch: 475| Step: 0
Training loss: 0.41827677134758434
Validation loss: 3.1292317031082035

Epoch: 6| Step: 1
Training loss: 0.3654968216362564
Validation loss: 3.1821204772622176

Epoch: 6| Step: 2
Training loss: 0.3083030925346305
Validation loss: 3.179897317048244

Epoch: 6| Step: 3
Training loss: 0.3445249513668831
Validation loss: 3.1531298987379226

Epoch: 6| Step: 4
Training loss: 0.2664315376697369
Validation loss: 3.166322392437921

Epoch: 6| Step: 5
Training loss: 0.13251859739082775
Validation loss: 3.116638900170762

Epoch: 6| Step: 6
Training loss: 0.25310154087949555
Validation loss: 3.1350634598786074

Epoch: 6| Step: 7
Training loss: 0.22013527052085402
Validation loss: 3.170407273536859

Epoch: 6| Step: 8
Training loss: 0.3039033531698126
Validation loss: 3.139454675749761

Epoch: 6| Step: 9
Training loss: 0.2640413450762144
Validation loss: 3.141919098754467

Epoch: 6| Step: 10
Training loss: 0.24235730217549012
Validation loss: 3.1118924925583773

Epoch: 6| Step: 11
Training loss: 0.24254636172644742
Validation loss: 3.1366141473249485

Epoch: 6| Step: 12
Training loss: 0.19990594000626083
Validation loss: 3.059989691843693

Epoch: 6| Step: 13
Training loss: 0.2672610666822417
Validation loss: 3.168708987600756

Epoch: 476| Step: 0
Training loss: 0.1482231449567012
Validation loss: 3.117428393445288

Epoch: 6| Step: 1
Training loss: 0.2547524656039819
Validation loss: 3.130608649952093

Epoch: 6| Step: 2
Training loss: 0.286154528109544
Validation loss: 3.084893042628447

Epoch: 6| Step: 3
Training loss: 0.2749873380563688
Validation loss: 3.0844728881391394

Epoch: 6| Step: 4
Training loss: 0.30278108298007417
Validation loss: 3.099002681810208

Epoch: 6| Step: 5
Training loss: 0.35864212108814053
Validation loss: 3.057204046515582

Epoch: 6| Step: 6
Training loss: 0.35815668917886057
Validation loss: 3.0714273410511614

Epoch: 6| Step: 7
Training loss: 0.32206800933069896
Validation loss: 3.1255610407424688

Epoch: 6| Step: 8
Training loss: 0.35097431146051616
Validation loss: 3.194863260613535

Epoch: 6| Step: 9
Training loss: 0.3109899395184811
Validation loss: 3.2393190126845073

Epoch: 6| Step: 10
Training loss: 0.3117782722377591
Validation loss: 3.153303565119374

Epoch: 6| Step: 11
Training loss: 0.21986123090758694
Validation loss: 3.142982509050968

Epoch: 6| Step: 12
Training loss: 0.3600868141614049
Validation loss: 3.152166652313632

Epoch: 6| Step: 13
Training loss: 0.3244152622556693
Validation loss: 3.1509868816730977

Epoch: 477| Step: 0
Training loss: 0.3208977075291026
Validation loss: 3.1237178461038813

Epoch: 6| Step: 1
Training loss: 0.3123144314064764
Validation loss: 3.149784453147206

Epoch: 6| Step: 2
Training loss: 0.3271924117410988
Validation loss: 3.1287577352150047

Epoch: 6| Step: 3
Training loss: 0.1850068113001039
Validation loss: 3.169744631171447

Epoch: 6| Step: 4
Training loss: 0.24468144596887803
Validation loss: 3.072321809423482

Epoch: 6| Step: 5
Training loss: 0.23968434364050964
Validation loss: 3.19512532874398

Epoch: 6| Step: 6
Training loss: 0.32754271931162265
Validation loss: 3.1307601738481936

Epoch: 6| Step: 7
Training loss: 0.21750835998681095
Validation loss: 3.191526574894091

Epoch: 6| Step: 8
Training loss: 0.4285593481717058
Validation loss: 3.1990411046924865

Epoch: 6| Step: 9
Training loss: 0.21049599006088626
Validation loss: 3.1854162323882607

Epoch: 6| Step: 10
Training loss: 0.2189161487113867
Validation loss: 3.184027469477378

Epoch: 6| Step: 11
Training loss: 0.2859907871893256
Validation loss: 3.0831312336714647

Epoch: 6| Step: 12
Training loss: 0.19320441307690506
Validation loss: 3.0899342983013756

Epoch: 6| Step: 13
Training loss: 0.2890352803379361
Validation loss: 3.12774362287587

Epoch: 478| Step: 0
Training loss: 0.25352390552040377
Validation loss: 3.1572549938428525

Epoch: 6| Step: 1
Training loss: 0.3361027000899052
Validation loss: 3.1463869799223887

Epoch: 6| Step: 2
Training loss: 0.2019083744546027
Validation loss: 3.178188236073825

Epoch: 6| Step: 3
Training loss: 0.24697691015137552
Validation loss: 3.1124764442829163

Epoch: 6| Step: 4
Training loss: 0.2639106375881196
Validation loss: 3.1291733150352288

Epoch: 6| Step: 5
Training loss: 0.32498853140549616
Validation loss: 3.1183555282205244

Epoch: 6| Step: 6
Training loss: 0.29348493243472573
Validation loss: 3.0950110463123472

Epoch: 6| Step: 7
Training loss: 0.3139860463436052
Validation loss: 3.1278844872387843

Epoch: 6| Step: 8
Training loss: 0.3028494216368961
Validation loss: 3.1823480271230307

Epoch: 6| Step: 9
Training loss: 0.28014854812034795
Validation loss: 3.1138783851066005

Epoch: 6| Step: 10
Training loss: 0.18829943185288547
Validation loss: 3.138125435548595

Epoch: 6| Step: 11
Training loss: 0.4119822952531095
Validation loss: 3.235954893941286

Epoch: 6| Step: 12
Training loss: 0.24246701139054622
Validation loss: 3.109556029910945

Epoch: 6| Step: 13
Training loss: 0.1761670012550581
Validation loss: 3.1313747490292227

Epoch: 479| Step: 0
Training loss: 0.2993777462707896
Validation loss: 3.0920779401078193

Epoch: 6| Step: 1
Training loss: 0.2799148392172379
Validation loss: 3.0500908728647995

Epoch: 6| Step: 2
Training loss: 0.25358520164348897
Validation loss: 3.113846099424159

Epoch: 6| Step: 3
Training loss: 0.28663052960904156
Validation loss: 3.1434254220260938

Epoch: 6| Step: 4
Training loss: 0.2805427958256441
Validation loss: 3.1340078481775953

Epoch: 6| Step: 5
Training loss: 0.28824667891303807
Validation loss: 3.1796862503036802

Epoch: 6| Step: 6
Training loss: 0.3345655994339415
Validation loss: 3.161783849977425

Epoch: 6| Step: 7
Training loss: 0.2885962411703784
Validation loss: 3.1589332983677867

Epoch: 6| Step: 8
Training loss: 0.4108596038962795
Validation loss: 3.1598120754633587

Epoch: 6| Step: 9
Training loss: 0.19033599896354234
Validation loss: 3.076945574308336

Epoch: 6| Step: 10
Training loss: 0.37225133141919375
Validation loss: 3.0897457012401044

Epoch: 6| Step: 11
Training loss: 0.2024367667300025
Validation loss: 3.169867921919676

Epoch: 6| Step: 12
Training loss: 0.2597476408046319
Validation loss: 3.076314106231543

Epoch: 6| Step: 13
Training loss: 0.2346044768039013
Validation loss: 3.099226423362552

Epoch: 480| Step: 0
Training loss: 0.19638960431680696
Validation loss: 3.132146312629694

Epoch: 6| Step: 1
Training loss: 0.307742090450507
Validation loss: 3.1886540486668777

Epoch: 6| Step: 2
Training loss: 0.32939590965002946
Validation loss: 3.195816149576302

Epoch: 6| Step: 3
Training loss: 0.3080814551715045
Validation loss: 3.2045633079634874

Epoch: 6| Step: 4
Training loss: 0.36275655530347317
Validation loss: 3.1670385234406147

Epoch: 6| Step: 5
Training loss: 0.33010934083943566
Validation loss: 3.191234769225741

Epoch: 6| Step: 6
Training loss: 0.2536122307004678
Validation loss: 3.1281408547715124

Epoch: 6| Step: 7
Training loss: 0.1737052611857645
Validation loss: 3.09065019361348

Epoch: 6| Step: 8
Training loss: 0.2923645655990974
Validation loss: 3.1182093781777387

Epoch: 6| Step: 9
Training loss: 0.2843113754696346
Validation loss: 3.055513535316604

Epoch: 6| Step: 10
Training loss: 0.3293758799850609
Validation loss: 3.09685696860619

Epoch: 6| Step: 11
Training loss: 0.32333042058460226
Validation loss: 3.1196319505230163

Epoch: 6| Step: 12
Training loss: 0.29914659471749466
Validation loss: 3.1323795288943024

Epoch: 6| Step: 13
Training loss: 0.2745211789276464
Validation loss: 3.105319754107169

Epoch: 481| Step: 0
Training loss: 0.2962004753558126
Validation loss: 3.146711142806213

Epoch: 6| Step: 1
Training loss: 0.30592530028476617
Validation loss: 3.209311810855415

Epoch: 6| Step: 2
Training loss: 0.353760018358476
Validation loss: 3.1965825448952416

Epoch: 6| Step: 3
Training loss: 0.2622591815710363
Validation loss: 3.1249719745650872

Epoch: 6| Step: 4
Training loss: 0.2577592621368453
Validation loss: 3.0994861740950173

Epoch: 6| Step: 5
Training loss: 0.32432839251718243
Validation loss: 3.0760971334752725

Epoch: 6| Step: 6
Training loss: 0.3012473965370095
Validation loss: 3.1085415846237874

Epoch: 6| Step: 7
Training loss: 0.44111620395545953
Validation loss: 3.0983043760684215

Epoch: 6| Step: 8
Training loss: 0.21873812983868163
Validation loss: 3.115603778426308

Epoch: 6| Step: 9
Training loss: 0.2760850254530501
Validation loss: 3.071180762810943

Epoch: 6| Step: 10
Training loss: 0.38991092263708815
Validation loss: 3.1130946417339675

Epoch: 6| Step: 11
Training loss: 0.28731630614313197
Validation loss: 3.133505880055405

Epoch: 6| Step: 12
Training loss: 0.19920781984451214
Validation loss: 3.1071879684292893

Epoch: 6| Step: 13
Training loss: 0.3502745454153196
Validation loss: 3.140265423638268

Epoch: 482| Step: 0
Training loss: 0.27793080697601535
Validation loss: 3.1860043251621275

Epoch: 6| Step: 1
Training loss: 0.34096508722205815
Validation loss: 3.123617502216069

Epoch: 6| Step: 2
Training loss: 0.3517686027807822
Validation loss: 3.085562793500512

Epoch: 6| Step: 3
Training loss: 0.44390455831751185
Validation loss: 3.034391944384842

Epoch: 6| Step: 4
Training loss: 0.29672642804858856
Validation loss: 3.0697476528305905

Epoch: 6| Step: 5
Training loss: 0.24286878804829154
Validation loss: 3.0848332743259217

Epoch: 6| Step: 6
Training loss: 0.18980265357008605
Validation loss: 3.1230611126869214

Epoch: 6| Step: 7
Training loss: 0.2022842006618422
Validation loss: 3.0851458471642372

Epoch: 6| Step: 8
Training loss: 0.4069159258345444
Validation loss: 3.126275094882445

Epoch: 6| Step: 9
Training loss: 0.4191322176499826
Validation loss: 3.0981545225943763

Epoch: 6| Step: 10
Training loss: 0.16594092988745743
Validation loss: 3.128605428483144

Epoch: 6| Step: 11
Training loss: 0.3709359486008349
Validation loss: 3.071324641876255

Epoch: 6| Step: 12
Training loss: 0.21703373797029438
Validation loss: 3.091311460244716

Epoch: 6| Step: 13
Training loss: 0.22036176631181506
Validation loss: 3.1001314437850715

Epoch: 483| Step: 0
Training loss: 0.21858362273942308
Validation loss: 3.1342853942821582

Epoch: 6| Step: 1
Training loss: 0.23610435484744002
Validation loss: 3.1091833263214332

Epoch: 6| Step: 2
Training loss: 0.3287958825296771
Validation loss: 3.158155589944203

Epoch: 6| Step: 3
Training loss: 0.2918533071465849
Validation loss: 3.1326645128870925

Epoch: 6| Step: 4
Training loss: 0.21170819738349037
Validation loss: 3.0876361791151647

Epoch: 6| Step: 5
Training loss: 0.23835924310471127
Validation loss: 3.1825272409971808

Epoch: 6| Step: 6
Training loss: 0.26931835833658213
Validation loss: 3.208258310076609

Epoch: 6| Step: 7
Training loss: 0.37947625614166697
Validation loss: 3.2132272963288044

Epoch: 6| Step: 8
Training loss: 0.24161682265742548
Validation loss: 3.186820687105937

Epoch: 6| Step: 9
Training loss: 0.27676688901545515
Validation loss: 3.194837116672313

Epoch: 6| Step: 10
Training loss: 0.17200600443176192
Validation loss: 3.1395315667643344

Epoch: 6| Step: 11
Training loss: 0.2929890434866041
Validation loss: 3.06613351050371

Epoch: 6| Step: 12
Training loss: 0.3074634591736953
Validation loss: 3.0985875182994587

Epoch: 6| Step: 13
Training loss: 0.4237591032440112
Validation loss: 3.1507489323269033

Epoch: 484| Step: 0
Training loss: 0.24954165971429748
Validation loss: 3.1023821256235453

Epoch: 6| Step: 1
Training loss: 0.32329557732776165
Validation loss: 3.1693073773164437

Epoch: 6| Step: 2
Training loss: 0.2820823591423023
Validation loss: 3.185257315948414

Epoch: 6| Step: 3
Training loss: 0.28554252694259796
Validation loss: 3.2202105865566057

Epoch: 6| Step: 4
Training loss: 0.2899124562761942
Validation loss: 3.1974007794075305

Epoch: 6| Step: 5
Training loss: 0.35581672320731683
Validation loss: 3.1826357907764695

Epoch: 6| Step: 6
Training loss: 0.32056772716958715
Validation loss: 3.1367330143066985

Epoch: 6| Step: 7
Training loss: 0.23524968328363421
Validation loss: 3.109357313045121

Epoch: 6| Step: 8
Training loss: 0.2852333173729611
Validation loss: 3.0554362466426572

Epoch: 6| Step: 9
Training loss: 0.2563916268557818
Validation loss: 3.1108042309231996

Epoch: 6| Step: 10
Training loss: 0.31310685362172586
Validation loss: 3.051294053304173

Epoch: 6| Step: 11
Training loss: 0.2530149514959617
Validation loss: 3.112937560469414

Epoch: 6| Step: 12
Training loss: 0.23414070816725896
Validation loss: 3.077290197472849

Epoch: 6| Step: 13
Training loss: 0.22097853971408987
Validation loss: 3.1343085568790348

Epoch: 485| Step: 0
Training loss: 0.2991345648202768
Validation loss: 3.1361455397569276

Epoch: 6| Step: 1
Training loss: 0.31114932469615453
Validation loss: 3.120934677685511

Epoch: 6| Step: 2
Training loss: 0.3169194756845718
Validation loss: 3.2174316842217605

Epoch: 6| Step: 3
Training loss: 0.3124457073732357
Validation loss: 3.152788977712791

Epoch: 6| Step: 4
Training loss: 0.3216719158000441
Validation loss: 3.1940610591057994

Epoch: 6| Step: 5
Training loss: 0.18084008173685373
Validation loss: 3.1984129074386143

Epoch: 6| Step: 6
Training loss: 0.21070204945630283
Validation loss: 3.1574787354225182

Epoch: 6| Step: 7
Training loss: 0.22163721761682814
Validation loss: 3.0809659289166547

Epoch: 6| Step: 8
Training loss: 0.2262331772445924
Validation loss: 3.1029930242906096

Epoch: 6| Step: 9
Training loss: 0.45138516689461444
Validation loss: 3.115931768692964

Epoch: 6| Step: 10
Training loss: 0.2498441150560032
Validation loss: 3.104477864652691

Epoch: 6| Step: 11
Training loss: 0.2914089259006887
Validation loss: 3.1751862829232937

Epoch: 6| Step: 12
Training loss: 0.24879599263449753
Validation loss: 3.13852834224985

Epoch: 6| Step: 13
Training loss: 0.29097606722906977
Validation loss: 3.1143762696159154

Epoch: 486| Step: 0
Training loss: 0.3579173796420533
Validation loss: 3.1386983221902565

Epoch: 6| Step: 1
Training loss: 0.36029143206498776
Validation loss: 3.180710736468006

Epoch: 6| Step: 2
Training loss: 0.13701413125968237
Validation loss: 3.1345422271003365

Epoch: 6| Step: 3
Training loss: 0.2660958940617841
Validation loss: 3.084026791371676

Epoch: 6| Step: 4
Training loss: 0.24110328341490694
Validation loss: 3.1226577373211915

Epoch: 6| Step: 5
Training loss: 0.3025463135393998
Validation loss: 3.074887452999291

Epoch: 6| Step: 6
Training loss: 0.22806614907059017
Validation loss: 3.101834981048995

Epoch: 6| Step: 7
Training loss: 0.23596189827482325
Validation loss: 3.0408953816662576

Epoch: 6| Step: 8
Training loss: 0.3562835744462928
Validation loss: 3.133313539286919

Epoch: 6| Step: 9
Training loss: 0.19706228370303774
Validation loss: 3.122229657856273

Epoch: 6| Step: 10
Training loss: 0.2562852474720013
Validation loss: 3.1387691043589867

Epoch: 6| Step: 11
Training loss: 0.1960371688126803
Validation loss: 3.115909668248456

Epoch: 6| Step: 12
Training loss: 0.2549870741831225
Validation loss: 3.0964984951063883

Epoch: 6| Step: 13
Training loss: 0.23532702686106025
Validation loss: 3.1411797079491377

Epoch: 487| Step: 0
Training loss: 0.2860371817181402
Validation loss: 3.091366437299411

Epoch: 6| Step: 1
Training loss: 0.2548806932149307
Validation loss: 3.19895102374725

Epoch: 6| Step: 2
Training loss: 0.23037468073414513
Validation loss: 3.1086929953532754

Epoch: 6| Step: 3
Training loss: 0.27072613991227806
Validation loss: 3.1411889552034067

Epoch: 6| Step: 4
Training loss: 0.2082313268001454
Validation loss: 3.1312411609557897

Epoch: 6| Step: 5
Training loss: 0.27174332159376163
Validation loss: 3.139785743032649

Epoch: 6| Step: 6
Training loss: 0.19596419329022693
Validation loss: 3.1818094632206817

Epoch: 6| Step: 7
Training loss: 0.2805848202901545
Validation loss: 3.1481433412311564

Epoch: 6| Step: 8
Training loss: 0.22069684585146107
Validation loss: 3.1240532012981173

Epoch: 6| Step: 9
Training loss: 0.34493249464265463
Validation loss: 3.1706595010181857

Epoch: 6| Step: 10
Training loss: 0.3151576756003973
Validation loss: 3.1327027311936897

Epoch: 6| Step: 11
Training loss: 0.20143376127733154
Validation loss: 3.1127729651113794

Epoch: 6| Step: 12
Training loss: 0.2664165203989785
Validation loss: 3.1180086894620795

Epoch: 6| Step: 13
Training loss: 0.22701507615763417
Validation loss: 3.112759944167136

Epoch: 488| Step: 0
Training loss: 0.23516398192206273
Validation loss: 3.1206517803790828

Epoch: 6| Step: 1
Training loss: 0.3376325823720883
Validation loss: 3.194741966840256

Epoch: 6| Step: 2
Training loss: 0.2814331253240376
Validation loss: 3.146257060400086

Epoch: 6| Step: 3
Training loss: 0.25586588319843945
Validation loss: 3.1565229719609023

Epoch: 6| Step: 4
Training loss: 0.3010827572156552
Validation loss: 3.1796556575845965

Epoch: 6| Step: 5
Training loss: 0.30301119545910343
Validation loss: 3.194123859259661

Epoch: 6| Step: 6
Training loss: 0.285489775640759
Validation loss: 3.200784910816163

Epoch: 6| Step: 7
Training loss: 0.260607080781244
Validation loss: 3.1907661135282916

Epoch: 6| Step: 8
Training loss: 0.25352349408696206
Validation loss: 3.1194584476960197

Epoch: 6| Step: 9
Training loss: 0.3979069037845879
Validation loss: 3.096825929747603

Epoch: 6| Step: 10
Training loss: 0.35362452731702654
Validation loss: 3.1017186712476037

Epoch: 6| Step: 11
Training loss: 0.2502271990740125
Validation loss: 3.0571282823480037

Epoch: 6| Step: 12
Training loss: 0.2820240601022047
Validation loss: 3.031417475003325

Epoch: 6| Step: 13
Training loss: 0.3015181073932036
Validation loss: 3.1020644748200765

Epoch: 489| Step: 0
Training loss: 0.14741155921856117
Validation loss: 3.1323048980267667

Epoch: 6| Step: 1
Training loss: 0.2773623393101678
Validation loss: 3.186914178208819

Epoch: 6| Step: 2
Training loss: 0.16808585586918207
Validation loss: 3.141639880783745

Epoch: 6| Step: 3
Training loss: 0.308444916772225
Validation loss: 3.1503606181125776

Epoch: 6| Step: 4
Training loss: 0.2917916748114601
Validation loss: 3.224428963192068

Epoch: 6| Step: 5
Training loss: 0.24567745966205534
Validation loss: 3.208115908864211

Epoch: 6| Step: 6
Training loss: 0.36242406477269706
Validation loss: 3.2184346732830216

Epoch: 6| Step: 7
Training loss: 0.3580745720102599
Validation loss: 3.1811511321027686

Epoch: 6| Step: 8
Training loss: 0.257493891504665
Validation loss: 3.1445869393481973

Epoch: 6| Step: 9
Training loss: 0.2929857376259807
Validation loss: 3.12927614740956

Epoch: 6| Step: 10
Training loss: 0.2370196306175714
Validation loss: 3.148438560163826

Epoch: 6| Step: 11
Training loss: 0.3018131267132693
Validation loss: 3.069737704945854

Epoch: 6| Step: 12
Training loss: 0.21945715600749263
Validation loss: 3.138400148547206

Epoch: 6| Step: 13
Training loss: 0.3367900786115615
Validation loss: 3.0817882472664775

Epoch: 490| Step: 0
Training loss: 0.18446011760662423
Validation loss: 3.1706698904801778

Epoch: 6| Step: 1
Training loss: 0.3329975652376581
Validation loss: 3.1307237849202236

Epoch: 6| Step: 2
Training loss: 0.44958037043394444
Validation loss: 3.2345217857285644

Epoch: 6| Step: 3
Training loss: 0.36499525596200716
Validation loss: 3.146594736447651

Epoch: 6| Step: 4
Training loss: 0.18988193080927335
Validation loss: 3.163657017224026

Epoch: 6| Step: 5
Training loss: 0.28707545592615585
Validation loss: 3.0597583020192154

Epoch: 6| Step: 6
Training loss: 0.49192008065173093
Validation loss: 3.0460826397758667

Epoch: 6| Step: 7
Training loss: 0.32078714791741514
Validation loss: 3.060822163502701

Epoch: 6| Step: 8
Training loss: 0.24176862086316867
Validation loss: 3.079514965822265

Epoch: 6| Step: 9
Training loss: 0.299228250736169
Validation loss: 3.155597090466435

Epoch: 6| Step: 10
Training loss: 0.15856244055341268
Validation loss: 3.1676525204295234

Epoch: 6| Step: 11
Training loss: 0.39973582246317996
Validation loss: 3.2704241591855476

Epoch: 6| Step: 12
Training loss: 0.34867892775089876
Validation loss: 3.2496436975256726

Epoch: 6| Step: 13
Training loss: 0.36586331971620273
Validation loss: 3.1422948873624326

Epoch: 491| Step: 0
Training loss: 0.28188141834538794
Validation loss: 3.1504619769257993

Epoch: 6| Step: 1
Training loss: 0.2235268920864009
Validation loss: 3.1179762426388433

Epoch: 6| Step: 2
Training loss: 0.4264633245072013
Validation loss: 3.097489765017936

Epoch: 6| Step: 3
Training loss: 0.26277409049460937
Validation loss: 3.078177604935797

Epoch: 6| Step: 4
Training loss: 0.21718027391007713
Validation loss: 3.0479285872029225

Epoch: 6| Step: 5
Training loss: 0.25036449980464903
Validation loss: 3.067686425191804

Epoch: 6| Step: 6
Training loss: 0.24525637683199714
Validation loss: 3.0712692284360563

Epoch: 6| Step: 7
Training loss: 0.33530788414898643
Validation loss: 3.1373108415460753

Epoch: 6| Step: 8
Training loss: 0.31526790520932
Validation loss: 3.1709719720742826

Epoch: 6| Step: 9
Training loss: 0.2809766924956037
Validation loss: 3.1679662288180666

Epoch: 6| Step: 10
Training loss: 0.3618200716355542
Validation loss: 3.146588902125424

Epoch: 6| Step: 11
Training loss: 0.23819255741608877
Validation loss: 3.173048481965667

Epoch: 6| Step: 12
Training loss: 0.3396278221538216
Validation loss: 3.140227803533709

Epoch: 6| Step: 13
Training loss: 0.21386233633453067
Validation loss: 3.1290452714341166

Epoch: 492| Step: 0
Training loss: 0.32462659714386316
Validation loss: 3.1034081618291323

Epoch: 6| Step: 1
Training loss: 0.3097367666494998
Validation loss: 3.097960063952741

Epoch: 6| Step: 2
Training loss: 0.4142092138953283
Validation loss: 3.0553833932251364

Epoch: 6| Step: 3
Training loss: 0.3797318028477993
Validation loss: 3.073184287276643

Epoch: 6| Step: 4
Training loss: 0.26621640508330763
Validation loss: 3.0911618590910312

Epoch: 6| Step: 5
Training loss: 0.24725288310071977
Validation loss: 3.1551610497077798

Epoch: 6| Step: 6
Training loss: 0.3369787513439483
Validation loss: 3.165616110073409

Epoch: 6| Step: 7
Training loss: 0.4496896680364775
Validation loss: 3.1878666137095184

Epoch: 6| Step: 8
Training loss: 0.24599506276495012
Validation loss: 3.176080618461316

Epoch: 6| Step: 9
Training loss: 0.2152579476382353
Validation loss: 3.112457025887493

Epoch: 6| Step: 10
Training loss: 0.3546994656800493
Validation loss: 3.080033615845377

Epoch: 6| Step: 11
Training loss: 0.2063703965864157
Validation loss: 3.069297227929954

Epoch: 6| Step: 12
Training loss: 0.2583291339276581
Validation loss: 3.0657501101848053

Epoch: 6| Step: 13
Training loss: 0.34818372465698155
Validation loss: 3.079852927874551

Epoch: 493| Step: 0
Training loss: 0.2022887217690027
Validation loss: 3.0988410265008137

Epoch: 6| Step: 1
Training loss: 0.3468326714610344
Validation loss: 3.069451144131061

Epoch: 6| Step: 2
Training loss: 0.3295998465821513
Validation loss: 3.080398139786102

Epoch: 6| Step: 3
Training loss: 0.3341863813237076
Validation loss: 3.145362494561382

Epoch: 6| Step: 4
Training loss: 0.3839098907596164
Validation loss: 3.1535247267074284

Epoch: 6| Step: 5
Training loss: 0.33265762710465424
Validation loss: 3.1631447045697945

Epoch: 6| Step: 6
Training loss: 0.34708568815865104
Validation loss: 3.219761340811878

Epoch: 6| Step: 7
Training loss: 0.34016015680931894
Validation loss: 3.2281599793165383

Epoch: 6| Step: 8
Training loss: 0.23759632478678805
Validation loss: 3.140527385251148

Epoch: 6| Step: 9
Training loss: 0.1619678304503722
Validation loss: 3.081597423762403

Epoch: 6| Step: 10
Training loss: 0.2819850772881261
Validation loss: 3.083933737437547

Epoch: 6| Step: 11
Training loss: 0.37604864841365887
Validation loss: 3.0747767018443524

Epoch: 6| Step: 12
Training loss: 0.28111596357393315
Validation loss: 3.08875603706514

Epoch: 6| Step: 13
Training loss: 0.4100698834268946
Validation loss: 3.091101132171171

Epoch: 494| Step: 0
Training loss: 0.32914775444981764
Validation loss: 3.0640277555169715

Epoch: 6| Step: 1
Training loss: 0.3923587091010433
Validation loss: 3.192021995731566

Epoch: 6| Step: 2
Training loss: 0.19267138994784014
Validation loss: 3.177360576769236

Epoch: 6| Step: 3
Training loss: 0.21246111703406756
Validation loss: 3.137905189419892

Epoch: 6| Step: 4
Training loss: 0.1853677386831437
Validation loss: 3.144741428846251

Epoch: 6| Step: 5
Training loss: 0.31079662524702284
Validation loss: 3.1214186173473912

Epoch: 6| Step: 6
Training loss: 0.26927434038476866
Validation loss: 3.156228823952722

Epoch: 6| Step: 7
Training loss: 0.24995793048226111
Validation loss: 3.160062583412258

Epoch: 6| Step: 8
Training loss: 0.2554561699385888
Validation loss: 3.1458507225785466

Epoch: 6| Step: 9
Training loss: 0.24468920301524363
Validation loss: 3.1720696250198084

Epoch: 6| Step: 10
Training loss: 0.3266428670598663
Validation loss: 3.178095488534728

Epoch: 6| Step: 11
Training loss: 0.3175254266612433
Validation loss: 3.1829298329562703

Epoch: 6| Step: 12
Training loss: 0.25070893085683893
Validation loss: 3.174801258064576

Epoch: 6| Step: 13
Training loss: 0.24630354461322487
Validation loss: 3.180205106978285

Epoch: 495| Step: 0
Training loss: 0.24334996941577836
Validation loss: 3.1699743480025546

Epoch: 6| Step: 1
Training loss: 0.22348784866465832
Validation loss: 3.1637737503476564

Epoch: 6| Step: 2
Training loss: 0.23284783319239585
Validation loss: 3.1264423602100684

Epoch: 6| Step: 3
Training loss: 0.26678898968640163
Validation loss: 3.1738133262876143

Epoch: 6| Step: 4
Training loss: 0.3163692075921811
Validation loss: 3.1532549606675784

Epoch: 6| Step: 5
Training loss: 0.32592997460899104
Validation loss: 3.12979540055638

Epoch: 6| Step: 6
Training loss: 0.25897683582868597
Validation loss: 3.137654837426333

Epoch: 6| Step: 7
Training loss: 0.23463638353448465
Validation loss: 3.1194841661091655

Epoch: 6| Step: 8
Training loss: 0.1853906073813384
Validation loss: 3.142700976872182

Epoch: 6| Step: 9
Training loss: 0.2734326225935675
Validation loss: 3.1423588232286157

Epoch: 6| Step: 10
Training loss: 0.2769818160633447
Validation loss: 3.065719974769278

Epoch: 6| Step: 11
Training loss: 0.2491322298450733
Validation loss: 3.119658113315923

Epoch: 6| Step: 12
Training loss: 0.3111202536788366
Validation loss: 3.1053028374262768

Epoch: 6| Step: 13
Training loss: 0.3045456384867885
Validation loss: 3.102768235252169

Epoch: 496| Step: 0
Training loss: 0.2083888436909391
Validation loss: 3.15695677293939

Epoch: 6| Step: 1
Training loss: 0.3096044022235129
Validation loss: 3.1784397460761538

Epoch: 6| Step: 2
Training loss: 0.2776198020716398
Validation loss: 3.1192930881387673

Epoch: 6| Step: 3
Training loss: 0.28436503969292803
Validation loss: 3.15097702002088

Epoch: 6| Step: 4
Training loss: 0.2871744640035834
Validation loss: 3.1088234749355492

Epoch: 6| Step: 5
Training loss: 0.370784751338639
Validation loss: 3.08338695342033

Epoch: 6| Step: 6
Training loss: 0.23611762390005514
Validation loss: 3.1300000308141414

Epoch: 6| Step: 7
Training loss: 0.28350849131073724
Validation loss: 3.109402705952516

Epoch: 6| Step: 8
Training loss: 0.2040243139509248
Validation loss: 3.113646571584134

Epoch: 6| Step: 9
Training loss: 0.28342195146470156
Validation loss: 3.1088419573959483

Epoch: 6| Step: 10
Training loss: 0.2179139030663017
Validation loss: 3.118337267804038

Epoch: 6| Step: 11
Training loss: 0.34454826304324937
Validation loss: 3.1655405618867363

Epoch: 6| Step: 12
Training loss: 0.1744145776756
Validation loss: 3.1801478921940403

Epoch: 6| Step: 13
Training loss: 0.2010204430398214
Validation loss: 3.1351388489244814

Epoch: 497| Step: 0
Training loss: 0.2643737211715034
Validation loss: 3.1665285774707104

Epoch: 6| Step: 1
Training loss: 0.38963505236741175
Validation loss: 3.1375528242469453

Epoch: 6| Step: 2
Training loss: 0.1865933871300037
Validation loss: 3.1538907540575116

Epoch: 6| Step: 3
Training loss: 0.3460537377127103
Validation loss: 3.114736385263551

Epoch: 6| Step: 4
Training loss: 0.22024874204261224
Validation loss: 3.1436444850680134

Epoch: 6| Step: 5
Training loss: 0.24467129825431735
Validation loss: 3.171376081042109

Epoch: 6| Step: 6
Training loss: 0.28085870809038166
Validation loss: 3.1939559457050204

Epoch: 6| Step: 7
Training loss: 0.3014783089475539
Validation loss: 3.134028172724818

Epoch: 6| Step: 8
Training loss: 0.27915089133275944
Validation loss: 3.1540105825596196

Epoch: 6| Step: 9
Training loss: 0.2723304955851354
Validation loss: 3.1050255161246447

Epoch: 6| Step: 10
Training loss: 0.31657249886781613
Validation loss: 3.156259391946951

Epoch: 6| Step: 11
Training loss: 0.21821255738289894
Validation loss: 3.0660758518798907

Epoch: 6| Step: 12
Training loss: 0.30579779140153246
Validation loss: 3.082806469176204

Epoch: 6| Step: 13
Training loss: 0.23847582955212632
Validation loss: 3.1002781768807077

Epoch: 498| Step: 0
Training loss: 0.33531972726248366
Validation loss: 3.046130175722085

Epoch: 6| Step: 1
Training loss: 0.25470926507731256
Validation loss: 3.077501185375887

Epoch: 6| Step: 2
Training loss: 0.26353332270102653
Validation loss: 3.120576728963424

Epoch: 6| Step: 3
Training loss: 0.23456680079236716
Validation loss: 3.103386010611698

Epoch: 6| Step: 4
Training loss: 0.22687745400354756
Validation loss: 3.1365174846124324

Epoch: 6| Step: 5
Training loss: 0.15614945037432368
Validation loss: 3.1139442060262454

Epoch: 6| Step: 6
Training loss: 0.31849994949268556
Validation loss: 3.192577282620637

Epoch: 6| Step: 7
Training loss: 0.3211130976358834
Validation loss: 3.194663469204977

Epoch: 6| Step: 8
Training loss: 0.38715996281790077
Validation loss: 3.1930864907734677

Epoch: 6| Step: 9
Training loss: 0.2991348761591187
Validation loss: 3.122263078622119

Epoch: 6| Step: 10
Training loss: 0.23710886406882728
Validation loss: 3.1410963549306894

Epoch: 6| Step: 11
Training loss: 0.2752023959957242
Validation loss: 3.0861304500472535

Epoch: 6| Step: 12
Training loss: 0.2926977430013874
Validation loss: 3.0524053609862682

Epoch: 6| Step: 13
Training loss: 0.3756488907971172
Validation loss: 3.03139633140123

Epoch: 499| Step: 0
Training loss: 0.26860597987623075
Validation loss: 3.076207656248581

Epoch: 6| Step: 1
Training loss: 0.3410760308214109
Validation loss: 3.10660600931139

Epoch: 6| Step: 2
Training loss: 0.3474221030411037
Validation loss: 3.1553408632165088

Epoch: 6| Step: 3
Training loss: 0.30541576257643865
Validation loss: 3.148437424273999

Epoch: 6| Step: 4
Training loss: 0.2757270597649525
Validation loss: 3.1727797497275425

Epoch: 6| Step: 5
Training loss: 0.1930482461248448
Validation loss: 3.1147196855754617

Epoch: 6| Step: 6
Training loss: 0.2912683349781261
Validation loss: 3.092478147124718

Epoch: 6| Step: 7
Training loss: 0.22277619661337933
Validation loss: 3.117880875570954

Epoch: 6| Step: 8
Training loss: 0.2318300116278981
Validation loss: 3.090481068262114

Epoch: 6| Step: 9
Training loss: 0.3616026582893943
Validation loss: 3.127675576814852

Epoch: 6| Step: 10
Training loss: 0.2593315484522619
Validation loss: 3.118549568804547

Epoch: 6| Step: 11
Training loss: 0.19009070914898343
Validation loss: 3.1575342970933766

Epoch: 6| Step: 12
Training loss: 0.38278774259269516
Validation loss: 3.1072483681656506

Epoch: 6| Step: 13
Training loss: 0.3064025148808927
Validation loss: 3.168094781453174

Epoch: 500| Step: 0
Training loss: 0.30998626826621634
Validation loss: 3.159266550559115

Epoch: 6| Step: 1
Training loss: 0.23032311509513326
Validation loss: 3.1215941497871422

Epoch: 6| Step: 2
Training loss: 0.1974785288475026
Validation loss: 3.16060559473561

Epoch: 6| Step: 3
Training loss: 0.24875144315904804
Validation loss: 3.153765339349775

Epoch: 6| Step: 4
Training loss: 0.2793082388320012
Validation loss: 3.1249189366317025

Epoch: 6| Step: 5
Training loss: 0.26799482769209537
Validation loss: 3.1035851482192838

Epoch: 6| Step: 6
Training loss: 0.34198483339917657
Validation loss: 3.1325037448147257

Epoch: 6| Step: 7
Training loss: 0.14958753052838125
Validation loss: 3.12708443106459

Epoch: 6| Step: 8
Training loss: 0.25791085418988063
Validation loss: 3.1494174060261644

Epoch: 6| Step: 9
Training loss: 0.3120235864713475
Validation loss: 3.182574986375753

Epoch: 6| Step: 10
Training loss: 0.2838123477380105
Validation loss: 3.1982180342599418

Epoch: 6| Step: 11
Training loss: 0.22289286973680647
Validation loss: 3.157149208821124

Epoch: 6| Step: 12
Training loss: 0.2581718281579236
Validation loss: 3.1929848174233877

Epoch: 6| Step: 13
Training loss: 0.3796682659033992
Validation loss: 3.2135986042800595

Testing loss: 2.608086970591533
