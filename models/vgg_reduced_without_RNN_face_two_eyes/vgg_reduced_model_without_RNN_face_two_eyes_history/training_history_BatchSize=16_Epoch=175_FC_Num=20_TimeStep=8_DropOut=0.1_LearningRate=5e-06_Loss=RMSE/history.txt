Epoch: 1| Step: 0
Training loss: 4.727633772580791
Validation loss: 4.793392677700233

Epoch: 6| Step: 1
Training loss: 5.019057385828172
Validation loss: 4.76747604025368

Epoch: 6| Step: 2
Training loss: 4.739721722381519
Validation loss: 4.739708341969066

Epoch: 6| Step: 3
Training loss: 4.501778145325085
Validation loss: 4.7116240533053855

Epoch: 6| Step: 4
Training loss: 4.686277102852198
Validation loss: 4.6895729737045215

Epoch: 6| Step: 5
Training loss: 4.8979571774699195
Validation loss: 4.663542479423478

Epoch: 6| Step: 6
Training loss: 5.132133915141851
Validation loss: 4.638865333136918

Epoch: 6| Step: 7
Training loss: 4.56254974756162
Validation loss: 4.614054555570689

Epoch: 6| Step: 8
Training loss: 4.229697483869705
Validation loss: 4.58984897910828

Epoch: 6| Step: 9
Training loss: 5.691694787748617
Validation loss: 4.566977546486906

Epoch: 6| Step: 10
Training loss: 5.013611766780317
Validation loss: 4.543344252011862

Epoch: 6| Step: 11
Training loss: 4.865057955452547
Validation loss: 4.519009247057574

Epoch: 6| Step: 12
Training loss: 4.512849476138896
Validation loss: 4.494634007429094

Epoch: 6| Step: 13
Training loss: 3.752789032419833
Validation loss: 4.4684301764297505

Epoch: 2| Step: 0
Training loss: 4.422525203065883
Validation loss: 4.446294531932996

Epoch: 6| Step: 1
Training loss: 4.4453860848341735
Validation loss: 4.416836009587818

Epoch: 6| Step: 2
Training loss: 4.698963846473895
Validation loss: 4.394564579590044

Epoch: 6| Step: 3
Training loss: 5.031489585716329
Validation loss: 4.362586603334335

Epoch: 6| Step: 4
Training loss: 3.8048128267987975
Validation loss: 4.3344186866353684

Epoch: 6| Step: 5
Training loss: 2.9054521675590586
Validation loss: 4.302702698293

Epoch: 6| Step: 6
Training loss: 4.305107303925818
Validation loss: 4.273211838775026

Epoch: 6| Step: 7
Training loss: 3.8542636893492555
Validation loss: 4.2459770872109095

Epoch: 6| Step: 8
Training loss: 4.220194929420864
Validation loss: 4.213702009786483

Epoch: 6| Step: 9
Training loss: 4.9356543072992975
Validation loss: 4.182550646347401

Epoch: 6| Step: 10
Training loss: 4.632849553235045
Validation loss: 4.143665027849975

Epoch: 6| Step: 11
Training loss: 4.950991390632998
Validation loss: 4.103868496257202

Epoch: 6| Step: 12
Training loss: 4.1902115426571
Validation loss: 4.066497303349131

Epoch: 6| Step: 13
Training loss: 4.21731271632081
Validation loss: 4.026574333587023

Epoch: 3| Step: 0
Training loss: 4.365585224295357
Validation loss: 3.9849539342409033

Epoch: 6| Step: 1
Training loss: 3.5438356527106123
Validation loss: 3.9417574435877696

Epoch: 6| Step: 2
Training loss: 3.3608850678096505
Validation loss: 3.8989432802486403

Epoch: 6| Step: 3
Training loss: 3.895277313428499
Validation loss: 3.8550554779982105

Epoch: 6| Step: 4
Training loss: 4.370650827229791
Validation loss: 3.805125614036092

Epoch: 6| Step: 5
Training loss: 3.208083171917376
Validation loss: 3.7599230554161265

Epoch: 6| Step: 6
Training loss: 4.18784979882278
Validation loss: 3.701158325922045

Epoch: 6| Step: 7
Training loss: 2.9703047044421966
Validation loss: 3.652118119666941

Epoch: 6| Step: 8
Training loss: 3.468515749058211
Validation loss: 3.5974373517867573

Epoch: 6| Step: 9
Training loss: 4.544305763729767
Validation loss: 3.540663289073247

Epoch: 6| Step: 10
Training loss: 4.079151243674891
Validation loss: 3.4865119208890634

Epoch: 6| Step: 11
Training loss: 3.4315975492636523
Validation loss: 3.4278286217233798

Epoch: 6| Step: 12
Training loss: 3.4705478717210094
Validation loss: 3.373293150698908

Epoch: 6| Step: 13
Training loss: 3.6727439339205765
Validation loss: 3.302122571132439

Epoch: 4| Step: 0
Training loss: 2.978609597646672
Validation loss: 3.23699904927014

Epoch: 6| Step: 1
Training loss: 3.8749397027031223
Validation loss: 3.169758195268908

Epoch: 6| Step: 2
Training loss: 2.8987196299157474
Validation loss: 3.1082203189121316

Epoch: 6| Step: 3
Training loss: 3.138962338768814
Validation loss: 3.0510606104630695

Epoch: 6| Step: 4
Training loss: 2.7579920550889625
Validation loss: 2.972031850650139

Epoch: 6| Step: 5
Training loss: 3.101637524675096
Validation loss: 2.908240316993056

Epoch: 6| Step: 6
Training loss: 3.2328281112743835
Validation loss: 2.8468125170017795

Epoch: 6| Step: 7
Training loss: 2.8533000512128015
Validation loss: 2.7947469816973305

Epoch: 6| Step: 8
Training loss: 2.455666458661491
Validation loss: 2.733340040252955

Epoch: 6| Step: 9
Training loss: 1.9523045151619853
Validation loss: 2.6855340464892463

Epoch: 6| Step: 10
Training loss: 3.384361000771774
Validation loss: 2.637690747852747

Epoch: 6| Step: 11
Training loss: 2.676413178829961
Validation loss: 2.6012824426155787

Epoch: 6| Step: 12
Training loss: 2.0162442461133896
Validation loss: 2.572821886939826

Epoch: 6| Step: 13
Training loss: 3.1437596102922196
Validation loss: 2.5421778107598962

Epoch: 5| Step: 0
Training loss: 2.4177086217228956
Validation loss: 2.5369511829812406

Epoch: 6| Step: 1
Training loss: 3.5901383537473666
Validation loss: 2.5360765789986894

Epoch: 6| Step: 2
Training loss: 2.5735135537949207
Validation loss: 2.5494387152284097

Epoch: 6| Step: 3
Training loss: 2.343651527879275
Validation loss: 2.5578828013178616

Epoch: 6| Step: 4
Training loss: 2.4897209565711087
Validation loss: 2.5598298404190505

Epoch: 6| Step: 5
Training loss: 2.956660500670164
Validation loss: 2.5650398646523125

Epoch: 6| Step: 6
Training loss: 2.114449507764664
Validation loss: 2.5738578701650066

Epoch: 6| Step: 7
Training loss: 1.8653988750678092
Validation loss: 2.618861817709276

Epoch: 6| Step: 8
Training loss: 2.7142354379744487
Validation loss: 2.608776564512336

Epoch: 6| Step: 9
Training loss: 2.2106278812647435
Validation loss: 2.619991595689141

Epoch: 6| Step: 10
Training loss: 2.764454222028449
Validation loss: 2.621722430707012

Epoch: 6| Step: 11
Training loss: 2.931713166886472
Validation loss: 2.606254341005999

Epoch: 6| Step: 12
Training loss: 2.741963869197651
Validation loss: 2.615142858649918

Epoch: 6| Step: 13
Training loss: 2.6592888895475966
Validation loss: 2.593575054228252

Epoch: 6| Step: 0
Training loss: 2.539120717481612
Validation loss: 2.567498379700325

Epoch: 6| Step: 1
Training loss: 2.596322220453042
Validation loss: 2.548596149669761

Epoch: 6| Step: 2
Training loss: 2.5902407702909382
Validation loss: 2.5589540650097327

Epoch: 6| Step: 3
Training loss: 1.4914426692234752
Validation loss: 2.5594070966646387

Epoch: 6| Step: 4
Training loss: 1.9298432939782297
Validation loss: 2.539824229689226

Epoch: 6| Step: 5
Training loss: 3.0737800721399644
Validation loss: 2.542415498162612

Epoch: 6| Step: 6
Training loss: 2.8825534611133854
Validation loss: 2.522569316091853

Epoch: 6| Step: 7
Training loss: 2.770585605953108
Validation loss: 2.523943115222083

Epoch: 6| Step: 8
Training loss: 2.5313474848307056
Validation loss: 2.517473161914841

Epoch: 6| Step: 9
Training loss: 2.8855552961371975
Validation loss: 2.5292379286487003

Epoch: 6| Step: 10
Training loss: 2.6940185979415006
Validation loss: 2.524382486152048

Epoch: 6| Step: 11
Training loss: 3.0857908576214266
Validation loss: 2.5047446685631725

Epoch: 6| Step: 12
Training loss: 2.443649750431351
Validation loss: 2.5112317979227963

Epoch: 6| Step: 13
Training loss: 1.9611303227065662
Validation loss: 2.515026566306345

Epoch: 7| Step: 0
Training loss: 2.947490342296668
Validation loss: 2.5280095461089735

Epoch: 6| Step: 1
Training loss: 2.3845238715376924
Validation loss: 2.5160909975351853

Epoch: 6| Step: 2
Training loss: 3.0594236531738472
Validation loss: 2.5272417239507314

Epoch: 6| Step: 3
Training loss: 2.2674681433949706
Validation loss: 2.529804680513388

Epoch: 6| Step: 4
Training loss: 2.029085032591913
Validation loss: 2.534289783592631

Epoch: 6| Step: 5
Training loss: 2.4725758327044534
Validation loss: 2.543720515124799

Epoch: 6| Step: 6
Training loss: 2.9321661064589604
Validation loss: 2.53353082071141

Epoch: 6| Step: 7
Training loss: 2.223081417348267
Validation loss: 2.5295314684934587

Epoch: 6| Step: 8
Training loss: 2.8314609137452162
Validation loss: 2.5444563007726315

Epoch: 6| Step: 9
Training loss: 2.2208819824768566
Validation loss: 2.5245877410939177

Epoch: 6| Step: 10
Training loss: 2.3468404104474967
Validation loss: 2.5117790725132654

Epoch: 6| Step: 11
Training loss: 3.14273273853456
Validation loss: 2.522949328999941

Epoch: 6| Step: 12
Training loss: 2.217749356567854
Validation loss: 2.51238272410624

Epoch: 6| Step: 13
Training loss: 2.785839451783042
Validation loss: 2.501666777020104

Epoch: 8| Step: 0
Training loss: 1.918545451739579
Validation loss: 2.510128579816806

Epoch: 6| Step: 1
Training loss: 3.06989128193657
Validation loss: 2.503759783558895

Epoch: 6| Step: 2
Training loss: 2.149652311023477
Validation loss: 2.502157424816523

Epoch: 6| Step: 3
Training loss: 2.1690677640889784
Validation loss: 2.5085708960853674

Epoch: 6| Step: 4
Training loss: 2.7716297544344743
Validation loss: 2.5066922736973596

Epoch: 6| Step: 5
Training loss: 2.4395017962643624
Validation loss: 2.5008622748753058

Epoch: 6| Step: 6
Training loss: 1.9653190508111713
Validation loss: 2.521991075052739

Epoch: 6| Step: 7
Training loss: 2.437731218375396
Validation loss: 2.5125371885947794

Epoch: 6| Step: 8
Training loss: 2.6691944440130158
Validation loss: 2.50817720290598

Epoch: 6| Step: 9
Training loss: 2.764683622502173
Validation loss: 2.522876090477621

Epoch: 6| Step: 10
Training loss: 2.5972209823886496
Validation loss: 2.5188513180885272

Epoch: 6| Step: 11
Training loss: 3.0642111532595555
Validation loss: 2.514258935879149

Epoch: 6| Step: 12
Training loss: 2.6577684438060274
Validation loss: 2.518062902969252

Epoch: 6| Step: 13
Training loss: 2.674396239978864
Validation loss: 2.5028223001535355

Epoch: 9| Step: 0
Training loss: 2.0308176607579367
Validation loss: 2.5075787507606573

Epoch: 6| Step: 1
Training loss: 2.626211522586242
Validation loss: 2.5064698662718587

Epoch: 6| Step: 2
Training loss: 2.6151420229387887
Validation loss: 2.516975956241839

Epoch: 6| Step: 3
Training loss: 2.8263651393566365
Validation loss: 2.502462906411704

Epoch: 6| Step: 4
Training loss: 2.728320410372967
Validation loss: 2.503776368389412

Epoch: 6| Step: 5
Training loss: 2.8142999611342487
Validation loss: 2.514556642109935

Epoch: 6| Step: 6
Training loss: 1.9166169229216714
Validation loss: 2.5011277516167034

Epoch: 6| Step: 7
Training loss: 2.6187200357912435
Validation loss: 2.5058575672550476

Epoch: 6| Step: 8
Training loss: 2.347129318334911
Validation loss: 2.4993739456844817

Epoch: 6| Step: 9
Training loss: 2.5006579486990224
Validation loss: 2.523500431878315

Epoch: 6| Step: 10
Training loss: 2.6837552617540736
Validation loss: 2.5118696405740057

Epoch: 6| Step: 11
Training loss: 2.9137489620617654
Validation loss: 2.5167182616024957

Epoch: 6| Step: 12
Training loss: 2.078886193856421
Validation loss: 2.502495450064289

Epoch: 6| Step: 13
Training loss: 2.601377830022481
Validation loss: 2.4997066802566947

Epoch: 10| Step: 0
Training loss: 2.3834167714841223
Validation loss: 2.5016022633956982

Epoch: 6| Step: 1
Training loss: 2.9644101193925634
Validation loss: 2.493756413272269

Epoch: 6| Step: 2
Training loss: 2.469099382231987
Validation loss: 2.48620068147822

Epoch: 6| Step: 3
Training loss: 2.9352401806688477
Validation loss: 2.5014615078423

Epoch: 6| Step: 4
Training loss: 1.5651996179334065
Validation loss: 2.49925832873088

Epoch: 6| Step: 5
Training loss: 2.0403076111987204
Validation loss: 2.493997408927993

Epoch: 6| Step: 6
Training loss: 2.6135427118945223
Validation loss: 2.5014768370956957

Epoch: 6| Step: 7
Training loss: 2.5410907801685996
Validation loss: 2.49444949379202

Epoch: 6| Step: 8
Training loss: 2.878597496588101
Validation loss: 2.4898806970298994

Epoch: 6| Step: 9
Training loss: 2.786155403759619
Validation loss: 2.5026093058511854

Epoch: 6| Step: 10
Training loss: 2.0848744859125876
Validation loss: 2.4957575245734605

Epoch: 6| Step: 11
Training loss: 2.221163229806586
Validation loss: 2.4966792542743366

Epoch: 6| Step: 12
Training loss: 2.8475909441457112
Validation loss: 2.488178995647399

Epoch: 6| Step: 13
Training loss: 2.8114553418779
Validation loss: 2.4915631507710967

Epoch: 11| Step: 0
Training loss: 2.3099493445585058
Validation loss: 2.4934984703337197

Epoch: 6| Step: 1
Training loss: 2.379692962299573
Validation loss: 2.4934462952736602

Epoch: 6| Step: 2
Training loss: 2.4855821663645545
Validation loss: 2.486382159464764

Epoch: 6| Step: 3
Training loss: 3.0934053479504615
Validation loss: 2.4809074034016327

Epoch: 6| Step: 4
Training loss: 2.7550134908411605
Validation loss: 2.4965711603712

Epoch: 6| Step: 5
Training loss: 2.3968272814918197
Validation loss: 2.4828367929488504

Epoch: 6| Step: 6
Training loss: 2.2771081818960877
Validation loss: 2.4909643920779154

Epoch: 6| Step: 7
Training loss: 2.3654601590210764
Validation loss: 2.482274413012178

Epoch: 6| Step: 8
Training loss: 2.3835422086441396
Validation loss: 2.4975616484890897

Epoch: 6| Step: 9
Training loss: 1.8252084403997184
Validation loss: 2.488201337695891

Epoch: 6| Step: 10
Training loss: 2.5264031430145772
Validation loss: 2.4891083688574507

Epoch: 6| Step: 11
Training loss: 2.6513988401655735
Validation loss: 2.494322353703706

Epoch: 6| Step: 12
Training loss: 2.5798438613426726
Validation loss: 2.4871161671130295

Epoch: 6| Step: 13
Training loss: 2.9816828063675866
Validation loss: 2.4877655916264323

Epoch: 12| Step: 0
Training loss: 2.1829250997501917
Validation loss: 2.487660632546031

Epoch: 6| Step: 1
Training loss: 2.8658404187152486
Validation loss: 2.4689100833287916

Epoch: 6| Step: 2
Training loss: 2.835289410816966
Validation loss: 2.5017628494399813

Epoch: 6| Step: 3
Training loss: 2.697414650967732
Validation loss: 2.489799064536078

Epoch: 6| Step: 4
Training loss: 2.8100700053390137
Validation loss: 2.516895660398953

Epoch: 6| Step: 5
Training loss: 2.324512213123687
Validation loss: 2.5007236704880698

Epoch: 6| Step: 6
Training loss: 2.032657077251638
Validation loss: 2.509363441551512

Epoch: 6| Step: 7
Training loss: 2.5583059833402517
Validation loss: 2.5017975067175042

Epoch: 6| Step: 8
Training loss: 2.4009988136908205
Validation loss: 2.501598848249184

Epoch: 6| Step: 9
Training loss: 2.3198983693060113
Validation loss: 2.4974746824247123

Epoch: 6| Step: 10
Training loss: 2.2073456936882567
Validation loss: 2.500130236730156

Epoch: 6| Step: 11
Training loss: 2.841754758332666
Validation loss: 2.4903063715082547

Epoch: 6| Step: 12
Training loss: 2.703016157660138
Validation loss: 2.494062079435287

Epoch: 6| Step: 13
Training loss: 2.4342502547341636
Validation loss: 2.4932080514137356

Epoch: 13| Step: 0
Training loss: 2.39321370304883
Validation loss: 2.485031664932494

Epoch: 6| Step: 1
Training loss: 3.0122763269733315
Validation loss: 2.493885717308041

Epoch: 6| Step: 2
Training loss: 1.642045632140662
Validation loss: 2.4816515888228317

Epoch: 6| Step: 3
Training loss: 2.5307369889691076
Validation loss: 2.4884515421597846

Epoch: 6| Step: 4
Training loss: 2.295067939168239
Validation loss: 2.4856997942332435

Epoch: 6| Step: 5
Training loss: 1.8935765328605472
Validation loss: 2.465988095054962

Epoch: 6| Step: 6
Training loss: 3.277496225222488
Validation loss: 2.4734514754561814

Epoch: 6| Step: 7
Training loss: 2.4104463721060196
Validation loss: 2.4830578045250973

Epoch: 6| Step: 8
Training loss: 1.9644088112048017
Validation loss: 2.476297711357718

Epoch: 6| Step: 9
Training loss: 2.3845974599670994
Validation loss: 2.4700038156467055

Epoch: 6| Step: 10
Training loss: 2.263099262267129
Validation loss: 2.4788741946339394

Epoch: 6| Step: 11
Training loss: 3.1352176708723114
Validation loss: 2.4906523469694353

Epoch: 6| Step: 12
Training loss: 3.101213027137133
Validation loss: 2.4633379012527064

Epoch: 6| Step: 13
Training loss: 2.2017347129030322
Validation loss: 2.4869043042697436

Epoch: 14| Step: 0
Training loss: 2.15804879167496
Validation loss: 2.4728236972865942

Epoch: 6| Step: 1
Training loss: 2.889564608343869
Validation loss: 2.469345616466973

Epoch: 6| Step: 2
Training loss: 2.3456740556197317
Validation loss: 2.4842966575186196

Epoch: 6| Step: 3
Training loss: 1.8516062799742388
Validation loss: 2.473929239737785

Epoch: 6| Step: 4
Training loss: 2.535168851988613
Validation loss: 2.4760147275142597

Epoch: 6| Step: 5
Training loss: 2.4383537557932633
Validation loss: 2.4684258260232355

Epoch: 6| Step: 6
Training loss: 2.764737089050209
Validation loss: 2.4806492857426234

Epoch: 6| Step: 7
Training loss: 2.8841574408085946
Validation loss: 2.481027951622385

Epoch: 6| Step: 8
Training loss: 2.345427662908416
Validation loss: 2.466560745112975

Epoch: 6| Step: 9
Training loss: 2.4870776944174557
Validation loss: 2.475158678613144

Epoch: 6| Step: 10
Training loss: 2.4162034105919563
Validation loss: 2.475658697078573

Epoch: 6| Step: 11
Training loss: 2.571460780441561
Validation loss: 2.4681499492369245

Epoch: 6| Step: 12
Training loss: 2.365669191620445
Validation loss: 2.474897866116525

Epoch: 6| Step: 13
Training loss: 2.7857386339961034
Validation loss: 2.477826282380941

Epoch: 15| Step: 0
Training loss: 2.7995796978073333
Validation loss: 2.479486850824431

Epoch: 6| Step: 1
Training loss: 2.8828728728963644
Validation loss: 2.4875666591843726

Epoch: 6| Step: 2
Training loss: 2.6808599014870893
Validation loss: 2.4752704446914886

Epoch: 6| Step: 3
Training loss: 2.3736556414370593
Validation loss: 2.482854045682768

Epoch: 6| Step: 4
Training loss: 1.6621648866592975
Validation loss: 2.477281275594734

Epoch: 6| Step: 5
Training loss: 2.0793435102439783
Validation loss: 2.4686362002899327

Epoch: 6| Step: 6
Training loss: 2.6154889872382374
Validation loss: 2.4884264078723004

Epoch: 6| Step: 7
Training loss: 2.467899803848101
Validation loss: 2.4806229991461053

Epoch: 6| Step: 8
Training loss: 2.721362732990903
Validation loss: 2.4903338323939934

Epoch: 6| Step: 9
Training loss: 2.6353256953725697
Validation loss: 2.480719846496651

Epoch: 6| Step: 10
Training loss: 2.6249225241717236
Validation loss: 2.4743863080254447

Epoch: 6| Step: 11
Training loss: 2.558477827168775
Validation loss: 2.4676456154136606

Epoch: 6| Step: 12
Training loss: 1.942925885030219
Validation loss: 2.473550965081675

Epoch: 6| Step: 13
Training loss: 2.4883244628986616
Validation loss: 2.472267349298014

Epoch: 16| Step: 0
Training loss: 1.9302882444745375
Validation loss: 2.463681405898147

Epoch: 6| Step: 1
Training loss: 2.878887699227885
Validation loss: 2.4728323987718355

Epoch: 6| Step: 2
Training loss: 1.9895846248709064
Validation loss: 2.4671651203412064

Epoch: 6| Step: 3
Training loss: 2.8256805140411116
Validation loss: 2.473623158019018

Epoch: 6| Step: 4
Training loss: 2.1608567714437568
Validation loss: 2.4710236553807934

Epoch: 6| Step: 5
Training loss: 3.021794624403716
Validation loss: 2.4725585805718

Epoch: 6| Step: 6
Training loss: 2.8403410548276167
Validation loss: 2.459520737475474

Epoch: 6| Step: 7
Training loss: 2.670557065135844
Validation loss: 2.471106712137663

Epoch: 6| Step: 8
Training loss: 2.48602221121038
Validation loss: 2.4864108862716106

Epoch: 6| Step: 9
Training loss: 2.318752393695593
Validation loss: 2.4585639769985144

Epoch: 6| Step: 10
Training loss: 2.513824766499256
Validation loss: 2.4814485311956447

Epoch: 6| Step: 11
Training loss: 2.6241440967095175
Validation loss: 2.466391454842994

Epoch: 6| Step: 12
Training loss: 2.048082534214763
Validation loss: 2.469426629741572

Epoch: 6| Step: 13
Training loss: 2.2821505088686402
Validation loss: 2.4633125913759337

Epoch: 17| Step: 0
Training loss: 1.9581385238282725
Validation loss: 2.4670973207446294

Epoch: 6| Step: 1
Training loss: 2.669698977985466
Validation loss: 2.4685331160809643

Epoch: 6| Step: 2
Training loss: 2.9525245984608834
Validation loss: 2.4745051666373348

Epoch: 6| Step: 3
Training loss: 1.968753269737798
Validation loss: 2.4511254456924134

Epoch: 6| Step: 4
Training loss: 2.7544518762173387
Validation loss: 2.466089126488157

Epoch: 6| Step: 5
Training loss: 3.280011915324829
Validation loss: 2.461419033189355

Epoch: 6| Step: 6
Training loss: 1.9865488475494257
Validation loss: 2.4706263755165967

Epoch: 6| Step: 7
Training loss: 2.5108484448234454
Validation loss: 2.462668303726484

Epoch: 6| Step: 8
Training loss: 1.9313559790115271
Validation loss: 2.477830580242353

Epoch: 6| Step: 9
Training loss: 2.3194725494306363
Validation loss: 2.473267795494739

Epoch: 6| Step: 10
Training loss: 1.9863881389962832
Validation loss: 2.461699578700771

Epoch: 6| Step: 11
Training loss: 2.6839714839460838
Validation loss: 2.467804466125955

Epoch: 6| Step: 12
Training loss: 3.084018081374543
Validation loss: 2.4603769138192235

Epoch: 6| Step: 13
Training loss: 2.0588251378349627
Validation loss: 2.465510403637664

Epoch: 18| Step: 0
Training loss: 2.409488826690181
Validation loss: 2.4720280448388543

Epoch: 6| Step: 1
Training loss: 1.9278908214838744
Validation loss: 2.4596528025238684

Epoch: 6| Step: 2
Training loss: 2.6138138164244125
Validation loss: 2.4508591167421483

Epoch: 6| Step: 3
Training loss: 2.438443319256781
Validation loss: 2.4643913131897595

Epoch: 6| Step: 4
Training loss: 2.8333479563017834
Validation loss: 2.4665246180495335

Epoch: 6| Step: 5
Training loss: 2.109812938298805
Validation loss: 2.4701085115193253

Epoch: 6| Step: 6
Training loss: 1.8419180351850197
Validation loss: 2.4593223478892794

Epoch: 6| Step: 7
Training loss: 2.7064755352386727
Validation loss: 2.4681742515875884

Epoch: 6| Step: 8
Training loss: 2.292705046324834
Validation loss: 2.4650266310470026

Epoch: 6| Step: 9
Training loss: 2.881126179382541
Validation loss: 2.4970848730540727

Epoch: 6| Step: 10
Training loss: 2.143272600317099
Validation loss: 2.4847905992974897

Epoch: 6| Step: 11
Training loss: 2.9179546963558827
Validation loss: 2.4872981374549763

Epoch: 6| Step: 12
Training loss: 2.9104188941359044
Validation loss: 2.48805143930958

Epoch: 6| Step: 13
Training loss: 2.5377763043384687
Validation loss: 2.4635492100240586

Epoch: 19| Step: 0
Training loss: 2.686009725739119
Validation loss: 2.4762962350600097

Epoch: 6| Step: 1
Training loss: 2.302623587572959
Validation loss: 2.464632600585849

Epoch: 6| Step: 2
Training loss: 2.1354712378499334
Validation loss: 2.4609705524142416

Epoch: 6| Step: 3
Training loss: 2.131483733037933
Validation loss: 2.4533170879990602

Epoch: 6| Step: 4
Training loss: 2.9679410133361106
Validation loss: 2.463724034167881

Epoch: 6| Step: 5
Training loss: 2.4533618399615538
Validation loss: 2.4555002364040255

Epoch: 6| Step: 6
Training loss: 2.233535929168637
Validation loss: 2.4586620407390245

Epoch: 6| Step: 7
Training loss: 2.5125026873673826
Validation loss: 2.4643556138702403

Epoch: 6| Step: 8
Training loss: 2.965666605232475
Validation loss: 2.4633635173577795

Epoch: 6| Step: 9
Training loss: 2.310976918718068
Validation loss: 2.4645391196388062

Epoch: 6| Step: 10
Training loss: 2.269112894759227
Validation loss: 2.4482569086063117

Epoch: 6| Step: 11
Training loss: 2.823240667426519
Validation loss: 2.4542950150282756

Epoch: 6| Step: 12
Training loss: 2.5202569433948554
Validation loss: 2.4476579948814385

Epoch: 6| Step: 13
Training loss: 2.154892203695094
Validation loss: 2.4621422296351687

Epoch: 20| Step: 0
Training loss: 2.803520958873984
Validation loss: 2.458657725531849

Epoch: 6| Step: 1
Training loss: 2.2978770866224782
Validation loss: 2.4464309783197096

Epoch: 6| Step: 2
Training loss: 2.221338186322086
Validation loss: 2.443413798627932

Epoch: 6| Step: 3
Training loss: 2.404778959779453
Validation loss: 2.452589895925577

Epoch: 6| Step: 4
Training loss: 2.1167102008257497
Validation loss: 2.4683618119619117

Epoch: 6| Step: 5
Training loss: 2.9193736094277725
Validation loss: 2.4619563501467017

Epoch: 6| Step: 6
Training loss: 2.187825750891937
Validation loss: 2.4673965381651315

Epoch: 6| Step: 7
Training loss: 2.364296334168312
Validation loss: 2.472354462714561

Epoch: 6| Step: 8
Training loss: 1.8948098518571261
Validation loss: 2.4701592008737276

Epoch: 6| Step: 9
Training loss: 2.2079586814870544
Validation loss: 2.4798952616152556

Epoch: 6| Step: 10
Training loss: 3.2239261229122627
Validation loss: 2.4681804498964284

Epoch: 6| Step: 11
Training loss: 2.357297070730648
Validation loss: 2.479270377247161

Epoch: 6| Step: 12
Training loss: 2.88841270124947
Validation loss: 2.4718532453593243

Epoch: 6| Step: 13
Training loss: 2.376216877842427
Validation loss: 2.4707747095968284

Epoch: 21| Step: 0
Training loss: 2.4450972099716073
Validation loss: 2.4661997245746554

Epoch: 6| Step: 1
Training loss: 2.4911678703769518
Validation loss: 2.4648522136561057

Epoch: 6| Step: 2
Training loss: 2.80781920129213
Validation loss: 2.4626548950741487

Epoch: 6| Step: 3
Training loss: 2.162510063721277
Validation loss: 2.466280245046872

Epoch: 6| Step: 4
Training loss: 2.3613691176523517
Validation loss: 2.4426954603906594

Epoch: 6| Step: 5
Training loss: 3.153518854803716
Validation loss: 2.470579869509272

Epoch: 6| Step: 6
Training loss: 2.037271348725997
Validation loss: 2.4581066097085973

Epoch: 6| Step: 7
Training loss: 2.332319641172679
Validation loss: 2.464206780511476

Epoch: 6| Step: 8
Training loss: 2.0909343405092375
Validation loss: 2.4647806827559555

Epoch: 6| Step: 9
Training loss: 1.9989850926227424
Validation loss: 2.4703578863573035

Epoch: 6| Step: 10
Training loss: 2.371105212917617
Validation loss: 2.4694234758332394

Epoch: 6| Step: 11
Training loss: 2.7588766924688835
Validation loss: 2.4752675229766044

Epoch: 6| Step: 12
Training loss: 2.395070548880043
Validation loss: 2.4841758920147843

Epoch: 6| Step: 13
Training loss: 2.77755388841105
Validation loss: 2.474308837689547

Epoch: 22| Step: 0
Training loss: 2.798142811793285
Validation loss: 2.459456418930295

Epoch: 6| Step: 1
Training loss: 2.2196014275042173
Validation loss: 2.455052317238621

Epoch: 6| Step: 2
Training loss: 2.3049978273592493
Validation loss: 2.4468960088393903

Epoch: 6| Step: 3
Training loss: 1.6538960985855133
Validation loss: 2.4545209440030784

Epoch: 6| Step: 4
Training loss: 2.8512061327511886
Validation loss: 2.4613002610648707

Epoch: 6| Step: 5
Training loss: 2.265864602935098
Validation loss: 2.455493156497103

Epoch: 6| Step: 6
Training loss: 2.3675004103921053
Validation loss: 2.4483401371874534

Epoch: 6| Step: 7
Training loss: 2.523964747096556
Validation loss: 2.4438012991721756

Epoch: 6| Step: 8
Training loss: 2.42596149849904
Validation loss: 2.440595356870696

Epoch: 6| Step: 9
Training loss: 2.526808999044322
Validation loss: 2.4430190473697

Epoch: 6| Step: 10
Training loss: 2.317643605446371
Validation loss: 2.445079317035013

Epoch: 6| Step: 11
Training loss: 2.052012163144773
Validation loss: 2.4370180533863146

Epoch: 6| Step: 12
Training loss: 2.635379253217376
Validation loss: 2.445677676167724

Epoch: 6| Step: 13
Training loss: 3.0216226182417802
Validation loss: 2.4440502609936945

Epoch: 23| Step: 0
Training loss: 2.5301355805086048
Validation loss: 2.447796957998367

Epoch: 6| Step: 1
Training loss: 2.415034718708184
Validation loss: 2.443909166230788

Epoch: 6| Step: 2
Training loss: 1.9488169651625686
Validation loss: 2.455243307670264

Epoch: 6| Step: 3
Training loss: 2.1054150746144034
Validation loss: 2.438698351776045

Epoch: 6| Step: 4
Training loss: 1.8213644630839962
Validation loss: 2.443552580303944

Epoch: 6| Step: 5
Training loss: 2.3675319307745997
Validation loss: 2.4461755336628404

Epoch: 6| Step: 6
Training loss: 2.8212599074460596
Validation loss: 2.446215153210259

Epoch: 6| Step: 7
Training loss: 2.507884562279964
Validation loss: 2.4473619089469922

Epoch: 6| Step: 8
Training loss: 2.9443639548314575
Validation loss: 2.4374884906725307

Epoch: 6| Step: 9
Training loss: 2.630128482827719
Validation loss: 2.443010133970803

Epoch: 6| Step: 10
Training loss: 2.5523813086701277
Validation loss: 2.4577719052715787

Epoch: 6| Step: 11
Training loss: 2.145626156876361
Validation loss: 2.461104008930121

Epoch: 6| Step: 12
Training loss: 2.6732830776650043
Validation loss: 2.469626749861791

Epoch: 6| Step: 13
Training loss: 2.496075028661209
Validation loss: 2.4781230738898126

Epoch: 24| Step: 0
Training loss: 2.723848144947849
Validation loss: 2.4619781715795095

Epoch: 6| Step: 1
Training loss: 1.8231964841160135
Validation loss: 2.460109478548401

Epoch: 6| Step: 2
Training loss: 2.5846963076141063
Validation loss: 2.458145608577149

Epoch: 6| Step: 3
Training loss: 2.94698053779816
Validation loss: 2.4453111999963264

Epoch: 6| Step: 4
Training loss: 1.5406988130107453
Validation loss: 2.443295322211881

Epoch: 6| Step: 5
Training loss: 2.431167201027232
Validation loss: 2.443067737050422

Epoch: 6| Step: 6
Training loss: 2.6380827815824297
Validation loss: 2.4343039107644664

Epoch: 6| Step: 7
Training loss: 2.332484726768935
Validation loss: 2.4374657979016545

Epoch: 6| Step: 8
Training loss: 2.04466944086471
Validation loss: 2.44377142920371

Epoch: 6| Step: 9
Training loss: 2.1911236857921117
Validation loss: 2.445179977319746

Epoch: 6| Step: 10
Training loss: 2.678721262056297
Validation loss: 2.4371320006538095

Epoch: 6| Step: 11
Training loss: 2.6523942675716543
Validation loss: 2.4538566972177795

Epoch: 6| Step: 12
Training loss: 2.5339490840707204
Validation loss: 2.438200906906562

Epoch: 6| Step: 13
Training loss: 2.6923427862458196
Validation loss: 2.451739152614314

Epoch: 25| Step: 0
Training loss: 2.497892540525403
Validation loss: 2.4536090705291396

Epoch: 6| Step: 1
Training loss: 2.1131131427909486
Validation loss: 2.45267925545798

Epoch: 6| Step: 2
Training loss: 2.5004048973263773
Validation loss: 2.439840138962307

Epoch: 6| Step: 3
Training loss: 2.536454583908746
Validation loss: 2.4438115755276515

Epoch: 6| Step: 4
Training loss: 2.5770525927137755
Validation loss: 2.443408675881825

Epoch: 6| Step: 5
Training loss: 1.5665217711357027
Validation loss: 2.452699417810468

Epoch: 6| Step: 6
Training loss: 2.733269080903274
Validation loss: 2.4643444879603535

Epoch: 6| Step: 7
Training loss: 3.2381039560558595
Validation loss: 2.441421313430092

Epoch: 6| Step: 8
Training loss: 2.3240594376531925
Validation loss: 2.4411090476653827

Epoch: 6| Step: 9
Training loss: 2.8097622580092434
Validation loss: 2.4610666069597578

Epoch: 6| Step: 10
Training loss: 2.294203573591249
Validation loss: 2.4518022149755576

Epoch: 6| Step: 11
Training loss: 1.8920293589122665
Validation loss: 2.469628736982765

Epoch: 6| Step: 12
Training loss: 2.188298324959601
Validation loss: 2.445927023731373

Epoch: 6| Step: 13
Training loss: 2.3777748762491333
Validation loss: 2.451950002419841

Epoch: 26| Step: 0
Training loss: 2.5026918224553367
Validation loss: 2.453772927020208

Epoch: 6| Step: 1
Training loss: 2.6831946374656486
Validation loss: 2.4585123212494073

Epoch: 6| Step: 2
Training loss: 1.552016988612133
Validation loss: 2.445531410761705

Epoch: 6| Step: 3
Training loss: 2.6459564921232603
Validation loss: 2.44792810532082

Epoch: 6| Step: 4
Training loss: 1.9633050130065577
Validation loss: 2.4457513579928563

Epoch: 6| Step: 5
Training loss: 2.032519838581182
Validation loss: 2.4504159113724917

Epoch: 6| Step: 6
Training loss: 2.4187458127007724
Validation loss: 2.4307266580816522

Epoch: 6| Step: 7
Training loss: 2.2707421754044743
Validation loss: 2.431881027900482

Epoch: 6| Step: 8
Training loss: 3.0173666870705595
Validation loss: 2.440713606173163

Epoch: 6| Step: 9
Training loss: 2.1726779688380913
Validation loss: 2.4325935835314008

Epoch: 6| Step: 10
Training loss: 2.4620374370985516
Validation loss: 2.443446071681439

Epoch: 6| Step: 11
Training loss: 2.8352611565437256
Validation loss: 2.447581026049839

Epoch: 6| Step: 12
Training loss: 2.148313206631906
Validation loss: 2.4445618928764805

Epoch: 6| Step: 13
Training loss: 2.803633127757156
Validation loss: 2.4374454524791815

Epoch: 27| Step: 0
Training loss: 2.2919358066536875
Validation loss: 2.45217577474536

Epoch: 6| Step: 1
Training loss: 2.502387432725867
Validation loss: 2.4441446881542195

Epoch: 6| Step: 2
Training loss: 2.3118999836879657
Validation loss: 2.44697368125652

Epoch: 6| Step: 3
Training loss: 2.3111826263065223
Validation loss: 2.4437096718454914

Epoch: 6| Step: 4
Training loss: 2.6512055012279245
Validation loss: 2.4659223337754095

Epoch: 6| Step: 5
Training loss: 2.139368621344144
Validation loss: 2.4750050201108222

Epoch: 6| Step: 6
Training loss: 2.430093026127005
Validation loss: 2.464327670004115

Epoch: 6| Step: 7
Training loss: 3.2598238437543783
Validation loss: 2.467642378714036

Epoch: 6| Step: 8
Training loss: 1.851710446398417
Validation loss: 2.458485361560074

Epoch: 6| Step: 9
Training loss: 2.530366343033367
Validation loss: 2.4444074123701007

Epoch: 6| Step: 10
Training loss: 2.128934023614705
Validation loss: 2.457402850637156

Epoch: 6| Step: 11
Training loss: 2.851265000801813
Validation loss: 2.4518733952141276

Epoch: 6| Step: 12
Training loss: 2.6950920567687495
Validation loss: 2.4453512804167676

Epoch: 6| Step: 13
Training loss: 1.5907287383960018
Validation loss: 2.4486856483726327

Epoch: 28| Step: 0
Training loss: 2.9355720524015942
Validation loss: 2.4476799924891974

Epoch: 6| Step: 1
Training loss: 1.9907265486034733
Validation loss: 2.440527706510775

Epoch: 6| Step: 2
Training loss: 2.016693423490384
Validation loss: 2.4352456615009777

Epoch: 6| Step: 3
Training loss: 2.682285839679401
Validation loss: 2.45082084502984

Epoch: 6| Step: 4
Training loss: 2.2337433248888727
Validation loss: 2.4522532880337593

Epoch: 6| Step: 5
Training loss: 2.1072211678202795
Validation loss: 2.447839327192428

Epoch: 6| Step: 6
Training loss: 2.089715971560938
Validation loss: 2.449936984023806

Epoch: 6| Step: 7
Training loss: 2.4931956198428775
Validation loss: 2.4511190421399878

Epoch: 6| Step: 8
Training loss: 2.448833331821959
Validation loss: 2.4561782269915584

Epoch: 6| Step: 9
Training loss: 2.315922652868576
Validation loss: 2.448327575176506

Epoch: 6| Step: 10
Training loss: 2.0903835276921505
Validation loss: 2.4496343362499924

Epoch: 6| Step: 11
Training loss: 2.7177286092972426
Validation loss: 2.442584513852075

Epoch: 6| Step: 12
Training loss: 2.7693062113812945
Validation loss: 2.443289312856912

Epoch: 6| Step: 13
Training loss: 2.651732698821613
Validation loss: 2.4336668506662824

Epoch: 29| Step: 0
Training loss: 2.255557085401061
Validation loss: 2.4586745095441658

Epoch: 6| Step: 1
Training loss: 2.477320606192153
Validation loss: 2.4442082472198408

Epoch: 6| Step: 2
Training loss: 1.2756167995520113
Validation loss: 2.431330412619304

Epoch: 6| Step: 3
Training loss: 2.2777752475672783
Validation loss: 2.4400714612877215

Epoch: 6| Step: 4
Training loss: 2.733960539878376
Validation loss: 2.4411253256343666

Epoch: 6| Step: 5
Training loss: 2.0570436609852165
Validation loss: 2.429946869215683

Epoch: 6| Step: 6
Training loss: 2.6487129540798398
Validation loss: 2.436704489505285

Epoch: 6| Step: 7
Training loss: 2.5005805295209234
Validation loss: 2.4330791012889756

Epoch: 6| Step: 8
Training loss: 2.1887875718530765
Validation loss: 2.4332590296474645

Epoch: 6| Step: 9
Training loss: 2.659522430600729
Validation loss: 2.4526726372450773

Epoch: 6| Step: 10
Training loss: 2.100544395727653
Validation loss: 2.443050829552879

Epoch: 6| Step: 11
Training loss: 2.973703367902703
Validation loss: 2.446401806414128

Epoch: 6| Step: 12
Training loss: 2.488763927073958
Validation loss: 2.451852699351455

Epoch: 6| Step: 13
Training loss: 2.688062919391203
Validation loss: 2.4427420173930767

Epoch: 30| Step: 0
Training loss: 2.353465884620906
Validation loss: 2.437602407798417

Epoch: 6| Step: 1
Training loss: 1.9282127026561593
Validation loss: 2.4423122017023764

Epoch: 6| Step: 2
Training loss: 2.0817557147210923
Validation loss: 2.452358798422108

Epoch: 6| Step: 3
Training loss: 3.0994667640574214
Validation loss: 2.4503056225272504

Epoch: 6| Step: 4
Training loss: 2.6382059607862915
Validation loss: 2.443289044509187

Epoch: 6| Step: 5
Training loss: 2.3379457956431495
Validation loss: 2.4600520564466617

Epoch: 6| Step: 6
Training loss: 2.7641183660973847
Validation loss: 2.4672502718689637

Epoch: 6| Step: 7
Training loss: 2.157437094504019
Validation loss: 2.4496855141440697

Epoch: 6| Step: 8
Training loss: 2.351685682346488
Validation loss: 2.442532943144212

Epoch: 6| Step: 9
Training loss: 1.9424165671950793
Validation loss: 2.439160303195081

Epoch: 6| Step: 10
Training loss: 2.181678218398124
Validation loss: 2.4436235699221527

Epoch: 6| Step: 11
Training loss: 2.559967091766082
Validation loss: 2.453606989458662

Epoch: 6| Step: 12
Training loss: 1.800228869934631
Validation loss: 2.4521158495496973

Epoch: 6| Step: 13
Training loss: 3.154313352559516
Validation loss: 2.453050178958034

Epoch: 31| Step: 0
Training loss: 2.202929332512273
Validation loss: 2.442405817512525

Epoch: 6| Step: 1
Training loss: 2.4644134677919562
Validation loss: 2.4423536735910476

Epoch: 6| Step: 2
Training loss: 1.5816190959796408
Validation loss: 2.4246500995064046

Epoch: 6| Step: 3
Training loss: 2.385037443398907
Validation loss: 2.430411816539881

Epoch: 6| Step: 4
Training loss: 2.2707893180664467
Validation loss: 2.449974872174799

Epoch: 6| Step: 5
Training loss: 3.209783119171627
Validation loss: 2.440155441304564

Epoch: 6| Step: 6
Training loss: 2.496571096705592
Validation loss: 2.442088869413245

Epoch: 6| Step: 7
Training loss: 3.051509521149494
Validation loss: 2.437436388277948

Epoch: 6| Step: 8
Training loss: 2.316203065037427
Validation loss: 2.445611255014726

Epoch: 6| Step: 9
Training loss: 2.1738615761759688
Validation loss: 2.423620271953866

Epoch: 6| Step: 10
Training loss: 2.315944271754622
Validation loss: 2.425827296214671

Epoch: 6| Step: 11
Training loss: 2.160516470869509
Validation loss: 2.4139930031987653

Epoch: 6| Step: 12
Training loss: 2.64216668082979
Validation loss: 2.4243121118625948

Epoch: 6| Step: 13
Training loss: 2.025996059764107
Validation loss: 2.434852466435051

Epoch: 32| Step: 0
Training loss: 2.3971689454316514
Validation loss: 2.4248280436384064

Epoch: 6| Step: 1
Training loss: 2.1029792179635356
Validation loss: 2.429580498043162

Epoch: 6| Step: 2
Training loss: 2.297585721248366
Validation loss: 2.427334888394193

Epoch: 6| Step: 3
Training loss: 2.2698045785953043
Validation loss: 2.44257986927931

Epoch: 6| Step: 4
Training loss: 2.5453193453701974
Validation loss: 2.4628348650507945

Epoch: 6| Step: 5
Training loss: 2.5126790870115943
Validation loss: 2.4356285475125157

Epoch: 6| Step: 6
Training loss: 2.865486492774132
Validation loss: 2.445420211028521

Epoch: 6| Step: 7
Training loss: 2.1223910528647916
Validation loss: 2.452660040719526

Epoch: 6| Step: 8
Training loss: 2.6179455015310795
Validation loss: 2.4420372556947387

Epoch: 6| Step: 9
Training loss: 2.127120810940445
Validation loss: 2.4496416439671815

Epoch: 6| Step: 10
Training loss: 2.4103499323894497
Validation loss: 2.446589427992597

Epoch: 6| Step: 11
Training loss: 2.344528984315331
Validation loss: 2.4469246633141526

Epoch: 6| Step: 12
Training loss: 2.4294650353151006
Validation loss: 2.4386288971245147

Epoch: 6| Step: 13
Training loss: 2.480910662837334
Validation loss: 2.4442913779346283

Epoch: 33| Step: 0
Training loss: 2.3623596916718026
Validation loss: 2.430089804817456

Epoch: 6| Step: 1
Training loss: 2.2331123252186527
Validation loss: 2.4642692819419985

Epoch: 6| Step: 2
Training loss: 1.5413134230336416
Validation loss: 2.467170604465157

Epoch: 6| Step: 3
Training loss: 2.0676939328810833
Validation loss: 2.4805607495805906

Epoch: 6| Step: 4
Training loss: 2.4864215218981083
Validation loss: 2.4941004523594588

Epoch: 6| Step: 5
Training loss: 2.5383412437123676
Validation loss: 2.506259330294548

Epoch: 6| Step: 6
Training loss: 2.951241028516383
Validation loss: 2.479722695280153

Epoch: 6| Step: 7
Training loss: 2.2388267717771018
Validation loss: 2.483077728208145

Epoch: 6| Step: 8
Training loss: 2.7210269907741607
Validation loss: 2.4755988828582676

Epoch: 6| Step: 9
Training loss: 2.133278708453988
Validation loss: 2.447564596194586

Epoch: 6| Step: 10
Training loss: 2.4748483014096507
Validation loss: 2.4428041570829317

Epoch: 6| Step: 11
Training loss: 2.9919022307104024
Validation loss: 2.4267178752844294

Epoch: 6| Step: 12
Training loss: 2.2513046720602765
Validation loss: 2.444730476119653

Epoch: 6| Step: 13
Training loss: 2.5324792585060165
Validation loss: 2.442832461025015

Epoch: 34| Step: 0
Training loss: 2.410495629057198
Validation loss: 2.4347906623743167

Epoch: 6| Step: 1
Training loss: 2.490420393634382
Validation loss: 2.4187015702740893

Epoch: 6| Step: 2
Training loss: 2.0727584497336835
Validation loss: 2.4314797712077225

Epoch: 6| Step: 3
Training loss: 2.5462645752854347
Validation loss: 2.4369525294605383

Epoch: 6| Step: 4
Training loss: 2.1948056976589236
Validation loss: 2.438346960177862

Epoch: 6| Step: 5
Training loss: 2.422414313534081
Validation loss: 2.435922878662755

Epoch: 6| Step: 6
Training loss: 3.099463225622673
Validation loss: 2.436072461343483

Epoch: 6| Step: 7
Training loss: 1.999455079707577
Validation loss: 2.4291242005795057

Epoch: 6| Step: 8
Training loss: 2.518827307487325
Validation loss: 2.440032605099274

Epoch: 6| Step: 9
Training loss: 2.4663133789209417
Validation loss: 2.4393242587403536

Epoch: 6| Step: 10
Training loss: 2.2252729998493765
Validation loss: 2.4366195751480677

Epoch: 6| Step: 11
Training loss: 2.74541785223117
Validation loss: 2.4175292043358505

Epoch: 6| Step: 12
Training loss: 2.330498733353204
Validation loss: 2.4333980802082653

Epoch: 6| Step: 13
Training loss: 1.9405679101578295
Validation loss: 2.432713038494498

Epoch: 35| Step: 0
Training loss: 2.338284235479843
Validation loss: 2.4511809451478728

Epoch: 6| Step: 1
Training loss: 1.6669128077266766
Validation loss: 2.448908435849197

Epoch: 6| Step: 2
Training loss: 2.409368896476644
Validation loss: 2.459975661167707

Epoch: 6| Step: 3
Training loss: 1.5586231200240286
Validation loss: 2.463384906924059

Epoch: 6| Step: 4
Training loss: 2.348913379811383
Validation loss: 2.472362924767567

Epoch: 6| Step: 5
Training loss: 2.034281888785217
Validation loss: 2.5022256480920593

Epoch: 6| Step: 6
Training loss: 2.8552239309165772
Validation loss: 2.4892359747963257

Epoch: 6| Step: 7
Training loss: 3.1137076245046575
Validation loss: 2.508194384311872

Epoch: 6| Step: 8
Training loss: 2.828822940251815
Validation loss: 2.526606519540137

Epoch: 6| Step: 9
Training loss: 2.6027490241291
Validation loss: 2.4989232128538132

Epoch: 6| Step: 10
Training loss: 2.615500928700318
Validation loss: 2.4765435989252285

Epoch: 6| Step: 11
Training loss: 2.3783062458522997
Validation loss: 2.4803068493648985

Epoch: 6| Step: 12
Training loss: 2.384275593816555
Validation loss: 2.4459392081701843

Epoch: 6| Step: 13
Training loss: 1.9733376714083097
Validation loss: 2.4521324352662393

Epoch: 36| Step: 0
Training loss: 1.7260542591888768
Validation loss: 2.4505366217779914

Epoch: 6| Step: 1
Training loss: 2.9380693898378154
Validation loss: 2.4368748311449324

Epoch: 6| Step: 2
Training loss: 2.0420400576496776
Validation loss: 2.441841473251203

Epoch: 6| Step: 3
Training loss: 2.30562238966602
Validation loss: 2.425510278741209

Epoch: 6| Step: 4
Training loss: 2.327154789450521
Validation loss: 2.412271281585978

Epoch: 6| Step: 5
Training loss: 2.7082229787400602
Validation loss: 2.4288476798872147

Epoch: 6| Step: 6
Training loss: 2.758971665002182
Validation loss: 2.4282755781735474

Epoch: 6| Step: 7
Training loss: 2.9937528096546218
Validation loss: 2.4315305958153246

Epoch: 6| Step: 8
Training loss: 2.4835727763962825
Validation loss: 2.4407563750938435

Epoch: 6| Step: 9
Training loss: 1.6596778090461075
Validation loss: 2.42963168130194

Epoch: 6| Step: 10
Training loss: 2.278784896240213
Validation loss: 2.436975129177083

Epoch: 6| Step: 11
Training loss: 1.785721637165741
Validation loss: 2.43284803694077

Epoch: 6| Step: 12
Training loss: 2.8718083121741533
Validation loss: 2.4224070631111543

Epoch: 6| Step: 13
Training loss: 1.8530201385317757
Validation loss: 2.4282730908362433

Epoch: 37| Step: 0
Training loss: 2.723967533327009
Validation loss: 2.421155022691781

Epoch: 6| Step: 1
Training loss: 2.2711692584922454
Validation loss: 2.440810002061015

Epoch: 6| Step: 2
Training loss: 2.055615117811027
Validation loss: 2.426508992447099

Epoch: 6| Step: 3
Training loss: 2.1282850566617406
Validation loss: 2.441596558337913

Epoch: 6| Step: 4
Training loss: 2.429635982641884
Validation loss: 2.4206473079342605

Epoch: 6| Step: 5
Training loss: 2.268032820240427
Validation loss: 2.431004517885145

Epoch: 6| Step: 6
Training loss: 2.419568938964714
Validation loss: 2.4452022084804077

Epoch: 6| Step: 7
Training loss: 2.296524955389673
Validation loss: 2.4390266234980804

Epoch: 6| Step: 8
Training loss: 3.0584241252453546
Validation loss: 2.4438619160371102

Epoch: 6| Step: 9
Training loss: 1.4574644043176166
Validation loss: 2.4408850680679683

Epoch: 6| Step: 10
Training loss: 2.899070485548046
Validation loss: 2.465461939587881

Epoch: 6| Step: 11
Training loss: 2.4982740166230344
Validation loss: 2.462805048448829

Epoch: 6| Step: 12
Training loss: 2.0631913846951697
Validation loss: 2.468374988385589

Epoch: 6| Step: 13
Training loss: 2.3089444431445987
Validation loss: 2.4923303417697875

Epoch: 38| Step: 0
Training loss: 2.571536992830001
Validation loss: 2.4779840635331674

Epoch: 6| Step: 1
Training loss: 2.2633329175556383
Validation loss: 2.482744333536992

Epoch: 6| Step: 2
Training loss: 1.4510119261458552
Validation loss: 2.4531254211555007

Epoch: 6| Step: 3
Training loss: 2.5693164507171518
Validation loss: 2.4746569694392075

Epoch: 6| Step: 4
Training loss: 2.393740749092254
Validation loss: 2.471902854045535

Epoch: 6| Step: 5
Training loss: 2.46439140993518
Validation loss: 2.487436060187522

Epoch: 6| Step: 6
Training loss: 3.012143670372779
Validation loss: 2.4699462052843777

Epoch: 6| Step: 7
Training loss: 2.150520785045246
Validation loss: 2.467321296335107

Epoch: 6| Step: 8
Training loss: 2.4088126074152845
Validation loss: 2.458383160964393

Epoch: 6| Step: 9
Training loss: 1.9915421581321842
Validation loss: 2.4440338724372803

Epoch: 6| Step: 10
Training loss: 1.881764353651147
Validation loss: 2.4319433960863033

Epoch: 6| Step: 11
Training loss: 2.796223058319243
Validation loss: 2.425639190855111

Epoch: 6| Step: 12
Training loss: 2.712053492488333
Validation loss: 2.4257957634156377

Epoch: 6| Step: 13
Training loss: 2.195936555505291
Validation loss: 2.434944900317499

Epoch: 39| Step: 0
Training loss: 2.5530246374044916
Validation loss: 2.428937512075212

Epoch: 6| Step: 1
Training loss: 2.5674539456791807
Validation loss: 2.4304399214591808

Epoch: 6| Step: 2
Training loss: 2.7061940669739486
Validation loss: 2.4439775115480535

Epoch: 6| Step: 3
Training loss: 2.546257646312291
Validation loss: 2.42798154743479

Epoch: 6| Step: 4
Training loss: 2.110138931401071
Validation loss: 2.4343495998926445

Epoch: 6| Step: 5
Training loss: 2.1020543540365977
Validation loss: 2.4239795031987152

Epoch: 6| Step: 6
Training loss: 2.422541963353573
Validation loss: 2.4335409110728077

Epoch: 6| Step: 7
Training loss: 2.6019121914472736
Validation loss: 2.4274415064324164

Epoch: 6| Step: 8
Training loss: 1.7915099615128316
Validation loss: 2.436775417714665

Epoch: 6| Step: 9
Training loss: 2.323395193672972
Validation loss: 2.4317805687851166

Epoch: 6| Step: 10
Training loss: 2.2986752468149616
Validation loss: 2.4482731228205266

Epoch: 6| Step: 11
Training loss: 2.088699854871502
Validation loss: 2.4427754136061224

Epoch: 6| Step: 12
Training loss: 2.762000429715531
Validation loss: 2.442804230283205

Epoch: 6| Step: 13
Training loss: 2.138243972960717
Validation loss: 2.435333348641899

Epoch: 40| Step: 0
Training loss: 2.1022909383898867
Validation loss: 2.446833843146527

Epoch: 6| Step: 1
Training loss: 2.7155324378003387
Validation loss: 2.452548337894913

Epoch: 6| Step: 2
Training loss: 1.7262954160114905
Validation loss: 2.456626466562802

Epoch: 6| Step: 3
Training loss: 2.846142443675717
Validation loss: 2.4540711945085403

Epoch: 6| Step: 4
Training loss: 2.104552910231846
Validation loss: 2.457418761956042

Epoch: 6| Step: 5
Training loss: 1.8595009128027755
Validation loss: 2.446487566926415

Epoch: 6| Step: 6
Training loss: 2.9280257331363555
Validation loss: 2.4609139900497388

Epoch: 6| Step: 7
Training loss: 1.9781548640933195
Validation loss: 2.477373345425948

Epoch: 6| Step: 8
Training loss: 2.3240250707117758
Validation loss: 2.495648682205918

Epoch: 6| Step: 9
Training loss: 1.7069457707073596
Validation loss: 2.4734430412251296

Epoch: 6| Step: 10
Training loss: 1.986380097225986
Validation loss: 2.5110715800618055

Epoch: 6| Step: 11
Training loss: 3.2118977319818964
Validation loss: 2.506735803288168

Epoch: 6| Step: 12
Training loss: 2.853528826276359
Validation loss: 2.4969497192050216

Epoch: 6| Step: 13
Training loss: 2.3824231439384738
Validation loss: 2.479708609664408

Epoch: 41| Step: 0
Training loss: 2.0458144141084444
Validation loss: 2.4538574745037285

Epoch: 6| Step: 1
Training loss: 2.172274106905532
Validation loss: 2.4518451875366325

Epoch: 6| Step: 2
Training loss: 2.2275991067984227
Validation loss: 2.449823559356832

Epoch: 6| Step: 3
Training loss: 2.290298076370298
Validation loss: 2.433979026377558

Epoch: 6| Step: 4
Training loss: 2.093779264786443
Validation loss: 2.4326953974907455

Epoch: 6| Step: 5
Training loss: 2.068638999703958
Validation loss: 2.442561608132642

Epoch: 6| Step: 6
Training loss: 2.336537567940324
Validation loss: 2.438743803784509

Epoch: 6| Step: 7
Training loss: 2.0631050609513792
Validation loss: 2.444069640970181

Epoch: 6| Step: 8
Training loss: 2.1658343281388306
Validation loss: 2.432372413836059

Epoch: 6| Step: 9
Training loss: 2.5943853680158346
Validation loss: 2.437872898889216

Epoch: 6| Step: 10
Training loss: 2.9696416218636026
Validation loss: 2.4355150112095942

Epoch: 6| Step: 11
Training loss: 2.7640125293861746
Validation loss: 2.4277016230097925

Epoch: 6| Step: 12
Training loss: 2.396126195727097
Validation loss: 2.4318444264912538

Epoch: 6| Step: 13
Training loss: 2.3821700433849355
Validation loss: 2.4270391391992754

Epoch: 42| Step: 0
Training loss: 2.25931032122504
Validation loss: 2.430621680011151

Epoch: 6| Step: 1
Training loss: 2.5273999734134587
Validation loss: 2.437877707275761

Epoch: 6| Step: 2
Training loss: 2.5916247565835544
Validation loss: 2.4379917610541417

Epoch: 6| Step: 3
Training loss: 2.160908407703662
Validation loss: 2.43094542752201

Epoch: 6| Step: 4
Training loss: 2.198044783728679
Validation loss: 2.430533177106258

Epoch: 6| Step: 5
Training loss: 2.758401521452641
Validation loss: 2.4306355105979045

Epoch: 6| Step: 6
Training loss: 2.0920592356331476
Validation loss: 2.4354664723764237

Epoch: 6| Step: 7
Training loss: 2.312964315453342
Validation loss: 2.440203626323042

Epoch: 6| Step: 8
Training loss: 1.8791359108764354
Validation loss: 2.454202038931557

Epoch: 6| Step: 9
Training loss: 2.5393192102799476
Validation loss: 2.450415700561907

Epoch: 6| Step: 10
Training loss: 2.2661991838753526
Validation loss: 2.454373230415019

Epoch: 6| Step: 11
Training loss: 2.6454282335357053
Validation loss: 2.436534274579795

Epoch: 6| Step: 12
Training loss: 2.4908790142949497
Validation loss: 2.4340766848011532

Epoch: 6| Step: 13
Training loss: 2.272179534104882
Validation loss: 2.4272983002866004

Epoch: 43| Step: 0
Training loss: 2.5861233647328556
Validation loss: 2.428996099162146

Epoch: 6| Step: 1
Training loss: 1.8181889799367132
Validation loss: 2.437633005409612

Epoch: 6| Step: 2
Training loss: 2.055739101027988
Validation loss: 2.4508669963765715

Epoch: 6| Step: 3
Training loss: 2.022269010992312
Validation loss: 2.448692382840866

Epoch: 6| Step: 4
Training loss: 2.9925863533021424
Validation loss: 2.45314111724548

Epoch: 6| Step: 5
Training loss: 2.310198076351363
Validation loss: 2.4468516582936317

Epoch: 6| Step: 6
Training loss: 2.4243635620571173
Validation loss: 2.4544858134534437

Epoch: 6| Step: 7
Training loss: 2.2109985343138048
Validation loss: 2.441841635982604

Epoch: 6| Step: 8
Training loss: 2.297148396316552
Validation loss: 2.460643577179349

Epoch: 6| Step: 9
Training loss: 2.8549333271318553
Validation loss: 2.4744673088259055

Epoch: 6| Step: 10
Training loss: 2.450777911255994
Validation loss: 2.4513812660864827

Epoch: 6| Step: 11
Training loss: 1.4290685929586227
Validation loss: 2.444009842192566

Epoch: 6| Step: 12
Training loss: 2.5548207659478117
Validation loss: 2.458376566188859

Epoch: 6| Step: 13
Training loss: 2.5933372444901317
Validation loss: 2.466126589245152

Epoch: 44| Step: 0
Training loss: 1.9898209221934222
Validation loss: 2.442133135606426

Epoch: 6| Step: 1
Training loss: 2.023126055340378
Validation loss: 2.4414374021450005

Epoch: 6| Step: 2
Training loss: 3.006525889087425
Validation loss: 2.430398311675387

Epoch: 6| Step: 3
Training loss: 2.1069525478036493
Validation loss: 2.441234075960179

Epoch: 6| Step: 4
Training loss: 2.4762534541376047
Validation loss: 2.435448296577851

Epoch: 6| Step: 5
Training loss: 1.8296505684061293
Validation loss: 2.4408842378124627

Epoch: 6| Step: 6
Training loss: 2.197420458954407
Validation loss: 2.424648468847985

Epoch: 6| Step: 7
Training loss: 2.4437826325171956
Validation loss: 2.4388355280668312

Epoch: 6| Step: 8
Training loss: 1.8389413487435242
Validation loss: 2.4335199776576597

Epoch: 6| Step: 9
Training loss: 2.624585800189926
Validation loss: 2.424235016480059

Epoch: 6| Step: 10
Training loss: 2.0061792046245808
Validation loss: 2.421278037055126

Epoch: 6| Step: 11
Training loss: 3.2462330041204708
Validation loss: 2.423421714496831

Epoch: 6| Step: 12
Training loss: 2.366306455717561
Validation loss: 2.4382677417867002

Epoch: 6| Step: 13
Training loss: 2.0977610414496515
Validation loss: 2.4233862069049326

Epoch: 45| Step: 0
Training loss: 2.785601180438866
Validation loss: 2.43454693965248

Epoch: 6| Step: 1
Training loss: 2.3586199227972413
Validation loss: 2.455376306764533

Epoch: 6| Step: 2
Training loss: 1.679837810089649
Validation loss: 2.448037754608139

Epoch: 6| Step: 3
Training loss: 2.1786600514774133
Validation loss: 2.454076060213072

Epoch: 6| Step: 4
Training loss: 2.0307163417815914
Validation loss: 2.4524018381949366

Epoch: 6| Step: 5
Training loss: 1.9187785690119155
Validation loss: 2.4798393191818633

Epoch: 6| Step: 6
Training loss: 3.0262680800668735
Validation loss: 2.475769060272803

Epoch: 6| Step: 7
Training loss: 2.128196331962907
Validation loss: 2.49852144705867

Epoch: 6| Step: 8
Training loss: 2.1565513953053057
Validation loss: 2.4988368189405388

Epoch: 6| Step: 9
Training loss: 3.0619194881884857
Validation loss: 2.4961297515676693

Epoch: 6| Step: 10
Training loss: 2.0645076343915365
Validation loss: 2.4791805897383186

Epoch: 6| Step: 11
Training loss: 2.0070193612951943
Validation loss: 2.481975780455986

Epoch: 6| Step: 12
Training loss: 2.5401699057394596
Validation loss: 2.464739515676995

Epoch: 6| Step: 13
Training loss: 2.56190967738294
Validation loss: 2.4410881140377167

Epoch: 46| Step: 0
Training loss: 2.2428962039409743
Validation loss: 2.460562993370435

Epoch: 6| Step: 1
Training loss: 2.531011216945503
Validation loss: 2.42346377199658

Epoch: 6| Step: 2
Training loss: 2.442938972001317
Validation loss: 2.44379850243504

Epoch: 6| Step: 3
Training loss: 1.8379582099771241
Validation loss: 2.4351819664147265

Epoch: 6| Step: 4
Training loss: 2.662314996873609
Validation loss: 2.4356519915532506

Epoch: 6| Step: 5
Training loss: 2.3838000643053165
Validation loss: 2.443140903934121

Epoch: 6| Step: 6
Training loss: 2.129257201218977
Validation loss: 2.426328809186377

Epoch: 6| Step: 7
Training loss: 2.6689819378089816
Validation loss: 2.436087533287435

Epoch: 6| Step: 8
Training loss: 1.7086684975933655
Validation loss: 2.4193835990146564

Epoch: 6| Step: 9
Training loss: 2.377412073091916
Validation loss: 2.4371581856792797

Epoch: 6| Step: 10
Training loss: 2.5281351963964553
Validation loss: 2.422565681661513

Epoch: 6| Step: 11
Training loss: 2.333288317200706
Validation loss: 2.424029919515743

Epoch: 6| Step: 12
Training loss: 2.144453648342658
Validation loss: 2.4167283861456466

Epoch: 6| Step: 13
Training loss: 2.467895553097524
Validation loss: 2.443707232739275

Epoch: 47| Step: 0
Training loss: 2.1045555158322555
Validation loss: 2.434860691626143

Epoch: 6| Step: 1
Training loss: 2.4430583277456424
Validation loss: 2.4622550384235478

Epoch: 6| Step: 2
Training loss: 2.3432223934141545
Validation loss: 2.4474655357924253

Epoch: 6| Step: 3
Training loss: 2.6733614707315843
Validation loss: 2.454743501350992

Epoch: 6| Step: 4
Training loss: 1.6803095885399313
Validation loss: 2.458141082315335

Epoch: 6| Step: 5
Training loss: 2.5468853909333182
Validation loss: 2.4632160920602337

Epoch: 6| Step: 6
Training loss: 2.204323733333625
Validation loss: 2.456254004296427

Epoch: 6| Step: 7
Training loss: 2.0021331855000226
Validation loss: 2.4251799644469343

Epoch: 6| Step: 8
Training loss: 2.8472409462248494
Validation loss: 2.4356954529775594

Epoch: 6| Step: 9
Training loss: 2.59278851808232
Validation loss: 2.443766925099488

Epoch: 6| Step: 10
Training loss: 2.340524106467725
Validation loss: 2.4214371808458033

Epoch: 6| Step: 11
Training loss: 2.044704655256544
Validation loss: 2.442565203433782

Epoch: 6| Step: 12
Training loss: 1.932000754393752
Validation loss: 2.4602955944776257

Epoch: 6| Step: 13
Training loss: 2.5367364646074573
Validation loss: 2.4276872191960486

Epoch: 48| Step: 0
Training loss: 2.252904712421169
Validation loss: 2.4411296392779533

Epoch: 6| Step: 1
Training loss: 2.156133455084646
Validation loss: 2.432563657617036

Epoch: 6| Step: 2
Training loss: 2.2685748660585565
Validation loss: 2.4474539759136626

Epoch: 6| Step: 3
Training loss: 2.4861194555993817
Validation loss: 2.443340404100409

Epoch: 6| Step: 4
Training loss: 2.204153700023026
Validation loss: 2.4431761813485173

Epoch: 6| Step: 5
Training loss: 2.6731409119049268
Validation loss: 2.4508447922801144

Epoch: 6| Step: 6
Training loss: 1.8245223321653448
Validation loss: 2.4394175494053245

Epoch: 6| Step: 7
Training loss: 2.3584769857843355
Validation loss: 2.4480082934390768

Epoch: 6| Step: 8
Training loss: 2.7233096943564337
Validation loss: 2.428787931707888

Epoch: 6| Step: 9
Training loss: 2.200502823675069
Validation loss: 2.4296396788442696

Epoch: 6| Step: 10
Training loss: 2.0152205423677834
Validation loss: 2.425407360377761

Epoch: 6| Step: 11
Training loss: 2.7259989596033947
Validation loss: 2.4577434015150224

Epoch: 6| Step: 12
Training loss: 2.513043897980835
Validation loss: 2.442917582341317

Epoch: 6| Step: 13
Training loss: 1.7824306925050366
Validation loss: 2.4645272045134137

Epoch: 49| Step: 0
Training loss: 2.042284061218356
Validation loss: 2.4624754605950483

Epoch: 6| Step: 1
Training loss: 1.4485964197178034
Validation loss: 2.4749431109071507

Epoch: 6| Step: 2
Training loss: 2.1384657390312567
Validation loss: 2.474128738691646

Epoch: 6| Step: 3
Training loss: 2.6887973936223224
Validation loss: 2.4948146131464997

Epoch: 6| Step: 4
Training loss: 2.6613910066831785
Validation loss: 2.5053720374493733

Epoch: 6| Step: 5
Training loss: 2.4806929839898872
Validation loss: 2.5158571724542984

Epoch: 6| Step: 6
Training loss: 2.006945233489706
Validation loss: 2.4699417971756215

Epoch: 6| Step: 7
Training loss: 2.364137907268986
Validation loss: 2.4460189903756224

Epoch: 6| Step: 8
Training loss: 2.093203003444518
Validation loss: 2.4330886880049842

Epoch: 6| Step: 9
Training loss: 2.2620224295869273
Validation loss: 2.443045079838501

Epoch: 6| Step: 10
Training loss: 2.3525402786422758
Validation loss: 2.424259873800622

Epoch: 6| Step: 11
Training loss: 2.206194531659309
Validation loss: 2.43238736167932

Epoch: 6| Step: 12
Training loss: 3.0918215511491587
Validation loss: 2.4547616314069662

Epoch: 6| Step: 13
Training loss: 2.5592303001105443
Validation loss: 2.422394809519004

Epoch: 50| Step: 0
Training loss: 2.7741523788449376
Validation loss: 2.4439549765838713

Epoch: 6| Step: 1
Training loss: 2.665379263137523
Validation loss: 2.4508374232967443

Epoch: 6| Step: 2
Training loss: 2.332497708236697
Validation loss: 2.4412170174059056

Epoch: 6| Step: 3
Training loss: 2.223460824486211
Validation loss: 2.4480812071563873

Epoch: 6| Step: 4
Training loss: 2.345088728993124
Validation loss: 2.428747209831045

Epoch: 6| Step: 5
Training loss: 2.5515296387293747
Validation loss: 2.447997710056522

Epoch: 6| Step: 6
Training loss: 2.962274818071126
Validation loss: 2.4439001422623083

Epoch: 6| Step: 7
Training loss: 1.7306457842305147
Validation loss: 2.4338873639663476

Epoch: 6| Step: 8
Training loss: 2.119313654010351
Validation loss: 2.4318917467803267

Epoch: 6| Step: 9
Training loss: 2.168533499077451
Validation loss: 2.436505807775857

Epoch: 6| Step: 10
Training loss: 2.092678080356401
Validation loss: 2.439865268885585

Epoch: 6| Step: 11
Training loss: 1.850953851125571
Validation loss: 2.4670251703925317

Epoch: 6| Step: 12
Training loss: 1.6412293547169285
Validation loss: 2.452612643180992

Epoch: 6| Step: 13
Training loss: 2.3131289271249447
Validation loss: 2.474958451882417

Epoch: 51| Step: 0
Training loss: 2.339968466260967
Validation loss: 2.4744976754132977

Epoch: 6| Step: 1
Training loss: 2.319873498559007
Validation loss: 2.4930917102054013

Epoch: 6| Step: 2
Training loss: 1.8859070479139692
Validation loss: 2.4923521364176286

Epoch: 6| Step: 3
Training loss: 2.3133844282387184
Validation loss: 2.5284067362383746

Epoch: 6| Step: 4
Training loss: 2.1543643833625894
Validation loss: 2.527540463589977

Epoch: 6| Step: 5
Training loss: 2.4758913111395695
Validation loss: 2.51454153481809

Epoch: 6| Step: 6
Training loss: 2.5644086846991927
Validation loss: 2.488195556570345

Epoch: 6| Step: 7
Training loss: 2.2626217635462287
Validation loss: 2.467500668299828

Epoch: 6| Step: 8
Training loss: 2.262865161406772
Validation loss: 2.488489969663185

Epoch: 6| Step: 9
Training loss: 2.95213648484183
Validation loss: 2.4530782512899796

Epoch: 6| Step: 10
Training loss: 2.865878853739125
Validation loss: 2.446071762819504

Epoch: 6| Step: 11
Training loss: 1.7216278951193054
Validation loss: 2.4576109913300184

Epoch: 6| Step: 12
Training loss: 2.0705238090496696
Validation loss: 2.430251731654019

Epoch: 6| Step: 13
Training loss: 1.991217522940005
Validation loss: 2.4393796764644646

Epoch: 52| Step: 0
Training loss: 2.2762681046781372
Validation loss: 2.402510937504742

Epoch: 6| Step: 1
Training loss: 2.2841634044417485
Validation loss: 2.4321527271218524

Epoch: 6| Step: 2
Training loss: 2.213764230347468
Validation loss: 2.439308815834555

Epoch: 6| Step: 3
Training loss: 2.118790248612341
Validation loss: 2.4517616241351705

Epoch: 6| Step: 4
Training loss: 1.6907465751779094
Validation loss: 2.4459469005812977

Epoch: 6| Step: 5
Training loss: 2.030397676498731
Validation loss: 2.425557280278851

Epoch: 6| Step: 6
Training loss: 1.7262663436215409
Validation loss: 2.446814550024149

Epoch: 6| Step: 7
Training loss: 2.354581903166824
Validation loss: 2.453044833353508

Epoch: 6| Step: 8
Training loss: 2.1579020708789503
Validation loss: 2.446572138790514

Epoch: 6| Step: 9
Training loss: 2.628672256372197
Validation loss: 2.463976917703687

Epoch: 6| Step: 10
Training loss: 2.1765537500034435
Validation loss: 2.476477572391855

Epoch: 6| Step: 11
Training loss: 2.802735140597674
Validation loss: 2.488911898635284

Epoch: 6| Step: 12
Training loss: 2.567366375440679
Validation loss: 2.4565061443745577

Epoch: 6| Step: 13
Training loss: 2.9725174940410986
Validation loss: 2.4376683788341365

Epoch: 53| Step: 0
Training loss: 1.618427188455216
Validation loss: 2.449098996809666

Epoch: 6| Step: 1
Training loss: 2.2680514266358127
Validation loss: 2.429170997238443

Epoch: 6| Step: 2
Training loss: 2.4305336021764012
Validation loss: 2.451587348975761

Epoch: 6| Step: 3
Training loss: 2.603421483552079
Validation loss: 2.423729201108404

Epoch: 6| Step: 4
Training loss: 1.785502928078461
Validation loss: 2.437975796291218

Epoch: 6| Step: 5
Training loss: 2.313597135352634
Validation loss: 2.4328363586052952

Epoch: 6| Step: 6
Training loss: 2.51172368596424
Validation loss: 2.42801414835671

Epoch: 6| Step: 7
Training loss: 2.576268955625552
Validation loss: 2.4370246244330978

Epoch: 6| Step: 8
Training loss: 2.2419343067722943
Validation loss: 2.439930804162602

Epoch: 6| Step: 9
Training loss: 1.856797427236212
Validation loss: 2.436796820522145

Epoch: 6| Step: 10
Training loss: 2.5253516339495286
Validation loss: 2.446198844134375

Epoch: 6| Step: 11
Training loss: 2.265759168138068
Validation loss: 2.4429783187270546

Epoch: 6| Step: 12
Training loss: 2.4814082251385314
Validation loss: 2.4250831111285946

Epoch: 6| Step: 13
Training loss: 2.285138930556696
Validation loss: 2.4476751871246

Epoch: 54| Step: 0
Training loss: 1.953569529490869
Validation loss: 2.4342543683506013

Epoch: 6| Step: 1
Training loss: 2.0794935954298674
Validation loss: 2.462526565253554

Epoch: 6| Step: 2
Training loss: 1.7100879528337138
Validation loss: 2.444432466891836

Epoch: 6| Step: 3
Training loss: 2.446659387513575
Validation loss: 2.4581925195569965

Epoch: 6| Step: 4
Training loss: 2.594231618265606
Validation loss: 2.4742650266912256

Epoch: 6| Step: 5
Training loss: 2.5194250749794205
Validation loss: 2.4630331814454314

Epoch: 6| Step: 6
Training loss: 2.866402250855329
Validation loss: 2.4781257837846695

Epoch: 6| Step: 7
Training loss: 2.6611980353245666
Validation loss: 2.4949676886933627

Epoch: 6| Step: 8
Training loss: 1.8833557864625843
Validation loss: 2.4942411214785114

Epoch: 6| Step: 9
Training loss: 2.314188984795458
Validation loss: 2.473355572537111

Epoch: 6| Step: 10
Training loss: 2.399985543843283
Validation loss: 2.4495816729996824

Epoch: 6| Step: 11
Training loss: 1.7217964223666116
Validation loss: 2.458539070529072

Epoch: 6| Step: 12
Training loss: 2.3303779095839907
Validation loss: 2.451912582359659

Epoch: 6| Step: 13
Training loss: 2.1689630101498256
Validation loss: 2.472415102769811

Epoch: 55| Step: 0
Training loss: 1.7843896066899556
Validation loss: 2.434127642919354

Epoch: 6| Step: 1
Training loss: 2.4090520224205445
Validation loss: 2.4501194775571684

Epoch: 6| Step: 2
Training loss: 1.5858824772051514
Validation loss: 2.4428224489496544

Epoch: 6| Step: 3
Training loss: 2.4299434024200735
Validation loss: 2.4336178504399535

Epoch: 6| Step: 4
Training loss: 2.2649090918345713
Validation loss: 2.4620239281719494

Epoch: 6| Step: 5
Training loss: 2.0406955303720995
Validation loss: 2.4593025953014918

Epoch: 6| Step: 6
Training loss: 2.7939499205331626
Validation loss: 2.433821976166695

Epoch: 6| Step: 7
Training loss: 1.8300753891638435
Validation loss: 2.4321241518505277

Epoch: 6| Step: 8
Training loss: 2.2861598231998426
Validation loss: 2.449360252725979

Epoch: 6| Step: 9
Training loss: 2.1801299052949075
Validation loss: 2.43732223514615

Epoch: 6| Step: 10
Training loss: 2.5936707633910725
Validation loss: 2.471657292568396

Epoch: 6| Step: 11
Training loss: 2.597050416899896
Validation loss: 2.426810185093086

Epoch: 6| Step: 12
Training loss: 2.3534074307340367
Validation loss: 2.442688985936395

Epoch: 6| Step: 13
Training loss: 2.1710341767617294
Validation loss: 2.440392261761073

Epoch: 56| Step: 0
Training loss: 2.6788748796327795
Validation loss: 2.4549523773805677

Epoch: 6| Step: 1
Training loss: 1.876523987996651
Validation loss: 2.4458836385134073

Epoch: 6| Step: 2
Training loss: 2.2798180462361666
Validation loss: 2.443118279930014

Epoch: 6| Step: 3
Training loss: 2.634147690347948
Validation loss: 2.4558233335421065

Epoch: 6| Step: 4
Training loss: 2.5349226316424502
Validation loss: 2.4292410290057687

Epoch: 6| Step: 5
Training loss: 1.9618070581781115
Validation loss: 2.4395657450505888

Epoch: 6| Step: 6
Training loss: 2.0989231709326637
Validation loss: 2.4623643644128275

Epoch: 6| Step: 7
Training loss: 2.5820704931834837
Validation loss: 2.4808114923889613

Epoch: 6| Step: 8
Training loss: 2.1191379248254685
Validation loss: 2.4742264505292018

Epoch: 6| Step: 9
Training loss: 1.762271430703637
Validation loss: 2.4897021394310945

Epoch: 6| Step: 10
Training loss: 2.314622884069667
Validation loss: 2.494448107886887

Epoch: 6| Step: 11
Training loss: 2.4010881818015575
Validation loss: 2.4525245449977926

Epoch: 6| Step: 12
Training loss: 2.389974966995468
Validation loss: 2.4384517278846496

Epoch: 6| Step: 13
Training loss: 1.807336489719818
Validation loss: 2.444368580401958

Epoch: 57| Step: 0
Training loss: 2.5136532845806334
Validation loss: 2.4599845615538305

Epoch: 6| Step: 1
Training loss: 1.8450712222280186
Validation loss: 2.4460601638637365

Epoch: 6| Step: 2
Training loss: 2.878488166089007
Validation loss: 2.425848361534116

Epoch: 6| Step: 3
Training loss: 1.8773871802149456
Validation loss: 2.436452901528903

Epoch: 6| Step: 4
Training loss: 2.0276958181925915
Validation loss: 2.433350674902728

Epoch: 6| Step: 5
Training loss: 2.005948043393799
Validation loss: 2.443647116131937

Epoch: 6| Step: 6
Training loss: 2.265244866412806
Validation loss: 2.4325441696375316

Epoch: 6| Step: 7
Training loss: 2.5385491893992347
Validation loss: 2.4384902181715318

Epoch: 6| Step: 8
Training loss: 2.561054473309537
Validation loss: 2.442063445074427

Epoch: 6| Step: 9
Training loss: 2.224519240484973
Validation loss: 2.4471135763279164

Epoch: 6| Step: 10
Training loss: 2.1325066315703234
Validation loss: 2.422793798592201

Epoch: 6| Step: 11
Training loss: 2.126343919226048
Validation loss: 2.4443267118996435

Epoch: 6| Step: 12
Training loss: 2.26219116969469
Validation loss: 2.4483726130953474

Epoch: 6| Step: 13
Training loss: 1.9072541890680248
Validation loss: 2.4620631151525316

Epoch: 58| Step: 0
Training loss: 2.121326637479683
Validation loss: 2.453126814207795

Epoch: 6| Step: 1
Training loss: 1.8818796466528045
Validation loss: 2.4801925705674925

Epoch: 6| Step: 2
Training loss: 2.530689507112378
Validation loss: 2.4684402818797344

Epoch: 6| Step: 3
Training loss: 2.001719331813457
Validation loss: 2.4750432389589254

Epoch: 6| Step: 4
Training loss: 2.501123938636568
Validation loss: 2.4697665282575927

Epoch: 6| Step: 5
Training loss: 2.4938677920102097
Validation loss: 2.4987893431560484

Epoch: 6| Step: 6
Training loss: 2.1959765098649533
Validation loss: 2.444038684961275

Epoch: 6| Step: 7
Training loss: 2.6983270124424616
Validation loss: 2.492114409806938

Epoch: 6| Step: 8
Training loss: 1.3786165186992694
Validation loss: 2.47433641188273

Epoch: 6| Step: 9
Training loss: 2.2997258976684023
Validation loss: 2.452816006259467

Epoch: 6| Step: 10
Training loss: 2.311869561116013
Validation loss: 2.432865562505462

Epoch: 6| Step: 11
Training loss: 2.1389392981706012
Validation loss: 2.46138845681671

Epoch: 6| Step: 12
Training loss: 2.3982787436961117
Validation loss: 2.45152332476405

Epoch: 6| Step: 13
Training loss: 2.0886549946645236
Validation loss: 2.472810841850703

Epoch: 59| Step: 0
Training loss: 2.264541261545954
Validation loss: 2.4645299938510448

Epoch: 6| Step: 1
Training loss: 2.16245901697386
Validation loss: 2.4715875502682794

Epoch: 6| Step: 2
Training loss: 2.7395887967092674
Validation loss: 2.4330278109000893

Epoch: 6| Step: 3
Training loss: 2.096683440007413
Validation loss: 2.460348101076939

Epoch: 6| Step: 4
Training loss: 2.0785799604043222
Validation loss: 2.4497208676306395

Epoch: 6| Step: 5
Training loss: 2.0812303101120855
Validation loss: 2.4470033659865726

Epoch: 6| Step: 6
Training loss: 2.741432977319439
Validation loss: 2.4709484757542715

Epoch: 6| Step: 7
Training loss: 1.4590324179464458
Validation loss: 2.427066742890812

Epoch: 6| Step: 8
Training loss: 2.261944431779277
Validation loss: 2.4368584921702414

Epoch: 6| Step: 9
Training loss: 2.1225130450563374
Validation loss: 2.451961573513844

Epoch: 6| Step: 10
Training loss: 2.478792456158936
Validation loss: 2.438973046926374

Epoch: 6| Step: 11
Training loss: 1.9103744787829375
Validation loss: 2.464699137899502

Epoch: 6| Step: 12
Training loss: 2.023279132316059
Validation loss: 2.442499169434452

Epoch: 6| Step: 13
Training loss: 2.545554538410053
Validation loss: 2.4579145484299127

Epoch: 60| Step: 0
Training loss: 1.8401117797774693
Validation loss: 2.437193076870045

Epoch: 6| Step: 1
Training loss: 2.4203708038301586
Validation loss: 2.4645383134751704

Epoch: 6| Step: 2
Training loss: 2.7036636786011874
Validation loss: 2.461463411842259

Epoch: 6| Step: 3
Training loss: 2.139169239755452
Validation loss: 2.476321845491103

Epoch: 6| Step: 4
Training loss: 2.4074541522104043
Validation loss: 2.4793172250973017

Epoch: 6| Step: 5
Training loss: 2.4306907422451
Validation loss: 2.444717578607814

Epoch: 6| Step: 6
Training loss: 1.7437156509789995
Validation loss: 2.4753033538791938

Epoch: 6| Step: 7
Training loss: 2.1248680522568812
Validation loss: 2.459118569499552

Epoch: 6| Step: 8
Training loss: 2.0290172336498875
Validation loss: 2.4711933438732485

Epoch: 6| Step: 9
Training loss: 2.3478258423951
Validation loss: 2.4878221504513967

Epoch: 6| Step: 10
Training loss: 2.3548463723516933
Validation loss: 2.4633735830591643

Epoch: 6| Step: 11
Training loss: 2.338570836033252
Validation loss: 2.4620558523737275

Epoch: 6| Step: 12
Training loss: 1.1957854787486835
Validation loss: 2.469525774658338

Epoch: 6| Step: 13
Training loss: 2.7209304309322473
Validation loss: 2.4583308548564595

Epoch: 61| Step: 0
Training loss: 2.3602299435982323
Validation loss: 2.449092174222238

Epoch: 6| Step: 1
Training loss: 1.6349360332750027
Validation loss: 2.465249956597841

Epoch: 6| Step: 2
Training loss: 2.5469278903454224
Validation loss: 2.462404941847686

Epoch: 6| Step: 3
Training loss: 2.001861540397489
Validation loss: 2.4946340910670455

Epoch: 6| Step: 4
Training loss: 2.524788226320884
Validation loss: 2.463547193804637

Epoch: 6| Step: 5
Training loss: 2.15650098141622
Validation loss: 2.477113102979186

Epoch: 6| Step: 6
Training loss: 2.296065830243977
Validation loss: 2.4573408860638866

Epoch: 6| Step: 7
Training loss: 1.7008736104773803
Validation loss: 2.4613816763658316

Epoch: 6| Step: 8
Training loss: 2.0947830157019927
Validation loss: 2.441565278023751

Epoch: 6| Step: 9
Training loss: 1.6289579168308517
Validation loss: 2.4466914472269177

Epoch: 6| Step: 10
Training loss: 2.4712867741026607
Validation loss: 2.468293658866455

Epoch: 6| Step: 11
Training loss: 2.177535769040697
Validation loss: 2.427964502149992

Epoch: 6| Step: 12
Training loss: 2.507187239518402
Validation loss: 2.443236024925957

Epoch: 6| Step: 13
Training loss: 2.344223178146646
Validation loss: 2.4603238748553715

Epoch: 62| Step: 0
Training loss: 2.4312166265634003
Validation loss: 2.4488327070947777

Epoch: 6| Step: 1
Training loss: 2.526256769728992
Validation loss: 2.4593786317959268

Epoch: 6| Step: 2
Training loss: 2.0291110000442285
Validation loss: 2.44867717752123

Epoch: 6| Step: 3
Training loss: 2.276581991789036
Validation loss: 2.4475517704404135

Epoch: 6| Step: 4
Training loss: 2.425778399725328
Validation loss: 2.4340718199306246

Epoch: 6| Step: 5
Training loss: 2.063504292436724
Validation loss: 2.4534283590140413

Epoch: 6| Step: 6
Training loss: 1.7808231042982596
Validation loss: 2.4578746162935086

Epoch: 6| Step: 7
Training loss: 1.5459403865518142
Validation loss: 2.463128881302184

Epoch: 6| Step: 8
Training loss: 1.6383121718588731
Validation loss: 2.472254699917556

Epoch: 6| Step: 9
Training loss: 2.4080381808755025
Validation loss: 2.462680082626783

Epoch: 6| Step: 10
Training loss: 2.681756024749779
Validation loss: 2.473435201380761

Epoch: 6| Step: 11
Training loss: 2.0710392665999424
Validation loss: 2.439087147234849

Epoch: 6| Step: 12
Training loss: 2.4255121299866556
Validation loss: 2.4458209150108465

Epoch: 6| Step: 13
Training loss: 2.2404500895693524
Validation loss: 2.448052282161533

Epoch: 63| Step: 0
Training loss: 2.0633085573318377
Validation loss: 2.457570738966

Epoch: 6| Step: 1
Training loss: 2.09071391875933
Validation loss: 2.4397312613532893

Epoch: 6| Step: 2
Training loss: 2.0490444421896066
Validation loss: 2.4428331442195637

Epoch: 6| Step: 3
Training loss: 2.4166989050282406
Validation loss: 2.435028543102645

Epoch: 6| Step: 4
Training loss: 1.7387272294813925
Validation loss: 2.4253506485600727

Epoch: 6| Step: 5
Training loss: 1.698401243494902
Validation loss: 2.4443451061678823

Epoch: 6| Step: 6
Training loss: 2.5857247901859695
Validation loss: 2.4507688315095857

Epoch: 6| Step: 7
Training loss: 1.704695651055
Validation loss: 2.44385820882566

Epoch: 6| Step: 8
Training loss: 2.605422081021783
Validation loss: 2.4440941908875478

Epoch: 6| Step: 9
Training loss: 1.939679243077262
Validation loss: 2.463164541938138

Epoch: 6| Step: 10
Training loss: 2.8957327589687463
Validation loss: 2.477641844180625

Epoch: 6| Step: 11
Training loss: 2.079100186413354
Validation loss: 2.453723583367493

Epoch: 6| Step: 12
Training loss: 2.4595739068491467
Validation loss: 2.502633265638064

Epoch: 6| Step: 13
Training loss: 1.706705791253416
Validation loss: 2.4595304796253896

Epoch: 64| Step: 0
Training loss: 2.7026147085118875
Validation loss: 2.4640220888735116

Epoch: 6| Step: 1
Training loss: 2.4553218650760646
Validation loss: 2.455561648683003

Epoch: 6| Step: 2
Training loss: 1.6705655112415836
Validation loss: 2.4636868735835136

Epoch: 6| Step: 3
Training loss: 2.0506783595841043
Validation loss: 2.483231127212369

Epoch: 6| Step: 4
Training loss: 2.03132910941202
Validation loss: 2.4555806465315033

Epoch: 6| Step: 5
Training loss: 1.96918724896295
Validation loss: 2.43587071015424

Epoch: 6| Step: 6
Training loss: 2.1532295190609316
Validation loss: 2.4714302289785532

Epoch: 6| Step: 7
Training loss: 1.9637102683726493
Validation loss: 2.442361507452497

Epoch: 6| Step: 8
Training loss: 2.4867667914713665
Validation loss: 2.468058895804595

Epoch: 6| Step: 9
Training loss: 2.2336360536447297
Validation loss: 2.4764160530120467

Epoch: 6| Step: 10
Training loss: 2.2696312572092348
Validation loss: 2.4510248512461867

Epoch: 6| Step: 11
Training loss: 2.6962954290716215
Validation loss: 2.4679873773415877

Epoch: 6| Step: 12
Training loss: 1.0959065566359596
Validation loss: 2.495736205472427

Epoch: 6| Step: 13
Training loss: 2.072854148139229
Validation loss: 2.4624671501382616

Epoch: 65| Step: 0
Training loss: 1.9106246904317388
Validation loss: 2.471223734611717

Epoch: 6| Step: 1
Training loss: 2.388194525394757
Validation loss: 2.500447312709522

Epoch: 6| Step: 2
Training loss: 1.9486947435102295
Validation loss: 2.4571850136745086

Epoch: 6| Step: 3
Training loss: 2.2518936242003873
Validation loss: 2.471260878340081

Epoch: 6| Step: 4
Training loss: 2.2710605006085407
Validation loss: 2.4865601963954456

Epoch: 6| Step: 5
Training loss: 2.6657246078001657
Validation loss: 2.44869840327751

Epoch: 6| Step: 6
Training loss: 1.8817639102028887
Validation loss: 2.4722938693900316

Epoch: 6| Step: 7
Training loss: 2.200788950339575
Validation loss: 2.4509443727165325

Epoch: 6| Step: 8
Training loss: 2.438659978834812
Validation loss: 2.437437733237995

Epoch: 6| Step: 9
Training loss: 2.4332565147432623
Validation loss: 2.44493040729494

Epoch: 6| Step: 10
Training loss: 1.1472620755206626
Validation loss: 2.4549373888835575

Epoch: 6| Step: 11
Training loss: 1.8213846217390814
Validation loss: 2.4510782697619233

Epoch: 6| Step: 12
Training loss: 2.131852153833479
Validation loss: 2.4653552089464714

Epoch: 6| Step: 13
Training loss: 2.2845873523959503
Validation loss: 2.43043730554091

Epoch: 66| Step: 0
Training loss: 2.737101214900156
Validation loss: 2.46532717970181

Epoch: 6| Step: 1
Training loss: 2.5250563964588695
Validation loss: 2.4496509225467173

Epoch: 6| Step: 2
Training loss: 2.2855353668554272
Validation loss: 2.4721156328299685

Epoch: 6| Step: 3
Training loss: 2.3385782784114397
Validation loss: 2.471516857413085

Epoch: 6| Step: 4
Training loss: 1.7521099585990871
Validation loss: 2.4986229600873395

Epoch: 6| Step: 5
Training loss: 2.2475328694656755
Validation loss: 2.4775857506265986

Epoch: 6| Step: 6
Training loss: 2.2594327294030045
Validation loss: 2.463811586740216

Epoch: 6| Step: 7
Training loss: 2.1195656345839073
Validation loss: 2.461760836327956

Epoch: 6| Step: 8
Training loss: 1.6523687121803148
Validation loss: 2.4354702576244103

Epoch: 6| Step: 9
Training loss: 1.8921697941777793
Validation loss: 2.4896014278078846

Epoch: 6| Step: 10
Training loss: 2.6342841769634497
Validation loss: 2.4833314251305674

Epoch: 6| Step: 11
Training loss: 2.0528310068834856
Validation loss: 2.4701365669427133

Epoch: 6| Step: 12
Training loss: 1.4511222574163896
Validation loss: 2.4981091183127435

Epoch: 6| Step: 13
Training loss: 1.8527112527876692
Validation loss: 2.47256501698935

Epoch: 67| Step: 0
Training loss: 2.142428119036729
Validation loss: 2.5210289104246018

Epoch: 6| Step: 1
Training loss: 2.011156792528748
Validation loss: 2.464884520373367

Epoch: 6| Step: 2
Training loss: 1.9488692648791444
Validation loss: 2.4828822451622794

Epoch: 6| Step: 3
Training loss: 2.2615015851322466
Validation loss: 2.4805568569284833

Epoch: 6| Step: 4
Training loss: 1.9279794276354767
Validation loss: 2.438921293952407

Epoch: 6| Step: 5
Training loss: 2.5467989857569324
Validation loss: 2.462956741498304

Epoch: 6| Step: 6
Training loss: 1.884810151676112
Validation loss: 2.4719692117425947

Epoch: 6| Step: 7
Training loss: 1.9335346867952183
Validation loss: 2.476045404114963

Epoch: 6| Step: 8
Training loss: 2.504451412656459
Validation loss: 2.445879576948272

Epoch: 6| Step: 9
Training loss: 2.010761514712541
Validation loss: 2.496346092303917

Epoch: 6| Step: 10
Training loss: 2.0787260864130186
Validation loss: 2.450474872759431

Epoch: 6| Step: 11
Training loss: 2.0988734175273014
Validation loss: 2.4619236983368302

Epoch: 6| Step: 12
Training loss: 2.189524993941992
Validation loss: 2.4661850541784873

Epoch: 6| Step: 13
Training loss: 2.016123155646835
Validation loss: 2.438511125214983

Epoch: 68| Step: 0
Training loss: 1.7705435646684997
Validation loss: 2.4328995516145038

Epoch: 6| Step: 1
Training loss: 1.5354982727945365
Validation loss: 2.4597357262828794

Epoch: 6| Step: 2
Training loss: 2.5820104739555116
Validation loss: 2.448930446563876

Epoch: 6| Step: 3
Training loss: 2.5479995959414845
Validation loss: 2.485054514982252

Epoch: 6| Step: 4
Training loss: 1.6765541126222736
Validation loss: 2.4308516155554103

Epoch: 6| Step: 5
Training loss: 2.4966041389380296
Validation loss: 2.4626551774472425

Epoch: 6| Step: 6
Training loss: 1.563663964652971
Validation loss: 2.470138561696922

Epoch: 6| Step: 7
Training loss: 2.1189205494883345
Validation loss: 2.4965004427961857

Epoch: 6| Step: 8
Training loss: 2.6506730718375375
Validation loss: 2.4753690184411274

Epoch: 6| Step: 9
Training loss: 1.6971620938558123
Validation loss: 2.486626634360768

Epoch: 6| Step: 10
Training loss: 2.199193381778088
Validation loss: 2.4829898867688582

Epoch: 6| Step: 11
Training loss: 1.6268210844059419
Validation loss: 2.4846396635140726

Epoch: 6| Step: 12
Training loss: 2.380150280222934
Validation loss: 2.492238744768913

Epoch: 6| Step: 13
Training loss: 2.0254115781371573
Validation loss: 2.487191305383279

Epoch: 69| Step: 0
Training loss: 1.7886911198317381
Validation loss: 2.4773218974185536

Epoch: 6| Step: 1
Training loss: 2.420230627183559
Validation loss: 2.4687938283900834

Epoch: 6| Step: 2
Training loss: 2.0518438002567
Validation loss: 2.436188646656031

Epoch: 6| Step: 3
Training loss: 1.5117391737709087
Validation loss: 2.4628102115226302

Epoch: 6| Step: 4
Training loss: 2.5917076434691295
Validation loss: 2.458822546520407

Epoch: 6| Step: 5
Training loss: 2.2726668791982982
Validation loss: 2.430508882589143

Epoch: 6| Step: 6
Training loss: 1.7591882366024783
Validation loss: 2.446073899035752

Epoch: 6| Step: 7
Training loss: 2.1869478891353817
Validation loss: 2.4633522982463085

Epoch: 6| Step: 8
Training loss: 2.533960280723569
Validation loss: 2.442176587452002

Epoch: 6| Step: 9
Training loss: 2.240385388021251
Validation loss: 2.4215807089894485

Epoch: 6| Step: 10
Training loss: 1.8906804226404923
Validation loss: 2.463155104543437

Epoch: 6| Step: 11
Training loss: 1.7085708204980052
Validation loss: 2.4561705261781355

Epoch: 6| Step: 12
Training loss: 2.1782602539101354
Validation loss: 2.5036069757599115

Epoch: 6| Step: 13
Training loss: 2.108625716892505
Validation loss: 2.531199874695591

Epoch: 70| Step: 0
Training loss: 2.178428368259936
Validation loss: 2.5032623145403985

Epoch: 6| Step: 1
Training loss: 2.2493242732605934
Validation loss: 2.5166213153601253

Epoch: 6| Step: 2
Training loss: 2.2449659617674893
Validation loss: 2.5045038740971304

Epoch: 6| Step: 3
Training loss: 2.2912462253404193
Validation loss: 2.481340726639838

Epoch: 6| Step: 4
Training loss: 1.8693485921603388
Validation loss: 2.473423819103468

Epoch: 6| Step: 5
Training loss: 2.0703751464578377
Validation loss: 2.4545842910459954

Epoch: 6| Step: 6
Training loss: 1.8767780774090637
Validation loss: 2.465146037657641

Epoch: 6| Step: 7
Training loss: 1.9912051901891064
Validation loss: 2.45609579791327

Epoch: 6| Step: 8
Training loss: 2.002071142672269
Validation loss: 2.4493407848239963

Epoch: 6| Step: 9
Training loss: 2.3231440776362846
Validation loss: 2.4414432777140003

Epoch: 6| Step: 10
Training loss: 2.1094211149473088
Validation loss: 2.4441362991119955

Epoch: 6| Step: 11
Training loss: 1.9157773179798798
Validation loss: 2.4528845893996287

Epoch: 6| Step: 12
Training loss: 2.0582770840556273
Validation loss: 2.449140272652669

Epoch: 6| Step: 13
Training loss: 2.139846437417021
Validation loss: 2.466130150191575

Epoch: 71| Step: 0
Training loss: 2.014236445051446
Validation loss: 2.4390909431553682

Epoch: 6| Step: 1
Training loss: 2.5694751245081764
Validation loss: 2.4596073410884762

Epoch: 6| Step: 2
Training loss: 1.6848601426398417
Validation loss: 2.452693553005062

Epoch: 6| Step: 3
Training loss: 2.0994123499490063
Validation loss: 2.4661201118543126

Epoch: 6| Step: 4
Training loss: 1.9786939625326807
Validation loss: 2.4783882046234544

Epoch: 6| Step: 5
Training loss: 1.4327173698568914
Validation loss: 2.5029311322126064

Epoch: 6| Step: 6
Training loss: 2.2403669775353237
Validation loss: 2.4791150822335055

Epoch: 6| Step: 7
Training loss: 1.759878885263386
Validation loss: 2.518907573305143

Epoch: 6| Step: 8
Training loss: 1.508417670208703
Validation loss: 2.495307078044099

Epoch: 6| Step: 9
Training loss: 2.195274054031124
Validation loss: 2.5469414325935342

Epoch: 6| Step: 10
Training loss: 2.74010333987085
Validation loss: 2.5170879651373124

Epoch: 6| Step: 11
Training loss: 2.130486753840205
Validation loss: 2.5012968990994366

Epoch: 6| Step: 12
Training loss: 1.652926439211995
Validation loss: 2.4781874691696855

Epoch: 6| Step: 13
Training loss: 2.18724723445479
Validation loss: 2.487159208534717

Epoch: 72| Step: 0
Training loss: 2.0480734541654573
Validation loss: 2.4505237548248573

Epoch: 6| Step: 1
Training loss: 2.2625302981882314
Validation loss: 2.4393659443238827

Epoch: 6| Step: 2
Training loss: 1.9672193480709472
Validation loss: 2.448597855176534

Epoch: 6| Step: 3
Training loss: 2.6390172815599042
Validation loss: 2.4378349530518113

Epoch: 6| Step: 4
Training loss: 1.803511595644053
Validation loss: 2.477438530080772

Epoch: 6| Step: 5
Training loss: 2.0256573493161123
Validation loss: 2.4532948817819555

Epoch: 6| Step: 6
Training loss: 2.079023353463844
Validation loss: 2.471547710422523

Epoch: 6| Step: 7
Training loss: 1.8323916343091633
Validation loss: 2.4631673086204993

Epoch: 6| Step: 8
Training loss: 2.3623885557339928
Validation loss: 2.4849231203289803

Epoch: 6| Step: 9
Training loss: 2.120974936064272
Validation loss: 2.4733342290330005

Epoch: 6| Step: 10
Training loss: 1.9619673498122048
Validation loss: 2.502382533923848

Epoch: 6| Step: 11
Training loss: 1.9219723808614393
Validation loss: 2.5104099025608813

Epoch: 6| Step: 12
Training loss: 2.007999990296079
Validation loss: 2.4775959911028447

Epoch: 6| Step: 13
Training loss: 1.7727458798381206
Validation loss: 2.4824991881954097

Epoch: 73| Step: 0
Training loss: 1.76535349420971
Validation loss: 2.4852486919505417

Epoch: 6| Step: 1
Training loss: 1.7875650460739358
Validation loss: 2.5024614773077203

Epoch: 6| Step: 2
Training loss: 1.6787279803890545
Validation loss: 2.492775794802264

Epoch: 6| Step: 3
Training loss: 1.593161380752003
Validation loss: 2.4824778352678254

Epoch: 6| Step: 4
Training loss: 1.5429518300348002
Validation loss: 2.5099178757853715

Epoch: 6| Step: 5
Training loss: 2.262773916618603
Validation loss: 2.519625892143043

Epoch: 6| Step: 6
Training loss: 2.01159157952871
Validation loss: 2.5151521226444187

Epoch: 6| Step: 7
Training loss: 2.4915925753835726
Validation loss: 2.470835082861381

Epoch: 6| Step: 8
Training loss: 1.8193878969071524
Validation loss: 2.5074185926585564

Epoch: 6| Step: 9
Training loss: 2.2913922116629615
Validation loss: 2.5017898986761704

Epoch: 6| Step: 10
Training loss: 1.8969675032105042
Validation loss: 2.4846544088633267

Epoch: 6| Step: 11
Training loss: 2.7157807194671015
Validation loss: 2.4557877442920333

Epoch: 6| Step: 12
Training loss: 1.9643662708657752
Validation loss: 2.439071678390356

Epoch: 6| Step: 13
Training loss: 2.105159701453034
Validation loss: 2.4690024572771962

Epoch: 74| Step: 0
Training loss: 2.2853863983329075
Validation loss: 2.4677007594273475

Epoch: 6| Step: 1
Training loss: 1.7049466111894018
Validation loss: 2.4400181845081166

Epoch: 6| Step: 2
Training loss: 1.9820179795605462
Validation loss: 2.452787047997834

Epoch: 6| Step: 3
Training loss: 1.2448179596022133
Validation loss: 2.4359481468726543

Epoch: 6| Step: 4
Training loss: 2.1142345823637205
Validation loss: 2.452486380287484

Epoch: 6| Step: 5
Training loss: 1.8246771749004094
Validation loss: 2.4663708646932734

Epoch: 6| Step: 6
Training loss: 2.6997198807259997
Validation loss: 2.4397889825637153

Epoch: 6| Step: 7
Training loss: 2.4289777399820123
Validation loss: 2.4571648315279315

Epoch: 6| Step: 8
Training loss: 1.7975136326894965
Validation loss: 2.4630001647774664

Epoch: 6| Step: 9
Training loss: 2.2044032291414313
Validation loss: 2.4844692860111866

Epoch: 6| Step: 10
Training loss: 2.155699286415466
Validation loss: 2.476062014095895

Epoch: 6| Step: 11
Training loss: 1.9869365829230952
Validation loss: 2.424692881363878

Epoch: 6| Step: 12
Training loss: 1.6264499651028783
Validation loss: 2.4450901893254464

Epoch: 6| Step: 13
Training loss: 1.631022809456772
Validation loss: 2.4535142464206974

Epoch: 75| Step: 0
Training loss: 2.7048326511760243
Validation loss: 2.444075526469532

Epoch: 6| Step: 1
Training loss: 1.0256567618724812
Validation loss: 2.5012264740037846

Epoch: 6| Step: 2
Training loss: 1.2484359492935653
Validation loss: 2.4845888377675682

Epoch: 6| Step: 3
Training loss: 1.9829979872161916
Validation loss: 2.537574324122259

Epoch: 6| Step: 4
Training loss: 2.0478916118818673
Validation loss: 2.51171939863688

Epoch: 6| Step: 5
Training loss: 1.351198886183375
Validation loss: 2.5797517672596566

Epoch: 6| Step: 6
Training loss: 2.3972819275074038
Validation loss: 2.5470011705221887

Epoch: 6| Step: 7
Training loss: 2.350938682571067
Validation loss: 2.498019276203786

Epoch: 6| Step: 8
Training loss: 1.7514838331185878
Validation loss: 2.4895829768692677

Epoch: 6| Step: 9
Training loss: 1.6571900920642635
Validation loss: 2.4889857134855395

Epoch: 6| Step: 10
Training loss: 2.473508474038967
Validation loss: 2.4592205941097824

Epoch: 6| Step: 11
Training loss: 2.4320545502994633
Validation loss: 2.4791088952351

Epoch: 6| Step: 12
Training loss: 1.7857486735166377
Validation loss: 2.443880614605638

Epoch: 6| Step: 13
Training loss: 1.8901709649805407
Validation loss: 2.4706435848495336

Epoch: 76| Step: 0
Training loss: 2.0872368926572125
Validation loss: 2.4567340454771873

Epoch: 6| Step: 1
Training loss: 1.8521524125365971
Validation loss: 2.478330428406741

Epoch: 6| Step: 2
Training loss: 1.9269646960331943
Validation loss: 2.4810169645429294

Epoch: 6| Step: 3
Training loss: 1.8665504805418827
Validation loss: 2.4633763575721868

Epoch: 6| Step: 4
Training loss: 1.8238425019972735
Validation loss: 2.4812642901799413

Epoch: 6| Step: 5
Training loss: 2.378069149369065
Validation loss: 2.4940162414586857

Epoch: 6| Step: 6
Training loss: 2.3611338545757277
Validation loss: 2.4559296370739325

Epoch: 6| Step: 7
Training loss: 2.1038563061950546
Validation loss: 2.4778450774512364

Epoch: 6| Step: 8
Training loss: 1.7621751688853697
Validation loss: 2.468499203107269

Epoch: 6| Step: 9
Training loss: 1.8493446555424764
Validation loss: 2.5242628434695624

Epoch: 6| Step: 10
Training loss: 2.0578903936591115
Validation loss: 2.5274073471408505

Epoch: 6| Step: 11
Training loss: 1.8297362440801108
Validation loss: 2.5032483137587245

Epoch: 6| Step: 12
Training loss: 1.8576319883541235
Validation loss: 2.5058621817593156

Epoch: 6| Step: 13
Training loss: 1.8133423262027197
Validation loss: 2.5053317594095224

Epoch: 77| Step: 0
Training loss: 1.6640045442473277
Validation loss: 2.470773181751336

Epoch: 6| Step: 1
Training loss: 1.445719398751202
Validation loss: 2.492021832196492

Epoch: 6| Step: 2
Training loss: 2.1026166236274717
Validation loss: 2.4783429505760832

Epoch: 6| Step: 3
Training loss: 1.4615211341000658
Validation loss: 2.444354925057761

Epoch: 6| Step: 4
Training loss: 2.0962330911553786
Validation loss: 2.4605651089310148

Epoch: 6| Step: 5
Training loss: 2.2378666412192296
Validation loss: 2.4220827239179235

Epoch: 6| Step: 6
Training loss: 2.231903416461518
Validation loss: 2.4531830377860735

Epoch: 6| Step: 7
Training loss: 2.154772597880779
Validation loss: 2.4571018744559363

Epoch: 6| Step: 8
Training loss: 1.2215089137360684
Validation loss: 2.4288868295263923

Epoch: 6| Step: 9
Training loss: 1.4761289737197945
Validation loss: 2.439593044123772

Epoch: 6| Step: 10
Training loss: 2.029614890828312
Validation loss: 2.4658526468202813

Epoch: 6| Step: 11
Training loss: 1.845877050853682
Validation loss: 2.4721984118006737

Epoch: 6| Step: 12
Training loss: 2.643029917957191
Validation loss: 2.4045680223990074

Epoch: 6| Step: 13
Training loss: 2.0081404481228913
Validation loss: 2.458550804562333

Epoch: 78| Step: 0
Training loss: 2.0339990646450175
Validation loss: 2.4359460507141466

Epoch: 6| Step: 1
Training loss: 2.182308467050735
Validation loss: 2.4485372419557234

Epoch: 6| Step: 2
Training loss: 1.326855130938538
Validation loss: 2.4341607165587655

Epoch: 6| Step: 3
Training loss: 2.243144824518887
Validation loss: 2.4835426167706895

Epoch: 6| Step: 4
Training loss: 1.9059399211897563
Validation loss: 2.4537376238186455

Epoch: 6| Step: 5
Training loss: 2.14289401567615
Validation loss: 2.4336656097530334

Epoch: 6| Step: 6
Training loss: 2.113958733176627
Validation loss: 2.48070775279824

Epoch: 6| Step: 7
Training loss: 1.258613236771935
Validation loss: 2.4634698826423995

Epoch: 6| Step: 8
Training loss: 1.5252232184967074
Validation loss: 2.4743603483458276

Epoch: 6| Step: 9
Training loss: 1.814991061291082
Validation loss: 2.4754168791921467

Epoch: 6| Step: 10
Training loss: 1.9993903899964378
Validation loss: 2.508695334127353

Epoch: 6| Step: 11
Training loss: 2.176807757250035
Validation loss: 2.49672793200726

Epoch: 6| Step: 12
Training loss: 1.9943755457012753
Validation loss: 2.5276191950462032

Epoch: 6| Step: 13
Training loss: 1.6065193692561464
Validation loss: 2.498179344977628

Epoch: 79| Step: 0
Training loss: 1.6247979552034013
Validation loss: 2.5013506102070346

Epoch: 6| Step: 1
Training loss: 2.5372151858589027
Validation loss: 2.477177187652445

Epoch: 6| Step: 2
Training loss: 1.9043329949499135
Validation loss: 2.4868978330617444

Epoch: 6| Step: 3
Training loss: 1.900138061928245
Validation loss: 2.4788934466262487

Epoch: 6| Step: 4
Training loss: 1.71620371078892
Validation loss: 2.468580264280353

Epoch: 6| Step: 5
Training loss: 2.0954252913894194
Validation loss: 2.45888592010618

Epoch: 6| Step: 6
Training loss: 1.6676012121136223
Validation loss: 2.4350899413284948

Epoch: 6| Step: 7
Training loss: 1.8678052829898504
Validation loss: 2.4806684518758284

Epoch: 6| Step: 8
Training loss: 1.97372727731933
Validation loss: 2.4696193403804205

Epoch: 6| Step: 9
Training loss: 1.6213741933155825
Validation loss: 2.484177059709353

Epoch: 6| Step: 10
Training loss: 2.1847295383342455
Validation loss: 2.517836520733134

Epoch: 6| Step: 11
Training loss: 1.892349969518062
Validation loss: 2.4924806205228243

Epoch: 6| Step: 12
Training loss: 1.5903391523146142
Validation loss: 2.491842957599911

Epoch: 6| Step: 13
Training loss: 1.0897113350443135
Validation loss: 2.4597146038490534

Epoch: 80| Step: 0
Training loss: 1.6429083057990266
Validation loss: 2.4884867361230176

Epoch: 6| Step: 1
Training loss: 1.8495476298514486
Validation loss: 2.472633719278851

Epoch: 6| Step: 2
Training loss: 2.3576417328997317
Validation loss: 2.509089064785879

Epoch: 6| Step: 3
Training loss: 1.577115330776746
Validation loss: 2.4782862956729623

Epoch: 6| Step: 4
Training loss: 1.534618176615293
Validation loss: 2.553181226555566

Epoch: 6| Step: 5
Training loss: 1.7360288965044017
Validation loss: 2.531236750564122

Epoch: 6| Step: 6
Training loss: 2.369695260458907
Validation loss: 2.529822343323376

Epoch: 6| Step: 7
Training loss: 1.8342723031353771
Validation loss: 2.520403948908553

Epoch: 6| Step: 8
Training loss: 1.7860758142986561
Validation loss: 2.4870123469883847

Epoch: 6| Step: 9
Training loss: 2.214139634688701
Validation loss: 2.484538298864105

Epoch: 6| Step: 10
Training loss: 1.9628154379645486
Validation loss: 2.4782781825399276

Epoch: 6| Step: 11
Training loss: 1.936690438245596
Validation loss: 2.4660972152692384

Epoch: 6| Step: 12
Training loss: 1.478054685311405
Validation loss: 2.461476972275037

Epoch: 6| Step: 13
Training loss: 1.6217382413797445
Validation loss: 2.4780603446078437

Epoch: 81| Step: 0
Training loss: 1.5264554379578348
Validation loss: 2.454761809469352

Epoch: 6| Step: 1
Training loss: 2.3570807209329714
Validation loss: 2.43479444867295

Epoch: 6| Step: 2
Training loss: 1.9491347178232388
Validation loss: 2.431934131644262

Epoch: 6| Step: 3
Training loss: 1.3122405295252835
Validation loss: 2.4509580399859083

Epoch: 6| Step: 4
Training loss: 1.782772083141953
Validation loss: 2.4662098753742994

Epoch: 6| Step: 5
Training loss: 2.1005818514604613
Validation loss: 2.456138412231622

Epoch: 6| Step: 6
Training loss: 1.9989111439706038
Validation loss: 2.4274316027585123

Epoch: 6| Step: 7
Training loss: 1.7769972243322227
Validation loss: 2.479960295861832

Epoch: 6| Step: 8
Training loss: 1.998203543657649
Validation loss: 2.502663782675288

Epoch: 6| Step: 9
Training loss: 1.65087081875607
Validation loss: 2.5691220310337375

Epoch: 6| Step: 10
Training loss: 1.9476462463783033
Validation loss: 2.6180389765229397

Epoch: 6| Step: 11
Training loss: 1.4975148117784918
Validation loss: 2.582822615889632

Epoch: 6| Step: 12
Training loss: 2.1946122216686286
Validation loss: 2.5903415882295033

Epoch: 6| Step: 13
Training loss: 1.5947371772744556
Validation loss: 2.459681146835066

Epoch: 82| Step: 0
Training loss: 1.742340081209075
Validation loss: 2.4662446777987523

Epoch: 6| Step: 1
Training loss: 0.8615104499621475
Validation loss: 2.4890339669545622

Epoch: 6| Step: 2
Training loss: 2.347356539111646
Validation loss: 2.471647316871299

Epoch: 6| Step: 3
Training loss: 1.7885392269176386
Validation loss: 2.4553759345454345

Epoch: 6| Step: 4
Training loss: 1.8061744542146578
Validation loss: 2.4669448272561985

Epoch: 6| Step: 5
Training loss: 2.0293842843903342
Validation loss: 2.501729478252959

Epoch: 6| Step: 6
Training loss: 1.1490875791666324
Validation loss: 2.445490122753645

Epoch: 6| Step: 7
Training loss: 1.5931437966340452
Validation loss: 2.46545167288771

Epoch: 6| Step: 8
Training loss: 1.9043123371768098
Validation loss: 2.4617006763475557

Epoch: 6| Step: 9
Training loss: 1.9217511889266814
Validation loss: 2.537892045426819

Epoch: 6| Step: 10
Training loss: 2.1203139752781346
Validation loss: 2.582032819738791

Epoch: 6| Step: 11
Training loss: 2.226948165954946
Validation loss: 2.529574259469071

Epoch: 6| Step: 12
Training loss: 1.8691217467372148
Validation loss: 2.4818730101444926

Epoch: 6| Step: 13
Training loss: 1.9981622597349915
Validation loss: 2.5226233618734586

Epoch: 83| Step: 0
Training loss: 1.6126048445808492
Validation loss: 2.510432584931068

Epoch: 6| Step: 1
Training loss: 1.8752516259787868
Validation loss: 2.4680289652096903

Epoch: 6| Step: 2
Training loss: 1.7927313088498764
Validation loss: 2.439235126741029

Epoch: 6| Step: 3
Training loss: 1.948620966370321
Validation loss: 2.4460533246777665

Epoch: 6| Step: 4
Training loss: 1.7562629482022758
Validation loss: 2.4706122139148645

Epoch: 6| Step: 5
Training loss: 1.7682404852510956
Validation loss: 2.4912339860803714

Epoch: 6| Step: 6
Training loss: 2.376493085039329
Validation loss: 2.487982923189457

Epoch: 6| Step: 7
Training loss: 1.7056208530038732
Validation loss: 2.480499876132422

Epoch: 6| Step: 8
Training loss: 2.1354427677203116
Validation loss: 2.4963743383456283

Epoch: 6| Step: 9
Training loss: 1.3434848523806866
Validation loss: 2.5042254184510266

Epoch: 6| Step: 10
Training loss: 1.7992491586610864
Validation loss: 2.4859885967573137

Epoch: 6| Step: 11
Training loss: 2.2860432264658215
Validation loss: 2.4719484671161456

Epoch: 6| Step: 12
Training loss: 1.0838181926739918
Validation loss: 2.497650043383187

Epoch: 6| Step: 13
Training loss: 1.902322819964751
Validation loss: 2.4915040373489092

Epoch: 84| Step: 0
Training loss: 2.325532224711975
Validation loss: 2.4733911981865635

Epoch: 6| Step: 1
Training loss: 1.2383909928943033
Validation loss: 2.450129686867655

Epoch: 6| Step: 2
Training loss: 2.114724165512754
Validation loss: 2.4657671327805035

Epoch: 6| Step: 3
Training loss: 1.6248564289932506
Validation loss: 2.456423443210624

Epoch: 6| Step: 4
Training loss: 1.6619943294313648
Validation loss: 2.4875567393005986

Epoch: 6| Step: 5
Training loss: 1.4959766152844045
Validation loss: 2.4878424752163433

Epoch: 6| Step: 6
Training loss: 2.2510017708051606
Validation loss: 2.5138953760905247

Epoch: 6| Step: 7
Training loss: 1.4732643713425746
Validation loss: 2.485077652642199

Epoch: 6| Step: 8
Training loss: 1.7514960161534596
Validation loss: 2.4148956474257286

Epoch: 6| Step: 9
Training loss: 1.594786662121509
Validation loss: 2.455611113174616

Epoch: 6| Step: 10
Training loss: 1.9262621667912136
Validation loss: 2.4826265016141527

Epoch: 6| Step: 11
Training loss: 2.1223119676242566
Validation loss: 2.4709491029306703

Epoch: 6| Step: 12
Training loss: 1.215971346746585
Validation loss: 2.4330894555939

Epoch: 6| Step: 13
Training loss: 1.5829351409666796
Validation loss: 2.5317297115935

Epoch: 85| Step: 0
Training loss: 1.4598195087225252
Validation loss: 2.529034512338775

Epoch: 6| Step: 1
Training loss: 2.334935818756045
Validation loss: 2.5811072623356046

Epoch: 6| Step: 2
Training loss: 2.284259952930545
Validation loss: 2.588093330553722

Epoch: 6| Step: 3
Training loss: 1.5913796843538532
Validation loss: 2.573180340886873

Epoch: 6| Step: 4
Training loss: 1.821970303432681
Validation loss: 2.5399859504861824

Epoch: 6| Step: 5
Training loss: 1.677235219328831
Validation loss: 2.4893232286851257

Epoch: 6| Step: 6
Training loss: 1.8296594945000584
Validation loss: 2.485977216012104

Epoch: 6| Step: 7
Training loss: 1.2756437135227445
Validation loss: 2.5047895963202795

Epoch: 6| Step: 8
Training loss: 1.6411692851804256
Validation loss: 2.431644024010342

Epoch: 6| Step: 9
Training loss: 1.6871474568899671
Validation loss: 2.4797485106890265

Epoch: 6| Step: 10
Training loss: 1.4886156242191304
Validation loss: 2.5002957884329318

Epoch: 6| Step: 11
Training loss: 1.8724389069067826
Validation loss: 2.469047270956688

Epoch: 6| Step: 12
Training loss: 1.6737728577150583
Validation loss: 2.4548743261269053

Epoch: 6| Step: 13
Training loss: 1.3964994843205785
Validation loss: 2.464588335429318

Epoch: 86| Step: 0
Training loss: 1.720368057171555
Validation loss: 2.512095215993358

Epoch: 6| Step: 1
Training loss: 1.398155397059999
Validation loss: 2.5154916005275845

Epoch: 6| Step: 2
Training loss: 1.772120856665098
Validation loss: 2.6039378002051117

Epoch: 6| Step: 3
Training loss: 2.110308631273178
Validation loss: 2.636916707460929

Epoch: 6| Step: 4
Training loss: 1.6920173369256686
Validation loss: 2.627742742256055

Epoch: 6| Step: 5
Training loss: 1.465312343669809
Validation loss: 2.5956744519427986

Epoch: 6| Step: 6
Training loss: 2.3818883886188713
Validation loss: 2.556947833925849

Epoch: 6| Step: 7
Training loss: 2.053546545221489
Validation loss: 2.489224449264371

Epoch: 6| Step: 8
Training loss: 1.617765608946711
Validation loss: 2.465185126651534

Epoch: 6| Step: 9
Training loss: 1.3669245003736232
Validation loss: 2.4556274608749575

Epoch: 6| Step: 10
Training loss: 1.9619634004031483
Validation loss: 2.4657552880504396

Epoch: 6| Step: 11
Training loss: 1.8450854362823952
Validation loss: 2.5106923807991306

Epoch: 6| Step: 12
Training loss: 1.6436916935663894
Validation loss: 2.4613025535809445

Epoch: 6| Step: 13
Training loss: 1.4468385630029972
Validation loss: 2.470279461267541

Epoch: 87| Step: 0
Training loss: 1.7212618419763446
Validation loss: 2.424828793358119

Epoch: 6| Step: 1
Training loss: 1.704613131711266
Validation loss: 2.4901237114146793

Epoch: 6| Step: 2
Training loss: 1.5440788042434845
Validation loss: 2.488336551516837

Epoch: 6| Step: 3
Training loss: 1.9174547924695775
Validation loss: 2.5000376698516944

Epoch: 6| Step: 4
Training loss: 1.6822675185542113
Validation loss: 2.5195003694913933

Epoch: 6| Step: 5
Training loss: 1.8050816753643941
Validation loss: 2.5389605144657157

Epoch: 6| Step: 6
Training loss: 2.196807786502083
Validation loss: 2.5017841966007963

Epoch: 6| Step: 7
Training loss: 2.4029381489629937
Validation loss: 2.4797958382406344

Epoch: 6| Step: 8
Training loss: 1.6549748244200306
Validation loss: 2.5037312558063363

Epoch: 6| Step: 9
Training loss: 1.2439303377615454
Validation loss: 2.4451383258511123

Epoch: 6| Step: 10
Training loss: 1.817369956043322
Validation loss: 2.446670691290238

Epoch: 6| Step: 11
Training loss: 1.2508135055776595
Validation loss: 2.4189339120160125

Epoch: 6| Step: 12
Training loss: 1.712795276663128
Validation loss: 2.451768204289094

Epoch: 6| Step: 13
Training loss: 1.1271698477229795
Validation loss: 2.4787717365742425

Epoch: 88| Step: 0
Training loss: 1.9997203750638324
Validation loss: 2.4458446959492095

Epoch: 6| Step: 1
Training loss: 1.1918784284617379
Validation loss: 2.4703044665224283

Epoch: 6| Step: 2
Training loss: 1.746591654882454
Validation loss: 2.451468055936854

Epoch: 6| Step: 3
Training loss: 2.0229482169658697
Validation loss: 2.443957813789569

Epoch: 6| Step: 4
Training loss: 1.421304273818817
Validation loss: 2.469715669949083

Epoch: 6| Step: 5
Training loss: 1.430711473323854
Validation loss: 2.4968793624693406

Epoch: 6| Step: 6
Training loss: 2.391919751572244
Validation loss: 2.540513751670388

Epoch: 6| Step: 7
Training loss: 1.5443208974750202
Validation loss: 2.536033999584678

Epoch: 6| Step: 8
Training loss: 1.3547167712154458
Validation loss: 2.5369240935666686

Epoch: 6| Step: 9
Training loss: 1.4683291055370926
Validation loss: 2.4767384511736714

Epoch: 6| Step: 10
Training loss: 1.5525358253068056
Validation loss: 2.51554447147854

Epoch: 6| Step: 11
Training loss: 1.777624355424684
Validation loss: 2.4769150475995962

Epoch: 6| Step: 12
Training loss: 1.9861536540148568
Validation loss: 2.4805360239272627

Epoch: 6| Step: 13
Training loss: 1.3619543137723231
Validation loss: 2.490443497397778

Epoch: 89| Step: 0
Training loss: 2.0010022989743135
Validation loss: 2.481255161846951

Epoch: 6| Step: 1
Training loss: 1.165422298202756
Validation loss: 2.491077586510009

Epoch: 6| Step: 2
Training loss: 2.1453070010498876
Validation loss: 2.5184804376152043

Epoch: 6| Step: 3
Training loss: 1.7236691219838824
Validation loss: 2.558369432084899

Epoch: 6| Step: 4
Training loss: 1.3739154613285436
Validation loss: 2.5020666640142233

Epoch: 6| Step: 5
Training loss: 1.576799194594303
Validation loss: 2.527743481367286

Epoch: 6| Step: 6
Training loss: 2.2238776901835218
Validation loss: 2.562875254997327

Epoch: 6| Step: 7
Training loss: 1.5938660074536337
Validation loss: 2.5609714166778224

Epoch: 6| Step: 8
Training loss: 1.39148796822558
Validation loss: 2.520563100617103

Epoch: 6| Step: 9
Training loss: 1.45115150242261
Validation loss: 2.519109346614877

Epoch: 6| Step: 10
Training loss: 1.4254461861484293
Validation loss: 2.523403580853934

Epoch: 6| Step: 11
Training loss: 1.6196227972026407
Validation loss: 2.4987622534874614

Epoch: 6| Step: 12
Training loss: 1.7917132999945726
Validation loss: 2.459920505515991

Epoch: 6| Step: 13
Training loss: 1.5067893396219703
Validation loss: 2.468632715392833

Epoch: 90| Step: 0
Training loss: 1.6667039708095304
Validation loss: 2.5101722081192896

Epoch: 6| Step: 1
Training loss: 1.5240871511455996
Validation loss: 2.465398259569387

Epoch: 6| Step: 2
Training loss: 1.5519443253431624
Validation loss: 2.475226136996462

Epoch: 6| Step: 3
Training loss: 1.7124253166230627
Validation loss: 2.4770066658220884

Epoch: 6| Step: 4
Training loss: 1.4610722933513338
Validation loss: 2.478512153993806

Epoch: 6| Step: 5
Training loss: 1.346128532150697
Validation loss: 2.511049251605602

Epoch: 6| Step: 6
Training loss: 1.2565595179107123
Validation loss: 2.452345203773122

Epoch: 6| Step: 7
Training loss: 1.5632193626038244
Validation loss: 2.469552919541547

Epoch: 6| Step: 8
Training loss: 1.3652318427808687
Validation loss: 2.483549232719917

Epoch: 6| Step: 9
Training loss: 1.763359506853888
Validation loss: 2.464354041733847

Epoch: 6| Step: 10
Training loss: 2.0276501962366043
Validation loss: 2.5062888994630725

Epoch: 6| Step: 11
Training loss: 2.4489621358041735
Validation loss: 2.569982938499568

Epoch: 6| Step: 12
Training loss: 1.270326429903012
Validation loss: 2.57150086485445

Epoch: 6| Step: 13
Training loss: 1.399817568950057
Validation loss: 2.5598116007412877

Epoch: 91| Step: 0
Training loss: 1.7192244828463248
Validation loss: 2.626828253329562

Epoch: 6| Step: 1
Training loss: 1.4938406050907735
Validation loss: 2.632718787331904

Epoch: 6| Step: 2
Training loss: 1.3808913166501042
Validation loss: 2.636005567008369

Epoch: 6| Step: 3
Training loss: 1.8218737934298306
Validation loss: 2.5177747730037243

Epoch: 6| Step: 4
Training loss: 1.7509373470580705
Validation loss: 2.512695612971019

Epoch: 6| Step: 5
Training loss: 1.6823003274637582
Validation loss: 2.4521298748991467

Epoch: 6| Step: 6
Training loss: 1.8709744791709437
Validation loss: 2.531880492505215

Epoch: 6| Step: 7
Training loss: 2.1838661528923375
Validation loss: 2.4976307609624926

Epoch: 6| Step: 8
Training loss: 1.7134202336316775
Validation loss: 2.5126822498830528

Epoch: 6| Step: 9
Training loss: 1.4499823108777985
Validation loss: 2.461369245490709

Epoch: 6| Step: 10
Training loss: 1.4551208899441332
Validation loss: 2.4793729829824076

Epoch: 6| Step: 11
Training loss: 1.5324871748470055
Validation loss: 2.484350448263159

Epoch: 6| Step: 12
Training loss: 1.4060778194558952
Validation loss: 2.4967379507330025

Epoch: 6| Step: 13
Training loss: 1.3305740664200372
Validation loss: 2.5143248552933577

Epoch: 92| Step: 0
Training loss: 2.111380407937012
Validation loss: 2.5312743480123596

Epoch: 6| Step: 1
Training loss: 1.0048828125
Validation loss: 2.5504423483972474

Epoch: 6| Step: 2
Training loss: 1.430391565612487
Validation loss: 2.6119229179758405

Epoch: 6| Step: 3
Training loss: 1.0609375179779545
Validation loss: 2.588692141994126

Epoch: 6| Step: 4
Training loss: 1.240829349090417
Validation loss: 2.569526621790308

Epoch: 6| Step: 5
Training loss: 1.5728991256982097
Validation loss: 2.535712825140222

Epoch: 6| Step: 6
Training loss: 1.838768906278938
Validation loss: 2.5093612721195546

Epoch: 6| Step: 7
Training loss: 1.8597504052491072
Validation loss: 2.517186606194093

Epoch: 6| Step: 8
Training loss: 1.5070099745574106
Validation loss: 2.5077967182744274

Epoch: 6| Step: 9
Training loss: 2.585040348852236
Validation loss: 2.518881212702466

Epoch: 6| Step: 10
Training loss: 1.421760638322466
Validation loss: 2.410893138511158

Epoch: 6| Step: 11
Training loss: 1.3824714628037043
Validation loss: 2.552428947453644

Epoch: 6| Step: 12
Training loss: 1.0776118287296075
Validation loss: 2.5177911866054425

Epoch: 6| Step: 13
Training loss: 1.3706222549459695
Validation loss: 2.5131510066707734

Epoch: 93| Step: 0
Training loss: 1.9903981868574647
Validation loss: 2.5339720889046946

Epoch: 6| Step: 1
Training loss: 1.3605456518430028
Validation loss: 2.5423766900651854

Epoch: 6| Step: 2
Training loss: 1.3785249869206269
Validation loss: 2.5270335082205206

Epoch: 6| Step: 3
Training loss: 1.7041589240883037
Validation loss: 2.56121842195609

Epoch: 6| Step: 4
Training loss: 1.8752018501987053
Validation loss: 2.5926426281591572

Epoch: 6| Step: 5
Training loss: 1.2075546265718542
Validation loss: 2.584088989200775

Epoch: 6| Step: 6
Training loss: 1.7445549040376758
Validation loss: 2.5260728394987115

Epoch: 6| Step: 7
Training loss: 1.0514448261596447
Validation loss: 2.486264515932367

Epoch: 6| Step: 8
Training loss: 1.4806252751605775
Validation loss: 2.5256239057294816

Epoch: 6| Step: 9
Training loss: 1.632734159935681
Validation loss: 2.5429691406499715

Epoch: 6| Step: 10
Training loss: 1.758502468754931
Validation loss: 2.5202338212517565

Epoch: 6| Step: 11
Training loss: 1.4067771771186834
Validation loss: 2.5407977390725858

Epoch: 6| Step: 12
Training loss: 1.4333803605341773
Validation loss: 2.4703072573794977

Epoch: 6| Step: 13
Training loss: 1.8699389499755714
Validation loss: 2.491442865082909

Epoch: 94| Step: 0
Training loss: 1.6340165512852884
Validation loss: 2.5140441998182594

Epoch: 6| Step: 1
Training loss: 1.5868931038279437
Validation loss: 2.485772833254712

Epoch: 6| Step: 2
Training loss: 1.713342030808654
Validation loss: 2.5687847292889017

Epoch: 6| Step: 3
Training loss: 1.4238734192309053
Validation loss: 2.6243451224983336

Epoch: 6| Step: 4
Training loss: 1.5009702882157818
Validation loss: 2.5801141867763344

Epoch: 6| Step: 5
Training loss: 1.3081488465068911
Validation loss: 2.585878377278899

Epoch: 6| Step: 6
Training loss: 1.3623855840256283
Validation loss: 2.5270231142807242

Epoch: 6| Step: 7
Training loss: 1.2449980794746263
Validation loss: 2.548600187864349

Epoch: 6| Step: 8
Training loss: 1.6211950798997214
Validation loss: 2.526710253979531

Epoch: 6| Step: 9
Training loss: 2.1242650949095143
Validation loss: 2.4741702072702396

Epoch: 6| Step: 10
Training loss: 1.3199269109778338
Validation loss: 2.4732926500407024

Epoch: 6| Step: 11
Training loss: 0.9942932611290227
Validation loss: 2.5085273904180068

Epoch: 6| Step: 12
Training loss: 1.8740744531634157
Validation loss: 2.5329539682116495

Epoch: 6| Step: 13
Training loss: 1.560739364497353
Validation loss: 2.462376532065395

Epoch: 95| Step: 0
Training loss: 1.2553586540065786
Validation loss: 2.52587006500563

Epoch: 6| Step: 1
Training loss: 2.068226003984659
Validation loss: 2.542732505157318

Epoch: 6| Step: 2
Training loss: 1.3749927173768433
Validation loss: 2.5002862607461704

Epoch: 6| Step: 3
Training loss: 1.2932136050253478
Validation loss: 2.5252820291794476

Epoch: 6| Step: 4
Training loss: 1.2371670014836058
Validation loss: 2.5513922605548203

Epoch: 6| Step: 5
Training loss: 1.4364117359167412
Validation loss: 2.5147351730844516

Epoch: 6| Step: 6
Training loss: 1.3996652083634982
Validation loss: 2.5053779454751854

Epoch: 6| Step: 7
Training loss: 1.5381490252438619
Validation loss: 2.5530277658574603

Epoch: 6| Step: 8
Training loss: 1.26775646865389
Validation loss: 2.4804421891520025

Epoch: 6| Step: 9
Training loss: 2.140356673526842
Validation loss: 2.5547576101406078

Epoch: 6| Step: 10
Training loss: 1.5962522722077235
Validation loss: 2.598644655571727

Epoch: 6| Step: 11
Training loss: 1.5564600362331404
Validation loss: 2.594335972421869

Epoch: 6| Step: 12
Training loss: 1.783565421762963
Validation loss: 2.6228367353707625

Epoch: 6| Step: 13
Training loss: 0.9298727027361122
Validation loss: 2.62527528711999

Epoch: 96| Step: 0
Training loss: 1.3232920957493124
Validation loss: 2.558238882833389

Epoch: 6| Step: 1
Training loss: 1.6598336658101431
Validation loss: 2.547076258284219

Epoch: 6| Step: 2
Training loss: 1.5293966482459727
Validation loss: 2.4811583994525277

Epoch: 6| Step: 3
Training loss: 1.316825098251847
Validation loss: 2.489921871348602

Epoch: 6| Step: 4
Training loss: 1.616511696666685
Validation loss: 2.522016268731891

Epoch: 6| Step: 5
Training loss: 2.0822331257297955
Validation loss: 2.4522738751902553

Epoch: 6| Step: 6
Training loss: 1.425967520473661
Validation loss: 2.4862786603004183

Epoch: 6| Step: 7
Training loss: 1.5937995902929403
Validation loss: 2.471206746395778

Epoch: 6| Step: 8
Training loss: 1.6725096166587987
Validation loss: 2.487162260069745

Epoch: 6| Step: 9
Training loss: 1.8415342044517586
Validation loss: 2.526297948886524

Epoch: 6| Step: 10
Training loss: 1.193548608938278
Validation loss: 2.5193938934972895

Epoch: 6| Step: 11
Training loss: 0.9419111741782284
Validation loss: 2.5430387222656092

Epoch: 6| Step: 12
Training loss: 1.288582359828868
Validation loss: 2.511342449091013

Epoch: 6| Step: 13
Training loss: 1.156881778394233
Validation loss: 2.5410784264754005

Epoch: 97| Step: 0
Training loss: 1.181582816735486
Validation loss: 2.552495235497203

Epoch: 6| Step: 1
Training loss: 1.6356885485608397
Validation loss: 2.5353169363359114

Epoch: 6| Step: 2
Training loss: 1.8851535536252344
Validation loss: 2.5549414427803585

Epoch: 6| Step: 3
Training loss: 1.096977376914974
Validation loss: 2.5036253392175842

Epoch: 6| Step: 4
Training loss: 1.2693887953428868
Validation loss: 2.504196531040472

Epoch: 6| Step: 5
Training loss: 1.4112213423786713
Validation loss: 2.44459166378485

Epoch: 6| Step: 6
Training loss: 1.085923887757536
Validation loss: 2.4728105847413033

Epoch: 6| Step: 7
Training loss: 1.911290867370428
Validation loss: 2.5063922064843775

Epoch: 6| Step: 8
Training loss: 1.121139046953481
Validation loss: 2.5074959433343085

Epoch: 6| Step: 9
Training loss: 1.0827300641715654
Validation loss: 2.5152831704231513

Epoch: 6| Step: 10
Training loss: 1.619056101250535
Validation loss: 2.5640821612292175

Epoch: 6| Step: 11
Training loss: 1.175230638715793
Validation loss: 2.5349387461066706

Epoch: 6| Step: 12
Training loss: 1.7396090461825555
Validation loss: 2.5677551254950743

Epoch: 6| Step: 13
Training loss: 1.9173355455761607
Validation loss: 2.4920831257838594

Epoch: 98| Step: 0
Training loss: 1.2919438843985738
Validation loss: 2.526595746389562

Epoch: 6| Step: 1
Training loss: 1.362615034514351
Validation loss: 2.477953883994291

Epoch: 6| Step: 2
Training loss: 1.2503229677676952
Validation loss: 2.5052825033796515

Epoch: 6| Step: 3
Training loss: 1.714239687528797
Validation loss: 2.4447153680633527

Epoch: 6| Step: 4
Training loss: 1.33653138997456
Validation loss: 2.5095216625104824

Epoch: 6| Step: 5
Training loss: 1.4811673491391868
Validation loss: 2.4736881684139553

Epoch: 6| Step: 6
Training loss: 1.5424272190525616
Validation loss: 2.5239688404434997

Epoch: 6| Step: 7
Training loss: 1.48845777691203
Validation loss: 2.4724797270701964

Epoch: 6| Step: 8
Training loss: 1.5526311876090626
Validation loss: 2.5422849580590343

Epoch: 6| Step: 9
Training loss: 0.8200456094269237
Validation loss: 2.538355270093913

Epoch: 6| Step: 10
Training loss: 2.5882592971474128
Validation loss: 2.631710104685499

Epoch: 6| Step: 11
Training loss: 1.429892436697139
Validation loss: 2.590413425519819

Epoch: 6| Step: 12
Training loss: 1.2645082138265364
Validation loss: 2.4924800306494004

Epoch: 6| Step: 13
Training loss: 1.1908168648145412
Validation loss: 2.4975710195143406

Epoch: 99| Step: 0
Training loss: 1.292891577869488
Validation loss: 2.5304656049632883

Epoch: 6| Step: 1
Training loss: 1.0404956657066424
Validation loss: 2.5052781970988383

Epoch: 6| Step: 2
Training loss: 2.142434017095659
Validation loss: 2.5008192627343706

Epoch: 6| Step: 3
Training loss: 1.3531525800682545
Validation loss: 2.5150713577916504

Epoch: 6| Step: 4
Training loss: 1.7427011596507718
Validation loss: 2.555848381869659

Epoch: 6| Step: 5
Training loss: 1.617009102384654
Validation loss: 2.498692345360367

Epoch: 6| Step: 6
Training loss: 1.2451709930163668
Validation loss: 2.509904790797533

Epoch: 6| Step: 7
Training loss: 1.3693961477801277
Validation loss: 2.528690378338227

Epoch: 6| Step: 8
Training loss: 1.1211919974099673
Validation loss: 2.5149676804839025

Epoch: 6| Step: 9
Training loss: 1.027104919289296
Validation loss: 2.5403694271404493

Epoch: 6| Step: 10
Training loss: 1.7551970288132424
Validation loss: 2.6759523508726817

Epoch: 6| Step: 11
Training loss: 1.4877468962088125
Validation loss: 2.7446381286491484

Epoch: 6| Step: 12
Training loss: 1.3223551912837104
Validation loss: 2.695310288580388

Epoch: 6| Step: 13
Training loss: 1.6073677359788492
Validation loss: 2.62613676071239

Epoch: 100| Step: 0
Training loss: 1.1973829600850814
Validation loss: 2.5000086068958898

Epoch: 6| Step: 1
Training loss: 0.8451049310100918
Validation loss: 2.5159331739119417

Epoch: 6| Step: 2
Training loss: 1.3384181855041906
Validation loss: 2.488942288554866

Epoch: 6| Step: 3
Training loss: 1.5299187926638447
Validation loss: 2.4955319930114737

Epoch: 6| Step: 4
Training loss: 1.252915035171047
Validation loss: 2.479144927071107

Epoch: 6| Step: 5
Training loss: 1.4824907088350425
Validation loss: 2.5304946714359087

Epoch: 6| Step: 6
Training loss: 1.7105193998992354
Validation loss: 2.5213152894982045

Epoch: 6| Step: 7
Training loss: 1.502431091531054
Validation loss: 2.4905309323519824

Epoch: 6| Step: 8
Training loss: 2.0275982235823777
Validation loss: 2.5119121312933186

Epoch: 6| Step: 9
Training loss: 1.0679202109903276
Validation loss: 2.509022960299823

Epoch: 6| Step: 10
Training loss: 1.326882398156175
Validation loss: 2.5699727646489157

Epoch: 6| Step: 11
Training loss: 1.5153040595280756
Validation loss: 2.5900503376324426

Epoch: 6| Step: 12
Training loss: 1.725265222698691
Validation loss: 2.601174823029679

Epoch: 6| Step: 13
Training loss: 1.4813294337095704
Validation loss: 2.6095032270223597

Epoch: 101| Step: 0
Training loss: 1.047098164471717
Validation loss: 2.5547272720896266

Epoch: 6| Step: 1
Training loss: 1.3520757329146254
Validation loss: 2.5343682034640858

Epoch: 6| Step: 2
Training loss: 2.017630828434943
Validation loss: 2.529650107993507

Epoch: 6| Step: 3
Training loss: 1.2137667183947414
Validation loss: 2.5432824851019773

Epoch: 6| Step: 4
Training loss: 0.9465330456961598
Validation loss: 2.473529711619228

Epoch: 6| Step: 5
Training loss: 1.5352273783816257
Validation loss: 2.5167023620431896

Epoch: 6| Step: 6
Training loss: 1.5882308238928555
Validation loss: 2.491972193490873

Epoch: 6| Step: 7
Training loss: 1.511185899610353
Validation loss: 2.4909602444953984

Epoch: 6| Step: 8
Training loss: 1.1842118465405072
Validation loss: 2.5115373149420885

Epoch: 6| Step: 9
Training loss: 1.564025896770198
Validation loss: 2.4992235567444756

Epoch: 6| Step: 10
Training loss: 1.1170999452654615
Validation loss: 2.5819340936230875

Epoch: 6| Step: 11
Training loss: 1.2193838574172353
Validation loss: 2.565743943933157

Epoch: 6| Step: 12
Training loss: 1.2552596064604349
Validation loss: 2.5390124193778982

Epoch: 6| Step: 13
Training loss: 1.177215208695083
Validation loss: 2.548183487286494

Epoch: 102| Step: 0
Training loss: 1.0656729052562586
Validation loss: 2.557500847511487

Epoch: 6| Step: 1
Training loss: 1.7603900914941997
Validation loss: 2.5668871625920646

Epoch: 6| Step: 2
Training loss: 0.8264758044749634
Validation loss: 2.5228084886470894

Epoch: 6| Step: 3
Training loss: 1.4586727110745052
Validation loss: 2.5437062527630556

Epoch: 6| Step: 4
Training loss: 0.9396177215091279
Validation loss: 2.4913324146767546

Epoch: 6| Step: 5
Training loss: 0.8736018863818305
Validation loss: 2.4678781313841935

Epoch: 6| Step: 6
Training loss: 1.4763994076388898
Validation loss: 2.5117638852348936

Epoch: 6| Step: 7
Training loss: 1.3824290805444543
Validation loss: 2.525508066560607

Epoch: 6| Step: 8
Training loss: 1.161089383813839
Validation loss: 2.636494146129182

Epoch: 6| Step: 9
Training loss: 1.1827463572463577
Validation loss: 2.5882167701814796

Epoch: 6| Step: 10
Training loss: 1.3658636168372758
Validation loss: 2.5264794720761263

Epoch: 6| Step: 11
Training loss: 2.192062741982724
Validation loss: 2.5579486839410404

Epoch: 6| Step: 12
Training loss: 0.8777966085525326
Validation loss: 2.526741565342402

Epoch: 6| Step: 13
Training loss: 1.4648471679647623
Validation loss: 2.5281382613429564

Epoch: 103| Step: 0
Training loss: 1.179686135802838
Validation loss: 2.519973676609631

Epoch: 6| Step: 1
Training loss: 1.2035518731165469
Validation loss: 2.5400073518671684

Epoch: 6| Step: 2
Training loss: 1.1450072460694891
Validation loss: 2.5158795924912787

Epoch: 6| Step: 3
Training loss: 1.5809215279877207
Validation loss: 2.521390007492941

Epoch: 6| Step: 4
Training loss: 1.526269481262796
Validation loss: 2.536817824145523

Epoch: 6| Step: 5
Training loss: 1.3202185061251812
Validation loss: 2.521745711064939

Epoch: 6| Step: 6
Training loss: 1.1884144725268844
Validation loss: 2.461815264750998

Epoch: 6| Step: 7
Training loss: 0.9087870371746989
Validation loss: 2.5075343246113717

Epoch: 6| Step: 8
Training loss: 1.2965910267444223
Validation loss: 2.5273890149771443

Epoch: 6| Step: 9
Training loss: 0.9446026367270237
Validation loss: 2.5586828784124234

Epoch: 6| Step: 10
Training loss: 1.1485248973574118
Validation loss: 2.661272349767694

Epoch: 6| Step: 11
Training loss: 2.3084161112388193
Validation loss: 2.6843472551504064

Epoch: 6| Step: 12
Training loss: 1.2078906212891762
Validation loss: 2.6357832089567856

Epoch: 6| Step: 13
Training loss: 1.1611904582351362
Validation loss: 2.6595626220980404

Epoch: 104| Step: 0
Training loss: 0.9680889088926363
Validation loss: 2.6796302603937368

Epoch: 6| Step: 1
Training loss: 1.6221512252405565
Validation loss: 2.582225836473457

Epoch: 6| Step: 2
Training loss: 1.2730448767010485
Validation loss: 2.5805278485273804

Epoch: 6| Step: 3
Training loss: 1.1222660966255427
Validation loss: 2.5287739452486084

Epoch: 6| Step: 4
Training loss: 1.070816700926177
Validation loss: 2.485777596942122

Epoch: 6| Step: 5
Training loss: 1.2565950935043337
Validation loss: 2.5206839041649767

Epoch: 6| Step: 6
Training loss: 2.0053853010552554
Validation loss: 2.5256713648203575

Epoch: 6| Step: 7
Training loss: 1.5345190536096687
Validation loss: 2.483762061683819

Epoch: 6| Step: 8
Training loss: 0.9889449955231217
Validation loss: 2.515638331660294

Epoch: 6| Step: 9
Training loss: 1.097952317461912
Validation loss: 2.503207628503174

Epoch: 6| Step: 10
Training loss: 1.0386021677120572
Validation loss: 2.5305161138304273

Epoch: 6| Step: 11
Training loss: 1.2556429330884793
Validation loss: 2.5485469892048087

Epoch: 6| Step: 12
Training loss: 1.495555332600119
Validation loss: 2.5505483150007806

Epoch: 6| Step: 13
Training loss: 1.3086905827920698
Validation loss: 2.5486868593864704

Epoch: 105| Step: 0
Training loss: 2.159061865177743
Validation loss: 2.5039828363648935

Epoch: 6| Step: 1
Training loss: 1.632016731807545
Validation loss: 2.587408855387085

Epoch: 6| Step: 2
Training loss: 0.8730301482029849
Validation loss: 2.538133140086873

Epoch: 6| Step: 3
Training loss: 1.2320840556959956
Validation loss: 2.5842371994975437

Epoch: 6| Step: 4
Training loss: 1.62084900260876
Validation loss: 2.6090633792550553

Epoch: 6| Step: 5
Training loss: 1.026986876027793
Validation loss: 2.5768549863963495

Epoch: 6| Step: 6
Training loss: 1.2474449747980574
Validation loss: 2.583093298763595

Epoch: 6| Step: 7
Training loss: 1.1652514639000002
Validation loss: 2.5846370104473335

Epoch: 6| Step: 8
Training loss: 1.1966901830702013
Validation loss: 2.577052361423783

Epoch: 6| Step: 9
Training loss: 1.3338601541837845
Validation loss: 2.51532306004312

Epoch: 6| Step: 10
Training loss: 1.0342912622768152
Validation loss: 2.4964077731597407

Epoch: 6| Step: 11
Training loss: 1.16657697241998
Validation loss: 2.568180177575035

Epoch: 6| Step: 12
Training loss: 1.1022845127294376
Validation loss: 2.5380988224060124

Epoch: 6| Step: 13
Training loss: 0.8812161080627112
Validation loss: 2.526161605242304

Epoch: 106| Step: 0
Training loss: 1.8794375994716124
Validation loss: 2.5607477182570992

Epoch: 6| Step: 1
Training loss: 1.1297128824888505
Validation loss: 2.555947929013112

Epoch: 6| Step: 2
Training loss: 0.8644246603049645
Validation loss: 2.4429086848382378

Epoch: 6| Step: 3
Training loss: 0.9316287249878753
Validation loss: 2.6073508949476785

Epoch: 6| Step: 4
Training loss: 1.0545399880566515
Validation loss: 2.6123453468652365

Epoch: 6| Step: 5
Training loss: 1.121056532823558
Validation loss: 2.681921010502454

Epoch: 6| Step: 6
Training loss: 1.5822824537734366
Validation loss: 2.760867680586307

Epoch: 6| Step: 7
Training loss: 1.1743172183599062
Validation loss: 2.6660454940520015

Epoch: 6| Step: 8
Training loss: 0.8663417713054761
Validation loss: 2.6034585574955327

Epoch: 6| Step: 9
Training loss: 1.4052882826645958
Validation loss: 2.6318925104802062

Epoch: 6| Step: 10
Training loss: 1.2885176923408315
Validation loss: 2.5900180733048908

Epoch: 6| Step: 11
Training loss: 1.3990921108034056
Validation loss: 2.530033604219039

Epoch: 6| Step: 12
Training loss: 1.399506187201776
Validation loss: 2.554864299850868

Epoch: 6| Step: 13
Training loss: 1.1738589976181393
Validation loss: 2.546153366110394

Epoch: 107| Step: 0
Training loss: 1.2138993987077782
Validation loss: 2.5910185407237494

Epoch: 6| Step: 1
Training loss: 1.6774487857419764
Validation loss: 2.605600913230713

Epoch: 6| Step: 2
Training loss: 1.5009353423554803
Validation loss: 2.6187013261955783

Epoch: 6| Step: 3
Training loss: 2.0945501364369035
Validation loss: 2.628319321931475

Epoch: 6| Step: 4
Training loss: 1.314956319322809
Validation loss: 2.5683174313600223

Epoch: 6| Step: 5
Training loss: 1.2116197202491308
Validation loss: 2.528127746203314

Epoch: 6| Step: 6
Training loss: 1.751831867015013
Validation loss: 2.7019259783226857

Epoch: 6| Step: 7
Training loss: 1.2918314931156964
Validation loss: 2.7348960743278456

Epoch: 6| Step: 8
Training loss: 1.4143285343023715
Validation loss: 2.8150423780089286

Epoch: 6| Step: 9
Training loss: 1.4337779246423668
Validation loss: 2.845733607505715

Epoch: 6| Step: 10
Training loss: 1.366616178758526
Validation loss: 2.830795895592161

Epoch: 6| Step: 11
Training loss: 1.1806877897416796
Validation loss: 2.6785806607284086

Epoch: 6| Step: 12
Training loss: 1.0657193273595265
Validation loss: 2.607464789752957

Epoch: 6| Step: 13
Training loss: 1.1247426904363245
Validation loss: 2.57843797883978

Epoch: 108| Step: 0
Training loss: 1.194503260921404
Validation loss: 2.5492918720488333

Epoch: 6| Step: 1
Training loss: 1.3954040189761985
Validation loss: 2.6019939488700508

Epoch: 6| Step: 2
Training loss: 1.758066252300876
Validation loss: 2.571733555355495

Epoch: 6| Step: 3
Training loss: 1.5178443940212283
Validation loss: 2.574025727185699

Epoch: 6| Step: 4
Training loss: 0.8973553982549404
Validation loss: 2.5701600776473947

Epoch: 6| Step: 5
Training loss: 2.084255840778803
Validation loss: 2.5549539471810014

Epoch: 6| Step: 6
Training loss: 1.0251833751678976
Validation loss: 2.503042340828713

Epoch: 6| Step: 7
Training loss: 1.521824457163513
Validation loss: 2.543550978426985

Epoch: 6| Step: 8
Training loss: 1.1845610037215393
Validation loss: 2.6115804401502873

Epoch: 6| Step: 9
Training loss: 1.1246573668161182
Validation loss: 2.611975403944952

Epoch: 6| Step: 10
Training loss: 1.0647729235776893
Validation loss: 2.584877196308881

Epoch: 6| Step: 11
Training loss: 0.7105189757823128
Validation loss: 2.554444685507268

Epoch: 6| Step: 12
Training loss: 1.0579506021840916
Validation loss: 2.52163653280285

Epoch: 6| Step: 13
Training loss: 1.584859697889188
Validation loss: 2.498406442747788

Epoch: 109| Step: 0
Training loss: 1.3589719854559286
Validation loss: 2.5863008887285655

Epoch: 6| Step: 1
Training loss: 1.4235340542084727
Validation loss: 2.5619404809963333

Epoch: 6| Step: 2
Training loss: 1.8964826149740803
Validation loss: 2.4894465059058417

Epoch: 6| Step: 3
Training loss: 1.2689665961832897
Validation loss: 2.5008435574553167

Epoch: 6| Step: 4
Training loss: 0.9345609371468421
Validation loss: 2.5116383177286585

Epoch: 6| Step: 5
Training loss: 0.9879660122465601
Validation loss: 2.6405662966491312

Epoch: 6| Step: 6
Training loss: 0.958486486028245
Validation loss: 2.657882435644944

Epoch: 6| Step: 7
Training loss: 1.7021574019055394
Validation loss: 2.6959411330290908

Epoch: 6| Step: 8
Training loss: 1.0344927694806412
Validation loss: 2.6491138191107795

Epoch: 6| Step: 9
Training loss: 1.0949021946325421
Validation loss: 2.6090255625154715

Epoch: 6| Step: 10
Training loss: 1.2928834639250721
Validation loss: 2.570579816373378

Epoch: 6| Step: 11
Training loss: 1.477907163928039
Validation loss: 2.501291648661612

Epoch: 6| Step: 12
Training loss: 0.832133076485762
Validation loss: 2.467711926564061

Epoch: 6| Step: 13
Training loss: 1.2619186573685885
Validation loss: 2.5060511629879922

Epoch: 110| Step: 0
Training loss: 0.9992727376924425
Validation loss: 2.580089814522748

Epoch: 6| Step: 1
Training loss: 1.1231979666535266
Validation loss: 2.489157035007835

Epoch: 6| Step: 2
Training loss: 1.3208894089950483
Validation loss: 2.5026808034625954

Epoch: 6| Step: 3
Training loss: 0.9971438090317516
Validation loss: 2.5125261099804588

Epoch: 6| Step: 4
Training loss: 0.9468856206619324
Validation loss: 2.5079252984178892

Epoch: 6| Step: 5
Training loss: 0.9144437597969287
Validation loss: 2.5377509696136107

Epoch: 6| Step: 6
Training loss: 1.7762149789620787
Validation loss: 2.6320922122854076

Epoch: 6| Step: 7
Training loss: 2.174951802739151
Validation loss: 2.6686990761346614

Epoch: 6| Step: 8
Training loss: 0.8902184746507781
Validation loss: 2.624406505279626

Epoch: 6| Step: 9
Training loss: 0.87813269588044
Validation loss: 2.6361874645588315

Epoch: 6| Step: 10
Training loss: 1.5244669248321614
Validation loss: 2.6081606538628397

Epoch: 6| Step: 11
Training loss: 1.1862637961804356
Validation loss: 2.6425488027001696

Epoch: 6| Step: 12
Training loss: 1.2308658988293075
Validation loss: 2.537839608728965

Epoch: 6| Step: 13
Training loss: 0.9724392016805566
Validation loss: 2.600523587533623

Epoch: 111| Step: 0
Training loss: 1.2383306836390395
Validation loss: 2.5340657840089182

Epoch: 6| Step: 1
Training loss: 1.0376603841333072
Validation loss: 2.555485685287147

Epoch: 6| Step: 2
Training loss: 1.2581595185003052
Validation loss: 2.5301385016847435

Epoch: 6| Step: 3
Training loss: 0.9408868330202159
Validation loss: 2.5819339320261947

Epoch: 6| Step: 4
Training loss: 1.1278059193796244
Validation loss: 2.479472379240984

Epoch: 6| Step: 5
Training loss: 1.0068183549590797
Validation loss: 2.571471257460989

Epoch: 6| Step: 6
Training loss: 0.8748332954731829
Validation loss: 2.572733518643124

Epoch: 6| Step: 7
Training loss: 0.8372858172159603
Validation loss: 2.5441075757117115

Epoch: 6| Step: 8
Training loss: 0.9922738225436235
Validation loss: 2.5729750550680985

Epoch: 6| Step: 9
Training loss: 1.1931853971386364
Validation loss: 2.5851699212363077

Epoch: 6| Step: 10
Training loss: 1.2026033137425696
Validation loss: 2.6363405460335048

Epoch: 6| Step: 11
Training loss: 1.24348545040489
Validation loss: 2.607446197510621

Epoch: 6| Step: 12
Training loss: 0.9163406868950986
Validation loss: 2.5238845633886915

Epoch: 6| Step: 13
Training loss: 2.1042813436651286
Validation loss: 2.600542786990239

Epoch: 112| Step: 0
Training loss: 0.8577846724090905
Validation loss: 2.500973591373878

Epoch: 6| Step: 1
Training loss: 1.3689450982804308
Validation loss: 2.5649702369594136

Epoch: 6| Step: 2
Training loss: 0.8976256309712111
Validation loss: 2.574849245911366

Epoch: 6| Step: 3
Training loss: 1.9975822855743341
Validation loss: 2.524147319658686

Epoch: 6| Step: 4
Training loss: 1.1968983620537352
Validation loss: 2.5818727938093864

Epoch: 6| Step: 5
Training loss: 0.8298683170624681
Validation loss: 2.59146122889926

Epoch: 6| Step: 6
Training loss: 1.4523827903059945
Validation loss: 2.6186954917485017

Epoch: 6| Step: 7
Training loss: 0.9966417787202366
Validation loss: 2.608109965119188

Epoch: 6| Step: 8
Training loss: 1.2751644570743628
Validation loss: 2.6109256515066672

Epoch: 6| Step: 9
Training loss: 1.047639596054304
Validation loss: 2.5822803494501785

Epoch: 6| Step: 10
Training loss: 0.765646330867155
Validation loss: 2.542061874014789

Epoch: 6| Step: 11
Training loss: 1.229173881164758
Validation loss: 2.508804156915187

Epoch: 6| Step: 12
Training loss: 1.153622657881796
Validation loss: 2.4904616707185183

Epoch: 6| Step: 13
Training loss: 0.8597780149642518
Validation loss: 2.4844372979436478

Epoch: 113| Step: 0
Training loss: 0.8952235578793452
Validation loss: 2.4804114467780165

Epoch: 6| Step: 1
Training loss: 1.8583930492072438
Validation loss: 2.520425138185474

Epoch: 6| Step: 2
Training loss: 1.0185800258450968
Validation loss: 2.5358843039626846

Epoch: 6| Step: 3
Training loss: 1.319536556687195
Validation loss: 2.546709535056536

Epoch: 6| Step: 4
Training loss: 1.0101325956497331
Validation loss: 2.579498911356106

Epoch: 6| Step: 5
Training loss: 1.27910387752811
Validation loss: 2.61692687297897

Epoch: 6| Step: 6
Training loss: 0.7356776594761756
Validation loss: 2.5183688141145093

Epoch: 6| Step: 7
Training loss: 1.028592703046734
Validation loss: 2.563127502896596

Epoch: 6| Step: 8
Training loss: 1.1358655631310508
Validation loss: 2.5709727945529135

Epoch: 6| Step: 9
Training loss: 0.8935372105958209
Validation loss: 2.6420171104096557

Epoch: 6| Step: 10
Training loss: 1.216482547432559
Validation loss: 2.592579251840368

Epoch: 6| Step: 11
Training loss: 0.8993322478121217
Validation loss: 2.612474987147567

Epoch: 6| Step: 12
Training loss: 1.2346442206658301
Validation loss: 2.620368603276542

Epoch: 6| Step: 13
Training loss: 0.9931357650701543
Validation loss: 2.5856906277463207

Epoch: 114| Step: 0
Training loss: 0.7136328608764319
Validation loss: 2.5662922594369384

Epoch: 6| Step: 1
Training loss: 1.1296994283845734
Validation loss: 2.5470508678540313

Epoch: 6| Step: 2
Training loss: 1.3974344929472928
Validation loss: 2.553533046305654

Epoch: 6| Step: 3
Training loss: 0.9939103075198618
Validation loss: 2.568335440443174

Epoch: 6| Step: 4
Training loss: 1.2995468560314085
Validation loss: 2.57922144992393

Epoch: 6| Step: 5
Training loss: 1.2517661492136618
Validation loss: 2.614656801951972

Epoch: 6| Step: 6
Training loss: 0.6699383569586123
Validation loss: 2.5498443954962213

Epoch: 6| Step: 7
Training loss: 1.1954615880202955
Validation loss: 2.583106651410199

Epoch: 6| Step: 8
Training loss: 0.8180450345585988
Validation loss: 2.591226629534264

Epoch: 6| Step: 9
Training loss: 0.8940799690894624
Validation loss: 2.596585604276058

Epoch: 6| Step: 10
Training loss: 1.831824642805068
Validation loss: 2.5945873594051174

Epoch: 6| Step: 11
Training loss: 1.0114998009795118
Validation loss: 2.588488523883125

Epoch: 6| Step: 12
Training loss: 1.3853134556617943
Validation loss: 2.5012986148225695

Epoch: 6| Step: 13
Training loss: 0.7334988013623721
Validation loss: 2.568644081648421

Epoch: 115| Step: 0
Training loss: 0.7677529793485558
Validation loss: 2.45811088546967

Epoch: 6| Step: 1
Training loss: 1.2451001932816972
Validation loss: 2.598100024872513

Epoch: 6| Step: 2
Training loss: 0.8987315484541691
Validation loss: 2.5106156034248652

Epoch: 6| Step: 3
Training loss: 0.838138428081952
Validation loss: 2.510901381892171

Epoch: 6| Step: 4
Training loss: 0.9263002574531949
Validation loss: 2.6203067695313895

Epoch: 6| Step: 5
Training loss: 1.2502541283728303
Validation loss: 2.5154709857684545

Epoch: 6| Step: 6
Training loss: 1.300207062883474
Validation loss: 2.5770957202248765

Epoch: 6| Step: 7
Training loss: 1.1003064508984175
Validation loss: 2.658335581293222

Epoch: 6| Step: 8
Training loss: 0.652111446111801
Validation loss: 2.6640212875266025

Epoch: 6| Step: 9
Training loss: 1.9634400467079716
Validation loss: 2.6630252672219825

Epoch: 6| Step: 10
Training loss: 0.9994554228925085
Validation loss: 2.6723539729914325

Epoch: 6| Step: 11
Training loss: 0.8088222309856906
Validation loss: 2.638090433380633

Epoch: 6| Step: 12
Training loss: 1.134509164321758
Validation loss: 2.57869128548857

Epoch: 6| Step: 13
Training loss: 1.1117568437774394
Validation loss: 2.538351340836362

Epoch: 116| Step: 0
Training loss: 0.7305403893576234
Validation loss: 2.5675788882875548

Epoch: 6| Step: 1
Training loss: 0.8191398595134195
Validation loss: 2.5665084067595347

Epoch: 6| Step: 2
Training loss: 1.8407306841575497
Validation loss: 2.518818007656181

Epoch: 6| Step: 3
Training loss: 0.9978693675470356
Validation loss: 2.620117020675117

Epoch: 6| Step: 4
Training loss: 0.749877403093911
Validation loss: 2.570747856520354

Epoch: 6| Step: 5
Training loss: 0.761604261352935
Validation loss: 2.5837961418117734

Epoch: 6| Step: 6
Training loss: 1.1317364021092777
Validation loss: 2.590409928042531

Epoch: 6| Step: 7
Training loss: 1.340688544770324
Validation loss: 2.592448133809981

Epoch: 6| Step: 8
Training loss: 1.0609744283235376
Validation loss: 2.615133354319416

Epoch: 6| Step: 9
Training loss: 1.3196922515704108
Validation loss: 2.6753215311346024

Epoch: 6| Step: 10
Training loss: 0.8252910490761863
Validation loss: 2.584792622254253

Epoch: 6| Step: 11
Training loss: 1.1580567548873772
Validation loss: 2.6067915593916595

Epoch: 6| Step: 12
Training loss: 1.2660515148957214
Validation loss: 2.644550370373106

Epoch: 6| Step: 13
Training loss: 0.9205405064569484
Validation loss: 2.595845092534535

Epoch: 117| Step: 0
Training loss: 1.2212490478480678
Validation loss: 2.601412061402626

Epoch: 6| Step: 1
Training loss: 1.2554532309464954
Validation loss: 2.6049075840124005

Epoch: 6| Step: 2
Training loss: 0.9029761406206093
Validation loss: 2.4922171484320668

Epoch: 6| Step: 3
Training loss: 1.930102222680534
Validation loss: 2.559715479373129

Epoch: 6| Step: 4
Training loss: 0.9528661282549346
Validation loss: 2.5977645736709922

Epoch: 6| Step: 5
Training loss: 0.9411923810590505
Validation loss: 2.5940067976100525

Epoch: 6| Step: 6
Training loss: 0.8376138581270836
Validation loss: 2.5747687640265853

Epoch: 6| Step: 7
Training loss: 0.9986649482520853
Validation loss: 2.612475177275839

Epoch: 6| Step: 8
Training loss: 1.3594594468819858
Validation loss: 2.5626001571062167

Epoch: 6| Step: 9
Training loss: 1.0882614845951084
Validation loss: 2.5516079258734417

Epoch: 6| Step: 10
Training loss: 1.2895608574424116
Validation loss: 2.6147112694756336

Epoch: 6| Step: 11
Training loss: 1.1215506230807202
Validation loss: 2.5751642971029973

Epoch: 6| Step: 12
Training loss: 0.7414113855535799
Validation loss: 2.62518988028525

Epoch: 6| Step: 13
Training loss: 0.7676692840569097
Validation loss: 2.6090378229361164

Epoch: 118| Step: 0
Training loss: 0.9779906549299799
Validation loss: 2.5673095259297676

Epoch: 6| Step: 1
Training loss: 0.9870197552846055
Validation loss: 2.5899693615400996

Epoch: 6| Step: 2
Training loss: 0.9700005366137092
Validation loss: 2.5578953845484116

Epoch: 6| Step: 3
Training loss: 1.1409096558599514
Validation loss: 2.582519377383086

Epoch: 6| Step: 4
Training loss: 1.7802536168671734
Validation loss: 2.5942757468160127

Epoch: 6| Step: 5
Training loss: 0.8700989658147454
Validation loss: 2.527453711513785

Epoch: 6| Step: 6
Training loss: 1.0762363421451873
Validation loss: 2.5590832424033576

Epoch: 6| Step: 7
Training loss: 1.0719815904652121
Validation loss: 2.599189600213981

Epoch: 6| Step: 8
Training loss: 1.3680286980373875
Validation loss: 2.579029179011953

Epoch: 6| Step: 9
Training loss: 1.0798904780203606
Validation loss: 2.5339687644289866

Epoch: 6| Step: 10
Training loss: 0.9735213878850725
Validation loss: 2.59069896020295

Epoch: 6| Step: 11
Training loss: 1.0017340050551593
Validation loss: 2.5476062871531076

Epoch: 6| Step: 12
Training loss: 0.8796552730098046
Validation loss: 2.5432639314482475

Epoch: 6| Step: 13
Training loss: 0.7018790331730581
Validation loss: 2.525859634814564

Epoch: 119| Step: 0
Training loss: 1.0116031536504144
Validation loss: 2.5616412390805983

Epoch: 6| Step: 1
Training loss: 1.349472149332937
Validation loss: 2.5189966546410365

Epoch: 6| Step: 2
Training loss: 0.8150480370903869
Validation loss: 2.5368334253298315

Epoch: 6| Step: 3
Training loss: 1.8923188495485992
Validation loss: 2.5667756084342352

Epoch: 6| Step: 4
Training loss: 1.0557536070443858
Validation loss: 2.582529663366102

Epoch: 6| Step: 5
Training loss: 0.8628070616421187
Validation loss: 2.4698752241240243

Epoch: 6| Step: 6
Training loss: 1.0497751063237863
Validation loss: 2.5445177133520445

Epoch: 6| Step: 7
Training loss: 1.0453106023431953
Validation loss: 2.638022635868181

Epoch: 6| Step: 8
Training loss: 0.896352055909359
Validation loss: 2.573008722262098

Epoch: 6| Step: 9
Training loss: 1.0948312047514828
Validation loss: 2.6244658123407643

Epoch: 6| Step: 10
Training loss: 1.0038366627602864
Validation loss: 2.6395496684403756

Epoch: 6| Step: 11
Training loss: 1.0509957587377048
Validation loss: 2.6449221195853143

Epoch: 6| Step: 12
Training loss: 0.9155152668474289
Validation loss: 2.5894666716571875

Epoch: 6| Step: 13
Training loss: 0.8849685133165855
Validation loss: 2.628172970098511

Epoch: 120| Step: 0
Training loss: 1.0459389558524972
Validation loss: 2.6094230601744544

Epoch: 6| Step: 1
Training loss: 1.3078087117312311
Validation loss: 2.620906286836457

Epoch: 6| Step: 2
Training loss: 1.089723587248124
Validation loss: 2.6339190805431985

Epoch: 6| Step: 3
Training loss: 1.1229261781269626
Validation loss: 2.53406410615216

Epoch: 6| Step: 4
Training loss: 0.9697515171370571
Validation loss: 2.6069212014917813

Epoch: 6| Step: 5
Training loss: 0.577888620869997
Validation loss: 2.6358534610529345

Epoch: 6| Step: 6
Training loss: 0.8467001027040609
Validation loss: 2.6584107679690634

Epoch: 6| Step: 7
Training loss: 1.7519163129972766
Validation loss: 2.6418677345755355

Epoch: 6| Step: 8
Training loss: 0.8252250711165212
Validation loss: 2.7605095229935515

Epoch: 6| Step: 9
Training loss: 1.0886512713335579
Validation loss: 2.7498342868698384

Epoch: 6| Step: 10
Training loss: 0.9434206293094348
Validation loss: 2.6998939976075844

Epoch: 6| Step: 11
Training loss: 0.735405462754216
Validation loss: 2.6587577500952984

Epoch: 6| Step: 12
Training loss: 1.3647284491256513
Validation loss: 2.6715199641760288

Epoch: 6| Step: 13
Training loss: 0.9800625145688788
Validation loss: 2.6245403492866655

Epoch: 121| Step: 0
Training loss: 0.6939673109188663
Validation loss: 2.5732396086571914

Epoch: 6| Step: 1
Training loss: 0.7792253580954842
Validation loss: 2.5675478427915217

Epoch: 6| Step: 2
Training loss: 1.1929232085902775
Validation loss: 2.6595041873452114

Epoch: 6| Step: 3
Training loss: 1.0966777308948485
Validation loss: 2.6316741686040226

Epoch: 6| Step: 4
Training loss: 0.713851573684624
Validation loss: 2.6676296988658676

Epoch: 6| Step: 5
Training loss: 1.432190668417622
Validation loss: 2.6375128937055052

Epoch: 6| Step: 6
Training loss: 1.85846655956825
Validation loss: 2.6371935456968276

Epoch: 6| Step: 7
Training loss: 0.6735953108473683
Validation loss: 2.603277319046251

Epoch: 6| Step: 8
Training loss: 0.7190451223436232
Validation loss: 2.59165981441054

Epoch: 6| Step: 9
Training loss: 0.7483460945904765
Validation loss: 2.633325045810004

Epoch: 6| Step: 10
Training loss: 0.9205311177146758
Validation loss: 2.623585577264377

Epoch: 6| Step: 11
Training loss: 0.5767154780119106
Validation loss: 2.5859536038883637

Epoch: 6| Step: 12
Training loss: 1.0814090964515901
Validation loss: 2.643596474568914

Epoch: 6| Step: 13
Training loss: 0.9787969127826931
Validation loss: 2.5350459015532185

Epoch: 122| Step: 0
Training loss: 0.8713319050889786
Validation loss: 2.5483963757815657

Epoch: 6| Step: 1
Training loss: 0.9364871593843519
Validation loss: 2.5378926717170507

Epoch: 6| Step: 2
Training loss: 0.7987414921649226
Validation loss: 2.605091881745483

Epoch: 6| Step: 3
Training loss: 0.6195520904999554
Validation loss: 2.6556295680085125

Epoch: 6| Step: 4
Training loss: 0.9817095196885167
Validation loss: 2.5919297430289965

Epoch: 6| Step: 5
Training loss: 1.810249905062977
Validation loss: 2.5181972708090776

Epoch: 6| Step: 6
Training loss: 0.9672387856735274
Validation loss: 2.6332599172941116

Epoch: 6| Step: 7
Training loss: 0.9063334591023549
Validation loss: 2.5780801017781996

Epoch: 6| Step: 8
Training loss: 0.5808492601921084
Validation loss: 2.615849485984466

Epoch: 6| Step: 9
Training loss: 1.3615283791410375
Validation loss: 2.676157339725973

Epoch: 6| Step: 10
Training loss: 1.0801442903805432
Validation loss: 2.660132289933548

Epoch: 6| Step: 11
Training loss: 1.1061451059385679
Validation loss: 2.63693013415308

Epoch: 6| Step: 12
Training loss: 0.9421243421854175
Validation loss: 2.6110823750323755

Epoch: 6| Step: 13
Training loss: 0.7622178618830323
Validation loss: 2.591842179524089

Epoch: 123| Step: 0
Training loss: 1.1490107033565515
Validation loss: 2.5997668724203415

Epoch: 6| Step: 1
Training loss: 0.8424874502317008
Validation loss: 2.6095687428805108

Epoch: 6| Step: 2
Training loss: 1.1410048387978178
Validation loss: 2.5603367117639433

Epoch: 6| Step: 3
Training loss: 0.5503110298773968
Validation loss: 2.5819506226232507

Epoch: 6| Step: 4
Training loss: 0.7927405870035771
Validation loss: 2.64129181066477

Epoch: 6| Step: 5
Training loss: 0.5777870943416674
Validation loss: 2.6309380353171967

Epoch: 6| Step: 6
Training loss: 0.6990765901253142
Validation loss: 2.589725865691769

Epoch: 6| Step: 7
Training loss: 1.0111552550794947
Validation loss: 2.6778362022013042

Epoch: 6| Step: 8
Training loss: 1.2558828206343253
Validation loss: 2.6086173413795932

Epoch: 6| Step: 9
Training loss: 0.653378950147582
Validation loss: 2.6745670134551656

Epoch: 6| Step: 10
Training loss: 0.5322013079049813
Validation loss: 2.578535844838868

Epoch: 6| Step: 11
Training loss: 1.761555598585338
Validation loss: 2.5810440646359623

Epoch: 6| Step: 12
Training loss: 0.7442252443916432
Validation loss: 2.6277549304690284

Epoch: 6| Step: 13
Training loss: 1.3462657001681424
Validation loss: 2.6246536571356938

Epoch: 124| Step: 0
Training loss: 0.5918560187368667
Validation loss: 2.5827334281693255

Epoch: 6| Step: 1
Training loss: 0.9915571237749554
Validation loss: 2.575531304122474

Epoch: 6| Step: 2
Training loss: 1.004445684351573
Validation loss: 2.5613699336322115

Epoch: 6| Step: 3
Training loss: 0.544981266189712
Validation loss: 2.5178868489443915

Epoch: 6| Step: 4
Training loss: 0.5247303383693557
Validation loss: 2.515237576997617

Epoch: 6| Step: 5
Training loss: 1.9517841466743577
Validation loss: 2.5907062151195928

Epoch: 6| Step: 6
Training loss: 0.8498957008997262
Validation loss: 2.6037637831258564

Epoch: 6| Step: 7
Training loss: 0.7141160857213313
Validation loss: 2.631687395554945

Epoch: 6| Step: 8
Training loss: 1.045249987274002
Validation loss: 2.5255910307593146

Epoch: 6| Step: 9
Training loss: 0.8760838947861003
Validation loss: 2.6351851083905853

Epoch: 6| Step: 10
Training loss: 0.7859346696867138
Validation loss: 2.6629399146629695

Epoch: 6| Step: 11
Training loss: 1.1876953365888625
Validation loss: 2.6261288773792235

Epoch: 6| Step: 12
Training loss: 0.9184083900368317
Validation loss: 2.7001152114070286

Epoch: 6| Step: 13
Training loss: 1.0701094386026824
Validation loss: 2.663545679579959

Epoch: 125| Step: 0
Training loss: 1.1135184052157703
Validation loss: 2.651238414805638

Epoch: 6| Step: 1
Training loss: 1.1338746451738029
Validation loss: 2.6670264259691217

Epoch: 6| Step: 2
Training loss: 0.5960830227547833
Validation loss: 2.651739591950012

Epoch: 6| Step: 3
Training loss: 0.6069735132594275
Validation loss: 2.5973884769567808

Epoch: 6| Step: 4
Training loss: 0.535848378815138
Validation loss: 2.551059000920295

Epoch: 6| Step: 5
Training loss: 1.1694052547453555
Validation loss: 2.5995968713992283

Epoch: 6| Step: 6
Training loss: 0.54035744413386
Validation loss: 2.5723189355901157

Epoch: 6| Step: 7
Training loss: 0.762874723816618
Validation loss: 2.512093048920548

Epoch: 6| Step: 8
Training loss: 0.7495634874986086
Validation loss: 2.5896256989389137

Epoch: 6| Step: 9
Training loss: 2.0051072000208467
Validation loss: 2.606832838257887

Epoch: 6| Step: 10
Training loss: 0.9861873110729839
Validation loss: 2.6153634314664447

Epoch: 6| Step: 11
Training loss: 0.5189706459509236
Validation loss: 2.6228561956955714

Epoch: 6| Step: 12
Training loss: 0.763703640718612
Validation loss: 2.6398973835643536

Epoch: 6| Step: 13
Training loss: 1.3128661598620543
Validation loss: 2.674069728296932

Epoch: 126| Step: 0
Training loss: 0.9354163857327205
Validation loss: 2.6177890522771086

Epoch: 6| Step: 1
Training loss: 1.331497577695115
Validation loss: 2.6741075019159917

Epoch: 6| Step: 2
Training loss: 0.66757529644844
Validation loss: 2.6323948650613183

Epoch: 6| Step: 3
Training loss: 0.9544897470897734
Validation loss: 2.607504404502555

Epoch: 6| Step: 4
Training loss: 1.7567900672339969
Validation loss: 2.5804005916354895

Epoch: 6| Step: 5
Training loss: 0.7381303824826864
Validation loss: 2.541561661307422

Epoch: 6| Step: 6
Training loss: 1.2238960196141633
Validation loss: 2.579632728591331

Epoch: 6| Step: 7
Training loss: 0.9449508858083396
Validation loss: 2.594327104090068

Epoch: 6| Step: 8
Training loss: 0.8882708304808175
Validation loss: 2.5842342779677625

Epoch: 6| Step: 9
Training loss: 1.1933157205791447
Validation loss: 2.564294806786986

Epoch: 6| Step: 10
Training loss: 0.699296829723109
Validation loss: 2.63466949325222

Epoch: 6| Step: 11
Training loss: 0.4823451734101078
Validation loss: 2.7248767935754854

Epoch: 6| Step: 12
Training loss: 0.8578823651766477
Validation loss: 2.7024398258743

Epoch: 6| Step: 13
Training loss: 0.7058973123797824
Validation loss: 2.7315185886192563

Epoch: 127| Step: 0
Training loss: 0.6257445668721149
Validation loss: 2.722401472491728

Epoch: 6| Step: 1
Training loss: 1.315707782668937
Validation loss: 2.6956276308573552

Epoch: 6| Step: 2
Training loss: 0.4904202416656186
Validation loss: 2.615512232018777

Epoch: 6| Step: 3
Training loss: 0.8690002328018561
Validation loss: 2.584723595845398

Epoch: 6| Step: 4
Training loss: 0.791461244500625
Validation loss: 2.5913568509821414

Epoch: 6| Step: 5
Training loss: 0.948673609798202
Validation loss: 2.592564185367852

Epoch: 6| Step: 6
Training loss: 0.9459051371023451
Validation loss: 2.591012360219798

Epoch: 6| Step: 7
Training loss: 0.9535807786159625
Validation loss: 2.6415030319443895

Epoch: 6| Step: 8
Training loss: 1.7070169339136172
Validation loss: 2.5337996651778956

Epoch: 6| Step: 9
Training loss: 0.6419313184328924
Validation loss: 2.5552344091624195

Epoch: 6| Step: 10
Training loss: 0.8255417677734983
Validation loss: 2.591471533057961

Epoch: 6| Step: 11
Training loss: 0.6969969202312912
Validation loss: 2.6097494606675036

Epoch: 6| Step: 12
Training loss: 0.8584377379637542
Validation loss: 2.6380642996869574

Epoch: 6| Step: 13
Training loss: 0.9818900699539548
Validation loss: 2.639873021364189

Epoch: 128| Step: 0
Training loss: 1.1691234073715757
Validation loss: 2.6573975870298296

Epoch: 6| Step: 1
Training loss: 0.8931733198288843
Validation loss: 2.668578145779497

Epoch: 6| Step: 2
Training loss: 0.6465099825210074
Validation loss: 2.646699243059988

Epoch: 6| Step: 3
Training loss: 0.6430268735327448
Validation loss: 2.6262577464809373

Epoch: 6| Step: 4
Training loss: 1.6829429129644056
Validation loss: 2.5927114437376324

Epoch: 6| Step: 5
Training loss: 0.5840215256525543
Validation loss: 2.5802942416987436

Epoch: 6| Step: 6
Training loss: 0.7753700618755768
Validation loss: 2.5242907299065216

Epoch: 6| Step: 7
Training loss: 1.01092327172763
Validation loss: 2.616392297594593

Epoch: 6| Step: 8
Training loss: 1.0458685178778102
Validation loss: 2.570270108972003

Epoch: 6| Step: 9
Training loss: 0.5557695231730099
Validation loss: 2.5676467661153475

Epoch: 6| Step: 10
Training loss: 0.8137875771819106
Validation loss: 2.5855373138221753

Epoch: 6| Step: 11
Training loss: 0.8837349047848679
Validation loss: 2.7285496448606907

Epoch: 6| Step: 12
Training loss: 1.1212530255569242
Validation loss: 2.7926320404327796

Epoch: 6| Step: 13
Training loss: 1.06623011661071
Validation loss: 2.774895183771703

Epoch: 129| Step: 0
Training loss: 0.5973473043333533
Validation loss: 2.728981205897081

Epoch: 6| Step: 1
Training loss: 1.2077263370786602
Validation loss: 2.622152767388559

Epoch: 6| Step: 2
Training loss: 0.859522824144698
Validation loss: 2.622840416860177

Epoch: 6| Step: 3
Training loss: 1.0372602277625231
Validation loss: 2.611370732091324

Epoch: 6| Step: 4
Training loss: 1.124160559382909
Validation loss: 2.632016953168783

Epoch: 6| Step: 5
Training loss: 0.8675342931757615
Validation loss: 2.5699386479393356

Epoch: 6| Step: 6
Training loss: 1.7617822200058553
Validation loss: 2.5914440092092708

Epoch: 6| Step: 7
Training loss: 0.5991264162705457
Validation loss: 2.6832511346283208

Epoch: 6| Step: 8
Training loss: 0.7861558235544267
Validation loss: 2.652513081946488

Epoch: 6| Step: 9
Training loss: 0.7903806044805027
Validation loss: 2.609803794608738

Epoch: 6| Step: 10
Training loss: 0.480807177439924
Validation loss: 2.6949032237807398

Epoch: 6| Step: 11
Training loss: 1.0461651687230504
Validation loss: 2.659202296338006

Epoch: 6| Step: 12
Training loss: 0.9788388995529735
Validation loss: 2.660467651484058

Epoch: 6| Step: 13
Training loss: 0.82009506977052
Validation loss: 2.7322548775929696

Epoch: 130| Step: 0
Training loss: 1.1162943971525598
Validation loss: 2.6322123808569677

Epoch: 6| Step: 1
Training loss: 1.1021571076380137
Validation loss: 2.6283565889425073

Epoch: 6| Step: 2
Training loss: 0.5589251835457916
Validation loss: 2.6292964651367883

Epoch: 6| Step: 3
Training loss: 0.8338199783995187
Validation loss: 2.6651238408995437

Epoch: 6| Step: 4
Training loss: 1.869176467663459
Validation loss: 2.6314689762577865

Epoch: 6| Step: 5
Training loss: 0.8705858195211464
Validation loss: 2.5608289278610905

Epoch: 6| Step: 6
Training loss: 0.6919982014092462
Validation loss: 2.6028107940830676

Epoch: 6| Step: 7
Training loss: 0.6688779922358539
Validation loss: 2.584268513476432

Epoch: 6| Step: 8
Training loss: 0.7685800473053577
Validation loss: 2.6661676645301107

Epoch: 6| Step: 9
Training loss: 0.7003537135868037
Validation loss: 2.6006326779844513

Epoch: 6| Step: 10
Training loss: 0.9651404785527672
Validation loss: 2.574274011384431

Epoch: 6| Step: 11
Training loss: 0.6530463267129074
Validation loss: 2.6029727996624303

Epoch: 6| Step: 12
Training loss: 0.7165492822931113
Validation loss: 2.567258046086985

Epoch: 6| Step: 13
Training loss: 0.4502879314351814
Validation loss: 2.5543220795296344

Epoch: 131| Step: 0
Training loss: 0.5608576534471713
Validation loss: 2.58452113336892

Epoch: 6| Step: 1
Training loss: 0.5058931906455074
Validation loss: 2.628234323956122

Epoch: 6| Step: 2
Training loss: 0.5634772236256547
Validation loss: 2.590607696831272

Epoch: 6| Step: 3
Training loss: 0.835421750694527
Validation loss: 2.620050775191252

Epoch: 6| Step: 4
Training loss: 1.049760059916258
Validation loss: 2.5703105211491875

Epoch: 6| Step: 5
Training loss: 0.7170179062659707
Validation loss: 2.61469380017444

Epoch: 6| Step: 6
Training loss: 0.48878977425925163
Validation loss: 2.583596621191573

Epoch: 6| Step: 7
Training loss: 0.6616781174976485
Validation loss: 2.5063461342351214

Epoch: 6| Step: 8
Training loss: 1.1576049701064632
Validation loss: 2.610707017278254

Epoch: 6| Step: 9
Training loss: 0.7911711363338361
Validation loss: 2.6356828778776142

Epoch: 6| Step: 10
Training loss: 0.95427721762974
Validation loss: 2.6180978434885946

Epoch: 6| Step: 11
Training loss: 1.8667804481819703
Validation loss: 2.63735185722381

Epoch: 6| Step: 12
Training loss: 0.7650075096185636
Validation loss: 2.5869153067044715

Epoch: 6| Step: 13
Training loss: 0.6327918955898224
Validation loss: 2.6674464893545182

Epoch: 132| Step: 0
Training loss: 0.7080345832762072
Validation loss: 2.6307089200194524

Epoch: 6| Step: 1
Training loss: 1.0694806841425268
Validation loss: 2.621395285137548

Epoch: 6| Step: 2
Training loss: 0.5563468827303678
Validation loss: 2.6814677161187257

Epoch: 6| Step: 3
Training loss: 1.01749717112155
Validation loss: 2.536256744290568

Epoch: 6| Step: 4
Training loss: 0.543323209040265
Validation loss: 2.564972762148511

Epoch: 6| Step: 5
Training loss: 0.6682688613324814
Validation loss: 2.6446378114493405

Epoch: 6| Step: 6
Training loss: 1.1596996295020165
Validation loss: 2.6452724858588836

Epoch: 6| Step: 7
Training loss: 0.9750260129539569
Validation loss: 2.6219808382080476

Epoch: 6| Step: 8
Training loss: 0.8815283423685525
Validation loss: 2.5813031268868

Epoch: 6| Step: 9
Training loss: 1.7098716307302282
Validation loss: 2.5670438271592753

Epoch: 6| Step: 10
Training loss: 0.7017938092387839
Validation loss: 2.62088346893276

Epoch: 6| Step: 11
Training loss: 0.5808173456231049
Validation loss: 2.640776755883594

Epoch: 6| Step: 12
Training loss: 0.5259072978821732
Validation loss: 2.5910316148181445

Epoch: 6| Step: 13
Training loss: 0.6170122887795711
Validation loss: 2.6498696085202034

Epoch: 133| Step: 0
Training loss: 0.6388299262324773
Validation loss: 2.6149258078996622

Epoch: 6| Step: 1
Training loss: 0.8911020440216132
Validation loss: 2.6278597679367506

Epoch: 6| Step: 2
Training loss: 0.8410893628953658
Validation loss: 2.7199952281063893

Epoch: 6| Step: 3
Training loss: 0.6426531159491234
Validation loss: 2.6949099843686795

Epoch: 6| Step: 4
Training loss: 0.9590768555840519
Validation loss: 2.728470769398357

Epoch: 6| Step: 5
Training loss: 1.0439421151436068
Validation loss: 2.6132750613258575

Epoch: 6| Step: 6
Training loss: 0.7063361697671828
Validation loss: 2.6463940894760483

Epoch: 6| Step: 7
Training loss: 0.7112382525125868
Validation loss: 2.6129563323959974

Epoch: 6| Step: 8
Training loss: 0.8294967949444899
Validation loss: 2.676360731653677

Epoch: 6| Step: 9
Training loss: 0.6412486785369403
Validation loss: 2.67296456174886

Epoch: 6| Step: 10
Training loss: 0.682308667580203
Validation loss: 2.762073154182301

Epoch: 6| Step: 11
Training loss: 1.824800647664572
Validation loss: 2.6853899693746532

Epoch: 6| Step: 12
Training loss: 0.9471567622287864
Validation loss: 2.7713653130257274

Epoch: 6| Step: 13
Training loss: 0.5775198991658167
Validation loss: 2.753824219259767

Epoch: 134| Step: 0
Training loss: 1.6564709498019703
Validation loss: 2.752125539944526

Epoch: 6| Step: 1
Training loss: 0.811938458576977
Validation loss: 2.6530614077701737

Epoch: 6| Step: 2
Training loss: 0.9362316452692226
Validation loss: 2.6867276198128054

Epoch: 6| Step: 3
Training loss: 0.8994513057656215
Validation loss: 2.680425751683202

Epoch: 6| Step: 4
Training loss: 0.7738584663647193
Validation loss: 2.662759934155608

Epoch: 6| Step: 5
Training loss: 1.1414655958514262
Validation loss: 2.604199544063296

Epoch: 6| Step: 6
Training loss: 0.6083445762440156
Validation loss: 2.6327348163739113

Epoch: 6| Step: 7
Training loss: 0.5598565080420298
Validation loss: 2.697054829648453

Epoch: 6| Step: 8
Training loss: 0.74379724304435
Validation loss: 2.6979302856415783

Epoch: 6| Step: 9
Training loss: 0.8212701203365164
Validation loss: 2.620138525831508

Epoch: 6| Step: 10
Training loss: 0.46867300036931614
Validation loss: 2.5940461966284083

Epoch: 6| Step: 11
Training loss: 0.4021767390011232
Validation loss: 2.6244958968757586

Epoch: 6| Step: 12
Training loss: 0.9138680927869728
Validation loss: 2.533807647581245

Epoch: 6| Step: 13
Training loss: 0.9151120477350413
Validation loss: 2.6187427966763064

Epoch: 135| Step: 0
Training loss: 0.5228405010434122
Validation loss: 2.6751603420129646

Epoch: 6| Step: 1
Training loss: 1.6220562754557066
Validation loss: 2.6740475126423564

Epoch: 6| Step: 2
Training loss: 0.7302532184063681
Validation loss: 2.6603454432939775

Epoch: 6| Step: 3
Training loss: 0.6443481185145589
Validation loss: 2.659684373228279

Epoch: 6| Step: 4
Training loss: 0.7337855550414618
Validation loss: 2.6432605209119555

Epoch: 6| Step: 5
Training loss: 0.47332221789919815
Validation loss: 2.70745083051271

Epoch: 6| Step: 6
Training loss: 1.234942245522932
Validation loss: 2.705864930747223

Epoch: 6| Step: 7
Training loss: 1.157091247115765
Validation loss: 2.623543516905764

Epoch: 6| Step: 8
Training loss: 0.5301699036746523
Validation loss: 2.658580281457705

Epoch: 6| Step: 9
Training loss: 0.6316024136471184
Validation loss: 2.6719630340291007

Epoch: 6| Step: 10
Training loss: 0.7954968147070199
Validation loss: 2.6154601512691396

Epoch: 6| Step: 11
Training loss: 0.5196597578542923
Validation loss: 2.677207355125078

Epoch: 6| Step: 12
Training loss: 0.7133753970332066
Validation loss: 2.6300877659927524

Epoch: 6| Step: 13
Training loss: 0.7071915334197966
Validation loss: 2.6208389241735586

Epoch: 136| Step: 0
Training loss: 1.6349255336637232
Validation loss: 2.6673484516800676

Epoch: 6| Step: 1
Training loss: 0.4932644883438505
Validation loss: 2.705941748444849

Epoch: 6| Step: 2
Training loss: 0.5143542380795333
Validation loss: 2.6325180462577618

Epoch: 6| Step: 3
Training loss: 0.8481139604135329
Validation loss: 2.657177378012242

Epoch: 6| Step: 4
Training loss: 0.5136917458523654
Validation loss: 2.638969685059363

Epoch: 6| Step: 5
Training loss: 0.9741290481739767
Validation loss: 2.589692154979086

Epoch: 6| Step: 6
Training loss: 1.0359987105615611
Validation loss: 2.588701996676725

Epoch: 6| Step: 7
Training loss: 0.9797312786049167
Validation loss: 2.5984529349120415

Epoch: 6| Step: 8
Training loss: 0.5759656116664398
Validation loss: 2.659673661025784

Epoch: 6| Step: 9
Training loss: 0.7148683053890662
Validation loss: 2.6584164853579098

Epoch: 6| Step: 10
Training loss: 0.9252859150559802
Validation loss: 2.6801927718535965

Epoch: 6| Step: 11
Training loss: 0.5653715482611062
Validation loss: 2.635419435964544

Epoch: 6| Step: 12
Training loss: 0.6547785793489024
Validation loss: 2.6189212199875853

Epoch: 6| Step: 13
Training loss: 0.5618826339254006
Validation loss: 2.671826367744315

Epoch: 137| Step: 0
Training loss: 0.8319208851002657
Validation loss: 2.717657227703977

Epoch: 6| Step: 1
Training loss: 1.6897471971303757
Validation loss: 2.6842866805338854

Epoch: 6| Step: 2
Training loss: 0.7257573989217686
Validation loss: 2.672813719097222

Epoch: 6| Step: 3
Training loss: 0.5252039694790773
Validation loss: 2.6457553511614145

Epoch: 6| Step: 4
Training loss: 0.6219608324328276
Validation loss: 2.6332676736476444

Epoch: 6| Step: 5
Training loss: 0.9253726814176046
Validation loss: 2.6934892467734737

Epoch: 6| Step: 6
Training loss: 0.7078528925336547
Validation loss: 2.5827897689505237

Epoch: 6| Step: 7
Training loss: 0.5039739341523606
Validation loss: 2.5835559246599917

Epoch: 6| Step: 8
Training loss: 0.6994527073729713
Validation loss: 2.587510382589988

Epoch: 6| Step: 9
Training loss: 0.8709707130474883
Validation loss: 2.6129818351825675

Epoch: 6| Step: 10
Training loss: 1.0195204927892745
Validation loss: 2.6464715223012014

Epoch: 6| Step: 11
Training loss: 0.6323778520027028
Validation loss: 2.7034601213291243

Epoch: 6| Step: 12
Training loss: 0.6813330188527784
Validation loss: 2.670652381214413

Epoch: 6| Step: 13
Training loss: 0.6453906716204845
Validation loss: 2.6744775125163507

Epoch: 138| Step: 0
Training loss: 0.620113438872774
Validation loss: 2.6903327384415245

Epoch: 6| Step: 1
Training loss: 0.7084224775729888
Validation loss: 2.690263613578951

Epoch: 6| Step: 2
Training loss: 0.7185051542454278
Validation loss: 2.698281662355732

Epoch: 6| Step: 3
Training loss: 0.503328095192
Validation loss: 2.706025054486718

Epoch: 6| Step: 4
Training loss: 0.8075701735626238
Validation loss: 2.602734795152925

Epoch: 6| Step: 5
Training loss: 0.6657555707282314
Validation loss: 2.5722688072916755

Epoch: 6| Step: 6
Training loss: 0.7079748527484405
Validation loss: 2.645894392815852

Epoch: 6| Step: 7
Training loss: 0.9021790589485063
Validation loss: 2.635219873210116

Epoch: 6| Step: 8
Training loss: 0.7460581586247601
Validation loss: 2.6134643262475934

Epoch: 6| Step: 9
Training loss: 1.639637168313902
Validation loss: 2.6287307718480415

Epoch: 6| Step: 10
Training loss: 0.8781461014027994
Validation loss: 2.5960436870972305

Epoch: 6| Step: 11
Training loss: 0.8222346719094267
Validation loss: 2.6861312101029235

Epoch: 6| Step: 12
Training loss: 0.7972788441901735
Validation loss: 2.7884319600662275

Epoch: 6| Step: 13
Training loss: 0.7732277017283413
Validation loss: 2.7331372247878027

Epoch: 139| Step: 0
Training loss: 0.5456891417845121
Validation loss: 2.7190050904316476

Epoch: 6| Step: 1
Training loss: 0.5267055464328503
Validation loss: 2.6699271138085643

Epoch: 6| Step: 2
Training loss: 0.8772288613238953
Validation loss: 2.651394538902238

Epoch: 6| Step: 3
Training loss: 1.7036011756385963
Validation loss: 2.6238866064533912

Epoch: 6| Step: 4
Training loss: 1.0932136310396154
Validation loss: 2.711107129626486

Epoch: 6| Step: 5
Training loss: 0.6969255959314592
Validation loss: 2.6439378862524903

Epoch: 6| Step: 6
Training loss: 0.41437227429490314
Validation loss: 2.718014467795488

Epoch: 6| Step: 7
Training loss: 0.3599965070184157
Validation loss: 2.667319833712592

Epoch: 6| Step: 8
Training loss: 0.6663656797056013
Validation loss: 2.6810956245091377

Epoch: 6| Step: 9
Training loss: 0.8013143486214066
Validation loss: 2.680650217452483

Epoch: 6| Step: 10
Training loss: 1.0483665658346146
Validation loss: 2.6985410583922635

Epoch: 6| Step: 11
Training loss: 0.7756889787794634
Validation loss: 2.6546298901865137

Epoch: 6| Step: 12
Training loss: 0.6831687478020375
Validation loss: 2.711347169730896

Epoch: 6| Step: 13
Training loss: 0.6219808373412558
Validation loss: 2.710715117114252

Epoch: 140| Step: 0
Training loss: 0.8500022593636498
Validation loss: 2.681418865135578

Epoch: 6| Step: 1
Training loss: 0.6749182245381214
Validation loss: 2.659597150442106

Epoch: 6| Step: 2
Training loss: 0.6069704199595493
Validation loss: 2.5869813715663788

Epoch: 6| Step: 3
Training loss: 0.8045546412739415
Validation loss: 2.594543213181606

Epoch: 6| Step: 4
Training loss: 0.8901897504601706
Validation loss: 2.608990243043758

Epoch: 6| Step: 5
Training loss: 0.51371831647719
Validation loss: 2.618179376261669

Epoch: 6| Step: 6
Training loss: 0.7799186807204211
Validation loss: 2.6099996142795128

Epoch: 6| Step: 7
Training loss: 0.7576587953719456
Validation loss: 2.622469257335762

Epoch: 6| Step: 8
Training loss: 1.5852408546818035
Validation loss: 2.6153825751608806

Epoch: 6| Step: 9
Training loss: 0.6782615875649134
Validation loss: 2.672688574113676

Epoch: 6| Step: 10
Training loss: 0.9257853061249158
Validation loss: 2.660350252864433

Epoch: 6| Step: 11
Training loss: 0.7716612407900031
Validation loss: 2.615220244343126

Epoch: 6| Step: 12
Training loss: 0.7570534276715503
Validation loss: 2.607548255095965

Epoch: 6| Step: 13
Training loss: 0.4116328951590782
Validation loss: 2.6575799940862455

Epoch: 141| Step: 0
Training loss: 0.902311349262292
Validation loss: 2.6655723193897116

Epoch: 6| Step: 1
Training loss: 0.6296207799658369
Validation loss: 2.647658812190625

Epoch: 6| Step: 2
Training loss: 0.6167819706841617
Validation loss: 2.6054995724190815

Epoch: 6| Step: 3
Training loss: 0.45282307793455684
Validation loss: 2.635651677224074

Epoch: 6| Step: 4
Training loss: 1.6592833614010118
Validation loss: 2.7139940793833275

Epoch: 6| Step: 5
Training loss: 0.9086839941051472
Validation loss: 2.6397473835014975

Epoch: 6| Step: 6
Training loss: 0.4358424565063634
Validation loss: 2.6737295782311907

Epoch: 6| Step: 7
Training loss: 0.8216149662135824
Validation loss: 2.5831011134545467

Epoch: 6| Step: 8
Training loss: 0.7147802105790456
Validation loss: 2.61104175687448

Epoch: 6| Step: 9
Training loss: 0.5135112264663305
Validation loss: 2.680909081328543

Epoch: 6| Step: 10
Training loss: 0.5715809915762238
Validation loss: 2.637064276767185

Epoch: 6| Step: 11
Training loss: 0.7772795684235554
Validation loss: 2.546779045684537

Epoch: 6| Step: 12
Training loss: 0.8840292588393264
Validation loss: 2.6699608830409467

Epoch: 6| Step: 13
Training loss: 0.6326005368751758
Validation loss: 2.592023374371647

Epoch: 142| Step: 0
Training loss: 0.8668432153706803
Validation loss: 2.674299697772705

Epoch: 6| Step: 1
Training loss: 0.7283465723657445
Validation loss: 2.6904115947431193

Epoch: 6| Step: 2
Training loss: 0.8082619322542904
Validation loss: 2.646082097971974

Epoch: 6| Step: 3
Training loss: 0.4586607908411518
Validation loss: 2.738058700623788

Epoch: 6| Step: 4
Training loss: 0.4409986487636063
Validation loss: 2.6974241526407887

Epoch: 6| Step: 5
Training loss: 0.6644435462507913
Validation loss: 2.705558254998662

Epoch: 6| Step: 6
Training loss: 0.47196174859975903
Validation loss: 2.7086658689339838

Epoch: 6| Step: 7
Training loss: 0.6229905727861097
Validation loss: 2.674145839661968

Epoch: 6| Step: 8
Training loss: 0.5839570718461982
Validation loss: 2.6187150890660535

Epoch: 6| Step: 9
Training loss: 0.5466506497820198
Validation loss: 2.629466087432597

Epoch: 6| Step: 10
Training loss: 1.005210237385951
Validation loss: 2.6464781438512515

Epoch: 6| Step: 11
Training loss: 1.7583425443266414
Validation loss: 2.626454041446925

Epoch: 6| Step: 12
Training loss: 0.6385433289307639
Validation loss: 2.6933640739800118

Epoch: 6| Step: 13
Training loss: 0.5637208088593448
Validation loss: 2.681478504263802

Epoch: 143| Step: 0
Training loss: 1.0016929482002257
Validation loss: 2.6828153426181762

Epoch: 6| Step: 1
Training loss: 0.6792009738924123
Validation loss: 2.686028735771427

Epoch: 6| Step: 2
Training loss: 0.6008911845767558
Validation loss: 2.644122604434194

Epoch: 6| Step: 3
Training loss: 0.5725139560830782
Validation loss: 2.6247032391360534

Epoch: 6| Step: 4
Training loss: 1.580281210392143
Validation loss: 2.72851467837966

Epoch: 6| Step: 5
Training loss: 0.873954557123464
Validation loss: 2.7114770006164215

Epoch: 6| Step: 6
Training loss: 0.536985931082545
Validation loss: 2.653036739587209

Epoch: 6| Step: 7
Training loss: 0.38380496159592137
Validation loss: 2.680872292876346

Epoch: 6| Step: 8
Training loss: 0.5834936931991677
Validation loss: 2.710537825116358

Epoch: 6| Step: 9
Training loss: 0.6243986097421754
Validation loss: 2.5967064825375306

Epoch: 6| Step: 10
Training loss: 0.6795485562778272
Validation loss: 2.615396051629985

Epoch: 6| Step: 11
Training loss: 0.6700256311794752
Validation loss: 2.6144246107661315

Epoch: 6| Step: 12
Training loss: 0.6609456009965801
Validation loss: 2.618878819188629

Epoch: 6| Step: 13
Training loss: 0.6641184614948488
Validation loss: 2.7014000888865777

Epoch: 144| Step: 0
Training loss: 1.5687971252415067
Validation loss: 2.7231633477133474

Epoch: 6| Step: 1
Training loss: 0.6139753265238332
Validation loss: 2.724319920267125

Epoch: 6| Step: 2
Training loss: 0.7317771006323703
Validation loss: 2.789151273110701

Epoch: 6| Step: 3
Training loss: 0.61798117103102
Validation loss: 2.687370873831194

Epoch: 6| Step: 4
Training loss: 0.644217443656846
Validation loss: 2.735277597320979

Epoch: 6| Step: 5
Training loss: 0.8340866061943706
Validation loss: 2.717843295501824

Epoch: 6| Step: 6
Training loss: 0.3939402468823267
Validation loss: 2.6587120090383425

Epoch: 6| Step: 7
Training loss: 0.5751253613357056
Validation loss: 2.607187690647982

Epoch: 6| Step: 8
Training loss: 0.611880945209926
Validation loss: 2.691591194637947

Epoch: 6| Step: 9
Training loss: 0.9362579064742018
Validation loss: 2.615751185501036

Epoch: 6| Step: 10
Training loss: 0.8001772579868609
Validation loss: 2.68694131056389

Epoch: 6| Step: 11
Training loss: 0.49543330768049665
Validation loss: 2.642494623256327

Epoch: 6| Step: 12
Training loss: 0.8761973363312107
Validation loss: 2.6906201045412312

Epoch: 6| Step: 13
Training loss: 0.42845831099146614
Validation loss: 2.6672975767364573

Epoch: 145| Step: 0
Training loss: 0.8931845309983794
Validation loss: 2.7447263117518905

Epoch: 6| Step: 1
Training loss: 0.5000078677512089
Validation loss: 2.6457210777278513

Epoch: 6| Step: 2
Training loss: 0.8386376880772506
Validation loss: 2.764848129442894

Epoch: 6| Step: 3
Training loss: 0.7909404954435312
Validation loss: 2.6812756191117515

Epoch: 6| Step: 4
Training loss: 0.5558233853965049
Validation loss: 2.663338063951603

Epoch: 6| Step: 5
Training loss: 0.6117747567408957
Validation loss: 2.706499848494569

Epoch: 6| Step: 6
Training loss: 1.578967483291995
Validation loss: 2.68443214909297

Epoch: 6| Step: 7
Training loss: 0.6992374396357052
Validation loss: 2.6715423049666196

Epoch: 6| Step: 8
Training loss: 0.5595119372637851
Validation loss: 2.647833351087071

Epoch: 6| Step: 9
Training loss: 0.4257563312483121
Validation loss: 2.6614453090839256

Epoch: 6| Step: 10
Training loss: 0.49132271133912336
Validation loss: 2.6541214586257453

Epoch: 6| Step: 11
Training loss: 0.47030974605932635
Validation loss: 2.7395507510801727

Epoch: 6| Step: 12
Training loss: 0.5548960602577662
Validation loss: 2.7448931294652374

Epoch: 6| Step: 13
Training loss: 0.8310117609612553
Validation loss: 2.732540365271729

Epoch: 146| Step: 0
Training loss: 0.7076685862309277
Validation loss: 2.6815647411792733

Epoch: 6| Step: 1
Training loss: 0.539010086828626
Validation loss: 2.723495448931865

Epoch: 6| Step: 2
Training loss: 0.7011879836758368
Validation loss: 2.640312161244868

Epoch: 6| Step: 3
Training loss: 0.511982041975338
Validation loss: 2.584802076730196

Epoch: 6| Step: 4
Training loss: 0.8711964499656081
Validation loss: 2.6501961929342692

Epoch: 6| Step: 5
Training loss: 0.7431477007274097
Validation loss: 2.689321927980091

Epoch: 6| Step: 6
Training loss: 1.6001778175964871
Validation loss: 2.673875873771861

Epoch: 6| Step: 7
Training loss: 0.5496200874981849
Validation loss: 2.6780412397487923

Epoch: 6| Step: 8
Training loss: 0.36379568530796136
Validation loss: 2.7255862290808097

Epoch: 6| Step: 9
Training loss: 0.5751538609851735
Validation loss: 2.6883058153113004

Epoch: 6| Step: 10
Training loss: 0.5345436822671504
Validation loss: 2.6559613538500404

Epoch: 6| Step: 11
Training loss: 0.41871846777778826
Validation loss: 2.6888501967342666

Epoch: 6| Step: 12
Training loss: 0.8148537800684523
Validation loss: 2.681376644958273

Epoch: 6| Step: 13
Training loss: 0.7668856926431405
Validation loss: 2.687576329825481

Epoch: 147| Step: 0
Training loss: 0.6718029604593037
Validation loss: 2.722164552968709

Epoch: 6| Step: 1
Training loss: 0.605854010296896
Validation loss: 2.6461322545479775

Epoch: 6| Step: 2
Training loss: 0.6150488437469607
Validation loss: 2.6990246406241667

Epoch: 6| Step: 3
Training loss: 0.6685099946489631
Validation loss: 2.741996468667173

Epoch: 6| Step: 4
Training loss: 0.6084438937673653
Validation loss: 2.6694570833062006

Epoch: 6| Step: 5
Training loss: 0.6971527991385791
Validation loss: 2.769400998430202

Epoch: 6| Step: 6
Training loss: 0.6511777176162953
Validation loss: 2.7215087165326155

Epoch: 6| Step: 7
Training loss: 0.4477292119562025
Validation loss: 2.726500298228674

Epoch: 6| Step: 8
Training loss: 0.725131892670803
Validation loss: 2.626569097307533

Epoch: 6| Step: 9
Training loss: 0.42309260380969554
Validation loss: 2.640201211062489

Epoch: 6| Step: 10
Training loss: 1.6956448558821695
Validation loss: 2.604021592231841

Epoch: 6| Step: 11
Training loss: 0.5897983760939447
Validation loss: 2.6207361711727155

Epoch: 6| Step: 12
Training loss: 0.788293747287735
Validation loss: 2.697360468694793

Epoch: 6| Step: 13
Training loss: 0.5614205174872013
Validation loss: 2.6075038330303535

Epoch: 148| Step: 0
Training loss: 0.5050823474067331
Validation loss: 2.6307742929424216

Epoch: 6| Step: 1
Training loss: 0.7285760031217259
Validation loss: 2.674908676252308

Epoch: 6| Step: 2
Training loss: 0.6852754669689975
Validation loss: 2.732230589912732

Epoch: 6| Step: 3
Training loss: 0.6206865475303218
Validation loss: 2.653297878185046

Epoch: 6| Step: 4
Training loss: 1.52786480145225
Validation loss: 2.6017180464088416

Epoch: 6| Step: 5
Training loss: 1.0812572368754496
Validation loss: 2.625548244929278

Epoch: 6| Step: 6
Training loss: 0.49707361006626605
Validation loss: 2.587409723092205

Epoch: 6| Step: 7
Training loss: 0.42048020615523474
Validation loss: 2.635073738755366

Epoch: 6| Step: 8
Training loss: 0.49645577385109635
Validation loss: 2.6394802222903464

Epoch: 6| Step: 9
Training loss: 0.6219628449317663
Validation loss: 2.6464752910312654

Epoch: 6| Step: 10
Training loss: 0.6999593041715625
Validation loss: 2.608348492242153

Epoch: 6| Step: 11
Training loss: 0.5596938338099716
Validation loss: 2.7389615348026743

Epoch: 6| Step: 12
Training loss: 0.5170005598784612
Validation loss: 2.7151891255412166

Epoch: 6| Step: 13
Training loss: 0.43801963124089466
Validation loss: 2.7003283724844254

Epoch: 149| Step: 0
Training loss: 0.5220545534095177
Validation loss: 2.6606461442174867

Epoch: 6| Step: 1
Training loss: 0.43352848283457485
Validation loss: 2.716762254550599

Epoch: 6| Step: 2
Training loss: 1.5045652852877043
Validation loss: 2.6372085078762146

Epoch: 6| Step: 3
Training loss: 0.5297056076870666
Validation loss: 2.636427875063026

Epoch: 6| Step: 4
Training loss: 0.38606434177862853
Validation loss: 2.7045575794417367

Epoch: 6| Step: 5
Training loss: 0.6970816404235068
Validation loss: 2.680106164611082

Epoch: 6| Step: 6
Training loss: 0.5427137366066763
Validation loss: 2.6050771469485796

Epoch: 6| Step: 7
Training loss: 0.7074889498275664
Validation loss: 2.617699962946155

Epoch: 6| Step: 8
Training loss: 0.4937363429534767
Validation loss: 2.7132771973891328

Epoch: 6| Step: 9
Training loss: 0.8708912224822553
Validation loss: 2.6410626231266328

Epoch: 6| Step: 10
Training loss: 0.6471424729226691
Validation loss: 2.5936316957265526

Epoch: 6| Step: 11
Training loss: 0.6080915678269294
Validation loss: 2.6822280036753696

Epoch: 6| Step: 12
Training loss: 0.47211819754283524
Validation loss: 2.660855119781077

Epoch: 6| Step: 13
Training loss: 1.118331323632274
Validation loss: 2.6769165749074593

Epoch: 150| Step: 0
Training loss: 0.8445458367682164
Validation loss: 2.7545829789182563

Epoch: 6| Step: 1
Training loss: 0.547013946320546
Validation loss: 2.6738880151692235

Epoch: 6| Step: 2
Training loss: 0.6058454264763563
Validation loss: 2.740231532781699

Epoch: 6| Step: 3
Training loss: 1.5207429972256457
Validation loss: 2.707885357903254

Epoch: 6| Step: 4
Training loss: 0.6360453221349028
Validation loss: 2.7307555739742178

Epoch: 6| Step: 5
Training loss: 0.6105278309922922
Validation loss: 2.682939563512714

Epoch: 6| Step: 6
Training loss: 0.6052972858429235
Validation loss: 2.730344086412987

Epoch: 6| Step: 7
Training loss: 0.4002403535532262
Validation loss: 2.5946631605092607

Epoch: 6| Step: 8
Training loss: 0.7245951031618648
Validation loss: 2.7280591702611816

Epoch: 6| Step: 9
Training loss: 0.6114297849325748
Validation loss: 2.7413585384373804

Epoch: 6| Step: 10
Training loss: 0.5904096200594726
Validation loss: 2.694533179210467

Epoch: 6| Step: 11
Training loss: 0.750905999686982
Validation loss: 2.6462530168706233

Epoch: 6| Step: 12
Training loss: 0.26583842510819905
Validation loss: 2.7205396001983795

Epoch: 6| Step: 13
Training loss: 0.6718804115254906
Validation loss: 2.6715150557216383

Epoch: 151| Step: 0
Training loss: 0.5262752304009233
Validation loss: 2.6570837021491904

Epoch: 6| Step: 1
Training loss: 0.9336553577222588
Validation loss: 2.5974138342768596

Epoch: 6| Step: 2
Training loss: 0.673260524357278
Validation loss: 2.68652330438079

Epoch: 6| Step: 3
Training loss: 0.7467915731785186
Validation loss: 2.696644064341328

Epoch: 6| Step: 4
Training loss: 0.657816017485794
Validation loss: 2.6373911209895016

Epoch: 6| Step: 5
Training loss: 0.4690492310702604
Validation loss: 2.6876994362101763

Epoch: 6| Step: 6
Training loss: 0.6251769053911373
Validation loss: 2.6724427049524104

Epoch: 6| Step: 7
Training loss: 0.5378728261092979
Validation loss: 2.653820879362949

Epoch: 6| Step: 8
Training loss: 0.46477222693790077
Validation loss: 2.68210413502541

Epoch: 6| Step: 9
Training loss: 0.4602039934140483
Validation loss: 2.6916631346247346

Epoch: 6| Step: 10
Training loss: 0.6731413506494023
Validation loss: 2.7009579566217075

Epoch: 6| Step: 11
Training loss: 0.5056955079474903
Validation loss: 2.6375694880439178

Epoch: 6| Step: 12
Training loss: 1.5477881770588282
Validation loss: 2.6169228187445555

Epoch: 6| Step: 13
Training loss: 0.615791117335733
Validation loss: 2.713373897781953

Epoch: 152| Step: 0
Training loss: 0.49021065035249595
Validation loss: 2.6282849723158046

Epoch: 6| Step: 1
Training loss: 0.5186822306936123
Validation loss: 2.636190434026055

Epoch: 6| Step: 2
Training loss: 0.9547008557173658
Validation loss: 2.6368523909998047

Epoch: 6| Step: 3
Training loss: 0.5567963499449706
Validation loss: 2.7236210533408904

Epoch: 6| Step: 4
Training loss: 0.6131278411068356
Validation loss: 2.68649913573936

Epoch: 6| Step: 5
Training loss: 0.5775136034465617
Validation loss: 2.6593397234539236

Epoch: 6| Step: 6
Training loss: 0.5859778326776166
Validation loss: 2.7024579998449756

Epoch: 6| Step: 7
Training loss: 0.5135365587126193
Validation loss: 2.700347149277915

Epoch: 6| Step: 8
Training loss: 0.44496464109315276
Validation loss: 2.6242558317601468

Epoch: 6| Step: 9
Training loss: 0.5050858581847841
Validation loss: 2.690506236977193

Epoch: 6| Step: 10
Training loss: 0.3978476365447691
Validation loss: 2.7400182564909166

Epoch: 6| Step: 11
Training loss: 0.978497107172585
Validation loss: 2.733318233642119

Epoch: 6| Step: 12
Training loss: 0.569626199266897
Validation loss: 2.6777226962320158

Epoch: 6| Step: 13
Training loss: 1.5666795145008492
Validation loss: 2.73239773423113

Epoch: 153| Step: 0
Training loss: 0.42324032433226916
Validation loss: 2.738254244059463

Epoch: 6| Step: 1
Training loss: 0.5796031098747672
Validation loss: 2.7568038666504133

Epoch: 6| Step: 2
Training loss: 0.964848414112509
Validation loss: 2.7107863736788147

Epoch: 6| Step: 3
Training loss: 1.6125882856463725
Validation loss: 2.767837063618385

Epoch: 6| Step: 4
Training loss: 0.515323695378694
Validation loss: 2.705527691259206

Epoch: 6| Step: 5
Training loss: 0.3226395374061587
Validation loss: 2.580104368597605

Epoch: 6| Step: 6
Training loss: 0.6861841006157872
Validation loss: 2.615185282034898

Epoch: 6| Step: 7
Training loss: 0.5906634666389915
Validation loss: 2.633628228330685

Epoch: 6| Step: 8
Training loss: 0.5289921182322909
Validation loss: 2.6579382598864147

Epoch: 6| Step: 9
Training loss: 0.5029707512248371
Validation loss: 2.683590477613354

Epoch: 6| Step: 10
Training loss: 0.6201209841634513
Validation loss: 2.717586765419049

Epoch: 6| Step: 11
Training loss: 0.5983226277430549
Validation loss: 2.6682808629710077

Epoch: 6| Step: 12
Training loss: 0.4593320138761913
Validation loss: 2.689615082694976

Epoch: 6| Step: 13
Training loss: 0.4972766830041885
Validation loss: 2.68345695787377

Epoch: 154| Step: 0
Training loss: 0.8426907212562844
Validation loss: 2.633681669816852

Epoch: 6| Step: 1
Training loss: 0.3815426297524369
Validation loss: 2.6138092860840025

Epoch: 6| Step: 2
Training loss: 0.4375539473923897
Validation loss: 2.6272174158650845

Epoch: 6| Step: 3
Training loss: 0.8503653484437691
Validation loss: 2.6692966193217464

Epoch: 6| Step: 4
Training loss: 0.35873418148402253
Validation loss: 2.6578723515748517

Epoch: 6| Step: 5
Training loss: 0.6216949336381326
Validation loss: 2.659575979286468

Epoch: 6| Step: 6
Training loss: 0.7607794423217984
Validation loss: 2.726767298194626

Epoch: 6| Step: 7
Training loss: 0.43187546706553925
Validation loss: 2.636379161677392

Epoch: 6| Step: 8
Training loss: 0.4642899042768367
Validation loss: 2.645028635241393

Epoch: 6| Step: 9
Training loss: 0.5999245079550061
Validation loss: 2.677088063355855

Epoch: 6| Step: 10
Training loss: 1.557165576674077
Validation loss: 2.688780220934248

Epoch: 6| Step: 11
Training loss: 0.5179619571476272
Validation loss: 2.719555702526927

Epoch: 6| Step: 12
Training loss: 0.5829651016616049
Validation loss: 2.74065953620426

Epoch: 6| Step: 13
Training loss: 0.35040470847720606
Validation loss: 2.6569728653103315

Epoch: 155| Step: 0
Training loss: 0.5768004528576929
Validation loss: 2.6865413049963207

Epoch: 6| Step: 1
Training loss: 0.5908161257761008
Validation loss: 2.7105765418465837

Epoch: 6| Step: 2
Training loss: 0.8272392286174087
Validation loss: 2.75450241093101

Epoch: 6| Step: 3
Training loss: 0.6713786842559029
Validation loss: 2.7126622938131977

Epoch: 6| Step: 4
Training loss: 0.3119892357022356
Validation loss: 2.685084432840756

Epoch: 6| Step: 5
Training loss: 0.5320499232035889
Validation loss: 2.686584612474459

Epoch: 6| Step: 6
Training loss: 0.38493233182038744
Validation loss: 2.6582985701325863

Epoch: 6| Step: 7
Training loss: 0.8197113741016804
Validation loss: 2.6816050320361104

Epoch: 6| Step: 8
Training loss: 0.5998828773625184
Validation loss: 2.79630894677971

Epoch: 6| Step: 9
Training loss: 0.7565173850775411
Validation loss: 2.7087768240484924

Epoch: 6| Step: 10
Training loss: 0.5719635722875283
Validation loss: 2.712590720304739

Epoch: 6| Step: 11
Training loss: 0.5225383095180838
Validation loss: 2.635547609556691

Epoch: 6| Step: 12
Training loss: 1.4167748671705804
Validation loss: 2.7199635921173373

Epoch: 6| Step: 13
Training loss: 0.5927807023484625
Validation loss: 2.7401866949477998

Epoch: 156| Step: 0
Training loss: 0.5003818305714578
Validation loss: 2.634468289944957

Epoch: 6| Step: 1
Training loss: 0.9384489978310763
Validation loss: 2.7121820588710555

Epoch: 6| Step: 2
Training loss: 0.4878424236594068
Validation loss: 2.705604826952657

Epoch: 6| Step: 3
Training loss: 0.4527683169631822
Validation loss: 2.6501557994124156

Epoch: 6| Step: 4
Training loss: 1.4727554085534575
Validation loss: 2.699696330666041

Epoch: 6| Step: 5
Training loss: 0.6434750543855848
Validation loss: 2.694588074564701

Epoch: 6| Step: 6
Training loss: 0.7054993699907048
Validation loss: 2.711188122453746

Epoch: 6| Step: 7
Training loss: 0.3821758308719026
Validation loss: 2.6770765302005124

Epoch: 6| Step: 8
Training loss: 0.5398126717439418
Validation loss: 2.6503119198145138

Epoch: 6| Step: 9
Training loss: 0.5091206061615923
Validation loss: 2.645601718006205

Epoch: 6| Step: 10
Training loss: 0.5521383138186639
Validation loss: 2.6660311557564267

Epoch: 6| Step: 11
Training loss: 0.7931049399097376
Validation loss: 2.74305307144074

Epoch: 6| Step: 12
Training loss: 0.5005324627983708
Validation loss: 2.661205411614824

Epoch: 6| Step: 13
Training loss: 0.5460751815498706
Validation loss: 2.713855898498358

Epoch: 157| Step: 0
Training loss: 0.5108001559385721
Validation loss: 2.6678968711244533

Epoch: 6| Step: 1
Training loss: 0.46898182858257637
Validation loss: 2.732336901456203

Epoch: 6| Step: 2
Training loss: 0.8510363992242432
Validation loss: 2.706528213683734

Epoch: 6| Step: 3
Training loss: 1.3846179791980464
Validation loss: 2.747162916003827

Epoch: 6| Step: 4
Training loss: 0.5387525911556517
Validation loss: 2.718369687544991

Epoch: 6| Step: 5
Training loss: 0.7275316071608365
Validation loss: 2.7207358842800367

Epoch: 6| Step: 6
Training loss: 0.3918612943500603
Validation loss: 2.7821147874378855

Epoch: 6| Step: 7
Training loss: 0.48294783118369505
Validation loss: 2.6973257608268115

Epoch: 6| Step: 8
Training loss: 0.4395763987254858
Validation loss: 2.7364453715605648

Epoch: 6| Step: 9
Training loss: 0.5090439170972298
Validation loss: 2.7435862858039974

Epoch: 6| Step: 10
Training loss: 0.7000377908791648
Validation loss: 2.699071914204753

Epoch: 6| Step: 11
Training loss: 0.5258979191792058
Validation loss: 2.716288727719612

Epoch: 6| Step: 12
Training loss: 0.37568236891980933
Validation loss: 2.7329436634039093

Epoch: 6| Step: 13
Training loss: 0.6020242231935633
Validation loss: 2.7368112446636763

Epoch: 158| Step: 0
Training loss: 0.5212570437863348
Validation loss: 2.7534241310677996

Epoch: 6| Step: 1
Training loss: 0.5354114675702351
Validation loss: 2.822463141088893

Epoch: 6| Step: 2
Training loss: 0.692760456007673
Validation loss: 2.790010179070393

Epoch: 6| Step: 3
Training loss: 0.5880275579517947
Validation loss: 2.8058381336995515

Epoch: 6| Step: 4
Training loss: 0.4507450710699951
Validation loss: 2.7735368666063738

Epoch: 6| Step: 5
Training loss: 0.539824596678036
Validation loss: 2.6652391730644642

Epoch: 6| Step: 6
Training loss: 0.5087672135536326
Validation loss: 2.7315075180431596

Epoch: 6| Step: 7
Training loss: 0.5293516855611725
Validation loss: 2.751595554445704

Epoch: 6| Step: 8
Training loss: 1.604273292994215
Validation loss: 2.7576360024662026

Epoch: 6| Step: 9
Training loss: 0.3716340598776894
Validation loss: 2.7335944087865456

Epoch: 6| Step: 10
Training loss: 0.7479275042953819
Validation loss: 2.7021101735315587

Epoch: 6| Step: 11
Training loss: 0.45471317572706677
Validation loss: 2.765163505254255

Epoch: 6| Step: 12
Training loss: 0.5568452693139873
Validation loss: 2.813501321069509

Epoch: 6| Step: 13
Training loss: 0.5522737234743825
Validation loss: 2.7907418004817965

Epoch: 159| Step: 0
Training loss: 0.7737359906285669
Validation loss: 2.7824302769254317

Epoch: 6| Step: 1
Training loss: 0.6723643893673921
Validation loss: 2.744778140262135

Epoch: 6| Step: 2
Training loss: 0.8859873372479786
Validation loss: 2.7317327321574094

Epoch: 6| Step: 3
Training loss: 0.43668720834344776
Validation loss: 2.742150635213385

Epoch: 6| Step: 4
Training loss: 0.4336862379529341
Validation loss: 2.7059823077794243

Epoch: 6| Step: 5
Training loss: 0.7233629225320384
Validation loss: 2.6531901518928946

Epoch: 6| Step: 6
Training loss: 0.5020588566787868
Validation loss: 2.6286985741369504

Epoch: 6| Step: 7
Training loss: 1.4841158992103072
Validation loss: 2.6733298848749056

Epoch: 6| Step: 8
Training loss: 0.4438082737336669
Validation loss: 2.685991255551626

Epoch: 6| Step: 9
Training loss: 0.5561768322946223
Validation loss: 2.7474812764023557

Epoch: 6| Step: 10
Training loss: 0.583218483744985
Validation loss: 2.74774794408831

Epoch: 6| Step: 11
Training loss: 0.6214738558413079
Validation loss: 2.8078396721743806

Epoch: 6| Step: 12
Training loss: 0.6327110962801653
Validation loss: 2.7559998402348636

Epoch: 6| Step: 13
Training loss: 0.5768039662941685
Validation loss: 2.7329060995955463

Epoch: 160| Step: 0
Training loss: 0.4805267578091658
Validation loss: 2.6143340996322797

Epoch: 6| Step: 1
Training loss: 1.4654468159651388
Validation loss: 2.7125963454707938

Epoch: 6| Step: 2
Training loss: 0.9569291040833168
Validation loss: 2.6924329035151895

Epoch: 6| Step: 3
Training loss: 0.6384214791161053
Validation loss: 2.6881659222399854

Epoch: 6| Step: 4
Training loss: 0.44606666950395346
Validation loss: 2.7320005443324846

Epoch: 6| Step: 5
Training loss: 0.5901723792528512
Validation loss: 2.7939072532688276

Epoch: 6| Step: 6
Training loss: 0.4665286199145628
Validation loss: 2.7547642590926054

Epoch: 6| Step: 7
Training loss: 0.6513729524142846
Validation loss: 2.8011665167930393

Epoch: 6| Step: 8
Training loss: 0.7649680452591724
Validation loss: 2.8685355001691706

Epoch: 6| Step: 9
Training loss: 0.741425574867825
Validation loss: 2.7685825604398655

Epoch: 6| Step: 10
Training loss: 0.523602075467903
Validation loss: 2.703427718600531

Epoch: 6| Step: 11
Training loss: 0.7392651495827693
Validation loss: 2.7956118581707297

Epoch: 6| Step: 12
Training loss: 0.39650993076890806
Validation loss: 2.681859595797484

Epoch: 6| Step: 13
Training loss: 0.6404030112864685
Validation loss: 2.7467011982250145

Epoch: 161| Step: 0
Training loss: 0.62746335002362
Validation loss: 2.7348049588719627

Epoch: 6| Step: 1
Training loss: 0.37451140044396514
Validation loss: 2.766138226721237

Epoch: 6| Step: 2
Training loss: 1.4980340631327547
Validation loss: 2.747114502783827

Epoch: 6| Step: 3
Training loss: 0.7693008232770804
Validation loss: 2.7881732025118526

Epoch: 6| Step: 4
Training loss: 0.4783180763251549
Validation loss: 2.7099146163693213

Epoch: 6| Step: 5
Training loss: 0.40379255971015005
Validation loss: 2.7339538976572335

Epoch: 6| Step: 6
Training loss: 0.8161257759425921
Validation loss: 2.7611008617902537

Epoch: 6| Step: 7
Training loss: 0.4231787422343286
Validation loss: 2.734460346161564

Epoch: 6| Step: 8
Training loss: 0.4601077677601872
Validation loss: 2.709244535679024

Epoch: 6| Step: 9
Training loss: 0.4811947772309049
Validation loss: 2.6604556430081483

Epoch: 6| Step: 10
Training loss: 0.41443660318447023
Validation loss: 2.7406971677284417

Epoch: 6| Step: 11
Training loss: 0.7413073490852498
Validation loss: 2.7315951503898117

Epoch: 6| Step: 12
Training loss: 0.35802109314405295
Validation loss: 2.637463755908482

Epoch: 6| Step: 13
Training loss: 0.7988553590492472
Validation loss: 2.67278299649069

Epoch: 162| Step: 0
Training loss: 0.5499651117530164
Validation loss: 2.6948219037113703

Epoch: 6| Step: 1
Training loss: 0.48109468145921463
Validation loss: 2.6834408023787697

Epoch: 6| Step: 2
Training loss: 0.5786864930525334
Validation loss: 2.7221812960949916

Epoch: 6| Step: 3
Training loss: 0.39085499668204343
Validation loss: 2.629837861109559

Epoch: 6| Step: 4
Training loss: 0.446205281546799
Validation loss: 2.635641975471793

Epoch: 6| Step: 5
Training loss: 0.44305283288341674
Validation loss: 2.642641219471122

Epoch: 6| Step: 6
Training loss: 0.8379146688074859
Validation loss: 2.6105495710300497

Epoch: 6| Step: 7
Training loss: 0.47829220285370916
Validation loss: 2.7063825820032714

Epoch: 6| Step: 8
Training loss: 1.5023450005377823
Validation loss: 2.6495533845731325

Epoch: 6| Step: 9
Training loss: 0.47974011757011625
Validation loss: 2.7268851744189266

Epoch: 6| Step: 10
Training loss: 0.5027358190698047
Validation loss: 2.6339412876711976

Epoch: 6| Step: 11
Training loss: 0.522187462652035
Validation loss: 2.642093678889173

Epoch: 6| Step: 12
Training loss: 0.38254399517209214
Validation loss: 2.6534546373624295

Epoch: 6| Step: 13
Training loss: 0.543024485629637
Validation loss: 2.674788776864303

Epoch: 163| Step: 0
Training loss: 0.5379768164010847
Validation loss: 2.74022943736887

Epoch: 6| Step: 1
Training loss: 0.542278784507168
Validation loss: 2.7246423935797983

Epoch: 6| Step: 2
Training loss: 1.4168621190196116
Validation loss: 2.7329074954343175

Epoch: 6| Step: 3
Training loss: 0.5496818988074433
Validation loss: 2.77137185124375

Epoch: 6| Step: 4
Training loss: 0.42061017425505387
Validation loss: 2.7592906934705153

Epoch: 6| Step: 5
Training loss: 0.4618286957197615
Validation loss: 2.6577907058267787

Epoch: 6| Step: 6
Training loss: 0.48611969675323474
Validation loss: 2.6990455612364244

Epoch: 6| Step: 7
Training loss: 0.4482966703659292
Validation loss: 2.740219859354187

Epoch: 6| Step: 8
Training loss: 0.5808841743639512
Validation loss: 2.7049930269923563

Epoch: 6| Step: 9
Training loss: 0.785366163139408
Validation loss: 2.7226938749511245

Epoch: 6| Step: 10
Training loss: 0.398079449459729
Validation loss: 2.692610015156391

Epoch: 6| Step: 11
Training loss: 0.23847595452208503
Validation loss: 2.7270542491957954

Epoch: 6| Step: 12
Training loss: 0.38243387922358135
Validation loss: 2.76507340155007

Epoch: 6| Step: 13
Training loss: 0.62508706440092
Validation loss: 2.7544131702986463

Epoch: 164| Step: 0
Training loss: 0.4990894848736427
Validation loss: 2.739954344329632

Epoch: 6| Step: 1
Training loss: 0.5195316802288368
Validation loss: 2.6960400028005984

Epoch: 6| Step: 2
Training loss: 0.7667224181332173
Validation loss: 2.704692657953549

Epoch: 6| Step: 3
Training loss: 0.5041782916386565
Validation loss: 2.8186788010045816

Epoch: 6| Step: 4
Training loss: 0.7598649771484778
Validation loss: 2.7401632098969326

Epoch: 6| Step: 5
Training loss: 0.3950594963161112
Validation loss: 2.7719845686699074

Epoch: 6| Step: 6
Training loss: 0.5555079128446891
Validation loss: 2.808355654694758

Epoch: 6| Step: 7
Training loss: 0.6187832158738817
Validation loss: 2.771080770893243

Epoch: 6| Step: 8
Training loss: 0.2759306057449987
Validation loss: 2.7464444554664644

Epoch: 6| Step: 9
Training loss: 0.3544220657983818
Validation loss: 2.714486897752027

Epoch: 6| Step: 10
Training loss: 0.3700031114782493
Validation loss: 2.732483389368552

Epoch: 6| Step: 11
Training loss: 0.5932589056003261
Validation loss: 2.756177466166884

Epoch: 6| Step: 12
Training loss: 1.3735808938849938
Validation loss: 2.616328266356463

Epoch: 6| Step: 13
Training loss: 0.372841144174421
Validation loss: 2.744040063574364

Epoch: 165| Step: 0
Training loss: 0.3558254338816282
Validation loss: 2.7153852256682223

Epoch: 6| Step: 1
Training loss: 0.5109946974257125
Validation loss: 2.7423393011869397

Epoch: 6| Step: 2
Training loss: 0.3841562043825112
Validation loss: 2.6340420924023835

Epoch: 6| Step: 3
Training loss: 0.5534117090299656
Validation loss: 2.8133364952289597

Epoch: 6| Step: 4
Training loss: 0.5927066671105571
Validation loss: 2.685324224316749

Epoch: 6| Step: 5
Training loss: 0.47072330605705914
Validation loss: 2.726876766307141

Epoch: 6| Step: 6
Training loss: 0.49828170027522606
Validation loss: 2.694145945327636

Epoch: 6| Step: 7
Training loss: 0.6570870646788273
Validation loss: 2.744232082087311

Epoch: 6| Step: 8
Training loss: 0.7300213754476883
Validation loss: 2.7295872798544285

Epoch: 6| Step: 9
Training loss: 0.450276051064719
Validation loss: 2.6842211009011816

Epoch: 6| Step: 10
Training loss: 1.350206742527315
Validation loss: 2.6852720473723046

Epoch: 6| Step: 11
Training loss: 0.4813016479818258
Validation loss: 2.7162950181573247

Epoch: 6| Step: 12
Training loss: 0.5508728221766298
Validation loss: 2.725750821469374

Epoch: 6| Step: 13
Training loss: 0.536047256397093
Validation loss: 2.735244569112513

Epoch: 166| Step: 0
Training loss: 0.3411841431672897
Validation loss: 2.674658026776696

Epoch: 6| Step: 1
Training loss: 0.5332059755353921
Validation loss: 2.7306034707963804

Epoch: 6| Step: 2
Training loss: 0.4892981354625485
Validation loss: 2.7259111619282117

Epoch: 6| Step: 3
Training loss: 0.5222957456886201
Validation loss: 2.7035950709524204

Epoch: 6| Step: 4
Training loss: 0.4596092191440098
Validation loss: 2.775931985392918

Epoch: 6| Step: 5
Training loss: 0.5939846829854218
Validation loss: 2.6896862925337706

Epoch: 6| Step: 6
Training loss: 0.5621398196481961
Validation loss: 2.709843424863924

Epoch: 6| Step: 7
Training loss: 0.38663655187774154
Validation loss: 2.6587626970469502

Epoch: 6| Step: 8
Training loss: 1.5389491005574047
Validation loss: 2.7081768186289215

Epoch: 6| Step: 9
Training loss: 0.3672953508134244
Validation loss: 2.735229678322883

Epoch: 6| Step: 10
Training loss: 0.765203905107491
Validation loss: 2.694698901521909

Epoch: 6| Step: 11
Training loss: 0.4437125223747566
Validation loss: 2.730634474193284

Epoch: 6| Step: 12
Training loss: 0.46192832102150794
Validation loss: 2.764121629403458

Epoch: 6| Step: 13
Training loss: 0.46695613937336794
Validation loss: 2.804998028211076

Epoch: 167| Step: 0
Training loss: 0.48083699078989706
Validation loss: 2.732668992948073

Epoch: 6| Step: 1
Training loss: 0.337046610977786
Validation loss: 2.7713402927287745

Epoch: 6| Step: 2
Training loss: 0.7357507764427866
Validation loss: 2.7125053013106664

Epoch: 6| Step: 3
Training loss: 1.4623940290873814
Validation loss: 2.7238667450211214

Epoch: 6| Step: 4
Training loss: 0.5879336623347101
Validation loss: 2.7260794079541184

Epoch: 6| Step: 5
Training loss: 0.5277983225064002
Validation loss: 2.73033493216155

Epoch: 6| Step: 6
Training loss: 0.38759208092748815
Validation loss: 2.7345003153831646

Epoch: 6| Step: 7
Training loss: 0.7111587180238843
Validation loss: 2.7127240072358627

Epoch: 6| Step: 8
Training loss: 0.3645118870438657
Validation loss: 2.743741456455146

Epoch: 6| Step: 9
Training loss: 0.5300317146601062
Validation loss: 2.7317279900802576

Epoch: 6| Step: 10
Training loss: 0.3273477203565364
Validation loss: 2.751763515289157

Epoch: 6| Step: 11
Training loss: 0.48600948573301855
Validation loss: 2.702967306546454

Epoch: 6| Step: 12
Training loss: 0.6359334444108842
Validation loss: 2.750081191164846

Epoch: 6| Step: 13
Training loss: 0.40810555565096696
Validation loss: 2.7536614780451796

Epoch: 168| Step: 0
Training loss: 0.3668839234561744
Validation loss: 2.8326902477819287

Epoch: 6| Step: 1
Training loss: 0.5388280109738913
Validation loss: 2.7032726739960125

Epoch: 6| Step: 2
Training loss: 0.6679179300529096
Validation loss: 2.7569978571622755

Epoch: 6| Step: 3
Training loss: 0.5532666666112167
Validation loss: 2.716012021819538

Epoch: 6| Step: 4
Training loss: 0.41416244380276906
Validation loss: 2.688662595417444

Epoch: 6| Step: 5
Training loss: 0.4155077991304488
Validation loss: 2.7286407507547943

Epoch: 6| Step: 6
Training loss: 0.5061803557917044
Validation loss: 2.701228349214373

Epoch: 6| Step: 7
Training loss: 0.47421626698379654
Validation loss: 2.7204877261965974

Epoch: 6| Step: 8
Training loss: 0.5276973527844456
Validation loss: 2.6943084173397454

Epoch: 6| Step: 9
Training loss: 0.897561350986204
Validation loss: 2.7512306580823367

Epoch: 6| Step: 10
Training loss: 1.3473435633483495
Validation loss: 2.726470544934966

Epoch: 6| Step: 11
Training loss: 0.510510744131236
Validation loss: 2.6709238779924127

Epoch: 6| Step: 12
Training loss: 0.3891255400421385
Validation loss: 2.733187085015059

Epoch: 6| Step: 13
Training loss: 0.4273536764662261
Validation loss: 2.69628468547329

Epoch: 169| Step: 0
Training loss: 0.488524719573346
Validation loss: 2.698225943808364

Epoch: 6| Step: 1
Training loss: 0.8256018365213941
Validation loss: 2.727603469527071

Epoch: 6| Step: 2
Training loss: 0.6800543135101272
Validation loss: 2.772800698400139

Epoch: 6| Step: 3
Training loss: 0.5359584893212038
Validation loss: 2.7011525817020257

Epoch: 6| Step: 4
Training loss: 0.396694484718319
Validation loss: 2.704543107393362

Epoch: 6| Step: 5
Training loss: 0.6159911814250382
Validation loss: 2.73516366393381

Epoch: 6| Step: 6
Training loss: 0.7420030866697532
Validation loss: 2.7636619253170425

Epoch: 6| Step: 7
Training loss: 1.2702430959512787
Validation loss: 2.745484430570356

Epoch: 6| Step: 8
Training loss: 0.3400909577044487
Validation loss: 2.706899752595091

Epoch: 6| Step: 9
Training loss: 0.42109049157065637
Validation loss: 2.700506069887296

Epoch: 6| Step: 10
Training loss: 0.5078338031701941
Validation loss: 2.7495016961470267

Epoch: 6| Step: 11
Training loss: 0.7074715102427629
Validation loss: 2.6633703054106626

Epoch: 6| Step: 12
Training loss: 0.37327339125768105
Validation loss: 2.716298353546295

Epoch: 6| Step: 13
Training loss: 0.45205687549477486
Validation loss: 2.721616906923784

Epoch: 170| Step: 0
Training loss: 0.47277918706450534
Validation loss: 2.7545726646163264

Epoch: 6| Step: 1
Training loss: 0.4132643510503971
Validation loss: 2.811337159975195

Epoch: 6| Step: 2
Training loss: 0.5193726720654479
Validation loss: 2.791266801769017

Epoch: 6| Step: 3
Training loss: 0.37438206623012804
Validation loss: 2.7794448909631657

Epoch: 6| Step: 4
Training loss: 0.6672013765986967
Validation loss: 2.7090011042431543

Epoch: 6| Step: 5
Training loss: 0.4970348472908746
Validation loss: 2.7929508946699437

Epoch: 6| Step: 6
Training loss: 0.4604719041108579
Validation loss: 2.8139988896454278

Epoch: 6| Step: 7
Training loss: 0.279000224782484
Validation loss: 2.7887834681849855

Epoch: 6| Step: 8
Training loss: 0.5907485287777552
Validation loss: 2.7458899229254894

Epoch: 6| Step: 9
Training loss: 0.7311580893636107
Validation loss: 2.751045967357721

Epoch: 6| Step: 10
Training loss: 0.3981041729448437
Validation loss: 2.7059459630021254

Epoch: 6| Step: 11
Training loss: 0.49476734570074965
Validation loss: 2.728178447186733

Epoch: 6| Step: 12
Training loss: 1.3358126576410656
Validation loss: 2.7255847857554967

Epoch: 6| Step: 13
Training loss: 0.32922268231926194
Validation loss: 2.75231152978612

Epoch: 171| Step: 0
Training loss: 0.4778891374341292
Validation loss: 2.770126042166628

Epoch: 6| Step: 1
Training loss: 0.5474490286558995
Validation loss: 2.6944012267021216

Epoch: 6| Step: 2
Training loss: 0.29810050191929793
Validation loss: 2.7098721069806624

Epoch: 6| Step: 3
Training loss: 0.42873498940396876
Validation loss: 2.770006304962107

Epoch: 6| Step: 4
Training loss: 0.6062771968050328
Validation loss: 2.706837803624633

Epoch: 6| Step: 5
Training loss: 0.4710212360705266
Validation loss: 2.753089137859499

Epoch: 6| Step: 6
Training loss: 0.5948696622021877
Validation loss: 2.7240666695538405

Epoch: 6| Step: 7
Training loss: 0.4531718098369744
Validation loss: 2.8547983561098755

Epoch: 6| Step: 8
Training loss: 0.5007339990852324
Validation loss: 2.7360385884088267

Epoch: 6| Step: 9
Training loss: 0.5311946279054474
Validation loss: 2.6932235657714805

Epoch: 6| Step: 10
Training loss: 0.3733846523287554
Validation loss: 2.707563735972551

Epoch: 6| Step: 11
Training loss: 0.6433451055115085
Validation loss: 2.695926246240776

Epoch: 6| Step: 12
Training loss: 1.3180995656901764
Validation loss: 2.71023380406468

Epoch: 6| Step: 13
Training loss: 0.5121944924157125
Validation loss: 2.6972989635722886

Epoch: 172| Step: 0
Training loss: 0.5177187170858875
Validation loss: 2.7346281243284474

Epoch: 6| Step: 1
Training loss: 0.4487348188951104
Validation loss: 2.667893519907085

Epoch: 6| Step: 2
Training loss: 0.3389013971216079
Validation loss: 2.662467367124489

Epoch: 6| Step: 3
Training loss: 0.4306704981316552
Validation loss: 2.69500446125763

Epoch: 6| Step: 4
Training loss: 0.41505378248253305
Validation loss: 2.6619352795476083

Epoch: 6| Step: 5
Training loss: 1.376100533222777
Validation loss: 2.682294624598579

Epoch: 6| Step: 6
Training loss: 0.4127823455793697
Validation loss: 2.7008025348307556

Epoch: 6| Step: 7
Training loss: 0.5060102613317073
Validation loss: 2.677013341876852

Epoch: 6| Step: 8
Training loss: 0.5728145739595335
Validation loss: 2.716645109251025

Epoch: 6| Step: 9
Training loss: 0.6967072802513
Validation loss: 2.7301780826115762

Epoch: 6| Step: 10
Training loss: 0.6571640052894702
Validation loss: 2.770592174695564

Epoch: 6| Step: 11
Training loss: 0.6338342964946776
Validation loss: 2.749855731300962

Epoch: 6| Step: 12
Training loss: 0.4838393695349424
Validation loss: 2.6478671544746093

Epoch: 6| Step: 13
Training loss: 0.4720760914863518
Validation loss: 2.743451833201227

Epoch: 173| Step: 0
Training loss: 0.7527273576663736
Validation loss: 2.7573816468982315

Epoch: 6| Step: 1
Training loss: 1.4827402850977502
Validation loss: 2.7662150010487583

Epoch: 6| Step: 2
Training loss: 0.6129836800162363
Validation loss: 2.781954358238178

Epoch: 6| Step: 3
Training loss: 0.4833170966868661
Validation loss: 2.73381625324999

Epoch: 6| Step: 4
Training loss: 0.4086123336446231
Validation loss: 2.789084853822687

Epoch: 6| Step: 5
Training loss: 0.45902591273874255
Validation loss: 2.758190716247926

Epoch: 6| Step: 6
Training loss: 0.47360405588845816
Validation loss: 2.8622565142316145

Epoch: 6| Step: 7
Training loss: 0.4767129535503947
Validation loss: 2.763741442700036

Epoch: 6| Step: 8
Training loss: 0.43826732443379685
Validation loss: 2.733200809320946

Epoch: 6| Step: 9
Training loss: 0.42322986762648884
Validation loss: 2.7099367872657014

Epoch: 6| Step: 10
Training loss: 0.42649784506402083
Validation loss: 2.757535652190706

Epoch: 6| Step: 11
Training loss: 0.728617234085746
Validation loss: 2.7002349721836922

Epoch: 6| Step: 12
Training loss: 0.4792967978977182
Validation loss: 2.721350007609181

Epoch: 6| Step: 13
Training loss: 0.4584394263530634
Validation loss: 2.705491501935289

Epoch: 174| Step: 0
Training loss: 0.4945612688882045
Validation loss: 2.7546257215508367

Epoch: 6| Step: 1
Training loss: 0.8743130848622409
Validation loss: 2.733586399257095

Epoch: 6| Step: 2
Training loss: 0.38802782688196236
Validation loss: 2.8130171688860908

Epoch: 6| Step: 3
Training loss: 1.2964914513073305
Validation loss: 2.791080859387146

Epoch: 6| Step: 4
Training loss: 0.5644421691887263
Validation loss: 2.8254535626022586

Epoch: 6| Step: 5
Training loss: 0.47798847044323484
Validation loss: 2.7846833800040405

Epoch: 6| Step: 6
Training loss: 0.3628712257809211
Validation loss: 2.816408888365435

Epoch: 6| Step: 7
Training loss: 0.3872348154882285
Validation loss: 2.754324374009565

Epoch: 6| Step: 8
Training loss: 0.5028399637425984
Validation loss: 2.79392766963611

Epoch: 6| Step: 9
Training loss: 0.42320331981218545
Validation loss: 2.7322485657255755

Epoch: 6| Step: 10
Training loss: 0.3738123046333633
Validation loss: 2.6944088512923132

Epoch: 6| Step: 11
Training loss: 0.5046882771111048
Validation loss: 2.714440317160769

Epoch: 6| Step: 12
Training loss: 0.41536486236020786
Validation loss: 2.76692232498059

Epoch: 6| Step: 13
Training loss: 0.6277927231510001
Validation loss: 2.7222900582206586

Epoch: 175| Step: 0
Training loss: 0.5221155754245183
Validation loss: 2.769154367418629

Epoch: 6| Step: 1
Training loss: 0.6601975332138932
Validation loss: 2.755902299697636

Epoch: 6| Step: 2
Training loss: 0.6411501662487274
Validation loss: 2.7465928963905464

Epoch: 6| Step: 3
Training loss: 0.4787912470277627
Validation loss: 2.747127897145183

Epoch: 6| Step: 4
Training loss: 0.3722542535860359
Validation loss: 2.801558694803207

Epoch: 6| Step: 5
Training loss: 0.4382193645774124
Validation loss: 2.7031344889509175

Epoch: 6| Step: 6
Training loss: 0.48714259324228454
Validation loss: 2.7762083441322813

Epoch: 6| Step: 7
Training loss: 0.35377846741456026
Validation loss: 2.7797221941584893

Epoch: 6| Step: 8
Training loss: 0.4911677529253219
Validation loss: 2.728845990004622

Epoch: 6| Step: 9
Training loss: 0.3724822919912073
Validation loss: 2.7494080513304944

Epoch: 6| Step: 10
Training loss: 0.3625366619907344
Validation loss: 2.7463730099863133

Epoch: 6| Step: 11
Training loss: 0.39773606284447854
Validation loss: 2.651619648959137

Epoch: 6| Step: 12
Training loss: 0.3735010069153068
Validation loss: 2.6465481420813584

Epoch: 6| Step: 13
Training loss: 1.2608572082292913
Validation loss: 2.685442144027926

Testing loss: 2.578087500429842
