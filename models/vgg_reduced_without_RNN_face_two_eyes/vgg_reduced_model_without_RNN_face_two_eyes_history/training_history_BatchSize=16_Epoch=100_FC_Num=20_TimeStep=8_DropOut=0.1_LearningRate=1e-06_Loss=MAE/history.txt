Epoch: 1| Step: 0
Training loss: 8.857977867126465
Validation loss: 9.715205508170367
Epoch: 9| Step: 1
Training loss: 9.580436706542969
Validation loss: 9.71136771689216
Epoch: 9| Step: 2
Training loss: 9.66949462890625
Validation loss: 9.701836675191098
Epoch: 9| Step: 3
Training loss: 10.115148544311523
Validation loss: 9.695222991833583
Epoch: 9| Step: 4
Training loss: 9.830692291259766
Validation loss: 9.684245486911252
Epoch: 9| Step: 5
Training loss: 9.300687789916992
Validation loss: 9.678521979626991
Epoch: 9| Step: 6
Training loss: 10.627117156982422
Validation loss: 9.674541528276402
Epoch: 9| Step: 7
Training loss: 9.878677368164062
Validation loss: 9.663744055109916
Epoch: 9| Step: 8
Training loss: 10.075225830078125
Validation loss: 9.659949076261451
Epoch: 9| Step: 9
Training loss: 10.182342529296875
Validation loss: 9.650566402956736
Epoch: 9| Step: 10
Training loss: 9.759912490844727
Validation loss: 9.643365359134812
Epoch: 9| Step: 11
Training loss: 10.0747652053833
Validation loss: 9.63537505033205
Epoch: 9| Step: 12
Training loss: 9.298696517944336
Validation loss: 9.628783541617633
Epoch: 9| Step: 13
Training loss: 9.045348167419434
Validation loss: 9.62071415331724
Epoch: 9| Step: 14
Training loss: 10.57122802734375
Validation loss: 9.614699953751598
Epoch: 9| Step: 15
Training loss: 9.931171417236328
Validation loss: 9.60735729272417
Epoch: 9| Step: 16
Training loss: 9.44822883605957
Validation loss: 9.601120413636131
Epoch: 9| Step: 17
Training loss: 9.416149139404297
Validation loss: 9.590145742292885
Epoch: 9| Step: 18
Training loss: 9.62153434753418
Validation loss: 9.584911874729952
Epoch: 9| Step: 19
Training loss: 10.527691841125488
Validation loss: 9.578427355924099
Epoch: 2| Step: 0
Training loss: 9.94749927520752
Validation loss: 9.569067337530122
Epoch: 9| Step: 1
Training loss: 10.871477127075195
Validation loss: 9.561708759060867
Epoch: 9| Step: 2
Training loss: 8.863920211791992
Validation loss: 9.557959782991478
Epoch: 9| Step: 3
Training loss: 8.985666275024414
Validation loss: 9.548980486478737
Epoch: 9| Step: 4
Training loss: 9.24366569519043
Validation loss: 9.539893905035884
Epoch: 9| Step: 5
Training loss: 9.745561599731445
Validation loss: 9.533525315977686
Epoch: 9| Step: 6
Training loss: 8.490857124328613
Validation loss: 9.52674498660959
Epoch: 9| Step: 7
Training loss: 9.620779037475586
Validation loss: 9.51944826661254
Epoch: 9| Step: 8
Training loss: 9.485097885131836
Validation loss: 9.510679855621119
Epoch: 9| Step: 9
Training loss: 9.592344284057617
Validation loss: 9.505326223030364
Epoch: 9| Step: 10
Training loss: 8.68497085571289
Validation loss: 9.496772402482067
Epoch: 9| Step: 11
Training loss: 9.802730560302734
Validation loss: 9.490150060585076
Epoch: 9| Step: 12
Training loss: 8.931419372558594
Validation loss: 9.482426588483852
Epoch: 9| Step: 13
Training loss: 9.75485897064209
Validation loss: 9.47686370328176
Epoch: 9| Step: 14
Training loss: 9.474340438842773
Validation loss: 9.46841420372613
Epoch: 9| Step: 15
Training loss: 10.142755508422852
Validation loss: 9.461162656331235
Epoch: 9| Step: 16
Training loss: 10.815580368041992
Validation loss: 9.453663023255713
Epoch: 9| Step: 17
Training loss: 9.99329948425293
Validation loss: 9.44494365445144
Epoch: 9| Step: 18
Training loss: 9.787435531616211
Validation loss: 9.438679640241665
Epoch: 9| Step: 19
Training loss: 10.718212127685547
Validation loss: 9.43017082077136
Epoch: 3| Step: 0
Training loss: 9.732932090759277
Validation loss: 9.42372046271674
Epoch: 9| Step: 1
Training loss: 9.979591369628906
Validation loss: 9.414302283911397
Epoch: 9| Step: 2
Training loss: 10.250179290771484
Validation loss: 9.406053467620191
Epoch: 9| Step: 3
Training loss: 9.405956268310547
Validation loss: 9.397549505714032
Epoch: 9| Step: 4
Training loss: 10.066067695617676
Validation loss: 9.39088414555831
Epoch: 9| Step: 5
Training loss: 9.274090766906738
Validation loss: 9.382908773079192
Epoch: 9| Step: 6
Training loss: 9.458809852600098
Validation loss: 9.376814464870975
Epoch: 9| Step: 7
Training loss: 9.611650466918945
Validation loss: 9.36572686888331
Epoch: 9| Step: 8
Training loss: 9.441466331481934
Validation loss: 9.359330616408972
Epoch: 9| Step: 9
Training loss: 8.417777061462402
Validation loss: 9.349817474968999
Epoch: 9| Step: 10
Training loss: 9.910842895507812
Validation loss: 9.341256759149566
Epoch: 9| Step: 11
Training loss: 9.854360580444336
Validation loss: 9.331049754465226
Epoch: 9| Step: 12
Training loss: 9.002973556518555
Validation loss: 9.325851015049777
Epoch: 9| Step: 13
Training loss: 9.970621109008789
Validation loss: 9.319320205304262
Epoch: 9| Step: 14
Training loss: 9.618425369262695
Validation loss: 9.308218317923785
Epoch: 9| Step: 15
Training loss: 9.046415328979492
Validation loss: 9.299477110663764
Epoch: 9| Step: 16
Training loss: 9.252179145812988
Validation loss: 9.29096905276072
Epoch: 9| Step: 17
Training loss: 9.023447036743164
Validation loss: 9.281659249779132
Epoch: 9| Step: 18
Training loss: 9.52005386352539
Validation loss: 9.27297237451128
Epoch: 9| Step: 19
Training loss: 9.10495376586914
Validation loss: 9.264498244086615
Epoch: 4| Step: 0
Training loss: 10.270013809204102
Validation loss: 9.255958838428525
Epoch: 9| Step: 1
Training loss: 9.218206405639648
Validation loss: 9.245934122757946
Epoch: 9| Step: 2
Training loss: 9.683916091918945
Validation loss: 9.23776028996749
Epoch: 9| Step: 3
Training loss: 10.783206939697266
Validation loss: 9.227390652937855
Epoch: 9| Step: 4
Training loss: 9.395150184631348
Validation loss: 9.22172555305975
Epoch: 9| Step: 5
Training loss: 9.42255687713623
Validation loss: 9.209843573810385
Epoch: 9| Step: 6
Training loss: 8.60585880279541
Validation loss: 9.198810659724174
Epoch: 9| Step: 7
Training loss: 9.139627456665039
Validation loss: 9.189419574874767
Epoch: 9| Step: 8
Training loss: 8.862951278686523
Validation loss: 9.184309904523891
Epoch: 9| Step: 9
Training loss: 9.210054397583008
Validation loss: 9.170686063148992
Epoch: 9| Step: 10
Training loss: 9.161678314208984
Validation loss: 9.16425535490187
Epoch: 9| Step: 11
Training loss: 8.602946281433105
Validation loss: 9.15231262865684
Epoch: 9| Step: 12
Training loss: 9.912545204162598
Validation loss: 9.14381748995335
Epoch: 9| Step: 13
Training loss: 10.575201034545898
Validation loss: 9.133362770080566
Epoch: 9| Step: 14
Training loss: 9.182645797729492
Validation loss: 9.123103505415882
Epoch: 9| Step: 15
Training loss: 8.919150352478027
Validation loss: 9.11159684846727
Epoch: 9| Step: 16
Training loss: 8.524460792541504
Validation loss: 9.10355432084996
Epoch: 9| Step: 17
Training loss: 8.374821662902832
Validation loss: 9.091835728652185
Epoch: 9| Step: 18
Training loss: 9.649215698242188
Validation loss: 9.080826045797883
Epoch: 9| Step: 19
Training loss: 8.975203514099121
Validation loss: 9.071879579008913
Epoch: 5| Step: 0
Training loss: 9.544532775878906
Validation loss: 9.059257157414937
Epoch: 9| Step: 1
Training loss: 9.747294425964355
Validation loss: 9.050347321325068
Epoch: 9| Step: 2
Training loss: 9.158947944641113
Validation loss: 9.038804328698905
Epoch: 9| Step: 3
Training loss: 8.172876358032227
Validation loss: 9.029477730071802
Epoch: 9| Step: 4
Training loss: 8.780328750610352
Validation loss: 9.01471495799881
Epoch: 9| Step: 5
Training loss: 10.25796890258789
Validation loss: 9.006328637651402
Epoch: 9| Step: 6
Training loss: 9.641423225402832
Validation loss: 8.992575926746396
Epoch: 9| Step: 7
Training loss: 9.879480361938477
Validation loss: 8.982039465321053
Epoch: 9| Step: 8
Training loss: 8.251039505004883
Validation loss: 8.969248593282357
Epoch: 9| Step: 9
Training loss: 9.170154571533203
Validation loss: 8.958142259995714
Epoch: 9| Step: 10
Training loss: 9.42837905883789
Validation loss: 8.948370933532715
Epoch: 9| Step: 11
Training loss: 10.313793182373047
Validation loss: 8.934645913487715
Epoch: 9| Step: 12
Training loss: 9.612001419067383
Validation loss: 8.922862450853525
Epoch: 9| Step: 13
Training loss: 8.129274368286133
Validation loss: 8.912043173536123
Epoch: 9| Step: 14
Training loss: 8.578365325927734
Validation loss: 8.900391167016338
Epoch: 9| Step: 15
Training loss: 9.128734588623047
Validation loss: 8.886677549897337
Epoch: 9| Step: 16
Training loss: 8.701432228088379
Validation loss: 8.876036273489753
Epoch: 9| Step: 17
Training loss: 8.565168380737305
Validation loss: 8.864635687080218
Epoch: 9| Step: 18
Training loss: 9.065481185913086
Validation loss: 8.849188097946936
Epoch: 9| Step: 19
Training loss: 8.266799926757812
Validation loss: 8.83443824850398
Epoch: 6| Step: 0
Training loss: 10.026144027709961
Validation loss: 8.824334621429443
Epoch: 9| Step: 1
Training loss: 9.048008918762207
Validation loss: 8.810869381582137
Epoch: 9| Step: 2
Training loss: 8.076834678649902
Validation loss: 8.796871288217229
Epoch: 9| Step: 3
Training loss: 9.13736343383789
Validation loss: 8.780407891856681
Epoch: 9| Step: 4
Training loss: 9.29407024383545
Validation loss: 8.769466657432721
Epoch: 9| Step: 5
Training loss: 8.933511734008789
Validation loss: 8.756094376817881
Epoch: 9| Step: 6
Training loss: 9.522387504577637
Validation loss: 8.741838002376419
Epoch: 9| Step: 7
Training loss: 7.701423645019531
Validation loss: 8.728244129702341
Epoch: 9| Step: 8
Training loss: 9.270075798034668
Validation loss: 8.710650509209941
Epoch: 9| Step: 9
Training loss: 9.248584747314453
Validation loss: 8.698976249145947
Epoch: 9| Step: 10
Training loss: 8.200510025024414
Validation loss: 8.682934850239926
Epoch: 9| Step: 11
Training loss: 8.280598640441895
Validation loss: 8.66807050499127
Epoch: 9| Step: 12
Training loss: 9.309483528137207
Validation loss: 8.65124493194141
Epoch: 9| Step: 13
Training loss: 8.41491413116455
Validation loss: 8.637786234025475
Epoch: 9| Step: 14
Training loss: 9.445358276367188
Validation loss: 8.622224800878291
Epoch: 9| Step: 15
Training loss: 8.402814865112305
Validation loss: 8.605434355975913
Epoch: 9| Step: 16
Training loss: 10.419668197631836
Validation loss: 8.588569483311057
Epoch: 9| Step: 17
Training loss: 7.555901050567627
Validation loss: 8.57122321780637
Epoch: 9| Step: 18
Training loss: 8.018779754638672
Validation loss: 8.554849868198092
Epoch: 9| Step: 19
Training loss: 8.947334289550781
Validation loss: 8.535626438881854
Epoch: 7| Step: 0
Training loss: 9.682095527648926
Validation loss: 8.51888047362403
Epoch: 9| Step: 1
Training loss: 10.217687606811523
Validation loss: 8.506460080043874
Epoch: 9| Step: 2
Training loss: 8.125650405883789
Validation loss: 8.481523458906215
Epoch: 9| Step: 3
Training loss: 8.809562683105469
Validation loss: 8.465104157976109
Epoch: 9| Step: 4
Training loss: 7.988578796386719
Validation loss: 8.445120790879503
Epoch: 9| Step: 5
Training loss: 9.086021423339844
Validation loss: 8.42795341134929
Epoch: 9| Step: 6
Training loss: 8.137849807739258
Validation loss: 8.406872262200006
Epoch: 9| Step: 7
Training loss: 8.635625839233398
Validation loss: 8.386738152812711
Epoch: 9| Step: 8
Training loss: 7.925239562988281
Validation loss: 8.362596793140439
Epoch: 9| Step: 9
Training loss: 7.743745803833008
Validation loss: 8.347278958601917
Epoch: 9| Step: 10
Training loss: 8.079071044921875
Validation loss: 8.323639766775447
Epoch: 9| Step: 11
Training loss: 7.657721996307373
Validation loss: 8.305534417680699
Epoch: 9| Step: 12
Training loss: 8.290345191955566
Validation loss: 8.283284842539176
Epoch: 9| Step: 13
Training loss: 9.530853271484375
Validation loss: 8.262636143526585
Epoch: 9| Step: 14
Training loss: 8.246211051940918
Validation loss: 8.240761619677647
Epoch: 9| Step: 15
Training loss: 9.094427108764648
Validation loss: 8.218197644185677
Epoch: 9| Step: 16
Training loss: 9.515544891357422
Validation loss: 8.20045445805831
Epoch: 9| Step: 17
Training loss: 8.06863021850586
Validation loss: 8.175411327279729
Epoch: 9| Step: 18
Training loss: 7.104728698730469
Validation loss: 8.155179119796204
Epoch: 9| Step: 19
Training loss: 8.497552871704102
Validation loss: 8.131004319774162
Epoch: 8| Step: 0
Training loss: 6.971614837646484
Validation loss: 8.103186559334075
Epoch: 9| Step: 1
Training loss: 7.478517532348633
Validation loss: 8.082559012680603
Epoch: 9| Step: 2
Training loss: 7.9781646728515625
Validation loss: 8.060827721794732
Epoch: 9| Step: 3
Training loss: 8.149679183959961
Validation loss: 8.036647487887375
Epoch: 9| Step: 4
Training loss: 8.121776580810547
Validation loss: 8.008466597083661
Epoch: 9| Step: 5
Training loss: 7.866609573364258
Validation loss: 7.985247920742996
Epoch: 9| Step: 6
Training loss: 8.466286659240723
Validation loss: 7.957583887113942
Epoch: 9| Step: 7
Training loss: 7.576797008514404
Validation loss: 7.93642243378454
Epoch: 9| Step: 8
Training loss: 9.304506301879883
Validation loss: 7.909109558132912
Epoch: 9| Step: 9
Training loss: 8.649979591369629
Validation loss: 7.878098323190812
Epoch: 9| Step: 10
Training loss: 7.851597309112549
Validation loss: 7.857411652160206
Epoch: 9| Step: 11
Training loss: 7.399094581604004
Validation loss: 7.830713539672413
Epoch: 9| Step: 12
Training loss: 9.366119384765625
Validation loss: 7.805443911243685
Epoch: 9| Step: 13
Training loss: 8.475452423095703
Validation loss: 7.780550994461389
Epoch: 9| Step: 14
Training loss: 7.5689263343811035
Validation loss: 7.754168023308404
Epoch: 9| Step: 15
Training loss: 7.385983943939209
Validation loss: 7.725726360897366
Epoch: 9| Step: 16
Training loss: 8.278099060058594
Validation loss: 7.696252644490853
Epoch: 9| Step: 17
Training loss: 8.389066696166992
Validation loss: 7.668552268323281
Epoch: 9| Step: 18
Training loss: 8.673912048339844
Validation loss: 7.6392142378168995
Epoch: 9| Step: 19
Training loss: 7.468963623046875
Validation loss: 7.6082802161895975
Epoch: 9| Step: 0
Training loss: 7.587230205535889
Validation loss: 7.584233733389875
Epoch: 9| Step: 1
Training loss: 7.4554901123046875
Validation loss: 7.550179213928661
Epoch: 9| Step: 2
Training loss: 7.411086082458496
Validation loss: 7.525491000937043
Epoch: 9| Step: 3
Training loss: 8.126962661743164
Validation loss: 7.482884527110367
Epoch: 9| Step: 4
Training loss: 7.183465003967285
Validation loss: 7.4563896295835645
Epoch: 9| Step: 5
Training loss: 5.999874591827393
Validation loss: 7.427812885037429
Epoch: 9| Step: 6
Training loss: 7.789134502410889
Validation loss: 7.401401866254189
Epoch: 9| Step: 7
Training loss: 8.820820808410645
Validation loss: 7.3694351491310615
Epoch: 9| Step: 8
Training loss: 8.195488929748535
Validation loss: 7.337065652120027
Epoch: 9| Step: 9
Training loss: 7.376474380493164
Validation loss: 7.30616777406322
Epoch: 9| Step: 10
Training loss: 7.622445106506348
Validation loss: 7.272625974613986
Epoch: 9| Step: 11
Training loss: 7.694134712219238
Validation loss: 7.241709112263412
Epoch: 9| Step: 12
Training loss: 7.4500322341918945
Validation loss: 7.2090797561535735
Epoch: 9| Step: 13
Training loss: 6.750471115112305
Validation loss: 7.178193442255473
Epoch: 9| Step: 14
Training loss: 8.090652465820312
Validation loss: 7.1428226052428325
Epoch: 9| Step: 15
Training loss: 6.938947677612305
Validation loss: 7.097529675463121
Epoch: 9| Step: 16
Training loss: 8.64436149597168
Validation loss: 7.0663369267964535
Epoch: 9| Step: 17
Training loss: 7.807343482971191
Validation loss: 7.027991023852671
Epoch: 9| Step: 18
Training loss: 7.6649322509765625
Validation loss: 6.999389741060545
Epoch: 9| Step: 19
Training loss: 5.615119934082031
Validation loss: 6.962000033838286
Epoch: 10| Step: 0
Training loss: 7.017149448394775
Validation loss: 6.921633675801668
Epoch: 9| Step: 1
Training loss: 6.72111701965332
Validation loss: 6.879571159966558
Epoch: 9| Step: 2
Training loss: 7.788006782531738
Validation loss: 6.85120501621164
Epoch: 9| Step: 3
Training loss: 7.6413469314575195
Validation loss: 6.816682098580779
Epoch: 9| Step: 4
Training loss: 6.9771013259887695
Validation loss: 6.773049268791143
Epoch: 9| Step: 5
Training loss: 6.529885292053223
Validation loss: 6.732069111556458
Epoch: 9| Step: 6
Training loss: 7.530965805053711
Validation loss: 6.6962681056784215
Epoch: 9| Step: 7
Training loss: 6.218448638916016
Validation loss: 6.6594260270647005
Epoch: 9| Step: 8
Training loss: 7.459540367126465
Validation loss: 6.614776676507305
Epoch: 9| Step: 9
Training loss: 7.513548374176025
Validation loss: 6.576717778075513
Epoch: 9| Step: 10
Training loss: 6.712547779083252
Validation loss: 6.545485801833997
Epoch: 9| Step: 11
Training loss: 6.277152061462402
Validation loss: 6.499404083910606
Epoch: 9| Step: 12
Training loss: 5.568938255310059
Validation loss: 6.45885724472485
Epoch: 9| Step: 13
Training loss: 6.470424175262451
Validation loss: 6.422514836565196
Epoch: 9| Step: 14
Training loss: 6.541596412658691
Validation loss: 6.37829742157202
Epoch: 9| Step: 15
Training loss: 6.995242595672607
Validation loss: 6.328695276658312
Epoch: 9| Step: 16
Training loss: 6.2648820877075195
Validation loss: 6.297707317544402
Epoch: 9| Step: 17
Training loss: 5.555781364440918
Validation loss: 6.245606292065957
Epoch: 9| Step: 18
Training loss: 7.60936164855957
Validation loss: 6.205558128494153
Epoch: 9| Step: 19
Training loss: 6.841751575469971
Validation loss: 6.1441817660983515
Epoch: 11| Step: 0
Training loss: 5.748218536376953
Validation loss: 6.111584793749473
Epoch: 9| Step: 1
Training loss: 6.780966758728027
Validation loss: 6.055231533462195
Epoch: 9| Step: 2
Training loss: 7.35202693939209
Validation loss: 6.02395348583194
Epoch: 9| Step: 3
Training loss: 6.307772636413574
Validation loss: 5.96825462451084
Epoch: 9| Step: 4
Training loss: 6.745670318603516
Validation loss: 5.915205001831055
Epoch: 9| Step: 5
Training loss: 6.980248928070068
Validation loss: 5.8666429691177475
Epoch: 9| Step: 6
Training loss: 6.1692914962768555
Validation loss: 5.821923235337511
Epoch: 9| Step: 7
Training loss: 6.160327434539795
Validation loss: 5.762912287128915
Epoch: 9| Step: 8
Training loss: 5.752958297729492
Validation loss: 5.711465832140806
Epoch: 9| Step: 9
Training loss: 6.100003242492676
Validation loss: 5.660410743823155
Epoch: 9| Step: 10
Training loss: 6.431609153747559
Validation loss: 5.615839844984974
Epoch: 9| Step: 11
Training loss: 5.538209438323975
Validation loss: 5.5605351118732695
Epoch: 9| Step: 12
Training loss: 5.41087532043457
Validation loss: 5.509654545955521
Epoch: 9| Step: 13
Training loss: 6.113965034484863
Validation loss: 5.459590067966379
Epoch: 9| Step: 14
Training loss: 5.086977958679199
Validation loss: 5.40171809848264
Epoch: 9| Step: 15
Training loss: 5.840210914611816
Validation loss: 5.340855094168684
Epoch: 9| Step: 16
Training loss: 4.234832286834717
Validation loss: 5.291409797805676
Epoch: 9| Step: 17
Training loss: 5.920141696929932
Validation loss: 5.238548687036089
Epoch: 9| Step: 18
Training loss: 5.454130172729492
Validation loss: 5.171654063163044
Epoch: 9| Step: 19
Training loss: 4.651039123535156
Validation loss: 5.114513496700808
Epoch: 12| Step: 0
Training loss: 4.165763854980469
Validation loss: 5.058402023727088
Epoch: 9| Step: 1
Training loss: 5.26174783706665
Validation loss: 4.9979303311958585
Epoch: 9| Step: 2
Training loss: 5.529999256134033
Validation loss: 4.933750691173746
Epoch: 9| Step: 3
Training loss: 4.598175525665283
Validation loss: 4.886637746001319
Epoch: 9| Step: 4
Training loss: 5.91229248046875
Validation loss: 4.821166398713914
Epoch: 9| Step: 5
Training loss: 5.812925815582275
Validation loss: 4.764833999194687
Epoch: 9| Step: 6
Training loss: 5.6934309005737305
Validation loss: 4.694694862091284
Epoch: 9| Step: 7
Training loss: 6.024145126342773
Validation loss: 4.628757809563506
Epoch: 9| Step: 8
Training loss: 5.352043628692627
Validation loss: 4.582850603748568
Epoch: 9| Step: 9
Training loss: 5.632673740386963
Validation loss: 4.515637312004034
Epoch: 9| Step: 10
Training loss: 3.7630600929260254
Validation loss: 4.43320306599569
Epoch: 9| Step: 11
Training loss: 3.72733211517334
Validation loss: 4.3663767704860765
Epoch: 9| Step: 12
Training loss: 4.190030097961426
Validation loss: 4.3059201617892695
Epoch: 9| Step: 13
Training loss: 4.210995674133301
Validation loss: 4.238246588398226
Epoch: 9| Step: 14
Training loss: 4.841270446777344
Validation loss: 4.182798762973264
Epoch: 9| Step: 15
Training loss: 5.454129219055176
Validation loss: 4.085676759267025
Epoch: 9| Step: 16
Training loss: 4.32680606842041
Validation loss: 4.019352396615117
Epoch: 9| Step: 17
Training loss: 5.041947364807129
Validation loss: 3.9600558075115835
Epoch: 9| Step: 18
Training loss: 3.105983018875122
Validation loss: 3.88478393863431
Epoch: 9| Step: 19
Training loss: 4.191049575805664
Validation loss: 3.830313850649827
Epoch: 13| Step: 0
Training loss: 4.204830169677734
Validation loss: 3.7422356725596697
Epoch: 9| Step: 1
Training loss: 3.868757724761963
Validation loss: 3.6620819071213977
Epoch: 9| Step: 2
Training loss: 4.153141021728516
Validation loss: 3.60422976583028
Epoch: 9| Step: 3
Training loss: 4.674956321716309
Validation loss: 3.510030406842129
Epoch: 9| Step: 4
Training loss: 4.216970920562744
Validation loss: 3.4878973343389497
Epoch: 9| Step: 5
Training loss: 4.554013729095459
Validation loss: 3.394294244779957
Epoch: 9| Step: 6
Training loss: 3.908458709716797
Validation loss: 3.312771991002474
Epoch: 9| Step: 7
Training loss: 2.7207469940185547
Validation loss: 3.249217244360944
Epoch: 9| Step: 8
Training loss: 4.542824745178223
Validation loss: 3.1987136559520692
Epoch: 9| Step: 9
Training loss: 3.56819748878479
Validation loss: 3.1189768914696123
Epoch: 9| Step: 10
Training loss: 3.5755057334899902
Validation loss: 3.062059484797416
Epoch: 9| Step: 11
Training loss: 3.6048731803894043
Validation loss: 3.0077378046598366
Epoch: 9| Step: 12
Training loss: 4.2410888671875
Validation loss: 2.9421297474730785
Epoch: 9| Step: 13
Training loss: 3.3353774547576904
Validation loss: 2.90186865724248
Epoch: 9| Step: 14
Training loss: 4.232998847961426
Validation loss: 2.8320774843366885
Epoch: 9| Step: 15
Training loss: 2.7423319816589355
Validation loss: 2.7890131370626765
Epoch: 9| Step: 16
Training loss: 3.7930359840393066
Validation loss: 2.7340970433873237
Epoch: 9| Step: 17
Training loss: 2.4551873207092285
Validation loss: 2.6765812712607624
Epoch: 9| Step: 18
Training loss: 2.49149751663208
Validation loss: 2.605539563748476
Epoch: 9| Step: 19
Training loss: 2.796109676361084
Validation loss: 2.5848257095693685
Epoch: 14| Step: 0
Training loss: 2.9589202404022217
Validation loss: 2.530508393006359
Epoch: 9| Step: 1
Training loss: 2.8593947887420654
Validation loss: 2.481605979178449
Epoch: 9| Step: 2
Training loss: 2.0540807247161865
Validation loss: 2.43670230975254
Epoch: 9| Step: 3
Training loss: 3.60286808013916
Validation loss: 2.3892361260146546
Epoch: 9| Step: 4
Training loss: 3.1426117420196533
Validation loss: 2.3534081736914545
Epoch: 9| Step: 5
Training loss: 3.570174217224121
Validation loss: 2.3296628461467277
Epoch: 9| Step: 6
Training loss: 2.2795515060424805
Validation loss: 2.2499121984989525
Epoch: 9| Step: 7
Training loss: 2.6132285594940186
Validation loss: 2.2459557905471583
Epoch: 9| Step: 8
Training loss: 3.194680690765381
Validation loss: 2.224097912260097
Epoch: 9| Step: 9
Training loss: 2.5574378967285156
Validation loss: 2.1739231562442916
Epoch: 9| Step: 10
Training loss: 3.165820360183716
Validation loss: 2.1662432332690673
Epoch: 9| Step: 11
Training loss: 2.9635653495788574
Validation loss: 2.1630758398728407
Epoch: 9| Step: 12
Training loss: 2.4361929893493652
Validation loss: 2.1528224996525607
Epoch: 9| Step: 13
Training loss: 2.8490099906921387
Validation loss: 2.1122313214720583
Epoch: 9| Step: 14
Training loss: 2.2806155681610107
Validation loss: 2.1030709177470035
Epoch: 9| Step: 15
Training loss: 2.5601861476898193
Validation loss: 2.10622462180021
Epoch: 9| Step: 16
Training loss: 3.597177505493164
Validation loss: 2.0879210310874226
Epoch: 9| Step: 17
Training loss: 2.0988755226135254
Validation loss: 2.0741619875105166
Epoch: 9| Step: 18
Training loss: 1.9191863536834717
Validation loss: 2.0446462082348282
Epoch: 9| Step: 19
Training loss: 2.9433114528656006
Validation loss: 2.055709249681706
Epoch: 15| Step: 0
Training loss: 3.042121171951294
Validation loss: 2.050441313990586
Epoch: 9| Step: 1
Training loss: 1.8379061222076416
Validation loss: 2.0316905452193117
Epoch: 9| Step: 2
Training loss: 3.0762574672698975
Validation loss: 2.0266863141986105
Epoch: 9| Step: 3
Training loss: 2.364229679107666
Validation loss: 2.0015759056420634
Epoch: 9| Step: 4
Training loss: 2.7344086170196533
Validation loss: 2.0219328943773998
Epoch: 9| Step: 5
Training loss: 2.546783447265625
Validation loss: 2.016172543704081
Epoch: 9| Step: 6
Training loss: 2.565788745880127
Validation loss: 2.025497503417859
Epoch: 9| Step: 7
Training loss: 3.075796365737915
Validation loss: 2.048457112243707
Epoch: 9| Step: 8
Training loss: 1.871908187866211
Validation loss: 2.011130965870919
Epoch: 9| Step: 9
Training loss: 1.8967808485031128
Validation loss: 2.0176928995324555
Epoch: 9| Step: 10
Training loss: 2.360485076904297
Validation loss: 2.0179232041612805
Epoch: 9| Step: 11
Training loss: 2.8713088035583496
Validation loss: 2.007822246860257
Epoch: 9| Step: 12
Training loss: 2.272643804550171
Validation loss: 2.0384385414260753
Epoch: 9| Step: 13
Training loss: 2.5452675819396973
Validation loss: 2.0128220997268347
Epoch: 9| Step: 14
Training loss: 3.0338101387023926
Validation loss: 2.0351776630758383
Epoch: 9| Step: 15
Training loss: 1.877670407295227
Validation loss: 2.022848468890293
Epoch: 9| Step: 16
Training loss: 2.272029399871826
Validation loss: 2.0277400239766075
Epoch: 9| Step: 17
Training loss: 2.521146774291992
Validation loss: 2.0606632481376046
Epoch: 9| Step: 18
Training loss: 2.148839235305786
Validation loss: 2.049860808489134
Epoch: 9| Step: 19
Training loss: 3.2093968391418457
Validation loss: 2.0499012418788114
Epoch: 16| Step: 0
Training loss: 2.2676453590393066
Validation loss: 2.0576995534004925
Epoch: 9| Step: 1
Training loss: 2.999840497970581
Validation loss: 2.0664769248139088
Epoch: 9| Step: 2
Training loss: 2.9651083946228027
Validation loss: 2.063536722883046
Epoch: 9| Step: 3
Training loss: 2.518848180770874
Validation loss: 2.0655455863733088
Epoch: 9| Step: 4
Training loss: 3.031244993209839
Validation loss: 2.074150654909422
Epoch: 9| Step: 5
Training loss: 1.8727550506591797
Validation loss: 2.0371684856552013
Epoch: 9| Step: 6
Training loss: 3.272223472595215
Validation loss: 2.07620568412671
Epoch: 9| Step: 7
Training loss: 2.28489351272583
Validation loss: 2.087483125624897
Epoch: 9| Step: 8
Training loss: 2.1846508979797363
Validation loss: 2.056926751308304
Epoch: 9| Step: 9
Training loss: 2.162069320678711
Validation loss: 2.0908946553580194
Epoch: 9| Step: 10
Training loss: 2.720686197280884
Validation loss: 2.0492219616183274
Epoch: 9| Step: 11
Training loss: 2.2671403884887695
Validation loss: 2.098170203270672
Epoch: 9| Step: 12
Training loss: 2.500776767730713
Validation loss: 2.066998891693225
Epoch: 9| Step: 13
Training loss: 2.427381753921509
Validation loss: 2.0665548482387184
Epoch: 9| Step: 14
Training loss: 2.0311479568481445
Validation loss: 2.085352039165634
Epoch: 9| Step: 15
Training loss: 1.9577741622924805
Validation loss: 2.073996898081663
Epoch: 9| Step: 16
Training loss: 2.3182485103607178
Validation loss: 2.078337047597487
Epoch: 9| Step: 17
Training loss: 2.1379730701446533
Validation loss: 2.066958492608379
Epoch: 9| Step: 18
Training loss: 2.0530006885528564
Validation loss: 2.0421222508382453
Epoch: 9| Step: 19
Training loss: 3.168163776397705
Validation loss: 2.061928102438398
Epoch: 17| Step: 0
Training loss: 2.608018398284912
Validation loss: 2.0853037088037394
Epoch: 9| Step: 1
Training loss: 2.493647336959839
Validation loss: 2.050750334485829
Epoch: 9| Step: 2
Training loss: 2.4245877265930176
Validation loss: 2.044278103670628
Epoch: 9| Step: 3
Training loss: 2.8351731300354004
Validation loss: 2.064329334300199
Epoch: 9| Step: 4
Training loss: 2.091667413711548
Validation loss: 2.0481971270746464
Epoch: 9| Step: 5
Training loss: 2.0993361473083496
Validation loss: 2.038610828866204
Epoch: 9| Step: 6
Training loss: 2.750182867050171
Validation loss: 2.0164439746801803
Epoch: 9| Step: 7
Training loss: 2.9997541904449463
Validation loss: 2.04373283737855
Epoch: 9| Step: 8
Training loss: 2.4752986431121826
Validation loss: 2.041060310473545
Epoch: 9| Step: 9
Training loss: 2.9547977447509766
Validation loss: 2.032945204981797
Epoch: 9| Step: 10
Training loss: 1.7440285682678223
Validation loss: 2.0320790551549237
Epoch: 9| Step: 11
Training loss: 2.2925291061401367
Validation loss: 2.024744388010862
Epoch: 9| Step: 12
Training loss: 2.6303906440734863
Validation loss: 2.0027652369986337
Epoch: 9| Step: 13
Training loss: 3.375649929046631
Validation loss: 2.0282880042096694
Epoch: 9| Step: 14
Training loss: 2.109823703765869
Validation loss: 2.0256709812356415
Epoch: 9| Step: 15
Training loss: 2.043494701385498
Validation loss: 2.011459259678134
Epoch: 9| Step: 16
Training loss: 1.9943259954452515
Validation loss: 2.0066202630241996
Epoch: 9| Step: 17
Training loss: 1.6193804740905762
Validation loss: 2.016157655407199
Epoch: 9| Step: 18
Training loss: 2.546196222305298
Validation loss: 1.9839323493216534
Epoch: 9| Step: 19
Training loss: 2.585178852081299
Validation loss: 1.9928957386840163
Epoch: 18| Step: 0
Training loss: 2.251265287399292
Validation loss: 2.000115212776678
Epoch: 9| Step: 1
Training loss: 1.6460472345352173
Validation loss: 1.987303246697076
Epoch: 9| Step: 2
Training loss: 2.3926846981048584
Validation loss: 1.992360643345675
Epoch: 9| Step: 3
Training loss: 2.714954137802124
Validation loss: 1.9807733563210468
Epoch: 9| Step: 4
Training loss: 2.2421486377716064
Validation loss: 1.9842228357740443
Epoch: 9| Step: 5
Training loss: 2.13509464263916
Validation loss: 1.970776024482233
Epoch: 9| Step: 6
Training loss: 2.4862592220306396
Validation loss: 1.9804888183264424
Epoch: 9| Step: 7
Training loss: 2.297999620437622
Validation loss: 1.988497649165366
Epoch: 9| Step: 8
Training loss: 1.9994683265686035
Validation loss: 2.0009973666650787
Epoch: 9| Step: 9
Training loss: 2.8782660961151123
Validation loss: 1.9959600409157843
Epoch: 9| Step: 10
Training loss: 2.359905481338501
Validation loss: 1.968021804480244
Epoch: 9| Step: 11
Training loss: 1.7433760166168213
Validation loss: 1.9785146867628578
Epoch: 9| Step: 12
Training loss: 3.169766426086426
Validation loss: 1.9737470716023617
Epoch: 9| Step: 13
Training loss: 3.5699143409729004
Validation loss: 1.9861178063660216
Epoch: 9| Step: 14
Training loss: 1.4913270473480225
Validation loss: 1.9850012544247744
Epoch: 9| Step: 15
Training loss: 2.2049434185028076
Validation loss: 1.9589772756151158
Epoch: 9| Step: 16
Training loss: 2.3673129081726074
Validation loss: 1.9694669203792545
Epoch: 9| Step: 17
Training loss: 2.7108540534973145
Validation loss: 1.9777272425109533
Epoch: 9| Step: 18
Training loss: 2.885953187942505
Validation loss: 1.96427080957152
Epoch: 9| Step: 19
Training loss: 2.736814260482788
Validation loss: 1.9932209965136412
Epoch: 19| Step: 0
Training loss: 1.978163242340088
Validation loss: 1.9911226222841003
Epoch: 9| Step: 1
Training loss: 2.06659197807312
Validation loss: 2.0172161301262945
Epoch: 9| Step: 2
Training loss: 2.9569621086120605
Validation loss: 1.9726650268911459
Epoch: 9| Step: 3
Training loss: 1.8810724020004272
Validation loss: 1.9877263736381805
Epoch: 9| Step: 4
Training loss: 3.1988401412963867
Validation loss: 2.002520029493373
Epoch: 9| Step: 5
Training loss: 2.6079506874084473
Validation loss: 1.9676183213432916
Epoch: 9| Step: 6
Training loss: 1.781643271446228
Validation loss: 2.0137486869482686
Epoch: 9| Step: 7
Training loss: 2.1430892944335938
Validation loss: 1.955563317957542
Epoch: 9| Step: 8
Training loss: 2.6220991611480713
Validation loss: 1.9790871169069688
Epoch: 9| Step: 9
Training loss: 1.9583266973495483
Validation loss: 1.980103530472131
Epoch: 9| Step: 10
Training loss: 1.6811084747314453
Validation loss: 1.9575398371374007
Epoch: 9| Step: 11
Training loss: 1.97079336643219
Validation loss: 1.98304098630123
Epoch: 9| Step: 12
Training loss: 2.3036627769470215
Validation loss: 1.9800135077332421
Epoch: 9| Step: 13
Training loss: 2.1609933376312256
Validation loss: 1.9984939338491976
Epoch: 9| Step: 14
Training loss: 3.0350356101989746
Validation loss: 1.9903311300620758
Epoch: 9| Step: 15
Training loss: 3.255675792694092
Validation loss: 2.0001961181489682
Epoch: 9| Step: 16
Training loss: 2.3083086013793945
Validation loss: 2.0032432585311453
Epoch: 9| Step: 17
Training loss: 3.281017541885376
Validation loss: 2.000649875016521
Epoch: 9| Step: 18
Training loss: 2.6586785316467285
Validation loss: 2.024162853364464
Epoch: 9| Step: 19
Training loss: 1.595463514328003
Validation loss: 2.0096868216562616
Epoch: 20| Step: 0
Training loss: 1.6881892681121826
Validation loss: 1.9768837184357129
Epoch: 9| Step: 1
Training loss: 2.306234836578369
Validation loss: 1.9972718593885572
Epoch: 9| Step: 2
Training loss: 2.8953652381896973
Validation loss: 2.0329622407611327
Epoch: 9| Step: 3
Training loss: 2.7559714317321777
Validation loss: 2.0270642659647002
Epoch: 9| Step: 4
Training loss: 2.379119873046875
Validation loss: 2.0279501273477676
Epoch: 9| Step: 5
Training loss: 2.105111837387085
Validation loss: 2.022656922717746
Epoch: 9| Step: 6
Training loss: 2.344754934310913
Validation loss: 2.0487409855822007
Epoch: 9| Step: 7
Training loss: 2.5616602897644043
Validation loss: 2.049815038125292
Epoch: 9| Step: 8
Training loss: 2.3968920707702637
Validation loss: 2.0173237452404105
Epoch: 9| Step: 9
Training loss: 2.227559804916382
Validation loss: 2.0723424626768923
Epoch: 9| Step: 10
Training loss: 2.4220147132873535
Validation loss: 2.05874492881967
Epoch: 9| Step: 11
Training loss: 2.735814332962036
Validation loss: 2.053605451858301
Epoch: 9| Step: 12
Training loss: 2.291588306427002
Validation loss: 2.0513600231074602
Epoch: 9| Step: 13
Training loss: 1.9863030910491943
Validation loss: 2.022747132417967
Epoch: 9| Step: 14
Training loss: 2.447284698486328
Validation loss: 2.0246255912369104
Epoch: 9| Step: 15
Training loss: 2.3196258544921875
Validation loss: 2.0516566552704187
Epoch: 9| Step: 16
Training loss: 2.4726948738098145
Validation loss: 2.0424891358656847
Epoch: 9| Step: 17
Training loss: 2.1927084922790527
Validation loss: 2.0454393891121843
Epoch: 9| Step: 18
Training loss: 2.212662696838379
Validation loss: 2.0299737496341734
Epoch: 9| Step: 19
Training loss: 2.273292303085327
Validation loss: 2.0155560438581506
Epoch: 21| Step: 0
Training loss: 2.5009193420410156
Validation loss: 2.025231370822989
Epoch: 9| Step: 1
Training loss: 2.7359681129455566
Validation loss: 2.0385835796809024
Epoch: 9| Step: 2
Training loss: 2.443958282470703
Validation loss: 2.009096474098645
Epoch: 9| Step: 3
Training loss: 2.3862404823303223
Validation loss: 2.0059861056238626
Epoch: 9| Step: 4
Training loss: 2.4762613773345947
Validation loss: 1.9682716397072773
Epoch: 9| Step: 5
Training loss: 2.662886619567871
Validation loss: 1.9899044242694224
Epoch: 9| Step: 6
Training loss: 2.5516250133514404
Validation loss: 1.9859056224068292
Epoch: 9| Step: 7
Training loss: 2.2457704544067383
Validation loss: 2.0277479329555153
Epoch: 9| Step: 8
Training loss: 2.5332465171813965
Validation loss: 1.9745155718686769
Epoch: 9| Step: 9
Training loss: 1.905005931854248
Validation loss: 1.9689776760211093
Epoch: 9| Step: 10
Training loss: 2.1115024089813232
Validation loss: 1.9703544181027859
Epoch: 9| Step: 11
Training loss: 2.7205617427825928
Validation loss: 1.9659621012296609
Epoch: 9| Step: 12
Training loss: 1.9734270572662354
Validation loss: 1.9975938771268447
Epoch: 9| Step: 13
Training loss: 1.4039208889007568
Validation loss: 1.955257514397875
Epoch: 9| Step: 14
Training loss: 1.9654510021209717
Validation loss: 2.0088571558753365
Epoch: 9| Step: 15
Training loss: 2.0072879791259766
Validation loss: 1.9595140656121344
Epoch: 9| Step: 16
Training loss: 2.6238088607788086
Validation loss: 1.9695089652383928
Epoch: 9| Step: 17
Training loss: 2.1878092288970947
Validation loss: 1.9760033012294083
Epoch: 9| Step: 18
Training loss: 3.02294921875
Validation loss: 2.002101652913814
Epoch: 9| Step: 19
Training loss: 2.2696094512939453
Validation loss: 1.983734050243021
Epoch: 22| Step: 0
Training loss: 1.6252858638763428
Validation loss: 1.975990389748443
Epoch: 9| Step: 1
Training loss: 1.9425262212753296
Validation loss: 1.9902568806847223
Epoch: 9| Step: 2
Training loss: 1.971970558166504
Validation loss: 1.9784583770971504
Epoch: 9| Step: 3
Training loss: 1.8294026851654053
Validation loss: 1.9891547453489236
Epoch: 9| Step: 4
Training loss: 2.7954630851745605
Validation loss: 1.9737544574325891
Epoch: 9| Step: 5
Training loss: 2.520002603530884
Validation loss: 2.0038547704545713
Epoch: 9| Step: 6
Training loss: 2.02663254737854
Validation loss: 1.9919934753033754
Epoch: 9| Step: 7
Training loss: 2.265625476837158
Validation loss: 1.954679890502271
Epoch: 9| Step: 8
Training loss: 3.43947696685791
Validation loss: 1.9579491392314006
Epoch: 9| Step: 9
Training loss: 2.448209285736084
Validation loss: 1.9830856709171543
Epoch: 9| Step: 10
Training loss: 2.4273719787597656
Validation loss: 1.992807611287069
Epoch: 9| Step: 11
Training loss: 2.523219585418701
Validation loss: 1.999040208274512
Epoch: 9| Step: 12
Training loss: 2.510998249053955
Validation loss: 1.982347497837149
Epoch: 9| Step: 13
Training loss: 1.5990405082702637
Validation loss: 1.9954195399936154
Epoch: 9| Step: 14
Training loss: 1.9709045886993408
Validation loss: 1.9986112881049836
Epoch: 9| Step: 15
Training loss: 2.3853511810302734
Validation loss: 2.0068502246047095
Epoch: 9| Step: 16
Training loss: 2.765172004699707
Validation loss: 1.965798481762838
Epoch: 9| Step: 17
Training loss: 2.4414894580841064
Validation loss: 2.015731525935715
Epoch: 9| Step: 18
Training loss: 1.95774507522583
Validation loss: 2.0195340973010167
Epoch: 9| Step: 19
Training loss: 3.019690990447998
Validation loss: 2.0293948547445613
Epoch: 23| Step: 0
Training loss: 3.065392255783081
Validation loss: 2.0120687261759804
Epoch: 9| Step: 1
Training loss: 2.7663509845733643
Validation loss: 1.9610338571260302
Epoch: 9| Step: 2
Training loss: 2.0626652240753174
Validation loss: 2.004906821593964
Epoch: 9| Step: 3
Training loss: 2.971562385559082
Validation loss: 1.988334492813769
Epoch: 9| Step: 4
Training loss: 1.9852087497711182
Validation loss: 2.0191946115425163
Epoch: 9| Step: 5
Training loss: 2.4657716751098633
Validation loss: 2.044443192241861
Epoch: 9| Step: 6
Training loss: 2.2456488609313965
Validation loss: 2.061485099277908
Epoch: 9| Step: 7
Training loss: 2.4110939502716064
Validation loss: 2.0049574546676747
Epoch: 9| Step: 8
Training loss: 2.278456211090088
Validation loss: 2.030905984288497
Epoch: 9| Step: 9
Training loss: 2.279545307159424
Validation loss: 2.006114162129464
Epoch: 9| Step: 10
Training loss: 3.059455394744873
Validation loss: 2.019701630091496
Epoch: 9| Step: 11
Training loss: 2.159332752227783
Validation loss: 2.017752878957515
Epoch: 9| Step: 12
Training loss: 2.0983986854553223
Validation loss: 1.9943929902083581
Epoch: 9| Step: 13
Training loss: 2.2070765495300293
Validation loss: 2.015523533169314
Epoch: 9| Step: 14
Training loss: 2.2468016147613525
Validation loss: 1.97343783498668
Epoch: 9| Step: 15
Training loss: 1.6539974212646484
Validation loss: 2.003220079614104
Epoch: 9| Step: 16
Training loss: 2.043039083480835
Validation loss: 1.9980840331358876
Epoch: 9| Step: 17
Training loss: 2.3884482383728027
Validation loss: 2.0128217609666232
Epoch: 9| Step: 18
Training loss: 1.8183763027191162
Validation loss: 1.997719220977893
Epoch: 9| Step: 19
Training loss: 1.9686412811279297
Validation loss: 1.952274204158097
Epoch: 24| Step: 0
Training loss: 1.6584115028381348
Validation loss: 2.00774951718694
Epoch: 9| Step: 1
Training loss: 2.233635425567627
Validation loss: 1.9794851018370485
Epoch: 9| Step: 2
Training loss: 2.2505908012390137
Validation loss: 1.986513003170919
Epoch: 9| Step: 3
Training loss: 2.269813299179077
Validation loss: 1.990452498840771
Epoch: 9| Step: 4
Training loss: 1.968085765838623
Validation loss: 1.982723711205901
Epoch: 9| Step: 5
Training loss: 2.3901491165161133
Validation loss: 1.9924032002044239
Epoch: 9| Step: 6
Training loss: 2.6085004806518555
Validation loss: 1.9825036637217022
Epoch: 9| Step: 7
Training loss: 2.850834846496582
Validation loss: 2.009968771351327
Epoch: 9| Step: 8
Training loss: 2.2754998207092285
Validation loss: 1.997270609835069
Epoch: 9| Step: 9
Training loss: 2.219538927078247
Validation loss: 2.0691545712862083
Epoch: 9| Step: 10
Training loss: 2.4826529026031494
Validation loss: 2.031515206364419
Epoch: 9| Step: 11
Training loss: 2.3094935417175293
Validation loss: 2.017485164052291
Epoch: 9| Step: 12
Training loss: 3.003781318664551
Validation loss: 2.001471294773568
Epoch: 9| Step: 13
Training loss: 2.2723753452301025
Validation loss: 2.0478908140882313
Epoch: 9| Step: 14
Training loss: 2.183119297027588
Validation loss: 2.0089115350366495
Epoch: 9| Step: 15
Training loss: 2.451625347137451
Validation loss: 2.0454151973449926
Epoch: 9| Step: 16
Training loss: 1.5755647420883179
Validation loss: 2.0489961174752214
Epoch: 9| Step: 17
Training loss: 2.4683265686035156
Validation loss: 2.03019061706049
Epoch: 9| Step: 18
Training loss: 2.456281900405884
Validation loss: 2.0277187018085727
Epoch: 9| Step: 19
Training loss: 1.7013285160064697
Validation loss: 2.005530072630738
Epoch: 25| Step: 0
Training loss: 1.8747979402542114
Validation loss: 2.020778690310691
Epoch: 9| Step: 1
Training loss: 2.9707589149475098
Validation loss: 2.008064238287562
Epoch: 9| Step: 2
Training loss: 2.4812960624694824
Validation loss: 2.024333272906516
Epoch: 9| Step: 3
Training loss: 2.1294660568237305
Validation loss: 2.0162728776177055
Epoch: 9| Step: 4
Training loss: 2.810972213745117
Validation loss: 1.985598337736061
Epoch: 9| Step: 5
Training loss: 2.8242108821868896
Validation loss: 2.0048566310525797
Epoch: 9| Step: 6
Training loss: 2.117861270904541
Validation loss: 2.028337066979717
Epoch: 9| Step: 7
Training loss: 1.5836317539215088
Validation loss: 1.9951490223836557
Epoch: 9| Step: 8
Training loss: 2.779496669769287
Validation loss: 2.044572596927341
Epoch: 9| Step: 9
Training loss: 2.3951621055603027
Validation loss: 1.9902453748442286
Epoch: 9| Step: 10
Training loss: 1.4729207754135132
Validation loss: 1.9947677722080148
Epoch: 9| Step: 11
Training loss: 1.946659803390503
Validation loss: 2.0002325061413884
Epoch: 9| Step: 12
Training loss: 2.2604660987854004
Validation loss: 2.025090613811136
Epoch: 9| Step: 13
Training loss: 2.03714656829834
Validation loss: 2.0597749159490464
Epoch: 9| Step: 14
Training loss: 2.534696102142334
Validation loss: 1.992714973662397
Epoch: 9| Step: 15
Training loss: 2.247389078140259
Validation loss: 2.017537288528552
Epoch: 9| Step: 16
Training loss: 2.1828017234802246
Validation loss: 2.0080630907909476
Epoch: 9| Step: 17
Training loss: 2.0132436752319336
Validation loss: 2.0176457449686613
Epoch: 9| Step: 18
Training loss: 2.3210110664367676
Validation loss: 1.9767348997884517
Epoch: 9| Step: 19
Training loss: 2.2579028606414795
Validation loss: 2.0023133789035055
Epoch: 26| Step: 0
Training loss: 2.130730152130127
Validation loss: 1.9756373167037964
Epoch: 9| Step: 1
Training loss: 2.0722336769104004
Validation loss: 2.0323427375272023
Epoch: 9| Step: 2
Training loss: 2.2820935249328613
Validation loss: 2.0575518265044948
Epoch: 9| Step: 3
Training loss: 2.354607105255127
Validation loss: 1.9825072923152567
Epoch: 9| Step: 4
Training loss: 1.5585792064666748
Validation loss: 1.9721880533712373
Epoch: 9| Step: 5
Training loss: 1.9092893600463867
Validation loss: 1.9955369345575786
Epoch: 9| Step: 6
Training loss: 1.959253191947937
Validation loss: 1.9869601958089596
Epoch: 9| Step: 7
Training loss: 2.6320836544036865
Validation loss: 2.024760989834079
Epoch: 9| Step: 8
Training loss: 2.3245248794555664
Validation loss: 1.987553767163119
Epoch: 9| Step: 9
Training loss: 2.488415479660034
Validation loss: 2.039024364176414
Epoch: 9| Step: 10
Training loss: 2.4757304191589355
Validation loss: 1.9855114384520827
Epoch: 9| Step: 11
Training loss: 2.4833860397338867
Validation loss: 1.967123905531794
Epoch: 9| Step: 12
Training loss: 2.586589813232422
Validation loss: 1.9696559674448246
Epoch: 9| Step: 13
Training loss: 1.8615803718566895
Validation loss: 1.9914103068893763
Epoch: 9| Step: 14
Training loss: 2.254493236541748
Validation loss: 1.9972588278406815
Epoch: 9| Step: 15
Training loss: 2.1220195293426514
Validation loss: 1.9637901199807366
Epoch: 9| Step: 16
Training loss: 1.8605146408081055
Validation loss: 2.027699456798087
Epoch: 9| Step: 17
Training loss: 2.350048780441284
Validation loss: 1.9734893076711422
Epoch: 9| Step: 18
Training loss: 3.032784938812256
Validation loss: 1.9823798927471792
Epoch: 9| Step: 19
Training loss: 2.345247268676758
Validation loss: 1.9596169801067105
Epoch: 27| Step: 0
Training loss: 2.002201557159424
Validation loss: 2.0006864276721323
Epoch: 9| Step: 1
Training loss: 2.014939785003662
Validation loss: 1.9796862988163242
Epoch: 9| Step: 2
Training loss: 1.9255754947662354
Validation loss: 1.9733819223993974
Epoch: 9| Step: 3
Training loss: 2.132073402404785
Validation loss: 1.9933588796382329
Epoch: 9| Step: 4
Training loss: 2.390113353729248
Validation loss: 1.9657893669691018
Epoch: 9| Step: 5
Training loss: 2.6766605377197266
Validation loss: 1.9582105377595203
Epoch: 9| Step: 6
Training loss: 1.8874475955963135
Validation loss: 1.9734141766596183
Epoch: 9| Step: 7
Training loss: 1.5553325414657593
Validation loss: 2.0405035962303764
Epoch: 9| Step: 8
Training loss: 2.671745538711548
Validation loss: 2.0029876377942752
Epoch: 9| Step: 9
Training loss: 2.3038694858551025
Validation loss: 2.0017562650090497
Epoch: 9| Step: 10
Training loss: 1.8135162591934204
Validation loss: 2.019468845223351
Epoch: 9| Step: 11
Training loss: 2.1219029426574707
Validation loss: 2.013833729483241
Epoch: 9| Step: 12
Training loss: 2.692328453063965
Validation loss: 2.0097146668880104
Epoch: 9| Step: 13
Training loss: 2.812453269958496
Validation loss: 2.0321351212563274
Epoch: 9| Step: 14
Training loss: 2.0715537071228027
Validation loss: 1.965715044693981
Epoch: 9| Step: 15
Training loss: 2.6558046340942383
Validation loss: 1.9720621683614716
Epoch: 9| Step: 16
Training loss: 1.5349631309509277
Validation loss: 2.018392255837969
Epoch: 9| Step: 17
Training loss: 2.3373241424560547
Validation loss: 1.9766999182941245
Epoch: 9| Step: 18
Training loss: 3.1282143592834473
Validation loss: 2.000066974180208
Epoch: 9| Step: 19
Training loss: 1.9119105339050293
Validation loss: 1.9645097255706787
Epoch: 28| Step: 0
Training loss: 1.953967809677124
Validation loss: 1.9590618233028934
Epoch: 9| Step: 1
Training loss: 2.019838333129883
Validation loss: 1.960506452930917
Epoch: 9| Step: 2
Training loss: 2.4549617767333984
Validation loss: 1.9926249380591963
Epoch: 9| Step: 3
Training loss: 2.479377508163452
Validation loss: 2.0051732234817616
Epoch: 9| Step: 4
Training loss: 1.7243008613586426
Validation loss: 1.9753253682911824
Epoch: 9| Step: 5
Training loss: 2.734814167022705
Validation loss: 2.048790309068968
Epoch: 9| Step: 6
Training loss: 1.7791465520858765
Validation loss: 1.9624536534865125
Epoch: 9| Step: 7
Training loss: 1.8499042987823486
Validation loss: 2.000955379266533
Epoch: 9| Step: 8
Training loss: 2.3509156703948975
Validation loss: 1.9584637700224952
Epoch: 9| Step: 9
Training loss: 2.166168689727783
Validation loss: 1.958121447254428
Epoch: 9| Step: 10
Training loss: 2.688851833343506
Validation loss: 1.9775032534016121
Epoch: 9| Step: 11
Training loss: 2.343458652496338
Validation loss: 2.03200702530017
Epoch: 9| Step: 12
Training loss: 1.668025016784668
Validation loss: 2.0089945630203907
Epoch: 9| Step: 13
Training loss: 2.0845320224761963
Validation loss: 1.9814453485200731
Epoch: 9| Step: 14
Training loss: 2.538594961166382
Validation loss: 2.0296082831115174
Epoch: 9| Step: 15
Training loss: 2.322929620742798
Validation loss: 2.0113627258822215
Epoch: 9| Step: 16
Training loss: 2.8985071182250977
Validation loss: 1.9865230416222441
Epoch: 9| Step: 17
Training loss: 2.681734323501587
Validation loss: 1.991010952338898
Epoch: 9| Step: 18
Training loss: 2.050039291381836
Validation loss: 1.9688136534725162
Epoch: 9| Step: 19
Training loss: 2.0407018661499023
Validation loss: 2.0166208855539773
Epoch: 29| Step: 0
Training loss: 2.613386869430542
Validation loss: 1.9543945669270248
Epoch: 9| Step: 1
Training loss: 2.297551393508911
Validation loss: 1.9314637338514808
Epoch: 9| Step: 2
Training loss: 1.8747518062591553
Validation loss: 1.9593807210167535
Epoch: 9| Step: 3
Training loss: 1.990622878074646
Validation loss: 1.942086566266396
Epoch: 9| Step: 4
Training loss: 1.652635931968689
Validation loss: 1.988358003630055
Epoch: 9| Step: 5
Training loss: 2.629608154296875
Validation loss: 1.9728334155871714
Epoch: 9| Step: 6
Training loss: 1.4580100774765015
Validation loss: 1.9432641928144496
Epoch: 9| Step: 7
Training loss: 1.6440649032592773
Validation loss: 2.0182621084528862
Epoch: 9| Step: 8
Training loss: 2.2946982383728027
Validation loss: 1.9644903965133558
Epoch: 9| Step: 9
Training loss: 2.4093663692474365
Validation loss: 1.9688845847150405
Epoch: 9| Step: 10
Training loss: 3.1539347171783447
Validation loss: 1.9492283785085884
Epoch: 9| Step: 11
Training loss: 2.5552988052368164
Validation loss: 1.9957828890505454
Epoch: 9| Step: 12
Training loss: 2.0545287132263184
Validation loss: 1.9993317538885762
Epoch: 9| Step: 13
Training loss: 2.9505090713500977
Validation loss: 1.9278080977981897
Epoch: 9| Step: 14
Training loss: 1.746354341506958
Validation loss: 1.9889012052000856
Epoch: 9| Step: 15
Training loss: 1.8567125797271729
Validation loss: 1.9456004787692063
Epoch: 9| Step: 16
Training loss: 2.444096565246582
Validation loss: 1.9839899437033015
Epoch: 9| Step: 17
Training loss: 2.193692445755005
Validation loss: 1.9864967443960175
Epoch: 9| Step: 18
Training loss: 2.4445600509643555
Validation loss: 1.9964983617659096
Epoch: 9| Step: 19
Training loss: 2.633932113647461
Validation loss: 1.9842997257658046
Epoch: 30| Step: 0
Training loss: 1.5690680742263794
Validation loss: 1.9692401079822788
Epoch: 9| Step: 1
Training loss: 2.6094627380371094
Validation loss: 1.9755283062406581
Epoch: 9| Step: 2
Training loss: 1.4910475015640259
Validation loss: 1.9402245265974416
Epoch: 9| Step: 3
Training loss: 2.2369883060455322
Validation loss: 1.992097618768541
Epoch: 9| Step: 4
Training loss: 1.9835121631622314
Validation loss: 1.989518566097287
Epoch: 9| Step: 5
Training loss: 1.9381614923477173
Validation loss: 1.9625232717116101
Epoch: 9| Step: 6
Training loss: 2.457272529602051
Validation loss: 1.9979402281397538
Epoch: 9| Step: 7
Training loss: 2.2358651161193848
Validation loss: 1.9929110669403625
Epoch: 9| Step: 8
Training loss: 2.429633617401123
Validation loss: 1.9720772487654104
Epoch: 9| Step: 9
Training loss: 2.3202385902404785
Validation loss: 1.9669019867190354
Epoch: 9| Step: 10
Training loss: 3.2150652408599854
Validation loss: 1.9558414881177943
Epoch: 9| Step: 11
Training loss: 2.040318489074707
Validation loss: 1.9457279726755705
Epoch: 9| Step: 12
Training loss: 2.3286027908325195
Validation loss: 1.9718341278515275
Epoch: 9| Step: 13
Training loss: 2.150824546813965
Validation loss: 2.0120083256591137
Epoch: 9| Step: 14
Training loss: 2.005302906036377
Validation loss: 2.016653433120508
Epoch: 9| Step: 15
Training loss: 3.00753116607666
Validation loss: 1.9935763739853454
Epoch: 9| Step: 16
Training loss: 2.00758695602417
Validation loss: 2.036504188029886
Epoch: 9| Step: 17
Training loss: 2.2696123123168945
Validation loss: 1.982265861771947
Epoch: 9| Step: 18
Training loss: 1.7617897987365723
Validation loss: 2.0331193817605215
Epoch: 9| Step: 19
Training loss: 2.6806390285491943
Validation loss: 1.9644591559609064
Epoch: 31| Step: 0
Training loss: 2.359121561050415
Validation loss: 2.020074942986742
Epoch: 9| Step: 1
Training loss: 2.0579757690429688
Validation loss: 2.0005195346667612
Epoch: 9| Step: 2
Training loss: 2.2865841388702393
Validation loss: 2.016548914017437
Epoch: 9| Step: 3
Training loss: 2.475947380065918
Validation loss: 2.009202840516893
Epoch: 9| Step: 4
Training loss: 1.76021409034729
Validation loss: 2.040742469348496
Epoch: 9| Step: 5
Training loss: 2.683804988861084
Validation loss: 1.9711469386121352
Epoch: 9| Step: 6
Training loss: 1.7566159963607788
Validation loss: 2.001393230698949
Epoch: 9| Step: 7
Training loss: 2.148519515991211
Validation loss: 2.0090599420259325
Epoch: 9| Step: 8
Training loss: 2.792646884918213
Validation loss: 2.020204276489697
Epoch: 9| Step: 9
Training loss: 1.9821830987930298
Validation loss: 2.044592855645598
Epoch: 9| Step: 10
Training loss: 2.016590118408203
Validation loss: 2.0115659296941413
Epoch: 9| Step: 11
Training loss: 2.5285420417785645
Validation loss: 2.0648201832668387
Epoch: 9| Step: 12
Training loss: 2.2964632511138916
Validation loss: 2.0353636167032256
Epoch: 9| Step: 13
Training loss: 1.6728404760360718
Validation loss: 2.0280155226481047
Epoch: 9| Step: 14
Training loss: 1.3636702299118042
Validation loss: 2.0333371839934973
Epoch: 9| Step: 15
Training loss: 1.4414219856262207
Validation loss: 2.0443810061585133
Epoch: 9| Step: 16
Training loss: 2.560822010040283
Validation loss: 2.0477893969995513
Epoch: 9| Step: 17
Training loss: 2.932695150375366
Validation loss: 2.055312820475736
Epoch: 9| Step: 18
Training loss: 2.337909460067749
Validation loss: 2.0308156836804727
Epoch: 9| Step: 19
Training loss: 2.556478500366211
Validation loss: 2.0038388255688786
Epoch: 32| Step: 0
Training loss: 1.7247109413146973
Validation loss: 1.97866917599877
Epoch: 9| Step: 1
Training loss: 1.9929821491241455
Validation loss: 1.946633062774329
Epoch: 9| Step: 2
Training loss: 2.3135509490966797
Validation loss: 2.004614372047589
Epoch: 9| Step: 3
Training loss: 2.570565700531006
Validation loss: 1.9791177536943834
Epoch: 9| Step: 4
Training loss: 2.894597053527832
Validation loss: 1.9913964014259173
Epoch: 9| Step: 5
Training loss: 2.071138381958008
Validation loss: 1.9761299675317119
Epoch: 9| Step: 6
Training loss: 2.1900625228881836
Validation loss: 1.9293604583191357
Epoch: 9| Step: 7
Training loss: 2.8241491317749023
Validation loss: 1.9837052204626069
Epoch: 9| Step: 8
Training loss: 1.7557809352874756
Validation loss: 1.9214811213582539
Epoch: 9| Step: 9
Training loss: 1.7781089544296265
Validation loss: 2.000385013415659
Epoch: 9| Step: 10
Training loss: 2.775529146194458
Validation loss: 2.001099125944453
Epoch: 9| Step: 11
Training loss: 2.617138147354126
Validation loss: 1.951177518144786
Epoch: 9| Step: 12
Training loss: 1.5057804584503174
Validation loss: 1.9476738919457086
Epoch: 9| Step: 13
Training loss: 1.7085232734680176
Validation loss: 1.971862711494775
Epoch: 9| Step: 14
Training loss: 2.5478105545043945
Validation loss: 1.9667809618462762
Epoch: 9| Step: 15
Training loss: 1.8782305717468262
Validation loss: 1.9311290370474616
Epoch: 9| Step: 16
Training loss: 1.9517172574996948
Validation loss: 1.97608775543652
Epoch: 9| Step: 17
Training loss: 2.0074570178985596
Validation loss: 1.964479663389192
Epoch: 9| Step: 18
Training loss: 2.0807695388793945
Validation loss: 1.9551397373350403
Epoch: 9| Step: 19
Training loss: 2.433891534805298
Validation loss: 2.0018636991651797
Epoch: 33| Step: 0
Training loss: 3.1564583778381348
Validation loss: 1.9416366806990808
Epoch: 9| Step: 1
Training loss: 1.9278442859649658
Validation loss: 1.9883857691030709
Epoch: 9| Step: 2
Training loss: 2.1685690879821777
Validation loss: 1.98589923570482
Epoch: 9| Step: 3
Training loss: 2.242084264755249
Validation loss: 1.9763461342818445
Epoch: 9| Step: 4
Training loss: 1.6441864967346191
Validation loss: 1.9519418563774165
Epoch: 9| Step: 5
Training loss: 2.2094147205352783
Validation loss: 1.95881589453855
Epoch: 9| Step: 6
Training loss: 1.8492810726165771
Validation loss: 1.9676014862472204
Epoch: 9| Step: 7
Training loss: 2.522282600402832
Validation loss: 1.9358278058415694
Epoch: 9| Step: 8
Training loss: 2.495525360107422
Validation loss: 2.0068173674370744
Epoch: 9| Step: 9
Training loss: 3.2250258922576904
Validation loss: 1.9106178806840086
Epoch: 9| Step: 10
Training loss: 1.958909034729004
Validation loss: 1.938116666224363
Epoch: 9| Step: 11
Training loss: 2.8213751316070557
Validation loss: 1.9855697403708807
Epoch: 9| Step: 12
Training loss: 1.9007515907287598
Validation loss: 1.965627285216352
Epoch: 9| Step: 13
Training loss: 2.0816030502319336
Validation loss: 1.9625490243486363
Epoch: 9| Step: 14
Training loss: 1.9770047664642334
Validation loss: 1.9319894365269503
Epoch: 9| Step: 15
Training loss: 1.9966301918029785
Validation loss: 1.94577244545916
Epoch: 9| Step: 16
Training loss: 1.466429352760315
Validation loss: 1.9212157314629863
Epoch: 9| Step: 17
Training loss: 2.0661637783050537
Validation loss: 1.9369960843230323
Epoch: 9| Step: 18
Training loss: 2.4728312492370605
Validation loss: 1.9245532793964413
Epoch: 9| Step: 19
Training loss: 2.0788657665252686
Validation loss: 1.9333846003031558
Epoch: 34| Step: 0
Training loss: 2.6729395389556885
Validation loss: 1.9381610095072135
Epoch: 9| Step: 1
Training loss: 1.8432416915893555
Validation loss: 1.905793239744447
Epoch: 9| Step: 2
Training loss: 1.8498179912567139
Validation loss: 1.9070401328930753
Epoch: 9| Step: 3
Training loss: 2.1202282905578613
Validation loss: 1.9343689191255637
Epoch: 9| Step: 4
Training loss: 2.3047776222229004
Validation loss: 1.9046911129848563
Epoch: 9| Step: 5
Training loss: 2.1603384017944336
Validation loss: 1.9574017524719238
Epoch: 9| Step: 6
Training loss: 1.9409775733947754
Validation loss: 1.901120836786229
Epoch: 9| Step: 7
Training loss: 1.2716104984283447
Validation loss: 2.0256555354852472
Epoch: 9| Step: 8
Training loss: 2.336017608642578
Validation loss: 2.017222843581824
Epoch: 9| Step: 9
Training loss: 2.0777618885040283
Validation loss: 2.027656393085452
Epoch: 9| Step: 10
Training loss: 1.9503998756408691
Validation loss: 2.0333490268789607
Epoch: 9| Step: 11
Training loss: 2.4208881855010986
Validation loss: 2.026318551825105
Epoch: 9| Step: 12
Training loss: 3.5542213916778564
Validation loss: 2.026892947636062
Epoch: 9| Step: 13
Training loss: 1.704270601272583
Validation loss: 2.040000126516219
Epoch: 9| Step: 14
Training loss: 2.123281240463257
Validation loss: 2.004321292149935
Epoch: 9| Step: 15
Training loss: 2.551217794418335
Validation loss: 1.9899262661556545
Epoch: 9| Step: 16
Training loss: 2.055365562438965
Validation loss: 2.016344565281765
Epoch: 9| Step: 17
Training loss: 2.409514904022217
Validation loss: 2.0115479805486665
Epoch: 9| Step: 18
Training loss: 2.1274542808532715
Validation loss: 2.001098738299857
Epoch: 9| Step: 19
Training loss: 2.497716188430786
Validation loss: 1.971399366426811
Epoch: 35| Step: 0
Training loss: 2.0403380393981934
Validation loss: 1.9377148202854952
Epoch: 9| Step: 1
Training loss: 1.9179563522338867
Validation loss: 1.9710311786733943
Epoch: 9| Step: 2
Training loss: 1.9323711395263672
Validation loss: 1.916000486277848
Epoch: 9| Step: 3
Training loss: 2.1376638412475586
Validation loss: 1.9204938686151298
Epoch: 9| Step: 4
Training loss: 2.39794659614563
Validation loss: 1.9365270395073102
Epoch: 9| Step: 5
Training loss: 2.161214828491211
Validation loss: 1.9762953039553526
Epoch: 9| Step: 6
Training loss: 2.2644381523132324
Validation loss: 1.9380950490347773
Epoch: 9| Step: 7
Training loss: 1.7215559482574463
Validation loss: 1.9151884025807002
Epoch: 9| Step: 8
Training loss: 3.2051000595092773
Validation loss: 1.890427289249228
Epoch: 9| Step: 9
Training loss: 2.2376112937927246
Validation loss: 1.9254335765358355
Epoch: 9| Step: 10
Training loss: 1.833426833152771
Validation loss: 1.8997297818712193
Epoch: 9| Step: 11
Training loss: 1.9520078897476196
Validation loss: 1.9239481455988163
Epoch: 9| Step: 12
Training loss: 2.103001117706299
Validation loss: 1.9511063690665815
Epoch: 9| Step: 13
Training loss: 2.577399730682373
Validation loss: 1.9555939333044368
Epoch: 9| Step: 14
Training loss: 2.4932217597961426
Validation loss: 1.987115299101356
Epoch: 9| Step: 15
Training loss: 2.21295166015625
Validation loss: 1.9225980609440976
Epoch: 9| Step: 16
Training loss: 1.9537907838821411
Validation loss: 1.917952266528452
Epoch: 9| Step: 17
Training loss: 2.673740863800049
Validation loss: 1.920928072586334
Epoch: 9| Step: 18
Training loss: 1.6845488548278809
Validation loss: 1.8773129303678333
Epoch: 9| Step: 19
Training loss: 2.5595743656158447
Validation loss: 1.9668384498829463
Epoch: 36| Step: 0
Training loss: 1.5498173236846924
Validation loss: 1.910967068706485
Epoch: 9| Step: 1
Training loss: 2.414942979812622
Validation loss: 1.9478456056375297
Epoch: 9| Step: 2
Training loss: 1.5390541553497314
Validation loss: 1.96994962537889
Epoch: 9| Step: 3
Training loss: 2.168236255645752
Validation loss: 1.9433490423847446
Epoch: 9| Step: 4
Training loss: 1.6243208646774292
Validation loss: 1.9887990591337354
Epoch: 9| Step: 5
Training loss: 2.2908706665039062
Validation loss: 1.9828209499661014
Epoch: 9| Step: 6
Training loss: 2.3070340156555176
Validation loss: 2.065891699825259
Epoch: 9| Step: 7
Training loss: 1.5549838542938232
Validation loss: 2.024448501977989
Epoch: 9| Step: 8
Training loss: 1.5511744022369385
Validation loss: 2.0237268012204614
Epoch: 9| Step: 9
Training loss: 2.4507031440734863
Validation loss: 2.0267691354957416
Epoch: 9| Step: 10
Training loss: 2.1489648818969727
Validation loss: 2.063966191929879
Epoch: 9| Step: 11
Training loss: 1.8633041381835938
Validation loss: 2.0506612980108465
Epoch: 9| Step: 12
Training loss: 3.4040002822875977
Validation loss: 2.0640501564355205
Epoch: 9| Step: 13
Training loss: 2.278439521789551
Validation loss: 2.041891538839546
Epoch: 9| Step: 14
Training loss: 2.011532783508301
Validation loss: 2.0681561463170772
Epoch: 9| Step: 15
Training loss: 2.1522090435028076
Validation loss: 2.013366995955543
Epoch: 9| Step: 16
Training loss: 2.4907522201538086
Validation loss: 2.0192181060640073
Epoch: 9| Step: 17
Training loss: 3.3658053874969482
Validation loss: 1.9966645137869197
Epoch: 9| Step: 18
Training loss: 2.603041648864746
Validation loss: 1.9313540836032346
Epoch: 9| Step: 19
Training loss: 1.7054634094238281
Validation loss: 2.006454776516921
Epoch: 37| Step: 0
Training loss: 1.8303463459014893
Validation loss: 1.962895741565622
Epoch: 9| Step: 1
Training loss: 2.9624321460723877
Validation loss: 2.0039238089280165
Epoch: 9| Step: 2
Training loss: 2.1427464485168457
Validation loss: 1.9880946300012603
Epoch: 9| Step: 3
Training loss: 2.2557454109191895
Validation loss: 1.9916138357395747
Epoch: 9| Step: 4
Training loss: 1.3917129039764404
Validation loss: 1.9415264549872857
Epoch: 9| Step: 5
Training loss: 3.34139347076416
Validation loss: 2.0317410899580812
Epoch: 9| Step: 6
Training loss: 2.134570598602295
Validation loss: 1.9682618542540846
Epoch: 9| Step: 7
Training loss: 2.246978759765625
Validation loss: 1.974253231672932
Epoch: 9| Step: 8
Training loss: 2.453913688659668
Validation loss: 1.9816160999613701
Epoch: 9| Step: 9
Training loss: 1.8056901693344116
Validation loss: 1.9757282656731365
Epoch: 9| Step: 10
Training loss: 1.3826758861541748
Validation loss: 1.9349155537516094
Epoch: 9| Step: 11
Training loss: 1.79766845703125
Validation loss: 1.9881780078942828
Epoch: 9| Step: 12
Training loss: 2.5368664264678955
Validation loss: 1.9605660721552458
Epoch: 9| Step: 13
Training loss: 2.36940860748291
Validation loss: 1.9319482407123922
Epoch: 9| Step: 14
Training loss: 2.514430284500122
Validation loss: 1.9692436430951674
Epoch: 9| Step: 15
Training loss: 1.7094963788986206
Validation loss: 1.8904543077345375
Epoch: 9| Step: 16
Training loss: 1.7148064374923706
Validation loss: 1.9105460789563844
Epoch: 9| Step: 17
Training loss: 2.0712890625
Validation loss: 1.9636660634184913
Epoch: 9| Step: 18
Training loss: 1.855072021484375
Validation loss: 1.9375498980926953
Epoch: 9| Step: 19
Training loss: 2.246495246887207
Validation loss: 1.9606454698301905
Epoch: 38| Step: 0
Training loss: 1.641276240348816
Validation loss: 1.967831736845936
Epoch: 9| Step: 1
Training loss: 1.7922049760818481
Validation loss: 1.9706966979898137
Epoch: 9| Step: 2
Training loss: 2.892258405685425
Validation loss: 2.001737474537582
Epoch: 9| Step: 3
Training loss: 2.2030301094055176
Validation loss: 1.9859039946425734
Epoch: 9| Step: 4
Training loss: 1.7627129554748535
Validation loss: 1.967029325396037
Epoch: 9| Step: 5
Training loss: 1.6219719648361206
Validation loss: 1.9718960223438071
Epoch: 9| Step: 6
Training loss: 2.1580424308776855
Validation loss: 1.986615028312738
Epoch: 9| Step: 7
Training loss: 2.1778664588928223
Validation loss: 1.9958710550404282
Epoch: 9| Step: 8
Training loss: 2.064976215362549
Validation loss: 2.0124396986240964
Epoch: 9| Step: 9
Training loss: 1.9845225811004639
Validation loss: 1.9631035173539635
Epoch: 9| Step: 10
Training loss: 1.982205867767334
Validation loss: 1.9702701774432505
Epoch: 9| Step: 11
Training loss: 1.9625829458236694
Validation loss: 2.00622964505669
Epoch: 9| Step: 12
Training loss: 2.3961243629455566
Validation loss: 2.0138381994027887
Epoch: 9| Step: 13
Training loss: 2.4178860187530518
Validation loss: 1.9498919591629247
Epoch: 9| Step: 14
Training loss: 1.918550729751587
Validation loss: 1.976179206971642
Epoch: 9| Step: 15
Training loss: 2.5871737003326416
Validation loss: 1.9885302996463914
Epoch: 9| Step: 16
Training loss: 3.2134957313537598
Validation loss: 1.9544651697007873
Epoch: 9| Step: 17
Training loss: 2.7349629402160645
Validation loss: 1.9399446137517475
Epoch: 9| Step: 18
Training loss: 2.243962049484253
Validation loss: 1.963285993329055
Epoch: 9| Step: 19
Training loss: 1.8641996383666992
Validation loss: 1.9868120649735705
Epoch: 39| Step: 0
Training loss: 1.7645190954208374
Validation loss: 1.9517419166702161
Epoch: 9| Step: 1
Training loss: 2.042612075805664
Validation loss: 1.9601302627179262
Epoch: 9| Step: 2
Training loss: 2.3160247802734375
Validation loss: 1.9607662211219183
Epoch: 9| Step: 3
Training loss: 1.8353575468063354
Validation loss: 1.955831935937456
Epoch: 9| Step: 4
Training loss: 1.3922039270401
Validation loss: 1.9617255797489084
Epoch: 9| Step: 5
Training loss: 1.5412073135375977
Validation loss: 1.9441277414774722
Epoch: 9| Step: 6
Training loss: 2.1128344535827637
Validation loss: 1.9918048793463399
Epoch: 9| Step: 7
Training loss: 2.0338921546936035
Validation loss: 1.9390825890808654
Epoch: 9| Step: 8
Training loss: 2.9205312728881836
Validation loss: 1.991831749463253
Epoch: 9| Step: 9
Training loss: 2.045923948287964
Validation loss: 1.985002915636241
Epoch: 9| Step: 10
Training loss: 1.657186508178711
Validation loss: 1.9618402024824841
Epoch: 9| Step: 11
Training loss: 2.177084445953369
Validation loss: 1.9441970509590862
Epoch: 9| Step: 12
Training loss: 2.1705658435821533
Validation loss: 1.9265669318411847
Epoch: 9| Step: 13
Training loss: 2.1505448818206787
Validation loss: 1.9716452660320474
Epoch: 9| Step: 14
Training loss: 2.5184755325317383
Validation loss: 2.0218881274298797
Epoch: 9| Step: 15
Training loss: 2.079044818878174
Validation loss: 1.9921699350686382
Epoch: 9| Step: 16
Training loss: 2.5928406715393066
Validation loss: 1.995878843952426
Epoch: 9| Step: 17
Training loss: 2.283818483352661
Validation loss: 2.036734420618565
Epoch: 9| Step: 18
Training loss: 2.4270052909851074
Validation loss: 2.021649729433677
Epoch: 9| Step: 19
Training loss: 2.57710599899292
Validation loss: 2.0598719763241227
Epoch: 40| Step: 0
Training loss: 2.0918080806732178
Validation loss: 2.007663462659438
Epoch: 9| Step: 1
Training loss: 2.6163296699523926
Validation loss: 1.9950177652372731
Epoch: 9| Step: 2
Training loss: 1.4367914199829102
Validation loss: 1.9960170100918777
Epoch: 9| Step: 3
Training loss: 2.086376905441284
Validation loss: 1.9953167387049833
Epoch: 9| Step: 4
Training loss: 1.7288404703140259
Validation loss: 2.0004656829422327
Epoch: 9| Step: 5
Training loss: 1.1821775436401367
Validation loss: 1.9270845857455576
Epoch: 9| Step: 6
Training loss: 2.3996734619140625
Validation loss: 1.9780693225723376
Epoch: 9| Step: 7
Training loss: 1.8031421899795532
Validation loss: 1.9785603413478934
Epoch: 9| Step: 8
Training loss: 2.598907947540283
Validation loss: 1.9891200331475238
Epoch: 9| Step: 9
Training loss: 2.327535629272461
Validation loss: 2.021238963380992
Epoch: 9| Step: 10
Training loss: 1.7001657485961914
Validation loss: 2.02734102962686
Epoch: 9| Step: 11
Training loss: 2.834336280822754
Validation loss: 1.9474553418674057
Epoch: 9| Step: 12
Training loss: 2.8596410751342773
Validation loss: 1.9942653616555304
Epoch: 9| Step: 13
Training loss: 2.9885191917419434
Validation loss: 1.9594084667644913
Epoch: 9| Step: 14
Training loss: 1.9327683448791504
Validation loss: 1.9611376138042202
Epoch: 9| Step: 15
Training loss: 2.354362964630127
Validation loss: 1.937550267727255
Epoch: 9| Step: 16
Training loss: 2.4375832080841064
Validation loss: 1.9978394293956618
Epoch: 9| Step: 17
Training loss: 1.5150192975997925
Validation loss: 1.9689207411498475
Epoch: 9| Step: 18
Training loss: 1.7393583059310913
Validation loss: 1.9708204303714012
Epoch: 9| Step: 19
Training loss: 2.189100742340088
Validation loss: 1.9781177318353447
Epoch: 41| Step: 0
Training loss: 1.992240309715271
Validation loss: 1.9655329357805869
Epoch: 9| Step: 1
Training loss: 2.311288833618164
Validation loss: 1.9805156670028357
Epoch: 9| Step: 2
Training loss: 2.651927947998047
Validation loss: 1.9486821538252797
Epoch: 9| Step: 3
Training loss: 1.8123868703842163
Validation loss: 1.9582638294576742
Epoch: 9| Step: 4
Training loss: 2.199215888977051
Validation loss: 1.9965493781961126
Epoch: 9| Step: 5
Training loss: 2.3171136379241943
Validation loss: 2.010357558298454
Epoch: 9| Step: 6
Training loss: 1.9589035511016846
Validation loss: 2.024920158249011
Epoch: 9| Step: 7
Training loss: 2.435403823852539
Validation loss: 1.9847212849761084
Epoch: 9| Step: 8
Training loss: 2.4333720207214355
Validation loss: 2.010291118415997
Epoch: 9| Step: 9
Training loss: 1.686455488204956
Validation loss: 1.9130806219663552
Epoch: 9| Step: 10
Training loss: 1.8420435190200806
Validation loss: 1.9825956598460246
Epoch: 9| Step: 11
Training loss: 1.9076652526855469
Validation loss: 1.9601769498783908
Epoch: 9| Step: 12
Training loss: 1.7365213632583618
Validation loss: 1.991031207626672
Epoch: 9| Step: 13
Training loss: 1.741243839263916
Validation loss: 1.9769921328524034
Epoch: 9| Step: 14
Training loss: 1.914446473121643
Validation loss: 1.9758590108199086
Epoch: 9| Step: 15
Training loss: 1.599654197692871
Validation loss: 1.9965004020457646
Epoch: 9| Step: 16
Training loss: 2.4932713508605957
Validation loss: 1.9469682707203377
Epoch: 9| Step: 17
Training loss: 2.0570318698883057
Validation loss: 2.007088853300904
Epoch: 9| Step: 18
Training loss: 2.961092472076416
Validation loss: 1.9552144746986224
Epoch: 9| Step: 19
Training loss: 2.6432926654815674
Validation loss: 1.993448128803171
Epoch: 42| Step: 0
Training loss: 1.612632393836975
Validation loss: 1.9360610855569085
Epoch: 9| Step: 1
Training loss: 1.6052768230438232
Validation loss: 2.0009890151538436
Epoch: 9| Step: 2
Training loss: 2.1962127685546875
Validation loss: 1.9813012999596356
Epoch: 9| Step: 3
Training loss: 2.8328046798706055
Validation loss: 2.0238436160327717
Epoch: 9| Step: 4
Training loss: 2.055527687072754
Validation loss: 2.0072207879677095
Epoch: 9| Step: 5
Training loss: 2.4526424407958984
Validation loss: 2.0127741570095363
Epoch: 9| Step: 6
Training loss: 2.659836530685425
Validation loss: 2.0248388575135374
Epoch: 9| Step: 7
Training loss: 2.1580584049224854
Validation loss: 2.018511892222672
Epoch: 9| Step: 8
Training loss: 2.08455491065979
Validation loss: 1.9861773055234402
Epoch: 9| Step: 9
Training loss: 2.5001633167266846
Validation loss: 2.006221577417936
Epoch: 9| Step: 10
Training loss: 2.2628636360168457
Validation loss: 1.9641394580868508
Epoch: 9| Step: 11
Training loss: 2.239903450012207
Validation loss: 1.9776507410214101
Epoch: 9| Step: 12
Training loss: 2.0961365699768066
Validation loss: 1.9251650794804525
Epoch: 9| Step: 13
Training loss: 2.4293527603149414
Validation loss: 1.95003978125483
Epoch: 9| Step: 14
Training loss: 2.1772356033325195
Validation loss: 1.9489765698961217
Epoch: 9| Step: 15
Training loss: 2.4409193992614746
Validation loss: 1.986827368358914
Epoch: 9| Step: 16
Training loss: 1.8562090396881104
Validation loss: 1.9308165363270602
Epoch: 9| Step: 17
Training loss: 2.012573480606079
Validation loss: 1.9546846571586114
Epoch: 9| Step: 18
Training loss: 1.968434453010559
Validation loss: 1.952633262538224
Epoch: 9| Step: 19
Training loss: 1.4855327606201172
Validation loss: 1.9686608734748345
Epoch: 43| Step: 0
Training loss: 2.800814628601074
Validation loss: 1.9390390399548647
Epoch: 9| Step: 1
Training loss: 2.0438218116760254
Validation loss: 1.9355304395552162
Epoch: 9| Step: 2
Training loss: 2.0656471252441406
Validation loss: 2.026976166011618
Epoch: 9| Step: 3
Training loss: 2.4208450317382812
Validation loss: 2.0228715551842886
Epoch: 9| Step: 4
Training loss: 1.6186736822128296
Validation loss: 2.0155816644215756
Epoch: 9| Step: 5
Training loss: 2.170182704925537
Validation loss: 2.004253572697262
Epoch: 9| Step: 6
Training loss: 2.2044506072998047
Validation loss: 2.041775953855446
Epoch: 9| Step: 7
Training loss: 1.613039255142212
Validation loss: 2.0028786959408
Epoch: 9| Step: 8
Training loss: 1.8053841590881348
Validation loss: 2.0016023323690293
Epoch: 9| Step: 9
Training loss: 1.1953927278518677
Validation loss: 1.9865130649196159
Epoch: 9| Step: 10
Training loss: 2.4747414588928223
Validation loss: 2.04217934093887
Epoch: 9| Step: 11
Training loss: 1.609177589416504
Validation loss: 1.9499916095527814
Epoch: 9| Step: 12
Training loss: 1.7528722286224365
Validation loss: 2.004007140509516
Epoch: 9| Step: 13
Training loss: 2.5125012397766113
Validation loss: 2.069020885357754
Epoch: 9| Step: 14
Training loss: 1.5766929388046265
Validation loss: 1.9885902816443135
Epoch: 9| Step: 15
Training loss: 2.518627643585205
Validation loss: 2.0314882007434214
Epoch: 9| Step: 16
Training loss: 1.948230504989624
Validation loss: 1.9957609210940574
Epoch: 9| Step: 17
Training loss: 2.454820394515991
Validation loss: 1.952253737037988
Epoch: 9| Step: 18
Training loss: 2.291975975036621
Validation loss: 1.9733506526878413
Epoch: 9| Step: 19
Training loss: 3.09478759765625
Validation loss: 1.9908817800686514
Epoch: 44| Step: 0
Training loss: 1.8750641345977783
Validation loss: 1.9422722651804094
Epoch: 9| Step: 1
Training loss: 2.1539993286132812
Validation loss: 1.9838282247241452
Epoch: 9| Step: 2
Training loss: 1.5912468433380127
Validation loss: 1.9431896312631292
Epoch: 9| Step: 3
Training loss: 2.4519898891448975
Validation loss: 2.0119174555908863
Epoch: 9| Step: 4
Training loss: 2.8288588523864746
Validation loss: 1.9941145957802697
Epoch: 9| Step: 5
Training loss: 2.206087350845337
Validation loss: 1.9438116944951118
Epoch: 9| Step: 6
Training loss: 1.6865185499191284
Validation loss: 1.9608799141945599
Epoch: 9| Step: 7
Training loss: 1.3279333114624023
Validation loss: 1.9537029249205007
Epoch: 9| Step: 8
Training loss: 1.3092362880706787
Validation loss: 2.0196977090492525
Epoch: 9| Step: 9
Training loss: 2.407270669937134
Validation loss: 1.9567755383553265
Epoch: 9| Step: 10
Training loss: 2.441316604614258
Validation loss: 2.026218052390668
Epoch: 9| Step: 11
Training loss: 2.707808494567871
Validation loss: 2.010644271219377
Epoch: 9| Step: 12
Training loss: 2.088775634765625
Validation loss: 1.97398283155702
Epoch: 9| Step: 13
Training loss: 1.9015095233917236
Validation loss: 2.040724784350224
Epoch: 9| Step: 14
Training loss: 2.65269136428833
Validation loss: 1.995784914750847
Epoch: 9| Step: 15
Training loss: 2.611392021179199
Validation loss: 1.9971412223020046
Epoch: 9| Step: 16
Training loss: 2.6165037155151367
Validation loss: 2.010772680207122
Epoch: 9| Step: 17
Training loss: 1.8491883277893066
Validation loss: 2.0043870973930082
Epoch: 9| Step: 18
Training loss: 2.0439770221710205
Validation loss: 2.0505876009412805
Epoch: 9| Step: 19
Training loss: 1.3943099975585938
Validation loss: 2.0750367152605125
Epoch: 45| Step: 0
Training loss: 2.317535400390625
Validation loss: 2.018536293249336
Epoch: 9| Step: 1
Training loss: 2.3885090351104736
Validation loss: 1.9981754718066977
Epoch: 9| Step: 2
Training loss: 2.3912808895111084
Validation loss: 2.0323416800807705
Epoch: 9| Step: 3
Training loss: 2.295686960220337
Validation loss: 1.9862475232254686
Epoch: 9| Step: 4
Training loss: 1.4868950843811035
Validation loss: 2.060566126871452
Epoch: 9| Step: 5
Training loss: 2.218172311782837
Validation loss: 2.06647995135767
Epoch: 9| Step: 6
Training loss: 1.1901676654815674
Validation loss: 2.1270983141960857
Epoch: 9| Step: 7
Training loss: 2.8991498947143555
Validation loss: 2.0396157889057407
Epoch: 9| Step: 8
Training loss: 3.0208301544189453
Validation loss: 2.089336751176299
Epoch: 9| Step: 9
Training loss: 1.9328044652938843
Validation loss: 2.066108020089513
Epoch: 9| Step: 10
Training loss: 2.6466338634490967
Validation loss: 2.0715226681112386
Epoch: 9| Step: 11
Training loss: 2.176516056060791
Validation loss: 2.1125191818895956
Epoch: 9| Step: 12
Training loss: 1.950927495956421
Validation loss: 2.0664547827604007
Epoch: 9| Step: 13
Training loss: 1.459268569946289
Validation loss: 2.089507874825018
Epoch: 9| Step: 14
Training loss: 1.7290029525756836
Validation loss: 2.036736752489488
Epoch: 9| Step: 15
Training loss: 2.6396515369415283
Validation loss: 2.0476945973128724
Epoch: 9| Step: 16
Training loss: 2.069761276245117
Validation loss: 2.0291021796439193
Epoch: 9| Step: 17
Training loss: 1.9060416221618652
Validation loss: 1.993315147839004
Epoch: 9| Step: 18
Training loss: 1.699460744857788
Validation loss: 2.02671703246
Epoch: 9| Step: 19
Training loss: 2.3312835693359375
Validation loss: 2.0397076486683576
Epoch: 46| Step: 0
Training loss: 2.418506145477295
Validation loss: 2.040449715346741
Epoch: 9| Step: 1
Training loss: 2.1910948753356934
Validation loss: 1.9557793903693879
Epoch: 9| Step: 2
Training loss: 2.8193581104278564
Validation loss: 1.9787769746437347
Epoch: 9| Step: 3
Training loss: 1.6468671560287476
Validation loss: 1.9486760630024422
Epoch: 9| Step: 4
Training loss: 1.8618559837341309
Validation loss: 1.9687693719383623
Epoch: 9| Step: 5
Training loss: 2.368889093399048
Validation loss: 1.9391053546246866
Epoch: 9| Step: 6
Training loss: 1.7048596143722534
Validation loss: 1.9198772649970843
Epoch: 9| Step: 7
Training loss: 2.1015372276306152
Validation loss: 1.9340404083402893
Epoch: 9| Step: 8
Training loss: 1.6679458618164062
Validation loss: 1.9157473414921933
Epoch: 9| Step: 9
Training loss: 2.040926456451416
Validation loss: 1.9545885255868487
Epoch: 9| Step: 10
Training loss: 2.165809154510498
Validation loss: 1.9530186927575859
Epoch: 9| Step: 11
Training loss: 1.5095490217208862
Validation loss: 1.9646574644733676
Epoch: 9| Step: 12
Training loss: 2.8263444900512695
Validation loss: 1.897332584257606
Epoch: 9| Step: 13
Training loss: 2.480557680130005
Validation loss: 1.93706717165254
Epoch: 9| Step: 14
Training loss: 1.790421724319458
Validation loss: 1.9394411903491122
Epoch: 9| Step: 15
Training loss: 2.3046648502349854
Validation loss: 1.8946940084155515
Epoch: 9| Step: 16
Training loss: 2.4215221405029297
Validation loss: 1.9553182639664026
Epoch: 9| Step: 17
Training loss: 1.5712366104125977
Validation loss: 1.9947095388988796
Epoch: 9| Step: 18
Training loss: 1.9667519330978394
Validation loss: 1.9432666696232856
Epoch: 9| Step: 19
Training loss: 2.4733927249908447
Validation loss: 1.899212113387293
Epoch: 47| Step: 0
Training loss: 2.3004579544067383
Validation loss: 1.932655801018365
Epoch: 9| Step: 1
Training loss: 2.178485870361328
Validation loss: 1.9333325941785633
Epoch: 9| Step: 2
Training loss: 2.8043010234832764
Validation loss: 1.9505371575732884
Epoch: 9| Step: 3
Training loss: 1.8941898345947266
Validation loss: 1.947407113562385
Epoch: 9| Step: 4
Training loss: 1.2438819408416748
Validation loss: 2.0078556571933004
Epoch: 9| Step: 5
Training loss: 1.6139767169952393
Validation loss: 1.9615351622053188
Epoch: 9| Step: 6
Training loss: 2.18319034576416
Validation loss: 1.9607834807402795
Epoch: 9| Step: 7
Training loss: 2.562535047531128
Validation loss: 1.9891990088730407
Epoch: 9| Step: 8
Training loss: 2.124995708465576
Validation loss: 1.9971430087261062
Epoch: 9| Step: 9
Training loss: 2.386746406555176
Validation loss: 1.9645088276417135
Epoch: 9| Step: 10
Training loss: 2.5042471885681152
Validation loss: 2.002296470052047
Epoch: 9| Step: 11
Training loss: 2.0654497146606445
Validation loss: 2.028929254991545
Epoch: 9| Step: 12
Training loss: 1.4283474683761597
Validation loss: 1.9783349551742884
Epoch: 9| Step: 13
Training loss: 2.0562572479248047
Validation loss: 2.013562523203788
Epoch: 9| Step: 14
Training loss: 2.1810388565063477
Validation loss: 2.04948669286083
Epoch: 9| Step: 15
Training loss: 1.7736120223999023
Validation loss: 2.045239975984148
Epoch: 9| Step: 16
Training loss: 2.4439682960510254
Validation loss: 2.0399358281128697
Epoch: 9| Step: 17
Training loss: 1.9608131647109985
Validation loss: 2.004603973395533
Epoch: 9| Step: 18
Training loss: 1.9257769584655762
Validation loss: 2.0444594956130433
Epoch: 9| Step: 19
Training loss: 2.331986904144287
Validation loss: 2.0452746573111993
Epoch: 48| Step: 0
Training loss: 2.3691399097442627
Validation loss: 2.017796756552278
Epoch: 9| Step: 1
Training loss: 1.8353073596954346
Validation loss: 1.9921494953923946
Epoch: 9| Step: 2
Training loss: 2.2818055152893066
Validation loss: 1.9681203176649353
Epoch: 9| Step: 3
Training loss: 1.8561738729476929
Validation loss: 1.9640963206188284
Epoch: 9| Step: 4
Training loss: 2.1620168685913086
Validation loss: 1.959772573100577
Epoch: 9| Step: 5
Training loss: 1.8802613019943237
Validation loss: 1.941362398133861
Epoch: 9| Step: 6
Training loss: 1.94781494140625
Validation loss: 1.956097077980316
Epoch: 9| Step: 7
Training loss: 1.9963030815124512
Validation loss: 1.9055343334623378
Epoch: 9| Step: 8
Training loss: 2.0953125953674316
Validation loss: 1.961736426079016
Epoch: 9| Step: 9
Training loss: 2.56597638130188
Validation loss: 1.9098724941555545
Epoch: 9| Step: 10
Training loss: 1.8532148599624634
Validation loss: 1.9382946199650386
Epoch: 9| Step: 11
Training loss: 2.3162739276885986
Validation loss: 1.955746172143401
Epoch: 9| Step: 12
Training loss: 2.124709129333496
Validation loss: 1.960844991876067
Epoch: 9| Step: 13
Training loss: 1.7521392107009888
Validation loss: 1.938050890998017
Epoch: 9| Step: 14
Training loss: 1.9644477367401123
Validation loss: 1.9105089456914999
Epoch: 9| Step: 15
Training loss: 2.609189748764038
Validation loss: 1.9250422115806196
Epoch: 9| Step: 16
Training loss: 1.8616106510162354
Validation loss: 1.923949932022918
Epoch: 9| Step: 17
Training loss: 1.874987006187439
Validation loss: 1.961634412943888
Epoch: 9| Step: 18
Training loss: 2.880141496658325
Validation loss: 1.968302898269763
Epoch: 9| Step: 19
Training loss: 1.908041000366211
Validation loss: 1.9435721935985757
Epoch: 49| Step: 0
Training loss: 1.740734338760376
Validation loss: 1.9760119477621942
Epoch: 9| Step: 1
Training loss: 2.5905299186706543
Validation loss: 1.9606338216246462
Epoch: 9| Step: 2
Training loss: 2.6165249347686768
Validation loss: 1.982867227183829
Epoch: 9| Step: 3
Training loss: 2.2964329719543457
Validation loss: 1.9640618099583138
Epoch: 9| Step: 4
Training loss: 2.8055057525634766
Validation loss: 1.9794219972418368
Epoch: 9| Step: 5
Training loss: 2.580172300338745
Validation loss: 1.9624648951798034
Epoch: 9| Step: 6
Training loss: 2.276688575744629
Validation loss: 1.9801883525985609
Epoch: 9| Step: 7
Training loss: 2.487893581390381
Validation loss: 1.9813347789023419
Epoch: 9| Step: 8
Training loss: 1.9307622909545898
Validation loss: 1.9467649279738501
Epoch: 9| Step: 9
Training loss: 2.178947687149048
Validation loss: 1.9144229846034977
Epoch: 9| Step: 10
Training loss: 2.0942070484161377
Validation loss: 1.9879518652991426
Epoch: 9| Step: 11
Training loss: 1.3183647394180298
Validation loss: 1.991741094657843
Epoch: 9| Step: 12
Training loss: 1.771881103515625
Validation loss: 1.9397454656285347
Epoch: 9| Step: 13
Training loss: 2.4559531211853027
Validation loss: 1.9736971855163574
Epoch: 9| Step: 14
Training loss: 1.2434797286987305
Validation loss: 1.95309498841814
Epoch: 9| Step: 15
Training loss: 2.2046525478363037
Validation loss: 2.0162649394796905
Epoch: 9| Step: 16
Training loss: 1.7905757427215576
Validation loss: 1.9835142111606736
Epoch: 9| Step: 17
Training loss: 2.889798164367676
Validation loss: 1.9724452727132564
Epoch: 9| Step: 18
Training loss: 1.4835965633392334
Validation loss: 2.0336417157015356
Epoch: 9| Step: 19
Training loss: 1.860432744026184
Validation loss: 2.0145899692027687
Epoch: 50| Step: 0
Training loss: 2.4946517944335938
Validation loss: 1.9788997773643877
Epoch: 9| Step: 1
Training loss: 1.94321608543396
Validation loss: 2.0054883776808814
Epoch: 9| Step: 2
Training loss: 1.5438649654388428
Validation loss: 1.9373598990680503
Epoch: 9| Step: 3
Training loss: 2.13411283493042
Validation loss: 1.9712049875328008
Epoch: 9| Step: 4
Training loss: 2.413395404815674
Validation loss: 2.0089855931645673
Epoch: 9| Step: 5
Training loss: 1.5750460624694824
Validation loss: 2.0693283038173647
Epoch: 9| Step: 6
Training loss: 3.126058340072632
Validation loss: 2.0255688900570217
Epoch: 9| Step: 7
Training loss: 2.3717994689941406
Validation loss: 2.050037486947698
Epoch: 9| Step: 8
Training loss: 2.0171377658843994
Validation loss: 2.018646562699791
Epoch: 9| Step: 9
Training loss: 2.1024553775787354
Validation loss: 1.9594674796509228
Epoch: 9| Step: 10
Training loss: 1.9176928997039795
Validation loss: 1.9420266837524853
Epoch: 9| Step: 11
Training loss: 1.902256965637207
Validation loss: 1.9666112121060597
Epoch: 9| Step: 12
Training loss: 2.3714420795440674
Validation loss: 1.8910378200544729
Epoch: 9| Step: 13
Training loss: 2.2320780754089355
Validation loss: 1.963789433884106
Epoch: 9| Step: 14
Training loss: 2.0782217979431152
Validation loss: 1.9625796877222954
Epoch: 9| Step: 15
Training loss: 1.7001676559448242
Validation loss: 1.9392874643957014
Epoch: 9| Step: 16
Training loss: 1.5438122749328613
Validation loss: 1.9593708901096591
Epoch: 9| Step: 17
Training loss: 2.2093148231506348
Validation loss: 1.9319788654931158
Epoch: 9| Step: 18
Training loss: 2.029381036758423
Validation loss: 1.9210606993531152
Epoch: 9| Step: 19
Training loss: 2.373101234436035
Validation loss: 2.0168900352587804
Epoch: 51| Step: 0
Training loss: 2.1359381675720215
Validation loss: 1.9991112973192613
Epoch: 9| Step: 1
Training loss: 2.0538077354431152
Validation loss: 1.962479339229117
Epoch: 9| Step: 2
Training loss: 2.3337440490722656
Validation loss: 2.0002855894376905
Epoch: 9| Step: 3
Training loss: 2.28458309173584
Validation loss: 1.9817596613931998
Epoch: 9| Step: 4
Training loss: 1.9545254707336426
Validation loss: 1.9926206808296039
Epoch: 9| Step: 5
Training loss: 2.927285671234131
Validation loss: 1.9508349123618585
Epoch: 9| Step: 6
Training loss: 2.567080020904541
Validation loss: 1.9870963010856573
Epoch: 9| Step: 7
Training loss: 2.410060167312622
Validation loss: 1.9772796459335218
Epoch: 9| Step: 8
Training loss: 1.8919161558151245
Validation loss: 1.9859358921325465
Epoch: 9| Step: 9
Training loss: 1.5673236846923828
Validation loss: 2.0056661427449836
Epoch: 9| Step: 10
Training loss: 2.2213597297668457
Validation loss: 1.9808760118141449
Epoch: 9| Step: 11
Training loss: 1.889035940170288
Validation loss: 1.980148847154576
Epoch: 9| Step: 12
Training loss: 1.814026117324829
Validation loss: 2.0394256132112134
Epoch: 9| Step: 13
Training loss: 2.318713903427124
Validation loss: 2.000656303741949
Epoch: 9| Step: 14
Training loss: 2.338123083114624
Validation loss: 2.043310774316033
Epoch: 9| Step: 15
Training loss: 1.6617287397384644
Validation loss: 2.0250596742835834
Epoch: 9| Step: 16
Training loss: 2.168980598449707
Validation loss: 1.988309213583418
Epoch: 9| Step: 17
Training loss: 1.5636626482009888
Validation loss: 2.005678665723732
Epoch: 9| Step: 18
Training loss: 1.6936842203140259
Validation loss: 1.992105063774603
Epoch: 9| Step: 19
Training loss: 1.983526349067688
Validation loss: 2.0220604431714944
Epoch: 52| Step: 0
Training loss: 1.800633192062378
Validation loss: 1.9617726339710702
Epoch: 9| Step: 1
Training loss: 1.856736183166504
Validation loss: 2.0353836327148
Epoch: 9| Step: 2
Training loss: 2.7598862648010254
Validation loss: 2.032418650688885
Epoch: 9| Step: 3
Training loss: 2.1359310150146484
Validation loss: 2.021821124948186
Epoch: 9| Step: 4
Training loss: 2.316887855529785
Validation loss: 2.046372772120743
Epoch: 9| Step: 5
Training loss: 2.230456590652466
Validation loss: 2.09919146496615
Epoch: 9| Step: 6
Training loss: 2.175323486328125
Validation loss: 2.0753613847622767
Epoch: 9| Step: 7
Training loss: 2.5050692558288574
Validation loss: 2.0805401965010937
Epoch: 9| Step: 8
Training loss: 1.5467536449432373
Validation loss: 2.080460199349218
Epoch: 9| Step: 9
Training loss: 2.421617031097412
Validation loss: 2.0449869358282293
Epoch: 9| Step: 10
Training loss: 2.2956595420837402
Validation loss: 2.0679001550880267
Epoch: 9| Step: 11
Training loss: 2.379992961883545
Validation loss: 2.027221242300898
Epoch: 9| Step: 12
Training loss: 1.621222972869873
Validation loss: 2.0691175512272677
Epoch: 9| Step: 13
Training loss: 2.19777512550354
Validation loss: 2.047047587607404
Epoch: 9| Step: 14
Training loss: 2.2527637481689453
Validation loss: 2.0107948488468748
Epoch: 9| Step: 15
Training loss: 2.2598495483398438
Validation loss: 1.9495070769632463
Epoch: 9| Step: 16
Training loss: 1.9298611879348755
Validation loss: 1.9755413969643683
Epoch: 9| Step: 17
Training loss: 1.2802550792694092
Validation loss: 1.9873290885266641
Epoch: 9| Step: 18
Training loss: 2.322744369506836
Validation loss: 1.9262773621854166
Epoch: 9| Step: 19
Training loss: 2.180359125137329
Validation loss: 1.9763417098161986
Epoch: 53| Step: 0
Training loss: 2.003300905227661
Validation loss: 1.946927098061541
Epoch: 9| Step: 1
Training loss: 1.8674407005310059
Validation loss: 1.9591586409712867
Epoch: 9| Step: 2
Training loss: 1.7033146619796753
Validation loss: 1.90014167483762
Epoch: 9| Step: 3
Training loss: 1.9249558448791504
Validation loss: 1.9330751467094147
Epoch: 9| Step: 4
Training loss: 2.29030704498291
Validation loss: 1.985915257776384
Epoch: 9| Step: 5
Training loss: 2.6707639694213867
Validation loss: 1.977361284571586
Epoch: 9| Step: 6
Training loss: 2.310128688812256
Validation loss: 1.9706891826588473
Epoch: 9| Step: 7
Training loss: 1.6593188047409058
Validation loss: 1.949498690289559
Epoch: 9| Step: 8
Training loss: 2.523770809173584
Validation loss: 1.9659545292957223
Epoch: 9| Step: 9
Training loss: 1.7081961631774902
Validation loss: 1.9492673582310298
Epoch: 9| Step: 10
Training loss: 2.532024383544922
Validation loss: 1.9439257460532429
Epoch: 9| Step: 11
Training loss: 1.508946418762207
Validation loss: 1.9648067813983066
Epoch: 9| Step: 12
Training loss: 2.269444465637207
Validation loss: 1.975984106818549
Epoch: 9| Step: 13
Training loss: 2.392080545425415
Validation loss: 1.9619958692317387
Epoch: 9| Step: 14
Training loss: 2.2003164291381836
Validation loss: 1.966327181822962
Epoch: 9| Step: 15
Training loss: 2.373469352722168
Validation loss: 1.9780719837696432
Epoch: 9| Step: 16
Training loss: 2.386134147644043
Validation loss: 1.9753783040767094
Epoch: 9| Step: 17
Training loss: 1.402843952178955
Validation loss: 1.9633916307696335
Epoch: 9| Step: 18
Training loss: 1.7636340856552124
Validation loss: 2.021785283260208
Epoch: 9| Step: 19
Training loss: 2.240108013153076
Validation loss: 1.9956100655974245
Epoch: 54| Step: 0
Training loss: 2.2060937881469727
Validation loss: 2.002083512518903
Epoch: 9| Step: 1
Training loss: 2.200160026550293
Validation loss: 2.0280643461419525
Epoch: 9| Step: 2
Training loss: 1.3989801406860352
Validation loss: 1.9888403389951308
Epoch: 9| Step: 3
Training loss: 2.273998737335205
Validation loss: 2.040338713488133
Epoch: 9| Step: 4
Training loss: 2.4504785537719727
Validation loss: 2.0146066533575815
Epoch: 9| Step: 5
Training loss: 2.0219573974609375
Validation loss: 1.9696946058341924
Epoch: 9| Step: 6
Training loss: 2.051032781600952
Validation loss: 1.9290104684212226
Epoch: 9| Step: 7
Training loss: 1.6331465244293213
Validation loss: 1.9852492637771497
Epoch: 9| Step: 8
Training loss: 2.1522164344787598
Validation loss: 1.9854771027462088
Epoch: 9| Step: 9
Training loss: 1.9708609580993652
Validation loss: 1.9637509352869267
Epoch: 9| Step: 10
Training loss: 2.162569046020508
Validation loss: 1.9377081076875866
Epoch: 9| Step: 11
Training loss: 2.3725156784057617
Validation loss: 1.9654181419516639
Epoch: 9| Step: 12
Training loss: 1.7612065076828003
Validation loss: 1.9844749754281352
Epoch: 9| Step: 13
Training loss: 2.7559895515441895
Validation loss: 1.9603060895590474
Epoch: 9| Step: 14
Training loss: 2.160677909851074
Validation loss: 1.9212635318152338
Epoch: 9| Step: 15
Training loss: 1.6754488945007324
Validation loss: 1.9726905831330115
Epoch: 9| Step: 16
Training loss: 1.980568289756775
Validation loss: 1.9748106929038067
Epoch: 9| Step: 17
Training loss: 2.315396308898926
Validation loss: 1.9466962419825493
Epoch: 9| Step: 18
Training loss: 1.7457886934280396
Validation loss: 1.9790067449748088
Epoch: 9| Step: 19
Training loss: 2.743849039077759
Validation loss: 1.9451382691911656
Epoch: 55| Step: 0
Training loss: 1.7891931533813477
Validation loss: 1.9592076445655
Epoch: 9| Step: 1
Training loss: 1.9194051027297974
Validation loss: 1.9547679630114878
Epoch: 9| Step: 2
Training loss: 1.4642213582992554
Validation loss: 1.968663798819343
Epoch: 9| Step: 3
Training loss: 2.2539474964141846
Validation loss: 1.961013625851638
Epoch: 9| Step: 4
Training loss: 2.4894111156463623
Validation loss: 1.9595845140141548
Epoch: 9| Step: 5
Training loss: 1.934572458267212
Validation loss: 1.9615001386875728
Epoch: 9| Step: 6
Training loss: 2.080052375793457
Validation loss: 1.9252910571132633
Epoch: 9| Step: 7
Training loss: 1.6354739665985107
Validation loss: 1.9986127074673878
Epoch: 9| Step: 8
Training loss: 2.012782573699951
Validation loss: 1.9637628064738761
Epoch: 9| Step: 9
Training loss: 2.763868570327759
Validation loss: 1.978383196343621
Epoch: 9| Step: 10
Training loss: 2.0855441093444824
Validation loss: 1.977661040189455
Epoch: 9| Step: 11
Training loss: 2.183192253112793
Validation loss: 2.0000588276403413
Epoch: 9| Step: 12
Training loss: 2.2005510330200195
Validation loss: 2.040062683091747
Epoch: 9| Step: 13
Training loss: 2.1599323749542236
Validation loss: 1.940463030081001
Epoch: 9| Step: 14
Training loss: 2.370115041732788
Validation loss: 1.982103818612133
Epoch: 9| Step: 15
Training loss: 2.0179991722106934
Validation loss: 1.960366470350636
Epoch: 9| Step: 16
Training loss: 2.1049644947052
Validation loss: 1.9920053533512911
Epoch: 9| Step: 17
Training loss: 1.9040069580078125
Validation loss: 1.9592710081621898
Epoch: 9| Step: 18
Training loss: 2.9540233612060547
Validation loss: 1.9751047813635079
Epoch: 9| Step: 19
Training loss: 1.1500146389007568
Validation loss: 1.9632816709202827
Epoch: 56| Step: 0
Training loss: 1.336372971534729
Validation loss: 1.9572286914578445
Epoch: 9| Step: 1
Training loss: 2.3013815879821777
Validation loss: 2.009811581467553
Epoch: 9| Step: 2
Training loss: 2.1982555389404297
Validation loss: 1.9938105061757478
Epoch: 9| Step: 3
Training loss: 2.4663186073303223
Validation loss: 1.9828012401251485
Epoch: 9| Step: 4
Training loss: 1.9734699726104736
Validation loss: 2.010644722327912
Epoch: 9| Step: 5
Training loss: 1.4237632751464844
Validation loss: 2.032810962457451
Epoch: 9| Step: 6
Training loss: 2.9305689334869385
Validation loss: 2.0071887558312724
Epoch: 9| Step: 7
Training loss: 1.9400070905685425
Validation loss: 1.994412555111398
Epoch: 9| Step: 8
Training loss: 2.1756606101989746
Validation loss: 2.017817926063812
Epoch: 9| Step: 9
Training loss: 2.6307029724121094
Validation loss: 2.0437270488670403
Epoch: 9| Step: 10
Training loss: 2.1215152740478516
Validation loss: 2.0398014037729166
Epoch: 9| Step: 11
Training loss: 2.371683120727539
Validation loss: 1.9967787514487616
Epoch: 9| Step: 12
Training loss: 2.291311025619507
Validation loss: 2.0333239843519473
Epoch: 9| Step: 13
Training loss: 2.514288902282715
Validation loss: 2.063824238537027
Epoch: 9| Step: 14
Training loss: 1.9386658668518066
Validation loss: 2.028346770101314
Epoch: 9| Step: 15
Training loss: 2.0382604598999023
Validation loss: 2.0551638294466965
Epoch: 9| Step: 16
Training loss: 1.8907932043075562
Validation loss: 1.9835847727686382
Epoch: 9| Step: 17
Training loss: 1.9132872819900513
Validation loss: 1.9925280354863448
Epoch: 9| Step: 18
Training loss: 1.5867300033569336
Validation loss: 1.999658870182449
Epoch: 9| Step: 19
Training loss: 1.8434042930603027
Validation loss: 1.9805205374312915
Epoch: 57| Step: 0
Training loss: 2.2209529876708984
Validation loss: 1.9793465772121073
Epoch: 9| Step: 1
Training loss: 2.125326156616211
Validation loss: 1.9932120609626496
Epoch: 9| Step: 2
Training loss: 2.1781179904937744
Validation loss: 1.9838209992690052
Epoch: 9| Step: 3
Training loss: 1.9398908615112305
Validation loss: 1.9851994102807353
Epoch: 9| Step: 4
Training loss: 2.54597544670105
Validation loss: 1.9760864569986467
Epoch: 9| Step: 5
Training loss: 2.1366357803344727
Validation loss: 1.9716113334079441
Epoch: 9| Step: 6
Training loss: 2.550281524658203
Validation loss: 1.9304922330293723
Epoch: 9| Step: 7
Training loss: 1.509107232093811
Validation loss: 1.935757673043999
Epoch: 9| Step: 8
Training loss: 2.196363925933838
Validation loss: 1.9312557625255997
Epoch: 9| Step: 9
Training loss: 2.0843234062194824
Validation loss: 1.9336244185193836
Epoch: 9| Step: 10
Training loss: 1.6171599626541138
Validation loss: 1.9682613122377464
Epoch: 9| Step: 11
Training loss: 1.880403757095337
Validation loss: 1.9508324561359214
Epoch: 9| Step: 12
Training loss: 1.6519429683685303
Validation loss: 1.9176684883858661
Epoch: 9| Step: 13
Training loss: 2.322781801223755
Validation loss: 1.9225322685653357
Epoch: 9| Step: 14
Training loss: 1.5881932973861694
Validation loss: 1.9177570102883756
Epoch: 9| Step: 15
Training loss: 1.9067634344100952
Validation loss: 1.921930728198813
Epoch: 9| Step: 16
Training loss: 2.0496227741241455
Validation loss: 1.8951540782297258
Epoch: 9| Step: 17
Training loss: 2.251262664794922
Validation loss: 1.9610526596041893
Epoch: 9| Step: 18
Training loss: 2.6516919136047363
Validation loss: 1.9099984366259128
Epoch: 9| Step: 19
Training loss: 2.2125442028045654
Validation loss: 1.9536003243151328
Epoch: 58| Step: 0
Training loss: 2.0579421520233154
Validation loss: 1.9605616339676672
Epoch: 9| Step: 1
Training loss: 1.5223643779754639
Validation loss: 1.9464729621255998
Epoch: 9| Step: 2
Training loss: 2.433389186859131
Validation loss: 1.9792099968134929
Epoch: 9| Step: 3
Training loss: 2.0111777782440186
Validation loss: 1.9814344181431283
Epoch: 9| Step: 4
Training loss: 2.1792078018188477
Validation loss: 2.0281546321704234
Epoch: 9| Step: 5
Training loss: 2.6547884941101074
Validation loss: 2.051254395958331
Epoch: 9| Step: 6
Training loss: 2.4085769653320312
Validation loss: 2.047468013900647
Epoch: 9| Step: 7
Training loss: 1.8284765481948853
Validation loss: 2.017676730807737
Epoch: 9| Step: 8
Training loss: 2.723886251449585
Validation loss: 1.9775667499295242
Epoch: 9| Step: 9
Training loss: 2.2661619186401367
Validation loss: 2.016632453143168
Epoch: 9| Step: 10
Training loss: 1.6724908351898193
Validation loss: 1.989392824310193
Epoch: 9| Step: 11
Training loss: 1.4690641164779663
Validation loss: 2.0210933462321328
Epoch: 9| Step: 12
Training loss: 2.8510375022888184
Validation loss: 2.041694576791722
Epoch: 9| Step: 13
Training loss: 1.3478646278381348
Validation loss: 1.9957586569751766
Epoch: 9| Step: 14
Training loss: 1.5809502601623535
Validation loss: 2.02993305981588
Epoch: 9| Step: 15
Training loss: 1.7922863960266113
Validation loss: 2.0386153716835187
Epoch: 9| Step: 16
Training loss: 1.9968429803848267
Validation loss: 1.9676150538080888
Epoch: 9| Step: 17
Training loss: 2.164459466934204
Validation loss: 1.931014935747325
Epoch: 9| Step: 18
Training loss: 1.9173929691314697
Validation loss: 2.0102392992527367
Epoch: 9| Step: 19
Training loss: 2.365602731704712
Validation loss: 1.9707126514517146
Epoch: 59| Step: 0
Training loss: 1.380921721458435
Validation loss: 1.976749492206162
Epoch: 9| Step: 1
Training loss: 2.4692976474761963
Validation loss: 1.9805457386181509
Epoch: 9| Step: 2
Training loss: 1.8918306827545166
Validation loss: 1.9862689122879247
Epoch: 9| Step: 3
Training loss: 1.0986881256103516
Validation loss: 1.941762332435992
Epoch: 9| Step: 4
Training loss: 2.379861831665039
Validation loss: 1.9811091337272588
Epoch: 9| Step: 5
Training loss: 2.6245005130767822
Validation loss: 1.954916729343881
Epoch: 9| Step: 6
Training loss: 1.8310120105743408
Validation loss: 1.9716283640415548
Epoch: 9| Step: 7
Training loss: 1.522237777709961
Validation loss: 1.9589418421546332
Epoch: 9| Step: 8
Training loss: 1.8600233793258667
Validation loss: 1.9479956558282427
Epoch: 9| Step: 9
Training loss: 2.4361023902893066
Validation loss: 1.9632508034328762
Epoch: 9| Step: 10
Training loss: 2.066956043243408
Validation loss: 1.9556067487318738
Epoch: 9| Step: 11
Training loss: 1.8338366746902466
Validation loss: 1.9377298372254954
Epoch: 9| Step: 12
Training loss: 2.674142360687256
Validation loss: 1.935457447449938
Epoch: 9| Step: 13
Training loss: 2.2471773624420166
Validation loss: 1.9177077948618277
Epoch: 9| Step: 14
Training loss: 2.1470208168029785
Validation loss: 1.88855374373978
Epoch: 9| Step: 15
Training loss: 1.7908928394317627
Validation loss: 1.9371452794658195
Epoch: 9| Step: 16
Training loss: 2.6477530002593994
Validation loss: 1.901742283388865
Epoch: 9| Step: 17
Training loss: 2.332545518875122
Validation loss: 1.933085872114991
Epoch: 9| Step: 18
Training loss: 1.9266644716262817
Validation loss: 1.9487075376853669
Epoch: 9| Step: 19
Training loss: 2.452347755432129
Validation loss: 1.9354708160427834
Epoch: 60| Step: 0
Training loss: 2.3880999088287354
Validation loss: 1.9511488916204989
Epoch: 9| Step: 1
Training loss: 2.024062156677246
Validation loss: 1.9492903030175956
Epoch: 9| Step: 2
Training loss: 2.194082021713257
Validation loss: 1.930961441650665
Epoch: 9| Step: 3
Training loss: 1.9106545448303223
Validation loss: 2.012751675338196
Epoch: 9| Step: 4
Training loss: 2.12156343460083
Validation loss: 1.9297736179914406
Epoch: 9| Step: 5
Training loss: 2.5376458168029785
Validation loss: 1.9522298548719008
Epoch: 9| Step: 6
Training loss: 2.4760024547576904
Validation loss: 2.0004046203421173
Epoch: 9| Step: 7
Training loss: 1.9018021821975708
Validation loss: 1.9689380247815906
Epoch: 9| Step: 8
Training loss: 1.2171521186828613
Validation loss: 2.006197464551857
Epoch: 9| Step: 9
Training loss: 2.5887162685394287
Validation loss: 1.995457823327977
Epoch: 9| Step: 10
Training loss: 2.524660587310791
Validation loss: 2.039615338654827
Epoch: 9| Step: 11
Training loss: 2.3130900859832764
Validation loss: 2.036035548011176
Epoch: 9| Step: 12
Training loss: 1.758598804473877
Validation loss: 2.0338786154342214
Epoch: 9| Step: 13
Training loss: 2.076333999633789
Validation loss: 1.9433282407925283
Epoch: 9| Step: 14
Training loss: 1.7816201448440552
Validation loss: 2.026491051097568
Epoch: 9| Step: 15
Training loss: 2.128450632095337
Validation loss: 1.9523475547488645
Epoch: 9| Step: 16
Training loss: 1.034967064857483
Validation loss: 1.9077149029258345
Epoch: 9| Step: 17
Training loss: 1.673965573310852
Validation loss: 1.9642636424345936
Epoch: 9| Step: 18
Training loss: 2.4156293869018555
Validation loss: 1.9615107783310706
Epoch: 9| Step: 19
Training loss: 1.897242784500122
Validation loss: 1.9875276277391174
Epoch: 61| Step: 0
Training loss: 1.6099923849105835
Validation loss: 2.016041394617918
Epoch: 9| Step: 1
Training loss: 2.9641261100769043
Validation loss: 1.9397603281967932
Epoch: 9| Step: 2
Training loss: 2.23820161819458
Validation loss: 1.967816442894421
Epoch: 9| Step: 3
Training loss: 1.8921782970428467
Validation loss: 1.9812496274495297
Epoch: 9| Step: 4
Training loss: 1.7049299478530884
Validation loss: 1.9501906298904967
Epoch: 9| Step: 5
Training loss: 2.158935070037842
Validation loss: 1.9492720022475978
Epoch: 9| Step: 6
Training loss: 2.813389778137207
Validation loss: 1.9243827749499314
Epoch: 9| Step: 7
Training loss: 1.850142478942871
Validation loss: 1.947152055424752
Epoch: 9| Step: 8
Training loss: 1.5156716108322144
Validation loss: 1.9057259353802358
Epoch: 9| Step: 9
Training loss: 2.3973278999328613
Validation loss: 1.94598619371867
Epoch: 9| Step: 10
Training loss: 1.758978247642517
Validation loss: 1.9464037229688904
Epoch: 9| Step: 11
Training loss: 2.365845203399658
Validation loss: 1.9433818386613035
Epoch: 9| Step: 12
Training loss: 1.775568962097168
Validation loss: 1.974934037640798
Epoch: 9| Step: 13
Training loss: 2.3183608055114746
Validation loss: 1.9460481105090903
Epoch: 9| Step: 14
Training loss: 2.22294282913208
Validation loss: 1.9515045263784394
Epoch: 9| Step: 15
Training loss: 1.9894475936889648
Validation loss: 1.9707947840793527
Epoch: 9| Step: 16
Training loss: 2.168668746948242
Validation loss: 1.9768287329365024
Epoch: 9| Step: 17
Training loss: 1.7640080451965332
Validation loss: 1.9076752405372455
Epoch: 9| Step: 18
Training loss: 1.7163596153259277
Validation loss: 1.9126994695594843
Epoch: 9| Step: 19
Training loss: 2.0257468223571777
Validation loss: 2.023862101191239
Epoch: 62| Step: 0
Training loss: 1.58800208568573
Validation loss: 1.9560307615952526
Epoch: 9| Step: 1
Training loss: 2.9625840187072754
Validation loss: 1.9157829627716283
Epoch: 9| Step: 2
Training loss: 2.097728729248047
Validation loss: 2.004479205865654
Epoch: 9| Step: 3
Training loss: 1.915231466293335
Validation loss: 1.9908935363344151
Epoch: 9| Step: 4
Training loss: 1.7175743579864502
Validation loss: 1.946357452612129
Epoch: 9| Step: 5
Training loss: 1.7772676944732666
Validation loss: 1.9484965543952777
Epoch: 9| Step: 6
Training loss: 2.2080068588256836
Validation loss: 1.999472745030904
Epoch: 9| Step: 7
Training loss: 1.532246470451355
Validation loss: 1.9748315056450934
Epoch: 9| Step: 8
Training loss: 2.9496002197265625
Validation loss: 1.9404401418974073
Epoch: 9| Step: 9
Training loss: 2.29628849029541
Validation loss: 1.974255299396652
Epoch: 9| Step: 10
Training loss: 2.0228922367095947
Validation loss: 2.0085970249107414
Epoch: 9| Step: 11
Training loss: 1.591578722000122
Validation loss: 2.0128103949183185
Epoch: 9| Step: 12
Training loss: 2.3580760955810547
Validation loss: 1.9880465226207706
Epoch: 9| Step: 13
Training loss: 2.364799976348877
Validation loss: 2.067057257933582
Epoch: 9| Step: 14
Training loss: 3.0112156867980957
Validation loss: 2.011133832039593
Epoch: 9| Step: 15
Training loss: 1.8410496711730957
Validation loss: 2.008121759771443
Epoch: 9| Step: 16
Training loss: 1.6087101697921753
Validation loss: 1.9997545549337812
Epoch: 9| Step: 17
Training loss: 1.6864029169082642
Validation loss: 2.012601776946363
Epoch: 9| Step: 18
Training loss: 2.069519519805908
Validation loss: 2.0542109149823085
Epoch: 9| Step: 19
Training loss: 1.9950520992279053
Validation loss: 2.049365329227859
Epoch: 63| Step: 0
Training loss: 2.651280403137207
Validation loss: 2.007191447045306
Epoch: 9| Step: 1
Training loss: 1.8889135122299194
Validation loss: 1.986271619796753
Epoch: 9| Step: 2
Training loss: 1.9780535697937012
Validation loss: 1.9908842371522093
Epoch: 9| Step: 3
Training loss: 1.7988502979278564
Validation loss: 1.9596025900875065
Epoch: 9| Step: 4
Training loss: 2.4443209171295166
Validation loss: 1.9512702655449188
Epoch: 9| Step: 5
Training loss: 1.9916414022445679
Validation loss: 2.003002904301925
Epoch: 9| Step: 6
Training loss: 2.025649070739746
Validation loss: 1.9794283342018402
Epoch: 9| Step: 7
Training loss: 1.8451924324035645
Validation loss: 1.9654792693021486
Epoch: 9| Step: 8
Training loss: 2.336822032928467
Validation loss: 1.9556469419877307
Epoch: 9| Step: 9
Training loss: 1.7886879444122314
Validation loss: 1.9846410948595554
Epoch: 9| Step: 10
Training loss: 1.508602499961853
Validation loss: 1.9820081484403542
Epoch: 9| Step: 11
Training loss: 1.8172862529754639
Validation loss: 1.9711286730045894
Epoch: 9| Step: 12
Training loss: 2.0756001472473145
Validation loss: 1.957045248086504
Epoch: 9| Step: 13
Training loss: 2.6782584190368652
Validation loss: 1.9511167711491206
Epoch: 9| Step: 14
Training loss: 2.0096492767333984
Validation loss: 1.91554165315285
Epoch: 9| Step: 15
Training loss: 2.182920455932617
Validation loss: 1.950658209032292
Epoch: 9| Step: 16
Training loss: 2.175741195678711
Validation loss: 1.9474579953461242
Epoch: 9| Step: 17
Training loss: 1.784562110900879
Validation loss: 1.9315936376722596
Epoch: 9| Step: 18
Training loss: 2.183835983276367
Validation loss: 1.916765417126443
Epoch: 9| Step: 19
Training loss: 1.9487282037734985
Validation loss: 1.9244460956655818
Epoch: 64| Step: 0
Training loss: 2.5437726974487305
Validation loss: 1.8895561832318204
Epoch: 9| Step: 1
Training loss: 1.8426742553710938
Validation loss: 1.946274534403849
Epoch: 9| Step: 2
Training loss: 2.1168482303619385
Validation loss: 1.9371841897209772
Epoch: 9| Step: 3
Training loss: 1.7371795177459717
Validation loss: 1.912606311358994
Epoch: 9| Step: 4
Training loss: 2.1938443183898926
Validation loss: 1.8805936617816952
Epoch: 9| Step: 5
Training loss: 2.037851333618164
Validation loss: 1.9157246685714173
Epoch: 9| Step: 6
Training loss: 1.8608157634735107
Validation loss: 1.949371977675733
Epoch: 9| Step: 7
Training loss: 2.847226619720459
Validation loss: 1.9399471806107664
Epoch: 9| Step: 8
Training loss: 2.544738292694092
Validation loss: 1.88207037157292
Epoch: 9| Step: 9
Training loss: 1.596999168395996
Validation loss: 1.947810181610876
Epoch: 9| Step: 10
Training loss: 1.8759005069732666
Validation loss: 1.9342430418343852
Epoch: 9| Step: 11
Training loss: 2.3498358726501465
Validation loss: 2.0026182871070697
Epoch: 9| Step: 12
Training loss: 1.6876623630523682
Validation loss: 1.9782330440960343
Epoch: 9| Step: 13
Training loss: 1.853250503540039
Validation loss: 2.009409878751357
Epoch: 9| Step: 14
Training loss: 2.416686534881592
Validation loss: 2.0281680539357576
Epoch: 9| Step: 15
Training loss: 2.194916248321533
Validation loss: 2.038908964438404
Epoch: 9| Step: 16
Training loss: 1.9741294384002686
Validation loss: 2.075749826088226
Epoch: 9| Step: 17
Training loss: 2.318134307861328
Validation loss: 2.022247995404031
Epoch: 9| Step: 18
Training loss: 2.044499158859253
Validation loss: 2.0535521421501106
Epoch: 9| Step: 19
Training loss: 2.1220932006835938
Validation loss: 2.03439566643118
Epoch: 65| Step: 0
Training loss: 2.04856538772583
Validation loss: 1.9806567730663491
Epoch: 9| Step: 1
Training loss: 1.4340797662734985
Validation loss: 2.021120345849785
Epoch: 9| Step: 2
Training loss: 1.8403853178024292
Validation loss: 1.9349464624048136
Epoch: 9| Step: 3
Training loss: 1.5221153497695923
Validation loss: 1.986891556986802
Epoch: 9| Step: 4
Training loss: 2.389737606048584
Validation loss: 1.9845899377795433
Epoch: 9| Step: 5
Training loss: 1.809003233909607
Validation loss: 1.9383054928813908
Epoch: 9| Step: 6
Training loss: 1.6558740139007568
Validation loss: 1.9265217094970264
Epoch: 9| Step: 7
Training loss: 1.8001070022583008
Validation loss: 1.9330692445631508
Epoch: 9| Step: 8
Training loss: 3.073486328125
Validation loss: 1.932245940613232
Epoch: 9| Step: 9
Training loss: 1.4348692893981934
Validation loss: 2.0110840385766338
Epoch: 9| Step: 10
Training loss: 2.4987192153930664
Validation loss: 1.9199357984734953
Epoch: 9| Step: 11
Training loss: 1.9489057064056396
Validation loss: 1.919541706284173
Epoch: 9| Step: 12
Training loss: 2.5636844635009766
Validation loss: 1.9426707904115856
Epoch: 9| Step: 13
Training loss: 1.8278450965881348
Validation loss: 1.915155733232018
Epoch: 9| Step: 14
Training loss: 1.8872452974319458
Validation loss: 1.974146081389283
Epoch: 9| Step: 15
Training loss: 2.2458338737487793
Validation loss: 1.9487521914269428
Epoch: 9| Step: 16
Training loss: 2.0247225761413574
Validation loss: 1.9200219636340794
Epoch: 9| Step: 17
Training loss: 1.9821172952651978
Validation loss: 1.9030398842242124
Epoch: 9| Step: 18
Training loss: 2.1698384284973145
Validation loss: 1.8799619074348066
Epoch: 9| Step: 19
Training loss: 3.0355224609375
Validation loss: 1.9638700270824294
Epoch: 66| Step: 0
Training loss: 2.193488359451294
Validation loss: 1.8809353704932783
Epoch: 9| Step: 1
Training loss: 2.282372236251831
Validation loss: 1.9591451643182218
Epoch: 9| Step: 2
Training loss: 2.5829358100891113
Validation loss: 1.91496752663482
Epoch: 9| Step: 3
Training loss: 2.7775025367736816
Validation loss: 1.8570802486200126
Epoch: 9| Step: 4
Training loss: 1.7671921253204346
Validation loss: 1.8857529969524136
Epoch: 9| Step: 5
Training loss: 1.9327694177627563
Validation loss: 1.9428006213345974
Epoch: 9| Step: 6
Training loss: 2.1849749088287354
Validation loss: 1.9239018615201222
Epoch: 9| Step: 7
Training loss: 2.4020628929138184
Validation loss: 1.9651153241987709
Epoch: 9| Step: 8
Training loss: 2.069181442260742
Validation loss: 1.9197450181563123
Epoch: 9| Step: 9
Training loss: 1.438356876373291
Validation loss: 1.8993200106586483
Epoch: 9| Step: 10
Training loss: 2.2569000720977783
Validation loss: 1.9376719461070548
Epoch: 9| Step: 11
Training loss: 2.509777545928955
Validation loss: 1.9389861470503773
Epoch: 9| Step: 12
Training loss: 2.094879150390625
Validation loss: 1.9837411925089445
Epoch: 9| Step: 13
Training loss: 1.3177464008331299
Validation loss: 1.9604848151584324
Epoch: 9| Step: 14
Training loss: 1.65065598487854
Validation loss: 1.9984625878093911
Epoch: 9| Step: 15
Training loss: 2.454101085662842
Validation loss: 2.0090272881144244
Epoch: 9| Step: 16
Training loss: 1.9589483737945557
Validation loss: 2.0550297044163983
Epoch: 9| Step: 17
Training loss: 1.9122824668884277
Validation loss: 1.9901416438946622
Epoch: 9| Step: 18
Training loss: 2.652008533477783
Validation loss: 1.9962568677586616
Epoch: 9| Step: 19
Training loss: 1.3334544897079468
Validation loss: 2.0423878139729124
Epoch: 67| Step: 0
Training loss: 1.5158594846725464
Validation loss: 1.9841265163833288
Epoch: 9| Step: 1
Training loss: 2.1912424564361572
Validation loss: 2.0017539545786467
Epoch: 9| Step: 2
Training loss: 2.2688066959381104
Validation loss: 2.058157690995031
Epoch: 9| Step: 3
Training loss: 1.3281201124191284
Validation loss: 2.0572294631450294
Epoch: 9| Step: 4
Training loss: 1.8612377643585205
Validation loss: 2.0376243557003764
Epoch: 9| Step: 5
Training loss: 2.0581841468811035
Validation loss: 1.99194471956157
Epoch: 9| Step: 6
Training loss: 2.285501480102539
Validation loss: 2.085793671848105
Epoch: 9| Step: 7
Training loss: 1.6863476037979126
Validation loss: 2.015234024404622
Epoch: 9| Step: 8
Training loss: 2.2374038696289062
Validation loss: 1.9740071622587794
Epoch: 9| Step: 9
Training loss: 1.5067145824432373
Validation loss: 2.000507185785033
Epoch: 9| Step: 10
Training loss: 2.151259183883667
Validation loss: 2.006614978364903
Epoch: 9| Step: 11
Training loss: 1.6145297288894653
Validation loss: 1.9764498961057595
Epoch: 9| Step: 12
Training loss: 2.302969455718994
Validation loss: 1.972304397349735
Epoch: 9| Step: 13
Training loss: 2.497668743133545
Validation loss: 1.9450206979573201
Epoch: 9| Step: 14
Training loss: 2.404240369796753
Validation loss: 2.002707489960485
Epoch: 9| Step: 15
Training loss: 2.0065841674804688
Validation loss: 1.9470550310697488
Epoch: 9| Step: 16
Training loss: 1.8210015296936035
Validation loss: 1.9871297894621924
Epoch: 9| Step: 17
Training loss: 3.2563400268554688
Validation loss: 1.9671240093039095
Epoch: 9| Step: 18
Training loss: 1.8886208534240723
Validation loss: 1.9389087321946947
Epoch: 9| Step: 19
Training loss: 2.557443141937256
Validation loss: 1.9389034758368842
Epoch: 68| Step: 0
Training loss: 1.3975251913070679
Validation loss: 1.9742868152453745
Epoch: 9| Step: 1
Training loss: 1.5177767276763916
Validation loss: 1.923501361188271
Epoch: 9| Step: 2
Training loss: 2.0696213245391846
Validation loss: 1.9589490315897002
Epoch: 9| Step: 3
Training loss: 2.559648036956787
Validation loss: 1.9740360726555475
Epoch: 9| Step: 4
Training loss: 1.7829475402832031
Validation loss: 1.9047324828964343
Epoch: 9| Step: 5
Training loss: 2.900926113128662
Validation loss: 1.9688261404311915
Epoch: 9| Step: 6
Training loss: 2.8636209964752197
Validation loss: 1.964096111359356
Epoch: 9| Step: 7
Training loss: 1.9570857286453247
Validation loss: 1.9491162282957448
Epoch: 9| Step: 8
Training loss: 1.7781856060028076
Validation loss: 1.8927025820711534
Epoch: 9| Step: 9
Training loss: 2.344881057739258
Validation loss: 1.9037523869987871
Epoch: 9| Step: 10
Training loss: 1.8446954488754272
Validation loss: 1.9498185056576627
Epoch: 9| Step: 11
Training loss: 1.947998046875
Validation loss: 1.9381793711682875
Epoch: 9| Step: 12
Training loss: 1.9525856971740723
Validation loss: 1.9533279516714082
Epoch: 9| Step: 13
Training loss: 2.4955360889434814
Validation loss: 1.931334918351482
Epoch: 9| Step: 14
Training loss: 1.3119721412658691
Validation loss: 1.9620322683732287
Epoch: 9| Step: 15
Training loss: 1.7575759887695312
Validation loss: 1.9511556899804863
Epoch: 9| Step: 16
Training loss: 2.1210241317749023
Validation loss: 1.923039930329906
Epoch: 9| Step: 17
Training loss: 1.9032326936721802
Validation loss: 1.9653566526852067
Epoch: 9| Step: 18
Training loss: 2.6400182247161865
Validation loss: 1.9527287997787806
Epoch: 9| Step: 19
Training loss: 2.2691140174865723
Validation loss: 1.9437474741352547
Epoch: 69| Step: 0
Training loss: 2.298841953277588
Validation loss: 2.0131861331651537
Epoch: 9| Step: 1
Training loss: 1.8609776496887207
Validation loss: 1.984451401147911
Epoch: 9| Step: 2
Training loss: 2.1203441619873047
Validation loss: 1.947933433724822
Epoch: 9| Step: 3
Training loss: 1.9824988842010498
Validation loss: 1.961559020358024
Epoch: 9| Step: 4
Training loss: 0.9969226121902466
Validation loss: 2.017552581622446
Epoch: 9| Step: 5
Training loss: 1.5349469184875488
Validation loss: 1.995178874448049
Epoch: 9| Step: 6
Training loss: 1.6474871635437012
Validation loss: 1.9661802439380893
Epoch: 9| Step: 7
Training loss: 2.311028480529785
Validation loss: 1.9773943698663505
Epoch: 9| Step: 8
Training loss: 2.572941303253174
Validation loss: 1.9617374372139251
Epoch: 9| Step: 9
Training loss: 2.4032509326934814
Validation loss: 1.9824731212725741
Epoch: 9| Step: 10
Training loss: 2.1528210639953613
Validation loss: 1.9932177770052024
Epoch: 9| Step: 11
Training loss: 2.278696060180664
Validation loss: 1.9542568115879306
Epoch: 9| Step: 12
Training loss: 1.5747497081756592
Validation loss: 2.012513684711868
Epoch: 9| Step: 13
Training loss: 2.0752410888671875
Validation loss: 1.9905038017163175
Epoch: 9| Step: 14
Training loss: 2.1463541984558105
Validation loss: 1.9593302414571638
Epoch: 9| Step: 15
Training loss: 2.591306209564209
Validation loss: 2.0065429553711156
Epoch: 9| Step: 16
Training loss: 2.3389205932617188
Validation loss: 2.0211731418431236
Epoch: 9| Step: 17
Training loss: 1.9157683849334717
Validation loss: 1.9752286012224156
Epoch: 9| Step: 18
Training loss: 2.158231735229492
Validation loss: 1.9545562473132456
Epoch: 9| Step: 19
Training loss: 2.0192883014678955
Validation loss: 1.951071619129867
Epoch: 70| Step: 0
Training loss: 2.55289888381958
Validation loss: 1.9441321985327082
Epoch: 9| Step: 1
Training loss: 2.2031712532043457
Validation loss: 1.9653843701314584
Epoch: 9| Step: 2
Training loss: 1.6769230365753174
Validation loss: 1.948191900047467
Epoch: 9| Step: 3
Training loss: 1.991504430770874
Validation loss: 2.0042486259405563
Epoch: 9| Step: 4
Training loss: 2.993772506713867
Validation loss: 1.9720047497920852
Epoch: 9| Step: 5
Training loss: 1.6235066652297974
Validation loss: 2.0120536732159073
Epoch: 9| Step: 6
Training loss: 1.6871047019958496
Validation loss: 2.0556463792169692
Epoch: 9| Step: 7
Training loss: 1.7751524448394775
Validation loss: 2.0202644180050857
Epoch: 9| Step: 8
Training loss: 2.3142642974853516
Validation loss: 2.0520607790501
Epoch: 9| Step: 9
Training loss: 2.352977752685547
Validation loss: 2.0504540625236016
Epoch: 9| Step: 10
Training loss: 2.1549296379089355
Validation loss: 2.0714459342064617
Epoch: 9| Step: 11
Training loss: 1.8157076835632324
Validation loss: 2.0593612125451615
Epoch: 9| Step: 12
Training loss: 1.6024301052093506
Validation loss: 1.9792258010493766
Epoch: 9| Step: 13
Training loss: 2.1913702487945557
Validation loss: 2.0643415073696656
Epoch: 9| Step: 14
Training loss: 1.868091106414795
Validation loss: 2.0426389210515743
Epoch: 9| Step: 15
Training loss: 1.8726035356521606
Validation loss: 2.059780607978217
Epoch: 9| Step: 16
Training loss: 2.1105873584747314
Validation loss: 2.028358117281962
Epoch: 9| Step: 17
Training loss: 1.5012469291687012
Validation loss: 2.0090355753041
Epoch: 9| Step: 18
Training loss: 2.688642740249634
Validation loss: 2.009863083311122
Epoch: 9| Step: 19
Training loss: 2.0298190116882324
Validation loss: 1.983765688731516
Epoch: 71| Step: 0
Training loss: 2.443730354309082
Validation loss: 1.99016817096326
Epoch: 9| Step: 1
Training loss: 1.5356664657592773
Validation loss: 1.9552331451031801
Epoch: 9| Step: 2
Training loss: 1.9985260963439941
Validation loss: 1.9834027418987357
Epoch: 9| Step: 3
Training loss: 1.664560079574585
Validation loss: 1.9731132435284073
Epoch: 9| Step: 4
Training loss: 1.9665617942810059
Validation loss: 1.9555414083192675
Epoch: 9| Step: 5
Training loss: 1.87874436378479
Validation loss: 1.8815842703949632
Epoch: 9| Step: 6
Training loss: 2.333329200744629
Validation loss: 1.9035988711624694
Epoch: 9| Step: 7
Training loss: 1.7983012199401855
Validation loss: 1.917507606444599
Epoch: 9| Step: 8
Training loss: 1.6351444721221924
Validation loss: 2.000283277292046
Epoch: 9| Step: 9
Training loss: 2.3110721111297607
Validation loss: 1.9685567368706354
Epoch: 9| Step: 10
Training loss: 2.242835521697998
Validation loss: 1.8994835572277042
Epoch: 9| Step: 11
Training loss: 2.034709930419922
Validation loss: 1.9156939597438565
Epoch: 9| Step: 12
Training loss: 1.5760605335235596
Validation loss: 1.8807452805608296
Epoch: 9| Step: 13
Training loss: 1.8762482404708862
Validation loss: 1.914166973649169
Epoch: 9| Step: 14
Training loss: 1.8622384071350098
Validation loss: 1.944208438447911
Epoch: 9| Step: 15
Training loss: 2.179795265197754
Validation loss: 1.9114821566094597
Epoch: 9| Step: 16
Training loss: 2.00523042678833
Validation loss: 1.9369348416225516
Epoch: 9| Step: 17
Training loss: 1.8502272367477417
Validation loss: 1.9669154856702407
Epoch: 9| Step: 18
Training loss: 1.997822642326355
Validation loss: 1.9415032366196887
Epoch: 9| Step: 19
Training loss: 3.8128347396850586
Validation loss: 1.9632928886001917
Epoch: 72| Step: 0
Training loss: 2.0225677490234375
Validation loss: 2.0070986456150632
Epoch: 9| Step: 1
Training loss: 2.2535200119018555
Validation loss: 1.9416371446719272
Epoch: 9| Step: 2
Training loss: 3.0468087196350098
Validation loss: 2.0241050608724143
Epoch: 9| Step: 3
Training loss: 1.5131855010986328
Validation loss: 1.9782389179408122
Epoch: 9| Step: 4
Training loss: 1.96148681640625
Validation loss: 2.0022693486522427
Epoch: 9| Step: 5
Training loss: 1.6220020055770874
Validation loss: 2.0042291022033143
Epoch: 9| Step: 6
Training loss: 2.423186779022217
Validation loss: 1.9719652374871344
Epoch: 9| Step: 7
Training loss: 2.6696245670318604
Validation loss: 1.990830881990117
Epoch: 9| Step: 8
Training loss: 1.9697678089141846
Validation loss: 1.959261847056931
Epoch: 9| Step: 9
Training loss: 1.5164337158203125
Validation loss: 1.9250294437511362
Epoch: 9| Step: 10
Training loss: 1.9555644989013672
Validation loss: 1.908292301267171
Epoch: 9| Step: 11
Training loss: 1.8274245262145996
Validation loss: 1.9257530917366632
Epoch: 9| Step: 12
Training loss: 1.6259678602218628
Validation loss: 1.9877467164032752
Epoch: 9| Step: 13
Training loss: 2.3363938331604004
Validation loss: 2.0148721024286833
Epoch: 9| Step: 14
Training loss: 2.2203593254089355
Validation loss: 2.007552742958069
Epoch: 9| Step: 15
Training loss: 1.9216550588607788
Validation loss: 1.951866274257358
Epoch: 9| Step: 16
Training loss: 2.086829900741577
Validation loss: 1.9973292633783903
Epoch: 9| Step: 17
Training loss: 2.282306432723999
Validation loss: 1.925448702393676
Epoch: 9| Step: 18
Training loss: 1.6853690147399902
Validation loss: 2.025476726696646
Epoch: 9| Step: 19
Training loss: 1.7860822677612305
Validation loss: 2.045277098957583
Epoch: 73| Step: 0
Training loss: 1.9791254997253418
Validation loss: 2.0212187646961897
Epoch: 9| Step: 1
Training loss: 1.9972041845321655
Validation loss: 2.00533246393684
Epoch: 9| Step: 2
Training loss: 1.6433353424072266
Validation loss: 1.998797622516001
Epoch: 9| Step: 3
Training loss: 1.2965904474258423
Validation loss: 2.0563117994678963
Epoch: 9| Step: 4
Training loss: 2.4183311462402344
Validation loss: 2.0009120857115272
Epoch: 9| Step: 5
Training loss: 1.6425378322601318
Validation loss: 2.0325902528900035
Epoch: 9| Step: 6
Training loss: 2.046964645385742
Validation loss: 1.9941138372146825
Epoch: 9| Step: 7
Training loss: 2.7828831672668457
Validation loss: 1.9744759026191216
Epoch: 9| Step: 8
Training loss: 2.6055068969726562
Validation loss: 2.0342355469147937
Epoch: 9| Step: 9
Training loss: 1.4873839616775513
Validation loss: 2.00042466722804
Epoch: 9| Step: 10
Training loss: 1.8796215057373047
Validation loss: 2.0155835863497615
Epoch: 9| Step: 11
Training loss: 2.2536048889160156
Validation loss: 2.0089151327558556
Epoch: 9| Step: 12
Training loss: 2.022818088531494
Validation loss: 2.03722331678267
Epoch: 9| Step: 13
Training loss: 1.5684207677841187
Validation loss: 1.9405593666241323
Epoch: 9| Step: 14
Training loss: 1.7419952154159546
Validation loss: 1.9748809346192175
Epoch: 9| Step: 15
Training loss: 2.2132151126861572
Validation loss: 2.0271026264849326
Epoch: 9| Step: 16
Training loss: 1.932417631149292
Validation loss: 2.049962274462199
Epoch: 9| Step: 17
Training loss: 2.209956645965576
Validation loss: 1.9901934124582963
Epoch: 9| Step: 18
Training loss: 3.078810214996338
Validation loss: 2.02151761809699
Epoch: 9| Step: 19
Training loss: 1.5780904293060303
Validation loss: 2.018139471253045
Epoch: 74| Step: 0
Training loss: 1.8545924425125122
Validation loss: 2.0332080580347736
Epoch: 9| Step: 1
Training loss: 2.035350799560547
Validation loss: 1.9537749496295298
Epoch: 9| Step: 2
Training loss: 1.714224100112915
Validation loss: 1.9122857875961194
Epoch: 9| Step: 3
Training loss: 1.8416500091552734
Validation loss: 2.0335381725709216
Epoch: 9| Step: 4
Training loss: 1.8305590152740479
Validation loss: 1.98031827871748
Epoch: 9| Step: 5
Training loss: 2.779851198196411
Validation loss: 1.9516761414438701
Epoch: 9| Step: 6
Training loss: 1.5742006301879883
Validation loss: 1.9899616824637214
Epoch: 9| Step: 7
Training loss: 2.2777342796325684
Validation loss: 2.0472190114233992
Epoch: 9| Step: 8
Training loss: 2.235424041748047
Validation loss: 1.9952018072279236
Epoch: 9| Step: 9
Training loss: 1.9206736087799072
Validation loss: 2.041974723767891
Epoch: 9| Step: 10
Training loss: 2.360090970993042
Validation loss: 2.009022722998969
Epoch: 9| Step: 11
Training loss: 1.911636233329773
Validation loss: 2.02174356515459
Epoch: 9| Step: 12
Training loss: 2.157374858856201
Validation loss: 1.989366848691762
Epoch: 9| Step: 13
Training loss: 1.823045015335083
Validation loss: 2.013382260747951
Epoch: 9| Step: 14
Training loss: 1.825490117073059
Validation loss: 2.014632779917271
Epoch: 9| Step: 15
Training loss: 2.203331708908081
Validation loss: 1.9523169188190708
Epoch: 9| Step: 16
Training loss: 2.557140588760376
Validation loss: 1.9380788974624743
Epoch: 9| Step: 17
Training loss: 1.5467548370361328
Validation loss: 1.9599350862365832
Epoch: 9| Step: 18
Training loss: 1.697096824645996
Validation loss: 2.0072119510431086
Epoch: 9| Step: 19
Training loss: 2.5421030521392822
Validation loss: 1.9189676492334269
Epoch: 75| Step: 0
Training loss: 2.2898173332214355
Validation loss: 1.9500292428105854
Epoch: 9| Step: 1
Training loss: 1.8437941074371338
Validation loss: 1.9994865338579357
Epoch: 9| Step: 2
Training loss: 1.1785051822662354
Validation loss: 1.9348459809804135
Epoch: 9| Step: 3
Training loss: 2.0190439224243164
Validation loss: 1.8987971621451618
Epoch: 9| Step: 4
Training loss: 1.8022228479385376
Validation loss: 1.970110917262894
Epoch: 9| Step: 5
Training loss: 2.3390305042266846
Validation loss: 1.9277025384011028
Epoch: 9| Step: 6
Training loss: 2.0627121925354004
Validation loss: 2.0160243442590287
Epoch: 9| Step: 7
Training loss: 1.7263052463531494
Validation loss: 2.008782682658957
Epoch: 9| Step: 8
Training loss: 1.764163851737976
Validation loss: 1.9668508622286132
Epoch: 9| Step: 9
Training loss: 2.558513641357422
Validation loss: 1.9360375627339315
Epoch: 9| Step: 10
Training loss: 2.352318286895752
Validation loss: 2.0000850125182446
Epoch: 9| Step: 11
Training loss: 1.700669765472412
Validation loss: 1.9485506188097617
Epoch: 9| Step: 12
Training loss: 3.171215534210205
Validation loss: 1.9142044765486135
Epoch: 9| Step: 13
Training loss: 1.982967734336853
Validation loss: 1.9608990580057926
Epoch: 9| Step: 14
Training loss: 2.1520497798919678
Validation loss: 1.932812457462009
Epoch: 9| Step: 15
Training loss: 2.191632032394409
Validation loss: 1.919413847888974
Epoch: 9| Step: 16
Training loss: 1.9557762145996094
Validation loss: 1.9586676753682197
Epoch: 9| Step: 17
Training loss: 1.3940823078155518
Validation loss: 1.918189095936233
Epoch: 9| Step: 18
Training loss: 2.4301393032073975
Validation loss: 1.9838860009214003
Epoch: 9| Step: 19
Training loss: 1.9457608461380005
Validation loss: 1.9225167644967278
Epoch: 76| Step: 0
Training loss: 2.2352705001831055
Validation loss: 1.9352159774560722
Epoch: 9| Step: 1
Training loss: 1.6715788841247559
Validation loss: 1.9407740891408578
Epoch: 9| Step: 2
Training loss: 2.1518242359161377
Validation loss: 1.983381366558212
Epoch: 9| Step: 3
Training loss: 2.4359500408172607
Validation loss: 1.9131378021171626
Epoch: 9| Step: 4
Training loss: 2.2965362071990967
Validation loss: 1.9103586742346235
Epoch: 9| Step: 5
Training loss: 2.1669247150421143
Validation loss: 1.9419131013129254
Epoch: 9| Step: 6
Training loss: 1.4791383743286133
Validation loss: 1.9537725054102837
Epoch: 9| Step: 7
Training loss: 2.7144675254821777
Validation loss: 1.9401686706131311
Epoch: 9| Step: 8
Training loss: 1.8116645812988281
Validation loss: 1.9661519561740135
Epoch: 9| Step: 9
Training loss: 1.9162890911102295
Validation loss: 1.9454788012470272
Epoch: 9| Step: 10
Training loss: 1.997774362564087
Validation loss: 1.9616004983298212
Epoch: 9| Step: 11
Training loss: 1.859191656112671
Validation loss: 1.9790919084343122
Epoch: 9| Step: 12
Training loss: 2.912778377532959
Validation loss: 1.9681321425403622
Epoch: 9| Step: 13
Training loss: 1.7033216953277588
Validation loss: 2.0468622626160546
Epoch: 9| Step: 14
Training loss: 1.7364706993103027
Validation loss: 1.9558074277081936
Epoch: 9| Step: 15
Training loss: 1.5978798866271973
Validation loss: 1.9919097818059028
Epoch: 9| Step: 16
Training loss: 1.6244733333587646
Validation loss: 2.0502551905542825
Epoch: 9| Step: 17
Training loss: 2.522427558898926
Validation loss: 1.983145658918422
Epoch: 9| Step: 18
Training loss: 2.237338066101074
Validation loss: 1.9886110000473132
Epoch: 9| Step: 19
Training loss: 2.032647132873535
Validation loss: 1.968256667363558
Epoch: 77| Step: 0
Training loss: 2.3426437377929688
Validation loss: 2.0677124476261275
Epoch: 9| Step: 1
Training loss: 1.8895354270935059
Validation loss: 1.9816113290169257
Epoch: 9| Step: 2
Training loss: 1.1843876838684082
Validation loss: 2.010359497379056
Epoch: 9| Step: 3
Training loss: 1.6429765224456787
Validation loss: 1.9631484009379105
Epoch: 9| Step: 4
Training loss: 2.624471426010132
Validation loss: 2.0271088648185454
Epoch: 9| Step: 5
Training loss: 1.9636896848678589
Validation loss: 2.000112933220623
Epoch: 9| Step: 6
Training loss: 2.852895498275757
Validation loss: 2.018369918246921
Epoch: 9| Step: 7
Training loss: 1.84438157081604
Validation loss: 1.9824384459488684
Epoch: 9| Step: 8
Training loss: 1.9568202495574951
Validation loss: 2.0007034437261897
Epoch: 9| Step: 9
Training loss: 1.9506241083145142
Validation loss: 1.943287511523679
Epoch: 9| Step: 10
Training loss: 2.1742846965789795
Validation loss: 1.9540102936381059
Epoch: 9| Step: 11
Training loss: 1.908642292022705
Validation loss: 1.9760651622744774
Epoch: 9| Step: 12
Training loss: 1.7624104022979736
Validation loss: 2.019552452101124
Epoch: 9| Step: 13
Training loss: 2.9146885871887207
Validation loss: 2.000620389156204
Epoch: 9| Step: 14
Training loss: 1.1721689701080322
Validation loss: 1.9424003902956737
Epoch: 9| Step: 15
Training loss: 2.861907958984375
Validation loss: 1.9390065567098933
Epoch: 9| Step: 16
Training loss: 2.2046966552734375
Validation loss: 1.9242475959036847
Epoch: 9| Step: 17
Training loss: 2.090176582336426
Validation loss: 1.9549047320866757
Epoch: 9| Step: 18
Training loss: 1.6244558095932007
Validation loss: 1.92487559215628
Epoch: 9| Step: 19
Training loss: 1.7316133975982666
Validation loss: 1.9212531631799052
Epoch: 78| Step: 0
Training loss: 2.1634206771850586
Validation loss: 1.940624661582837
Epoch: 9| Step: 1
Training loss: 1.8643406629562378
Validation loss: 1.9820075686887013
Epoch: 9| Step: 2
Training loss: 1.7492458820343018
Validation loss: 1.8955464397402977
Epoch: 9| Step: 3
Training loss: 2.1523923873901367
Validation loss: 1.9369353150292266
Epoch: 9| Step: 4
Training loss: 1.4686583280563354
Validation loss: 1.9847997675696722
Epoch: 9| Step: 5
Training loss: 1.889609932899475
Validation loss: 1.9731996110874972
Epoch: 9| Step: 6
Training loss: 1.7603120803833008
Validation loss: 2.018253497940173
Epoch: 9| Step: 7
Training loss: 1.7411268949508667
Validation loss: 2.0352980378720402
Epoch: 9| Step: 8
Training loss: 3.2032504081726074
Validation loss: 2.0038857442869555
Epoch: 9| Step: 9
Training loss: 2.0966572761535645
Validation loss: 1.9912938411287266
Epoch: 9| Step: 10
Training loss: 2.7933995723724365
Validation loss: 1.9919496037119584
Epoch: 9| Step: 11
Training loss: 1.8172764778137207
Validation loss: 1.9837496820971263
Epoch: 9| Step: 12
Training loss: 1.3459069728851318
Validation loss: 2.003763641384866
Epoch: 9| Step: 13
Training loss: 2.4315271377563477
Validation loss: 2.020586023227774
Epoch: 9| Step: 14
Training loss: 1.9926552772521973
Validation loss: 2.1123057629564683
Epoch: 9| Step: 15
Training loss: 2.4454846382141113
Validation loss: 2.012623154002128
Epoch: 9| Step: 16
Training loss: 1.7757197618484497
Validation loss: 1.9670345208627715
Epoch: 9| Step: 17
Training loss: 1.593098759651184
Validation loss: 2.0426100586815705
Epoch: 9| Step: 18
Training loss: 2.2335715293884277
Validation loss: 2.0174250774246327
Epoch: 9| Step: 19
Training loss: 2.183378219604492
Validation loss: 1.9574674042008764
Epoch: 79| Step: 0
Training loss: 1.461393117904663
Validation loss: 1.9972698148205983
Epoch: 9| Step: 1
Training loss: 2.4961376190185547
Validation loss: 1.999199369828478
Epoch: 9| Step: 2
Training loss: 2.511262893676758
Validation loss: 2.0106812998545256
Epoch: 9| Step: 3
Training loss: 2.5580813884735107
Validation loss: 2.0086369574498786
Epoch: 9| Step: 4
Training loss: 1.945685625076294
Validation loss: 2.0080715563657474
Epoch: 9| Step: 5
Training loss: 1.9597258567810059
Validation loss: 1.9792790121311763
Epoch: 9| Step: 6
Training loss: 2.4844448566436768
Validation loss: 1.9365041676185113
Epoch: 9| Step: 7
Training loss: 1.423816204071045
Validation loss: 2.006172845689513
Epoch: 9| Step: 8
Training loss: 2.0011415481567383
Validation loss: 1.9799550548731852
Epoch: 9| Step: 9
Training loss: 3.2797694206237793
Validation loss: 1.984705164278154
Epoch: 9| Step: 10
Training loss: 1.7335166931152344
Validation loss: 1.9592258149771382
Epoch: 9| Step: 11
Training loss: 1.6858165264129639
Validation loss: 2.0498987204736943
Epoch: 9| Step: 12
Training loss: 1.4547855854034424
Validation loss: 1.9599177082665533
Epoch: 9| Step: 13
Training loss: 2.0001707077026367
Validation loss: 1.9385567397522412
Epoch: 9| Step: 14
Training loss: 1.7749165296554565
Validation loss: 1.9929632420162502
Epoch: 9| Step: 15
Training loss: 1.5410118103027344
Validation loss: 1.9996013006718039
Epoch: 9| Step: 16
Training loss: 1.854541301727295
Validation loss: 2.0052967551800847
Epoch: 9| Step: 17
Training loss: 2.1069860458374023
Validation loss: 1.981244836779807
Epoch: 9| Step: 18
Training loss: 1.9999796152114868
Validation loss: 2.0309000495526432
Epoch: 9| Step: 19
Training loss: 2.162440776824951
Validation loss: 1.9499771792254001
Epoch: 80| Step: 0
Training loss: 1.8092858791351318
Validation loss: 1.988595902490959
Epoch: 9| Step: 1
Training loss: 2.968456745147705
Validation loss: 1.9325052954310136
Epoch: 9| Step: 2
Training loss: 1.9943139553070068
Validation loss: 1.9955883592152768
Epoch: 9| Step: 3
Training loss: 1.9874160289764404
Validation loss: 1.9632267145801792
Epoch: 9| Step: 4
Training loss: 2.0489277839660645
Validation loss: 2.0139824117687968
Epoch: 9| Step: 5
Training loss: 1.7687686681747437
Validation loss: 2.003957305880759
Epoch: 9| Step: 6
Training loss: 2.3278191089630127
Validation loss: 1.981667998883364
Epoch: 9| Step: 7
Training loss: 1.368011236190796
Validation loss: 2.0060283708915434
Epoch: 9| Step: 8
Training loss: 2.235755443572998
Validation loss: 1.9807079901798166
Epoch: 9| Step: 9
Training loss: 1.9514248371124268
Validation loss: 1.985623035499518
Epoch: 9| Step: 10
Training loss: 2.0515122413635254
Validation loss: 2.0527592871686537
Epoch: 9| Step: 11
Training loss: 2.4246363639831543
Validation loss: 2.0060528491040786
Epoch: 9| Step: 12
Training loss: 1.5591434240341187
Validation loss: 1.9634504232475225
Epoch: 9| Step: 13
Training loss: 2.9364237785339355
Validation loss: 1.9556109973852582
Epoch: 9| Step: 14
Training loss: 2.3078606128692627
Validation loss: 1.9933088031604136
Epoch: 9| Step: 15
Training loss: 2.0142364501953125
Validation loss: 1.9514652396277559
Epoch: 9| Step: 16
Training loss: 1.918203353881836
Validation loss: 1.985955741765688
Epoch: 9| Step: 17
Training loss: 1.282171368598938
Validation loss: 1.986561246913114
Epoch: 9| Step: 18
Training loss: 1.9812802076339722
Validation loss: 2.014449856264128
Epoch: 9| Step: 19
Training loss: 2.305288791656494
Validation loss: 1.935816776838234
Epoch: 81| Step: 0
Training loss: 1.7777485847473145
Validation loss: 1.9996276536433817
Epoch: 9| Step: 1
Training loss: 1.3387689590454102
Validation loss: 2.0403988104072406
Epoch: 9| Step: 2
Training loss: 1.650450587272644
Validation loss: 1.9489872455596924
Epoch: 9| Step: 3
Training loss: 2.277749538421631
Validation loss: 2.004042055109422
Epoch: 9| Step: 4
Training loss: 1.8923357725143433
Validation loss: 1.979789016058119
Epoch: 9| Step: 5
Training loss: 1.945776343345642
Validation loss: 2.0296588475755653
Epoch: 9| Step: 6
Training loss: 1.8364067077636719
Validation loss: 2.0802382316520744
Epoch: 9| Step: 7
Training loss: 2.212026596069336
Validation loss: 2.0349183417052674
Epoch: 9| Step: 8
Training loss: 2.2442703247070312
Validation loss: 1.9939785758368402
Epoch: 9| Step: 9
Training loss: 2.4679911136627197
Validation loss: 2.004227524181064
Epoch: 9| Step: 10
Training loss: 1.3392775058746338
Validation loss: 2.0474292940373044
Epoch: 9| Step: 11
Training loss: 2.555992841720581
Validation loss: 2.034642161225243
Epoch: 9| Step: 12
Training loss: 1.371788740158081
Validation loss: 1.9818225284274533
Epoch: 9| Step: 13
Training loss: 2.0916011333465576
Validation loss: 2.0411081794354557
Epoch: 9| Step: 14
Training loss: 2.749028205871582
Validation loss: 2.0561723726258863
Epoch: 9| Step: 15
Training loss: 2.199286699295044
Validation loss: 2.020322815977412
Epoch: 9| Step: 16
Training loss: 1.7402902841567993
Validation loss: 1.9518026147814964
Epoch: 9| Step: 17
Training loss: 1.8898369073867798
Validation loss: 2.0105519997987815
Epoch: 9| Step: 18
Training loss: 2.4130520820617676
Validation loss: 1.994062126969262
Epoch: 9| Step: 19
Training loss: 2.214534282684326
Validation loss: 2.0383874057865827
Epoch: 82| Step: 0
Training loss: 2.1936488151550293
Validation loss: 2.0026520910880548
Epoch: 9| Step: 1
Training loss: 2.0083789825439453
Validation loss: 1.9918519301380184
Epoch: 9| Step: 2
Training loss: 1.2823340892791748
Validation loss: 1.9519969147743939
Epoch: 9| Step: 3
Training loss: 2.0223727226257324
Validation loss: 1.9828879387258627
Epoch: 9| Step: 4
Training loss: 1.9287985563278198
Validation loss: 2.0125058692136255
Epoch: 9| Step: 5
Training loss: 2.1095643043518066
Validation loss: 2.0001794640108836
Epoch: 9| Step: 6
Training loss: 2.037337064743042
Validation loss: 1.9483566953123903
Epoch: 9| Step: 7
Training loss: 1.519282579421997
Validation loss: 2.02695910536128
Epoch: 9| Step: 8
Training loss: 2.3306751251220703
Validation loss: 2.038891878059442
Epoch: 9| Step: 9
Training loss: 1.7619712352752686
Validation loss: 1.993855919769342
Epoch: 9| Step: 10
Training loss: 1.8638956546783447
Validation loss: 1.9902491989753228
Epoch: 9| Step: 11
Training loss: 2.1721839904785156
Validation loss: 2.004658227344211
Epoch: 9| Step: 12
Training loss: 3.0775885581970215
Validation loss: 2.059855106065599
Epoch: 9| Step: 13
Training loss: 1.910836100578308
Validation loss: 1.9760448435227649
Epoch: 9| Step: 14
Training loss: 1.8637664318084717
Validation loss: 2.0931311905812873
Epoch: 9| Step: 15
Training loss: 2.3909082412719727
Validation loss: 2.0080526466849897
Epoch: 9| Step: 16
Training loss: 2.790318489074707
Validation loss: 1.9680573811633981
Epoch: 9| Step: 17
Training loss: 1.8203142881393433
Validation loss: 1.9693061756573136
Epoch: 9| Step: 18
Training loss: 1.2237111330032349
Validation loss: 2.004973352384224
Epoch: 9| Step: 19
Training loss: 1.9603354930877686
Validation loss: 2.027345575017037
Epoch: 83| Step: 0
Training loss: 2.06187105178833
Validation loss: 1.9926265881215925
Epoch: 9| Step: 1
Training loss: 2.0980069637298584
Validation loss: 1.9814637633536358
Epoch: 9| Step: 2
Training loss: 2.5595908164978027
Validation loss: 2.008789569353886
Epoch: 9| Step: 3
Training loss: 1.498652458190918
Validation loss: 1.9185945095775796
Epoch: 9| Step: 4
Training loss: 2.5813980102539062
Validation loss: 1.96613421543039
Epoch: 9| Step: 5
Training loss: 2.0694844722747803
Validation loss: 1.9855477089504543
Epoch: 9| Step: 6
Training loss: 2.1215054988861084
Validation loss: 1.9322401756862941
Epoch: 9| Step: 7
Training loss: 2.096686601638794
Validation loss: 1.9096039679410646
Epoch: 9| Step: 8
Training loss: 2.3030388355255127
Validation loss: 1.9223099389522196
Epoch: 9| Step: 9
Training loss: 1.7325620651245117
Validation loss: 1.910461457513219
Epoch: 9| Step: 10
Training loss: 2.2772457599639893
Validation loss: 1.8679429189764338
Epoch: 9| Step: 11
Training loss: 1.6884052753448486
Validation loss: 1.901999098791493
Epoch: 9| Step: 12
Training loss: 2.025271415710449
Validation loss: 1.9146965253267356
Epoch: 9| Step: 13
Training loss: 2.1754579544067383
Validation loss: 1.9182234693774216
Epoch: 9| Step: 14
Training loss: 2.015254020690918
Validation loss: 1.9209421727297118
Epoch: 9| Step: 15
Training loss: 2.483128070831299
Validation loss: 1.9579982440248669
Epoch: 9| Step: 16
Training loss: 1.4235458374023438
Validation loss: 1.9416981652486238
Epoch: 9| Step: 17
Training loss: 2.1144471168518066
Validation loss: 1.9135726973307219
Epoch: 9| Step: 18
Training loss: 1.6483521461486816
Validation loss: 1.903090679388252
Epoch: 9| Step: 19
Training loss: 1.624191164970398
Validation loss: 2.032416400291937
Epoch: 84| Step: 0
Training loss: 1.789007544517517
Validation loss: 2.016112322429959
Epoch: 9| Step: 1
Training loss: 2.636824607849121
Validation loss: 2.0042656865908945
Epoch: 9| Step: 2
Training loss: 1.7518904209136963
Validation loss: 2.0373139484323186
Epoch: 9| Step: 3
Training loss: 1.699601650238037
Validation loss: 2.0145631857055553
Epoch: 9| Step: 4
Training loss: 1.980584740638733
Validation loss: 2.0463832187995634
Epoch: 9| Step: 5
Training loss: 2.6945033073425293
Validation loss: 2.070711515790267
Epoch: 9| Step: 6
Training loss: 2.189366102218628
Validation loss: 2.056703615531647
Epoch: 9| Step: 7
Training loss: 2.0100057125091553
Validation loss: 2.0316779450546925
Epoch: 9| Step: 8
Training loss: 1.785849690437317
Validation loss: 2.0850296174879555
Epoch: 9| Step: 9
Training loss: 2.020618438720703
Validation loss: 2.1331766149122937
Epoch: 9| Step: 10
Training loss: 1.9051430225372314
Validation loss: 2.0978400003995827
Epoch: 9| Step: 11
Training loss: 2.0898330211639404
Validation loss: 2.0977364795671094
Epoch: 9| Step: 12
Training loss: 1.957521677017212
Validation loss: 2.1101589777486787
Epoch: 9| Step: 13
Training loss: 1.6165008544921875
Validation loss: 2.082736682548797
Epoch: 9| Step: 14
Training loss: 2.653508186340332
Validation loss: 2.0579881453685624
Epoch: 9| Step: 15
Training loss: 2.280393123626709
Validation loss: 2.08189112676991
Epoch: 9| Step: 16
Training loss: 1.4481041431427002
Validation loss: 2.0754653584185263
Epoch: 9| Step: 17
Training loss: 1.8996080160140991
Validation loss: 2.0255387961435662
Epoch: 9| Step: 18
Training loss: 1.4563953876495361
Validation loss: 2.119522979791216
Epoch: 9| Step: 19
Training loss: 2.3330459594726562
Validation loss: 2.0705418466664045
Epoch: 85| Step: 0
Training loss: 1.5421159267425537
Validation loss: 2.054012708526721
Epoch: 9| Step: 1
Training loss: 1.985312819480896
Validation loss: 1.9975986437831852
Epoch: 9| Step: 2
Training loss: 1.6288948059082031
Validation loss: 2.010193195274408
Epoch: 9| Step: 3
Training loss: 2.053295850753784
Validation loss: 2.0050576942430127
Epoch: 9| Step: 4
Training loss: 2.130875825881958
Validation loss: 2.017290643650851
Epoch: 9| Step: 5
Training loss: 2.147712230682373
Validation loss: 1.9946507052551927
Epoch: 9| Step: 6
Training loss: 1.8261973857879639
Validation loss: 1.9927098219343227
Epoch: 9| Step: 7
Training loss: 2.22794246673584
Validation loss: 1.9313516651126121
Epoch: 9| Step: 8
Training loss: 1.8735177516937256
Validation loss: 1.964589642963821
Epoch: 9| Step: 9
Training loss: 1.7004859447479248
Validation loss: 1.9572535333015937
Epoch: 9| Step: 10
Training loss: 1.6240520477294922
Validation loss: 1.9174310114743898
Epoch: 9| Step: 11
Training loss: 2.256056547164917
Validation loss: 1.9737165557394782
Epoch: 9| Step: 12
Training loss: 3.344773530960083
Validation loss: 1.947109786726588
Epoch: 9| Step: 13
Training loss: 1.7317789793014526
Validation loss: 1.9670964942561637
Epoch: 9| Step: 14
Training loss: 1.501518964767456
Validation loss: 1.8885565104244424
Epoch: 9| Step: 15
Training loss: 2.026566505432129
Validation loss: 1.9182813347672387
Epoch: 9| Step: 16
Training loss: 2.2326853275299072
Validation loss: 1.917724787760124
Epoch: 9| Step: 17
Training loss: 1.8065296411514282
Validation loss: 1.937867044544906
Epoch: 9| Step: 18
Training loss: 2.1746554374694824
Validation loss: 1.9528962682477005
Epoch: 9| Step: 19
Training loss: 1.8951573371887207
Validation loss: 1.9408924150809967
Epoch: 86| Step: 0
Training loss: 2.2722268104553223
Validation loss: 1.921522725400307
Epoch: 9| Step: 1
Training loss: 2.7278738021850586
Validation loss: 1.9020346343088492
Epoch: 9| Step: 2
Training loss: 2.9876480102539062
Validation loss: 1.9794494728390262
Epoch: 9| Step: 3
Training loss: 2.3093059062957764
Validation loss: 1.9539350022514947
Epoch: 9| Step: 4
Training loss: 1.8953617811203003
Validation loss: 1.913383001046215
Epoch: 9| Step: 5
Training loss: 1.9462497234344482
Validation loss: 1.9600977846186796
Epoch: 9| Step: 6
Training loss: 1.959522008895874
Validation loss: 1.9111197749487787
Epoch: 9| Step: 7
Training loss: 1.7158002853393555
Validation loss: 1.9793209660825113
Epoch: 9| Step: 8
Training loss: 2.098188638687134
Validation loss: 1.930800208084875
Epoch: 9| Step: 9
Training loss: 1.3665693998336792
Validation loss: 1.9188006164358675
Epoch: 9| Step: 10
Training loss: 1.8066028356552124
Validation loss: 1.9477735183221832
Epoch: 9| Step: 11
Training loss: 1.7160654067993164
Validation loss: 1.9556545396502927
Epoch: 9| Step: 12
Training loss: 1.9878320693969727
Validation loss: 1.9939948809232644
Epoch: 9| Step: 13
Training loss: 2.955538749694824
Validation loss: 1.9502374336873884
Epoch: 9| Step: 14
Training loss: 1.9974302053451538
Validation loss: 1.998860220257327
Epoch: 9| Step: 15
Training loss: 1.4352359771728516
Validation loss: 1.9389531886834892
Epoch: 9| Step: 16
Training loss: 1.6638805866241455
Validation loss: 2.015732379268399
Epoch: 9| Step: 17
Training loss: 2.132401943206787
Validation loss: 2.0146190442627283
Epoch: 9| Step: 18
Training loss: 1.7363804578781128
Validation loss: 1.9416103122903288
Epoch: 9| Step: 19
Training loss: 1.9890336990356445
Validation loss: 2.04042758101182
Epoch: 87| Step: 0
Training loss: 2.618257522583008
Validation loss: 2.0472456122473845
Epoch: 9| Step: 1
Training loss: 1.7530381679534912
Validation loss: 2.0324890870842145
Epoch: 9| Step: 2
Training loss: 2.6005592346191406
Validation loss: 2.035691621492235
Epoch: 9| Step: 3
Training loss: 2.0643749237060547
Validation loss: 2.0290359893291114
Epoch: 9| Step: 4
Training loss: 2.0773043632507324
Validation loss: 1.9987038845638576
Epoch: 9| Step: 5
Training loss: 1.433363437652588
Validation loss: 1.9403013599862298
Epoch: 9| Step: 6
Training loss: 1.6875941753387451
Validation loss: 1.9770865629045227
Epoch: 9| Step: 7
Training loss: 2.2823851108551025
Validation loss: 1.9873860619908614
Epoch: 9| Step: 8
Training loss: 1.321199893951416
Validation loss: 1.9294955250170591
Epoch: 9| Step: 9
Training loss: 1.5853500366210938
Validation loss: 2.0332040392237603
Epoch: 9| Step: 10
Training loss: 1.64644455909729
Validation loss: 1.9362983154735978
Epoch: 9| Step: 11
Training loss: 1.9131171703338623
Validation loss: 2.001762312093227
Epoch: 9| Step: 12
Training loss: 2.694258213043213
Validation loss: 1.9594254227850934
Epoch: 9| Step: 13
Training loss: 1.8212534189224243
Validation loss: 1.9784721684970443
Epoch: 9| Step: 14
Training loss: 2.0510692596435547
Validation loss: 1.96468978562801
Epoch: 9| Step: 15
Training loss: 2.1870803833007812
Validation loss: 1.995457766725005
Epoch: 9| Step: 16
Training loss: 1.6470208168029785
Validation loss: 1.9545222040560606
Epoch: 9| Step: 17
Training loss: 2.099720001220703
Validation loss: 1.9621487178390833
Epoch: 9| Step: 18
Training loss: 2.52960467338562
Validation loss: 1.9703877581109246
Epoch: 9| Step: 19
Training loss: 1.449549674987793
Validation loss: 1.9581077759214442
Epoch: 88| Step: 0
Training loss: 1.816876769065857
Validation loss: 1.968300841695113
Epoch: 9| Step: 1
Training loss: 2.44592547416687
Validation loss: 1.9513117186457134
Epoch: 9| Step: 2
Training loss: 1.8304548263549805
Validation loss: 1.9256919871131293
Epoch: 9| Step: 3
Training loss: 2.1810696125030518
Validation loss: 1.9826914457966098
Epoch: 9| Step: 4
Training loss: 2.0359301567077637
Validation loss: 1.9586778253102475
Epoch: 9| Step: 5
Training loss: 1.911280870437622
Validation loss: 1.957552971599771
Epoch: 9| Step: 6
Training loss: 1.2078235149383545
Validation loss: 1.9898260926171172
Epoch: 9| Step: 7
Training loss: 1.9276399612426758
Validation loss: 2.018900718620355
Epoch: 9| Step: 8
Training loss: 2.000735282897949
Validation loss: 1.9868341650036598
Epoch: 9| Step: 9
Training loss: 2.001173973083496
Validation loss: 2.0161609958401687
Epoch: 9| Step: 10
Training loss: 2.129002571105957
Validation loss: 1.9886079726459311
Epoch: 9| Step: 11
Training loss: 1.979346513748169
Validation loss: 2.0446235301683275
Epoch: 9| Step: 12
Training loss: 2.0472679138183594
Validation loss: 2.045143986777436
Epoch: 9| Step: 13
Training loss: 1.6296559572219849
Validation loss: 2.023697487741923
Epoch: 9| Step: 14
Training loss: 2.1395163536071777
Validation loss: 2.0335155742631543
Epoch: 9| Step: 15
Training loss: 2.4934325218200684
Validation loss: 2.0289661223939857
Epoch: 9| Step: 16
Training loss: 2.3359827995300293
Validation loss: 1.990643345194755
Epoch: 9| Step: 17
Training loss: 2.1668949127197266
Validation loss: 1.9934324978066862
Epoch: 9| Step: 18
Training loss: 1.9921150207519531
Validation loss: 1.9469363483593618
Epoch: 9| Step: 19
Training loss: 1.8181496858596802
Validation loss: 1.985192165957938
Epoch: 89| Step: 0
Training loss: 1.798621416091919
Validation loss: 1.9525958694142402
Epoch: 9| Step: 1
Training loss: 2.699094295501709
Validation loss: 1.960270643234253
Epoch: 9| Step: 2
Training loss: 1.7143738269805908
Validation loss: 1.9793335979790996
Epoch: 9| Step: 3
Training loss: 1.7552337646484375
Validation loss: 1.969777267613857
Epoch: 9| Step: 4
Training loss: 1.8327301740646362
Validation loss: 1.9792505176804907
Epoch: 9| Step: 5
Training loss: 1.462768793106079
Validation loss: 1.9240333708070165
Epoch: 9| Step: 6
Training loss: 1.776341199874878
Validation loss: 2.0143803641092863
Epoch: 9| Step: 7
Training loss: 1.8689558506011963
Validation loss: 2.0209419864544764
Epoch: 9| Step: 8
Training loss: 1.9937204122543335
Validation loss: 1.9309096585074774
Epoch: 9| Step: 9
Training loss: 2.4938836097717285
Validation loss: 1.9720212855785013
Epoch: 9| Step: 10
Training loss: 2.3599066734313965
Validation loss: 1.9626799152909422
Epoch: 9| Step: 11
Training loss: 2.2108206748962402
Validation loss: 1.9056636378061858
Epoch: 9| Step: 12
Training loss: 1.5463430881500244
Validation loss: 1.9812326388393375
Epoch: 9| Step: 13
Training loss: 2.9865283966064453
Validation loss: 1.9706030423692662
Epoch: 9| Step: 14
Training loss: 1.5183422565460205
Validation loss: 1.9784924898216192
Epoch: 9| Step: 15
Training loss: 2.3659486770629883
Validation loss: 1.9845710075158867
Epoch: 9| Step: 16
Training loss: 1.5473579168319702
Validation loss: 1.9786446832066817
Epoch: 9| Step: 17
Training loss: 2.165933609008789
Validation loss: 2.0068474759300834
Epoch: 9| Step: 18
Training loss: 1.870750069618225
Validation loss: 2.023135956242788
Epoch: 9| Step: 19
Training loss: 2.3658230304718018
Validation loss: 2.019661852781721
Epoch: 90| Step: 0
Training loss: 1.7308293581008911
Validation loss: 2.0116202573982074
Epoch: 9| Step: 1
Training loss: 2.2344412803649902
Validation loss: 2.0514504686533974
Epoch: 9| Step: 2
Training loss: 2.4893360137939453
Validation loss: 2.000047121974204
Epoch: 9| Step: 3
Training loss: 2.3812832832336426
Validation loss: 2.0307027298769507
Epoch: 9| Step: 4
Training loss: 1.6876837015151978
Validation loss: 1.978530169390946
Epoch: 9| Step: 5
Training loss: 2.292962074279785
Validation loss: 2.011264047176718
Epoch: 9| Step: 6
Training loss: 1.7494885921478271
Validation loss: 2.0592262050230725
Epoch: 9| Step: 7
Training loss: 2.033797025680542
Validation loss: 1.9991518319081918
Epoch: 9| Step: 8
Training loss: 2.540640115737915
Validation loss: 2.0534825187792882
Epoch: 9| Step: 9
Training loss: 1.6477900743484497
Validation loss: 1.9978151595849785
Epoch: 9| Step: 10
Training loss: 2.3375802040100098
Validation loss: 1.9860247184904358
Epoch: 9| Step: 11
Training loss: 1.7646161317825317
Validation loss: 2.01341637433004
Epoch: 9| Step: 12
Training loss: 1.6519067287445068
Validation loss: 2.007997864441906
Epoch: 9| Step: 13
Training loss: 1.9616672992706299
Validation loss: 1.9944852856423358
Epoch: 9| Step: 14
Training loss: 1.3483319282531738
Validation loss: 1.9496747143834614
Epoch: 9| Step: 15
Training loss: 2.1829280853271484
Validation loss: 1.9524867020064978
Epoch: 9| Step: 16
Training loss: 1.560121774673462
Validation loss: 1.9751815247021134
Epoch: 9| Step: 17
Training loss: 2.760874032974243
Validation loss: 1.9733680340883544
Epoch: 9| Step: 18
Training loss: 1.9973125457763672
Validation loss: 1.9226888075149318
Epoch: 9| Step: 19
Training loss: 1.6922221183776855
Validation loss: 1.939749836064071
Epoch: 91| Step: 0
Training loss: 1.5612883567810059
Validation loss: 1.980447562478429
Epoch: 9| Step: 1
Training loss: 1.4878902435302734
Validation loss: 1.9549068890029577
Epoch: 9| Step: 2
Training loss: 2.110901117324829
Validation loss: 1.9617452449935804
Epoch: 9| Step: 3
Training loss: 1.928200364112854
Validation loss: 1.9373795831803795
Epoch: 9| Step: 4
Training loss: 2.1047329902648926
Validation loss: 1.8985139963438185
Epoch: 9| Step: 5
Training loss: 2.052238941192627
Validation loss: 1.980762963672336
Epoch: 9| Step: 6
Training loss: 1.3201416730880737
Validation loss: 2.0206560067993276
Epoch: 9| Step: 7
Training loss: 1.7596509456634521
Validation loss: 1.9788172245025635
Epoch: 9| Step: 8
Training loss: 1.93683922290802
Validation loss: 1.951606350836994
Epoch: 9| Step: 9
Training loss: 2.5323331356048584
Validation loss: 1.9804484243873213
Epoch: 9| Step: 10
Training loss: 1.986593246459961
Validation loss: 1.9482892434374035
Epoch: 9| Step: 11
Training loss: 2.098236083984375
Validation loss: 2.0269470231996167
Epoch: 9| Step: 12
Training loss: 2.988830804824829
Validation loss: 1.9941767634247705
Epoch: 9| Step: 13
Training loss: 1.274446964263916
Validation loss: 1.9715039644309942
Epoch: 9| Step: 14
Training loss: 2.5682170391082764
Validation loss: 1.9626829341161165
Epoch: 9| Step: 15
Training loss: 1.9162957668304443
Validation loss: 1.934212408477454
Epoch: 9| Step: 16
Training loss: 1.7616605758666992
Validation loss: 1.9109382800918688
Epoch: 9| Step: 17
Training loss: 2.6830310821533203
Validation loss: 1.9169350579488191
Epoch: 9| Step: 18
Training loss: 2.491096258163452
Validation loss: 1.9528551341818392
Epoch: 9| Step: 19
Training loss: 1.6231589317321777
Validation loss: 1.9852858850424238
Epoch: 92| Step: 0
Training loss: 2.349968433380127
Validation loss: 1.949175788344239
Epoch: 9| Step: 1
Training loss: 1.944223403930664
Validation loss: 1.9515304651191767
Epoch: 9| Step: 2
Training loss: 2.0765867233276367
Validation loss: 1.994670640650413
Epoch: 9| Step: 3
Training loss: 2.247591733932495
Validation loss: 2.0514924097404204
Epoch: 9| Step: 4
Training loss: 2.6779417991638184
Validation loss: 1.957664335374352
Epoch: 9| Step: 5
Training loss: 2.4932847023010254
Validation loss: 1.9332287783245388
Epoch: 9| Step: 6
Training loss: 1.5925506353378296
Validation loss: 1.9621824978066862
Epoch: 9| Step: 7
Training loss: 1.550413727760315
Validation loss: 1.9485946867963393
Epoch: 9| Step: 8
Training loss: 1.8029587268829346
Validation loss: 1.979999586832609
Epoch: 9| Step: 9
Training loss: 2.017700672149658
Validation loss: 1.9799059192053705
Epoch: 9| Step: 10
Training loss: 1.4868621826171875
Validation loss: 1.975714941676572
Epoch: 9| Step: 11
Training loss: 2.262819290161133
Validation loss: 1.966415176288687
Epoch: 9| Step: 12
Training loss: 1.4093363285064697
Validation loss: 1.9995442585979435
Epoch: 9| Step: 13
Training loss: 2.596310615539551
Validation loss: 2.016227632975407
Epoch: 9| Step: 14
Training loss: 1.737097978591919
Validation loss: 2.0017017897942084
Epoch: 9| Step: 15
Training loss: 1.8343286514282227
Validation loss: 2.0239686511403363
Epoch: 9| Step: 16
Training loss: 2.340968132019043
Validation loss: 1.9681430686292032
Epoch: 9| Step: 17
Training loss: 1.735041618347168
Validation loss: 2.0167574590916257
Epoch: 9| Step: 18
Training loss: 2.3286585807800293
Validation loss: 2.0358498062161234
Epoch: 9| Step: 19
Training loss: 1.8381857872009277
Validation loss: 1.9836160098906044
Epoch: 93| Step: 0
Training loss: 1.832882046699524
Validation loss: 1.929948993724027
Epoch: 9| Step: 1
Training loss: 1.962207555770874
Validation loss: 1.9873765852811525
Epoch: 9| Step: 2
Training loss: 1.656602144241333
Validation loss: 1.9541457213943811
Epoch: 9| Step: 3
Training loss: 2.1961755752563477
Validation loss: 1.9719602624289423
Epoch: 9| Step: 4
Training loss: 2.384549379348755
Validation loss: 1.9475048222987772
Epoch: 9| Step: 5
Training loss: 1.630149483680725
Validation loss: 1.9804079695571242
Epoch: 9| Step: 6
Training loss: 2.6752266883850098
Validation loss: 2.006198193529527
Epoch: 9| Step: 7
Training loss: 1.6994426250457764
Validation loss: 1.9728598303074458
Epoch: 9| Step: 8
Training loss: 2.0454049110412598
Validation loss: 2.0077390876605357
Epoch: 9| Step: 9
Training loss: 2.2595298290252686
Validation loss: 2.00822038787732
Epoch: 9| Step: 10
Training loss: 2.510434865951538
Validation loss: 2.0213169854321924
Epoch: 9| Step: 11
Training loss: 1.5844043493270874
Validation loss: 2.034208606472976
Epoch: 9| Step: 12
Training loss: 1.9006717205047607
Validation loss: 2.029798056581895
Epoch: 9| Step: 13
Training loss: 1.6147804260253906
Validation loss: 2.019365684591609
Epoch: 9| Step: 14
Training loss: 1.9942213296890259
Validation loss: 2.0688776198050958
Epoch: 9| Step: 15
Training loss: 2.0639219284057617
Validation loss: 2.010848012759531
Epoch: 9| Step: 16
Training loss: 2.084669589996338
Validation loss: 2.0084044247222463
Epoch: 9| Step: 17
Training loss: 2.0325515270233154
Validation loss: 1.9708843265506004
Epoch: 9| Step: 18
Training loss: 2.219398260116577
Validation loss: 2.00837766009269
Epoch: 9| Step: 19
Training loss: 1.8928052186965942
Validation loss: 1.9075012069811923
Epoch: 94| Step: 0
Training loss: 1.9511643648147583
Validation loss: 1.9803028586957094
Epoch: 9| Step: 1
Training loss: 1.6120591163635254
Validation loss: 1.8946687283275796
Epoch: 9| Step: 2
Training loss: 2.1022987365722656
Validation loss: 1.9491360187530518
Epoch: 9| Step: 3
Training loss: 1.7938916683197021
Validation loss: 1.8932116083103976
Epoch: 9| Step: 4
Training loss: 1.8673059940338135
Validation loss: 1.9349419864819204
Epoch: 9| Step: 5
Training loss: 1.6490660905838013
Validation loss: 1.9018996508001424
Epoch: 9| Step: 6
Training loss: 1.8355528116226196
Validation loss: 1.9107650655636685
Epoch: 9| Step: 7
Training loss: 2.846374988555908
Validation loss: 1.9233848353941663
Epoch: 9| Step: 8
Training loss: 1.6266372203826904
Validation loss: 1.936511876771776
Epoch: 9| Step: 9
Training loss: 2.4659690856933594
Validation loss: 1.945839043143842
Epoch: 9| Step: 10
Training loss: 2.2659459114074707
Validation loss: 1.9435067399800252
Epoch: 9| Step: 11
Training loss: 1.5819722414016724
Validation loss: 1.958856390534545
Epoch: 9| Step: 12
Training loss: 1.6845574378967285
Validation loss: 1.9074894618644989
Epoch: 9| Step: 13
Training loss: 1.5104882717132568
Validation loss: 1.9566465093077516
Epoch: 9| Step: 14
Training loss: 2.379283905029297
Validation loss: 2.025932768265978
Epoch: 9| Step: 15
Training loss: 1.9356653690338135
Validation loss: 1.9550499418656604
Epoch: 9| Step: 16
Training loss: 2.4804906845092773
Validation loss: 1.9728219594886836
Epoch: 9| Step: 17
Training loss: 2.246680974960327
Validation loss: 1.9894474787677792
Epoch: 9| Step: 18
Training loss: 2.057420253753662
Validation loss: 2.0220571799243956
Epoch: 9| Step: 19
Training loss: 1.9281225204467773
Validation loss: 2.0057400971007864
Epoch: 95| Step: 0
Training loss: 2.118530511856079
Validation loss: 2.020989774800033
Epoch: 9| Step: 1
Training loss: 1.4329192638397217
Validation loss: 2.0081182006451725
Epoch: 9| Step: 2
Training loss: 1.6549077033996582
Validation loss: 1.998570834990028
Epoch: 9| Step: 3
Training loss: 2.7866721153259277
Validation loss: 2.0292325877457214
Epoch: 9| Step: 4
Training loss: 2.4883627891540527
Validation loss: 1.9999149660412356
Epoch: 9| Step: 5
Training loss: 1.749500036239624
Validation loss: 2.0385552155885764
Epoch: 9| Step: 6
Training loss: 1.6724600791931152
Validation loss: 2.0276372175422503
Epoch: 9| Step: 7
Training loss: 2.553133249282837
Validation loss: 2.0081328711063744
Epoch: 9| Step: 8
Training loss: 1.8106215000152588
Validation loss: 1.9837469197005677
Epoch: 9| Step: 9
Training loss: 2.132880687713623
Validation loss: 1.9692705346526003
Epoch: 9| Step: 10
Training loss: 1.616915225982666
Validation loss: 2.026345566879931
Epoch: 9| Step: 11
Training loss: 3.16437029838562
Validation loss: 1.9696189842635778
Epoch: 9| Step: 12
Training loss: 1.7338072061538696
Validation loss: 1.9672544577138886
Epoch: 9| Step: 13
Training loss: 2.5716781616210938
Validation loss: 1.9917864868109174
Epoch: 9| Step: 14
Training loss: 1.2811635732650757
Validation loss: 1.99535089259525
Epoch: 9| Step: 15
Training loss: 2.213239908218384
Validation loss: 1.9663205206823007
Epoch: 9| Step: 16
Training loss: 2.392000675201416
Validation loss: 2.022376573343071
Epoch: 9| Step: 17
Training loss: 2.025669574737549
Validation loss: 2.052099934584803
Epoch: 9| Step: 18
Training loss: 1.5213885307312012
Validation loss: 1.9597118569792604
Epoch: 9| Step: 19
Training loss: 1.6479675769805908
Validation loss: 1.9331546378650253
Epoch: 96| Step: 0
Training loss: 1.8753001689910889
Validation loss: 1.9815750756709696
Epoch: 9| Step: 1
Training loss: 2.0657684803009033
Validation loss: 1.9379248318912314
Epoch: 9| Step: 2
Training loss: 1.7773336172103882
Validation loss: 1.9805140735434115
Epoch: 9| Step: 3
Training loss: 2.7212367057800293
Validation loss: 1.9757452585714326
Epoch: 9| Step: 4
Training loss: 2.4658007621765137
Validation loss: 1.9208311185562352
Epoch: 9| Step: 5
Training loss: 2.2749881744384766
Validation loss: 2.0184574015706565
Epoch: 9| Step: 6
Training loss: 2.2411727905273438
Validation loss: 2.014362113938915
Epoch: 9| Step: 7
Training loss: 1.3356473445892334
Validation loss: 1.999053611172189
Epoch: 9| Step: 8
Training loss: 1.583028793334961
Validation loss: 2.0075275177578273
Epoch: 9| Step: 9
Training loss: 1.2707651853561401
Validation loss: 1.9602475800960184
Epoch: 9| Step: 10
Training loss: 1.9968798160552979
Validation loss: 1.964909492636756
Epoch: 9| Step: 11
Training loss: 2.455441951751709
Validation loss: 2.0188798046798158
Epoch: 9| Step: 12
Training loss: 2.2042789459228516
Validation loss: 2.066044948083891
Epoch: 9| Step: 13
Training loss: 1.9185118675231934
Validation loss: 2.0391039505279323
Epoch: 9| Step: 14
Training loss: 2.263876438140869
Validation loss: 1.991517537789379
Epoch: 9| Step: 15
Training loss: 1.6599780321121216
Validation loss: 2.0497578888488333
Epoch: 9| Step: 16
Training loss: 1.2383604049682617
Validation loss: 2.0255774937087683
Epoch: 9| Step: 17
Training loss: 2.3926665782928467
Validation loss: 1.9913644396143853
Epoch: 9| Step: 18
Training loss: 1.9001083374023438
Validation loss: 2.041682772499194
Epoch: 9| Step: 19
Training loss: 2.389495849609375
Validation loss: 1.9109463957573871
Epoch: 97| Step: 0
Training loss: 2.2402915954589844
Validation loss: 2.0903008155685536
Epoch: 9| Step: 1
Training loss: 1.385838508605957
Validation loss: 2.078120019796083
Epoch: 9| Step: 2
Training loss: 2.299799680709839
Validation loss: 1.9771254963154414
Epoch: 9| Step: 3
Training loss: 2.5980005264282227
Validation loss: 1.9455854601139644
Epoch: 9| Step: 4
Training loss: 2.0239837169647217
Validation loss: 1.9782981169309548
Epoch: 9| Step: 5
Training loss: 2.3248963356018066
Validation loss: 2.001379350964114
Epoch: 9| Step: 6
Training loss: 1.881471872329712
Validation loss: 1.9636509487097211
Epoch: 9| Step: 7
Training loss: 1.749040126800537
Validation loss: 1.9473158507038364
Epoch: 9| Step: 8
Training loss: 2.615119218826294
Validation loss: 1.9091188204374245
Epoch: 9| Step: 9
Training loss: 1.9212082624435425
Validation loss: 1.939083938975986
Epoch: 9| Step: 10
Training loss: 2.119825839996338
Validation loss: 1.9263757064188127
Epoch: 9| Step: 11
Training loss: 1.9143671989440918
Validation loss: 1.8952892461269022
Epoch: 9| Step: 12
Training loss: 1.7763769626617432
Validation loss: 1.900722051695954
Epoch: 9| Step: 13
Training loss: 1.3288116455078125
Validation loss: 1.9250652361259186
Epoch: 9| Step: 14
Training loss: 1.5261008739471436
Validation loss: 1.8977654580589678
Epoch: 9| Step: 15
Training loss: 1.6308867931365967
Validation loss: 1.972017967443672
Epoch: 9| Step: 16
Training loss: 1.996617317199707
Validation loss: 1.8937131869707176
Epoch: 9| Step: 17
Training loss: 2.208399534225464
Validation loss: 1.9429629277839935
Epoch: 9| Step: 18
Training loss: 1.6645851135253906
Validation loss: 1.9468606976296405
Epoch: 9| Step: 19
Training loss: 2.140115737915039
Validation loss: 1.921470827335934
Epoch: 98| Step: 0
Training loss: 2.282456398010254
Validation loss: 1.9154947773158122
Epoch: 9| Step: 1
Training loss: 1.863598346710205
Validation loss: 1.9286347704825642
Epoch: 9| Step: 2
Training loss: 1.9947969913482666
Validation loss: 1.9834112546426788
Epoch: 9| Step: 3
Training loss: 2.5135886669158936
Validation loss: 1.9796203872282727
Epoch: 9| Step: 4
Training loss: 1.6737618446350098
Validation loss: 2.0201843342335106
Epoch: 9| Step: 5
Training loss: 2.1641297340393066
Validation loss: 1.9869603733364627
Epoch: 9| Step: 6
Training loss: 2.471808910369873
Validation loss: 1.9953494698023624
Epoch: 9| Step: 7
Training loss: 1.9702298641204834
Validation loss: 2.0295361477694067
Epoch: 9| Step: 8
Training loss: 1.7547978162765503
Validation loss: 1.9932384045003988
Epoch: 9| Step: 9
Training loss: 2.032599687576294
Validation loss: 2.015652371825074
Epoch: 9| Step: 10
Training loss: 2.3869032859802246
Validation loss: 2.0563116442385336
Epoch: 9| Step: 11
Training loss: 1.6097936630249023
Validation loss: 2.0405211071316285
Epoch: 9| Step: 12
Training loss: 1.2787030935287476
Validation loss: 1.9849482508872052
Epoch: 9| Step: 13
Training loss: 2.1688413619995117
Validation loss: 2.0358512615986006
Epoch: 9| Step: 14
Training loss: 2.3335092067718506
Validation loss: 1.9791495422665164
Epoch: 9| Step: 15
Training loss: 1.7231030464172363
Validation loss: 2.014069232151663
Epoch: 9| Step: 16
Training loss: 2.0879135131835938
Validation loss: 2.002688286973418
Epoch: 9| Step: 17
Training loss: 1.782881259918213
Validation loss: 1.987699133029087
Epoch: 9| Step: 18
Training loss: 1.5088037252426147
Validation loss: 1.982892879479223
Epoch: 9| Step: 19
Training loss: 2.492475986480713
Validation loss: 1.9510589838027954
Epoch: 99| Step: 0
Training loss: 1.3779207468032837
Validation loss: 1.9305151983988371
Epoch: 9| Step: 1
Training loss: 2.142151355743408
Validation loss: 1.9727980644582845
Epoch: 9| Step: 2
Training loss: 2.0912718772888184
Validation loss: 2.014715561763846
Epoch: 9| Step: 3
Training loss: 2.0484554767608643
Validation loss: 2.04279490512052
Epoch: 9| Step: 4
Training loss: 1.6252007484436035
Validation loss: 1.9558694534164538
Epoch: 9| Step: 5
Training loss: 2.278532028198242
Validation loss: 1.9758907110571005
Epoch: 9| Step: 6
Training loss: 2.2331953048706055
Validation loss: 2.0105217412221346
Epoch: 9| Step: 7
Training loss: 1.969174861907959
Validation loss: 2.0102528565221554
Epoch: 9| Step: 8
Training loss: 1.4560959339141846
Validation loss: 1.9539994395894111
Epoch: 9| Step: 9
Training loss: 2.007073402404785
Validation loss: 1.9027593873387618
Epoch: 9| Step: 10
Training loss: 2.337212085723877
Validation loss: 1.9609369365431422
Epoch: 9| Step: 11
Training loss: 2.462843179702759
Validation loss: 1.990795151792842
Epoch: 9| Step: 12
Training loss: 1.9391121864318848
Validation loss: 1.9560805121771723
Epoch: 9| Step: 13
Training loss: 2.2831735610961914
Validation loss: 1.9471768749703606
Epoch: 9| Step: 14
Training loss: 1.4760669469833374
Validation loss: 1.9613874833360851
Epoch: 9| Step: 15
Training loss: 2.1464505195617676
Validation loss: 1.959206195186368
Epoch: 9| Step: 16
Training loss: 2.1446897983551025
Validation loss: 1.913296495410178
Epoch: 9| Step: 17
Training loss: 2.151761531829834
Validation loss: 1.9122497375062901
Epoch: 9| Step: 18
Training loss: 2.091820240020752
Validation loss: 1.944767222987662
Epoch: 9| Step: 19
Training loss: 1.9256579875946045
Validation loss: 1.9744504818813406
Epoch: 100| Step: 0
Training loss: 2.8025693893432617
Validation loss: 1.967886140878252
Epoch: 9| Step: 1
Training loss: 2.325631856918335
Validation loss: 1.966497431556098
Epoch: 9| Step: 2
Training loss: 1.8124468326568604
Validation loss: 1.9953327299021988
Epoch: 9| Step: 3
Training loss: 2.36991024017334
Validation loss: 1.984696206429022
Epoch: 9| Step: 4
Training loss: 1.9392129182815552
Validation loss: 1.9569458618438502
Epoch: 9| Step: 5
Training loss: 2.9433279037475586
Validation loss: 1.963274169311249
Epoch: 9| Step: 6
Training loss: 2.227445602416992
Validation loss: 1.979793756128215
Epoch: 9| Step: 7
Training loss: 1.9360206127166748
Validation loss: 1.9977507110979917
Epoch: 9| Step: 8
Training loss: 1.850562572479248
Validation loss: 1.975689784228373
Epoch: 9| Step: 9
Training loss: 1.8958091735839844
Validation loss: 1.9474500229032776
Epoch: 9| Step: 10
Training loss: 1.902271032333374
Validation loss: 1.971743961032346
Epoch: 9| Step: 11
Training loss: 1.4202382564544678
Validation loss: 1.9477118185098223
Epoch: 9| Step: 12
Training loss: 1.451584815979004
Validation loss: 2.007826263098408
Epoch: 9| Step: 13
Training loss: 1.7894331216812134
Validation loss: 1.9565752495964654
Epoch: 9| Step: 14
Training loss: 1.4860607385635376
Validation loss: 1.9519813686823673
Epoch: 9| Step: 15
Training loss: 2.118401050567627
Validation loss: 1.9321873479609868
Epoch: 9| Step: 16
Training loss: 1.6771901845932007
Validation loss: 1.9424381256103516
Epoch: 9| Step: 17
Training loss: 2.1804356575012207
Validation loss: 2.0070210172118044
Epoch: 9| Step: 18
Training loss: 1.561110019683838
Validation loss: 1.979839158572739
Epoch: 9| Step: 19
Training loss: 2.307265520095825
Validation loss: 2.000567062295598
