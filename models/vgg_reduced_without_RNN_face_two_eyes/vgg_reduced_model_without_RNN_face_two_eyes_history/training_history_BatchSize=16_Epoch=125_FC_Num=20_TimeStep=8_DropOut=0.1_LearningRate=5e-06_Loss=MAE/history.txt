Epoch: 1| Step: 0
Training loss: 3.480231285095215
Validation loss: 3.915117859840393

Epoch: 6| Step: 1
Training loss: 4.501936435699463
Validation loss: 3.8886187076568604

Epoch: 6| Step: 2
Training loss: 3.7581634521484375
Validation loss: 3.8586252530415854

Epoch: 6| Step: 3
Training loss: 4.543863296508789
Validation loss: 3.831454594930013

Epoch: 6| Step: 4
Training loss: 4.613374710083008
Validation loss: 3.8076833486557007

Epoch: 6| Step: 5
Training loss: 3.476560354232788
Validation loss: 3.7754486401875815

Epoch: 6| Step: 6
Training loss: 3.6058619022369385
Validation loss: 3.7460235754648843

Epoch: 6| Step: 7
Training loss: 3.2122905254364014
Validation loss: 3.710741559664408

Epoch: 6| Step: 8
Training loss: 4.1861371994018555
Validation loss: 3.6886685689290366

Epoch: 6| Step: 9
Training loss: 3.238473415374756
Validation loss: 3.654052178064982

Epoch: 6| Step: 10
Training loss: 4.0505218505859375
Validation loss: 3.6245630582173667

Epoch: 6| Step: 11
Training loss: 3.4420671463012695
Validation loss: 3.597034772237142

Epoch: 6| Step: 12
Training loss: 4.357476234436035
Validation loss: 3.5678888956705728

Epoch: 6| Step: 13
Training loss: 3.758739709854126
Validation loss: 3.531183441480001

Epoch: 2| Step: 0
Training loss: 3.3187246322631836
Validation loss: 3.5018145640691123

Epoch: 6| Step: 1
Training loss: 4.305621147155762
Validation loss: 3.4677889744440713

Epoch: 6| Step: 2
Training loss: 3.171391010284424
Validation loss: 3.4335956970850625

Epoch: 6| Step: 3
Training loss: 4.16392183303833
Validation loss: 3.398899038632711

Epoch: 6| Step: 4
Training loss: 4.069550514221191
Validation loss: 3.3640106916427612

Epoch: 6| Step: 5
Training loss: 3.6384425163269043
Validation loss: 3.3281258742014566

Epoch: 6| Step: 6
Training loss: 3.2801434993743896
Validation loss: 3.2858962615331015

Epoch: 6| Step: 7
Training loss: 2.8213753700256348
Validation loss: 3.2552011807759604

Epoch: 6| Step: 8
Training loss: 3.178877592086792
Validation loss: 3.2111034393310547

Epoch: 6| Step: 9
Training loss: 3.39247727394104
Validation loss: 3.1791990200678506

Epoch: 6| Step: 10
Training loss: 2.972362995147705
Validation loss: 3.138213872909546

Epoch: 6| Step: 11
Training loss: 2.983889102935791
Validation loss: 3.0936954816182456

Epoch: 6| Step: 12
Training loss: 3.7152514457702637
Validation loss: 3.0493160088857016

Epoch: 6| Step: 13
Training loss: 2.82570481300354
Validation loss: 3.0091011921564736

Epoch: 3| Step: 0
Training loss: 4.020778179168701
Validation loss: 2.972061276435852

Epoch: 6| Step: 1
Training loss: 3.3090476989746094
Validation loss: 2.9228060642878213

Epoch: 6| Step: 2
Training loss: 2.674643039703369
Validation loss: 2.879990816116333

Epoch: 6| Step: 3
Training loss: 2.8304860591888428
Validation loss: 2.8347513675689697

Epoch: 6| Step: 4
Training loss: 2.745326280593872
Validation loss: 2.783599297205607

Epoch: 6| Step: 5
Training loss: 2.420010566711426
Validation loss: 2.7339539527893066

Epoch: 6| Step: 6
Training loss: 2.7864863872528076
Validation loss: 2.6904639403025308

Epoch: 6| Step: 7
Training loss: 2.6000518798828125
Validation loss: 2.629885951677958

Epoch: 6| Step: 8
Training loss: 2.2276782989501953
Validation loss: 2.5848267475763955

Epoch: 6| Step: 9
Training loss: 3.130732297897339
Validation loss: 2.5318384170532227

Epoch: 6| Step: 10
Training loss: 2.187236785888672
Validation loss: 2.477867364883423

Epoch: 6| Step: 11
Training loss: 1.9104981422424316
Validation loss: 2.425804932912191

Epoch: 6| Step: 12
Training loss: 2.277533531188965
Validation loss: 2.3684071699778237

Epoch: 6| Step: 13
Training loss: 3.165478229522705
Validation loss: 2.317314346631368

Epoch: 4| Step: 0
Training loss: 2.0793957710266113
Validation loss: 2.2560351292292276

Epoch: 6| Step: 1
Training loss: 1.8965308666229248
Validation loss: 2.2030234336853027

Epoch: 6| Step: 2
Training loss: 2.2702865600585938
Validation loss: 2.1769184470176697

Epoch: 6| Step: 3
Training loss: 2.2943198680877686
Validation loss: 2.122842868169149

Epoch: 6| Step: 4
Training loss: 2.4438223838806152
Validation loss: 2.09164830048879

Epoch: 6| Step: 5
Training loss: 2.029189348220825
Validation loss: 2.046538511912028

Epoch: 6| Step: 6
Training loss: 1.7425689697265625
Validation loss: 2.0471163789431253

Epoch: 6| Step: 7
Training loss: 2.445002794265747
Validation loss: 2.0264099836349487

Epoch: 6| Step: 8
Training loss: 1.9974510669708252
Validation loss: 1.9911060134569805

Epoch: 6| Step: 9
Training loss: 1.8337477445602417
Validation loss: 2.0026445190111795

Epoch: 6| Step: 10
Training loss: 1.7954987287521362
Validation loss: 2.026025633017222

Epoch: 6| Step: 11
Training loss: 2.4989051818847656
Validation loss: 2.0418745477994285

Epoch: 6| Step: 12
Training loss: 3.039423942565918
Validation loss: 2.0486128330230713

Epoch: 6| Step: 13
Training loss: 2.42935848236084
Validation loss: 2.0579444964726767

Epoch: 5| Step: 0
Training loss: 2.300832986831665
Validation loss: 2.0842463771502175

Epoch: 6| Step: 1
Training loss: 1.9676878452301025
Validation loss: 2.054496109485626

Epoch: 6| Step: 2
Training loss: 1.3321259021759033
Validation loss: 2.07296754916509

Epoch: 6| Step: 3
Training loss: 2.135908365249634
Validation loss: 2.040190100669861

Epoch: 6| Step: 4
Training loss: 2.027285099029541
Validation loss: 2.049219568570455

Epoch: 6| Step: 5
Training loss: 2.0134289264678955
Validation loss: 2.036783536275228

Epoch: 6| Step: 6
Training loss: 1.9151747226715088
Validation loss: 2.040330449740092

Epoch: 6| Step: 7
Training loss: 2.555079460144043
Validation loss: 2.02319343884786

Epoch: 6| Step: 8
Training loss: 2.575860023498535
Validation loss: 2.0037330985069275

Epoch: 6| Step: 9
Training loss: 2.100493907928467
Validation loss: 2.006947616736094

Epoch: 6| Step: 10
Training loss: 1.9035906791687012
Validation loss: 1.9962618350982666

Epoch: 6| Step: 11
Training loss: 1.4167892932891846
Validation loss: 1.9991624355316162

Epoch: 6| Step: 12
Training loss: 2.4710750579833984
Validation loss: 1.9987373352050781

Epoch: 6| Step: 13
Training loss: 1.9460593461990356
Validation loss: 1.9972884853680928

Epoch: 6| Step: 0
Training loss: 1.689727544784546
Validation loss: 2.0034480690956116

Epoch: 6| Step: 1
Training loss: 2.8895695209503174
Validation loss: 1.9888140559196472

Epoch: 6| Step: 2
Training loss: 1.9136477708816528
Validation loss: 2.010833442211151

Epoch: 6| Step: 3
Training loss: 1.715062141418457
Validation loss: 1.9882323741912842

Epoch: 6| Step: 4
Training loss: 2.0906615257263184
Validation loss: 1.9917022387186687

Epoch: 6| Step: 5
Training loss: 3.26688814163208
Validation loss: 1.9838958779970806

Epoch: 6| Step: 6
Training loss: 2.1842169761657715
Validation loss: 1.9945216178894043

Epoch: 6| Step: 7
Training loss: 2.069497585296631
Validation loss: 1.9850402275721233

Epoch: 6| Step: 8
Training loss: 1.8022165298461914
Validation loss: 1.982467512289683

Epoch: 6| Step: 9
Training loss: 1.5233838558197021
Validation loss: 2.000926911830902

Epoch: 6| Step: 10
Training loss: 1.4098715782165527
Validation loss: 1.9882690906524658

Epoch: 6| Step: 11
Training loss: 1.6982638835906982
Validation loss: 1.980634371439616

Epoch: 6| Step: 12
Training loss: 2.0449609756469727
Validation loss: 1.9908481041590373

Epoch: 6| Step: 13
Training loss: 2.269913673400879
Validation loss: 1.998592476050059

Epoch: 7| Step: 0
Training loss: 1.8465666770935059
Validation loss: 1.9878111282984416

Epoch: 6| Step: 1
Training loss: 1.7304458618164062
Validation loss: 1.98814461628596

Epoch: 6| Step: 2
Training loss: 2.170363187789917
Validation loss: 1.9909434914588928

Epoch: 6| Step: 3
Training loss: 2.3293025493621826
Validation loss: 2.000305990378062

Epoch: 6| Step: 4
Training loss: 1.9361751079559326
Validation loss: 2.0097997387250266

Epoch: 6| Step: 5
Training loss: 3.1615099906921387
Validation loss: 2.0123468041419983

Epoch: 6| Step: 6
Training loss: 1.7078408002853394
Validation loss: 2.0146172841389975

Epoch: 6| Step: 7
Training loss: 1.5684826374053955
Validation loss: 2.003720998764038

Epoch: 6| Step: 8
Training loss: 2.0323662757873535
Validation loss: 1.9941973487536113

Epoch: 6| Step: 9
Training loss: 2.213637351989746
Validation loss: 1.989268163839976

Epoch: 6| Step: 10
Training loss: 1.8353333473205566
Validation loss: 1.9880651235580444

Epoch: 6| Step: 11
Training loss: 2.21939754486084
Validation loss: 1.9865288734436035

Epoch: 6| Step: 12
Training loss: 1.8162405490875244
Validation loss: 1.998193085193634

Epoch: 6| Step: 13
Training loss: 2.0089757442474365
Validation loss: 1.9945102334022522

Epoch: 8| Step: 0
Training loss: 2.338104724884033
Validation loss: 1.9950374960899353

Epoch: 6| Step: 1
Training loss: 1.3091044425964355
Validation loss: 1.9764479200045268

Epoch: 6| Step: 2
Training loss: 1.7209711074829102
Validation loss: 1.9756940404574077

Epoch: 6| Step: 3
Training loss: 1.9790276288986206
Validation loss: 1.9794985055923462

Epoch: 6| Step: 4
Training loss: 2.040985345840454
Validation loss: 1.9886961976687114

Epoch: 6| Step: 5
Training loss: 1.6809484958648682
Validation loss: 1.9965724349021912

Epoch: 6| Step: 6
Training loss: 2.110822916030884
Validation loss: 1.9870197176933289

Epoch: 6| Step: 7
Training loss: 2.29032301902771
Validation loss: 1.9782852530479431

Epoch: 6| Step: 8
Training loss: 1.6473312377929688
Validation loss: 1.982628842194875

Epoch: 6| Step: 9
Training loss: 1.90049409866333
Validation loss: 1.9853039185206096

Epoch: 6| Step: 10
Training loss: 1.685226321220398
Validation loss: 1.991259018580119

Epoch: 6| Step: 11
Training loss: 2.3492627143859863
Validation loss: 2.0031931002934775

Epoch: 6| Step: 12
Training loss: 2.6478004455566406
Validation loss: 1.9823790192604065

Epoch: 6| Step: 13
Training loss: 2.70658278465271
Validation loss: 1.9725200931231182

Epoch: 9| Step: 0
Training loss: 1.8417353630065918
Validation loss: 1.9834193189938862

Epoch: 6| Step: 1
Training loss: 1.7504117488861084
Validation loss: 1.9907882610956829

Epoch: 6| Step: 2
Training loss: 2.2036921977996826
Validation loss: 1.9943699439366658

Epoch: 6| Step: 3
Training loss: 2.3119101524353027
Validation loss: 1.9975942174593608

Epoch: 6| Step: 4
Training loss: 1.8519095182418823
Validation loss: 1.9830453991889954

Epoch: 6| Step: 5
Training loss: 2.5141139030456543
Validation loss: 1.975504179795583

Epoch: 6| Step: 6
Training loss: 2.040982484817505
Validation loss: 1.9885746240615845

Epoch: 6| Step: 7
Training loss: 2.0686087608337402
Validation loss: 1.9748432636260986

Epoch: 6| Step: 8
Training loss: 1.4839409589767456
Validation loss: 1.9863500197728474

Epoch: 6| Step: 9
Training loss: 2.248948335647583
Validation loss: 1.9753388166427612

Epoch: 6| Step: 10
Training loss: 2.09011173248291
Validation loss: 1.9918458461761475

Epoch: 6| Step: 11
Training loss: 2.010735511779785
Validation loss: 1.97667795419693

Epoch: 6| Step: 12
Training loss: 1.886379599571228
Validation loss: 1.9814299543698628

Epoch: 6| Step: 13
Training loss: 2.0181400775909424
Validation loss: 1.9705645044644673

Epoch: 10| Step: 0
Training loss: 2.596238613128662
Validation loss: 1.9909114241600037

Epoch: 6| Step: 1
Training loss: 1.561929702758789
Validation loss: 1.969250241915385

Epoch: 6| Step: 2
Training loss: 2.1290359497070312
Validation loss: 1.9651485085487366

Epoch: 6| Step: 3
Training loss: 1.8978450298309326
Validation loss: 1.9763838450113933

Epoch: 6| Step: 4
Training loss: 1.7000725269317627
Validation loss: 1.975251038869222

Epoch: 6| Step: 5
Training loss: 1.8105179071426392
Validation loss: 1.9847042163213093

Epoch: 6| Step: 6
Training loss: 2.419478178024292
Validation loss: 1.9760714371999104

Epoch: 6| Step: 7
Training loss: 2.332642078399658
Validation loss: 1.9906526605288188

Epoch: 6| Step: 8
Training loss: 1.3763339519500732
Validation loss: 1.9952271580696106

Epoch: 6| Step: 9
Training loss: 2.174551010131836
Validation loss: 1.974520246187846

Epoch: 6| Step: 10
Training loss: 1.740457534790039
Validation loss: 1.9757514595985413

Epoch: 6| Step: 11
Training loss: 1.6660431623458862
Validation loss: 1.9838141798973083

Epoch: 6| Step: 12
Training loss: 2.515592575073242
Validation loss: 1.9859000245730083

Epoch: 6| Step: 13
Training loss: 2.3001515865325928
Validation loss: 1.9647574424743652

Epoch: 11| Step: 0
Training loss: 2.4697442054748535
Validation loss: 1.9790035287539165

Epoch: 6| Step: 1
Training loss: 2.074338912963867
Validation loss: 1.9661829074223836

Epoch: 6| Step: 2
Training loss: 2.493856430053711
Validation loss: 1.978826145331065

Epoch: 6| Step: 3
Training loss: 2.2198197841644287
Validation loss: 1.9633745352427165

Epoch: 6| Step: 4
Training loss: 2.287149429321289
Validation loss: 1.9561524589856465

Epoch: 6| Step: 5
Training loss: 1.4451833963394165
Validation loss: 1.9691034356753032

Epoch: 6| Step: 6
Training loss: 1.459148645401001
Validation loss: 1.9673277735710144

Epoch: 6| Step: 7
Training loss: 1.9220927953720093
Validation loss: 1.9733189741770427

Epoch: 6| Step: 8
Training loss: 2.2368383407592773
Validation loss: 1.9691943128903706

Epoch: 6| Step: 9
Training loss: 1.8503668308258057
Validation loss: 1.9609873096148174

Epoch: 6| Step: 10
Training loss: 2.2624852657318115
Validation loss: 1.9769327839215596

Epoch: 6| Step: 11
Training loss: 1.125044345855713
Validation loss: 1.9730019768079121

Epoch: 6| Step: 12
Training loss: 2.0068657398223877
Validation loss: 1.969235599040985

Epoch: 6| Step: 13
Training loss: 2.1975574493408203
Validation loss: 1.9746559262275696

Epoch: 12| Step: 0
Training loss: 1.603543996810913
Validation loss: 1.9954940478007

Epoch: 6| Step: 1
Training loss: 2.0743021965026855
Validation loss: 1.9885048667589824

Epoch: 6| Step: 2
Training loss: 1.564317226409912
Validation loss: 2.002379536628723

Epoch: 6| Step: 3
Training loss: 2.862105369567871
Validation loss: 1.9881244897842407

Epoch: 6| Step: 4
Training loss: 1.6996898651123047
Validation loss: 1.9722437858581543

Epoch: 6| Step: 5
Training loss: 2.2215933799743652
Validation loss: 1.988436996936798

Epoch: 6| Step: 6
Training loss: 1.5106459856033325
Validation loss: 1.9623594681421916

Epoch: 6| Step: 7
Training loss: 1.5722246170043945
Validation loss: 1.9669427275657654

Epoch: 6| Step: 8
Training loss: 1.8891903162002563
Validation loss: 1.9809753100077312

Epoch: 6| Step: 9
Training loss: 2.0060646533966064
Validation loss: 1.9524244666099548

Epoch: 6| Step: 10
Training loss: 2.0829339027404785
Validation loss: 1.9729455312093098

Epoch: 6| Step: 11
Training loss: 2.471571207046509
Validation loss: 1.9880754351615906

Epoch: 6| Step: 12
Training loss: 2.066298246383667
Validation loss: 1.99496191740036

Epoch: 6| Step: 13
Training loss: 2.4503867626190186
Validation loss: 1.9983926018079121

Epoch: 13| Step: 0
Training loss: 1.9723620414733887
Validation loss: 1.9955871105194092

Epoch: 6| Step: 1
Training loss: 2.371771812438965
Validation loss: 1.9733323057492573

Epoch: 6| Step: 2
Training loss: 2.014232635498047
Validation loss: 1.9972317218780518

Epoch: 6| Step: 3
Training loss: 1.8095731735229492
Validation loss: 1.9848565657933552

Epoch: 6| Step: 4
Training loss: 1.8132590055465698
Validation loss: 1.995894769827525

Epoch: 6| Step: 5
Training loss: 2.0371501445770264
Validation loss: 1.9886419773101807

Epoch: 6| Step: 6
Training loss: 2.0080606937408447
Validation loss: 1.981277306874593

Epoch: 6| Step: 7
Training loss: 2.2657361030578613
Validation loss: 1.9968879024187725

Epoch: 6| Step: 8
Training loss: 1.8074333667755127
Validation loss: 1.9790412386258442

Epoch: 6| Step: 9
Training loss: 2.395052433013916
Validation loss: 1.9889421065648396

Epoch: 6| Step: 10
Training loss: 2.0300252437591553
Validation loss: 1.9958730737368267

Epoch: 6| Step: 11
Training loss: 1.6566441059112549
Validation loss: 1.9869727889696758

Epoch: 6| Step: 12
Training loss: 1.4569618701934814
Validation loss: 1.9920098384221394

Epoch: 6| Step: 13
Training loss: 2.23417067527771
Validation loss: 2.0029253562291465

Epoch: 14| Step: 0
Training loss: 1.5762393474578857
Validation loss: 1.9730880657831829

Epoch: 6| Step: 1
Training loss: 1.4003854990005493
Validation loss: 1.9795638124148052

Epoch: 6| Step: 2
Training loss: 2.5953330993652344
Validation loss: 1.971673270066579

Epoch: 6| Step: 3
Training loss: 1.8161128759384155
Validation loss: 1.9793662230173747

Epoch: 6| Step: 4
Training loss: 2.1016950607299805
Validation loss: 1.9670183062553406

Epoch: 6| Step: 5
Training loss: 2.223956346511841
Validation loss: 1.9622198343276978

Epoch: 6| Step: 6
Training loss: 2.356602191925049
Validation loss: 1.9703132112820942

Epoch: 6| Step: 7
Training loss: 1.8564541339874268
Validation loss: 1.9682229955991108

Epoch: 6| Step: 8
Training loss: 2.1977386474609375
Validation loss: 1.9663191437721252

Epoch: 6| Step: 9
Training loss: 1.971587896347046
Validation loss: 1.9854482611020405

Epoch: 6| Step: 10
Training loss: 1.9397093057632446
Validation loss: 1.9858754674593608

Epoch: 6| Step: 11
Training loss: 1.8045673370361328
Validation loss: 1.9874511361122131

Epoch: 6| Step: 12
Training loss: 1.7007734775543213
Validation loss: 1.982073187828064

Epoch: 6| Step: 13
Training loss: 2.182971239089966
Validation loss: 2.0022048354148865

Epoch: 15| Step: 0
Training loss: 1.578782081604004
Validation loss: 1.9653711517651875

Epoch: 6| Step: 1
Training loss: 1.3102924823760986
Validation loss: 1.9745986660321553

Epoch: 6| Step: 2
Training loss: 1.7857718467712402
Validation loss: 1.9765620231628418

Epoch: 6| Step: 3
Training loss: 2.036968946456909
Validation loss: 1.9704505602518718

Epoch: 6| Step: 4
Training loss: 2.231832504272461
Validation loss: 1.957169493039449

Epoch: 6| Step: 5
Training loss: 1.7721872329711914
Validation loss: 1.9730778932571411

Epoch: 6| Step: 6
Training loss: 1.5490412712097168
Validation loss: 1.9489771922429402

Epoch: 6| Step: 7
Training loss: 2.740997791290283
Validation loss: 1.9582828084627788

Epoch: 6| Step: 8
Training loss: 1.5403132438659668
Validation loss: 1.9739143053690593

Epoch: 6| Step: 9
Training loss: 2.169504165649414
Validation loss: 1.966121753056844

Epoch: 6| Step: 10
Training loss: 2.301175355911255
Validation loss: 1.9625381032625835

Epoch: 6| Step: 11
Training loss: 2.5832362174987793
Validation loss: 1.9732792576154072

Epoch: 6| Step: 12
Training loss: 2.0703201293945312
Validation loss: 1.95903875430425

Epoch: 6| Step: 13
Training loss: 2.0108540058135986
Validation loss: 1.9696566263834636

Epoch: 16| Step: 0
Training loss: 2.1859512329101562
Validation loss: 1.956160267194112

Epoch: 6| Step: 1
Training loss: 1.6880364418029785
Validation loss: 1.970917324225108

Epoch: 6| Step: 2
Training loss: 2.147752285003662
Validation loss: 1.9571029543876648

Epoch: 6| Step: 3
Training loss: 1.6742353439331055
Validation loss: 1.9556905428568523

Epoch: 6| Step: 4
Training loss: 1.9376699924468994
Validation loss: 1.9784243901570637

Epoch: 6| Step: 5
Training loss: 2.3642611503601074
Validation loss: 1.9775752623875935

Epoch: 6| Step: 6
Training loss: 1.67534601688385
Validation loss: 1.9810681144396465

Epoch: 6| Step: 7
Training loss: 2.0303096771240234
Validation loss: 1.9682695468266804

Epoch: 6| Step: 8
Training loss: 1.8328351974487305
Validation loss: 1.971186896165212

Epoch: 6| Step: 9
Training loss: 2.123882532119751
Validation loss: 1.9688378969828289

Epoch: 6| Step: 10
Training loss: 1.797644853591919
Validation loss: 1.9738553762435913

Epoch: 6| Step: 11
Training loss: 1.8302241563796997
Validation loss: 1.9808950821558635

Epoch: 6| Step: 12
Training loss: 2.0518417358398438
Validation loss: 1.975331425666809

Epoch: 6| Step: 13
Training loss: 2.1192257404327393
Validation loss: 1.996638337771098

Epoch: 17| Step: 0
Training loss: 1.4278526306152344
Validation loss: 2.002632816632589

Epoch: 6| Step: 1
Training loss: 2.2715046405792236
Validation loss: 2.0076522628466287

Epoch: 6| Step: 2
Training loss: 2.077725410461426
Validation loss: 1.9924481908480327

Epoch: 6| Step: 3
Training loss: 1.8578693866729736
Validation loss: 2.0034311413764954

Epoch: 6| Step: 4
Training loss: 1.5264892578125
Validation loss: 2.019372363885244

Epoch: 6| Step: 5
Training loss: 1.7955161333084106
Validation loss: 2.0402506987253823

Epoch: 6| Step: 6
Training loss: 2.298548460006714
Validation loss: 2.0230704148610434

Epoch: 6| Step: 7
Training loss: 2.211219072341919
Validation loss: 2.017725666364034

Epoch: 6| Step: 8
Training loss: 2.776984691619873
Validation loss: 2.0040355126063027

Epoch: 6| Step: 9
Training loss: 1.8078460693359375
Validation loss: 1.9913657307624817

Epoch: 6| Step: 10
Training loss: 1.50942063331604
Validation loss: 1.9774341384569805

Epoch: 6| Step: 11
Training loss: 2.3748841285705566
Validation loss: 1.9659656683603923

Epoch: 6| Step: 12
Training loss: 1.9349937438964844
Validation loss: 1.9605109691619873

Epoch: 6| Step: 13
Training loss: 1.4658879041671753
Validation loss: 1.9604242245356243

Epoch: 18| Step: 0
Training loss: 2.3882036209106445
Validation loss: 1.952614188194275

Epoch: 6| Step: 1
Training loss: 1.9243314266204834
Validation loss: 1.949498991171519

Epoch: 6| Step: 2
Training loss: 1.4568028450012207
Validation loss: 1.9500574668248494

Epoch: 6| Step: 3
Training loss: 1.6618123054504395
Validation loss: 1.960315505663554

Epoch: 6| Step: 4
Training loss: 2.2219502925872803
Validation loss: 1.9690337975819905

Epoch: 6| Step: 5
Training loss: 2.033191680908203
Validation loss: 1.9766748746236165

Epoch: 6| Step: 6
Training loss: 2.182121753692627
Validation loss: 1.9756307005882263

Epoch: 6| Step: 7
Training loss: 1.9758563041687012
Validation loss: 1.9495304028193157

Epoch: 6| Step: 8
Training loss: 1.6945135593414307
Validation loss: 1.9687604109446208

Epoch: 6| Step: 9
Training loss: 2.0007786750793457
Validation loss: 1.960282842318217

Epoch: 6| Step: 10
Training loss: 1.912071943283081
Validation loss: 1.9584299325942993

Epoch: 6| Step: 11
Training loss: 2.1204471588134766
Validation loss: 1.9578503767649333

Epoch: 6| Step: 12
Training loss: 2.001753330230713
Validation loss: 1.953713635603587

Epoch: 6| Step: 13
Training loss: 2.312838315963745
Validation loss: 1.9684927066167195

Epoch: 19| Step: 0
Training loss: 2.373685598373413
Validation loss: 1.9596279462178547

Epoch: 6| Step: 1
Training loss: 1.4843391180038452
Validation loss: 1.9605339964230855

Epoch: 6| Step: 2
Training loss: 1.959505319595337
Validation loss: 1.9550634423891704

Epoch: 6| Step: 3
Training loss: 2.8394317626953125
Validation loss: 1.9641479849815369

Epoch: 6| Step: 4
Training loss: 1.4856985807418823
Validation loss: 1.9698609709739685

Epoch: 6| Step: 5
Training loss: 1.9627025127410889
Validation loss: 1.988241453965505

Epoch: 6| Step: 6
Training loss: 1.7778286933898926
Validation loss: 1.9976274768511455

Epoch: 6| Step: 7
Training loss: 1.2349931001663208
Validation loss: 2.013047695159912

Epoch: 6| Step: 8
Training loss: 2.1808104515075684
Validation loss: 2.021756192048391

Epoch: 6| Step: 9
Training loss: 2.085573196411133
Validation loss: 2.0279729763666787

Epoch: 6| Step: 10
Training loss: 2.2973885536193848
Validation loss: 2.056004742781321

Epoch: 6| Step: 11
Training loss: 1.963985800743103
Validation loss: 2.0467851161956787

Epoch: 6| Step: 12
Training loss: 2.401899814605713
Validation loss: 2.052598536014557

Epoch: 6| Step: 13
Training loss: 1.8195929527282715
Validation loss: 2.046990394592285

Epoch: 20| Step: 0
Training loss: 2.5779197216033936
Validation loss: 2.0094945828119912

Epoch: 6| Step: 1
Training loss: 1.39743971824646
Validation loss: 2.0060431559880576

Epoch: 6| Step: 2
Training loss: 1.7691893577575684
Validation loss: 1.9705891609191895

Epoch: 6| Step: 3
Training loss: 1.2708802223205566
Validation loss: 1.9709901213645935

Epoch: 6| Step: 4
Training loss: 1.8955559730529785
Validation loss: 1.9616790016492207

Epoch: 6| Step: 5
Training loss: 1.9860754013061523
Validation loss: 1.954550862312317

Epoch: 6| Step: 6
Training loss: 2.0494165420532227
Validation loss: 1.947702964146932

Epoch: 6| Step: 7
Training loss: 1.6829240322113037
Validation loss: 1.9415149490038555

Epoch: 6| Step: 8
Training loss: 2.602511405944824
Validation loss: 1.9401610294977825

Epoch: 6| Step: 9
Training loss: 1.9738695621490479
Validation loss: 1.9595184524854024

Epoch: 6| Step: 10
Training loss: 1.9021214246749878
Validation loss: 1.9515505234400432

Epoch: 6| Step: 11
Training loss: 2.082597017288208
Validation loss: 1.9410072565078735

Epoch: 6| Step: 12
Training loss: 2.28297758102417
Validation loss: 1.943912108739217

Epoch: 6| Step: 13
Training loss: 2.1203572750091553
Validation loss: 1.9392715096473694

Epoch: 21| Step: 0
Training loss: 1.6974856853485107
Validation loss: 1.9393826723098755

Epoch: 6| Step: 1
Training loss: 2.1726527214050293
Validation loss: 1.9479262828826904

Epoch: 6| Step: 2
Training loss: 2.462519407272339
Validation loss: 1.9608978827794392

Epoch: 6| Step: 3
Training loss: 2.136059045791626
Validation loss: 1.9574292302131653

Epoch: 6| Step: 4
Training loss: 1.0183552503585815
Validation loss: 1.9625005722045898

Epoch: 6| Step: 5
Training loss: 1.6929073333740234
Validation loss: 1.9705970287322998

Epoch: 6| Step: 6
Training loss: 1.248877763748169
Validation loss: 1.9762751658757527

Epoch: 6| Step: 7
Training loss: 2.760124921798706
Validation loss: 1.975909133752187

Epoch: 6| Step: 8
Training loss: 1.917550802230835
Validation loss: 1.9953446785608928

Epoch: 6| Step: 9
Training loss: 2.160576581954956
Validation loss: 1.9917200207710266

Epoch: 6| Step: 10
Training loss: 1.993200421333313
Validation loss: 2.0050538778305054

Epoch: 6| Step: 11
Training loss: 2.7094478607177734
Validation loss: 2.0156068007151284

Epoch: 6| Step: 12
Training loss: 1.6878434419631958
Validation loss: 2.0043006340662637

Epoch: 6| Step: 13
Training loss: 1.8206772804260254
Validation loss: 2.010204017162323

Epoch: 22| Step: 0
Training loss: 1.895002841949463
Validation loss: 2.0047404170036316

Epoch: 6| Step: 1
Training loss: 1.6392066478729248
Validation loss: 1.9941049218177795

Epoch: 6| Step: 2
Training loss: 1.4946808815002441
Validation loss: 1.9916265606880188

Epoch: 6| Step: 3
Training loss: 1.1947038173675537
Validation loss: 1.9876449902852376

Epoch: 6| Step: 4
Training loss: 2.8070104122161865
Validation loss: 2.0040650367736816

Epoch: 6| Step: 5
Training loss: 2.056532859802246
Validation loss: 1.9798609217007954

Epoch: 6| Step: 6
Training loss: 1.8208835124969482
Validation loss: 1.9938808878262837

Epoch: 6| Step: 7
Training loss: 1.859430193901062
Validation loss: 1.981418530146281

Epoch: 6| Step: 8
Training loss: 2.090587615966797
Validation loss: 1.9797694683074951

Epoch: 6| Step: 9
Training loss: 2.2318525314331055
Validation loss: 1.962101678053538

Epoch: 6| Step: 10
Training loss: 2.387294292449951
Validation loss: 1.9519605835278828

Epoch: 6| Step: 11
Training loss: 2.1914591789245605
Validation loss: 1.9579888979593914

Epoch: 6| Step: 12
Training loss: 1.599459171295166
Validation loss: 1.9553762276967366

Epoch: 6| Step: 13
Training loss: 1.9682409763336182
Validation loss: 1.9532457391421

Epoch: 23| Step: 0
Training loss: 2.5413973331451416
Validation loss: 1.9533488353093464

Epoch: 6| Step: 1
Training loss: 1.7992539405822754
Validation loss: 1.9429943561553955

Epoch: 6| Step: 2
Training loss: 1.2939666509628296
Validation loss: 1.9564889073371887

Epoch: 6| Step: 3
Training loss: 1.801664113998413
Validation loss: 1.9476316372553508

Epoch: 6| Step: 4
Training loss: 1.9915425777435303
Validation loss: 1.9509939352671306

Epoch: 6| Step: 5
Training loss: 1.9870327711105347
Validation loss: 1.945229172706604

Epoch: 6| Step: 6
Training loss: 1.9704434871673584
Validation loss: 1.9546248118082683

Epoch: 6| Step: 7
Training loss: 1.9078619480133057
Validation loss: 1.952008068561554

Epoch: 6| Step: 8
Training loss: 2.4086101055145264
Validation loss: 1.9386816223462422

Epoch: 6| Step: 9
Training loss: 1.8257710933685303
Validation loss: 1.962534765402476

Epoch: 6| Step: 10
Training loss: 2.0998215675354004
Validation loss: 1.9638799627621968

Epoch: 6| Step: 11
Training loss: 1.8165353536605835
Validation loss: 1.9608672559261322

Epoch: 6| Step: 12
Training loss: 2.159043788909912
Validation loss: 1.987668752670288

Epoch: 6| Step: 13
Training loss: 1.60276460647583
Validation loss: 1.974552035331726

Epoch: 24| Step: 0
Training loss: 1.7665601968765259
Validation loss: 2.005473534266154

Epoch: 6| Step: 1
Training loss: 1.9167286157608032
Validation loss: 2.000718673070272

Epoch: 6| Step: 2
Training loss: 1.7179266214370728
Validation loss: 1.9807119965553284

Epoch: 6| Step: 3
Training loss: 2.6081953048706055
Validation loss: 1.9899022380510967

Epoch: 6| Step: 4
Training loss: 2.830103874206543
Validation loss: 2.033860901991526

Epoch: 6| Step: 5
Training loss: 1.5844075679779053
Validation loss: 2.0212367177009583

Epoch: 6| Step: 6
Training loss: 1.766735553741455
Validation loss: 2.0290690859158835

Epoch: 6| Step: 7
Training loss: 1.7784583568572998
Validation loss: 2.026810626188914

Epoch: 6| Step: 8
Training loss: 1.8601778745651245
Validation loss: 2.019775927066803

Epoch: 6| Step: 9
Training loss: 2.236175537109375
Validation loss: 2.004668394724528

Epoch: 6| Step: 10
Training loss: 1.4645118713378906
Validation loss: 1.9954880873362224

Epoch: 6| Step: 11
Training loss: 2.1156182289123535
Validation loss: 1.9871870477994282

Epoch: 6| Step: 12
Training loss: 2.091831922531128
Validation loss: 1.9551366766293843

Epoch: 6| Step: 13
Training loss: 1.6785656213760376
Validation loss: 1.9387162725130718

Epoch: 25| Step: 0
Training loss: 1.6407066583633423
Validation loss: 1.9500845273335774

Epoch: 6| Step: 1
Training loss: 2.239330768585205
Validation loss: 1.9340195655822754

Epoch: 6| Step: 2
Training loss: 1.5055866241455078
Validation loss: 1.9442806243896484

Epoch: 6| Step: 3
Training loss: 2.5918874740600586
Validation loss: 1.941573719183604

Epoch: 6| Step: 4
Training loss: 1.6033884286880493
Validation loss: 1.9387445251146953

Epoch: 6| Step: 5
Training loss: 1.5270417928695679
Validation loss: 1.9410061637560527

Epoch: 6| Step: 6
Training loss: 2.3232040405273438
Validation loss: 1.9439218640327454

Epoch: 6| Step: 7
Training loss: 1.8751718997955322
Validation loss: 1.9519602457682292

Epoch: 6| Step: 8
Training loss: 2.0172934532165527
Validation loss: 1.962341884771983

Epoch: 6| Step: 9
Training loss: 2.288119077682495
Validation loss: 1.9376619855562847

Epoch: 6| Step: 10
Training loss: 2.0280563831329346
Validation loss: 1.950389603773753

Epoch: 6| Step: 11
Training loss: 1.3467378616333008
Validation loss: 1.9371562600135803

Epoch: 6| Step: 12
Training loss: 2.0019657611846924
Validation loss: 1.9438436031341553

Epoch: 6| Step: 13
Training loss: 2.2606678009033203
Validation loss: 1.95180082321167

Epoch: 26| Step: 0
Training loss: 1.373302936553955
Validation loss: 1.9465476870536804

Epoch: 6| Step: 1
Training loss: 1.690056324005127
Validation loss: 1.9632143179575603

Epoch: 6| Step: 2
Training loss: 2.882089138031006
Validation loss: 1.9887220462163289

Epoch: 6| Step: 3
Training loss: 1.7409498691558838
Validation loss: 1.9984654982884724

Epoch: 6| Step: 4
Training loss: 1.784481167793274
Validation loss: 2.002816677093506

Epoch: 6| Step: 5
Training loss: 1.871504306793213
Validation loss: 2.0205646753311157

Epoch: 6| Step: 6
Training loss: 1.4108682870864868
Validation loss: 2.0419081250826516

Epoch: 6| Step: 7
Training loss: 2.483948230743408
Validation loss: 2.054124037424723

Epoch: 6| Step: 8
Training loss: 2.0173678398132324
Validation loss: 2.0373728473981223

Epoch: 6| Step: 9
Training loss: 1.5322136878967285
Validation loss: 2.0206481218338013

Epoch: 6| Step: 10
Training loss: 1.3906968832015991
Validation loss: 1.9909250537554424

Epoch: 6| Step: 11
Training loss: 2.736243724822998
Validation loss: 1.985314428806305

Epoch: 6| Step: 12
Training loss: 2.2972185611724854
Validation loss: 1.9636129935582478

Epoch: 6| Step: 13
Training loss: 2.206371307373047
Validation loss: 1.9538320899009705

Epoch: 27| Step: 0
Training loss: 1.4868626594543457
Validation loss: 1.9322181940078735

Epoch: 6| Step: 1
Training loss: 1.6958668231964111
Validation loss: 1.9406384825706482

Epoch: 6| Step: 2
Training loss: 1.680646538734436
Validation loss: 1.9395917256673176

Epoch: 6| Step: 3
Training loss: 1.994002103805542
Validation loss: 1.9420461455980937

Epoch: 6| Step: 4
Training loss: 1.7814292907714844
Validation loss: 1.9483986496925354

Epoch: 6| Step: 5
Training loss: 2.1743392944335938
Validation loss: 1.9497725168863933

Epoch: 6| Step: 6
Training loss: 1.994969367980957
Validation loss: 1.9505850076675415

Epoch: 6| Step: 7
Training loss: 1.8769423961639404
Validation loss: 1.9412258466084797

Epoch: 6| Step: 8
Training loss: 2.0662121772766113
Validation loss: 1.9414817889531453

Epoch: 6| Step: 9
Training loss: 1.5101778507232666
Validation loss: 1.945441464583079

Epoch: 6| Step: 10
Training loss: 1.9781441688537598
Validation loss: 1.930781900882721

Epoch: 6| Step: 11
Training loss: 3.0095882415771484
Validation loss: 1.936052401860555

Epoch: 6| Step: 12
Training loss: 1.823272466659546
Validation loss: 1.9453391432762146

Epoch: 6| Step: 13
Training loss: 2.192335605621338
Validation loss: 1.9502164125442505

Epoch: 28| Step: 0
Training loss: 1.788537621498108
Validation loss: 1.9664102792739868

Epoch: 6| Step: 1
Training loss: 2.089388847351074
Validation loss: 1.9728267590204875

Epoch: 6| Step: 2
Training loss: 1.9453411102294922
Validation loss: 1.9713692267735798

Epoch: 6| Step: 3
Training loss: 2.2813720703125
Validation loss: 1.9770522713661194

Epoch: 6| Step: 4
Training loss: 2.270303249359131
Validation loss: 1.9774256547292073

Epoch: 6| Step: 5
Training loss: 1.5504035949707031
Validation loss: 1.9500416119893391

Epoch: 6| Step: 6
Training loss: 1.6021164655685425
Validation loss: 1.979510982831319

Epoch: 6| Step: 7
Training loss: 1.87092125415802
Validation loss: 1.9680786331494649

Epoch: 6| Step: 8
Training loss: 2.359013319015503
Validation loss: 1.975955565770467

Epoch: 6| Step: 9
Training loss: 1.6180819272994995
Validation loss: 1.9827044208844502

Epoch: 6| Step: 10
Training loss: 1.362972617149353
Validation loss: 1.9566285808881123

Epoch: 6| Step: 11
Training loss: 1.8524141311645508
Validation loss: 1.9336848258972168

Epoch: 6| Step: 12
Training loss: 2.231205940246582
Validation loss: 1.9628304640452068

Epoch: 6| Step: 13
Training loss: 2.012205123901367
Validation loss: 1.9702202479044597

Epoch: 29| Step: 0
Training loss: 2.3552939891815186
Validation loss: 1.9623762766520183

Epoch: 6| Step: 1
Training loss: 2.7170300483703613
Validation loss: 1.9786808490753174

Epoch: 6| Step: 2
Training loss: 1.3929870128631592
Validation loss: 2.001496990521749

Epoch: 6| Step: 3
Training loss: 1.988010048866272
Validation loss: 2.0044686595598855

Epoch: 6| Step: 4
Training loss: 1.8050280809402466
Validation loss: 2.022847294807434

Epoch: 6| Step: 5
Training loss: 2.0508804321289062
Validation loss: 1.9979858597119649

Epoch: 6| Step: 6
Training loss: 1.5886120796203613
Validation loss: 1.9866896470387776

Epoch: 6| Step: 7
Training loss: 1.5267637968063354
Validation loss: 2.017889360586802

Epoch: 6| Step: 8
Training loss: 2.450392961502075
Validation loss: 1.9639533360799153

Epoch: 6| Step: 9
Training loss: 1.1608500480651855
Validation loss: 1.9656355579694111

Epoch: 6| Step: 10
Training loss: 2.062140464782715
Validation loss: 1.9535263975461323

Epoch: 6| Step: 11
Training loss: 1.824457049369812
Validation loss: 1.9538306792577107

Epoch: 6| Step: 12
Training loss: 1.9549024105072021
Validation loss: 1.9558959603309631

Epoch: 6| Step: 13
Training loss: 1.8092927932739258
Validation loss: 1.9704572359720867

Epoch: 30| Step: 0
Training loss: 2.066591262817383
Validation loss: 1.9627229571342468

Epoch: 6| Step: 1
Training loss: 2.0867905616760254
Validation loss: 1.9384274284044902

Epoch: 6| Step: 2
Training loss: 1.8685102462768555
Validation loss: 1.9530837535858154

Epoch: 6| Step: 3
Training loss: 1.051713228225708
Validation loss: 1.9594695369402568

Epoch: 6| Step: 4
Training loss: 1.8012144565582275
Validation loss: 1.945552388827006

Epoch: 6| Step: 5
Training loss: 1.9263274669647217
Validation loss: 1.9474090735117595

Epoch: 6| Step: 6
Training loss: 1.8330177068710327
Validation loss: 1.9466893871625264

Epoch: 6| Step: 7
Training loss: 1.9627115726470947
Validation loss: 1.9523479342460632

Epoch: 6| Step: 8
Training loss: 2.01735520362854
Validation loss: 1.9528251886367798

Epoch: 6| Step: 9
Training loss: 1.6530979871749878
Validation loss: 1.9654876589775085

Epoch: 6| Step: 10
Training loss: 2.2352943420410156
Validation loss: 1.952738881111145

Epoch: 6| Step: 11
Training loss: 1.714594841003418
Validation loss: 1.93704758087794

Epoch: 6| Step: 12
Training loss: 2.224553108215332
Validation loss: 1.9349082907040913

Epoch: 6| Step: 13
Training loss: 2.299025058746338
Validation loss: 1.939083198706309

Epoch: 31| Step: 0
Training loss: 1.641249656677246
Validation loss: 1.955253501733144

Epoch: 6| Step: 1
Training loss: 2.301821708679199
Validation loss: 1.9648150602976482

Epoch: 6| Step: 2
Training loss: 1.6141020059585571
Validation loss: 1.9817988276481628

Epoch: 6| Step: 3
Training loss: 2.2919623851776123
Validation loss: 2.002218266328176

Epoch: 6| Step: 4
Training loss: 1.744493842124939
Validation loss: 1.9923551281293232

Epoch: 6| Step: 5
Training loss: 1.6341253519058228
Validation loss: 1.996243158976237

Epoch: 6| Step: 6
Training loss: 2.1085052490234375
Validation loss: 1.9724082549413045

Epoch: 6| Step: 7
Training loss: 1.86326265335083
Validation loss: 1.992393175760905

Epoch: 6| Step: 8
Training loss: 2.7997570037841797
Validation loss: 1.994771679242452

Epoch: 6| Step: 9
Training loss: 1.5053861141204834
Validation loss: 1.9672963619232178

Epoch: 6| Step: 10
Training loss: 1.7336233854293823
Validation loss: 1.9453193545341492

Epoch: 6| Step: 11
Training loss: 1.9978147745132446
Validation loss: 1.9447522163391113

Epoch: 6| Step: 12
Training loss: 1.8435673713684082
Validation loss: 1.9516687790552776

Epoch: 6| Step: 13
Training loss: 1.7963556051254272
Validation loss: 1.9439553221066792

Epoch: 32| Step: 0
Training loss: 1.8160756826400757
Validation loss: 1.9536876777807872

Epoch: 6| Step: 1
Training loss: 2.2777624130249023
Validation loss: 1.9567800760269165

Epoch: 6| Step: 2
Training loss: 2.2114686965942383
Validation loss: 1.9439268509546916

Epoch: 6| Step: 3
Training loss: 1.4131884574890137
Validation loss: 1.9425302346547444

Epoch: 6| Step: 4
Training loss: 2.0354018211364746
Validation loss: 1.9424998958905537

Epoch: 6| Step: 5
Training loss: 1.6600990295410156
Validation loss: 1.9396874904632568

Epoch: 6| Step: 6
Training loss: 1.7036237716674805
Validation loss: 1.9307476083437602

Epoch: 6| Step: 7
Training loss: 1.6435059309005737
Validation loss: 1.9315412839253743

Epoch: 6| Step: 8
Training loss: 2.1124815940856934
Validation loss: 1.9463521043459575

Epoch: 6| Step: 9
Training loss: 2.1885881423950195
Validation loss: 1.957216242949168

Epoch: 6| Step: 10
Training loss: 1.7789180278778076
Validation loss: 1.9774749080340068

Epoch: 6| Step: 11
Training loss: 1.8969109058380127
Validation loss: 1.9653451840082805

Epoch: 6| Step: 12
Training loss: 1.8670649528503418
Validation loss: 1.9865642587343852

Epoch: 6| Step: 13
Training loss: 2.1486716270446777
Validation loss: 2.004648963610331

Epoch: 33| Step: 0
Training loss: 1.5604641437530518
Validation loss: 1.9976606567700703

Epoch: 6| Step: 1
Training loss: 2.067122220993042
Validation loss: 1.9940082629521687

Epoch: 6| Step: 2
Training loss: 1.7441191673278809
Validation loss: 1.997047742207845

Epoch: 6| Step: 3
Training loss: 2.0703463554382324
Validation loss: 1.9893025358517964

Epoch: 6| Step: 4
Training loss: 1.6186859607696533
Validation loss: 1.9793532689412434

Epoch: 6| Step: 5
Training loss: 1.907087802886963
Validation loss: 1.9796857833862305

Epoch: 6| Step: 6
Training loss: 1.6353317499160767
Validation loss: 1.964799960454305

Epoch: 6| Step: 7
Training loss: 2.0193300247192383
Validation loss: 1.9472562670707703

Epoch: 6| Step: 8
Training loss: 1.5778367519378662
Validation loss: 1.9573822816212971

Epoch: 6| Step: 9
Training loss: 1.8438613414764404
Validation loss: 1.9549251397450764

Epoch: 6| Step: 10
Training loss: 2.4392600059509277
Validation loss: 1.9408358335494995

Epoch: 6| Step: 11
Training loss: 1.9105433225631714
Validation loss: 1.9439160227775574

Epoch: 6| Step: 12
Training loss: 2.3137001991271973
Validation loss: 1.9200170238812764

Epoch: 6| Step: 13
Training loss: 2.151223659515381
Validation loss: 1.9457729856173198

Epoch: 34| Step: 0
Training loss: 1.5645135641098022
Validation loss: 1.9658199946085613

Epoch: 6| Step: 1
Training loss: 1.778472661972046
Validation loss: 1.9772769212722778

Epoch: 6| Step: 2
Training loss: 1.832115888595581
Validation loss: 1.9903594255447388

Epoch: 6| Step: 3
Training loss: 2.3015642166137695
Validation loss: 1.989432454109192

Epoch: 6| Step: 4
Training loss: 1.398712396621704
Validation loss: 2.0094783703486123

Epoch: 6| Step: 5
Training loss: 1.7406938076019287
Validation loss: 1.9774985512097676

Epoch: 6| Step: 6
Training loss: 1.8451685905456543
Validation loss: 1.9830411672592163

Epoch: 6| Step: 7
Training loss: 2.273169755935669
Validation loss: 1.9697389403978984

Epoch: 6| Step: 8
Training loss: 1.8614985942840576
Validation loss: 1.995040198167165

Epoch: 6| Step: 9
Training loss: 1.8633348941802979
Validation loss: 1.975911557674408

Epoch: 6| Step: 10
Training loss: 2.3936233520507812
Validation loss: 1.9932077328364055

Epoch: 6| Step: 11
Training loss: 1.6657114028930664
Validation loss: 1.9944931467374165

Epoch: 6| Step: 12
Training loss: 2.3437082767486572
Validation loss: 1.9734140237172444

Epoch: 6| Step: 13
Training loss: 1.7182555198669434
Validation loss: 1.9685045679410298

Epoch: 35| Step: 0
Training loss: 1.2749325037002563
Validation loss: 1.957858403523763

Epoch: 6| Step: 1
Training loss: 2.079434394836426
Validation loss: 1.962548851966858

Epoch: 6| Step: 2
Training loss: 1.8386321067810059
Validation loss: 1.961460570494334

Epoch: 6| Step: 3
Training loss: 2.078472852706909
Validation loss: 1.9620767037073772

Epoch: 6| Step: 4
Training loss: 1.7308151721954346
Validation loss: 1.9569915930430095

Epoch: 6| Step: 5
Training loss: 1.89816153049469
Validation loss: 1.9576520323753357

Epoch: 6| Step: 6
Training loss: 2.216763973236084
Validation loss: 1.9423003792762756

Epoch: 6| Step: 7
Training loss: 1.8185982704162598
Validation loss: 1.9470403393109639

Epoch: 6| Step: 8
Training loss: 1.8595170974731445
Validation loss: 1.9405442476272583

Epoch: 6| Step: 9
Training loss: 1.9597322940826416
Validation loss: 1.9435978929201763

Epoch: 6| Step: 10
Training loss: 2.212646007537842
Validation loss: 1.939198652903239

Epoch: 6| Step: 11
Training loss: 1.5567547082901
Validation loss: 1.9487184882164001

Epoch: 6| Step: 12
Training loss: 2.3781158924102783
Validation loss: 1.9346681634585063

Epoch: 6| Step: 13
Training loss: 1.6428534984588623
Validation loss: 1.9539113640785217

Epoch: 36| Step: 0
Training loss: 1.4932770729064941
Validation loss: 1.948458770910899

Epoch: 6| Step: 1
Training loss: 1.4744240045547485
Validation loss: 1.9529614349206288

Epoch: 6| Step: 2
Training loss: 2.2524333000183105
Validation loss: 1.956392725308736

Epoch: 6| Step: 3
Training loss: 1.768049716949463
Validation loss: 1.9606203436851501

Epoch: 6| Step: 4
Training loss: 1.5775065422058105
Validation loss: 1.9295652508735657

Epoch: 6| Step: 5
Training loss: 1.7559276819229126
Validation loss: 1.9572784701983135

Epoch: 6| Step: 6
Training loss: 2.759634494781494
Validation loss: 1.9669588208198547

Epoch: 6| Step: 7
Training loss: 1.7633423805236816
Validation loss: 1.9647424817085266

Epoch: 6| Step: 8
Training loss: 1.5478607416152954
Validation loss: 1.969389259815216

Epoch: 6| Step: 9
Training loss: 1.9541001319885254
Validation loss: 1.9639291564623516

Epoch: 6| Step: 10
Training loss: 2.1991024017333984
Validation loss: 1.9965226848920186

Epoch: 6| Step: 11
Training loss: 1.2369635105133057
Validation loss: 1.9929094314575195

Epoch: 6| Step: 12
Training loss: 2.769714117050171
Validation loss: 2.026717801888784

Epoch: 6| Step: 13
Training loss: 1.9176121950149536
Validation loss: 2.0126729210217795

Epoch: 37| Step: 0
Training loss: 1.5261014699935913
Validation loss: 2.0105245113372803

Epoch: 6| Step: 1
Training loss: 1.4345457553863525
Validation loss: 2.0222408970197043

Epoch: 6| Step: 2
Training loss: 2.5516858100891113
Validation loss: 2.0255326430002847

Epoch: 6| Step: 3
Training loss: 2.0893332958221436
Validation loss: 2.0020164251327515

Epoch: 6| Step: 4
Training loss: 2.200209617614746
Validation loss: 1.9602558811505635

Epoch: 6| Step: 5
Training loss: 1.953434705734253
Validation loss: 1.9645658532778423

Epoch: 6| Step: 6
Training loss: 1.861890435218811
Validation loss: 1.9536959926287334

Epoch: 6| Step: 7
Training loss: 2.1563401222229004
Validation loss: 1.9535648425420125

Epoch: 6| Step: 8
Training loss: 1.9617767333984375
Validation loss: 1.953129490216573

Epoch: 6| Step: 9
Training loss: 1.5136170387268066
Validation loss: 1.9448367953300476

Epoch: 6| Step: 10
Training loss: 1.8300000429153442
Validation loss: 1.9575570424397786

Epoch: 6| Step: 11
Training loss: 2.0166385173797607
Validation loss: 1.963689108689626

Epoch: 6| Step: 12
Training loss: 1.8401246070861816
Validation loss: 1.9446642796198528

Epoch: 6| Step: 13
Training loss: 1.4523142576217651
Validation loss: 1.9338128964106243

Epoch: 38| Step: 0
Training loss: 1.4869657754898071
Validation loss: 1.9284016489982605

Epoch: 6| Step: 1
Training loss: 1.975395917892456
Validation loss: 1.9318064053853352

Epoch: 6| Step: 2
Training loss: 1.861158847808838
Validation loss: 1.94722984234492

Epoch: 6| Step: 3
Training loss: 1.3872274160385132
Validation loss: 1.9542593955993652

Epoch: 6| Step: 4
Training loss: 1.7838664054870605
Validation loss: 1.9425342480341594

Epoch: 6| Step: 5
Training loss: 2.1069774627685547
Validation loss: 1.975472668806712

Epoch: 6| Step: 6
Training loss: 1.9781869649887085
Validation loss: 1.9943233529726665

Epoch: 6| Step: 7
Training loss: 2.041966676712036
Validation loss: 2.0037695368131003

Epoch: 6| Step: 8
Training loss: 2.2243099212646484
Validation loss: 2.0066901445388794

Epoch: 6| Step: 9
Training loss: 1.838712215423584
Validation loss: 2.00235124429067

Epoch: 6| Step: 10
Training loss: 2.181852340698242
Validation loss: 1.998833914597829

Epoch: 6| Step: 11
Training loss: 2.0792791843414307
Validation loss: 2.01215132077535

Epoch: 6| Step: 12
Training loss: 1.71234130859375
Validation loss: 1.996518035729726

Epoch: 6| Step: 13
Training loss: 1.8568012714385986
Validation loss: 1.9781088829040527

Epoch: 39| Step: 0
Training loss: 1.249885082244873
Validation loss: 1.9591522614161174

Epoch: 6| Step: 1
Training loss: 1.9961882829666138
Validation loss: 1.9516412019729614

Epoch: 6| Step: 2
Training loss: 2.661841630935669
Validation loss: 1.936208148797353

Epoch: 6| Step: 3
Training loss: 2.5246593952178955
Validation loss: 1.9275431632995605

Epoch: 6| Step: 4
Training loss: 1.7501853704452515
Validation loss: 1.9264447291692097

Epoch: 6| Step: 5
Training loss: 2.0966591835021973
Validation loss: 1.931286096572876

Epoch: 6| Step: 6
Training loss: 1.6325026750564575
Validation loss: 1.9294580221176147

Epoch: 6| Step: 7
Training loss: 1.5851243734359741
Validation loss: 1.9297900199890137

Epoch: 6| Step: 8
Training loss: 2.344552516937256
Validation loss: 1.9209323922793071

Epoch: 6| Step: 9
Training loss: 1.6154099702835083
Validation loss: 1.9302749435106914

Epoch: 6| Step: 10
Training loss: 1.7934274673461914
Validation loss: 1.9352248311042786

Epoch: 6| Step: 11
Training loss: 1.912042260169983
Validation loss: 1.937156319618225

Epoch: 6| Step: 12
Training loss: 1.5934748649597168
Validation loss: 1.9337303241093953

Epoch: 6| Step: 13
Training loss: 1.7365443706512451
Validation loss: 1.9461544553438823

Epoch: 40| Step: 0
Training loss: 1.8348287343978882
Validation loss: 1.9561639825503032

Epoch: 6| Step: 1
Training loss: 2.294532537460327
Validation loss: 1.966316560904185

Epoch: 6| Step: 2
Training loss: 2.031125545501709
Validation loss: 1.987587034702301

Epoch: 6| Step: 3
Training loss: 1.854663610458374
Validation loss: 1.9960759282112122

Epoch: 6| Step: 4
Training loss: 2.1264171600341797
Validation loss: 2.0085251927375793

Epoch: 6| Step: 5
Training loss: 1.8125768899917603
Validation loss: 2.0039526422818503

Epoch: 6| Step: 6
Training loss: 1.4145712852478027
Validation loss: 2.0104539593060813

Epoch: 6| Step: 7
Training loss: 2.717367649078369
Validation loss: 2.005553384621938

Epoch: 6| Step: 8
Training loss: 1.7417268753051758
Validation loss: 1.9699586431185405

Epoch: 6| Step: 9
Training loss: 1.8694252967834473
Validation loss: 1.9617289702097576

Epoch: 6| Step: 10
Training loss: 2.0614569187164307
Validation loss: 1.9597668647766113

Epoch: 6| Step: 11
Training loss: 1.8989733457565308
Validation loss: 1.9512554009755452

Epoch: 6| Step: 12
Training loss: 1.686498999595642
Validation loss: 1.9593821962674458

Epoch: 6| Step: 13
Training loss: 1.0158847570419312
Validation loss: 1.9423935612042744

Epoch: 41| Step: 0
Training loss: 2.037714719772339
Validation loss: 1.9375754992167156

Epoch: 6| Step: 1
Training loss: 2.1998636722564697
Validation loss: 1.9500667651494343

Epoch: 6| Step: 2
Training loss: 1.996003270149231
Validation loss: 1.9407220482826233

Epoch: 6| Step: 3
Training loss: 1.4868113994598389
Validation loss: 1.9372683962186177

Epoch: 6| Step: 4
Training loss: 2.024354934692383
Validation loss: 1.9670498569806416

Epoch: 6| Step: 5
Training loss: 1.3556139469146729
Validation loss: 1.96050097544988

Epoch: 6| Step: 6
Training loss: 1.9596104621887207
Validation loss: 1.9851218263308208

Epoch: 6| Step: 7
Training loss: 1.527834177017212
Validation loss: 1.9948495626449585

Epoch: 6| Step: 8
Training loss: 1.6001746654510498
Validation loss: 2.016720732053121

Epoch: 6| Step: 9
Training loss: 2.171788215637207
Validation loss: 1.9907735188802083

Epoch: 6| Step: 10
Training loss: 2.148484945297241
Validation loss: 2.006679813067118

Epoch: 6| Step: 11
Training loss: 1.8690969944000244
Validation loss: 1.9856668710708618

Epoch: 6| Step: 12
Training loss: 1.762940764427185
Validation loss: 2.0073665181795755

Epoch: 6| Step: 13
Training loss: 2.148613691329956
Validation loss: 1.9880121946334839

Epoch: 42| Step: 0
Training loss: 1.6083076000213623
Validation loss: 1.9887516101201375

Epoch: 6| Step: 1
Training loss: 1.2584359645843506
Validation loss: 1.961574375629425

Epoch: 6| Step: 2
Training loss: 2.0235157012939453
Validation loss: 1.9286275903383892

Epoch: 6| Step: 3
Training loss: 2.3356823921203613
Validation loss: 1.9356727202733357

Epoch: 6| Step: 4
Training loss: 1.9293102025985718
Validation loss: 1.9267906149228413

Epoch: 6| Step: 5
Training loss: 2.271611213684082
Validation loss: 1.9237961173057556

Epoch: 6| Step: 6
Training loss: 1.4703086614608765
Validation loss: 1.9382325013478596

Epoch: 6| Step: 7
Training loss: 1.7385636568069458
Validation loss: 1.9342207312583923

Epoch: 6| Step: 8
Training loss: 2.2053728103637695
Validation loss: 1.9321547349294026

Epoch: 6| Step: 9
Training loss: 1.9672281742095947
Validation loss: 1.9375881950060527

Epoch: 6| Step: 10
Training loss: 2.102367401123047
Validation loss: 1.929545521736145

Epoch: 6| Step: 11
Training loss: 2.100700855255127
Validation loss: 1.9276253779729207

Epoch: 6| Step: 12
Training loss: 1.7513363361358643
Validation loss: 1.9332324465115864

Epoch: 6| Step: 13
Training loss: 2.0307352542877197
Validation loss: 1.9379203915596008

Epoch: 43| Step: 0
Training loss: 1.9756085872650146
Validation loss: 1.9501238067944844

Epoch: 6| Step: 1
Training loss: 1.5282888412475586
Validation loss: 1.96861066420873

Epoch: 6| Step: 2
Training loss: 1.862401008605957
Validation loss: 1.9891836047172546

Epoch: 6| Step: 3
Training loss: 2.168900489807129
Validation loss: 1.9865189393361409

Epoch: 6| Step: 4
Training loss: 2.100522518157959
Validation loss: 2.023711919784546

Epoch: 6| Step: 5
Training loss: 1.8255879878997803
Validation loss: 2.026787519454956

Epoch: 6| Step: 6
Training loss: 1.8466479778289795
Validation loss: 2.042143245538076

Epoch: 6| Step: 7
Training loss: 1.351619839668274
Validation loss: 2.037810285886129

Epoch: 6| Step: 8
Training loss: 1.8292288780212402
Validation loss: 2.033003826936086

Epoch: 6| Step: 9
Training loss: 1.9239816665649414
Validation loss: 2.0216353933016458

Epoch: 6| Step: 10
Training loss: 2.006030559539795
Validation loss: 1.9991694688796997

Epoch: 6| Step: 11
Training loss: 1.6398118734359741
Validation loss: 2.004335264364878

Epoch: 6| Step: 12
Training loss: 2.194046974182129
Validation loss: 1.9673791130383809

Epoch: 6| Step: 13
Training loss: 2.202345609664917
Validation loss: 1.9704185326894124

Epoch: 44| Step: 0
Training loss: 1.6665699481964111
Validation loss: 1.9453283548355103

Epoch: 6| Step: 1
Training loss: 2.168854236602783
Validation loss: 1.9465669393539429

Epoch: 6| Step: 2
Training loss: 1.6844942569732666
Validation loss: 1.9416282176971436

Epoch: 6| Step: 3
Training loss: 1.6642563343048096
Validation loss: 1.9191144903500874

Epoch: 6| Step: 4
Training loss: 1.776673674583435
Validation loss: 1.940734604994456

Epoch: 6| Step: 5
Training loss: 2.222865581512451
Validation loss: 1.907288630803426

Epoch: 6| Step: 6
Training loss: 1.6558611392974854
Validation loss: 1.9412722984949748

Epoch: 6| Step: 7
Training loss: 2.050387382507324
Validation loss: 1.9482810497283936

Epoch: 6| Step: 8
Training loss: 1.2788341045379639
Validation loss: 1.9436044295628865

Epoch: 6| Step: 9
Training loss: 1.7697739601135254
Validation loss: 1.96098389228185

Epoch: 6| Step: 10
Training loss: 2.0745460987091064
Validation loss: 1.9458115696907043

Epoch: 6| Step: 11
Training loss: 2.437016487121582
Validation loss: 1.9525826374689739

Epoch: 6| Step: 12
Training loss: 1.8705103397369385
Validation loss: 1.9688877662022908

Epoch: 6| Step: 13
Training loss: 1.599049687385559
Validation loss: 1.9407360156377156

Epoch: 45| Step: 0
Training loss: 1.7034024000167847
Validation loss: 1.9396475156148274

Epoch: 6| Step: 1
Training loss: 1.8561005592346191
Validation loss: 1.9785333077112834

Epoch: 6| Step: 2
Training loss: 2.4899768829345703
Validation loss: 1.991433839003245

Epoch: 6| Step: 3
Training loss: 1.661553144454956
Validation loss: 1.9551466703414917

Epoch: 6| Step: 4
Training loss: 1.825474500656128
Validation loss: 1.9656976858774822

Epoch: 6| Step: 5
Training loss: 1.690143346786499
Validation loss: 1.9421459436416626

Epoch: 6| Step: 6
Training loss: 2.2212882041931152
Validation loss: 1.9546945293744404

Epoch: 6| Step: 7
Training loss: 2.537614345550537
Validation loss: 1.9406418999036152

Epoch: 6| Step: 8
Training loss: 1.5051298141479492
Validation loss: 1.951618731021881

Epoch: 6| Step: 9
Training loss: 1.443021297454834
Validation loss: 1.949798345565796

Epoch: 6| Step: 10
Training loss: 1.8353567123413086
Validation loss: 1.9570507605870564

Epoch: 6| Step: 11
Training loss: 1.8446435928344727
Validation loss: 1.9686299562454224

Epoch: 6| Step: 12
Training loss: 1.6725976467132568
Validation loss: 1.9952509601910908

Epoch: 6| Step: 13
Training loss: 1.5965521335601807
Validation loss: 1.9893042246500652

Epoch: 46| Step: 0
Training loss: 2.467362403869629
Validation loss: 1.9802592992782593

Epoch: 6| Step: 1
Training loss: 2.017096757888794
Validation loss: 1.9678179423014324

Epoch: 6| Step: 2
Training loss: 1.5532701015472412
Validation loss: 1.9706851840019226

Epoch: 6| Step: 3
Training loss: 1.795985221862793
Validation loss: 1.9613194465637207

Epoch: 6| Step: 4
Training loss: 1.7661161422729492
Validation loss: 1.9520617723464966

Epoch: 6| Step: 5
Training loss: 1.9853193759918213
Validation loss: 1.9406473636627197

Epoch: 6| Step: 6
Training loss: 1.6867709159851074
Validation loss: 1.9388524095217388

Epoch: 6| Step: 7
Training loss: 1.9846937656402588
Validation loss: 1.9306424061457317

Epoch: 6| Step: 8
Training loss: 1.8222185373306274
Validation loss: 1.9318710962931316

Epoch: 6| Step: 9
Training loss: 1.5070809125900269
Validation loss: 1.9373801350593567

Epoch: 6| Step: 10
Training loss: 2.030944347381592
Validation loss: 1.9290526906649272

Epoch: 6| Step: 11
Training loss: 1.950556993484497
Validation loss: 1.9292537768681843

Epoch: 6| Step: 12
Training loss: 1.3560376167297363
Validation loss: 1.9263787865638733

Epoch: 6| Step: 13
Training loss: 2.1609718799591064
Validation loss: 1.9428573648134868

Epoch: 47| Step: 0
Training loss: 1.0924034118652344
Validation loss: 1.9259333610534668

Epoch: 6| Step: 1
Training loss: 1.7916138172149658
Validation loss: 1.940026064713796

Epoch: 6| Step: 2
Training loss: 2.027209758758545
Validation loss: 1.9519842863082886

Epoch: 6| Step: 3
Training loss: 1.7123093605041504
Validation loss: 1.9713243246078491

Epoch: 6| Step: 4
Training loss: 1.7444727420806885
Validation loss: 1.987557848294576

Epoch: 6| Step: 5
Training loss: 1.8763760328292847
Validation loss: 1.9803234338760376

Epoch: 6| Step: 6
Training loss: 2.1890249252319336
Validation loss: 1.9828219413757324

Epoch: 6| Step: 7
Training loss: 2.0046255588531494
Validation loss: 1.996968150138855

Epoch: 6| Step: 8
Training loss: 2.4942479133605957
Validation loss: 1.9841009974479675

Epoch: 6| Step: 9
Training loss: 1.9577291011810303
Validation loss: 1.9878544410069783

Epoch: 6| Step: 10
Training loss: 1.92105233669281
Validation loss: 1.957046389579773

Epoch: 6| Step: 11
Training loss: 1.2747248411178589
Validation loss: 1.94534432888031

Epoch: 6| Step: 12
Training loss: 2.0383782386779785
Validation loss: 1.973279853661855

Epoch: 6| Step: 13
Training loss: 1.5998173952102661
Validation loss: 1.9822181065877278

Epoch: 48| Step: 0
Training loss: 2.115161418914795
Validation loss: 1.9808538158734639

Epoch: 6| Step: 1
Training loss: 1.010694980621338
Validation loss: 1.96202685435613

Epoch: 6| Step: 2
Training loss: 2.233673572540283
Validation loss: 1.9630747437477112

Epoch: 6| Step: 3
Training loss: 1.5203697681427002
Validation loss: 1.9613900184631348

Epoch: 6| Step: 4
Training loss: 1.616966962814331
Validation loss: 1.9328596393267314

Epoch: 6| Step: 5
Training loss: 1.6417741775512695
Validation loss: 1.9551955262819927

Epoch: 6| Step: 6
Training loss: 1.2282533645629883
Validation loss: 1.9468047221501668

Epoch: 6| Step: 7
Training loss: 2.0713422298431396
Validation loss: 1.9611271222432454

Epoch: 6| Step: 8
Training loss: 2.322977066040039
Validation loss: 1.9507383704185486

Epoch: 6| Step: 9
Training loss: 2.4220027923583984
Validation loss: 1.9556084275245667

Epoch: 6| Step: 10
Training loss: 1.7179811000823975
Validation loss: 1.957018494606018

Epoch: 6| Step: 11
Training loss: 1.6365528106689453
Validation loss: 1.918679118156433

Epoch: 6| Step: 12
Training loss: 2.0960607528686523
Validation loss: 1.9391152461369832

Epoch: 6| Step: 13
Training loss: 1.9283077716827393
Validation loss: 1.938865562280019

Epoch: 49| Step: 0
Training loss: 2.0008649826049805
Validation loss: 1.949967046578725

Epoch: 6| Step: 1
Training loss: 1.7168166637420654
Validation loss: 1.9438252250353496

Epoch: 6| Step: 2
Training loss: 2.1192450523376465
Validation loss: 1.954176386197408

Epoch: 6| Step: 3
Training loss: 1.356264352798462
Validation loss: 1.9728053013483684

Epoch: 6| Step: 4
Training loss: 1.6439720392227173
Validation loss: 2.0118624567985535

Epoch: 6| Step: 5
Training loss: 1.4751248359680176
Validation loss: 1.9693905313809712

Epoch: 6| Step: 6
Training loss: 2.2382192611694336
Validation loss: 1.987909158070882

Epoch: 6| Step: 7
Training loss: 1.6601579189300537
Validation loss: 2.0129066904385886

Epoch: 6| Step: 8
Training loss: 1.6458313465118408
Validation loss: 2.0018367369969687

Epoch: 6| Step: 9
Training loss: 1.7408595085144043
Validation loss: 1.9915190935134888

Epoch: 6| Step: 10
Training loss: 1.471388339996338
Validation loss: 1.9866269826889038

Epoch: 6| Step: 11
Training loss: 2.029874801635742
Validation loss: 1.9687963326772053

Epoch: 6| Step: 12
Training loss: 1.4905331134796143
Validation loss: 1.9502568642298381

Epoch: 6| Step: 13
Training loss: 2.7973482608795166
Validation loss: 1.9538408319155376

Epoch: 50| Step: 0
Training loss: 1.7694369554519653
Validation loss: 1.9389185309410095

Epoch: 6| Step: 1
Training loss: 1.9585095643997192
Validation loss: 1.9341012636820476

Epoch: 6| Step: 2
Training loss: 2.673201322555542
Validation loss: 1.9355243841807048

Epoch: 6| Step: 3
Training loss: 1.8272730112075806
Validation loss: 1.9328452547391255

Epoch: 6| Step: 4
Training loss: 1.910245418548584
Validation loss: 1.9521667162577312

Epoch: 6| Step: 5
Training loss: 1.641034483909607
Validation loss: 1.947092314561208

Epoch: 6| Step: 6
Training loss: 1.7947956323623657
Validation loss: 1.9371400872866313

Epoch: 6| Step: 7
Training loss: 1.7320451736450195
Validation loss: 1.933499852816264

Epoch: 6| Step: 8
Training loss: 1.6102374792099
Validation loss: 1.9381297032038372

Epoch: 6| Step: 9
Training loss: 2.239382743835449
Validation loss: 1.9451029300689697

Epoch: 6| Step: 10
Training loss: 1.3639538288116455
Validation loss: 1.9540281494458516

Epoch: 6| Step: 11
Training loss: 1.7045066356658936
Validation loss: 1.968424141407013

Epoch: 6| Step: 12
Training loss: 1.1450858116149902
Validation loss: 1.9612384637196858

Epoch: 6| Step: 13
Training loss: 1.9604417085647583
Validation loss: 1.966648797194163

Epoch: 51| Step: 0
Training loss: 2.3388125896453857
Validation loss: 2.01203586657842

Epoch: 6| Step: 1
Training loss: 1.6518474817276
Validation loss: 2.0080888668696084

Epoch: 6| Step: 2
Training loss: 1.5571532249450684
Validation loss: 1.9940980275472004

Epoch: 6| Step: 3
Training loss: 1.5505832433700562
Validation loss: 2.0218293269475303

Epoch: 6| Step: 4
Training loss: 1.3330540657043457
Validation loss: 2.0287591020266214

Epoch: 6| Step: 5
Training loss: 1.8088597059249878
Validation loss: 2.030804991722107

Epoch: 6| Step: 6
Training loss: 1.4732979536056519
Validation loss: 2.0152545173962912

Epoch: 6| Step: 7
Training loss: 1.240558385848999
Validation loss: 1.999437153339386

Epoch: 6| Step: 8
Training loss: 1.8645058870315552
Validation loss: 1.985580305258433

Epoch: 6| Step: 9
Training loss: 2.1194214820861816
Validation loss: 1.978027621905009

Epoch: 6| Step: 10
Training loss: 2.115927219390869
Validation loss: 1.9554906487464905

Epoch: 6| Step: 11
Training loss: 1.6197909116744995
Validation loss: 1.9453832904497783

Epoch: 6| Step: 12
Training loss: 2.809054136276245
Validation loss: 1.9366855422655742

Epoch: 6| Step: 13
Training loss: 1.686406135559082
Validation loss: 1.9266884525616963

Epoch: 52| Step: 0
Training loss: 1.7423796653747559
Validation loss: 1.9216256539026897

Epoch: 6| Step: 1
Training loss: 2.0841732025146484
Validation loss: 1.9209163586298625

Epoch: 6| Step: 2
Training loss: 1.8001275062561035
Validation loss: 1.9291530847549438

Epoch: 6| Step: 3
Training loss: 2.063514471054077
Validation loss: 1.945685863494873

Epoch: 6| Step: 4
Training loss: 1.345321536064148
Validation loss: 1.9339301784833272

Epoch: 6| Step: 5
Training loss: 1.8958775997161865
Validation loss: 1.9241865078608196

Epoch: 6| Step: 6
Training loss: 1.7062339782714844
Validation loss: 1.925741453965505

Epoch: 6| Step: 7
Training loss: 1.8995853662490845
Validation loss: 1.9409634272257488

Epoch: 6| Step: 8
Training loss: 1.5830621719360352
Validation loss: 1.923556625843048

Epoch: 6| Step: 9
Training loss: 1.4475173950195312
Validation loss: 1.9446550011634827

Epoch: 6| Step: 10
Training loss: 2.0137243270874023
Validation loss: 1.923457105954488

Epoch: 6| Step: 11
Training loss: 1.9836058616638184
Validation loss: 1.9400452574094136

Epoch: 6| Step: 12
Training loss: 1.5784497261047363
Validation loss: 1.9627506136894226

Epoch: 6| Step: 13
Training loss: 2.2725353240966797
Validation loss: 2.0008740425109863

Epoch: 53| Step: 0
Training loss: 1.9555695056915283
Validation loss: 2.0330190658569336

Epoch: 6| Step: 1
Training loss: 2.2469120025634766
Validation loss: 2.0449471275011697

Epoch: 6| Step: 2
Training loss: 2.3440089225769043
Validation loss: 2.0885568459828696

Epoch: 6| Step: 3
Training loss: 1.540207862854004
Validation loss: 2.075993279616038

Epoch: 6| Step: 4
Training loss: 2.0036864280700684
Validation loss: 2.1138842701911926

Epoch: 6| Step: 5
Training loss: 1.955030083656311
Validation loss: 2.111864149570465

Epoch: 6| Step: 6
Training loss: 1.0712040662765503
Validation loss: 2.098139504591624

Epoch: 6| Step: 7
Training loss: 1.7699363231658936
Validation loss: 2.0712085962295532

Epoch: 6| Step: 8
Training loss: 2.2764813899993896
Validation loss: 2.0338214635849

Epoch: 6| Step: 9
Training loss: 1.3782826662063599
Validation loss: 2.019459545612335

Epoch: 6| Step: 10
Training loss: 2.171520233154297
Validation loss: 1.9911452531814575

Epoch: 6| Step: 11
Training loss: 1.6468980312347412
Validation loss: 1.976721187432607

Epoch: 6| Step: 12
Training loss: 2.198118209838867
Validation loss: 1.971351444721222

Epoch: 6| Step: 13
Training loss: 1.1211786270141602
Validation loss: 1.9241373737653096

Epoch: 54| Step: 0
Training loss: 1.5839366912841797
Validation loss: 1.9328033725420635

Epoch: 6| Step: 1
Training loss: 1.6919429302215576
Validation loss: 1.9217440485954285

Epoch: 6| Step: 2
Training loss: 1.576159954071045
Validation loss: 1.9278031190236409

Epoch: 6| Step: 3
Training loss: 2.1369900703430176
Validation loss: 1.9377799828847249

Epoch: 6| Step: 4
Training loss: 2.214211940765381
Validation loss: 1.9126148621241252

Epoch: 6| Step: 5
Training loss: 1.6527248620986938
Validation loss: 1.9330485860506694

Epoch: 6| Step: 6
Training loss: 2.3320679664611816
Validation loss: 1.9322315057118733

Epoch: 6| Step: 7
Training loss: 2.202039957046509
Validation loss: 1.9087984561920166

Epoch: 6| Step: 8
Training loss: 1.3595525026321411
Validation loss: 1.9449899593989055

Epoch: 6| Step: 9
Training loss: 2.19093656539917
Validation loss: 1.9333206415176392

Epoch: 6| Step: 10
Training loss: 1.553309679031372
Validation loss: 1.9405377705891926

Epoch: 6| Step: 11
Training loss: 1.8962862491607666
Validation loss: 1.9422675967216492

Epoch: 6| Step: 12
Training loss: 1.3802014589309692
Validation loss: 1.9375327229499817

Epoch: 6| Step: 13
Training loss: 1.6104695796966553
Validation loss: 1.9568378925323486

Epoch: 55| Step: 0
Training loss: 1.8702292442321777
Validation loss: 1.9649370908737183

Epoch: 6| Step: 1
Training loss: 1.410193681716919
Validation loss: 1.9732232491175334

Epoch: 6| Step: 2
Training loss: 1.334877848625183
Validation loss: 1.9490378499031067

Epoch: 6| Step: 3
Training loss: 1.847899317741394
Validation loss: 1.9476497173309326

Epoch: 6| Step: 4
Training loss: 1.8880141973495483
Validation loss: 1.9737511078516643

Epoch: 6| Step: 5
Training loss: 2.587899684906006
Validation loss: 1.987233857313792

Epoch: 6| Step: 6
Training loss: 1.791694164276123
Validation loss: 1.992779016494751

Epoch: 6| Step: 7
Training loss: 1.869550347328186
Validation loss: 1.9953754146893818

Epoch: 6| Step: 8
Training loss: 1.5177029371261597
Validation loss: 2.000784416993459

Epoch: 6| Step: 9
Training loss: 1.549572467803955
Validation loss: 2.013530751069387

Epoch: 6| Step: 10
Training loss: 1.955335021018982
Validation loss: 1.9816593726476033

Epoch: 6| Step: 11
Training loss: 1.6566884517669678
Validation loss: 1.938028077284495

Epoch: 6| Step: 12
Training loss: 1.9334114789962769
Validation loss: 1.9531383315722148

Epoch: 6| Step: 13
Training loss: 1.5490539073944092
Validation loss: 1.9483755032221477

Epoch: 56| Step: 0
Training loss: 1.2745219469070435
Validation loss: 1.960949718952179

Epoch: 6| Step: 1
Training loss: 2.0421395301818848
Validation loss: 1.932519793510437

Epoch: 6| Step: 2
Training loss: 1.5189279317855835
Validation loss: 1.9272504647572835

Epoch: 6| Step: 3
Training loss: 1.3329408168792725
Validation loss: 1.9410760203997295

Epoch: 6| Step: 4
Training loss: 1.819577693939209
Validation loss: 1.9172620971997578

Epoch: 6| Step: 5
Training loss: 1.9032419919967651
Validation loss: 1.9102078278859456

Epoch: 6| Step: 6
Training loss: 1.536767601966858
Validation loss: 1.9269534945487976

Epoch: 6| Step: 7
Training loss: 2.2132325172424316
Validation loss: 1.940171519915263

Epoch: 6| Step: 8
Training loss: 1.4172396659851074
Validation loss: 1.9547702471415203

Epoch: 6| Step: 9
Training loss: 1.9136812686920166
Validation loss: 1.9454896251360576

Epoch: 6| Step: 10
Training loss: 2.0727477073669434
Validation loss: 1.945671280225118

Epoch: 6| Step: 11
Training loss: 1.8463053703308105
Validation loss: 1.9450758298238118

Epoch: 6| Step: 12
Training loss: 2.313321590423584
Validation loss: 1.95220951239268

Epoch: 6| Step: 13
Training loss: 1.5233216285705566
Validation loss: 1.945041298866272

Epoch: 57| Step: 0
Training loss: 1.7018382549285889
Validation loss: 1.9550972978274028

Epoch: 6| Step: 1
Training loss: 1.4594417810440063
Validation loss: 1.9788796305656433

Epoch: 6| Step: 2
Training loss: 1.9978234767913818
Validation loss: 1.9593204657236736

Epoch: 6| Step: 3
Training loss: 1.5199720859527588
Validation loss: 1.9865436553955078

Epoch: 6| Step: 4
Training loss: 2.083247184753418
Validation loss: 1.9893800814946492

Epoch: 6| Step: 5
Training loss: 1.278139352798462
Validation loss: 1.9794891277949016

Epoch: 6| Step: 6
Training loss: 1.7538901567459106
Validation loss: 1.9734238187472026

Epoch: 6| Step: 7
Training loss: 1.9866188764572144
Validation loss: 1.9716087381045024

Epoch: 6| Step: 8
Training loss: 1.8178926706314087
Validation loss: 1.9546671907107036

Epoch: 6| Step: 9
Training loss: 2.543375015258789
Validation loss: 1.9190909266471863

Epoch: 6| Step: 10
Training loss: 1.6003023386001587
Validation loss: 1.9557935396830242

Epoch: 6| Step: 11
Training loss: 1.5572136640548706
Validation loss: 1.9584094683329265

Epoch: 6| Step: 12
Training loss: 1.7481224536895752
Validation loss: 1.9335117936134338

Epoch: 6| Step: 13
Training loss: 1.2162113189697266
Validation loss: 1.9611209034919739

Epoch: 58| Step: 0
Training loss: 0.8144940137863159
Validation loss: 1.9462687969207764

Epoch: 6| Step: 1
Training loss: 1.4373775720596313
Validation loss: 1.9954339663187664

Epoch: 6| Step: 2
Training loss: 1.5969897508621216
Validation loss: 1.98433119058609

Epoch: 6| Step: 3
Training loss: 1.8077666759490967
Validation loss: 1.9928657015164692

Epoch: 6| Step: 4
Training loss: 1.6629701852798462
Validation loss: 1.9982770681381226

Epoch: 6| Step: 5
Training loss: 1.9941928386688232
Validation loss: 2.0262029568354287

Epoch: 6| Step: 6
Training loss: 1.9193618297576904
Validation loss: 1.9948676228523254

Epoch: 6| Step: 7
Training loss: 1.946084976196289
Validation loss: 1.9922060370445251

Epoch: 6| Step: 8
Training loss: 1.5352540016174316
Validation loss: 1.9725699424743652

Epoch: 6| Step: 9
Training loss: 1.579211950302124
Validation loss: 1.9518359104792278

Epoch: 6| Step: 10
Training loss: 1.776742935180664
Validation loss: 1.973659336566925

Epoch: 6| Step: 11
Training loss: 2.503553867340088
Validation loss: 1.9509976704915364

Epoch: 6| Step: 12
Training loss: 1.7569326162338257
Validation loss: 1.9205421209335327

Epoch: 6| Step: 13
Training loss: 2.215442180633545
Validation loss: 1.948824167251587

Epoch: 59| Step: 0
Training loss: 2.1542937755584717
Validation loss: 1.9372476935386658

Epoch: 6| Step: 1
Training loss: 1.3005027770996094
Validation loss: 1.9459970196088154

Epoch: 6| Step: 2
Training loss: 1.8472121953964233
Validation loss: 1.9099323352177937

Epoch: 6| Step: 3
Training loss: 1.2489354610443115
Validation loss: 1.9356859127680461

Epoch: 6| Step: 4
Training loss: 1.5459508895874023
Validation loss: 1.9440123438835144

Epoch: 6| Step: 5
Training loss: 1.7262020111083984
Validation loss: 1.9574257532755535

Epoch: 6| Step: 6
Training loss: 1.781576156616211
Validation loss: 1.9838560819625854

Epoch: 6| Step: 7
Training loss: 1.2016689777374268
Validation loss: 1.946786920229594

Epoch: 6| Step: 8
Training loss: 2.6471915245056152
Validation loss: 1.9556972185770671

Epoch: 6| Step: 9
Training loss: 1.7933087348937988
Validation loss: 1.9515364567438762

Epoch: 6| Step: 10
Training loss: 1.7026515007019043
Validation loss: 1.9646958708763123

Epoch: 6| Step: 11
Training loss: 2.051246166229248
Validation loss: 1.9438961148262024

Epoch: 6| Step: 12
Training loss: 1.2824695110321045
Validation loss: 1.9398978153864543

Epoch: 6| Step: 13
Training loss: 2.1028103828430176
Validation loss: 1.924792210261027

Epoch: 60| Step: 0
Training loss: 2.2866415977478027
Validation loss: 1.929373304049174

Epoch: 6| Step: 1
Training loss: 1.8272180557250977
Validation loss: 1.940356155236562

Epoch: 6| Step: 2
Training loss: 1.7328851222991943
Validation loss: 1.9241877396901448

Epoch: 6| Step: 3
Training loss: 1.4644474983215332
Validation loss: 1.9318002859751384

Epoch: 6| Step: 4
Training loss: 1.6086914539337158
Validation loss: 1.9258700013160706

Epoch: 6| Step: 5
Training loss: 1.6582634449005127
Validation loss: 1.9205197890599568

Epoch: 6| Step: 6
Training loss: 1.219984531402588
Validation loss: 1.9236478408177693

Epoch: 6| Step: 7
Training loss: 2.0413401126861572
Validation loss: 1.927714506785075

Epoch: 6| Step: 8
Training loss: 1.9728188514709473
Validation loss: 1.9366652170817058

Epoch: 6| Step: 9
Training loss: 1.7912482023239136
Validation loss: 1.9354839126269023

Epoch: 6| Step: 10
Training loss: 1.839390754699707
Validation loss: 1.9406778812408447

Epoch: 6| Step: 11
Training loss: 1.814780592918396
Validation loss: 1.9582151174545288

Epoch: 6| Step: 12
Training loss: 1.2872185707092285
Validation loss: 1.9766295949618022

Epoch: 6| Step: 13
Training loss: 1.109268307685852
Validation loss: 1.9781992832819622

Epoch: 61| Step: 0
Training loss: 1.0708178281784058
Validation loss: 1.984479268391927

Epoch: 6| Step: 1
Training loss: 1.0077546834945679
Validation loss: 1.9590590397516887

Epoch: 6| Step: 2
Training loss: 1.675104022026062
Validation loss: 1.942069371541341

Epoch: 6| Step: 3
Training loss: 2.162393093109131
Validation loss: 1.9583965341250102

Epoch: 6| Step: 4
Training loss: 1.197014570236206
Validation loss: 1.9716493884722393

Epoch: 6| Step: 5
Training loss: 1.8803739547729492
Validation loss: 1.9449916084607441

Epoch: 6| Step: 6
Training loss: 1.6948301792144775
Validation loss: 1.9463006258010864

Epoch: 6| Step: 7
Training loss: 1.9371589422225952
Validation loss: 1.9627320170402527

Epoch: 6| Step: 8
Training loss: 2.341712474822998
Validation loss: 1.9380676746368408

Epoch: 6| Step: 9
Training loss: 1.7441768646240234
Validation loss: 1.9225159287452698

Epoch: 6| Step: 10
Training loss: 2.5983052253723145
Validation loss: 1.9336661100387573

Epoch: 6| Step: 11
Training loss: 1.3708624839782715
Validation loss: 1.9340859254201253

Epoch: 6| Step: 12
Training loss: 1.6375324726104736
Validation loss: 1.9412073493003845

Epoch: 6| Step: 13
Training loss: 1.4404957294464111
Validation loss: 1.948856274286906

Epoch: 62| Step: 0
Training loss: 1.434788703918457
Validation loss: 1.9512095252672832

Epoch: 6| Step: 1
Training loss: 1.9243558645248413
Validation loss: 1.979864517847697

Epoch: 6| Step: 2
Training loss: 1.8026397228240967
Validation loss: 1.9756718079249065

Epoch: 6| Step: 3
Training loss: 1.8824642896652222
Validation loss: 1.9894629120826721

Epoch: 6| Step: 4
Training loss: 2.364872455596924
Validation loss: 1.9896101355552673

Epoch: 6| Step: 5
Training loss: 1.5775597095489502
Validation loss: 1.9805592894554138

Epoch: 6| Step: 6
Training loss: 1.6861467361450195
Validation loss: 2.001158674558004

Epoch: 6| Step: 7
Training loss: 1.328376054763794
Validation loss: 1.9696679711341858

Epoch: 6| Step: 8
Training loss: 1.7500563859939575
Validation loss: 1.976697325706482

Epoch: 6| Step: 9
Training loss: 1.2830160856246948
Validation loss: 1.9419101277987163

Epoch: 6| Step: 10
Training loss: 1.8564245700836182
Validation loss: 1.919084946314494

Epoch: 6| Step: 11
Training loss: 1.831673502922058
Validation loss: 1.9123829404513042

Epoch: 6| Step: 12
Training loss: 1.1645671129226685
Validation loss: 1.9249487320582073

Epoch: 6| Step: 13
Training loss: 1.780791163444519
Validation loss: 1.9257850845654805

Epoch: 63| Step: 0
Training loss: 1.1979174613952637
Validation loss: 1.9197059671084087

Epoch: 6| Step: 1
Training loss: 1.7152094841003418
Validation loss: 1.9137051502863567

Epoch: 6| Step: 2
Training loss: 1.3302900791168213
Validation loss: 1.9179698626200359

Epoch: 6| Step: 3
Training loss: 1.7507418394088745
Validation loss: 1.9369149605433147

Epoch: 6| Step: 4
Training loss: 1.9166966676712036
Validation loss: 1.9212524890899658

Epoch: 6| Step: 5
Training loss: 2.307109832763672
Validation loss: 1.9191739956537883

Epoch: 6| Step: 6
Training loss: 1.1132230758666992
Validation loss: 1.92585285504659

Epoch: 6| Step: 7
Training loss: 1.922729253768921
Validation loss: 1.956473708152771

Epoch: 6| Step: 8
Training loss: 1.6359846591949463
Validation loss: 1.9567573269208272

Epoch: 6| Step: 9
Training loss: 1.7918764352798462
Validation loss: 1.9491908152898152

Epoch: 6| Step: 10
Training loss: 1.5627071857452393
Validation loss: 1.9444320797920227

Epoch: 6| Step: 11
Training loss: 1.6784040927886963
Validation loss: 1.9652776916821797

Epoch: 6| Step: 12
Training loss: 1.5532331466674805
Validation loss: 1.9571513533592224

Epoch: 6| Step: 13
Training loss: 1.8022034168243408
Validation loss: 2.006416122118632

Epoch: 64| Step: 0
Training loss: 1.3902262449264526
Validation loss: 1.966007669766744

Epoch: 6| Step: 1
Training loss: 1.1199665069580078
Validation loss: 1.9700734814008076

Epoch: 6| Step: 2
Training loss: 2.0234146118164062
Validation loss: 1.9991182287534077

Epoch: 6| Step: 3
Training loss: 2.104527473449707
Validation loss: 1.9622024893760681

Epoch: 6| Step: 4
Training loss: 1.54524827003479
Validation loss: 1.9576139052708943

Epoch: 6| Step: 5
Training loss: 1.543124794960022
Validation loss: 1.9714225331942241

Epoch: 6| Step: 6
Training loss: 1.5395585298538208
Validation loss: 1.9583720167477925

Epoch: 6| Step: 7
Training loss: 1.7534135580062866
Validation loss: 1.9587963819503784

Epoch: 6| Step: 8
Training loss: 1.2940638065338135
Validation loss: 1.9063369035720825

Epoch: 6| Step: 9
Training loss: 1.711534857749939
Validation loss: 1.9390202760696411

Epoch: 6| Step: 10
Training loss: 2.149799346923828
Validation loss: 1.8933245340983074

Epoch: 6| Step: 11
Training loss: 1.2123818397521973
Validation loss: 1.8915322820345561

Epoch: 6| Step: 12
Training loss: 1.8470697402954102
Validation loss: 1.926329255104065

Epoch: 6| Step: 13
Training loss: 1.794546127319336
Validation loss: 1.8826929132143657

Epoch: 65| Step: 0
Training loss: 1.5279088020324707
Validation loss: 1.9488513271013896

Epoch: 6| Step: 1
Training loss: 1.8332395553588867
Validation loss: 1.9269697864850361

Epoch: 6| Step: 2
Training loss: 1.6750459671020508
Validation loss: 1.906047761440277

Epoch: 6| Step: 3
Training loss: 2.0473885536193848
Validation loss: 1.9086745778719585

Epoch: 6| Step: 4
Training loss: 1.4951467514038086
Validation loss: 1.9259519577026367

Epoch: 6| Step: 5
Training loss: 1.3561389446258545
Validation loss: 1.9116497834523518

Epoch: 6| Step: 6
Training loss: 1.7001537084579468
Validation loss: 1.9431466658910115

Epoch: 6| Step: 7
Training loss: 1.3755494356155396
Validation loss: 1.923374056816101

Epoch: 6| Step: 8
Training loss: 1.893836259841919
Validation loss: 1.9683703382809956

Epoch: 6| Step: 9
Training loss: 2.2479710578918457
Validation loss: 1.9677287737528484

Epoch: 6| Step: 10
Training loss: 1.4148712158203125
Validation loss: 1.9387742280960083

Epoch: 6| Step: 11
Training loss: 1.6106646060943604
Validation loss: 1.9427234927813213

Epoch: 6| Step: 12
Training loss: 1.513061285018921
Validation loss: 1.9680027763048809

Epoch: 6| Step: 13
Training loss: 1.2169415950775146
Validation loss: 1.9835813840230305

Epoch: 66| Step: 0
Training loss: 1.7065379619598389
Validation loss: 1.959506054719289

Epoch: 6| Step: 1
Training loss: 1.7545216083526611
Validation loss: 1.981806496779124

Epoch: 6| Step: 2
Training loss: 1.6839298009872437
Validation loss: 1.975492537021637

Epoch: 6| Step: 3
Training loss: 1.595009446144104
Validation loss: 1.9559375246365864

Epoch: 6| Step: 4
Training loss: 1.7030518054962158
Validation loss: 1.9518981178601582

Epoch: 6| Step: 5
Training loss: 1.0516974925994873
Validation loss: 1.9188539783159893

Epoch: 6| Step: 6
Training loss: 1.5030723810195923
Validation loss: 1.959212064743042

Epoch: 6| Step: 7
Training loss: 1.4018336534500122
Validation loss: 1.933962841828664

Epoch: 6| Step: 8
Training loss: 1.6271427869796753
Validation loss: 1.9193775653839111

Epoch: 6| Step: 9
Training loss: 1.3536617755889893
Validation loss: 1.9204336404800415

Epoch: 6| Step: 10
Training loss: 2.235459089279175
Validation loss: 1.9194546143213909

Epoch: 6| Step: 11
Training loss: 1.624489426612854
Validation loss: 1.9313098192214966

Epoch: 6| Step: 12
Training loss: 1.5837175846099854
Validation loss: 1.9375428160031636

Epoch: 6| Step: 13
Training loss: 1.9111518859863281
Validation loss: 1.9211621284484863

Epoch: 67| Step: 0
Training loss: 1.8458826541900635
Validation loss: 1.9185094038645427

Epoch: 6| Step: 1
Training loss: 1.36370849609375
Validation loss: 1.991697092851003

Epoch: 6| Step: 2
Training loss: 1.6997771263122559
Validation loss: 1.976455827554067

Epoch: 6| Step: 3
Training loss: 1.285872220993042
Validation loss: 1.977478822072347

Epoch: 6| Step: 4
Training loss: 1.496935486793518
Validation loss: 1.9615849653879802

Epoch: 6| Step: 5
Training loss: 1.629382610321045
Validation loss: 1.9757328629493713

Epoch: 6| Step: 6
Training loss: 1.4653565883636475
Validation loss: 1.9301401575406392

Epoch: 6| Step: 7
Training loss: 1.385130763053894
Validation loss: 1.961532175540924

Epoch: 6| Step: 8
Training loss: 1.121993064880371
Validation loss: 1.9333808819452922

Epoch: 6| Step: 9
Training loss: 2.3919517993927
Validation loss: 1.9336160222689311

Epoch: 6| Step: 10
Training loss: 1.7047858238220215
Validation loss: 1.8997828960418701

Epoch: 6| Step: 11
Training loss: 1.7909526824951172
Validation loss: 1.9365094701449077

Epoch: 6| Step: 12
Training loss: 1.6225411891937256
Validation loss: 1.948508381843567

Epoch: 6| Step: 13
Training loss: 1.7003027200698853
Validation loss: 1.9488510489463806

Epoch: 68| Step: 0
Training loss: 2.5770623683929443
Validation loss: 1.9582486152648926

Epoch: 6| Step: 1
Training loss: 1.186067819595337
Validation loss: 1.9378154277801514

Epoch: 6| Step: 2
Training loss: 1.653706431388855
Validation loss: 1.9636648495992024

Epoch: 6| Step: 3
Training loss: 1.8110053539276123
Validation loss: 1.9540703694025676

Epoch: 6| Step: 4
Training loss: 1.7968144416809082
Validation loss: 1.9265610774358113

Epoch: 6| Step: 5
Training loss: 0.9559013843536377
Validation loss: 1.9509341915448506

Epoch: 6| Step: 6
Training loss: 1.1644306182861328
Validation loss: 1.946177363395691

Epoch: 6| Step: 7
Training loss: 1.546797275543213
Validation loss: 1.9504904349644978

Epoch: 6| Step: 8
Training loss: 1.6462297439575195
Validation loss: 1.9416462381680806

Epoch: 6| Step: 9
Training loss: 2.0803980827331543
Validation loss: 1.9781567653020222

Epoch: 6| Step: 10
Training loss: 1.6989284753799438
Validation loss: 1.9435945550600688

Epoch: 6| Step: 11
Training loss: 1.0012363195419312
Validation loss: 1.9526486992835999

Epoch: 6| Step: 12
Training loss: 1.264514684677124
Validation loss: 1.9579426248868306

Epoch: 6| Step: 13
Training loss: 1.5780253410339355
Validation loss: 1.9625685413678486

Epoch: 69| Step: 0
Training loss: 1.7068445682525635
Validation loss: 1.9608408212661743

Epoch: 6| Step: 1
Training loss: 1.0797679424285889
Validation loss: 1.9777895212173462

Epoch: 6| Step: 2
Training loss: 1.2539923191070557
Validation loss: 1.958662708600362

Epoch: 6| Step: 3
Training loss: 1.2292555570602417
Validation loss: 1.9414083361625671

Epoch: 6| Step: 4
Training loss: 2.0182595252990723
Validation loss: 1.9470625122388203

Epoch: 6| Step: 5
Training loss: 1.2244809865951538
Validation loss: 1.949069579442342

Epoch: 6| Step: 6
Training loss: 1.2079161405563354
Validation loss: 1.9482293923695881

Epoch: 6| Step: 7
Training loss: 2.423020362854004
Validation loss: 1.9639527797698975

Epoch: 6| Step: 8
Training loss: 1.589254379272461
Validation loss: 1.9626999497413635

Epoch: 6| Step: 9
Training loss: 1.7398412227630615
Validation loss: 1.970844527085622

Epoch: 6| Step: 10
Training loss: 1.3445651531219482
Validation loss: 1.9606260657310486

Epoch: 6| Step: 11
Training loss: 1.8159416913986206
Validation loss: 1.94049866994222

Epoch: 6| Step: 12
Training loss: 1.566067099571228
Validation loss: 1.9492108225822449

Epoch: 6| Step: 13
Training loss: 1.3966617584228516
Validation loss: 1.9577877322832744

Epoch: 70| Step: 0
Training loss: 1.2559679746627808
Validation loss: 1.9126279552777607

Epoch: 6| Step: 1
Training loss: 1.170858383178711
Validation loss: 1.9272459745407104

Epoch: 6| Step: 2
Training loss: 1.4889670610427856
Validation loss: 1.9519156217575073

Epoch: 6| Step: 3
Training loss: 1.3963162899017334
Validation loss: 1.9595132271448772

Epoch: 6| Step: 4
Training loss: 1.5332088470458984
Validation loss: 1.9180127779642742

Epoch: 6| Step: 5
Training loss: 1.187947392463684
Validation loss: 1.947503924369812

Epoch: 6| Step: 6
Training loss: 1.5270591974258423
Validation loss: 1.968674103418986

Epoch: 6| Step: 7
Training loss: 1.601117730140686
Validation loss: 1.9717015425364177

Epoch: 6| Step: 8
Training loss: 1.9878973960876465
Validation loss: 1.9922966758410137

Epoch: 6| Step: 9
Training loss: 2.304940700531006
Validation loss: 1.9876234928766887

Epoch: 6| Step: 10
Training loss: 1.8963749408721924
Validation loss: 1.9397725860277812

Epoch: 6| Step: 11
Training loss: 1.732697606086731
Validation loss: 1.961441159248352

Epoch: 6| Step: 12
Training loss: 1.0834925174713135
Validation loss: 1.9614742994308472

Epoch: 6| Step: 13
Training loss: 1.8067569732666016
Validation loss: 1.9621916611989338

Epoch: 71| Step: 0
Training loss: 1.5746960639953613
Validation loss: 1.9395734667778015

Epoch: 6| Step: 1
Training loss: 1.1316031217575073
Validation loss: 1.9427342414855957

Epoch: 6| Step: 2
Training loss: 2.434410572052002
Validation loss: 1.9402458270390828

Epoch: 6| Step: 3
Training loss: 1.1893998384475708
Validation loss: 1.9391181270281475

Epoch: 6| Step: 4
Training loss: 1.2921403646469116
Validation loss: 1.9374960064888

Epoch: 6| Step: 5
Training loss: 1.141725778579712
Validation loss: 1.9636488556861877

Epoch: 6| Step: 6
Training loss: 1.913116216659546
Validation loss: 1.9648508230845134

Epoch: 6| Step: 7
Training loss: 1.929524302482605
Validation loss: 1.981671969095866

Epoch: 6| Step: 8
Training loss: 1.1668895483016968
Validation loss: 1.9495439728101094

Epoch: 6| Step: 9
Training loss: 1.431717872619629
Validation loss: 1.965905984242757

Epoch: 6| Step: 10
Training loss: 1.8131380081176758
Validation loss: 1.953946014245351

Epoch: 6| Step: 11
Training loss: 1.4827241897583008
Validation loss: 1.9685483773549397

Epoch: 6| Step: 12
Training loss: 1.4716370105743408
Validation loss: 1.9666287302970886

Epoch: 6| Step: 13
Training loss: 1.4152343273162842
Validation loss: 1.985513985157013

Epoch: 72| Step: 0
Training loss: 2.077784299850464
Validation loss: 1.9155025283495586

Epoch: 6| Step: 1
Training loss: 1.9031659364700317
Validation loss: 1.9536375999450684

Epoch: 6| Step: 2
Training loss: 1.0789520740509033
Validation loss: 1.9362149834632874

Epoch: 6| Step: 3
Training loss: 1.2573305368423462
Validation loss: 1.9387221733729045

Epoch: 6| Step: 4
Training loss: 1.815366268157959
Validation loss: 1.952440579732259

Epoch: 6| Step: 5
Training loss: 1.5761674642562866
Validation loss: 1.96278582016627

Epoch: 6| Step: 6
Training loss: 1.5976221561431885
Validation loss: 1.97672043244044

Epoch: 6| Step: 7
Training loss: 1.0937833786010742
Validation loss: 1.977692445119222

Epoch: 6| Step: 8
Training loss: 1.1457045078277588
Validation loss: 1.9508373141288757

Epoch: 6| Step: 9
Training loss: 1.5624492168426514
Validation loss: 1.9760660926500957

Epoch: 6| Step: 10
Training loss: 1.7149419784545898
Validation loss: 2.0049211184183755

Epoch: 6| Step: 11
Training loss: 1.3010109663009644
Validation loss: 1.993070383866628

Epoch: 6| Step: 12
Training loss: 1.2752556800842285
Validation loss: 2.0216995080312095

Epoch: 6| Step: 13
Training loss: 1.6414422988891602
Validation loss: 2.0635160406430564

Epoch: 73| Step: 0
Training loss: 0.9476159811019897
Validation loss: 2.0282165010770163

Epoch: 6| Step: 1
Training loss: 1.4552584886550903
Validation loss: 2.064057211081187

Epoch: 6| Step: 2
Training loss: 1.7412866353988647
Validation loss: 1.9895468552907307

Epoch: 6| Step: 3
Training loss: 1.695270299911499
Validation loss: 1.984853744506836

Epoch: 6| Step: 4
Training loss: 1.025878667831421
Validation loss: 1.9672409892082214

Epoch: 6| Step: 5
Training loss: 1.3005372285842896
Validation loss: 1.9613704284032185

Epoch: 6| Step: 6
Training loss: 1.4187707901000977
Validation loss: 1.9674190680185955

Epoch: 6| Step: 7
Training loss: 1.9282739162445068
Validation loss: 1.945449968179067

Epoch: 6| Step: 8
Training loss: 1.9863519668579102
Validation loss: 1.9764311114947002

Epoch: 6| Step: 9
Training loss: 1.4769179821014404
Validation loss: 1.9586410919825237

Epoch: 6| Step: 10
Training loss: 1.310058355331421
Validation loss: 1.9729489088058472

Epoch: 6| Step: 11
Training loss: 1.615006685256958
Validation loss: 1.9730203946431477

Epoch: 6| Step: 12
Training loss: 1.893784761428833
Validation loss: 1.973464548587799

Epoch: 6| Step: 13
Training loss: 1.6238751411437988
Validation loss: 2.008504271507263

Epoch: 74| Step: 0
Training loss: 1.2918620109558105
Validation loss: 1.9896848996480305

Epoch: 6| Step: 1
Training loss: 1.6726430654525757
Validation loss: 2.0024514396985373

Epoch: 6| Step: 2
Training loss: 1.618910312652588
Validation loss: 2.0040504733721414

Epoch: 6| Step: 3
Training loss: 1.6904455423355103
Validation loss: 2.0028832157452903

Epoch: 6| Step: 4
Training loss: 1.2134541273117065
Validation loss: 1.9708039164543152

Epoch: 6| Step: 5
Training loss: 1.8032584190368652
Validation loss: 1.8961015542348225

Epoch: 6| Step: 6
Training loss: 2.008167028427124
Validation loss: 1.9528376460075378

Epoch: 6| Step: 7
Training loss: 1.6087521314620972
Validation loss: 1.9532032211621602

Epoch: 6| Step: 8
Training loss: 1.5795586109161377
Validation loss: 1.9360868533452351

Epoch: 6| Step: 9
Training loss: 1.1307095289230347
Validation loss: 1.9548112750053406

Epoch: 6| Step: 10
Training loss: 1.596421241760254
Validation loss: 1.9171395500500996

Epoch: 6| Step: 11
Training loss: 1.306488037109375
Validation loss: 2.0121392409006753

Epoch: 6| Step: 12
Training loss: 1.0647497177124023
Validation loss: 1.9836636583010356

Epoch: 6| Step: 13
Training loss: 0.910270631313324
Validation loss: 1.9721765518188477

Epoch: 75| Step: 0
Training loss: 1.5169097185134888
Validation loss: 1.9718347390492756

Epoch: 6| Step: 1
Training loss: 1.7318108081817627
Validation loss: 1.9587791363398235

Epoch: 6| Step: 2
Training loss: 1.7553684711456299
Validation loss: 1.9444226026535034

Epoch: 6| Step: 3
Training loss: 0.9745224714279175
Validation loss: 1.9659027258555095

Epoch: 6| Step: 4
Training loss: 1.1047406196594238
Validation loss: 1.9571325580279033

Epoch: 6| Step: 5
Training loss: 1.295975685119629
Validation loss: 1.9509486158688862

Epoch: 6| Step: 6
Training loss: 1.5547116994857788
Validation loss: 1.9676316579182942

Epoch: 6| Step: 7
Training loss: 1.7003790140151978
Validation loss: 1.947935938835144

Epoch: 6| Step: 8
Training loss: 1.8238410949707031
Validation loss: 1.9458104968070984

Epoch: 6| Step: 9
Training loss: 1.8403785228729248
Validation loss: 1.961429238319397

Epoch: 6| Step: 10
Training loss: 1.708608627319336
Validation loss: 1.9791324337323506

Epoch: 6| Step: 11
Training loss: 1.0155954360961914
Validation loss: 1.9131796956062317

Epoch: 6| Step: 12
Training loss: 1.4037854671478271
Validation loss: 1.94443412621816

Epoch: 6| Step: 13
Training loss: 1.0652278661727905
Validation loss: 1.9601478377978008

Epoch: 76| Step: 0
Training loss: 1.9908549785614014
Validation loss: 1.974873463312785

Epoch: 6| Step: 1
Training loss: 1.948289155960083
Validation loss: 2.007367650667826

Epoch: 6| Step: 2
Training loss: 1.690375566482544
Validation loss: 2.0080950061480203

Epoch: 6| Step: 3
Training loss: 1.5402741432189941
Validation loss: 1.9701453844706218

Epoch: 6| Step: 4
Training loss: 1.7759828567504883
Validation loss: 1.9731183846791585

Epoch: 6| Step: 5
Training loss: 1.626136302947998
Validation loss: 1.9881361921628316

Epoch: 6| Step: 6
Training loss: 1.7681987285614014
Validation loss: 1.9551587303479512

Epoch: 6| Step: 7
Training loss: 1.0808477401733398
Validation loss: 1.967781126499176

Epoch: 6| Step: 8
Training loss: 1.0220263004302979
Validation loss: 1.947037895520528

Epoch: 6| Step: 9
Training loss: 0.96775883436203
Validation loss: 1.9711111982663472

Epoch: 6| Step: 10
Training loss: 1.5267791748046875
Validation loss: 1.9543570677439372

Epoch: 6| Step: 11
Training loss: 0.676179051399231
Validation loss: 1.9595078031222026

Epoch: 6| Step: 12
Training loss: 1.4342565536499023
Validation loss: 1.965638279914856

Epoch: 6| Step: 13
Training loss: 1.1968657970428467
Validation loss: 1.9559508363405864

Epoch: 77| Step: 0
Training loss: 1.3199503421783447
Validation loss: 1.9877764383951824

Epoch: 6| Step: 1
Training loss: 2.056406021118164
Validation loss: 1.9810211062431335

Epoch: 6| Step: 2
Training loss: 1.1575555801391602
Validation loss: 1.9971810579299927

Epoch: 6| Step: 3
Training loss: 1.4252784252166748
Validation loss: 1.9779336055119832

Epoch: 6| Step: 4
Training loss: 1.1496782302856445
Validation loss: 1.9897404710451763

Epoch: 6| Step: 5
Training loss: 1.7593531608581543
Validation loss: 1.947609802087148

Epoch: 6| Step: 6
Training loss: 1.1842149496078491
Validation loss: 1.9329727292060852

Epoch: 6| Step: 7
Training loss: 0.9874515533447266
Validation loss: 1.9093586802482605

Epoch: 6| Step: 8
Training loss: 1.6867313385009766
Validation loss: 1.9305630127588909

Epoch: 6| Step: 9
Training loss: 1.2195875644683838
Validation loss: 1.9343478083610535

Epoch: 6| Step: 10
Training loss: 1.1707898378372192
Validation loss: 1.9422115882237752

Epoch: 6| Step: 11
Training loss: 1.740567684173584
Validation loss: 1.936564286549886

Epoch: 6| Step: 12
Training loss: 2.241914749145508
Validation loss: 1.9633267720540364

Epoch: 6| Step: 13
Training loss: 1.159672498703003
Validation loss: 1.9511111378669739

Epoch: 78| Step: 0
Training loss: 0.5564297437667847
Validation loss: 1.974366823832194

Epoch: 6| Step: 1
Training loss: 1.3819395303726196
Validation loss: 1.975207010904948

Epoch: 6| Step: 2
Training loss: 1.2646312713623047
Validation loss: 1.9830824534098308

Epoch: 6| Step: 3
Training loss: 0.9729152321815491
Validation loss: 1.9808070659637451

Epoch: 6| Step: 4
Training loss: 2.091737747192383
Validation loss: 1.982975959777832

Epoch: 6| Step: 5
Training loss: 1.3008677959442139
Validation loss: 1.9423537651697795

Epoch: 6| Step: 6
Training loss: 1.2464840412139893
Validation loss: 1.9568408131599426

Epoch: 6| Step: 7
Training loss: 1.665784239768982
Validation loss: 1.9426626960436504

Epoch: 6| Step: 8
Training loss: 1.69590163230896
Validation loss: 1.9961302677790325

Epoch: 6| Step: 9
Training loss: 1.1645147800445557
Validation loss: 1.981656014919281

Epoch: 6| Step: 10
Training loss: 2.005539655685425
Validation loss: 1.9722107648849487

Epoch: 6| Step: 11
Training loss: 1.9599202871322632
Validation loss: 2.005831321080526

Epoch: 6| Step: 12
Training loss: 1.5179715156555176
Validation loss: 1.980195124944051

Epoch: 6| Step: 13
Training loss: 1.1839758157730103
Validation loss: 1.9862605730692546

Epoch: 79| Step: 0
Training loss: 1.604466199874878
Validation loss: 1.9607664545377095

Epoch: 6| Step: 1
Training loss: 2.045456647872925
Validation loss: 1.9343865911165874

Epoch: 6| Step: 2
Training loss: 1.4202184677124023
Validation loss: 1.9899268945058186

Epoch: 6| Step: 3
Training loss: 1.449240803718567
Validation loss: 1.9795572757720947

Epoch: 6| Step: 4
Training loss: 1.284864902496338
Validation loss: 1.9358344475428264

Epoch: 6| Step: 5
Training loss: 1.236175298690796
Validation loss: 1.9331354697545369

Epoch: 6| Step: 6
Training loss: 1.1061404943466187
Validation loss: 1.9269116719563801

Epoch: 6| Step: 7
Training loss: 1.1157045364379883
Validation loss: 1.980745017528534

Epoch: 6| Step: 8
Training loss: 1.3652775287628174
Validation loss: 1.9741211136182149

Epoch: 6| Step: 9
Training loss: 1.1218308210372925
Validation loss: 2.005637069543203

Epoch: 6| Step: 10
Training loss: 1.7175071239471436
Validation loss: 1.9898614883422852

Epoch: 6| Step: 11
Training loss: 2.27114200592041
Validation loss: 2.037835439046224

Epoch: 6| Step: 12
Training loss: 1.6537494659423828
Validation loss: 2.034039835135142

Epoch: 6| Step: 13
Training loss: 1.253350019454956
Validation loss: 1.983054757118225

Epoch: 80| Step: 0
Training loss: 1.3365511894226074
Validation loss: 1.9417239824930828

Epoch: 6| Step: 1
Training loss: 0.8436636924743652
Validation loss: 1.9536239107449849

Epoch: 6| Step: 2
Training loss: 0.9063951969146729
Validation loss: 1.9529147346814473

Epoch: 6| Step: 3
Training loss: 2.0965659618377686
Validation loss: 1.8972376386324565

Epoch: 6| Step: 4
Training loss: 1.9274873733520508
Validation loss: 1.9138530492782593

Epoch: 6| Step: 5
Training loss: 1.038343071937561
Validation loss: 1.930016299088796

Epoch: 6| Step: 6
Training loss: 1.4899897575378418
Validation loss: 1.8982621828715007

Epoch: 6| Step: 7
Training loss: 1.4361640214920044
Validation loss: 1.952601393063863

Epoch: 6| Step: 8
Training loss: 1.1087660789489746
Validation loss: 1.9438133438428242

Epoch: 6| Step: 9
Training loss: 1.7686221599578857
Validation loss: 1.9500376383463542

Epoch: 6| Step: 10
Training loss: 1.3326371908187866
Validation loss: 2.0007897218068442

Epoch: 6| Step: 11
Training loss: 1.1665223836898804
Validation loss: 2.00821723540624

Epoch: 6| Step: 12
Training loss: 1.3563292026519775
Validation loss: 1.9973623951276143

Epoch: 6| Step: 13
Training loss: 1.9113490581512451
Validation loss: 2.041282335917155

Epoch: 81| Step: 0
Training loss: 0.9824585914611816
Validation loss: 1.989987810452779

Epoch: 6| Step: 1
Training loss: 1.645503282546997
Validation loss: 2.002179443836212

Epoch: 6| Step: 2
Training loss: 1.0298428535461426
Validation loss: 1.9912013014157612

Epoch: 6| Step: 3
Training loss: 1.230355978012085
Validation loss: 1.9681958158810933

Epoch: 6| Step: 4
Training loss: 1.464959979057312
Validation loss: 1.9731472333272297

Epoch: 6| Step: 5
Training loss: 1.4005897045135498
Validation loss: 1.9566929539044697

Epoch: 6| Step: 6
Training loss: 1.4226278066635132
Validation loss: 1.9887662927309673

Epoch: 6| Step: 7
Training loss: 1.3957500457763672
Validation loss: 2.0023129185040793

Epoch: 6| Step: 8
Training loss: 1.53212308883667
Validation loss: 1.9893104632695515

Epoch: 6| Step: 9
Training loss: 1.7764825820922852
Validation loss: 1.965185781319936

Epoch: 6| Step: 10
Training loss: 1.1201679706573486
Validation loss: 1.9248367150624592

Epoch: 6| Step: 11
Training loss: 2.0590739250183105
Validation loss: 1.9734683235486348

Epoch: 6| Step: 12
Training loss: 1.3834123611450195
Validation loss: 1.9484513600667317

Epoch: 6| Step: 13
Training loss: 1.1290814876556396
Validation loss: 1.957252283891042

Epoch: 82| Step: 0
Training loss: 0.9461475610733032
Validation loss: 2.0090800722440085

Epoch: 6| Step: 1
Training loss: 1.063201665878296
Validation loss: 1.9851340254147847

Epoch: 6| Step: 2
Training loss: 0.9604550004005432
Validation loss: 2.024010101954142

Epoch: 6| Step: 3
Training loss: 1.2852365970611572
Validation loss: 2.0188622077306113

Epoch: 6| Step: 4
Training loss: 1.0372307300567627
Validation loss: 2.0191131035486856

Epoch: 6| Step: 5
Training loss: 1.9286810159683228
Validation loss: 1.9822315375010173

Epoch: 6| Step: 6
Training loss: 1.222204327583313
Validation loss: 1.9653674165407817

Epoch: 6| Step: 7
Training loss: 1.3986537456512451
Validation loss: 1.9602943062782288

Epoch: 6| Step: 8
Training loss: 2.016127347946167
Validation loss: 1.9482589364051819

Epoch: 6| Step: 9
Training loss: 1.3617711067199707
Validation loss: 1.9621034264564514

Epoch: 6| Step: 10
Training loss: 1.6601006984710693
Validation loss: 1.962352712949117

Epoch: 6| Step: 11
Training loss: 1.1869118213653564
Validation loss: 1.9541654984156291

Epoch: 6| Step: 12
Training loss: 1.5620641708374023
Validation loss: 1.980971892674764

Epoch: 6| Step: 13
Training loss: 1.3817150592803955
Validation loss: 1.983574132124583

Epoch: 83| Step: 0
Training loss: 1.0490355491638184
Validation loss: 2.0017045736312866

Epoch: 6| Step: 1
Training loss: 1.3188347816467285
Validation loss: 1.960635244846344

Epoch: 6| Step: 2
Training loss: 1.6374651193618774
Validation loss: 2.0163161357243857

Epoch: 6| Step: 3
Training loss: 1.303226351737976
Validation loss: 2.003327409426371

Epoch: 6| Step: 4
Training loss: 1.295779824256897
Validation loss: 1.98545906941096

Epoch: 6| Step: 5
Training loss: 1.5921061038970947
Validation loss: 2.0013831853866577

Epoch: 6| Step: 6
Training loss: 1.6446199417114258
Validation loss: 2.009087602297465

Epoch: 6| Step: 7
Training loss: 1.4842896461486816
Validation loss: 2.0281726320584617

Epoch: 6| Step: 8
Training loss: 1.013828992843628
Validation loss: 1.9889776508013408

Epoch: 6| Step: 9
Training loss: 1.1082544326782227
Validation loss: 1.994176725546519

Epoch: 6| Step: 10
Training loss: 1.2444725036621094
Validation loss: 1.983591337998708

Epoch: 6| Step: 11
Training loss: 1.205181360244751
Validation loss: 2.0673604011535645

Epoch: 6| Step: 12
Training loss: 1.2782104015350342
Validation loss: 2.040277083714803

Epoch: 6| Step: 13
Training loss: 1.629669189453125
Validation loss: 1.9698704878489177

Epoch: 84| Step: 0
Training loss: 0.7382105588912964
Validation loss: 2.0135827461878457

Epoch: 6| Step: 1
Training loss: 1.4820895195007324
Validation loss: 1.9420681397120159

Epoch: 6| Step: 2
Training loss: 1.6778579950332642
Validation loss: 1.9280051787694295

Epoch: 6| Step: 3
Training loss: 1.6464247703552246
Validation loss: 1.9668482939402263

Epoch: 6| Step: 4
Training loss: 1.6519017219543457
Validation loss: 1.9226522048314412

Epoch: 6| Step: 5
Training loss: 0.9283645153045654
Validation loss: 1.9576703310012817

Epoch: 6| Step: 6
Training loss: 1.213935136795044
Validation loss: 1.9572264552116394

Epoch: 6| Step: 7
Training loss: 1.6946629285812378
Validation loss: 1.9815979997316997

Epoch: 6| Step: 8
Training loss: 0.7081077694892883
Validation loss: 1.9744012355804443

Epoch: 6| Step: 9
Training loss: 1.6108386516571045
Validation loss: 2.003551721572876

Epoch: 6| Step: 10
Training loss: 1.0219016075134277
Validation loss: 1.9912612438201904

Epoch: 6| Step: 11
Training loss: 1.5881168842315674
Validation loss: 2.0315762758255005

Epoch: 6| Step: 12
Training loss: 0.9862334728240967
Validation loss: 2.0167644023895264

Epoch: 6| Step: 13
Training loss: 2.060555934906006
Validation loss: 2.0249644915262857

Epoch: 85| Step: 0
Training loss: 1.3199845552444458
Validation loss: 1.9532370766003926

Epoch: 6| Step: 1
Training loss: 1.0266426801681519
Validation loss: 1.9570021430651348

Epoch: 6| Step: 2
Training loss: 1.5038552284240723
Validation loss: 1.9557811220486958

Epoch: 6| Step: 3
Training loss: 1.474050760269165
Validation loss: 1.965550422668457

Epoch: 6| Step: 4
Training loss: 1.1701817512512207
Validation loss: 1.9155379732449849

Epoch: 6| Step: 5
Training loss: 1.2945890426635742
Validation loss: 1.957283854484558

Epoch: 6| Step: 6
Training loss: 1.3965277671813965
Validation loss: 1.9328497250874836

Epoch: 6| Step: 7
Training loss: 1.3458385467529297
Validation loss: 1.9469470977783203

Epoch: 6| Step: 8
Training loss: 1.2929307222366333
Validation loss: 1.982089102268219

Epoch: 6| Step: 9
Training loss: 1.731682538986206
Validation loss: 2.009475350379944

Epoch: 6| Step: 10
Training loss: 1.3356517553329468
Validation loss: 2.002582311630249

Epoch: 6| Step: 11
Training loss: 1.413456916809082
Validation loss: 2.003071665763855

Epoch: 6| Step: 12
Training loss: 1.3584202527999878
Validation loss: 1.973101278146108

Epoch: 6| Step: 13
Training loss: 1.051080346107483
Validation loss: 1.9691406687100728

Epoch: 86| Step: 0
Training loss: 1.4134553670883179
Validation loss: 2.003693381945292

Epoch: 6| Step: 1
Training loss: 1.6231335401535034
Validation loss: 2.0032083789507547

Epoch: 6| Step: 2
Training loss: 2.2794036865234375
Validation loss: 1.9702894290288289

Epoch: 6| Step: 3
Training loss: 0.9884696006774902
Validation loss: 1.98091854651769

Epoch: 6| Step: 4
Training loss: 1.4317123889923096
Validation loss: 1.9563313325246174

Epoch: 6| Step: 5
Training loss: 0.7647160291671753
Validation loss: 1.942726969718933

Epoch: 6| Step: 6
Training loss: 0.8108521103858948
Validation loss: 1.92479674021403

Epoch: 6| Step: 7
Training loss: 0.835644006729126
Validation loss: 1.9279715816179912

Epoch: 6| Step: 8
Training loss: 1.6992828845977783
Validation loss: 1.960944652557373

Epoch: 6| Step: 9
Training loss: 1.187961459159851
Validation loss: 1.9794576168060303

Epoch: 6| Step: 10
Training loss: 1.3620202541351318
Validation loss: 1.9439879258473713

Epoch: 6| Step: 11
Training loss: 1.180522084236145
Validation loss: 1.959086835384369

Epoch: 6| Step: 12
Training loss: 1.6041443347930908
Validation loss: 2.0038052598635354

Epoch: 6| Step: 13
Training loss: 0.9025033712387085
Validation loss: 2.0394421219825745

Epoch: 87| Step: 0
Training loss: 1.3309040069580078
Validation loss: 1.9989731709162395

Epoch: 6| Step: 1
Training loss: 1.4429214000701904
Validation loss: 1.9856730302174885

Epoch: 6| Step: 2
Training loss: 1.7109037637710571
Validation loss: 1.9832934737205505

Epoch: 6| Step: 3
Training loss: 0.8101776242256165
Validation loss: 1.971847116947174

Epoch: 6| Step: 4
Training loss: 0.958838939666748
Validation loss: 2.0157843828201294

Epoch: 6| Step: 5
Training loss: 1.3475958108901978
Validation loss: 1.9966815114021301

Epoch: 6| Step: 6
Training loss: 1.5754950046539307
Validation loss: 2.008792241414388

Epoch: 6| Step: 7
Training loss: 1.5246663093566895
Validation loss: 2.0099262396494546

Epoch: 6| Step: 8
Training loss: 1.0310348272323608
Validation loss: 1.9849825501441956

Epoch: 6| Step: 9
Training loss: 1.1567152738571167
Validation loss: 1.9697840611139934

Epoch: 6| Step: 10
Training loss: 1.0634602308273315
Validation loss: 1.9689036011695862

Epoch: 6| Step: 11
Training loss: 0.790656566619873
Validation loss: 1.9522354205449421

Epoch: 6| Step: 12
Training loss: 1.379136562347412
Validation loss: 1.9506789048512776

Epoch: 6| Step: 13
Training loss: 2.074740409851074
Validation loss: 1.9382739265759785

Epoch: 88| Step: 0
Training loss: 0.724469006061554
Validation loss: 1.9504223465919495

Epoch: 6| Step: 1
Training loss: 1.4102623462677002
Validation loss: 1.9115628401438396

Epoch: 6| Step: 2
Training loss: 1.1904324293136597
Validation loss: 1.9617487788200378

Epoch: 6| Step: 3
Training loss: 1.5063223838806152
Validation loss: 1.981146514415741

Epoch: 6| Step: 4
Training loss: 0.8258243799209595
Validation loss: 1.9717901349067688

Epoch: 6| Step: 5
Training loss: 2.005138874053955
Validation loss: 1.9810278018315632

Epoch: 6| Step: 6
Training loss: 1.0282799005508423
Validation loss: 2.0032608111699424

Epoch: 6| Step: 7
Training loss: 1.5925354957580566
Validation loss: 1.9952225089073181

Epoch: 6| Step: 8
Training loss: 0.9915741682052612
Validation loss: 1.9770196676254272

Epoch: 6| Step: 9
Training loss: 2.2957353591918945
Validation loss: 1.990630288918813

Epoch: 6| Step: 10
Training loss: 1.5337430238723755
Validation loss: 2.0137312610944114

Epoch: 6| Step: 11
Training loss: 0.9113467931747437
Validation loss: 1.9679685235023499

Epoch: 6| Step: 12
Training loss: 1.0482722520828247
Validation loss: 1.963449239730835

Epoch: 6| Step: 13
Training loss: 1.019497036933899
Validation loss: 1.9679736097653706

Epoch: 89| Step: 0
Training loss: 1.2065891027450562
Validation loss: 1.9437451163927715

Epoch: 6| Step: 1
Training loss: 1.1129953861236572
Validation loss: 1.9571669499079387

Epoch: 6| Step: 2
Training loss: 0.9908748865127563
Validation loss: 1.9607929189999898

Epoch: 6| Step: 3
Training loss: 1.7394487857818604
Validation loss: 1.985237757364909

Epoch: 6| Step: 4
Training loss: 1.3281497955322266
Validation loss: 2.028952717781067

Epoch: 6| Step: 5
Training loss: 1.5127695798873901
Validation loss: 1.9848744471867878

Epoch: 6| Step: 6
Training loss: 0.7416568994522095
Validation loss: 1.986130138238271

Epoch: 6| Step: 7
Training loss: 0.9738480448722839
Validation loss: 2.031879246234894

Epoch: 6| Step: 8
Training loss: 1.359278678894043
Validation loss: 2.05507093667984

Epoch: 6| Step: 9
Training loss: 1.4284017086029053
Validation loss: 2.0204877456029258

Epoch: 6| Step: 10
Training loss: 0.6386047601699829
Validation loss: 2.0048449436823526

Epoch: 6| Step: 11
Training loss: 1.3820044994354248
Validation loss: 1.9459181825319927

Epoch: 6| Step: 12
Training loss: 1.6182547807693481
Validation loss: 1.985615114370982

Epoch: 6| Step: 13
Training loss: 1.7085051536560059
Validation loss: 1.933467169602712

Epoch: 90| Step: 0
Training loss: 1.338897943496704
Validation loss: 1.9583101669947307

Epoch: 6| Step: 1
Training loss: 0.9747568368911743
Validation loss: 1.9589642683664958

Epoch: 6| Step: 2
Training loss: 1.0615971088409424
Validation loss: 1.9441221157709758

Epoch: 6| Step: 3
Training loss: 1.737351655960083
Validation loss: 1.9589568376541138

Epoch: 6| Step: 4
Training loss: 1.0921177864074707
Validation loss: 1.9969202876091003

Epoch: 6| Step: 5
Training loss: 1.3109610080718994
Validation loss: 2.00252228975296

Epoch: 6| Step: 6
Training loss: 1.4666966199874878
Validation loss: 2.0708843072255454

Epoch: 6| Step: 7
Training loss: 1.4509919881820679
Validation loss: 2.0196786125501

Epoch: 6| Step: 8
Training loss: 1.2410590648651123
Validation loss: 2.0284813245137534

Epoch: 6| Step: 9
Training loss: 1.2401297092437744
Validation loss: 1.976561466852824

Epoch: 6| Step: 10
Training loss: 1.3122234344482422
Validation loss: 1.9297974904378254

Epoch: 6| Step: 11
Training loss: 1.2970596551895142
Validation loss: 1.9305465420087178

Epoch: 6| Step: 12
Training loss: 0.8491359353065491
Validation loss: 1.9788996577262878

Epoch: 6| Step: 13
Training loss: 2.0234766006469727
Validation loss: 1.9504262208938599

Epoch: 91| Step: 0
Training loss: 1.5856997966766357
Validation loss: 1.9652504324913025

Epoch: 6| Step: 1
Training loss: 0.8255481123924255
Validation loss: 1.9882257580757141

Epoch: 6| Step: 2
Training loss: 0.8474280834197998
Validation loss: 1.987515648206075

Epoch: 6| Step: 3
Training loss: 1.6256338357925415
Validation loss: 2.0084190368652344

Epoch: 6| Step: 4
Training loss: 1.4587972164154053
Validation loss: 2.009246567885081

Epoch: 6| Step: 5
Training loss: 1.1758701801300049
Validation loss: 2.0343915621439614

Epoch: 6| Step: 6
Training loss: 1.199726939201355
Validation loss: 2.01039711634318

Epoch: 6| Step: 7
Training loss: 1.209106683731079
Validation loss: 1.9903413852055867

Epoch: 6| Step: 8
Training loss: 1.2804534435272217
Validation loss: 2.0095481673876443

Epoch: 6| Step: 9
Training loss: 1.4526289701461792
Validation loss: 1.9615921179453533

Epoch: 6| Step: 10
Training loss: 1.1425546407699585
Validation loss: 1.9180034796396892

Epoch: 6| Step: 11
Training loss: 1.5346324443817139
Validation loss: 1.9694256782531738

Epoch: 6| Step: 12
Training loss: 1.1643061637878418
Validation loss: 1.958640456199646

Epoch: 6| Step: 13
Training loss: 0.8198014497756958
Validation loss: 1.9514794548352559

Epoch: 92| Step: 0
Training loss: 1.2646045684814453
Validation loss: 1.9893783529599507

Epoch: 6| Step: 1
Training loss: 1.5100899934768677
Validation loss: 2.009999374548594

Epoch: 6| Step: 2
Training loss: 0.9028888940811157
Validation loss: 1.9718910058339436

Epoch: 6| Step: 3
Training loss: 1.4411873817443848
Validation loss: 1.9816976984341939

Epoch: 6| Step: 4
Training loss: 0.45456060767173767
Validation loss: 1.9761974215507507

Epoch: 6| Step: 5
Training loss: 1.4901025295257568
Validation loss: 2.014050920804342

Epoch: 6| Step: 6
Training loss: 1.6548243761062622
Validation loss: 1.9960255026817322

Epoch: 6| Step: 7
Training loss: 0.7367583513259888
Validation loss: 2.0157315333684287

Epoch: 6| Step: 8
Training loss: 1.1633009910583496
Validation loss: 2.006739318370819

Epoch: 6| Step: 9
Training loss: 1.1983718872070312
Validation loss: 2.0180184642473855

Epoch: 6| Step: 10
Training loss: 1.5625568628311157
Validation loss: 1.9836036960283916

Epoch: 6| Step: 11
Training loss: 1.297615885734558
Validation loss: 1.942357103029887

Epoch: 6| Step: 12
Training loss: 1.1292839050292969
Validation loss: 1.9501768549283345

Epoch: 6| Step: 13
Training loss: 1.1948245763778687
Validation loss: 1.966250975926717

Epoch: 93| Step: 0
Training loss: 0.8374967575073242
Validation loss: 1.9615397254625957

Epoch: 6| Step: 1
Training loss: 1.725261926651001
Validation loss: 1.9632689158121746

Epoch: 6| Step: 2
Training loss: 1.2358273267745972
Validation loss: 1.9790595372517903

Epoch: 6| Step: 3
Training loss: 1.4173011779785156
Validation loss: 1.9739724198977153

Epoch: 6| Step: 4
Training loss: 0.8693434000015259
Validation loss: 1.9900500178337097

Epoch: 6| Step: 5
Training loss: 1.8847001791000366
Validation loss: 1.9891313711802165

Epoch: 6| Step: 6
Training loss: 0.6295847296714783
Validation loss: 1.9576145609219868

Epoch: 6| Step: 7
Training loss: 1.2638229131698608
Validation loss: 1.9771581888198853

Epoch: 6| Step: 8
Training loss: 1.2287099361419678
Validation loss: 1.9839694301287334

Epoch: 6| Step: 9
Training loss: 0.8269321918487549
Validation loss: 1.9199580351511638

Epoch: 6| Step: 10
Training loss: 1.0707252025604248
Validation loss: 1.9596431255340576

Epoch: 6| Step: 11
Training loss: 1.0484035015106201
Validation loss: 1.992311159769694

Epoch: 6| Step: 12
Training loss: 1.1614583730697632
Validation loss: 1.9899595181147258

Epoch: 6| Step: 13
Training loss: 1.4927635192871094
Validation loss: 1.9907386700312297

Epoch: 94| Step: 0
Training loss: 1.1588704586029053
Validation loss: 2.0195329984029136

Epoch: 6| Step: 1
Training loss: 1.65276038646698
Validation loss: 1.9907764792442322

Epoch: 6| Step: 2
Training loss: 0.8140059113502502
Validation loss: 1.9446688493092854

Epoch: 6| Step: 3
Training loss: 1.1685776710510254
Validation loss: 1.9860002994537354

Epoch: 6| Step: 4
Training loss: 1.3186118602752686
Validation loss: 1.966411868731181

Epoch: 6| Step: 5
Training loss: 0.4926852583885193
Validation loss: 1.9389248291651409

Epoch: 6| Step: 6
Training loss: 1.6835743188858032
Validation loss: 1.9744187792142232

Epoch: 6| Step: 7
Training loss: 1.1279371976852417
Validation loss: 1.9282726645469666

Epoch: 6| Step: 8
Training loss: 0.9206662178039551
Validation loss: 1.9465468128522236

Epoch: 6| Step: 9
Training loss: 1.5204018354415894
Validation loss: 1.9294885595639546

Epoch: 6| Step: 10
Training loss: 1.378021001815796
Validation loss: 1.9667806426684062

Epoch: 6| Step: 11
Training loss: 1.420835018157959
Validation loss: 1.9503594636917114

Epoch: 6| Step: 12
Training loss: 0.9111114740371704
Validation loss: 1.9980864524841309

Epoch: 6| Step: 13
Training loss: 1.275184988975525
Validation loss: 2.000510573387146

Epoch: 95| Step: 0
Training loss: 1.5347256660461426
Validation loss: 1.9885019461313884

Epoch: 6| Step: 1
Training loss: 1.3441944122314453
Validation loss: 2.0142276883125305

Epoch: 6| Step: 2
Training loss: 0.942794680595398
Validation loss: 1.9913313587506611

Epoch: 6| Step: 3
Training loss: 1.217444658279419
Validation loss: 1.9791802763938904

Epoch: 6| Step: 4
Training loss: 1.2456915378570557
Validation loss: 1.9632661938667297

Epoch: 6| Step: 5
Training loss: 1.0787965059280396
Validation loss: 1.9669654568036397

Epoch: 6| Step: 6
Training loss: 0.9832937717437744
Validation loss: 1.985549807548523

Epoch: 6| Step: 7
Training loss: 1.5008875131607056
Validation loss: 1.976870059967041

Epoch: 6| Step: 8
Training loss: 1.3939893245697021
Validation loss: 1.9379506309827168

Epoch: 6| Step: 9
Training loss: 1.2468953132629395
Validation loss: 1.9414878090222676

Epoch: 6| Step: 10
Training loss: 0.8011148571968079
Validation loss: 1.9394765297571819

Epoch: 6| Step: 11
Training loss: 0.7224308848381042
Validation loss: 1.9237770239512126

Epoch: 6| Step: 12
Training loss: 0.9349279403686523
Validation loss: 1.9713940223058064

Epoch: 6| Step: 13
Training loss: 1.5922207832336426
Validation loss: 1.9633997678756714

Epoch: 96| Step: 0
Training loss: 1.4996633529663086
Validation loss: 1.9779985745747883

Epoch: 6| Step: 1
Training loss: 0.8543122410774231
Validation loss: 1.9593249162038167

Epoch: 6| Step: 2
Training loss: 1.3394575119018555
Validation loss: 1.966093401114146

Epoch: 6| Step: 3
Training loss: 0.9092552661895752
Validation loss: 1.984612246354421

Epoch: 6| Step: 4
Training loss: 1.124600887298584
Validation loss: 1.9940419395764668

Epoch: 6| Step: 5
Training loss: 0.7156491875648499
Validation loss: 2.01458611090978

Epoch: 6| Step: 6
Training loss: 1.227459192276001
Validation loss: 2.004784723122915

Epoch: 6| Step: 7
Training loss: 1.0693224668502808
Validation loss: 1.9724932312965393

Epoch: 6| Step: 8
Training loss: 1.7556806802749634
Validation loss: 1.9624350269635518

Epoch: 6| Step: 9
Training loss: 1.380964756011963
Validation loss: 1.9456123113632202

Epoch: 6| Step: 10
Training loss: 1.4523816108703613
Validation loss: 1.950725257396698

Epoch: 6| Step: 11
Training loss: 1.2791781425476074
Validation loss: 1.8918664852778118

Epoch: 6| Step: 12
Training loss: 1.347736120223999
Validation loss: 1.9454596042633057

Epoch: 6| Step: 13
Training loss: 1.344559907913208
Validation loss: 1.9339017868041992

Epoch: 97| Step: 0
Training loss: 1.3777564764022827
Validation loss: 1.919030209382375

Epoch: 6| Step: 1
Training loss: 0.8791122436523438
Validation loss: 1.9763986468315125

Epoch: 6| Step: 2
Training loss: 1.6596797704696655
Validation loss: 1.961927851041158

Epoch: 6| Step: 3
Training loss: 0.858409583568573
Validation loss: 2.0113122860590615

Epoch: 6| Step: 4
Training loss: 1.1106301546096802
Validation loss: 2.0664788087209067

Epoch: 6| Step: 5
Training loss: 0.8103841543197632
Validation loss: 2.054732322692871

Epoch: 6| Step: 6
Training loss: 1.4345178604125977
Validation loss: 1.976355254650116

Epoch: 6| Step: 7
Training loss: 1.2801365852355957
Validation loss: 2.00831268231074

Epoch: 6| Step: 8
Training loss: 0.5917478799819946
Validation loss: 2.0002755721410117

Epoch: 6| Step: 9
Training loss: 1.1519522666931152
Validation loss: 1.951330542564392

Epoch: 6| Step: 10
Training loss: 1.3650916814804077
Validation loss: 1.9828970432281494

Epoch: 6| Step: 11
Training loss: 1.405531406402588
Validation loss: 1.9922430713971455

Epoch: 6| Step: 12
Training loss: 1.596325397491455
Validation loss: 1.9675171971321106

Epoch: 6| Step: 13
Training loss: 0.9963110089302063
Validation loss: 2.015494386355082

Epoch: 98| Step: 0
Training loss: 1.056844711303711
Validation loss: 2.001235286394755

Epoch: 6| Step: 1
Training loss: 1.0734343528747559
Validation loss: 1.981443703174591

Epoch: 6| Step: 2
Training loss: 0.9746347665786743
Validation loss: 1.9651183485984802

Epoch: 6| Step: 3
Training loss: 1.844508171081543
Validation loss: 1.9638455708821614

Epoch: 6| Step: 4
Training loss: 1.7528051137924194
Validation loss: 1.9480260610580444

Epoch: 6| Step: 5
Training loss: 1.0984116792678833
Validation loss: 1.9656321009000142

Epoch: 6| Step: 6
Training loss: 1.166609287261963
Validation loss: 1.936194360256195

Epoch: 6| Step: 7
Training loss: 1.4848077297210693
Validation loss: 1.990927775700887

Epoch: 6| Step: 8
Training loss: 1.0124216079711914
Validation loss: 1.995305061340332

Epoch: 6| Step: 9
Training loss: 1.0154016017913818
Validation loss: 1.9563950101534526

Epoch: 6| Step: 10
Training loss: 1.079960823059082
Validation loss: 1.9601372480392456

Epoch: 6| Step: 11
Training loss: 0.8964197635650635
Validation loss: 2.0007800857226052

Epoch: 6| Step: 12
Training loss: 0.8279033303260803
Validation loss: 2.0215697288513184

Epoch: 6| Step: 13
Training loss: 1.4181350469589233
Validation loss: 1.9643207987149556

Epoch: 99| Step: 0
Training loss: 1.0552148818969727
Validation loss: 1.980947494506836

Epoch: 6| Step: 1
Training loss: 1.1777887344360352
Validation loss: 1.9463676810264587

Epoch: 6| Step: 2
Training loss: 1.3706724643707275
Validation loss: 1.9393925269444783

Epoch: 6| Step: 3
Training loss: 1.803558349609375
Validation loss: 1.9118035236994426

Epoch: 6| Step: 4
Training loss: 1.20078706741333
Validation loss: 1.9338860114415486

Epoch: 6| Step: 5
Training loss: 1.3918203115463257
Validation loss: 1.9312278827031453

Epoch: 6| Step: 6
Training loss: 1.0074394941329956
Validation loss: 1.9751969575881958

Epoch: 6| Step: 7
Training loss: 0.6832674741744995
Validation loss: 1.9618161519368489

Epoch: 6| Step: 8
Training loss: 1.28313148021698
Validation loss: 1.9973541895548503

Epoch: 6| Step: 9
Training loss: 1.5819919109344482
Validation loss: 1.9525819023450215

Epoch: 6| Step: 10
Training loss: 0.46824216842651367
Validation loss: 1.9887905319531758

Epoch: 6| Step: 11
Training loss: 1.385177493095398
Validation loss: 2.0175644357999167

Epoch: 6| Step: 12
Training loss: 1.121265172958374
Validation loss: 1.9702324469884236

Epoch: 6| Step: 13
Training loss: 0.9322777390480042
Validation loss: 1.9514677325884502

Epoch: 100| Step: 0
Training loss: 0.7897446155548096
Validation loss: 1.985371192296346

Epoch: 6| Step: 1
Training loss: 1.5518748760223389
Validation loss: 1.9466490149497986

Epoch: 6| Step: 2
Training loss: 0.8801045417785645
Validation loss: 1.9831053018569946

Epoch: 6| Step: 3
Training loss: 0.5814168453216553
Validation loss: 1.9931216438611348

Epoch: 6| Step: 4
Training loss: 1.376110315322876
Validation loss: 1.9895377953847249

Epoch: 6| Step: 5
Training loss: 0.8329689502716064
Validation loss: 2.0002082188924155

Epoch: 6| Step: 6
Training loss: 1.394632339477539
Validation loss: 1.9926910599072774

Epoch: 6| Step: 7
Training loss: 1.3985962867736816
Validation loss: 1.9712783892949421

Epoch: 6| Step: 8
Training loss: 1.1274261474609375
Validation loss: 1.9731741944948833

Epoch: 6| Step: 9
Training loss: 1.3714847564697266
Validation loss: 1.9978345235188801

Epoch: 6| Step: 10
Training loss: 1.139306664466858
Validation loss: 1.9364997545878093

Epoch: 6| Step: 11
Training loss: 1.0168664455413818
Validation loss: 1.9648999373118083

Epoch: 6| Step: 12
Training loss: 1.125150203704834
Validation loss: 1.9639345208803813

Epoch: 6| Step: 13
Training loss: 1.2852576971054077
Validation loss: 1.9379414319992065

Epoch: 101| Step: 0
Training loss: 1.5634186267852783
Validation loss: 1.914059082667033

Epoch: 6| Step: 1
Training loss: 0.6755341291427612
Validation loss: 1.9770127137502034

Epoch: 6| Step: 2
Training loss: 1.1576974391937256
Validation loss: 1.9292171796162922

Epoch: 6| Step: 3
Training loss: 1.37454354763031
Validation loss: 2.040164828300476

Epoch: 6| Step: 4
Training loss: 0.8873282670974731
Validation loss: 2.013212502002716

Epoch: 6| Step: 5
Training loss: 1.2376478910446167
Validation loss: 2.0154723525047302

Epoch: 6| Step: 6
Training loss: 0.9508578181266785
Validation loss: 1.987434168656667

Epoch: 6| Step: 7
Training loss: 0.9123827219009399
Validation loss: 1.9751798709233601

Epoch: 6| Step: 8
Training loss: 1.2514113187789917
Validation loss: 1.9755232334136963

Epoch: 6| Step: 9
Training loss: 1.3358206748962402
Validation loss: 1.9377110997835796

Epoch: 6| Step: 10
Training loss: 1.1970596313476562
Validation loss: 1.9211851358413696

Epoch: 6| Step: 11
Training loss: 1.0785441398620605
Validation loss: 1.918985386689504

Epoch: 6| Step: 12
Training loss: 1.592214822769165
Validation loss: 1.9998706976572673

Epoch: 6| Step: 13
Training loss: 0.896934449672699
Validation loss: 1.9807805220286052

Epoch: 102| Step: 0
Training loss: 1.7454280853271484
Validation loss: 1.9787311951319377

Epoch: 6| Step: 1
Training loss: 1.4331687688827515
Validation loss: 1.9994141459465027

Epoch: 6| Step: 2
Training loss: 0.9516652822494507
Validation loss: 1.9942866961161296

Epoch: 6| Step: 3
Training loss: 0.9973396062850952
Validation loss: 1.9622248609860737

Epoch: 6| Step: 4
Training loss: 0.9024597406387329
Validation loss: 1.9630004167556763

Epoch: 6| Step: 5
Training loss: 1.1535828113555908
Validation loss: 1.9494614601135254

Epoch: 6| Step: 6
Training loss: 0.9970868825912476
Validation loss: 1.9758152564366658

Epoch: 6| Step: 7
Training loss: 0.9474028944969177
Validation loss: 1.9363695581754048

Epoch: 6| Step: 8
Training loss: 1.342416524887085
Validation loss: 2.0202080806096396

Epoch: 6| Step: 9
Training loss: 1.2457365989685059
Validation loss: 1.9858413338661194

Epoch: 6| Step: 10
Training loss: 0.9624934792518616
Validation loss: 1.9466456770896912

Epoch: 6| Step: 11
Training loss: 0.9283277988433838
Validation loss: 2.0054099361101785

Epoch: 6| Step: 12
Training loss: 0.8283767700195312
Validation loss: 2.0129482547442117

Epoch: 6| Step: 13
Training loss: 1.2251613140106201
Validation loss: 2.0031804839769998

Epoch: 103| Step: 0
Training loss: 1.6342272758483887
Validation loss: 1.9470149278640747

Epoch: 6| Step: 1
Training loss: 1.3286306858062744
Validation loss: 1.9602151115735371

Epoch: 6| Step: 2
Training loss: 1.4076013565063477
Validation loss: 1.9554906884829204

Epoch: 6| Step: 3
Training loss: 1.1847848892211914
Validation loss: 1.9306734005610149

Epoch: 6| Step: 4
Training loss: 0.9644856452941895
Validation loss: 1.9531051516532898

Epoch: 6| Step: 5
Training loss: 1.2975239753723145
Validation loss: 1.952249526977539

Epoch: 6| Step: 6
Training loss: 0.8886853456497192
Validation loss: 1.9741291999816895

Epoch: 6| Step: 7
Training loss: 1.1228914260864258
Validation loss: 2.021923065185547

Epoch: 6| Step: 8
Training loss: 1.0895817279815674
Validation loss: 2.0601232250531516

Epoch: 6| Step: 9
Training loss: 0.7631257772445679
Validation loss: 1.9962526162465413

Epoch: 6| Step: 10
Training loss: 1.548258662223816
Validation loss: 1.9940338134765625

Epoch: 6| Step: 11
Training loss: 0.9201552867889404
Validation loss: 2.02054230372111

Epoch: 6| Step: 12
Training loss: 0.6213047504425049
Validation loss: 1.9978666702906291

Epoch: 6| Step: 13
Training loss: 0.7269854545593262
Validation loss: 2.008858064810435

Epoch: 104| Step: 0
Training loss: 1.3540349006652832
Validation loss: 1.996245761712392

Epoch: 6| Step: 1
Training loss: 1.3769829273223877
Validation loss: 2.0348423520723977

Epoch: 6| Step: 2
Training loss: 1.2043368816375732
Validation loss: 2.051587700843811

Epoch: 6| Step: 3
Training loss: 0.3693636953830719
Validation loss: 2.0394585927327475

Epoch: 6| Step: 4
Training loss: 1.0992975234985352
Validation loss: 2.013431191444397

Epoch: 6| Step: 5
Training loss: 0.946533203125
Validation loss: 2.0311848719914756

Epoch: 6| Step: 6
Training loss: 0.795386552810669
Validation loss: 2.0204617381095886

Epoch: 6| Step: 7
Training loss: 0.5225790739059448
Validation loss: 1.9958542585372925

Epoch: 6| Step: 8
Training loss: 1.1101183891296387
Validation loss: 1.9477798144022624

Epoch: 6| Step: 9
Training loss: 1.3774571418762207
Validation loss: 1.9803046981493633

Epoch: 6| Step: 10
Training loss: 1.0545958280563354
Validation loss: 1.978974183400472

Epoch: 6| Step: 11
Training loss: 1.3623895645141602
Validation loss: 1.9850396315256755

Epoch: 6| Step: 12
Training loss: 1.0691783428192139
Validation loss: 1.962860147158305

Epoch: 6| Step: 13
Training loss: 1.3287090063095093
Validation loss: 1.982839862505595

Epoch: 105| Step: 0
Training loss: 1.336435079574585
Validation loss: 1.9504133661588032

Epoch: 6| Step: 1
Training loss: 1.069931983947754
Validation loss: 1.9405237436294556

Epoch: 6| Step: 2
Training loss: 0.8035848736763
Validation loss: 1.9335081378618877

Epoch: 6| Step: 3
Training loss: 0.9097656011581421
Validation loss: 1.9536122878392537

Epoch: 6| Step: 4
Training loss: 1.3171172142028809
Validation loss: 1.9671444495519002

Epoch: 6| Step: 5
Training loss: 0.9948180913925171
Validation loss: 2.0076241294542947

Epoch: 6| Step: 6
Training loss: 1.0419665575027466
Validation loss: 2.01675017674764

Epoch: 6| Step: 7
Training loss: 0.9373945593833923
Validation loss: 2.003643016020457

Epoch: 6| Step: 8
Training loss: 1.2323734760284424
Validation loss: 2.023699680964152

Epoch: 6| Step: 9
Training loss: 1.3041064739227295
Validation loss: 2.038325011730194

Epoch: 6| Step: 10
Training loss: 0.6952494978904724
Validation loss: 2.0177089174588523

Epoch: 6| Step: 11
Training loss: 1.6311365365982056
Validation loss: 2.013852854569753

Epoch: 6| Step: 12
Training loss: 1.914825439453125
Validation loss: 2.009381592273712

Epoch: 6| Step: 13
Training loss: 0.29858800768852234
Validation loss: 1.970354696114858

Epoch: 106| Step: 0
Training loss: 0.902135968208313
Validation loss: 1.981139878431956

Epoch: 6| Step: 1
Training loss: 1.199371099472046
Validation loss: 1.998908559481303

Epoch: 6| Step: 2
Training loss: 1.2936750650405884
Validation loss: 2.0123782952626548

Epoch: 6| Step: 3
Training loss: 1.2483251094818115
Validation loss: 1.940029005209605

Epoch: 6| Step: 4
Training loss: 0.8730222582817078
Validation loss: 1.968700071175893

Epoch: 6| Step: 5
Training loss: 1.319180965423584
Validation loss: 2.002651274204254

Epoch: 6| Step: 6
Training loss: 1.0807628631591797
Validation loss: 2.0077228347460427

Epoch: 6| Step: 7
Training loss: 1.312261939048767
Validation loss: 1.999311586221059

Epoch: 6| Step: 8
Training loss: 0.9131494760513306
Validation loss: 1.9894268711407979

Epoch: 6| Step: 9
Training loss: 0.8053991198539734
Validation loss: 2.049420634905497

Epoch: 6| Step: 10
Training loss: 1.0210729837417603
Validation loss: 2.0004701813062034

Epoch: 6| Step: 11
Training loss: 1.1739262342453003
Validation loss: 1.983946959177653

Epoch: 6| Step: 12
Training loss: 0.917392373085022
Validation loss: 1.965433418750763

Epoch: 6| Step: 13
Training loss: 1.0834100246429443
Validation loss: 2.009000539779663

Epoch: 107| Step: 0
Training loss: 0.7298475503921509
Validation loss: 2.0074127515157065

Epoch: 6| Step: 1
Training loss: 0.8985309600830078
Validation loss: 1.96221262216568

Epoch: 6| Step: 2
Training loss: 0.8728030920028687
Validation loss: 1.9436353246370952

Epoch: 6| Step: 3
Training loss: 1.3103598356246948
Validation loss: 1.9895745118459065

Epoch: 6| Step: 4
Training loss: 0.7571892738342285
Validation loss: 1.9743226766586304

Epoch: 6| Step: 5
Training loss: 0.9513423442840576
Validation loss: 2.00403501590093

Epoch: 6| Step: 6
Training loss: 1.2525769472122192
Validation loss: 2.007762869199117

Epoch: 6| Step: 7
Training loss: 0.9678892493247986
Validation loss: 2.027559200922648

Epoch: 6| Step: 8
Training loss: 0.8763891458511353
Validation loss: 2.053308288256327

Epoch: 6| Step: 9
Training loss: 0.7911701798439026
Validation loss: 2.0173861384391785

Epoch: 6| Step: 10
Training loss: 2.057933807373047
Validation loss: 1.9800982276598613

Epoch: 6| Step: 11
Training loss: 1.1076631546020508
Validation loss: 1.9951261480649312

Epoch: 6| Step: 12
Training loss: 1.0963213443756104
Validation loss: 1.9834707975387573

Epoch: 6| Step: 13
Training loss: 1.2235875129699707
Validation loss: 1.976176420847575

Epoch: 108| Step: 0
Training loss: 1.2076128721237183
Validation loss: 2.0513232549031577

Epoch: 6| Step: 1
Training loss: 0.36628714203834534
Validation loss: 2.022514899571737

Epoch: 6| Step: 2
Training loss: 1.281999111175537
Validation loss: 2.025204122066498

Epoch: 6| Step: 3
Training loss: 1.039157748222351
Validation loss: 2.0260861118634543

Epoch: 6| Step: 4
Training loss: 1.1911317110061646
Validation loss: 2.0250701109568277

Epoch: 6| Step: 5
Training loss: 1.4001638889312744
Validation loss: 2.017276406288147

Epoch: 6| Step: 6
Training loss: 0.6570506691932678
Validation loss: 2.0133686661720276

Epoch: 6| Step: 7
Training loss: 1.0554745197296143
Validation loss: 1.9501444896062214

Epoch: 6| Step: 8
Training loss: 0.9318158030509949
Validation loss: 1.9966829816500347

Epoch: 6| Step: 9
Training loss: 1.1222498416900635
Validation loss: 1.9741138021151226

Epoch: 6| Step: 10
Training loss: 0.9587884545326233
Validation loss: 1.9611460367838542

Epoch: 6| Step: 11
Training loss: 1.1936919689178467
Validation loss: 1.974901835123698

Epoch: 6| Step: 12
Training loss: 1.3534951210021973
Validation loss: 1.9826494852701824

Epoch: 6| Step: 13
Training loss: 0.6656510829925537
Validation loss: 1.990857481956482

Epoch: 109| Step: 0
Training loss: 1.2910317182540894
Validation loss: 2.015763541062673

Epoch: 6| Step: 1
Training loss: 0.9258519411087036
Validation loss: 1.9926044543584187

Epoch: 6| Step: 2
Training loss: 1.0364234447479248
Validation loss: 1.980542818705241

Epoch: 6| Step: 3
Training loss: 1.4788492918014526
Validation loss: 1.997004012266795

Epoch: 6| Step: 4
Training loss: 0.5779702663421631
Validation loss: 1.9737441539764404

Epoch: 6| Step: 5
Training loss: 1.315791130065918
Validation loss: 1.9586204687754314

Epoch: 6| Step: 6
Training loss: 0.8854191899299622
Validation loss: 1.9814373254776

Epoch: 6| Step: 7
Training loss: 1.118603229522705
Validation loss: 1.9952529271443684

Epoch: 6| Step: 8
Training loss: 1.037563443183899
Validation loss: 1.976862867673238

Epoch: 6| Step: 9
Training loss: 0.5984202027320862
Validation loss: 1.9851982196172078

Epoch: 6| Step: 10
Training loss: 1.1073507070541382
Validation loss: 1.9779462814331055

Epoch: 6| Step: 11
Training loss: 1.16843581199646
Validation loss: 1.9577867190043132

Epoch: 6| Step: 12
Training loss: 0.8552677631378174
Validation loss: 1.9998552997907002

Epoch: 6| Step: 13
Training loss: 1.2264211177825928
Validation loss: 1.9430705904960632

Epoch: 110| Step: 0
Training loss: 1.3841865062713623
Validation loss: 1.9686306516329448

Epoch: 6| Step: 1
Training loss: 0.7467193603515625
Validation loss: 2.0050562222798667

Epoch: 6| Step: 2
Training loss: 0.8390544652938843
Validation loss: 2.059320390224457

Epoch: 6| Step: 3
Training loss: 1.1164336204528809
Validation loss: 2.0566145380338035

Epoch: 6| Step: 4
Training loss: 1.0756428241729736
Validation loss: 2.0281684597333274

Epoch: 6| Step: 5
Training loss: 1.1750773191452026
Validation loss: 1.9517608483632405

Epoch: 6| Step: 6
Training loss: 1.0543138980865479
Validation loss: 1.989820698897044

Epoch: 6| Step: 7
Training loss: 1.5945250988006592
Validation loss: 1.9356058239936829

Epoch: 6| Step: 8
Training loss: 0.8220903277397156
Validation loss: 1.9691187342007954

Epoch: 6| Step: 9
Training loss: 1.0051922798156738
Validation loss: 1.9426234364509583

Epoch: 6| Step: 10
Training loss: 1.259413242340088
Validation loss: 1.9540399710337322

Epoch: 6| Step: 11
Training loss: 0.675544023513794
Validation loss: 1.9353045423825581

Epoch: 6| Step: 12
Training loss: 0.757702648639679
Validation loss: 1.988938570022583

Epoch: 6| Step: 13
Training loss: 1.011321783065796
Validation loss: 2.0029463370641074

Epoch: 111| Step: 0
Training loss: 1.3638789653778076
Validation loss: 1.9737566312154133

Epoch: 6| Step: 1
Training loss: 1.4836773872375488
Validation loss: 1.9750918944676716

Epoch: 6| Step: 2
Training loss: 0.29499679803848267
Validation loss: 2.0022268493970237

Epoch: 6| Step: 3
Training loss: 0.8821790218353271
Validation loss: 1.9467086990674336

Epoch: 6| Step: 4
Training loss: 1.0411720275878906
Validation loss: 1.9521504044532776

Epoch: 6| Step: 5
Training loss: 1.1563222408294678
Validation loss: 1.9479866822560628

Epoch: 6| Step: 6
Training loss: 1.1614651679992676
Validation loss: 1.9768200516700745

Epoch: 6| Step: 7
Training loss: 1.2692313194274902
Validation loss: 1.9637670715649922

Epoch: 6| Step: 8
Training loss: 1.059735894203186
Validation loss: 1.9375307361284893

Epoch: 6| Step: 9
Training loss: 0.8251771926879883
Validation loss: 1.993113398551941

Epoch: 6| Step: 10
Training loss: 0.9498831033706665
Validation loss: 2.000214954217275

Epoch: 6| Step: 11
Training loss: 1.477699637413025
Validation loss: 2.0570506850878396

Epoch: 6| Step: 12
Training loss: 0.6513790488243103
Validation loss: 2.0795843799908957

Epoch: 6| Step: 13
Training loss: 1.0084543228149414
Validation loss: 2.0747258265813193

Epoch: 112| Step: 0
Training loss: 1.2176620960235596
Validation loss: 2.0032872557640076

Epoch: 6| Step: 1
Training loss: 1.1552913188934326
Validation loss: 2.00637157758077

Epoch: 6| Step: 2
Training loss: 1.0670173168182373
Validation loss: 1.989111324151357

Epoch: 6| Step: 3
Training loss: 1.0821940898895264
Validation loss: 1.931606372197469

Epoch: 6| Step: 4
Training loss: 1.0990259647369385
Validation loss: 2.0355247259140015

Epoch: 6| Step: 5
Training loss: 1.1366053819656372
Validation loss: 1.9640559554100037

Epoch: 6| Step: 6
Training loss: 0.8723046779632568
Validation loss: 1.9968530138333638

Epoch: 6| Step: 7
Training loss: 0.8603093028068542
Validation loss: 2.0184999903043113

Epoch: 6| Step: 8
Training loss: 0.7601426839828491
Validation loss: 1.9582198063532512

Epoch: 6| Step: 9
Training loss: 0.7920196652412415
Validation loss: 2.081973691781362

Epoch: 6| Step: 10
Training loss: 0.8599408268928528
Validation loss: 2.0206310153007507

Epoch: 6| Step: 11
Training loss: 1.2607665061950684
Validation loss: 2.082732399304708

Epoch: 6| Step: 12
Training loss: 1.0737898349761963
Validation loss: 2.0590264002482095

Epoch: 6| Step: 13
Training loss: 1.2957245111465454
Validation loss: 2.044821778933207

Epoch: 113| Step: 0
Training loss: 1.028944492340088
Validation loss: 2.0629369815190635

Epoch: 6| Step: 1
Training loss: 0.7879339456558228
Validation loss: 2.0235551794370017

Epoch: 6| Step: 2
Training loss: 0.8660280704498291
Validation loss: 1.9972113768259685

Epoch: 6| Step: 3
Training loss: 1.0633008480072021
Validation loss: 2.001934210459391

Epoch: 6| Step: 4
Training loss: 0.8787724375724792
Validation loss: 2.002073129018148

Epoch: 6| Step: 5
Training loss: 1.5617296695709229
Validation loss: 2.0467474659283957

Epoch: 6| Step: 6
Training loss: 1.1780143976211548
Validation loss: 1.979905327161153

Epoch: 6| Step: 7
Training loss: 1.05586838722229
Validation loss: 2.00732030471166

Epoch: 6| Step: 8
Training loss: 1.2389944791793823
Validation loss: 2.010541617870331

Epoch: 6| Step: 9
Training loss: 1.0395863056182861
Validation loss: 2.0427892208099365

Epoch: 6| Step: 10
Training loss: 1.111993670463562
Validation loss: 2.087384740511576

Epoch: 6| Step: 11
Training loss: 0.6904118061065674
Validation loss: 2.0555264353752136

Epoch: 6| Step: 12
Training loss: 0.8664026260375977
Validation loss: 2.0977065165837607

Epoch: 6| Step: 13
Training loss: 2.001779556274414
Validation loss: 2.0212204655011496

Epoch: 114| Step: 0
Training loss: 0.7327013611793518
Validation loss: 2.013704001903534

Epoch: 6| Step: 1
Training loss: 0.8830801248550415
Validation loss: 1.9703354438145955

Epoch: 6| Step: 2
Training loss: 1.06072199344635
Validation loss: 1.9718361894289653

Epoch: 6| Step: 3
Training loss: 1.4072518348693848
Validation loss: 1.9571935931841533

Epoch: 6| Step: 4
Training loss: 1.2310950756072998
Validation loss: 2.0063854257265725

Epoch: 6| Step: 5
Training loss: 0.6234167814254761
Validation loss: 1.9970435897509258

Epoch: 6| Step: 6
Training loss: 0.9785219430923462
Validation loss: 1.9908396005630493

Epoch: 6| Step: 7
Training loss: 1.1350109577178955
Validation loss: 2.030972103277842

Epoch: 6| Step: 8
Training loss: 0.7723709344863892
Validation loss: 1.9869829614957173

Epoch: 6| Step: 9
Training loss: 1.3926894664764404
Validation loss: 2.0106889804204306

Epoch: 6| Step: 10
Training loss: 0.9770865440368652
Validation loss: 2.0406395196914673

Epoch: 6| Step: 11
Training loss: 0.4283967614173889
Validation loss: 1.975600818792979

Epoch: 6| Step: 12
Training loss: 1.3380284309387207
Validation loss: 1.9923675457636516

Epoch: 6| Step: 13
Training loss: 1.2067879438400269
Validation loss: 1.9458896120389302

Epoch: 115| Step: 0
Training loss: 1.0089693069458008
Validation loss: 1.9440404971440632

Epoch: 6| Step: 1
Training loss: 0.8957631587982178
Validation loss: 1.9735405047734578

Epoch: 6| Step: 2
Training loss: 1.4602758884429932
Validation loss: 1.9567665656407673

Epoch: 6| Step: 3
Training loss: 0.7044920921325684
Validation loss: 2.0441561341285706

Epoch: 6| Step: 4
Training loss: 0.7272645235061646
Validation loss: 1.9821712374687195

Epoch: 6| Step: 5
Training loss: 1.203305721282959
Validation loss: 2.0406755208969116

Epoch: 6| Step: 6
Training loss: 0.9458434581756592
Validation loss: 2.097523808479309

Epoch: 6| Step: 7
Training loss: 0.7974367141723633
Validation loss: 2.0510918696721396

Epoch: 6| Step: 8
Training loss: 1.741732120513916
Validation loss: 2.0294185280799866

Epoch: 6| Step: 9
Training loss: 0.451976478099823
Validation loss: 1.9334639310836792

Epoch: 6| Step: 10
Training loss: 0.7337292432785034
Validation loss: 2.0148032903671265

Epoch: 6| Step: 11
Training loss: 1.0299656391143799
Validation loss: 1.9780594110488892

Epoch: 6| Step: 12
Training loss: 0.9559582471847534
Validation loss: 2.00259139140447

Epoch: 6| Step: 13
Training loss: 1.862720012664795
Validation loss: 1.9728715022404988

Epoch: 116| Step: 0
Training loss: 0.9860237836837769
Validation loss: 1.9723235567410786

Epoch: 6| Step: 1
Training loss: 0.9896733164787292
Validation loss: 1.9743319153785706

Epoch: 6| Step: 2
Training loss: 0.6830509901046753
Validation loss: 2.0073321064313254

Epoch: 6| Step: 3
Training loss: 1.0437164306640625
Validation loss: 2.055891434351603

Epoch: 6| Step: 4
Training loss: 1.4123759269714355
Validation loss: 2.0371258656183877

Epoch: 6| Step: 5
Training loss: 1.4567787647247314
Validation loss: 1.9951420823733013

Epoch: 6| Step: 6
Training loss: 0.6109524369239807
Validation loss: 2.0177399714787803

Epoch: 6| Step: 7
Training loss: 1.0134944915771484
Validation loss: 1.9872931440671284

Epoch: 6| Step: 8
Training loss: 1.1572208404541016
Validation loss: 2.0122990012168884

Epoch: 6| Step: 9
Training loss: 0.8543386459350586
Validation loss: 2.0059638222058616

Epoch: 6| Step: 10
Training loss: 0.7278106808662415
Validation loss: 2.0092304944992065

Epoch: 6| Step: 11
Training loss: 1.3925106525421143
Validation loss: 2.0308952927589417

Epoch: 6| Step: 12
Training loss: 0.9854673743247986
Validation loss: 1.9217455387115479

Epoch: 6| Step: 13
Training loss: 0.5906482934951782
Validation loss: 1.9750039180119832

Epoch: 117| Step: 0
Training loss: 0.7153278589248657
Validation loss: 1.9819032947222393

Epoch: 6| Step: 1
Training loss: 0.8013763427734375
Validation loss: 1.9693973660469055

Epoch: 6| Step: 2
Training loss: 1.3399324417114258
Validation loss: 2.0301865140597024

Epoch: 6| Step: 3
Training loss: 1.004679799079895
Validation loss: 2.003516912460327

Epoch: 6| Step: 4
Training loss: 0.9721854329109192
Validation loss: 1.9705716172854106

Epoch: 6| Step: 5
Training loss: 0.9300085306167603
Validation loss: 1.9935639103253682

Epoch: 6| Step: 6
Training loss: 0.8697546124458313
Validation loss: 2.009120066960653

Epoch: 6| Step: 7
Training loss: 1.346045970916748
Validation loss: 1.9636579553286235

Epoch: 6| Step: 8
Training loss: 1.1395703554153442
Validation loss: 1.95473708709081

Epoch: 6| Step: 9
Training loss: 1.2518184185028076
Validation loss: 1.9999513030052185

Epoch: 6| Step: 10
Training loss: 0.9843449592590332
Validation loss: 2.013279219468435

Epoch: 6| Step: 11
Training loss: 0.6844255328178406
Validation loss: 1.9979057709376018

Epoch: 6| Step: 12
Training loss: 0.7255803346633911
Validation loss: 1.9582626620928447

Epoch: 6| Step: 13
Training loss: 0.8581777811050415
Validation loss: 2.025788346926371

Epoch: 118| Step: 0
Training loss: 0.8651506900787354
Validation loss: 2.0343570510546365

Epoch: 6| Step: 1
Training loss: 0.5383443236351013
Validation loss: 2.0303079883257547

Epoch: 6| Step: 2
Training loss: 1.1598687171936035
Validation loss: 2.01070773601532

Epoch: 6| Step: 3
Training loss: 0.7998069524765015
Validation loss: 2.0323368310928345

Epoch: 6| Step: 4
Training loss: 0.9294264316558838
Validation loss: 2.0337690114974976

Epoch: 6| Step: 5
Training loss: 0.41305094957351685
Validation loss: 1.9698285857836406

Epoch: 6| Step: 6
Training loss: 0.7654393315315247
Validation loss: 2.021589756011963

Epoch: 6| Step: 7
Training loss: 1.0066065788269043
Validation loss: 2.0039302508036294

Epoch: 6| Step: 8
Training loss: 1.1672090291976929
Validation loss: 2.0193855365117392

Epoch: 6| Step: 9
Training loss: 1.0282456874847412
Validation loss: 1.9857279459635417

Epoch: 6| Step: 10
Training loss: 1.0636147260665894
Validation loss: 2.021239479382833

Epoch: 6| Step: 11
Training loss: 0.737925112247467
Validation loss: 2.0387601057688394

Epoch: 6| Step: 12
Training loss: 1.5783060789108276
Validation loss: 1.992776056130727

Epoch: 6| Step: 13
Training loss: 1.2198392152786255
Validation loss: 1.989997406800588

Epoch: 119| Step: 0
Training loss: 0.5103682279586792
Validation loss: 1.9810944199562073

Epoch: 6| Step: 1
Training loss: 1.0147408246994019
Validation loss: 2.0307838122049966

Epoch: 6| Step: 2
Training loss: 1.37662935256958
Validation loss: 1.9874380032221477

Epoch: 6| Step: 3
Training loss: 0.8938193917274475
Validation loss: 1.993766963481903

Epoch: 6| Step: 4
Training loss: 0.7805702090263367
Validation loss: 2.0096304217974343

Epoch: 6| Step: 5
Training loss: 1.3847525119781494
Validation loss: 2.015393634637197

Epoch: 6| Step: 6
Training loss: 0.6316185593605042
Validation loss: 1.956726650396983

Epoch: 6| Step: 7
Training loss: 0.9380475878715515
Validation loss: 2.000861883163452

Epoch: 6| Step: 8
Training loss: 0.42776018381118774
Validation loss: 2.005622227986654

Epoch: 6| Step: 9
Training loss: 0.8779295086860657
Validation loss: 1.9979481895764668

Epoch: 6| Step: 10
Training loss: 0.9687889218330383
Validation loss: 2.003873030344645

Epoch: 6| Step: 11
Training loss: 0.7653199434280396
Validation loss: 2.074026048183441

Epoch: 6| Step: 12
Training loss: 1.348554253578186
Validation loss: 2.0364341735839844

Epoch: 6| Step: 13
Training loss: 1.1864402294158936
Validation loss: 1.994696319103241

Epoch: 120| Step: 0
Training loss: 0.3979240655899048
Validation loss: 2.0071726044019065

Epoch: 6| Step: 1
Training loss: 0.7688436508178711
Validation loss: 1.9844085574150085

Epoch: 6| Step: 2
Training loss: 0.6845710277557373
Validation loss: 2.0125697255134583

Epoch: 6| Step: 3
Training loss: 1.3133480548858643
Validation loss: 2.0192837715148926

Epoch: 6| Step: 4
Training loss: 0.7196394205093384
Validation loss: 2.0034379760424295

Epoch: 6| Step: 5
Training loss: 0.7498732805252075
Validation loss: 1.966826816399892

Epoch: 6| Step: 6
Training loss: 1.1705000400543213
Validation loss: 1.9840072989463806

Epoch: 6| Step: 7
Training loss: 0.6681254506111145
Validation loss: 2.020055572191874

Epoch: 6| Step: 8
Training loss: 1.0317637920379639
Validation loss: 2.017864724000295

Epoch: 6| Step: 9
Training loss: 0.7714453935623169
Validation loss: 2.027664085229238

Epoch: 6| Step: 10
Training loss: 2.161909818649292
Validation loss: 2.019696036974589

Epoch: 6| Step: 11
Training loss: 0.7125027179718018
Validation loss: 2.0423985719680786

Epoch: 6| Step: 12
Training loss: 1.1921615600585938
Validation loss: 2.014034390449524

Epoch: 6| Step: 13
Training loss: 1.039952278137207
Validation loss: 2.012170751889547

Epoch: 121| Step: 0
Training loss: 1.1933410167694092
Validation loss: 1.9699540932973225

Epoch: 6| Step: 1
Training loss: 1.8587126731872559
Validation loss: 1.986498276392619

Epoch: 6| Step: 2
Training loss: 0.7121472954750061
Validation loss: 2.0258017778396606

Epoch: 6| Step: 3
Training loss: 1.3114690780639648
Validation loss: 2.046929200490316

Epoch: 6| Step: 4
Training loss: 0.8195692300796509
Validation loss: 2.0591564575831094

Epoch: 6| Step: 5
Training loss: 0.7894284725189209
Validation loss: 2.0160837173461914

Epoch: 6| Step: 6
Training loss: 1.2374128103256226
Validation loss: 2.0247082312901816

Epoch: 6| Step: 7
Training loss: 1.0013833045959473
Validation loss: 2.003302733103434

Epoch: 6| Step: 8
Training loss: 0.9364492297172546
Validation loss: 2.0197975635528564

Epoch: 6| Step: 9
Training loss: 1.0004440546035767
Validation loss: 2.0357808272043862

Epoch: 6| Step: 10
Training loss: 0.803803026676178
Validation loss: 1.997929871082306

Epoch: 6| Step: 11
Training loss: 0.6027662754058838
Validation loss: 1.9810913602511089

Epoch: 6| Step: 12
Training loss: 0.5860904455184937
Validation loss: 2.028448780377706

Epoch: 6| Step: 13
Training loss: 0.2939925491809845
Validation loss: 2.021350006262461

Epoch: 122| Step: 0
Training loss: 0.9290019273757935
Validation loss: 1.9946390787760417

Epoch: 6| Step: 1
Training loss: 0.8188612461090088
Validation loss: 2.033226231733958

Epoch: 6| Step: 2
Training loss: 0.7651629447937012
Validation loss: 1.9986198544502258

Epoch: 6| Step: 3
Training loss: 0.966500997543335
Validation loss: 1.9653358856836955

Epoch: 6| Step: 4
Training loss: 1.1548914909362793
Validation loss: 2.0067167480786643

Epoch: 6| Step: 5
Training loss: 1.62152099609375
Validation loss: 1.9769798517227173

Epoch: 6| Step: 6
Training loss: 1.1396219730377197
Validation loss: 2.011501888434092

Epoch: 6| Step: 7
Training loss: 0.8216053247451782
Validation loss: 2.0266268452008567

Epoch: 6| Step: 8
Training loss: 0.8161097764968872
Validation loss: 2.0384470025698342

Epoch: 6| Step: 9
Training loss: 0.9996085166931152
Validation loss: 1.9639215270678203

Epoch: 6| Step: 10
Training loss: 0.9243773221969604
Validation loss: 1.9960242708524067

Epoch: 6| Step: 11
Training loss: 0.774605929851532
Validation loss: 2.010013699531555

Epoch: 6| Step: 12
Training loss: 0.46077755093574524
Validation loss: 1.9945669571558635

Epoch: 6| Step: 13
Training loss: 0.83775794506073
Validation loss: 2.014410972595215

Epoch: 123| Step: 0
Training loss: 1.1044813394546509
Validation loss: 2.0270056327184043

Epoch: 6| Step: 1
Training loss: 0.6442971229553223
Validation loss: 2.0183459917704263

Epoch: 6| Step: 2
Training loss: 0.7492647171020508
Validation loss: 2.018243432044983

Epoch: 6| Step: 3
Training loss: 1.0178569555282593
Validation loss: 1.9742554227511089

Epoch: 6| Step: 4
Training loss: 1.1161503791809082
Validation loss: 1.9829871654510498

Epoch: 6| Step: 5
Training loss: 1.0374187231063843
Validation loss: 2.036708394686381

Epoch: 6| Step: 6
Training loss: 0.7655692100524902
Validation loss: 1.9964436690012615

Epoch: 6| Step: 7
Training loss: 0.9822643995285034
Validation loss: 1.9611413876215618

Epoch: 6| Step: 8
Training loss: 1.1200854778289795
Validation loss: 2.046772758165995

Epoch: 6| Step: 9
Training loss: 1.0853896141052246
Validation loss: 2.046644469102224

Epoch: 6| Step: 10
Training loss: 0.7970442175865173
Validation loss: 2.0304994185765586

Epoch: 6| Step: 11
Training loss: 1.1477171182632446
Validation loss: 2.077315628528595

Epoch: 6| Step: 12
Training loss: 1.0989418029785156
Validation loss: 2.0536874532699585

Epoch: 6| Step: 13
Training loss: 0.5947062969207764
Validation loss: 2.069036841392517

Epoch: 124| Step: 0
Training loss: 0.9530843496322632
Validation loss: 2.0357126593589783

Epoch: 6| Step: 1
Training loss: 0.6989148259162903
Validation loss: 2.0018773873647056

Epoch: 6| Step: 2
Training loss: 1.0002455711364746
Validation loss: 2.0054434339205423

Epoch: 6| Step: 3
Training loss: 0.7117515802383423
Validation loss: 1.9837328791618347

Epoch: 6| Step: 4
Training loss: 1.1490907669067383
Validation loss: 1.9919428825378418

Epoch: 6| Step: 5
Training loss: 1.4049623012542725
Validation loss: 2.0025968154271445

Epoch: 6| Step: 6
Training loss: 1.4944329261779785
Validation loss: 2.0063395500183105

Epoch: 6| Step: 7
Training loss: 1.1168214082717896
Validation loss: 2.056839108467102

Epoch: 6| Step: 8
Training loss: 1.1802209615707397
Validation loss: 2.0698732137680054

Epoch: 6| Step: 9
Training loss: 0.5414113402366638
Validation loss: 2.0634819666544595

Epoch: 6| Step: 10
Training loss: 0.6488429307937622
Validation loss: 2.017541309197744

Epoch: 6| Step: 11
Training loss: 0.8774678111076355
Validation loss: 2.002683182557424

Epoch: 6| Step: 12
Training loss: 0.7588375806808472
Validation loss: 1.9745052456855774

Epoch: 6| Step: 13
Training loss: 0.9667974710464478
Validation loss: 2.0004042387008667

Epoch: 125| Step: 0
Training loss: 1.057827353477478
Validation loss: 1.9914247592290242

Epoch: 6| Step: 1
Training loss: 1.3396751880645752
Validation loss: 1.987009863058726

Epoch: 6| Step: 2
Training loss: 1.342868447303772
Validation loss: 2.016619642575582

Epoch: 6| Step: 3
Training loss: 0.6468544006347656
Validation loss: 1.99105304479599

Epoch: 6| Step: 4
Training loss: 0.562260627746582
Validation loss: 2.053928871949514

Epoch: 6| Step: 5
Training loss: 1.2566277980804443
Validation loss: 2.029349664847056

Epoch: 6| Step: 6
Training loss: 1.2289305925369263
Validation loss: 2.034543812274933

Epoch: 6| Step: 7
Training loss: 0.642546534538269
Validation loss: 2.0659767985343933

Epoch: 6| Step: 8
Training loss: 0.9960893392562866
Validation loss: 2.026441196600596

Epoch: 6| Step: 9
Training loss: 1.0306034088134766
Validation loss: 2.0505571762720742

Epoch: 6| Step: 10
Training loss: 0.7375785112380981
Validation loss: 1.997135877609253

Epoch: 6| Step: 11
Training loss: 0.9366948008537292
Validation loss: 2.0197277466456094

Epoch: 6| Step: 12
Training loss: 0.6368633508682251
Validation loss: 1.9954599539438884

Epoch: 6| Step: 13
Training loss: 0.7836441993713379
Validation loss: 2.0216225584348044

Testing loss: 1.8074586348567936
