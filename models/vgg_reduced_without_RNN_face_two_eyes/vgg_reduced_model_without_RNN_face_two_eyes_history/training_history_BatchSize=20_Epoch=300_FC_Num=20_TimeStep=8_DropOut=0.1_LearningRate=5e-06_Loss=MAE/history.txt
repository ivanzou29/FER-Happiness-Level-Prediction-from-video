Epoch: 1| Step: 0
Training loss: 5.99453067779541
Validation loss: 5.597842613855998

Epoch: 5| Step: 1
Training loss: 4.939342498779297
Validation loss: 5.560801486174266

Epoch: 5| Step: 2
Training loss: 5.428839683532715
Validation loss: 5.525745848814647

Epoch: 5| Step: 3
Training loss: 6.197635650634766
Validation loss: 5.4887251655260725

Epoch: 5| Step: 4
Training loss: 5.198335647583008
Validation loss: 5.456199546655019

Epoch: 5| Step: 5
Training loss: 5.538328647613525
Validation loss: 5.420834422111511

Epoch: 5| Step: 6
Training loss: 6.034764289855957
Validation loss: 5.386430283387502

Epoch: 5| Step: 7
Training loss: 5.831577301025391
Validation loss: 5.3506582379341125

Epoch: 5| Step: 8
Training loss: 5.484626293182373
Validation loss: 5.315949221452077

Epoch: 5| Step: 9
Training loss: 5.330047607421875
Validation loss: 5.276491979757945

Epoch: 5| Step: 10
Training loss: 4.361903190612793
Validation loss: 5.238138516743978

Epoch: 5| Step: 11
Training loss: 5.291604995727539
Validation loss: 5.199987709522247

Epoch: 2| Step: 0
Training loss: 5.16365909576416
Validation loss: 5.1602442264556885

Epoch: 5| Step: 1
Training loss: 4.461610317230225
Validation loss: 5.12188857793808

Epoch: 5| Step: 2
Training loss: 5.134368419647217
Validation loss: 5.081078926722209

Epoch: 5| Step: 3
Training loss: 5.242319583892822
Validation loss: 5.035302400588989

Epoch: 5| Step: 4
Training loss: 5.765159606933594
Validation loss: 4.990472853183746

Epoch: 5| Step: 5
Training loss: 4.0230607986450195
Validation loss: 4.946534117062886

Epoch: 5| Step: 6
Training loss: 5.370370388031006
Validation loss: 4.897256374359131

Epoch: 5| Step: 7
Training loss: 4.684169769287109
Validation loss: 4.850182741880417

Epoch: 5| Step: 8
Training loss: 6.292416572570801
Validation loss: 4.797745327154796

Epoch: 5| Step: 9
Training loss: 4.117605209350586
Validation loss: 4.745119829972585

Epoch: 5| Step: 10
Training loss: 5.169903755187988
Validation loss: 4.690148631731669

Epoch: 5| Step: 11
Training loss: 2.2330117225646973
Validation loss: 4.632418135801951

Epoch: 3| Step: 0
Training loss: 5.028378009796143
Validation loss: 4.574297447999318

Epoch: 5| Step: 1
Training loss: 5.0410661697387695
Validation loss: 4.509518941243489

Epoch: 5| Step: 2
Training loss: 4.494603157043457
Validation loss: 4.442418396472931

Epoch: 5| Step: 3
Training loss: 3.525353193283081
Validation loss: 4.369446227947871

Epoch: 5| Step: 4
Training loss: 4.661088943481445
Validation loss: 4.301382561524709

Epoch: 5| Step: 5
Training loss: 4.255107402801514
Validation loss: 4.227323929468791

Epoch: 5| Step: 6
Training loss: 4.690178871154785
Validation loss: 4.1484158635139465

Epoch: 5| Step: 7
Training loss: 4.5932416915893555
Validation loss: 4.071313967307408

Epoch: 5| Step: 8
Training loss: 2.808793306350708
Validation loss: 3.992869645357132

Epoch: 5| Step: 9
Training loss: 3.954012632369995
Validation loss: 3.9236562649408975

Epoch: 5| Step: 10
Training loss: 4.218303203582764
Validation loss: 3.8344048062960305

Epoch: 5| Step: 11
Training loss: 4.212254047393799
Validation loss: 3.752531329790751

Epoch: 4| Step: 0
Training loss: 3.463352680206299
Validation loss: 3.675380845864614

Epoch: 5| Step: 1
Training loss: 3.876234769821167
Validation loss: 3.587610423564911

Epoch: 5| Step: 2
Training loss: 4.111515045166016
Validation loss: 3.5042433043320975

Epoch: 5| Step: 3
Training loss: 2.924227237701416
Validation loss: 3.421938975652059

Epoch: 5| Step: 4
Training loss: 3.3407504558563232
Validation loss: 3.3321499129136405

Epoch: 5| Step: 5
Training loss: 3.3247807025909424
Validation loss: 3.252151777346929

Epoch: 5| Step: 6
Training loss: 4.06509256362915
Validation loss: 3.156416883071264

Epoch: 5| Step: 7
Training loss: 2.7456698417663574
Validation loss: 3.0702221393585205

Epoch: 5| Step: 8
Training loss: 2.949317455291748
Validation loss: 2.9746081034342446

Epoch: 5| Step: 9
Training loss: 2.764660358428955
Validation loss: 2.8889093001683555

Epoch: 5| Step: 10
Training loss: 2.8104445934295654
Validation loss: 2.8044917583465576

Epoch: 5| Step: 11
Training loss: 1.5210621356964111
Validation loss: 2.713677624861399

Epoch: 5| Step: 0
Training loss: 3.3542075157165527
Validation loss: 2.6400634348392487

Epoch: 5| Step: 1
Training loss: 2.1886038780212402
Validation loss: 2.564757784207662

Epoch: 5| Step: 2
Training loss: 2.583665132522583
Validation loss: 2.5014106035232544

Epoch: 5| Step: 3
Training loss: 2.3233509063720703
Validation loss: 2.4370728631814322

Epoch: 5| Step: 4
Training loss: 2.7489843368530273
Validation loss: 2.373379478851954

Epoch: 5| Step: 5
Training loss: 2.1450746059417725
Validation loss: 2.3280120392640433

Epoch: 5| Step: 6
Training loss: 2.2827696800231934
Validation loss: 2.2987049917380014

Epoch: 5| Step: 7
Training loss: 2.360973358154297
Validation loss: 2.260895013809204

Epoch: 5| Step: 8
Training loss: 2.0146985054016113
Validation loss: 2.2353515028953552

Epoch: 5| Step: 9
Training loss: 2.61958909034729
Validation loss: 2.2111609975496926

Epoch: 5| Step: 10
Training loss: 1.884006142616272
Validation loss: 2.2193613201379776

Epoch: 5| Step: 11
Training loss: 1.3303122520446777
Validation loss: 2.232956826686859

Epoch: 6| Step: 0
Training loss: 2.4808506965637207
Validation loss: 2.2196757197380066

Epoch: 5| Step: 1
Training loss: 2.2407174110412598
Validation loss: 2.187035376826922

Epoch: 5| Step: 2
Training loss: 2.213374376296997
Validation loss: 2.2122168640295663

Epoch: 5| Step: 3
Training loss: 2.4483604431152344
Validation loss: 2.2281697342793145

Epoch: 5| Step: 4
Training loss: 2.3029983043670654
Validation loss: 2.211293707291285

Epoch: 5| Step: 5
Training loss: 2.157733917236328
Validation loss: 2.204544877012571

Epoch: 5| Step: 6
Training loss: 2.112682580947876
Validation loss: 2.1748005747795105

Epoch: 5| Step: 7
Training loss: 2.3193562030792236
Validation loss: 2.211345463991165

Epoch: 5| Step: 8
Training loss: 2.0686936378479004
Validation loss: 2.203106790781021

Epoch: 5| Step: 9
Training loss: 2.075064182281494
Validation loss: 2.206550752123197

Epoch: 5| Step: 10
Training loss: 2.2943058013916016
Validation loss: 2.216570094227791

Epoch: 5| Step: 11
Training loss: 3.3612594604492188
Validation loss: 2.2250488698482513

Epoch: 7| Step: 0
Training loss: 2.1753971576690674
Validation loss: 2.2149025400479636

Epoch: 5| Step: 1
Training loss: 2.271540403366089
Validation loss: 2.233288745085398

Epoch: 5| Step: 2
Training loss: 1.937097191810608
Validation loss: 2.2369747112194696

Epoch: 5| Step: 3
Training loss: 1.973162055015564
Validation loss: 2.255502159396807

Epoch: 5| Step: 4
Training loss: 3.035367965698242
Validation loss: 2.24699533979098

Epoch: 5| Step: 5
Training loss: 1.8502877950668335
Validation loss: 2.258734871943792

Epoch: 5| Step: 6
Training loss: 2.2665646076202393
Validation loss: 2.247758830587069

Epoch: 5| Step: 7
Training loss: 1.578775405883789
Validation loss: 2.2579100330670676

Epoch: 5| Step: 8
Training loss: 2.7741122245788574
Validation loss: 2.265417834122976

Epoch: 5| Step: 9
Training loss: 2.4892632961273193
Validation loss: 2.2676255106925964

Epoch: 5| Step: 10
Training loss: 1.8532108068466187
Validation loss: 2.2533280501763024

Epoch: 5| Step: 11
Training loss: 2.867382526397705
Validation loss: 2.263360232114792

Epoch: 8| Step: 0
Training loss: 2.504721164703369
Validation loss: 2.2447218100229898

Epoch: 5| Step: 1
Training loss: 1.8600819110870361
Validation loss: 2.239497577150663

Epoch: 5| Step: 2
Training loss: 1.9519942998886108
Validation loss: 2.226555253068606

Epoch: 5| Step: 3
Training loss: 2.6114370822906494
Validation loss: 2.20993738869826

Epoch: 5| Step: 4
Training loss: 2.325810432434082
Validation loss: 2.2063346405824027

Epoch: 5| Step: 5
Training loss: 2.2880911827087402
Validation loss: 2.1967023809750876

Epoch: 5| Step: 6
Training loss: 1.5180538892745972
Validation loss: 2.192360669374466

Epoch: 5| Step: 7
Training loss: 2.2962698936462402
Validation loss: 2.1713121930758157

Epoch: 5| Step: 8
Training loss: 1.9548470973968506
Validation loss: 2.168460632363955

Epoch: 5| Step: 9
Training loss: 2.2836809158325195
Validation loss: 2.1725326478481293

Epoch: 5| Step: 10
Training loss: 2.499783754348755
Validation loss: 2.1578799287478128

Epoch: 5| Step: 11
Training loss: 1.7877085208892822
Validation loss: 2.15439107020696

Epoch: 9| Step: 0
Training loss: 2.552893877029419
Validation loss: 2.147319972515106

Epoch: 5| Step: 1
Training loss: 1.5697147846221924
Validation loss: 2.1498780151208243

Epoch: 5| Step: 2
Training loss: 2.196223258972168
Validation loss: 2.1561095317204795

Epoch: 5| Step: 3
Training loss: 2.0963845252990723
Validation loss: 2.1467964400847754

Epoch: 5| Step: 4
Training loss: 2.1028354167938232
Validation loss: 2.126637245217959

Epoch: 5| Step: 5
Training loss: 1.5819315910339355
Validation loss: 2.1342843423287072

Epoch: 5| Step: 6
Training loss: 2.7490482330322266
Validation loss: 2.1330419878164926

Epoch: 5| Step: 7
Training loss: 2.656693458557129
Validation loss: 2.1442169845104218

Epoch: 5| Step: 8
Training loss: 1.770147681236267
Validation loss: 2.144034763177236

Epoch: 5| Step: 9
Training loss: 2.4702181816101074
Validation loss: 2.1267783294121423

Epoch: 5| Step: 10
Training loss: 1.9126399755477905
Validation loss: 2.124578903118769

Epoch: 5| Step: 11
Training loss: 3.644057273864746
Validation loss: 2.131415863831838

Epoch: 10| Step: 0
Training loss: 2.287189483642578
Validation loss: 2.1287730832894645

Epoch: 5| Step: 1
Training loss: 1.83199143409729
Validation loss: 2.120187431573868

Epoch: 5| Step: 2
Training loss: 1.887027382850647
Validation loss: 2.151145567496618

Epoch: 5| Step: 3
Training loss: 1.3640714883804321
Validation loss: 2.150606984893481

Epoch: 5| Step: 4
Training loss: 1.934520959854126
Validation loss: 2.145596216122309

Epoch: 5| Step: 5
Training loss: 2.3502583503723145
Validation loss: 2.1519450743993125

Epoch: 5| Step: 6
Training loss: 2.0275721549987793
Validation loss: 2.137579465905825

Epoch: 5| Step: 7
Training loss: 2.56558895111084
Validation loss: 2.1634615063667297

Epoch: 5| Step: 8
Training loss: 2.3625974655151367
Validation loss: 2.151179959376653

Epoch: 5| Step: 9
Training loss: 2.433666944503784
Validation loss: 2.1579284071922302

Epoch: 5| Step: 10
Training loss: 2.4850010871887207
Validation loss: 2.1574745923280716

Epoch: 5| Step: 11
Training loss: 2.6081221103668213
Validation loss: 2.1442909141381583

Epoch: 11| Step: 0
Training loss: 2.217172384262085
Validation loss: 2.1501092116038003

Epoch: 5| Step: 1
Training loss: 2.005593776702881
Validation loss: 2.1567365477482476

Epoch: 5| Step: 2
Training loss: 2.0151424407958984
Validation loss: 2.142716407775879

Epoch: 5| Step: 3
Training loss: 2.7692160606384277
Validation loss: 2.1398269732793174

Epoch: 5| Step: 4
Training loss: 2.6204428672790527
Validation loss: 2.1394318342208862

Epoch: 5| Step: 5
Training loss: 1.5442160367965698
Validation loss: 2.124124417702357

Epoch: 5| Step: 6
Training loss: 2.069725513458252
Validation loss: 2.1108365257581077

Epoch: 5| Step: 7
Training loss: 2.253190517425537
Validation loss: 2.1127417385578156

Epoch: 5| Step: 8
Training loss: 2.0230441093444824
Validation loss: 2.1173663387695947

Epoch: 5| Step: 9
Training loss: 1.692525863647461
Validation loss: 2.1085470567146936

Epoch: 5| Step: 10
Training loss: 2.2900376319885254
Validation loss: 2.0980971356232962

Epoch: 5| Step: 11
Training loss: 1.030082106590271
Validation loss: 2.1047458400328956

Epoch: 12| Step: 0
Training loss: 2.260639190673828
Validation loss: 2.088916783531507

Epoch: 5| Step: 1
Training loss: 2.059636354446411
Validation loss: 2.0856301883856454

Epoch: 5| Step: 2
Training loss: 1.9670093059539795
Validation loss: 2.104191521803538

Epoch: 5| Step: 3
Training loss: 2.1488354206085205
Validation loss: 2.0829139898220697

Epoch: 5| Step: 4
Training loss: 2.045616388320923
Validation loss: 2.092654804388682

Epoch: 5| Step: 5
Training loss: 2.26702880859375
Validation loss: 2.080934305985769

Epoch: 5| Step: 6
Training loss: 2.2317237854003906
Validation loss: 2.100690613190333

Epoch: 5| Step: 7
Training loss: 2.1615548133850098
Validation loss: 2.0976855754852295

Epoch: 5| Step: 8
Training loss: 1.3651515245437622
Validation loss: 2.082901433110237

Epoch: 5| Step: 9
Training loss: 2.4540460109710693
Validation loss: 2.094137743115425

Epoch: 5| Step: 10
Training loss: 2.2787551879882812
Validation loss: 2.087303747733434

Epoch: 5| Step: 11
Training loss: 1.6652028560638428
Validation loss: 2.081248934070269

Epoch: 13| Step: 0
Training loss: 1.9218164682388306
Validation loss: 2.0738949924707413

Epoch: 5| Step: 1
Training loss: 2.1817736625671387
Validation loss: 2.065804342428843

Epoch: 5| Step: 2
Training loss: 2.024567127227783
Validation loss: 2.0774256785710654

Epoch: 5| Step: 3
Training loss: 2.412785291671753
Validation loss: 2.085040956735611

Epoch: 5| Step: 4
Training loss: 2.769861936569214
Validation loss: 2.101097588737806

Epoch: 5| Step: 5
Training loss: 1.4964032173156738
Validation loss: 2.0949493100245795

Epoch: 5| Step: 6
Training loss: 2.095757246017456
Validation loss: 2.0752397179603577

Epoch: 5| Step: 7
Training loss: 2.3993098735809326
Validation loss: 2.101204181710879

Epoch: 5| Step: 8
Training loss: 2.117949962615967
Validation loss: 2.0854205638170242

Epoch: 5| Step: 9
Training loss: 2.1896121501922607
Validation loss: 2.0763568679491677

Epoch: 5| Step: 10
Training loss: 1.640440583229065
Validation loss: 2.080484410127004

Epoch: 5| Step: 11
Training loss: 1.1766849756240845
Validation loss: 2.060633381207784

Epoch: 14| Step: 0
Training loss: 2.2915215492248535
Validation loss: 2.073627163966497

Epoch: 5| Step: 1
Training loss: 2.4356529712677
Validation loss: 2.072618549068769

Epoch: 5| Step: 2
Training loss: 2.362835645675659
Validation loss: 2.079017514983813

Epoch: 5| Step: 3
Training loss: 2.6421573162078857
Validation loss: 2.064312373598417

Epoch: 5| Step: 4
Training loss: 2.2130231857299805
Validation loss: 2.071368674437205

Epoch: 5| Step: 5
Training loss: 2.2503914833068848
Validation loss: 2.0794062862793603

Epoch: 5| Step: 6
Training loss: 1.9993022680282593
Validation loss: 2.082003101706505

Epoch: 5| Step: 7
Training loss: 1.6278423070907593
Validation loss: 2.096716985106468

Epoch: 5| Step: 8
Training loss: 1.7351605892181396
Validation loss: 2.071804463863373

Epoch: 5| Step: 9
Training loss: 1.5253713130950928
Validation loss: 2.0555214136838913

Epoch: 5| Step: 10
Training loss: 1.8538011312484741
Validation loss: 2.0673752228418985

Epoch: 5| Step: 11
Training loss: 1.6347172260284424
Validation loss: 2.0689853876829147

Epoch: 15| Step: 0
Training loss: 2.02931547164917
Validation loss: 2.057143360376358

Epoch: 5| Step: 1
Training loss: 2.0751843452453613
Validation loss: 2.0572542448838553

Epoch: 5| Step: 2
Training loss: 2.1211941242218018
Validation loss: 2.069925973812739

Epoch: 5| Step: 3
Training loss: 2.5480990409851074
Validation loss: 2.063006122907003

Epoch: 5| Step: 4
Training loss: 1.8539485931396484
Validation loss: 2.049694314599037

Epoch: 5| Step: 5
Training loss: 2.167945146560669
Validation loss: 2.0537005265553794

Epoch: 5| Step: 6
Training loss: 1.8431133031845093
Validation loss: 2.063447341322899

Epoch: 5| Step: 7
Training loss: 1.51388418674469
Validation loss: 2.0636586993932724

Epoch: 5| Step: 8
Training loss: 2.1543335914611816
Validation loss: 2.040616035461426

Epoch: 5| Step: 9
Training loss: 2.280393362045288
Validation loss: 2.0506123999754586

Epoch: 5| Step: 10
Training loss: 2.2341058254241943
Validation loss: 2.0386383533477783

Epoch: 5| Step: 11
Training loss: 2.361024856567383
Validation loss: 2.047085995475451

Epoch: 16| Step: 0
Training loss: 2.1627511978149414
Validation loss: 2.0471296906471252

Epoch: 5| Step: 1
Training loss: 1.7737935781478882
Validation loss: 2.046493425965309

Epoch: 5| Step: 2
Training loss: 1.4804730415344238
Validation loss: 2.069295143087705

Epoch: 5| Step: 3
Training loss: 1.3982616662979126
Validation loss: 2.0546712229649224

Epoch: 5| Step: 4
Training loss: 2.554856538772583
Validation loss: 2.060521826148033

Epoch: 5| Step: 5
Training loss: 2.499520778656006
Validation loss: 2.0663577020168304

Epoch: 5| Step: 6
Training loss: 2.3266258239746094
Validation loss: 2.0628154228130975

Epoch: 5| Step: 7
Training loss: 1.937294363975525
Validation loss: 2.068687374393145

Epoch: 5| Step: 8
Training loss: 2.5083470344543457
Validation loss: 2.0705488125483194

Epoch: 5| Step: 9
Training loss: 2.4962048530578613
Validation loss: 2.0711314578851066

Epoch: 5| Step: 10
Training loss: 1.717420220375061
Validation loss: 2.055811896920204

Epoch: 5| Step: 11
Training loss: 0.8267986178398132
Validation loss: 2.0495879699786506

Epoch: 17| Step: 0
Training loss: 1.9401490688323975
Validation loss: 2.050217176477114

Epoch: 5| Step: 1
Training loss: 2.3359692096710205
Validation loss: 2.0463992059230804

Epoch: 5| Step: 2
Training loss: 2.001397132873535
Validation loss: 2.0599326143662133

Epoch: 5| Step: 3
Training loss: 1.967161774635315
Validation loss: 2.0590322564045587

Epoch: 5| Step: 4
Training loss: 2.0971474647521973
Validation loss: 2.078249533971151

Epoch: 5| Step: 5
Training loss: 2.07533597946167
Validation loss: 2.0821161617835364

Epoch: 5| Step: 6
Training loss: 2.0219528675079346
Validation loss: 2.0870332370201745

Epoch: 5| Step: 7
Training loss: 2.3578476905822754
Validation loss: 2.074575732151667

Epoch: 5| Step: 8
Training loss: 2.084965705871582
Validation loss: 2.074872533480326

Epoch: 5| Step: 9
Training loss: 1.841430902481079
Validation loss: 2.063634157180786

Epoch: 5| Step: 10
Training loss: 2.3877575397491455
Validation loss: 2.0580157538255057

Epoch: 5| Step: 11
Training loss: 0.8750520944595337
Validation loss: 2.038799618681272

Epoch: 18| Step: 0
Training loss: 1.410137414932251
Validation loss: 2.0408447633186975

Epoch: 5| Step: 1
Training loss: 2.4170801639556885
Validation loss: 2.0329218357801437

Epoch: 5| Step: 2
Training loss: 2.201831102371216
Validation loss: 2.0440134555101395

Epoch: 5| Step: 3
Training loss: 1.7551324367523193
Validation loss: 2.028564289212227

Epoch: 5| Step: 4
Training loss: 1.931372046470642
Validation loss: 2.0422136833270392

Epoch: 5| Step: 5
Training loss: 2.011151075363159
Validation loss: 2.0355805307626724

Epoch: 5| Step: 6
Training loss: 1.7274253368377686
Validation loss: 2.053390234708786

Epoch: 5| Step: 7
Training loss: 2.0660881996154785
Validation loss: 2.034478545188904

Epoch: 5| Step: 8
Training loss: 2.1910667419433594
Validation loss: 2.022230635086695

Epoch: 5| Step: 9
Training loss: 2.5160703659057617
Validation loss: 2.0166108707586923

Epoch: 5| Step: 10
Training loss: 2.243788242340088
Validation loss: 2.0244888762633004

Epoch: 5| Step: 11
Training loss: 2.623347282409668
Validation loss: 2.0179812659819922

Epoch: 19| Step: 0
Training loss: 1.8634250164031982
Validation loss: 2.028370574116707

Epoch: 5| Step: 1
Training loss: 1.679372787475586
Validation loss: 2.0503164678812027

Epoch: 5| Step: 2
Training loss: 2.130004644393921
Validation loss: 2.0231100420157113

Epoch: 5| Step: 3
Training loss: 1.9897301197052002
Validation loss: 2.0126894315083823

Epoch: 5| Step: 4
Training loss: 1.522696852684021
Validation loss: 2.0329218606154122

Epoch: 5| Step: 5
Training loss: 2.1046886444091797
Validation loss: 2.026179621616999

Epoch: 5| Step: 6
Training loss: 2.3034920692443848
Validation loss: 2.0243346095085144

Epoch: 5| Step: 7
Training loss: 2.077939510345459
Validation loss: 2.0298300435145697

Epoch: 5| Step: 8
Training loss: 2.8838818073272705
Validation loss: 2.019825498263041

Epoch: 5| Step: 9
Training loss: 1.7217895984649658
Validation loss: 2.0319302330414453

Epoch: 5| Step: 10
Training loss: 2.0732181072235107
Validation loss: 2.036115989089012

Epoch: 5| Step: 11
Training loss: 2.2340333461761475
Validation loss: 2.019289751847585

Epoch: 20| Step: 0
Training loss: 2.203566312789917
Validation loss: 2.0659332076708474

Epoch: 5| Step: 1
Training loss: 1.9763838052749634
Validation loss: 2.022551750143369

Epoch: 5| Step: 2
Training loss: 2.263155937194824
Validation loss: 2.0318027635415397

Epoch: 5| Step: 3
Training loss: 2.228949546813965
Validation loss: 2.021578684449196

Epoch: 5| Step: 4
Training loss: 2.567491054534912
Validation loss: 2.0246940652529397

Epoch: 5| Step: 5
Training loss: 1.4765082597732544
Validation loss: 2.0217985212802887

Epoch: 5| Step: 6
Training loss: 2.0750892162323
Validation loss: 2.025946855545044

Epoch: 5| Step: 7
Training loss: 2.1774449348449707
Validation loss: 2.0207574317852655

Epoch: 5| Step: 8
Training loss: 2.158412218093872
Validation loss: 2.0358195851246514

Epoch: 5| Step: 9
Training loss: 1.6334459781646729
Validation loss: 2.0215005030234656

Epoch: 5| Step: 10
Training loss: 1.5338003635406494
Validation loss: 2.0308205833037696

Epoch: 5| Step: 11
Training loss: 1.7269229888916016
Validation loss: 2.029560203353564

Epoch: 21| Step: 0
Training loss: 1.6766014099121094
Validation loss: 2.0202201704184213

Epoch: 5| Step: 1
Training loss: 1.9982240200042725
Validation loss: 2.0200520207484565

Epoch: 5| Step: 2
Training loss: 1.1988513469696045
Validation loss: 2.0282110621531806

Epoch: 5| Step: 3
Training loss: 1.2201145887374878
Validation loss: 2.0137248734633126

Epoch: 5| Step: 4
Training loss: 2.073951005935669
Validation loss: 2.0228778272867203

Epoch: 5| Step: 5
Training loss: 2.0784690380096436
Validation loss: 2.0358968476454415

Epoch: 5| Step: 6
Training loss: 2.3266403675079346
Validation loss: 2.0269268304109573

Epoch: 5| Step: 7
Training loss: 2.0089666843414307
Validation loss: 2.0104349156220755

Epoch: 5| Step: 8
Training loss: 3.139072895050049
Validation loss: 2.028788775205612

Epoch: 5| Step: 9
Training loss: 2.2626686096191406
Validation loss: 2.012147471308708

Epoch: 5| Step: 10
Training loss: 2.2961506843566895
Validation loss: 2.0233123898506165

Epoch: 5| Step: 11
Training loss: 1.6695116758346558
Validation loss: 2.014267678062121

Epoch: 22| Step: 0
Training loss: 2.0130953788757324
Validation loss: 2.024802088737488

Epoch: 5| Step: 1
Training loss: 1.9431579113006592
Validation loss: 2.0133052319288254

Epoch: 5| Step: 2
Training loss: 2.0598955154418945
Validation loss: 2.0474050442377725

Epoch: 5| Step: 3
Training loss: 2.280038833618164
Validation loss: 2.020009527603785

Epoch: 5| Step: 4
Training loss: 2.0714950561523438
Validation loss: 2.035332883397738

Epoch: 5| Step: 5
Training loss: 1.9061863422393799
Validation loss: 2.0204352835814157

Epoch: 5| Step: 6
Training loss: 1.7305488586425781
Validation loss: 2.034080922603607

Epoch: 5| Step: 7
Training loss: 1.8918311595916748
Validation loss: 2.0244480272134147

Epoch: 5| Step: 8
Training loss: 2.2840476036071777
Validation loss: 2.010444318254789

Epoch: 5| Step: 9
Training loss: 2.4261410236358643
Validation loss: 2.0337206423282623

Epoch: 5| Step: 10
Training loss: 1.4587252140045166
Validation loss: 2.0015342930952706

Epoch: 5| Step: 11
Training loss: 1.3931243419647217
Validation loss: 2.0143886357545853

Epoch: 23| Step: 0
Training loss: 2.6361687183380127
Validation loss: 2.0051098267237344

Epoch: 5| Step: 1
Training loss: 1.5172088146209717
Validation loss: 2.011754939953486

Epoch: 5| Step: 2
Training loss: 1.841102957725525
Validation loss: 2.0135743816693625

Epoch: 5| Step: 3
Training loss: 2.1548755168914795
Validation loss: 2.005356883009275

Epoch: 5| Step: 4
Training loss: 1.626262903213501
Validation loss: 2.0200292517741523

Epoch: 5| Step: 5
Training loss: 2.0204997062683105
Validation loss: 2.011945739388466

Epoch: 5| Step: 6
Training loss: 2.5606637001037598
Validation loss: 2.01164048910141

Epoch: 5| Step: 7
Training loss: 2.14430570602417
Validation loss: 2.0242476761341095

Epoch: 5| Step: 8
Training loss: 2.1792001724243164
Validation loss: 2.0172984302043915

Epoch: 5| Step: 9
Training loss: 1.3869823217391968
Validation loss: 2.023376723130544

Epoch: 5| Step: 10
Training loss: 2.2848610877990723
Validation loss: 1.9951939086119335

Epoch: 5| Step: 11
Training loss: 0.5126199722290039
Validation loss: 2.018544668952624

Epoch: 24| Step: 0
Training loss: 1.9139950275421143
Validation loss: 2.0207981715599694

Epoch: 5| Step: 1
Training loss: 1.7332839965820312
Validation loss: 2.0024375965197883

Epoch: 5| Step: 2
Training loss: 1.9705946445465088
Validation loss: 2.000800127784411

Epoch: 5| Step: 3
Training loss: 2.218906879425049
Validation loss: 2.018287310997645

Epoch: 5| Step: 4
Training loss: 2.074566125869751
Validation loss: 2.0148296654224396

Epoch: 5| Step: 5
Training loss: 2.367300510406494
Validation loss: 1.9980493187904358

Epoch: 5| Step: 6
Training loss: 1.673293113708496
Validation loss: 2.0063403149445853

Epoch: 5| Step: 7
Training loss: 1.868109941482544
Validation loss: 2.0153666784365973

Epoch: 5| Step: 8
Training loss: 2.1254844665527344
Validation loss: 2.014551063378652

Epoch: 5| Step: 9
Training loss: 2.268627166748047
Validation loss: 1.995320439338684

Epoch: 5| Step: 10
Training loss: 1.7748119831085205
Validation loss: 1.9983686010042827

Epoch: 5| Step: 11
Training loss: 1.6917234659194946
Validation loss: 2.012575015425682

Epoch: 25| Step: 0
Training loss: 2.021440029144287
Validation loss: 2.025577187538147

Epoch: 5| Step: 1
Training loss: 2.0771644115448
Validation loss: 2.021919017036756

Epoch: 5| Step: 2
Training loss: 2.3189680576324463
Validation loss: 2.0290975322326026

Epoch: 5| Step: 3
Training loss: 1.9658836126327515
Validation loss: 2.0326263904571533

Epoch: 5| Step: 4
Training loss: 2.1262247562408447
Validation loss: 2.051632046699524

Epoch: 5| Step: 5
Training loss: 1.909685492515564
Validation loss: 2.017265111207962

Epoch: 5| Step: 6
Training loss: 1.67690908908844
Validation loss: 2.029428333044052

Epoch: 5| Step: 7
Training loss: 1.6228313446044922
Validation loss: 2.0318719297647476

Epoch: 5| Step: 8
Training loss: 2.4621100425720215
Validation loss: 2.002758880456289

Epoch: 5| Step: 9
Training loss: 1.8021819591522217
Validation loss: 2.002671221892039

Epoch: 5| Step: 10
Training loss: 2.006652593612671
Validation loss: 1.9898096819718678

Epoch: 5| Step: 11
Training loss: 2.0592548847198486
Validation loss: 2.015759845574697

Epoch: 26| Step: 0
Training loss: 2.231386661529541
Validation loss: 2.0239784320195517

Epoch: 5| Step: 1
Training loss: 2.0226168632507324
Validation loss: 2.0189609676599503

Epoch: 5| Step: 2
Training loss: 1.5502042770385742
Validation loss: 2.001108547051748

Epoch: 5| Step: 3
Training loss: 1.9250094890594482
Validation loss: 2.0280011892318726

Epoch: 5| Step: 4
Training loss: 1.8579765558242798
Validation loss: 2.014024476210276

Epoch: 5| Step: 5
Training loss: 1.8998816013336182
Validation loss: 2.020732874671618

Epoch: 5| Step: 6
Training loss: 2.1174561977386475
Validation loss: 2.0409933278958

Epoch: 5| Step: 7
Training loss: 2.808427095413208
Validation loss: 2.0375923961400986

Epoch: 5| Step: 8
Training loss: 2.019697666168213
Validation loss: 2.054226299126943

Epoch: 5| Step: 9
Training loss: 1.7193514108657837
Validation loss: 2.0033844212690988

Epoch: 5| Step: 10
Training loss: 1.7690986394882202
Validation loss: 2.0102911641200385

Epoch: 5| Step: 11
Training loss: 1.7963587045669556
Validation loss: 2.002252052227656

Epoch: 27| Step: 0
Training loss: 1.8483864068984985
Validation loss: 2.0006403774023056

Epoch: 5| Step: 1
Training loss: 1.7289193868637085
Validation loss: 2.0048283686240516

Epoch: 5| Step: 2
Training loss: 1.9637285470962524
Validation loss: 2.015739435950915

Epoch: 5| Step: 3
Training loss: 2.0351181030273438
Validation loss: 2.010848432779312

Epoch: 5| Step: 4
Training loss: 1.600162148475647
Validation loss: 1.9656232794125874

Epoch: 5| Step: 5
Training loss: 1.7573349475860596
Validation loss: 1.9930995454390843

Epoch: 5| Step: 6
Training loss: 2.1592071056365967
Validation loss: 2.0194463034470878

Epoch: 5| Step: 7
Training loss: 2.082834243774414
Validation loss: 2.006752237677574

Epoch: 5| Step: 8
Training loss: 2.6858458518981934
Validation loss: 2.001712659994761

Epoch: 5| Step: 9
Training loss: 1.941851258277893
Validation loss: 2.0089399019877114

Epoch: 5| Step: 10
Training loss: 2.2235488891601562
Validation loss: 2.012873575091362

Epoch: 5| Step: 11
Training loss: 1.2852967977523804
Validation loss: 2.017446830868721

Epoch: 28| Step: 0
Training loss: 2.0943336486816406
Validation loss: 2.00686584909757

Epoch: 5| Step: 1
Training loss: 1.9089065790176392
Validation loss: 2.017607177297274

Epoch: 5| Step: 2
Training loss: 1.7024505138397217
Validation loss: 1.9926395664612453

Epoch: 5| Step: 3
Training loss: 2.3738110065460205
Validation loss: 1.9948220054308574

Epoch: 5| Step: 4
Training loss: 1.8954484462738037
Validation loss: 2.008970096707344

Epoch: 5| Step: 5
Training loss: 1.6493136882781982
Validation loss: 1.9977522045373917

Epoch: 5| Step: 6
Training loss: 1.7957757711410522
Validation loss: 2.010458086927732

Epoch: 5| Step: 7
Training loss: 1.7941064834594727
Validation loss: 1.9932006945212681

Epoch: 5| Step: 8
Training loss: 2.019561767578125
Validation loss: 2.0156643191973367

Epoch: 5| Step: 9
Training loss: 1.9074580669403076
Validation loss: 2.003415768345197

Epoch: 5| Step: 10
Training loss: 2.7318520545959473
Validation loss: 2.0031009316444397

Epoch: 5| Step: 11
Training loss: 2.090599298477173
Validation loss: 2.0019724120696387

Epoch: 29| Step: 0
Training loss: 2.190516948699951
Validation loss: 2.0371531347433725

Epoch: 5| Step: 1
Training loss: 1.9389705657958984
Validation loss: 2.0192791869242988

Epoch: 5| Step: 2
Training loss: 2.5249106884002686
Validation loss: 2.029244383176168

Epoch: 5| Step: 3
Training loss: 2.3665881156921387
Validation loss: 2.001644551753998

Epoch: 5| Step: 4
Training loss: 1.4159438610076904
Validation loss: 1.9890179087718327

Epoch: 5| Step: 5
Training loss: 1.7987953424453735
Validation loss: 2.010452777147293

Epoch: 5| Step: 6
Training loss: 1.3823316097259521
Validation loss: 1.9944833169380825

Epoch: 5| Step: 7
Training loss: 2.152129888534546
Validation loss: 2.026943484942118

Epoch: 5| Step: 8
Training loss: 2.1186554431915283
Validation loss: 2.0143276900053024

Epoch: 5| Step: 9
Training loss: 1.5155785083770752
Validation loss: 2.0277210672696433

Epoch: 5| Step: 10
Training loss: 2.1727473735809326
Validation loss: 2.0138090203205743

Epoch: 5| Step: 11
Training loss: 3.1164629459381104
Validation loss: 2.004522368311882

Epoch: 30| Step: 0
Training loss: 2.027611494064331
Validation loss: 1.9959545284509659

Epoch: 5| Step: 1
Training loss: 2.8106541633605957
Validation loss: 1.989586700995763

Epoch: 5| Step: 2
Training loss: 1.978868842124939
Validation loss: 1.983909289042155

Epoch: 5| Step: 3
Training loss: 1.9425891637802124
Validation loss: 1.9846451083819072

Epoch: 5| Step: 4
Training loss: 1.6843910217285156
Validation loss: 1.9904020180304844

Epoch: 5| Step: 5
Training loss: 1.8422828912734985
Validation loss: 1.9874678055445354

Epoch: 5| Step: 6
Training loss: 2.2785961627960205
Validation loss: 2.0043224344650903

Epoch: 5| Step: 7
Training loss: 2.2332541942596436
Validation loss: 1.9689626296361287

Epoch: 5| Step: 8
Training loss: 1.7706663608551025
Validation loss: 1.9913298736015956

Epoch: 5| Step: 9
Training loss: 1.4334660768508911
Validation loss: 2.002219572663307

Epoch: 5| Step: 10
Training loss: 2.00026798248291
Validation loss: 1.9925370464722316

Epoch: 5| Step: 11
Training loss: 1.1473065614700317
Validation loss: 2.011880338191986

Epoch: 31| Step: 0
Training loss: 1.202354073524475
Validation loss: 2.019714499513308

Epoch: 5| Step: 1
Training loss: 2.4849979877471924
Validation loss: 2.0138132721185684

Epoch: 5| Step: 2
Training loss: 1.7624056339263916
Validation loss: 2.053982670108477

Epoch: 5| Step: 3
Training loss: 2.0869252681732178
Validation loss: 2.0459586332241693

Epoch: 5| Step: 4
Training loss: 2.169525623321533
Validation loss: 2.076416770617167

Epoch: 5| Step: 5
Training loss: 1.3991689682006836
Validation loss: 2.056520104408264

Epoch: 5| Step: 6
Training loss: 2.2519335746765137
Validation loss: 2.0441273003816605

Epoch: 5| Step: 7
Training loss: 2.55537748336792
Validation loss: 2.037540222207705

Epoch: 5| Step: 8
Training loss: 1.945600152015686
Validation loss: 2.0150584975878396

Epoch: 5| Step: 9
Training loss: 2.192366361618042
Validation loss: 1.995453695456187

Epoch: 5| Step: 10
Training loss: 2.0904765129089355
Validation loss: 1.974673792719841

Epoch: 5| Step: 11
Training loss: 1.6820534467697144
Validation loss: 2.0069823066393533

Epoch: 32| Step: 0
Training loss: 2.091395854949951
Validation loss: 1.9964299152294795

Epoch: 5| Step: 1
Training loss: 2.1074166297912598
Validation loss: 2.0028616885344186

Epoch: 5| Step: 2
Training loss: 1.9400972127914429
Validation loss: 2.0376149863004684

Epoch: 5| Step: 3
Training loss: 2.076798915863037
Validation loss: 2.0421948979298272

Epoch: 5| Step: 4
Training loss: 2.1759238243103027
Validation loss: 2.0453647524118423

Epoch: 5| Step: 5
Training loss: 2.1862847805023193
Validation loss: 2.032840152581533

Epoch: 5| Step: 6
Training loss: 1.6937198638916016
Validation loss: 2.020120620727539

Epoch: 5| Step: 7
Training loss: 2.204528331756592
Validation loss: 2.0132800738016763

Epoch: 5| Step: 8
Training loss: 2.1028056144714355
Validation loss: 2.0084642320871353

Epoch: 5| Step: 9
Training loss: 1.9428592920303345
Validation loss: 2.0106023053328195

Epoch: 5| Step: 10
Training loss: 1.935839295387268
Validation loss: 1.9889981995026271

Epoch: 5| Step: 11
Training loss: 1.6099621057510376
Validation loss: 1.9838028252124786

Epoch: 33| Step: 0
Training loss: 2.110635757446289
Validation loss: 1.9704224814971287

Epoch: 5| Step: 1
Training loss: 2.248494863510132
Validation loss: 1.999544953306516

Epoch: 5| Step: 2
Training loss: 1.7474676370620728
Validation loss: 2.0074461698532104

Epoch: 5| Step: 3
Training loss: 1.7520759105682373
Validation loss: 2.002707655231158

Epoch: 5| Step: 4
Training loss: 1.730420708656311
Validation loss: 1.9765791048606236

Epoch: 5| Step: 5
Training loss: 1.3795115947723389
Validation loss: 1.9714667052030563

Epoch: 5| Step: 6
Training loss: 1.8305946588516235
Validation loss: 1.994512140750885

Epoch: 5| Step: 7
Training loss: 2.2527987957000732
Validation loss: 1.976478636264801

Epoch: 5| Step: 8
Training loss: 1.9442598819732666
Validation loss: 2.011056219538053

Epoch: 5| Step: 9
Training loss: 2.5604989528656006
Validation loss: 2.004490335782369

Epoch: 5| Step: 10
Training loss: 1.7669769525527954
Validation loss: 1.9828996906677883

Epoch: 5| Step: 11
Training loss: 2.288574457168579
Validation loss: 1.9923935731252034

Epoch: 34| Step: 0
Training loss: 1.8984873294830322
Validation loss: 1.9647336900234222

Epoch: 5| Step: 1
Training loss: 2.04964017868042
Validation loss: 2.0187617937723794

Epoch: 5| Step: 2
Training loss: 2.274388074874878
Validation loss: 2.0062809884548187

Epoch: 5| Step: 3
Training loss: 1.8485982418060303
Validation loss: 1.9794282267491023

Epoch: 5| Step: 4
Training loss: 1.7831192016601562
Validation loss: 2.0116367042064667

Epoch: 5| Step: 5
Training loss: 1.667536735534668
Validation loss: 2.0076479415098825

Epoch: 5| Step: 6
Training loss: 2.5911078453063965
Validation loss: 2.0187593698501587

Epoch: 5| Step: 7
Training loss: 1.7892789840698242
Validation loss: 2.0181041906277337

Epoch: 5| Step: 8
Training loss: 2.0885298252105713
Validation loss: 2.0283299535512924

Epoch: 5| Step: 9
Training loss: 1.8585071563720703
Validation loss: 2.024403909842173

Epoch: 5| Step: 10
Training loss: 1.6087265014648438
Validation loss: 2.0193135490020118

Epoch: 5| Step: 11
Training loss: 1.396440029144287
Validation loss: 1.9925503780444462

Epoch: 35| Step: 0
Training loss: 2.8130829334259033
Validation loss: 1.99588746825854

Epoch: 5| Step: 1
Training loss: 2.034634828567505
Validation loss: 1.9801270216703415

Epoch: 5| Step: 2
Training loss: 2.3286097049713135
Validation loss: 1.975904921690623

Epoch: 5| Step: 3
Training loss: 1.8806473016738892
Validation loss: 1.9764137615760167

Epoch: 5| Step: 4
Training loss: 1.1957448720932007
Validation loss: 1.9736477533976238

Epoch: 5| Step: 5
Training loss: 2.265510320663452
Validation loss: 1.9670324275890987

Epoch: 5| Step: 6
Training loss: 1.8489128351211548
Validation loss: 1.9978824307521184

Epoch: 5| Step: 7
Training loss: 1.4354568719863892
Validation loss: 1.9804125626881917

Epoch: 5| Step: 8
Training loss: 1.4677019119262695
Validation loss: 1.9682005643844604

Epoch: 5| Step: 9
Training loss: 1.934107780456543
Validation loss: 2.006552363435427

Epoch: 5| Step: 10
Training loss: 2.3619027137756348
Validation loss: 1.9794142097234726

Epoch: 5| Step: 11
Training loss: 1.951082468032837
Validation loss: 1.9945187717676163

Epoch: 36| Step: 0
Training loss: 1.847272276878357
Validation loss: 2.000565305352211

Epoch: 5| Step: 1
Training loss: 1.3506525754928589
Validation loss: 2.0130386302868524

Epoch: 5| Step: 2
Training loss: 2.4221692085266113
Validation loss: 2.003957067926725

Epoch: 5| Step: 3
Training loss: 1.8104625940322876
Validation loss: 2.0361193865537643

Epoch: 5| Step: 4
Training loss: 2.150961399078369
Validation loss: 2.0373902271191278

Epoch: 5| Step: 5
Training loss: 1.8572546243667603
Validation loss: 2.0549979905287423

Epoch: 5| Step: 6
Training loss: 1.9386165142059326
Validation loss: 2.013917480905851

Epoch: 5| Step: 7
Training loss: 1.9342578649520874
Validation loss: 1.9954954087734222

Epoch: 5| Step: 8
Training loss: 1.4707778692245483
Validation loss: 2.0260137567917504

Epoch: 5| Step: 9
Training loss: 2.5942881107330322
Validation loss: 2.024464334050814

Epoch: 5| Step: 10
Training loss: 2.106835126876831
Validation loss: 2.0151549031337104

Epoch: 5| Step: 11
Training loss: 1.217484951019287
Validation loss: 2.0010981957117715

Epoch: 37| Step: 0
Training loss: 1.8221702575683594
Validation loss: 2.0117286145687103

Epoch: 5| Step: 1
Training loss: 2.1035237312316895
Validation loss: 2.016221468647321

Epoch: 5| Step: 2
Training loss: 2.4573781490325928
Validation loss: 2.035218929251035

Epoch: 5| Step: 3
Training loss: 1.7054246664047241
Validation loss: 2.012674331665039

Epoch: 5| Step: 4
Training loss: 1.6058409214019775
Validation loss: 2.004075437784195

Epoch: 5| Step: 5
Training loss: 2.0372722148895264
Validation loss: 2.028899778922399

Epoch: 5| Step: 6
Training loss: 2.184771776199341
Validation loss: 2.006319686770439

Epoch: 5| Step: 7
Training loss: 2.0147545337677
Validation loss: 1.981940637032191

Epoch: 5| Step: 8
Training loss: 1.7663919925689697
Validation loss: 2.0064634829759598

Epoch: 5| Step: 9
Training loss: 1.5952566862106323
Validation loss: 2.0171840141216912

Epoch: 5| Step: 10
Training loss: 1.4683058261871338
Validation loss: 2.010554184516271

Epoch: 5| Step: 11
Training loss: 3.318901538848877
Validation loss: 2.0177660137414932

Epoch: 38| Step: 0
Training loss: 1.8391294479370117
Validation loss: 2.0199834605058036

Epoch: 5| Step: 1
Training loss: 1.4817763566970825
Validation loss: 2.0323545237382254

Epoch: 5| Step: 2
Training loss: 2.0975253582000732
Validation loss: 2.0167100032170615

Epoch: 5| Step: 3
Training loss: 2.392122268676758
Validation loss: 2.0394624869028726

Epoch: 5| Step: 4
Training loss: 2.516399621963501
Validation loss: 2.0312209129333496

Epoch: 5| Step: 5
Training loss: 2.034261465072632
Validation loss: 2.0109125624100366

Epoch: 5| Step: 6
Training loss: 1.9514825344085693
Validation loss: 1.9920674463113148

Epoch: 5| Step: 7
Training loss: 1.9774227142333984
Validation loss: 2.011007994413376

Epoch: 5| Step: 8
Training loss: 1.4803111553192139
Validation loss: 1.9845024198293686

Epoch: 5| Step: 9
Training loss: 1.2841497659683228
Validation loss: 1.9929763227701187

Epoch: 5| Step: 10
Training loss: 2.1739559173583984
Validation loss: 2.0265639970699945

Epoch: 5| Step: 11
Training loss: 2.4512710571289062
Validation loss: 2.027770474553108

Epoch: 39| Step: 0
Training loss: 1.7748092412948608
Validation loss: 2.015296091636022

Epoch: 5| Step: 1
Training loss: 1.9730138778686523
Validation loss: 2.052717387676239

Epoch: 5| Step: 2
Training loss: 2.0839264392852783
Validation loss: 1.986234779159228

Epoch: 5| Step: 3
Training loss: 1.8838332891464233
Validation loss: 2.012991060813268

Epoch: 5| Step: 4
Training loss: 1.6463607549667358
Validation loss: 1.999204029639562

Epoch: 5| Step: 5
Training loss: 2.071012020111084
Validation loss: 1.9850213179985683

Epoch: 5| Step: 6
Training loss: 1.8777577877044678
Validation loss: 1.9854303002357483

Epoch: 5| Step: 7
Training loss: 2.2421271800994873
Validation loss: 1.9983252386252086

Epoch: 5| Step: 8
Training loss: 1.7180936336517334
Validation loss: 2.0034171044826508

Epoch: 5| Step: 9
Training loss: 1.5065501928329468
Validation loss: 1.9812914530436199

Epoch: 5| Step: 10
Training loss: 2.0008366107940674
Validation loss: 1.9885964840650558

Epoch: 5| Step: 11
Training loss: 3.284682273864746
Validation loss: 2.002666195233663

Epoch: 40| Step: 0
Training loss: 2.0669236183166504
Validation loss: 2.027894606192907

Epoch: 5| Step: 1
Training loss: 1.9738458395004272
Validation loss: 2.0336558471123376

Epoch: 5| Step: 2
Training loss: 1.4734947681427002
Validation loss: 2.0370969424645105

Epoch: 5| Step: 3
Training loss: 1.8168232440948486
Validation loss: 2.0379008998473487

Epoch: 5| Step: 4
Training loss: 2.0160460472106934
Validation loss: 2.037827715277672

Epoch: 5| Step: 5
Training loss: 2.6071009635925293
Validation loss: 2.0339168856541314

Epoch: 5| Step: 6
Training loss: 1.9215072393417358
Validation loss: 2.01280477643013

Epoch: 5| Step: 7
Training loss: 1.463984727859497
Validation loss: 2.0420118272304535

Epoch: 5| Step: 8
Training loss: 2.0002036094665527
Validation loss: 2.053962995608648

Epoch: 5| Step: 9
Training loss: 2.443459987640381
Validation loss: 2.0157537957032523

Epoch: 5| Step: 10
Training loss: 1.6379833221435547
Validation loss: 1.9938746591409047

Epoch: 5| Step: 11
Training loss: 0.637686550617218
Validation loss: 1.9799856543540955

Epoch: 41| Step: 0
Training loss: 1.4810470342636108
Validation loss: 1.9732192556063335

Epoch: 5| Step: 1
Training loss: 1.6066070795059204
Validation loss: 1.995991513133049

Epoch: 5| Step: 2
Training loss: 2.1402523517608643
Validation loss: 2.0069855550924935

Epoch: 5| Step: 3
Training loss: 2.111100912094116
Validation loss: 2.010438864429792

Epoch: 5| Step: 4
Training loss: 1.5614186525344849
Validation loss: 2.0026218394438424

Epoch: 5| Step: 5
Training loss: 1.8729078769683838
Validation loss: 2.015808825691541

Epoch: 5| Step: 6
Training loss: 1.9683310985565186
Validation loss: 2.031984264651934

Epoch: 5| Step: 7
Training loss: 1.8228130340576172
Validation loss: 2.070046549042066

Epoch: 5| Step: 8
Training loss: 1.9773391485214233
Validation loss: 2.0329729517300925

Epoch: 5| Step: 9
Training loss: 2.295563220977783
Validation loss: 2.0749530643224716

Epoch: 5| Step: 10
Training loss: 2.426806926727295
Validation loss: 2.0299642384052277

Epoch: 5| Step: 11
Training loss: 1.7556663751602173
Validation loss: 2.0124099800984063

Epoch: 42| Step: 0
Training loss: 1.8225529193878174
Validation loss: 2.0123150050640106

Epoch: 5| Step: 1
Training loss: 1.3600260019302368
Validation loss: 1.9892471631368

Epoch: 5| Step: 2
Training loss: 1.8816114664077759
Validation loss: 1.9912361701329548

Epoch: 5| Step: 3
Training loss: 1.5793006420135498
Validation loss: 2.036197324593862

Epoch: 5| Step: 4
Training loss: 2.1902663707733154
Validation loss: 2.014066865046819

Epoch: 5| Step: 5
Training loss: 1.5248212814331055
Validation loss: 2.0192245543003082

Epoch: 5| Step: 6
Training loss: 2.5103538036346436
Validation loss: 2.047812263170878

Epoch: 5| Step: 7
Training loss: 2.2637267112731934
Validation loss: 2.0205267717440925

Epoch: 5| Step: 8
Training loss: 1.8489910364151
Validation loss: 2.0323495864868164

Epoch: 5| Step: 9
Training loss: 1.9491252899169922
Validation loss: 2.033477986852328

Epoch: 5| Step: 10
Training loss: 2.0383400917053223
Validation loss: 2.0359344134728112

Epoch: 5| Step: 11
Training loss: 3.095684051513672
Validation loss: 2.0097010334332785

Epoch: 43| Step: 0
Training loss: 1.862432837486267
Validation loss: 2.00023345152537

Epoch: 5| Step: 1
Training loss: 2.1508820056915283
Validation loss: 1.9795407851537068

Epoch: 5| Step: 2
Training loss: 2.1636481285095215
Validation loss: 1.987919380267461

Epoch: 5| Step: 3
Training loss: 1.6552737951278687
Validation loss: 1.9516400198141735

Epoch: 5| Step: 4
Training loss: 2.081298828125
Validation loss: 1.9870448211828868

Epoch: 5| Step: 5
Training loss: 1.645808219909668
Validation loss: 1.9905362675587337

Epoch: 5| Step: 6
Training loss: 2.398406505584717
Validation loss: 1.9799887090921402

Epoch: 5| Step: 7
Training loss: 1.923862099647522
Validation loss: 1.9824209312597911

Epoch: 5| Step: 8
Training loss: 1.3324114084243774
Validation loss: 1.98794025182724

Epoch: 5| Step: 9
Training loss: 1.8736950159072876
Validation loss: 2.006656547387441

Epoch: 5| Step: 10
Training loss: 1.8252273797988892
Validation loss: 1.9472686002651851

Epoch: 5| Step: 11
Training loss: 3.1421093940734863
Validation loss: 1.9593576242526372

Epoch: 44| Step: 0
Training loss: 1.6660823822021484
Validation loss: 2.020075927178065

Epoch: 5| Step: 1
Training loss: 1.7754833698272705
Validation loss: 2.013654515147209

Epoch: 5| Step: 2
Training loss: 1.9496667385101318
Validation loss: 2.0213119784990945

Epoch: 5| Step: 3
Training loss: 1.9740664958953857
Validation loss: 2.0209918717543283

Epoch: 5| Step: 4
Training loss: 2.0166754722595215
Validation loss: 2.0255160182714462

Epoch: 5| Step: 5
Training loss: 2.061069965362549
Validation loss: 2.011134152611097

Epoch: 5| Step: 6
Training loss: 2.1010618209838867
Validation loss: 2.0005024671554565

Epoch: 5| Step: 7
Training loss: 1.67340886592865
Validation loss: 2.0293047428131104

Epoch: 5| Step: 8
Training loss: 1.3520302772521973
Validation loss: 1.9629792322715123

Epoch: 5| Step: 9
Training loss: 1.7756668329238892
Validation loss: 2.000537301103274

Epoch: 5| Step: 10
Training loss: 2.106066942214966
Validation loss: 1.974268967906634

Epoch: 5| Step: 11
Training loss: 3.988762855529785
Validation loss: 1.9766669124364853

Epoch: 45| Step: 0
Training loss: 1.9645566940307617
Validation loss: 2.042584682504336

Epoch: 5| Step: 1
Training loss: 2.1229355335235596
Validation loss: 2.0625151842832565

Epoch: 5| Step: 2
Training loss: 2.0282676219940186
Validation loss: 2.0640140622854233

Epoch: 5| Step: 3
Training loss: 1.4865522384643555
Validation loss: 2.0603362868229547

Epoch: 5| Step: 4
Training loss: 1.8074824810028076
Validation loss: 2.0330263574918113

Epoch: 5| Step: 5
Training loss: 1.894666075706482
Validation loss: 2.051497677961985

Epoch: 5| Step: 6
Training loss: 2.132838487625122
Validation loss: 2.0838641623655954

Epoch: 5| Step: 7
Training loss: 1.4119094610214233
Validation loss: 2.0226062486569085

Epoch: 5| Step: 8
Training loss: 1.716688871383667
Validation loss: 2.024493863185247

Epoch: 5| Step: 9
Training loss: 1.9079227447509766
Validation loss: 2.0066816161076226

Epoch: 5| Step: 10
Training loss: 2.1342926025390625
Validation loss: 2.000034968058268

Epoch: 5| Step: 11
Training loss: 1.9168481826782227
Validation loss: 1.999110370874405

Epoch: 46| Step: 0
Training loss: 1.683175802230835
Validation loss: 2.0170529385407767

Epoch: 5| Step: 1
Training loss: 1.5326101779937744
Validation loss: 1.9896478305260341

Epoch: 5| Step: 2
Training loss: 2.198103427886963
Validation loss: 2.0007207741340003

Epoch: 5| Step: 3
Training loss: 2.1156253814697266
Validation loss: 1.9828609774510066

Epoch: 5| Step: 4
Training loss: 1.264511227607727
Validation loss: 2.0421323031187057

Epoch: 5| Step: 5
Training loss: 1.7886922359466553
Validation loss: 2.0254800816377005

Epoch: 5| Step: 6
Training loss: 1.7537672519683838
Validation loss: 2.0264167338609695

Epoch: 5| Step: 7
Training loss: 1.4148982763290405
Validation loss: 2.0817867865165076

Epoch: 5| Step: 8
Training loss: 1.8906110525131226
Validation loss: 2.0985715687274933

Epoch: 5| Step: 9
Training loss: 1.9564155340194702
Validation loss: 2.092741479476293

Epoch: 5| Step: 10
Training loss: 2.700723171234131
Validation loss: 2.0877196739117303

Epoch: 5| Step: 11
Training loss: 2.992335319519043
Validation loss: 2.0640982190767923

Epoch: 47| Step: 0
Training loss: 1.5761706829071045
Validation loss: 2.005954682826996

Epoch: 5| Step: 1
Training loss: 1.7874500751495361
Validation loss: 2.0227402647336326

Epoch: 5| Step: 2
Training loss: 2.121835231781006
Validation loss: 1.9920120388269424

Epoch: 5| Step: 3
Training loss: 1.9423506259918213
Validation loss: 2.0054605652888617

Epoch: 5| Step: 4
Training loss: 2.1156437397003174
Validation loss: 2.0055024474859238

Epoch: 5| Step: 5
Training loss: 2.156883478164673
Validation loss: 1.94286052385966

Epoch: 5| Step: 6
Training loss: 2.098355770111084
Validation loss: 1.9961468676726024

Epoch: 5| Step: 7
Training loss: 1.6547486782073975
Validation loss: 1.9676824261744816

Epoch: 5| Step: 8
Training loss: 1.756786584854126
Validation loss: 2.0101135323445

Epoch: 5| Step: 9
Training loss: 1.924978494644165
Validation loss: 2.024857223033905

Epoch: 5| Step: 10
Training loss: 1.7219152450561523
Validation loss: 1.9851846148570378

Epoch: 5| Step: 11
Training loss: 1.3510053157806396
Validation loss: 2.0180309315522513

Epoch: 48| Step: 0
Training loss: 1.7711153030395508
Validation loss: 1.9946219176054

Epoch: 5| Step: 1
Training loss: 1.451928734779358
Validation loss: 2.040005718668302

Epoch: 5| Step: 2
Training loss: 1.7262945175170898
Validation loss: 2.057716732223829

Epoch: 5| Step: 3
Training loss: 2.574056625366211
Validation loss: 2.108366936445236

Epoch: 5| Step: 4
Training loss: 1.8134336471557617
Validation loss: 2.0943058828512826

Epoch: 5| Step: 5
Training loss: 1.8705075979232788
Validation loss: 2.0705912113189697

Epoch: 5| Step: 6
Training loss: 1.8209308385849
Validation loss: 2.089473401506742

Epoch: 5| Step: 7
Training loss: 1.7718899250030518
Validation loss: 2.1003248492876687

Epoch: 5| Step: 8
Training loss: 1.6527992486953735
Validation loss: 2.070408120751381

Epoch: 5| Step: 9
Training loss: 1.6728168725967407
Validation loss: 2.0916457027196884

Epoch: 5| Step: 10
Training loss: 2.182955503463745
Validation loss: 2.0354084223508835

Epoch: 5| Step: 11
Training loss: 1.8531968593597412
Validation loss: 2.009372959534327

Epoch: 49| Step: 0
Training loss: 2.0971574783325195
Validation loss: 1.997032458583514

Epoch: 5| Step: 1
Training loss: 1.5121897459030151
Validation loss: 2.0034436931212745

Epoch: 5| Step: 2
Training loss: 1.6957095861434937
Validation loss: 1.9747179249922435

Epoch: 5| Step: 3
Training loss: 1.7329353094100952
Validation loss: 1.9923470815022786

Epoch: 5| Step: 4
Training loss: 2.1785614490509033
Validation loss: 1.9767542878786724

Epoch: 5| Step: 5
Training loss: 2.2857816219329834
Validation loss: 1.9753884822130203

Epoch: 5| Step: 6
Training loss: 1.601745843887329
Validation loss: 1.9631712436676025

Epoch: 5| Step: 7
Training loss: 1.7766921520233154
Validation loss: 1.9723215649525325

Epoch: 5| Step: 8
Training loss: 1.4137799739837646
Validation loss: 1.9940065989891689

Epoch: 5| Step: 9
Training loss: 2.6506054401397705
Validation loss: 1.99831519027551

Epoch: 5| Step: 10
Training loss: 1.962274193763733
Validation loss: 2.0215227901935577

Epoch: 5| Step: 11
Training loss: 1.1374211311340332
Validation loss: 2.0351281265417733

Epoch: 50| Step: 0
Training loss: 2.2764370441436768
Validation loss: 2.0759305208921432

Epoch: 5| Step: 1
Training loss: 1.4768168926239014
Validation loss: 2.0658457974592843

Epoch: 5| Step: 2
Training loss: 2.1256942749023438
Validation loss: 2.0441505014896393

Epoch: 5| Step: 3
Training loss: 1.891336441040039
Validation loss: 2.0928155382474265

Epoch: 5| Step: 4
Training loss: 1.604921579360962
Validation loss: 2.0454463809728622

Epoch: 5| Step: 5
Training loss: 1.9333423376083374
Validation loss: 2.052358200152715

Epoch: 5| Step: 6
Training loss: 1.917210340499878
Validation loss: 2.0604020754496255

Epoch: 5| Step: 7
Training loss: 1.7191054821014404
Validation loss: 2.040153215328852

Epoch: 5| Step: 8
Training loss: 2.2325007915496826
Validation loss: 2.00806200504303

Epoch: 5| Step: 9
Training loss: 2.0173449516296387
Validation loss: 1.9682737191518147

Epoch: 5| Step: 10
Training loss: 1.4198038578033447
Validation loss: 1.9556733518838882

Epoch: 5| Step: 11
Training loss: 1.375203013420105
Validation loss: 2.0133345325787864

Epoch: 51| Step: 0
Training loss: 1.9385364055633545
Validation loss: 1.9762545377016068

Epoch: 5| Step: 1
Training loss: 2.087578296661377
Validation loss: 1.9718577613433201

Epoch: 5| Step: 2
Training loss: 2.33024001121521
Validation loss: 1.9619414309660594

Epoch: 5| Step: 3
Training loss: 0.9627355337142944
Validation loss: 1.98874931037426

Epoch: 5| Step: 4
Training loss: 1.713543176651001
Validation loss: 1.9471933245658875

Epoch: 5| Step: 5
Training loss: 2.031019687652588
Validation loss: 1.9869202077388763

Epoch: 5| Step: 6
Training loss: 1.4366042613983154
Validation loss: 2.0378611187140145

Epoch: 5| Step: 7
Training loss: 1.9681549072265625
Validation loss: 2.0472113142410913

Epoch: 5| Step: 8
Training loss: 2.087646722793579
Validation loss: 2.085424999396006

Epoch: 5| Step: 9
Training loss: 1.7609784603118896
Validation loss: 2.1029142290353775

Epoch: 5| Step: 10
Training loss: 1.7060836553573608
Validation loss: 2.0726199398438134

Epoch: 5| Step: 11
Training loss: 1.8921446800231934
Validation loss: 2.055019070704778

Epoch: 52| Step: 0
Training loss: 1.9796838760375977
Validation loss: 2.0716990480820336

Epoch: 5| Step: 1
Training loss: 1.893827199935913
Validation loss: 2.040008465449015

Epoch: 5| Step: 2
Training loss: 2.3169586658477783
Validation loss: 2.032573680082957

Epoch: 5| Step: 3
Training loss: 2.2998504638671875
Validation loss: 2.0078791280587516

Epoch: 5| Step: 4
Training loss: 2.2726731300354004
Validation loss: 2.0080950260162354

Epoch: 5| Step: 5
Training loss: 1.7115848064422607
Validation loss: 2.0007816702127457

Epoch: 5| Step: 6
Training loss: 1.879556655883789
Validation loss: 2.0118254125118256

Epoch: 5| Step: 7
Training loss: 1.7144845724105835
Validation loss: 1.9785495946804683

Epoch: 5| Step: 8
Training loss: 1.7309448719024658
Validation loss: 2.011856978138288

Epoch: 5| Step: 9
Training loss: 1.073718547821045
Validation loss: 2.009607752164205

Epoch: 5| Step: 10
Training loss: 1.7516698837280273
Validation loss: 2.0093638002872467

Epoch: 5| Step: 11
Training loss: 0.883427083492279
Validation loss: 2.039445256193479

Epoch: 53| Step: 0
Training loss: 1.4313743114471436
Validation loss: 2.0347252686818442

Epoch: 5| Step: 1
Training loss: 2.3738367557525635
Validation loss: 2.022700866063436

Epoch: 5| Step: 2
Training loss: 1.4806268215179443
Validation loss: 1.959562102953593

Epoch: 5| Step: 3
Training loss: 1.9926109313964844
Validation loss: 2.0333162248134613

Epoch: 5| Step: 4
Training loss: 2.5554280281066895
Validation loss: 2.0295522858699164

Epoch: 5| Step: 5
Training loss: 1.5722631216049194
Validation loss: 1.9931009262800217

Epoch: 5| Step: 6
Training loss: 1.4164178371429443
Validation loss: 1.9635543425877888

Epoch: 5| Step: 7
Training loss: 2.2812235355377197
Validation loss: 1.9724275569121044

Epoch: 5| Step: 8
Training loss: 1.4627047777175903
Validation loss: 2.0342796643575034

Epoch: 5| Step: 9
Training loss: 1.9934526681900024
Validation loss: 1.9986579765876133

Epoch: 5| Step: 10
Training loss: 1.9016568660736084
Validation loss: 2.0135637670755386

Epoch: 5| Step: 11
Training loss: 0.7732899188995361
Validation loss: 1.9930632561445236

Epoch: 54| Step: 0
Training loss: 1.6516414880752563
Validation loss: 2.041770095626513

Epoch: 5| Step: 1
Training loss: 1.3849889039993286
Validation loss: 2.037498434384664

Epoch: 5| Step: 2
Training loss: 2.6332013607025146
Validation loss: 2.0168872624635696

Epoch: 5| Step: 3
Training loss: 1.8796800374984741
Validation loss: 2.0191597143809

Epoch: 5| Step: 4
Training loss: 1.3744888305664062
Validation loss: 2.0419841607411704

Epoch: 5| Step: 5
Training loss: 2.0625827312469482
Validation loss: 2.0657795667648315

Epoch: 5| Step: 6
Training loss: 2.375185489654541
Validation loss: 2.0287661999464035

Epoch: 5| Step: 7
Training loss: 1.975956678390503
Validation loss: 2.0328970849514008

Epoch: 5| Step: 8
Training loss: 1.3908226490020752
Validation loss: 2.031565527121226

Epoch: 5| Step: 9
Training loss: 1.522911787033081
Validation loss: 2.001670698324839

Epoch: 5| Step: 10
Training loss: 1.8794056177139282
Validation loss: 2.006120060880979

Epoch: 5| Step: 11
Training loss: 1.637215256690979
Validation loss: 2.016379545132319

Epoch: 55| Step: 0
Training loss: 2.0039052963256836
Validation loss: 2.0124437659978867

Epoch: 5| Step: 1
Training loss: 1.8200794458389282
Validation loss: 1.9840809603532155

Epoch: 5| Step: 2
Training loss: 1.8272349834442139
Validation loss: 1.983815665046374

Epoch: 5| Step: 3
Training loss: 1.511206865310669
Validation loss: 2.029758632183075

Epoch: 5| Step: 4
Training loss: 1.6087100505828857
Validation loss: 1.99146402378877

Epoch: 5| Step: 5
Training loss: 2.014611005783081
Validation loss: 1.9925231238206227

Epoch: 5| Step: 6
Training loss: 1.7109243869781494
Validation loss: 2.023089716831843

Epoch: 5| Step: 7
Training loss: 1.9245784282684326
Validation loss: 2.0376069794098535

Epoch: 5| Step: 8
Training loss: 1.4563062191009521
Validation loss: 2.0837763796250024

Epoch: 5| Step: 9
Training loss: 2.206468105316162
Validation loss: 2.052026078104973

Epoch: 5| Step: 10
Training loss: 1.7454475164413452
Validation loss: 2.0312295655409494

Epoch: 5| Step: 11
Training loss: 3.57733154296875
Validation loss: 2.082496151328087

Epoch: 56| Step: 0
Training loss: 1.6897125244140625
Validation loss: 2.0309764643510184

Epoch: 5| Step: 1
Training loss: 1.7594263553619385
Validation loss: 2.004835377136866

Epoch: 5| Step: 2
Training loss: 1.7015098333358765
Validation loss: 2.0126913537581763

Epoch: 5| Step: 3
Training loss: 2.076406240463257
Validation loss: 1.9541936616102855

Epoch: 5| Step: 4
Training loss: 1.7993221282958984
Validation loss: 2.0148638784885406

Epoch: 5| Step: 5
Training loss: 2.6430861949920654
Validation loss: 2.034440358479818

Epoch: 5| Step: 6
Training loss: 1.5522764921188354
Validation loss: 1.978929951786995

Epoch: 5| Step: 7
Training loss: 1.6761245727539062
Validation loss: 1.9742085089286168

Epoch: 5| Step: 8
Training loss: 2.06524920463562
Validation loss: 1.994924748937289

Epoch: 5| Step: 9
Training loss: 1.3150687217712402
Validation loss: 1.999391794204712

Epoch: 5| Step: 10
Training loss: 1.9592643976211548
Validation loss: 2.0498233834902444

Epoch: 5| Step: 11
Training loss: 3.1475112438201904
Validation loss: 2.0407241533199945

Epoch: 57| Step: 0
Training loss: 1.7040647268295288
Validation loss: 2.032861759265264

Epoch: 5| Step: 1
Training loss: 1.7583339214324951
Validation loss: 2.0204675694306693

Epoch: 5| Step: 2
Training loss: 1.0055248737335205
Validation loss: 2.0426554530858994

Epoch: 5| Step: 3
Training loss: 1.3169610500335693
Validation loss: 2.004110743602117

Epoch: 5| Step: 4
Training loss: 1.81820809841156
Validation loss: 2.0268564919630685

Epoch: 5| Step: 5
Training loss: 2.0652856826782227
Validation loss: 2.003062372406324

Epoch: 5| Step: 6
Training loss: 1.9536069631576538
Validation loss: 2.0293768793344498

Epoch: 5| Step: 7
Training loss: 2.107882261276245
Validation loss: 1.992374872167905

Epoch: 5| Step: 8
Training loss: 2.084301471710205
Validation loss: 1.9737345278263092

Epoch: 5| Step: 9
Training loss: 2.0431573390960693
Validation loss: 1.9479991296927135

Epoch: 5| Step: 10
Training loss: 1.873439073562622
Validation loss: 1.9865821450948715

Epoch: 5| Step: 11
Training loss: 0.9608548879623413
Validation loss: 1.9819536755482356

Epoch: 58| Step: 0
Training loss: 1.7059837579727173
Validation loss: 2.0056961377461753

Epoch: 5| Step: 1
Training loss: 1.7671787738800049
Validation loss: 2.027266412973404

Epoch: 5| Step: 2
Training loss: 1.3152177333831787
Validation loss: 2.0564980755249658

Epoch: 5| Step: 3
Training loss: 1.741754174232483
Validation loss: 2.070730999112129

Epoch: 5| Step: 4
Training loss: 1.7192203998565674
Validation loss: 2.0455426226059594

Epoch: 5| Step: 5
Training loss: 1.6257190704345703
Validation loss: 2.0781964162985482

Epoch: 5| Step: 6
Training loss: 1.8461507558822632
Validation loss: 2.0293986002604165

Epoch: 5| Step: 7
Training loss: 2.3523764610290527
Validation loss: 1.9934999744097393

Epoch: 5| Step: 8
Training loss: 1.9815953969955444
Validation loss: 2.0612028936545053

Epoch: 5| Step: 9
Training loss: 1.566644310951233
Validation loss: 1.998526856303215

Epoch: 5| Step: 10
Training loss: 2.0861763954162598
Validation loss: 1.9804603159427643

Epoch: 5| Step: 11
Training loss: 1.417662262916565
Validation loss: 2.0011445383230844

Epoch: 59| Step: 0
Training loss: 1.4558613300323486
Validation loss: 2.0049939850966134

Epoch: 5| Step: 1
Training loss: 1.6599667072296143
Validation loss: 2.0131403108437858

Epoch: 5| Step: 2
Training loss: 2.071974277496338
Validation loss: 2.0658562779426575

Epoch: 5| Step: 3
Training loss: 1.2732176780700684
Validation loss: 2.0450738221406937

Epoch: 5| Step: 4
Training loss: 1.5548688173294067
Validation loss: 2.046745846668879

Epoch: 5| Step: 5
Training loss: 2.2685768604278564
Validation loss: 2.0775256802638373

Epoch: 5| Step: 6
Training loss: 2.1543452739715576
Validation loss: 2.044826775789261

Epoch: 5| Step: 7
Training loss: 1.7428019046783447
Validation loss: 2.0588639775911965

Epoch: 5| Step: 8
Training loss: 1.5896389484405518
Validation loss: 2.062123656272888

Epoch: 5| Step: 9
Training loss: 2.2660539150238037
Validation loss: 2.04483126103878

Epoch: 5| Step: 10
Training loss: 1.5107464790344238
Validation loss: 1.9984155247608821

Epoch: 5| Step: 11
Training loss: 1.599569320678711
Validation loss: 2.0202555855115256

Epoch: 60| Step: 0
Training loss: 1.4247726202011108
Validation loss: 1.981138601899147

Epoch: 5| Step: 1
Training loss: 1.6006721258163452
Validation loss: 1.9905973970890045

Epoch: 5| Step: 2
Training loss: 2.2002627849578857
Validation loss: 2.0149390449126563

Epoch: 5| Step: 3
Training loss: 1.7193142175674438
Validation loss: 1.9756639798482258

Epoch: 5| Step: 4
Training loss: 1.6031734943389893
Validation loss: 1.9521621068318684

Epoch: 5| Step: 5
Training loss: 2.1378653049468994
Validation loss: 1.9964641133944194

Epoch: 5| Step: 6
Training loss: 1.807003378868103
Validation loss: 2.0141028563181558

Epoch: 5| Step: 7
Training loss: 1.8354871273040771
Validation loss: 1.965046723683675

Epoch: 5| Step: 8
Training loss: 2.2426741123199463
Validation loss: 2.0064846773942313

Epoch: 5| Step: 9
Training loss: 2.047478199005127
Validation loss: 2.0265829463799796

Epoch: 5| Step: 10
Training loss: 1.2812551259994507
Validation loss: 2.0273954619963965

Epoch: 5| Step: 11
Training loss: 1.4490125179290771
Validation loss: 2.0398750752210617

Epoch: 61| Step: 0
Training loss: 1.9487285614013672
Validation loss: 2.032872090737025

Epoch: 5| Step: 1
Training loss: 1.668267846107483
Validation loss: 2.1742888192335763

Epoch: 5| Step: 2
Training loss: 1.6988840103149414
Validation loss: 2.1052005688349404

Epoch: 5| Step: 3
Training loss: 1.4955520629882812
Validation loss: 2.138858442505201

Epoch: 5| Step: 4
Training loss: 2.3038923740386963
Validation loss: 2.0938992500305176

Epoch: 5| Step: 5
Training loss: 1.9207509756088257
Validation loss: 2.107193390528361

Epoch: 5| Step: 6
Training loss: 1.5188922882080078
Validation loss: 1.9911635220050812

Epoch: 5| Step: 7
Training loss: 1.4895108938217163
Validation loss: 1.9979466150204341

Epoch: 5| Step: 8
Training loss: 2.49273419380188
Validation loss: 1.9735611180464427

Epoch: 5| Step: 9
Training loss: 1.6879249811172485
Validation loss: 1.9618802666664124

Epoch: 5| Step: 10
Training loss: 1.8489360809326172
Validation loss: 1.991267591714859

Epoch: 5| Step: 11
Training loss: 1.5479899644851685
Validation loss: 2.0198576897382736

Epoch: 62| Step: 0
Training loss: 1.8999429941177368
Validation loss: 1.995450645685196

Epoch: 5| Step: 1
Training loss: 2.1696765422821045
Validation loss: 2.0164024084806442

Epoch: 5| Step: 2
Training loss: 2.062250852584839
Validation loss: 1.963881939649582

Epoch: 5| Step: 3
Training loss: 1.5674941539764404
Validation loss: 2.005645533402761

Epoch: 5| Step: 4
Training loss: 2.027452230453491
Validation loss: 2.0159902373949685

Epoch: 5| Step: 5
Training loss: 1.8815838098526
Validation loss: 1.9651743471622467

Epoch: 5| Step: 6
Training loss: 1.837132215499878
Validation loss: 1.9564869701862335

Epoch: 5| Step: 7
Training loss: 1.3820594549179077
Validation loss: 1.9682117700576782

Epoch: 5| Step: 8
Training loss: 1.351523756980896
Validation loss: 2.026170233885447

Epoch: 5| Step: 9
Training loss: 2.1646714210510254
Validation loss: 2.020945409933726

Epoch: 5| Step: 10
Training loss: 1.5231850147247314
Validation loss: 2.0691108802954354

Epoch: 5| Step: 11
Training loss: 1.663055419921875
Validation loss: 2.0641853362321854

Epoch: 63| Step: 0
Training loss: 1.7090446949005127
Validation loss: 2.1056171456972756

Epoch: 5| Step: 1
Training loss: 2.103557586669922
Validation loss: 2.203888883193334

Epoch: 5| Step: 2
Training loss: 2.2765769958496094
Validation loss: 2.1677920470635095

Epoch: 5| Step: 3
Training loss: 2.2211921215057373
Validation loss: 2.193124314149221

Epoch: 5| Step: 4
Training loss: 1.5321732759475708
Validation loss: 2.151780595382055

Epoch: 5| Step: 5
Training loss: 1.1716643571853638
Validation loss: 2.11842713256677

Epoch: 5| Step: 6
Training loss: 1.710689902305603
Validation loss: 2.0576848636070886

Epoch: 5| Step: 7
Training loss: 2.5862183570861816
Validation loss: 2.014402136206627

Epoch: 5| Step: 8
Training loss: 1.928354024887085
Validation loss: 1.9929525603850682

Epoch: 5| Step: 9
Training loss: 1.3978818655014038
Validation loss: 2.001127004623413

Epoch: 5| Step: 10
Training loss: 1.350973129272461
Validation loss: 1.979944184422493

Epoch: 5| Step: 11
Training loss: 2.9644672870635986
Validation loss: 1.957207977771759

Epoch: 64| Step: 0
Training loss: 2.145327091217041
Validation loss: 1.9778105368216832

Epoch: 5| Step: 1
Training loss: 1.7488247156143188
Validation loss: 1.981434981028239

Epoch: 5| Step: 2
Training loss: 1.6968860626220703
Validation loss: 2.009473462899526

Epoch: 5| Step: 3
Training loss: 1.7438623905181885
Validation loss: 1.983695387840271

Epoch: 5| Step: 4
Training loss: 1.5019853115081787
Validation loss: 1.9923333078622818

Epoch: 5| Step: 5
Training loss: 1.0829753875732422
Validation loss: 1.9999455710252125

Epoch: 5| Step: 6
Training loss: 2.4817214012145996
Validation loss: 1.9647723933060963

Epoch: 5| Step: 7
Training loss: 1.4734829664230347
Validation loss: 2.0107783327500024

Epoch: 5| Step: 8
Training loss: 2.2895965576171875
Validation loss: 1.9755659500757854

Epoch: 5| Step: 9
Training loss: 1.5989341735839844
Validation loss: 2.048078179359436

Epoch: 5| Step: 10
Training loss: 1.7504265308380127
Validation loss: 2.001485859354337

Epoch: 5| Step: 11
Training loss: 2.052480936050415
Validation loss: 2.079599599043528

Epoch: 65| Step: 0
Training loss: 1.6856844425201416
Validation loss: 2.1086898197730384

Epoch: 5| Step: 1
Training loss: 1.8630268573760986
Validation loss: 2.1677750746409097

Epoch: 5| Step: 2
Training loss: 1.3951383829116821
Validation loss: 2.1866874992847443

Epoch: 5| Step: 3
Training loss: 1.622446060180664
Validation loss: 2.234963377316793

Epoch: 5| Step: 4
Training loss: 1.2714996337890625
Validation loss: 2.1651600748300552

Epoch: 5| Step: 5
Training loss: 1.9743478298187256
Validation loss: 2.1544082711140313

Epoch: 5| Step: 6
Training loss: 2.5372278690338135
Validation loss: 2.0742830634117126

Epoch: 5| Step: 7
Training loss: 1.863612413406372
Validation loss: 2.0740374674399695

Epoch: 5| Step: 8
Training loss: 2.226919651031494
Validation loss: 2.0022027591864267

Epoch: 5| Step: 9
Training loss: 1.3775399923324585
Validation loss: 1.9970824072758357

Epoch: 5| Step: 10
Training loss: 1.9674673080444336
Validation loss: 1.9808815171321232

Epoch: 5| Step: 11
Training loss: 1.2056150436401367
Validation loss: 2.001072237888972

Epoch: 66| Step: 0
Training loss: 2.614943742752075
Validation loss: 2.0069339176019034

Epoch: 5| Step: 1
Training loss: 1.970876693725586
Validation loss: 2.029993628462156

Epoch: 5| Step: 2
Training loss: 2.1616930961608887
Validation loss: 2.032263398170471

Epoch: 5| Step: 3
Training loss: 1.5675666332244873
Validation loss: 2.0112411777178445

Epoch: 5| Step: 4
Training loss: 1.9735206365585327
Validation loss: 2.0062836507956185

Epoch: 5| Step: 5
Training loss: 1.930925726890564
Validation loss: 1.9884441643953323

Epoch: 5| Step: 6
Training loss: 1.3502914905548096
Validation loss: 1.9909771631161373

Epoch: 5| Step: 7
Training loss: 1.49861741065979
Validation loss: 2.0190544525782266

Epoch: 5| Step: 8
Training loss: 1.5779836177825928
Validation loss: 2.033473422129949

Epoch: 5| Step: 9
Training loss: 1.7995903491973877
Validation loss: 2.006254250804583

Epoch: 5| Step: 10
Training loss: 1.6497581005096436
Validation loss: 2.0094113995631537

Epoch: 5| Step: 11
Training loss: 3.2667243480682373
Validation loss: 2.0548378576835

Epoch: 67| Step: 0
Training loss: 2.2359158992767334
Validation loss: 2.042587215701739

Epoch: 5| Step: 1
Training loss: 1.2366361618041992
Validation loss: 2.0744412938753762

Epoch: 5| Step: 2
Training loss: 1.6741113662719727
Validation loss: 2.0570892741282782

Epoch: 5| Step: 3
Training loss: 1.4957401752471924
Validation loss: 2.027138282855352

Epoch: 5| Step: 4
Training loss: 1.511176347732544
Validation loss: 2.046727562944094

Epoch: 5| Step: 5
Training loss: 1.6939138174057007
Validation loss: 2.0130052814881005

Epoch: 5| Step: 6
Training loss: 1.915975570678711
Validation loss: 2.0081584751605988

Epoch: 5| Step: 7
Training loss: 2.3626859188079834
Validation loss: 1.9961245357990265

Epoch: 5| Step: 8
Training loss: 1.3580735921859741
Validation loss: 1.9927107940117519

Epoch: 5| Step: 9
Training loss: 1.2012635469436646
Validation loss: 1.993711307644844

Epoch: 5| Step: 10
Training loss: 1.7778949737548828
Validation loss: 2.0369667361179986

Epoch: 5| Step: 11
Training loss: 2.9380104541778564
Validation loss: 1.9944943636655807

Epoch: 68| Step: 0
Training loss: 1.5506161451339722
Validation loss: 2.0456175953149796

Epoch: 5| Step: 1
Training loss: 1.4718233346939087
Validation loss: 2.0544028083483377

Epoch: 5| Step: 2
Training loss: 1.4797632694244385
Validation loss: 2.0521445870399475

Epoch: 5| Step: 3
Training loss: 1.6804805994033813
Validation loss: 2.0257776975631714

Epoch: 5| Step: 4
Training loss: 1.4167163372039795
Validation loss: 2.035136173168818

Epoch: 5| Step: 5
Training loss: 1.8225021362304688
Validation loss: 2.0380052427450814

Epoch: 5| Step: 6
Training loss: 2.1926541328430176
Validation loss: 2.05227721730868

Epoch: 5| Step: 7
Training loss: 2.195730686187744
Validation loss: 2.0284134099880853

Epoch: 5| Step: 8
Training loss: 1.5212035179138184
Validation loss: 2.0187751253445945

Epoch: 5| Step: 9
Training loss: 1.705911636352539
Validation loss: 1.9959558099508286

Epoch: 5| Step: 10
Training loss: 1.761364221572876
Validation loss: 2.04527685046196

Epoch: 5| Step: 11
Training loss: 1.0805144309997559
Validation loss: 2.058702826499939

Epoch: 69| Step: 0
Training loss: 1.6534955501556396
Validation loss: 2.0562935372193656

Epoch: 5| Step: 1
Training loss: 2.038015842437744
Validation loss: 2.051527733604113

Epoch: 5| Step: 2
Training loss: 2.179666519165039
Validation loss: 2.0469638208548226

Epoch: 5| Step: 3
Training loss: 1.7468913793563843
Validation loss: 2.0056370397408805

Epoch: 5| Step: 4
Training loss: 1.5856226682662964
Validation loss: 2.01044354836146

Epoch: 5| Step: 5
Training loss: 1.7217533588409424
Validation loss: 2.0320379386345544

Epoch: 5| Step: 6
Training loss: 1.6224864721298218
Validation loss: 2.0123267521460853

Epoch: 5| Step: 7
Training loss: 1.8913211822509766
Validation loss: 2.0334323892990747

Epoch: 5| Step: 8
Training loss: 1.3864762783050537
Validation loss: 2.0096955796082816

Epoch: 5| Step: 9
Training loss: 1.18583083152771
Validation loss: 2.034508844216665

Epoch: 5| Step: 10
Training loss: 2.0713939666748047
Validation loss: 2.024165297547976

Epoch: 5| Step: 11
Training loss: 2.056417942047119
Validation loss: 2.0432125280300775

Epoch: 70| Step: 0
Training loss: 1.823887825012207
Validation loss: 2.1157496770222983

Epoch: 5| Step: 1
Training loss: 1.3226677179336548
Validation loss: 2.175460288921992

Epoch: 5| Step: 2
Training loss: 2.297089099884033
Validation loss: 2.181181167562803

Epoch: 5| Step: 3
Training loss: 2.1535885334014893
Validation loss: 2.2235254496335983

Epoch: 5| Step: 4
Training loss: 2.078263759613037
Validation loss: 2.1933369686206183

Epoch: 5| Step: 5
Training loss: 1.5530707836151123
Validation loss: 2.193803603450457

Epoch: 5| Step: 6
Training loss: 2.2105586528778076
Validation loss: 2.108774150411288

Epoch: 5| Step: 7
Training loss: 1.657134771347046
Validation loss: 2.043697252869606

Epoch: 5| Step: 8
Training loss: 1.4560496807098389
Validation loss: 2.0385188162326813

Epoch: 5| Step: 9
Training loss: 1.7135133743286133
Validation loss: 1.9871471027533214

Epoch: 5| Step: 10
Training loss: 1.5039594173431396
Validation loss: 2.008375252286593

Epoch: 5| Step: 11
Training loss: 2.0866289138793945
Validation loss: 1.9687448938687642

Epoch: 71| Step: 0
Training loss: 1.7213332653045654
Validation loss: 1.9819203317165375

Epoch: 5| Step: 1
Training loss: 1.1685702800750732
Validation loss: 1.9962161580721538

Epoch: 5| Step: 2
Training loss: 1.3478087186813354
Validation loss: 1.9824260820945103

Epoch: 5| Step: 3
Training loss: 1.9212024211883545
Validation loss: 1.968051681915919

Epoch: 5| Step: 4
Training loss: 2.2896947860717773
Validation loss: 2.031298299630483

Epoch: 5| Step: 5
Training loss: 1.5931308269500732
Validation loss: 2.0313495695590973

Epoch: 5| Step: 6
Training loss: 2.135946035385132
Validation loss: 2.0292378266652427

Epoch: 5| Step: 7
Training loss: 1.250040054321289
Validation loss: 2.074733411272367

Epoch: 5| Step: 8
Training loss: 2.208277940750122
Validation loss: 2.0467213690280914

Epoch: 5| Step: 9
Training loss: 1.733036756515503
Validation loss: 2.028147985537847

Epoch: 5| Step: 10
Training loss: 1.7234258651733398
Validation loss: 2.056137517094612

Epoch: 5| Step: 11
Training loss: 1.471872091293335
Validation loss: 2.041202868024508

Epoch: 72| Step: 0
Training loss: 2.0276436805725098
Validation loss: 1.9999901205301285

Epoch: 5| Step: 1
Training loss: 1.6285909414291382
Validation loss: 2.015368307630221

Epoch: 5| Step: 2
Training loss: 1.688431739807129
Validation loss: 1.9830033679803212

Epoch: 5| Step: 3
Training loss: 1.758577585220337
Validation loss: 1.9807196507851283

Epoch: 5| Step: 4
Training loss: 2.5710768699645996
Validation loss: 1.974318226178487

Epoch: 5| Step: 5
Training loss: 1.827989935874939
Validation loss: 1.9845782270034154

Epoch: 5| Step: 6
Training loss: 1.2142407894134521
Validation loss: 1.968335563937823

Epoch: 5| Step: 7
Training loss: 1.7097342014312744
Validation loss: 1.9819384664297104

Epoch: 5| Step: 8
Training loss: 1.7892429828643799
Validation loss: 1.9300106714169185

Epoch: 5| Step: 9
Training loss: 1.6626962423324585
Validation loss: 2.027125592033068

Epoch: 5| Step: 10
Training loss: 1.3547139167785645
Validation loss: 2.0150424440701804

Epoch: 5| Step: 11
Training loss: 0.31100237369537354
Validation loss: 2.0411637177069983

Epoch: 73| Step: 0
Training loss: 1.8213800191879272
Validation loss: 2.157493939002355

Epoch: 5| Step: 1
Training loss: 2.222738265991211
Validation loss: 2.252203052242597

Epoch: 5| Step: 2
Training loss: 2.1505260467529297
Validation loss: 2.326211710770925

Epoch: 5| Step: 3
Training loss: 1.9348350763320923
Validation loss: 2.288602481285731

Epoch: 5| Step: 4
Training loss: 1.9953922033309937
Validation loss: 2.2859945396582284

Epoch: 5| Step: 5
Training loss: 1.7753422260284424
Validation loss: 2.2506457616885505

Epoch: 5| Step: 6
Training loss: 1.5443332195281982
Validation loss: 2.144121547540029

Epoch: 5| Step: 7
Training loss: 1.4648873805999756
Validation loss: 2.088544934988022

Epoch: 5| Step: 8
Training loss: 1.9420738220214844
Validation loss: 2.0321462651093802

Epoch: 5| Step: 9
Training loss: 1.94539475440979
Validation loss: 1.9532413283983867

Epoch: 5| Step: 10
Training loss: 1.3559317588806152
Validation loss: 1.9704001148541768

Epoch: 5| Step: 11
Training loss: 2.3313891887664795
Validation loss: 1.9627617696921031

Epoch: 74| Step: 0
Training loss: 1.4561952352523804
Validation loss: 2.006514757871628

Epoch: 5| Step: 1
Training loss: 2.207235336303711
Validation loss: 1.9982900867859523

Epoch: 5| Step: 2
Training loss: 1.4976621866226196
Validation loss: 2.0304642617702484

Epoch: 5| Step: 3
Training loss: 1.9442713260650635
Validation loss: 1.9606776982545853

Epoch: 5| Step: 4
Training loss: 2.0586204528808594
Validation loss: 1.9808308134476345

Epoch: 5| Step: 5
Training loss: 1.7876739501953125
Validation loss: 2.004703164100647

Epoch: 5| Step: 6
Training loss: 1.6433990001678467
Validation loss: 1.993314986427625

Epoch: 5| Step: 7
Training loss: 1.3121392726898193
Validation loss: 1.9529873132705688

Epoch: 5| Step: 8
Training loss: 1.5574958324432373
Validation loss: 1.972859303156535

Epoch: 5| Step: 9
Training loss: 1.8531068563461304
Validation loss: 2.0107541382312775

Epoch: 5| Step: 10
Training loss: 1.7090425491333008
Validation loss: 2.045528848965963

Epoch: 5| Step: 11
Training loss: 2.4192819595336914
Validation loss: 2.078976114590963

Epoch: 75| Step: 0
Training loss: 2.025578737258911
Validation loss: 2.0343879659970603

Epoch: 5| Step: 1
Training loss: 1.7986955642700195
Validation loss: 2.091049094994863

Epoch: 5| Step: 2
Training loss: 2.174748659133911
Validation loss: 2.0812090088923774

Epoch: 5| Step: 3
Training loss: 1.465586543083191
Validation loss: 2.0489448805650077

Epoch: 5| Step: 4
Training loss: 1.6177072525024414
Validation loss: 2.0313410063584647

Epoch: 5| Step: 5
Training loss: 2.0544991493225098
Validation loss: 2.052261287967364

Epoch: 5| Step: 6
Training loss: 1.3231735229492188
Validation loss: 2.0294800251722336

Epoch: 5| Step: 7
Training loss: 1.582896113395691
Validation loss: 2.0677903840939202

Epoch: 5| Step: 8
Training loss: 1.8931865692138672
Validation loss: 2.0493458112080893

Epoch: 5| Step: 9
Training loss: 1.241599678993225
Validation loss: 2.0180838853120804

Epoch: 5| Step: 10
Training loss: 1.2242546081542969
Validation loss: 2.005566274126371

Epoch: 5| Step: 11
Training loss: 1.6572452783584595
Validation loss: 2.018198147416115

Epoch: 76| Step: 0
Training loss: 1.2668405771255493
Validation loss: 2.024989143013954

Epoch: 5| Step: 1
Training loss: 1.764556884765625
Validation loss: 2.0512999395529428

Epoch: 5| Step: 2
Training loss: 1.4969182014465332
Validation loss: 2.0085881451765695

Epoch: 5| Step: 3
Training loss: 2.388845920562744
Validation loss: 2.009204392631849

Epoch: 5| Step: 4
Training loss: 1.5946524143218994
Validation loss: 2.057710056503614

Epoch: 5| Step: 5
Training loss: 1.58414626121521
Validation loss: 2.040950725475947

Epoch: 5| Step: 6
Training loss: 1.7629426717758179
Validation loss: 2.055301328500112

Epoch: 5| Step: 7
Training loss: 1.2899290323257446
Validation loss: 2.049793536464373

Epoch: 5| Step: 8
Training loss: 1.9961068630218506
Validation loss: 2.011172483364741

Epoch: 5| Step: 9
Training loss: 1.658339500427246
Validation loss: 1.9885044991970062

Epoch: 5| Step: 10
Training loss: 1.6577098369598389
Validation loss: 1.9891016532977421

Epoch: 5| Step: 11
Training loss: 1.8618688583374023
Validation loss: 1.9746143619219463

Epoch: 77| Step: 0
Training loss: 1.9057390689849854
Validation loss: 1.9841623554627101

Epoch: 5| Step: 1
Training loss: 1.5701026916503906
Validation loss: 2.040038213133812

Epoch: 5| Step: 2
Training loss: 1.9347301721572876
Validation loss: 2.0117881844441095

Epoch: 5| Step: 3
Training loss: 2.1728391647338867
Validation loss: 2.0187192062536874

Epoch: 5| Step: 4
Training loss: 1.3954527378082275
Validation loss: 2.018846164147059

Epoch: 5| Step: 5
Training loss: 1.356166958808899
Validation loss: 2.0655823896328607

Epoch: 5| Step: 6
Training loss: 1.2616522312164307
Validation loss: 2.0868346442778907

Epoch: 5| Step: 7
Training loss: 2.3159399032592773
Validation loss: 2.097693214813868

Epoch: 5| Step: 8
Training loss: 1.33439040184021
Validation loss: 2.061499153574308

Epoch: 5| Step: 9
Training loss: 1.5281469821929932
Validation loss: 2.0288963367541633

Epoch: 5| Step: 10
Training loss: 1.537902593612671
Validation loss: 1.9951132188240688

Epoch: 5| Step: 11
Training loss: 1.9629707336425781
Validation loss: 2.0037488838036857

Epoch: 78| Step: 0
Training loss: 1.7191646099090576
Validation loss: 1.9967577209075291

Epoch: 5| Step: 1
Training loss: 2.0632705688476562
Validation loss: 2.0146563748518624

Epoch: 5| Step: 2
Training loss: 1.8937991857528687
Validation loss: 2.005934864282608

Epoch: 5| Step: 3
Training loss: 1.3686944246292114
Validation loss: 1.9525677810112636

Epoch: 5| Step: 4
Training loss: 1.7540203332901
Validation loss: 2.0420583138863244

Epoch: 5| Step: 5
Training loss: 1.0976308584213257
Validation loss: 2.0369902600844703

Epoch: 5| Step: 6
Training loss: 1.8330631256103516
Validation loss: 2.0255904495716095

Epoch: 5| Step: 7
Training loss: 1.5439809560775757
Validation loss: 2.0289452920357385

Epoch: 5| Step: 8
Training loss: 1.619985818862915
Validation loss: 2.0415461162726083

Epoch: 5| Step: 9
Training loss: 1.6216857433319092
Validation loss: 2.048369417587916

Epoch: 5| Step: 10
Training loss: 1.877931833267212
Validation loss: 2.0260778218507767

Epoch: 5| Step: 11
Training loss: 1.1137943267822266
Validation loss: 2.07013209660848

Epoch: 79| Step: 0
Training loss: 2.081350803375244
Validation loss: 2.007409850756327

Epoch: 5| Step: 1
Training loss: 1.999826192855835
Validation loss: 2.057424614826838

Epoch: 5| Step: 2
Training loss: 1.6115093231201172
Validation loss: 1.9527833859125774

Epoch: 5| Step: 3
Training loss: 1.2086788415908813
Validation loss: 1.9762586305538814

Epoch: 5| Step: 4
Training loss: 1.4807677268981934
Validation loss: 1.9688602536916733

Epoch: 5| Step: 5
Training loss: 1.8285152912139893
Validation loss: 2.0195343693097434

Epoch: 5| Step: 6
Training loss: 1.4622604846954346
Validation loss: 1.9616604646046956

Epoch: 5| Step: 7
Training loss: 1.2427538633346558
Validation loss: 1.980034962296486

Epoch: 5| Step: 8
Training loss: 1.678393006324768
Validation loss: 2.0078800121943154

Epoch: 5| Step: 9
Training loss: 1.4208950996398926
Validation loss: 2.018499861160914

Epoch: 5| Step: 10
Training loss: 1.9758189916610718
Validation loss: 2.1172923843065896

Epoch: 5| Step: 11
Training loss: 0.705696165561676
Validation loss: 2.10364530980587

Epoch: 80| Step: 0
Training loss: 1.5111157894134521
Validation loss: 2.0629655669132867

Epoch: 5| Step: 1
Training loss: 1.3150800466537476
Validation loss: 2.0478981932004294

Epoch: 5| Step: 2
Training loss: 2.123217821121216
Validation loss: 2.015397315224012

Epoch: 5| Step: 3
Training loss: 2.1926939487457275
Validation loss: 2.00453611711661

Epoch: 5| Step: 4
Training loss: 1.7939059734344482
Validation loss: 1.9942855934302013

Epoch: 5| Step: 5
Training loss: 1.144265055656433
Validation loss: 1.9633133262395859

Epoch: 5| Step: 6
Training loss: 1.7639148235321045
Validation loss: 1.9906942298014958

Epoch: 5| Step: 7
Training loss: 1.4403936862945557
Validation loss: 2.023174300789833

Epoch: 5| Step: 8
Training loss: 1.886887788772583
Validation loss: 1.9772585332393646

Epoch: 5| Step: 9
Training loss: 1.4175138473510742
Validation loss: 1.9766023854414623

Epoch: 5| Step: 10
Training loss: 1.2612186670303345
Validation loss: 2.0193111350138984

Epoch: 5| Step: 11
Training loss: 1.6939857006072998
Validation loss: 2.0374758392572403

Epoch: 81| Step: 0
Training loss: 1.2338792085647583
Validation loss: 2.079688092072805

Epoch: 5| Step: 1
Training loss: 1.973122000694275
Validation loss: 2.1112222323815026

Epoch: 5| Step: 2
Training loss: 1.6358562707901
Validation loss: 2.1533557971318564

Epoch: 5| Step: 3
Training loss: 1.1737502813339233
Validation loss: 2.1301258703072867

Epoch: 5| Step: 4
Training loss: 1.7608680725097656
Validation loss: 2.1175635953744254

Epoch: 5| Step: 5
Training loss: 2.0410332679748535
Validation loss: 2.113928268353144

Epoch: 5| Step: 6
Training loss: 1.6287078857421875
Validation loss: 2.027909442782402

Epoch: 5| Step: 7
Training loss: 1.4441261291503906
Validation loss: 2.022885332504908

Epoch: 5| Step: 8
Training loss: 1.8099256753921509
Validation loss: 2.0519550095001855

Epoch: 5| Step: 9
Training loss: 2.2141356468200684
Validation loss: 2.028517891963323

Epoch: 5| Step: 10
Training loss: 1.6349890232086182
Validation loss: 1.9430942833423615

Epoch: 5| Step: 11
Training loss: 0.7872428894042969
Validation loss: 2.0074558506409326

Epoch: 82| Step: 0
Training loss: 1.8543789386749268
Validation loss: 2.000233009457588

Epoch: 5| Step: 1
Training loss: 2.0030112266540527
Validation loss: 1.9864640335241954

Epoch: 5| Step: 2
Training loss: 1.6307214498519897
Validation loss: 1.962118352452914

Epoch: 5| Step: 3
Training loss: 1.7739166021347046
Validation loss: 2.0467593570550284

Epoch: 5| Step: 4
Training loss: 1.6347720623016357
Validation loss: 2.019937500357628

Epoch: 5| Step: 5
Training loss: 1.7206408977508545
Validation loss: 2.0287305613358817

Epoch: 5| Step: 6
Training loss: 1.5543264150619507
Validation loss: 2.065082465608915

Epoch: 5| Step: 7
Training loss: 1.6294653415679932
Validation loss: 2.0969635248184204

Epoch: 5| Step: 8
Training loss: 1.2958494424819946
Validation loss: 2.052325591444969

Epoch: 5| Step: 9
Training loss: 1.569685459136963
Validation loss: 2.099262371659279

Epoch: 5| Step: 10
Training loss: 1.3351497650146484
Validation loss: 2.107875948150953

Epoch: 5| Step: 11
Training loss: 1.742220163345337
Validation loss: 2.0960915237665176

Epoch: 83| Step: 0
Training loss: 1.4599263668060303
Validation loss: 2.1007335782051086

Epoch: 5| Step: 1
Training loss: 1.1838325262069702
Validation loss: 2.0231598069270453

Epoch: 5| Step: 2
Training loss: 1.030987024307251
Validation loss: 1.9822093745072682

Epoch: 5| Step: 3
Training loss: 1.6559703350067139
Validation loss: 2.0124358981847763

Epoch: 5| Step: 4
Training loss: 2.1558334827423096
Validation loss: 2.0295435786247253

Epoch: 5| Step: 5
Training loss: 1.957360863685608
Validation loss: 1.9890929361184437

Epoch: 5| Step: 6
Training loss: 1.3476197719573975
Validation loss: 2.0479891349871955

Epoch: 5| Step: 7
Training loss: 1.6587260961532593
Validation loss: 2.0190067489941916

Epoch: 5| Step: 8
Training loss: 1.6471216678619385
Validation loss: 2.022900809844335

Epoch: 5| Step: 9
Training loss: 2.073629140853882
Validation loss: 2.0260314544041953

Epoch: 5| Step: 10
Training loss: 1.502917766571045
Validation loss: 1.961852600177129

Epoch: 5| Step: 11
Training loss: 2.3646838665008545
Validation loss: 2.013962725798289

Epoch: 84| Step: 0
Training loss: 1.5347602367401123
Validation loss: 2.1047328809897103

Epoch: 5| Step: 1
Training loss: 1.6228878498077393
Validation loss: 2.1359424044688544

Epoch: 5| Step: 2
Training loss: 1.5251357555389404
Validation loss: 2.1628151486317315

Epoch: 5| Step: 3
Training loss: 1.438012719154358
Validation loss: 2.2262450754642487

Epoch: 5| Step: 4
Training loss: 1.331561803817749
Validation loss: 2.2081843465566635

Epoch: 5| Step: 5
Training loss: 2.293182849884033
Validation loss: 2.18296746412913

Epoch: 5| Step: 6
Training loss: 1.1892921924591064
Validation loss: 2.091136405865351

Epoch: 5| Step: 7
Training loss: 1.7720019817352295
Validation loss: 2.103020121653875

Epoch: 5| Step: 8
Training loss: 1.5458871126174927
Validation loss: 2.096296191215515

Epoch: 5| Step: 9
Training loss: 1.5200268030166626
Validation loss: 1.9877832134564717

Epoch: 5| Step: 10
Training loss: 2.1798596382141113
Validation loss: 1.9828736235698063

Epoch: 5| Step: 11
Training loss: 0.5809582471847534
Validation loss: 1.979598527153333

Epoch: 85| Step: 0
Training loss: 2.138502597808838
Validation loss: 2.026852533221245

Epoch: 5| Step: 1
Training loss: 1.5204927921295166
Validation loss: 2.0485229839881263

Epoch: 5| Step: 2
Training loss: 0.9792307019233704
Validation loss: 2.012391895055771

Epoch: 5| Step: 3
Training loss: 1.6707429885864258
Validation loss: 2.0325280924638114

Epoch: 5| Step: 4
Training loss: 1.977890968322754
Validation loss: 2.007748772700628

Epoch: 5| Step: 5
Training loss: 1.5080947875976562
Validation loss: 1.9839382867018382

Epoch: 5| Step: 6
Training loss: 1.953603744506836
Validation loss: 1.9976254254579544

Epoch: 5| Step: 7
Training loss: 1.7328612804412842
Validation loss: 1.9608733355998993

Epoch: 5| Step: 8
Training loss: 1.2324994802474976
Validation loss: 2.0039686312278113

Epoch: 5| Step: 9
Training loss: 2.614595413208008
Validation loss: 2.0796996106704078

Epoch: 5| Step: 10
Training loss: 1.5152915716171265
Validation loss: 2.107308824857076

Epoch: 5| Step: 11
Training loss: 2.5675551891326904
Validation loss: 2.2060399105151496

Epoch: 86| Step: 0
Training loss: 2.0236833095550537
Validation loss: 2.1759087344010672

Epoch: 5| Step: 1
Training loss: 1.5717144012451172
Validation loss: 2.1910849263270697

Epoch: 5| Step: 2
Training loss: 1.8844486474990845
Validation loss: 2.145204116900762

Epoch: 5| Step: 3
Training loss: 1.3423876762390137
Validation loss: 2.1371250450611115

Epoch: 5| Step: 4
Training loss: 1.1258563995361328
Validation loss: 2.108457843462626

Epoch: 5| Step: 5
Training loss: 2.027179718017578
Validation loss: 2.006300081809362

Epoch: 5| Step: 6
Training loss: 1.208215355873108
Validation loss: 2.007574816544851

Epoch: 5| Step: 7
Training loss: 1.6720577478408813
Validation loss: 1.990396832426389

Epoch: 5| Step: 8
Training loss: 1.8638255596160889
Validation loss: 2.0019780546426773

Epoch: 5| Step: 9
Training loss: 2.05009388923645
Validation loss: 2.0078806231419244

Epoch: 5| Step: 10
Training loss: 1.4279919862747192
Validation loss: 1.9700563450654347

Epoch: 5| Step: 11
Training loss: 1.9143400192260742
Validation loss: 2.003247022628784

Epoch: 87| Step: 0
Training loss: 1.7073290348052979
Validation loss: 1.9374382843573887

Epoch: 5| Step: 1
Training loss: 1.5366544723510742
Validation loss: 2.012548347314199

Epoch: 5| Step: 2
Training loss: 1.5602363348007202
Validation loss: 1.9851996848980586

Epoch: 5| Step: 3
Training loss: 1.6742264032363892
Validation loss: 2.0282777547836304

Epoch: 5| Step: 4
Training loss: 1.2126930952072144
Validation loss: 2.065427248676618

Epoch: 5| Step: 5
Training loss: 1.570290446281433
Validation loss: 2.077207242449125

Epoch: 5| Step: 6
Training loss: 1.6392028331756592
Validation loss: 2.1462260435024896

Epoch: 5| Step: 7
Training loss: 2.1688568592071533
Validation loss: 2.105075274904569

Epoch: 5| Step: 8
Training loss: 2.3126275539398193
Validation loss: 2.08334348599116

Epoch: 5| Step: 9
Training loss: 1.3331793546676636
Validation loss: 2.044564818342527

Epoch: 5| Step: 10
Training loss: 1.2933225631713867
Validation loss: 2.0539308240016303

Epoch: 5| Step: 11
Training loss: 0.8877923488616943
Validation loss: 2.019395664334297

Epoch: 88| Step: 0
Training loss: 1.4668760299682617
Validation loss: 1.985994388659795

Epoch: 5| Step: 1
Training loss: 1.8232730627059937
Validation loss: 1.9935735116402309

Epoch: 5| Step: 2
Training loss: 1.8635095357894897
Validation loss: 1.9635234077771504

Epoch: 5| Step: 3
Training loss: 1.814101219177246
Validation loss: 1.965848907828331

Epoch: 5| Step: 4
Training loss: 1.5869783163070679
Validation loss: 1.9619223326444626

Epoch: 5| Step: 5
Training loss: 1.3328641653060913
Validation loss: 2.010051056742668

Epoch: 5| Step: 6
Training loss: 1.465624213218689
Validation loss: 1.990100383758545

Epoch: 5| Step: 7
Training loss: 1.7108824253082275
Validation loss: 1.9787953396638234

Epoch: 5| Step: 8
Training loss: 1.9118499755859375
Validation loss: 2.010371148586273

Epoch: 5| Step: 9
Training loss: 1.4175001382827759
Validation loss: 1.9887106517950695

Epoch: 5| Step: 10
Training loss: 1.3000173568725586
Validation loss: 2.050854886571566

Epoch: 5| Step: 11
Training loss: 0.517626166343689
Validation loss: 2.0521351993083954

Epoch: 89| Step: 0
Training loss: 1.5730472803115845
Validation loss: 2.0401185800631843

Epoch: 5| Step: 1
Training loss: 1.5347576141357422
Validation loss: 2.016786669691404

Epoch: 5| Step: 2
Training loss: 1.4187004566192627
Validation loss: 2.0364704777797065

Epoch: 5| Step: 3
Training loss: 1.3834925889968872
Validation loss: 2.0678425282239914

Epoch: 5| Step: 4
Training loss: 1.576874017715454
Validation loss: 2.00998754799366

Epoch: 5| Step: 5
Training loss: 1.6183973550796509
Validation loss: 1.9996654192606609

Epoch: 5| Step: 6
Training loss: 1.9654461145401
Validation loss: 2.019221464792887

Epoch: 5| Step: 7
Training loss: 1.348960280418396
Validation loss: 2.0527777125438056

Epoch: 5| Step: 8
Training loss: 1.5972172021865845
Validation loss: 2.0502832581599555

Epoch: 5| Step: 9
Training loss: 1.3110425472259521
Validation loss: 2.0187376836935678

Epoch: 5| Step: 10
Training loss: 1.9362140893936157
Validation loss: 2.0049780209859214

Epoch: 5| Step: 11
Training loss: 2.8219730854034424
Validation loss: 2.024447962641716

Epoch: 90| Step: 0
Training loss: 1.2494500875473022
Validation loss: 2.022825837135315

Epoch: 5| Step: 1
Training loss: 2.2705092430114746
Validation loss: 1.9921053101619084

Epoch: 5| Step: 2
Training loss: 1.5559805631637573
Validation loss: 2.0708949665228524

Epoch: 5| Step: 3
Training loss: 1.1928482055664062
Validation loss: 2.0337824722131095

Epoch: 5| Step: 4
Training loss: 2.142449378967285
Validation loss: 1.9868304133415222

Epoch: 5| Step: 5
Training loss: 1.1880792379379272
Validation loss: 2.0234144032001495

Epoch: 5| Step: 6
Training loss: 1.276386022567749
Validation loss: 2.048609972000122

Epoch: 5| Step: 7
Training loss: 1.561488389968872
Validation loss: 1.982649137576421

Epoch: 5| Step: 8
Training loss: 1.3738768100738525
Validation loss: 2.0189555088678994

Epoch: 5| Step: 9
Training loss: 1.6104965209960938
Validation loss: 2.0447867810726166

Epoch: 5| Step: 10
Training loss: 1.6330848932266235
Validation loss: 2.0835820585489273

Epoch: 5| Step: 11
Training loss: 1.841765284538269
Validation loss: 2.0027083108822503

Epoch: 91| Step: 0
Training loss: 1.7961070537567139
Validation loss: 2.090513860185941

Epoch: 5| Step: 1
Training loss: 0.9536895751953125
Validation loss: 2.0899755557378135

Epoch: 5| Step: 2
Training loss: 1.3346693515777588
Validation loss: 2.0193406492471695

Epoch: 5| Step: 3
Training loss: 1.3375797271728516
Validation loss: 2.034739837050438

Epoch: 5| Step: 4
Training loss: 1.8162858486175537
Validation loss: 2.0419612924257913

Epoch: 5| Step: 5
Training loss: 1.7864971160888672
Validation loss: 2.032949442664782

Epoch: 5| Step: 6
Training loss: 1.8068933486938477
Validation loss: 2.0103863179683685

Epoch: 5| Step: 7
Training loss: 1.3832828998565674
Validation loss: 2.0578076293071113

Epoch: 5| Step: 8
Training loss: 1.999932050704956
Validation loss: 2.0207854161659875

Epoch: 5| Step: 9
Training loss: 1.4966963529586792
Validation loss: 2.0554601152737937

Epoch: 5| Step: 10
Training loss: 1.4776815176010132
Validation loss: 1.9919729779163997

Epoch: 5| Step: 11
Training loss: 1.609810471534729
Validation loss: 2.006347378094991

Epoch: 92| Step: 0
Training loss: 1.0204765796661377
Validation loss: 2.0409837861855826

Epoch: 5| Step: 1
Training loss: 1.5950645208358765
Validation loss: 2.00265338520209

Epoch: 5| Step: 2
Training loss: 1.2144113779067993
Validation loss: 2.0497411688168845

Epoch: 5| Step: 3
Training loss: 1.9436256885528564
Validation loss: 2.0219026307264962

Epoch: 5| Step: 4
Training loss: 1.9200979471206665
Validation loss: 2.0439272026220956

Epoch: 5| Step: 5
Training loss: 1.4619567394256592
Validation loss: 2.0464607030153275

Epoch: 5| Step: 6
Training loss: 1.2085052728652954
Validation loss: 2.083517293135325

Epoch: 5| Step: 7
Training loss: 1.9293415546417236
Validation loss: 2.050553247332573

Epoch: 5| Step: 8
Training loss: 1.6944873332977295
Validation loss: 2.1025746713081994

Epoch: 5| Step: 9
Training loss: 1.4135743379592896
Validation loss: 2.06062783797582

Epoch: 5| Step: 10
Training loss: 1.5297844409942627
Validation loss: 2.101754918694496

Epoch: 5| Step: 11
Training loss: 1.9618648290634155
Validation loss: 2.0927650034427643

Epoch: 93| Step: 0
Training loss: 1.9257495403289795
Validation loss: 2.0160918682813644

Epoch: 5| Step: 1
Training loss: 1.7426351308822632
Validation loss: 1.997758095463117

Epoch: 5| Step: 2
Training loss: 2.2462430000305176
Validation loss: 2.0178233236074448

Epoch: 5| Step: 3
Training loss: 1.7567780017852783
Validation loss: 1.9877618253231049

Epoch: 5| Step: 4
Training loss: 1.795464277267456
Validation loss: 2.030217374364535

Epoch: 5| Step: 5
Training loss: 1.5890015363693237
Validation loss: 2.0329176088174186

Epoch: 5| Step: 6
Training loss: 1.7787342071533203
Validation loss: 1.9905858387549717

Epoch: 5| Step: 7
Training loss: 1.4414820671081543
Validation loss: 2.0330092857281366

Epoch: 5| Step: 8
Training loss: 1.488600254058838
Validation loss: 1.994598239660263

Epoch: 5| Step: 9
Training loss: 1.4643895626068115
Validation loss: 2.084692736466726

Epoch: 5| Step: 10
Training loss: 1.2969719171524048
Validation loss: 2.1014561156431832

Epoch: 5| Step: 11
Training loss: 0.5074228048324585
Validation loss: 2.170422742764155

Epoch: 94| Step: 0
Training loss: 1.2266103029251099
Validation loss: 2.0903556694587073

Epoch: 5| Step: 1
Training loss: 1.7805824279785156
Validation loss: 2.0840737372636795

Epoch: 5| Step: 2
Training loss: 1.9256012439727783
Validation loss: 2.0529953986406326

Epoch: 5| Step: 3
Training loss: 1.9497816562652588
Validation loss: 2.0565816263357797

Epoch: 5| Step: 4
Training loss: 1.8231594562530518
Validation loss: 2.0381754686435065

Epoch: 5| Step: 5
Training loss: 1.4389111995697021
Validation loss: 1.995685448249181

Epoch: 5| Step: 6
Training loss: 1.4940706491470337
Validation loss: 2.016622950633367

Epoch: 5| Step: 7
Training loss: 1.0765578746795654
Validation loss: 2.000725199778875

Epoch: 5| Step: 8
Training loss: 1.615136742591858
Validation loss: 2.0279305477937064

Epoch: 5| Step: 9
Training loss: 1.413903832435608
Validation loss: 1.988315264383952

Epoch: 5| Step: 10
Training loss: 1.415489912033081
Validation loss: 2.0337504098812738

Epoch: 5| Step: 11
Training loss: 0.5484973788261414
Validation loss: 2.037342290083567

Epoch: 95| Step: 0
Training loss: 1.2288001775741577
Validation loss: 2.0383220265309014

Epoch: 5| Step: 1
Training loss: 0.965164840221405
Validation loss: 2.047966092824936

Epoch: 5| Step: 2
Training loss: 1.3708631992340088
Validation loss: 2.071154202024142

Epoch: 5| Step: 3
Training loss: 1.7390085458755493
Validation loss: 2.118706757823626

Epoch: 5| Step: 4
Training loss: 1.5610498189926147
Validation loss: 2.1256212989489236

Epoch: 5| Step: 5
Training loss: 1.31553053855896
Validation loss: 2.0925783763329187

Epoch: 5| Step: 6
Training loss: 1.901320219039917
Validation loss: 2.1656889021396637

Epoch: 5| Step: 7
Training loss: 1.9998500347137451
Validation loss: 2.105943118532499

Epoch: 5| Step: 8
Training loss: 2.102154493331909
Validation loss: 2.0267234444618225

Epoch: 5| Step: 9
Training loss: 0.9828144907951355
Validation loss: 1.9995512713988621

Epoch: 5| Step: 10
Training loss: 1.7126853466033936
Validation loss: 1.9805912921826045

Epoch: 5| Step: 11
Training loss: 0.3902972936630249
Validation loss: 1.9997835805018742

Epoch: 96| Step: 0
Training loss: 1.199009656906128
Validation loss: 2.0190769334634147

Epoch: 5| Step: 1
Training loss: 2.0059213638305664
Validation loss: 1.9944500476121902

Epoch: 5| Step: 2
Training loss: 1.9203441143035889
Validation loss: 1.9953083942333858

Epoch: 5| Step: 3
Training loss: 1.3902305364608765
Validation loss: 2.0260185996691384

Epoch: 5| Step: 4
Training loss: 1.1461818218231201
Validation loss: 2.0182001342376075

Epoch: 5| Step: 5
Training loss: 1.908172845840454
Validation loss: 2.043877383073171

Epoch: 5| Step: 6
Training loss: 1.772274374961853
Validation loss: 2.0243503401676812

Epoch: 5| Step: 7
Training loss: 1.1114202737808228
Validation loss: 2.0754317740599313

Epoch: 5| Step: 8
Training loss: 1.5868151187896729
Validation loss: 2.0748573392629623

Epoch: 5| Step: 9
Training loss: 2.124528408050537
Validation loss: 2.116790677110354

Epoch: 5| Step: 10
Training loss: 1.316392183303833
Validation loss: 2.1823867658774057

Epoch: 5| Step: 11
Training loss: 2.0177056789398193
Validation loss: 2.1561406552791595

Epoch: 97| Step: 0
Training loss: 1.4349708557128906
Validation loss: 2.082044487198194

Epoch: 5| Step: 1
Training loss: 1.0366156101226807
Validation loss: 2.019502932826678

Epoch: 5| Step: 2
Training loss: 1.6244910955429077
Validation loss: 2.0659572978814444

Epoch: 5| Step: 3
Training loss: 1.258183240890503
Validation loss: 2.019129494825999

Epoch: 5| Step: 4
Training loss: 1.602181077003479
Validation loss: 1.9987457742293675

Epoch: 5| Step: 5
Training loss: 1.6661638021469116
Validation loss: 2.0231404900550842

Epoch: 5| Step: 6
Training loss: 1.249976396560669
Validation loss: 2.0078670531511307

Epoch: 5| Step: 7
Training loss: 2.1596226692199707
Validation loss: 2.0339489032824836

Epoch: 5| Step: 8
Training loss: 1.4910252094268799
Validation loss: 2.046233907341957

Epoch: 5| Step: 9
Training loss: 1.6580836772918701
Validation loss: 2.0386333564917245

Epoch: 5| Step: 10
Training loss: 2.093337059020996
Validation loss: 2.072941536704699

Epoch: 5| Step: 11
Training loss: 2.3020806312561035
Validation loss: 2.113238051533699

Epoch: 98| Step: 0
Training loss: 1.1275172233581543
Validation loss: 2.0899808555841446

Epoch: 5| Step: 1
Training loss: 1.759766936302185
Validation loss: 2.1365008453528085

Epoch: 5| Step: 2
Training loss: 2.3577723503112793
Validation loss: 2.123280664285024

Epoch: 5| Step: 3
Training loss: 1.3470938205718994
Validation loss: 2.1077139725287757

Epoch: 5| Step: 4
Training loss: 1.395855188369751
Validation loss: 2.111080894867579

Epoch: 5| Step: 5
Training loss: 1.3272674083709717
Validation loss: 2.111992617448171

Epoch: 5| Step: 6
Training loss: 1.403220772743225
Validation loss: 2.0406503478686013

Epoch: 5| Step: 7
Training loss: 1.4133222103118896
Validation loss: 2.035357798139254

Epoch: 5| Step: 8
Training loss: 1.3917185068130493
Validation loss: 2.0294133126735687

Epoch: 5| Step: 9
Training loss: 1.7814209461212158
Validation loss: 2.0203082263469696

Epoch: 5| Step: 10
Training loss: 1.435258388519287
Validation loss: 1.9850882142782211

Epoch: 5| Step: 11
Training loss: 1.3419737815856934
Validation loss: 1.9864272971947987

Epoch: 99| Step: 0
Training loss: 1.5938808917999268
Validation loss: 2.0654054482777915

Epoch: 5| Step: 1
Training loss: 1.630875825881958
Validation loss: 2.07329132159551

Epoch: 5| Step: 2
Training loss: 1.442673921585083
Validation loss: 2.048706670602163

Epoch: 5| Step: 3
Training loss: 1.8045650720596313
Validation loss: 2.112168858448664

Epoch: 5| Step: 4
Training loss: 1.4584949016571045
Validation loss: 2.116361270348231

Epoch: 5| Step: 5
Training loss: 1.369581937789917
Validation loss: 2.075314223766327

Epoch: 5| Step: 6
Training loss: 2.2136154174804688
Validation loss: 2.0786481300989785

Epoch: 5| Step: 7
Training loss: 1.0869979858398438
Validation loss: 2.034451276063919

Epoch: 5| Step: 8
Training loss: 1.3755831718444824
Validation loss: 2.0333581417798996

Epoch: 5| Step: 9
Training loss: 1.3824294805526733
Validation loss: 2.011623149116834

Epoch: 5| Step: 10
Training loss: 1.3854161500930786
Validation loss: 2.0086672256390252

Epoch: 5| Step: 11
Training loss: 2.1568126678466797
Validation loss: 1.9827164113521576

Epoch: 100| Step: 0
Training loss: 1.9932568073272705
Validation loss: 2.0364265541235604

Epoch: 5| Step: 1
Training loss: 1.4003267288208008
Validation loss: 2.06726643939813

Epoch: 5| Step: 2
Training loss: 1.583702802658081
Validation loss: 2.072912489374479

Epoch: 5| Step: 3
Training loss: 1.4427385330200195
Validation loss: 2.0649480521678925

Epoch: 5| Step: 4
Training loss: 1.1518086194992065
Validation loss: 2.0739244520664215

Epoch: 5| Step: 5
Training loss: 1.7218917608261108
Validation loss: 2.0607363482316337

Epoch: 5| Step: 6
Training loss: 1.4515354633331299
Validation loss: 2.0513642728328705

Epoch: 5| Step: 7
Training loss: 1.6764981746673584
Validation loss: 2.034220188856125

Epoch: 5| Step: 8
Training loss: 0.9049989581108093
Validation loss: 2.0428892026344934

Epoch: 5| Step: 9
Training loss: 1.168864130973816
Validation loss: 1.989182968934377

Epoch: 5| Step: 10
Training loss: 1.6887481212615967
Validation loss: 2.0213738133509955

Epoch: 5| Step: 11
Training loss: 1.4551048278808594
Validation loss: 2.026039441426595

Epoch: 101| Step: 0
Training loss: 0.9932066202163696
Validation loss: 2.05220036705335

Epoch: 5| Step: 1
Training loss: 1.8560727834701538
Validation loss: 2.010911598801613

Epoch: 5| Step: 2
Training loss: 1.994468092918396
Validation loss: 2.022024775544802

Epoch: 5| Step: 3
Training loss: 0.9665699005126953
Validation loss: 2.0399147272109985

Epoch: 5| Step: 4
Training loss: 0.988254189491272
Validation loss: 2.0010765194892883

Epoch: 5| Step: 5
Training loss: 0.9343727827072144
Validation loss: 2.0577754080295563

Epoch: 5| Step: 6
Training loss: 1.5964634418487549
Validation loss: 2.010780160625776

Epoch: 5| Step: 7
Training loss: 1.7843122482299805
Validation loss: 2.091160664955775

Epoch: 5| Step: 8
Training loss: 2.0307774543762207
Validation loss: 2.0534039735794067

Epoch: 5| Step: 9
Training loss: 1.566857099533081
Validation loss: 2.04273222386837

Epoch: 5| Step: 10
Training loss: 1.5348402261734009
Validation loss: 2.0462995767593384

Epoch: 5| Step: 11
Training loss: 0.49817728996276855
Validation loss: 2.0361148516337075

Epoch: 102| Step: 0
Training loss: 1.5199146270751953
Validation loss: 2.028756618499756

Epoch: 5| Step: 1
Training loss: 1.1241165399551392
Validation loss: 2.0506089677413306

Epoch: 5| Step: 2
Training loss: 1.6581592559814453
Validation loss: 2.0777675112088523

Epoch: 5| Step: 3
Training loss: 1.2438634634017944
Validation loss: 2.0864820033311844

Epoch: 5| Step: 4
Training loss: 1.2766852378845215
Validation loss: 2.0674293835957847

Epoch: 5| Step: 5
Training loss: 1.582622766494751
Validation loss: 2.028743882973989

Epoch: 5| Step: 6
Training loss: 1.615064263343811
Validation loss: 2.0638731867074966

Epoch: 5| Step: 7
Training loss: 1.1842985153198242
Validation loss: 2.1006685694058738

Epoch: 5| Step: 8
Training loss: 1.6498289108276367
Validation loss: 2.0612983852624893

Epoch: 5| Step: 9
Training loss: 1.1676783561706543
Validation loss: 2.064729983607928

Epoch: 5| Step: 10
Training loss: 1.7891696691513062
Validation loss: 1.989769885937373

Epoch: 5| Step: 11
Training loss: 1.4693424701690674
Validation loss: 2.0346584022045135

Epoch: 103| Step: 0
Training loss: 1.6279222965240479
Validation loss: 1.9752810696760814

Epoch: 5| Step: 1
Training loss: 1.5457839965820312
Validation loss: 2.0186187426249185

Epoch: 5| Step: 2
Training loss: 1.7970073223114014
Validation loss: 2.0292102793852487

Epoch: 5| Step: 3
Training loss: 1.3548988103866577
Validation loss: 1.9874801834424336

Epoch: 5| Step: 4
Training loss: 1.2249583005905151
Validation loss: 2.044581929842631

Epoch: 5| Step: 5
Training loss: 0.9074112176895142
Validation loss: 2.0006943146387735

Epoch: 5| Step: 6
Training loss: 1.4520944356918335
Validation loss: 2.04971049229304

Epoch: 5| Step: 7
Training loss: 1.4504172801971436
Validation loss: 2.047947953144709

Epoch: 5| Step: 8
Training loss: 1.7207162380218506
Validation loss: 2.042264550924301

Epoch: 5| Step: 9
Training loss: 1.2418633699417114
Validation loss: 2.003739759325981

Epoch: 5| Step: 10
Training loss: 1.4797823429107666
Validation loss: 2.0914513866106668

Epoch: 5| Step: 11
Training loss: 0.8077794313430786
Validation loss: 2.11248413225015

Epoch: 104| Step: 0
Training loss: 1.1153913736343384
Validation loss: 2.1564105649789176

Epoch: 5| Step: 1
Training loss: 1.5574266910552979
Validation loss: 2.047417794664701

Epoch: 5| Step: 2
Training loss: 1.717458963394165
Validation loss: 2.0825569530328116

Epoch: 5| Step: 3
Training loss: 1.1132034063339233
Validation loss: 2.101876159509023

Epoch: 5| Step: 4
Training loss: 1.5959712266921997
Validation loss: 2.0582463393608728

Epoch: 5| Step: 5
Training loss: 1.1330114603042603
Validation loss: 2.0239075422286987

Epoch: 5| Step: 6
Training loss: 1.4646211862564087
Validation loss: 2.0426835119724274

Epoch: 5| Step: 7
Training loss: 1.2016650438308716
Validation loss: 1.9934483865896861

Epoch: 5| Step: 8
Training loss: 1.1927779912948608
Validation loss: 2.0444600333770118

Epoch: 5| Step: 9
Training loss: 1.3391151428222656
Validation loss: 2.036794309814771

Epoch: 5| Step: 10
Training loss: 1.7227375507354736
Validation loss: 2.050425092379252

Epoch: 5| Step: 11
Training loss: 2.012826442718506
Validation loss: 2.0350716412067413

Epoch: 105| Step: 0
Training loss: 1.3080737590789795
Validation loss: 2.0033943355083466

Epoch: 5| Step: 1
Training loss: 1.2423484325408936
Validation loss: 2.08253205815951

Epoch: 5| Step: 2
Training loss: 1.5518250465393066
Validation loss: 2.078575298190117

Epoch: 5| Step: 3
Training loss: 1.2825372219085693
Validation loss: 2.080512990554174

Epoch: 5| Step: 4
Training loss: 1.5757793188095093
Validation loss: 2.0915362437566123

Epoch: 5| Step: 5
Training loss: 1.565591812133789
Validation loss: 2.0479955772558847

Epoch: 5| Step: 6
Training loss: 1.741598129272461
Validation loss: 2.0496176977952323

Epoch: 5| Step: 7
Training loss: 1.9107704162597656
Validation loss: 2.086379533012708

Epoch: 5| Step: 8
Training loss: 1.1023898124694824
Validation loss: 2.0493015348911285

Epoch: 5| Step: 9
Training loss: 1.0557693243026733
Validation loss: 2.003744343916575

Epoch: 5| Step: 10
Training loss: 1.3245952129364014
Validation loss: 2.0313994586467743

Epoch: 5| Step: 11
Training loss: 1.3669230937957764
Validation loss: 2.0472622911135354

Epoch: 106| Step: 0
Training loss: 1.6095387935638428
Validation loss: 2.0215444564819336

Epoch: 5| Step: 1
Training loss: 1.4499750137329102
Validation loss: 1.981170266866684

Epoch: 5| Step: 2
Training loss: 1.4611424207687378
Validation loss: 2.020990788936615

Epoch: 5| Step: 3
Training loss: 1.133492112159729
Validation loss: 2.090282370646795

Epoch: 5| Step: 4
Training loss: 1.7882850170135498
Validation loss: 2.0275074938933053

Epoch: 5| Step: 5
Training loss: 1.379392385482788
Validation loss: 2.071365311741829

Epoch: 5| Step: 6
Training loss: 1.3692271709442139
Validation loss: 2.081659788886706

Epoch: 5| Step: 7
Training loss: 1.1005141735076904
Validation loss: 2.148874655365944

Epoch: 5| Step: 8
Training loss: 1.3963981866836548
Validation loss: 2.0950704216957092

Epoch: 5| Step: 9
Training loss: 1.3503215312957764
Validation loss: 2.1049956927696862

Epoch: 5| Step: 10
Training loss: 1.9477252960205078
Validation loss: 2.0514056235551834

Epoch: 5| Step: 11
Training loss: 0.6623391509056091
Validation loss: 1.999195431669553

Epoch: 107| Step: 0
Training loss: 1.0216501951217651
Validation loss: 2.008273462454478

Epoch: 5| Step: 1
Training loss: 1.3777384757995605
Validation loss: 2.043589477737745

Epoch: 5| Step: 2
Training loss: 1.085046410560608
Validation loss: 2.0454739530881247

Epoch: 5| Step: 3
Training loss: 1.3924853801727295
Validation loss: 2.0643932819366455

Epoch: 5| Step: 4
Training loss: 1.9354861974716187
Validation loss: 2.0348458935817084

Epoch: 5| Step: 5
Training loss: 1.0439122915267944
Validation loss: 2.0903659562269845

Epoch: 5| Step: 6
Training loss: 1.3833240270614624
Validation loss: 2.090913106997808

Epoch: 5| Step: 7
Training loss: 1.8859806060791016
Validation loss: 2.0230273753404617

Epoch: 5| Step: 8
Training loss: 1.4216073751449585
Validation loss: 2.051753416657448

Epoch: 5| Step: 9
Training loss: 1.1817184686660767
Validation loss: 2.020680000384649

Epoch: 5| Step: 10
Training loss: 1.3698617219924927
Validation loss: 2.0709509601195655

Epoch: 5| Step: 11
Training loss: 2.8335466384887695
Validation loss: 2.0617500245571136

Epoch: 108| Step: 0
Training loss: 1.9451277256011963
Validation loss: 2.0012540568908057

Epoch: 5| Step: 1
Training loss: 0.8629374504089355
Validation loss: 1.9908225188652675

Epoch: 5| Step: 2
Training loss: 1.5041732788085938
Validation loss: 1.979604423046112

Epoch: 5| Step: 3
Training loss: 1.7045599222183228
Validation loss: 2.0751285602649054

Epoch: 5| Step: 4
Training loss: 1.1625337600708008
Validation loss: 2.0366563300291696

Epoch: 5| Step: 5
Training loss: 1.2562551498413086
Validation loss: 2.0736780067284903

Epoch: 5| Step: 6
Training loss: 0.9780021905899048
Validation loss: 2.0985966126124063

Epoch: 5| Step: 7
Training loss: 1.8034923076629639
Validation loss: 2.13218259314696

Epoch: 5| Step: 8
Training loss: 2.1193184852600098
Validation loss: 2.125623727838198

Epoch: 5| Step: 9
Training loss: 1.4223419427871704
Validation loss: 2.076620946327845

Epoch: 5| Step: 10
Training loss: 1.0999497175216675
Validation loss: 2.052470693985621

Epoch: 5| Step: 11
Training loss: 1.0388014316558838
Validation loss: 2.088140085339546

Epoch: 109| Step: 0
Training loss: 1.0747339725494385
Validation loss: 2.020009661714236

Epoch: 5| Step: 1
Training loss: 1.675384521484375
Validation loss: 2.030461053053538

Epoch: 5| Step: 2
Training loss: 1.1829025745391846
Validation loss: 2.0407742659250894

Epoch: 5| Step: 3
Training loss: 1.5530025959014893
Validation loss: 2.039464478691419

Epoch: 5| Step: 4
Training loss: 1.9003608226776123
Validation loss: 2.0679149279991784

Epoch: 5| Step: 5
Training loss: 1.0814790725708008
Validation loss: 2.077713966369629

Epoch: 5| Step: 6
Training loss: 1.3434088230133057
Validation loss: 2.1280072033405304

Epoch: 5| Step: 7
Training loss: 2.0473132133483887
Validation loss: 2.133835027615229

Epoch: 5| Step: 8
Training loss: 1.1792376041412354
Validation loss: 2.1437879701455436

Epoch: 5| Step: 9
Training loss: 1.3222535848617554
Validation loss: 2.122519244750341

Epoch: 5| Step: 10
Training loss: 1.2232991456985474
Validation loss: 2.083899309237798

Epoch: 5| Step: 11
Training loss: 2.3415160179138184
Validation loss: 2.0738423615694046

Epoch: 110| Step: 0
Training loss: 1.2778910398483276
Validation loss: 2.0314874748388925

Epoch: 5| Step: 1
Training loss: 1.6355228424072266
Validation loss: 2.0169573426246643

Epoch: 5| Step: 2
Training loss: 1.6472461223602295
Validation loss: 2.058644006649653

Epoch: 5| Step: 3
Training loss: 1.606388807296753
Validation loss: 2.0042093793551126

Epoch: 5| Step: 4
Training loss: 1.2589714527130127
Validation loss: 2.0622628480196

Epoch: 5| Step: 5
Training loss: 1.1036840677261353
Validation loss: 2.029311711589495

Epoch: 5| Step: 6
Training loss: 1.920069932937622
Validation loss: 2.0251230796178183

Epoch: 5| Step: 7
Training loss: 2.0195517539978027
Validation loss: 2.069283882776896

Epoch: 5| Step: 8
Training loss: 0.952105700969696
Validation loss: 2.0928097466627755

Epoch: 5| Step: 9
Training loss: 1.26719069480896
Validation loss: 2.1122895777225494

Epoch: 5| Step: 10
Training loss: 1.2716333866119385
Validation loss: 2.149534692366918

Epoch: 5| Step: 11
Training loss: 1.372414469718933
Validation loss: 2.131193811694781

Epoch: 111| Step: 0
Training loss: 1.494547724723816
Validation loss: 2.1346158186594644

Epoch: 5| Step: 1
Training loss: 1.2252475023269653
Validation loss: 2.144571195046107

Epoch: 5| Step: 2
Training loss: 1.2238765954971313
Validation loss: 2.108387380838394

Epoch: 5| Step: 3
Training loss: 1.2829644680023193
Validation loss: 2.064611410101255

Epoch: 5| Step: 4
Training loss: 1.7104213237762451
Validation loss: 2.072361687819163

Epoch: 5| Step: 5
Training loss: 1.228743314743042
Validation loss: 2.081195652484894

Epoch: 5| Step: 6
Training loss: 1.4741677045822144
Validation loss: 2.0124089419841766

Epoch: 5| Step: 7
Training loss: 1.5748519897460938
Validation loss: 1.9975580076376598

Epoch: 5| Step: 8
Training loss: 1.7586787939071655
Validation loss: 1.9850259025891621

Epoch: 5| Step: 9
Training loss: 1.2828668355941772
Validation loss: 2.005156879623731

Epoch: 5| Step: 10
Training loss: 1.0908759832382202
Validation loss: 2.0913942654927573

Epoch: 5| Step: 11
Training loss: 1.8043384552001953
Validation loss: 2.012237067023913

Epoch: 112| Step: 0
Training loss: 1.5235437154769897
Validation loss: 2.0459047804276147

Epoch: 5| Step: 1
Training loss: 1.383979320526123
Validation loss: 2.0946154594421387

Epoch: 5| Step: 2
Training loss: 1.2637466192245483
Validation loss: 2.164973497390747

Epoch: 5| Step: 3
Training loss: 1.9543781280517578
Validation loss: 2.271942933400472

Epoch: 5| Step: 4
Training loss: 1.8429062366485596
Validation loss: 2.28317092359066

Epoch: 5| Step: 5
Training loss: 1.6861457824707031
Validation loss: 2.271145537495613

Epoch: 5| Step: 6
Training loss: 1.0447641611099243
Validation loss: 2.1454903980096183

Epoch: 5| Step: 7
Training loss: 1.2605072259902954
Validation loss: 2.149259631832441

Epoch: 5| Step: 8
Training loss: 1.630063772201538
Validation loss: 1.9809780567884445

Epoch: 5| Step: 9
Training loss: 1.116442084312439
Validation loss: 2.024443492293358

Epoch: 5| Step: 10
Training loss: 1.7384361028671265
Validation loss: 1.9826071957747142

Epoch: 5| Step: 11
Training loss: 1.7308013439178467
Validation loss: 2.0087281316518784

Epoch: 113| Step: 0
Training loss: 1.6916946172714233
Validation loss: 2.0294495026270547

Epoch: 5| Step: 1
Training loss: 1.4066826105117798
Validation loss: 2.046232913931211

Epoch: 5| Step: 2
Training loss: 1.5702028274536133
Validation loss: 2.00236114859581

Epoch: 5| Step: 3
Training loss: 1.1081544160842896
Validation loss: 2.0140694628159204

Epoch: 5| Step: 4
Training loss: 1.6071596145629883
Validation loss: 2.031795620918274

Epoch: 5| Step: 5
Training loss: 1.4750877618789673
Validation loss: 2.0909318029880524

Epoch: 5| Step: 6
Training loss: 1.2972809076309204
Validation loss: 2.090993752082189

Epoch: 5| Step: 7
Training loss: 1.7697570323944092
Validation loss: 2.152631625533104

Epoch: 5| Step: 8
Training loss: 0.7991951704025269
Validation loss: 2.149084687232971

Epoch: 5| Step: 9
Training loss: 1.2281908988952637
Validation loss: 2.176198502381643

Epoch: 5| Step: 10
Training loss: 1.9751449823379517
Validation loss: 2.150049860278765

Epoch: 5| Step: 11
Training loss: 1.3966058492660522
Validation loss: 2.134898826479912

Epoch: 114| Step: 0
Training loss: 1.5634076595306396
Validation loss: 2.0831775118907294

Epoch: 5| Step: 1
Training loss: 1.0382709503173828
Validation loss: 2.0610218544801078

Epoch: 5| Step: 2
Training loss: 1.6405271291732788
Validation loss: 2.040503114461899

Epoch: 5| Step: 3
Training loss: 1.9917961359024048
Validation loss: 2.0729472835858664

Epoch: 5| Step: 4
Training loss: 1.3149229288101196
Validation loss: 2.0287576665480933

Epoch: 5| Step: 5
Training loss: 1.1758853197097778
Validation loss: 1.995690996448199

Epoch: 5| Step: 6
Training loss: 1.1368603706359863
Validation loss: 1.9845917423566182

Epoch: 5| Step: 7
Training loss: 1.3269858360290527
Validation loss: 2.0104415665070214

Epoch: 5| Step: 8
Training loss: 1.3525387048721313
Validation loss: 2.045943001906077

Epoch: 5| Step: 9
Training loss: 1.385091781616211
Validation loss: 2.0361938923597336

Epoch: 5| Step: 10
Training loss: 1.1028826236724854
Validation loss: 2.078807214895884

Epoch: 5| Step: 11
Training loss: 1.3920032978057861
Validation loss: 1.9782220373551052

Epoch: 115| Step: 0
Training loss: 0.8470059633255005
Validation loss: 2.0492489685614905

Epoch: 5| Step: 1
Training loss: 1.021170973777771
Validation loss: 2.048192098736763

Epoch: 5| Step: 2
Training loss: 1.2279393672943115
Validation loss: 2.0566244473059974

Epoch: 5| Step: 3
Training loss: 1.4752347469329834
Validation loss: 2.0322570502758026

Epoch: 5| Step: 4
Training loss: 1.6703914403915405
Validation loss: 2.030543401837349

Epoch: 5| Step: 5
Training loss: 1.2632875442504883
Validation loss: 2.0325016180674234

Epoch: 5| Step: 6
Training loss: 1.2951807975769043
Validation loss: 2.044801334540049

Epoch: 5| Step: 7
Training loss: 1.4059441089630127
Validation loss: 2.0929286231597266

Epoch: 5| Step: 8
Training loss: 1.4611517190933228
Validation loss: 2.1088607062896094

Epoch: 5| Step: 9
Training loss: 1.6763126850128174
Validation loss: 2.0687182645003

Epoch: 5| Step: 10
Training loss: 1.339482307434082
Validation loss: 2.1021847824255624

Epoch: 5| Step: 11
Training loss: 1.0235203504562378
Validation loss: 2.07018252213796

Epoch: 116| Step: 0
Training loss: 1.0563390254974365
Validation loss: 2.0572875291109085

Epoch: 5| Step: 1
Training loss: 1.8488019704818726
Validation loss: 2.047831137975057

Epoch: 5| Step: 2
Training loss: 0.9726360440254211
Validation loss: 2.053898185491562

Epoch: 5| Step: 3
Training loss: 1.3649133443832397
Validation loss: 2.03147945801417

Epoch: 5| Step: 4
Training loss: 1.2978153228759766
Validation loss: 2.0291435023148856

Epoch: 5| Step: 5
Training loss: 1.4201841354370117
Validation loss: 2.038898785909017

Epoch: 5| Step: 6
Training loss: 1.4669221639633179
Validation loss: 2.04706579943498

Epoch: 5| Step: 7
Training loss: 1.0379537343978882
Validation loss: 2.032204811771711

Epoch: 5| Step: 8
Training loss: 1.237322211265564
Validation loss: 2.0569917211929956

Epoch: 5| Step: 9
Training loss: 1.4807196855545044
Validation loss: 2.0617731561263404

Epoch: 5| Step: 10
Training loss: 1.3478829860687256
Validation loss: 2.1577181220054626

Epoch: 5| Step: 11
Training loss: 1.0016173124313354
Validation loss: 2.1152741511662803

Epoch: 117| Step: 0
Training loss: 1.7104671001434326
Validation loss: 2.1588000605503717

Epoch: 5| Step: 1
Training loss: 1.1895745992660522
Validation loss: 2.1156278252601624

Epoch: 5| Step: 2
Training loss: 1.0728557109832764
Validation loss: 2.1455093920230865

Epoch: 5| Step: 3
Training loss: 1.3807861804962158
Validation loss: 2.1065243085225425

Epoch: 5| Step: 4
Training loss: 1.3976457118988037
Validation loss: 2.066708197196325

Epoch: 5| Step: 5
Training loss: 1.5107898712158203
Validation loss: 2.0468110144138336

Epoch: 5| Step: 6
Training loss: 1.2056373357772827
Validation loss: 2.055884207288424

Epoch: 5| Step: 7
Training loss: 0.9306687116622925
Validation loss: 2.066565910975138

Epoch: 5| Step: 8
Training loss: 1.0679903030395508
Validation loss: 2.095783938964208

Epoch: 5| Step: 9
Training loss: 1.3770819902420044
Validation loss: 2.106376528739929

Epoch: 5| Step: 10
Training loss: 1.8059543371200562
Validation loss: 2.04425773024559

Epoch: 5| Step: 11
Training loss: 0.9739216566085815
Validation loss: 2.06393730143706

Epoch: 118| Step: 0
Training loss: 0.6872752904891968
Validation loss: 2.028792535265287

Epoch: 5| Step: 1
Training loss: 1.4812493324279785
Validation loss: 2.0926315933465958

Epoch: 5| Step: 2
Training loss: 1.1842787265777588
Validation loss: 2.090038706858953

Epoch: 5| Step: 3
Training loss: 2.009909152984619
Validation loss: 2.072308594981829

Epoch: 5| Step: 4
Training loss: 1.1563968658447266
Validation loss: 2.047759806116422

Epoch: 5| Step: 5
Training loss: 1.5509634017944336
Validation loss: 2.078956206639608

Epoch: 5| Step: 6
Training loss: 1.0552374124526978
Validation loss: 2.064570799469948

Epoch: 5| Step: 7
Training loss: 1.0915849208831787
Validation loss: 2.055034706989924

Epoch: 5| Step: 8
Training loss: 0.801395058631897
Validation loss: 2.1092014412085214

Epoch: 5| Step: 9
Training loss: 1.682483434677124
Validation loss: 2.1060748298962912

Epoch: 5| Step: 10
Training loss: 1.4723174571990967
Validation loss: 2.1196979880332947

Epoch: 5| Step: 11
Training loss: 0.8373895883560181
Validation loss: 2.063514863451322

Epoch: 119| Step: 0
Training loss: 1.3399795293807983
Validation loss: 2.0758476008971534

Epoch: 5| Step: 1
Training loss: 1.6355974674224854
Validation loss: 2.049431120355924

Epoch: 5| Step: 2
Training loss: 1.586035966873169
Validation loss: 2.052924702564875

Epoch: 5| Step: 3
Training loss: 1.4730366468429565
Validation loss: 2.059660881757736

Epoch: 5| Step: 4
Training loss: 0.9197921752929688
Validation loss: 2.0157500207424164

Epoch: 5| Step: 5
Training loss: 1.485971212387085
Validation loss: 2.03392264743646

Epoch: 5| Step: 6
Training loss: 1.6408004760742188
Validation loss: 2.0527659753958383

Epoch: 5| Step: 7
Training loss: 0.9394937753677368
Validation loss: 2.0693069994449615

Epoch: 5| Step: 8
Training loss: 1.0057317018508911
Validation loss: 2.064361353715261

Epoch: 5| Step: 9
Training loss: 1.277414321899414
Validation loss: 2.0774490584929786

Epoch: 5| Step: 10
Training loss: 0.934546172618866
Validation loss: 2.089200422167778

Epoch: 5| Step: 11
Training loss: 1.76776921749115
Validation loss: 2.087309514482816

Epoch: 120| Step: 0
Training loss: 1.6960992813110352
Validation loss: 2.00571870803833

Epoch: 5| Step: 1
Training loss: 1.6784931421279907
Validation loss: 2.037716602285703

Epoch: 5| Step: 2
Training loss: 1.167072057723999
Validation loss: 2.053946793079376

Epoch: 5| Step: 3
Training loss: 1.0895178318023682
Validation loss: 2.0578545232613883

Epoch: 5| Step: 4
Training loss: 1.6130220890045166
Validation loss: 2.076326141754786

Epoch: 5| Step: 5
Training loss: 1.0133192539215088
Validation loss: 2.0528034617503486

Epoch: 5| Step: 6
Training loss: 1.0160844326019287
Validation loss: 2.004053846001625

Epoch: 5| Step: 7
Training loss: 1.028264045715332
Validation loss: 2.0509731670220694

Epoch: 5| Step: 8
Training loss: 1.4481470584869385
Validation loss: 2.0842482894659042

Epoch: 5| Step: 9
Training loss: 1.1237730979919434
Validation loss: 2.016321877638499

Epoch: 5| Step: 10
Training loss: 1.0773566961288452
Validation loss: 2.080040310819944

Epoch: 5| Step: 11
Training loss: 1.0351636409759521
Validation loss: 2.109626660744349

Epoch: 121| Step: 0
Training loss: 1.0169200897216797
Validation loss: 2.0909238358338675

Epoch: 5| Step: 1
Training loss: 0.9125238656997681
Validation loss: 2.025590325395266

Epoch: 5| Step: 2
Training loss: 1.4501911401748657
Validation loss: 2.0473623822132745

Epoch: 5| Step: 3
Training loss: 1.4553368091583252
Validation loss: 2.0810308953126273

Epoch: 5| Step: 4
Training loss: 1.58441162109375
Validation loss: 2.0279509872198105

Epoch: 5| Step: 5
Training loss: 1.6656253337860107
Validation loss: 2.0740977227687836

Epoch: 5| Step: 6
Training loss: 1.4075915813446045
Validation loss: 2.086641122897466

Epoch: 5| Step: 7
Training loss: 1.09494948387146
Validation loss: 2.102941185235977

Epoch: 5| Step: 8
Training loss: 1.0402557849884033
Validation loss: 2.134103943904241

Epoch: 5| Step: 9
Training loss: 1.404132604598999
Validation loss: 2.1265465170145035

Epoch: 5| Step: 10
Training loss: 1.1223127841949463
Validation loss: 2.1005980571111045

Epoch: 5| Step: 11
Training loss: 0.727595865726471
Validation loss: 2.0832032759984336

Epoch: 122| Step: 0
Training loss: 1.3317584991455078
Validation loss: 2.0951414853334427

Epoch: 5| Step: 1
Training loss: 0.9496367573738098
Validation loss: 2.039335702856382

Epoch: 5| Step: 2
Training loss: 1.0301072597503662
Validation loss: 2.0302343567212424

Epoch: 5| Step: 3
Training loss: 1.2349376678466797
Validation loss: 2.068954567114512

Epoch: 5| Step: 4
Training loss: 1.4047954082489014
Validation loss: 2.011874442299207

Epoch: 5| Step: 5
Training loss: 1.45531165599823
Validation loss: 2.030770813425382

Epoch: 5| Step: 6
Training loss: 1.2499992847442627
Validation loss: 2.0463118056456246

Epoch: 5| Step: 7
Training loss: 1.1985276937484741
Validation loss: 2.041360472639402

Epoch: 5| Step: 8
Training loss: 2.3537790775299072
Validation loss: 2.067145218451818

Epoch: 5| Step: 9
Training loss: 1.1742429733276367
Validation loss: 2.010193556547165

Epoch: 5| Step: 10
Training loss: 0.8757225275039673
Validation loss: 2.031857058405876

Epoch: 5| Step: 11
Training loss: 0.7241900563240051
Validation loss: 2.0862336109081903

Epoch: 123| Step: 0
Training loss: 0.9591447114944458
Validation loss: 2.145328457156817

Epoch: 5| Step: 1
Training loss: 2.1533353328704834
Validation loss: 2.1811344623565674

Epoch: 5| Step: 2
Training loss: 1.585345983505249
Validation loss: 2.1346154858668647

Epoch: 5| Step: 3
Training loss: 0.971794605255127
Validation loss: 2.0495771914720535

Epoch: 5| Step: 4
Training loss: 1.1589076519012451
Validation loss: 2.1126274367173514

Epoch: 5| Step: 5
Training loss: 1.6306865215301514
Validation loss: 2.0347100347280502

Epoch: 5| Step: 6
Training loss: 1.3566416501998901
Validation loss: 2.029019902149836

Epoch: 5| Step: 7
Training loss: 1.182617425918579
Validation loss: 2.055351108312607

Epoch: 5| Step: 8
Training loss: 1.6974983215332031
Validation loss: 1.9812371631463368

Epoch: 5| Step: 9
Training loss: 1.0989573001861572
Validation loss: 2.0144968728224435

Epoch: 5| Step: 10
Training loss: 0.865683913230896
Validation loss: 2.069519971807798

Epoch: 5| Step: 11
Training loss: 0.8073844909667969
Validation loss: 2.1173935333887735

Epoch: 124| Step: 0
Training loss: 1.9219942092895508
Validation loss: 2.1862026254336038

Epoch: 5| Step: 1
Training loss: 1.405225157737732
Validation loss: 2.200905834635099

Epoch: 5| Step: 2
Training loss: 1.1551635265350342
Validation loss: 2.128568783402443

Epoch: 5| Step: 3
Training loss: 1.0633790493011475
Validation loss: 2.070833588639895

Epoch: 5| Step: 4
Training loss: 1.2513917684555054
Validation loss: 2.038093462586403

Epoch: 5| Step: 5
Training loss: 1.3295469284057617
Validation loss: 2.0176398555437722

Epoch: 5| Step: 6
Training loss: 1.0380756855010986
Validation loss: 2.057402287920316

Epoch: 5| Step: 7
Training loss: 1.3415738344192505
Validation loss: 2.027282029390335

Epoch: 5| Step: 8
Training loss: 1.5388778448104858
Validation loss: 2.065342644850413

Epoch: 5| Step: 9
Training loss: 1.3200618028640747
Validation loss: 2.073791633049647

Epoch: 5| Step: 10
Training loss: 1.0367578268051147
Validation loss: 2.0623083064953485

Epoch: 5| Step: 11
Training loss: 0.5586270689964294
Validation loss: 2.0613780518372855

Epoch: 125| Step: 0
Training loss: 1.2237589359283447
Validation loss: 2.1180196503798165

Epoch: 5| Step: 1
Training loss: 1.1154054403305054
Validation loss: 2.145337129632632

Epoch: 5| Step: 2
Training loss: 0.970147430896759
Validation loss: 2.148602435986201

Epoch: 5| Step: 3
Training loss: 1.3844010829925537
Validation loss: 2.2246191253264747

Epoch: 5| Step: 4
Training loss: 1.5833213329315186
Validation loss: 2.1559904664754868

Epoch: 5| Step: 5
Training loss: 1.3083429336547852
Validation loss: 2.185647631684939

Epoch: 5| Step: 6
Training loss: 1.2584717273712158
Validation loss: 2.1038891673088074

Epoch: 5| Step: 7
Training loss: 1.4532878398895264
Validation loss: 2.071034093697866

Epoch: 5| Step: 8
Training loss: 0.8695617914199829
Validation loss: 2.062348504861196

Epoch: 5| Step: 9
Training loss: 1.4407731294631958
Validation loss: 2.062307978669802

Epoch: 5| Step: 10
Training loss: 1.3428279161453247
Validation loss: 2.06675353149573

Epoch: 5| Step: 11
Training loss: 0.5794572234153748
Validation loss: 2.0881079832712808

Epoch: 126| Step: 0
Training loss: 0.7517054677009583
Validation loss: 2.0557050108909607

Epoch: 5| Step: 1
Training loss: 1.1431864500045776
Validation loss: 2.097739110390345

Epoch: 5| Step: 2
Training loss: 0.857815146446228
Validation loss: 2.097744325796763

Epoch: 5| Step: 3
Training loss: 1.6526315212249756
Validation loss: 2.129808728893598

Epoch: 5| Step: 4
Training loss: 1.3532603979110718
Validation loss: 2.1264701187610626

Epoch: 5| Step: 5
Training loss: 1.398078203201294
Validation loss: 2.0995329320430756

Epoch: 5| Step: 6
Training loss: 1.1380887031555176
Validation loss: 2.0397385358810425

Epoch: 5| Step: 7
Training loss: 1.188739538192749
Validation loss: 2.0471037924289703

Epoch: 5| Step: 8
Training loss: 1.221250057220459
Validation loss: 2.0494385759035745

Epoch: 5| Step: 9
Training loss: 1.1051102876663208
Validation loss: 2.047384098172188

Epoch: 5| Step: 10
Training loss: 1.5522209405899048
Validation loss: 2.0509610573450723

Epoch: 5| Step: 11
Training loss: 0.5068156123161316
Validation loss: 2.0812545120716095

Epoch: 127| Step: 0
Training loss: 1.2851835489273071
Validation loss: 2.072004973888397

Epoch: 5| Step: 1
Training loss: 0.9346000552177429
Validation loss: 2.0702182153860726

Epoch: 5| Step: 2
Training loss: 2.0822689533233643
Validation loss: 2.1428920874993005

Epoch: 5| Step: 3
Training loss: 1.1854814291000366
Validation loss: 2.145202467838923

Epoch: 5| Step: 4
Training loss: 1.592627763748169
Validation loss: 2.141821583112081

Epoch: 5| Step: 5
Training loss: 1.1705849170684814
Validation loss: 2.0986100236574807

Epoch: 5| Step: 6
Training loss: 1.4076467752456665
Validation loss: 2.0370301057895026

Epoch: 5| Step: 7
Training loss: 0.8690959811210632
Validation loss: 2.0673943360646567

Epoch: 5| Step: 8
Training loss: 1.0446748733520508
Validation loss: 2.0466850250959396

Epoch: 5| Step: 9
Training loss: 1.2663805484771729
Validation loss: 2.0386809508005777

Epoch: 5| Step: 10
Training loss: 0.6060665845870972
Validation loss: 2.0895950545867286

Epoch: 5| Step: 11
Training loss: 1.2609524726867676
Validation loss: 2.06385467449824

Epoch: 128| Step: 0
Training loss: 0.967670738697052
Validation loss: 2.024786258737246

Epoch: 5| Step: 1
Training loss: 1.046346664428711
Validation loss: 2.0809816271066666

Epoch: 5| Step: 2
Training loss: 1.0450645685195923
Validation loss: 2.1588659634192786

Epoch: 5| Step: 3
Training loss: 1.6295751333236694
Validation loss: 2.195055569211642

Epoch: 5| Step: 4
Training loss: 0.9433348774909973
Validation loss: 2.1473024487495422

Epoch: 5| Step: 5
Training loss: 0.9243221282958984
Validation loss: 2.145289416114489

Epoch: 5| Step: 6
Training loss: 1.4574460983276367
Validation loss: 2.1089758773644767

Epoch: 5| Step: 7
Training loss: 1.2812761068344116
Validation loss: 2.087248017390569

Epoch: 5| Step: 8
Training loss: 0.9424850344657898
Validation loss: 2.111512447396914

Epoch: 5| Step: 9
Training loss: 1.7722089290618896
Validation loss: 2.0402396420637765

Epoch: 5| Step: 10
Training loss: 1.468724250793457
Validation loss: 2.0095562438170114

Epoch: 5| Step: 11
Training loss: 2.015204906463623
Validation loss: 1.987657015522321

Epoch: 129| Step: 0
Training loss: 1.2895262241363525
Validation loss: 2.027896597981453

Epoch: 5| Step: 1
Training loss: 1.2025185823440552
Validation loss: 2.0612256030241647

Epoch: 5| Step: 2
Training loss: 1.6290286779403687
Validation loss: 2.050286258260409

Epoch: 5| Step: 3
Training loss: 1.4264010190963745
Validation loss: 2.0340642233689628

Epoch: 5| Step: 4
Training loss: 0.7762510180473328
Validation loss: 2.074599266052246

Epoch: 5| Step: 5
Training loss: 1.2308714389801025
Validation loss: 2.093341981371244

Epoch: 5| Step: 6
Training loss: 1.053183913230896
Validation loss: 2.1055636554956436

Epoch: 5| Step: 7
Training loss: 1.4215718507766724
Validation loss: 2.1338410625855126

Epoch: 5| Step: 8
Training loss: 1.3039120435714722
Validation loss: 2.1154254426558814

Epoch: 5| Step: 9
Training loss: 1.063165545463562
Validation loss: 2.0991108814875283

Epoch: 5| Step: 10
Training loss: 1.3758209943771362
Validation loss: 2.0335500836372375

Epoch: 5| Step: 11
Training loss: 1.2510769367218018
Validation loss: 2.064045379559199

Epoch: 130| Step: 0
Training loss: 1.072361707687378
Validation loss: 2.0504096945126853

Epoch: 5| Step: 1
Training loss: 1.1950266361236572
Validation loss: 2.0931561092535653

Epoch: 5| Step: 2
Training loss: 1.4200451374053955
Validation loss: 2.0199687083562217

Epoch: 5| Step: 3
Training loss: 1.5066019296646118
Validation loss: 2.0377130657434464

Epoch: 5| Step: 4
Training loss: 1.0304099321365356
Validation loss: 2.0858138352632523

Epoch: 5| Step: 5
Training loss: 1.0483332872390747
Validation loss: 2.0698038140932717

Epoch: 5| Step: 6
Training loss: 1.4907195568084717
Validation loss: 2.081336756547292

Epoch: 5| Step: 7
Training loss: 1.2587791681289673
Validation loss: 2.10280571381251

Epoch: 5| Step: 8
Training loss: 0.972213864326477
Validation loss: 2.06850258509318

Epoch: 5| Step: 9
Training loss: 0.8239037394523621
Validation loss: 2.085031862060229

Epoch: 5| Step: 10
Training loss: 1.5700476169586182
Validation loss: 2.0783874541521072

Epoch: 5| Step: 11
Training loss: 0.21317636966705322
Validation loss: 2.0700132151444754

Epoch: 131| Step: 0
Training loss: 1.2005103826522827
Validation loss: 2.0402493129173913

Epoch: 5| Step: 1
Training loss: 1.0224151611328125
Validation loss: 2.0456012785434723

Epoch: 5| Step: 2
Training loss: 1.2992738485336304
Validation loss: 2.011441245675087

Epoch: 5| Step: 3
Training loss: 1.1329538822174072
Validation loss: 2.0116241425275803

Epoch: 5| Step: 4
Training loss: 1.0202538967132568
Validation loss: 2.003734494249026

Epoch: 5| Step: 5
Training loss: 0.7549564242362976
Validation loss: 2.017631302277247

Epoch: 5| Step: 6
Training loss: 0.929939866065979
Validation loss: 2.032495523492495

Epoch: 5| Step: 7
Training loss: 0.9225848913192749
Validation loss: 2.0711833238601685

Epoch: 5| Step: 8
Training loss: 1.5501518249511719
Validation loss: 2.109723607699076

Epoch: 5| Step: 9
Training loss: 1.271009087562561
Validation loss: 2.1026465197404227

Epoch: 5| Step: 10
Training loss: 2.0345053672790527
Validation loss: 2.0990858525037766

Epoch: 5| Step: 11
Training loss: 1.2187302112579346
Validation loss: 2.106644883751869

Epoch: 132| Step: 0
Training loss: 0.9771119356155396
Validation loss: 2.089356536666552

Epoch: 5| Step: 1
Training loss: 0.9317439198493958
Validation loss: 2.0219457844893136

Epoch: 5| Step: 2
Training loss: 1.5462255477905273
Validation loss: 2.053282951315244

Epoch: 5| Step: 3
Training loss: 1.2984545230865479
Validation loss: 2.0381466696659722

Epoch: 5| Step: 4
Training loss: 1.3553473949432373
Validation loss: 2.0017764965693154

Epoch: 5| Step: 5
Training loss: 0.9293271899223328
Validation loss: 2.0347573359807334

Epoch: 5| Step: 6
Training loss: 1.2790310382843018
Validation loss: 2.0917846461137137

Epoch: 5| Step: 7
Training loss: 1.0586165189743042
Validation loss: 2.057932590444883

Epoch: 5| Step: 8
Training loss: 1.1310707330703735
Validation loss: 2.118488331635793

Epoch: 5| Step: 9
Training loss: 1.0397450923919678
Validation loss: 2.124578987558683

Epoch: 5| Step: 10
Training loss: 1.094543218612671
Validation loss: 2.1491330365339913

Epoch: 5| Step: 11
Training loss: 2.533876895904541
Validation loss: 2.125297193725904

Epoch: 133| Step: 0
Training loss: 1.261839509010315
Validation loss: 2.0683610886335373

Epoch: 5| Step: 1
Training loss: 1.0992047786712646
Validation loss: 2.065040464202563

Epoch: 5| Step: 2
Training loss: 1.2628175020217896
Validation loss: 2.084113453825315

Epoch: 5| Step: 3
Training loss: 1.3388930559158325
Validation loss: 2.0505020221074424

Epoch: 5| Step: 4
Training loss: 1.28261137008667
Validation loss: 2.037882203857104

Epoch: 5| Step: 5
Training loss: 0.7984144687652588
Validation loss: 2.054092342654864

Epoch: 5| Step: 6
Training loss: 1.0443570613861084
Validation loss: 2.0753317326307297

Epoch: 5| Step: 7
Training loss: 1.191641926765442
Validation loss: 2.086118737856547

Epoch: 5| Step: 8
Training loss: 1.09751296043396
Validation loss: 2.090407133102417

Epoch: 5| Step: 9
Training loss: 1.017271637916565
Validation loss: 2.0775658885637918

Epoch: 5| Step: 10
Training loss: 0.9384525418281555
Validation loss: 2.0587489704291024

Epoch: 5| Step: 11
Training loss: 2.923593521118164
Validation loss: 2.0518631488084793

Epoch: 134| Step: 0
Training loss: 1.5044881105422974
Validation loss: 2.0625018725792565

Epoch: 5| Step: 1
Training loss: 0.6909275054931641
Validation loss: 2.0920545061429343

Epoch: 5| Step: 2
Training loss: 0.9894902110099792
Validation loss: 2.064236412445704

Epoch: 5| Step: 3
Training loss: 1.0298771858215332
Validation loss: 2.0880995839834213

Epoch: 5| Step: 4
Training loss: 1.1147747039794922
Validation loss: 2.103057791789373

Epoch: 5| Step: 5
Training loss: 1.2541465759277344
Validation loss: 2.1641534666220346

Epoch: 5| Step: 6
Training loss: 1.389715313911438
Validation loss: 2.1172394454479218

Epoch: 5| Step: 7
Training loss: 1.3151671886444092
Validation loss: 2.0757931421200433

Epoch: 5| Step: 8
Training loss: 0.968758761882782
Validation loss: 2.0752711494763694

Epoch: 5| Step: 9
Training loss: 1.2350115776062012
Validation loss: 2.0635948727528253

Epoch: 5| Step: 10
Training loss: 1.0535902976989746
Validation loss: 2.0754267225662866

Epoch: 5| Step: 11
Training loss: 1.8839432001113892
Validation loss: 2.049665222565333

Epoch: 135| Step: 0
Training loss: 0.890782356262207
Validation loss: 2.0851190040508905

Epoch: 5| Step: 1
Training loss: 1.1228011846542358
Validation loss: 2.031738410393397

Epoch: 5| Step: 2
Training loss: 1.4806225299835205
Validation loss: 2.094668577114741

Epoch: 5| Step: 3
Training loss: 0.9531181454658508
Validation loss: 2.1114280372858047

Epoch: 5| Step: 4
Training loss: 1.2436835765838623
Validation loss: 2.0769094973802567

Epoch: 5| Step: 5
Training loss: 0.8361489176750183
Validation loss: 2.1146427194277444

Epoch: 5| Step: 6
Training loss: 1.318260669708252
Validation loss: 2.130175625284513

Epoch: 5| Step: 7
Training loss: 0.8364887237548828
Validation loss: 2.1547203212976456

Epoch: 5| Step: 8
Training loss: 1.4488105773925781
Validation loss: 2.1035119046767554

Epoch: 5| Step: 9
Training loss: 0.9092351794242859
Validation loss: 2.0774412552515664

Epoch: 5| Step: 10
Training loss: 1.2130366563796997
Validation loss: 2.0854129095872245

Epoch: 5| Step: 11
Training loss: 2.102694511413574
Validation loss: 2.1044325828552246

Epoch: 136| Step: 0
Training loss: 1.2014243602752686
Validation loss: 2.0673388093709946

Epoch: 5| Step: 1
Training loss: 1.5095638036727905
Validation loss: 2.0328578849633536

Epoch: 5| Step: 2
Training loss: 0.8596963882446289
Validation loss: 2.0463835249344506

Epoch: 5| Step: 3
Training loss: 1.8209717273712158
Validation loss: 2.0885599702596664

Epoch: 5| Step: 4
Training loss: 1.0901398658752441
Validation loss: 2.124020849665006

Epoch: 5| Step: 5
Training loss: 0.8337192535400391
Validation loss: 2.1336982399225235

Epoch: 5| Step: 6
Training loss: 0.44917458295822144
Validation loss: 2.072868878642718

Epoch: 5| Step: 7
Training loss: 1.5691699981689453
Validation loss: 2.066842277844747

Epoch: 5| Step: 8
Training loss: 1.2765671014785767
Validation loss: 2.090295468767484

Epoch: 5| Step: 9
Training loss: 0.7967656254768372
Validation loss: 2.0892305175463357

Epoch: 5| Step: 10
Training loss: 1.1922849416732788
Validation loss: 2.0861748357613883

Epoch: 5| Step: 11
Training loss: 1.2708609104156494
Validation loss: 2.0863380233446756

Epoch: 137| Step: 0
Training loss: 1.1087549924850464
Validation loss: 2.0919550955295563

Epoch: 5| Step: 1
Training loss: 0.8785710334777832
Validation loss: 2.0753079454104104

Epoch: 5| Step: 2
Training loss: 1.342738151550293
Validation loss: 2.0429920057455697

Epoch: 5| Step: 3
Training loss: 1.1050441265106201
Validation loss: 2.1189234207073846

Epoch: 5| Step: 4
Training loss: 1.0043913125991821
Validation loss: 2.100764940182368

Epoch: 5| Step: 5
Training loss: 0.8637250065803528
Validation loss: 2.108976344267527

Epoch: 5| Step: 6
Training loss: 1.2413877248764038
Validation loss: 2.133822257320086

Epoch: 5| Step: 7
Training loss: 1.402282953262329
Validation loss: 2.071302463610967

Epoch: 5| Step: 8
Training loss: 0.647840142250061
Validation loss: 2.120022232333819

Epoch: 5| Step: 9
Training loss: 1.5849103927612305
Validation loss: 2.1538270711898804

Epoch: 5| Step: 10
Training loss: 1.1238104104995728
Validation loss: 2.0832126984993615

Epoch: 5| Step: 11
Training loss: 0.6518443822860718
Validation loss: 2.1392394403616586

Epoch: 138| Step: 0
Training loss: 1.6141865253448486
Validation loss: 2.1242730170488358

Epoch: 5| Step: 1
Training loss: 0.7726460099220276
Validation loss: 2.1237607101599374

Epoch: 5| Step: 2
Training loss: 0.8036869168281555
Validation loss: 2.1306319336096444

Epoch: 5| Step: 3
Training loss: 1.0616002082824707
Validation loss: 2.102052782972654

Epoch: 5| Step: 4
Training loss: 0.7232511639595032
Validation loss: 2.1308285097281137

Epoch: 5| Step: 5
Training loss: 1.0998296737670898
Validation loss: 2.0661679208278656

Epoch: 5| Step: 6
Training loss: 0.9542811512947083
Validation loss: 2.1242277026176453

Epoch: 5| Step: 7
Training loss: 1.3483201265335083
Validation loss: 2.0425307850042977

Epoch: 5| Step: 8
Training loss: 1.1620218753814697
Validation loss: 2.060903569062551

Epoch: 5| Step: 9
Training loss: 1.1979601383209229
Validation loss: 2.0839152485132217

Epoch: 5| Step: 10
Training loss: 1.0650451183319092
Validation loss: 2.0556887288888297

Epoch: 5| Step: 11
Training loss: 1.8023030757904053
Validation loss: 2.0344294806321463

Epoch: 139| Step: 0
Training loss: 1.025084137916565
Validation loss: 2.1192371199528375

Epoch: 5| Step: 1
Training loss: 1.2060877084732056
Validation loss: 2.095423176884651

Epoch: 5| Step: 2
Training loss: 1.7383321523666382
Validation loss: 2.0752215683460236

Epoch: 5| Step: 3
Training loss: 1.1871471405029297
Validation loss: 2.0562430719534555

Epoch: 5| Step: 4
Training loss: 1.1763454675674438
Validation loss: 2.0546504855155945

Epoch: 5| Step: 5
Training loss: 0.48462313413619995
Validation loss: 2.0894856800635657

Epoch: 5| Step: 6
Training loss: 1.191534399986267
Validation loss: 2.0472387174765267

Epoch: 5| Step: 7
Training loss: 0.7856332063674927
Validation loss: 2.1248648216327033

Epoch: 5| Step: 8
Training loss: 1.0893481969833374
Validation loss: 2.124821146329244

Epoch: 5| Step: 9
Training loss: 1.4336551427841187
Validation loss: 2.12033911049366

Epoch: 5| Step: 10
Training loss: 1.0270847082138062
Validation loss: 2.1245921005805335

Epoch: 5| Step: 11
Training loss: 0.9521806240081787
Validation loss: 2.118850439786911

Epoch: 140| Step: 0
Training loss: 0.9584242105484009
Validation loss: 2.0530493557453156

Epoch: 5| Step: 1
Training loss: 0.9287370443344116
Validation loss: 2.080782269438108

Epoch: 5| Step: 2
Training loss: 1.0979387760162354
Validation loss: 2.0829496632019677

Epoch: 5| Step: 3
Training loss: 1.4460560083389282
Validation loss: 2.068314323822657

Epoch: 5| Step: 4
Training loss: 1.1024525165557861
Validation loss: 2.0719600717226663

Epoch: 5| Step: 5
Training loss: 1.2730112075805664
Validation loss: 2.0664562483628592

Epoch: 5| Step: 6
Training loss: 1.0506346225738525
Validation loss: 2.0874331245819726

Epoch: 5| Step: 7
Training loss: 1.383256196975708
Validation loss: 2.0896316270033517

Epoch: 5| Step: 8
Training loss: 0.7560657262802124
Validation loss: 2.089312066634496

Epoch: 5| Step: 9
Training loss: 1.036143183708191
Validation loss: 2.1112961818774543

Epoch: 5| Step: 10
Training loss: 0.9858749508857727
Validation loss: 2.1260839998722076

Epoch: 5| Step: 11
Training loss: 0.5824798345565796
Validation loss: 2.084502841035525

Epoch: 141| Step: 0
Training loss: 1.4319169521331787
Validation loss: 2.0513511846462884

Epoch: 5| Step: 1
Training loss: 1.0130904912948608
Validation loss: 2.0688381443421044

Epoch: 5| Step: 2
Training loss: 1.2863649129867554
Validation loss: 2.044511695702871

Epoch: 5| Step: 3
Training loss: 0.9642223119735718
Validation loss: 2.0550099909305573

Epoch: 5| Step: 4
Training loss: 0.9733775854110718
Validation loss: 2.0383280366659164

Epoch: 5| Step: 5
Training loss: 1.3499410152435303
Validation loss: 2.10794028143088

Epoch: 5| Step: 6
Training loss: 1.2310497760772705
Validation loss: 2.1608309149742126

Epoch: 5| Step: 7
Training loss: 1.141723394393921
Validation loss: 2.156545023123423

Epoch: 5| Step: 8
Training loss: 0.8425407409667969
Validation loss: 2.165163218975067

Epoch: 5| Step: 9
Training loss: 0.8646562695503235
Validation loss: 2.128917708992958

Epoch: 5| Step: 10
Training loss: 0.584492027759552
Validation loss: 2.0987984091043472

Epoch: 5| Step: 11
Training loss: 2.8919262886047363
Validation loss: 2.048439919948578

Epoch: 142| Step: 0
Training loss: 1.294582724571228
Validation loss: 2.0784843415021896

Epoch: 5| Step: 1
Training loss: 1.146824598312378
Validation loss: 2.0528090745210648

Epoch: 5| Step: 2
Training loss: 0.7994004487991333
Validation loss: 2.0467622031768165

Epoch: 5| Step: 3
Training loss: 0.5757620930671692
Validation loss: 2.0241800298293433

Epoch: 5| Step: 4
Training loss: 1.2406748533248901
Validation loss: 2.0532421320676804

Epoch: 5| Step: 5
Training loss: 1.0485502481460571
Validation loss: 2.0970744540294013

Epoch: 5| Step: 6
Training loss: 1.0410552024841309
Validation loss: 2.1424427777528763

Epoch: 5| Step: 7
Training loss: 1.2277082204818726
Validation loss: 2.1413952062527337

Epoch: 5| Step: 8
Training loss: 1.0302625894546509
Validation loss: 2.116227646668752

Epoch: 5| Step: 9
Training loss: 1.5624815225601196
Validation loss: 2.092186361551285

Epoch: 5| Step: 10
Training loss: 0.9049771428108215
Validation loss: 2.0790366381406784

Epoch: 5| Step: 11
Training loss: 1.1741600036621094
Validation loss: 2.1386649956305823

Epoch: 143| Step: 0
Training loss: 1.4187184572219849
Validation loss: 2.0938936124245324

Epoch: 5| Step: 1
Training loss: 1.0547837018966675
Validation loss: 2.0920232931772866

Epoch: 5| Step: 2
Training loss: 1.0515027046203613
Validation loss: 2.073136185606321

Epoch: 5| Step: 3
Training loss: 0.9601227641105652
Validation loss: 2.107204576333364

Epoch: 5| Step: 4
Training loss: 1.0427383184432983
Validation loss: 2.1120336204767227

Epoch: 5| Step: 5
Training loss: 0.8471541404724121
Validation loss: 2.1217313607533774

Epoch: 5| Step: 6
Training loss: 0.7856323719024658
Validation loss: 2.0965533405542374

Epoch: 5| Step: 7
Training loss: 1.2590272426605225
Validation loss: 2.0822540521621704

Epoch: 5| Step: 8
Training loss: 1.0934581756591797
Validation loss: 2.0416578551133475

Epoch: 5| Step: 9
Training loss: 1.059114933013916
Validation loss: 2.046881397565206

Epoch: 5| Step: 10
Training loss: 0.947292685508728
Validation loss: 2.093860367933909

Epoch: 5| Step: 11
Training loss: 0.44888174533843994
Validation loss: 2.0970112830400467

Epoch: 144| Step: 0
Training loss: 0.9170352220535278
Validation loss: 2.1053709189097085

Epoch: 5| Step: 1
Training loss: 0.8392203450202942
Validation loss: 2.071817790468534

Epoch: 5| Step: 2
Training loss: 1.2568832635879517
Validation loss: 2.1065613130728402

Epoch: 5| Step: 3
Training loss: 0.6484383344650269
Validation loss: 2.0874654203653336

Epoch: 5| Step: 4
Training loss: 1.4326156377792358
Validation loss: 2.0934994916121163

Epoch: 5| Step: 5
Training loss: 0.998184859752655
Validation loss: 2.0974687983592353

Epoch: 5| Step: 6
Training loss: 1.6779922246932983
Validation loss: 2.098086098829905

Epoch: 5| Step: 7
Training loss: 0.7670828104019165
Validation loss: 2.0531942943731942

Epoch: 5| Step: 8
Training loss: 1.1967570781707764
Validation loss: 2.054644539952278

Epoch: 5| Step: 9
Training loss: 1.1707849502563477
Validation loss: 2.1195361961921058

Epoch: 5| Step: 10
Training loss: 0.839991569519043
Validation loss: 2.0945053547620773

Epoch: 5| Step: 11
Training loss: 0.1460857391357422
Validation loss: 2.050520737965902

Epoch: 145| Step: 0
Training loss: 1.585805892944336
Validation loss: 2.114054208000501

Epoch: 5| Step: 1
Training loss: 1.3294190168380737
Validation loss: 2.1389709413051605

Epoch: 5| Step: 2
Training loss: 0.7536071538925171
Validation loss: 2.1102009962002435

Epoch: 5| Step: 3
Training loss: 0.6236718893051147
Validation loss: 2.0725458562374115

Epoch: 5| Step: 4
Training loss: 0.9334457516670227
Validation loss: 2.045527776082357

Epoch: 5| Step: 5
Training loss: 0.5415714383125305
Validation loss: 2.0598744799693427

Epoch: 5| Step: 6
Training loss: 1.4142262935638428
Validation loss: 2.0990500847498574

Epoch: 5| Step: 7
Training loss: 0.9093950986862183
Validation loss: 2.102775732676188

Epoch: 5| Step: 8
Training loss: 1.2855020761489868
Validation loss: 2.0954404125610986

Epoch: 5| Step: 9
Training loss: 1.3457727432250977
Validation loss: 2.0811679114898047

Epoch: 5| Step: 10
Training loss: 0.9482585787773132
Validation loss: 2.067726105451584

Epoch: 5| Step: 11
Training loss: 1.0046651363372803
Validation loss: 2.041063775618871

Epoch: 146| Step: 0
Training loss: 0.4971480369567871
Validation loss: 2.066566457351049

Epoch: 5| Step: 1
Training loss: 0.895319938659668
Validation loss: 2.043204019467036

Epoch: 5| Step: 2
Training loss: 1.317395567893982
Validation loss: 2.093204359213511

Epoch: 5| Step: 3
Training loss: 1.2166341543197632
Validation loss: 2.1036827067534127

Epoch: 5| Step: 4
Training loss: 1.1333757638931274
Validation loss: 2.0762908856074014

Epoch: 5| Step: 5
Training loss: 0.7803841829299927
Validation loss: 2.123729641238848

Epoch: 5| Step: 6
Training loss: 1.2634251117706299
Validation loss: 2.067940359314283

Epoch: 5| Step: 7
Training loss: 1.1805603504180908
Validation loss: 2.0843492448329926

Epoch: 5| Step: 8
Training loss: 0.9581983685493469
Validation loss: 2.045763368407885

Epoch: 5| Step: 9
Training loss: 1.1222083568572998
Validation loss: 2.096912160515785

Epoch: 5| Step: 10
Training loss: 0.986541748046875
Validation loss: 2.047586813569069

Epoch: 5| Step: 11
Training loss: 1.5063002109527588
Validation loss: 2.0555252383152642

Epoch: 147| Step: 0
Training loss: 1.005956768989563
Validation loss: 2.1227020074923835

Epoch: 5| Step: 1
Training loss: 1.0738425254821777
Validation loss: 2.094357877969742

Epoch: 5| Step: 2
Training loss: 1.200317621231079
Validation loss: 2.1595616340637207

Epoch: 5| Step: 3
Training loss: 0.8390723466873169
Validation loss: 2.1480422616004944

Epoch: 5| Step: 4
Training loss: 1.070705771446228
Validation loss: 2.1361290911833444

Epoch: 5| Step: 5
Training loss: 1.2070605754852295
Validation loss: 2.0753824412822723

Epoch: 5| Step: 6
Training loss: 1.0620508193969727
Validation loss: 2.1064449548721313

Epoch: 5| Step: 7
Training loss: 1.1988918781280518
Validation loss: 2.118823071320852

Epoch: 5| Step: 8
Training loss: 1.0188500881195068
Validation loss: 2.0842161824305854

Epoch: 5| Step: 9
Training loss: 1.1848002672195435
Validation loss: 2.0629891802867255

Epoch: 5| Step: 10
Training loss: 0.8489373326301575
Validation loss: 2.0404741863409677

Epoch: 5| Step: 11
Training loss: 0.6767206192016602
Validation loss: 2.0852595567703247

Epoch: 148| Step: 0
Training loss: 1.8004268407821655
Validation loss: 2.1177028318246207

Epoch: 5| Step: 1
Training loss: 1.0533143281936646
Validation loss: 2.1048258244991302

Epoch: 5| Step: 2
Training loss: 1.3744959831237793
Validation loss: 2.1298030068476996

Epoch: 5| Step: 3
Training loss: 1.682488203048706
Validation loss: 2.142196079095205

Epoch: 5| Step: 4
Training loss: 0.682102382183075
Validation loss: 2.102271760503451

Epoch: 5| Step: 5
Training loss: 1.1973031759262085
Validation loss: 2.0765133251746497

Epoch: 5| Step: 6
Training loss: 0.8950992822647095
Validation loss: 2.063142384092013

Epoch: 5| Step: 7
Training loss: 0.47839659452438354
Validation loss: 2.1081101099650064

Epoch: 5| Step: 8
Training loss: 0.46519890427589417
Validation loss: 2.0840992281834283

Epoch: 5| Step: 9
Training loss: 0.9384516477584839
Validation loss: 2.11954432229201

Epoch: 5| Step: 10
Training loss: 0.46986493468284607
Validation loss: 2.116473307212194

Epoch: 5| Step: 11
Training loss: 0.6720056533813477
Validation loss: 2.109059969584147

Epoch: 149| Step: 0
Training loss: 1.2208353281021118
Validation loss: 2.0952724864085517

Epoch: 5| Step: 1
Training loss: 0.7550867795944214
Validation loss: 2.047548602024714

Epoch: 5| Step: 2
Training loss: 0.6988270282745361
Validation loss: 2.0451065798600516

Epoch: 5| Step: 3
Training loss: 1.271991491317749
Validation loss: 2.0513713359832764

Epoch: 5| Step: 4
Training loss: 0.8713849782943726
Validation loss: 2.1185713708400726

Epoch: 5| Step: 5
Training loss: 1.0799050331115723
Validation loss: 2.140473594268163

Epoch: 5| Step: 6
Training loss: 1.530050277709961
Validation loss: 2.1200850307941437

Epoch: 5| Step: 7
Training loss: 0.8158060908317566
Validation loss: 2.1276699801286063

Epoch: 5| Step: 8
Training loss: 0.8751762509346008
Validation loss: 2.1487339387337365

Epoch: 5| Step: 9
Training loss: 0.6693817377090454
Validation loss: 2.138335963090261

Epoch: 5| Step: 10
Training loss: 1.0296697616577148
Validation loss: 2.0754550447066626

Epoch: 5| Step: 11
Training loss: 2.095557689666748
Validation loss: 2.061022857824961

Epoch: 150| Step: 0
Training loss: 1.3074592351913452
Validation loss: 2.0882102698087692

Epoch: 5| Step: 1
Training loss: 0.9266210794448853
Validation loss: 2.0777325530846915

Epoch: 5| Step: 2
Training loss: 1.379685878753662
Validation loss: 2.0897928178310394

Epoch: 5| Step: 3
Training loss: 0.7304642200469971
Validation loss: 2.1700472036997476

Epoch: 5| Step: 4
Training loss: 1.1051291227340698
Validation loss: 2.184025744597117

Epoch: 5| Step: 5
Training loss: 1.821306824684143
Validation loss: 2.237889587879181

Epoch: 5| Step: 6
Training loss: 1.0524466037750244
Validation loss: 2.200414980451266

Epoch: 5| Step: 7
Training loss: 1.0670963525772095
Validation loss: 2.109544818600019

Epoch: 5| Step: 8
Training loss: 0.7550294995307922
Validation loss: 2.0688822666803994

Epoch: 5| Step: 9
Training loss: 0.8621512651443481
Validation loss: 2.059887612859408

Epoch: 5| Step: 10
Training loss: 0.9132028818130493
Validation loss: 2.0681774566570916

Epoch: 5| Step: 11
Training loss: 1.6945022344589233
Validation loss: 2.0668150981267295

Epoch: 151| Step: 0
Training loss: 1.1906192302703857
Validation loss: 2.0873119036356607

Epoch: 5| Step: 1
Training loss: 1.0020554065704346
Validation loss: 2.0480423669020333

Epoch: 5| Step: 2
Training loss: 0.7222894430160522
Validation loss: 2.057788759469986

Epoch: 5| Step: 3
Training loss: 1.1208890676498413
Validation loss: 2.1376365025838218

Epoch: 5| Step: 4
Training loss: 0.5703983306884766
Validation loss: 2.122607628504435

Epoch: 5| Step: 5
Training loss: 1.073900818824768
Validation loss: 2.1353414009014764

Epoch: 5| Step: 6
Training loss: 1.0594873428344727
Validation loss: 2.0719217658042908

Epoch: 5| Step: 7
Training loss: 0.7989119291305542
Validation loss: 2.0923291941483817

Epoch: 5| Step: 8
Training loss: 0.5158035755157471
Validation loss: 2.100332498550415

Epoch: 5| Step: 9
Training loss: 1.3503412008285522
Validation loss: 2.0940516839424768

Epoch: 5| Step: 10
Training loss: 1.2600419521331787
Validation loss: 2.1257547189792

Epoch: 5| Step: 11
Training loss: 1.176282525062561
Validation loss: 2.106536790728569

Epoch: 152| Step: 0
Training loss: 0.7167121767997742
Validation loss: 2.075150102376938

Epoch: 5| Step: 1
Training loss: 0.8516039848327637
Validation loss: 2.092329944173495

Epoch: 5| Step: 2
Training loss: 1.1114037036895752
Validation loss: 2.074589063723882

Epoch: 5| Step: 3
Training loss: 0.9002555012702942
Validation loss: 2.0668872644503913

Epoch: 5| Step: 4
Training loss: 1.1073846817016602
Validation loss: 2.116432766119639

Epoch: 5| Step: 5
Training loss: 0.8955901265144348
Validation loss: 2.1685784657796225

Epoch: 5| Step: 6
Training loss: 1.0295464992523193
Validation loss: 2.1168944040934243

Epoch: 5| Step: 7
Training loss: 1.0439726114273071
Validation loss: 2.136187662680944

Epoch: 5| Step: 8
Training loss: 1.072882056236267
Validation loss: 2.0521053820848465

Epoch: 5| Step: 9
Training loss: 1.0674240589141846
Validation loss: 2.106148988008499

Epoch: 5| Step: 10
Training loss: 1.223156213760376
Validation loss: 2.072806383172671

Epoch: 5| Step: 11
Training loss: 1.249598503112793
Validation loss: 2.0648374458154044

Epoch: 153| Step: 0
Training loss: 0.9715649485588074
Validation loss: 2.0642134696245193

Epoch: 5| Step: 1
Training loss: 1.4877631664276123
Validation loss: 2.074644943078359

Epoch: 5| Step: 2
Training loss: 0.8763471841812134
Validation loss: 2.0868950386842093

Epoch: 5| Step: 3
Training loss: 0.5472655296325684
Validation loss: 2.065786292155584

Epoch: 5| Step: 4
Training loss: 1.151157021522522
Validation loss: 2.107927213112513

Epoch: 5| Step: 5
Training loss: 0.9119235277175903
Validation loss: 2.0857972502708435

Epoch: 5| Step: 6
Training loss: 1.0867784023284912
Validation loss: 2.1036050766706467

Epoch: 5| Step: 7
Training loss: 1.4671815633773804
Validation loss: 2.0910086830457053

Epoch: 5| Step: 8
Training loss: 0.7597748637199402
Validation loss: 2.0621781398852668

Epoch: 5| Step: 9
Training loss: 0.3588526248931885
Validation loss: 2.086384117603302

Epoch: 5| Step: 10
Training loss: 0.9609219431877136
Validation loss: 2.129472255706787

Epoch: 5| Step: 11
Training loss: 0.6386795043945312
Validation loss: 2.08428663512071

Epoch: 154| Step: 0
Training loss: 0.8779792785644531
Validation loss: 2.095243662595749

Epoch: 5| Step: 1
Training loss: 0.7512693405151367
Validation loss: 2.144679302970568

Epoch: 5| Step: 2
Training loss: 0.5076265335083008
Validation loss: 2.07355002562205

Epoch: 5| Step: 3
Training loss: 1.184321641921997
Validation loss: 2.0731394290924072

Epoch: 5| Step: 4
Training loss: 0.7427831888198853
Validation loss: 2.1031697541475296

Epoch: 5| Step: 5
Training loss: 1.1221612691879272
Validation loss: 2.1440015733242035

Epoch: 5| Step: 6
Training loss: 0.9391700625419617
Validation loss: 2.072296013434728

Epoch: 5| Step: 7
Training loss: 1.0723645687103271
Validation loss: 2.148191213607788

Epoch: 5| Step: 8
Training loss: 0.92381751537323
Validation loss: 2.180637111266454

Epoch: 5| Step: 9
Training loss: 1.2161668539047241
Validation loss: 2.1719848066568375

Epoch: 5| Step: 10
Training loss: 1.256638526916504
Validation loss: 2.125670741001765

Epoch: 5| Step: 11
Training loss: 0.3290271759033203
Validation loss: 2.1398696849743524

Epoch: 155| Step: 0
Training loss: 1.241257667541504
Validation loss: 2.151489347219467

Epoch: 5| Step: 1
Training loss: 0.524485170841217
Validation loss: 2.1357523600260415

Epoch: 5| Step: 2
Training loss: 0.9195135235786438
Validation loss: 2.0961091121037803

Epoch: 5| Step: 3
Training loss: 1.1404848098754883
Validation loss: 2.1265302499135337

Epoch: 5| Step: 4
Training loss: 0.9831331968307495
Validation loss: 2.1196562151114144

Epoch: 5| Step: 5
Training loss: 1.1941864490509033
Validation loss: 2.130352651079496

Epoch: 5| Step: 6
Training loss: 0.7837696671485901
Validation loss: 2.166680877407392

Epoch: 5| Step: 7
Training loss: 1.1271533966064453
Validation loss: 2.1210022419691086

Epoch: 5| Step: 8
Training loss: 0.6570224761962891
Validation loss: 2.1620474259058633

Epoch: 5| Step: 9
Training loss: 1.0865367650985718
Validation loss: 2.086207941174507

Epoch: 5| Step: 10
Training loss: 0.5421217679977417
Validation loss: 2.119450251261393

Epoch: 5| Step: 11
Training loss: 1.2165014743804932
Validation loss: 2.142202764749527

Epoch: 156| Step: 0
Training loss: 1.3883451223373413
Validation loss: 2.1360215793053308

Epoch: 5| Step: 1
Training loss: 0.9264332056045532
Validation loss: 2.0698800881703696

Epoch: 5| Step: 2
Training loss: 0.7296168804168701
Validation loss: 2.161919802427292

Epoch: 5| Step: 3
Training loss: 0.6312387585639954
Validation loss: 2.1120116263628006

Epoch: 5| Step: 4
Training loss: 0.5518085360527039
Validation loss: 2.1194325536489487

Epoch: 5| Step: 5
Training loss: 1.1316471099853516
Validation loss: 2.132827957471212

Epoch: 5| Step: 6
Training loss: 1.0870096683502197
Validation loss: 2.1235834658145905

Epoch: 5| Step: 7
Training loss: 0.9447759389877319
Validation loss: 2.121160780390104

Epoch: 5| Step: 8
Training loss: 0.9415618181228638
Validation loss: 2.1073072950045266

Epoch: 5| Step: 9
Training loss: 1.074610948562622
Validation loss: 2.103794127702713

Epoch: 5| Step: 10
Training loss: 0.4653142988681793
Validation loss: 2.0571106324593225

Epoch: 5| Step: 11
Training loss: 0.4578041434288025
Validation loss: 2.155545731385549

Epoch: 157| Step: 0
Training loss: 0.9866568446159363
Validation loss: 2.1393099228541055

Epoch: 5| Step: 1
Training loss: 0.8812042474746704
Validation loss: 2.1325309524933496

Epoch: 5| Step: 2
Training loss: 1.3629486560821533
Validation loss: 2.1700885792573295

Epoch: 5| Step: 3
Training loss: 1.0162208080291748
Validation loss: 2.115593820810318

Epoch: 5| Step: 4
Training loss: 0.678756594657898
Validation loss: 2.1592484960953393

Epoch: 5| Step: 5
Training loss: 1.0469064712524414
Validation loss: 2.1553455690542855

Epoch: 5| Step: 6
Training loss: 0.9573966860771179
Validation loss: 2.08925332625707

Epoch: 5| Step: 7
Training loss: 0.7215729355812073
Validation loss: 2.0870248625675836

Epoch: 5| Step: 8
Training loss: 0.8833006024360657
Validation loss: 2.1452048818270364

Epoch: 5| Step: 9
Training loss: 0.5516360402107239
Validation loss: 2.1233463883399963

Epoch: 5| Step: 10
Training loss: 1.1794253587722778
Validation loss: 2.0974571953217187

Epoch: 5| Step: 11
Training loss: 0.16788649559020996
Validation loss: 2.114361842473348

Epoch: 158| Step: 0
Training loss: 0.7720979452133179
Validation loss: 2.1055172234773636

Epoch: 5| Step: 1
Training loss: 1.148305058479309
Validation loss: 2.1027133762836456

Epoch: 5| Step: 2
Training loss: 0.8495540618896484
Validation loss: 2.1568998297055564

Epoch: 5| Step: 3
Training loss: 0.469381719827652
Validation loss: 2.115292345484098

Epoch: 5| Step: 4
Training loss: 1.0394011735916138
Validation loss: 2.116050680478414

Epoch: 5| Step: 5
Training loss: 0.9090789556503296
Validation loss: 2.090923155347506

Epoch: 5| Step: 6
Training loss: 0.8570511937141418
Validation loss: 2.102501173814138

Epoch: 5| Step: 7
Training loss: 1.0408782958984375
Validation loss: 2.091634059945742

Epoch: 5| Step: 8
Training loss: 0.5495560765266418
Validation loss: 2.138776813944181

Epoch: 5| Step: 9
Training loss: 0.8291773796081543
Validation loss: 2.111267775297165

Epoch: 5| Step: 10
Training loss: 1.6198174953460693
Validation loss: 2.1412707368532815

Epoch: 5| Step: 11
Training loss: 1.1490713357925415
Validation loss: 2.139271726210912

Epoch: 159| Step: 0
Training loss: 0.9592329263687134
Validation loss: 2.1302361488342285

Epoch: 5| Step: 1
Training loss: 1.0781205892562866
Validation loss: 2.1258720010519028

Epoch: 5| Step: 2
Training loss: 0.8440176844596863
Validation loss: 2.0765907913446426

Epoch: 5| Step: 3
Training loss: 0.7952143549919128
Validation loss: 2.125867187976837

Epoch: 5| Step: 4
Training loss: 0.8662203550338745
Validation loss: 2.1227884193261466

Epoch: 5| Step: 5
Training loss: 0.556403636932373
Validation loss: 2.1087765445311866

Epoch: 5| Step: 6
Training loss: 0.9283372759819031
Validation loss: 2.0707601805528006

Epoch: 5| Step: 7
Training loss: 1.023783564567566
Validation loss: 2.1109628627697625

Epoch: 5| Step: 8
Training loss: 0.7006766200065613
Validation loss: 2.110847070813179

Epoch: 5| Step: 9
Training loss: 0.9617670774459839
Validation loss: 2.151456361015638

Epoch: 5| Step: 10
Training loss: 1.4021326303482056
Validation loss: 2.216577226916949

Epoch: 5| Step: 11
Training loss: 1.7911063432693481
Validation loss: 2.0945567935705185

Epoch: 160| Step: 0
Training loss: 1.0982004404067993
Validation loss: 2.1101896117130914

Epoch: 5| Step: 1
Training loss: 0.9128503799438477
Validation loss: 2.1184413532416024

Epoch: 5| Step: 2
Training loss: 1.0151108503341675
Validation loss: 2.162197098135948

Epoch: 5| Step: 3
Training loss: 0.7747117877006531
Validation loss: 2.177819157640139

Epoch: 5| Step: 4
Training loss: 0.7060526013374329
Validation loss: 2.1501260697841644

Epoch: 5| Step: 5
Training loss: 0.8397762179374695
Validation loss: 2.1400980601708093

Epoch: 5| Step: 6
Training loss: 0.8746203184127808
Validation loss: 2.162885149319967

Epoch: 5| Step: 7
Training loss: 1.281562089920044
Validation loss: 2.160626143217087

Epoch: 5| Step: 8
Training loss: 1.1322336196899414
Validation loss: 2.183515320221583

Epoch: 5| Step: 9
Training loss: 0.6923351287841797
Validation loss: 2.166185905536016

Epoch: 5| Step: 10
Training loss: 0.580557644367218
Validation loss: 2.129292050997416

Epoch: 5| Step: 11
Training loss: 0.5489588379859924
Validation loss: 2.1445003549257913

Epoch: 161| Step: 0
Training loss: 1.108370065689087
Validation loss: 2.1815528323252997

Epoch: 5| Step: 1
Training loss: 0.9227749109268188
Validation loss: 2.25074910124143

Epoch: 5| Step: 2
Training loss: 1.087561845779419
Validation loss: 2.1914844115575156

Epoch: 5| Step: 3
Training loss: 0.9951693415641785
Validation loss: 2.1868365754683814

Epoch: 5| Step: 4
Training loss: 0.9035853147506714
Validation loss: 2.1430134872595468

Epoch: 5| Step: 5
Training loss: 0.7560347318649292
Validation loss: 2.1092646022637687

Epoch: 5| Step: 6
Training loss: 0.7444320917129517
Validation loss: 2.0983978509902954

Epoch: 5| Step: 7
Training loss: 1.1326673030853271
Validation loss: 2.1013791263103485

Epoch: 5| Step: 8
Training loss: 0.7213488817214966
Validation loss: 2.1257687906424203

Epoch: 5| Step: 9
Training loss: 0.967448890209198
Validation loss: 2.118504857023557

Epoch: 5| Step: 10
Training loss: 1.143584966659546
Validation loss: 2.1162500580151877

Epoch: 5| Step: 11
Training loss: 1.0609649419784546
Validation loss: 2.1416209042072296

Epoch: 162| Step: 0
Training loss: 1.29544997215271
Validation loss: 2.143849809964498

Epoch: 5| Step: 1
Training loss: 0.7967294454574585
Validation loss: 2.1202555944522223

Epoch: 5| Step: 2
Training loss: 1.155640959739685
Validation loss: 2.095124344031016

Epoch: 5| Step: 3
Training loss: 0.7124188542366028
Validation loss: 2.111152390638987

Epoch: 5| Step: 4
Training loss: 0.7195354104042053
Validation loss: 2.115436072150866

Epoch: 5| Step: 5
Training loss: 0.9741141200065613
Validation loss: 2.1204429815212884

Epoch: 5| Step: 6
Training loss: 0.7726805806159973
Validation loss: 2.1846338907877603

Epoch: 5| Step: 7
Training loss: 0.7512493133544922
Validation loss: 2.1394706269105277

Epoch: 5| Step: 8
Training loss: 0.6835389137268066
Validation loss: 2.1556095530589423

Epoch: 5| Step: 9
Training loss: 1.1509532928466797
Validation loss: 2.0814189016819

Epoch: 5| Step: 10
Training loss: 0.8501682281494141
Validation loss: 2.1136653323968253

Epoch: 5| Step: 11
Training loss: 0.9562339782714844
Validation loss: 2.0931102633476257

Epoch: 163| Step: 0
Training loss: 0.5706042051315308
Validation loss: 2.129611551761627

Epoch: 5| Step: 1
Training loss: 1.0823030471801758
Validation loss: 2.1356938232978186

Epoch: 5| Step: 2
Training loss: 1.3455568552017212
Validation loss: 2.1100984315077462

Epoch: 5| Step: 3
Training loss: 0.7845175266265869
Validation loss: 2.142471273740133

Epoch: 5| Step: 4
Training loss: 0.7600850462913513
Validation loss: 2.177070905764898

Epoch: 5| Step: 5
Training loss: 0.5756174921989441
Validation loss: 2.2068509409825006

Epoch: 5| Step: 6
Training loss: 1.2513694763183594
Validation loss: 2.1657068183024726

Epoch: 5| Step: 7
Training loss: 1.0332601070404053
Validation loss: 2.1623496611913047

Epoch: 5| Step: 8
Training loss: 0.8024032711982727
Validation loss: 2.124540865421295

Epoch: 5| Step: 9
Training loss: 0.8715978860855103
Validation loss: 2.102373649676641

Epoch: 5| Step: 10
Training loss: 0.6983615756034851
Validation loss: 2.131143013636271

Epoch: 5| Step: 11
Training loss: 1.0504467487335205
Validation loss: 2.0869721472263336

Epoch: 164| Step: 0
Training loss: 0.8520523309707642
Validation loss: 2.108344634373983

Epoch: 5| Step: 1
Training loss: 0.8310688138008118
Validation loss: 2.089034621914228

Epoch: 5| Step: 2
Training loss: 1.045904517173767
Validation loss: 2.1974566330512366

Epoch: 5| Step: 3
Training loss: 1.172893762588501
Validation loss: 2.1840107838312783

Epoch: 5| Step: 4
Training loss: 1.2391587495803833
Validation loss: 2.2471558650334678

Epoch: 5| Step: 5
Training loss: 0.597944438457489
Validation loss: 2.184249291817347

Epoch: 5| Step: 6
Training loss: 0.653851330280304
Validation loss: 2.172752877076467

Epoch: 5| Step: 7
Training loss: 1.1599690914154053
Validation loss: 2.1261319468418756

Epoch: 5| Step: 8
Training loss: 0.9949854016304016
Validation loss: 2.138618772228559

Epoch: 5| Step: 9
Training loss: 0.8751386404037476
Validation loss: 2.1565490812063217

Epoch: 5| Step: 10
Training loss: 0.8537940979003906
Validation loss: 2.099361394842466

Epoch: 5| Step: 11
Training loss: 0.1732305884361267
Validation loss: 2.136690855026245

Epoch: 165| Step: 0
Training loss: 0.6182025671005249
Validation loss: 2.093886504570643

Epoch: 5| Step: 1
Training loss: 0.566550076007843
Validation loss: 2.1174192130565643

Epoch: 5| Step: 2
Training loss: 0.6658339500427246
Validation loss: 2.151768525441488

Epoch: 5| Step: 3
Training loss: 0.6577639579772949
Validation loss: 2.14217742284139

Epoch: 5| Step: 4
Training loss: 1.3261678218841553
Validation loss: 2.0908521711826324

Epoch: 5| Step: 5
Training loss: 0.9944337606430054
Validation loss: 2.122501621643702

Epoch: 5| Step: 6
Training loss: 0.9668583869934082
Validation loss: 2.1246548146009445

Epoch: 5| Step: 7
Training loss: 0.8927825093269348
Validation loss: 2.1330309907595315

Epoch: 5| Step: 8
Training loss: 0.9687873125076294
Validation loss: 2.167872409025828

Epoch: 5| Step: 9
Training loss: 1.1539826393127441
Validation loss: 2.1648129473129907

Epoch: 5| Step: 10
Training loss: 0.954820454120636
Validation loss: 2.15008008480072

Epoch: 5| Step: 11
Training loss: 0.581832766532898
Validation loss: 2.103752166032791

Epoch: 166| Step: 0
Training loss: 1.033063530921936
Validation loss: 2.1142822206020355

Epoch: 5| Step: 1
Training loss: 0.5667080879211426
Validation loss: 2.1469567666451135

Epoch: 5| Step: 2
Training loss: 0.6972955465316772
Validation loss: 2.2160889208316803

Epoch: 5| Step: 3
Training loss: 1.1104800701141357
Validation loss: 2.195945074160894

Epoch: 5| Step: 4
Training loss: 1.1271926164627075
Validation loss: 2.1769940108060837

Epoch: 5| Step: 5
Training loss: 0.6044067740440369
Validation loss: 2.1251460313796997

Epoch: 5| Step: 6
Training loss: 0.7529301047325134
Validation loss: 2.1143044432004294

Epoch: 5| Step: 7
Training loss: 0.6483677625656128
Validation loss: 2.135417362054189

Epoch: 5| Step: 8
Training loss: 1.3471325635910034
Validation loss: 2.0756774644056954

Epoch: 5| Step: 9
Training loss: 1.374568223953247
Validation loss: 2.141432285308838

Epoch: 5| Step: 10
Training loss: 0.9035302996635437
Validation loss: 2.1254996756712594

Epoch: 5| Step: 11
Training loss: 0.3228273391723633
Validation loss: 2.1298658351103463

Epoch: 167| Step: 0
Training loss: 1.041141152381897
Validation loss: 2.136352300643921

Epoch: 5| Step: 1
Training loss: 0.7098531126976013
Validation loss: 2.1110179473956427

Epoch: 5| Step: 2
Training loss: 0.8133479952812195
Validation loss: 2.0836945176124573

Epoch: 5| Step: 3
Training loss: 0.8941481709480286
Validation loss: 2.130019873380661

Epoch: 5| Step: 4
Training loss: 0.9443267583847046
Validation loss: 2.127909779548645

Epoch: 5| Step: 5
Training loss: 1.0959540605545044
Validation loss: 2.085659076770147

Epoch: 5| Step: 6
Training loss: 0.4494800567626953
Validation loss: 2.1418987611929574

Epoch: 5| Step: 7
Training loss: 1.2477272748947144
Validation loss: 2.1091917951901755

Epoch: 5| Step: 8
Training loss: 0.6719594597816467
Validation loss: 2.123740459481875

Epoch: 5| Step: 9
Training loss: 0.45387202501296997
Validation loss: 2.108389526605606

Epoch: 5| Step: 10
Training loss: 0.9155685305595398
Validation loss: 2.128161832690239

Epoch: 5| Step: 11
Training loss: 1.6623592376708984
Validation loss: 2.1265849272410073

Epoch: 168| Step: 0
Training loss: 1.2232038974761963
Validation loss: 2.1286255021890006

Epoch: 5| Step: 1
Training loss: 0.7417128086090088
Validation loss: 2.1209413011868796

Epoch: 5| Step: 2
Training loss: 1.1822634935379028
Validation loss: 2.131770819425583

Epoch: 5| Step: 3
Training loss: 0.7021547555923462
Validation loss: 2.19767157236735

Epoch: 5| Step: 4
Training loss: 0.8143091201782227
Validation loss: 2.195579712589582

Epoch: 5| Step: 5
Training loss: 0.6423107981681824
Validation loss: 2.1810229967037835

Epoch: 5| Step: 6
Training loss: 0.8860429525375366
Validation loss: 2.1200894167025885

Epoch: 5| Step: 7
Training loss: 0.7249135971069336
Validation loss: 2.1193695813417435

Epoch: 5| Step: 8
Training loss: 0.8165291547775269
Validation loss: 2.1486556927363076

Epoch: 5| Step: 9
Training loss: 0.9520924687385559
Validation loss: 2.1455979545911155

Epoch: 5| Step: 10
Training loss: 1.0281150341033936
Validation loss: 2.12620318432649

Epoch: 5| Step: 11
Training loss: 0.1872573047876358
Validation loss: 2.163221259911855

Epoch: 169| Step: 0
Training loss: 0.6189242601394653
Validation loss: 2.104955608646075

Epoch: 5| Step: 1
Training loss: 1.3948233127593994
Validation loss: 2.194839467604955

Epoch: 5| Step: 2
Training loss: 0.7215297222137451
Validation loss: 2.219879632194837

Epoch: 5| Step: 3
Training loss: 0.8494375348091125
Validation loss: 2.193699538707733

Epoch: 5| Step: 4
Training loss: 0.7911290526390076
Validation loss: 2.224458158016205

Epoch: 5| Step: 5
Training loss: 0.9554094076156616
Validation loss: 2.141318450371424

Epoch: 5| Step: 6
Training loss: 0.8800808191299438
Validation loss: 2.1352998663981757

Epoch: 5| Step: 7
Training loss: 0.5200167894363403
Validation loss: 2.114962711930275

Epoch: 5| Step: 8
Training loss: 1.1853406429290771
Validation loss: 2.0972935060660043

Epoch: 5| Step: 9
Training loss: 0.8073700070381165
Validation loss: 2.1140492061773934

Epoch: 5| Step: 10
Training loss: 0.600799560546875
Validation loss: 2.1151654918988547

Epoch: 5| Step: 11
Training loss: 0.9410653114318848
Validation loss: 2.0758775571982064

Epoch: 170| Step: 0
Training loss: 1.0434092283248901
Validation loss: 2.1401174068450928

Epoch: 5| Step: 1
Training loss: 1.0822361707687378
Validation loss: 2.1313845266898475

Epoch: 5| Step: 2
Training loss: 0.6591309309005737
Validation loss: 2.140096286932627

Epoch: 5| Step: 3
Training loss: 0.5886150598526001
Validation loss: 2.1537369589010873

Epoch: 5| Step: 4
Training loss: 1.0995746850967407
Validation loss: 2.213999261458715

Epoch: 5| Step: 5
Training loss: 0.9729577302932739
Validation loss: 2.1581442455450692

Epoch: 5| Step: 6
Training loss: 0.6167075634002686
Validation loss: 2.1889227281014123

Epoch: 5| Step: 7
Training loss: 1.1029454469680786
Validation loss: 2.1753547290960946

Epoch: 5| Step: 8
Training loss: 0.915637195110321
Validation loss: 2.149813642104467

Epoch: 5| Step: 9
Training loss: 0.6096603274345398
Validation loss: 2.10100128253301

Epoch: 5| Step: 10
Training loss: 0.9584059715270996
Validation loss: 2.1319100807110467

Epoch: 5| Step: 11
Training loss: 0.3098495602607727
Validation loss: 2.1144828548034034

Epoch: 171| Step: 0
Training loss: 1.091572880744934
Validation loss: 2.104059269030889

Epoch: 5| Step: 1
Training loss: 0.7016748189926147
Validation loss: 2.1219216684500375

Epoch: 5| Step: 2
Training loss: 0.9460528492927551
Validation loss: 2.1071486373742423

Epoch: 5| Step: 3
Training loss: 0.9625856280326843
Validation loss: 2.1722483138243356

Epoch: 5| Step: 4
Training loss: 0.9231764674186707
Validation loss: 2.1087834487358728

Epoch: 5| Step: 5
Training loss: 0.5110705494880676
Validation loss: 2.1370576669772468

Epoch: 5| Step: 6
Training loss: 0.9799715280532837
Validation loss: 2.1846118718385696

Epoch: 5| Step: 7
Training loss: 0.611935019493103
Validation loss: 2.1620628982782364

Epoch: 5| Step: 8
Training loss: 0.7073591351509094
Validation loss: 2.0958415418863297

Epoch: 5| Step: 9
Training loss: 0.7482029795646667
Validation loss: 2.16111167271932

Epoch: 5| Step: 10
Training loss: 0.7852767705917358
Validation loss: 2.1854106187820435

Epoch: 5| Step: 11
Training loss: 0.6219794154167175
Validation loss: 2.1225910782814026

Epoch: 172| Step: 0
Training loss: 0.8215215802192688
Validation loss: 2.1449087113142014

Epoch: 5| Step: 1
Training loss: 1.1929285526275635
Validation loss: 2.1539718558390937

Epoch: 5| Step: 2
Training loss: 0.47790631651878357
Validation loss: 2.1568924486637115

Epoch: 5| Step: 3
Training loss: 0.9426347017288208
Validation loss: 2.120093355576197

Epoch: 5| Step: 4
Training loss: 0.5846274495124817
Validation loss: 2.201747715473175

Epoch: 5| Step: 5
Training loss: 0.7484172582626343
Validation loss: 2.140486399332682

Epoch: 5| Step: 6
Training loss: 0.8699105381965637
Validation loss: 2.1219796935717263

Epoch: 5| Step: 7
Training loss: 0.8247442245483398
Validation loss: 2.12899341682593

Epoch: 5| Step: 8
Training loss: 1.0995826721191406
Validation loss: 2.1790730406840644

Epoch: 5| Step: 9
Training loss: 0.6507858037948608
Validation loss: 2.1081188023090363

Epoch: 5| Step: 10
Training loss: 0.8362674713134766
Validation loss: 2.1160653630892434

Epoch: 5| Step: 11
Training loss: 0.9303799271583557
Validation loss: 2.1190906862417855

Epoch: 173| Step: 0
Training loss: 0.8103460073471069
Validation loss: 2.1514882594347

Epoch: 5| Step: 1
Training loss: 0.5262071490287781
Validation loss: 2.155254522959391

Epoch: 5| Step: 2
Training loss: 0.8625877499580383
Validation loss: 2.1128600438435874

Epoch: 5| Step: 3
Training loss: 0.6160918474197388
Validation loss: 2.1019641111294427

Epoch: 5| Step: 4
Training loss: 1.0149130821228027
Validation loss: 2.1216875513394675

Epoch: 5| Step: 5
Training loss: 1.3142037391662598
Validation loss: 2.154470066229502

Epoch: 5| Step: 6
Training loss: 0.8762208819389343
Validation loss: 2.097145343820254

Epoch: 5| Step: 7
Training loss: 0.6191698312759399
Validation loss: 2.1626472075780234

Epoch: 5| Step: 8
Training loss: 0.8643963932991028
Validation loss: 2.1487318724393845

Epoch: 5| Step: 9
Training loss: 0.8508483171463013
Validation loss: 2.1335375209649405

Epoch: 5| Step: 10
Training loss: 0.5623343586921692
Validation loss: 2.1490642627080283

Epoch: 5| Step: 11
Training loss: 0.343137264251709
Validation loss: 2.226416046420733

Epoch: 174| Step: 0
Training loss: 0.5132609605789185
Validation loss: 2.1445238888263702

Epoch: 5| Step: 1
Training loss: 1.280907392501831
Validation loss: 2.114088997244835

Epoch: 5| Step: 2
Training loss: 0.9308581352233887
Validation loss: 2.1330136756102243

Epoch: 5| Step: 3
Training loss: 0.6722387075424194
Validation loss: 2.124222988883654

Epoch: 5| Step: 4
Training loss: 0.5938924551010132
Validation loss: 2.115246057510376

Epoch: 5| Step: 5
Training loss: 0.7373859286308289
Validation loss: 2.1368021766344705

Epoch: 5| Step: 6
Training loss: 0.7355912923812866
Validation loss: 2.209966540336609

Epoch: 5| Step: 7
Training loss: 0.8940123319625854
Validation loss: 2.149138202269872

Epoch: 5| Step: 8
Training loss: 1.0735318660736084
Validation loss: 2.1762394408384957

Epoch: 5| Step: 9
Training loss: 1.0699762105941772
Validation loss: 2.182825634876887

Epoch: 5| Step: 10
Training loss: 0.6991154551506042
Validation loss: 2.0941711167494454

Epoch: 5| Step: 11
Training loss: 0.6328399181365967
Validation loss: 2.107736865679423

Epoch: 175| Step: 0
Training loss: 0.5481716990470886
Validation loss: 2.1202395061651864

Epoch: 5| Step: 1
Training loss: 0.7816958427429199
Validation loss: 2.12193471690019

Epoch: 5| Step: 2
Training loss: 0.7814555168151855
Validation loss: 2.116449842850367

Epoch: 5| Step: 3
Training loss: 0.9144250750541687
Validation loss: 2.157825509707133

Epoch: 5| Step: 4
Training loss: 0.9561570286750793
Validation loss: 2.1953727255264917

Epoch: 5| Step: 5
Training loss: 0.3326854109764099
Validation loss: 2.1208797742923102

Epoch: 5| Step: 6
Training loss: 0.8856128454208374
Validation loss: 2.1528367350498834

Epoch: 5| Step: 7
Training loss: 1.3548929691314697
Validation loss: 2.1063945343097052

Epoch: 5| Step: 8
Training loss: 0.5628752708435059
Validation loss: 2.085754926005999

Epoch: 5| Step: 9
Training loss: 0.6187822222709656
Validation loss: 2.0969514697790146

Epoch: 5| Step: 10
Training loss: 1.1888244152069092
Validation loss: 2.0954883297284446

Epoch: 5| Step: 11
Training loss: 0.2785228490829468
Validation loss: 2.0676847795645394

Epoch: 176| Step: 0
Training loss: 0.5777975916862488
Validation loss: 2.0901162922382355

Epoch: 5| Step: 1
Training loss: 1.0383455753326416
Validation loss: 2.1310248374938965

Epoch: 5| Step: 2
Training loss: 0.4585517942905426
Validation loss: 2.1747203717629113

Epoch: 5| Step: 3
Training loss: 0.6528976559638977
Validation loss: 2.1873161842425666

Epoch: 5| Step: 4
Training loss: 0.3563520312309265
Validation loss: 2.127918948729833

Epoch: 5| Step: 5
Training loss: 0.83526611328125
Validation loss: 2.1625221172968545

Epoch: 5| Step: 6
Training loss: 1.0489962100982666
Validation loss: 2.101615955432256

Epoch: 5| Step: 7
Training loss: 1.0482715368270874
Validation loss: 2.1652015844980874

Epoch: 5| Step: 8
Training loss: 0.5600484013557434
Validation loss: 2.1277801593144736

Epoch: 5| Step: 9
Training loss: 1.3561592102050781
Validation loss: 2.136186728874842

Epoch: 5| Step: 10
Training loss: 1.0381944179534912
Validation loss: 2.170422146717707

Epoch: 5| Step: 11
Training loss: 0.22132042050361633
Validation loss: 2.1125520964463553

Epoch: 177| Step: 0
Training loss: 1.4439284801483154
Validation loss: 2.0766982287168503

Epoch: 5| Step: 1
Training loss: 0.8364849090576172
Validation loss: 2.1644371151924133

Epoch: 5| Step: 2
Training loss: 0.7369023561477661
Validation loss: 2.1839785873889923

Epoch: 5| Step: 3
Training loss: 0.9411343336105347
Validation loss: 2.2270415971676507

Epoch: 5| Step: 4
Training loss: 0.6864933967590332
Validation loss: 2.2177190532286963

Epoch: 5| Step: 5
Training loss: 0.999188244342804
Validation loss: 2.2636315623919168

Epoch: 5| Step: 6
Training loss: 0.4878060221672058
Validation loss: 2.1715710759162903

Epoch: 5| Step: 7
Training loss: 0.4077071249485016
Validation loss: 2.1237307588259378

Epoch: 5| Step: 8
Training loss: 1.0030053853988647
Validation loss: 2.1198453406492868

Epoch: 5| Step: 9
Training loss: 0.9340798258781433
Validation loss: 2.088635891675949

Epoch: 5| Step: 10
Training loss: 0.9071847200393677
Validation loss: 2.096905454993248

Epoch: 5| Step: 11
Training loss: 0.8263729810714722
Validation loss: 2.1402718325455985

Epoch: 178| Step: 0
Training loss: 1.224743366241455
Validation loss: 2.131450672944387

Epoch: 5| Step: 1
Training loss: 0.6811478137969971
Validation loss: 2.1031745771567025

Epoch: 5| Step: 2
Training loss: 0.9796320199966431
Validation loss: 2.248482828338941

Epoch: 5| Step: 3
Training loss: 0.8525160551071167
Validation loss: 2.295809989174207

Epoch: 5| Step: 4
Training loss: 1.1088746786117554
Validation loss: 2.2913265973329544

Epoch: 5| Step: 5
Training loss: 1.5634797811508179
Validation loss: 2.281378666559855

Epoch: 5| Step: 6
Training loss: 0.8861209154129028
Validation loss: 2.257881373167038

Epoch: 5| Step: 7
Training loss: 0.7640087008476257
Validation loss: 2.133558288216591

Epoch: 5| Step: 8
Training loss: 0.6371795535087585
Validation loss: 2.104752396543821

Epoch: 5| Step: 9
Training loss: 0.6607485413551331
Validation loss: 2.0750679671764374

Epoch: 5| Step: 10
Training loss: 1.3883490562438965
Validation loss: 2.127149353424708

Epoch: 5| Step: 11
Training loss: 2.3425912857055664
Validation loss: 2.1336905856927237

Epoch: 179| Step: 0
Training loss: 1.0253236293792725
Validation loss: 2.1177605291207633

Epoch: 5| Step: 1
Training loss: 1.111270546913147
Validation loss: 2.1186218510071435

Epoch: 5| Step: 2
Training loss: 1.132177710533142
Validation loss: 2.0981878439585366

Epoch: 5| Step: 3
Training loss: 1.2809970378875732
Validation loss: 2.1539313743511834

Epoch: 5| Step: 4
Training loss: 0.9407142400741577
Validation loss: 2.1681500573952994

Epoch: 5| Step: 5
Training loss: 0.719125509262085
Validation loss: 2.282962510983149

Epoch: 5| Step: 6
Training loss: 0.9059903025627136
Validation loss: 2.2218755781650543

Epoch: 5| Step: 7
Training loss: 0.7347193956375122
Validation loss: 2.282487064599991

Epoch: 5| Step: 8
Training loss: 0.6901220083236694
Validation loss: 2.2116373429695764

Epoch: 5| Step: 9
Training loss: 0.8823026418685913
Validation loss: 2.139284541209539

Epoch: 5| Step: 10
Training loss: 0.9674226641654968
Validation loss: 2.132856289545695

Epoch: 5| Step: 11
Training loss: 0.6125520467758179
Validation loss: 2.1138239006201425

Epoch: 180| Step: 0
Training loss: 0.6282863616943359
Validation loss: 2.081159770488739

Epoch: 5| Step: 1
Training loss: 1.3488423824310303
Validation loss: 2.080023075143496

Epoch: 5| Step: 2
Training loss: 1.2976315021514893
Validation loss: 2.0742998520533242

Epoch: 5| Step: 3
Training loss: 0.6355894207954407
Validation loss: 2.097057595849037

Epoch: 5| Step: 4
Training loss: 0.508240282535553
Validation loss: 2.133085067073504

Epoch: 5| Step: 5
Training loss: 1.1003139019012451
Validation loss: 2.1153964747985206

Epoch: 5| Step: 6
Training loss: 0.3571451008319855
Validation loss: 2.1170678536097207

Epoch: 5| Step: 7
Training loss: 0.5435050129890442
Validation loss: 2.1315302699804306

Epoch: 5| Step: 8
Training loss: 1.0080667734146118
Validation loss: 2.140958641966184

Epoch: 5| Step: 9
Training loss: 0.8344545364379883
Validation loss: 2.163641725977262

Epoch: 5| Step: 10
Training loss: 0.8008297681808472
Validation loss: 2.0659783631563187

Epoch: 5| Step: 11
Training loss: 0.38059914112091064
Validation loss: 2.084961473941803

Epoch: 181| Step: 0
Training loss: 0.6849550008773804
Validation loss: 2.0305969268083572

Epoch: 5| Step: 1
Training loss: 0.9677532911300659
Validation loss: 2.044216970602671

Epoch: 5| Step: 2
Training loss: 0.6154834628105164
Validation loss: 2.077395955721537

Epoch: 5| Step: 3
Training loss: 0.8358068466186523
Validation loss: 2.10193932056427

Epoch: 5| Step: 4
Training loss: 0.7694166898727417
Validation loss: 2.075287406643232

Epoch: 5| Step: 5
Training loss: 0.8516042828559875
Validation loss: 2.117378756403923

Epoch: 5| Step: 6
Training loss: 1.1235005855560303
Validation loss: 2.136662463347117

Epoch: 5| Step: 7
Training loss: 1.005763292312622
Validation loss: 2.1595392376184464

Epoch: 5| Step: 8
Training loss: 0.6862512826919556
Validation loss: 2.1466289460659027

Epoch: 5| Step: 9
Training loss: 0.5726086497306824
Validation loss: 2.1383833487828574

Epoch: 5| Step: 10
Training loss: 0.7649588584899902
Validation loss: 2.0779137363036475

Epoch: 5| Step: 11
Training loss: 0.24833357334136963
Validation loss: 2.0929150581359863

Epoch: 182| Step: 0
Training loss: 0.8262864351272583
Validation loss: 2.1442424803972244

Epoch: 5| Step: 1
Training loss: 0.5757166743278503
Validation loss: 2.131600091854731

Epoch: 5| Step: 2
Training loss: 1.0476993322372437
Validation loss: 2.1219680110613504

Epoch: 5| Step: 3
Training loss: 0.972746729850769
Validation loss: 2.1371667881806693

Epoch: 5| Step: 4
Training loss: 0.9642063975334167
Validation loss: 2.1339698235193887

Epoch: 5| Step: 5
Training loss: 0.742845356464386
Validation loss: 2.14732293287913

Epoch: 5| Step: 6
Training loss: 1.0449602603912354
Validation loss: 2.1698245108127594

Epoch: 5| Step: 7
Training loss: 0.3201755881309509
Validation loss: 2.1763025522232056

Epoch: 5| Step: 8
Training loss: 0.8987380862236023
Validation loss: 2.192416707674662

Epoch: 5| Step: 9
Training loss: 0.6511296033859253
Validation loss: 2.185809756318728

Epoch: 5| Step: 10
Training loss: 0.602874755859375
Validation loss: 2.227120270331701

Epoch: 5| Step: 11
Training loss: 1.1650606393814087
Validation loss: 2.12462309996287

Epoch: 183| Step: 0
Training loss: 0.7425457239151001
Validation loss: 2.12761581937472

Epoch: 5| Step: 1
Training loss: 0.6078755259513855
Validation loss: 2.1409838795661926

Epoch: 5| Step: 2
Training loss: 1.0256038904190063
Validation loss: 2.1291091044743857

Epoch: 5| Step: 3
Training loss: 0.7450389266014099
Validation loss: 2.104764401912689

Epoch: 5| Step: 4
Training loss: 1.0960919857025146
Validation loss: 2.1611454288164773

Epoch: 5| Step: 5
Training loss: 0.6961308717727661
Validation loss: 2.170945127805074

Epoch: 5| Step: 6
Training loss: 0.7741190791130066
Validation loss: 2.254114200671514

Epoch: 5| Step: 7
Training loss: 1.1922762393951416
Validation loss: 2.292884369691213

Epoch: 5| Step: 8
Training loss: 0.8728830218315125
Validation loss: 2.2520430783430734

Epoch: 5| Step: 9
Training loss: 1.1509182453155518
Validation loss: 2.227930227915446

Epoch: 5| Step: 10
Training loss: 0.8597649335861206
Validation loss: 2.2016854484876

Epoch: 5| Step: 11
Training loss: 0.7201162576675415
Validation loss: 2.173156355818113

Epoch: 184| Step: 0
Training loss: 1.2185258865356445
Validation loss: 2.1584302683671317

Epoch: 5| Step: 1
Training loss: 0.8308300971984863
Validation loss: 2.0739626636107764

Epoch: 5| Step: 2
Training loss: 0.7156249284744263
Validation loss: 2.08854145805041

Epoch: 5| Step: 3
Training loss: 0.503531277179718
Validation loss: 2.119592532515526

Epoch: 5| Step: 4
Training loss: 0.9439123868942261
Validation loss: 2.1704504092534385

Epoch: 5| Step: 5
Training loss: 0.6095529794692993
Validation loss: 2.1874179194370904

Epoch: 5| Step: 6
Training loss: 1.1740012168884277
Validation loss: 2.239327331384023

Epoch: 5| Step: 7
Training loss: 0.9418352246284485
Validation loss: 2.239298199613889

Epoch: 5| Step: 8
Training loss: 0.7054826021194458
Validation loss: 2.198736866315206

Epoch: 5| Step: 9
Training loss: 0.7032399773597717
Validation loss: 2.1777642369270325

Epoch: 5| Step: 10
Training loss: 0.43226462602615356
Validation loss: 2.1404472986857095

Epoch: 5| Step: 11
Training loss: 2.1154401302337646
Validation loss: 2.1135462522506714

Epoch: 185| Step: 0
Training loss: 0.48489683866500854
Validation loss: 2.1308233390251794

Epoch: 5| Step: 1
Training loss: 1.100401520729065
Validation loss: 2.1344684263070426

Epoch: 5| Step: 2
Training loss: 0.3443743586540222
Validation loss: 2.1041994988918304

Epoch: 5| Step: 3
Training loss: 0.9161332845687866
Validation loss: 2.166324476401011

Epoch: 5| Step: 4
Training loss: 0.718849241733551
Validation loss: 2.145907461643219

Epoch: 5| Step: 5
Training loss: 0.5194917917251587
Validation loss: 2.1535100986560187

Epoch: 5| Step: 6
Training loss: 0.7789020538330078
Validation loss: 2.160112942258517

Epoch: 5| Step: 7
Training loss: 0.9994146227836609
Validation loss: 2.172976866364479

Epoch: 5| Step: 8
Training loss: 0.9108495712280273
Validation loss: 2.188019255797068

Epoch: 5| Step: 9
Training loss: 0.7586674094200134
Validation loss: 2.124259874224663

Epoch: 5| Step: 10
Training loss: 0.7128490805625916
Validation loss: 2.126526723305384

Epoch: 5| Step: 11
Training loss: 0.28400886058807373
Validation loss: 2.0930781910816827

Epoch: 186| Step: 0
Training loss: 0.6555184125900269
Validation loss: 2.1543168326218924

Epoch: 5| Step: 1
Training loss: 0.5241504907608032
Validation loss: 2.131125181913376

Epoch: 5| Step: 2
Training loss: 0.6423269510269165
Validation loss: 2.1597391863663993

Epoch: 5| Step: 3
Training loss: 0.29810094833374023
Validation loss: 2.160611942410469

Epoch: 5| Step: 4
Training loss: 0.8284939527511597
Validation loss: 2.1767742534478507

Epoch: 5| Step: 5
Training loss: 0.8360764384269714
Validation loss: 2.1148375819126763

Epoch: 5| Step: 6
Training loss: 0.6442615389823914
Validation loss: 2.142451375722885

Epoch: 5| Step: 7
Training loss: 0.6474707126617432
Validation loss: 2.17755592862765

Epoch: 5| Step: 8
Training loss: 0.8354058265686035
Validation loss: 2.128109648823738

Epoch: 5| Step: 9
Training loss: 1.2051434516906738
Validation loss: 2.1631888250509896

Epoch: 5| Step: 10
Training loss: 0.8810647130012512
Validation loss: 2.1163201133410134

Epoch: 5| Step: 11
Training loss: 0.43557989597320557
Validation loss: 2.1409978369871774

Epoch: 187| Step: 0
Training loss: 0.30452054738998413
Validation loss: 2.1504999895890555

Epoch: 5| Step: 1
Training loss: 0.9977536201477051
Validation loss: 2.176665569345156

Epoch: 5| Step: 2
Training loss: 0.6524691581726074
Validation loss: 2.138717919588089

Epoch: 5| Step: 3
Training loss: 0.7042689323425293
Validation loss: 2.152181009451548

Epoch: 5| Step: 4
Training loss: 1.0527817010879517
Validation loss: 2.130189617474874

Epoch: 5| Step: 5
Training loss: 0.532780647277832
Validation loss: 2.164741188287735

Epoch: 5| Step: 6
Training loss: 0.7043245434761047
Validation loss: 2.1427098214626312

Epoch: 5| Step: 7
Training loss: 0.9152928590774536
Validation loss: 2.226274530092875

Epoch: 5| Step: 8
Training loss: 0.8533719778060913
Validation loss: 2.207639237244924

Epoch: 5| Step: 9
Training loss: 0.9030414819717407
Validation loss: 2.2064971923828125

Epoch: 5| Step: 10
Training loss: 0.6121140718460083
Validation loss: 2.1202574372291565

Epoch: 5| Step: 11
Training loss: 0.8162850737571716
Validation loss: 2.1253912895917892

Epoch: 188| Step: 0
Training loss: 1.2201249599456787
Validation loss: 2.1089338461558023

Epoch: 5| Step: 1
Training loss: 0.7352232933044434
Validation loss: 2.113822023073832

Epoch: 5| Step: 2
Training loss: 0.7023933529853821
Validation loss: 2.108678008119265

Epoch: 5| Step: 3
Training loss: 0.7680066227912903
Validation loss: 2.128241961201032

Epoch: 5| Step: 4
Training loss: 0.5276459455490112
Validation loss: 2.1559459467728934

Epoch: 5| Step: 5
Training loss: 0.5945302248001099
Validation loss: 2.160983140269915

Epoch: 5| Step: 6
Training loss: 0.7175801396369934
Validation loss: 2.1713748474915824

Epoch: 5| Step: 7
Training loss: 0.9255620241165161
Validation loss: 2.1714786887168884

Epoch: 5| Step: 8
Training loss: 0.3937559127807617
Validation loss: 2.146698907017708

Epoch: 5| Step: 9
Training loss: 0.6654137372970581
Validation loss: 2.114361653725306

Epoch: 5| Step: 10
Training loss: 1.2683013677597046
Validation loss: 2.154564286271731

Epoch: 5| Step: 11
Training loss: 0.45079901814460754
Validation loss: 2.161817967891693

Epoch: 189| Step: 0
Training loss: 0.6467148065567017
Validation loss: 2.1395734002192817

Epoch: 5| Step: 1
Training loss: 0.5159436464309692
Validation loss: 2.1301503082116446

Epoch: 5| Step: 2
Training loss: 0.6435874700546265
Validation loss: 2.1697418143351874

Epoch: 5| Step: 3
Training loss: 0.35618525743484497
Validation loss: 2.1280031154553094

Epoch: 5| Step: 4
Training loss: 0.9866896867752075
Validation loss: 2.168777654568354

Epoch: 5| Step: 5
Training loss: 0.8192042112350464
Validation loss: 2.199136565128962

Epoch: 5| Step: 6
Training loss: 0.6687585711479187
Validation loss: 2.2014213850100837

Epoch: 5| Step: 7
Training loss: 0.38375261425971985
Validation loss: 2.166233832637469

Epoch: 5| Step: 8
Training loss: 0.9298421740531921
Validation loss: 2.191415806611379

Epoch: 5| Step: 9
Training loss: 1.4871803522109985
Validation loss: 2.130439798037211

Epoch: 5| Step: 10
Training loss: 0.6559644937515259
Validation loss: 2.1207318107287088

Epoch: 5| Step: 11
Training loss: 0.46897488832473755
Validation loss: 2.151105304559072

Epoch: 190| Step: 0
Training loss: 0.8611053228378296
Validation loss: 2.174499899148941

Epoch: 5| Step: 1
Training loss: 0.5538510084152222
Validation loss: 2.173432856798172

Epoch: 5| Step: 2
Training loss: 0.8356019854545593
Validation loss: 2.203029120961825

Epoch: 5| Step: 3
Training loss: 1.187868595123291
Validation loss: 2.1366173028945923

Epoch: 5| Step: 4
Training loss: 1.3448654413223267
Validation loss: 2.138099282979965

Epoch: 5| Step: 5
Training loss: 0.5024265050888062
Validation loss: 2.136370539665222

Epoch: 5| Step: 6
Training loss: 0.3308120369911194
Validation loss: 2.172275890906652

Epoch: 5| Step: 7
Training loss: 0.44289660453796387
Validation loss: 2.1354633371035256

Epoch: 5| Step: 8
Training loss: 0.672524094581604
Validation loss: 2.176835988958677

Epoch: 5| Step: 9
Training loss: 0.5197286605834961
Validation loss: 2.1320886413256326

Epoch: 5| Step: 10
Training loss: 0.8504582643508911
Validation loss: 2.161115104953448

Epoch: 5| Step: 11
Training loss: 0.1349671483039856
Validation loss: 2.15456023812294

Epoch: 191| Step: 0
Training loss: 1.6276209354400635
Validation loss: 2.21721983452638

Epoch: 5| Step: 1
Training loss: 0.631299614906311
Validation loss: 2.214217096567154

Epoch: 5| Step: 2
Training loss: 0.42510414123535156
Validation loss: 2.1982184996207557

Epoch: 5| Step: 3
Training loss: 1.050208330154419
Validation loss: 2.1766832570234933

Epoch: 5| Step: 4
Training loss: 0.6184819936752319
Validation loss: 2.2166992525259652

Epoch: 5| Step: 5
Training loss: 0.9558665156364441
Validation loss: 2.157624031106631

Epoch: 5| Step: 6
Training loss: 0.6072036623954773
Validation loss: 2.1378523657719293

Epoch: 5| Step: 7
Training loss: 0.5423167943954468
Validation loss: 2.1165706465641656

Epoch: 5| Step: 8
Training loss: 0.7021743059158325
Validation loss: 2.133758470416069

Epoch: 5| Step: 9
Training loss: 0.6410325169563293
Validation loss: 2.1476911505063376

Epoch: 5| Step: 10
Training loss: 0.5721014738082886
Validation loss: 2.1952711939811707

Epoch: 5| Step: 11
Training loss: 1.0990928411483765
Validation loss: 2.1885863095521927

Epoch: 192| Step: 0
Training loss: 0.5421443581581116
Validation loss: 2.2045257488886514

Epoch: 5| Step: 1
Training loss: 0.7898391485214233
Validation loss: 2.1960607121388116

Epoch: 5| Step: 2
Training loss: 0.8983087539672852
Validation loss: 2.161970684925715

Epoch: 5| Step: 3
Training loss: 0.6735671162605286
Validation loss: 2.1539831211169562

Epoch: 5| Step: 4
Training loss: 0.34542807936668396
Validation loss: 2.14991761247317

Epoch: 5| Step: 5
Training loss: 0.4951601028442383
Validation loss: 2.1225109497706094

Epoch: 5| Step: 6
Training loss: 0.4773980975151062
Validation loss: 2.1701609194278717

Epoch: 5| Step: 7
Training loss: 0.5007199048995972
Validation loss: 2.1347373922665915

Epoch: 5| Step: 8
Training loss: 0.8730400204658508
Validation loss: 2.1576024989287057

Epoch: 5| Step: 9
Training loss: 1.6458044052124023
Validation loss: 2.122191791733106

Epoch: 5| Step: 10
Training loss: 0.7547341585159302
Validation loss: 2.2249324520428977

Epoch: 5| Step: 11
Training loss: 0.9144584536552429
Validation loss: 2.173964351415634

Epoch: 193| Step: 0
Training loss: 0.7573418021202087
Validation loss: 2.167571559548378

Epoch: 5| Step: 1
Training loss: 0.6048370003700256
Validation loss: 2.1898348182439804

Epoch: 5| Step: 2
Training loss: 0.6835607290267944
Validation loss: 2.1588532427946725

Epoch: 5| Step: 3
Training loss: 1.1122854948043823
Validation loss: 2.117875690261523

Epoch: 5| Step: 4
Training loss: 0.5218678712844849
Validation loss: 2.1379989087581635

Epoch: 5| Step: 5
Training loss: 0.5340343713760376
Validation loss: 2.1212153285741806

Epoch: 5| Step: 6
Training loss: 0.9468580484390259
Validation loss: 2.1626438101132712

Epoch: 5| Step: 7
Training loss: 0.8950484991073608
Validation loss: 2.158799802263578

Epoch: 5| Step: 8
Training loss: 0.5755752325057983
Validation loss: 2.1144538670778275

Epoch: 5| Step: 9
Training loss: 0.6106945872306824
Validation loss: 2.154077226916949

Epoch: 5| Step: 10
Training loss: 0.6082109212875366
Validation loss: 2.1777714093526206

Epoch: 5| Step: 11
Training loss: 0.4426983594894409
Validation loss: 2.1813184221585593

Epoch: 194| Step: 0
Training loss: 0.643693745136261
Validation loss: 2.181925813357035

Epoch: 5| Step: 1
Training loss: 0.6841778755187988
Validation loss: 2.140927309791247

Epoch: 5| Step: 2
Training loss: 0.7059260606765747
Validation loss: 2.1709676682949066

Epoch: 5| Step: 3
Training loss: 0.8465906381607056
Validation loss: 2.1057306031386056

Epoch: 5| Step: 4
Training loss: 0.6652461886405945
Validation loss: 2.131219873825709

Epoch: 5| Step: 5
Training loss: 0.3217148184776306
Validation loss: 2.102948382496834

Epoch: 5| Step: 6
Training loss: 0.824258029460907
Validation loss: 2.174100269873937

Epoch: 5| Step: 7
Training loss: 0.672278881072998
Validation loss: 2.155214617649714

Epoch: 5| Step: 8
Training loss: 0.6837025284767151
Validation loss: 2.1732694705327353

Epoch: 5| Step: 9
Training loss: 0.5939947962760925
Validation loss: 2.1086333245038986

Epoch: 5| Step: 10
Training loss: 0.9936428070068359
Validation loss: 2.164678340156873

Epoch: 5| Step: 11
Training loss: 0.7696995139122009
Validation loss: 2.1370648642381034

Epoch: 195| Step: 0
Training loss: 0.6083641052246094
Validation loss: 2.130740394194921

Epoch: 5| Step: 1
Training loss: 1.1068919897079468
Validation loss: 2.165104697148005

Epoch: 5| Step: 2
Training loss: 0.8173394203186035
Validation loss: 2.158345157901446

Epoch: 5| Step: 3
Training loss: 0.8403574824333191
Validation loss: 2.177117904027303

Epoch: 5| Step: 4
Training loss: 0.5118058919906616
Validation loss: 2.0887869199117026

Epoch: 5| Step: 5
Training loss: 0.4126344621181488
Validation loss: 2.1678658525149026

Epoch: 5| Step: 6
Training loss: 0.9962396621704102
Validation loss: 2.1657819598913193

Epoch: 5| Step: 7
Training loss: 0.8037464022636414
Validation loss: 2.134961967666944

Epoch: 5| Step: 8
Training loss: 0.5479419827461243
Validation loss: 2.166057586669922

Epoch: 5| Step: 9
Training loss: 0.8171811103820801
Validation loss: 2.1901480307181678

Epoch: 5| Step: 10
Training loss: 0.6460059881210327
Validation loss: 2.1901250084241233

Epoch: 5| Step: 11
Training loss: 0.6500969529151917
Validation loss: 2.1640280038118362

Epoch: 196| Step: 0
Training loss: 0.843880832195282
Validation loss: 2.1780016670624414

Epoch: 5| Step: 1
Training loss: 0.3219450116157532
Validation loss: 2.15898726383845

Epoch: 5| Step: 2
Training loss: 0.6729322671890259
Validation loss: 2.1447035372257233

Epoch: 5| Step: 3
Training loss: 1.051868200302124
Validation loss: 2.0723535418510437

Epoch: 5| Step: 4
Training loss: 0.8875665664672852
Validation loss: 2.1140898764133453

Epoch: 5| Step: 5
Training loss: 0.49851351976394653
Validation loss: 2.143033509453138

Epoch: 5| Step: 6
Training loss: 0.5199514627456665
Validation loss: 2.1486157973607383

Epoch: 5| Step: 7
Training loss: 0.825515627861023
Validation loss: 2.1091139068206153

Epoch: 5| Step: 8
Training loss: 0.987396240234375
Validation loss: 2.1541185528039932

Epoch: 5| Step: 9
Training loss: 0.47785553336143494
Validation loss: 2.1968988180160522

Epoch: 5| Step: 10
Training loss: 0.600448489189148
Validation loss: 2.22912605603536

Epoch: 5| Step: 11
Training loss: 0.9955451488494873
Validation loss: 2.2629245022932687

Epoch: 197| Step: 0
Training loss: 0.5618678331375122
Validation loss: 2.184131701787313

Epoch: 5| Step: 1
Training loss: 0.8968544006347656
Validation loss: 2.13047024110953

Epoch: 5| Step: 2
Training loss: 0.7173043489456177
Validation loss: 2.099512060483297

Epoch: 5| Step: 3
Training loss: 0.9898263216018677
Validation loss: 2.1225876013437905

Epoch: 5| Step: 4
Training loss: 1.0706062316894531
Validation loss: 2.0989178319772086

Epoch: 5| Step: 5
Training loss: 0.6343511343002319
Validation loss: 2.1122198700904846

Epoch: 5| Step: 6
Training loss: 0.2722524106502533
Validation loss: 2.149083952109019

Epoch: 5| Step: 7
Training loss: 0.6457926630973816
Validation loss: 2.2105913956960044

Epoch: 5| Step: 8
Training loss: 0.6119179725646973
Validation loss: 2.181521395842234

Epoch: 5| Step: 9
Training loss: 0.582821249961853
Validation loss: 2.1828512102365494

Epoch: 5| Step: 10
Training loss: 0.9742063283920288
Validation loss: 2.225613757967949

Epoch: 5| Step: 11
Training loss: 1.598215103149414
Validation loss: 2.121158629655838

Epoch: 198| Step: 0
Training loss: 0.5066678524017334
Validation loss: 2.160007566213608

Epoch: 5| Step: 1
Training loss: 0.23910245299339294
Validation loss: 2.1646443754434586

Epoch: 5| Step: 2
Training loss: 0.4836856722831726
Validation loss: 2.17995955546697

Epoch: 5| Step: 3
Training loss: 1.1107252836227417
Validation loss: 2.1984655310710273

Epoch: 5| Step: 4
Training loss: 0.6173022389411926
Validation loss: 2.2027549048264823

Epoch: 5| Step: 5
Training loss: 0.5950678586959839
Validation loss: 2.185881848136584

Epoch: 5| Step: 6
Training loss: 0.8495723009109497
Validation loss: 2.20684082309405

Epoch: 5| Step: 7
Training loss: 0.9033514261245728
Validation loss: 2.1750179678201675

Epoch: 5| Step: 8
Training loss: 0.7003296613693237
Validation loss: 2.199375053246816

Epoch: 5| Step: 9
Training loss: 0.793289065361023
Validation loss: 2.19183578590552

Epoch: 5| Step: 10
Training loss: 0.46606549620628357
Validation loss: 2.1853329042593637

Epoch: 5| Step: 11
Training loss: 0.42072927951812744
Validation loss: 2.1976231733957925

Epoch: 199| Step: 0
Training loss: 0.4182921350002289
Validation loss: 2.2215757171312966

Epoch: 5| Step: 1
Training loss: 0.7722973227500916
Validation loss: 2.181728055079778

Epoch: 5| Step: 2
Training loss: 0.5537392497062683
Validation loss: 2.2020042141278586

Epoch: 5| Step: 3
Training loss: 0.8786457180976868
Validation loss: 2.1941794554392495

Epoch: 5| Step: 4
Training loss: 0.8090880513191223
Validation loss: 2.1502789358297982

Epoch: 5| Step: 5
Training loss: 0.3620530962944031
Validation loss: 2.145308166742325

Epoch: 5| Step: 6
Training loss: 1.0610072612762451
Validation loss: 2.2031299819548926

Epoch: 5| Step: 7
Training loss: 0.545610249042511
Validation loss: 2.1514833023150763

Epoch: 5| Step: 8
Training loss: 0.27979254722595215
Validation loss: 2.1992667615413666

Epoch: 5| Step: 9
Training loss: 0.8429625630378723
Validation loss: 2.1647664457559586

Epoch: 5| Step: 10
Training loss: 0.9096742868423462
Validation loss: 2.190691997607549

Epoch: 5| Step: 11
Training loss: 0.26161646842956543
Validation loss: 2.108398069938024

Epoch: 200| Step: 0
Training loss: 0.38402485847473145
Validation loss: 2.1275130063295364

Epoch: 5| Step: 1
Training loss: 0.46741360425949097
Validation loss: 2.192564388116201

Epoch: 5| Step: 2
Training loss: 0.5284589529037476
Validation loss: 2.179852172732353

Epoch: 5| Step: 3
Training loss: 0.8983204960823059
Validation loss: 2.213292251030604

Epoch: 5| Step: 4
Training loss: 0.5071167349815369
Validation loss: 2.1759629249572754

Epoch: 5| Step: 5
Training loss: 0.39531999826431274
Validation loss: 2.1647703697284064

Epoch: 5| Step: 6
Training loss: 0.8542410731315613
Validation loss: 2.2134629487991333

Epoch: 5| Step: 7
Training loss: 0.8632038235664368
Validation loss: 2.0964533388614655

Epoch: 5| Step: 8
Training loss: 1.3038394451141357
Validation loss: 2.153169905145963

Epoch: 5| Step: 9
Training loss: 0.5479039549827576
Validation loss: 2.095100477337837

Epoch: 5| Step: 10
Training loss: 0.44558778405189514
Validation loss: 2.190679262081782

Epoch: 5| Step: 11
Training loss: 0.23351678252220154
Validation loss: 2.1308006793260574

Epoch: 201| Step: 0
Training loss: 0.4068949222564697
Validation loss: 2.1914033194382987

Epoch: 5| Step: 1
Training loss: 0.5707645416259766
Validation loss: 2.195204878846804

Epoch: 5| Step: 2
Training loss: 0.39568501710891724
Validation loss: 2.172498345375061

Epoch: 5| Step: 3
Training loss: 0.8210992813110352
Validation loss: 2.1540605227152505

Epoch: 5| Step: 4
Training loss: 0.7976093292236328
Validation loss: 2.16136501232783

Epoch: 5| Step: 5
Training loss: 1.0902076959609985
Validation loss: 2.160434529185295

Epoch: 5| Step: 6
Training loss: 0.7156147956848145
Validation loss: 2.1091128985087075

Epoch: 5| Step: 7
Training loss: 1.1493844985961914
Validation loss: 2.1139597445726395

Epoch: 5| Step: 8
Training loss: 0.7138408422470093
Validation loss: 2.169891575972239

Epoch: 5| Step: 9
Training loss: 0.5644210577011108
Validation loss: 2.1422150979439416

Epoch: 5| Step: 10
Training loss: 0.6285964846611023
Validation loss: 2.103643154104551

Epoch: 5| Step: 11
Training loss: 0.46192121505737305
Validation loss: 2.1405407389005027

Epoch: 202| Step: 0
Training loss: 0.5355233550071716
Validation loss: 2.215047150850296

Epoch: 5| Step: 1
Training loss: 1.211748480796814
Validation loss: 2.266046086947123

Epoch: 5| Step: 2
Training loss: 0.6343839764595032
Validation loss: 2.2277407745520272

Epoch: 5| Step: 3
Training loss: 0.8250110745429993
Validation loss: 2.1820016354322433

Epoch: 5| Step: 4
Training loss: 1.0538192987442017
Validation loss: 2.198444575071335

Epoch: 5| Step: 5
Training loss: 0.7838455438613892
Validation loss: 2.1420971055825553

Epoch: 5| Step: 6
Training loss: 0.6477287411689758
Validation loss: 2.0991127441326776

Epoch: 5| Step: 7
Training loss: 0.6893997192382812
Validation loss: 2.150052179892858

Epoch: 5| Step: 8
Training loss: 0.35816681385040283
Validation loss: 2.1868596275647483

Epoch: 5| Step: 9
Training loss: 0.616761326789856
Validation loss: 2.1834364285071692

Epoch: 5| Step: 10
Training loss: 0.44061923027038574
Validation loss: 2.1759777814149857

Epoch: 5| Step: 11
Training loss: 0.21210798621177673
Validation loss: 2.168352554241816

Epoch: 203| Step: 0
Training loss: 0.4783552289009094
Validation loss: 2.158879672487577

Epoch: 5| Step: 1
Training loss: 0.995531439781189
Validation loss: 2.1930315295855203

Epoch: 5| Step: 2
Training loss: 0.7432464361190796
Validation loss: 2.2392190347115197

Epoch: 5| Step: 3
Training loss: 0.5284892320632935
Validation loss: 2.1779358933369317

Epoch: 5| Step: 4
Training loss: 0.3664541244506836
Validation loss: 2.105727051695188

Epoch: 5| Step: 5
Training loss: 0.6841776371002197
Validation loss: 2.1552872955799103

Epoch: 5| Step: 6
Training loss: 0.9077879190444946
Validation loss: 2.2204520851373672

Epoch: 5| Step: 7
Training loss: 0.5559884905815125
Validation loss: 2.1140144616365433

Epoch: 5| Step: 8
Training loss: 0.9435529708862305
Validation loss: 2.164425159494082

Epoch: 5| Step: 9
Training loss: 0.46934086084365845
Validation loss: 2.18974602719148

Epoch: 5| Step: 10
Training loss: 0.7442615628242493
Validation loss: 2.229081948598226

Epoch: 5| Step: 11
Training loss: 0.3373357057571411
Validation loss: 2.1483648916085563

Epoch: 204| Step: 0
Training loss: 0.3007919192314148
Validation loss: 2.108971724907557

Epoch: 5| Step: 1
Training loss: 0.44125643372535706
Validation loss: 2.1318077395359674

Epoch: 5| Step: 2
Training loss: 0.9770759344100952
Validation loss: 2.183084006110827

Epoch: 5| Step: 3
Training loss: 0.8066722750663757
Validation loss: 2.1213719695806503

Epoch: 5| Step: 4
Training loss: 0.5350682139396667
Validation loss: 2.089313422640165

Epoch: 5| Step: 5
Training loss: 0.7265541553497314
Validation loss: 2.1573954870303473

Epoch: 5| Step: 6
Training loss: 0.4539243280887604
Validation loss: 2.1987449675798416

Epoch: 5| Step: 7
Training loss: 0.47069764137268066
Validation loss: 2.170553187529246

Epoch: 5| Step: 8
Training loss: 0.9228490591049194
Validation loss: 2.1615545749664307

Epoch: 5| Step: 9
Training loss: 0.6217567920684814
Validation loss: 2.1772811015446982

Epoch: 5| Step: 10
Training loss: 0.9840772747993469
Validation loss: 2.1901313165823617

Epoch: 5| Step: 11
Training loss: 0.13918954133987427
Validation loss: 2.1363521267970405

Epoch: 205| Step: 0
Training loss: 0.6906368732452393
Validation loss: 2.104754224419594

Epoch: 5| Step: 1
Training loss: 0.7086647152900696
Validation loss: 2.1101766924063363

Epoch: 5| Step: 2
Training loss: 0.5132410526275635
Validation loss: 2.09263983865579

Epoch: 5| Step: 3
Training loss: 0.8016276359558105
Validation loss: 2.119081045190493

Epoch: 5| Step: 4
Training loss: 0.6529771089553833
Validation loss: 2.1251385460297265

Epoch: 5| Step: 5
Training loss: 0.5683981776237488
Validation loss: 2.1097300251324973

Epoch: 5| Step: 6
Training loss: 0.5173757672309875
Validation loss: 2.137069841225942

Epoch: 5| Step: 7
Training loss: 0.650128960609436
Validation loss: 2.16135927538077

Epoch: 5| Step: 8
Training loss: 0.7390633821487427
Validation loss: 2.1858518620332084

Epoch: 5| Step: 9
Training loss: 0.43410611152648926
Validation loss: 2.1866383304198584

Epoch: 5| Step: 10
Training loss: 0.9911935925483704
Validation loss: 2.1519095599651337

Epoch: 5| Step: 11
Training loss: 0.4572589099407196
Validation loss: 2.1177806506554284

Epoch: 206| Step: 0
Training loss: 0.3139643967151642
Validation loss: 2.1126863757769265

Epoch: 5| Step: 1
Training loss: 0.6660281419754028
Validation loss: 2.1170648833115897

Epoch: 5| Step: 2
Training loss: 0.7702258229255676
Validation loss: 2.2021105686823526

Epoch: 5| Step: 3
Training loss: 0.637035071849823
Validation loss: 2.1530350695053735

Epoch: 5| Step: 4
Training loss: 0.9643701314926147
Validation loss: 2.1575907270113626

Epoch: 5| Step: 5
Training loss: 0.4501243531703949
Validation loss: 2.1430093894402185

Epoch: 5| Step: 6
Training loss: 0.3527233600616455
Validation loss: 2.1496411859989166

Epoch: 5| Step: 7
Training loss: 0.751386284828186
Validation loss: 2.1687733183304467

Epoch: 5| Step: 8
Training loss: 0.7272129058837891
Validation loss: 2.099247097969055

Epoch: 5| Step: 9
Training loss: 0.7273027300834656
Validation loss: 2.169352119167646

Epoch: 5| Step: 10
Training loss: 0.5014177560806274
Validation loss: 2.1251958509286246

Epoch: 5| Step: 11
Training loss: 0.4056738615036011
Validation loss: 2.1995584269364676

Epoch: 207| Step: 0
Training loss: 0.8638252019882202
Validation loss: 2.2044678827126822

Epoch: 5| Step: 1
Training loss: 0.860009491443634
Validation loss: 2.2336202959219613

Epoch: 5| Step: 2
Training loss: 0.5281532406806946
Validation loss: 2.1844229896863303

Epoch: 5| Step: 3
Training loss: 0.46842795610427856
Validation loss: 2.177554269631704

Epoch: 5| Step: 4
Training loss: 0.6759978532791138
Validation loss: 2.0839176376660666

Epoch: 5| Step: 5
Training loss: 0.689620852470398
Validation loss: 2.1158830672502518

Epoch: 5| Step: 6
Training loss: 0.6142129302024841
Validation loss: 2.0782080044349036

Epoch: 5| Step: 7
Training loss: 0.8463131189346313
Validation loss: 2.1748598466316857

Epoch: 5| Step: 8
Training loss: 0.3625717759132385
Validation loss: 2.1901234736045203

Epoch: 5| Step: 9
Training loss: 0.8379200100898743
Validation loss: 2.2165326178073883

Epoch: 5| Step: 10
Training loss: 0.6785333752632141
Validation loss: 2.1898256738980613

Epoch: 5| Step: 11
Training loss: 0.5108327865600586
Validation loss: 2.1431355277697244

Epoch: 208| Step: 0
Training loss: 0.551776111125946
Validation loss: 2.168425386150678

Epoch: 5| Step: 1
Training loss: 0.37061575055122375
Validation loss: 2.1756273160378137

Epoch: 5| Step: 2
Training loss: 1.0276415348052979
Validation loss: 2.1427544156710305

Epoch: 5| Step: 3
Training loss: 0.7471349835395813
Validation loss: 2.1371863881746926

Epoch: 5| Step: 4
Training loss: 0.6884621381759644
Validation loss: 2.142298251390457

Epoch: 5| Step: 5
Training loss: 0.6963075399398804
Validation loss: 2.121596038341522

Epoch: 5| Step: 6
Training loss: 0.5650237202644348
Validation loss: 2.1435143848260245

Epoch: 5| Step: 7
Training loss: 0.5703760385513306
Validation loss: 2.1295461853345237

Epoch: 5| Step: 8
Training loss: 0.7079175710678101
Validation loss: 2.1562661131223044

Epoch: 5| Step: 9
Training loss: 0.7330187559127808
Validation loss: 2.131440391143163

Epoch: 5| Step: 10
Training loss: 0.38735032081604004
Validation loss: 2.135103856523832

Epoch: 5| Step: 11
Training loss: 0.34648215770721436
Validation loss: 2.1409563521544137

Epoch: 209| Step: 0
Training loss: 0.3978170156478882
Validation loss: 2.19755553205808

Epoch: 5| Step: 1
Training loss: 0.6473273038864136
Validation loss: 2.2199267596006393

Epoch: 5| Step: 2
Training loss: 0.808139979839325
Validation loss: 2.1869948407014212

Epoch: 5| Step: 3
Training loss: 0.7471656799316406
Validation loss: 2.182232141494751

Epoch: 5| Step: 4
Training loss: 0.36443203687667847
Validation loss: 2.184473673502604

Epoch: 5| Step: 5
Training loss: 0.6229338645935059
Validation loss: 2.1456897457440696

Epoch: 5| Step: 6
Training loss: 0.9619752764701843
Validation loss: 2.146759122610092

Epoch: 5| Step: 7
Training loss: 0.5806377530097961
Validation loss: 2.129055271546046

Epoch: 5| Step: 8
Training loss: 0.5158534646034241
Validation loss: 2.215613548954328

Epoch: 5| Step: 9
Training loss: 0.7219616174697876
Validation loss: 2.2475763956705728

Epoch: 5| Step: 10
Training loss: 0.5727845430374146
Validation loss: 2.1667324006557465

Epoch: 5| Step: 11
Training loss: 0.39073872566223145
Validation loss: 2.1643105149269104

Epoch: 210| Step: 0
Training loss: 0.7807639837265015
Validation loss: 2.1877670933802924

Epoch: 5| Step: 1
Training loss: 0.5576543807983398
Validation loss: 2.1970352033774057

Epoch: 5| Step: 2
Training loss: 0.7208301424980164
Validation loss: 2.1598547995090485

Epoch: 5| Step: 3
Training loss: 0.7686258554458618
Validation loss: 2.080416426062584

Epoch: 5| Step: 4
Training loss: 0.6201754212379456
Validation loss: 2.1067242523034415

Epoch: 5| Step: 5
Training loss: 0.3814656138420105
Validation loss: 2.175540268421173

Epoch: 5| Step: 6
Training loss: 0.5595754384994507
Validation loss: 2.1822913040717444

Epoch: 5| Step: 7
Training loss: 0.4897392690181732
Validation loss: 2.171407530705134

Epoch: 5| Step: 8
Training loss: 0.5231203436851501
Validation loss: 2.167247235774994

Epoch: 5| Step: 9
Training loss: 0.8024681210517883
Validation loss: 2.1787200470765433

Epoch: 5| Step: 10
Training loss: 0.7579207420349121
Validation loss: 2.162729640801748

Epoch: 5| Step: 11
Training loss: 0.36603492498397827
Validation loss: 2.144644702474276

Epoch: 211| Step: 0
Training loss: 0.6354953646659851
Validation loss: 2.0960359623034797

Epoch: 5| Step: 1
Training loss: 0.4815707802772522
Validation loss: 2.104741950829824

Epoch: 5| Step: 2
Training loss: 0.701860785484314
Validation loss: 2.0759300887584686

Epoch: 5| Step: 3
Training loss: 0.5989817380905151
Validation loss: 2.0708889216184616

Epoch: 5| Step: 4
Training loss: 0.47143179178237915
Validation loss: 2.121942733724912

Epoch: 5| Step: 5
Training loss: 0.8857512474060059
Validation loss: 2.1543379922707877

Epoch: 5| Step: 6
Training loss: 0.6985886096954346
Validation loss: 2.1310615241527557

Epoch: 5| Step: 7
Training loss: 0.3616020679473877
Validation loss: 2.164664700627327

Epoch: 5| Step: 8
Training loss: 0.6504477262496948
Validation loss: 2.1702821950117746

Epoch: 5| Step: 9
Training loss: 0.4743322432041168
Validation loss: 2.138114626208941

Epoch: 5| Step: 10
Training loss: 1.06263267993927
Validation loss: 2.150760372479757

Epoch: 5| Step: 11
Training loss: 0.5633566379547119
Validation loss: 2.1103628228108087

Epoch: 212| Step: 0
Training loss: 0.8386438488960266
Validation loss: 2.134531185030937

Epoch: 5| Step: 1
Training loss: 0.30633047223091125
Validation loss: 2.1370465705792108

Epoch: 5| Step: 2
Training loss: 0.8180039525032043
Validation loss: 2.160284106930097

Epoch: 5| Step: 3
Training loss: 0.4915485382080078
Validation loss: 2.1636946698029837

Epoch: 5| Step: 4
Training loss: 0.8103006482124329
Validation loss: 2.213167111078898

Epoch: 5| Step: 5
Training loss: 0.4472588002681732
Validation loss: 2.1481138368447623

Epoch: 5| Step: 6
Training loss: 0.590606689453125
Validation loss: 2.159651671846708

Epoch: 5| Step: 7
Training loss: 0.681922197341919
Validation loss: 2.1085150440533957

Epoch: 5| Step: 8
Training loss: 0.5280697345733643
Validation loss: 2.1663500169912973

Epoch: 5| Step: 9
Training loss: 0.3621280789375305
Validation loss: 2.14776078859965

Epoch: 5| Step: 10
Training loss: 0.9624444246292114
Validation loss: 2.1755932569503784

Epoch: 5| Step: 11
Training loss: 0.2537449598312378
Validation loss: 2.158515011270841

Epoch: 213| Step: 0
Training loss: 0.7494164705276489
Validation loss: 2.2308576852083206

Epoch: 5| Step: 1
Training loss: 0.7729976177215576
Validation loss: 2.2256143738826117

Epoch: 5| Step: 2
Training loss: 0.9969059228897095
Validation loss: 2.208540494243304

Epoch: 5| Step: 3
Training loss: 0.36674171686172485
Validation loss: 2.1759637196858725

Epoch: 5| Step: 4
Training loss: 0.40621867775917053
Validation loss: 2.138211563229561

Epoch: 5| Step: 5
Training loss: 0.8076127171516418
Validation loss: 2.149083728591601

Epoch: 5| Step: 6
Training loss: 0.6809288263320923
Validation loss: 2.1542748361825943

Epoch: 5| Step: 7
Training loss: 0.5246006846427917
Validation loss: 2.129291281104088

Epoch: 5| Step: 8
Training loss: 1.0962715148925781
Validation loss: 2.146518091360728

Epoch: 5| Step: 9
Training loss: 0.19721488654613495
Validation loss: 2.2074378629525504

Epoch: 5| Step: 10
Training loss: 0.714544415473938
Validation loss: 2.2075700561205545

Epoch: 5| Step: 11
Training loss: 0.6674329042434692
Validation loss: 2.20256969332695

Epoch: 214| Step: 0
Training loss: 0.49310803413391113
Validation loss: 2.2025443762540817

Epoch: 5| Step: 1
Training loss: 0.9668577909469604
Validation loss: 2.2071932355562844

Epoch: 5| Step: 2
Training loss: 0.5936562418937683
Validation loss: 2.1964596261580787

Epoch: 5| Step: 3
Training loss: 0.5603703260421753
Validation loss: 2.176235775152842

Epoch: 5| Step: 4
Training loss: 0.6391939520835876
Validation loss: 2.1893115987380347

Epoch: 5| Step: 5
Training loss: 0.4403608441352844
Validation loss: 2.1836543480555215

Epoch: 5| Step: 6
Training loss: 0.5321442484855652
Validation loss: 2.1693831086158752

Epoch: 5| Step: 7
Training loss: 0.5017231702804565
Validation loss: 2.149459923307101

Epoch: 5| Step: 8
Training loss: 0.4038194715976715
Validation loss: 2.1912121971448264

Epoch: 5| Step: 9
Training loss: 0.78874272108078
Validation loss: 2.168929090102514

Epoch: 5| Step: 10
Training loss: 0.8064349889755249
Validation loss: 2.118067979812622

Epoch: 5| Step: 11
Training loss: 0.6913752555847168
Validation loss: 2.131822809576988

Epoch: 215| Step: 0
Training loss: 0.5021227598190308
Validation loss: 2.1484771271546683

Epoch: 5| Step: 1
Training loss: 0.6435933113098145
Validation loss: 2.1493514428536096

Epoch: 5| Step: 2
Training loss: 0.5166741609573364
Validation loss: 2.1298010845979056

Epoch: 5| Step: 3
Training loss: 0.5286182165145874
Validation loss: 2.103750064969063

Epoch: 5| Step: 4
Training loss: 0.23535101115703583
Validation loss: 2.145118216673533

Epoch: 5| Step: 5
Training loss: 0.4250848889350891
Validation loss: 2.1798721849918365

Epoch: 5| Step: 6
Training loss: 0.6153298616409302
Validation loss: 2.2308296809593835

Epoch: 5| Step: 7
Training loss: 0.7848678827285767
Validation loss: 2.1983999709288278

Epoch: 5| Step: 8
Training loss: 1.0637540817260742
Validation loss: 2.180389722188314

Epoch: 5| Step: 9
Training loss: 0.865567684173584
Validation loss: 2.210761313637098

Epoch: 5| Step: 10
Training loss: 0.5560334324836731
Validation loss: 2.1266564577817917

Epoch: 5| Step: 11
Training loss: 0.9985440373420715
Validation loss: 2.1154791563749313

Epoch: 216| Step: 0
Training loss: 0.5876709222793579
Validation loss: 2.133837193250656

Epoch: 5| Step: 1
Training loss: 0.6212738156318665
Validation loss: 2.1361484676599503

Epoch: 5| Step: 2
Training loss: 0.3146352171897888
Validation loss: 2.1262309650580087

Epoch: 5| Step: 3
Training loss: 0.459663450717926
Validation loss: 2.1543680975834527

Epoch: 5| Step: 4
Training loss: 0.9979580044746399
Validation loss: 2.1671685725450516

Epoch: 5| Step: 5
Training loss: 0.40156474709510803
Validation loss: 2.198547492424647

Epoch: 5| Step: 6
Training loss: 0.611899197101593
Validation loss: 2.1892958035071692

Epoch: 5| Step: 7
Training loss: 0.7508403062820435
Validation loss: 2.2235450744628906

Epoch: 5| Step: 8
Training loss: 0.49095526337623596
Validation loss: 2.2166430751482644

Epoch: 5| Step: 9
Training loss: 0.8721736669540405
Validation loss: 2.187791417042414

Epoch: 5| Step: 10
Training loss: 0.5198608636856079
Validation loss: 2.152519921461741

Epoch: 5| Step: 11
Training loss: 0.7506757974624634
Validation loss: 2.162582745154699

Epoch: 217| Step: 0
Training loss: 0.8340089917182922
Validation loss: 2.1971021443605423

Epoch: 5| Step: 1
Training loss: 0.581734299659729
Validation loss: 2.1619772712389627

Epoch: 5| Step: 2
Training loss: 0.9075110554695129
Validation loss: 2.235909362634023

Epoch: 5| Step: 3
Training loss: 0.6135799884796143
Validation loss: 2.261251300573349

Epoch: 5| Step: 4
Training loss: 0.48444515466690063
Validation loss: 2.2503217309713364

Epoch: 5| Step: 5
Training loss: 0.2625500559806824
Validation loss: 2.260642131169637

Epoch: 5| Step: 6
Training loss: 0.513708233833313
Validation loss: 2.2041818102200827

Epoch: 5| Step: 7
Training loss: 0.4149910807609558
Validation loss: 2.186840424935023

Epoch: 5| Step: 8
Training loss: 0.3283267021179199
Validation loss: 2.195067365964254

Epoch: 5| Step: 9
Training loss: 0.756447434425354
Validation loss: 2.162187044819196

Epoch: 5| Step: 10
Training loss: 0.7763769030570984
Validation loss: 2.2213627099990845

Epoch: 5| Step: 11
Training loss: 1.6255344152450562
Validation loss: 2.1955051720142365

Epoch: 218| Step: 0
Training loss: 0.43570834398269653
Validation loss: 2.165116329987844

Epoch: 5| Step: 1
Training loss: 0.5928860902786255
Validation loss: 2.154684523741404

Epoch: 5| Step: 2
Training loss: 0.6023108959197998
Validation loss: 2.159611185391744

Epoch: 5| Step: 3
Training loss: 0.5456317067146301
Validation loss: 2.2081921249628067

Epoch: 5| Step: 4
Training loss: 0.4353242814540863
Validation loss: 2.189151808619499

Epoch: 5| Step: 5
Training loss: 0.8311104774475098
Validation loss: 2.2554040600856147

Epoch: 5| Step: 6
Training loss: 0.9179415702819824
Validation loss: 2.2182616889476776

Epoch: 5| Step: 7
Training loss: 0.622225284576416
Validation loss: 2.2135499318440757

Epoch: 5| Step: 8
Training loss: 1.0055334568023682
Validation loss: 2.165500670671463

Epoch: 5| Step: 9
Training loss: 0.43104204535484314
Validation loss: 2.2007645269234977

Epoch: 5| Step: 10
Training loss: 0.5081891417503357
Validation loss: 2.219854027032852

Epoch: 5| Step: 11
Training loss: 0.4130953550338745
Validation loss: 2.2035703659057617

Epoch: 219| Step: 0
Training loss: 0.4389948844909668
Validation loss: 2.191012054681778

Epoch: 5| Step: 1
Training loss: 0.36584383249282837
Validation loss: 2.1943059961001077

Epoch: 5| Step: 2
Training loss: 0.6674776673316956
Validation loss: 2.171730568011602

Epoch: 5| Step: 3
Training loss: 1.0500767230987549
Validation loss: 2.200521325071653

Epoch: 5| Step: 4
Training loss: 0.5233583450317383
Validation loss: 2.1825760205586753

Epoch: 5| Step: 5
Training loss: 0.3647431433200836
Validation loss: 2.1772662699222565

Epoch: 5| Step: 6
Training loss: 0.5713053941726685
Validation loss: 2.2008536408344903

Epoch: 5| Step: 7
Training loss: 0.6979284286499023
Validation loss: 2.18646606306235

Epoch: 5| Step: 8
Training loss: 0.5846651792526245
Validation loss: 2.159443567196528

Epoch: 5| Step: 9
Training loss: 0.8291794657707214
Validation loss: 2.120053986708323

Epoch: 5| Step: 10
Training loss: 0.49848833680152893
Validation loss: 2.151410679022471

Epoch: 5| Step: 11
Training loss: 0.27830326557159424
Validation loss: 2.170695811510086

Epoch: 220| Step: 0
Training loss: 0.7086306810379028
Validation loss: 2.149748772382736

Epoch: 5| Step: 1
Training loss: 0.5025123357772827
Validation loss: 2.22423525651296

Epoch: 5| Step: 2
Training loss: 0.3893016278743744
Validation loss: 2.2238534887631736

Epoch: 5| Step: 3
Training loss: 0.8177148103713989
Validation loss: 2.2182373702526093

Epoch: 5| Step: 4
Training loss: 0.4503024220466614
Validation loss: 2.206650525331497

Epoch: 5| Step: 5
Training loss: 0.5746437907218933
Validation loss: 2.1101373732089996

Epoch: 5| Step: 6
Training loss: 0.37901028990745544
Validation loss: 2.1110292077064514

Epoch: 5| Step: 7
Training loss: 0.5007410049438477
Validation loss: 2.134039729833603

Epoch: 5| Step: 8
Training loss: 1.0343375205993652
Validation loss: 2.176572968562444

Epoch: 5| Step: 9
Training loss: 0.4837643504142761
Validation loss: 2.184249406059583

Epoch: 5| Step: 10
Training loss: 0.5227675437927246
Validation loss: 2.170636907219887

Epoch: 5| Step: 11
Training loss: 1.3947664499282837
Validation loss: 2.2209325631459556

Epoch: 221| Step: 0
Training loss: 0.7274200916290283
Validation loss: 2.193611055612564

Epoch: 5| Step: 1
Training loss: 0.3260611593723297
Validation loss: 2.21870519220829

Epoch: 5| Step: 2
Training loss: 0.23777036368846893
Validation loss: 2.2268092383941016

Epoch: 5| Step: 3
Training loss: 0.9969837069511414
Validation loss: 2.159780129790306

Epoch: 5| Step: 4
Training loss: 0.6398974657058716
Validation loss: 2.138470729192098

Epoch: 5| Step: 5
Training loss: 0.3888390362262726
Validation loss: 2.190922553340594

Epoch: 5| Step: 6
Training loss: 0.8624446988105774
Validation loss: 2.191168228785197

Epoch: 5| Step: 7
Training loss: 0.31882673501968384
Validation loss: 2.2039182434479394

Epoch: 5| Step: 8
Training loss: 0.5931047797203064
Validation loss: 2.2138513773679733

Epoch: 5| Step: 9
Training loss: 0.47192659974098206
Validation loss: 2.1684012413024902

Epoch: 5| Step: 10
Training loss: 0.9899290204048157
Validation loss: 2.136613835891088

Epoch: 5| Step: 11
Training loss: 0.2696262001991272
Validation loss: 2.162438521782557

Epoch: 222| Step: 0
Training loss: 1.0070829391479492
Validation loss: 2.138661280274391

Epoch: 5| Step: 1
Training loss: 0.7496799826622009
Validation loss: 2.123292416334152

Epoch: 5| Step: 2
Training loss: 0.6197774410247803
Validation loss: 2.177865579724312

Epoch: 5| Step: 3
Training loss: 0.4916554391384125
Validation loss: 2.153046945730845

Epoch: 5| Step: 4
Training loss: 0.7367322444915771
Validation loss: 2.170792837937673

Epoch: 5| Step: 5
Training loss: 0.695559561252594
Validation loss: 2.2104565699895224

Epoch: 5| Step: 6
Training loss: 0.5684261322021484
Validation loss: 2.216783955693245

Epoch: 5| Step: 7
Training loss: 0.8349741101264954
Validation loss: 2.194268077611923

Epoch: 5| Step: 8
Training loss: 0.2779637277126312
Validation loss: 2.180394704143206

Epoch: 5| Step: 9
Training loss: 0.3498988151550293
Validation loss: 2.1833944668372474

Epoch: 5| Step: 10
Training loss: 0.3911871910095215
Validation loss: 2.1653696298599243

Epoch: 5| Step: 11
Training loss: 0.15100789070129395
Validation loss: 2.1303722858428955

Epoch: 223| Step: 0
Training loss: 0.3602004945278168
Validation loss: 2.1685448984305062

Epoch: 5| Step: 1
Training loss: 0.6161972880363464
Validation loss: 2.152235527833303

Epoch: 5| Step: 2
Training loss: 0.9216980934143066
Validation loss: 2.192992612719536

Epoch: 5| Step: 3
Training loss: 0.34314626455307007
Validation loss: 2.1976723422606788

Epoch: 5| Step: 4
Training loss: 0.3990219235420227
Validation loss: 2.1868785520394645

Epoch: 5| Step: 5
Training loss: 0.6501181721687317
Validation loss: 2.1436403741439185

Epoch: 5| Step: 6
Training loss: 0.3375770151615143
Validation loss: 2.1838621894518533

Epoch: 5| Step: 7
Training loss: 0.6942657232284546
Validation loss: 2.1580597112576165

Epoch: 5| Step: 8
Training loss: 0.45096078515052795
Validation loss: 2.1560358305772147

Epoch: 5| Step: 9
Training loss: 0.8484966158866882
Validation loss: 2.1468577633301416

Epoch: 5| Step: 10
Training loss: 0.5733003616333008
Validation loss: 2.134540155529976

Epoch: 5| Step: 11
Training loss: 0.5328608155250549
Validation loss: 2.208815356095632

Epoch: 224| Step: 0
Training loss: 0.6111814379692078
Validation loss: 2.1937724401553473

Epoch: 5| Step: 1
Training loss: 0.4025474190711975
Validation loss: 2.2365824480851493

Epoch: 5| Step: 2
Training loss: 0.32494670152664185
Validation loss: 2.243393898010254

Epoch: 5| Step: 3
Training loss: 0.6419456005096436
Validation loss: 2.211968461672465

Epoch: 5| Step: 4
Training loss: 0.5090760588645935
Validation loss: 2.234564403692881

Epoch: 5| Step: 5
Training loss: 0.5117601156234741
Validation loss: 2.222436472773552

Epoch: 5| Step: 6
Training loss: 0.3015998303890228
Validation loss: 2.188591072956721

Epoch: 5| Step: 7
Training loss: 1.0713595151901245
Validation loss: 2.190119743347168

Epoch: 5| Step: 8
Training loss: 0.48312386870384216
Validation loss: 2.193575123945872

Epoch: 5| Step: 9
Training loss: 0.7065356969833374
Validation loss: 2.1790373474359512

Epoch: 5| Step: 10
Training loss: 0.7802615165710449
Validation loss: 2.23131433626016

Epoch: 5| Step: 11
Training loss: 0.3194587230682373
Validation loss: 2.205841133991877

Epoch: 225| Step: 0
Training loss: 0.6082965135574341
Validation loss: 2.2112767845392227

Epoch: 5| Step: 1
Training loss: 0.5542643070220947
Validation loss: 2.1871847410996756

Epoch: 5| Step: 2
Training loss: 0.3406466841697693
Validation loss: 2.2201121548811593

Epoch: 5| Step: 3
Training loss: 0.48533353209495544
Validation loss: 2.2494550198316574

Epoch: 5| Step: 4
Training loss: 0.6070340871810913
Validation loss: 2.1757963548103967

Epoch: 5| Step: 5
Training loss: 0.34930405020713806
Validation loss: 2.1547511716683707

Epoch: 5| Step: 6
Training loss: 0.5680214166641235
Validation loss: 2.1596013804276786

Epoch: 5| Step: 7
Training loss: 0.8205922842025757
Validation loss: 2.169810483853022

Epoch: 5| Step: 8
Training loss: 0.4049813747406006
Validation loss: 2.188956235845884

Epoch: 5| Step: 9
Training loss: 0.6313644647598267
Validation loss: 2.1843672692775726

Epoch: 5| Step: 10
Training loss: 0.9751180410385132
Validation loss: 2.2268923074007034

Epoch: 5| Step: 11
Training loss: 1.3548823595046997
Validation loss: 2.2199928065141044

Epoch: 226| Step: 0
Training loss: 0.616376519203186
Validation loss: 2.200716416041056

Epoch: 5| Step: 1
Training loss: 0.47887665033340454
Validation loss: 2.1808005571365356

Epoch: 5| Step: 2
Training loss: 0.6007074117660522
Validation loss: 2.139618699749311

Epoch: 5| Step: 3
Training loss: 0.6074302196502686
Validation loss: 2.245277618368467

Epoch: 5| Step: 4
Training loss: 0.3601418137550354
Validation loss: 2.1960346400737762

Epoch: 5| Step: 5
Training loss: 0.5672091245651245
Validation loss: 2.18549736837546

Epoch: 5| Step: 6
Training loss: 1.008679747581482
Validation loss: 2.2088525593280792

Epoch: 5| Step: 7
Training loss: 0.44003763794898987
Validation loss: 2.1815855403741202

Epoch: 5| Step: 8
Training loss: 0.4792875349521637
Validation loss: 2.1744845559199653

Epoch: 5| Step: 9
Training loss: 0.2781919836997986
Validation loss: 2.192373658219973

Epoch: 5| Step: 10
Training loss: 0.6945503354072571
Validation loss: 2.229713280995687

Epoch: 5| Step: 11
Training loss: 0.8164924383163452
Validation loss: 2.1629852006832757

Epoch: 227| Step: 0
Training loss: 0.6664928197860718
Validation loss: 2.260054791967074

Epoch: 5| Step: 1
Training loss: 0.36322274804115295
Validation loss: 2.183047036329905

Epoch: 5| Step: 2
Training loss: 0.6795200109481812
Validation loss: 2.116702432433764

Epoch: 5| Step: 3
Training loss: 0.4791994094848633
Validation loss: 2.1435438295205436

Epoch: 5| Step: 4
Training loss: 0.508175790309906
Validation loss: 2.190553759535154

Epoch: 5| Step: 5
Training loss: 0.2453138381242752
Validation loss: 2.1737299958864846

Epoch: 5| Step: 6
Training loss: 0.4776444435119629
Validation loss: 2.1879614094893136

Epoch: 5| Step: 7
Training loss: 0.48194369673728943
Validation loss: 2.212502787510554

Epoch: 5| Step: 8
Training loss: 0.47104907035827637
Validation loss: 2.1795603235562644

Epoch: 5| Step: 9
Training loss: 0.6445020437240601
Validation loss: 2.1464152534802756

Epoch: 5| Step: 10
Training loss: 1.0575093030929565
Validation loss: 2.1411143392324448

Epoch: 5| Step: 11
Training loss: 0.8301559686660767
Validation loss: 2.188723439971606

Epoch: 228| Step: 0
Training loss: 0.2860645651817322
Validation loss: 2.142869681119919

Epoch: 5| Step: 1
Training loss: 1.0082762241363525
Validation loss: 2.1900674402713776

Epoch: 5| Step: 2
Training loss: 0.29700616002082825
Validation loss: 2.1924087752898536

Epoch: 5| Step: 3
Training loss: 0.37058985233306885
Validation loss: 2.1890043367942176

Epoch: 5| Step: 4
Training loss: 0.34865841269493103
Validation loss: 2.208995292584101

Epoch: 5| Step: 5
Training loss: 0.7976197004318237
Validation loss: 2.201280802488327

Epoch: 5| Step: 6
Training loss: 0.46126532554626465
Validation loss: 2.2127578258514404

Epoch: 5| Step: 7
Training loss: 0.6954882740974426
Validation loss: 2.1838714381059012

Epoch: 5| Step: 8
Training loss: 0.4000207781791687
Validation loss: 2.145323390762011

Epoch: 5| Step: 9
Training loss: 0.7834805250167847
Validation loss: 2.1534845183293023

Epoch: 5| Step: 10
Training loss: 0.4690691828727722
Validation loss: 2.153467446565628

Epoch: 5| Step: 11
Training loss: 0.8249355554580688
Validation loss: 2.1518655667702355

Epoch: 229| Step: 0
Training loss: 0.7686184048652649
Validation loss: 2.159119337797165

Epoch: 5| Step: 1
Training loss: 0.7586780786514282
Validation loss: 2.1701759149630866

Epoch: 5| Step: 2
Training loss: 0.5267125964164734
Validation loss: 2.2015362481276193

Epoch: 5| Step: 3
Training loss: 0.427928626537323
Validation loss: 2.249865507086118

Epoch: 5| Step: 4
Training loss: 0.5638672113418579
Validation loss: 2.2203750709692636

Epoch: 5| Step: 5
Training loss: 0.46428316831588745
Validation loss: 2.219875971476237

Epoch: 5| Step: 6
Training loss: 0.35657036304473877
Validation loss: 2.1932102839152017

Epoch: 5| Step: 7
Training loss: 0.6475434303283691
Validation loss: 2.1334136178096137

Epoch: 5| Step: 8
Training loss: 0.5707803964614868
Validation loss: 2.1695999950170517

Epoch: 5| Step: 9
Training loss: 0.4006735682487488
Validation loss: 2.187181442975998

Epoch: 5| Step: 10
Training loss: 0.642264723777771
Validation loss: 2.1785775820414224

Epoch: 5| Step: 11
Training loss: 0.2623085379600525
Validation loss: 2.1826669921477637

Epoch: 230| Step: 0
Training loss: 0.31376317143440247
Validation loss: 2.1781469931205115

Epoch: 5| Step: 1
Training loss: 0.6554882526397705
Validation loss: 2.2171026865641275

Epoch: 5| Step: 2
Training loss: 0.8538690805435181
Validation loss: 2.2255387703577676

Epoch: 5| Step: 3
Training loss: 0.29370611906051636
Validation loss: 2.2080869476000466

Epoch: 5| Step: 4
Training loss: 0.44391441345214844
Validation loss: 2.1420160233974457

Epoch: 5| Step: 5
Training loss: 0.5455543398857117
Validation loss: 2.1179572691520057

Epoch: 5| Step: 6
Training loss: 0.5229431390762329
Validation loss: 2.151600976785024

Epoch: 5| Step: 7
Training loss: 0.6095504760742188
Validation loss: 2.1513609687487283

Epoch: 5| Step: 8
Training loss: 0.569257915019989
Validation loss: 2.1996238181988397

Epoch: 5| Step: 9
Training loss: 0.4023246169090271
Validation loss: 2.187573730945587

Epoch: 5| Step: 10
Training loss: 0.49193304777145386
Validation loss: 2.117618257800738

Epoch: 5| Step: 11
Training loss: 0.15373700857162476
Validation loss: 2.147856588164965

Epoch: 231| Step: 0
Training loss: 0.27128034830093384
Validation loss: 2.1277287205060325

Epoch: 5| Step: 1
Training loss: 0.5030502080917358
Validation loss: 2.1299273123343787

Epoch: 5| Step: 2
Training loss: 0.41671839356422424
Validation loss: 2.1167676746845245

Epoch: 5| Step: 3
Training loss: 0.5086988210678101
Validation loss: 2.1562561790148416

Epoch: 5| Step: 4
Training loss: 0.6728014349937439
Validation loss: 2.1285323798656464

Epoch: 5| Step: 5
Training loss: 0.44454509019851685
Validation loss: 2.148785059650739

Epoch: 5| Step: 6
Training loss: 0.4998853802680969
Validation loss: 2.1613225092490516

Epoch: 5| Step: 7
Training loss: 0.38247671723365784
Validation loss: 2.1703810890515647

Epoch: 5| Step: 8
Training loss: 0.5896876454353333
Validation loss: 2.137261683742205

Epoch: 5| Step: 9
Training loss: 0.7823183536529541
Validation loss: 2.159613693753878

Epoch: 5| Step: 10
Training loss: 0.4483298659324646
Validation loss: 2.179613083600998

Epoch: 5| Step: 11
Training loss: 1.3312984704971313
Validation loss: 2.146840830643972

Epoch: 232| Step: 0
Training loss: 0.49466973543167114
Validation loss: 2.135861029227575

Epoch: 5| Step: 1
Training loss: 0.3654175400733948
Validation loss: 2.1543148110310235

Epoch: 5| Step: 2
Training loss: 0.9867792129516602
Validation loss: 2.100107113520304

Epoch: 5| Step: 3
Training loss: 0.743392288684845
Validation loss: 2.113327662150065

Epoch: 5| Step: 4
Training loss: 0.28692299127578735
Validation loss: 2.1400369803110757

Epoch: 5| Step: 5
Training loss: 0.28369492292404175
Validation loss: 2.188345347841581

Epoch: 5| Step: 6
Training loss: 0.7391498684883118
Validation loss: 2.1876977334419885

Epoch: 5| Step: 7
Training loss: 0.4622637629508972
Validation loss: 2.229391018549601

Epoch: 5| Step: 8
Training loss: 0.46878838539123535
Validation loss: 2.2350045144557953

Epoch: 5| Step: 9
Training loss: 0.4398113191127777
Validation loss: 2.212196429570516

Epoch: 5| Step: 10
Training loss: 0.6761380434036255
Validation loss: 2.2140970726807914

Epoch: 5| Step: 11
Training loss: 0.3755502700805664
Validation loss: 2.1722004314263663

Epoch: 233| Step: 0
Training loss: 0.7093013525009155
Validation loss: 2.177725369731585

Epoch: 5| Step: 1
Training loss: 0.6318392753601074
Validation loss: 2.1755173007647195

Epoch: 5| Step: 2
Training loss: 0.40150022506713867
Validation loss: 2.236416925986608

Epoch: 5| Step: 3
Training loss: 0.3841954171657562
Validation loss: 2.2350965489943824

Epoch: 5| Step: 4
Training loss: 0.5119912028312683
Validation loss: 2.2174478669961295

Epoch: 5| Step: 5
Training loss: 1.0164380073547363
Validation loss: 2.190814579526583

Epoch: 5| Step: 6
Training loss: 0.5471656322479248
Validation loss: 2.1967969636122384

Epoch: 5| Step: 7
Training loss: 0.3627922236919403
Validation loss: 2.2005266745885215

Epoch: 5| Step: 8
Training loss: 0.602692723274231
Validation loss: 2.1670392403999963

Epoch: 5| Step: 9
Training loss: 0.3437357544898987
Validation loss: 2.190204973022143

Epoch: 5| Step: 10
Training loss: 0.48046913743019104
Validation loss: 2.1945322255293527

Epoch: 5| Step: 11
Training loss: 0.6060165166854858
Validation loss: 2.1830511738856635

Epoch: 234| Step: 0
Training loss: 0.4545436501502991
Validation loss: 2.2573959628740945

Epoch: 5| Step: 1
Training loss: 0.5546725392341614
Validation loss: 2.226184532046318

Epoch: 5| Step: 2
Training loss: 0.6917443871498108
Validation loss: 2.2369436025619507

Epoch: 5| Step: 3
Training loss: 0.5624831914901733
Validation loss: 2.2570015539725623

Epoch: 5| Step: 4
Training loss: 0.47964826226234436
Validation loss: 2.179801975687345

Epoch: 5| Step: 5
Training loss: 0.8935216665267944
Validation loss: 2.189987654487292

Epoch: 5| Step: 6
Training loss: 0.4224177300930023
Validation loss: 2.13233749071757

Epoch: 5| Step: 7
Training loss: 0.4703788161277771
Validation loss: 2.1709905564785004

Epoch: 5| Step: 8
Training loss: 0.4076520800590515
Validation loss: 2.1961861650149026

Epoch: 5| Step: 9
Training loss: 0.5973653197288513
Validation loss: 2.237194354335467

Epoch: 5| Step: 10
Training loss: 0.4781419634819031
Validation loss: 2.2155886044104895

Epoch: 5| Step: 11
Training loss: 0.33878740668296814
Validation loss: 2.20370585223039

Epoch: 235| Step: 0
Training loss: 0.5323479771614075
Validation loss: 2.2072189251581826

Epoch: 5| Step: 1
Training loss: 0.9230634570121765
Validation loss: 2.161417707800865

Epoch: 5| Step: 2
Training loss: 0.4053746163845062
Validation loss: 2.168935095270475

Epoch: 5| Step: 3
Training loss: 0.5218260884284973
Validation loss: 2.1449407239754996

Epoch: 5| Step: 4
Training loss: 0.6262307167053223
Validation loss: 2.186489706238111

Epoch: 5| Step: 5
Training loss: 0.4182654321193695
Validation loss: 2.162929500142733

Epoch: 5| Step: 6
Training loss: 0.3530598282814026
Validation loss: 2.203828305006027

Epoch: 5| Step: 7
Training loss: 0.5082241296768188
Validation loss: 2.2069376905759177

Epoch: 5| Step: 8
Training loss: 0.5109645128250122
Validation loss: 2.237933099269867

Epoch: 5| Step: 9
Training loss: 0.8123456239700317
Validation loss: 2.1915518989165625

Epoch: 5| Step: 10
Training loss: 0.6741050481796265
Validation loss: 2.177264094352722

Epoch: 5| Step: 11
Training loss: 0.22943231463432312
Validation loss: 2.134891922275225

Epoch: 236| Step: 0
Training loss: 0.7744817733764648
Validation loss: 2.1510719458262124

Epoch: 5| Step: 1
Training loss: 0.45186886191368103
Validation loss: 2.1772976020971933

Epoch: 5| Step: 2
Training loss: 0.27898603677749634
Validation loss: 2.133286620179812

Epoch: 5| Step: 3
Training loss: 0.35014018416404724
Validation loss: 2.162204717596372

Epoch: 5| Step: 4
Training loss: 0.743438720703125
Validation loss: 2.169476975997289

Epoch: 5| Step: 5
Training loss: 0.7986165881156921
Validation loss: 2.1483187824487686

Epoch: 5| Step: 6
Training loss: 0.2599392533302307
Validation loss: 2.210342397292455

Epoch: 5| Step: 7
Training loss: 0.3288491368293762
Validation loss: 2.2082447608311973

Epoch: 5| Step: 8
Training loss: 0.43541988730430603
Validation loss: 2.1709623634815216

Epoch: 5| Step: 9
Training loss: 0.4955764710903168
Validation loss: 2.200509414076805

Epoch: 5| Step: 10
Training loss: 0.6005028486251831
Validation loss: 2.198141564925512

Epoch: 5| Step: 11
Training loss: 0.33307182788848877
Validation loss: 2.1733587235212326

Epoch: 237| Step: 0
Training loss: 0.4098937511444092
Validation loss: 2.1337226033210754

Epoch: 5| Step: 1
Training loss: 0.5706161856651306
Validation loss: 2.1373537381490073

Epoch: 5| Step: 2
Training loss: 0.2952793836593628
Validation loss: 2.161355644464493

Epoch: 5| Step: 3
Training loss: 0.7095886468887329
Validation loss: 2.1697787990172706

Epoch: 5| Step: 4
Training loss: 0.3879849314689636
Validation loss: 2.192871650060018

Epoch: 5| Step: 5
Training loss: 0.45297083258628845
Validation loss: 2.2203453729550042

Epoch: 5| Step: 6
Training loss: 0.876353919506073
Validation loss: 2.194352696339289

Epoch: 5| Step: 7
Training loss: 0.8858033418655396
Validation loss: 2.208354781071345

Epoch: 5| Step: 8
Training loss: 0.22161421179771423
Validation loss: 2.1887311140696206

Epoch: 5| Step: 9
Training loss: 0.3501213788986206
Validation loss: 2.192795674006144

Epoch: 5| Step: 10
Training loss: 0.4800930917263031
Validation loss: 2.189101775487264

Epoch: 5| Step: 11
Training loss: 0.43842101097106934
Validation loss: 2.1864209274450936

Epoch: 238| Step: 0
Training loss: 0.4918627142906189
Validation loss: 2.193161278963089

Epoch: 5| Step: 1
Training loss: 0.4684155583381653
Validation loss: 2.1589235812425613

Epoch: 5| Step: 2
Training loss: 0.536826491355896
Validation loss: 2.127164458235105

Epoch: 5| Step: 3
Training loss: 0.6305867433547974
Validation loss: 2.13527704278628

Epoch: 5| Step: 4
Training loss: 0.45192915201187134
Validation loss: 2.1443468779325485

Epoch: 5| Step: 5
Training loss: 0.3935168385505676
Validation loss: 2.1481985797484717

Epoch: 5| Step: 6
Training loss: 0.6125589609146118
Validation loss: 2.1513603826363883

Epoch: 5| Step: 7
Training loss: 0.4975619316101074
Validation loss: 2.1673754354317984

Epoch: 5| Step: 8
Training loss: 0.6117860078811646
Validation loss: 2.212635805209478

Epoch: 5| Step: 9
Training loss: 0.339642733335495
Validation loss: 2.1648803452650704

Epoch: 5| Step: 10
Training loss: 0.6727910041809082
Validation loss: 2.2016372680664062

Epoch: 5| Step: 11
Training loss: 0.4039355516433716
Validation loss: 2.135048826535543

Epoch: 239| Step: 0
Training loss: 0.6033414006233215
Validation loss: 2.134046653906504

Epoch: 5| Step: 1
Training loss: 0.4403041899204254
Validation loss: 2.154940331975619

Epoch: 5| Step: 2
Training loss: 0.5438079237937927
Validation loss: 2.147314190864563

Epoch: 5| Step: 3
Training loss: 0.3822517395019531
Validation loss: 2.152975539366404

Epoch: 5| Step: 4
Training loss: 0.7857405543327332
Validation loss: 2.1814411779244742

Epoch: 5| Step: 5
Training loss: 0.5425044298171997
Validation loss: 2.143415868282318

Epoch: 5| Step: 6
Training loss: 0.4062555432319641
Validation loss: 2.215047230323156

Epoch: 5| Step: 7
Training loss: 0.4739314913749695
Validation loss: 2.2167022923628488

Epoch: 5| Step: 8
Training loss: 0.6030701398849487
Validation loss: 2.1826357195774713

Epoch: 5| Step: 9
Training loss: 0.539336085319519
Validation loss: 2.16261492172877

Epoch: 5| Step: 10
Training loss: 0.3120533227920532
Validation loss: 2.136317412058512

Epoch: 5| Step: 11
Training loss: 0.298270583152771
Validation loss: 2.1604042450586953

Epoch: 240| Step: 0
Training loss: 0.3597620725631714
Validation loss: 2.1630411744117737

Epoch: 5| Step: 1
Training loss: 0.35320907831192017
Validation loss: 2.162082865834236

Epoch: 5| Step: 2
Training loss: 0.3151577115058899
Validation loss: 2.1767707814772925

Epoch: 5| Step: 3
Training loss: 0.27834272384643555
Validation loss: 2.164774388074875

Epoch: 5| Step: 4
Training loss: 0.5992978811264038
Validation loss: 2.160861308375994

Epoch: 5| Step: 5
Training loss: 0.36260369420051575
Validation loss: 2.1681735763947168

Epoch: 5| Step: 6
Training loss: 0.4013655185699463
Validation loss: 2.1852957954009375

Epoch: 5| Step: 7
Training loss: 0.6009528040885925
Validation loss: 2.160579279065132

Epoch: 5| Step: 8
Training loss: 0.46866124868392944
Validation loss: 2.185051287213961

Epoch: 5| Step: 9
Training loss: 0.7118493318557739
Validation loss: 2.174586683511734

Epoch: 5| Step: 10
Training loss: 0.9390022158622742
Validation loss: 2.2026771903038025

Epoch: 5| Step: 11
Training loss: 1.103961706161499
Validation loss: 2.1500364243984222

Epoch: 241| Step: 0
Training loss: 0.48677077889442444
Validation loss: 2.14866840839386

Epoch: 5| Step: 1
Training loss: 0.3315120339393616
Validation loss: 2.176013171672821

Epoch: 5| Step: 2
Training loss: 0.4019809663295746
Validation loss: 2.18857770661513

Epoch: 5| Step: 3
Training loss: 0.44319087266921997
Validation loss: 2.26231819887956

Epoch: 5| Step: 4
Training loss: 0.6629826426506042
Validation loss: 2.1667844454447427

Epoch: 5| Step: 5
Training loss: 0.8783276677131653
Validation loss: 2.141756226619085

Epoch: 5| Step: 6
Training loss: 0.5360844731330872
Validation loss: 2.2094011902809143

Epoch: 5| Step: 7
Training loss: 0.2901783585548401
Validation loss: 2.2661324739456177

Epoch: 5| Step: 8
Training loss: 0.5042968988418579
Validation loss: 2.1891890267531076

Epoch: 5| Step: 9
Training loss: 0.5587993264198303
Validation loss: 2.2038723031679788

Epoch: 5| Step: 10
Training loss: 0.5326529741287231
Validation loss: 2.1552542249361673

Epoch: 5| Step: 11
Training loss: 0.36426401138305664
Validation loss: 2.1781681726376214

Epoch: 242| Step: 0
Training loss: 0.34034863114356995
Validation loss: 2.1550096422433853

Epoch: 5| Step: 1
Training loss: 0.7721303701400757
Validation loss: 2.170084794362386

Epoch: 5| Step: 2
Training loss: 0.3382943272590637
Validation loss: 2.2167458534240723

Epoch: 5| Step: 3
Training loss: 0.2616097629070282
Validation loss: 2.247158949573835

Epoch: 5| Step: 4
Training loss: 0.8641977310180664
Validation loss: 2.219270244240761

Epoch: 5| Step: 5
Training loss: 0.7079784870147705
Validation loss: 2.2049656311670938

Epoch: 5| Step: 6
Training loss: 0.573395848274231
Validation loss: 2.1433521658182144

Epoch: 5| Step: 7
Training loss: 0.7183560132980347
Validation loss: 2.120759040117264

Epoch: 5| Step: 8
Training loss: 0.48614341020584106
Validation loss: 2.159045765797297

Epoch: 5| Step: 9
Training loss: 0.29907530546188354
Validation loss: 2.1090385615825653

Epoch: 5| Step: 10
Training loss: 0.5555949807167053
Validation loss: 2.1611749678850174

Epoch: 5| Step: 11
Training loss: 0.22528934478759766
Validation loss: 2.1945193310578666

Epoch: 243| Step: 0
Training loss: 0.6852439641952515
Validation loss: 2.2037366181612015

Epoch: 5| Step: 1
Training loss: 0.4263997972011566
Validation loss: 2.1679434974988303

Epoch: 5| Step: 2
Training loss: 0.4630983769893646
Validation loss: 2.164189467827479

Epoch: 5| Step: 3
Training loss: 0.7430712580680847
Validation loss: 2.166099692384402

Epoch: 5| Step: 4
Training loss: 0.3851541578769684
Validation loss: 2.1827253798643746

Epoch: 5| Step: 5
Training loss: 0.5301981568336487
Validation loss: 2.1299902498722076

Epoch: 5| Step: 6
Training loss: 0.7409406900405884
Validation loss: 2.1637298464775085

Epoch: 5| Step: 7
Training loss: 0.5830108523368835
Validation loss: 2.1800558219353356

Epoch: 5| Step: 8
Training loss: 0.378928005695343
Validation loss: 2.1683698097864785

Epoch: 5| Step: 9
Training loss: 0.23092786967754364
Validation loss: 2.210675229628881

Epoch: 5| Step: 10
Training loss: 0.6509624719619751
Validation loss: 2.260890935858091

Epoch: 5| Step: 11
Training loss: 0.5504951477050781
Validation loss: 2.1934745808442435

Epoch: 244| Step: 0
Training loss: 0.6393853425979614
Validation loss: 2.191212629278501

Epoch: 5| Step: 1
Training loss: 0.4207235872745514
Validation loss: 2.1856988221406937

Epoch: 5| Step: 2
Training loss: 0.5495489239692688
Validation loss: 2.147707531849543

Epoch: 5| Step: 3
Training loss: 0.5123817324638367
Validation loss: 2.1254042287667594

Epoch: 5| Step: 4
Training loss: 0.5307101011276245
Validation loss: 2.159848690032959

Epoch: 5| Step: 5
Training loss: 0.48692232370376587
Validation loss: 2.1822613378365836

Epoch: 5| Step: 6
Training loss: 0.2749963104724884
Validation loss: 2.1845951676368713

Epoch: 5| Step: 7
Training loss: 0.4612225890159607
Validation loss: 2.1781459848086038

Epoch: 5| Step: 8
Training loss: 0.3635968267917633
Validation loss: 2.217096135020256

Epoch: 5| Step: 9
Training loss: 0.6775118708610535
Validation loss: 2.1660807927449546

Epoch: 5| Step: 10
Training loss: 0.7903949618339539
Validation loss: 2.177070066332817

Epoch: 5| Step: 11
Training loss: 0.18868210911750793
Validation loss: 2.1470262706279755

Epoch: 245| Step: 0
Training loss: 0.568651556968689
Validation loss: 2.100142260392507

Epoch: 5| Step: 1
Training loss: 0.3625602722167969
Validation loss: 2.153289715449015

Epoch: 5| Step: 2
Training loss: 0.668283998966217
Validation loss: 2.1156691908836365

Epoch: 5| Step: 3
Training loss: 0.5711156129837036
Validation loss: 2.223992029825846

Epoch: 5| Step: 4
Training loss: 0.5199977159500122
Validation loss: 2.160463978846868

Epoch: 5| Step: 5
Training loss: 0.5305191874504089
Validation loss: 2.217346375187238

Epoch: 5| Step: 6
Training loss: 0.6034619808197021
Validation loss: 2.2029355267683663

Epoch: 5| Step: 7
Training loss: 0.43601617217063904
Validation loss: 2.227231209476789

Epoch: 5| Step: 8
Training loss: 0.5443397760391235
Validation loss: 2.205032924811045

Epoch: 5| Step: 9
Training loss: 0.389221727848053
Validation loss: 2.1689034700393677

Epoch: 5| Step: 10
Training loss: 0.46249309182167053
Validation loss: 2.1842047522465386

Epoch: 5| Step: 11
Training loss: 0.5556883811950684
Validation loss: 2.1444461047649384

Epoch: 246| Step: 0
Training loss: 0.5741564035415649
Validation loss: 2.1954342424869537

Epoch: 5| Step: 1
Training loss: 0.36109215021133423
Validation loss: 2.1813658326864243

Epoch: 5| Step: 2
Training loss: 0.3472043573856354
Validation loss: 2.205216114719709

Epoch: 5| Step: 3
Training loss: 0.4449061453342438
Validation loss: 2.2012940297524133

Epoch: 5| Step: 4
Training loss: 0.5949949026107788
Validation loss: 2.225725367665291

Epoch: 5| Step: 5
Training loss: 0.7393321990966797
Validation loss: 2.175181269645691

Epoch: 5| Step: 6
Training loss: 0.4636557102203369
Validation loss: 2.188557689388593

Epoch: 5| Step: 7
Training loss: 0.4673735499382019
Validation loss: 2.1801153222719827

Epoch: 5| Step: 8
Training loss: 0.20268642902374268
Validation loss: 2.180109366774559

Epoch: 5| Step: 9
Training loss: 0.29340893030166626
Validation loss: 2.1623833080132804

Epoch: 5| Step: 10
Training loss: 0.5654860734939575
Validation loss: 2.1825274924437204

Epoch: 5| Step: 11
Training loss: 0.4425510764122009
Validation loss: 2.188291842738787

Epoch: 247| Step: 0
Training loss: 0.2902144491672516
Validation loss: 2.1695722540219626

Epoch: 5| Step: 1
Training loss: 0.3327559530735016
Validation loss: 2.1686592449744544

Epoch: 5| Step: 2
Training loss: 0.24030828475952148
Validation loss: 2.2000107864538827

Epoch: 5| Step: 3
Training loss: 0.5860951542854309
Validation loss: 2.1782389928897223

Epoch: 5| Step: 4
Training loss: 0.3759263753890991
Validation loss: 2.1293294578790665

Epoch: 5| Step: 5
Training loss: 0.6731990575790405
Validation loss: 2.164924403031667

Epoch: 5| Step: 6
Training loss: 0.6305732727050781
Validation loss: 2.1661070634921393

Epoch: 5| Step: 7
Training loss: 0.4249196946620941
Validation loss: 2.1815566966931024

Epoch: 5| Step: 8
Training loss: 0.5070542693138123
Validation loss: 2.13666932284832

Epoch: 5| Step: 9
Training loss: 0.2836621403694153
Validation loss: 2.1308341026306152

Epoch: 5| Step: 10
Training loss: 1.0042108297348022
Validation loss: 2.1576116184393563

Epoch: 5| Step: 11
Training loss: 0.20959985256195068
Validation loss: 2.1822506288687387

Epoch: 248| Step: 0
Training loss: 0.7233508229255676
Validation loss: 2.2181876053412757

Epoch: 5| Step: 1
Training loss: 0.3767380714416504
Validation loss: 2.2042278796434402

Epoch: 5| Step: 2
Training loss: 0.814378559589386
Validation loss: 2.2419110437234244

Epoch: 5| Step: 3
Training loss: 0.5126091241836548
Validation loss: 2.1784284015496573

Epoch: 5| Step: 4
Training loss: 0.5359750986099243
Validation loss: 2.162321984767914

Epoch: 5| Step: 5
Training loss: 0.3125212788581848
Validation loss: 2.1944613605737686

Epoch: 5| Step: 6
Training loss: 0.47885662317276
Validation loss: 2.117981478571892

Epoch: 5| Step: 7
Training loss: 0.5538438558578491
Validation loss: 2.211768865585327

Epoch: 5| Step: 8
Training loss: 0.5332719087600708
Validation loss: 2.1556753118832908

Epoch: 5| Step: 9
Training loss: 0.2589024603366852
Validation loss: 2.1785575846831002

Epoch: 5| Step: 10
Training loss: 0.21343238651752472
Validation loss: 2.222667117913564

Epoch: 5| Step: 11
Training loss: 0.6537512540817261
Validation loss: 2.169732838869095

Epoch: 249| Step: 0
Training loss: 0.6087158918380737
Validation loss: 2.2373328556617103

Epoch: 5| Step: 1
Training loss: 0.42513322830200195
Validation loss: 2.1661843260129294

Epoch: 5| Step: 2
Training loss: 0.6273192167282104
Validation loss: 2.2028553187847137

Epoch: 5| Step: 3
Training loss: 0.19752143323421478
Validation loss: 2.1835408757130303

Epoch: 5| Step: 4
Training loss: 0.2115050107240677
Validation loss: 2.1782873372236886

Epoch: 5| Step: 5
Training loss: 0.227183535695076
Validation loss: 2.1787952284018197

Epoch: 5| Step: 6
Training loss: 0.344041645526886
Validation loss: 2.1763216853141785

Epoch: 5| Step: 7
Training loss: 0.571387767791748
Validation loss: 2.1720487574736276

Epoch: 5| Step: 8
Training loss: 0.6829625368118286
Validation loss: 2.176662484804789

Epoch: 5| Step: 9
Training loss: 0.8514155149459839
Validation loss: 2.148515755931536

Epoch: 5| Step: 10
Training loss: 0.3398863673210144
Validation loss: 2.1772862871487937

Epoch: 5| Step: 11
Training loss: 1.138979196548462
Validation loss: 2.1994625578324

Epoch: 250| Step: 0
Training loss: 0.38284429907798767
Validation loss: 2.1291321367025375

Epoch: 5| Step: 1
Training loss: 0.31787729263305664
Validation loss: 2.1538415352503457

Epoch: 5| Step: 2
Training loss: 0.2187970131635666
Validation loss: 2.2075240860382714

Epoch: 5| Step: 3
Training loss: 0.5830128788948059
Validation loss: 2.228774090607961

Epoch: 5| Step: 4
Training loss: 0.5532400012016296
Validation loss: 2.2040936996539435

Epoch: 5| Step: 5
Training loss: 0.210114523768425
Validation loss: 2.209638108809789

Epoch: 5| Step: 6
Training loss: 0.878437340259552
Validation loss: 2.24356979628404

Epoch: 5| Step: 7
Training loss: 0.34857386350631714
Validation loss: 2.2444047977526984

Epoch: 5| Step: 8
Training loss: 0.6340166330337524
Validation loss: 2.186204875508944

Epoch: 5| Step: 9
Training loss: 0.1865374594926834
Validation loss: 2.191473752260208

Epoch: 5| Step: 10
Training loss: 0.6080603003501892
Validation loss: 2.246005967259407

Epoch: 5| Step: 11
Training loss: 0.9230147004127502
Validation loss: 2.183722903331121

Epoch: 251| Step: 0
Training loss: 0.47647756338119507
Validation loss: 2.2110296537478766

Epoch: 5| Step: 1
Training loss: 0.2810208201408386
Validation loss: 2.1956924299399057

Epoch: 5| Step: 2
Training loss: 0.4474644064903259
Validation loss: 2.2526930967966714

Epoch: 5| Step: 3
Training loss: 0.42566537857055664
Validation loss: 2.2430684715509415

Epoch: 5| Step: 4
Training loss: 0.5739957094192505
Validation loss: 2.2185263385375342

Epoch: 5| Step: 5
Training loss: 0.34514516592025757
Validation loss: 2.2402803798516593

Epoch: 5| Step: 6
Training loss: 0.40293341875076294
Validation loss: 2.1924810806910195

Epoch: 5| Step: 7
Training loss: 0.7726567983627319
Validation loss: 2.2840782006581626

Epoch: 5| Step: 8
Training loss: 0.46970444917678833
Validation loss: 2.2305180430412292

Epoch: 5| Step: 9
Training loss: 0.43878284096717834
Validation loss: 2.2295410434405007

Epoch: 5| Step: 10
Training loss: 0.5367286205291748
Validation loss: 2.1677802205085754

Epoch: 5| Step: 11
Training loss: 0.3041501045227051
Validation loss: 2.1904722452163696

Epoch: 252| Step: 0
Training loss: 0.48365679383277893
Validation loss: 2.194477582971255

Epoch: 5| Step: 1
Training loss: 0.47131744027137756
Validation loss: 2.1673783560593924

Epoch: 5| Step: 2
Training loss: 0.5452471971511841
Validation loss: 2.1702909717957177

Epoch: 5| Step: 3
Training loss: 0.3438813090324402
Validation loss: 2.2326685339212418

Epoch: 5| Step: 4
Training loss: 0.4054628908634186
Validation loss: 2.2655885815620422

Epoch: 5| Step: 5
Training loss: 0.4864436984062195
Validation loss: 2.165641958514849

Epoch: 5| Step: 6
Training loss: 0.38143405318260193
Validation loss: 2.143826405207316

Epoch: 5| Step: 7
Training loss: 0.7157973647117615
Validation loss: 2.180798724293709

Epoch: 5| Step: 8
Training loss: 0.5017189979553223
Validation loss: 2.183477520942688

Epoch: 5| Step: 9
Training loss: 0.6764962077140808
Validation loss: 2.1553956071535745

Epoch: 5| Step: 10
Training loss: 0.4745001792907715
Validation loss: 2.2118346194426217

Epoch: 5| Step: 11
Training loss: 0.23639225959777832
Validation loss: 2.1855730563402176

Epoch: 253| Step: 0
Training loss: 0.3146330714225769
Validation loss: 2.1802201122045517

Epoch: 5| Step: 1
Training loss: 0.8176398277282715
Validation loss: 2.269734740257263

Epoch: 5| Step: 2
Training loss: 0.43438538908958435
Validation loss: 2.209433674812317

Epoch: 5| Step: 3
Training loss: 0.781220555305481
Validation loss: 2.1910602847735086

Epoch: 5| Step: 4
Training loss: 0.2745165228843689
Validation loss: 2.1704198519388833

Epoch: 5| Step: 5
Training loss: 0.9362108111381531
Validation loss: 2.1354170590639114

Epoch: 5| Step: 6
Training loss: 0.5271661877632141
Validation loss: 2.193045159180959

Epoch: 5| Step: 7
Training loss: 0.33055776357650757
Validation loss: 2.1779746214548745

Epoch: 5| Step: 8
Training loss: 0.2699379324913025
Validation loss: 2.1793977369864783

Epoch: 5| Step: 9
Training loss: 0.5117636919021606
Validation loss: 2.199288626511892

Epoch: 5| Step: 10
Training loss: 0.6162480115890503
Validation loss: 2.2826503813266754

Epoch: 5| Step: 11
Training loss: 1.4834558963775635
Validation loss: 2.3223261535167694

Epoch: 254| Step: 0
Training loss: 0.7244864702224731
Validation loss: 2.262714316447576

Epoch: 5| Step: 1
Training loss: 0.4799443781375885
Validation loss: 2.230716953674952

Epoch: 5| Step: 2
Training loss: 0.5646309852600098
Validation loss: 2.155292163292567

Epoch: 5| Step: 3
Training loss: 0.4563508629798889
Validation loss: 2.16158993045489

Epoch: 5| Step: 4
Training loss: 0.4643325209617615
Validation loss: 2.1397620340188346

Epoch: 5| Step: 5
Training loss: 0.5181401968002319
Validation loss: 2.144243617852529

Epoch: 5| Step: 6
Training loss: 0.45355647802352905
Validation loss: 2.1393599013487496

Epoch: 5| Step: 7
Training loss: 0.5922116041183472
Validation loss: 2.2246508498986564

Epoch: 5| Step: 8
Training loss: 0.6104621291160583
Validation loss: 2.1850730876127877

Epoch: 5| Step: 9
Training loss: 0.5002326965332031
Validation loss: 2.274837280313174

Epoch: 5| Step: 10
Training loss: 0.5007280111312866
Validation loss: 2.2580423752466836

Epoch: 5| Step: 11
Training loss: 0.36545443534851074
Validation loss: 2.1776341994603476

Epoch: 255| Step: 0
Training loss: 0.3601471185684204
Validation loss: 2.1418704092502594

Epoch: 5| Step: 1
Training loss: 0.5679165124893188
Validation loss: 2.1701641579469046

Epoch: 5| Step: 2
Training loss: 0.6146342158317566
Validation loss: 2.1603907644748688

Epoch: 5| Step: 3
Training loss: 0.39085209369659424
Validation loss: 2.1238579948743186

Epoch: 5| Step: 4
Training loss: 0.5633499026298523
Validation loss: 2.1362292915582657

Epoch: 5| Step: 5
Training loss: 0.4098857045173645
Validation loss: 2.160410443941752

Epoch: 5| Step: 6
Training loss: 0.7975548505783081
Validation loss: 2.258716652790705

Epoch: 5| Step: 7
Training loss: 0.21181616187095642
Validation loss: 2.2083734224239984

Epoch: 5| Step: 8
Training loss: 0.5595653653144836
Validation loss: 2.2077810863653817

Epoch: 5| Step: 9
Training loss: 0.6800093650817871
Validation loss: 2.1733676195144653

Epoch: 5| Step: 10
Training loss: 0.4934471547603607
Validation loss: 2.1787802328666053

Epoch: 5| Step: 11
Training loss: 0.6801904439926147
Validation loss: 2.1579726338386536

Epoch: 256| Step: 0
Training loss: 0.5606109499931335
Validation loss: 2.1556794742743173

Epoch: 5| Step: 1
Training loss: 0.42185378074645996
Validation loss: 2.159980744123459

Epoch: 5| Step: 2
Training loss: 0.7332339882850647
Validation loss: 2.170993139346441

Epoch: 5| Step: 3
Training loss: 0.3980197012424469
Validation loss: 2.197139799594879

Epoch: 5| Step: 4
Training loss: 0.6472499966621399
Validation loss: 2.1826691379149756

Epoch: 5| Step: 5
Training loss: 0.6190163493156433
Validation loss: 2.186736265818278

Epoch: 5| Step: 6
Training loss: 0.5293499827384949
Validation loss: 2.2071957141160965

Epoch: 5| Step: 7
Training loss: 0.35913175344467163
Validation loss: 2.1478359599908194

Epoch: 5| Step: 8
Training loss: 0.35408276319503784
Validation loss: 2.1654566576083503

Epoch: 5| Step: 9
Training loss: 0.47654977440834045
Validation loss: 2.159785936276118

Epoch: 5| Step: 10
Training loss: 0.21207764744758606
Validation loss: 2.156084358692169

Epoch: 5| Step: 11
Training loss: 0.6342939138412476
Validation loss: 2.1856825202703476

Epoch: 257| Step: 0
Training loss: 0.3065463900566101
Validation loss: 2.1632994512716928

Epoch: 5| Step: 1
Training loss: 0.31857946515083313
Validation loss: 2.1876395493745804

Epoch: 5| Step: 2
Training loss: 0.5021020770072937
Validation loss: 2.1410213311513266

Epoch: 5| Step: 3
Training loss: 0.4697142541408539
Validation loss: 2.1327859411636987

Epoch: 5| Step: 4
Training loss: 0.26390355825424194
Validation loss: 2.226527512073517

Epoch: 5| Step: 5
Training loss: 0.4991385340690613
Validation loss: 2.164556364218394

Epoch: 5| Step: 6
Training loss: 0.555858314037323
Validation loss: 2.1453879475593567

Epoch: 5| Step: 7
Training loss: 0.25333482027053833
Validation loss: 2.194735830028852

Epoch: 5| Step: 8
Training loss: 0.7668310403823853
Validation loss: 2.1879245390494666

Epoch: 5| Step: 9
Training loss: 0.402965247631073
Validation loss: 2.179039711753527

Epoch: 5| Step: 10
Training loss: 0.48609957098960876
Validation loss: 2.190825273593267

Epoch: 5| Step: 11
Training loss: 0.3347114324569702
Validation loss: 2.21511239806811

Epoch: 258| Step: 0
Training loss: 0.29529672861099243
Validation loss: 2.211473266283671

Epoch: 5| Step: 1
Training loss: 0.6060539484024048
Validation loss: 2.201678012808164

Epoch: 5| Step: 2
Training loss: 0.3988630771636963
Validation loss: 2.1705046544472375

Epoch: 5| Step: 3
Training loss: 0.34974974393844604
Validation loss: 2.1945630411307016

Epoch: 5| Step: 4
Training loss: 0.49018025398254395
Validation loss: 2.199307789405187

Epoch: 5| Step: 5
Training loss: 0.4322344660758972
Validation loss: 2.1649804015954337

Epoch: 5| Step: 6
Training loss: 0.620339035987854
Validation loss: 2.11496672530969

Epoch: 5| Step: 7
Training loss: 0.2811729609966278
Validation loss: 2.188933496673902

Epoch: 5| Step: 8
Training loss: 0.7056369185447693
Validation loss: 2.219226131836573

Epoch: 5| Step: 9
Training loss: 0.3160800039768219
Validation loss: 2.1632183442513147

Epoch: 5| Step: 10
Training loss: 0.49916449189186096
Validation loss: 2.1794297844171524

Epoch: 5| Step: 11
Training loss: 0.42489659786224365
Validation loss: 2.2299377024173737

Epoch: 259| Step: 0
Training loss: 0.4118768572807312
Validation loss: 2.2041253248850503

Epoch: 5| Step: 1
Training loss: 0.3993951976299286
Validation loss: 2.183012252052625

Epoch: 5| Step: 2
Training loss: 0.749728798866272
Validation loss: 2.144883652528127

Epoch: 5| Step: 3
Training loss: 0.5433454513549805
Validation loss: 2.203528801600138

Epoch: 5| Step: 4
Training loss: 0.5872983336448669
Validation loss: 2.173086499174436

Epoch: 5| Step: 5
Training loss: 0.4111357629299164
Validation loss: 2.1775064220031104

Epoch: 5| Step: 6
Training loss: 0.38523948192596436
Validation loss: 2.1957390209039054

Epoch: 5| Step: 7
Training loss: 0.5360764861106873
Validation loss: 2.113761693239212

Epoch: 5| Step: 8
Training loss: 0.5647674798965454
Validation loss: 2.1995350321133933

Epoch: 5| Step: 9
Training loss: 0.2310965359210968
Validation loss: 2.1663163900375366

Epoch: 5| Step: 10
Training loss: 0.44563865661621094
Validation loss: 2.194765875736872

Epoch: 5| Step: 11
Training loss: 0.21915221214294434
Validation loss: 2.212147240837415

Epoch: 260| Step: 0
Training loss: 0.3154025375843048
Validation loss: 2.138652965426445

Epoch: 5| Step: 1
Training loss: 0.7199437022209167
Validation loss: 2.2084335386753082

Epoch: 5| Step: 2
Training loss: 0.2658452093601227
Validation loss: 2.190638706088066

Epoch: 5| Step: 3
Training loss: 0.42937135696411133
Validation loss: 2.224864433209101

Epoch: 5| Step: 4
Training loss: 0.4608469605445862
Validation loss: 2.2904752592245736

Epoch: 5| Step: 5
Training loss: 0.7578502297401428
Validation loss: 2.2882473170757294

Epoch: 5| Step: 6
Training loss: 0.5440662503242493
Validation loss: 2.2819162706534066

Epoch: 5| Step: 7
Training loss: 0.4007847309112549
Validation loss: 2.248653680086136

Epoch: 5| Step: 8
Training loss: 0.20909066498279572
Validation loss: 2.1695887049039206

Epoch: 5| Step: 9
Training loss: 0.44358310103416443
Validation loss: 2.127211352189382

Epoch: 5| Step: 10
Training loss: 0.6135141253471375
Validation loss: 2.1786754379669824

Epoch: 5| Step: 11
Training loss: 0.900035560131073
Validation loss: 2.145528092980385

Epoch: 261| Step: 0
Training loss: 0.5651887059211731
Validation loss: 2.1740885575612388

Epoch: 5| Step: 1
Training loss: 0.3538156747817993
Validation loss: 2.161074231068293

Epoch: 5| Step: 2
Training loss: 1.0426641702651978
Validation loss: 2.173085778951645

Epoch: 5| Step: 3
Training loss: 0.45686960220336914
Validation loss: 2.2148562421401343

Epoch: 5| Step: 4
Training loss: 0.48324209451675415
Validation loss: 2.181011065840721

Epoch: 5| Step: 5
Training loss: 0.21893298625946045
Validation loss: 2.2067189117272696

Epoch: 5| Step: 6
Training loss: 0.3950757682323456
Validation loss: 2.265355492631594

Epoch: 5| Step: 7
Training loss: 0.3347765803337097
Validation loss: 2.208447833855947

Epoch: 5| Step: 8
Training loss: 0.4107452929019928
Validation loss: 2.175899932781855

Epoch: 5| Step: 9
Training loss: 0.3387161195278168
Validation loss: 2.193430945277214

Epoch: 5| Step: 10
Training loss: 0.6214743852615356
Validation loss: 2.156717469294866

Epoch: 5| Step: 11
Training loss: 0.11979955434799194
Validation loss: 2.1701825857162476

Epoch: 262| Step: 0
Training loss: 0.5175638794898987
Validation loss: 2.1335310538609824

Epoch: 5| Step: 1
Training loss: 0.44193124771118164
Validation loss: 2.1195445458094277

Epoch: 5| Step: 2
Training loss: 0.23889438807964325
Validation loss: 2.1627303461233773

Epoch: 5| Step: 3
Training loss: 0.7460275888442993
Validation loss: 2.1877909998099008

Epoch: 5| Step: 4
Training loss: 0.5580013990402222
Validation loss: 2.19282728433609

Epoch: 5| Step: 5
Training loss: 0.4923442304134369
Validation loss: 2.237565870086352

Epoch: 5| Step: 6
Training loss: 0.4250729978084564
Validation loss: 2.169585958123207

Epoch: 5| Step: 7
Training loss: 0.4126749634742737
Validation loss: 2.186339259147644

Epoch: 5| Step: 8
Training loss: 0.44374561309814453
Validation loss: 2.1490548501412072

Epoch: 5| Step: 9
Training loss: 0.455956369638443
Validation loss: 2.198014130194982

Epoch: 5| Step: 10
Training loss: 0.6699492931365967
Validation loss: 2.1620126565297446

Epoch: 5| Step: 11
Training loss: 1.0042355060577393
Validation loss: 2.1981757829586663

Epoch: 263| Step: 0
Training loss: 0.35718613862991333
Validation loss: 2.1411020010709763

Epoch: 5| Step: 1
Training loss: 0.6608282327651978
Validation loss: 2.221111367146174

Epoch: 5| Step: 2
Training loss: 0.3617825508117676
Validation loss: 2.203471561272939

Epoch: 5| Step: 3
Training loss: 0.44612041115760803
Validation loss: 2.2094039221604667

Epoch: 5| Step: 4
Training loss: 0.7332911491394043
Validation loss: 2.177357465028763

Epoch: 5| Step: 5
Training loss: 0.41917166113853455
Validation loss: 2.2230506986379623

Epoch: 5| Step: 6
Training loss: 0.33560043573379517
Validation loss: 2.1778716146945953

Epoch: 5| Step: 7
Training loss: 0.5033015012741089
Validation loss: 2.1516213913758597

Epoch: 5| Step: 8
Training loss: 0.31726789474487305
Validation loss: 2.1749628285566964

Epoch: 5| Step: 9
Training loss: 0.540980875492096
Validation loss: 2.177319273352623

Epoch: 5| Step: 10
Training loss: 0.37825626134872437
Validation loss: 2.2177052249511084

Epoch: 5| Step: 11
Training loss: 0.5157623887062073
Validation loss: 2.1707224001487098

Epoch: 264| Step: 0
Training loss: 0.23557782173156738
Validation loss: 2.210323224465052

Epoch: 5| Step: 1
Training loss: 0.4075380265712738
Validation loss: 2.1631287137667337

Epoch: 5| Step: 2
Training loss: 0.6461782455444336
Validation loss: 2.1985455254713693

Epoch: 5| Step: 3
Training loss: 0.5325459837913513
Validation loss: 2.1397273441155753

Epoch: 5| Step: 4
Training loss: 0.7638810873031616
Validation loss: 2.229861795902252

Epoch: 5| Step: 5
Training loss: 0.6667569279670715
Validation loss: 2.183259571592013

Epoch: 5| Step: 6
Training loss: 0.31630396842956543
Validation loss: 2.2103103597958884

Epoch: 5| Step: 7
Training loss: 0.2603495121002197
Validation loss: 2.221762383977572

Epoch: 5| Step: 8
Training loss: 0.2477368861436844
Validation loss: 2.1595658560593924

Epoch: 5| Step: 9
Training loss: 0.2657666802406311
Validation loss: 2.1733680764834085

Epoch: 5| Step: 10
Training loss: 0.298678994178772
Validation loss: 2.1769056220849357

Epoch: 5| Step: 11
Training loss: 0.7283251285552979
Validation loss: 2.175974354147911

Epoch: 265| Step: 0
Training loss: 0.47178903222084045
Validation loss: 2.1817351380983987

Epoch: 5| Step: 1
Training loss: 0.40489301085472107
Validation loss: 2.1430756002664566

Epoch: 5| Step: 2
Training loss: 0.39691776037216187
Validation loss: 2.2488669951756797

Epoch: 5| Step: 3
Training loss: 0.7666879892349243
Validation loss: 2.1868104288975396

Epoch: 5| Step: 4
Training loss: 0.3424796462059021
Validation loss: 2.170542190472285

Epoch: 5| Step: 5
Training loss: 0.519903838634491
Validation loss: 2.1753367433945336

Epoch: 5| Step: 6
Training loss: 0.42365676164627075
Validation loss: 2.190365269780159

Epoch: 5| Step: 7
Training loss: 0.36524853110313416
Validation loss: 2.21440323193868

Epoch: 5| Step: 8
Training loss: 0.3443446755409241
Validation loss: 2.1605821400880814

Epoch: 5| Step: 9
Training loss: 0.46015262603759766
Validation loss: 2.1740736812353134

Epoch: 5| Step: 10
Training loss: 0.29769301414489746
Validation loss: 2.1912842194239297

Epoch: 5| Step: 11
Training loss: 0.5473902225494385
Validation loss: 2.2385621269543967

Epoch: 266| Step: 0
Training loss: 0.42102178931236267
Validation loss: 2.208390345176061

Epoch: 5| Step: 1
Training loss: 0.5202297568321228
Validation loss: 2.156505733728409

Epoch: 5| Step: 2
Training loss: 0.287834107875824
Validation loss: 2.2258594632148743

Epoch: 5| Step: 3
Training loss: 0.2993103563785553
Validation loss: 2.26094514131546

Epoch: 5| Step: 4
Training loss: 0.36874085664749146
Validation loss: 2.1969361255566278

Epoch: 5| Step: 5
Training loss: 0.3464706838130951
Validation loss: 2.2151014705499015

Epoch: 5| Step: 6
Training loss: 0.3820492625236511
Validation loss: 2.1724355965852737

Epoch: 5| Step: 7
Training loss: 0.4624848961830139
Validation loss: 2.173165495196978

Epoch: 5| Step: 8
Training loss: 0.32501834630966187
Validation loss: 2.1845340629418692

Epoch: 5| Step: 9
Training loss: 0.4196353852748871
Validation loss: 2.138389358917872

Epoch: 5| Step: 10
Training loss: 0.7504186034202576
Validation loss: 2.1722292602062225

Epoch: 5| Step: 11
Training loss: 1.255082130432129
Validation loss: 2.157766809066137

Epoch: 267| Step: 0
Training loss: 0.24621649086475372
Validation loss: 2.1821074138085046

Epoch: 5| Step: 1
Training loss: 0.2361142933368683
Validation loss: 2.173851490020752

Epoch: 5| Step: 2
Training loss: 0.6525161266326904
Validation loss: 2.1892401625712714

Epoch: 5| Step: 3
Training loss: 0.3784448206424713
Validation loss: 2.1601569056510925

Epoch: 5| Step: 4
Training loss: 0.32843926548957825
Validation loss: 2.176373675465584

Epoch: 5| Step: 5
Training loss: 0.4266362190246582
Validation loss: 2.185747896631559

Epoch: 5| Step: 6
Training loss: 0.24742154777050018
Validation loss: 2.190029283364614

Epoch: 5| Step: 7
Training loss: 0.6368155479431152
Validation loss: 2.1675125112136207

Epoch: 5| Step: 8
Training loss: 0.4918389320373535
Validation loss: 2.179612403114637

Epoch: 5| Step: 9
Training loss: 0.39727750420570374
Validation loss: 2.194276531537374

Epoch: 5| Step: 10
Training loss: 0.7063135504722595
Validation loss: 2.1641805122296014

Epoch: 5| Step: 11
Training loss: 0.2103395164012909
Validation loss: 2.1711478928724923

Epoch: 268| Step: 0
Training loss: 0.5834225416183472
Validation loss: 2.1729174852371216

Epoch: 5| Step: 1
Training loss: 0.6097962856292725
Validation loss: 2.1897124350070953

Epoch: 5| Step: 2
Training loss: 0.7280840873718262
Validation loss: 2.215817908445994

Epoch: 5| Step: 3
Training loss: 0.38600608706474304
Validation loss: 2.193043276667595

Epoch: 5| Step: 4
Training loss: 0.44170594215393066
Validation loss: 2.191548317670822

Epoch: 5| Step: 5
Training loss: 0.3492322564125061
Validation loss: 2.1410291691621146

Epoch: 5| Step: 6
Training loss: 0.3780497908592224
Validation loss: 2.2200287083784738

Epoch: 5| Step: 7
Training loss: 0.3120788633823395
Validation loss: 2.1591521203517914

Epoch: 5| Step: 8
Training loss: 0.2987295985221863
Validation loss: 2.1745082984368005

Epoch: 5| Step: 9
Training loss: 0.3665192723274231
Validation loss: 2.1886023183663688

Epoch: 5| Step: 10
Training loss: 0.30581241846084595
Validation loss: 2.2126370122035346

Epoch: 5| Step: 11
Training loss: 1.0392310619354248
Validation loss: 2.158177986741066

Epoch: 269| Step: 0
Training loss: 0.2733455300331116
Validation loss: 2.143144831061363

Epoch: 5| Step: 1
Training loss: 0.3433306813240051
Validation loss: 2.126028726498286

Epoch: 5| Step: 2
Training loss: 0.38294413685798645
Validation loss: 2.1255062917868295

Epoch: 5| Step: 3
Training loss: 0.5479066967964172
Validation loss: 2.185519432028135

Epoch: 5| Step: 4
Training loss: 0.273954302072525
Validation loss: 2.1917555828889212

Epoch: 5| Step: 5
Training loss: 0.38597002625465393
Validation loss: 2.233300824960073

Epoch: 5| Step: 6
Training loss: 0.5191753506660461
Validation loss: 2.2224984715382257

Epoch: 5| Step: 7
Training loss: 0.6823529005050659
Validation loss: 2.2232172389825187

Epoch: 5| Step: 8
Training loss: 0.22581252455711365
Validation loss: 2.190396413207054

Epoch: 5| Step: 9
Training loss: 0.8023616075515747
Validation loss: 2.163535103201866

Epoch: 5| Step: 10
Training loss: 0.4001101553440094
Validation loss: 2.1837024291356406

Epoch: 5| Step: 11
Training loss: 0.335145503282547
Validation loss: 2.19687627752622

Epoch: 270| Step: 0
Training loss: 0.2728022038936615
Validation loss: 2.200061649084091

Epoch: 5| Step: 1
Training loss: 0.43180519342422485
Validation loss: 2.2307673494021096

Epoch: 5| Step: 2
Training loss: 0.3376428484916687
Validation loss: 2.1588732302188873

Epoch: 5| Step: 3
Training loss: 0.2979336977005005
Validation loss: 2.1770709107319512

Epoch: 5| Step: 4
Training loss: 0.7079045176506042
Validation loss: 2.1460983703533807

Epoch: 5| Step: 5
Training loss: 0.40420570969581604
Validation loss: 2.1557774543762207

Epoch: 5| Step: 6
Training loss: 0.3274933993816376
Validation loss: 2.165292282899221

Epoch: 5| Step: 7
Training loss: 0.28227323293685913
Validation loss: 2.160034661491712

Epoch: 5| Step: 8
Training loss: 0.8152861595153809
Validation loss: 2.2118620375792184

Epoch: 5| Step: 9
Training loss: 0.343360960483551
Validation loss: 2.181241268912951

Epoch: 5| Step: 10
Training loss: 0.5065726041793823
Validation loss: 2.207414448261261

Epoch: 5| Step: 11
Training loss: 0.26214611530303955
Validation loss: 2.1798680226008096

Epoch: 271| Step: 0
Training loss: 0.30977702140808105
Validation loss: 2.2029812882343927

Epoch: 5| Step: 1
Training loss: 0.5868312120437622
Validation loss: 2.1602333337068558

Epoch: 5| Step: 2
Training loss: 0.7590707540512085
Validation loss: 2.188307543595632

Epoch: 5| Step: 3
Training loss: 0.7256875038146973
Validation loss: 2.1693654557069144

Epoch: 5| Step: 4
Training loss: 1.0040525197982788
Validation loss: 2.148802950978279

Epoch: 5| Step: 5
Training loss: 0.3347182273864746
Validation loss: 2.1916086971759796

Epoch: 5| Step: 6
Training loss: 0.4782504141330719
Validation loss: 2.210181141893069

Epoch: 5| Step: 7
Training loss: 0.5411115884780884
Validation loss: 2.2562726885080338

Epoch: 5| Step: 8
Training loss: 0.548473596572876
Validation loss: 2.219657445947329

Epoch: 5| Step: 9
Training loss: 0.3068731725215912
Validation loss: 2.299307808279991

Epoch: 5| Step: 10
Training loss: 0.48931512236595154
Validation loss: 2.242136632402738

Epoch: 5| Step: 11
Training loss: 0.1456862986087799
Validation loss: 2.176813696821531

Epoch: 272| Step: 0
Training loss: 0.8150426149368286
Validation loss: 2.1415418684482574

Epoch: 5| Step: 1
Training loss: 0.46638941764831543
Validation loss: 2.1520944635073342

Epoch: 5| Step: 2
Training loss: 0.41332921385765076
Validation loss: 2.14799165725708

Epoch: 5| Step: 3
Training loss: 0.3880229592323303
Validation loss: 2.2030694037675858

Epoch: 5| Step: 4
Training loss: 0.49027305841445923
Validation loss: 2.2293817599614463

Epoch: 5| Step: 5
Training loss: 0.37109071016311646
Validation loss: 2.2787609001000724

Epoch: 5| Step: 6
Training loss: 0.34006547927856445
Validation loss: 2.2097754776477814

Epoch: 5| Step: 7
Training loss: 0.37162578105926514
Validation loss: 2.235191116730372

Epoch: 5| Step: 8
Training loss: 0.46690255403518677
Validation loss: 2.180673067768415

Epoch: 5| Step: 9
Training loss: 0.6670457720756531
Validation loss: 2.193790460626284

Epoch: 5| Step: 10
Training loss: 0.5233505964279175
Validation loss: 2.1892396410306296

Epoch: 5| Step: 11
Training loss: 0.3130232095718384
Validation loss: 2.1531372368335724

Epoch: 273| Step: 0
Training loss: 0.6305038928985596
Validation loss: 2.133168041706085

Epoch: 5| Step: 1
Training loss: 0.6752643585205078
Validation loss: 2.1684799989064536

Epoch: 5| Step: 2
Training loss: 0.36945754289627075
Validation loss: 2.174097925424576

Epoch: 5| Step: 3
Training loss: 0.43787670135498047
Validation loss: 2.2295355796813965

Epoch: 5| Step: 4
Training loss: 0.4704650938510895
Validation loss: 2.235035260518392

Epoch: 5| Step: 5
Training loss: 0.6600836515426636
Validation loss: 2.2766242822011313

Epoch: 5| Step: 6
Training loss: 0.780872642993927
Validation loss: 2.3055969129006066

Epoch: 5| Step: 7
Training loss: 0.5352575778961182
Validation loss: 2.2671440740426383

Epoch: 5| Step: 8
Training loss: 0.6362627744674683
Validation loss: 2.2302009711662927

Epoch: 5| Step: 9
Training loss: 0.533482015132904
Validation loss: 2.203827122847239

Epoch: 5| Step: 10
Training loss: 0.43048095703125
Validation loss: 2.1767507195472717

Epoch: 5| Step: 11
Training loss: 0.2195400893688202
Validation loss: 2.134900430838267

Epoch: 274| Step: 0
Training loss: 0.561883270740509
Validation loss: 2.1583755811055503

Epoch: 5| Step: 1
Training loss: 0.61763995885849
Validation loss: 2.146942655245463

Epoch: 5| Step: 2
Training loss: 0.5165995359420776
Validation loss: 2.1750683734814324

Epoch: 5| Step: 3
Training loss: 0.36234357953071594
Validation loss: 2.1769719272851944

Epoch: 5| Step: 4
Training loss: 0.4279994070529938
Validation loss: 2.203450287381808

Epoch: 5| Step: 5
Training loss: 0.7958948016166687
Validation loss: 2.231193701426188

Epoch: 5| Step: 6
Training loss: 0.8427274823188782
Validation loss: 2.262359857559204

Epoch: 5| Step: 7
Training loss: 0.6832301616668701
Validation loss: 2.238348642985026

Epoch: 5| Step: 8
Training loss: 0.593269944190979
Validation loss: 2.2193501691023507

Epoch: 5| Step: 9
Training loss: 0.31325048208236694
Validation loss: 2.1738791863123574

Epoch: 5| Step: 10
Training loss: 0.7372177243232727
Validation loss: 2.182903523246447

Epoch: 5| Step: 11
Training loss: 0.307442843914032
Validation loss: 2.1910321513811746

Epoch: 275| Step: 0
Training loss: 0.6100643277168274
Validation loss: 2.1458694487810135

Epoch: 5| Step: 1
Training loss: 0.44860023260116577
Validation loss: 2.134915351867676

Epoch: 5| Step: 2
Training loss: 0.3837427496910095
Validation loss: 2.155682384967804

Epoch: 5| Step: 3
Training loss: 0.6959238052368164
Validation loss: 2.234970619281133

Epoch: 5| Step: 4
Training loss: 0.5179243087768555
Validation loss: 2.2277822494506836

Epoch: 5| Step: 5
Training loss: 0.5809330940246582
Validation loss: 2.236830194791158

Epoch: 5| Step: 6
Training loss: 0.4434189200401306
Validation loss: 2.265088066458702

Epoch: 5| Step: 7
Training loss: 0.3477376401424408
Validation loss: 2.2084875305493674

Epoch: 5| Step: 8
Training loss: 0.5909731984138489
Validation loss: 2.2267262091239295

Epoch: 5| Step: 9
Training loss: 0.7658486366271973
Validation loss: 2.1933861672878265

Epoch: 5| Step: 10
Training loss: 0.46072831749916077
Validation loss: 2.105660855770111

Epoch: 5| Step: 11
Training loss: 0.6923894286155701
Validation loss: 2.16865836083889

Epoch: 276| Step: 0
Training loss: 0.3569573163986206
Validation loss: 2.1867082168658576

Epoch: 5| Step: 1
Training loss: 0.8025678396224976
Validation loss: 2.212506969769796

Epoch: 5| Step: 2
Training loss: 0.3327876925468445
Validation loss: 2.2404950658480325

Epoch: 5| Step: 3
Training loss: 0.404287725687027
Validation loss: 2.2477318346500397

Epoch: 5| Step: 4
Training loss: 0.4540737271308899
Validation loss: 2.2879324505726495

Epoch: 5| Step: 5
Training loss: 0.3577428162097931
Validation loss: 2.265115370353063

Epoch: 5| Step: 6
Training loss: 0.32209688425064087
Validation loss: 2.237070048848788

Epoch: 5| Step: 7
Training loss: 0.48588594794273376
Validation loss: 2.170248622695605

Epoch: 5| Step: 8
Training loss: 0.49318727850914
Validation loss: 2.1771217733621597

Epoch: 5| Step: 9
Training loss: 0.4625362455844879
Validation loss: 2.1727519730726876

Epoch: 5| Step: 10
Training loss: 0.9562107920646667
Validation loss: 2.183242122332255

Epoch: 5| Step: 11
Training loss: 0.2931387722492218
Validation loss: 2.184677536288897

Epoch: 277| Step: 0
Training loss: 0.299659788608551
Validation loss: 2.2380211303631463

Epoch: 5| Step: 1
Training loss: 0.26599735021591187
Validation loss: 2.206118335326513

Epoch: 5| Step: 2
Training loss: 0.4381827414035797
Validation loss: 2.2070011595884957

Epoch: 5| Step: 3
Training loss: 0.624531090259552
Validation loss: 2.2464085121949515

Epoch: 5| Step: 4
Training loss: 0.8270577192306519
Validation loss: 2.239963471889496

Epoch: 5| Step: 5
Training loss: 0.8451700210571289
Validation loss: 2.170255000392596

Epoch: 5| Step: 6
Training loss: 0.4789358079433441
Validation loss: 2.1465190599362054

Epoch: 5| Step: 7
Training loss: 0.37992948293685913
Validation loss: 2.121730590860049

Epoch: 5| Step: 8
Training loss: 0.482354074716568
Validation loss: 2.1386005133390427

Epoch: 5| Step: 9
Training loss: 0.4422551989555359
Validation loss: 2.1734068443377814

Epoch: 5| Step: 10
Training loss: 0.4197016656398773
Validation loss: 2.1752580404281616

Epoch: 5| Step: 11
Training loss: 1.7219948768615723
Validation loss: 2.1227586766084037

Epoch: 278| Step: 0
Training loss: 0.8165634274482727
Validation loss: 2.191413407524427

Epoch: 5| Step: 1
Training loss: 0.3555601239204407
Validation loss: 2.261272872487704

Epoch: 5| Step: 2
Training loss: 0.5927685499191284
Validation loss: 2.1736379812161126

Epoch: 5| Step: 3
Training loss: 0.2746157646179199
Validation loss: 2.1498149583737054

Epoch: 5| Step: 4
Training loss: 0.39452141523361206
Validation loss: 2.145975803335508

Epoch: 5| Step: 5
Training loss: 0.24706599116325378
Validation loss: 2.1721375534931817

Epoch: 5| Step: 6
Training loss: 0.43536290526390076
Validation loss: 2.1323139667510986

Epoch: 5| Step: 7
Training loss: 0.43473464250564575
Validation loss: 2.133173947532972

Epoch: 5| Step: 8
Training loss: 0.4025724530220032
Validation loss: 2.157293602824211

Epoch: 5| Step: 9
Training loss: 0.2910939157009125
Validation loss: 2.1677219569683075

Epoch: 5| Step: 10
Training loss: 0.5681819915771484
Validation loss: 2.147137865424156

Epoch: 5| Step: 11
Training loss: 0.4304279088973999
Validation loss: 2.188031032681465

Epoch: 279| Step: 0
Training loss: 0.5667132139205933
Validation loss: 2.1689768532911935

Epoch: 5| Step: 1
Training loss: 0.2793394923210144
Validation loss: 2.1484850545724234

Epoch: 5| Step: 2
Training loss: 0.3517467975616455
Validation loss: 2.21873739361763

Epoch: 5| Step: 3
Training loss: 0.6474364399909973
Validation loss: 2.160308609406153

Epoch: 5| Step: 4
Training loss: 0.4855884909629822
Validation loss: 2.145818814635277

Epoch: 5| Step: 5
Training loss: 0.43286556005477905
Validation loss: 2.153215472896894

Epoch: 5| Step: 6
Training loss: 0.24517393112182617
Validation loss: 2.136162221431732

Epoch: 5| Step: 7
Training loss: 0.6522165536880493
Validation loss: 2.2249257812897363

Epoch: 5| Step: 8
Training loss: 0.2366248071193695
Validation loss: 2.1888406922419867

Epoch: 5| Step: 9
Training loss: 0.3919745087623596
Validation loss: 2.193997244040171

Epoch: 5| Step: 10
Training loss: 0.35026130080223083
Validation loss: 2.22571824491024

Epoch: 5| Step: 11
Training loss: 0.3837880492210388
Validation loss: 2.152717113494873

Epoch: 280| Step: 0
Training loss: 0.32504770159721375
Validation loss: 2.2036335368951163

Epoch: 5| Step: 1
Training loss: 0.38838934898376465
Validation loss: 2.2152254382769265

Epoch: 5| Step: 2
Training loss: 0.29808515310287476
Validation loss: 2.214730143547058

Epoch: 5| Step: 3
Training loss: 0.19820749759674072
Validation loss: 2.1801406294107437

Epoch: 5| Step: 4
Training loss: 0.5553780794143677
Validation loss: 2.2265922725200653

Epoch: 5| Step: 5
Training loss: 0.5235482454299927
Validation loss: 2.2204820215702057

Epoch: 5| Step: 6
Training loss: 0.36272844672203064
Validation loss: 2.208056797583898

Epoch: 5| Step: 7
Training loss: 0.4728023409843445
Validation loss: 2.18751552204291

Epoch: 5| Step: 8
Training loss: 0.32220783829689026
Validation loss: 2.210746775070826

Epoch: 5| Step: 9
Training loss: 0.465346097946167
Validation loss: 2.189974620938301

Epoch: 5| Step: 10
Training loss: 0.2626109719276428
Validation loss: 2.2192749083042145

Epoch: 5| Step: 11
Training loss: 0.3384610414505005
Validation loss: 2.202809050679207

Epoch: 281| Step: 0
Training loss: 0.579998254776001
Validation loss: 2.2076005935668945

Epoch: 5| Step: 1
Training loss: 0.266275018453598
Validation loss: 2.248089075088501

Epoch: 5| Step: 2
Training loss: 0.44782519340515137
Validation loss: 2.233945702513059

Epoch: 5| Step: 3
Training loss: 0.34439095854759216
Validation loss: 2.1857024927934012

Epoch: 5| Step: 4
Training loss: 0.7569711208343506
Validation loss: 2.172416071097056

Epoch: 5| Step: 5
Training loss: 0.39508095383644104
Validation loss: 2.216890578468641

Epoch: 5| Step: 6
Training loss: 0.39487701654434204
Validation loss: 2.15874782204628

Epoch: 5| Step: 7
Training loss: 0.33392420411109924
Validation loss: 2.2330313523610434

Epoch: 5| Step: 8
Training loss: 0.5926069021224976
Validation loss: 2.215340331196785

Epoch: 5| Step: 9
Training loss: 0.2579818069934845
Validation loss: 2.213107407093048

Epoch: 5| Step: 10
Training loss: 0.36295369267463684
Validation loss: 2.1680103540420532

Epoch: 5| Step: 11
Training loss: 0.2185152769088745
Validation loss: 2.1940332849820456

Epoch: 282| Step: 0
Training loss: 0.4078424572944641
Validation loss: 2.1575002620617547

Epoch: 5| Step: 1
Training loss: 0.25556883215904236
Validation loss: 2.1683891067902246

Epoch: 5| Step: 2
Training loss: 0.2656394839286804
Validation loss: 2.174365142981211

Epoch: 5| Step: 3
Training loss: 0.656396746635437
Validation loss: 2.1510810057322183

Epoch: 5| Step: 4
Training loss: 0.6107343435287476
Validation loss: 2.19805571436882

Epoch: 5| Step: 5
Training loss: 0.3412904441356659
Validation loss: 2.185471256573995

Epoch: 5| Step: 6
Training loss: 0.47872114181518555
Validation loss: 2.193545480569204

Epoch: 5| Step: 7
Training loss: 0.45080700516700745
Validation loss: 2.2320167471965155

Epoch: 5| Step: 8
Training loss: 0.37025365233421326
Validation loss: 2.21163817246755

Epoch: 5| Step: 9
Training loss: 0.2893065810203552
Validation loss: 2.2292867253224053

Epoch: 5| Step: 10
Training loss: 0.5275861620903015
Validation loss: 2.165705511967341

Epoch: 5| Step: 11
Training loss: 0.174841046333313
Validation loss: 2.192083721359571

Epoch: 283| Step: 0
Training loss: 0.5589829683303833
Validation loss: 2.126381610830625

Epoch: 5| Step: 1
Training loss: 0.45053666830062866
Validation loss: 2.1782954881588616

Epoch: 5| Step: 2
Training loss: 0.24608783423900604
Validation loss: 2.1614819020032883

Epoch: 5| Step: 3
Training loss: 0.27603670954704285
Validation loss: 2.1611509919166565

Epoch: 5| Step: 4
Training loss: 0.4383562505245209
Validation loss: 2.181094318628311

Epoch: 5| Step: 5
Training loss: 0.5307073593139648
Validation loss: 2.214582016070684

Epoch: 5| Step: 6
Training loss: 0.5808873772621155
Validation loss: 2.1902912110090256

Epoch: 5| Step: 7
Training loss: 0.30812010169029236
Validation loss: 2.216613213221232

Epoch: 5| Step: 8
Training loss: 0.6695008873939514
Validation loss: 2.1607940793037415

Epoch: 5| Step: 9
Training loss: 0.6881352066993713
Validation loss: 2.1966655254364014

Epoch: 5| Step: 10
Training loss: 0.3858329653739929
Validation loss: 2.109296237428983

Epoch: 5| Step: 11
Training loss: 0.32281172275543213
Validation loss: 2.1670418630043664

Epoch: 284| Step: 0
Training loss: 0.2345292568206787
Validation loss: 2.1731942892074585

Epoch: 5| Step: 1
Training loss: 0.27556055784225464
Validation loss: 2.1795714994271598

Epoch: 5| Step: 2
Training loss: 0.49240532517433167
Validation loss: 2.177988479534785

Epoch: 5| Step: 3
Training loss: 0.3038385808467865
Validation loss: 2.1496872355540595

Epoch: 5| Step: 4
Training loss: 0.6116225123405457
Validation loss: 2.2306682666142783

Epoch: 5| Step: 5
Training loss: 0.4612336754798889
Validation loss: 2.1845977008342743

Epoch: 5| Step: 6
Training loss: 0.3803025484085083
Validation loss: 2.1890822649002075

Epoch: 5| Step: 7
Training loss: 0.2135879546403885
Validation loss: 2.1632770697275796

Epoch: 5| Step: 8
Training loss: 0.4617578387260437
Validation loss: 2.2350773165623345

Epoch: 5| Step: 9
Training loss: 0.34629449248313904
Validation loss: 2.1711268623669944

Epoch: 5| Step: 10
Training loss: 0.7189130783081055
Validation loss: 2.1270662049452462

Epoch: 5| Step: 11
Training loss: 0.3031908869743347
Validation loss: 2.136264647046725

Epoch: 285| Step: 0
Training loss: 0.18472036719322205
Validation loss: 2.1793847332398095

Epoch: 5| Step: 1
Training loss: 0.38865581154823303
Validation loss: 2.2630163530508676

Epoch: 5| Step: 2
Training loss: 0.5040998458862305
Validation loss: 2.247062861919403

Epoch: 5| Step: 3
Training loss: 0.4426461160182953
Validation loss: 2.218968689441681

Epoch: 5| Step: 4
Training loss: 0.3761882781982422
Validation loss: 2.2019557456175485

Epoch: 5| Step: 5
Training loss: 0.6737512350082397
Validation loss: 2.1484104643265405

Epoch: 5| Step: 6
Training loss: 0.39777418971061707
Validation loss: 2.1699222922325134

Epoch: 5| Step: 7
Training loss: 0.863143801689148
Validation loss: 2.140570958455404

Epoch: 5| Step: 8
Training loss: 0.4128497242927551
Validation loss: 2.143583913644155

Epoch: 5| Step: 9
Training loss: 0.32541459798812866
Validation loss: 2.1715992589791617

Epoch: 5| Step: 10
Training loss: 0.4583195745944977
Validation loss: 2.2205222646395364

Epoch: 5| Step: 11
Training loss: 1.0333149433135986
Validation loss: 2.16531565785408

Epoch: 286| Step: 0
Training loss: 0.44679293036460876
Validation loss: 2.2699228872855506

Epoch: 5| Step: 1
Training loss: 0.7640652656555176
Validation loss: 2.1830845872561135

Epoch: 5| Step: 2
Training loss: 0.40496405959129333
Validation loss: 2.272312472263972

Epoch: 5| Step: 3
Training loss: 0.43461257219314575
Validation loss: 2.212303474545479

Epoch: 5| Step: 4
Training loss: 0.3961765766143799
Validation loss: 2.165107245246569

Epoch: 5| Step: 5
Training loss: 0.6741630434989929
Validation loss: 2.1411149501800537

Epoch: 5| Step: 6
Training loss: 0.6498407125473022
Validation loss: 2.1355276803175607

Epoch: 5| Step: 7
Training loss: 0.5413463711738586
Validation loss: 2.1525952567656836

Epoch: 5| Step: 8
Training loss: 0.4164637625217438
Validation loss: 2.1548273960749307

Epoch: 5| Step: 9
Training loss: 0.5305474400520325
Validation loss: 2.1727259010076523

Epoch: 5| Step: 10
Training loss: 0.4817272126674652
Validation loss: 2.173666978875796

Epoch: 5| Step: 11
Training loss: 0.2366316318511963
Validation loss: 2.1720054298639297

Epoch: 287| Step: 0
Training loss: 0.41271480917930603
Validation loss: 2.2016087671120963

Epoch: 5| Step: 1
Training loss: 0.28153514862060547
Validation loss: 2.170523519317309

Epoch: 5| Step: 2
Training loss: 0.31550872325897217
Validation loss: 2.172830561796824

Epoch: 5| Step: 3
Training loss: 0.2292279303073883
Validation loss: 2.161024490992228

Epoch: 5| Step: 4
Training loss: 0.3131123185157776
Validation loss: 2.1780468622843423

Epoch: 5| Step: 5
Training loss: 0.6094084978103638
Validation loss: 2.1521175553401313

Epoch: 5| Step: 6
Training loss: 0.21077299118041992
Validation loss: 2.1943913648525872

Epoch: 5| Step: 7
Training loss: 0.567891001701355
Validation loss: 2.1399925500154495

Epoch: 5| Step: 8
Training loss: 0.6803487539291382
Validation loss: 2.210343132416407

Epoch: 5| Step: 9
Training loss: 0.44766244292259216
Validation loss: 2.2160181601842246

Epoch: 5| Step: 10
Training loss: 0.4206147789955139
Validation loss: 2.1893149415651956

Epoch: 5| Step: 11
Training loss: 0.38792169094085693
Validation loss: 2.145819917321205

Epoch: 288| Step: 0
Training loss: 0.6894444227218628
Validation loss: 2.1849248856306076

Epoch: 5| Step: 1
Training loss: 0.385468453168869
Validation loss: 2.1479151298602424

Epoch: 5| Step: 2
Training loss: 0.4325138032436371
Validation loss: 2.2106845527887344

Epoch: 5| Step: 3
Training loss: 0.5550379753112793
Validation loss: 2.1941580971082053

Epoch: 5| Step: 4
Training loss: 0.35571759939193726
Validation loss: 2.1829700817664466

Epoch: 5| Step: 5
Training loss: 0.3478734493255615
Validation loss: 2.2047086159388223

Epoch: 5| Step: 6
Training loss: 0.2989650368690491
Validation loss: 2.219814976056417

Epoch: 5| Step: 7
Training loss: 0.4244823455810547
Validation loss: 2.226737603545189

Epoch: 5| Step: 8
Training loss: 0.20148925483226776
Validation loss: 2.182285969456037

Epoch: 5| Step: 9
Training loss: 0.449453741312027
Validation loss: 2.176057979464531

Epoch: 5| Step: 10
Training loss: 0.4216848313808441
Validation loss: 2.172926510373751

Epoch: 5| Step: 11
Training loss: 0.19697058200836182
Validation loss: 2.1491415798664093

Epoch: 289| Step: 0
Training loss: 0.250302255153656
Validation loss: 2.2330626298983893

Epoch: 5| Step: 1
Training loss: 0.44432562589645386
Validation loss: 2.194021165370941

Epoch: 5| Step: 2
Training loss: 0.47157230973243713
Validation loss: 2.195877432823181

Epoch: 5| Step: 3
Training loss: 0.2598072588443756
Validation loss: 2.2184240420659385

Epoch: 5| Step: 4
Training loss: 0.21993955969810486
Validation loss: 2.184142082929611

Epoch: 5| Step: 5
Training loss: 0.39837169647216797
Validation loss: 2.2072717994451523

Epoch: 5| Step: 6
Training loss: 0.3973385691642761
Validation loss: 2.1808048685391745

Epoch: 5| Step: 7
Training loss: 0.8127665519714355
Validation loss: 2.1487631450096765

Epoch: 5| Step: 8
Training loss: 0.5057624578475952
Validation loss: 2.1996609270572662

Epoch: 5| Step: 9
Training loss: 0.4309140741825104
Validation loss: 2.1835205803314843

Epoch: 5| Step: 10
Training loss: 0.273404061794281
Validation loss: 2.208703209956487

Epoch: 5| Step: 11
Training loss: 0.8659043312072754
Validation loss: 2.196486304203669

Epoch: 290| Step: 0
Training loss: 0.30858030915260315
Validation loss: 2.167921021580696

Epoch: 5| Step: 1
Training loss: 0.464816153049469
Validation loss: 2.148197501897812

Epoch: 5| Step: 2
Training loss: 0.3468976616859436
Validation loss: 2.158048391342163

Epoch: 5| Step: 3
Training loss: 0.4984942376613617
Validation loss: 2.1307124495506287

Epoch: 5| Step: 4
Training loss: 0.4375775456428528
Validation loss: 2.217890759309133

Epoch: 5| Step: 5
Training loss: 0.4744819104671478
Validation loss: 2.2193139592806497

Epoch: 5| Step: 6
Training loss: 0.46720343828201294
Validation loss: 2.2148570517698922

Epoch: 5| Step: 7
Training loss: 0.4099227488040924
Validation loss: 2.2221340785423913

Epoch: 5| Step: 8
Training loss: 0.32956528663635254
Validation loss: 2.2147906720638275

Epoch: 5| Step: 9
Training loss: 0.257844477891922
Validation loss: 2.1667356888453164

Epoch: 5| Step: 10
Training loss: 0.5567123293876648
Validation loss: 2.2040278712908425

Epoch: 5| Step: 11
Training loss: 0.42350876331329346
Validation loss: 2.2087949315706887

Epoch: 291| Step: 0
Training loss: 0.5062133073806763
Validation loss: 2.1958782176176705

Epoch: 5| Step: 1
Training loss: 0.4669509828090668
Validation loss: 2.1756035635868707

Epoch: 5| Step: 2
Training loss: 0.3735429346561432
Validation loss: 2.2321129739284515

Epoch: 5| Step: 3
Training loss: 0.5085751414299011
Validation loss: 2.2068921625614166

Epoch: 5| Step: 4
Training loss: 0.39487630128860474
Validation loss: 2.2072279949982962

Epoch: 5| Step: 5
Training loss: 0.25826287269592285
Validation loss: 2.2277547965447106

Epoch: 5| Step: 6
Training loss: 0.29592365026474
Validation loss: 2.169279709458351

Epoch: 5| Step: 7
Training loss: 0.28225865960121155
Validation loss: 2.196225235859553

Epoch: 5| Step: 8
Training loss: 0.5579401254653931
Validation loss: 2.202787548303604

Epoch: 5| Step: 9
Training loss: 0.37210527062416077
Validation loss: 2.1890979558229446

Epoch: 5| Step: 10
Training loss: 0.4506677985191345
Validation loss: 2.1896538138389587

Epoch: 5| Step: 11
Training loss: 0.1496589183807373
Validation loss: 2.211630562941233

Epoch: 292| Step: 0
Training loss: 0.4421292245388031
Validation loss: 2.227024873097738

Epoch: 5| Step: 1
Training loss: 0.25757163763046265
Validation loss: 2.1883751451969147

Epoch: 5| Step: 2
Training loss: 0.3241746425628662
Validation loss: 2.1361840615669885

Epoch: 5| Step: 3
Training loss: 0.48547250032424927
Validation loss: 2.1539331475893655

Epoch: 5| Step: 4
Training loss: 0.6827592253684998
Validation loss: 2.1639121820529303

Epoch: 5| Step: 5
Training loss: 0.39914605021476746
Validation loss: 2.1559305687745414

Epoch: 5| Step: 6
Training loss: 0.5369074940681458
Validation loss: 2.16304841140906

Epoch: 5| Step: 7
Training loss: 0.3526550233364105
Validation loss: 2.168791135152181

Epoch: 5| Step: 8
Training loss: 0.2767886221408844
Validation loss: 2.214519908030828

Epoch: 5| Step: 9
Training loss: 0.6053392291069031
Validation loss: 2.2281394749879837

Epoch: 5| Step: 10
Training loss: 0.41732659935951233
Validation loss: 2.2271968722343445

Epoch: 5| Step: 11
Training loss: 0.3426879942417145
Validation loss: 2.1628845036029816

Epoch: 293| Step: 0
Training loss: 0.40446025133132935
Validation loss: 2.160133808851242

Epoch: 5| Step: 1
Training loss: 0.44562655687332153
Validation loss: 2.171180268128713

Epoch: 5| Step: 2
Training loss: 0.2718355059623718
Validation loss: 2.144182105859121

Epoch: 5| Step: 3
Training loss: 0.55924391746521
Validation loss: 2.1600432842969894

Epoch: 5| Step: 4
Training loss: 0.3089422583580017
Validation loss: 2.1386022617419562

Epoch: 5| Step: 5
Training loss: 0.6180656552314758
Validation loss: 2.183623676498731

Epoch: 5| Step: 6
Training loss: 0.27191266417503357
Validation loss: 2.1704850097497306

Epoch: 5| Step: 7
Training loss: 0.6785033941268921
Validation loss: 2.201922575632731

Epoch: 5| Step: 8
Training loss: 0.2923133671283722
Validation loss: 2.2195363442103067

Epoch: 5| Step: 9
Training loss: 0.45623812079429626
Validation loss: 2.194280683994293

Epoch: 5| Step: 10
Training loss: 0.19166657328605652
Validation loss: 2.2253222664197287

Epoch: 5| Step: 11
Training loss: 0.09986662864685059
Validation loss: 2.1938543071349463

Epoch: 294| Step: 0
Training loss: 0.3090609014034271
Validation loss: 2.1929296255111694

Epoch: 5| Step: 1
Training loss: 0.29733020067214966
Validation loss: 2.152408336599668

Epoch: 5| Step: 2
Training loss: 0.1699986457824707
Validation loss: 2.224853048721949

Epoch: 5| Step: 3
Training loss: 0.27931445837020874
Validation loss: 2.194049338499705

Epoch: 5| Step: 4
Training loss: 0.5407809019088745
Validation loss: 2.2241234878698983

Epoch: 5| Step: 5
Training loss: 0.6909120678901672
Validation loss: 2.205302799741427

Epoch: 5| Step: 6
Training loss: 0.4973781108856201
Validation loss: 2.138928140203158

Epoch: 5| Step: 7
Training loss: 0.21799588203430176
Validation loss: 2.1931316405534744

Epoch: 5| Step: 8
Training loss: 0.6073122024536133
Validation loss: 2.2095745305220285

Epoch: 5| Step: 9
Training loss: 0.3596622347831726
Validation loss: 2.1866178711255393

Epoch: 5| Step: 10
Training loss: 0.3158252239227295
Validation loss: 2.179121603568395

Epoch: 5| Step: 11
Training loss: 0.18766671419143677
Validation loss: 2.179287056128184

Epoch: 295| Step: 0
Training loss: 0.20662541687488556
Validation loss: 2.1687691062688828

Epoch: 5| Step: 1
Training loss: 0.6917423009872437
Validation loss: 2.16070486108462

Epoch: 5| Step: 2
Training loss: 0.27469614148139954
Validation loss: 2.1745007385810218

Epoch: 5| Step: 3
Training loss: 0.34419485926628113
Validation loss: 2.1789836237827935

Epoch: 5| Step: 4
Training loss: 0.7369970083236694
Validation loss: 2.1664390563964844

Epoch: 5| Step: 5
Training loss: 0.28174740076065063
Validation loss: 2.162682036558787

Epoch: 5| Step: 6
Training loss: 0.4080253541469574
Validation loss: 2.166435514887174

Epoch: 5| Step: 7
Training loss: 0.443301260471344
Validation loss: 2.1544607182343802

Epoch: 5| Step: 8
Training loss: 0.399755597114563
Validation loss: 2.2005043824513755

Epoch: 5| Step: 9
Training loss: 0.23513516783714294
Validation loss: 2.1824409117301307

Epoch: 5| Step: 10
Training loss: 0.31580546498298645
Validation loss: 2.1916713217894235

Epoch: 5| Step: 11
Training loss: 0.3247233033180237
Validation loss: 2.184149498740832

Epoch: 296| Step: 0
Training loss: 0.9131919145584106
Validation loss: 2.234823614358902

Epoch: 5| Step: 1
Training loss: 0.2637007236480713
Validation loss: 2.21836419403553

Epoch: 5| Step: 2
Training loss: 0.39162716269493103
Validation loss: 2.245463937520981

Epoch: 5| Step: 3
Training loss: 0.33954089879989624
Validation loss: 2.224171966314316

Epoch: 5| Step: 4
Training loss: 0.40062910318374634
Validation loss: 2.205415646235148

Epoch: 5| Step: 5
Training loss: 0.362642765045166
Validation loss: 2.1833707143863044

Epoch: 5| Step: 6
Training loss: 0.2772611081600189
Validation loss: 2.174863417943319

Epoch: 5| Step: 7
Training loss: 0.3136726915836334
Validation loss: 2.1956220269203186

Epoch: 5| Step: 8
Training loss: 0.3206759989261627
Validation loss: 2.198963259657224

Epoch: 5| Step: 9
Training loss: 0.2773657441139221
Validation loss: 2.202703913052877

Epoch: 5| Step: 10
Training loss: 0.5488353967666626
Validation loss: 2.26942973335584

Epoch: 5| Step: 11
Training loss: 1.0094431638717651
Validation loss: 2.169074689348539

Epoch: 297| Step: 0
Training loss: 0.5419649481773376
Validation loss: 2.201063960790634

Epoch: 5| Step: 1
Training loss: 0.2927112579345703
Validation loss: 2.2200649082660675

Epoch: 5| Step: 2
Training loss: 0.3330024182796478
Validation loss: 2.1965091675519943

Epoch: 5| Step: 3
Training loss: 0.440131813287735
Validation loss: 2.1597518821557364

Epoch: 5| Step: 4
Training loss: 0.46388131380081177
Validation loss: 2.1752805511156716

Epoch: 5| Step: 5
Training loss: 0.6420990228652954
Validation loss: 2.235454017917315

Epoch: 5| Step: 6
Training loss: 0.2992008924484253
Validation loss: 2.2281596859296164

Epoch: 5| Step: 7
Training loss: 0.27401524782180786
Validation loss: 2.1999369462331138

Epoch: 5| Step: 8
Training loss: 0.2999860644340515
Validation loss: 2.2499073992172876

Epoch: 5| Step: 9
Training loss: 0.36983078718185425
Validation loss: 2.2284665356079736

Epoch: 5| Step: 10
Training loss: 0.29683369398117065
Validation loss: 2.2151200075944266

Epoch: 5| Step: 11
Training loss: 0.13545745611190796
Validation loss: 2.194045513868332

Epoch: 298| Step: 0
Training loss: 0.35232338309288025
Validation loss: 2.2043683528900146

Epoch: 5| Step: 1
Training loss: 0.4462781846523285
Validation loss: 2.1754742860794067

Epoch: 5| Step: 2
Training loss: 0.33257919549942017
Validation loss: 2.175545647740364

Epoch: 5| Step: 3
Training loss: 0.21035167574882507
Validation loss: 2.2116859455903373

Epoch: 5| Step: 4
Training loss: 0.5028015971183777
Validation loss: 2.2057440330584845

Epoch: 5| Step: 5
Training loss: 0.3392294943332672
Validation loss: 2.2368689825137458

Epoch: 5| Step: 6
Training loss: 0.7091888189315796
Validation loss: 2.218609924117724

Epoch: 5| Step: 7
Training loss: 0.39509347081184387
Validation loss: 2.2692261834939322

Epoch: 5| Step: 8
Training loss: 0.29271331429481506
Validation loss: 2.216425543030103

Epoch: 5| Step: 9
Training loss: 0.24715860188007355
Validation loss: 2.2246821969747543

Epoch: 5| Step: 10
Training loss: 0.30739930272102356
Validation loss: 2.2093267838160195

Epoch: 5| Step: 11
Training loss: 0.7488712072372437
Validation loss: 2.205240860581398

Epoch: 299| Step: 0
Training loss: 0.2578499913215637
Validation loss: 2.1610418359438577

Epoch: 5| Step: 1
Training loss: 0.6874849200248718
Validation loss: 2.195444484551748

Epoch: 5| Step: 2
Training loss: 0.22666391730308533
Validation loss: 2.207458724578222

Epoch: 5| Step: 3
Training loss: 0.35734397172927856
Validation loss: 2.1950510442256927

Epoch: 5| Step: 4
Training loss: 0.3016142249107361
Validation loss: 2.244798948367437

Epoch: 5| Step: 5
Training loss: 0.5664459466934204
Validation loss: 2.229404846827189

Epoch: 5| Step: 6
Training loss: 0.550499439239502
Validation loss: 2.2478595872720084

Epoch: 5| Step: 7
Training loss: 0.35462719202041626
Validation loss: 2.261563460032145

Epoch: 5| Step: 8
Training loss: 0.4397372305393219
Validation loss: 2.2244296272595725

Epoch: 5| Step: 9
Training loss: 0.33029961585998535
Validation loss: 2.2211320201555886

Epoch: 5| Step: 10
Training loss: 0.2842036783695221
Validation loss: 2.2016386489073434

Epoch: 5| Step: 11
Training loss: 1.0859578847885132
Validation loss: 2.1892973631620407

Epoch: 300| Step: 0
Training loss: 0.4377209544181824
Validation loss: 2.207878669102987

Epoch: 5| Step: 1
Training loss: 0.506177544593811
Validation loss: 2.214004228512446

Epoch: 5| Step: 2
Training loss: 0.23733794689178467
Validation loss: 2.182042290767034

Epoch: 5| Step: 3
Training loss: 0.17385022342205048
Validation loss: 2.1970041543245316

Epoch: 5| Step: 4
Training loss: 0.8065973520278931
Validation loss: 2.21684796611468

Epoch: 5| Step: 5
Training loss: 0.40321293473243713
Validation loss: 2.2407626857360206

Epoch: 5| Step: 6
Training loss: 0.2548878788948059
Validation loss: 2.214139610528946

Epoch: 5| Step: 7
Training loss: 0.2970397174358368
Validation loss: 2.2044524202744165

Epoch: 5| Step: 8
Training loss: 0.3519754409790039
Validation loss: 2.164382959405581

Epoch: 5| Step: 9
Training loss: 0.5346290469169617
Validation loss: 2.1467435459295907

Epoch: 5| Step: 10
Training loss: 0.3995380997657776
Validation loss: 2.226105918486913

Epoch: 5| Step: 11
Training loss: 0.32980984449386597
Validation loss: 2.208008661866188

Testing loss: 1.9521692305160083
