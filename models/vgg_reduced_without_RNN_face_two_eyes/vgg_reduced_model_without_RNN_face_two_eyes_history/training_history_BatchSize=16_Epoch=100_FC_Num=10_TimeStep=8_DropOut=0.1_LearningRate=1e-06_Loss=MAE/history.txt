Epoch: 1| Step: 0
Training loss: 4.391136169433594
Validation loss: 4.759950843646372
Epoch: 9| Step: 1
Training loss: 4.885507583618164
Validation loss: 4.755717370149901
Epoch: 9| Step: 2
Training loss: 3.69264554977417
Validation loss: 4.750948298749306
Epoch: 9| Step: 3
Training loss: 3.7178726196289062
Validation loss: 4.746121626106097
Epoch: 9| Step: 4
Training loss: 3.9223544597625732
Validation loss: 4.742080743364293
Epoch: 9| Step: 5
Training loss: 4.951111793518066
Validation loss: 4.7352912305927966
Epoch: 9| Step: 6
Training loss: 3.0448708534240723
Validation loss: 4.7329528074470355
Epoch: 9| Step: 7
Training loss: 5.847627639770508
Validation loss: 4.728165269755631
Epoch: 9| Step: 8
Training loss: 5.059937000274658
Validation loss: 4.723066522063111
Epoch: 9| Step: 9
Training loss: 5.481122970581055
Validation loss: 4.7191579667784325
Epoch: 9| Step: 10
Training loss: 5.192282676696777
Validation loss: 4.7132711650656285
Epoch: 9| Step: 11
Training loss: 5.191514015197754
Validation loss: 4.71062744950219
Epoch: 9| Step: 12
Training loss: 4.4954023361206055
Validation loss: 4.705922339459975
Epoch: 9| Step: 13
Training loss: 4.881317138671875
Validation loss: 4.6989977548448305
Epoch: 9| Step: 14
Training loss: 5.596958160400391
Validation loss: 4.695544664808314
Epoch: 9| Step: 15
Training loss: 5.371851444244385
Validation loss: 4.691306194813132
Epoch: 9| Step: 16
Training loss: 4.921298503875732
Validation loss: 4.685544531980007
Epoch: 9| Step: 17
Training loss: 6.090268135070801
Validation loss: 4.682520008773255
Epoch: 9| Step: 18
Training loss: 5.1830244064331055
Validation loss: 4.676776683587822
Epoch: 9| Step: 19
Training loss: 5.546653747558594
Validation loss: 4.671380368925685
Epoch: 2| Step: 0
Training loss: 5.338520526885986
Validation loss: 4.666137287085005
Epoch: 9| Step: 1
Training loss: 3.74851655960083
Validation loss: 4.663149396292598
Epoch: 9| Step: 2
Training loss: 3.92018461227417
Validation loss: 4.65660969301951
Epoch: 9| Step: 3
Training loss: 5.13046932220459
Validation loss: 4.651322875949119
Epoch: 9| Step: 4
Training loss: 4.765926837921143
Validation loss: 4.646356845073563
Epoch: 9| Step: 5
Training loss: 4.197817802429199
Validation loss: 4.6416115006096925
Epoch: 9| Step: 6
Training loss: 3.9516870975494385
Validation loss: 4.637768707687049
Epoch: 9| Step: 7
Training loss: 3.3940072059631348
Validation loss: 4.631654221376927
Epoch: 9| Step: 8
Training loss: 4.7756757736206055
Validation loss: 4.627251120780012
Epoch: 9| Step: 9
Training loss: 4.387985706329346
Validation loss: 4.621271929294943
Epoch: 9| Step: 10
Training loss: 5.478374004364014
Validation loss: 4.616638955452459
Epoch: 9| Step: 11
Training loss: 4.4102606773376465
Validation loss: 4.609111830484953
Epoch: 9| Step: 12
Training loss: 5.490263938903809
Validation loss: 4.604536701449387
Epoch: 9| Step: 13
Training loss: 5.304928779602051
Validation loss: 4.599881364287232
Epoch: 9| Step: 14
Training loss: 4.674022674560547
Validation loss: 4.593820932100145
Epoch: 9| Step: 15
Training loss: 5.581460952758789
Validation loss: 4.587879324988496
Epoch: 9| Step: 16
Training loss: 6.134778022766113
Validation loss: 4.582858526449409
Epoch: 9| Step: 17
Training loss: 5.319931983947754
Validation loss: 4.576936951644129
Epoch: 9| Step: 18
Training loss: 4.330750942230225
Validation loss: 4.568326047856173
Epoch: 9| Step: 19
Training loss: 5.319596290588379
Validation loss: 4.564936939760935
Epoch: 3| Step: 0
Training loss: 5.500545501708984
Validation loss: 4.5574277596508
Epoch: 9| Step: 1
Training loss: 5.242279052734375
Validation loss: 4.554604935131485
Epoch: 9| Step: 2
Training loss: 5.026388168334961
Validation loss: 4.545086174560108
Epoch: 9| Step: 3
Training loss: 4.762229919433594
Validation loss: 4.539103830461022
Epoch: 9| Step: 4
Training loss: 4.545722007751465
Validation loss: 4.534130799684593
Epoch: 9| Step: 5
Training loss: 5.942584991455078
Validation loss: 4.528502443711535
Epoch: 9| Step: 6
Training loss: 4.4861650466918945
Validation loss: 4.518053987900988
Epoch: 9| Step: 7
Training loss: 4.753507614135742
Validation loss: 4.5149311539080506
Epoch: 9| Step: 8
Training loss: 5.405023574829102
Validation loss: 4.509047298980274
Epoch: 9| Step: 9
Training loss: 4.972678184509277
Validation loss: 4.5000981564144436
Epoch: 9| Step: 10
Training loss: 4.009804725646973
Validation loss: 4.4943180358667165
Epoch: 9| Step: 11
Training loss: 3.4018125534057617
Validation loss: 4.487926947984764
Epoch: 9| Step: 12
Training loss: 4.955585479736328
Validation loss: 4.481257761125084
Epoch: 9| Step: 13
Training loss: 5.028770446777344
Validation loss: 4.473527920331886
Epoch: 9| Step: 14
Training loss: 3.3789877891540527
Validation loss: 4.467048209348171
Epoch: 9| Step: 15
Training loss: 4.559106826782227
Validation loss: 4.457476506130301
Epoch: 9| Step: 16
Training loss: 4.530239105224609
Validation loss: 4.4523445993876285
Epoch: 9| Step: 17
Training loss: 4.332181930541992
Validation loss: 4.445177139995767
Epoch: 9| Step: 18
Training loss: 4.487396240234375
Validation loss: 4.43499316242959
Epoch: 9| Step: 19
Training loss: 4.1692609786987305
Validation loss: 4.426910650815895
Epoch: 4| Step: 0
Training loss: 4.770354747772217
Validation loss: 4.421555580852701
Epoch: 9| Step: 1
Training loss: 4.018033027648926
Validation loss: 4.4109904285815125
Epoch: 9| Step: 2
Training loss: 4.952498435974121
Validation loss: 4.40261001381085
Epoch: 9| Step: 3
Training loss: 4.570468902587891
Validation loss: 4.392877715954677
Epoch: 9| Step: 4
Training loss: 5.088347434997559
Validation loss: 4.385334479723046
Epoch: 9| Step: 5
Training loss: 4.665384292602539
Validation loss: 4.378429292774887
Epoch: 9| Step: 6
Training loss: 5.461454391479492
Validation loss: 4.369907878285689
Epoch: 9| Step: 7
Training loss: 4.377734661102295
Validation loss: 4.35983702433195
Epoch: 9| Step: 8
Training loss: 5.403223991394043
Validation loss: 4.3516807075884705
Epoch: 9| Step: 9
Training loss: 4.685302734375
Validation loss: 4.341481754248091
Epoch: 9| Step: 10
Training loss: 4.655433654785156
Validation loss: 4.32874376310719
Epoch: 9| Step: 11
Training loss: 5.11522102355957
Validation loss: 4.319116115570068
Epoch: 9| Step: 12
Training loss: 3.772596836090088
Validation loss: 4.313090010512647
Epoch: 9| Step: 13
Training loss: 4.561004638671875
Validation loss: 4.300615988189368
Epoch: 9| Step: 14
Training loss: 5.222038269042969
Validation loss: 4.292040279443316
Epoch: 9| Step: 15
Training loss: 3.2886524200439453
Validation loss: 4.279040453245314
Epoch: 9| Step: 16
Training loss: 4.476611137390137
Validation loss: 4.2706983878458145
Epoch: 9| Step: 17
Training loss: 4.7718305587768555
Validation loss: 4.255770873680389
Epoch: 9| Step: 18
Training loss: 3.075772523880005
Validation loss: 4.247207041267011
Epoch: 9| Step: 19
Training loss: 3.6799888610839844
Validation loss: 4.236653454869771
Epoch: 5| Step: 0
Training loss: 3.665623188018799
Validation loss: 4.2230590093050075
Epoch: 9| Step: 1
Training loss: 4.372498512268066
Validation loss: 4.216350558850405
Epoch: 9| Step: 2
Training loss: 3.03576397895813
Validation loss: 4.20577126441242
Epoch: 9| Step: 3
Training loss: 4.396332263946533
Validation loss: 4.194918080199536
Epoch: 9| Step: 4
Training loss: 5.244566917419434
Validation loss: 4.183385152610944
Epoch: 9| Step: 5
Training loss: 4.174385070800781
Validation loss: 4.1727353754661065
Epoch: 9| Step: 6
Training loss: 4.484307765960693
Validation loss: 4.161640746987981
Epoch: 9| Step: 7
Training loss: 3.6242170333862305
Validation loss: 4.148060839810817
Epoch: 9| Step: 8
Training loss: 3.901533842086792
Validation loss: 4.137235526558307
Epoch: 9| Step: 9
Training loss: 4.196577548980713
Validation loss: 4.126114491936114
Epoch: 9| Step: 10
Training loss: 4.782816410064697
Validation loss: 4.114135793644747
Epoch: 9| Step: 11
Training loss: 3.610372543334961
Validation loss: 4.102716222941447
Epoch: 9| Step: 12
Training loss: 4.794818878173828
Validation loss: 4.089404025523782
Epoch: 9| Step: 13
Training loss: 5.0334153175354
Validation loss: 4.078174236009446
Epoch: 9| Step: 14
Training loss: 5.540637493133545
Validation loss: 4.067580202500597
Epoch: 9| Step: 15
Training loss: 4.645778656005859
Validation loss: 4.054472065658021
Epoch: 9| Step: 16
Training loss: 5.413653373718262
Validation loss: 4.041629582000294
Epoch: 9| Step: 17
Training loss: 4.155638694763184
Validation loss: 4.027686746858007
Epoch: 9| Step: 18
Training loss: 3.7459146976470947
Validation loss: 4.015913196604886
Epoch: 9| Step: 19
Training loss: 4.055079460144043
Validation loss: 4.000239502611778
Epoch: 6| Step: 0
Training loss: 5.271869659423828
Validation loss: 3.988287613546248
Epoch: 9| Step: 1
Training loss: 4.373104572296143
Validation loss: 3.9768268067202124
Epoch: 9| Step: 2
Training loss: 3.568394184112549
Validation loss: 3.9610928185552146
Epoch: 9| Step: 3
Training loss: 4.807739734649658
Validation loss: 3.9481867766208785
Epoch: 9| Step: 4
Training loss: 4.968889236450195
Validation loss: 3.9374495478842757
Epoch: 9| Step: 5
Training loss: 4.454453468322754
Validation loss: 3.9209081629197375
Epoch: 9| Step: 6
Training loss: 3.4891724586486816
Validation loss: 3.90445670464056
Epoch: 9| Step: 7
Training loss: 4.430325031280518
Validation loss: 3.889855746742633
Epoch: 9| Step: 8
Training loss: 3.646357536315918
Validation loss: 3.8772095330327536
Epoch: 9| Step: 9
Training loss: 4.251045227050781
Validation loss: 3.862797040733502
Epoch: 9| Step: 10
Training loss: 3.2707316875457764
Validation loss: 3.8487117787916882
Epoch: 9| Step: 11
Training loss: 4.329870700836182
Validation loss: 3.830785193889261
Epoch: 9| Step: 12
Training loss: 4.780090808868408
Validation loss: 3.81800476424128
Epoch: 9| Step: 13
Training loss: 4.768784523010254
Validation loss: 3.8037872966244923
Epoch: 9| Step: 14
Training loss: 3.80745267868042
Validation loss: 3.7907246634256926
Epoch: 9| Step: 15
Training loss: 3.409090518951416
Validation loss: 3.7717288621037985
Epoch: 9| Step: 16
Training loss: 3.9035632610321045
Validation loss: 3.756289327744957
Epoch: 9| Step: 17
Training loss: 3.7907052040100098
Validation loss: 3.74292086868835
Epoch: 9| Step: 18
Training loss: 3.5800750255584717
Validation loss: 3.727660611379061
Epoch: 9| Step: 19
Training loss: 3.6470255851745605
Validation loss: 3.7120406850636436
Epoch: 7| Step: 0
Training loss: 4.528816223144531
Validation loss: 3.6953238034419877
Epoch: 9| Step: 1
Training loss: 4.136301040649414
Validation loss: 3.676418110621061
Epoch: 9| Step: 2
Training loss: 4.002307891845703
Validation loss: 3.6659833613059503
Epoch: 9| Step: 3
Training loss: 2.239631175994873
Validation loss: 3.646090751071628
Epoch: 9| Step: 4
Training loss: 3.9644699096679688
Validation loss: 3.6309638435034444
Epoch: 9| Step: 5
Training loss: 2.095828056335449
Validation loss: 3.6142127977000724
Epoch: 9| Step: 6
Training loss: 4.4685821533203125
Validation loss: 3.5920440979141124
Epoch: 9| Step: 7
Training loss: 4.149773597717285
Validation loss: 3.5734782407609678
Epoch: 9| Step: 8
Training loss: 4.423955917358398
Validation loss: 3.560045105090244
Epoch: 9| Step: 9
Training loss: 3.4501776695251465
Validation loss: 3.5443126554969404
Epoch: 9| Step: 10
Training loss: 3.6152350902557373
Validation loss: 3.523789117662169
Epoch: 9| Step: 11
Training loss: 4.424697399139404
Validation loss: 3.5040540386446946
Epoch: 9| Step: 12
Training loss: 3.9857382774353027
Validation loss: 3.4861658528554353
Epoch: 9| Step: 13
Training loss: 3.8856210708618164
Validation loss: 3.4676407772860083
Epoch: 9| Step: 14
Training loss: 3.8947601318359375
Validation loss: 3.4485021906790974
Epoch: 9| Step: 15
Training loss: 3.8659143447875977
Validation loss: 3.4270512543136267
Epoch: 9| Step: 16
Training loss: 4.727622985839844
Validation loss: 3.407474408046805
Epoch: 9| Step: 17
Training loss: 4.261682987213135
Validation loss: 3.392894226870091
Epoch: 9| Step: 18
Training loss: 4.064953804016113
Validation loss: 3.365155808359599
Epoch: 9| Step: 19
Training loss: 2.991530179977417
Validation loss: 3.3494462932614115
Epoch: 8| Step: 0
Training loss: 3.0725340843200684
Validation loss: 3.326267134371421
Epoch: 9| Step: 1
Training loss: 4.3541998863220215
Validation loss: 3.304939263158565
Epoch: 9| Step: 2
Training loss: 4.877619743347168
Validation loss: 3.2810921360262864
Epoch: 9| Step: 3
Training loss: 2.6002235412597656
Validation loss: 3.2624284998118447
Epoch: 9| Step: 4
Training loss: 4.941646575927734
Validation loss: 3.2363134493930734
Epoch: 9| Step: 5
Training loss: 4.087891578674316
Validation loss: 3.216246922239125
Epoch: 9| Step: 6
Training loss: 3.7517645359039307
Validation loss: 3.1889974676447808
Epoch: 9| Step: 7
Training loss: 3.349438190460205
Validation loss: 3.165648813727948
Epoch: 9| Step: 8
Training loss: 3.265763282775879
Validation loss: 3.141990490096936
Epoch: 9| Step: 9
Training loss: 3.2276055812835693
Validation loss: 3.1215171230782706
Epoch: 9| Step: 10
Training loss: 3.856895923614502
Validation loss: 3.0944896481877606
Epoch: 9| Step: 11
Training loss: 2.636849880218506
Validation loss: 3.072558639718474
Epoch: 9| Step: 12
Training loss: 3.6425461769104004
Validation loss: 3.0531814269882314
Epoch: 9| Step: 13
Training loss: 3.122572422027588
Validation loss: 3.0332420112417755
Epoch: 9| Step: 14
Training loss: 2.747877597808838
Validation loss: 3.0052041853074547
Epoch: 9| Step: 15
Training loss: 2.9394822120666504
Validation loss: 2.9869382810249605
Epoch: 9| Step: 16
Training loss: 3.841456890106201
Validation loss: 2.9635950404105427
Epoch: 9| Step: 17
Training loss: 3.4489526748657227
Validation loss: 2.9454777600953905
Epoch: 9| Step: 18
Training loss: 3.4808404445648193
Validation loss: 2.9200450190537266
Epoch: 9| Step: 19
Training loss: 3.3661608695983887
Validation loss: 2.902054803834545
Epoch: 9| Step: 0
Training loss: 2.976706027984619
Validation loss: 2.8813024802173643
Epoch: 9| Step: 1
Training loss: 3.23909330368042
Validation loss: 2.8596878600635116
Epoch: 9| Step: 2
Training loss: 3.138021945953369
Validation loss: 2.834878544155642
Epoch: 9| Step: 3
Training loss: 4.065068244934082
Validation loss: 2.811471906497324
Epoch: 9| Step: 4
Training loss: 3.220193862915039
Validation loss: 2.801155757561004
Epoch: 9| Step: 5
Training loss: 2.49509859085083
Validation loss: 2.7705159153012064
Epoch: 9| Step: 6
Training loss: 3.3066787719726562
Validation loss: 2.755878451916811
Epoch: 9| Step: 7
Training loss: 2.791102409362793
Validation loss: 2.7347220139537782
Epoch: 9| Step: 8
Training loss: 2.8705344200134277
Validation loss: 2.700179942220235
Epoch: 9| Step: 9
Training loss: 3.4582090377807617
Validation loss: 2.6771355996028983
Epoch: 9| Step: 10
Training loss: 4.115786552429199
Validation loss: 2.6651308931035103
Epoch: 9| Step: 11
Training loss: 2.9911065101623535
Validation loss: 2.6342347045596557
Epoch: 9| Step: 12
Training loss: 2.7161026000976562
Validation loss: 2.611422005317194
Epoch: 9| Step: 13
Training loss: 3.043081283569336
Validation loss: 2.588634473814381
Epoch: 9| Step: 14
Training loss: 3.6598880290985107
Validation loss: 2.569933618572976
Epoch: 9| Step: 15
Training loss: 3.411750316619873
Validation loss: 2.5484108667579486
Epoch: 9| Step: 16
Training loss: 2.8737478256225586
Validation loss: 2.5274978009916897
Epoch: 9| Step: 17
Training loss: 3.030479907989502
Validation loss: 2.5049132597532204
Epoch: 9| Step: 18
Training loss: 2.9685330390930176
Validation loss: 2.4946397380005543
Epoch: 9| Step: 19
Training loss: 2.9020814895629883
Validation loss: 2.4524899995584284
Epoch: 10| Step: 0
Training loss: 3.4060025215148926
Validation loss: 2.441274504009768
Epoch: 9| Step: 1
Training loss: 3.1414029598236084
Validation loss: 2.43076016920076
Epoch: 9| Step: 2
Training loss: 3.0446577072143555
Validation loss: 2.4046803275458246
Epoch: 9| Step: 3
Training loss: 3.0509796142578125
Validation loss: 2.383978399441397
Epoch: 9| Step: 4
Training loss: 2.9583520889282227
Validation loss: 2.3637832446064024
Epoch: 9| Step: 5
Training loss: 2.484072208404541
Validation loss: 2.346535433968194
Epoch: 9| Step: 6
Training loss: 2.4678332805633545
Validation loss: 2.3137033671783884
Epoch: 9| Step: 7
Training loss: 3.0002315044403076
Validation loss: 2.298003827925209
Epoch: 9| Step: 8
Training loss: 3.386558771133423
Validation loss: 2.281508385706291
Epoch: 9| Step: 9
Training loss: 2.801405668258667
Validation loss: 2.260954908329806
Epoch: 9| Step: 10
Training loss: 2.5733797550201416
Validation loss: 2.252772177723672
Epoch: 9| Step: 11
Training loss: 3.6123340129852295
Validation loss: 2.2300550405927697
Epoch: 9| Step: 12
Training loss: 2.1356887817382812
Validation loss: 2.2071564969398993
Epoch: 9| Step: 13
Training loss: 2.7855794429779053
Validation loss: 2.175784961782771
Epoch: 9| Step: 14
Training loss: 2.9026405811309814
Validation loss: 2.1678110198151295
Epoch: 9| Step: 15
Training loss: 2.3313746452331543
Validation loss: 2.152396190080711
Epoch: 9| Step: 16
Training loss: 1.5320954322814941
Validation loss: 2.125542446863737
Epoch: 9| Step: 17
Training loss: 2.849276542663574
Validation loss: 2.112332877495306
Epoch: 9| Step: 18
Training loss: 2.4212894439697266
Validation loss: 2.0919228937986087
Epoch: 9| Step: 19
Training loss: 2.9042158126831055
Validation loss: 2.086690497912949
Epoch: 11| Step: 0
Training loss: 2.339411735534668
Validation loss: 2.0639582640833134
Epoch: 9| Step: 1
Training loss: 2.4183449745178223
Validation loss: 2.0453767296221614
Epoch: 9| Step: 2
Training loss: 2.6143317222595215
Validation loss: 2.0438835063426612
Epoch: 9| Step: 3
Training loss: 2.17533278465271
Validation loss: 2.0364036508601346
Epoch: 9| Step: 4
Training loss: 3.2911624908447266
Validation loss: 2.004889006237332
Epoch: 9| Step: 5
Training loss: 2.5307414531707764
Validation loss: 2.0061578853524846
Epoch: 9| Step: 6
Training loss: 2.370828151702881
Validation loss: 1.9870447229138382
Epoch: 9| Step: 7
Training loss: 2.205197811126709
Validation loss: 1.9713051979490321
Epoch: 9| Step: 8
Training loss: 2.467933416366577
Validation loss: 1.9702398331045248
Epoch: 9| Step: 9
Training loss: 2.5098793506622314
Validation loss: 1.9432394453089872
Epoch: 9| Step: 10
Training loss: 2.501995086669922
Validation loss: 1.9310758559823893
Epoch: 9| Step: 11
Training loss: 2.336343288421631
Validation loss: 1.9156973833660427
Epoch: 9| Step: 12
Training loss: 2.8182766437530518
Validation loss: 1.896173625541248
Epoch: 9| Step: 13
Training loss: 1.9991376399993896
Validation loss: 1.9076018427773345
Epoch: 9| Step: 14
Training loss: 2.821425199508667
Validation loss: 1.88744185725562
Epoch: 9| Step: 15
Training loss: 2.651341438293457
Validation loss: 1.8808124477057149
Epoch: 9| Step: 16
Training loss: 2.065260410308838
Validation loss: 1.87801054913363
Epoch: 9| Step: 17
Training loss: 2.3918983936309814
Validation loss: 1.8719249509221358
Epoch: 9| Step: 18
Training loss: 2.1234166622161865
Validation loss: 1.8772749188992617
Epoch: 9| Step: 19
Training loss: 2.024033546447754
Validation loss: 1.8685785634912175
Epoch: 12| Step: 0
Training loss: 2.24800705909729
Validation loss: 1.8614880781379535
Epoch: 9| Step: 1
Training loss: 2.0497305393218994
Validation loss: 1.8510994996955927
Epoch: 9| Step: 2
Training loss: 2.7824676036834717
Validation loss: 1.842391156464172
Epoch: 9| Step: 3
Training loss: 2.4176931381225586
Validation loss: 1.8552185202674043
Epoch: 9| Step: 4
Training loss: 2.1374058723449707
Validation loss: 1.8476086040194943
Epoch: 9| Step: 5
Training loss: 2.7506113052368164
Validation loss: 1.8443227723348055
Epoch: 9| Step: 6
Training loss: 2.151888370513916
Validation loss: 1.8535602761687135
Epoch: 9| Step: 7
Training loss: 2.4744298458099365
Validation loss: 1.8459431601942873
Epoch: 9| Step: 8
Training loss: 2.54116153717041
Validation loss: 1.8258566135982814
Epoch: 9| Step: 9
Training loss: 2.2665061950683594
Validation loss: 1.8487516710226484
Epoch: 9| Step: 10
Training loss: 1.7477483749389648
Validation loss: 1.833751103860869
Epoch: 9| Step: 11
Training loss: 2.3073387145996094
Validation loss: 1.8624488981507665
Epoch: 9| Step: 12
Training loss: 2.295283794403076
Validation loss: 1.8507692179233908
Epoch: 9| Step: 13
Training loss: 2.1634016036987305
Validation loss: 1.8577243364114555
Epoch: 9| Step: 14
Training loss: 1.7930934429168701
Validation loss: 1.8429503432280725
Epoch: 9| Step: 15
Training loss: 2.2793822288513184
Validation loss: 1.8532661113807622
Epoch: 9| Step: 16
Training loss: 2.2982125282287598
Validation loss: 1.856402772793667
Epoch: 9| Step: 17
Training loss: 2.0921454429626465
Validation loss: 1.8617784702520577
Epoch: 9| Step: 18
Training loss: 1.915111780166626
Validation loss: 1.8582470168312677
Epoch: 9| Step: 19
Training loss: 2.3190979957580566
Validation loss: 1.8665853224212317
Epoch: 13| Step: 0
Training loss: 1.8423960208892822
Validation loss: 1.8730030162728948
Epoch: 9| Step: 1
Training loss: 1.669112205505371
Validation loss: 1.8898903303009142
Epoch: 9| Step: 2
Training loss: 1.8160346746444702
Validation loss: 1.8752329469584732
Epoch: 9| Step: 3
Training loss: 2.093294858932495
Validation loss: 1.8756816627310335
Epoch: 9| Step: 4
Training loss: 2.207396984100342
Validation loss: 1.8965224242038865
Epoch: 9| Step: 5
Training loss: 2.2207250595092773
Validation loss: 1.9045796685939214
Epoch: 9| Step: 6
Training loss: 2.6309428215026855
Validation loss: 1.9003690309661756
Epoch: 9| Step: 7
Training loss: 2.2766880989074707
Validation loss: 1.9074601749722049
Epoch: 9| Step: 8
Training loss: 2.499420166015625
Validation loss: 1.9135744142875397
Epoch: 9| Step: 9
Training loss: 1.8986774682998657
Validation loss: 1.9060097709834147
Epoch: 9| Step: 10
Training loss: 1.7119457721710205
Validation loss: 1.9045456536382221
Epoch: 9| Step: 11
Training loss: 2.6812376976013184
Validation loss: 1.9372439315850787
Epoch: 9| Step: 12
Training loss: 2.2543365955352783
Validation loss: 1.9200668034793662
Epoch: 9| Step: 13
Training loss: 2.9045028686523438
Validation loss: 1.9184460837206394
Epoch: 9| Step: 14
Training loss: 1.5757787227630615
Validation loss: 1.917222463827339
Epoch: 9| Step: 15
Training loss: 2.797278642654419
Validation loss: 1.9262308928606322
Epoch: 9| Step: 16
Training loss: 2.027017593383789
Validation loss: 1.9310474618733358
Epoch: 9| Step: 17
Training loss: 2.855351209640503
Validation loss: 1.9384915056846124
Epoch: 9| Step: 18
Training loss: 2.6091017723083496
Validation loss: 1.9347153293143073
Epoch: 9| Step: 19
Training loss: 1.6658713817596436
Validation loss: 1.9226687949338406
Epoch: 14| Step: 0
Training loss: 1.9586496353149414
Validation loss: 1.913456864494214
Epoch: 9| Step: 1
Training loss: 2.1490843296051025
Validation loss: 1.9506372393464013
Epoch: 9| Step: 2
Training loss: 2.4215450286865234
Validation loss: 1.9396199888462642
Epoch: 9| Step: 3
Training loss: 2.169433832168579
Validation loss: 1.9240667862857845
Epoch: 9| Step: 4
Training loss: 2.6520681381225586
Validation loss: 1.9423661086199095
Epoch: 9| Step: 5
Training loss: 2.6280574798583984
Validation loss: 1.9319221673251914
Epoch: 9| Step: 6
Training loss: 1.9411624670028687
Validation loss: 1.9386204275295889
Epoch: 9| Step: 7
Training loss: 2.360399007797241
Validation loss: 1.9336434354027399
Epoch: 9| Step: 8
Training loss: 2.1053614616394043
Validation loss: 1.9381640849353599
Epoch: 9| Step: 9
Training loss: 2.4888722896575928
Validation loss: 1.9246467060322383
Epoch: 9| Step: 10
Training loss: 1.8282337188720703
Validation loss: 1.9202595854834688
Epoch: 9| Step: 11
Training loss: 2.270573139190674
Validation loss: 1.9263861162199392
Epoch: 9| Step: 12
Training loss: 1.8810029029846191
Validation loss: 1.9298947251957954
Epoch: 9| Step: 13
Training loss: 1.8589218854904175
Validation loss: 1.9233693030240724
Epoch: 9| Step: 14
Training loss: 2.7652194499969482
Validation loss: 1.9388764985173725
Epoch: 9| Step: 15
Training loss: 2.3305819034576416
Validation loss: 1.9203595060238736
Epoch: 9| Step: 16
Training loss: 1.8306117057800293
Validation loss: 1.9505041786235013
Epoch: 9| Step: 17
Training loss: 2.3535244464874268
Validation loss: 1.923744659629657
Epoch: 9| Step: 18
Training loss: 1.4757118225097656
Validation loss: 1.9171554647761284
Epoch: 9| Step: 19
Training loss: 2.506176471710205
Validation loss: 1.9162679730559424
Epoch: 15| Step: 0
Training loss: 1.7706880569458008
Validation loss: 1.9206342465585942
Epoch: 9| Step: 1
Training loss: 2.170238971710205
Validation loss: 1.9145232541955632
Epoch: 9| Step: 2
Training loss: 2.7758638858795166
Validation loss: 1.902919811310528
Epoch: 9| Step: 3
Training loss: 1.6463230848312378
Validation loss: 1.9037627170411804
Epoch: 9| Step: 4
Training loss: 1.466731071472168
Validation loss: 1.9110539731361884
Epoch: 9| Step: 5
Training loss: 1.8182451725006104
Validation loss: 1.9167826467280766
Epoch: 9| Step: 6
Training loss: 2.5050816535949707
Validation loss: 1.9176597783891418
Epoch: 9| Step: 7
Training loss: 2.0589025020599365
Validation loss: 1.9028133831435827
Epoch: 9| Step: 8
Training loss: 2.3918142318725586
Validation loss: 1.9148722561143285
Epoch: 9| Step: 9
Training loss: 2.0392045974731445
Validation loss: 1.9273183551623667
Epoch: 9| Step: 10
Training loss: 2.2139430046081543
Validation loss: 1.9187070122725671
Epoch: 9| Step: 11
Training loss: 2.39654278755188
Validation loss: 1.9153574970986347
Epoch: 9| Step: 12
Training loss: 3.217148780822754
Validation loss: 1.9350206165862598
Epoch: 9| Step: 13
Training loss: 1.56892728805542
Validation loss: 1.9093559585886895
Epoch: 9| Step: 14
Training loss: 2.322202682495117
Validation loss: 1.9154222912067989
Epoch: 9| Step: 15
Training loss: 2.034372329711914
Validation loss: 1.9339842710563604
Epoch: 9| Step: 16
Training loss: 1.9575121402740479
Validation loss: 1.9232910760015034
Epoch: 9| Step: 17
Training loss: 2.6841516494750977
Validation loss: 1.9389841676615982
Epoch: 9| Step: 18
Training loss: 2.608016014099121
Validation loss: 1.9256190215940956
Epoch: 9| Step: 19
Training loss: 2.2127699851989746
Validation loss: 1.9298261858576493
Epoch: 16| Step: 0
Training loss: 1.7888914346694946
Validation loss: 1.9248518935210412
Epoch: 9| Step: 1
Training loss: 2.1898560523986816
Validation loss: 1.9147763492392122
Epoch: 9| Step: 2
Training loss: 1.8032076358795166
Validation loss: 1.9343933407351268
Epoch: 9| Step: 3
Training loss: 2.017416477203369
Validation loss: 1.9276811639182
Epoch: 9| Step: 4
Training loss: 2.0917751789093018
Validation loss: 1.9311538806064523
Epoch: 9| Step: 5
Training loss: 2.301023244857788
Validation loss: 1.925722182225838
Epoch: 9| Step: 6
Training loss: 2.099926233291626
Validation loss: 1.9282649918425856
Epoch: 9| Step: 7
Training loss: 2.1817874908447266
Validation loss: 1.9281177143398807
Epoch: 9| Step: 8
Training loss: 1.928166389465332
Validation loss: 1.9236124916899977
Epoch: 9| Step: 9
Training loss: 2.2371387481689453
Validation loss: 1.9084008580489125
Epoch: 9| Step: 10
Training loss: 2.56170916557312
Validation loss: 1.8999934565249106
Epoch: 9| Step: 11
Training loss: 1.8236734867095947
Validation loss: 1.9330338385465333
Epoch: 9| Step: 12
Training loss: 2.177039623260498
Validation loss: 1.9046168052892891
Epoch: 9| Step: 13
Training loss: 2.807089328765869
Validation loss: 1.9110128090535994
Epoch: 9| Step: 14
Training loss: 2.466353416442871
Validation loss: 1.9052568039448141
Epoch: 9| Step: 15
Training loss: 2.009510040283203
Validation loss: 1.9109257656893284
Epoch: 9| Step: 16
Training loss: 2.4084181785583496
Validation loss: 1.906857144918373
Epoch: 9| Step: 17
Training loss: 2.3863277435302734
Validation loss: 1.8948339798467622
Epoch: 9| Step: 18
Training loss: 2.356067657470703
Validation loss: 1.9182237258060373
Epoch: 9| Step: 19
Training loss: 1.94199538230896
Validation loss: 1.9139672157575758
Epoch: 17| Step: 0
Training loss: 1.4451130628585815
Validation loss: 1.9012135541696342
Epoch: 9| Step: 1
Training loss: 2.6239733695983887
Validation loss: 1.899482598407663
Epoch: 9| Step: 2
Training loss: 2.3467209339141846
Validation loss: 1.8929394655090441
Epoch: 9| Step: 3
Training loss: 2.0227160453796387
Validation loss: 1.8931204123462704
Epoch: 9| Step: 4
Training loss: 2.4010400772094727
Validation loss: 1.8909238671227324
Epoch: 9| Step: 5
Training loss: 2.5816121101379395
Validation loss: 1.8967432975769043
Epoch: 9| Step: 6
Training loss: 2.279470443725586
Validation loss: 1.8778172705670912
Epoch: 9| Step: 7
Training loss: 2.86090350151062
Validation loss: 1.8962842371823976
Epoch: 9| Step: 8
Training loss: 2.077822685241699
Validation loss: 1.8854541538430631
Epoch: 9| Step: 9
Training loss: 2.2293949127197266
Validation loss: 1.8739587094286363
Epoch: 9| Step: 10
Training loss: 2.1863439083099365
Validation loss: 1.8872961869342721
Epoch: 9| Step: 11
Training loss: 1.7026838064193726
Validation loss: 1.8788441393872817
Epoch: 9| Step: 12
Training loss: 1.860498070716858
Validation loss: 1.890931447632879
Epoch: 9| Step: 13
Training loss: 2.020643711090088
Validation loss: 1.8819174440644628
Epoch: 9| Step: 14
Training loss: 2.447924852371216
Validation loss: 1.8778289393555345
Epoch: 9| Step: 15
Training loss: 2.3234004974365234
Validation loss: 1.8817767933975877
Epoch: 9| Step: 16
Training loss: 1.719995141029358
Validation loss: 1.9045072442336048
Epoch: 9| Step: 17
Training loss: 1.5956876277923584
Validation loss: 1.869126760702339
Epoch: 9| Step: 18
Training loss: 2.876741409301758
Validation loss: 1.8928057752924858
Epoch: 9| Step: 19
Training loss: 1.6171960830688477
Validation loss: 1.8989975366661016
Epoch: 18| Step: 0
Training loss: 2.009470224380493
Validation loss: 1.8955677962131638
Epoch: 9| Step: 1
Training loss: 2.4080440998077393
Validation loss: 1.8974067178561533
Epoch: 9| Step: 2
Training loss: 1.9731736183166504
Validation loss: 1.9147315582783102
Epoch: 9| Step: 3
Training loss: 2.4172425270080566
Validation loss: 1.9051388733678585
Epoch: 9| Step: 4
Training loss: 2.723829746246338
Validation loss: 1.9063318796295057
Epoch: 9| Step: 5
Training loss: 2.0463972091674805
Validation loss: 1.8968070668282269
Epoch: 9| Step: 6
Training loss: 2.1311118602752686
Validation loss: 1.9062499982847585
Epoch: 9| Step: 7
Training loss: 2.1134257316589355
Validation loss: 1.9064430933204486
Epoch: 9| Step: 8
Training loss: 2.0404748916625977
Validation loss: 1.913121774899874
Epoch: 9| Step: 9
Training loss: 2.7060630321502686
Validation loss: 1.898685319818181
Epoch: 9| Step: 10
Training loss: 1.8664233684539795
Validation loss: 1.914295047307186
Epoch: 9| Step: 11
Training loss: 2.4591150283813477
Validation loss: 1.9200617100695054
Epoch: 9| Step: 12
Training loss: 1.612473487854004
Validation loss: 1.9096294152650901
Epoch: 9| Step: 13
Training loss: 1.855114221572876
Validation loss: 1.8985137767928968
Epoch: 9| Step: 14
Training loss: 2.092651844024658
Validation loss: 1.9122822970795117
Epoch: 9| Step: 15
Training loss: 2.1613221168518066
Validation loss: 1.8945334214958356
Epoch: 9| Step: 16
Training loss: 2.7067759037017822
Validation loss: 1.8843362528643162
Epoch: 9| Step: 17
Training loss: 2.3926146030426025
Validation loss: 1.8958158390127497
Epoch: 9| Step: 18
Training loss: 1.5905356407165527
Validation loss: 1.8927910122082388
Epoch: 9| Step: 19
Training loss: 1.9587984085083008
Validation loss: 1.8867016524719677
Epoch: 19| Step: 0
Training loss: 1.745330810546875
Validation loss: 1.8974313821723994
Epoch: 9| Step: 1
Training loss: 2.8379173278808594
Validation loss: 1.887943873302542
Epoch: 9| Step: 2
Training loss: 1.7340798377990723
Validation loss: 1.8953826667593539
Epoch: 9| Step: 3
Training loss: 1.7011072635650635
Validation loss: 1.8868457164695795
Epoch: 9| Step: 4
Training loss: 2.369703769683838
Validation loss: 1.8819981538992134
Epoch: 9| Step: 5
Training loss: 2.4236862659454346
Validation loss: 1.8722000568033121
Epoch: 9| Step: 6
Training loss: 1.8939887285232544
Validation loss: 1.8625584360506895
Epoch: 9| Step: 7
Training loss: 1.5944236516952515
Validation loss: 1.876145199906054
Epoch: 9| Step: 8
Training loss: 1.6988754272460938
Validation loss: 1.8735963200493682
Epoch: 9| Step: 9
Training loss: 2.1866097450256348
Validation loss: 1.8612835338647418
Epoch: 9| Step: 10
Training loss: 2.475080966949463
Validation loss: 1.855522210649449
Epoch: 9| Step: 11
Training loss: 2.3349037170410156
Validation loss: 1.873292699992228
Epoch: 9| Step: 12
Training loss: 2.470874547958374
Validation loss: 1.861044605858892
Epoch: 9| Step: 13
Training loss: 2.286067008972168
Validation loss: 1.8555337216356675
Epoch: 9| Step: 14
Training loss: 2.1566693782806396
Validation loss: 1.8430602370406226
Epoch: 9| Step: 15
Training loss: 2.825408935546875
Validation loss: 1.8437027253692957
Epoch: 9| Step: 16
Training loss: 2.0542898178100586
Validation loss: 1.8563314024492992
Epoch: 9| Step: 17
Training loss: 2.6377573013305664
Validation loss: 1.8625103098025424
Epoch: 9| Step: 18
Training loss: 1.1457619667053223
Validation loss: 1.8675914634045938
Epoch: 9| Step: 19
Training loss: 2.5201187133789062
Validation loss: 1.8526479923467842
Epoch: 20| Step: 0
Training loss: 2.099412441253662
Validation loss: 1.8662738645677086
Epoch: 9| Step: 1
Training loss: 2.6993045806884766
Validation loss: 1.8631299674082145
Epoch: 9| Step: 2
Training loss: 2.286667823791504
Validation loss: 1.8739421050325573
Epoch: 9| Step: 3
Training loss: 2.8130269050598145
Validation loss: 1.8982634998911576
Epoch: 9| Step: 4
Training loss: 1.6462360620498657
Validation loss: 1.8783339339194538
Epoch: 9| Step: 5
Training loss: 2.120326042175293
Validation loss: 1.8749121118792527
Epoch: 9| Step: 6
Training loss: 2.021672487258911
Validation loss: 1.8795226297790197
Epoch: 9| Step: 7
Training loss: 2.490947961807251
Validation loss: 1.8893153075691607
Epoch: 9| Step: 8
Training loss: 1.9316720962524414
Validation loss: 1.8852658323246798
Epoch: 9| Step: 9
Training loss: 1.7705881595611572
Validation loss: 1.8871697539048229
Epoch: 9| Step: 10
Training loss: 1.7576006650924683
Validation loss: 1.8799981016049283
Epoch: 9| Step: 11
Training loss: 2.0875930786132812
Validation loss: 1.9011190426435403
Epoch: 9| Step: 12
Training loss: 1.6395150423049927
Validation loss: 1.9041225601443283
Epoch: 9| Step: 13
Training loss: 2.678522825241089
Validation loss: 1.9092699134950157
Epoch: 9| Step: 14
Training loss: 2.3759279251098633
Validation loss: 1.9194314642775832
Epoch: 9| Step: 15
Training loss: 1.7673704624176025
Validation loss: 1.9120610780853162
Epoch: 9| Step: 16
Training loss: 2.2135634422302246
Validation loss: 1.9026776063356468
Epoch: 9| Step: 17
Training loss: 2.1053626537323
Validation loss: 1.9053856005771554
Epoch: 9| Step: 18
Training loss: 1.8494458198547363
Validation loss: 1.8933816839465134
Epoch: 9| Step: 19
Training loss: 2.4329206943511963
Validation loss: 1.908313626008068
Epoch: 21| Step: 0
Training loss: 1.9523123502731323
Validation loss: 1.9153619344285924
Epoch: 9| Step: 1
Training loss: 2.4381954669952393
Validation loss: 1.9027454347061596
Epoch: 9| Step: 2
Training loss: 1.8707962036132812
Validation loss: 1.8928185607031953
Epoch: 9| Step: 3
Training loss: 2.6179771423339844
Validation loss: 1.896207903786529
Epoch: 9| Step: 4
Training loss: 1.8097991943359375
Validation loss: 1.895624915472895
Epoch: 9| Step: 5
Training loss: 1.4854133129119873
Validation loss: 1.8851977355188603
Epoch: 9| Step: 6
Training loss: 1.8867677450180054
Validation loss: 1.8807219601363587
Epoch: 9| Step: 7
Training loss: 2.341501235961914
Validation loss: 1.8709652338096563
Epoch: 9| Step: 8
Training loss: 2.45805287361145
Validation loss: 1.8861114155474326
Epoch: 9| Step: 9
Training loss: 1.9979203939437866
Validation loss: 1.8910406373387618
Epoch: 9| Step: 10
Training loss: 2.4078798294067383
Validation loss: 1.89642431924669
Epoch: 9| Step: 11
Training loss: 1.409705400466919
Validation loss: 1.8773054733550807
Epoch: 9| Step: 12
Training loss: 1.8260149955749512
Validation loss: 1.8779712906844324
Epoch: 9| Step: 13
Training loss: 2.5771594047546387
Validation loss: 1.8697613040320307
Epoch: 9| Step: 14
Training loss: 2.3552098274230957
Validation loss: 1.8851657454058421
Epoch: 9| Step: 15
Training loss: 2.2003839015960693
Validation loss: 1.882051953308874
Epoch: 9| Step: 16
Training loss: 2.4890151023864746
Validation loss: 1.8757561239407217
Epoch: 9| Step: 17
Training loss: 1.8389697074890137
Validation loss: 1.8875967924543422
Epoch: 9| Step: 18
Training loss: 2.3259668350219727
Validation loss: 1.8746904572136969
Epoch: 9| Step: 19
Training loss: 2.319702386856079
Validation loss: 1.8686518806347745
Epoch: 22| Step: 0
Training loss: 2.020763635635376
Validation loss: 1.8775880808452907
Epoch: 9| Step: 1
Training loss: 2.134714126586914
Validation loss: 1.8605750130234862
Epoch: 9| Step: 2
Training loss: 1.644871473312378
Validation loss: 1.8586113212777555
Epoch: 9| Step: 3
Training loss: 2.5461068153381348
Validation loss: 1.8759368014850204
Epoch: 9| Step: 4
Training loss: 2.0311691761016846
Validation loss: 1.8822002569548517
Epoch: 9| Step: 5
Training loss: 2.3463997840881348
Validation loss: 1.877963110697355
Epoch: 9| Step: 6
Training loss: 1.8404347896575928
Validation loss: 1.87957864871128
Epoch: 9| Step: 7
Training loss: 1.7653892040252686
Validation loss: 1.8895233329251515
Epoch: 9| Step: 8
Training loss: 2.32700252532959
Validation loss: 1.8971624254322739
Epoch: 9| Step: 9
Training loss: 1.8484020233154297
Validation loss: 1.8903383659801896
Epoch: 9| Step: 10
Training loss: 1.9770039319992065
Validation loss: 1.8831212692123522
Epoch: 9| Step: 11
Training loss: 1.9333291053771973
Validation loss: 1.887166252239145
Epoch: 9| Step: 12
Training loss: 2.1088075637817383
Validation loss: 1.8975447887996975
Epoch: 9| Step: 13
Training loss: 2.9961400032043457
Validation loss: 1.8960246576679696
Epoch: 9| Step: 14
Training loss: 2.071934223175049
Validation loss: 1.894837457499058
Epoch: 9| Step: 15
Training loss: 1.9441194534301758
Validation loss: 1.8833880887614738
Epoch: 9| Step: 16
Training loss: 1.8588069677352905
Validation loss: 1.9050711582032898
Epoch: 9| Step: 17
Training loss: 3.2782833576202393
Validation loss: 1.8953913030006904
Epoch: 9| Step: 18
Training loss: 2.017052173614502
Validation loss: 1.8766993515783077
Epoch: 9| Step: 19
Training loss: 1.9704680442810059
Validation loss: 1.8998891020850313
Epoch: 23| Step: 0
Training loss: 2.2668206691741943
Validation loss: 1.8914624855672713
Epoch: 9| Step: 1
Training loss: 2.4418864250183105
Validation loss: 1.8742850058370357
Epoch: 9| Step: 2
Training loss: 2.127347946166992
Validation loss: 1.8672792860072294
Epoch: 9| Step: 3
Training loss: 2.246654510498047
Validation loss: 1.8727076542463235
Epoch: 9| Step: 4
Training loss: 2.6837925910949707
Validation loss: 1.8650486932384025
Epoch: 9| Step: 5
Training loss: 2.250336170196533
Validation loss: 1.8676644194897989
Epoch: 9| Step: 6
Training loss: 2.0180912017822266
Validation loss: 1.8634774136028702
Epoch: 9| Step: 7
Training loss: 1.9522038698196411
Validation loss: 1.8715658127832755
Epoch: 9| Step: 8
Training loss: 1.7780745029449463
Validation loss: 1.870471197924168
Epoch: 9| Step: 9
Training loss: 2.3134589195251465
Validation loss: 1.877855715134161
Epoch: 9| Step: 10
Training loss: 2.442176342010498
Validation loss: 1.8690184586339718
Epoch: 9| Step: 11
Training loss: 1.861041784286499
Validation loss: 1.8796135487316323
Epoch: 9| Step: 12
Training loss: 2.552194356918335
Validation loss: 1.8568601985629514
Epoch: 9| Step: 13
Training loss: 1.43716561794281
Validation loss: 1.8518371925079564
Epoch: 9| Step: 14
Training loss: 1.4703757762908936
Validation loss: 1.8393851115549211
Epoch: 9| Step: 15
Training loss: 2.152318000793457
Validation loss: 1.8475507900869246
Epoch: 9| Step: 16
Training loss: 2.287163257598877
Validation loss: 1.8454198760094402
Epoch: 9| Step: 17
Training loss: 2.8296990394592285
Validation loss: 1.8467464652850474
Epoch: 9| Step: 18
Training loss: 1.6984094381332397
Validation loss: 1.837694841323139
Epoch: 9| Step: 19
Training loss: 1.479149341583252
Validation loss: 1.8456199100549273
Epoch: 24| Step: 0
Training loss: 1.6285583972930908
Validation loss: 1.8550466805053272
Epoch: 9| Step: 1
Training loss: 2.238365650177002
Validation loss: 1.8426280759221358
Epoch: 9| Step: 2
Training loss: 1.8435543775558472
Validation loss: 1.8445876570914288
Epoch: 9| Step: 3
Training loss: 2.0971240997314453
Validation loss: 1.825740953143552
Epoch: 9| Step: 4
Training loss: 2.444304943084717
Validation loss: 1.8406347465172088
Epoch: 9| Step: 5
Training loss: 1.947130799293518
Validation loss: 1.8467936884585043
Epoch: 9| Step: 6
Training loss: 2.7209763526916504
Validation loss: 1.847036450886898
Epoch: 9| Step: 7
Training loss: 2.2968382835388184
Validation loss: 1.8483687373374005
Epoch: 9| Step: 8
Training loss: 2.003085136413574
Validation loss: 1.8527692642143305
Epoch: 9| Step: 9
Training loss: 1.7262262105941772
Validation loss: 1.8567744613551407
Epoch: 9| Step: 10
Training loss: 1.608492136001587
Validation loss: 1.8494904358609974
Epoch: 9| Step: 11
Training loss: 2.4094576835632324
Validation loss: 1.8570858454532762
Epoch: 9| Step: 12
Training loss: 2.0306894779205322
Validation loss: 1.8594504397550076
Epoch: 9| Step: 13
Training loss: 2.3310070037841797
Validation loss: 1.8674203166001135
Epoch: 9| Step: 14
Training loss: 2.1162707805633545
Validation loss: 1.8777933060694083
Epoch: 9| Step: 15
Training loss: 2.3088366985321045
Validation loss: 1.8735106385869087
Epoch: 9| Step: 16
Training loss: 2.116219997406006
Validation loss: 1.8701261573558232
Epoch: 9| Step: 17
Training loss: 2.373783588409424
Validation loss: 1.8702839175574213
Epoch: 9| Step: 18
Training loss: 1.9835989475250244
Validation loss: 1.871392606831283
Epoch: 9| Step: 19
Training loss: 1.8676555156707764
Validation loss: 1.87593105542574
Epoch: 25| Step: 0
Training loss: 2.263059616088867
Validation loss: 1.8593416557037572
Epoch: 9| Step: 1
Training loss: 2.285414457321167
Validation loss: 1.879877639331406
Epoch: 9| Step: 2
Training loss: 1.9889382123947144
Validation loss: 1.8590149810845904
Epoch: 9| Step: 3
Training loss: 2.68127179145813
Validation loss: 1.8736848942667461
Epoch: 9| Step: 4
Training loss: 1.9332525730133057
Validation loss: 1.8783375539368006
Epoch: 9| Step: 5
Training loss: 2.4928336143493652
Validation loss: 1.8743945111473688
Epoch: 9| Step: 6
Training loss: 2.3553836345672607
Validation loss: 1.8974505148345617
Epoch: 9| Step: 7
Training loss: 2.3830649852752686
Validation loss: 1.888927584929432
Epoch: 9| Step: 8
Training loss: 1.6495641469955444
Validation loss: 1.9001662936999644
Epoch: 9| Step: 9
Training loss: 1.0127006769180298
Validation loss: 1.876465155923967
Epoch: 9| Step: 10
Training loss: 1.4608345031738281
Validation loss: 1.892668107430712
Epoch: 9| Step: 11
Training loss: 2.146493673324585
Validation loss: 1.9080095840015
Epoch: 9| Step: 12
Training loss: 2.427999973297119
Validation loss: 1.8948431735416111
Epoch: 9| Step: 13
Training loss: 1.9483909606933594
Validation loss: 1.9058520219308868
Epoch: 9| Step: 14
Training loss: 2.6105685234069824
Validation loss: 1.9159264049941687
Epoch: 9| Step: 15
Training loss: 2.9070065021514893
Validation loss: 1.922522483112143
Epoch: 9| Step: 16
Training loss: 1.6547372341156006
Validation loss: 1.919063544959473
Epoch: 9| Step: 17
Training loss: 2.270993232727051
Validation loss: 1.9002465069722787
Epoch: 9| Step: 18
Training loss: 1.703857660293579
Validation loss: 1.903507676913584
Epoch: 9| Step: 19
Training loss: 1.916628122329712
Validation loss: 1.9115674572882893
Epoch: 26| Step: 0
Training loss: 2.0817646980285645
Validation loss: 1.8936256341796984
Epoch: 9| Step: 1
Training loss: 1.7562305927276611
Validation loss: 1.894102539089944
Epoch: 9| Step: 2
Training loss: 2.1687121391296387
Validation loss: 1.9007871090937003
Epoch: 9| Step: 3
Training loss: 1.9394054412841797
Validation loss: 1.8945157202027685
Epoch: 9| Step: 4
Training loss: 2.0666005611419678
Validation loss: 1.8995667910404344
Epoch: 9| Step: 5
Training loss: 1.7661168575286865
Validation loss: 1.8969002198829925
Epoch: 9| Step: 6
Training loss: 2.053940534591675
Validation loss: 1.8988670505208076
Epoch: 9| Step: 7
Training loss: 2.42460298538208
Validation loss: 1.8849510812073302
Epoch: 9| Step: 8
Training loss: 2.1342360973358154
Validation loss: 1.8696307930157339
Epoch: 9| Step: 9
Training loss: 2.5004215240478516
Validation loss: 1.884353951584521
Epoch: 9| Step: 10
Training loss: 2.4722306728363037
Validation loss: 1.8818949898369879
Epoch: 9| Step: 11
Training loss: 0.9913879632949829
Validation loss: 1.8784840604384168
Epoch: 9| Step: 12
Training loss: 2.2131600379943848
Validation loss: 1.8880066116936773
Epoch: 9| Step: 13
Training loss: 2.2495243549346924
Validation loss: 1.883505579378965
Epoch: 9| Step: 14
Training loss: 2.5823402404785156
Validation loss: 1.882546929146746
Epoch: 9| Step: 15
Training loss: 2.0134825706481934
Validation loss: 1.8438698430713132
Epoch: 9| Step: 16
Training loss: 2.2425179481506348
Validation loss: 1.8508099163178917
Epoch: 9| Step: 17
Training loss: 1.3341933488845825
Validation loss: 1.854035014728848
Epoch: 9| Step: 18
Training loss: 1.9782159328460693
Validation loss: 1.8614532467272642
Epoch: 9| Step: 19
Training loss: 2.9210104942321777
Validation loss: 1.853338142093137
Epoch: 27| Step: 0
Training loss: 2.0152249336242676
Validation loss: 1.8425904057866378
Epoch: 9| Step: 1
Training loss: 1.1741273403167725
Validation loss: 1.851469465296903
Epoch: 9| Step: 2
Training loss: 2.025364398956299
Validation loss: 1.8342831597911369
Epoch: 9| Step: 3
Training loss: 2.087390422821045
Validation loss: 1.8461711320945684
Epoch: 9| Step: 4
Training loss: 2.282550811767578
Validation loss: 1.8525301543928736
Epoch: 9| Step: 5
Training loss: 1.958638072013855
Validation loss: 1.864913168570978
Epoch: 9| Step: 6
Training loss: 1.9021848440170288
Validation loss: 1.855840991726882
Epoch: 9| Step: 7
Training loss: 1.8721970319747925
Validation loss: 1.8749687748847248
Epoch: 9| Step: 8
Training loss: 2.707033395767212
Validation loss: 1.8714152660301264
Epoch: 9| Step: 9
Training loss: 2.788454055786133
Validation loss: 1.8696028045613131
Epoch: 9| Step: 10
Training loss: 3.128970146179199
Validation loss: 1.8698817431497916
Epoch: 9| Step: 11
Training loss: 1.674202799797058
Validation loss: 1.8813797801518612
Epoch: 9| Step: 12
Training loss: 1.7873029708862305
Validation loss: 1.8716398623349855
Epoch: 9| Step: 13
Training loss: 1.958589792251587
Validation loss: 1.8706422452446367
Epoch: 9| Step: 14
Training loss: 2.0834341049194336
Validation loss: 1.8716356634236069
Epoch: 9| Step: 15
Training loss: 2.1640515327453613
Validation loss: 1.8742183858542134
Epoch: 9| Step: 16
Training loss: 2.514150619506836
Validation loss: 1.8756120342144864
Epoch: 9| Step: 17
Training loss: 2.3245654106140137
Validation loss: 1.8605304115967785
Epoch: 9| Step: 18
Training loss: 1.4184231758117676
Validation loss: 1.86927403391694
Epoch: 9| Step: 19
Training loss: 1.8479931354522705
Validation loss: 1.8743485546798158
Epoch: 28| Step: 0
Training loss: 1.6153514385223389
Validation loss: 1.872943837865651
Epoch: 9| Step: 1
Training loss: 2.0550553798675537
Validation loss: 1.8556375563573495
Epoch: 9| Step: 2
Training loss: 1.5029257535934448
Validation loss: 1.8732653135876003
Epoch: 9| Step: 3
Training loss: 2.0618014335632324
Validation loss: 1.875497077866424
Epoch: 9| Step: 4
Training loss: 2.257352590560913
Validation loss: 1.8795871485909112
Epoch: 9| Step: 5
Training loss: 1.6805542707443237
Validation loss: 1.8882944009286895
Epoch: 9| Step: 6
Training loss: 1.4152472019195557
Validation loss: 1.8915623743757068
Epoch: 9| Step: 7
Training loss: 1.5334851741790771
Validation loss: 1.9137869661660503
Epoch: 9| Step: 8
Training loss: 1.9307780265808105
Validation loss: 1.9034607667717145
Epoch: 9| Step: 9
Training loss: 1.7287065982818604
Validation loss: 1.910243928861275
Epoch: 9| Step: 10
Training loss: 2.553438663482666
Validation loss: 1.9191688873785004
Epoch: 9| Step: 11
Training loss: 2.1518912315368652
Validation loss: 1.92038289763087
Epoch: 9| Step: 12
Training loss: 1.8843803405761719
Validation loss: 1.933822811936303
Epoch: 9| Step: 13
Training loss: 2.1072192192077637
Validation loss: 1.9385706109108685
Epoch: 9| Step: 14
Training loss: 2.885470151901245
Validation loss: 1.9320430524057621
Epoch: 9| Step: 15
Training loss: 2.7538702487945557
Validation loss: 1.9240064946867579
Epoch: 9| Step: 16
Training loss: 2.644378185272217
Validation loss: 1.9406501749436633
Epoch: 9| Step: 17
Training loss: 2.5155491828918457
Validation loss: 1.921507598684846
Epoch: 9| Step: 18
Training loss: 2.3946690559387207
Validation loss: 1.9284619341651312
Epoch: 9| Step: 19
Training loss: 2.1550168991088867
Validation loss: 1.9222306278969745
Epoch: 29| Step: 0
Training loss: 1.6744601726531982
Validation loss: 1.9173816125169933
Epoch: 9| Step: 1
Training loss: 1.7587792873382568
Validation loss: 1.9141932554382215
Epoch: 9| Step: 2
Training loss: 2.082880973815918
Validation loss: 1.8934923762040172
Epoch: 9| Step: 3
Training loss: 2.4121971130371094
Validation loss: 1.894472060443686
Epoch: 9| Step: 4
Training loss: 1.5720975399017334
Validation loss: 1.885773639884784
Epoch: 9| Step: 5
Training loss: 2.2125473022460938
Validation loss: 1.8792545400935112
Epoch: 9| Step: 6
Training loss: 1.9110894203186035
Validation loss: 1.8664491828397023
Epoch: 9| Step: 7
Training loss: 2.6096415519714355
Validation loss: 1.8608337889472357
Epoch: 9| Step: 8
Training loss: 2.0943970680236816
Validation loss: 1.8823270900643987
Epoch: 9| Step: 9
Training loss: 2.407501459121704
Validation loss: 1.8520225046349943
Epoch: 9| Step: 10
Training loss: 2.3548924922943115
Validation loss: 1.8717244812052884
Epoch: 9| Step: 11
Training loss: 2.020822525024414
Validation loss: 1.8495752211097334
Epoch: 9| Step: 12
Training loss: 1.3621573448181152
Validation loss: 1.8518816447086472
Epoch: 9| Step: 13
Training loss: 1.4304579496383667
Validation loss: 1.8318835282497268
Epoch: 9| Step: 14
Training loss: 2.5655250549316406
Validation loss: 1.857935212498946
Epoch: 9| Step: 15
Training loss: 1.7522002458572388
Validation loss: 1.8526570462494445
Epoch: 9| Step: 16
Training loss: 2.0714478492736816
Validation loss: 1.852920040809851
Epoch: 9| Step: 17
Training loss: 1.9762473106384277
Validation loss: 1.8596037814943054
Epoch: 9| Step: 18
Training loss: 3.3669192790985107
Validation loss: 1.8424870659121506
Epoch: 9| Step: 19
Training loss: 1.8797670602798462
Validation loss: 1.8437038702930477
Epoch: 30| Step: 0
Training loss: 2.325962543487549
Validation loss: 1.864573076474581
Epoch: 9| Step: 1
Training loss: 2.178215503692627
Validation loss: 1.8524948641550627
Epoch: 9| Step: 2
Training loss: 2.0807979106903076
Validation loss: 1.8310095886532352
Epoch: 9| Step: 3
Training loss: 1.9369412660598755
Validation loss: 1.846958531750192
Epoch: 9| Step: 4
Training loss: 2.800535202026367
Validation loss: 1.8385747070792768
Epoch: 9| Step: 5
Training loss: 1.447896957397461
Validation loss: 1.8455520636743779
Epoch: 9| Step: 6
Training loss: 2.7002999782562256
Validation loss: 1.8327249142763427
Epoch: 9| Step: 7
Training loss: 2.5364298820495605
Validation loss: 1.827761080625246
Epoch: 9| Step: 8
Training loss: 1.7034212350845337
Validation loss: 1.831981111773484
Epoch: 9| Step: 9
Training loss: 1.9042680263519287
Validation loss: 1.8329054554589361
Epoch: 9| Step: 10
Training loss: 2.263997793197632
Validation loss: 1.8305188168724664
Epoch: 9| Step: 11
Training loss: 2.1297144889831543
Validation loss: 1.8303398837288507
Epoch: 9| Step: 12
Training loss: 1.7491514682769775
Validation loss: 1.8190500521831374
Epoch: 9| Step: 13
Training loss: 1.4867010116577148
Validation loss: 1.828342860551189
Epoch: 9| Step: 14
Training loss: 2.676389694213867
Validation loss: 1.8283021192756488
Epoch: 9| Step: 15
Training loss: 2.369462013244629
Validation loss: 1.8287574687450052
Epoch: 9| Step: 16
Training loss: 1.6500803232192993
Validation loss: 1.8397096129630108
Epoch: 9| Step: 17
Training loss: 1.9736669063568115
Validation loss: 1.835709329131696
Epoch: 9| Step: 18
Training loss: 2.16094970703125
Validation loss: 1.8454734095566565
Epoch: 9| Step: 19
Training loss: 1.4860444068908691
Validation loss: 1.8166960863758335
Epoch: 31| Step: 0
Training loss: 2.7324352264404297
Validation loss: 1.8405128057054478
Epoch: 9| Step: 1
Training loss: 1.3201320171356201
Validation loss: 1.8457268159166516
Epoch: 9| Step: 2
Training loss: 2.396888256072998
Validation loss: 1.8331781591442848
Epoch: 9| Step: 3
Training loss: 2.6834559440612793
Validation loss: 1.8437036558878508
Epoch: 9| Step: 4
Training loss: 1.9288346767425537
Validation loss: 1.8407092557536613
Epoch: 9| Step: 5
Training loss: 1.984492301940918
Validation loss: 1.8489029844887823
Epoch: 9| Step: 6
Training loss: 1.902392864227295
Validation loss: 1.863483320894859
Epoch: 9| Step: 7
Training loss: 1.62605881690979
Validation loss: 1.8483261676143399
Epoch: 9| Step: 8
Training loss: 2.628593683242798
Validation loss: 1.8832239530069366
Epoch: 9| Step: 9
Training loss: 1.8870232105255127
Validation loss: 1.8629307618244089
Epoch: 9| Step: 10
Training loss: 2.7118003368377686
Validation loss: 1.8661941718712127
Epoch: 9| Step: 11
Training loss: 2.3549156188964844
Validation loss: 1.8698556886302482
Epoch: 9| Step: 12
Training loss: 1.683457851409912
Validation loss: 1.876609456624916
Epoch: 9| Step: 13
Training loss: 1.8175361156463623
Validation loss: 1.845660152195169
Epoch: 9| Step: 14
Training loss: 1.6859126091003418
Validation loss: 1.874067920575039
Epoch: 9| Step: 15
Training loss: 1.6718864440917969
Validation loss: 1.8788059392421366
Epoch: 9| Step: 16
Training loss: 1.973159670829773
Validation loss: 1.8644966530285294
Epoch: 9| Step: 17
Training loss: 2.1861064434051514
Validation loss: 1.8793627349592799
Epoch: 9| Step: 18
Training loss: 1.8149431943893433
Validation loss: 1.8733636458143055
Epoch: 9| Step: 19
Training loss: 2.539235830307007
Validation loss: 1.8744745760512866
Epoch: 32| Step: 0
Training loss: 2.565018653869629
Validation loss: 1.8864103735779687
Epoch: 9| Step: 1
Training loss: 2.0936813354492188
Validation loss: 1.879746687498024
Epoch: 9| Step: 2
Training loss: 2.402533531188965
Validation loss: 1.8771583262107354
Epoch: 9| Step: 3
Training loss: 1.513562798500061
Validation loss: 1.8724734225719095
Epoch: 9| Step: 4
Training loss: 2.1104393005371094
Validation loss: 1.8742032445591987
Epoch: 9| Step: 5
Training loss: 2.417890787124634
Validation loss: 1.8602847486948795
Epoch: 9| Step: 6
Training loss: 1.9137194156646729
Validation loss: 1.8529503542742283
Epoch: 9| Step: 7
Training loss: 2.445594072341919
Validation loss: 1.8584211858914053
Epoch: 9| Step: 8
Training loss: 1.9252556562423706
Validation loss: 1.867913117511667
Epoch: 9| Step: 9
Training loss: 1.5422585010528564
Validation loss: 1.8660927667892238
Epoch: 9| Step: 10
Training loss: 1.809064507484436
Validation loss: 1.855302779794597
Epoch: 9| Step: 11
Training loss: 1.9291414022445679
Validation loss: 1.8524995399035995
Epoch: 9| Step: 12
Training loss: 2.2715606689453125
Validation loss: 1.8447469095531985
Epoch: 9| Step: 13
Training loss: 1.6753875017166138
Validation loss: 1.8503202285697993
Epoch: 9| Step: 14
Training loss: 1.604032039642334
Validation loss: 1.860534444987345
Epoch: 9| Step: 15
Training loss: 1.6258833408355713
Validation loss: 1.8486224078445983
Epoch: 9| Step: 16
Training loss: 1.832241415977478
Validation loss: 1.8661190074124783
Epoch: 9| Step: 17
Training loss: 2.6125571727752686
Validation loss: 1.8600126667846022
Epoch: 9| Step: 18
Training loss: 2.108180046081543
Validation loss: 1.8678116978501245
Epoch: 9| Step: 19
Training loss: 2.7658417224884033
Validation loss: 1.8749543882960038
Epoch: 33| Step: 0
Training loss: 2.634516477584839
Validation loss: 1.86286890077934
Epoch: 9| Step: 1
Training loss: 1.6300945281982422
Validation loss: 1.8499797239578029
Epoch: 9| Step: 2
Training loss: 2.2947211265563965
Validation loss: 1.865276271490742
Epoch: 9| Step: 3
Training loss: 2.5661487579345703
Validation loss: 1.8523107724224064
Epoch: 9| Step: 4
Training loss: 2.556985855102539
Validation loss: 1.8558121319297407
Epoch: 9| Step: 5
Training loss: 2.149683952331543
Validation loss: 1.859325878054118
Epoch: 9| Step: 6
Training loss: 2.0962469577789307
Validation loss: 1.8640593701986958
Epoch: 9| Step: 7
Training loss: 1.6325604915618896
Validation loss: 1.8553551469775413
Epoch: 9| Step: 8
Training loss: 1.9095121622085571
Validation loss: 1.8382903414664509
Epoch: 9| Step: 9
Training loss: 2.013831615447998
Validation loss: 1.8582559558127423
Epoch: 9| Step: 10
Training loss: 1.8447697162628174
Validation loss: 1.8542667138490745
Epoch: 9| Step: 11
Training loss: 2.526707172393799
Validation loss: 1.8396577937997503
Epoch: 9| Step: 12
Training loss: 1.6419577598571777
Validation loss: 1.858171909833126
Epoch: 9| Step: 13
Training loss: 1.9335286617279053
Validation loss: 1.8427838473011264
Epoch: 9| Step: 14
Training loss: 1.965926170349121
Validation loss: 1.8526965225343224
Epoch: 9| Step: 15
Training loss: 2.1260414123535156
Validation loss: 1.863469403424709
Epoch: 9| Step: 16
Training loss: 2.0223217010498047
Validation loss: 1.857860681821974
Epoch: 9| Step: 17
Training loss: 1.9350624084472656
Validation loss: 1.8546110065720922
Epoch: 9| Step: 18
Training loss: 2.0738818645477295
Validation loss: 1.8561751019182822
Epoch: 9| Step: 19
Training loss: 1.649757981300354
Validation loss: 1.859008278778131
Epoch: 34| Step: 0
Training loss: 1.9109210968017578
Validation loss: 1.8663288938055793
Epoch: 9| Step: 1
Training loss: 2.158907175064087
Validation loss: 1.861690778526471
Epoch: 9| Step: 2
Training loss: 2.4516894817352295
Validation loss: 1.8623026154881759
Epoch: 9| Step: 3
Training loss: 1.5492000579833984
Validation loss: 1.860087133997636
Epoch: 9| Step: 4
Training loss: 1.8737361431121826
Validation loss: 1.8681594056191204
Epoch: 9| Step: 5
Training loss: 3.084848642349243
Validation loss: 1.8477671901099115
Epoch: 9| Step: 6
Training loss: 1.747989296913147
Validation loss: 1.861034822120941
Epoch: 9| Step: 7
Training loss: 2.173699140548706
Validation loss: 1.8622824022238202
Epoch: 9| Step: 8
Training loss: 1.9258607625961304
Validation loss: 1.8649566019181725
Epoch: 9| Step: 9
Training loss: 2.077305316925049
Validation loss: 1.854027036282656
Epoch: 9| Step: 10
Training loss: 1.757696270942688
Validation loss: 1.8672997857169282
Epoch: 9| Step: 11
Training loss: 2.2072505950927734
Validation loss: 1.8558643112937323
Epoch: 9| Step: 12
Training loss: 1.9427614212036133
Validation loss: 1.8680093134049889
Epoch: 9| Step: 13
Training loss: 2.236107110977173
Validation loss: 1.8619959989040018
Epoch: 9| Step: 14
Training loss: 1.3392162322998047
Validation loss: 1.8778266177760612
Epoch: 9| Step: 15
Training loss: 2.8781187534332275
Validation loss: 1.8601139054881584
Epoch: 9| Step: 16
Training loss: 2.554889678955078
Validation loss: 1.8700332229943584
Epoch: 9| Step: 17
Training loss: 2.1771881580352783
Validation loss: 1.8465419124356277
Epoch: 9| Step: 18
Training loss: 1.9470704793930054
Validation loss: 1.8586157911973034
Epoch: 9| Step: 19
Training loss: 1.1154954433441162
Validation loss: 1.8766882899853823
Epoch: 35| Step: 0
Training loss: 2.0134618282318115
Validation loss: 1.850581358662612
Epoch: 9| Step: 1
Training loss: 2.1532979011535645
Validation loss: 1.8497193168393142
Epoch: 9| Step: 2
Training loss: 2.4226813316345215
Validation loss: 1.847118737028657
Epoch: 9| Step: 3
Training loss: 1.6871421337127686
Validation loss: 1.8521257458830909
Epoch: 9| Step: 4
Training loss: 2.4603092670440674
Validation loss: 1.8501297638570662
Epoch: 9| Step: 5
Training loss: 2.039457321166992
Validation loss: 1.8452626003635872
Epoch: 9| Step: 6
Training loss: 2.3498873710632324
Validation loss: 1.8372058576817134
Epoch: 9| Step: 7
Training loss: 2.43514347076416
Validation loss: 1.8382819299217608
Epoch: 9| Step: 8
Training loss: 2.0239624977111816
Validation loss: 1.8426151601530665
Epoch: 9| Step: 9
Training loss: 2.144733428955078
Validation loss: 1.8634580330883
Epoch: 9| Step: 10
Training loss: 1.6747798919677734
Validation loss: 1.8509536595653286
Epoch: 9| Step: 11
Training loss: 2.125960111618042
Validation loss: 1.8605481694928176
Epoch: 9| Step: 12
Training loss: 1.4124109745025635
Validation loss: 1.8620485787769017
Epoch: 9| Step: 13
Training loss: 1.718423843383789
Validation loss: 1.8626539621421758
Epoch: 9| Step: 14
Training loss: 1.7375943660736084
Validation loss: 1.8763112730259517
Epoch: 9| Step: 15
Training loss: 2.781017303466797
Validation loss: 1.8769623632911299
Epoch: 9| Step: 16
Training loss: 2.2146008014678955
Validation loss: 1.8609102406947733
Epoch: 9| Step: 17
Training loss: 2.1700897216796875
Validation loss: 1.8644449933827352
Epoch: 9| Step: 18
Training loss: 1.6646732091903687
Validation loss: 1.8750436786267397
Epoch: 9| Step: 19
Training loss: 2.1143953800201416
Validation loss: 1.8754717583278957
Epoch: 36| Step: 0
Training loss: 2.4238197803497314
Validation loss: 1.871662844856866
Epoch: 9| Step: 1
Training loss: 2.3667850494384766
Validation loss: 1.8759092401257522
Epoch: 9| Step: 2
Training loss: 1.6809673309326172
Validation loss: 1.860631774655349
Epoch: 9| Step: 3
Training loss: 2.280254364013672
Validation loss: 1.8462586582993432
Epoch: 9| Step: 4
Training loss: 1.821568489074707
Validation loss: 1.8549989298950853
Epoch: 9| Step: 5
Training loss: 1.7524497509002686
Validation loss: 1.8727283426325956
Epoch: 9| Step: 6
Training loss: 1.8284220695495605
Validation loss: 1.870288157634598
Epoch: 9| Step: 7
Training loss: 2.2735018730163574
Validation loss: 1.8615642897516704
Epoch: 9| Step: 8
Training loss: 2.100123882293701
Validation loss: 1.8553750686508288
Epoch: 9| Step: 9
Training loss: 1.902691125869751
Validation loss: 1.8557696085182025
Epoch: 9| Step: 10
Training loss: 1.372060775756836
Validation loss: 1.864790139438437
Epoch: 9| Step: 11
Training loss: 2.214320659637451
Validation loss: 1.8624039828348502
Epoch: 9| Step: 12
Training loss: 1.7728749513626099
Validation loss: 1.8694521814799137
Epoch: 9| Step: 13
Training loss: 2.698932409286499
Validation loss: 1.8795945472854505
Epoch: 9| Step: 14
Training loss: 1.1211947202682495
Validation loss: 1.8684649124419948
Epoch: 9| Step: 15
Training loss: 2.945744514465332
Validation loss: 1.8667272818174294
Epoch: 9| Step: 16
Training loss: 1.721449613571167
Validation loss: 1.8770667220191133
Epoch: 9| Step: 17
Training loss: 2.5114498138427734
Validation loss: 1.871463556083844
Epoch: 9| Step: 18
Training loss: 2.282754898071289
Validation loss: 1.8527331832501528
Epoch: 9| Step: 19
Training loss: 1.9327337741851807
Validation loss: 1.8724001200079061
Epoch: 37| Step: 0
Training loss: 1.9146881103515625
Validation loss: 1.8507534599990296
Epoch: 9| Step: 1
Training loss: 1.7679959535598755
Validation loss: 1.8568030415679053
Epoch: 9| Step: 2
Training loss: 2.0375547409057617
Validation loss: 1.8363873967163855
Epoch: 9| Step: 3
Training loss: 1.624143123626709
Validation loss: 1.8380071019097197
Epoch: 9| Step: 4
Training loss: 3.015453815460205
Validation loss: 1.843487250719139
Epoch: 9| Step: 5
Training loss: 2.090494155883789
Validation loss: 1.8515944034933187
Epoch: 9| Step: 6
Training loss: 2.140167236328125
Validation loss: 1.8461573767147477
Epoch: 9| Step: 7
Training loss: 2.2544608116149902
Validation loss: 1.8415125960068737
Epoch: 9| Step: 8
Training loss: 2.3777942657470703
Validation loss: 1.8342092448858907
Epoch: 9| Step: 9
Training loss: 1.743642807006836
Validation loss: 1.8218747025771107
Epoch: 9| Step: 10
Training loss: 2.1236767768859863
Validation loss: 1.835757511982815
Epoch: 9| Step: 11
Training loss: 1.9080798625946045
Validation loss: 1.828184621797191
Epoch: 9| Step: 12
Training loss: 2.0648250579833984
Validation loss: 1.8476527577681507
Epoch: 9| Step: 13
Training loss: 2.175528049468994
Validation loss: 1.8460738401618793
Epoch: 9| Step: 14
Training loss: 1.882752537727356
Validation loss: 1.8312507413274093
Epoch: 9| Step: 15
Training loss: 2.426590919494629
Validation loss: 1.8454058985058353
Epoch: 9| Step: 16
Training loss: 1.5679374933242798
Validation loss: 1.8528619292828676
Epoch: 9| Step: 17
Training loss: 1.4932575225830078
Validation loss: 1.8435261661200215
Epoch: 9| Step: 18
Training loss: 2.382181406021118
Validation loss: 1.8417534853914659
Epoch: 9| Step: 19
Training loss: 1.995461106300354
Validation loss: 1.8378005851086954
Epoch: 38| Step: 0
Training loss: 2.2119522094726562
Validation loss: 1.8299124155113164
Epoch: 9| Step: 1
Training loss: 1.2272975444793701
Validation loss: 1.830555533333648
Epoch: 9| Step: 2
Training loss: 1.2195169925689697
Validation loss: 1.8334100160667364
Epoch: 9| Step: 3
Training loss: 1.95375394821167
Validation loss: 1.838539469156334
Epoch: 9| Step: 4
Training loss: 2.0009701251983643
Validation loss: 1.843157131894887
Epoch: 9| Step: 5
Training loss: 1.939481258392334
Validation loss: 1.832326407055203
Epoch: 9| Step: 6
Training loss: 1.8525640964508057
Validation loss: 1.8272325199285
Epoch: 9| Step: 7
Training loss: 1.8880369663238525
Validation loss: 1.8261284176394237
Epoch: 9| Step: 8
Training loss: 2.1610612869262695
Validation loss: 1.8342333997753884
Epoch: 9| Step: 9
Training loss: 2.243455410003662
Validation loss: 1.821210807175945
Epoch: 9| Step: 10
Training loss: 2.5376815795898438
Validation loss: 1.82398232453161
Epoch: 9| Step: 11
Training loss: 2.4383673667907715
Validation loss: 1.8250877085349542
Epoch: 9| Step: 12
Training loss: 2.0405516624450684
Validation loss: 1.8292983127154891
Epoch: 9| Step: 13
Training loss: 2.477435827255249
Validation loss: 1.8183591014189686
Epoch: 9| Step: 14
Training loss: 1.8501091003417969
Validation loss: 1.8322127019758705
Epoch: 9| Step: 15
Training loss: 2.577343702316284
Validation loss: 1.8360997652835984
Epoch: 9| Step: 16
Training loss: 2.0335657596588135
Validation loss: 1.8251892474057863
Epoch: 9| Step: 17
Training loss: 2.5137476921081543
Validation loss: 1.8338759039803374
Epoch: 9| Step: 18
Training loss: 1.5393707752227783
Validation loss: 1.8105414574094814
Epoch: 9| Step: 19
Training loss: 1.9603760242462158
Validation loss: 1.8248055856004894
Epoch: 39| Step: 0
Training loss: 2.639632225036621
Validation loss: 1.8235839991260776
Epoch: 9| Step: 1
Training loss: 2.4765915870666504
Validation loss: 1.83076926186788
Epoch: 9| Step: 2
Training loss: 2.1392269134521484
Validation loss: 1.8176257498830342
Epoch: 9| Step: 3
Training loss: 2.2676711082458496
Validation loss: 1.8330903730804113
Epoch: 9| Step: 4
Training loss: 2.369765281677246
Validation loss: 1.836169727414632
Epoch: 9| Step: 5
Training loss: 2.417417049407959
Validation loss: 1.8487536358318741
Epoch: 9| Step: 6
Training loss: 2.0824570655822754
Validation loss: 1.837662376088204
Epoch: 9| Step: 7
Training loss: 1.8514816761016846
Validation loss: 1.8409792785164263
Epoch: 9| Step: 8
Training loss: 1.8172956705093384
Validation loss: 1.8600406166460874
Epoch: 9| Step: 9
Training loss: 2.0690207481384277
Validation loss: 1.848706311459164
Epoch: 9| Step: 10
Training loss: 2.1603665351867676
Validation loss: 1.847390809505106
Epoch: 9| Step: 11
Training loss: 1.292015790939331
Validation loss: 1.846800414778346
Epoch: 9| Step: 12
Training loss: 1.8708027601242065
Validation loss: 1.8618379042302962
Epoch: 9| Step: 13
Training loss: 2.37485671043396
Validation loss: 1.8643662432114856
Epoch: 9| Step: 14
Training loss: 1.737709641456604
Validation loss: 1.8645736347857138
Epoch: 9| Step: 15
Training loss: 1.896519422531128
Validation loss: 1.8671643425234787
Epoch: 9| Step: 16
Training loss: 1.8069076538085938
Validation loss: 1.8742780290919243
Epoch: 9| Step: 17
Training loss: 1.7891511917114258
Validation loss: 1.8599538648728844
Epoch: 9| Step: 18
Training loss: 1.631815791130066
Validation loss: 1.8810809704897216
Epoch: 9| Step: 19
Training loss: 2.070291042327881
Validation loss: 1.8702538905383872
Epoch: 40| Step: 0
Training loss: 1.788092851638794
Validation loss: 1.8589995987981343
Epoch: 9| Step: 1
Training loss: 3.381140947341919
Validation loss: 1.8527642771494475
Epoch: 9| Step: 2
Training loss: 1.6475071907043457
Validation loss: 1.842705440178192
Epoch: 9| Step: 3
Training loss: 2.801839590072632
Validation loss: 1.8557777576309313
Epoch: 9| Step: 4
Training loss: 2.047637939453125
Validation loss: 1.8369120213625243
Epoch: 9| Step: 5
Training loss: 1.7144992351531982
Validation loss: 1.8414481663875442
Epoch: 9| Step: 6
Training loss: 2.1842522621154785
Validation loss: 1.8519493487241456
Epoch: 9| Step: 7
Training loss: 1.605226993560791
Validation loss: 1.8439259391894443
Epoch: 9| Step: 8
Training loss: 1.747187614440918
Validation loss: 1.8343251557658902
Epoch: 9| Step: 9
Training loss: 2.1318094730377197
Validation loss: 1.8346659674061288
Epoch: 9| Step: 10
Training loss: 2.0875537395477295
Validation loss: 1.8215554446625195
Epoch: 9| Step: 11
Training loss: 1.4902397394180298
Validation loss: 1.8302851332177361
Epoch: 9| Step: 12
Training loss: 1.5568022727966309
Validation loss: 1.8308009621050718
Epoch: 9| Step: 13
Training loss: 2.3021044731140137
Validation loss: 1.8340394891423286
Epoch: 9| Step: 14
Training loss: 2.3956758975982666
Validation loss: 1.8325436158145931
Epoch: 9| Step: 15
Training loss: 1.9630142450332642
Validation loss: 1.8390059179539302
Epoch: 9| Step: 16
Training loss: 1.3690139055252075
Validation loss: 1.830905285670603
Epoch: 9| Step: 17
Training loss: 2.6178722381591797
Validation loss: 1.8198064771487559
Epoch: 9| Step: 18
Training loss: 2.113448143005371
Validation loss: 1.8267572620789783
Epoch: 9| Step: 19
Training loss: 1.7796082496643066
Validation loss: 1.838977579590228
Epoch: 41| Step: 0
Training loss: 1.8245214223861694
Validation loss: 1.8156214549387102
Epoch: 9| Step: 1
Training loss: 1.8498568534851074
Validation loss: 1.8231355149111301
Epoch: 9| Step: 2
Training loss: 2.025188446044922
Validation loss: 1.8265929299292805
Epoch: 9| Step: 3
Training loss: 2.0292444229125977
Validation loss: 1.8179577940659557
Epoch: 9| Step: 4
Training loss: 1.7040714025497437
Validation loss: 1.8152720473653121
Epoch: 9| Step: 5
Training loss: 2.3729891777038574
Validation loss: 1.8388395944087625
Epoch: 9| Step: 6
Training loss: 1.5575191974639893
Validation loss: 1.8119196728836717
Epoch: 9| Step: 7
Training loss: 2.0588488578796387
Validation loss: 1.840472519826546
Epoch: 9| Step: 8
Training loss: 1.963666319847107
Validation loss: 1.8588594009550354
Epoch: 9| Step: 9
Training loss: 2.267814874649048
Validation loss: 1.845475135089682
Epoch: 9| Step: 10
Training loss: 2.5295610427856445
Validation loss: 1.8443400010788182
Epoch: 9| Step: 11
Training loss: 2.3031694889068604
Validation loss: 1.8621559383200228
Epoch: 9| Step: 12
Training loss: 1.9778398275375366
Validation loss: 1.8513750395328878
Epoch: 9| Step: 13
Training loss: 1.6242986917495728
Validation loss: 1.8507101312815715
Epoch: 9| Step: 14
Training loss: 2.4447414875030518
Validation loss: 1.8505752292468394
Epoch: 9| Step: 15
Training loss: 1.6593737602233887
Validation loss: 1.862061028000262
Epoch: 9| Step: 16
Training loss: 1.7089855670928955
Validation loss: 1.8502629000505955
Epoch: 9| Step: 17
Training loss: 2.166163444519043
Validation loss: 1.8335590456887114
Epoch: 9| Step: 18
Training loss: 2.174315929412842
Validation loss: 1.8343284361654049
Epoch: 9| Step: 19
Training loss: 2.3510076999664307
Validation loss: 1.8376789796266624
Epoch: 42| Step: 0
Training loss: 2.4885945320129395
Validation loss: 1.8384789399963488
Epoch: 9| Step: 1
Training loss: 2.69460391998291
Validation loss: 1.8283161053554617
Epoch: 9| Step: 2
Training loss: 1.7670785188674927
Validation loss: 1.8326332226074
Epoch: 9| Step: 3
Training loss: 2.2572884559631348
Validation loss: 1.8313977675472233
Epoch: 9| Step: 4
Training loss: 1.3201768398284912
Validation loss: 1.8213925627495746
Epoch: 9| Step: 5
Training loss: 1.9069205522537231
Validation loss: 1.8211416426322442
Epoch: 9| Step: 6
Training loss: 2.198030948638916
Validation loss: 1.7998884341699615
Epoch: 9| Step: 7
Training loss: 1.6852972507476807
Validation loss: 1.8102022109271811
Epoch: 9| Step: 8
Training loss: 1.6842594146728516
Validation loss: 1.8078191125993248
Epoch: 9| Step: 9
Training loss: 2.395145893096924
Validation loss: 1.826396577649837
Epoch: 9| Step: 10
Training loss: 1.6202641725540161
Validation loss: 1.8109424517309065
Epoch: 9| Step: 11
Training loss: 2.2259714603424072
Validation loss: 1.8164838432408066
Epoch: 9| Step: 12
Training loss: 1.6123275756835938
Validation loss: 1.810918104734352
Epoch: 9| Step: 13
Training loss: 1.6550939083099365
Validation loss: 1.8082314240846702
Epoch: 9| Step: 14
Training loss: 2.388659954071045
Validation loss: 1.8152432578930753
Epoch: 9| Step: 15
Training loss: 1.653630256652832
Validation loss: 1.8114379464293555
Epoch: 9| Step: 16
Training loss: 1.6661057472229004
Validation loss: 1.8075498676986146
Epoch: 9| Step: 17
Training loss: 2.1931638717651367
Validation loss: 1.823264091134929
Epoch: 9| Step: 18
Training loss: 2.5474114418029785
Validation loss: 1.8184486944898426
Epoch: 9| Step: 19
Training loss: 2.702641487121582
Validation loss: 1.8228807209206999
Epoch: 43| Step: 0
Training loss: 2.1289501190185547
Validation loss: 1.8395300237394923
Epoch: 9| Step: 1
Training loss: 1.4972729682922363
Validation loss: 1.8298074564487814
Epoch: 9| Step: 2
Training loss: 2.343935489654541
Validation loss: 1.8399108142303906
Epoch: 9| Step: 3
Training loss: 1.7147654294967651
Validation loss: 1.8118794101605313
Epoch: 9| Step: 4
Training loss: 2.4694526195526123
Validation loss: 1.81903125142022
Epoch: 9| Step: 5
Training loss: 1.7070894241333008
Validation loss: 1.8176908655989943
Epoch: 9| Step: 6
Training loss: 2.0994014739990234
Validation loss: 1.829485017618687
Epoch: 9| Step: 7
Training loss: 1.5499846935272217
Validation loss: 1.8240873058922857
Epoch: 9| Step: 8
Training loss: 2.204251766204834
Validation loss: 1.8224870129454909
Epoch: 9| Step: 9
Training loss: 1.5625219345092773
Validation loss: 1.8307597860157918
Epoch: 9| Step: 10
Training loss: 1.934126377105713
Validation loss: 1.822310933963858
Epoch: 9| Step: 11
Training loss: 1.993757724761963
Validation loss: 1.847049889804648
Epoch: 9| Step: 12
Training loss: 2.732937812805176
Validation loss: 1.841243182154868
Epoch: 9| Step: 13
Training loss: 1.7023017406463623
Validation loss: 1.8325716016961515
Epoch: 9| Step: 14
Training loss: 2.206911087036133
Validation loss: 1.8569029964131416
Epoch: 9| Step: 15
Training loss: 2.5961227416992188
Validation loss: 1.8457330954160622
Epoch: 9| Step: 16
Training loss: 2.2316153049468994
Validation loss: 1.8633234792476079
Epoch: 9| Step: 17
Training loss: 2.3922083377838135
Validation loss: 1.869370257254127
Epoch: 9| Step: 18
Training loss: 2.2792975902557373
Validation loss: 1.8545334064703194
Epoch: 9| Step: 19
Training loss: 1.2044661045074463
Validation loss: 1.8611498427905624
Epoch: 44| Step: 0
Training loss: 2.137507915496826
Validation loss: 1.8532408587366558
Epoch: 9| Step: 1
Training loss: 1.674577236175537
Validation loss: 1.85592038168324
Epoch: 9| Step: 2
Training loss: 1.6465989351272583
Validation loss: 1.850177173991855
Epoch: 9| Step: 3
Training loss: 2.278407096862793
Validation loss: 1.8506797963766743
Epoch: 9| Step: 4
Training loss: 2.017240524291992
Validation loss: 1.8401790968805767
Epoch: 9| Step: 5
Training loss: 1.5258723497390747
Validation loss: 1.8478011990622651
Epoch: 9| Step: 6
Training loss: 1.5397343635559082
Validation loss: 1.8467229913464553
Epoch: 9| Step: 7
Training loss: 1.5066006183624268
Validation loss: 1.8676277021709964
Epoch: 9| Step: 8
Training loss: 1.8844685554504395
Validation loss: 1.8643568831382038
Epoch: 9| Step: 9
Training loss: 1.8048332929611206
Validation loss: 1.8501598397604853
Epoch: 9| Step: 10
Training loss: 2.711216449737549
Validation loss: 1.8857014059162827
Epoch: 9| Step: 11
Training loss: 1.878664255142212
Validation loss: 1.860930712102986
Epoch: 9| Step: 12
Training loss: 2.5130271911621094
Validation loss: 1.8623084996244033
Epoch: 9| Step: 13
Training loss: 2.5605623722076416
Validation loss: 1.870681061161508
Epoch: 9| Step: 14
Training loss: 2.0576577186584473
Validation loss: 1.8660994227841603
Epoch: 9| Step: 15
Training loss: 2.1143107414245605
Validation loss: 1.845666706133232
Epoch: 9| Step: 16
Training loss: 2.083207130432129
Validation loss: 1.8591411122315222
Epoch: 9| Step: 17
Training loss: 1.8097870349884033
Validation loss: 1.8477632587762187
Epoch: 9| Step: 18
Training loss: 2.6810574531555176
Validation loss: 1.8358878334649176
Epoch: 9| Step: 19
Training loss: 2.075979471206665
Validation loss: 1.839990670732457
Epoch: 45| Step: 0
Training loss: 1.8527412414550781
Validation loss: 1.8347813242630993
Epoch: 9| Step: 1
Training loss: 2.7278409004211426
Validation loss: 1.8337085761612268
Epoch: 9| Step: 2
Training loss: 2.194847345352173
Validation loss: 1.8159319393926387
Epoch: 9| Step: 3
Training loss: 2.394320011138916
Validation loss: 1.8297857775104989
Epoch: 9| Step: 4
Training loss: 2.366624116897583
Validation loss: 1.824134252911849
Epoch: 9| Step: 5
Training loss: 2.241790294647217
Validation loss: 1.8234466194248886
Epoch: 9| Step: 6
Training loss: 2.378028392791748
Validation loss: 1.8379006471565302
Epoch: 9| Step: 7
Training loss: 1.7718465328216553
Validation loss: 1.8149179897720007
Epoch: 9| Step: 8
Training loss: 2.050609588623047
Validation loss: 1.825372337437362
Epoch: 9| Step: 9
Training loss: 1.9928853511810303
Validation loss: 1.8161698399687842
Epoch: 9| Step: 10
Training loss: 1.9082688093185425
Validation loss: 1.8335697685214256
Epoch: 9| Step: 11
Training loss: 1.898491621017456
Validation loss: 1.8411112346237513
Epoch: 9| Step: 12
Training loss: 1.6135187149047852
Validation loss: 1.825515497502663
Epoch: 9| Step: 13
Training loss: 1.7811784744262695
Validation loss: 1.8172818576689247
Epoch: 9| Step: 14
Training loss: 2.308109998703003
Validation loss: 1.8192738912088409
Epoch: 9| Step: 15
Training loss: 1.7431246042251587
Validation loss: 1.8253292891619017
Epoch: 9| Step: 16
Training loss: 1.483193039894104
Validation loss: 1.847392732290913
Epoch: 9| Step: 17
Training loss: 1.9607855081558228
Validation loss: 1.8059237372103354
Epoch: 9| Step: 18
Training loss: 1.7662675380706787
Validation loss: 1.8101878440637382
Epoch: 9| Step: 19
Training loss: 2.0442440509796143
Validation loss: 1.8241341096891774
Epoch: 46| Step: 0
Training loss: 2.0556960105895996
Validation loss: 1.821318767053618
Epoch: 9| Step: 1
Training loss: 1.8697733879089355
Validation loss: 1.8305859428515536
Epoch: 9| Step: 2
Training loss: 2.16096830368042
Validation loss: 1.8361943085416614
Epoch: 9| Step: 3
Training loss: 1.9031914472579956
Validation loss: 1.8410115988134481
Epoch: 9| Step: 4
Training loss: 1.0654798746109009
Validation loss: 1.8439070037800631
Epoch: 9| Step: 5
Training loss: 2.133338212966919
Validation loss: 1.8401841945785413
Epoch: 9| Step: 6
Training loss: 2.3491530418395996
Validation loss: 1.8300163505746305
Epoch: 9| Step: 7
Training loss: 2.2447314262390137
Validation loss: 1.8414465703552576
Epoch: 9| Step: 8
Training loss: 2.0841383934020996
Validation loss: 1.826956143482126
Epoch: 9| Step: 9
Training loss: 2.0156519412994385
Validation loss: 1.836145593108033
Epoch: 9| Step: 10
Training loss: 1.9218835830688477
Validation loss: 1.827998679318874
Epoch: 9| Step: 11
Training loss: 2.313265800476074
Validation loss: 1.839922507032216
Epoch: 9| Step: 12
Training loss: 1.5380332469940186
Validation loss: 1.8310259289021114
Epoch: 9| Step: 13
Training loss: 2.2302658557891846
Validation loss: 1.8367225686423212
Epoch: 9| Step: 14
Training loss: 2.275792360305786
Validation loss: 1.8570160068196357
Epoch: 9| Step: 15
Training loss: 2.7324447631835938
Validation loss: 1.8337562024164542
Epoch: 9| Step: 16
Training loss: 1.6430613994598389
Validation loss: 1.8179512092535444
Epoch: 9| Step: 17
Training loss: 1.7552129030227661
Validation loss: 1.8201796854142662
Epoch: 9| Step: 18
Training loss: 2.03450083732605
Validation loss: 1.8402738485404913
Epoch: 9| Step: 19
Training loss: 1.9598393440246582
Validation loss: 1.8230930626821176
Epoch: 47| Step: 0
Training loss: 2.120931386947632
Validation loss: 1.822047885373342
Epoch: 9| Step: 1
Training loss: 2.38622784614563
Validation loss: 1.8470963128179096
Epoch: 9| Step: 2
Training loss: 2.352238655090332
Validation loss: 1.84016815363932
Epoch: 9| Step: 3
Training loss: 1.3628178834915161
Validation loss: 1.845007672584314
Epoch: 9| Step: 4
Training loss: 1.6551313400268555
Validation loss: 1.8364901894288097
Epoch: 9| Step: 5
Training loss: 1.8387672901153564
Validation loss: 1.8511132876650036
Epoch: 9| Step: 6
Training loss: 1.6499054431915283
Validation loss: 1.8487216963184823
Epoch: 9| Step: 7
Training loss: 1.6011924743652344
Validation loss: 1.8420407377558647
Epoch: 9| Step: 8
Training loss: 1.6497923135757446
Validation loss: 1.8523687561638922
Epoch: 9| Step: 9
Training loss: 2.2161715030670166
Validation loss: 1.8431426552559833
Epoch: 9| Step: 10
Training loss: 1.423263430595398
Validation loss: 1.8561653885052358
Epoch: 9| Step: 11
Training loss: 2.047541618347168
Validation loss: 1.8469191515188423
Epoch: 9| Step: 12
Training loss: 2.641136646270752
Validation loss: 1.8594288242806634
Epoch: 9| Step: 13
Training loss: 2.5411295890808105
Validation loss: 1.868898298242967
Epoch: 9| Step: 14
Training loss: 2.0300798416137695
Validation loss: 1.8578569451682
Epoch: 9| Step: 15
Training loss: 1.7254765033721924
Validation loss: 1.8638325277849925
Epoch: 9| Step: 16
Training loss: 2.3453547954559326
Validation loss: 1.8461670077961982
Epoch: 9| Step: 17
Training loss: 2.596433639526367
Validation loss: 1.87514645590199
Epoch: 9| Step: 18
Training loss: 2.2704310417175293
Validation loss: 1.8730301994213956
Epoch: 9| Step: 19
Training loss: 1.8719333410263062
Validation loss: 1.8553355374782206
Epoch: 48| Step: 0
Training loss: 2.4962918758392334
Validation loss: 1.864510279765232
Epoch: 9| Step: 1
Training loss: 2.1874823570251465
Validation loss: 1.8417098127680718
Epoch: 9| Step: 2
Training loss: 1.616020679473877
Validation loss: 1.830601461499715
Epoch: 9| Step: 3
Training loss: 1.6043622493743896
Validation loss: 1.8311443346009837
Epoch: 9| Step: 4
Training loss: 2.637691020965576
Validation loss: 1.8302909118666066
Epoch: 9| Step: 5
Training loss: 2.0035133361816406
Validation loss: 1.808884053779163
Epoch: 9| Step: 6
Training loss: 1.6574702262878418
Validation loss: 1.8134656149706394
Epoch: 9| Step: 7
Training loss: 2.3637824058532715
Validation loss: 1.818951664211081
Epoch: 9| Step: 8
Training loss: 1.4097950458526611
Validation loss: 1.8292050961967852
Epoch: 9| Step: 9
Training loss: 1.9303468465805054
Validation loss: 1.8174436624101598
Epoch: 9| Step: 10
Training loss: 2.0719823837280273
Validation loss: 1.8345439236798733
Epoch: 9| Step: 11
Training loss: 1.6717782020568848
Validation loss: 1.8067675631680935
Epoch: 9| Step: 12
Training loss: 1.7606358528137207
Validation loss: 1.8168925784474654
Epoch: 9| Step: 13
Training loss: 1.965369462966919
Validation loss: 1.812437013756457
Epoch: 9| Step: 14
Training loss: 1.9438130855560303
Validation loss: 1.8287646899120413
Epoch: 9| Step: 15
Training loss: 1.8349647521972656
Validation loss: 1.8102868400889336
Epoch: 9| Step: 16
Training loss: 1.782811164855957
Validation loss: 1.8221412099522651
Epoch: 9| Step: 17
Training loss: 2.687511920928955
Validation loss: 1.8166565414812925
Epoch: 9| Step: 18
Training loss: 2.6159675121307373
Validation loss: 1.8326150247518964
Epoch: 9| Step: 19
Training loss: 2.063854694366455
Validation loss: 1.819825837938048
Epoch: 49| Step: 0
Training loss: 1.7712666988372803
Validation loss: 1.8082148025361755
Epoch: 9| Step: 1
Training loss: 2.2998311519622803
Validation loss: 1.8160015215976633
Epoch: 9| Step: 2
Training loss: 1.8515844345092773
Validation loss: 1.81023185115924
Epoch: 9| Step: 3
Training loss: 1.8532824516296387
Validation loss: 1.8145008378749272
Epoch: 9| Step: 4
Training loss: 2.1361708641052246
Validation loss: 1.8057459018213287
Epoch: 9| Step: 5
Training loss: 1.927614450454712
Validation loss: 1.7858355268300008
Epoch: 9| Step: 6
Training loss: 1.8824515342712402
Validation loss: 1.797356367968827
Epoch: 9| Step: 7
Training loss: 1.9598171710968018
Validation loss: 1.8029912109855268
Epoch: 9| Step: 8
Training loss: 1.766139268875122
Validation loss: 1.7859529591292786
Epoch: 9| Step: 9
Training loss: 1.6296653747558594
Validation loss: 1.7992781889524392
Epoch: 9| Step: 10
Training loss: 2.155391216278076
Validation loss: 1.7885127685052886
Epoch: 9| Step: 11
Training loss: 1.750551462173462
Validation loss: 1.787055602176584
Epoch: 9| Step: 12
Training loss: 1.984383463859558
Validation loss: 1.7973314943931085
Epoch: 9| Step: 13
Training loss: 2.108229637145996
Validation loss: 1.7893943460725195
Epoch: 9| Step: 14
Training loss: 1.5607450008392334
Validation loss: 1.7901185450794028
Epoch: 9| Step: 15
Training loss: 2.423830509185791
Validation loss: 1.7984813588986295
Epoch: 9| Step: 16
Training loss: 2.081432342529297
Validation loss: 1.7976128437536225
Epoch: 9| Step: 17
Training loss: 3.4210610389709473
Validation loss: 1.8157099699802537
Epoch: 9| Step: 18
Training loss: 1.4578680992126465
Validation loss: 1.8132877915883236
Epoch: 9| Step: 19
Training loss: 2.115190029144287
Validation loss: 1.8083564248874033
Epoch: 50| Step: 0
Training loss: 2.4236509799957275
Validation loss: 1.8107703126591743
Epoch: 9| Step: 1
Training loss: 2.139838457107544
Validation loss: 1.8093085692083235
Epoch: 9| Step: 2
Training loss: 2.0631930828094482
Validation loss: 1.8227068666073916
Epoch: 9| Step: 3
Training loss: 1.7701719999313354
Validation loss: 1.8027430575528591
Epoch: 9| Step: 4
Training loss: 1.8252766132354736
Validation loss: 1.829646583941343
Epoch: 9| Step: 5
Training loss: 1.8807640075683594
Validation loss: 1.8117711303903044
Epoch: 9| Step: 6
Training loss: 2.1641149520874023
Validation loss: 1.809844643091984
Epoch: 9| Step: 7
Training loss: 1.9333122968673706
Validation loss: 1.8349831413022049
Epoch: 9| Step: 8
Training loss: 2.092442512512207
Validation loss: 1.8138597028718577
Epoch: 9| Step: 9
Training loss: 2.586925506591797
Validation loss: 1.841374349251068
Epoch: 9| Step: 10
Training loss: 1.6637349128723145
Validation loss: 1.814964653776704
Epoch: 9| Step: 11
Training loss: 2.017765998840332
Validation loss: 1.8168510996180474
Epoch: 9| Step: 12
Training loss: 1.9662786722183228
Validation loss: 1.8148724269523895
Epoch: 9| Step: 13
Training loss: 1.4988577365875244
Validation loss: 1.8437785982228012
Epoch: 9| Step: 14
Training loss: 1.821588158607483
Validation loss: 1.8364506505376144
Epoch: 9| Step: 15
Training loss: 2.6235029697418213
Validation loss: 1.8419726906920508
Epoch: 9| Step: 16
Training loss: 1.7855299711227417
Validation loss: 1.855457589780684
Epoch: 9| Step: 17
Training loss: 2.1577391624450684
Validation loss: 1.8400216651477401
Epoch: 9| Step: 18
Training loss: 1.3078371286392212
Validation loss: 1.8312949122284814
Epoch: 9| Step: 19
Training loss: 2.3942983150482178
Validation loss: 1.8411173957714932
Epoch: 51| Step: 0
Training loss: 2.5920615196228027
Validation loss: 1.8437707046810672
Epoch: 9| Step: 1
Training loss: 2.233821392059326
Validation loss: 1.8389339198311456
Epoch: 9| Step: 2
Training loss: 1.9665155410766602
Validation loss: 1.8377676893481247
Epoch: 9| Step: 3
Training loss: 1.6956901550292969
Validation loss: 1.8383308794858644
Epoch: 9| Step: 4
Training loss: 1.564729928970337
Validation loss: 1.8261365959112592
Epoch: 9| Step: 5
Training loss: 2.214120626449585
Validation loss: 1.8277948777452648
Epoch: 9| Step: 6
Training loss: 2.5400705337524414
Validation loss: 1.822606386040612
Epoch: 9| Step: 7
Training loss: 1.7410603761672974
Validation loss: 1.824847054996079
Epoch: 9| Step: 8
Training loss: 2.255511522293091
Validation loss: 1.8059994994307593
Epoch: 9| Step: 9
Training loss: 2.4079201221466064
Validation loss: 1.8135324030471363
Epoch: 9| Step: 10
Training loss: 1.2352570295333862
Validation loss: 1.8215523229228507
Epoch: 9| Step: 11
Training loss: 2.013882637023926
Validation loss: 1.8122571886872216
Epoch: 9| Step: 12
Training loss: 1.641088604927063
Validation loss: 1.8071196876841484
Epoch: 9| Step: 13
Training loss: 2.059720993041992
Validation loss: 1.8054948427694306
Epoch: 9| Step: 14
Training loss: 1.936609148979187
Validation loss: 1.8063608931122923
Epoch: 9| Step: 15
Training loss: 1.7745177745819092
Validation loss: 1.8133090014080349
Epoch: 9| Step: 16
Training loss: 1.6688542366027832
Validation loss: 1.812163824657742
Epoch: 9| Step: 17
Training loss: 1.951499342918396
Validation loss: 1.7933067400678455
Epoch: 9| Step: 18
Training loss: 2.674285411834717
Validation loss: 1.821929130622809
Epoch: 9| Step: 19
Training loss: 1.9644265174865723
Validation loss: 1.8152047584382751
Epoch: 52| Step: 0
Training loss: 1.7286573648452759
Validation loss: 1.8272406188704127
Epoch: 9| Step: 1
Training loss: 2.1459012031555176
Validation loss: 1.8204740165806503
Epoch: 9| Step: 2
Training loss: 2.4039769172668457
Validation loss: 1.8327203448727833
Epoch: 9| Step: 3
Training loss: 2.053241014480591
Validation loss: 1.8286797803082913
Epoch: 9| Step: 4
Training loss: 1.4500160217285156
Validation loss: 1.849171850321104
Epoch: 9| Step: 5
Training loss: 2.268601179122925
Validation loss: 1.82227814969399
Epoch: 9| Step: 6
Training loss: 1.9506633281707764
Validation loss: 1.822011607156383
Epoch: 9| Step: 7
Training loss: 2.998229503631592
Validation loss: 1.83098304271698
Epoch: 9| Step: 8
Training loss: 1.2563362121582031
Validation loss: 1.8187961029491837
Epoch: 9| Step: 9
Training loss: 1.5322227478027344
Validation loss: 1.8134565619256
Epoch: 9| Step: 10
Training loss: 1.3821132183074951
Validation loss: 1.80664823123877
Epoch: 9| Step: 11
Training loss: 2.207362174987793
Validation loss: 1.8216385909979291
Epoch: 9| Step: 12
Training loss: 2.785066843032837
Validation loss: 1.8393541720273683
Epoch: 9| Step: 13
Training loss: 1.4663026332855225
Validation loss: 1.8128009219821408
Epoch: 9| Step: 14
Training loss: 1.8724523782730103
Validation loss: 1.8068719356180094
Epoch: 9| Step: 15
Training loss: 2.182219982147217
Validation loss: 1.8203030575951227
Epoch: 9| Step: 16
Training loss: 2.001979112625122
Validation loss: 1.8140049152237048
Epoch: 9| Step: 17
Training loss: 2.2259774208068848
Validation loss: 1.8208838126642242
Epoch: 9| Step: 18
Training loss: 1.498380184173584
Validation loss: 1.816030218446855
Epoch: 9| Step: 19
Training loss: 2.4082226753234863
Validation loss: 1.818167606703669
Epoch: 53| Step: 0
Training loss: 2.091475486755371
Validation loss: 1.807625206254369
Epoch: 9| Step: 1
Training loss: 2.2647593021392822
Validation loss: 1.8148081285490407
Epoch: 9| Step: 2
Training loss: 2.084366798400879
Validation loss: 1.8152649008112847
Epoch: 9| Step: 3
Training loss: 1.9289368391036987
Validation loss: 1.7943727215416998
Epoch: 9| Step: 4
Training loss: 1.282645344734192
Validation loss: 1.818127977762291
Epoch: 9| Step: 5
Training loss: 2.1307504177093506
Validation loss: 1.8039484135538555
Epoch: 9| Step: 6
Training loss: 1.7155438661575317
Validation loss: 1.812940422579539
Epoch: 9| Step: 7
Training loss: 1.4768016338348389
Validation loss: 1.8071639958045465
Epoch: 9| Step: 8
Training loss: 2.305051803588867
Validation loss: 1.7987918596473529
Epoch: 9| Step: 9
Training loss: 2.954774856567383
Validation loss: 1.8192051537602925
Epoch: 9| Step: 10
Training loss: 2.0330770015716553
Validation loss: 1.8111664605655258
Epoch: 9| Step: 11
Training loss: 2.1512255668640137
Validation loss: 1.8055894803657806
Epoch: 9| Step: 12
Training loss: 2.074828624725342
Validation loss: 1.793873615402112
Epoch: 9| Step: 13
Training loss: 1.8516863584518433
Validation loss: 1.813208575728986
Epoch: 9| Step: 14
Training loss: 1.9224028587341309
Validation loss: 1.80176260059686
Epoch: 9| Step: 15
Training loss: 1.7660596370697021
Validation loss: 1.8062553491523798
Epoch: 9| Step: 16
Training loss: 1.7472450733184814
Validation loss: 1.810502901351709
Epoch: 9| Step: 17
Training loss: 2.2514994144439697
Validation loss: 1.8206558939364317
Epoch: 9| Step: 18
Training loss: 1.8607059717178345
Validation loss: 1.8253615245544652
Epoch: 9| Step: 19
Training loss: 2.230626106262207
Validation loss: 1.8263531923294067
Epoch: 54| Step: 0
Training loss: 1.7982511520385742
Validation loss: 1.8180387757664962
Epoch: 9| Step: 1
Training loss: 2.6182100772857666
Validation loss: 1.8117476761769906
Epoch: 9| Step: 2
Training loss: 2.024371862411499
Validation loss: 1.8234238676030001
Epoch: 9| Step: 3
Training loss: 1.8633263111114502
Validation loss: 1.8105530327172588
Epoch: 9| Step: 4
Training loss: 1.7370415925979614
Validation loss: 1.8073693976985465
Epoch: 9| Step: 5
Training loss: 2.259396553039551
Validation loss: 1.8165417369321095
Epoch: 9| Step: 6
Training loss: 2.4633538722991943
Validation loss: 1.7940105963096344
Epoch: 9| Step: 7
Training loss: 2.724055528640747
Validation loss: 1.8121209007372958
Epoch: 9| Step: 8
Training loss: 1.5939348936080933
Validation loss: 1.8275603064530188
Epoch: 9| Step: 9
Training loss: 1.8607935905456543
Validation loss: 1.8269490458124833
Epoch: 9| Step: 10
Training loss: 2.219999313354492
Validation loss: 1.8110274745406008
Epoch: 9| Step: 11
Training loss: 2.2986507415771484
Validation loss: 1.7944871616020477
Epoch: 9| Step: 12
Training loss: 1.4966542720794678
Validation loss: 1.8224631813790302
Epoch: 9| Step: 13
Training loss: 1.7582447528839111
Validation loss: 1.8200367448998869
Epoch: 9| Step: 14
Training loss: 1.8742752075195312
Validation loss: 1.8178866930145154
Epoch: 9| Step: 15
Training loss: 1.640565037727356
Validation loss: 1.8038025734235914
Epoch: 9| Step: 16
Training loss: 2.4198074340820312
Validation loss: 1.8203724399745036
Epoch: 9| Step: 17
Training loss: 1.7517640590667725
Validation loss: 1.8191307277130566
Epoch: 9| Step: 18
Training loss: 2.05069899559021
Validation loss: 1.8227507450597749
Epoch: 9| Step: 19
Training loss: 1.4982774257659912
Validation loss: 1.8232469284277169
Epoch: 55| Step: 0
Training loss: 2.139573335647583
Validation loss: 1.8324124864537081
Epoch: 9| Step: 1
Training loss: 1.6000733375549316
Validation loss: 1.8261683347413866
Epoch: 9| Step: 2
Training loss: 1.7737808227539062
Validation loss: 1.8229926224235151
Epoch: 9| Step: 3
Training loss: 2.590934991836548
Validation loss: 1.824764471259906
Epoch: 9| Step: 4
Training loss: 2.1135120391845703
Validation loss: 1.8187012852524682
Epoch: 9| Step: 5
Training loss: 2.398477077484131
Validation loss: 1.84047848715199
Epoch: 9| Step: 6
Training loss: 2.5925259590148926
Validation loss: 1.8281181973519085
Epoch: 9| Step: 7
Training loss: 1.9706926345825195
Validation loss: 1.841566590954074
Epoch: 9| Step: 8
Training loss: 2.1544203758239746
Validation loss: 1.8254565712359312
Epoch: 9| Step: 9
Training loss: 1.9462831020355225
Validation loss: 1.8344993754256544
Epoch: 9| Step: 10
Training loss: 1.3677266836166382
Validation loss: 1.822363439223749
Epoch: 9| Step: 11
Training loss: 1.0861210823059082
Validation loss: 1.8252692008190017
Epoch: 9| Step: 12
Training loss: 2.4320101737976074
Validation loss: 1.8020886337156776
Epoch: 9| Step: 13
Training loss: 1.6850106716156006
Validation loss: 1.8126957176400602
Epoch: 9| Step: 14
Training loss: 2.633786916732788
Validation loss: 1.8434979786975778
Epoch: 9| Step: 15
Training loss: 2.100250720977783
Validation loss: 1.8235174957796825
Epoch: 9| Step: 16
Training loss: 1.8227601051330566
Validation loss: 1.8465136383934844
Epoch: 9| Step: 17
Training loss: 2.2334442138671875
Validation loss: 1.8273189076416785
Epoch: 9| Step: 18
Training loss: 1.7292838096618652
Validation loss: 1.8092038717201289
Epoch: 9| Step: 19
Training loss: 1.6127516031265259
Validation loss: 1.8146871834350147
Epoch: 56| Step: 0
Training loss: 1.4626765251159668
Validation loss: 1.8207429690326717
Epoch: 9| Step: 1
Training loss: 2.336277723312378
Validation loss: 1.8130076720560198
Epoch: 9| Step: 2
Training loss: 2.285158157348633
Validation loss: 1.816097746650092
Epoch: 9| Step: 3
Training loss: 1.9019496440887451
Validation loss: 1.8084547845579737
Epoch: 9| Step: 4
Training loss: 1.254704236984253
Validation loss: 1.7991985442827074
Epoch: 9| Step: 5
Training loss: 2.1756176948547363
Validation loss: 1.8147895336151123
Epoch: 9| Step: 6
Training loss: 2.3882641792297363
Validation loss: 1.8092861544314047
Epoch: 9| Step: 7
Training loss: 1.2909278869628906
Validation loss: 1.8059379951559382
Epoch: 9| Step: 8
Training loss: 2.47969126701355
Validation loss: 1.8167241374365717
Epoch: 9| Step: 9
Training loss: 2.5724267959594727
Validation loss: 1.8206705198013524
Epoch: 9| Step: 10
Training loss: 2.5210211277008057
Validation loss: 1.797351619322523
Epoch: 9| Step: 11
Training loss: 1.9219000339508057
Validation loss: 1.8108127674610495
Epoch: 9| Step: 12
Training loss: 1.8301362991333008
Validation loss: 1.7887561175463011
Epoch: 9| Step: 13
Training loss: 1.9987311363220215
Validation loss: 1.8053166531830382
Epoch: 9| Step: 14
Training loss: 1.9422343969345093
Validation loss: 1.807776198970328
Epoch: 9| Step: 15
Training loss: 1.9476698637008667
Validation loss: 1.7862308385560839
Epoch: 9| Step: 16
Training loss: 1.5708986520767212
Validation loss: 1.8134632633744383
Epoch: 9| Step: 17
Training loss: 1.8711105585098267
Validation loss: 1.815048049679763
Epoch: 9| Step: 18
Training loss: 1.8723225593566895
Validation loss: 1.8285516543354061
Epoch: 9| Step: 19
Training loss: 2.4164350032806396
Validation loss: 1.816384237447231
Epoch: 57| Step: 0
Training loss: 1.6444809436798096
Validation loss: 1.8051229200774817
Epoch: 9| Step: 1
Training loss: 1.4158936738967896
Validation loss: 1.8102941838957423
Epoch: 9| Step: 2
Training loss: 2.512329578399658
Validation loss: 1.8420679817954413
Epoch: 9| Step: 3
Training loss: 1.9769312143325806
Validation loss: 1.8210517330992995
Epoch: 9| Step: 4
Training loss: 1.4550247192382812
Validation loss: 1.8341182701879268
Epoch: 9| Step: 5
Training loss: 2.3079471588134766
Validation loss: 1.8362735672820387
Epoch: 9| Step: 6
Training loss: 1.7981531620025635
Validation loss: 1.852854479988702
Epoch: 9| Step: 7
Training loss: 2.0909297466278076
Validation loss: 1.8389217493345411
Epoch: 9| Step: 8
Training loss: 1.7254868745803833
Validation loss: 1.8446087751457159
Epoch: 9| Step: 9
Training loss: 2.7108676433563232
Validation loss: 1.866557839963076
Epoch: 9| Step: 10
Training loss: 1.7701444625854492
Validation loss: 1.8407323411900363
Epoch: 9| Step: 11
Training loss: 2.490204334259033
Validation loss: 1.8517633239142328
Epoch: 9| Step: 12
Training loss: 1.547480821609497
Validation loss: 1.8577653898609627
Epoch: 9| Step: 13
Training loss: 2.5776171684265137
Validation loss: 1.8445505401213391
Epoch: 9| Step: 14
Training loss: 2.0832467079162598
Validation loss: 1.8425416354652788
Epoch: 9| Step: 15
Training loss: 1.8098376989364624
Validation loss: 1.8258029814246748
Epoch: 9| Step: 16
Training loss: 1.6800124645233154
Validation loss: 1.845544736162364
Epoch: 9| Step: 17
Training loss: 2.7934882640838623
Validation loss: 1.8224810018813868
Epoch: 9| Step: 18
Training loss: 1.770032525062561
Validation loss: 1.8204486627372907
Epoch: 9| Step: 19
Training loss: 1.699317216873169
Validation loss: 1.8242543592727443
Epoch: 58| Step: 0
Training loss: 2.518995761871338
Validation loss: 1.8262168211902645
Epoch: 9| Step: 1
Training loss: 1.6780750751495361
Validation loss: 1.8002114278807058
Epoch: 9| Step: 2
Training loss: 2.0402064323425293
Validation loss: 1.7828209503091497
Epoch: 9| Step: 3
Training loss: 2.2758047580718994
Validation loss: 1.7956743274661278
Epoch: 9| Step: 4
Training loss: 2.134459972381592
Validation loss: 1.804005916170079
Epoch: 9| Step: 5
Training loss: 1.960381269454956
Validation loss: 1.7781145675576848
Epoch: 9| Step: 6
Training loss: 2.184332847595215
Validation loss: 1.7899243299909633
Epoch: 9| Step: 7
Training loss: 1.9467718601226807
Validation loss: 1.7805165712781947
Epoch: 9| Step: 8
Training loss: 1.3749213218688965
Validation loss: 1.77215601214402
Epoch: 9| Step: 9
Training loss: 1.9366554021835327
Validation loss: 1.7795441305037025
Epoch: 9| Step: 10
Training loss: 1.5345299243927002
Validation loss: 1.7877277032934504
Epoch: 9| Step: 11
Training loss: 1.9651498794555664
Validation loss: 1.7730431685344779
Epoch: 9| Step: 12
Training loss: 1.7705674171447754
Validation loss: 1.7606681250839782
Epoch: 9| Step: 13
Training loss: 2.0413877964019775
Validation loss: 1.7676541187780366
Epoch: 9| Step: 14
Training loss: 1.532548189163208
Validation loss: 1.7336889102304582
Epoch: 9| Step: 15
Training loss: 2.2120704650878906
Validation loss: 1.7659004009027275
Epoch: 9| Step: 16
Training loss: 1.7873176336288452
Validation loss: 1.7598119365225593
Epoch: 9| Step: 17
Training loss: 2.5429463386535645
Validation loss: 1.7691192678410372
Epoch: 9| Step: 18
Training loss: 2.43414306640625
Validation loss: 1.769646005664798
Epoch: 9| Step: 19
Training loss: 2.323598861694336
Validation loss: 1.7646055830468377
Epoch: 59| Step: 0
Training loss: 2.4338560104370117
Validation loss: 1.7861721206912033
Epoch: 9| Step: 1
Training loss: 2.2741031646728516
Validation loss: 1.790002687371892
Epoch: 9| Step: 2
Training loss: 1.9515101909637451
Validation loss: 1.772485901125901
Epoch: 9| Step: 3
Training loss: 1.5731855630874634
Validation loss: 1.799682136062238
Epoch: 9| Step: 4
Training loss: 1.8651663064956665
Validation loss: 1.8007547134975734
Epoch: 9| Step: 5
Training loss: 2.19974946975708
Validation loss: 1.8048039143034023
Epoch: 9| Step: 6
Training loss: 2.605738639831543
Validation loss: 1.814833042432936
Epoch: 9| Step: 7
Training loss: 2.52407169342041
Validation loss: 1.8107579277573729
Epoch: 9| Step: 8
Training loss: 0.9113228917121887
Validation loss: 1.817335856046608
Epoch: 9| Step: 9
Training loss: 1.7965457439422607
Validation loss: 1.8488616428786901
Epoch: 9| Step: 10
Training loss: 2.231910228729248
Validation loss: 1.8509257302867423
Epoch: 9| Step: 11
Training loss: 1.7605103254318237
Validation loss: 1.8416890652059652
Epoch: 9| Step: 12
Training loss: 1.551522970199585
Validation loss: 1.862831091709274
Epoch: 9| Step: 13
Training loss: 2.415198802947998
Validation loss: 1.8534927153758864
Epoch: 9| Step: 14
Training loss: 2.507925271987915
Validation loss: 1.8500152123060158
Epoch: 9| Step: 15
Training loss: 1.6857242584228516
Validation loss: 1.8748583716454266
Epoch: 9| Step: 16
Training loss: 1.9626545906066895
Validation loss: 1.8492634021978585
Epoch: 9| Step: 17
Training loss: 1.9263442754745483
Validation loss: 1.8397097107317808
Epoch: 9| Step: 18
Training loss: 1.6217080354690552
Validation loss: 1.8511410274093958
Epoch: 9| Step: 19
Training loss: 2.211825132369995
Validation loss: 1.8423378999284703
Epoch: 60| Step: 0
Training loss: 2.182544231414795
Validation loss: 1.8529345020115804
Epoch: 9| Step: 1
Training loss: 2.2439146041870117
Validation loss: 1.8615646379457103
Epoch: 9| Step: 2
Training loss: 2.58425235748291
Validation loss: 1.846093320160461
Epoch: 9| Step: 3
Training loss: 1.7932974100112915
Validation loss: 1.837068205257114
Epoch: 9| Step: 4
Training loss: 1.882617712020874
Validation loss: 1.8334950963370233
Epoch: 9| Step: 5
Training loss: 1.8883452415466309
Validation loss: 1.8222652956736174
Epoch: 9| Step: 6
Training loss: 2.0268850326538086
Validation loss: 1.839265397126726
Epoch: 9| Step: 7
Training loss: 1.69930899143219
Validation loss: 1.8250784307932681
Epoch: 9| Step: 8
Training loss: 2.3390121459960938
Validation loss: 1.8230772627343377
Epoch: 9| Step: 9
Training loss: 1.724571943283081
Validation loss: 1.821839463796547
Epoch: 9| Step: 10
Training loss: 1.459770917892456
Validation loss: 1.8220360776503308
Epoch: 9| Step: 11
Training loss: 1.9254419803619385
Validation loss: 1.830423958009953
Epoch: 9| Step: 12
Training loss: 2.5847673416137695
Validation loss: 1.841830489446791
Epoch: 9| Step: 13
Training loss: 2.371323585510254
Validation loss: 1.8317334000155223
Epoch: 9| Step: 14
Training loss: 1.7222633361816406
Validation loss: 1.834961750524507
Epoch: 9| Step: 15
Training loss: 1.7106335163116455
Validation loss: 1.8321110670515102
Epoch: 9| Step: 16
Training loss: 1.9588764905929565
Validation loss: 1.8248799258856465
Epoch: 9| Step: 17
Training loss: 2.386033058166504
Validation loss: 1.8172488538481348
Epoch: 9| Step: 18
Training loss: 1.8985226154327393
Validation loss: 1.8288953861744284
Epoch: 9| Step: 19
Training loss: 1.429065227508545
Validation loss: 1.8201084720145027
Epoch: 61| Step: 0
Training loss: 1.9590754508972168
Validation loss: 1.810041162607481
Epoch: 9| Step: 1
Training loss: 2.093773126602173
Validation loss: 1.7985007994466549
Epoch: 9| Step: 2
Training loss: 1.4186218976974487
Validation loss: 1.8190696196590397
Epoch: 9| Step: 3
Training loss: 1.4888405799865723
Validation loss: 1.783636281816222
Epoch: 9| Step: 4
Training loss: 1.8005095720291138
Validation loss: 1.7814473651295943
Epoch: 9| Step: 5
Training loss: 2.1379237174987793
Validation loss: 1.796270360191949
Epoch: 9| Step: 6
Training loss: 2.7942657470703125
Validation loss: 1.7988639358136294
Epoch: 9| Step: 7
Training loss: 2.2643702030181885
Validation loss: 1.8089270128620614
Epoch: 9| Step: 8
Training loss: 1.2792491912841797
Validation loss: 1.8033937430210252
Epoch: 9| Step: 9
Training loss: 2.0741653442382812
Validation loss: 1.7945984164587885
Epoch: 9| Step: 10
Training loss: 1.824446439743042
Validation loss: 1.8049528830343013
Epoch: 9| Step: 11
Training loss: 2.833897590637207
Validation loss: 1.824426009500627
Epoch: 9| Step: 12
Training loss: 1.8219358921051025
Validation loss: 1.8308113187337094
Epoch: 9| Step: 13
Training loss: 1.714292049407959
Validation loss: 1.8285373432173146
Epoch: 9| Step: 14
Training loss: 2.2681896686553955
Validation loss: 1.8246349996800044
Epoch: 9| Step: 15
Training loss: 1.9934759140014648
Validation loss: 1.8127584371635381
Epoch: 9| Step: 16
Training loss: 1.5640590190887451
Validation loss: 1.8345598591317376
Epoch: 9| Step: 17
Training loss: 1.9496272802352905
Validation loss: 1.813948660445728
Epoch: 9| Step: 18
Training loss: 2.4684102535247803
Validation loss: 1.8155019300447093
Epoch: 9| Step: 19
Training loss: 1.9598865509033203
Validation loss: 1.7906938302431175
Epoch: 62| Step: 0
Training loss: 1.9605295658111572
Validation loss: 1.8061394459909672
Epoch: 9| Step: 1
Training loss: 1.5493412017822266
Validation loss: 1.7885402149433711
Epoch: 9| Step: 2
Training loss: 2.2872374057769775
Validation loss: 1.798046107772443
Epoch: 9| Step: 3
Training loss: 1.7779450416564941
Validation loss: 1.7989368618821069
Epoch: 9| Step: 4
Training loss: 2.8829050064086914
Validation loss: 1.7998834067969014
Epoch: 9| Step: 5
Training loss: 1.7735786437988281
Validation loss: 1.802940164538596
Epoch: 9| Step: 6
Training loss: 2.1897637844085693
Validation loss: 1.8141306167026219
Epoch: 9| Step: 7
Training loss: 1.4096447229385376
Validation loss: 1.7925397011873534
Epoch: 9| Step: 8
Training loss: 1.9032964706420898
Validation loss: 1.8027415061168532
Epoch: 9| Step: 9
Training loss: 2.3710246086120605
Validation loss: 1.794300262018931
Epoch: 9| Step: 10
Training loss: 1.9413869380950928
Validation loss: 1.8018142851136572
Epoch: 9| Step: 11
Training loss: 1.9609888792037964
Validation loss: 1.8137407131332288
Epoch: 9| Step: 12
Training loss: 2.661201238632202
Validation loss: 1.7892233236230535
Epoch: 9| Step: 13
Training loss: 2.198336124420166
Validation loss: 1.8148795932316952
Epoch: 9| Step: 14
Training loss: 1.615250587463379
Validation loss: 1.79252939258548
Epoch: 9| Step: 15
Training loss: 1.7518054246902466
Validation loss: 1.8062473355437354
Epoch: 9| Step: 16
Training loss: 1.5781145095825195
Validation loss: 1.7917467175627784
Epoch: 9| Step: 17
Training loss: 1.6003812551498413
Validation loss: 1.7785646074967418
Epoch: 9| Step: 18
Training loss: 2.1816322803497314
Validation loss: 1.78638721455773
Epoch: 9| Step: 19
Training loss: 1.9662046432495117
Validation loss: 1.8055209384547721
Epoch: 63| Step: 0
Training loss: 1.912583589553833
Validation loss: 1.7803420197191855
Epoch: 9| Step: 1
Training loss: 1.793525218963623
Validation loss: 1.7695098437851282
Epoch: 9| Step: 2
Training loss: 1.5131120681762695
Validation loss: 1.8071977354639726
Epoch: 9| Step: 3
Training loss: 1.753267526626587
Validation loss: 1.7788234485996712
Epoch: 9| Step: 4
Training loss: 2.8684816360473633
Validation loss: 1.810621086642039
Epoch: 9| Step: 5
Training loss: 2.407836675643921
Validation loss: 1.820255521390078
Epoch: 9| Step: 6
Training loss: 2.265453577041626
Validation loss: 1.795905310472996
Epoch: 9| Step: 7
Training loss: 1.770588755607605
Validation loss: 1.79854088206943
Epoch: 9| Step: 8
Training loss: 1.3541557788848877
Validation loss: 1.795066269181615
Epoch: 9| Step: 9
Training loss: 1.6535567045211792
Validation loss: 1.810177696694573
Epoch: 9| Step: 10
Training loss: 2.1329541206359863
Validation loss: 1.7862735823761644
Epoch: 9| Step: 11
Training loss: 2.2177810668945312
Validation loss: 1.7971985880419505
Epoch: 9| Step: 12
Training loss: 2.3284664154052734
Validation loss: 1.8005769578672999
Epoch: 9| Step: 13
Training loss: 2.2954230308532715
Validation loss: 1.7928353479440264
Epoch: 9| Step: 14
Training loss: 1.704948902130127
Validation loss: 1.784788967036515
Epoch: 9| Step: 15
Training loss: 1.6025314331054688
Validation loss: 1.7915985009653106
Epoch: 9| Step: 16
Training loss: 2.456744909286499
Validation loss: 1.7938858159154438
Epoch: 9| Step: 17
Training loss: 1.4086960554122925
Validation loss: 1.8095481507212139
Epoch: 9| Step: 18
Training loss: 1.8778018951416016
Validation loss: 1.8060840719895397
Epoch: 9| Step: 19
Training loss: 2.263538122177124
Validation loss: 1.8014606666221893
Epoch: 64| Step: 0
Training loss: 1.9648168087005615
Validation loss: 1.7920282221526551
Epoch: 9| Step: 1
Training loss: 1.8679322004318237
Validation loss: 1.7826760672836852
Epoch: 9| Step: 2
Training loss: 2.0226399898529053
Validation loss: 1.7999317783245938
Epoch: 9| Step: 3
Training loss: 1.8598887920379639
Validation loss: 1.7852320345185644
Epoch: 9| Step: 4
Training loss: 2.7013540267944336
Validation loss: 1.8064353620405678
Epoch: 9| Step: 5
Training loss: 1.1196357011795044
Validation loss: 1.7945377132017835
Epoch: 9| Step: 6
Training loss: 1.4923145771026611
Validation loss: 1.7994375794911557
Epoch: 9| Step: 7
Training loss: 1.1315534114837646
Validation loss: 1.794145868836547
Epoch: 9| Step: 8
Training loss: 2.3165111541748047
Validation loss: 1.812285647975455
Epoch: 9| Step: 9
Training loss: 2.9287028312683105
Validation loss: 1.8203757152282933
Epoch: 9| Step: 10
Training loss: 2.164850950241089
Validation loss: 1.805686451548295
Epoch: 9| Step: 11
Training loss: 1.6156995296478271
Validation loss: 1.8211510867523633
Epoch: 9| Step: 12
Training loss: 1.246899127960205
Validation loss: 1.8206696261604913
Epoch: 9| Step: 13
Training loss: 2.4972646236419678
Validation loss: 1.8433438753910203
Epoch: 9| Step: 14
Training loss: 2.2226901054382324
Validation loss: 1.835449065235879
Epoch: 9| Step: 15
Training loss: 2.0971860885620117
Validation loss: 1.8256666754647124
Epoch: 9| Step: 16
Training loss: 2.3103182315826416
Validation loss: 1.8319904564095915
Epoch: 9| Step: 17
Training loss: 2.150021553039551
Validation loss: 1.8395041544660389
Epoch: 9| Step: 18
Training loss: 1.8232777118682861
Validation loss: 1.814844323576783
Epoch: 9| Step: 19
Training loss: 2.201038122177124
Validation loss: 1.8302908921413283
Epoch: 65| Step: 0
Training loss: 1.553812861442566
Validation loss: 1.827394682726414
Epoch: 9| Step: 1
Training loss: 2.4365172386169434
Validation loss: 1.8139030118640378
Epoch: 9| Step: 2
Training loss: 1.774540901184082
Validation loss: 1.825563778122552
Epoch: 9| Step: 3
Training loss: 2.644090414047241
Validation loss: 1.811702896365159
Epoch: 9| Step: 4
Training loss: 1.7512097358703613
Validation loss: 1.8042929841460085
Epoch: 9| Step: 5
Training loss: 2.2644009590148926
Validation loss: 1.8010149456614213
Epoch: 9| Step: 6
Training loss: 2.1147677898406982
Validation loss: 1.7970562504349852
Epoch: 9| Step: 7
Training loss: 2.2077748775482178
Validation loss: 1.7859718096342019
Epoch: 9| Step: 8
Training loss: 1.753153681755066
Validation loss: 1.7826580040746456
Epoch: 9| Step: 9
Training loss: 2.0062952041625977
Validation loss: 1.7834396568133677
Epoch: 9| Step: 10
Training loss: 1.8241169452667236
Validation loss: 1.7860285095173678
Epoch: 9| Step: 11
Training loss: 1.9115718603134155
Validation loss: 1.792424315171276
Epoch: 9| Step: 12
Training loss: 1.7928260564804077
Validation loss: 1.7722663913699364
Epoch: 9| Step: 13
Training loss: 1.5214248895645142
Validation loss: 1.7718734235214673
Epoch: 9| Step: 14
Training loss: 1.7634607553482056
Validation loss: 1.785526358823982
Epoch: 9| Step: 15
Training loss: 2.369576930999756
Validation loss: 1.7652804285502262
Epoch: 9| Step: 16
Training loss: 1.5276954174041748
Validation loss: 1.7600971374580328
Epoch: 9| Step: 17
Training loss: 2.0822346210479736
Validation loss: 1.776395121924311
Epoch: 9| Step: 18
Training loss: 1.8688503503799438
Validation loss: 1.7671071308122264
Epoch: 9| Step: 19
Training loss: 2.377638816833496
Validation loss: 1.7694394811451863
Epoch: 66| Step: 0
Training loss: 1.1343939304351807
Validation loss: 1.78108151953855
Epoch: 9| Step: 1
Training loss: 2.3498244285583496
Validation loss: 1.7774024121195293
Epoch: 9| Step: 2
Training loss: 2.075080394744873
Validation loss: 1.7750839938362726
Epoch: 9| Step: 3
Training loss: 1.566712498664856
Validation loss: 1.791032658206473
Epoch: 9| Step: 4
Training loss: 2.292863130569458
Validation loss: 1.7903189479018287
Epoch: 9| Step: 5
Training loss: 2.1998696327209473
Validation loss: 1.7856330923039279
Epoch: 9| Step: 6
Training loss: 2.168978214263916
Validation loss: 1.8171083232481702
Epoch: 9| Step: 7
Training loss: 1.7293081283569336
Validation loss: 1.8016955277902618
Epoch: 9| Step: 8
Training loss: 3.051478385925293
Validation loss: 1.8018886142497441
Epoch: 9| Step: 9
Training loss: 2.232666492462158
Validation loss: 1.8103958925754904
Epoch: 9| Step: 10
Training loss: 1.3770617246627808
Validation loss: 1.8089433471075922
Epoch: 9| Step: 11
Training loss: 2.371903896331787
Validation loss: 1.7941721737813607
Epoch: 9| Step: 12
Training loss: 1.2913862466812134
Validation loss: 1.8049303824953038
Epoch: 9| Step: 13
Training loss: 2.08803391456604
Validation loss: 1.8004844806177154
Epoch: 9| Step: 14
Training loss: 2.229529619216919
Validation loss: 1.804326721232572
Epoch: 9| Step: 15
Training loss: 2.0478267669677734
Validation loss: 1.8162789259025518
Epoch: 9| Step: 16
Training loss: 1.4476287364959717
Validation loss: 1.7975223201641934
Epoch: 9| Step: 17
Training loss: 1.673597812652588
Validation loss: 1.8099901847702136
Epoch: 9| Step: 18
Training loss: 1.9003159999847412
Validation loss: 1.798153252910367
Epoch: 9| Step: 19
Training loss: 2.0810494422912598
Validation loss: 1.8042313975395916
Epoch: 67| Step: 0
Training loss: 2.041567802429199
Validation loss: 1.7982490062713623
Epoch: 9| Step: 1
Training loss: 1.6899675130844116
Validation loss: 1.7986390599243933
Epoch: 9| Step: 2
Training loss: 1.5901920795440674
Validation loss: 1.7875471586803737
Epoch: 9| Step: 3
Training loss: 2.204397201538086
Validation loss: 1.8111633439715817
Epoch: 9| Step: 4
Training loss: 1.9700772762298584
Validation loss: 1.7907685015698989
Epoch: 9| Step: 5
Training loss: 1.8117331266403198
Validation loss: 1.8156883202010778
Epoch: 9| Step: 6
Training loss: 2.0597431659698486
Validation loss: 1.7832471826951282
Epoch: 9| Step: 7
Training loss: 2.2474052906036377
Validation loss: 1.8066914416045594
Epoch: 9| Step: 8
Training loss: 1.6405255794525146
Validation loss: 1.8039196069292027
Epoch: 9| Step: 9
Training loss: 2.904886484146118
Validation loss: 1.8068905974463594
Epoch: 9| Step: 10
Training loss: 1.4825047254562378
Validation loss: 1.8070803863539113
Epoch: 9| Step: 11
Training loss: 2.0636069774627686
Validation loss: 1.8199789781364606
Epoch: 9| Step: 12
Training loss: 1.2893424034118652
Validation loss: 1.808578979197166
Epoch: 9| Step: 13
Training loss: 2.8049123287200928
Validation loss: 1.7963471978688412
Epoch: 9| Step: 14
Training loss: 2.309753656387329
Validation loss: 1.8169545595594447
Epoch: 9| Step: 15
Training loss: 1.9648962020874023
Validation loss: 1.805648951221713
Epoch: 9| Step: 16
Training loss: 1.9865506887435913
Validation loss: 1.8200864268721437
Epoch: 9| Step: 17
Training loss: 1.6017482280731201
Validation loss: 1.7942517541295333
Epoch: 9| Step: 18
Training loss: 1.955506443977356
Validation loss: 1.799231253081946
Epoch: 9| Step: 19
Training loss: 1.9510912895202637
Validation loss: 1.7943586831470189
Epoch: 68| Step: 0
Training loss: 1.2547237873077393
Validation loss: 1.8042045797375466
Epoch: 9| Step: 1
Training loss: 1.769287109375
Validation loss: 1.7816948804923955
Epoch: 9| Step: 2
Training loss: 2.5391907691955566
Validation loss: 1.8036698840504928
Epoch: 9| Step: 3
Training loss: 2.613621234893799
Validation loss: 1.7932282060170346
Epoch: 9| Step: 4
Training loss: 2.199251890182495
Validation loss: 1.8058968550867314
Epoch: 9| Step: 5
Training loss: 1.8286986351013184
Validation loss: 1.7896282038242697
Epoch: 9| Step: 6
Training loss: 2.8266408443450928
Validation loss: 1.8069634368951373
Epoch: 9| Step: 7
Training loss: 1.7846839427947998
Validation loss: 1.80096345239406
Epoch: 9| Step: 8
Training loss: 2.0550122261047363
Validation loss: 1.8044397419305156
Epoch: 9| Step: 9
Training loss: 1.9405548572540283
Validation loss: 1.7872817550631737
Epoch: 9| Step: 10
Training loss: 1.6932475566864014
Validation loss: 1.8020631769578235
Epoch: 9| Step: 11
Training loss: 1.9139306545257568
Validation loss: 1.7896356170983623
Epoch: 9| Step: 12
Training loss: 1.6272814273834229
Validation loss: 1.8032394561836187
Epoch: 9| Step: 13
Training loss: 1.7041387557983398
Validation loss: 1.801546816345599
Epoch: 9| Step: 14
Training loss: 1.695439338684082
Validation loss: 1.817088610834355
Epoch: 9| Step: 15
Training loss: 1.8230479955673218
Validation loss: 1.7934881423017104
Epoch: 9| Step: 16
Training loss: 2.2466559410095215
Validation loss: 1.7975346707611632
Epoch: 9| Step: 17
Training loss: 2.2215211391448975
Validation loss: 1.8111722152010143
Epoch: 9| Step: 18
Training loss: 2.015838146209717
Validation loss: 1.7995351467201177
Epoch: 9| Step: 19
Training loss: 1.887378454208374
Validation loss: 1.8212277511898562
Epoch: 69| Step: 0
Training loss: 1.4703869819641113
Validation loss: 1.7984700245822933
Epoch: 9| Step: 1
Training loss: 2.497671127319336
Validation loss: 1.8174145058762254
Epoch: 9| Step: 2
Training loss: 2.028841972351074
Validation loss: 1.8049068450927734
Epoch: 9| Step: 3
Training loss: 1.8717482089996338
Validation loss: 1.7979097160504018
Epoch: 9| Step: 4
Training loss: 1.4266843795776367
Validation loss: 1.793352662230567
Epoch: 9| Step: 5
Training loss: 2.023742198944092
Validation loss: 1.7876943838682107
Epoch: 9| Step: 6
Training loss: 1.5570242404937744
Validation loss: 1.8059071842715038
Epoch: 9| Step: 7
Training loss: 2.6530091762542725
Validation loss: 1.7899844989502172
Epoch: 9| Step: 8
Training loss: 2.6363792419433594
Validation loss: 1.8096661078844138
Epoch: 9| Step: 9
Training loss: 1.8667945861816406
Validation loss: 1.808673267741855
Epoch: 9| Step: 10
Training loss: 2.072521209716797
Validation loss: 1.788603052818518
Epoch: 9| Step: 11
Training loss: 2.2636194229125977
Validation loss: 1.815597042762976
Epoch: 9| Step: 12
Training loss: 2.168515682220459
Validation loss: 1.804574812916543
Epoch: 9| Step: 13
Training loss: 2.0706138610839844
Validation loss: 1.7832613454448234
Epoch: 9| Step: 14
Training loss: 1.8103662729263306
Validation loss: 1.8138749933928895
Epoch: 9| Step: 15
Training loss: 2.145897388458252
Validation loss: 1.8199813220140746
Epoch: 9| Step: 16
Training loss: 1.7035475969314575
Validation loss: 1.8001371081784474
Epoch: 9| Step: 17
Training loss: 1.8172895908355713
Validation loss: 1.7924729096803733
Epoch: 9| Step: 18
Training loss: 1.571975827217102
Validation loss: 1.82511596370944
Epoch: 9| Step: 19
Training loss: 2.054800271987915
Validation loss: 1.8084126033371302
Epoch: 70| Step: 0
Training loss: 2.3665771484375
Validation loss: 1.8277010754715624
Epoch: 9| Step: 1
Training loss: 2.092191219329834
Validation loss: 1.8039007023941698
Epoch: 9| Step: 2
Training loss: 1.805481195449829
Validation loss: 1.8243592325732005
Epoch: 9| Step: 3
Training loss: 2.1626393795013428
Validation loss: 1.811323590415845
Epoch: 9| Step: 4
Training loss: 1.8134095668792725
Validation loss: 1.8163541941334018
Epoch: 9| Step: 5
Training loss: 2.028233051300049
Validation loss: 1.8212200943514598
Epoch: 9| Step: 6
Training loss: 2.034801959991455
Validation loss: 1.8158367237598776
Epoch: 9| Step: 7
Training loss: 1.853663444519043
Validation loss: 1.8359505787170192
Epoch: 9| Step: 8
Training loss: 1.4688043594360352
Validation loss: 1.8470886542642717
Epoch: 9| Step: 9
Training loss: 2.488992214202881
Validation loss: 1.8478734441798368
Epoch: 9| Step: 10
Training loss: 2.3514227867126465
Validation loss: 1.840851149970679
Epoch: 9| Step: 11
Training loss: 1.4788618087768555
Validation loss: 1.837912055228254
Epoch: 9| Step: 12
Training loss: 1.6807796955108643
Validation loss: 1.8390270720282904
Epoch: 9| Step: 13
Training loss: 1.6949304342269897
Validation loss: 1.8435404635161805
Epoch: 9| Step: 14
Training loss: 1.7216122150421143
Validation loss: 1.8407140652910412
Epoch: 9| Step: 15
Training loss: 2.36210298538208
Validation loss: 1.8192062232134154
Epoch: 9| Step: 16
Training loss: 1.8711538314819336
Validation loss: 1.826847681896292
Epoch: 9| Step: 17
Training loss: 2.4603612422943115
Validation loss: 1.8307291174964082
Epoch: 9| Step: 18
Training loss: 1.8607110977172852
Validation loss: 1.8239947188672403
Epoch: 9| Step: 19
Training loss: 1.9587371349334717
Validation loss: 1.805851904608363
Epoch: 71| Step: 0
Training loss: 1.9677797555923462
Validation loss: 1.8067714567664717
Epoch: 9| Step: 1
Training loss: 2.2735769748687744
Validation loss: 1.8097131904080617
Epoch: 9| Step: 2
Training loss: 1.6934983730316162
Validation loss: 1.79253682472723
Epoch: 9| Step: 3
Training loss: 1.9438713788986206
Validation loss: 1.8226618775360877
Epoch: 9| Step: 4
Training loss: 1.6834971904754639
Validation loss: 1.8133553112153526
Epoch: 9| Step: 5
Training loss: 1.5311942100524902
Validation loss: 1.8013996923570152
Epoch: 9| Step: 6
Training loss: 2.0452239513397217
Validation loss: 1.8197819946481169
Epoch: 9| Step: 7
Training loss: 1.5240179300308228
Validation loss: 1.8251905904399406
Epoch: 9| Step: 8
Training loss: 2.1995959281921387
Validation loss: 1.8309975159254006
Epoch: 9| Step: 9
Training loss: 1.627561092376709
Validation loss: 1.8355810359227571
Epoch: 9| Step: 10
Training loss: 2.337677001953125
Validation loss: 1.8277407344296681
Epoch: 9| Step: 11
Training loss: 1.6690764427185059
Validation loss: 1.8173831109520342
Epoch: 9| Step: 12
Training loss: 2.345211982727051
Validation loss: 1.8293831374147813
Epoch: 9| Step: 13
Training loss: 2.0156967639923096
Validation loss: 1.8294029141501558
Epoch: 9| Step: 14
Training loss: 1.894932508468628
Validation loss: 1.8354528962279395
Epoch: 9| Step: 15
Training loss: 1.7038099765777588
Validation loss: 1.8319309795503136
Epoch: 9| Step: 16
Training loss: 2.240260362625122
Validation loss: 1.8419126452301904
Epoch: 9| Step: 17
Training loss: 2.7642245292663574
Validation loss: 1.7991018595455361
Epoch: 9| Step: 18
Training loss: 1.3985252380371094
Validation loss: 1.7987696189674542
Epoch: 9| Step: 19
Training loss: 2.299388885498047
Validation loss: 1.79591927596991
Epoch: 72| Step: 0
Training loss: 2.1745858192443848
Validation loss: 1.8001067166705784
Epoch: 9| Step: 1
Training loss: 1.840653896331787
Validation loss: 1.7912224942831685
Epoch: 9| Step: 2
Training loss: 2.253300666809082
Validation loss: 1.786204866368136
Epoch: 9| Step: 3
Training loss: 1.9860934019088745
Validation loss: 1.7776729760410117
Epoch: 9| Step: 4
Training loss: 2.119894027709961
Validation loss: 1.7940400032688388
Epoch: 9| Step: 5
Training loss: 2.1734910011291504
Validation loss: 1.7860221039477011
Epoch: 9| Step: 6
Training loss: 2.6912894248962402
Validation loss: 1.7532661192708736
Epoch: 9| Step: 7
Training loss: 2.1330506801605225
Validation loss: 1.7743180938761869
Epoch: 9| Step: 8
Training loss: 1.6576725244522095
Validation loss: 1.7618999026662154
Epoch: 9| Step: 9
Training loss: 2.226571559906006
Validation loss: 1.7634827155861066
Epoch: 9| Step: 10
Training loss: 1.6753495931625366
Validation loss: 1.7718966607567217
Epoch: 9| Step: 11
Training loss: 2.0664122104644775
Validation loss: 1.7472338685028845
Epoch: 9| Step: 12
Training loss: 2.705763339996338
Validation loss: 1.766396678608956
Epoch: 9| Step: 13
Training loss: 1.784793734550476
Validation loss: 1.7589410732118347
Epoch: 9| Step: 14
Training loss: 2.2133724689483643
Validation loss: 1.7699181004393874
Epoch: 9| Step: 15
Training loss: 1.576629638671875
Validation loss: 1.731510435934547
Epoch: 9| Step: 16
Training loss: 1.1406731605529785
Validation loss: 1.7376983903294845
Epoch: 9| Step: 17
Training loss: 1.6676831245422363
Validation loss: 1.7495874432351093
Epoch: 9| Step: 18
Training loss: 1.780737042427063
Validation loss: 1.7616251509824246
Epoch: 9| Step: 19
Training loss: 1.611626148223877
Validation loss: 1.7648454552931752
Epoch: 73| Step: 0
Training loss: 2.4386885166168213
Validation loss: 1.7524976558822523
Epoch: 9| Step: 1
Training loss: 2.1869523525238037
Validation loss: 1.7699340667656
Epoch: 9| Step: 2
Training loss: 1.6881248950958252
Validation loss: 1.7625325283558249
Epoch: 9| Step: 3
Training loss: 1.8209922313690186
Validation loss: 1.7789901597894353
Epoch: 9| Step: 4
Training loss: 2.526181221008301
Validation loss: 1.77081982180369
Epoch: 9| Step: 5
Training loss: 2.018362045288086
Validation loss: 1.7963448557064687
Epoch: 9| Step: 6
Training loss: 2.100633144378662
Validation loss: 1.792171095772613
Epoch: 9| Step: 7
Training loss: 1.4838122129440308
Validation loss: 1.7854818217188335
Epoch: 9| Step: 8
Training loss: 2.2558679580688477
Validation loss: 1.8090809232039418
Epoch: 9| Step: 9
Training loss: 1.4550366401672363
Validation loss: 1.7968526040907387
Epoch: 9| Step: 10
Training loss: 1.9943370819091797
Validation loss: 1.7951075499006313
Epoch: 9| Step: 11
Training loss: 2.1151630878448486
Validation loss: 1.7863308577228794
Epoch: 9| Step: 12
Training loss: 1.5920734405517578
Validation loss: 1.80433657786829
Epoch: 9| Step: 13
Training loss: 1.4259992837905884
Validation loss: 1.804785294498471
Epoch: 9| Step: 14
Training loss: 2.5404553413391113
Validation loss: 1.7935321288143131
Epoch: 9| Step: 15
Training loss: 1.9201289415359497
Validation loss: 1.801982729555034
Epoch: 9| Step: 16
Training loss: 2.2226767539978027
Validation loss: 1.8171317045637172
Epoch: 9| Step: 17
Training loss: 1.9430513381958008
Validation loss: 1.8227511395653375
Epoch: 9| Step: 18
Training loss: 1.7461204528808594
Validation loss: 1.820192044587444
Epoch: 9| Step: 19
Training loss: 2.0341763496398926
Validation loss: 1.8197424789126828
Epoch: 74| Step: 0
Training loss: 1.3444173336029053
Validation loss: 1.8097951189219523
Epoch: 9| Step: 1
Training loss: 2.065730333328247
Validation loss: 1.8197041098162425
Epoch: 9| Step: 2
Training loss: 2.0498335361480713
Validation loss: 1.7937560021448478
Epoch: 9| Step: 3
Training loss: 1.6259593963623047
Validation loss: 1.7906266403712814
Epoch: 9| Step: 4
Training loss: 1.5526880025863647
Validation loss: 1.8012237866147816
Epoch: 9| Step: 5
Training loss: 2.063211441040039
Validation loss: 1.800039221914552
Epoch: 9| Step: 6
Training loss: 1.9632718563079834
Validation loss: 1.8154982465634244
Epoch: 9| Step: 7
Training loss: 1.935569167137146
Validation loss: 1.7775923605445478
Epoch: 9| Step: 8
Training loss: 1.6952029466629028
Validation loss: 1.8019993725440484
Epoch: 9| Step: 9
Training loss: 1.7712998390197754
Validation loss: 1.7873339730201008
Epoch: 9| Step: 10
Training loss: 1.9490504264831543
Validation loss: 1.791356326007157
Epoch: 9| Step: 11
Training loss: 2.7032055854797363
Validation loss: 1.814226581038331
Epoch: 9| Step: 12
Training loss: 1.6736533641815186
Validation loss: 1.796400210840239
Epoch: 9| Step: 13
Training loss: 2.478942394256592
Validation loss: 1.7992312522243252
Epoch: 9| Step: 14
Training loss: 2.2204079627990723
Validation loss: 1.7782296396845536
Epoch: 9| Step: 15
Training loss: 2.571585178375244
Validation loss: 1.7900745637125248
Epoch: 9| Step: 16
Training loss: 2.18530535697937
Validation loss: 1.784161301825544
Epoch: 9| Step: 17
Training loss: 2.575005292892456
Validation loss: 1.8099248889538881
Epoch: 9| Step: 18
Training loss: 1.640660047531128
Validation loss: 1.8059037555035928
Epoch: 9| Step: 19
Training loss: 1.1905388832092285
Validation loss: 1.768763962409479
Epoch: 75| Step: 0
Training loss: 2.2775707244873047
Validation loss: 1.7972385463097114
Epoch: 9| Step: 1
Training loss: 1.8209689855575562
Validation loss: 1.7991788327265128
Epoch: 9| Step: 2
Training loss: 2.1019468307495117
Validation loss: 1.7957681992071137
Epoch: 9| Step: 3
Training loss: 2.0799689292907715
Validation loss: 1.8043234614159565
Epoch: 9| Step: 4
Training loss: 2.0246288776397705
Validation loss: 1.7816935846273847
Epoch: 9| Step: 5
Training loss: 2.1377875804901123
Validation loss: 1.8067328072280335
Epoch: 9| Step: 6
Training loss: 1.9415110349655151
Validation loss: 1.7933836575034712
Epoch: 9| Step: 7
Training loss: 1.6833171844482422
Validation loss: 1.7853279945661695
Epoch: 9| Step: 8
Training loss: 2.211663246154785
Validation loss: 1.7810245229185915
Epoch: 9| Step: 9
Training loss: 1.579859733581543
Validation loss: 1.8006713613331746
Epoch: 9| Step: 10
Training loss: 1.8124020099639893
Validation loss: 1.779642065651983
Epoch: 9| Step: 11
Training loss: 2.2547760009765625
Validation loss: 1.7834668022265536
Epoch: 9| Step: 12
Training loss: 1.5117493867874146
Validation loss: 1.776790555432546
Epoch: 9| Step: 13
Training loss: 2.634068250656128
Validation loss: 1.7792240621374666
Epoch: 9| Step: 14
Training loss: 1.654820203781128
Validation loss: 1.7890855374096108
Epoch: 9| Step: 15
Training loss: 1.876799464225769
Validation loss: 1.773561921908701
Epoch: 9| Step: 16
Training loss: 1.7617783546447754
Validation loss: 1.7883670141371033
Epoch: 9| Step: 17
Training loss: 2.115229845046997
Validation loss: 1.7923203886841699
Epoch: 9| Step: 18
Training loss: 2.021170139312744
Validation loss: 1.7817127678891738
Epoch: 9| Step: 19
Training loss: 1.5116610527038574
Validation loss: 1.7835857079183455
Epoch: 76| Step: 0
Training loss: 2.1372921466827393
Validation loss: 1.7961759592989366
Epoch: 9| Step: 1
Training loss: 1.4553759098052979
Validation loss: 1.7809378423279139
Epoch: 9| Step: 2
Training loss: 2.638648748397827
Validation loss: 1.7961095760194519
Epoch: 9| Step: 3
Training loss: 1.5521997213363647
Validation loss: 1.786137597166377
Epoch: 9| Step: 4
Training loss: 2.1102187633514404
Validation loss: 1.7913063447252453
Epoch: 9| Step: 5
Training loss: 2.4412150382995605
Validation loss: 1.7771497510319991
Epoch: 9| Step: 6
Training loss: 2.5370588302612305
Validation loss: 1.7831792334000842
Epoch: 9| Step: 7
Training loss: 1.809713363647461
Validation loss: 1.7805863833255906
Epoch: 9| Step: 8
Training loss: 2.4913597106933594
Validation loss: 1.7742062944302457
Epoch: 9| Step: 9
Training loss: 1.6952638626098633
Validation loss: 1.7630644959511517
Epoch: 9| Step: 10
Training loss: 1.9113167524337769
Validation loss: 1.7800162044360484
Epoch: 9| Step: 11
Training loss: 1.9084293842315674
Validation loss: 1.7614527554820767
Epoch: 9| Step: 12
Training loss: 1.7086447477340698
Validation loss: 1.766909976657346
Epoch: 9| Step: 13
Training loss: 0.9029324054718018
Validation loss: 1.7498747419110305
Epoch: 9| Step: 14
Training loss: 1.2326464653015137
Validation loss: 1.778699558415859
Epoch: 9| Step: 15
Training loss: 1.8324599266052246
Validation loss: 1.7619789632961904
Epoch: 9| Step: 16
Training loss: 2.7560524940490723
Validation loss: 1.781066182705996
Epoch: 9| Step: 17
Training loss: 2.518322467803955
Validation loss: 1.7783369460551859
Epoch: 9| Step: 18
Training loss: 1.616729497909546
Validation loss: 1.803214863907519
Epoch: 9| Step: 19
Training loss: 1.9762723445892334
Validation loss: 1.8062958623007905
Epoch: 77| Step: 0
Training loss: 1.5336003303527832
Validation loss: 1.7949130483668485
Epoch: 9| Step: 1
Training loss: 1.1930248737335205
Validation loss: 1.7971684829794246
Epoch: 9| Step: 2
Training loss: 2.0752625465393066
Validation loss: 1.8064053993430926
Epoch: 9| Step: 3
Training loss: 1.432638168334961
Validation loss: 1.8147921707990358
Epoch: 9| Step: 4
Training loss: 2.1606743335723877
Validation loss: 1.8063683904332222
Epoch: 9| Step: 5
Training loss: 1.9424548149108887
Validation loss: 1.7958200235160993
Epoch: 9| Step: 6
Training loss: 1.9976322650909424
Validation loss: 1.8076368759004333
Epoch: 9| Step: 7
Training loss: 1.8518822193145752
Validation loss: 1.7949300755699762
Epoch: 9| Step: 8
Training loss: 1.6498547792434692
Validation loss: 1.791703956590282
Epoch: 9| Step: 9
Training loss: 2.855597972869873
Validation loss: 1.8054789279004653
Epoch: 9| Step: 10
Training loss: 1.7027578353881836
Validation loss: 1.807155658872865
Epoch: 9| Step: 11
Training loss: 1.574181318283081
Validation loss: 1.810826334164297
Epoch: 9| Step: 12
Training loss: 1.8095499277114868
Validation loss: 1.7962940836981904
Epoch: 9| Step: 13
Training loss: 2.5588722229003906
Validation loss: 1.8014869441231378
Epoch: 9| Step: 14
Training loss: 2.674071788787842
Validation loss: 1.827520340466671
Epoch: 9| Step: 15
Training loss: 1.8184007406234741
Validation loss: 1.8060577893428664
Epoch: 9| Step: 16
Training loss: 2.263339042663574
Validation loss: 1.816431878282012
Epoch: 9| Step: 17
Training loss: 1.6232497692108154
Validation loss: 1.795275630710794
Epoch: 9| Step: 18
Training loss: 1.5599780082702637
Validation loss: 1.8000805532331947
Epoch: 9| Step: 19
Training loss: 2.793757438659668
Validation loss: 1.8195679084860163
Epoch: 78| Step: 0
Training loss: 1.582101821899414
Validation loss: 1.7968896584545109
Epoch: 9| Step: 1
Training loss: 1.8708131313323975
Validation loss: 1.802794835550322
Epoch: 9| Step: 2
Training loss: 1.732338309288025
Validation loss: 1.8029678699781568
Epoch: 9| Step: 3
Training loss: 1.8440443277359009
Validation loss: 1.8179152552172435
Epoch: 9| Step: 4
Training loss: 1.929900050163269
Validation loss: 1.8171726731087665
Epoch: 9| Step: 5
Training loss: 1.6424373388290405
Validation loss: 1.8124052517705684
Epoch: 9| Step: 6
Training loss: 2.262604236602783
Validation loss: 1.8234155684066333
Epoch: 9| Step: 7
Training loss: 1.449819803237915
Validation loss: 1.7931655353779414
Epoch: 9| Step: 8
Training loss: 1.9941301345825195
Validation loss: 1.8244807437169466
Epoch: 9| Step: 9
Training loss: 1.593536376953125
Validation loss: 1.7866085621950438
Epoch: 9| Step: 10
Training loss: 1.5850772857666016
Validation loss: 1.7957946456593574
Epoch: 9| Step: 11
Training loss: 2.7600462436676025
Validation loss: 1.8095433034485193
Epoch: 9| Step: 12
Training loss: 2.635117530822754
Validation loss: 1.8088631226862077
Epoch: 9| Step: 13
Training loss: 1.6276748180389404
Validation loss: 1.7991574016406382
Epoch: 9| Step: 14
Training loss: 2.249464988708496
Validation loss: 1.7961955893811563
Epoch: 9| Step: 15
Training loss: 1.6901803016662598
Validation loss: 1.8009435701713288
Epoch: 9| Step: 16
Training loss: 2.9417295455932617
Validation loss: 1.778366346153424
Epoch: 9| Step: 17
Training loss: 1.8189997673034668
Validation loss: 1.7846405403219538
Epoch: 9| Step: 18
Training loss: 2.367922067642212
Validation loss: 1.8054534462716083
Epoch: 9| Step: 19
Training loss: 1.5955480337142944
Validation loss: 1.7938106986258526
Epoch: 79| Step: 0
Training loss: 2.809077501296997
Validation loss: 1.7798359599902476
Epoch: 9| Step: 1
Training loss: 1.7454078197479248
Validation loss: 1.8071322080900343
Epoch: 9| Step: 2
Training loss: 1.500307321548462
Validation loss: 1.7617632982542188
Epoch: 9| Step: 3
Training loss: 1.754869818687439
Validation loss: 1.7657633959818229
Epoch: 9| Step: 4
Training loss: 2.5054049491882324
Validation loss: 1.7563414436450107
Epoch: 9| Step: 5
Training loss: 2.250941276550293
Validation loss: 1.753285167886199
Epoch: 9| Step: 6
Training loss: 1.8349857330322266
Validation loss: 1.7449024169565104
Epoch: 9| Step: 7
Training loss: 1.725186824798584
Validation loss: 1.741409639660403
Epoch: 9| Step: 8
Training loss: 1.6208765506744385
Validation loss: 1.7293038256734394
Epoch: 9| Step: 9
Training loss: 1.999841570854187
Validation loss: 1.7501150498287283
Epoch: 9| Step: 10
Training loss: 2.412379741668701
Validation loss: 1.751479999624568
Epoch: 9| Step: 11
Training loss: 2.0030908584594727
Validation loss: 1.7468518293161186
Epoch: 9| Step: 12
Training loss: 1.578081488609314
Validation loss: 1.7337718953331598
Epoch: 9| Step: 13
Training loss: 2.4510128498077393
Validation loss: 1.7442596782025674
Epoch: 9| Step: 14
Training loss: 2.1902923583984375
Validation loss: 1.7449870787078527
Epoch: 9| Step: 15
Training loss: 1.8695549964904785
Validation loss: 1.7556464697817247
Epoch: 9| Step: 16
Training loss: 1.9337488412857056
Validation loss: 1.7419598093993371
Epoch: 9| Step: 17
Training loss: 2.027897357940674
Validation loss: 1.743446194010673
Epoch: 9| Step: 18
Training loss: 1.7169122695922852
Validation loss: 1.7590265085371277
Epoch: 9| Step: 19
Training loss: 1.2664307355880737
Validation loss: 1.76716270721216
Epoch: 80| Step: 0
Training loss: 2.1927833557128906
Validation loss: 1.765152307723066
Epoch: 9| Step: 1
Training loss: 1.5639617443084717
Validation loss: 1.764472444280446
Epoch: 9| Step: 2
Training loss: 2.39365553855896
Validation loss: 1.787931807607198
Epoch: 9| Step: 3
Training loss: 2.0239336490631104
Validation loss: 1.7817910566604396
Epoch: 9| Step: 4
Training loss: 1.6606435775756836
Validation loss: 1.7740631069210793
Epoch: 9| Step: 5
Training loss: 2.8575096130371094
Validation loss: 1.7722708201236863
Epoch: 9| Step: 6
Training loss: 2.544070243835449
Validation loss: 1.7796692119227897
Epoch: 9| Step: 7
Training loss: 1.359351396560669
Validation loss: 1.8169393282142474
Epoch: 9| Step: 8
Training loss: 2.4515228271484375
Validation loss: 1.7845174545864406
Epoch: 9| Step: 9
Training loss: 1.9836031198501587
Validation loss: 1.7914564660984835
Epoch: 9| Step: 10
Training loss: 2.1236014366149902
Validation loss: 1.8062503277826651
Epoch: 9| Step: 11
Training loss: 1.6955335140228271
Validation loss: 1.808036556346811
Epoch: 9| Step: 12
Training loss: 1.7013812065124512
Validation loss: 1.8140737264276408
Epoch: 9| Step: 13
Training loss: 2.8660836219787598
Validation loss: 1.818001255714636
Epoch: 9| Step: 14
Training loss: 1.940915822982788
Validation loss: 1.8217912346339054
Epoch: 9| Step: 15
Training loss: 1.751227617263794
Validation loss: 1.806587896758704
Epoch: 9| Step: 16
Training loss: 1.2005865573883057
Validation loss: 1.8131548389256429
Epoch: 9| Step: 17
Training loss: 2.028301477432251
Validation loss: 1.8143799768077384
Epoch: 9| Step: 18
Training loss: 1.3121919631958008
Validation loss: 1.8106038441760934
Epoch: 9| Step: 19
Training loss: 1.5107530355453491
Validation loss: 1.7966899580235103
Epoch: 81| Step: 0
Training loss: 1.8453400135040283
Validation loss: 1.7929586086341802
Epoch: 9| Step: 1
Training loss: 1.6215026378631592
Validation loss: 1.7726789447043438
Epoch: 9| Step: 2
Training loss: 1.7188684940338135
Validation loss: 1.7795315903725384
Epoch: 9| Step: 3
Training loss: 2.2076094150543213
Validation loss: 1.7728430555878782
Epoch: 9| Step: 4
Training loss: 2.7582321166992188
Validation loss: 1.7707486015429599
Epoch: 9| Step: 5
Training loss: 2.314301013946533
Validation loss: 1.76359123120205
Epoch: 9| Step: 6
Training loss: 2.0102248191833496
Validation loss: 1.7786568446125057
Epoch: 9| Step: 7
Training loss: 1.4302223920822144
Validation loss: 1.7619704222507615
Epoch: 9| Step: 8
Training loss: 1.6953318119049072
Validation loss: 1.7570142505837858
Epoch: 9| Step: 9
Training loss: 1.343017816543579
Validation loss: 1.768070474803019
Epoch: 9| Step: 10
Training loss: 1.4335217475891113
Validation loss: 1.77185727795251
Epoch: 9| Step: 11
Training loss: 2.738339900970459
Validation loss: 1.7574647459194814
Epoch: 9| Step: 12
Training loss: 1.5788389444351196
Validation loss: 1.7598956077218912
Epoch: 9| Step: 13
Training loss: 2.3956661224365234
Validation loss: 1.7561541349767782
Epoch: 9| Step: 14
Training loss: 1.5034360885620117
Validation loss: 1.7509990098665087
Epoch: 9| Step: 15
Training loss: 1.8836586475372314
Validation loss: 1.758204196854461
Epoch: 9| Step: 16
Training loss: 1.9808026552200317
Validation loss: 1.7471875149569065
Epoch: 9| Step: 17
Training loss: 1.4295940399169922
Validation loss: 1.7753387132136942
Epoch: 9| Step: 18
Training loss: 2.4340977668762207
Validation loss: 1.7941389607010985
Epoch: 9| Step: 19
Training loss: 2.712313652038574
Validation loss: 1.778215725644887
Epoch: 82| Step: 0
Training loss: 1.8059146404266357
Validation loss: 1.7866887806130827
Epoch: 9| Step: 1
Training loss: 2.3221089839935303
Validation loss: 1.8018294392729834
Epoch: 9| Step: 2
Training loss: 1.9707016944885254
Validation loss: 1.7969195868471544
Epoch: 9| Step: 3
Training loss: 2.056015968322754
Validation loss: 1.778815686273918
Epoch: 9| Step: 4
Training loss: 1.6417548656463623
Validation loss: 1.799894988965645
Epoch: 9| Step: 5
Training loss: 2.266059398651123
Validation loss: 1.809529828510696
Epoch: 9| Step: 6
Training loss: 1.8528971672058105
Validation loss: 1.7909346964719484
Epoch: 9| Step: 7
Training loss: 2.190730571746826
Validation loss: 1.7804365921363556
Epoch: 9| Step: 8
Training loss: 1.6193287372589111
Validation loss: 1.7891024479763113
Epoch: 9| Step: 9
Training loss: 1.8074736595153809
Validation loss: 1.7838746926767364
Epoch: 9| Step: 10
Training loss: 1.7570769786834717
Validation loss: 1.7746624316242958
Epoch: 9| Step: 11
Training loss: 1.5547070503234863
Validation loss: 1.7992994905375748
Epoch: 9| Step: 12
Training loss: 1.328338384628296
Validation loss: 1.7941949813486002
Epoch: 9| Step: 13
Training loss: 2.099557399749756
Validation loss: 1.8052362032073865
Epoch: 9| Step: 14
Training loss: 1.8337500095367432
Validation loss: 1.7796537129999064
Epoch: 9| Step: 15
Training loss: 2.8202104568481445
Validation loss: 1.7800228235532911
Epoch: 9| Step: 16
Training loss: 1.3116803169250488
Validation loss: 1.7993602306722738
Epoch: 9| Step: 17
Training loss: 1.918138027191162
Validation loss: 1.8047615478364685
Epoch: 9| Step: 18
Training loss: 2.426013946533203
Validation loss: 1.7975660322381437
Epoch: 9| Step: 19
Training loss: 2.551570415496826
Validation loss: 1.8029642362388776
Epoch: 83| Step: 0
Training loss: 2.762301206588745
Validation loss: 1.7928920306747766
Epoch: 9| Step: 1
Training loss: 2.1324551105499268
Validation loss: 1.7929298757649155
Epoch: 9| Step: 2
Training loss: 1.3155765533447266
Validation loss: 1.8068388271674836
Epoch: 9| Step: 3
Training loss: 1.974575161933899
Validation loss: 1.7845748259866838
Epoch: 9| Step: 4
Training loss: 1.813981533050537
Validation loss: 1.7962978306434136
Epoch: 9| Step: 5
Training loss: 2.139617919921875
Validation loss: 1.7999567187947334
Epoch: 9| Step: 6
Training loss: 1.6499621868133545
Validation loss: 1.7742865874612932
Epoch: 9| Step: 7
Training loss: 1.46412992477417
Validation loss: 1.7831142463272425
Epoch: 9| Step: 8
Training loss: 2.6800098419189453
Validation loss: 1.7768609763907015
Epoch: 9| Step: 9
Training loss: 1.6848373413085938
Validation loss: 1.7712200717102708
Epoch: 9| Step: 10
Training loss: 2.108832359313965
Validation loss: 1.7729049903883352
Epoch: 9| Step: 11
Training loss: 2.2014052867889404
Validation loss: 1.7731614824679258
Epoch: 9| Step: 12
Training loss: 1.613278865814209
Validation loss: 1.7734500907307906
Epoch: 9| Step: 13
Training loss: 2.0608716011047363
Validation loss: 1.766141276565387
Epoch: 9| Step: 14
Training loss: 2.0060057640075684
Validation loss: 1.762122258865576
Epoch: 9| Step: 15
Training loss: 1.7362992763519287
Validation loss: 1.7650537156372619
Epoch: 9| Step: 16
Training loss: 2.454317092895508
Validation loss: 1.7723257104269892
Epoch: 9| Step: 17
Training loss: 2.0629725456237793
Validation loss: 1.7635633104996715
Epoch: 9| Step: 18
Training loss: 1.3699650764465332
Validation loss: 1.7644644392480096
Epoch: 9| Step: 19
Training loss: 1.759514570236206
Validation loss: 1.7707502481748731
Epoch: 84| Step: 0
Training loss: 1.9449951648712158
Validation loss: 1.807181185955624
Epoch: 9| Step: 1
Training loss: 2.141380786895752
Validation loss: 1.7822955975429617
Epoch: 9| Step: 2
Training loss: 1.5611188411712646
Validation loss: 1.795665720383898
Epoch: 9| Step: 3
Training loss: 2.6569631099700928
Validation loss: 1.8003005158129355
Epoch: 9| Step: 4
Training loss: 2.0029523372650146
Validation loss: 1.793297270219103
Epoch: 9| Step: 5
Training loss: 1.1647528409957886
Validation loss: 1.7791533024191
Epoch: 9| Step: 6
Training loss: 2.374002456665039
Validation loss: 1.7774975025396553
Epoch: 9| Step: 7
Training loss: 2.013535976409912
Validation loss: 1.7834604849918283
Epoch: 9| Step: 8
Training loss: 1.471016526222229
Validation loss: 1.7852696240377084
Epoch: 9| Step: 9
Training loss: 2.1600656509399414
Validation loss: 1.7821414599315726
Epoch: 9| Step: 10
Training loss: 2.180403709411621
Validation loss: 1.7882054966988323
Epoch: 9| Step: 11
Training loss: 1.2142715454101562
Validation loss: 1.7878417454177526
Epoch: 9| Step: 12
Training loss: 2.305906295776367
Validation loss: 1.7723015023650026
Epoch: 9| Step: 13
Training loss: 2.3213930130004883
Validation loss: 1.7650346635914536
Epoch: 9| Step: 14
Training loss: 1.8850200176239014
Validation loss: 1.7862340160411039
Epoch: 9| Step: 15
Training loss: 2.38382625579834
Validation loss: 1.7974159803321894
Epoch: 9| Step: 16
Training loss: 2.0383212566375732
Validation loss: 1.8064402693467174
Epoch: 9| Step: 17
Training loss: 2.0889604091644287
Validation loss: 1.8111810306850955
Epoch: 9| Step: 18
Training loss: 1.5445002317428589
Validation loss: 1.779513064905894
Epoch: 9| Step: 19
Training loss: 1.642834186553955
Validation loss: 1.7889563085363924
Epoch: 85| Step: 0
Training loss: 1.6546037197113037
Validation loss: 1.7699154383844609
Epoch: 9| Step: 1
Training loss: 1.9805896282196045
Validation loss: 1.7987462282180786
Epoch: 9| Step: 2
Training loss: 2.0183098316192627
Validation loss: 1.7862282193821968
Epoch: 9| Step: 3
Training loss: 0.9223178625106812
Validation loss: 1.8017237426565706
Epoch: 9| Step: 4
Training loss: 1.3565751314163208
Validation loss: 1.786598303335176
Epoch: 9| Step: 5
Training loss: 2.084899663925171
Validation loss: 1.8355976471798026
Epoch: 9| Step: 6
Training loss: 1.6862587928771973
Validation loss: 1.8216041060660382
Epoch: 9| Step: 7
Training loss: 2.2866928577423096
Validation loss: 1.7821176661004265
Epoch: 9| Step: 8
Training loss: 1.9926769733428955
Validation loss: 1.8180054760665345
Epoch: 9| Step: 9
Training loss: 2.2077159881591797
Validation loss: 1.8022303186732231
Epoch: 9| Step: 10
Training loss: 2.1799731254577637
Validation loss: 1.784534005810031
Epoch: 9| Step: 11
Training loss: 2.1302380561828613
Validation loss: 1.799276279030944
Epoch: 9| Step: 12
Training loss: 2.4073381423950195
Validation loss: 1.7779594050894538
Epoch: 9| Step: 13
Training loss: 1.9233508110046387
Validation loss: 1.7957447424209376
Epoch: 9| Step: 14
Training loss: 1.8508172035217285
Validation loss: 1.7800567999160548
Epoch: 9| Step: 15
Training loss: 2.072845458984375
Validation loss: 1.79371659103915
Epoch: 9| Step: 16
Training loss: 1.8688820600509644
Validation loss: 1.7811687224202877
Epoch: 9| Step: 17
Training loss: 1.8677425384521484
Validation loss: 1.792738797853319
Epoch: 9| Step: 18
Training loss: 2.512566328048706
Validation loss: 1.8015058177838223
Epoch: 9| Step: 19
Training loss: 1.6694607734680176
Validation loss: 1.7953107605735175
Epoch: 86| Step: 0
Training loss: 1.8712294101715088
Validation loss: 1.7841107253548052
Epoch: 9| Step: 1
Training loss: 2.5781846046447754
Validation loss: 1.780651500756792
Epoch: 9| Step: 2
Training loss: 1.3153306245803833
Validation loss: 1.7910050453899575
Epoch: 9| Step: 3
Training loss: 1.9688067436218262
Validation loss: 1.7824000514668525
Epoch: 9| Step: 4
Training loss: 2.725743532180786
Validation loss: 1.763837918960791
Epoch: 9| Step: 5
Training loss: 1.5792229175567627
Validation loss: 1.7962148884217517
Epoch: 9| Step: 6
Training loss: 1.421359658241272
Validation loss: 1.7647884543851124
Epoch: 9| Step: 7
Training loss: 1.6242094039916992
Validation loss: 1.7833708061588753
Epoch: 9| Step: 8
Training loss: 3.122424364089966
Validation loss: 1.746311541941526
Epoch: 9| Step: 9
Training loss: 2.3079147338867188
Validation loss: 1.7692694449596267
Epoch: 9| Step: 10
Training loss: 1.8964735269546509
Validation loss: 1.7863240181970939
Epoch: 9| Step: 11
Training loss: 1.7983982563018799
Validation loss: 1.7727795110332023
Epoch: 9| Step: 12
Training loss: 1.7730066776275635
Validation loss: 1.7813895108888476
Epoch: 9| Step: 13
Training loss: 1.7174336910247803
Validation loss: 1.7744451701212272
Epoch: 9| Step: 14
Training loss: 1.4647691249847412
Validation loss: 1.7518024238751089
Epoch: 9| Step: 15
Training loss: 2.204324960708618
Validation loss: 1.7627446136886267
Epoch: 9| Step: 16
Training loss: 1.6969636678695679
Validation loss: 1.7851143277806343
Epoch: 9| Step: 17
Training loss: 2.5372915267944336
Validation loss: 1.7534878657018538
Epoch: 9| Step: 18
Training loss: 1.6992852687835693
Validation loss: 1.7548341305135824
Epoch: 9| Step: 19
Training loss: 1.7514463663101196
Validation loss: 1.7662520228530005
Epoch: 87| Step: 0
Training loss: 1.7960602045059204
Validation loss: 1.7726980096144642
Epoch: 9| Step: 1
Training loss: 1.9418643712997437
Validation loss: 1.7725408591812464
Epoch: 9| Step: 2
Training loss: 1.8792237043380737
Validation loss: 1.7795406562818898
Epoch: 9| Step: 3
Training loss: 1.463762879371643
Validation loss: 1.7826330738959553
Epoch: 9| Step: 4
Training loss: 2.065408229827881
Validation loss: 1.7587212641462147
Epoch: 9| Step: 5
Training loss: 1.7672759294509888
Validation loss: 1.799802967112699
Epoch: 9| Step: 6
Training loss: 2.1645071506500244
Validation loss: 1.7925836259512593
Epoch: 9| Step: 7
Training loss: 2.1624014377593994
Validation loss: 1.8042879293290832
Epoch: 9| Step: 8
Training loss: 2.002676248550415
Validation loss: 1.7876698087445266
Epoch: 9| Step: 9
Training loss: 2.3467586040496826
Validation loss: 1.8112916080214136
Epoch: 9| Step: 10
Training loss: 2.424785852432251
Validation loss: 1.818366211952923
Epoch: 9| Step: 11
Training loss: 1.5953510999679565
Validation loss: 1.7940182600089971
Epoch: 9| Step: 12
Training loss: 1.7282335758209229
Validation loss: 1.8093257970947156
Epoch: 9| Step: 13
Training loss: 1.3087503910064697
Validation loss: 1.7980120250647016
Epoch: 9| Step: 14
Training loss: 1.820101261138916
Validation loss: 1.8030088402384477
Epoch: 9| Step: 15
Training loss: 1.9163742065429688
Validation loss: 1.8030275715340813
Epoch: 9| Step: 16
Training loss: 2.149569511413574
Validation loss: 1.8103273763931056
Epoch: 9| Step: 17
Training loss: 1.6605820655822754
Validation loss: 1.7971183318885968
Epoch: 9| Step: 18
Training loss: 2.612767457962036
Validation loss: 1.7847326805265686
Epoch: 9| Step: 19
Training loss: 1.9971401691436768
Validation loss: 1.8059584253983532
Epoch: 88| Step: 0
Training loss: 2.16042423248291
Validation loss: 1.8052265927088347
Epoch: 9| Step: 1
Training loss: 2.6198558807373047
Validation loss: 1.799912821474693
Epoch: 9| Step: 2
Training loss: 1.744779109954834
Validation loss: 1.7919472807602916
Epoch: 9| Step: 3
Training loss: 1.765655279159546
Validation loss: 1.7954031151833294
Epoch: 9| Step: 4
Training loss: 1.550933599472046
Validation loss: 1.7832841307139224
Epoch: 9| Step: 5
Training loss: 1.548923373222351
Validation loss: 1.7801100238621663
Epoch: 9| Step: 6
Training loss: 1.8344013690948486
Validation loss: 1.7665081984705204
Epoch: 9| Step: 7
Training loss: 2.1715660095214844
Validation loss: 1.7653325856160775
Epoch: 9| Step: 8
Training loss: 2.5752334594726562
Validation loss: 1.7996720341469745
Epoch: 9| Step: 9
Training loss: 2.0558831691741943
Validation loss: 1.778981247394205
Epoch: 9| Step: 10
Training loss: 2.1338205337524414
Validation loss: 1.7811149092886944
Epoch: 9| Step: 11
Training loss: 1.9484531879425049
Validation loss: 1.7731758459008855
Epoch: 9| Step: 12
Training loss: 1.8179739713668823
Validation loss: 1.7682343352612833
Epoch: 9| Step: 13
Training loss: 1.62544846534729
Validation loss: 1.7618574135595089
Epoch: 9| Step: 14
Training loss: 1.561888575553894
Validation loss: 1.7565127139468846
Epoch: 9| Step: 15
Training loss: 2.547631025314331
Validation loss: 1.7608211743745872
Epoch: 9| Step: 16
Training loss: 1.9518139362335205
Validation loss: 1.753969685636836
Epoch: 9| Step: 17
Training loss: 1.5674512386322021
Validation loss: 1.7355689444987894
Epoch: 9| Step: 18
Training loss: 1.9420559406280518
Validation loss: 1.7475052308693206
Epoch: 9| Step: 19
Training loss: 2.0467474460601807
Validation loss: 1.7546082906585803
Epoch: 89| Step: 0
Training loss: 2.0135152339935303
Validation loss: 1.7801053138087979
Epoch: 9| Step: 1
Training loss: 1.9748210906982422
Validation loss: 1.7418500064945908
Epoch: 9| Step: 2
Training loss: 1.8705613613128662
Validation loss: 1.7492501624196553
Epoch: 9| Step: 3
Training loss: 2.2502713203430176
Validation loss: 1.76661748251469
Epoch: 9| Step: 4
Training loss: 2.3316328525543213
Validation loss: 1.773656344242233
Epoch: 9| Step: 5
Training loss: 2.1501481533050537
Validation loss: 1.7716485922285121
Epoch: 9| Step: 6
Training loss: 1.821835994720459
Validation loss: 1.7770435964460853
Epoch: 9| Step: 7
Training loss: 1.6299593448638916
Validation loss: 1.7753292313582605
Epoch: 9| Step: 8
Training loss: 1.8707598447799683
Validation loss: 1.7898565573658016
Epoch: 9| Step: 9
Training loss: 2.1826136112213135
Validation loss: 1.7624893222781395
Epoch: 9| Step: 10
Training loss: 1.7074495553970337
Validation loss: 1.7654534492561285
Epoch: 9| Step: 11
Training loss: 2.1091837882995605
Validation loss: 1.7762224631343815
Epoch: 9| Step: 12
Training loss: 2.0222277641296387
Validation loss: 1.7998752499655855
Epoch: 9| Step: 13
Training loss: 1.6780190467834473
Validation loss: 1.776922867452498
Epoch: 9| Step: 14
Training loss: 2.1530680656433105
Validation loss: 1.8000753354683197
Epoch: 9| Step: 15
Training loss: 1.757594108581543
Validation loss: 1.7623895020793667
Epoch: 9| Step: 16
Training loss: 1.9707785844802856
Validation loss: 1.789883920614668
Epoch: 9| Step: 17
Training loss: 1.7216590642929077
Validation loss: 1.7572667350014337
Epoch: 9| Step: 18
Training loss: 2.1262004375457764
Validation loss: 1.775207021253572
Epoch: 9| Step: 19
Training loss: 1.4297651052474976
Validation loss: 1.7687573998952084
Epoch: 90| Step: 0
Training loss: 1.8350229263305664
Validation loss: 1.7888452372105001
Epoch: 9| Step: 1
Training loss: 2.4722204208374023
Validation loss: 1.7795071275971777
Epoch: 9| Step: 2
Training loss: 2.0234365463256836
Validation loss: 1.7926306733124548
Epoch: 9| Step: 3
Training loss: 2.142526626586914
Validation loss: 1.7888990846469248
Epoch: 9| Step: 4
Training loss: 1.8492354154586792
Validation loss: 1.7651428824706044
Epoch: 9| Step: 5
Training loss: 1.2837588787078857
Validation loss: 1.7960593571765817
Epoch: 9| Step: 6
Training loss: 1.899660348892212
Validation loss: 1.805015166028798
Epoch: 9| Step: 7
Training loss: 1.5035525560379028
Validation loss: 1.7963443145477513
Epoch: 9| Step: 8
Training loss: 2.922684669494629
Validation loss: 1.7996627040904203
Epoch: 9| Step: 9
Training loss: 1.4039881229400635
Validation loss: 1.7807520850956868
Epoch: 9| Step: 10
Training loss: 1.641965389251709
Validation loss: 1.824812921688711
Epoch: 9| Step: 11
Training loss: 1.8656138181686401
Validation loss: 1.8055015991059997
Epoch: 9| Step: 12
Training loss: 2.060227394104004
Validation loss: 1.7941484382684283
Epoch: 9| Step: 13
Training loss: 1.4803764820098877
Validation loss: 1.7682923961886399
Epoch: 9| Step: 14
Training loss: 2.3909926414489746
Validation loss: 1.7864927842462663
Epoch: 9| Step: 15
Training loss: 1.453518033027649
Validation loss: 1.7957203585466892
Epoch: 9| Step: 16
Training loss: 2.0951452255249023
Validation loss: 1.7906309572055186
Epoch: 9| Step: 17
Training loss: 2.275503396987915
Validation loss: 1.7661406119092762
Epoch: 9| Step: 18
Training loss: 2.6023473739624023
Validation loss: 1.7732781926505
Epoch: 9| Step: 19
Training loss: 1.8005163669586182
Validation loss: 1.7512829878347382
Epoch: 91| Step: 0
Training loss: 1.5542447566986084
Validation loss: 1.7516296347268194
Epoch: 9| Step: 1
Training loss: 2.161546230316162
Validation loss: 1.7728077413366854
Epoch: 9| Step: 2
Training loss: 1.8842909336090088
Validation loss: 1.7623924445762909
Epoch: 9| Step: 3
Training loss: 2.570725917816162
Validation loss: 1.7770389395652058
Epoch: 9| Step: 4
Training loss: 1.5287926197052002
Validation loss: 1.7648774608433675
Epoch: 9| Step: 5
Training loss: 2.1746721267700195
Validation loss: 1.7814856578977845
Epoch: 9| Step: 6
Training loss: 1.5903221368789673
Validation loss: 1.778084850997376
Epoch: 9| Step: 7
Training loss: 2.1915860176086426
Validation loss: 1.7763079233306776
Epoch: 9| Step: 8
Training loss: 1.4040614366531372
Validation loss: 1.7429819836033333
Epoch: 9| Step: 9
Training loss: 2.5947694778442383
Validation loss: 1.7471018077658236
Epoch: 9| Step: 10
Training loss: 1.302248239517212
Validation loss: 1.757068237812399
Epoch: 9| Step: 11
Training loss: 1.9351357221603394
Validation loss: 1.7429912047420475
Epoch: 9| Step: 12
Training loss: 2.536957263946533
Validation loss: 1.762142478990898
Epoch: 9| Step: 13
Training loss: 2.148575782775879
Validation loss: 1.7668824410267014
Epoch: 9| Step: 14
Training loss: 1.9077885150909424
Validation loss: 1.754790418439632
Epoch: 9| Step: 15
Training loss: 1.9851319789886475
Validation loss: 1.741617931736459
Epoch: 9| Step: 16
Training loss: 2.000303268432617
Validation loss: 1.743090843125213
Epoch: 9| Step: 17
Training loss: 2.0059216022491455
Validation loss: 1.7426463588536214
Epoch: 9| Step: 18
Training loss: 1.5036559104919434
Validation loss: 1.7535097015847405
Epoch: 9| Step: 19
Training loss: 1.8181629180908203
Validation loss: 1.7488386570978507
Epoch: 92| Step: 0
Training loss: 1.894758939743042
Validation loss: 1.7973314163496168
Epoch: 9| Step: 1
Training loss: 1.9141359329223633
Validation loss: 1.7645408686974067
Epoch: 9| Step: 2
Training loss: 2.5405640602111816
Validation loss: 1.7606114689394725
Epoch: 9| Step: 3
Training loss: 1.2234456539154053
Validation loss: 1.775573426870991
Epoch: 9| Step: 4
Training loss: 1.6302238702774048
Validation loss: 1.7762344458120332
Epoch: 9| Step: 5
Training loss: 1.8163597583770752
Validation loss: 1.810127153671045
Epoch: 9| Step: 6
Training loss: 2.084390878677368
Validation loss: 1.7734793201624919
Epoch: 9| Step: 7
Training loss: 1.8823556900024414
Validation loss: 1.8142343467945674
Epoch: 9| Step: 8
Training loss: 1.5838494300842285
Validation loss: 1.7828517920679325
Epoch: 9| Step: 9
Training loss: 2.833080768585205
Validation loss: 1.8010274420539252
Epoch: 9| Step: 10
Training loss: 1.7311034202575684
Validation loss: 1.7967992815182363
Epoch: 9| Step: 11
Training loss: 1.5675976276397705
Validation loss: 1.7846306948353061
Epoch: 9| Step: 12
Training loss: 1.9924101829528809
Validation loss: 1.7849440660408076
Epoch: 9| Step: 13
Training loss: 2.791301965713501
Validation loss: 1.8239385206922352
Epoch: 9| Step: 14
Training loss: 1.6607619524002075
Validation loss: 1.8102801334943703
Epoch: 9| Step: 15
Training loss: 1.8527107238769531
Validation loss: 1.7837402065880865
Epoch: 9| Step: 16
Training loss: 1.665257453918457
Validation loss: 1.8072622388386899
Epoch: 9| Step: 17
Training loss: 2.0281176567077637
Validation loss: 1.8027158418147684
Epoch: 9| Step: 18
Training loss: 1.9168705940246582
Validation loss: 1.799273376842197
Epoch: 9| Step: 19
Training loss: 2.0605156421661377
Validation loss: 1.780888679216234
Epoch: 93| Step: 0
Training loss: 1.8203294277191162
Validation loss: 1.7962539719163084
Epoch: 9| Step: 1
Training loss: 1.4225291013717651
Validation loss: 1.7781006809618833
Epoch: 9| Step: 2
Training loss: 2.055572509765625
Validation loss: 1.7845711313563286
Epoch: 9| Step: 3
Training loss: 1.9137547016143799
Validation loss: 1.7677501611572375
Epoch: 9| Step: 4
Training loss: 1.7203266620635986
Validation loss: 1.7994723148483167
Epoch: 9| Step: 5
Training loss: 1.7721174955368042
Validation loss: 1.7586355586703732
Epoch: 9| Step: 6
Training loss: 1.8863425254821777
Validation loss: 1.7680331974578418
Epoch: 9| Step: 7
Training loss: 1.7544463872909546
Validation loss: 1.7626983467623485
Epoch: 9| Step: 8
Training loss: 2.3441312313079834
Validation loss: 1.77512003106179
Epoch: 9| Step: 9
Training loss: 1.6817240715026855
Validation loss: 1.7687220556272878
Epoch: 9| Step: 10
Training loss: 2.5317792892456055
Validation loss: 1.7528805175273539
Epoch: 9| Step: 11
Training loss: 2.103365659713745
Validation loss: 1.7798488157258616
Epoch: 9| Step: 12
Training loss: 2.179762601852417
Validation loss: 1.7870447352635774
Epoch: 9| Step: 13
Training loss: 2.0744762420654297
Validation loss: 1.7844065299137033
Epoch: 9| Step: 14
Training loss: 2.056387186050415
Validation loss: 1.815587136385252
Epoch: 9| Step: 15
Training loss: 1.917844295501709
Validation loss: 1.786539247567705
Epoch: 9| Step: 16
Training loss: 1.776490569114685
Validation loss: 1.7903573358659264
Epoch: 9| Step: 17
Training loss: 1.8711519241333008
Validation loss: 1.7889115501650803
Epoch: 9| Step: 18
Training loss: 2.43489146232605
Validation loss: 1.8129022678882956
Epoch: 9| Step: 19
Training loss: 1.6504162549972534
Validation loss: 1.785611629486084
Epoch: 94| Step: 0
Training loss: 2.3957760334014893
Validation loss: 1.77712512702393
Epoch: 9| Step: 1
Training loss: 1.6940501928329468
Validation loss: 1.7751238792062662
Epoch: 9| Step: 2
Training loss: 1.7762207984924316
Validation loss: 1.7919870091856813
Epoch: 9| Step: 3
Training loss: 1.741908311843872
Validation loss: 1.781098334909343
Epoch: 9| Step: 4
Training loss: 2.4228224754333496
Validation loss: 1.7739666468805546
Epoch: 9| Step: 5
Training loss: 1.5600908994674683
Validation loss: 1.7638702066682226
Epoch: 9| Step: 6
Training loss: 1.9778327941894531
Validation loss: 1.7846229076385498
Epoch: 9| Step: 7
Training loss: 2.5314507484436035
Validation loss: 1.7902729768547223
Epoch: 9| Step: 8
Training loss: 1.9538884162902832
Validation loss: 1.7679766613802463
Epoch: 9| Step: 9
Training loss: 1.7299325466156006
Validation loss: 1.7685868294118978
Epoch: 9| Step: 10
Training loss: 2.145956516265869
Validation loss: 1.7748777514739003
Epoch: 9| Step: 11
Training loss: 1.7570511102676392
Validation loss: 1.7448272156200821
Epoch: 9| Step: 12
Training loss: 1.4258209466934204
Validation loss: 1.77158432298427
Epoch: 9| Step: 13
Training loss: 2.0518720149993896
Validation loss: 1.7719014256978207
Epoch: 9| Step: 14
Training loss: 2.4961137771606445
Validation loss: 1.768243250229376
Epoch: 9| Step: 15
Training loss: 1.6709091663360596
Validation loss: 1.767466442190486
Epoch: 9| Step: 16
Training loss: 2.147690773010254
Validation loss: 1.7386416342618654
Epoch: 9| Step: 17
Training loss: 2.025348663330078
Validation loss: 1.752003566824275
Epoch: 9| Step: 18
Training loss: 1.8048882484436035
Validation loss: 1.7613272649778737
Epoch: 9| Step: 19
Training loss: 1.5721758604049683
Validation loss: 1.7736888154805135
Epoch: 95| Step: 0
Training loss: 1.766800880432129
Validation loss: 1.7657985172683386
Epoch: 9| Step: 1
Training loss: 1.8779799938201904
Validation loss: 1.7652776498588727
Epoch: 9| Step: 2
Training loss: 2.5185165405273438
Validation loss: 1.7796574505113012
Epoch: 9| Step: 3
Training loss: 2.258172035217285
Validation loss: 1.7606534940733327
Epoch: 9| Step: 4
Training loss: 1.3469135761260986
Validation loss: 1.745152380826662
Epoch: 9| Step: 5
Training loss: 1.6934958696365356
Validation loss: 1.746171527629276
Epoch: 9| Step: 6
Training loss: 1.4816049337387085
Validation loss: 1.749779572589792
Epoch: 9| Step: 7
Training loss: 2.5661473274230957
Validation loss: 1.7544688646741908
Epoch: 9| Step: 8
Training loss: 2.1287784576416016
Validation loss: 1.7512806928415092
Epoch: 9| Step: 9
Training loss: 1.9183270931243896
Validation loss: 1.7667234072582327
Epoch: 9| Step: 10
Training loss: 1.39390230178833
Validation loss: 1.778883396292762
Epoch: 9| Step: 11
Training loss: 1.8884284496307373
Validation loss: 1.7443607119347553
Epoch: 9| Step: 12
Training loss: 1.9147417545318604
Validation loss: 1.7196226943311075
Epoch: 9| Step: 13
Training loss: 3.167816162109375
Validation loss: 1.7574734138927872
Epoch: 9| Step: 14
Training loss: 1.6000969409942627
Validation loss: 1.7407357281060527
Epoch: 9| Step: 15
Training loss: 1.6996910572052002
Validation loss: 1.7641071792986753
Epoch: 9| Step: 16
Training loss: 1.9301811456680298
Validation loss: 1.755612627207804
Epoch: 9| Step: 17
Training loss: 1.824967622756958
Validation loss: 1.7709336598142444
Epoch: 9| Step: 18
Training loss: 1.6502954959869385
Validation loss: 1.7665276801843437
Epoch: 9| Step: 19
Training loss: 2.0770978927612305
Validation loss: 1.7705873122318185
Epoch: 96| Step: 0
Training loss: 1.9744207859039307
Validation loss: 1.7692715624253528
Epoch: 9| Step: 1
Training loss: 1.8020503520965576
Validation loss: 1.785606970032342
Epoch: 9| Step: 2
Training loss: 1.7484359741210938
Validation loss: 1.7875204463656857
Epoch: 9| Step: 3
Training loss: 1.143918514251709
Validation loss: 1.774471681752651
Epoch: 9| Step: 4
Training loss: 1.9746028184890747
Validation loss: 1.7726896975537856
Epoch: 9| Step: 5
Training loss: 2.0395100116729736
Validation loss: 1.7918359873106153
Epoch: 9| Step: 6
Training loss: 1.937898874282837
Validation loss: 1.7918986699563995
Epoch: 9| Step: 7
Training loss: 2.277923583984375
Validation loss: 1.794233644608971
Epoch: 9| Step: 8
Training loss: 2.1144986152648926
Validation loss: 1.7964418946410254
Epoch: 9| Step: 9
Training loss: 1.5148265361785889
Validation loss: 1.802995226366057
Epoch: 9| Step: 10
Training loss: 2.2255825996398926
Validation loss: 1.804533378683406
Epoch: 9| Step: 11
Training loss: 1.6622973680496216
Validation loss: 1.8131971573658128
Epoch: 9| Step: 12
Training loss: 1.7649774551391602
Validation loss: 1.8149352622546737
Epoch: 9| Step: 13
Training loss: 2.8506524562835693
Validation loss: 1.8137896575516077
Epoch: 9| Step: 14
Training loss: 1.4979060888290405
Validation loss: 1.7907651825774489
Epoch: 9| Step: 15
Training loss: 2.8198814392089844
Validation loss: 1.8229245230448332
Epoch: 9| Step: 16
Training loss: 1.0028700828552246
Validation loss: 1.8159942481157592
Epoch: 9| Step: 17
Training loss: 1.9491355419158936
Validation loss: 1.7981747002910367
Epoch: 9| Step: 18
Training loss: 2.174376964569092
Validation loss: 1.7988378881550522
Epoch: 9| Step: 19
Training loss: 2.130063772201538
Validation loss: 1.7939716474615413
Epoch: 97| Step: 0
Training loss: 2.0756242275238037
Validation loss: 1.7863444544428544
Epoch: 9| Step: 1
Training loss: 3.496649742126465
Validation loss: 1.7821804113525281
Epoch: 9| Step: 2
Training loss: 2.2401745319366455
Validation loss: 1.7635385801466248
Epoch: 9| Step: 3
Training loss: 1.7690403461456299
Validation loss: 1.7872978860525777
Epoch: 9| Step: 4
Training loss: 2.116995096206665
Validation loss: 1.7713119820725145
Epoch: 9| Step: 5
Training loss: 1.6849415302276611
Validation loss: 1.7647446239594933
Epoch: 9| Step: 6
Training loss: 1.5739079713821411
Validation loss: 1.762577261856134
Epoch: 9| Step: 7
Training loss: 1.5174278020858765
Validation loss: 1.760575593804284
Epoch: 9| Step: 8
Training loss: 2.1863770484924316
Validation loss: 1.7622284374648718
Epoch: 9| Step: 9
Training loss: 1.7986276149749756
Validation loss: 1.7757515547086866
Epoch: 9| Step: 10
Training loss: 2.017369508743286
Validation loss: 1.7736648312575525
Epoch: 9| Step: 11
Training loss: 1.5981898307800293
Validation loss: 1.7564344011622368
Epoch: 9| Step: 12
Training loss: 1.9702520370483398
Validation loss: 1.7816197151760402
Epoch: 9| Step: 13
Training loss: 1.9414788484573364
Validation loss: 1.7724078816475628
Epoch: 9| Step: 14
Training loss: 1.2871038913726807
Validation loss: 1.7823100175788935
Epoch: 9| Step: 15
Training loss: 1.5955203771591187
Validation loss: 1.7547851698004084
Epoch: 9| Step: 16
Training loss: 1.590742588043213
Validation loss: 1.7640904771338264
Epoch: 9| Step: 17
Training loss: 2.1223409175872803
Validation loss: 1.786869472736935
Epoch: 9| Step: 18
Training loss: 2.3429253101348877
Validation loss: 1.7728345454167977
Epoch: 9| Step: 19
Training loss: 2.081141471862793
Validation loss: 1.7929560940900295
Epoch: 98| Step: 0
Training loss: 1.8098896741867065
Validation loss: 1.7891928703664877
Epoch: 9| Step: 1
Training loss: 2.2574026584625244
Validation loss: 1.7915377222376763
Epoch: 9| Step: 2
Training loss: 1.8067162036895752
Validation loss: 1.781093898437006
Epoch: 9| Step: 3
Training loss: 1.9558594226837158
Validation loss: 1.7732034158363617
Epoch: 9| Step: 4
Training loss: 2.2052581310272217
Validation loss: 1.7810050249099731
Epoch: 9| Step: 5
Training loss: 1.677281141281128
Validation loss: 1.7896876746802022
Epoch: 9| Step: 6
Training loss: 1.3042664527893066
Validation loss: 1.7645428197846995
Epoch: 9| Step: 7
Training loss: 1.6268727779388428
Validation loss: 1.80346844007643
Epoch: 9| Step: 8
Training loss: 1.5501649379730225
Validation loss: 1.7855897944608181
Epoch: 9| Step: 9
Training loss: 2.2058358192443848
Validation loss: 1.821912683171334
Epoch: 9| Step: 10
Training loss: 2.204404830932617
Validation loss: 1.8158114616819423
Epoch: 9| Step: 11
Training loss: 1.2751739025115967
Validation loss: 1.7878054346112038
Epoch: 9| Step: 12
Training loss: 2.041802406311035
Validation loss: 1.7980893052739204
Epoch: 9| Step: 13
Training loss: 2.498086452484131
Validation loss: 1.7867142974043921
Epoch: 9| Step: 14
Training loss: 2.0806820392608643
Validation loss: 1.8084703246466547
Epoch: 9| Step: 15
Training loss: 2.0384316444396973
Validation loss: 1.8128897723534125
Epoch: 9| Step: 16
Training loss: 2.006944179534912
Validation loss: 1.8086835154526526
Epoch: 9| Step: 17
Training loss: 1.5317769050598145
Validation loss: 1.8074717084280878
Epoch: 9| Step: 18
Training loss: 2.322248935699463
Validation loss: 1.8209187847247226
Epoch: 9| Step: 19
Training loss: 2.2969419956207275
Validation loss: 1.8235249673719887
Epoch: 99| Step: 0
Training loss: 1.8381593227386475
Validation loss: 1.8228591954965385
Epoch: 9| Step: 1
Training loss: 2.1178059577941895
Validation loss: 1.8120464043651554
Epoch: 9| Step: 2
Training loss: 2.096585512161255
Validation loss: 1.8012647525869685
Epoch: 9| Step: 3
Training loss: 1.904251217842102
Validation loss: 1.8021075751284044
Epoch: 9| Step: 4
Training loss: 1.6921494007110596
Validation loss: 1.7823463824155519
Epoch: 9| Step: 5
Training loss: 1.8905200958251953
Validation loss: 1.7935531774013163
Epoch: 9| Step: 6
Training loss: 2.00364089012146
Validation loss: 1.7856750093775688
Epoch: 9| Step: 7
Training loss: 1.7804973125457764
Validation loss: 1.7910291591136576
Epoch: 9| Step: 8
Training loss: 1.9755817651748657
Validation loss: 1.7659254262773254
Epoch: 9| Step: 9
Training loss: 1.7528504133224487
Validation loss: 1.7925585894275913
Epoch: 9| Step: 10
Training loss: 1.0618046522140503
Validation loss: 1.7827861677828452
Epoch: 9| Step: 11
Training loss: 2.454211473464966
Validation loss: 1.7684588114992321
Epoch: 9| Step: 12
Training loss: 2.062631845474243
Validation loss: 1.7695559074552796
Epoch: 9| Step: 13
Training loss: 2.0118284225463867
Validation loss: 1.7656994449148933
Epoch: 9| Step: 14
Training loss: 1.6647024154663086
Validation loss: 1.7984678127782807
Epoch: 9| Step: 15
Training loss: 1.768229603767395
Validation loss: 1.7767061432488531
Epoch: 9| Step: 16
Training loss: 2.600890636444092
Validation loss: 1.800839179711376
Epoch: 9| Step: 17
Training loss: 2.0895445346832275
Validation loss: 1.7970561243647294
Epoch: 9| Step: 18
Training loss: 2.257965564727783
Validation loss: 1.7691814727920423
Epoch: 9| Step: 19
Training loss: 1.6274865865707397
Validation loss: 1.7621399867448875
Epoch: 100| Step: 0
Training loss: 1.9979910850524902
Validation loss: 1.7751709780247091
Epoch: 9| Step: 1
Training loss: 1.6106741428375244
Validation loss: 1.770282223927889
Epoch: 9| Step: 2
Training loss: 2.272533655166626
Validation loss: 1.7647804519255383
Epoch: 9| Step: 3
Training loss: 1.8215570449829102
Validation loss: 1.7882081561808965
Epoch: 9| Step: 4
Training loss: 2.4747087955474854
Validation loss: 1.7673764451802205
Epoch: 9| Step: 5
Training loss: 1.4187681674957275
Validation loss: 1.772544256217188
Epoch: 9| Step: 6
Training loss: 2.3065450191497803
Validation loss: 1.7850411495716452
Epoch: 9| Step: 7
Training loss: 1.91616952419281
Validation loss: 1.784058515974086
Epoch: 9| Step: 8
Training loss: 1.5486385822296143
Validation loss: 1.7717629482420227
Epoch: 9| Step: 9
Training loss: 2.7535128593444824
Validation loss: 1.7834204666906124
Epoch: 9| Step: 10
Training loss: 1.6966297626495361
Validation loss: 1.7873823385444476
Epoch: 9| Step: 11
Training loss: 1.471392035484314
Validation loss: 1.7832406664923799
Epoch: 9| Step: 12
Training loss: 2.058346748352051
Validation loss: 1.7715503740653717
Epoch: 9| Step: 13
Training loss: 2.290684938430786
Validation loss: 1.7928016031388756
Epoch: 9| Step: 14
Training loss: 1.6975045204162598
Validation loss: 1.7936146979709324
Epoch: 9| Step: 15
Training loss: 1.9416158199310303
Validation loss: 1.8021860843082127
Epoch: 9| Step: 16
Training loss: 2.0770697593688965
Validation loss: 1.7954276980256005
Epoch: 9| Step: 17
Training loss: 1.4419691562652588
Validation loss: 1.7960453067752098
Epoch: 9| Step: 18
Training loss: 1.6958003044128418
Validation loss: 1.8139533893667537
Epoch: 9| Step: 19
Training loss: 2.19466495513916
Validation loss: 1.779113308131266
