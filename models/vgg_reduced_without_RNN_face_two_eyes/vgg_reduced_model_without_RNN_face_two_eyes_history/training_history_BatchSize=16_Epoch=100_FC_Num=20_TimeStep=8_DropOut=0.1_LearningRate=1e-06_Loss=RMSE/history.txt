Epoch: 1| Step: 0
Training loss: 6.524480057970556
Validation loss: 6.20717321132126
Epoch: 9| Step: 1
Training loss: 6.763149874727555
Validation loss: 6.18210238321194
Epoch: 9| Step: 2
Training loss: 5.756271922248904
Validation loss: 6.1805581482261305
Epoch: 9| Step: 3
Training loss: 6.34307677356362
Validation loss: 6.194728931753062
Epoch: 9| Step: 4
Training loss: 7.140649574287583
Validation loss: 6.181280957372005
Epoch: 9| Step: 5
Training loss: 6.697241417370219
Validation loss: 6.152356630186862
Epoch: 9| Step: 6
Training loss: 6.835825612923631
Validation loss: 6.169127247310453
Epoch: 9| Step: 7
Training loss: 5.423127219408616
Validation loss: 6.160529591906984
Epoch: 9| Step: 8
Training loss: 6.451570115716624
Validation loss: 6.150965919485637
Epoch: 9| Step: 9
Training loss: 6.80333211826212
Validation loss: 6.141096674656304
Epoch: 9| Step: 10
Training loss: 7.213910747317551
Validation loss: 6.1482676036501465
Epoch: 9| Step: 11
Training loss: 7.318090665519903
Validation loss: 6.134723698540869
Epoch: 9| Step: 12
Training loss: 6.720526030251725
Validation loss: 6.121270770778841
Epoch: 9| Step: 13
Training loss: 6.865156027291203
Validation loss: 6.128354303967031
Epoch: 9| Step: 14
Training loss: 6.519890502759134
Validation loss: 6.106879313339865
Epoch: 9| Step: 15
Training loss: 6.022923231126798
Validation loss: 6.102316273667539
Epoch: 9| Step: 16
Training loss: 6.215819315224783
Validation loss: 6.100314540754505
Epoch: 9| Step: 17
Training loss: 6.258704875511387
Validation loss: 6.094319669964978
Epoch: 9| Step: 18
Training loss: 6.098224581638143
Validation loss: 6.08522997431462
Epoch: 9| Step: 19
Training loss: 5.531612923133006
Validation loss: 6.066132162932315
Epoch: 2| Step: 0
Training loss: 6.221135127758601
Validation loss: 6.08241167637943
Epoch: 9| Step: 1
Training loss: 7.139560745362333
Validation loss: 6.0559704748009615
Epoch: 9| Step: 2
Training loss: 6.067532996617246
Validation loss: 6.0583985983400135
Epoch: 9| Step: 3
Training loss: 6.824961333112908
Validation loss: 6.0364552650534415
Epoch: 9| Step: 4
Training loss: 6.731219692038024
Validation loss: 6.0571534809916106
Epoch: 9| Step: 5
Training loss: 5.510102097799444
Validation loss: 6.030391861218942
Epoch: 9| Step: 6
Training loss: 5.862177715105246
Validation loss: 6.027417092339759
Epoch: 9| Step: 7
Training loss: 6.473542580383562
Validation loss: 6.012906255769601
Epoch: 9| Step: 8
Training loss: 6.23375237972198
Validation loss: 6.021523105052786
Epoch: 9| Step: 9
Training loss: 6.222037055272774
Validation loss: 6.01624868950329
Epoch: 9| Step: 10
Training loss: 5.477056505503438
Validation loss: 5.993807079140476
Epoch: 9| Step: 11
Training loss: 5.968856730680233
Validation loss: 5.988689542297176
Epoch: 9| Step: 12
Training loss: 7.0234437460866275
Validation loss: 5.9804510739214845
Epoch: 9| Step: 13
Training loss: 6.515738872749685
Validation loss: 5.980091004205141
Epoch: 9| Step: 14
Training loss: 6.026351283325513
Validation loss: 5.977784326770034
Epoch: 9| Step: 15
Training loss: 6.3238924164955685
Validation loss: 5.970549740339949
Epoch: 9| Step: 16
Training loss: 6.595862461522991
Validation loss: 5.971573417130223
Epoch: 9| Step: 17
Training loss: 6.501749243480377
Validation loss: 5.945455820713721
Epoch: 9| Step: 18
Training loss: 6.788481482258086
Validation loss: 5.951488715861649
Epoch: 9| Step: 19
Training loss: 6.501559437240176
Validation loss: 5.931883743131817
Epoch: 3| Step: 0
Training loss: 6.422919195444618
Validation loss: 5.937951043846629
Epoch: 9| Step: 1
Training loss: 5.931384340137611
Validation loss: 5.9240397210459115
Epoch: 9| Step: 2
Training loss: 6.333738648679419
Validation loss: 5.927390604164271
Epoch: 9| Step: 3
Training loss: 5.668476189810902
Validation loss: 5.879739658966065
Epoch: 9| Step: 4
Training loss: 6.306683570618722
Validation loss: 5.910519301537246
Epoch: 9| Step: 5
Training loss: 5.845192797428613
Validation loss: 5.901778387536447
Epoch: 9| Step: 6
Training loss: 5.876577287334326
Validation loss: 5.89690210870002
Epoch: 9| Step: 7
Training loss: 6.234272814991199
Validation loss: 5.882483841529956
Epoch: 9| Step: 8
Training loss: 5.839663785375037
Validation loss: 5.86340372695491
Epoch: 9| Step: 9
Training loss: 5.83784619107379
Validation loss: 5.866128492021243
Epoch: 9| Step: 10
Training loss: 6.400854602022332
Validation loss: 5.868663634050892
Epoch: 9| Step: 11
Training loss: 6.6871754219933335
Validation loss: 5.853621973096341
Epoch: 9| Step: 12
Training loss: 5.8446876467219475
Validation loss: 5.849295212001123
Epoch: 9| Step: 13
Training loss: 6.582027482843878
Validation loss: 5.832933850574203
Epoch: 9| Step: 14
Training loss: 5.992314821007196
Validation loss: 5.8304589568490135
Epoch: 9| Step: 15
Training loss: 6.321771139818198
Validation loss: 5.822408291000281
Epoch: 9| Step: 16
Training loss: 6.482393922713913
Validation loss: 5.799770171842745
Epoch: 9| Step: 17
Training loss: 6.12542193769498
Validation loss: 5.789627424219015
Epoch: 9| Step: 18
Training loss: 6.715530830812975
Validation loss: 5.777769387252219
Epoch: 9| Step: 19
Training loss: 6.889348264301634
Validation loss: 5.794303497731778
Epoch: 4| Step: 0
Training loss: 6.346638740563595
Validation loss: 5.781638392521414
Epoch: 9| Step: 1
Training loss: 5.479870459703126
Validation loss: 5.7746549894285915
Epoch: 9| Step: 2
Training loss: 6.610197408385927
Validation loss: 5.770498126828458
Epoch: 9| Step: 3
Training loss: 6.280388768305246
Validation loss: 5.740998487383247
Epoch: 9| Step: 4
Training loss: 5.799313590111771
Validation loss: 5.746798191536177
Epoch: 9| Step: 5
Training loss: 6.057423461984702
Validation loss: 5.736496202259664
Epoch: 9| Step: 6
Training loss: 6.278349401205167
Validation loss: 5.7289720668316635
Epoch: 9| Step: 7
Training loss: 5.6864924953273315
Validation loss: 5.729250103216469
Epoch: 9| Step: 8
Training loss: 6.117943883832432
Validation loss: 5.709298800916114
Epoch: 9| Step: 9
Training loss: 5.758437227599101
Validation loss: 5.689892281522831
Epoch: 9| Step: 10
Training loss: 5.713638439303619
Validation loss: 5.693798609253972
Epoch: 9| Step: 11
Training loss: 6.791712130841007
Validation loss: 5.670149776704305
Epoch: 9| Step: 12
Training loss: 5.350046474932301
Validation loss: 5.671298489787311
Epoch: 9| Step: 13
Training loss: 5.4376078627838895
Validation loss: 5.674908978898321
Epoch: 9| Step: 14
Training loss: 5.625635916473948
Validation loss: 5.65012560099485
Epoch: 9| Step: 15
Training loss: 5.9245267783686675
Validation loss: 5.623963482541985
Epoch: 9| Step: 16
Training loss: 6.678136241655255
Validation loss: 5.63673025239993
Epoch: 9| Step: 17
Training loss: 6.196761165156221
Validation loss: 5.615905887962979
Epoch: 9| Step: 18
Training loss: 6.509198356059323
Validation loss: 5.617355984181053
Epoch: 9| Step: 19
Training loss: 6.415493284007741
Validation loss: 5.613803753146471
Epoch: 5| Step: 0
Training loss: 6.0292136752236525
Validation loss: 5.585937502217242
Epoch: 9| Step: 1
Training loss: 5.767004659519526
Validation loss: 5.584313191923927
Epoch: 9| Step: 2
Training loss: 5.900207981387844
Validation loss: 5.580762613677411
Epoch: 9| Step: 3
Training loss: 5.729086950498915
Validation loss: 5.553844292533807
Epoch: 9| Step: 4
Training loss: 6.894602901097231
Validation loss: 5.551643244672612
Epoch: 9| Step: 5
Training loss: 4.929260138654316
Validation loss: 5.535892648187425
Epoch: 9| Step: 6
Training loss: 6.3017985970563455
Validation loss: 5.522239880149483
Epoch: 9| Step: 7
Training loss: 5.345201083362723
Validation loss: 5.4887338528948755
Epoch: 9| Step: 8
Training loss: 6.921706910169844
Validation loss: 5.510101651855234
Epoch: 9| Step: 9
Training loss: 6.019251772997893
Validation loss: 5.513752861157941
Epoch: 9| Step: 10
Training loss: 6.645182546802026
Validation loss: 5.461888448550962
Epoch: 9| Step: 11
Training loss: 5.919297112673553
Validation loss: 5.474971009949501
Epoch: 9| Step: 12
Training loss: 4.138355712912049
Validation loss: 5.480538178944692
Epoch: 9| Step: 13
Training loss: 5.968229740496889
Validation loss: 5.453451840886758
Epoch: 9| Step: 14
Training loss: 5.336717584872604
Validation loss: 5.452123681998597
Epoch: 9| Step: 15
Training loss: 6.3120570263432025
Validation loss: 5.434378195201638
Epoch: 9| Step: 16
Training loss: 5.22241265150389
Validation loss: 5.421244609536918
Epoch: 9| Step: 17
Training loss: 5.400085815878082
Validation loss: 5.396027489175203
Epoch: 9| Step: 18
Training loss: 5.261857040162569
Validation loss: 5.407158541624536
Epoch: 9| Step: 19
Training loss: 6.694566077485554
Validation loss: 5.385789010646773
Epoch: 6| Step: 0
Training loss: 5.802461877752704
Validation loss: 5.363019271693431
Epoch: 9| Step: 1
Training loss: 5.126658473675898
Validation loss: 5.345495823658924
Epoch: 9| Step: 2
Training loss: 5.673807618831274
Validation loss: 5.359264008585184
Epoch: 9| Step: 3
Training loss: 5.369596204582664
Validation loss: 5.3480430210915415
Epoch: 9| Step: 4
Training loss: 5.6827553881255115
Validation loss: 5.330380749318697
Epoch: 9| Step: 5
Training loss: 6.1393926805973456
Validation loss: 5.296214380862599
Epoch: 9| Step: 6
Training loss: 5.545438510627134
Validation loss: 5.306235971968048
Epoch: 9| Step: 7
Training loss: 6.0352687590645555
Validation loss: 5.2761847172708
Epoch: 9| Step: 8
Training loss: 6.0030840259208125
Validation loss: 5.274056242156294
Epoch: 9| Step: 9
Training loss: 6.157846621360996
Validation loss: 5.227456941093333
Epoch: 9| Step: 10
Training loss: 5.479807285623577
Validation loss: 5.243546765657087
Epoch: 9| Step: 11
Training loss: 4.812416769521756
Validation loss: 5.231521450836006
Epoch: 9| Step: 12
Training loss: 6.414472559878602
Validation loss: 5.208150536784608
Epoch: 9| Step: 13
Training loss: 5.094702883097406
Validation loss: 5.1973689539978905
Epoch: 9| Step: 14
Training loss: 5.364465548015453
Validation loss: 5.1945508930383095
Epoch: 9| Step: 15
Training loss: 6.2038948868898585
Validation loss: 5.163467597199575
Epoch: 9| Step: 16
Training loss: 5.071929062645091
Validation loss: 5.149255433439148
Epoch: 9| Step: 17
Training loss: 5.364263057098519
Validation loss: 5.150978153869115
Epoch: 9| Step: 18
Training loss: 5.925580397881529
Validation loss: 5.125712104093813
Epoch: 9| Step: 19
Training loss: 5.220813092159278
Validation loss: 5.091190418523099
Epoch: 7| Step: 0
Training loss: 5.074747975673429
Validation loss: 5.09292001683814
Epoch: 9| Step: 1
Training loss: 5.03249575907059
Validation loss: 5.076981331681726
Epoch: 9| Step: 2
Training loss: 5.585178563773355
Validation loss: 5.053721751214277
Epoch: 9| Step: 3
Training loss: 5.908036219233379
Validation loss: 5.040835028945656
Epoch: 9| Step: 4
Training loss: 5.227232292833111
Validation loss: 5.025890002947155
Epoch: 9| Step: 5
Training loss: 6.037046819070919
Validation loss: 4.996719378157303
Epoch: 9| Step: 6
Training loss: 4.820633789434325
Validation loss: 4.9713774878552695
Epoch: 9| Step: 7
Training loss: 5.445773790652259
Validation loss: 4.976982618521026
Epoch: 9| Step: 8
Training loss: 5.138327412675599
Validation loss: 4.959179960458714
Epoch: 9| Step: 9
Training loss: 5.666651819247074
Validation loss: 4.941823047573906
Epoch: 9| Step: 10
Training loss: 5.555402020346143
Validation loss: 4.900915491985308
Epoch: 9| Step: 11
Training loss: 4.354729258621431
Validation loss: 4.8949644991917545
Epoch: 9| Step: 12
Training loss: 5.284135199666035
Validation loss: 4.883272716859497
Epoch: 9| Step: 13
Training loss: 5.478795008751907
Validation loss: 4.879683619321211
Epoch: 9| Step: 14
Training loss: 5.0556575545942755
Validation loss: 4.855288467953306
Epoch: 9| Step: 15
Training loss: 5.931019669814835
Validation loss: 4.821430308157791
Epoch: 9| Step: 16
Training loss: 5.724874583373974
Validation loss: 4.812619863805317
Epoch: 9| Step: 17
Training loss: 5.2965375854691255
Validation loss: 4.788039293937753
Epoch: 9| Step: 18
Training loss: 4.814977033170154
Validation loss: 4.782213240529936
Epoch: 9| Step: 19
Training loss: 5.137629879982734
Validation loss: 4.74078890286064
Epoch: 8| Step: 0
Training loss: 4.745129145803259
Validation loss: 4.73438969142204
Epoch: 9| Step: 1
Training loss: 4.906994805628078
Validation loss: 4.713084119129442
Epoch: 9| Step: 2
Training loss: 4.869581487951285
Validation loss: 4.675230888232457
Epoch: 9| Step: 3
Training loss: 4.40952974368297
Validation loss: 4.6730875657730016
Epoch: 9| Step: 4
Training loss: 4.1069760590796625
Validation loss: 4.664297190109007
Epoch: 9| Step: 5
Training loss: 4.917641214457978
Validation loss: 4.622799810895565
Epoch: 9| Step: 6
Training loss: 5.144540889560066
Validation loss: 4.625345132417958
Epoch: 9| Step: 7
Training loss: 5.42515899847105
Validation loss: 4.596682705360367
Epoch: 9| Step: 8
Training loss: 5.496961447863879
Validation loss: 4.574811470968558
Epoch: 9| Step: 9
Training loss: 4.455671044362051
Validation loss: 4.558506088926009
Epoch: 9| Step: 10
Training loss: 5.3681707245103745
Validation loss: 4.535096219725186
Epoch: 9| Step: 11
Training loss: 5.645518708230923
Validation loss: 4.465304710815992
Epoch: 9| Step: 12
Training loss: 4.624721415609493
Validation loss: 4.474912074743982
Epoch: 9| Step: 13
Training loss: 4.953259198509812
Validation loss: 4.4495017133793
Epoch: 9| Step: 14
Training loss: 5.344942372567215
Validation loss: 4.454604147911675
Epoch: 9| Step: 15
Training loss: 4.288788555686865
Validation loss: 4.400490211101612
Epoch: 9| Step: 16
Training loss: 4.993956346509721
Validation loss: 4.368982246986447
Epoch: 9| Step: 17
Training loss: 4.688511650273568
Validation loss: 4.3672503322592
Epoch: 9| Step: 18
Training loss: 5.3319704380689705
Validation loss: 4.323948324420273
Epoch: 9| Step: 19
Training loss: 5.294166074793105
Validation loss: 4.307544124156228
Epoch: 9| Step: 0
Training loss: 5.095654090771171
Validation loss: 4.273226567144288
Epoch: 9| Step: 1
Training loss: 4.235530231164845
Validation loss: 4.280402013858544
Epoch: 9| Step: 2
Training loss: 5.249185044750585
Validation loss: 4.248367582464388
Epoch: 9| Step: 3
Training loss: 4.3863717652729335
Validation loss: 4.204293166167581
Epoch: 9| Step: 4
Training loss: 5.624763992444761
Validation loss: 4.180675074544943
Epoch: 9| Step: 5
Training loss: 4.531218850916643
Validation loss: 4.159540007651673
Epoch: 9| Step: 6
Training loss: 4.342742363947465
Validation loss: 4.147641126193398
Epoch: 9| Step: 7
Training loss: 4.621432191220258
Validation loss: 4.107811670392474
Epoch: 9| Step: 8
Training loss: 4.624496844991457
Validation loss: 4.067703173094853
Epoch: 9| Step: 9
Training loss: 4.49935315039536
Validation loss: 4.060092336401893
Epoch: 9| Step: 10
Training loss: 5.131080555876943
Validation loss: 4.0236478998432315
Epoch: 9| Step: 11
Training loss: 4.772363719882792
Validation loss: 4.004558431473696
Epoch: 9| Step: 12
Training loss: 3.7879294677580733
Validation loss: 3.9707551516033903
Epoch: 9| Step: 13
Training loss: 3.901445531714941
Validation loss: 3.925444872446185
Epoch: 9| Step: 14
Training loss: 4.334934427893994
Validation loss: 3.904754704494574
Epoch: 9| Step: 15
Training loss: 3.7912525887107877
Validation loss: 3.901999103347755
Epoch: 9| Step: 16
Training loss: 4.391333471949634
Validation loss: 3.8559397759497926
Epoch: 9| Step: 17
Training loss: 4.598073157738578
Validation loss: 3.844434174044134
Epoch: 9| Step: 18
Training loss: 4.428567411710965
Validation loss: 3.790435609423846
Epoch: 9| Step: 19
Training loss: 3.8248662040098425
Validation loss: 3.780137287451716
Epoch: 10| Step: 0
Training loss: 4.656535504695968
Validation loss: 3.7581642109462043
Epoch: 9| Step: 1
Training loss: 3.8324236965359804
Validation loss: 3.704692949315307
Epoch: 9| Step: 2
Training loss: 3.330405443499458
Validation loss: 3.6999419346512368
Epoch: 9| Step: 3
Training loss: 4.010846690452828
Validation loss: 3.6508632113809765
Epoch: 9| Step: 4
Training loss: 4.53344988860096
Validation loss: 3.6248382696614363
Epoch: 9| Step: 5
Training loss: 4.177419571253526
Validation loss: 3.609496379941765
Epoch: 9| Step: 6
Training loss: 4.068620736548932
Validation loss: 3.5886101321235646
Epoch: 9| Step: 7
Training loss: 4.901087286071669
Validation loss: 3.539002485488538
Epoch: 9| Step: 8
Training loss: 3.822882102096312
Validation loss: 3.5296499436233137
Epoch: 9| Step: 9
Training loss: 3.5695419314703254
Validation loss: 3.4898200427493995
Epoch: 9| Step: 10
Training loss: 3.6899350418534667
Validation loss: 3.4534898015368416
Epoch: 9| Step: 11
Training loss: 3.9758304903980637
Validation loss: 3.4152681287172917
Epoch: 9| Step: 12
Training loss: 4.334632800960773
Validation loss: 3.3696213595468825
Epoch: 9| Step: 13
Training loss: 3.7753767318193674
Validation loss: 3.3714515678056984
Epoch: 9| Step: 14
Training loss: 3.7518829704529177
Validation loss: 3.3466525846980706
Epoch: 9| Step: 15
Training loss: 3.973107536437159
Validation loss: 3.302785203870895
Epoch: 9| Step: 16
Training loss: 3.071364205658663
Validation loss: 3.276649360337314
Epoch: 9| Step: 17
Training loss: 4.085092490000131
Validation loss: 3.247138801323448
Epoch: 9| Step: 18
Training loss: 4.440853946805216
Validation loss: 3.223753384004333
Epoch: 9| Step: 19
Training loss: 3.5458368470966097
Validation loss: 3.175152161964077
Epoch: 11| Step: 0
Training loss: 4.451009468707896
Validation loss: 3.1684646433485435
Epoch: 9| Step: 1
Training loss: 4.27561858760117
Validation loss: 3.1399821189115715
Epoch: 9| Step: 2
Training loss: 3.8922479760346462
Validation loss: 3.1012181137100048
Epoch: 9| Step: 3
Training loss: 3.177063855387697
Validation loss: 3.060721210478939
Epoch: 9| Step: 4
Training loss: 3.635761204581946
Validation loss: 3.0347504335892888
Epoch: 9| Step: 5
Training loss: 4.602733521346883
Validation loss: 2.9752511289298944
Epoch: 9| Step: 6
Training loss: 2.4644721910359233
Validation loss: 2.975578965276698
Epoch: 9| Step: 7
Training loss: 3.086326555281369
Validation loss: 2.9391435935300034
Epoch: 9| Step: 8
Training loss: 3.454603474189099
Validation loss: 2.923956310224331
Epoch: 9| Step: 9
Training loss: 3.61371645394282
Validation loss: 2.8967970879251492
Epoch: 9| Step: 10
Training loss: 3.8014054761035423
Validation loss: 2.8661848444393336
Epoch: 9| Step: 11
Training loss: 2.971748042879626
Validation loss: 2.8377689474167416
Epoch: 9| Step: 12
Training loss: 2.0324865245489683
Validation loss: 2.803444703188226
Epoch: 9| Step: 13
Training loss: 3.4393430450690783
Validation loss: 2.78719644727548
Epoch: 9| Step: 14
Training loss: 3.059127975325875
Validation loss: 2.768652993261557
Epoch: 9| Step: 15
Training loss: 3.470354688474704
Validation loss: 2.739170764877844
Epoch: 9| Step: 16
Training loss: 3.9849924843213516
Validation loss: 2.7163970647926945
Epoch: 9| Step: 17
Training loss: 2.9862680871989786
Validation loss: 2.70239141017227
Epoch: 9| Step: 18
Training loss: 2.810678528014507
Validation loss: 2.6579784568441465
Epoch: 9| Step: 19
Training loss: 2.6732789751204047
Validation loss: 2.6235298603868156
Epoch: 12| Step: 0
Training loss: 2.9489466257423262
Validation loss: 2.6096220665460677
Epoch: 9| Step: 1
Training loss: 1.9862972771003733
Validation loss: 2.5870694577228397
Epoch: 9| Step: 2
Training loss: 3.271480293840738
Validation loss: 2.576779553401944
Epoch: 9| Step: 3
Training loss: 3.9452854268873088
Validation loss: 2.536662706987039
Epoch: 9| Step: 4
Training loss: 3.982702644781617
Validation loss: 2.5174879158757357
Epoch: 9| Step: 5
Training loss: 3.1484211431414444
Validation loss: 2.512287050496208
Epoch: 9| Step: 6
Training loss: 2.964303632146945
Validation loss: 2.4968583162809495
Epoch: 9| Step: 7
Training loss: 3.026415558311812
Validation loss: 2.483182377736846
Epoch: 9| Step: 8
Training loss: 2.7381626598673954
Validation loss: 2.4286791446164746
Epoch: 9| Step: 9
Training loss: 3.105742359703779
Validation loss: 2.449497390946432
Epoch: 9| Step: 10
Training loss: 2.4063984218252363
Validation loss: 2.3901873530785678
Epoch: 9| Step: 11
Training loss: 2.7288834713679466
Validation loss: 2.3539839577208372
Epoch: 9| Step: 12
Training loss: 3.0560427730023547
Validation loss: 2.399865390892391
Epoch: 9| Step: 13
Training loss: 2.6282647130890546
Validation loss: 2.356045116869191
Epoch: 9| Step: 14
Training loss: 2.7047412428428093
Validation loss: 2.3634524480344106
Epoch: 9| Step: 15
Training loss: 3.39880958361797
Validation loss: 2.3638263259798897
Epoch: 9| Step: 16
Training loss: 2.9121788011509606
Validation loss: 2.303448924604589
Epoch: 9| Step: 17
Training loss: 2.602749665347224
Validation loss: 2.3277534485632887
Epoch: 9| Step: 18
Training loss: 3.2468798405131145
Validation loss: 2.3329011099872154
Epoch: 9| Step: 19
Training loss: 2.7186721264439955
Validation loss: 2.3116456008728896
Epoch: 13| Step: 0
Training loss: 3.086894444684183
Validation loss: 2.3110193051756265
Epoch: 9| Step: 1
Training loss: 3.3922281298846433
Validation loss: 2.288853858834987
Epoch: 9| Step: 2
Training loss: 2.9477532187576845
Validation loss: 2.3020457643282963
Epoch: 9| Step: 3
Training loss: 2.6290165281476336
Validation loss: 2.2829277077387364
Epoch: 9| Step: 4
Training loss: 2.378827674708076
Validation loss: 2.286726309426816
Epoch: 9| Step: 5
Training loss: 3.136069870812693
Validation loss: 2.291028504678022
Epoch: 9| Step: 6
Training loss: 2.7353273313702715
Validation loss: 2.2789355313009647
Epoch: 9| Step: 7
Training loss: 2.7847214368743507
Validation loss: 2.2789555421662477
Epoch: 9| Step: 8
Training loss: 2.9838769307363804
Validation loss: 2.2406554580300675
Epoch: 9| Step: 9
Training loss: 2.240369957277412
Validation loss: 2.2470194040926055
Epoch: 9| Step: 10
Training loss: 3.3243197326024934
Validation loss: 2.258753135511911
Epoch: 9| Step: 11
Training loss: 2.8237766114999348
Validation loss: 2.253430707668463
Epoch: 9| Step: 12
Training loss: 2.0483447905743306
Validation loss: 2.264713311104961
Epoch: 9| Step: 13
Training loss: 2.651866572157868
Validation loss: 2.2265030802396115
Epoch: 9| Step: 14
Training loss: 2.470145108983688
Validation loss: 2.2566253819074102
Epoch: 9| Step: 15
Training loss: 2.16823574862068
Validation loss: 2.2629251272740833
Epoch: 9| Step: 16
Training loss: 2.6037800819831216
Validation loss: 2.2499709058496418
Epoch: 9| Step: 17
Training loss: 3.2680479853082547
Validation loss: 2.2206957047103644
Epoch: 9| Step: 18
Training loss: 2.3710857058141963
Validation loss: 2.264497594368765
Epoch: 9| Step: 19
Training loss: 2.888342868930802
Validation loss: 2.268506508678702
Epoch: 14| Step: 0
Training loss: 3.1234458110292285
Validation loss: 2.2541275675285104
Epoch: 9| Step: 1
Training loss: 3.513109451582576
Validation loss: 2.2394369421752063
Epoch: 9| Step: 2
Training loss: 3.4057364820413545
Validation loss: 2.263642367212296
Epoch: 9| Step: 3
Training loss: 2.6215985376325435
Validation loss: 2.2834773803896398
Epoch: 9| Step: 4
Training loss: 2.0229341919359523
Validation loss: 2.2590694300462975
Epoch: 9| Step: 5
Training loss: 3.346696357696664
Validation loss: 2.2760451390045797
Epoch: 9| Step: 6
Training loss: 1.9040668055130228
Validation loss: 2.2723107049069156
Epoch: 9| Step: 7
Training loss: 2.2088437360250275
Validation loss: 2.2644987773050067
Epoch: 9| Step: 8
Training loss: 2.9276921916261434
Validation loss: 2.255241302879701
Epoch: 9| Step: 9
Training loss: 2.8559536502613985
Validation loss: 2.2625263807948994
Epoch: 9| Step: 10
Training loss: 2.422209981086356
Validation loss: 2.266823675168651
Epoch: 9| Step: 11
Training loss: 2.2621717773430734
Validation loss: 2.246122113378486
Epoch: 9| Step: 12
Training loss: 2.9057830107211218
Validation loss: 2.2546806778294273
Epoch: 9| Step: 13
Training loss: 2.675787665366397
Validation loss: 2.2682242308904694
Epoch: 9| Step: 14
Training loss: 1.5689577550215419
Validation loss: 2.2988587634602053
Epoch: 9| Step: 15
Training loss: 2.4063750395550674
Validation loss: 2.283095209009535
Epoch: 9| Step: 16
Training loss: 2.7578772518347776
Validation loss: 2.265408588166457
Epoch: 9| Step: 17
Training loss: 3.2089023498342053
Validation loss: 2.2634991837694183
Epoch: 9| Step: 18
Training loss: 2.407224185470429
Validation loss: 2.255383292191257
Epoch: 9| Step: 19
Training loss: 3.2783380575554895
Validation loss: 2.258452095194978
Epoch: 15| Step: 0
Training loss: 2.9092896675355147
Validation loss: 2.2899718763364585
Epoch: 9| Step: 1
Training loss: 1.870282915306819
Validation loss: 2.2507262466917592
Epoch: 9| Step: 2
Training loss: 2.3894612590158064
Validation loss: 2.259044947315488
Epoch: 9| Step: 3
Training loss: 2.5577076083553543
Validation loss: 2.266986587591845
Epoch: 9| Step: 4
Training loss: 3.374518889997897
Validation loss: 2.2511543978600086
Epoch: 9| Step: 5
Training loss: 2.3489805729413056
Validation loss: 2.2443780225233936
Epoch: 9| Step: 6
Training loss: 1.8570561414951339
Validation loss: 2.2257935120793415
Epoch: 9| Step: 7
Training loss: 2.5420115085824504
Validation loss: 2.223398756363867
Epoch: 9| Step: 8
Training loss: 3.111700827096576
Validation loss: 2.194854685261767
Epoch: 9| Step: 9
Training loss: 2.8647194200037602
Validation loss: 2.2729475001449235
Epoch: 9| Step: 10
Training loss: 2.650071261905285
Validation loss: 2.2737679835709104
Epoch: 9| Step: 11
Training loss: 2.31575092997713
Validation loss: 2.2647477851502993
Epoch: 9| Step: 12
Training loss: 2.1814299151266296
Validation loss: 2.2550447788946584
Epoch: 9| Step: 13
Training loss: 2.45277917453164
Validation loss: 2.2605593323717055
Epoch: 9| Step: 14
Training loss: 2.5846772133677054
Validation loss: 2.262093006166251
Epoch: 9| Step: 15
Training loss: 3.5657416870388303
Validation loss: 2.2446597627599165
Epoch: 9| Step: 16
Training loss: 3.440829797066808
Validation loss: 2.2575089191915243
Epoch: 9| Step: 17
Training loss: 2.8352813381961997
Validation loss: 2.269366833533916
Epoch: 9| Step: 18
Training loss: 2.6807760357704598
Validation loss: 2.266120061481404
Epoch: 9| Step: 19
Training loss: 3.1217616277352747
Validation loss: 2.246183451119636
Epoch: 16| Step: 0
Training loss: 2.658111368875827
Validation loss: 2.18056768540182
Epoch: 9| Step: 1
Training loss: 2.184431266878589
Validation loss: 2.2751325267533433
Epoch: 9| Step: 2
Training loss: 2.1707484115810924
Validation loss: 2.2748558087317803
Epoch: 9| Step: 3
Training loss: 2.4531645559049617
Validation loss: 2.2702655645889016
Epoch: 9| Step: 4
Training loss: 2.486514339980215
Validation loss: 2.263242889255846
Epoch: 9| Step: 5
Training loss: 3.3208886218922897
Validation loss: 2.2638576035846154
Epoch: 9| Step: 6
Training loss: 2.702193965328419
Validation loss: 2.2460457731167502
Epoch: 9| Step: 7
Training loss: 2.85967682459709
Validation loss: 2.2674637042704946
Epoch: 9| Step: 8
Training loss: 2.8984766543640736
Validation loss: 2.2468327685051506
Epoch: 9| Step: 9
Training loss: 2.9336418625382206
Validation loss: 2.2333733989245177
Epoch: 9| Step: 10
Training loss: 3.208130735135447
Validation loss: 2.2317573361986174
Epoch: 9| Step: 11
Training loss: 2.651865133662304
Validation loss: 2.2160820760954834
Epoch: 9| Step: 12
Training loss: 2.675963190951739
Validation loss: 2.24339366783638
Epoch: 9| Step: 13
Training loss: 1.5948049008621603
Validation loss: 2.2224920746205177
Epoch: 9| Step: 14
Training loss: 2.809809436241747
Validation loss: 2.2471443247577736
Epoch: 9| Step: 15
Training loss: 3.052459294378133
Validation loss: 2.2338395762556953
Epoch: 9| Step: 16
Training loss: 2.529669939608117
Validation loss: 2.252385388376727
Epoch: 9| Step: 17
Training loss: 3.312355182289136
Validation loss: 2.2092607393555204
Epoch: 9| Step: 18
Training loss: 3.22483265760499
Validation loss: 2.1697943587206123
Epoch: 9| Step: 19
Training loss: 1.9773627308537771
Validation loss: 2.237963236282125
Epoch: 17| Step: 0
Training loss: 2.3092547146620097
Validation loss: 2.241473013301761
Epoch: 9| Step: 1
Training loss: 2.6488942340431363
Validation loss: 2.2178464248117744
Epoch: 9| Step: 2
Training loss: 2.3392861136433
Validation loss: 2.2223859469439082
Epoch: 9| Step: 3
Training loss: 2.9203103511959556
Validation loss: 2.228811377570353
Epoch: 9| Step: 4
Training loss: 2.3938401486625276
Validation loss: 2.2262070931732554
Epoch: 9| Step: 5
Training loss: 2.9273939590077984
Validation loss: 2.208147329178394
Epoch: 9| Step: 6
Training loss: 2.4535997259420337
Validation loss: 2.212895412551277
Epoch: 9| Step: 7
Training loss: 1.990330627330107
Validation loss: 2.2461854542682596
Epoch: 9| Step: 8
Training loss: 2.550218131515527
Validation loss: 2.2058792590061103
Epoch: 9| Step: 9
Training loss: 3.056859329735667
Validation loss: 2.2366479109007793
Epoch: 9| Step: 10
Training loss: 2.9677509433788862
Validation loss: 2.23427481641023
Epoch: 9| Step: 11
Training loss: 2.1009598899691144
Validation loss: 2.2628819243845433
Epoch: 9| Step: 12
Training loss: 3.3703431391130207
Validation loss: 2.2429817452617136
Epoch: 9| Step: 13
Training loss: 2.286821642073612
Validation loss: 2.2473945289432864
Epoch: 9| Step: 14
Training loss: 2.2768363583699665
Validation loss: 2.2440691940837056
Epoch: 9| Step: 15
Training loss: 2.6352212906339294
Validation loss: 2.243500246070476
Epoch: 9| Step: 16
Training loss: 2.8736637161263925
Validation loss: 2.210348844963026
Epoch: 9| Step: 17
Training loss: 3.3425046794347884
Validation loss: 2.2552395845356177
Epoch: 9| Step: 18
Training loss: 3.3297318712032125
Validation loss: 2.258700362889673
Epoch: 9| Step: 19
Training loss: 2.7487429433387707
Validation loss: 2.2605953109613615
Epoch: 18| Step: 0
Training loss: 1.8854784314346513
Validation loss: 2.237148826555666
Epoch: 9| Step: 1
Training loss: 2.097685914922049
Validation loss: 2.246136753552618
Epoch: 9| Step: 2
Training loss: 2.763893835637337
Validation loss: 2.2481564335666158
Epoch: 9| Step: 3
Training loss: 2.9575662469095088
Validation loss: 2.2231170537512943
Epoch: 9| Step: 4
Training loss: 3.1063493739606094
Validation loss: 2.2427610404345537
Epoch: 9| Step: 5
Training loss: 2.687641672348018
Validation loss: 2.2671436108849323
Epoch: 9| Step: 6
Training loss: 2.104062546775791
Validation loss: 2.2381787907038557
Epoch: 9| Step: 7
Training loss: 2.247231051230275
Validation loss: 2.2175131681317506
Epoch: 9| Step: 8
Training loss: 2.6559238906836633
Validation loss: 2.2063838379581706
Epoch: 9| Step: 9
Training loss: 3.0193493234327926
Validation loss: 2.2510669194404094
Epoch: 9| Step: 10
Training loss: 2.5085387322194013
Validation loss: 2.2623075118600733
Epoch: 9| Step: 11
Training loss: 2.643618630466276
Validation loss: 2.2514508365984827
Epoch: 9| Step: 12
Training loss: 2.2482114676931078
Validation loss: 2.2217174954867396
Epoch: 9| Step: 13
Training loss: 2.7590349205989977
Validation loss: 2.241433812240041
Epoch: 9| Step: 14
Training loss: 1.8894899602473383
Validation loss: 2.2483494136546733
Epoch: 9| Step: 15
Training loss: 3.2143775351594277
Validation loss: 2.2338441242438125
Epoch: 9| Step: 16
Training loss: 3.4523221977132623
Validation loss: 2.257544310757976
Epoch: 9| Step: 17
Training loss: 3.250422670316211
Validation loss: 2.2529560048542483
Epoch: 9| Step: 18
Training loss: 3.099693830814198
Validation loss: 2.2133308722264946
Epoch: 9| Step: 19
Training loss: 2.4964291820295386
Validation loss: 2.2462827011843194
Epoch: 19| Step: 0
Training loss: 2.8408614359239905
Validation loss: 2.2620521294932394
Epoch: 9| Step: 1
Training loss: 2.196742125137921
Validation loss: 2.2332223821110455
Epoch: 9| Step: 2
Training loss: 2.686515627828525
Validation loss: 2.222304370047957
Epoch: 9| Step: 3
Training loss: 2.701256519682226
Validation loss: 2.254392604991474
Epoch: 9| Step: 4
Training loss: 2.2872203927007946
Validation loss: 2.2079735080149385
Epoch: 9| Step: 5
Training loss: 1.7926517779842202
Validation loss: 2.209800195373443
Epoch: 9| Step: 6
Training loss: 2.9810932750012724
Validation loss: 2.21881512504494
Epoch: 9| Step: 7
Training loss: 3.089945447866123
Validation loss: 2.2079280878368346
Epoch: 9| Step: 8
Training loss: 3.196131967238204
Validation loss: 2.2118582397204523
Epoch: 9| Step: 9
Training loss: 2.2611722137584827
Validation loss: 2.2036412173826907
Epoch: 9| Step: 10
Training loss: 2.681685700839977
Validation loss: 2.208728543556295
Epoch: 9| Step: 11
Training loss: 2.672729177185305
Validation loss: 2.219617168325624
Epoch: 9| Step: 12
Training loss: 2.247752232469535
Validation loss: 2.223436901394741
Epoch: 9| Step: 13
Training loss: 2.9211411804119356
Validation loss: 2.1929914500874053
Epoch: 9| Step: 14
Training loss: 3.3332205435426157
Validation loss: 2.2312064445041395
Epoch: 9| Step: 15
Training loss: 2.3030428950712327
Validation loss: 2.242011903695404
Epoch: 9| Step: 16
Training loss: 2.9905191655899386
Validation loss: 2.201394454628512
Epoch: 9| Step: 17
Training loss: 2.437682120537576
Validation loss: 2.1741675082047567
Epoch: 9| Step: 18
Training loss: 3.2206530824455184
Validation loss: 2.182072051907369
Epoch: 9| Step: 19
Training loss: 2.3118800801522736
Validation loss: 2.212875178178166
Epoch: 20| Step: 0
Training loss: 2.967288330036253
Validation loss: 2.208251708521
Epoch: 9| Step: 1
Training loss: 2.533572791310166
Validation loss: 2.2285025395197606
Epoch: 9| Step: 2
Training loss: 2.6837708083022593
Validation loss: 2.222450185002037
Epoch: 9| Step: 3
Training loss: 2.937877711909445
Validation loss: 2.230644530893524
Epoch: 9| Step: 4
Training loss: 2.719519319976616
Validation loss: 2.2166025621939904
Epoch: 9| Step: 5
Training loss: 2.630748449081316
Validation loss: 2.1981442042314927
Epoch: 9| Step: 6
Training loss: 2.3345210140783355
Validation loss: 2.2073147099124477
Epoch: 9| Step: 7
Training loss: 1.9673255126631355
Validation loss: 2.2354421151252692
Epoch: 9| Step: 8
Training loss: 3.0138522456959826
Validation loss: 2.2118595463754134
Epoch: 9| Step: 9
Training loss: 3.0185758552315067
Validation loss: 2.2056312068634303
Epoch: 9| Step: 10
Training loss: 2.1566067828905484
Validation loss: 2.2414862177695793
Epoch: 9| Step: 11
Training loss: 2.453556290149689
Validation loss: 2.2087465512414073
Epoch: 9| Step: 12
Training loss: 2.0760419917995607
Validation loss: 2.2219244503578395
Epoch: 9| Step: 13
Training loss: 2.683412237567097
Validation loss: 2.2147934570893515
Epoch: 9| Step: 14
Training loss: 2.7647553709229618
Validation loss: 2.2026220221728927
Epoch: 9| Step: 15
Training loss: 2.989387177911702
Validation loss: 2.208902297863466
Epoch: 9| Step: 16
Training loss: 3.2023475261665038
Validation loss: 2.2230916108630576
Epoch: 9| Step: 17
Training loss: 2.139628045922057
Validation loss: 2.216074366826836
Epoch: 9| Step: 18
Training loss: 2.9579602574895585
Validation loss: 2.207994331251301
Epoch: 9| Step: 19
Training loss: 2.6768288893450083
Validation loss: 2.1917589851983634
Epoch: 21| Step: 0
Training loss: 1.8453079365698892
Validation loss: 2.2241302430423464
Epoch: 9| Step: 1
Training loss: 3.0396956933955193
Validation loss: 2.227471963494134
Epoch: 9| Step: 2
Training loss: 2.279547277979008
Validation loss: 2.1886953939134943
Epoch: 9| Step: 3
Training loss: 2.5254832381328702
Validation loss: 2.2058758813560844
Epoch: 9| Step: 4
Training loss: 3.446265402431888
Validation loss: 2.211756802748285
Epoch: 9| Step: 5
Training loss: 2.803077256764672
Validation loss: 2.217737975428021
Epoch: 9| Step: 6
Training loss: 2.301474811569437
Validation loss: 2.2172090264891313
Epoch: 9| Step: 7
Training loss: 3.337462315721678
Validation loss: 2.20983167980754
Epoch: 9| Step: 8
Training loss: 3.0261429700237916
Validation loss: 2.190449484098483
Epoch: 9| Step: 9
Training loss: 2.367939744530681
Validation loss: 2.2051072507686653
Epoch: 9| Step: 10
Training loss: 3.1913163021863857
Validation loss: 2.2177211853545664
Epoch: 9| Step: 11
Training loss: 2.19636548402503
Validation loss: 2.211819939480535
Epoch: 9| Step: 12
Training loss: 2.1386890428106606
Validation loss: 2.172706027909843
Epoch: 9| Step: 13
Training loss: 2.435222931512795
Validation loss: 2.202745729073283
Epoch: 9| Step: 14
Training loss: 2.6963065705357865
Validation loss: 2.218680142536269
Epoch: 9| Step: 15
Training loss: 3.073093542838335
Validation loss: 2.215196526408311
Epoch: 9| Step: 16
Training loss: 2.9264562258592077
Validation loss: 2.2302572667877505
Epoch: 9| Step: 17
Training loss: 1.8230787223353881
Validation loss: 2.214562480505283
Epoch: 9| Step: 18
Training loss: 2.2475238526365335
Validation loss: 2.221041052520379
Epoch: 9| Step: 19
Training loss: 2.7272067033116305
Validation loss: 2.2030867693683134
Epoch: 22| Step: 0
Training loss: 2.0880370128902666
Validation loss: 2.215403342131461
Epoch: 9| Step: 1
Training loss: 2.1049885671128434
Validation loss: 2.1886185922768413
Epoch: 9| Step: 2
Training loss: 2.7829687401307477
Validation loss: 2.2032371233771904
Epoch: 9| Step: 3
Training loss: 2.8319049675508636
Validation loss: 2.2087582933386165
Epoch: 9| Step: 4
Training loss: 1.9729417046714124
Validation loss: 2.2229172136622766
Epoch: 9| Step: 5
Training loss: 3.4234561141399045
Validation loss: 2.196389745057035
Epoch: 9| Step: 6
Training loss: 1.8961177514769014
Validation loss: 2.190669158837529
Epoch: 9| Step: 7
Training loss: 3.018524673297885
Validation loss: 2.1801653916135906
Epoch: 9| Step: 8
Training loss: 3.012495086792544
Validation loss: 2.189361298785381
Epoch: 9| Step: 9
Training loss: 2.466547695933715
Validation loss: 2.193656722396853
Epoch: 9| Step: 10
Training loss: 2.4341681768388077
Validation loss: 2.2193236122219537
Epoch: 9| Step: 11
Training loss: 2.537765970056028
Validation loss: 2.1947231499988624
Epoch: 9| Step: 12
Training loss: 2.974056119808766
Validation loss: 2.1497788891953893
Epoch: 9| Step: 13
Training loss: 2.7344681206241845
Validation loss: 2.203370546017088
Epoch: 9| Step: 14
Training loss: 3.235325180761364
Validation loss: 2.185058476551646
Epoch: 9| Step: 15
Training loss: 2.48840188013989
Validation loss: 2.19815097639203
Epoch: 9| Step: 16
Training loss: 2.546598454538852
Validation loss: 2.17943760295944
Epoch: 9| Step: 17
Training loss: 2.7691488284434667
Validation loss: 2.208020907990664
Epoch: 9| Step: 18
Training loss: 2.664997194156279
Validation loss: 2.196019335024156
Epoch: 9| Step: 19
Training loss: 2.576512427736999
Validation loss: 2.195575987439147
Epoch: 23| Step: 0
Training loss: 2.4633029771034733
Validation loss: 2.2060944439818124
Epoch: 9| Step: 1
Training loss: 3.1090535520086835
Validation loss: 2.1996123562840473
Epoch: 9| Step: 2
Training loss: 2.6355073533770663
Validation loss: 2.2055030571013203
Epoch: 9| Step: 3
Training loss: 2.819249002816241
Validation loss: 2.1942420418449937
Epoch: 9| Step: 4
Training loss: 2.6491640607835647
Validation loss: 2.178755148237848
Epoch: 9| Step: 5
Training loss: 2.4806950984016822
Validation loss: 2.216376668470006
Epoch: 9| Step: 6
Training loss: 2.7379070031678587
Validation loss: 2.20775269515454
Epoch: 9| Step: 7
Training loss: 2.3590999215549076
Validation loss: 2.1681600297294206
Epoch: 9| Step: 8
Training loss: 2.9905548820925554
Validation loss: 2.2030935063865664
Epoch: 9| Step: 9
Training loss: 2.8034917891266313
Validation loss: 2.214222749745446
Epoch: 9| Step: 10
Training loss: 2.8420133213318914
Validation loss: 2.218708212002802
Epoch: 9| Step: 11
Training loss: 2.639824650027317
Validation loss: 2.204138045960341
Epoch: 9| Step: 12
Training loss: 2.7410852548171545
Validation loss: 2.202635031728151
Epoch: 9| Step: 13
Training loss: 2.779820364081334
Validation loss: 2.203748161582607
Epoch: 9| Step: 14
Training loss: 3.0677886762390507
Validation loss: 2.202187164784656
Epoch: 9| Step: 15
Training loss: 2.5883791365278856
Validation loss: 2.2293007559239113
Epoch: 9| Step: 16
Training loss: 2.4625296150401828
Validation loss: 2.212425596830808
Epoch: 9| Step: 17
Training loss: 2.0762148230947064
Validation loss: 2.1848569282753494
Epoch: 9| Step: 18
Training loss: 2.1388251541462067
Validation loss: 2.1869393643429182
Epoch: 9| Step: 19
Training loss: 2.3582914782293267
Validation loss: 2.161270715386001
Epoch: 24| Step: 0
Training loss: 3.3732953888438986
Validation loss: 2.1665973032035053
Epoch: 9| Step: 1
Training loss: 2.631565240021192
Validation loss: 2.197785395795729
Epoch: 9| Step: 2
Training loss: 2.6529259920463106
Validation loss: 2.2044064296066783
Epoch: 9| Step: 3
Training loss: 2.6534919332263414
Validation loss: 2.197028826633988
Epoch: 9| Step: 4
Training loss: 2.450945815646554
Validation loss: 2.182301934865339
Epoch: 9| Step: 5
Training loss: 2.0440017685108036
Validation loss: 2.1818542778250114
Epoch: 9| Step: 6
Training loss: 2.8783505031454246
Validation loss: 2.1802634908967153
Epoch: 9| Step: 7
Training loss: 2.996585492260609
Validation loss: 2.164820976102008
Epoch: 9| Step: 8
Training loss: 2.3683152738451283
Validation loss: 2.1927475687511455
Epoch: 9| Step: 9
Training loss: 3.019497139603583
Validation loss: 2.1947366403479083
Epoch: 9| Step: 10
Training loss: 2.6481982097720227
Validation loss: 2.2080564178083235
Epoch: 9| Step: 11
Training loss: 2.647568281552141
Validation loss: 2.181771927161857
Epoch: 9| Step: 12
Training loss: 3.300838456419953
Validation loss: 2.182112858869975
Epoch: 9| Step: 13
Training loss: 2.1960152692420287
Validation loss: 2.1855733594366447
Epoch: 9| Step: 14
Training loss: 2.3833971650794563
Validation loss: 2.2099788222396803
Epoch: 9| Step: 15
Training loss: 2.8959209694168795
Validation loss: 2.1781154598132666
Epoch: 9| Step: 16
Training loss: 2.5512149085809344
Validation loss: 2.1572177433614144
Epoch: 9| Step: 17
Training loss: 2.2511280199181356
Validation loss: 2.1941362359091183
Epoch: 9| Step: 18
Training loss: 2.3675268955978925
Validation loss: 2.18431671847691
Epoch: 9| Step: 19
Training loss: 2.2022859314754317
Validation loss: 2.177423908509086
Epoch: 25| Step: 0
Training loss: 2.602719344717314
Validation loss: 2.1718560634326938
Epoch: 9| Step: 1
Training loss: 2.3367063347918053
Validation loss: 2.181026001191808
Epoch: 9| Step: 2
Training loss: 2.834584315266781
Validation loss: 2.185533334247635
Epoch: 9| Step: 3
Training loss: 2.256326892842276
Validation loss: 2.1791609451636176
Epoch: 9| Step: 4
Training loss: 2.823073200986156
Validation loss: 2.185769119653107
Epoch: 9| Step: 5
Training loss: 2.4784581002608324
Validation loss: 2.1707473817381775
Epoch: 9| Step: 6
Training loss: 1.9687335301270419
Validation loss: 2.1747695656676664
Epoch: 9| Step: 7
Training loss: 2.5600280003208478
Validation loss: 2.1648724103520602
Epoch: 9| Step: 8
Training loss: 2.728956859959143
Validation loss: 2.163108381937235
Epoch: 9| Step: 9
Training loss: 2.3256976895863244
Validation loss: 2.1762642891789232
Epoch: 9| Step: 10
Training loss: 2.6133350771619206
Validation loss: 2.1435652152995863
Epoch: 9| Step: 11
Training loss: 3.059539297989549
Validation loss: 2.1462031263113244
Epoch: 9| Step: 12
Training loss: 3.5256659994596897
Validation loss: 2.1711143357222684
Epoch: 9| Step: 13
Training loss: 2.6560967793871795
Validation loss: 2.1500161410437664
Epoch: 9| Step: 14
Training loss: 2.605419884813978
Validation loss: 2.1829228055911694
Epoch: 9| Step: 15
Training loss: 2.7844969409138773
Validation loss: 2.149686617612987
Epoch: 9| Step: 16
Training loss: 2.535281326664651
Validation loss: 2.169993093137632
Epoch: 9| Step: 17
Training loss: 3.0883927633705923
Validation loss: 2.1677533064138266
Epoch: 9| Step: 18
Training loss: 1.9468103486863946
Validation loss: 2.162887900822791
Epoch: 9| Step: 19
Training loss: 2.468834597912664
Validation loss: 2.1662908755930625
Epoch: 26| Step: 0
Training loss: 2.7448894524332124
Validation loss: 2.163873667028262
Epoch: 9| Step: 1
Training loss: 2.3800532139511112
Validation loss: 2.166015442723579
Epoch: 9| Step: 2
Training loss: 2.9551655818808205
Validation loss: 2.179547167856321
Epoch: 9| Step: 3
Training loss: 3.140743424189852
Validation loss: 2.1832401674424347
Epoch: 9| Step: 4
Training loss: 2.172175983458245
Validation loss: 2.179224207810859
Epoch: 9| Step: 5
Training loss: 3.120478754480717
Validation loss: 2.182120170360715
Epoch: 9| Step: 6
Training loss: 2.3384565466758023
Validation loss: 2.134188755167219
Epoch: 9| Step: 7
Training loss: 2.4956294957786094
Validation loss: 2.1789160869642665
Epoch: 9| Step: 8
Training loss: 2.0898110075194976
Validation loss: 2.1364477271221296
Epoch: 9| Step: 9
Training loss: 2.4821306563545047
Validation loss: 2.1667579893682474
Epoch: 9| Step: 10
Training loss: 2.5083389442693704
Validation loss: 2.172021036972981
Epoch: 9| Step: 11
Training loss: 2.3121828428784275
Validation loss: 2.1590815306444373
Epoch: 9| Step: 12
Training loss: 3.2048412656232754
Validation loss: 2.1644743476284676
Epoch: 9| Step: 13
Training loss: 2.990861484341605
Validation loss: 2.1637888092931727
Epoch: 9| Step: 14
Training loss: 3.03659514461949
Validation loss: 2.1622792749602024
Epoch: 9| Step: 15
Training loss: 2.355535351268722
Validation loss: 2.1715305208143287
Epoch: 9| Step: 16
Training loss: 2.207799403103847
Validation loss: 2.1785527185049776
Epoch: 9| Step: 17
Training loss: 2.720334084834356
Validation loss: 2.1565402506451417
Epoch: 9| Step: 18
Training loss: 2.281710539015894
Validation loss: 2.159306382217207
Epoch: 9| Step: 19
Training loss: 2.4779894836239573
Validation loss: 2.1780352851592246
Epoch: 27| Step: 0
Training loss: 2.0202882038021506
Validation loss: 2.1767549371998776
Epoch: 9| Step: 1
Training loss: 2.6059849812447395
Validation loss: 2.1124320118299944
Epoch: 9| Step: 2
Training loss: 2.943856038575
Validation loss: 2.1743197069541456
Epoch: 9| Step: 3
Training loss: 2.808865551271479
Validation loss: 2.1468867907150506
Epoch: 9| Step: 4
Training loss: 2.498138020443096
Validation loss: 2.1717136318565666
Epoch: 9| Step: 5
Training loss: 2.689737763367882
Validation loss: 2.1721674815251815
Epoch: 9| Step: 6
Training loss: 3.7572056524197865
Validation loss: 2.163888662830419
Epoch: 9| Step: 7
Training loss: 1.831584298408155
Validation loss: 2.18741144725824
Epoch: 9| Step: 8
Training loss: 3.0953301912097757
Validation loss: 2.1654597224486625
Epoch: 9| Step: 9
Training loss: 2.7069290824425094
Validation loss: 2.1682011028510586
Epoch: 9| Step: 10
Training loss: 2.793389049997074
Validation loss: 2.1597803504368476
Epoch: 9| Step: 11
Training loss: 2.2905534178827964
Validation loss: 2.179516763127134
Epoch: 9| Step: 12
Training loss: 2.5436420164690583
Validation loss: 2.1739943437178106
Epoch: 9| Step: 13
Training loss: 2.527242054138764
Validation loss: 2.1843872145853087
Epoch: 9| Step: 14
Training loss: 2.1383112076377535
Validation loss: 2.147607945331801
Epoch: 9| Step: 15
Training loss: 2.5068508693129994
Validation loss: 2.1744933763815997
Epoch: 9| Step: 16
Training loss: 3.032566846345068
Validation loss: 2.1681356516451658
Epoch: 9| Step: 17
Training loss: 2.455272924787155
Validation loss: 2.1625959964059396
Epoch: 9| Step: 18
Training loss: 1.912034747310756
Validation loss: 2.1680151814751416
Epoch: 9| Step: 19
Training loss: 2.580931090081261
Validation loss: 2.1689371459526825
Epoch: 28| Step: 0
Training loss: 2.4816376582649906
Validation loss: 2.1723643647335282
Epoch: 9| Step: 1
Training loss: 2.7533017191638276
Validation loss: 2.1804320502787307
Epoch: 9| Step: 2
Training loss: 3.148712524821033
Validation loss: 2.172425963800362
Epoch: 9| Step: 3
Training loss: 2.785646029044843
Validation loss: 2.178895215999591
Epoch: 9| Step: 4
Training loss: 2.794337736089054
Validation loss: 2.1745389147637164
Epoch: 9| Step: 5
Training loss: 2.746028112546822
Validation loss: 2.159607548504518
Epoch: 9| Step: 6
Training loss: 2.5427493514946313
Validation loss: 2.169716389381855
Epoch: 9| Step: 7
Training loss: 2.444655845151401
Validation loss: 2.161063384716842
Epoch: 9| Step: 8
Training loss: 2.603312685498337
Validation loss: 2.1252247692520894
Epoch: 9| Step: 9
Training loss: 2.3402511929726084
Validation loss: 2.1743617460575138
Epoch: 9| Step: 10
Training loss: 2.831730520132073
Validation loss: 2.1470056408272677
Epoch: 9| Step: 11
Training loss: 2.075041124786606
Validation loss: 2.1417414904999976
Epoch: 9| Step: 12
Training loss: 2.4907867417413465
Validation loss: 2.138015179019321
Epoch: 9| Step: 13
Training loss: 2.828006467917032
Validation loss: 2.183950863027004
Epoch: 9| Step: 14
Training loss: 3.2496427192907764
Validation loss: 2.164908710827818
Epoch: 9| Step: 15
Training loss: 2.205868683192963
Validation loss: 2.1490734030239227
Epoch: 9| Step: 16
Training loss: 2.5872576245295007
Validation loss: 2.1802244696200845
Epoch: 9| Step: 17
Training loss: 2.385798550040324
Validation loss: 2.1732163345191835
Epoch: 9| Step: 18
Training loss: 2.6965869488935668
Validation loss: 2.104376704495463
Epoch: 9| Step: 19
Training loss: 2.0687660055319284
Validation loss: 2.1605697852766617
Epoch: 29| Step: 0
Training loss: 2.1144713824724426
Validation loss: 2.175393230073142
Epoch: 9| Step: 1
Training loss: 2.7354777700936026
Validation loss: 2.1281369704628057
Epoch: 9| Step: 2
Training loss: 1.9719750162867198
Validation loss: 2.1527907480609296
Epoch: 9| Step: 3
Training loss: 1.8560857449694594
Validation loss: 2.1704422002792296
Epoch: 9| Step: 4
Training loss: 2.568426768067808
Validation loss: 2.1448300778419838
Epoch: 9| Step: 5
Training loss: 3.2876617275823503
Validation loss: 2.155177444095526
Epoch: 9| Step: 6
Training loss: 2.6491501111087956
Validation loss: 2.146734330076342
Epoch: 9| Step: 7
Training loss: 2.772657601750384
Validation loss: 2.164627448967265
Epoch: 9| Step: 8
Training loss: 2.4584089580046204
Validation loss: 2.1478931056510184
Epoch: 9| Step: 9
Training loss: 1.9658044851379428
Validation loss: 2.1490155350330706
Epoch: 9| Step: 10
Training loss: 2.8233209768548084
Validation loss: 2.1725481610143076
Epoch: 9| Step: 11
Training loss: 3.07890844299037
Validation loss: 2.1604351207467647
Epoch: 9| Step: 12
Training loss: 3.3505001207222724
Validation loss: 2.148917110516494
Epoch: 9| Step: 13
Training loss: 2.6086173413795932
Validation loss: 2.1592622288958165
Epoch: 9| Step: 14
Training loss: 2.023852567188282
Validation loss: 2.1473332599026724
Epoch: 9| Step: 15
Training loss: 2.8554697519449337
Validation loss: 2.1651642241932874
Epoch: 9| Step: 16
Training loss: 2.476085917829417
Validation loss: 2.1435070162154877
Epoch: 9| Step: 17
Training loss: 2.4221008195502347
Validation loss: 2.158159700446246
Epoch: 9| Step: 18
Training loss: 2.852614117411685
Validation loss: 2.1276610693617393
Epoch: 9| Step: 19
Training loss: 2.6999993748134314
Validation loss: 2.169083242326103
Epoch: 30| Step: 0
Training loss: 2.523048394499949
Validation loss: 2.1284113528945823
Epoch: 9| Step: 1
Training loss: 2.533656918623084
Validation loss: 2.142828993400122
Epoch: 9| Step: 2
Training loss: 2.6924111493113445
Validation loss: 2.1415172697959015
Epoch: 9| Step: 3
Training loss: 3.4929152035603006
Validation loss: 2.1591287613720826
Epoch: 9| Step: 4
Training loss: 3.006041483478002
Validation loss: 2.0866116780210873
Epoch: 9| Step: 5
Training loss: 1.7300801066776794
Validation loss: 2.164642334948995
Epoch: 9| Step: 6
Training loss: 2.60456157487483
Validation loss: 2.1829787694862524
Epoch: 9| Step: 7
Training loss: 2.8234166527185875
Validation loss: 2.1661091453523476
Epoch: 9| Step: 8
Training loss: 2.518878609755459
Validation loss: 2.1291903618590284
Epoch: 9| Step: 9
Training loss: 2.674570430596326
Validation loss: 2.1606468405383277
Epoch: 9| Step: 10
Training loss: 2.9236338824193044
Validation loss: 2.1511753698426066
Epoch: 9| Step: 11
Training loss: 2.098020497101042
Validation loss: 2.1501402396392
Epoch: 9| Step: 12
Training loss: 2.698694909767204
Validation loss: 2.175429988506861
Epoch: 9| Step: 13
Training loss: 2.7825659735331
Validation loss: 2.160465441243973
Epoch: 9| Step: 14
Training loss: 2.3713298346996194
Validation loss: 2.164323101611027
Epoch: 9| Step: 15
Training loss: 2.41069225119557
Validation loss: 2.1538530074829385
Epoch: 9| Step: 16
Training loss: 2.5592198661393257
Validation loss: 2.161796218448962
Epoch: 9| Step: 17
Training loss: 2.146861549124302
Validation loss: 2.156783683797945
Epoch: 9| Step: 18
Training loss: 2.9518827217190053
Validation loss: 2.155755311182995
Epoch: 9| Step: 19
Training loss: 2.1026659482947854
Validation loss: 2.1482341472565007
Epoch: 31| Step: 0
Training loss: 2.473241751775558
Validation loss: 2.173589803262928
Epoch: 9| Step: 1
Training loss: 2.7234492412758327
Validation loss: 2.1633617180650075
Epoch: 9| Step: 2
Training loss: 2.604811830076211
Validation loss: 2.1802773656848755
Epoch: 9| Step: 3
Training loss: 2.336541853585578
Validation loss: 2.1492711531872333
Epoch: 9| Step: 4
Training loss: 2.8759293090876104
Validation loss: 2.162844667671041
Epoch: 9| Step: 5
Training loss: 2.281990453661677
Validation loss: 2.16644056245599
Epoch: 9| Step: 6
Training loss: 3.21647815711991
Validation loss: 2.1600550497133675
Epoch: 9| Step: 7
Training loss: 1.6909933313004772
Validation loss: 2.156682323657343
Epoch: 9| Step: 8
Training loss: 2.203608899373136
Validation loss: 2.15170023820042
Epoch: 9| Step: 9
Training loss: 2.5300282485048307
Validation loss: 2.1531287050411554
Epoch: 9| Step: 10
Training loss: 2.477125904005126
Validation loss: 2.1335237803069864
Epoch: 9| Step: 11
Training loss: 1.8736250604528597
Validation loss: 2.162148389596476
Epoch: 9| Step: 12
Training loss: 2.834434594449984
Validation loss: 2.1603826121483314
Epoch: 9| Step: 13
Training loss: 2.5272344126332453
Validation loss: 2.1611926630218545
Epoch: 9| Step: 14
Training loss: 3.4027835110639857
Validation loss: 2.136836106406707
Epoch: 9| Step: 15
Training loss: 2.435546875
Validation loss: 2.1358126685158894
Epoch: 9| Step: 16
Training loss: 2.5649839318201595
Validation loss: 2.160402266204123
Epoch: 9| Step: 17
Training loss: 2.1735887969811163
Validation loss: 2.1487426644948258
Epoch: 9| Step: 18
Training loss: 2.6042332958598653
Validation loss: 2.126885356610132
Epoch: 9| Step: 19
Training loss: 3.4161926188781195
Validation loss: 2.133948718117735
Epoch: 32| Step: 0
Training loss: 2.891637181581532
Validation loss: 2.1477658391050345
Epoch: 9| Step: 1
Training loss: 2.2769431650124203
Validation loss: 2.1523491671890267
Epoch: 9| Step: 2
Training loss: 2.577665160814029
Validation loss: 2.1547686519378186
Epoch: 9| Step: 3
Training loss: 1.837524377570345
Validation loss: 2.131484414813806
Epoch: 9| Step: 4
Training loss: 2.542858678073328
Validation loss: 2.145966279453287
Epoch: 9| Step: 5
Training loss: 2.1676330856419694
Validation loss: 2.1213192260301974
Epoch: 9| Step: 6
Training loss: 2.634990572252002
Validation loss: 2.149182334215147
Epoch: 9| Step: 7
Training loss: 2.811567703009906
Validation loss: 2.1354055256309024
Epoch: 9| Step: 8
Training loss: 2.9823617585624227
Validation loss: 2.1564188182407835
Epoch: 9| Step: 9
Training loss: 2.659691230808062
Validation loss: 2.1455285646034024
Epoch: 9| Step: 10
Training loss: 3.183713870912526
Validation loss: 2.158147299919058
Epoch: 9| Step: 11
Training loss: 1.8380569236831885
Validation loss: 2.131952118693484
Epoch: 9| Step: 12
Training loss: 2.394619465582941
Validation loss: 2.152788221794606
Epoch: 9| Step: 13
Training loss: 2.039521030595351
Validation loss: 2.124954457808926
Epoch: 9| Step: 14
Training loss: 2.6370129682491807
Validation loss: 2.1300407594641393
Epoch: 9| Step: 15
Training loss: 2.924663824341628
Validation loss: 2.1460373377622166
Epoch: 9| Step: 16
Training loss: 2.6561068327973305
Validation loss: 2.130482927354234
Epoch: 9| Step: 17
Training loss: 2.664639676124459
Validation loss: 2.129171264410741
Epoch: 9| Step: 18
Training loss: 2.9588959029162267
Validation loss: 2.1240693259109973
Epoch: 9| Step: 19
Training loss: 2.503580104874261
Validation loss: 2.1414238257492597
Epoch: 33| Step: 0
Training loss: 2.3827532651448813
Validation loss: 2.151075192202664
Epoch: 9| Step: 1
Training loss: 2.119778782260988
Validation loss: 2.1411532910157396
Epoch: 9| Step: 2
Training loss: 3.1160257799112925
Validation loss: 2.1394702178590994
Epoch: 9| Step: 3
Training loss: 3.060557781071028
Validation loss: 2.1434289751324687
Epoch: 9| Step: 4
Training loss: 1.9634417467133616
Validation loss: 2.146397552880594
Epoch: 9| Step: 5
Training loss: 2.167978867515806
Validation loss: 2.114775349154062
Epoch: 9| Step: 6
Training loss: 2.384017889595755
Validation loss: 2.114671975257472
Epoch: 9| Step: 7
Training loss: 2.403643000894836
Validation loss: 2.1425134055372337
Epoch: 9| Step: 8
Training loss: 3.3327598714272386
Validation loss: 2.1158495089126528
Epoch: 9| Step: 9
Training loss: 2.7517562806640106
Validation loss: 2.1312071139220503
Epoch: 9| Step: 10
Training loss: 3.0141651790644404
Validation loss: 2.1299562012542284
Epoch: 9| Step: 11
Training loss: 2.7759559050309184
Validation loss: 2.14239736660035
Epoch: 9| Step: 12
Training loss: 1.6165981969721144
Validation loss: 2.131969602735285
Epoch: 9| Step: 13
Training loss: 2.5217507219477104
Validation loss: 2.1102715416718616
Epoch: 9| Step: 14
Training loss: 1.8679633663391875
Validation loss: 2.1390735357099877
Epoch: 9| Step: 15
Training loss: 2.5977913498702967
Validation loss: 2.1411025440505607
Epoch: 9| Step: 16
Training loss: 2.443787510576684
Validation loss: 2.1316194736736858
Epoch: 9| Step: 17
Training loss: 2.3959248953751793
Validation loss: 2.1319409919161414
Epoch: 9| Step: 18
Training loss: 3.0863707419377624
Validation loss: 2.0919030142189516
Epoch: 9| Step: 19
Training loss: 2.9224448234890406
Validation loss: 2.1230906976674615
Epoch: 34| Step: 0
Training loss: 3.1109058694654066
Validation loss: 2.1380282208579753
Epoch: 9| Step: 1
Training loss: 2.2006442123826853
Validation loss: 2.120820216279405
Epoch: 9| Step: 2
Training loss: 2.753419657255312
Validation loss: 2.141027806121234
Epoch: 9| Step: 3
Training loss: 3.3345356839047153
Validation loss: 2.1111109800867376
Epoch: 9| Step: 4
Training loss: 2.3885203552848076
Validation loss: 2.1160277647311307
Epoch: 9| Step: 5
Training loss: 2.7787513224280707
Validation loss: 2.1095891915853784
Epoch: 9| Step: 6
Training loss: 1.7354081659311078
Validation loss: 2.135695663917284
Epoch: 9| Step: 7
Training loss: 2.5391928301887265
Validation loss: 2.1597783090466116
Epoch: 9| Step: 8
Training loss: 2.653051447663191
Validation loss: 2.1310219303741205
Epoch: 9| Step: 9
Training loss: 3.02186500208403
Validation loss: 2.137271835921071
Epoch: 9| Step: 10
Training loss: 2.881215881013245
Validation loss: 2.16344618354298
Epoch: 9| Step: 11
Training loss: 2.4039727867223784
Validation loss: 2.1409276942560327
Epoch: 9| Step: 12
Training loss: 2.7293635193007
Validation loss: 2.160532648221075
Epoch: 9| Step: 13
Training loss: 1.6710825673175465
Validation loss: 2.1473806031375906
Epoch: 9| Step: 14
Training loss: 2.411811742296554
Validation loss: 2.170699891635512
Epoch: 9| Step: 15
Training loss: 2.3611213334803476
Validation loss: 2.1592567903823854
Epoch: 9| Step: 16
Training loss: 1.967783615048122
Validation loss: 2.1287688385504073
Epoch: 9| Step: 17
Training loss: 3.5254353951018054
Validation loss: 2.15749533119964
Epoch: 9| Step: 18
Training loss: 2.419938229805004
Validation loss: 2.122094950282167
Epoch: 9| Step: 19
Training loss: 1.9373672809059406
Validation loss: 2.1566394482841726
Epoch: 35| Step: 0
Training loss: 2.4190052380798828
Validation loss: 2.1472184169777533
Epoch: 9| Step: 1
Training loss: 2.901205463453824
Validation loss: 2.1559172120494643
Epoch: 9| Step: 2
Training loss: 2.7205551994513395
Validation loss: 2.15965715675445
Epoch: 9| Step: 3
Training loss: 2.312573405982314
Validation loss: 2.1515158724922228
Epoch: 9| Step: 4
Training loss: 2.049422447909439
Validation loss: 2.133830024568882
Epoch: 9| Step: 5
Training loss: 2.750154577592517
Validation loss: 2.110965747121251
Epoch: 9| Step: 6
Training loss: 2.5710577072913807
Validation loss: 2.0921010199392174
Epoch: 9| Step: 7
Training loss: 2.4450345109871585
Validation loss: 2.0823682600202074
Epoch: 9| Step: 8
Training loss: 2.101330939373034
Validation loss: 2.1186481838481153
Epoch: 9| Step: 9
Training loss: 2.4332588663420758
Validation loss: 2.1181369090962288
Epoch: 9| Step: 10
Training loss: 3.212410025319988
Validation loss: 2.116116482544463
Epoch: 9| Step: 11
Training loss: 2.469110100474043
Validation loss: 2.0990872443057946
Epoch: 9| Step: 12
Training loss: 2.760296877775032
Validation loss: 2.104077388680178
Epoch: 9| Step: 13
Training loss: 3.0466180155046447
Validation loss: 2.0952250273435533
Epoch: 9| Step: 14
Training loss: 1.903665510320315
Validation loss: 2.1332273465649596
Epoch: 9| Step: 15
Training loss: 2.2362468854649
Validation loss: 2.1019504506534235
Epoch: 9| Step: 16
Training loss: 2.7272727937409362
Validation loss: 2.1353474663293124
Epoch: 9| Step: 17
Training loss: 1.8438106462235209
Validation loss: 2.1132835936654986
Epoch: 9| Step: 18
Training loss: 2.993516910533886
Validation loss: 2.1163084065965156
Epoch: 9| Step: 19
Training loss: 2.8308362241619247
Validation loss: 2.085677784550167
Epoch: 36| Step: 0
Training loss: 2.6369407277800065
Validation loss: 2.084525358568832
Epoch: 9| Step: 1
Training loss: 2.6929911914373994
Validation loss: 2.095212963475168
Epoch: 9| Step: 2
Training loss: 2.2798295497759242
Validation loss: 2.1082484311688714
Epoch: 9| Step: 3
Training loss: 1.936290486493051
Validation loss: 2.12016713803852
Epoch: 9| Step: 4
Training loss: 3.0910097567337353
Validation loss: 2.1452802282197423
Epoch: 9| Step: 5
Training loss: 2.9987138534345474
Validation loss: 2.115797002502255
Epoch: 9| Step: 6
Training loss: 2.3013371312576787
Validation loss: 2.131895890196197
Epoch: 9| Step: 7
Training loss: 2.989747967766949
Validation loss: 2.0978030427405363
Epoch: 9| Step: 8
Training loss: 2.4309536005485626
Validation loss: 2.14646289618979
Epoch: 9| Step: 9
Training loss: 2.3028087134814803
Validation loss: 2.11419440239468
Epoch: 9| Step: 10
Training loss: 2.7922275226544566
Validation loss: 2.1086083609947197
Epoch: 9| Step: 11
Training loss: 2.677279889402894
Validation loss: 2.123320429866303
Epoch: 9| Step: 12
Training loss: 3.02306495756722
Validation loss: 2.1020446447598946
Epoch: 9| Step: 13
Training loss: 2.750199484092204
Validation loss: 2.1402682158562056
Epoch: 9| Step: 14
Training loss: 2.4898519543984494
Validation loss: 2.114879645304595
Epoch: 9| Step: 15
Training loss: 2.328891192838307
Validation loss: 2.12541989915574
Epoch: 9| Step: 16
Training loss: 2.08387637372441
Validation loss: 2.090472472492301
Epoch: 9| Step: 17
Training loss: 2.3119895990395145
Validation loss: 2.104103603904292
Epoch: 9| Step: 18
Training loss: 2.6107882024973916
Validation loss: 2.1198739143944443
Epoch: 9| Step: 19
Training loss: 2.2543600012415395
Validation loss: 2.12221400920637
Epoch: 37| Step: 0
Training loss: 2.6977665882761865
Validation loss: 2.1175166006024555
Epoch: 9| Step: 1
Training loss: 2.6730799049567695
Validation loss: 2.081057519679268
Epoch: 9| Step: 2
Training loss: 2.190247037009726
Validation loss: 2.1117822570932323
Epoch: 9| Step: 3
Training loss: 2.3080271172343623
Validation loss: 2.1154658334654344
Epoch: 9| Step: 4
Training loss: 3.4961438052893623
Validation loss: 2.1081814207939087
Epoch: 9| Step: 5
Training loss: 1.7803342372537496
Validation loss: 2.1376037195261492
Epoch: 9| Step: 6
Training loss: 2.753792661664545
Validation loss: 2.1313172947657417
Epoch: 9| Step: 7
Training loss: 2.569775093271545
Validation loss: 2.120809508802338
Epoch: 9| Step: 8
Training loss: 2.6027361081303795
Validation loss: 2.111874137152995
Epoch: 9| Step: 9
Training loss: 2.4569180072832997
Validation loss: 2.1370994696743177
Epoch: 9| Step: 10
Training loss: 2.021694773169129
Validation loss: 2.1256233602846697
Epoch: 9| Step: 11
Training loss: 2.258805000720628
Validation loss: 2.128835546433249
Epoch: 9| Step: 12
Training loss: 2.9465795569108733
Validation loss: 2.086144882947231
Epoch: 9| Step: 13
Training loss: 2.5444157434517067
Validation loss: 2.12853973503747
Epoch: 9| Step: 14
Training loss: 3.2449939025915664
Validation loss: 2.1283595338664942
Epoch: 9| Step: 15
Training loss: 2.653650425441214
Validation loss: 2.127269938162858
Epoch: 9| Step: 16
Training loss: 2.661733554611932
Validation loss: 2.1154450599811145
Epoch: 9| Step: 17
Training loss: 2.3872783897566228
Validation loss: 2.119867260623355
Epoch: 9| Step: 18
Training loss: 1.9992084128741279
Validation loss: 2.1055766065635675
Epoch: 9| Step: 19
Training loss: 2.5006158070298756
Validation loss: 2.092749896053846
Epoch: 38| Step: 0
Training loss: 2.50977436464918
Validation loss: 2.112147037885981
Epoch: 9| Step: 1
Training loss: 2.2111141282555695
Validation loss: 2.138842255502624
Epoch: 9| Step: 2
Training loss: 2.464395860220428
Validation loss: 2.104362016925101
Epoch: 9| Step: 3
Training loss: 2.7338403669578177
Validation loss: 2.109416600063673
Epoch: 9| Step: 4
Training loss: 2.45101449164811
Validation loss: 2.1257479370061554
Epoch: 9| Step: 5
Training loss: 1.9398787877470909
Validation loss: 2.1010957430972623
Epoch: 9| Step: 6
Training loss: 2.320512448310957
Validation loss: 2.0964560126184435
Epoch: 9| Step: 7
Training loss: 2.08200468293322
Validation loss: 2.100728935755771
Epoch: 9| Step: 8
Training loss: 2.887069247264599
Validation loss: 2.1496123994255223
Epoch: 9| Step: 9
Training loss: 2.121277859110918
Validation loss: 2.1429729028108526
Epoch: 9| Step: 10
Training loss: 2.694643860960953
Validation loss: 2.0950656340605
Epoch: 9| Step: 11
Training loss: 2.157265686536911
Validation loss: 2.1301276466151124
Epoch: 9| Step: 12
Training loss: 3.175766385314612
Validation loss: 2.1194531043236844
Epoch: 9| Step: 13
Training loss: 2.5695211473534862
Validation loss: 2.11723677810657
Epoch: 9| Step: 14
Training loss: 3.209278132714221
Validation loss: 2.1042141152880705
Epoch: 9| Step: 15
Training loss: 2.6758263354436163
Validation loss: 2.0908143927574456
Epoch: 9| Step: 16
Training loss: 2.0982278794425127
Validation loss: 2.116824058798461
Epoch: 9| Step: 17
Training loss: 2.886339795089921
Validation loss: 2.1052049415770497
Epoch: 9| Step: 18
Training loss: 3.2234493874845183
Validation loss: 2.103230874791708
Epoch: 9| Step: 19
Training loss: 2.188598139193299
Validation loss: 2.12269960586002
Epoch: 39| Step: 0
Training loss: 2.9540629839939636
Validation loss: 2.075762871628311
Epoch: 9| Step: 1
Training loss: 2.720394908482841
Validation loss: 2.100409235550641
Epoch: 9| Step: 2
Training loss: 2.786159853531587
Validation loss: 2.100939736415631
Epoch: 9| Step: 3
Training loss: 2.5823171113978933
Validation loss: 2.127247024414082
Epoch: 9| Step: 4
Training loss: 2.4747038885672943
Validation loss: 2.1132071197198004
Epoch: 9| Step: 5
Training loss: 2.493921328517496
Validation loss: 2.1185140570103167
Epoch: 9| Step: 6
Training loss: 2.869800676076678
Validation loss: 2.104868806898252
Epoch: 9| Step: 7
Training loss: 2.815664757247837
Validation loss: 2.114090803374229
Epoch: 9| Step: 8
Training loss: 2.703943734954882
Validation loss: 2.0822857427410977
Epoch: 9| Step: 9
Training loss: 2.606608311747114
Validation loss: 2.111542867907802
Epoch: 9| Step: 10
Training loss: 1.8095515374219944
Validation loss: 2.0883489493876817
Epoch: 9| Step: 11
Training loss: 2.2404855256450555
Validation loss: 2.0945137006340624
Epoch: 9| Step: 12
Training loss: 2.917260754344371
Validation loss: 2.105629611169947
Epoch: 9| Step: 13
Training loss: 2.60768858727782
Validation loss: 2.0724755265696087
Epoch: 9| Step: 14
Training loss: 2.4436589216738236
Validation loss: 2.0912410870782887
Epoch: 9| Step: 15
Training loss: 2.5346712139228647
Validation loss: 2.089010822151173
Epoch: 9| Step: 16
Training loss: 1.896834336273882
Validation loss: 2.083242608378211
Epoch: 9| Step: 17
Training loss: 2.426138982026261
Validation loss: 2.0670107050726796
Epoch: 9| Step: 18
Training loss: 2.666069639448245
Validation loss: 2.109796265118327
Epoch: 9| Step: 19
Training loss: 2.278100543943983
Validation loss: 2.103920799463564
Epoch: 40| Step: 0
Training loss: 3.068105744211893
Validation loss: 2.07984386284466
Epoch: 9| Step: 1
Training loss: 2.638273557787868
Validation loss: 2.099336891007544
Epoch: 9| Step: 2
Training loss: 2.586783279448196
Validation loss: 2.1122184690356525
Epoch: 9| Step: 3
Training loss: 2.6588323270303675
Validation loss: 2.0941679262590625
Epoch: 9| Step: 4
Training loss: 2.1049762213444447
Validation loss: 2.0613780963089954
Epoch: 9| Step: 5
Training loss: 2.3676755295067147
Validation loss: 2.0895952500716843
Epoch: 9| Step: 6
Training loss: 2.318116147170206
Validation loss: 2.098309380368166
Epoch: 9| Step: 7
Training loss: 2.260302691655269
Validation loss: 2.111518658925706
Epoch: 9| Step: 8
Training loss: 1.957515816460213
Validation loss: 2.104896173781389
Epoch: 9| Step: 9
Training loss: 2.3181791934510194
Validation loss: 2.096963699458636
Epoch: 9| Step: 10
Training loss: 2.485557610564883
Validation loss: 2.1171620464100434
Epoch: 9| Step: 11
Training loss: 3.002550630293449
Validation loss: 2.1110661740736347
Epoch: 9| Step: 12
Training loss: 2.265286755799039
Validation loss: 2.08528764937271
Epoch: 9| Step: 13
Training loss: 3.705408993487898
Validation loss: 2.1003100047815586
Epoch: 9| Step: 14
Training loss: 2.3189156691601074
Validation loss: 2.100247640958682
Epoch: 9| Step: 15
Training loss: 2.2682038461620113
Validation loss: 2.121201891700011
Epoch: 9| Step: 16
Training loss: 2.672554866559433
Validation loss: 2.136582941862721
Epoch: 9| Step: 17
Training loss: 2.486141704274008
Validation loss: 2.1051984049571812
Epoch: 9| Step: 18
Training loss: 2.869709454493686
Validation loss: 2.1084127323117077
Epoch: 9| Step: 19
Training loss: 2.027283301949865
Validation loss: 2.1212652939178085
Epoch: 41| Step: 0
Training loss: 3.4348546339701698
Validation loss: 2.1423210974743454
Epoch: 9| Step: 1
Training loss: 2.776536268841299
Validation loss: 2.091107155118861
Epoch: 9| Step: 2
Training loss: 2.3394479560126147
Validation loss: 2.093684483750777
Epoch: 9| Step: 3
Training loss: 2.793169945359295
Validation loss: 2.0830294754827134
Epoch: 9| Step: 4
Training loss: 1.8348974650369696
Validation loss: 2.1342888365660557
Epoch: 9| Step: 5
Training loss: 1.9691835561838684
Validation loss: 2.1321497994380922
Epoch: 9| Step: 6
Training loss: 2.3854451628958286
Validation loss: 2.111336825443618
Epoch: 9| Step: 7
Training loss: 2.0477260538404907
Validation loss: 2.121804213676873
Epoch: 9| Step: 8
Training loss: 2.474807647012081
Validation loss: 2.1233759390716984
Epoch: 9| Step: 9
Training loss: 2.5803119053931773
Validation loss: 2.0871924207273995
Epoch: 9| Step: 10
Training loss: 2.993115472943702
Validation loss: 2.0869932818157895
Epoch: 9| Step: 11
Training loss: 2.53653438592482
Validation loss: 2.086093847854415
Epoch: 9| Step: 12
Training loss: 2.766989161374695
Validation loss: 2.0735725229208026
Epoch: 9| Step: 13
Training loss: 2.4723376510285484
Validation loss: 2.0944415532381004
Epoch: 9| Step: 14
Training loss: 3.080085865656887
Validation loss: 2.112348793552021
Epoch: 9| Step: 15
Training loss: 2.190322036580896
Validation loss: 2.1123760374459417
Epoch: 9| Step: 16
Training loss: 2.505969930396856
Validation loss: 2.102441818534593
Epoch: 9| Step: 17
Training loss: 2.269731680182575
Validation loss: 2.0985836842367256
Epoch: 9| Step: 18
Training loss: 2.3544858080391076
Validation loss: 2.1176299196487594
Epoch: 9| Step: 19
Training loss: 2.363590541808926
Validation loss: 2.111267767073161
Epoch: 42| Step: 0
Training loss: 1.92942332571471
Validation loss: 2.0879079425071905
Epoch: 9| Step: 1
Training loss: 2.4455637452360426
Validation loss: 2.0914665539240382
Epoch: 9| Step: 2
Training loss: 2.7121020187724305
Validation loss: 2.0749130791671972
Epoch: 9| Step: 3
Training loss: 3.1627890956055307
Validation loss: 2.115175271964358
Epoch: 9| Step: 4
Training loss: 1.4846298802041769
Validation loss: 2.121031175457903
Epoch: 9| Step: 5
Training loss: 2.247000284110893
Validation loss: 2.0982676988791162
Epoch: 9| Step: 6
Training loss: 2.95979049327805
Validation loss: 2.061773283595764
Epoch: 9| Step: 7
Training loss: 1.8297392410272644
Validation loss: 2.0968460827561444
Epoch: 9| Step: 8
Training loss: 2.765907143893988
Validation loss: 2.1003352601195893
Epoch: 9| Step: 9
Training loss: 3.0456349514822736
Validation loss: 2.0945669687288504
Epoch: 9| Step: 10
Training loss: 2.2890106299450568
Validation loss: 2.1350595345237076
Epoch: 9| Step: 11
Training loss: 2.9770046116053517
Validation loss: 2.1011618537277217
Epoch: 9| Step: 12
Training loss: 2.4122503200850627
Validation loss: 2.090096270643825
Epoch: 9| Step: 13
Training loss: 2.1073243522529097
Validation loss: 2.0710992029263755
Epoch: 9| Step: 14
Training loss: 2.017648080829799
Validation loss: 2.0968402341517107
Epoch: 9| Step: 15
Training loss: 2.5849886072376296
Validation loss: 2.094838996863579
Epoch: 9| Step: 16
Training loss: 3.2344947092505687
Validation loss: 2.114251735362051
Epoch: 9| Step: 17
Training loss: 2.7183162299327
Validation loss: 2.126230165682761
Epoch: 9| Step: 18
Training loss: 3.1100404880255503
Validation loss: 2.1034937532041593
Epoch: 9| Step: 19
Training loss: 2.0281211817724554
Validation loss: 2.1013129481648813
Epoch: 43| Step: 0
Training loss: 2.695278709310378
Validation loss: 2.091041233187288
Epoch: 9| Step: 1
Training loss: 3.15301105758417
Validation loss: 2.1310911148561735
Epoch: 9| Step: 2
Training loss: 2.858903356124198
Validation loss: 2.09537448653368
Epoch: 9| Step: 3
Training loss: 2.7368835277646655
Validation loss: 2.102890333940296
Epoch: 9| Step: 4
Training loss: 2.6637012762574828
Validation loss: 2.08922766148121
Epoch: 9| Step: 5
Training loss: 2.437784325082696
Validation loss: 2.0787946034778884
Epoch: 9| Step: 6
Training loss: 2.41617094633868
Validation loss: 2.0831916465658185
Epoch: 9| Step: 7
Training loss: 2.463869316351141
Validation loss: 2.0706272043252625
Epoch: 9| Step: 8
Training loss: 2.9685781328746335
Validation loss: 2.084449813678121
Epoch: 9| Step: 9
Training loss: 2.8994227788581513
Validation loss: 2.0666364011504097
Epoch: 9| Step: 10
Training loss: 2.2565265940361274
Validation loss: 2.0674575957804677
Epoch: 9| Step: 11
Training loss: 1.989645858767471
Validation loss: 2.08275898292913
Epoch: 9| Step: 12
Training loss: 2.9308298554091166
Validation loss: 2.0933039023924187
Epoch: 9| Step: 13
Training loss: 2.4315203165832844
Validation loss: 2.0954957679318547
Epoch: 9| Step: 14
Training loss: 2.374644805046489
Validation loss: 2.0595097030785254
Epoch: 9| Step: 15
Training loss: 2.577442795630214
Validation loss: 2.030654686022641
Epoch: 9| Step: 16
Training loss: 1.8943537992765491
Validation loss: 2.096168555049294
Epoch: 9| Step: 17
Training loss: 2.6218511678092216
Validation loss: 2.08247116313456
Epoch: 9| Step: 18
Training loss: 1.3639519470789394
Validation loss: 2.0920386525425285
Epoch: 9| Step: 19
Training loss: 2.3283916551098014
Validation loss: 2.1058130535301207
Epoch: 44| Step: 0
Training loss: 2.7452101174349455
Validation loss: 2.0839316698042296
Epoch: 9| Step: 1
Training loss: 3.0194282859628023
Validation loss: 2.060245054074407
Epoch: 9| Step: 2
Training loss: 2.618018721488067
Validation loss: 2.085876066373792
Epoch: 9| Step: 3
Training loss: 2.4225191305721987
Validation loss: 2.0892325548816437
Epoch: 9| Step: 4
Training loss: 2.7864946784860725
Validation loss: 2.081199057988198
Epoch: 9| Step: 5
Training loss: 2.197181747530993
Validation loss: 2.0924238318438473
Epoch: 9| Step: 6
Training loss: 2.3589242668851016
Validation loss: 2.074722538526724
Epoch: 9| Step: 7
Training loss: 1.7837954620577336
Validation loss: 2.044643497259213
Epoch: 9| Step: 8
Training loss: 1.799397166288849
Validation loss: 2.1080849764025835
Epoch: 9| Step: 9
Training loss: 2.35862174230734
Validation loss: 2.0709234694075223
Epoch: 9| Step: 10
Training loss: 1.9665076186097763
Validation loss: 2.085436062354421
Epoch: 9| Step: 11
Training loss: 2.3077065559094065
Validation loss: 2.105954963260992
Epoch: 9| Step: 12
Training loss: 2.8079137071679847
Validation loss: 2.081038256139132
Epoch: 9| Step: 13
Training loss: 2.779754579537722
Validation loss: 2.0863855360447383
Epoch: 9| Step: 14
Training loss: 2.529950031797291
Validation loss: 2.101504363340024
Epoch: 9| Step: 15
Training loss: 1.6396286618447105
Validation loss: 2.084139730560148
Epoch: 9| Step: 16
Training loss: 2.803791976389992
Validation loss: 2.100917387024737
Epoch: 9| Step: 17
Training loss: 2.8643245695745034
Validation loss: 2.067493761527086
Epoch: 9| Step: 18
Training loss: 2.8626511779576984
Validation loss: 2.08800191348976
Epoch: 9| Step: 19
Training loss: 3.2490850774698417
Validation loss: 2.102613120065371
Epoch: 45| Step: 0
Training loss: 2.856609069825204
Validation loss: 2.0986367421176713
Epoch: 9| Step: 1
Training loss: 2.279758122313076
Validation loss: 2.0804209398798985
Epoch: 9| Step: 2
Training loss: 2.566990523115378
Validation loss: 2.0970935743287407
Epoch: 9| Step: 3
Training loss: 3.6314138037394277
Validation loss: 2.1020347579623992
Epoch: 9| Step: 4
Training loss: 2.1710952346977876
Validation loss: 2.0894076811921947
Epoch: 9| Step: 5
Training loss: 2.6287810932085507
Validation loss: 2.0691540681855902
Epoch: 9| Step: 6
Training loss: 2.3586931064296186
Validation loss: 2.083677071255345
Epoch: 9| Step: 7
Training loss: 2.8101781798104395
Validation loss: 2.0947897776450097
Epoch: 9| Step: 8
Training loss: 2.53000186241594
Validation loss: 2.0962721802794575
Epoch: 9| Step: 9
Training loss: 2.0350544440932246
Validation loss: 2.082635571667515
Epoch: 9| Step: 10
Training loss: 2.3023417286108363
Validation loss: 2.072621741605111
Epoch: 9| Step: 11
Training loss: 2.3288579209568407
Validation loss: 2.0964685494743533
Epoch: 9| Step: 12
Training loss: 2.367555495259261
Validation loss: 2.1093511826725635
Epoch: 9| Step: 13
Training loss: 2.4526502793803147
Validation loss: 2.1567706008743137
Epoch: 9| Step: 14
Training loss: 2.3450360647978608
Validation loss: 2.1037587640729343
Epoch: 9| Step: 15
Training loss: 2.4348445023346597
Validation loss: 2.0844114449426425
Epoch: 9| Step: 16
Training loss: 1.524753882137222
Validation loss: 2.071710510825818
Epoch: 9| Step: 17
Training loss: 3.2452141663774268
Validation loss: 2.069906392592818
Epoch: 9| Step: 18
Training loss: 2.907019400527617
Validation loss: 2.063029967613185
Epoch: 9| Step: 19
Training loss: 2.399246626070605
Validation loss: 2.1047665771493818
Epoch: 46| Step: 0
Training loss: 2.445361152140557
Validation loss: 2.12402401156226
Epoch: 9| Step: 1
Training loss: 2.6237375765974784
Validation loss: 2.071372587766385
Epoch: 9| Step: 2
Training loss: 2.267338387682309
Validation loss: 2.073201136357384
Epoch: 9| Step: 3
Training loss: 2.7380973547380374
Validation loss: 2.0836433307480346
Epoch: 9| Step: 4
Training loss: 2.8954850863357717
Validation loss: 2.0939132111648644
Epoch: 9| Step: 5
Training loss: 2.8877765539594895
Validation loss: 2.0972062809906475
Epoch: 9| Step: 6
Training loss: 2.169617062369915
Validation loss: 2.048166964410086
Epoch: 9| Step: 7
Training loss: 2.6486540849285864
Validation loss: 2.0470867963342196
Epoch: 9| Step: 8
Training loss: 2.2879554753672946
Validation loss: 2.060782215213455
Epoch: 9| Step: 9
Training loss: 2.878638245984569
Validation loss: 2.0794982398021116
Epoch: 9| Step: 10
Training loss: 2.158635243787763
Validation loss: 2.098014690837683
Epoch: 9| Step: 11
Training loss: 2.003918385608356
Validation loss: 2.053763638037576
Epoch: 9| Step: 12
Training loss: 2.409737375915938
Validation loss: 2.0829913093387544
Epoch: 9| Step: 13
Training loss: 2.3621514764676546
Validation loss: 2.0737229805138826
Epoch: 9| Step: 14
Training loss: 2.2409999773058704
Validation loss: 2.0809302047814033
Epoch: 9| Step: 15
Training loss: 2.300973466444155
Validation loss: 2.0688031335380126
Epoch: 9| Step: 16
Training loss: 2.638062446971469
Validation loss: 2.046108252948656
Epoch: 9| Step: 17
Training loss: 2.90786239031875
Validation loss: 2.0626625206905334
Epoch: 9| Step: 18
Training loss: 2.0755111202713112
Validation loss: 2.0521265850014134
Epoch: 9| Step: 19
Training loss: 3.205508354922283
Validation loss: 2.063013659599984
Epoch: 47| Step: 0
Training loss: 2.5728785914848364
Validation loss: 2.0821765624489057
Epoch: 9| Step: 1
Training loss: 2.5714455747799088
Validation loss: 2.101938615540623
Epoch: 9| Step: 2
Training loss: 2.5771974686861965
Validation loss: 2.0645880523768874
Epoch: 9| Step: 3
Training loss: 2.728227953808907
Validation loss: 2.091481959341527
Epoch: 9| Step: 4
Training loss: 1.9333611859036302
Validation loss: 2.067053493099928
Epoch: 9| Step: 5
Training loss: 2.7158656111378616
Validation loss: 2.0495615674077063
Epoch: 9| Step: 6
Training loss: 2.9776596490320437
Validation loss: 2.07975698808238
Epoch: 9| Step: 7
Training loss: 2.801451620108684
Validation loss: 2.077053114300696
Epoch: 9| Step: 8
Training loss: 2.184752673679038
Validation loss: 2.091592921758785
Epoch: 9| Step: 9
Training loss: 2.6340605270916004
Validation loss: 2.0759770597877534
Epoch: 9| Step: 10
Training loss: 1.730674989694019
Validation loss: 2.05895391743921
Epoch: 9| Step: 11
Training loss: 2.173064859615156
Validation loss: 2.07917613563712
Epoch: 9| Step: 12
Training loss: 1.8786556211561531
Validation loss: 2.067174871955255
Epoch: 9| Step: 13
Training loss: 3.319236096201821
Validation loss: 2.059781710493478
Epoch: 9| Step: 14
Training loss: 2.2680227285723036
Validation loss: 2.0534920143592994
Epoch: 9| Step: 15
Training loss: 3.016263745905401
Validation loss: 2.0603539560872792
Epoch: 9| Step: 16
Training loss: 2.618418480912958
Validation loss: 2.052002012802221
Epoch: 9| Step: 17
Training loss: 1.9229341395263788
Validation loss: 2.0673264231633834
Epoch: 9| Step: 18
Training loss: 2.9265044557402904
Validation loss: 2.0615856231973018
Epoch: 9| Step: 19
Training loss: 2.200641503872099
Validation loss: 2.0882959999937754
Epoch: 48| Step: 0
Training loss: 2.7397259480495966
Validation loss: 2.121992830154007
Epoch: 9| Step: 1
Training loss: 2.3950838879445846
Validation loss: 2.0777566118677604
Epoch: 9| Step: 2
Training loss: 2.1543664860481084
Validation loss: 2.09971753548196
Epoch: 9| Step: 3
Training loss: 2.3719845752761337
Validation loss: 2.0844371876375263
Epoch: 9| Step: 4
Training loss: 2.5590173268776932
Validation loss: 2.109633306932486
Epoch: 9| Step: 5
Training loss: 1.9568123152472419
Validation loss: 2.0846103242842724
Epoch: 9| Step: 6
Training loss: 2.674810213861122
Validation loss: 2.0502091889575507
Epoch: 9| Step: 7
Training loss: 2.0489021338813704
Validation loss: 2.100394026525226
Epoch: 9| Step: 8
Training loss: 2.671380515937667
Validation loss: 2.0940476639613554
Epoch: 9| Step: 9
Training loss: 2.5827682759029114
Validation loss: 2.0885881284617818
Epoch: 9| Step: 10
Training loss: 1.8292358805335822
Validation loss: 2.0822724295602537
Epoch: 9| Step: 11
Training loss: 2.453805816839501
Validation loss: 2.1113061730760805
Epoch: 9| Step: 12
Training loss: 2.6004355799333503
Validation loss: 2.0833706898985285
Epoch: 9| Step: 13
Training loss: 2.6484535239305993
Validation loss: 2.07873906180288
Epoch: 9| Step: 14
Training loss: 3.603183604919305
Validation loss: 2.0808783366072254
Epoch: 9| Step: 15
Training loss: 2.932042835760566
Validation loss: 2.112376629943883
Epoch: 9| Step: 16
Training loss: 1.9128232096905249
Validation loss: 2.0910030022405275
Epoch: 9| Step: 17
Training loss: 2.3978292582401197
Validation loss: 2.0860034219011783
Epoch: 9| Step: 18
Training loss: 2.463089259560344
Validation loss: 2.082219775992903
Epoch: 9| Step: 19
Training loss: 2.5040469792136264
Validation loss: 2.105619545482856
Epoch: 49| Step: 0
Training loss: 2.14998579242359
Validation loss: 2.0874092491016967
Epoch: 9| Step: 1
Training loss: 2.9441951990099176
Validation loss: 2.0874444785426594
Epoch: 9| Step: 2
Training loss: 2.0084436515594004
Validation loss: 2.0798159757060573
Epoch: 9| Step: 3
Training loss: 2.526311884843586
Validation loss: 2.093292505027553
Epoch: 9| Step: 4
Training loss: 2.5861613473498455
Validation loss: 2.075037048292989
Epoch: 9| Step: 5
Training loss: 2.7951201149340936
Validation loss: 2.0727328487938417
Epoch: 9| Step: 6
Training loss: 2.469615350031623
Validation loss: 2.0671161698173224
Epoch: 9| Step: 7
Training loss: 2.722584442986909
Validation loss: 2.0644408134760983
Epoch: 9| Step: 8
Training loss: 2.663450735780546
Validation loss: 2.098084290491435
Epoch: 9| Step: 9
Training loss: 2.378781570650037
Validation loss: 2.096599755996464
Epoch: 9| Step: 10
Training loss: 2.847935708649011
Validation loss: 2.0572614442880233
Epoch: 9| Step: 11
Training loss: 2.2952241739063064
Validation loss: 2.07495009590119
Epoch: 9| Step: 12
Training loss: 1.795146010790761
Validation loss: 2.0943538856415147
Epoch: 9| Step: 13
Training loss: 2.880077687911095
Validation loss: 2.0983251157537937
Epoch: 9| Step: 14
Training loss: 1.66393111162457
Validation loss: 2.059600429168231
Epoch: 9| Step: 15
Training loss: 2.3192919403721675
Validation loss: 2.08235031984124
Epoch: 9| Step: 16
Training loss: 2.985610147095473
Validation loss: 2.079387914449181
Epoch: 9| Step: 17
Training loss: 2.938164493804145
Validation loss: 2.093601326773565
Epoch: 9| Step: 18
Training loss: 2.2615694777489255
Validation loss: 2.092450564551517
Epoch: 9| Step: 19
Training loss: 2.543077785890859
Validation loss: 2.064993196895114
Epoch: 50| Step: 0
Training loss: 2.277399445207675
Validation loss: 2.0861225007962823
Epoch: 9| Step: 1
Training loss: 1.6526923206508468
Validation loss: 2.0858660093351054
Epoch: 9| Step: 2
Training loss: 2.59580553712449
Validation loss: 2.070848878576533
Epoch: 9| Step: 3
Training loss: 2.3440201667204543
Validation loss: 2.0872778369313214
Epoch: 9| Step: 4
Training loss: 2.7377099326821663
Validation loss: 2.0833606131194444
Epoch: 9| Step: 5
Training loss: 2.133889398027155
Validation loss: 2.1022982333856555
Epoch: 9| Step: 6
Training loss: 2.024496500974624
Validation loss: 2.1118093198174397
Epoch: 9| Step: 7
Training loss: 2.9814227615938016
Validation loss: 2.0807029745751744
Epoch: 9| Step: 8
Training loss: 3.0882768093919664
Validation loss: 2.0982103062930015
Epoch: 9| Step: 9
Training loss: 2.21056920950487
Validation loss: 2.1006693558185963
Epoch: 9| Step: 10
Training loss: 2.345843486413841
Validation loss: 2.0944216685089967
Epoch: 9| Step: 11
Training loss: 1.9003532382467072
Validation loss: 2.09350527265707
Epoch: 9| Step: 12
Training loss: 2.6542688498796436
Validation loss: 2.1149527179217076
Epoch: 9| Step: 13
Training loss: 2.4255652093435525
Validation loss: 2.096638707377744
Epoch: 9| Step: 14
Training loss: 2.714509133773786
Validation loss: 2.1089717201822964
Epoch: 9| Step: 15
Training loss: 2.604437536775472
Validation loss: 2.084083286915683
Epoch: 9| Step: 16
Training loss: 2.8695301599082463
Validation loss: 2.0537317303260427
Epoch: 9| Step: 17
Training loss: 2.1521383696390792
Validation loss: 2.1024223638642443
Epoch: 9| Step: 18
Training loss: 3.1584152499591176
Validation loss: 2.0707553952923226
Epoch: 9| Step: 19
Training loss: 2.859257263094319
Validation loss: 2.065227624672521
Epoch: 51| Step: 0
Training loss: 2.536373651384684
Validation loss: 2.086288874415193
Epoch: 9| Step: 1
Training loss: 2.166617417387111
Validation loss: 2.0834651306846874
Epoch: 9| Step: 2
Training loss: 2.252574084013062
Validation loss: 2.046671025321278
Epoch: 9| Step: 3
Training loss: 2.4206712253765414
Validation loss: 2.0509058236337805
Epoch: 9| Step: 4
Training loss: 1.4396104661930458
Validation loss: 2.067913895295237
Epoch: 9| Step: 5
Training loss: 2.3674592217837844
Validation loss: 2.0763037728498372
Epoch: 9| Step: 6
Training loss: 2.581954054609087
Validation loss: 2.078650556956487
Epoch: 9| Step: 7
Training loss: 2.4590693088737305
Validation loss: 2.0557339682171376
Epoch: 9| Step: 8
Training loss: 3.1414402145678504
Validation loss: 2.028284023766551
Epoch: 9| Step: 9
Training loss: 2.7078891292059537
Validation loss: 2.0649948443132216
Epoch: 9| Step: 10
Training loss: 2.1015189354220674
Validation loss: 2.0676847316489577
Epoch: 9| Step: 11
Training loss: 2.3820531416825705
Validation loss: 2.0584978232169173
Epoch: 9| Step: 12
Training loss: 2.7996781436675686
Validation loss: 2.0643137023542133
Epoch: 9| Step: 13
Training loss: 2.630290377001405
Validation loss: 2.0752929496954864
Epoch: 9| Step: 14
Training loss: 3.369279322326285
Validation loss: 2.062066008747579
Epoch: 9| Step: 15
Training loss: 2.2098326601565956
Validation loss: 2.083985072346056
Epoch: 9| Step: 16
Training loss: 2.5573580254816894
Validation loss: 2.077529164080122
Epoch: 9| Step: 17
Training loss: 2.1437585546917846
Validation loss: 2.035132674067269
Epoch: 9| Step: 18
Training loss: 2.3962889749444725
Validation loss: 2.0764359324076573
Epoch: 9| Step: 19
Training loss: 2.7370305708326694
Validation loss: 2.0490344700193046
Epoch: 52| Step: 0
Training loss: 2.439107902539265
Validation loss: 2.0575203098395503
Epoch: 9| Step: 1
Training loss: 2.3886092919349164
Validation loss: 2.0682023811859347
Epoch: 9| Step: 2
Training loss: 2.2249556247700863
Validation loss: 2.074063082706405
Epoch: 9| Step: 3
Training loss: 1.8839799103040349
Validation loss: 2.091758217581005
Epoch: 9| Step: 4
Training loss: 2.1797507218793832
Validation loss: 2.0554494077275893
Epoch: 9| Step: 5
Training loss: 2.442661981746118
Validation loss: 2.065027691137133
Epoch: 9| Step: 6
Training loss: 3.0992738365468466
Validation loss: 2.0611359826208178
Epoch: 9| Step: 7
Training loss: 2.2006745474735023
Validation loss: 2.02745154576918
Epoch: 9| Step: 8
Training loss: 2.7011536923759865
Validation loss: 2.0539227625975953
Epoch: 9| Step: 9
Training loss: 3.0443420836913484
Validation loss: 2.0215012485132737
Epoch: 9| Step: 10
Training loss: 2.305395088841719
Validation loss: 2.067984999908355
Epoch: 9| Step: 11
Training loss: 2.5314283896799523
Validation loss: 2.0628890028578635
Epoch: 9| Step: 12
Training loss: 2.4140178589875307
Validation loss: 2.045123031597471
Epoch: 9| Step: 13
Training loss: 2.795057761289833
Validation loss: 2.0710707066616796
Epoch: 9| Step: 14
Training loss: 2.6916711065139607
Validation loss: 2.0537940681269116
Epoch: 9| Step: 15
Training loss: 2.2775642196696095
Validation loss: 2.071110511488981
Epoch: 9| Step: 16
Training loss: 2.8398773317306056
Validation loss: 2.067560311692909
Epoch: 9| Step: 17
Training loss: 2.6076775243351795
Validation loss: 2.0500708338904414
Epoch: 9| Step: 18
Training loss: 2.3157000695542997
Validation loss: 2.0860067224243806
Epoch: 9| Step: 19
Training loss: 2.2531421761248267
Validation loss: 2.0511865177698323
Epoch: 53| Step: 0
Training loss: 2.9927584349947014
Validation loss: 2.0220444095608134
Epoch: 9| Step: 1
Training loss: 2.1084723907971634
Validation loss: 2.044683941140542
Epoch: 9| Step: 2
Training loss: 1.7268883583195556
Validation loss: 2.056201577991653
Epoch: 9| Step: 3
Training loss: 1.8136138781859164
Validation loss: 2.0707582667003908
Epoch: 9| Step: 4
Training loss: 2.4065311812554975
Validation loss: 2.0841881007698366
Epoch: 9| Step: 5
Training loss: 2.353710524217352
Validation loss: 2.0528524488841633
Epoch: 9| Step: 6
Training loss: 1.9276505194052627
Validation loss: 2.0513215010698658
Epoch: 9| Step: 7
Training loss: 2.268020415892034
Validation loss: 2.061802088680224
Epoch: 9| Step: 8
Training loss: 3.1058851430747816
Validation loss: 2.086456185386807
Epoch: 9| Step: 9
Training loss: 2.435302330533331
Validation loss: 2.0746527354090762
Epoch: 9| Step: 10
Training loss: 2.950146985029113
Validation loss: 2.1025966625386783
Epoch: 9| Step: 11
Training loss: 2.3792187214605427
Validation loss: 2.0807721733170697
Epoch: 9| Step: 12
Training loss: 2.702677254170383
Validation loss: 2.055762317156686
Epoch: 9| Step: 13
Training loss: 2.856513253732599
Validation loss: 2.081499122463946
Epoch: 9| Step: 14
Training loss: 2.5843109824059836
Validation loss: 2.061725393908361
Epoch: 9| Step: 15
Training loss: 2.455216506299181
Validation loss: 2.067202626674112
Epoch: 9| Step: 16
Training loss: 2.643485421723699
Validation loss: 2.049238153240476
Epoch: 9| Step: 17
Training loss: 2.32184157418056
Validation loss: 2.082276566135421
Epoch: 9| Step: 18
Training loss: 2.6458058293232165
Validation loss: 2.0911448450952927
Epoch: 9| Step: 19
Training loss: 2.714713421444571
Validation loss: 2.0600294930618355
Epoch: 54| Step: 0
Training loss: 2.8108033890933517
Validation loss: 2.0676417400638103
Epoch: 9| Step: 1
Training loss: 2.5937163569095403
Validation loss: 2.053219425850006
Epoch: 9| Step: 2
Training loss: 2.775045267371672
Validation loss: 2.075861059574919
Epoch: 9| Step: 3
Training loss: 2.2635730790967674
Validation loss: 2.056673247613182
Epoch: 9| Step: 4
Training loss: 2.916297525933461
Validation loss: 2.058218234038957
Epoch: 9| Step: 5
Training loss: 1.8141368840859418
Validation loss: 2.0328411161077535
Epoch: 9| Step: 6
Training loss: 2.393076418933731
Validation loss: 2.0561101736356844
Epoch: 9| Step: 7
Training loss: 2.9351230500663448
Validation loss: 2.036825941865579
Epoch: 9| Step: 8
Training loss: 2.1640056506240035
Validation loss: 2.0503911288570693
Epoch: 9| Step: 9
Training loss: 2.794095666993791
Validation loss: 2.049723533869455
Epoch: 9| Step: 10
Training loss: 2.6963542307239092
Validation loss: 2.073161888504098
Epoch: 9| Step: 11
Training loss: 3.053780267341384
Validation loss: 2.036481384731583
Epoch: 9| Step: 12
Training loss: 2.25582671699169
Validation loss: 2.046083211448467
Epoch: 9| Step: 13
Training loss: 2.9845197552630918
Validation loss: 2.020786017477306
Epoch: 9| Step: 14
Training loss: 1.7576936808800514
Validation loss: 2.0098320151012627
Epoch: 9| Step: 15
Training loss: 1.7784868190685548
Validation loss: 2.0698055193346607
Epoch: 9| Step: 16
Training loss: 2.737909093101413
Validation loss: 2.043516142298162
Epoch: 9| Step: 17
Training loss: 2.2843031635809097
Validation loss: 2.053526524259485
Epoch: 9| Step: 18
Training loss: 2.1355928177790844
Validation loss: 2.077536052159297
Epoch: 9| Step: 19
Training loss: 1.671178369577687
Validation loss: 2.042669488910111
Epoch: 55| Step: 0
Training loss: 2.4830055541069727
Validation loss: 2.0712059733828494
Epoch: 9| Step: 1
Training loss: 2.562683378031476
Validation loss: 2.0398367300356113
Epoch: 9| Step: 2
Training loss: 2.32025372466068
Validation loss: 2.0737371441426387
Epoch: 9| Step: 3
Training loss: 2.299262849188453
Validation loss: 2.056169945292187
Epoch: 9| Step: 4
Training loss: 2.393100528905749
Validation loss: 2.0478726448781233
Epoch: 9| Step: 5
Training loss: 2.5892373780497873
Validation loss: 2.0751764710340495
Epoch: 9| Step: 6
Training loss: 2.2495068963448146
Validation loss: 2.050367081207931
Epoch: 9| Step: 7
Training loss: 1.7989479381244002
Validation loss: 2.0723116789002374
Epoch: 9| Step: 8
Training loss: 2.542657554793505
Validation loss: 2.103431444822519
Epoch: 9| Step: 9
Training loss: 2.8593976796402476
Validation loss: 2.0895097143201524
Epoch: 9| Step: 10
Training loss: 2.8808067394555943
Validation loss: 2.0781371016535264
Epoch: 9| Step: 11
Training loss: 2.7694003957979954
Validation loss: 2.0398939202089554
Epoch: 9| Step: 12
Training loss: 2.2876075052315996
Validation loss: 2.0474805645744545
Epoch: 9| Step: 13
Training loss: 1.9019766890123193
Validation loss: 2.086647196162081
Epoch: 9| Step: 14
Training loss: 2.9326001146793246
Validation loss: 2.084816763300957
Epoch: 9| Step: 15
Training loss: 2.5422992440243912
Validation loss: 2.0425458467325486
Epoch: 9| Step: 16
Training loss: 3.1455901264551844
Validation loss: 2.0674646656444597
Epoch: 9| Step: 17
Training loss: 2.1327834354418447
Validation loss: 2.0727252322005603
Epoch: 9| Step: 18
Training loss: 2.6161630020221245
Validation loss: 2.1029403369817152
Epoch: 9| Step: 19
Training loss: 2.034218247991755
Validation loss: 2.0370998378516307
Epoch: 56| Step: 0
Training loss: 2.6313441678772804
Validation loss: 2.081840538323454
Epoch: 9| Step: 1
Training loss: 2.3712329100946654
Validation loss: 2.051824018430882
Epoch: 9| Step: 2
Training loss: 2.303996768180912
Validation loss: 2.0439253871402037
Epoch: 9| Step: 3
Training loss: 2.0112471240623497
Validation loss: 2.0553992227055464
Epoch: 9| Step: 4
Training loss: 2.420910846390646
Validation loss: 2.0688851655031173
Epoch: 9| Step: 5
Training loss: 2.196314681375705
Validation loss: 2.0710046123406114
Epoch: 9| Step: 6
Training loss: 2.369834905097187
Validation loss: 2.0388094893534867
Epoch: 9| Step: 7
Training loss: 2.739934446706219
Validation loss: 2.041962473273743
Epoch: 9| Step: 8
Training loss: 2.162972185919872
Validation loss: 2.0596565153073
Epoch: 9| Step: 9
Training loss: 2.309501146889811
Validation loss: 2.032075376732965
Epoch: 9| Step: 10
Training loss: 3.1861552973636513
Validation loss: 2.032409538790104
Epoch: 9| Step: 11
Training loss: 2.5743889759607694
Validation loss: 2.0588649137367345
Epoch: 9| Step: 12
Training loss: 2.139134242970329
Validation loss: 2.072730473175037
Epoch: 9| Step: 13
Training loss: 2.9622905930818684
Validation loss: 2.0456394822402446
Epoch: 9| Step: 14
Training loss: 2.2321963058612004
Validation loss: 2.0437598818027762
Epoch: 9| Step: 15
Training loss: 2.311909574449686
Validation loss: 2.0185992562903943
Epoch: 9| Step: 16
Training loss: 2.5752397518207717
Validation loss: 2.0444463969870763
Epoch: 9| Step: 17
Training loss: 3.294157960588946
Validation loss: 2.019949129934358
Epoch: 9| Step: 18
Training loss: 2.358256902455913
Validation loss: 2.003081423136821
Epoch: 9| Step: 19
Training loss: 2.3293119131623503
Validation loss: 2.036323085368397
Epoch: 57| Step: 0
Training loss: 2.4279098631453246
Validation loss: 2.029638526476321
Epoch: 9| Step: 1
Training loss: 2.34370218863994
Validation loss: 2.0322976202788388
Epoch: 9| Step: 2
Training loss: 1.922574419979655
Validation loss: 2.054254835804156
Epoch: 9| Step: 3
Training loss: 2.5797002430444556
Validation loss: 2.073937979179739
Epoch: 9| Step: 4
Training loss: 3.1029830485258016
Validation loss: 2.0524130295958134
Epoch: 9| Step: 5
Training loss: 3.0073032493002687
Validation loss: 2.045980814977706
Epoch: 9| Step: 6
Training loss: 2.5264060685063754
Validation loss: 2.0432283389653816
Epoch: 9| Step: 7
Training loss: 2.7927213545916265
Validation loss: 2.0204756474788748
Epoch: 9| Step: 8
Training loss: 2.2564105793034606
Validation loss: 2.0455708285049763
Epoch: 9| Step: 9
Training loss: 2.400818478574636
Validation loss: 2.057214315856634
Epoch: 9| Step: 10
Training loss: 2.3319457787676594
Validation loss: 2.04532576368752
Epoch: 9| Step: 11
Training loss: 2.486669188882539
Validation loss: 2.0483009752043606
Epoch: 9| Step: 12
Training loss: 2.3714659648514314
Validation loss: 2.0539721754326075
Epoch: 9| Step: 13
Training loss: 2.597855685042731
Validation loss: 2.0418455440665153
Epoch: 9| Step: 14
Training loss: 3.204995851082579
Validation loss: 2.0185981928362637
Epoch: 9| Step: 15
Training loss: 2.5584834184226697
Validation loss: 2.0388999507792565
Epoch: 9| Step: 16
Training loss: 2.198533488376222
Validation loss: 2.0454505167532178
Epoch: 9| Step: 17
Training loss: 1.7028379985925506
Validation loss: 2.082587142648533
Epoch: 9| Step: 18
Training loss: 1.7314100611541225
Validation loss: 2.0493348683576826
Epoch: 9| Step: 19
Training loss: 2.394290084269113
Validation loss: 2.070437628878607
Epoch: 58| Step: 0
Training loss: 2.6057533211700172
Validation loss: 2.088162933381845
Epoch: 9| Step: 1
Training loss: 2.739779901644354
Validation loss: 2.042439032088215
Epoch: 9| Step: 2
Training loss: 2.1809454675264623
Validation loss: 2.0714644133493247
Epoch: 9| Step: 3
Training loss: 2.7000625108617458
Validation loss: 2.091165259590424
Epoch: 9| Step: 4
Training loss: 2.4755099493700143
Validation loss: 2.085754601380694
Epoch: 9| Step: 5
Training loss: 2.478225775229423
Validation loss: 2.082487396760382
Epoch: 9| Step: 6
Training loss: 2.918096700413869
Validation loss: 2.0626797853761576
Epoch: 9| Step: 7
Training loss: 1.6727475892829087
Validation loss: 2.091106318760615
Epoch: 9| Step: 8
Training loss: 1.9182875731462563
Validation loss: 2.065345244353324
Epoch: 9| Step: 9
Training loss: 2.2517193476878847
Validation loss: 2.028173864987393
Epoch: 9| Step: 10
Training loss: 2.2478131156972516
Validation loss: 2.076978556162253
Epoch: 9| Step: 11
Training loss: 1.8023815533030552
Validation loss: 2.089904590991907
Epoch: 9| Step: 12
Training loss: 2.7292474244571983
Validation loss: 2.0702398016006356
Epoch: 9| Step: 13
Training loss: 2.791114714607348
Validation loss: 2.0296274790230484
Epoch: 9| Step: 14
Training loss: 2.415933717096318
Validation loss: 2.022415491217457
Epoch: 9| Step: 15
Training loss: 2.063808835055662
Validation loss: 2.0859616201971316
Epoch: 9| Step: 16
Training loss: 2.8167392570877827
Validation loss: 2.0812621477230313
Epoch: 9| Step: 17
Training loss: 2.570913134489918
Validation loss: 2.0744679418201772
Epoch: 9| Step: 18
Training loss: 3.0394563003011625
Validation loss: 2.091790598693006
Epoch: 9| Step: 19
Training loss: 2.5062054865587005
Validation loss: 2.046460870527404
Epoch: 59| Step: 0
Training loss: 2.406779342489934
Validation loss: 2.083898889386997
Epoch: 9| Step: 1
Training loss: 2.2672444836575383
Validation loss: 2.0777974326599917
Epoch: 9| Step: 2
Training loss: 2.3545093005716224
Validation loss: 2.0703342531958406
Epoch: 9| Step: 3
Training loss: 2.6705582257329703
Validation loss: 2.0895173579696626
Epoch: 9| Step: 4
Training loss: 2.9731549159291664
Validation loss: 2.072836576314625
Epoch: 9| Step: 5
Training loss: 2.8428742454107474
Validation loss: 2.0749025525219453
Epoch: 9| Step: 6
Training loss: 2.934677878644232
Validation loss: 2.072459627680602
Epoch: 9| Step: 7
Training loss: 2.2683774868238955
Validation loss: 2.053040149379433
Epoch: 9| Step: 8
Training loss: 2.3721459958914783
Validation loss: 2.060628756640728
Epoch: 9| Step: 9
Training loss: 2.846226211468545
Validation loss: 2.098738571041774
Epoch: 9| Step: 10
Training loss: 2.113114609555974
Validation loss: 2.087175701564488
Epoch: 9| Step: 11
Training loss: 2.369655619198932
Validation loss: 2.06695694140612
Epoch: 9| Step: 12
Training loss: 2.720378344252223
Validation loss: 2.069749558255163
Epoch: 9| Step: 13
Training loss: 2.2364030717176706
Validation loss: 2.0612438240204103
Epoch: 9| Step: 14
Training loss: 2.6945462671902765
Validation loss: 2.0571632874498174
Epoch: 9| Step: 15
Training loss: 2.2452931445089868
Validation loss: 2.0639875074683816
Epoch: 9| Step: 16
Training loss: 2.4684518561626083
Validation loss: 2.029099256077383
Epoch: 9| Step: 17
Training loss: 2.6097762661622603
Validation loss: 2.0622985730669074
Epoch: 9| Step: 18
Training loss: 1.9659083612453692
Validation loss: 1.9985785480666491
Epoch: 9| Step: 19
Training loss: 2.086481716299861
Validation loss: 2.0144572440741353
Epoch: 60| Step: 0
Training loss: 1.7704171832413016
Validation loss: 2.0676685023955526
Epoch: 9| Step: 1
Training loss: 2.3644621113584807
Validation loss: 2.060134715114774
Epoch: 9| Step: 2
Training loss: 2.2982164475020825
Validation loss: 2.0446995343036467
Epoch: 9| Step: 3
Training loss: 2.0100220867860323
Validation loss: 2.0560001013977427
Epoch: 9| Step: 4
Training loss: 2.8445537395473566
Validation loss: 2.048956840930505
Epoch: 9| Step: 5
Training loss: 2.5996587162508473
Validation loss: 2.060411265756554
Epoch: 9| Step: 6
Training loss: 3.0296322940008786
Validation loss: 2.076479062605054
Epoch: 9| Step: 7
Training loss: 2.845153462271755
Validation loss: 2.0762257934440655
Epoch: 9| Step: 8
Training loss: 2.344976180714093
Validation loss: 2.0920405893877367
Epoch: 9| Step: 9
Training loss: 2.2158199897049675
Validation loss: 2.0879303877446733
Epoch: 9| Step: 10
Training loss: 3.012243559120087
Validation loss: 2.060177065085842
Epoch: 9| Step: 11
Training loss: 2.143646113155636
Validation loss: 2.0857002187230185
Epoch: 9| Step: 12
Training loss: 1.1085652364514358
Validation loss: 2.06960077840933
Epoch: 9| Step: 13
Training loss: 2.633376969406486
Validation loss: 2.0469541442660755
Epoch: 9| Step: 14
Training loss: 2.983244517050311
Validation loss: 2.038117670786132
Epoch: 9| Step: 15
Training loss: 2.650904224083026
Validation loss: 2.087745215632225
Epoch: 9| Step: 16
Training loss: 2.2366041254698166
Validation loss: 2.069130368178751
Epoch: 9| Step: 17
Training loss: 3.052474134680834
Validation loss: 2.0620940721261545
Epoch: 9| Step: 18
Training loss: 2.4537772508177795
Validation loss: 2.0551177795605167
Epoch: 9| Step: 19
Training loss: 2.222372831433126
Validation loss: 2.050598696309568
Epoch: 61| Step: 0
Training loss: 2.297574306610555
Validation loss: 2.02967107142658
Epoch: 9| Step: 1
Training loss: 2.6466092351196107
Validation loss: 2.057881192731607
Epoch: 9| Step: 2
Training loss: 2.6476875075957165
Validation loss: 2.0383703750274185
Epoch: 9| Step: 3
Training loss: 2.3794540000167688
Validation loss: 2.0291219091156147
Epoch: 9| Step: 4
Training loss: 3.6385479023935763
Validation loss: 2.0357669844653836
Epoch: 9| Step: 5
Training loss: 2.1481616033787954
Validation loss: 2.0399921281170164
Epoch: 9| Step: 6
Training loss: 1.9060787686846574
Validation loss: 2.050886638423859
Epoch: 9| Step: 7
Training loss: 2.815319428284536
Validation loss: 2.043023997668853
Epoch: 9| Step: 8
Training loss: 2.1507021533681603
Validation loss: 2.022379249364776
Epoch: 9| Step: 9
Training loss: 2.4973077582831675
Validation loss: 2.017939430472366
Epoch: 9| Step: 10
Training loss: 2.4627479312227023
Validation loss: 2.0532057698606154
Epoch: 9| Step: 11
Training loss: 2.304814739270998
Validation loss: 2.0518393857735937
Epoch: 9| Step: 12
Training loss: 2.2040933415331843
Validation loss: 2.0384919258531164
Epoch: 9| Step: 13
Training loss: 2.272228850417456
Validation loss: 2.05327640903402
Epoch: 9| Step: 14
Training loss: 2.435897398123696
Validation loss: 2.048447741835448
Epoch: 9| Step: 15
Training loss: 2.207366971838679
Validation loss: 2.002849492215823
Epoch: 9| Step: 16
Training loss: 2.698112117408747
Validation loss: 2.024092329967623
Epoch: 9| Step: 17
Training loss: 2.267424191319063
Validation loss: 2.059701659160759
Epoch: 9| Step: 18
Training loss: 2.423027699474745
Validation loss: 2.050131949288004
Epoch: 9| Step: 19
Training loss: 2.557763910035956
Validation loss: 2.02624785307822
Epoch: 62| Step: 0
Training loss: 2.861555425058825
Validation loss: 2.0631734726039452
Epoch: 9| Step: 1
Training loss: 2.5620315867970103
Validation loss: 2.0686597236638256
Epoch: 9| Step: 2
Training loss: 3.031489726546703
Validation loss: 2.041241360646955
Epoch: 9| Step: 3
Training loss: 1.9762547671835415
Validation loss: 2.0467698831869074
Epoch: 9| Step: 4
Training loss: 2.7026370275095806
Validation loss: 2.0434805316762277
Epoch: 9| Step: 5
Training loss: 3.2649196611366653
Validation loss: 2.0335356030842715
Epoch: 9| Step: 6
Training loss: 2.5938240867972353
Validation loss: 2.0564474378383797
Epoch: 9| Step: 7
Training loss: 2.565405245440521
Validation loss: 2.0506883307960417
Epoch: 9| Step: 8
Training loss: 1.6380755279417671
Validation loss: 2.07485067502434
Epoch: 9| Step: 9
Training loss: 2.87140879037926
Validation loss: 2.064902358387792
Epoch: 9| Step: 10
Training loss: 2.8991711451477684
Validation loss: 1.9978110675394931
Epoch: 9| Step: 11
Training loss: 1.9309100398123535
Validation loss: 2.035321454820069
Epoch: 9| Step: 12
Training loss: 2.4960817148697534
Validation loss: 2.041678836169691
Epoch: 9| Step: 13
Training loss: 2.0041206349289817
Validation loss: 2.045892298479317
Epoch: 9| Step: 14
Training loss: 1.7765995018426382
Validation loss: 2.0327216270234136
Epoch: 9| Step: 15
Training loss: 1.917551030122797
Validation loss: 2.0301800813940205
Epoch: 9| Step: 16
Training loss: 2.813310294516483
Validation loss: 2.053717255829646
Epoch: 9| Step: 17
Training loss: 2.2580502922735186
Validation loss: 2.02440000748865
Epoch: 9| Step: 18
Training loss: 1.703497889583211
Validation loss: 2.035612006881648
Epoch: 9| Step: 19
Training loss: 2.5591173873756095
Validation loss: 2.036500057250208
Epoch: 63| Step: 0
Training loss: 2.2262971418766684
Validation loss: 2.033498260912232
Epoch: 9| Step: 1
Training loss: 2.874246249698562
Validation loss: 2.0194270708762154
Epoch: 9| Step: 2
Training loss: 2.7799612767109196
Validation loss: 2.063552886996042
Epoch: 9| Step: 3
Training loss: 1.9375127361248168
Validation loss: 2.0549408588654177
Epoch: 9| Step: 4
Training loss: 2.7845778540154416
Validation loss: 2.0345724971819057
Epoch: 9| Step: 5
Training loss: 2.417996753043621
Validation loss: 2.074437738624072
Epoch: 9| Step: 6
Training loss: 2.750150589721188
Validation loss: 2.076304416033234
Epoch: 9| Step: 7
Training loss: 2.793320426941449
Validation loss: 2.057914609805008
Epoch: 9| Step: 8
Training loss: 2.5540503777753396
Validation loss: 2.0604261955737107
Epoch: 9| Step: 9
Training loss: 2.1596423015410373
Validation loss: 2.057026100010297
Epoch: 9| Step: 10
Training loss: 2.687171561110368
Validation loss: 2.0638090770636413
Epoch: 9| Step: 11
Training loss: 1.8918081317498179
Validation loss: 2.080713453321496
Epoch: 9| Step: 12
Training loss: 2.7538729185427484
Validation loss: 2.0967328312609035
Epoch: 9| Step: 13
Training loss: 2.294765411887076
Validation loss: 2.0694004124205216
Epoch: 9| Step: 14
Training loss: 2.08631499228659
Validation loss: 2.074981044579668
Epoch: 9| Step: 15
Training loss: 2.0612507128786572
Validation loss: 2.0419461777228727
Epoch: 9| Step: 16
Training loss: 2.4762526838816656
Validation loss: 2.0350942330904975
Epoch: 9| Step: 17
Training loss: 2.6079980563642127
Validation loss: 2.0555653114156316
Epoch: 9| Step: 18
Training loss: 2.1240914590401205
Validation loss: 2.04094693820399
Epoch: 9| Step: 19
Training loss: 2.5427915449850698
Validation loss: 2.050617158128542
Epoch: 64| Step: 0
Training loss: 2.0703060509923144
Validation loss: 2.039133576645874
Epoch: 9| Step: 1
Training loss: 2.0107659018453456
Validation loss: 2.039017785775102
Epoch: 9| Step: 2
Training loss: 2.428705243823744
Validation loss: 2.066947968495517
Epoch: 9| Step: 3
Training loss: 2.767258414981229
Validation loss: 2.027321621613682
Epoch: 9| Step: 4
Training loss: 2.2104646965750634
Validation loss: 2.044152232829748
Epoch: 9| Step: 5
Training loss: 3.0495007278283897
Validation loss: 2.0361119862061923
Epoch: 9| Step: 6
Training loss: 2.5699886593401464
Validation loss: 2.0194270625434294
Epoch: 9| Step: 7
Training loss: 2.711213111608908
Validation loss: 2.0378818272362618
Epoch: 9| Step: 8
Training loss: 2.860789465082216
Validation loss: 2.0326268216317946
Epoch: 9| Step: 9
Training loss: 2.298792862277336
Validation loss: 2.0361208484423097
Epoch: 9| Step: 10
Training loss: 2.1698643001193916
Validation loss: 2.028672856686615
Epoch: 9| Step: 11
Training loss: 2.695463226084494
Validation loss: 2.0246446458294027
Epoch: 9| Step: 12
Training loss: 3.11009476348651
Validation loss: 2.001055133727909
Epoch: 9| Step: 13
Training loss: 1.9499318379935862
Validation loss: 2.002136437465462
Epoch: 9| Step: 14
Training loss: 2.4035645399195325
Validation loss: 2.019431614400752
Epoch: 9| Step: 15
Training loss: 2.1186740062667315
Validation loss: 2.036190825451875
Epoch: 9| Step: 16
Training loss: 2.6639681712703522
Validation loss: 2.026537271384477
Epoch: 9| Step: 17
Training loss: 2.402125998451989
Validation loss: 2.033056651874684
Epoch: 9| Step: 18
Training loss: 2.17251292129379
Validation loss: 2.0281288518027742
Epoch: 9| Step: 19
Training loss: 2.442720349464604
Validation loss: 2.0350366110545703
Epoch: 65| Step: 0
Training loss: 1.5999773321930202
Validation loss: 2.022906245470352
Epoch: 9| Step: 1
Training loss: 2.535644014102465
Validation loss: 2.0571653906657645
Epoch: 9| Step: 2
Training loss: 2.7312290077362964
Validation loss: 2.0573143889114727
Epoch: 9| Step: 3
Training loss: 2.6098917375231863
Validation loss: 2.0609745924869833
Epoch: 9| Step: 4
Training loss: 2.373512605404213
Validation loss: 2.0800659837254627
Epoch: 9| Step: 5
Training loss: 2.1514002121699263
Validation loss: 2.0297798456465785
Epoch: 9| Step: 6
Training loss: 1.7493720290311094
Validation loss: 2.0560473893903146
Epoch: 9| Step: 7
Training loss: 2.8553981119960703
Validation loss: 2.0548307095695915
Epoch: 9| Step: 8
Training loss: 2.135460296433259
Validation loss: 2.0538994908338477
Epoch: 9| Step: 9
Training loss: 1.7009497233590603
Validation loss: 2.0082878396218566
Epoch: 9| Step: 10
Training loss: 2.7095906982446927
Validation loss: 2.0504545083503283
Epoch: 9| Step: 11
Training loss: 2.3457212169499013
Validation loss: 2.008460137093609
Epoch: 9| Step: 12
Training loss: 2.6233187241331257
Validation loss: 2.051892306435831
Epoch: 9| Step: 13
Training loss: 3.0469125598646474
Validation loss: 2.0499844069600677
Epoch: 9| Step: 14
Training loss: 3.0037967180737684
Validation loss: 2.0573793060485324
Epoch: 9| Step: 15
Training loss: 2.4080225373287525
Validation loss: 2.001699444601245
Epoch: 9| Step: 16
Training loss: 2.4417014469972185
Validation loss: 2.0657583327451414
Epoch: 9| Step: 17
Training loss: 2.4299329038862196
Validation loss: 2.0553211277486034
Epoch: 9| Step: 18
Training loss: 2.930241972269909
Validation loss: 2.022208517090436
Epoch: 9| Step: 19
Training loss: 2.407011431817047
Validation loss: 2.0187641360540045
Epoch: 66| Step: 0
Training loss: 3.0322924522329866
Validation loss: 2.05982621099765
Epoch: 9| Step: 1
Training loss: 2.1594341926908207
Validation loss: 2.018952121729513
Epoch: 9| Step: 2
Training loss: 1.826874786387381
Validation loss: 2.0443056128230435
Epoch: 9| Step: 3
Training loss: 2.57663059271876
Validation loss: 2.046733931668264
Epoch: 9| Step: 4
Training loss: 2.5091589049598584
Validation loss: 2.0406986811466337
Epoch: 9| Step: 5
Training loss: 1.848001459950948
Validation loss: 2.039346423642918
Epoch: 9| Step: 6
Training loss: 2.4878101711408442
Validation loss: 2.0447494857589485
Epoch: 9| Step: 7
Training loss: 2.5784164726334757
Validation loss: 2.015885843533682
Epoch: 9| Step: 8
Training loss: 2.7312178341435795
Validation loss: 2.005135802516619
Epoch: 9| Step: 9
Training loss: 2.6685535689165025
Validation loss: 2.0190122915284245
Epoch: 9| Step: 10
Training loss: 2.753331160863923
Validation loss: 2.02831215750637
Epoch: 9| Step: 11
Training loss: 2.668563486054166
Validation loss: 2.0323645970326805
Epoch: 9| Step: 12
Training loss: 3.463093725316944
Validation loss: 1.9769249306662224
Epoch: 9| Step: 13
Training loss: 1.7127709167477232
Validation loss: 1.9983526523557473
Epoch: 9| Step: 14
Training loss: 2.0682067526610894
Validation loss: 2.0014242564461293
Epoch: 9| Step: 15
Training loss: 2.7706864588155704
Validation loss: 2.016183255806046
Epoch: 9| Step: 16
Training loss: 1.8395112014516555
Validation loss: 2.006439355116232
Epoch: 9| Step: 17
Training loss: 1.9870716905029477
Validation loss: 2.004558908637005
Epoch: 9| Step: 18
Training loss: 2.4621906299186263
Validation loss: 2.067351244563151
Epoch: 9| Step: 19
Training loss: 2.253333695014759
Validation loss: 2.022817903710119
Epoch: 67| Step: 0
Training loss: 2.949091018032777
Validation loss: 2.0434518722005754
Epoch: 9| Step: 1
Training loss: 2.6815333112233457
Validation loss: 2.0291918389497785
Epoch: 9| Step: 2
Training loss: 2.898374325457074
Validation loss: 2.0186540496154333
Epoch: 9| Step: 3
Training loss: 2.90541458428142
Validation loss: 2.0323302586155516
Epoch: 9| Step: 4
Training loss: 2.2772996744434972
Validation loss: 2.0573348966548326
Epoch: 9| Step: 5
Training loss: 2.738872643792923
Validation loss: 2.0404780451117603
Epoch: 9| Step: 6
Training loss: 2.415741864100402
Validation loss: 2.0700599211008215
Epoch: 9| Step: 7
Training loss: 2.6967085166987634
Validation loss: 2.0636760650313675
Epoch: 9| Step: 8
Training loss: 1.7347002154093683
Validation loss: 2.040270533472982
Epoch: 9| Step: 9
Training loss: 2.3896325737941466
Validation loss: 2.0365760862914293
Epoch: 9| Step: 10
Training loss: 2.2145892607596718
Validation loss: 2.046199825065627
Epoch: 9| Step: 11
Training loss: 3.0450377573763605
Validation loss: 2.039841718292137
Epoch: 9| Step: 12
Training loss: 2.514120279789732
Validation loss: 2.040826387255585
Epoch: 9| Step: 13
Training loss: 2.3790302212989562
Validation loss: 2.0724178932211186
Epoch: 9| Step: 14
Training loss: 2.2230993275075677
Validation loss: 2.0679924324321894
Epoch: 9| Step: 15
Training loss: 2.070933813756952
Validation loss: 2.042547907220716
Epoch: 9| Step: 16
Training loss: 1.9771380886887426
Validation loss: 2.0556854904395356
Epoch: 9| Step: 17
Training loss: 1.4511664532936237
Validation loss: 2.0367508716110403
Epoch: 9| Step: 18
Training loss: 2.384546768180975
Validation loss: 2.059245410641267
Epoch: 9| Step: 19
Training loss: 2.1472120084378457
Validation loss: 2.0330056663514666
Epoch: 68| Step: 0
Training loss: 1.6377878271004798
Validation loss: 2.0503445552489277
Epoch: 9| Step: 1
Training loss: 2.337643615880257
Validation loss: 2.0639952924098637
Epoch: 9| Step: 2
Training loss: 2.0083441716873836
Validation loss: 2.051725768021938
Epoch: 9| Step: 3
Training loss: 2.8329633770429337
Validation loss: 2.06641598793954
Epoch: 9| Step: 4
Training loss: 1.806062909108909
Validation loss: 2.0231794564470698
Epoch: 9| Step: 5
Training loss: 2.3838239680527673
Validation loss: 2.0496113970261294
Epoch: 9| Step: 6
Training loss: 2.8443572685009215
Validation loss: 2.0179499327313395
Epoch: 9| Step: 7
Training loss: 2.5079968346084502
Validation loss: 2.03226973600569
Epoch: 9| Step: 8
Training loss: 2.5146672101847822
Validation loss: 2.0449603654608457
Epoch: 9| Step: 9
Training loss: 2.8749170706025238
Validation loss: 2.022445638400383
Epoch: 9| Step: 10
Training loss: 2.8707222003954445
Validation loss: 2.0518242396393003
Epoch: 9| Step: 11
Training loss: 2.879078501461557
Validation loss: 2.040309201655215
Epoch: 9| Step: 12
Training loss: 1.7595020228008709
Validation loss: 1.9841719108441271
Epoch: 9| Step: 13
Training loss: 2.630607791190891
Validation loss: 2.0373115284226366
Epoch: 9| Step: 14
Training loss: 2.0682983965795896
Validation loss: 2.009115305454214
Epoch: 9| Step: 15
Training loss: 2.7749038473430954
Validation loss: 2.009412740111334
Epoch: 9| Step: 16
Training loss: 2.2420809517775515
Validation loss: 2.0156208462979355
Epoch: 9| Step: 17
Training loss: 2.4722344639888187
Validation loss: 2.0049732178969824
Epoch: 9| Step: 18
Training loss: 2.8136801045234017
Validation loss: 2.0219684720977757
Epoch: 9| Step: 19
Training loss: 2.092686169362808
Validation loss: 2.0183507690442277
Epoch: 69| Step: 0
Training loss: 2.222873026864286
Validation loss: 2.0350960740525497
Epoch: 9| Step: 1
Training loss: 3.069428372424948
Validation loss: 2.067299347484586
Epoch: 9| Step: 2
Training loss: 2.0879563980519364
Validation loss: 2.0419825327665513
Epoch: 9| Step: 3
Training loss: 2.4219128021243352
Validation loss: 2.024454490628373
Epoch: 9| Step: 4
Training loss: 2.4029544209234692
Validation loss: 2.0420688571936543
Epoch: 9| Step: 5
Training loss: 2.428819311137571
Validation loss: 2.033795644604442
Epoch: 9| Step: 6
Training loss: 1.9988086251445867
Validation loss: 2.0294952035272362
Epoch: 9| Step: 7
Training loss: 2.6804794164549324
Validation loss: 2.0650076535981077
Epoch: 9| Step: 8
Training loss: 2.127087185140392
Validation loss: 2.0500219544453397
Epoch: 9| Step: 9
Training loss: 2.807715521375805
Validation loss: 2.0574383925210697
Epoch: 9| Step: 10
Training loss: 2.0463081332031066
Validation loss: 2.0657522841200113
Epoch: 9| Step: 11
Training loss: 2.762560164542978
Validation loss: 2.062604383165909
Epoch: 9| Step: 12
Training loss: 2.703169893983455
Validation loss: 2.0706608532246147
Epoch: 9| Step: 13
Training loss: 2.5939143484970484
Validation loss: 2.0453731873240115
Epoch: 9| Step: 14
Training loss: 2.3572950479166006
Validation loss: 2.0784992789415946
Epoch: 9| Step: 15
Training loss: 2.513563555419148
Validation loss: 2.083875681356062
Epoch: 9| Step: 16
Training loss: 2.9895184517619713
Validation loss: 2.1254829637088215
Epoch: 9| Step: 17
Training loss: 2.548293017344374
Validation loss: 2.0654948514434954
Epoch: 9| Step: 18
Training loss: 2.625781079297683
Validation loss: 2.0440443484710307
Epoch: 9| Step: 19
Training loss: 1.3351480482640816
Validation loss: 2.0710056741337435
Epoch: 70| Step: 0
Training loss: 2.487246024043189
Validation loss: 2.0504818668915537
Epoch: 9| Step: 1
Training loss: 2.001715639496232
Validation loss: 2.0921372391577124
Epoch: 9| Step: 2
Training loss: 2.2855042803884285
Validation loss: 2.018340035139369
Epoch: 9| Step: 3
Training loss: 2.4924880656699893
Validation loss: 2.033773869785082
Epoch: 9| Step: 4
Training loss: 2.623263647647636
Validation loss: 2.024499136834089
Epoch: 9| Step: 5
Training loss: 2.3632732801066543
Validation loss: 2.0371828881094123
Epoch: 9| Step: 6
Training loss: 2.5934819462156815
Validation loss: 2.0486963176175244
Epoch: 9| Step: 7
Training loss: 2.8100386975973533
Validation loss: 2.040764072698744
Epoch: 9| Step: 8
Training loss: 2.404186900123682
Validation loss: 1.9962889481413812
Epoch: 9| Step: 9
Training loss: 2.324936392129365
Validation loss: 2.0184228564105915
Epoch: 9| Step: 10
Training loss: 2.2664053789707155
Validation loss: 2.0566108848068705
Epoch: 9| Step: 11
Training loss: 2.9575248114866395
Validation loss: 2.0361552245692613
Epoch: 9| Step: 12
Training loss: 2.9657896038396188
Validation loss: 2.045385086850426
Epoch: 9| Step: 13
Training loss: 2.357907476717907
Validation loss: 2.0085127558793983
Epoch: 9| Step: 14
Training loss: 2.0321702486491207
Validation loss: 2.038524468138723
Epoch: 9| Step: 15
Training loss: 3.0627354122689745
Validation loss: 2.0337811029566324
Epoch: 9| Step: 16
Training loss: 2.050255815315163
Validation loss: 2.0236401913444304
Epoch: 9| Step: 17
Training loss: 2.3010188499782704
Validation loss: 1.9981944199689003
Epoch: 9| Step: 18
Training loss: 2.1199300534927232
Validation loss: 2.040014420105161
Epoch: 9| Step: 19
Training loss: 2.4676205912672815
Validation loss: 2.043012986410111
Epoch: 71| Step: 0
Training loss: 2.395174173540254
Validation loss: 2.0525342372689264
Epoch: 9| Step: 1
Training loss: 2.593748621193393
Validation loss: 2.0323242953929324
Epoch: 9| Step: 2
Training loss: 2.345173924549981
Validation loss: 2.0269420754348046
Epoch: 9| Step: 3
Training loss: 2.827102897949288
Validation loss: 2.0250583705382947
Epoch: 9| Step: 4
Training loss: 2.1202250294644736
Validation loss: 2.0314631884548024
Epoch: 9| Step: 5
Training loss: 3.136500596836787
Validation loss: 1.9977430496038202
Epoch: 9| Step: 6
Training loss: 2.274361439051484
Validation loss: 2.0102168237936997
Epoch: 9| Step: 7
Training loss: 3.079595998549522
Validation loss: 1.9999973622533684
Epoch: 9| Step: 8
Training loss: 2.871908432991092
Validation loss: 1.9816520204630845
Epoch: 9| Step: 9
Training loss: 2.029531133089173
Validation loss: 2.0130201633490468
Epoch: 9| Step: 10
Training loss: 1.6302748677709147
Validation loss: 2.0366844962608135
Epoch: 9| Step: 11
Training loss: 2.8175380088862254
Validation loss: 2.0220396919278087
Epoch: 9| Step: 12
Training loss: 2.1837544663574104
Validation loss: 2.020795011172034
Epoch: 9| Step: 13
Training loss: 2.0748609565201233
Validation loss: 2.030902559970227
Epoch: 9| Step: 14
Training loss: 2.361765275977068
Validation loss: 1.9843663355561694
Epoch: 9| Step: 15
Training loss: 2.1552061788610573
Validation loss: 2.091445336057716
Epoch: 9| Step: 16
Training loss: 2.32300922112476
Validation loss: 1.990429222273483
Epoch: 9| Step: 17
Training loss: 2.8524372588068765
Validation loss: 2.04894266952239
Epoch: 9| Step: 18
Training loss: 1.9134415845564154
Validation loss: 2.0565813060175033
Epoch: 9| Step: 19
Training loss: 2.5348759806315213
Validation loss: 2.0188943441127827
Epoch: 72| Step: 0
Training loss: 2.574068889973536
Validation loss: 2.0001664612266707
Epoch: 9| Step: 1
Training loss: 2.2170567028346353
Validation loss: 2.0038209386688703
Epoch: 9| Step: 2
Training loss: 2.686494861091656
Validation loss: 2.028721599200307
Epoch: 9| Step: 3
Training loss: 2.2178414862207148
Validation loss: 2.029727495608271
Epoch: 9| Step: 4
Training loss: 2.489676331468336
Validation loss: 2.062754478804676
Epoch: 9| Step: 5
Training loss: 2.2382331030761864
Validation loss: 2.051534549185284
Epoch: 9| Step: 6
Training loss: 2.1190474669903923
Validation loss: 2.0382460076088607
Epoch: 9| Step: 7
Training loss: 2.8141400112086723
Validation loss: 2.0146580592879597
Epoch: 9| Step: 8
Training loss: 2.4305583215122533
Validation loss: 2.065236654418194
Epoch: 9| Step: 9
Training loss: 2.0642679901983816
Validation loss: 2.029476621489057
Epoch: 9| Step: 10
Training loss: 3.083880625085516
Validation loss: 2.043263399667035
Epoch: 9| Step: 11
Training loss: 2.1259682637211705
Validation loss: 2.0205716454173634
Epoch: 9| Step: 12
Training loss: 2.0701000176559985
Validation loss: 2.0369728880495614
Epoch: 9| Step: 13
Training loss: 2.018284189438132
Validation loss: 2.0506273786723654
Epoch: 9| Step: 14
Training loss: 2.6335679959713016
Validation loss: 2.0672266178682333
Epoch: 9| Step: 15
Training loss: 2.775573251985296
Validation loss: 2.0602996348134455
Epoch: 9| Step: 16
Training loss: 2.444587770749188
Validation loss: 2.0663894839084773
Epoch: 9| Step: 17
Training loss: 2.4097828877264034
Validation loss: 2.0324013060304784
Epoch: 9| Step: 18
Training loss: 2.8548965820180867
Validation loss: 2.0656060367035467
Epoch: 9| Step: 19
Training loss: 2.400348908175944
Validation loss: 2.0667107845848753
Epoch: 73| Step: 0
Training loss: 2.5157912300110454
Validation loss: 2.055108250777588
Epoch: 9| Step: 1
Training loss: 2.3830220114731477
Validation loss: 2.030458772036336
Epoch: 9| Step: 2
Training loss: 2.8559262682803133
Validation loss: 2.0673739655839394
Epoch: 9| Step: 3
Training loss: 2.2781551741078685
Validation loss: 2.053288198414676
Epoch: 9| Step: 4
Training loss: 2.4118577092270814
Validation loss: 2.042599324640359
Epoch: 9| Step: 5
Training loss: 2.1540700978142766
Validation loss: 2.032852573981131
Epoch: 9| Step: 6
Training loss: 2.3029934104066525
Validation loss: 2.024048654269182
Epoch: 9| Step: 7
Training loss: 2.4780334532714092
Validation loss: 2.0377802806150616
Epoch: 9| Step: 8
Training loss: 2.5515077733409774
Validation loss: 2.05648889734049
Epoch: 9| Step: 9
Training loss: 2.5716340630030943
Validation loss: 2.031613004751246
Epoch: 9| Step: 10
Training loss: 2.886539851156899
Validation loss: 2.019954805810033
Epoch: 9| Step: 11
Training loss: 1.6323648231470127
Validation loss: 2.0245678991164517
Epoch: 9| Step: 12
Training loss: 2.2359938725709982
Validation loss: 2.0418014274057485
Epoch: 9| Step: 13
Training loss: 2.433325885952914
Validation loss: 2.004054305289185
Epoch: 9| Step: 14
Training loss: 2.653508106335035
Validation loss: 2.0315394038182575
Epoch: 9| Step: 15
Training loss: 2.4770832657446396
Validation loss: 2.0203574116294836
Epoch: 9| Step: 16
Training loss: 2.7257396254199917
Validation loss: 2.04562375561361
Epoch: 9| Step: 17
Training loss: 2.33089103491832
Validation loss: 2.004446551882079
Epoch: 9| Step: 18
Training loss: 2.3623025680475713
Validation loss: 2.010229099911142
Epoch: 9| Step: 19
Training loss: 2.5014893863627425
Validation loss: 2.0215695738025454
Epoch: 74| Step: 0
Training loss: 2.8465667859257824
Validation loss: 2.004721935368915
Epoch: 9| Step: 1
Training loss: 2.273222922984142
Validation loss: 2.017395410971373
Epoch: 9| Step: 2
Training loss: 2.0270644272971023
Validation loss: 2.008355312656504
Epoch: 9| Step: 3
Training loss: 2.121909193794349
Validation loss: 2.046559782980289
Epoch: 9| Step: 4
Training loss: 2.586456984233978
Validation loss: 2.015121096139815
Epoch: 9| Step: 5
Training loss: 3.0529799115506853
Validation loss: 2.0075453610099108
Epoch: 9| Step: 6
Training loss: 2.692289387462556
Validation loss: 2.0601849526341995
Epoch: 9| Step: 7
Training loss: 2.3606293230368145
Validation loss: 2.00695117728228
Epoch: 9| Step: 8
Training loss: 2.588565286468466
Validation loss: 2.0568261126311516
Epoch: 9| Step: 9
Training loss: 2.417759801559768
Validation loss: 2.0545017152047365
Epoch: 9| Step: 10
Training loss: 1.8172114730657511
Validation loss: 2.0378305900690687
Epoch: 9| Step: 11
Training loss: 2.6457210326704597
Validation loss: 2.0305879220487597
Epoch: 9| Step: 12
Training loss: 2.6552450635207054
Validation loss: 2.0344155972670253
Epoch: 9| Step: 13
Training loss: 2.314962982804557
Validation loss: 2.04159124761049
Epoch: 9| Step: 14
Training loss: 2.1907485818219494
Validation loss: 2.041419973993412
Epoch: 9| Step: 15
Training loss: 2.1908633941797437
Validation loss: 2.0553172122374717
Epoch: 9| Step: 16
Training loss: 1.9100313672391038
Validation loss: 2.0326399457003133
Epoch: 9| Step: 17
Training loss: 2.8693171187844353
Validation loss: 2.03175187716806
Epoch: 9| Step: 18
Training loss: 2.207129336177699
Validation loss: 2.0340214709520112
Epoch: 9| Step: 19
Training loss: 2.8366691549299947
Validation loss: 2.0424537824255395
Epoch: 75| Step: 0
Training loss: 2.5138636518116693
Validation loss: 2.017173882024138
Epoch: 9| Step: 1
Training loss: 2.018313130918911
Validation loss: 2.0255879781113992
Epoch: 9| Step: 2
Training loss: 3.015679393534705
Validation loss: 2.0498920555136038
Epoch: 9| Step: 3
Training loss: 2.2189088146699096
Validation loss: 2.0530429183827166
Epoch: 9| Step: 4
Training loss: 1.9839491499875515
Validation loss: 2.073538255971936
Epoch: 9| Step: 5
Training loss: 2.0566793439939124
Validation loss: 2.0325489131420778
Epoch: 9| Step: 6
Training loss: 2.361206556398135
Validation loss: 2.040045271431249
Epoch: 9| Step: 7
Training loss: 2.172553964873058
Validation loss: 2.077964629922196
Epoch: 9| Step: 8
Training loss: 2.2986264979016204
Validation loss: 2.0283734314437063
Epoch: 9| Step: 9
Training loss: 2.179628870459247
Validation loss: 2.0150398696268774
Epoch: 9| Step: 10
Training loss: 3.1561859426513266
Validation loss: 2.0507288708285634
Epoch: 9| Step: 11
Training loss: 2.291819711834405
Validation loss: 2.06041094536854
Epoch: 9| Step: 12
Training loss: 2.2617838953943705
Validation loss: 2.0441195411145716
Epoch: 9| Step: 13
Training loss: 2.2267551271870594
Validation loss: 2.0477617437009568
Epoch: 9| Step: 14
Training loss: 2.4447803832418025
Validation loss: 2.065355235505033
Epoch: 9| Step: 15
Training loss: 2.4276008108874665
Validation loss: 2.0379204514553133
Epoch: 9| Step: 16
Training loss: 2.337484198532142
Validation loss: 2.0178165269499386
Epoch: 9| Step: 17
Training loss: 2.744507332732082
Validation loss: 2.0254979961458446
Epoch: 9| Step: 18
Training loss: 2.4429227711809864
Validation loss: 2.0184420725669483
Epoch: 9| Step: 19
Training loss: 3.2244765810595926
Validation loss: 2.0395869886779794
Epoch: 76| Step: 0
Training loss: 1.9829189936279614
Validation loss: 2.0431347164738822
Epoch: 9| Step: 1
Training loss: 2.8834341976038957
Validation loss: 2.0101135300371302
Epoch: 9| Step: 2
Training loss: 2.313484600885676
Validation loss: 2.005424482192746
Epoch: 9| Step: 3
Training loss: 2.462588964104227
Validation loss: 2.0330207510618634
Epoch: 9| Step: 4
Training loss: 2.967734554697572
Validation loss: 1.9905095383343403
Epoch: 9| Step: 5
Training loss: 2.4347417826887434
Validation loss: 2.0196201498701964
Epoch: 9| Step: 6
Training loss: 2.560618942957486
Validation loss: 2.0303074600497495
Epoch: 9| Step: 7
Training loss: 2.4218530469330135
Validation loss: 2.038894881872562
Epoch: 9| Step: 8
Training loss: 2.621670200501534
Validation loss: 1.988108365715609
Epoch: 9| Step: 9
Training loss: 2.6656060096269987
Validation loss: 2.037038013944545
Epoch: 9| Step: 10
Training loss: 2.2717322807137323
Validation loss: 2.0510936044654704
Epoch: 9| Step: 11
Training loss: 2.3590156332017873
Validation loss: 2.060941997642993
Epoch: 9| Step: 12
Training loss: 2.483044730021314
Validation loss: 2.057932163862804
Epoch: 9| Step: 13
Training loss: 2.6380168968741198
Validation loss: 2.07846606995276
Epoch: 9| Step: 14
Training loss: 2.5706843423149968
Validation loss: 2.0419711844573043
Epoch: 9| Step: 15
Training loss: 1.7341340043626012
Validation loss: 2.0559508083327414
Epoch: 9| Step: 16
Training loss: 1.3441664028384255
Validation loss: 2.02426711496526
Epoch: 9| Step: 17
Training loss: 2.1369999172298146
Validation loss: 2.062567493559042
Epoch: 9| Step: 18
Training loss: 2.8522841285110183
Validation loss: 2.060389535979499
Epoch: 9| Step: 19
Training loss: 2.571127718779613
Validation loss: 2.04996971912617
Epoch: 77| Step: 0
Training loss: 1.8237449798619474
Validation loss: 2.0332730262181706
Epoch: 9| Step: 1
Training loss: 1.7605259276422585
Validation loss: 2.05052361952864
Epoch: 9| Step: 2
Training loss: 1.78285319142288
Validation loss: 2.0450033037704634
Epoch: 9| Step: 3
Training loss: 2.331886274217984
Validation loss: 2.0389093492999226
Epoch: 9| Step: 4
Training loss: 2.555694288367304
Validation loss: 2.066724640214954
Epoch: 9| Step: 5
Training loss: 2.325405298818245
Validation loss: 2.0360084489086123
Epoch: 9| Step: 6
Training loss: 2.648460995730264
Validation loss: 2.045693937223761
Epoch: 9| Step: 7
Training loss: 2.5439331288695772
Validation loss: 2.0413515156056214
Epoch: 9| Step: 8
Training loss: 2.9239921855065414
Validation loss: 1.9651883022905967
Epoch: 9| Step: 9
Training loss: 2.3164944559578906
Validation loss: 2.0159149286092175
Epoch: 9| Step: 10
Training loss: 2.374056779383307
Validation loss: 2.004196751261222
Epoch: 9| Step: 11
Training loss: 1.916671780565599
Validation loss: 2.0249751835890057
Epoch: 9| Step: 12
Training loss: 2.7974788930197256
Validation loss: 2.002766551003055
Epoch: 9| Step: 13
Training loss: 2.666169080404995
Validation loss: 2.0140269932781534
Epoch: 9| Step: 14
Training loss: 3.066603888684552
Validation loss: 1.9918432561485089
Epoch: 9| Step: 15
Training loss: 1.9735778468734588
Validation loss: 1.9922659393717015
Epoch: 9| Step: 16
Training loss: 2.6603652491090375
Validation loss: 2.0202271043390154
Epoch: 9| Step: 17
Training loss: 2.729150281861797
Validation loss: 2.0641337425487194
Epoch: 9| Step: 18
Training loss: 2.698005723894861
Validation loss: 2.0152872703533924
Epoch: 9| Step: 19
Training loss: 2.307579269452807
Validation loss: 2.0271368409178683
Epoch: 78| Step: 0
Training loss: 2.7896423591900628
Validation loss: 2.0130661392470053
Epoch: 9| Step: 1
Training loss: 2.2694189467360237
Validation loss: 1.9936520349414069
Epoch: 9| Step: 2
Training loss: 2.2177029140317206
Validation loss: 2.001769277740311
Epoch: 9| Step: 3
Training loss: 3.054303469506246
Validation loss: 2.004012983594904
Epoch: 9| Step: 4
Training loss: 2.3934202121419568
Validation loss: 1.9746813296040833
Epoch: 9| Step: 5
Training loss: 2.7957347911252866
Validation loss: 2.024387834142429
Epoch: 9| Step: 6
Training loss: 2.552634251096903
Validation loss: 2.009727615024084
Epoch: 9| Step: 7
Training loss: 2.9468394401726785
Validation loss: 2.0263542003054242
Epoch: 9| Step: 8
Training loss: 2.1294280646329167
Validation loss: 2.0056667150005683
Epoch: 9| Step: 9
Training loss: 2.5693716628847048
Validation loss: 2.033509379769152
Epoch: 9| Step: 10
Training loss: 2.5684593500325783
Validation loss: 2.0110527169719785
Epoch: 9| Step: 11
Training loss: 2.4446113726907126
Validation loss: 2.0064200406075328
Epoch: 9| Step: 12
Training loss: 2.2153035650343513
Validation loss: 2.0098966659674224
Epoch: 9| Step: 13
Training loss: 1.9203739041598005
Validation loss: 2.0073637088090535
Epoch: 9| Step: 14
Training loss: 2.4835666325022596
Validation loss: 2.0218588367750012
Epoch: 9| Step: 15
Training loss: 2.147787543731412
Validation loss: 1.9750541762437666
Epoch: 9| Step: 16
Training loss: 2.146803355791466
Validation loss: 2.003970456224033
Epoch: 9| Step: 17
Training loss: 2.3956407773687385
Validation loss: 2.0037063757263516
Epoch: 9| Step: 18
Training loss: 2.0533408041401158
Validation loss: 2.007944110221299
Epoch: 9| Step: 19
Training loss: 2.050620924722656
Validation loss: 2.006574147415302
Epoch: 79| Step: 0
Training loss: 2.8135378300286273
Validation loss: 2.0496226340723975
Epoch: 9| Step: 1
Training loss: 2.754623514471975
Validation loss: 2.017000459572925
Epoch: 9| Step: 2
Training loss: 2.9933893165649037
Validation loss: 2.007764298578606
Epoch: 9| Step: 3
Training loss: 2.6865874227033597
Validation loss: 2.0676355173830854
Epoch: 9| Step: 4
Training loss: 2.7711665782494452
Validation loss: 2.0336091152430242
Epoch: 9| Step: 5
Training loss: 1.7497055623450257
Validation loss: 2.0472584991633647
Epoch: 9| Step: 6
Training loss: 2.439584183360233
Validation loss: 2.0558439108960997
Epoch: 9| Step: 7
Training loss: 2.3463445925049764
Validation loss: 2.0654587271258813
Epoch: 9| Step: 8
Training loss: 2.6867303855224747
Validation loss: 2.070460534944105
Epoch: 9| Step: 9
Training loss: 1.9125906131196908
Validation loss: 2.0178047452215746
Epoch: 9| Step: 10
Training loss: 2.3294896983983095
Validation loss: 2.0279917942295254
Epoch: 9| Step: 11
Training loss: 2.295545647441698
Validation loss: 2.0302937472378892
Epoch: 9| Step: 12
Training loss: 1.8712114842591263
Validation loss: 2.027703835748687
Epoch: 9| Step: 13
Training loss: 2.491725197129052
Validation loss: 2.084855679999267
Epoch: 9| Step: 14
Training loss: 2.65109614607936
Validation loss: 2.076932842472848
Epoch: 9| Step: 15
Training loss: 2.133757776515491
Validation loss: 2.056468316847496
Epoch: 9| Step: 16
Training loss: 2.9568617657526737
Validation loss: 2.008250533538473
Epoch: 9| Step: 17
Training loss: 1.5926831732642779
Validation loss: 2.053456548373552
Epoch: 9| Step: 18
Training loss: 2.9740548371503577
Validation loss: 2.0682690750913495
Epoch: 9| Step: 19
Training loss: 2.2831026680076336
Validation loss: 2.0748839446643244
Epoch: 80| Step: 0
Training loss: 2.9882976855655046
Validation loss: 2.0583432267350394
Epoch: 9| Step: 1
Training loss: 2.8520208121098136
Validation loss: 2.0236949782712292
Epoch: 9| Step: 2
Training loss: 1.8710287636320235
Validation loss: 2.0538396586922465
Epoch: 9| Step: 3
Training loss: 2.8504920936184424
Validation loss: 2.022143297280088
Epoch: 9| Step: 4
Training loss: 2.42036144583891
Validation loss: 2.055262797973332
Epoch: 9| Step: 5
Training loss: 2.3665880508081214
Validation loss: 2.0596488920265212
Epoch: 9| Step: 6
Training loss: 2.5541145078758785
Validation loss: 2.055260712348159
Epoch: 9| Step: 7
Training loss: 2.0535744092457624
Validation loss: 2.013112976136076
Epoch: 9| Step: 8
Training loss: 2.3620814280609648
Validation loss: 2.030722363049742
Epoch: 9| Step: 9
Training loss: 2.0046675576268407
Validation loss: 2.0530707977142986
Epoch: 9| Step: 10
Training loss: 2.2783146615741106
Validation loss: 2.0147336172684973
Epoch: 9| Step: 11
Training loss: 2.1162276115517544
Validation loss: 2.0366872532515496
Epoch: 9| Step: 12
Training loss: 2.5616688194423043
Validation loss: 2.047137944358174
Epoch: 9| Step: 13
Training loss: 1.9811228136701264
Validation loss: 2.020169475175957
Epoch: 9| Step: 14
Training loss: 2.348591597546374
Validation loss: 2.066145539492552
Epoch: 9| Step: 15
Training loss: 3.5479476583892726
Validation loss: 2.0137757745921947
Epoch: 9| Step: 16
Training loss: 1.8719917324649797
Validation loss: 2.026739277929008
Epoch: 9| Step: 17
Training loss: 2.6945820136416274
Validation loss: 1.996976650284535
Epoch: 9| Step: 18
Training loss: 2.3313565963633143
Validation loss: 2.0082242986325927
Epoch: 9| Step: 19
Training loss: 2.317066117938256
Validation loss: 2.0189537470617633
Epoch: 81| Step: 0
Training loss: 2.182512537689727
Validation loss: 2.0311575706608496
Epoch: 9| Step: 1
Training loss: 2.0859200123257473
Validation loss: 2.0200563131923897
Epoch: 9| Step: 2
Training loss: 2.43577377620644
Validation loss: 2.077448563004096
Epoch: 9| Step: 3
Training loss: 2.341888604105521
Validation loss: 2.034508407389286
Epoch: 9| Step: 4
Training loss: 3.4138580191195755
Validation loss: 2.020288863418608
Epoch: 9| Step: 5
Training loss: 2.034681268423806
Validation loss: 2.007327943684592
Epoch: 9| Step: 6
Training loss: 2.559169558895377
Validation loss: 2.0404917433186713
Epoch: 9| Step: 7
Training loss: 2.2815335241258685
Validation loss: 2.033210347021977
Epoch: 9| Step: 8
Training loss: 2.309068246995096
Validation loss: 2.022555244501893
Epoch: 9| Step: 9
Training loss: 2.2721627453287243
Validation loss: 2.057965785559706
Epoch: 9| Step: 10
Training loss: 2.558161715074642
Validation loss: 2.022792404319368
Epoch: 9| Step: 11
Training loss: 2.8082472119205026
Validation loss: 2.070781938668625
Epoch: 9| Step: 12
Training loss: 2.3954046003995813
Validation loss: 2.050414958821285
Epoch: 9| Step: 13
Training loss: 2.7966568504800797
Validation loss: 2.018052703130585
Epoch: 9| Step: 14
Training loss: 2.2522647903368322
Validation loss: 2.014466597786035
Epoch: 9| Step: 15
Training loss: 2.3656769518772656
Validation loss: 2.0142180253419024
Epoch: 9| Step: 16
Training loss: 1.6892215283365455
Validation loss: 2.0260912650568046
Epoch: 9| Step: 17
Training loss: 2.0983590026852865
Validation loss: 2.019074053568624
Epoch: 9| Step: 18
Training loss: 2.787798341258244
Validation loss: 2.0276945081743682
Epoch: 9| Step: 19
Training loss: 2.4725663830183846
Validation loss: 2.0557912779923053
Epoch: 82| Step: 0
Training loss: 3.104320769783855
Validation loss: 2.0274521229138784
Epoch: 9| Step: 1
Training loss: 2.141986274867603
Validation loss: 2.0348806700467206
Epoch: 9| Step: 2
Training loss: 2.369181079943656
Validation loss: 2.004299258251942
Epoch: 9| Step: 3
Training loss: 2.015258992402098
Validation loss: 2.0145398431769217
Epoch: 9| Step: 4
Training loss: 2.6279319556207694
Validation loss: 2.054048603069893
Epoch: 9| Step: 5
Training loss: 2.9688370541307068
Validation loss: 2.0494345418096525
Epoch: 9| Step: 6
Training loss: 2.4722880832124
Validation loss: 2.031040043959945
Epoch: 9| Step: 7
Training loss: 2.3668367736646707
Validation loss: 2.0556004129754384
Epoch: 9| Step: 8
Training loss: 1.9366126951268583
Validation loss: 2.033353480490407
Epoch: 9| Step: 9
Training loss: 2.676036961720747
Validation loss: 2.0061227346919304
Epoch: 9| Step: 10
Training loss: 1.8170778407091335
Validation loss: 2.070800384902399
Epoch: 9| Step: 11
Training loss: 2.599024912580836
Validation loss: 2.0447115095045327
Epoch: 9| Step: 12
Training loss: 2.4308286483173736
Validation loss: 2.0526480274006214
Epoch: 9| Step: 13
Training loss: 2.4929577823924856
Validation loss: 2.0223030093020378
Epoch: 9| Step: 14
Training loss: 2.2825421370996635
Validation loss: 2.049314740818388
Epoch: 9| Step: 15
Training loss: 2.704658558391515
Validation loss: 2.057025646110537
Epoch: 9| Step: 16
Training loss: 1.291566670556653
Validation loss: 2.022890162148276
Epoch: 9| Step: 17
Training loss: 2.4816610999863675
Validation loss: 2.0248997055115443
Epoch: 9| Step: 18
Training loss: 2.2889250105360426
Validation loss: 2.0278349126596558
Epoch: 9| Step: 19
Training loss: 2.8524561487650324
Validation loss: 2.03134235387885
Epoch: 83| Step: 0
Training loss: 2.6345098893100705
Validation loss: 2.0281874183227155
Epoch: 9| Step: 1
Training loss: 2.3736562440987377
Validation loss: 2.065587074213404
Epoch: 9| Step: 2
Training loss: 1.8289492452554776
Validation loss: 2.015349374229397
Epoch: 9| Step: 3
Training loss: 1.983264882912688
Validation loss: 2.0142487255415005
Epoch: 9| Step: 4
Training loss: 2.6271810099518293
Validation loss: 2.039971402997854
Epoch: 9| Step: 5
Training loss: 2.561229390796352
Validation loss: 2.052610143843403
Epoch: 9| Step: 6
Training loss: 2.0425439104755383
Validation loss: 2.0368764095196097
Epoch: 9| Step: 7
Training loss: 2.5820598744985768
Validation loss: 2.0151391562556955
Epoch: 9| Step: 8
Training loss: 2.63191547450548
Validation loss: 2.0607092772983884
Epoch: 9| Step: 9
Training loss: 1.5830576639956615
Validation loss: 2.024326137642728
Epoch: 9| Step: 10
Training loss: 2.2811754815459073
Validation loss: 1.999535306445371
Epoch: 9| Step: 11
Training loss: 2.8963793415927537
Validation loss: 2.022713989897955
Epoch: 9| Step: 12
Training loss: 2.4838089208040777
Validation loss: 2.025293766164559
Epoch: 9| Step: 13
Training loss: 2.766581483088756
Validation loss: 2.033790244916733
Epoch: 9| Step: 14
Training loss: 2.1299486320641474
Validation loss: 2.0147277366441374
Epoch: 9| Step: 15
Training loss: 2.485285753978939
Validation loss: 1.986981869376485
Epoch: 9| Step: 16
Training loss: 2.773913189564473
Validation loss: 2.032506695073976
Epoch: 9| Step: 17
Training loss: 2.3976342661058894
Validation loss: 2.0037700614290435
Epoch: 9| Step: 18
Training loss: 2.515146909029177
Validation loss: 2.0091046937296033
Epoch: 9| Step: 19
Training loss: 2.7986836472653893
Validation loss: 1.973033598038912
Epoch: 84| Step: 0
Training loss: 2.478957501304515
Validation loss: 2.0232310872270336
Epoch: 9| Step: 1
Training loss: 1.904457562831821
Validation loss: 2.0265743602457307
Epoch: 9| Step: 2
Training loss: 1.8724872282073928
Validation loss: 2.0330139214660643
Epoch: 9| Step: 3
Training loss: 2.200163020249597
Validation loss: 1.972833896349479
Epoch: 9| Step: 4
Training loss: 2.5532582802693815
Validation loss: 1.999489279439362
Epoch: 9| Step: 5
Training loss: 2.55121322642714
Validation loss: 2.0133079373254046
Epoch: 9| Step: 6
Training loss: 2.712939048428302
Validation loss: 2.0262986906130656
Epoch: 9| Step: 7
Training loss: 2.1432964056382575
Validation loss: 2.010611698773422
Epoch: 9| Step: 8
Training loss: 1.888689547971864
Validation loss: 2.0112929611218964
Epoch: 9| Step: 9
Training loss: 3.0072011351075583
Validation loss: 2.061749000029046
Epoch: 9| Step: 10
Training loss: 2.204676629572942
Validation loss: 2.032409477454211
Epoch: 9| Step: 11
Training loss: 2.232938931878464
Validation loss: 2.0218546197814926
Epoch: 9| Step: 12
Training loss: 2.1640292278720437
Validation loss: 2.0762789971494513
Epoch: 9| Step: 13
Training loss: 2.7644041136024238
Validation loss: 2.052177426552363
Epoch: 9| Step: 14
Training loss: 3.083901962908921
Validation loss: 2.038012610364982
Epoch: 9| Step: 15
Training loss: 2.406011198009837
Validation loss: 2.0372627130605747
Epoch: 9| Step: 16
Training loss: 2.403281027462342
Validation loss: 2.001446580859111
Epoch: 9| Step: 17
Training loss: 2.3509583568446457
Validation loss: 2.044830883049461
Epoch: 9| Step: 18
Training loss: 2.63573856925928
Validation loss: 2.0678566525187807
Epoch: 9| Step: 19
Training loss: 2.4924652997110455
Validation loss: 2.0022033669932826
Epoch: 85| Step: 0
Training loss: 2.646714992258165
Validation loss: 1.985889106742703
Epoch: 9| Step: 1
Training loss: 2.2911490347052843
Validation loss: 2.017679311463622
Epoch: 9| Step: 2
Training loss: 2.8175505325402717
Validation loss: 2.0316859013928608
Epoch: 9| Step: 3
Training loss: 2.038722101204262
Validation loss: 2.0068349006579087
Epoch: 9| Step: 4
Training loss: 2.3444260702974997
Validation loss: 2.003913646899635
Epoch: 9| Step: 5
Training loss: 2.6190338454359114
Validation loss: 2.000299474122091
Epoch: 9| Step: 6
Training loss: 2.7379560291055944
Validation loss: 2.060283034462192
Epoch: 9| Step: 7
Training loss: 2.797500455172777
Validation loss: 2.0287671220643757
Epoch: 9| Step: 8
Training loss: 2.4538015416737373
Validation loss: 2.0095091602024824
Epoch: 9| Step: 9
Training loss: 2.0883182269760425
Validation loss: 2.0242664413228106
Epoch: 9| Step: 10
Training loss: 2.5645252691203946
Validation loss: 2.020259968280822
Epoch: 9| Step: 11
Training loss: 2.3696788607287314
Validation loss: 2.072144133153697
Epoch: 9| Step: 12
Training loss: 2.7637205301591625
Validation loss: 2.0098393590214854
Epoch: 9| Step: 13
Training loss: 2.0048844773647496
Validation loss: 2.068731241762356
Epoch: 9| Step: 14
Training loss: 2.584793529270518
Validation loss: 1.9981736812705693
Epoch: 9| Step: 15
Training loss: 2.031628500079482
Validation loss: 2.0237273023185973
Epoch: 9| Step: 16
Training loss: 2.53242371273842
Validation loss: 2.0172661848234577
Epoch: 9| Step: 17
Training loss: 2.3588365357196954
Validation loss: 1.989363463396975
Epoch: 9| Step: 18
Training loss: 2.346785753689131
Validation loss: 1.9940329045756762
Epoch: 9| Step: 19
Training loss: 1.943424334949951
Validation loss: 2.0105023871546734
Epoch: 86| Step: 0
Training loss: 2.1221974910118364
Validation loss: 2.0178569315742694
Epoch: 9| Step: 1
Training loss: 1.972586874166827
Validation loss: 1.9960032452962246
Epoch: 9| Step: 2
Training loss: 2.0507554406858075
Validation loss: 2.0110964451295694
Epoch: 9| Step: 3
Training loss: 2.481946417944072
Validation loss: 1.9899978758312307
Epoch: 9| Step: 4
Training loss: 2.4876152356930223
Validation loss: 2.021721075649339
Epoch: 9| Step: 5
Training loss: 2.385935453502724
Validation loss: 2.0235280931099044
Epoch: 9| Step: 6
Training loss: 2.6872311834694544
Validation loss: 2.056646368225098
Epoch: 9| Step: 7
Training loss: 2.2406426933153947
Validation loss: 2.0248340028810015
Epoch: 9| Step: 8
Training loss: 2.841277672179332
Validation loss: 2.018227603828246
Epoch: 9| Step: 9
Training loss: 2.3150499049301065
Validation loss: 2.027205553861957
Epoch: 9| Step: 10
Training loss: 1.9867793258090543
Validation loss: 2.069823439551507
Epoch: 9| Step: 11
Training loss: 3.219894798171441
Validation loss: 2.053366672508071
Epoch: 9| Step: 12
Training loss: 2.487664689789539
Validation loss: 2.0490786005413884
Epoch: 9| Step: 13
Training loss: 2.2186316875021905
Validation loss: 2.00030231848423
Epoch: 9| Step: 14
Training loss: 2.651559435652141
Validation loss: 2.0594685722536528
Epoch: 9| Step: 15
Training loss: 3.1706627845430257
Validation loss: 2.065262192125132
Epoch: 9| Step: 16
Training loss: 2.635020250101472
Validation loss: 2.0564034484470275
Epoch: 9| Step: 17
Training loss: 1.7228653622991286
Validation loss: 2.0578436033652037
Epoch: 9| Step: 18
Training loss: 2.403929148488397
Validation loss: 2.0439009299870836
Epoch: 9| Step: 19
Training loss: 2.320603272171692
Validation loss: 2.0238965144183605
Epoch: 87| Step: 0
Training loss: 1.9984919107410375
Validation loss: 1.9790123196018805
Epoch: 9| Step: 1
Training loss: 2.203676844533208
Validation loss: 2.0248307267484185
Epoch: 9| Step: 2
Training loss: 1.9875148652678412
Validation loss: 2.043061712383708
Epoch: 9| Step: 3
Training loss: 2.758401435019038
Validation loss: 2.0071836900484747
Epoch: 9| Step: 4
Training loss: 2.611101321840085
Validation loss: 2.029606069132792
Epoch: 9| Step: 5
Training loss: 2.7196196119007268
Validation loss: 2.0103194339098627
Epoch: 9| Step: 6
Training loss: 2.538757963257269
Validation loss: 1.9924774814866202
Epoch: 9| Step: 7
Training loss: 2.5864054553223648
Validation loss: 2.0043862612075367
Epoch: 9| Step: 8
Training loss: 2.7432549727393156
Validation loss: 1.9940579376604282
Epoch: 9| Step: 9
Training loss: 2.735168429110318
Validation loss: 2.0090360750090155
Epoch: 9| Step: 10
Training loss: 1.979843371968312
Validation loss: 1.9912343806232955
Epoch: 9| Step: 11
Training loss: 2.5012575801217873
Validation loss: 2.0347429986762613
Epoch: 9| Step: 12
Training loss: 1.694359155325431
Validation loss: 1.9924078106504106
Epoch: 9| Step: 13
Training loss: 2.721171123183312
Validation loss: 1.9850427710177183
Epoch: 9| Step: 14
Training loss: 2.653617721473602
Validation loss: 2.0567505462147753
Epoch: 9| Step: 15
Training loss: 1.7219242261991334
Validation loss: 2.0002953607588414
Epoch: 9| Step: 16
Training loss: 2.0754600015019498
Validation loss: 2.019517666647967
Epoch: 9| Step: 17
Training loss: 2.7281436216018156
Validation loss: 2.030692425633964
Epoch: 9| Step: 18
Training loss: 2.54612795867366
Validation loss: 2.035296104062627
Epoch: 9| Step: 19
Training loss: 2.5168849088342573
Validation loss: 2.0098821188233473
Epoch: 88| Step: 0
Training loss: 3.212451587119246
Validation loss: 2.0399276206968087
Epoch: 9| Step: 1
Training loss: 2.2737497855884183
Validation loss: 2.0092286824837773
Epoch: 9| Step: 2
Training loss: 2.294265614278849
Validation loss: 2.0206754169822188
Epoch: 9| Step: 3
Training loss: 1.9778916786318514
Validation loss: 2.0159570308426846
Epoch: 9| Step: 4
Training loss: 2.6545483692480976
Validation loss: 2.0344766683071827
Epoch: 9| Step: 5
Training loss: 3.0037617940111585
Validation loss: 2.018476200270714
Epoch: 9| Step: 6
Training loss: 2.8191787258352217
Validation loss: 2.016254288330538
Epoch: 9| Step: 7
Training loss: 2.2453500594552844
Validation loss: 2.020877489117665
Epoch: 9| Step: 8
Training loss: 2.6664697057783155
Validation loss: 1.9868386518458705
Epoch: 9| Step: 9
Training loss: 2.4527045211518272
Validation loss: 2.029794348490437
Epoch: 9| Step: 10
Training loss: 1.903302399583806
Validation loss: 1.9495427629141364
Epoch: 9| Step: 11
Training loss: 1.987627682693098
Validation loss: 1.996826202255896
Epoch: 9| Step: 12
Training loss: 2.043940180058057
Validation loss: 2.0127955018943133
Epoch: 9| Step: 13
Training loss: 2.2848098361896176
Validation loss: 1.9958671689040328
Epoch: 9| Step: 14
Training loss: 2.3875205633266527
Validation loss: 1.9926688178076752
Epoch: 9| Step: 15
Training loss: 2.619230560419929
Validation loss: 2.0207950985189034
Epoch: 9| Step: 16
Training loss: 2.8014944277831693
Validation loss: 2.0079009586664793
Epoch: 9| Step: 17
Training loss: 1.9221297924822738
Validation loss: 2.0287132922043156
Epoch: 9| Step: 18
Training loss: 1.9740366723075617
Validation loss: 2.051209955614376
Epoch: 9| Step: 19
Training loss: 2.2745832459752036
Validation loss: 2.0295246818862305
Epoch: 89| Step: 0
Training loss: 2.5626587237070595
Validation loss: 2.0067436005106214
Epoch: 9| Step: 1
Training loss: 2.4867333308975015
Validation loss: 2.0383215756638777
Epoch: 9| Step: 2
Training loss: 2.0544304632551644
Validation loss: 2.02321863632533
Epoch: 9| Step: 3
Training loss: 3.029758833802357
Validation loss: 2.038863872651001
Epoch: 9| Step: 4
Training loss: 1.744342172902198
Validation loss: 2.035686021482582
Epoch: 9| Step: 5
Training loss: 2.930636239610931
Validation loss: 2.0358296872065424
Epoch: 9| Step: 6
Training loss: 1.613205877949519
Validation loss: 2.047015402162579
Epoch: 9| Step: 7
Training loss: 2.1501418133474086
Validation loss: 2.0703489135393913
Epoch: 9| Step: 8
Training loss: 2.241157534426398
Validation loss: 2.0169848780134667
Epoch: 9| Step: 9
Training loss: 2.2901776302360144
Validation loss: 2.0205588767713083
Epoch: 9| Step: 10
Training loss: 3.044635438690289
Validation loss: 2.0315610573593483
Epoch: 9| Step: 11
Training loss: 2.4551700887397465
Validation loss: 2.045290012487701
Epoch: 9| Step: 12
Training loss: 2.8576266253859592
Validation loss: 2.016135219588429
Epoch: 9| Step: 13
Training loss: 3.040466768670021
Validation loss: 2.0375751469371464
Epoch: 9| Step: 14
Training loss: 2.4008394323040037
Validation loss: 2.0341794469088392
Epoch: 9| Step: 15
Training loss: 2.6901898784344667
Validation loss: 2.0473857342969084
Epoch: 9| Step: 16
Training loss: 1.810012689198226
Validation loss: 2.0317399305019874
Epoch: 9| Step: 17
Training loss: 2.4594818169591903
Validation loss: 2.0315042778669157
Epoch: 9| Step: 18
Training loss: 1.8264342094119965
Validation loss: 2.004211143461548
Epoch: 9| Step: 19
Training loss: 1.7234383189665439
Validation loss: 2.0111020784605644
Epoch: 90| Step: 0
Training loss: 2.2259259301104093
Validation loss: 2.0184062087819545
Epoch: 9| Step: 1
Training loss: 2.5850411789231744
Validation loss: 2.018848801078493
Epoch: 9| Step: 2
Training loss: 2.3524651806775054
Validation loss: 1.997725013571605
Epoch: 9| Step: 3
Training loss: 2.106079918760573
Validation loss: 2.039046987312842
Epoch: 9| Step: 4
Training loss: 3.063418814954206
Validation loss: 2.0499686768846077
Epoch: 9| Step: 5
Training loss: 2.184581662772257
Validation loss: 2.027777430078646
Epoch: 9| Step: 6
Training loss: 2.8109842242460132
Validation loss: 2.045739082080914
Epoch: 9| Step: 7
Training loss: 2.910635971366481
Validation loss: 2.044233426572766
Epoch: 9| Step: 8
Training loss: 2.0441380030409086
Validation loss: 2.0091926314041184
Epoch: 9| Step: 9
Training loss: 1.6533738841318892
Validation loss: 1.9975996886759535
Epoch: 9| Step: 10
Training loss: 1.733470233988465
Validation loss: 2.015031243309512
Epoch: 9| Step: 11
Training loss: 2.6816420475232934
Validation loss: 2.0435136669707608
Epoch: 9| Step: 12
Training loss: 2.240635989706204
Validation loss: 2.045450558581078
Epoch: 9| Step: 13
Training loss: 2.57845614069515
Validation loss: 2.0333086921515924
Epoch: 9| Step: 14
Training loss: 2.5625339598847745
Validation loss: 2.0424934352346744
Epoch: 9| Step: 15
Training loss: 2.3473755324316534
Validation loss: 2.02138264898737
Epoch: 9| Step: 16
Training loss: 2.3534599076003246
Validation loss: 2.0093484297753097
Epoch: 9| Step: 17
Training loss: 2.4829237435868396
Validation loss: 2.0130906793212504
Epoch: 9| Step: 18
Training loss: 2.0793719458550424
Validation loss: 2.0148069542937272
Epoch: 9| Step: 19
Training loss: 2.4684950298516593
Validation loss: 2.0343283102027185
Epoch: 91| Step: 0
Training loss: 2.553597313885961
Validation loss: 2.026792024586833
Epoch: 9| Step: 1
Training loss: 2.034449478403379
Validation loss: 1.990203826371619
Epoch: 9| Step: 2
Training loss: 2.1655035075668154
Validation loss: 1.9893934736148633
Epoch: 9| Step: 3
Training loss: 1.975612306442441
Validation loss: 2.031632107849513
Epoch: 9| Step: 4
Training loss: 2.584398439755402
Validation loss: 1.9902184593921957
Epoch: 9| Step: 5
Training loss: 2.881465773043418
Validation loss: 2.0466393203837026
Epoch: 9| Step: 6
Training loss: 2.211906732879688
Validation loss: 2.026722126353121
Epoch: 9| Step: 7
Training loss: 2.6181876477805175
Validation loss: 2.025203412201352
Epoch: 9| Step: 8
Training loss: 2.001661325913969
Validation loss: 2.0257700274589805
Epoch: 9| Step: 9
Training loss: 2.3522360207864668
Validation loss: 2.0219839765475975
Epoch: 9| Step: 10
Training loss: 1.8040753271696541
Validation loss: 2.067809804283805
Epoch: 9| Step: 11
Training loss: 2.3505668686908296
Validation loss: 2.029408693072931
Epoch: 9| Step: 12
Training loss: 2.6352044624466857
Validation loss: 2.0380692082606524
Epoch: 9| Step: 13
Training loss: 2.2803188147920737
Validation loss: 2.058148955375429
Epoch: 9| Step: 14
Training loss: 2.236755063811105
Validation loss: 2.064395775362086
Epoch: 9| Step: 15
Training loss: 1.920590227124496
Validation loss: 2.048965433490362
Epoch: 9| Step: 16
Training loss: 2.877982044293854
Validation loss: 2.054661231923068
Epoch: 9| Step: 17
Training loss: 2.2347014928909634
Validation loss: 2.055721214283732
Epoch: 9| Step: 18
Training loss: 3.2825387512848225
Validation loss: 2.0374334538588266
Epoch: 9| Step: 19
Training loss: 2.8985416362799645
Validation loss: 2.061281634523625
Epoch: 92| Step: 0
Training loss: 2.7927239157329597
Validation loss: 2.0309440401541075
Epoch: 9| Step: 1
Training loss: 2.2016350868880723
Validation loss: 2.013975678121625
Epoch: 9| Step: 2
Training loss: 2.3231847177896103
Validation loss: 1.9789545077755848
Epoch: 9| Step: 3
Training loss: 2.3892070080380856
Validation loss: 2.012546280195889
Epoch: 9| Step: 4
Training loss: 2.3413859333713565
Validation loss: 2.021027928449785
Epoch: 9| Step: 5
Training loss: 2.4614259265429683
Validation loss: 1.984836180106945
Epoch: 9| Step: 6
Training loss: 2.4814641442122896
Validation loss: 2.0067697384785017
Epoch: 9| Step: 7
Training loss: 2.757856244396778
Validation loss: 2.0091507519218172
Epoch: 9| Step: 8
Training loss: 1.9332241128894883
Validation loss: 2.0133547526772513
Epoch: 9| Step: 9
Training loss: 2.285592114214834
Validation loss: 2.0156313055003543
Epoch: 9| Step: 10
Training loss: 2.7832133189232175
Validation loss: 2.015263937584382
Epoch: 9| Step: 11
Training loss: 1.9142066745565565
Validation loss: 1.9808150851619042
Epoch: 9| Step: 12
Training loss: 2.405378505876105
Validation loss: 2.0222633079542853
Epoch: 9| Step: 13
Training loss: 2.672925508345274
Validation loss: 2.0044755435786135
Epoch: 9| Step: 14
Training loss: 2.194052989935303
Validation loss: 2.0033733847336443
Epoch: 9| Step: 15
Training loss: 2.1968504382045118
Validation loss: 1.978390166715677
Epoch: 9| Step: 16
Training loss: 2.3652169363196416
Validation loss: 2.0070593512869053
Epoch: 9| Step: 17
Training loss: 2.8433232249191693
Validation loss: 2.01117561478279
Epoch: 9| Step: 18
Training loss: 2.1186612901149267
Validation loss: 2.020447579632763
Epoch: 9| Step: 19
Training loss: 2.562316887988809
Validation loss: 1.968160001138445
Epoch: 93| Step: 0
Training loss: 2.484857092572491
Validation loss: 1.9947989022226762
Epoch: 9| Step: 1
Training loss: 1.9946156383432652
Validation loss: 1.9946566805806834
Epoch: 9| Step: 2
Training loss: 2.2324351179342554
Validation loss: 1.9880465845173965
Epoch: 9| Step: 3
Training loss: 2.8618661836787007
Validation loss: 1.9794236668403002
Epoch: 9| Step: 4
Training loss: 1.9463783010188127
Validation loss: 1.9657783713942338
Epoch: 9| Step: 5
Training loss: 1.7668941291391587
Validation loss: 2.008614618532975
Epoch: 9| Step: 6
Training loss: 2.7288106050283583
Validation loss: 2.0431566502449914
Epoch: 9| Step: 7
Training loss: 2.9536812071794443
Validation loss: 2.0294991742689388
Epoch: 9| Step: 8
Training loss: 1.895416933659118
Validation loss: 2.041105088573591
Epoch: 9| Step: 9
Training loss: 2.6275236623408147
Validation loss: 2.05239450374401
Epoch: 9| Step: 10
Training loss: 2.489897821160651
Validation loss: 2.006001487274498
Epoch: 9| Step: 11
Training loss: 2.447888464799038
Validation loss: 2.057945734316396
Epoch: 9| Step: 12
Training loss: 2.11021327563461
Validation loss: 1.994650735076318
Epoch: 9| Step: 13
Training loss: 2.0201778594171356
Validation loss: 2.0489806102262675
Epoch: 9| Step: 14
Training loss: 2.711320130007077
Validation loss: 2.0602653116299847
Epoch: 9| Step: 15
Training loss: 2.7589980216771024
Validation loss: 2.037630102564039
Epoch: 9| Step: 16
Training loss: 2.218928800013928
Validation loss: 1.999521645190483
Epoch: 9| Step: 17
Training loss: 2.79355104151863
Validation loss: 2.0398025387895564
Epoch: 9| Step: 18
Training loss: 2.332953751433865
Validation loss: 2.0306779435579414
Epoch: 9| Step: 19
Training loss: 2.657976823377062
Validation loss: 2.027612173125604
Epoch: 94| Step: 0
Training loss: 1.890830288925623
Validation loss: 2.0314134240051605
Epoch: 9| Step: 1
Training loss: 2.2988457561584923
Validation loss: 2.0714589539872397
Epoch: 9| Step: 2
Training loss: 1.3722932356161428
Validation loss: 2.0271547152623817
Epoch: 9| Step: 3
Training loss: 1.8703959842364666
Validation loss: 2.011367340978835
Epoch: 9| Step: 4
Training loss: 3.1553869294913244
Validation loss: 2.011352693131925
Epoch: 9| Step: 5
Training loss: 2.5042347328045875
Validation loss: 2.0167829730120617
Epoch: 9| Step: 6
Training loss: 2.4622197761458464
Validation loss: 1.996188581971488
Epoch: 9| Step: 7
Training loss: 2.021904795690968
Validation loss: 2.0306598400830826
Epoch: 9| Step: 8
Training loss: 2.6341147442432806
Validation loss: 2.045772344848045
Epoch: 9| Step: 9
Training loss: 1.8628855031079659
Validation loss: 2.03115843446062
Epoch: 9| Step: 10
Training loss: 2.486638315753379
Validation loss: 2.012163916728437
Epoch: 9| Step: 11
Training loss: 2.593025933738803
Validation loss: 2.0358263741438813
Epoch: 9| Step: 12
Training loss: 2.339636180503884
Validation loss: 2.030649864675641
Epoch: 9| Step: 13
Training loss: 2.254028105458162
Validation loss: 2.042136754111166
Epoch: 9| Step: 14
Training loss: 2.62209622673996
Validation loss: 2.0130930951538932
Epoch: 9| Step: 15
Training loss: 2.767219213285684
Validation loss: 2.0464825415754038
Epoch: 9| Step: 16
Training loss: 3.185912990054844
Validation loss: 2.0622675512500024
Epoch: 9| Step: 17
Training loss: 2.8530709235424174
Validation loss: 2.024057110355376
Epoch: 9| Step: 18
Training loss: 2.1056761913695063
Validation loss: 2.0055235750155873
Epoch: 9| Step: 19
Training loss: 2.12566197126226
Validation loss: 2.0096944376126036
Epoch: 95| Step: 0
Training loss: 2.6732111930374236
Validation loss: 2.0502591958595056
Epoch: 9| Step: 1
Training loss: 2.621366074538374
Validation loss: 2.050175659234549
Epoch: 9| Step: 2
Training loss: 1.6675813390290237
Validation loss: 2.031490536600381
Epoch: 9| Step: 3
Training loss: 2.5974476207044996
Validation loss: 1.9940251732238001
Epoch: 9| Step: 4
Training loss: 2.24160408112279
Validation loss: 2.0643303659648784
Epoch: 9| Step: 5
Training loss: 1.935954985335654
Validation loss: 2.049650977831052
Epoch: 9| Step: 6
Training loss: 2.8816128847726907
Validation loss: 2.009961414343791
Epoch: 9| Step: 7
Training loss: 2.529473328787027
Validation loss: 2.0258346051823772
Epoch: 9| Step: 8
Training loss: 2.7530242589733214
Validation loss: 2.030276361730413
Epoch: 9| Step: 9
Training loss: 1.9635142384307438
Validation loss: 2.0183102510713806
Epoch: 9| Step: 10
Training loss: 3.189778130926371
Validation loss: 1.9902032595044032
Epoch: 9| Step: 11
Training loss: 2.3189639915575717
Validation loss: 1.9976282151665437
Epoch: 9| Step: 12
Training loss: 2.3620089550446113
Validation loss: 1.9986366793006014
Epoch: 9| Step: 13
Training loss: 2.2550884564425884
Validation loss: 1.9949136463658326
Epoch: 9| Step: 14
Training loss: 2.40168845070413
Validation loss: 1.9788728212915594
Epoch: 9| Step: 15
Training loss: 3.0210910731013483
Validation loss: 2.005307676189155
Epoch: 9| Step: 16
Training loss: 2.1455765974906287
Validation loss: 1.9907155421367522
Epoch: 9| Step: 17
Training loss: 2.23667458594901
Validation loss: 2.010066208335945
Epoch: 9| Step: 18
Training loss: 2.482002901246176
Validation loss: 1.9771563553552332
Epoch: 9| Step: 19
Training loss: 1.9238558849520027
Validation loss: 1.994710520505606
Epoch: 96| Step: 0
Training loss: 2.1174272352234595
Validation loss: 1.995611064837663
Epoch: 9| Step: 1
Training loss: 2.29908718571354
Validation loss: 2.02388047048085
Epoch: 9| Step: 2
Training loss: 2.284603841150263
Validation loss: 2.03653242854759
Epoch: 9| Step: 3
Training loss: 2.456399857703402
Validation loss: 1.9976938143662837
Epoch: 9| Step: 4
Training loss: 2.6674237567334216
Validation loss: 2.0010161896690923
Epoch: 9| Step: 5
Training loss: 2.0996806855622694
Validation loss: 2.0085879907241457
Epoch: 9| Step: 6
Training loss: 2.365947134038386
Validation loss: 2.026207446364647
Epoch: 9| Step: 7
Training loss: 2.3059353828342912
Validation loss: 1.974449469291145
Epoch: 9| Step: 8
Training loss: 2.161400214336911
Validation loss: 2.0256614215759816
Epoch: 9| Step: 9
Training loss: 2.7119180186829714
Validation loss: 1.9697262979478125
Epoch: 9| Step: 10
Training loss: 2.268920501103097
Validation loss: 1.9975849511050032
Epoch: 9| Step: 11
Training loss: 2.801048191602509
Validation loss: 1.9814603287194645
Epoch: 9| Step: 12
Training loss: 2.455561988509523
Validation loss: 2.010711028738717
Epoch: 9| Step: 13
Training loss: 2.3439139753837006
Validation loss: 2.030056008347755
Epoch: 9| Step: 14
Training loss: 2.7166022224817663
Validation loss: 2.045845176721268
Epoch: 9| Step: 15
Training loss: 2.6371695578161756
Validation loss: 2.008541531677717
Epoch: 9| Step: 16
Training loss: 3.075264468101417
Validation loss: 2.0360685339330185
Epoch: 9| Step: 17
Training loss: 1.7547635232654593
Validation loss: 1.9999412607555127
Epoch: 9| Step: 18
Training loss: 2.6228370838247144
Validation loss: 2.0401289265794507
Epoch: 9| Step: 19
Training loss: 1.6273943061319267
Validation loss: 2.0481738935708855
Epoch: 97| Step: 0
Training loss: 2.063353853056912
Validation loss: 1.9989318441562691
Epoch: 9| Step: 1
Training loss: 2.6160777002163633
Validation loss: 2.0113005341190755
Epoch: 9| Step: 2
Training loss: 1.9829889698423946
Validation loss: 2.0472658244959976
Epoch: 9| Step: 3
Training loss: 1.9760424868498692
Validation loss: 2.034564637698866
Epoch: 9| Step: 4
Training loss: 2.559762748810951
Validation loss: 2.0024363046162392
Epoch: 9| Step: 5
Training loss: 2.652796126652272
Validation loss: 2.0099991775073316
Epoch: 9| Step: 6
Training loss: 2.219514419615384
Validation loss: 2.062555696871629
Epoch: 9| Step: 7
Training loss: 2.5522974248861683
Validation loss: 2.0152840332830992
Epoch: 9| Step: 8
Training loss: 1.9237277396874204
Validation loss: 2.023403139815029
Epoch: 9| Step: 9
Training loss: 2.609566595844174
Validation loss: 2.006757082827945
Epoch: 9| Step: 10
Training loss: 2.91759614212371
Validation loss: 2.0114499002536608
Epoch: 9| Step: 11
Training loss: 2.452877931240943
Validation loss: 2.0346955609018433
Epoch: 9| Step: 12
Training loss: 1.9862541852634477
Validation loss: 2.03460221853554
Epoch: 9| Step: 13
Training loss: 3.021522250489822
Validation loss: 2.0227237690250055
Epoch: 9| Step: 14
Training loss: 2.204813317075411
Validation loss: 2.010580734030748
Epoch: 9| Step: 15
Training loss: 2.65218464032843
Validation loss: 2.0316926735049137
Epoch: 9| Step: 16
Training loss: 2.3993063480604686
Validation loss: 2.011793926658654
Epoch: 9| Step: 17
Training loss: 2.490321306693433
Validation loss: 1.9861776236431905
Epoch: 9| Step: 18
Training loss: 2.481685694341257
Validation loss: 2.033016533181572
Epoch: 9| Step: 19
Training loss: 2.1141501172412522
Validation loss: 1.9846254283585667
Epoch: 98| Step: 0
Training loss: 2.5205643775738285
Validation loss: 2.0194911633505335
Epoch: 9| Step: 1
Training loss: 2.3301785008569005
Validation loss: 2.0270707855861168
Epoch: 9| Step: 2
Training loss: 2.506688326512088
Validation loss: 1.990688433469763
Epoch: 9| Step: 3
Training loss: 2.9350553038811418
Validation loss: 2.0126771758534643
Epoch: 9| Step: 4
Training loss: 2.0368538656949675
Validation loss: 1.9996400038505382
Epoch: 9| Step: 5
Training loss: 2.401090167721794
Validation loss: 2.0031627646467864
Epoch: 9| Step: 6
Training loss: 2.351841906807143
Validation loss: 2.0168861178608597
Epoch: 9| Step: 7
Training loss: 2.9159485795833944
Validation loss: 2.0072567842073403
Epoch: 9| Step: 8
Training loss: 2.155423655631047
Validation loss: 2.011351121792041
Epoch: 9| Step: 9
Training loss: 2.7524013438548183
Validation loss: 1.994629229011972
Epoch: 9| Step: 10
Training loss: 1.6509679382741593
Validation loss: 2.01709319911533
Epoch: 9| Step: 11
Training loss: 1.8579628975759772
Validation loss: 1.9670664618749425
Epoch: 9| Step: 12
Training loss: 2.6378014270236876
Validation loss: 1.9894730898703636
Epoch: 9| Step: 13
Training loss: 2.912482029937186
Validation loss: 1.9906057371987227
Epoch: 9| Step: 14
Training loss: 1.7908525465474097
Validation loss: 2.00509286811866
Epoch: 9| Step: 15
Training loss: 2.2547546588203713
Validation loss: 2.0167437590487975
Epoch: 9| Step: 16
Training loss: 2.6962709353734646
Validation loss: 2.0167454450269764
Epoch: 9| Step: 17
Training loss: 1.9109279579304894
Validation loss: 1.9948553931619069
Epoch: 9| Step: 18
Training loss: 2.5232558997034333
Validation loss: 1.9766836370648875
Epoch: 9| Step: 19
Training loss: 2.36830923363032
Validation loss: 1.947542140909446
Epoch: 99| Step: 0
Training loss: 2.016749814844129
Validation loss: 1.9749329583196242
Epoch: 9| Step: 1
Training loss: 2.6749891904808614
Validation loss: 1.9964342842366336
Epoch: 9| Step: 2
Training loss: 1.8957565906907619
Validation loss: 1.9911787621512533
Epoch: 9| Step: 3
Training loss: 2.75605013029684
Validation loss: 2.00126663298584
Epoch: 9| Step: 4
Training loss: 1.8010116065719388
Validation loss: 2.025582952866143
Epoch: 9| Step: 5
Training loss: 2.230216685146876
Validation loss: 2.01617820096606
Epoch: 9| Step: 6
Training loss: 2.3781786277228347
Validation loss: 2.0188139249676977
Epoch: 9| Step: 7
Training loss: 2.022802069024357
Validation loss: 2.008150430617146
Epoch: 9| Step: 8
Training loss: 2.643537100658391
Validation loss: 2.0392960940781473
Epoch: 9| Step: 9
Training loss: 2.357906566687447
Validation loss: 2.027559962461712
Epoch: 9| Step: 10
Training loss: 2.4195916025125435
Validation loss: 2.0152827387528793
Epoch: 9| Step: 11
Training loss: 2.856956084141201
Validation loss: 2.0156165567425846
Epoch: 9| Step: 12
Training loss: 2.6675088466508314
Validation loss: 2.0424939999317338
Epoch: 9| Step: 13
Training loss: 2.2121633629169835
Validation loss: 2.039069359911831
Epoch: 9| Step: 14
Training loss: 2.456607266522749
Validation loss: 2.0140706421643464
Epoch: 9| Step: 15
Training loss: 2.3506082518674947
Validation loss: 2.0421571592541135
Epoch: 9| Step: 16
Training loss: 2.243830381350925
Validation loss: 2.048665453616218
Epoch: 9| Step: 17
Training loss: 2.640508344432299
Validation loss: 2.032505473472144
Epoch: 9| Step: 18
Training loss: 2.0021399731783207
Validation loss: 2.062889030266283
Epoch: 9| Step: 19
Training loss: 2.8233637907268694
Validation loss: 2.0524403814677235
Epoch: 100| Step: 0
Training loss: 3.10497858749599
Validation loss: 2.00750625577805
Epoch: 9| Step: 1
Training loss: 2.535174494649777
Validation loss: 2.031900825747954
Epoch: 9| Step: 2
Training loss: 2.8016025929685715
Validation loss: 2.0433211155248228
Epoch: 9| Step: 3
Training loss: 2.7732144978017605
Validation loss: 2.0633727650227276
Epoch: 9| Step: 4
Training loss: 2.432797909535467
Validation loss: 1.981961458448846
Epoch: 9| Step: 5
Training loss: 2.423090279138293
Validation loss: 2.0326809693185344
Epoch: 9| Step: 6
Training loss: 1.986069083788027
Validation loss: 2.03674835145453
Epoch: 9| Step: 7
Training loss: 2.5140344555359273
Validation loss: 2.00575465377252
Epoch: 9| Step: 8
Training loss: 2.3973964954424756
Validation loss: 1.9953204946245953
Epoch: 9| Step: 9
Training loss: 1.4523572636920041
Validation loss: 2.0171109806322147
Epoch: 9| Step: 10
Training loss: 3.1386317670119386
Validation loss: 2.0274390331313743
Epoch: 9| Step: 11
Training loss: 1.9673645957876718
Validation loss: 2.0260132897295713
Epoch: 9| Step: 12
Training loss: 2.152256238650287
Validation loss: 2.0175402145179038
Epoch: 9| Step: 13
Training loss: 2.442303253183657
Validation loss: 1.9630697196222147
Epoch: 9| Step: 14
Training loss: 1.9453022048861615
Validation loss: 2.0029925246385973
Epoch: 9| Step: 15
Training loss: 2.7568421642464216
Validation loss: 1.994388500342437
Epoch: 9| Step: 16
Training loss: 2.4503897220726056
Validation loss: 1.9779511049736347
Epoch: 9| Step: 17
Training loss: 1.58396345282306
Validation loss: 2.0536099014798954
Epoch: 9| Step: 18
Training loss: 2.136390674796266
Validation loss: 1.981358820605091
Epoch: 9| Step: 19
Training loss: 2.4819846499796037
Validation loss: 1.9891112551272132
