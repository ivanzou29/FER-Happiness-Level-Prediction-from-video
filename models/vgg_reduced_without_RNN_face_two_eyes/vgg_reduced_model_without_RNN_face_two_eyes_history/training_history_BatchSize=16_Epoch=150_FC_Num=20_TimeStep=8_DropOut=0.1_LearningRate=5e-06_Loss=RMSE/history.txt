Epoch: 1| Step: 0
Training loss: 3.2664481407824155
Validation loss: 2.7945835949342293

Epoch: 6| Step: 1
Training loss: 2.3018680201395374
Validation loss: 2.7785153607116686

Epoch: 6| Step: 2
Training loss: 2.895951101712234
Validation loss: 2.7634900432030225

Epoch: 6| Step: 3
Training loss: 3.4195978260596944
Validation loss: 2.751666070078141

Epoch: 6| Step: 4
Training loss: 3.274751167453832
Validation loss: 2.7385376262864733

Epoch: 6| Step: 5
Training loss: 3.078123760707238
Validation loss: 2.725354879060197

Epoch: 6| Step: 6
Training loss: 3.1122495313005616
Validation loss: 2.7146552516713496

Epoch: 6| Step: 7
Training loss: 2.8727054561646965
Validation loss: 2.703388473224348

Epoch: 6| Step: 8
Training loss: 2.7313334960745026
Validation loss: 2.6905116424724547

Epoch: 6| Step: 9
Training loss: 2.5545160545192567
Validation loss: 2.6822030259581213

Epoch: 6| Step: 10
Training loss: 2.180550790553411
Validation loss: 2.672520743522395

Epoch: 6| Step: 11
Training loss: 2.664895741210796
Validation loss: 2.661287818617278

Epoch: 6| Step: 12
Training loss: 2.6654031462209926
Validation loss: 2.6506640921704294

Epoch: 6| Step: 13
Training loss: 2.66255480929272
Validation loss: 2.642989279599338

Epoch: 2| Step: 0
Training loss: 2.719842011828154
Validation loss: 2.63470102979893

Epoch: 6| Step: 1
Training loss: 3.030989173600493
Validation loss: 2.624246443715629

Epoch: 6| Step: 2
Training loss: 2.5829830752596186
Validation loss: 2.6144715598076895

Epoch: 6| Step: 3
Training loss: 2.7089518109862354
Validation loss: 2.606191966556489

Epoch: 6| Step: 4
Training loss: 2.705678538539335
Validation loss: 2.596065514122345

Epoch: 6| Step: 5
Training loss: 2.9608440938020926
Validation loss: 2.5831618149536233

Epoch: 6| Step: 6
Training loss: 2.803706175435698
Validation loss: 2.575076587858978

Epoch: 6| Step: 7
Training loss: 2.024381910584948
Validation loss: 2.5690187794696997

Epoch: 6| Step: 8
Training loss: 2.7460265497311953
Validation loss: 2.559293555150391

Epoch: 6| Step: 9
Training loss: 2.564887818379982
Validation loss: 2.5529479813267466

Epoch: 6| Step: 10
Training loss: 2.575511925929101
Validation loss: 2.5447193688766663

Epoch: 6| Step: 11
Training loss: 2.742730676482965
Validation loss: 2.5401351306293334

Epoch: 6| Step: 12
Training loss: 2.5404839395587135
Validation loss: 2.531140548788662

Epoch: 6| Step: 13
Training loss: 2.7206474785957306
Validation loss: 2.5290190201659146

Epoch: 3| Step: 0
Training loss: 2.7742062644924617
Validation loss: 2.5183538322531716

Epoch: 6| Step: 1
Training loss: 2.1672300437706356
Validation loss: 2.5109409929657533

Epoch: 6| Step: 2
Training loss: 3.021304617764113
Validation loss: 2.5066148665162187

Epoch: 6| Step: 3
Training loss: 2.89529256551337
Validation loss: 2.5016214040142883

Epoch: 6| Step: 4
Training loss: 2.180635417061631
Validation loss: 2.498465416716314

Epoch: 6| Step: 5
Training loss: 2.768688337272318
Validation loss: 2.4969772025124177

Epoch: 6| Step: 6
Training loss: 1.9663321770958164
Validation loss: 2.4947398398689704

Epoch: 6| Step: 7
Training loss: 2.6104415267243626
Validation loss: 2.4905093610937743

Epoch: 6| Step: 8
Training loss: 2.1273151576501923
Validation loss: 2.488849401361801

Epoch: 6| Step: 9
Training loss: 2.317554723099709
Validation loss: 2.49050028260158

Epoch: 6| Step: 10
Training loss: 2.4219817107287356
Validation loss: 2.4956589520586827

Epoch: 6| Step: 11
Training loss: 3.150286186175721
Validation loss: 2.491832695939889

Epoch: 6| Step: 12
Training loss: 2.7151944818970013
Validation loss: 2.494403439911409

Epoch: 6| Step: 13
Training loss: 2.8895611429130224
Validation loss: 2.491517378460976

Epoch: 4| Step: 0
Training loss: 2.5454020541216007
Validation loss: 2.493203899594721

Epoch: 6| Step: 1
Training loss: 2.8546854554718664
Validation loss: 2.4981187099759037

Epoch: 6| Step: 2
Training loss: 2.274214464325767
Validation loss: 2.500894974412111

Epoch: 6| Step: 3
Training loss: 2.6482974215121846
Validation loss: 2.499055040106754

Epoch: 6| Step: 4
Training loss: 2.1230745006683547
Validation loss: 2.4984310313083995

Epoch: 6| Step: 5
Training loss: 2.7308510006598996
Validation loss: 2.4976598436323574

Epoch: 6| Step: 6
Training loss: 2.4968560477099677
Validation loss: 2.5039244208269187

Epoch: 6| Step: 7
Training loss: 2.0364775075440704
Validation loss: 2.4975919092963705

Epoch: 6| Step: 8
Training loss: 3.116157380650709
Validation loss: 2.506238687161529

Epoch: 6| Step: 9
Training loss: 2.3666858708135305
Validation loss: 2.4978131584333014

Epoch: 6| Step: 10
Training loss: 2.495476635985012
Validation loss: 2.4955043504789525

Epoch: 6| Step: 11
Training loss: 2.5193086747618816
Validation loss: 2.494869769844202

Epoch: 6| Step: 12
Training loss: 2.7926510930316533
Validation loss: 2.4991402737236252

Epoch: 6| Step: 13
Training loss: 2.639659547094407
Validation loss: 2.4926861749395615

Epoch: 5| Step: 0
Training loss: 2.1622242746259555
Validation loss: 2.49641232554445

Epoch: 6| Step: 1
Training loss: 2.102718673383811
Validation loss: 2.490952467759566

Epoch: 6| Step: 2
Training loss: 2.669160769294594
Validation loss: 2.4993597482360763

Epoch: 6| Step: 3
Training loss: 2.691662426011216
Validation loss: 2.4953158524088037

Epoch: 6| Step: 4
Training loss: 2.3161413031578726
Validation loss: 2.493086267162311

Epoch: 6| Step: 5
Training loss: 2.679553592995138
Validation loss: 2.498490799905316

Epoch: 6| Step: 6
Training loss: 2.392532285912928
Validation loss: 2.497085716449685

Epoch: 6| Step: 7
Training loss: 2.5993441267993678
Validation loss: 2.4967600331676385

Epoch: 6| Step: 8
Training loss: 3.022755154046301
Validation loss: 2.499612730548298

Epoch: 6| Step: 9
Training loss: 2.008961389667143
Validation loss: 2.48839331294201

Epoch: 6| Step: 10
Training loss: 2.3379160179346226
Validation loss: 2.4906061431030526

Epoch: 6| Step: 11
Training loss: 2.5678116246946527
Validation loss: 2.493054405597031

Epoch: 6| Step: 12
Training loss: 3.0362011302723007
Validation loss: 2.489884782574122

Epoch: 6| Step: 13
Training loss: 2.902243529035952
Validation loss: 2.4849144851687104

Epoch: 6| Step: 0
Training loss: 2.6029369858783777
Validation loss: 2.4826398824291123

Epoch: 6| Step: 1
Training loss: 2.5874162116743613
Validation loss: 2.485014939010612

Epoch: 6| Step: 2
Training loss: 2.6463811312310703
Validation loss: 2.4856440184072404

Epoch: 6| Step: 3
Training loss: 2.877177864821762
Validation loss: 2.485713470229958

Epoch: 6| Step: 4
Training loss: 1.974262029658758
Validation loss: 2.4846550165873404

Epoch: 6| Step: 5
Training loss: 1.9838474804027875
Validation loss: 2.4787867172120066

Epoch: 6| Step: 6
Training loss: 2.2460433290876014
Validation loss: 2.480128579831405

Epoch: 6| Step: 7
Training loss: 2.868720619200802
Validation loss: 2.479057619490845

Epoch: 6| Step: 8
Training loss: 2.881941997317663
Validation loss: 2.4811924957350913

Epoch: 6| Step: 9
Training loss: 2.322445694829511
Validation loss: 2.4759076653664716

Epoch: 6| Step: 10
Training loss: 2.4896612966505693
Validation loss: 2.480654924269396

Epoch: 6| Step: 11
Training loss: 3.0086538748130756
Validation loss: 2.479689155679017

Epoch: 6| Step: 12
Training loss: 2.0323567823037796
Validation loss: 2.4782970303012477

Epoch: 6| Step: 13
Training loss: 2.8187204871144567
Validation loss: 2.477623865512892

Epoch: 7| Step: 0
Training loss: 2.518764456051975
Validation loss: 2.4801356775332652

Epoch: 6| Step: 1
Training loss: 2.4599446549431354
Validation loss: 2.4747921445372807

Epoch: 6| Step: 2
Training loss: 2.6543666670425714
Validation loss: 2.475323420242335

Epoch: 6| Step: 3
Training loss: 2.464490088286758
Validation loss: 2.4770548398299015

Epoch: 6| Step: 4
Training loss: 2.342226576017901
Validation loss: 2.4764630992688756

Epoch: 6| Step: 5
Training loss: 2.23780676587567
Validation loss: 2.475545584144729

Epoch: 6| Step: 6
Training loss: 3.3487818994316334
Validation loss: 2.4715220344431232

Epoch: 6| Step: 7
Training loss: 2.0962874565804315
Validation loss: 2.4732622365252634

Epoch: 6| Step: 8
Training loss: 2.6954931226277132
Validation loss: 2.4680901945430307

Epoch: 6| Step: 9
Training loss: 2.6595117625696982
Validation loss: 2.4749830245389526

Epoch: 6| Step: 10
Training loss: 2.1666887233296137
Validation loss: 2.467712522357967

Epoch: 6| Step: 11
Training loss: 2.5379240799739597
Validation loss: 2.468040734626245

Epoch: 6| Step: 12
Training loss: 2.891827307498081
Validation loss: 2.4691025606945067

Epoch: 6| Step: 13
Training loss: 2.1733055617697516
Validation loss: 2.473009450875649

Epoch: 8| Step: 0
Training loss: 2.4991963048358126
Validation loss: 2.471074470688431

Epoch: 6| Step: 1
Training loss: 1.972487278112813
Validation loss: 2.469330441771202

Epoch: 6| Step: 2
Training loss: 2.0511254593946715
Validation loss: 2.470056614580893

Epoch: 6| Step: 3
Training loss: 2.2350669803012853
Validation loss: 2.467631799024449

Epoch: 6| Step: 4
Training loss: 2.8569215348216916
Validation loss: 2.4723545430760745

Epoch: 6| Step: 5
Training loss: 3.018196867187686
Validation loss: 2.468007487087341

Epoch: 6| Step: 6
Training loss: 2.454216975250739
Validation loss: 2.466655422090555

Epoch: 6| Step: 7
Training loss: 2.4094100613151954
Validation loss: 2.4715781289583725

Epoch: 6| Step: 8
Training loss: 2.6003120785265756
Validation loss: 2.469203762411356

Epoch: 6| Step: 9
Training loss: 2.7922048951361216
Validation loss: 2.4648987068220025

Epoch: 6| Step: 10
Training loss: 1.9761154211983543
Validation loss: 2.462142116662404

Epoch: 6| Step: 11
Training loss: 2.971657704332508
Validation loss: 2.463681059127132

Epoch: 6| Step: 12
Training loss: 2.488053962711079
Validation loss: 2.468135193834065

Epoch: 6| Step: 13
Training loss: 2.781047084992725
Validation loss: 2.469229027995606

Epoch: 9| Step: 0
Training loss: 2.2913708813835107
Validation loss: 2.460808297454183

Epoch: 6| Step: 1
Training loss: 2.647369619586574
Validation loss: 2.4658195792722712

Epoch: 6| Step: 2
Training loss: 2.9201521256416845
Validation loss: 2.4683134682925125

Epoch: 6| Step: 3
Training loss: 2.587621503547955
Validation loss: 2.4656040089224986

Epoch: 6| Step: 4
Training loss: 2.553661081910567
Validation loss: 2.4624925171146206

Epoch: 6| Step: 5
Training loss: 2.322490248151494
Validation loss: 2.469492337930897

Epoch: 6| Step: 6
Training loss: 2.5946094973239258
Validation loss: 2.4684511800585645

Epoch: 6| Step: 7
Training loss: 2.37992038000586
Validation loss: 2.469203078466787

Epoch: 6| Step: 8
Training loss: 2.5685549585404486
Validation loss: 2.471023583016477

Epoch: 6| Step: 9
Training loss: 2.7349625310475703
Validation loss: 2.4675657916871696

Epoch: 6| Step: 10
Training loss: 2.2223465474107162
Validation loss: 2.4709632143575653

Epoch: 6| Step: 11
Training loss: 2.3526014903246644
Validation loss: 2.469219573547693

Epoch: 6| Step: 12
Training loss: 2.5422717661335184
Validation loss: 2.4682549732793997

Epoch: 6| Step: 13
Training loss: 2.5174656170312577
Validation loss: 2.4674870282430934

Epoch: 10| Step: 0
Training loss: 2.33165805712354
Validation loss: 2.459379043801977

Epoch: 6| Step: 1
Training loss: 3.4007142606973253
Validation loss: 2.4668441610870793

Epoch: 6| Step: 2
Training loss: 2.132324610090558
Validation loss: 2.459362127261502

Epoch: 6| Step: 3
Training loss: 2.586953876746278
Validation loss: 2.4642318231996456

Epoch: 6| Step: 4
Training loss: 2.3499638899605784
Validation loss: 2.4604365570616693

Epoch: 6| Step: 5
Training loss: 2.338368149559593
Validation loss: 2.467241107792326

Epoch: 6| Step: 6
Training loss: 2.2092723169705057
Validation loss: 2.4679200753192676

Epoch: 6| Step: 7
Training loss: 2.7490520577440005
Validation loss: 2.462984152381126

Epoch: 6| Step: 8
Training loss: 2.2508572958506674
Validation loss: 2.4624177386490795

Epoch: 6| Step: 9
Training loss: 2.35092225341234
Validation loss: 2.461001973594299

Epoch: 6| Step: 10
Training loss: 2.5981259487830353
Validation loss: 2.462522740912603

Epoch: 6| Step: 11
Training loss: 2.673180779728453
Validation loss: 2.4593172421231

Epoch: 6| Step: 12
Training loss: 2.398178235681755
Validation loss: 2.4541113585461156

Epoch: 6| Step: 13
Training loss: 2.551830689257848
Validation loss: 2.460444938977433

Epoch: 11| Step: 0
Training loss: 2.867765862030705
Validation loss: 2.461373846536222

Epoch: 6| Step: 1
Training loss: 2.7914196493455514
Validation loss: 2.456676884150727

Epoch: 6| Step: 2
Training loss: 2.117968650938881
Validation loss: 2.454996759628778

Epoch: 6| Step: 3
Training loss: 1.875530485767321
Validation loss: 2.4580618228871494

Epoch: 6| Step: 4
Training loss: 2.2444892791743545
Validation loss: 2.4544441094385556

Epoch: 6| Step: 5
Training loss: 2.374356835263931
Validation loss: 2.4520655650551397

Epoch: 6| Step: 6
Training loss: 2.3084444104219406
Validation loss: 2.4510677644826586

Epoch: 6| Step: 7
Training loss: 3.1163589026391993
Validation loss: 2.454775763045234

Epoch: 6| Step: 8
Training loss: 2.279196559656505
Validation loss: 2.45068380453754

Epoch: 6| Step: 9
Training loss: 3.0255450805876234
Validation loss: 2.447965748612759

Epoch: 6| Step: 10
Training loss: 1.852742909350073
Validation loss: 2.4457217474269424

Epoch: 6| Step: 11
Training loss: 2.824204061003035
Validation loss: 2.4523795710298315

Epoch: 6| Step: 12
Training loss: 2.474848879429446
Validation loss: 2.4477693283434308

Epoch: 6| Step: 13
Training loss: 2.553299086202456
Validation loss: 2.4454768311489685

Epoch: 12| Step: 0
Training loss: 2.588740187054892
Validation loss: 2.447974854988408

Epoch: 6| Step: 1
Training loss: 2.7309208442449844
Validation loss: 2.4486197713144744

Epoch: 6| Step: 2
Training loss: 2.6916709293611234
Validation loss: 2.4486723254303113

Epoch: 6| Step: 3
Training loss: 2.0380148114385888
Validation loss: 2.448328711278338

Epoch: 6| Step: 4
Training loss: 2.7219440508382156
Validation loss: 2.4467772300678066

Epoch: 6| Step: 5
Training loss: 2.3635994184714413
Validation loss: 2.4477301398020845

Epoch: 6| Step: 6
Training loss: 1.8737431446278316
Validation loss: 2.4454335435640364

Epoch: 6| Step: 7
Training loss: 2.5903955852682983
Validation loss: 2.4452732233340213

Epoch: 6| Step: 8
Training loss: 2.370327821102429
Validation loss: 2.444628927706053

Epoch: 6| Step: 9
Training loss: 2.534575738259489
Validation loss: 2.4466903753283966

Epoch: 6| Step: 10
Training loss: 3.0018619481314675
Validation loss: 2.450501709774583

Epoch: 6| Step: 11
Training loss: 2.0000462526695184
Validation loss: 2.441904343720912

Epoch: 6| Step: 12
Training loss: 2.568926034357786
Validation loss: 2.4419700846317194

Epoch: 6| Step: 13
Training loss: 2.642674299859739
Validation loss: 2.4429949583464023

Epoch: 13| Step: 0
Training loss: 2.4291145655004955
Validation loss: 2.45321475308229

Epoch: 6| Step: 1
Training loss: 2.5636969771312206
Validation loss: 2.4427435790381535

Epoch: 6| Step: 2
Training loss: 2.5412460562792196
Validation loss: 2.445387866531512

Epoch: 6| Step: 3
Training loss: 2.6522452289783973
Validation loss: 2.4502396673934275

Epoch: 6| Step: 4
Training loss: 3.445478854845081
Validation loss: 2.4591144166818633

Epoch: 6| Step: 5
Training loss: 2.1316255613315214
Validation loss: 2.4521776139622475

Epoch: 6| Step: 6
Training loss: 2.2445132856649272
Validation loss: 2.4506876473533588

Epoch: 6| Step: 7
Training loss: 2.4646587030318052
Validation loss: 2.4488316929269365

Epoch: 6| Step: 8
Training loss: 2.7191796675790285
Validation loss: 2.451268054144144

Epoch: 6| Step: 9
Training loss: 2.3142880924152083
Validation loss: 2.4478347494067982

Epoch: 6| Step: 10
Training loss: 2.09373815732425
Validation loss: 2.451945918491273

Epoch: 6| Step: 11
Training loss: 2.3673994013552315
Validation loss: 2.445888431151592

Epoch: 6| Step: 12
Training loss: 2.6081424931758375
Validation loss: 2.4499407955723527

Epoch: 6| Step: 13
Training loss: 2.0277456719398517
Validation loss: 2.4390976389492653

Epoch: 14| Step: 0
Training loss: 2.410118263476984
Validation loss: 2.4507036995568114

Epoch: 6| Step: 1
Training loss: 2.8857451618004974
Validation loss: 2.4497672911175616

Epoch: 6| Step: 2
Training loss: 2.2968681491048977
Validation loss: 2.447351696208764

Epoch: 6| Step: 3
Training loss: 2.4600254851471037
Validation loss: 2.4469491602286992

Epoch: 6| Step: 4
Training loss: 2.1844950063154616
Validation loss: 2.4389622451213424

Epoch: 6| Step: 5
Training loss: 2.65237458201313
Validation loss: 2.4501734266726523

Epoch: 6| Step: 6
Training loss: 2.6609689420588523
Validation loss: 2.4568563863029276

Epoch: 6| Step: 7
Training loss: 2.2291172295433173
Validation loss: 2.4577803771128064

Epoch: 6| Step: 8
Training loss: 2.5247158910470247
Validation loss: 2.458141939072675

Epoch: 6| Step: 9
Training loss: 2.3065672369384913
Validation loss: 2.4624530626396783

Epoch: 6| Step: 10
Training loss: 2.7572963328815017
Validation loss: 2.468487834289255

Epoch: 6| Step: 11
Training loss: 2.6914521367074338
Validation loss: 2.4609354009064295

Epoch: 6| Step: 12
Training loss: 2.459926724621901
Validation loss: 2.454996015075433

Epoch: 6| Step: 13
Training loss: 2.256700921899781
Validation loss: 2.4478222335023867

Epoch: 15| Step: 0
Training loss: 2.947094608348059
Validation loss: 2.4395908615122113

Epoch: 6| Step: 1
Training loss: 2.4194383730874844
Validation loss: 2.4383276243484144

Epoch: 6| Step: 2
Training loss: 2.580492262194673
Validation loss: 2.439330041659875

Epoch: 6| Step: 3
Training loss: 2.0020961505692645
Validation loss: 2.4298002128992633

Epoch: 6| Step: 4
Training loss: 2.398404596457171
Validation loss: 2.4272924068485704

Epoch: 6| Step: 5
Training loss: 2.945841531773606
Validation loss: 2.433706347298202

Epoch: 6| Step: 6
Training loss: 2.56179772034543
Validation loss: 2.4274821438117904

Epoch: 6| Step: 7
Training loss: 2.5529277001560624
Validation loss: 2.431813984810301

Epoch: 6| Step: 8
Training loss: 1.8977182540720787
Validation loss: 2.4364007199050817

Epoch: 6| Step: 9
Training loss: 2.2446178065073883
Validation loss: 2.421994532434858

Epoch: 6| Step: 10
Training loss: 2.6369174006476075
Validation loss: 2.4311761741902953

Epoch: 6| Step: 11
Training loss: 2.1231607443445455
Validation loss: 2.433361452628229

Epoch: 6| Step: 12
Training loss: 2.563303844627873
Validation loss: 2.4312852224431594

Epoch: 6| Step: 13
Training loss: 2.6364084923076256
Validation loss: 2.4320876521305883

Epoch: 16| Step: 0
Training loss: 2.5601404072583027
Validation loss: 2.4251337994371833

Epoch: 6| Step: 1
Training loss: 2.884582803004222
Validation loss: 2.426818568532824

Epoch: 6| Step: 2
Training loss: 2.7920265155615254
Validation loss: 2.4276220408705544

Epoch: 6| Step: 3
Training loss: 1.7210279454739172
Validation loss: 2.4228782954721444

Epoch: 6| Step: 4
Training loss: 1.7863885478485013
Validation loss: 2.4372529287727276

Epoch: 6| Step: 5
Training loss: 2.5628723246207814
Validation loss: 2.4403729014298494

Epoch: 6| Step: 6
Training loss: 2.2983126131174467
Validation loss: 2.455341431208292

Epoch: 6| Step: 7
Training loss: 2.730824721548521
Validation loss: 2.4491525546776347

Epoch: 6| Step: 8
Training loss: 2.715208180070288
Validation loss: 2.4466450953074017

Epoch: 6| Step: 9
Training loss: 3.4765498814728866
Validation loss: 2.4491706125496506

Epoch: 6| Step: 10
Training loss: 2.436286037094375
Validation loss: 2.444027621019495

Epoch: 6| Step: 11
Training loss: 1.6087214059370771
Validation loss: 2.438468789488137

Epoch: 6| Step: 12
Training loss: 2.0745780331932817
Validation loss: 2.4333718220614937

Epoch: 6| Step: 13
Training loss: 2.4242180104182323
Validation loss: 2.432659249367683

Epoch: 17| Step: 0
Training loss: 2.2411627471330506
Validation loss: 2.4293463856960242

Epoch: 6| Step: 1
Training loss: 3.128778233570299
Validation loss: 2.4374416213910464

Epoch: 6| Step: 2
Training loss: 2.111291085764378
Validation loss: 2.428554749231202

Epoch: 6| Step: 3
Training loss: 1.980840584122875
Validation loss: 2.4442458746433964

Epoch: 6| Step: 4
Training loss: 2.2114043804336805
Validation loss: 2.4383206086555727

Epoch: 6| Step: 5
Training loss: 2.6966292109047427
Validation loss: 2.4405737187285

Epoch: 6| Step: 6
Training loss: 2.4105052231655097
Validation loss: 2.443984234601382

Epoch: 6| Step: 7
Training loss: 2.187552969155007
Validation loss: 2.446543504549702

Epoch: 6| Step: 8
Training loss: 2.542932091139617
Validation loss: 2.443288564735908

Epoch: 6| Step: 9
Training loss: 2.954556879941817
Validation loss: 2.4464498521623748

Epoch: 6| Step: 10
Training loss: 2.173661190454076
Validation loss: 2.4428047914852264

Epoch: 6| Step: 11
Training loss: 3.055677326742943
Validation loss: 2.439460601673015

Epoch: 6| Step: 12
Training loss: 2.4099820412564212
Validation loss: 2.4359884058160173

Epoch: 6| Step: 13
Training loss: 2.069301142271764
Validation loss: 2.4223787829736048

Epoch: 18| Step: 0
Training loss: 2.6592055090786344
Validation loss: 2.417396720144947

Epoch: 6| Step: 1
Training loss: 2.763707762576179
Validation loss: 2.413674793569876

Epoch: 6| Step: 2
Training loss: 1.7594648267130633
Validation loss: 2.411325098123674

Epoch: 6| Step: 3
Training loss: 2.091578367986122
Validation loss: 2.422451369089761

Epoch: 6| Step: 4
Training loss: 2.4709596040913477
Validation loss: 2.42120625276683

Epoch: 6| Step: 5
Training loss: 2.567601684666509
Validation loss: 2.417477690874195

Epoch: 6| Step: 6
Training loss: 2.8058552555700302
Validation loss: 2.4227834494899363

Epoch: 6| Step: 7
Training loss: 2.6144537013366875
Validation loss: 2.4215694275735307

Epoch: 6| Step: 8
Training loss: 2.8464674489384576
Validation loss: 2.4237121177206205

Epoch: 6| Step: 9
Training loss: 2.9575172337395115
Validation loss: 2.4134288725813398

Epoch: 6| Step: 10
Training loss: 2.0019368091941843
Validation loss: 2.413615229548444

Epoch: 6| Step: 11
Training loss: 2.0645420484780836
Validation loss: 2.408899854621976

Epoch: 6| Step: 12
Training loss: 1.8618019997844473
Validation loss: 2.418219927681741

Epoch: 6| Step: 13
Training loss: 2.5559720883942356
Validation loss: 2.4191425947865755

Epoch: 19| Step: 0
Training loss: 2.3639671654397705
Validation loss: 2.4159965298514043

Epoch: 6| Step: 1
Training loss: 2.621496587459679
Validation loss: 2.415521002106278

Epoch: 6| Step: 2
Training loss: 1.843894564893251
Validation loss: 2.4122376854421077

Epoch: 6| Step: 3
Training loss: 2.6243337966580658
Validation loss: 2.4347374822086736

Epoch: 6| Step: 4
Training loss: 2.4232225176395
Validation loss: 2.420478237544665

Epoch: 6| Step: 5
Training loss: 1.9808550275492742
Validation loss: 2.417154169787824

Epoch: 6| Step: 6
Training loss: 2.976220298980975
Validation loss: 2.4248524401363354

Epoch: 6| Step: 7
Training loss: 2.0225434555836177
Validation loss: 2.424291008607838

Epoch: 6| Step: 8
Training loss: 2.388067236019283
Validation loss: 2.4306436928406057

Epoch: 6| Step: 9
Training loss: 2.1686093595344125
Validation loss: 2.4293147677187767

Epoch: 6| Step: 10
Training loss: 2.2822165335947813
Validation loss: 2.424598442336925

Epoch: 6| Step: 11
Training loss: 2.8190577878194825
Validation loss: 2.434628531459553

Epoch: 6| Step: 12
Training loss: 2.0141106172885133
Validation loss: 2.4297624271856226

Epoch: 6| Step: 13
Training loss: 3.280023690812687
Validation loss: 2.440106351533208

Epoch: 20| Step: 0
Training loss: 2.15510196807433
Validation loss: 2.4317779379685254

Epoch: 6| Step: 1
Training loss: 2.2171052020917577
Validation loss: 2.4280513639343217

Epoch: 6| Step: 2
Training loss: 2.625084830230399
Validation loss: 2.4379936109714175

Epoch: 6| Step: 3
Training loss: 2.526239781951247
Validation loss: 2.4334664349754194

Epoch: 6| Step: 4
Training loss: 2.0345397132490675
Validation loss: 2.424164213107395

Epoch: 6| Step: 5
Training loss: 2.7704150426726666
Validation loss: 2.429846199307023

Epoch: 6| Step: 6
Training loss: 2.4780942590257156
Validation loss: 2.4245323615106336

Epoch: 6| Step: 7
Training loss: 2.5566818432148173
Validation loss: 2.4263683351945287

Epoch: 6| Step: 8
Training loss: 2.5497614879886084
Validation loss: 2.418097965565578

Epoch: 6| Step: 9
Training loss: 2.332737596846192
Validation loss: 2.4183761754656734

Epoch: 6| Step: 10
Training loss: 2.747747539167575
Validation loss: 2.4144934935117073

Epoch: 6| Step: 11
Training loss: 2.049730129621596
Validation loss: 2.4115133972692218

Epoch: 6| Step: 12
Training loss: 2.7136608153755217
Validation loss: 2.415468014595809

Epoch: 6| Step: 13
Training loss: 2.0406347768178406
Validation loss: 2.4085967687603773

Epoch: 21| Step: 0
Training loss: 1.9964662566358335
Validation loss: 2.4055751002689685

Epoch: 6| Step: 1
Training loss: 2.049832020832232
Validation loss: 2.4130732413636817

Epoch: 6| Step: 2
Training loss: 2.393772222749428
Validation loss: 2.4027049054198235

Epoch: 6| Step: 3
Training loss: 2.6374591155295826
Validation loss: 2.411087499218229

Epoch: 6| Step: 4
Training loss: 2.9695438327537778
Validation loss: 2.419046608533012

Epoch: 6| Step: 5
Training loss: 2.453693008266254
Validation loss: 2.4178869904318425

Epoch: 6| Step: 6
Training loss: 2.371153276126771
Validation loss: 2.4294256251145363

Epoch: 6| Step: 7
Training loss: 2.668845974985406
Validation loss: 2.43029900120227

Epoch: 6| Step: 8
Training loss: 2.2876093812232874
Validation loss: 2.4419861127785008

Epoch: 6| Step: 9
Training loss: 2.845480256265003
Validation loss: 2.445353644759181

Epoch: 6| Step: 10
Training loss: 2.2666255451660984
Validation loss: 2.425483361800441

Epoch: 6| Step: 11
Training loss: 2.071571514290144
Validation loss: 2.444985576059224

Epoch: 6| Step: 12
Training loss: 2.1286303980185024
Validation loss: 2.4265628851542074

Epoch: 6| Step: 13
Training loss: 2.761901072482446
Validation loss: 2.4184984685863933

Epoch: 22| Step: 0
Training loss: 2.4332708202675724
Validation loss: 2.4164763463375034

Epoch: 6| Step: 1
Training loss: 2.412865202937957
Validation loss: 2.4130722368675546

Epoch: 6| Step: 2
Training loss: 2.346696349555912
Validation loss: 2.4160507392850015

Epoch: 6| Step: 3
Training loss: 1.8833192008959552
Validation loss: 2.3969676166066223

Epoch: 6| Step: 4
Training loss: 2.1587504387674508
Validation loss: 2.40778688173324

Epoch: 6| Step: 5
Training loss: 2.2754042465391633
Validation loss: 2.4159018989097514

Epoch: 6| Step: 6
Training loss: 2.3881548917048243
Validation loss: 2.4088337555441552

Epoch: 6| Step: 7
Training loss: 2.235812918273257
Validation loss: 2.401448285032816

Epoch: 6| Step: 8
Training loss: 2.630164379596129
Validation loss: 2.4052971195857378

Epoch: 6| Step: 9
Training loss: 2.257961703851682
Validation loss: 2.4062673229568294

Epoch: 6| Step: 10
Training loss: 2.620197080232289
Validation loss: 2.3988039148953186

Epoch: 6| Step: 11
Training loss: 2.2490134725544544
Validation loss: 2.407149109745354

Epoch: 6| Step: 12
Training loss: 2.6937162675980306
Validation loss: 2.4012445183472466

Epoch: 6| Step: 13
Training loss: 3.091482699559751
Validation loss: 2.406220349215842

Epoch: 23| Step: 0
Training loss: 2.4978225762402517
Validation loss: 2.4066759203189605

Epoch: 6| Step: 1
Training loss: 2.2869983519100763
Validation loss: 2.4041786030473586

Epoch: 6| Step: 2
Training loss: 1.6400830054793143
Validation loss: 2.4043776092898557

Epoch: 6| Step: 3
Training loss: 2.643962939910166
Validation loss: 2.4113800717226446

Epoch: 6| Step: 4
Training loss: 2.500192539430196
Validation loss: 2.411023676830492

Epoch: 6| Step: 5
Training loss: 2.268949923363278
Validation loss: 2.3998892467163397

Epoch: 6| Step: 6
Training loss: 2.6787206390238554
Validation loss: 2.4223708106709982

Epoch: 6| Step: 7
Training loss: 2.717294325217572
Validation loss: 2.4088780596123787

Epoch: 6| Step: 8
Training loss: 2.369415342751727
Validation loss: 2.4066196504510753

Epoch: 6| Step: 9
Training loss: 2.558780016925705
Validation loss: 2.4103551913384194

Epoch: 6| Step: 10
Training loss: 1.9997240114522703
Validation loss: 2.4010542140365287

Epoch: 6| Step: 11
Training loss: 2.341819069497098
Validation loss: 2.4040226556585265

Epoch: 6| Step: 12
Training loss: 2.6269164582710567
Validation loss: 2.4042711088698985

Epoch: 6| Step: 13
Training loss: 2.275487440939209
Validation loss: 2.3995495101877444

Epoch: 24| Step: 0
Training loss: 1.9589116547951095
Validation loss: 2.413550782519168

Epoch: 6| Step: 1
Training loss: 2.0776414810646067
Validation loss: 2.4190044906619734

Epoch: 6| Step: 2
Training loss: 2.333525468091037
Validation loss: 2.4260461143582823

Epoch: 6| Step: 3
Training loss: 2.630006647718027
Validation loss: 2.4431545741959537

Epoch: 6| Step: 4
Training loss: 2.439478535821416
Validation loss: 2.428269081635883

Epoch: 6| Step: 5
Training loss: 2.7511204257732764
Validation loss: 2.430025475843346

Epoch: 6| Step: 6
Training loss: 1.7905550398815828
Validation loss: 2.4287784179998724

Epoch: 6| Step: 7
Training loss: 1.9459475051527106
Validation loss: 2.435515174363705

Epoch: 6| Step: 8
Training loss: 2.6136564661089743
Validation loss: 2.4344262851835032

Epoch: 6| Step: 9
Training loss: 2.242369109451533
Validation loss: 2.4352046478328013

Epoch: 6| Step: 10
Training loss: 2.5196285258595554
Validation loss: 2.4447925246347864

Epoch: 6| Step: 11
Training loss: 2.4577433853471713
Validation loss: 2.4486092392593397

Epoch: 6| Step: 12
Training loss: 2.265183609684543
Validation loss: 2.4305933646637046

Epoch: 6| Step: 13
Training loss: 3.2860685299711863
Validation loss: 2.428614045017648

Epoch: 25| Step: 0
Training loss: 2.536275231699793
Validation loss: 2.4150153525412734

Epoch: 6| Step: 1
Training loss: 2.4319191646756777
Validation loss: 2.4151325343998904

Epoch: 6| Step: 2
Training loss: 2.285126827735268
Validation loss: 2.3969539398894546

Epoch: 6| Step: 3
Training loss: 2.2309531305537416
Validation loss: 2.401082488821109

Epoch: 6| Step: 4
Training loss: 2.7558179348020455
Validation loss: 2.4112606970017647

Epoch: 6| Step: 5
Training loss: 1.9209561516256706
Validation loss: 2.3906457937495644

Epoch: 6| Step: 6
Training loss: 2.7100563926037644
Validation loss: 2.407294323362774

Epoch: 6| Step: 7
Training loss: 2.658369228714619
Validation loss: 2.400894745298704

Epoch: 6| Step: 8
Training loss: 2.4739252242164977
Validation loss: 2.4085610756115297

Epoch: 6| Step: 9
Training loss: 2.2316079245317733
Validation loss: 2.4059610234583935

Epoch: 6| Step: 10
Training loss: 2.3688694986683396
Validation loss: 2.4012000361997803

Epoch: 6| Step: 11
Training loss: 2.4069938996019387
Validation loss: 2.4016909738467

Epoch: 6| Step: 12
Training loss: 2.314434788627259
Validation loss: 2.4013410755303073

Epoch: 6| Step: 13
Training loss: 2.218470918538295
Validation loss: 2.401638218933808

Epoch: 26| Step: 0
Training loss: 1.9519442231542314
Validation loss: 2.3972514281759776

Epoch: 6| Step: 1
Training loss: 1.8430601219434337
Validation loss: 2.400200294375433

Epoch: 6| Step: 2
Training loss: 2.4943016914332885
Validation loss: 2.4024499554405288

Epoch: 6| Step: 3
Training loss: 2.857734584841192
Validation loss: 2.4217341310284333

Epoch: 6| Step: 4
Training loss: 2.8748202060374166
Validation loss: 2.425107705782066

Epoch: 6| Step: 5
Training loss: 1.891349212404129
Validation loss: 2.4322719423418713

Epoch: 6| Step: 6
Training loss: 2.426595210378723
Validation loss: 2.4393489867340015

Epoch: 6| Step: 7
Training loss: 2.1460169247602456
Validation loss: 2.4411491645240613

Epoch: 6| Step: 8
Training loss: 3.369077501673162
Validation loss: 2.4466490743959155

Epoch: 6| Step: 9
Training loss: 2.0673747398135967
Validation loss: 2.447821486766767

Epoch: 6| Step: 10
Training loss: 1.520416472624814
Validation loss: 2.448621272412635

Epoch: 6| Step: 11
Training loss: 2.1868757174551487
Validation loss: 2.4480684409199265

Epoch: 6| Step: 12
Training loss: 2.8069465911100338
Validation loss: 2.4288136667966502

Epoch: 6| Step: 13
Training loss: 2.106517749826588
Validation loss: 2.4447318170668844

Epoch: 27| Step: 0
Training loss: 2.8997179683478653
Validation loss: 2.40834774708202

Epoch: 6| Step: 1
Training loss: 2.446786746873146
Validation loss: 2.4054790021267594

Epoch: 6| Step: 2
Training loss: 2.338053787643906
Validation loss: 2.3953707759874145

Epoch: 6| Step: 3
Training loss: 2.7153948546977373
Validation loss: 2.3965675611082315

Epoch: 6| Step: 4
Training loss: 2.397824286684588
Validation loss: 2.4139492662656292

Epoch: 6| Step: 5
Training loss: 2.297769800394075
Validation loss: 2.4054857336644253

Epoch: 6| Step: 6
Training loss: 2.336872742889775
Validation loss: 2.4087776020700913

Epoch: 6| Step: 7
Training loss: 2.395897529958253
Validation loss: 2.395316596213279

Epoch: 6| Step: 8
Training loss: 1.566488439824722
Validation loss: 2.404220187309339

Epoch: 6| Step: 9
Training loss: 2.270293693700874
Validation loss: 2.3977978378358697

Epoch: 6| Step: 10
Training loss: 1.9526729213127767
Validation loss: 2.398126637943157

Epoch: 6| Step: 11
Training loss: 2.182461631061845
Validation loss: 2.401956633518047

Epoch: 6| Step: 12
Training loss: 2.625727234874729
Validation loss: 2.4032495460595804

Epoch: 6| Step: 13
Training loss: 2.4895197542337297
Validation loss: 2.3983569633887374

Epoch: 28| Step: 0
Training loss: 1.867603718483124
Validation loss: 2.4050341915785194

Epoch: 6| Step: 1
Training loss: 2.1848250246149217
Validation loss: 2.41023545261289

Epoch: 6| Step: 2
Training loss: 2.3583452617581733
Validation loss: 2.40347217223155

Epoch: 6| Step: 3
Training loss: 2.3488529855543967
Validation loss: 2.4034208038785794

Epoch: 6| Step: 4
Training loss: 2.4557152940203886
Validation loss: 2.422334803751089

Epoch: 6| Step: 5
Training loss: 2.695060474941616
Validation loss: 2.4187877379372247

Epoch: 6| Step: 6
Training loss: 2.7358965318925046
Validation loss: 2.4187696832320897

Epoch: 6| Step: 7
Training loss: 2.4738505343324686
Validation loss: 2.407276264990399

Epoch: 6| Step: 8
Training loss: 2.723271260793401
Validation loss: 2.4095417477918084

Epoch: 6| Step: 9
Training loss: 2.0048486824679577
Validation loss: 2.4122725582137448

Epoch: 6| Step: 10
Training loss: 2.3069006686874123
Validation loss: 2.3988270893600956

Epoch: 6| Step: 11
Training loss: 1.8561570988793525
Validation loss: 2.3984109088032497

Epoch: 6| Step: 12
Training loss: 2.4085067470995334
Validation loss: 2.386381018218884

Epoch: 6| Step: 13
Training loss: 2.4601136781431885
Validation loss: 2.4092431546497597

Epoch: 29| Step: 0
Training loss: 2.100243704142634
Validation loss: 2.3880633589945783

Epoch: 6| Step: 1
Training loss: 2.5174927974472885
Validation loss: 2.4034188364174174

Epoch: 6| Step: 2
Training loss: 2.5814859388649345
Validation loss: 2.39758380023459

Epoch: 6| Step: 3
Training loss: 2.4682817618653328
Validation loss: 2.3875529594605904

Epoch: 6| Step: 4
Training loss: 1.9331205771661106
Validation loss: 2.4055035576940424

Epoch: 6| Step: 5
Training loss: 2.380798489274807
Validation loss: 2.398114301710513

Epoch: 6| Step: 6
Training loss: 1.7753628265923962
Validation loss: 2.3911873316059884

Epoch: 6| Step: 7
Training loss: 2.4094479600519465
Validation loss: 2.4117937754140666

Epoch: 6| Step: 8
Training loss: 1.8648019019658468
Validation loss: 2.418634128998695

Epoch: 6| Step: 9
Training loss: 2.687952491459623
Validation loss: 2.4176982179819366

Epoch: 6| Step: 10
Training loss: 2.196623712659014
Validation loss: 2.443569321713449

Epoch: 6| Step: 11
Training loss: 2.8999217055702555
Validation loss: 2.4514465340262577

Epoch: 6| Step: 12
Training loss: 2.5789836031809266
Validation loss: 2.4341772287233874

Epoch: 6| Step: 13
Training loss: 2.152634284320035
Validation loss: 2.422769205051052

Epoch: 30| Step: 0
Training loss: 2.209615359255577
Validation loss: 2.4038173053673226

Epoch: 6| Step: 1
Training loss: 1.946514570203722
Validation loss: 2.4218443673770493

Epoch: 6| Step: 2
Training loss: 2.5410934072753584
Validation loss: 2.420541293529494

Epoch: 6| Step: 3
Training loss: 1.6009055674412085
Validation loss: 2.4086633445145984

Epoch: 6| Step: 4
Training loss: 2.401668000742612
Validation loss: 2.401992623324982

Epoch: 6| Step: 5
Training loss: 2.4297723785980643
Validation loss: 2.406319555292908

Epoch: 6| Step: 6
Training loss: 2.55997621882837
Validation loss: 2.41220258977962

Epoch: 6| Step: 7
Training loss: 2.0224809779155586
Validation loss: 2.4058865194208248

Epoch: 6| Step: 8
Training loss: 2.1231262697536657
Validation loss: 2.3994163313407144

Epoch: 6| Step: 9
Training loss: 2.5495284598199017
Validation loss: 2.4028359423257175

Epoch: 6| Step: 10
Training loss: 2.0669647212088367
Validation loss: 2.399487392995743

Epoch: 6| Step: 11
Training loss: 3.0468668619682986
Validation loss: 2.3936768294025135

Epoch: 6| Step: 12
Training loss: 2.332417569518248
Validation loss: 2.3946398761747374

Epoch: 6| Step: 13
Training loss: 2.2768709140084376
Validation loss: 2.3976133506585637

Epoch: 31| Step: 0
Training loss: 2.6413327684987578
Validation loss: 2.394763663516617

Epoch: 6| Step: 1
Training loss: 2.568774566161662
Validation loss: 2.3875805786275985

Epoch: 6| Step: 2
Training loss: 2.0157494321753955
Validation loss: 2.379992725003234

Epoch: 6| Step: 3
Training loss: 2.460524073190953
Validation loss: 2.386583939411427

Epoch: 6| Step: 4
Training loss: 2.159039669250196
Validation loss: 2.4049713733949436

Epoch: 6| Step: 5
Training loss: 2.448102340690766
Validation loss: 2.4015833863487868

Epoch: 6| Step: 6
Training loss: 2.281536032106879
Validation loss: 2.3960627459831674

Epoch: 6| Step: 7
Training loss: 1.7789233890825242
Validation loss: 2.400017250184478

Epoch: 6| Step: 8
Training loss: 2.006400595268514
Validation loss: 2.3867215303778386

Epoch: 6| Step: 9
Training loss: 2.4919738677967675
Validation loss: 2.3882396241398616

Epoch: 6| Step: 10
Training loss: 2.5676348342332043
Validation loss: 2.412222085602601

Epoch: 6| Step: 11
Training loss: 2.892544001159709
Validation loss: 2.3996891562175504

Epoch: 6| Step: 12
Training loss: 1.6000593621447565
Validation loss: 2.4057521883109465

Epoch: 6| Step: 13
Training loss: 2.237391003559194
Validation loss: 2.418429074612647

Epoch: 32| Step: 0
Training loss: 2.0110321947401166
Validation loss: 2.425409056059533

Epoch: 6| Step: 1
Training loss: 1.9366884069924126
Validation loss: 2.4342875708573577

Epoch: 6| Step: 2
Training loss: 2.692543442852945
Validation loss: 2.416766622273937

Epoch: 6| Step: 3
Training loss: 2.542127713354433
Validation loss: 2.437266469022462

Epoch: 6| Step: 4
Training loss: 2.3328972363524416
Validation loss: 2.4410149588777044

Epoch: 6| Step: 5
Training loss: 2.0844167816687116
Validation loss: 2.415535766348347

Epoch: 6| Step: 6
Training loss: 1.9914136991963889
Validation loss: 2.402569602542926

Epoch: 6| Step: 7
Training loss: 2.556825915238216
Validation loss: 2.4128008758616692

Epoch: 6| Step: 8
Training loss: 2.6557390506967185
Validation loss: 2.4170076250296137

Epoch: 6| Step: 9
Training loss: 2.298944488147228
Validation loss: 2.3916043870461916

Epoch: 6| Step: 10
Training loss: 2.1644789091982988
Validation loss: 2.398527427420563

Epoch: 6| Step: 11
Training loss: 1.9670265768221233
Validation loss: 2.397117790117302

Epoch: 6| Step: 12
Training loss: 2.687888272648522
Validation loss: 2.397746099332118

Epoch: 6| Step: 13
Training loss: 2.2191488417930083
Validation loss: 2.3967895147736837

Epoch: 33| Step: 0
Training loss: 2.2372896617716194
Validation loss: 2.3805557320217727

Epoch: 6| Step: 1
Training loss: 2.1006555124533706
Validation loss: 2.386094215041136

Epoch: 6| Step: 2
Training loss: 2.0537407728232857
Validation loss: 2.3935658270333997

Epoch: 6| Step: 3
Training loss: 2.386256895939578
Validation loss: 2.4082926877649693

Epoch: 6| Step: 4
Training loss: 2.1614798548595977
Validation loss: 2.4077763361012856

Epoch: 6| Step: 5
Training loss: 2.096599632408563
Validation loss: 2.38908161881695

Epoch: 6| Step: 6
Training loss: 1.6256865004976793
Validation loss: 2.415674101678815

Epoch: 6| Step: 7
Training loss: 2.6296468204608976
Validation loss: 2.432729201135179

Epoch: 6| Step: 8
Training loss: 1.6229025435741147
Validation loss: 2.4285639938406316

Epoch: 6| Step: 9
Training loss: 2.648464236504287
Validation loss: 2.4205970427795247

Epoch: 6| Step: 10
Training loss: 2.0948081687556734
Validation loss: 2.430345035397492

Epoch: 6| Step: 11
Training loss: 2.49565767828079
Validation loss: 2.4314489981074128

Epoch: 6| Step: 12
Training loss: 2.999529642743634
Validation loss: 2.4355043490647796

Epoch: 6| Step: 13
Training loss: 2.4152859547336303
Validation loss: 2.4209286060943787

Epoch: 34| Step: 0
Training loss: 2.151491082806185
Validation loss: 2.410088734477133

Epoch: 6| Step: 1
Training loss: 2.47576910842321
Validation loss: 2.4067673560483858

Epoch: 6| Step: 2
Training loss: 2.0787221867942347
Validation loss: 2.4037911869513726

Epoch: 6| Step: 3
Training loss: 2.0125204618373362
Validation loss: 2.393100412673684

Epoch: 6| Step: 4
Training loss: 2.5161904593945184
Validation loss: 2.3966060442767025

Epoch: 6| Step: 5
Training loss: 2.654323013547485
Validation loss: 2.3909784525292967

Epoch: 6| Step: 6
Training loss: 2.5708267022227167
Validation loss: 2.4038662601021334

Epoch: 6| Step: 7
Training loss: 2.7876798905287
Validation loss: 2.4117407966333513

Epoch: 6| Step: 8
Training loss: 2.156044328251565
Validation loss: 2.4085824569188286

Epoch: 6| Step: 9
Training loss: 2.0870522938397302
Validation loss: 2.412481471305151

Epoch: 6| Step: 10
Training loss: 2.0972377139341067
Validation loss: 2.4221438350981663

Epoch: 6| Step: 11
Training loss: 2.0584611361385767
Validation loss: 2.399598874903264

Epoch: 6| Step: 12
Training loss: 2.1255301767817056
Validation loss: 2.4057503136014198

Epoch: 6| Step: 13
Training loss: 2.0906031859760903
Validation loss: 2.3955838336122874

Epoch: 35| Step: 0
Training loss: 2.2684930997478294
Validation loss: 2.4116768350059496

Epoch: 6| Step: 1
Training loss: 2.5609564435443257
Validation loss: 2.417739495752214

Epoch: 6| Step: 2
Training loss: 2.411403141804515
Validation loss: 2.425596532172154

Epoch: 6| Step: 3
Training loss: 1.7410641456982667
Validation loss: 2.4387281535291288

Epoch: 6| Step: 4
Training loss: 2.5533075834657466
Validation loss: 2.435703104326707

Epoch: 6| Step: 5
Training loss: 1.2014044311684304
Validation loss: 2.419248522658004

Epoch: 6| Step: 6
Training loss: 2.307489689466063
Validation loss: 2.434888402482116

Epoch: 6| Step: 7
Training loss: 1.9646020213506148
Validation loss: 2.440904098749101

Epoch: 6| Step: 8
Training loss: 2.1830110540175673
Validation loss: 2.437753338160489

Epoch: 6| Step: 9
Training loss: 1.6241207678572445
Validation loss: 2.433655306883071

Epoch: 6| Step: 10
Training loss: 2.5666691429159267
Validation loss: 2.417934090854309

Epoch: 6| Step: 11
Training loss: 2.341585711327615
Validation loss: 2.426656871106041

Epoch: 6| Step: 12
Training loss: 2.53937028633298
Validation loss: 2.432347402539871

Epoch: 6| Step: 13
Training loss: 2.8201545819058795
Validation loss: 2.423096969950078

Epoch: 36| Step: 0
Training loss: 2.280881878140297
Validation loss: 2.40637560099642

Epoch: 6| Step: 1
Training loss: 2.3427609200439354
Validation loss: 2.407536546661492

Epoch: 6| Step: 2
Training loss: 2.0557893184820433
Validation loss: 2.4066080594874077

Epoch: 6| Step: 3
Training loss: 2.577131970213115
Validation loss: 2.398137656821278

Epoch: 6| Step: 4
Training loss: 2.2342680792135217
Validation loss: 2.3946988170047225

Epoch: 6| Step: 5
Training loss: 2.083474752076805
Validation loss: 2.3955014676221134

Epoch: 6| Step: 6
Training loss: 2.2267969911473102
Validation loss: 2.3951679439102844

Epoch: 6| Step: 7
Training loss: 2.0811659283311212
Validation loss: 2.3998320850269543

Epoch: 6| Step: 8
Training loss: 2.6961599593321894
Validation loss: 2.3986460608512084

Epoch: 6| Step: 9
Training loss: 2.4935320154203495
Validation loss: 2.401599568213505

Epoch: 6| Step: 10
Training loss: 2.034716655678742
Validation loss: 2.402851710593903

Epoch: 6| Step: 11
Training loss: 1.9662688833640711
Validation loss: 2.3925111265598082

Epoch: 6| Step: 12
Training loss: 2.257540676557354
Validation loss: 2.4148962397955485

Epoch: 6| Step: 13
Training loss: 1.8816258660153997
Validation loss: 2.407891535137426

Epoch: 37| Step: 0
Training loss: 1.625614636896725
Validation loss: 2.3991607172067306

Epoch: 6| Step: 1
Training loss: 1.9556248650165242
Validation loss: 2.406650394303672

Epoch: 6| Step: 2
Training loss: 1.8621245498631076
Validation loss: 2.4271911357028766

Epoch: 6| Step: 3
Training loss: 1.7883328611593106
Validation loss: 2.460184383705934

Epoch: 6| Step: 4
Training loss: 2.5322977417203862
Validation loss: 2.458016008705172

Epoch: 6| Step: 5
Training loss: 2.0645147944165347
Validation loss: 2.4867515632908526

Epoch: 6| Step: 6
Training loss: 1.9915996806266851
Validation loss: 2.483182752980847

Epoch: 6| Step: 7
Training loss: 2.8350522680022476
Validation loss: 2.5124814787224725

Epoch: 6| Step: 8
Training loss: 2.9609555367194704
Validation loss: 2.4929605877379144

Epoch: 6| Step: 9
Training loss: 1.6695277055587594
Validation loss: 2.4827273361231272

Epoch: 6| Step: 10
Training loss: 2.008666691740947
Validation loss: 2.462378073189514

Epoch: 6| Step: 11
Training loss: 2.32961967671437
Validation loss: 2.4486277474092892

Epoch: 6| Step: 12
Training loss: 2.475371450428488
Validation loss: 2.4211218042134117

Epoch: 6| Step: 13
Training loss: 2.6078965801492027
Validation loss: 2.4073324369782596

Epoch: 38| Step: 0
Training loss: 1.6488590515027086
Validation loss: 2.4033023400056437

Epoch: 6| Step: 1
Training loss: 1.8653748464366366
Validation loss: 2.399364486966755

Epoch: 6| Step: 2
Training loss: 2.360592963516645
Validation loss: 2.4064152070507023

Epoch: 6| Step: 3
Training loss: 2.454385130074279
Validation loss: 2.3926504941622087

Epoch: 6| Step: 4
Training loss: 2.240074092116461
Validation loss: 2.4131850753956026

Epoch: 6| Step: 5
Training loss: 2.1355478261970284
Validation loss: 2.4165522504446346

Epoch: 6| Step: 6
Training loss: 2.5238560190742043
Validation loss: 2.428822730456561

Epoch: 6| Step: 7
Training loss: 2.2091356895152323
Validation loss: 2.4291430125930584

Epoch: 6| Step: 8
Training loss: 2.320934892917215
Validation loss: 2.4103999496403405

Epoch: 6| Step: 9
Training loss: 2.06745638781749
Validation loss: 2.411903032751346

Epoch: 6| Step: 10
Training loss: 2.772122095355841
Validation loss: 2.3959043298789156

Epoch: 6| Step: 11
Training loss: 2.091984132279854
Validation loss: 2.391323635764231

Epoch: 6| Step: 12
Training loss: 2.2974055708946417
Validation loss: 2.4025860423897027

Epoch: 6| Step: 13
Training loss: 2.0743893195816296
Validation loss: 2.3945594690515586

Epoch: 39| Step: 0
Training loss: 1.6511478650648916
Validation loss: 2.416163923871901

Epoch: 6| Step: 1
Training loss: 1.9301478651456458
Validation loss: 2.463759992628576

Epoch: 6| Step: 2
Training loss: 2.5719447185573294
Validation loss: 2.4969522574849443

Epoch: 6| Step: 3
Training loss: 2.6696426256729224
Validation loss: 2.505054101670652

Epoch: 6| Step: 4
Training loss: 1.7715769683629286
Validation loss: 2.501673067069036

Epoch: 6| Step: 5
Training loss: 2.244700230080802
Validation loss: 2.4961676469748166

Epoch: 6| Step: 6
Training loss: 2.0524789522418376
Validation loss: 2.475284362923291

Epoch: 6| Step: 7
Training loss: 2.654549806289621
Validation loss: 2.467641927830169

Epoch: 6| Step: 8
Training loss: 2.292896796012216
Validation loss: 2.4549217528377456

Epoch: 6| Step: 9
Training loss: 2.2919955162150947
Validation loss: 2.428886248748642

Epoch: 6| Step: 10
Training loss: 2.2829527052710477
Validation loss: 2.425488129217074

Epoch: 6| Step: 11
Training loss: 2.2990394825708047
Validation loss: 2.4003698660043677

Epoch: 6| Step: 12
Training loss: 1.681519259194782
Validation loss: 2.3962558097417372

Epoch: 6| Step: 13
Training loss: 2.382662608951016
Validation loss: 2.4019911675308

Epoch: 40| Step: 0
Training loss: 2.421028038332092
Validation loss: 2.394798218291022

Epoch: 6| Step: 1
Training loss: 1.931487815066027
Validation loss: 2.403920305037629

Epoch: 6| Step: 2
Training loss: 2.429370920831952
Validation loss: 2.418718754766166

Epoch: 6| Step: 3
Training loss: 1.7600212631241618
Validation loss: 2.4349785992976356

Epoch: 6| Step: 4
Training loss: 2.5760306434585747
Validation loss: 2.429556676484726

Epoch: 6| Step: 5
Training loss: 1.9325176288545831
Validation loss: 2.4120729677899364

Epoch: 6| Step: 6
Training loss: 1.997870384319334
Validation loss: 2.394361613385644

Epoch: 6| Step: 7
Training loss: 1.9040537830618425
Validation loss: 2.4188946341446016

Epoch: 6| Step: 8
Training loss: 2.288134181596329
Validation loss: 2.4009696855878153

Epoch: 6| Step: 9
Training loss: 1.7441946194312379
Validation loss: 2.4028118969645367

Epoch: 6| Step: 10
Training loss: 2.682096949549633
Validation loss: 2.432710800707588

Epoch: 6| Step: 11
Training loss: 2.704924144562678
Validation loss: 2.469882286937397

Epoch: 6| Step: 12
Training loss: 2.423620665445475
Validation loss: 2.4451130794829172

Epoch: 6| Step: 13
Training loss: 2.2447932716121968
Validation loss: 2.469711197070834

Epoch: 41| Step: 0
Training loss: 1.784347384317623
Validation loss: 2.4628817512499572

Epoch: 6| Step: 1
Training loss: 2.470445461181518
Validation loss: 2.4549574598522983

Epoch: 6| Step: 2
Training loss: 2.4956784089351727
Validation loss: 2.46512522755281

Epoch: 6| Step: 3
Training loss: 2.10775174448554
Validation loss: 2.4726003406505397

Epoch: 6| Step: 4
Training loss: 1.4094008855705138
Validation loss: 2.431195926473535

Epoch: 6| Step: 5
Training loss: 1.8555466806208387
Validation loss: 2.4488427027105506

Epoch: 6| Step: 6
Training loss: 2.620436197908579
Validation loss: 2.426470999907506

Epoch: 6| Step: 7
Training loss: 1.839259482102752
Validation loss: 2.4103130040233562

Epoch: 6| Step: 8
Training loss: 2.455152317768163
Validation loss: 2.4286599229936625

Epoch: 6| Step: 9
Training loss: 1.7038838507060208
Validation loss: 2.3943667000036153

Epoch: 6| Step: 10
Training loss: 2.1765319515365653
Validation loss: 2.4013402316025956

Epoch: 6| Step: 11
Training loss: 2.658673964374032
Validation loss: 2.4007467445966655

Epoch: 6| Step: 12
Training loss: 2.099579850809861
Validation loss: 2.411514608387047

Epoch: 6| Step: 13
Training loss: 2.3241466350747633
Validation loss: 2.4166326575243007

Epoch: 42| Step: 0
Training loss: 1.8473559532740094
Validation loss: 2.4028254824578

Epoch: 6| Step: 1
Training loss: 2.1058729700248655
Validation loss: 2.4096348062930395

Epoch: 6| Step: 2
Training loss: 1.7334436888899767
Validation loss: 2.417224233258203

Epoch: 6| Step: 3
Training loss: 2.343713582073834
Validation loss: 2.40675495678777

Epoch: 6| Step: 4
Training loss: 2.5928177594493254
Validation loss: 2.413174034660503

Epoch: 6| Step: 5
Training loss: 1.9659464417125225
Validation loss: 2.407833932182551

Epoch: 6| Step: 6
Training loss: 2.099005181962696
Validation loss: 2.41391436833244

Epoch: 6| Step: 7
Training loss: 1.8712240982046764
Validation loss: 2.418545113493527

Epoch: 6| Step: 8
Training loss: 2.774682853377772
Validation loss: 2.426854893708099

Epoch: 6| Step: 9
Training loss: 1.838120546462012
Validation loss: 2.4371145546836654

Epoch: 6| Step: 10
Training loss: 2.888484017619614
Validation loss: 2.445500310768467

Epoch: 6| Step: 11
Training loss: 1.8408603329950055
Validation loss: 2.4280130354810496

Epoch: 6| Step: 12
Training loss: 1.9318447641593925
Validation loss: 2.450833832023991

Epoch: 6| Step: 13
Training loss: 1.8493589012113094
Validation loss: 2.451382141416183

Epoch: 43| Step: 0
Training loss: 2.137215899945187
Validation loss: 2.461622758351945

Epoch: 6| Step: 1
Training loss: 1.8573015978325327
Validation loss: 2.461868981777485

Epoch: 6| Step: 2
Training loss: 2.6276278285210988
Validation loss: 2.459885791308725

Epoch: 6| Step: 3
Training loss: 1.679755417980978
Validation loss: 2.448140143616343

Epoch: 6| Step: 4
Training loss: 2.6339873910021385
Validation loss: 2.435593593121812

Epoch: 6| Step: 5
Training loss: 1.8397831026031366
Validation loss: 2.420834340299396

Epoch: 6| Step: 6
Training loss: 1.8127695738167433
Validation loss: 2.4263842043740143

Epoch: 6| Step: 7
Training loss: 2.037649900386872
Validation loss: 2.4272131550877267

Epoch: 6| Step: 8
Training loss: 1.906393327171311
Validation loss: 2.4394299129606476

Epoch: 6| Step: 9
Training loss: 1.564183358354207
Validation loss: 2.4284408494828638

Epoch: 6| Step: 10
Training loss: 2.6310663517088897
Validation loss: 2.4242137650309368

Epoch: 6| Step: 11
Training loss: 2.370600490388053
Validation loss: 2.41339968868926

Epoch: 6| Step: 12
Training loss: 2.3938385551147974
Validation loss: 2.424192537982938

Epoch: 6| Step: 13
Training loss: 1.8608675824282273
Validation loss: 2.43023600218504

Epoch: 44| Step: 0
Training loss: 2.1174396209935873
Validation loss: 2.414190360986557

Epoch: 6| Step: 1
Training loss: 2.699147202775984
Validation loss: 2.4012290622182926

Epoch: 6| Step: 2
Training loss: 2.015735002221802
Validation loss: 2.4032788780099343

Epoch: 6| Step: 3
Training loss: 1.3419685087417625
Validation loss: 2.434167393265611

Epoch: 6| Step: 4
Training loss: 2.5672996046092207
Validation loss: 2.4056803784595657

Epoch: 6| Step: 5
Training loss: 1.8772344626478297
Validation loss: 2.4058998976156944

Epoch: 6| Step: 6
Training loss: 2.8105307572613767
Validation loss: 2.39599221297067

Epoch: 6| Step: 7
Training loss: 1.665076148551427
Validation loss: 2.4183961719557514

Epoch: 6| Step: 8
Training loss: 2.0817955699599757
Validation loss: 2.4025217791498683

Epoch: 6| Step: 9
Training loss: 2.107792578646188
Validation loss: 2.4229433062054624

Epoch: 6| Step: 10
Training loss: 2.0876962626588256
Validation loss: 2.406275166962038

Epoch: 6| Step: 11
Training loss: 1.8296043735453544
Validation loss: 2.435438376515665

Epoch: 6| Step: 12
Training loss: 2.3845660651812244
Validation loss: 2.439687806674213

Epoch: 6| Step: 13
Training loss: 1.7709726690189862
Validation loss: 2.44484469780593

Epoch: 45| Step: 0
Training loss: 2.7421835005424002
Validation loss: 2.443332573377518

Epoch: 6| Step: 1
Training loss: 1.8371106883650021
Validation loss: 2.44243137657573

Epoch: 6| Step: 2
Training loss: 1.9995308564216934
Validation loss: 2.417642533375099

Epoch: 6| Step: 3
Training loss: 1.9763998937252025
Validation loss: 2.414310265658356

Epoch: 6| Step: 4
Training loss: 1.795323373680286
Validation loss: 2.4295783473250268

Epoch: 6| Step: 5
Training loss: 1.8832278604708819
Validation loss: 2.4415120094280502

Epoch: 6| Step: 6
Training loss: 2.567215279575714
Validation loss: 2.436928722894651

Epoch: 6| Step: 7
Training loss: 2.236074801427297
Validation loss: 2.430835620245666

Epoch: 6| Step: 8
Training loss: 1.9640462481691998
Validation loss: 2.397975152233477

Epoch: 6| Step: 9
Training loss: 1.9274200832557615
Validation loss: 2.4254151179073835

Epoch: 6| Step: 10
Training loss: 1.4162682459195448
Validation loss: 2.430947503473358

Epoch: 6| Step: 11
Training loss: 1.9702345685196025
Validation loss: 2.4344156264317247

Epoch: 6| Step: 12
Training loss: 2.2746979146080406
Validation loss: 2.4532204222697755

Epoch: 6| Step: 13
Training loss: 2.425841792974351
Validation loss: 2.425130055404078

Epoch: 46| Step: 0
Training loss: 2.4792583245609534
Validation loss: 2.4524260738117674

Epoch: 6| Step: 1
Training loss: 2.091945496879415
Validation loss: 2.465817057289518

Epoch: 6| Step: 2
Training loss: 2.3063263836541985
Validation loss: 2.4535067801823986

Epoch: 6| Step: 3
Training loss: 2.2706142868179864
Validation loss: 2.4575289822017794

Epoch: 6| Step: 4
Training loss: 1.8412973286747687
Validation loss: 2.436414917266427

Epoch: 6| Step: 5
Training loss: 2.0669798316359183
Validation loss: 2.465763490733508

Epoch: 6| Step: 6
Training loss: 1.945978808904141
Validation loss: 2.4364230067081496

Epoch: 6| Step: 7
Training loss: 2.2772498397701457
Validation loss: 2.4296746616494533

Epoch: 6| Step: 8
Training loss: 2.2389502998345887
Validation loss: 2.415988914775891

Epoch: 6| Step: 9
Training loss: 1.8281553869085805
Validation loss: 2.4335724088285176

Epoch: 6| Step: 10
Training loss: 1.6465527937713966
Validation loss: 2.42008197820281

Epoch: 6| Step: 11
Training loss: 2.4451475240125227
Validation loss: 2.4094865343506955

Epoch: 6| Step: 12
Training loss: 1.480156938634644
Validation loss: 2.4142804258347215

Epoch: 6| Step: 13
Training loss: 2.06969906337894
Validation loss: 2.421144879943855

Epoch: 47| Step: 0
Training loss: 2.1730070388546525
Validation loss: 2.4188975541337747

Epoch: 6| Step: 1
Training loss: 2.5971970231119497
Validation loss: 2.4116991937584022

Epoch: 6| Step: 2
Training loss: 1.865444758668571
Validation loss: 2.4254554779594613

Epoch: 6| Step: 3
Training loss: 2.123502989398387
Validation loss: 2.405802433285434

Epoch: 6| Step: 4
Training loss: 1.4356069124084616
Validation loss: 2.4185288108803626

Epoch: 6| Step: 5
Training loss: 2.5763032892704354
Validation loss: 2.4549128826556825

Epoch: 6| Step: 6
Training loss: 2.0203534634738065
Validation loss: 2.43905698330451

Epoch: 6| Step: 7
Training loss: 2.051821374067519
Validation loss: 2.462190549225381

Epoch: 6| Step: 8
Training loss: 2.1592748682238136
Validation loss: 2.4429253574637277

Epoch: 6| Step: 9
Training loss: 2.2824934614407497
Validation loss: 2.444397874109177

Epoch: 6| Step: 10
Training loss: 1.810702386162923
Validation loss: 2.4066108581653713

Epoch: 6| Step: 11
Training loss: 2.314160549809146
Validation loss: 2.440338576764481

Epoch: 6| Step: 12
Training loss: 1.6134491987762924
Validation loss: 2.4094482239226975

Epoch: 6| Step: 13
Training loss: 1.9491579585256644
Validation loss: 2.4176633905991394

Epoch: 48| Step: 0
Training loss: 2.19217552785398
Validation loss: 2.416544637120322

Epoch: 6| Step: 1
Training loss: 1.9136541437003867
Validation loss: 2.4035434115580054

Epoch: 6| Step: 2
Training loss: 1.7038431315950833
Validation loss: 2.4163682577996757

Epoch: 6| Step: 3
Training loss: 1.9996926548362757
Validation loss: 2.4177993772611677

Epoch: 6| Step: 4
Training loss: 1.7153673350249021
Validation loss: 2.4167641066496

Epoch: 6| Step: 5
Training loss: 1.4299051087913859
Validation loss: 2.41546772670644

Epoch: 6| Step: 6
Training loss: 1.7046257895987929
Validation loss: 2.4229879139740342

Epoch: 6| Step: 7
Training loss: 2.3080050109861774
Validation loss: 2.438153171241282

Epoch: 6| Step: 8
Training loss: 2.8474606628648096
Validation loss: 2.4728165625279273

Epoch: 6| Step: 9
Training loss: 1.7993942513053829
Validation loss: 2.492138087820183

Epoch: 6| Step: 10
Training loss: 2.7906047072746047
Validation loss: 2.4776537283131006

Epoch: 6| Step: 11
Training loss: 2.3920435467841954
Validation loss: 2.447070358292199

Epoch: 6| Step: 12
Training loss: 2.0705163243563836
Validation loss: 2.4531529337918485

Epoch: 6| Step: 13
Training loss: 1.4494067787282454
Validation loss: 2.42883171228112

Epoch: 49| Step: 0
Training loss: 1.7798648601837634
Validation loss: 2.428457441446481

Epoch: 6| Step: 1
Training loss: 1.5996193611848695
Validation loss: 2.404389673751321

Epoch: 6| Step: 2
Training loss: 2.4806930800995532
Validation loss: 2.42537485548543

Epoch: 6| Step: 3
Training loss: 2.0556778642277176
Validation loss: 2.421635113392639

Epoch: 6| Step: 4
Training loss: 1.7777886473137976
Validation loss: 2.413706007295954

Epoch: 6| Step: 5
Training loss: 2.240944122189765
Validation loss: 2.4359684232388825

Epoch: 6| Step: 6
Training loss: 1.596412080976462
Validation loss: 2.4289857560367407

Epoch: 6| Step: 7
Training loss: 2.1152173549710565
Validation loss: 2.4218927444300182

Epoch: 6| Step: 8
Training loss: 2.0080860708567125
Validation loss: 2.47082469374726

Epoch: 6| Step: 9
Training loss: 2.380653879436647
Validation loss: 2.4655281483009044

Epoch: 6| Step: 10
Training loss: 2.0602221770979816
Validation loss: 2.4920267433927648

Epoch: 6| Step: 11
Training loss: 2.508440265932004
Validation loss: 2.484680444906258

Epoch: 6| Step: 12
Training loss: 1.9778660030665438
Validation loss: 2.5233863770273532

Epoch: 6| Step: 13
Training loss: 2.1090646020898873
Validation loss: 2.5042821053562436

Epoch: 50| Step: 0
Training loss: 2.0859588736249894
Validation loss: 2.441948653940132

Epoch: 6| Step: 1
Training loss: 2.08941988345362
Validation loss: 2.4437174444477283

Epoch: 6| Step: 2
Training loss: 2.231590616850093
Validation loss: 2.416927066015597

Epoch: 6| Step: 3
Training loss: 2.2462319505716777
Validation loss: 2.4233264142566884

Epoch: 6| Step: 4
Training loss: 1.9951072688890137
Validation loss: 2.410459098563334

Epoch: 6| Step: 5
Training loss: 2.255042465723605
Validation loss: 2.4290015753977414

Epoch: 6| Step: 6
Training loss: 1.9359362659958423
Validation loss: 2.443948692446058

Epoch: 6| Step: 7
Training loss: 1.5217192521188943
Validation loss: 2.438205225723996

Epoch: 6| Step: 8
Training loss: 2.2420710623144884
Validation loss: 2.4499859822449634

Epoch: 6| Step: 9
Training loss: 1.779227530743439
Validation loss: 2.4416547480955204

Epoch: 6| Step: 10
Training loss: 2.228296080196819
Validation loss: 2.450350356514786

Epoch: 6| Step: 11
Training loss: 1.8179159473968884
Validation loss: 2.430440297497201

Epoch: 6| Step: 12
Training loss: 2.035035347596399
Validation loss: 2.4420084950551604

Epoch: 6| Step: 13
Training loss: 1.8650908250144222
Validation loss: 2.4638972170331948

Epoch: 51| Step: 0
Training loss: 2.7462413417174405
Validation loss: 2.4782831610565292

Epoch: 6| Step: 1
Training loss: 2.091703183082084
Validation loss: 2.5068688444348743

Epoch: 6| Step: 2
Training loss: 1.681136672727752
Validation loss: 2.4905800094593373

Epoch: 6| Step: 3
Training loss: 1.8161001296145907
Validation loss: 2.5007173780511227

Epoch: 6| Step: 4
Training loss: 1.7014098323994853
Validation loss: 2.5061402414947302

Epoch: 6| Step: 5
Training loss: 2.3070372935680026
Validation loss: 2.490548953463285

Epoch: 6| Step: 6
Training loss: 1.5491216508885637
Validation loss: 2.452340958468009

Epoch: 6| Step: 7
Training loss: 1.6972749663733515
Validation loss: 2.4339251101310992

Epoch: 6| Step: 8
Training loss: 2.0346359202802065
Validation loss: 2.4365047150875534

Epoch: 6| Step: 9
Training loss: 2.1990566702111267
Validation loss: 2.4486224895185758

Epoch: 6| Step: 10
Training loss: 1.9864437103400048
Validation loss: 2.438467485835922

Epoch: 6| Step: 11
Training loss: 2.021613399792407
Validation loss: 2.460475648199426

Epoch: 6| Step: 12
Training loss: 2.2674530021061634
Validation loss: 2.433899714797925

Epoch: 6| Step: 13
Training loss: 2.034965286521171
Validation loss: 2.4162769715944488

Epoch: 52| Step: 0
Training loss: 1.544530228116166
Validation loss: 2.438851967848081

Epoch: 6| Step: 1
Training loss: 2.487112204836324
Validation loss: 2.4624619702082886

Epoch: 6| Step: 2
Training loss: 1.336335864542271
Validation loss: 2.48633960802134

Epoch: 6| Step: 3
Training loss: 2.164496863666253
Validation loss: 2.520059156682219

Epoch: 6| Step: 4
Training loss: 2.407043722455312
Validation loss: 2.553610602912625

Epoch: 6| Step: 5
Training loss: 2.2113089636946395
Validation loss: 2.563886313978422

Epoch: 6| Step: 6
Training loss: 1.615178800316416
Validation loss: 2.5239740988102164

Epoch: 6| Step: 7
Training loss: 1.8806280229518197
Validation loss: 2.503383683114401

Epoch: 6| Step: 8
Training loss: 1.9892606889706743
Validation loss: 2.474860455853022

Epoch: 6| Step: 9
Training loss: 2.3416309186530433
Validation loss: 2.4581015984101606

Epoch: 6| Step: 10
Training loss: 1.8618094271317198
Validation loss: 2.433522769878668

Epoch: 6| Step: 11
Training loss: 1.4583642502186887
Validation loss: 2.439902547990387

Epoch: 6| Step: 12
Training loss: 2.4444709280294084
Validation loss: 2.4170066714896405

Epoch: 6| Step: 13
Training loss: 1.8962202271228297
Validation loss: 2.4052003247136113

Epoch: 53| Step: 0
Training loss: 2.0675638630423943
Validation loss: 2.413744357152026

Epoch: 6| Step: 1
Training loss: 1.7568240629158518
Validation loss: 2.4317120930945526

Epoch: 6| Step: 2
Training loss: 1.736033016567668
Validation loss: 2.41502074941563

Epoch: 6| Step: 3
Training loss: 2.1836498710503887
Validation loss: 2.416545031764072

Epoch: 6| Step: 4
Training loss: 1.7002068113302997
Validation loss: 2.4304539983210365

Epoch: 6| Step: 5
Training loss: 2.2677465568502044
Validation loss: 2.4375744017632925

Epoch: 6| Step: 6
Training loss: 1.9328122187547163
Validation loss: 2.4964483941452364

Epoch: 6| Step: 7
Training loss: 1.7779129625950412
Validation loss: 2.50343771452334

Epoch: 6| Step: 8
Training loss: 2.1072809067918294
Validation loss: 2.484284621220214

Epoch: 6| Step: 9
Training loss: 2.2368679411255274
Validation loss: 2.5111231673728622

Epoch: 6| Step: 10
Training loss: 2.4835727763962825
Validation loss: 2.487025855992565

Epoch: 6| Step: 11
Training loss: 2.16200825386695
Validation loss: 2.442220811378728

Epoch: 6| Step: 12
Training loss: 1.5701641563074498
Validation loss: 2.4198223480455896

Epoch: 6| Step: 13
Training loss: 1.7938140007058754
Validation loss: 2.4259702534126872

Epoch: 54| Step: 0
Training loss: 2.5369958536477313
Validation loss: 2.4423936642549724

Epoch: 6| Step: 1
Training loss: 2.115189063096735
Validation loss: 2.441646798045417

Epoch: 6| Step: 2
Training loss: 1.4814610841901068
Validation loss: 2.4601865238197806

Epoch: 6| Step: 3
Training loss: 2.0674667665700412
Validation loss: 2.4520821268040343

Epoch: 6| Step: 4
Training loss: 1.81015764350821
Validation loss: 2.4604363632598107

Epoch: 6| Step: 5
Training loss: 1.3929622596508218
Validation loss: 2.443959122642663

Epoch: 6| Step: 6
Training loss: 2.292228098212706
Validation loss: 2.4235452942411295

Epoch: 6| Step: 7
Training loss: 1.9382503656204688
Validation loss: 2.4116995068124183

Epoch: 6| Step: 8
Training loss: 1.8005699977134044
Validation loss: 2.4238919463094533

Epoch: 6| Step: 9
Training loss: 1.6272329980428228
Validation loss: 2.455057909347914

Epoch: 6| Step: 10
Training loss: 1.788123938231168
Validation loss: 2.4696197426329656

Epoch: 6| Step: 11
Training loss: 1.6131650130028967
Validation loss: 2.4745117505454166

Epoch: 6| Step: 12
Training loss: 1.9716783573624166
Validation loss: 2.4679460141868654

Epoch: 6| Step: 13
Training loss: 2.531754620020205
Validation loss: 2.5071910749753306

Epoch: 55| Step: 0
Training loss: 1.2307803773604502
Validation loss: 2.541566226621446

Epoch: 6| Step: 1
Training loss: 1.691449876183012
Validation loss: 2.5101937053856904

Epoch: 6| Step: 2
Training loss: 1.8355851504890872
Validation loss: 2.5149438224064635

Epoch: 6| Step: 3
Training loss: 2.283579955971264
Validation loss: 2.452775075783063

Epoch: 6| Step: 4
Training loss: 2.4546235967970986
Validation loss: 2.4845571711065513

Epoch: 6| Step: 5
Training loss: 1.7091905567589487
Validation loss: 2.430092094073412

Epoch: 6| Step: 6
Training loss: 2.094497661043793
Validation loss: 2.424350007110215

Epoch: 6| Step: 7
Training loss: 1.9793297014512563
Validation loss: 2.423152742395141

Epoch: 6| Step: 8
Training loss: 1.9787160126110144
Validation loss: 2.4519080445915775

Epoch: 6| Step: 9
Training loss: 2.0315181848574464
Validation loss: 2.451755084481939

Epoch: 6| Step: 10
Training loss: 2.0548739620642142
Validation loss: 2.425919680861032

Epoch: 6| Step: 11
Training loss: 1.7485815839401317
Validation loss: 2.4220024977728105

Epoch: 6| Step: 12
Training loss: 1.9066114239370346
Validation loss: 2.4409248223246367

Epoch: 6| Step: 13
Training loss: 2.360056797572583
Validation loss: 2.4096142753537477

Epoch: 56| Step: 0
Training loss: 1.6003690413215355
Validation loss: 2.4036283371861336

Epoch: 6| Step: 1
Training loss: 1.952450506093434
Validation loss: 2.4379211942189194

Epoch: 6| Step: 2
Training loss: 1.7118343981036137
Validation loss: 2.460869746814517

Epoch: 6| Step: 3
Training loss: 1.7903644205729092
Validation loss: 2.453826512423009

Epoch: 6| Step: 4
Training loss: 1.845124330544155
Validation loss: 2.4482962672485753

Epoch: 6| Step: 5
Training loss: 1.9955217769985838
Validation loss: 2.436170150025003

Epoch: 6| Step: 6
Training loss: 2.3316488543528338
Validation loss: 2.4048316044848037

Epoch: 6| Step: 7
Training loss: 2.3194451043387545
Validation loss: 2.414120390526085

Epoch: 6| Step: 8
Training loss: 2.5376736172817616
Validation loss: 2.401047743143487

Epoch: 6| Step: 9
Training loss: 2.0767732971067603
Validation loss: 2.4327926337660704

Epoch: 6| Step: 10
Training loss: 1.2246204722508554
Validation loss: 2.435028143295171

Epoch: 6| Step: 11
Training loss: 1.5823847622969918
Validation loss: 2.431945307792173

Epoch: 6| Step: 12
Training loss: 2.456589408895036
Validation loss: 2.424134494580686

Epoch: 6| Step: 13
Training loss: 1.8629883350000975
Validation loss: 2.4368151167159606

Epoch: 57| Step: 0
Training loss: 1.4963933181642066
Validation loss: 2.4609614618335747

Epoch: 6| Step: 1
Training loss: 1.724879830086118
Validation loss: 2.5023983577344016

Epoch: 6| Step: 2
Training loss: 1.3876874092623293
Validation loss: 2.485113086263633

Epoch: 6| Step: 3
Training loss: 2.084314064610725
Validation loss: 2.4986185071504816

Epoch: 6| Step: 4
Training loss: 2.228370548109676
Validation loss: 2.450868171834268

Epoch: 6| Step: 5
Training loss: 2.0454796847330257
Validation loss: 2.476557959262604

Epoch: 6| Step: 6
Training loss: 2.3712068684726857
Validation loss: 2.475070588232341

Epoch: 6| Step: 7
Training loss: 1.6066113047077295
Validation loss: 2.43101645020464

Epoch: 6| Step: 8
Training loss: 1.32145591748048
Validation loss: 2.426035713613262

Epoch: 6| Step: 9
Training loss: 2.5017393737061053
Validation loss: 2.4408805586376063

Epoch: 6| Step: 10
Training loss: 2.197305446687761
Validation loss: 2.407651451842641

Epoch: 6| Step: 11
Training loss: 2.2644366074387876
Validation loss: 2.4151179569046195

Epoch: 6| Step: 12
Training loss: 1.5489003957120007
Validation loss: 2.4230977735022114

Epoch: 6| Step: 13
Training loss: 1.4873777836190822
Validation loss: 2.394609243627685

Epoch: 58| Step: 0
Training loss: 2.4733617658943046
Validation loss: 2.4155322788697817

Epoch: 6| Step: 1
Training loss: 1.9560619397916916
Validation loss: 2.43718370194964

Epoch: 6| Step: 2
Training loss: 1.9657743460923074
Validation loss: 2.455160547783289

Epoch: 6| Step: 3
Training loss: 1.9853661532412386
Validation loss: 2.463893862517033

Epoch: 6| Step: 4
Training loss: 1.993445504114611
Validation loss: 2.4658227377901647

Epoch: 6| Step: 5
Training loss: 1.5840714474227988
Validation loss: 2.4883538539480656

Epoch: 6| Step: 6
Training loss: 1.6315429716726149
Validation loss: 2.527105069571467

Epoch: 6| Step: 7
Training loss: 1.6881616496203862
Validation loss: 2.504642340684707

Epoch: 6| Step: 8
Training loss: 1.875112911639319
Validation loss: 2.495932035028243

Epoch: 6| Step: 9
Training loss: 1.9221612980668747
Validation loss: 2.500573140249927

Epoch: 6| Step: 10
Training loss: 1.8771583214732694
Validation loss: 2.4670131867387095

Epoch: 6| Step: 11
Training loss: 1.8184377815231942
Validation loss: 2.4297868845280752

Epoch: 6| Step: 12
Training loss: 1.401985611516608
Validation loss: 2.4311788383470874

Epoch: 6| Step: 13
Training loss: 1.9957579686769018
Validation loss: 2.3988980690833124

Epoch: 59| Step: 0
Training loss: 1.2822137789877084
Validation loss: 2.4191712576936144

Epoch: 6| Step: 1
Training loss: 2.253745035260191
Validation loss: 2.4417004868266683

Epoch: 6| Step: 2
Training loss: 1.6571042718764242
Validation loss: 2.4547837434189885

Epoch: 6| Step: 3
Training loss: 2.036918126434243
Validation loss: 2.459729046282309

Epoch: 6| Step: 4
Training loss: 2.0110585138504478
Validation loss: 2.4339437870826397

Epoch: 6| Step: 5
Training loss: 2.3771823092379263
Validation loss: 2.394817391205275

Epoch: 6| Step: 6
Training loss: 1.794986030503003
Validation loss: 2.407188579267398

Epoch: 6| Step: 7
Training loss: 2.6654927729628692
Validation loss: 2.473885486266442

Epoch: 6| Step: 8
Training loss: 1.8418721479970483
Validation loss: 2.4453349412044756

Epoch: 6| Step: 9
Training loss: 1.4843472126819355
Validation loss: 2.4849240797893803

Epoch: 6| Step: 10
Training loss: 1.5271941987404563
Validation loss: 2.43491777760346

Epoch: 6| Step: 11
Training loss: 2.032049637901593
Validation loss: 2.4348290473360095

Epoch: 6| Step: 12
Training loss: 1.2553480184030044
Validation loss: 2.433064035206656

Epoch: 6| Step: 13
Training loss: 1.7877059524437888
Validation loss: 2.444330605351089

Epoch: 60| Step: 0
Training loss: 1.6713222409871724
Validation loss: 2.433832392617956

Epoch: 6| Step: 1
Training loss: 1.891172912902459
Validation loss: 2.4621834482094376

Epoch: 6| Step: 2
Training loss: 2.167098466932423
Validation loss: 2.4272454880231678

Epoch: 6| Step: 3
Training loss: 2.241114874881645
Validation loss: 2.4899504695444663

Epoch: 6| Step: 4
Training loss: 1.5740509322383038
Validation loss: 2.446142330071056

Epoch: 6| Step: 5
Training loss: 2.0224110713688894
Validation loss: 2.4788731366516767

Epoch: 6| Step: 6
Training loss: 1.6825303261731812
Validation loss: 2.450508487898687

Epoch: 6| Step: 7
Training loss: 1.26072256721577
Validation loss: 2.456702715282715

Epoch: 6| Step: 8
Training loss: 1.9858047260887084
Validation loss: 2.469121655523722

Epoch: 6| Step: 9
Training loss: 1.9359332487168943
Validation loss: 2.4945635017646155

Epoch: 6| Step: 10
Training loss: 2.3993052549924783
Validation loss: 2.50322858236544

Epoch: 6| Step: 11
Training loss: 1.3273523214780814
Validation loss: 2.453683591123106

Epoch: 6| Step: 12
Training loss: 1.6152598368657072
Validation loss: 2.4347112221864364

Epoch: 6| Step: 13
Training loss: 1.5844102844282018
Validation loss: 2.429021795237601

Epoch: 61| Step: 0
Training loss: 1.803522634048508
Validation loss: 2.4479717140230943

Epoch: 6| Step: 1
Training loss: 1.8215151894433723
Validation loss: 2.416126114033704

Epoch: 6| Step: 2
Training loss: 2.1313529697277698
Validation loss: 2.4354455799858914

Epoch: 6| Step: 3
Training loss: 1.672595002764843
Validation loss: 2.4344104194594474

Epoch: 6| Step: 4
Training loss: 1.6254472850558277
Validation loss: 2.432505568928893

Epoch: 6| Step: 5
Training loss: 1.6787066057381212
Validation loss: 2.4105850819203667

Epoch: 6| Step: 6
Training loss: 2.264862563656121
Validation loss: 2.4481040612316165

Epoch: 6| Step: 7
Training loss: 1.6423188684186651
Validation loss: 2.405951923221922

Epoch: 6| Step: 8
Training loss: 1.6037139584066056
Validation loss: 2.4276596143755325

Epoch: 6| Step: 9
Training loss: 1.401236391775596
Validation loss: 2.420369851615159

Epoch: 6| Step: 10
Training loss: 1.365614853042162
Validation loss: 2.4908974396807135

Epoch: 6| Step: 11
Training loss: 1.6049740068464
Validation loss: 2.4443516087483723

Epoch: 6| Step: 12
Training loss: 2.733879087982184
Validation loss: 2.4943786443793465

Epoch: 6| Step: 13
Training loss: 1.6600403509636121
Validation loss: 2.5064901032388454

Epoch: 62| Step: 0
Training loss: 1.6424842834881974
Validation loss: 2.506702450748785

Epoch: 6| Step: 1
Training loss: 1.9024173166200753
Validation loss: 2.513263739407384

Epoch: 6| Step: 2
Training loss: 1.9031573363314647
Validation loss: 2.524786054404198

Epoch: 6| Step: 3
Training loss: 1.8220134859140815
Validation loss: 2.4517975959679124

Epoch: 6| Step: 4
Training loss: 2.5671125627424365
Validation loss: 2.4577484135438152

Epoch: 6| Step: 5
Training loss: 1.7936519742225827
Validation loss: 2.4097999874127547

Epoch: 6| Step: 6
Training loss: 1.3552618390994509
Validation loss: 2.4285679698299707

Epoch: 6| Step: 7
Training loss: 1.9479730635313972
Validation loss: 2.4511485631880348

Epoch: 6| Step: 8
Training loss: 1.911262737803055
Validation loss: 2.45967546022829

Epoch: 6| Step: 9
Training loss: 2.0337446885839694
Validation loss: 2.4526473631220593

Epoch: 6| Step: 10
Training loss: 1.4675280580973915
Validation loss: 2.4685859303741227

Epoch: 6| Step: 11
Training loss: 1.5037962241611293
Validation loss: 2.4273560552220688

Epoch: 6| Step: 12
Training loss: 1.5304108480704133
Validation loss: 2.457129908583827

Epoch: 6| Step: 13
Training loss: 1.8162121740866783
Validation loss: 2.4485377369291985

Epoch: 63| Step: 0
Training loss: 1.7395279774643189
Validation loss: 2.470816491784203

Epoch: 6| Step: 1
Training loss: 1.7393126438928588
Validation loss: 2.519131997976478

Epoch: 6| Step: 2
Training loss: 2.0859640169779903
Validation loss: 2.55748750878121

Epoch: 6| Step: 3
Training loss: 2.345643766161941
Validation loss: 2.531743758909013

Epoch: 6| Step: 4
Training loss: 1.6528367193203455
Validation loss: 2.513536032143285

Epoch: 6| Step: 5
Training loss: 1.6424618565326852
Validation loss: 2.4718693851707787

Epoch: 6| Step: 6
Training loss: 1.4412472851769849
Validation loss: 2.458277618186332

Epoch: 6| Step: 7
Training loss: 1.496288874478883
Validation loss: 2.4160529596090523

Epoch: 6| Step: 8
Training loss: 1.8776661672597708
Validation loss: 2.4368464661583

Epoch: 6| Step: 9
Training loss: 1.2757404309182443
Validation loss: 2.4572806825563465

Epoch: 6| Step: 10
Training loss: 1.6323624862306922
Validation loss: 2.446764822436655

Epoch: 6| Step: 11
Training loss: 1.5891059081863805
Validation loss: 2.4872056361968404

Epoch: 6| Step: 12
Training loss: 2.6389778914138047
Validation loss: 2.4693175198729747

Epoch: 6| Step: 13
Training loss: 1.8561456670243137
Validation loss: 2.457750224338801

Epoch: 64| Step: 0
Training loss: 1.0425113432196205
Validation loss: 2.4752950864902634

Epoch: 6| Step: 1
Training loss: 2.176968755551279
Validation loss: 2.430286632071696

Epoch: 6| Step: 2
Training loss: 1.69827714459601
Validation loss: 2.4666775483028855

Epoch: 6| Step: 3
Training loss: 2.665388565937053
Validation loss: 2.461854011179529

Epoch: 6| Step: 4
Training loss: 1.657492837099274
Validation loss: 2.4204976913366543

Epoch: 6| Step: 5
Training loss: 1.5677551397726914
Validation loss: 2.4453827966695347

Epoch: 6| Step: 6
Training loss: 1.6142746496966742
Validation loss: 2.4236138121241617

Epoch: 6| Step: 7
Training loss: 1.5430574415767455
Validation loss: 2.4450919932433983

Epoch: 6| Step: 8
Training loss: 1.1523310773766897
Validation loss: 2.4739131454891767

Epoch: 6| Step: 9
Training loss: 2.0461923174222725
Validation loss: 2.408780571440513

Epoch: 6| Step: 10
Training loss: 1.7925328075859512
Validation loss: 2.4674283767503575

Epoch: 6| Step: 11
Training loss: 1.4247928067209423
Validation loss: 2.4272390705836586

Epoch: 6| Step: 12
Training loss: 1.6427539636067474
Validation loss: 2.424813340072158

Epoch: 6| Step: 13
Training loss: 1.7398423632105358
Validation loss: 2.423433766135695

Epoch: 65| Step: 0
Training loss: 1.5469505214558479
Validation loss: 2.4496878094191805

Epoch: 6| Step: 1
Training loss: 2.138194576983523
Validation loss: 2.440039644368746

Epoch: 6| Step: 2
Training loss: 1.3560831837528715
Validation loss: 2.4519531788040245

Epoch: 6| Step: 3
Training loss: 1.6782004227551448
Validation loss: 2.4220779826102246

Epoch: 6| Step: 4
Training loss: 0.8658309498724442
Validation loss: 2.485729192337769

Epoch: 6| Step: 5
Training loss: 1.9541121772809527
Validation loss: 2.438140198191564

Epoch: 6| Step: 6
Training loss: 1.2670815645803701
Validation loss: 2.4384345765344615

Epoch: 6| Step: 7
Training loss: 2.3288155370101604
Validation loss: 2.4426431599742924

Epoch: 6| Step: 8
Training loss: 1.5558205314535893
Validation loss: 2.4565930807185823

Epoch: 6| Step: 9
Training loss: 1.8458071078926745
Validation loss: 2.4622435802559743

Epoch: 6| Step: 10
Training loss: 1.731996709868938
Validation loss: 2.435709858376131

Epoch: 6| Step: 11
Training loss: 1.8692424112665635
Validation loss: 2.460610278137779

Epoch: 6| Step: 12
Training loss: 1.4530002991688493
Validation loss: 2.458629724986667

Epoch: 6| Step: 13
Training loss: 1.8815180337261113
Validation loss: 2.5013535173414474

Epoch: 66| Step: 0
Training loss: 1.6044230896088385
Validation loss: 2.466064569946403

Epoch: 6| Step: 1
Training loss: 1.7573720422561536
Validation loss: 2.483301030552682

Epoch: 6| Step: 2
Training loss: 1.6465364314455708
Validation loss: 2.5255004198084943

Epoch: 6| Step: 3
Training loss: 1.4425775994331649
Validation loss: 2.515255744955073

Epoch: 6| Step: 4
Training loss: 1.2559485040483018
Validation loss: 2.455003169252586

Epoch: 6| Step: 5
Training loss: 1.7646546524689948
Validation loss: 2.467132714637484

Epoch: 6| Step: 6
Training loss: 2.2258324212525027
Validation loss: 2.4368252676198563

Epoch: 6| Step: 7
Training loss: 1.715939460660182
Validation loss: 2.4238450600244823

Epoch: 6| Step: 8
Training loss: 1.5239951653591575
Validation loss: 2.4356653204583942

Epoch: 6| Step: 9
Training loss: 1.8651009876430433
Validation loss: 2.457234401016745

Epoch: 6| Step: 10
Training loss: 1.6074894349743258
Validation loss: 2.444845087881521

Epoch: 6| Step: 11
Training loss: 1.679533485626172
Validation loss: 2.4405180350425772

Epoch: 6| Step: 12
Training loss: 1.9065912910492213
Validation loss: 2.4556692742453445

Epoch: 6| Step: 13
Training loss: 2.1021332940578072
Validation loss: 2.4333542184935006

Epoch: 67| Step: 0
Training loss: 1.0692912331908384
Validation loss: 2.430355041649548

Epoch: 6| Step: 1
Training loss: 1.2181210973764205
Validation loss: 2.5371151934589546

Epoch: 6| Step: 2
Training loss: 1.9179228798534067
Validation loss: 2.5484147049574166

Epoch: 6| Step: 3
Training loss: 2.3121014844473295
Validation loss: 2.5645353406252442

Epoch: 6| Step: 4
Training loss: 1.5154439287073305
Validation loss: 2.498118312312325

Epoch: 6| Step: 5
Training loss: 1.540673743786494
Validation loss: 2.4529795674425436

Epoch: 6| Step: 6
Training loss: 1.7552250786802253
Validation loss: 2.4478156102741595

Epoch: 6| Step: 7
Training loss: 1.5115609493251605
Validation loss: 2.437458298807363

Epoch: 6| Step: 8
Training loss: 2.0579990635490697
Validation loss: 2.4413896158287494

Epoch: 6| Step: 9
Training loss: 1.7006502282382356
Validation loss: 2.443089084733716

Epoch: 6| Step: 10
Training loss: 1.9662945284836528
Validation loss: 2.413323174998821

Epoch: 6| Step: 11
Training loss: 1.4731165320922215
Validation loss: 2.442603677705146

Epoch: 6| Step: 12
Training loss: 1.708442645723706
Validation loss: 2.4714497479739825

Epoch: 6| Step: 13
Training loss: 1.8820990639294446
Validation loss: 2.4521583304743064

Epoch: 68| Step: 0
Training loss: 1.4754211212553474
Validation loss: 2.4843799023209994

Epoch: 6| Step: 1
Training loss: 1.3586659829590648
Validation loss: 2.4876479496240456

Epoch: 6| Step: 2
Training loss: 1.5296469880799588
Validation loss: 2.475935277925408

Epoch: 6| Step: 3
Training loss: 2.131672425231234
Validation loss: 2.5159842193211723

Epoch: 6| Step: 4
Training loss: 1.2489068973863637
Validation loss: 2.5063103983285018

Epoch: 6| Step: 5
Training loss: 1.6906599904950415
Validation loss: 2.5108398671724084

Epoch: 6| Step: 6
Training loss: 1.463557785144527
Validation loss: 2.531360074385353

Epoch: 6| Step: 7
Training loss: 1.6955417179250178
Validation loss: 2.505469442759395

Epoch: 6| Step: 8
Training loss: 1.324355846948823
Validation loss: 2.4965323717985535

Epoch: 6| Step: 9
Training loss: 1.911201113268375
Validation loss: 2.460412662792474

Epoch: 6| Step: 10
Training loss: 1.3996488982403184
Validation loss: 2.473646081325858

Epoch: 6| Step: 11
Training loss: 2.0148623894209803
Validation loss: 2.449225937276594

Epoch: 6| Step: 12
Training loss: 1.7234888810965825
Validation loss: 2.4227133007645407

Epoch: 6| Step: 13
Training loss: 1.5819161078855273
Validation loss: 2.4220008489253946

Epoch: 69| Step: 0
Training loss: 1.3045505748783626
Validation loss: 2.431591967972964

Epoch: 6| Step: 1
Training loss: 1.6820897157308756
Validation loss: 2.4958445823131474

Epoch: 6| Step: 2
Training loss: 1.6820035358985994
Validation loss: 2.4290352341399952

Epoch: 6| Step: 3
Training loss: 1.9123968857038298
Validation loss: 2.46549456065603

Epoch: 6| Step: 4
Training loss: 2.056876637247478
Validation loss: 2.443431467953919

Epoch: 6| Step: 5
Training loss: 1.889816552700155
Validation loss: 2.418111818484231

Epoch: 6| Step: 6
Training loss: 1.7178143815739337
Validation loss: 2.4880003957778762

Epoch: 6| Step: 7
Training loss: 1.48310637220025
Validation loss: 2.4985090101170067

Epoch: 6| Step: 8
Training loss: 1.7251224640207838
Validation loss: 2.4678113416430967

Epoch: 6| Step: 9
Training loss: 2.055878384759751
Validation loss: 2.5281064878838277

Epoch: 6| Step: 10
Training loss: 1.2407660358506434
Validation loss: 2.489247639953173

Epoch: 6| Step: 11
Training loss: 1.6865702292926261
Validation loss: 2.4763385338500368

Epoch: 6| Step: 12
Training loss: 1.4407481937321003
Validation loss: 2.4829099962102537

Epoch: 6| Step: 13
Training loss: 1.0328494297644837
Validation loss: 2.451561285650351

Epoch: 70| Step: 0
Training loss: 1.4742202346381883
Validation loss: 2.4349277813833345

Epoch: 6| Step: 1
Training loss: 1.5520437180073896
Validation loss: 2.487644115982507

Epoch: 6| Step: 2
Training loss: 1.8363503499198504
Validation loss: 2.4624621638507267

Epoch: 6| Step: 3
Training loss: 1.265557840708239
Validation loss: 2.4587276406524796

Epoch: 6| Step: 4
Training loss: 1.6184625436657543
Validation loss: 2.4831308652493447

Epoch: 6| Step: 5
Training loss: 2.358409759936589
Validation loss: 2.455112729148614

Epoch: 6| Step: 6
Training loss: 1.4067303155145867
Validation loss: 2.4750065694265806

Epoch: 6| Step: 7
Training loss: 1.9816978598220494
Validation loss: 2.493344635232344

Epoch: 6| Step: 8
Training loss: 1.556165136758091
Validation loss: 2.5151352178526794

Epoch: 6| Step: 9
Training loss: 1.2324772987054735
Validation loss: 2.5300954061419305

Epoch: 6| Step: 10
Training loss: 1.9936456467634887
Validation loss: 2.584707568848694

Epoch: 6| Step: 11
Training loss: 1.4783731490188357
Validation loss: 2.5960342582554277

Epoch: 6| Step: 12
Training loss: 1.0512070484436022
Validation loss: 2.563466238818498

Epoch: 6| Step: 13
Training loss: 1.2314120597494167
Validation loss: 2.596327531244956

Epoch: 71| Step: 0
Training loss: 1.609963911137767
Validation loss: 2.568705093845169

Epoch: 6| Step: 1
Training loss: 1.4532208975045637
Validation loss: 2.5214998504297728

Epoch: 6| Step: 2
Training loss: 1.8626734224008987
Validation loss: 2.466354447228502

Epoch: 6| Step: 3
Training loss: 1.424301843107756
Validation loss: 2.448225891927386

Epoch: 6| Step: 4
Training loss: 1.307014263656059
Validation loss: 2.4510085174311906

Epoch: 6| Step: 5
Training loss: 1.7667218067753057
Validation loss: 2.402131242321179

Epoch: 6| Step: 6
Training loss: 1.7483880930065527
Validation loss: 2.49461152787526

Epoch: 6| Step: 7
Training loss: 1.7716894062672677
Validation loss: 2.4682474147886513

Epoch: 6| Step: 8
Training loss: 1.409922403405332
Validation loss: 2.464819874272529

Epoch: 6| Step: 9
Training loss: 1.8925607402936064
Validation loss: 2.5141990837896007

Epoch: 6| Step: 10
Training loss: 2.102452653313227
Validation loss: 2.4876208264831976

Epoch: 6| Step: 11
Training loss: 1.3010665534850996
Validation loss: 2.564378639024605

Epoch: 6| Step: 12
Training loss: 1.141035763707452
Validation loss: 2.580179447838364

Epoch: 6| Step: 13
Training loss: 1.854571316172395
Validation loss: 2.576255243633227

Epoch: 72| Step: 0
Training loss: 1.7827621198752266
Validation loss: 2.582005102936075

Epoch: 6| Step: 1
Training loss: 1.4635546085242492
Validation loss: 2.493108493510894

Epoch: 6| Step: 2
Training loss: 1.858065424482767
Validation loss: 2.503288490394944

Epoch: 6| Step: 3
Training loss: 1.305493180270665
Validation loss: 2.493558349192359

Epoch: 6| Step: 4
Training loss: 1.8322969093558594
Validation loss: 2.4639695315500187

Epoch: 6| Step: 5
Training loss: 1.2625260265424803
Validation loss: 2.484677278375069

Epoch: 6| Step: 6
Training loss: 1.781310498732747
Validation loss: 2.4469200107401905

Epoch: 6| Step: 7
Training loss: 1.3734803037949688
Validation loss: 2.469394213486569

Epoch: 6| Step: 8
Training loss: 1.3061627938396214
Validation loss: 2.4938381074336515

Epoch: 6| Step: 9
Training loss: 1.687407597025252
Validation loss: 2.4958685911189953

Epoch: 6| Step: 10
Training loss: 1.5087429990187238
Validation loss: 2.5112999724673633

Epoch: 6| Step: 11
Training loss: 1.1459369554770626
Validation loss: 2.521293902817916

Epoch: 6| Step: 12
Training loss: 1.4794705933861396
Validation loss: 2.5662837587153087

Epoch: 6| Step: 13
Training loss: 2.1610787544781056
Validation loss: 2.5155151374789586

Epoch: 73| Step: 0
Training loss: 1.7310371240505815
Validation loss: 2.545583885279811

Epoch: 6| Step: 1
Training loss: 1.784863203774722
Validation loss: 2.5211456646542434

Epoch: 6| Step: 2
Training loss: 1.5232158793126582
Validation loss: 2.4516822962345928

Epoch: 6| Step: 3
Training loss: 1.3938356689673181
Validation loss: 2.441283859236886

Epoch: 6| Step: 4
Training loss: 1.240970038950676
Validation loss: 2.4544459064817565

Epoch: 6| Step: 5
Training loss: 1.714281133236895
Validation loss: 2.4502214065729304

Epoch: 6| Step: 6
Training loss: 2.162093495876649
Validation loss: 2.4727228928072873

Epoch: 6| Step: 7
Training loss: 1.2971646548441869
Validation loss: 2.458446267060919

Epoch: 6| Step: 8
Training loss: 1.752664989154797
Validation loss: 2.489258530842261

Epoch: 6| Step: 9
Training loss: 1.4830012339035734
Validation loss: 2.5287234722964183

Epoch: 6| Step: 10
Training loss: 1.26964969962746
Validation loss: 2.4950057052720354

Epoch: 6| Step: 11
Training loss: 1.4787671619751155
Validation loss: 2.5832646627425646

Epoch: 6| Step: 12
Training loss: 1.4835572248786852
Validation loss: 2.5390927982967915

Epoch: 6| Step: 13
Training loss: 1.6038636586089523
Validation loss: 2.5135785263105435

Epoch: 74| Step: 0
Training loss: 1.1784786068087671
Validation loss: 2.481816443831083

Epoch: 6| Step: 1
Training loss: 1.5432695699143375
Validation loss: 2.4328301927482188

Epoch: 6| Step: 2
Training loss: 1.3077063441062644
Validation loss: 2.430381814711247

Epoch: 6| Step: 3
Training loss: 1.4462535372124543
Validation loss: 2.4927830158995996

Epoch: 6| Step: 4
Training loss: 1.6426041064662642
Validation loss: 2.4406845775826826

Epoch: 6| Step: 5
Training loss: 1.4759504068825144
Validation loss: 2.460663924577512

Epoch: 6| Step: 6
Training loss: 2.286260354428962
Validation loss: 2.4991569210098636

Epoch: 6| Step: 7
Training loss: 2.020023131096472
Validation loss: 2.5683549501407543

Epoch: 6| Step: 8
Training loss: 1.2343167158442407
Validation loss: 2.486243754731152

Epoch: 6| Step: 9
Training loss: 1.2294680446832844
Validation loss: 2.538477488882983

Epoch: 6| Step: 10
Training loss: 1.6454031981767607
Validation loss: 2.519108053146577

Epoch: 6| Step: 11
Training loss: 1.4773730117264183
Validation loss: 2.5141115078319154

Epoch: 6| Step: 12
Training loss: 1.200040355639582
Validation loss: 2.492866112805724

Epoch: 6| Step: 13
Training loss: 1.50364353808272
Validation loss: 2.522420341587407

Epoch: 75| Step: 0
Training loss: 1.6927676459460173
Validation loss: 2.4545291194736136

Epoch: 6| Step: 1
Training loss: 1.3021626054156958
Validation loss: 2.4750298090465797

Epoch: 6| Step: 2
Training loss: 1.4332763985851475
Validation loss: 2.446937078254429

Epoch: 6| Step: 3
Training loss: 1.255468091032832
Validation loss: 2.4457717967916395

Epoch: 6| Step: 4
Training loss: 1.6162202310438993
Validation loss: 2.467298902106784

Epoch: 6| Step: 5
Training loss: 2.058712342409464
Validation loss: 2.4408002503109776

Epoch: 6| Step: 6
Training loss: 1.254828710911219
Validation loss: 2.4676686586599295

Epoch: 6| Step: 7
Training loss: 0.8258727774517257
Validation loss: 2.5461985698082175

Epoch: 6| Step: 8
Training loss: 1.4606944815318792
Validation loss: 2.597970447325214

Epoch: 6| Step: 9
Training loss: 1.4514257688972656
Validation loss: 2.6256399131568706

Epoch: 6| Step: 10
Training loss: 2.2365849376628035
Validation loss: 2.6317331608961654

Epoch: 6| Step: 11
Training loss: 1.7913187117884324
Validation loss: 2.5235421520219985

Epoch: 6| Step: 12
Training loss: 1.4196709958258498
Validation loss: 2.47220423837138

Epoch: 6| Step: 13
Training loss: 1.1406153848321188
Validation loss: 2.492935052602319

Epoch: 76| Step: 0
Training loss: 1.474319611431114
Validation loss: 2.4398862130049634

Epoch: 6| Step: 1
Training loss: 1.5859764357424182
Validation loss: 2.43754963131448

Epoch: 6| Step: 2
Training loss: 1.531044615381384
Validation loss: 2.4874417871663694

Epoch: 6| Step: 3
Training loss: 1.0686792874506197
Validation loss: 2.4631662922885647

Epoch: 6| Step: 4
Training loss: 1.744686506907546
Validation loss: 2.475612084967313

Epoch: 6| Step: 5
Training loss: 1.235314313605917
Validation loss: 2.4750053733227904

Epoch: 6| Step: 6
Training loss: 1.5885738015181645
Validation loss: 2.472320421342622

Epoch: 6| Step: 7
Training loss: 1.662119774612185
Validation loss: 2.4722376946764

Epoch: 6| Step: 8
Training loss: 1.7425201508986465
Validation loss: 2.514521070297882

Epoch: 6| Step: 9
Training loss: 1.1718957009076563
Validation loss: 2.5079046056199363

Epoch: 6| Step: 10
Training loss: 1.8338000902694895
Validation loss: 2.5352737564103878

Epoch: 6| Step: 11
Training loss: 1.1106546570398401
Validation loss: 2.520674051554282

Epoch: 6| Step: 12
Training loss: 1.2701298168246087
Validation loss: 2.556800660481127

Epoch: 6| Step: 13
Training loss: 1.4475697803972225
Validation loss: 2.531921548810197

Epoch: 77| Step: 0
Training loss: 1.7793217980725666
Validation loss: 2.544380667172665

Epoch: 6| Step: 1
Training loss: 1.5028740052733358
Validation loss: 2.4752100993417883

Epoch: 6| Step: 2
Training loss: 1.3958702604429083
Validation loss: 2.456637595076716

Epoch: 6| Step: 3
Training loss: 1.2520780932443216
Validation loss: 2.4470000045499916

Epoch: 6| Step: 4
Training loss: 1.524982314710785
Validation loss: 2.4705586628653315

Epoch: 6| Step: 5
Training loss: 1.269209319157956
Validation loss: 2.4476579461780283

Epoch: 6| Step: 6
Training loss: 1.3152728989128082
Validation loss: 2.466164373685972

Epoch: 6| Step: 7
Training loss: 1.3604596951482255
Validation loss: 2.4718582930806066

Epoch: 6| Step: 8
Training loss: 1.6647883878155338
Validation loss: 2.554026752537432

Epoch: 6| Step: 9
Training loss: 2.1628970095964104
Validation loss: 2.544970199895136

Epoch: 6| Step: 10
Training loss: 1.6856509073803283
Validation loss: 2.5627610686137614

Epoch: 6| Step: 11
Training loss: 0.9642261891687742
Validation loss: 2.4993695576799237

Epoch: 6| Step: 12
Training loss: 1.1020891269947395
Validation loss: 2.4604469415889194

Epoch: 6| Step: 13
Training loss: 1.6091595848134432
Validation loss: 2.4355077671560736

Epoch: 78| Step: 0
Training loss: 1.571683598235356
Validation loss: 2.5122713753603927

Epoch: 6| Step: 1
Training loss: 1.5843229296552892
Validation loss: 2.4815132885434346

Epoch: 6| Step: 2
Training loss: 1.3670069984083877
Validation loss: 2.46387400142994

Epoch: 6| Step: 3
Training loss: 1.8498418353747734
Validation loss: 2.471988814892921

Epoch: 6| Step: 4
Training loss: 2.0538877373895272
Validation loss: 2.4785686754782263

Epoch: 6| Step: 5
Training loss: 1.1998625775963978
Validation loss: 2.4648239691132527

Epoch: 6| Step: 6
Training loss: 0.9426685591819881
Validation loss: 2.5287491331729104

Epoch: 6| Step: 7
Training loss: 0.9087425352836783
Validation loss: 2.5523626265515236

Epoch: 6| Step: 8
Training loss: 1.340965802105817
Validation loss: 2.571587058133283

Epoch: 6| Step: 9
Training loss: 0.9932028613768682
Validation loss: 2.581934786181084

Epoch: 6| Step: 10
Training loss: 1.136744757810292
Validation loss: 2.5694958627269995

Epoch: 6| Step: 11
Training loss: 1.4372049941167528
Validation loss: 2.596653573166821

Epoch: 6| Step: 12
Training loss: 1.6689084552871396
Validation loss: 2.4864056523440463

Epoch: 6| Step: 13
Training loss: 1.361074503365241
Validation loss: 2.4772416556421804

Epoch: 79| Step: 0
Training loss: 1.244736269858095
Validation loss: 2.4592316866476525

Epoch: 6| Step: 1
Training loss: 1.2359375540134114
Validation loss: 2.4275933631624387

Epoch: 6| Step: 2
Training loss: 1.3866860399283663
Validation loss: 2.4614688683110972

Epoch: 6| Step: 3
Training loss: 1.5586405582139433
Validation loss: 2.4748727065723966

Epoch: 6| Step: 4
Training loss: 1.6929918570145222
Validation loss: 2.4722535426647783

Epoch: 6| Step: 5
Training loss: 1.3477427579231964
Validation loss: 2.518190296166336

Epoch: 6| Step: 6
Training loss: 1.4822364258899818
Validation loss: 2.5529820371434924

Epoch: 6| Step: 7
Training loss: 1.6737615333940363
Validation loss: 2.5590470317758642

Epoch: 6| Step: 8
Training loss: 1.6110549602735385
Validation loss: 2.58615378774724

Epoch: 6| Step: 9
Training loss: 1.1578949748328753
Validation loss: 2.5411192638032176

Epoch: 6| Step: 10
Training loss: 1.7424637784983257
Validation loss: 2.4393988980735237

Epoch: 6| Step: 11
Training loss: 1.361184330136492
Validation loss: 2.4854633018891343

Epoch: 6| Step: 12
Training loss: 1.096151386031712
Validation loss: 2.467067942219921

Epoch: 6| Step: 13
Training loss: 1.2629050237776975
Validation loss: 2.4834505196471635

Epoch: 80| Step: 0
Training loss: 1.0365694583892724
Validation loss: 2.4914461506084438

Epoch: 6| Step: 1
Training loss: 1.088909938640152
Validation loss: 2.5065976742835647

Epoch: 6| Step: 2
Training loss: 0.9920910165086828
Validation loss: 2.4938403620716993

Epoch: 6| Step: 3
Training loss: 1.3183945488652709
Validation loss: 2.538467431395033

Epoch: 6| Step: 4
Training loss: 1.1477512722785228
Validation loss: 2.505934331837767

Epoch: 6| Step: 5
Training loss: 0.9303378547183634
Validation loss: 2.5103236981875074

Epoch: 6| Step: 6
Training loss: 1.6123318961589708
Validation loss: 2.5301620280233736

Epoch: 6| Step: 7
Training loss: 1.5969326180591008
Validation loss: 2.5545659789756536

Epoch: 6| Step: 8
Training loss: 1.8563394210290003
Validation loss: 2.515028414859615

Epoch: 6| Step: 9
Training loss: 1.059358609053029
Validation loss: 2.494050512475825

Epoch: 6| Step: 10
Training loss: 1.2155843850536578
Validation loss: 2.512376350156368

Epoch: 6| Step: 11
Training loss: 1.237467405101878
Validation loss: 2.4824287180352305

Epoch: 6| Step: 12
Training loss: 1.2129217810322583
Validation loss: 2.4970677345569894

Epoch: 6| Step: 13
Training loss: 2.155948894319671
Validation loss: 2.508189837469022

Epoch: 81| Step: 0
Training loss: 0.8107634473350642
Validation loss: 2.4635421129243755

Epoch: 6| Step: 1
Training loss: 1.0365949888890984
Validation loss: 2.563394956228346

Epoch: 6| Step: 2
Training loss: 1.1381442121699354
Validation loss: 2.5457504223580916

Epoch: 6| Step: 3
Training loss: 1.1239750749804223
Validation loss: 2.560459627226141

Epoch: 6| Step: 4
Training loss: 1.2400190031225988
Validation loss: 2.512821949943918

Epoch: 6| Step: 5
Training loss: 1.4711441655365514
Validation loss: 2.5220114316910625

Epoch: 6| Step: 6
Training loss: 1.1679628301872345
Validation loss: 2.504851568967856

Epoch: 6| Step: 7
Training loss: 1.5349248270023974
Validation loss: 2.4897898078966634

Epoch: 6| Step: 8
Training loss: 1.4401675642061007
Validation loss: 2.5304054766622737

Epoch: 6| Step: 9
Training loss: 0.9086365352669313
Validation loss: 2.5343939012605805

Epoch: 6| Step: 10
Training loss: 1.304586440872265
Validation loss: 2.5307645763979942

Epoch: 6| Step: 11
Training loss: 1.5491130321480255
Validation loss: 2.5118720767701888

Epoch: 6| Step: 12
Training loss: 2.3788537331282402
Validation loss: 2.501181323373045

Epoch: 6| Step: 13
Training loss: 0.9186029394358144
Validation loss: 2.5191198047549097

Epoch: 82| Step: 0
Training loss: 1.38547677313651
Validation loss: 2.5688012346168705

Epoch: 6| Step: 1
Training loss: 1.2133977692824534
Validation loss: 2.5024913454112556

Epoch: 6| Step: 2
Training loss: 1.430362562887401
Validation loss: 2.479281500285902

Epoch: 6| Step: 3
Training loss: 1.0425762338002997
Validation loss: 2.508748039443779

Epoch: 6| Step: 4
Training loss: 1.1901765574580387
Validation loss: 2.506501834739096

Epoch: 6| Step: 5
Training loss: 1.150956278722083
Validation loss: 2.4517973933796586

Epoch: 6| Step: 6
Training loss: 1.191303286246272
Validation loss: 2.475908042523521

Epoch: 6| Step: 7
Training loss: 1.6555252648824736
Validation loss: 2.4919358049648626

Epoch: 6| Step: 8
Training loss: 1.471802319718534
Validation loss: 2.536317752229611

Epoch: 6| Step: 9
Training loss: 1.3139749141719723
Validation loss: 2.584556648854204

Epoch: 6| Step: 10
Training loss: 1.73367927962599
Validation loss: 2.6808427001873283

Epoch: 6| Step: 11
Training loss: 1.3582694282399064
Validation loss: 2.596692947328973

Epoch: 6| Step: 12
Training loss: 1.291775616798786
Validation loss: 2.544836269762793

Epoch: 6| Step: 13
Training loss: 1.387804406942827
Validation loss: 2.514489504041477

Epoch: 83| Step: 0
Training loss: 2.1266131168706814
Validation loss: 2.4740548098307586

Epoch: 6| Step: 1
Training loss: 1.4306217330555342
Validation loss: 2.460128182842353

Epoch: 6| Step: 2
Training loss: 1.4572665354388876
Validation loss: 2.470768662539665

Epoch: 6| Step: 3
Training loss: 1.4158952332980097
Validation loss: 2.492489946881385

Epoch: 6| Step: 4
Training loss: 0.9079653520968561
Validation loss: 2.4445621204469066

Epoch: 6| Step: 5
Training loss: 0.9076248132505594
Validation loss: 2.488200978372181

Epoch: 6| Step: 6
Training loss: 0.99490321201393
Validation loss: 2.510195074682505

Epoch: 6| Step: 7
Training loss: 1.4822785681411428
Validation loss: 2.537679121275597

Epoch: 6| Step: 8
Training loss: 0.9370752007954328
Validation loss: 2.622824494002548

Epoch: 6| Step: 9
Training loss: 1.3342253214666135
Validation loss: 2.738487812691413

Epoch: 6| Step: 10
Training loss: 1.0198983302589242
Validation loss: 2.6639482729112185

Epoch: 6| Step: 11
Training loss: 1.7783917701269931
Validation loss: 2.6009510837762284

Epoch: 6| Step: 12
Training loss: 1.2845455214265964
Validation loss: 2.5623050863678243

Epoch: 6| Step: 13
Training loss: 1.2730009114576075
Validation loss: 2.5512614010037917

Epoch: 84| Step: 0
Training loss: 1.1223504336823409
Validation loss: 2.5073478799141196

Epoch: 6| Step: 1
Training loss: 1.1279279964814164
Validation loss: 2.515668232864183

Epoch: 6| Step: 2
Training loss: 1.3888825633646713
Validation loss: 2.4982610058467776

Epoch: 6| Step: 3
Training loss: 1.2883009076859748
Validation loss: 2.5182115514087204

Epoch: 6| Step: 4
Training loss: 1.0241166984177874
Validation loss: 2.50665457703164

Epoch: 6| Step: 5
Training loss: 0.9558965378783297
Validation loss: 2.4917747610198964

Epoch: 6| Step: 6
Training loss: 0.9524343208136268
Validation loss: 2.4974910226023495

Epoch: 6| Step: 7
Training loss: 1.297941160302579
Validation loss: 2.507389789579456

Epoch: 6| Step: 8
Training loss: 1.1756540527485455
Validation loss: 2.558020661990658

Epoch: 6| Step: 9
Training loss: 1.8900877133961416
Validation loss: 2.574373077567206

Epoch: 6| Step: 10
Training loss: 1.6804302613742366
Validation loss: 2.590562401396024

Epoch: 6| Step: 11
Training loss: 0.938583891861115
Validation loss: 2.5576559663201817

Epoch: 6| Step: 12
Training loss: 1.0118093560492962
Validation loss: 2.564122841400273

Epoch: 6| Step: 13
Training loss: 1.6830966153533105
Validation loss: 2.517066984569253

Epoch: 85| Step: 0
Training loss: 1.507913694790753
Validation loss: 2.546373298392647

Epoch: 6| Step: 1
Training loss: 1.054766447150151
Validation loss: 2.5373997961344554

Epoch: 6| Step: 2
Training loss: 1.550208151592211
Validation loss: 2.525030438393917

Epoch: 6| Step: 3
Training loss: 1.8931104228383198
Validation loss: 2.53808952273558

Epoch: 6| Step: 4
Training loss: 1.245046528325963
Validation loss: 2.468975266106238

Epoch: 6| Step: 5
Training loss: 0.8942199565180095
Validation loss: 2.5562078713425223

Epoch: 6| Step: 6
Training loss: 1.3899393856087767
Validation loss: 2.4839294961833116

Epoch: 6| Step: 7
Training loss: 1.4659488019342892
Validation loss: 2.510435038350313

Epoch: 6| Step: 8
Training loss: 0.6077621095848277
Validation loss: 2.4608538497352037

Epoch: 6| Step: 9
Training loss: 1.2331437839444346
Validation loss: 2.5935090807207923

Epoch: 6| Step: 10
Training loss: 1.0536026072564737
Validation loss: 2.5363508406675037

Epoch: 6| Step: 11
Training loss: 1.400087970285862
Validation loss: 2.565318008003668

Epoch: 6| Step: 12
Training loss: 1.0365716434566559
Validation loss: 2.5500167783796046

Epoch: 6| Step: 13
Training loss: 1.188920626904958
Validation loss: 2.4943840686719585

Epoch: 86| Step: 0
Training loss: 1.4965398934983427
Validation loss: 2.5254707451561353

Epoch: 6| Step: 1
Training loss: 0.7372334629039694
Validation loss: 2.4854491528809843

Epoch: 6| Step: 2
Training loss: 1.07737750248807
Validation loss: 2.5363337011612335

Epoch: 6| Step: 3
Training loss: 1.3695946129842236
Validation loss: 2.5461459062136154

Epoch: 6| Step: 4
Training loss: 1.2677593836330827
Validation loss: 2.5309410691611953

Epoch: 6| Step: 5
Training loss: 0.8433813066621313
Validation loss: 2.490895836438275

Epoch: 6| Step: 6
Training loss: 0.7876790827018639
Validation loss: 2.578491331333819

Epoch: 6| Step: 7
Training loss: 1.40224522321557
Validation loss: 2.656359516952829

Epoch: 6| Step: 8
Training loss: 1.5344508445625302
Validation loss: 2.611850287825705

Epoch: 6| Step: 9
Training loss: 0.9885470669876586
Validation loss: 2.6659712828510607

Epoch: 6| Step: 10
Training loss: 1.2724014467398446
Validation loss: 2.5510479727735

Epoch: 6| Step: 11
Training loss: 1.1939709683567723
Validation loss: 2.490889144285809

Epoch: 6| Step: 12
Training loss: 1.4981722822752828
Validation loss: 2.529709633786731

Epoch: 6| Step: 13
Training loss: 1.8382575127997896
Validation loss: 2.502511447825687

Epoch: 87| Step: 0
Training loss: 1.5601816907860957
Validation loss: 2.472125518231433

Epoch: 6| Step: 1
Training loss: 1.2289121924739856
Validation loss: 2.5065372508540595

Epoch: 6| Step: 2
Training loss: 0.9295443576921587
Validation loss: 2.501162370032884

Epoch: 6| Step: 3
Training loss: 1.4201244435382723
Validation loss: 2.4853020703697144

Epoch: 6| Step: 4
Training loss: 1.8112108315602256
Validation loss: 2.5042260769626803

Epoch: 6| Step: 5
Training loss: 1.4321724396991067
Validation loss: 2.573854921415374

Epoch: 6| Step: 6
Training loss: 0.9761234669858345
Validation loss: 2.5313181141923353

Epoch: 6| Step: 7
Training loss: 1.4568828271944427
Validation loss: 2.5621591822059693

Epoch: 6| Step: 8
Training loss: 1.2567691147949678
Validation loss: 2.573441785180748

Epoch: 6| Step: 9
Training loss: 0.9745350964207145
Validation loss: 2.513846864811558

Epoch: 6| Step: 10
Training loss: 0.9821636247297023
Validation loss: 2.483441767362688

Epoch: 6| Step: 11
Training loss: 1.1808463966294944
Validation loss: 2.4846069419601116

Epoch: 6| Step: 12
Training loss: 0.891570275584001
Validation loss: 2.5140491707311945

Epoch: 6| Step: 13
Training loss: 0.796764740141155
Validation loss: 2.6102738345668945

Epoch: 88| Step: 0
Training loss: 1.047886544787538
Validation loss: 2.615374112449748

Epoch: 6| Step: 1
Training loss: 0.9039319086678003
Validation loss: 2.5608718165410767

Epoch: 6| Step: 2
Training loss: 1.2342345725229813
Validation loss: 2.566671635470184

Epoch: 6| Step: 3
Training loss: 1.2886070140323869
Validation loss: 2.6178066451260826

Epoch: 6| Step: 4
Training loss: 1.2482451041194558
Validation loss: 2.582155594979308

Epoch: 6| Step: 5
Training loss: 0.9269916331912559
Validation loss: 2.526510251554206

Epoch: 6| Step: 6
Training loss: 1.1965075234998772
Validation loss: 2.5148212104380616

Epoch: 6| Step: 7
Training loss: 1.4183858462936185
Validation loss: 2.466360086213022

Epoch: 6| Step: 8
Training loss: 1.4445314513598848
Validation loss: 2.484081090980009

Epoch: 6| Step: 9
Training loss: 1.351360019224308
Validation loss: 2.5250359463414913

Epoch: 6| Step: 10
Training loss: 0.8721880347408458
Validation loss: 2.4856858064322913

Epoch: 6| Step: 11
Training loss: 1.2633180196550253
Validation loss: 2.4874271701649473

Epoch: 6| Step: 12
Training loss: 1.7479353032655
Validation loss: 2.5094261800789

Epoch: 6| Step: 13
Training loss: 0.9369203046821777
Validation loss: 2.5340046120832223

Epoch: 89| Step: 0
Training loss: 1.1108516482889268
Validation loss: 2.59036326388059

Epoch: 6| Step: 1
Training loss: 1.1942935664723207
Validation loss: 2.6324434861326638

Epoch: 6| Step: 2
Training loss: 0.9957269928362369
Validation loss: 2.6109744440885887

Epoch: 6| Step: 3
Training loss: 1.0786196914420205
Validation loss: 2.584303325134271

Epoch: 6| Step: 4
Training loss: 1.5910742494387786
Validation loss: 2.5095645096645205

Epoch: 6| Step: 5
Training loss: 0.9658362962964228
Validation loss: 2.5600970562030585

Epoch: 6| Step: 6
Training loss: 1.1481383057198637
Validation loss: 2.5301867477189344

Epoch: 6| Step: 7
Training loss: 1.2781066482830672
Validation loss: 2.492675000127408

Epoch: 6| Step: 8
Training loss: 1.895693833245632
Validation loss: 2.539961263581511

Epoch: 6| Step: 9
Training loss: 0.8088464756632943
Validation loss: 2.566051688976206

Epoch: 6| Step: 10
Training loss: 1.2181827496637643
Validation loss: 2.5383061617647034

Epoch: 6| Step: 11
Training loss: 0.9200159498573617
Validation loss: 2.565274248761573

Epoch: 6| Step: 12
Training loss: 1.0319099048831537
Validation loss: 2.530537728773635

Epoch: 6| Step: 13
Training loss: 0.9835582554043186
Validation loss: 2.551470505192284

Epoch: 90| Step: 0
Training loss: 1.1927803495340192
Validation loss: 2.4998011192051712

Epoch: 6| Step: 1
Training loss: 0.8377647038520933
Validation loss: 2.526792730513923

Epoch: 6| Step: 2
Training loss: 1.1164537701326938
Validation loss: 2.527101956199549

Epoch: 6| Step: 3
Training loss: 2.053066644173116
Validation loss: 2.5318103845004205

Epoch: 6| Step: 4
Training loss: 1.00748538837297
Validation loss: 2.488309308127922

Epoch: 6| Step: 5
Training loss: 1.1000035936123496
Validation loss: 2.538548860681917

Epoch: 6| Step: 6
Training loss: 1.2379574517809746
Validation loss: 2.5765405274968174

Epoch: 6| Step: 7
Training loss: 0.6954088894329363
Validation loss: 2.658375715996117

Epoch: 6| Step: 8
Training loss: 0.949286909756671
Validation loss: 2.6026333122054113

Epoch: 6| Step: 9
Training loss: 1.3645675405893987
Validation loss: 2.580638053715055

Epoch: 6| Step: 10
Training loss: 0.9708222713304114
Validation loss: 2.568081027227213

Epoch: 6| Step: 11
Training loss: 0.46732378792991014
Validation loss: 2.5283206268306424

Epoch: 6| Step: 12
Training loss: 1.5132144753726
Validation loss: 2.516378151753422

Epoch: 6| Step: 13
Training loss: 1.0540485848696668
Validation loss: 2.5642958372738267

Epoch: 91| Step: 0
Training loss: 1.165805203414511
Validation loss: 2.504274623868986

Epoch: 6| Step: 1
Training loss: 1.0417306244606659
Validation loss: 2.482759202177429

Epoch: 6| Step: 2
Training loss: 0.9863623282667994
Validation loss: 2.4893777089348044

Epoch: 6| Step: 3
Training loss: 1.040655535458994
Validation loss: 2.4875862592249045

Epoch: 6| Step: 4
Training loss: 0.7526415955279226
Validation loss: 2.519600516853092

Epoch: 6| Step: 5
Training loss: 1.3135527975088255
Validation loss: 2.532988685035458

Epoch: 6| Step: 6
Training loss: 1.0052006314366366
Validation loss: 2.5483356180257726

Epoch: 6| Step: 7
Training loss: 0.9322836394292963
Validation loss: 2.5231662128072716

Epoch: 6| Step: 8
Training loss: 2.222751715944645
Validation loss: 2.5109599516204484

Epoch: 6| Step: 9
Training loss: 1.1130316203476327
Validation loss: 2.5635322569594714

Epoch: 6| Step: 10
Training loss: 0.9877845812831313
Validation loss: 2.56831208585614

Epoch: 6| Step: 11
Training loss: 1.1016802352862252
Validation loss: 2.5696631387196547

Epoch: 6| Step: 12
Training loss: 0.7957814885440022
Validation loss: 2.5473650361417546

Epoch: 6| Step: 13
Training loss: 1.1517841596793565
Validation loss: 2.530847745102173

Epoch: 92| Step: 0
Training loss: 0.87959459264775
Validation loss: 2.596713797182772

Epoch: 6| Step: 1
Training loss: 0.9115574737399795
Validation loss: 2.561210431894361

Epoch: 6| Step: 2
Training loss: 0.893101778576077
Validation loss: 2.58000988115592

Epoch: 6| Step: 3
Training loss: 0.9369372904341329
Validation loss: 2.556686521409124

Epoch: 6| Step: 4
Training loss: 0.7903634479311351
Validation loss: 2.605770293805926

Epoch: 6| Step: 5
Training loss: 1.0341827997695734
Validation loss: 2.563192646107858

Epoch: 6| Step: 6
Training loss: 2.1734782277507056
Validation loss: 2.6026990086286586

Epoch: 6| Step: 7
Training loss: 0.8388853060061283
Validation loss: 2.553861229718439

Epoch: 6| Step: 8
Training loss: 1.0230737869783855
Validation loss: 2.549927191224698

Epoch: 6| Step: 9
Training loss: 1.2737578942650423
Validation loss: 2.4652765038237767

Epoch: 6| Step: 10
Training loss: 0.9337341011562874
Validation loss: 2.5040857783332533

Epoch: 6| Step: 11
Training loss: 1.45992680640497
Validation loss: 2.5183283652511794

Epoch: 6| Step: 12
Training loss: 1.1547062336766065
Validation loss: 2.48280139886204

Epoch: 6| Step: 13
Training loss: 1.0637560880780403
Validation loss: 2.478037903110199

Epoch: 93| Step: 0
Training loss: 0.9769692451278856
Validation loss: 2.5825547665318607

Epoch: 6| Step: 1
Training loss: 0.8294983757835522
Validation loss: 2.650784985320149

Epoch: 6| Step: 2
Training loss: 1.6154966498918428
Validation loss: 2.633387879116567

Epoch: 6| Step: 3
Training loss: 1.4968071175555375
Validation loss: 2.7135677641469678

Epoch: 6| Step: 4
Training loss: 1.2401041277880491
Validation loss: 2.6415558026593406

Epoch: 6| Step: 5
Training loss: 0.9189822182455312
Validation loss: 2.5290065446555015

Epoch: 6| Step: 6
Training loss: 1.1185469459091275
Validation loss: 2.5097628621879045

Epoch: 6| Step: 7
Training loss: 1.204671386135999
Validation loss: 2.45020807576368

Epoch: 6| Step: 8
Training loss: 1.0400719006149486
Validation loss: 2.5077871636272464

Epoch: 6| Step: 9
Training loss: 1.1473323149320998
Validation loss: 2.502499737315588

Epoch: 6| Step: 10
Training loss: 1.137766299673098
Validation loss: 2.5196610922464306

Epoch: 6| Step: 11
Training loss: 0.713123774615212
Validation loss: 2.569057664599468

Epoch: 6| Step: 12
Training loss: 1.3795109792523388
Validation loss: 2.530995171674838

Epoch: 6| Step: 13
Training loss: 1.028493781460891
Validation loss: 2.66942239966824

Epoch: 94| Step: 0
Training loss: 1.2205955519007454
Validation loss: 2.599661024322367

Epoch: 6| Step: 1
Training loss: 1.0083785722110565
Validation loss: 2.527601917726208

Epoch: 6| Step: 2
Training loss: 0.8349936317155318
Validation loss: 2.5158734722121756

Epoch: 6| Step: 3
Training loss: 0.7057882310050393
Validation loss: 2.5414773422352948

Epoch: 6| Step: 4
Training loss: 0.8907415748730927
Validation loss: 2.4680578653867045

Epoch: 6| Step: 5
Training loss: 0.7500623041341351
Validation loss: 2.5210324095837224

Epoch: 6| Step: 6
Training loss: 1.653609852637184
Validation loss: 2.477762374868068

Epoch: 6| Step: 7
Training loss: 0.8532845470208996
Validation loss: 2.530590693633128

Epoch: 6| Step: 8
Training loss: 0.8952654694725612
Validation loss: 2.5414945408639085

Epoch: 6| Step: 9
Training loss: 1.303600978143143
Validation loss: 2.610833862366325

Epoch: 6| Step: 10
Training loss: 0.7231894098608902
Validation loss: 2.5338512994345543

Epoch: 6| Step: 11
Training loss: 1.2862276289971308
Validation loss: 2.575608013183148

Epoch: 6| Step: 12
Training loss: 1.5600154960302843
Validation loss: 2.545353495449378

Epoch: 6| Step: 13
Training loss: 1.0549173175357645
Validation loss: 2.5175772884694028

Epoch: 95| Step: 0
Training loss: 1.0660829158692586
Validation loss: 2.537188154078681

Epoch: 6| Step: 1
Training loss: 0.8640209498426342
Validation loss: 2.483857234847086

Epoch: 6| Step: 2
Training loss: 0.8528494253583011
Validation loss: 2.5090883521210228

Epoch: 6| Step: 3
Training loss: 0.9461213741789923
Validation loss: 2.535099258134914

Epoch: 6| Step: 4
Training loss: 1.6945560015589434
Validation loss: 2.497804361024124

Epoch: 6| Step: 5
Training loss: 0.865122906326695
Validation loss: 2.507997500051807

Epoch: 6| Step: 6
Training loss: 1.354822273986055
Validation loss: 2.532967757734555

Epoch: 6| Step: 7
Training loss: 1.292759258897357
Validation loss: 2.634035952505893

Epoch: 6| Step: 8
Training loss: 1.3593797354780126
Validation loss: 2.546658653010331

Epoch: 6| Step: 9
Training loss: 1.0581074966812591
Validation loss: 2.556205197589114

Epoch: 6| Step: 10
Training loss: 1.0044746422612174
Validation loss: 2.5440106032688368

Epoch: 6| Step: 11
Training loss: 1.107884224747485
Validation loss: 2.6016904629538122

Epoch: 6| Step: 12
Training loss: 0.6938265019412752
Validation loss: 2.6141294538820268

Epoch: 6| Step: 13
Training loss: 1.1266389670061228
Validation loss: 2.5806910219783377

Epoch: 96| Step: 0
Training loss: 0.8020430137771861
Validation loss: 2.6073918525405624

Epoch: 6| Step: 1
Training loss: 1.1749359336593808
Validation loss: 2.649758946053557

Epoch: 6| Step: 2
Training loss: 1.2053838555337957
Validation loss: 2.5655536754759685

Epoch: 6| Step: 3
Training loss: 1.7707522729010552
Validation loss: 2.5495105205058723

Epoch: 6| Step: 4
Training loss: 0.9959234353859743
Validation loss: 2.5105303399610994

Epoch: 6| Step: 5
Training loss: 1.338386031823881
Validation loss: 2.519529247036712

Epoch: 6| Step: 6
Training loss: 0.9326159092759565
Validation loss: 2.609014977385465

Epoch: 6| Step: 7
Training loss: 1.0096418943173575
Validation loss: 2.508971599047641

Epoch: 6| Step: 8
Training loss: 0.7686790356019978
Validation loss: 2.588608744089261

Epoch: 6| Step: 9
Training loss: 1.2588424730474588
Validation loss: 2.60507740625732

Epoch: 6| Step: 10
Training loss: 0.924139893651072
Validation loss: 2.6331179750078513

Epoch: 6| Step: 11
Training loss: 0.8565890149226436
Validation loss: 2.549867467303404

Epoch: 6| Step: 12
Training loss: 0.9963940934302087
Validation loss: 2.5581099113381605

Epoch: 6| Step: 13
Training loss: 0.9527229336547786
Validation loss: 2.5556243905066482

Epoch: 97| Step: 0
Training loss: 1.0018380677191672
Validation loss: 2.5995402834466796

Epoch: 6| Step: 1
Training loss: 0.7054864646740592
Validation loss: 2.537522272347357

Epoch: 6| Step: 2
Training loss: 0.957507050241754
Validation loss: 2.586437879940612

Epoch: 6| Step: 3
Training loss: 1.1580757984594174
Validation loss: 2.4776231999308065

Epoch: 6| Step: 4
Training loss: 1.0917426080473145
Validation loss: 2.504320869098796

Epoch: 6| Step: 5
Training loss: 0.9944468927678871
Validation loss: 2.5750353708893354

Epoch: 6| Step: 6
Training loss: 1.259860107663892
Validation loss: 2.5725832013910113

Epoch: 6| Step: 7
Training loss: 0.8216555545383052
Validation loss: 2.7036276553934306

Epoch: 6| Step: 8
Training loss: 1.1633571561562022
Validation loss: 2.673473259370654

Epoch: 6| Step: 9
Training loss: 1.091614846220224
Validation loss: 2.6429441301471632

Epoch: 6| Step: 10
Training loss: 0.711184573994122
Validation loss: 2.543581449780942

Epoch: 6| Step: 11
Training loss: 1.3124348760524402
Validation loss: 2.5373644662625217

Epoch: 6| Step: 12
Training loss: 1.7245091444808849
Validation loss: 2.5181541918245007

Epoch: 6| Step: 13
Training loss: 0.905715390071909
Validation loss: 2.5021202871329034

Epoch: 98| Step: 0
Training loss: 1.201760496734493
Validation loss: 2.525247111991417

Epoch: 6| Step: 1
Training loss: 1.2120317007017016
Validation loss: 2.543240096640135

Epoch: 6| Step: 2
Training loss: 0.8834365731913533
Validation loss: 2.5873442911667794

Epoch: 6| Step: 3
Training loss: 1.737062382646825
Validation loss: 2.6071160869381105

Epoch: 6| Step: 4
Training loss: 1.1500489224518202
Validation loss: 2.532362626678302

Epoch: 6| Step: 5
Training loss: 0.9832663575224723
Validation loss: 2.5806578630489225

Epoch: 6| Step: 6
Training loss: 0.7221747366463632
Validation loss: 2.551160222439041

Epoch: 6| Step: 7
Training loss: 1.2649371314729358
Validation loss: 2.5059804750845376

Epoch: 6| Step: 8
Training loss: 0.8270450243657754
Validation loss: 2.457480959024587

Epoch: 6| Step: 9
Training loss: 0.8961844680216605
Validation loss: 2.5846947087454226

Epoch: 6| Step: 10
Training loss: 0.892720417725812
Validation loss: 2.5316450650580826

Epoch: 6| Step: 11
Training loss: 0.6131113874069478
Validation loss: 2.587708088897046

Epoch: 6| Step: 12
Training loss: 0.9753418274307724
Validation loss: 2.5144113017739413

Epoch: 6| Step: 13
Training loss: 0.8314780245209313
Validation loss: 2.531425831029127

Epoch: 99| Step: 0
Training loss: 0.6574135184252737
Validation loss: 2.5492783422867

Epoch: 6| Step: 1
Training loss: 1.10196180749263
Validation loss: 2.5073967863413373

Epoch: 6| Step: 2
Training loss: 1.1134054549683687
Validation loss: 2.5554764333399747

Epoch: 6| Step: 3
Training loss: 0.48889222639141566
Validation loss: 2.523689407041948

Epoch: 6| Step: 4
Training loss: 1.0129018810160222
Validation loss: 2.552802235042602

Epoch: 6| Step: 5
Training loss: 1.2705486270526778
Validation loss: 2.4663766244746945

Epoch: 6| Step: 6
Training loss: 1.0087108304763381
Validation loss: 2.4941081714833824

Epoch: 6| Step: 7
Training loss: 1.0762034998295393
Validation loss: 2.5525473244240704

Epoch: 6| Step: 8
Training loss: 0.9782392526509522
Validation loss: 2.458566231659965

Epoch: 6| Step: 9
Training loss: 0.7954778203407772
Validation loss: 2.5585448204584136

Epoch: 6| Step: 10
Training loss: 0.9802304772454349
Validation loss: 2.539179011875043

Epoch: 6| Step: 11
Training loss: 0.7312310876601449
Validation loss: 2.5199021808117035

Epoch: 6| Step: 12
Training loss: 0.603805817892748
Validation loss: 2.5868982410823125

Epoch: 6| Step: 13
Training loss: 1.6540019054978452
Validation loss: 2.634713231068429

Epoch: 100| Step: 0
Training loss: 0.8278811833598415
Validation loss: 2.6096064603867855

Epoch: 6| Step: 1
Training loss: 0.907901869821498
Validation loss: 2.5899199584365915

Epoch: 6| Step: 2
Training loss: 0.8783253763539364
Validation loss: 2.6118628240494584

Epoch: 6| Step: 3
Training loss: 1.245998223448906
Validation loss: 2.5523130715695057

Epoch: 6| Step: 4
Training loss: 1.230125839650205
Validation loss: 2.581701983888948

Epoch: 6| Step: 5
Training loss: 0.6822827656483199
Validation loss: 2.518074848820966

Epoch: 6| Step: 6
Training loss: 0.9218139628231198
Validation loss: 2.59164879803973

Epoch: 6| Step: 7
Training loss: 1.1768328757503759
Validation loss: 2.4510832873138324

Epoch: 6| Step: 8
Training loss: 0.815953909666217
Validation loss: 2.491133192826399

Epoch: 6| Step: 9
Training loss: 0.9352473215423219
Validation loss: 2.5078385095247757

Epoch: 6| Step: 10
Training loss: 0.6512227734752133
Validation loss: 2.512624171021227

Epoch: 6| Step: 11
Training loss: 1.6028072823126986
Validation loss: 2.5460546377571758

Epoch: 6| Step: 12
Training loss: 0.8446474600562532
Validation loss: 2.6362961267927965

Epoch: 6| Step: 13
Training loss: 0.8485117168527931
Validation loss: 2.6085495623539723

Epoch: 101| Step: 0
Training loss: 0.7766148969753546
Validation loss: 2.619101451758149

Epoch: 6| Step: 1
Training loss: 1.2272365200276096
Validation loss: 2.6055376385947353

Epoch: 6| Step: 2
Training loss: 0.6841272724447734
Validation loss: 2.6233073635665867

Epoch: 6| Step: 3
Training loss: 0.6006574882747405
Validation loss: 2.5405576714997813

Epoch: 6| Step: 4
Training loss: 0.8170702118884249
Validation loss: 2.5131033901957425

Epoch: 6| Step: 5
Training loss: 0.7234150794491205
Validation loss: 2.533249681329765

Epoch: 6| Step: 6
Training loss: 0.7551194544264759
Validation loss: 2.5437959027971737

Epoch: 6| Step: 7
Training loss: 0.8371112818124391
Validation loss: 2.5315952458037705

Epoch: 6| Step: 8
Training loss: 1.274477434592349
Validation loss: 2.5376450636541423

Epoch: 6| Step: 9
Training loss: 1.7824686800437517
Validation loss: 2.6437675691927156

Epoch: 6| Step: 10
Training loss: 0.6788454649724933
Validation loss: 2.604481858570437

Epoch: 6| Step: 11
Training loss: 0.745916135727329
Validation loss: 2.5983853418831333

Epoch: 6| Step: 12
Training loss: 1.012164632568962
Validation loss: 2.5958332902674623

Epoch: 6| Step: 13
Training loss: 1.1758932776325706
Validation loss: 2.5626238661191167

Epoch: 102| Step: 0
Training loss: 1.006567844399183
Validation loss: 2.5422529159410634

Epoch: 6| Step: 1
Training loss: 0.8208716530415775
Validation loss: 2.521837938076561

Epoch: 6| Step: 2
Training loss: 0.8217241765285751
Validation loss: 2.576818578304258

Epoch: 6| Step: 3
Training loss: 1.007665874845156
Validation loss: 2.5654645844094697

Epoch: 6| Step: 4
Training loss: 0.9536104998179322
Validation loss: 2.6207902621766603

Epoch: 6| Step: 5
Training loss: 0.7971056436094118
Validation loss: 2.5942147079939

Epoch: 6| Step: 6
Training loss: 0.789621438454849
Validation loss: 2.64321815726457

Epoch: 6| Step: 7
Training loss: 0.8522322234730567
Validation loss: 2.6141881960792066

Epoch: 6| Step: 8
Training loss: 1.6423698229712131
Validation loss: 2.5196669036857386

Epoch: 6| Step: 9
Training loss: 1.027302730307065
Validation loss: 2.533347434289069

Epoch: 6| Step: 10
Training loss: 0.505288851767909
Validation loss: 2.566266493957205

Epoch: 6| Step: 11
Training loss: 1.2685301134461837
Validation loss: 2.4951271888049718

Epoch: 6| Step: 12
Training loss: 0.536470456279575
Validation loss: 2.569051547268225

Epoch: 6| Step: 13
Training loss: 0.9294798162237817
Validation loss: 2.532959207925442

Epoch: 103| Step: 0
Training loss: 0.8966568591835341
Validation loss: 2.5136189172358683

Epoch: 6| Step: 1
Training loss: 1.0845196476304597
Validation loss: 2.5473516209385267

Epoch: 6| Step: 2
Training loss: 0.781590463838902
Validation loss: 2.503953033660867

Epoch: 6| Step: 3
Training loss: 1.139881780250113
Validation loss: 2.5864493025889517

Epoch: 6| Step: 4
Training loss: 0.638162859205536
Validation loss: 2.5801525581706306

Epoch: 6| Step: 5
Training loss: 1.2033977447100632
Validation loss: 2.658360708528233

Epoch: 6| Step: 6
Training loss: 1.2475030278262775
Validation loss: 2.692981615101276

Epoch: 6| Step: 7
Training loss: 0.9650914418671224
Validation loss: 2.6703217362091047

Epoch: 6| Step: 8
Training loss: 0.9749637792657361
Validation loss: 2.6711040522289395

Epoch: 6| Step: 9
Training loss: 1.5729045825350907
Validation loss: 2.565216783610691

Epoch: 6| Step: 10
Training loss: 0.8368351119024505
Validation loss: 2.5354861381330878

Epoch: 6| Step: 11
Training loss: 1.1324921779909805
Validation loss: 2.5436210049750887

Epoch: 6| Step: 12
Training loss: 1.3606882000580072
Validation loss: 2.558412890072251

Epoch: 6| Step: 13
Training loss: 0.8446364514572586
Validation loss: 2.559565981119356

Epoch: 104| Step: 0
Training loss: 0.7561153796468909
Validation loss: 2.5834596100574707

Epoch: 6| Step: 1
Training loss: 0.8006225800905724
Validation loss: 2.655083972587168

Epoch: 6| Step: 2
Training loss: 0.559165315380065
Validation loss: 2.809058902936358

Epoch: 6| Step: 3
Training loss: 1.1224989109841144
Validation loss: 2.737574175405995

Epoch: 6| Step: 4
Training loss: 0.7644331082007452
Validation loss: 2.673391867121284

Epoch: 6| Step: 5
Training loss: 0.930065879436757
Validation loss: 2.6309128878332917

Epoch: 6| Step: 6
Training loss: 0.7840558592057835
Validation loss: 2.6240035845307546

Epoch: 6| Step: 7
Training loss: 0.8717681600540554
Validation loss: 2.5226962611984116

Epoch: 6| Step: 8
Training loss: 0.9771112044913493
Validation loss: 2.565357336469656

Epoch: 6| Step: 9
Training loss: 1.0855406989889311
Validation loss: 2.5008180551423456

Epoch: 6| Step: 10
Training loss: 1.052679849603289
Validation loss: 2.4712169731067277

Epoch: 6| Step: 11
Training loss: 0.6555602445160835
Validation loss: 2.484215209428642

Epoch: 6| Step: 12
Training loss: 1.973295988081765
Validation loss: 2.558453800169216

Epoch: 6| Step: 13
Training loss: 0.750456075281336
Validation loss: 2.609683370738066

Epoch: 105| Step: 0
Training loss: 0.753702837922011
Validation loss: 2.5869496219351586

Epoch: 6| Step: 1
Training loss: 1.1251320231641977
Validation loss: 2.5587926423321696

Epoch: 6| Step: 2
Training loss: 0.6822826127672195
Validation loss: 2.5587089997947987

Epoch: 6| Step: 3
Training loss: 0.6304091272913909
Validation loss: 2.499803861235462

Epoch: 6| Step: 4
Training loss: 1.0281915683704108
Validation loss: 2.5408334825598486

Epoch: 6| Step: 5
Training loss: 0.7876976597696825
Validation loss: 2.4752744259238018

Epoch: 6| Step: 6
Training loss: 0.8153300515709512
Validation loss: 2.52201217221583

Epoch: 6| Step: 7
Training loss: 1.9551611700722404
Validation loss: 2.5200383112280997

Epoch: 6| Step: 8
Training loss: 0.839144641968535
Validation loss: 2.541837113298727

Epoch: 6| Step: 9
Training loss: 0.8139093353804725
Validation loss: 2.608298774547172

Epoch: 6| Step: 10
Training loss: 1.0147203377737146
Validation loss: 2.70999172983632

Epoch: 6| Step: 11
Training loss: 1.4442205479705723
Validation loss: 2.7078734423131294

Epoch: 6| Step: 12
Training loss: 1.000012040065763
Validation loss: 2.617537540541861

Epoch: 6| Step: 13
Training loss: 0.5650094007030706
Validation loss: 2.583033703275842

Epoch: 106| Step: 0
Training loss: 0.629918580924837
Validation loss: 2.581189609464624

Epoch: 6| Step: 1
Training loss: 1.7071385120762939
Validation loss: 2.5579997297679054

Epoch: 6| Step: 2
Training loss: 1.1723612475903853
Validation loss: 2.5705416035219137

Epoch: 6| Step: 3
Training loss: 0.9619123274889175
Validation loss: 2.5270001090849417

Epoch: 6| Step: 4
Training loss: 0.701593766227288
Validation loss: 2.521168147989985

Epoch: 6| Step: 5
Training loss: 0.8324713818897902
Validation loss: 2.6463237267940602

Epoch: 6| Step: 6
Training loss: 0.9584687938873628
Validation loss: 2.73848498317076

Epoch: 6| Step: 7
Training loss: 1.246219736265535
Validation loss: 2.782516919587577

Epoch: 6| Step: 8
Training loss: 0.7771185160454304
Validation loss: 2.7041748301456785

Epoch: 6| Step: 9
Training loss: 0.9961743490484422
Validation loss: 2.6634645508806787

Epoch: 6| Step: 10
Training loss: 1.013519746099674
Validation loss: 2.6052263443568418

Epoch: 6| Step: 11
Training loss: 0.8332683696856488
Validation loss: 2.4968661693660334

Epoch: 6| Step: 12
Training loss: 1.08433689193384
Validation loss: 2.487709319031403

Epoch: 6| Step: 13
Training loss: 0.9076439233154002
Validation loss: 2.468690300070742

Epoch: 107| Step: 0
Training loss: 0.9645155375461656
Validation loss: 2.4979456805743956

Epoch: 6| Step: 1
Training loss: 1.0590265381741522
Validation loss: 2.525196686565639

Epoch: 6| Step: 2
Training loss: 1.0886890488040935
Validation loss: 2.4913648006786824

Epoch: 6| Step: 3
Training loss: 0.5588466898574128
Validation loss: 2.5534125674663763

Epoch: 6| Step: 4
Training loss: 0.789395252732122
Validation loss: 2.506471958938769

Epoch: 6| Step: 5
Training loss: 1.6271581989930084
Validation loss: 2.5423129750434423

Epoch: 6| Step: 6
Training loss: 0.7744506981206616
Validation loss: 2.544601861405201

Epoch: 6| Step: 7
Training loss: 0.7386075867869327
Validation loss: 2.6012086064352293

Epoch: 6| Step: 8
Training loss: 0.9558250455377841
Validation loss: 2.542816235665858

Epoch: 6| Step: 9
Training loss: 1.0218033885070084
Validation loss: 2.5873622292468936

Epoch: 6| Step: 10
Training loss: 0.56271980547471
Validation loss: 2.5453091197716375

Epoch: 6| Step: 11
Training loss: 0.6230956151188128
Validation loss: 2.4722168639002344

Epoch: 6| Step: 12
Training loss: 0.8237140068213736
Validation loss: 2.4599906270435277

Epoch: 6| Step: 13
Training loss: 0.8464360045945366
Validation loss: 2.5121791293093385

Epoch: 108| Step: 0
Training loss: 0.5960208733282951
Validation loss: 2.587065136804993

Epoch: 6| Step: 1
Training loss: 0.5668282876751479
Validation loss: 2.5746225784141465

Epoch: 6| Step: 2
Training loss: 0.6495909485809997
Validation loss: 2.5996621095738304

Epoch: 6| Step: 3
Training loss: 0.8480106439147377
Validation loss: 2.5857507613293222

Epoch: 6| Step: 4
Training loss: 0.9329366885636796
Validation loss: 2.592688132473413

Epoch: 6| Step: 5
Training loss: 0.7633761250344109
Validation loss: 2.6100282289237815

Epoch: 6| Step: 6
Training loss: 0.9220118663504169
Validation loss: 2.6050072089136385

Epoch: 6| Step: 7
Training loss: 1.4838559498033648
Validation loss: 2.543810976939383

Epoch: 6| Step: 8
Training loss: 0.9498878601043015
Validation loss: 2.6287249672194073

Epoch: 6| Step: 9
Training loss: 1.2461651629131516
Validation loss: 2.5506800445995803

Epoch: 6| Step: 10
Training loss: 0.7027675567816849
Validation loss: 2.619473391867709

Epoch: 6| Step: 11
Training loss: 0.6861964351823849
Validation loss: 2.584723995558194

Epoch: 6| Step: 12
Training loss: 1.2152831825257266
Validation loss: 2.6283979826744943

Epoch: 6| Step: 13
Training loss: 0.6158430207212809
Validation loss: 2.5492763393146602

Epoch: 109| Step: 0
Training loss: 1.0486474476484142
Validation loss: 2.524870490224441

Epoch: 6| Step: 1
Training loss: 0.7655476122300863
Validation loss: 2.547482010600345

Epoch: 6| Step: 2
Training loss: 1.1314124565022765
Validation loss: 2.514112440347804

Epoch: 6| Step: 3
Training loss: 0.5398261148799078
Validation loss: 2.5443952849505704

Epoch: 6| Step: 4
Training loss: 1.4891039559356667
Validation loss: 2.5129086536939007

Epoch: 6| Step: 5
Training loss: 0.8096049891500954
Validation loss: 2.543040472328859

Epoch: 6| Step: 6
Training loss: 0.9925529527831357
Validation loss: 2.578112669635918

Epoch: 6| Step: 7
Training loss: 0.7586854449089632
Validation loss: 2.551497977461609

Epoch: 6| Step: 8
Training loss: 0.7216773749328644
Validation loss: 2.5374797876614754

Epoch: 6| Step: 9
Training loss: 0.6548165606108568
Validation loss: 2.5165048328264574

Epoch: 6| Step: 10
Training loss: 0.8360957058374138
Validation loss: 2.518004324868154

Epoch: 6| Step: 11
Training loss: 0.6662983671742871
Validation loss: 2.67357790927721

Epoch: 6| Step: 12
Training loss: 0.8091068206470391
Validation loss: 2.6121909809024704

Epoch: 6| Step: 13
Training loss: 0.9851001309074212
Validation loss: 2.6474783031569973

Epoch: 110| Step: 0
Training loss: 0.8195367323816601
Validation loss: 2.639724743514371

Epoch: 6| Step: 1
Training loss: 1.067025364725359
Validation loss: 2.612637290815077

Epoch: 6| Step: 2
Training loss: 1.4317333821097802
Validation loss: 2.5580553570638895

Epoch: 6| Step: 3
Training loss: 1.0698149701149178
Validation loss: 2.531548376511337

Epoch: 6| Step: 4
Training loss: 0.6946261157716251
Validation loss: 2.545453780850692

Epoch: 6| Step: 5
Training loss: 1.0621652075686017
Validation loss: 2.578398241147909

Epoch: 6| Step: 6
Training loss: 0.7246899418627291
Validation loss: 2.5582021476668793

Epoch: 6| Step: 7
Training loss: 0.9610888974397964
Validation loss: 2.540514408596507

Epoch: 6| Step: 8
Training loss: 0.6928708356731813
Validation loss: 2.669524930939616

Epoch: 6| Step: 9
Training loss: 0.6929008579649082
Validation loss: 2.6243394595843097

Epoch: 6| Step: 10
Training loss: 0.6831325610162077
Validation loss: 2.647825697429976

Epoch: 6| Step: 11
Training loss: 0.9655450596480963
Validation loss: 2.6681484536100513

Epoch: 6| Step: 12
Training loss: 0.4777800375200524
Validation loss: 2.609786962398994

Epoch: 6| Step: 13
Training loss: 0.8030734865759849
Validation loss: 2.5425518766529014

Epoch: 111| Step: 0
Training loss: 1.1040858053192728
Validation loss: 2.6099424221123617

Epoch: 6| Step: 1
Training loss: 0.9045482310883772
Validation loss: 2.6150717614698693

Epoch: 6| Step: 2
Training loss: 0.7549700569379316
Validation loss: 2.5506664637802166

Epoch: 6| Step: 3
Training loss: 0.8934213340767113
Validation loss: 2.5664785095292117

Epoch: 6| Step: 4
Training loss: 0.9387794029822364
Validation loss: 2.5662865922923137

Epoch: 6| Step: 5
Training loss: 0.7396432332958047
Validation loss: 2.509247651437601

Epoch: 6| Step: 6
Training loss: 0.660346618832415
Validation loss: 2.577829579083144

Epoch: 6| Step: 7
Training loss: 0.5200022233401964
Validation loss: 2.5071896010194368

Epoch: 6| Step: 8
Training loss: 0.6399747292923705
Validation loss: 2.6292101083139934

Epoch: 6| Step: 9
Training loss: 0.7580297099810728
Validation loss: 2.6901810011303273

Epoch: 6| Step: 10
Training loss: 0.9334337105305355
Validation loss: 2.688326523715636

Epoch: 6| Step: 11
Training loss: 1.4404454944842433
Validation loss: 2.7014053254879142

Epoch: 6| Step: 12
Training loss: 1.0120779452933668
Validation loss: 2.6809654636171936

Epoch: 6| Step: 13
Training loss: 0.5948702383393877
Validation loss: 2.5540168496315174

Epoch: 112| Step: 0
Training loss: 0.851257409555058
Validation loss: 2.5587055055706327

Epoch: 6| Step: 1
Training loss: 0.52162097184879
Validation loss: 2.572263632203694

Epoch: 6| Step: 2
Training loss: 1.5599812615320663
Validation loss: 2.528274765576852

Epoch: 6| Step: 3
Training loss: 0.8007803568020934
Validation loss: 2.497583882740472

Epoch: 6| Step: 4
Training loss: 0.698273515331958
Validation loss: 2.557033103618189

Epoch: 6| Step: 5
Training loss: 0.6939976722639771
Validation loss: 2.6191145601428785

Epoch: 6| Step: 6
Training loss: 0.983071266156089
Validation loss: 2.6569927000041926

Epoch: 6| Step: 7
Training loss: 0.9446549138219937
Validation loss: 2.6999586372974806

Epoch: 6| Step: 8
Training loss: 0.5660319439817353
Validation loss: 2.719579080615647

Epoch: 6| Step: 9
Training loss: 0.8792379473916858
Validation loss: 2.6882710496656657

Epoch: 6| Step: 10
Training loss: 0.7707319622570828
Validation loss: 2.6372118679511516

Epoch: 6| Step: 11
Training loss: 0.6889614913502001
Validation loss: 2.642167222245795

Epoch: 6| Step: 12
Training loss: 1.0330140602469589
Validation loss: 2.5822366776073618

Epoch: 6| Step: 13
Training loss: 1.1095737225561213
Validation loss: 2.5331167864687907

Epoch: 113| Step: 0
Training loss: 0.8415081121900265
Validation loss: 2.543482356007338

Epoch: 6| Step: 1
Training loss: 0.692747012232075
Validation loss: 2.5302060647208067

Epoch: 6| Step: 2
Training loss: 1.1577136081156418
Validation loss: 2.5399838697867465

Epoch: 6| Step: 3
Training loss: 0.9948567207728676
Validation loss: 2.6059726149719853

Epoch: 6| Step: 4
Training loss: 1.0537272285001082
Validation loss: 2.566624005590675

Epoch: 6| Step: 5
Training loss: 0.649872444548428
Validation loss: 2.5886520474781074

Epoch: 6| Step: 6
Training loss: 0.5867760316643433
Validation loss: 2.694136284600732

Epoch: 6| Step: 7
Training loss: 0.8004447416048112
Validation loss: 2.7070566151409032

Epoch: 6| Step: 8
Training loss: 1.0213223797515394
Validation loss: 2.6921553249875547

Epoch: 6| Step: 9
Training loss: 1.403963688782969
Validation loss: 2.686683101848315

Epoch: 6| Step: 10
Training loss: 0.584369596160546
Validation loss: 2.6638359204664614

Epoch: 6| Step: 11
Training loss: 0.6804976841482856
Validation loss: 2.618984778174655

Epoch: 6| Step: 12
Training loss: 0.5886529434693658
Validation loss: 2.5096538038861067

Epoch: 6| Step: 13
Training loss: 0.7996247663260544
Validation loss: 2.5625571577939206

Epoch: 114| Step: 0
Training loss: 0.6379254146510147
Validation loss: 2.5212545332003407

Epoch: 6| Step: 1
Training loss: 0.5458743067886147
Validation loss: 2.5764857311390377

Epoch: 6| Step: 2
Training loss: 0.7392123774042364
Validation loss: 2.6142926352148987

Epoch: 6| Step: 3
Training loss: 0.5625847646636377
Validation loss: 2.5843029868607

Epoch: 6| Step: 4
Training loss: 0.7096941209128982
Validation loss: 2.6154873084405335

Epoch: 6| Step: 5
Training loss: 1.5402112053045844
Validation loss: 2.5445758450638785

Epoch: 6| Step: 6
Training loss: 0.6002805600265374
Validation loss: 2.543964025193093

Epoch: 6| Step: 7
Training loss: 0.7801536496755308
Validation loss: 2.6094267682024634

Epoch: 6| Step: 8
Training loss: 0.6217681773848986
Validation loss: 2.63787173081718

Epoch: 6| Step: 9
Training loss: 0.9505278425959814
Validation loss: 2.654213517362903

Epoch: 6| Step: 10
Training loss: 0.6057153999248961
Validation loss: 2.570457647644866

Epoch: 6| Step: 11
Training loss: 0.7061063502234828
Validation loss: 2.518608527552853

Epoch: 6| Step: 12
Training loss: 1.0174387069349116
Validation loss: 2.484557419003697

Epoch: 6| Step: 13
Training loss: 0.9181344714627269
Validation loss: 2.590772750807115

Epoch: 115| Step: 0
Training loss: 0.5958214314034528
Validation loss: 2.5860922499161343

Epoch: 6| Step: 1
Training loss: 0.6458595690987077
Validation loss: 2.6104838895146565

Epoch: 6| Step: 2
Training loss: 0.9461541330612635
Validation loss: 2.6450642246364415

Epoch: 6| Step: 3
Training loss: 0.8192469260932497
Validation loss: 2.6433917266518048

Epoch: 6| Step: 4
Training loss: 0.9051498114687617
Validation loss: 2.6272899841863016

Epoch: 6| Step: 5
Training loss: 0.602182440427183
Validation loss: 2.5868158452613765

Epoch: 6| Step: 6
Training loss: 0.8894840092714618
Validation loss: 2.634547558944355

Epoch: 6| Step: 7
Training loss: 1.3595627402966206
Validation loss: 2.6080299306606904

Epoch: 6| Step: 8
Training loss: 1.0801370614994914
Validation loss: 2.6469695787822993

Epoch: 6| Step: 9
Training loss: 0.40226930096151164
Validation loss: 2.5306802744256705

Epoch: 6| Step: 10
Training loss: 0.7287856923256607
Validation loss: 2.571232454261389

Epoch: 6| Step: 11
Training loss: 0.8390774446715784
Validation loss: 2.572617985818973

Epoch: 6| Step: 12
Training loss: 0.6028507360154736
Validation loss: 2.5440531194667253

Epoch: 6| Step: 13
Training loss: 0.7294015687681398
Validation loss: 2.5215909833406793

Epoch: 116| Step: 0
Training loss: 0.9407287629138287
Validation loss: 2.60173348751762

Epoch: 6| Step: 1
Training loss: 0.6347425016446344
Validation loss: 2.6110482095577408

Epoch: 6| Step: 2
Training loss: 0.657558816302485
Validation loss: 2.647515007807406

Epoch: 6| Step: 3
Training loss: 0.8077564788223226
Validation loss: 2.590910111380969

Epoch: 6| Step: 4
Training loss: 1.0228857052552964
Validation loss: 2.5671973709842293

Epoch: 6| Step: 5
Training loss: 0.8563702157827521
Validation loss: 2.611444988503207

Epoch: 6| Step: 6
Training loss: 1.565732663653854
Validation loss: 2.585288789482798

Epoch: 6| Step: 7
Training loss: 0.5442440507009035
Validation loss: 2.545557488722363

Epoch: 6| Step: 8
Training loss: 0.5261047784948293
Validation loss: 2.6109605186630245

Epoch: 6| Step: 9
Training loss: 0.6727490395447315
Validation loss: 2.626187040992654

Epoch: 6| Step: 10
Training loss: 0.7686644188610118
Validation loss: 2.602670412643595

Epoch: 6| Step: 11
Training loss: 0.7498033583664796
Validation loss: 2.5788558694640455

Epoch: 6| Step: 12
Training loss: 0.7061574183183987
Validation loss: 2.55474321497087

Epoch: 6| Step: 13
Training loss: 0.5283300712657228
Validation loss: 2.5489872011941133

Epoch: 117| Step: 0
Training loss: 0.5278687301144149
Validation loss: 2.6386303939589513

Epoch: 6| Step: 1
Training loss: 0.4472692564437901
Validation loss: 2.6538993756752944

Epoch: 6| Step: 2
Training loss: 0.6993134503727592
Validation loss: 2.6262293237994627

Epoch: 6| Step: 3
Training loss: 0.9012279464943989
Validation loss: 2.5979723592222133

Epoch: 6| Step: 4
Training loss: 0.5044018577789532
Validation loss: 2.549910018305683

Epoch: 6| Step: 5
Training loss: 0.8002867125289325
Validation loss: 2.6126630552717427

Epoch: 6| Step: 6
Training loss: 0.5266049614151382
Validation loss: 2.5239150753767103

Epoch: 6| Step: 7
Training loss: 0.8492983895643519
Validation loss: 2.5473846284511623

Epoch: 6| Step: 8
Training loss: 0.7850052417895985
Validation loss: 2.57310986018767

Epoch: 6| Step: 9
Training loss: 0.7993142437308484
Validation loss: 2.5428617565267273

Epoch: 6| Step: 10
Training loss: 1.619563472002178
Validation loss: 2.632064003578777

Epoch: 6| Step: 11
Training loss: 0.755868128053122
Validation loss: 2.648547842602228

Epoch: 6| Step: 12
Training loss: 0.8982142295393185
Validation loss: 2.6330034996050022

Epoch: 6| Step: 13
Training loss: 1.0466398288136924
Validation loss: 2.6814048757928024

Epoch: 118| Step: 0
Training loss: 0.46537154551291315
Validation loss: 2.709369671444931

Epoch: 6| Step: 1
Training loss: 0.43412121487567445
Validation loss: 2.6058305129851362

Epoch: 6| Step: 2
Training loss: 0.8352286640172162
Validation loss: 2.5412672125012477

Epoch: 6| Step: 3
Training loss: 1.3746012629719213
Validation loss: 2.587326475827137

Epoch: 6| Step: 4
Training loss: 1.174648258642683
Validation loss: 2.5334559118162487

Epoch: 6| Step: 5
Training loss: 0.4601480544806341
Validation loss: 2.5726645857120563

Epoch: 6| Step: 6
Training loss: 0.6283706374524435
Validation loss: 2.621524341460299

Epoch: 6| Step: 7
Training loss: 0.6892261942148162
Validation loss: 2.459864330931371

Epoch: 6| Step: 8
Training loss: 0.7151160633480276
Validation loss: 2.610304996043253

Epoch: 6| Step: 9
Training loss: 0.46634182636815424
Validation loss: 2.6325769517162767

Epoch: 6| Step: 10
Training loss: 1.0452254665390595
Validation loss: 2.6450051841372555

Epoch: 6| Step: 11
Training loss: 0.8901482360061269
Validation loss: 2.5952334317498327

Epoch: 6| Step: 12
Training loss: 0.47984990529938576
Validation loss: 2.5292371273961884

Epoch: 6| Step: 13
Training loss: 0.5990475187383497
Validation loss: 2.6104347985427703

Epoch: 119| Step: 0
Training loss: 0.5381078975232638
Validation loss: 2.5335410311116524

Epoch: 6| Step: 1
Training loss: 0.7487947793858054
Validation loss: 2.5172114690976923

Epoch: 6| Step: 2
Training loss: 0.9379929835823698
Validation loss: 2.599807330475447

Epoch: 6| Step: 3
Training loss: 0.5726293768308488
Validation loss: 2.5714236933041277

Epoch: 6| Step: 4
Training loss: 0.5151613636358912
Validation loss: 2.5503830260540785

Epoch: 6| Step: 5
Training loss: 1.0043847394659735
Validation loss: 2.61464129278576

Epoch: 6| Step: 6
Training loss: 0.5831319143328976
Validation loss: 2.576809480056055

Epoch: 6| Step: 7
Training loss: 1.4138456146664355
Validation loss: 2.656092680217953

Epoch: 6| Step: 8
Training loss: 0.6028782710477614
Validation loss: 2.6333583941253034

Epoch: 6| Step: 9
Training loss: 0.8702172972077656
Validation loss: 2.6433668930678134

Epoch: 6| Step: 10
Training loss: 1.0182862847089431
Validation loss: 2.6219977209555085

Epoch: 6| Step: 11
Training loss: 0.6359390446224715
Validation loss: 2.6094680739076863

Epoch: 6| Step: 12
Training loss: 0.6690873044087328
Validation loss: 2.6314748276851017

Epoch: 6| Step: 13
Training loss: 0.8413807488759236
Validation loss: 2.5842491854233103

Epoch: 120| Step: 0
Training loss: 0.8686891904996038
Validation loss: 2.6330687929219936

Epoch: 6| Step: 1
Training loss: 0.9620980798365725
Validation loss: 2.555290765335948

Epoch: 6| Step: 2
Training loss: 0.8358673351467516
Validation loss: 2.6330612019873856

Epoch: 6| Step: 3
Training loss: 0.6935927307300164
Validation loss: 2.5986718967255285

Epoch: 6| Step: 4
Training loss: 0.5422294028852004
Validation loss: 2.540418214034709

Epoch: 6| Step: 5
Training loss: 0.34841943403203524
Validation loss: 2.599777250651675

Epoch: 6| Step: 6
Training loss: 0.8062554056149032
Validation loss: 2.6695209417012937

Epoch: 6| Step: 7
Training loss: 0.8351596528885888
Validation loss: 2.5385015327704954

Epoch: 6| Step: 8
Training loss: 0.6402431373392246
Validation loss: 2.6279418748459347

Epoch: 6| Step: 9
Training loss: 0.5877896345721809
Validation loss: 2.6308313192199337

Epoch: 6| Step: 10
Training loss: 1.4063429483849184
Validation loss: 2.611656562048818

Epoch: 6| Step: 11
Training loss: 0.7581070396390357
Validation loss: 2.5980088608898755

Epoch: 6| Step: 12
Training loss: 0.6304423604403262
Validation loss: 2.677216735563848

Epoch: 6| Step: 13
Training loss: 0.5845947902868192
Validation loss: 2.664402571793587

Epoch: 121| Step: 0
Training loss: 0.6554213696565903
Validation loss: 2.6221041676604724

Epoch: 6| Step: 1
Training loss: 0.7018686302079449
Validation loss: 2.6012703671407316

Epoch: 6| Step: 2
Training loss: 0.6150834640218881
Validation loss: 2.6088669181375526

Epoch: 6| Step: 3
Training loss: 0.8473684639820039
Validation loss: 2.646331099497438

Epoch: 6| Step: 4
Training loss: 0.7140288580851444
Validation loss: 2.5593274644249635

Epoch: 6| Step: 5
Training loss: 0.5766546780473807
Validation loss: 2.619894087642994

Epoch: 6| Step: 6
Training loss: 0.9582134807663113
Validation loss: 2.5666448597373845

Epoch: 6| Step: 7
Training loss: 0.5195395963758463
Validation loss: 2.5702996683621735

Epoch: 6| Step: 8
Training loss: 0.369034282564942
Validation loss: 2.516026956419887

Epoch: 6| Step: 9
Training loss: 0.8359301201325273
Validation loss: 2.610123898061042

Epoch: 6| Step: 10
Training loss: 1.371714742072186
Validation loss: 2.6132337777806214

Epoch: 6| Step: 11
Training loss: 0.5720042390132767
Validation loss: 2.678508962780843

Epoch: 6| Step: 12
Training loss: 0.5695197199738853
Validation loss: 2.6491229615311718

Epoch: 6| Step: 13
Training loss: 0.7980052188377575
Validation loss: 2.633680553320327

Epoch: 122| Step: 0
Training loss: 1.452379343008122
Validation loss: 2.5469418070325514

Epoch: 6| Step: 1
Training loss: 0.6251122850644083
Validation loss: 2.6161996827661285

Epoch: 6| Step: 2
Training loss: 0.6713504517903522
Validation loss: 2.565421462726514

Epoch: 6| Step: 3
Training loss: 0.5463426451169752
Validation loss: 2.623651120105341

Epoch: 6| Step: 4
Training loss: 0.817098333333582
Validation loss: 2.5700172942751043

Epoch: 6| Step: 5
Training loss: 0.7060202646899792
Validation loss: 2.591472330401867

Epoch: 6| Step: 6
Training loss: 0.5574280105606015
Validation loss: 2.5864852064019224

Epoch: 6| Step: 7
Training loss: 1.1262388296134354
Validation loss: 2.5940258997749437

Epoch: 6| Step: 8
Training loss: 0.6508863696209152
Validation loss: 2.6621299587992353

Epoch: 6| Step: 9
Training loss: 0.5004916158425499
Validation loss: 2.6025151903537926

Epoch: 6| Step: 10
Training loss: 0.6928849222256295
Validation loss: 2.6143474447117656

Epoch: 6| Step: 11
Training loss: 0.7470589032268085
Validation loss: 2.6604216933794165

Epoch: 6| Step: 12
Training loss: 0.6607573892827535
Validation loss: 2.6160011221609127

Epoch: 6| Step: 13
Training loss: 0.7201836013483169
Validation loss: 2.5775578886574375

Epoch: 123| Step: 0
Training loss: 1.3583402970882468
Validation loss: 2.6645264282194865

Epoch: 6| Step: 1
Training loss: 0.47278511245383287
Validation loss: 2.6179442872525076

Epoch: 6| Step: 2
Training loss: 0.5919026698862226
Validation loss: 2.562004025850451

Epoch: 6| Step: 3
Training loss: 0.5462509136497835
Validation loss: 2.6279672170865496

Epoch: 6| Step: 4
Training loss: 0.6817322590180399
Validation loss: 2.5732678831338816

Epoch: 6| Step: 5
Training loss: 0.5298204823331728
Validation loss: 2.590630489967827

Epoch: 6| Step: 6
Training loss: 0.6242966509014134
Validation loss: 2.607193634673428

Epoch: 6| Step: 7
Training loss: 0.6818592191036138
Validation loss: 2.5842543980151182

Epoch: 6| Step: 8
Training loss: 0.9409392532134659
Validation loss: 2.624615898489468

Epoch: 6| Step: 9
Training loss: 0.5760875575553006
Validation loss: 2.7146600089341284

Epoch: 6| Step: 10
Training loss: 1.1280030329913764
Validation loss: 2.6433987918540156

Epoch: 6| Step: 11
Training loss: 0.6943675703308755
Validation loss: 2.617908496138638

Epoch: 6| Step: 12
Training loss: 0.49280149521329936
Validation loss: 2.6501252564631828

Epoch: 6| Step: 13
Training loss: 0.8540519932010927
Validation loss: 2.6276793656617174

Epoch: 124| Step: 0
Training loss: 0.4572496788833016
Validation loss: 2.580186724633257

Epoch: 6| Step: 1
Training loss: 0.5140398977116833
Validation loss: 2.5713671343896687

Epoch: 6| Step: 2
Training loss: 0.41233228467328914
Validation loss: 2.54582205071163

Epoch: 6| Step: 3
Training loss: 1.399842052405463
Validation loss: 2.6122702718113606

Epoch: 6| Step: 4
Training loss: 0.6841186905703603
Validation loss: 2.5842003956692703

Epoch: 6| Step: 5
Training loss: 0.6552462849342494
Validation loss: 2.664790556492407

Epoch: 6| Step: 6
Training loss: 1.0006173731497148
Validation loss: 2.642723077640945

Epoch: 6| Step: 7
Training loss: 0.9555823744354356
Validation loss: 2.638308937078843

Epoch: 6| Step: 8
Training loss: 0.6912360763182226
Validation loss: 2.6469839903075076

Epoch: 6| Step: 9
Training loss: 0.6074702498133255
Validation loss: 2.5778486932211533

Epoch: 6| Step: 10
Training loss: 0.6263668373137858
Validation loss: 2.570087334105122

Epoch: 6| Step: 11
Training loss: 0.7839234576010382
Validation loss: 2.5208156338115004

Epoch: 6| Step: 12
Training loss: 0.7080790727204412
Validation loss: 2.5418460866001062

Epoch: 6| Step: 13
Training loss: 0.6635587689058672
Validation loss: 2.564489228303634

Epoch: 125| Step: 0
Training loss: 0.42877075195138736
Validation loss: 2.5964883497351305

Epoch: 6| Step: 1
Training loss: 0.8880651393960963
Validation loss: 2.6461643001978854

Epoch: 6| Step: 2
Training loss: 0.32751359061441054
Validation loss: 2.708092551654357

Epoch: 6| Step: 3
Training loss: 0.6330977373947085
Validation loss: 2.7052330514402594

Epoch: 6| Step: 4
Training loss: 0.6877336971856395
Validation loss: 2.608443956395695

Epoch: 6| Step: 5
Training loss: 0.7134960791139929
Validation loss: 2.674898114150636

Epoch: 6| Step: 6
Training loss: 1.3518161425429667
Validation loss: 2.664065647216608

Epoch: 6| Step: 7
Training loss: 0.6273499180928775
Validation loss: 2.6033641545046042

Epoch: 6| Step: 8
Training loss: 0.5241512158435889
Validation loss: 2.632673922098008

Epoch: 6| Step: 9
Training loss: 0.314601436729873
Validation loss: 2.638144831302335

Epoch: 6| Step: 10
Training loss: 0.7554639624805889
Validation loss: 2.50866152452923

Epoch: 6| Step: 11
Training loss: 0.5241798716197326
Validation loss: 2.50648416612759

Epoch: 6| Step: 12
Training loss: 0.6826906178371887
Validation loss: 2.6297554054188983

Epoch: 6| Step: 13
Training loss: 0.8596385551671922
Validation loss: 2.634033734898483

Epoch: 126| Step: 0
Training loss: 0.5496172136454055
Validation loss: 2.6594455271841024

Epoch: 6| Step: 1
Training loss: 0.6016357426828549
Validation loss: 2.635286468687305

Epoch: 6| Step: 2
Training loss: 0.7411767602411518
Validation loss: 2.6535725881384162

Epoch: 6| Step: 3
Training loss: 0.6575187498399904
Validation loss: 2.6477897699674755

Epoch: 6| Step: 4
Training loss: 0.9465168618716912
Validation loss: 2.6868039198177778

Epoch: 6| Step: 5
Training loss: 0.5406626572475963
Validation loss: 2.6657865730979147

Epoch: 6| Step: 6
Training loss: 0.5791233824145993
Validation loss: 2.609184410459684

Epoch: 6| Step: 7
Training loss: 0.6026513043043188
Validation loss: 2.5899536201566193

Epoch: 6| Step: 8
Training loss: 0.7118401717992778
Validation loss: 2.5602634175073207

Epoch: 6| Step: 9
Training loss: 0.8237001496022524
Validation loss: 2.626295821952007

Epoch: 6| Step: 10
Training loss: 1.3403128200467476
Validation loss: 2.5802268351904227

Epoch: 6| Step: 11
Training loss: 0.6012349413534485
Validation loss: 2.5931200388476836

Epoch: 6| Step: 12
Training loss: 0.5889494223292185
Validation loss: 2.627433390718276

Epoch: 6| Step: 13
Training loss: 0.6349487275352137
Validation loss: 2.63165585309304

Epoch: 127| Step: 0
Training loss: 0.6231314144359167
Validation loss: 2.706747050227036

Epoch: 6| Step: 1
Training loss: 0.8133458356469637
Validation loss: 2.5873172455899938

Epoch: 6| Step: 2
Training loss: 1.4651811948566624
Validation loss: 2.585522698116807

Epoch: 6| Step: 3
Training loss: 0.5353640967164394
Validation loss: 2.5864437257003683

Epoch: 6| Step: 4
Training loss: 0.9533400996397113
Validation loss: 2.6174053044573578

Epoch: 6| Step: 5
Training loss: 0.40169031357837076
Validation loss: 2.5258088361793316

Epoch: 6| Step: 6
Training loss: 0.4897449071228926
Validation loss: 2.6842484580172306

Epoch: 6| Step: 7
Training loss: 0.6275363479208862
Validation loss: 2.6578327923477927

Epoch: 6| Step: 8
Training loss: 0.662121752958022
Validation loss: 2.6488137217080707

Epoch: 6| Step: 9
Training loss: 0.5893297545378682
Validation loss: 2.6374277174266734

Epoch: 6| Step: 10
Training loss: 0.758450505004087
Validation loss: 2.6482189467134045

Epoch: 6| Step: 11
Training loss: 0.4838497482634616
Validation loss: 2.64018745484143

Epoch: 6| Step: 12
Training loss: 0.627640202122209
Validation loss: 2.679491805186799

Epoch: 6| Step: 13
Training loss: 0.5682095989024755
Validation loss: 2.594892166092431

Epoch: 128| Step: 0
Training loss: 0.9394197517542209
Validation loss: 2.6014416182560356

Epoch: 6| Step: 1
Training loss: 0.7289544387049033
Validation loss: 2.636880623828852

Epoch: 6| Step: 2
Training loss: 0.6382843381697282
Validation loss: 2.6007471802178648

Epoch: 6| Step: 3
Training loss: 0.43115984347464026
Validation loss: 2.6145787232701565

Epoch: 6| Step: 4
Training loss: 1.288637912067965
Validation loss: 2.6292153677885834

Epoch: 6| Step: 5
Training loss: 0.6650005671133047
Validation loss: 2.618550612719933

Epoch: 6| Step: 6
Training loss: 0.5290216384853726
Validation loss: 2.679566168378415

Epoch: 6| Step: 7
Training loss: 0.7188262898965136
Validation loss: 2.714158488999079

Epoch: 6| Step: 8
Training loss: 0.6559669020243608
Validation loss: 2.673144999796367

Epoch: 6| Step: 9
Training loss: 0.6607761294278603
Validation loss: 2.644952422148589

Epoch: 6| Step: 10
Training loss: 0.7407732288092884
Validation loss: 2.658489450117741

Epoch: 6| Step: 11
Training loss: 0.5628046694162621
Validation loss: 2.607112886215506

Epoch: 6| Step: 12
Training loss: 0.4789119558321153
Validation loss: 2.61499548066176

Epoch: 6| Step: 13
Training loss: 0.38659504154437624
Validation loss: 2.6538025744526954

Epoch: 129| Step: 0
Training loss: 0.41784666185660385
Validation loss: 2.6102671668455724

Epoch: 6| Step: 1
Training loss: 0.4767040605260474
Validation loss: 2.7201130252851122

Epoch: 6| Step: 2
Training loss: 0.5715009769054217
Validation loss: 2.591526296213913

Epoch: 6| Step: 3
Training loss: 0.4765184413367501
Validation loss: 2.5735153294560007

Epoch: 6| Step: 4
Training loss: 0.6000536537022937
Validation loss: 2.7076567807394163

Epoch: 6| Step: 5
Training loss: 0.5920825935786881
Validation loss: 2.6565098803677687

Epoch: 6| Step: 6
Training loss: 0.603575373287644
Validation loss: 2.683634898810971

Epoch: 6| Step: 7
Training loss: 0.8371232081919988
Validation loss: 2.6340276025254146

Epoch: 6| Step: 8
Training loss: 1.305318211677006
Validation loss: 2.6055860593086115

Epoch: 6| Step: 9
Training loss: 0.4778649402031532
Validation loss: 2.5994130401261546

Epoch: 6| Step: 10
Training loss: 0.9531912233453654
Validation loss: 2.6626181019601334

Epoch: 6| Step: 11
Training loss: 0.757792207111914
Validation loss: 2.571954227986977

Epoch: 6| Step: 12
Training loss: 0.47448436833310453
Validation loss: 2.6047379490162634

Epoch: 6| Step: 13
Training loss: 0.49267133516057826
Validation loss: 2.6506219967644666

Epoch: 130| Step: 0
Training loss: 0.611944941652619
Validation loss: 2.646785269473215

Epoch: 6| Step: 1
Training loss: 0.7099862914038011
Validation loss: 2.5900265383189263

Epoch: 6| Step: 2
Training loss: 0.47793066900017667
Validation loss: 2.6827398178869064

Epoch: 6| Step: 3
Training loss: 1.337661968656101
Validation loss: 2.5800008865719635

Epoch: 6| Step: 4
Training loss: 0.7253451249371436
Validation loss: 2.655905921940713

Epoch: 6| Step: 5
Training loss: 0.5081755880625957
Validation loss: 2.6299302183860735

Epoch: 6| Step: 6
Training loss: 0.46065769754969954
Validation loss: 2.6826669942728922

Epoch: 6| Step: 7
Training loss: 0.792336235153679
Validation loss: 2.6688748818093573

Epoch: 6| Step: 8
Training loss: 0.6039632476715482
Validation loss: 2.6494946465784612

Epoch: 6| Step: 9
Training loss: 0.6661456923575373
Validation loss: 2.5287029811217066

Epoch: 6| Step: 10
Training loss: 0.7221342108563163
Validation loss: 2.5686390075465018

Epoch: 6| Step: 11
Training loss: 0.7763208147510741
Validation loss: 2.547059908592291

Epoch: 6| Step: 12
Training loss: 0.776252862921947
Validation loss: 2.540885294475411

Epoch: 6| Step: 13
Training loss: 0.4873320546998829
Validation loss: 2.606078465928447

Epoch: 131| Step: 0
Training loss: 0.6432936374823465
Validation loss: 2.639941576638771

Epoch: 6| Step: 1
Training loss: 0.6020209807038128
Validation loss: 2.579106122992308

Epoch: 6| Step: 2
Training loss: 0.48794492201048395
Validation loss: 2.6402075774293743

Epoch: 6| Step: 3
Training loss: 0.6932700086141781
Validation loss: 2.6200872953446495

Epoch: 6| Step: 4
Training loss: 0.4848837488009129
Validation loss: 2.698204633939492

Epoch: 6| Step: 5
Training loss: 0.28551108348630827
Validation loss: 2.673152313390184

Epoch: 6| Step: 6
Training loss: 0.8274525485306606
Validation loss: 2.661886510478529

Epoch: 6| Step: 7
Training loss: 0.5537095381031149
Validation loss: 2.5605425142337883

Epoch: 6| Step: 8
Training loss: 0.6548532198833557
Validation loss: 2.6128784690388254

Epoch: 6| Step: 9
Training loss: 0.5307498147957865
Validation loss: 2.606600933400632

Epoch: 6| Step: 10
Training loss: 0.5556831021390691
Validation loss: 2.689606764908263

Epoch: 6| Step: 11
Training loss: 0.7941322997970764
Validation loss: 2.6981947079306767

Epoch: 6| Step: 12
Training loss: 0.7019272669475176
Validation loss: 2.6207538200490554

Epoch: 6| Step: 13
Training loss: 1.2703321542193038
Validation loss: 2.6991045090845014

Epoch: 132| Step: 0
Training loss: 0.5800148258287475
Validation loss: 2.6613216004206977

Epoch: 6| Step: 1
Training loss: 0.6657686642627978
Validation loss: 2.6284698381053393

Epoch: 6| Step: 2
Training loss: 0.2648738731425116
Validation loss: 2.6015838759635255

Epoch: 6| Step: 3
Training loss: 0.6129913616847484
Validation loss: 2.5928959493674273

Epoch: 6| Step: 4
Training loss: 0.699334119091132
Validation loss: 2.567885941455676

Epoch: 6| Step: 5
Training loss: 0.7300380314104211
Validation loss: 2.619122320457783

Epoch: 6| Step: 6
Training loss: 0.35004040450801066
Validation loss: 2.582410714279183

Epoch: 6| Step: 7
Training loss: 0.7750991542513794
Validation loss: 2.6281683435543775

Epoch: 6| Step: 8
Training loss: 0.5006556086999528
Validation loss: 2.6492864247824737

Epoch: 6| Step: 9
Training loss: 0.3688437059921656
Validation loss: 2.558405667834577

Epoch: 6| Step: 10
Training loss: 0.6784949748092803
Validation loss: 2.629959976002943

Epoch: 6| Step: 11
Training loss: 0.6034525125336025
Validation loss: 2.6294636241792655

Epoch: 6| Step: 12
Training loss: 1.3276135974707204
Validation loss: 2.6257283093526507

Epoch: 6| Step: 13
Training loss: 0.5147076161940406
Validation loss: 2.621736101935458

Epoch: 133| Step: 0
Training loss: 0.4813029173454481
Validation loss: 2.5562185974181983

Epoch: 6| Step: 1
Training loss: 0.749863135247622
Validation loss: 2.6744868430993525

Epoch: 6| Step: 2
Training loss: 0.6686628873185173
Validation loss: 2.634972098828335

Epoch: 6| Step: 3
Training loss: 0.5283874920283647
Validation loss: 2.6204233842536064

Epoch: 6| Step: 4
Training loss: 0.4873081428848716
Validation loss: 2.5740233498151244

Epoch: 6| Step: 5
Training loss: 0.7782310903759698
Validation loss: 2.6251418665742836

Epoch: 6| Step: 6
Training loss: 0.5218069957351925
Validation loss: 2.5842161797859897

Epoch: 6| Step: 7
Training loss: 1.3263322736009338
Validation loss: 2.6167807343600136

Epoch: 6| Step: 8
Training loss: 0.32343014787066987
Validation loss: 2.6736552459134573

Epoch: 6| Step: 9
Training loss: 0.4722824667932155
Validation loss: 2.6671142401203407

Epoch: 6| Step: 10
Training loss: 0.7519280367542647
Validation loss: 2.6567389393512175

Epoch: 6| Step: 11
Training loss: 0.3598692025224137
Validation loss: 2.6969688891307984

Epoch: 6| Step: 12
Training loss: 0.6844460541928478
Validation loss: 2.621189940005085

Epoch: 6| Step: 13
Training loss: 0.33547884658949506
Validation loss: 2.655332129969585

Epoch: 134| Step: 0
Training loss: 0.5914874133272727
Validation loss: 2.6056511017805133

Epoch: 6| Step: 1
Training loss: 0.49413430733845065
Validation loss: 2.698748343771844

Epoch: 6| Step: 2
Training loss: 0.5402298602331347
Validation loss: 2.6349854072465915

Epoch: 6| Step: 3
Training loss: 0.48214788030601313
Validation loss: 2.6636314080588055

Epoch: 6| Step: 4
Training loss: 1.2844190715273192
Validation loss: 2.6301063266021947

Epoch: 6| Step: 5
Training loss: 0.878932528632752
Validation loss: 2.5888885378212025

Epoch: 6| Step: 6
Training loss: 0.5703278369670304
Validation loss: 2.632465373623907

Epoch: 6| Step: 7
Training loss: 0.5516959906858484
Validation loss: 2.639336943373492

Epoch: 6| Step: 8
Training loss: 0.8241835672544048
Validation loss: 2.58004564355796

Epoch: 6| Step: 9
Training loss: 0.5721909405924152
Validation loss: 2.6217492123037576

Epoch: 6| Step: 10
Training loss: 0.5016191016847832
Validation loss: 2.5908825355570255

Epoch: 6| Step: 11
Training loss: 0.35866794275759356
Validation loss: 2.6355443830540994

Epoch: 6| Step: 12
Training loss: 0.4249016662045168
Validation loss: 2.6892179720153093

Epoch: 6| Step: 13
Training loss: 0.4803894101516964
Validation loss: 2.652722503481258

Epoch: 135| Step: 0
Training loss: 0.5108263227262777
Validation loss: 2.6719944501503208

Epoch: 6| Step: 1
Training loss: 0.7495721550348824
Validation loss: 2.653336516606835

Epoch: 6| Step: 2
Training loss: 0.6057916088069674
Validation loss: 2.647058493639109

Epoch: 6| Step: 3
Training loss: 0.6961293298124634
Validation loss: 2.6451839541217907

Epoch: 6| Step: 4
Training loss: 1.2305743459774314
Validation loss: 2.626657779923847

Epoch: 6| Step: 5
Training loss: 0.48825717103714783
Validation loss: 2.6442532414368416

Epoch: 6| Step: 6
Training loss: 0.4174200181528866
Validation loss: 2.6625124541515226

Epoch: 6| Step: 7
Training loss: 0.7395796887661676
Validation loss: 2.6307112612681705

Epoch: 6| Step: 8
Training loss: 0.6050614248178924
Validation loss: 2.663719446015075

Epoch: 6| Step: 9
Training loss: 0.39972292423223466
Validation loss: 2.6939069464707175

Epoch: 6| Step: 10
Training loss: 0.6743145500008394
Validation loss: 2.765713893230456

Epoch: 6| Step: 11
Training loss: 0.4780171191609538
Validation loss: 2.7135397727408117

Epoch: 6| Step: 12
Training loss: 0.6312323492245183
Validation loss: 2.7128456282265474

Epoch: 6| Step: 13
Training loss: 0.5722352888900325
Validation loss: 2.7252086057930875

Epoch: 136| Step: 0
Training loss: 0.6792344962419162
Validation loss: 2.6858652450965037

Epoch: 6| Step: 1
Training loss: 0.6676486402739008
Validation loss: 2.670007882434006

Epoch: 6| Step: 2
Training loss: 0.7448736470237872
Validation loss: 2.628198431064931

Epoch: 6| Step: 3
Training loss: 0.4614455122992873
Validation loss: 2.6117755788998522

Epoch: 6| Step: 4
Training loss: 0.4344676893125684
Validation loss: 2.620333702078965

Epoch: 6| Step: 5
Training loss: 0.45099502664454416
Validation loss: 2.57212530673993

Epoch: 6| Step: 6
Training loss: 0.6029542206819979
Validation loss: 2.5533730861451036

Epoch: 6| Step: 7
Training loss: 0.4426285690555859
Validation loss: 2.5919183675294373

Epoch: 6| Step: 8
Training loss: 0.5020420277753813
Validation loss: 2.6908433507325467

Epoch: 6| Step: 9
Training loss: 1.1757681202709864
Validation loss: 2.6730017414860368

Epoch: 6| Step: 10
Training loss: 0.7347984716282183
Validation loss: 2.751514140795718

Epoch: 6| Step: 11
Training loss: 0.8216381079706034
Validation loss: 2.71085062171762

Epoch: 6| Step: 12
Training loss: 0.5113994096997241
Validation loss: 2.7015786130213932

Epoch: 6| Step: 13
Training loss: 0.7072592520460919
Validation loss: 2.7408485875256616

Epoch: 137| Step: 0
Training loss: 0.4291069270038691
Validation loss: 2.6419176929069472

Epoch: 6| Step: 1
Training loss: 0.6821139858965146
Validation loss: 2.605164852844639

Epoch: 6| Step: 2
Training loss: 0.4856036508254047
Validation loss: 2.580220582635474

Epoch: 6| Step: 3
Training loss: 0.4741600955592735
Validation loss: 2.5837240436383935

Epoch: 6| Step: 4
Training loss: 0.5693615340012873
Validation loss: 2.5817202690015537

Epoch: 6| Step: 5
Training loss: 0.49937948824091366
Validation loss: 2.638773432654239

Epoch: 6| Step: 6
Training loss: 0.6467929115362888
Validation loss: 2.6538701934356475

Epoch: 6| Step: 7
Training loss: 0.49794771291860834
Validation loss: 2.69192994388117

Epoch: 6| Step: 8
Training loss: 0.5299035568479317
Validation loss: 2.694040132668749

Epoch: 6| Step: 9
Training loss: 0.670700332733545
Validation loss: 2.6565652548014302

Epoch: 6| Step: 10
Training loss: 0.5473793428975698
Validation loss: 2.7072344580302343

Epoch: 6| Step: 11
Training loss: 0.6739206222958037
Validation loss: 2.7197773771715408

Epoch: 6| Step: 12
Training loss: 0.9375826163446991
Validation loss: 2.6908163707817163

Epoch: 6| Step: 13
Training loss: 1.2830301804029272
Validation loss: 2.6605947528004243

Epoch: 138| Step: 0
Training loss: 0.670238119947076
Validation loss: 2.6458300993491606

Epoch: 6| Step: 1
Training loss: 0.9069338881803388
Validation loss: 2.6089374380948547

Epoch: 6| Step: 2
Training loss: 1.1995425703501628
Validation loss: 2.6438771523153712

Epoch: 6| Step: 3
Training loss: 0.2959134441133301
Validation loss: 2.6946133503840266

Epoch: 6| Step: 4
Training loss: 0.7704646457430515
Validation loss: 2.713807432860468

Epoch: 6| Step: 5
Training loss: 0.5926660883574923
Validation loss: 2.7607972272620422

Epoch: 6| Step: 6
Training loss: 0.784147687095165
Validation loss: 2.667124319045194

Epoch: 6| Step: 7
Training loss: 0.7983192371193735
Validation loss: 2.666720677861964

Epoch: 6| Step: 8
Training loss: 0.46703622978059567
Validation loss: 2.595550456076977

Epoch: 6| Step: 9
Training loss: 0.41545898735911313
Validation loss: 2.624236722511557

Epoch: 6| Step: 10
Training loss: 0.7987511931217935
Validation loss: 2.5982260631206335

Epoch: 6| Step: 11
Training loss: 0.4340659311267427
Validation loss: 2.6830836833500995

Epoch: 6| Step: 12
Training loss: 0.603066187545757
Validation loss: 2.6124735269619763

Epoch: 6| Step: 13
Training loss: 0.3811014237673311
Validation loss: 2.6154146481317238

Epoch: 139| Step: 0
Training loss: 0.531027466783801
Validation loss: 2.677568181484993

Epoch: 6| Step: 1
Training loss: 0.7053225191458526
Validation loss: 2.6880032711321364

Epoch: 6| Step: 2
Training loss: 0.43476893996956817
Validation loss: 2.713063991821191

Epoch: 6| Step: 3
Training loss: 0.39870507474520406
Validation loss: 2.6733928183963624

Epoch: 6| Step: 4
Training loss: 0.37526627861843104
Validation loss: 2.5942532767315916

Epoch: 6| Step: 5
Training loss: 0.3769112598316175
Validation loss: 2.526743735578187

Epoch: 6| Step: 6
Training loss: 0.7842715008907152
Validation loss: 2.553895864604638

Epoch: 6| Step: 7
Training loss: 0.5613280113820045
Validation loss: 2.641927890517386

Epoch: 6| Step: 8
Training loss: 0.8166456464735145
Validation loss: 2.5656587004529423

Epoch: 6| Step: 9
Training loss: 1.205416985696451
Validation loss: 2.646311601580395

Epoch: 6| Step: 10
Training loss: 0.40489164086086604
Validation loss: 2.6258665350006716

Epoch: 6| Step: 11
Training loss: 0.5150877725932121
Validation loss: 2.7374607077555533

Epoch: 6| Step: 12
Training loss: 0.7137121614090018
Validation loss: 2.679580804982508

Epoch: 6| Step: 13
Training loss: 0.8255697450478025
Validation loss: 2.6379628954917718

Epoch: 140| Step: 0
Training loss: 0.5142162035238895
Validation loss: 2.6320603500875683

Epoch: 6| Step: 1
Training loss: 0.5161266198866172
Validation loss: 2.64519786462402

Epoch: 6| Step: 2
Training loss: 0.7728399029542258
Validation loss: 2.6180798503873897

Epoch: 6| Step: 3
Training loss: 1.3850131439108608
Validation loss: 2.647219742712314

Epoch: 6| Step: 4
Training loss: 0.516678975584192
Validation loss: 2.620255208701825

Epoch: 6| Step: 5
Training loss: 0.7416112570120191
Validation loss: 2.6301174689482822

Epoch: 6| Step: 6
Training loss: 0.5279190880956519
Validation loss: 2.6195376041045937

Epoch: 6| Step: 7
Training loss: 0.6012250523536523
Validation loss: 2.6880884635196662

Epoch: 6| Step: 8
Training loss: 0.3183219045107001
Validation loss: 2.6472038914420644

Epoch: 6| Step: 9
Training loss: 0.4379870904844634
Validation loss: 2.6364330598505776

Epoch: 6| Step: 10
Training loss: 0.6206667649966953
Validation loss: 2.6698356117762554

Epoch: 6| Step: 11
Training loss: 0.5934297300194672
Validation loss: 2.6864269539246717

Epoch: 6| Step: 12
Training loss: 0.6158144683512191
Validation loss: 2.6704095015179456

Epoch: 6| Step: 13
Training loss: 0.563272793054255
Validation loss: 2.6984372146155686

Epoch: 141| Step: 0
Training loss: 0.7376828468083563
Validation loss: 2.6026892832808475

Epoch: 6| Step: 1
Training loss: 0.26858641003604
Validation loss: 2.637790264410566

Epoch: 6| Step: 2
Training loss: 0.48833231849640907
Validation loss: 2.6754728784633084

Epoch: 6| Step: 3
Training loss: 1.2280219561418846
Validation loss: 2.628855008990545

Epoch: 6| Step: 4
Training loss: 0.627310630142604
Validation loss: 2.6504745526332627

Epoch: 6| Step: 5
Training loss: 0.5863740439227264
Validation loss: 2.654966186241063

Epoch: 6| Step: 6
Training loss: 0.5182456839787042
Validation loss: 2.667602305382534

Epoch: 6| Step: 7
Training loss: 0.6234228261497086
Validation loss: 2.746784165015721

Epoch: 6| Step: 8
Training loss: 0.43815621481151806
Validation loss: 2.7032849038517606

Epoch: 6| Step: 9
Training loss: 0.5501849687096207
Validation loss: 2.742761521065768

Epoch: 6| Step: 10
Training loss: 0.2848463857071594
Validation loss: 2.606942312499078

Epoch: 6| Step: 11
Training loss: 0.5957419460967235
Validation loss: 2.633841429555061

Epoch: 6| Step: 12
Training loss: 0.4644061200328019
Validation loss: 2.5844782988919524

Epoch: 6| Step: 13
Training loss: 0.6116575870654244
Validation loss: 2.629393382708276

Epoch: 142| Step: 0
Training loss: 0.5431781886299815
Validation loss: 2.5645425920842446

Epoch: 6| Step: 1
Training loss: 0.7803761363329016
Validation loss: 2.611839546790015

Epoch: 6| Step: 2
Training loss: 0.3669694293539767
Validation loss: 2.562723103557107

Epoch: 6| Step: 3
Training loss: 0.6395659182369665
Validation loss: 2.667167695978884

Epoch: 6| Step: 4
Training loss: 0.5849047141846005
Validation loss: 2.647748664390504

Epoch: 6| Step: 5
Training loss: 0.35679435884454264
Validation loss: 2.6073858937270415

Epoch: 6| Step: 6
Training loss: 0.33678505680565873
Validation loss: 2.611925732467612

Epoch: 6| Step: 7
Training loss: 0.5818345934547249
Validation loss: 2.65288634408172

Epoch: 6| Step: 8
Training loss: 0.5773136786655024
Validation loss: 2.684267880216095

Epoch: 6| Step: 9
Training loss: 0.5772398280870299
Validation loss: 2.591884761988464

Epoch: 6| Step: 10
Training loss: 1.1977600769307006
Validation loss: 2.6524719072484766

Epoch: 6| Step: 11
Training loss: 0.7170461694092534
Validation loss: 2.585230205266193

Epoch: 6| Step: 12
Training loss: 0.6249860285151028
Validation loss: 2.6484858265596487

Epoch: 6| Step: 13
Training loss: 0.46133441323202634
Validation loss: 2.5448625723076628

Epoch: 143| Step: 0
Training loss: 0.5547806298961493
Validation loss: 2.537559486969709

Epoch: 6| Step: 1
Training loss: 0.6395067363768966
Validation loss: 2.6207545175107994

Epoch: 6| Step: 2
Training loss: 0.5148553884577115
Validation loss: 2.5673700668233335

Epoch: 6| Step: 3
Training loss: 0.4608517098197578
Validation loss: 2.634310159605515

Epoch: 6| Step: 4
Training loss: 0.7659935356196049
Validation loss: 2.6449700746964675

Epoch: 6| Step: 5
Training loss: 0.743635712185265
Validation loss: 2.5545099179203588

Epoch: 6| Step: 6
Training loss: 0.5995280306930741
Validation loss: 2.662399279938464

Epoch: 6| Step: 7
Training loss: 0.5282641819947157
Validation loss: 2.5835021538075464

Epoch: 6| Step: 8
Training loss: 1.147444159202466
Validation loss: 2.6284124506732356

Epoch: 6| Step: 9
Training loss: 0.5501192321284282
Validation loss: 2.6360733410275836

Epoch: 6| Step: 10
Training loss: 0.3805108652167659
Validation loss: 2.6524458703076697

Epoch: 6| Step: 11
Training loss: 0.2788238788429991
Validation loss: 2.6776508417509155

Epoch: 6| Step: 12
Training loss: 0.451964998212919
Validation loss: 2.664058875475792

Epoch: 6| Step: 13
Training loss: 0.3423958788400652
Validation loss: 2.7145351755979727

Epoch: 144| Step: 0
Training loss: 0.5184913208602028
Validation loss: 2.6254193939750183

Epoch: 6| Step: 1
Training loss: 0.5545100882053672
Validation loss: 2.656348911014579

Epoch: 6| Step: 2
Training loss: 1.150853942936997
Validation loss: 2.7679329417876355

Epoch: 6| Step: 3
Training loss: 0.29420155860402447
Validation loss: 2.7323009363313635

Epoch: 6| Step: 4
Training loss: 0.4784452736968637
Validation loss: 2.751206025184219

Epoch: 6| Step: 5
Training loss: 0.7060239793106524
Validation loss: 2.636817911426269

Epoch: 6| Step: 6
Training loss: 0.668113781983823
Validation loss: 2.64856049768739

Epoch: 6| Step: 7
Training loss: 0.6016405228388221
Validation loss: 2.6609346704473587

Epoch: 6| Step: 8
Training loss: 0.4718612100468312
Validation loss: 2.6704212271495233

Epoch: 6| Step: 9
Training loss: 0.598568363672019
Validation loss: 2.638180972953538

Epoch: 6| Step: 10
Training loss: 0.41102187229695286
Validation loss: 2.7312318447740456

Epoch: 6| Step: 11
Training loss: 0.7397135006614118
Validation loss: 2.677340155032226

Epoch: 6| Step: 12
Training loss: 0.41877309109235256
Validation loss: 2.647775828059799

Epoch: 6| Step: 13
Training loss: 0.4512389162134209
Validation loss: 2.6508594717635625

Epoch: 145| Step: 0
Training loss: 0.6528998648553522
Validation loss: 2.668472711599058

Epoch: 6| Step: 1
Training loss: 0.4131991544645619
Validation loss: 2.683079788321144

Epoch: 6| Step: 2
Training loss: 0.6461344345180344
Validation loss: 2.751210668693756

Epoch: 6| Step: 3
Training loss: 0.4377188305577275
Validation loss: 2.6271084839970444

Epoch: 6| Step: 4
Training loss: 0.45978430983075486
Validation loss: 2.643740123853581

Epoch: 6| Step: 5
Training loss: 0.491218551667736
Validation loss: 2.6220261970848537

Epoch: 6| Step: 6
Training loss: 0.5620654069725018
Validation loss: 2.6699469973747965

Epoch: 6| Step: 7
Training loss: 0.3603245381298796
Validation loss: 2.688720765935475

Epoch: 6| Step: 8
Training loss: 1.2120907613964433
Validation loss: 2.6666514773730974

Epoch: 6| Step: 9
Training loss: 0.5241289837952156
Validation loss: 2.661410423987278

Epoch: 6| Step: 10
Training loss: 0.4852527694397107
Validation loss: 2.6135799615476163

Epoch: 6| Step: 11
Training loss: 0.548667694210575
Validation loss: 2.6410825359322536

Epoch: 6| Step: 12
Training loss: 0.4721641816516946
Validation loss: 2.6473546698056345

Epoch: 6| Step: 13
Training loss: 0.6566624707565576
Validation loss: 2.610945299533751

Epoch: 146| Step: 0
Training loss: 0.45039432785483907
Validation loss: 2.6789948927975535

Epoch: 6| Step: 1
Training loss: 0.4530997104822336
Validation loss: 2.6881624041251193

Epoch: 6| Step: 2
Training loss: 0.4802204513951602
Validation loss: 2.6669067235024912

Epoch: 6| Step: 3
Training loss: 0.5089215711958309
Validation loss: 2.6355045188363775

Epoch: 6| Step: 4
Training loss: 1.2588271319519722
Validation loss: 2.6485145205060747

Epoch: 6| Step: 5
Training loss: 0.4324122302901778
Validation loss: 2.6586905842275668

Epoch: 6| Step: 6
Training loss: 0.35564707380818156
Validation loss: 2.620591988744172

Epoch: 6| Step: 7
Training loss: 0.5670544302715251
Validation loss: 2.580763636005038

Epoch: 6| Step: 8
Training loss: 0.6649485791195267
Validation loss: 2.600753704279255

Epoch: 6| Step: 9
Training loss: 0.5957822653308844
Validation loss: 2.6397295304427306

Epoch: 6| Step: 10
Training loss: 0.5151304705634107
Validation loss: 2.6765902816004665

Epoch: 6| Step: 11
Training loss: 0.4334755470062541
Validation loss: 2.727407490285862

Epoch: 6| Step: 12
Training loss: 0.5042591485672092
Validation loss: 2.706508569500526

Epoch: 6| Step: 13
Training loss: 0.4124744840879871
Validation loss: 2.6918431311791147

Epoch: 147| Step: 0
Training loss: 0.43772812413510326
Validation loss: 2.741383027900332

Epoch: 6| Step: 1
Training loss: 0.6394981615429326
Validation loss: 2.6765993375928496

Epoch: 6| Step: 2
Training loss: 0.41496051718284693
Validation loss: 2.6818268654079755

Epoch: 6| Step: 3
Training loss: 0.5145269319252906
Validation loss: 2.657626898443107

Epoch: 6| Step: 4
Training loss: 1.2110113305995844
Validation loss: 2.671930412922508

Epoch: 6| Step: 5
Training loss: 0.6365780587184027
Validation loss: 2.6271829762167833

Epoch: 6| Step: 6
Training loss: 0.46908628798619534
Validation loss: 2.6090310911346464

Epoch: 6| Step: 7
Training loss: 0.5263150955496781
Validation loss: 2.725788782732005

Epoch: 6| Step: 8
Training loss: 0.5114533995826116
Validation loss: 2.693141752344241

Epoch: 6| Step: 9
Training loss: 0.42425195974954977
Validation loss: 2.6580889450989735

Epoch: 6| Step: 10
Training loss: 0.4009125076318208
Validation loss: 2.765652658212872

Epoch: 6| Step: 11
Training loss: 0.5520658460282671
Validation loss: 2.6388155363718697

Epoch: 6| Step: 12
Training loss: 0.8046467594833133
Validation loss: 2.657455604567572

Epoch: 6| Step: 13
Training loss: 0.4785761892177511
Validation loss: 2.6376557067662034

Epoch: 148| Step: 0
Training loss: 0.30024423591486943
Validation loss: 2.6525933471754644

Epoch: 6| Step: 1
Training loss: 0.6123212358833362
Validation loss: 2.756277801015926

Epoch: 6| Step: 2
Training loss: 0.5698907939130504
Validation loss: 2.72550792393372

Epoch: 6| Step: 3
Training loss: 0.6742477879288157
Validation loss: 2.6455940428731837

Epoch: 6| Step: 4
Training loss: 0.3518487824316345
Validation loss: 2.681129297534769

Epoch: 6| Step: 5
Training loss: 1.0980039432781403
Validation loss: 2.664328270088589

Epoch: 6| Step: 6
Training loss: 0.4179727964116247
Validation loss: 2.7156964835886854

Epoch: 6| Step: 7
Training loss: 0.7664311116237037
Validation loss: 2.6569365418254525

Epoch: 6| Step: 8
Training loss: 0.49887835340106407
Validation loss: 2.6398922657899546

Epoch: 6| Step: 9
Training loss: 0.4850484104673496
Validation loss: 2.6113334965751673

Epoch: 6| Step: 10
Training loss: 0.4597045443011712
Validation loss: 2.6468998168838795

Epoch: 6| Step: 11
Training loss: 0.38211897874430134
Validation loss: 2.6654217292586893

Epoch: 6| Step: 12
Training loss: 0.5252921426925787
Validation loss: 2.7122768204810104

Epoch: 6| Step: 13
Training loss: 0.4539740598783869
Validation loss: 2.621189166860724

Epoch: 149| Step: 0
Training loss: 1.0950050238054247
Validation loss: 2.6063284535114946

Epoch: 6| Step: 1
Training loss: 0.5671433486778488
Validation loss: 2.73558381018606

Epoch: 6| Step: 2
Training loss: 0.4223212072330956
Validation loss: 2.710366752413162

Epoch: 6| Step: 3
Training loss: 0.4820338244500804
Validation loss: 2.7030047792370566

Epoch: 6| Step: 4
Training loss: 0.5049113813393212
Validation loss: 2.6876264734597846

Epoch: 6| Step: 5
Training loss: 0.4812175993725707
Validation loss: 2.625154914523365

Epoch: 6| Step: 6
Training loss: 0.5142255344830039
Validation loss: 2.6301424427403175

Epoch: 6| Step: 7
Training loss: 0.37727480588269324
Validation loss: 2.653515144601553

Epoch: 6| Step: 8
Training loss: 0.8297499063876227
Validation loss: 2.634265849430437

Epoch: 6| Step: 9
Training loss: 0.4745638790223618
Validation loss: 2.6343050385186917

Epoch: 6| Step: 10
Training loss: 0.43533953191838504
Validation loss: 2.719356564203801

Epoch: 6| Step: 11
Training loss: 0.5992067457685198
Validation loss: 2.6493834435071255

Epoch: 6| Step: 12
Training loss: 0.31526876779575924
Validation loss: 2.6895374514810175

Epoch: 6| Step: 13
Training loss: 0.32846671430922153
Validation loss: 2.697022268931072

Epoch: 150| Step: 0
Training loss: 0.4849700656481942
Validation loss: 2.6337111361013523

Epoch: 6| Step: 1
Training loss: 0.4377230177983312
Validation loss: 2.628803714077048

Epoch: 6| Step: 2
Training loss: 0.784845395019071
Validation loss: 2.634634155582826

Epoch: 6| Step: 3
Training loss: 1.1767892160617834
Validation loss: 2.660342067627533

Epoch: 6| Step: 4
Training loss: 0.3441085787519125
Validation loss: 2.5854190794641227

Epoch: 6| Step: 5
Training loss: 0.31981706684065714
Validation loss: 2.6681289736444938

Epoch: 6| Step: 6
Training loss: 0.624771767906031
Validation loss: 2.609003645918124

Epoch: 6| Step: 7
Training loss: 0.3608600574659562
Validation loss: 2.67107493894264

Epoch: 6| Step: 8
Training loss: 0.5600623718506775
Validation loss: 2.637724251878493

Epoch: 6| Step: 9
Training loss: 0.6627985875217671
Validation loss: 2.642967952856323

Epoch: 6| Step: 10
Training loss: 0.4996069018531652
Validation loss: 2.7602881971490207

Epoch: 6| Step: 11
Training loss: 0.48409132187642967
Validation loss: 2.7075846346339483

Epoch: 6| Step: 12
Training loss: 0.4214211070857909
Validation loss: 2.704510563367188

Epoch: 6| Step: 13
Training loss: 0.6717223504114835
Validation loss: 2.7380250673997253

Testing loss: 2.347604393764484
