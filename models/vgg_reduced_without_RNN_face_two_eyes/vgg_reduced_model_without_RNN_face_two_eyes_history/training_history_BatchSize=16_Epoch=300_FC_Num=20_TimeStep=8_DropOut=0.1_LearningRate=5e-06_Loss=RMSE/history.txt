Epoch: 1| Step: 0
Training loss: 6.809355123630066
Validation loss: 7.486255003474754

Epoch: 6| Step: 1
Training loss: 7.504695185622236
Validation loss: 7.463633424701097

Epoch: 6| Step: 2
Training loss: 7.59735674819382
Validation loss: 7.437376389958892

Epoch: 6| Step: 3
Training loss: 6.937750184642837
Validation loss: 7.414364218057806

Epoch: 6| Step: 4
Training loss: 7.202421671194175
Validation loss: 7.394721048736807

Epoch: 6| Step: 5
Training loss: 7.543706572375258
Validation loss: 7.370651730517221

Epoch: 6| Step: 6
Training loss: 7.333758890924547
Validation loss: 7.348702999214934

Epoch: 6| Step: 7
Training loss: 6.471419074016376
Validation loss: 7.32593569285441

Epoch: 6| Step: 8
Training loss: 7.6041612877674325
Validation loss: 7.303814198994539

Epoch: 6| Step: 9
Training loss: 7.9927922203712605
Validation loss: 7.282458531141263

Epoch: 6| Step: 10
Training loss: 7.716203153570915
Validation loss: 7.256071332845154

Epoch: 6| Step: 11
Training loss: 7.96801371445299
Validation loss: 7.235629605287443

Epoch: 6| Step: 12
Training loss: 7.841795415628756
Validation loss: 7.212850474674447

Epoch: 6| Step: 13
Training loss: 7.472075803221085
Validation loss: 7.187223169275397

Epoch: 2| Step: 0
Training loss: 6.444070370366266
Validation loss: 7.164991168140719

Epoch: 6| Step: 1
Training loss: 7.6179063663191515
Validation loss: 7.136963999988065

Epoch: 6| Step: 2
Training loss: 7.244741966649335
Validation loss: 7.110951186739511

Epoch: 6| Step: 3
Training loss: 7.5670971729748615
Validation loss: 7.084832096483856

Epoch: 6| Step: 4
Training loss: 7.63045444200115
Validation loss: 7.0574538396428625

Epoch: 6| Step: 5
Training loss: 6.276036162525681
Validation loss: 7.028903055213281

Epoch: 6| Step: 6
Training loss: 7.067900896553098
Validation loss: 6.997855675459835

Epoch: 6| Step: 7
Training loss: 6.959880847130215
Validation loss: 6.971093620492103

Epoch: 6| Step: 8
Training loss: 7.58327210230438
Validation loss: 6.9370498740309845

Epoch: 6| Step: 9
Training loss: 6.783976626373907
Validation loss: 6.9050023489618235

Epoch: 6| Step: 10
Training loss: 7.2478997707215695
Validation loss: 6.867137968067717

Epoch: 6| Step: 11
Training loss: 7.0698341840105625
Validation loss: 6.835596392159138

Epoch: 6| Step: 12
Training loss: 6.628149183805627
Validation loss: 6.796566309441321

Epoch: 6| Step: 13
Training loss: 6.760905745281621
Validation loss: 6.758482183596011

Epoch: 3| Step: 0
Training loss: 6.745982069229738
Validation loss: 6.7181346995992595

Epoch: 6| Step: 1
Training loss: 6.76085383603914
Validation loss: 6.675362978815918

Epoch: 6| Step: 2
Training loss: 7.1336221559230735
Validation loss: 6.632236295428692

Epoch: 6| Step: 3
Training loss: 6.685155725027735
Validation loss: 6.590601743509673

Epoch: 6| Step: 4
Training loss: 7.416836025861802
Validation loss: 6.537641449097651

Epoch: 6| Step: 5
Training loss: 6.78158104435696
Validation loss: 6.487948175432631

Epoch: 6| Step: 6
Training loss: 5.765966720585577
Validation loss: 6.435351510138459

Epoch: 6| Step: 7
Training loss: 6.33542902889967
Validation loss: 6.377320633911424

Epoch: 6| Step: 8
Training loss: 6.151451138124754
Validation loss: 6.3172082244434975

Epoch: 6| Step: 9
Training loss: 6.773735418224813
Validation loss: 6.25658334510262

Epoch: 6| Step: 10
Training loss: 6.309892474677535
Validation loss: 6.1969710539611205

Epoch: 6| Step: 11
Training loss: 5.2549059515902465
Validation loss: 6.121357412041765

Epoch: 6| Step: 12
Training loss: 6.447803732561407
Validation loss: 6.047845491504502

Epoch: 6| Step: 13
Training loss: 5.731066172739446
Validation loss: 5.973626506428542

Epoch: 4| Step: 0
Training loss: 6.896646165529991
Validation loss: 5.884380048985002

Epoch: 6| Step: 1
Training loss: 5.538406828259594
Validation loss: 5.798194563695321

Epoch: 6| Step: 2
Training loss: 5.924142046269232
Validation loss: 5.703691762693345

Epoch: 6| Step: 3
Training loss: 5.365388482667988
Validation loss: 5.602285624869153

Epoch: 6| Step: 4
Training loss: 4.967407813020729
Validation loss: 5.505477980473391

Epoch: 6| Step: 5
Training loss: 4.914177388362866
Validation loss: 5.404216494167542

Epoch: 6| Step: 6
Training loss: 5.47095972376623
Validation loss: 5.2768400240334685

Epoch: 6| Step: 7
Training loss: 5.345171109236047
Validation loss: 5.167522615882463

Epoch: 6| Step: 8
Training loss: 5.0102083899126955
Validation loss: 5.034151618748536

Epoch: 6| Step: 9
Training loss: 4.654164711392003
Validation loss: 4.900062141543425

Epoch: 6| Step: 10
Training loss: 4.722929259581984
Validation loss: 4.757764293006754

Epoch: 6| Step: 11
Training loss: 4.857239477815422
Validation loss: 4.617099371691378

Epoch: 6| Step: 12
Training loss: 4.615425716119329
Validation loss: 4.453697444417609

Epoch: 6| Step: 13
Training loss: 4.862368137170116
Validation loss: 4.31574720411776

Epoch: 5| Step: 0
Training loss: 4.695752826170921
Validation loss: 4.146416084828067

Epoch: 6| Step: 1
Training loss: 3.453732674410616
Validation loss: 3.996232404195823

Epoch: 6| Step: 2
Training loss: 3.9479639189751703
Validation loss: 3.819764205186157

Epoch: 6| Step: 3
Training loss: 4.003578730888022
Validation loss: 3.6610180231460165

Epoch: 6| Step: 4
Training loss: 3.487419132949509
Validation loss: 3.488190596008777

Epoch: 6| Step: 5
Training loss: 3.337310865665186
Validation loss: 3.3509960155245184

Epoch: 6| Step: 6
Training loss: 2.769017439556206
Validation loss: 3.2158339417407498

Epoch: 6| Step: 7
Training loss: 2.991572623160527
Validation loss: 3.093142594329625

Epoch: 6| Step: 8
Training loss: 3.2792837882221004
Validation loss: 2.9927717390468245

Epoch: 6| Step: 9
Training loss: 2.382076962871573
Validation loss: 2.944323008410322

Epoch: 6| Step: 10
Training loss: 2.657948747357462
Validation loss: 2.895430013073515

Epoch: 6| Step: 11
Training loss: 2.453051134686101
Validation loss: 2.8860889207143745

Epoch: 6| Step: 12
Training loss: 3.160362208648869
Validation loss: 2.8845258822779547

Epoch: 6| Step: 13
Training loss: 2.625712888282322
Validation loss: 2.909789811176058

Epoch: 6| Step: 0
Training loss: 2.072303361755834
Validation loss: 2.9834582133946133

Epoch: 6| Step: 1
Training loss: 3.52268483312554
Validation loss: 3.0633774103833935

Epoch: 6| Step: 2
Training loss: 2.819822147253027
Validation loss: 3.085330745746491

Epoch: 6| Step: 3
Training loss: 3.549082602581446
Validation loss: 3.1331066649878494

Epoch: 6| Step: 4
Training loss: 2.7957347058458875
Validation loss: 3.1568291765360224

Epoch: 6| Step: 5
Training loss: 2.794346524244728
Validation loss: 3.1584105446133486

Epoch: 6| Step: 6
Training loss: 3.7412291635633435
Validation loss: 3.1570225264364145

Epoch: 6| Step: 7
Training loss: 3.3908916315814204
Validation loss: 3.1192583489063366

Epoch: 6| Step: 8
Training loss: 2.923359865904062
Validation loss: 3.081618235819394

Epoch: 6| Step: 9
Training loss: 3.306069664462886
Validation loss: 3.0318891238201635

Epoch: 6| Step: 10
Training loss: 3.000549425040657
Validation loss: 2.9701463192990087

Epoch: 6| Step: 11
Training loss: 2.772041764774531
Validation loss: 2.9490591515478983

Epoch: 6| Step: 12
Training loss: 2.590781385903619
Validation loss: 2.912701763755666

Epoch: 6| Step: 13
Training loss: 2.7951280476509286
Validation loss: 2.9069227581629793

Epoch: 7| Step: 0
Training loss: 2.8051807533000974
Validation loss: 2.841845912444715

Epoch: 6| Step: 1
Training loss: 2.5556187230287537
Validation loss: 2.8453906569970506

Epoch: 6| Step: 2
Training loss: 2.511769722855883
Validation loss: 2.8227243017740298

Epoch: 6| Step: 3
Training loss: 2.262304569466025
Validation loss: 2.8375527341986646

Epoch: 6| Step: 4
Training loss: 3.290546725683477
Validation loss: 2.840810674985622

Epoch: 6| Step: 5
Training loss: 2.940801510190524
Validation loss: 2.852543979855149

Epoch: 6| Step: 6
Training loss: 2.160301051882729
Validation loss: 2.848966167283431

Epoch: 6| Step: 7
Training loss: 3.0815339551469547
Validation loss: 2.851607948533277

Epoch: 6| Step: 8
Training loss: 3.756432928369268
Validation loss: 2.8639540564885118

Epoch: 6| Step: 9
Training loss: 2.5772268869501667
Validation loss: 2.8517218000952242

Epoch: 6| Step: 10
Training loss: 2.9229515662707533
Validation loss: 2.8628812461071687

Epoch: 6| Step: 11
Training loss: 2.993911923547022
Validation loss: 2.8693697158209774

Epoch: 6| Step: 12
Training loss: 2.4364731410765645
Validation loss: 2.8487168139379486

Epoch: 6| Step: 13
Training loss: 3.2887094629878453
Validation loss: 2.8386326533209396

Epoch: 8| Step: 0
Training loss: 3.0304835028804344
Validation loss: 2.824273804918987

Epoch: 6| Step: 1
Training loss: 2.7447038282976948
Validation loss: 2.8191692821442818

Epoch: 6| Step: 2
Training loss: 2.8401416060913878
Validation loss: 2.8468885743159174

Epoch: 6| Step: 3
Training loss: 3.1207863437865226
Validation loss: 2.8366520229354597

Epoch: 6| Step: 4
Training loss: 2.2823249687946707
Validation loss: 2.8155624811737474

Epoch: 6| Step: 5
Training loss: 2.5263401025618575
Validation loss: 2.7848870431306962

Epoch: 6| Step: 6
Training loss: 2.267946514003551
Validation loss: 2.8040803554982054

Epoch: 6| Step: 7
Training loss: 3.0246976843220166
Validation loss: 2.795791558201361

Epoch: 6| Step: 8
Training loss: 2.4096750431285465
Validation loss: 2.791667330917355

Epoch: 6| Step: 9
Training loss: 3.6430956925361686
Validation loss: 2.799281883681174

Epoch: 6| Step: 10
Training loss: 2.9478813322036697
Validation loss: 2.8065650768726225

Epoch: 6| Step: 11
Training loss: 2.193523614836739
Validation loss: 2.796618160339411

Epoch: 6| Step: 12
Training loss: 3.807021660717325
Validation loss: 2.7855083426713105

Epoch: 6| Step: 13
Training loss: 1.9933526913820319
Validation loss: 2.7694809608215962

Epoch: 9| Step: 0
Training loss: 2.6234971240176734
Validation loss: 2.781996337534443

Epoch: 6| Step: 1
Training loss: 2.789962836944385
Validation loss: 2.8000650665125444

Epoch: 6| Step: 2
Training loss: 3.246220959168841
Validation loss: 2.8034597700895185

Epoch: 6| Step: 3
Training loss: 2.09735150672054
Validation loss: 2.8087033677937625

Epoch: 6| Step: 4
Training loss: 2.676836371008381
Validation loss: 2.7850785211146944

Epoch: 6| Step: 5
Training loss: 2.97422702909399
Validation loss: 2.7680029120200245

Epoch: 6| Step: 6
Training loss: 2.7182006280885553
Validation loss: 2.779652097211042

Epoch: 6| Step: 7
Training loss: 2.297225510198825
Validation loss: 2.7716430446591507

Epoch: 6| Step: 8
Training loss: 2.6687343051993855
Validation loss: 2.7656328305350906

Epoch: 6| Step: 9
Training loss: 2.9442620870713467
Validation loss: 2.7430680863514048

Epoch: 6| Step: 10
Training loss: 3.1973006724846815
Validation loss: 2.7766610767251754

Epoch: 6| Step: 11
Training loss: 3.0820218123568273
Validation loss: 2.7769274893719595

Epoch: 6| Step: 12
Training loss: 3.129557833411298
Validation loss: 2.7846136148592775

Epoch: 6| Step: 13
Training loss: 2.145446470874351
Validation loss: 2.7679638931385413

Epoch: 10| Step: 0
Training loss: 3.0907220375865325
Validation loss: 2.7769053668046664

Epoch: 6| Step: 1
Training loss: 1.6868906687079124
Validation loss: 2.7774276184209783

Epoch: 6| Step: 2
Training loss: 2.5409780934968444
Validation loss: 2.758658793476732

Epoch: 6| Step: 3
Training loss: 3.0806285920202483
Validation loss: 2.7548456416010794

Epoch: 6| Step: 4
Training loss: 2.0627897810381977
Validation loss: 2.7645988644065675

Epoch: 6| Step: 5
Training loss: 2.3031005568223035
Validation loss: 2.755558220052798

Epoch: 6| Step: 6
Training loss: 3.3197517908911505
Validation loss: 2.7685151309821094

Epoch: 6| Step: 7
Training loss: 3.293107469924369
Validation loss: 2.769543431178585

Epoch: 6| Step: 8
Training loss: 2.8603035508304124
Validation loss: 2.7442094787430618

Epoch: 6| Step: 9
Training loss: 2.673968738455912
Validation loss: 2.768978320166278

Epoch: 6| Step: 10
Training loss: 2.1150286601764807
Validation loss: 2.753491684752784

Epoch: 6| Step: 11
Training loss: 3.0423917211042295
Validation loss: 2.76495590305863

Epoch: 6| Step: 12
Training loss: 2.5764081382432225
Validation loss: 2.7443260700378835

Epoch: 6| Step: 13
Training loss: 3.337312723113168
Validation loss: 2.7669284428611856

Epoch: 11| Step: 0
Training loss: 2.729665307848399
Validation loss: 2.754427986232632

Epoch: 6| Step: 1
Training loss: 2.81143236029322
Validation loss: 2.7257645249047258

Epoch: 6| Step: 2
Training loss: 2.096267098144971
Validation loss: 2.72437671684368

Epoch: 6| Step: 3
Training loss: 2.069557138513637
Validation loss: 2.7259075176003105

Epoch: 6| Step: 4
Training loss: 2.9010425798196686
Validation loss: 2.7435575650915345

Epoch: 6| Step: 5
Training loss: 3.0031731037014664
Validation loss: 2.7185246312064706

Epoch: 6| Step: 6
Training loss: 2.6730340596379194
Validation loss: 2.7308511025164286

Epoch: 6| Step: 7
Training loss: 3.024860372552343
Validation loss: 2.7195499310303437

Epoch: 6| Step: 8
Training loss: 3.193175405633486
Validation loss: 2.726449142475153

Epoch: 6| Step: 9
Training loss: 3.160553368512363
Validation loss: 2.729677870729258

Epoch: 6| Step: 10
Training loss: 2.676718265167543
Validation loss: 2.741367576154565

Epoch: 6| Step: 11
Training loss: 2.4832342635838676
Validation loss: 2.7016261802038537

Epoch: 6| Step: 12
Training loss: 2.591086065219658
Validation loss: 2.710923120641912

Epoch: 6| Step: 13
Training loss: 2.5152701370438697
Validation loss: 2.7200998923247015

Epoch: 12| Step: 0
Training loss: 1.9139066671657052
Validation loss: 2.6968580744194908

Epoch: 6| Step: 1
Training loss: 3.105779361185957
Validation loss: 2.68359283195528

Epoch: 6| Step: 2
Training loss: 3.3212129695781982
Validation loss: 2.715836129067609

Epoch: 6| Step: 3
Training loss: 2.7089886875022002
Validation loss: 2.7028219093526222

Epoch: 6| Step: 4
Training loss: 2.025580960989391
Validation loss: 2.7092846495667318

Epoch: 6| Step: 5
Training loss: 1.5949664989528722
Validation loss: 2.6917801566355113

Epoch: 6| Step: 6
Training loss: 2.6589572349744732
Validation loss: 2.6859767944231097

Epoch: 6| Step: 7
Training loss: 2.9468559450603453
Validation loss: 2.7155028204142626

Epoch: 6| Step: 8
Training loss: 2.2916120580466846
Validation loss: 2.716172117921093

Epoch: 6| Step: 9
Training loss: 3.2060024827744074
Validation loss: 2.713166521515233

Epoch: 6| Step: 10
Training loss: 2.3402072834248107
Validation loss: 2.712433591812016

Epoch: 6| Step: 11
Training loss: 3.197668275081225
Validation loss: 2.7096843039877596

Epoch: 6| Step: 12
Training loss: 3.1951534166351014
Validation loss: 2.693113283049381

Epoch: 6| Step: 13
Training loss: 2.2471318507979468
Validation loss: 2.730018633195496

Epoch: 13| Step: 0
Training loss: 2.6000393827830197
Validation loss: 2.7256929892976824

Epoch: 6| Step: 1
Training loss: 3.0424647568829783
Validation loss: 2.715332323931906

Epoch: 6| Step: 2
Training loss: 2.893071804122074
Validation loss: 2.71392215299269

Epoch: 6| Step: 3
Training loss: 2.2391962707553894
Validation loss: 2.6945955364123413

Epoch: 6| Step: 4
Training loss: 3.1849184240796484
Validation loss: 2.739940189766878

Epoch: 6| Step: 5
Training loss: 1.6501870656177082
Validation loss: 2.7272070238599055

Epoch: 6| Step: 6
Training loss: 2.3082524029514624
Validation loss: 2.7117175501633297

Epoch: 6| Step: 7
Training loss: 2.913880206995094
Validation loss: 2.7160320508074243

Epoch: 6| Step: 8
Training loss: 2.5560487626010646
Validation loss: 2.718080065389367

Epoch: 6| Step: 9
Training loss: 2.128139868864976
Validation loss: 2.7181501055566986

Epoch: 6| Step: 10
Training loss: 3.1825818284895266
Validation loss: 2.6950098724750595

Epoch: 6| Step: 11
Training loss: 2.2538003615657045
Validation loss: 2.70885903073748

Epoch: 6| Step: 12
Training loss: 2.8210513343886716
Validation loss: 2.67567407249521

Epoch: 6| Step: 13
Training loss: 3.057093304638673
Validation loss: 2.6992501801254036

Epoch: 14| Step: 0
Training loss: 2.3004833086814016
Validation loss: 2.7021080706152025

Epoch: 6| Step: 1
Training loss: 3.2870712232727293
Validation loss: 2.689601593979933

Epoch: 6| Step: 2
Training loss: 3.0136861151842758
Validation loss: 2.691962728565437

Epoch: 6| Step: 3
Training loss: 2.419923057278767
Validation loss: 2.6656549938760916

Epoch: 6| Step: 4
Training loss: 2.5138786367227235
Validation loss: 2.6946085724760263

Epoch: 6| Step: 5
Training loss: 3.0179349126654405
Validation loss: 2.678594620316635

Epoch: 6| Step: 6
Training loss: 2.662170991583323
Validation loss: 2.6837314087321964

Epoch: 6| Step: 7
Training loss: 2.0186803563626787
Validation loss: 2.6854254381871607

Epoch: 6| Step: 8
Training loss: 3.5422752904592887
Validation loss: 2.6769445113666883

Epoch: 6| Step: 9
Training loss: 3.037859602626658
Validation loss: 2.678818097337071

Epoch: 6| Step: 10
Training loss: 2.52904753763177
Validation loss: 2.684294822362935

Epoch: 6| Step: 11
Training loss: 2.8090105238296705
Validation loss: 2.713030868944274

Epoch: 6| Step: 12
Training loss: 1.6626694987231385
Validation loss: 2.689841204355915

Epoch: 6| Step: 13
Training loss: 2.0251431732426592
Validation loss: 2.6935145550330986

Epoch: 15| Step: 0
Training loss: 2.3408573865441236
Validation loss: 2.6965642261576965

Epoch: 6| Step: 1
Training loss: 2.308222448759071
Validation loss: 2.676257890632943

Epoch: 6| Step: 2
Training loss: 2.6691839932837977
Validation loss: 2.6860277002089297

Epoch: 6| Step: 3
Training loss: 2.1383452144222366
Validation loss: 2.6678924921995817

Epoch: 6| Step: 4
Training loss: 3.350780191241235
Validation loss: 2.667822279477077

Epoch: 6| Step: 5
Training loss: 2.5881467296625003
Validation loss: 2.695997495728376

Epoch: 6| Step: 6
Training loss: 2.6381490261390943
Validation loss: 2.662032471682063

Epoch: 6| Step: 7
Training loss: 1.8986227941940386
Validation loss: 2.673770968019252

Epoch: 6| Step: 8
Training loss: 2.590140991644644
Validation loss: 2.641304613347045

Epoch: 6| Step: 9
Training loss: 2.814001572630876
Validation loss: 2.6702211552251796

Epoch: 6| Step: 10
Training loss: 3.005546211452222
Validation loss: 2.6633669634173045

Epoch: 6| Step: 11
Training loss: 2.620702313502492
Validation loss: 2.6730498320623424

Epoch: 6| Step: 12
Training loss: 2.4984803349375846
Validation loss: 2.689580969264033

Epoch: 6| Step: 13
Training loss: 2.9859517510841074
Validation loss: 2.6615417128987326

Epoch: 16| Step: 0
Training loss: 2.7314708000687866
Validation loss: 2.645652259177361

Epoch: 6| Step: 1
Training loss: 2.807504413495964
Validation loss: 2.680741039067263

Epoch: 6| Step: 2
Training loss: 3.1356912452553884
Validation loss: 2.6658714767816503

Epoch: 6| Step: 3
Training loss: 2.7571107657800535
Validation loss: 2.642142482428957

Epoch: 6| Step: 4
Training loss: 2.4569446930550645
Validation loss: 2.6734178338367016

Epoch: 6| Step: 5
Training loss: 3.044230560654186
Validation loss: 2.6570731140565513

Epoch: 6| Step: 6
Training loss: 2.3122234694643375
Validation loss: 2.665365845581014

Epoch: 6| Step: 7
Training loss: 3.122477008866268
Validation loss: 2.6508580102364543

Epoch: 6| Step: 8
Training loss: 1.9416285182277815
Validation loss: 2.657390177740179

Epoch: 6| Step: 9
Training loss: 2.4994202895376443
Validation loss: 2.6247883287494322

Epoch: 6| Step: 10
Training loss: 2.1632844373156708
Validation loss: 2.6431418919679373

Epoch: 6| Step: 11
Training loss: 1.7299751628349693
Validation loss: 2.661935578100529

Epoch: 6| Step: 12
Training loss: 3.1391576878806013
Validation loss: 2.6634149444912842

Epoch: 6| Step: 13
Training loss: 2.145167744442013
Validation loss: 2.683875545271219

Epoch: 17| Step: 0
Training loss: 2.3513159131510806
Validation loss: 2.71559641259309

Epoch: 6| Step: 1
Training loss: 1.7246704090762495
Validation loss: 2.6960131043324136

Epoch: 6| Step: 2
Training loss: 3.4830746811716713
Validation loss: 2.7544108620641707

Epoch: 6| Step: 3
Training loss: 2.1373685026712024
Validation loss: 2.7557183834988

Epoch: 6| Step: 4
Training loss: 2.538113742513145
Validation loss: 2.7165574627167723

Epoch: 6| Step: 5
Training loss: 3.223060166448627
Validation loss: 2.753307679690293

Epoch: 6| Step: 6
Training loss: 2.5004462797469555
Validation loss: 2.744162027042505

Epoch: 6| Step: 7
Training loss: 2.022773309637691
Validation loss: 2.7245616986149406

Epoch: 6| Step: 8
Training loss: 2.865360519867173
Validation loss: 2.719026602636078

Epoch: 6| Step: 9
Training loss: 2.064083531840709
Validation loss: 2.696700264996874

Epoch: 6| Step: 10
Training loss: 3.1397676578744758
Validation loss: 2.668169452496203

Epoch: 6| Step: 11
Training loss: 2.8264343941222734
Validation loss: 2.648890258738393

Epoch: 6| Step: 12
Training loss: 2.4066809726547023
Validation loss: 2.654845954966397

Epoch: 6| Step: 13
Training loss: 2.5747337462907365
Validation loss: 2.6480343192009608

Epoch: 18| Step: 0
Training loss: 2.8712149873424733
Validation loss: 2.650872325672398

Epoch: 6| Step: 1
Training loss: 2.517041678203691
Validation loss: 2.6529464973157357

Epoch: 6| Step: 2
Training loss: 2.8847459548351893
Validation loss: 2.659275381491379

Epoch: 6| Step: 3
Training loss: 2.619280442297157
Validation loss: 2.632781967152061

Epoch: 6| Step: 4
Training loss: 2.3661609601872313
Validation loss: 2.6503923191710763

Epoch: 6| Step: 5
Training loss: 2.4404487380146294
Validation loss: 2.661104680183868

Epoch: 6| Step: 6
Training loss: 2.1076193956468368
Validation loss: 2.635460417212207

Epoch: 6| Step: 7
Training loss: 2.9208339529721576
Validation loss: 2.6861232587554333

Epoch: 6| Step: 8
Training loss: 3.6082674779601476
Validation loss: 2.6860842709239723

Epoch: 6| Step: 9
Training loss: 1.9298773915377132
Validation loss: 2.6542974588535277

Epoch: 6| Step: 10
Training loss: 2.1168536947128245
Validation loss: 2.672563482743245

Epoch: 6| Step: 11
Training loss: 2.692356777791699
Validation loss: 2.6343205827588423

Epoch: 6| Step: 12
Training loss: 2.6639626224175323
Validation loss: 2.655396073654232

Epoch: 6| Step: 13
Training loss: 2.6915455022257673
Validation loss: 2.6479228522115674

Epoch: 19| Step: 0
Training loss: 2.7987712207447997
Validation loss: 2.636264971079671

Epoch: 6| Step: 1
Training loss: 2.3937999112575636
Validation loss: 2.653708719563462

Epoch: 6| Step: 2
Training loss: 1.6196576111037855
Validation loss: 2.6203949058706026

Epoch: 6| Step: 3
Training loss: 2.8593132971271142
Validation loss: 2.615837409397177

Epoch: 6| Step: 4
Training loss: 2.257707533986853
Validation loss: 2.6435016109576366

Epoch: 6| Step: 5
Training loss: 2.3924537595228625
Validation loss: 2.6616434280521233

Epoch: 6| Step: 6
Training loss: 2.3990298853639027
Validation loss: 2.645780462702958

Epoch: 6| Step: 7
Training loss: 2.2787801880963423
Validation loss: 2.6850835597025733

Epoch: 6| Step: 8
Training loss: 3.0348575793665464
Validation loss: 2.6906378414543206

Epoch: 6| Step: 9
Training loss: 2.796634685059174
Validation loss: 2.633829857898429

Epoch: 6| Step: 10
Training loss: 3.5519952996197093
Validation loss: 2.66662106375643

Epoch: 6| Step: 11
Training loss: 2.569495352392527
Validation loss: 2.6073396553096857

Epoch: 6| Step: 12
Training loss: 1.8529206779247271
Validation loss: 2.6455898823710258

Epoch: 6| Step: 13
Training loss: 2.6522416332514545
Validation loss: 2.664544652002411

Epoch: 20| Step: 0
Training loss: 2.5462818040017927
Validation loss: 2.689093952486351

Epoch: 6| Step: 1
Training loss: 3.1262732391530856
Validation loss: 2.6706527383085295

Epoch: 6| Step: 2
Training loss: 2.416327639070989
Validation loss: 2.654328672374386

Epoch: 6| Step: 3
Training loss: 2.364570707267852
Validation loss: 2.6477000692416026

Epoch: 6| Step: 4
Training loss: 1.9002774588125786
Validation loss: 2.6713329903148826

Epoch: 6| Step: 5
Training loss: 2.7992133057200927
Validation loss: 2.6975616948164323

Epoch: 6| Step: 6
Training loss: 2.7815242160673512
Validation loss: 2.668860640603515

Epoch: 6| Step: 7
Training loss: 2.8748976647781355
Validation loss: 2.6858866010854365

Epoch: 6| Step: 8
Training loss: 2.1798712540152527
Validation loss: 2.6344226626198215

Epoch: 6| Step: 9
Training loss: 2.511667111638702
Validation loss: 2.671718882857387

Epoch: 6| Step: 10
Training loss: 2.1802378407495655
Validation loss: 2.630774519509339

Epoch: 6| Step: 11
Training loss: 2.905597080187654
Validation loss: 2.636783672522483

Epoch: 6| Step: 12
Training loss: 1.9997273497702603
Validation loss: 2.6455097801639584

Epoch: 6| Step: 13
Training loss: 2.9634902136190395
Validation loss: 2.648019613270187

Epoch: 21| Step: 0
Training loss: 2.535606215033412
Validation loss: 2.6211225239917293

Epoch: 6| Step: 1
Training loss: 2.095975006755298
Validation loss: 2.5832596096676084

Epoch: 6| Step: 2
Training loss: 2.411234758090607
Validation loss: 2.603165019362357

Epoch: 6| Step: 3
Training loss: 2.6866533587041754
Validation loss: 2.5753195555092345

Epoch: 6| Step: 4
Training loss: 2.4906515811664804
Validation loss: 2.6523887544314846

Epoch: 6| Step: 5
Training loss: 2.788960943857462
Validation loss: 2.61632576035821

Epoch: 6| Step: 6
Training loss: 3.181981114761253
Validation loss: 2.6270773554549143

Epoch: 6| Step: 7
Training loss: 2.888562265499901
Validation loss: 2.642185592725875

Epoch: 6| Step: 8
Training loss: 1.918689972873579
Validation loss: 2.6533567641132634

Epoch: 6| Step: 9
Training loss: 2.491281374567728
Validation loss: 2.6685449770121834

Epoch: 6| Step: 10
Training loss: 3.195698833660867
Validation loss: 2.6546944195838873

Epoch: 6| Step: 11
Training loss: 2.5203704619201965
Validation loss: 2.6984811484424243

Epoch: 6| Step: 12
Training loss: 2.3323602236686467
Validation loss: 2.6808289524082496

Epoch: 6| Step: 13
Training loss: 2.1607890245646844
Validation loss: 2.6957611152924246

Epoch: 22| Step: 0
Training loss: 3.3482396297403896
Validation loss: 2.6896309056249783

Epoch: 6| Step: 1
Training loss: 2.052313067232638
Validation loss: 2.625437064342593

Epoch: 6| Step: 2
Training loss: 2.365210585785609
Validation loss: 2.632121198171565

Epoch: 6| Step: 3
Training loss: 2.5795983006232044
Validation loss: 2.6214038572573144

Epoch: 6| Step: 4
Training loss: 2.2504137506473745
Validation loss: 2.5920056525137376

Epoch: 6| Step: 5
Training loss: 2.5972235527193828
Validation loss: 2.6370854327641067

Epoch: 6| Step: 6
Training loss: 2.3975637627516733
Validation loss: 2.6486730330168515

Epoch: 6| Step: 7
Training loss: 2.69090773529117
Validation loss: 2.6583971807132953

Epoch: 6| Step: 8
Training loss: 2.9143589881426033
Validation loss: 2.66453097672035

Epoch: 6| Step: 9
Training loss: 2.5223208575724305
Validation loss: 2.6735930691285077

Epoch: 6| Step: 10
Training loss: 2.8317780059186646
Validation loss: 2.6348428868040474

Epoch: 6| Step: 11
Training loss: 2.276004142073632
Validation loss: 2.6275979764403568

Epoch: 6| Step: 12
Training loss: 3.0417330660605337
Validation loss: 2.619013939471665

Epoch: 6| Step: 13
Training loss: 2.400103757522787
Validation loss: 2.6336161729161143

Epoch: 23| Step: 0
Training loss: 2.2225444745483083
Validation loss: 2.6257057754911983

Epoch: 6| Step: 1
Training loss: 1.9896188969121578
Validation loss: 2.722678244167612

Epoch: 6| Step: 2
Training loss: 2.667612345223655
Validation loss: 2.7645005923559345

Epoch: 6| Step: 3
Training loss: 3.4927161582512505
Validation loss: 2.8584616962188787

Epoch: 6| Step: 4
Training loss: 3.1753638111643134
Validation loss: 2.858950376684172

Epoch: 6| Step: 5
Training loss: 2.807381189130319
Validation loss: 2.821119705456876

Epoch: 6| Step: 6
Training loss: 3.050191942022454
Validation loss: 2.813475404364204

Epoch: 6| Step: 7
Training loss: 2.9615540680297854
Validation loss: 2.723265511762773

Epoch: 6| Step: 8
Training loss: 2.207462450963121
Validation loss: 2.66584738921355

Epoch: 6| Step: 9
Training loss: 2.157802188967433
Validation loss: 2.622085444325615

Epoch: 6| Step: 10
Training loss: 2.1679709494639745
Validation loss: 2.622467908781091

Epoch: 6| Step: 11
Training loss: 2.3754519986148717
Validation loss: 2.628383907669306

Epoch: 6| Step: 12
Training loss: 3.0868703470390058
Validation loss: 2.638973780711008

Epoch: 6| Step: 13
Training loss: 2.849350664554071
Validation loss: 2.65330903546152

Epoch: 24| Step: 0
Training loss: 2.8613701202122996
Validation loss: 2.6222882114564525

Epoch: 6| Step: 1
Training loss: 2.5412790805486862
Validation loss: 2.6392357838040543

Epoch: 6| Step: 2
Training loss: 3.137244079608576
Validation loss: 2.617355675299624

Epoch: 6| Step: 3
Training loss: 2.5871507270707133
Validation loss: 2.636266139237146

Epoch: 6| Step: 4
Training loss: 2.3725737174573283
Validation loss: 2.610686560761839

Epoch: 6| Step: 5
Training loss: 1.926557775090991
Validation loss: 2.617542831060753

Epoch: 6| Step: 6
Training loss: 2.3295991058261434
Validation loss: 2.6143408785763858

Epoch: 6| Step: 7
Training loss: 2.1807650838669406
Validation loss: 2.6400512884677747

Epoch: 6| Step: 8
Training loss: 2.175925779079616
Validation loss: 2.6490196855955315

Epoch: 6| Step: 9
Training loss: 2.6705181402016342
Validation loss: 2.640116475213872

Epoch: 6| Step: 10
Training loss: 3.2746096312850312
Validation loss: 2.638521895627599

Epoch: 6| Step: 11
Training loss: 2.164364129264161
Validation loss: 2.6450969592460813

Epoch: 6| Step: 12
Training loss: 2.7124323612341046
Validation loss: 2.6245605010001265

Epoch: 6| Step: 13
Training loss: 2.4515793906141172
Validation loss: 2.621711336043498

Epoch: 25| Step: 0
Training loss: 2.439695494364944
Validation loss: 2.6256551379149693

Epoch: 6| Step: 1
Training loss: 2.5734901149538416
Validation loss: 2.62249978903402

Epoch: 6| Step: 2
Training loss: 2.943652750340536
Validation loss: 2.606860580703219

Epoch: 6| Step: 3
Training loss: 2.376752909218687
Validation loss: 2.6294969156840398

Epoch: 6| Step: 4
Training loss: 2.8988638921540235
Validation loss: 2.6599134725584985

Epoch: 6| Step: 5
Training loss: 2.8816166907132645
Validation loss: 2.665062963542321

Epoch: 6| Step: 6
Training loss: 2.8007064234741743
Validation loss: 2.619442157422988

Epoch: 6| Step: 7
Training loss: 2.7432158625849685
Validation loss: 2.6059837766412186

Epoch: 6| Step: 8
Training loss: 2.008412787209872
Validation loss: 2.553118800603592

Epoch: 6| Step: 9
Training loss: 2.291979600752348
Validation loss: 2.6063064075101554

Epoch: 6| Step: 10
Training loss: 2.4421389525524995
Validation loss: 2.5944183285215847

Epoch: 6| Step: 11
Training loss: 2.322963240859353
Validation loss: 2.615926896344435

Epoch: 6| Step: 12
Training loss: 2.582333453292847
Validation loss: 2.6038719671712527

Epoch: 6| Step: 13
Training loss: 2.321208125955418
Validation loss: 2.5949562056318283

Epoch: 26| Step: 0
Training loss: 2.795786981629532
Validation loss: 2.6359426453515113

Epoch: 6| Step: 1
Training loss: 2.1824970254954272
Validation loss: 2.606662810250411

Epoch: 6| Step: 2
Training loss: 2.289921622121907
Validation loss: 2.569590984209585

Epoch: 6| Step: 3
Training loss: 2.687747677767707
Validation loss: 2.602740825683441

Epoch: 6| Step: 4
Training loss: 3.0765940930481723
Validation loss: 2.6232847331714266

Epoch: 6| Step: 5
Training loss: 2.594553995190688
Validation loss: 2.6145794147801515

Epoch: 6| Step: 6
Training loss: 2.526561586548517
Validation loss: 2.595669430680757

Epoch: 6| Step: 7
Training loss: 2.1111058798384965
Validation loss: 2.625161499020612

Epoch: 6| Step: 8
Training loss: 2.2471169968803264
Validation loss: 2.6201446224657348

Epoch: 6| Step: 9
Training loss: 2.1689831259367014
Validation loss: 2.6339973326814126

Epoch: 6| Step: 10
Training loss: 2.608072286914604
Validation loss: 2.61831403940896

Epoch: 6| Step: 11
Training loss: 3.0850076167725153
Validation loss: 2.616203722932576

Epoch: 6| Step: 12
Training loss: 1.940509182089254
Validation loss: 2.6136985867523155

Epoch: 6| Step: 13
Training loss: 2.3427834107098056
Validation loss: 2.5972925376100173

Epoch: 27| Step: 0
Training loss: 1.9735196782849678
Validation loss: 2.6276246074162475

Epoch: 6| Step: 1
Training loss: 2.501554673305946
Validation loss: 2.620993159827959

Epoch: 6| Step: 2
Training loss: 2.3696988824699017
Validation loss: 2.5982076953497857

Epoch: 6| Step: 3
Training loss: 2.5258911297699833
Validation loss: 2.6061593989077605

Epoch: 6| Step: 4
Training loss: 2.1780126556365076
Validation loss: 2.5866399773182676

Epoch: 6| Step: 5
Training loss: 2.0042941961603247
Validation loss: 2.601044932709521

Epoch: 6| Step: 6
Training loss: 2.4514777611990617
Validation loss: 2.606084092285051

Epoch: 6| Step: 7
Training loss: 1.9473158237793642
Validation loss: 2.591042051042041

Epoch: 6| Step: 8
Training loss: 2.5041474272316298
Validation loss: 2.5808046691094324

Epoch: 6| Step: 9
Training loss: 3.0620717897576935
Validation loss: 2.6273176769876474

Epoch: 6| Step: 10
Training loss: 2.682885044474555
Validation loss: 2.61103680321177

Epoch: 6| Step: 11
Training loss: 2.9748610391940407
Validation loss: 2.6205671817130853

Epoch: 6| Step: 12
Training loss: 2.790168179737903
Validation loss: 2.6274148490360907

Epoch: 6| Step: 13
Training loss: 2.912104135223321
Validation loss: 2.5853581389371185

Epoch: 28| Step: 0
Training loss: 2.5396770027124886
Validation loss: 2.6005235187728792

Epoch: 6| Step: 1
Training loss: 3.100012403894035
Validation loss: 2.6123815792568013

Epoch: 6| Step: 2
Training loss: 2.0109653284241436
Validation loss: 2.6088258161557336

Epoch: 6| Step: 3
Training loss: 1.9551169041952003
Validation loss: 2.5891082010665443

Epoch: 6| Step: 4
Training loss: 1.8737019178088432
Validation loss: 2.59193234160309

Epoch: 6| Step: 5
Training loss: 2.241471339038916
Validation loss: 2.6022825418842226

Epoch: 6| Step: 6
Training loss: 2.1134838634675437
Validation loss: 2.5872541842203023

Epoch: 6| Step: 7
Training loss: 2.5245831135973593
Validation loss: 2.5873199025501505

Epoch: 6| Step: 8
Training loss: 2.4162784023362116
Validation loss: 2.5895324182351414

Epoch: 6| Step: 9
Training loss: 3.3430548685120076
Validation loss: 2.609692613227204

Epoch: 6| Step: 10
Training loss: 2.3692384402468156
Validation loss: 2.6128976613552277

Epoch: 6| Step: 11
Training loss: 2.3454683235548752
Validation loss: 2.6046326538242965

Epoch: 6| Step: 12
Training loss: 3.268043608039503
Validation loss: 2.581827791463118

Epoch: 6| Step: 13
Training loss: 1.940124211218461
Validation loss: 2.5630978917986944

Epoch: 29| Step: 0
Training loss: 2.5843456704852126
Validation loss: 2.619391231888582

Epoch: 6| Step: 1
Training loss: 1.8120436258264296
Validation loss: 2.5942898690189624

Epoch: 6| Step: 2
Training loss: 2.766886795049825
Validation loss: 2.6127440428330866

Epoch: 6| Step: 3
Training loss: 2.511647367278813
Validation loss: 2.6294504767144824

Epoch: 6| Step: 4
Training loss: 2.648687840335892
Validation loss: 2.6002486369872697

Epoch: 6| Step: 5
Training loss: 2.4147790135592473
Validation loss: 2.588388324598798

Epoch: 6| Step: 6
Training loss: 1.761744327740113
Validation loss: 2.6144240484060406

Epoch: 6| Step: 7
Training loss: 2.3521480401607446
Validation loss: 2.6011169174200504

Epoch: 6| Step: 8
Training loss: 2.9534724601312785
Validation loss: 2.575708478231885

Epoch: 6| Step: 9
Training loss: 2.4560132366345604
Validation loss: 2.5791973157385577

Epoch: 6| Step: 10
Training loss: 2.5747372650622706
Validation loss: 2.634236057489449

Epoch: 6| Step: 11
Training loss: 2.9131659798234937
Validation loss: 2.621608814281026

Epoch: 6| Step: 12
Training loss: 1.9357244908572073
Validation loss: 2.6703986240141906

Epoch: 6| Step: 13
Training loss: 2.958310373423135
Validation loss: 2.6902717964010905

Epoch: 30| Step: 0
Training loss: 1.7169957311596067
Validation loss: 2.676852224940234

Epoch: 6| Step: 1
Training loss: 2.0383231624038642
Validation loss: 2.696487082367154

Epoch: 6| Step: 2
Training loss: 3.1147904513247857
Validation loss: 2.7356761924503745

Epoch: 6| Step: 3
Training loss: 1.7571921377105542
Validation loss: 2.694282828942838

Epoch: 6| Step: 4
Training loss: 2.7909575363531713
Validation loss: 2.697543178515639

Epoch: 6| Step: 5
Training loss: 2.456601734554129
Validation loss: 2.63317809693581

Epoch: 6| Step: 6
Training loss: 2.4200202977298684
Validation loss: 2.6171452001692845

Epoch: 6| Step: 7
Training loss: 2.6754390748368877
Validation loss: 2.6115010902567573

Epoch: 6| Step: 8
Training loss: 2.262319323665208
Validation loss: 2.58391294334984

Epoch: 6| Step: 9
Training loss: 2.6275134088263017
Validation loss: 2.6035229052522695

Epoch: 6| Step: 10
Training loss: 2.7196356547587417
Validation loss: 2.6274911322475805

Epoch: 6| Step: 11
Training loss: 2.4989494023568284
Validation loss: 2.615695645841658

Epoch: 6| Step: 12
Training loss: 2.6622463087546544
Validation loss: 2.5914940579288777

Epoch: 6| Step: 13
Training loss: 3.068760603441616
Validation loss: 2.598273962475075

Epoch: 31| Step: 0
Training loss: 3.0709828816976783
Validation loss: 2.5835768267001615

Epoch: 6| Step: 1
Training loss: 2.3107206355045777
Validation loss: 2.6182664990854256

Epoch: 6| Step: 2
Training loss: 2.23720536662999
Validation loss: 2.615380569637558

Epoch: 6| Step: 3
Training loss: 2.473318291572972
Validation loss: 2.629564449448212

Epoch: 6| Step: 4
Training loss: 2.6154759518395267
Validation loss: 2.662687496812833

Epoch: 6| Step: 5
Training loss: 2.374411058184741
Validation loss: 2.645677912394977

Epoch: 6| Step: 6
Training loss: 2.088209650629675
Validation loss: 2.6557118936652655

Epoch: 6| Step: 7
Training loss: 2.9550403660632925
Validation loss: 2.6784812800057245

Epoch: 6| Step: 8
Training loss: 2.6444172912115427
Validation loss: 2.651133887305121

Epoch: 6| Step: 9
Training loss: 2.4838083448694204
Validation loss: 2.6362201888073633

Epoch: 6| Step: 10
Training loss: 3.016852884885262
Validation loss: 2.627544880032128

Epoch: 6| Step: 11
Training loss: 2.0451627369044165
Validation loss: 2.5758988759013883

Epoch: 6| Step: 12
Training loss: 2.009174997868057
Validation loss: 2.5805690701608373

Epoch: 6| Step: 13
Training loss: 2.2153416634027154
Validation loss: 2.5607157597446046

Epoch: 32| Step: 0
Training loss: 1.6185402487581133
Validation loss: 2.59056132767139

Epoch: 6| Step: 1
Training loss: 2.5432451276703443
Validation loss: 2.570113710641267

Epoch: 6| Step: 2
Training loss: 2.4030953076813857
Validation loss: 2.6122954086186456

Epoch: 6| Step: 3
Training loss: 2.2769504946963277
Validation loss: 2.621404152847151

Epoch: 6| Step: 4
Training loss: 3.676476764449373
Validation loss: 2.5877546089943815

Epoch: 6| Step: 5
Training loss: 2.5492747416120993
Validation loss: 2.588546681287323

Epoch: 6| Step: 6
Training loss: 2.6644988387855695
Validation loss: 2.6021452624299632

Epoch: 6| Step: 7
Training loss: 2.658430035146688
Validation loss: 2.5763850342023953

Epoch: 6| Step: 8
Training loss: 2.2732531285983373
Validation loss: 2.58933337031514

Epoch: 6| Step: 9
Training loss: 2.8082621541798978
Validation loss: 2.585094748678387

Epoch: 6| Step: 10
Training loss: 1.7914868050125794
Validation loss: 2.570744278188123

Epoch: 6| Step: 11
Training loss: 2.198119408776898
Validation loss: 2.579372343162584

Epoch: 6| Step: 12
Training loss: 2.5196470721924933
Validation loss: 2.609313644327425

Epoch: 6| Step: 13
Training loss: 2.0593797605514497
Validation loss: 2.636217671571898

Epoch: 33| Step: 0
Training loss: 2.2800851225439245
Validation loss: 2.647280790231035

Epoch: 6| Step: 1
Training loss: 2.4093952183054492
Validation loss: 2.6500329357475683

Epoch: 6| Step: 2
Training loss: 2.138332949742644
Validation loss: 2.6549823952694056

Epoch: 6| Step: 3
Training loss: 1.6663463125703337
Validation loss: 2.624622726576794

Epoch: 6| Step: 4
Training loss: 2.60820757854242
Validation loss: 2.6673514013542112

Epoch: 6| Step: 5
Training loss: 1.96926927530314
Validation loss: 2.6832207462629807

Epoch: 6| Step: 6
Training loss: 2.739136131154331
Validation loss: 2.6344893008739034

Epoch: 6| Step: 7
Training loss: 2.518838287396434
Validation loss: 2.628575508734496

Epoch: 6| Step: 8
Training loss: 2.610001540201836
Validation loss: 2.6234288736352647

Epoch: 6| Step: 9
Training loss: 2.5025488258194586
Validation loss: 2.6072310817221256

Epoch: 6| Step: 10
Training loss: 3.255689043281838
Validation loss: 2.5765819671432135

Epoch: 6| Step: 11
Training loss: 2.5493418910183516
Validation loss: 2.602370128194422

Epoch: 6| Step: 12
Training loss: 2.6329490558289996
Validation loss: 2.6108756861055484

Epoch: 6| Step: 13
Training loss: 2.588847663543883
Validation loss: 2.593263174430215

Epoch: 34| Step: 0
Training loss: 1.8125040120047529
Validation loss: 2.626638204046005

Epoch: 6| Step: 1
Training loss: 2.50459515739886
Validation loss: 2.595235682511781

Epoch: 6| Step: 2
Training loss: 2.182731881424405
Validation loss: 2.6129735775991385

Epoch: 6| Step: 3
Training loss: 2.0991183110334255
Validation loss: 2.592248413032475

Epoch: 6| Step: 4
Training loss: 2.23302819269323
Validation loss: 2.5987660114528417

Epoch: 6| Step: 5
Training loss: 3.3655071269781502
Validation loss: 2.560285091718271

Epoch: 6| Step: 6
Training loss: 2.669550191015534
Validation loss: 2.6070465236815035

Epoch: 6| Step: 7
Training loss: 2.4647648189620384
Validation loss: 2.589033488186087

Epoch: 6| Step: 8
Training loss: 2.7423250430137793
Validation loss: 2.627893503148593

Epoch: 6| Step: 9
Training loss: 2.6302327271390977
Validation loss: 2.649863040431801

Epoch: 6| Step: 10
Training loss: 2.4337491250685583
Validation loss: 2.6441408335901255

Epoch: 6| Step: 11
Training loss: 2.063904024287992
Validation loss: 2.603913567005601

Epoch: 6| Step: 12
Training loss: 2.9052667082380053
Validation loss: 2.6788143147746135

Epoch: 6| Step: 13
Training loss: 2.0575972575565413
Validation loss: 2.6457222867675716

Epoch: 35| Step: 0
Training loss: 3.0250036633682136
Validation loss: 2.609006303639008

Epoch: 6| Step: 1
Training loss: 2.253177095146923
Validation loss: 2.5794231961006147

Epoch: 6| Step: 2
Training loss: 2.7968801146732214
Validation loss: 2.577597415771606

Epoch: 6| Step: 3
Training loss: 3.197657538403723
Validation loss: 2.621606040499343

Epoch: 6| Step: 4
Training loss: 1.5900164986000342
Validation loss: 2.5678022624097974

Epoch: 6| Step: 5
Training loss: 2.302887604899723
Validation loss: 2.577587757583795

Epoch: 6| Step: 6
Training loss: 2.123702270079235
Validation loss: 2.5776000596267643

Epoch: 6| Step: 7
Training loss: 2.0531496740336235
Validation loss: 2.5842835360559056

Epoch: 6| Step: 8
Training loss: 2.4705383004557033
Validation loss: 2.5472872581785935

Epoch: 6| Step: 9
Training loss: 2.338664730603335
Validation loss: 2.5588271638819924

Epoch: 6| Step: 10
Training loss: 2.7891291762644568
Validation loss: 2.601929158595422

Epoch: 6| Step: 11
Training loss: 2.5603343837626458
Validation loss: 2.5949088116244785

Epoch: 6| Step: 12
Training loss: 1.9343642424005443
Validation loss: 2.5762793822435346

Epoch: 6| Step: 13
Training loss: 2.3122120239755564
Validation loss: 2.610721781182328

Epoch: 36| Step: 0
Training loss: 3.1722775659523137
Validation loss: 2.6243528446341284

Epoch: 6| Step: 1
Training loss: 2.1058641391559445
Validation loss: 2.599660137778582

Epoch: 6| Step: 2
Training loss: 2.0999170831931964
Validation loss: 2.550605086298949

Epoch: 6| Step: 3
Training loss: 3.0501297219627856
Validation loss: 2.5790474984818044

Epoch: 6| Step: 4
Training loss: 2.063895706957301
Validation loss: 2.565615024462073

Epoch: 6| Step: 5
Training loss: 2.0505382575535913
Validation loss: 2.578688203580021

Epoch: 6| Step: 6
Training loss: 2.681972941501788
Validation loss: 2.5810313633280932

Epoch: 6| Step: 7
Training loss: 2.140225115549075
Validation loss: 2.586363297333588

Epoch: 6| Step: 8
Training loss: 3.366241251314044
Validation loss: 2.5847917767303294

Epoch: 6| Step: 9
Training loss: 1.9353066611944914
Validation loss: 2.5630024828244538

Epoch: 6| Step: 10
Training loss: 1.7876049251038708
Validation loss: 2.6273099635660273

Epoch: 6| Step: 11
Training loss: 2.0108410744716316
Validation loss: 2.6430773962386596

Epoch: 6| Step: 12
Training loss: 2.1584879001174904
Validation loss: 2.6596132117215743

Epoch: 6| Step: 13
Training loss: 2.789654922611353
Validation loss: 2.6435557096376243

Epoch: 37| Step: 0
Training loss: 1.915969832531275
Validation loss: 2.6129362166503745

Epoch: 6| Step: 1
Training loss: 2.3951856207541478
Validation loss: 2.6585515840519447

Epoch: 6| Step: 2
Training loss: 2.618437602271581
Validation loss: 2.6317096592622824

Epoch: 6| Step: 3
Training loss: 2.080636020400889
Validation loss: 2.567718882406874

Epoch: 6| Step: 4
Training loss: 2.133798895143249
Validation loss: 2.60682446973702

Epoch: 6| Step: 5
Training loss: 2.0633811224526943
Validation loss: 2.588541001461156

Epoch: 6| Step: 6
Training loss: 3.6368534050913452
Validation loss: 2.611449903351048

Epoch: 6| Step: 7
Training loss: 2.005220751703294
Validation loss: 2.603731810820154

Epoch: 6| Step: 8
Training loss: 2.5929401466237874
Validation loss: 2.589799100971412

Epoch: 6| Step: 9
Training loss: 2.7000089998448455
Validation loss: 2.605464769443291

Epoch: 6| Step: 10
Training loss: 2.196637714100638
Validation loss: 2.5709355303598103

Epoch: 6| Step: 11
Training loss: 2.9004790732515406
Validation loss: 2.6211512825076744

Epoch: 6| Step: 12
Training loss: 2.1602829521781817
Validation loss: 2.590921230581784

Epoch: 6| Step: 13
Training loss: 2.0683358599052806
Validation loss: 2.5738686153183297

Epoch: 38| Step: 0
Training loss: 1.7211089159089097
Validation loss: 2.58998341517005

Epoch: 6| Step: 1
Training loss: 2.5725802820726003
Validation loss: 2.549010740634403

Epoch: 6| Step: 2
Training loss: 2.9131949516561675
Validation loss: 2.6248428963772343

Epoch: 6| Step: 3
Training loss: 2.3854491607807184
Validation loss: 2.5351742438651033

Epoch: 6| Step: 4
Training loss: 2.216326182132375
Validation loss: 2.565656841915285

Epoch: 6| Step: 5
Training loss: 2.540370662857255
Validation loss: 2.5814002762247354

Epoch: 6| Step: 6
Training loss: 2.2030555227159923
Validation loss: 2.6150656530090264

Epoch: 6| Step: 7
Training loss: 2.225255321469323
Validation loss: 2.6164128765615735

Epoch: 6| Step: 8
Training loss: 2.2662249592882597
Validation loss: 2.6755967422320284

Epoch: 6| Step: 9
Training loss: 2.738040581546645
Validation loss: 2.655860109324914

Epoch: 6| Step: 10
Training loss: 3.1181235377984393
Validation loss: 2.667648877115964

Epoch: 6| Step: 11
Training loss: 2.548542717048576
Validation loss: 2.6298502813688795

Epoch: 6| Step: 12
Training loss: 2.532438587826137
Validation loss: 2.6170941540217485

Epoch: 6| Step: 13
Training loss: 1.5538579366546632
Validation loss: 2.5988742200634896

Epoch: 39| Step: 0
Training loss: 2.6361942476008826
Validation loss: 2.57552519445304

Epoch: 6| Step: 1
Training loss: 2.2484303403399735
Validation loss: 2.6020181312261634

Epoch: 6| Step: 2
Training loss: 2.145421133604108
Validation loss: 2.547479046918548

Epoch: 6| Step: 3
Training loss: 2.0703197551096344
Validation loss: 2.568787931361757

Epoch: 6| Step: 4
Training loss: 1.999196487189508
Validation loss: 2.603536122597441

Epoch: 6| Step: 5
Training loss: 2.520703420102551
Validation loss: 2.6133876792169652

Epoch: 6| Step: 6
Training loss: 2.1322295681312973
Validation loss: 2.639141230202143

Epoch: 6| Step: 7
Training loss: 2.4121602782774128
Validation loss: 2.6339668588264735

Epoch: 6| Step: 8
Training loss: 2.389911819491223
Validation loss: 2.575781001317671

Epoch: 6| Step: 9
Training loss: 2.4247811877448164
Validation loss: 2.591577477980136

Epoch: 6| Step: 10
Training loss: 2.794092253814671
Validation loss: 2.6011890070722874

Epoch: 6| Step: 11
Training loss: 2.7392652977281866
Validation loss: 2.631021707497194

Epoch: 6| Step: 12
Training loss: 2.98177044242401
Validation loss: 2.726619453891936

Epoch: 6| Step: 13
Training loss: 2.592473278882772
Validation loss: 2.740581436999925

Epoch: 40| Step: 0
Training loss: 2.427985966260093
Validation loss: 2.72896178158373

Epoch: 6| Step: 1
Training loss: 2.490489895744788
Validation loss: 2.7154636617537817

Epoch: 6| Step: 2
Training loss: 2.7739087201469914
Validation loss: 2.710041861943938

Epoch: 6| Step: 3
Training loss: 2.424435744560865
Validation loss: 2.681394813497945

Epoch: 6| Step: 4
Training loss: 2.645052206321043
Validation loss: 2.6617614862093806

Epoch: 6| Step: 5
Training loss: 2.1571172545798487
Validation loss: 2.6458583490185346

Epoch: 6| Step: 6
Training loss: 2.4545726999382653
Validation loss: 2.6177621618571316

Epoch: 6| Step: 7
Training loss: 2.4557656817723372
Validation loss: 2.616154632968724

Epoch: 6| Step: 8
Training loss: 2.619116320059907
Validation loss: 2.564499299950026

Epoch: 6| Step: 9
Training loss: 2.1650659321178836
Validation loss: 2.5914987806135406

Epoch: 6| Step: 10
Training loss: 2.965077266619115
Validation loss: 2.5937797820438147

Epoch: 6| Step: 11
Training loss: 2.1242496063135086
Validation loss: 2.5943826340517315

Epoch: 6| Step: 12
Training loss: 1.9475174016995291
Validation loss: 2.5890119395348483

Epoch: 6| Step: 13
Training loss: 2.108606269067134
Validation loss: 2.5468803046859696

Epoch: 41| Step: 0
Training loss: 2.59732700641979
Validation loss: 2.5500482242985862

Epoch: 6| Step: 1
Training loss: 1.6259299331714783
Validation loss: 2.5829273079127146

Epoch: 6| Step: 2
Training loss: 3.1713982585553135
Validation loss: 2.585098330203492

Epoch: 6| Step: 3
Training loss: 1.906088900403188
Validation loss: 2.5836943533087418

Epoch: 6| Step: 4
Training loss: 1.9245058986130406
Validation loss: 2.620707847813469

Epoch: 6| Step: 5
Training loss: 2.3838275685964656
Validation loss: 2.556000250730766

Epoch: 6| Step: 6
Training loss: 2.160608282270079
Validation loss: 2.6008221219045344

Epoch: 6| Step: 7
Training loss: 2.9805489025612517
Validation loss: 2.5847322511509723

Epoch: 6| Step: 8
Training loss: 2.7289386877299315
Validation loss: 2.609768165922496

Epoch: 6| Step: 9
Training loss: 2.291659083498344
Validation loss: 2.596783384749074

Epoch: 6| Step: 10
Training loss: 2.772614348850848
Validation loss: 2.598181619315527

Epoch: 6| Step: 11
Training loss: 2.0467670208353823
Validation loss: 2.6060340188090296

Epoch: 6| Step: 12
Training loss: 1.8459201261323706
Validation loss: 2.589039673413962

Epoch: 6| Step: 13
Training loss: 2.4575459679527523
Validation loss: 2.591637252648878

Epoch: 42| Step: 0
Training loss: 2.5792763653311956
Validation loss: 2.5819425120376964

Epoch: 6| Step: 1
Training loss: 2.48522982495934
Validation loss: 2.5945348509675745

Epoch: 6| Step: 2
Training loss: 2.692624462796501
Validation loss: 2.6024038884484186

Epoch: 6| Step: 3
Training loss: 1.8921886314936813
Validation loss: 2.590724344653335

Epoch: 6| Step: 4
Training loss: 1.5273307936331053
Validation loss: 2.5665183001733527

Epoch: 6| Step: 5
Training loss: 3.020561960242508
Validation loss: 2.5694018357555883

Epoch: 6| Step: 6
Training loss: 1.9964744966188308
Validation loss: 2.5586957061876263

Epoch: 6| Step: 7
Training loss: 2.960117196263147
Validation loss: 2.5887850999379

Epoch: 6| Step: 8
Training loss: 2.227978707710035
Validation loss: 2.5760920668650265

Epoch: 6| Step: 9
Training loss: 2.2249090111805083
Validation loss: 2.5507986351460574

Epoch: 6| Step: 10
Training loss: 2.202588604499021
Validation loss: 2.5835702131222225

Epoch: 6| Step: 11
Training loss: 2.596907658377347
Validation loss: 2.5557870316599884

Epoch: 6| Step: 12
Training loss: 2.4186041617968788
Validation loss: 2.5754857743939947

Epoch: 6| Step: 13
Training loss: 1.8665407090038326
Validation loss: 2.5784531201493706

Epoch: 43| Step: 0
Training loss: 1.813671456968944
Validation loss: 2.5867960754038757

Epoch: 6| Step: 1
Training loss: 2.3528075106605
Validation loss: 2.6208580809386546

Epoch: 6| Step: 2
Training loss: 2.396856824664221
Validation loss: 2.654601883550745

Epoch: 6| Step: 3
Training loss: 2.276643360720524
Validation loss: 2.6371508133656096

Epoch: 6| Step: 4
Training loss: 2.039678955434275
Validation loss: 2.599651302894688

Epoch: 6| Step: 5
Training loss: 2.5513826511255813
Validation loss: 2.6687474675877487

Epoch: 6| Step: 6
Training loss: 2.878659117403272
Validation loss: 2.607280934080945

Epoch: 6| Step: 7
Training loss: 2.0385556815212573
Validation loss: 2.624594876650106

Epoch: 6| Step: 8
Training loss: 1.9145370206603485
Validation loss: 2.6098259024207824

Epoch: 6| Step: 9
Training loss: 2.5231781344976385
Validation loss: 2.5519113651387446

Epoch: 6| Step: 10
Training loss: 3.38952745525598
Validation loss: 2.570556319865302

Epoch: 6| Step: 11
Training loss: 2.2325171369384007
Validation loss: 2.5632664069362465

Epoch: 6| Step: 12
Training loss: 2.4750026279011657
Validation loss: 2.53954017254081

Epoch: 6| Step: 13
Training loss: 2.3594693802909927
Validation loss: 2.5880559443805087

Epoch: 44| Step: 0
Training loss: 2.1356236303256417
Validation loss: 2.584299434985533

Epoch: 6| Step: 1
Training loss: 2.258827905118902
Validation loss: 2.595546712915644

Epoch: 6| Step: 2
Training loss: 2.1697305754657843
Validation loss: 2.607056796724469

Epoch: 6| Step: 3
Training loss: 2.160035059255834
Validation loss: 2.5885308698484013

Epoch: 6| Step: 4
Training loss: 2.521624123196985
Validation loss: 2.5672464529192456

Epoch: 6| Step: 5
Training loss: 2.3341449506739798
Validation loss: 2.6044314644019577

Epoch: 6| Step: 6
Training loss: 2.8918423125672663
Validation loss: 2.5953482181204874

Epoch: 6| Step: 7
Training loss: 2.676674263619948
Validation loss: 2.6000271257795036

Epoch: 6| Step: 8
Training loss: 1.8600169123629289
Validation loss: 2.601976562174531

Epoch: 6| Step: 9
Training loss: 2.1037568048830635
Validation loss: 2.5805556889855503

Epoch: 6| Step: 10
Training loss: 2.018218980989082
Validation loss: 2.609953247080297

Epoch: 6| Step: 11
Training loss: 2.422379373513495
Validation loss: 2.559444575282034

Epoch: 6| Step: 12
Training loss: 2.7542230085726405
Validation loss: 2.546518203300779

Epoch: 6| Step: 13
Training loss: 2.4491755285510513
Validation loss: 2.554528218785793

Epoch: 45| Step: 0
Training loss: 2.714733972319628
Validation loss: 2.597468778112344

Epoch: 6| Step: 1
Training loss: 2.024893218627709
Validation loss: 2.5677077710587595

Epoch: 6| Step: 2
Training loss: 2.235431128102857
Validation loss: 2.571030892231914

Epoch: 6| Step: 3
Training loss: 2.7008369773299523
Validation loss: 2.547165805307895

Epoch: 6| Step: 4
Training loss: 2.6893594208837253
Validation loss: 2.5608195090135393

Epoch: 6| Step: 5
Training loss: 2.5322763693339745
Validation loss: 2.527468254249701

Epoch: 6| Step: 6
Training loss: 2.2740563667846856
Validation loss: 2.5501802835749348

Epoch: 6| Step: 7
Training loss: 2.1213722678415237
Validation loss: 2.529191722672441

Epoch: 6| Step: 8
Training loss: 2.792714439498295
Validation loss: 2.5541659725949546

Epoch: 6| Step: 9
Training loss: 2.1986282667126766
Validation loss: 2.580569901670015

Epoch: 6| Step: 10
Training loss: 2.015925895055537
Validation loss: 2.55747921962257

Epoch: 6| Step: 11
Training loss: 2.4666835973347596
Validation loss: 2.586487418687319

Epoch: 6| Step: 12
Training loss: 2.129346329585866
Validation loss: 2.585434871510101

Epoch: 6| Step: 13
Training loss: 2.03295392681403
Validation loss: 2.590770526843319

Epoch: 46| Step: 0
Training loss: 2.2465869660583433
Validation loss: 2.6295310303498325

Epoch: 6| Step: 1
Training loss: 2.318617178924974
Validation loss: 2.624814995800961

Epoch: 6| Step: 2
Training loss: 2.855976357070982
Validation loss: 2.6086591397254946

Epoch: 6| Step: 3
Training loss: 2.490716960745669
Validation loss: 2.545686346910658

Epoch: 6| Step: 4
Training loss: 2.348128234844807
Validation loss: 2.563798761373718

Epoch: 6| Step: 5
Training loss: 2.3494188036416124
Validation loss: 2.5960452177501363

Epoch: 6| Step: 6
Training loss: 2.0446261799703906
Validation loss: 2.584846366261935

Epoch: 6| Step: 7
Training loss: 2.44786674502717
Validation loss: 2.538120803309765

Epoch: 6| Step: 8
Training loss: 1.8608724510681238
Validation loss: 2.5585262377036404

Epoch: 6| Step: 9
Training loss: 2.6332696806381257
Validation loss: 2.5578968603553465

Epoch: 6| Step: 10
Training loss: 2.797262495252491
Validation loss: 2.5517120688136847

Epoch: 6| Step: 11
Training loss: 1.9936037900881
Validation loss: 2.593612713225362

Epoch: 6| Step: 12
Training loss: 2.537017844107684
Validation loss: 2.60195119586929

Epoch: 6| Step: 13
Training loss: 2.2494319622589236
Validation loss: 2.5872047907053406

Epoch: 47| Step: 0
Training loss: 2.7109661705413854
Validation loss: 2.568619654706004

Epoch: 6| Step: 1
Training loss: 2.853876883467682
Validation loss: 2.6032161631044484

Epoch: 6| Step: 2
Training loss: 1.8767850008640798
Validation loss: 2.6279298387081123

Epoch: 6| Step: 3
Training loss: 2.09780218373306
Validation loss: 2.5947917393567352

Epoch: 6| Step: 4
Training loss: 2.557999916178066
Validation loss: 2.6200199571242524

Epoch: 6| Step: 5
Training loss: 2.6528673961296585
Validation loss: 2.584368649543731

Epoch: 6| Step: 6
Training loss: 2.7492930630707906
Validation loss: 2.603741410183728

Epoch: 6| Step: 7
Training loss: 2.1743449704606737
Validation loss: 2.569528755889638

Epoch: 6| Step: 8
Training loss: 2.153608390239679
Validation loss: 2.547496540390426

Epoch: 6| Step: 9
Training loss: 1.8526184676330393
Validation loss: 2.5340417921197336

Epoch: 6| Step: 10
Training loss: 2.5219900036461707
Validation loss: 2.5685262763617662

Epoch: 6| Step: 11
Training loss: 2.7012635806411764
Validation loss: 2.5733683623349375

Epoch: 6| Step: 12
Training loss: 1.6608300132099403
Validation loss: 2.591503687289789

Epoch: 6| Step: 13
Training loss: 2.3565129990861626
Validation loss: 2.5977629140117373

Epoch: 48| Step: 0
Training loss: 2.1138718884932253
Validation loss: 2.575335725792901

Epoch: 6| Step: 1
Training loss: 2.1917197807267708
Validation loss: 2.5889981875952914

Epoch: 6| Step: 2
Training loss: 2.15606500688971
Validation loss: 2.566165055350787

Epoch: 6| Step: 3
Training loss: 1.2468689806035194
Validation loss: 2.5995704424412573

Epoch: 6| Step: 4
Training loss: 2.700204142164587
Validation loss: 2.631834170990247

Epoch: 6| Step: 5
Training loss: 2.239829494935236
Validation loss: 2.6294643495547194

Epoch: 6| Step: 6
Training loss: 1.9378475369732637
Validation loss: 2.6597319874751606

Epoch: 6| Step: 7
Training loss: 2.4947307369514125
Validation loss: 2.63975141773414

Epoch: 6| Step: 8
Training loss: 1.9875244618955765
Validation loss: 2.66206337060358

Epoch: 6| Step: 9
Training loss: 2.6076736842945296
Validation loss: 2.713286672803309

Epoch: 6| Step: 10
Training loss: 2.7716780118390836
Validation loss: 2.6476960020963527

Epoch: 6| Step: 11
Training loss: 2.0426823431680052
Validation loss: 2.6326839819385652

Epoch: 6| Step: 12
Training loss: 2.6259771072540343
Validation loss: 2.6071824477014682

Epoch: 6| Step: 13
Training loss: 2.663182267005486
Validation loss: 2.5525420782174697

Epoch: 49| Step: 0
Training loss: 2.2520884252367734
Validation loss: 2.5461761514338423

Epoch: 6| Step: 1
Training loss: 1.3488976993950386
Validation loss: 2.553730247721168

Epoch: 6| Step: 2
Training loss: 2.3115526269214786
Validation loss: 2.597691792409865

Epoch: 6| Step: 3
Training loss: 2.6608868686520464
Validation loss: 2.574917371899432

Epoch: 6| Step: 4
Training loss: 1.9738955391296045
Validation loss: 2.5514386874494557

Epoch: 6| Step: 5
Training loss: 2.6135025728985544
Validation loss: 2.5631386341004276

Epoch: 6| Step: 6
Training loss: 2.1894250301358684
Validation loss: 2.528002504226796

Epoch: 6| Step: 7
Training loss: 1.602304426330993
Validation loss: 2.532647237812471

Epoch: 6| Step: 8
Training loss: 2.4231390822825176
Validation loss: 2.5616385089499016

Epoch: 6| Step: 9
Training loss: 2.438634950552892
Validation loss: 2.5932028472927517

Epoch: 6| Step: 10
Training loss: 3.03545787593924
Validation loss: 2.685204479238342

Epoch: 6| Step: 11
Training loss: 3.123302761757426
Validation loss: 2.66589703977336

Epoch: 6| Step: 12
Training loss: 2.796421461787075
Validation loss: 2.6562834644079594

Epoch: 6| Step: 13
Training loss: 2.3415693183656088
Validation loss: 2.636867385254099

Epoch: 50| Step: 0
Training loss: 2.6048768156070845
Validation loss: 2.5860429417682753

Epoch: 6| Step: 1
Training loss: 1.6624120846785488
Validation loss: 2.530903058549157

Epoch: 6| Step: 2
Training loss: 2.0410749654950227
Validation loss: 2.5411450418819115

Epoch: 6| Step: 3
Training loss: 2.6263015789938677
Validation loss: 2.5466525988997457

Epoch: 6| Step: 4
Training loss: 1.809549034063542
Validation loss: 2.528693804038706

Epoch: 6| Step: 5
Training loss: 3.0624146741541405
Validation loss: 2.5763648604111937

Epoch: 6| Step: 6
Training loss: 1.936237416038723
Validation loss: 2.537681164718349

Epoch: 6| Step: 7
Training loss: 2.069324646397346
Validation loss: 2.543212191428528

Epoch: 6| Step: 8
Training loss: 2.329520197898484
Validation loss: 2.5513000038675577

Epoch: 6| Step: 9
Training loss: 2.529187810601009
Validation loss: 2.5844798825194966

Epoch: 6| Step: 10
Training loss: 2.686115440523835
Validation loss: 2.5539759462558664

Epoch: 6| Step: 11
Training loss: 1.979439010620986
Validation loss: 2.5594059632927633

Epoch: 6| Step: 12
Training loss: 2.5362412962334098
Validation loss: 2.5960513556592235

Epoch: 6| Step: 13
Training loss: 2.5531592974932966
Validation loss: 2.558687716013168

Epoch: 51| Step: 0
Training loss: 3.0598023658707887
Validation loss: 2.580480682286943

Epoch: 6| Step: 1
Training loss: 2.204441840356567
Validation loss: 2.5530275790842563

Epoch: 6| Step: 2
Training loss: 1.4236486921027958
Validation loss: 2.5421989123356523

Epoch: 6| Step: 3
Training loss: 1.7477775494119363
Validation loss: 2.523569881088644

Epoch: 6| Step: 4
Training loss: 1.5024030033989524
Validation loss: 2.5229751903530246

Epoch: 6| Step: 5
Training loss: 2.4129375317957638
Validation loss: 2.548367739591321

Epoch: 6| Step: 6
Training loss: 3.089293998877255
Validation loss: 2.5399575245427077

Epoch: 6| Step: 7
Training loss: 2.525586798439649
Validation loss: 2.507084361498749

Epoch: 6| Step: 8
Training loss: 2.190434150164034
Validation loss: 2.5531747210052873

Epoch: 6| Step: 9
Training loss: 1.9641955540760445
Validation loss: 2.5700309622417206

Epoch: 6| Step: 10
Training loss: 2.966430721830023
Validation loss: 2.6006581335471295

Epoch: 6| Step: 11
Training loss: 2.559765822458456
Validation loss: 2.5093629348230473

Epoch: 6| Step: 12
Training loss: 1.8590372243584292
Validation loss: 2.599300313605657

Epoch: 6| Step: 13
Training loss: 2.091944357181252
Validation loss: 2.6456204176010796

Epoch: 52| Step: 0
Training loss: 1.774858821036193
Validation loss: 2.634232293875971

Epoch: 6| Step: 1
Training loss: 2.9237535934784957
Validation loss: 2.682177099849006

Epoch: 6| Step: 2
Training loss: 2.964466578600961
Validation loss: 2.6230352557226286

Epoch: 6| Step: 3
Training loss: 2.439713084752608
Validation loss: 2.565251044442906

Epoch: 6| Step: 4
Training loss: 1.9089354688149445
Validation loss: 2.544667947337936

Epoch: 6| Step: 5
Training loss: 1.942655840480715
Validation loss: 2.569493651276887

Epoch: 6| Step: 6
Training loss: 1.54620824759014
Validation loss: 2.520841383067328

Epoch: 6| Step: 7
Training loss: 2.2956180376943793
Validation loss: 2.5779466047121353

Epoch: 6| Step: 8
Training loss: 1.7744771455962824
Validation loss: 2.556351783547909

Epoch: 6| Step: 9
Training loss: 2.629848725062228
Validation loss: 2.528136909623419

Epoch: 6| Step: 10
Training loss: 2.636407768842768
Validation loss: 2.5624449344083873

Epoch: 6| Step: 11
Training loss: 2.818287299299275
Validation loss: 2.569691174205411

Epoch: 6| Step: 12
Training loss: 2.286327824673225
Validation loss: 2.5621983730536604

Epoch: 6| Step: 13
Training loss: 2.044244138377322
Validation loss: 2.541691019118749

Epoch: 53| Step: 0
Training loss: 2.460641994596884
Validation loss: 2.6071365562283195

Epoch: 6| Step: 1
Training loss: 1.675030733652132
Validation loss: 2.5398119793534573

Epoch: 6| Step: 2
Training loss: 2.146655644256221
Validation loss: 2.6039693045533174

Epoch: 6| Step: 3
Training loss: 2.121315173539925
Validation loss: 2.665017308339399

Epoch: 6| Step: 4
Training loss: 2.3208928779163718
Validation loss: 2.693628863379018

Epoch: 6| Step: 5
Training loss: 3.2823698040374034
Validation loss: 2.649527461428726

Epoch: 6| Step: 6
Training loss: 2.540458694401506
Validation loss: 2.623715692022926

Epoch: 6| Step: 7
Training loss: 1.694236026863341
Validation loss: 2.5279464985592237

Epoch: 6| Step: 8
Training loss: 1.9521129580122236
Validation loss: 2.521054428955573

Epoch: 6| Step: 9
Training loss: 2.4034544323354643
Validation loss: 2.4874284162077616

Epoch: 6| Step: 10
Training loss: 2.95157190889845
Validation loss: 2.5760917120881297

Epoch: 6| Step: 11
Training loss: 2.6220375783571246
Validation loss: 2.5778539649987984

Epoch: 6| Step: 12
Training loss: 2.511836356202485
Validation loss: 2.5856151783299968

Epoch: 6| Step: 13
Training loss: 2.077147289682922
Validation loss: 2.560548597578201

Epoch: 54| Step: 0
Training loss: 1.9992994035057376
Validation loss: 2.5557343091045537

Epoch: 6| Step: 1
Training loss: 2.160302817699444
Validation loss: 2.5427553211346883

Epoch: 6| Step: 2
Training loss: 2.7358495605557636
Validation loss: 2.533067913853787

Epoch: 6| Step: 3
Training loss: 2.2531878881897227
Validation loss: 2.5995821054558337

Epoch: 6| Step: 4
Training loss: 2.4288072371401412
Validation loss: 2.656265453218874

Epoch: 6| Step: 5
Training loss: 1.7837937245025577
Validation loss: 2.6469618100369425

Epoch: 6| Step: 6
Training loss: 2.6268197064748673
Validation loss: 2.651524727709103

Epoch: 6| Step: 7
Training loss: 2.4435748181395436
Validation loss: 2.674769568099585

Epoch: 6| Step: 8
Training loss: 1.7064970738866192
Validation loss: 2.6471414311095645

Epoch: 6| Step: 9
Training loss: 2.329903045241546
Validation loss: 2.648527505821224

Epoch: 6| Step: 10
Training loss: 2.1332940197342207
Validation loss: 2.606683321210173

Epoch: 6| Step: 11
Training loss: 3.017362262202254
Validation loss: 2.5437088303042303

Epoch: 6| Step: 12
Training loss: 2.2710860108885704
Validation loss: 2.505383686952694

Epoch: 6| Step: 13
Training loss: 2.0760720804082253
Validation loss: 2.482511497258367

Epoch: 55| Step: 0
Training loss: 2.8019354874606077
Validation loss: 2.5644750814473634

Epoch: 6| Step: 1
Training loss: 2.1766072046162246
Validation loss: 2.563512873316743

Epoch: 6| Step: 2
Training loss: 2.5463230962659456
Validation loss: 2.519732618540239

Epoch: 6| Step: 3
Training loss: 1.8259208629084587
Validation loss: 2.546853141456837

Epoch: 6| Step: 4
Training loss: 2.3776423161187297
Validation loss: 2.5730391613505037

Epoch: 6| Step: 5
Training loss: 1.753810412670802
Validation loss: 2.5519429434224747

Epoch: 6| Step: 6
Training loss: 2.144325566112545
Validation loss: 2.5612741344897914

Epoch: 6| Step: 7
Training loss: 1.992119582271348
Validation loss: 2.553326569922564

Epoch: 6| Step: 8
Training loss: 2.1016663025813602
Validation loss: 2.516786358578609

Epoch: 6| Step: 9
Training loss: 2.54870810975228
Validation loss: 2.598022205704254

Epoch: 6| Step: 10
Training loss: 2.009830277332606
Validation loss: 2.5716265534070044

Epoch: 6| Step: 11
Training loss: 3.0357830328329665
Validation loss: 2.6166652936587607

Epoch: 6| Step: 12
Training loss: 1.7556935742336202
Validation loss: 2.5841036591469853

Epoch: 6| Step: 13
Training loss: 2.44666192112323
Validation loss: 2.5758857712786334

Epoch: 56| Step: 0
Training loss: 2.394259015736609
Validation loss: 2.597945057199645

Epoch: 6| Step: 1
Training loss: 3.0175405160479967
Validation loss: 2.602115011111468

Epoch: 6| Step: 2
Training loss: 2.3138545425184156
Validation loss: 2.5697311006626613

Epoch: 6| Step: 3
Training loss: 2.6077840374947
Validation loss: 2.573870900201471

Epoch: 6| Step: 4
Training loss: 2.001862969578214
Validation loss: 2.531463033243621

Epoch: 6| Step: 5
Training loss: 1.8188190801026995
Validation loss: 2.5575260487432785

Epoch: 6| Step: 6
Training loss: 2.1728293977099846
Validation loss: 2.593215412369784

Epoch: 6| Step: 7
Training loss: 2.2188195231116383
Validation loss: 2.5068487611112484

Epoch: 6| Step: 8
Training loss: 1.909590124320298
Validation loss: 2.4941357418640813

Epoch: 6| Step: 9
Training loss: 2.194337458624862
Validation loss: 2.5355641057054834

Epoch: 6| Step: 10
Training loss: 2.7445688368354277
Validation loss: 2.5192930123708885

Epoch: 6| Step: 11
Training loss: 1.97185731326724
Validation loss: 2.5639369316279295

Epoch: 6| Step: 12
Training loss: 2.1680747616254084
Validation loss: 2.554308008594695

Epoch: 6| Step: 13
Training loss: 1.828066311407715
Validation loss: 2.5722491110057013

Epoch: 57| Step: 0
Training loss: 2.04734575522027
Validation loss: 2.5462709736447913

Epoch: 6| Step: 1
Training loss: 2.3929169084124937
Validation loss: 2.598586632414891

Epoch: 6| Step: 2
Training loss: 2.30370617680464
Validation loss: 2.5854023420955

Epoch: 6| Step: 3
Training loss: 2.7363948664125943
Validation loss: 2.6290286197683734

Epoch: 6| Step: 4
Training loss: 3.1854172428214578
Validation loss: 2.5922371768924277

Epoch: 6| Step: 5
Training loss: 2.01339551063341
Validation loss: 2.5986502597953764

Epoch: 6| Step: 6
Training loss: 2.092004304462038
Validation loss: 2.597713513806777

Epoch: 6| Step: 7
Training loss: 2.006940244019838
Validation loss: 2.578340941354006

Epoch: 6| Step: 8
Training loss: 2.268476283688724
Validation loss: 2.541623276720573

Epoch: 6| Step: 9
Training loss: 2.081400877836322
Validation loss: 2.5388656305137687

Epoch: 6| Step: 10
Training loss: 2.234528222865887
Validation loss: 2.533879315577211

Epoch: 6| Step: 11
Training loss: 1.904214992229948
Validation loss: 2.5694144244344828

Epoch: 6| Step: 12
Training loss: 2.066702520408133
Validation loss: 2.5524949085758952

Epoch: 6| Step: 13
Training loss: 2.31812262672021
Validation loss: 2.555538164185581

Epoch: 58| Step: 0
Training loss: 2.9605221419277106
Validation loss: 2.5160881548075493

Epoch: 6| Step: 1
Training loss: 2.0345312758746688
Validation loss: 2.5483332634679043

Epoch: 6| Step: 2
Training loss: 2.4598989081351754
Validation loss: 2.5044101598823048

Epoch: 6| Step: 3
Training loss: 2.647923242384226
Validation loss: 2.5567891286875475

Epoch: 6| Step: 4
Training loss: 2.2640863916204044
Validation loss: 2.5870871854968356

Epoch: 6| Step: 5
Training loss: 1.7703906534423126
Validation loss: 2.522592471960518

Epoch: 6| Step: 6
Training loss: 2.615921762054754
Validation loss: 2.5269564882685454

Epoch: 6| Step: 7
Training loss: 1.6959720857860192
Validation loss: 2.52110800284451

Epoch: 6| Step: 8
Training loss: 1.8159456715082385
Validation loss: 2.5786573226529956

Epoch: 6| Step: 9
Training loss: 2.139285371481506
Validation loss: 2.5366026088615063

Epoch: 6| Step: 10
Training loss: 2.963144571866884
Validation loss: 2.596007731800879

Epoch: 6| Step: 11
Training loss: 1.459891123043341
Validation loss: 2.6152168864016088

Epoch: 6| Step: 12
Training loss: 1.4494959316821605
Validation loss: 2.6164600405133283

Epoch: 6| Step: 13
Training loss: 2.379813686739731
Validation loss: 2.6698543648880766

Epoch: 59| Step: 0
Training loss: 1.9990719191612707
Validation loss: 2.6664539838456824

Epoch: 6| Step: 1
Training loss: 1.8280321407372353
Validation loss: 2.60277439792576

Epoch: 6| Step: 2
Training loss: 2.185886114687652
Validation loss: 2.555595135612633

Epoch: 6| Step: 3
Training loss: 2.1892361971594396
Validation loss: 2.5922796379026307

Epoch: 6| Step: 4
Training loss: 2.079867672012105
Validation loss: 2.5142670593431475

Epoch: 6| Step: 5
Training loss: 2.15869554796665
Validation loss: 2.4703778883378877

Epoch: 6| Step: 6
Training loss: 2.7426881686313416
Validation loss: 2.52513745566418

Epoch: 6| Step: 7
Training loss: 2.8349259519241534
Validation loss: 2.5879762417048155

Epoch: 6| Step: 8
Training loss: 1.8727360090538478
Validation loss: 2.5458006826035375

Epoch: 6| Step: 9
Training loss: 1.9257146425315588
Validation loss: 2.5457344543767575

Epoch: 6| Step: 10
Training loss: 2.2949507561347575
Validation loss: 2.561997697802861

Epoch: 6| Step: 11
Training loss: 2.9972932048410166
Validation loss: 2.5622471630378367

Epoch: 6| Step: 12
Training loss: 1.9603673706451081
Validation loss: 2.568113041077261

Epoch: 6| Step: 13
Training loss: 1.9757232693709383
Validation loss: 2.577064773957371

Epoch: 60| Step: 0
Training loss: 2.034374357771296
Validation loss: 2.546657092673928

Epoch: 6| Step: 1
Training loss: 2.735341190208155
Validation loss: 2.571566545383833

Epoch: 6| Step: 2
Training loss: 2.7774056429076266
Validation loss: 2.5511645369394254

Epoch: 6| Step: 3
Training loss: 1.927222155820268
Validation loss: 2.55750676718196

Epoch: 6| Step: 4
Training loss: 2.595504351282119
Validation loss: 2.5453256680479908

Epoch: 6| Step: 5
Training loss: 2.045363006084777
Validation loss: 2.566165643771301

Epoch: 6| Step: 6
Training loss: 2.4444008002093702
Validation loss: 2.6412907801288914

Epoch: 6| Step: 7
Training loss: 2.2874920245589174
Validation loss: 2.603062881516227

Epoch: 6| Step: 8
Training loss: 1.950229604359407
Validation loss: 2.639121257578834

Epoch: 6| Step: 9
Training loss: 2.2546373897067618
Validation loss: 2.6649735758260484

Epoch: 6| Step: 10
Training loss: 1.8901112386473606
Validation loss: 2.5672442240532263

Epoch: 6| Step: 11
Training loss: 2.0408152796781542
Validation loss: 2.585669005132243

Epoch: 6| Step: 12
Training loss: 2.079494856604021
Validation loss: 2.5754748199847435

Epoch: 6| Step: 13
Training loss: 2.4691931411331502
Validation loss: 2.5625541650273336

Epoch: 61| Step: 0
Training loss: 2.0834910015207573
Validation loss: 2.533222920956367

Epoch: 6| Step: 1
Training loss: 2.5902358919040576
Validation loss: 2.5879664456758498

Epoch: 6| Step: 2
Training loss: 2.1701763288871057
Validation loss: 2.538926591414689

Epoch: 6| Step: 3
Training loss: 2.4892694975083725
Validation loss: 2.5118400896425443

Epoch: 6| Step: 4
Training loss: 2.4300277815121576
Validation loss: 2.5880843180020263

Epoch: 6| Step: 5
Training loss: 1.5394474071056747
Validation loss: 2.526732679937322

Epoch: 6| Step: 6
Training loss: 1.9192992527038204
Validation loss: 2.5750701839178407

Epoch: 6| Step: 7
Training loss: 1.5700173931008796
Validation loss: 2.5802873887071427

Epoch: 6| Step: 8
Training loss: 2.0761448884432023
Validation loss: 2.6127897597732663

Epoch: 6| Step: 9
Training loss: 2.359628625841806
Validation loss: 2.629932749194211

Epoch: 6| Step: 10
Training loss: 3.185363651996265
Validation loss: 2.605064989915716

Epoch: 6| Step: 11
Training loss: 2.0839660700929916
Validation loss: 2.608779123457794

Epoch: 6| Step: 12
Training loss: 2.0617556529267693
Validation loss: 2.552171313786947

Epoch: 6| Step: 13
Training loss: 2.670139842425241
Validation loss: 2.566425046653562

Epoch: 62| Step: 0
Training loss: 2.162274996126652
Validation loss: 2.5614405667212536

Epoch: 6| Step: 1
Training loss: 1.8703034390363091
Validation loss: 2.531569409723776

Epoch: 6| Step: 2
Training loss: 2.8795849273181187
Validation loss: 2.569361270096752

Epoch: 6| Step: 3
Training loss: 2.0447922221911923
Validation loss: 2.5463996240734414

Epoch: 6| Step: 4
Training loss: 1.7871703424112066
Validation loss: 2.5921359114737874

Epoch: 6| Step: 5
Training loss: 2.799396081918726
Validation loss: 2.5459778342519477

Epoch: 6| Step: 6
Training loss: 2.4565839739390967
Validation loss: 2.5444521623001135

Epoch: 6| Step: 7
Training loss: 1.9650338841203139
Validation loss: 2.501433327187348

Epoch: 6| Step: 8
Training loss: 2.0251730762504057
Validation loss: 2.5329820334982927

Epoch: 6| Step: 9
Training loss: 2.384042491201345
Validation loss: 2.5997848394205283

Epoch: 6| Step: 10
Training loss: 2.1592086175837775
Validation loss: 2.57207929959319

Epoch: 6| Step: 11
Training loss: 2.1826000375095234
Validation loss: 2.5471103458063182

Epoch: 6| Step: 12
Training loss: 1.4780754935944254
Validation loss: 2.5543326812939777

Epoch: 6| Step: 13
Training loss: 2.4079754080546376
Validation loss: 2.5942465831514383

Epoch: 63| Step: 0
Training loss: 1.7669113334641602
Validation loss: 2.540874800810252

Epoch: 6| Step: 1
Training loss: 2.0751274115729554
Validation loss: 2.6266954108866485

Epoch: 6| Step: 2
Training loss: 2.3325170269801556
Validation loss: 2.5987952620133656

Epoch: 6| Step: 3
Training loss: 1.4819183901866324
Validation loss: 2.5935850129259084

Epoch: 6| Step: 4
Training loss: 2.403246305303532
Validation loss: 2.5130046995498265

Epoch: 6| Step: 5
Training loss: 1.9730528782111454
Validation loss: 2.529299490791058

Epoch: 6| Step: 6
Training loss: 2.200532727331638
Validation loss: 2.585769171484781

Epoch: 6| Step: 7
Training loss: 2.0000634183365698
Validation loss: 2.529086503125857

Epoch: 6| Step: 8
Training loss: 2.3001526781905284
Validation loss: 2.505481797570835

Epoch: 6| Step: 9
Training loss: 2.6245966101823
Validation loss: 2.5221667953269686

Epoch: 6| Step: 10
Training loss: 1.9626327421160652
Validation loss: 2.555464289136628

Epoch: 6| Step: 11
Training loss: 2.8609131391687104
Validation loss: 2.5887314684008245

Epoch: 6| Step: 12
Training loss: 1.9539808305602435
Validation loss: 2.615682049383215

Epoch: 6| Step: 13
Training loss: 2.6285824625897276
Validation loss: 2.5900604326176664

Epoch: 64| Step: 0
Training loss: 2.3307617412542685
Validation loss: 2.627189812757323

Epoch: 6| Step: 1
Training loss: 2.486683474766002
Validation loss: 2.5887751074260614

Epoch: 6| Step: 2
Training loss: 2.2857797668648314
Validation loss: 2.540786267582099

Epoch: 6| Step: 3
Training loss: 1.7862862447554464
Validation loss: 2.5602971276938806

Epoch: 6| Step: 4
Training loss: 2.8550926618353416
Validation loss: 2.5680674107756287

Epoch: 6| Step: 5
Training loss: 2.405378109400293
Validation loss: 2.5901425487978766

Epoch: 6| Step: 6
Training loss: 2.087597590009852
Validation loss: 2.516533650005076

Epoch: 6| Step: 7
Training loss: 1.8776287724491512
Validation loss: 2.5500469776887633

Epoch: 6| Step: 8
Training loss: 2.1092165286971367
Validation loss: 2.6025467424595488

Epoch: 6| Step: 9
Training loss: 2.059380455183523
Validation loss: 2.5745346500675015

Epoch: 6| Step: 10
Training loss: 2.0246307507342785
Validation loss: 2.5183510551948327

Epoch: 6| Step: 11
Training loss: 2.1056717755270458
Validation loss: 2.513194084454397

Epoch: 6| Step: 12
Training loss: 2.5291778182947033
Validation loss: 2.556635387192838

Epoch: 6| Step: 13
Training loss: 2.035350944007199
Validation loss: 2.557592297899368

Epoch: 65| Step: 0
Training loss: 2.486296480491377
Validation loss: 2.628369893061863

Epoch: 6| Step: 1
Training loss: 2.475711230957798
Validation loss: 2.591234925749613

Epoch: 6| Step: 2
Training loss: 2.0016953911839117
Validation loss: 2.525529291683316

Epoch: 6| Step: 3
Training loss: 1.7829023360303244
Validation loss: 2.5619010690561854

Epoch: 6| Step: 4
Training loss: 2.430374882355934
Validation loss: 2.551259983659368

Epoch: 6| Step: 5
Training loss: 1.8579801568818488
Validation loss: 2.565680662070971

Epoch: 6| Step: 6
Training loss: 2.406949226544382
Validation loss: 2.537942414325112

Epoch: 6| Step: 7
Training loss: 2.6342605547860503
Validation loss: 2.5581870185273954

Epoch: 6| Step: 8
Training loss: 1.797349949968388
Validation loss: 2.520149703107878

Epoch: 6| Step: 9
Training loss: 2.480487493008665
Validation loss: 2.534666651867073

Epoch: 6| Step: 10
Training loss: 1.715934458688053
Validation loss: 2.5870142881649882

Epoch: 6| Step: 11
Training loss: 1.6442731713693322
Validation loss: 2.714219934161181

Epoch: 6| Step: 12
Training loss: 2.0602740211081687
Validation loss: 2.7828401741595186

Epoch: 6| Step: 13
Training loss: 2.900446193175601
Validation loss: 2.8538764936049947

Epoch: 66| Step: 0
Training loss: 3.1402274871837945
Validation loss: 2.8279883209416306

Epoch: 6| Step: 1
Training loss: 2.9892710523738972
Validation loss: 2.7707952673646807

Epoch: 6| Step: 2
Training loss: 1.5478123608748344
Validation loss: 2.6210940986856683

Epoch: 6| Step: 3
Training loss: 2.019185197057434
Validation loss: 2.541219083013447

Epoch: 6| Step: 4
Training loss: 2.004517579106022
Validation loss: 2.554389072918003

Epoch: 6| Step: 5
Training loss: 1.911945901025572
Validation loss: 2.5927531000310737

Epoch: 6| Step: 6
Training loss: 1.9254595814803672
Validation loss: 2.5667504515741153

Epoch: 6| Step: 7
Training loss: 2.337825866669165
Validation loss: 2.61823756470379

Epoch: 6| Step: 8
Training loss: 1.7981265146343919
Validation loss: 2.6050508574843714

Epoch: 6| Step: 9
Training loss: 2.3022280226126663
Validation loss: 2.607698050170853

Epoch: 6| Step: 10
Training loss: 1.912181007360516
Validation loss: 2.5480938980541077

Epoch: 6| Step: 11
Training loss: 2.7863776269556104
Validation loss: 2.622242675268649

Epoch: 6| Step: 12
Training loss: 2.2859814841053736
Validation loss: 2.50748638754104

Epoch: 6| Step: 13
Training loss: 2.4582255603852143
Validation loss: 2.543705643525669

Epoch: 67| Step: 0
Training loss: 2.388030096193498
Validation loss: 2.6129920012508205

Epoch: 6| Step: 1
Training loss: 1.8853779010756708
Validation loss: 2.6695191405880085

Epoch: 6| Step: 2
Training loss: 2.2339795169420644
Validation loss: 2.7022086558302942

Epoch: 6| Step: 3
Training loss: 2.6392817946500227
Validation loss: 2.6670987901645473

Epoch: 6| Step: 4
Training loss: 2.0538720663134584
Validation loss: 2.5839759478596207

Epoch: 6| Step: 5
Training loss: 2.0947486431674225
Validation loss: 2.601023621064329

Epoch: 6| Step: 6
Training loss: 2.0686370403878254
Validation loss: 2.5286085687177295

Epoch: 6| Step: 7
Training loss: 1.6138603888946341
Validation loss: 2.568948323807244

Epoch: 6| Step: 8
Training loss: 2.768297531322063
Validation loss: 2.6006822137300296

Epoch: 6| Step: 9
Training loss: 2.015111103639143
Validation loss: 2.5397397903511036

Epoch: 6| Step: 10
Training loss: 2.5286473209731612
Validation loss: 2.493502884606059

Epoch: 6| Step: 11
Training loss: 1.7463851787916798
Validation loss: 2.5769819403654433

Epoch: 6| Step: 12
Training loss: 2.778436587939243
Validation loss: 2.52766454941439

Epoch: 6| Step: 13
Training loss: 2.1002891114449107
Validation loss: 2.549339163303027

Epoch: 68| Step: 0
Training loss: 1.5126377831115843
Validation loss: 2.5244161245508585

Epoch: 6| Step: 1
Training loss: 2.4800429091279295
Validation loss: 2.5678396184964885

Epoch: 6| Step: 2
Training loss: 2.0228577007757838
Validation loss: 2.546495740927263

Epoch: 6| Step: 3
Training loss: 1.7883309946936645
Validation loss: 2.588709326264455

Epoch: 6| Step: 4
Training loss: 2.330999251474778
Validation loss: 2.6390730682034964

Epoch: 6| Step: 5
Training loss: 2.590867612588863
Validation loss: 2.6993858039123353

Epoch: 6| Step: 6
Training loss: 2.3304819554905256
Validation loss: 2.6509646171559824

Epoch: 6| Step: 7
Training loss: 2.752963809816464
Validation loss: 2.6329427926474294

Epoch: 6| Step: 8
Training loss: 1.316670920369162
Validation loss: 2.620707650701224

Epoch: 6| Step: 9
Training loss: 1.92451277425188
Validation loss: 2.5748924952043413

Epoch: 6| Step: 10
Training loss: 2.2328640824400026
Validation loss: 2.5812427511413616

Epoch: 6| Step: 11
Training loss: 1.7906355959061155
Validation loss: 2.5581456070986506

Epoch: 6| Step: 12
Training loss: 1.9979792757801929
Validation loss: 2.4966360188662824

Epoch: 6| Step: 13
Training loss: 2.5646958595791305
Validation loss: 2.540091438149453

Epoch: 69| Step: 0
Training loss: 1.8003846101997665
Validation loss: 2.61667296252941

Epoch: 6| Step: 1
Training loss: 2.0272391996087733
Validation loss: 2.6606097028616786

Epoch: 6| Step: 2
Training loss: 2.032270321977511
Validation loss: 2.6393772766406975

Epoch: 6| Step: 3
Training loss: 2.6010270584382678
Validation loss: 2.665175249350666

Epoch: 6| Step: 4
Training loss: 1.9211022288789608
Validation loss: 2.587664040296798

Epoch: 6| Step: 5
Training loss: 1.889734484071264
Validation loss: 2.5194119368501307

Epoch: 6| Step: 6
Training loss: 2.0532678841815613
Validation loss: 2.525815365017476

Epoch: 6| Step: 7
Training loss: 1.9306312755064083
Validation loss: 2.583224883930795

Epoch: 6| Step: 8
Training loss: 1.7234213723667078
Validation loss: 2.635134705750344

Epoch: 6| Step: 9
Training loss: 3.1682574308782785
Validation loss: 2.7570045303429267

Epoch: 6| Step: 10
Training loss: 2.2479290438344584
Validation loss: 2.7732734380919326

Epoch: 6| Step: 11
Training loss: 2.7555434101958243
Validation loss: 2.761646275196599

Epoch: 6| Step: 12
Training loss: 2.3892550064677893
Validation loss: 2.718611395799602

Epoch: 6| Step: 13
Training loss: 2.5064805911713055
Validation loss: 2.5972066313286404

Epoch: 70| Step: 0
Training loss: 2.365391216543218
Validation loss: 2.555707924096809

Epoch: 6| Step: 1
Training loss: 2.0843638223923144
Validation loss: 2.475780857094577

Epoch: 6| Step: 2
Training loss: 2.2968712631506594
Validation loss: 2.5147805386013884

Epoch: 6| Step: 3
Training loss: 2.1188111783087638
Validation loss: 2.5457192667512336

Epoch: 6| Step: 4
Training loss: 2.1073077208931514
Validation loss: 2.611688498199041

Epoch: 6| Step: 5
Training loss: 2.450798826972403
Validation loss: 2.5548240321827844

Epoch: 6| Step: 6
Training loss: 2.427338571730174
Validation loss: 2.5692683517554396

Epoch: 6| Step: 7
Training loss: 1.9540564185346354
Validation loss: 2.5413894397903958

Epoch: 6| Step: 8
Training loss: 2.1886367024324467
Validation loss: 2.542208353280241

Epoch: 6| Step: 9
Training loss: 2.0143797820599945
Validation loss: 2.5029223527923645

Epoch: 6| Step: 10
Training loss: 2.1742488046173287
Validation loss: 2.57129116422879

Epoch: 6| Step: 11
Training loss: 2.522062133501655
Validation loss: 2.6143414409543673

Epoch: 6| Step: 12
Training loss: 2.295478551998325
Validation loss: 2.6701631471887595

Epoch: 6| Step: 13
Training loss: 1.8327654768301107
Validation loss: 2.7106851978872584

Epoch: 71| Step: 0
Training loss: 2.826979262803202
Validation loss: 2.709377239245436

Epoch: 6| Step: 1
Training loss: 1.825256248669286
Validation loss: 2.641551756139556

Epoch: 6| Step: 2
Training loss: 1.9978015857233118
Validation loss: 2.667197775602147

Epoch: 6| Step: 3
Training loss: 2.058191596748413
Validation loss: 2.5209183928165673

Epoch: 6| Step: 4
Training loss: 2.006004261404058
Validation loss: 2.4585275950429284

Epoch: 6| Step: 5
Training loss: 2.2871431499694435
Validation loss: 2.4802875602807326

Epoch: 6| Step: 6
Training loss: 2.6903230787918444
Validation loss: 2.5745988024038886

Epoch: 6| Step: 7
Training loss: 2.3116948556132466
Validation loss: 2.57966980553575

Epoch: 6| Step: 8
Training loss: 2.485214955111109
Validation loss: 2.5484023399897935

Epoch: 6| Step: 9
Training loss: 1.7585403630860752
Validation loss: 2.5274539473426025

Epoch: 6| Step: 10
Training loss: 1.6829392296012966
Validation loss: 2.5262834623304795

Epoch: 6| Step: 11
Training loss: 2.1807965700896417
Validation loss: 2.5104084146662116

Epoch: 6| Step: 12
Training loss: 2.098237878730566
Validation loss: 2.505518861639621

Epoch: 6| Step: 13
Training loss: 2.433667716039621
Validation loss: 2.560496454157103

Epoch: 72| Step: 0
Training loss: 2.1265006656892345
Validation loss: 2.533957175774375

Epoch: 6| Step: 1
Training loss: 2.5793071464115678
Validation loss: 2.6637358852127675

Epoch: 6| Step: 2
Training loss: 2.305753196405542
Validation loss: 2.6224398920221383

Epoch: 6| Step: 3
Training loss: 1.9033081617990166
Validation loss: 2.624528819893413

Epoch: 6| Step: 4
Training loss: 2.492836894508602
Validation loss: 2.571519871508796

Epoch: 6| Step: 5
Training loss: 1.7970720929399329
Validation loss: 2.5727334491396423

Epoch: 6| Step: 6
Training loss: 1.7249729900733355
Validation loss: 2.538299226721667

Epoch: 6| Step: 7
Training loss: 1.9241887253259196
Validation loss: 2.5341252609611815

Epoch: 6| Step: 8
Training loss: 2.1677941054374457
Validation loss: 2.5562080889734906

Epoch: 6| Step: 9
Training loss: 2.2850620348166055
Validation loss: 2.5157391855929294

Epoch: 6| Step: 10
Training loss: 1.7148019007831323
Validation loss: 2.488568379729968

Epoch: 6| Step: 11
Training loss: 2.2656336290918646
Validation loss: 2.548596594027394

Epoch: 6| Step: 12
Training loss: 2.349354363077083
Validation loss: 2.5263955933426736

Epoch: 6| Step: 13
Training loss: 1.7336925504224383
Validation loss: 2.5094640409603253

Epoch: 73| Step: 0
Training loss: 2.374461966355576
Validation loss: 2.5629108688825575

Epoch: 6| Step: 1
Training loss: 2.1610703698474554
Validation loss: 2.547601623479815

Epoch: 6| Step: 2
Training loss: 2.018566262590784
Validation loss: 2.536174379678169

Epoch: 6| Step: 3
Training loss: 2.498912288553764
Validation loss: 2.4944223968175305

Epoch: 6| Step: 4
Training loss: 2.0708604771186634
Validation loss: 2.531871664371018

Epoch: 6| Step: 5
Training loss: 2.605993581182812
Validation loss: 2.5733080011646154

Epoch: 6| Step: 6
Training loss: 1.3249247421628614
Validation loss: 2.5507216629148717

Epoch: 6| Step: 7
Training loss: 2.4731021617637943
Validation loss: 2.5215065952920526

Epoch: 6| Step: 8
Training loss: 1.888013817785098
Validation loss: 2.644353006912049

Epoch: 6| Step: 9
Training loss: 2.2139223257635217
Validation loss: 2.636966073952217

Epoch: 6| Step: 10
Training loss: 1.9926263064145722
Validation loss: 2.6280124877602025

Epoch: 6| Step: 11
Training loss: 2.184394921469814
Validation loss: 2.6149315975717697

Epoch: 6| Step: 12
Training loss: 2.017152902083355
Validation loss: 2.573959175417454

Epoch: 6| Step: 13
Training loss: 2.208240603053508
Validation loss: 2.522120050171121

Epoch: 74| Step: 0
Training loss: 2.4027895133945276
Validation loss: 2.4910382338429997

Epoch: 6| Step: 1
Training loss: 2.663666010462913
Validation loss: 2.5402859444750847

Epoch: 6| Step: 2
Training loss: 1.9648214228974992
Validation loss: 2.552206656661743

Epoch: 6| Step: 3
Training loss: 1.5605939301807477
Validation loss: 2.430799828622015

Epoch: 6| Step: 4
Training loss: 2.311767668366015
Validation loss: 2.5608688683552407

Epoch: 6| Step: 5
Training loss: 1.952422725305925
Validation loss: 2.511654739790327

Epoch: 6| Step: 6
Training loss: 1.8788518124504108
Validation loss: 2.5179409321064923

Epoch: 6| Step: 7
Training loss: 2.0891064065044063
Validation loss: 2.572406290891288

Epoch: 6| Step: 8
Training loss: 2.4347019274742796
Validation loss: 2.568986080858084

Epoch: 6| Step: 9
Training loss: 2.5227635667644215
Validation loss: 2.5938600417237683

Epoch: 6| Step: 10
Training loss: 1.6064944367014122
Validation loss: 2.515385168106983

Epoch: 6| Step: 11
Training loss: 1.653860563819358
Validation loss: 2.510369523319353

Epoch: 6| Step: 12
Training loss: 2.312604953343102
Validation loss: 2.532629241683247

Epoch: 6| Step: 13
Training loss: 1.5492107596987275
Validation loss: 2.55377106167272

Epoch: 75| Step: 0
Training loss: 1.4798298365482938
Validation loss: 2.6049664807741046

Epoch: 6| Step: 1
Training loss: 2.4233493378157513
Validation loss: 2.516864068666169

Epoch: 6| Step: 2
Training loss: 3.039434179804165
Validation loss: 2.5694085321981084

Epoch: 6| Step: 3
Training loss: 1.62229768099988
Validation loss: 2.583230006294745

Epoch: 6| Step: 4
Training loss: 2.0833191171796863
Validation loss: 2.5951287768193625

Epoch: 6| Step: 5
Training loss: 1.7756058129224266
Validation loss: 2.576881925894477

Epoch: 6| Step: 6
Training loss: 2.221334751725555
Validation loss: 2.5777664551769437

Epoch: 6| Step: 7
Training loss: 2.2376807241071663
Validation loss: 2.520451041203886

Epoch: 6| Step: 8
Training loss: 1.7328985992587997
Validation loss: 2.5267191866429513

Epoch: 6| Step: 9
Training loss: 2.077469916097179
Validation loss: 2.548130794540702

Epoch: 6| Step: 10
Training loss: 2.2402790733607465
Validation loss: 2.5207859591821933

Epoch: 6| Step: 11
Training loss: 1.6537623887524315
Validation loss: 2.4949923429964103

Epoch: 6| Step: 12
Training loss: 1.9668330593625605
Validation loss: 2.5714821593879504

Epoch: 6| Step: 13
Training loss: 1.817509929099896
Validation loss: 2.566323149800323

Epoch: 76| Step: 0
Training loss: 2.1558718142363995
Validation loss: 2.5506476639433426

Epoch: 6| Step: 1
Training loss: 1.8227301656595856
Validation loss: 2.536623020556896

Epoch: 6| Step: 2
Training loss: 2.7231950924485093
Validation loss: 2.526219695329614

Epoch: 6| Step: 3
Training loss: 1.8868720898601055
Validation loss: 2.5456772778802588

Epoch: 6| Step: 4
Training loss: 2.387096318974073
Validation loss: 2.5331898230343377

Epoch: 6| Step: 5
Training loss: 1.886852567677745
Validation loss: 2.595652835952961

Epoch: 6| Step: 6
Training loss: 1.9157604549241654
Validation loss: 2.560508023570324

Epoch: 6| Step: 7
Training loss: 1.8300114215431869
Validation loss: 2.614013455256336

Epoch: 6| Step: 8
Training loss: 1.9243425485093073
Validation loss: 2.6107329453780634

Epoch: 6| Step: 9
Training loss: 1.4042926305460022
Validation loss: 2.6477143717359852

Epoch: 6| Step: 10
Training loss: 1.4672233276542772
Validation loss: 2.6438460784239703

Epoch: 6| Step: 11
Training loss: 1.7866667986390554
Validation loss: 2.6423115958878096

Epoch: 6| Step: 12
Training loss: 2.5828634470526324
Validation loss: 2.619087751605382

Epoch: 6| Step: 13
Training loss: 2.4954416679912934
Validation loss: 2.570355678763815

Epoch: 77| Step: 0
Training loss: 2.1471358361522355
Validation loss: 2.5798769922282507

Epoch: 6| Step: 1
Training loss: 2.0799671698693647
Validation loss: 2.555801887376801

Epoch: 6| Step: 2
Training loss: 2.126310393267946
Validation loss: 2.6187718999731437

Epoch: 6| Step: 3
Training loss: 2.2509030543176496
Validation loss: 2.5840675069594607

Epoch: 6| Step: 4
Training loss: 1.7197501307122964
Validation loss: 2.5450865115792483

Epoch: 6| Step: 5
Training loss: 2.950387321519814
Validation loss: 2.5941998807809092

Epoch: 6| Step: 6
Training loss: 1.7850861984298083
Validation loss: 2.5441182668984132

Epoch: 6| Step: 7
Training loss: 2.271064174946374
Validation loss: 2.6214573281585416

Epoch: 6| Step: 8
Training loss: 1.8992742256526611
Validation loss: 2.5543482066156256

Epoch: 6| Step: 9
Training loss: 1.810211973686771
Validation loss: 2.5664426277481693

Epoch: 6| Step: 10
Training loss: 2.065264727270399
Validation loss: 2.64591884975454

Epoch: 6| Step: 11
Training loss: 2.399157586866155
Validation loss: 2.660808167793062

Epoch: 6| Step: 12
Training loss: 1.5671163647406077
Validation loss: 2.6131302391254585

Epoch: 6| Step: 13
Training loss: 2.360286511308809
Validation loss: 2.6402292199518844

Epoch: 78| Step: 0
Training loss: 1.9472743792705363
Validation loss: 2.6159581423812255

Epoch: 6| Step: 1
Training loss: 1.9342539883479157
Validation loss: 2.4995112577173257

Epoch: 6| Step: 2
Training loss: 2.0946378960328267
Validation loss: 2.511627575300747

Epoch: 6| Step: 3
Training loss: 2.3916510081913938
Validation loss: 2.548777137139174

Epoch: 6| Step: 4
Training loss: 2.0356738700774644
Validation loss: 2.539304923197659

Epoch: 6| Step: 5
Training loss: 1.8240589668170433
Validation loss: 2.5656364908398595

Epoch: 6| Step: 6
Training loss: 2.4447430322331107
Validation loss: 2.4969333277427626

Epoch: 6| Step: 7
Training loss: 1.856366841655916
Validation loss: 2.5393534488750875

Epoch: 6| Step: 8
Training loss: 1.9455016017447422
Validation loss: 2.5435475883588885

Epoch: 6| Step: 9
Training loss: 2.369664473141925
Validation loss: 2.5428429732149866

Epoch: 6| Step: 10
Training loss: 2.0189980369282474
Validation loss: 2.5652256247848166

Epoch: 6| Step: 11
Training loss: 1.7374773888523187
Validation loss: 2.5548347796217183

Epoch: 6| Step: 12
Training loss: 1.4404501289598282
Validation loss: 2.5494173774336275

Epoch: 6| Step: 13
Training loss: 1.799261747070908
Validation loss: 2.5647329200567333

Epoch: 79| Step: 0
Training loss: 2.1588342632730604
Validation loss: 2.554421009470416

Epoch: 6| Step: 1
Training loss: 1.9430554636344073
Validation loss: 2.5964951446632765

Epoch: 6| Step: 2
Training loss: 2.1837574141692593
Validation loss: 2.5255112763015086

Epoch: 6| Step: 3
Training loss: 1.1483928645795551
Validation loss: 2.5395916979064967

Epoch: 6| Step: 4
Training loss: 2.3662615183022453
Validation loss: 2.5578889997317575

Epoch: 6| Step: 5
Training loss: 2.0316374189208144
Validation loss: 2.552768558194523

Epoch: 6| Step: 6
Training loss: 2.1207852920856824
Validation loss: 2.57604046945098

Epoch: 6| Step: 7
Training loss: 2.1437188504905977
Validation loss: 2.5345431596978525

Epoch: 6| Step: 8
Training loss: 1.6941144375209698
Validation loss: 2.5269134328094105

Epoch: 6| Step: 9
Training loss: 2.1882536543522857
Validation loss: 2.541786602713358

Epoch: 6| Step: 10
Training loss: 1.4396331550305559
Validation loss: 2.569229523946398

Epoch: 6| Step: 11
Training loss: 2.387785977317507
Validation loss: 2.5730390686902025

Epoch: 6| Step: 12
Training loss: 2.0983810451295737
Validation loss: 2.565663764961224

Epoch: 6| Step: 13
Training loss: 2.2433700367313687
Validation loss: 2.517070599743564

Epoch: 80| Step: 0
Training loss: 1.6594900432585658
Validation loss: 2.5808227912146378

Epoch: 6| Step: 1
Training loss: 2.1990920143808497
Validation loss: 2.5457347197301496

Epoch: 6| Step: 2
Training loss: 1.7485513822201617
Validation loss: 2.5742486190799605

Epoch: 6| Step: 3
Training loss: 1.9227981211228353
Validation loss: 2.5908163707869485

Epoch: 6| Step: 4
Training loss: 1.7681041630271919
Validation loss: 2.530766405605044

Epoch: 6| Step: 5
Training loss: 1.838438951542638
Validation loss: 2.5409008863240845

Epoch: 6| Step: 6
Training loss: 1.858810659725817
Validation loss: 2.5815184791480346

Epoch: 6| Step: 7
Training loss: 2.0927953109274546
Validation loss: 2.581209145161836

Epoch: 6| Step: 8
Training loss: 2.0851832251234965
Validation loss: 2.542770432700149

Epoch: 6| Step: 9
Training loss: 1.742921614682826
Validation loss: 2.5491777864703944

Epoch: 6| Step: 10
Training loss: 1.9696640435936923
Validation loss: 2.5169233600702716

Epoch: 6| Step: 11
Training loss: 1.7569113901251436
Validation loss: 2.543489167558507

Epoch: 6| Step: 12
Training loss: 2.1352245957748464
Validation loss: 2.5313904334777915

Epoch: 6| Step: 13
Training loss: 2.8584466479855597
Validation loss: 2.5956327047523775

Epoch: 81| Step: 0
Training loss: 1.604721749450028
Validation loss: 2.5403697869061634

Epoch: 6| Step: 1
Training loss: 2.0699307071679494
Validation loss: 2.5014749467576087

Epoch: 6| Step: 2
Training loss: 2.0893531294718444
Validation loss: 2.5584291206180088

Epoch: 6| Step: 3
Training loss: 1.3573077476331494
Validation loss: 2.5706597492674335

Epoch: 6| Step: 4
Training loss: 2.196823957346777
Validation loss: 2.641471952689118

Epoch: 6| Step: 5
Training loss: 2.312309463487022
Validation loss: 2.633578965243552

Epoch: 6| Step: 6
Training loss: 2.281560798271327
Validation loss: 2.662168163043203

Epoch: 6| Step: 7
Training loss: 2.601768691681143
Validation loss: 2.544604250647701

Epoch: 6| Step: 8
Training loss: 1.6856224776869004
Validation loss: 2.5656586230139

Epoch: 6| Step: 9
Training loss: 2.2803574997888516
Validation loss: 2.582574453459265

Epoch: 6| Step: 10
Training loss: 1.8722422982952824
Validation loss: 2.728525484395401

Epoch: 6| Step: 11
Training loss: 2.535454919088193
Validation loss: 2.8952477958628426

Epoch: 6| Step: 12
Training loss: 1.795243824839679
Validation loss: 2.9628247207825713

Epoch: 6| Step: 13
Training loss: 2.804669988465962
Validation loss: 2.9125210773540324

Epoch: 82| Step: 0
Training loss: 1.9415235886910376
Validation loss: 2.856171416711791

Epoch: 6| Step: 1
Training loss: 2.222355666392483
Validation loss: 2.722194419013873

Epoch: 6| Step: 2
Training loss: 1.8304768619528562
Validation loss: 2.5551050371849238

Epoch: 6| Step: 3
Training loss: 2.2294395731308123
Validation loss: 2.537402286120171

Epoch: 6| Step: 4
Training loss: 2.2120335965562776
Validation loss: 2.5991032674023913

Epoch: 6| Step: 5
Training loss: 2.012969167292246
Validation loss: 2.701704633337351

Epoch: 6| Step: 6
Training loss: 2.4576642262719046
Validation loss: 2.6842483691958763

Epoch: 6| Step: 7
Training loss: 2.397328869198443
Validation loss: 2.689857195841724

Epoch: 6| Step: 8
Training loss: 1.842526304556708
Validation loss: 2.607466892801531

Epoch: 6| Step: 9
Training loss: 2.8088866016154626
Validation loss: 2.589584928365284

Epoch: 6| Step: 10
Training loss: 1.489975093018931
Validation loss: 2.5376792308855944

Epoch: 6| Step: 11
Training loss: 1.6079490788970674
Validation loss: 2.6018384113193385

Epoch: 6| Step: 12
Training loss: 1.8902783036571889
Validation loss: 2.641254869087378

Epoch: 6| Step: 13
Training loss: 1.9135987011822149
Validation loss: 2.7021895390454302

Epoch: 83| Step: 0
Training loss: 1.5364359018875895
Validation loss: 2.7357595226437357

Epoch: 6| Step: 1
Training loss: 1.3002861386620044
Validation loss: 2.7607514424321273

Epoch: 6| Step: 2
Training loss: 1.9831174334920616
Validation loss: 2.840519757729045

Epoch: 6| Step: 3
Training loss: 2.637941339819576
Validation loss: 2.8181630095034143

Epoch: 6| Step: 4
Training loss: 0.8921497076417931
Validation loss: 2.762529728011737

Epoch: 6| Step: 5
Training loss: 2.2095838520879805
Validation loss: 2.6827810538538692

Epoch: 6| Step: 6
Training loss: 2.192308535942502
Validation loss: 2.658017583907524

Epoch: 6| Step: 7
Training loss: 2.304786602411123
Validation loss: 2.589360272065403

Epoch: 6| Step: 8
Training loss: 1.7990501175706601
Validation loss: 2.5531000771895536

Epoch: 6| Step: 9
Training loss: 1.6400696314009067
Validation loss: 2.5763285996294094

Epoch: 6| Step: 10
Training loss: 2.3553392871306715
Validation loss: 2.655570268612391

Epoch: 6| Step: 11
Training loss: 2.1783254873206936
Validation loss: 2.635901566075645

Epoch: 6| Step: 12
Training loss: 2.3897728492018797
Validation loss: 2.6326504741433805

Epoch: 6| Step: 13
Training loss: 1.4322919625946664
Validation loss: 2.6298165259286446

Epoch: 84| Step: 0
Training loss: 2.0489856815759406
Validation loss: 2.6605643894304416

Epoch: 6| Step: 1
Training loss: 1.9771354357570687
Validation loss: 2.600174099032787

Epoch: 6| Step: 2
Training loss: 1.8744669474416964
Validation loss: 2.589875418122749

Epoch: 6| Step: 3
Training loss: 2.1977006947742077
Validation loss: 2.559144459247866

Epoch: 6| Step: 4
Training loss: 2.1931323972606083
Validation loss: 2.6328548348755785

Epoch: 6| Step: 5
Training loss: 1.4736119414836635
Validation loss: 2.507396865579752

Epoch: 6| Step: 6
Training loss: 2.0238661146399464
Validation loss: 2.589559317917586

Epoch: 6| Step: 7
Training loss: 1.5511918377174123
Validation loss: 2.6356034394877126

Epoch: 6| Step: 8
Training loss: 1.892731745954229
Validation loss: 2.5853931357280926

Epoch: 6| Step: 9
Training loss: 1.7306276683297739
Validation loss: 2.655348890457086

Epoch: 6| Step: 10
Training loss: 1.8271340839060741
Validation loss: 2.6454348877386282

Epoch: 6| Step: 11
Training loss: 2.682802752842023
Validation loss: 2.686474789385015

Epoch: 6| Step: 12
Training loss: 1.9479586210849624
Validation loss: 2.6416774210024037

Epoch: 6| Step: 13
Training loss: 2.2068393860187454
Validation loss: 2.5745627251108076

Epoch: 85| Step: 0
Training loss: 2.0649216047281542
Validation loss: 2.5839726723396104

Epoch: 6| Step: 1
Training loss: 1.7248092656490028
Validation loss: 2.589149362829374

Epoch: 6| Step: 2
Training loss: 1.752396645430032
Validation loss: 2.5617232657413407

Epoch: 6| Step: 3
Training loss: 2.002301441687792
Validation loss: 2.558178234576302

Epoch: 6| Step: 4
Training loss: 2.019708090737261
Validation loss: 2.5659874081251886

Epoch: 6| Step: 5
Training loss: 1.7173781034920657
Validation loss: 2.587811700349164

Epoch: 6| Step: 6
Training loss: 1.9023001977215865
Validation loss: 2.559306348812256

Epoch: 6| Step: 7
Training loss: 1.3411759851516813
Validation loss: 2.5643995889080937

Epoch: 6| Step: 8
Training loss: 2.010025289385919
Validation loss: 2.5675259590508097

Epoch: 6| Step: 9
Training loss: 2.0666393011598885
Validation loss: 2.544745914663692

Epoch: 6| Step: 10
Training loss: 1.7922990998672654
Validation loss: 2.566308022084863

Epoch: 6| Step: 11
Training loss: 1.691361072104315
Validation loss: 2.5199186436321916

Epoch: 6| Step: 12
Training loss: 2.17292156663917
Validation loss: 2.5567051874746114

Epoch: 6| Step: 13
Training loss: 2.841426864603784
Validation loss: 2.6273069538130183

Epoch: 86| Step: 0
Training loss: 1.6837597121289238
Validation loss: 2.5561228694874245

Epoch: 6| Step: 1
Training loss: 1.768086026390206
Validation loss: 2.582194236116573

Epoch: 6| Step: 2
Training loss: 2.051824627623119
Validation loss: 2.537932644371384

Epoch: 6| Step: 3
Training loss: 2.6781377731962297
Validation loss: 2.582568537395642

Epoch: 6| Step: 4
Training loss: 2.1820572853925304
Validation loss: 2.6271903799473875

Epoch: 6| Step: 5
Training loss: 1.6243102003428613
Validation loss: 2.611383240183993

Epoch: 6| Step: 6
Training loss: 1.6193195239583222
Validation loss: 2.5992843688442013

Epoch: 6| Step: 7
Training loss: 1.2807309564756608
Validation loss: 2.671628840300257

Epoch: 6| Step: 8
Training loss: 1.5535257110383394
Validation loss: 2.615760345785614

Epoch: 6| Step: 9
Training loss: 2.2632448519386186
Validation loss: 2.5560869356110385

Epoch: 6| Step: 10
Training loss: 1.374627583093966
Validation loss: 2.5808062626896318

Epoch: 6| Step: 11
Training loss: 2.385005454610989
Validation loss: 2.55127291884494

Epoch: 6| Step: 12
Training loss: 1.9994075612943172
Validation loss: 2.57704050392903

Epoch: 6| Step: 13
Training loss: 2.010730567368682
Validation loss: 2.6098238317245728

Epoch: 87| Step: 0
Training loss: 1.799287718669714
Validation loss: 2.6037177550904045

Epoch: 6| Step: 1
Training loss: 2.5314788714888445
Validation loss: 2.6224681209133327

Epoch: 6| Step: 2
Training loss: 1.619165068328011
Validation loss: 2.6152129814596714

Epoch: 6| Step: 3
Training loss: 1.9340684096220961
Validation loss: 2.617248018238817

Epoch: 6| Step: 4
Training loss: 1.9350108492840354
Validation loss: 2.585461268218302

Epoch: 6| Step: 5
Training loss: 1.6693946764667216
Validation loss: 2.576697769454362

Epoch: 6| Step: 6
Training loss: 1.8076872232431185
Validation loss: 2.6727362243051846

Epoch: 6| Step: 7
Training loss: 1.9596094748637622
Validation loss: 2.6402459408613552

Epoch: 6| Step: 8
Training loss: 1.4715348484424906
Validation loss: 2.7461996550959675

Epoch: 6| Step: 9
Training loss: 1.8761805314756446
Validation loss: 2.7179700309952883

Epoch: 6| Step: 10
Training loss: 2.3327996347510807
Validation loss: 2.701775833393718

Epoch: 6| Step: 11
Training loss: 2.7080620458642537
Validation loss: 2.623460833089978

Epoch: 6| Step: 12
Training loss: 1.905494790487743
Validation loss: 2.590299018747773

Epoch: 6| Step: 13
Training loss: 2.1519447136764955
Validation loss: 2.6054272054994625

Epoch: 88| Step: 0
Training loss: 1.9337487977411913
Validation loss: 2.588233013415564

Epoch: 6| Step: 1
Training loss: 1.9921548279719778
Validation loss: 2.6816380466746073

Epoch: 6| Step: 2
Training loss: 2.8013977478909395
Validation loss: 2.556423689981289

Epoch: 6| Step: 3
Training loss: 2.426990250752173
Validation loss: 2.594805598416186

Epoch: 6| Step: 4
Training loss: 1.3687816807812465
Validation loss: 2.5067471056402444

Epoch: 6| Step: 5
Training loss: 1.9098807606250994
Validation loss: 2.5659036129623387

Epoch: 6| Step: 6
Training loss: 1.8171190401467492
Validation loss: 2.632122111523728

Epoch: 6| Step: 7
Training loss: 1.8642355596334272
Validation loss: 2.603471622538764

Epoch: 6| Step: 8
Training loss: 2.4114084808491554
Validation loss: 2.709390497511643

Epoch: 6| Step: 9
Training loss: 1.6695213506795161
Validation loss: 2.6722471784782043

Epoch: 6| Step: 10
Training loss: 1.8246033485687114
Validation loss: 2.6930258813930066

Epoch: 6| Step: 11
Training loss: 1.7670041664605491
Validation loss: 2.6586059519214698

Epoch: 6| Step: 12
Training loss: 1.6697886631352221
Validation loss: 2.568443430406273

Epoch: 6| Step: 13
Training loss: 1.6223184762048029
Validation loss: 2.581212578133543

Epoch: 89| Step: 0
Training loss: 1.7433166949983754
Validation loss: 2.533033472643444

Epoch: 6| Step: 1
Training loss: 1.5610256105285634
Validation loss: 2.593750352361571

Epoch: 6| Step: 2
Training loss: 2.1088207505708803
Validation loss: 2.6274496032401715

Epoch: 6| Step: 3
Training loss: 2.2256829917270533
Validation loss: 2.5685019101816553

Epoch: 6| Step: 4
Training loss: 1.681459849141121
Validation loss: 2.5934254546666584

Epoch: 6| Step: 5
Training loss: 1.689079605001813
Validation loss: 2.5157526114184043

Epoch: 6| Step: 6
Training loss: 1.9058207044139925
Validation loss: 2.5477273836940943

Epoch: 6| Step: 7
Training loss: 1.752124926798742
Validation loss: 2.5716461462989204

Epoch: 6| Step: 8
Training loss: 2.585942663089634
Validation loss: 2.5537512071593884

Epoch: 6| Step: 9
Training loss: 1.6406161353462148
Validation loss: 2.640456109599359

Epoch: 6| Step: 10
Training loss: 1.5310703094304434
Validation loss: 2.651632476704507

Epoch: 6| Step: 11
Training loss: 1.5635386257493624
Validation loss: 2.62244028598621

Epoch: 6| Step: 12
Training loss: 1.5111776955900738
Validation loss: 2.636642243959027

Epoch: 6| Step: 13
Training loss: 2.7840531185607387
Validation loss: 2.59235641851942

Epoch: 90| Step: 0
Training loss: 1.8581977771989213
Validation loss: 2.621794082611469

Epoch: 6| Step: 1
Training loss: 1.1527738124263436
Validation loss: 2.5994925679313816

Epoch: 6| Step: 2
Training loss: 2.4471720976741227
Validation loss: 2.599181573997702

Epoch: 6| Step: 3
Training loss: 1.6956790932035712
Validation loss: 2.584711512190913

Epoch: 6| Step: 4
Training loss: 1.6951847995179172
Validation loss: 2.6566433633989237

Epoch: 6| Step: 5
Training loss: 2.518314795367993
Validation loss: 2.680898142671481

Epoch: 6| Step: 6
Training loss: 1.914611737604762
Validation loss: 2.620826643150374

Epoch: 6| Step: 7
Training loss: 1.503250732238987
Validation loss: 2.669081166049562

Epoch: 6| Step: 8
Training loss: 1.8674357101629488
Validation loss: 2.616374938236811

Epoch: 6| Step: 9
Training loss: 1.6619442634738986
Validation loss: 2.54186658125153

Epoch: 6| Step: 10
Training loss: 1.9021027900004293
Validation loss: 2.6094235474720704

Epoch: 6| Step: 11
Training loss: 1.9145493491570453
Validation loss: 2.591715815487981

Epoch: 6| Step: 12
Training loss: 1.5382809276202685
Validation loss: 2.6170487855808164

Epoch: 6| Step: 13
Training loss: 1.6168296528618256
Validation loss: 2.6030629120467457

Epoch: 91| Step: 0
Training loss: 1.8181055139655975
Validation loss: 2.5580455085885814

Epoch: 6| Step: 1
Training loss: 1.7130605685097817
Validation loss: 2.5873382247502437

Epoch: 6| Step: 2
Training loss: 2.0218062140012028
Validation loss: 2.5990184759139145

Epoch: 6| Step: 3
Training loss: 1.268299902393073
Validation loss: 2.6166286194418404

Epoch: 6| Step: 4
Training loss: 1.5623757885199139
Validation loss: 2.5713853152802235

Epoch: 6| Step: 5
Training loss: 1.4794201521757835
Validation loss: 2.6165485266319926

Epoch: 6| Step: 6
Training loss: 1.3230447431828163
Validation loss: 2.5851577243856445

Epoch: 6| Step: 7
Training loss: 2.1506794277355725
Validation loss: 2.628554435417382

Epoch: 6| Step: 8
Training loss: 1.8449321771576774
Validation loss: 2.5611154180652798

Epoch: 6| Step: 9
Training loss: 1.628691075884713
Validation loss: 2.634455514373575

Epoch: 6| Step: 10
Training loss: 1.3805158692345536
Validation loss: 2.6278157799571344

Epoch: 6| Step: 11
Training loss: 1.5835341861553018
Validation loss: 2.6817939568137166

Epoch: 6| Step: 12
Training loss: 2.1555350403721616
Validation loss: 2.6371369960285627

Epoch: 6| Step: 13
Training loss: 3.0105177566468426
Validation loss: 2.6012362713797503

Epoch: 92| Step: 0
Training loss: 1.3501626411236396
Validation loss: 2.5884418941639966

Epoch: 6| Step: 1
Training loss: 1.78839112057189
Validation loss: 2.5784149315154234

Epoch: 6| Step: 2
Training loss: 2.1404528026514433
Validation loss: 2.583251203236382

Epoch: 6| Step: 3
Training loss: 2.0885610476488017
Validation loss: 2.656540379827212

Epoch: 6| Step: 4
Training loss: 1.1402685575206675
Validation loss: 2.6577973739310212

Epoch: 6| Step: 5
Training loss: 2.261851041676951
Validation loss: 2.6656184719254705

Epoch: 6| Step: 6
Training loss: 1.987357713896368
Validation loss: 2.623629711895873

Epoch: 6| Step: 7
Training loss: 1.5285627178967651
Validation loss: 2.646595091808827

Epoch: 6| Step: 8
Training loss: 1.8325821753756077
Validation loss: 2.642720476382491

Epoch: 6| Step: 9
Training loss: 2.541550857740543
Validation loss: 2.6271286008858894

Epoch: 6| Step: 10
Training loss: 1.9892304258938016
Validation loss: 2.6371404315346125

Epoch: 6| Step: 11
Training loss: 1.6844894964763104
Validation loss: 2.7852865779821343

Epoch: 6| Step: 12
Training loss: 1.6781985758701174
Validation loss: 2.8104510155104103

Epoch: 6| Step: 13
Training loss: 1.7009856760497257
Validation loss: 2.8146994997151826

Epoch: 93| Step: 0
Training loss: 1.8094408593190918
Validation loss: 2.7179060462823306

Epoch: 6| Step: 1
Training loss: 1.3853481342698666
Validation loss: 2.700932578343104

Epoch: 6| Step: 2
Training loss: 1.5919284508743623
Validation loss: 2.6043716400859616

Epoch: 6| Step: 3
Training loss: 1.6445307425817581
Validation loss: 2.5964421315088013

Epoch: 6| Step: 4
Training loss: 1.7923094756998161
Validation loss: 2.6633517602785175

Epoch: 6| Step: 5
Training loss: 2.174025314997842
Validation loss: 2.6880328071641437

Epoch: 6| Step: 6
Training loss: 2.3448932148384416
Validation loss: 2.669255629085255

Epoch: 6| Step: 7
Training loss: 1.8186308988920838
Validation loss: 2.66872790265669

Epoch: 6| Step: 8
Training loss: 2.0926630415571608
Validation loss: 2.637359194740935

Epoch: 6| Step: 9
Training loss: 2.1285746184861885
Validation loss: 2.592907397203419

Epoch: 6| Step: 10
Training loss: 2.3085014208615138
Validation loss: 2.585354311854825

Epoch: 6| Step: 11
Training loss: 1.4900874994175377
Validation loss: 2.6261842871773653

Epoch: 6| Step: 12
Training loss: 2.0869082360193
Validation loss: 2.685501079746849

Epoch: 6| Step: 13
Training loss: 1.523570910750011
Validation loss: 2.6652728451494387

Epoch: 94| Step: 0
Training loss: 1.480267271961942
Validation loss: 2.698728952165268

Epoch: 6| Step: 1
Training loss: 2.1638235242528694
Validation loss: 2.76349478829361

Epoch: 6| Step: 2
Training loss: 1.5566322776350452
Validation loss: 2.692608421336391

Epoch: 6| Step: 3
Training loss: 1.8920766128569657
Validation loss: 2.693460928680819

Epoch: 6| Step: 4
Training loss: 1.6382103725922303
Validation loss: 2.596090340992345

Epoch: 6| Step: 5
Training loss: 1.672381814450227
Validation loss: 2.6042814585498975

Epoch: 6| Step: 6
Training loss: 1.383215980071451
Validation loss: 2.600930940111871

Epoch: 6| Step: 7
Training loss: 1.7271775060854242
Validation loss: 2.5789353763569207

Epoch: 6| Step: 8
Training loss: 1.9534218524409288
Validation loss: 2.6512413074639274

Epoch: 6| Step: 9
Training loss: 1.9317995320404178
Validation loss: 2.5673100986101263

Epoch: 6| Step: 10
Training loss: 1.1512812484493118
Validation loss: 2.5764495029042633

Epoch: 6| Step: 11
Training loss: 1.8394135379156606
Validation loss: 2.645959105218147

Epoch: 6| Step: 12
Training loss: 2.662677662254455
Validation loss: 2.669810696723937

Epoch: 6| Step: 13
Training loss: 2.031038009145148
Validation loss: 2.5940403143868416

Epoch: 95| Step: 0
Training loss: 1.3626423297700778
Validation loss: 2.6420441525264353

Epoch: 6| Step: 1
Training loss: 1.7723638166401265
Validation loss: 2.6002822032022768

Epoch: 6| Step: 2
Training loss: 1.958332778714149
Validation loss: 2.6934409162623107

Epoch: 6| Step: 3
Training loss: 1.9627414627715534
Validation loss: 2.7063159300281416

Epoch: 6| Step: 4
Training loss: 1.4410064887245528
Validation loss: 2.6980965356751687

Epoch: 6| Step: 5
Training loss: 2.316281191455788
Validation loss: 2.632353005841209

Epoch: 6| Step: 6
Training loss: 1.4246370087462465
Validation loss: 2.645267521189852

Epoch: 6| Step: 7
Training loss: 1.8300468580573412
Validation loss: 2.637581480192901

Epoch: 6| Step: 8
Training loss: 1.623038355028029
Validation loss: 2.7018066013563615

Epoch: 6| Step: 9
Training loss: 1.4693449722655236
Validation loss: 2.746290595070454

Epoch: 6| Step: 10
Training loss: 1.95223594267126
Validation loss: 2.7253697800628514

Epoch: 6| Step: 11
Training loss: 1.8324965677060072
Validation loss: 2.6667495555711023

Epoch: 6| Step: 12
Training loss: 1.3658121220863926
Validation loss: 2.6160491213629395

Epoch: 6| Step: 13
Training loss: 2.386629942694912
Validation loss: 2.673857505531034

Epoch: 96| Step: 0
Training loss: 1.7009849051423038
Validation loss: 2.5665007273384814

Epoch: 6| Step: 1
Training loss: 1.480755136615243
Validation loss: 2.658928720971434

Epoch: 6| Step: 2
Training loss: 1.4762240228781864
Validation loss: 2.6715678880659284

Epoch: 6| Step: 3
Training loss: 1.4675153859516297
Validation loss: 2.7306921580560273

Epoch: 6| Step: 4
Training loss: 1.6079216477962042
Validation loss: 2.6046823041955984

Epoch: 6| Step: 5
Training loss: 1.8209617668382334
Validation loss: 2.6193635463077345

Epoch: 6| Step: 6
Training loss: 1.7944603659780056
Validation loss: 2.648037170341353

Epoch: 6| Step: 7
Training loss: 1.059475014615658
Validation loss: 2.6688381880305476

Epoch: 6| Step: 8
Training loss: 2.0937743683720687
Validation loss: 2.6809935135123206

Epoch: 6| Step: 9
Training loss: 1.8168852143842011
Validation loss: 2.699585186329205

Epoch: 6| Step: 10
Training loss: 2.206222629107174
Validation loss: 2.6649130230774567

Epoch: 6| Step: 11
Training loss: 1.379594841650535
Validation loss: 2.660339379040575

Epoch: 6| Step: 12
Training loss: 2.250733997573243
Validation loss: 2.6775612509661424

Epoch: 6| Step: 13
Training loss: 2.0026137438984524
Validation loss: 2.6144604799706825

Epoch: 97| Step: 0
Training loss: 1.39731207373938
Validation loss: 2.6234387038597147

Epoch: 6| Step: 1
Training loss: 1.7604953214089722
Validation loss: 2.59307235077119

Epoch: 6| Step: 2
Training loss: 1.8896611807144608
Validation loss: 2.6474836914405504

Epoch: 6| Step: 3
Training loss: 1.9698934716017586
Validation loss: 2.6336238980441924

Epoch: 6| Step: 4
Training loss: 1.3038613450515937
Validation loss: 2.6604626778308353

Epoch: 6| Step: 5
Training loss: 1.7427861164593286
Validation loss: 2.7004823501086412

Epoch: 6| Step: 6
Training loss: 2.1167703477992754
Validation loss: 2.667957564666074

Epoch: 6| Step: 7
Training loss: 1.962107032259576
Validation loss: 2.6495480829845377

Epoch: 6| Step: 8
Training loss: 1.895444669462846
Validation loss: 2.7167412363439154

Epoch: 6| Step: 9
Training loss: 1.7012785255120362
Validation loss: 2.612809325345048

Epoch: 6| Step: 10
Training loss: 2.549516676931082
Validation loss: 2.6317454665185953

Epoch: 6| Step: 11
Training loss: 1.8602263481073014
Validation loss: 2.6651668254699654

Epoch: 6| Step: 12
Training loss: 0.90990903059078
Validation loss: 2.641866080060968

Epoch: 6| Step: 13
Training loss: 1.5548585577171403
Validation loss: 2.6366907339609207

Epoch: 98| Step: 0
Training loss: 2.3041555016944426
Validation loss: 2.6272863996789364

Epoch: 6| Step: 1
Training loss: 0.7788816411790233
Validation loss: 2.6192792817350776

Epoch: 6| Step: 2
Training loss: 1.4672625700216702
Validation loss: 2.7164702668215446

Epoch: 6| Step: 3
Training loss: 2.0656595016576014
Validation loss: 2.634872875476804

Epoch: 6| Step: 4
Training loss: 1.617375164845387
Validation loss: 2.6369504774957715

Epoch: 6| Step: 5
Training loss: 2.0183588458002015
Validation loss: 2.67915375994653

Epoch: 6| Step: 6
Training loss: 1.8167485396574994
Validation loss: 2.6663189204292586

Epoch: 6| Step: 7
Training loss: 1.402138272588825
Validation loss: 2.656898568951516

Epoch: 6| Step: 8
Training loss: 2.071180629454877
Validation loss: 2.629296495362691

Epoch: 6| Step: 9
Training loss: 1.659121417481236
Validation loss: 2.6482229980505743

Epoch: 6| Step: 10
Training loss: 1.9632264414619425
Validation loss: 2.625686018477742

Epoch: 6| Step: 11
Training loss: 1.4410313064329987
Validation loss: 2.615959387961734

Epoch: 6| Step: 12
Training loss: 1.6919956369727045
Validation loss: 2.615144423708223

Epoch: 6| Step: 13
Training loss: 2.0759156608208014
Validation loss: 2.638671257570516

Epoch: 99| Step: 0
Training loss: 1.406320866812453
Validation loss: 2.6811114828969576

Epoch: 6| Step: 1
Training loss: 1.6200115222285674
Validation loss: 2.6825540630300067

Epoch: 6| Step: 2
Training loss: 2.128191402704515
Validation loss: 2.69502710867832

Epoch: 6| Step: 3
Training loss: 1.2925134877251911
Validation loss: 2.7035473473388207

Epoch: 6| Step: 4
Training loss: 2.732367950627211
Validation loss: 2.7128058745967545

Epoch: 6| Step: 5
Training loss: 1.8930284340360797
Validation loss: 2.669006801045341

Epoch: 6| Step: 6
Training loss: 1.8838095023636754
Validation loss: 2.742575611641645

Epoch: 6| Step: 7
Training loss: 1.2615837284746607
Validation loss: 2.7181569325856394

Epoch: 6| Step: 8
Training loss: 1.428581769088378
Validation loss: 2.615356488044231

Epoch: 6| Step: 9
Training loss: 1.6432325440708118
Validation loss: 2.648370537525557

Epoch: 6| Step: 10
Training loss: 1.4079938883892629
Validation loss: 2.6629202026079493

Epoch: 6| Step: 11
Training loss: 1.2439547269623334
Validation loss: 2.621188439195235

Epoch: 6| Step: 12
Training loss: 1.6280521193463389
Validation loss: 2.637101092462346

Epoch: 6| Step: 13
Training loss: 1.4604994173136916
Validation loss: 2.634763046048474

Epoch: 100| Step: 0
Training loss: 1.189809510908717
Validation loss: 2.6403149454746093

Epoch: 6| Step: 1
Training loss: 2.0499754276198567
Validation loss: 2.6652165408905004

Epoch: 6| Step: 2
Training loss: 1.8137706380520435
Validation loss: 2.669532366089908

Epoch: 6| Step: 3
Training loss: 1.9305568080626647
Validation loss: 2.59382276164875

Epoch: 6| Step: 4
Training loss: 1.3124018132858515
Validation loss: 2.611259982642532

Epoch: 6| Step: 5
Training loss: 1.795168256816609
Validation loss: 2.6822675734737236

Epoch: 6| Step: 6
Training loss: 1.7431417682835544
Validation loss: 2.768636798481984

Epoch: 6| Step: 7
Training loss: 1.7233393346336443
Validation loss: 2.716050441062873

Epoch: 6| Step: 8
Training loss: 1.1398326786959911
Validation loss: 2.6853116611008985

Epoch: 6| Step: 9
Training loss: 1.764321039815845
Validation loss: 2.658926285012553

Epoch: 6| Step: 10
Training loss: 1.918088951928076
Validation loss: 2.721666401498863

Epoch: 6| Step: 11
Training loss: 1.588703918509058
Validation loss: 2.6846099365832954

Epoch: 6| Step: 12
Training loss: 2.5874553731856977
Validation loss: 2.690327820000379

Epoch: 6| Step: 13
Training loss: 1.4284721169692953
Validation loss: 2.6040929148085117

Epoch: 101| Step: 0
Training loss: 1.2607876675629537
Validation loss: 2.7163288399819945

Epoch: 6| Step: 1
Training loss: 1.8079265904672552
Validation loss: 2.678133900648748

Epoch: 6| Step: 2
Training loss: 2.351320476053747
Validation loss: 2.7124448647586874

Epoch: 6| Step: 3
Training loss: 1.5338785615372486
Validation loss: 2.7134216242991416

Epoch: 6| Step: 4
Training loss: 1.8259616016766973
Validation loss: 2.7090839421778328

Epoch: 6| Step: 5
Training loss: 2.203048812955724
Validation loss: 2.7477376908984614

Epoch: 6| Step: 6
Training loss: 1.7859959870621216
Validation loss: 2.730586350018216

Epoch: 6| Step: 7
Training loss: 1.4904720971721446
Validation loss: 2.6964417087038814

Epoch: 6| Step: 8
Training loss: 1.7110823478524353
Validation loss: 2.611767948899465

Epoch: 6| Step: 9
Training loss: 1.6099568768762103
Validation loss: 2.670104959308445

Epoch: 6| Step: 10
Training loss: 1.7106030280946432
Validation loss: 2.667072508645515

Epoch: 6| Step: 11
Training loss: 1.7001524716610394
Validation loss: 2.642057853960491

Epoch: 6| Step: 12
Training loss: 1.5433174608429165
Validation loss: 2.6681796391303796

Epoch: 6| Step: 13
Training loss: 1.537358458912223
Validation loss: 2.625413059857128

Epoch: 102| Step: 0
Training loss: 1.3538493836220984
Validation loss: 2.606232599311635

Epoch: 6| Step: 1
Training loss: 1.9965355789105876
Validation loss: 2.699768304891296

Epoch: 6| Step: 2
Training loss: 2.0373366495192005
Validation loss: 2.732606355785018

Epoch: 6| Step: 3
Training loss: 1.7088769497486718
Validation loss: 2.6940933935048035

Epoch: 6| Step: 4
Training loss: 1.5764192483959516
Validation loss: 2.778504062648016

Epoch: 6| Step: 5
Training loss: 2.0844515533344117
Validation loss: 2.7966622639311853

Epoch: 6| Step: 6
Training loss: 2.1831082536222732
Validation loss: 2.780945107539315

Epoch: 6| Step: 7
Training loss: 1.5614323592448531
Validation loss: 2.679793656955484

Epoch: 6| Step: 8
Training loss: 1.6740361443859482
Validation loss: 2.6599114333851155

Epoch: 6| Step: 9
Training loss: 1.196818033162464
Validation loss: 2.751329230797293

Epoch: 6| Step: 10
Training loss: 1.6152734901646113
Validation loss: 2.5879280442705475

Epoch: 6| Step: 11
Training loss: 1.4637598528966096
Validation loss: 2.667565973950298

Epoch: 6| Step: 12
Training loss: 1.641390812477604
Validation loss: 2.6255039003917497

Epoch: 6| Step: 13
Training loss: 1.558754207602346
Validation loss: 2.602859128126058

Epoch: 103| Step: 0
Training loss: 1.4348583828099875
Validation loss: 2.714630821165928

Epoch: 6| Step: 1
Training loss: 1.6749597060637775
Validation loss: 2.6788208563792595

Epoch: 6| Step: 2
Training loss: 1.7237115166609747
Validation loss: 2.631477764719198

Epoch: 6| Step: 3
Training loss: 1.9026604296780973
Validation loss: 2.7528438169057994

Epoch: 6| Step: 4
Training loss: 1.236415721327228
Validation loss: 2.6873035654832296

Epoch: 6| Step: 5
Training loss: 1.487638800420232
Validation loss: 2.7054330530986883

Epoch: 6| Step: 6
Training loss: 1.057672529102344
Validation loss: 2.5984824948401717

Epoch: 6| Step: 7
Training loss: 1.5183278003233094
Validation loss: 2.6958545968948098

Epoch: 6| Step: 8
Training loss: 2.108824255358951
Validation loss: 2.6973064768480777

Epoch: 6| Step: 9
Training loss: 1.752136152864568
Validation loss: 2.792341340560091

Epoch: 6| Step: 10
Training loss: 2.2163010097255404
Validation loss: 2.7401665524866954

Epoch: 6| Step: 11
Training loss: 1.4464364295490357
Validation loss: 2.7616581314390896

Epoch: 6| Step: 12
Training loss: 2.468981575063972
Validation loss: 2.6879208922708986

Epoch: 6| Step: 13
Training loss: 1.3493525789349656
Validation loss: 2.718731803394677

Epoch: 104| Step: 0
Training loss: 1.7732300489984774
Validation loss: 2.6133723601846115

Epoch: 6| Step: 1
Training loss: 1.9542849338859778
Validation loss: 2.662400070965748

Epoch: 6| Step: 2
Training loss: 1.5702250442064427
Validation loss: 2.744801665450143

Epoch: 6| Step: 3
Training loss: 1.5007227110280925
Validation loss: 2.674899428844889

Epoch: 6| Step: 4
Training loss: 1.8138477970523277
Validation loss: 2.635717507984487

Epoch: 6| Step: 5
Training loss: 1.101750242859511
Validation loss: 2.660453551974464

Epoch: 6| Step: 6
Training loss: 1.3455354671928257
Validation loss: 2.710251551902807

Epoch: 6| Step: 7
Training loss: 2.37227886314976
Validation loss: 2.7510265110633085

Epoch: 6| Step: 8
Training loss: 1.231947818270286
Validation loss: 2.8068106433232245

Epoch: 6| Step: 9
Training loss: 2.0657396016381453
Validation loss: 2.9051272777047665

Epoch: 6| Step: 10
Training loss: 2.348792792758226
Validation loss: 2.8164167470114716

Epoch: 6| Step: 11
Training loss: 1.2506988002614878
Validation loss: 2.769958448798441

Epoch: 6| Step: 12
Training loss: 1.3543595934644235
Validation loss: 2.6909023601254884

Epoch: 6| Step: 13
Training loss: 1.554057774892313
Validation loss: 2.6759350809025992

Epoch: 105| Step: 0
Training loss: 1.329263087316015
Validation loss: 2.6809032118107905

Epoch: 6| Step: 1
Training loss: 1.943158838094639
Validation loss: 2.7019779513203255

Epoch: 6| Step: 2
Training loss: 1.7049600357115158
Validation loss: 2.682032709059266

Epoch: 6| Step: 3
Training loss: 2.117342447051477
Validation loss: 2.708207279108415

Epoch: 6| Step: 4
Training loss: 1.951923458537317
Validation loss: 2.650926408841556

Epoch: 6| Step: 5
Training loss: 1.3836456202945988
Validation loss: 2.666096363079388

Epoch: 6| Step: 6
Training loss: 1.487531337888776
Validation loss: 2.676389215831498

Epoch: 6| Step: 7
Training loss: 2.0369040805441485
Validation loss: 2.812958927152576

Epoch: 6| Step: 8
Training loss: 1.7826131991787653
Validation loss: 2.840787679100801

Epoch: 6| Step: 9
Training loss: 1.8583600776469933
Validation loss: 2.767499830618706

Epoch: 6| Step: 10
Training loss: 1.9254901658259973
Validation loss: 2.750968935803237

Epoch: 6| Step: 11
Training loss: 1.7141508818576372
Validation loss: 2.7498091429168454

Epoch: 6| Step: 12
Training loss: 1.0262284988213946
Validation loss: 2.664108469875025

Epoch: 6| Step: 13
Training loss: 1.5256588122517325
Validation loss: 2.689896941473879

Epoch: 106| Step: 0
Training loss: 1.0486637036325541
Validation loss: 2.707147842545945

Epoch: 6| Step: 1
Training loss: 1.5379502203267983
Validation loss: 2.7395871722021634

Epoch: 6| Step: 2
Training loss: 1.3820644445837336
Validation loss: 2.7489556005497326

Epoch: 6| Step: 3
Training loss: 1.8667046469275967
Validation loss: 2.7539601999323597

Epoch: 6| Step: 4
Training loss: 1.6578390308094435
Validation loss: 2.647757698967796

Epoch: 6| Step: 5
Training loss: 1.2280672889719768
Validation loss: 2.7025593807155732

Epoch: 6| Step: 6
Training loss: 1.266029622895969
Validation loss: 2.6872923423324018

Epoch: 6| Step: 7
Training loss: 1.5342472870112613
Validation loss: 2.7236659158651086

Epoch: 6| Step: 8
Training loss: 1.2893538637042194
Validation loss: 2.746163712356879

Epoch: 6| Step: 9
Training loss: 1.928763102538228
Validation loss: 2.7851654666072228

Epoch: 6| Step: 10
Training loss: 1.81504314507941
Validation loss: 2.7583975743153286

Epoch: 6| Step: 11
Training loss: 2.2761016651570323
Validation loss: 2.7349214425622717

Epoch: 6| Step: 12
Training loss: 1.7076848435222267
Validation loss: 2.7374281776563465

Epoch: 6| Step: 13
Training loss: 1.760537235562868
Validation loss: 2.6774195201471946

Epoch: 107| Step: 0
Training loss: 1.1231329047381826
Validation loss: 2.673239911445568

Epoch: 6| Step: 1
Training loss: 1.6691301577164188
Validation loss: 2.721023193869902

Epoch: 6| Step: 2
Training loss: 2.377534618105597
Validation loss: 2.721029896862687

Epoch: 6| Step: 3
Training loss: 1.4043940270445996
Validation loss: 2.669958710154761

Epoch: 6| Step: 4
Training loss: 1.2248909123174774
Validation loss: 2.7009341966752345

Epoch: 6| Step: 5
Training loss: 1.5138699309691226
Validation loss: 2.700261136954797

Epoch: 6| Step: 6
Training loss: 1.4532815172133464
Validation loss: 2.6629824420666712

Epoch: 6| Step: 7
Training loss: 1.3786656761494835
Validation loss: 2.7363192812050383

Epoch: 6| Step: 8
Training loss: 1.40173062918314
Validation loss: 2.659440491852715

Epoch: 6| Step: 9
Training loss: 1.4859602644627667
Validation loss: 2.6853662936445897

Epoch: 6| Step: 10
Training loss: 1.9453745759305276
Validation loss: 2.7200010936164527

Epoch: 6| Step: 11
Training loss: 1.5864335209923925
Validation loss: 2.647859883593718

Epoch: 6| Step: 12
Training loss: 1.5117199328514026
Validation loss: 2.7634422755039263

Epoch: 6| Step: 13
Training loss: 1.5956742880560657
Validation loss: 2.717293535546941

Epoch: 108| Step: 0
Training loss: 1.2640036098875334
Validation loss: 2.6930136787245638

Epoch: 6| Step: 1
Training loss: 1.7435297563714074
Validation loss: 2.7259273572624676

Epoch: 6| Step: 2
Training loss: 1.3362429977818757
Validation loss: 2.736853618748832

Epoch: 6| Step: 3
Training loss: 1.540934706812849
Validation loss: 2.6919018234263947

Epoch: 6| Step: 4
Training loss: 0.8932226345761333
Validation loss: 2.7305137183070585

Epoch: 6| Step: 5
Training loss: 1.903051601053096
Validation loss: 2.703428813641247

Epoch: 6| Step: 6
Training loss: 0.7813249933488806
Validation loss: 2.8041748598459915

Epoch: 6| Step: 7
Training loss: 1.476528429718124
Validation loss: 2.736211585014382

Epoch: 6| Step: 8
Training loss: 1.849899059841091
Validation loss: 2.640982353513561

Epoch: 6| Step: 9
Training loss: 1.5158766704709605
Validation loss: 2.6830087437780468

Epoch: 6| Step: 10
Training loss: 1.9213229371163962
Validation loss: 2.6241432790076433

Epoch: 6| Step: 11
Training loss: 2.2041370421103204
Validation loss: 2.745317605364327

Epoch: 6| Step: 12
Training loss: 1.9112463338952739
Validation loss: 2.705396855164905

Epoch: 6| Step: 13
Training loss: 1.0811401443682158
Validation loss: 2.655090467895655

Epoch: 109| Step: 0
Training loss: 1.7289042752509338
Validation loss: 2.7541322150987653

Epoch: 6| Step: 1
Training loss: 1.0406882968473645
Validation loss: 2.7866876501870634

Epoch: 6| Step: 2
Training loss: 1.7925879379472707
Validation loss: 2.829898215104595

Epoch: 6| Step: 3
Training loss: 1.5537875844103182
Validation loss: 2.7548120907199456

Epoch: 6| Step: 4
Training loss: 1.3692831055081671
Validation loss: 2.717435219257827

Epoch: 6| Step: 5
Training loss: 1.2766813841503475
Validation loss: 2.6993905880851785

Epoch: 6| Step: 6
Training loss: 1.915493364151842
Validation loss: 2.720583155192134

Epoch: 6| Step: 7
Training loss: 1.5784419279729331
Validation loss: 2.6494616363487364

Epoch: 6| Step: 8
Training loss: 1.2765963172869041
Validation loss: 2.693105145748099

Epoch: 6| Step: 9
Training loss: 1.3536661788196211
Validation loss: 2.73713021386363

Epoch: 6| Step: 10
Training loss: 1.8150980514649573
Validation loss: 2.7530628978178147

Epoch: 6| Step: 11
Training loss: 1.308051472368553
Validation loss: 2.717613815900121

Epoch: 6| Step: 12
Training loss: 2.518912495182441
Validation loss: 2.7508068634981546

Epoch: 6| Step: 13
Training loss: 1.754566365762907
Validation loss: 2.7243429657593774

Epoch: 110| Step: 0
Training loss: 1.7975097198647976
Validation loss: 2.7913164564399486

Epoch: 6| Step: 1
Training loss: 0.9142836930740103
Validation loss: 2.7814964299558205

Epoch: 6| Step: 2
Training loss: 1.2970110350810706
Validation loss: 2.7177351742041993

Epoch: 6| Step: 3
Training loss: 1.6723244321445694
Validation loss: 2.7980660969323665

Epoch: 6| Step: 4
Training loss: 1.7688430222491818
Validation loss: 2.78845491745801

Epoch: 6| Step: 5
Training loss: 1.3244905896081138
Validation loss: 2.757707919838601

Epoch: 6| Step: 6
Training loss: 1.3265018193145826
Validation loss: 2.703781077711469

Epoch: 6| Step: 7
Training loss: 1.307486541124442
Validation loss: 2.730317700546171

Epoch: 6| Step: 8
Training loss: 1.4408960447385384
Validation loss: 2.7347307536896914

Epoch: 6| Step: 9
Training loss: 1.8398482855155747
Validation loss: 2.7790433008893505

Epoch: 6| Step: 10
Training loss: 2.2376269171324963
Validation loss: 2.7209901021646297

Epoch: 6| Step: 11
Training loss: 1.4018031276284288
Validation loss: 2.6364892930396326

Epoch: 6| Step: 12
Training loss: 1.5817970385080113
Validation loss: 2.7698270696237928

Epoch: 6| Step: 13
Training loss: 1.2631658988571468
Validation loss: 2.6812326704886495

Epoch: 111| Step: 0
Training loss: 1.64709924550102
Validation loss: 2.7664569961043233

Epoch: 6| Step: 1
Training loss: 1.1931613689173026
Validation loss: 2.800750476875595

Epoch: 6| Step: 2
Training loss: 1.6995311932126698
Validation loss: 2.8738557777666207

Epoch: 6| Step: 3
Training loss: 1.3615852014707923
Validation loss: 2.901513276498332

Epoch: 6| Step: 4
Training loss: 1.4415381559891953
Validation loss: 2.790303756376046

Epoch: 6| Step: 5
Training loss: 1.3354194484370276
Validation loss: 2.7752586582136862

Epoch: 6| Step: 6
Training loss: 1.429235501573313
Validation loss: 2.6734613241757597

Epoch: 6| Step: 7
Training loss: 1.2334441042893136
Validation loss: 2.7291721800149067

Epoch: 6| Step: 8
Training loss: 1.6293327084325246
Validation loss: 2.740219293807989

Epoch: 6| Step: 9
Training loss: 1.869577004127453
Validation loss: 2.75323556078328

Epoch: 6| Step: 10
Training loss: 1.7727058010312617
Validation loss: 2.6993544195282255

Epoch: 6| Step: 11
Training loss: 1.0311233558341089
Validation loss: 2.7349058380747917

Epoch: 6| Step: 12
Training loss: 1.800054374509333
Validation loss: 2.7905213915254397

Epoch: 6| Step: 13
Training loss: 2.2035436570647033
Validation loss: 2.8097079087217187

Epoch: 112| Step: 0
Training loss: 2.1012073769861637
Validation loss: 2.8475115564439464

Epoch: 6| Step: 1
Training loss: 0.7490116600891223
Validation loss: 2.7634813582282374

Epoch: 6| Step: 2
Training loss: 1.1133656787647013
Validation loss: 2.86530461796229

Epoch: 6| Step: 3
Training loss: 1.3495008146178256
Validation loss: 2.688988487795919

Epoch: 6| Step: 4
Training loss: 1.1900492960873175
Validation loss: 2.672147130957549

Epoch: 6| Step: 5
Training loss: 1.395829139057899
Validation loss: 2.7609468106953177

Epoch: 6| Step: 6
Training loss: 1.7950707706962032
Validation loss: 2.7179936639488758

Epoch: 6| Step: 7
Training loss: 1.2541854404974904
Validation loss: 2.711785996274682

Epoch: 6| Step: 8
Training loss: 1.945277876335167
Validation loss: 2.741096141745791

Epoch: 6| Step: 9
Training loss: 1.4597269846778722
Validation loss: 2.8240209767874624

Epoch: 6| Step: 10
Training loss: 1.8333345832242463
Validation loss: 2.7046588816121306

Epoch: 6| Step: 11
Training loss: 1.6307886896405062
Validation loss: 2.72875065338551

Epoch: 6| Step: 12
Training loss: 1.428998437142502
Validation loss: 2.6765529884040213

Epoch: 6| Step: 13
Training loss: 1.4430407016166305
Validation loss: 2.7492544868721462

Epoch: 113| Step: 0
Training loss: 1.417910487972088
Validation loss: 2.782968411726793

Epoch: 6| Step: 1
Training loss: 0.8048839884737603
Validation loss: 2.7563877333685904

Epoch: 6| Step: 2
Training loss: 1.8466437955098751
Validation loss: 2.7168269975035804

Epoch: 6| Step: 3
Training loss: 1.2933738050977894
Validation loss: 2.7784736577574036

Epoch: 6| Step: 4
Training loss: 1.9887814595187643
Validation loss: 2.7571770761791408

Epoch: 6| Step: 5
Training loss: 1.0837268970319338
Validation loss: 2.754075657028108

Epoch: 6| Step: 6
Training loss: 1.3979843513638932
Validation loss: 2.706386414129933

Epoch: 6| Step: 7
Training loss: 1.2276066508839196
Validation loss: 2.7964338810747407

Epoch: 6| Step: 8
Training loss: 2.3749003138451736
Validation loss: 2.7112637047826507

Epoch: 6| Step: 9
Training loss: 1.2180913465850942
Validation loss: 2.714227049236622

Epoch: 6| Step: 10
Training loss: 1.3318679127712711
Validation loss: 2.7530853130065074

Epoch: 6| Step: 11
Training loss: 1.4386699725181726
Validation loss: 2.789444506331447

Epoch: 6| Step: 12
Training loss: 1.8484500526653367
Validation loss: 2.788450457098113

Epoch: 6| Step: 13
Training loss: 1.3308251253630152
Validation loss: 2.75655711763176

Epoch: 114| Step: 0
Training loss: 1.4529735527283276
Validation loss: 2.7534730106035674

Epoch: 6| Step: 1
Training loss: 1.1652833821512145
Validation loss: 2.667502113443936

Epoch: 6| Step: 2
Training loss: 1.290218597786853
Validation loss: 2.745609463222908

Epoch: 6| Step: 3
Training loss: 1.261652989046714
Validation loss: 2.7565455854163843

Epoch: 6| Step: 4
Training loss: 2.3834051677130863
Validation loss: 2.74825740279809

Epoch: 6| Step: 5
Training loss: 0.7943900013729472
Validation loss: 2.7398813518303946

Epoch: 6| Step: 6
Training loss: 1.5066486669973098
Validation loss: 2.7009429650761

Epoch: 6| Step: 7
Training loss: 1.4652204105583309
Validation loss: 2.7930165889173133

Epoch: 6| Step: 8
Training loss: 1.636599515882726
Validation loss: 2.745340865395199

Epoch: 6| Step: 9
Training loss: 1.4365628546332003
Validation loss: 2.790153154820527

Epoch: 6| Step: 10
Training loss: 1.2762246552135526
Validation loss: 2.852505393016196

Epoch: 6| Step: 11
Training loss: 1.6918995338354974
Validation loss: 2.7474744933138724

Epoch: 6| Step: 12
Training loss: 1.7466110384918259
Validation loss: 2.7764578263404514

Epoch: 6| Step: 13
Training loss: 0.9503653551560814
Validation loss: 2.8102198506167184

Epoch: 115| Step: 0
Training loss: 1.2384277160858705
Validation loss: 2.84846815021965

Epoch: 6| Step: 1
Training loss: 1.4518013124326792
Validation loss: 2.7992127237016415

Epoch: 6| Step: 2
Training loss: 1.0441716147810676
Validation loss: 2.763472558192834

Epoch: 6| Step: 3
Training loss: 1.7624246405324422
Validation loss: 2.827184109635701

Epoch: 6| Step: 4
Training loss: 1.6348717950141571
Validation loss: 2.7706456276168554

Epoch: 6| Step: 5
Training loss: 0.961346298969819
Validation loss: 2.717180639532143

Epoch: 6| Step: 6
Training loss: 2.374014499385426
Validation loss: 2.736647680493968

Epoch: 6| Step: 7
Training loss: 1.5419301074277059
Validation loss: 2.834231140904861

Epoch: 6| Step: 8
Training loss: 1.1046804036690832
Validation loss: 2.76268415110565

Epoch: 6| Step: 9
Training loss: 1.6191078615267391
Validation loss: 2.775605320707892

Epoch: 6| Step: 10
Training loss: 1.3030070372689333
Validation loss: 2.6875957057974404

Epoch: 6| Step: 11
Training loss: 1.1448002521909146
Validation loss: 2.701146513442189

Epoch: 6| Step: 12
Training loss: 1.061141435801228
Validation loss: 2.748948662092671

Epoch: 6| Step: 13
Training loss: 1.6733185427545239
Validation loss: 2.7980153904074165

Epoch: 116| Step: 0
Training loss: 1.3828995671852466
Validation loss: 2.8174164221845297

Epoch: 6| Step: 1
Training loss: 1.6903894905586878
Validation loss: 2.820498332684439

Epoch: 6| Step: 2
Training loss: 1.40509651348096
Validation loss: 2.838986147923014

Epoch: 6| Step: 3
Training loss: 1.4102585351256611
Validation loss: 2.7807394409180413

Epoch: 6| Step: 4
Training loss: 1.2945196064878357
Validation loss: 2.802598066925309

Epoch: 6| Step: 5
Training loss: 1.238949520160347
Validation loss: 2.8232653825938097

Epoch: 6| Step: 6
Training loss: 1.1337302338076822
Validation loss: 2.7701516472107284

Epoch: 6| Step: 7
Training loss: 0.9689050980973098
Validation loss: 2.807605482878682

Epoch: 6| Step: 8
Training loss: 1.5356845092421392
Validation loss: 2.8537745426841994

Epoch: 6| Step: 9
Training loss: 2.2869407011750256
Validation loss: 2.7947642497166814

Epoch: 6| Step: 10
Training loss: 1.1269577793177286
Validation loss: 2.7818973945053953

Epoch: 6| Step: 11
Training loss: 1.3534268877189841
Validation loss: 2.7900460981619233

Epoch: 6| Step: 12
Training loss: 1.363986819200791
Validation loss: 2.783937848471627

Epoch: 6| Step: 13
Training loss: 1.371692841760221
Validation loss: 2.8052925583558874

Epoch: 117| Step: 0
Training loss: 1.4032459810091686
Validation loss: 2.8568772487705245

Epoch: 6| Step: 1
Training loss: 2.262246500218905
Validation loss: 2.872083864306529

Epoch: 6| Step: 2
Training loss: 1.6281672935337548
Validation loss: 2.836672909106309

Epoch: 6| Step: 3
Training loss: 0.8805126852803807
Validation loss: 2.892440610609475

Epoch: 6| Step: 4
Training loss: 1.7558114423987972
Validation loss: 2.772233785971675

Epoch: 6| Step: 5
Training loss: 1.177648841699978
Validation loss: 2.8085875955442607

Epoch: 6| Step: 6
Training loss: 1.766019321396437
Validation loss: 2.8403915303734197

Epoch: 6| Step: 7
Training loss: 1.5020409051173513
Validation loss: 2.7196271219571524

Epoch: 6| Step: 8
Training loss: 1.3414590068700318
Validation loss: 2.735397162347324

Epoch: 6| Step: 9
Training loss: 1.314769553744701
Validation loss: 2.782069853340123

Epoch: 6| Step: 10
Training loss: 1.207021966299755
Validation loss: 2.857655506747506

Epoch: 6| Step: 11
Training loss: 1.6022371685379118
Validation loss: 2.843783451763886

Epoch: 6| Step: 12
Training loss: 1.3117886386631175
Validation loss: 2.8420133492954687

Epoch: 6| Step: 13
Training loss: 1.2737182120567232
Validation loss: 2.864422468812705

Epoch: 118| Step: 0
Training loss: 1.4408657642345497
Validation loss: 2.8004810805523643

Epoch: 6| Step: 1
Training loss: 1.375188901236431
Validation loss: 2.752941292599253

Epoch: 6| Step: 2
Training loss: 1.3107350608007808
Validation loss: 2.844697996869787

Epoch: 6| Step: 3
Training loss: 1.1976848322673361
Validation loss: 2.802714596987599

Epoch: 6| Step: 4
Training loss: 1.3072728108823128
Validation loss: 2.7175345206736674

Epoch: 6| Step: 5
Training loss: 1.4763012205794173
Validation loss: 2.777574460748009

Epoch: 6| Step: 6
Training loss: 1.2556246097577382
Validation loss: 2.7502132535380452

Epoch: 6| Step: 7
Training loss: 0.9117613624741276
Validation loss: 2.7718520956659285

Epoch: 6| Step: 8
Training loss: 1.9245594164506146
Validation loss: 2.7762799807822884

Epoch: 6| Step: 9
Training loss: 1.5212337889861551
Validation loss: 2.822835074133568

Epoch: 6| Step: 10
Training loss: 1.609068906248627
Validation loss: 2.9032393143851216

Epoch: 6| Step: 11
Training loss: 1.4637963377722127
Validation loss: 2.82688162713543

Epoch: 6| Step: 12
Training loss: 1.480105232157666
Validation loss: 2.8216677128053256

Epoch: 6| Step: 13
Training loss: 1.7855254277769093
Validation loss: 2.689784587084266

Epoch: 119| Step: 0
Training loss: 1.3730332440368467
Validation loss: 2.7346285166609623

Epoch: 6| Step: 1
Training loss: 1.0935726566953847
Validation loss: 2.767289833375147

Epoch: 6| Step: 2
Training loss: 1.3713213087821035
Validation loss: 2.8231558798097036

Epoch: 6| Step: 3
Training loss: 1.34516371060373
Validation loss: 2.8169202190093476

Epoch: 6| Step: 4
Training loss: 1.9565671572274146
Validation loss: 2.797966344585973

Epoch: 6| Step: 5
Training loss: 1.3005435027546648
Validation loss: 2.845527973426995

Epoch: 6| Step: 6
Training loss: 1.0947228600935384
Validation loss: 2.7990595492731116

Epoch: 6| Step: 7
Training loss: 1.3651162288772762
Validation loss: 2.860666369055071

Epoch: 6| Step: 8
Training loss: 2.006661526788527
Validation loss: 2.9202679109035254

Epoch: 6| Step: 9
Training loss: 1.4180011167589102
Validation loss: 2.8121674235059992

Epoch: 6| Step: 10
Training loss: 1.666562490386362
Validation loss: 2.811596972700895

Epoch: 6| Step: 11
Training loss: 1.314103600112144
Validation loss: 2.750394706143338

Epoch: 6| Step: 12
Training loss: 1.2139758478021447
Validation loss: 2.804866845250804

Epoch: 6| Step: 13
Training loss: 0.930910604190206
Validation loss: 2.771053883850394

Epoch: 120| Step: 0
Training loss: 1.223484575284281
Validation loss: 2.746444903984264

Epoch: 6| Step: 1
Training loss: 2.1157916771102383
Validation loss: 2.8829067390566108

Epoch: 6| Step: 2
Training loss: 1.2265296494282205
Validation loss: 2.8407779015970234

Epoch: 6| Step: 3
Training loss: 1.1222338046891498
Validation loss: 2.7769495974536325

Epoch: 6| Step: 4
Training loss: 1.1819081405600724
Validation loss: 2.823350237293224

Epoch: 6| Step: 5
Training loss: 1.3803145697631933
Validation loss: 2.841998304851115

Epoch: 6| Step: 6
Training loss: 1.4083719985590004
Validation loss: 2.810688947453879

Epoch: 6| Step: 7
Training loss: 1.3397266570326818
Validation loss: 2.8062541698263406

Epoch: 6| Step: 8
Training loss: 1.6203973584223497
Validation loss: 2.805576930788234

Epoch: 6| Step: 9
Training loss: 0.7066967631362386
Validation loss: 2.792421741760767

Epoch: 6| Step: 10
Training loss: 1.5461610630026101
Validation loss: 2.8938109427860166

Epoch: 6| Step: 11
Training loss: 1.1664356388955497
Validation loss: 2.7735505846636124

Epoch: 6| Step: 12
Training loss: 1.5940759362927868
Validation loss: 2.850565167210145

Epoch: 6| Step: 13
Training loss: 1.7183727890847333
Validation loss: 2.833636510747398

Epoch: 121| Step: 0
Training loss: 1.2268393623201492
Validation loss: 2.8301513325428367

Epoch: 6| Step: 1
Training loss: 1.4398933886428358
Validation loss: 2.8048655843912886

Epoch: 6| Step: 2
Training loss: 1.1429577319121937
Validation loss: 2.7805874924842744

Epoch: 6| Step: 3
Training loss: 1.2768499137217835
Validation loss: 2.8281283580556362

Epoch: 6| Step: 4
Training loss: 1.3208999681160731
Validation loss: 2.7815134516606794

Epoch: 6| Step: 5
Training loss: 2.2224354827064117
Validation loss: 2.892170632023107

Epoch: 6| Step: 6
Training loss: 0.810753926867851
Validation loss: 2.8782378912871227

Epoch: 6| Step: 7
Training loss: 1.4179278911662325
Validation loss: 2.9117561738468525

Epoch: 6| Step: 8
Training loss: 1.3336298682356114
Validation loss: 2.8599924417987177

Epoch: 6| Step: 9
Training loss: 1.245531822428993
Validation loss: 2.831088569984881

Epoch: 6| Step: 10
Training loss: 1.5798347200790765
Validation loss: 2.868484785664974

Epoch: 6| Step: 11
Training loss: 1.3216771403824097
Validation loss: 2.8254653057964885

Epoch: 6| Step: 12
Training loss: 1.1971369762907005
Validation loss: 2.824082015558506

Epoch: 6| Step: 13
Training loss: 1.030801097383311
Validation loss: 2.822582799915071

Epoch: 122| Step: 0
Training loss: 1.3947090014271093
Validation loss: 2.8001405629570644

Epoch: 6| Step: 1
Training loss: 1.6222810005545067
Validation loss: 2.7875482845828734

Epoch: 6| Step: 2
Training loss: 1.1082076257151072
Validation loss: 2.904850817804057

Epoch: 6| Step: 3
Training loss: 1.4193342375518752
Validation loss: 2.9011649899435055

Epoch: 6| Step: 4
Training loss: 1.2618812480014183
Validation loss: 2.7484707770864083

Epoch: 6| Step: 5
Training loss: 1.0216756317052336
Validation loss: 2.7734810839170074

Epoch: 6| Step: 6
Training loss: 1.6549365035493142
Validation loss: 2.799893843818299

Epoch: 6| Step: 7
Training loss: 1.5922859797845539
Validation loss: 2.797645789408007

Epoch: 6| Step: 8
Training loss: 1.1963121808990664
Validation loss: 2.8315024537746045

Epoch: 6| Step: 9
Training loss: 1.08717445894223
Validation loss: 2.88873003457693

Epoch: 6| Step: 10
Training loss: 2.2441821646435587
Validation loss: 2.8834286163183305

Epoch: 6| Step: 11
Training loss: 1.4440830259467898
Validation loss: 2.911444380197318

Epoch: 6| Step: 12
Training loss: 1.3581925873104883
Validation loss: 2.977797518187499

Epoch: 6| Step: 13
Training loss: 1.02871484967573
Validation loss: 2.8657463672025556

Epoch: 123| Step: 0
Training loss: 1.2422631678536846
Validation loss: 2.8058553122178984

Epoch: 6| Step: 1
Training loss: 1.1686138808190378
Validation loss: 2.8155117439752666

Epoch: 6| Step: 2
Training loss: 1.0871667285501814
Validation loss: 2.8028320437259735

Epoch: 6| Step: 3
Training loss: 1.4280455285462548
Validation loss: 2.8056699401107

Epoch: 6| Step: 4
Training loss: 0.9922357682629689
Validation loss: 2.8615970697828574

Epoch: 6| Step: 5
Training loss: 1.034615429367444
Validation loss: 2.8208801318239853

Epoch: 6| Step: 6
Training loss: 2.4214615991994806
Validation loss: 2.7906434095913886

Epoch: 6| Step: 7
Training loss: 1.545207348091573
Validation loss: 2.832889063916166

Epoch: 6| Step: 8
Training loss: 1.6675109949850393
Validation loss: 2.8526987259446566

Epoch: 6| Step: 9
Training loss: 1.2076861632525824
Validation loss: 2.8051430589910455

Epoch: 6| Step: 10
Training loss: 1.1035928074674592
Validation loss: 2.938574776952566

Epoch: 6| Step: 11
Training loss: 1.273881799619276
Validation loss: 2.8819305531934267

Epoch: 6| Step: 12
Training loss: 1.0236384070828919
Validation loss: 2.8864586299555137

Epoch: 6| Step: 13
Training loss: 1.339349327393184
Validation loss: 2.8596007044362426

Epoch: 124| Step: 0
Training loss: 1.415496688989818
Validation loss: 2.8974714562911172

Epoch: 6| Step: 1
Training loss: 2.072258376702981
Validation loss: 2.820948563386388

Epoch: 6| Step: 2
Training loss: 0.8881654071676045
Validation loss: 2.7570406776584835

Epoch: 6| Step: 3
Training loss: 1.4523182752323447
Validation loss: 2.7968659640544504

Epoch: 6| Step: 4
Training loss: 1.5496589962337373
Validation loss: 2.8868875897233424

Epoch: 6| Step: 5
Training loss: 1.3922292478319354
Validation loss: 2.8235008554927377

Epoch: 6| Step: 6
Training loss: 1.1561201383505184
Validation loss: 2.789590132070912

Epoch: 6| Step: 7
Training loss: 1.179945153400343
Validation loss: 2.874739178975625

Epoch: 6| Step: 8
Training loss: 1.622140128454997
Validation loss: 2.8792169645657255

Epoch: 6| Step: 9
Training loss: 1.1730534540957955
Validation loss: 2.786715976295556

Epoch: 6| Step: 10
Training loss: 0.9720111837371623
Validation loss: 2.8678586557168617

Epoch: 6| Step: 11
Training loss: 1.2102090428795127
Validation loss: 2.86376707527335

Epoch: 6| Step: 12
Training loss: 1.038062395921622
Validation loss: 2.8894376360945815

Epoch: 6| Step: 13
Training loss: 1.1665166803860527
Validation loss: 2.8010945519537875

Epoch: 125| Step: 0
Training loss: 1.1470366777178083
Validation loss: 2.8433205137004807

Epoch: 6| Step: 1
Training loss: 1.4665298726849778
Validation loss: 2.83372289186089

Epoch: 6| Step: 2
Training loss: 0.9589087928463514
Validation loss: 2.836771006213602

Epoch: 6| Step: 3
Training loss: 2.168837364701735
Validation loss: 2.8459574477320198

Epoch: 6| Step: 4
Training loss: 1.0873034551746092
Validation loss: 2.871397698677464

Epoch: 6| Step: 5
Training loss: 1.5475477817042402
Validation loss: 2.9060133834280397

Epoch: 6| Step: 6
Training loss: 1.441268128597855
Validation loss: 2.872007803186426

Epoch: 6| Step: 7
Training loss: 1.2719644088624178
Validation loss: 2.868922499468741

Epoch: 6| Step: 8
Training loss: 1.0817479062149382
Validation loss: 2.869624613603505

Epoch: 6| Step: 9
Training loss: 1.8541423996040982
Validation loss: 2.8553394822389864

Epoch: 6| Step: 10
Training loss: 1.2001234984426736
Validation loss: 2.8635975939212015

Epoch: 6| Step: 11
Training loss: 0.836512964696566
Validation loss: 2.84600074484166

Epoch: 6| Step: 12
Training loss: 1.056761560200402
Validation loss: 2.8315466876224

Epoch: 6| Step: 13
Training loss: 0.7748401907769666
Validation loss: 2.837883329896243

Epoch: 126| Step: 0
Training loss: 1.4242276022463853
Validation loss: 2.8541773821404526

Epoch: 6| Step: 1
Training loss: 1.1908284771880076
Validation loss: 2.8971205441668237

Epoch: 6| Step: 2
Training loss: 1.0639263564523818
Validation loss: 2.9317144002998896

Epoch: 6| Step: 3
Training loss: 1.3285672517350458
Validation loss: 2.833401992377347

Epoch: 6| Step: 4
Training loss: 1.2095645135056474
Validation loss: 2.9230995264221895

Epoch: 6| Step: 5
Training loss: 1.1960447972880242
Validation loss: 2.855112605883342

Epoch: 6| Step: 6
Training loss: 1.1276723064364644
Validation loss: 2.8758722999900423

Epoch: 6| Step: 7
Training loss: 1.21780133616925
Validation loss: 2.8838174200423805

Epoch: 6| Step: 8
Training loss: 0.9950623801340152
Validation loss: 2.9255143753930364

Epoch: 6| Step: 9
Training loss: 1.2310391511803724
Validation loss: 3.040258490966604

Epoch: 6| Step: 10
Training loss: 2.1896652404777415
Validation loss: 2.885024120928565

Epoch: 6| Step: 11
Training loss: 1.2383486852725378
Validation loss: 2.877336547743116

Epoch: 6| Step: 12
Training loss: 1.3999306576449757
Validation loss: 2.8035093080200446

Epoch: 6| Step: 13
Training loss: 1.5158969595825216
Validation loss: 2.825571161106124

Epoch: 127| Step: 0
Training loss: 1.727885779160001
Validation loss: 2.8316801427917553

Epoch: 6| Step: 1
Training loss: 1.1357003595418613
Validation loss: 2.8062834949377735

Epoch: 6| Step: 2
Training loss: 1.2748286599613734
Validation loss: 2.846448281917281

Epoch: 6| Step: 3
Training loss: 1.0178342412700219
Validation loss: 2.747994341751448

Epoch: 6| Step: 4
Training loss: 1.5007562320496586
Validation loss: 2.847490233442813

Epoch: 6| Step: 5
Training loss: 1.199722035321571
Validation loss: 2.909688754156055

Epoch: 6| Step: 6
Training loss: 1.423797648957963
Validation loss: 2.821110197836446

Epoch: 6| Step: 7
Training loss: 1.5559672546912768
Validation loss: 2.84101618894364

Epoch: 6| Step: 8
Training loss: 0.8725404230498189
Validation loss: 2.7892153259065995

Epoch: 6| Step: 9
Training loss: 1.9584400337316066
Validation loss: 2.840323329416216

Epoch: 6| Step: 10
Training loss: 1.298178052630839
Validation loss: 2.7915425533964364

Epoch: 6| Step: 11
Training loss: 1.2634538465372258
Validation loss: 2.7973163192623742

Epoch: 6| Step: 12
Training loss: 1.2414338806803258
Validation loss: 2.8095992211357435

Epoch: 6| Step: 13
Training loss: 1.1434883860743466
Validation loss: 2.8103040246090902

Epoch: 128| Step: 0
Training loss: 1.2566837909317623
Validation loss: 2.912999590809849

Epoch: 6| Step: 1
Training loss: 1.0425099710403867
Validation loss: 2.8541270320581424

Epoch: 6| Step: 2
Training loss: 1.0997610851404696
Validation loss: 2.9337254616147694

Epoch: 6| Step: 3
Training loss: 1.6638610431348575
Validation loss: 2.887327275470282

Epoch: 6| Step: 4
Training loss: 1.6337646190686803
Validation loss: 2.8112484301784186

Epoch: 6| Step: 5
Training loss: 1.9705659272268368
Validation loss: 2.8263810262068207

Epoch: 6| Step: 6
Training loss: 1.1602102453337413
Validation loss: 2.797674934887979

Epoch: 6| Step: 7
Training loss: 1.4934973435226635
Validation loss: 2.8832403346225255

Epoch: 6| Step: 8
Training loss: 1.25420644618893
Validation loss: 2.834432155112776

Epoch: 6| Step: 9
Training loss: 1.0013953249426606
Validation loss: 2.882745674826765

Epoch: 6| Step: 10
Training loss: 1.0860822841811226
Validation loss: 2.939908697198393

Epoch: 6| Step: 11
Training loss: 0.8969343132582842
Validation loss: 2.865214182429983

Epoch: 6| Step: 12
Training loss: 1.368513978788476
Validation loss: 2.843677666551144

Epoch: 6| Step: 13
Training loss: 1.0163743995643149
Validation loss: 2.8135195261764268

Epoch: 129| Step: 0
Training loss: 1.212932886932292
Validation loss: 2.8786517599693724

Epoch: 6| Step: 1
Training loss: 1.1868767357562944
Validation loss: 2.8803866758311467

Epoch: 6| Step: 2
Training loss: 0.8037301451750597
Validation loss: 2.8474011579489

Epoch: 6| Step: 3
Training loss: 1.0773292037059303
Validation loss: 2.8714679223346353

Epoch: 6| Step: 4
Training loss: 0.8629614121019595
Validation loss: 2.9129799066800652

Epoch: 6| Step: 5
Training loss: 2.019879132233359
Validation loss: 2.8533037278015003

Epoch: 6| Step: 6
Training loss: 1.5081770065958728
Validation loss: 2.85394118223507

Epoch: 6| Step: 7
Training loss: 1.560221880514681
Validation loss: 2.8882990371449444

Epoch: 6| Step: 8
Training loss: 1.2044381245974767
Validation loss: 2.8629530319134657

Epoch: 6| Step: 9
Training loss: 1.304691520273559
Validation loss: 2.819363040615417

Epoch: 6| Step: 10
Training loss: 0.9156341083581334
Validation loss: 2.8001817303674232

Epoch: 6| Step: 11
Training loss: 1.1764242752159542
Validation loss: 2.793067130110086

Epoch: 6| Step: 12
Training loss: 1.5249230599927672
Validation loss: 2.7928982812487937

Epoch: 6| Step: 13
Training loss: 1.0988770887285382
Validation loss: 2.815040952317983

Epoch: 130| Step: 0
Training loss: 1.1828601943444643
Validation loss: 2.8471136775428842

Epoch: 6| Step: 1
Training loss: 0.9380581465859087
Validation loss: 2.920045385225743

Epoch: 6| Step: 2
Training loss: 1.2181677772522825
Validation loss: 2.9459890571739757

Epoch: 6| Step: 3
Training loss: 1.862067124927946
Validation loss: 2.9470938532856494

Epoch: 6| Step: 4
Training loss: 0.9781317652751729
Validation loss: 2.8470462377688377

Epoch: 6| Step: 5
Training loss: 0.9792957051790947
Validation loss: 2.874873614643068

Epoch: 6| Step: 6
Training loss: 0.8074974700132247
Validation loss: 2.7936358244320374

Epoch: 6| Step: 7
Training loss: 1.9295262566663338
Validation loss: 2.848078371567149

Epoch: 6| Step: 8
Training loss: 1.2943885591055568
Validation loss: 2.807664104567232

Epoch: 6| Step: 9
Training loss: 1.2126466564088487
Validation loss: 2.8244839407906106

Epoch: 6| Step: 10
Training loss: 1.1296743136278729
Validation loss: 2.8182506262721776

Epoch: 6| Step: 11
Training loss: 1.1204019997571744
Validation loss: 2.882924106163956

Epoch: 6| Step: 12
Training loss: 1.2202509416397984
Validation loss: 2.8320742268425496

Epoch: 6| Step: 13
Training loss: 1.330844607885699
Validation loss: 2.90263736928781

Epoch: 131| Step: 0
Training loss: 1.0342882655909382
Validation loss: 2.8883692970025323

Epoch: 6| Step: 1
Training loss: 1.3992740111138744
Validation loss: 2.885756756035208

Epoch: 6| Step: 2
Training loss: 0.975247833347334
Validation loss: 2.9059482677613153

Epoch: 6| Step: 3
Training loss: 1.4416557447574687
Validation loss: 2.8702686741860517

Epoch: 6| Step: 4
Training loss: 1.2421382198515112
Validation loss: 2.817111296988668

Epoch: 6| Step: 5
Training loss: 0.6556827045934733
Validation loss: 2.882098322262203

Epoch: 6| Step: 6
Training loss: 1.2446706651855983
Validation loss: 2.899515806532734

Epoch: 6| Step: 7
Training loss: 1.0966307169714025
Validation loss: 2.843937626612099

Epoch: 6| Step: 8
Training loss: 1.4239249072259594
Validation loss: 2.877200335076278

Epoch: 6| Step: 9
Training loss: 2.075569359671963
Validation loss: 2.9056571574546926

Epoch: 6| Step: 10
Training loss: 0.8915018483419294
Validation loss: 2.850256076261661

Epoch: 6| Step: 11
Training loss: 1.472078650249623
Validation loss: 2.797857002044414

Epoch: 6| Step: 12
Training loss: 0.8435512591232934
Validation loss: 2.8515914009754746

Epoch: 6| Step: 13
Training loss: 0.9804315749944013
Validation loss: 2.8786535268595292

Epoch: 132| Step: 0
Training loss: 1.1520984970575658
Validation loss: 2.8250475696620896

Epoch: 6| Step: 1
Training loss: 0.9906522331946951
Validation loss: 2.8043292143493073

Epoch: 6| Step: 2
Training loss: 1.5304596087195896
Validation loss: 2.8422562305486054

Epoch: 6| Step: 3
Training loss: 1.045083348997693
Validation loss: 2.8595197185866583

Epoch: 6| Step: 4
Training loss: 1.4755654172650774
Validation loss: 2.9521730829746082

Epoch: 6| Step: 5
Training loss: 0.9927178714983794
Validation loss: 2.776083329814341

Epoch: 6| Step: 6
Training loss: 1.1148466114202613
Validation loss: 2.866896210026433

Epoch: 6| Step: 7
Training loss: 1.9522454074058684
Validation loss: 2.854143091554571

Epoch: 6| Step: 8
Training loss: 1.248270268513107
Validation loss: 2.8243711508701965

Epoch: 6| Step: 9
Training loss: 1.2913987692023763
Validation loss: 2.930227746954564

Epoch: 6| Step: 10
Training loss: 0.8420080995306045
Validation loss: 2.899239209013064

Epoch: 6| Step: 11
Training loss: 1.453433916624315
Validation loss: 2.910857591881966

Epoch: 6| Step: 12
Training loss: 1.0628986171883175
Validation loss: 2.905629963516719

Epoch: 6| Step: 13
Training loss: 1.0742140891234113
Validation loss: 2.903027597250419

Epoch: 133| Step: 0
Training loss: 1.3096335763463853
Validation loss: 2.8764013800254387

Epoch: 6| Step: 1
Training loss: 1.2828678058778262
Validation loss: 2.8870813247872604

Epoch: 6| Step: 2
Training loss: 1.5526241239356842
Validation loss: 2.9415232654952415

Epoch: 6| Step: 3
Training loss: 1.158127986535608
Validation loss: 2.804060898742139

Epoch: 6| Step: 4
Training loss: 1.2825437852103727
Validation loss: 2.857687961429464

Epoch: 6| Step: 5
Training loss: 0.8776212666069049
Validation loss: 2.906090024421388

Epoch: 6| Step: 6
Training loss: 0.8515427613376775
Validation loss: 3.0240695499717605

Epoch: 6| Step: 7
Training loss: 0.965475763436517
Validation loss: 3.0350358138047855

Epoch: 6| Step: 8
Training loss: 1.0874326005416728
Validation loss: 3.0464595544049096

Epoch: 6| Step: 9
Training loss: 1.9268909530152483
Validation loss: 2.9987914512094167

Epoch: 6| Step: 10
Training loss: 1.2300314958928356
Validation loss: 2.9081384956073504

Epoch: 6| Step: 11
Training loss: 1.0162990387443298
Validation loss: 2.8813417675219086

Epoch: 6| Step: 12
Training loss: 1.2925186065131435
Validation loss: 2.8488246367964214

Epoch: 6| Step: 13
Training loss: 1.3685273934418145
Validation loss: 2.888088660078622

Epoch: 134| Step: 0
Training loss: 1.2093509740685413
Validation loss: 2.832703651319052

Epoch: 6| Step: 1
Training loss: 1.2537411970322034
Validation loss: 2.799553254795732

Epoch: 6| Step: 2
Training loss: 1.6089276923604692
Validation loss: 2.854198126143853

Epoch: 6| Step: 3
Training loss: 1.1611702851199441
Validation loss: 2.9655633387370774

Epoch: 6| Step: 4
Training loss: 1.5885562416617056
Validation loss: 2.916281243244259

Epoch: 6| Step: 5
Training loss: 1.0946436909352606
Validation loss: 2.9050306407868614

Epoch: 6| Step: 6
Training loss: 0.8478831325963755
Validation loss: 2.869391873314985

Epoch: 6| Step: 7
Training loss: 1.8102002516771107
Validation loss: 2.8680528379544943

Epoch: 6| Step: 8
Training loss: 1.0543533360958393
Validation loss: 2.906425183666585

Epoch: 6| Step: 9
Training loss: 0.960302065275276
Validation loss: 2.9009611756660165

Epoch: 6| Step: 10
Training loss: 0.649111661559838
Validation loss: 2.887081978554852

Epoch: 6| Step: 11
Training loss: 0.9043882912883009
Validation loss: 2.833477203605932

Epoch: 6| Step: 12
Training loss: 1.1838592130880996
Validation loss: 2.9861709224023856

Epoch: 6| Step: 13
Training loss: 1.167020227582195
Validation loss: 2.8779898383606453

Epoch: 135| Step: 0
Training loss: 0.9913465585617427
Validation loss: 2.962092567680225

Epoch: 6| Step: 1
Training loss: 1.7996044492560994
Validation loss: 2.945370080791453

Epoch: 6| Step: 2
Training loss: 1.1522524005436985
Validation loss: 2.8884940188293533

Epoch: 6| Step: 3
Training loss: 1.088813650414514
Validation loss: 2.9350310832927846

Epoch: 6| Step: 4
Training loss: 1.381061889819556
Validation loss: 2.796943010181721

Epoch: 6| Step: 5
Training loss: 1.165418002078169
Validation loss: 2.8744433596680694

Epoch: 6| Step: 6
Training loss: 0.8594038524986103
Validation loss: 2.874647754707243

Epoch: 6| Step: 7
Training loss: 0.647024015871208
Validation loss: 2.8836062474902815

Epoch: 6| Step: 8
Training loss: 1.0643120068441385
Validation loss: 2.882244988107031

Epoch: 6| Step: 9
Training loss: 1.125555695937201
Validation loss: 2.884091514799403

Epoch: 6| Step: 10
Training loss: 1.513774095590782
Validation loss: 2.935990087536598

Epoch: 6| Step: 11
Training loss: 0.8087892894841281
Validation loss: 2.8956793234142957

Epoch: 6| Step: 12
Training loss: 0.9385141926821753
Validation loss: 2.9318693996406586

Epoch: 6| Step: 13
Training loss: 1.4421907269905663
Validation loss: 2.9139268722539464

Epoch: 136| Step: 0
Training loss: 1.3768972831928115
Validation loss: 2.980153131668192

Epoch: 6| Step: 1
Training loss: 1.3326791658599328
Validation loss: 2.895652522930553

Epoch: 6| Step: 2
Training loss: 1.625576723900621
Validation loss: 2.882643421594

Epoch: 6| Step: 3
Training loss: 1.0699704591291848
Validation loss: 2.917095606915701

Epoch: 6| Step: 4
Training loss: 0.9186813186093945
Validation loss: 2.852556858270602

Epoch: 6| Step: 5
Training loss: 0.9163145378771318
Validation loss: 2.9418084763304195

Epoch: 6| Step: 6
Training loss: 1.0972344073223923
Validation loss: 2.8855578024232846

Epoch: 6| Step: 7
Training loss: 1.754953186628025
Validation loss: 2.8289650921556264

Epoch: 6| Step: 8
Training loss: 1.9413954429402425
Validation loss: 2.8186137965100055

Epoch: 6| Step: 9
Training loss: 1.0080349698812736
Validation loss: 2.947966832429423

Epoch: 6| Step: 10
Training loss: 1.1524505048537639
Validation loss: 2.9207825820003674

Epoch: 6| Step: 11
Training loss: 1.211448020377288
Validation loss: 3.0658820414910024

Epoch: 6| Step: 12
Training loss: 1.2470391492900537
Validation loss: 3.1155880654510693

Epoch: 6| Step: 13
Training loss: 1.0522948074570868
Validation loss: 2.973083398568145

Epoch: 137| Step: 0
Training loss: 0.955461358878493
Validation loss: 2.890116768912217

Epoch: 6| Step: 1
Training loss: 2.1226317728966904
Validation loss: 2.8793524401105053

Epoch: 6| Step: 2
Training loss: 1.0563811091024191
Validation loss: 2.867070929351646

Epoch: 6| Step: 3
Training loss: 1.1179412219952272
Validation loss: 2.7843751672587005

Epoch: 6| Step: 4
Training loss: 1.2182484108115825
Validation loss: 2.8438089106120508

Epoch: 6| Step: 5
Training loss: 0.9874758548440533
Validation loss: 2.9646755567848704

Epoch: 6| Step: 6
Training loss: 1.1265214063368887
Validation loss: 2.9684171657372462

Epoch: 6| Step: 7
Training loss: 0.7404556145099624
Validation loss: 2.953607025366887

Epoch: 6| Step: 8
Training loss: 1.330772095626692
Validation loss: 2.9882880582711113

Epoch: 6| Step: 9
Training loss: 0.8094574374483604
Validation loss: 2.9432756040347203

Epoch: 6| Step: 10
Training loss: 1.1150712463470358
Validation loss: 2.973818297465762

Epoch: 6| Step: 11
Training loss: 1.2722120883395525
Validation loss: 2.886988357528398

Epoch: 6| Step: 12
Training loss: 1.084586421352997
Validation loss: 2.8553760685732725

Epoch: 6| Step: 13
Training loss: 1.3634166049164913
Validation loss: 2.899647860139097

Epoch: 138| Step: 0
Training loss: 1.3862760455038414
Validation loss: 2.9096287601323905

Epoch: 6| Step: 1
Training loss: 1.066325984630998
Validation loss: 2.911626279805949

Epoch: 6| Step: 2
Training loss: 1.1250913370989866
Validation loss: 2.919354322171453

Epoch: 6| Step: 3
Training loss: 1.1641456011097542
Validation loss: 2.959089482521104

Epoch: 6| Step: 4
Training loss: 1.0723515599458444
Validation loss: 2.9740580304343274

Epoch: 6| Step: 5
Training loss: 0.9659303731664677
Validation loss: 2.981913511813383

Epoch: 6| Step: 6
Training loss: 1.1859039321993772
Validation loss: 2.8710252403337635

Epoch: 6| Step: 7
Training loss: 0.8680214180061816
Validation loss: 2.892754040472477

Epoch: 6| Step: 8
Training loss: 1.0430380123157057
Validation loss: 2.8395642226526037

Epoch: 6| Step: 9
Training loss: 2.0577145170086886
Validation loss: 2.9004934444676724

Epoch: 6| Step: 10
Training loss: 0.8064137063423618
Validation loss: 2.856701509555515

Epoch: 6| Step: 11
Training loss: 1.035683954433675
Validation loss: 2.8627314089504914

Epoch: 6| Step: 12
Training loss: 1.66438039689258
Validation loss: 2.8829339612616747

Epoch: 6| Step: 13
Training loss: 0.6808155827054574
Validation loss: 2.9113550469236125

Epoch: 139| Step: 0
Training loss: 1.430348894732625
Validation loss: 2.9756828603638965

Epoch: 6| Step: 1
Training loss: 1.338410436626952
Validation loss: 2.9923865482003325

Epoch: 6| Step: 2
Training loss: 0.8324202939845967
Validation loss: 2.9766047250284147

Epoch: 6| Step: 3
Training loss: 1.0500211554621315
Validation loss: 2.982590359781626

Epoch: 6| Step: 4
Training loss: 2.0369530066424044
Validation loss: 2.965243735156468

Epoch: 6| Step: 5
Training loss: 1.0113544765677163
Validation loss: 2.880481249460805

Epoch: 6| Step: 6
Training loss: 0.844670888135498
Validation loss: 2.9095559817470784

Epoch: 6| Step: 7
Training loss: 1.0979042723292092
Validation loss: 2.9515940147374717

Epoch: 6| Step: 8
Training loss: 1.2480120109261343
Validation loss: 2.9704459984277785

Epoch: 6| Step: 9
Training loss: 1.154454873981998
Validation loss: 2.905959179728275

Epoch: 6| Step: 10
Training loss: 0.8976414014419862
Validation loss: 2.930508863811347

Epoch: 6| Step: 11
Training loss: 1.299030030124415
Validation loss: 2.9269264332994887

Epoch: 6| Step: 12
Training loss: 0.8808993649762242
Validation loss: 2.860947279164247

Epoch: 6| Step: 13
Training loss: 0.699966563550197
Validation loss: 2.9844409475979075

Epoch: 140| Step: 0
Training loss: 1.270813514471552
Validation loss: 2.9358944935581546

Epoch: 6| Step: 1
Training loss: 1.1711601111280736
Validation loss: 2.9164696263558967

Epoch: 6| Step: 2
Training loss: 1.118186344107965
Validation loss: 2.930335974238396

Epoch: 6| Step: 3
Training loss: 1.0678631119850595
Validation loss: 2.9378659446520596

Epoch: 6| Step: 4
Training loss: 1.03051315339202
Validation loss: 2.8813493387415297

Epoch: 6| Step: 5
Training loss: 0.8614760637284562
Validation loss: 2.9255770929102134

Epoch: 6| Step: 6
Training loss: 0.7638649854869701
Validation loss: 2.81809350916677

Epoch: 6| Step: 7
Training loss: 1.0902018078512075
Validation loss: 2.924253383128696

Epoch: 6| Step: 8
Training loss: 0.9538092736540271
Validation loss: 2.990242135610711

Epoch: 6| Step: 9
Training loss: 0.9716105527580348
Validation loss: 2.871680361101999

Epoch: 6| Step: 10
Training loss: 1.441269121134187
Validation loss: 2.9671822005323856

Epoch: 6| Step: 11
Training loss: 1.309008723265605
Validation loss: 2.9053176013143625

Epoch: 6| Step: 12
Training loss: 1.7797700857772443
Validation loss: 2.973154114024732

Epoch: 6| Step: 13
Training loss: 0.9041759171137218
Validation loss: 2.933596851873811

Epoch: 141| Step: 0
Training loss: 0.6384712860832279
Validation loss: 2.9976622559466795

Epoch: 6| Step: 1
Training loss: 1.2606461161110671
Validation loss: 2.936403516294065

Epoch: 6| Step: 2
Training loss: 0.8437024562297614
Validation loss: 2.9123948739961865

Epoch: 6| Step: 3
Training loss: 1.9223766757613745
Validation loss: 2.946091647515347

Epoch: 6| Step: 4
Training loss: 0.876521762710468
Validation loss: 2.89393011621522

Epoch: 6| Step: 5
Training loss: 0.9826313500776038
Validation loss: 2.9010177054291724

Epoch: 6| Step: 6
Training loss: 1.5443926072207277
Validation loss: 3.1031825833389712

Epoch: 6| Step: 7
Training loss: 0.9865358039595936
Validation loss: 3.098426482565294

Epoch: 6| Step: 8
Training loss: 0.8812731259605522
Validation loss: 2.9786878659001403

Epoch: 6| Step: 9
Training loss: 1.1021167632274664
Validation loss: 2.963142265307609

Epoch: 6| Step: 10
Training loss: 0.9902795484121888
Validation loss: 2.8991373045040176

Epoch: 6| Step: 11
Training loss: 0.9738124425354437
Validation loss: 2.9090716156355874

Epoch: 6| Step: 12
Training loss: 0.9827396796438373
Validation loss: 2.99538219876918

Epoch: 6| Step: 13
Training loss: 1.0241393965672223
Validation loss: 3.01805961248932

Epoch: 142| Step: 0
Training loss: 0.9643327232285948
Validation loss: 3.00971637927313

Epoch: 6| Step: 1
Training loss: 1.0502740706654945
Validation loss: 2.8747094325415525

Epoch: 6| Step: 2
Training loss: 1.6637271310336548
Validation loss: 2.946874384847977

Epoch: 6| Step: 3
Training loss: 0.6679600943735158
Validation loss: 2.980181612288092

Epoch: 6| Step: 4
Training loss: 0.9499070297726441
Validation loss: 3.055246703597026

Epoch: 6| Step: 5
Training loss: 0.8900300431270634
Validation loss: 3.034491716229537

Epoch: 6| Step: 6
Training loss: 1.0595397663547705
Validation loss: 2.9721918064910193

Epoch: 6| Step: 7
Training loss: 0.8176877126503195
Validation loss: 2.9716304390953163

Epoch: 6| Step: 8
Training loss: 1.2855639984835772
Validation loss: 3.0104716250848944

Epoch: 6| Step: 9
Training loss: 0.9625628302242737
Validation loss: 2.9476473969502597

Epoch: 6| Step: 10
Training loss: 1.5476640942763253
Validation loss: 2.8811548941383442

Epoch: 6| Step: 11
Training loss: 0.8478938881503653
Validation loss: 3.0322597696366724

Epoch: 6| Step: 12
Training loss: 0.7976496428123568
Validation loss: 2.9482627144337235

Epoch: 6| Step: 13
Training loss: 1.2395469382363318
Validation loss: 3.001994847289222

Epoch: 143| Step: 0
Training loss: 1.2056518376093837
Validation loss: 2.9104102516695254

Epoch: 6| Step: 1
Training loss: 0.9941812743024816
Validation loss: 2.9287525227897135

Epoch: 6| Step: 2
Training loss: 0.8320500188152301
Validation loss: 2.957492579055552

Epoch: 6| Step: 3
Training loss: 1.0291997005911435
Validation loss: 2.973995994601089

Epoch: 6| Step: 4
Training loss: 0.8194814559602617
Validation loss: 2.934681642846257

Epoch: 6| Step: 5
Training loss: 0.7049325385857211
Validation loss: 2.883047974712071

Epoch: 6| Step: 6
Training loss: 1.0740795808287993
Validation loss: 2.937114555015077

Epoch: 6| Step: 7
Training loss: 0.6983488841665917
Validation loss: 2.9157505276865483

Epoch: 6| Step: 8
Training loss: 1.0228598325729017
Validation loss: 3.0193130789400504

Epoch: 6| Step: 9
Training loss: 1.6957256323553793
Validation loss: 2.958609532281514

Epoch: 6| Step: 10
Training loss: 1.4353163345920228
Validation loss: 3.023850208276244

Epoch: 6| Step: 11
Training loss: 1.0708209312898342
Validation loss: 3.038818754932346

Epoch: 6| Step: 12
Training loss: 1.033091201921707
Validation loss: 2.972639540810395

Epoch: 6| Step: 13
Training loss: 1.311782050181603
Validation loss: 3.000030861801775

Epoch: 144| Step: 0
Training loss: 0.9078504636511754
Validation loss: 2.9414276757205076

Epoch: 6| Step: 1
Training loss: 0.9182282425992445
Validation loss: 3.0114797587222477

Epoch: 6| Step: 2
Training loss: 0.9851545547119849
Validation loss: 2.9953558658491284

Epoch: 6| Step: 3
Training loss: 1.2835411427839454
Validation loss: 2.988213831321795

Epoch: 6| Step: 4
Training loss: 1.1112143084498096
Validation loss: 3.0569028764211645

Epoch: 6| Step: 5
Training loss: 1.8444051709966534
Validation loss: 2.986472971871119

Epoch: 6| Step: 6
Training loss: 0.8226843558325787
Validation loss: 2.919191321391291

Epoch: 6| Step: 7
Training loss: 1.294804632480526
Validation loss: 2.897405325785865

Epoch: 6| Step: 8
Training loss: 1.3342353729881535
Validation loss: 2.980008377643731

Epoch: 6| Step: 9
Training loss: 0.9358584974058568
Validation loss: 2.978907705047036

Epoch: 6| Step: 10
Training loss: 0.8533892854461809
Validation loss: 2.842014887291799

Epoch: 6| Step: 11
Training loss: 1.053820048455462
Validation loss: 2.933880029653853

Epoch: 6| Step: 12
Training loss: 1.0933739151827702
Validation loss: 2.942649467127041

Epoch: 6| Step: 13
Training loss: 1.09634886292589
Validation loss: 2.846920677178735

Epoch: 145| Step: 0
Training loss: 1.069256059284715
Validation loss: 2.9686282350431323

Epoch: 6| Step: 1
Training loss: 0.6243191109617645
Validation loss: 2.9650826004041853

Epoch: 6| Step: 2
Training loss: 1.7470436328708048
Validation loss: 2.9393458012011964

Epoch: 6| Step: 3
Training loss: 0.973422166388233
Validation loss: 2.996643055839437

Epoch: 6| Step: 4
Training loss: 1.1632603179093643
Validation loss: 3.104675063588448

Epoch: 6| Step: 5
Training loss: 0.5561054534838151
Validation loss: 3.017259671918418

Epoch: 6| Step: 6
Training loss: 1.1578482330203355
Validation loss: 2.976591949450705

Epoch: 6| Step: 7
Training loss: 1.1032144051002077
Validation loss: 3.031229812187796

Epoch: 6| Step: 8
Training loss: 0.8710636424519509
Validation loss: 2.880207225024451

Epoch: 6| Step: 9
Training loss: 1.2023136326002772
Validation loss: 3.0324629359274686

Epoch: 6| Step: 10
Training loss: 1.1672883364259836
Validation loss: 3.0158827017666026

Epoch: 6| Step: 11
Training loss: 1.183532310376785
Validation loss: 3.0127508932187292

Epoch: 6| Step: 12
Training loss: 1.1611065809464691
Validation loss: 2.991977853626764

Epoch: 6| Step: 13
Training loss: 0.9212491125260405
Validation loss: 2.9974484586804966

Epoch: 146| Step: 0
Training loss: 0.7153974379493879
Validation loss: 2.9696527145956613

Epoch: 6| Step: 1
Training loss: 1.2471607387561066
Validation loss: 3.0039242271411233

Epoch: 6| Step: 2
Training loss: 0.8904449548602701
Validation loss: 3.02502095028687

Epoch: 6| Step: 3
Training loss: 1.0606675895992206
Validation loss: 3.01351776025658

Epoch: 6| Step: 4
Training loss: 0.7528802086075038
Validation loss: 2.997429368897308

Epoch: 6| Step: 5
Training loss: 1.5084674578865418
Validation loss: 2.9556328084198147

Epoch: 6| Step: 6
Training loss: 0.6972869314149385
Validation loss: 3.0081256521786868

Epoch: 6| Step: 7
Training loss: 0.6860572675623753
Validation loss: 2.9901176577694883

Epoch: 6| Step: 8
Training loss: 1.154300231412342
Validation loss: 2.955814704273485

Epoch: 6| Step: 9
Training loss: 0.874837451550362
Validation loss: 2.9861363377848558

Epoch: 6| Step: 10
Training loss: 1.4949363434676768
Validation loss: 3.032852522677507

Epoch: 6| Step: 11
Training loss: 1.6946281774718581
Validation loss: 3.033056513937196

Epoch: 6| Step: 12
Training loss: 1.0317006138119318
Validation loss: 3.0034846095501617

Epoch: 6| Step: 13
Training loss: 0.7751343733674941
Validation loss: 3.0851213365802534

Epoch: 147| Step: 0
Training loss: 1.1944275615790265
Validation loss: 3.011079369874659

Epoch: 6| Step: 1
Training loss: 0.670764337766765
Validation loss: 2.962767962048002

Epoch: 6| Step: 2
Training loss: 0.5890072075673214
Validation loss: 2.982817864417369

Epoch: 6| Step: 3
Training loss: 0.7500379870649254
Validation loss: 2.993773860743397

Epoch: 6| Step: 4
Training loss: 0.952842733141864
Validation loss: 2.9768937695007827

Epoch: 6| Step: 5
Training loss: 1.8329250213347077
Validation loss: 2.9379806666386212

Epoch: 6| Step: 6
Training loss: 1.0439634116363994
Validation loss: 2.985487752113823

Epoch: 6| Step: 7
Training loss: 1.1299720669560067
Validation loss: 2.8882403736009663

Epoch: 6| Step: 8
Training loss: 0.61242348523907
Validation loss: 2.9484641888786394

Epoch: 6| Step: 9
Training loss: 1.132852645688828
Validation loss: 3.070307154889425

Epoch: 6| Step: 10
Training loss: 1.1147726141857366
Validation loss: 3.107688574272411

Epoch: 6| Step: 11
Training loss: 1.2188678586654984
Validation loss: 3.0906368994668574

Epoch: 6| Step: 12
Training loss: 1.2152317322984616
Validation loss: 3.035198772693869

Epoch: 6| Step: 13
Training loss: 1.247259186949991
Validation loss: 2.9684581278492423

Epoch: 148| Step: 0
Training loss: 1.1525325814397667
Validation loss: 2.8476619851220755

Epoch: 6| Step: 1
Training loss: 1.1149371764954912
Validation loss: 2.9190751258841945

Epoch: 6| Step: 2
Training loss: 1.4815256176219722
Validation loss: 2.9466392908255874

Epoch: 6| Step: 3
Training loss: 0.8793691475788029
Validation loss: 2.923748510479123

Epoch: 6| Step: 4
Training loss: 0.6898283977247495
Validation loss: 2.902473046360823

Epoch: 6| Step: 5
Training loss: 0.7112412275500748
Validation loss: 2.9286946695538867

Epoch: 6| Step: 6
Training loss: 1.2007438579388736
Validation loss: 3.0352578950060862

Epoch: 6| Step: 7
Training loss: 1.9383083626059021
Validation loss: 3.1265559201327786

Epoch: 6| Step: 8
Training loss: 0.7341114139296764
Validation loss: 2.957161595215192

Epoch: 6| Step: 9
Training loss: 0.7953940449037797
Validation loss: 2.9934488133058297

Epoch: 6| Step: 10
Training loss: 1.141226936266054
Validation loss: 2.8728284512909705

Epoch: 6| Step: 11
Training loss: 0.9498137191038698
Validation loss: 2.946215652159865

Epoch: 6| Step: 12
Training loss: 1.0651503772861888
Validation loss: 2.9397794928866476

Epoch: 6| Step: 13
Training loss: 1.2230455552675479
Validation loss: 2.900827209289393

Epoch: 149| Step: 0
Training loss: 0.9331269952914961
Validation loss: 2.8864798165197243

Epoch: 6| Step: 1
Training loss: 0.7375567479041438
Validation loss: 2.9989083741189355

Epoch: 6| Step: 2
Training loss: 0.7496946428474667
Validation loss: 2.9073538375944366

Epoch: 6| Step: 3
Training loss: 0.9836500616823324
Validation loss: 3.04077965505455

Epoch: 6| Step: 4
Training loss: 1.9330669263373212
Validation loss: 3.0720031846066367

Epoch: 6| Step: 5
Training loss: 1.3522099173626903
Validation loss: 3.010612842191307

Epoch: 6| Step: 6
Training loss: 0.8062450556640424
Validation loss: 2.99094131189423

Epoch: 6| Step: 7
Training loss: 1.165391150940686
Validation loss: 2.921649631777723

Epoch: 6| Step: 8
Training loss: 0.8164300139404549
Validation loss: 2.9313227722417863

Epoch: 6| Step: 9
Training loss: 0.9156178991673851
Validation loss: 2.9205178085391124

Epoch: 6| Step: 10
Training loss: 0.8877594675984247
Validation loss: 2.9322487990033506

Epoch: 6| Step: 11
Training loss: 0.9479511101022906
Validation loss: 2.938018239076566

Epoch: 6| Step: 12
Training loss: 0.6362980581993439
Validation loss: 2.994940066876282

Epoch: 6| Step: 13
Training loss: 1.4469479766963376
Validation loss: 3.0198855568504577

Epoch: 150| Step: 0
Training loss: 0.9424941239312952
Validation loss: 3.04599541903857

Epoch: 6| Step: 1
Training loss: 0.806677718152513
Validation loss: 3.087921702200214

Epoch: 6| Step: 2
Training loss: 0.8310129444293898
Validation loss: 2.9892059823492114

Epoch: 6| Step: 3
Training loss: 2.0085595073474085
Validation loss: 2.9786683223751638

Epoch: 6| Step: 4
Training loss: 0.8638003070496006
Validation loss: 2.920743216477133

Epoch: 6| Step: 5
Training loss: 0.7594751033029844
Validation loss: 3.036095695150113

Epoch: 6| Step: 6
Training loss: 0.8711169457875447
Validation loss: 2.9820819853418543

Epoch: 6| Step: 7
Training loss: 0.9159779490061377
Validation loss: 3.0534146804329065

Epoch: 6| Step: 8
Training loss: 0.9238876420380491
Validation loss: 3.1021531292962865

Epoch: 6| Step: 9
Training loss: 0.5646701910155892
Validation loss: 3.054310052549495

Epoch: 6| Step: 10
Training loss: 1.302234284869827
Validation loss: 3.047597581001587

Epoch: 6| Step: 11
Training loss: 0.8304193849865231
Validation loss: 3.159184429434392

Epoch: 6| Step: 12
Training loss: 0.855796785908347
Validation loss: 3.0680927668277236

Epoch: 6| Step: 13
Training loss: 1.0593674988607669
Validation loss: 2.98654432826022

Epoch: 151| Step: 0
Training loss: 1.0011874539654926
Validation loss: 3.0469519841828507

Epoch: 6| Step: 1
Training loss: 0.8608879988990479
Validation loss: 2.9608545484640816

Epoch: 6| Step: 2
Training loss: 1.036886245087114
Validation loss: 3.0336527395984643

Epoch: 6| Step: 3
Training loss: 1.577627197916954
Validation loss: 2.9169966420208917

Epoch: 6| Step: 4
Training loss: 1.5221621138747106
Validation loss: 3.0169381822105583

Epoch: 6| Step: 5
Training loss: 0.7717308712965273
Validation loss: 2.988314626336961

Epoch: 6| Step: 6
Training loss: 0.7467179408590878
Validation loss: 3.012373019084049

Epoch: 6| Step: 7
Training loss: 1.0579645180043615
Validation loss: 3.0449462915746173

Epoch: 6| Step: 8
Training loss: 1.0873488441739347
Validation loss: 3.039011061624519

Epoch: 6| Step: 9
Training loss: 0.9311558003754011
Validation loss: 3.096120985451824

Epoch: 6| Step: 10
Training loss: 0.8060445361079331
Validation loss: 3.0588375431238912

Epoch: 6| Step: 11
Training loss: 0.958714215979795
Validation loss: 3.0086370881884466

Epoch: 6| Step: 12
Training loss: 1.0032434316344543
Validation loss: 2.9867916874249603

Epoch: 6| Step: 13
Training loss: 0.936499475007488
Validation loss: 3.0721217317991276

Epoch: 152| Step: 0
Training loss: 1.0798013894812823
Validation loss: 3.0246724605570674

Epoch: 6| Step: 1
Training loss: 0.7375883049550788
Validation loss: 2.9071176867546353

Epoch: 6| Step: 2
Training loss: 1.1087546964973833
Validation loss: 2.9654626815961334

Epoch: 6| Step: 3
Training loss: 1.7366243502366419
Validation loss: 3.013441965823181

Epoch: 6| Step: 4
Training loss: 1.1438195421099955
Validation loss: 3.0264000256408226

Epoch: 6| Step: 5
Training loss: 0.9564734877178847
Validation loss: 2.960606015454354

Epoch: 6| Step: 6
Training loss: 0.6020957020431794
Validation loss: 2.997598852755216

Epoch: 6| Step: 7
Training loss: 0.9212560030302946
Validation loss: 2.9946740345726965

Epoch: 6| Step: 8
Training loss: 1.3128426876470158
Validation loss: 2.995555194328197

Epoch: 6| Step: 9
Training loss: 0.9040355922836396
Validation loss: 2.9979171807715264

Epoch: 6| Step: 10
Training loss: 0.5971295398190614
Validation loss: 3.098134822043658

Epoch: 6| Step: 11
Training loss: 0.8602887930688499
Validation loss: 2.9696695743985733

Epoch: 6| Step: 12
Training loss: 0.6568980876955748
Validation loss: 2.9273904704891027

Epoch: 6| Step: 13
Training loss: 0.5988280085434773
Validation loss: 2.9980789100020635

Epoch: 153| Step: 0
Training loss: 0.9633056489030977
Validation loss: 3.0222104364715414

Epoch: 6| Step: 1
Training loss: 0.8797509436487122
Validation loss: 3.0971482619239428

Epoch: 6| Step: 2
Training loss: 1.2180550868256868
Validation loss: 3.0053649456044953

Epoch: 6| Step: 3
Training loss: 0.7077488076898307
Validation loss: 3.1050827970128485

Epoch: 6| Step: 4
Training loss: 0.5882683234548683
Validation loss: 3.060413726916025

Epoch: 6| Step: 5
Training loss: 0.74265427216552
Validation loss: 3.029609629597758

Epoch: 6| Step: 6
Training loss: 0.9800582573565743
Validation loss: 3.059160085110056

Epoch: 6| Step: 7
Training loss: 0.6417251537552418
Validation loss: 3.0214571780012505

Epoch: 6| Step: 8
Training loss: 1.7849570399011296
Validation loss: 2.9794554314794173

Epoch: 6| Step: 9
Training loss: 0.8259598119394345
Validation loss: 2.931340245617937

Epoch: 6| Step: 10
Training loss: 0.8469532103512519
Validation loss: 2.950270401690293

Epoch: 6| Step: 11
Training loss: 1.2508848872902816
Validation loss: 2.9751568776930326

Epoch: 6| Step: 12
Training loss: 1.0532645339669295
Validation loss: 2.999710320686184

Epoch: 6| Step: 13
Training loss: 1.0720227909796893
Validation loss: 3.0558313958091063

Epoch: 154| Step: 0
Training loss: 0.7464413856571943
Validation loss: 3.091834364676011

Epoch: 6| Step: 1
Training loss: 1.1452841511922034
Validation loss: 3.068358934686938

Epoch: 6| Step: 2
Training loss: 1.0271432775268816
Validation loss: 2.9887611951183577

Epoch: 6| Step: 3
Training loss: 0.8133662814231006
Validation loss: 3.0754229696640163

Epoch: 6| Step: 4
Training loss: 0.7138887707412892
Validation loss: 3.0784825409433436

Epoch: 6| Step: 5
Training loss: 1.7474105614516662
Validation loss: 2.911295541068874

Epoch: 6| Step: 6
Training loss: 0.8925882752089719
Validation loss: 2.9958248224964317

Epoch: 6| Step: 7
Training loss: 0.7777449372904504
Validation loss: 3.005592140974787

Epoch: 6| Step: 8
Training loss: 1.2281708104565883
Validation loss: 2.937459539581207

Epoch: 6| Step: 9
Training loss: 0.8538781973793322
Validation loss: 3.102051729169801

Epoch: 6| Step: 10
Training loss: 0.9328911344013912
Validation loss: 3.034460104925152

Epoch: 6| Step: 11
Training loss: 0.9923028653575643
Validation loss: 2.9650861383869787

Epoch: 6| Step: 12
Training loss: 1.00283447526847
Validation loss: 3.0734825949373876

Epoch: 6| Step: 13
Training loss: 1.007552534773584
Validation loss: 3.0788339227742494

Epoch: 155| Step: 0
Training loss: 0.967666727875057
Validation loss: 3.0159200151784025

Epoch: 6| Step: 1
Training loss: 1.073522446115659
Validation loss: 2.9473947572995463

Epoch: 6| Step: 2
Training loss: 0.8413548205002658
Validation loss: 3.0744773565320744

Epoch: 6| Step: 3
Training loss: 0.853594219857732
Validation loss: 3.0595655330649447

Epoch: 6| Step: 4
Training loss: 0.9744930159649787
Validation loss: 3.0801292516786547

Epoch: 6| Step: 5
Training loss: 0.6460023217971461
Validation loss: 2.952092469568502

Epoch: 6| Step: 6
Training loss: 1.1617471595271376
Validation loss: 3.013598484242538

Epoch: 6| Step: 7
Training loss: 0.7899196991972093
Validation loss: 3.066810247612135

Epoch: 6| Step: 8
Training loss: 1.7060453243249791
Validation loss: 3.153231609597631

Epoch: 6| Step: 9
Training loss: 0.953712126203613
Validation loss: 3.183627612474083

Epoch: 6| Step: 10
Training loss: 0.8280516537988121
Validation loss: 3.051542531469184

Epoch: 6| Step: 11
Training loss: 1.2651715820408647
Validation loss: 3.06263880512428

Epoch: 6| Step: 12
Training loss: 0.5990595082510287
Validation loss: 2.9823052517369106

Epoch: 6| Step: 13
Training loss: 1.0176588381572267
Validation loss: 2.9715465959206324

Epoch: 156| Step: 0
Training loss: 0.7683543388849399
Validation loss: 2.9486127420250106

Epoch: 6| Step: 1
Training loss: 0.9344983367149936
Validation loss: 2.9366088218779716

Epoch: 6| Step: 2
Training loss: 0.604394858664225
Validation loss: 2.977497664802206

Epoch: 6| Step: 3
Training loss: 0.9544114982855626
Validation loss: 2.9936627634779995

Epoch: 6| Step: 4
Training loss: 0.7469421276746843
Validation loss: 3.002655417056492

Epoch: 6| Step: 5
Training loss: 1.0739462767009662
Validation loss: 2.967551822804391

Epoch: 6| Step: 6
Training loss: 0.8157879619106734
Validation loss: 2.9281921232462667

Epoch: 6| Step: 7
Training loss: 0.7796730911666475
Validation loss: 2.9974330410386574

Epoch: 6| Step: 8
Training loss: 0.9874239735370136
Validation loss: 2.968312870435598

Epoch: 6| Step: 9
Training loss: 0.6809881196939314
Validation loss: 2.973618554225703

Epoch: 6| Step: 10
Training loss: 0.5590950910217295
Validation loss: 2.899692863335788

Epoch: 6| Step: 11
Training loss: 0.7470373607673603
Validation loss: 3.00025793132354

Epoch: 6| Step: 12
Training loss: 1.8916106374007924
Validation loss: 2.96016847526232

Epoch: 6| Step: 13
Training loss: 0.9401652597176661
Validation loss: 3.0470346783913

Epoch: 157| Step: 0
Training loss: 0.9873150410849774
Validation loss: 3.1209775085828473

Epoch: 6| Step: 1
Training loss: 0.5585556550807563
Validation loss: 2.997347586359751

Epoch: 6| Step: 2
Training loss: 0.8319033672216469
Validation loss: 2.990753733363196

Epoch: 6| Step: 3
Training loss: 0.7180358822126067
Validation loss: 3.0434849586472352

Epoch: 6| Step: 4
Training loss: 0.6803682579352659
Validation loss: 2.998135371356918

Epoch: 6| Step: 5
Training loss: 0.8255976130804038
Validation loss: 3.004470567150779

Epoch: 6| Step: 6
Training loss: 1.0962356660399473
Validation loss: 3.0491399448749825

Epoch: 6| Step: 7
Training loss: 0.8262849554496237
Validation loss: 2.9882774070432463

Epoch: 6| Step: 8
Training loss: 1.3450445991694413
Validation loss: 3.0274181594728047

Epoch: 6| Step: 9
Training loss: 0.7783837573758142
Validation loss: 2.9903737041322445

Epoch: 6| Step: 10
Training loss: 0.8315584155544706
Validation loss: 3.063392094023298

Epoch: 6| Step: 11
Training loss: 1.566337450756878
Validation loss: 2.997877045334902

Epoch: 6| Step: 12
Training loss: 0.6508096713927167
Validation loss: 3.0408318737051268

Epoch: 6| Step: 13
Training loss: 0.7052320909278252
Validation loss: 3.1354198561406097

Epoch: 158| Step: 0
Training loss: 0.6329752865738428
Validation loss: 3.0472272359582098

Epoch: 6| Step: 1
Training loss: 0.93890167991934
Validation loss: 3.0337476108595585

Epoch: 6| Step: 2
Training loss: 0.9278276256074851
Validation loss: 3.075640661805298

Epoch: 6| Step: 3
Training loss: 0.6691385031965457
Validation loss: 2.973186103161368

Epoch: 6| Step: 4
Training loss: 0.5351973469122457
Validation loss: 3.035205514999786

Epoch: 6| Step: 5
Training loss: 0.7704801179770157
Validation loss: 2.9635282135151355

Epoch: 6| Step: 6
Training loss: 0.7812368010359648
Validation loss: 2.967179923895762

Epoch: 6| Step: 7
Training loss: 0.8633863290209423
Validation loss: 3.078389190335041

Epoch: 6| Step: 8
Training loss: 1.0126046679990985
Validation loss: 3.015042856585579

Epoch: 6| Step: 9
Training loss: 0.7318508923450536
Validation loss: 3.0033350526703866

Epoch: 6| Step: 10
Training loss: 1.0017182370417936
Validation loss: 2.9362981380210122

Epoch: 6| Step: 11
Training loss: 0.7649430332290721
Validation loss: 2.943087755346841

Epoch: 6| Step: 12
Training loss: 1.352440697573872
Validation loss: 3.0002202774345883

Epoch: 6| Step: 13
Training loss: 1.7205659463089884
Validation loss: 2.9118312171536926

Epoch: 159| Step: 0
Training loss: 0.596370260918233
Validation loss: 2.9191392681183843

Epoch: 6| Step: 1
Training loss: 0.7455362763741286
Validation loss: 3.006609787695488

Epoch: 6| Step: 2
Training loss: 0.8586710734515909
Validation loss: 3.025747200606614

Epoch: 6| Step: 3
Training loss: 0.8167782898607815
Validation loss: 3.102649591094295

Epoch: 6| Step: 4
Training loss: 0.9537279379456557
Validation loss: 3.0674626889455925

Epoch: 6| Step: 5
Training loss: 0.8160116163623714
Validation loss: 3.0927155303271743

Epoch: 6| Step: 6
Training loss: 0.5731050759516203
Validation loss: 2.99836621566675

Epoch: 6| Step: 7
Training loss: 1.853349105381349
Validation loss: 2.970500523641048

Epoch: 6| Step: 8
Training loss: 1.2238574480183828
Validation loss: 2.972322850489686

Epoch: 6| Step: 9
Training loss: 0.67725302452716
Validation loss: 2.9728457657384273

Epoch: 6| Step: 10
Training loss: 0.6358934448128675
Validation loss: 3.0443699377074367

Epoch: 6| Step: 11
Training loss: 0.9334077530096914
Validation loss: 3.072739280279131

Epoch: 6| Step: 12
Training loss: 0.9691825331791099
Validation loss: 3.0431841021993304

Epoch: 6| Step: 13
Training loss: 0.9710799470198261
Validation loss: 3.066364497003758

Epoch: 160| Step: 0
Training loss: 0.7913852911053921
Validation loss: 2.9861741027299433

Epoch: 6| Step: 1
Training loss: 0.8268818070873238
Validation loss: 2.9759278910012195

Epoch: 6| Step: 2
Training loss: 0.759332528516071
Validation loss: 2.9378984262256087

Epoch: 6| Step: 3
Training loss: 0.9867390598070471
Validation loss: 3.0263416887858385

Epoch: 6| Step: 4
Training loss: 1.7896862691718842
Validation loss: 2.982756836739647

Epoch: 6| Step: 5
Training loss: 0.7251191929145894
Validation loss: 3.0774186513165196

Epoch: 6| Step: 6
Training loss: 0.9735083466981695
Validation loss: 3.137792293515308

Epoch: 6| Step: 7
Training loss: 0.809312215601292
Validation loss: 3.1367996097718818

Epoch: 6| Step: 8
Training loss: 0.7017162197069966
Validation loss: 3.0914237784697813

Epoch: 6| Step: 9
Training loss: 1.0122532555661334
Validation loss: 3.09253783192336

Epoch: 6| Step: 10
Training loss: 1.3273856405077231
Validation loss: 3.0079691396112627

Epoch: 6| Step: 11
Training loss: 0.8345930393230395
Validation loss: 3.0442502706641985

Epoch: 6| Step: 12
Training loss: 0.9072747520566479
Validation loss: 3.0135022006641026

Epoch: 6| Step: 13
Training loss: 0.8572039142501473
Validation loss: 3.0865702950062244

Epoch: 161| Step: 0
Training loss: 1.5352075776893652
Validation loss: 2.987785800260882

Epoch: 6| Step: 1
Training loss: 0.6405772447231778
Validation loss: 3.12836314745194

Epoch: 6| Step: 2
Training loss: 0.8191239966076824
Validation loss: 3.009381196466908

Epoch: 6| Step: 3
Training loss: 0.6919516012901369
Validation loss: 3.0298551909462006

Epoch: 6| Step: 4
Training loss: 0.8241310615357136
Validation loss: 3.018370095430562

Epoch: 6| Step: 5
Training loss: 0.5457441354140291
Validation loss: 2.9927144595033797

Epoch: 6| Step: 6
Training loss: 1.0110905291194014
Validation loss: 3.041019989317611

Epoch: 6| Step: 7
Training loss: 0.8082100884057839
Validation loss: 3.001606590507161

Epoch: 6| Step: 8
Training loss: 0.831821540587912
Validation loss: 3.0009719942941353

Epoch: 6| Step: 9
Training loss: 0.8064868771241601
Validation loss: 3.022232275444339

Epoch: 6| Step: 10
Training loss: 0.9445782481728203
Validation loss: 2.9963845878996067

Epoch: 6| Step: 11
Training loss: 0.7947146733806334
Validation loss: 3.054877051726928

Epoch: 6| Step: 12
Training loss: 1.0352501592684349
Validation loss: 3.023054284280853

Epoch: 6| Step: 13
Training loss: 1.3531391010915215
Validation loss: 3.0851273901845264

Epoch: 162| Step: 0
Training loss: 1.027973518691024
Validation loss: 3.003552174958707

Epoch: 6| Step: 1
Training loss: 0.46115136438428694
Validation loss: 3.015921161451753

Epoch: 6| Step: 2
Training loss: 1.58767071804726
Validation loss: 3.0334467580220483

Epoch: 6| Step: 3
Training loss: 1.4058090366298308
Validation loss: 3.0151366001391677

Epoch: 6| Step: 4
Training loss: 0.7751862763531515
Validation loss: 3.022584438317217

Epoch: 6| Step: 5
Training loss: 0.5034679310349035
Validation loss: 2.943190710090692

Epoch: 6| Step: 6
Training loss: 0.6371301831204299
Validation loss: 3.059187648337194

Epoch: 6| Step: 7
Training loss: 0.9082550362138381
Validation loss: 2.9887348570440713

Epoch: 6| Step: 8
Training loss: 0.62102148247386
Validation loss: 3.0516619125556965

Epoch: 6| Step: 9
Training loss: 0.4940403169288202
Validation loss: 3.0354811642998167

Epoch: 6| Step: 10
Training loss: 0.9830761469436357
Validation loss: 3.074596777636392

Epoch: 6| Step: 11
Training loss: 0.8757928934267615
Validation loss: 3.066260397129235

Epoch: 6| Step: 12
Training loss: 0.7817210875222124
Validation loss: 3.0378012896274917

Epoch: 6| Step: 13
Training loss: 0.5935401796737616
Validation loss: 3.1518673700314292

Epoch: 163| Step: 0
Training loss: 0.7341283018615038
Validation loss: 3.035970780678903

Epoch: 6| Step: 1
Training loss: 0.8536322402725254
Validation loss: 3.113014200165317

Epoch: 6| Step: 2
Training loss: 0.5484671440698711
Validation loss: 2.925183522479843

Epoch: 6| Step: 3
Training loss: 0.6881881217867123
Validation loss: 3.004919244270366

Epoch: 6| Step: 4
Training loss: 0.6131266502334831
Validation loss: 2.971005529912345

Epoch: 6| Step: 5
Training loss: 0.9862178929738981
Validation loss: 2.9168475821561732

Epoch: 6| Step: 6
Training loss: 0.8967567312702092
Validation loss: 3.0158029217191125

Epoch: 6| Step: 7
Training loss: 1.1426799500567597
Validation loss: 3.050241016287271

Epoch: 6| Step: 8
Training loss: 0.6214464253959879
Validation loss: 3.1187361946896144

Epoch: 6| Step: 9
Training loss: 1.6423510236835812
Validation loss: 3.14671832808689

Epoch: 6| Step: 10
Training loss: 0.8782083410714416
Validation loss: 3.2212424889801254

Epoch: 6| Step: 11
Training loss: 0.9113739446901524
Validation loss: 3.31399235007432

Epoch: 6| Step: 12
Training loss: 1.0000119804618341
Validation loss: 3.195183363514701

Epoch: 6| Step: 13
Training loss: 0.7917599413951972
Validation loss: 3.146615061777934

Epoch: 164| Step: 0
Training loss: 0.903737762494948
Validation loss: 2.960474748106566

Epoch: 6| Step: 1
Training loss: 0.5631007059934591
Validation loss: 2.984385771673712

Epoch: 6| Step: 2
Training loss: 0.8539774886811501
Validation loss: 2.967524519842883

Epoch: 6| Step: 3
Training loss: 1.6479633969297496
Validation loss: 3.0135994204276657

Epoch: 6| Step: 4
Training loss: 1.2950166463334365
Validation loss: 3.013583426126303

Epoch: 6| Step: 5
Training loss: 0.7361488022741466
Validation loss: 3.0410800699156515

Epoch: 6| Step: 6
Training loss: 0.7915661061984512
Validation loss: 3.0852309564976883

Epoch: 6| Step: 7
Training loss: 1.0674526125465003
Validation loss: 3.2016431032220853

Epoch: 6| Step: 8
Training loss: 0.7364536653952568
Validation loss: 3.1873564344998644

Epoch: 6| Step: 9
Training loss: 0.6765384290963514
Validation loss: 3.1909548791620006

Epoch: 6| Step: 10
Training loss: 0.8191655451267931
Validation loss: 3.1865460208642418

Epoch: 6| Step: 11
Training loss: 0.5699983018715978
Validation loss: 3.125541830773688

Epoch: 6| Step: 12
Training loss: 0.809002169602624
Validation loss: 3.0662325216594253

Epoch: 6| Step: 13
Training loss: 0.6072278709557032
Validation loss: 3.0983613964640986

Epoch: 165| Step: 0
Training loss: 0.5560747717126769
Validation loss: 3.0032222847161023

Epoch: 6| Step: 1
Training loss: 0.9375846824547005
Validation loss: 2.9983149538082934

Epoch: 6| Step: 2
Training loss: 1.0976426744809418
Validation loss: 2.9673553537168647

Epoch: 6| Step: 3
Training loss: 1.5907262653724634
Validation loss: 2.972053349729323

Epoch: 6| Step: 4
Training loss: 0.5064459974679313
Validation loss: 3.0768930903679172

Epoch: 6| Step: 5
Training loss: 0.5844668943396804
Validation loss: 3.089569748385387

Epoch: 6| Step: 6
Training loss: 0.7997215889227473
Validation loss: 3.13746894425908

Epoch: 6| Step: 7
Training loss: 0.7258372224673618
Validation loss: 3.0007609488427787

Epoch: 6| Step: 8
Training loss: 0.7442357360451943
Validation loss: 2.9868206502042285

Epoch: 6| Step: 9
Training loss: 0.49376935920910003
Validation loss: 2.9557729888669897

Epoch: 6| Step: 10
Training loss: 0.8869542552759688
Validation loss: 2.9641092267573734

Epoch: 6| Step: 11
Training loss: 0.8626172373054378
Validation loss: 2.969845378973829

Epoch: 6| Step: 12
Training loss: 1.1425982612074475
Validation loss: 2.9730856573188067

Epoch: 6| Step: 13
Training loss: 0.9693063860971058
Validation loss: 2.976031331939075

Epoch: 166| Step: 0
Training loss: 0.7021253473254855
Validation loss: 2.987012832482921

Epoch: 6| Step: 1
Training loss: 0.6346708725855346
Validation loss: 3.1198007055967873

Epoch: 6| Step: 2
Training loss: 0.792551692034926
Validation loss: 3.042522732355374

Epoch: 6| Step: 3
Training loss: 0.5732821137075294
Validation loss: 3.0601370382269937

Epoch: 6| Step: 4
Training loss: 0.8765824857939125
Validation loss: 3.0772926509036846

Epoch: 6| Step: 5
Training loss: 1.1060535515104588
Validation loss: 3.0347465588844766

Epoch: 6| Step: 6
Training loss: 0.7004765540289648
Validation loss: 2.9740055211872565

Epoch: 6| Step: 7
Training loss: 0.6692226531106196
Validation loss: 2.925295665121876

Epoch: 6| Step: 8
Training loss: 0.522817899741079
Validation loss: 2.945217046700271

Epoch: 6| Step: 9
Training loss: 0.5173071385790529
Validation loss: 3.0050094556315896

Epoch: 6| Step: 10
Training loss: 0.6527981574572478
Validation loss: 2.96916522418328

Epoch: 6| Step: 11
Training loss: 1.8948425037288397
Validation loss: 2.9831578700361114

Epoch: 6| Step: 12
Training loss: 0.8116123779622033
Validation loss: 3.0010166432428576

Epoch: 6| Step: 13
Training loss: 1.1927800996780795
Validation loss: 3.1649521946523316

Epoch: 167| Step: 0
Training loss: 0.6013806055696173
Validation loss: 3.099564620690247

Epoch: 6| Step: 1
Training loss: 0.8978177462357158
Validation loss: 3.033519576891099

Epoch: 6| Step: 2
Training loss: 0.7018224094556534
Validation loss: 2.9572207592969653

Epoch: 6| Step: 3
Training loss: 0.8733860526176517
Validation loss: 3.048523585676206

Epoch: 6| Step: 4
Training loss: 0.6956145027170614
Validation loss: 2.9976368444585293

Epoch: 6| Step: 5
Training loss: 1.0083630854313077
Validation loss: 3.0976533765486884

Epoch: 6| Step: 6
Training loss: 0.5226523075610809
Validation loss: 3.040369937518985

Epoch: 6| Step: 7
Training loss: 0.8924985219905808
Validation loss: 3.1230888880769943

Epoch: 6| Step: 8
Training loss: 0.7764968475896804
Validation loss: 3.1191118589765563

Epoch: 6| Step: 9
Training loss: 0.5522896153361433
Validation loss: 3.1226802481107017

Epoch: 6| Step: 10
Training loss: 0.5935568244295607
Validation loss: 3.0273871437162168

Epoch: 6| Step: 11
Training loss: 1.5003031583247675
Validation loss: 3.0846945404187776

Epoch: 6| Step: 12
Training loss: 0.7624468331483781
Validation loss: 3.0071064306084536

Epoch: 6| Step: 13
Training loss: 1.1424088833658521
Validation loss: 3.05285911118105

Epoch: 168| Step: 0
Training loss: 0.5862173810721529
Validation loss: 3.000290704258695

Epoch: 6| Step: 1
Training loss: 0.6865806067418345
Validation loss: 3.0892594753991753

Epoch: 6| Step: 2
Training loss: 0.8572883588897806
Validation loss: 3.1130575995560843

Epoch: 6| Step: 3
Training loss: 0.8918798206736384
Validation loss: 3.187803316332774

Epoch: 6| Step: 4
Training loss: 0.6825105422816166
Validation loss: 3.1116915177502404

Epoch: 6| Step: 5
Training loss: 0.8624780292753352
Validation loss: 3.060063891834611

Epoch: 6| Step: 6
Training loss: 0.849414847016822
Validation loss: 2.945825668677503

Epoch: 6| Step: 7
Training loss: 0.5609304464847755
Validation loss: 2.9681620366960044

Epoch: 6| Step: 8
Training loss: 2.025924509251887
Validation loss: 2.966587389911858

Epoch: 6| Step: 9
Training loss: 0.980174472614512
Validation loss: 2.9557897799602504

Epoch: 6| Step: 10
Training loss: 0.772165813566061
Validation loss: 2.99626544458777

Epoch: 6| Step: 11
Training loss: 1.0675585323787293
Validation loss: 3.0839379637086575

Epoch: 6| Step: 12
Training loss: 0.7757721161856881
Validation loss: 3.191571994370078

Epoch: 6| Step: 13
Training loss: 0.7620465478071403
Validation loss: 3.1111543251245526

Epoch: 169| Step: 0
Training loss: 0.5502580904125383
Validation loss: 3.1481341522711843

Epoch: 6| Step: 1
Training loss: 0.7069362555489435
Validation loss: 3.0997886037017692

Epoch: 6| Step: 2
Training loss: 0.7045995297893002
Validation loss: 3.0497711762854967

Epoch: 6| Step: 3
Training loss: 0.7129465577640446
Validation loss: 2.9922794762826777

Epoch: 6| Step: 4
Training loss: 0.8531012675020038
Validation loss: 3.0802706293629405

Epoch: 6| Step: 5
Training loss: 0.787451884903972
Validation loss: 2.960696194628695

Epoch: 6| Step: 6
Training loss: 1.03845087851517
Validation loss: 3.0492911776294886

Epoch: 6| Step: 7
Training loss: 0.6547678149357049
Validation loss: 3.1250067901537557

Epoch: 6| Step: 8
Training loss: 0.7824794251049579
Validation loss: 3.140989760034729

Epoch: 6| Step: 9
Training loss: 1.2700049822251522
Validation loss: 3.102542866388426

Epoch: 6| Step: 10
Training loss: 1.6395165468191228
Validation loss: 3.1259504144542847

Epoch: 6| Step: 11
Training loss: 0.7438132699934078
Validation loss: 3.1182782042452275

Epoch: 6| Step: 12
Training loss: 0.8698010282336289
Validation loss: 2.9687561704337257

Epoch: 6| Step: 13
Training loss: 0.9932044217021624
Validation loss: 3.0254123096743784

Epoch: 170| Step: 0
Training loss: 0.8643962856934909
Validation loss: 2.9856857430551114

Epoch: 6| Step: 1
Training loss: 0.69432821148787
Validation loss: 2.9978256955812896

Epoch: 6| Step: 2
Training loss: 0.6550529779965606
Validation loss: 2.957613136490091

Epoch: 6| Step: 3
Training loss: 0.6416128497241321
Validation loss: 3.0584576455888417

Epoch: 6| Step: 4
Training loss: 1.5232165054052123
Validation loss: 3.055365913940998

Epoch: 6| Step: 5
Training loss: 0.6610823235891364
Validation loss: 3.089555266328492

Epoch: 6| Step: 6
Training loss: 1.135940967328894
Validation loss: 3.082851853452199

Epoch: 6| Step: 7
Training loss: 0.5062570076916606
Validation loss: 3.0817143769299196

Epoch: 6| Step: 8
Training loss: 0.6269536954217615
Validation loss: 3.039118670652978

Epoch: 6| Step: 9
Training loss: 0.6422052896082203
Validation loss: 3.1329500543927766

Epoch: 6| Step: 10
Training loss: 0.6426468554440088
Validation loss: 3.0210594004962066

Epoch: 6| Step: 11
Training loss: 0.7196133859746463
Validation loss: 3.0445305827949856

Epoch: 6| Step: 12
Training loss: 1.009573174736584
Validation loss: 2.9884903844983226

Epoch: 6| Step: 13
Training loss: 0.6958256660160825
Validation loss: 3.069888188337922

Epoch: 171| Step: 0
Training loss: 0.8556065208941837
Validation loss: 3.0490902664386685

Epoch: 6| Step: 1
Training loss: 0.5893098296767351
Validation loss: 2.9834845847320857

Epoch: 6| Step: 2
Training loss: 0.6173034752153923
Validation loss: 3.075717184381252

Epoch: 6| Step: 3
Training loss: 0.9110914672760162
Validation loss: 3.06904766247364

Epoch: 6| Step: 4
Training loss: 0.9987685847075112
Validation loss: 3.1016789053365095

Epoch: 6| Step: 5
Training loss: 0.6370713831311133
Validation loss: 3.0567618739055904

Epoch: 6| Step: 6
Training loss: 1.1115138430022948
Validation loss: 3.109130926472933

Epoch: 6| Step: 7
Training loss: 0.5501064739336621
Validation loss: 3.1174578505631216

Epoch: 6| Step: 8
Training loss: 0.751382070919027
Validation loss: 3.114881486347576

Epoch: 6| Step: 9
Training loss: 0.7456800502206413
Validation loss: 3.156849039469849

Epoch: 6| Step: 10
Training loss: 0.6668601401048978
Validation loss: 3.126427667656824

Epoch: 6| Step: 11
Training loss: 1.4245132451511155
Validation loss: 3.0955327160580635

Epoch: 6| Step: 12
Training loss: 0.7328422865680373
Validation loss: 3.0782123688822143

Epoch: 6| Step: 13
Training loss: 0.6822853427817147
Validation loss: 3.026382694079512

Epoch: 172| Step: 0
Training loss: 0.4377143198675457
Validation loss: 3.007894869910929

Epoch: 6| Step: 1
Training loss: 0.9846725619631849
Validation loss: 2.996302922725314

Epoch: 6| Step: 2
Training loss: 0.7168820613789345
Validation loss: 3.0756461139241824

Epoch: 6| Step: 3
Training loss: 0.4031351509590476
Validation loss: 3.105350349776294

Epoch: 6| Step: 4
Training loss: 0.6699437174002756
Validation loss: 3.151496202877629

Epoch: 6| Step: 5
Training loss: 0.793338144639062
Validation loss: 3.1761771905814142

Epoch: 6| Step: 6
Training loss: 0.7846400903426907
Validation loss: 3.185839937545659

Epoch: 6| Step: 7
Training loss: 0.758991778971261
Validation loss: 3.099443712877335

Epoch: 6| Step: 8
Training loss: 1.5162570854455448
Validation loss: 3.1255117633122014

Epoch: 6| Step: 9
Training loss: 0.5916837074171938
Validation loss: 3.0997790534744385

Epoch: 6| Step: 10
Training loss: 0.740675701546637
Validation loss: 3.122534707708518

Epoch: 6| Step: 11
Training loss: 0.6681838776684094
Validation loss: 2.9936458795183496

Epoch: 6| Step: 12
Training loss: 0.6148967967240442
Validation loss: 3.0573302639675357

Epoch: 6| Step: 13
Training loss: 1.0767660006788362
Validation loss: 3.059050349309703

Epoch: 173| Step: 0
Training loss: 0.9063169520409307
Validation loss: 3.057597940539304

Epoch: 6| Step: 1
Training loss: 0.5967345267160775
Validation loss: 3.06670120019404

Epoch: 6| Step: 2
Training loss: 0.8391909168935535
Validation loss: 3.102591298317693

Epoch: 6| Step: 3
Training loss: 1.4230505307381245
Validation loss: 3.0640009102085446

Epoch: 6| Step: 4
Training loss: 0.5798667753885839
Validation loss: 3.1312156406327087

Epoch: 6| Step: 5
Training loss: 0.7824640377909365
Validation loss: 3.15659510422274

Epoch: 6| Step: 6
Training loss: 0.9693877674199072
Validation loss: 3.1337673923135076

Epoch: 6| Step: 7
Training loss: 0.7647416994555344
Validation loss: 3.182399521085819

Epoch: 6| Step: 8
Training loss: 0.583227221737854
Validation loss: 3.070900560641253

Epoch: 6| Step: 9
Training loss: 0.6285240480985899
Validation loss: 3.042874558002604

Epoch: 6| Step: 10
Training loss: 0.7547242070782196
Validation loss: 3.0593063544214814

Epoch: 6| Step: 11
Training loss: 1.1598166537084305
Validation loss: 3.0885384845342

Epoch: 6| Step: 12
Training loss: 0.4294834172497024
Validation loss: 3.0719994722529793

Epoch: 6| Step: 13
Training loss: 0.7037555622199476
Validation loss: 3.0831610120269204

Epoch: 174| Step: 0
Training loss: 0.5966673005312033
Validation loss: 3.0572888809182746

Epoch: 6| Step: 1
Training loss: 0.7301740408847706
Validation loss: 3.1970632866195685

Epoch: 6| Step: 2
Training loss: 0.9792855102707385
Validation loss: 3.228612253320403

Epoch: 6| Step: 3
Training loss: 1.446949130109878
Validation loss: 3.209152133710299

Epoch: 6| Step: 4
Training loss: 0.8779043633157573
Validation loss: 3.0782418527385094

Epoch: 6| Step: 5
Training loss: 0.58607237217275
Validation loss: 3.0248171265025867

Epoch: 6| Step: 6
Training loss: 0.7635095916575243
Validation loss: 3.0220317085920185

Epoch: 6| Step: 7
Training loss: 0.6066877338223877
Validation loss: 3.0495151134340994

Epoch: 6| Step: 8
Training loss: 0.6973316364402925
Validation loss: 3.0627236317059037

Epoch: 6| Step: 9
Training loss: 0.5663927800122456
Validation loss: 3.1213487784313023

Epoch: 6| Step: 10
Training loss: 0.6691917021364638
Validation loss: 3.114684806029798

Epoch: 6| Step: 11
Training loss: 0.7100756944683396
Validation loss: 3.1307589046216897

Epoch: 6| Step: 12
Training loss: 0.7842031358987441
Validation loss: 3.0371570513909285

Epoch: 6| Step: 13
Training loss: 1.2414221175027749
Validation loss: 3.1866005270437467

Epoch: 175| Step: 0
Training loss: 0.8569296290640123
Validation loss: 3.145231888393893

Epoch: 6| Step: 1
Training loss: 0.6449286420664666
Validation loss: 2.9551712831620303

Epoch: 6| Step: 2
Training loss: 1.732123348143074
Validation loss: 3.1283796091845346

Epoch: 6| Step: 3
Training loss: 0.5918018353446329
Validation loss: 3.0840189059907104

Epoch: 6| Step: 4
Training loss: 0.9957567430249228
Validation loss: 2.984229125873305

Epoch: 6| Step: 5
Training loss: 0.838278478384991
Validation loss: 3.0975819114176946

Epoch: 6| Step: 6
Training loss: 0.5618707528128832
Validation loss: 3.077609282019308

Epoch: 6| Step: 7
Training loss: 0.5050430191242653
Validation loss: 3.0261768216772666

Epoch: 6| Step: 8
Training loss: 0.7312369973094434
Validation loss: 3.1419646156410077

Epoch: 6| Step: 9
Training loss: 0.6217406400904765
Validation loss: 3.1138003629278934

Epoch: 6| Step: 10
Training loss: 0.6116408989136205
Validation loss: 3.1137676553061033

Epoch: 6| Step: 11
Training loss: 0.8552694567552657
Validation loss: 3.121075976674858

Epoch: 6| Step: 12
Training loss: 0.559046421832674
Validation loss: 3.048562963091507

Epoch: 6| Step: 13
Training loss: 0.6571442324352977
Validation loss: 3.0261555889350085

Epoch: 176| Step: 0
Training loss: 0.7786606794662202
Validation loss: 3.058218382841463

Epoch: 6| Step: 1
Training loss: 0.7741679970805464
Validation loss: 2.9811093503135058

Epoch: 6| Step: 2
Training loss: 1.6237881616772847
Validation loss: 3.0443938627202316

Epoch: 6| Step: 3
Training loss: 0.7383784881013439
Validation loss: 3.0974134083021485

Epoch: 6| Step: 4
Training loss: 1.2719834808650492
Validation loss: 3.0868150453215426

Epoch: 6| Step: 5
Training loss: 0.749099508747087
Validation loss: 3.180182865930904

Epoch: 6| Step: 6
Training loss: 0.7340501107201182
Validation loss: 3.1784112166884273

Epoch: 6| Step: 7
Training loss: 0.8416461853959784
Validation loss: 3.117716821586116

Epoch: 6| Step: 8
Training loss: 0.6367532685641153
Validation loss: 3.053758042405987

Epoch: 6| Step: 9
Training loss: 0.7121163539994383
Validation loss: 3.0594217439067197

Epoch: 6| Step: 10
Training loss: 0.9094080653520688
Validation loss: 3.0918793979539214

Epoch: 6| Step: 11
Training loss: 0.7532502319558411
Validation loss: 3.086717350923335

Epoch: 6| Step: 12
Training loss: 0.6555253296576721
Validation loss: 3.065184681541719

Epoch: 6| Step: 13
Training loss: 0.7443332372780086
Validation loss: 3.1090760334893752

Epoch: 177| Step: 0
Training loss: 0.831889610592127
Validation loss: 3.201248313886483

Epoch: 6| Step: 1
Training loss: 0.472210965965165
Validation loss: 3.1460960396385023

Epoch: 6| Step: 2
Training loss: 0.8927976976769169
Validation loss: 3.127802126567407

Epoch: 6| Step: 3
Training loss: 1.1139446222933413
Validation loss: 3.1640407106253656

Epoch: 6| Step: 4
Training loss: 0.8165139670243214
Validation loss: 3.055990697239902

Epoch: 6| Step: 5
Training loss: 0.5462607339899902
Validation loss: 3.0488879735344097

Epoch: 6| Step: 6
Training loss: 0.8215839160610549
Validation loss: 3.1029411217900695

Epoch: 6| Step: 7
Training loss: 0.7374366086451225
Validation loss: 3.0563717334845255

Epoch: 6| Step: 8
Training loss: 0.5761024562590643
Validation loss: 3.061864228980742

Epoch: 6| Step: 9
Training loss: 0.5544348127746995
Validation loss: 3.124596684178894

Epoch: 6| Step: 10
Training loss: 0.44525582806212255
Validation loss: 3.1027649823316454

Epoch: 6| Step: 11
Training loss: 0.46474894991464166
Validation loss: 3.0993817379424318

Epoch: 6| Step: 12
Training loss: 0.6750286961566287
Validation loss: 3.046690910842504

Epoch: 6| Step: 13
Training loss: 1.3373060745403662
Validation loss: 3.164385793990104

Epoch: 178| Step: 0
Training loss: 0.4525030405774889
Validation loss: 3.1295411620237923

Epoch: 6| Step: 1
Training loss: 0.6250437244379461
Validation loss: 3.1861082915855583

Epoch: 6| Step: 2
Training loss: 0.8863389466366071
Validation loss: 3.1346953101902715

Epoch: 6| Step: 3
Training loss: 1.0362591320413121
Validation loss: 3.0583355804005476

Epoch: 6| Step: 4
Training loss: 0.5890056390411433
Validation loss: 3.0069487813713236

Epoch: 6| Step: 5
Training loss: 0.516989722568471
Validation loss: 3.0619997147888673

Epoch: 6| Step: 6
Training loss: 1.500224176185561
Validation loss: 3.0574827031633767

Epoch: 6| Step: 7
Training loss: 0.7859152166950288
Validation loss: 3.1408857803506876

Epoch: 6| Step: 8
Training loss: 0.47449826482308843
Validation loss: 3.0459099178540194

Epoch: 6| Step: 9
Training loss: 0.6177509488291847
Validation loss: 3.085788990422923

Epoch: 6| Step: 10
Training loss: 0.8400623125851313
Validation loss: 3.185426511348051

Epoch: 6| Step: 11
Training loss: 0.5381092267266767
Validation loss: 3.16071858096607

Epoch: 6| Step: 12
Training loss: 0.4656945624649839
Validation loss: 3.1477571419656143

Epoch: 6| Step: 13
Training loss: 0.5870053542443715
Validation loss: 3.037532378705713

Epoch: 179| Step: 0
Training loss: 0.6814296800433587
Validation loss: 3.1324312480699543

Epoch: 6| Step: 1
Training loss: 0.445276727410739
Validation loss: 3.149623309929441

Epoch: 6| Step: 2
Training loss: 0.7019196032638138
Validation loss: 3.128640876784298

Epoch: 6| Step: 3
Training loss: 0.6035368091605924
Validation loss: 3.0998743236867172

Epoch: 6| Step: 4
Training loss: 0.7139261328369925
Validation loss: 3.0582038172878097

Epoch: 6| Step: 5
Training loss: 0.9438130490292791
Validation loss: 3.1281056040525517

Epoch: 6| Step: 6
Training loss: 1.3647400666514946
Validation loss: 3.1135538158177587

Epoch: 6| Step: 7
Training loss: 0.2910308449880706
Validation loss: 3.103622265042508

Epoch: 6| Step: 8
Training loss: 0.6292127490272562
Validation loss: 3.180512867122362

Epoch: 6| Step: 9
Training loss: 0.5546505875461499
Validation loss: 3.1303577842304504

Epoch: 6| Step: 10
Training loss: 1.2244404215370628
Validation loss: 3.0979886672360832

Epoch: 6| Step: 11
Training loss: 0.7346465237839467
Validation loss: 3.1243202868979143

Epoch: 6| Step: 12
Training loss: 0.5897932473092664
Validation loss: 3.0531486153706093

Epoch: 6| Step: 13
Training loss: 0.4284393562593878
Validation loss: 3.006200264184232

Epoch: 180| Step: 0
Training loss: 0.5511650209385969
Validation loss: 3.1237880391133612

Epoch: 6| Step: 1
Training loss: 0.6053600336730003
Validation loss: 3.1062014948884644

Epoch: 6| Step: 2
Training loss: 0.436404047604312
Validation loss: 3.0550793870381

Epoch: 6| Step: 3
Training loss: 0.7113571605171559
Validation loss: 3.1169877271128104

Epoch: 6| Step: 4
Training loss: 0.4863770242029802
Validation loss: 3.033835720721094

Epoch: 6| Step: 5
Training loss: 0.7547745917004499
Validation loss: 3.0865825767542594

Epoch: 6| Step: 6
Training loss: 0.5262582698090689
Validation loss: 3.077395460810125

Epoch: 6| Step: 7
Training loss: 0.565433166176961
Validation loss: 3.1417872237963516

Epoch: 6| Step: 8
Training loss: 0.9074769757505333
Validation loss: 3.103211676292091

Epoch: 6| Step: 9
Training loss: 0.7300526458882487
Validation loss: 3.1128242824201116

Epoch: 6| Step: 10
Training loss: 1.660913774782045
Validation loss: 3.110726042221567

Epoch: 6| Step: 11
Training loss: 0.9108841895180019
Validation loss: 3.2259745828076984

Epoch: 6| Step: 12
Training loss: 0.93336953379613
Validation loss: 3.2589140446905867

Epoch: 6| Step: 13
Training loss: 0.45949683293007654
Validation loss: 3.115561409329683

Epoch: 181| Step: 0
Training loss: 0.43893500408042546
Validation loss: 3.110824885901457

Epoch: 6| Step: 1
Training loss: 0.4691294247118489
Validation loss: 3.0458029531972013

Epoch: 6| Step: 2
Training loss: 0.6332393901777991
Validation loss: 2.9829543029212577

Epoch: 6| Step: 3
Training loss: 0.5866150054437889
Validation loss: 3.07553924029616

Epoch: 6| Step: 4
Training loss: 0.5919373096992994
Validation loss: 3.090767819891433

Epoch: 6| Step: 5
Training loss: 0.6869938027242581
Validation loss: 3.139872497189071

Epoch: 6| Step: 6
Training loss: 0.7278821712181904
Validation loss: 3.074315949728738

Epoch: 6| Step: 7
Training loss: 0.5647862385322815
Validation loss: 3.098004097507526

Epoch: 6| Step: 8
Training loss: 0.4434006289475935
Validation loss: 3.159544984273802

Epoch: 6| Step: 9
Training loss: 1.402231621044907
Validation loss: 3.023242901462852

Epoch: 6| Step: 10
Training loss: 0.6097911489693238
Validation loss: 3.194888993903367

Epoch: 6| Step: 11
Training loss: 1.07078408203463
Validation loss: 3.1408157670267074

Epoch: 6| Step: 12
Training loss: 0.7505944995257781
Validation loss: 3.1546448254859714

Epoch: 6| Step: 13
Training loss: 1.0439205898287223
Validation loss: 3.061546021397963

Epoch: 182| Step: 0
Training loss: 1.3270224089638472
Validation loss: 3.1339901227318663

Epoch: 6| Step: 1
Training loss: 0.6712873683593966
Validation loss: 3.189031968320272

Epoch: 6| Step: 2
Training loss: 0.7250620618104823
Validation loss: 3.0982512535589897

Epoch: 6| Step: 3
Training loss: 1.0666039252206996
Validation loss: 3.124193354448802

Epoch: 6| Step: 4
Training loss: 0.793186627602212
Validation loss: 3.0429050894310725

Epoch: 6| Step: 5
Training loss: 0.7000269773938775
Validation loss: 3.1678468905779793

Epoch: 6| Step: 6
Training loss: 0.7075798477568013
Validation loss: 3.085703510153338

Epoch: 6| Step: 7
Training loss: 0.6154778619359504
Validation loss: 3.1165305379898047

Epoch: 6| Step: 8
Training loss: 0.5679001673622106
Validation loss: 3.243029773799369

Epoch: 6| Step: 9
Training loss: 0.671573793184055
Validation loss: 3.190960333498417

Epoch: 6| Step: 10
Training loss: 0.8804033202642965
Validation loss: 3.1995541773618235

Epoch: 6| Step: 11
Training loss: 0.35995622984715375
Validation loss: 3.2052929372513748

Epoch: 6| Step: 12
Training loss: 0.7349048894211115
Validation loss: 3.0046945239543894

Epoch: 6| Step: 13
Training loss: 0.8040229497642207
Validation loss: 3.0840041788281516

Epoch: 183| Step: 0
Training loss: 0.890938151669406
Validation loss: 3.1559985095255483

Epoch: 6| Step: 1
Training loss: 0.5623747103288239
Validation loss: 2.9939024470304982

Epoch: 6| Step: 2
Training loss: 0.5445763918145544
Validation loss: 3.0903225418068083

Epoch: 6| Step: 3
Training loss: 0.5665639723491948
Validation loss: 3.1077800538709326

Epoch: 6| Step: 4
Training loss: 0.6744278602282372
Validation loss: 3.097466211634997

Epoch: 6| Step: 5
Training loss: 0.5364176231665343
Validation loss: 3.1446568308014573

Epoch: 6| Step: 6
Training loss: 1.7035195129951977
Validation loss: 3.1127558846851464

Epoch: 6| Step: 7
Training loss: 0.5780513819655314
Validation loss: 3.160318465562776

Epoch: 6| Step: 8
Training loss: 0.6304404695542468
Validation loss: 3.0737318778748093

Epoch: 6| Step: 9
Training loss: 0.7245745791900311
Validation loss: 3.1353351206435405

Epoch: 6| Step: 10
Training loss: 0.541808446033135
Validation loss: 3.0515373618292885

Epoch: 6| Step: 11
Training loss: 0.719368378370949
Validation loss: 3.0529694469733615

Epoch: 6| Step: 12
Training loss: 0.7831241253895911
Validation loss: 3.0662848511332714

Epoch: 6| Step: 13
Training loss: 0.6258664324406215
Validation loss: 3.135877573264034

Epoch: 184| Step: 0
Training loss: 0.47844922909103954
Validation loss: 3.094502624004363

Epoch: 6| Step: 1
Training loss: 0.6381303083477358
Validation loss: 3.232633628708907

Epoch: 6| Step: 2
Training loss: 0.6257353747979485
Validation loss: 3.149511616302432

Epoch: 6| Step: 3
Training loss: 0.6113416286354287
Validation loss: 3.1177171912015953

Epoch: 6| Step: 4
Training loss: 0.8557542298435583
Validation loss: 3.0998893215561796

Epoch: 6| Step: 5
Training loss: 0.6727670469757417
Validation loss: 3.051635140763644

Epoch: 6| Step: 6
Training loss: 0.7276735731884327
Validation loss: 3.122915844517439

Epoch: 6| Step: 7
Training loss: 0.7131235238677652
Validation loss: 3.03923038126839

Epoch: 6| Step: 8
Training loss: 1.1616302784913002
Validation loss: 3.0705012295013434

Epoch: 6| Step: 9
Training loss: 0.5214367676910047
Validation loss: 3.1244626664094124

Epoch: 6| Step: 10
Training loss: 1.3784872396416066
Validation loss: 3.142870592061698

Epoch: 6| Step: 11
Training loss: 0.6348398722728062
Validation loss: 3.2101118351913582

Epoch: 6| Step: 12
Training loss: 0.5249470820323952
Validation loss: 3.209603310115574

Epoch: 6| Step: 13
Training loss: 0.6058214452443806
Validation loss: 3.1969199765678167

Epoch: 185| Step: 0
Training loss: 0.5743925389547773
Validation loss: 3.135541581784274

Epoch: 6| Step: 1
Training loss: 0.5573125698649547
Validation loss: 3.16655460376885

Epoch: 6| Step: 2
Training loss: 0.4507348722668775
Validation loss: 3.213415249523022

Epoch: 6| Step: 3
Training loss: 1.0577931209349907
Validation loss: 3.098329051690087

Epoch: 6| Step: 4
Training loss: 0.5742104977384541
Validation loss: 3.1683420760147647

Epoch: 6| Step: 5
Training loss: 0.7223000963318998
Validation loss: 3.194853882649711

Epoch: 6| Step: 6
Training loss: 0.6161643130018692
Validation loss: 3.1418496143556727

Epoch: 6| Step: 7
Training loss: 0.5632449092067722
Validation loss: 3.253321979482048

Epoch: 6| Step: 8
Training loss: 1.5175430117046624
Validation loss: 3.090934384105674

Epoch: 6| Step: 9
Training loss: 0.36553697749168595
Validation loss: 3.1864351351341322

Epoch: 6| Step: 10
Training loss: 0.7293836724845243
Validation loss: 3.1765931215075325

Epoch: 6| Step: 11
Training loss: 0.6564691949533148
Validation loss: 3.164703454924503

Epoch: 6| Step: 12
Training loss: 0.6850540476381032
Validation loss: 3.1135715427456376

Epoch: 6| Step: 13
Training loss: 0.6782311369638284
Validation loss: 3.0682941043742042

Epoch: 186| Step: 0
Training loss: 0.6649413184038301
Validation loss: 3.0751711490215192

Epoch: 6| Step: 1
Training loss: 0.5147736196263323
Validation loss: 3.1033897110283855

Epoch: 6| Step: 2
Training loss: 0.6857025317549924
Validation loss: 3.0952352818102504

Epoch: 6| Step: 3
Training loss: 0.6899519674541664
Validation loss: 3.1263573305501255

Epoch: 6| Step: 4
Training loss: 0.7086683677743835
Validation loss: 3.1763499346288016

Epoch: 6| Step: 5
Training loss: 0.5018607325443933
Validation loss: 3.1095825074953094

Epoch: 6| Step: 6
Training loss: 0.5174029359687756
Validation loss: 3.170221746633212

Epoch: 6| Step: 7
Training loss: 1.0743667777980126
Validation loss: 3.2117086383298825

Epoch: 6| Step: 8
Training loss: 1.2956253833466556
Validation loss: 3.260292316945787

Epoch: 6| Step: 9
Training loss: 0.5863019191469147
Validation loss: 3.11485749040655

Epoch: 6| Step: 10
Training loss: 0.5310566494208542
Validation loss: 3.1294772817267864

Epoch: 6| Step: 11
Training loss: 0.566171215883937
Validation loss: 3.05661687384692

Epoch: 6| Step: 12
Training loss: 0.5960569237848905
Validation loss: 2.991983923033328

Epoch: 6| Step: 13
Training loss: 0.5520463037368312
Validation loss: 3.079923875454219

Epoch: 187| Step: 0
Training loss: 0.8200937615265111
Validation loss: 3.026256853463796

Epoch: 6| Step: 1
Training loss: 1.0162450218313361
Validation loss: 3.091297423393214

Epoch: 6| Step: 2
Training loss: 0.5841539321777516
Validation loss: 3.0839993728359985

Epoch: 6| Step: 3
Training loss: 0.5464738737110336
Validation loss: 3.0519289925948914

Epoch: 6| Step: 4
Training loss: 0.7542816176370329
Validation loss: 3.1993468045110514

Epoch: 6| Step: 5
Training loss: 0.7620789287669975
Validation loss: 3.10121637137776

Epoch: 6| Step: 6
Training loss: 0.680364819373587
Validation loss: 3.1888492944705713

Epoch: 6| Step: 7
Training loss: 1.3441634318404858
Validation loss: 3.2059647788328016

Epoch: 6| Step: 8
Training loss: 0.6249151172217711
Validation loss: 3.1946056551037545

Epoch: 6| Step: 9
Training loss: 0.48603249568874
Validation loss: 3.0896383764637414

Epoch: 6| Step: 10
Training loss: 0.4287323826876646
Validation loss: 3.082307069118357

Epoch: 6| Step: 11
Training loss: 0.7690959803157641
Validation loss: 3.14405246035494

Epoch: 6| Step: 12
Training loss: 0.6089025279717634
Validation loss: 3.1400589567266337

Epoch: 6| Step: 13
Training loss: 0.5866586443594592
Validation loss: 3.142047262706003

Epoch: 188| Step: 0
Training loss: 1.000435376758268
Validation loss: 3.241980255734383

Epoch: 6| Step: 1
Training loss: 0.5237658310730443
Validation loss: 3.090501254760507

Epoch: 6| Step: 2
Training loss: 0.5894267142656674
Validation loss: 3.1657265890678175

Epoch: 6| Step: 3
Training loss: 0.4169861661310994
Validation loss: 3.1314727886685962

Epoch: 6| Step: 4
Training loss: 0.7404508249077706
Validation loss: 3.0551301159076907

Epoch: 6| Step: 5
Training loss: 0.6823906038103622
Validation loss: 3.1957494659228414

Epoch: 6| Step: 6
Training loss: 0.653034347193138
Validation loss: 3.0622823988232737

Epoch: 6| Step: 7
Training loss: 0.5865995354562449
Validation loss: 3.097824650115983

Epoch: 6| Step: 8
Training loss: 0.5272623635113604
Validation loss: 3.1287207260723284

Epoch: 6| Step: 9
Training loss: 1.4442937611372844
Validation loss: 3.0652338139359405

Epoch: 6| Step: 10
Training loss: 0.6885069928309323
Validation loss: 3.1335666221320015

Epoch: 6| Step: 11
Training loss: 0.718420077357817
Validation loss: 3.189572564291055

Epoch: 6| Step: 12
Training loss: 0.5836662012599801
Validation loss: 3.0980735648434106

Epoch: 6| Step: 13
Training loss: 0.4780734140330015
Validation loss: 3.146194896172509

Epoch: 189| Step: 0
Training loss: 0.55581957848195
Validation loss: 3.1485101330174925

Epoch: 6| Step: 1
Training loss: 0.5249213920508149
Validation loss: 3.1714667698029753

Epoch: 6| Step: 2
Training loss: 0.6771108743983968
Validation loss: 3.1820002462473704

Epoch: 6| Step: 3
Training loss: 1.5525654634934454
Validation loss: 3.1283993352052573

Epoch: 6| Step: 4
Training loss: 0.6332403785058965
Validation loss: 3.169541024837163

Epoch: 6| Step: 5
Training loss: 0.5051895478941074
Validation loss: 3.238004776181238

Epoch: 6| Step: 6
Training loss: 0.5716115970287362
Validation loss: 3.236661179816496

Epoch: 6| Step: 7
Training loss: 0.732845824567736
Validation loss: 3.1940637960637535

Epoch: 6| Step: 8
Training loss: 0.6365984469541924
Validation loss: 3.1440026259496268

Epoch: 6| Step: 9
Training loss: 0.6202776363386119
Validation loss: 3.1418946895939817

Epoch: 6| Step: 10
Training loss: 0.8297787115101101
Validation loss: 3.1039865983455766

Epoch: 6| Step: 11
Training loss: 0.543049319210597
Validation loss: 3.1654270322354714

Epoch: 6| Step: 12
Training loss: 0.628597728802944
Validation loss: 3.10161718004841

Epoch: 6| Step: 13
Training loss: 0.5602865112881492
Validation loss: 3.163629535203797

Epoch: 190| Step: 0
Training loss: 0.9635460346569684
Validation loss: 3.075836751132066

Epoch: 6| Step: 1
Training loss: 0.6560054732201948
Validation loss: 3.234525139559654

Epoch: 6| Step: 2
Training loss: 0.566150475991546
Validation loss: 3.2631342148420863

Epoch: 6| Step: 3
Training loss: 0.5905898472250125
Validation loss: 3.2834898070666143

Epoch: 6| Step: 4
Training loss: 0.6032396197732173
Validation loss: 3.2891236312392294

Epoch: 6| Step: 5
Training loss: 1.2779325009163016
Validation loss: 3.115912697026087

Epoch: 6| Step: 6
Training loss: 0.7188440344291316
Validation loss: 3.0639355986112595

Epoch: 6| Step: 7
Training loss: 0.7337344602404733
Validation loss: 3.0475261481511287

Epoch: 6| Step: 8
Training loss: 0.6540214072567742
Validation loss: 3.1129099370384736

Epoch: 6| Step: 9
Training loss: 0.604142218676105
Validation loss: 3.0809566685742267

Epoch: 6| Step: 10
Training loss: 0.5446136040168353
Validation loss: 3.1187131585217513

Epoch: 6| Step: 11
Training loss: 0.7396831624170207
Validation loss: 3.128979228450923

Epoch: 6| Step: 12
Training loss: 0.6634813346163382
Validation loss: 3.1783027226641467

Epoch: 6| Step: 13
Training loss: 0.7823617273104746
Validation loss: 3.2381955247797647

Epoch: 191| Step: 0
Training loss: 0.6602818747629473
Validation loss: 3.260057390952103

Epoch: 6| Step: 1
Training loss: 0.6973230888559055
Validation loss: 3.1020948207856875

Epoch: 6| Step: 2
Training loss: 0.6175765248036027
Validation loss: 3.142690027116398

Epoch: 6| Step: 3
Training loss: 0.6680554116231966
Validation loss: 3.0332750065055003

Epoch: 6| Step: 4
Training loss: 1.1307387740636201
Validation loss: 3.1733695832620983

Epoch: 6| Step: 5
Training loss: 0.5579503495454655
Validation loss: 3.11937455247812

Epoch: 6| Step: 6
Training loss: 0.5174468251795808
Validation loss: 3.1385839735223136

Epoch: 6| Step: 7
Training loss: 0.5334730198838838
Validation loss: 3.1190607342952155

Epoch: 6| Step: 8
Training loss: 0.6298608110710568
Validation loss: 3.0449406539863175

Epoch: 6| Step: 9
Training loss: 0.7706343204896831
Validation loss: 3.133937807992012

Epoch: 6| Step: 10
Training loss: 1.2476875372912783
Validation loss: 3.1058026851994134

Epoch: 6| Step: 11
Training loss: 0.6570490559128105
Validation loss: 3.176313054663534

Epoch: 6| Step: 12
Training loss: 0.5359488694567055
Validation loss: 3.288169757804505

Epoch: 6| Step: 13
Training loss: 0.6946942441735633
Validation loss: 3.1527534354152893

Epoch: 192| Step: 0
Training loss: 0.5101036617169313
Validation loss: 3.2104915733106014

Epoch: 6| Step: 1
Training loss: 0.4819571538575286
Validation loss: 3.096113259216083

Epoch: 6| Step: 2
Training loss: 0.6252059597168198
Validation loss: 3.0673636527254007

Epoch: 6| Step: 3
Training loss: 0.7119700719833407
Validation loss: 3.1106100904176257

Epoch: 6| Step: 4
Training loss: 0.426260774397946
Validation loss: 3.1557213242924407

Epoch: 6| Step: 5
Training loss: 0.5039698538449681
Validation loss: 3.0930123525463906

Epoch: 6| Step: 6
Training loss: 0.6613439451016472
Validation loss: 3.184693278840004

Epoch: 6| Step: 7
Training loss: 0.6944633184623197
Validation loss: 3.1583515510604028

Epoch: 6| Step: 8
Training loss: 0.7257192086268973
Validation loss: 3.1424037773556353

Epoch: 6| Step: 9
Training loss: 0.4493529741197509
Validation loss: 3.072990718315682

Epoch: 6| Step: 10
Training loss: 0.5540085519171898
Validation loss: 3.1015234751772556

Epoch: 6| Step: 11
Training loss: 0.5213272772481558
Validation loss: 3.0823918056346775

Epoch: 6| Step: 12
Training loss: 1.2481308313347186
Validation loss: 3.1447449289702494

Epoch: 6| Step: 13
Training loss: 1.309985977418119
Validation loss: 3.0357721686521493

Epoch: 193| Step: 0
Training loss: 1.2857726685574518
Validation loss: 3.2146535688149527

Epoch: 6| Step: 1
Training loss: 0.6772839811325715
Validation loss: 3.220692736545493

Epoch: 6| Step: 2
Training loss: 0.7857382975042753
Validation loss: 3.3391723671859648

Epoch: 6| Step: 3
Training loss: 0.6700103968197946
Validation loss: 3.1699510574172747

Epoch: 6| Step: 4
Training loss: 0.5506375984456621
Validation loss: 3.1063844494342243

Epoch: 6| Step: 5
Training loss: 0.5897317742170929
Validation loss: 3.102542956042306

Epoch: 6| Step: 6
Training loss: 0.9445747144620267
Validation loss: 3.043674072216788

Epoch: 6| Step: 7
Training loss: 0.9253122614557796
Validation loss: 3.127141803463364

Epoch: 6| Step: 8
Training loss: 0.5298050977759744
Validation loss: 3.0232063093351926

Epoch: 6| Step: 9
Training loss: 0.45883552897341706
Validation loss: 3.112443812117197

Epoch: 6| Step: 10
Training loss: 0.8902386613770251
Validation loss: 3.1797251906102053

Epoch: 6| Step: 11
Training loss: 0.9782464728931586
Validation loss: 3.1668793372634028

Epoch: 6| Step: 12
Training loss: 0.7286439838799507
Validation loss: 3.177800924006406

Epoch: 6| Step: 13
Training loss: 1.2387920012219829
Validation loss: 3.0276851207270568

Epoch: 194| Step: 0
Training loss: 1.3014601576777927
Validation loss: 3.047456265292956

Epoch: 6| Step: 1
Training loss: 0.5059243237839584
Validation loss: 3.0910894468585712

Epoch: 6| Step: 2
Training loss: 0.5006607874867132
Validation loss: 3.1199867981443923

Epoch: 6| Step: 3
Training loss: 0.3702982557752213
Validation loss: 3.074594955336209

Epoch: 6| Step: 4
Training loss: 0.8595624199149303
Validation loss: 3.122760606106354

Epoch: 6| Step: 5
Training loss: 1.0192761449167014
Validation loss: 3.229066186797772

Epoch: 6| Step: 6
Training loss: 0.5604208030217144
Validation loss: 3.1685640063553726

Epoch: 6| Step: 7
Training loss: 0.4788298840022878
Validation loss: 3.042790366458566

Epoch: 6| Step: 8
Training loss: 0.6468601114522323
Validation loss: 3.050611542537418

Epoch: 6| Step: 9
Training loss: 0.4443785426914732
Validation loss: 3.1223434473542273

Epoch: 6| Step: 10
Training loss: 0.5033498249867974
Validation loss: 3.069762344833013

Epoch: 6| Step: 11
Training loss: 0.7535151915205386
Validation loss: 3.1045890793785365

Epoch: 6| Step: 12
Training loss: 0.6555924527332591
Validation loss: 3.093927153579064

Epoch: 6| Step: 13
Training loss: 0.5184043192118389
Validation loss: 3.099643372972416

Epoch: 195| Step: 0
Training loss: 0.6424676864008846
Validation loss: 3.0860194843202082

Epoch: 6| Step: 1
Training loss: 0.7121752768618812
Validation loss: 3.1725684724857994

Epoch: 6| Step: 2
Training loss: 0.5396367207434608
Validation loss: 3.1888238738148695

Epoch: 6| Step: 3
Training loss: 1.3834103084121132
Validation loss: 3.1360445735121094

Epoch: 6| Step: 4
Training loss: 0.5376795014351059
Validation loss: 3.1211688399084685

Epoch: 6| Step: 5
Training loss: 0.5172746452371255
Validation loss: 3.0871914404380467

Epoch: 6| Step: 6
Training loss: 1.1046314640751755
Validation loss: 3.0283980439038993

Epoch: 6| Step: 7
Training loss: 0.6018676479282726
Validation loss: 3.1052260330004584

Epoch: 6| Step: 8
Training loss: 0.4379088671080733
Validation loss: 3.1027495885433836

Epoch: 6| Step: 9
Training loss: 0.5562403795931972
Validation loss: 3.037638208727393

Epoch: 6| Step: 10
Training loss: 0.4794712722474291
Validation loss: 3.12568400208757

Epoch: 6| Step: 11
Training loss: 0.5598285338888916
Validation loss: 3.125807568789617

Epoch: 6| Step: 12
Training loss: 0.5176452593179268
Validation loss: 3.15077598439546

Epoch: 6| Step: 13
Training loss: 0.5814896694456377
Validation loss: 3.1774622373340393

Epoch: 196| Step: 0
Training loss: 0.4036210903664761
Validation loss: 3.123039870644946

Epoch: 6| Step: 1
Training loss: 0.5106814113072372
Validation loss: 3.2809040916615095

Epoch: 6| Step: 2
Training loss: 0.6501644531700607
Validation loss: 3.2961035092451887

Epoch: 6| Step: 3
Training loss: 0.9112093158425729
Validation loss: 3.201367263463466

Epoch: 6| Step: 4
Training loss: 0.48928765912111977
Validation loss: 3.1925985287343726

Epoch: 6| Step: 5
Training loss: 1.3983225855150954
Validation loss: 3.190974610615693

Epoch: 6| Step: 6
Training loss: 0.7415727981000226
Validation loss: 3.0892609546172127

Epoch: 6| Step: 7
Training loss: 0.872582399527051
Validation loss: 3.0968416352692913

Epoch: 6| Step: 8
Training loss: 0.5310043440172343
Validation loss: 3.0708391483688335

Epoch: 6| Step: 9
Training loss: 0.7390785554266973
Validation loss: 3.0878100673229834

Epoch: 6| Step: 10
Training loss: 0.6040383948160554
Validation loss: 3.145826647079806

Epoch: 6| Step: 11
Training loss: 0.6083044037624543
Validation loss: 3.128420458294949

Epoch: 6| Step: 12
Training loss: 1.0946263753218688
Validation loss: 3.156422638656787

Epoch: 6| Step: 13
Training loss: 0.5357093458856169
Validation loss: 3.145350334949342

Epoch: 197| Step: 0
Training loss: 0.5940132059658665
Validation loss: 3.1626441445250975

Epoch: 6| Step: 1
Training loss: 0.5972242352232411
Validation loss: 3.148035735313232

Epoch: 6| Step: 2
Training loss: 0.6182166584895249
Validation loss: 3.189555982343303

Epoch: 6| Step: 3
Training loss: 0.5010848792694231
Validation loss: 3.143684693423506

Epoch: 6| Step: 4
Training loss: 1.5644368945933604
Validation loss: 3.162226592497473

Epoch: 6| Step: 5
Training loss: 0.5129719305854887
Validation loss: 3.218952061505045

Epoch: 6| Step: 6
Training loss: 0.519424743060568
Validation loss: 3.199488602444815

Epoch: 6| Step: 7
Training loss: 0.7274204643923308
Validation loss: 3.172482424547808

Epoch: 6| Step: 8
Training loss: 0.5013200797941983
Validation loss: 3.1093572235877236

Epoch: 6| Step: 9
Training loss: 0.4430449795266202
Validation loss: 3.1851678182644325

Epoch: 6| Step: 10
Training loss: 0.42377295772286994
Validation loss: 3.1410873351134154

Epoch: 6| Step: 11
Training loss: 0.4980929484280446
Validation loss: 3.119313521301962

Epoch: 6| Step: 12
Training loss: 0.7771024856729875
Validation loss: 3.114431502980341

Epoch: 6| Step: 13
Training loss: 0.5734923562568982
Validation loss: 3.144208315740192

Epoch: 198| Step: 0
Training loss: 0.620835424479434
Validation loss: 3.1907574458316454

Epoch: 6| Step: 1
Training loss: 0.47263783820996397
Validation loss: 3.130459606645047

Epoch: 6| Step: 2
Training loss: 0.5069929111368858
Validation loss: 3.2382418849072474

Epoch: 6| Step: 3
Training loss: 0.6158644341301299
Validation loss: 3.2126177299884993

Epoch: 6| Step: 4
Training loss: 0.9228766866826394
Validation loss: 3.187752183898827

Epoch: 6| Step: 5
Training loss: 0.7529428285473693
Validation loss: 3.2129584493695975

Epoch: 6| Step: 6
Training loss: 0.3887009346224749
Validation loss: 3.1153008688085424

Epoch: 6| Step: 7
Training loss: 1.2543445902408912
Validation loss: 3.0939180219344213

Epoch: 6| Step: 8
Training loss: 0.604658877264564
Validation loss: 3.0733410084298285

Epoch: 6| Step: 9
Training loss: 0.41928542054510237
Validation loss: 3.115729160538188

Epoch: 6| Step: 10
Training loss: 0.5797322073505425
Validation loss: 3.1559311104505285

Epoch: 6| Step: 11
Training loss: 0.4903316477288025
Validation loss: 3.184622606528339

Epoch: 6| Step: 12
Training loss: 0.9592582171806224
Validation loss: 3.2329012082249804

Epoch: 6| Step: 13
Training loss: 0.43616105298708113
Validation loss: 3.1091427740281374

Epoch: 199| Step: 0
Training loss: 0.6901545212326524
Validation loss: 3.0830122978170573

Epoch: 6| Step: 1
Training loss: 0.49734675246808613
Validation loss: 3.193936972921258

Epoch: 6| Step: 2
Training loss: 0.6678721932565156
Validation loss: 3.124989128093881

Epoch: 6| Step: 3
Training loss: 0.6305400878934212
Validation loss: 3.1720409255953386

Epoch: 6| Step: 4
Training loss: 0.5638738913908885
Validation loss: 3.157105610012729

Epoch: 6| Step: 5
Training loss: 1.2670250672116508
Validation loss: 3.1863922612769486

Epoch: 6| Step: 6
Training loss: 1.106929662938957
Validation loss: 3.235119695517581

Epoch: 6| Step: 7
Training loss: 0.5020056077408369
Validation loss: 3.2692957299166565

Epoch: 6| Step: 8
Training loss: 0.6378327202663993
Validation loss: 3.1916390890087056

Epoch: 6| Step: 9
Training loss: 0.572316919312844
Validation loss: 3.1007139388768907

Epoch: 6| Step: 10
Training loss: 0.5603474385165292
Validation loss: 3.174588951275767

Epoch: 6| Step: 11
Training loss: 0.45758906175029734
Validation loss: 3.179108575579334

Epoch: 6| Step: 12
Training loss: 0.6899112983716233
Validation loss: 3.1280071666981777

Epoch: 6| Step: 13
Training loss: 0.4505397447207389
Validation loss: 3.118303804962881

Epoch: 200| Step: 0
Training loss: 1.0269669686737783
Validation loss: 3.1433797872379987

Epoch: 6| Step: 1
Training loss: 0.6815797620123879
Validation loss: 3.099469238395262

Epoch: 6| Step: 2
Training loss: 0.5318960020712925
Validation loss: 3.206350721297895

Epoch: 6| Step: 3
Training loss: 0.6007533390620697
Validation loss: 3.175915579557068

Epoch: 6| Step: 4
Training loss: 0.706570005921115
Validation loss: 3.158406795429081

Epoch: 6| Step: 5
Training loss: 0.5080430021201454
Validation loss: 3.285853870903946

Epoch: 6| Step: 6
Training loss: 0.6211633223428334
Validation loss: 3.1992943412846055

Epoch: 6| Step: 7
Training loss: 1.2217513565764713
Validation loss: 3.0863363402598125

Epoch: 6| Step: 8
Training loss: 0.6063475599149092
Validation loss: 3.1446476190173587

Epoch: 6| Step: 9
Training loss: 0.4677418994823989
Validation loss: 3.101008201540709

Epoch: 6| Step: 10
Training loss: 0.5749778142049051
Validation loss: 3.2521274890300953

Epoch: 6| Step: 11
Training loss: 0.4887452934116568
Validation loss: 3.1084762341392227

Epoch: 6| Step: 12
Training loss: 0.6141882100418038
Validation loss: 3.071186242254951

Epoch: 6| Step: 13
Training loss: 0.5220580927670665
Validation loss: 3.152326417581462

Epoch: 201| Step: 0
Training loss: 0.5053200221401244
Validation loss: 3.1601084676870195

Epoch: 6| Step: 1
Training loss: 0.6086977104743074
Validation loss: 3.2307343564055118

Epoch: 6| Step: 2
Training loss: 0.5522864585850588
Validation loss: 3.2524455968210066

Epoch: 6| Step: 3
Training loss: 0.5734779094209659
Validation loss: 3.2076954806179074

Epoch: 6| Step: 4
Training loss: 0.7217051252494188
Validation loss: 3.2210295916365252

Epoch: 6| Step: 5
Training loss: 0.5668595177535055
Validation loss: 3.17130814421442

Epoch: 6| Step: 6
Training loss: 1.1767835938727929
Validation loss: 3.0768994055350958

Epoch: 6| Step: 7
Training loss: 0.5093633006805954
Validation loss: 3.1184602209101215

Epoch: 6| Step: 8
Training loss: 0.6603486271736281
Validation loss: 3.0935873380599346

Epoch: 6| Step: 9
Training loss: 0.5245954033076868
Validation loss: 3.1134436870910274

Epoch: 6| Step: 10
Training loss: 0.5305499625646283
Validation loss: 3.1154501016157767

Epoch: 6| Step: 11
Training loss: 1.0591151230998836
Validation loss: 3.1753911165448296

Epoch: 6| Step: 12
Training loss: 0.7675166602920331
Validation loss: 3.2136851340016075

Epoch: 6| Step: 13
Training loss: 0.42991507312538235
Validation loss: 3.28143979689253

Epoch: 202| Step: 0
Training loss: 0.6003208971205761
Validation loss: 3.319908865535747

Epoch: 6| Step: 1
Training loss: 0.9445195300666404
Validation loss: 3.2495792679007796

Epoch: 6| Step: 2
Training loss: 0.35185215991071317
Validation loss: 3.127340813358328

Epoch: 6| Step: 3
Training loss: 0.49323470110206796
Validation loss: 3.1192636101350812

Epoch: 6| Step: 4
Training loss: 1.2497382843695497
Validation loss: 3.105626592883283

Epoch: 6| Step: 5
Training loss: 0.4819361291449582
Validation loss: 3.1938802902808696

Epoch: 6| Step: 6
Training loss: 0.5530046267376268
Validation loss: 3.127301983153767

Epoch: 6| Step: 7
Training loss: 0.8207263810695167
Validation loss: 3.1903437227364226

Epoch: 6| Step: 8
Training loss: 0.5482228698697436
Validation loss: 3.2383036319341114

Epoch: 6| Step: 9
Training loss: 0.5231513479563787
Validation loss: 3.1810186725441367

Epoch: 6| Step: 10
Training loss: 0.38994734157952765
Validation loss: 3.1885855328494856

Epoch: 6| Step: 11
Training loss: 0.3685542702482982
Validation loss: 3.1524352131699787

Epoch: 6| Step: 12
Training loss: 0.5125080166166465
Validation loss: 3.114383465702259

Epoch: 6| Step: 13
Training loss: 0.5817699998139843
Validation loss: 3.1319339373276747

Epoch: 203| Step: 0
Training loss: 0.9255501502951446
Validation loss: 3.1677114912973

Epoch: 6| Step: 1
Training loss: 1.2445713896423622
Validation loss: 3.1628381817197195

Epoch: 6| Step: 2
Training loss: 0.5188393251657395
Validation loss: 3.180173719567407

Epoch: 6| Step: 3
Training loss: 0.5860872713044649
Validation loss: 3.2994948910903283

Epoch: 6| Step: 4
Training loss: 0.7749454940579248
Validation loss: 3.14486184603631

Epoch: 6| Step: 5
Training loss: 0.5284389567115417
Validation loss: 3.1945422922343

Epoch: 6| Step: 6
Training loss: 0.5123126536545122
Validation loss: 3.1437388809846754

Epoch: 6| Step: 7
Training loss: 0.8560120063880026
Validation loss: 3.1747475506199607

Epoch: 6| Step: 8
Training loss: 0.7359834061415741
Validation loss: 3.1240524254078346

Epoch: 6| Step: 9
Training loss: 0.38236286070360603
Validation loss: 3.0688774372477683

Epoch: 6| Step: 10
Training loss: 0.6037933303258676
Validation loss: 3.1834136100619825

Epoch: 6| Step: 11
Training loss: 0.23710605172808805
Validation loss: 3.230944191427374

Epoch: 6| Step: 12
Training loss: 0.36837835171989836
Validation loss: 3.1428773815362105

Epoch: 6| Step: 13
Training loss: 0.4221230413500457
Validation loss: 3.125836018949565

Epoch: 204| Step: 0
Training loss: 0.37990069898845796
Validation loss: 3.154211928539648

Epoch: 6| Step: 1
Training loss: 0.6965513658211285
Validation loss: 3.1923970770320267

Epoch: 6| Step: 2
Training loss: 0.6092098452437517
Validation loss: 3.0920043027485153

Epoch: 6| Step: 3
Training loss: 0.7477150123647218
Validation loss: 3.2191440871873196

Epoch: 6| Step: 4
Training loss: 0.5627988974851208
Validation loss: 3.1420818764467753

Epoch: 6| Step: 5
Training loss: 0.9483008636643652
Validation loss: 3.1326935603647605

Epoch: 6| Step: 6
Training loss: 0.6464032586138921
Validation loss: 3.070173912382583

Epoch: 6| Step: 7
Training loss: 0.6189356804649266
Validation loss: 3.1785239075281706

Epoch: 6| Step: 8
Training loss: 0.602671628740477
Validation loss: 3.1228396005178913

Epoch: 6| Step: 9
Training loss: 0.45714667077315146
Validation loss: 3.0870074513770422

Epoch: 6| Step: 10
Training loss: 0.618660051377598
Validation loss: 3.138481534746266

Epoch: 6| Step: 11
Training loss: 0.6089398713455768
Validation loss: 3.1715939652540954

Epoch: 6| Step: 12
Training loss: 0.5715123970843127
Validation loss: 3.1721393243306135

Epoch: 6| Step: 13
Training loss: 1.2618891834144002
Validation loss: 3.172674745356895

Epoch: 205| Step: 0
Training loss: 0.5820307635618903
Validation loss: 3.188697540118853

Epoch: 6| Step: 1
Training loss: 0.509049508178986
Validation loss: 3.190659446916437

Epoch: 6| Step: 2
Training loss: 1.3040952880306222
Validation loss: 3.1518881341298846

Epoch: 6| Step: 3
Training loss: 0.42070613636862375
Validation loss: 3.2059170471385796

Epoch: 6| Step: 4
Training loss: 0.7259785756557119
Validation loss: 3.2690524742362426

Epoch: 6| Step: 5
Training loss: 0.43951188436373767
Validation loss: 3.124708594404781

Epoch: 6| Step: 6
Training loss: 0.582455115901601
Validation loss: 3.064624296148416

Epoch: 6| Step: 7
Training loss: 0.499164718067949
Validation loss: 3.1718829425781228

Epoch: 6| Step: 8
Training loss: 0.7232564135127648
Validation loss: 3.151769674814297

Epoch: 6| Step: 9
Training loss: 0.4400465963356196
Validation loss: 3.1796624809861704

Epoch: 6| Step: 10
Training loss: 0.4064001942806362
Validation loss: 3.1424209242456236

Epoch: 6| Step: 11
Training loss: 0.9390684359294634
Validation loss: 3.1426275900201195

Epoch: 6| Step: 12
Training loss: 0.5918790048949145
Validation loss: 3.1822846574388763

Epoch: 6| Step: 13
Training loss: 0.4518596476668117
Validation loss: 3.2201216654567943

Epoch: 206| Step: 0
Training loss: 1.0332489291964781
Validation loss: 3.2421832594020334

Epoch: 6| Step: 1
Training loss: 0.4607554253927835
Validation loss: 3.230205471345498

Epoch: 6| Step: 2
Training loss: 0.5803807814468486
Validation loss: 3.1746580445376664

Epoch: 6| Step: 3
Training loss: 0.5882531502587057
Validation loss: 3.076407610221791

Epoch: 6| Step: 4
Training loss: 0.5492601967769263
Validation loss: 3.128243695680179

Epoch: 6| Step: 5
Training loss: 0.4936797061811561
Validation loss: 3.161450837999453

Epoch: 6| Step: 6
Training loss: 0.4195532311731633
Validation loss: 3.1152788786863264

Epoch: 6| Step: 7
Training loss: 0.4271777289053748
Validation loss: 3.0719124182139046

Epoch: 6| Step: 8
Training loss: 0.5339041771763371
Validation loss: 3.1725552836301554

Epoch: 6| Step: 9
Training loss: 0.6459591394351455
Validation loss: 3.2168692862647266

Epoch: 6| Step: 10
Training loss: 1.1990379669407747
Validation loss: 3.2182437535651087

Epoch: 6| Step: 11
Training loss: 0.4469184027448474
Validation loss: 3.1685237625689395

Epoch: 6| Step: 12
Training loss: 0.46842738811834733
Validation loss: 3.1503231437883468

Epoch: 6| Step: 13
Training loss: 0.5023994391202073
Validation loss: 3.226531329554751

Epoch: 207| Step: 0
Training loss: 0.5110580022258717
Validation loss: 3.1427086391497294

Epoch: 6| Step: 1
Training loss: 0.5578251065237484
Validation loss: 3.2095251016700463

Epoch: 6| Step: 2
Training loss: 0.6547354978752007
Validation loss: 3.0960372279210033

Epoch: 6| Step: 3
Training loss: 0.4947301190561314
Validation loss: 3.2478548575427855

Epoch: 6| Step: 4
Training loss: 0.5848185472615024
Validation loss: 3.2240009623447996

Epoch: 6| Step: 5
Training loss: 1.2611858553496422
Validation loss: 3.2013608338695962

Epoch: 6| Step: 6
Training loss: 0.46559687919955434
Validation loss: 3.181364274985915

Epoch: 6| Step: 7
Training loss: 0.9425193885306525
Validation loss: 3.2169117662873257

Epoch: 6| Step: 8
Training loss: 0.2743026670204589
Validation loss: 3.2121318690323317

Epoch: 6| Step: 9
Training loss: 0.6354104156395116
Validation loss: 3.2279593805280875

Epoch: 6| Step: 10
Training loss: 0.5141055810842442
Validation loss: 3.233441081332796

Epoch: 6| Step: 11
Training loss: 0.6268065569435463
Validation loss: 3.2021132445236193

Epoch: 6| Step: 12
Training loss: 0.6038890781897504
Validation loss: 3.243103461736524

Epoch: 6| Step: 13
Training loss: 0.43382367060878657
Validation loss: 3.125921901775955

Epoch: 208| Step: 0
Training loss: 0.40119340016117633
Validation loss: 3.098259949193858

Epoch: 6| Step: 1
Training loss: 0.9591977878385969
Validation loss: 3.1356339025595994

Epoch: 6| Step: 2
Training loss: 0.634987542901289
Validation loss: 3.1452171446408186

Epoch: 6| Step: 3
Training loss: 0.4458703010895397
Validation loss: 3.173155703007556

Epoch: 6| Step: 4
Training loss: 0.5325472644193044
Validation loss: 3.166038040875625

Epoch: 6| Step: 5
Training loss: 0.6267684712132208
Validation loss: 3.1259631643551384

Epoch: 6| Step: 6
Training loss: 0.47842565196670067
Validation loss: 3.1521181816062325

Epoch: 6| Step: 7
Training loss: 0.5626283605136616
Validation loss: 3.2879900901819896

Epoch: 6| Step: 8
Training loss: 0.6078767453246464
Validation loss: 3.1417909801655037

Epoch: 6| Step: 9
Training loss: 0.5326029435348965
Validation loss: 3.11219782147581

Epoch: 6| Step: 10
Training loss: 1.2003594853452142
Validation loss: 3.126057954360408

Epoch: 6| Step: 11
Training loss: 0.4908642009599265
Validation loss: 3.1619624700070355

Epoch: 6| Step: 12
Training loss: 0.6584274860447978
Validation loss: 3.09902712107162

Epoch: 6| Step: 13
Training loss: 0.3650589587982428
Validation loss: 3.1478004158076134

Epoch: 209| Step: 0
Training loss: 0.43135292511188417
Validation loss: 3.2091193330401437

Epoch: 6| Step: 1
Training loss: 1.0116924739061879
Validation loss: 3.2424996712164122

Epoch: 6| Step: 2
Training loss: 0.7104598736045958
Validation loss: 3.3384952789908566

Epoch: 6| Step: 3
Training loss: 0.632868022602217
Validation loss: 3.161943996440992

Epoch: 6| Step: 4
Training loss: 0.6677508082297463
Validation loss: 3.133775634356456

Epoch: 6| Step: 5
Training loss: 0.7931951566048132
Validation loss: 3.129053513216121

Epoch: 6| Step: 6
Training loss: 0.5926940965423149
Validation loss: 3.1943921020384383

Epoch: 6| Step: 7
Training loss: 0.6363008918344092
Validation loss: 3.2097124793323295

Epoch: 6| Step: 8
Training loss: 1.1926521665627408
Validation loss: 3.2356479860938094

Epoch: 6| Step: 9
Training loss: 0.6892533053269413
Validation loss: 3.2667437618915476

Epoch: 6| Step: 10
Training loss: 1.1037510443538854
Validation loss: 3.3271335324915627

Epoch: 6| Step: 11
Training loss: 0.7230245528029052
Validation loss: 3.341122269144707

Epoch: 6| Step: 12
Training loss: 0.5633440043588014
Validation loss: 3.182959270635772

Epoch: 6| Step: 13
Training loss: 0.4765367657326399
Validation loss: 3.1637286979513792

Epoch: 210| Step: 0
Training loss: 0.4119177096889584
Validation loss: 3.0292742474397696

Epoch: 6| Step: 1
Training loss: 0.8213232080934171
Validation loss: 3.1240070800098616

Epoch: 6| Step: 2
Training loss: 0.7925791041488954
Validation loss: 3.0745433230488657

Epoch: 6| Step: 3
Training loss: 0.6997627827061821
Validation loss: 3.0100721582315972

Epoch: 6| Step: 4
Training loss: 1.0236141256261841
Validation loss: 3.107864933329172

Epoch: 6| Step: 5
Training loss: 0.7551026018164814
Validation loss: 3.1786237807271713

Epoch: 6| Step: 6
Training loss: 0.7989971103401114
Validation loss: 3.22334160809275

Epoch: 6| Step: 7
Training loss: 0.5409248358501861
Validation loss: 3.1651978390627513

Epoch: 6| Step: 8
Training loss: 0.5117868567417762
Validation loss: 3.0630036413528328

Epoch: 6| Step: 9
Training loss: 1.2812002684082884
Validation loss: 3.0801077716104523

Epoch: 6| Step: 10
Training loss: 0.6544504924756288
Validation loss: 3.0504110700283875

Epoch: 6| Step: 11
Training loss: 0.4284526246598911
Validation loss: 3.0414842307017307

Epoch: 6| Step: 12
Training loss: 0.5953842059826681
Validation loss: 3.100099155932166

Epoch: 6| Step: 13
Training loss: 0.8355458848545223
Validation loss: 3.14246836854507

Epoch: 211| Step: 0
Training loss: 0.5433701328334277
Validation loss: 3.1305130457443555

Epoch: 6| Step: 1
Training loss: 0.6396964717621592
Validation loss: 3.277185532483297

Epoch: 6| Step: 2
Training loss: 0.5643519802616079
Validation loss: 3.2279787072917636

Epoch: 6| Step: 3
Training loss: 1.2986103075991686
Validation loss: 3.1874892290718755

Epoch: 6| Step: 4
Training loss: 0.6021836034532907
Validation loss: 3.1319260456891533

Epoch: 6| Step: 5
Training loss: 0.4448350387915492
Validation loss: 3.101392291288725

Epoch: 6| Step: 6
Training loss: 0.5908583447534259
Validation loss: 3.06636769782775

Epoch: 6| Step: 7
Training loss: 0.5052922726406263
Validation loss: 3.0467969052992543

Epoch: 6| Step: 8
Training loss: 0.583241018302164
Validation loss: 3.050416580267585

Epoch: 6| Step: 9
Training loss: 1.1046956192862094
Validation loss: 3.1011606720033584

Epoch: 6| Step: 10
Training loss: 0.6933163051928937
Validation loss: 3.1256746453976025

Epoch: 6| Step: 11
Training loss: 0.6377462977171429
Validation loss: 3.253037952403011

Epoch: 6| Step: 12
Training loss: 0.5621469767428721
Validation loss: 3.292665297892656

Epoch: 6| Step: 13
Training loss: 0.5479143348131733
Validation loss: 3.2090340299164075

Epoch: 212| Step: 0
Training loss: 0.6196453071269399
Validation loss: 3.1941162705586366

Epoch: 6| Step: 1
Training loss: 0.40724390665346755
Validation loss: 3.1831275520586617

Epoch: 6| Step: 2
Training loss: 0.5630801970327864
Validation loss: 3.088440175610957

Epoch: 6| Step: 3
Training loss: 0.7296822541597644
Validation loss: 3.0965315134621405

Epoch: 6| Step: 4
Training loss: 0.5136935733520146
Validation loss: 3.0737373204517224

Epoch: 6| Step: 5
Training loss: 0.6230451530026164
Validation loss: 3.128071890020326

Epoch: 6| Step: 6
Training loss: 0.475811898758635
Validation loss: 3.1239345132840333

Epoch: 6| Step: 7
Training loss: 0.5793351832743667
Validation loss: 3.1676760913462867

Epoch: 6| Step: 8
Training loss: 1.1804440327246106
Validation loss: 3.190227251857246

Epoch: 6| Step: 9
Training loss: 0.828585442708738
Validation loss: 3.2547619973952497

Epoch: 6| Step: 10
Training loss: 0.4566635870075568
Validation loss: 3.192683549113738

Epoch: 6| Step: 11
Training loss: 0.43160658482061687
Validation loss: 3.145667726481849

Epoch: 6| Step: 12
Training loss: 0.5308192133360511
Validation loss: 3.0928186112800526

Epoch: 6| Step: 13
Training loss: 1.0370809834935035
Validation loss: 3.107492308235009

Epoch: 213| Step: 0
Training loss: 0.5972360118363194
Validation loss: 3.121322273351582

Epoch: 6| Step: 1
Training loss: 0.49054279732137107
Validation loss: 3.106097438041268

Epoch: 6| Step: 2
Training loss: 0.5477776299023552
Validation loss: 3.154004824948939

Epoch: 6| Step: 3
Training loss: 0.4281866043208405
Validation loss: 3.103085135325167

Epoch: 6| Step: 4
Training loss: 0.9118772615714524
Validation loss: 3.2014112276376836

Epoch: 6| Step: 5
Training loss: 0.3406106910849884
Validation loss: 3.1954428872364797

Epoch: 6| Step: 6
Training loss: 0.5463424814706237
Validation loss: 3.193966246946308

Epoch: 6| Step: 7
Training loss: 1.1675129386952738
Validation loss: 3.263574969749532

Epoch: 6| Step: 8
Training loss: 0.42375502417407584
Validation loss: 3.239107340262931

Epoch: 6| Step: 9
Training loss: 0.6401758713027793
Validation loss: 3.2466315884689325

Epoch: 6| Step: 10
Training loss: 0.4088024503554198
Validation loss: 3.201690749700529

Epoch: 6| Step: 11
Training loss: 0.5349749794127208
Validation loss: 3.179309519453472

Epoch: 6| Step: 12
Training loss: 0.45671161657786097
Validation loss: 3.2217438733723043

Epoch: 6| Step: 13
Training loss: 0.5139633628074421
Validation loss: 3.1796192158733168

Epoch: 214| Step: 0
Training loss: 1.2067663402031945
Validation loss: 3.149184814310658

Epoch: 6| Step: 1
Training loss: 0.5236099869940598
Validation loss: 3.137884459427555

Epoch: 6| Step: 2
Training loss: 0.5762634204617434
Validation loss: 3.1145361361972976

Epoch: 6| Step: 3
Training loss: 0.5143509643890516
Validation loss: 3.234091151954029

Epoch: 6| Step: 4
Training loss: 0.9192946577722143
Validation loss: 3.216121130885755

Epoch: 6| Step: 5
Training loss: 0.5022854725210409
Validation loss: 3.2751653779961543

Epoch: 6| Step: 6
Training loss: 0.4164626893805953
Validation loss: 3.243356124886715

Epoch: 6| Step: 7
Training loss: 0.6023082569317636
Validation loss: 3.2054349184245963

Epoch: 6| Step: 8
Training loss: 0.4700431787663609
Validation loss: 3.2343254638416785

Epoch: 6| Step: 9
Training loss: 0.5265852948696723
Validation loss: 3.1411021615034214

Epoch: 6| Step: 10
Training loss: 0.48287635121760075
Validation loss: 3.073893948773423

Epoch: 6| Step: 11
Training loss: 0.42753978117511654
Validation loss: 3.0683595174542124

Epoch: 6| Step: 12
Training loss: 0.42572542577035977
Validation loss: 3.1004152137832577

Epoch: 6| Step: 13
Training loss: 0.553190117575198
Validation loss: 3.193542649417872

Epoch: 215| Step: 0
Training loss: 1.1500762872685775
Validation loss: 3.082427849854645

Epoch: 6| Step: 1
Training loss: 0.5511972466137055
Validation loss: 3.210783212981587

Epoch: 6| Step: 2
Training loss: 0.45814554384390194
Validation loss: 3.154310455135563

Epoch: 6| Step: 3
Training loss: 0.557482487698561
Validation loss: 3.140264449292103

Epoch: 6| Step: 4
Training loss: 0.5243818674558538
Validation loss: 3.187694930056378

Epoch: 6| Step: 5
Training loss: 0.6776464223819748
Validation loss: 3.057588661407608

Epoch: 6| Step: 6
Training loss: 0.9968205212861062
Validation loss: 3.1087841450189244

Epoch: 6| Step: 7
Training loss: 0.5569055294997385
Validation loss: 3.155992805904671

Epoch: 6| Step: 8
Training loss: 0.49894788435133736
Validation loss: 3.1344832914134972

Epoch: 6| Step: 9
Training loss: 0.5150730184067293
Validation loss: 3.200968542152378

Epoch: 6| Step: 10
Training loss: 0.7269709269759094
Validation loss: 3.2665165196835106

Epoch: 6| Step: 11
Training loss: 0.7056941038948947
Validation loss: 3.325476032494003

Epoch: 6| Step: 12
Training loss: 0.5798854829104214
Validation loss: 3.2121279103949205

Epoch: 6| Step: 13
Training loss: 0.6294734363799043
Validation loss: 3.187850608741247

Epoch: 216| Step: 0
Training loss: 0.5842541738025607
Validation loss: 3.113196282082859

Epoch: 6| Step: 1
Training loss: 1.2162333694528538
Validation loss: 3.060063255545522

Epoch: 6| Step: 2
Training loss: 0.48527031876692556
Validation loss: 3.189176691911894

Epoch: 6| Step: 3
Training loss: 1.021107416273103
Validation loss: 3.1478356731976542

Epoch: 6| Step: 4
Training loss: 0.47274019741141216
Validation loss: 3.1991324997276687

Epoch: 6| Step: 5
Training loss: 0.4965522929751606
Validation loss: 3.1530201819205774

Epoch: 6| Step: 6
Training loss: 0.49339897679418815
Validation loss: 3.1626000183734293

Epoch: 6| Step: 7
Training loss: 0.5516427519340878
Validation loss: 3.134593403522975

Epoch: 6| Step: 8
Training loss: 0.45962612657821317
Validation loss: 3.1218970342857055

Epoch: 6| Step: 9
Training loss: 0.44354091406215296
Validation loss: 3.1148121514785467

Epoch: 6| Step: 10
Training loss: 0.6160953854706757
Validation loss: 3.211492306437515

Epoch: 6| Step: 11
Training loss: 0.4775296075739131
Validation loss: 3.143103891239725

Epoch: 6| Step: 12
Training loss: 0.3612946572140225
Validation loss: 3.222836921328359

Epoch: 6| Step: 13
Training loss: 0.6090268827997483
Validation loss: 3.1383612905774094

Epoch: 217| Step: 0
Training loss: 1.1252725059226538
Validation loss: 3.2301778297169097

Epoch: 6| Step: 1
Training loss: 0.4711916592453984
Validation loss: 3.245626624841722

Epoch: 6| Step: 2
Training loss: 0.4545004948412947
Validation loss: 3.1925510701730118

Epoch: 6| Step: 3
Training loss: 0.4118313506908594
Validation loss: 3.1844937977142718

Epoch: 6| Step: 4
Training loss: 0.950392636925339
Validation loss: 3.189833366681721

Epoch: 6| Step: 5
Training loss: 0.3202403499011442
Validation loss: 3.214824319551321

Epoch: 6| Step: 6
Training loss: 0.661573975634253
Validation loss: 3.1852118812800927

Epoch: 6| Step: 7
Training loss: 0.5686701550872364
Validation loss: 3.2227138321481266

Epoch: 6| Step: 8
Training loss: 0.5626231164771476
Validation loss: 3.1894382492811775

Epoch: 6| Step: 9
Training loss: 0.49663010086063153
Validation loss: 3.1767711840431323

Epoch: 6| Step: 10
Training loss: 0.5342082237418292
Validation loss: 3.1690860632784745

Epoch: 6| Step: 11
Training loss: 0.3324427803181035
Validation loss: 3.203458046074935

Epoch: 6| Step: 12
Training loss: 0.3668624575548909
Validation loss: 3.2000818078193642

Epoch: 6| Step: 13
Training loss: 0.46962327674161686
Validation loss: 3.1855584009314017

Epoch: 218| Step: 0
Training loss: 0.44651461521377167
Validation loss: 3.2010417087073693

Epoch: 6| Step: 1
Training loss: 0.48967963820368215
Validation loss: 3.215610652158787

Epoch: 6| Step: 2
Training loss: 0.5787907452998774
Validation loss: 3.2164528189286794

Epoch: 6| Step: 3
Training loss: 0.5569996529240785
Validation loss: 3.151509479864114

Epoch: 6| Step: 4
Training loss: 0.39943778939879043
Validation loss: 3.1605239358768165

Epoch: 6| Step: 5
Training loss: 0.44968527742304504
Validation loss: 3.2283016071588895

Epoch: 6| Step: 6
Training loss: 1.111311927503062
Validation loss: 3.1412498017106234

Epoch: 6| Step: 7
Training loss: 0.3723333435269192
Validation loss: 3.1349334133160625

Epoch: 6| Step: 8
Training loss: 0.6196982583147522
Validation loss: 3.16294623884289

Epoch: 6| Step: 9
Training loss: 1.1380497850915234
Validation loss: 3.1546102110319363

Epoch: 6| Step: 10
Training loss: 0.40958517372336195
Validation loss: 3.1774827466366746

Epoch: 6| Step: 11
Training loss: 0.49749875293747914
Validation loss: 3.284112245046997

Epoch: 6| Step: 12
Training loss: 0.7388381068945097
Validation loss: 3.2736693112786988

Epoch: 6| Step: 13
Training loss: 0.43749182557234934
Validation loss: 3.185079702880187

Epoch: 219| Step: 0
Training loss: 0.3987137080212446
Validation loss: 3.2290214546942377

Epoch: 6| Step: 1
Training loss: 0.5327195150728249
Validation loss: 3.1531912205336243

Epoch: 6| Step: 2
Training loss: 0.7036820642126008
Validation loss: 3.1334673545122547

Epoch: 6| Step: 3
Training loss: 0.7254798370046538
Validation loss: 3.0672559204865255

Epoch: 6| Step: 4
Training loss: 0.5487048462036539
Validation loss: 3.088170630225923

Epoch: 6| Step: 5
Training loss: 0.6621392617471203
Validation loss: 3.1631334110256972

Epoch: 6| Step: 6
Training loss: 0.5602101234907736
Validation loss: 3.176580875041484

Epoch: 6| Step: 7
Training loss: 0.48143214271592494
Validation loss: 3.2129482832259866

Epoch: 6| Step: 8
Training loss: 0.40540012080167714
Validation loss: 3.1338729268652052

Epoch: 6| Step: 9
Training loss: 0.5222030145610725
Validation loss: 3.280461825213354

Epoch: 6| Step: 10
Training loss: 0.8907900874742162
Validation loss: 3.2043249100267825

Epoch: 6| Step: 11
Training loss: 0.27291523239011234
Validation loss: 3.1998032131881278

Epoch: 6| Step: 12
Training loss: 1.1191642718787762
Validation loss: 3.225206005308413

Epoch: 6| Step: 13
Training loss: 0.5587306621798007
Validation loss: 3.184503343445934

Epoch: 220| Step: 0
Training loss: 0.5949863812146221
Validation loss: 3.1525680292036067

Epoch: 6| Step: 1
Training loss: 1.3943768584112062
Validation loss: 3.1458174008267035

Epoch: 6| Step: 2
Training loss: 0.4924546984833108
Validation loss: 3.1287335027853387

Epoch: 6| Step: 3
Training loss: 0.4212192631439676
Validation loss: 3.211649374157276

Epoch: 6| Step: 4
Training loss: 0.4240609158153924
Validation loss: 3.1851721597211324

Epoch: 6| Step: 5
Training loss: 0.5900943299629906
Validation loss: 3.166772819714084

Epoch: 6| Step: 6
Training loss: 0.4927097758728374
Validation loss: 3.1918443856091705

Epoch: 6| Step: 7
Training loss: 0.4293593454075325
Validation loss: 3.203221426652153

Epoch: 6| Step: 8
Training loss: 0.4697303375282786
Validation loss: 3.1689534254318015

Epoch: 6| Step: 9
Training loss: 0.3565955694511731
Validation loss: 3.1765593716840073

Epoch: 6| Step: 10
Training loss: 0.46767856217117315
Validation loss: 3.1611223539820297

Epoch: 6| Step: 11
Training loss: 0.6438951995205009
Validation loss: 3.1176771896307347

Epoch: 6| Step: 12
Training loss: 0.5220589776027045
Validation loss: 3.105510361110764

Epoch: 6| Step: 13
Training loss: 0.5325221369623806
Validation loss: 3.2018417144798605

Epoch: 221| Step: 0
Training loss: 0.5020137408872204
Validation loss: 3.182414417219868

Epoch: 6| Step: 1
Training loss: 1.1478338406700481
Validation loss: 3.200672432661541

Epoch: 6| Step: 2
Training loss: 0.6375354607387269
Validation loss: 3.179142560821642

Epoch: 6| Step: 3
Training loss: 0.902713551233669
Validation loss: 3.155933464972649

Epoch: 6| Step: 4
Training loss: 0.5085473538989344
Validation loss: 3.1912314072538126

Epoch: 6| Step: 5
Training loss: 0.4539741583498254
Validation loss: 3.183736586535619

Epoch: 6| Step: 6
Training loss: 0.35968174489816873
Validation loss: 3.126906995653461

Epoch: 6| Step: 7
Training loss: 0.3392252939964458
Validation loss: 3.1536727177518507

Epoch: 6| Step: 8
Training loss: 0.5659711547820694
Validation loss: 3.1001936728983175

Epoch: 6| Step: 9
Training loss: 0.5377887659859387
Validation loss: 3.131074475605463

Epoch: 6| Step: 10
Training loss: 0.4248556873795199
Validation loss: 3.152473153976374

Epoch: 6| Step: 11
Training loss: 0.5318683503718075
Validation loss: 3.2429355723485793

Epoch: 6| Step: 12
Training loss: 0.5626775408410796
Validation loss: 3.2725786221907023

Epoch: 6| Step: 13
Training loss: 0.484093030258608
Validation loss: 3.2641802060318224

Epoch: 222| Step: 0
Training loss: 0.7376376783234584
Validation loss: 3.2474331072289724

Epoch: 6| Step: 1
Training loss: 0.6830799024377154
Validation loss: 3.1137999928474773

Epoch: 6| Step: 2
Training loss: 0.42545558128753247
Validation loss: 3.144773940678403

Epoch: 6| Step: 3
Training loss: 1.164597049329827
Validation loss: 3.1303984488557086

Epoch: 6| Step: 4
Training loss: 0.7241873527560286
Validation loss: 3.136085329117812

Epoch: 6| Step: 5
Training loss: 0.37540727592321094
Validation loss: 3.132017039387856

Epoch: 6| Step: 6
Training loss: 1.0018068322058202
Validation loss: 3.2015877671343906

Epoch: 6| Step: 7
Training loss: 0.5045250338835686
Validation loss: 3.245297159383065

Epoch: 6| Step: 8
Training loss: 0.5562126254266353
Validation loss: 3.201136423022879

Epoch: 6| Step: 9
Training loss: 0.5564108391015217
Validation loss: 3.2933166489069112

Epoch: 6| Step: 10
Training loss: 0.5721672676630343
Validation loss: 3.2326663628783434

Epoch: 6| Step: 11
Training loss: 0.4559540729504354
Validation loss: 3.1749797840425984

Epoch: 6| Step: 12
Training loss: 0.47459778948171427
Validation loss: 3.134947090006642

Epoch: 6| Step: 13
Training loss: 0.5192364594903067
Validation loss: 3.1377852144331815

Epoch: 223| Step: 0
Training loss: 0.4751544067738441
Validation loss: 3.0675378869744847

Epoch: 6| Step: 1
Training loss: 0.7112964939414478
Validation loss: 3.118405645059781

Epoch: 6| Step: 2
Training loss: 0.5372664898045425
Validation loss: 3.1525476729287214

Epoch: 6| Step: 3
Training loss: 0.5028101214156426
Validation loss: 3.1457859734681795

Epoch: 6| Step: 4
Training loss: 0.4426457042898879
Validation loss: 3.19207490214247

Epoch: 6| Step: 5
Training loss: 0.8705256709543009
Validation loss: 3.1348579939784

Epoch: 6| Step: 6
Training loss: 0.3004405085661211
Validation loss: 3.125259744657708

Epoch: 6| Step: 7
Training loss: 0.4742099666881841
Validation loss: 3.17201542034546

Epoch: 6| Step: 8
Training loss: 0.4534837355068172
Validation loss: 3.132810115416928

Epoch: 6| Step: 9
Training loss: 1.1979413016177303
Validation loss: 3.1513499127570506

Epoch: 6| Step: 10
Training loss: 0.5396508033526621
Validation loss: 3.075218558362409

Epoch: 6| Step: 11
Training loss: 0.46963604790549707
Validation loss: 3.12084455772456

Epoch: 6| Step: 12
Training loss: 0.5390451953708847
Validation loss: 3.0767890367594632

Epoch: 6| Step: 13
Training loss: 0.426651790900983
Validation loss: 3.1140013356190623

Epoch: 224| Step: 0
Training loss: 1.1536836754280693
Validation loss: 3.0624188911959793

Epoch: 6| Step: 1
Training loss: 0.9572780368790732
Validation loss: 3.067135889672076

Epoch: 6| Step: 2
Training loss: 0.4413886108925047
Validation loss: 3.1919951562852686

Epoch: 6| Step: 3
Training loss: 0.5739468560106862
Validation loss: 3.1584720280841725

Epoch: 6| Step: 4
Training loss: 0.39486287597901126
Validation loss: 3.3048008868498004

Epoch: 6| Step: 5
Training loss: 0.6182995929363774
Validation loss: 3.170410406920584

Epoch: 6| Step: 6
Training loss: 0.4426763036772369
Validation loss: 3.1756751186252634

Epoch: 6| Step: 7
Training loss: 0.43596051336545055
Validation loss: 3.17509197091888

Epoch: 6| Step: 8
Training loss: 0.6246416017999104
Validation loss: 3.0963515058954654

Epoch: 6| Step: 9
Training loss: 0.407219481921217
Validation loss: 3.1638677843249794

Epoch: 6| Step: 10
Training loss: 0.43997981404470726
Validation loss: 3.168745604944034

Epoch: 6| Step: 11
Training loss: 0.49312364771455686
Validation loss: 3.1629056346226694

Epoch: 6| Step: 12
Training loss: 0.48346460063012536
Validation loss: 3.2709675698565377

Epoch: 6| Step: 13
Training loss: 0.7498150438496252
Validation loss: 3.1743986366244688

Epoch: 225| Step: 0
Training loss: 0.6438206772754796
Validation loss: 3.204249871458857

Epoch: 6| Step: 1
Training loss: 0.38366656496058776
Validation loss: 3.1663482572859296

Epoch: 6| Step: 2
Training loss: 0.6411077494793004
Validation loss: 3.1682567159815864

Epoch: 6| Step: 3
Training loss: 0.6475647027595196
Validation loss: 3.1098027661900804

Epoch: 6| Step: 4
Training loss: 0.5070180106528498
Validation loss: 3.207225624850791

Epoch: 6| Step: 5
Training loss: 1.065228716867078
Validation loss: 3.2015509855138724

Epoch: 6| Step: 6
Training loss: 0.8655377409434363
Validation loss: 3.212993461717795

Epoch: 6| Step: 7
Training loss: 0.5467907431953994
Validation loss: 3.2043303912084555

Epoch: 6| Step: 8
Training loss: 0.5570694192058392
Validation loss: 3.138489631468783

Epoch: 6| Step: 9
Training loss: 0.5368802778453106
Validation loss: 3.2100126198295746

Epoch: 6| Step: 10
Training loss: 0.511265240700904
Validation loss: 3.1308362122692457

Epoch: 6| Step: 11
Training loss: 0.5036579673696626
Validation loss: 3.1478501017256786

Epoch: 6| Step: 12
Training loss: 0.350196643492791
Validation loss: 3.1183523935020587

Epoch: 6| Step: 13
Training loss: 0.46762084064708936
Validation loss: 3.17347784525401

Epoch: 226| Step: 0
Training loss: 0.6273279941048194
Validation loss: 3.091937076605253

Epoch: 6| Step: 1
Training loss: 0.34431407986754703
Validation loss: 3.112381266176584

Epoch: 6| Step: 2
Training loss: 0.44021547102598924
Validation loss: 3.1997160969402065

Epoch: 6| Step: 3
Training loss: 0.48838855327314834
Validation loss: 3.1660091361642775

Epoch: 6| Step: 4
Training loss: 1.1486983749030124
Validation loss: 3.195814893753058

Epoch: 6| Step: 5
Training loss: 0.5156223123653766
Validation loss: 3.12490540679181

Epoch: 6| Step: 6
Training loss: 0.661101392622003
Validation loss: 3.1708483733640493

Epoch: 6| Step: 7
Training loss: 0.4087726143172034
Validation loss: 3.075551230172452

Epoch: 6| Step: 8
Training loss: 0.36481088167595915
Validation loss: 3.1640972998946286

Epoch: 6| Step: 9
Training loss: 0.5720466481240887
Validation loss: 3.163956352305774

Epoch: 6| Step: 10
Training loss: 0.47331998266725067
Validation loss: 3.153218831335042

Epoch: 6| Step: 11
Training loss: 0.9927939116239024
Validation loss: 3.057191204822797

Epoch: 6| Step: 12
Training loss: 0.47435408268423396
Validation loss: 3.165990033557151

Epoch: 6| Step: 13
Training loss: 0.47503893843213885
Validation loss: 3.1998659503198374

Epoch: 227| Step: 0
Training loss: 0.6216643968835598
Validation loss: 3.251464342685456

Epoch: 6| Step: 1
Training loss: 0.38861296317501676
Validation loss: 3.294035461621697

Epoch: 6| Step: 2
Training loss: 0.41915422401515934
Validation loss: 3.2500191467894908

Epoch: 6| Step: 3
Training loss: 0.36363453248224004
Validation loss: 3.2391667031681606

Epoch: 6| Step: 4
Training loss: 0.46763057557967697
Validation loss: 3.1575465293389726

Epoch: 6| Step: 5
Training loss: 0.42187696032598476
Validation loss: 3.173024900865073

Epoch: 6| Step: 6
Training loss: 0.6369226047442531
Validation loss: 3.2174642642985116

Epoch: 6| Step: 7
Training loss: 0.5940559753268356
Validation loss: 3.276557982754993

Epoch: 6| Step: 8
Training loss: 0.4881653915280955
Validation loss: 3.2698240525042515

Epoch: 6| Step: 9
Training loss: 0.8374310280027139
Validation loss: 3.3252887848998243

Epoch: 6| Step: 10
Training loss: 0.6041196497895941
Validation loss: 3.257486694535167

Epoch: 6| Step: 11
Training loss: 0.5965517097244656
Validation loss: 3.326279105912444

Epoch: 6| Step: 12
Training loss: 1.1052988953059157
Validation loss: 3.2429176948392486

Epoch: 6| Step: 13
Training loss: 0.5045966807751797
Validation loss: 3.2657593816580444

Epoch: 228| Step: 0
Training loss: 0.558477909908042
Validation loss: 3.138477116041352

Epoch: 6| Step: 1
Training loss: 0.5938408430775399
Validation loss: 3.1799607468027746

Epoch: 6| Step: 2
Training loss: 1.1614355361594249
Validation loss: 3.131503369910969

Epoch: 6| Step: 3
Training loss: 0.430485089194476
Validation loss: 3.051744453095759

Epoch: 6| Step: 4
Training loss: 0.7880907023119202
Validation loss: 3.0734047238118642

Epoch: 6| Step: 5
Training loss: 0.4118510697783349
Validation loss: 3.2662074590210253

Epoch: 6| Step: 6
Training loss: 0.7318266624431019
Validation loss: 3.3255852215337978

Epoch: 6| Step: 7
Training loss: 0.5654244167365521
Validation loss: 3.187585430621041

Epoch: 6| Step: 8
Training loss: 0.36948070301388586
Validation loss: 3.246886069823833

Epoch: 6| Step: 9
Training loss: 0.5486134825492929
Validation loss: 3.1791905695132052

Epoch: 6| Step: 10
Training loss: 1.1406522773720944
Validation loss: 3.1131488001276857

Epoch: 6| Step: 11
Training loss: 0.5428641788037459
Validation loss: 3.09864694436024

Epoch: 6| Step: 12
Training loss: 0.4311054415913096
Validation loss: 3.1189051128947427

Epoch: 6| Step: 13
Training loss: 0.3835707764437339
Validation loss: 3.107375852130935

Epoch: 229| Step: 0
Training loss: 1.043594515520761
Validation loss: 3.255953763933437

Epoch: 6| Step: 1
Training loss: 1.0326147585588277
Validation loss: 3.326530492463465

Epoch: 6| Step: 2
Training loss: 0.6110140935393079
Validation loss: 3.3321097909928703

Epoch: 6| Step: 3
Training loss: 0.5831482173472137
Validation loss: 3.2288268782161373

Epoch: 6| Step: 4
Training loss: 0.5962193987848993
Validation loss: 3.177906259156504

Epoch: 6| Step: 5
Training loss: 0.7402660594590832
Validation loss: 3.1914962450814475

Epoch: 6| Step: 6
Training loss: 0.5337987235207301
Validation loss: 3.1349107370034464

Epoch: 6| Step: 7
Training loss: 0.5824419914880473
Validation loss: 3.220875300733997

Epoch: 6| Step: 8
Training loss: 0.5466929541446919
Validation loss: 3.1986244279970086

Epoch: 6| Step: 9
Training loss: 0.5294137241562566
Validation loss: 3.176523645016072

Epoch: 6| Step: 10
Training loss: 0.42729795304684565
Validation loss: 3.237679824842685

Epoch: 6| Step: 11
Training loss: 0.5279354590503743
Validation loss: 3.2015563721518254

Epoch: 6| Step: 12
Training loss: 0.37285527206981456
Validation loss: 3.1411667415070847

Epoch: 6| Step: 13
Training loss: 0.6000480414071965
Validation loss: 3.19787238936365

Epoch: 230| Step: 0
Training loss: 0.9665541527206062
Validation loss: 3.2067854892052354

Epoch: 6| Step: 1
Training loss: 0.6113803341542563
Validation loss: 3.1551572210975083

Epoch: 6| Step: 2
Training loss: 0.6524899712884394
Validation loss: 3.231173049925437

Epoch: 6| Step: 3
Training loss: 0.3513179988474848
Validation loss: 3.134124176851727

Epoch: 6| Step: 4
Training loss: 0.33888151155039126
Validation loss: 3.2030791612772243

Epoch: 6| Step: 5
Training loss: 0.4502417153629372
Validation loss: 3.2178722777403097

Epoch: 6| Step: 6
Training loss: 0.4441808744392374
Validation loss: 3.1305700252897712

Epoch: 6| Step: 7
Training loss: 0.32984969456753793
Validation loss: 3.198025833072463

Epoch: 6| Step: 8
Training loss: 0.48518334895083903
Validation loss: 3.1252290006019092

Epoch: 6| Step: 9
Training loss: 0.45446929808429287
Validation loss: 3.070548180358722

Epoch: 6| Step: 10
Training loss: 0.5013525371840745
Validation loss: 3.1584577990509586

Epoch: 6| Step: 11
Training loss: 0.29660152086136815
Validation loss: 3.1479319757425483

Epoch: 6| Step: 12
Training loss: 1.127803435422641
Validation loss: 3.082187585769771

Epoch: 6| Step: 13
Training loss: 0.3686805360637222
Validation loss: 3.1549237804405355

Epoch: 231| Step: 0
Training loss: 0.9251790079681732
Validation loss: 3.2148041102768614

Epoch: 6| Step: 1
Training loss: 0.3245438703600199
Validation loss: 3.204215023997038

Epoch: 6| Step: 2
Training loss: 0.44662476315773664
Validation loss: 3.2087487327534543

Epoch: 6| Step: 3
Training loss: 0.569434940897199
Validation loss: 3.226985925165183

Epoch: 6| Step: 4
Training loss: 0.4678616370907727
Validation loss: 3.148891192263157

Epoch: 6| Step: 5
Training loss: 0.38087572894075133
Validation loss: 3.1891026675186565

Epoch: 6| Step: 6
Training loss: 0.37924851365574547
Validation loss: 3.171769928092309

Epoch: 6| Step: 7
Training loss: 0.5078015252908138
Validation loss: 3.0886381669217537

Epoch: 6| Step: 8
Training loss: 0.5567011750065124
Validation loss: 3.248207698471711

Epoch: 6| Step: 9
Training loss: 0.4552670033645437
Validation loss: 3.1154745011375655

Epoch: 6| Step: 10
Training loss: 1.0217887468712537
Validation loss: 3.1861288574782867

Epoch: 6| Step: 11
Training loss: 0.5162315846592365
Validation loss: 3.212778125405029

Epoch: 6| Step: 12
Training loss: 0.6377806438469519
Validation loss: 3.3168967715111246

Epoch: 6| Step: 13
Training loss: 0.46647933310699025
Validation loss: 3.1906483379410915

Epoch: 232| Step: 0
Training loss: 0.4841163621541121
Validation loss: 3.1734902789937323

Epoch: 6| Step: 1
Training loss: 0.547537429697188
Validation loss: 3.237558245042885

Epoch: 6| Step: 2
Training loss: 0.4045267971673383
Validation loss: 3.1971964734459575

Epoch: 6| Step: 3
Training loss: 0.407826884516614
Validation loss: 3.1491627958148936

Epoch: 6| Step: 4
Training loss: 0.5432260576002539
Validation loss: 3.1108737189873925

Epoch: 6| Step: 5
Training loss: 1.0813059665550242
Validation loss: 3.1101643057307378

Epoch: 6| Step: 6
Training loss: 0.38274102614215033
Validation loss: 3.1957476505363513

Epoch: 6| Step: 7
Training loss: 0.35864999450535745
Validation loss: 3.1722901171314324

Epoch: 6| Step: 8
Training loss: 0.41172586467466127
Validation loss: 3.2280066262594325

Epoch: 6| Step: 9
Training loss: 0.41951817469049557
Validation loss: 3.165940042417579

Epoch: 6| Step: 10
Training loss: 0.3676307924262432
Validation loss: 3.1922865065701584

Epoch: 6| Step: 11
Training loss: 0.3856221458910608
Validation loss: 3.1397468389315026

Epoch: 6| Step: 12
Training loss: 0.8313817099147172
Validation loss: 3.129362392949961

Epoch: 6| Step: 13
Training loss: 0.5829696770596501
Validation loss: 3.1735481396935503

Epoch: 233| Step: 0
Training loss: 0.4695605264127422
Validation loss: 3.202489699963323

Epoch: 6| Step: 1
Training loss: 0.4575912598490913
Validation loss: 3.1230151930508776

Epoch: 6| Step: 2
Training loss: 0.31539473915771227
Validation loss: 3.1412851326239353

Epoch: 6| Step: 3
Training loss: 0.6128405791857077
Validation loss: 3.112073663316961

Epoch: 6| Step: 4
Training loss: 0.435401259230316
Validation loss: 3.0494694675689833

Epoch: 6| Step: 5
Training loss: 0.7955908432526113
Validation loss: 3.0729599814945234

Epoch: 6| Step: 6
Training loss: 0.3524559853007273
Validation loss: 3.127711238928763

Epoch: 6| Step: 7
Training loss: 0.5285036118094347
Validation loss: 3.164529635635326

Epoch: 6| Step: 8
Training loss: 0.3156144395326809
Validation loss: 3.1108796586120477

Epoch: 6| Step: 9
Training loss: 0.4688613123653963
Validation loss: 3.1010529350167437

Epoch: 6| Step: 10
Training loss: 0.42323310676835635
Validation loss: 3.224715522422304

Epoch: 6| Step: 11
Training loss: 0.5586465663882578
Validation loss: 3.0926104543702664

Epoch: 6| Step: 12
Training loss: 0.40409049696081606
Validation loss: 3.1466513490169357

Epoch: 6| Step: 13
Training loss: 1.0709739924175061
Validation loss: 3.162504237879551

Epoch: 234| Step: 0
Training loss: 0.6333903276581258
Validation loss: 3.134893587061659

Epoch: 6| Step: 1
Training loss: 0.9861122726081372
Validation loss: 3.111218364509272

Epoch: 6| Step: 2
Training loss: 0.5332072610659752
Validation loss: 3.1890216262194144

Epoch: 6| Step: 3
Training loss: 0.5101711954495097
Validation loss: 3.16310887663578

Epoch: 6| Step: 4
Training loss: 0.5312662122160039
Validation loss: 3.1613420887188584

Epoch: 6| Step: 5
Training loss: 0.39377150703911956
Validation loss: 3.129635475451268

Epoch: 6| Step: 6
Training loss: 0.3930727371748501
Validation loss: 3.1188505193479776

Epoch: 6| Step: 7
Training loss: 0.45950928561299775
Validation loss: 3.1635609672760676

Epoch: 6| Step: 8
Training loss: 0.5374943688563413
Validation loss: 3.1594260322632484

Epoch: 6| Step: 9
Training loss: 0.5728840789774681
Validation loss: 3.0850401269744157

Epoch: 6| Step: 10
Training loss: 0.48914468336775085
Validation loss: 3.2171106577276354

Epoch: 6| Step: 11
Training loss: 0.4405438260458132
Validation loss: 3.182009262482281

Epoch: 6| Step: 12
Training loss: 0.8141006329001556
Validation loss: 3.12703230577109

Epoch: 6| Step: 13
Training loss: 0.37606285393045086
Validation loss: 3.211885150003364

Epoch: 235| Step: 0
Training loss: 0.6037952553036074
Validation loss: 3.141828606847758

Epoch: 6| Step: 1
Training loss: 0.6114742604076252
Validation loss: 3.1701657931377074

Epoch: 6| Step: 2
Training loss: 0.3611543392121937
Validation loss: 3.2016783882441526

Epoch: 6| Step: 3
Training loss: 0.5925285424226501
Validation loss: 3.1833271562473087

Epoch: 6| Step: 4
Training loss: 0.4025961260303162
Validation loss: 3.148774942216246

Epoch: 6| Step: 5
Training loss: 0.4234041299374813
Validation loss: 3.2109738090299977

Epoch: 6| Step: 6
Training loss: 0.44861926007259156
Validation loss: 3.223376976106958

Epoch: 6| Step: 7
Training loss: 0.3866230624718006
Validation loss: 3.209492181002499

Epoch: 6| Step: 8
Training loss: 0.38706782990907856
Validation loss: 3.2107868515030886

Epoch: 6| Step: 9
Training loss: 1.0348572497125943
Validation loss: 3.2220901146111993

Epoch: 6| Step: 10
Training loss: 0.7434488921156506
Validation loss: 3.267202747564191

Epoch: 6| Step: 11
Training loss: 0.35453117303355675
Validation loss: 3.149006049959491

Epoch: 6| Step: 12
Training loss: 0.84486520324075
Validation loss: 3.132597626557379

Epoch: 6| Step: 13
Training loss: 0.504800904231841
Validation loss: 3.166008307801313

Epoch: 236| Step: 0
Training loss: 0.4698114774407904
Validation loss: 3.2065112319226907

Epoch: 6| Step: 1
Training loss: 0.42008567986302464
Validation loss: 3.208597065047923

Epoch: 6| Step: 2
Training loss: 0.48840165751735976
Validation loss: 3.187079445514925

Epoch: 6| Step: 3
Training loss: 0.6377840783582038
Validation loss: 3.092102189932873

Epoch: 6| Step: 4
Training loss: 0.45029028099778495
Validation loss: 3.170176372234519

Epoch: 6| Step: 5
Training loss: 0.8296674363176274
Validation loss: 3.2440073566596377

Epoch: 6| Step: 6
Training loss: 1.0368673900764176
Validation loss: 3.2917334553827735

Epoch: 6| Step: 7
Training loss: 0.6472568564318879
Validation loss: 3.287585279376363

Epoch: 6| Step: 8
Training loss: 0.7126949093901941
Validation loss: 3.2288759572420016

Epoch: 6| Step: 9
Training loss: 0.351779976442527
Validation loss: 3.2137634266776005

Epoch: 6| Step: 10
Training loss: 0.6163910180979055
Validation loss: 3.1129762124372937

Epoch: 6| Step: 11
Training loss: 0.6238972472112855
Validation loss: 3.1984661305383377

Epoch: 6| Step: 12
Training loss: 0.6058115819185967
Validation loss: 3.0387193605402243

Epoch: 6| Step: 13
Training loss: 0.35626370754974873
Validation loss: 3.1385211635409025

Epoch: 237| Step: 0
Training loss: 0.4464638031953624
Validation loss: 3.142991826858275

Epoch: 6| Step: 1
Training loss: 0.4153831940151822
Validation loss: 3.1372133453345183

Epoch: 6| Step: 2
Training loss: 0.4606275971441667
Validation loss: 3.230549821678169

Epoch: 6| Step: 3
Training loss: 0.5214392824715193
Validation loss: 3.188916321786727

Epoch: 6| Step: 4
Training loss: 0.396112747037787
Validation loss: 3.2294841528247433

Epoch: 6| Step: 5
Training loss: 1.1707059496799996
Validation loss: 3.1413428148937212

Epoch: 6| Step: 6
Training loss: 0.4599271466261027
Validation loss: 3.1509606637342578

Epoch: 6| Step: 7
Training loss: 0.4868629609310167
Validation loss: 3.1428932488728965

Epoch: 6| Step: 8
Training loss: 0.431082455251023
Validation loss: 3.1280862445698006

Epoch: 6| Step: 9
Training loss: 0.47708250035986444
Validation loss: 3.1859916908154213

Epoch: 6| Step: 10
Training loss: 0.5307902422332197
Validation loss: 3.203846076500104

Epoch: 6| Step: 11
Training loss: 0.3820600315477907
Validation loss: 3.189486713470056

Epoch: 6| Step: 12
Training loss: 0.5526296833222129
Validation loss: 3.1919413148788327

Epoch: 6| Step: 13
Training loss: 0.9023739367963745
Validation loss: 3.1135224648159316

Epoch: 238| Step: 0
Training loss: 0.3793705327558116
Validation loss: 3.225547304460087

Epoch: 6| Step: 1
Training loss: 0.41376313597810416
Validation loss: 3.189903039106416

Epoch: 6| Step: 2
Training loss: 0.4602375211334576
Validation loss: 3.1279374240728353

Epoch: 6| Step: 3
Training loss: 0.4568807403005538
Validation loss: 3.1199762271725318

Epoch: 6| Step: 4
Training loss: 0.425024813039898
Validation loss: 3.1024737168601746

Epoch: 6| Step: 5
Training loss: 0.4606522469504172
Validation loss: 3.1861819989308637

Epoch: 6| Step: 6
Training loss: 0.37319823385047657
Validation loss: 3.2952942154486946

Epoch: 6| Step: 7
Training loss: 0.5279943902844755
Validation loss: 3.191859461752331

Epoch: 6| Step: 8
Training loss: 0.5502347196063081
Validation loss: 3.14592160907366

Epoch: 6| Step: 9
Training loss: 0.8448438265338155
Validation loss: 3.244897529422247

Epoch: 6| Step: 10
Training loss: 0.3670850164365485
Validation loss: 3.2462908168180777

Epoch: 6| Step: 11
Training loss: 0.42077259563352687
Validation loss: 3.1459932265583643

Epoch: 6| Step: 12
Training loss: 0.98877498672299
Validation loss: 3.179126674422224

Epoch: 6| Step: 13
Training loss: 0.4350864559889102
Validation loss: 3.2310870869221624

Epoch: 239| Step: 0
Training loss: 0.419500663111166
Validation loss: 3.2298455211833916

Epoch: 6| Step: 1
Training loss: 0.3189825733516059
Validation loss: 3.133319081280808

Epoch: 6| Step: 2
Training loss: 0.5545635622208472
Validation loss: 3.1507260671572968

Epoch: 6| Step: 3
Training loss: 0.43152767101623885
Validation loss: 3.184115439266382

Epoch: 6| Step: 4
Training loss: 0.5317452870757775
Validation loss: 3.1477478256405917

Epoch: 6| Step: 5
Training loss: 0.555514243364782
Validation loss: 3.2433914461709192

Epoch: 6| Step: 6
Training loss: 0.5079695532096302
Validation loss: 3.160529052975812

Epoch: 6| Step: 7
Training loss: 0.48520403333368917
Validation loss: 3.274847147434589

Epoch: 6| Step: 8
Training loss: 0.5096998501140336
Validation loss: 3.223166130651192

Epoch: 6| Step: 9
Training loss: 0.36596390593890266
Validation loss: 3.166594019274024

Epoch: 6| Step: 10
Training loss: 1.0542567751121512
Validation loss: 3.1758800333260226

Epoch: 6| Step: 11
Training loss: 0.9535124882228816
Validation loss: 3.2528726402311

Epoch: 6| Step: 12
Training loss: 0.425156476161999
Validation loss: 3.190254865966447

Epoch: 6| Step: 13
Training loss: 0.2666102676926628
Validation loss: 3.1150731793416355

Epoch: 240| Step: 0
Training loss: 0.41752137100892933
Validation loss: 3.1890734983706555

Epoch: 6| Step: 1
Training loss: 0.41281443662571793
Validation loss: 3.1831450538145867

Epoch: 6| Step: 2
Training loss: 0.46893440434083467
Validation loss: 3.292758993796729

Epoch: 6| Step: 3
Training loss: 0.42516516813873706
Validation loss: 3.213344961583267

Epoch: 6| Step: 4
Training loss: 0.4710889161274708
Validation loss: 3.100178894398116

Epoch: 6| Step: 5
Training loss: 0.4537836089705028
Validation loss: 3.1512369310813417

Epoch: 6| Step: 6
Training loss: 0.420915590011986
Validation loss: 3.190307066816233

Epoch: 6| Step: 7
Training loss: 0.4356358185003543
Validation loss: 3.183863304287735

Epoch: 6| Step: 8
Training loss: 0.3400493416500632
Validation loss: 3.224402344201933

Epoch: 6| Step: 9
Training loss: 0.7554328365527572
Validation loss: 3.194507139853042

Epoch: 6| Step: 10
Training loss: 0.5927526228390975
Validation loss: 3.181765415530271

Epoch: 6| Step: 11
Training loss: 0.8431639578763761
Validation loss: 3.175219909681573

Epoch: 6| Step: 12
Training loss: 1.055896489954903
Validation loss: 3.195889371921919

Epoch: 6| Step: 13
Training loss: 0.6616785679026332
Validation loss: 3.1922001063390004

Epoch: 241| Step: 0
Training loss: 0.3726406182103538
Validation loss: 3.123191488200911

Epoch: 6| Step: 1
Training loss: 0.4887554764989585
Validation loss: 3.2156014335616474

Epoch: 6| Step: 2
Training loss: 0.469270576056418
Validation loss: 3.270181084653599

Epoch: 6| Step: 3
Training loss: 0.567676146641838
Validation loss: 3.1928431289038572

Epoch: 6| Step: 4
Training loss: 0.5009805482107228
Validation loss: 3.2877944229432012

Epoch: 6| Step: 5
Training loss: 0.5418896827336481
Validation loss: 3.257892659494815

Epoch: 6| Step: 6
Training loss: 0.3507467342124071
Validation loss: 3.1960893477872143

Epoch: 6| Step: 7
Training loss: 0.43583207992144934
Validation loss: 3.1810247685030677

Epoch: 6| Step: 8
Training loss: 0.5247530844744517
Validation loss: 3.1515290106760965

Epoch: 6| Step: 9
Training loss: 0.5859481301932861
Validation loss: 3.12779277621374

Epoch: 6| Step: 10
Training loss: 0.9405508309965623
Validation loss: 3.210570203776279

Epoch: 6| Step: 11
Training loss: 0.5023439422179903
Validation loss: 3.113561192478194

Epoch: 6| Step: 12
Training loss: 0.9745730162051752
Validation loss: 3.238450902184528

Epoch: 6| Step: 13
Training loss: 0.4733078303764737
Validation loss: 3.2924264843727005

Epoch: 242| Step: 0
Training loss: 0.7893934783222536
Validation loss: 3.3364258765290367

Epoch: 6| Step: 1
Training loss: 0.6228326171979427
Validation loss: 3.3373765663057475

Epoch: 6| Step: 2
Training loss: 0.85475742256309
Validation loss: 3.180047991888313

Epoch: 6| Step: 3
Training loss: 0.46146779348465833
Validation loss: 3.156393091968007

Epoch: 6| Step: 4
Training loss: 0.5143283376931147
Validation loss: 3.0912937213558225

Epoch: 6| Step: 5
Training loss: 0.7336191386256641
Validation loss: 3.163016742209725

Epoch: 6| Step: 6
Training loss: 0.5541560891463708
Validation loss: 3.1098715355355733

Epoch: 6| Step: 7
Training loss: 0.40486107495073115
Validation loss: 3.081516082602862

Epoch: 6| Step: 8
Training loss: 0.3933113235475436
Validation loss: 3.154263037784517

Epoch: 6| Step: 9
Training loss: 0.5272022481324101
Validation loss: 3.224121475816683

Epoch: 6| Step: 10
Training loss: 0.4963885505217699
Validation loss: 3.2518269221319698

Epoch: 6| Step: 11
Training loss: 0.7169200573092059
Validation loss: 3.2270408688323386

Epoch: 6| Step: 12
Training loss: 0.332022520960338
Validation loss: 3.245125244693892

Epoch: 6| Step: 13
Training loss: 1.0198961094699492
Validation loss: 3.15344753424195

Epoch: 243| Step: 0
Training loss: 0.5471646223182068
Validation loss: 3.1284564675628186

Epoch: 6| Step: 1
Training loss: 0.7883729471156046
Validation loss: 3.086903236673486

Epoch: 6| Step: 2
Training loss: 0.3187925048612352
Validation loss: 3.1099424116030097

Epoch: 6| Step: 3
Training loss: 0.3812954484709439
Validation loss: 3.180496962579985

Epoch: 6| Step: 4
Training loss: 0.8493569887116821
Validation loss: 3.2137120148669074

Epoch: 6| Step: 5
Training loss: 0.46170019638556387
Validation loss: 3.2225565453720937

Epoch: 6| Step: 6
Training loss: 0.5459001571819263
Validation loss: 3.252166747140037

Epoch: 6| Step: 7
Training loss: 0.4134185389916108
Validation loss: 3.253832599100975

Epoch: 6| Step: 8
Training loss: 0.9411748071350796
Validation loss: 3.2787697152308413

Epoch: 6| Step: 9
Training loss: 0.4732115612440005
Validation loss: 3.1313861698026897

Epoch: 6| Step: 10
Training loss: 0.3386769269062659
Validation loss: 3.16002136370121

Epoch: 6| Step: 11
Training loss: 0.49180512485750427
Validation loss: 3.167956043724358

Epoch: 6| Step: 12
Training loss: 0.335894648458149
Validation loss: 3.122930502696537

Epoch: 6| Step: 13
Training loss: 0.4783279362262175
Validation loss: 3.1731420532513677

Epoch: 244| Step: 0
Training loss: 0.8439896914205117
Validation loss: 3.1896567808166743

Epoch: 6| Step: 1
Training loss: 0.6756343351102101
Validation loss: 3.2300230469880384

Epoch: 6| Step: 2
Training loss: 0.5974802742977985
Validation loss: 3.304177174946325

Epoch: 6| Step: 3
Training loss: 0.4345454691097098
Validation loss: 3.2219440019916408

Epoch: 6| Step: 4
Training loss: 0.2779381520851469
Validation loss: 3.1545636169585998

Epoch: 6| Step: 5
Training loss: 1.0385606744239062
Validation loss: 3.1334575645357536

Epoch: 6| Step: 6
Training loss: 0.40083807157635787
Validation loss: 3.230134564619109

Epoch: 6| Step: 7
Training loss: 0.635344138983047
Validation loss: 3.182274967697125

Epoch: 6| Step: 8
Training loss: 0.28046277924454177
Validation loss: 3.1577656572086785

Epoch: 6| Step: 9
Training loss: 0.4656927705895799
Validation loss: 3.1918247031053566

Epoch: 6| Step: 10
Training loss: 0.4644367616175548
Validation loss: 3.2643827299225787

Epoch: 6| Step: 11
Training loss: 0.4923820716522466
Validation loss: 3.3009541904506974

Epoch: 6| Step: 12
Training loss: 0.4911967099140924
Validation loss: 3.198535714305543

Epoch: 6| Step: 13
Training loss: 0.6034654516209266
Validation loss: 3.233284562192053

Epoch: 245| Step: 0
Training loss: 0.5431255141717828
Validation loss: 3.2063736731241566

Epoch: 6| Step: 1
Training loss: 0.6619711087324454
Validation loss: 3.1984878220518405

Epoch: 6| Step: 2
Training loss: 0.5258377044886993
Validation loss: 3.137789849397524

Epoch: 6| Step: 3
Training loss: 0.3058355782558118
Validation loss: 3.196380710268857

Epoch: 6| Step: 4
Training loss: 1.011217029727213
Validation loss: 3.2167660052191196

Epoch: 6| Step: 5
Training loss: 0.39456002914160215
Validation loss: 3.268605601401712

Epoch: 6| Step: 6
Training loss: 0.9074009131359931
Validation loss: 3.3194164667763837

Epoch: 6| Step: 7
Training loss: 0.36494954880758257
Validation loss: 3.186194058836719

Epoch: 6| Step: 8
Training loss: 0.5041740356516292
Validation loss: 3.2334005512709543

Epoch: 6| Step: 9
Training loss: 0.37533488817482963
Validation loss: 3.1483671245171774

Epoch: 6| Step: 10
Training loss: 0.4655242234820271
Validation loss: 3.2224016678562415

Epoch: 6| Step: 11
Training loss: 0.9080644399110367
Validation loss: 3.165012559207949

Epoch: 6| Step: 12
Training loss: 0.5468314289719475
Validation loss: 3.1292255316495887

Epoch: 6| Step: 13
Training loss: 0.39403706939705685
Validation loss: 3.1594194921623893

Epoch: 246| Step: 0
Training loss: 0.9783913539164464
Validation loss: 3.147460457753157

Epoch: 6| Step: 1
Training loss: 0.6545590459039868
Validation loss: 3.204294031701444

Epoch: 6| Step: 2
Training loss: 0.5528697734295066
Validation loss: 3.2184617984470703

Epoch: 6| Step: 3
Training loss: 0.4559961644919026
Validation loss: 3.2102875063240828

Epoch: 6| Step: 4
Training loss: 0.8883539658226525
Validation loss: 3.1075092513585294

Epoch: 6| Step: 5
Training loss: 0.4054056526437856
Validation loss: 3.1232925836869336

Epoch: 6| Step: 6
Training loss: 0.4682378514226646
Validation loss: 3.0671097323067498

Epoch: 6| Step: 7
Training loss: 0.4297544600592071
Validation loss: 3.0987500716467538

Epoch: 6| Step: 8
Training loss: 0.4509902852887748
Validation loss: 3.2007737252517305

Epoch: 6| Step: 9
Training loss: 0.3702157928446581
Validation loss: 3.1592899450668868

Epoch: 6| Step: 10
Training loss: 0.48209765578117214
Validation loss: 3.2118260375506775

Epoch: 6| Step: 11
Training loss: 0.5689978405386871
Validation loss: 3.2058533128777382

Epoch: 6| Step: 12
Training loss: 0.42057455040896846
Validation loss: 3.1939280898873696

Epoch: 6| Step: 13
Training loss: 0.5051753895299201
Validation loss: 3.1694893721140396

Epoch: 247| Step: 0
Training loss: 0.3974118401573011
Validation loss: 3.177732124163693

Epoch: 6| Step: 1
Training loss: 0.6077730200333531
Validation loss: 3.182282697016702

Epoch: 6| Step: 2
Training loss: 1.0029125713607627
Validation loss: 3.1178674171476977

Epoch: 6| Step: 3
Training loss: 0.33740288476307134
Validation loss: 3.0991289535269733

Epoch: 6| Step: 4
Training loss: 0.6151276511011357
Validation loss: 3.2060934934534338

Epoch: 6| Step: 5
Training loss: 0.33981623483401174
Validation loss: 3.251890965078622

Epoch: 6| Step: 6
Training loss: 0.4843407434224601
Validation loss: 3.2685950004827746

Epoch: 6| Step: 7
Training loss: 0.8472313936880119
Validation loss: 3.1297842786873944

Epoch: 6| Step: 8
Training loss: 0.46270358656718935
Validation loss: 3.1823415965623645

Epoch: 6| Step: 9
Training loss: 0.45731064822948286
Validation loss: 3.1934656652401876

Epoch: 6| Step: 10
Training loss: 0.3798269510261615
Validation loss: 3.087540042221142

Epoch: 6| Step: 11
Training loss: 0.2752081489682693
Validation loss: 3.209025560154594

Epoch: 6| Step: 12
Training loss: 0.44082493608489737
Validation loss: 3.157383454005008

Epoch: 6| Step: 13
Training loss: 0.4628267203856656
Validation loss: 3.2833684954882405

Epoch: 248| Step: 0
Training loss: 0.33714352961824146
Validation loss: 3.1384236226301585

Epoch: 6| Step: 1
Training loss: 0.31707549255057327
Validation loss: 3.203138472365913

Epoch: 6| Step: 2
Training loss: 0.8414046929503533
Validation loss: 3.215208679474721

Epoch: 6| Step: 3
Training loss: 0.6070870706429663
Validation loss: 3.241445494774558

Epoch: 6| Step: 4
Training loss: 0.3865902619812376
Validation loss: 3.1908099124341462

Epoch: 6| Step: 5
Training loss: 0.5990115736367063
Validation loss: 3.1935168057364787

Epoch: 6| Step: 6
Training loss: 0.5729268391023998
Validation loss: 3.220821960613377

Epoch: 6| Step: 7
Training loss: 0.4458330023696004
Validation loss: 3.1885856948566107

Epoch: 6| Step: 8
Training loss: 0.5776807263621143
Validation loss: 3.104398492609402

Epoch: 6| Step: 9
Training loss: 0.44492678082769865
Validation loss: 3.233421295647458

Epoch: 6| Step: 10
Training loss: 0.46412844077020754
Validation loss: 3.142265448100574

Epoch: 6| Step: 11
Training loss: 0.3200029296107597
Validation loss: 3.162148066804891

Epoch: 6| Step: 12
Training loss: 0.943212146208761
Validation loss: 3.1236726612227175

Epoch: 6| Step: 13
Training loss: 0.47270129911261566
Validation loss: 3.208912925056345

Epoch: 249| Step: 0
Training loss: 0.5007163221429787
Validation loss: 3.1688496610981605

Epoch: 6| Step: 1
Training loss: 0.5235648498482424
Validation loss: 3.2367555147686162

Epoch: 6| Step: 2
Training loss: 0.9070674892286483
Validation loss: 3.200595210271397

Epoch: 6| Step: 3
Training loss: 0.27064484523488774
Validation loss: 3.1571486298570584

Epoch: 6| Step: 4
Training loss: 0.5381547776511045
Validation loss: 3.2190756154710503

Epoch: 6| Step: 5
Training loss: 0.49689742943384224
Validation loss: 3.220382893505693

Epoch: 6| Step: 6
Training loss: 0.48449880801980355
Validation loss: 3.2699272860842767

Epoch: 6| Step: 7
Training loss: 0.4461566887329877
Validation loss: 3.1562510827191703

Epoch: 6| Step: 8
Training loss: 0.5811416176274221
Validation loss: 3.1965253124733546

Epoch: 6| Step: 9
Training loss: 0.3945111184602151
Validation loss: 3.2456766251492906

Epoch: 6| Step: 10
Training loss: 0.4095030715312509
Validation loss: 3.2163641769280256

Epoch: 6| Step: 11
Training loss: 0.903939689472688
Validation loss: 3.2521657513363835

Epoch: 6| Step: 12
Training loss: 0.37943286284803746
Validation loss: 3.1732934996431585

Epoch: 6| Step: 13
Training loss: 0.43217024955607963
Validation loss: 3.179286797196587

Epoch: 250| Step: 0
Training loss: 0.29874905306773764
Validation loss: 3.130633743668923

Epoch: 6| Step: 1
Training loss: 0.3859404428655572
Validation loss: 3.1812881327543914

Epoch: 6| Step: 2
Training loss: 0.8693702994355977
Validation loss: 3.228728053340444

Epoch: 6| Step: 3
Training loss: 0.3446153672137754
Validation loss: 3.1608833196462163

Epoch: 6| Step: 4
Training loss: 0.7355324166893149
Validation loss: 3.26241204056731

Epoch: 6| Step: 5
Training loss: 0.4727995789168592
Validation loss: 3.1802178142933983

Epoch: 6| Step: 6
Training loss: 0.5511406341501688
Validation loss: 3.300481634442494

Epoch: 6| Step: 7
Training loss: 0.3737649647003729
Validation loss: 3.2023260345179914

Epoch: 6| Step: 8
Training loss: 0.4540752116115392
Validation loss: 3.2254856212206575

Epoch: 6| Step: 9
Training loss: 0.4962927952145267
Validation loss: 3.1631970261917903

Epoch: 6| Step: 10
Training loss: 0.28193843878351055
Validation loss: 3.2176471042868933

Epoch: 6| Step: 11
Training loss: 0.3506389142231794
Validation loss: 3.2585411812002065

Epoch: 6| Step: 12
Training loss: 0.4238710161998914
Validation loss: 3.206247027063014

Epoch: 6| Step: 13
Training loss: 0.4132696153701291
Validation loss: 3.2484287229428257

Epoch: 251| Step: 0
Training loss: 0.4253474484224648
Validation loss: 3.2422693326496597

Epoch: 6| Step: 1
Training loss: 0.39798231864836164
Validation loss: 3.1758755790712025

Epoch: 6| Step: 2
Training loss: 0.4320172699085678
Validation loss: 3.227126274701543

Epoch: 6| Step: 3
Training loss: 0.5569714817762842
Validation loss: 3.2135725138382636

Epoch: 6| Step: 4
Training loss: 0.7836486234306357
Validation loss: 3.1783556073999746

Epoch: 6| Step: 5
Training loss: 0.4821833279442169
Validation loss: 3.160103601395134

Epoch: 6| Step: 6
Training loss: 0.486056792161078
Validation loss: 3.0949945098096956

Epoch: 6| Step: 7
Training loss: 0.52233485902094
Validation loss: 3.265201887983837

Epoch: 6| Step: 8
Training loss: 0.5783309827320726
Validation loss: 3.1768197789340746

Epoch: 6| Step: 9
Training loss: 0.3565015983559088
Validation loss: 3.2609247090104487

Epoch: 6| Step: 10
Training loss: 0.3943122218021144
Validation loss: 3.152627811608956

Epoch: 6| Step: 11
Training loss: 0.5131481096683561
Validation loss: 3.1190646581728627

Epoch: 6| Step: 12
Training loss: 0.2527881653512158
Validation loss: 3.228573299568975

Epoch: 6| Step: 13
Training loss: 0.9836722393397264
Validation loss: 3.296712090925334

Epoch: 252| Step: 0
Training loss: 0.4339499170613795
Validation loss: 3.222317801534148

Epoch: 6| Step: 1
Training loss: 1.0029746159757724
Validation loss: 3.2312971818776233

Epoch: 6| Step: 2
Training loss: 0.3117265188831341
Validation loss: 3.283462529295041

Epoch: 6| Step: 3
Training loss: 0.4136856091230339
Validation loss: 3.2898117987884588

Epoch: 6| Step: 4
Training loss: 0.4712425243735886
Validation loss: 3.326452405071409

Epoch: 6| Step: 5
Training loss: 0.35114515752434045
Validation loss: 3.188722039626878

Epoch: 6| Step: 6
Training loss: 0.43043937790595205
Validation loss: 3.161536909673944

Epoch: 6| Step: 7
Training loss: 0.5741556093962622
Validation loss: 3.216780149273141

Epoch: 6| Step: 8
Training loss: 0.5066807974342292
Validation loss: 3.170355998405602

Epoch: 6| Step: 9
Training loss: 0.43132086600047875
Validation loss: 3.1636116365933287

Epoch: 6| Step: 10
Training loss: 0.3785705258893358
Validation loss: 3.2251835201595114

Epoch: 6| Step: 11
Training loss: 0.797225164632503
Validation loss: 3.2258282211553584

Epoch: 6| Step: 12
Training loss: 0.2858125762914326
Validation loss: 3.2666263292378255

Epoch: 6| Step: 13
Training loss: 0.4283665031578888
Validation loss: 3.172240463274167

Epoch: 253| Step: 0
Training loss: 0.3778306698275461
Validation loss: 3.2413891893368305

Epoch: 6| Step: 1
Training loss: 0.44045540000817596
Validation loss: 3.182056441200718

Epoch: 6| Step: 2
Training loss: 0.5010438096865732
Validation loss: 3.1375848659876953

Epoch: 6| Step: 3
Training loss: 0.617680413149629
Validation loss: 3.122821417219728

Epoch: 6| Step: 4
Training loss: 0.4531129473694665
Validation loss: 3.208288852994325

Epoch: 6| Step: 5
Training loss: 0.349791346241795
Validation loss: 3.1595825127163693

Epoch: 6| Step: 6
Training loss: 0.3865844608998176
Validation loss: 3.1987919474220656

Epoch: 6| Step: 7
Training loss: 0.9161535944057815
Validation loss: 3.1982313409286496

Epoch: 6| Step: 8
Training loss: 0.5367304904769746
Validation loss: 3.1712716065802096

Epoch: 6| Step: 9
Training loss: 0.40890639471649887
Validation loss: 3.236559144213827

Epoch: 6| Step: 10
Training loss: 0.3729223872479441
Validation loss: 3.2566613863066314

Epoch: 6| Step: 11
Training loss: 0.5041127336307011
Validation loss: 3.193232822535375

Epoch: 6| Step: 12
Training loss: 0.23718657517284278
Validation loss: 3.2614612165495367

Epoch: 6| Step: 13
Training loss: 0.8662508812331524
Validation loss: 3.2015964241272217

Epoch: 254| Step: 0
Training loss: 0.4517745084600628
Validation loss: 3.229116886534563

Epoch: 6| Step: 1
Training loss: 0.4481738667997928
Validation loss: 3.242910980026185

Epoch: 6| Step: 2
Training loss: 0.43167198723136974
Validation loss: 3.2051813611488886

Epoch: 6| Step: 3
Training loss: 0.2777164265645003
Validation loss: 3.2300372437100457

Epoch: 6| Step: 4
Training loss: 0.643302578668631
Validation loss: 3.1148632565931966

Epoch: 6| Step: 5
Training loss: 0.4904565801505159
Validation loss: 3.2120042871159202

Epoch: 6| Step: 6
Training loss: 0.9187556688302505
Validation loss: 3.193084375204305

Epoch: 6| Step: 7
Training loss: 0.6281489438859484
Validation loss: 3.334092474959509

Epoch: 6| Step: 8
Training loss: 0.3935222754371838
Validation loss: 3.329845133188308

Epoch: 6| Step: 9
Training loss: 0.5785491779083854
Validation loss: 3.3790053748142332

Epoch: 6| Step: 10
Training loss: 0.5519453962018458
Validation loss: 3.3136448591165975

Epoch: 6| Step: 11
Training loss: 0.9374427777946792
Validation loss: 3.2974388279228517

Epoch: 6| Step: 12
Training loss: 0.37753527659626124
Validation loss: 3.2131412860522177

Epoch: 6| Step: 13
Training loss: 0.5432936430497578
Validation loss: 3.1931377244527686

Epoch: 255| Step: 0
Training loss: 0.8031898932456565
Validation loss: 3.1671005671194163

Epoch: 6| Step: 1
Training loss: 1.04609246684787
Validation loss: 3.2424826246397527

Epoch: 6| Step: 2
Training loss: 0.5074985413929691
Validation loss: 3.194436796612269

Epoch: 6| Step: 3
Training loss: 0.4468679534249833
Validation loss: 3.2515344665286765

Epoch: 6| Step: 4
Training loss: 0.48451835295320633
Validation loss: 3.337386305797694

Epoch: 6| Step: 5
Training loss: 0.45816652195677143
Validation loss: 3.337636998635386

Epoch: 6| Step: 6
Training loss: 0.45260699029472634
Validation loss: 3.2476957417719814

Epoch: 6| Step: 7
Training loss: 0.4809536541660467
Validation loss: 3.2311289987837077

Epoch: 6| Step: 8
Training loss: 0.44200374033583806
Validation loss: 3.197568064689212

Epoch: 6| Step: 9
Training loss: 0.33521850292331484
Validation loss: 3.1396684850643

Epoch: 6| Step: 10
Training loss: 0.41217810613586653
Validation loss: 3.1822523665095575

Epoch: 6| Step: 11
Training loss: 0.8622565769067495
Validation loss: 3.0881994528520504

Epoch: 6| Step: 12
Training loss: 0.4789264550232892
Validation loss: 3.155391979361903

Epoch: 6| Step: 13
Training loss: 0.4157034907404813
Validation loss: 3.1961615319727383

Epoch: 256| Step: 0
Training loss: 0.47549743142121165
Validation loss: 3.131001812508228

Epoch: 6| Step: 1
Training loss: 0.7640550437516624
Validation loss: 3.153374788127409

Epoch: 6| Step: 2
Training loss: 0.3404613889377276
Validation loss: 3.177078826567575

Epoch: 6| Step: 3
Training loss: 0.34322088875095946
Validation loss: 3.0701022217679816

Epoch: 6| Step: 4
Training loss: 0.32661280267410825
Validation loss: 3.1753264692372354

Epoch: 6| Step: 5
Training loss: 0.5775069980279903
Validation loss: 3.2123348292577236

Epoch: 6| Step: 6
Training loss: 0.9005738773171316
Validation loss: 3.1508751102702286

Epoch: 6| Step: 7
Training loss: 0.5693021734835761
Validation loss: 3.112791743259563

Epoch: 6| Step: 8
Training loss: 0.4291436655244838
Validation loss: 3.1531692804227283

Epoch: 6| Step: 9
Training loss: 0.4208379290427383
Validation loss: 3.129393020211284

Epoch: 6| Step: 10
Training loss: 0.46231624522747894
Validation loss: 3.2340548075795414

Epoch: 6| Step: 11
Training loss: 0.24199321860524012
Validation loss: 3.1766560918652655

Epoch: 6| Step: 12
Training loss: 0.5898674461202806
Validation loss: 3.1629527842145047

Epoch: 6| Step: 13
Training loss: 0.41533436759975073
Validation loss: 3.2239111227708865

Epoch: 257| Step: 0
Training loss: 0.49312067124240005
Validation loss: 3.2011693427289405

Epoch: 6| Step: 1
Training loss: 0.344854995533807
Validation loss: 3.118313961087812

Epoch: 6| Step: 2
Training loss: 0.6794349157238434
Validation loss: 3.1630813270402554

Epoch: 6| Step: 3
Training loss: 0.2186240787475788
Validation loss: 3.171064251291591

Epoch: 6| Step: 4
Training loss: 0.9383206907903389
Validation loss: 3.2645734222462903

Epoch: 6| Step: 5
Training loss: 0.25149331533485975
Validation loss: 3.2738471188388902

Epoch: 6| Step: 6
Training loss: 0.5465898587864395
Validation loss: 3.2345118593509694

Epoch: 6| Step: 7
Training loss: 0.4300654742938166
Validation loss: 3.342744325464058

Epoch: 6| Step: 8
Training loss: 0.8392651716286507
Validation loss: 3.2421095382938088

Epoch: 6| Step: 9
Training loss: 0.2885303108904898
Validation loss: 3.2497149000074397

Epoch: 6| Step: 10
Training loss: 0.43327897476715943
Validation loss: 3.2116762225713806

Epoch: 6| Step: 11
Training loss: 0.5176478788768104
Validation loss: 3.1789143440104164

Epoch: 6| Step: 12
Training loss: 0.3082290377438813
Validation loss: 3.1317670668065416

Epoch: 6| Step: 13
Training loss: 0.4582134509081659
Validation loss: 3.2010050635702467

Epoch: 258| Step: 0
Training loss: 0.3677048386722016
Validation loss: 3.224393816219726

Epoch: 6| Step: 1
Training loss: 0.3813437096541741
Validation loss: 3.20781765959223

Epoch: 6| Step: 2
Training loss: 0.34573116296550244
Validation loss: 3.2825340543880057

Epoch: 6| Step: 3
Training loss: 0.5634221888708212
Validation loss: 3.136526238854946

Epoch: 6| Step: 4
Training loss: 1.0763319280722918
Validation loss: 3.180858099779975

Epoch: 6| Step: 5
Training loss: 0.5015584381034109
Validation loss: 3.184620048620418

Epoch: 6| Step: 6
Training loss: 0.39116166442990546
Validation loss: 3.1859336569879666

Epoch: 6| Step: 7
Training loss: 0.5641379879133215
Validation loss: 3.0762552304554744

Epoch: 6| Step: 8
Training loss: 0.8208091322401991
Validation loss: 3.1558026541269717

Epoch: 6| Step: 9
Training loss: 0.4144650427914165
Validation loss: 3.117569417988731

Epoch: 6| Step: 10
Training loss: 0.44099736475751855
Validation loss: 3.201290976368728

Epoch: 6| Step: 11
Training loss: 0.4335268329842729
Validation loss: 3.279014164740365

Epoch: 6| Step: 12
Training loss: 0.8924621239540454
Validation loss: 3.356902260743923

Epoch: 6| Step: 13
Training loss: 0.8556236928033979
Validation loss: 3.2049048836252414

Epoch: 259| Step: 0
Training loss: 0.3043321591489006
Validation loss: 3.112282906025065

Epoch: 6| Step: 1
Training loss: 0.6078306337608148
Validation loss: 3.074462467341905

Epoch: 6| Step: 2
Training loss: 0.4514724423847728
Validation loss: 3.107282730142546

Epoch: 6| Step: 3
Training loss: 0.4862277681912006
Validation loss: 3.16451999198267

Epoch: 6| Step: 4
Training loss: 0.5399399678540057
Validation loss: 3.0637708090328792

Epoch: 6| Step: 5
Training loss: 0.43760060107400817
Validation loss: 3.201716440526474

Epoch: 6| Step: 6
Training loss: 0.29400708889605476
Validation loss: 3.2686448925812055

Epoch: 6| Step: 7
Training loss: 0.364169378514235
Validation loss: 3.2638080050319025

Epoch: 6| Step: 8
Training loss: 0.4320024035793125
Validation loss: 3.211335725987595

Epoch: 6| Step: 9
Training loss: 0.34022762278744817
Validation loss: 3.229495792638756

Epoch: 6| Step: 10
Training loss: 0.45113739278233506
Validation loss: 3.208576432633308

Epoch: 6| Step: 11
Training loss: 0.9015867352327304
Validation loss: 3.241955165887981

Epoch: 6| Step: 12
Training loss: 0.47696287502911205
Validation loss: 3.1842363266828144

Epoch: 6| Step: 13
Training loss: 0.7933367547060282
Validation loss: 3.260093323555605

Epoch: 260| Step: 0
Training loss: 0.4250007440055618
Validation loss: 3.3398599308209405

Epoch: 6| Step: 1
Training loss: 0.6133486473808074
Validation loss: 3.208156399162298

Epoch: 6| Step: 2
Training loss: 0.3864763058633011
Validation loss: 3.1824193367995357

Epoch: 6| Step: 3
Training loss: 0.31702915147713845
Validation loss: 3.2775473881876356

Epoch: 6| Step: 4
Training loss: 0.4163292432509809
Validation loss: 3.17686609661569

Epoch: 6| Step: 5
Training loss: 0.5234474636666852
Validation loss: 3.2875007068551083

Epoch: 6| Step: 6
Training loss: 0.4584358021315303
Validation loss: 3.1662990498900694

Epoch: 6| Step: 7
Training loss: 0.36363750340407736
Validation loss: 3.2511848588475143

Epoch: 6| Step: 8
Training loss: 0.3517577159146479
Validation loss: 3.217545256100041

Epoch: 6| Step: 9
Training loss: 0.2921091821327603
Validation loss: 3.215491994684206

Epoch: 6| Step: 10
Training loss: 0.9006610720715064
Validation loss: 3.2605114802182946

Epoch: 6| Step: 11
Training loss: 0.7514423567770346
Validation loss: 3.2276078348147665

Epoch: 6| Step: 12
Training loss: 0.33189791077665715
Validation loss: 3.2035041522654137

Epoch: 6| Step: 13
Training loss: 0.3891042480130979
Validation loss: 3.1782548505924653

Epoch: 261| Step: 0
Training loss: 0.7661829102908715
Validation loss: 3.2376245585160315

Epoch: 6| Step: 1
Training loss: 0.35217722025629256
Validation loss: 3.272853292381396

Epoch: 6| Step: 2
Training loss: 0.3274387494897275
Validation loss: 3.18337552623515

Epoch: 6| Step: 3
Training loss: 0.5395244333039306
Validation loss: 3.2153232814753765

Epoch: 6| Step: 4
Training loss: 0.8336990904814179
Validation loss: 3.3180615263560016

Epoch: 6| Step: 5
Training loss: 0.44061436133020365
Validation loss: 3.203778356892241

Epoch: 6| Step: 6
Training loss: 0.5918153564790273
Validation loss: 3.3074805778957725

Epoch: 6| Step: 7
Training loss: 0.445445191540822
Validation loss: 3.2310160765590807

Epoch: 6| Step: 8
Training loss: 0.5272410540013985
Validation loss: 3.175265161950878

Epoch: 6| Step: 9
Training loss: 0.34452654084946915
Validation loss: 3.213131281256619

Epoch: 6| Step: 10
Training loss: 0.37808023455748946
Validation loss: 3.242549008969902

Epoch: 6| Step: 11
Training loss: 0.35806741421257554
Validation loss: 3.2142377910371756

Epoch: 6| Step: 12
Training loss: 0.5013234385776225
Validation loss: 3.1594278182115145

Epoch: 6| Step: 13
Training loss: 0.37019759942749436
Validation loss: 3.139067508787821

Epoch: 262| Step: 0
Training loss: 0.45160330749707805
Validation loss: 3.1747838104415855

Epoch: 6| Step: 1
Training loss: 0.4599579408066112
Validation loss: 3.2024557267324267

Epoch: 6| Step: 2
Training loss: 0.260046957158889
Validation loss: 3.2786857758084484

Epoch: 6| Step: 3
Training loss: 0.7752997972154296
Validation loss: 3.2115496990031267

Epoch: 6| Step: 4
Training loss: 0.4661547342086404
Validation loss: 3.193556124879908

Epoch: 6| Step: 5
Training loss: 0.3798057262198904
Validation loss: 3.1839970058302485

Epoch: 6| Step: 6
Training loss: 0.40984847010440617
Validation loss: 3.2899623917398357

Epoch: 6| Step: 7
Training loss: 0.39815876130420697
Validation loss: 3.1675939373487743

Epoch: 6| Step: 8
Training loss: 0.30592925782444924
Validation loss: 3.14262407489357

Epoch: 6| Step: 9
Training loss: 0.4394803695710471
Validation loss: 3.212958597780215

Epoch: 6| Step: 10
Training loss: 0.40482251923226853
Validation loss: 3.1874718259675765

Epoch: 6| Step: 11
Training loss: 0.29123630732982997
Validation loss: 3.2012290988266106

Epoch: 6| Step: 12
Training loss: 0.4484519716911682
Validation loss: 3.1952742844016364

Epoch: 6| Step: 13
Training loss: 1.0013120507718536
Validation loss: 3.2397536123648942

Epoch: 263| Step: 0
Training loss: 0.33228678126715006
Validation loss: 3.2607451609593863

Epoch: 6| Step: 1
Training loss: 0.3605025473939834
Validation loss: 3.20731559728797

Epoch: 6| Step: 2
Training loss: 0.40400143208344325
Validation loss: 3.2128125213127334

Epoch: 6| Step: 3
Training loss: 0.3545476066208928
Validation loss: 3.2074996476087727

Epoch: 6| Step: 4
Training loss: 0.8502171239107912
Validation loss: 3.144613791699408

Epoch: 6| Step: 5
Training loss: 0.7190786522514622
Validation loss: 3.2325773910498397

Epoch: 6| Step: 6
Training loss: 0.5662529047203088
Validation loss: 3.2182452228864014

Epoch: 6| Step: 7
Training loss: 0.396745060502368
Validation loss: 3.1642625784702187

Epoch: 6| Step: 8
Training loss: 0.4365137086334585
Validation loss: 3.2658233095641287

Epoch: 6| Step: 9
Training loss: 0.45583068443565466
Validation loss: 3.2358202446545055

Epoch: 6| Step: 10
Training loss: 0.5520156123054337
Validation loss: 3.1787447144822814

Epoch: 6| Step: 11
Training loss: 0.34416228192671333
Validation loss: 3.126241259424762

Epoch: 6| Step: 12
Training loss: 0.467722736708925
Validation loss: 3.1285066131120334

Epoch: 6| Step: 13
Training loss: 0.4889614250622808
Validation loss: 3.1103608630813326

Epoch: 264| Step: 0
Training loss: 0.3614953556210925
Validation loss: 3.143895927364097

Epoch: 6| Step: 1
Training loss: 0.5613353115569449
Validation loss: 3.160569511712517

Epoch: 6| Step: 2
Training loss: 0.36685876131268397
Validation loss: 3.1353479084236064

Epoch: 6| Step: 3
Training loss: 0.49249659021523623
Validation loss: 3.2168992780341576

Epoch: 6| Step: 4
Training loss: 0.41102957618643454
Validation loss: 3.2157260306761337

Epoch: 6| Step: 5
Training loss: 0.5109384425909931
Validation loss: 3.2459856819437185

Epoch: 6| Step: 6
Training loss: 0.486096154467265
Validation loss: 3.199659678124636

Epoch: 6| Step: 7
Training loss: 0.503033051470436
Validation loss: 3.0547853081826126

Epoch: 6| Step: 8
Training loss: 0.6160122510277
Validation loss: 3.189734006412929

Epoch: 6| Step: 9
Training loss: 0.5144048472629205
Validation loss: 3.1409113739175005

Epoch: 6| Step: 10
Training loss: 0.40385078846277234
Validation loss: 3.0832355887582645

Epoch: 6| Step: 11
Training loss: 0.41458322063361447
Validation loss: 3.0943902249116757

Epoch: 6| Step: 12
Training loss: 0.5414650492920087
Validation loss: 3.2430938556886417

Epoch: 6| Step: 13
Training loss: 1.2484550942719708
Validation loss: 3.2745936134320366

Epoch: 265| Step: 0
Training loss: 0.5161832042089946
Validation loss: 3.2201012549661066

Epoch: 6| Step: 1
Training loss: 0.33703488381115343
Validation loss: 3.125550628470934

Epoch: 6| Step: 2
Training loss: 0.8774021417985126
Validation loss: 3.1397007330241644

Epoch: 6| Step: 3
Training loss: 0.520462520840375
Validation loss: 3.091069932673702

Epoch: 6| Step: 4
Training loss: 0.494355467881893
Validation loss: 3.1972000155730456

Epoch: 6| Step: 5
Training loss: 0.405731089844102
Validation loss: 3.18199287839101

Epoch: 6| Step: 6
Training loss: 0.4719324796922636
Validation loss: 3.135603095476086

Epoch: 6| Step: 7
Training loss: 0.4875059457563065
Validation loss: 3.191866246615985

Epoch: 6| Step: 8
Training loss: 0.287530175470617
Validation loss: 3.2170694155063235

Epoch: 6| Step: 9
Training loss: 0.4014705329998548
Validation loss: 3.2162795725002926

Epoch: 6| Step: 10
Training loss: 0.4620902630682212
Validation loss: 3.215923067890286

Epoch: 6| Step: 11
Training loss: 0.659910799703311
Validation loss: 3.148207196188855

Epoch: 6| Step: 12
Training loss: 0.9341213060528297
Validation loss: 3.11486616519657

Epoch: 6| Step: 13
Training loss: 0.3807389680337484
Validation loss: 3.1409292374203877

Epoch: 266| Step: 0
Training loss: 0.3200869347531024
Validation loss: 3.1172368835259747

Epoch: 6| Step: 1
Training loss: 0.9067848863266831
Validation loss: 3.2619644772980867

Epoch: 6| Step: 2
Training loss: 0.3308615782393021
Validation loss: 3.2189834287868084

Epoch: 6| Step: 3
Training loss: 0.40729516638433527
Validation loss: 3.222094726963306

Epoch: 6| Step: 4
Training loss: 0.41768310269317604
Validation loss: 3.215672055250179

Epoch: 6| Step: 5
Training loss: 0.5796490247764469
Validation loss: 3.271047309793036

Epoch: 6| Step: 6
Training loss: 0.4873187688042932
Validation loss: 3.232151354392428

Epoch: 6| Step: 7
Training loss: 0.6442804946935693
Validation loss: 3.1752025769905723

Epoch: 6| Step: 8
Training loss: 0.4436804999070527
Validation loss: 3.1686797937444586

Epoch: 6| Step: 9
Training loss: 0.32231439163676673
Validation loss: 3.1970485457432627

Epoch: 6| Step: 10
Training loss: 0.9007535852450365
Validation loss: 3.1843807441277776

Epoch: 6| Step: 11
Training loss: 0.5698548139581181
Validation loss: 3.2057375914243207

Epoch: 6| Step: 12
Training loss: 0.687398686313234
Validation loss: 3.2149133377299886

Epoch: 6| Step: 13
Training loss: 0.6062935656202189
Validation loss: 3.319639094261742

Epoch: 267| Step: 0
Training loss: 0.7894216041368921
Validation loss: 3.261223913487822

Epoch: 6| Step: 1
Training loss: 0.36708485406365043
Validation loss: 3.136611651614789

Epoch: 6| Step: 2
Training loss: 0.5781969334982537
Validation loss: 3.1662321273574374

Epoch: 6| Step: 3
Training loss: 0.5471065303603797
Validation loss: 3.110652220371034

Epoch: 6| Step: 4
Training loss: 0.5227094968121705
Validation loss: 3.112467890501045

Epoch: 6| Step: 5
Training loss: 0.5120064603632655
Validation loss: 3.051302348824357

Epoch: 6| Step: 6
Training loss: 0.39237167851481397
Validation loss: 3.1187864073397424

Epoch: 6| Step: 7
Training loss: 0.40732095845576943
Validation loss: 3.138785030443471

Epoch: 6| Step: 8
Training loss: 0.4134899535463579
Validation loss: 3.1920295396169363

Epoch: 6| Step: 9
Training loss: 0.4284156355784534
Validation loss: 3.211438686736809

Epoch: 6| Step: 10
Training loss: 0.3820677148933278
Validation loss: 3.1431401241978065

Epoch: 6| Step: 11
Training loss: 0.3547299641132194
Validation loss: 3.086317826024417

Epoch: 6| Step: 12
Training loss: 0.9730787164048754
Validation loss: 3.158194456007963

Epoch: 6| Step: 13
Training loss: 0.36639979261226907
Validation loss: 3.125049031190872

Epoch: 268| Step: 0
Training loss: 0.3973061825014618
Validation loss: 3.1596919262077563

Epoch: 6| Step: 1
Training loss: 0.42013884860512335
Validation loss: 3.130844157422501

Epoch: 6| Step: 2
Training loss: 0.4180916578743892
Validation loss: 3.2586558566915684

Epoch: 6| Step: 3
Training loss: 0.3017708858880149
Validation loss: 3.1827825031418193

Epoch: 6| Step: 4
Training loss: 0.3615592423591479
Validation loss: 3.2300413895347697

Epoch: 6| Step: 5
Training loss: 0.3785017942061033
Validation loss: 3.183642315640398

Epoch: 6| Step: 6
Training loss: 0.4219387853933698
Validation loss: 3.070300334359512

Epoch: 6| Step: 7
Training loss: 0.3736415736382159
Validation loss: 3.147377624576882

Epoch: 6| Step: 8
Training loss: 0.43694078946038295
Validation loss: 3.145886747062556

Epoch: 6| Step: 9
Training loss: 0.741271608304672
Validation loss: 3.219212940096459

Epoch: 6| Step: 10
Training loss: 0.29901102490018
Validation loss: 3.2171050130463343

Epoch: 6| Step: 11
Training loss: 0.8856147245404606
Validation loss: 3.173764773005544

Epoch: 6| Step: 12
Training loss: 0.6630088075884206
Validation loss: 3.2178117810571107

Epoch: 6| Step: 13
Training loss: 0.36372690655133055
Validation loss: 3.237093902215797

Epoch: 269| Step: 0
Training loss: 0.8583478511273874
Validation loss: 3.2209750265625634

Epoch: 6| Step: 1
Training loss: 0.5485412010551164
Validation loss: 3.189805786295565

Epoch: 6| Step: 2
Training loss: 0.6033253786535635
Validation loss: 3.1356574480409156

Epoch: 6| Step: 3
Training loss: 0.42952062660976226
Validation loss: 3.166559660927322

Epoch: 6| Step: 4
Training loss: 0.34867565842750453
Validation loss: 3.130157030206702

Epoch: 6| Step: 5
Training loss: 0.36726025611314267
Validation loss: 3.2609068204529916

Epoch: 6| Step: 6
Training loss: 0.37092349513674794
Validation loss: 3.3120094631869192

Epoch: 6| Step: 7
Training loss: 0.8592365847004546
Validation loss: 3.290819123360531

Epoch: 6| Step: 8
Training loss: 0.6019825397807751
Validation loss: 3.2378680644701143

Epoch: 6| Step: 9
Training loss: 0.4963535019295382
Validation loss: 3.2474047495768774

Epoch: 6| Step: 10
Training loss: 0.34723534983084553
Validation loss: 3.2107252435998825

Epoch: 6| Step: 11
Training loss: 0.5713777391780739
Validation loss: 3.0669864178590935

Epoch: 6| Step: 12
Training loss: 0.5376118754239698
Validation loss: 3.180070508779022

Epoch: 6| Step: 13
Training loss: 0.40824300397799124
Validation loss: 3.14373129705752

Epoch: 270| Step: 0
Training loss: 0.3877034606846047
Validation loss: 3.1738253455516676

Epoch: 6| Step: 1
Training loss: 0.7573411793288386
Validation loss: 3.2770974298179247

Epoch: 6| Step: 2
Training loss: 0.5502996300443931
Validation loss: 3.253059530439158

Epoch: 6| Step: 3
Training loss: 0.5588365573958812
Validation loss: 3.2640055119305864

Epoch: 6| Step: 4
Training loss: 0.6089019406395966
Validation loss: 3.254597810585981

Epoch: 6| Step: 5
Training loss: 0.4205744441174936
Validation loss: 3.137503114574655

Epoch: 6| Step: 6
Training loss: 1.0033333178823307
Validation loss: 3.1774518575755457

Epoch: 6| Step: 7
Training loss: 0.3499815361227648
Validation loss: 3.074394043348188

Epoch: 6| Step: 8
Training loss: 0.38631718912258134
Validation loss: 3.193049343664111

Epoch: 6| Step: 9
Training loss: 0.40666397716591746
Validation loss: 3.2045244586797037

Epoch: 6| Step: 10
Training loss: 0.5399009707387559
Validation loss: 3.175407897599406

Epoch: 6| Step: 11
Training loss: 0.40140587093562563
Validation loss: 3.2064998556621154

Epoch: 6| Step: 12
Training loss: 0.49993235905404354
Validation loss: 3.198258600168606

Epoch: 6| Step: 13
Training loss: 0.3920960194254558
Validation loss: 3.1873270748329383

Epoch: 271| Step: 0
Training loss: 0.6722239763479579
Validation loss: 3.2150972868149883

Epoch: 6| Step: 1
Training loss: 0.27914401853320564
Validation loss: 3.1478476149237284

Epoch: 6| Step: 2
Training loss: 0.3218605038239609
Validation loss: 3.1390287983263887

Epoch: 6| Step: 3
Training loss: 0.4128467236929278
Validation loss: 3.1554970173562498

Epoch: 6| Step: 4
Training loss: 0.3937069051865151
Validation loss: 3.1924410900554654

Epoch: 6| Step: 5
Training loss: 1.0988644504068925
Validation loss: 3.205105995492524

Epoch: 6| Step: 6
Training loss: 0.44331892391978606
Validation loss: 3.183243109304914

Epoch: 6| Step: 7
Training loss: 0.3996135707720719
Validation loss: 3.2021122517683236

Epoch: 6| Step: 8
Training loss: 0.5840093805069235
Validation loss: 3.216661893185514

Epoch: 6| Step: 9
Training loss: 0.3917111554986393
Validation loss: 3.2227006882194975

Epoch: 6| Step: 10
Training loss: 0.30350140031353273
Validation loss: 3.2310726980415185

Epoch: 6| Step: 11
Training loss: 0.2909626880604665
Validation loss: 3.177107643076128

Epoch: 6| Step: 12
Training loss: 0.3458486347758332
Validation loss: 3.1704524064970916

Epoch: 6| Step: 13
Training loss: 0.4613285345710403
Validation loss: 3.2151435474328296

Epoch: 272| Step: 0
Training loss: 0.49138313748538937
Validation loss: 3.11054766090195

Epoch: 6| Step: 1
Training loss: 0.401731822017427
Validation loss: 3.1865540141646433

Epoch: 6| Step: 2
Training loss: 0.41313185560623794
Validation loss: 3.1606660171612186

Epoch: 6| Step: 3
Training loss: 0.45911311515217057
Validation loss: 3.2350631448674543

Epoch: 6| Step: 4
Training loss: 0.37582509346167003
Validation loss: 3.228503095475977

Epoch: 6| Step: 5
Training loss: 0.3670504699845365
Validation loss: 3.2319454706402864

Epoch: 6| Step: 6
Training loss: 0.41934672156558245
Validation loss: 3.194596885876965

Epoch: 6| Step: 7
Training loss: 0.439143432000145
Validation loss: 3.1338578253588314

Epoch: 6| Step: 8
Training loss: 0.4210393187495016
Validation loss: 3.1427291223742237

Epoch: 6| Step: 9
Training loss: 0.8663619983816451
Validation loss: 3.0866277510233813

Epoch: 6| Step: 10
Training loss: 0.7393992602382031
Validation loss: 3.2558045393138633

Epoch: 6| Step: 11
Training loss: 0.5357136016795923
Validation loss: 3.1728130888903134

Epoch: 6| Step: 12
Training loss: 0.47530793949625444
Validation loss: 3.2896840647631227

Epoch: 6| Step: 13
Training loss: 0.5625183049508433
Validation loss: 3.252720501145055

Epoch: 273| Step: 0
Training loss: 0.760312077545287
Validation loss: 3.259362234088772

Epoch: 6| Step: 1
Training loss: 0.44885298723992617
Validation loss: 3.262870600419076

Epoch: 6| Step: 2
Training loss: 0.3907793884355026
Validation loss: 3.2164731784467024

Epoch: 6| Step: 3
Training loss: 0.2665059543529522
Validation loss: 3.2268330827731995

Epoch: 6| Step: 4
Training loss: 0.6057737997136597
Validation loss: 3.1446557693626898

Epoch: 6| Step: 5
Training loss: 0.46228012838429366
Validation loss: 3.1193713296134793

Epoch: 6| Step: 6
Training loss: 0.44732683920599714
Validation loss: 3.194683084465895

Epoch: 6| Step: 7
Training loss: 0.8742901443087382
Validation loss: 3.2123041392585057

Epoch: 6| Step: 8
Training loss: 0.41733768988593656
Validation loss: 3.1713632130014835

Epoch: 6| Step: 9
Training loss: 0.35297590754235797
Validation loss: 3.25732751250583

Epoch: 6| Step: 10
Training loss: 0.6439212571274179
Validation loss: 3.267693212974976

Epoch: 6| Step: 11
Training loss: 0.3110573130430568
Validation loss: 3.237809659565573

Epoch: 6| Step: 12
Training loss: 0.5651538551623645
Validation loss: 3.1906636750420705

Epoch: 6| Step: 13
Training loss: 0.4029804857844424
Validation loss: 3.158828424955281

Epoch: 274| Step: 0
Training loss: 0.4020369758301995
Validation loss: 3.1822790134176295

Epoch: 6| Step: 1
Training loss: 0.5468027339599061
Validation loss: 3.1661073207421624

Epoch: 6| Step: 2
Training loss: 0.8349683616263506
Validation loss: 3.156256345232638

Epoch: 6| Step: 3
Training loss: 0.4485023757314541
Validation loss: 3.2701453965591876

Epoch: 6| Step: 4
Training loss: 0.3849114466052584
Validation loss: 3.220715216033121

Epoch: 6| Step: 5
Training loss: 0.563604118943443
Validation loss: 3.2555440541398037

Epoch: 6| Step: 6
Training loss: 0.4151463627956961
Validation loss: 3.203049697611109

Epoch: 6| Step: 7
Training loss: 0.589835665817945
Validation loss: 3.2814220443913893

Epoch: 6| Step: 8
Training loss: 0.4426145472947326
Validation loss: 3.252241291036144

Epoch: 6| Step: 9
Training loss: 0.34694716115359936
Validation loss: 3.1524661456757554

Epoch: 6| Step: 10
Training loss: 0.5863816675877648
Validation loss: 3.1421280865242642

Epoch: 6| Step: 11
Training loss: 0.6866580402502143
Validation loss: 3.2079682121755155

Epoch: 6| Step: 12
Training loss: 0.8474851866358669
Validation loss: 3.1807067387245467

Epoch: 6| Step: 13
Training loss: 0.39542736601079775
Validation loss: 3.2805080725491997

Epoch: 275| Step: 0
Training loss: 0.719105715424942
Validation loss: 3.3059764179189455

Epoch: 6| Step: 1
Training loss: 0.4031302902702551
Validation loss: 3.2788980319847463

Epoch: 6| Step: 2
Training loss: 0.8325901930010384
Validation loss: 3.2047187995839095

Epoch: 6| Step: 3
Training loss: 0.4136964511505197
Validation loss: 3.2924303464635183

Epoch: 6| Step: 4
Training loss: 0.4160057030869159
Validation loss: 3.1951952277739264

Epoch: 6| Step: 5
Training loss: 0.3781316252198959
Validation loss: 3.2233823755814304

Epoch: 6| Step: 6
Training loss: 0.4996119572958227
Validation loss: 3.1994860688415097

Epoch: 6| Step: 7
Training loss: 0.4227466761516471
Validation loss: 3.251568159165377

Epoch: 6| Step: 8
Training loss: 0.380279784695751
Validation loss: 3.1890531383715293

Epoch: 6| Step: 9
Training loss: 0.37705707599134813
Validation loss: 3.2603299106028327

Epoch: 6| Step: 10
Training loss: 0.7399490329872471
Validation loss: 3.22350493382283

Epoch: 6| Step: 11
Training loss: 0.6321528021982281
Validation loss: 3.2067707682370963

Epoch: 6| Step: 12
Training loss: 0.3331973747302836
Validation loss: 3.2860929202359768

Epoch: 6| Step: 13
Training loss: 0.2548341814322878
Validation loss: 3.187876735190034

Epoch: 276| Step: 0
Training loss: 0.42749047837612614
Validation loss: 3.1305163206048623

Epoch: 6| Step: 1
Training loss: 0.38327049573078326
Validation loss: 3.1561935847814664

Epoch: 6| Step: 2
Training loss: 0.40808005051827356
Validation loss: 3.0987216549205683

Epoch: 6| Step: 3
Training loss: 0.37348119807251684
Validation loss: 3.131939532512714

Epoch: 6| Step: 4
Training loss: 0.3432976282038653
Validation loss: 3.1472532760316616

Epoch: 6| Step: 5
Training loss: 0.4541645457571128
Validation loss: 3.1977201188083373

Epoch: 6| Step: 6
Training loss: 0.7100547508164085
Validation loss: 3.1839506296406888

Epoch: 6| Step: 7
Training loss: 0.3665114327035777
Validation loss: 3.161578197605555

Epoch: 6| Step: 8
Training loss: 0.37156222036237274
Validation loss: 3.225839640115932

Epoch: 6| Step: 9
Training loss: 0.36193108639562144
Validation loss: 3.157151726054956

Epoch: 6| Step: 10
Training loss: 0.8024448513083793
Validation loss: 3.166858295029977

Epoch: 6| Step: 11
Training loss: 0.45634767976022433
Validation loss: 3.251108555144879

Epoch: 6| Step: 12
Training loss: 0.35055484474462384
Validation loss: 3.21160168983072

Epoch: 6| Step: 13
Training loss: 0.3156513226740761
Validation loss: 3.1373240139100442

Epoch: 277| Step: 0
Training loss: 0.4232779240891196
Validation loss: 3.1909787760600263

Epoch: 6| Step: 1
Training loss: 0.49021411565128276
Validation loss: 3.152639583932999

Epoch: 6| Step: 2
Training loss: 0.3917926883188572
Validation loss: 3.1642622770810838

Epoch: 6| Step: 3
Training loss: 0.4924816130822068
Validation loss: 3.2450638111464736

Epoch: 6| Step: 4
Training loss: 0.4280075350648497
Validation loss: 3.2548394240829355

Epoch: 6| Step: 5
Training loss: 0.4811540693806108
Validation loss: 3.264053234174234

Epoch: 6| Step: 6
Training loss: 0.8150405046426029
Validation loss: 3.2751284096079627

Epoch: 6| Step: 7
Training loss: 0.4288845188771162
Validation loss: 3.2056829148072126

Epoch: 6| Step: 8
Training loss: 0.5079682918137004
Validation loss: 3.2244261041258837

Epoch: 6| Step: 9
Training loss: 0.36674915689892845
Validation loss: 3.1308627510330234

Epoch: 6| Step: 10
Training loss: 0.7517680547288568
Validation loss: 3.2283717663994276

Epoch: 6| Step: 11
Training loss: 0.3787818783226999
Validation loss: 3.154653894712445

Epoch: 6| Step: 12
Training loss: 0.5157671067899762
Validation loss: 3.2110012818473224

Epoch: 6| Step: 13
Training loss: 0.4603655709816649
Validation loss: 3.1734704450897206

Epoch: 278| Step: 0
Training loss: 0.3048487994363878
Validation loss: 3.1931970833107335

Epoch: 6| Step: 1
Training loss: 0.4154135058380651
Validation loss: 3.289738130380052

Epoch: 6| Step: 2
Training loss: 0.36145433850604747
Validation loss: 3.248382630526245

Epoch: 6| Step: 3
Training loss: 0.7030417287048748
Validation loss: 3.2192212225899213

Epoch: 6| Step: 4
Training loss: 0.44695064331283213
Validation loss: 3.220767762148761

Epoch: 6| Step: 5
Training loss: 0.4127861901388424
Validation loss: 3.2062272470719124

Epoch: 6| Step: 6
Training loss: 0.4775117893660973
Validation loss: 3.1045451008240383

Epoch: 6| Step: 7
Training loss: 0.45442303179343896
Validation loss: 3.110696827935072

Epoch: 6| Step: 8
Training loss: 0.5024928593958528
Validation loss: 3.078603510446595

Epoch: 6| Step: 9
Training loss: 0.44868211620611564
Validation loss: 2.9786913477023957

Epoch: 6| Step: 10
Training loss: 0.3907883111986131
Validation loss: 3.1268286123271802

Epoch: 6| Step: 11
Training loss: 0.3816376388261179
Validation loss: 3.185933270341686

Epoch: 6| Step: 12
Training loss: 0.4744969615537519
Validation loss: 3.142332596529481

Epoch: 6| Step: 13
Training loss: 0.9212150150938834
Validation loss: 3.2376411888334724

Epoch: 279| Step: 0
Training loss: 0.4405869501337143
Validation loss: 3.1490345681405914

Epoch: 6| Step: 1
Training loss: 0.5254191280985974
Validation loss: 3.216511562211789

Epoch: 6| Step: 2
Training loss: 0.39689352037364806
Validation loss: 3.229072598143406

Epoch: 6| Step: 3
Training loss: 0.4672370176323176
Validation loss: 3.1238232240697665

Epoch: 6| Step: 4
Training loss: 0.347359895300912
Validation loss: 3.056860408661041

Epoch: 6| Step: 5
Training loss: 0.7525822373377535
Validation loss: 3.1678516320821495

Epoch: 6| Step: 6
Training loss: 0.3508578444120276
Validation loss: 3.1326647792625653

Epoch: 6| Step: 7
Training loss: 0.42816756795612854
Validation loss: 3.20174934185807

Epoch: 6| Step: 8
Training loss: 0.42256570717043473
Validation loss: 3.1673078557090246

Epoch: 6| Step: 9
Training loss: 0.2733236211969275
Validation loss: 3.116475902845906

Epoch: 6| Step: 10
Training loss: 0.7677119092370599
Validation loss: 3.1557867005996463

Epoch: 6| Step: 11
Training loss: 0.3406449115253026
Validation loss: 3.1587074331664304

Epoch: 6| Step: 12
Training loss: 0.36142863344903325
Validation loss: 3.1533233746525275

Epoch: 6| Step: 13
Training loss: 0.39796412153364485
Validation loss: 3.2377515727015203

Epoch: 280| Step: 0
Training loss: 0.32159622490052614
Validation loss: 3.2287355360769747

Epoch: 6| Step: 1
Training loss: 0.47293390047990524
Validation loss: 3.1587525823391625

Epoch: 6| Step: 2
Training loss: 0.5338295969697836
Validation loss: 3.1825117585553553

Epoch: 6| Step: 3
Training loss: 0.9088953804938749
Validation loss: 3.1543278396393597

Epoch: 6| Step: 4
Training loss: 0.38153577553202805
Validation loss: 3.1197532222631406

Epoch: 6| Step: 5
Training loss: 0.3250963673404205
Validation loss: 3.1804195689171415

Epoch: 6| Step: 6
Training loss: 0.48644143435296144
Validation loss: 3.1899915942616466

Epoch: 6| Step: 7
Training loss: 0.36450708363953555
Validation loss: 3.255103359310002

Epoch: 6| Step: 8
Training loss: 0.5571093810769823
Validation loss: 3.289635663444753

Epoch: 6| Step: 9
Training loss: 0.4703643972969328
Validation loss: 3.2657288043545663

Epoch: 6| Step: 10
Training loss: 0.3602571441264979
Validation loss: 3.222295888153689

Epoch: 6| Step: 11
Training loss: 0.6982359985930923
Validation loss: 3.212384469494308

Epoch: 6| Step: 12
Training loss: 0.41519540871261873
Validation loss: 3.1681986457641846

Epoch: 6| Step: 13
Training loss: 0.46848197267834557
Validation loss: 3.163591790998073

Epoch: 281| Step: 0
Training loss: 0.4084216358924463
Validation loss: 3.1799337305805273

Epoch: 6| Step: 1
Training loss: 0.37990371921151656
Validation loss: 3.2302264945708714

Epoch: 6| Step: 2
Training loss: 0.2527608713119341
Validation loss: 3.224509114601999

Epoch: 6| Step: 3
Training loss: 0.7127831783058701
Validation loss: 3.219417885433166

Epoch: 6| Step: 4
Training loss: 0.46942776318669505
Validation loss: 3.1813972743830634

Epoch: 6| Step: 5
Training loss: 0.4192913911253658
Validation loss: 3.236571176012764

Epoch: 6| Step: 6
Training loss: 0.38582913348395537
Validation loss: 3.1697004785039775

Epoch: 6| Step: 7
Training loss: 0.662495458335424
Validation loss: 3.1454977062796874

Epoch: 6| Step: 8
Training loss: 0.4289523337921782
Validation loss: 3.1502084350249553

Epoch: 6| Step: 9
Training loss: 0.9225540892708188
Validation loss: 3.159058621114521

Epoch: 6| Step: 10
Training loss: 0.3494499525015304
Validation loss: 3.1182697046075765

Epoch: 6| Step: 11
Training loss: 0.3929481849825562
Validation loss: 3.1452750453749756

Epoch: 6| Step: 12
Training loss: 0.3567239586695906
Validation loss: 3.1284771711164745

Epoch: 6| Step: 13
Training loss: 0.46612741835323085
Validation loss: 3.119157606766188

Epoch: 282| Step: 0
Training loss: 0.42795548319926796
Validation loss: 3.1343645419564035

Epoch: 6| Step: 1
Training loss: 0.3971891856664248
Validation loss: 3.138389538305386

Epoch: 6| Step: 2
Training loss: 0.5405454830720184
Validation loss: 3.2219450564681287

Epoch: 6| Step: 3
Training loss: 0.2578702630732681
Validation loss: 3.1594351254963686

Epoch: 6| Step: 4
Training loss: 0.3114231749479675
Validation loss: 3.282495147360599

Epoch: 6| Step: 5
Training loss: 0.30348744402715666
Validation loss: 3.273824373021654

Epoch: 6| Step: 6
Training loss: 0.704385771512495
Validation loss: 3.2559535259508157

Epoch: 6| Step: 7
Training loss: 1.0531654395424157
Validation loss: 3.110032004204999

Epoch: 6| Step: 8
Training loss: 0.39884344626354384
Validation loss: 3.1170687290341257

Epoch: 6| Step: 9
Training loss: 0.4077085574459239
Validation loss: 3.1723228226153837

Epoch: 6| Step: 10
Training loss: 0.42729572116906517
Validation loss: 3.14126704344836

Epoch: 6| Step: 11
Training loss: 0.5929408331972663
Validation loss: 3.135956592055033

Epoch: 6| Step: 12
Training loss: 0.4353952528815234
Validation loss: 3.201956372959211

Epoch: 6| Step: 13
Training loss: 0.4895943647183439
Validation loss: 3.275843874606188

Epoch: 283| Step: 0
Training loss: 0.5467453121634944
Validation loss: 3.2674867594809904

Epoch: 6| Step: 1
Training loss: 0.5306842259580211
Validation loss: 3.2001997949892638

Epoch: 6| Step: 2
Training loss: 0.3293692069295201
Validation loss: 3.235167082334155

Epoch: 6| Step: 3
Training loss: 0.4160401243061224
Validation loss: 3.145204510692881

Epoch: 6| Step: 4
Training loss: 0.42518078170710427
Validation loss: 3.2248274700333552

Epoch: 6| Step: 5
Training loss: 0.5105352037025354
Validation loss: 3.25384086674475

Epoch: 6| Step: 6
Training loss: 0.5129006401531042
Validation loss: 3.2644256141473824

Epoch: 6| Step: 7
Training loss: 0.44176323557716063
Validation loss: 3.288078819443185

Epoch: 6| Step: 8
Training loss: 0.9188831077221103
Validation loss: 3.2806085110864878

Epoch: 6| Step: 9
Training loss: 0.3286674420869577
Validation loss: 3.3261665468141532

Epoch: 6| Step: 10
Training loss: 0.350105402606726
Validation loss: 3.260619493377113

Epoch: 6| Step: 11
Training loss: 0.408875910267856
Validation loss: 3.2140582930123642

Epoch: 6| Step: 12
Training loss: 0.8013954598304162
Validation loss: 3.217871191057522

Epoch: 6| Step: 13
Training loss: 0.5893409556551128
Validation loss: 3.234235628476156

Epoch: 284| Step: 0
Training loss: 0.48176016580954456
Validation loss: 3.24251584761175

Epoch: 6| Step: 1
Training loss: 0.43103535534918364
Validation loss: 3.252762647340765

Epoch: 6| Step: 2
Training loss: 0.3911115667755611
Validation loss: 3.212300799337635

Epoch: 6| Step: 3
Training loss: 0.32722153487526406
Validation loss: 3.2600189470157894

Epoch: 6| Step: 4
Training loss: 0.41047124120611933
Validation loss: 3.14946184304437

Epoch: 6| Step: 5
Training loss: 0.786189448052093
Validation loss: 3.240753518538539

Epoch: 6| Step: 6
Training loss: 0.3632974518475262
Validation loss: 3.196826082006369

Epoch: 6| Step: 7
Training loss: 0.36297910697700203
Validation loss: 3.3042201439922234

Epoch: 6| Step: 8
Training loss: 0.2699873423920779
Validation loss: 3.1732533534039358

Epoch: 6| Step: 9
Training loss: 0.3944452777519438
Validation loss: 3.1887714368417894

Epoch: 6| Step: 10
Training loss: 0.8282389652358815
Validation loss: 3.2270253783099805

Epoch: 6| Step: 11
Training loss: 0.41269284566709796
Validation loss: 3.2333022840392056

Epoch: 6| Step: 12
Training loss: 0.3946123700735334
Validation loss: 3.191231855516941

Epoch: 6| Step: 13
Training loss: 0.42418002097586305
Validation loss: 3.170662609087586

Epoch: 285| Step: 0
Training loss: 0.7869725262210062
Validation loss: 3.234320721501015

Epoch: 6| Step: 1
Training loss: 0.5280990842521253
Validation loss: 3.210437893575557

Epoch: 6| Step: 2
Training loss: 0.2877555892792584
Validation loss: 3.1580208698466516

Epoch: 6| Step: 3
Training loss: 0.4410880976175259
Validation loss: 3.201602034094306

Epoch: 6| Step: 4
Training loss: 0.40864540853031794
Validation loss: 3.2460440131889925

Epoch: 6| Step: 5
Training loss: 0.36236197540519993
Validation loss: 3.177630484738313

Epoch: 6| Step: 6
Training loss: 0.37153320392714423
Validation loss: 3.3259081195543283

Epoch: 6| Step: 7
Training loss: 0.6972971462957256
Validation loss: 3.2282547473221173

Epoch: 6| Step: 8
Training loss: 0.43660452002200845
Validation loss: 3.18659305759498

Epoch: 6| Step: 9
Training loss: 0.4655630332881246
Validation loss: 3.160482659318334

Epoch: 6| Step: 10
Training loss: 0.35003878685065887
Validation loss: 3.174079867820574

Epoch: 6| Step: 11
Training loss: 0.3423855861414378
Validation loss: 3.1922187035607568

Epoch: 6| Step: 12
Training loss: 0.41511678528921025
Validation loss: 3.144068410231064

Epoch: 6| Step: 13
Training loss: 0.39332085186880317
Validation loss: 3.2366940574063205

Epoch: 286| Step: 0
Training loss: 0.418649173099016
Validation loss: 3.2357865354062008

Epoch: 6| Step: 1
Training loss: 0.7728107880273746
Validation loss: 3.2366610447696953

Epoch: 6| Step: 2
Training loss: 0.48999221109505675
Validation loss: 3.2386055520522175

Epoch: 6| Step: 3
Training loss: 0.4951491486656176
Validation loss: 3.2291945097348442

Epoch: 6| Step: 4
Training loss: 0.2919351018008018
Validation loss: 3.2557312242795065

Epoch: 6| Step: 5
Training loss: 0.5777496975510457
Validation loss: 3.1298108136747733

Epoch: 6| Step: 6
Training loss: 0.6244218059175403
Validation loss: 3.16866855754939

Epoch: 6| Step: 7
Training loss: 0.39830514167969405
Validation loss: 3.245679526710583

Epoch: 6| Step: 8
Training loss: 0.46569120269294556
Validation loss: 3.1591862155192407

Epoch: 6| Step: 9
Training loss: 0.40832725718252777
Validation loss: 3.253952703796932

Epoch: 6| Step: 10
Training loss: 0.48036397396301156
Validation loss: 3.2118167214872537

Epoch: 6| Step: 11
Training loss: 0.4287555123967401
Validation loss: 3.2652143618718825

Epoch: 6| Step: 12
Training loss: 0.444391687270333
Validation loss: 3.1911614649826494

Epoch: 6| Step: 13
Training loss: 0.7623969164723927
Validation loss: 3.2219796875041675

Epoch: 287| Step: 0
Training loss: 0.6125691890563459
Validation loss: 3.1995284567543782

Epoch: 6| Step: 1
Training loss: 0.5750020970430696
Validation loss: 3.1485191063287314

Epoch: 6| Step: 2
Training loss: 0.6933794905202674
Validation loss: 3.2040988465181073

Epoch: 6| Step: 3
Training loss: 0.41428257833548293
Validation loss: 3.2782911735529803

Epoch: 6| Step: 4
Training loss: 0.4783380607156495
Validation loss: 3.3046365167338934

Epoch: 6| Step: 5
Training loss: 0.600431593004151
Validation loss: 3.218208069842021

Epoch: 6| Step: 6
Training loss: 0.44073134282091114
Validation loss: 3.2540391739908268

Epoch: 6| Step: 7
Training loss: 0.3937402103357552
Validation loss: 3.2135046529673392

Epoch: 6| Step: 8
Training loss: 0.30374440931740276
Validation loss: 3.176832737446117

Epoch: 6| Step: 9
Training loss: 0.3739893925164671
Validation loss: 3.2455110359715365

Epoch: 6| Step: 10
Training loss: 0.38039373641387864
Validation loss: 3.1551331662358915

Epoch: 6| Step: 11
Training loss: 0.46583294801349207
Validation loss: 3.1760284340143756

Epoch: 6| Step: 12
Training loss: 0.3806203238665095
Validation loss: 3.1803646631902356

Epoch: 6| Step: 13
Training loss: 0.7782034792256379
Validation loss: 3.097117559568128

Epoch: 288| Step: 0
Training loss: 0.35734845016984595
Validation loss: 3.148962552926613

Epoch: 6| Step: 1
Training loss: 0.28901108722720115
Validation loss: 3.211874770143264

Epoch: 6| Step: 2
Training loss: 0.315612185095307
Validation loss: 3.19652755007643

Epoch: 6| Step: 3
Training loss: 0.3974697665047006
Validation loss: 3.1697200978089177

Epoch: 6| Step: 4
Training loss: 0.4310026502981371
Validation loss: 3.2058799991197584

Epoch: 6| Step: 5
Training loss: 0.39235498719889256
Validation loss: 3.1492418093236543

Epoch: 6| Step: 6
Training loss: 0.7992856084428335
Validation loss: 3.1664890105623367

Epoch: 6| Step: 7
Training loss: 0.8738097883405739
Validation loss: 3.151058964116984

Epoch: 6| Step: 8
Training loss: 0.4962213307129848
Validation loss: 3.1700637230951503

Epoch: 6| Step: 9
Training loss: 0.3028285218557992
Validation loss: 3.214536656065328

Epoch: 6| Step: 10
Training loss: 0.44565692765834586
Validation loss: 3.198721052433604

Epoch: 6| Step: 11
Training loss: 0.4318653057020609
Validation loss: 3.245888260918131

Epoch: 6| Step: 12
Training loss: 0.3668838422252351
Validation loss: 3.199471475744197

Epoch: 6| Step: 13
Training loss: 0.4428820288001053
Validation loss: 3.2131993849788056

Epoch: 289| Step: 0
Training loss: 0.8032976758991909
Validation loss: 3.2121610143500896

Epoch: 6| Step: 1
Training loss: 0.4216676485040163
Validation loss: 3.1612701024806165

Epoch: 6| Step: 2
Training loss: 0.2732410951692072
Validation loss: 3.1752733338212504

Epoch: 6| Step: 3
Training loss: 0.28590477719700524
Validation loss: 3.1857762631283695

Epoch: 6| Step: 4
Training loss: 0.43467018608533875
Validation loss: 3.1391700423664455

Epoch: 6| Step: 5
Training loss: 0.35711894721648946
Validation loss: 3.2259945619761576

Epoch: 6| Step: 6
Training loss: 0.7056920556777913
Validation loss: 3.1907524145716426

Epoch: 6| Step: 7
Training loss: 0.3976102543818636
Validation loss: 3.2338514165282426

Epoch: 6| Step: 8
Training loss: 0.40465323549827426
Validation loss: 3.187910066045262

Epoch: 6| Step: 9
Training loss: 0.4542707066695047
Validation loss: 3.3168408963113194

Epoch: 6| Step: 10
Training loss: 0.34680050101450266
Validation loss: 3.1561570862039505

Epoch: 6| Step: 11
Training loss: 0.27982336718749934
Validation loss: 3.194615108427659

Epoch: 6| Step: 12
Training loss: 0.3619580319864687
Validation loss: 3.1840873476032905

Epoch: 6| Step: 13
Training loss: 0.3464476440124133
Validation loss: 3.2214602692178103

Epoch: 290| Step: 0
Training loss: 0.71918354227534
Validation loss: 3.182337750706281

Epoch: 6| Step: 1
Training loss: 0.3490191864454965
Validation loss: 3.2608554207683946

Epoch: 6| Step: 2
Training loss: 0.39372416366099805
Validation loss: 3.2495500913399256

Epoch: 6| Step: 3
Training loss: 0.5881922762231698
Validation loss: 3.2681295716611256

Epoch: 6| Step: 4
Training loss: 0.36121834814275533
Validation loss: 3.238387550538871

Epoch: 6| Step: 5
Training loss: 0.497550627370444
Validation loss: 3.1648776538859393

Epoch: 6| Step: 6
Training loss: 0.42767985096577077
Validation loss: 3.176136880617032

Epoch: 6| Step: 7
Training loss: 0.2788381343764736
Validation loss: 3.1784889905473963

Epoch: 6| Step: 8
Training loss: 0.3713496079060293
Validation loss: 3.2157830449429796

Epoch: 6| Step: 9
Training loss: 0.2887221213915096
Validation loss: 3.237942765740686

Epoch: 6| Step: 10
Training loss: 0.7607889222271196
Validation loss: 3.328638195414468

Epoch: 6| Step: 11
Training loss: 0.2747521133940328
Validation loss: 3.3101047757056716

Epoch: 6| Step: 12
Training loss: 0.41149125591179214
Validation loss: 3.2048460143893127

Epoch: 6| Step: 13
Training loss: 0.47642571409205675
Validation loss: 3.298613766228572

Epoch: 291| Step: 0
Training loss: 0.3808599227510084
Validation loss: 3.2445919450961003

Epoch: 6| Step: 1
Training loss: 0.37004370450603885
Validation loss: 3.2481806382104477

Epoch: 6| Step: 2
Training loss: 0.4837857322901662
Validation loss: 3.193363089369734

Epoch: 6| Step: 3
Training loss: 0.3779293326442738
Validation loss: 3.142681808452466

Epoch: 6| Step: 4
Training loss: 0.586420877072476
Validation loss: 3.3093206154422417

Epoch: 6| Step: 5
Training loss: 0.40906544913794496
Validation loss: 3.255840775151206

Epoch: 6| Step: 6
Training loss: 0.3741905297328258
Validation loss: 3.176131313247789

Epoch: 6| Step: 7
Training loss: 0.44186426554351993
Validation loss: 3.2146136053559062

Epoch: 6| Step: 8
Training loss: 0.36024264625413716
Validation loss: 3.2576802422795454

Epoch: 6| Step: 9
Training loss: 0.5805463602954163
Validation loss: 3.2167562834620824

Epoch: 6| Step: 10
Training loss: 0.3785560798875274
Validation loss: 3.1952895433367603

Epoch: 6| Step: 11
Training loss: 0.3474489837185594
Validation loss: 3.2312263114055964

Epoch: 6| Step: 12
Training loss: 0.7653007599259983
Validation loss: 3.2361909004238303

Epoch: 6| Step: 13
Training loss: 0.6256907460729897
Validation loss: 3.2630713789491375

Epoch: 292| Step: 0
Training loss: 0.38858130851925426
Validation loss: 3.234921174305069

Epoch: 6| Step: 1
Training loss: 0.5240680824851394
Validation loss: 3.2305177548807262

Epoch: 6| Step: 2
Training loss: 0.34687872532399194
Validation loss: 3.1969752007943413

Epoch: 6| Step: 3
Training loss: 0.27309428882556636
Validation loss: 3.2041198767150556

Epoch: 6| Step: 4
Training loss: 0.7208861245318442
Validation loss: 3.1370073045615756

Epoch: 6| Step: 5
Training loss: 0.3086834547786111
Validation loss: 3.1456527952889712

Epoch: 6| Step: 6
Training loss: 0.27761536045420626
Validation loss: 3.287437031267357

Epoch: 6| Step: 7
Training loss: 0.2757746541690672
Validation loss: 3.2055746496268402

Epoch: 6| Step: 8
Training loss: 0.5645427170767944
Validation loss: 3.211455229935996

Epoch: 6| Step: 9
Training loss: 0.41224778368616116
Validation loss: 3.247718707290014

Epoch: 6| Step: 10
Training loss: 0.7674034249869303
Validation loss: 3.2910519138527685

Epoch: 6| Step: 11
Training loss: 0.4810175359011734
Validation loss: 3.3173373427637696

Epoch: 6| Step: 12
Training loss: 0.5150975795539385
Validation loss: 3.3109032603196598

Epoch: 6| Step: 13
Training loss: 0.4818337133114263
Validation loss: 3.268939804489146

Epoch: 293| Step: 0
Training loss: 0.33932446674374445
Validation loss: 3.1904109677552857

Epoch: 6| Step: 1
Training loss: 0.3892477169153662
Validation loss: 3.1810679395500374

Epoch: 6| Step: 2
Training loss: 0.5838482037755018
Validation loss: 3.16725646767084

Epoch: 6| Step: 3
Training loss: 0.7369222091034422
Validation loss: 3.165158418725365

Epoch: 6| Step: 4
Training loss: 0.2315380297021028
Validation loss: 3.2376583468131535

Epoch: 6| Step: 5
Training loss: 0.4276853559441113
Validation loss: 3.249238866542123

Epoch: 6| Step: 6
Training loss: 0.7021773628144856
Validation loss: 3.314247570059108

Epoch: 6| Step: 7
Training loss: 0.5650717701100365
Validation loss: 3.2655264856302826

Epoch: 6| Step: 8
Training loss: 0.39168808283320417
Validation loss: 3.166708096852243

Epoch: 6| Step: 9
Training loss: 0.9152630477888004
Validation loss: 3.1412775554225085

Epoch: 6| Step: 10
Training loss: 0.5036734405441178
Validation loss: 3.16335104647609

Epoch: 6| Step: 11
Training loss: 0.3684497807262284
Validation loss: 3.154746928355133

Epoch: 6| Step: 12
Training loss: 0.5896299366229787
Validation loss: 3.1954474510042754

Epoch: 6| Step: 13
Training loss: 0.5738311809045533
Validation loss: 3.30809032178651

Epoch: 294| Step: 0
Training loss: 0.3931543287426304
Validation loss: 3.264730486122619

Epoch: 6| Step: 1
Training loss: 0.6123088489737846
Validation loss: 3.2991551112388313

Epoch: 6| Step: 2
Training loss: 0.8034001023956036
Validation loss: 3.294561638140516

Epoch: 6| Step: 3
Training loss: 0.5303061459396126
Validation loss: 3.163420661535521

Epoch: 6| Step: 4
Training loss: 0.5715100504908398
Validation loss: 3.1419898716006336

Epoch: 6| Step: 5
Training loss: 0.4530503441706892
Validation loss: 3.23786077465304

Epoch: 6| Step: 6
Training loss: 0.7191478623207846
Validation loss: 3.1263136327938783

Epoch: 6| Step: 7
Training loss: 0.751910835166837
Validation loss: 3.1797882613979214

Epoch: 6| Step: 8
Training loss: 0.4218402424375495
Validation loss: 3.2598880099541816

Epoch: 6| Step: 9
Training loss: 0.6256862211045732
Validation loss: 3.329754616991624

Epoch: 6| Step: 10
Training loss: 0.6666357336219152
Validation loss: 3.25932017323217

Epoch: 6| Step: 11
Training loss: 0.4870090543445733
Validation loss: 3.2247972932338436

Epoch: 6| Step: 12
Training loss: 0.2750572730159113
Validation loss: 3.1418740491610784

Epoch: 6| Step: 13
Training loss: 0.5426262797771372
Validation loss: 3.1041040776917286

Epoch: 295| Step: 0
Training loss: 0.6033892946827986
Validation loss: 3.132168406344869

Epoch: 6| Step: 1
Training loss: 0.4402548026191742
Validation loss: 3.1868964851843677

Epoch: 6| Step: 2
Training loss: 0.2915555821913598
Validation loss: 3.19477589771984

Epoch: 6| Step: 3
Training loss: 0.49808198393696956
Validation loss: 3.2320715400336715

Epoch: 6| Step: 4
Training loss: 0.45261288346594586
Validation loss: 3.29368388660342

Epoch: 6| Step: 5
Training loss: 0.3014690165328236
Validation loss: 3.2665625873515665

Epoch: 6| Step: 6
Training loss: 0.4379873286378297
Validation loss: 3.2662563048383513

Epoch: 6| Step: 7
Training loss: 0.7573859203789741
Validation loss: 3.218884659700253

Epoch: 6| Step: 8
Training loss: 0.5017334572422308
Validation loss: 3.189984543821705

Epoch: 6| Step: 9
Training loss: 0.4059751387745237
Validation loss: 3.177448606077959

Epoch: 6| Step: 10
Training loss: 0.7188368205831972
Validation loss: 3.201412400586632

Epoch: 6| Step: 11
Training loss: 0.40223584996733835
Validation loss: 3.2303914526379316

Epoch: 6| Step: 12
Training loss: 0.7680729249167115
Validation loss: 3.265748832338178

Epoch: 6| Step: 13
Training loss: 0.477612745221165
Validation loss: 3.320400904058252

Epoch: 296| Step: 0
Training loss: 0.59270684309662
Validation loss: 3.330767637522259

Epoch: 6| Step: 1
Training loss: 0.6802346011742264
Validation loss: 3.2995903921712166

Epoch: 6| Step: 2
Training loss: 0.37605732632451466
Validation loss: 3.2431207991106192

Epoch: 6| Step: 3
Training loss: 0.3141743745393736
Validation loss: 3.24020894051921

Epoch: 6| Step: 4
Training loss: 0.2971524021711118
Validation loss: 3.202823407621107

Epoch: 6| Step: 5
Training loss: 0.2746597900344781
Validation loss: 3.217924005886232

Epoch: 6| Step: 6
Training loss: 0.4311843289945589
Validation loss: 3.176598225230211

Epoch: 6| Step: 7
Training loss: 0.3939519349252219
Validation loss: 3.184081594460016

Epoch: 6| Step: 8
Training loss: 0.34996820927041755
Validation loss: 3.161553902519612

Epoch: 6| Step: 9
Training loss: 0.33554033710474174
Validation loss: 3.2183899909599414

Epoch: 6| Step: 10
Training loss: 0.46981152501676865
Validation loss: 3.2082882832588617

Epoch: 6| Step: 11
Training loss: 0.773007745509063
Validation loss: 3.2993251139328446

Epoch: 6| Step: 12
Training loss: 0.2517068827677329
Validation loss: 3.208777599208593

Epoch: 6| Step: 13
Training loss: 0.38431229971624403
Validation loss: 3.172014130044952

Epoch: 297| Step: 0
Training loss: 0.3516807992899175
Validation loss: 3.2621582709733072

Epoch: 6| Step: 1
Training loss: 0.34857642094360053
Validation loss: 3.1958029944924857

Epoch: 6| Step: 2
Training loss: 0.773933059224947
Validation loss: 3.2420042055092138

Epoch: 6| Step: 3
Training loss: 0.4205350435602765
Validation loss: 3.2263890205157386

Epoch: 6| Step: 4
Training loss: 0.5376619582911112
Validation loss: 3.296523522900471

Epoch: 6| Step: 5
Training loss: 0.4948589396336165
Validation loss: 3.2639661162057516

Epoch: 6| Step: 6
Training loss: 0.766081420936163
Validation loss: 3.183349962007987

Epoch: 6| Step: 7
Training loss: 0.43629505916698885
Validation loss: 3.2372675567998512

Epoch: 6| Step: 8
Training loss: 0.23311406931934175
Validation loss: 3.2104487607929015

Epoch: 6| Step: 9
Training loss: 0.35312096289631
Validation loss: 3.2131596631357766

Epoch: 6| Step: 10
Training loss: 0.24077469454783473
Validation loss: 3.240387664412685

Epoch: 6| Step: 11
Training loss: 0.5049276719372185
Validation loss: 3.231031892303264

Epoch: 6| Step: 12
Training loss: 0.36785361560103963
Validation loss: 3.348531257763371

Epoch: 6| Step: 13
Training loss: 0.3812899185607198
Validation loss: 3.193797304881825

Epoch: 298| Step: 0
Training loss: 0.3504138407251182
Validation loss: 3.208942743527816

Epoch: 6| Step: 1
Training loss: 0.44454878854596175
Validation loss: 3.218605556765461

Epoch: 6| Step: 2
Training loss: 0.468120215458987
Validation loss: 3.2341400282274773

Epoch: 6| Step: 3
Training loss: 0.33374260076257345
Validation loss: 3.2031906493367726

Epoch: 6| Step: 4
Training loss: 0.4764999442395701
Validation loss: 3.1822016069037797

Epoch: 6| Step: 5
Training loss: 0.4359757915893662
Validation loss: 3.162256511919475

Epoch: 6| Step: 6
Training loss: 0.3437402030242322
Validation loss: 3.147613266049933

Epoch: 6| Step: 7
Training loss: 0.42249605594577316
Validation loss: 3.1926959453962658

Epoch: 6| Step: 8
Training loss: 0.27822820912982715
Validation loss: 3.285228968846248

Epoch: 6| Step: 9
Training loss: 0.348540072033676
Validation loss: 3.2466204751845718

Epoch: 6| Step: 10
Training loss: 0.763705669933379
Validation loss: 3.174396921687883

Epoch: 6| Step: 11
Training loss: 0.4426327603480484
Validation loss: 3.268730536476476

Epoch: 6| Step: 12
Training loss: 0.2737772873991318
Validation loss: 3.2821880150282796

Epoch: 6| Step: 13
Training loss: 0.7011448209425897
Validation loss: 3.1884237334707484

Epoch: 299| Step: 0
Training loss: 0.309213836191389
Validation loss: 3.305571609924681

Epoch: 6| Step: 1
Training loss: 0.3737860541352688
Validation loss: 3.2258924846174586

Epoch: 6| Step: 2
Training loss: 0.34568828615572683
Validation loss: 3.2175739077892813

Epoch: 6| Step: 3
Training loss: 0.3020518330340815
Validation loss: 3.243157005130081

Epoch: 6| Step: 4
Training loss: 0.4802085668214353
Validation loss: 3.1680064922299955

Epoch: 6| Step: 5
Training loss: 0.2720770233268694
Validation loss: 3.208385607471088

Epoch: 6| Step: 6
Training loss: 0.3310625418572438
Validation loss: 3.250669117052231

Epoch: 6| Step: 7
Training loss: 0.7221105628832876
Validation loss: 3.2597302251485583

Epoch: 6| Step: 8
Training loss: 0.29639466226355843
Validation loss: 3.1948623899814477

Epoch: 6| Step: 9
Training loss: 0.6367528239301016
Validation loss: 3.2720220475064163

Epoch: 6| Step: 10
Training loss: 0.3018464634124976
Validation loss: 3.2684261470366143

Epoch: 6| Step: 11
Training loss: 0.3249647910046332
Validation loss: 3.332870848678928

Epoch: 6| Step: 12
Training loss: 0.38073779390773915
Validation loss: 3.2281300060015523

Epoch: 6| Step: 13
Training loss: 0.4137870124039397
Validation loss: 3.279257020751684

Epoch: 300| Step: 0
Training loss: 0.7437877869824221
Validation loss: 3.3075813386872386

Epoch: 6| Step: 1
Training loss: 0.4380499584782745
Validation loss: 3.3230395678011657

Epoch: 6| Step: 2
Training loss: 0.2859237479983402
Validation loss: 3.226112796211565

Epoch: 6| Step: 3
Training loss: 0.3107308376692317
Validation loss: 3.2777511470776086

Epoch: 6| Step: 4
Training loss: 0.47518049813605595
Validation loss: 3.333599846834851

Epoch: 6| Step: 5
Training loss: 0.32719003213669573
Validation loss: 3.2125922871357413

Epoch: 6| Step: 6
Training loss: 0.4231010212154051
Validation loss: 3.2457078321007056

Epoch: 6| Step: 7
Training loss: 0.4832187973848384
Validation loss: 3.2524064275997477

Epoch: 6| Step: 8
Training loss: 0.35994544572864784
Validation loss: 3.2616418521062567

Epoch: 6| Step: 9
Training loss: 0.7167286437611442
Validation loss: 3.326541840486294

Epoch: 6| Step: 10
Training loss: 0.4267724076138747
Validation loss: 3.2225891599511147

Epoch: 6| Step: 11
Training loss: 0.3684012056549465
Validation loss: 3.195192864874659

Epoch: 6| Step: 12
Training loss: 0.4341832698343045
Validation loss: 3.2058828747257055

Epoch: 6| Step: 13
Training loss: 0.3304994365973006
Validation loss: 3.1554704465119334

Testing loss: 2.6703085033223477
