Epoch: 1| Step: 0
Training loss: 3.1950039863586426
Validation loss: 2.2788150344821188
Epoch: 5| Step: 1
Training loss: 2.904494524002075
Validation loss: 2.274943127048959
Epoch: 5| Step: 2
Training loss: 2.6419785022735596
Validation loss: 2.272402885148851
Epoch: 5| Step: 3
Training loss: 2.9299943447113037
Validation loss: 2.269307313205527
Epoch: 5| Step: 4
Training loss: 2.6104657649993896
Validation loss: 2.2665742532812434
Epoch: 5| Step: 5
Training loss: 3.1325221061706543
Validation loss: 2.265338379702122
Epoch: 5| Step: 6
Training loss: 2.755305767059326
Validation loss: 2.2636307126326525
Epoch: 5| Step: 7
Training loss: 2.791393756866455
Validation loss: 2.259607647820342
Epoch: 5| Step: 8
Training loss: 2.4202523231506348
Validation loss: 2.2585480118826995
Epoch: 5| Step: 9
Training loss: 2.593820095062256
Validation loss: 2.2561928968635394
Epoch: 2| Step: 0
Training loss: 2.79691219329834
Validation loss: 2.2510614172160195
Epoch: 5| Step: 1
Training loss: 2.547300338745117
Validation loss: 2.2475755609196724
Epoch: 5| Step: 2
Training loss: 2.967707633972168
Validation loss: 2.2450903173830867
Epoch: 5| Step: 3
Training loss: 2.622292995452881
Validation loss: 2.2433047843494003
Epoch: 5| Step: 4
Training loss: 2.3034520149230957
Validation loss: 2.2391631603240967
Epoch: 5| Step: 5
Training loss: 3.375657320022583
Validation loss: 2.238632835072579
Epoch: 5| Step: 6
Training loss: 2.6347970962524414
Validation loss: 2.232582396740536
Epoch: 5| Step: 7
Training loss: 3.0270180702209473
Validation loss: 2.231524325103211
Epoch: 5| Step: 8
Training loss: 2.534533739089966
Validation loss: 2.230290755951147
Epoch: 5| Step: 9
Training loss: 2.870737075805664
Validation loss: 2.226075076370788
Epoch: 3| Step: 0
Training loss: 3.222980499267578
Validation loss: 2.2240081536684104
Epoch: 5| Step: 1
Training loss: 2.8972480297088623
Validation loss: 2.222215993798894
Epoch: 5| Step: 2
Training loss: 2.8073983192443848
Validation loss: 2.2190788701283846
Epoch: 5| Step: 3
Training loss: 2.742483615875244
Validation loss: 2.2157787813557137
Epoch: 5| Step: 4
Training loss: 2.5930118560791016
Validation loss: 2.211999689074729
Epoch: 5| Step: 5
Training loss: 2.6576504707336426
Validation loss: 2.2103282067415524
Epoch: 5| Step: 6
Training loss: 2.549821376800537
Validation loss: 2.2076359687091633
Epoch: 5| Step: 7
Training loss: 2.220780611038208
Validation loss: 2.2037262264773143
Epoch: 5| Step: 8
Training loss: 3.143099308013916
Validation loss: 2.200898062410972
Epoch: 5| Step: 9
Training loss: 2.57426381111145
Validation loss: 2.197757136049888
Epoch: 4| Step: 0
Training loss: 2.9003758430480957
Validation loss: 2.194684054354112
Epoch: 5| Step: 1
Training loss: 2.88187575340271
Validation loss: 2.1924063078791116
Epoch: 5| Step: 2
Training loss: 2.378544807434082
Validation loss: 2.1908469157253236
Epoch: 5| Step: 3
Training loss: 2.872523784637451
Validation loss: 2.1852077854623038
Epoch: 5| Step: 4
Training loss: 2.6233904361724854
Validation loss: 2.1849839970362273
Epoch: 5| Step: 5
Training loss: 2.885889768600464
Validation loss: 2.1825642259858493
Epoch: 5| Step: 6
Training loss: 2.7119274139404297
Validation loss: 2.177029283784276
Epoch: 5| Step: 7
Training loss: 2.3195695877075195
Validation loss: 2.1715168369759756
Epoch: 5| Step: 8
Training loss: 2.7101588249206543
Validation loss: 2.1724084589978774
Epoch: 5| Step: 9
Training loss: 2.8063011169433594
Validation loss: 2.1693092738981727
Epoch: 5| Step: 0
Training loss: 2.345771312713623
Validation loss: 2.166467896468348
Epoch: 5| Step: 1
Training loss: 2.8944220542907715
Validation loss: 2.162747321368979
Epoch: 5| Step: 2
Training loss: 2.332803726196289
Validation loss: 2.158149611178062
Epoch: 5| Step: 3
Training loss: 2.695713996887207
Validation loss: 2.1575323111719364
Epoch: 5| Step: 4
Training loss: 2.7671337127685547
Validation loss: 2.154601088530726
Epoch: 5| Step: 5
Training loss: 2.814169406890869
Validation loss: 2.15027048090379
Epoch: 5| Step: 6
Training loss: 2.4929161071777344
Validation loss: 2.1460853377692133
Epoch: 5| Step: 7
Training loss: 3.246704339981079
Validation loss: 2.1437368598773325
Epoch: 5| Step: 8
Training loss: 2.763914108276367
Validation loss: 2.140218840228568
Epoch: 5| Step: 9
Training loss: 2.4367077350616455
Validation loss: 2.1375274898336944
Epoch: 6| Step: 0
Training loss: 2.3546178340911865
Validation loss: 2.132261775380416
Epoch: 5| Step: 1
Training loss: 2.7771315574645996
Validation loss: 2.1289760105901485
Epoch: 5| Step: 2
Training loss: 2.539853811264038
Validation loss: 2.1282091603862296
Epoch: 5| Step: 3
Training loss: 2.359743595123291
Validation loss: 2.1216482447205687
Epoch: 5| Step: 4
Training loss: 2.2848501205444336
Validation loss: 2.11870496736156
Epoch: 5| Step: 5
Training loss: 2.71809720993042
Validation loss: 2.1188907777662758
Epoch: 5| Step: 6
Training loss: 2.947784900665283
Validation loss: 2.1139139597364465
Epoch: 5| Step: 7
Training loss: 3.040403366088867
Validation loss: 2.1073581451992336
Epoch: 5| Step: 8
Training loss: 2.5322604179382324
Validation loss: 2.103756738223618
Epoch: 5| Step: 9
Training loss: 2.9128756523132324
Validation loss: 2.101707571702038
Epoch: 7| Step: 0
Training loss: 2.5661325454711914
Validation loss: 2.0964845942078734
Epoch: 5| Step: 1
Training loss: 3.0736913681030273
Validation loss: 2.092454466888373
Epoch: 5| Step: 2
Training loss: 2.2823069095611572
Validation loss: 2.0865407127270594
Epoch: 5| Step: 3
Training loss: 2.5372180938720703
Validation loss: 2.0831675958290377
Epoch: 5| Step: 4
Training loss: 2.7096872329711914
Validation loss: 2.07962893067504
Epoch: 5| Step: 5
Training loss: 2.544485569000244
Validation loss: 2.0754964540330625
Epoch: 5| Step: 6
Training loss: 2.4354424476623535
Validation loss: 2.071726044304937
Epoch: 5| Step: 7
Training loss: 2.7985141277313232
Validation loss: 2.066590180499948
Epoch: 5| Step: 8
Training loss: 2.157529354095459
Validation loss: 2.063570033732078
Epoch: 5| Step: 9
Training loss: 2.9543142318725586
Validation loss: 2.0574273325556476
Epoch: 8| Step: 0
Training loss: 2.662034034729004
Validation loss: 2.0573660118116748
Epoch: 5| Step: 1
Training loss: 2.4855782985687256
Validation loss: 2.0490578618838633
Epoch: 5| Step: 2
Training loss: 2.420680046081543
Validation loss: 2.048339187670097
Epoch: 5| Step: 3
Training loss: 2.5011258125305176
Validation loss: 2.043400145263123
Epoch: 5| Step: 4
Training loss: 3.10441517829895
Validation loss: 2.034603362460788
Epoch: 5| Step: 5
Training loss: 2.36972975730896
Validation loss: 2.0323324392167783
Epoch: 5| Step: 6
Training loss: 2.8145573139190674
Validation loss: 2.0312330191083947
Epoch: 5| Step: 7
Training loss: 2.6326680183410645
Validation loss: 2.024932924792063
Epoch: 5| Step: 8
Training loss: 2.398864269256592
Validation loss: 2.0220984083285436
Epoch: 5| Step: 9
Training loss: 2.2634997367858887
Validation loss: 2.0159207908369656
Epoch: 9| Step: 0
Training loss: 2.5891597270965576
Validation loss: 2.0133366867792692
Epoch: 5| Step: 1
Training loss: 2.49721622467041
Validation loss: 2.0067988814209863
Epoch: 5| Step: 2
Training loss: 2.540600299835205
Validation loss: 2.002134004085184
Epoch: 5| Step: 3
Training loss: 2.3108174800872803
Validation loss: 1.9947886012440963
Epoch: 5| Step: 4
Training loss: 2.1417806148529053
Validation loss: 1.9931366889596842
Epoch: 5| Step: 5
Training loss: 2.860567092895508
Validation loss: 1.9872043767421366
Epoch: 5| Step: 6
Training loss: 2.883932113647461
Validation loss: 1.9818411396561766
Epoch: 5| Step: 7
Training loss: 2.317934036254883
Validation loss: 1.9766648964916202
Epoch: 5| Step: 8
Training loss: 2.339956045150757
Validation loss: 1.9722151824896283
Epoch: 5| Step: 9
Training loss: 2.666759490966797
Validation loss: 1.9668501049494571
Epoch: 10| Step: 0
Training loss: 2.291562080383301
Validation loss: 1.9610008747457601
Epoch: 5| Step: 1
Training loss: 2.411759376525879
Validation loss: 1.9576442130177998
Epoch: 5| Step: 2
Training loss: 2.89493989944458
Validation loss: 1.9525810883199568
Epoch: 5| Step: 3
Training loss: 2.6151156425476074
Validation loss: 1.9473064769086221
Epoch: 5| Step: 4
Training loss: 2.2184596061706543
Validation loss: 1.9419061108458815
Epoch: 5| Step: 5
Training loss: 2.702399253845215
Validation loss: 1.9334762319386434
Epoch: 5| Step: 6
Training loss: 1.9693243503570557
Validation loss: 1.9310787658897235
Epoch: 5| Step: 7
Training loss: 2.3601906299591064
Validation loss: 1.9246109895568957
Epoch: 5| Step: 8
Training loss: 2.7130768299102783
Validation loss: 1.9233833114020258
Epoch: 5| Step: 9
Training loss: 2.4684157371520996
Validation loss: 1.9142998842884311
Epoch: 11| Step: 0
Training loss: 2.397186279296875
Validation loss: 1.905706035147468
Epoch: 5| Step: 1
Training loss: 2.4271345138549805
Validation loss: 1.9022003077774596
Epoch: 5| Step: 2
Training loss: 2.4979918003082275
Validation loss: 1.8963057017154832
Epoch: 5| Step: 3
Training loss: 2.1463797092437744
Validation loss: 1.8941585039920945
Epoch: 5| Step: 4
Training loss: 2.6059443950653076
Validation loss: 1.8883771759142978
Epoch: 5| Step: 5
Training loss: 2.541363000869751
Validation loss: 1.8777023236528576
Epoch: 5| Step: 6
Training loss: 2.460578441619873
Validation loss: 1.8742463331428363
Epoch: 5| Step: 7
Training loss: 2.3101155757904053
Validation loss: 1.865242798551381
Epoch: 5| Step: 8
Training loss: 2.1521873474121094
Validation loss: 1.8635628935244444
Epoch: 5| Step: 9
Training loss: 2.5280842781066895
Validation loss: 1.855370065291151
Epoch: 12| Step: 0
Training loss: 2.7801108360290527
Validation loss: 1.8467848669710776
Epoch: 5| Step: 1
Training loss: 1.998468279838562
Validation loss: 1.8414538000985015
Epoch: 5| Step: 2
Training loss: 2.5842065811157227
Validation loss: 1.8357155648924464
Epoch: 5| Step: 3
Training loss: 2.9514760971069336
Validation loss: 1.8346169526628453
Epoch: 5| Step: 4
Training loss: 2.2032041549682617
Validation loss: 1.8204060938718507
Epoch: 5| Step: 5
Training loss: 2.3341879844665527
Validation loss: 1.8152891697643472
Epoch: 5| Step: 6
Training loss: 2.5076332092285156
Validation loss: 1.8127275791099604
Epoch: 5| Step: 7
Training loss: 1.8983235359191895
Validation loss: 1.8028088439282755
Epoch: 5| Step: 8
Training loss: 2.134927988052368
Validation loss: 1.7959612813784922
Epoch: 5| Step: 9
Training loss: 2.0543246269226074
Validation loss: 1.7911078929901123
Epoch: 13| Step: 0
Training loss: 1.9373387098312378
Validation loss: 1.7879134373699161
Epoch: 5| Step: 1
Training loss: 2.3811087608337402
Validation loss: 1.7727305314523711
Epoch: 5| Step: 2
Training loss: 2.680807590484619
Validation loss: 1.77007071834674
Epoch: 5| Step: 3
Training loss: 2.435628890991211
Validation loss: 1.7608553668577893
Epoch: 5| Step: 4
Training loss: 2.197324275970459
Validation loss: 1.7568535684681625
Epoch: 5| Step: 5
Training loss: 2.3958239555358887
Validation loss: 1.7451359179380128
Epoch: 5| Step: 6
Training loss: 2.479053020477295
Validation loss: 1.7440878950434624
Epoch: 5| Step: 7
Training loss: 2.282231330871582
Validation loss: 1.7406504145629114
Epoch: 5| Step: 8
Training loss: 1.7978639602661133
Validation loss: 1.7320835204433194
Epoch: 5| Step: 9
Training loss: 2.2226271629333496
Validation loss: 1.7248048876686919
Epoch: 14| Step: 0
Training loss: 2.1719915866851807
Validation loss: 1.7159344498202098
Epoch: 5| Step: 1
Training loss: 2.49694561958313
Validation loss: 1.7106174496438007
Epoch: 5| Step: 2
Training loss: 1.7457407712936401
Validation loss: 1.7092136993682643
Epoch: 5| Step: 3
Training loss: 2.775043249130249
Validation loss: 1.6977981740622212
Epoch: 5| Step: 4
Training loss: 1.8700534105300903
Validation loss: 1.696990821001341
Epoch: 5| Step: 5
Training loss: 2.2307674884796143
Validation loss: 1.6929431763484324
Epoch: 5| Step: 6
Training loss: 1.8393888473510742
Validation loss: 1.6824911687013915
Epoch: 5| Step: 7
Training loss: 2.230673313140869
Validation loss: 1.6825774179088127
Epoch: 5| Step: 8
Training loss: 2.5898561477661133
Validation loss: 1.6741247159971608
Epoch: 5| Step: 9
Training loss: 2.2403488159179688
Validation loss: 1.6781981034244564
Epoch: 15| Step: 0
Training loss: 2.4152755737304688
Validation loss: 1.6719618478267313
Epoch: 5| Step: 1
Training loss: 1.7622050046920776
Validation loss: 1.6744256679960292
Epoch: 5| Step: 2
Training loss: 2.522810459136963
Validation loss: 1.6654698771538494
Epoch: 5| Step: 3
Training loss: 1.8581372499465942
Validation loss: 1.666087888985229
Epoch: 5| Step: 4
Training loss: 2.198431968688965
Validation loss: 1.6711109936666146
Epoch: 5| Step: 5
Training loss: 2.407363176345825
Validation loss: 1.66524385505443
Epoch: 5| Step: 6
Training loss: 1.8245903253555298
Validation loss: 1.6572003218767455
Epoch: 5| Step: 7
Training loss: 2.6523797512054443
Validation loss: 1.6582465120356717
Epoch: 5| Step: 8
Training loss: 2.198500394821167
Validation loss: 1.654612486311
Epoch: 5| Step: 9
Training loss: 1.8967537879943848
Validation loss: 1.6539767405969634
Epoch: 16| Step: 0
Training loss: 2.280433177947998
Validation loss: 1.6549158276413842
Epoch: 5| Step: 1
Training loss: 2.152059316635132
Validation loss: 1.6495152317362725
Epoch: 5| Step: 2
Training loss: 2.482855796813965
Validation loss: 1.6523876010085181
Epoch: 5| Step: 3
Training loss: 1.9894081354141235
Validation loss: 1.6549660421961503
Epoch: 5| Step: 4
Training loss: 2.1124916076660156
Validation loss: 1.6588037631494537
Epoch: 5| Step: 5
Training loss: 1.90598464012146
Validation loss: 1.6530116547783502
Epoch: 5| Step: 6
Training loss: 2.30117130279541
Validation loss: 1.654185531808318
Epoch: 5| Step: 7
Training loss: 2.4755971431732178
Validation loss: 1.6461860258802234
Epoch: 5| Step: 8
Training loss: 1.6551754474639893
Validation loss: 1.6516973886558477
Epoch: 5| Step: 9
Training loss: 1.9708921909332275
Validation loss: 1.6487999768565884
Epoch: 17| Step: 0
Training loss: 2.8151016235351562
Validation loss: 1.6572730884277562
Epoch: 5| Step: 1
Training loss: 1.8125996589660645
Validation loss: 1.6547674781126942
Epoch: 5| Step: 2
Training loss: 2.2743825912475586
Validation loss: 1.6537046681205145
Epoch: 5| Step: 3
Training loss: 1.8067270517349243
Validation loss: 1.6587396234059506
Epoch: 5| Step: 4
Training loss: 2.1772420406341553
Validation loss: 1.6747670019273277
Epoch: 5| Step: 5
Training loss: 2.0554800033569336
Validation loss: 1.6678511264512865
Epoch: 5| Step: 6
Training loss: 2.126823902130127
Validation loss: 1.670809438760332
Epoch: 5| Step: 7
Training loss: 1.7643241882324219
Validation loss: 1.6741190865743074
Epoch: 5| Step: 8
Training loss: 2.319392681121826
Validation loss: 1.6753174452472934
Epoch: 5| Step: 9
Training loss: 1.9611555337905884
Validation loss: 1.6832430834392849
Epoch: 18| Step: 0
Training loss: 2.705070972442627
Validation loss: 1.6776188354698016
Epoch: 5| Step: 1
Training loss: 2.2729129791259766
Validation loss: 1.6890658466078394
Epoch: 5| Step: 2
Training loss: 1.8918712139129639
Validation loss: 1.6846372240738903
Epoch: 5| Step: 3
Training loss: 1.4822998046875
Validation loss: 1.6968188097151062
Epoch: 5| Step: 4
Training loss: 2.573979377746582
Validation loss: 1.6887202871789178
Epoch: 5| Step: 5
Training loss: 1.765731692314148
Validation loss: 1.6941788145106473
Epoch: 5| Step: 6
Training loss: 2.2383668422698975
Validation loss: 1.7022187349607618
Epoch: 5| Step: 7
Training loss: 2.058285713195801
Validation loss: 1.7042005653861616
Epoch: 5| Step: 8
Training loss: 1.8929500579833984
Validation loss: 1.7080592860420831
Epoch: 5| Step: 9
Training loss: 2.0112032890319824
Validation loss: 1.7163394355087829
Epoch: 19| Step: 0
Training loss: 1.9532583951950073
Validation loss: 1.7130759105407933
Epoch: 5| Step: 1
Training loss: 2.190828800201416
Validation loss: 1.7123515074201625
Epoch: 5| Step: 2
Training loss: 2.3122968673706055
Validation loss: 1.7195865258896093
Epoch: 5| Step: 3
Training loss: 1.7568345069885254
Validation loss: 1.7211785376500741
Epoch: 5| Step: 4
Training loss: 2.1605446338653564
Validation loss: 1.7217177975949625
Epoch: 5| Step: 5
Training loss: 2.322266101837158
Validation loss: 1.7339390113199358
Epoch: 5| Step: 6
Training loss: 1.836572527885437
Validation loss: 1.7358032181966219
Epoch: 5| Step: 7
Training loss: 2.055283308029175
Validation loss: 1.7404198680850242
Epoch: 5| Step: 8
Training loss: 1.893019199371338
Validation loss: 1.7389881199212383
Epoch: 5| Step: 9
Training loss: 2.2616453170776367
Validation loss: 1.7407133484915864
Epoch: 20| Step: 0
Training loss: 1.6465086936950684
Validation loss: 1.7477013018491456
Epoch: 5| Step: 1
Training loss: 1.8339859247207642
Validation loss: 1.7571978217406239
Epoch: 5| Step: 2
Training loss: 2.0013558864593506
Validation loss: 1.7507630663810017
Epoch: 5| Step: 3
Training loss: 2.0291783809661865
Validation loss: 1.7576401954074559
Epoch: 5| Step: 4
Training loss: 2.202226161956787
Validation loss: 1.7546360681382873
Epoch: 5| Step: 5
Training loss: 2.8142731189727783
Validation loss: 1.7598205333133397
Epoch: 5| Step: 6
Training loss: 2.311544895172119
Validation loss: 1.765372091917683
Epoch: 5| Step: 7
Training loss: 1.8816908597946167
Validation loss: 1.7527699770687295
Epoch: 5| Step: 8
Training loss: 1.7892688512802124
Validation loss: 1.7661576725596146
Epoch: 5| Step: 9
Training loss: 2.110311985015869
Validation loss: 1.7674589517305224
Epoch: 21| Step: 0
Training loss: 2.0836479663848877
Validation loss: 1.765177987462325
Epoch: 5| Step: 1
Training loss: 1.8533430099487305
Validation loss: 1.7663145356898686
Epoch: 5| Step: 2
Training loss: 2.066175937652588
Validation loss: 1.771519863348213
Epoch: 5| Step: 3
Training loss: 1.8019706010818481
Validation loss: 1.7743393560107663
Epoch: 5| Step: 4
Training loss: 1.87777578830719
Validation loss: 1.77054222024602
Epoch: 5| Step: 5
Training loss: 2.1221704483032227
Validation loss: 1.776682118717715
Epoch: 5| Step: 6
Training loss: 2.145843505859375
Validation loss: 1.770945085038384
Epoch: 5| Step: 7
Training loss: 2.5356364250183105
Validation loss: 1.7791739642191275
Epoch: 5| Step: 8
Training loss: 2.0897490978240967
Validation loss: 1.7750214604165058
Epoch: 5| Step: 9
Training loss: 2.040820598602295
Validation loss: 1.7804948751874965
Epoch: 22| Step: 0
Training loss: 1.9802212715148926
Validation loss: 1.7845656005598658
Epoch: 5| Step: 1
Training loss: 2.2614407539367676
Validation loss: 1.7816476787594582
Epoch: 5| Step: 2
Training loss: 1.6896233558654785
Validation loss: 1.7821331401523068
Epoch: 5| Step: 3
Training loss: 2.207902431488037
Validation loss: 1.7954515407411316
Epoch: 5| Step: 4
Training loss: 2.2773351669311523
Validation loss: 1.7825265428145154
Epoch: 5| Step: 5
Training loss: 2.0451767444610596
Validation loss: 1.790230182435015
Epoch: 5| Step: 6
Training loss: 2.112083673477173
Validation loss: 1.7993975165936587
Epoch: 5| Step: 7
Training loss: 2.0236382484436035
Validation loss: 1.7897633048270245
Epoch: 5| Step: 8
Training loss: 1.8446781635284424
Validation loss: 1.7921882499036172
Epoch: 5| Step: 9
Training loss: 2.0935606956481934
Validation loss: 1.7904780708628594
Epoch: 23| Step: 0
Training loss: 2.2447593212127686
Validation loss: 1.7969148484922999
Epoch: 5| Step: 1
Training loss: 2.2572641372680664
Validation loss: 1.8019523723519963
Epoch: 5| Step: 2
Training loss: 1.957191824913025
Validation loss: 1.7902919662942132
Epoch: 5| Step: 3
Training loss: 2.4344327449798584
Validation loss: 1.799994285158116
Epoch: 5| Step: 4
Training loss: 2.5403263568878174
Validation loss: 1.7975000031560444
Epoch: 5| Step: 5
Training loss: 1.8328006267547607
Validation loss: 1.7935400540880162
Epoch: 5| Step: 6
Training loss: 1.8131484985351562
Validation loss: 1.782632156241712
Epoch: 5| Step: 7
Training loss: 1.9833760261535645
Validation loss: 1.793890086009348
Epoch: 5| Step: 8
Training loss: 1.3925628662109375
Validation loss: 1.7993152784786637
Epoch: 5| Step: 9
Training loss: 2.0886940956115723
Validation loss: 1.792722973892157
Epoch: 24| Step: 0
Training loss: 1.7866783142089844
Validation loss: 1.7964202997495802
Epoch: 5| Step: 1
Training loss: 2.1074917316436768
Validation loss: 1.7914668707538852
Epoch: 5| Step: 2
Training loss: 2.269216299057007
Validation loss: 1.785689823919063
Epoch: 5| Step: 3
Training loss: 1.8305704593658447
Validation loss: 1.7901341520625054
Epoch: 5| Step: 4
Training loss: 2.340331792831421
Validation loss: 1.7852763031884062
Epoch: 5| Step: 5
Training loss: 2.0253989696502686
Validation loss: 1.7881982369388607
Epoch: 5| Step: 6
Training loss: 2.2985503673553467
Validation loss: 1.7930155983931726
Epoch: 5| Step: 7
Training loss: 1.920194387435913
Validation loss: 1.7844876454030867
Epoch: 5| Step: 8
Training loss: 2.006991386413574
Validation loss: 1.7876853205317216
Epoch: 5| Step: 9
Training loss: 1.9586381912231445
Validation loss: 1.7884642820564105
Epoch: 25| Step: 0
Training loss: 1.961625099182129
Validation loss: 1.7930424762286727
Epoch: 5| Step: 1
Training loss: 2.4773285388946533
Validation loss: 1.7856032290904642
Epoch: 5| Step: 2
Training loss: 2.2749860286712646
Validation loss: 1.7980144366943578
Epoch: 5| Step: 3
Training loss: 1.8282842636108398
Validation loss: 1.7952868947022254
Epoch: 5| Step: 4
Training loss: 1.798419713973999
Validation loss: 1.7971167375715515
Epoch: 5| Step: 5
Training loss: 2.078047275543213
Validation loss: 1.800165847051058
Epoch: 5| Step: 6
Training loss: 2.1731441020965576
Validation loss: 1.8018142748222077
Epoch: 5| Step: 7
Training loss: 1.9780787229537964
Validation loss: 1.7999069742161593
Epoch: 5| Step: 8
Training loss: 2.1744041442871094
Validation loss: 1.8023015286425035
Epoch: 5| Step: 9
Training loss: 1.7802374362945557
Validation loss: 1.800011441004362
Epoch: 26| Step: 0
Training loss: 2.205873966217041
Validation loss: 1.8042965449875208
Epoch: 5| Step: 1
Training loss: 2.1724789142608643
Validation loss: 1.8106731073461848
Epoch: 5| Step: 2
Training loss: 1.8840043544769287
Validation loss: 1.8129334346853572
Epoch: 5| Step: 3
Training loss: 2.4032769203186035
Validation loss: 1.8140510140563086
Epoch: 5| Step: 4
Training loss: 1.787322759628296
Validation loss: 1.8154760350426324
Epoch: 5| Step: 5
Training loss: 2.2827274799346924
Validation loss: 1.805758274716439
Epoch: 5| Step: 6
Training loss: 1.2914597988128662
Validation loss: 1.8210793141838457
Epoch: 5| Step: 7
Training loss: 2.1800575256347656
Validation loss: 1.816438739248317
Epoch: 5| Step: 8
Training loss: 2.244699716567993
Validation loss: 1.814781945386379
Epoch: 5| Step: 9
Training loss: 2.0697946548461914
Validation loss: 1.8097030070188234
Epoch: 27| Step: 0
Training loss: 1.407954454421997
Validation loss: 1.8035035673662914
Epoch: 5| Step: 1
Training loss: 2.3617751598358154
Validation loss: 1.8105849936711702
Epoch: 5| Step: 2
Training loss: 1.9010862112045288
Validation loss: 1.8095107284381236
Epoch: 5| Step: 3
Training loss: 1.833606481552124
Validation loss: 1.8129415331984595
Epoch: 5| Step: 4
Training loss: 2.1912901401519775
Validation loss: 1.8039892448795785
Epoch: 5| Step: 5
Training loss: 1.9904377460479736
Validation loss: 1.8035961569641992
Epoch: 5| Step: 6
Training loss: 2.2783267498016357
Validation loss: 1.814325165405548
Epoch: 5| Step: 7
Training loss: 2.206418991088867
Validation loss: 1.8142024458741113
Epoch: 5| Step: 8
Training loss: 2.473748207092285
Validation loss: 1.8010900792458076
Epoch: 5| Step: 9
Training loss: 1.8071553707122803
Validation loss: 1.7990574613749553
Epoch: 28| Step: 0
Training loss: 1.6474390029907227
Validation loss: 1.8062802964834859
Epoch: 5| Step: 1
Training loss: 2.267477035522461
Validation loss: 1.8073950602853899
Epoch: 5| Step: 2
Training loss: 2.1258130073547363
Validation loss: 1.802463060660328
Epoch: 5| Step: 3
Training loss: 2.4767587184906006
Validation loss: 1.7961669002505516
Epoch: 5| Step: 4
Training loss: 2.4719796180725098
Validation loss: 1.7967253743315772
Epoch: 5| Step: 5
Training loss: 2.329390525817871
Validation loss: 1.8008381179768405
Epoch: 5| Step: 6
Training loss: 2.231503963470459
Validation loss: 1.7984504811197735
Epoch: 5| Step: 7
Training loss: 1.790785789489746
Validation loss: 1.7890022092585942
Epoch: 5| Step: 8
Training loss: 1.544872760772705
Validation loss: 1.801400798687832
Epoch: 5| Step: 9
Training loss: 1.5187644958496094
Validation loss: 1.7964405301663515
Epoch: 29| Step: 0
Training loss: 1.9525141716003418
Validation loss: 1.799256674677348
Epoch: 5| Step: 1
Training loss: 2.4190406799316406
Validation loss: 1.7898591859735173
Epoch: 5| Step: 2
Training loss: 1.934462308883667
Validation loss: 1.8048407508314943
Epoch: 5| Step: 3
Training loss: 1.8779888153076172
Validation loss: 1.791791318989486
Epoch: 5| Step: 4
Training loss: 2.196953058242798
Validation loss: 1.7914364766731536
Epoch: 5| Step: 5
Training loss: 1.9411920309066772
Validation loss: 1.7939306111644497
Epoch: 5| Step: 6
Training loss: 2.201289653778076
Validation loss: 1.7992208201250584
Epoch: 5| Step: 7
Training loss: 1.7558090686798096
Validation loss: 1.7971212503721388
Epoch: 5| Step: 8
Training loss: 2.111952781677246
Validation loss: 1.7982928735746755
Epoch: 5| Step: 9
Training loss: 2.085127592086792
Validation loss: 1.797035671824174
Epoch: 30| Step: 0
Training loss: 1.8628227710723877
Validation loss: 1.7964766951773663
Epoch: 5| Step: 1
Training loss: 2.212322235107422
Validation loss: 1.790478651472133
Epoch: 5| Step: 2
Training loss: 2.368196964263916
Validation loss: 1.8021403070834043
Epoch: 5| Step: 3
Training loss: 1.8413251638412476
Validation loss: 1.7813704485515895
Epoch: 5| Step: 4
Training loss: 2.072580337524414
Validation loss: 1.7959368065964403
Epoch: 5| Step: 5
Training loss: 1.9484755992889404
Validation loss: 1.7942205170075671
Epoch: 5| Step: 6
Training loss: 2.215488910675049
Validation loss: 1.8020318420670873
Epoch: 5| Step: 7
Training loss: 2.506763219833374
Validation loss: 1.7906065861955822
Epoch: 5| Step: 8
Training loss: 1.613896369934082
Validation loss: 1.8010271041513346
Epoch: 5| Step: 9
Training loss: 1.807053565979004
Validation loss: 1.7986883422453626
Epoch: 31| Step: 0
Training loss: 2.162321090698242
Validation loss: 1.7893329867356116
Epoch: 5| Step: 1
Training loss: 1.8698986768722534
Validation loss: 1.7972102216679415
Epoch: 5| Step: 2
Training loss: 2.423583507537842
Validation loss: 1.7969022972120656
Epoch: 5| Step: 3
Training loss: 1.8525004386901855
Validation loss: 1.7863913783066565
Epoch: 5| Step: 4
Training loss: 1.946640968322754
Validation loss: 1.7902060309760004
Epoch: 5| Step: 5
Training loss: 2.1014299392700195
Validation loss: 1.791902318275232
Epoch: 5| Step: 6
Training loss: 1.763503909111023
Validation loss: 1.797614793125674
Epoch: 5| Step: 7
Training loss: 2.0546014308929443
Validation loss: 1.7930062674789977
Epoch: 5| Step: 8
Training loss: 2.32177734375
Validation loss: 1.7931784811637383
Epoch: 5| Step: 9
Training loss: 1.908236026763916
Validation loss: 1.7850719115716949
Epoch: 32| Step: 0
Training loss: 2.1393721103668213
Validation loss: 1.7945560517070962
Epoch: 5| Step: 1
Training loss: 1.76028573513031
Validation loss: 1.7940117506672153
Epoch: 5| Step: 2
Training loss: 1.885632038116455
Validation loss: 1.7924579287604463
Epoch: 5| Step: 3
Training loss: 2.248664140701294
Validation loss: 1.7947511364230149
Epoch: 5| Step: 4
Training loss: 1.8422962427139282
Validation loss: 1.797566177176057
Epoch: 5| Step: 5
Training loss: 2.386321783065796
Validation loss: 1.7990166935131704
Epoch: 5| Step: 6
Training loss: 2.471339464187622
Validation loss: 1.8035923491278998
Epoch: 5| Step: 7
Training loss: 2.0422160625457764
Validation loss: 1.8085767862608106
Epoch: 5| Step: 8
Training loss: 1.8840528726577759
Validation loss: 1.7958193631480923
Epoch: 5| Step: 9
Training loss: 1.7665274143218994
Validation loss: 1.8004742877946482
Epoch: 33| Step: 0
Training loss: 1.659050464630127
Validation loss: 1.7922478511179094
Epoch: 5| Step: 1
Training loss: 2.1916708946228027
Validation loss: 1.7973434007425102
Epoch: 5| Step: 2
Training loss: 2.1049602031707764
Validation loss: 1.7980746897004491
Epoch: 5| Step: 3
Training loss: 2.27734375
Validation loss: 1.7942636621941765
Epoch: 5| Step: 4
Training loss: 1.6778721809387207
Validation loss: 1.7987259086087453
Epoch: 5| Step: 5
Training loss: 2.020291328430176
Validation loss: 1.790988843218028
Epoch: 5| Step: 6
Training loss: 2.11488676071167
Validation loss: 1.8024558283442216
Epoch: 5| Step: 7
Training loss: 2.2058918476104736
Validation loss: 1.7895224703301629
Epoch: 5| Step: 8
Training loss: 2.083656072616577
Validation loss: 1.7947911307108488
Epoch: 5| Step: 9
Training loss: 2.0346145629882812
Validation loss: 1.7980816758793892
Epoch: 34| Step: 0
Training loss: 1.9886369705200195
Validation loss: 1.7867164851950228
Epoch: 5| Step: 1
Training loss: 1.7773489952087402
Validation loss: 1.7911585552229299
Epoch: 5| Step: 2
Training loss: 2.039782762527466
Validation loss: 1.782661600936231
Epoch: 5| Step: 3
Training loss: 1.5668774843215942
Validation loss: 1.7845815428726965
Epoch: 5| Step: 4
Training loss: 2.4883522987365723
Validation loss: 1.7713346172579758
Epoch: 5| Step: 5
Training loss: 2.133866548538208
Validation loss: 1.7812718204457125
Epoch: 5| Step: 6
Training loss: 1.9411064386367798
Validation loss: 1.7802383530911783
Epoch: 5| Step: 7
Training loss: 2.182295799255371
Validation loss: 1.7851626487087002
Epoch: 5| Step: 8
Training loss: 2.299210548400879
Validation loss: 1.782788014240402
Epoch: 5| Step: 9
Training loss: 1.9660964012145996
Validation loss: 1.7840217137508254
Epoch: 35| Step: 0
Training loss: 2.052673101425171
Validation loss: 1.7891286911724282
Epoch: 5| Step: 1
Training loss: 2.002096652984619
Validation loss: 1.7743728186586778
Epoch: 5| Step: 2
Training loss: 1.6729416847229004
Validation loss: 1.7718389737520286
Epoch: 5| Step: 3
Training loss: 1.8164284229278564
Validation loss: 1.7731858273204282
Epoch: 5| Step: 4
Training loss: 1.9541478157043457
Validation loss: 1.7841773830729424
Epoch: 5| Step: 5
Training loss: 2.1647465229034424
Validation loss: 1.7697753734725843
Epoch: 5| Step: 6
Training loss: 2.674708366394043
Validation loss: 1.7789001439115126
Epoch: 5| Step: 7
Training loss: 1.7591242790222168
Validation loss: 1.7830558989545424
Epoch: 5| Step: 8
Training loss: 1.7819488048553467
Validation loss: 1.784490676234952
Epoch: 5| Step: 9
Training loss: 2.4305496215820312
Validation loss: 1.783270479106217
Epoch: 36| Step: 0
Training loss: 2.35775089263916
Validation loss: 1.7766349821639575
Epoch: 5| Step: 1
Training loss: 2.173638343811035
Validation loss: 1.787685991191178
Epoch: 5| Step: 2
Training loss: 1.7918065786361694
Validation loss: 1.7730296875933091
Epoch: 5| Step: 3
Training loss: 2.473782539367676
Validation loss: 1.7772343956309258
Epoch: 5| Step: 4
Training loss: 1.6943466663360596
Validation loss: 1.7815685778213062
Epoch: 5| Step: 5
Training loss: 2.5429201126098633
Validation loss: 1.776536197971097
Epoch: 5| Step: 6
Training loss: 1.6260275840759277
Validation loss: 1.7857282084526775
Epoch: 5| Step: 7
Training loss: 1.39364492893219
Validation loss: 1.7687335400272617
Epoch: 5| Step: 8
Training loss: 2.034637451171875
Validation loss: 1.7810260957951167
Epoch: 5| Step: 9
Training loss: 2.2630019187927246
Validation loss: 1.7834259511755526
Epoch: 37| Step: 0
Training loss: 1.5577775239944458
Validation loss: 1.7844390320263321
Epoch: 5| Step: 1
Training loss: 1.8807637691497803
Validation loss: 1.777931299140985
Epoch: 5| Step: 2
Training loss: 1.7324161529541016
Validation loss: 1.7852416733186023
Epoch: 5| Step: 3
Training loss: 1.8489716053009033
Validation loss: 1.789729668082093
Epoch: 5| Step: 4
Training loss: 2.467430591583252
Validation loss: 1.779049851911531
Epoch: 5| Step: 5
Training loss: 2.3546242713928223
Validation loss: 1.7948807752389702
Epoch: 5| Step: 6
Training loss: 2.2146403789520264
Validation loss: 1.8005298599064778
Epoch: 5| Step: 7
Training loss: 1.9001531600952148
Validation loss: 1.7911628887807722
Epoch: 5| Step: 8
Training loss: 1.9916183948516846
Validation loss: 1.797096435972255
Epoch: 5| Step: 9
Training loss: 2.361309289932251
Validation loss: 1.791119200720204
Epoch: 38| Step: 0
Training loss: 2.0309550762176514
Validation loss: 1.792831087283951
Epoch: 5| Step: 1
Training loss: 1.5997707843780518
Validation loss: 1.7972634859222303
Epoch: 5| Step: 2
Training loss: 2.091370105743408
Validation loss: 1.787922035875938
Epoch: 5| Step: 3
Training loss: 1.9851624965667725
Validation loss: 1.7977858172903816
Epoch: 5| Step: 4
Training loss: 1.6458408832550049
Validation loss: 1.7882400605318358
Epoch: 5| Step: 5
Training loss: 2.6039130687713623
Validation loss: 1.7824391469681005
Epoch: 5| Step: 6
Training loss: 2.169339656829834
Validation loss: 1.7905090438376228
Epoch: 5| Step: 7
Training loss: 1.9752856492996216
Validation loss: 1.7794618718058086
Epoch: 5| Step: 8
Training loss: 2.2587547302246094
Validation loss: 1.7886560194783931
Epoch: 5| Step: 9
Training loss: 1.960740327835083
Validation loss: 1.7834270069067426
Epoch: 39| Step: 0
Training loss: 1.8656799793243408
Validation loss: 1.7825210051570866
Epoch: 5| Step: 1
Training loss: 1.8538655042648315
Validation loss: 1.785620944105464
Epoch: 5| Step: 2
Training loss: 2.250422239303589
Validation loss: 1.7899436170248677
Epoch: 5| Step: 3
Training loss: 2.8016140460968018
Validation loss: 1.7802906259358358
Epoch: 5| Step: 4
Training loss: 1.4612349271774292
Validation loss: 1.798259723100731
Epoch: 5| Step: 5
Training loss: 2.5287811756134033
Validation loss: 1.785038199356134
Epoch: 5| Step: 6
Training loss: 2.1502978801727295
Validation loss: 1.7918161102336088
Epoch: 5| Step: 7
Training loss: 1.5596230030059814
Validation loss: 1.7863839504530103
Epoch: 5| Step: 8
Training loss: 1.7423334121704102
Validation loss: 1.793362231563321
Epoch: 5| Step: 9
Training loss: 2.0743207931518555
Validation loss: 1.7850608568397357
Epoch: 40| Step: 0
Training loss: 2.260706901550293
Validation loss: 1.7908567241627535
Epoch: 5| Step: 1
Training loss: 2.4375858306884766
Validation loss: 1.7780459827656367
Epoch: 5| Step: 2
Training loss: 2.3179731369018555
Validation loss: 1.791908702404379
Epoch: 5| Step: 3
Training loss: 2.0393800735473633
Validation loss: 1.7802698140521702
Epoch: 5| Step: 4
Training loss: 1.9683382511138916
Validation loss: 1.7893222836281757
Epoch: 5| Step: 5
Training loss: 1.777239203453064
Validation loss: 1.7879858866012355
Epoch: 5| Step: 6
Training loss: 2.2810816764831543
Validation loss: 1.7846903629440198
Epoch: 5| Step: 7
Training loss: 1.5182242393493652
Validation loss: 1.7725109445105354
Epoch: 5| Step: 8
Training loss: 1.8884401321411133
Validation loss: 1.7816787177710225
Epoch: 5| Step: 9
Training loss: 1.7667778730392456
Validation loss: 1.7837490117807182
Epoch: 41| Step: 0
Training loss: 2.358398914337158
Validation loss: 1.7876220058194168
Epoch: 5| Step: 1
Training loss: 1.7443784475326538
Validation loss: 1.7959124330136416
Epoch: 5| Step: 2
Training loss: 1.8868317604064941
Validation loss: 1.7863128168119802
Epoch: 5| Step: 3
Training loss: 2.2027831077575684
Validation loss: 1.788657849641155
Epoch: 5| Step: 4
Training loss: 1.929945468902588
Validation loss: 1.7935640597514968
Epoch: 5| Step: 5
Training loss: 2.0339226722717285
Validation loss: 1.765645037452094
Epoch: 5| Step: 6
Training loss: 2.434202194213867
Validation loss: 1.7880144290786852
Epoch: 5| Step: 7
Training loss: 1.8915495872497559
Validation loss: 1.7718105684939047
Epoch: 5| Step: 8
Training loss: 1.621732234954834
Validation loss: 1.7876442053335175
Epoch: 5| Step: 9
Training loss: 2.1880407333374023
Validation loss: 1.7845714984180259
Epoch: 42| Step: 0
Training loss: 1.9733456373214722
Validation loss: 1.7840386714866694
Epoch: 5| Step: 1
Training loss: 1.7216229438781738
Validation loss: 1.7868709710004518
Epoch: 5| Step: 2
Training loss: 1.7547857761383057
Validation loss: 1.7939642753532465
Epoch: 5| Step: 3
Training loss: 2.0793192386627197
Validation loss: 1.7970710401054766
Epoch: 5| Step: 4
Training loss: 2.378594398498535
Validation loss: 1.7991308865787314
Epoch: 5| Step: 5
Training loss: 1.9712694883346558
Validation loss: 1.8000914510205495
Epoch: 5| Step: 6
Training loss: 2.284839153289795
Validation loss: 1.8027137646572196
Epoch: 5| Step: 7
Training loss: 2.1299149990081787
Validation loss: 1.7903034052402853
Epoch: 5| Step: 8
Training loss: 1.9654829502105713
Validation loss: 1.8068574692705552
Epoch: 5| Step: 9
Training loss: 1.9474852085113525
Validation loss: 1.8027079534187591
Epoch: 43| Step: 0
Training loss: 1.7336817979812622
Validation loss: 1.809387340820093
Epoch: 5| Step: 1
Training loss: 1.9989564418792725
Validation loss: 1.7862391111662062
Epoch: 5| Step: 2
Training loss: 1.9342259168624878
Validation loss: 1.7920447236342396
Epoch: 5| Step: 3
Training loss: 2.217721939086914
Validation loss: 1.7920031393174645
Epoch: 5| Step: 4
Training loss: 1.982176661491394
Validation loss: 1.7945692993754105
Epoch: 5| Step: 5
Training loss: 2.0381908416748047
Validation loss: 1.7852329761861898
Epoch: 5| Step: 6
Training loss: 2.0256471633911133
Validation loss: 1.7861569613861523
Epoch: 5| Step: 7
Training loss: 2.2585744857788086
Validation loss: 1.7909135732719366
Epoch: 5| Step: 8
Training loss: 2.0700693130493164
Validation loss: 1.7861175983072184
Epoch: 5| Step: 9
Training loss: 1.9710075855255127
Validation loss: 1.7902602197454989
Epoch: 44| Step: 0
Training loss: 2.239074230194092
Validation loss: 1.7823617775663196
Epoch: 5| Step: 1
Training loss: 1.819361686706543
Validation loss: 1.7756583793557805
Epoch: 5| Step: 2
Training loss: 2.2241013050079346
Validation loss: 1.786066413783341
Epoch: 5| Step: 3
Training loss: 2.218484878540039
Validation loss: 1.7844651268540526
Epoch: 5| Step: 4
Training loss: 2.5058884620666504
Validation loss: 1.785286675254218
Epoch: 5| Step: 5
Training loss: 2.1636948585510254
Validation loss: 1.7799569265447932
Epoch: 5| Step: 6
Training loss: 2.0795459747314453
Validation loss: 1.7740137817190706
Epoch: 5| Step: 7
Training loss: 1.8827202320098877
Validation loss: 1.7745527689405483
Epoch: 5| Step: 8
Training loss: 1.4740116596221924
Validation loss: 1.7730734476940238
Epoch: 5| Step: 9
Training loss: 1.6939526796340942
Validation loss: 1.774896774360602
Epoch: 45| Step: 0
Training loss: 1.586218237876892
Validation loss: 1.7678775332814498
Epoch: 5| Step: 1
Training loss: 2.0513739585876465
Validation loss: 1.7712633532585857
Epoch: 5| Step: 2
Training loss: 2.0935521125793457
Validation loss: 1.764488296543094
Epoch: 5| Step: 3
Training loss: 2.0909993648529053
Validation loss: 1.7626057871811682
Epoch: 5| Step: 4
Training loss: 2.4604151248931885
Validation loss: 1.7742333000512431
Epoch: 5| Step: 5
Training loss: 1.8077268600463867
Validation loss: 1.7618756714484674
Epoch: 5| Step: 6
Training loss: 2.277960777282715
Validation loss: 1.7686924831472712
Epoch: 5| Step: 7
Training loss: 2.0497124195098877
Validation loss: 1.7735355835166766
Epoch: 5| Step: 8
Training loss: 1.9636592864990234
Validation loss: 1.771279438794088
Epoch: 5| Step: 9
Training loss: 1.7828837633132935
Validation loss: 1.760830210267211
Epoch: 46| Step: 0
Training loss: 1.956608772277832
Validation loss: 1.7696069521869686
Epoch: 5| Step: 1
Training loss: 1.8600153923034668
Validation loss: 1.7828410649471145
Epoch: 5| Step: 2
Training loss: 1.9734731912612915
Validation loss: 1.773518312749245
Epoch: 5| Step: 3
Training loss: 1.956421136856079
Validation loss: 1.7699293532817484
Epoch: 5| Step: 4
Training loss: 2.1474897861480713
Validation loss: 1.7856475775190395
Epoch: 5| Step: 5
Training loss: 2.054326057434082
Validation loss: 1.780334443497143
Epoch: 5| Step: 6
Training loss: 2.334959030151367
Validation loss: 1.786244382961191
Epoch: 5| Step: 7
Training loss: 2.3960702419281006
Validation loss: 1.7764810864016307
Epoch: 5| Step: 8
Training loss: 1.7096848487854004
Validation loss: 1.7841055298880708
Epoch: 5| Step: 9
Training loss: 1.8321171998977661
Validation loss: 1.7815280269375808
Epoch: 47| Step: 0
Training loss: 1.8565772771835327
Validation loss: 1.7961353063583374
Epoch: 5| Step: 1
Training loss: 2.159353017807007
Validation loss: 1.77888854115987
Epoch: 5| Step: 2
Training loss: 2.468308210372925
Validation loss: 1.7891071606025422
Epoch: 5| Step: 3
Training loss: 1.8900938034057617
Validation loss: 1.785882308328752
Epoch: 5| Step: 4
Training loss: 2.1198370456695557
Validation loss: 1.7740310850760919
Epoch: 5| Step: 5
Training loss: 2.038245439529419
Validation loss: 1.7786154669823406
Epoch: 5| Step: 6
Training loss: 2.352515935897827
Validation loss: 1.7703286829612237
Epoch: 5| Step: 7
Training loss: 1.500562071800232
Validation loss: 1.7747662581985804
Epoch: 5| Step: 8
Training loss: 1.793375849723816
Validation loss: 1.7829449828580128
Epoch: 5| Step: 9
Training loss: 1.9898087978363037
Validation loss: 1.7882417611938586
Epoch: 48| Step: 0
Training loss: 1.8240160942077637
Validation loss: 1.7824692477425226
Epoch: 5| Step: 1
Training loss: 2.3665642738342285
Validation loss: 1.7894905213829424
Epoch: 5| Step: 2
Training loss: 2.6547796726226807
Validation loss: 1.7900913936628713
Epoch: 5| Step: 3
Training loss: 1.9016435146331787
Validation loss: 1.791709385329871
Epoch: 5| Step: 4
Training loss: 1.6495635509490967
Validation loss: 1.7914401833102
Epoch: 5| Step: 5
Training loss: 1.7422447204589844
Validation loss: 1.7952187738830236
Epoch: 5| Step: 6
Training loss: 1.8830513954162598
Validation loss: 1.792107757046926
Epoch: 5| Step: 7
Training loss: 2.161726951599121
Validation loss: 1.7900110131545033
Epoch: 5| Step: 8
Training loss: 2.048809051513672
Validation loss: 1.7877237711021368
Epoch: 5| Step: 9
Training loss: 2.0053606033325195
Validation loss: 1.7926665150004326
Epoch: 49| Step: 0
Training loss: 1.710235834121704
Validation loss: 1.7823350386653873
Epoch: 5| Step: 1
Training loss: 1.5810707807540894
Validation loss: 1.787765569824109
Epoch: 5| Step: 2
Training loss: 2.137033462524414
Validation loss: 1.7918367977622602
Epoch: 5| Step: 3
Training loss: 2.1088764667510986
Validation loss: 1.7951415391277066
Epoch: 5| Step: 4
Training loss: 1.927746295928955
Validation loss: 1.7929359511505785
Epoch: 5| Step: 5
Training loss: 1.9802907705307007
Validation loss: 1.7915432427426894
Epoch: 5| Step: 6
Training loss: 2.0055434703826904
Validation loss: 1.7855702098325001
Epoch: 5| Step: 7
Training loss: 2.2884316444396973
Validation loss: 1.7999162631069157
Epoch: 5| Step: 8
Training loss: 1.9255131483078003
Validation loss: 1.7984548043861663
Epoch: 5| Step: 9
Training loss: 2.4989748001098633
Validation loss: 1.797826173494188
Epoch: 50| Step: 0
Training loss: 1.9080350399017334
Validation loss: 1.8059520318353777
Epoch: 5| Step: 1
Training loss: 2.6288490295410156
Validation loss: 1.7867990552092627
Epoch: 5| Step: 2
Training loss: 2.0793542861938477
Validation loss: 1.783805109614091
Epoch: 5| Step: 3
Training loss: 1.8699568510055542
Validation loss: 1.7928338265247483
Epoch: 5| Step: 4
Training loss: 1.6915361881256104
Validation loss: 1.7749666061332758
Epoch: 5| Step: 5
Training loss: 2.0782315731048584
Validation loss: 1.7934680002198802
Epoch: 5| Step: 6
Training loss: 1.8784490823745728
Validation loss: 1.783093708024608
Epoch: 5| Step: 7
Training loss: 2.2059288024902344
Validation loss: 1.7840160800398683
Epoch: 5| Step: 8
Training loss: 1.9165765047073364
Validation loss: 1.7713414061841348
Epoch: 5| Step: 9
Training loss: 1.9122231006622314
Validation loss: 1.7788613014083972
Epoch: 51| Step: 0
Training loss: 2.336803913116455
Validation loss: 1.7812273408011567
Epoch: 5| Step: 1
Training loss: 2.0003161430358887
Validation loss: 1.7690936472776124
Epoch: 5| Step: 2
Training loss: 1.711356520652771
Validation loss: 1.7700498327076863
Epoch: 5| Step: 3
Training loss: 2.273146152496338
Validation loss: 1.7668378850538953
Epoch: 5| Step: 4
Training loss: 1.9037853479385376
Validation loss: 1.7741841275057346
Epoch: 5| Step: 5
Training loss: 1.7732489109039307
Validation loss: 1.7706851667637447
Epoch: 5| Step: 6
Training loss: 2.0400266647338867
Validation loss: 1.7755537153147964
Epoch: 5| Step: 7
Training loss: 1.966253399848938
Validation loss: 1.772243546067382
Epoch: 5| Step: 8
Training loss: 2.0097250938415527
Validation loss: 1.7695718480528688
Epoch: 5| Step: 9
Training loss: 2.1617870330810547
Validation loss: 1.7637249668725103
Epoch: 52| Step: 0
Training loss: 1.9473131895065308
Validation loss: 1.7677087509374825
Epoch: 5| Step: 1
Training loss: 2.127504348754883
Validation loss: 1.7715579288468943
Epoch: 5| Step: 2
Training loss: 2.015437602996826
Validation loss: 1.77521572438933
Epoch: 5| Step: 3
Training loss: 2.157154083251953
Validation loss: 1.7706693230773047
Epoch: 5| Step: 4
Training loss: 1.7638022899627686
Validation loss: 1.7805131322188343
Epoch: 5| Step: 5
Training loss: 2.0663275718688965
Validation loss: 1.7762012310165296
Epoch: 5| Step: 6
Training loss: 2.2160983085632324
Validation loss: 1.783806704788757
Epoch: 5| Step: 7
Training loss: 1.7458161115646362
Validation loss: 1.7775420447905286
Epoch: 5| Step: 8
Training loss: 1.9614615440368652
Validation loss: 1.7756248532439307
Epoch: 5| Step: 9
Training loss: 2.090928316116333
Validation loss: 1.7709812757780226
Epoch: 53| Step: 0
Training loss: 1.8174864053726196
Validation loss: 1.7800120115280151
Epoch: 5| Step: 1
Training loss: 2.454807996749878
Validation loss: 1.7863037963565305
Epoch: 5| Step: 2
Training loss: 1.9342252016067505
Validation loss: 1.785597081664655
Epoch: 5| Step: 3
Training loss: 1.9004733562469482
Validation loss: 1.7873758231993202
Epoch: 5| Step: 4
Training loss: 1.6766629219055176
Validation loss: 1.7760624782644587
Epoch: 5| Step: 5
Training loss: 2.088956832885742
Validation loss: 1.7847796061056123
Epoch: 5| Step: 6
Training loss: 2.182332992553711
Validation loss: 1.780280160389358
Epoch: 5| Step: 7
Training loss: 1.8390268087387085
Validation loss: 1.7788097729785837
Epoch: 5| Step: 8
Training loss: 1.9790605306625366
Validation loss: 1.7815420567560538
Epoch: 5| Step: 9
Training loss: 2.284158706665039
Validation loss: 1.779563299185938
Epoch: 54| Step: 0
Training loss: 1.858647346496582
Validation loss: 1.77891890093577
Epoch: 5| Step: 1
Training loss: 2.0122835636138916
Validation loss: 1.780098780453634
Epoch: 5| Step: 2
Training loss: 1.7466706037521362
Validation loss: 1.7824963699999472
Epoch: 5| Step: 3
Training loss: 2.437525749206543
Validation loss: 1.7905177203871363
Epoch: 5| Step: 4
Training loss: 1.9169825315475464
Validation loss: 1.7877119033456705
Epoch: 5| Step: 5
Training loss: 1.6953613758087158
Validation loss: 1.7822147316212276
Epoch: 5| Step: 6
Training loss: 2.1348490715026855
Validation loss: 1.791294808868024
Epoch: 5| Step: 7
Training loss: 1.8046011924743652
Validation loss: 1.791470202610647
Epoch: 5| Step: 8
Training loss: 1.9885960817337036
Validation loss: 1.7837964519322347
Epoch: 5| Step: 9
Training loss: 2.5149526596069336
Validation loss: 1.773418923933729
Epoch: 55| Step: 0
Training loss: 1.7241615056991577
Validation loss: 1.776835249482299
Epoch: 5| Step: 1
Training loss: 1.9617475271224976
Validation loss: 1.7753684211977951
Epoch: 5| Step: 2
Training loss: 1.7035958766937256
Validation loss: 1.7778249198584248
Epoch: 5| Step: 3
Training loss: 2.252497434616089
Validation loss: 1.7793645944526728
Epoch: 5| Step: 4
Training loss: 1.5922043323516846
Validation loss: 1.7750199355667444
Epoch: 5| Step: 5
Training loss: 2.319049119949341
Validation loss: 1.7730158919053112
Epoch: 5| Step: 6
Training loss: 1.908067226409912
Validation loss: 1.776426352185311
Epoch: 5| Step: 7
Training loss: 1.8273457288742065
Validation loss: 1.780482631793125
Epoch: 5| Step: 8
Training loss: 2.3265838623046875
Validation loss: 1.7742949235353538
Epoch: 5| Step: 9
Training loss: 2.449751615524292
Validation loss: 1.780240734704107
Epoch: 56| Step: 0
Training loss: 2.202788829803467
Validation loss: 1.7731638486436803
Epoch: 5| Step: 1
Training loss: 1.7221155166625977
Validation loss: 1.774254418963151
Epoch: 5| Step: 2
Training loss: 2.2609424591064453
Validation loss: 1.7707641330554331
Epoch: 5| Step: 3
Training loss: 1.6049368381500244
Validation loss: 1.7742757771512587
Epoch: 5| Step: 4
Training loss: 2.118285655975342
Validation loss: 1.7800138554127096
Epoch: 5| Step: 5
Training loss: 2.184612512588501
Validation loss: 1.7715917662750902
Epoch: 5| Step: 6
Training loss: 2.1788530349731445
Validation loss: 1.7668186932158985
Epoch: 5| Step: 7
Training loss: 1.576240062713623
Validation loss: 1.7704918693295486
Epoch: 5| Step: 8
Training loss: 2.2399544715881348
Validation loss: 1.7750244843874046
Epoch: 5| Step: 9
Training loss: 1.933586597442627
Validation loss: 1.778897948402295
Epoch: 57| Step: 0
Training loss: 2.337007999420166
Validation loss: 1.7696154906595354
Epoch: 5| Step: 1
Training loss: 2.080843687057495
Validation loss: 1.7683826367632092
Epoch: 5| Step: 2
Training loss: 1.5842058658599854
Validation loss: 1.7658992714161494
Epoch: 5| Step: 3
Training loss: 1.8587301969528198
Validation loss: 1.7720341922567904
Epoch: 5| Step: 4
Training loss: 2.490579128265381
Validation loss: 1.7690005937068582
Epoch: 5| Step: 5
Training loss: 1.6790612936019897
Validation loss: 1.767743476860815
Epoch: 5| Step: 6
Training loss: 1.805340051651001
Validation loss: 1.7695985372117955
Epoch: 5| Step: 7
Training loss: 2.1037983894348145
Validation loss: 1.7701687006641635
Epoch: 5| Step: 8
Training loss: 2.116142749786377
Validation loss: 1.7763897146252419
Epoch: 5| Step: 9
Training loss: 2.003955841064453
Validation loss: 1.7593767685855892
Epoch: 58| Step: 0
Training loss: 1.7031478881835938
Validation loss: 1.7647663663617141
Epoch: 5| Step: 1
Training loss: 1.91019606590271
Validation loss: 1.7727818334702965
Epoch: 5| Step: 2
Training loss: 1.8736402988433838
Validation loss: 1.7712873760744823
Epoch: 5| Step: 3
Training loss: 2.158694267272949
Validation loss: 1.771601697523817
Epoch: 5| Step: 4
Training loss: 1.9522855281829834
Validation loss: 1.772799144545905
Epoch: 5| Step: 5
Training loss: 2.1154820919036865
Validation loss: 1.7831006315972309
Epoch: 5| Step: 6
Training loss: 1.9047703742980957
Validation loss: 1.7923405976604214
Epoch: 5| Step: 7
Training loss: 1.8691229820251465
Validation loss: 1.7926089857979643
Epoch: 5| Step: 8
Training loss: 2.0577526092529297
Validation loss: 1.7864279403960963
Epoch: 5| Step: 9
Training loss: 2.44443678855896
Validation loss: 1.7894440674953322
Epoch: 59| Step: 0
Training loss: 2.0366501808166504
Validation loss: 1.7834986782760072
Epoch: 5| Step: 1
Training loss: 2.2655935287475586
Validation loss: 1.8034173293079403
Epoch: 5| Step: 2
Training loss: 1.8254101276397705
Validation loss: 1.8026334373213404
Epoch: 5| Step: 3
Training loss: 2.152691602706909
Validation loss: 1.7965172177596058
Epoch: 5| Step: 4
Training loss: 1.7801867723464966
Validation loss: 1.7990655847590604
Epoch: 5| Step: 5
Training loss: 2.1977591514587402
Validation loss: 1.7956927457301737
Epoch: 5| Step: 6
Training loss: 1.9483705759048462
Validation loss: 1.7810457395992692
Epoch: 5| Step: 7
Training loss: 1.7745842933654785
Validation loss: 1.807696867332184
Epoch: 5| Step: 8
Training loss: 1.9824919700622559
Validation loss: 1.7977649951152663
Epoch: 5| Step: 9
Training loss: 2.0328502655029297
Validation loss: 1.7924055847332632
Epoch: 60| Step: 0
Training loss: 2.0437347888946533
Validation loss: 1.782018828735077
Epoch: 5| Step: 1
Training loss: 2.324063301086426
Validation loss: 1.7782296774198683
Epoch: 5| Step: 2
Training loss: 2.52663516998291
Validation loss: 1.7825204519916782
Epoch: 5| Step: 3
Training loss: 1.622006893157959
Validation loss: 1.7912009302660716
Epoch: 5| Step: 4
Training loss: 1.9924421310424805
Validation loss: 1.7962957414791738
Epoch: 5| Step: 5
Training loss: 1.8074370622634888
Validation loss: 1.777243833747699
Epoch: 5| Step: 6
Training loss: 2.357698917388916
Validation loss: 1.780150375777869
Epoch: 5| Step: 7
Training loss: 1.7529902458190918
Validation loss: 1.7723909324879268
Epoch: 5| Step: 8
Training loss: 1.8237755298614502
Validation loss: 1.7637294710968896
Epoch: 5| Step: 9
Training loss: 1.779862403869629
Validation loss: 1.7645170517104993
Epoch: 61| Step: 0
Training loss: 2.1502859592437744
Validation loss: 1.7729049620868491
Epoch: 5| Step: 1
Training loss: 2.094348669052124
Validation loss: 1.7750997243167685
Epoch: 5| Step: 2
Training loss: 1.5960383415222168
Validation loss: 1.7631638110112802
Epoch: 5| Step: 3
Training loss: 1.6720712184906006
Validation loss: 1.7845375186247792
Epoch: 5| Step: 4
Training loss: 1.9133708477020264
Validation loss: 1.7856010876113562
Epoch: 5| Step: 5
Training loss: 1.8074722290039062
Validation loss: 1.770503922332105
Epoch: 5| Step: 6
Training loss: 1.9036285877227783
Validation loss: 1.774988998612054
Epoch: 5| Step: 7
Training loss: 2.114875316619873
Validation loss: 1.7787669253863876
Epoch: 5| Step: 8
Training loss: 2.48333477973938
Validation loss: 1.78675904033853
Epoch: 5| Step: 9
Training loss: 2.210944414138794
Validation loss: 1.7770592934793705
Epoch: 62| Step: 0
Training loss: 1.9290013313293457
Validation loss: 1.7880864632215432
Epoch: 5| Step: 1
Training loss: 1.9121713638305664
Validation loss: 1.7836259080351686
Epoch: 5| Step: 2
Training loss: 2.545449733734131
Validation loss: 1.7750795950992502
Epoch: 5| Step: 3
Training loss: 1.8194465637207031
Validation loss: 1.7810346711453775
Epoch: 5| Step: 4
Training loss: 2.2509634494781494
Validation loss: 1.7703320053841571
Epoch: 5| Step: 5
Training loss: 2.051454544067383
Validation loss: 1.7620894034131824
Epoch: 5| Step: 6
Training loss: 1.9345980882644653
Validation loss: 1.7576942212290043
Epoch: 5| Step: 7
Training loss: 1.6645095348358154
Validation loss: 1.7655145667439742
Epoch: 5| Step: 8
Training loss: 2.054478645324707
Validation loss: 1.7709618420909634
Epoch: 5| Step: 9
Training loss: 1.8566334247589111
Validation loss: 1.761043776711114
Epoch: 63| Step: 0
Training loss: 2.334764242172241
Validation loss: 1.7671558565373042
Epoch: 5| Step: 1
Training loss: 2.0604629516601562
Validation loss: 1.7606223238457879
Epoch: 5| Step: 2
Training loss: 1.8657020330429077
Validation loss: 1.7711701881971291
Epoch: 5| Step: 3
Training loss: 1.5402185916900635
Validation loss: 1.7741322268684991
Epoch: 5| Step: 4
Training loss: 1.979038119316101
Validation loss: 1.7766398448738263
Epoch: 5| Step: 5
Training loss: 1.5351383686065674
Validation loss: 1.7788608494422418
Epoch: 5| Step: 6
Training loss: 2.309075355529785
Validation loss: 1.7866986183811435
Epoch: 5| Step: 7
Training loss: 2.169743061065674
Validation loss: 1.7803920541735863
Epoch: 5| Step: 8
Training loss: 1.868838906288147
Validation loss: 1.7851693098493617
Epoch: 5| Step: 9
Training loss: 2.3119945526123047
Validation loss: 1.7771241484786109
Epoch: 64| Step: 0
Training loss: 2.2300591468811035
Validation loss: 1.779718757533341
Epoch: 5| Step: 1
Training loss: 2.4892873764038086
Validation loss: 1.777934905436399
Epoch: 5| Step: 2
Training loss: 2.051118850708008
Validation loss: 1.7875896469294597
Epoch: 5| Step: 3
Training loss: 1.582459807395935
Validation loss: 1.8050451312991356
Epoch: 5| Step: 4
Training loss: 2.4066624641418457
Validation loss: 1.7965444746634942
Epoch: 5| Step: 5
Training loss: 1.782088041305542
Validation loss: 1.7799272863127344
Epoch: 5| Step: 6
Training loss: 1.9052449464797974
Validation loss: 1.7791562389126785
Epoch: 5| Step: 7
Training loss: 1.544429063796997
Validation loss: 1.7796677796960734
Epoch: 5| Step: 8
Training loss: 2.0292625427246094
Validation loss: 1.7709548842135092
Epoch: 5| Step: 9
Training loss: 1.9329485893249512
Validation loss: 1.7781617512805856
Epoch: 65| Step: 0
Training loss: 1.9592359066009521
Validation loss: 1.7676683021106308
Epoch: 5| Step: 1
Training loss: 1.825937271118164
Validation loss: 1.7713044890396887
Epoch: 5| Step: 2
Training loss: 2.4453444480895996
Validation loss: 1.777556401362522
Epoch: 5| Step: 3
Training loss: 1.8346002101898193
Validation loss: 1.759239142747234
Epoch: 5| Step: 4
Training loss: 1.9059035778045654
Validation loss: 1.7619983566750725
Epoch: 5| Step: 5
Training loss: 1.9628522396087646
Validation loss: 1.7645318936958587
Epoch: 5| Step: 6
Training loss: 2.0981783866882324
Validation loss: 1.765553152818474
Epoch: 5| Step: 7
Training loss: 1.766019344329834
Validation loss: 1.7484154058017318
Epoch: 5| Step: 8
Training loss: 1.9434878826141357
Validation loss: 1.7651428541691183
Epoch: 5| Step: 9
Training loss: 2.216553211212158
Validation loss: 1.772874926491607
Epoch: 66| Step: 0
Training loss: 1.901393175125122
Validation loss: 1.7626925852658937
Epoch: 5| Step: 1
Training loss: 1.9621660709381104
Validation loss: 1.767537803101025
Epoch: 5| Step: 2
Training loss: 2.3945200443267822
Validation loss: 1.7748548898765508
Epoch: 5| Step: 3
Training loss: 1.9786980152130127
Validation loss: 1.7717771452965496
Epoch: 5| Step: 4
Training loss: 1.9679608345031738
Validation loss: 1.7749948175691015
Epoch: 5| Step: 5
Training loss: 1.816524624824524
Validation loss: 1.7658028525414227
Epoch: 5| Step: 6
Training loss: 2.135009288787842
Validation loss: 1.784579872227401
Epoch: 5| Step: 7
Training loss: 1.8121389150619507
Validation loss: 1.7867423287398523
Epoch: 5| Step: 8
Training loss: 2.20426082611084
Validation loss: 1.7764496331592259
Epoch: 5| Step: 9
Training loss: 1.731562852859497
Validation loss: 1.7800218570146629
Epoch: 67| Step: 0
Training loss: 1.9254766702651978
Validation loss: 1.7850864636812278
Epoch: 5| Step: 1
Training loss: 1.6627740859985352
Validation loss: 1.7684864534748543
Epoch: 5| Step: 2
Training loss: 2.154639482498169
Validation loss: 1.7809195106835674
Epoch: 5| Step: 3
Training loss: 2.2388291358947754
Validation loss: 1.7647669178118808
Epoch: 5| Step: 4
Training loss: 2.3125882148742676
Validation loss: 1.7754790182593916
Epoch: 5| Step: 5
Training loss: 1.7291948795318604
Validation loss: 1.7742085654100925
Epoch: 5| Step: 6
Training loss: 2.4807381629943848
Validation loss: 1.7699721665691128
Epoch: 5| Step: 7
Training loss: 1.7523537874221802
Validation loss: 1.7806657707090858
Epoch: 5| Step: 8
Training loss: 1.8830091953277588
Validation loss: 1.7871682137894116
Epoch: 5| Step: 9
Training loss: 1.7866218090057373
Validation loss: 1.775565055634478
Epoch: 68| Step: 0
Training loss: 1.8219537734985352
Validation loss: 1.7855225406962334
Epoch: 5| Step: 1
Training loss: 2.2059497833251953
Validation loss: 1.7865862511902404
Epoch: 5| Step: 2
Training loss: 2.0602006912231445
Validation loss: 1.77918188863521
Epoch: 5| Step: 3
Training loss: 1.887149691581726
Validation loss: 1.7942145951360249
Epoch: 5| Step: 4
Training loss: 2.259047031402588
Validation loss: 1.7834317306820437
Epoch: 5| Step: 5
Training loss: 1.4429926872253418
Validation loss: 1.783358869792746
Epoch: 5| Step: 6
Training loss: 1.966568946838379
Validation loss: 1.78157237965426
Epoch: 5| Step: 7
Training loss: 2.320958137512207
Validation loss: 1.7809541920106189
Epoch: 5| Step: 8
Training loss: 2.0309975147247314
Validation loss: 1.7851738389447438
Epoch: 5| Step: 9
Training loss: 1.8978519439697266
Validation loss: 1.7837923130543112
Epoch: 69| Step: 0
Training loss: 2.0498993396759033
Validation loss: 1.7918929684934
Epoch: 5| Step: 1
Training loss: 2.048705816268921
Validation loss: 1.8034509103075207
Epoch: 5| Step: 2
Training loss: 2.153693437576294
Validation loss: 1.7908520895800144
Epoch: 5| Step: 3
Training loss: 2.349486827850342
Validation loss: 1.787754741504038
Epoch: 5| Step: 4
Training loss: 2.208338499069214
Validation loss: 1.7942827365381255
Epoch: 5| Step: 5
Training loss: 1.4471523761749268
Validation loss: 1.7787103309905787
Epoch: 5| Step: 6
Training loss: 1.8627781867980957
Validation loss: 1.7729048797552533
Epoch: 5| Step: 7
Training loss: 1.7439411878585815
Validation loss: 1.7805751596423363
Epoch: 5| Step: 8
Training loss: 1.7714881896972656
Validation loss: 1.7785394886414783
Epoch: 5| Step: 9
Training loss: 2.226875066757202
Validation loss: 1.7851660448870212
Epoch: 70| Step: 0
Training loss: 2.02007794380188
Validation loss: 1.7863313757258354
Epoch: 5| Step: 1
Training loss: 1.8531830310821533
Validation loss: 1.8005464651601777
Epoch: 5| Step: 2
Training loss: 2.0150704383850098
Validation loss: 1.7929544620376696
Epoch: 5| Step: 3
Training loss: 2.0734570026397705
Validation loss: 1.8060147985279988
Epoch: 5| Step: 4
Training loss: 2.0021133422851562
Validation loss: 1.8109276080303054
Epoch: 5| Step: 5
Training loss: 1.7221405506134033
Validation loss: 1.8182076807502363
Epoch: 5| Step: 6
Training loss: 2.122039318084717
Validation loss: 1.801724879004115
Epoch: 5| Step: 7
Training loss: 1.8582513332366943
Validation loss: 1.8026511146010256
Epoch: 5| Step: 8
Training loss: 1.683622121810913
Validation loss: 1.7988517027107074
Epoch: 5| Step: 9
Training loss: 2.460303783416748
Validation loss: 1.806993032530915
Epoch: 71| Step: 0
Training loss: 2.3529725074768066
Validation loss: 1.8026389432468002
Epoch: 5| Step: 1
Training loss: 1.799512267112732
Validation loss: 1.7970725169284738
Epoch: 5| Step: 2
Training loss: 2.1536529064178467
Validation loss: 1.8047052819094211
Epoch: 5| Step: 3
Training loss: 1.7830562591552734
Validation loss: 1.8033753805023303
Epoch: 5| Step: 4
Training loss: 1.9575344324111938
Validation loss: 1.8092559473120051
Epoch: 5| Step: 5
Training loss: 1.7191195487976074
Validation loss: 1.805836396251651
Epoch: 5| Step: 6
Training loss: 1.8987783193588257
Validation loss: 1.7862798961804067
Epoch: 5| Step: 7
Training loss: 2.2473888397216797
Validation loss: 1.7887145152194894
Epoch: 5| Step: 8
Training loss: 1.7381094694137573
Validation loss: 1.7775593464323085
Epoch: 5| Step: 9
Training loss: 2.196319341659546
Validation loss: 1.7700246932695238
Epoch: 72| Step: 0
Training loss: 2.012761116027832
Validation loss: 1.7687239612606789
Epoch: 5| Step: 1
Training loss: 1.8585624694824219
Validation loss: 1.771986831864007
Epoch: 5| Step: 2
Training loss: 2.185643196105957
Validation loss: 1.7636440100429727
Epoch: 5| Step: 3
Training loss: 1.8487449884414673
Validation loss: 1.7697096385544153
Epoch: 5| Step: 4
Training loss: 2.2500405311584473
Validation loss: 1.7641298076231702
Epoch: 5| Step: 5
Training loss: 1.8293548822402954
Validation loss: 1.7562268929515812
Epoch: 5| Step: 6
Training loss: 1.731889247894287
Validation loss: 1.7521321430480739
Epoch: 5| Step: 7
Training loss: 2.2302017211914062
Validation loss: 1.7539218895726925
Epoch: 5| Step: 8
Training loss: 1.854627251625061
Validation loss: 1.7509946317123852
Epoch: 5| Step: 9
Training loss: 2.0170130729675293
Validation loss: 1.7545852695437645
Epoch: 73| Step: 0
Training loss: 1.6748300790786743
Validation loss: 1.75064709889803
Epoch: 5| Step: 1
Training loss: 1.9453392028808594
Validation loss: 1.7542717190955182
Epoch: 5| Step: 2
Training loss: 2.0276105403900146
Validation loss: 1.7674342985633467
Epoch: 5| Step: 3
Training loss: 2.1204938888549805
Validation loss: 1.7658625815412123
Epoch: 5| Step: 4
Training loss: 2.205813407897949
Validation loss: 1.7658724716241412
Epoch: 5| Step: 5
Training loss: 2.2461180686950684
Validation loss: 1.7652564794897176
Epoch: 5| Step: 6
Training loss: 1.7959420680999756
Validation loss: 1.754432124199627
Epoch: 5| Step: 7
Training loss: 2.1340627670288086
Validation loss: 1.7665230456016046
Epoch: 5| Step: 8
Training loss: 1.7628884315490723
Validation loss: 1.7619692687508013
Epoch: 5| Step: 9
Training loss: 1.9867674112319946
Validation loss: 1.772677629114055
Epoch: 74| Step: 0
Training loss: 2.142120599746704
Validation loss: 1.7664658242849995
Epoch: 5| Step: 1
Training loss: 1.7902727127075195
Validation loss: 1.7678340356126965
Epoch: 5| Step: 2
Training loss: 2.0777783393859863
Validation loss: 1.7651688735262097
Epoch: 5| Step: 3
Training loss: 2.0697879791259766
Validation loss: 1.774619549298458
Epoch: 5| Step: 4
Training loss: 1.8432941436767578
Validation loss: 1.7759821149085064
Epoch: 5| Step: 5
Training loss: 2.3290157318115234
Validation loss: 1.778570302098775
Epoch: 5| Step: 6
Training loss: 2.202853202819824
Validation loss: 1.7789907060938774
Epoch: 5| Step: 7
Training loss: 1.808326244354248
Validation loss: 1.77519994588207
Epoch: 5| Step: 8
Training loss: 1.6554977893829346
Validation loss: 1.7841722819444945
Epoch: 5| Step: 9
Training loss: 1.89131760597229
Validation loss: 1.7754739505781545
Epoch: 75| Step: 0
Training loss: 1.6633548736572266
Validation loss: 1.7985367131747787
Epoch: 5| Step: 1
Training loss: 2.2442245483398438
Validation loss: 1.802892823871091
Epoch: 5| Step: 2
Training loss: 1.959717035293579
Validation loss: 1.8081459553121664
Epoch: 5| Step: 3
Training loss: 1.8994479179382324
Validation loss: 1.8033878648881432
Epoch: 5| Step: 4
Training loss: 2.342247724533081
Validation loss: 1.80149499889758
Epoch: 5| Step: 5
Training loss: 1.5703864097595215
Validation loss: 1.8019302448780417
Epoch: 5| Step: 6
Training loss: 2.113135576248169
Validation loss: 1.815418288004484
Epoch: 5| Step: 7
Training loss: 1.9155707359313965
Validation loss: 1.796922940144436
Epoch: 5| Step: 8
Training loss: 1.6685489416122437
Validation loss: 1.8041036283369545
Epoch: 5| Step: 9
Training loss: 2.4965059757232666
Validation loss: 1.8077870667409555
Epoch: 76| Step: 0
Training loss: 2.0583596229553223
Validation loss: 1.8027133487111373
Epoch: 5| Step: 1
Training loss: 2.1051700115203857
Validation loss: 1.8052686487170433
Epoch: 5| Step: 2
Training loss: 2.4785425662994385
Validation loss: 1.8010993012421423
Epoch: 5| Step: 3
Training loss: 1.9727694988250732
Validation loss: 1.8046382841446418
Epoch: 5| Step: 4
Training loss: 2.063122510910034
Validation loss: 1.7988814741587467
Epoch: 5| Step: 5
Training loss: 1.4347736835479736
Validation loss: 1.7906775946239772
Epoch: 5| Step: 6
Training loss: 1.970342993736267
Validation loss: 1.78709119172405
Epoch: 5| Step: 7
Training loss: 2.0672919750213623
Validation loss: 1.7923608881106479
Epoch: 5| Step: 8
Training loss: 1.831863284111023
Validation loss: 1.795472579894306
Epoch: 5| Step: 9
Training loss: 1.7970035076141357
Validation loss: 1.7955406758425048
Epoch: 77| Step: 0
Training loss: 1.8102856874465942
Validation loss: 1.7843033049604018
Epoch: 5| Step: 1
Training loss: 2.0861690044403076
Validation loss: 1.790468712504819
Epoch: 5| Step: 2
Training loss: 2.0091607570648193
Validation loss: 1.7709177106404477
Epoch: 5| Step: 3
Training loss: 2.131735324859619
Validation loss: 1.7884563567827074
Epoch: 5| Step: 4
Training loss: 1.5941494703292847
Validation loss: 1.770788231341959
Epoch: 5| Step: 5
Training loss: 2.1546120643615723
Validation loss: 1.7908773610917785
Epoch: 5| Step: 6
Training loss: 1.9144394397735596
Validation loss: 1.7804210623391241
Epoch: 5| Step: 7
Training loss: 1.9558041095733643
Validation loss: 1.775472628126899
Epoch: 5| Step: 8
Training loss: 2.07619571685791
Validation loss: 1.7756067042728123
Epoch: 5| Step: 9
Training loss: 2.005949020385742
Validation loss: 1.7699781278912112
Epoch: 78| Step: 0
Training loss: 1.7560651302337646
Validation loss: 1.7605273329096733
Epoch: 5| Step: 1
Training loss: 1.6702003479003906
Validation loss: 1.7631636420599848
Epoch: 5| Step: 2
Training loss: 2.1160778999328613
Validation loss: 1.7816141920981647
Epoch: 5| Step: 3
Training loss: 1.9632362127304077
Validation loss: 1.7704756071241639
Epoch: 5| Step: 4
Training loss: 2.156147003173828
Validation loss: 1.764884320952052
Epoch: 5| Step: 5
Training loss: 2.3918628692626953
Validation loss: 1.7706532812804627
Epoch: 5| Step: 6
Training loss: 2.024829387664795
Validation loss: 1.7670975048765003
Epoch: 5| Step: 7
Training loss: 1.6710646152496338
Validation loss: 1.7557144190767686
Epoch: 5| Step: 8
Training loss: 2.1957015991210938
Validation loss: 1.7707742066692105
Epoch: 5| Step: 9
Training loss: 1.8733129501342773
Validation loss: 1.7737125518510668
Epoch: 79| Step: 0
Training loss: 1.6301063299179077
Validation loss: 1.7894366293502368
Epoch: 5| Step: 1
Training loss: 2.095975160598755
Validation loss: 1.7825412055571301
Epoch: 5| Step: 2
Training loss: 1.780889868736267
Validation loss: 1.783994428545451
Epoch: 5| Step: 3
Training loss: 1.9330321550369263
Validation loss: 1.7896005498419563
Epoch: 5| Step: 4
Training loss: 2.3251256942749023
Validation loss: 1.799079498798727
Epoch: 5| Step: 5
Training loss: 2.4350380897521973
Validation loss: 1.8006049394607544
Epoch: 5| Step: 6
Training loss: 1.5721064805984497
Validation loss: 1.7943983266679504
Epoch: 5| Step: 7
Training loss: 1.8934924602508545
Validation loss: 1.811154061084171
Epoch: 5| Step: 8
Training loss: 2.041107177734375
Validation loss: 1.8072629112133878
Epoch: 5| Step: 9
Training loss: 2.0465738773345947
Validation loss: 1.8113712080948645
Epoch: 80| Step: 0
Training loss: 2.077122449874878
Validation loss: 1.8074446496346015
Epoch: 5| Step: 1
Training loss: 2.2080581188201904
Validation loss: 1.807005613827877
Epoch: 5| Step: 2
Training loss: 2.362945556640625
Validation loss: 1.8036141995903399
Epoch: 5| Step: 3
Training loss: 1.8552170991897583
Validation loss: 1.798110801538975
Epoch: 5| Step: 4
Training loss: 2.091660499572754
Validation loss: 1.787930937122098
Epoch: 5| Step: 5
Training loss: 2.0146241188049316
Validation loss: 1.787543648438488
Epoch: 5| Step: 6
Training loss: 1.5257145166397095
Validation loss: 1.7981562906031987
Epoch: 5| Step: 7
Training loss: 2.1071243286132812
Validation loss: 1.794031849868006
Epoch: 5| Step: 8
Training loss: 1.534061074256897
Validation loss: 1.7957528572288348
Epoch: 5| Step: 9
Training loss: 1.9971226453781128
Validation loss: 1.786510548145651
Epoch: 81| Step: 0
Training loss: 1.9181089401245117
Validation loss: 1.7926357830171105
Epoch: 5| Step: 1
Training loss: 1.8398373126983643
Validation loss: 1.7853727254936163
Epoch: 5| Step: 2
Training loss: 2.0736560821533203
Validation loss: 1.7857192334511298
Epoch: 5| Step: 3
Training loss: 1.6715309619903564
Validation loss: 1.7810926540292424
Epoch: 5| Step: 4
Training loss: 2.328183174133301
Validation loss: 1.7894397485170432
Epoch: 5| Step: 5
Training loss: 2.213662624359131
Validation loss: 1.778753242046713
Epoch: 5| Step: 6
Training loss: 1.8138281106948853
Validation loss: 1.7894017164655727
Epoch: 5| Step: 7
Training loss: 2.230508327484131
Validation loss: 1.786227270853605
Epoch: 5| Step: 8
Training loss: 1.9146528244018555
Validation loss: 1.8033088805864184
Epoch: 5| Step: 9
Training loss: 1.7183959484100342
Validation loss: 1.7693576949963468
Epoch: 82| Step: 0
Training loss: 2.0728683471679688
Validation loss: 1.787366793310042
Epoch: 5| Step: 1
Training loss: 1.8999851942062378
Validation loss: 1.77186032507917
Epoch: 5| Step: 2
Training loss: 2.0023550987243652
Validation loss: 1.7832073539281064
Epoch: 5| Step: 3
Training loss: 1.7758386135101318
Validation loss: 1.7747473948293453
Epoch: 5| Step: 4
Training loss: 2.0669925212860107
Validation loss: 1.789148903579163
Epoch: 5| Step: 5
Training loss: 1.709399938583374
Validation loss: 1.8002800615571386
Epoch: 5| Step: 6
Training loss: 2.0145163536071777
Validation loss: 1.7798940526495735
Epoch: 5| Step: 7
Training loss: 2.140939712524414
Validation loss: 1.7881428740865035
Epoch: 5| Step: 8
Training loss: 2.3170487880706787
Validation loss: 1.7905151243690107
Epoch: 5| Step: 9
Training loss: 1.6750550270080566
Validation loss: 1.7804272312054532
Epoch: 83| Step: 0
Training loss: 1.9436335563659668
Validation loss: 1.7862785377090784
Epoch: 5| Step: 1
Training loss: 1.688760757446289
Validation loss: 1.8072516257814366
Epoch: 5| Step: 2
Training loss: 2.23195743560791
Validation loss: 1.7909702534298244
Epoch: 5| Step: 3
Training loss: 2.006791353225708
Validation loss: 1.8011132024174972
Epoch: 5| Step: 4
Training loss: 1.579917550086975
Validation loss: 1.8009599249997585
Epoch: 5| Step: 5
Training loss: 2.0940699577331543
Validation loss: 1.7942706140682851
Epoch: 5| Step: 6
Training loss: 2.1648597717285156
Validation loss: 1.7986915085813124
Epoch: 5| Step: 7
Training loss: 1.910374402999878
Validation loss: 1.797002927862483
Epoch: 5| Step: 8
Training loss: 2.025377035140991
Validation loss: 1.798590407954703
Epoch: 5| Step: 9
Training loss: 1.9952813386917114
Validation loss: 1.788634841390651
Epoch: 84| Step: 0
Training loss: 2.1286725997924805
Validation loss: 1.8082128908994386
Epoch: 5| Step: 1
Training loss: 2.124048948287964
Validation loss: 1.7794961997930951
Epoch: 5| Step: 2
Training loss: 1.7522391080856323
Validation loss: 1.7973986135112296
Epoch: 5| Step: 3
Training loss: 2.134706497192383
Validation loss: 1.7808255248790166
Epoch: 5| Step: 4
Training loss: 2.078500270843506
Validation loss: 1.7743595066688043
Epoch: 5| Step: 5
Training loss: 1.7720024585723877
Validation loss: 1.7794759830982565
Epoch: 5| Step: 6
Training loss: 2.212031602859497
Validation loss: 1.775655377683022
Epoch: 5| Step: 7
Training loss: 1.8891600370407104
Validation loss: 1.775590099876733
Epoch: 5| Step: 8
Training loss: 2.030874252319336
Validation loss: 1.7784307843489613
Epoch: 5| Step: 9
Training loss: 1.5516831874847412
Validation loss: 1.7651767113225922
Epoch: 85| Step: 0
Training loss: 1.926206111907959
Validation loss: 1.7719084341749012
Epoch: 5| Step: 1
Training loss: 2.1874544620513916
Validation loss: 1.7716208713517771
Epoch: 5| Step: 2
Training loss: 1.9391069412231445
Validation loss: 1.770744388052028
Epoch: 5| Step: 3
Training loss: 2.392941474914551
Validation loss: 1.7754373207366725
Epoch: 5| Step: 4
Training loss: 1.5936663150787354
Validation loss: 1.7694873406732683
Epoch: 5| Step: 5
Training loss: 2.3411269187927246
Validation loss: 1.7812815844583854
Epoch: 5| Step: 6
Training loss: 1.4728929996490479
Validation loss: 1.7756718302802217
Epoch: 5| Step: 7
Training loss: 1.574577808380127
Validation loss: 1.7776690575716307
Epoch: 5| Step: 8
Training loss: 2.3384995460510254
Validation loss: 1.7652175649464559
Epoch: 5| Step: 9
Training loss: 1.788558006286621
Validation loss: 1.7762345547298732
Epoch: 86| Step: 0
Training loss: 1.970767855644226
Validation loss: 1.7848377090563876
Epoch: 5| Step: 1
Training loss: 2.0652859210968018
Validation loss: 1.7732366100489665
Epoch: 5| Step: 2
Training loss: 2.0677952766418457
Validation loss: 1.7782948274406598
Epoch: 5| Step: 3
Training loss: 1.8603812456130981
Validation loss: 1.7924048463217646
Epoch: 5| Step: 4
Training loss: 2.026594638824463
Validation loss: 1.7915360018503752
Epoch: 5| Step: 5
Training loss: 1.7761452198028564
Validation loss: 1.7951523948916428
Epoch: 5| Step: 6
Training loss: 1.529085397720337
Validation loss: 1.7942643199893211
Epoch: 5| Step: 7
Training loss: 2.111368179321289
Validation loss: 1.794893595812132
Epoch: 5| Step: 8
Training loss: 2.461669445037842
Validation loss: 1.7870065651351599
Epoch: 5| Step: 9
Training loss: 1.7802927494049072
Validation loss: 1.8008586725742697
Epoch: 87| Step: 0
Training loss: 1.8725864887237549
Validation loss: 1.7882710094932173
Epoch: 5| Step: 1
Training loss: 1.7596991062164307
Validation loss: 1.791167382713702
Epoch: 5| Step: 2
Training loss: 1.8452532291412354
Validation loss: 1.7922843265876496
Epoch: 5| Step: 3
Training loss: 2.5572922229766846
Validation loss: 1.7987835338647418
Epoch: 5| Step: 4
Training loss: 2.0139684677124023
Validation loss: 1.7896587882968162
Epoch: 5| Step: 5
Training loss: 1.8741464614868164
Validation loss: 1.795964163841961
Epoch: 5| Step: 6
Training loss: 1.8559808731079102
Validation loss: 1.7947980508529882
Epoch: 5| Step: 7
Training loss: 1.8753941059112549
Validation loss: 1.7990203847130426
Epoch: 5| Step: 8
Training loss: 2.1625843048095703
Validation loss: 1.7951376789765392
Epoch: 5| Step: 9
Training loss: 1.8177400827407837
Validation loss: 1.7895656146591516
Epoch: 88| Step: 0
Training loss: 1.899622917175293
Validation loss: 1.811803536449405
Epoch: 5| Step: 1
Training loss: 2.324418067932129
Validation loss: 1.7892589328957975
Epoch: 5| Step: 2
Training loss: 2.1335744857788086
Validation loss: 1.7961813177136208
Epoch: 5| Step: 3
Training loss: 1.883632779121399
Validation loss: 1.7858957798360922
Epoch: 5| Step: 4
Training loss: 1.9045629501342773
Validation loss: 1.7981516740304961
Epoch: 5| Step: 5
Training loss: 1.591004490852356
Validation loss: 1.7897690731844456
Epoch: 5| Step: 6
Training loss: 2.163362503051758
Validation loss: 1.804830149780932
Epoch: 5| Step: 7
Training loss: 2.095196008682251
Validation loss: 1.7972353971261772
Epoch: 5| Step: 8
Training loss: 1.8001041412353516
Validation loss: 1.804809229837047
Epoch: 5| Step: 9
Training loss: 1.7612807750701904
Validation loss: 1.7954799965988817
Epoch: 89| Step: 0
Training loss: 2.124621629714966
Validation loss: 1.7928571906878794
Epoch: 5| Step: 1
Training loss: 2.2456698417663574
Validation loss: 1.7982039022788727
Epoch: 5| Step: 2
Training loss: 1.3893942832946777
Validation loss: 1.7864851539941142
Epoch: 5| Step: 3
Training loss: 1.939228892326355
Validation loss: 1.7995306442109802
Epoch: 5| Step: 4
Training loss: 2.2280280590057373
Validation loss: 1.811600895236722
Epoch: 5| Step: 5
Training loss: 2.0238685607910156
Validation loss: 1.7953516991018392
Epoch: 5| Step: 6
Training loss: 1.9343397617340088
Validation loss: 1.8064428919510875
Epoch: 5| Step: 7
Training loss: 1.7046329975128174
Validation loss: 1.8008323410432117
Epoch: 5| Step: 8
Training loss: 2.0911786556243896
Validation loss: 1.7950162287238691
Epoch: 5| Step: 9
Training loss: 1.9099252223968506
Validation loss: 1.7947565016986655
Epoch: 90| Step: 0
Training loss: 1.8068866729736328
Validation loss: 1.7982129210190807
Epoch: 5| Step: 1
Training loss: 1.6996936798095703
Validation loss: 1.7978207953542256
Epoch: 5| Step: 2
Training loss: 1.9437646865844727
Validation loss: 1.8023025980956262
Epoch: 5| Step: 3
Training loss: 2.039964199066162
Validation loss: 1.8042658901900697
Epoch: 5| Step: 4
Training loss: 2.3123888969421387
Validation loss: 1.8073486561397853
Epoch: 5| Step: 5
Training loss: 1.9202337265014648
Validation loss: 1.796698087410961
Epoch: 5| Step: 6
Training loss: 2.041214942932129
Validation loss: 1.7837095560787393
Epoch: 5| Step: 7
Training loss: 1.7954840660095215
Validation loss: 1.7913893709937445
Epoch: 5| Step: 8
Training loss: 2.053852081298828
Validation loss: 1.786854697645997
Epoch: 5| Step: 9
Training loss: 1.9784873723983765
Validation loss: 1.7896384009354407
Epoch: 91| Step: 0
Training loss: 2.1278743743896484
Validation loss: 1.8077465990464465
Epoch: 5| Step: 1
Training loss: 1.8711541891098022
Validation loss: 1.7922862210719706
Epoch: 5| Step: 2
Training loss: 1.9736438989639282
Validation loss: 1.7771015621775346
Epoch: 5| Step: 3
Training loss: 2.2580833435058594
Validation loss: 1.778214446074671
Epoch: 5| Step: 4
Training loss: 1.8147672414779663
Validation loss: 1.7888644110384604
Epoch: 5| Step: 5
Training loss: 2.1645004749298096
Validation loss: 1.7832027116267801
Epoch: 5| Step: 6
Training loss: 1.51686429977417
Validation loss: 1.7933973133992807
Epoch: 5| Step: 7
Training loss: 2.4328110218048096
Validation loss: 1.7871726013773637
Epoch: 5| Step: 8
Training loss: 1.69346284866333
Validation loss: 1.7748936740614527
Epoch: 5| Step: 9
Training loss: 1.7799855470657349
Validation loss: 1.7766660503346285
Epoch: 92| Step: 0
Training loss: 2.1068921089172363
Validation loss: 1.7768881003633679
Epoch: 5| Step: 1
Training loss: 1.519782543182373
Validation loss: 1.7932273192371395
Epoch: 5| Step: 2
Training loss: 2.4986162185668945
Validation loss: 1.789130857522539
Epoch: 5| Step: 3
Training loss: 1.67867910861969
Validation loss: 1.795530145974468
Epoch: 5| Step: 4
Training loss: 1.6405531167984009
Validation loss: 1.7994853112337401
Epoch: 5| Step: 5
Training loss: 1.9648654460906982
Validation loss: 1.797351448655986
Epoch: 5| Step: 6
Training loss: 2.050790786743164
Validation loss: 1.8119352224061815
Epoch: 5| Step: 7
Training loss: 1.9160324335098267
Validation loss: 1.8056087313796119
Epoch: 5| Step: 8
Training loss: 2.2728710174560547
Validation loss: 1.8056945766476418
Epoch: 5| Step: 9
Training loss: 1.9042134284973145
Validation loss: 1.804194530994772
Epoch: 93| Step: 0
Training loss: 2.055239200592041
Validation loss: 1.795043593687977
Epoch: 5| Step: 1
Training loss: 2.0310468673706055
Validation loss: 1.8110774232329225
Epoch: 5| Step: 2
Training loss: 1.9584850072860718
Validation loss: 1.7950078832159797
Epoch: 5| Step: 3
Training loss: 1.6865569353103638
Validation loss: 1.7965877493508429
Epoch: 5| Step: 4
Training loss: 1.9752990007400513
Validation loss: 1.7970458226238224
Epoch: 5| Step: 5
Training loss: 2.024787425994873
Validation loss: 1.7934064890840928
Epoch: 5| Step: 6
Training loss: 1.9889739751815796
Validation loss: 1.8020338463268692
Epoch: 5| Step: 7
Training loss: 1.612806797027588
Validation loss: 1.79735787309331
Epoch: 5| Step: 8
Training loss: 2.081218719482422
Validation loss: 1.8030758761673522
Epoch: 5| Step: 9
Training loss: 2.1090519428253174
Validation loss: 1.8077514729053854
Epoch: 94| Step: 0
Training loss: 1.9000821113586426
Validation loss: 1.7931155498079259
Epoch: 5| Step: 1
Training loss: 2.582350730895996
Validation loss: 1.787327620622923
Epoch: 5| Step: 2
Training loss: 2.012317657470703
Validation loss: 1.7919787134197975
Epoch: 5| Step: 3
Training loss: 1.8292663097381592
Validation loss: 1.7718360887156974
Epoch: 5| Step: 4
Training loss: 2.137155055999756
Validation loss: 1.7810069708515415
Epoch: 5| Step: 5
Training loss: 2.0644888877868652
Validation loss: 1.7736338437032357
Epoch: 5| Step: 6
Training loss: 1.6150627136230469
Validation loss: 1.7796981403295942
Epoch: 5| Step: 7
Training loss: 1.6202174425125122
Validation loss: 1.7773006348301181
Epoch: 5| Step: 8
Training loss: 1.7556471824645996
Validation loss: 1.7769365284940322
Epoch: 5| Step: 9
Training loss: 1.986291766166687
Validation loss: 1.7854300763109605
Epoch: 95| Step: 0
Training loss: 1.6640405654907227
Validation loss: 1.774842842019719
Epoch: 5| Step: 1
Training loss: 2.1279690265655518
Validation loss: 1.7865994576927569
Epoch: 5| Step: 2
Training loss: 1.710688829421997
Validation loss: 1.769926686938718
Epoch: 5| Step: 3
Training loss: 1.791888952255249
Validation loss: 1.7753081321716309
Epoch: 5| Step: 4
Training loss: 2.114210605621338
Validation loss: 1.7840802317900624
Epoch: 5| Step: 5
Training loss: 2.142011880874634
Validation loss: 1.7752232765979905
Epoch: 5| Step: 6
Training loss: 1.4930082559585571
Validation loss: 1.775021438975986
Epoch: 5| Step: 7
Training loss: 1.9145746231079102
Validation loss: 1.7793908942517618
Epoch: 5| Step: 8
Training loss: 2.2181973457336426
Validation loss: 1.792964050238081
Epoch: 5| Step: 9
Training loss: 2.2601113319396973
Validation loss: 1.7905619513216635
Epoch: 96| Step: 0
Training loss: 1.7486200332641602
Validation loss: 1.786191844254089
Epoch: 5| Step: 1
Training loss: 2.0306594371795654
Validation loss: 1.7921357832366613
Epoch: 5| Step: 2
Training loss: 1.4204816818237305
Validation loss: 1.7934519352672769
Epoch: 5| Step: 3
Training loss: 2.2250142097473145
Validation loss: 1.7932664704837387
Epoch: 5| Step: 4
Training loss: 2.1657626628875732
Validation loss: 1.8010011173838334
Epoch: 5| Step: 5
Training loss: 2.1697916984558105
Validation loss: 1.795955222287624
Epoch: 5| Step: 6
Training loss: 1.6642706394195557
Validation loss: 1.8146757273365268
Epoch: 5| Step: 7
Training loss: 1.8021076917648315
Validation loss: 1.8003429251609089
Epoch: 5| Step: 8
Training loss: 2.382153034210205
Validation loss: 1.8127009671369045
Epoch: 5| Step: 9
Training loss: 1.8815431594848633
Validation loss: 1.8037364045493036
Epoch: 97| Step: 0
Training loss: 1.729754090309143
Validation loss: 1.8027668265130024
Epoch: 5| Step: 1
Training loss: 2.062709093093872
Validation loss: 1.7994994979968173
Epoch: 5| Step: 2
Training loss: 1.4868834018707275
Validation loss: 1.800751253855314
Epoch: 5| Step: 3
Training loss: 1.8819496631622314
Validation loss: 1.8014937767879569
Epoch: 5| Step: 4
Training loss: 2.0554847717285156
Validation loss: 1.8090790381534494
Epoch: 5| Step: 5
Training loss: 1.9974870681762695
Validation loss: 1.8130144849955607
Epoch: 5| Step: 6
Training loss: 2.545340061187744
Validation loss: 1.8108907998036996
Epoch: 5| Step: 7
Training loss: 1.7184903621673584
Validation loss: 1.8013224190087627
Epoch: 5| Step: 8
Training loss: 1.5238251686096191
Validation loss: 1.7959195804252899
Epoch: 5| Step: 9
Training loss: 2.475008010864258
Validation loss: 1.8093278219373963
Epoch: 98| Step: 0
Training loss: 1.8999345302581787
Validation loss: 1.812771201133728
Epoch: 5| Step: 1
Training loss: 2.0759754180908203
Validation loss: 1.7964595033110475
Epoch: 5| Step: 2
Training loss: 1.6023998260498047
Validation loss: 1.8001610195036415
Epoch: 5| Step: 3
Training loss: 1.8283109664916992
Validation loss: 1.8043666417650182
Epoch: 5| Step: 4
Training loss: 1.812799096107483
Validation loss: 1.7926665115699494
Epoch: 5| Step: 5
Training loss: 2.274524450302124
Validation loss: 1.8029140002435917
Epoch: 5| Step: 6
Training loss: 1.859953761100769
Validation loss: 1.8074572755278444
Epoch: 5| Step: 7
Training loss: 1.8858497142791748
Validation loss: 1.8042451031774067
Epoch: 5| Step: 8
Training loss: 2.077296257019043
Validation loss: 1.789161529472406
Epoch: 5| Step: 9
Training loss: 2.1726021766662598
Validation loss: 1.808062835563001
Epoch: 99| Step: 0
Training loss: 1.965634822845459
Validation loss: 1.7983981113639667
Epoch: 5| Step: 1
Training loss: 1.610065221786499
Validation loss: 1.804976156289629
Epoch: 5| Step: 2
Training loss: 1.5402648448944092
Validation loss: 1.7987450824367057
Epoch: 5| Step: 3
Training loss: 1.9882830381393433
Validation loss: 1.7963528495898349
Epoch: 5| Step: 4
Training loss: 2.192556858062744
Validation loss: 1.808149535021336
Epoch: 5| Step: 5
Training loss: 1.8374156951904297
Validation loss: 1.7997517654364057
Epoch: 5| Step: 6
Training loss: 1.9527859687805176
Validation loss: 1.808730595403438
Epoch: 5| Step: 7
Training loss: 2.4973113536834717
Validation loss: 1.809773050623832
Epoch: 5| Step: 8
Training loss: 2.0041117668151855
Validation loss: 1.8075116932820932
Epoch: 5| Step: 9
Training loss: 1.8302977085113525
Validation loss: 1.806559802816926
Epoch: 100| Step: 0
Training loss: 2.2493059635162354
Validation loss: 1.7978754120764973
Epoch: 5| Step: 1
Training loss: 1.7462990283966064
Validation loss: 1.7987364659206473
Epoch: 5| Step: 2
Training loss: 1.9638652801513672
Validation loss: 1.7986499139730878
Epoch: 5| Step: 3
Training loss: 2.2574872970581055
Validation loss: 1.8065817587667232
Epoch: 5| Step: 4
Training loss: 2.092613697052002
Validation loss: 1.7861439169739648
Epoch: 5| Step: 5
Training loss: 1.7829551696777344
Validation loss: 1.7928900521436184
Epoch: 5| Step: 6
Training loss: 1.891089916229248
Validation loss: 1.7998554414982417
Epoch: 5| Step: 7
Training loss: 1.7600008249282837
Validation loss: 1.8049872101639672
Epoch: 5| Step: 8
Training loss: 1.9852930307388306
Validation loss: 1.786801616922557
Epoch: 5| Step: 9
Training loss: 1.6853145360946655
Validation loss: 1.7989913611103305
