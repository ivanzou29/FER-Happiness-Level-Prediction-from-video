Epoch: 1| Step: 0
Training loss: 2.883746897708595
Validation loss: 2.5477785446291814

Epoch: 5| Step: 1
Training loss: 3.0507237310518835
Validation loss: 2.5459603771678503

Epoch: 5| Step: 2
Training loss: 2.5104390587869885
Validation loss: 2.5428850401398697

Epoch: 5| Step: 3
Training loss: 2.1007780858842735
Validation loss: 2.5447957028827886

Epoch: 5| Step: 4
Training loss: 2.719757419596048
Validation loss: 2.5429890598124794

Epoch: 5| Step: 5
Training loss: 2.7337915288477035
Validation loss: 2.5452793091853536

Epoch: 5| Step: 6
Training loss: 2.7322580916949573
Validation loss: 2.543695083387783

Epoch: 5| Step: 7
Training loss: 3.135454010767451
Validation loss: 2.5450607539059527

Epoch: 5| Step: 8
Training loss: 2.468343580569423
Validation loss: 2.542404952202808

Epoch: 5| Step: 9
Training loss: 2.3510834975965653
Validation loss: 2.5449695558294656

Epoch: 5| Step: 10
Training loss: 2.466083680242125
Validation loss: 2.5433095028857826

Epoch: 5| Step: 11
Training loss: 2.913957936556063
Validation loss: 2.5406800932343847

Epoch: 2| Step: 0
Training loss: 2.9245205086797523
Validation loss: 2.5450684004374766

Epoch: 5| Step: 1
Training loss: 3.0533250663123455
Validation loss: 2.5437532846677975

Epoch: 5| Step: 2
Training loss: 2.785714498806341
Validation loss: 2.543423359555816

Epoch: 5| Step: 3
Training loss: 2.714010118891519
Validation loss: 2.5392789190932263

Epoch: 5| Step: 4
Training loss: 2.608096786189188
Validation loss: 2.541305005550447

Epoch: 5| Step: 5
Training loss: 2.203320217276281
Validation loss: 2.5415556458682884

Epoch: 5| Step: 6
Training loss: 2.9669129158716827
Validation loss: 2.538129594052386

Epoch: 5| Step: 7
Training loss: 2.125711882783261
Validation loss: 2.5382408534160437

Epoch: 5| Step: 8
Training loss: 2.2845351720094915
Validation loss: 2.539945877166888

Epoch: 5| Step: 9
Training loss: 2.6126451844388914
Validation loss: 2.541639344792919

Epoch: 5| Step: 10
Training loss: 2.828041623398697
Validation loss: 2.5393729347798333

Epoch: 5| Step: 11
Training loss: 2.3479163205119176
Validation loss: 2.539891370805822

Epoch: 3| Step: 0
Training loss: 3.0099766463580897
Validation loss: 2.5418463093689447

Epoch: 5| Step: 1
Training loss: 2.519928562271926
Validation loss: 2.5398972259151784

Epoch: 5| Step: 2
Training loss: 2.2026759562531244
Validation loss: 2.538646088712936

Epoch: 5| Step: 3
Training loss: 2.3322308069977495
Validation loss: 2.5398812406916234

Epoch: 5| Step: 4
Training loss: 2.7169621168464353
Validation loss: 2.5419154449301713

Epoch: 5| Step: 5
Training loss: 2.501895948556283
Validation loss: 2.5395731329354483

Epoch: 5| Step: 6
Training loss: 2.95395967505327
Validation loss: 2.5424068941631233

Epoch: 5| Step: 7
Training loss: 2.551585983289775
Validation loss: 2.5382874269293882

Epoch: 5| Step: 8
Training loss: 2.6622545478402957
Validation loss: 2.541108290252997

Epoch: 5| Step: 9
Training loss: 2.2801388686537183
Validation loss: 2.5410843140341437

Epoch: 5| Step: 10
Training loss: 3.2716984829656814
Validation loss: 2.5417197461656946

Epoch: 5| Step: 11
Training loss: 2.3720974502487375
Validation loss: 2.54292259428344

Epoch: 4| Step: 0
Training loss: 2.485797402913705
Validation loss: 2.5390992382032644

Epoch: 5| Step: 1
Training loss: 2.61149976647011
Validation loss: 2.5414541317197035

Epoch: 5| Step: 2
Training loss: 2.7505349592585207
Validation loss: 2.5405213766952355

Epoch: 5| Step: 3
Training loss: 2.50009403051925
Validation loss: 2.5424219882628525

Epoch: 5| Step: 4
Training loss: 2.8987528585705267
Validation loss: 2.540830737890726

Epoch: 5| Step: 5
Training loss: 2.3454288827380663
Validation loss: 2.5420358121384217

Epoch: 5| Step: 6
Training loss: 2.456069830967231
Validation loss: 2.5399844310282096

Epoch: 5| Step: 7
Training loss: 2.5328772694838704
Validation loss: 2.5413267398173622

Epoch: 5| Step: 8
Training loss: 2.1461680129692966
Validation loss: 2.5414869812992125

Epoch: 5| Step: 9
Training loss: 2.5010076399499246
Validation loss: 2.5426055523827977

Epoch: 5| Step: 10
Training loss: 3.520146425192759
Validation loss: 2.5445392288771593

Epoch: 5| Step: 11
Training loss: 3.20361845355902
Validation loss: 2.5423740525622374

Epoch: 5| Step: 0
Training loss: 2.512707268055992
Validation loss: 2.5405807885408853

Epoch: 5| Step: 1
Training loss: 2.614680487257584
Validation loss: 2.5419080781156143

Epoch: 5| Step: 2
Training loss: 2.481520062025956
Validation loss: 2.5389571808710945

Epoch: 5| Step: 3
Training loss: 2.329647718329128
Validation loss: 2.5395116868420833

Epoch: 5| Step: 4
Training loss: 2.6118985154443632
Validation loss: 2.5401100814611763

Epoch: 5| Step: 5
Training loss: 2.233408685618158
Validation loss: 2.5373473336031824

Epoch: 5| Step: 6
Training loss: 2.891118847700371
Validation loss: 2.539233165776179

Epoch: 5| Step: 7
Training loss: 2.362563952836811
Validation loss: 2.5360054509994816

Epoch: 5| Step: 8
Training loss: 2.9753312896144832
Validation loss: 2.5403049774189936

Epoch: 5| Step: 9
Training loss: 2.845584654845655
Validation loss: 2.5375062369284063

Epoch: 5| Step: 10
Training loss: 3.0489050728998905
Validation loss: 2.5363023084608063

Epoch: 5| Step: 11
Training loss: 2.769758164077793
Validation loss: 2.5348974878574726

Epoch: 6| Step: 0
Training loss: 2.5353223278974704
Validation loss: 2.5343021978167193

Epoch: 5| Step: 1
Training loss: 2.6318531495842548
Validation loss: 2.5340479155614055

Epoch: 5| Step: 2
Training loss: 2.6355283409451875
Validation loss: 2.531626371180597

Epoch: 5| Step: 3
Training loss: 2.605744537444411
Validation loss: 2.5298501449176487

Epoch: 5| Step: 4
Training loss: 2.7673529275549535
Validation loss: 2.5274359653321428

Epoch: 5| Step: 5
Training loss: 2.6044779070193425
Validation loss: 2.5314818107360386

Epoch: 5| Step: 6
Training loss: 2.635472072174716
Validation loss: 2.5297939720311895

Epoch: 5| Step: 7
Training loss: 2.411177111404518
Validation loss: 2.524698885031731

Epoch: 5| Step: 8
Training loss: 2.398591275830459
Validation loss: 2.525921346151925

Epoch: 5| Step: 9
Training loss: 3.083307850362961
Validation loss: 2.52558716424451

Epoch: 5| Step: 10
Training loss: 2.667243289196437
Validation loss: 2.526856766115307

Epoch: 5| Step: 11
Training loss: 2.3582081719964214
Validation loss: 2.523543738460349

Epoch: 7| Step: 0
Training loss: 3.0072564738193868
Validation loss: 2.5258624665449045

Epoch: 5| Step: 1
Training loss: 2.2976614714987633
Validation loss: 2.525490043160319

Epoch: 5| Step: 2
Training loss: 2.3938695295087205
Validation loss: 2.523786211671938

Epoch: 5| Step: 3
Training loss: 2.3137058516401385
Validation loss: 2.524220513426136

Epoch: 5| Step: 4
Training loss: 3.1822878540482393
Validation loss: 2.524080129705657

Epoch: 5| Step: 5
Training loss: 2.722334942678916
Validation loss: 2.5227642086237423

Epoch: 5| Step: 6
Training loss: 2.384338690605031
Validation loss: 2.526107698082206

Epoch: 5| Step: 7
Training loss: 2.624561091468736
Validation loss: 2.523143255126621

Epoch: 5| Step: 8
Training loss: 3.0289823564360003
Validation loss: 2.5230802533113836

Epoch: 5| Step: 9
Training loss: 2.702963851799902
Validation loss: 2.5222473763013538

Epoch: 5| Step: 10
Training loss: 2.000875162335893
Validation loss: 2.519776750772481

Epoch: 5| Step: 11
Training loss: 2.5420600920146583
Validation loss: 2.5256983743324177

Epoch: 8| Step: 0
Training loss: 3.262509406649888
Validation loss: 2.521227671121356

Epoch: 5| Step: 1
Training loss: 2.1673248709532316
Validation loss: 2.520588943099959

Epoch: 5| Step: 2
Training loss: 2.562191270047785
Validation loss: 2.517745070425518

Epoch: 5| Step: 3
Training loss: 2.932171635630059
Validation loss: 2.5169188368902806

Epoch: 5| Step: 4
Training loss: 2.6971510656338125
Validation loss: 2.519341588336216

Epoch: 5| Step: 5
Training loss: 2.461389990487533
Validation loss: 2.5162030971493485

Epoch: 5| Step: 6
Training loss: 2.8576211188438374
Validation loss: 2.5164125524736254

Epoch: 5| Step: 7
Training loss: 2.466557941961771
Validation loss: 2.5147152236908883

Epoch: 5| Step: 8
Training loss: 1.9373866017289156
Validation loss: 2.518477183413254

Epoch: 5| Step: 9
Training loss: 3.103193570058425
Validation loss: 2.5160582309561

Epoch: 5| Step: 10
Training loss: 2.1810886705958255
Validation loss: 2.5144509997834703

Epoch: 5| Step: 11
Training loss: 1.7500420974027695
Validation loss: 2.510097686530831

Epoch: 9| Step: 0
Training loss: 2.4825129218403865
Validation loss: 2.514959116882146

Epoch: 5| Step: 1
Training loss: 2.2422217389725736
Validation loss: 2.512931752314316

Epoch: 5| Step: 2
Training loss: 3.040416425743545
Validation loss: 2.51818227214734

Epoch: 5| Step: 3
Training loss: 2.2761035506319707
Validation loss: 2.514215299468707

Epoch: 5| Step: 4
Training loss: 2.613224046021192
Validation loss: 2.517874961382226

Epoch: 5| Step: 5
Training loss: 2.47414985852321
Validation loss: 2.518442211324221

Epoch: 5| Step: 6
Training loss: 2.7827775168000426
Validation loss: 2.5144086507400325

Epoch: 5| Step: 7
Training loss: 2.5945714545990093
Validation loss: 2.515577675194574

Epoch: 5| Step: 8
Training loss: 2.9027758106020194
Validation loss: 2.519976637160525

Epoch: 5| Step: 9
Training loss: 2.2505803949098633
Validation loss: 2.516964459063624

Epoch: 5| Step: 10
Training loss: 2.76467698222967
Validation loss: 2.515105977824345

Epoch: 5| Step: 11
Training loss: 3.1883412167388028
Validation loss: 2.521488121733183

Epoch: 10| Step: 0
Training loss: 2.6849962148515387
Validation loss: 2.5156079917632868

Epoch: 5| Step: 1
Training loss: 2.4450841437528767
Validation loss: 2.520255224811224

Epoch: 5| Step: 2
Training loss: 2.7248723166413304
Validation loss: 2.5200052687801806

Epoch: 5| Step: 3
Training loss: 3.020778225801679
Validation loss: 2.5205036859430514

Epoch: 5| Step: 4
Training loss: 2.4540355960406366
Validation loss: 2.5170955940326434

Epoch: 5| Step: 5
Training loss: 2.44663775427814
Validation loss: 2.5238001103281325

Epoch: 5| Step: 6
Training loss: 2.7103877760695942
Validation loss: 2.520307006483088

Epoch: 5| Step: 7
Training loss: 2.749433545813657
Validation loss: 2.519601599132562

Epoch: 5| Step: 8
Training loss: 1.8817965350457797
Validation loss: 2.519697202594188

Epoch: 5| Step: 9
Training loss: 2.498925550361595
Validation loss: 2.520053696987472

Epoch: 5| Step: 10
Training loss: 2.8128200772728738
Validation loss: 2.5230250577588222

Epoch: 5| Step: 11
Training loss: 2.9169840140494796
Validation loss: 2.5154028689798165

Epoch: 11| Step: 0
Training loss: 2.531810557143963
Validation loss: 2.513818348784176

Epoch: 5| Step: 1
Training loss: 2.564462050155832
Validation loss: 2.5113761474397642

Epoch: 5| Step: 2
Training loss: 2.2196149617581633
Validation loss: 2.5077006908301454

Epoch: 5| Step: 3
Training loss: 2.581710633933106
Validation loss: 2.5061564577868087

Epoch: 5| Step: 4
Training loss: 2.642294271467281
Validation loss: 2.5078184260439946

Epoch: 5| Step: 5
Training loss: 2.658227969466236
Validation loss: 2.501208406700192

Epoch: 5| Step: 6
Training loss: 2.54869585534432
Validation loss: 2.499756813142276

Epoch: 5| Step: 7
Training loss: 2.485837781669617
Validation loss: 2.501349386985534

Epoch: 5| Step: 8
Training loss: 2.5504911062014117
Validation loss: 2.5037815818756406

Epoch: 5| Step: 9
Training loss: 3.0157054831087287
Validation loss: 2.505451996837178

Epoch: 5| Step: 10
Training loss: 2.6778145965201143
Validation loss: 2.4998341942481406

Epoch: 5| Step: 11
Training loss: 2.5636014664511104
Validation loss: 2.5038343192097336

Epoch: 12| Step: 0
Training loss: 2.782188857128674
Validation loss: 2.4971072587457788

Epoch: 5| Step: 1
Training loss: 2.679704760615419
Validation loss: 2.5026597497478997

Epoch: 5| Step: 2
Training loss: 2.044200868482436
Validation loss: 2.4946350866144

Epoch: 5| Step: 3
Training loss: 2.3467968273731126
Validation loss: 2.4990486719155074

Epoch: 5| Step: 4
Training loss: 2.593853684156925
Validation loss: 2.4979346784260974

Epoch: 5| Step: 5
Training loss: 2.5871008707972583
Validation loss: 2.497561203006539

Epoch: 5| Step: 6
Training loss: 2.713302767750931
Validation loss: 2.497344812396423

Epoch: 5| Step: 7
Training loss: 2.352321666967346
Validation loss: 2.4931072622608412

Epoch: 5| Step: 8
Training loss: 2.7611815538466904
Validation loss: 2.4977595900037537

Epoch: 5| Step: 9
Training loss: 2.5469321964136897
Validation loss: 2.49292782995292

Epoch: 5| Step: 10
Training loss: 2.8619006733056245
Validation loss: 2.494899330656463

Epoch: 5| Step: 11
Training loss: 2.8064893284888206
Validation loss: 2.493650989271914

Epoch: 13| Step: 0
Training loss: 2.749115281408703
Validation loss: 2.494314424159488

Epoch: 5| Step: 1
Training loss: 2.362609969713164
Validation loss: 2.4897861850301424

Epoch: 5| Step: 2
Training loss: 2.2464631150098167
Validation loss: 2.4919187227445687

Epoch: 5| Step: 3
Training loss: 2.7195978706087827
Validation loss: 2.498270270862488

Epoch: 5| Step: 4
Training loss: 2.647857242360628
Validation loss: 2.4902887555336832

Epoch: 5| Step: 5
Training loss: 2.9198732097742237
Validation loss: 2.496825250807155

Epoch: 5| Step: 6
Training loss: 1.792686955533043
Validation loss: 2.497100125740155

Epoch: 5| Step: 7
Training loss: 3.013197005431686
Validation loss: 2.5043649357478537

Epoch: 5| Step: 8
Training loss: 2.7176729019875197
Validation loss: 2.502475355460772

Epoch: 5| Step: 9
Training loss: 2.254768405025832
Validation loss: 2.4976445187939587

Epoch: 5| Step: 10
Training loss: 2.649891322084712
Validation loss: 2.4981866200450393

Epoch: 5| Step: 11
Training loss: 3.1615175915128657
Validation loss: 2.491930419194628

Epoch: 14| Step: 0
Training loss: 2.5676849756216598
Validation loss: 2.4894689562924808

Epoch: 5| Step: 1
Training loss: 3.2592076669167414
Validation loss: 2.489718586481149

Epoch: 5| Step: 2
Training loss: 2.917755650267508
Validation loss: 2.4895583966867108

Epoch: 5| Step: 3
Training loss: 2.3243921038948927
Validation loss: 2.4864584346004657

Epoch: 5| Step: 4
Training loss: 2.2436099973050854
Validation loss: 2.477935165920793

Epoch: 5| Step: 5
Training loss: 2.9421155664500427
Validation loss: 2.4809203770515067

Epoch: 5| Step: 6
Training loss: 2.4115895070156323
Validation loss: 2.4811848205089677

Epoch: 5| Step: 7
Training loss: 2.8238238933160558
Validation loss: 2.4755858291535664

Epoch: 5| Step: 8
Training loss: 2.5852440771572347
Validation loss: 2.4792001238470034

Epoch: 5| Step: 9
Training loss: 1.9024057241132328
Validation loss: 2.477976646969607

Epoch: 5| Step: 10
Training loss: 2.0092427543916735
Validation loss: 2.480448428894266

Epoch: 5| Step: 11
Training loss: 2.486345385471313
Validation loss: 2.4834075859562352

Epoch: 15| Step: 0
Training loss: 3.106159330153841
Validation loss: 2.478051569276853

Epoch: 5| Step: 1
Training loss: 2.8306185862476325
Validation loss: 2.4800179539948375

Epoch: 5| Step: 2
Training loss: 2.2453554747947857
Validation loss: 2.4764007431297346

Epoch: 5| Step: 3
Training loss: 2.3534666950632057
Validation loss: 2.477755963979541

Epoch: 5| Step: 4
Training loss: 2.8269537086164678
Validation loss: 2.4800226406120167

Epoch: 5| Step: 5
Training loss: 2.449969746928369
Validation loss: 2.4813482292327067

Epoch: 5| Step: 6
Training loss: 2.6842154014669104
Validation loss: 2.480084591250918

Epoch: 5| Step: 7
Training loss: 2.3366572569341564
Validation loss: 2.4825785037494583

Epoch: 5| Step: 8
Training loss: 2.5331803484784654
Validation loss: 2.4840077422654083

Epoch: 5| Step: 9
Training loss: 2.3998718942784745
Validation loss: 2.481658998406653

Epoch: 5| Step: 10
Training loss: 2.260964908710529
Validation loss: 2.4897248069649702

Epoch: 5| Step: 11
Training loss: 1.641198339644319
Validation loss: 2.4912617996109923

Epoch: 16| Step: 0
Training loss: 2.457539079885119
Validation loss: 2.494388947339159

Epoch: 5| Step: 1
Training loss: 2.681048345207449
Validation loss: 2.4884296135460264

Epoch: 5| Step: 2
Training loss: 2.463698808901747
Validation loss: 2.486835580778473

Epoch: 5| Step: 3
Training loss: 2.1564171767733633
Validation loss: 2.4870196487300933

Epoch: 5| Step: 4
Training loss: 2.1729017067598777
Validation loss: 2.4832732038664203

Epoch: 5| Step: 5
Training loss: 2.6094771496542886
Validation loss: 2.4745616832975856

Epoch: 5| Step: 6
Training loss: 2.471373021677256
Validation loss: 2.483923001227784

Epoch: 5| Step: 7
Training loss: 2.579559851664681
Validation loss: 2.4811349850124933

Epoch: 5| Step: 8
Training loss: 2.6342598307312897
Validation loss: 2.4786064225507958

Epoch: 5| Step: 9
Training loss: 3.0745131316525716
Validation loss: 2.4804248155122206

Epoch: 5| Step: 10
Training loss: 2.5661324597405017
Validation loss: 2.47454709659882

Epoch: 5| Step: 11
Training loss: 3.0425985990171642
Validation loss: 2.47266930711783

Epoch: 17| Step: 0
Training loss: 2.5931177862494095
Validation loss: 2.467165277375762

Epoch: 5| Step: 1
Training loss: 2.786223861003543
Validation loss: 2.4728066316809203

Epoch: 5| Step: 2
Training loss: 2.656446472082452
Validation loss: 2.466844467142943

Epoch: 5| Step: 3
Training loss: 2.266922257075174
Validation loss: 2.467896833153866

Epoch: 5| Step: 4
Training loss: 2.5310188470483124
Validation loss: 2.4580125612908437

Epoch: 5| Step: 5
Training loss: 2.2936424292512814
Validation loss: 2.4594895154829444

Epoch: 5| Step: 6
Training loss: 1.9547889640448188
Validation loss: 2.4597756322445425

Epoch: 5| Step: 7
Training loss: 1.7714295299918574
Validation loss: 2.4602063096898172

Epoch: 5| Step: 8
Training loss: 3.005008331642724
Validation loss: 2.456542544136473

Epoch: 5| Step: 9
Training loss: 2.8274691332305184
Validation loss: 2.45103099565065

Epoch: 5| Step: 10
Training loss: 2.5980639144987947
Validation loss: 2.448020857088417

Epoch: 5| Step: 11
Training loss: 3.7819987414845633
Validation loss: 2.460906776357539

Epoch: 18| Step: 0
Training loss: 2.9104919649585668
Validation loss: 2.4491147389855454

Epoch: 5| Step: 1
Training loss: 2.4626197514728574
Validation loss: 2.4450007840215755

Epoch: 5| Step: 2
Training loss: 2.4270482094860486
Validation loss: 2.448072823487945

Epoch: 5| Step: 3
Training loss: 2.043077046603817
Validation loss: 2.4490010125711223

Epoch: 5| Step: 4
Training loss: 2.1542962109728125
Validation loss: 2.4424705037132375

Epoch: 5| Step: 5
Training loss: 2.6840075488943715
Validation loss: 2.452463996420728

Epoch: 5| Step: 6
Training loss: 2.785930937771602
Validation loss: 2.446041977435108

Epoch: 5| Step: 7
Training loss: 2.3313825717897356
Validation loss: 2.444145456335426

Epoch: 5| Step: 8
Training loss: 2.526285931814419
Validation loss: 2.4511665536688483

Epoch: 5| Step: 9
Training loss: 2.4414967756654353
Validation loss: 2.4444938524327178

Epoch: 5| Step: 10
Training loss: 2.920371581694853
Validation loss: 2.444173171664128

Epoch: 5| Step: 11
Training loss: 2.104989246694322
Validation loss: 2.449405265573098

Epoch: 19| Step: 0
Training loss: 2.761234052067193
Validation loss: 2.445636354071211

Epoch: 5| Step: 1
Training loss: 2.9526211747797606
Validation loss: 2.437024300365139

Epoch: 5| Step: 2
Training loss: 2.1332155622319866
Validation loss: 2.439915308094844

Epoch: 5| Step: 3
Training loss: 2.277344378149034
Validation loss: 2.4438101527753173

Epoch: 5| Step: 4
Training loss: 2.739673298759461
Validation loss: 2.43632890004948

Epoch: 5| Step: 5
Training loss: 2.6887987236882513
Validation loss: 2.443984974380002

Epoch: 5| Step: 6
Training loss: 2.5001224487834857
Validation loss: 2.44776155237373

Epoch: 5| Step: 7
Training loss: 2.3660232148309315
Validation loss: 2.4479952387002486

Epoch: 5| Step: 8
Training loss: 2.7514705194179485
Validation loss: 2.450837500310436

Epoch: 5| Step: 9
Training loss: 2.106684119880584
Validation loss: 2.4528577136556335

Epoch: 5| Step: 10
Training loss: 2.1124636043144562
Validation loss: 2.4593027952517947

Epoch: 5| Step: 11
Training loss: 1.8461731327406612
Validation loss: 2.456603623027273

Epoch: 20| Step: 0
Training loss: 2.030090353134172
Validation loss: 2.4709870709284654

Epoch: 5| Step: 1
Training loss: 2.9087938230169867
Validation loss: 2.476616198000702

Epoch: 5| Step: 2
Training loss: 2.042172803876982
Validation loss: 2.476513086943151

Epoch: 5| Step: 3
Training loss: 2.5727475583079067
Validation loss: 2.4808754254675183

Epoch: 5| Step: 4
Training loss: 3.0008330777913326
Validation loss: 2.483247373093793

Epoch: 5| Step: 5
Training loss: 2.6087394442890797
Validation loss: 2.4735147272561804

Epoch: 5| Step: 6
Training loss: 1.9723992208594952
Validation loss: 2.4692873148732533

Epoch: 5| Step: 7
Training loss: 2.4955429400703295
Validation loss: 2.4658892510474586

Epoch: 5| Step: 8
Training loss: 2.8446814719757207
Validation loss: 2.4565552178076664

Epoch: 5| Step: 9
Training loss: 2.3533517107727793
Validation loss: 2.45646558677757

Epoch: 5| Step: 10
Training loss: 2.5964008251858255
Validation loss: 2.452255617364545

Epoch: 5| Step: 11
Training loss: 2.56311902268519
Validation loss: 2.446929171755438

Epoch: 21| Step: 0
Training loss: 1.7841432063439886
Validation loss: 2.4325031185881594

Epoch: 5| Step: 1
Training loss: 2.6656080668046847
Validation loss: 2.4310859997506453

Epoch: 5| Step: 2
Training loss: 2.539457883127705
Validation loss: 2.428304890106268

Epoch: 5| Step: 3
Training loss: 2.639775698265309
Validation loss: 2.425078637857017

Epoch: 5| Step: 4
Training loss: 3.116271532139638
Validation loss: 2.425827263453534

Epoch: 5| Step: 5
Training loss: 2.358129513653061
Validation loss: 2.438267971981701

Epoch: 5| Step: 6
Training loss: 2.3241409929876555
Validation loss: 2.4245524649734556

Epoch: 5| Step: 7
Training loss: 2.626090686002138
Validation loss: 2.432972121917947

Epoch: 5| Step: 8
Training loss: 2.637565872309908
Validation loss: 2.431209451423902

Epoch: 5| Step: 9
Training loss: 2.0708529936421987
Validation loss: 2.4305744494354733

Epoch: 5| Step: 10
Training loss: 2.2927160692467194
Validation loss: 2.4233482023012103

Epoch: 5| Step: 11
Training loss: 3.0687422680417487
Validation loss: 2.4280154719416203

Epoch: 22| Step: 0
Training loss: 2.5173991326862555
Validation loss: 2.4162003228885625

Epoch: 5| Step: 1
Training loss: 2.3311452028993673
Validation loss: 2.4198905690333388

Epoch: 5| Step: 2
Training loss: 2.327482813393703
Validation loss: 2.4200079581626373

Epoch: 5| Step: 3
Training loss: 3.081058401840075
Validation loss: 2.4190283175741842

Epoch: 5| Step: 4
Training loss: 2.248797307176854
Validation loss: 2.421203856638197

Epoch: 5| Step: 5
Training loss: 2.640486312926087
Validation loss: 2.422174554162817

Epoch: 5| Step: 6
Training loss: 2.297603154403944
Validation loss: 2.428645778467575

Epoch: 5| Step: 7
Training loss: 3.0001568753234045
Validation loss: 2.434006245261335

Epoch: 5| Step: 8
Training loss: 2.0005181356655353
Validation loss: 2.430140944646309

Epoch: 5| Step: 9
Training loss: 1.9689935200566675
Validation loss: 2.4343681021948895

Epoch: 5| Step: 10
Training loss: 2.624327800605194
Validation loss: 2.4395397691124505

Epoch: 5| Step: 11
Training loss: 2.459099170771576
Validation loss: 2.4338139107333707

Epoch: 23| Step: 0
Training loss: 2.3753571492743752
Validation loss: 2.432319740334886

Epoch: 5| Step: 1
Training loss: 2.5680692675687324
Validation loss: 2.4337872039989463

Epoch: 5| Step: 2
Training loss: 2.7895979167014793
Validation loss: 2.4252416283872247

Epoch: 5| Step: 3
Training loss: 2.2274623190350376
Validation loss: 2.433181474684986

Epoch: 5| Step: 4
Training loss: 2.1310321237836036
Validation loss: 2.423476344013918

Epoch: 5| Step: 5
Training loss: 2.5305958597281863
Validation loss: 2.4188924041083024

Epoch: 5| Step: 6
Training loss: 2.3496788820052115
Validation loss: 2.4179401960931193

Epoch: 5| Step: 7
Training loss: 2.4001953442865567
Validation loss: 2.4251916755550074

Epoch: 5| Step: 8
Training loss: 2.7155976710025356
Validation loss: 2.415977292693477

Epoch: 5| Step: 9
Training loss: 2.299549543802141
Validation loss: 2.4288704286365133

Epoch: 5| Step: 10
Training loss: 2.452738251541022
Validation loss: 2.42118930338818

Epoch: 5| Step: 11
Training loss: 2.9423602863288902
Validation loss: 2.4115689844790142

Epoch: 24| Step: 0
Training loss: 2.5882795624593617
Validation loss: 2.417725180507365

Epoch: 5| Step: 1
Training loss: 2.668154083114893
Validation loss: 2.412674474995486

Epoch: 5| Step: 2
Training loss: 2.548442147798586
Validation loss: 2.401847366285219

Epoch: 5| Step: 3
Training loss: 2.0225640845784856
Validation loss: 2.4147269271818304

Epoch: 5| Step: 4
Training loss: 2.1198559375614194
Validation loss: 2.41297558921084

Epoch: 5| Step: 5
Training loss: 2.8330288517725313
Validation loss: 2.4119442408325833

Epoch: 5| Step: 6
Training loss: 2.237334525526697
Validation loss: 2.4030202476512548

Epoch: 5| Step: 7
Training loss: 2.7401078644286274
Validation loss: 2.4024855036898582

Epoch: 5| Step: 8
Training loss: 2.666579771612926
Validation loss: 2.405811158328985

Epoch: 5| Step: 9
Training loss: 2.279043096880567
Validation loss: 2.395804481056191

Epoch: 5| Step: 10
Training loss: 2.2756498393793554
Validation loss: 2.405634429766478

Epoch: 5| Step: 11
Training loss: 1.2910593461151758
Validation loss: 2.399288622907875

Epoch: 25| Step: 0
Training loss: 2.7107181515299024
Validation loss: 2.405258659826436

Epoch: 5| Step: 1
Training loss: 2.7587188009581567
Validation loss: 2.411632434061135

Epoch: 5| Step: 2
Training loss: 2.236745790350762
Validation loss: 2.421153588677208

Epoch: 5| Step: 3
Training loss: 2.5821814789113793
Validation loss: 2.4232302145212365

Epoch: 5| Step: 4
Training loss: 2.8112992160503882
Validation loss: 2.4343810341351753

Epoch: 5| Step: 5
Training loss: 2.6022851072155486
Validation loss: 2.4247052257683275

Epoch: 5| Step: 6
Training loss: 2.3278252325427995
Validation loss: 2.429758285521679

Epoch: 5| Step: 7
Training loss: 2.257212417213617
Validation loss: 2.424570077133411

Epoch: 5| Step: 8
Training loss: 1.4567100845925345
Validation loss: 2.411654904443845

Epoch: 5| Step: 9
Training loss: 2.433154707932308
Validation loss: 2.4327948143099167

Epoch: 5| Step: 10
Training loss: 2.3216752183277
Validation loss: 2.421495982219874

Epoch: 5| Step: 11
Training loss: 1.296294484566124
Validation loss: 2.4150590454870837

Epoch: 26| Step: 0
Training loss: 2.828540076044883
Validation loss: 2.4269963045575427

Epoch: 5| Step: 1
Training loss: 2.201625340622789
Validation loss: 2.3972307331640876

Epoch: 5| Step: 2
Training loss: 2.375814197917704
Validation loss: 2.4060756735799065

Epoch: 5| Step: 3
Training loss: 2.1012460690200045
Validation loss: 2.3970083934829014

Epoch: 5| Step: 4
Training loss: 2.5028514812633134
Validation loss: 2.388889085568807

Epoch: 5| Step: 5
Training loss: 2.6705409952776415
Validation loss: 2.399765897631763

Epoch: 5| Step: 6
Training loss: 2.46458586055554
Validation loss: 2.398323648672673

Epoch: 5| Step: 7
Training loss: 2.0537100087670273
Validation loss: 2.3910886817660213

Epoch: 5| Step: 8
Training loss: 2.108588064835507
Validation loss: 2.388467933347431

Epoch: 5| Step: 9
Training loss: 2.031577920120225
Validation loss: 2.389781341785387

Epoch: 5| Step: 10
Training loss: 2.9751766312680754
Validation loss: 2.3960130534282174

Epoch: 5| Step: 11
Training loss: 1.9503627928679605
Validation loss: 2.4072811757586368

Epoch: 27| Step: 0
Training loss: 2.0709431389518467
Validation loss: 2.395316297607331

Epoch: 5| Step: 1
Training loss: 2.268737549130242
Validation loss: 2.3918372095646485

Epoch: 5| Step: 2
Training loss: 3.0008152807600745
Validation loss: 2.4048032870311125

Epoch: 5| Step: 3
Training loss: 2.083422569906874
Validation loss: 2.4021522052769564

Epoch: 5| Step: 4
Training loss: 2.4321292493506332
Validation loss: 2.3880878731661075

Epoch: 5| Step: 5
Training loss: 2.632778722167178
Validation loss: 2.391628283404228

Epoch: 5| Step: 6
Training loss: 2.1910372880751243
Validation loss: 2.3752015471687025

Epoch: 5| Step: 7
Training loss: 2.2729905990292054
Validation loss: 2.375121607093147

Epoch: 5| Step: 8
Training loss: 2.29909682992429
Validation loss: 2.3800400869949807

Epoch: 5| Step: 9
Training loss: 2.3365729752974507
Validation loss: 2.382921764599338

Epoch: 5| Step: 10
Training loss: 2.313710076530183
Validation loss: 2.38646658789546

Epoch: 5| Step: 11
Training loss: 2.891084541702388
Validation loss: 2.387433342061377

Epoch: 28| Step: 0
Training loss: 2.938660574996136
Validation loss: 2.3858015438466467

Epoch: 5| Step: 1
Training loss: 2.1835504025983132
Validation loss: 2.3738595897352543

Epoch: 5| Step: 2
Training loss: 2.5225633931960703
Validation loss: 2.385272264621436

Epoch: 5| Step: 3
Training loss: 2.304950349980503
Validation loss: 2.3802301390558203

Epoch: 5| Step: 4
Training loss: 2.1714965710174803
Validation loss: 2.383432155563293

Epoch: 5| Step: 5
Training loss: 2.433421807008891
Validation loss: 2.375057125659368

Epoch: 5| Step: 6
Training loss: 2.3912411562670832
Validation loss: 2.3678726111327855

Epoch: 5| Step: 7
Training loss: 2.8275282425148713
Validation loss: 2.36948858915086

Epoch: 5| Step: 8
Training loss: 1.8753565131439947
Validation loss: 2.3871570877652806

Epoch: 5| Step: 9
Training loss: 2.232402437647774
Validation loss: 2.39762623845726

Epoch: 5| Step: 10
Training loss: 1.7785711389126655
Validation loss: 2.38923489497701

Epoch: 5| Step: 11
Training loss: 2.6011946134522925
Validation loss: 2.3979229287055537

Epoch: 29| Step: 0
Training loss: 2.0810478135151604
Validation loss: 2.391353217850333

Epoch: 5| Step: 1
Training loss: 1.9460134200979118
Validation loss: 2.3916125449814616

Epoch: 5| Step: 2
Training loss: 2.353484524723197
Validation loss: 2.3786286942246173

Epoch: 5| Step: 3
Training loss: 2.3082490976803474
Validation loss: 2.396548746245048

Epoch: 5| Step: 4
Training loss: 2.4374411160130127
Validation loss: 2.4079383855147043

Epoch: 5| Step: 5
Training loss: 2.371475515787325
Validation loss: 2.4015965361904055

Epoch: 5| Step: 6
Training loss: 2.4499329616172068
Validation loss: 2.397885539672843

Epoch: 5| Step: 7
Training loss: 1.9211957397939485
Validation loss: 2.407087560100475

Epoch: 5| Step: 8
Training loss: 2.864066688880001
Validation loss: 2.3730838662863247

Epoch: 5| Step: 9
Training loss: 1.983212588612441
Validation loss: 2.379463393641386

Epoch: 5| Step: 10
Training loss: 2.382656905300309
Validation loss: 2.381908612187204

Epoch: 5| Step: 11
Training loss: 3.0568899034734645
Validation loss: 2.380223778494397

Epoch: 30| Step: 0
Training loss: 2.2829556294297144
Validation loss: 2.36951196857426

Epoch: 5| Step: 1
Training loss: 2.242797662208336
Validation loss: 2.382673962010435

Epoch: 5| Step: 2
Training loss: 2.7443771097500465
Validation loss: 2.381337986386051

Epoch: 5| Step: 3
Training loss: 2.312244091823642
Validation loss: 2.3771125616694424

Epoch: 5| Step: 4
Training loss: 1.903144871399714
Validation loss: 2.3815641207694287

Epoch: 5| Step: 5
Training loss: 1.3745386910375348
Validation loss: 2.3578075187264775

Epoch: 5| Step: 6
Training loss: 2.7093107856083836
Validation loss: 2.361308890517583

Epoch: 5| Step: 7
Training loss: 2.659244330632983
Validation loss: 2.3924052626256405

Epoch: 5| Step: 8
Training loss: 2.4787274353570026
Validation loss: 2.371160754493537

Epoch: 5| Step: 9
Training loss: 2.288956883828927
Validation loss: 2.3758765242829893

Epoch: 5| Step: 10
Training loss: 2.5446885910322288
Validation loss: 2.386279669797515

Epoch: 5| Step: 11
Training loss: 0.9201668901001583
Validation loss: 2.372297941687409

Epoch: 31| Step: 0
Training loss: 1.972312852033776
Validation loss: 2.3823004500729383

Epoch: 5| Step: 1
Training loss: 2.435334931354362
Validation loss: 2.404948964486189

Epoch: 5| Step: 2
Training loss: 2.280748390545915
Validation loss: 2.415011749133692

Epoch: 5| Step: 3
Training loss: 2.374600025427802
Validation loss: 2.42285592097862

Epoch: 5| Step: 4
Training loss: 2.6193028342177826
Validation loss: 2.413922545523129

Epoch: 5| Step: 5
Training loss: 2.531308020409498
Validation loss: 2.3894777225302826

Epoch: 5| Step: 6
Training loss: 2.301573327188605
Validation loss: 2.3674284641343823

Epoch: 5| Step: 7
Training loss: 2.27742331416544
Validation loss: 2.35911379246113

Epoch: 5| Step: 8
Training loss: 2.2942941919206463
Validation loss: 2.35767619550275

Epoch: 5| Step: 9
Training loss: 2.1493408523424895
Validation loss: 2.3607302303962943

Epoch: 5| Step: 10
Training loss: 2.3177965697447873
Validation loss: 2.3558471443231124

Epoch: 5| Step: 11
Training loss: 1.2806408992765226
Validation loss: 2.3758836616471557

Epoch: 32| Step: 0
Training loss: 2.1250905410327037
Validation loss: 2.375539797792439

Epoch: 5| Step: 1
Training loss: 1.8368596135313084
Validation loss: 2.378891957892052

Epoch: 5| Step: 2
Training loss: 2.1764465082046405
Validation loss: 2.3624738506773952

Epoch: 5| Step: 3
Training loss: 2.605437454424584
Validation loss: 2.3842926306139764

Epoch: 5| Step: 4
Training loss: 2.1870718400735214
Validation loss: 2.3713537636084956

Epoch: 5| Step: 5
Training loss: 2.0909757311382715
Validation loss: 2.384021148156339

Epoch: 5| Step: 6
Training loss: 2.456004791056281
Validation loss: 2.3805746357288045

Epoch: 5| Step: 7
Training loss: 2.804964949716952
Validation loss: 2.409942155805996

Epoch: 5| Step: 8
Training loss: 2.1339983315930553
Validation loss: 2.3951926694733134

Epoch: 5| Step: 9
Training loss: 2.2881065690090963
Validation loss: 2.4025802764653053

Epoch: 5| Step: 10
Training loss: 2.2527010917023875
Validation loss: 2.4327998042362347

Epoch: 5| Step: 11
Training loss: 2.2825568649378276
Validation loss: 2.3995632756101415

Epoch: 33| Step: 0
Training loss: 2.7517974354635872
Validation loss: 2.425820068278115

Epoch: 5| Step: 1
Training loss: 2.253288197526193
Validation loss: 2.40663491510367

Epoch: 5| Step: 2
Training loss: 2.0100525705854895
Validation loss: 2.378626877489451

Epoch: 5| Step: 3
Training loss: 2.4735454870714078
Validation loss: 2.3857904346827326

Epoch: 5| Step: 4
Training loss: 2.1031299970774353
Validation loss: 2.3706626730661937

Epoch: 5| Step: 5
Training loss: 1.9647665748076655
Validation loss: 2.3835048399307195

Epoch: 5| Step: 6
Training loss: 2.2328819141316125
Validation loss: 2.3637225072772496

Epoch: 5| Step: 7
Training loss: 2.1616229136364318
Validation loss: 2.3678971497389605

Epoch: 5| Step: 8
Training loss: 2.4256622236109004
Validation loss: 2.384233299201146

Epoch: 5| Step: 9
Training loss: 2.246314739468279
Validation loss: 2.3717731799090704

Epoch: 5| Step: 10
Training loss: 2.465545989536552
Validation loss: 2.374276958796807

Epoch: 5| Step: 11
Training loss: 0.8554127992770819
Validation loss: 2.3880754892354616

Epoch: 34| Step: 0
Training loss: 2.526987607882525
Validation loss: 2.408073535246818

Epoch: 5| Step: 1
Training loss: 2.539792000071165
Validation loss: 2.3888747159558403

Epoch: 5| Step: 2
Training loss: 2.3222648036689044
Validation loss: 2.4350726071955218

Epoch: 5| Step: 3
Training loss: 1.577511961055817
Validation loss: 2.4056431161890957

Epoch: 5| Step: 4
Training loss: 2.116742076681889
Validation loss: 2.401445575482875

Epoch: 5| Step: 5
Training loss: 2.0692435329917367
Validation loss: 2.3942259468903684

Epoch: 5| Step: 6
Training loss: 2.4787767782222065
Validation loss: 2.3864596278768353

Epoch: 5| Step: 7
Training loss: 1.9122060063603237
Validation loss: 2.4005880416915932

Epoch: 5| Step: 8
Training loss: 2.147306609322124
Validation loss: 2.4022337477395572

Epoch: 5| Step: 9
Training loss: 2.4081037242512893
Validation loss: 2.3872069501028284

Epoch: 5| Step: 10
Training loss: 2.3005273546111042
Validation loss: 2.3875997928581376

Epoch: 5| Step: 11
Training loss: 2.956383738809323
Validation loss: 2.3668577302340137

Epoch: 35| Step: 0
Training loss: 2.4616751397911885
Validation loss: 2.373725716572301

Epoch: 5| Step: 1
Training loss: 1.8824175661840796
Validation loss: 2.3908802158033367

Epoch: 5| Step: 2
Training loss: 2.346537344017021
Validation loss: 2.3977581557296013

Epoch: 5| Step: 3
Training loss: 1.8856814358376572
Validation loss: 2.3870545196347868

Epoch: 5| Step: 4
Training loss: 2.0355617829375166
Validation loss: 2.376381560089574

Epoch: 5| Step: 5
Training loss: 2.963905155749393
Validation loss: 2.360985368453331

Epoch: 5| Step: 6
Training loss: 1.9981534897745268
Validation loss: 2.353893961907594

Epoch: 5| Step: 7
Training loss: 2.2009961820549373
Validation loss: 2.351095793279451

Epoch: 5| Step: 8
Training loss: 2.270935779558808
Validation loss: 2.4045511705711715

Epoch: 5| Step: 9
Training loss: 2.4992593621844357
Validation loss: 2.4110247357437995

Epoch: 5| Step: 10
Training loss: 2.206514064990351
Validation loss: 2.434644660982481

Epoch: 5| Step: 11
Training loss: 1.35241826478561
Validation loss: 2.4211624902217537

Epoch: 36| Step: 0
Training loss: 2.02584801331064
Validation loss: 2.3866701552984466

Epoch: 5| Step: 1
Training loss: 2.1583217674544444
Validation loss: 2.4051668115344014

Epoch: 5| Step: 2
Training loss: 1.9801559050668136
Validation loss: 2.368518002203087

Epoch: 5| Step: 3
Training loss: 1.9542306440843467
Validation loss: 2.3922543053545917

Epoch: 5| Step: 4
Training loss: 2.3871445595956233
Validation loss: 2.4110717642106

Epoch: 5| Step: 5
Training loss: 2.1603487284274197
Validation loss: 2.3801532706994535

Epoch: 5| Step: 6
Training loss: 2.5766136594635753
Validation loss: 2.4000853884262456

Epoch: 5| Step: 7
Training loss: 2.045440054370142
Validation loss: 2.3779023405848583

Epoch: 5| Step: 8
Training loss: 2.1634917350031078
Validation loss: 2.387399512900808

Epoch: 5| Step: 9
Training loss: 2.2198098029033195
Validation loss: 2.409478696677095

Epoch: 5| Step: 10
Training loss: 2.261022378189042
Validation loss: 2.41140860855764

Epoch: 5| Step: 11
Training loss: 4.522056777347958
Validation loss: 2.459875743643125

Epoch: 37| Step: 0
Training loss: 2.5671535199471043
Validation loss: 2.4185617322700295

Epoch: 5| Step: 1
Training loss: 2.3647953448147825
Validation loss: 2.372200294473191

Epoch: 5| Step: 2
Training loss: 1.8997324228097325
Validation loss: 2.3705532834313057

Epoch: 5| Step: 3
Training loss: 2.639185586501555
Validation loss: 2.3742844398769285

Epoch: 5| Step: 4
Training loss: 2.332147898863636
Validation loss: 2.3919854417443465

Epoch: 5| Step: 5
Training loss: 1.8701385417147334
Validation loss: 2.3681844284387914

Epoch: 5| Step: 6
Training loss: 2.036307391908707
Validation loss: 2.369607869381151

Epoch: 5| Step: 7
Training loss: 1.9385426084860171
Validation loss: 2.3456126928036243

Epoch: 5| Step: 8
Training loss: 1.9100917188981454
Validation loss: 2.3742221261113756

Epoch: 5| Step: 9
Training loss: 2.377539632087852
Validation loss: 2.366252317865751

Epoch: 5| Step: 10
Training loss: 2.11740674224469
Validation loss: 2.3602224811048327

Epoch: 5| Step: 11
Training loss: 1.9344383784004315
Validation loss: 2.3747032549001172

Epoch: 38| Step: 0
Training loss: 2.1459670410967147
Validation loss: 2.3625782617257967

Epoch: 5| Step: 1
Training loss: 2.058903303524218
Validation loss: 2.389904678297987

Epoch: 5| Step: 2
Training loss: 2.5428680540619193
Validation loss: 2.4121330846941706

Epoch: 5| Step: 3
Training loss: 2.407382351861752
Validation loss: 2.411742254780505

Epoch: 5| Step: 4
Training loss: 2.172736127551678
Validation loss: 2.4324746903713157

Epoch: 5| Step: 5
Training loss: 2.353066403899318
Validation loss: 2.3893106520889758

Epoch: 5| Step: 6
Training loss: 2.254138954354214
Validation loss: 2.402206739534956

Epoch: 5| Step: 7
Training loss: 2.1288428620867066
Validation loss: 2.3940770525901436

Epoch: 5| Step: 8
Training loss: 2.1240692344200705
Validation loss: 2.4175676702373083

Epoch: 5| Step: 9
Training loss: 1.8411917961746689
Validation loss: 2.410459152139599

Epoch: 5| Step: 10
Training loss: 2.2677987030017515
Validation loss: 2.4527487921925175

Epoch: 5| Step: 11
Training loss: 3.3453423817211805
Validation loss: 2.4730891109481803

Epoch: 39| Step: 0
Training loss: 2.1715502599090435
Validation loss: 2.4422815000114246

Epoch: 5| Step: 1
Training loss: 2.2362690613788785
Validation loss: 2.399854806640715

Epoch: 5| Step: 2
Training loss: 2.006087337566544
Validation loss: 2.386305428286326

Epoch: 5| Step: 3
Training loss: 2.3336513393410763
Validation loss: 2.3789055108631407

Epoch: 5| Step: 4
Training loss: 2.1926631484884442
Validation loss: 2.4219113377952177

Epoch: 5| Step: 5
Training loss: 1.7452165076923618
Validation loss: 2.4267199835077102

Epoch: 5| Step: 6
Training loss: 2.403798030665015
Validation loss: 2.457658797734957

Epoch: 5| Step: 7
Training loss: 2.3894071780669064
Validation loss: 2.462290320368755

Epoch: 5| Step: 8
Training loss: 2.396711791050979
Validation loss: 2.441247508673919

Epoch: 5| Step: 9
Training loss: 2.7555580325867517
Validation loss: 2.4247260959859083

Epoch: 5| Step: 10
Training loss: 2.0607299144857736
Validation loss: 2.386882245696308

Epoch: 5| Step: 11
Training loss: 2.377396829735237
Validation loss: 2.3956313186284843

Epoch: 40| Step: 0
Training loss: 2.531948605430124
Validation loss: 2.3945155140627827

Epoch: 5| Step: 1
Training loss: 2.0763409062188924
Validation loss: 2.425915694388752

Epoch: 5| Step: 2
Training loss: 1.7186542137504741
Validation loss: 2.5026203410366588

Epoch: 5| Step: 3
Training loss: 2.2694492029798785
Validation loss: 2.5181715734155734

Epoch: 5| Step: 4
Training loss: 2.121134889319622
Validation loss: 2.544618353769532

Epoch: 5| Step: 5
Training loss: 2.4954470183171646
Validation loss: 2.5326851084993254

Epoch: 5| Step: 6
Training loss: 2.2568364657141853
Validation loss: 2.475313310828917

Epoch: 5| Step: 7
Training loss: 2.260682074322285
Validation loss: 2.4269033264293705

Epoch: 5| Step: 8
Training loss: 2.5598175150680604
Validation loss: 2.412641407391633

Epoch: 5| Step: 9
Training loss: 1.779354894301378
Validation loss: 2.4045150538019753

Epoch: 5| Step: 10
Training loss: 2.161688759405827
Validation loss: 2.389776108229173

Epoch: 5| Step: 11
Training loss: 1.68418275659656
Validation loss: 2.3914606175623754

Epoch: 41| Step: 0
Training loss: 2.066806112732734
Validation loss: 2.391390792097172

Epoch: 5| Step: 1
Training loss: 2.1956570718031605
Validation loss: 2.389202663018293

Epoch: 5| Step: 2
Training loss: 2.812451425768692
Validation loss: 2.3968427059081936

Epoch: 5| Step: 3
Training loss: 1.809468529479481
Validation loss: 2.3897682350102287

Epoch: 5| Step: 4
Training loss: 1.925919224127632
Validation loss: 2.393886925455601

Epoch: 5| Step: 5
Training loss: 2.4209446258262783
Validation loss: 2.3897752602173967

Epoch: 5| Step: 6
Training loss: 2.1698649593823958
Validation loss: 2.4232807940072454

Epoch: 5| Step: 7
Training loss: 2.5286163946468543
Validation loss: 2.4077071942293182

Epoch: 5| Step: 8
Training loss: 2.122747124617537
Validation loss: 2.433237318099891

Epoch: 5| Step: 9
Training loss: 1.960001748823826
Validation loss: 2.451341195103323

Epoch: 5| Step: 10
Training loss: 2.1951474165020857
Validation loss: 2.448400434754307

Epoch: 5| Step: 11
Training loss: 2.5857340107401026
Validation loss: 2.4131563496193804

Epoch: 42| Step: 0
Training loss: 1.8419249602325845
Validation loss: 2.3769704692190023

Epoch: 5| Step: 1
Training loss: 1.982282240887468
Validation loss: 2.3788075084687197

Epoch: 5| Step: 2
Training loss: 1.7006453214901176
Validation loss: 2.405054460088665

Epoch: 5| Step: 3
Training loss: 1.9733983220963243
Validation loss: 2.3783335672385997

Epoch: 5| Step: 4
Training loss: 2.0968044263444425
Validation loss: 2.425371992445435

Epoch: 5| Step: 5
Training loss: 2.4340310476888503
Validation loss: 2.4023163584566456

Epoch: 5| Step: 6
Training loss: 2.4462387719381558
Validation loss: 2.4180111796611286

Epoch: 5| Step: 7
Training loss: 2.2635453775524392
Validation loss: 2.409041383358536

Epoch: 5| Step: 8
Training loss: 2.4766522219798435
Validation loss: 2.388389872271952

Epoch: 5| Step: 9
Training loss: 1.8978726523942038
Validation loss: 2.3839129132252723

Epoch: 5| Step: 10
Training loss: 2.6513175496044097
Validation loss: 2.3708937517142825

Epoch: 5| Step: 11
Training loss: 1.6908438718920769
Validation loss: 2.3822150518465524

Epoch: 43| Step: 0
Training loss: 2.586262293584044
Validation loss: 2.4065211234163963

Epoch: 5| Step: 1
Training loss: 2.0696299453420988
Validation loss: 2.40369942103558

Epoch: 5| Step: 2
Training loss: 2.1157578712559464
Validation loss: 2.4211744382218034

Epoch: 5| Step: 3
Training loss: 2.627208870276416
Validation loss: 2.422772017862833

Epoch: 5| Step: 4
Training loss: 1.8285725363659908
Validation loss: 2.423378487972602

Epoch: 5| Step: 5
Training loss: 1.8945542166979372
Validation loss: 2.388746853574673

Epoch: 5| Step: 6
Training loss: 1.967889325158401
Validation loss: 2.414928499049221

Epoch: 5| Step: 7
Training loss: 2.2670815882798485
Validation loss: 2.3906908587191587

Epoch: 5| Step: 8
Training loss: 1.7762757834080618
Validation loss: 2.3967399989359435

Epoch: 5| Step: 9
Training loss: 1.7826928435414953
Validation loss: 2.389195665232964

Epoch: 5| Step: 10
Training loss: 2.4076035891040797
Validation loss: 2.399560754370262

Epoch: 5| Step: 11
Training loss: 1.6910692544400356
Validation loss: 2.396073384629088

Epoch: 44| Step: 0
Training loss: 1.8569511836039105
Validation loss: 2.4111905756052154

Epoch: 5| Step: 1
Training loss: 2.0931200816431863
Validation loss: 2.401504527153171

Epoch: 5| Step: 2
Training loss: 2.1174371438453576
Validation loss: 2.369017838674068

Epoch: 5| Step: 3
Training loss: 2.34394225285714
Validation loss: 2.4085577553876414

Epoch: 5| Step: 4
Training loss: 2.5071126846777103
Validation loss: 2.4138025619161203

Epoch: 5| Step: 5
Training loss: 2.2313854785468217
Validation loss: 2.3965182272197154

Epoch: 5| Step: 6
Training loss: 2.2245242778253234
Validation loss: 2.383151746270142

Epoch: 5| Step: 7
Training loss: 1.778463828147189
Validation loss: 2.3829192174142

Epoch: 5| Step: 8
Training loss: 2.158316465137604
Validation loss: 2.382870103316979

Epoch: 5| Step: 9
Training loss: 2.5567112177813804
Validation loss: 2.383335912781989

Epoch: 5| Step: 10
Training loss: 1.1589918361998366
Validation loss: 2.36921211254325

Epoch: 5| Step: 11
Training loss: 2.0625534050703003
Validation loss: 2.387088255886898

Epoch: 45| Step: 0
Training loss: 1.8960125038523359
Validation loss: 2.388674915111122

Epoch: 5| Step: 1
Training loss: 2.031133795128568
Validation loss: 2.419344057440236

Epoch: 5| Step: 2
Training loss: 2.3293444620786246
Validation loss: 2.400839035078607

Epoch: 5| Step: 3
Training loss: 1.888843232737507
Validation loss: 2.4379503046102533

Epoch: 5| Step: 4
Training loss: 2.0600879320802865
Validation loss: 2.4501080802186785

Epoch: 5| Step: 5
Training loss: 2.1523541625060068
Validation loss: 2.464204752735987

Epoch: 5| Step: 6
Training loss: 2.294070237591884
Validation loss: 2.45766344210573

Epoch: 5| Step: 7
Training loss: 1.8058178156931366
Validation loss: 2.4288766086357025

Epoch: 5| Step: 8
Training loss: 2.2889891733135994
Validation loss: 2.437795841163545

Epoch: 5| Step: 9
Training loss: 2.4413345692602113
Validation loss: 2.413419572054891

Epoch: 5| Step: 10
Training loss: 1.8025740761951778
Validation loss: 2.3918990062767858

Epoch: 5| Step: 11
Training loss: 1.8545176427459134
Validation loss: 2.3985669476992966

Epoch: 46| Step: 0
Training loss: 1.9342816603023034
Validation loss: 2.392838735075844

Epoch: 5| Step: 1
Training loss: 2.074887844869361
Validation loss: 2.377594242026488

Epoch: 5| Step: 2
Training loss: 1.7677193432451754
Validation loss: 2.370214782222793

Epoch: 5| Step: 3
Training loss: 2.2081075828852215
Validation loss: 2.3920655948499725

Epoch: 5| Step: 4
Training loss: 1.8766790501517414
Validation loss: 2.3782038327625585

Epoch: 5| Step: 5
Training loss: 2.2935379595545666
Validation loss: 2.393745036074386

Epoch: 5| Step: 6
Training loss: 2.00266684114546
Validation loss: 2.4121622756737584

Epoch: 5| Step: 7
Training loss: 1.9057858011345106
Validation loss: 2.4409145317808902

Epoch: 5| Step: 8
Training loss: 2.134645673308273
Validation loss: 2.4000453033244433

Epoch: 5| Step: 9
Training loss: 2.6101444046587514
Validation loss: 2.4289504034005236

Epoch: 5| Step: 10
Training loss: 2.1700451504277556
Validation loss: 2.431826591274594

Epoch: 5| Step: 11
Training loss: 0.4602705122268674
Validation loss: 2.387386076807231

Epoch: 47| Step: 0
Training loss: 2.0534549395770267
Validation loss: 2.376495843939475

Epoch: 5| Step: 1
Training loss: 2.0726541196349895
Validation loss: 2.4106302871988983

Epoch: 5| Step: 2
Training loss: 2.3367797966025936
Validation loss: 2.392898940810541

Epoch: 5| Step: 3
Training loss: 1.920382408564318
Validation loss: 2.4036821518975255

Epoch: 5| Step: 4
Training loss: 2.500105283427611
Validation loss: 2.3982653747658804

Epoch: 5| Step: 5
Training loss: 2.1696076118346963
Validation loss: 2.392311386498409

Epoch: 5| Step: 6
Training loss: 2.0986622364081446
Validation loss: 2.417841890013555

Epoch: 5| Step: 7
Training loss: 2.0860825391772035
Validation loss: 2.3963715688140876

Epoch: 5| Step: 8
Training loss: 1.918276635842034
Validation loss: 2.420322462028161

Epoch: 5| Step: 9
Training loss: 1.7435033644306528
Validation loss: 2.395742588121446

Epoch: 5| Step: 10
Training loss: 1.9547953062875003
Validation loss: 2.4090255030277974

Epoch: 5| Step: 11
Training loss: 1.3198346960715284
Validation loss: 2.430761878626745

Epoch: 48| Step: 0
Training loss: 2.482076289194855
Validation loss: 2.4555310398300128

Epoch: 5| Step: 1
Training loss: 2.777040446227626
Validation loss: 2.4844296407388864

Epoch: 5| Step: 2
Training loss: 2.042357723552211
Validation loss: 2.43296648312818

Epoch: 5| Step: 3
Training loss: 2.2694996291566
Validation loss: 2.4455433534439774

Epoch: 5| Step: 4
Training loss: 1.6853010897937162
Validation loss: 2.392722682608155

Epoch: 5| Step: 5
Training loss: 1.8045453432579697
Validation loss: 2.397546981852392

Epoch: 5| Step: 6
Training loss: 1.976922888186325
Validation loss: 2.397572165587478

Epoch: 5| Step: 7
Training loss: 1.7032128407635296
Validation loss: 2.4183563513375668

Epoch: 5| Step: 8
Training loss: 1.7966453737236878
Validation loss: 2.419551501847821

Epoch: 5| Step: 9
Training loss: 2.104449136740638
Validation loss: 2.3951422745117354

Epoch: 5| Step: 10
Training loss: 2.2373589284741504
Validation loss: 2.398010851741769

Epoch: 5| Step: 11
Training loss: 1.7098957530809937
Validation loss: 2.40779747063998

Epoch: 49| Step: 0
Training loss: 2.7500591271719768
Validation loss: 2.420341399914839

Epoch: 5| Step: 1
Training loss: 1.8594461635787691
Validation loss: 2.4462002736194774

Epoch: 5| Step: 2
Training loss: 1.9536887003921994
Validation loss: 2.4791021352004075

Epoch: 5| Step: 3
Training loss: 1.6587482540348526
Validation loss: 2.4803012340780515

Epoch: 5| Step: 4
Training loss: 2.030222001738424
Validation loss: 2.495346184242216

Epoch: 5| Step: 5
Training loss: 2.218960281938053
Validation loss: 2.4556471014351087

Epoch: 5| Step: 6
Training loss: 1.3380370122639935
Validation loss: 2.4804291549285793

Epoch: 5| Step: 7
Training loss: 1.6155584856578404
Validation loss: 2.4713450405862143

Epoch: 5| Step: 8
Training loss: 1.6274339347825795
Validation loss: 2.4082568065459076

Epoch: 5| Step: 9
Training loss: 2.5234517666912395
Validation loss: 2.4224323902858846

Epoch: 5| Step: 10
Training loss: 1.6695018574720608
Validation loss: 2.388078846256261

Epoch: 5| Step: 11
Training loss: 3.9530241580208543
Validation loss: 2.3967569492054053

Epoch: 50| Step: 0
Training loss: 2.2228788187319917
Validation loss: 2.38625719151613

Epoch: 5| Step: 1
Training loss: 2.6755904749224704
Validation loss: 2.4465600305917454

Epoch: 5| Step: 2
Training loss: 1.9537832142843252
Validation loss: 2.416436272085312

Epoch: 5| Step: 3
Training loss: 1.974294092078944
Validation loss: 2.443547565583071

Epoch: 5| Step: 4
Training loss: 1.9110834722528711
Validation loss: 2.370190028708689

Epoch: 5| Step: 5
Training loss: 1.7919571958862264
Validation loss: 2.388904937578108

Epoch: 5| Step: 6
Training loss: 1.3079777876341538
Validation loss: 2.4093544036802927

Epoch: 5| Step: 7
Training loss: 1.3745324466965065
Validation loss: 2.403923912673577

Epoch: 5| Step: 8
Training loss: 2.1859870037938505
Validation loss: 2.4745200406242747

Epoch: 5| Step: 9
Training loss: 1.8619619373155734
Validation loss: 2.504058864979177

Epoch: 5| Step: 10
Training loss: 2.818197117481486
Validation loss: 2.4789802590715575

Epoch: 5| Step: 11
Training loss: 2.976626578214475
Validation loss: 2.46068703320423

Epoch: 51| Step: 0
Training loss: 1.9332197347788047
Validation loss: 2.4377203947670356

Epoch: 5| Step: 1
Training loss: 2.000068544166916
Validation loss: 2.392607359415624

Epoch: 5| Step: 2
Training loss: 1.7307351899671213
Validation loss: 2.3965353324299676

Epoch: 5| Step: 3
Training loss: 2.0033997012594846
Validation loss: 2.4031823986856127

Epoch: 5| Step: 4
Training loss: 2.117226913479427
Validation loss: 2.4101591063842664

Epoch: 5| Step: 5
Training loss: 1.798882068400929
Validation loss: 2.4099883150342416

Epoch: 5| Step: 6
Training loss: 1.7785059220861847
Validation loss: 2.409364233227928

Epoch: 5| Step: 7
Training loss: 2.308120085119391
Validation loss: 2.4081689110785347

Epoch: 5| Step: 8
Training loss: 2.1642367847096877
Validation loss: 2.4021994157143847

Epoch: 5| Step: 9
Training loss: 2.185294101746195
Validation loss: 2.398044897827321

Epoch: 5| Step: 10
Training loss: 2.1663605644947355
Validation loss: 2.403408246819382

Epoch: 5| Step: 11
Training loss: 2.403369021086811
Validation loss: 2.4261668252552036

Epoch: 52| Step: 0
Training loss: 1.7913973702012256
Validation loss: 2.4523434740552275

Epoch: 5| Step: 1
Training loss: 2.255255918169645
Validation loss: 2.455467767783023

Epoch: 5| Step: 2
Training loss: 1.4513000185262914
Validation loss: 2.4070279899029483

Epoch: 5| Step: 3
Training loss: 2.097524628159313
Validation loss: 2.4181770395223894

Epoch: 5| Step: 4
Training loss: 2.0608879494078876
Validation loss: 2.420445892191251

Epoch: 5| Step: 5
Training loss: 1.6615057273809655
Validation loss: 2.4104609077919337

Epoch: 5| Step: 6
Training loss: 1.325976844795434
Validation loss: 2.424477194441428

Epoch: 5| Step: 7
Training loss: 2.350649735742283
Validation loss: 2.4438475912108717

Epoch: 5| Step: 8
Training loss: 1.9678242641349946
Validation loss: 2.4127183976745936

Epoch: 5| Step: 9
Training loss: 2.63620220634797
Validation loss: 2.411096017669303

Epoch: 5| Step: 10
Training loss: 2.1603418860250247
Validation loss: 2.393614294191104

Epoch: 5| Step: 11
Training loss: 1.665003837145717
Validation loss: 2.399670576958328

Epoch: 53| Step: 0
Training loss: 1.920986435333448
Validation loss: 2.461407591309799

Epoch: 5| Step: 1
Training loss: 2.4057539391396694
Validation loss: 2.431451868291562

Epoch: 5| Step: 2
Training loss: 2.017816933811203
Validation loss: 2.4744644503971145

Epoch: 5| Step: 3
Training loss: 2.2780677861484615
Validation loss: 2.478797245283947

Epoch: 5| Step: 4
Training loss: 2.095311393993521
Validation loss: 2.485468775615171

Epoch: 5| Step: 5
Training loss: 1.8292660534852752
Validation loss: 2.467968080525973

Epoch: 5| Step: 6
Training loss: 1.172791084807574
Validation loss: 2.4451822402596304

Epoch: 5| Step: 7
Training loss: 1.9872769140603803
Validation loss: 2.41548997634085

Epoch: 5| Step: 8
Training loss: 1.3552461380881542
Validation loss: 2.4549601427133076

Epoch: 5| Step: 9
Training loss: 2.3756217142798453
Validation loss: 2.4294990679091493

Epoch: 5| Step: 10
Training loss: 1.866467899854791
Validation loss: 2.394438465388883

Epoch: 5| Step: 11
Training loss: 1.7596037151948696
Validation loss: 2.4076077482487652

Epoch: 54| Step: 0
Training loss: 2.328325301392923
Validation loss: 2.4131448271031637

Epoch: 5| Step: 1
Training loss: 1.7011178464664134
Validation loss: 2.4236927880992236

Epoch: 5| Step: 2
Training loss: 1.970564112377466
Validation loss: 2.4319663854752145

Epoch: 5| Step: 3
Training loss: 1.3258065126312915
Validation loss: 2.415905977976988

Epoch: 5| Step: 4
Training loss: 1.7209048548037482
Validation loss: 2.397116882539896

Epoch: 5| Step: 5
Training loss: 1.9580210240553344
Validation loss: 2.425064787867694

Epoch: 5| Step: 6
Training loss: 1.817039527018048
Validation loss: 2.4152469260185634

Epoch: 5| Step: 7
Training loss: 2.082893350552983
Validation loss: 2.424274216022611

Epoch: 5| Step: 8
Training loss: 2.15347155258276
Validation loss: 2.44321702054063

Epoch: 5| Step: 9
Training loss: 2.478570455030342
Validation loss: 2.4242186128036654

Epoch: 5| Step: 10
Training loss: 1.4905464775468409
Validation loss: 2.4726412523085

Epoch: 5| Step: 11
Training loss: 1.3254732024722744
Validation loss: 2.4692055205503487

Epoch: 55| Step: 0
Training loss: 2.4096686118761808
Validation loss: 2.454019861142755

Epoch: 5| Step: 1
Training loss: 2.282976829468039
Validation loss: 2.4766565459452354

Epoch: 5| Step: 2
Training loss: 2.153523919476873
Validation loss: 2.449121662914914

Epoch: 5| Step: 3
Training loss: 1.5403714882531163
Validation loss: 2.4573089976317424

Epoch: 5| Step: 4
Training loss: 1.5410426999265225
Validation loss: 2.4240808634381885

Epoch: 5| Step: 5
Training loss: 2.5321085851265024
Validation loss: 2.4070178288976347

Epoch: 5| Step: 6
Training loss: 1.5567440060851938
Validation loss: 2.439406757713262

Epoch: 5| Step: 7
Training loss: 1.477127290115589
Validation loss: 2.405683929773443

Epoch: 5| Step: 8
Training loss: 1.7778026617149763
Validation loss: 2.391110102982655

Epoch: 5| Step: 9
Training loss: 1.8823944514094333
Validation loss: 2.4054701519844652

Epoch: 5| Step: 10
Training loss: 1.6432971809284564
Validation loss: 2.42318799103351

Epoch: 5| Step: 11
Training loss: 1.7871439946057632
Validation loss: 2.42066195883206

Epoch: 56| Step: 0
Training loss: 2.349064612398445
Validation loss: 2.411507218087177

Epoch: 5| Step: 1
Training loss: 1.7666025072119502
Validation loss: 2.4220703743505325

Epoch: 5| Step: 2
Training loss: 2.0088161231162247
Validation loss: 2.392862793472467

Epoch: 5| Step: 3
Training loss: 1.9137126992226434
Validation loss: 2.429967318303305

Epoch: 5| Step: 4
Training loss: 1.7590218008229073
Validation loss: 2.432323203743496

Epoch: 5| Step: 5
Training loss: 2.0212798526519817
Validation loss: 2.4143933765930927

Epoch: 5| Step: 6
Training loss: 1.9010657809744298
Validation loss: 2.4230650285369495

Epoch: 5| Step: 7
Training loss: 1.7844656311641736
Validation loss: 2.442549358039703

Epoch: 5| Step: 8
Training loss: 1.3353885169590893
Validation loss: 2.4317757442574837

Epoch: 5| Step: 9
Training loss: 2.1224590143890247
Validation loss: 2.429813692469016

Epoch: 5| Step: 10
Training loss: 2.0935848797267824
Validation loss: 2.4680695340391536

Epoch: 5| Step: 11
Training loss: 1.181576813795493
Validation loss: 2.488429218326201

Epoch: 57| Step: 0
Training loss: 1.7324068053750228
Validation loss: 2.439134086716687

Epoch: 5| Step: 1
Training loss: 1.4457574108025533
Validation loss: 2.4963623742082

Epoch: 5| Step: 2
Training loss: 2.339449382784722
Validation loss: 2.497495159339223

Epoch: 5| Step: 3
Training loss: 1.8490154275451702
Validation loss: 2.4654002843485197

Epoch: 5| Step: 4
Training loss: 2.1697599142836803
Validation loss: 2.4187904465420766

Epoch: 5| Step: 5
Training loss: 1.775119672690046
Validation loss: 2.4336208731832354

Epoch: 5| Step: 6
Training loss: 1.5685866251826528
Validation loss: 2.447851445296394

Epoch: 5| Step: 7
Training loss: 2.1064026412214214
Validation loss: 2.416786418337469

Epoch: 5| Step: 8
Training loss: 1.7620807284286824
Validation loss: 2.4076356696223558

Epoch: 5| Step: 9
Training loss: 1.918339275922058
Validation loss: 2.407478964097394

Epoch: 5| Step: 10
Training loss: 2.257638997206002
Validation loss: 2.4590354916140575

Epoch: 5| Step: 11
Training loss: 1.185452251648851
Validation loss: 2.426613992872174

Epoch: 58| Step: 0
Training loss: 2.1823023490067706
Validation loss: 2.449042703810487

Epoch: 5| Step: 1
Training loss: 1.5040613664170635
Validation loss: 2.430264252205853

Epoch: 5| Step: 2
Training loss: 1.9673382374865995
Validation loss: 2.4214860008969863

Epoch: 5| Step: 3
Training loss: 1.8974345505274104
Validation loss: 2.43574605095234

Epoch: 5| Step: 4
Training loss: 1.8261635193659111
Validation loss: 2.41309617587256

Epoch: 5| Step: 5
Training loss: 1.7227841284381054
Validation loss: 2.431265336047969

Epoch: 5| Step: 6
Training loss: 1.9895587407001918
Validation loss: 2.4484811429611564

Epoch: 5| Step: 7
Training loss: 1.596767411461526
Validation loss: 2.4546335445490453

Epoch: 5| Step: 8
Training loss: 1.981258197370352
Validation loss: 2.445249721220925

Epoch: 5| Step: 9
Training loss: 1.9802861176500652
Validation loss: 2.4104594962640427

Epoch: 5| Step: 10
Training loss: 1.7349523322293416
Validation loss: 2.4259240788721566

Epoch: 5| Step: 11
Training loss: 2.656559825106545
Validation loss: 2.451243199175774

Epoch: 59| Step: 0
Training loss: 1.667161446879926
Validation loss: 2.405548790325561

Epoch: 5| Step: 1
Training loss: 2.0920294909249386
Validation loss: 2.4330931424670736

Epoch: 5| Step: 2
Training loss: 1.3631591742218283
Validation loss: 2.4132848596139382

Epoch: 5| Step: 3
Training loss: 1.7459433403347606
Validation loss: 2.390991419716552

Epoch: 5| Step: 4
Training loss: 1.5606341092932705
Validation loss: 2.453687548675844

Epoch: 5| Step: 5
Training loss: 2.14252482289698
Validation loss: 2.465540090822521

Epoch: 5| Step: 6
Training loss: 1.4584134579400099
Validation loss: 2.482981869022349

Epoch: 5| Step: 7
Training loss: 1.9884714811264081
Validation loss: 2.5349625178894843

Epoch: 5| Step: 8
Training loss: 2.839375243441995
Validation loss: 2.5017879450417815

Epoch: 5| Step: 9
Training loss: 2.0647590287862516
Validation loss: 2.499916909744385

Epoch: 5| Step: 10
Training loss: 1.6087294089208133
Validation loss: 2.450927981620366

Epoch: 5| Step: 11
Training loss: 1.4390580399865571
Validation loss: 2.4339023106686333

Epoch: 60| Step: 0
Training loss: 1.7500162123882814
Validation loss: 2.3915460802597317

Epoch: 5| Step: 1
Training loss: 1.9155346250140417
Validation loss: 2.41480627196433

Epoch: 5| Step: 2
Training loss: 2.521532313853691
Validation loss: 2.431721954824013

Epoch: 5| Step: 3
Training loss: 1.426311237648735
Validation loss: 2.4293172417217486

Epoch: 5| Step: 4
Training loss: 1.405958102978945
Validation loss: 2.3921235671284204

Epoch: 5| Step: 5
Training loss: 2.230001156725391
Validation loss: 2.4147787502710094

Epoch: 5| Step: 6
Training loss: 1.4413306570519353
Validation loss: 2.449267823428859

Epoch: 5| Step: 7
Training loss: 1.5015463011440473
Validation loss: 2.449653899146518

Epoch: 5| Step: 8
Training loss: 2.077213632468878
Validation loss: 2.4800484168481964

Epoch: 5| Step: 9
Training loss: 1.8270129872796408
Validation loss: 2.4986646264691132

Epoch: 5| Step: 10
Training loss: 2.26575190747747
Validation loss: 2.5181829112294363

Epoch: 5| Step: 11
Training loss: 1.5704071623704439
Validation loss: 2.437851864124042

Epoch: 61| Step: 0
Training loss: 1.4579880260190385
Validation loss: 2.40951890725948

Epoch: 5| Step: 1
Training loss: 1.6024277001554434
Validation loss: 2.424139940818928

Epoch: 5| Step: 2
Training loss: 1.6554031366268545
Validation loss: 2.4067513905438607

Epoch: 5| Step: 3
Training loss: 2.43002758528511
Validation loss: 2.414977993664145

Epoch: 5| Step: 4
Training loss: 2.152541579001115
Validation loss: 2.453946629997301

Epoch: 5| Step: 5
Training loss: 1.9228229200904452
Validation loss: 2.452753622043631

Epoch: 5| Step: 6
Training loss: 1.5650379930704648
Validation loss: 2.42843822322971

Epoch: 5| Step: 7
Training loss: 1.8341846945727498
Validation loss: 2.3964568211412725

Epoch: 5| Step: 8
Training loss: 2.1217804248615555
Validation loss: 2.429776377140969

Epoch: 5| Step: 9
Training loss: 1.3038393107443063
Validation loss: 2.445138886517418

Epoch: 5| Step: 10
Training loss: 1.9527248735648832
Validation loss: 2.452117692862768

Epoch: 5| Step: 11
Training loss: 0.8997222339302584
Validation loss: 2.4747913537559265

Epoch: 62| Step: 0
Training loss: 2.267906566034135
Validation loss: 2.514849337851779

Epoch: 5| Step: 1
Training loss: 1.7941541555381575
Validation loss: 2.437359210781953

Epoch: 5| Step: 2
Training loss: 1.5698302178394314
Validation loss: 2.4560594400672104

Epoch: 5| Step: 3
Training loss: 1.817434368601404
Validation loss: 2.435288244983525

Epoch: 5| Step: 4
Training loss: 1.8154182618403902
Validation loss: 2.39346072156351

Epoch: 5| Step: 5
Training loss: 1.7459044897954163
Validation loss: 2.404953954358965

Epoch: 5| Step: 6
Training loss: 1.7025517190031958
Validation loss: 2.4321394279807373

Epoch: 5| Step: 7
Training loss: 2.1518221740709063
Validation loss: 2.440372408871059

Epoch: 5| Step: 8
Training loss: 1.5946273632697385
Validation loss: 2.4057396475500377

Epoch: 5| Step: 9
Training loss: 1.350329812699657
Validation loss: 2.4071882016605453

Epoch: 5| Step: 10
Training loss: 2.2218035250513632
Validation loss: 2.399312637332145

Epoch: 5| Step: 11
Training loss: 1.5138119737332763
Validation loss: 2.410345067027148

Epoch: 63| Step: 0
Training loss: 2.02929499518681
Validation loss: 2.507624035781917

Epoch: 5| Step: 1
Training loss: 2.0822523618738082
Validation loss: 2.5651610095443576

Epoch: 5| Step: 2
Training loss: 1.7326593247072533
Validation loss: 2.5919379603399384

Epoch: 5| Step: 3
Training loss: 1.7601063321244321
Validation loss: 2.5697689815138993

Epoch: 5| Step: 4
Training loss: 2.0134769793080856
Validation loss: 2.5250512268988605

Epoch: 5| Step: 5
Training loss: 1.8543600845894201
Validation loss: 2.4534096400839247

Epoch: 5| Step: 6
Training loss: 1.7037811415268853
Validation loss: 2.4155219315570475

Epoch: 5| Step: 7
Training loss: 1.4036089786746786
Validation loss: 2.3771618177065426

Epoch: 5| Step: 8
Training loss: 2.2278775798716532
Validation loss: 2.4725216491929127

Epoch: 5| Step: 9
Training loss: 1.799785148195789
Validation loss: 2.40842499217558

Epoch: 5| Step: 10
Training loss: 1.6073664751853969
Validation loss: 2.4472862906470145

Epoch: 5| Step: 11
Training loss: 1.5155529516340045
Validation loss: 2.4503805800761658

Epoch: 64| Step: 0
Training loss: 1.4809382758507805
Validation loss: 2.4427885877416435

Epoch: 5| Step: 1
Training loss: 2.1294477701474936
Validation loss: 2.415352440706699

Epoch: 5| Step: 2
Training loss: 2.221434782174592
Validation loss: 2.4213495874118864

Epoch: 5| Step: 3
Training loss: 2.1501292833004264
Validation loss: 2.4213131160515227

Epoch: 5| Step: 4
Training loss: 1.7578146701375492
Validation loss: 2.421038193879245

Epoch: 5| Step: 5
Training loss: 1.580968956982168
Validation loss: 2.447931974782492

Epoch: 5| Step: 6
Training loss: 1.351714197366553
Validation loss: 2.414954871347704

Epoch: 5| Step: 7
Training loss: 1.869892921645951
Validation loss: 2.419899735902383

Epoch: 5| Step: 8
Training loss: 1.614715751222138
Validation loss: 2.420038679709685

Epoch: 5| Step: 9
Training loss: 1.7904294717762974
Validation loss: 2.463052287028293

Epoch: 5| Step: 10
Training loss: 1.2458984795998091
Validation loss: 2.4657770557197476

Epoch: 5| Step: 11
Training loss: 0.9214748225216247
Validation loss: 2.4527043631914203

Epoch: 65| Step: 0
Training loss: 1.7843440438974172
Validation loss: 2.435282272979518

Epoch: 5| Step: 1
Training loss: 1.486138430707732
Validation loss: 2.4194615901041923

Epoch: 5| Step: 2
Training loss: 2.325215409667453
Validation loss: 2.44694674059078

Epoch: 5| Step: 3
Training loss: 1.7896297838120878
Validation loss: 2.414819514353425

Epoch: 5| Step: 4
Training loss: 1.699165992356273
Validation loss: 2.404246226690647

Epoch: 5| Step: 5
Training loss: 1.5222529574506614
Validation loss: 2.409928136383301

Epoch: 5| Step: 6
Training loss: 1.4541449300167044
Validation loss: 2.4111974518769963

Epoch: 5| Step: 7
Training loss: 1.4278161146819925
Validation loss: 2.392542192876973

Epoch: 5| Step: 8
Training loss: 1.461653345338034
Validation loss: 2.377023125910464

Epoch: 5| Step: 9
Training loss: 2.0117883170237936
Validation loss: 2.399014795930603

Epoch: 5| Step: 10
Training loss: 1.8415510351321622
Validation loss: 2.390875452091011

Epoch: 5| Step: 11
Training loss: 1.1275693904221504
Validation loss: 2.430304319173294

Epoch: 66| Step: 0
Training loss: 1.590914803655697
Validation loss: 2.473605158174741

Epoch: 5| Step: 1
Training loss: 1.9307627905926164
Validation loss: 2.473333692832323

Epoch: 5| Step: 2
Training loss: 1.9155065577670338
Validation loss: 2.4698265440586025

Epoch: 5| Step: 3
Training loss: 2.109420323767987
Validation loss: 2.4831548009505684

Epoch: 5| Step: 4
Training loss: 1.4249820507324533
Validation loss: 2.5002664185663757

Epoch: 5| Step: 5
Training loss: 1.9039397702027159
Validation loss: 2.442153342315858

Epoch: 5| Step: 6
Training loss: 1.563931839064993
Validation loss: 2.4048410807398466

Epoch: 5| Step: 7
Training loss: 1.3305310613854846
Validation loss: 2.4084366073926824

Epoch: 5| Step: 8
Training loss: 1.7412094313036812
Validation loss: 2.4260488865178345

Epoch: 5| Step: 9
Training loss: 1.7925072036449445
Validation loss: 2.4416341364996903

Epoch: 5| Step: 10
Training loss: 1.6563555126049971
Validation loss: 2.3916558596624937

Epoch: 5| Step: 11
Training loss: 0.7105909068602951
Validation loss: 2.357068700917504

Epoch: 67| Step: 0
Training loss: 1.6706219549754286
Validation loss: 2.417884443104405

Epoch: 5| Step: 1
Training loss: 1.8403651314721956
Validation loss: 2.4569842804592334

Epoch: 5| Step: 2
Training loss: 1.1804477692310527
Validation loss: 2.442952932109968

Epoch: 5| Step: 3
Training loss: 2.056377571577853
Validation loss: 2.453816443994854

Epoch: 5| Step: 4
Training loss: 1.7883687235852126
Validation loss: 2.395826726710844

Epoch: 5| Step: 5
Training loss: 1.326697805668615
Validation loss: 2.439496158314968

Epoch: 5| Step: 6
Training loss: 1.5084028916451864
Validation loss: 2.4111169253433995

Epoch: 5| Step: 7
Training loss: 2.2340088657691592
Validation loss: 2.433509247579718

Epoch: 5| Step: 8
Training loss: 1.8041714677754128
Validation loss: 2.4394521456192937

Epoch: 5| Step: 9
Training loss: 1.4427600488677972
Validation loss: 2.436345890892322

Epoch: 5| Step: 10
Training loss: 1.4626847696554717
Validation loss: 2.468642314944491

Epoch: 5| Step: 11
Training loss: 1.5558478084654326
Validation loss: 2.404248288508377

Epoch: 68| Step: 0
Training loss: 1.719727186368605
Validation loss: 2.449056006484586

Epoch: 5| Step: 1
Training loss: 2.497915161573536
Validation loss: 2.4523887906410007

Epoch: 5| Step: 2
Training loss: 1.2902683513439828
Validation loss: 2.45898372861224

Epoch: 5| Step: 3
Training loss: 1.5305520627458291
Validation loss: 2.433299798494868

Epoch: 5| Step: 4
Training loss: 1.5733999389892814
Validation loss: 2.417121245666609

Epoch: 5| Step: 5
Training loss: 1.3544662682130515
Validation loss: 2.4590548827647645

Epoch: 5| Step: 6
Training loss: 1.6287082030290183
Validation loss: 2.440731970689233

Epoch: 5| Step: 7
Training loss: 1.3909509683958394
Validation loss: 2.4148969699734244

Epoch: 5| Step: 8
Training loss: 1.9351254340233484
Validation loss: 2.4118028371321882

Epoch: 5| Step: 9
Training loss: 1.438540372449701
Validation loss: 2.3909575619560353

Epoch: 5| Step: 10
Training loss: 1.538798043239332
Validation loss: 2.448636100778803

Epoch: 5| Step: 11
Training loss: 2.5095625145804603
Validation loss: 2.4236036837651347

Epoch: 69| Step: 0
Training loss: 1.5775761924757885
Validation loss: 2.391243819218631

Epoch: 5| Step: 1
Training loss: 1.5423978497826558
Validation loss: 2.4025196042089645

Epoch: 5| Step: 2
Training loss: 1.4625008933561807
Validation loss: 2.456017863893104

Epoch: 5| Step: 3
Training loss: 2.0463447175099456
Validation loss: 2.4595125220504044

Epoch: 5| Step: 4
Training loss: 1.0386765989588538
Validation loss: 2.4314698472114156

Epoch: 5| Step: 5
Training loss: 1.7507271618299258
Validation loss: 2.4171460651774503

Epoch: 5| Step: 6
Training loss: 1.504788702139253
Validation loss: 2.4190650430841796

Epoch: 5| Step: 7
Training loss: 2.2794724946735787
Validation loss: 2.3980237829730076

Epoch: 5| Step: 8
Training loss: 1.3956559718548074
Validation loss: 2.431738211883511

Epoch: 5| Step: 9
Training loss: 1.7555683645889046
Validation loss: 2.417244161193668

Epoch: 5| Step: 10
Training loss: 1.7502679619675914
Validation loss: 2.4471697188509056

Epoch: 5| Step: 11
Training loss: 0.7591481187762077
Validation loss: 2.4627066575551755

Epoch: 70| Step: 0
Training loss: 1.5213243745600789
Validation loss: 2.4881116528805047

Epoch: 5| Step: 1
Training loss: 1.2361213306237913
Validation loss: 2.519896212224262

Epoch: 5| Step: 2
Training loss: 2.088983947144401
Validation loss: 2.5657614716178583

Epoch: 5| Step: 3
Training loss: 0.8942855097625948
Validation loss: 2.562049907605456

Epoch: 5| Step: 4
Training loss: 1.638709485028207
Validation loss: 2.5080985820160664

Epoch: 5| Step: 5
Training loss: 1.4063007345584344
Validation loss: 2.491442235090867

Epoch: 5| Step: 6
Training loss: 1.8382835819409549
Validation loss: 2.4302643666604853

Epoch: 5| Step: 7
Training loss: 1.8118778344797029
Validation loss: 2.4130101178498977

Epoch: 5| Step: 8
Training loss: 1.6307954878485702
Validation loss: 2.4224012397919577

Epoch: 5| Step: 9
Training loss: 1.6936622005664783
Validation loss: 2.433804155441763

Epoch: 5| Step: 10
Training loss: 1.3192718738783227
Validation loss: 2.5158502663477083

Epoch: 5| Step: 11
Training loss: 3.7449898629758005
Validation loss: 2.48383598958235

Epoch: 71| Step: 0
Training loss: 2.0150659066679015
Validation loss: 2.47911329105097

Epoch: 5| Step: 1
Training loss: 1.7797548142346753
Validation loss: 2.432912083039101

Epoch: 5| Step: 2
Training loss: 1.3305879083698395
Validation loss: 2.5240849745893064

Epoch: 5| Step: 3
Training loss: 1.576171723735665
Validation loss: 2.5596567949755538

Epoch: 5| Step: 4
Training loss: 1.4823736250794044
Validation loss: 2.527507338420454

Epoch: 5| Step: 5
Training loss: 2.442144614909075
Validation loss: 2.503881564442655

Epoch: 5| Step: 6
Training loss: 1.0767598008736516
Validation loss: 2.4918139067069416

Epoch: 5| Step: 7
Training loss: 2.017558035884376
Validation loss: 2.428895312137706

Epoch: 5| Step: 8
Training loss: 1.1117418320297658
Validation loss: 2.4219001543112855

Epoch: 5| Step: 9
Training loss: 1.39643917410731
Validation loss: 2.4066195720223775

Epoch: 5| Step: 10
Training loss: 1.5853024418604102
Validation loss: 2.3731942841384983

Epoch: 5| Step: 11
Training loss: 1.4381440419938682
Validation loss: 2.396807461499504

Epoch: 72| Step: 0
Training loss: 1.675091795042907
Validation loss: 2.386492400562413

Epoch: 5| Step: 1
Training loss: 1.513038394408047
Validation loss: 2.4194334500412524

Epoch: 5| Step: 2
Training loss: 1.2645286238188336
Validation loss: 2.432321586397636

Epoch: 5| Step: 3
Training loss: 1.407995539376389
Validation loss: 2.3925984575095347

Epoch: 5| Step: 4
Training loss: 1.3957086289150766
Validation loss: 2.388523799021442

Epoch: 5| Step: 5
Training loss: 1.106230618150828
Validation loss: 2.4226704654975677

Epoch: 5| Step: 6
Training loss: 1.6939406227865874
Validation loss: 2.479671846871987

Epoch: 5| Step: 7
Training loss: 1.991047072765641
Validation loss: 2.4644966949192555

Epoch: 5| Step: 8
Training loss: 2.0610171680799656
Validation loss: 2.468761423945654

Epoch: 5| Step: 9
Training loss: 1.7990322266470515
Validation loss: 2.464155493001295

Epoch: 5| Step: 10
Training loss: 1.550886789569332
Validation loss: 2.449664102286779

Epoch: 5| Step: 11
Training loss: 0.5912767396973303
Validation loss: 2.426112882803578

Epoch: 73| Step: 0
Training loss: 1.1286950887374982
Validation loss: 2.4578087955615886

Epoch: 5| Step: 1
Training loss: 1.655260906340841
Validation loss: 2.3887842692031827

Epoch: 5| Step: 2
Training loss: 1.8050094251307363
Validation loss: 2.4579191842340835

Epoch: 5| Step: 3
Training loss: 1.2948561891952814
Validation loss: 2.433644922329748

Epoch: 5| Step: 4
Training loss: 1.6759414418444636
Validation loss: 2.4088434057596775

Epoch: 5| Step: 5
Training loss: 1.3854294922122672
Validation loss: 2.4782883620323943

Epoch: 5| Step: 6
Training loss: 1.6025862236452457
Validation loss: 2.4551072666458804

Epoch: 5| Step: 7
Training loss: 1.6935290259325422
Validation loss: 2.4334859727207405

Epoch: 5| Step: 8
Training loss: 1.8728160855191958
Validation loss: 2.4349052932201904

Epoch: 5| Step: 9
Training loss: 1.6276624582660577
Validation loss: 2.485257014166815

Epoch: 5| Step: 10
Training loss: 1.1814648710332423
Validation loss: 2.5249302624681245

Epoch: 5| Step: 11
Training loss: 0.6849769984163346
Validation loss: 2.5591301722136017

Epoch: 74| Step: 0
Training loss: 2.2734218741073287
Validation loss: 2.5559705609497785

Epoch: 5| Step: 1
Training loss: 1.6266359750530892
Validation loss: 2.544799036636538

Epoch: 5| Step: 2
Training loss: 1.3404876229562468
Validation loss: 2.4738815951575948

Epoch: 5| Step: 3
Training loss: 1.6226022343100492
Validation loss: 2.4887737762852047

Epoch: 5| Step: 4
Training loss: 1.481034626171538
Validation loss: 2.495106788011392

Epoch: 5| Step: 5
Training loss: 1.2622468392386768
Validation loss: 2.432493031326145

Epoch: 5| Step: 6
Training loss: 1.5151053255438893
Validation loss: 2.5101534216055836

Epoch: 5| Step: 7
Training loss: 1.366071190820668
Validation loss: 2.429751253262683

Epoch: 5| Step: 8
Training loss: 1.637803330609588
Validation loss: 2.4713314820438663

Epoch: 5| Step: 9
Training loss: 1.709366586723754
Validation loss: 2.4539188023986687

Epoch: 5| Step: 10
Training loss: 1.3866139546945422
Validation loss: 2.4634124541857396

Epoch: 5| Step: 11
Training loss: 2.6156276324588195
Validation loss: 2.4614002014820704

Epoch: 75| Step: 0
Training loss: 1.537419948199643
Validation loss: 2.4286808430793903

Epoch: 5| Step: 1
Training loss: 0.9881558847637508
Validation loss: 2.4675534624191062

Epoch: 5| Step: 2
Training loss: 0.8562420002361744
Validation loss: 2.475706471976772

Epoch: 5| Step: 3
Training loss: 1.2676441898381163
Validation loss: 2.488538396414557

Epoch: 5| Step: 4
Training loss: 1.6834468202136432
Validation loss: 2.4462289240609314

Epoch: 5| Step: 5
Training loss: 1.4944691415295703
Validation loss: 2.417208620392995

Epoch: 5| Step: 6
Training loss: 1.874682208786772
Validation loss: 2.4728938466159773

Epoch: 5| Step: 7
Training loss: 1.87576971149828
Validation loss: 2.486346396323905

Epoch: 5| Step: 8
Training loss: 1.6348891490723885
Validation loss: 2.44883419183574

Epoch: 5| Step: 9
Training loss: 1.4162068836352475
Validation loss: 2.370700772193625

Epoch: 5| Step: 10
Training loss: 1.7070632337982654
Validation loss: 2.4672842523384566

Epoch: 5| Step: 11
Training loss: 1.4220681530894537
Validation loss: 2.4223973644062835

Epoch: 76| Step: 0
Training loss: 1.7258317186221248
Validation loss: 2.434775194793635

Epoch: 5| Step: 1
Training loss: 0.9049029039490419
Validation loss: 2.4421956284075135

Epoch: 5| Step: 2
Training loss: 1.5975274591369417
Validation loss: 2.5130492424553266

Epoch: 5| Step: 3
Training loss: 1.5805538107458823
Validation loss: 2.4927428771730105

Epoch: 5| Step: 4
Training loss: 1.3817929318479023
Validation loss: 2.4526666508657597

Epoch: 5| Step: 5
Training loss: 1.4846144633634286
Validation loss: 2.4421655964291156

Epoch: 5| Step: 6
Training loss: 1.248042051398518
Validation loss: 2.4354617163345145

Epoch: 5| Step: 7
Training loss: 1.7240684758370244
Validation loss: 2.491284090087365

Epoch: 5| Step: 8
Training loss: 1.7913022742726397
Validation loss: 2.5241755812525217

Epoch: 5| Step: 9
Training loss: 1.4063638005304473
Validation loss: 2.497063410131179

Epoch: 5| Step: 10
Training loss: 1.5165114022872404
Validation loss: 2.47994878730784

Epoch: 5| Step: 11
Training loss: 0.6075277450881901
Validation loss: 2.412474032494527

Epoch: 77| Step: 0
Training loss: 1.3334504562832012
Validation loss: 2.4626836525905773

Epoch: 5| Step: 1
Training loss: 1.4471422315291427
Validation loss: 2.4243521829547428

Epoch: 5| Step: 2
Training loss: 1.6121884540363527
Validation loss: 2.478534150311132

Epoch: 5| Step: 3
Training loss: 1.653703927849389
Validation loss: 2.415299980074202

Epoch: 5| Step: 4
Training loss: 1.0493486132323186
Validation loss: 2.4469000869868043

Epoch: 5| Step: 5
Training loss: 2.0224698967691466
Validation loss: 2.460181581365365

Epoch: 5| Step: 6
Training loss: 1.2079841284561859
Validation loss: 2.4530106860048724

Epoch: 5| Step: 7
Training loss: 1.5561796915495836
Validation loss: 2.4619444104162276

Epoch: 5| Step: 8
Training loss: 1.1306314979986463
Validation loss: 2.490004026442902

Epoch: 5| Step: 9
Training loss: 1.0592445540784472
Validation loss: 2.4960871235217756

Epoch: 5| Step: 10
Training loss: 1.8022141455064178
Validation loss: 2.5093553615956004

Epoch: 5| Step: 11
Training loss: 1.5471249773355757
Validation loss: 2.477142374400775

Epoch: 78| Step: 0
Training loss: 1.4318794998371311
Validation loss: 2.449013652255146

Epoch: 5| Step: 1
Training loss: 1.240578527084603
Validation loss: 2.4598271806936647

Epoch: 5| Step: 2
Training loss: 2.079453352107546
Validation loss: 2.4794221046562575

Epoch: 5| Step: 3
Training loss: 1.6947005613380457
Validation loss: 2.4343724706601546

Epoch: 5| Step: 4
Training loss: 1.0168196474471618
Validation loss: 2.463402098290387

Epoch: 5| Step: 5
Training loss: 1.1464283814152083
Validation loss: 2.4153781174163163

Epoch: 5| Step: 6
Training loss: 1.6552044429297208
Validation loss: 2.4617857303786597

Epoch: 5| Step: 7
Training loss: 1.8170971940644787
Validation loss: 2.4371714329775873

Epoch: 5| Step: 8
Training loss: 1.1652520265690502
Validation loss: 2.481207335639396

Epoch: 5| Step: 9
Training loss: 1.4506979742271504
Validation loss: 2.4728526900665266

Epoch: 5| Step: 10
Training loss: 1.1880560627081165
Validation loss: 2.431784845898562

Epoch: 5| Step: 11
Training loss: 0.7269569884724881
Validation loss: 2.4520623037386646

Epoch: 79| Step: 0
Training loss: 1.2609701386379057
Validation loss: 2.4677193780031668

Epoch: 5| Step: 1
Training loss: 1.4832091722422893
Validation loss: 2.4546998308383183

Epoch: 5| Step: 2
Training loss: 1.1511949923251987
Validation loss: 2.410171599419104

Epoch: 5| Step: 3
Training loss: 1.3578874626581547
Validation loss: 2.440589178052821

Epoch: 5| Step: 4
Training loss: 0.9582256104559889
Validation loss: 2.441100872014511

Epoch: 5| Step: 5
Training loss: 2.1744577981656525
Validation loss: 2.4109741010378447

Epoch: 5| Step: 6
Training loss: 1.5002370488097738
Validation loss: 2.451323457162245

Epoch: 5| Step: 7
Training loss: 1.2205997026500937
Validation loss: 2.423403038437387

Epoch: 5| Step: 8
Training loss: 1.2382820682944111
Validation loss: 2.4860846436960546

Epoch: 5| Step: 9
Training loss: 1.6641064848481957
Validation loss: 2.4459653598324103

Epoch: 5| Step: 10
Training loss: 1.3351124675395756
Validation loss: 2.4825823132012177

Epoch: 5| Step: 11
Training loss: 1.01459938496158
Validation loss: 2.4749501432027503

Epoch: 80| Step: 0
Training loss: 1.3759186017057468
Validation loss: 2.4639786876356933

Epoch: 5| Step: 1
Training loss: 1.0269891975599876
Validation loss: 2.4744206823012087

Epoch: 5| Step: 2
Training loss: 1.1989394866142604
Validation loss: 2.4069148255788355

Epoch: 5| Step: 3
Training loss: 1.2524962772001877
Validation loss: 2.454574618302752

Epoch: 5| Step: 4
Training loss: 1.4751341031422933
Validation loss: 2.4168227175501427

Epoch: 5| Step: 5
Training loss: 1.2161674034716219
Validation loss: 2.4501389372446916

Epoch: 5| Step: 6
Training loss: 1.706114219321238
Validation loss: 2.4449477446744106

Epoch: 5| Step: 7
Training loss: 1.244825620733501
Validation loss: 2.463213603708757

Epoch: 5| Step: 8
Training loss: 1.210012316286442
Validation loss: 2.430326837647231

Epoch: 5| Step: 9
Training loss: 1.5945703227869081
Validation loss: 2.4997644790335385

Epoch: 5| Step: 10
Training loss: 1.518398931923783
Validation loss: 2.486128741887928

Epoch: 5| Step: 11
Training loss: 3.006855601896562
Validation loss: 2.501571431601705

Epoch: 81| Step: 0
Training loss: 1.8532431013225132
Validation loss: 2.5473506927910394

Epoch: 5| Step: 1
Training loss: 1.5600886239040443
Validation loss: 2.5728034073049524

Epoch: 5| Step: 2
Training loss: 1.549842684976462
Validation loss: 2.503191623285299

Epoch: 5| Step: 3
Training loss: 1.5599387730296328
Validation loss: 2.5142046352217307

Epoch: 5| Step: 4
Training loss: 0.8115032390922355
Validation loss: 2.48021342648033

Epoch: 5| Step: 5
Training loss: 1.353015273228593
Validation loss: 2.467835297115535

Epoch: 5| Step: 6
Training loss: 1.8333493434322539
Validation loss: 2.494952271666877

Epoch: 5| Step: 7
Training loss: 1.2049026732493704
Validation loss: 2.389973956947808

Epoch: 5| Step: 8
Training loss: 1.272187069560395
Validation loss: 2.489204463035362

Epoch: 5| Step: 9
Training loss: 1.5912540563395328
Validation loss: 2.4376789214824535

Epoch: 5| Step: 10
Training loss: 1.307490188095009
Validation loss: 2.4496609837639194

Epoch: 5| Step: 11
Training loss: 0.8922652148923941
Validation loss: 2.50681215658129

Epoch: 82| Step: 0
Training loss: 1.6891112229680194
Validation loss: 2.4415449993125273

Epoch: 5| Step: 1
Training loss: 1.7571484477035073
Validation loss: 2.4527725646886536

Epoch: 5| Step: 2
Training loss: 1.4094452055977194
Validation loss: 2.453126749414683

Epoch: 5| Step: 3
Training loss: 1.5937853042581789
Validation loss: 2.4770117070521125

Epoch: 5| Step: 4
Training loss: 1.0430482984059832
Validation loss: 2.4658259224906534

Epoch: 5| Step: 5
Training loss: 1.2424946051467043
Validation loss: 2.468664558155379

Epoch: 5| Step: 6
Training loss: 1.2000040471485556
Validation loss: 2.4508539305183215

Epoch: 5| Step: 7
Training loss: 1.3939780198448202
Validation loss: 2.4808910060526466

Epoch: 5| Step: 8
Training loss: 1.3130200127923508
Validation loss: 2.477890140136379

Epoch: 5| Step: 9
Training loss: 1.5501007970214433
Validation loss: 2.4717274930870765

Epoch: 5| Step: 10
Training loss: 1.1972208683677938
Validation loss: 2.442698355995304

Epoch: 5| Step: 11
Training loss: 1.4242960680273584
Validation loss: 2.45949283965443

Epoch: 83| Step: 0
Training loss: 1.2652548260403595
Validation loss: 2.5583480872330417

Epoch: 5| Step: 1
Training loss: 2.156302188849854
Validation loss: 2.6350306289757834

Epoch: 5| Step: 2
Training loss: 1.6296567948723089
Validation loss: 2.6781836350089576

Epoch: 5| Step: 3
Training loss: 1.5889122035725012
Validation loss: 2.5125951073645343

Epoch: 5| Step: 4
Training loss: 1.4570118593454604
Validation loss: 2.4706116670711484

Epoch: 5| Step: 5
Training loss: 1.3123758802308345
Validation loss: 2.477623059597211

Epoch: 5| Step: 6
Training loss: 1.35285922781576
Validation loss: 2.4742158909628476

Epoch: 5| Step: 7
Training loss: 1.3152925664832775
Validation loss: 2.4966919151917297

Epoch: 5| Step: 8
Training loss: 1.4413983931495302
Validation loss: 2.5202537663792413

Epoch: 5| Step: 9
Training loss: 1.5451194742914203
Validation loss: 2.4914336504366

Epoch: 5| Step: 10
Training loss: 1.3442721128796362
Validation loss: 2.4844935666787444

Epoch: 5| Step: 11
Training loss: 1.3768125638169104
Validation loss: 2.4027920064400727

Epoch: 84| Step: 0
Training loss: 1.52588242187095
Validation loss: 2.4511492926987235

Epoch: 5| Step: 1
Training loss: 1.4659979177046452
Validation loss: 2.422135579026783

Epoch: 5| Step: 2
Training loss: 0.9790044541963866
Validation loss: 2.430418156115946

Epoch: 5| Step: 3
Training loss: 1.2472166066702939
Validation loss: 2.4441517765472986

Epoch: 5| Step: 4
Training loss: 1.879948380552961
Validation loss: 2.452539904688123

Epoch: 5| Step: 5
Training loss: 1.478531347314647
Validation loss: 2.4682207606609095

Epoch: 5| Step: 6
Training loss: 1.3876771006238098
Validation loss: 2.479826011386764

Epoch: 5| Step: 7
Training loss: 0.9705528588146216
Validation loss: 2.4473868642186556

Epoch: 5| Step: 8
Training loss: 0.9422205335605182
Validation loss: 2.394685251781748

Epoch: 5| Step: 9
Training loss: 1.2225516277559352
Validation loss: 2.41978487043101

Epoch: 5| Step: 10
Training loss: 1.3704656047826271
Validation loss: 2.5233206274094

Epoch: 5| Step: 11
Training loss: 1.447509745036315
Validation loss: 2.4708167651834096

Epoch: 85| Step: 0
Training loss: 1.068908996355454
Validation loss: 2.4526956064986054

Epoch: 5| Step: 1
Training loss: 1.4386287901302497
Validation loss: 2.4603259017917205

Epoch: 5| Step: 2
Training loss: 1.5965771750109643
Validation loss: 2.4898640675190062

Epoch: 5| Step: 3
Training loss: 1.181893616382954
Validation loss: 2.467547268574172

Epoch: 5| Step: 4
Training loss: 1.3936823122839876
Validation loss: 2.4548582728679915

Epoch: 5| Step: 5
Training loss: 1.4687771084495496
Validation loss: 2.4753213614409657

Epoch: 5| Step: 6
Training loss: 0.9469963713559295
Validation loss: 2.417614978224423

Epoch: 5| Step: 7
Training loss: 1.707638560491531
Validation loss: 2.4583643544928444

Epoch: 5| Step: 8
Training loss: 1.3115378895273646
Validation loss: 2.500057482058584

Epoch: 5| Step: 9
Training loss: 0.9786067470982962
Validation loss: 2.522540607245266

Epoch: 5| Step: 10
Training loss: 1.4649007964152427
Validation loss: 2.4072514922815875

Epoch: 5| Step: 11
Training loss: 0.7674024541044625
Validation loss: 2.4349773794516474

Epoch: 86| Step: 0
Training loss: 1.0823498198398354
Validation loss: 2.46627030399225

Epoch: 5| Step: 1
Training loss: 1.78755477607936
Validation loss: 2.4777383229248633

Epoch: 5| Step: 2
Training loss: 1.1748550670599742
Validation loss: 2.460356584235801

Epoch: 5| Step: 3
Training loss: 1.147195209008618
Validation loss: 2.433761527624065

Epoch: 5| Step: 4
Training loss: 1.5095831401732522
Validation loss: 2.4820900732075586

Epoch: 5| Step: 5
Training loss: 1.4950989286676972
Validation loss: 2.402536608803761

Epoch: 5| Step: 6
Training loss: 1.313267574205057
Validation loss: 2.44941429156636

Epoch: 5| Step: 7
Training loss: 0.684943169721502
Validation loss: 2.4222941046245623

Epoch: 5| Step: 8
Training loss: 1.029999639640671
Validation loss: 2.4222717862521717

Epoch: 5| Step: 9
Training loss: 1.406770186110452
Validation loss: 2.4874377175781537

Epoch: 5| Step: 10
Training loss: 1.3427605201793458
Validation loss: 2.5057763006365184

Epoch: 5| Step: 11
Training loss: 1.336964441190358
Validation loss: 2.5089971214294136

Epoch: 87| Step: 0
Training loss: 1.645115691873504
Validation loss: 2.5471481067598893

Epoch: 5| Step: 1
Training loss: 0.9972577642720456
Validation loss: 2.4578433976410867

Epoch: 5| Step: 2
Training loss: 1.3661492465353864
Validation loss: 2.4215596311595458

Epoch: 5| Step: 3
Training loss: 0.5341042250867699
Validation loss: 2.4365814385553257

Epoch: 5| Step: 4
Training loss: 1.0150068309159452
Validation loss: 2.467900548533765

Epoch: 5| Step: 5
Training loss: 1.3300439323253908
Validation loss: 2.4450266288082134

Epoch: 5| Step: 6
Training loss: 1.2814427672728494
Validation loss: 2.393051125618329

Epoch: 5| Step: 7
Training loss: 1.715528486139292
Validation loss: 2.420736102505954

Epoch: 5| Step: 8
Training loss: 1.0257556084059543
Validation loss: 2.4742801671083683

Epoch: 5| Step: 9
Training loss: 1.008927844417421
Validation loss: 2.435473993919455

Epoch: 5| Step: 10
Training loss: 1.3199553599178662
Validation loss: 2.3459495374774626

Epoch: 5| Step: 11
Training loss: 2.128550648519261
Validation loss: 2.3825550211223527

Epoch: 88| Step: 0
Training loss: 1.2438276487102402
Validation loss: 2.45052539258824

Epoch: 5| Step: 1
Training loss: 0.9952420950860491
Validation loss: 2.4407155842726245

Epoch: 5| Step: 2
Training loss: 1.4878033849528713
Validation loss: 2.4349453735751703

Epoch: 5| Step: 3
Training loss: 1.282116852575157
Validation loss: 2.4557942570258167

Epoch: 5| Step: 4
Training loss: 1.295841632624275
Validation loss: 2.474656287001794

Epoch: 5| Step: 5
Training loss: 1.2720776183300586
Validation loss: 2.4255763042567975

Epoch: 5| Step: 6
Training loss: 1.1990299635412989
Validation loss: 2.4846369647218585

Epoch: 5| Step: 7
Training loss: 1.5280134289036573
Validation loss: 2.459762357253558

Epoch: 5| Step: 8
Training loss: 1.052241788709291
Validation loss: 2.409635193823143

Epoch: 5| Step: 9
Training loss: 1.6674553753373598
Validation loss: 2.452537636385478

Epoch: 5| Step: 10
Training loss: 0.8394522530687436
Validation loss: 2.476927689222831

Epoch: 5| Step: 11
Training loss: 0.887150932222169
Validation loss: 2.502946998197973

Epoch: 89| Step: 0
Training loss: 1.6540055812294097
Validation loss: 2.402760944478992

Epoch: 5| Step: 1
Training loss: 1.3505114398967497
Validation loss: 2.442508007421679

Epoch: 5| Step: 2
Training loss: 0.9534663230217718
Validation loss: 2.419719551091253

Epoch: 5| Step: 3
Training loss: 1.180683246264227
Validation loss: 2.4144424049013145

Epoch: 5| Step: 4
Training loss: 1.4038913868248415
Validation loss: 2.4134724892877255

Epoch: 5| Step: 5
Training loss: 1.3884382735513596
Validation loss: 2.460907696740261

Epoch: 5| Step: 6
Training loss: 1.2204110978818785
Validation loss: 2.371139861092662

Epoch: 5| Step: 7
Training loss: 1.3881751780434317
Validation loss: 2.4264291951444883

Epoch: 5| Step: 8
Training loss: 0.9307704356386421
Validation loss: 2.4464210865488334

Epoch: 5| Step: 9
Training loss: 1.0664096035747406
Validation loss: 2.4571899419419307

Epoch: 5| Step: 10
Training loss: 0.9831885499294486
Validation loss: 2.462762591840481

Epoch: 5| Step: 11
Training loss: 1.889065375061624
Validation loss: 2.423981583066704

Epoch: 90| Step: 0
Training loss: 1.4046765319599694
Validation loss: 2.4677737112363407

Epoch: 5| Step: 1
Training loss: 1.165801624487666
Validation loss: 2.495819988172598

Epoch: 5| Step: 2
Training loss: 1.397718319226309
Validation loss: 2.4231358886256325

Epoch: 5| Step: 3
Training loss: 1.1595650653357363
Validation loss: 2.4441577939428365

Epoch: 5| Step: 4
Training loss: 0.9506843774573843
Validation loss: 2.4262589554029352

Epoch: 5| Step: 5
Training loss: 1.3075730627590663
Validation loss: 2.4682407859973625

Epoch: 5| Step: 6
Training loss: 1.2815538836852063
Validation loss: 2.4712791123297038

Epoch: 5| Step: 7
Training loss: 1.7168011800909475
Validation loss: 2.5090636819144687

Epoch: 5| Step: 8
Training loss: 1.4715016338975748
Validation loss: 2.4501245051816287

Epoch: 5| Step: 9
Training loss: 0.8330626206965662
Validation loss: 2.4863907615600964

Epoch: 5| Step: 10
Training loss: 1.3806930074869872
Validation loss: 2.537588194236807

Epoch: 5| Step: 11
Training loss: 1.207773961566424
Validation loss: 2.5026040700753014

Epoch: 91| Step: 0
Training loss: 1.078343521307841
Validation loss: 2.491195277901678

Epoch: 5| Step: 1
Training loss: 1.6000184594520022
Validation loss: 2.480389411037891

Epoch: 5| Step: 2
Training loss: 1.0787361734682177
Validation loss: 2.48721866486371

Epoch: 5| Step: 3
Training loss: 1.0660743616122654
Validation loss: 2.4665795575582377

Epoch: 5| Step: 4
Training loss: 1.0315212702146046
Validation loss: 2.418906638521994

Epoch: 5| Step: 5
Training loss: 1.0790663217166996
Validation loss: 2.4386804342947133

Epoch: 5| Step: 6
Training loss: 1.1723661283675342
Validation loss: 2.46421270660523

Epoch: 5| Step: 7
Training loss: 1.4311533433018515
Validation loss: 2.4488084724251458

Epoch: 5| Step: 8
Training loss: 1.03793129975856
Validation loss: 2.4645442266793127

Epoch: 5| Step: 9
Training loss: 1.4346603874248756
Validation loss: 2.5059837772276095

Epoch: 5| Step: 10
Training loss: 0.9956656340061686
Validation loss: 2.505280096463019

Epoch: 5| Step: 11
Training loss: 1.8210488332268375
Validation loss: 2.556346638414285

Epoch: 92| Step: 0
Training loss: 1.3927002755585616
Validation loss: 2.518549934531622

Epoch: 5| Step: 1
Training loss: 1.2034787240170397
Validation loss: 2.556886770407347

Epoch: 5| Step: 2
Training loss: 0.9847027974588438
Validation loss: 2.5094867813625883

Epoch: 5| Step: 3
Training loss: 1.580377764871332
Validation loss: 2.526596206411894

Epoch: 5| Step: 4
Training loss: 1.3544222174891216
Validation loss: 2.5069111504520425

Epoch: 5| Step: 5
Training loss: 1.1992170103973794
Validation loss: 2.5322905156143274

Epoch: 5| Step: 6
Training loss: 0.9093782759145348
Validation loss: 2.4695735475223883

Epoch: 5| Step: 7
Training loss: 1.1434666496287382
Validation loss: 2.5268638701614057

Epoch: 5| Step: 8
Training loss: 0.7579306677485745
Validation loss: 2.5501512038524146

Epoch: 5| Step: 9
Training loss: 1.3256920015128177
Validation loss: 2.4798074356364403

Epoch: 5| Step: 10
Training loss: 1.17062199043828
Validation loss: 2.5214029580191486

Epoch: 5| Step: 11
Training loss: 0.5177852000451275
Validation loss: 2.5234360237235367

Epoch: 93| Step: 0
Training loss: 1.4460264349983756
Validation loss: 2.50960649314892

Epoch: 5| Step: 1
Training loss: 1.070957796802205
Validation loss: 2.4584752192742774

Epoch: 5| Step: 2
Training loss: 1.1153189231236553
Validation loss: 2.546795834050087

Epoch: 5| Step: 3
Training loss: 0.9340020727302049
Validation loss: 2.5388150529839613

Epoch: 5| Step: 4
Training loss: 1.6797249013595759
Validation loss: 2.534476978305813

Epoch: 5| Step: 5
Training loss: 1.4126645338391317
Validation loss: 2.6209736932508676

Epoch: 5| Step: 6
Training loss: 1.1102114465724373
Validation loss: 2.491763350887208

Epoch: 5| Step: 7
Training loss: 0.9668032251014625
Validation loss: 2.480777683193424

Epoch: 5| Step: 8
Training loss: 0.9394544890903396
Validation loss: 2.429313565475101

Epoch: 5| Step: 9
Training loss: 0.9726613056097433
Validation loss: 2.536065708977052

Epoch: 5| Step: 10
Training loss: 1.523167512885024
Validation loss: 2.5313552708968277

Epoch: 5| Step: 11
Training loss: 1.104797159279963
Validation loss: 2.5502291126109475

Epoch: 94| Step: 0
Training loss: 1.1611298351714876
Validation loss: 2.5738746787453235

Epoch: 5| Step: 1
Training loss: 1.6391720105180903
Validation loss: 2.533348010725452

Epoch: 5| Step: 2
Training loss: 1.2908126048144966
Validation loss: 2.4765946218691846

Epoch: 5| Step: 3
Training loss: 1.2354416885972694
Validation loss: 2.4103911793866146

Epoch: 5| Step: 4
Training loss: 1.1648331721623173
Validation loss: 2.509863675152849

Epoch: 5| Step: 5
Training loss: 1.2687928385150018
Validation loss: 2.453049786137492

Epoch: 5| Step: 6
Training loss: 1.047363053613029
Validation loss: 2.413100807208966

Epoch: 5| Step: 7
Training loss: 1.2975320185861645
Validation loss: 2.4577551838084157

Epoch: 5| Step: 8
Training loss: 1.4134404199820125
Validation loss: 2.452894860100456

Epoch: 5| Step: 9
Training loss: 0.9833718289636574
Validation loss: 2.526778034491874

Epoch: 5| Step: 10
Training loss: 1.1469178818006083
Validation loss: 2.4230045350777925

Epoch: 5| Step: 11
Training loss: 0.2991843624623845
Validation loss: 2.414499434647422

Epoch: 95| Step: 0
Training loss: 0.6178291462115872
Validation loss: 2.4417409438551836

Epoch: 5| Step: 1
Training loss: 0.9027308504835561
Validation loss: 2.5090637333852213

Epoch: 5| Step: 2
Training loss: 1.480591137339001
Validation loss: 2.4749279063093192

Epoch: 5| Step: 3
Training loss: 1.2412668331115055
Validation loss: 2.4484920772335763

Epoch: 5| Step: 4
Training loss: 0.962557350035435
Validation loss: 2.485687468986469

Epoch: 5| Step: 5
Training loss: 1.2730923518403494
Validation loss: 2.441409623207305

Epoch: 5| Step: 6
Training loss: 1.1637056559012937
Validation loss: 2.493295556762267

Epoch: 5| Step: 7
Training loss: 0.6673061810249935
Validation loss: 2.4397635138994382

Epoch: 5| Step: 8
Training loss: 1.1433390895450224
Validation loss: 2.446519738524989

Epoch: 5| Step: 9
Training loss: 1.4640039910642493
Validation loss: 2.4723931082648964

Epoch: 5| Step: 10
Training loss: 1.0469448009393758
Validation loss: 2.4393932130540756

Epoch: 5| Step: 11
Training loss: 1.0259153930624758
Validation loss: 2.3944008829577745

Epoch: 96| Step: 0
Training loss: 0.8933015391814917
Validation loss: 2.5531237265662665

Epoch: 5| Step: 1
Training loss: 1.3087594454041003
Validation loss: 2.5059501451131325

Epoch: 5| Step: 2
Training loss: 1.2757071179765433
Validation loss: 2.4565215762248274

Epoch: 5| Step: 3
Training loss: 1.2116801783942164
Validation loss: 2.535878535564713

Epoch: 5| Step: 4
Training loss: 1.4983161375921121
Validation loss: 2.4926633589805856

Epoch: 5| Step: 5
Training loss: 0.9580701210843182
Validation loss: 2.4390836710299206

Epoch: 5| Step: 6
Training loss: 0.9598216579601736
Validation loss: 2.4488802203873608

Epoch: 5| Step: 7
Training loss: 0.9924542826829807
Validation loss: 2.441939478308432

Epoch: 5| Step: 8
Training loss: 0.8762096490425778
Validation loss: 2.4924009943193473

Epoch: 5| Step: 9
Training loss: 1.4808210693492685
Validation loss: 2.410296386074027

Epoch: 5| Step: 10
Training loss: 0.7919667871355539
Validation loss: 2.4988423289673074

Epoch: 5| Step: 11
Training loss: 0.49927968054841887
Validation loss: 2.5277860589526377

Epoch: 97| Step: 0
Training loss: 0.9880365966011302
Validation loss: 2.500876801435143

Epoch: 5| Step: 1
Training loss: 1.1641592203192017
Validation loss: 2.563912711687772

Epoch: 5| Step: 2
Training loss: 0.8970719284086252
Validation loss: 2.444858135061527

Epoch: 5| Step: 3
Training loss: 1.552879624200891
Validation loss: 2.4265177863251477

Epoch: 5| Step: 4
Training loss: 1.4602747755282035
Validation loss: 2.484479913955475

Epoch: 5| Step: 5
Training loss: 1.2279489541487691
Validation loss: 2.4451800199784164

Epoch: 5| Step: 6
Training loss: 0.9349766787512162
Validation loss: 2.480128095168178

Epoch: 5| Step: 7
Training loss: 1.277265260483913
Validation loss: 2.4532057147505766

Epoch: 5| Step: 8
Training loss: 0.9543299953039455
Validation loss: 2.4496275678731716

Epoch: 5| Step: 9
Training loss: 0.9182131178231073
Validation loss: 2.4503338114401942

Epoch: 5| Step: 10
Training loss: 0.9841950267180053
Validation loss: 2.51532644075807

Epoch: 5| Step: 11
Training loss: 1.1887020251423974
Validation loss: 2.5901719542719537

Epoch: 98| Step: 0
Training loss: 0.7624044608625098
Validation loss: 2.510920815609231

Epoch: 5| Step: 1
Training loss: 0.9034458712358548
Validation loss: 2.5576121031739887

Epoch: 5| Step: 2
Training loss: 1.164620745654482
Validation loss: 2.4502120369028346

Epoch: 5| Step: 3
Training loss: 1.0567602629279396
Validation loss: 2.4772620471645115

Epoch: 5| Step: 4
Training loss: 1.29128300701249
Validation loss: 2.570862603961207

Epoch: 5| Step: 5
Training loss: 0.683254964529203
Validation loss: 2.5752983009981665

Epoch: 5| Step: 6
Training loss: 1.4802832977977194
Validation loss: 2.540059706660133

Epoch: 5| Step: 7
Training loss: 1.1505791553355058
Validation loss: 2.5779226242937057

Epoch: 5| Step: 8
Training loss: 1.5969005933528422
Validation loss: 2.505724630997292

Epoch: 5| Step: 9
Training loss: 1.3718664268973075
Validation loss: 2.497040017523186

Epoch: 5| Step: 10
Training loss: 0.9522460887425007
Validation loss: 2.540193890589171

Epoch: 5| Step: 11
Training loss: 0.3820714200047369
Validation loss: 2.5436314560670183

Epoch: 99| Step: 0
Training loss: 0.8314570205003937
Validation loss: 2.5527770727897097

Epoch: 5| Step: 1
Training loss: 1.3785470381173741
Validation loss: 2.5605399652771452

Epoch: 5| Step: 2
Training loss: 1.1255648042891533
Validation loss: 2.526227119690751

Epoch: 5| Step: 3
Training loss: 1.1055557162850762
Validation loss: 2.5404700539712257

Epoch: 5| Step: 4
Training loss: 1.2438539566991007
Validation loss: 2.5351095366717273

Epoch: 5| Step: 5
Training loss: 1.1770600116861225
Validation loss: 2.5019496388625733

Epoch: 5| Step: 6
Training loss: 1.2034442527579559
Validation loss: 2.529290814680893

Epoch: 5| Step: 7
Training loss: 0.8475579059702208
Validation loss: 2.478852525945011

Epoch: 5| Step: 8
Training loss: 0.8502543840101819
Validation loss: 2.488764294299555

Epoch: 5| Step: 9
Training loss: 1.6861579644810452
Validation loss: 2.5096080250617616

Epoch: 5| Step: 10
Training loss: 1.0452843153365552
Validation loss: 2.4840316235265436

Epoch: 5| Step: 11
Training loss: 0.7338129693067093
Validation loss: 2.4956848613560143

Epoch: 100| Step: 0
Training loss: 1.0070878610021232
Validation loss: 2.570024932265409

Epoch: 5| Step: 1
Training loss: 0.9096022135239594
Validation loss: 2.5689006703996027

Epoch: 5| Step: 2
Training loss: 0.7022956831696601
Validation loss: 2.5701702391611145

Epoch: 5| Step: 3
Training loss: 1.6361539681086827
Validation loss: 2.5320176306741486

Epoch: 5| Step: 4
Training loss: 0.8098455129284432
Validation loss: 2.4939935173319037

Epoch: 5| Step: 5
Training loss: 0.8447473777014546
Validation loss: 2.496583953146416

Epoch: 5| Step: 6
Training loss: 1.2190881406761547
Validation loss: 2.546866282348691

Epoch: 5| Step: 7
Training loss: 1.1990182317535938
Validation loss: 2.524500442886389

Epoch: 5| Step: 8
Training loss: 1.1316259549776442
Validation loss: 2.482157367227399

Epoch: 5| Step: 9
Training loss: 1.3492569414928222
Validation loss: 2.458767712465766

Epoch: 5| Step: 10
Training loss: 1.2374288230232255
Validation loss: 2.491272689670073

Epoch: 5| Step: 11
Training loss: 0.7914907653207219
Validation loss: 2.4814058170831066

Epoch: 101| Step: 0
Training loss: 0.7841869463174899
Validation loss: 2.4949524747326697

Epoch: 5| Step: 1
Training loss: 1.3654863946265512
Validation loss: 2.4686718819729077

Epoch: 5| Step: 2
Training loss: 0.9548275546718444
Validation loss: 2.4521700788358505

Epoch: 5| Step: 3
Training loss: 0.9261051046114002
Validation loss: 2.4297321352277885

Epoch: 5| Step: 4
Training loss: 1.0278643895218231
Validation loss: 2.4991093042291914

Epoch: 5| Step: 5
Training loss: 1.210817294153485
Validation loss: 2.5051070263550312

Epoch: 5| Step: 6
Training loss: 1.1854458157799825
Validation loss: 2.522715037001446

Epoch: 5| Step: 7
Training loss: 1.0734258326267025
Validation loss: 2.4184765711292227

Epoch: 5| Step: 8
Training loss: 1.0789224743572718
Validation loss: 2.5050100471449914

Epoch: 5| Step: 9
Training loss: 1.0227216007576305
Validation loss: 2.4738669422067194

Epoch: 5| Step: 10
Training loss: 0.7317694033861047
Validation loss: 2.539007348659839

Epoch: 5| Step: 11
Training loss: 0.2967308346907408
Validation loss: 2.488296708358903

Epoch: 102| Step: 0
Training loss: 1.081725535257833
Validation loss: 2.4445308577611486

Epoch: 5| Step: 1
Training loss: 0.938645426059666
Validation loss: 2.5025956150084805

Epoch: 5| Step: 2
Training loss: 0.7622304518117594
Validation loss: 2.538714910337016

Epoch: 5| Step: 3
Training loss: 1.4174600324428897
Validation loss: 2.4467774635223054

Epoch: 5| Step: 4
Training loss: 1.6256787276491644
Validation loss: 2.5092356754388314

Epoch: 5| Step: 5
Training loss: 0.8441535196727242
Validation loss: 2.4790063547078853

Epoch: 5| Step: 6
Training loss: 0.6514566751802001
Validation loss: 2.4476154642596173

Epoch: 5| Step: 7
Training loss: 0.7520364690393866
Validation loss: 2.4836186911230684

Epoch: 5| Step: 8
Training loss: 0.7661380994775082
Validation loss: 2.452112713888675

Epoch: 5| Step: 9
Training loss: 1.0678551859776209
Validation loss: 2.459427187445487

Epoch: 5| Step: 10
Training loss: 1.2094987258904422
Validation loss: 2.4504363882910867

Epoch: 5| Step: 11
Training loss: 1.6233408600843537
Validation loss: 2.429038121490332

Epoch: 103| Step: 0
Training loss: 0.9070385429095705
Validation loss: 2.477806893801528

Epoch: 5| Step: 1
Training loss: 0.8963706083561193
Validation loss: 2.484801649649974

Epoch: 5| Step: 2
Training loss: 0.8080284980927411
Validation loss: 2.474909936024018

Epoch: 5| Step: 3
Training loss: 1.1298047354451897
Validation loss: 2.5206823829243996

Epoch: 5| Step: 4
Training loss: 1.0612573649911339
Validation loss: 2.493830072779369

Epoch: 5| Step: 5
Training loss: 0.6013152865456404
Validation loss: 2.4625067415484017

Epoch: 5| Step: 6
Training loss: 1.0270951118851348
Validation loss: 2.5223002868132824

Epoch: 5| Step: 7
Training loss: 0.9041273975780906
Validation loss: 2.5328646992366632

Epoch: 5| Step: 8
Training loss: 0.9643466302007938
Validation loss: 2.523711883461137

Epoch: 5| Step: 9
Training loss: 1.6707105770662873
Validation loss: 2.516008758496069

Epoch: 5| Step: 10
Training loss: 0.9569203215168296
Validation loss: 2.441038798845228

Epoch: 5| Step: 11
Training loss: 0.6663436305688183
Validation loss: 2.4884683368002896

Epoch: 104| Step: 0
Training loss: 1.1651575966686945
Validation loss: 2.4848341687451563

Epoch: 5| Step: 1
Training loss: 0.7162976098339864
Validation loss: 2.445126771221225

Epoch: 5| Step: 2
Training loss: 1.0557141993471173
Validation loss: 2.4435373490992203

Epoch: 5| Step: 3
Training loss: 1.3782994391315035
Validation loss: 2.4996425452587188

Epoch: 5| Step: 4
Training loss: 1.4824532366062564
Validation loss: 2.508883436741164

Epoch: 5| Step: 5
Training loss: 0.7341300880623443
Validation loss: 2.420642381190862

Epoch: 5| Step: 6
Training loss: 0.9523774326492165
Validation loss: 2.4577859387636884

Epoch: 5| Step: 7
Training loss: 0.8145266712381272
Validation loss: 2.485666802879457

Epoch: 5| Step: 8
Training loss: 0.9857441901573425
Validation loss: 2.5392431458987907

Epoch: 5| Step: 9
Training loss: 0.9235757559667656
Validation loss: 2.4944407402748334

Epoch: 5| Step: 10
Training loss: 0.56814316769834
Validation loss: 2.4393698945620415

Epoch: 5| Step: 11
Training loss: 1.135588093453416
Validation loss: 2.5384861375080696

Epoch: 105| Step: 0
Training loss: 0.8310710757440576
Validation loss: 2.47230007746139

Epoch: 5| Step: 1
Training loss: 0.9921694175694468
Validation loss: 2.4481166690259077

Epoch: 5| Step: 2
Training loss: 0.7988079413589928
Validation loss: 2.4729850715125434

Epoch: 5| Step: 3
Training loss: 0.8560238086963426
Validation loss: 2.5251257674681526

Epoch: 5| Step: 4
Training loss: 1.0743823117666997
Validation loss: 2.50689554137427

Epoch: 5| Step: 5
Training loss: 0.7371476366132637
Validation loss: 2.4677498920355503

Epoch: 5| Step: 6
Training loss: 1.0761868844482745
Validation loss: 2.45955896267155

Epoch: 5| Step: 7
Training loss: 1.3985225289350558
Validation loss: 2.4471999126845834

Epoch: 5| Step: 8
Training loss: 0.9820425465373349
Validation loss: 2.486874436708131

Epoch: 5| Step: 9
Training loss: 0.8035980553227046
Validation loss: 2.5332775629538653

Epoch: 5| Step: 10
Training loss: 1.0234940491406894
Validation loss: 2.578853477285534

Epoch: 5| Step: 11
Training loss: 0.5372846837481792
Validation loss: 2.5403369815382093

Epoch: 106| Step: 0
Training loss: 1.5920158376049713
Validation loss: 2.5138756749178772

Epoch: 5| Step: 1
Training loss: 0.9100003743432921
Validation loss: 2.5621920571176378

Epoch: 5| Step: 2
Training loss: 1.173199680575052
Validation loss: 2.5327845109651723

Epoch: 5| Step: 3
Training loss: 0.5034692924969667
Validation loss: 2.510742296307647

Epoch: 5| Step: 4
Training loss: 1.123557225242295
Validation loss: 2.4841282520077432

Epoch: 5| Step: 5
Training loss: 1.2008720209762362
Validation loss: 2.4256737972423985

Epoch: 5| Step: 6
Training loss: 1.116448111046283
Validation loss: 2.5047935980561693

Epoch: 5| Step: 7
Training loss: 0.8692004922543294
Validation loss: 2.506962458814977

Epoch: 5| Step: 8
Training loss: 0.9323959647431315
Validation loss: 2.4931047957742787

Epoch: 5| Step: 9
Training loss: 0.8030231262786574
Validation loss: 2.477302089851345

Epoch: 5| Step: 10
Training loss: 0.7597503268312414
Validation loss: 2.514126665123561

Epoch: 5| Step: 11
Training loss: 0.4827804777025748
Validation loss: 2.5142818403452853

Epoch: 107| Step: 0
Training loss: 1.7610093272198815
Validation loss: 2.4885906783640435

Epoch: 5| Step: 1
Training loss: 0.7167864390764707
Validation loss: 2.550881177922313

Epoch: 5| Step: 2
Training loss: 0.6877569238722563
Validation loss: 2.550233611769059

Epoch: 5| Step: 3
Training loss: 0.9436164647801656
Validation loss: 2.4148913589107215

Epoch: 5| Step: 4
Training loss: 1.1294583353309118
Validation loss: 2.5083641800192975

Epoch: 5| Step: 5
Training loss: 0.7492737034919872
Validation loss: 2.525236093071495

Epoch: 5| Step: 6
Training loss: 0.9330865288154178
Validation loss: 2.487138636537591

Epoch: 5| Step: 7
Training loss: 0.7900589420566516
Validation loss: 2.508222825656642

Epoch: 5| Step: 8
Training loss: 1.157449049023941
Validation loss: 2.5384006204868634

Epoch: 5| Step: 9
Training loss: 0.8053478753369586
Validation loss: 2.510631632537729

Epoch: 5| Step: 10
Training loss: 0.934027375587903
Validation loss: 2.4988532853769327

Epoch: 5| Step: 11
Training loss: 0.6120930721251745
Validation loss: 2.518596856389285

Epoch: 108| Step: 0
Training loss: 0.7090417928013156
Validation loss: 2.4910314064828043

Epoch: 5| Step: 1
Training loss: 0.8603218064807664
Validation loss: 2.517862513509715

Epoch: 5| Step: 2
Training loss: 1.3693214547410644
Validation loss: 2.45726329878188

Epoch: 5| Step: 3
Training loss: 1.3436569359068269
Validation loss: 2.458890432876684

Epoch: 5| Step: 4
Training loss: 1.1414596430244226
Validation loss: 2.470055946959733

Epoch: 5| Step: 5
Training loss: 0.8076944187419677
Validation loss: 2.5439256644146124

Epoch: 5| Step: 6
Training loss: 1.0287479913258555
Validation loss: 2.5481665833103695

Epoch: 5| Step: 7
Training loss: 1.0598575044617053
Validation loss: 2.595535912066078

Epoch: 5| Step: 8
Training loss: 0.714316710582943
Validation loss: 2.5161295714524368

Epoch: 5| Step: 9
Training loss: 1.4269397784051954
Validation loss: 2.4932471506907086

Epoch: 5| Step: 10
Training loss: 0.7415052791981149
Validation loss: 2.5719938528070014

Epoch: 5| Step: 11
Training loss: 0.5273319101770554
Validation loss: 2.5066517969197277

Epoch: 109| Step: 0
Training loss: 0.7015178326361023
Validation loss: 2.4980856420448165

Epoch: 5| Step: 1
Training loss: 0.7584541593088661
Validation loss: 2.4957627269478073

Epoch: 5| Step: 2
Training loss: 1.0421779649289733
Validation loss: 2.496854257318421

Epoch: 5| Step: 3
Training loss: 1.000348030562852
Validation loss: 2.5199669237022326

Epoch: 5| Step: 4
Training loss: 0.8694459528871017
Validation loss: 2.5235053999104653

Epoch: 5| Step: 5
Training loss: 0.5607362752859854
Validation loss: 2.553833598101931

Epoch: 5| Step: 6
Training loss: 0.7610543116338677
Validation loss: 2.5333338860356416

Epoch: 5| Step: 7
Training loss: 1.015756979950027
Validation loss: 2.5016297233868743

Epoch: 5| Step: 8
Training loss: 1.7632457264781218
Validation loss: 2.5428277019052414

Epoch: 5| Step: 9
Training loss: 0.9863582795320884
Validation loss: 2.5267361770949526

Epoch: 5| Step: 10
Training loss: 0.9496424792791156
Validation loss: 2.419313483106943

Epoch: 5| Step: 11
Training loss: 1.1075845158278161
Validation loss: 2.5648828878988654

Epoch: 110| Step: 0
Training loss: 0.7025529441702847
Validation loss: 2.4233026542015907

Epoch: 5| Step: 1
Training loss: 1.0318502355477046
Validation loss: 2.4611061119163247

Epoch: 5| Step: 2
Training loss: 1.3139726460656496
Validation loss: 2.4235228562218722

Epoch: 5| Step: 3
Training loss: 1.2156779378234772
Validation loss: 2.5235683733973677

Epoch: 5| Step: 4
Training loss: 0.7062205730485429
Validation loss: 2.4489270228682085

Epoch: 5| Step: 5
Training loss: 1.215037192493613
Validation loss: 2.5586292021724337

Epoch: 5| Step: 6
Training loss: 0.7178150813679496
Validation loss: 2.457369786619374

Epoch: 5| Step: 7
Training loss: 0.9413272302157752
Validation loss: 2.4662649669022283

Epoch: 5| Step: 8
Training loss: 0.7170641658008517
Validation loss: 2.4488128455553446

Epoch: 5| Step: 9
Training loss: 0.521387241189641
Validation loss: 2.4827461220999045

Epoch: 5| Step: 10
Training loss: 1.0553300948592343
Validation loss: 2.4614385992855428

Epoch: 5| Step: 11
Training loss: 0.8325050330367894
Validation loss: 2.5338114349013465

Epoch: 111| Step: 0
Training loss: 0.9107358666809495
Validation loss: 2.4807186811792716

Epoch: 5| Step: 1
Training loss: 0.8519254838254047
Validation loss: 2.502262170839205

Epoch: 5| Step: 2
Training loss: 0.9117564267935359
Validation loss: 2.484066510191065

Epoch: 5| Step: 3
Training loss: 0.738296427898712
Validation loss: 2.5016353503644844

Epoch: 5| Step: 4
Training loss: 0.7496938875474042
Validation loss: 2.473611856927271

Epoch: 5| Step: 5
Training loss: 1.0419281186371439
Validation loss: 2.468280940825251

Epoch: 5| Step: 6
Training loss: 1.4887216472087863
Validation loss: 2.5057807091376993

Epoch: 5| Step: 7
Training loss: 0.802037588689367
Validation loss: 2.5458513203582256

Epoch: 5| Step: 8
Training loss: 0.8996427992766258
Validation loss: 2.497025325421125

Epoch: 5| Step: 9
Training loss: 0.6565660669228984
Validation loss: 2.466189249469552

Epoch: 5| Step: 10
Training loss: 1.0435387129134794
Validation loss: 2.5784183797657905

Epoch: 5| Step: 11
Training loss: 1.0691706002674206
Validation loss: 2.459909868385412

Epoch: 112| Step: 0
Training loss: 1.2136941358319167
Validation loss: 2.5034984786240617

Epoch: 5| Step: 1
Training loss: 0.8251001427299535
Validation loss: 2.455174246205994

Epoch: 5| Step: 2
Training loss: 1.6064033108585936
Validation loss: 2.540931991541777

Epoch: 5| Step: 3
Training loss: 0.8387540623300702
Validation loss: 2.5184629634875226

Epoch: 5| Step: 4
Training loss: 1.0353823432887623
Validation loss: 2.472457950107184

Epoch: 5| Step: 5
Training loss: 0.8494922776480257
Validation loss: 2.50365981993562

Epoch: 5| Step: 6
Training loss: 0.8590143313872158
Validation loss: 2.591115939225064

Epoch: 5| Step: 7
Training loss: 0.6125577315545896
Validation loss: 2.476159633596788

Epoch: 5| Step: 8
Training loss: 0.4929784595482442
Validation loss: 2.5660828261282376

Epoch: 5| Step: 9
Training loss: 0.5265840214709067
Validation loss: 2.4593020984552134

Epoch: 5| Step: 10
Training loss: 0.9040865560865585
Validation loss: 2.5391019690942733

Epoch: 5| Step: 11
Training loss: 0.3693283249722607
Validation loss: 2.5326533920827687

Epoch: 113| Step: 0
Training loss: 1.4558874964269035
Validation loss: 2.4816805785433735

Epoch: 5| Step: 1
Training loss: 0.9488118245282164
Validation loss: 2.520355109626953

Epoch: 5| Step: 2
Training loss: 0.7529013859715183
Validation loss: 2.521111371861702

Epoch: 5| Step: 3
Training loss: 0.7635391002853028
Validation loss: 2.489669512343822

Epoch: 5| Step: 4
Training loss: 1.1417142291962958
Validation loss: 2.551567184387878

Epoch: 5| Step: 5
Training loss: 0.8037082676709909
Validation loss: 2.4514374689134057

Epoch: 5| Step: 6
Training loss: 0.5737416627481778
Validation loss: 2.5063214806362137

Epoch: 5| Step: 7
Training loss: 0.6413468504151715
Validation loss: 2.528391407202425

Epoch: 5| Step: 8
Training loss: 0.887168870859981
Validation loss: 2.535693742056739

Epoch: 5| Step: 9
Training loss: 0.8239072238070664
Validation loss: 2.4364204909925076

Epoch: 5| Step: 10
Training loss: 1.0749480390188988
Validation loss: 2.4461376435199695

Epoch: 5| Step: 11
Training loss: 0.5545172094146013
Validation loss: 2.53779499597349

Epoch: 114| Step: 0
Training loss: 0.8832196672350657
Validation loss: 2.4899411775606564

Epoch: 5| Step: 1
Training loss: 0.8894806587470895
Validation loss: 2.5488574731532956

Epoch: 5| Step: 2
Training loss: 0.9111329106272555
Validation loss: 2.5193145146163816

Epoch: 5| Step: 3
Training loss: 0.6623204887752847
Validation loss: 2.539108393327729

Epoch: 5| Step: 4
Training loss: 0.9554265484726532
Validation loss: 2.4805847060766752

Epoch: 5| Step: 5
Training loss: 0.884842723998752
Validation loss: 2.499768969669134

Epoch: 5| Step: 6
Training loss: 0.5988041195471643
Validation loss: 2.4984927004532635

Epoch: 5| Step: 7
Training loss: 1.053905168650124
Validation loss: 2.5426932916713345

Epoch: 5| Step: 8
Training loss: 0.9752736245633119
Validation loss: 2.4202960866491003

Epoch: 5| Step: 9
Training loss: 0.7333248421509755
Validation loss: 2.5304186578220684

Epoch: 5| Step: 10
Training loss: 1.5042301770413498
Validation loss: 2.491807228980226

Epoch: 5| Step: 11
Training loss: 0.8064834404632969
Validation loss: 2.4708677093812055

Epoch: 115| Step: 0
Training loss: 0.7292838865246306
Validation loss: 2.594281417915968

Epoch: 5| Step: 1
Training loss: 1.2882204021752988
Validation loss: 2.5790988470003278

Epoch: 5| Step: 2
Training loss: 0.9543707164375989
Validation loss: 2.5296944677623334

Epoch: 5| Step: 3
Training loss: 0.98918327811438
Validation loss: 2.536493721518631

Epoch: 5| Step: 4
Training loss: 0.6232042502509904
Validation loss: 2.446775240628565

Epoch: 5| Step: 5
Training loss: 0.7921895676083641
Validation loss: 2.573231451312547

Epoch: 5| Step: 6
Training loss: 0.8956278114248101
Validation loss: 2.518811283202179

Epoch: 5| Step: 7
Training loss: 1.1780792288148234
Validation loss: 2.5149388216615405

Epoch: 5| Step: 8
Training loss: 0.8808021949766702
Validation loss: 2.5005744790603237

Epoch: 5| Step: 9
Training loss: 0.8181523172642381
Validation loss: 2.504077114042109

Epoch: 5| Step: 10
Training loss: 0.6856918833683511
Validation loss: 2.4712313603772498

Epoch: 5| Step: 11
Training loss: 0.5560768082844376
Validation loss: 2.5702078468483287

Epoch: 116| Step: 0
Training loss: 0.9014102351033949
Validation loss: 2.551583612264736

Epoch: 5| Step: 1
Training loss: 0.9063494397558818
Validation loss: 2.456797016018567

Epoch: 5| Step: 2
Training loss: 0.6995465879311699
Validation loss: 2.6115889227623197

Epoch: 5| Step: 3
Training loss: 0.9095060129601268
Validation loss: 2.5060862207845656

Epoch: 5| Step: 4
Training loss: 0.7522477006455559
Validation loss: 2.565960214873837

Epoch: 5| Step: 5
Training loss: 0.7755777051647741
Validation loss: 2.524451088649171

Epoch: 5| Step: 6
Training loss: 0.7966700645664274
Validation loss: 2.5098030216186795

Epoch: 5| Step: 7
Training loss: 1.466044185857256
Validation loss: 2.5437796062211846

Epoch: 5| Step: 8
Training loss: 0.6988373254177824
Validation loss: 2.5378799658237314

Epoch: 5| Step: 9
Training loss: 0.9868306003703013
Validation loss: 2.5565990564101213

Epoch: 5| Step: 10
Training loss: 0.9721143814101474
Validation loss: 2.5207998664988387

Epoch: 5| Step: 11
Training loss: 0.44779522121766563
Validation loss: 2.5328478381425263

Epoch: 117| Step: 0
Training loss: 0.6155111507735112
Validation loss: 2.5637055251791074

Epoch: 5| Step: 1
Training loss: 0.6017736089280442
Validation loss: 2.4484681556598598

Epoch: 5| Step: 2
Training loss: 0.7485693160472376
Validation loss: 2.490564615131069

Epoch: 5| Step: 3
Training loss: 0.9393554763643245
Validation loss: 2.580925732211772

Epoch: 5| Step: 4
Training loss: 0.7875243955194073
Validation loss: 2.5020063971814532

Epoch: 5| Step: 5
Training loss: 0.9822313491786577
Validation loss: 2.52992520769614

Epoch: 5| Step: 6
Training loss: 1.3862506774955725
Validation loss: 2.471614246464178

Epoch: 5| Step: 7
Training loss: 0.758684070054291
Validation loss: 2.4643350349286064

Epoch: 5| Step: 8
Training loss: 0.9997779480446762
Validation loss: 2.5013899872938823

Epoch: 5| Step: 9
Training loss: 0.7485377441680028
Validation loss: 2.5039473047724283

Epoch: 5| Step: 10
Training loss: 0.709236751646456
Validation loss: 2.5526389055755807

Epoch: 5| Step: 11
Training loss: 0.7847323435765505
Validation loss: 2.455852021386898

Epoch: 118| Step: 0
Training loss: 0.5270867180495717
Validation loss: 2.502395975832537

Epoch: 5| Step: 1
Training loss: 0.8120354277910872
Validation loss: 2.4704957696602703

Epoch: 5| Step: 2
Training loss: 0.41447974720840974
Validation loss: 2.4990736755194995

Epoch: 5| Step: 3
Training loss: 0.6986406163224232
Validation loss: 2.5186597652537226

Epoch: 5| Step: 4
Training loss: 0.938239187652469
Validation loss: 2.4574872166432744

Epoch: 5| Step: 5
Training loss: 0.7951558586504935
Validation loss: 2.452371947406015

Epoch: 5| Step: 6
Training loss: 0.9316302924712829
Validation loss: 2.4866502327946978

Epoch: 5| Step: 7
Training loss: 0.8480185160909623
Validation loss: 2.509378643357865

Epoch: 5| Step: 8
Training loss: 1.5493952709747743
Validation loss: 2.457142700513991

Epoch: 5| Step: 9
Training loss: 0.9211416722224209
Validation loss: 2.6071676027899073

Epoch: 5| Step: 10
Training loss: 0.5780741695018482
Validation loss: 2.5413264896398076

Epoch: 5| Step: 11
Training loss: 1.2897675406795128
Validation loss: 2.545020514582284

Epoch: 119| Step: 0
Training loss: 1.4299098607977756
Validation loss: 2.5187314836627634

Epoch: 5| Step: 1
Training loss: 0.9180026758296257
Validation loss: 2.592111403145628

Epoch: 5| Step: 2
Training loss: 0.7740012532206796
Validation loss: 2.464583794799873

Epoch: 5| Step: 3
Training loss: 0.8161672214869439
Validation loss: 2.5481706611709614

Epoch: 5| Step: 4
Training loss: 0.7926906605445242
Validation loss: 2.5555997069548475

Epoch: 5| Step: 5
Training loss: 0.7380711089898497
Validation loss: 2.501508563586246

Epoch: 5| Step: 6
Training loss: 0.6388798879482329
Validation loss: 2.522368248843756

Epoch: 5| Step: 7
Training loss: 0.8114819751343002
Validation loss: 2.4726065559877606

Epoch: 5| Step: 8
Training loss: 0.7932424965379447
Validation loss: 2.489120679160642

Epoch: 5| Step: 9
Training loss: 1.0343891684492421
Validation loss: 2.558723702661313

Epoch: 5| Step: 10
Training loss: 0.5636123943074016
Validation loss: 2.5920407205192073

Epoch: 5| Step: 11
Training loss: 0.7214325312569164
Validation loss: 2.511733648830462

Epoch: 120| Step: 0
Training loss: 1.010863365980938
Validation loss: 2.557873635715902

Epoch: 5| Step: 1
Training loss: 0.6197725554867006
Validation loss: 2.5083717958431087

Epoch: 5| Step: 2
Training loss: 0.8230229240738227
Validation loss: 2.6222783125171674

Epoch: 5| Step: 3
Training loss: 0.5875246550073849
Validation loss: 2.599431718487397

Epoch: 5| Step: 4
Training loss: 1.4963749155725352
Validation loss: 2.520753769893161

Epoch: 5| Step: 5
Training loss: 0.7071863921018141
Validation loss: 2.5722700103050395

Epoch: 5| Step: 6
Training loss: 0.7866918625541304
Validation loss: 2.545195987564582

Epoch: 5| Step: 7
Training loss: 0.8551319452167389
Validation loss: 2.5373822447979073

Epoch: 5| Step: 8
Training loss: 0.6906690600740664
Validation loss: 2.5476784404219885

Epoch: 5| Step: 9
Training loss: 0.6218174970101861
Validation loss: 2.542517134122025

Epoch: 5| Step: 10
Training loss: 0.5340188462489246
Validation loss: 2.427986841841189

Epoch: 5| Step: 11
Training loss: 0.3952497982914969
Validation loss: 2.5212555083859436

Epoch: 121| Step: 0
Training loss: 1.4215606509649696
Validation loss: 2.5299801290244384

Epoch: 5| Step: 1
Training loss: 0.7714433490129973
Validation loss: 2.5710682864122605

Epoch: 5| Step: 2
Training loss: 0.7353157754120706
Validation loss: 2.55168218119801

Epoch: 5| Step: 3
Training loss: 0.7136460573634732
Validation loss: 2.5428403440090745

Epoch: 5| Step: 4
Training loss: 0.9786277600146052
Validation loss: 2.531449910499571

Epoch: 5| Step: 5
Training loss: 0.7855073134496455
Validation loss: 2.4956497808433484

Epoch: 5| Step: 6
Training loss: 0.9581709634365269
Validation loss: 2.4757114837533303

Epoch: 5| Step: 7
Training loss: 0.6593386762114541
Validation loss: 2.5132507627513787

Epoch: 5| Step: 8
Training loss: 0.726344127037667
Validation loss: 2.5029805218310446

Epoch: 5| Step: 9
Training loss: 0.66021046613367
Validation loss: 2.4151197564732008

Epoch: 5| Step: 10
Training loss: 0.634729683665468
Validation loss: 2.535418045797942

Epoch: 5| Step: 11
Training loss: 0.8595553122271027
Validation loss: 2.4064269702617826

Epoch: 122| Step: 0
Training loss: 0.8498755027252205
Validation loss: 2.5729778735542173

Epoch: 5| Step: 1
Training loss: 0.7922480272272742
Validation loss: 2.546027091145625

Epoch: 5| Step: 2
Training loss: 0.8400592970922189
Validation loss: 2.5103503821289657

Epoch: 5| Step: 3
Training loss: 1.2585233965863523
Validation loss: 2.5040488160362204

Epoch: 5| Step: 4
Training loss: 0.8371382316283015
Validation loss: 2.4954271595536253

Epoch: 5| Step: 5
Training loss: 0.8781206477047183
Validation loss: 2.543920160268083

Epoch: 5| Step: 6
Training loss: 0.7871583681974231
Validation loss: 2.538723861413274

Epoch: 5| Step: 7
Training loss: 0.6786582432332185
Validation loss: 2.3998912419074983

Epoch: 5| Step: 8
Training loss: 0.649583607963747
Validation loss: 2.556726561584146

Epoch: 5| Step: 9
Training loss: 0.8110090661488757
Validation loss: 2.501319751481833

Epoch: 5| Step: 10
Training loss: 0.9117187709203618
Validation loss: 2.561226881309814

Epoch: 5| Step: 11
Training loss: 0.3170687133590828
Validation loss: 2.5325474023980012

Epoch: 123| Step: 0
Training loss: 0.8727763053253799
Validation loss: 2.580477148248902

Epoch: 5| Step: 1
Training loss: 0.6561399776328459
Validation loss: 2.4747063452938454

Epoch: 5| Step: 2
Training loss: 0.7267926989708787
Validation loss: 2.5724398612619535

Epoch: 5| Step: 3
Training loss: 0.739432391134448
Validation loss: 2.5549750210013156

Epoch: 5| Step: 4
Training loss: 0.6821520179541416
Validation loss: 2.528533134869317

Epoch: 5| Step: 5
Training loss: 0.4224812954650355
Validation loss: 2.581768732388793

Epoch: 5| Step: 6
Training loss: 0.8198027707373465
Validation loss: 2.6073135791629443

Epoch: 5| Step: 7
Training loss: 0.7502313495492754
Validation loss: 2.500042122247606

Epoch: 5| Step: 8
Training loss: 0.9335424177670041
Validation loss: 2.5205187338516435

Epoch: 5| Step: 9
Training loss: 0.5234678174249042
Validation loss: 2.545060254284921

Epoch: 5| Step: 10
Training loss: 1.3480154249910474
Validation loss: 2.555427622933077

Epoch: 5| Step: 11
Training loss: 0.37262478261721826
Validation loss: 2.5579451343074697

Epoch: 124| Step: 0
Training loss: 1.3180960385146625
Validation loss: 2.545989805200647

Epoch: 5| Step: 1
Training loss: 0.5734800920598048
Validation loss: 2.567923957844892

Epoch: 5| Step: 2
Training loss: 0.8467182647821951
Validation loss: 2.5847210284578863

Epoch: 5| Step: 3
Training loss: 0.6759598115720937
Validation loss: 2.5326429388359464

Epoch: 5| Step: 4
Training loss: 0.6822944281912869
Validation loss: 2.5333139144839176

Epoch: 5| Step: 5
Training loss: 0.880851728655664
Validation loss: 2.5540438899971667

Epoch: 5| Step: 6
Training loss: 0.7615547199188408
Validation loss: 2.5015816572838943

Epoch: 5| Step: 7
Training loss: 0.513440736469045
Validation loss: 2.460323228819531

Epoch: 5| Step: 8
Training loss: 1.0207490042803764
Validation loss: 2.563517225154929

Epoch: 5| Step: 9
Training loss: 0.6622090672522297
Validation loss: 2.5675314725638807

Epoch: 5| Step: 10
Training loss: 0.4579507592948486
Validation loss: 2.545969492012567

Epoch: 5| Step: 11
Training loss: 1.2011107886683803
Validation loss: 2.4762069214230666

Epoch: 125| Step: 0
Training loss: 0.8949009160651696
Validation loss: 2.477345977464611

Epoch: 5| Step: 1
Training loss: 0.9920058797577452
Validation loss: 2.6369079145227947

Epoch: 5| Step: 2
Training loss: 0.8353386989242574
Validation loss: 2.5833961968823074

Epoch: 5| Step: 3
Training loss: 0.8382849132390253
Validation loss: 2.5930867898387198

Epoch: 5| Step: 4
Training loss: 1.3166525409439724
Validation loss: 2.544714975131824

Epoch: 5| Step: 5
Training loss: 0.6092765435129331
Validation loss: 2.5856209298983104

Epoch: 5| Step: 6
Training loss: 0.6169967356553738
Validation loss: 2.5814704728510045

Epoch: 5| Step: 7
Training loss: 0.6619818910732277
Validation loss: 2.5140162392377303

Epoch: 5| Step: 8
Training loss: 0.960859000868662
Validation loss: 2.6793395392044754

Epoch: 5| Step: 9
Training loss: 0.6240779273848781
Validation loss: 2.574820417790027

Epoch: 5| Step: 10
Training loss: 0.7023480679354894
Validation loss: 2.4876056774094297

Epoch: 5| Step: 11
Training loss: 0.5249234359406877
Validation loss: 2.5787960489266273

Epoch: 126| Step: 0
Training loss: 0.7005701697654001
Validation loss: 2.595300437015776

Epoch: 5| Step: 1
Training loss: 0.8492114308032177
Validation loss: 2.596495883075005

Epoch: 5| Step: 2
Training loss: 0.8531277471365383
Validation loss: 2.477352467608504

Epoch: 5| Step: 3
Training loss: 0.6773247704052261
Validation loss: 2.4994985117199775

Epoch: 5| Step: 4
Training loss: 0.7422524674741718
Validation loss: 2.5076534898205445

Epoch: 5| Step: 5
Training loss: 0.5155415322919622
Validation loss: 2.5203663174014665

Epoch: 5| Step: 6
Training loss: 0.7139872020862065
Validation loss: 2.422475668549098

Epoch: 5| Step: 7
Training loss: 0.5410157076288153
Validation loss: 2.469504454371921

Epoch: 5| Step: 8
Training loss: 0.6242613480681868
Validation loss: 2.527060265342756

Epoch: 5| Step: 9
Training loss: 1.288131979118738
Validation loss: 2.4916279243298085

Epoch: 5| Step: 10
Training loss: 0.8536382451785954
Validation loss: 2.5398432739157237

Epoch: 5| Step: 11
Training loss: 0.718405972950941
Validation loss: 2.5146846158779983

Epoch: 127| Step: 0
Training loss: 0.6096821524396782
Validation loss: 2.5700910872893714

Epoch: 5| Step: 1
Training loss: 0.7462415698548133
Validation loss: 2.5665266762575865

Epoch: 5| Step: 2
Training loss: 0.8175653506765074
Validation loss: 2.6450344716946397

Epoch: 5| Step: 3
Training loss: 0.8107709092447304
Validation loss: 2.4978858034858935

Epoch: 5| Step: 4
Training loss: 1.5320227094117502
Validation loss: 2.626570511835403

Epoch: 5| Step: 5
Training loss: 0.720936104351887
Validation loss: 2.554348887207477

Epoch: 5| Step: 6
Training loss: 0.668341928384772
Validation loss: 2.48847436479907

Epoch: 5| Step: 7
Training loss: 0.727076891858734
Validation loss: 2.549345175963076

Epoch: 5| Step: 8
Training loss: 0.9402441552813995
Validation loss: 2.6325096914626807

Epoch: 5| Step: 9
Training loss: 0.8357416797056035
Validation loss: 2.682609871936623

Epoch: 5| Step: 10
Training loss: 0.6896338941779462
Validation loss: 2.6169177775154746

Epoch: 5| Step: 11
Training loss: 0.7118231737597804
Validation loss: 2.5375163530345826

Epoch: 128| Step: 0
Training loss: 0.708150494109002
Validation loss: 2.5190441715488765

Epoch: 5| Step: 1
Training loss: 0.5991581763097925
Validation loss: 2.556887704806334

Epoch: 5| Step: 2
Training loss: 0.8290125211568476
Validation loss: 2.5632012074646364

Epoch: 5| Step: 3
Training loss: 0.5889469934034565
Validation loss: 2.5768755592082204

Epoch: 5| Step: 4
Training loss: 0.6740288476939627
Validation loss: 2.6030849053759075

Epoch: 5| Step: 5
Training loss: 0.7896188719576427
Validation loss: 2.6103591738065552

Epoch: 5| Step: 6
Training loss: 0.5747738963780683
Validation loss: 2.5835815407866605

Epoch: 5| Step: 7
Training loss: 1.1252168870184187
Validation loss: 2.611942303677266

Epoch: 5| Step: 8
Training loss: 1.2280597659735868
Validation loss: 2.591907593720175

Epoch: 5| Step: 9
Training loss: 0.8270313310650156
Validation loss: 2.626953730057241

Epoch: 5| Step: 10
Training loss: 0.7305726982042583
Validation loss: 2.5588269717086622

Epoch: 5| Step: 11
Training loss: 0.9822536802312735
Validation loss: 2.575879226655433

Epoch: 129| Step: 0
Training loss: 0.7731730461764696
Validation loss: 2.598814004064334

Epoch: 5| Step: 1
Training loss: 1.0391857676419047
Validation loss: 2.567917197568526

Epoch: 5| Step: 2
Training loss: 1.024457117854145
Validation loss: 2.58759019943253

Epoch: 5| Step: 3
Training loss: 1.3534571427210458
Validation loss: 2.58437759817501

Epoch: 5| Step: 4
Training loss: 0.6741759798312779
Validation loss: 2.556251855739178

Epoch: 5| Step: 5
Training loss: 0.8313900980091093
Validation loss: 2.5370978124373167

Epoch: 5| Step: 6
Training loss: 0.6179964582594828
Validation loss: 2.6565694429882507

Epoch: 5| Step: 7
Training loss: 0.9478792385774722
Validation loss: 2.603094751366228

Epoch: 5| Step: 8
Training loss: 0.8322276568634995
Validation loss: 2.573860849788167

Epoch: 5| Step: 9
Training loss: 0.7963070434905526
Validation loss: 2.5304658699549236

Epoch: 5| Step: 10
Training loss: 0.8323388404192961
Validation loss: 2.4914382158973822

Epoch: 5| Step: 11
Training loss: 0.7812099446518751
Validation loss: 2.5806410986497585

Epoch: 130| Step: 0
Training loss: 0.9537278129526754
Validation loss: 2.558517423855086

Epoch: 5| Step: 1
Training loss: 0.8872159664562788
Validation loss: 2.580261358723185

Epoch: 5| Step: 2
Training loss: 1.302320102781316
Validation loss: 2.5847484394155726

Epoch: 5| Step: 3
Training loss: 0.9189828344097227
Validation loss: 2.5982651534646615

Epoch: 5| Step: 4
Training loss: 0.6169863022840262
Validation loss: 2.578621887720461

Epoch: 5| Step: 5
Training loss: 0.9848785626157817
Validation loss: 2.628577368136719

Epoch: 5| Step: 6
Training loss: 0.939666787196117
Validation loss: 2.637288319799813

Epoch: 5| Step: 7
Training loss: 0.9905607148500438
Validation loss: 2.610684330930979

Epoch: 5| Step: 8
Training loss: 0.8321859368178168
Validation loss: 2.582142610596396

Epoch: 5| Step: 9
Training loss: 0.3160838026479416
Validation loss: 2.5891156292630373

Epoch: 5| Step: 10
Training loss: 0.7250240815208108
Validation loss: 2.577200930129341

Epoch: 5| Step: 11
Training loss: 0.20488266485770754
Validation loss: 2.4444379999847667

Epoch: 131| Step: 0
Training loss: 0.9792365732331599
Validation loss: 2.561098890357008

Epoch: 5| Step: 1
Training loss: 0.8432081389951859
Validation loss: 2.495748906997604

Epoch: 5| Step: 2
Training loss: 0.9333115793712932
Validation loss: 2.505038310498489

Epoch: 5| Step: 3
Training loss: 0.7563783505185405
Validation loss: 2.5057138830392933

Epoch: 5| Step: 4
Training loss: 0.8720488508259894
Validation loss: 2.5550487313472563

Epoch: 5| Step: 5
Training loss: 1.0602644795528908
Validation loss: 2.5634457812202047

Epoch: 5| Step: 6
Training loss: 0.7201389492586266
Validation loss: 2.532218739882083

Epoch: 5| Step: 7
Training loss: 0.9527142687213017
Validation loss: 2.5107237376115457

Epoch: 5| Step: 8
Training loss: 0.6047999472143766
Validation loss: 2.5236219214729974

Epoch: 5| Step: 9
Training loss: 1.2620575630039663
Validation loss: 2.526246738302751

Epoch: 5| Step: 10
Training loss: 0.5106939289349893
Validation loss: 2.5313766471356742

Epoch: 5| Step: 11
Training loss: 0.3186957098035632
Validation loss: 2.5447285369639747

Epoch: 132| Step: 0
Training loss: 0.40016255279546387
Validation loss: 2.4899288334117444

Epoch: 5| Step: 1
Training loss: 0.5762670406047897
Validation loss: 2.497472450955935

Epoch: 5| Step: 2
Training loss: 0.42564514154511146
Validation loss: 2.4872281227863597

Epoch: 5| Step: 3
Training loss: 0.8576471124135526
Validation loss: 2.5046322881332985

Epoch: 5| Step: 4
Training loss: 0.6515270077120234
Validation loss: 2.4895148859763343

Epoch: 5| Step: 5
Training loss: 0.6022612241820988
Validation loss: 2.494117826329213

Epoch: 5| Step: 6
Training loss: 0.755046318477595
Validation loss: 2.478866824816294

Epoch: 5| Step: 7
Training loss: 0.6855469836808251
Validation loss: 2.4790569102143607

Epoch: 5| Step: 8
Training loss: 1.414608423219334
Validation loss: 2.5236489233963075

Epoch: 5| Step: 9
Training loss: 0.8919425053435003
Validation loss: 2.5457868260153753

Epoch: 5| Step: 10
Training loss: 0.5042613353069849
Validation loss: 2.5470662308496346

Epoch: 5| Step: 11
Training loss: 0.6274888551337849
Validation loss: 2.4703294212570874

Epoch: 133| Step: 0
Training loss: 0.4635135306345259
Validation loss: 2.517532723083771

Epoch: 5| Step: 1
Training loss: 0.6493242244677201
Validation loss: 2.5649027840556635

Epoch: 5| Step: 2
Training loss: 0.6950630426287259
Validation loss: 2.518358392302551

Epoch: 5| Step: 3
Training loss: 0.6468209949008923
Validation loss: 2.4744881025915895

Epoch: 5| Step: 4
Training loss: 0.546255387382216
Validation loss: 2.5009763837558814

Epoch: 5| Step: 5
Training loss: 0.8159810834543273
Validation loss: 2.5296077817027482

Epoch: 5| Step: 6
Training loss: 0.8064933069664442
Validation loss: 2.5413519998055345

Epoch: 5| Step: 7
Training loss: 1.2196775965639184
Validation loss: 2.5116305990852674

Epoch: 5| Step: 8
Training loss: 0.5854849530052995
Validation loss: 2.5154480644854296

Epoch: 5| Step: 9
Training loss: 0.6401937708102047
Validation loss: 2.598737926476515

Epoch: 5| Step: 10
Training loss: 0.843119951180738
Validation loss: 2.557689543860093

Epoch: 5| Step: 11
Training loss: 1.2773128120805375
Validation loss: 2.5204071296763293

Epoch: 134| Step: 0
Training loss: 1.2431405687771693
Validation loss: 2.584136823836346

Epoch: 5| Step: 1
Training loss: 0.5995031505021517
Validation loss: 2.6324455239412554

Epoch: 5| Step: 2
Training loss: 0.8431161689719983
Validation loss: 2.5342567917223913

Epoch: 5| Step: 3
Training loss: 0.6912096034864674
Validation loss: 2.5587853357545955

Epoch: 5| Step: 4
Training loss: 0.7354493095206424
Validation loss: 2.5352531575243873

Epoch: 5| Step: 5
Training loss: 0.9493830974200888
Validation loss: 2.534656688998472

Epoch: 5| Step: 6
Training loss: 0.8249107095775805
Validation loss: 2.553901121644521

Epoch: 5| Step: 7
Training loss: 0.7597078826065524
Validation loss: 2.600346919903442

Epoch: 5| Step: 8
Training loss: 0.6767967840426041
Validation loss: 2.5578708743776875

Epoch: 5| Step: 9
Training loss: 0.7223446560869882
Validation loss: 2.5528081928487216

Epoch: 5| Step: 10
Training loss: 1.193335000646126
Validation loss: 2.516772729068169

Epoch: 5| Step: 11
Training loss: 0.5581353447394359
Validation loss: 2.4547391347393765

Epoch: 135| Step: 0
Training loss: 0.4807180052756888
Validation loss: 2.4615838145718727

Epoch: 5| Step: 1
Training loss: 0.6561964785231114
Validation loss: 2.576058245223878

Epoch: 5| Step: 2
Training loss: 0.5298196104597883
Validation loss: 2.564306661234646

Epoch: 5| Step: 3
Training loss: 0.7589556929606701
Validation loss: 2.494693878954448

Epoch: 5| Step: 4
Training loss: 1.3015162593692038
Validation loss: 2.492734197367355

Epoch: 5| Step: 5
Training loss: 0.5912641387281243
Validation loss: 2.551070324970571

Epoch: 5| Step: 6
Training loss: 0.6359644675570582
Validation loss: 2.466205243070121

Epoch: 5| Step: 7
Training loss: 0.658100901286562
Validation loss: 2.463540943513943

Epoch: 5| Step: 8
Training loss: 0.6087899211428341
Validation loss: 2.5219335926596615

Epoch: 5| Step: 9
Training loss: 0.7634904260516008
Validation loss: 2.486439764568499

Epoch: 5| Step: 10
Training loss: 0.8904295924463408
Validation loss: 2.476225423888289

Epoch: 5| Step: 11
Training loss: 1.0036752635452912
Validation loss: 2.515147469888305

Epoch: 136| Step: 0
Training loss: 0.6525368090730251
Validation loss: 2.5630741212810793

Epoch: 5| Step: 1
Training loss: 0.9084590428241736
Validation loss: 2.529590808574816

Epoch: 5| Step: 2
Training loss: 0.6857775873245884
Validation loss: 2.5896365493734392

Epoch: 5| Step: 3
Training loss: 0.7364196720433923
Validation loss: 2.583844035694633

Epoch: 5| Step: 4
Training loss: 0.7727574142401499
Validation loss: 2.545068181853944

Epoch: 5| Step: 5
Training loss: 0.49374646837444236
Validation loss: 2.6003731499565585

Epoch: 5| Step: 6
Training loss: 0.6850181127158347
Validation loss: 2.5299474441650913

Epoch: 5| Step: 7
Training loss: 1.2300996257008923
Validation loss: 2.6061216143600845

Epoch: 5| Step: 8
Training loss: 0.7173719463984654
Validation loss: 2.574554135939574

Epoch: 5| Step: 9
Training loss: 0.8283352135215416
Validation loss: 2.5983324514056805

Epoch: 5| Step: 10
Training loss: 0.7044302798684599
Validation loss: 2.717719785393979

Epoch: 5| Step: 11
Training loss: 0.7929424413065678
Validation loss: 2.5872475090091043

Epoch: 137| Step: 0
Training loss: 0.6696489851534968
Validation loss: 2.567494317060531

Epoch: 5| Step: 1
Training loss: 1.2840479562009561
Validation loss: 2.5835297853364656

Epoch: 5| Step: 2
Training loss: 0.559616379897049
Validation loss: 2.605058953325307

Epoch: 5| Step: 3
Training loss: 0.8189601468344592
Validation loss: 2.5531551575640257

Epoch: 5| Step: 4
Training loss: 0.4919069944055827
Validation loss: 2.5388434330263077

Epoch: 5| Step: 5
Training loss: 0.7560269271101963
Validation loss: 2.494808052954221

Epoch: 5| Step: 6
Training loss: 0.4837956809621843
Validation loss: 2.552537618155011

Epoch: 5| Step: 7
Training loss: 0.7859556389416166
Validation loss: 2.494840358001473

Epoch: 5| Step: 8
Training loss: 0.8476695398088736
Validation loss: 2.4904352962245353

Epoch: 5| Step: 9
Training loss: 0.5637018820956733
Validation loss: 2.505061303236961

Epoch: 5| Step: 10
Training loss: 0.8381114748689137
Validation loss: 2.4679283070347444

Epoch: 5| Step: 11
Training loss: 0.4520449921687858
Validation loss: 2.4870697377807316

Epoch: 138| Step: 0
Training loss: 0.5594807498217949
Validation loss: 2.503532193274355

Epoch: 5| Step: 1
Training loss: 0.8413698746407932
Validation loss: 2.519313883707702

Epoch: 5| Step: 2
Training loss: 0.47034302862703975
Validation loss: 2.495719133342551

Epoch: 5| Step: 3
Training loss: 0.7733102558929382
Validation loss: 2.4754836041870583

Epoch: 5| Step: 4
Training loss: 0.6626737096960377
Validation loss: 2.501740414076514

Epoch: 5| Step: 5
Training loss: 0.4732005555610749
Validation loss: 2.4629579777373016

Epoch: 5| Step: 6
Training loss: 1.198591534241165
Validation loss: 2.535058449228728

Epoch: 5| Step: 7
Training loss: 0.5959288622785751
Validation loss: 2.4790191539721005

Epoch: 5| Step: 8
Training loss: 0.8211574743861091
Validation loss: 2.4782923604630662

Epoch: 5| Step: 9
Training loss: 0.7599277274376145
Validation loss: 2.4934831119516456

Epoch: 5| Step: 10
Training loss: 0.5909905306675519
Validation loss: 2.49518601334436

Epoch: 5| Step: 11
Training loss: 0.6290517603132255
Validation loss: 2.5173188898046317

Epoch: 139| Step: 0
Training loss: 0.5798844293434984
Validation loss: 2.526428390998243

Epoch: 5| Step: 1
Training loss: 0.46664826968522244
Validation loss: 2.556360150197016

Epoch: 5| Step: 2
Training loss: 0.4592335937478818
Validation loss: 2.483474220262654

Epoch: 5| Step: 3
Training loss: 0.3817879141733089
Validation loss: 2.5647907175295708

Epoch: 5| Step: 4
Training loss: 1.222411841195734
Validation loss: 2.504386986631683

Epoch: 5| Step: 5
Training loss: 0.909531210889686
Validation loss: 2.5284462380854467

Epoch: 5| Step: 6
Training loss: 0.8624381526942063
Validation loss: 2.548517048878829

Epoch: 5| Step: 7
Training loss: 0.5447632753646205
Validation loss: 2.5613612498009455

Epoch: 5| Step: 8
Training loss: 0.5735224959659898
Validation loss: 2.562953017284055

Epoch: 5| Step: 9
Training loss: 0.6064357296098998
Validation loss: 2.5080542086444617

Epoch: 5| Step: 10
Training loss: 0.6828182726513461
Validation loss: 2.5070832480600234

Epoch: 5| Step: 11
Training loss: 1.1029560121772644
Validation loss: 2.5174131613133293

Epoch: 140| Step: 0
Training loss: 0.8324636490935957
Validation loss: 2.5283261983347907

Epoch: 5| Step: 1
Training loss: 0.6892979044616337
Validation loss: 2.5178620301917123

Epoch: 5| Step: 2
Training loss: 0.5794674005661916
Validation loss: 2.6051936426146356

Epoch: 5| Step: 3
Training loss: 0.5570799582908649
Validation loss: 2.5522757334423702

Epoch: 5| Step: 4
Training loss: 0.5208253446602101
Validation loss: 2.6213158457957912

Epoch: 5| Step: 5
Training loss: 1.0880856570296713
Validation loss: 2.511028849616166

Epoch: 5| Step: 6
Training loss: 0.6475828122238454
Validation loss: 2.5947009032577606

Epoch: 5| Step: 7
Training loss: 0.8199608185176374
Validation loss: 2.6396197600788

Epoch: 5| Step: 8
Training loss: 0.9210822365957698
Validation loss: 2.6059479451499103

Epoch: 5| Step: 9
Training loss: 0.5587135666611542
Validation loss: 2.5888535959564987

Epoch: 5| Step: 10
Training loss: 0.7135076491514608
Validation loss: 2.557739783115418

Epoch: 5| Step: 11
Training loss: 0.339783707061026
Validation loss: 2.568088365381552

Epoch: 141| Step: 0
Training loss: 0.8270304301820169
Validation loss: 2.5372162116826655

Epoch: 5| Step: 1
Training loss: 0.7203009498977594
Validation loss: 2.594575650965602

Epoch: 5| Step: 2
Training loss: 0.7413844532470852
Validation loss: 2.564921731157485

Epoch: 5| Step: 3
Training loss: 0.6011731758128389
Validation loss: 2.4973741768437314

Epoch: 5| Step: 4
Training loss: 0.7430804452461034
Validation loss: 2.4893385069797516

Epoch: 5| Step: 5
Training loss: 1.1910605507519574
Validation loss: 2.54605700612757

Epoch: 5| Step: 6
Training loss: 0.6651459998644172
Validation loss: 2.500037944028914

Epoch: 5| Step: 7
Training loss: 0.5793195960540064
Validation loss: 2.5279402503057917

Epoch: 5| Step: 8
Training loss: 0.6205363861699794
Validation loss: 2.494498481857838

Epoch: 5| Step: 9
Training loss: 0.6187240932320004
Validation loss: 2.532812283967166

Epoch: 5| Step: 10
Training loss: 0.4732724736213204
Validation loss: 2.6028385927557505

Epoch: 5| Step: 11
Training loss: 0.7137978411806722
Validation loss: 2.4774959982985005

Epoch: 142| Step: 0
Training loss: 0.6517790903213948
Validation loss: 2.5345660102006002

Epoch: 5| Step: 1
Training loss: 0.7475982595692884
Validation loss: 2.581717571647757

Epoch: 5| Step: 2
Training loss: 1.0322887506581735
Validation loss: 2.5724637769392302

Epoch: 5| Step: 3
Training loss: 0.6549524467620006
Validation loss: 2.556814682730133

Epoch: 5| Step: 4
Training loss: 0.6163755218234432
Validation loss: 2.5452603212444616

Epoch: 5| Step: 5
Training loss: 0.6185360191715257
Validation loss: 2.5876758644674025

Epoch: 5| Step: 6
Training loss: 0.6536669759383273
Validation loss: 2.5862183663234464

Epoch: 5| Step: 7
Training loss: 0.5644662188954889
Validation loss: 2.6278083137221495

Epoch: 5| Step: 8
Training loss: 0.6748393777192049
Validation loss: 2.511414540617191

Epoch: 5| Step: 9
Training loss: 0.6125971386233964
Validation loss: 2.5072571405924076

Epoch: 5| Step: 10
Training loss: 0.6248860732194562
Validation loss: 2.584937394931693

Epoch: 5| Step: 11
Training loss: 0.8112497614197461
Validation loss: 2.5440077448802993

Epoch: 143| Step: 0
Training loss: 0.5619024705801637
Validation loss: 2.6038627078366985

Epoch: 5| Step: 1
Training loss: 0.5261458177351913
Validation loss: 2.5040070428661623

Epoch: 5| Step: 2
Training loss: 0.7217528599047182
Validation loss: 2.510451254599798

Epoch: 5| Step: 3
Training loss: 0.6534271152935416
Validation loss: 2.5772789578418305

Epoch: 5| Step: 4
Training loss: 0.4521630698816872
Validation loss: 2.5096212224323726

Epoch: 5| Step: 5
Training loss: 1.2042049663661136
Validation loss: 2.454514545261846

Epoch: 5| Step: 6
Training loss: 0.5878822097936439
Validation loss: 2.559821838261531

Epoch: 5| Step: 7
Training loss: 0.7973972927672329
Validation loss: 2.536591686265563

Epoch: 5| Step: 8
Training loss: 0.4327649624054329
Validation loss: 2.5867121286325707

Epoch: 5| Step: 9
Training loss: 0.45273273852812046
Validation loss: 2.496942545964269

Epoch: 5| Step: 10
Training loss: 0.7604215874360307
Validation loss: 2.528985003043654

Epoch: 5| Step: 11
Training loss: 0.6992584728700062
Validation loss: 2.523150149145963

Epoch: 144| Step: 0
Training loss: 0.8387537070134161
Validation loss: 2.5740274060093764

Epoch: 5| Step: 1
Training loss: 0.5175273942377046
Validation loss: 2.541307929523796

Epoch: 5| Step: 2
Training loss: 0.6012045303012237
Validation loss: 2.636912177255462

Epoch: 5| Step: 3
Training loss: 0.6120122427152147
Validation loss: 2.536261887093994

Epoch: 5| Step: 4
Training loss: 0.37472146339251694
Validation loss: 2.4948021019788373

Epoch: 5| Step: 5
Training loss: 0.6197160519761484
Validation loss: 2.521399833666465

Epoch: 5| Step: 6
Training loss: 0.5829070497782497
Validation loss: 2.517999278913288

Epoch: 5| Step: 7
Training loss: 0.4507815832074023
Validation loss: 2.584767317909477

Epoch: 5| Step: 8
Training loss: 1.166667813345936
Validation loss: 2.5516475785557025

Epoch: 5| Step: 9
Training loss: 0.7277984771098289
Validation loss: 2.5691570653240032

Epoch: 5| Step: 10
Training loss: 0.6149008679548693
Validation loss: 2.5406901771533996

Epoch: 5| Step: 11
Training loss: 0.7531994288219002
Validation loss: 2.559870762797647

Epoch: 145| Step: 0
Training loss: 1.0127997790523187
Validation loss: 2.5551735885088767

Epoch: 5| Step: 1
Training loss: 0.6111996549222132
Validation loss: 2.5522067656478247

Epoch: 5| Step: 2
Training loss: 0.8792698425991184
Validation loss: 2.5194940648057904

Epoch: 5| Step: 3
Training loss: 0.4819843300314111
Validation loss: 2.5059979569689883

Epoch: 5| Step: 4
Training loss: 0.5713136586168236
Validation loss: 2.5155769485717965

Epoch: 5| Step: 5
Training loss: 0.48252592624919105
Validation loss: 2.5161184138990844

Epoch: 5| Step: 6
Training loss: 0.6613370278531495
Validation loss: 2.5043218092271378

Epoch: 5| Step: 7
Training loss: 0.8213707047569164
Validation loss: 2.47618416625025

Epoch: 5| Step: 8
Training loss: 0.5807275700796672
Validation loss: 2.5682460552014343

Epoch: 5| Step: 9
Training loss: 0.7037932928737026
Validation loss: 2.5172510992690498

Epoch: 5| Step: 10
Training loss: 0.43137356535861743
Validation loss: 2.4969072404291035

Epoch: 5| Step: 11
Training loss: 1.0518506362459783
Validation loss: 2.5387886212652946

Epoch: 146| Step: 0
Training loss: 0.5613195165134665
Validation loss: 2.4748605401471697

Epoch: 5| Step: 1
Training loss: 0.7019115149085389
Validation loss: 2.525163798165439

Epoch: 5| Step: 2
Training loss: 0.41185532101751393
Validation loss: 2.5220788855150817

Epoch: 5| Step: 3
Training loss: 0.7094109042992015
Validation loss: 2.5843048781169142

Epoch: 5| Step: 4
Training loss: 0.5251488678903371
Validation loss: 2.520638838008873

Epoch: 5| Step: 5
Training loss: 0.7615516674975977
Validation loss: 2.490149075910941

Epoch: 5| Step: 6
Training loss: 1.1077020953303314
Validation loss: 2.4810647363626135

Epoch: 5| Step: 7
Training loss: 0.5665042397810952
Validation loss: 2.5003299237148657

Epoch: 5| Step: 8
Training loss: 0.5864560185370377
Validation loss: 2.480703796303974

Epoch: 5| Step: 9
Training loss: 0.43532969101961344
Validation loss: 2.555271241421509

Epoch: 5| Step: 10
Training loss: 0.5494961457243156
Validation loss: 2.551572239879201

Epoch: 5| Step: 11
Training loss: 0.7689747613602209
Validation loss: 2.568912236766832

Epoch: 147| Step: 0
Training loss: 0.4799319579406428
Validation loss: 2.618955662070815

Epoch: 5| Step: 1
Training loss: 0.5618517637274858
Validation loss: 2.5759019997127464

Epoch: 5| Step: 2
Training loss: 0.6128088474116196
Validation loss: 2.521850447080226

Epoch: 5| Step: 3
Training loss: 0.6087365841023649
Validation loss: 2.590787589964956

Epoch: 5| Step: 4
Training loss: 0.7976862947520191
Validation loss: 2.5936715906999583

Epoch: 5| Step: 5
Training loss: 0.5831976857733369
Validation loss: 2.5975029118533515

Epoch: 5| Step: 6
Training loss: 0.5917580720877124
Validation loss: 2.58369180412312

Epoch: 5| Step: 7
Training loss: 1.1348501886318816
Validation loss: 2.5366665671772965

Epoch: 5| Step: 8
Training loss: 0.6753938700221283
Validation loss: 2.543545955812963

Epoch: 5| Step: 9
Training loss: 0.6327199986043678
Validation loss: 2.499769057097357

Epoch: 5| Step: 10
Training loss: 0.45585946718033593
Validation loss: 2.490553656162112

Epoch: 5| Step: 11
Training loss: 0.7439193997485858
Validation loss: 2.5638494543707666

Epoch: 148| Step: 0
Training loss: 0.8258594977516153
Validation loss: 2.5273427358917138

Epoch: 5| Step: 1
Training loss: 0.49864570669737446
Validation loss: 2.5686979005454025

Epoch: 5| Step: 2
Training loss: 0.5505892100918588
Validation loss: 2.460896426064979

Epoch: 5| Step: 3
Training loss: 0.5101106725548825
Validation loss: 2.5901694191320623

Epoch: 5| Step: 4
Training loss: 1.185666576293979
Validation loss: 2.4896715512999203

Epoch: 5| Step: 5
Training loss: 0.6147576074226475
Validation loss: 2.5506838185511707

Epoch: 5| Step: 6
Training loss: 0.6369688794814758
Validation loss: 2.58420689615376

Epoch: 5| Step: 7
Training loss: 0.7012180748810505
Validation loss: 2.500210735260662

Epoch: 5| Step: 8
Training loss: 0.5476122110593631
Validation loss: 2.579571505025336

Epoch: 5| Step: 9
Training loss: 0.5455592266783864
Validation loss: 2.5526308575251595

Epoch: 5| Step: 10
Training loss: 0.5345349011244935
Validation loss: 2.4884815784181535

Epoch: 5| Step: 11
Training loss: 0.3184105767575612
Validation loss: 2.4723279352362764

Epoch: 149| Step: 0
Training loss: 0.5292705796808052
Validation loss: 2.561261556222915

Epoch: 5| Step: 1
Training loss: 0.6461678043901872
Validation loss: 2.615396306117318

Epoch: 5| Step: 2
Training loss: 0.6708065008835101
Validation loss: 2.4971582951447293

Epoch: 5| Step: 3
Training loss: 0.5183613159787276
Validation loss: 2.5459154462813176

Epoch: 5| Step: 4
Training loss: 0.7826724644811212
Validation loss: 2.574553732718567

Epoch: 5| Step: 5
Training loss: 0.6464818625963147
Validation loss: 2.581657309489555

Epoch: 5| Step: 6
Training loss: 0.5066421226414624
Validation loss: 2.6362655099394736

Epoch: 5| Step: 7
Training loss: 1.0628685031707115
Validation loss: 2.5428116335286624

Epoch: 5| Step: 8
Training loss: 0.5590346137182368
Validation loss: 2.5601310246807722

Epoch: 5| Step: 9
Training loss: 0.5264666857834909
Validation loss: 2.499491852536486

Epoch: 5| Step: 10
Training loss: 0.6373944120292031
Validation loss: 2.521661399105476

Epoch: 5| Step: 11
Training loss: 0.23933412541543522
Validation loss: 2.543414063730613

Epoch: 150| Step: 0
Training loss: 0.6300140244194526
Validation loss: 2.574849218904444

Epoch: 5| Step: 1
Training loss: 0.6793624275960327
Validation loss: 2.5133173133540225

Epoch: 5| Step: 2
Training loss: 0.4432104591638301
Validation loss: 2.5353569535177374

Epoch: 5| Step: 3
Training loss: 1.1680272830853213
Validation loss: 2.623519862390912

Epoch: 5| Step: 4
Training loss: 0.7152573269839105
Validation loss: 2.5466715764598384

Epoch: 5| Step: 5
Training loss: 0.5548251612521614
Validation loss: 2.6012366532791895

Epoch: 5| Step: 6
Training loss: 0.6214438837025256
Validation loss: 2.565540808420333

Epoch: 5| Step: 7
Training loss: 0.43952105526944824
Validation loss: 2.5154141639830563

Epoch: 5| Step: 8
Training loss: 0.7095455334403254
Validation loss: 2.5806636410634445

Epoch: 5| Step: 9
Training loss: 0.6788054256395463
Validation loss: 2.5690310452086265

Epoch: 5| Step: 10
Training loss: 0.5040539074216831
Validation loss: 2.5892284653979196

Epoch: 5| Step: 11
Training loss: 0.41630150370384683
Validation loss: 2.5519388209837945

Epoch: 151| Step: 0
Training loss: 0.42161960288584843
Validation loss: 2.633897974546244

Epoch: 5| Step: 1
Training loss: 0.682798435232183
Validation loss: 2.6021092998185353

Epoch: 5| Step: 2
Training loss: 1.1036153292554662
Validation loss: 2.618090072548205

Epoch: 5| Step: 3
Training loss: 0.5784761290426573
Validation loss: 2.5753086273950543

Epoch: 5| Step: 4
Training loss: 0.4824614566518816
Validation loss: 2.5009028632305164

Epoch: 5| Step: 5
Training loss: 0.4595142147067602
Validation loss: 2.5312006498164905

Epoch: 5| Step: 6
Training loss: 0.48469586665829123
Validation loss: 2.5706335792858983

Epoch: 5| Step: 7
Training loss: 0.5505466637977053
Validation loss: 2.6221798135730183

Epoch: 5| Step: 8
Training loss: 0.5127869732981557
Validation loss: 2.5564925401278984

Epoch: 5| Step: 9
Training loss: 0.731980213515405
Validation loss: 2.556432717002507

Epoch: 5| Step: 10
Training loss: 0.6632794868796271
Validation loss: 2.55712849833886

Epoch: 5| Step: 11
Training loss: 0.49320204182540167
Validation loss: 2.58542807825251

Epoch: 152| Step: 0
Training loss: 0.5405572264422139
Validation loss: 2.546456405939359

Epoch: 5| Step: 1
Training loss: 0.5960883474042653
Validation loss: 2.5557906620288984

Epoch: 5| Step: 2
Training loss: 1.0406845167398033
Validation loss: 2.573942834387296

Epoch: 5| Step: 3
Training loss: 0.5997336939065507
Validation loss: 2.5239439457068578

Epoch: 5| Step: 4
Training loss: 0.5774092496436966
Validation loss: 2.54301397710175

Epoch: 5| Step: 5
Training loss: 0.3253690810931023
Validation loss: 2.558262045909811

Epoch: 5| Step: 6
Training loss: 0.5452251615783013
Validation loss: 2.5216008658552913

Epoch: 5| Step: 7
Training loss: 0.3997209484548968
Validation loss: 2.543397678779522

Epoch: 5| Step: 8
Training loss: 0.8478862257108457
Validation loss: 2.609332177577919

Epoch: 5| Step: 9
Training loss: 0.833680501783663
Validation loss: 2.583990041775111

Epoch: 5| Step: 10
Training loss: 0.5129241142176427
Validation loss: 2.570986637112528

Epoch: 5| Step: 11
Training loss: 0.2675213440285492
Validation loss: 2.5508215425433387

Epoch: 153| Step: 0
Training loss: 0.6172191273758274
Validation loss: 2.5727180347655625

Epoch: 5| Step: 1
Training loss: 0.6442275979273859
Validation loss: 2.5741142942531097

Epoch: 5| Step: 2
Training loss: 0.6265996964750702
Validation loss: 2.5778901272530765

Epoch: 5| Step: 3
Training loss: 0.544502808144144
Validation loss: 2.5259462214000825

Epoch: 5| Step: 4
Training loss: 0.726837188314519
Validation loss: 2.5016805881042576

Epoch: 5| Step: 5
Training loss: 0.5479786499364817
Validation loss: 2.649255223099562

Epoch: 5| Step: 6
Training loss: 0.9651295474167257
Validation loss: 2.524854527900223

Epoch: 5| Step: 7
Training loss: 0.5486594378704729
Validation loss: 2.4920964000159285

Epoch: 5| Step: 8
Training loss: 0.51636475181337
Validation loss: 2.602867387264714

Epoch: 5| Step: 9
Training loss: 0.49660707183688846
Validation loss: 2.5624678927635345

Epoch: 5| Step: 10
Training loss: 0.3299835114622429
Validation loss: 2.5492096168447205

Epoch: 5| Step: 11
Training loss: 0.6458414805318844
Validation loss: 2.5151638828618434

Epoch: 154| Step: 0
Training loss: 0.4303643531003106
Validation loss: 2.456641655030724

Epoch: 5| Step: 1
Training loss: 0.4864613607123177
Validation loss: 2.542530664698533

Epoch: 5| Step: 2
Training loss: 0.5119709238014252
Validation loss: 2.5103300694346613

Epoch: 5| Step: 3
Training loss: 0.5544279323969752
Validation loss: 2.560800655697317

Epoch: 5| Step: 4
Training loss: 0.9689224458844015
Validation loss: 2.5471253223308223

Epoch: 5| Step: 5
Training loss: 0.39373517689732423
Validation loss: 2.5076356451117503

Epoch: 5| Step: 6
Training loss: 0.7020663875342136
Validation loss: 2.606008606228142

Epoch: 5| Step: 7
Training loss: 0.6052206700217196
Validation loss: 2.5010429074624474

Epoch: 5| Step: 8
Training loss: 0.6188923912740637
Validation loss: 2.5346269255771263

Epoch: 5| Step: 9
Training loss: 0.5936222189884104
Validation loss: 2.493500239230794

Epoch: 5| Step: 10
Training loss: 0.4816366747766081
Validation loss: 2.492478081674729

Epoch: 5| Step: 11
Training loss: 0.7537571655869113
Validation loss: 2.508207957460099

Epoch: 155| Step: 0
Training loss: 0.5054570369159296
Validation loss: 2.4803257618138197

Epoch: 5| Step: 1
Training loss: 0.6898806491889383
Validation loss: 2.5476430210806114

Epoch: 5| Step: 2
Training loss: 0.8180566560132998
Validation loss: 2.544527071515155

Epoch: 5| Step: 3
Training loss: 0.8064563901052186
Validation loss: 2.574755437588712

Epoch: 5| Step: 4
Training loss: 1.046983570902702
Validation loss: 2.644329504735033

Epoch: 5| Step: 5
Training loss: 0.5756188017255679
Validation loss: 2.5687982413904766

Epoch: 5| Step: 6
Training loss: 0.6483321966130245
Validation loss: 2.6471272793838816

Epoch: 5| Step: 7
Training loss: 0.7096703943620821
Validation loss: 2.6492955628575072

Epoch: 5| Step: 8
Training loss: 0.7973611134337877
Validation loss: 2.617038642863293

Epoch: 5| Step: 9
Training loss: 0.5955310760688357
Validation loss: 2.6034868395683786

Epoch: 5| Step: 10
Training loss: 0.3180967429489001
Validation loss: 2.613146992776153

Epoch: 5| Step: 11
Training loss: 0.6455097746711029
Validation loss: 2.582305135739248

Epoch: 156| Step: 0
Training loss: 0.662149636273888
Validation loss: 2.5981262929040017

Epoch: 5| Step: 1
Training loss: 1.039745421887257
Validation loss: 2.638960654275601

Epoch: 5| Step: 2
Training loss: 0.560882042823818
Validation loss: 2.618067605749495

Epoch: 5| Step: 3
Training loss: 0.5863164566373359
Validation loss: 2.5233569649047927

Epoch: 5| Step: 4
Training loss: 0.6831863715340736
Validation loss: 2.522917123999792

Epoch: 5| Step: 5
Training loss: 0.7330217676742675
Validation loss: 2.557414148405542

Epoch: 5| Step: 6
Training loss: 0.5819685217318138
Validation loss: 2.6127263968839745

Epoch: 5| Step: 7
Training loss: 0.5539674786944587
Validation loss: 2.644335477974373

Epoch: 5| Step: 8
Training loss: 0.44551359621915293
Validation loss: 2.5707163063557283

Epoch: 5| Step: 9
Training loss: 0.5392160887916443
Validation loss: 2.493448171778024

Epoch: 5| Step: 10
Training loss: 0.4299492125681296
Validation loss: 2.5586710677949758

Epoch: 5| Step: 11
Training loss: 0.8460313191016325
Validation loss: 2.5210473637056383

Epoch: 157| Step: 0
Training loss: 0.4677659195393385
Validation loss: 2.575341315163618

Epoch: 5| Step: 1
Training loss: 0.35279896842814923
Validation loss: 2.5780967171398843

Epoch: 5| Step: 2
Training loss: 0.409945515582908
Validation loss: 2.6294588072278158

Epoch: 5| Step: 3
Training loss: 0.41009001424120256
Validation loss: 2.5107627263435233

Epoch: 5| Step: 4
Training loss: 0.5474037339220794
Validation loss: 2.4811355495561402

Epoch: 5| Step: 5
Training loss: 0.5863084254808952
Validation loss: 2.467225412822778

Epoch: 5| Step: 6
Training loss: 0.8267755850312981
Validation loss: 2.5532337392018225

Epoch: 5| Step: 7
Training loss: 0.44759549965330386
Validation loss: 2.5715873130929814

Epoch: 5| Step: 8
Training loss: 0.5569694752299184
Validation loss: 2.566628944338578

Epoch: 5| Step: 9
Training loss: 0.5266442640082921
Validation loss: 2.586876090934986

Epoch: 5| Step: 10
Training loss: 1.0657412513125057
Validation loss: 2.5258422707320163

Epoch: 5| Step: 11
Training loss: 0.3637976309144999
Validation loss: 2.494811813867777

Epoch: 158| Step: 0
Training loss: 0.4364946769780873
Validation loss: 2.511714233267813

Epoch: 5| Step: 1
Training loss: 0.643249346664933
Validation loss: 2.5656039620829016

Epoch: 5| Step: 2
Training loss: 0.5891840953443251
Validation loss: 2.5683146851184624

Epoch: 5| Step: 3
Training loss: 0.6423275815672901
Validation loss: 2.5545096768116093

Epoch: 5| Step: 4
Training loss: 0.4800229834726455
Validation loss: 2.513400770860713

Epoch: 5| Step: 5
Training loss: 0.4739003635069835
Validation loss: 2.564455331112372

Epoch: 5| Step: 6
Training loss: 0.31727597125593604
Validation loss: 2.551758680648841

Epoch: 5| Step: 7
Training loss: 0.4589115653218888
Validation loss: 2.562150946933818

Epoch: 5| Step: 8
Training loss: 0.924158500971262
Validation loss: 2.5749576397686154

Epoch: 5| Step: 9
Training loss: 0.6849637934590134
Validation loss: 2.5433642172177775

Epoch: 5| Step: 10
Training loss: 0.495473398735977
Validation loss: 2.5712179156489796

Epoch: 5| Step: 11
Training loss: 0.5167720347552439
Validation loss: 2.5712052701188277

Epoch: 159| Step: 0
Training loss: 0.6104603418689465
Validation loss: 2.562116272425548

Epoch: 5| Step: 1
Training loss: 0.5350933177170748
Validation loss: 2.527123006764513

Epoch: 5| Step: 2
Training loss: 0.41097711437439555
Validation loss: 2.5290363506531914

Epoch: 5| Step: 3
Training loss: 0.5352464029154739
Validation loss: 2.5279802467202184

Epoch: 5| Step: 4
Training loss: 0.7848873532011574
Validation loss: 2.6093722893554254

Epoch: 5| Step: 5
Training loss: 0.4550080961775181
Validation loss: 2.540805941899396

Epoch: 5| Step: 6
Training loss: 0.9524897350048512
Validation loss: 2.6235292833277777

Epoch: 5| Step: 7
Training loss: 0.5404801455793755
Validation loss: 2.52749421872095

Epoch: 5| Step: 8
Training loss: 0.36080884993937223
Validation loss: 2.549375987213659

Epoch: 5| Step: 9
Training loss: 0.4827430366495927
Validation loss: 2.534984318291579

Epoch: 5| Step: 10
Training loss: 0.4805698133416455
Validation loss: 2.5049974362010614

Epoch: 5| Step: 11
Training loss: 0.27802883746727713
Validation loss: 2.5875816227912765

Epoch: 160| Step: 0
Training loss: 0.5159579849104388
Validation loss: 2.581931925530602

Epoch: 5| Step: 1
Training loss: 0.7287971832024149
Validation loss: 2.5656174134960446

Epoch: 5| Step: 2
Training loss: 0.9642979240149075
Validation loss: 2.4907980805696606

Epoch: 5| Step: 3
Training loss: 0.6294659085045083
Validation loss: 2.588288977331557

Epoch: 5| Step: 4
Training loss: 0.4796319668462437
Validation loss: 2.5927958016350003

Epoch: 5| Step: 5
Training loss: 0.6990159662385159
Validation loss: 2.5385322486620296

Epoch: 5| Step: 6
Training loss: 0.5840589290732208
Validation loss: 2.672810113873757

Epoch: 5| Step: 7
Training loss: 0.6474996011504488
Validation loss: 2.5910887604886446

Epoch: 5| Step: 8
Training loss: 0.49899904075752055
Validation loss: 2.4856995184744997

Epoch: 5| Step: 9
Training loss: 0.47626648761714574
Validation loss: 2.612230288197746

Epoch: 5| Step: 10
Training loss: 0.6689242394462499
Validation loss: 2.5734877563893357

Epoch: 5| Step: 11
Training loss: 0.3350930134264353
Validation loss: 2.5731402440299425

Epoch: 161| Step: 0
Training loss: 0.45459839908076294
Validation loss: 2.564906738480745

Epoch: 5| Step: 1
Training loss: 0.5750738511135932
Validation loss: 2.527995116516821

Epoch: 5| Step: 2
Training loss: 0.7686421636605918
Validation loss: 2.6161809969151495

Epoch: 5| Step: 3
Training loss: 0.7362671277914961
Validation loss: 2.6288678382308133

Epoch: 5| Step: 4
Training loss: 0.40627915937972775
Validation loss: 2.61678975817023

Epoch: 5| Step: 5
Training loss: 0.6513051428119885
Validation loss: 2.529396037510772

Epoch: 5| Step: 6
Training loss: 0.8388757849575799
Validation loss: 2.5359852184444995

Epoch: 5| Step: 7
Training loss: 0.6609991437153312
Validation loss: 2.5290824769811437

Epoch: 5| Step: 8
Training loss: 0.5199556266668773
Validation loss: 2.5919058919831333

Epoch: 5| Step: 9
Training loss: 0.44179296854384936
Validation loss: 2.555696511758037

Epoch: 5| Step: 10
Training loss: 0.5471157361545544
Validation loss: 2.614381918551849

Epoch: 5| Step: 11
Training loss: 0.26218296274435393
Validation loss: 2.5638937164458424

Epoch: 162| Step: 0
Training loss: 0.42503724145407146
Validation loss: 2.4922751069490667

Epoch: 5| Step: 1
Training loss: 1.0377271288706587
Validation loss: 2.5256828616961697

Epoch: 5| Step: 2
Training loss: 0.5610116234899474
Validation loss: 2.4987178494902613

Epoch: 5| Step: 3
Training loss: 0.5696255191183666
Validation loss: 2.5369002814269432

Epoch: 5| Step: 4
Training loss: 0.6490747468809538
Validation loss: 2.4962196119372546

Epoch: 5| Step: 5
Training loss: 0.5821906517955013
Validation loss: 2.554806577219086

Epoch: 5| Step: 6
Training loss: 0.5349482668169616
Validation loss: 2.593276612618452

Epoch: 5| Step: 7
Training loss: 0.5137480472611119
Validation loss: 2.5100803242264087

Epoch: 5| Step: 8
Training loss: 0.5292763794031125
Validation loss: 2.5009216814972044

Epoch: 5| Step: 9
Training loss: 0.6255631294106305
Validation loss: 2.5385343422912534

Epoch: 5| Step: 10
Training loss: 0.36961265941475685
Validation loss: 2.4897762480547687

Epoch: 5| Step: 11
Training loss: 0.23809087684020305
Validation loss: 2.5382220124259334

Epoch: 163| Step: 0
Training loss: 0.4366019090956723
Validation loss: 2.50620544692066

Epoch: 5| Step: 1
Training loss: 0.5897402388333699
Validation loss: 2.5369405438224137

Epoch: 5| Step: 2
Training loss: 0.5423700063949876
Validation loss: 2.522817895836968

Epoch: 5| Step: 3
Training loss: 0.43553544786456605
Validation loss: 2.4553322914649387

Epoch: 5| Step: 4
Training loss: 0.5030824003488457
Validation loss: 2.513254059294769

Epoch: 5| Step: 5
Training loss: 0.995192505266956
Validation loss: 2.5414424130258797

Epoch: 5| Step: 6
Training loss: 0.46461335250565683
Validation loss: 2.5259177869066614

Epoch: 5| Step: 7
Training loss: 0.4384458399419225
Validation loss: 2.5309587161905895

Epoch: 5| Step: 8
Training loss: 0.6078280596469885
Validation loss: 2.5180015829314635

Epoch: 5| Step: 9
Training loss: 0.7095084447163257
Validation loss: 2.516038082792305

Epoch: 5| Step: 10
Training loss: 0.5064070104906963
Validation loss: 2.5731528646081374

Epoch: 5| Step: 11
Training loss: 0.4149873768656124
Validation loss: 2.5578176238533574

Epoch: 164| Step: 0
Training loss: 0.5144663131981483
Validation loss: 2.5603525091368318

Epoch: 5| Step: 1
Training loss: 0.6648436495896296
Validation loss: 2.491590356588526

Epoch: 5| Step: 2
Training loss: 0.6382405168850112
Validation loss: 2.489299723433365

Epoch: 5| Step: 3
Training loss: 0.6214468570032792
Validation loss: 2.4826440919289534

Epoch: 5| Step: 4
Training loss: 0.3880165364413689
Validation loss: 2.5154807501557874

Epoch: 5| Step: 5
Training loss: 0.40871776646200353
Validation loss: 2.5838670461269975

Epoch: 5| Step: 6
Training loss: 0.5380143188889672
Validation loss: 2.4810930122338997

Epoch: 5| Step: 7
Training loss: 0.5596622571252705
Validation loss: 2.5196604929656314

Epoch: 5| Step: 8
Training loss: 0.5387376552857981
Validation loss: 2.5269441617919854

Epoch: 5| Step: 9
Training loss: 1.048441497749632
Validation loss: 2.5533720784841574

Epoch: 5| Step: 10
Training loss: 0.497207997257421
Validation loss: 2.576373775148803

Epoch: 5| Step: 11
Training loss: 0.5692622822511649
Validation loss: 2.5582991607591374

Epoch: 165| Step: 0
Training loss: 0.4105784287018779
Validation loss: 2.507647987269869

Epoch: 5| Step: 1
Training loss: 0.5532044746933036
Validation loss: 2.4890413066682546

Epoch: 5| Step: 2
Training loss: 0.7140472644207253
Validation loss: 2.4925905178829897

Epoch: 5| Step: 3
Training loss: 0.34597962308221
Validation loss: 2.523885921321698

Epoch: 5| Step: 4
Training loss: 0.9499511405025213
Validation loss: 2.5775488354138565

Epoch: 5| Step: 5
Training loss: 0.5072675862429359
Validation loss: 2.530052305938608

Epoch: 5| Step: 6
Training loss: 0.6138832879086654
Validation loss: 2.505868159987605

Epoch: 5| Step: 7
Training loss: 0.5782480882084468
Validation loss: 2.583622790599141

Epoch: 5| Step: 8
Training loss: 0.48684635663278963
Validation loss: 2.5113760089922557

Epoch: 5| Step: 9
Training loss: 0.5040071667301683
Validation loss: 2.5119891023660172

Epoch: 5| Step: 10
Training loss: 0.557578678438164
Validation loss: 2.508174287837885

Epoch: 5| Step: 11
Training loss: 0.4835404312740368
Validation loss: 2.5154629649228406

Epoch: 166| Step: 0
Training loss: 0.724814578713287
Validation loss: 2.556503369926312

Epoch: 5| Step: 1
Training loss: 0.5864068249791876
Validation loss: 2.597356284660008

Epoch: 5| Step: 2
Training loss: 0.45639419171455453
Validation loss: 2.535764980656903

Epoch: 5| Step: 3
Training loss: 0.5394960401564713
Validation loss: 2.5875656211751092

Epoch: 5| Step: 4
Training loss: 0.5907656809872303
Validation loss: 2.59340129561189

Epoch: 5| Step: 5
Training loss: 0.41218251668536465
Validation loss: 2.487129084410794

Epoch: 5| Step: 6
Training loss: 0.5685922466781296
Validation loss: 2.5917340069533688

Epoch: 5| Step: 7
Training loss: 0.42104186692092316
Validation loss: 2.5783883702010435

Epoch: 5| Step: 8
Training loss: 0.4220231996832638
Validation loss: 2.556107592016376

Epoch: 5| Step: 9
Training loss: 0.822851918888445
Validation loss: 2.571934274366626

Epoch: 5| Step: 10
Training loss: 0.6061406744867294
Validation loss: 2.5989159534084907

Epoch: 5| Step: 11
Training loss: 0.5307019997613872
Validation loss: 2.558258308378141

Epoch: 167| Step: 0
Training loss: 0.39150583138757356
Validation loss: 2.630567323465241

Epoch: 5| Step: 1
Training loss: 0.3696309622502058
Validation loss: 2.5593881824854128

Epoch: 5| Step: 2
Training loss: 0.8738255793637135
Validation loss: 2.495100354002862

Epoch: 5| Step: 3
Training loss: 0.6979093598699735
Validation loss: 2.5548775084098585

Epoch: 5| Step: 4
Training loss: 0.5290348206617649
Validation loss: 2.5513649545738777

Epoch: 5| Step: 5
Training loss: 0.44448677269550435
Validation loss: 2.5615203814743412

Epoch: 5| Step: 6
Training loss: 0.446336055092897
Validation loss: 2.513518278600966

Epoch: 5| Step: 7
Training loss: 0.5172130520780863
Validation loss: 2.5251923001590275

Epoch: 5| Step: 8
Training loss: 0.40952233873530397
Validation loss: 2.538922287419643

Epoch: 5| Step: 9
Training loss: 0.4471369729064034
Validation loss: 2.5103728196890733

Epoch: 5| Step: 10
Training loss: 0.4572515527282764
Validation loss: 2.546486588955158

Epoch: 5| Step: 11
Training loss: 0.6495070770882436
Validation loss: 2.575587189182471

Epoch: 168| Step: 0
Training loss: 0.3949205724919212
Validation loss: 2.5352033151294844

Epoch: 5| Step: 1
Training loss: 0.45497118630717553
Validation loss: 2.533462828748002

Epoch: 5| Step: 2
Training loss: 0.9974110588060354
Validation loss: 2.5854883946856853

Epoch: 5| Step: 3
Training loss: 0.4629497248911532
Validation loss: 2.575395823428659

Epoch: 5| Step: 4
Training loss: 0.48125028238659784
Validation loss: 2.5664951961283364

Epoch: 5| Step: 5
Training loss: 0.6244456693962334
Validation loss: 2.6138928528783913

Epoch: 5| Step: 6
Training loss: 0.3911175864526823
Validation loss: 2.498789337192696

Epoch: 5| Step: 7
Training loss: 0.6333511791308316
Validation loss: 2.6287064535428364

Epoch: 5| Step: 8
Training loss: 0.48086974615445227
Validation loss: 2.4976601896631796

Epoch: 5| Step: 9
Training loss: 0.48110222343473386
Validation loss: 2.594845326033569

Epoch: 5| Step: 10
Training loss: 0.4202521511274719
Validation loss: 2.577981505591032

Epoch: 5| Step: 11
Training loss: 0.1061830439387562
Validation loss: 2.5891851371185717

Epoch: 169| Step: 0
Training loss: 0.6033033225945085
Validation loss: 2.555445703417902

Epoch: 5| Step: 1
Training loss: 0.471351351299273
Validation loss: 2.5431581535062704

Epoch: 5| Step: 2
Training loss: 0.86508576987723
Validation loss: 2.5864086317391983

Epoch: 5| Step: 3
Training loss: 0.5581846539782862
Validation loss: 2.4904783421106784

Epoch: 5| Step: 4
Training loss: 0.459227769314668
Validation loss: 2.573271504282812

Epoch: 5| Step: 5
Training loss: 0.40262882540430184
Validation loss: 2.56547107041168

Epoch: 5| Step: 6
Training loss: 0.6479985233454892
Validation loss: 2.5911516595260577

Epoch: 5| Step: 7
Training loss: 0.4193694450874659
Validation loss: 2.543019709782105

Epoch: 5| Step: 8
Training loss: 0.5564099821133182
Validation loss: 2.580890921185374

Epoch: 5| Step: 9
Training loss: 0.6365977915446007
Validation loss: 2.529862039037476

Epoch: 5| Step: 10
Training loss: 0.5131829839788093
Validation loss: 2.575170534931135

Epoch: 5| Step: 11
Training loss: 0.6656738478238692
Validation loss: 2.5788767094438425

Epoch: 170| Step: 0
Training loss: 0.43963702274724054
Validation loss: 2.5199187973792903

Epoch: 5| Step: 1
Training loss: 0.4645070371146079
Validation loss: 2.5455487938768036

Epoch: 5| Step: 2
Training loss: 0.6430907364328903
Validation loss: 2.553554071552548

Epoch: 5| Step: 3
Training loss: 0.3393647995358971
Validation loss: 2.5541515702013577

Epoch: 5| Step: 4
Training loss: 0.5434718922573619
Validation loss: 2.5553294006313743

Epoch: 5| Step: 5
Training loss: 0.5125000209343138
Validation loss: 2.534732773438068

Epoch: 5| Step: 6
Training loss: 0.576124441489646
Validation loss: 2.54848571270201

Epoch: 5| Step: 7
Training loss: 0.9267365239133202
Validation loss: 2.619184155615654

Epoch: 5| Step: 8
Training loss: 0.5899266064787162
Validation loss: 2.545197687356023

Epoch: 5| Step: 9
Training loss: 0.4640652364271255
Validation loss: 2.590740487807354

Epoch: 5| Step: 10
Training loss: 0.4997644614712551
Validation loss: 2.5063790476007566

Epoch: 5| Step: 11
Training loss: 0.4835882103376215
Validation loss: 2.576869524045448

Epoch: 171| Step: 0
Training loss: 0.4909650365341701
Validation loss: 2.4998988409238985

Epoch: 5| Step: 1
Training loss: 0.7724208893745055
Validation loss: 2.5165053183789126

Epoch: 5| Step: 2
Training loss: 0.5920825935786881
Validation loss: 2.541570197812592

Epoch: 5| Step: 3
Training loss: 0.6028196896232565
Validation loss: 2.6144168441066036

Epoch: 5| Step: 4
Training loss: 0.4390327647175774
Validation loss: 2.5841936798943186

Epoch: 5| Step: 5
Training loss: 0.5857103543282531
Validation loss: 2.5203256778959826

Epoch: 5| Step: 6
Training loss: 0.4398401886980464
Validation loss: 2.5331836308513784

Epoch: 5| Step: 7
Training loss: 0.4844596850291398
Validation loss: 2.6330404777189944

Epoch: 5| Step: 8
Training loss: 0.4838595262387352
Validation loss: 2.496249887023577

Epoch: 5| Step: 9
Training loss: 0.7243320314764596
Validation loss: 2.6599390218492815

Epoch: 5| Step: 10
Training loss: 0.5480928484666056
Validation loss: 2.56748925616311

Epoch: 5| Step: 11
Training loss: 0.4973305730964691
Validation loss: 2.546064513105825

Epoch: 172| Step: 0
Training loss: 0.5156545919538824
Validation loss: 2.5194362376038635

Epoch: 5| Step: 1
Training loss: 0.45806360616614156
Validation loss: 2.602705096494685

Epoch: 5| Step: 2
Training loss: 0.45759555832288606
Validation loss: 2.587005771054463

Epoch: 5| Step: 3
Training loss: 0.43257242492150066
Validation loss: 2.590413306636348

Epoch: 5| Step: 4
Training loss: 0.5016410837377813
Validation loss: 2.5122547121654493

Epoch: 5| Step: 5
Training loss: 0.447930171304616
Validation loss: 2.5099929924280695

Epoch: 5| Step: 6
Training loss: 0.7056016748186809
Validation loss: 2.529077066225349

Epoch: 5| Step: 7
Training loss: 0.9009013351501672
Validation loss: 2.5589231089823743

Epoch: 5| Step: 8
Training loss: 0.42728607862561035
Validation loss: 2.5957963179025443

Epoch: 5| Step: 9
Training loss: 0.5652072712819964
Validation loss: 2.56632871621975

Epoch: 5| Step: 10
Training loss: 0.40650546771239754
Validation loss: 2.5553809341834235

Epoch: 5| Step: 11
Training loss: 0.5296559259687253
Validation loss: 2.466748379844535

Epoch: 173| Step: 0
Training loss: 0.587567541622837
Validation loss: 2.4867037489144264

Epoch: 5| Step: 1
Training loss: 0.4706750125325173
Validation loss: 2.525800281802607

Epoch: 5| Step: 2
Training loss: 0.49163530042242154
Validation loss: 2.5333014483599428

Epoch: 5| Step: 3
Training loss: 0.37722555011266984
Validation loss: 2.4964405429816034

Epoch: 5| Step: 4
Training loss: 0.8915888941053896
Validation loss: 2.497023980729426

Epoch: 5| Step: 5
Training loss: 0.7224659437185041
Validation loss: 2.470248524052354

Epoch: 5| Step: 6
Training loss: 0.3583867749387687
Validation loss: 2.487036141480252

Epoch: 5| Step: 7
Training loss: 0.7233633345287412
Validation loss: 2.5384235849781405

Epoch: 5| Step: 8
Training loss: 0.5829079700645624
Validation loss: 2.5350616272840916

Epoch: 5| Step: 9
Training loss: 0.46474624059858766
Validation loss: 2.433480069774525

Epoch: 5| Step: 10
Training loss: 0.44399696247677034
Validation loss: 2.500457908497057

Epoch: 5| Step: 11
Training loss: 0.5641406293107505
Validation loss: 2.5036601452980167

Epoch: 174| Step: 0
Training loss: 0.5131165436153583
Validation loss: 2.468228136105204

Epoch: 5| Step: 1
Training loss: 0.6087433157442241
Validation loss: 2.561540792398904

Epoch: 5| Step: 2
Training loss: 0.5617043643218184
Validation loss: 2.534415596802631

Epoch: 5| Step: 3
Training loss: 0.3393843384682065
Validation loss: 2.4767912830210683

Epoch: 5| Step: 4
Training loss: 0.4015711616442866
Validation loss: 2.546961425999874

Epoch: 5| Step: 5
Training loss: 0.5169121830584008
Validation loss: 2.5172157510174125

Epoch: 5| Step: 6
Training loss: 0.46986891399723646
Validation loss: 2.5202130954955284

Epoch: 5| Step: 7
Training loss: 0.7683311825706296
Validation loss: 2.5239501999175458

Epoch: 5| Step: 8
Training loss: 0.8713686385304887
Validation loss: 2.515630828661119

Epoch: 5| Step: 9
Training loss: 0.518220840719487
Validation loss: 2.5721335795965867

Epoch: 5| Step: 10
Training loss: 0.5049348136640583
Validation loss: 2.5042401317815703

Epoch: 5| Step: 11
Training loss: 0.468665894274507
Validation loss: 2.559504952894604

Epoch: 175| Step: 0
Training loss: 0.5536001319958828
Validation loss: 2.6078588950523476

Epoch: 5| Step: 1
Training loss: 0.613210345986461
Validation loss: 2.609935030353889

Epoch: 5| Step: 2
Training loss: 0.4280356474028963
Validation loss: 2.580189619944883

Epoch: 5| Step: 3
Training loss: 0.7406099519126379
Validation loss: 2.6113490482120736

Epoch: 5| Step: 4
Training loss: 0.38266759192845556
Validation loss: 2.5689647816805063

Epoch: 5| Step: 5
Training loss: 0.7272518128536075
Validation loss: 2.661585856379207

Epoch: 5| Step: 6
Training loss: 0.44853907042958435
Validation loss: 2.6062702888656544

Epoch: 5| Step: 7
Training loss: 0.41532146943613024
Validation loss: 2.619590840058644

Epoch: 5| Step: 8
Training loss: 0.46185783060085944
Validation loss: 2.5609562379540596

Epoch: 5| Step: 9
Training loss: 0.5318043845486954
Validation loss: 2.62442836138215

Epoch: 5| Step: 10
Training loss: 0.6793763555672886
Validation loss: 2.619872971038443

Epoch: 5| Step: 11
Training loss: 0.3622773769398349
Validation loss: 2.5473790869314796

Epoch: 176| Step: 0
Training loss: 0.9153110421567321
Validation loss: 2.6334140064058715

Epoch: 5| Step: 1
Training loss: 0.5153494879111872
Validation loss: 2.5096944044326377

Epoch: 5| Step: 2
Training loss: 0.35538529894165544
Validation loss: 2.600866642813732

Epoch: 5| Step: 3
Training loss: 0.39492345898288883
Validation loss: 2.50342405995674

Epoch: 5| Step: 4
Training loss: 0.2654398806020369
Validation loss: 2.5035558466290047

Epoch: 5| Step: 5
Training loss: 0.437329599711038
Validation loss: 2.5658421508544222

Epoch: 5| Step: 6
Training loss: 0.5852913663585507
Validation loss: 2.6271874343389876

Epoch: 5| Step: 7
Training loss: 0.4535022020612456
Validation loss: 2.568796791182636

Epoch: 5| Step: 8
Training loss: 0.5326912067879188
Validation loss: 2.4695846096486265

Epoch: 5| Step: 9
Training loss: 0.47961781520597063
Validation loss: 2.483532876813363

Epoch: 5| Step: 10
Training loss: 0.48915432503656037
Validation loss: 2.5527930395248726

Epoch: 5| Step: 11
Training loss: 0.36971287044557277
Validation loss: 2.5159024822031566

Epoch: 177| Step: 0
Training loss: 0.8720757461839923
Validation loss: 2.550322405217795

Epoch: 5| Step: 1
Training loss: 0.34862546084904567
Validation loss: 2.568077940322074

Epoch: 5| Step: 2
Training loss: 0.4819281828015168
Validation loss: 2.549096213476315

Epoch: 5| Step: 3
Training loss: 0.4016278202647667
Validation loss: 2.51275172925748

Epoch: 5| Step: 4
Training loss: 0.5279026037248445
Validation loss: 2.551422704451682

Epoch: 5| Step: 5
Training loss: 0.38893363994121616
Validation loss: 2.6234437022648

Epoch: 5| Step: 6
Training loss: 0.4610016665004472
Validation loss: 2.5310465295275857

Epoch: 5| Step: 7
Training loss: 0.5423380255280276
Validation loss: 2.600552035225462

Epoch: 5| Step: 8
Training loss: 0.6763166610876018
Validation loss: 2.5749814954111314

Epoch: 5| Step: 9
Training loss: 0.6877725234453232
Validation loss: 2.6638755844636104

Epoch: 5| Step: 10
Training loss: 0.5390055806060395
Validation loss: 2.5967292068386896

Epoch: 5| Step: 11
Training loss: 0.31145855697360136
Validation loss: 2.5848931261753405

Epoch: 178| Step: 0
Training loss: 0.5738634580325203
Validation loss: 2.534407326256564

Epoch: 5| Step: 1
Training loss: 0.5645230523851711
Validation loss: 2.5576526920494973

Epoch: 5| Step: 2
Training loss: 0.46680182290746863
Validation loss: 2.5463225890898924

Epoch: 5| Step: 3
Training loss: 0.48692017638235174
Validation loss: 2.482257080210693

Epoch: 5| Step: 4
Training loss: 0.44992994319453256
Validation loss: 2.549291973365906

Epoch: 5| Step: 5
Training loss: 0.7758333494088745
Validation loss: 2.516557015362857

Epoch: 5| Step: 6
Training loss: 0.4571428244268244
Validation loss: 2.5101289953657164

Epoch: 5| Step: 7
Training loss: 0.452850126884302
Validation loss: 2.553260035000174

Epoch: 5| Step: 8
Training loss: 0.5951123669651002
Validation loss: 2.510606854833548

Epoch: 5| Step: 9
Training loss: 0.423310750733809
Validation loss: 2.5678528957153706

Epoch: 5| Step: 10
Training loss: 0.6127098969464767
Validation loss: 2.555810261656345

Epoch: 5| Step: 11
Training loss: 0.18414142773549966
Validation loss: 2.5136212924550088

Epoch: 179| Step: 0
Training loss: 0.6383260321344825
Validation loss: 2.629292524431742

Epoch: 5| Step: 1
Training loss: 0.5263930616937523
Validation loss: 2.505786881819216

Epoch: 5| Step: 2
Training loss: 0.648115445786687
Validation loss: 2.5073172851783596

Epoch: 5| Step: 3
Training loss: 0.45835827268315443
Validation loss: 2.560988887808933

Epoch: 5| Step: 4
Training loss: 0.3900987704540024
Validation loss: 2.5737874466165267

Epoch: 5| Step: 5
Training loss: 0.4110449835322343
Validation loss: 2.604138898065654

Epoch: 5| Step: 6
Training loss: 0.6320784750365921
Validation loss: 2.5236976615399946

Epoch: 5| Step: 7
Training loss: 0.8007817710316522
Validation loss: 2.51754125425548

Epoch: 5| Step: 8
Training loss: 0.6169395190029981
Validation loss: 2.5211108182398876

Epoch: 5| Step: 9
Training loss: 0.4405159199746519
Validation loss: 2.5438338808730876

Epoch: 5| Step: 10
Training loss: 0.4441186730051989
Validation loss: 2.4772712623932818

Epoch: 5| Step: 11
Training loss: 0.29452355119270984
Validation loss: 2.528438694514026

Epoch: 180| Step: 0
Training loss: 0.49752150108131044
Validation loss: 2.6086019181691733

Epoch: 5| Step: 1
Training loss: 0.5278499010926992
Validation loss: 2.515696096106704

Epoch: 5| Step: 2
Training loss: 0.6950491717322719
Validation loss: 2.491407150662342

Epoch: 5| Step: 3
Training loss: 0.43349383465959634
Validation loss: 2.537219798147218

Epoch: 5| Step: 4
Training loss: 0.3177343680965891
Validation loss: 2.5482516751347015

Epoch: 5| Step: 5
Training loss: 0.5284360522628796
Validation loss: 2.5472720096131587

Epoch: 5| Step: 6
Training loss: 0.48723358675272094
Validation loss: 2.5369601050386312

Epoch: 5| Step: 7
Training loss: 0.5539595972366902
Validation loss: 2.6060867720427674

Epoch: 5| Step: 8
Training loss: 0.4760004700490089
Validation loss: 2.606473546919168

Epoch: 5| Step: 9
Training loss: 0.7914371073996829
Validation loss: 2.5140528416136907

Epoch: 5| Step: 10
Training loss: 0.5089331951743973
Validation loss: 2.521917507360148

Epoch: 5| Step: 11
Training loss: 0.6661640348674346
Validation loss: 2.5700921231827203

Epoch: 181| Step: 0
Training loss: 0.50267662422076
Validation loss: 2.6203797965069913

Epoch: 5| Step: 1
Training loss: 0.5442749065873408
Validation loss: 2.5545630585112655

Epoch: 5| Step: 2
Training loss: 0.4406325386971628
Validation loss: 2.543686081460481

Epoch: 5| Step: 3
Training loss: 0.3774314573094509
Validation loss: 2.511697000792032

Epoch: 5| Step: 4
Training loss: 0.4927336977289764
Validation loss: 2.4934042787360697

Epoch: 5| Step: 5
Training loss: 0.48060147072848397
Validation loss: 2.5442993854858558

Epoch: 5| Step: 6
Training loss: 0.35557489591928354
Validation loss: 2.6129595715830467

Epoch: 5| Step: 7
Training loss: 0.45920984127804443
Validation loss: 2.558550128128112

Epoch: 5| Step: 8
Training loss: 0.4576461926075062
Validation loss: 2.5198323939736498

Epoch: 5| Step: 9
Training loss: 0.8937976611040421
Validation loss: 2.5312488540207267

Epoch: 5| Step: 10
Training loss: 0.39416341347121436
Validation loss: 2.5313435132998516

Epoch: 5| Step: 11
Training loss: 0.36238718250399304
Validation loss: 2.5708014729430357

Epoch: 182| Step: 0
Training loss: 0.5099675739489126
Validation loss: 2.542989491477247

Epoch: 5| Step: 1
Training loss: 0.6013474513523149
Validation loss: 2.55732323160263

Epoch: 5| Step: 2
Training loss: 0.5931960583681273
Validation loss: 2.57233563064554

Epoch: 5| Step: 3
Training loss: 0.46711121832647695
Validation loss: 2.5650415842132035

Epoch: 5| Step: 4
Training loss: 0.6010213374683714
Validation loss: 2.501154857368888

Epoch: 5| Step: 5
Training loss: 0.7096001759216022
Validation loss: 2.528134528394802

Epoch: 5| Step: 6
Training loss: 0.5855106324729781
Validation loss: 2.5408786010546516

Epoch: 5| Step: 7
Training loss: 0.5256519731184675
Validation loss: 2.585719542139226

Epoch: 5| Step: 8
Training loss: 0.5891511905999041
Validation loss: 2.5265416754888843

Epoch: 5| Step: 9
Training loss: 0.6182652250560151
Validation loss: 2.504086881203327

Epoch: 5| Step: 10
Training loss: 0.5665904041705072
Validation loss: 2.5224005908174223

Epoch: 5| Step: 11
Training loss: 0.3839635476627457
Validation loss: 2.576830964977822

Epoch: 183| Step: 0
Training loss: 0.5869186578910285
Validation loss: 2.5652125430892925

Epoch: 5| Step: 1
Training loss: 0.6207791377314156
Validation loss: 2.605559469966573

Epoch: 5| Step: 2
Training loss: 0.5331246734027824
Validation loss: 2.5428992094423797

Epoch: 5| Step: 3
Training loss: 0.6593656150547728
Validation loss: 2.5263077992253136

Epoch: 5| Step: 4
Training loss: 0.35867328135838505
Validation loss: 2.495127861662028

Epoch: 5| Step: 5
Training loss: 0.5179894594221034
Validation loss: 2.5827038956932484

Epoch: 5| Step: 6
Training loss: 0.7272914388265247
Validation loss: 2.5203750222624595

Epoch: 5| Step: 7
Training loss: 0.2776540980902356
Validation loss: 2.500181342541527

Epoch: 5| Step: 8
Training loss: 0.3629461609358966
Validation loss: 2.525093196810815

Epoch: 5| Step: 9
Training loss: 0.5211854284986177
Validation loss: 2.521442242582354

Epoch: 5| Step: 10
Training loss: 0.4181859174181631
Validation loss: 2.5051436914892817

Epoch: 5| Step: 11
Training loss: 0.5848016537949521
Validation loss: 2.5938874173817785

Epoch: 184| Step: 0
Training loss: 0.6449977689157386
Validation loss: 2.542652264739612

Epoch: 5| Step: 1
Training loss: 0.45250821063985947
Validation loss: 2.581032267817236

Epoch: 5| Step: 2
Training loss: 0.5955819678998366
Validation loss: 2.515400886425064

Epoch: 5| Step: 3
Training loss: 0.4732220471072111
Validation loss: 2.4846402032721637

Epoch: 5| Step: 4
Training loss: 0.6023146398414664
Validation loss: 2.507036915098395

Epoch: 5| Step: 5
Training loss: 0.34778326907374313
Validation loss: 2.476357621022691

Epoch: 5| Step: 6
Training loss: 0.5203944041537701
Validation loss: 2.5160366298124686

Epoch: 5| Step: 7
Training loss: 0.3823897304409881
Validation loss: 2.559019182473431

Epoch: 5| Step: 8
Training loss: 0.5544773025906571
Validation loss: 2.537188099263075

Epoch: 5| Step: 9
Training loss: 0.5278014845570989
Validation loss: 2.5352483810039956

Epoch: 5| Step: 10
Training loss: 0.4047167344009627
Validation loss: 2.4747664801413705

Epoch: 5| Step: 11
Training loss: 0.3773747986208267
Validation loss: 2.5624333698635136

Epoch: 185| Step: 0
Training loss: 0.36831623443698874
Validation loss: 2.482331375085142

Epoch: 5| Step: 1
Training loss: 0.5231679535507963
Validation loss: 2.6125487482733787

Epoch: 5| Step: 2
Training loss: 0.45252469187751787
Validation loss: 2.6191538886963066

Epoch: 5| Step: 3
Training loss: 0.4890773539374528
Validation loss: 2.4911398125432913

Epoch: 5| Step: 4
Training loss: 0.564590147078197
Validation loss: 2.548195069720154

Epoch: 5| Step: 5
Training loss: 0.3423336283146393
Validation loss: 2.5754399159946617

Epoch: 5| Step: 6
Training loss: 0.49226923672589656
Validation loss: 2.488507171227841

Epoch: 5| Step: 7
Training loss: 0.2932368005918623
Validation loss: 2.5108559858522277

Epoch: 5| Step: 8
Training loss: 0.7467074441702455
Validation loss: 2.523691497239285

Epoch: 5| Step: 9
Training loss: 0.3958764324650144
Validation loss: 2.4721980702426545

Epoch: 5| Step: 10
Training loss: 0.8099715431536401
Validation loss: 2.510067746671695

Epoch: 5| Step: 11
Training loss: 0.368486258376075
Validation loss: 2.5449584817778628

Epoch: 186| Step: 0
Training loss: 0.678082489403977
Validation loss: 2.5366275869267434

Epoch: 5| Step: 1
Training loss: 0.7007510269094912
Validation loss: 2.5109343463250426

Epoch: 5| Step: 2
Training loss: 0.48664467249393706
Validation loss: 2.568963756933487

Epoch: 5| Step: 3
Training loss: 0.3902568417364225
Validation loss: 2.5134704576331663

Epoch: 5| Step: 4
Training loss: 0.46483318733588264
Validation loss: 2.5907538432195505

Epoch: 5| Step: 5
Training loss: 0.47359452240319916
Validation loss: 2.4913914284993437

Epoch: 5| Step: 6
Training loss: 0.44438560124452736
Validation loss: 2.5607005911437652

Epoch: 5| Step: 7
Training loss: 0.5251441008488447
Validation loss: 2.5700948829860972

Epoch: 5| Step: 8
Training loss: 0.5360724687924726
Validation loss: 2.5280993991179574

Epoch: 5| Step: 9
Training loss: 0.5287214297157884
Validation loss: 2.5671409685527005

Epoch: 5| Step: 10
Training loss: 0.37598809558964924
Validation loss: 2.532765723519567

Epoch: 5| Step: 11
Training loss: 0.38228409168038857
Validation loss: 2.5547991387008784

Epoch: 187| Step: 0
Training loss: 0.6692436054395914
Validation loss: 2.559991376199204

Epoch: 5| Step: 1
Training loss: 0.5802603798151126
Validation loss: 2.5511574041863163

Epoch: 5| Step: 2
Training loss: 0.4451105764248756
Validation loss: 2.5593732738372608

Epoch: 5| Step: 3
Training loss: 0.36901227546318854
Validation loss: 2.5632396886468034

Epoch: 5| Step: 4
Training loss: 0.5033379832530865
Validation loss: 2.664941014543043

Epoch: 5| Step: 5
Training loss: 0.37561868256066056
Validation loss: 2.522317167215007

Epoch: 5| Step: 6
Training loss: 0.475274847847953
Validation loss: 2.5742271897867917

Epoch: 5| Step: 7
Training loss: 0.5045557493781032
Validation loss: 2.587040340441942

Epoch: 5| Step: 8
Training loss: 0.49743966879757107
Validation loss: 2.6028117902375163

Epoch: 5| Step: 9
Training loss: 0.4191136055491666
Validation loss: 2.540217476317877

Epoch: 5| Step: 10
Training loss: 0.4447960452088348
Validation loss: 2.587210930389003

Epoch: 5| Step: 11
Training loss: 0.43101673866613494
Validation loss: 2.458523162420031

Epoch: 188| Step: 0
Training loss: 0.45451592029725996
Validation loss: 2.5827339435807315

Epoch: 5| Step: 1
Training loss: 0.4677224977666442
Validation loss: 2.5760061901491538

Epoch: 5| Step: 2
Training loss: 0.5941581828816698
Validation loss: 2.628146783146525

Epoch: 5| Step: 3
Training loss: 0.38112631026430943
Validation loss: 2.553889314197218

Epoch: 5| Step: 4
Training loss: 0.41429597641949767
Validation loss: 2.5119002945521687

Epoch: 5| Step: 5
Training loss: 0.4841028494915138
Validation loss: 2.583155723331843

Epoch: 5| Step: 6
Training loss: 0.4356676284971081
Validation loss: 2.544470063097453

Epoch: 5| Step: 7
Training loss: 0.3748362104032111
Validation loss: 2.5218613724653522

Epoch: 5| Step: 8
Training loss: 0.39675082569481085
Validation loss: 2.524470717128252

Epoch: 5| Step: 9
Training loss: 0.6769225345310126
Validation loss: 2.5505296817745755

Epoch: 5| Step: 10
Training loss: 0.557030658266842
Validation loss: 2.590176813602751

Epoch: 5| Step: 11
Training loss: 0.30251403911973457
Validation loss: 2.5786648079216334

Epoch: 189| Step: 0
Training loss: 0.5402198199271877
Validation loss: 2.550515917092378

Epoch: 5| Step: 1
Training loss: 0.6028975991971152
Validation loss: 2.5574515901945256

Epoch: 5| Step: 2
Training loss: 0.25797102129448696
Validation loss: 2.50300518253939

Epoch: 5| Step: 3
Training loss: 0.4487878972311578
Validation loss: 2.589842449665462

Epoch: 5| Step: 4
Training loss: 0.4466434465725893
Validation loss: 2.5914775782986657

Epoch: 5| Step: 5
Training loss: 0.375323116651005
Validation loss: 2.561444933715207

Epoch: 5| Step: 6
Training loss: 0.41721205978395476
Validation loss: 2.5629760214760147

Epoch: 5| Step: 7
Training loss: 0.7179219825298379
Validation loss: 2.591983411870523

Epoch: 5| Step: 8
Training loss: 0.4112027940064255
Validation loss: 2.5994354273920575

Epoch: 5| Step: 9
Training loss: 0.4053061414644864
Validation loss: 2.6633166390549476

Epoch: 5| Step: 10
Training loss: 0.5541164790160309
Validation loss: 2.5872044681699613

Epoch: 5| Step: 11
Training loss: 1.0251010449544173
Validation loss: 2.5851775451994294

Epoch: 190| Step: 0
Training loss: 0.44650028163713074
Validation loss: 2.523795426280928

Epoch: 5| Step: 1
Training loss: 0.34086021692529184
Validation loss: 2.6176062253707393

Epoch: 5| Step: 2
Training loss: 0.47715505126166974
Validation loss: 2.610658777161658

Epoch: 5| Step: 3
Training loss: 0.3776673779250841
Validation loss: 2.5657523883661146

Epoch: 5| Step: 4
Training loss: 0.4959425357834555
Validation loss: 2.5866822728955365

Epoch: 5| Step: 5
Training loss: 0.3523660589290184
Validation loss: 2.6464144388978212

Epoch: 5| Step: 6
Training loss: 0.6198154466271836
Validation loss: 2.5216248362585314

Epoch: 5| Step: 7
Training loss: 0.5564650409236613
Validation loss: 2.5793258143878464

Epoch: 5| Step: 8
Training loss: 0.3507088682095748
Validation loss: 2.5421312108262617

Epoch: 5| Step: 9
Training loss: 0.6942746421058922
Validation loss: 2.5797972294009326

Epoch: 5| Step: 10
Training loss: 0.573605761671125
Validation loss: 2.4969561961900606

Epoch: 5| Step: 11
Training loss: 0.45303435898891764
Validation loss: 2.5865093109928803

Epoch: 191| Step: 0
Training loss: 0.3634254825537142
Validation loss: 2.6025163698429736

Epoch: 5| Step: 1
Training loss: 0.4350402691168372
Validation loss: 2.561481284966532

Epoch: 5| Step: 2
Training loss: 0.45901060638141017
Validation loss: 2.5790679074351712

Epoch: 5| Step: 3
Training loss: 0.4969667727811204
Validation loss: 2.5916442711180387

Epoch: 5| Step: 4
Training loss: 0.6799076206203805
Validation loss: 2.5419142998511135

Epoch: 5| Step: 5
Training loss: 0.6320459408932936
Validation loss: 2.5843144189452496

Epoch: 5| Step: 6
Training loss: 0.34850501274570234
Validation loss: 2.6157761388460288

Epoch: 5| Step: 7
Training loss: 0.40397729082891565
Validation loss: 2.5741476185164793

Epoch: 5| Step: 8
Training loss: 0.5667481541479448
Validation loss: 2.5715388142815385

Epoch: 5| Step: 9
Training loss: 0.5665028456829411
Validation loss: 2.5711751300022723

Epoch: 5| Step: 10
Training loss: 0.4552158425655235
Validation loss: 2.591117146906694

Epoch: 5| Step: 11
Training loss: 0.19810024121817163
Validation loss: 2.593700875732468

Epoch: 192| Step: 0
Training loss: 0.6672762353926891
Validation loss: 2.676891495675127

Epoch: 5| Step: 1
Training loss: 0.5430760174734067
Validation loss: 2.673428639602173

Epoch: 5| Step: 2
Training loss: 0.49248273260083014
Validation loss: 2.6044516038778167

Epoch: 5| Step: 3
Training loss: 0.6667177185737208
Validation loss: 2.5890372215791215

Epoch: 5| Step: 4
Training loss: 0.5165883226627035
Validation loss: 2.4888709670499667

Epoch: 5| Step: 5
Training loss: 0.46732396330375864
Validation loss: 2.5519123928405207

Epoch: 5| Step: 6
Training loss: 0.4801535774452023
Validation loss: 2.598652790484496

Epoch: 5| Step: 7
Training loss: 0.4698026916608683
Validation loss: 2.5815467437606867

Epoch: 5| Step: 8
Training loss: 0.4214386802983802
Validation loss: 2.498686508992871

Epoch: 5| Step: 9
Training loss: 0.5161584637659044
Validation loss: 2.5845120929856495

Epoch: 5| Step: 10
Training loss: 0.40655374175951164
Validation loss: 2.479757800805324

Epoch: 5| Step: 11
Training loss: 0.31061560392080434
Validation loss: 2.5529748812571755

Epoch: 193| Step: 0
Training loss: 0.5525114330990257
Validation loss: 2.5430260381774388

Epoch: 5| Step: 1
Training loss: 0.5468828473209301
Validation loss: 2.605925230714114

Epoch: 5| Step: 2
Training loss: 0.5574407081122478
Validation loss: 2.4758216359471943

Epoch: 5| Step: 3
Training loss: 0.413615903588916
Validation loss: 2.5771032254482615

Epoch: 5| Step: 4
Training loss: 0.6263772571730877
Validation loss: 2.5761493009938

Epoch: 5| Step: 5
Training loss: 0.5122696917292312
Validation loss: 2.5513553586696

Epoch: 5| Step: 6
Training loss: 0.32826641986145505
Validation loss: 2.6006915913424584

Epoch: 5| Step: 7
Training loss: 0.437206800169774
Validation loss: 2.5500628816574364

Epoch: 5| Step: 8
Training loss: 0.44167900098216106
Validation loss: 2.578163921178007

Epoch: 5| Step: 9
Training loss: 0.36256411741751143
Validation loss: 2.5119024993620056

Epoch: 5| Step: 10
Training loss: 0.42932838692219616
Validation loss: 2.5373009542561515

Epoch: 5| Step: 11
Training loss: 0.38600398969688454
Validation loss: 2.6119124168520695

Epoch: 194| Step: 0
Training loss: 0.658634101292208
Validation loss: 2.600151653176845

Epoch: 5| Step: 1
Training loss: 0.4130591165118604
Validation loss: 2.483830978201059

Epoch: 5| Step: 2
Training loss: 0.47536460222222143
Validation loss: 2.542444549144664

Epoch: 5| Step: 3
Training loss: 0.3867152628115244
Validation loss: 2.556900745561548

Epoch: 5| Step: 4
Training loss: 0.42339466272426396
Validation loss: 2.5224580704449604

Epoch: 5| Step: 5
Training loss: 0.34594333514536224
Validation loss: 2.5189456742213387

Epoch: 5| Step: 6
Training loss: 0.36942076775482885
Validation loss: 2.5165546034395305

Epoch: 5| Step: 7
Training loss: 0.44411446218338707
Validation loss: 2.5881281137958196

Epoch: 5| Step: 8
Training loss: 0.5614448824128232
Validation loss: 2.5473362908625297

Epoch: 5| Step: 9
Training loss: 0.46470478128342196
Validation loss: 2.533887144830101

Epoch: 5| Step: 10
Training loss: 0.5530098003101939
Validation loss: 2.5278611614083224

Epoch: 5| Step: 11
Training loss: 0.15052953720227025
Validation loss: 2.5502697527702307

Epoch: 195| Step: 0
Training loss: 0.34394923851809506
Validation loss: 2.525240699701845

Epoch: 5| Step: 1
Training loss: 0.48812489867361974
Validation loss: 2.5252908803502714

Epoch: 5| Step: 2
Training loss: 0.34931539183979377
Validation loss: 2.5361286545696013

Epoch: 5| Step: 3
Training loss: 0.5550041369550329
Validation loss: 2.529762140829679

Epoch: 5| Step: 4
Training loss: 0.40879125981804265
Validation loss: 2.4941775787969602

Epoch: 5| Step: 5
Training loss: 0.475242365315742
Validation loss: 2.545492811316612

Epoch: 5| Step: 6
Training loss: 0.617299588805222
Validation loss: 2.495206071100364

Epoch: 5| Step: 7
Training loss: 0.4298148400011554
Validation loss: 2.521808830915254

Epoch: 5| Step: 8
Training loss: 0.473669133317611
Validation loss: 2.579705930783016

Epoch: 5| Step: 9
Training loss: 0.35183784510604743
Validation loss: 2.5682197755265275

Epoch: 5| Step: 10
Training loss: 0.2968646223362534
Validation loss: 2.527874854922913

Epoch: 5| Step: 11
Training loss: 0.3296252196365105
Validation loss: 2.520254375373239

Epoch: 196| Step: 0
Training loss: 0.478457996245817
Validation loss: 2.5542173896055207

Epoch: 5| Step: 1
Training loss: 0.3125412079344475
Validation loss: 2.587087769158713

Epoch: 5| Step: 2
Training loss: 0.6572588931062792
Validation loss: 2.531546661668962

Epoch: 5| Step: 3
Training loss: 0.403737182945208
Validation loss: 2.6288441447101363

Epoch: 5| Step: 4
Training loss: 0.4236016085693213
Validation loss: 2.5898542945766065

Epoch: 5| Step: 5
Training loss: 0.49613383273899886
Validation loss: 2.5676174702278356

Epoch: 5| Step: 6
Training loss: 0.3954162303244163
Validation loss: 2.623629507430349

Epoch: 5| Step: 7
Training loss: 0.4026769536076195
Validation loss: 2.580131701544361

Epoch: 5| Step: 8
Training loss: 0.5787922385273373
Validation loss: 2.566262111941824

Epoch: 5| Step: 9
Training loss: 0.4919022990240683
Validation loss: 2.6323777433168822

Epoch: 5| Step: 10
Training loss: 0.3995337085551261
Validation loss: 2.5487314451938237

Epoch: 5| Step: 11
Training loss: 0.4117498411422636
Validation loss: 2.564245370050231

Epoch: 197| Step: 0
Training loss: 0.47657313100495063
Validation loss: 2.574381509130389

Epoch: 5| Step: 1
Training loss: 0.3591410248417897
Validation loss: 2.5029051351961624

Epoch: 5| Step: 2
Training loss: 0.424392956675438
Validation loss: 2.6295003536161503

Epoch: 5| Step: 3
Training loss: 0.2742965555257086
Validation loss: 2.622999268963996

Epoch: 5| Step: 4
Training loss: 0.3295739968340229
Validation loss: 2.6077923038920385

Epoch: 5| Step: 5
Training loss: 0.4444236417296102
Validation loss: 2.636232447106795

Epoch: 5| Step: 6
Training loss: 0.4621745981733125
Validation loss: 2.5978957981188167

Epoch: 5| Step: 7
Training loss: 0.5869780900658181
Validation loss: 2.6153176113763497

Epoch: 5| Step: 8
Training loss: 0.4187658143259972
Validation loss: 2.650855263312811

Epoch: 5| Step: 9
Training loss: 0.40335393215942555
Validation loss: 2.5697781936009862

Epoch: 5| Step: 10
Training loss: 0.5032231039751853
Validation loss: 2.6147285638928603

Epoch: 5| Step: 11
Training loss: 0.5025061740780628
Validation loss: 2.5660223245496976

Epoch: 198| Step: 0
Training loss: 0.6728033261663701
Validation loss: 2.6568129186108163

Epoch: 5| Step: 1
Training loss: 0.4937292505081221
Validation loss: 2.6278000120000136

Epoch: 5| Step: 2
Training loss: 0.5408739806576234
Validation loss: 2.60812483513828

Epoch: 5| Step: 3
Training loss: 0.3689518602314239
Validation loss: 2.6109524639499075

Epoch: 5| Step: 4
Training loss: 0.4369933396209399
Validation loss: 2.5355014223169867

Epoch: 5| Step: 5
Training loss: 0.24464011404589933
Validation loss: 2.5345418741059853

Epoch: 5| Step: 6
Training loss: 0.5172044088590244
Validation loss: 2.6269276670902815

Epoch: 5| Step: 7
Training loss: 0.4075087523251817
Validation loss: 2.599826730095882

Epoch: 5| Step: 8
Training loss: 0.4286121610886283
Validation loss: 2.6015223594524337

Epoch: 5| Step: 9
Training loss: 0.37647030600062126
Validation loss: 2.57375671145611

Epoch: 5| Step: 10
Training loss: 0.38877890181968733
Validation loss: 2.5596800965798314

Epoch: 5| Step: 11
Training loss: 0.22587809284227023
Validation loss: 2.592406068339895

Epoch: 199| Step: 0
Training loss: 0.3564127449938942
Validation loss: 2.547484172916007

Epoch: 5| Step: 1
Training loss: 0.40623224659788437
Validation loss: 2.5409824448339013

Epoch: 5| Step: 2
Training loss: 0.46139132254972587
Validation loss: 2.6276006266957923

Epoch: 5| Step: 3
Training loss: 0.48698358142776005
Validation loss: 2.6741145268289856

Epoch: 5| Step: 4
Training loss: 0.45772659355043277
Validation loss: 2.5644961428805093

Epoch: 5| Step: 5
Training loss: 0.42892754715538217
Validation loss: 2.6026063300833657

Epoch: 5| Step: 6
Training loss: 0.49917276316896386
Validation loss: 2.545798087669506

Epoch: 5| Step: 7
Training loss: 0.36666792775428536
Validation loss: 2.604778314604185

Epoch: 5| Step: 8
Training loss: 0.5441956962545652
Validation loss: 2.545893021511828

Epoch: 5| Step: 9
Training loss: 0.5229258242662673
Validation loss: 2.474544734055371

Epoch: 5| Step: 10
Training loss: 0.3292458215236913
Validation loss: 2.5678098953826236

Epoch: 5| Step: 11
Training loss: 0.6591860622521618
Validation loss: 2.5894055424917

Epoch: 200| Step: 0
Training loss: 0.5263698485807907
Validation loss: 2.466022485684917

Epoch: 5| Step: 1
Training loss: 0.647542128499577
Validation loss: 2.536062218808872

Epoch: 5| Step: 2
Training loss: 0.24353711876295292
Validation loss: 2.5119640335385416

Epoch: 5| Step: 3
Training loss: 0.4800177993305466
Validation loss: 2.5433232714161087

Epoch: 5| Step: 4
Training loss: 0.34485455263171105
Validation loss: 2.627957585249426

Epoch: 5| Step: 5
Training loss: 0.658103731614161
Validation loss: 2.623638288074335

Epoch: 5| Step: 6
Training loss: 0.4636411095867582
Validation loss: 2.6738640221098797

Epoch: 5| Step: 7
Training loss: 0.5293976803889832
Validation loss: 2.68594271430219

Epoch: 5| Step: 8
Training loss: 0.3349487814073765
Validation loss: 2.6019953423968323

Epoch: 5| Step: 9
Training loss: 0.6459314569154597
Validation loss: 2.5796656580893154

Epoch: 5| Step: 10
Training loss: 0.41619716856014893
Validation loss: 2.6000795653285445

Epoch: 5| Step: 11
Training loss: 0.33175257039170336
Validation loss: 2.4985880957650743

Testing loss: 2.603925560344292
