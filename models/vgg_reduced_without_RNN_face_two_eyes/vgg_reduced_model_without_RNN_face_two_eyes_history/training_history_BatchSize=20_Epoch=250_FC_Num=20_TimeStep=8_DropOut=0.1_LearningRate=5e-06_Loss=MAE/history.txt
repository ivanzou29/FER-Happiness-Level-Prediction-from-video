Epoch: 1| Step: 0
Training loss: 6.697778224945068
Validation loss: 6.4599360426266985

Epoch: 5| Step: 1
Training loss: 5.7760138511657715
Validation loss: 6.421826899051666

Epoch: 5| Step: 2
Training loss: 6.521330833435059
Validation loss: 6.382029155890147

Epoch: 5| Step: 3
Training loss: 6.228765964508057
Validation loss: 6.338151335716248

Epoch: 5| Step: 4
Training loss: 6.63693380355835
Validation loss: 6.299672305583954

Epoch: 5| Step: 5
Training loss: 6.468544006347656
Validation loss: 6.2599345445632935

Epoch: 5| Step: 6
Training loss: 5.786226749420166
Validation loss: 6.219407955805461

Epoch: 5| Step: 7
Training loss: 6.489433288574219
Validation loss: 6.181803961594899

Epoch: 5| Step: 8
Training loss: 6.069266319274902
Validation loss: 6.141387422879537

Epoch: 5| Step: 9
Training loss: 6.414085388183594
Validation loss: 6.101623992125194

Epoch: 5| Step: 10
Training loss: 6.901711463928223
Validation loss: 6.0640813906987505

Epoch: 5| Step: 11
Training loss: 4.448105812072754
Validation loss: 6.024614751338959

Epoch: 2| Step: 0
Training loss: 6.4195356369018555
Validation loss: 5.983860095342

Epoch: 5| Step: 1
Training loss: 5.895315647125244
Validation loss: 5.944636702537537

Epoch: 5| Step: 2
Training loss: 4.918841361999512
Validation loss: 5.904316147168477

Epoch: 5| Step: 3
Training loss: 6.157886505126953
Validation loss: 5.859290421009064

Epoch: 5| Step: 4
Training loss: 5.885878086090088
Validation loss: 5.816835780938466

Epoch: 5| Step: 5
Training loss: 5.578920841217041
Validation loss: 5.76765392223994

Epoch: 5| Step: 6
Training loss: 6.327452659606934
Validation loss: 5.714928686618805

Epoch: 5| Step: 7
Training loss: 5.879310131072998
Validation loss: 5.66383562485377

Epoch: 5| Step: 8
Training loss: 5.8694562911987305
Validation loss: 5.615282436211904

Epoch: 5| Step: 9
Training loss: 5.564187049865723
Validation loss: 5.554185728232066

Epoch: 5| Step: 10
Training loss: 5.207161903381348
Validation loss: 5.488844911257426

Epoch: 5| Step: 11
Training loss: 7.420134544372559
Validation loss: 5.42857692639033

Epoch: 3| Step: 0
Training loss: 5.2957763671875
Validation loss: 5.360056360562642

Epoch: 5| Step: 1
Training loss: 5.5802764892578125
Validation loss: 5.2931254506111145

Epoch: 5| Step: 2
Training loss: 6.018784999847412
Validation loss: 5.220698356628418

Epoch: 5| Step: 3
Training loss: 3.779433488845825
Validation loss: 5.147112150986989

Epoch: 5| Step: 4
Training loss: 5.222741603851318
Validation loss: 5.064506034056346

Epoch: 5| Step: 5
Training loss: 4.6534600257873535
Validation loss: 4.9885207414627075

Epoch: 5| Step: 6
Training loss: 5.457904815673828
Validation loss: 4.8987405101458235

Epoch: 5| Step: 7
Training loss: 4.332877159118652
Validation loss: 4.808774650096893

Epoch: 5| Step: 8
Training loss: 5.638088703155518
Validation loss: 4.711940705776215

Epoch: 5| Step: 9
Training loss: 4.316206932067871
Validation loss: 4.613439043362935

Epoch: 5| Step: 10
Training loss: 4.953650951385498
Validation loss: 4.514913856983185

Epoch: 5| Step: 11
Training loss: 4.884725570678711
Validation loss: 4.404755870501201

Epoch: 4| Step: 0
Training loss: 4.720341205596924
Validation loss: 4.303686678409576

Epoch: 5| Step: 1
Training loss: 4.296823024749756
Validation loss: 4.184660027424495

Epoch: 5| Step: 2
Training loss: 4.3864240646362305
Validation loss: 4.065129508574803

Epoch: 5| Step: 3
Training loss: 3.365679979324341
Validation loss: 3.954819917678833

Epoch: 5| Step: 4
Training loss: 4.385732650756836
Validation loss: 3.8361379206180573

Epoch: 5| Step: 5
Training loss: 4.51005220413208
Validation loss: 3.7222337424755096

Epoch: 5| Step: 6
Training loss: 3.7409279346466064
Validation loss: 3.6053251723448434

Epoch: 5| Step: 7
Training loss: 3.9849987030029297
Validation loss: 3.4874006708463035

Epoch: 5| Step: 8
Training loss: 3.0083582401275635
Validation loss: 3.366046061118444

Epoch: 5| Step: 9
Training loss: 2.729853630065918
Validation loss: 3.251017222801844

Epoch: 5| Step: 10
Training loss: 2.7414326667785645
Validation loss: 3.1149604817231498

Epoch: 5| Step: 11
Training loss: 3.1368091106414795
Validation loss: 2.999470372994741

Epoch: 5| Step: 0
Training loss: 2.779491424560547
Validation loss: 2.887955198685328

Epoch: 5| Step: 1
Training loss: 2.3363189697265625
Validation loss: 2.7741925021012626

Epoch: 5| Step: 2
Training loss: 3.221417188644409
Validation loss: 2.645932341615359

Epoch: 5| Step: 3
Training loss: 2.657224178314209
Validation loss: 2.5215857525666556

Epoch: 5| Step: 4
Training loss: 2.311323642730713
Validation loss: 2.421829263369242

Epoch: 5| Step: 5
Training loss: 2.1852245330810547
Validation loss: 2.3433798054854074

Epoch: 5| Step: 6
Training loss: 3.260688066482544
Validation loss: 2.293900499741236

Epoch: 5| Step: 7
Training loss: 1.9261947870254517
Validation loss: 2.2642063101132712

Epoch: 5| Step: 8
Training loss: 2.550820827484131
Validation loss: 2.2413638532161713

Epoch: 5| Step: 9
Training loss: 2.0375051498413086
Validation loss: 2.230402539173762

Epoch: 5| Step: 10
Training loss: 2.02695631980896
Validation loss: 2.2431817253430686

Epoch: 5| Step: 11
Training loss: 1.2032133340835571
Validation loss: 2.1998966137568154

Epoch: 6| Step: 0
Training loss: 1.7122974395751953
Validation loss: 2.251341328024864

Epoch: 5| Step: 1
Training loss: 1.5413233041763306
Validation loss: 2.287857453028361

Epoch: 5| Step: 2
Training loss: 2.7468955516815186
Validation loss: 2.324375738700231

Epoch: 5| Step: 3
Training loss: 2.5862295627593994
Validation loss: 2.3024979333082833

Epoch: 5| Step: 4
Training loss: 2.985433578491211
Validation loss: 2.283436954021454

Epoch: 5| Step: 5
Training loss: 2.18674898147583
Validation loss: 2.307650148868561

Epoch: 5| Step: 6
Training loss: 2.503446340560913
Validation loss: 2.2972134153048196

Epoch: 5| Step: 7
Training loss: 3.1957945823669434
Validation loss: 2.249579777320226

Epoch: 5| Step: 8
Training loss: 2.19219708442688
Validation loss: 2.232136140267054

Epoch: 5| Step: 9
Training loss: 2.032688856124878
Validation loss: 2.196665888031324

Epoch: 5| Step: 10
Training loss: 2.055636167526245
Validation loss: 2.2115245262781777

Epoch: 5| Step: 11
Training loss: 2.4277849197387695
Validation loss: 2.20363915959994

Epoch: 7| Step: 0
Training loss: 1.684865951538086
Validation loss: 2.226326048374176

Epoch: 5| Step: 1
Training loss: 2.6557087898254395
Validation loss: 2.195669338107109

Epoch: 5| Step: 2
Training loss: 2.737396478652954
Validation loss: 2.1987891842921576

Epoch: 5| Step: 3
Training loss: 2.4247918128967285
Validation loss: 2.1907860338687897

Epoch: 5| Step: 4
Training loss: 2.2720227241516113
Validation loss: 2.212216079235077

Epoch: 5| Step: 5
Training loss: 2.127469301223755
Validation loss: 2.189182569583257

Epoch: 5| Step: 6
Training loss: 2.0328855514526367
Validation loss: 2.2007637917995453

Epoch: 5| Step: 7
Training loss: 2.5082170963287354
Validation loss: 2.1839968313773475

Epoch: 5| Step: 8
Training loss: 1.8164371252059937
Validation loss: 2.1897190709908805

Epoch: 5| Step: 9
Training loss: 2.03084135055542
Validation loss: 2.1963625301917395

Epoch: 5| Step: 10
Training loss: 1.8056904077529907
Validation loss: 2.2023190458615622

Epoch: 5| Step: 11
Training loss: 2.8952693939208984
Validation loss: 2.186342885096868

Epoch: 8| Step: 0
Training loss: 1.6771007776260376
Validation loss: 2.2094014088312783

Epoch: 5| Step: 1
Training loss: 2.663489818572998
Validation loss: 2.1781881948312125

Epoch: 5| Step: 2
Training loss: 2.2166926860809326
Validation loss: 2.2096990793943405

Epoch: 5| Step: 3
Training loss: 2.308809280395508
Validation loss: 2.182237461209297

Epoch: 5| Step: 4
Training loss: 2.0218393802642822
Validation loss: 2.197678575913111

Epoch: 5| Step: 5
Training loss: 1.8089170455932617
Validation loss: 2.189097205797831

Epoch: 5| Step: 6
Training loss: 1.8934123516082764
Validation loss: 2.1945906480153403

Epoch: 5| Step: 7
Training loss: 2.1699700355529785
Validation loss: 2.1785046458244324

Epoch: 5| Step: 8
Training loss: 1.841797113418579
Validation loss: 2.1916367461284003

Epoch: 5| Step: 9
Training loss: 2.6316802501678467
Validation loss: 2.1806514958540597

Epoch: 5| Step: 10
Training loss: 2.6636767387390137
Validation loss: 2.182238817214966

Epoch: 5| Step: 11
Training loss: 2.2331879138946533
Validation loss: 2.1799619446198144

Epoch: 9| Step: 0
Training loss: 2.2631959915161133
Validation loss: 2.1854861776034036

Epoch: 5| Step: 1
Training loss: 1.6910030841827393
Validation loss: 2.1806070307890573

Epoch: 5| Step: 2
Training loss: 2.0472772121429443
Validation loss: 2.166176900267601

Epoch: 5| Step: 3
Training loss: 2.137774705886841
Validation loss: 2.1676497161388397

Epoch: 5| Step: 4
Training loss: 2.437669038772583
Validation loss: 2.1856332470973334

Epoch: 5| Step: 5
Training loss: 1.8446155786514282
Validation loss: 2.1848134150107703

Epoch: 5| Step: 6
Training loss: 2.1211509704589844
Validation loss: 2.1708668768405914

Epoch: 5| Step: 7
Training loss: 1.9309194087982178
Validation loss: 2.1648285736640296

Epoch: 5| Step: 8
Training loss: 2.4088611602783203
Validation loss: 2.153301661213239

Epoch: 5| Step: 9
Training loss: 2.7408607006073
Validation loss: 2.1548316876093545

Epoch: 5| Step: 10
Training loss: 2.322117328643799
Validation loss: 2.1584804157416024

Epoch: 5| Step: 11
Training loss: 1.7120797634124756
Validation loss: 2.153372829159101

Epoch: 10| Step: 0
Training loss: 2.5390238761901855
Validation loss: 2.1596333384513855

Epoch: 5| Step: 1
Training loss: 2.26234769821167
Validation loss: 2.1461563408374786

Epoch: 5| Step: 2
Training loss: 2.346487045288086
Validation loss: 2.1398921608924866

Epoch: 5| Step: 3
Training loss: 1.9097248315811157
Validation loss: 2.1651960710684457

Epoch: 5| Step: 4
Training loss: 2.116147041320801
Validation loss: 2.1405668358008065

Epoch: 5| Step: 5
Training loss: 2.136854648590088
Validation loss: 2.136723985274633

Epoch: 5| Step: 6
Training loss: 2.4307780265808105
Validation loss: 2.1194710234800973

Epoch: 5| Step: 7
Training loss: 2.499269962310791
Validation loss: 2.1367975572745004

Epoch: 5| Step: 8
Training loss: 1.6765539646148682
Validation loss: 2.167960226535797

Epoch: 5| Step: 9
Training loss: 2.184081554412842
Validation loss: 2.149283309777578

Epoch: 5| Step: 10
Training loss: 1.7432644367218018
Validation loss: 2.1212167938550315

Epoch: 5| Step: 11
Training loss: 0.813595175743103
Validation loss: 2.133755957086881

Epoch: 11| Step: 0
Training loss: 2.5920214653015137
Validation loss: 2.146556337674459

Epoch: 5| Step: 1
Training loss: 2.074293851852417
Validation loss: 2.1280521949132285

Epoch: 5| Step: 2
Training loss: 2.2416605949401855
Validation loss: 2.148555338382721

Epoch: 5| Step: 3
Training loss: 1.8540544509887695
Validation loss: 2.1410242716471353

Epoch: 5| Step: 4
Training loss: 2.483105421066284
Validation loss: 2.13920226196448

Epoch: 5| Step: 5
Training loss: 1.6095542907714844
Validation loss: 2.131354237596194

Epoch: 5| Step: 6
Training loss: 2.0884151458740234
Validation loss: 2.141774997115135

Epoch: 5| Step: 7
Training loss: 2.282970428466797
Validation loss: 2.128167370955149

Epoch: 5| Step: 8
Training loss: 2.0530006885528564
Validation loss: 2.13098772863547

Epoch: 5| Step: 9
Training loss: 2.2366766929626465
Validation loss: 2.1292362411816916

Epoch: 5| Step: 10
Training loss: 2.0049757957458496
Validation loss: 2.1489522655804953

Epoch: 5| Step: 11
Training loss: 1.2264289855957031
Validation loss: 2.139435554544131

Epoch: 12| Step: 0
Training loss: 2.0756382942199707
Validation loss: 2.1338238219420114

Epoch: 5| Step: 1
Training loss: 2.0257344245910645
Validation loss: 2.1155239591995874

Epoch: 5| Step: 2
Training loss: 1.9486862421035767
Validation loss: 2.1271767020225525

Epoch: 5| Step: 3
Training loss: 2.648960590362549
Validation loss: 2.124716470638911

Epoch: 5| Step: 4
Training loss: 2.5972018241882324
Validation loss: 2.1356176187594733

Epoch: 5| Step: 5
Training loss: 2.128624677658081
Validation loss: 2.1122115701436996

Epoch: 5| Step: 6
Training loss: 2.0172653198242188
Validation loss: 2.11314948896567

Epoch: 5| Step: 7
Training loss: 2.226447105407715
Validation loss: 2.095479408899943

Epoch: 5| Step: 8
Training loss: 1.9982799291610718
Validation loss: 2.0944521774848304

Epoch: 5| Step: 9
Training loss: 1.8088123798370361
Validation loss: 2.1006804009278617

Epoch: 5| Step: 10
Training loss: 1.9674783945083618
Validation loss: 2.1179284503062568

Epoch: 5| Step: 11
Training loss: 0.9788117408752441
Validation loss: 2.102835769454638

Epoch: 13| Step: 0
Training loss: 2.1691861152648926
Validation loss: 2.113580892483393

Epoch: 5| Step: 1
Training loss: 1.797849416732788
Validation loss: 2.1040750294923782

Epoch: 5| Step: 2
Training loss: 2.222076416015625
Validation loss: 2.107508420944214

Epoch: 5| Step: 3
Training loss: 1.889089584350586
Validation loss: 2.082725152373314

Epoch: 5| Step: 4
Training loss: 2.1607961654663086
Validation loss: 2.1193127433458963

Epoch: 5| Step: 5
Training loss: 2.1802430152893066
Validation loss: 2.0970403303702674

Epoch: 5| Step: 6
Training loss: 1.9721676111221313
Validation loss: 2.103867640097936

Epoch: 5| Step: 7
Training loss: 1.971704125404358
Validation loss: 2.087734659512838

Epoch: 5| Step: 8
Training loss: 2.6426079273223877
Validation loss: 2.1008185148239136

Epoch: 5| Step: 9
Training loss: 2.233718156814575
Validation loss: 2.107274999221166

Epoch: 5| Step: 10
Training loss: 1.8611652851104736
Validation loss: 2.1207540730635324

Epoch: 5| Step: 11
Training loss: 1.9084579944610596
Validation loss: 2.096732626358668

Epoch: 14| Step: 0
Training loss: 1.6576846837997437
Validation loss: 2.105103681484858

Epoch: 5| Step: 1
Training loss: 1.869826078414917
Validation loss: 2.10544016957283

Epoch: 5| Step: 2
Training loss: 2.2585129737854004
Validation loss: 2.087255284190178

Epoch: 5| Step: 3
Training loss: 2.1090550422668457
Validation loss: 2.0904723604520163

Epoch: 5| Step: 4
Training loss: 2.051478147506714
Validation loss: 2.1001949508984885

Epoch: 5| Step: 5
Training loss: 2.3943257331848145
Validation loss: 2.126425455013911

Epoch: 5| Step: 6
Training loss: 2.4073996543884277
Validation loss: 2.101147005955378

Epoch: 5| Step: 7
Training loss: 1.8169782161712646
Validation loss: 2.0883889297644296

Epoch: 5| Step: 8
Training loss: 1.8762174844741821
Validation loss: 2.0833136836687722

Epoch: 5| Step: 9
Training loss: 1.8531272411346436
Validation loss: 2.08808163801829

Epoch: 5| Step: 10
Training loss: 2.3056979179382324
Validation loss: 2.0970198810100555

Epoch: 5| Step: 11
Training loss: 3.128220558166504
Validation loss: 2.082797721028328

Epoch: 15| Step: 0
Training loss: 2.219735622406006
Validation loss: 2.0870113223791122

Epoch: 5| Step: 1
Training loss: 2.0942633152008057
Validation loss: 2.0875566055377326

Epoch: 5| Step: 2
Training loss: 1.9848787784576416
Validation loss: 2.0765627970298133

Epoch: 5| Step: 3
Training loss: 2.0863468647003174
Validation loss: 2.070595527688662

Epoch: 5| Step: 4
Training loss: 2.2746951580047607
Validation loss: 2.07989065349102

Epoch: 5| Step: 5
Training loss: 2.0111591815948486
Validation loss: 2.0624317775170007

Epoch: 5| Step: 6
Training loss: 2.307631254196167
Validation loss: 2.0724582572778067

Epoch: 5| Step: 7
Training loss: 2.2108683586120605
Validation loss: 2.061671664317449

Epoch: 5| Step: 8
Training loss: 1.5355570316314697
Validation loss: 2.0687256207068763

Epoch: 5| Step: 9
Training loss: 2.260281562805176
Validation loss: 2.092777758836746

Epoch: 5| Step: 10
Training loss: 1.8671979904174805
Validation loss: 2.0770299583673477

Epoch: 5| Step: 11
Training loss: 1.7248623371124268
Validation loss: 2.0730646749337516

Epoch: 16| Step: 0
Training loss: 1.930789589881897
Validation loss: 2.052717144290606

Epoch: 5| Step: 1
Training loss: 2.7366392612457275
Validation loss: 2.0800866335630417

Epoch: 5| Step: 2
Training loss: 1.9727684259414673
Validation loss: 2.0644065539042153

Epoch: 5| Step: 3
Training loss: 2.3754444122314453
Validation loss: 2.0679327646891275

Epoch: 5| Step: 4
Training loss: 1.718667984008789
Validation loss: 2.0806647588809333

Epoch: 5| Step: 5
Training loss: 1.6832879781723022
Validation loss: 2.0768256336450577

Epoch: 5| Step: 6
Training loss: 1.7084068059921265
Validation loss: 2.0878812024990716

Epoch: 5| Step: 7
Training loss: 2.133683443069458
Validation loss: 2.0942526906728745

Epoch: 5| Step: 8
Training loss: 2.8650920391082764
Validation loss: 2.0680462419986725

Epoch: 5| Step: 9
Training loss: 1.9485843181610107
Validation loss: 2.0878391017516456

Epoch: 5| Step: 10
Training loss: 2.0199687480926514
Validation loss: 2.078063115477562

Epoch: 5| Step: 11
Training loss: 1.039076328277588
Validation loss: 2.0652236143747964

Epoch: 17| Step: 0
Training loss: 1.5416584014892578
Validation loss: 2.051374008258184

Epoch: 5| Step: 1
Training loss: 2.2116310596466064
Validation loss: 2.0700616588195166

Epoch: 5| Step: 2
Training loss: 1.8441082239151
Validation loss: 2.0592559526364007

Epoch: 5| Step: 3
Training loss: 2.690570592880249
Validation loss: 2.065097560485204

Epoch: 5| Step: 4
Training loss: 2.173576831817627
Validation loss: 2.0478502909342446

Epoch: 5| Step: 5
Training loss: 2.0649399757385254
Validation loss: 2.07266104221344

Epoch: 5| Step: 6
Training loss: 1.8204402923583984
Validation loss: 2.063098053137461

Epoch: 5| Step: 7
Training loss: 2.4804587364196777
Validation loss: 2.0692554910977683

Epoch: 5| Step: 8
Training loss: 2.12742280960083
Validation loss: 2.063483660419782

Epoch: 5| Step: 9
Training loss: 2.163210391998291
Validation loss: 2.0624999552965164

Epoch: 5| Step: 10
Training loss: 1.4208829402923584
Validation loss: 2.0442067831754684

Epoch: 5| Step: 11
Training loss: 2.475634813308716
Validation loss: 2.070123717188835

Epoch: 18| Step: 0
Training loss: 2.0297176837921143
Validation loss: 2.07154173652331

Epoch: 5| Step: 1
Training loss: 1.9748274087905884
Validation loss: 2.0377607693274817

Epoch: 5| Step: 2
Training loss: 1.6705119609832764
Validation loss: 2.0666696975628533

Epoch: 5| Step: 3
Training loss: 1.8167355060577393
Validation loss: 2.0964849988619485

Epoch: 5| Step: 4
Training loss: 1.773402452468872
Validation loss: 2.0869144151608148

Epoch: 5| Step: 5
Training loss: 2.314753770828247
Validation loss: 2.0990851571162543

Epoch: 5| Step: 6
Training loss: 1.6355676651000977
Validation loss: 2.1292104522387185

Epoch: 5| Step: 7
Training loss: 2.603604555130005
Validation loss: 2.1391494224468866

Epoch: 5| Step: 8
Training loss: 2.9136881828308105
Validation loss: 2.104935109615326

Epoch: 5| Step: 9
Training loss: 1.6765350103378296
Validation loss: 2.106872022151947

Epoch: 5| Step: 10
Training loss: 2.651392936706543
Validation loss: 2.058261310060819

Epoch: 5| Step: 11
Training loss: 1.6865977048873901
Validation loss: 2.0480148742596307

Epoch: 19| Step: 0
Training loss: 1.857710599899292
Validation loss: 2.06303134560585

Epoch: 5| Step: 1
Training loss: 2.917208433151245
Validation loss: 2.069194639722506

Epoch: 5| Step: 2
Training loss: 2.091583013534546
Validation loss: 2.05489981174469

Epoch: 5| Step: 3
Training loss: 2.0411429405212402
Validation loss: 2.046878774960836

Epoch: 5| Step: 4
Training loss: 1.9959644079208374
Validation loss: 2.0476794888575873

Epoch: 5| Step: 5
Training loss: 2.335503339767456
Validation loss: 2.0514725893735886

Epoch: 5| Step: 6
Training loss: 1.7271324396133423
Validation loss: 2.0675242096185684

Epoch: 5| Step: 7
Training loss: 2.339972734451294
Validation loss: 2.0701941351095834

Epoch: 5| Step: 8
Training loss: 1.5654999017715454
Validation loss: 2.056901276111603

Epoch: 5| Step: 9
Training loss: 1.9161131381988525
Validation loss: 2.0658411930004754

Epoch: 5| Step: 10
Training loss: 1.9028383493423462
Validation loss: 2.0689824471871057

Epoch: 5| Step: 11
Training loss: 1.336970567703247
Validation loss: 2.0633400628964105

Epoch: 20| Step: 0
Training loss: 2.3767964839935303
Validation loss: 2.0383532494306564

Epoch: 5| Step: 1
Training loss: 2.381864547729492
Validation loss: 2.074744572242101

Epoch: 5| Step: 2
Training loss: 1.7259738445281982
Validation loss: 2.088784525791804

Epoch: 5| Step: 3
Training loss: 2.29496169090271
Validation loss: 2.111601695418358

Epoch: 5| Step: 4
Training loss: 1.850080132484436
Validation loss: 2.110047365228335

Epoch: 5| Step: 5
Training loss: 1.6844098567962646
Validation loss: 2.126792758703232

Epoch: 5| Step: 6
Training loss: 2.5888442993164062
Validation loss: 2.1015999813874564

Epoch: 5| Step: 7
Training loss: 1.590624451637268
Validation loss: 2.0969692170619965

Epoch: 5| Step: 8
Training loss: 1.701170563697815
Validation loss: 2.080638771255811

Epoch: 5| Step: 9
Training loss: 2.0961499214172363
Validation loss: 2.065617640813192

Epoch: 5| Step: 10
Training loss: 2.302277088165283
Validation loss: 2.031425212820371

Epoch: 5| Step: 11
Training loss: 2.450317859649658
Validation loss: 2.0505417635043464

Epoch: 21| Step: 0
Training loss: 1.7123734951019287
Validation loss: 2.0242568055788674

Epoch: 5| Step: 1
Training loss: 1.5076342821121216
Validation loss: 2.0405652771393457

Epoch: 5| Step: 2
Training loss: 1.6035293340682983
Validation loss: 2.0234326322873435

Epoch: 5| Step: 3
Training loss: 2.173377513885498
Validation loss: 2.036737938721975

Epoch: 5| Step: 4
Training loss: 2.6939523220062256
Validation loss: 2.0374507308006287

Epoch: 5| Step: 5
Training loss: 2.347482204437256
Validation loss: 2.041977842648824

Epoch: 5| Step: 6
Training loss: 2.142490863800049
Validation loss: 2.0565875271956124

Epoch: 5| Step: 7
Training loss: 2.0564122200012207
Validation loss: 2.0215280453364053

Epoch: 5| Step: 8
Training loss: 2.3568596839904785
Validation loss: 2.0432636439800262

Epoch: 5| Step: 9
Training loss: 1.7244904041290283
Validation loss: 2.0211793233950934

Epoch: 5| Step: 10
Training loss: 2.219791889190674
Validation loss: 2.0376732299725213

Epoch: 5| Step: 11
Training loss: 1.176286220550537
Validation loss: 2.0321895629167557

Epoch: 22| Step: 0
Training loss: 1.9584968090057373
Validation loss: 2.0475913484891257

Epoch: 5| Step: 1
Training loss: 2.6332828998565674
Validation loss: 2.035347804427147

Epoch: 5| Step: 2
Training loss: 1.8684371709823608
Validation loss: 2.019486447175344

Epoch: 5| Step: 3
Training loss: 2.008634090423584
Validation loss: 2.0585366586844125

Epoch: 5| Step: 4
Training loss: 1.9262720346450806
Validation loss: 2.0163855999708176

Epoch: 5| Step: 5
Training loss: 1.3678127527236938
Validation loss: 2.039241095383962

Epoch: 5| Step: 6
Training loss: 1.6671336889266968
Validation loss: 2.024256115158399

Epoch: 5| Step: 7
Training loss: 1.5935636758804321
Validation loss: 2.0372357169787088

Epoch: 5| Step: 8
Training loss: 2.735978364944458
Validation loss: 2.076807200908661

Epoch: 5| Step: 9
Training loss: 2.2508039474487305
Validation loss: 2.0645176072915397

Epoch: 5| Step: 10
Training loss: 2.09121036529541
Validation loss: 2.055200939377149

Epoch: 5| Step: 11
Training loss: 1.9658435583114624
Validation loss: 2.0259144008159637

Epoch: 23| Step: 0
Training loss: 1.9887815713882446
Validation loss: 2.0300669372081757

Epoch: 5| Step: 1
Training loss: 1.9162403345108032
Validation loss: 2.037442301710447

Epoch: 5| Step: 2
Training loss: 2.4120125770568848
Validation loss: 2.0360184709231057

Epoch: 5| Step: 3
Training loss: 1.7891075611114502
Validation loss: 2.0505461990833282

Epoch: 5| Step: 4
Training loss: 2.387484312057495
Validation loss: 2.0374973714351654

Epoch: 5| Step: 5
Training loss: 1.723902940750122
Validation loss: 2.0465151170889535

Epoch: 5| Step: 6
Training loss: 1.775217056274414
Validation loss: 2.011532634496689

Epoch: 5| Step: 7
Training loss: 2.530879497528076
Validation loss: 2.0439902395009995

Epoch: 5| Step: 8
Training loss: 1.9634244441986084
Validation loss: 2.0542545368274054

Epoch: 5| Step: 9
Training loss: 1.9936459064483643
Validation loss: 2.041608065366745

Epoch: 5| Step: 10
Training loss: 2.038090705871582
Validation loss: 2.031939576069514

Epoch: 5| Step: 11
Training loss: 0.9922935962677002
Validation loss: 2.037597512205442

Epoch: 24| Step: 0
Training loss: 1.8982775211334229
Validation loss: 2.047886610031128

Epoch: 5| Step: 1
Training loss: 2.263890027999878
Validation loss: 2.0202514876921973

Epoch: 5| Step: 2
Training loss: 1.9042317867279053
Validation loss: 1.9942822605371475

Epoch: 5| Step: 3
Training loss: 1.9582955837249756
Validation loss: 2.045769234498342

Epoch: 5| Step: 4
Training loss: 1.8285675048828125
Validation loss: 2.023910944660505

Epoch: 5| Step: 5
Training loss: 1.9356168508529663
Validation loss: 2.0671254694461823

Epoch: 5| Step: 6
Training loss: 3.0687203407287598
Validation loss: 2.0237054775158563

Epoch: 5| Step: 7
Training loss: 1.8939645290374756
Validation loss: 2.029163345694542

Epoch: 5| Step: 8
Training loss: 2.019061326980591
Validation loss: 2.0510531862576804

Epoch: 5| Step: 9
Training loss: 1.8137226104736328
Validation loss: 2.0434133211771646

Epoch: 5| Step: 10
Training loss: 1.818556785583496
Validation loss: 2.0449980994065604

Epoch: 5| Step: 11
Training loss: 2.7039613723754883
Validation loss: 2.0279160539309182

Epoch: 25| Step: 0
Training loss: 1.677915334701538
Validation loss: 2.029146984219551

Epoch: 5| Step: 1
Training loss: 2.3044867515563965
Validation loss: 2.0350036223729453

Epoch: 5| Step: 2
Training loss: 1.4013539552688599
Validation loss: 2.062563121318817

Epoch: 5| Step: 3
Training loss: 1.8454889059066772
Validation loss: 2.0604073951641717

Epoch: 5| Step: 4
Training loss: 2.2596652507781982
Validation loss: 2.0454158236583075

Epoch: 5| Step: 5
Training loss: 2.045055866241455
Validation loss: 2.0239457388718924

Epoch: 5| Step: 6
Training loss: 2.09035325050354
Validation loss: 2.057748168706894

Epoch: 5| Step: 7
Training loss: 1.8201701641082764
Validation loss: 2.03586878379186

Epoch: 5| Step: 8
Training loss: 2.173961639404297
Validation loss: 2.034966930747032

Epoch: 5| Step: 9
Training loss: 2.0482425689697266
Validation loss: 2.043302039305369

Epoch: 5| Step: 10
Training loss: 2.304978132247925
Validation loss: 2.024790436029434

Epoch: 5| Step: 11
Training loss: 1.6259629726409912
Validation loss: 2.030202180147171

Epoch: 26| Step: 0
Training loss: 2.668325662612915
Validation loss: 2.053798039754232

Epoch: 5| Step: 1
Training loss: 1.6932346820831299
Validation loss: 2.0398955742518106

Epoch: 5| Step: 2
Training loss: 2.1456284523010254
Validation loss: 2.0517704685529075

Epoch: 5| Step: 3
Training loss: 2.120857000350952
Validation loss: 2.0177375972270966

Epoch: 5| Step: 4
Training loss: 1.8805968761444092
Validation loss: 1.9991744309663773

Epoch: 5| Step: 5
Training loss: 2.3158516883850098
Validation loss: 2.0227465679248176

Epoch: 5| Step: 6
Training loss: 1.4964735507965088
Validation loss: 2.0114837090174356

Epoch: 5| Step: 7
Training loss: 1.6964633464813232
Validation loss: 2.028182198603948

Epoch: 5| Step: 8
Training loss: 2.0123095512390137
Validation loss: 2.016652231415113

Epoch: 5| Step: 9
Training loss: 1.8891422748565674
Validation loss: 2.022098109126091

Epoch: 5| Step: 10
Training loss: 1.9599050283432007
Validation loss: 2.0235218008359275

Epoch: 5| Step: 11
Training loss: 1.946589708328247
Validation loss: 2.058260882894198

Epoch: 27| Step: 0
Training loss: 1.7279523611068726
Validation loss: 2.017132043838501

Epoch: 5| Step: 1
Training loss: 1.9629123210906982
Validation loss: 2.0288935601711273

Epoch: 5| Step: 2
Training loss: 1.8482879400253296
Validation loss: 1.9894792437553406

Epoch: 5| Step: 3
Training loss: 1.659780740737915
Validation loss: 2.0584664146105447

Epoch: 5| Step: 4
Training loss: 1.75163996219635
Validation loss: 2.0597290893395743

Epoch: 5| Step: 5
Training loss: 2.744562864303589
Validation loss: 2.017084230979284

Epoch: 5| Step: 6
Training loss: 2.1851489543914795
Validation loss: 2.0683043946822486

Epoch: 5| Step: 7
Training loss: 2.41495418548584
Validation loss: 2.0832060426473618

Epoch: 5| Step: 8
Training loss: 1.7051336765289307
Validation loss: 2.045008589824041

Epoch: 5| Step: 9
Training loss: 2.123377799987793
Validation loss: 2.033663888772329

Epoch: 5| Step: 10
Training loss: 1.8373310565948486
Validation loss: 2.0597122659285865

Epoch: 5| Step: 11
Training loss: 2.5709567070007324
Validation loss: 2.0736858000357947

Epoch: 28| Step: 0
Training loss: 1.9056949615478516
Validation loss: 2.0290452937285104

Epoch: 5| Step: 1
Training loss: 2.0380146503448486
Validation loss: 2.033984899520874

Epoch: 5| Step: 2
Training loss: 1.871175765991211
Validation loss: 2.0441605548063913

Epoch: 5| Step: 3
Training loss: 2.3365044593811035
Validation loss: 2.04103555281957

Epoch: 5| Step: 4
Training loss: 1.4946420192718506
Validation loss: 2.017127126455307

Epoch: 5| Step: 5
Training loss: 2.0906291007995605
Validation loss: 2.032698313395182

Epoch: 5| Step: 6
Training loss: 1.9141197204589844
Validation loss: 2.017737547556559

Epoch: 5| Step: 7
Training loss: 2.444005012512207
Validation loss: 2.0228349020083747

Epoch: 5| Step: 8
Training loss: 2.5282464027404785
Validation loss: 2.028190111120542

Epoch: 5| Step: 9
Training loss: 1.6601152420043945
Validation loss: 2.0280524641275406

Epoch: 5| Step: 10
Training loss: 1.7509574890136719
Validation loss: 2.026988759636879

Epoch: 5| Step: 11
Training loss: 1.1625232696533203
Validation loss: 2.009890908996264

Epoch: 29| Step: 0
Training loss: 1.7827003002166748
Validation loss: 2.0225313554207482

Epoch: 5| Step: 1
Training loss: 1.712247610092163
Validation loss: 2.0223497301340103

Epoch: 5| Step: 2
Training loss: 1.9549968242645264
Validation loss: 2.008977790673574

Epoch: 5| Step: 3
Training loss: 1.9789451360702515
Validation loss: 2.0250741442044577

Epoch: 5| Step: 4
Training loss: 1.9795875549316406
Validation loss: 2.003524978955587

Epoch: 5| Step: 5
Training loss: 2.263172149658203
Validation loss: 2.000904470682144

Epoch: 5| Step: 6
Training loss: 2.411235809326172
Validation loss: 2.0403788636128106

Epoch: 5| Step: 7
Training loss: 1.4880468845367432
Validation loss: 2.0124364296595254

Epoch: 5| Step: 8
Training loss: 2.349675416946411
Validation loss: 2.019024506211281

Epoch: 5| Step: 9
Training loss: 1.4827650785446167
Validation loss: 2.053236370285352

Epoch: 5| Step: 10
Training loss: 2.4624195098876953
Validation loss: 2.031081606944402

Epoch: 5| Step: 11
Training loss: 1.6615370512008667
Validation loss: 2.0391999979813895

Epoch: 30| Step: 0
Training loss: 1.8372424840927124
Validation loss: 2.009634017944336

Epoch: 5| Step: 1
Training loss: 2.214407444000244
Validation loss: 2.0368170142173767

Epoch: 5| Step: 2
Training loss: 1.4097449779510498
Validation loss: 2.015549252430598

Epoch: 5| Step: 3
Training loss: 1.4140526056289673
Validation loss: 2.025786985953649

Epoch: 5| Step: 4
Training loss: 1.5564239025115967
Validation loss: 2.034497151772181

Epoch: 5| Step: 5
Training loss: 2.0883896350860596
Validation loss: 2.0098022520542145

Epoch: 5| Step: 6
Training loss: 2.097008228302002
Validation loss: 2.051343912879626

Epoch: 5| Step: 7
Training loss: 2.1128525733947754
Validation loss: 2.0217974334955215

Epoch: 5| Step: 8
Training loss: 2.4006760120391846
Validation loss: 2.0313320606946945

Epoch: 5| Step: 9
Training loss: 2.2790026664733887
Validation loss: 2.0185917019844055

Epoch: 5| Step: 10
Training loss: 2.3543248176574707
Validation loss: 2.0218209624290466

Epoch: 5| Step: 11
Training loss: 1.1879388093948364
Validation loss: 2.0259236792723336

Epoch: 31| Step: 0
Training loss: 1.7458066940307617
Validation loss: 2.0265618562698364

Epoch: 5| Step: 1
Training loss: 2.0275115966796875
Validation loss: 2.0051609873771667

Epoch: 5| Step: 2
Training loss: 2.6468684673309326
Validation loss: 2.0207101504007974

Epoch: 5| Step: 3
Training loss: 1.5879755020141602
Validation loss: 2.011196494102478

Epoch: 5| Step: 4
Training loss: 1.6071159839630127
Validation loss: 2.0215338865915933

Epoch: 5| Step: 5
Training loss: 1.8279306888580322
Validation loss: 2.0387375503778458

Epoch: 5| Step: 6
Training loss: 1.7812492847442627
Validation loss: 2.0268879185120263

Epoch: 5| Step: 7
Training loss: 2.073460817337036
Validation loss: 2.0450075020392737

Epoch: 5| Step: 8
Training loss: 2.002190113067627
Validation loss: 1.9784166912237804

Epoch: 5| Step: 9
Training loss: 2.381150007247925
Validation loss: 1.997157911459605

Epoch: 5| Step: 10
Training loss: 1.9632428884506226
Validation loss: 2.0293982326984406

Epoch: 5| Step: 11
Training loss: 2.2809767723083496
Validation loss: 2.028321256240209

Epoch: 32| Step: 0
Training loss: 2.3881194591522217
Validation loss: 2.032320390144984

Epoch: 5| Step: 1
Training loss: 1.9891220331192017
Validation loss: 2.0278537571430206

Epoch: 5| Step: 2
Training loss: 1.843374252319336
Validation loss: 1.9821397364139557

Epoch: 5| Step: 3
Training loss: 2.2217564582824707
Validation loss: 2.016405080755552

Epoch: 5| Step: 4
Training loss: 2.3918838500976562
Validation loss: 2.004884362220764

Epoch: 5| Step: 5
Training loss: 1.998215913772583
Validation loss: 2.0148157477378845

Epoch: 5| Step: 6
Training loss: 2.033965826034546
Validation loss: 1.9978545357783635

Epoch: 5| Step: 7
Training loss: 1.9718177318572998
Validation loss: 2.030880570411682

Epoch: 5| Step: 8
Training loss: 1.6839462518692017
Validation loss: 2.036694551507632

Epoch: 5| Step: 9
Training loss: 1.2570459842681885
Validation loss: 2.0306653579076133

Epoch: 5| Step: 10
Training loss: 1.9788873195648193
Validation loss: 1.9999680072069168

Epoch: 5| Step: 11
Training loss: 0.999845027923584
Validation loss: 1.9888118157784145

Epoch: 33| Step: 0
Training loss: 1.4011977910995483
Validation loss: 2.0123279243707657

Epoch: 5| Step: 1
Training loss: 1.6645501852035522
Validation loss: 2.034361854195595

Epoch: 5| Step: 2
Training loss: 2.2774016857147217
Validation loss: 2.0360365410645804

Epoch: 5| Step: 3
Training loss: 1.573988676071167
Validation loss: 2.051544100046158

Epoch: 5| Step: 4
Training loss: 2.477457046508789
Validation loss: 2.06307390332222

Epoch: 5| Step: 5
Training loss: 2.4631474018096924
Validation loss: 2.0787130842606225

Epoch: 5| Step: 6
Training loss: 1.4900743961334229
Validation loss: 2.0356070697307587

Epoch: 5| Step: 7
Training loss: 1.8840376138687134
Validation loss: 2.037362893422445

Epoch: 5| Step: 8
Training loss: 2.301297426223755
Validation loss: 2.0324174960454306

Epoch: 5| Step: 9
Training loss: 1.6873223781585693
Validation loss: 2.005357190966606

Epoch: 5| Step: 10
Training loss: 2.3550899028778076
Validation loss: 1.9778245041767757

Epoch: 5| Step: 11
Training loss: 1.2844246625900269
Validation loss: 2.005522052447001

Epoch: 34| Step: 0
Training loss: 2.514641523361206
Validation loss: 1.983020822207133

Epoch: 5| Step: 1
Training loss: 1.8365392684936523
Validation loss: 2.018378416697184

Epoch: 5| Step: 2
Training loss: 1.6725361347198486
Validation loss: 2.0132742623488107

Epoch: 5| Step: 3
Training loss: 1.9786221981048584
Validation loss: 2.0287652015686035

Epoch: 5| Step: 4
Training loss: 1.9218889474868774
Validation loss: 2.007559393843015

Epoch: 5| Step: 5
Training loss: 2.3996329307556152
Validation loss: 2.00468801955382

Epoch: 5| Step: 6
Training loss: 2.401106834411621
Validation loss: 2.0217546224594116

Epoch: 5| Step: 7
Training loss: 2.0967745780944824
Validation loss: 2.020581156015396

Epoch: 5| Step: 8
Training loss: 1.7519235610961914
Validation loss: 1.967232197523117

Epoch: 5| Step: 9
Training loss: 1.6447092294692993
Validation loss: 2.023889188965162

Epoch: 5| Step: 10
Training loss: 1.3232192993164062
Validation loss: 2.0214295585950217

Epoch: 5| Step: 11
Training loss: 2.4798152446746826
Validation loss: 2.013130004207293

Epoch: 35| Step: 0
Training loss: 2.329460859298706
Validation loss: 2.0125989665587745

Epoch: 5| Step: 1
Training loss: 1.816240668296814
Validation loss: 2.0030447592337928

Epoch: 5| Step: 2
Training loss: 1.6468889713287354
Validation loss: 2.029581308364868

Epoch: 5| Step: 3
Training loss: 2.0105793476104736
Validation loss: 2.0259768764177957

Epoch: 5| Step: 4
Training loss: 2.3370842933654785
Validation loss: 2.042811627189318

Epoch: 5| Step: 5
Training loss: 2.174051284790039
Validation loss: 2.0265379349390664

Epoch: 5| Step: 6
Training loss: 1.7739970684051514
Validation loss: 2.01446803410848

Epoch: 5| Step: 7
Training loss: 1.778130292892456
Validation loss: 2.007852256298065

Epoch: 5| Step: 8
Training loss: 2.3576481342315674
Validation loss: 2.0181705156962075

Epoch: 5| Step: 9
Training loss: 1.8362691402435303
Validation loss: 2.040777792533239

Epoch: 5| Step: 10
Training loss: 1.6652151346206665
Validation loss: 1.996415138244629

Epoch: 5| Step: 11
Training loss: 1.4652124643325806
Validation loss: 2.0443808833758035

Epoch: 36| Step: 0
Training loss: 2.011183500289917
Validation loss: 1.9969062954187393

Epoch: 5| Step: 1
Training loss: 1.791400671005249
Validation loss: 2.005306283632914

Epoch: 5| Step: 2
Training loss: 1.6822278499603271
Validation loss: 2.0218563228845596

Epoch: 5| Step: 3
Training loss: 2.9388949871063232
Validation loss: 2.021152580777804

Epoch: 5| Step: 4
Training loss: 1.737839698791504
Validation loss: 2.0152354488770166

Epoch: 5| Step: 5
Training loss: 2.1089138984680176
Validation loss: 2.0243162512779236

Epoch: 5| Step: 6
Training loss: 1.6005290746688843
Validation loss: 2.0338288644949594

Epoch: 5| Step: 7
Training loss: 2.2988860607147217
Validation loss: 2.0216224690278373

Epoch: 5| Step: 8
Training loss: 1.3316320180892944
Validation loss: 2.0238231966892877

Epoch: 5| Step: 9
Training loss: 1.9912782907485962
Validation loss: 1.9853546917438507

Epoch: 5| Step: 10
Training loss: 1.9523370265960693
Validation loss: 2.0031474828720093

Epoch: 5| Step: 11
Training loss: 2.2178869247436523
Validation loss: 1.9985509167114894

Epoch: 37| Step: 0
Training loss: 2.249452590942383
Validation loss: 2.0380620708068213

Epoch: 5| Step: 1
Training loss: 1.8323423862457275
Validation loss: 1.9946487148602803

Epoch: 5| Step: 2
Training loss: 1.3674370050430298
Validation loss: 2.022429327170054

Epoch: 5| Step: 3
Training loss: 1.6763637065887451
Validation loss: 2.0500415017207465

Epoch: 5| Step: 4
Training loss: 2.3695011138916016
Validation loss: 2.0170301347970963

Epoch: 5| Step: 5
Training loss: 1.627279281616211
Validation loss: 2.0159377654393515

Epoch: 5| Step: 6
Training loss: 2.1987388134002686
Validation loss: 2.0214070628086724

Epoch: 5| Step: 7
Training loss: 1.9813158512115479
Validation loss: 1.989519476890564

Epoch: 5| Step: 8
Training loss: 2.4447991847991943
Validation loss: 2.0131110896666846

Epoch: 5| Step: 9
Training loss: 1.6048457622528076
Validation loss: 1.988823726773262

Epoch: 5| Step: 10
Training loss: 1.94000244140625
Validation loss: 2.024016817410787

Epoch: 5| Step: 11
Training loss: 2.929030418395996
Validation loss: 2.023840233683586

Epoch: 38| Step: 0
Training loss: 2.043081045150757
Validation loss: 2.038785770535469

Epoch: 5| Step: 1
Training loss: 1.977434515953064
Validation loss: 2.0316134244203568

Epoch: 5| Step: 2
Training loss: 2.0888466835021973
Validation loss: 2.0168578773736954

Epoch: 5| Step: 3
Training loss: 2.1301493644714355
Validation loss: 2.0355184376239777

Epoch: 5| Step: 4
Training loss: 1.7283458709716797
Validation loss: 2.042889510591825

Epoch: 5| Step: 5
Training loss: 1.8331000804901123
Validation loss: 1.9934896975755692

Epoch: 5| Step: 6
Training loss: 2.2058568000793457
Validation loss: 2.066932886838913

Epoch: 5| Step: 7
Training loss: 1.788598656654358
Validation loss: 2.0209009498357773

Epoch: 5| Step: 8
Training loss: 1.9396655559539795
Validation loss: 1.9762481252352397

Epoch: 5| Step: 9
Training loss: 2.0068392753601074
Validation loss: 2.0225998560587564

Epoch: 5| Step: 10
Training loss: 2.0945825576782227
Validation loss: 2.0008153170347214

Epoch: 5| Step: 11
Training loss: 1.7626837491989136
Validation loss: 2.0001350740591683

Epoch: 39| Step: 0
Training loss: 1.490221381187439
Validation loss: 2.0527326414982476

Epoch: 5| Step: 1
Training loss: 2.4696197509765625
Validation loss: 2.071099524696668

Epoch: 5| Step: 2
Training loss: 1.6931571960449219
Validation loss: 2.1033465564250946

Epoch: 5| Step: 3
Training loss: 2.3331995010375977
Validation loss: 2.083088288704554

Epoch: 5| Step: 4
Training loss: 1.6218907833099365
Validation loss: 2.0781311442454657

Epoch: 5| Step: 5
Training loss: 1.7411553859710693
Validation loss: 2.0718921969334283

Epoch: 5| Step: 6
Training loss: 2.190171480178833
Validation loss: 2.0834191292524338

Epoch: 5| Step: 7
Training loss: 2.085526704788208
Validation loss: 2.0381103108326593

Epoch: 5| Step: 8
Training loss: 1.7133948802947998
Validation loss: 2.036214381456375

Epoch: 5| Step: 9
Training loss: 2.2235140800476074
Validation loss: 2.0072004844745

Epoch: 5| Step: 10
Training loss: 1.9895992279052734
Validation loss: 2.0391885886589685

Epoch: 5| Step: 11
Training loss: 2.114060878753662
Validation loss: 1.977324475844701

Epoch: 40| Step: 0
Training loss: 1.281883716583252
Validation loss: 2.0130015214284263

Epoch: 5| Step: 1
Training loss: 2.1810402870178223
Validation loss: 1.9996426701545715

Epoch: 5| Step: 2
Training loss: 2.2733936309814453
Validation loss: 2.027719333767891

Epoch: 5| Step: 3
Training loss: 1.480980634689331
Validation loss: 1.9994578907887142

Epoch: 5| Step: 4
Training loss: 2.0869672298431396
Validation loss: 2.008000910282135

Epoch: 5| Step: 5
Training loss: 2.0928471088409424
Validation loss: 2.025698979695638

Epoch: 5| Step: 6
Training loss: 1.6187009811401367
Validation loss: 2.032465452949206

Epoch: 5| Step: 7
Training loss: 2.1926846504211426
Validation loss: 2.009876931707064

Epoch: 5| Step: 8
Training loss: 1.7165491580963135
Validation loss: 2.0120345652103424

Epoch: 5| Step: 9
Training loss: 2.1434531211853027
Validation loss: 2.025409922003746

Epoch: 5| Step: 10
Training loss: 2.3757431507110596
Validation loss: 2.0127760668595633

Epoch: 5| Step: 11
Training loss: 1.4686360359191895
Validation loss: 2.03285081187884

Epoch: 41| Step: 0
Training loss: 1.6992404460906982
Validation loss: 1.998166526357333

Epoch: 5| Step: 1
Training loss: 1.685914397239685
Validation loss: 2.0183281352122626

Epoch: 5| Step: 2
Training loss: 1.9109185934066772
Validation loss: 2.0078280245264373

Epoch: 5| Step: 3
Training loss: 2.3319168090820312
Validation loss: 1.9879895100990932

Epoch: 5| Step: 4
Training loss: 2.1176440715789795
Validation loss: 2.0507213721672692

Epoch: 5| Step: 5
Training loss: 1.5979201793670654
Validation loss: 2.009913980960846

Epoch: 5| Step: 6
Training loss: 2.196551561355591
Validation loss: 2.0001658697923026

Epoch: 5| Step: 7
Training loss: 1.8820171356201172
Validation loss: 2.020047520597776

Epoch: 5| Step: 8
Training loss: 1.946557641029358
Validation loss: 2.0104983846346536

Epoch: 5| Step: 9
Training loss: 1.483361005783081
Validation loss: 1.980366696914037

Epoch: 5| Step: 10
Training loss: 2.2955784797668457
Validation loss: 1.9899390290180843

Epoch: 5| Step: 11
Training loss: 2.448035717010498
Validation loss: 2.0231425563494363

Epoch: 42| Step: 0
Training loss: 2.0739073753356934
Validation loss: 2.0340885718663535

Epoch: 5| Step: 1
Training loss: 1.9242206811904907
Validation loss: 2.0279859801133475

Epoch: 5| Step: 2
Training loss: 2.139495611190796
Validation loss: 2.040163735548655

Epoch: 5| Step: 3
Training loss: 1.5490615367889404
Validation loss: 2.0197338362534842

Epoch: 5| Step: 4
Training loss: 1.769195318222046
Validation loss: 2.0318424503008523

Epoch: 5| Step: 5
Training loss: 1.6298351287841797
Validation loss: 2.049303099513054

Epoch: 5| Step: 6
Training loss: 2.3475143909454346
Validation loss: 2.0481067995230355

Epoch: 5| Step: 7
Training loss: 1.8987972736358643
Validation loss: 2.0447944601376853

Epoch: 5| Step: 8
Training loss: 1.5965626239776611
Validation loss: 1.996486594279607

Epoch: 5| Step: 9
Training loss: 1.7792333364486694
Validation loss: 2.032477150360743

Epoch: 5| Step: 10
Training loss: 2.0658392906188965
Validation loss: 2.0212051769097648

Epoch: 5| Step: 11
Training loss: 3.8907508850097656
Validation loss: 2.0129103710254035

Epoch: 43| Step: 0
Training loss: 1.7113466262817383
Validation loss: 1.9907216827074687

Epoch: 5| Step: 1
Training loss: 1.6002063751220703
Validation loss: 1.9864200452963512

Epoch: 5| Step: 2
Training loss: 2.5243287086486816
Validation loss: 2.0452960282564163

Epoch: 5| Step: 3
Training loss: 2.0545248985290527
Validation loss: 2.0240624646345773

Epoch: 5| Step: 4
Training loss: 1.710801124572754
Validation loss: 2.0503322581450143

Epoch: 5| Step: 5
Training loss: 2.031970739364624
Validation loss: 2.0560801972945533

Epoch: 5| Step: 6
Training loss: 1.6534332036972046
Validation loss: 2.0074773530165353

Epoch: 5| Step: 7
Training loss: 1.7828766107559204
Validation loss: 2.0242697099844613

Epoch: 5| Step: 8
Training loss: 1.7096771001815796
Validation loss: 2.032869910200437

Epoch: 5| Step: 9
Training loss: 2.2136788368225098
Validation loss: 2.0452405214309692

Epoch: 5| Step: 10
Training loss: 2.1133384704589844
Validation loss: 1.9896255433559418

Epoch: 5| Step: 11
Training loss: 2.0823802947998047
Validation loss: 2.0107265760501227

Epoch: 44| Step: 0
Training loss: 1.8045780658721924
Validation loss: 2.062039544185003

Epoch: 5| Step: 1
Training loss: 1.800143837928772
Validation loss: 2.0563398400942483

Epoch: 5| Step: 2
Training loss: 1.4945827722549438
Validation loss: 2.0728860398133597

Epoch: 5| Step: 3
Training loss: 1.7873256206512451
Validation loss: 2.080536504586538

Epoch: 5| Step: 4
Training loss: 2.061340570449829
Validation loss: 2.0633331487576165

Epoch: 5| Step: 5
Training loss: 1.580986499786377
Validation loss: 2.041811724503835

Epoch: 5| Step: 6
Training loss: 2.081738233566284
Validation loss: 2.0533870855967202

Epoch: 5| Step: 7
Training loss: 2.0118560791015625
Validation loss: 2.0318853755791983

Epoch: 5| Step: 8
Training loss: 2.403324842453003
Validation loss: 2.010514403382937

Epoch: 5| Step: 9
Training loss: 2.0805275440216064
Validation loss: 1.9830728471279144

Epoch: 5| Step: 10
Training loss: 2.1981472969055176
Validation loss: 2.0003773172696433

Epoch: 5| Step: 11
Training loss: 2.567978858947754
Validation loss: 2.0015733341375985

Epoch: 45| Step: 0
Training loss: 1.5907856225967407
Validation loss: 1.9996628761291504

Epoch: 5| Step: 1
Training loss: 2.2277863025665283
Validation loss: 2.007153814037641

Epoch: 5| Step: 2
Training loss: 2.0542495250701904
Validation loss: 2.0228132605552673

Epoch: 5| Step: 3
Training loss: 1.9420959949493408
Validation loss: 2.004272679487864

Epoch: 5| Step: 4
Training loss: 2.137880325317383
Validation loss: 2.024020160237948

Epoch: 5| Step: 5
Training loss: 1.8390185832977295
Validation loss: 2.0069719851017

Epoch: 5| Step: 6
Training loss: 1.938206672668457
Validation loss: 2.016297241051992

Epoch: 5| Step: 7
Training loss: 1.7871358394622803
Validation loss: 2.02437690893809

Epoch: 5| Step: 8
Training loss: 1.879502534866333
Validation loss: 2.0191351224978766

Epoch: 5| Step: 9
Training loss: 2.185978412628174
Validation loss: 2.010673845807711

Epoch: 5| Step: 10
Training loss: 1.5219430923461914
Validation loss: 2.0023235778013864

Epoch: 5| Step: 11
Training loss: 2.623244285583496
Validation loss: 2.0344959994157157

Epoch: 46| Step: 0
Training loss: 1.9362598657608032
Validation loss: 2.034360075990359

Epoch: 5| Step: 1
Training loss: 1.7384731769561768
Validation loss: 1.9995415310064952

Epoch: 5| Step: 2
Training loss: 1.7801685333251953
Validation loss: 2.0371585537989936

Epoch: 5| Step: 3
Training loss: 2.524768829345703
Validation loss: 2.013151635726293

Epoch: 5| Step: 4
Training loss: 2.048905372619629
Validation loss: 2.0232494920492172

Epoch: 5| Step: 5
Training loss: 1.381461501121521
Validation loss: 2.0333989510933557

Epoch: 5| Step: 6
Training loss: 1.6543352603912354
Validation loss: 2.0348271975914636

Epoch: 5| Step: 7
Training loss: 2.322915554046631
Validation loss: 2.031467710932096

Epoch: 5| Step: 8
Training loss: 1.6946866512298584
Validation loss: 2.0731429060300193

Epoch: 5| Step: 9
Training loss: 1.3336496353149414
Validation loss: 2.019976889093717

Epoch: 5| Step: 10
Training loss: 1.9657773971557617
Validation loss: 2.0315970132748284

Epoch: 5| Step: 11
Training loss: 3.1578478813171387
Validation loss: 2.020287036895752

Epoch: 47| Step: 0
Training loss: 1.938250184059143
Validation loss: 2.022538567582766

Epoch: 5| Step: 1
Training loss: 1.7489173412322998
Validation loss: 2.0178544024626413

Epoch: 5| Step: 2
Training loss: 1.867498755455017
Validation loss: 2.005053773522377

Epoch: 5| Step: 3
Training loss: 1.8600679636001587
Validation loss: 2.0230137507120767

Epoch: 5| Step: 4
Training loss: 2.1521427631378174
Validation loss: 2.04121666153272

Epoch: 5| Step: 5
Training loss: 2.2086880207061768
Validation loss: 2.0693179666996

Epoch: 5| Step: 6
Training loss: 2.1858270168304443
Validation loss: 2.0117564648389816

Epoch: 5| Step: 7
Training loss: 1.617370843887329
Validation loss: 2.0058131714661918

Epoch: 5| Step: 8
Training loss: 1.8894176483154297
Validation loss: 2.03839410841465

Epoch: 5| Step: 9
Training loss: 1.4065462350845337
Validation loss: 2.028613189856211

Epoch: 5| Step: 10
Training loss: 2.107680559158325
Validation loss: 1.9949702471494675

Epoch: 5| Step: 11
Training loss: 2.8410098552703857
Validation loss: 1.971216157078743

Epoch: 48| Step: 0
Training loss: 1.5942076444625854
Validation loss: 2.0338597695032754

Epoch: 5| Step: 1
Training loss: 1.952527642250061
Validation loss: 2.0418443282445273

Epoch: 5| Step: 2
Training loss: 1.7377277612686157
Validation loss: 2.0073498437801995

Epoch: 5| Step: 3
Training loss: 3.197002410888672
Validation loss: 2.0568849444389343

Epoch: 5| Step: 4
Training loss: 2.0455126762390137
Validation loss: 2.0288335730632148

Epoch: 5| Step: 5
Training loss: 1.9702026844024658
Validation loss: 1.983646348118782

Epoch: 5| Step: 6
Training loss: 1.6986545324325562
Validation loss: 2.005550061662992

Epoch: 5| Step: 7
Training loss: 1.1564531326293945
Validation loss: 2.0424706041812897

Epoch: 5| Step: 8
Training loss: 1.9131892919540405
Validation loss: 2.0372211188077927

Epoch: 5| Step: 9
Training loss: 1.8633205890655518
Validation loss: 1.9893935521443684

Epoch: 5| Step: 10
Training loss: 1.5009791851043701
Validation loss: 2.006829167405764

Epoch: 5| Step: 11
Training loss: 2.4458155632019043
Validation loss: 2.0197738061348596

Epoch: 49| Step: 0
Training loss: 1.9916101694107056
Validation loss: 2.014811635017395

Epoch: 5| Step: 1
Training loss: 2.0069174766540527
Validation loss: 1.990083947777748

Epoch: 5| Step: 2
Training loss: 2.3378655910491943
Validation loss: 2.029564027984937

Epoch: 5| Step: 3
Training loss: 1.6795917749404907
Validation loss: 2.017771845062574

Epoch: 5| Step: 4
Training loss: 1.9952924251556396
Validation loss: 2.0320187161366143

Epoch: 5| Step: 5
Training loss: 1.611161231994629
Validation loss: 1.9903010775645573

Epoch: 5| Step: 6
Training loss: 1.9770243167877197
Validation loss: 1.9963242014249165

Epoch: 5| Step: 7
Training loss: 1.5147411823272705
Validation loss: 1.9862172255913417

Epoch: 5| Step: 8
Training loss: 1.9465688467025757
Validation loss: 2.031611571709315

Epoch: 5| Step: 9
Training loss: 2.127095937728882
Validation loss: 2.0050955017407737

Epoch: 5| Step: 10
Training loss: 1.4500837326049805
Validation loss: 2.0278284549713135

Epoch: 5| Step: 11
Training loss: 1.062779426574707
Validation loss: 2.0194241354862847

Epoch: 50| Step: 0
Training loss: 2.001281261444092
Validation loss: 2.045105348030726

Epoch: 5| Step: 1
Training loss: 2.2223732471466064
Validation loss: 2.023936534921328

Epoch: 5| Step: 2
Training loss: 1.5824962854385376
Validation loss: 2.014468491077423

Epoch: 5| Step: 3
Training loss: 1.3965919017791748
Validation loss: 1.993221456805865

Epoch: 5| Step: 4
Training loss: 2.050297498703003
Validation loss: 1.9879078219334285

Epoch: 5| Step: 5
Training loss: 1.9363682270050049
Validation loss: 2.024669269720713

Epoch: 5| Step: 6
Training loss: 2.146717071533203
Validation loss: 1.9930115391810734

Epoch: 5| Step: 7
Training loss: 2.0714499950408936
Validation loss: 2.0275790890057883

Epoch: 5| Step: 8
Training loss: 1.8281877040863037
Validation loss: 2.033358027537664

Epoch: 5| Step: 9
Training loss: 1.748938798904419
Validation loss: 2.046696146329244

Epoch: 5| Step: 10
Training loss: 2.0457205772399902
Validation loss: 2.033169354001681

Epoch: 5| Step: 11
Training loss: 1.079733967781067
Validation loss: 2.012618934114774

Epoch: 51| Step: 0
Training loss: 1.7649738788604736
Validation loss: 1.9982614417870839

Epoch: 5| Step: 1
Training loss: 2.566333055496216
Validation loss: 2.004060303171476

Epoch: 5| Step: 2
Training loss: 1.7155892848968506
Validation loss: 1.9874341388543446

Epoch: 5| Step: 3
Training loss: 2.1094789505004883
Validation loss: 2.0219482829173407

Epoch: 5| Step: 4
Training loss: 1.926719307899475
Validation loss: 1.9814759194850922

Epoch: 5| Step: 5
Training loss: 1.753832459449768
Validation loss: 1.9889586716890335

Epoch: 5| Step: 6
Training loss: 1.4243217706680298
Validation loss: 1.9542097995678585

Epoch: 5| Step: 7
Training loss: 1.998929738998413
Validation loss: 2.0150259683529534

Epoch: 5| Step: 8
Training loss: 2.05525541305542
Validation loss: 1.9988621473312378

Epoch: 5| Step: 9
Training loss: 1.7817974090576172
Validation loss: 1.9967516014973323

Epoch: 5| Step: 10
Training loss: 1.684260606765747
Validation loss: 1.9685345143079758

Epoch: 5| Step: 11
Training loss: 0.9492623805999756
Validation loss: 2.005341420571009

Epoch: 52| Step: 0
Training loss: 1.5204522609710693
Validation loss: 2.0414086977640786

Epoch: 5| Step: 1
Training loss: 1.929978609085083
Validation loss: 2.0073900520801544

Epoch: 5| Step: 2
Training loss: 1.9698063135147095
Validation loss: 2.0297874808311462

Epoch: 5| Step: 3
Training loss: 2.006619930267334
Validation loss: 2.0181872149308524

Epoch: 5| Step: 4
Training loss: 2.1606452465057373
Validation loss: 2.0380533585945764

Epoch: 5| Step: 5
Training loss: 1.4966058731079102
Validation loss: 2.0120690564314523

Epoch: 5| Step: 6
Training loss: 2.281144380569458
Validation loss: 1.9851750681797664

Epoch: 5| Step: 7
Training loss: 2.29469633102417
Validation loss: 2.035969610015551

Epoch: 5| Step: 8
Training loss: 1.1494404077529907
Validation loss: 2.0003871619701385

Epoch: 5| Step: 9
Training loss: 2.452033519744873
Validation loss: 2.034884532292684

Epoch: 5| Step: 10
Training loss: 1.7661393880844116
Validation loss: 2.0175918539365134

Epoch: 5| Step: 11
Training loss: 0.849364161491394
Validation loss: 2.017920106649399

Epoch: 53| Step: 0
Training loss: 1.5107934474945068
Validation loss: 2.010540430744489

Epoch: 5| Step: 1
Training loss: 2.259463310241699
Validation loss: 2.0294853200515113

Epoch: 5| Step: 2
Training loss: 1.8432462215423584
Validation loss: 2.0228672325611115

Epoch: 5| Step: 3
Training loss: 1.7159219980239868
Validation loss: 1.9871033231417339

Epoch: 5| Step: 4
Training loss: 1.7045189142227173
Validation loss: 2.032987510164579

Epoch: 5| Step: 5
Training loss: 2.206864595413208
Validation loss: 2.0261566042900085

Epoch: 5| Step: 6
Training loss: 1.9473403692245483
Validation loss: 2.0495129078626633

Epoch: 5| Step: 7
Training loss: 2.3783862590789795
Validation loss: 2.018425221244494

Epoch: 5| Step: 8
Training loss: 1.558733344078064
Validation loss: 2.0556901146968207

Epoch: 5| Step: 9
Training loss: 1.8757137060165405
Validation loss: 2.0138665636380515

Epoch: 5| Step: 10
Training loss: 1.7508649826049805
Validation loss: 2.0047364185253778

Epoch: 5| Step: 11
Training loss: 2.0284948348999023
Validation loss: 2.0303543309370675

Epoch: 54| Step: 0
Training loss: 1.4799200296401978
Validation loss: 2.0161083340644836

Epoch: 5| Step: 1
Training loss: 1.7841018438339233
Validation loss: 1.9927060157060623

Epoch: 5| Step: 2
Training loss: 1.9105123281478882
Validation loss: 2.0376384556293488

Epoch: 5| Step: 3
Training loss: 1.7993106842041016
Validation loss: 2.0283347964286804

Epoch: 5| Step: 4
Training loss: 2.0335044860839844
Validation loss: 2.032559961080551

Epoch: 5| Step: 5
Training loss: 1.606713891029358
Validation loss: 1.9869913111130397

Epoch: 5| Step: 6
Training loss: 2.2065112590789795
Validation loss: 2.043996294339498

Epoch: 5| Step: 7
Training loss: 1.955430269241333
Validation loss: 2.0413442850112915

Epoch: 5| Step: 8
Training loss: 1.7679433822631836
Validation loss: 2.0079897244771323

Epoch: 5| Step: 9
Training loss: 1.9204633235931396
Validation loss: 1.9951643000046413

Epoch: 5| Step: 10
Training loss: 1.967002511024475
Validation loss: 2.0292320450146994

Epoch: 5| Step: 11
Training loss: 2.3428823947906494
Validation loss: 2.0377113223075867

Epoch: 55| Step: 0
Training loss: 1.5074858665466309
Validation loss: 2.007894446452459

Epoch: 5| Step: 1
Training loss: 2.3459548950195312
Validation loss: 2.0435567051172256

Epoch: 5| Step: 2
Training loss: 1.9200494289398193
Validation loss: 1.9717338532209396

Epoch: 5| Step: 3
Training loss: 1.321354627609253
Validation loss: 2.031213785211245

Epoch: 5| Step: 4
Training loss: 2.8257174491882324
Validation loss: 2.0165148824453354

Epoch: 5| Step: 5
Training loss: 2.1370582580566406
Validation loss: 1.9892780830462773

Epoch: 5| Step: 6
Training loss: 2.1013596057891846
Validation loss: 2.0328522523244223

Epoch: 5| Step: 7
Training loss: 1.1918607950210571
Validation loss: 2.012328411142031

Epoch: 5| Step: 8
Training loss: 2.2763805389404297
Validation loss: 2.00908916691939

Epoch: 5| Step: 9
Training loss: 1.7874736785888672
Validation loss: 1.991938292980194

Epoch: 5| Step: 10
Training loss: 1.3418575525283813
Validation loss: 2.0159053405125937

Epoch: 5| Step: 11
Training loss: 0.508182168006897
Validation loss: 2.0588461558024087

Epoch: 56| Step: 0
Training loss: 1.6282646656036377
Validation loss: 2.011267736554146

Epoch: 5| Step: 1
Training loss: 1.6548410654067993
Validation loss: 2.035863141218821

Epoch: 5| Step: 2
Training loss: 1.9321563243865967
Validation loss: 1.984961450099945

Epoch: 5| Step: 3
Training loss: 2.1633784770965576
Validation loss: 2.057564541697502

Epoch: 5| Step: 4
Training loss: 1.6389939785003662
Validation loss: 1.9923878113428752

Epoch: 5| Step: 5
Training loss: 2.0835375785827637
Validation loss: 2.0406512767076492

Epoch: 5| Step: 6
Training loss: 1.8552064895629883
Validation loss: 2.0126135696967444

Epoch: 5| Step: 7
Training loss: 1.929302453994751
Validation loss: 2.011422942082087

Epoch: 5| Step: 8
Training loss: 1.3635706901550293
Validation loss: 2.0343596935272217

Epoch: 5| Step: 9
Training loss: 2.132376194000244
Validation loss: 2.0274386753638587

Epoch: 5| Step: 10
Training loss: 2.1783359050750732
Validation loss: 2.056467274824778

Epoch: 5| Step: 11
Training loss: 1.6095449924468994
Validation loss: 2.0124250948429108

Epoch: 57| Step: 0
Training loss: 2.07460355758667
Validation loss: 2.005133698383967

Epoch: 5| Step: 1
Training loss: 1.587615966796875
Validation loss: 2.0265795588493347

Epoch: 5| Step: 2
Training loss: 1.8176307678222656
Validation loss: 1.9933095375696819

Epoch: 5| Step: 3
Training loss: 1.5563914775848389
Validation loss: 2.0549552887678146

Epoch: 5| Step: 4
Training loss: 2.1491947174072266
Validation loss: 2.030124768614769

Epoch: 5| Step: 5
Training loss: 2.5536952018737793
Validation loss: 2.055530364314715

Epoch: 5| Step: 6
Training loss: 2.051997661590576
Validation loss: 2.041610817114512

Epoch: 5| Step: 7
Training loss: 1.8000761270523071
Validation loss: 2.008515556653341

Epoch: 5| Step: 8
Training loss: 1.698258399963379
Validation loss: 2.0192785958449044

Epoch: 5| Step: 9
Training loss: 1.9060842990875244
Validation loss: 2.005509947737058

Epoch: 5| Step: 10
Training loss: 1.4348232746124268
Validation loss: 2.008264124393463

Epoch: 5| Step: 11
Training loss: 1.8459810018539429
Validation loss: 2.012225642800331

Epoch: 58| Step: 0
Training loss: 2.105848550796509
Validation loss: 2.04742102821668

Epoch: 5| Step: 1
Training loss: 2.1995224952697754
Validation loss: 2.016847918430964

Epoch: 5| Step: 2
Training loss: 1.8615646362304688
Validation loss: 2.0212321331103644

Epoch: 5| Step: 3
Training loss: 1.586010217666626
Validation loss: 2.0313673118750253

Epoch: 5| Step: 4
Training loss: 1.8919013738632202
Validation loss: 2.035589039325714

Epoch: 5| Step: 5
Training loss: 1.9048471450805664
Validation loss: 2.0398663183053336

Epoch: 5| Step: 6
Training loss: 1.9534953832626343
Validation loss: 1.9933254619439442

Epoch: 5| Step: 7
Training loss: 1.6328681707382202
Validation loss: 1.9977429409821827

Epoch: 5| Step: 8
Training loss: 1.7540241479873657
Validation loss: 2.012350618839264

Epoch: 5| Step: 9
Training loss: 1.9389171600341797
Validation loss: 2.039159635702769

Epoch: 5| Step: 10
Training loss: 1.6144813299179077
Validation loss: 1.967122529943784

Epoch: 5| Step: 11
Training loss: 1.4886245727539062
Validation loss: 1.9855505128701527

Epoch: 59| Step: 0
Training loss: 1.7103217840194702
Validation loss: 2.0202424377202988

Epoch: 5| Step: 1
Training loss: 1.995679497718811
Validation loss: 2.0261606921752295

Epoch: 5| Step: 2
Training loss: 1.8253624439239502
Validation loss: 2.0185973147551217

Epoch: 5| Step: 3
Training loss: 2.075199842453003
Validation loss: 1.9807861198981602

Epoch: 5| Step: 4
Training loss: 1.5443063974380493
Validation loss: 2.004447653889656

Epoch: 5| Step: 5
Training loss: 1.7923873662948608
Validation loss: 1.9942310998837154

Epoch: 5| Step: 6
Training loss: 1.943579912185669
Validation loss: 2.004734685023626

Epoch: 5| Step: 7
Training loss: 2.10257887840271
Validation loss: 2.000628481308619

Epoch: 5| Step: 8
Training loss: 1.287590742111206
Validation loss: 2.0085362046957016

Epoch: 5| Step: 9
Training loss: 1.7603895664215088
Validation loss: 1.9907764544089634

Epoch: 5| Step: 10
Training loss: 2.2002289295196533
Validation loss: 2.0381982028484344

Epoch: 5| Step: 11
Training loss: 2.7844018936157227
Validation loss: 2.0238121300935745

Epoch: 60| Step: 0
Training loss: 1.9836734533309937
Validation loss: 2.012761359413465

Epoch: 5| Step: 1
Training loss: 1.346096158027649
Validation loss: 2.0169609238704047

Epoch: 5| Step: 2
Training loss: 1.6695754528045654
Validation loss: 1.9810361564159393

Epoch: 5| Step: 3
Training loss: 1.5349143743515015
Validation loss: 2.0174738466739655

Epoch: 5| Step: 4
Training loss: 2.101862907409668
Validation loss: 2.026696821053823

Epoch: 5| Step: 5
Training loss: 1.6930339336395264
Validation loss: 2.0120100478331246

Epoch: 5| Step: 6
Training loss: 1.958060622215271
Validation loss: 2.0241645773251853

Epoch: 5| Step: 7
Training loss: 2.0352325439453125
Validation loss: 2.0423659284909568

Epoch: 5| Step: 8
Training loss: 1.8150599002838135
Validation loss: 1.969809611638387

Epoch: 5| Step: 9
Training loss: 1.59920334815979
Validation loss: 1.99441097676754

Epoch: 5| Step: 10
Training loss: 2.440568447113037
Validation loss: 2.0250849028428397

Epoch: 5| Step: 11
Training loss: 1.9089781045913696
Validation loss: 2.0413288126389184

Epoch: 61| Step: 0
Training loss: 1.5701946020126343
Validation loss: 1.9931575109561284

Epoch: 5| Step: 1
Training loss: 1.285037875175476
Validation loss: 1.997394507129987

Epoch: 5| Step: 2
Training loss: 1.9664833545684814
Validation loss: 2.0287378480037055

Epoch: 5| Step: 3
Training loss: 2.075636625289917
Validation loss: 2.0150266687075296

Epoch: 5| Step: 4
Training loss: 2.487488031387329
Validation loss: 1.9957954585552216

Epoch: 5| Step: 5
Training loss: 2.0878899097442627
Validation loss: 2.014954303701719

Epoch: 5| Step: 6
Training loss: 1.698988676071167
Validation loss: 2.0351397146781287

Epoch: 5| Step: 7
Training loss: 1.625889539718628
Validation loss: 2.028172552585602

Epoch: 5| Step: 8
Training loss: 2.002554416656494
Validation loss: 2.013618657986323

Epoch: 5| Step: 9
Training loss: 1.792549729347229
Validation loss: 1.9947025428215663

Epoch: 5| Step: 10
Training loss: 1.4843943119049072
Validation loss: 1.9961014439662297

Epoch: 5| Step: 11
Training loss: 2.389416217803955
Validation loss: 2.047625164190928

Epoch: 62| Step: 0
Training loss: 1.589381456375122
Validation loss: 1.9812533507744472

Epoch: 5| Step: 1
Training loss: 1.6064974069595337
Validation loss: 2.0764943112929664

Epoch: 5| Step: 2
Training loss: 1.7304779291152954
Validation loss: 2.019774412115415

Epoch: 5| Step: 3
Training loss: 1.7081722021102905
Validation loss: 2.041948914527893

Epoch: 5| Step: 4
Training loss: 1.667980432510376
Validation loss: 2.021121213833491

Epoch: 5| Step: 5
Training loss: 1.6015520095825195
Validation loss: 1.9642735520998638

Epoch: 5| Step: 6
Training loss: 1.988207459449768
Validation loss: 2.0120024730761847

Epoch: 5| Step: 7
Training loss: 2.3247628211975098
Validation loss: 1.9957584291696548

Epoch: 5| Step: 8
Training loss: 2.177293300628662
Validation loss: 2.0321106712023416

Epoch: 5| Step: 9
Training loss: 1.490995168685913
Validation loss: 2.0086296250422797

Epoch: 5| Step: 10
Training loss: 2.0212972164154053
Validation loss: 2.0124188562234244

Epoch: 5| Step: 11
Training loss: 2.3990609645843506
Validation loss: 1.9747018714745839

Epoch: 63| Step: 0
Training loss: 2.502722978591919
Validation loss: 2.032053664326668

Epoch: 5| Step: 1
Training loss: 1.2007347345352173
Validation loss: 1.9936029762029648

Epoch: 5| Step: 2
Training loss: 2.096254348754883
Validation loss: 2.009295334418615

Epoch: 5| Step: 3
Training loss: 2.5632240772247314
Validation loss: 1.9750643769900005

Epoch: 5| Step: 4
Training loss: 2.1221134662628174
Validation loss: 2.0014494905869165

Epoch: 5| Step: 5
Training loss: 1.4797329902648926
Validation loss: 2.014804740746816

Epoch: 5| Step: 6
Training loss: 1.6371700763702393
Validation loss: 2.0311719328165054

Epoch: 5| Step: 7
Training loss: 1.8005449771881104
Validation loss: 2.007337694366773

Epoch: 5| Step: 8
Training loss: 1.9625164270401
Validation loss: 2.0441316664218903

Epoch: 5| Step: 9
Training loss: 1.4796936511993408
Validation loss: 2.02481742699941

Epoch: 5| Step: 10
Training loss: 1.7908769845962524
Validation loss: 1.9807212799787521

Epoch: 5| Step: 11
Training loss: 1.3212082386016846
Validation loss: 2.0433919529120126

Epoch: 64| Step: 0
Training loss: 1.3102915287017822
Validation loss: 2.0212990740935006

Epoch: 5| Step: 1
Training loss: 1.3610148429870605
Validation loss: 2.020568827788035

Epoch: 5| Step: 2
Training loss: 1.7986938953399658
Validation loss: 2.0355392595132193

Epoch: 5| Step: 3
Training loss: 2.028132677078247
Validation loss: 2.0210283945004144

Epoch: 5| Step: 4
Training loss: 1.6487315893173218
Validation loss: 2.025215730071068

Epoch: 5| Step: 5
Training loss: 2.014341115951538
Validation loss: 2.0675620337327323

Epoch: 5| Step: 6
Training loss: 2.5699031352996826
Validation loss: 2.0085896452267966

Epoch: 5| Step: 7
Training loss: 1.8565318584442139
Validation loss: 2.021122102936109

Epoch: 5| Step: 8
Training loss: 1.8451846837997437
Validation loss: 2.0087896287441254

Epoch: 5| Step: 9
Training loss: 2.04514479637146
Validation loss: 1.9945007214943569

Epoch: 5| Step: 10
Training loss: 1.8523685932159424
Validation loss: 1.9525833676258724

Epoch: 5| Step: 11
Training loss: 1.7422529458999634
Validation loss: 1.9896651456753414

Epoch: 65| Step: 0
Training loss: 2.3993642330169678
Validation loss: 1.9805265019337337

Epoch: 5| Step: 1
Training loss: 1.661939263343811
Validation loss: 2.0108077079057693

Epoch: 5| Step: 2
Training loss: 1.573377013206482
Validation loss: 2.0010791569948196

Epoch: 5| Step: 3
Training loss: 2.0939013957977295
Validation loss: 2.00862609843413

Epoch: 5| Step: 4
Training loss: 1.255070447921753
Validation loss: 2.0079083989063897

Epoch: 5| Step: 5
Training loss: 2.1726677417755127
Validation loss: 2.012083267172178

Epoch: 5| Step: 6
Training loss: 2.1466662883758545
Validation loss: 2.0153718292713165

Epoch: 5| Step: 7
Training loss: 1.777986764907837
Validation loss: 2.0418651153643927

Epoch: 5| Step: 8
Training loss: 1.4030311107635498
Validation loss: 2.0500214248895645

Epoch: 5| Step: 9
Training loss: 2.1700377464294434
Validation loss: 2.005987286567688

Epoch: 5| Step: 10
Training loss: 1.5141172409057617
Validation loss: 2.0512956182161965

Epoch: 5| Step: 11
Training loss: 1.7421226501464844
Validation loss: 2.01957676311334

Epoch: 66| Step: 0
Training loss: 1.7582862377166748
Validation loss: 2.003952071070671

Epoch: 5| Step: 1
Training loss: 1.6204665899276733
Validation loss: 1.9836698472499847

Epoch: 5| Step: 2
Training loss: 1.6789757013320923
Validation loss: 2.0742598126331964

Epoch: 5| Step: 3
Training loss: 1.3124752044677734
Validation loss: 1.9771206925312679

Epoch: 5| Step: 4
Training loss: 1.4088879823684692
Validation loss: 1.9889184931914012

Epoch: 5| Step: 5
Training loss: 1.9031769037246704
Validation loss: 2.004973088701566

Epoch: 5| Step: 6
Training loss: 2.163064956665039
Validation loss: 2.0116368929545083

Epoch: 5| Step: 7
Training loss: 1.5836883783340454
Validation loss: 2.0202906330426535

Epoch: 5| Step: 8
Training loss: 1.1754655838012695
Validation loss: 2.0280563086271286

Epoch: 5| Step: 9
Training loss: 2.218494415283203
Validation loss: 2.0235609312852225

Epoch: 5| Step: 10
Training loss: 2.8241162300109863
Validation loss: 2.0055677940448127

Epoch: 5| Step: 11
Training loss: 2.818384885787964
Validation loss: 1.9993998557329178

Epoch: 67| Step: 0
Training loss: 2.0999796390533447
Validation loss: 2.026756450533867

Epoch: 5| Step: 1
Training loss: 1.670950174331665
Validation loss: 2.0447216977675757

Epoch: 5| Step: 2
Training loss: 1.347980260848999
Validation loss: 2.0050669411818185

Epoch: 5| Step: 3
Training loss: 1.7968170642852783
Validation loss: 2.033088485399882

Epoch: 5| Step: 4
Training loss: 1.9460318088531494
Validation loss: 2.0459561745325723

Epoch: 5| Step: 5
Training loss: 2.028296947479248
Validation loss: 2.0931652635335922

Epoch: 5| Step: 6
Training loss: 1.9534469842910767
Validation loss: 2.0651838332414627

Epoch: 5| Step: 7
Training loss: 2.1277854442596436
Validation loss: 2.051147093375524

Epoch: 5| Step: 8
Training loss: 2.1183021068573
Validation loss: 2.0248470455408096

Epoch: 5| Step: 9
Training loss: 1.4947048425674438
Validation loss: 2.0537736813227334

Epoch: 5| Step: 10
Training loss: 1.510362148284912
Validation loss: 2.0526844461758933

Epoch: 5| Step: 11
Training loss: 3.027416229248047
Validation loss: 2.0336967209974923

Epoch: 68| Step: 0
Training loss: 1.9174035787582397
Validation loss: 2.036128138502439

Epoch: 5| Step: 1
Training loss: 2.016798496246338
Validation loss: 2.060360382000605

Epoch: 5| Step: 2
Training loss: 1.5994625091552734
Validation loss: 2.0383713444073996

Epoch: 5| Step: 3
Training loss: 2.0567069053649902
Validation loss: 2.0909370879332223

Epoch: 5| Step: 4
Training loss: 2.2270572185516357
Validation loss: 2.0255775103966394

Epoch: 5| Step: 5
Training loss: 1.5443521738052368
Validation loss: 2.048247739672661

Epoch: 5| Step: 6
Training loss: 1.5629417896270752
Validation loss: 2.0412303060293198

Epoch: 5| Step: 7
Training loss: 1.59200918674469
Validation loss: 2.037111774086952

Epoch: 5| Step: 8
Training loss: 2.117140293121338
Validation loss: 1.9889696538448334

Epoch: 5| Step: 9
Training loss: 2.0093722343444824
Validation loss: 2.028043528397878

Epoch: 5| Step: 10
Training loss: 2.084555149078369
Validation loss: 2.0079666127761207

Epoch: 5| Step: 11
Training loss: 2.609177827835083
Validation loss: 2.049638564387957

Epoch: 69| Step: 0
Training loss: 1.6422621011734009
Validation loss: 2.0169009218613305

Epoch: 5| Step: 1
Training loss: 2.104311466217041
Validation loss: 2.003482475876808

Epoch: 5| Step: 2
Training loss: 1.6523010730743408
Validation loss: 2.014652048548063

Epoch: 5| Step: 3
Training loss: 1.8350627422332764
Validation loss: 2.0328749467929206

Epoch: 5| Step: 4
Training loss: 1.4573533535003662
Validation loss: 2.0706607898076377

Epoch: 5| Step: 5
Training loss: 2.528266191482544
Validation loss: 1.9740225821733475

Epoch: 5| Step: 6
Training loss: 1.1628923416137695
Validation loss: 1.995955194036166

Epoch: 5| Step: 7
Training loss: 1.5294697284698486
Validation loss: 1.991843005021413

Epoch: 5| Step: 8
Training loss: 1.7498900890350342
Validation loss: 1.9734290440877278

Epoch: 5| Step: 9
Training loss: 2.227511167526245
Validation loss: 2.028565173347791

Epoch: 5| Step: 10
Training loss: 2.3045859336853027
Validation loss: 1.9981990804274876

Epoch: 5| Step: 11
Training loss: 0.797943115234375
Validation loss: 2.0326831390460334

Epoch: 70| Step: 0
Training loss: 2.282832622528076
Validation loss: 2.012400577465693

Epoch: 5| Step: 1
Training loss: 1.518964409828186
Validation loss: 2.0331462621688843

Epoch: 5| Step: 2
Training loss: 1.341148018836975
Validation loss: 1.9969934870799382

Epoch: 5| Step: 3
Training loss: 1.6653938293457031
Validation loss: 2.0337538917859397

Epoch: 5| Step: 4
Training loss: 1.92228102684021
Validation loss: 2.0347920854886374

Epoch: 5| Step: 5
Training loss: 2.0606353282928467
Validation loss: 2.0049323787291846

Epoch: 5| Step: 6
Training loss: 1.9559653997421265
Validation loss: 2.029139136274656

Epoch: 5| Step: 7
Training loss: 1.829162836074829
Validation loss: 2.0214084833860397

Epoch: 5| Step: 8
Training loss: 1.247698426246643
Validation loss: 1.9902176161607106

Epoch: 5| Step: 9
Training loss: 1.827703833580017
Validation loss: 2.0209816098213196

Epoch: 5| Step: 10
Training loss: 1.9569050073623657
Validation loss: 2.0022381444772086

Epoch: 5| Step: 11
Training loss: 3.0004348754882812
Validation loss: 2.0209025740623474

Epoch: 71| Step: 0
Training loss: 2.005871057510376
Validation loss: 2.0266061623891196

Epoch: 5| Step: 1
Training loss: 2.061352491378784
Validation loss: 2.0381487607955933

Epoch: 5| Step: 2
Training loss: 1.6558488607406616
Validation loss: 1.9752848595380783

Epoch: 5| Step: 3
Training loss: 2.0441737174987793
Validation loss: 2.0162947873274484

Epoch: 5| Step: 4
Training loss: 2.3198273181915283
Validation loss: 2.0147789071003595

Epoch: 5| Step: 5
Training loss: 1.5352579355239868
Validation loss: 1.9421171496311824

Epoch: 5| Step: 6
Training loss: 1.707810640335083
Validation loss: 2.0199054131905236

Epoch: 5| Step: 7
Training loss: 1.3832224607467651
Validation loss: 2.0570191045602164

Epoch: 5| Step: 8
Training loss: 1.8374334573745728
Validation loss: 2.0143444488445916

Epoch: 5| Step: 9
Training loss: 1.8147690296173096
Validation loss: 1.9767381697893143

Epoch: 5| Step: 10
Training loss: 1.2198185920715332
Validation loss: 2.0064235726992288

Epoch: 5| Step: 11
Training loss: 1.519418478012085
Validation loss: 2.0050032983223596

Epoch: 72| Step: 0
Training loss: 1.0552036762237549
Validation loss: 1.9755998402833939

Epoch: 5| Step: 1
Training loss: 1.8645004034042358
Validation loss: 2.0351769973834357

Epoch: 5| Step: 2
Training loss: 1.7883384227752686
Validation loss: 2.0117537130912146

Epoch: 5| Step: 3
Training loss: 1.890091896057129
Validation loss: 2.016031185785929

Epoch: 5| Step: 4
Training loss: 1.7062456607818604
Validation loss: 2.0365005880594254

Epoch: 5| Step: 5
Training loss: 1.8415143489837646
Validation loss: 2.029611736536026

Epoch: 5| Step: 6
Training loss: 2.127781391143799
Validation loss: 1.9825065582990646

Epoch: 5| Step: 7
Training loss: 2.115116596221924
Validation loss: 2.03174419204394

Epoch: 5| Step: 8
Training loss: 1.7192074060440063
Validation loss: 2.0394873867432275

Epoch: 5| Step: 9
Training loss: 1.5698662996292114
Validation loss: 2.0193717082341514

Epoch: 5| Step: 10
Training loss: 2.1061105728149414
Validation loss: 1.9649113416671753

Epoch: 5| Step: 11
Training loss: 0.720553457736969
Validation loss: 1.9920388013124466

Epoch: 73| Step: 0
Training loss: 2.173954486846924
Validation loss: 1.9528642197450001

Epoch: 5| Step: 1
Training loss: 2.0045206546783447
Validation loss: 1.981088365117709

Epoch: 5| Step: 2
Training loss: 1.5580450296401978
Validation loss: 2.009726256132126

Epoch: 5| Step: 3
Training loss: 1.7174594402313232
Validation loss: 2.002684459090233

Epoch: 5| Step: 4
Training loss: 1.6202911138534546
Validation loss: 1.9970840563376744

Epoch: 5| Step: 5
Training loss: 1.4845695495605469
Validation loss: 1.9818306813637416

Epoch: 5| Step: 6
Training loss: 1.5977277755737305
Validation loss: 1.9827843258778255

Epoch: 5| Step: 7
Training loss: 1.2827117443084717
Validation loss: 1.9829314351081848

Epoch: 5| Step: 8
Training loss: 2.0375430583953857
Validation loss: 2.0017672081788382

Epoch: 5| Step: 9
Training loss: 1.8372255563735962
Validation loss: 1.999515141050021

Epoch: 5| Step: 10
Training loss: 1.8268616199493408
Validation loss: 2.025200292468071

Epoch: 5| Step: 11
Training loss: 2.770573139190674
Validation loss: 2.0188765873511634

Epoch: 74| Step: 0
Training loss: 1.7037639617919922
Validation loss: 2.0037274062633514

Epoch: 5| Step: 1
Training loss: 2.1406102180480957
Validation loss: 1.9906393339236577

Epoch: 5| Step: 2
Training loss: 1.8995640277862549
Validation loss: 2.039206311106682

Epoch: 5| Step: 3
Training loss: 1.5583560466766357
Validation loss: 1.9642852246761322

Epoch: 5| Step: 4
Training loss: 2.4109861850738525
Validation loss: 1.99275504052639

Epoch: 5| Step: 5
Training loss: 1.8210995197296143
Validation loss: 1.989530439178149

Epoch: 5| Step: 6
Training loss: 2.162510395050049
Validation loss: 1.9956091741720836

Epoch: 5| Step: 7
Training loss: 1.1945815086364746
Validation loss: 1.9946216146151226

Epoch: 5| Step: 8
Training loss: 1.7460826635360718
Validation loss: 1.9888175974289577

Epoch: 5| Step: 9
Training loss: 1.441957712173462
Validation loss: 2.014779423673948

Epoch: 5| Step: 10
Training loss: 1.4314883947372437
Validation loss: 2.0079737156629562

Epoch: 5| Step: 11
Training loss: 0.2459651231765747
Validation loss: 1.9955220619837444

Epoch: 75| Step: 0
Training loss: 1.312546968460083
Validation loss: 1.9998748451471329

Epoch: 5| Step: 1
Training loss: 1.8128303289413452
Validation loss: 1.9759153227011363

Epoch: 5| Step: 2
Training loss: 1.953455924987793
Validation loss: 1.982288897037506

Epoch: 5| Step: 3
Training loss: 1.7830356359481812
Validation loss: 1.9961582620938618

Epoch: 5| Step: 4
Training loss: 1.6699966192245483
Validation loss: 2.035365492105484

Epoch: 5| Step: 5
Training loss: 1.6585781574249268
Validation loss: 1.9672681788603466

Epoch: 5| Step: 6
Training loss: 1.9339535236358643
Validation loss: 2.0157686173915863

Epoch: 5| Step: 7
Training loss: 2.1360602378845215
Validation loss: 2.004950081308683

Epoch: 5| Step: 8
Training loss: 1.6773490905761719
Validation loss: 1.9696373045444489

Epoch: 5| Step: 9
Training loss: 1.463100790977478
Validation loss: 1.9825206498305004

Epoch: 5| Step: 10
Training loss: 1.8363056182861328
Validation loss: 2.023997411131859

Epoch: 5| Step: 11
Training loss: 2.459789276123047
Validation loss: 2.031965270638466

Epoch: 76| Step: 0
Training loss: 2.3172922134399414
Validation loss: 2.024769753217697

Epoch: 5| Step: 1
Training loss: 1.735914945602417
Validation loss: 1.9889235695203145

Epoch: 5| Step: 2
Training loss: 1.9487507343292236
Validation loss: 2.0364470879236856

Epoch: 5| Step: 3
Training loss: 1.6152656078338623
Validation loss: 2.013315642873446

Epoch: 5| Step: 4
Training loss: 1.595218300819397
Validation loss: 2.036719173192978

Epoch: 5| Step: 5
Training loss: 2.1074061393737793
Validation loss: 1.9927059262990952

Epoch: 5| Step: 6
Training loss: 1.3733245134353638
Validation loss: 2.007805898785591

Epoch: 5| Step: 7
Training loss: 1.0004172325134277
Validation loss: 2.0194765677054725

Epoch: 5| Step: 8
Training loss: 2.1834664344787598
Validation loss: 2.023484160502752

Epoch: 5| Step: 9
Training loss: 1.4720667600631714
Validation loss: 2.0411338905493417

Epoch: 5| Step: 10
Training loss: 2.0852274894714355
Validation loss: 2.0211723695198693

Epoch: 5| Step: 11
Training loss: 2.2989511489868164
Validation loss: 2.019786740342776

Epoch: 77| Step: 0
Training loss: 1.5282171964645386
Validation loss: 2.030357519785563

Epoch: 5| Step: 1
Training loss: 1.4669525623321533
Validation loss: 1.997485766808192

Epoch: 5| Step: 2
Training loss: 1.3031619787216187
Validation loss: 1.9958238403002422

Epoch: 5| Step: 3
Training loss: 2.010981798171997
Validation loss: 2.0070013304551444

Epoch: 5| Step: 4
Training loss: 2.0183701515197754
Validation loss: 2.0336051881313324

Epoch: 5| Step: 5
Training loss: 1.8948709964752197
Validation loss: 1.9994972894589107

Epoch: 5| Step: 6
Training loss: 1.919034719467163
Validation loss: 2.0120796809593835

Epoch: 5| Step: 7
Training loss: 1.9221585988998413
Validation loss: 2.016659145553907

Epoch: 5| Step: 8
Training loss: 1.5991184711456299
Validation loss: 2.015579809745153

Epoch: 5| Step: 9
Training loss: 2.304948329925537
Validation loss: 1.9631977925697963

Epoch: 5| Step: 10
Training loss: 1.465839147567749
Validation loss: 1.9659274766842525

Epoch: 5| Step: 11
Training loss: 3.0957112312316895
Validation loss: 2.0038770933945975

Epoch: 78| Step: 0
Training loss: 2.059781312942505
Validation loss: 1.9882032225529354

Epoch: 5| Step: 1
Training loss: 1.8922334909439087
Validation loss: 1.9943736294905345

Epoch: 5| Step: 2
Training loss: 1.7633883953094482
Validation loss: 2.044111132621765

Epoch: 5| Step: 3
Training loss: 1.5651404857635498
Validation loss: 2.089194893836975

Epoch: 5| Step: 4
Training loss: 1.6382414102554321
Validation loss: 2.0743852953116098

Epoch: 5| Step: 5
Training loss: 2.182835102081299
Validation loss: 2.0335695346196494

Epoch: 5| Step: 6
Training loss: 1.7932565212249756
Validation loss: 1.9968002537886302

Epoch: 5| Step: 7
Training loss: 1.841148018836975
Validation loss: 1.9673005640506744

Epoch: 5| Step: 8
Training loss: 1.879528284072876
Validation loss: 1.9879408876101177

Epoch: 5| Step: 9
Training loss: 1.8462448120117188
Validation loss: 1.9962317049503326

Epoch: 5| Step: 10
Training loss: 1.7047817707061768
Validation loss: 2.014836107691129

Epoch: 5| Step: 11
Training loss: 0.6430968046188354
Validation loss: 1.9993222455183666

Epoch: 79| Step: 0
Training loss: 1.499464511871338
Validation loss: 2.0015750229358673

Epoch: 5| Step: 1
Training loss: 2.16099214553833
Validation loss: 2.007575660943985

Epoch: 5| Step: 2
Training loss: 1.6404924392700195
Validation loss: 2.019808908303579

Epoch: 5| Step: 3
Training loss: 2.0596680641174316
Validation loss: 1.9833307365576427

Epoch: 5| Step: 4
Training loss: 1.8224239349365234
Validation loss: 1.9727279196182887

Epoch: 5| Step: 5
Training loss: 1.6479930877685547
Validation loss: 1.9522359172503154

Epoch: 5| Step: 6
Training loss: 1.2363475561141968
Validation loss: 1.9936388333638508

Epoch: 5| Step: 7
Training loss: 2.153212547302246
Validation loss: 1.9787856340408325

Epoch: 5| Step: 8
Training loss: 2.0818417072296143
Validation loss: 1.9903245717287064

Epoch: 5| Step: 9
Training loss: 1.472345232963562
Validation loss: 1.985318625966708

Epoch: 5| Step: 10
Training loss: 1.9817078113555908
Validation loss: 2.016339063644409

Epoch: 5| Step: 11
Training loss: 2.0391156673431396
Validation loss: 1.995906154314677

Epoch: 80| Step: 0
Training loss: 0.7522711157798767
Validation loss: 2.0008621315161386

Epoch: 5| Step: 1
Training loss: 2.175841808319092
Validation loss: 2.0125041753053665

Epoch: 5| Step: 2
Training loss: 1.6444753408432007
Validation loss: 1.951425979534785

Epoch: 5| Step: 3
Training loss: 1.689691185951233
Validation loss: 1.9582590411106746

Epoch: 5| Step: 4
Training loss: 1.7449414730072021
Validation loss: 1.9875645885864894

Epoch: 5| Step: 5
Training loss: 2.114515542984009
Validation loss: 1.9913646082083385

Epoch: 5| Step: 6
Training loss: 1.6797916889190674
Validation loss: 1.9643139491478603

Epoch: 5| Step: 7
Training loss: 2.087846040725708
Validation loss: 1.9881064643462498

Epoch: 5| Step: 8
Training loss: 2.3848464488983154
Validation loss: 1.9292029390732448

Epoch: 5| Step: 9
Training loss: 1.5686964988708496
Validation loss: 1.927415519952774

Epoch: 5| Step: 10
Training loss: 1.2899068593978882
Validation loss: 1.985641712943713

Epoch: 5| Step: 11
Training loss: 1.3717267513275146
Validation loss: 1.989210804303487

Epoch: 81| Step: 0
Training loss: 2.1291286945343018
Validation loss: 1.9890002657969792

Epoch: 5| Step: 1
Training loss: 1.5835233926773071
Validation loss: 1.9832893759012222

Epoch: 5| Step: 2
Training loss: 1.1131598949432373
Validation loss: 1.9829444239536922

Epoch: 5| Step: 3
Training loss: 2.086111307144165
Validation loss: 1.990998198588689

Epoch: 5| Step: 4
Training loss: 1.7398736476898193
Validation loss: 1.986655260125796

Epoch: 5| Step: 5
Training loss: 1.6777498722076416
Validation loss: 2.0140398989121118

Epoch: 5| Step: 6
Training loss: 1.7716896533966064
Validation loss: 1.9754385501146317

Epoch: 5| Step: 7
Training loss: 1.4205950498580933
Validation loss: 2.01682818432649

Epoch: 5| Step: 8
Training loss: 1.8256431818008423
Validation loss: 2.0378563851118088

Epoch: 5| Step: 9
Training loss: 1.8581393957138062
Validation loss: 2.021133854985237

Epoch: 5| Step: 10
Training loss: 1.7089931964874268
Validation loss: 2.008614704012871

Epoch: 5| Step: 11
Training loss: 0.930168867111206
Validation loss: 1.9594008028507233

Epoch: 82| Step: 0
Training loss: 2.050525188446045
Validation loss: 1.9870546559492748

Epoch: 5| Step: 1
Training loss: 2.4368553161621094
Validation loss: 1.9761684487263362

Epoch: 5| Step: 2
Training loss: 1.46208918094635
Validation loss: 2.0046222557624183

Epoch: 5| Step: 3
Training loss: 1.6005100011825562
Validation loss: 2.0196530520915985

Epoch: 5| Step: 4
Training loss: 1.7324298620224
Validation loss: 2.0426295896371207

Epoch: 5| Step: 5
Training loss: 2.025902509689331
Validation loss: 1.9761882573366165

Epoch: 5| Step: 6
Training loss: 1.4187872409820557
Validation loss: 2.0115455985069275

Epoch: 5| Step: 7
Training loss: 2.395207643508911
Validation loss: 2.0059143602848053

Epoch: 5| Step: 8
Training loss: 0.9568662643432617
Validation loss: 1.9989288846651714

Epoch: 5| Step: 9
Training loss: 1.3883979320526123
Validation loss: 2.0021309008200965

Epoch: 5| Step: 10
Training loss: 1.3844937086105347
Validation loss: 1.9863890955845516

Epoch: 5| Step: 11
Training loss: 2.524689197540283
Validation loss: 1.97189199924469

Epoch: 83| Step: 0
Training loss: 2.323050022125244
Validation loss: 1.9684533576170604

Epoch: 5| Step: 1
Training loss: 1.8180696964263916
Validation loss: 1.9749496082464855

Epoch: 5| Step: 2
Training loss: 1.3545893430709839
Validation loss: 1.9474079410235088

Epoch: 5| Step: 3
Training loss: 1.6008942127227783
Validation loss: 1.9896390636761982

Epoch: 5| Step: 4
Training loss: 1.513273000717163
Validation loss: 1.9560714463392894

Epoch: 5| Step: 5
Training loss: 2.06596040725708
Validation loss: 1.9887358844280243

Epoch: 5| Step: 6
Training loss: 1.8550907373428345
Validation loss: 2.015521635611852

Epoch: 5| Step: 7
Training loss: 1.5578043460845947
Validation loss: 1.9891210148731868

Epoch: 5| Step: 8
Training loss: 1.5150909423828125
Validation loss: 1.9892508337895076

Epoch: 5| Step: 9
Training loss: 1.4534761905670166
Validation loss: 1.9646078596512477

Epoch: 5| Step: 10
Training loss: 1.681465744972229
Validation loss: 1.9919594923655193

Epoch: 5| Step: 11
Training loss: 1.516175627708435
Validation loss: 1.9839141766230266

Epoch: 84| Step: 0
Training loss: 1.386712908744812
Validation loss: 1.9793627113103867

Epoch: 5| Step: 1
Training loss: 1.7794408798217773
Validation loss: 1.9957452764113743

Epoch: 5| Step: 2
Training loss: 1.4523627758026123
Validation loss: 1.9848270267248154

Epoch: 5| Step: 3
Training loss: 1.9760150909423828
Validation loss: 1.9771877626578014

Epoch: 5| Step: 4
Training loss: 1.334990382194519
Validation loss: 1.9800752848386765

Epoch: 5| Step: 5
Training loss: 1.8440215587615967
Validation loss: 2.023634841044744

Epoch: 5| Step: 6
Training loss: 1.8201892375946045
Validation loss: 1.9574060887098312

Epoch: 5| Step: 7
Training loss: 1.822420358657837
Validation loss: 2.0203347355127335

Epoch: 5| Step: 8
Training loss: 1.7314493656158447
Validation loss: 1.9841062873601913

Epoch: 5| Step: 9
Training loss: 1.9141937494277954
Validation loss: 2.0191337118546167

Epoch: 5| Step: 10
Training loss: 1.552485704421997
Validation loss: 2.006135642528534

Epoch: 5| Step: 11
Training loss: 1.441680669784546
Validation loss: 1.9662079562743504

Epoch: 85| Step: 0
Training loss: 1.5362876653671265
Validation loss: 1.934574231505394

Epoch: 5| Step: 1
Training loss: 1.358001470565796
Validation loss: 1.988189771771431

Epoch: 5| Step: 2
Training loss: 1.9642013311386108
Validation loss: 1.990810975432396

Epoch: 5| Step: 3
Training loss: 1.0133575201034546
Validation loss: 2.013625135024389

Epoch: 5| Step: 4
Training loss: 1.9298694133758545
Validation loss: 2.0021554132302604

Epoch: 5| Step: 5
Training loss: 1.664541244506836
Validation loss: 2.0082135051488876

Epoch: 5| Step: 6
Training loss: 1.5159518718719482
Validation loss: 1.9468848009904225

Epoch: 5| Step: 7
Training loss: 2.04130482673645
Validation loss: 2.0082827309767404

Epoch: 5| Step: 8
Training loss: 1.4379384517669678
Validation loss: 2.066913957397143

Epoch: 5| Step: 9
Training loss: 1.9896762371063232
Validation loss: 1.986621951063474

Epoch: 5| Step: 10
Training loss: 2.144960403442383
Validation loss: 1.961267386873563

Epoch: 5| Step: 11
Training loss: 1.5444958209991455
Validation loss: 2.0481837689876556

Epoch: 86| Step: 0
Training loss: 1.7444231510162354
Validation loss: 2.0222818553447723

Epoch: 5| Step: 1
Training loss: 1.2868833541870117
Validation loss: 2.0168471535046897

Epoch: 5| Step: 2
Training loss: 1.8852964639663696
Validation loss: 2.015181009968122

Epoch: 5| Step: 3
Training loss: 1.6794302463531494
Validation loss: 1.9754898299773533

Epoch: 5| Step: 4
Training loss: 1.7024692296981812
Validation loss: 1.9991066604852676

Epoch: 5| Step: 5
Training loss: 1.7633693218231201
Validation loss: 2.0153738955656686

Epoch: 5| Step: 6
Training loss: 1.7430965900421143
Validation loss: 1.9835267513990402

Epoch: 5| Step: 7
Training loss: 1.6069387197494507
Validation loss: 2.018118530511856

Epoch: 5| Step: 8
Training loss: 2.2474308013916016
Validation loss: 2.0275276601314545

Epoch: 5| Step: 9
Training loss: 1.6198012828826904
Validation loss: 2.0025594830513

Epoch: 5| Step: 10
Training loss: 1.7512578964233398
Validation loss: 1.9741459836562474

Epoch: 5| Step: 11
Training loss: 1.8079054355621338
Validation loss: 2.025868053237597

Epoch: 87| Step: 0
Training loss: 1.3306095600128174
Validation loss: 1.9970993598302205

Epoch: 5| Step: 1
Training loss: 1.7906177043914795
Validation loss: 2.0050652772188187

Epoch: 5| Step: 2
Training loss: 1.5027034282684326
Validation loss: 2.0313373853762946

Epoch: 5| Step: 3
Training loss: 1.108729600906372
Validation loss: 1.9806869526704152

Epoch: 5| Step: 4
Training loss: 2.074321746826172
Validation loss: 1.9921103914578755

Epoch: 5| Step: 5
Training loss: 1.9184303283691406
Validation loss: 1.9836467057466507

Epoch: 5| Step: 6
Training loss: 1.94110906124115
Validation loss: 2.0089158515135446

Epoch: 5| Step: 7
Training loss: 1.8705886602401733
Validation loss: 2.0087342858314514

Epoch: 5| Step: 8
Training loss: 1.365698218345642
Validation loss: 2.000742663939794

Epoch: 5| Step: 9
Training loss: 1.3893073797225952
Validation loss: 2.0045187175273895

Epoch: 5| Step: 10
Training loss: 2.0638160705566406
Validation loss: 1.992873231569926

Epoch: 5| Step: 11
Training loss: 1.4104043245315552
Validation loss: 2.0252369145552316

Epoch: 88| Step: 0
Training loss: 1.3289052248001099
Validation loss: 1.9938174039125443

Epoch: 5| Step: 1
Training loss: 1.8202478885650635
Validation loss: 2.00270942846934

Epoch: 5| Step: 2
Training loss: 1.44557523727417
Validation loss: 2.036887804667155

Epoch: 5| Step: 3
Training loss: 2.170788288116455
Validation loss: 1.9711084812879562

Epoch: 5| Step: 4
Training loss: 2.039159059524536
Validation loss: 1.9551245371500652

Epoch: 5| Step: 5
Training loss: 1.6455520391464233
Validation loss: 1.9836107691129048

Epoch: 5| Step: 6
Training loss: 1.534505009651184
Validation loss: 1.9312940488258998

Epoch: 5| Step: 7
Training loss: 1.666185736656189
Validation loss: 1.9961740175882976

Epoch: 5| Step: 8
Training loss: 1.895176887512207
Validation loss: 2.015661726395289

Epoch: 5| Step: 9
Training loss: 1.3115708827972412
Validation loss: 1.995402529835701

Epoch: 5| Step: 10
Training loss: 1.184236764907837
Validation loss: 1.9771557748317719

Epoch: 5| Step: 11
Training loss: 2.302950859069824
Validation loss: 1.9508224825064342

Epoch: 89| Step: 0
Training loss: 1.652305006980896
Validation loss: 1.9708798329035442

Epoch: 5| Step: 1
Training loss: 1.5726286172866821
Validation loss: 1.9534926513830821

Epoch: 5| Step: 2
Training loss: 1.536839485168457
Validation loss: 1.960892270008723

Epoch: 5| Step: 3
Training loss: 2.337531089782715
Validation loss: 1.9488994032144547

Epoch: 5| Step: 4
Training loss: 1.5614941120147705
Validation loss: 1.975682571530342

Epoch: 5| Step: 5
Training loss: 1.333428144454956
Validation loss: 1.9954549769560497

Epoch: 5| Step: 6
Training loss: 1.7645657062530518
Validation loss: 2.0081780602534614

Epoch: 5| Step: 7
Training loss: 1.776282548904419
Validation loss: 1.9678417841593425

Epoch: 5| Step: 8
Training loss: 1.8003475666046143
Validation loss: 1.9365568558375041

Epoch: 5| Step: 9
Training loss: 1.3255481719970703
Validation loss: 1.9320491949717205

Epoch: 5| Step: 10
Training loss: 1.6176338195800781
Validation loss: 1.9968892981608708

Epoch: 5| Step: 11
Training loss: 1.4109437465667725
Validation loss: 1.9699547042449315

Epoch: 90| Step: 0
Training loss: 1.9139554500579834
Validation loss: 1.9897328565518062

Epoch: 5| Step: 1
Training loss: 1.8014278411865234
Validation loss: 1.9877426127592723

Epoch: 5| Step: 2
Training loss: 1.6725794076919556
Validation loss: 2.0003348886966705

Epoch: 5| Step: 3
Training loss: 1.2724900245666504
Validation loss: 2.0195034742355347

Epoch: 5| Step: 4
Training loss: 2.1669933795928955
Validation loss: 1.9554503113031387

Epoch: 5| Step: 5
Training loss: 1.9495735168457031
Validation loss: 1.9375717242558796

Epoch: 5| Step: 6
Training loss: 1.0573577880859375
Validation loss: 1.9795616467793782

Epoch: 5| Step: 7
Training loss: 1.470963716506958
Validation loss: 1.9590847541888554

Epoch: 5| Step: 8
Training loss: 1.5250780582427979
Validation loss: 1.9688966572284698

Epoch: 5| Step: 9
Training loss: 1.771551489830017
Validation loss: 1.9544055461883545

Epoch: 5| Step: 10
Training loss: 1.5680135488510132
Validation loss: 2.0001508394877114

Epoch: 5| Step: 11
Training loss: 0.6981205940246582
Validation loss: 1.950220028559367

Epoch: 91| Step: 0
Training loss: 1.6086571216583252
Validation loss: 1.9531050622463226

Epoch: 5| Step: 1
Training loss: 1.6509273052215576
Validation loss: 2.010474349061648

Epoch: 5| Step: 2
Training loss: 1.3151905536651611
Validation loss: 2.0037895341714225

Epoch: 5| Step: 3
Training loss: 1.941802978515625
Validation loss: 1.9744127442439396

Epoch: 5| Step: 4
Training loss: 1.4900157451629639
Validation loss: 1.9739877432584763

Epoch: 5| Step: 5
Training loss: 1.517581582069397
Validation loss: 1.984347144762675

Epoch: 5| Step: 6
Training loss: 1.6599130630493164
Validation loss: 1.9436175972223282

Epoch: 5| Step: 7
Training loss: 2.2181098461151123
Validation loss: 1.9969048251708348

Epoch: 5| Step: 8
Training loss: 1.0955994129180908
Validation loss: 1.9782038778066635

Epoch: 5| Step: 9
Training loss: 1.755693793296814
Validation loss: 2.0033816496531167

Epoch: 5| Step: 10
Training loss: 1.6040951013565063
Validation loss: 1.9752282003561656

Epoch: 5| Step: 11
Training loss: 1.2620420455932617
Validation loss: 2.0070681075255075

Epoch: 92| Step: 0
Training loss: 1.0571290254592896
Validation loss: 1.9365281114975612

Epoch: 5| Step: 1
Training loss: 1.8561166524887085
Validation loss: 1.9762495905160904

Epoch: 5| Step: 2
Training loss: 2.0008482933044434
Validation loss: 1.9895865321159363

Epoch: 5| Step: 3
Training loss: 2.372995376586914
Validation loss: 1.9737033446629841

Epoch: 5| Step: 4
Training loss: 1.844953179359436
Validation loss: 1.984241098165512

Epoch: 5| Step: 5
Training loss: 1.4908084869384766
Validation loss: 1.9887341956297557

Epoch: 5| Step: 6
Training loss: 1.4787153005599976
Validation loss: 1.9498822937409084

Epoch: 5| Step: 7
Training loss: 1.3256351947784424
Validation loss: 2.016338268915812

Epoch: 5| Step: 8
Training loss: 1.8377692699432373
Validation loss: 1.9529861559470494

Epoch: 5| Step: 9
Training loss: 1.4347410202026367
Validation loss: 2.065583656231562

Epoch: 5| Step: 10
Training loss: 1.2789658308029175
Validation loss: 1.9638961901267369

Epoch: 5| Step: 11
Training loss: 2.902036428451538
Validation loss: 1.9532675643761952

Epoch: 93| Step: 0
Training loss: 1.2330501079559326
Validation loss: 1.997312565644582

Epoch: 5| Step: 1
Training loss: 1.5084079504013062
Validation loss: 2.0171740452448526

Epoch: 5| Step: 2
Training loss: 2.1212010383605957
Validation loss: 1.9809689621130626

Epoch: 5| Step: 3
Training loss: 1.6241073608398438
Validation loss: 1.9688907712697983

Epoch: 5| Step: 4
Training loss: 1.6559196710586548
Validation loss: 1.9661420385042827

Epoch: 5| Step: 5
Training loss: 1.306444525718689
Validation loss: 2.0304106175899506

Epoch: 5| Step: 6
Training loss: 1.8038345575332642
Validation loss: 2.034442732731501

Epoch: 5| Step: 7
Training loss: 2.1031317710876465
Validation loss: 1.9469126164913177

Epoch: 5| Step: 8
Training loss: 1.2718544006347656
Validation loss: 1.9802834739287694

Epoch: 5| Step: 9
Training loss: 1.5170974731445312
Validation loss: 1.9039385865132015

Epoch: 5| Step: 10
Training loss: 2.0525472164154053
Validation loss: 1.9668551236391068

Epoch: 5| Step: 11
Training loss: 0.41676604747772217
Validation loss: 1.9544426401456196

Epoch: 94| Step: 0
Training loss: 1.2588224411010742
Validation loss: 1.944172203540802

Epoch: 5| Step: 1
Training loss: 1.4667104482650757
Validation loss: 1.9925539195537567

Epoch: 5| Step: 2
Training loss: 1.6623218059539795
Validation loss: 1.9519510219494502

Epoch: 5| Step: 3
Training loss: 1.467559814453125
Validation loss: 2.011613513032595

Epoch: 5| Step: 4
Training loss: 1.194161057472229
Validation loss: 1.9787003894646962

Epoch: 5| Step: 5
Training loss: 1.3898522853851318
Validation loss: 1.9700974722703297

Epoch: 5| Step: 6
Training loss: 1.7742239236831665
Validation loss: 1.9819663713375728

Epoch: 5| Step: 7
Training loss: 1.687459945678711
Validation loss: 1.962245151400566

Epoch: 5| Step: 8
Training loss: 2.169398307800293
Validation loss: 1.9943834394216537

Epoch: 5| Step: 9
Training loss: 1.8655380010604858
Validation loss: 1.9723528722922008

Epoch: 5| Step: 10
Training loss: 1.397383213043213
Validation loss: 1.8977859715620677

Epoch: 5| Step: 11
Training loss: 3.044212579727173
Validation loss: 1.9408456981182098

Epoch: 95| Step: 0
Training loss: 1.3297092914581299
Validation loss: 1.9512153913577397

Epoch: 5| Step: 1
Training loss: 1.4355144500732422
Validation loss: 1.9887762715419133

Epoch: 5| Step: 2
Training loss: 1.4502407312393188
Validation loss: 1.9435622344414394

Epoch: 5| Step: 3
Training loss: 1.6406900882720947
Validation loss: 1.9538663178682327

Epoch: 5| Step: 4
Training loss: 1.1273549795150757
Validation loss: 1.9257859140634537

Epoch: 5| Step: 5
Training loss: 2.4043776988983154
Validation loss: 1.9554611543814342

Epoch: 5| Step: 6
Training loss: 1.9226906299591064
Validation loss: 1.9575644334157307

Epoch: 5| Step: 7
Training loss: 1.3253698348999023
Validation loss: 1.969108169277509

Epoch: 5| Step: 8
Training loss: 1.586329698562622
Validation loss: 1.9328430593013763

Epoch: 5| Step: 9
Training loss: 1.759826898574829
Validation loss: 1.934760053952535

Epoch: 5| Step: 10
Training loss: 1.603955626487732
Validation loss: 1.9286508460839589

Epoch: 5| Step: 11
Training loss: 2.815946340560913
Validation loss: 2.0005384385585785

Epoch: 96| Step: 0
Training loss: 1.4368489980697632
Validation loss: 1.9340849767128627

Epoch: 5| Step: 1
Training loss: 1.5351999998092651
Validation loss: 1.9417304893334706

Epoch: 5| Step: 2
Training loss: 1.4862301349639893
Validation loss: 1.958876113096873

Epoch: 5| Step: 3
Training loss: 1.7446876764297485
Validation loss: 1.9321896135807037

Epoch: 5| Step: 4
Training loss: 1.5956356525421143
Validation loss: 1.9304587642351787

Epoch: 5| Step: 5
Training loss: 1.6580193042755127
Validation loss: 1.9810979863007863

Epoch: 5| Step: 6
Training loss: 1.7841132879257202
Validation loss: 2.0071276873350143

Epoch: 5| Step: 7
Training loss: 1.1288559436798096
Validation loss: 2.0475328962008157

Epoch: 5| Step: 8
Training loss: 1.713780403137207
Validation loss: 2.0354109505812326

Epoch: 5| Step: 9
Training loss: 2.0270402431488037
Validation loss: 2.075421099861463

Epoch: 5| Step: 10
Training loss: 1.6785509586334229
Validation loss: 2.007966180642446

Epoch: 5| Step: 11
Training loss: 2.5196571350097656
Validation loss: 2.0034996469815574

Epoch: 97| Step: 0
Training loss: 1.5474897623062134
Validation loss: 1.9460626939932506

Epoch: 5| Step: 1
Training loss: 0.948973536491394
Validation loss: 1.9397206902503967

Epoch: 5| Step: 2
Training loss: 2.1344382762908936
Validation loss: 1.9223758925994237

Epoch: 5| Step: 3
Training loss: 1.397137999534607
Validation loss: 1.9617753326892853

Epoch: 5| Step: 4
Training loss: 1.743283987045288
Validation loss: 1.9542795767386754

Epoch: 5| Step: 5
Training loss: 2.027980089187622
Validation loss: 1.9592745403448741

Epoch: 5| Step: 6
Training loss: 1.776586890220642
Validation loss: 1.929020956158638

Epoch: 5| Step: 7
Training loss: 1.559312105178833
Validation loss: 1.9244543711344402

Epoch: 5| Step: 8
Training loss: 1.439321756362915
Validation loss: 1.9436893860499065

Epoch: 5| Step: 9
Training loss: 0.8033748865127563
Validation loss: 1.8926521688699722

Epoch: 5| Step: 10
Training loss: 1.7320390939712524
Validation loss: 1.9729856103658676

Epoch: 5| Step: 11
Training loss: 2.3169338703155518
Validation loss: 1.9235076854626338

Epoch: 98| Step: 0
Training loss: 1.5322116613388062
Validation loss: 1.9140778134266536

Epoch: 5| Step: 1
Training loss: 0.8014728426933289
Validation loss: 1.9668462822834651

Epoch: 5| Step: 2
Training loss: 1.6531997919082642
Validation loss: 1.9164866308371227

Epoch: 5| Step: 3
Training loss: 1.739190697669983
Validation loss: 1.9616760859886806

Epoch: 5| Step: 4
Training loss: 1.5643624067306519
Validation loss: 1.9887671619653702

Epoch: 5| Step: 5
Training loss: 1.882948875427246
Validation loss: 2.0242488284905753

Epoch: 5| Step: 6
Training loss: 1.7979977130889893
Validation loss: 1.987959012389183

Epoch: 5| Step: 7
Training loss: 1.5587193965911865
Validation loss: 1.9583058804273605

Epoch: 5| Step: 8
Training loss: 1.661041259765625
Validation loss: 1.9278164356946945

Epoch: 5| Step: 9
Training loss: 1.7132762670516968
Validation loss: 1.9361191242933273

Epoch: 5| Step: 10
Training loss: 1.6058051586151123
Validation loss: 1.9506353338559468

Epoch: 5| Step: 11
Training loss: 1.1784688234329224
Validation loss: 1.9577129632234573

Epoch: 99| Step: 0
Training loss: 1.4839063882827759
Validation loss: 1.9430928478638332

Epoch: 5| Step: 1
Training loss: 1.9333254098892212
Validation loss: 1.920262152949969

Epoch: 5| Step: 2
Training loss: 1.1171387434005737
Validation loss: 1.9467068115870159

Epoch: 5| Step: 3
Training loss: 1.4051513671875
Validation loss: 1.9803133358558018

Epoch: 5| Step: 4
Training loss: 1.6453297138214111
Validation loss: 1.9987437923749287

Epoch: 5| Step: 5
Training loss: 1.7337535619735718
Validation loss: 1.9891698757807414

Epoch: 5| Step: 6
Training loss: 1.3166191577911377
Validation loss: 1.9729483773310978

Epoch: 5| Step: 7
Training loss: 1.9058094024658203
Validation loss: 1.9695818970600765

Epoch: 5| Step: 8
Training loss: 2.126124858856201
Validation loss: 1.9258823891480763

Epoch: 5| Step: 9
Training loss: 1.372302770614624
Validation loss: 1.9930281241734822

Epoch: 5| Step: 10
Training loss: 1.1388094425201416
Validation loss: 1.9465581824382145

Epoch: 5| Step: 11
Training loss: 1.1502288579940796
Validation loss: 1.9613863428433735

Epoch: 100| Step: 0
Training loss: 1.5980879068374634
Validation loss: 1.9818301647901535

Epoch: 5| Step: 1
Training loss: 1.8628370761871338
Validation loss: 1.9919264515240986

Epoch: 5| Step: 2
Training loss: 1.5110785961151123
Validation loss: 1.9422851006189983

Epoch: 5| Step: 3
Training loss: 1.4555437564849854
Validation loss: 1.9292277346054714

Epoch: 5| Step: 4
Training loss: 1.0717960596084595
Validation loss: 1.985474556684494

Epoch: 5| Step: 5
Training loss: 1.9237086772918701
Validation loss: 1.9912580847740173

Epoch: 5| Step: 6
Training loss: 1.839525580406189
Validation loss: 1.9992154190937679

Epoch: 5| Step: 7
Training loss: 1.5225154161453247
Validation loss: 1.977771629889806

Epoch: 5| Step: 8
Training loss: 1.1641736030578613
Validation loss: 1.992612178126971

Epoch: 5| Step: 9
Training loss: 1.5744454860687256
Validation loss: 1.9094527959823608

Epoch: 5| Step: 10
Training loss: 1.7568365335464478
Validation loss: 1.9332644840081532

Epoch: 5| Step: 11
Training loss: 1.8873074054718018
Validation loss: 1.972675288716952

Epoch: 101| Step: 0
Training loss: 1.6076509952545166
Validation loss: 1.984673152367274

Epoch: 5| Step: 1
Training loss: 1.4313629865646362
Validation loss: 1.9506729245185852

Epoch: 5| Step: 2
Training loss: 1.2675975561141968
Validation loss: 1.9962232410907745

Epoch: 5| Step: 3
Training loss: 2.006859302520752
Validation loss: 1.9146957596143086

Epoch: 5| Step: 4
Training loss: 1.4107975959777832
Validation loss: 1.9478453248739243

Epoch: 5| Step: 5
Training loss: 1.5735052824020386
Validation loss: 1.96850124001503

Epoch: 5| Step: 6
Training loss: 1.096048355102539
Validation loss: 1.9766769707202911

Epoch: 5| Step: 7
Training loss: 1.5182781219482422
Validation loss: 1.978610763947169

Epoch: 5| Step: 8
Training loss: 1.6369307041168213
Validation loss: 1.923115496834119

Epoch: 5| Step: 9
Training loss: 1.680211067199707
Validation loss: 1.9512611428896587

Epoch: 5| Step: 10
Training loss: 1.676043152809143
Validation loss: 1.8811636914809544

Epoch: 5| Step: 11
Training loss: 2.5169219970703125
Validation loss: 1.969908873240153

Epoch: 102| Step: 0
Training loss: 1.3101835250854492
Validation loss: 1.9282653331756592

Epoch: 5| Step: 1
Training loss: 1.9548594951629639
Validation loss: 1.9459131608406703

Epoch: 5| Step: 2
Training loss: 1.3836508989334106
Validation loss: 1.9504416435956955

Epoch: 5| Step: 3
Training loss: 1.4356869459152222
Validation loss: 1.9699462056159973

Epoch: 5| Step: 4
Training loss: 1.4155458211898804
Validation loss: 2.022285118699074

Epoch: 5| Step: 5
Training loss: 1.100795030593872
Validation loss: 1.9797418415546417

Epoch: 5| Step: 6
Training loss: 1.625329613685608
Validation loss: 1.9930366575717926

Epoch: 5| Step: 7
Training loss: 1.5727444887161255
Validation loss: 1.9312879890203476

Epoch: 5| Step: 8
Training loss: 1.1117185354232788
Validation loss: 1.9684662967920303

Epoch: 5| Step: 9
Training loss: 2.23018217086792
Validation loss: 1.9497607598702114

Epoch: 5| Step: 10
Training loss: 1.7645012140274048
Validation loss: 1.9417114357153575

Epoch: 5| Step: 11
Training loss: 1.224170207977295
Validation loss: 1.9397979378700256

Epoch: 103| Step: 0
Training loss: 1.4389617443084717
Validation loss: 1.954154243071874

Epoch: 5| Step: 1
Training loss: 1.1472476720809937
Validation loss: 1.9292937964200974

Epoch: 5| Step: 2
Training loss: 1.4478678703308105
Validation loss: 1.973679095506668

Epoch: 5| Step: 3
Training loss: 1.3862049579620361
Validation loss: 1.9551188846429188

Epoch: 5| Step: 4
Training loss: 1.6948131322860718
Validation loss: 1.9679797540108364

Epoch: 5| Step: 5
Training loss: 1.5418800115585327
Validation loss: 1.9482579479614894

Epoch: 5| Step: 6
Training loss: 1.5635344982147217
Validation loss: 2.004787191748619

Epoch: 5| Step: 7
Training loss: 1.7361328601837158
Validation loss: 1.972327634692192

Epoch: 5| Step: 8
Training loss: 1.4798080921173096
Validation loss: 1.9316178609927495

Epoch: 5| Step: 9
Training loss: 1.3671064376831055
Validation loss: 1.968795691927274

Epoch: 5| Step: 10
Training loss: 1.8824443817138672
Validation loss: 1.9471929321686428

Epoch: 5| Step: 11
Training loss: 0.7796367406845093
Validation loss: 1.9439218441645305

Epoch: 104| Step: 0
Training loss: 1.513165831565857
Validation loss: 1.9585621058940887

Epoch: 5| Step: 1
Training loss: 0.9078415632247925
Validation loss: 1.9483881046374638

Epoch: 5| Step: 2
Training loss: 1.3244935274124146
Validation loss: 1.9662204881509144

Epoch: 5| Step: 3
Training loss: 1.4085626602172852
Validation loss: 1.9586949795484543

Epoch: 5| Step: 4
Training loss: 1.8069015741348267
Validation loss: 1.908319006363551

Epoch: 5| Step: 5
Training loss: 1.8476394414901733
Validation loss: 1.9417961190144222

Epoch: 5| Step: 6
Training loss: 1.3578245639801025
Validation loss: 1.9155677656332653

Epoch: 5| Step: 7
Training loss: 1.389952301979065
Validation loss: 1.9785346488157909

Epoch: 5| Step: 8
Training loss: 1.6853916645050049
Validation loss: 1.9373530546824138

Epoch: 5| Step: 9
Training loss: 1.7059848308563232
Validation loss: 1.9253988812367122

Epoch: 5| Step: 10
Training loss: 1.4510079622268677
Validation loss: 1.925312747557958

Epoch: 5| Step: 11
Training loss: 1.756273627281189
Validation loss: 1.9170614530642827

Epoch: 105| Step: 0
Training loss: 1.8999011516571045
Validation loss: 1.949244608481725

Epoch: 5| Step: 1
Training loss: 1.5609937906265259
Validation loss: 1.9340457568566005

Epoch: 5| Step: 2
Training loss: 1.0017623901367188
Validation loss: 1.9968608021736145

Epoch: 5| Step: 3
Training loss: 1.9082657098770142
Validation loss: 1.9257466991742451

Epoch: 5| Step: 4
Training loss: 1.5829880237579346
Validation loss: 1.94784909983476

Epoch: 5| Step: 5
Training loss: 1.0852081775665283
Validation loss: 1.9176289836565654

Epoch: 5| Step: 6
Training loss: 1.3331186771392822
Validation loss: 1.9453768233458202

Epoch: 5| Step: 7
Training loss: 1.8413536548614502
Validation loss: 1.919584756096204

Epoch: 5| Step: 8
Training loss: 1.3792030811309814
Validation loss: 1.9334275275468826

Epoch: 5| Step: 9
Training loss: 1.7583973407745361
Validation loss: 1.9444621255000432

Epoch: 5| Step: 10
Training loss: 1.4077808856964111
Validation loss: 1.9408168494701385

Epoch: 5| Step: 11
Training loss: 1.009265661239624
Validation loss: 1.9350809852282207

Epoch: 106| Step: 0
Training loss: 1.078891396522522
Validation loss: 1.9198751151561737

Epoch: 5| Step: 1
Training loss: 1.1658921241760254
Validation loss: 1.9574992110331852

Epoch: 5| Step: 2
Training loss: 1.5943681001663208
Validation loss: 1.9265998403231304

Epoch: 5| Step: 3
Training loss: 1.495441198348999
Validation loss: 1.920576959848404

Epoch: 5| Step: 4
Training loss: 1.5165154933929443
Validation loss: 1.974029317498207

Epoch: 5| Step: 5
Training loss: 1.6819241046905518
Validation loss: 2.0068613986174264

Epoch: 5| Step: 6
Training loss: 1.767869234085083
Validation loss: 1.9723666310310364

Epoch: 5| Step: 7
Training loss: 1.6242214441299438
Validation loss: 1.938536951939265

Epoch: 5| Step: 8
Training loss: 1.9908473491668701
Validation loss: 1.9569799949725468

Epoch: 5| Step: 9
Training loss: 1.6460508108139038
Validation loss: 1.9592925012111664

Epoch: 5| Step: 10
Training loss: 1.3123725652694702
Validation loss: 1.9530947307745616

Epoch: 5| Step: 11
Training loss: 0.9336719512939453
Validation loss: 1.9296552042166393

Epoch: 107| Step: 0
Training loss: 1.7504055500030518
Validation loss: 1.9447731425364811

Epoch: 5| Step: 1
Training loss: 1.5520350933074951
Validation loss: 1.8964359362920125

Epoch: 5| Step: 2
Training loss: 1.2681201696395874
Validation loss: 1.9133838216463726

Epoch: 5| Step: 3
Training loss: 1.2488677501678467
Validation loss: 1.8918495972951253

Epoch: 5| Step: 4
Training loss: 1.2889680862426758
Validation loss: 1.9062808404366176

Epoch: 5| Step: 5
Training loss: 1.0174610614776611
Validation loss: 1.9341905663410823

Epoch: 5| Step: 6
Training loss: 1.4748661518096924
Validation loss: 1.8475743035475414

Epoch: 5| Step: 7
Training loss: 1.7450714111328125
Validation loss: 1.9619245280822117

Epoch: 5| Step: 8
Training loss: 1.957236886024475
Validation loss: 1.9353876908620198

Epoch: 5| Step: 9
Training loss: 1.620894432067871
Validation loss: 1.9554271548986435

Epoch: 5| Step: 10
Training loss: 1.1857221126556396
Validation loss: 1.9363590727249782

Epoch: 5| Step: 11
Training loss: 1.0369362831115723
Validation loss: 1.9256127973397572

Epoch: 108| Step: 0
Training loss: 1.0522619485855103
Validation loss: 1.9853737900654476

Epoch: 5| Step: 1
Training loss: 1.4233804941177368
Validation loss: 1.9686959584554036

Epoch: 5| Step: 2
Training loss: 0.9523748159408569
Validation loss: 1.9408100843429565

Epoch: 5| Step: 3
Training loss: 2.198092460632324
Validation loss: 1.956284190217654

Epoch: 5| Step: 4
Training loss: 1.447295904159546
Validation loss: 1.9626333663860958

Epoch: 5| Step: 5
Training loss: 1.7924482822418213
Validation loss: 1.9553310374418895

Epoch: 5| Step: 6
Training loss: 1.6011097431182861
Validation loss: 1.989518091082573

Epoch: 5| Step: 7
Training loss: 1.682530164718628
Validation loss: 1.9509767939647038

Epoch: 5| Step: 8
Training loss: 1.3204715251922607
Validation loss: 1.9377796649932861

Epoch: 5| Step: 9
Training loss: 1.1354377269744873
Validation loss: 1.9681495030721028

Epoch: 5| Step: 10
Training loss: 1.6788206100463867
Validation loss: 1.9512038479248683

Epoch: 5| Step: 11
Training loss: 1.1165745258331299
Validation loss: 1.9807208428780239

Epoch: 109| Step: 0
Training loss: 1.1405560970306396
Validation loss: 1.944503903388977

Epoch: 5| Step: 1
Training loss: 1.6277856826782227
Validation loss: 1.9279493391513824

Epoch: 5| Step: 2
Training loss: 1.8638362884521484
Validation loss: 1.9542547514041264

Epoch: 5| Step: 3
Training loss: 1.9267009496688843
Validation loss: 1.9560237129529316

Epoch: 5| Step: 4
Training loss: 2.023712158203125
Validation loss: 1.8967790106932323

Epoch: 5| Step: 5
Training loss: 1.2519304752349854
Validation loss: 1.9209105769793193

Epoch: 5| Step: 6
Training loss: 1.5308340787887573
Validation loss: 1.9214880218108494

Epoch: 5| Step: 7
Training loss: 1.3410794734954834
Validation loss: 1.9682070761919022

Epoch: 5| Step: 8
Training loss: 1.5748307704925537
Validation loss: 1.927894766132037

Epoch: 5| Step: 9
Training loss: 1.387250542640686
Validation loss: 1.916406179467837

Epoch: 5| Step: 10
Training loss: 0.8335207104682922
Validation loss: 1.9152992814779282

Epoch: 5| Step: 11
Training loss: 2.1605124473571777
Validation loss: 1.9269105692704518

Epoch: 110| Step: 0
Training loss: 1.1261982917785645
Validation loss: 1.9510930677254994

Epoch: 5| Step: 1
Training loss: 1.17234206199646
Validation loss: 1.917898342013359

Epoch: 5| Step: 2
Training loss: 1.4098656177520752
Validation loss: 1.9497878402471542

Epoch: 5| Step: 3
Training loss: 1.7319351434707642
Validation loss: 1.9603875329097111

Epoch: 5| Step: 4
Training loss: 1.1098048686981201
Validation loss: 1.9575086285670598

Epoch: 5| Step: 5
Training loss: 1.6962449550628662
Validation loss: 1.9392469276984532

Epoch: 5| Step: 6
Training loss: 2.126976728439331
Validation loss: 1.9327499717473984

Epoch: 5| Step: 7
Training loss: 1.1683194637298584
Validation loss: 1.9601619243621826

Epoch: 5| Step: 8
Training loss: 1.4432293176651
Validation loss: 1.9830349534749985

Epoch: 5| Step: 9
Training loss: 1.4538120031356812
Validation loss: 1.9571368147929509

Epoch: 5| Step: 10
Training loss: 1.26090407371521
Validation loss: 1.9342177510261536

Epoch: 5| Step: 11
Training loss: 1.1606649160385132
Validation loss: 1.9921656449635823

Epoch: 111| Step: 0
Training loss: 2.02351713180542
Validation loss: 1.9959679295619328

Epoch: 5| Step: 1
Training loss: 1.3867290019989014
Validation loss: 2.028169905145963

Epoch: 5| Step: 2
Training loss: 0.832955002784729
Validation loss: 1.9249076346556346

Epoch: 5| Step: 3
Training loss: 1.4789530038833618
Validation loss: 1.953713282942772

Epoch: 5| Step: 4
Training loss: 1.250565528869629
Validation loss: 2.0100111911694207

Epoch: 5| Step: 5
Training loss: 1.826094627380371
Validation loss: 1.9743203818798065

Epoch: 5| Step: 6
Training loss: 1.4802316427230835
Validation loss: 2.0240466793378196

Epoch: 5| Step: 7
Training loss: 1.5776972770690918
Validation loss: 2.0117194751898446

Epoch: 5| Step: 8
Training loss: 1.4185044765472412
Validation loss: 2.029194841782252

Epoch: 5| Step: 9
Training loss: 1.1434524059295654
Validation loss: 2.016705796122551

Epoch: 5| Step: 10
Training loss: 2.2616279125213623
Validation loss: 2.0419321407874427

Epoch: 5| Step: 11
Training loss: 1.4926480054855347
Validation loss: 2.0429951747258506

Epoch: 112| Step: 0
Training loss: 1.8507000207901
Validation loss: 2.0583672722180686

Epoch: 5| Step: 1
Training loss: 2.198913335800171
Validation loss: 2.0009401539961496

Epoch: 5| Step: 2
Training loss: 1.2436878681182861
Validation loss: 1.984911948442459

Epoch: 5| Step: 3
Training loss: 1.5919296741485596
Validation loss: 1.9538964132467906

Epoch: 5| Step: 4
Training loss: 1.293755054473877
Validation loss: 2.0124915341536203

Epoch: 5| Step: 5
Training loss: 1.3664442300796509
Validation loss: 1.98201122879982

Epoch: 5| Step: 6
Training loss: 1.4092378616333008
Validation loss: 1.9813830852508545

Epoch: 5| Step: 7
Training loss: 1.2552239894866943
Validation loss: 1.9469521045684814

Epoch: 5| Step: 8
Training loss: 1.2261525392532349
Validation loss: 1.9650797545909882

Epoch: 5| Step: 9
Training loss: 1.619101881980896
Validation loss: 2.0360823472340903

Epoch: 5| Step: 10
Training loss: 1.3415597677230835
Validation loss: 1.9811636159817378

Epoch: 5| Step: 11
Training loss: 0.7391664981842041
Validation loss: 1.961527168750763

Epoch: 113| Step: 0
Training loss: 1.2295420169830322
Validation loss: 1.9610092292229335

Epoch: 5| Step: 1
Training loss: 1.559638261795044
Validation loss: 1.987235854069392

Epoch: 5| Step: 2
Training loss: 1.8312664031982422
Validation loss: 1.9730099985996883

Epoch: 5| Step: 3
Training loss: 1.1585590839385986
Validation loss: 1.9872053513924282

Epoch: 5| Step: 4
Training loss: 1.4994186162948608
Validation loss: 1.965307320157687

Epoch: 5| Step: 5
Training loss: 1.5681437253952026
Validation loss: 1.937643786271413

Epoch: 5| Step: 6
Training loss: 1.6341615915298462
Validation loss: 2.0142444421847663

Epoch: 5| Step: 7
Training loss: 1.0278676748275757
Validation loss: 1.9623096485932667

Epoch: 5| Step: 8
Training loss: 1.5658334493637085
Validation loss: 1.9309624085823696

Epoch: 5| Step: 9
Training loss: 1.5429232120513916
Validation loss: 1.9547899216413498

Epoch: 5| Step: 10
Training loss: 1.1177793741226196
Validation loss: 1.9730420957008998

Epoch: 5| Step: 11
Training loss: 2.2303850650787354
Validation loss: 1.9423751731713612

Epoch: 114| Step: 0
Training loss: 0.9059735536575317
Validation loss: 1.9732378621896107

Epoch: 5| Step: 1
Training loss: 1.061769723892212
Validation loss: 1.9881886790196102

Epoch: 5| Step: 2
Training loss: 1.3772728443145752
Validation loss: 1.9769610911607742

Epoch: 5| Step: 3
Training loss: 1.2182738780975342
Validation loss: 1.9501013805468876

Epoch: 5| Step: 4
Training loss: 1.4752861261367798
Validation loss: 1.9591745535532634

Epoch: 5| Step: 5
Training loss: 1.39823317527771
Validation loss: 1.9476243158181508

Epoch: 5| Step: 6
Training loss: 1.2903921604156494
Validation loss: 1.9393200824658077

Epoch: 5| Step: 7
Training loss: 2.0423038005828857
Validation loss: 1.948204144835472

Epoch: 5| Step: 8
Training loss: 1.3314049243927002
Validation loss: 1.9428709546724956

Epoch: 5| Step: 9
Training loss: 1.9361116886138916
Validation loss: 1.8988229483366013

Epoch: 5| Step: 10
Training loss: 1.3481734991073608
Validation loss: 1.9532154003779094

Epoch: 5| Step: 11
Training loss: 2.321202278137207
Validation loss: 1.9134148905674617

Epoch: 115| Step: 0
Training loss: 1.0372207164764404
Validation loss: 1.932215377688408

Epoch: 5| Step: 1
Training loss: 1.2332698106765747
Validation loss: 1.9757131040096283

Epoch: 5| Step: 2
Training loss: 2.152672529220581
Validation loss: 2.0200401892264686

Epoch: 5| Step: 3
Training loss: 1.4055230617523193
Validation loss: 1.9825437515974045

Epoch: 5| Step: 4
Training loss: 1.696557641029358
Validation loss: 1.9400577694177628

Epoch: 5| Step: 5
Training loss: 1.1915839910507202
Validation loss: 1.8982076048851013

Epoch: 5| Step: 6
Training loss: 1.523982286453247
Validation loss: 1.931580866376559

Epoch: 5| Step: 7
Training loss: 1.1319644451141357
Validation loss: 1.9427140305439632

Epoch: 5| Step: 8
Training loss: 1.6875126361846924
Validation loss: 1.980681374669075

Epoch: 5| Step: 9
Training loss: 1.4713563919067383
Validation loss: 1.9636295586824417

Epoch: 5| Step: 10
Training loss: 1.3863195180892944
Validation loss: 1.9432642112175624

Epoch: 5| Step: 11
Training loss: 2.1314268112182617
Validation loss: 1.9672355502843857

Epoch: 116| Step: 0
Training loss: 1.3817106485366821
Validation loss: 1.962890510757764

Epoch: 5| Step: 1
Training loss: 1.068264365196228
Validation loss: 1.9280747721592586

Epoch: 5| Step: 2
Training loss: 1.2027270793914795
Validation loss: 1.9056888868411381

Epoch: 5| Step: 3
Training loss: 0.9200774431228638
Validation loss: 1.9290275027354558

Epoch: 5| Step: 4
Training loss: 1.3374383449554443
Validation loss: 1.948469340801239

Epoch: 5| Step: 5
Training loss: 1.642136812210083
Validation loss: 1.9226677765448887

Epoch: 5| Step: 6
Training loss: 1.6532671451568604
Validation loss: 1.9712354441483815

Epoch: 5| Step: 7
Training loss: 1.092231035232544
Validation loss: 1.956521342198054

Epoch: 5| Step: 8
Training loss: 1.457068681716919
Validation loss: 1.9533260116974513

Epoch: 5| Step: 9
Training loss: 1.4015642404556274
Validation loss: 1.9163012405236561

Epoch: 5| Step: 10
Training loss: 1.8806965351104736
Validation loss: 1.8950184335311253

Epoch: 5| Step: 11
Training loss: 1.7107172012329102
Validation loss: 1.8819508651892345

Epoch: 117| Step: 0
Training loss: 1.4332854747772217
Validation loss: 1.9188712139924367

Epoch: 5| Step: 1
Training loss: 1.4049806594848633
Validation loss: 1.9243314613898594

Epoch: 5| Step: 2
Training loss: 1.087132453918457
Validation loss: 1.9201116512219112

Epoch: 5| Step: 3
Training loss: 1.9172112941741943
Validation loss: 1.9083903133869171

Epoch: 5| Step: 4
Training loss: 1.0064064264297485
Validation loss: 1.9519453545411427

Epoch: 5| Step: 5
Training loss: 1.098576545715332
Validation loss: 1.9286084175109863

Epoch: 5| Step: 6
Training loss: 1.4303104877471924
Validation loss: 1.9135161290566127

Epoch: 5| Step: 7
Training loss: 1.1883699893951416
Validation loss: 1.959623098373413

Epoch: 5| Step: 8
Training loss: 1.1585012674331665
Validation loss: 1.9219642877578735

Epoch: 5| Step: 9
Training loss: 1.5170507431030273
Validation loss: 1.9832755674918492

Epoch: 5| Step: 10
Training loss: 1.6928268671035767
Validation loss: 1.97401229540507

Epoch: 5| Step: 11
Training loss: 1.732470989227295
Validation loss: 1.9781165917714436

Epoch: 118| Step: 0
Training loss: 1.47316575050354
Validation loss: 1.964680512746175

Epoch: 5| Step: 1
Training loss: 1.0389316082000732
Validation loss: 1.9321396400531132

Epoch: 5| Step: 2
Training loss: 1.3814284801483154
Validation loss: 1.9939532180627186

Epoch: 5| Step: 3
Training loss: 1.4816030263900757
Validation loss: 1.9814408471186955

Epoch: 5| Step: 4
Training loss: 1.2645723819732666
Validation loss: 1.9284884333610535

Epoch: 5| Step: 5
Training loss: 0.904720664024353
Validation loss: 1.956321820616722

Epoch: 5| Step: 6
Training loss: 1.7530889511108398
Validation loss: 1.9485828926165898

Epoch: 5| Step: 7
Training loss: 1.5048272609710693
Validation loss: 1.9384064475695293

Epoch: 5| Step: 8
Training loss: 1.5922783613204956
Validation loss: 1.92104771733284

Epoch: 5| Step: 9
Training loss: 1.2564129829406738
Validation loss: 1.9618358214696248

Epoch: 5| Step: 10
Training loss: 1.342095136642456
Validation loss: 1.928358018398285

Epoch: 5| Step: 11
Training loss: 2.0416407585144043
Validation loss: 1.9550448507070541

Epoch: 119| Step: 0
Training loss: 1.1701971292495728
Validation loss: 1.8887320011854172

Epoch: 5| Step: 1
Training loss: 1.8602187633514404
Validation loss: 1.9953212291002274

Epoch: 5| Step: 2
Training loss: 1.0160071849822998
Validation loss: 1.9232859114805858

Epoch: 5| Step: 3
Training loss: 1.1905667781829834
Validation loss: 1.9096330106258392

Epoch: 5| Step: 4
Training loss: 1.218148946762085
Validation loss: 1.9545651376247406

Epoch: 5| Step: 5
Training loss: 1.4050166606903076
Validation loss: 1.9498162120580673

Epoch: 5| Step: 6
Training loss: 1.1398876905441284
Validation loss: 1.9251332978407543

Epoch: 5| Step: 7
Training loss: 1.10866379737854
Validation loss: 1.9603986243406932

Epoch: 5| Step: 8
Training loss: 1.4525136947631836
Validation loss: 1.9713646918535233

Epoch: 5| Step: 9
Training loss: 1.3757343292236328
Validation loss: 1.9473627706368764

Epoch: 5| Step: 10
Training loss: 1.5080652236938477
Validation loss: 1.8845421373844147

Epoch: 5| Step: 11
Training loss: 2.9270148277282715
Validation loss: 1.936329538623492

Epoch: 120| Step: 0
Training loss: 1.658158540725708
Validation loss: 1.9403993636369705

Epoch: 5| Step: 1
Training loss: 1.226710557937622
Validation loss: 1.9187245815992355

Epoch: 5| Step: 2
Training loss: 2.1560142040252686
Validation loss: 1.9378898044427235

Epoch: 5| Step: 3
Training loss: 1.186115026473999
Validation loss: 1.9468127985795338

Epoch: 5| Step: 4
Training loss: 1.5397852659225464
Validation loss: 1.9629619518915813

Epoch: 5| Step: 5
Training loss: 1.5558544397354126
Validation loss: 1.8986156086126964

Epoch: 5| Step: 6
Training loss: 1.1147526502609253
Validation loss: 1.9263752003510792

Epoch: 5| Step: 7
Training loss: 0.9245441555976868
Validation loss: 1.935700277487437

Epoch: 5| Step: 8
Training loss: 1.3847947120666504
Validation loss: 1.9140582233667374

Epoch: 5| Step: 9
Training loss: 0.9875281453132629
Validation loss: 1.966096967458725

Epoch: 5| Step: 10
Training loss: 1.0096713304519653
Validation loss: 1.9510155816872914

Epoch: 5| Step: 11
Training loss: 0.7270174026489258
Validation loss: 1.9366134355465572

Epoch: 121| Step: 0
Training loss: 1.2313288450241089
Validation loss: 1.9177041798830032

Epoch: 5| Step: 1
Training loss: 1.4915845394134521
Validation loss: 1.9762910852829616

Epoch: 5| Step: 2
Training loss: 1.6565845012664795
Validation loss: 1.956310858329137

Epoch: 5| Step: 3
Training loss: 0.9079896807670593
Validation loss: 1.9639560083548229

Epoch: 5| Step: 4
Training loss: 0.9886639714241028
Validation loss: 1.9303127825260162

Epoch: 5| Step: 5
Training loss: 1.1406145095825195
Validation loss: 1.9256910383701324

Epoch: 5| Step: 6
Training loss: 2.1514105796813965
Validation loss: 2.025409256418546

Epoch: 5| Step: 7
Training loss: 1.0494980812072754
Validation loss: 1.9493629932403564

Epoch: 5| Step: 8
Training loss: 1.3945163488388062
Validation loss: 1.9341757794221242

Epoch: 5| Step: 9
Training loss: 1.0300078392028809
Validation loss: 1.9635404894749324

Epoch: 5| Step: 10
Training loss: 1.2497673034667969
Validation loss: 1.9270941664775212

Epoch: 5| Step: 11
Training loss: 2.366882801055908
Validation loss: 1.965517486135165

Epoch: 122| Step: 0
Training loss: 1.3784314393997192
Validation loss: 1.953472798069318

Epoch: 5| Step: 1
Training loss: 0.9668850898742676
Validation loss: 1.924904505411784

Epoch: 5| Step: 2
Training loss: 1.5809109210968018
Validation loss: 1.943792884548505

Epoch: 5| Step: 3
Training loss: 1.2548408508300781
Validation loss: 1.9686124126116435

Epoch: 5| Step: 4
Training loss: 1.3288860321044922
Validation loss: 1.9393798808256786

Epoch: 5| Step: 5
Training loss: 1.4383492469787598
Validation loss: 1.9464776664972305

Epoch: 5| Step: 6
Training loss: 1.4887930154800415
Validation loss: 1.9599132885535557

Epoch: 5| Step: 7
Training loss: 1.4059476852416992
Validation loss: 1.9540531535943348

Epoch: 5| Step: 8
Training loss: 0.8085119128227234
Validation loss: 1.87641375263532

Epoch: 5| Step: 9
Training loss: 1.1858413219451904
Validation loss: 1.936876008907954

Epoch: 5| Step: 10
Training loss: 1.1730377674102783
Validation loss: 1.9665125509103139

Epoch: 5| Step: 11
Training loss: 0.6173444986343384
Validation loss: 1.9504526158173878

Epoch: 123| Step: 0
Training loss: 1.1331671476364136
Validation loss: 1.9738333970308304

Epoch: 5| Step: 1
Training loss: 1.3716366291046143
Validation loss: 1.9959386835495632

Epoch: 5| Step: 2
Training loss: 0.9476349949836731
Validation loss: 1.8796802411476772

Epoch: 5| Step: 3
Training loss: 1.3170703649520874
Validation loss: 1.9607110023498535

Epoch: 5| Step: 4
Training loss: 1.302327036857605
Validation loss: 1.9269283364216487

Epoch: 5| Step: 5
Training loss: 1.0580960512161255
Validation loss: 1.9433831721544266

Epoch: 5| Step: 6
Training loss: 1.6286693811416626
Validation loss: 1.904832015434901

Epoch: 5| Step: 7
Training loss: 1.625927209854126
Validation loss: 1.917370359102885

Epoch: 5| Step: 8
Training loss: 0.7171663045883179
Validation loss: 2.0059207876523337

Epoch: 5| Step: 9
Training loss: 1.4910264015197754
Validation loss: 1.9477327466011047

Epoch: 5| Step: 10
Training loss: 1.6742267608642578
Validation loss: 1.9374127437671025

Epoch: 5| Step: 11
Training loss: 2.436058759689331
Validation loss: 1.9138361314932506

Epoch: 124| Step: 0
Training loss: 1.4679522514343262
Validation loss: 1.9801851759354274

Epoch: 5| Step: 1
Training loss: 1.2136576175689697
Validation loss: 1.957545633117358

Epoch: 5| Step: 2
Training loss: 1.4098727703094482
Validation loss: 1.9623104333877563

Epoch: 5| Step: 3
Training loss: 0.8889980316162109
Validation loss: 1.964935724933942

Epoch: 5| Step: 4
Training loss: 1.6845157146453857
Validation loss: 1.9668730596701305

Epoch: 5| Step: 5
Training loss: 0.9632657766342163
Validation loss: 1.9697457253932953

Epoch: 5| Step: 6
Training loss: 1.181898832321167
Validation loss: 2.0056181649367013

Epoch: 5| Step: 7
Training loss: 1.6059551239013672
Validation loss: 2.005020797252655

Epoch: 5| Step: 8
Training loss: 1.2649399042129517
Validation loss: 1.9347447405258815

Epoch: 5| Step: 9
Training loss: 1.483400583267212
Validation loss: 1.9260919292767842

Epoch: 5| Step: 10
Training loss: 1.3601233959197998
Validation loss: 1.8816746572653453

Epoch: 5| Step: 11
Training loss: 1.137482762336731
Validation loss: 1.9098438322544098

Epoch: 125| Step: 0
Training loss: 1.1151598691940308
Validation loss: 1.9286086161931355

Epoch: 5| Step: 1
Training loss: 1.4257341623306274
Validation loss: 1.9429556628068287

Epoch: 5| Step: 2
Training loss: 0.886142373085022
Validation loss: 1.9728244443734486

Epoch: 5| Step: 3
Training loss: 1.907271146774292
Validation loss: 1.94834399720033

Epoch: 5| Step: 4
Training loss: 1.1647647619247437
Validation loss: 1.9590357293685277

Epoch: 5| Step: 5
Training loss: 1.0511691570281982
Validation loss: 1.9322813302278519

Epoch: 5| Step: 6
Training loss: 1.424041748046875
Validation loss: 1.9251565386851628

Epoch: 5| Step: 7
Training loss: 1.2492425441741943
Validation loss: 1.9375543942054112

Epoch: 5| Step: 8
Training loss: 1.2087182998657227
Validation loss: 1.9749812086423237

Epoch: 5| Step: 9
Training loss: 1.4847121238708496
Validation loss: 1.8966541041930516

Epoch: 5| Step: 10
Training loss: 1.1813749074935913
Validation loss: 1.9859264194965363

Epoch: 5| Step: 11
Training loss: 2.524077892303467
Validation loss: 1.9048563192288082

Epoch: 126| Step: 0
Training loss: 1.1133596897125244
Validation loss: 1.8607735335826874

Epoch: 5| Step: 1
Training loss: 1.4357922077178955
Validation loss: 1.9121999144554138

Epoch: 5| Step: 2
Training loss: 1.1973544359207153
Validation loss: 1.9117761452992756

Epoch: 5| Step: 3
Training loss: 0.6974695920944214
Validation loss: 1.9068645338217418

Epoch: 5| Step: 4
Training loss: 1.0380451679229736
Validation loss: 1.8944579114516575

Epoch: 5| Step: 5
Training loss: 1.29935622215271
Validation loss: 1.8968369215726852

Epoch: 5| Step: 6
Training loss: 1.179208517074585
Validation loss: 1.9926392783721287

Epoch: 5| Step: 7
Training loss: 1.4991986751556396
Validation loss: 1.9598903705676396

Epoch: 5| Step: 8
Training loss: 1.6940011978149414
Validation loss: 1.9985398550828297

Epoch: 5| Step: 9
Training loss: 1.2759615182876587
Validation loss: 1.9543993671735127

Epoch: 5| Step: 10
Training loss: 1.1281137466430664
Validation loss: 1.9622707217931747

Epoch: 5| Step: 11
Training loss: 1.2662794589996338
Validation loss: 1.9609039574861526

Epoch: 127| Step: 0
Training loss: 1.2651970386505127
Validation loss: 1.9722846895456314

Epoch: 5| Step: 1
Training loss: 1.0638835430145264
Validation loss: 1.9647427797317505

Epoch: 5| Step: 2
Training loss: 1.4771727323532104
Validation loss: 1.9672151654958725

Epoch: 5| Step: 3
Training loss: 1.6796987056732178
Validation loss: 1.993092492222786

Epoch: 5| Step: 4
Training loss: 1.1398462057113647
Validation loss: 1.938605527083079

Epoch: 5| Step: 5
Training loss: 1.0186822414398193
Validation loss: 1.919172316789627

Epoch: 5| Step: 6
Training loss: 1.1703630685806274
Validation loss: 1.9785688370466232

Epoch: 5| Step: 7
Training loss: 0.9477909803390503
Validation loss: 1.9680359065532684

Epoch: 5| Step: 8
Training loss: 1.3374830484390259
Validation loss: 2.010836308201154

Epoch: 5| Step: 9
Training loss: 0.9386510848999023
Validation loss: 2.008454531431198

Epoch: 5| Step: 10
Training loss: 1.7736749649047852
Validation loss: 2.0270105401674905

Epoch: 5| Step: 11
Training loss: 1.1022542715072632
Validation loss: 1.989458257953326

Epoch: 128| Step: 0
Training loss: 1.1851520538330078
Validation loss: 1.969156821568807

Epoch: 5| Step: 1
Training loss: 1.273646593093872
Validation loss: 1.958274116118749

Epoch: 5| Step: 2
Training loss: 1.2741467952728271
Validation loss: 1.9106709162394206

Epoch: 5| Step: 3
Training loss: 1.381506085395813
Validation loss: 2.0232382118701935

Epoch: 5| Step: 4
Training loss: 1.2130372524261475
Validation loss: 2.0621362378199897

Epoch: 5| Step: 5
Training loss: 0.9302867650985718
Validation loss: 1.9413877228895824

Epoch: 5| Step: 6
Training loss: 1.2151353359222412
Validation loss: 1.9931258658568065

Epoch: 5| Step: 7
Training loss: 0.7183117866516113
Validation loss: 1.9807110180457432

Epoch: 5| Step: 8
Training loss: 1.3502509593963623
Validation loss: 1.9390653272469838

Epoch: 5| Step: 9
Training loss: 1.7851030826568604
Validation loss: 1.9652775079011917

Epoch: 5| Step: 10
Training loss: 1.3512126207351685
Validation loss: 2.0438380936781564

Epoch: 5| Step: 11
Training loss: 1.5431437492370605
Validation loss: 2.007035478949547

Epoch: 129| Step: 0
Training loss: 1.188434362411499
Validation loss: 2.0785396297772727

Epoch: 5| Step: 1
Training loss: 0.815826416015625
Validation loss: 1.9880223621924717

Epoch: 5| Step: 2
Training loss: 1.5721654891967773
Validation loss: 1.9892154037952423

Epoch: 5| Step: 3
Training loss: 1.1452105045318604
Validation loss: 1.9319994350274403

Epoch: 5| Step: 4
Training loss: 1.3487269878387451
Validation loss: 1.9842921247084935

Epoch: 5| Step: 5
Training loss: 1.4706003665924072
Validation loss: 1.9718549648920696

Epoch: 5| Step: 6
Training loss: 1.2817338705062866
Validation loss: 1.9617957025766373

Epoch: 5| Step: 7
Training loss: 1.384993314743042
Validation loss: 1.9962370196978252

Epoch: 5| Step: 8
Training loss: 1.42482590675354
Validation loss: 1.9707219749689102

Epoch: 5| Step: 9
Training loss: 1.1828947067260742
Validation loss: 1.9517652193705242

Epoch: 5| Step: 10
Training loss: 1.131615400314331
Validation loss: 1.9709154069423676

Epoch: 5| Step: 11
Training loss: 1.1210782527923584
Validation loss: 1.9364653279383977

Epoch: 130| Step: 0
Training loss: 1.6981887817382812
Validation loss: 1.9691996326049168

Epoch: 5| Step: 1
Training loss: 1.2700048685073853
Validation loss: 1.9603346139192581

Epoch: 5| Step: 2
Training loss: 1.1578996181488037
Validation loss: 1.9614242017269135

Epoch: 5| Step: 3
Training loss: 1.087477445602417
Validation loss: 1.953008050719897

Epoch: 5| Step: 4
Training loss: 1.4339466094970703
Validation loss: 1.9559815923372905

Epoch: 5| Step: 5
Training loss: 1.4509867429733276
Validation loss: 1.9582901100317638

Epoch: 5| Step: 6
Training loss: 1.5438603162765503
Validation loss: 1.9829806983470917

Epoch: 5| Step: 7
Training loss: 0.9489145278930664
Validation loss: 1.9385478148857753

Epoch: 5| Step: 8
Training loss: 1.3859493732452393
Validation loss: 1.9357750167449315

Epoch: 5| Step: 9
Training loss: 1.101718544960022
Validation loss: 1.9480938365062077

Epoch: 5| Step: 10
Training loss: 0.9821431040763855
Validation loss: 1.9559063812096913

Epoch: 5| Step: 11
Training loss: 0.4606921076774597
Validation loss: 1.9774196247259777

Epoch: 131| Step: 0
Training loss: 0.9692686200141907
Validation loss: 2.007797196507454

Epoch: 5| Step: 1
Training loss: 0.9527737498283386
Validation loss: 2.0039432694514594

Epoch: 5| Step: 2
Training loss: 0.7889019250869751
Validation loss: 1.9012258847554524

Epoch: 5| Step: 3
Training loss: 1.5991942882537842
Validation loss: 1.9278475691874821

Epoch: 5| Step: 4
Training loss: 1.1799490451812744
Validation loss: 1.9479552259047825

Epoch: 5| Step: 5
Training loss: 1.2316805124282837
Validation loss: 1.9430653154850006

Epoch: 5| Step: 6
Training loss: 1.2410056591033936
Validation loss: 1.966268276174863

Epoch: 5| Step: 7
Training loss: 1.0792720317840576
Validation loss: 1.9158568282922108

Epoch: 5| Step: 8
Training loss: 1.591819405555725
Validation loss: 1.9235135614871979

Epoch: 5| Step: 9
Training loss: 1.2809584140777588
Validation loss: 1.907294233640035

Epoch: 5| Step: 10
Training loss: 1.0584865808486938
Validation loss: 1.9681371649106343

Epoch: 5| Step: 11
Training loss: 2.180044174194336
Validation loss: 1.9501688778400421

Epoch: 132| Step: 0
Training loss: 0.7855726480484009
Validation loss: 1.9404798050721486

Epoch: 5| Step: 1
Training loss: 0.9473785161972046
Validation loss: 1.9491197615861893

Epoch: 5| Step: 2
Training loss: 1.0281141996383667
Validation loss: 1.9055645565191905

Epoch: 5| Step: 3
Training loss: 0.9917501211166382
Validation loss: 1.9531611253817875

Epoch: 5| Step: 4
Training loss: 1.4231966733932495
Validation loss: 1.9113849798838298

Epoch: 5| Step: 5
Training loss: 0.8325215578079224
Validation loss: 1.9116637607415516

Epoch: 5| Step: 6
Training loss: 1.5352132320404053
Validation loss: 1.8558001170555751

Epoch: 5| Step: 7
Training loss: 1.4789453744888306
Validation loss: 1.9823347926139832

Epoch: 5| Step: 8
Training loss: 1.2664426565170288
Validation loss: 1.9425893624623616

Epoch: 5| Step: 9
Training loss: 1.5642417669296265
Validation loss: 1.9367740750312805

Epoch: 5| Step: 10
Training loss: 1.2808289527893066
Validation loss: 1.8572800656159718

Epoch: 5| Step: 11
Training loss: 0.7032489776611328
Validation loss: 1.8974779099225998

Epoch: 133| Step: 0
Training loss: 1.2072336673736572
Validation loss: 1.9578029563029606

Epoch: 5| Step: 1
Training loss: 0.7526489496231079
Validation loss: 2.069636583328247

Epoch: 5| Step: 2
Training loss: 1.2053031921386719
Validation loss: 2.1159748882055283

Epoch: 5| Step: 3
Training loss: 1.859020471572876
Validation loss: 2.059721310933431

Epoch: 5| Step: 4
Training loss: 1.5292088985443115
Validation loss: 2.0525636275609336

Epoch: 5| Step: 5
Training loss: 1.4165552854537964
Validation loss: 2.0204937855402627

Epoch: 5| Step: 6
Training loss: 1.0691471099853516
Validation loss: 1.924640382329623

Epoch: 5| Step: 7
Training loss: 1.2674378156661987
Validation loss: 1.9617059181133907

Epoch: 5| Step: 8
Training loss: 1.4138368368148804
Validation loss: 1.959224209189415

Epoch: 5| Step: 9
Training loss: 1.8435205221176147
Validation loss: 1.9957869599262874

Epoch: 5| Step: 10
Training loss: 1.153678297996521
Validation loss: 2.0116177946329117

Epoch: 5| Step: 11
Training loss: 1.5022821426391602
Validation loss: 1.9549195269743602

Epoch: 134| Step: 0
Training loss: 1.2008224725723267
Validation loss: 1.924848015109698

Epoch: 5| Step: 1
Training loss: 1.030443549156189
Validation loss: 1.9393891841173172

Epoch: 5| Step: 2
Training loss: 1.7095482349395752
Validation loss: 1.959645261367162

Epoch: 5| Step: 3
Training loss: 1.0860106945037842
Validation loss: 1.993559996287028

Epoch: 5| Step: 4
Training loss: 1.1266117095947266
Validation loss: 2.0832144369681678

Epoch: 5| Step: 5
Training loss: 1.5659748315811157
Validation loss: 2.0671403408050537

Epoch: 5| Step: 6
Training loss: 1.1036380529403687
Validation loss: 2.0172695765892663

Epoch: 5| Step: 7
Training loss: 1.7404224872589111
Validation loss: 2.0169190168380737

Epoch: 5| Step: 8
Training loss: 1.44756281375885
Validation loss: 1.9173803329467773

Epoch: 5| Step: 9
Training loss: 1.1749743223190308
Validation loss: 1.9507120847702026

Epoch: 5| Step: 10
Training loss: 0.7838922739028931
Validation loss: 1.947626491387685

Epoch: 5| Step: 11
Training loss: 0.5965566635131836
Validation loss: 1.9481003532807033

Epoch: 135| Step: 0
Training loss: 0.9945827722549438
Validation loss: 1.992275819182396

Epoch: 5| Step: 1
Training loss: 1.10648775100708
Validation loss: 1.992166355252266

Epoch: 5| Step: 2
Training loss: 1.2594860792160034
Validation loss: 1.9992110629876454

Epoch: 5| Step: 3
Training loss: 1.4734761714935303
Validation loss: 1.9455817490816116

Epoch: 5| Step: 4
Training loss: 0.8949405550956726
Validation loss: 1.9107255339622498

Epoch: 5| Step: 5
Training loss: 1.3995137214660645
Validation loss: 1.9378788818915684

Epoch: 5| Step: 6
Training loss: 1.1850206851959229
Validation loss: 1.954011137286822

Epoch: 5| Step: 7
Training loss: 1.6546434164047241
Validation loss: 2.015042985479037

Epoch: 5| Step: 8
Training loss: 1.203879952430725
Validation loss: 1.9720988770325978

Epoch: 5| Step: 9
Training loss: 1.6168327331542969
Validation loss: 2.0219200948874154

Epoch: 5| Step: 10
Training loss: 1.5830141305923462
Validation loss: 1.9964427252610524

Epoch: 5| Step: 11
Training loss: 0.828205943107605
Validation loss: 1.9408175547917683

Epoch: 136| Step: 0
Training loss: 1.1778331995010376
Validation loss: 1.9535707632700603

Epoch: 5| Step: 1
Training loss: 1.6344448328018188
Validation loss: 1.9788855363925297

Epoch: 5| Step: 2
Training loss: 1.1355328559875488
Validation loss: 2.034597565730413

Epoch: 5| Step: 3
Training loss: 1.50430166721344
Validation loss: 1.9699835727612178

Epoch: 5| Step: 4
Training loss: 1.114903450012207
Validation loss: 1.935364544391632

Epoch: 5| Step: 5
Training loss: 1.2054656744003296
Validation loss: 1.9366635779539745

Epoch: 5| Step: 6
Training loss: 1.0398786067962646
Validation loss: 1.9515111297369003

Epoch: 5| Step: 7
Training loss: 1.470343828201294
Validation loss: 1.944605603814125

Epoch: 5| Step: 8
Training loss: 1.5496947765350342
Validation loss: 1.9629761675993602

Epoch: 5| Step: 9
Training loss: 1.3703569173812866
Validation loss: 1.9833969225486119

Epoch: 5| Step: 10
Training loss: 0.5045285224914551
Validation loss: 1.8677923878033955

Epoch: 5| Step: 11
Training loss: 1.2368738651275635
Validation loss: 1.9262540986140568

Epoch: 137| Step: 0
Training loss: 1.1213834285736084
Validation loss: 1.9252258489529293

Epoch: 5| Step: 1
Training loss: 1.0650882720947266
Validation loss: 1.9900771379470825

Epoch: 5| Step: 2
Training loss: 1.0073742866516113
Validation loss: 2.0102713952461877

Epoch: 5| Step: 3
Training loss: 1.0517194271087646
Validation loss: 2.004168137907982

Epoch: 5| Step: 4
Training loss: 1.2844899892807007
Validation loss: 1.9557197789351146

Epoch: 5| Step: 5
Training loss: 0.8839018940925598
Validation loss: 1.9425023198127747

Epoch: 5| Step: 6
Training loss: 1.4218279123306274
Validation loss: 1.9867124209801357

Epoch: 5| Step: 7
Training loss: 0.9876816868782043
Validation loss: 1.9993885109821956

Epoch: 5| Step: 8
Training loss: 1.328381896018982
Validation loss: 1.9634513904651005

Epoch: 5| Step: 9
Training loss: 1.7700512409210205
Validation loss: 1.9981657316287358

Epoch: 5| Step: 10
Training loss: 1.133101463317871
Validation loss: 1.9760141372680664

Epoch: 5| Step: 11
Training loss: 0.9020850658416748
Validation loss: 1.9330542633930843

Epoch: 138| Step: 0
Training loss: 1.3866394758224487
Validation loss: 1.9075973530610402

Epoch: 5| Step: 1
Training loss: 1.8962116241455078
Validation loss: 1.990314284960429

Epoch: 5| Step: 2
Training loss: 1.314047932624817
Validation loss: 2.02481480439504

Epoch: 5| Step: 3
Training loss: 1.3418619632720947
Validation loss: 2.0611529548962912

Epoch: 5| Step: 4
Training loss: 1.4626072645187378
Validation loss: 2.0391124387582145

Epoch: 5| Step: 5
Training loss: 1.121884822845459
Validation loss: 1.9767285287380219

Epoch: 5| Step: 6
Training loss: 1.0935604572296143
Validation loss: 1.940869743625323

Epoch: 5| Step: 7
Training loss: 0.6981384754180908
Validation loss: 1.9349604845046997

Epoch: 5| Step: 8
Training loss: 0.7728900909423828
Validation loss: 2.020433003703753

Epoch: 5| Step: 9
Training loss: 1.1624611616134644
Validation loss: 2.064215441544851

Epoch: 5| Step: 10
Training loss: 1.2353745698928833
Validation loss: 2.0121967246135077

Epoch: 5| Step: 11
Training loss: 2.0325205326080322
Validation loss: 2.083775927623113

Epoch: 139| Step: 0
Training loss: 1.1019344329833984
Validation loss: 2.124066010117531

Epoch: 5| Step: 1
Training loss: 1.3674993515014648
Validation loss: 2.0488602916399636

Epoch: 5| Step: 2
Training loss: 1.056726336479187
Validation loss: 2.1330280105272927

Epoch: 5| Step: 3
Training loss: 1.0225461721420288
Validation loss: 1.9976708243290584

Epoch: 5| Step: 4
Training loss: 1.6889909505844116
Validation loss: 1.9453794012467067

Epoch: 5| Step: 5
Training loss: 1.276672124862671
Validation loss: 1.9553843835989635

Epoch: 5| Step: 6
Training loss: 0.7909743785858154
Validation loss: 1.9709064463774364

Epoch: 5| Step: 7
Training loss: 1.4343533515930176
Validation loss: 2.0091291119654975

Epoch: 5| Step: 8
Training loss: 1.6271286010742188
Validation loss: 2.078038568298022

Epoch: 5| Step: 9
Training loss: 1.8375192880630493
Validation loss: 2.060515816013018

Epoch: 5| Step: 10
Training loss: 1.1326252222061157
Validation loss: 2.0255428751309714

Epoch: 5| Step: 11
Training loss: 1.1991918087005615
Validation loss: 1.9826133648554485

Epoch: 140| Step: 0
Training loss: 1.1535618305206299
Validation loss: 1.9958528876304626

Epoch: 5| Step: 1
Training loss: 0.584322452545166
Validation loss: 1.9632368981838226

Epoch: 5| Step: 2
Training loss: 1.2145768404006958
Validation loss: 1.995622495810191

Epoch: 5| Step: 3
Training loss: 1.9649269580841064
Validation loss: 2.013522187868754

Epoch: 5| Step: 4
Training loss: 1.8020431995391846
Validation loss: 2.0559045424064

Epoch: 5| Step: 5
Training loss: 1.1226222515106201
Validation loss: 1.9421863704919815

Epoch: 5| Step: 6
Training loss: 1.089313268661499
Validation loss: 1.9554986009995143

Epoch: 5| Step: 7
Training loss: 1.1414449214935303
Validation loss: 1.9228109270334244

Epoch: 5| Step: 8
Training loss: 1.427058458328247
Validation loss: 1.9829940994580586

Epoch: 5| Step: 9
Training loss: 0.9839008450508118
Validation loss: 1.9999479800462723

Epoch: 5| Step: 10
Training loss: 1.2035739421844482
Validation loss: 1.9760835121075313

Epoch: 5| Step: 11
Training loss: 1.2711817026138306
Validation loss: 2.0129836897055307

Epoch: 141| Step: 0
Training loss: 1.0606205463409424
Validation loss: 1.952944666147232

Epoch: 5| Step: 1
Training loss: 0.9501826167106628
Validation loss: 1.9508825689554214

Epoch: 5| Step: 2
Training loss: 1.2760990858078003
Validation loss: 1.9797558238108952

Epoch: 5| Step: 3
Training loss: 1.352765440940857
Validation loss: 1.97629776597023

Epoch: 5| Step: 4
Training loss: 0.7355536222457886
Validation loss: 2.0031187931696572

Epoch: 5| Step: 5
Training loss: 1.2034046649932861
Validation loss: 1.9759817918141682

Epoch: 5| Step: 6
Training loss: 0.928184986114502
Validation loss: 1.9301838527123134

Epoch: 5| Step: 7
Training loss: 1.711251974105835
Validation loss: 1.9459769576787949

Epoch: 5| Step: 8
Training loss: 1.3273890018463135
Validation loss: 1.9273548523585002

Epoch: 5| Step: 9
Training loss: 1.2557041645050049
Validation loss: 1.9147584388653438

Epoch: 5| Step: 10
Training loss: 1.0449515581130981
Validation loss: 1.9548810720443726

Epoch: 5| Step: 11
Training loss: 1.0777716636657715
Validation loss: 1.9261363645394642

Epoch: 142| Step: 0
Training loss: 1.2647734880447388
Validation loss: 1.9336621661980946

Epoch: 5| Step: 1
Training loss: 0.935746967792511
Validation loss: 1.962102343638738

Epoch: 5| Step: 2
Training loss: 1.2653042078018188
Validation loss: 1.9872311900059383

Epoch: 5| Step: 3
Training loss: 1.1654225587844849
Validation loss: 1.9931727200746536

Epoch: 5| Step: 4
Training loss: 0.7538481950759888
Validation loss: 1.9466801285743713

Epoch: 5| Step: 5
Training loss: 1.584733247756958
Validation loss: 1.941592623790105

Epoch: 5| Step: 6
Training loss: 1.1165168285369873
Validation loss: 1.971051553885142

Epoch: 5| Step: 7
Training loss: 1.3718550205230713
Validation loss: 1.9995570878187816

Epoch: 5| Step: 8
Training loss: 1.1830713748931885
Validation loss: 1.9443463136752446

Epoch: 5| Step: 9
Training loss: 0.8930767178535461
Validation loss: 2.0642231504122415

Epoch: 5| Step: 10
Training loss: 1.192495346069336
Validation loss: 1.9282717754443486

Epoch: 5| Step: 11
Training loss: 1.0670751333236694
Validation loss: 2.016068776448568

Epoch: 143| Step: 0
Training loss: 1.0134851932525635
Validation loss: 1.9721671988566716

Epoch: 5| Step: 1
Training loss: 1.1625250577926636
Validation loss: 1.9839141964912415

Epoch: 5| Step: 2
Training loss: 1.6049506664276123
Validation loss: 2.001940364638964

Epoch: 5| Step: 3
Training loss: 1.003894567489624
Validation loss: 2.0125616689523063

Epoch: 5| Step: 4
Training loss: 1.3645483255386353
Validation loss: 1.9696512122948964

Epoch: 5| Step: 5
Training loss: 1.103357195854187
Validation loss: 1.9219642678896587

Epoch: 5| Step: 6
Training loss: 0.9759984016418457
Validation loss: 1.9427147954702377

Epoch: 5| Step: 7
Training loss: 1.416182279586792
Validation loss: 1.996699869632721

Epoch: 5| Step: 8
Training loss: 0.7803179025650024
Validation loss: 1.9792729715506236

Epoch: 5| Step: 9
Training loss: 0.965807318687439
Validation loss: 1.937698210279147

Epoch: 5| Step: 10
Training loss: 0.9543192982673645
Validation loss: 1.9060140003760655

Epoch: 5| Step: 11
Training loss: 1.3345444202423096
Validation loss: 1.910136158267657

Epoch: 144| Step: 0
Training loss: 1.1964434385299683
Validation loss: 1.9320440987745922

Epoch: 5| Step: 1
Training loss: 0.8839906454086304
Validation loss: 1.9089565575122833

Epoch: 5| Step: 2
Training loss: 1.2138465642929077
Validation loss: 1.9505747258663177

Epoch: 5| Step: 3
Training loss: 1.1369667053222656
Validation loss: 1.9269750118255615

Epoch: 5| Step: 4
Training loss: 1.4664310216903687
Validation loss: 1.9047327438990276

Epoch: 5| Step: 5
Training loss: 0.7187856435775757
Validation loss: 1.9040145923693974

Epoch: 5| Step: 6
Training loss: 0.8512107729911804
Validation loss: 1.9323814709981282

Epoch: 5| Step: 7
Training loss: 1.306135892868042
Validation loss: 1.9068712145090103

Epoch: 5| Step: 8
Training loss: 1.1632804870605469
Validation loss: 1.9413868089516957

Epoch: 5| Step: 9
Training loss: 1.0993479490280151
Validation loss: 1.9175494809945424

Epoch: 5| Step: 10
Training loss: 1.035599708557129
Validation loss: 1.9515390694141388

Epoch: 5| Step: 11
Training loss: 1.3920786380767822
Validation loss: 1.9430172840754192

Epoch: 145| Step: 0
Training loss: 1.0228040218353271
Validation loss: 1.9053715417782466

Epoch: 5| Step: 1
Training loss: 0.8601990938186646
Validation loss: 1.944932555158933

Epoch: 5| Step: 2
Training loss: 1.2461018562316895
Validation loss: 1.9717634270588558

Epoch: 5| Step: 3
Training loss: 0.9417478442192078
Validation loss: 1.9461735039949417

Epoch: 5| Step: 4
Training loss: 1.1176530122756958
Validation loss: 1.9173193822304408

Epoch: 5| Step: 5
Training loss: 1.1963523626327515
Validation loss: 1.9634450525045395

Epoch: 5| Step: 6
Training loss: 1.164504051208496
Validation loss: 1.8921171873807907

Epoch: 5| Step: 7
Training loss: 1.0030076503753662
Validation loss: 1.963663602868716

Epoch: 5| Step: 8
Training loss: 1.0190973281860352
Validation loss: 1.9570819189151127

Epoch: 5| Step: 9
Training loss: 1.3177932500839233
Validation loss: 1.9835135142008464

Epoch: 5| Step: 10
Training loss: 1.0612503290176392
Validation loss: 1.9390829652547836

Epoch: 5| Step: 11
Training loss: 0.698474645614624
Validation loss: 1.9786751468976338

Epoch: 146| Step: 0
Training loss: 1.5421899557113647
Validation loss: 2.02865169942379

Epoch: 5| Step: 1
Training loss: 1.0802751779556274
Validation loss: 2.073355426390966

Epoch: 5| Step: 2
Training loss: 1.1025846004486084
Validation loss: 2.075097863872846

Epoch: 5| Step: 3
Training loss: 1.0975067615509033
Validation loss: 2.032799725731214

Epoch: 5| Step: 4
Training loss: 0.9714679718017578
Validation loss: 2.060993656516075

Epoch: 5| Step: 5
Training loss: 0.9890867471694946
Validation loss: 2.002037142713865

Epoch: 5| Step: 6
Training loss: 0.770033061504364
Validation loss: 2.0061336209376655

Epoch: 5| Step: 7
Training loss: 0.9723711013793945
Validation loss: 1.9955569008986156

Epoch: 5| Step: 8
Training loss: 1.5412051677703857
Validation loss: 1.9910246382157009

Epoch: 5| Step: 9
Training loss: 0.8680626749992371
Validation loss: 2.032825912038485

Epoch: 5| Step: 10
Training loss: 1.6846625804901123
Validation loss: 1.9662176370620728

Epoch: 5| Step: 11
Training loss: 1.0757079124450684
Validation loss: 2.0038309693336487

Epoch: 147| Step: 0
Training loss: 0.9682378768920898
Validation loss: 2.0414425681034722

Epoch: 5| Step: 1
Training loss: 0.965855598449707
Validation loss: 2.0708867758512497

Epoch: 5| Step: 2
Training loss: 1.364139199256897
Validation loss: 2.0780915121237435

Epoch: 5| Step: 3
Training loss: 1.0225712060928345
Validation loss: 2.0860251585642495

Epoch: 5| Step: 4
Training loss: 1.4135442972183228
Validation loss: 2.029268965125084

Epoch: 5| Step: 5
Training loss: 1.2827057838439941
Validation loss: 1.985655610760053

Epoch: 5| Step: 6
Training loss: 0.8686882853507996
Validation loss: 1.9441869060198467

Epoch: 5| Step: 7
Training loss: 0.8090590238571167
Validation loss: 1.9291353474060695

Epoch: 5| Step: 8
Training loss: 1.3030292987823486
Validation loss: 1.9951588759819667

Epoch: 5| Step: 9
Training loss: 1.0264841318130493
Validation loss: 1.9520785013834636

Epoch: 5| Step: 10
Training loss: 1.3451114892959595
Validation loss: 2.017560596267382

Epoch: 5| Step: 11
Training loss: 0.4059157371520996
Validation loss: 1.9402717798948288

Epoch: 148| Step: 0
Training loss: 0.8716591000556946
Validation loss: 1.9763452957073848

Epoch: 5| Step: 1
Training loss: 1.1000816822052002
Validation loss: 1.911182125409444

Epoch: 5| Step: 2
Training loss: 0.7839487791061401
Validation loss: 1.954285055398941

Epoch: 5| Step: 3
Training loss: 1.0210059881210327
Validation loss: 1.9363040924072266

Epoch: 5| Step: 4
Training loss: 1.2976499795913696
Validation loss: 1.9920954803625743

Epoch: 5| Step: 5
Training loss: 1.241908073425293
Validation loss: 1.979899823665619

Epoch: 5| Step: 6
Training loss: 0.8824159502983093
Validation loss: 1.9625361561775208

Epoch: 5| Step: 7
Training loss: 1.5903856754302979
Validation loss: 1.9652907848358154

Epoch: 5| Step: 8
Training loss: 1.6376087665557861
Validation loss: 1.8928636014461517

Epoch: 5| Step: 9
Training loss: 0.9120289087295532
Validation loss: 1.8644261906544368

Epoch: 5| Step: 10
Training loss: 1.17203688621521
Validation loss: 1.980121374130249

Epoch: 5| Step: 11
Training loss: 0.623324990272522
Validation loss: 1.9470268140236537

Epoch: 149| Step: 0
Training loss: 1.1927975416183472
Validation loss: 1.9693315575520198

Epoch: 5| Step: 1
Training loss: 1.1005483865737915
Validation loss: 1.977773944536845

Epoch: 5| Step: 2
Training loss: 1.3638547658920288
Validation loss: 1.9640770653883617

Epoch: 5| Step: 3
Training loss: 0.8473779559135437
Validation loss: 1.9375082850456238

Epoch: 5| Step: 4
Training loss: 1.2986104488372803
Validation loss: 1.904414360721906

Epoch: 5| Step: 5
Training loss: 0.8138783574104309
Validation loss: 1.9249104112386703

Epoch: 5| Step: 6
Training loss: 1.2264318466186523
Validation loss: 1.9481404324372609

Epoch: 5| Step: 7
Training loss: 0.9241286516189575
Validation loss: 1.9368499567111332

Epoch: 5| Step: 8
Training loss: 1.0404160022735596
Validation loss: 1.9982812305291493

Epoch: 5| Step: 9
Training loss: 1.0034701824188232
Validation loss: 2.0134855955839157

Epoch: 5| Step: 10
Training loss: 0.9999567866325378
Validation loss: 1.9521445035934448

Epoch: 5| Step: 11
Training loss: 0.5383472442626953
Validation loss: 1.9646412829558055

Epoch: 150| Step: 0
Training loss: 1.2342822551727295
Validation loss: 1.9637967646121979

Epoch: 5| Step: 1
Training loss: 1.1290172338485718
Validation loss: 1.9986984133720398

Epoch: 5| Step: 2
Training loss: 0.6128779649734497
Validation loss: 1.8808363328377407

Epoch: 5| Step: 3
Training loss: 0.9710052609443665
Validation loss: 1.942384973168373

Epoch: 5| Step: 4
Training loss: 0.9640408754348755
Validation loss: 1.9138986666997273

Epoch: 5| Step: 5
Training loss: 0.9506447911262512
Validation loss: 1.9393294056256611

Epoch: 5| Step: 6
Training loss: 1.1520304679870605
Validation loss: 1.90482401351134

Epoch: 5| Step: 7
Training loss: 1.0425372123718262
Validation loss: 1.96200796465079

Epoch: 5| Step: 8
Training loss: 0.6357725858688354
Validation loss: 1.8957821776469548

Epoch: 5| Step: 9
Training loss: 1.1570069789886475
Validation loss: 1.9313004811604817

Epoch: 5| Step: 10
Training loss: 1.5137603282928467
Validation loss: 1.9059319694836934

Epoch: 5| Step: 11
Training loss: 1.2669175863265991
Validation loss: 1.9439511199792225

Epoch: 151| Step: 0
Training loss: 0.8055478930473328
Validation loss: 1.906041552623113

Epoch: 5| Step: 1
Training loss: 0.8767495155334473
Validation loss: 1.9150670766830444

Epoch: 5| Step: 2
Training loss: 1.297953724861145
Validation loss: 1.9280589918295543

Epoch: 5| Step: 3
Training loss: 1.2250101566314697
Validation loss: 1.9309688806533813

Epoch: 5| Step: 4
Training loss: 1.1208809614181519
Validation loss: 1.9646301964918773

Epoch: 5| Step: 5
Training loss: 1.0594758987426758
Validation loss: 1.9561645487944286

Epoch: 5| Step: 6
Training loss: 1.1840944290161133
Validation loss: 1.97979436814785

Epoch: 5| Step: 7
Training loss: 0.8955915570259094
Validation loss: 1.9499999036391575

Epoch: 5| Step: 8
Training loss: 0.7220637798309326
Validation loss: 1.9436336209376652

Epoch: 5| Step: 9
Training loss: 1.0833085775375366
Validation loss: 1.9672469745079677

Epoch: 5| Step: 10
Training loss: 1.3373386859893799
Validation loss: 1.9169319818417232

Epoch: 5| Step: 11
Training loss: 0.545284628868103
Validation loss: 1.9612595091263454

Epoch: 152| Step: 0
Training loss: 0.8879358172416687
Validation loss: 1.9485411296288173

Epoch: 5| Step: 1
Training loss: 0.8338521122932434
Validation loss: 1.9997511754433315

Epoch: 5| Step: 2
Training loss: 1.1767911911010742
Validation loss: 2.019046346346537

Epoch: 5| Step: 3
Training loss: 1.149931788444519
Validation loss: 1.9944464961687725

Epoch: 5| Step: 4
Training loss: 1.1470921039581299
Validation loss: 1.9259178737799327

Epoch: 5| Step: 5
Training loss: 1.1277097463607788
Validation loss: 1.956351414322853

Epoch: 5| Step: 6
Training loss: 1.2434375286102295
Validation loss: 1.9834989408651988

Epoch: 5| Step: 7
Training loss: 1.041937232017517
Validation loss: 1.9287635932366054

Epoch: 5| Step: 8
Training loss: 0.938369870185852
Validation loss: 1.9348804304997127

Epoch: 5| Step: 9
Training loss: 1.1266733407974243
Validation loss: 1.9252433329820633

Epoch: 5| Step: 10
Training loss: 0.6213516592979431
Validation loss: 2.0000861088434854

Epoch: 5| Step: 11
Training loss: 0.8791736364364624
Validation loss: 1.94449416299661

Epoch: 153| Step: 0
Training loss: 0.7915712594985962
Validation loss: 1.9825492004553478

Epoch: 5| Step: 1
Training loss: 1.1181879043579102
Validation loss: 1.999675860007604

Epoch: 5| Step: 2
Training loss: 1.1387110948562622
Validation loss: 2.002052133282026

Epoch: 5| Step: 3
Training loss: 1.4670970439910889
Validation loss: 1.9569124778111775

Epoch: 5| Step: 4
Training loss: 0.5979443788528442
Validation loss: 1.9528357684612274

Epoch: 5| Step: 5
Training loss: 1.0116297006607056
Validation loss: 1.8684650311867397

Epoch: 5| Step: 6
Training loss: 0.7607496976852417
Validation loss: 1.9154632240533829

Epoch: 5| Step: 7
Training loss: 1.2236912250518799
Validation loss: 1.946307937304179

Epoch: 5| Step: 8
Training loss: 1.1629433631896973
Validation loss: 1.9828000962734222

Epoch: 5| Step: 9
Training loss: 1.1236231327056885
Validation loss: 1.9999166031678517

Epoch: 5| Step: 10
Training loss: 0.9801902770996094
Validation loss: 1.9429427534341812

Epoch: 5| Step: 11
Training loss: 1.7702997922897339
Validation loss: 2.018522168199221

Epoch: 154| Step: 0
Training loss: 1.814867615699768
Validation loss: 1.9939886679251988

Epoch: 5| Step: 1
Training loss: 0.8166149258613586
Validation loss: 1.974583591024081

Epoch: 5| Step: 2
Training loss: 0.9298599362373352
Validation loss: 2.005500376224518

Epoch: 5| Step: 3
Training loss: 0.9597217440605164
Validation loss: 2.0170369346936545

Epoch: 5| Step: 4
Training loss: 1.0517202615737915
Validation loss: 1.9338848342498143

Epoch: 5| Step: 5
Training loss: 1.1682506799697876
Validation loss: 1.9575579911470413

Epoch: 5| Step: 6
Training loss: 1.1458524465560913
Validation loss: 1.9972159564495087

Epoch: 5| Step: 7
Training loss: 1.0895851850509644
Validation loss: 2.0038610895474753

Epoch: 5| Step: 8
Training loss: 0.6966304779052734
Validation loss: 1.9560909122228622

Epoch: 5| Step: 9
Training loss: 0.8310164213180542
Validation loss: 1.9682658513387044

Epoch: 5| Step: 10
Training loss: 1.046871542930603
Validation loss: 1.9287973046302795

Epoch: 5| Step: 11
Training loss: 0.871584415435791
Validation loss: 1.9253789136807125

Epoch: 155| Step: 0
Training loss: 1.047276258468628
Validation loss: 1.9362087299426396

Epoch: 5| Step: 1
Training loss: 0.9936335682868958
Validation loss: 1.9824590931336086

Epoch: 5| Step: 2
Training loss: 1.0210535526275635
Validation loss: 1.9685423026482265

Epoch: 5| Step: 3
Training loss: 0.8334959149360657
Validation loss: 1.8860225876172383

Epoch: 5| Step: 4
Training loss: 0.8087900280952454
Validation loss: 1.9169545372327168

Epoch: 5| Step: 5
Training loss: 1.1381508111953735
Validation loss: 1.9717170546452205

Epoch: 5| Step: 6
Training loss: 1.4825185537338257
Validation loss: 1.8930679708719254

Epoch: 5| Step: 7
Training loss: 1.3661777973175049
Validation loss: 1.9636719673871994

Epoch: 5| Step: 8
Training loss: 1.1721384525299072
Validation loss: 1.9611494094133377

Epoch: 5| Step: 9
Training loss: 0.7478167414665222
Validation loss: 1.9185570925474167

Epoch: 5| Step: 10
Training loss: 0.6965199708938599
Validation loss: 1.926609938343366

Epoch: 5| Step: 11
Training loss: 0.9823752641677856
Validation loss: 1.943438281615575

Epoch: 156| Step: 0
Training loss: 1.1391000747680664
Validation loss: 1.9508276184399922

Epoch: 5| Step: 1
Training loss: 0.9301409721374512
Validation loss: 1.9461263914903004

Epoch: 5| Step: 2
Training loss: 1.3899250030517578
Validation loss: 2.0099634726842246

Epoch: 5| Step: 3
Training loss: 0.9617422819137573
Validation loss: 1.9618591964244843

Epoch: 5| Step: 4
Training loss: 1.0215175151824951
Validation loss: 1.8848368376493454

Epoch: 5| Step: 5
Training loss: 0.9618989825248718
Validation loss: 1.8935681233803432

Epoch: 5| Step: 6
Training loss: 0.735175371170044
Validation loss: 1.932564417521159

Epoch: 5| Step: 7
Training loss: 0.7867351174354553
Validation loss: 1.9174326658248901

Epoch: 5| Step: 8
Training loss: 1.1786925792694092
Validation loss: 1.8993789007266362

Epoch: 5| Step: 9
Training loss: 0.8463722467422485
Validation loss: 1.9308457175890605

Epoch: 5| Step: 10
Training loss: 1.053427815437317
Validation loss: 1.9073418627182643

Epoch: 5| Step: 11
Training loss: 1.0859153270721436
Validation loss: 1.9437243243058522

Epoch: 157| Step: 0
Training loss: 1.0224545001983643
Validation loss: 1.910832365353902

Epoch: 5| Step: 1
Training loss: 0.8603687286376953
Validation loss: 1.9478077193101246

Epoch: 5| Step: 2
Training loss: 0.8256866335868835
Validation loss: 1.956601197520892

Epoch: 5| Step: 3
Training loss: 1.3621127605438232
Validation loss: 1.9472141116857529

Epoch: 5| Step: 4
Training loss: 0.4803915023803711
Validation loss: 1.926207423210144

Epoch: 5| Step: 5
Training loss: 0.9372397661209106
Validation loss: 1.9245241930087407

Epoch: 5| Step: 6
Training loss: 1.193895936012268
Validation loss: 1.9552454849084218

Epoch: 5| Step: 7
Training loss: 1.1034704446792603
Validation loss: 1.9646423409382503

Epoch: 5| Step: 8
Training loss: 0.5363327860832214
Validation loss: 1.9046578059593837

Epoch: 5| Step: 9
Training loss: 0.721003532409668
Validation loss: 1.93989393611749

Epoch: 5| Step: 10
Training loss: 1.1151803731918335
Validation loss: 1.9929938117663066

Epoch: 5| Step: 11
Training loss: 1.1616508960723877
Validation loss: 1.9534963270028431

Epoch: 158| Step: 0
Training loss: 1.3387482166290283
Validation loss: 1.8908013304074605

Epoch: 5| Step: 1
Training loss: 1.0720179080963135
Validation loss: 1.9286213964223862

Epoch: 5| Step: 2
Training loss: 0.8913031816482544
Validation loss: 1.9676534285147984

Epoch: 5| Step: 3
Training loss: 0.9646912813186646
Validation loss: 1.92967456082503

Epoch: 5| Step: 4
Training loss: 1.0502408742904663
Validation loss: 1.9846048404773076

Epoch: 5| Step: 5
Training loss: 0.6545308232307434
Validation loss: 2.004674971103668

Epoch: 5| Step: 6
Training loss: 0.7764663696289062
Validation loss: 1.926323304573695

Epoch: 5| Step: 7
Training loss: 0.9602051973342896
Validation loss: 1.990489994486173

Epoch: 5| Step: 8
Training loss: 1.589002251625061
Validation loss: 1.943550820151965

Epoch: 5| Step: 9
Training loss: 0.9651690721511841
Validation loss: 1.9427795559167862

Epoch: 5| Step: 10
Training loss: 0.7518743872642517
Validation loss: 1.9430539458990097

Epoch: 5| Step: 11
Training loss: 0.29021090269088745
Validation loss: 1.968320329984029

Epoch: 159| Step: 0
Training loss: 0.5699101090431213
Validation loss: 1.9377013196547825

Epoch: 5| Step: 1
Training loss: 0.942700207233429
Validation loss: 1.9174021085103352

Epoch: 5| Step: 2
Training loss: 1.0099009275436401
Validation loss: 1.9722896466652553

Epoch: 5| Step: 3
Training loss: 0.6718586683273315
Validation loss: 1.9714570293823879

Epoch: 5| Step: 4
Training loss: 1.3067501783370972
Validation loss: 1.9846765448649724

Epoch: 5| Step: 5
Training loss: 0.7344534993171692
Validation loss: 1.9789140472809474

Epoch: 5| Step: 6
Training loss: 1.1059129238128662
Validation loss: 1.9492182433605194

Epoch: 5| Step: 7
Training loss: 1.3331050872802734
Validation loss: 1.955470417936643

Epoch: 5| Step: 8
Training loss: 0.8587691187858582
Validation loss: 1.946448986728986

Epoch: 5| Step: 9
Training loss: 1.083478569984436
Validation loss: 2.0691962987184525

Epoch: 5| Step: 10
Training loss: 0.8682062029838562
Validation loss: 1.96251380443573

Epoch: 5| Step: 11
Training loss: 0.2761673331260681
Validation loss: 1.9881117641925812

Epoch: 160| Step: 0
Training loss: 0.9448143839836121
Validation loss: 1.9805870701869328

Epoch: 5| Step: 1
Training loss: 0.9766938090324402
Validation loss: 1.976502776145935

Epoch: 5| Step: 2
Training loss: 0.7372387647628784
Validation loss: 1.925659065445264

Epoch: 5| Step: 3
Training loss: 1.4041626453399658
Validation loss: 1.9584685961405437

Epoch: 5| Step: 4
Training loss: 1.1141571998596191
Validation loss: 1.9807642350594203

Epoch: 5| Step: 5
Training loss: 1.2182893753051758
Validation loss: 1.9436083436012268

Epoch: 5| Step: 6
Training loss: 1.0496312379837036
Validation loss: 1.912602186203003

Epoch: 5| Step: 7
Training loss: 0.7228349447250366
Validation loss: 1.8856554230054219

Epoch: 5| Step: 8
Training loss: 0.7160843014717102
Validation loss: 1.9547236810127895

Epoch: 5| Step: 9
Training loss: 0.9584193229675293
Validation loss: 1.9378920197486877

Epoch: 5| Step: 10
Training loss: 0.9280372858047485
Validation loss: 2.0168240865071616

Epoch: 5| Step: 11
Training loss: 0.48881661891937256
Validation loss: 1.994734525680542

Epoch: 161| Step: 0
Training loss: 0.715523898601532
Validation loss: 1.9474313606818516

Epoch: 5| Step: 1
Training loss: 1.1781752109527588
Validation loss: 1.9453079501787822

Epoch: 5| Step: 2
Training loss: 0.7757054567337036
Validation loss: 1.9182460308074951

Epoch: 5| Step: 3
Training loss: 1.3056690692901611
Validation loss: 1.977589726448059

Epoch: 5| Step: 4
Training loss: 1.4306105375289917
Validation loss: 1.9168038765589397

Epoch: 5| Step: 5
Training loss: 0.7769378423690796
Validation loss: 1.9138949414094288

Epoch: 5| Step: 6
Training loss: 1.0384501218795776
Validation loss: 1.9769381086031597

Epoch: 5| Step: 7
Training loss: 0.8576585054397583
Validation loss: 1.9562897781531017

Epoch: 5| Step: 8
Training loss: 0.9498001337051392
Validation loss: 1.9780903508265812

Epoch: 5| Step: 9
Training loss: 0.9123226404190063
Validation loss: 1.9584952692190807

Epoch: 5| Step: 10
Training loss: 1.3021445274353027
Validation loss: 2.039533590277036

Epoch: 5| Step: 11
Training loss: 0.2620552182197571
Validation loss: 2.001190721988678

Epoch: 162| Step: 0
Training loss: 1.2380812168121338
Validation loss: 2.009445091088613

Epoch: 5| Step: 1
Training loss: 0.9574001431465149
Validation loss: 1.947291374206543

Epoch: 5| Step: 2
Training loss: 1.05298912525177
Validation loss: 1.9816174258788426

Epoch: 5| Step: 3
Training loss: 1.012437105178833
Validation loss: 1.881512592236201

Epoch: 5| Step: 4
Training loss: 1.2779558897018433
Validation loss: 1.939404899875323

Epoch: 5| Step: 5
Training loss: 0.5127801895141602
Validation loss: 1.9778607438007991

Epoch: 5| Step: 6
Training loss: 0.7782996892929077
Validation loss: 1.9509515513976414

Epoch: 5| Step: 7
Training loss: 0.9733096957206726
Validation loss: 1.9692264298597972

Epoch: 5| Step: 8
Training loss: 0.8230050802230835
Validation loss: 1.9674034814039867

Epoch: 5| Step: 9
Training loss: 1.088613748550415
Validation loss: 1.9478440980116527

Epoch: 5| Step: 10
Training loss: 0.8796173334121704
Validation loss: 1.9404830187559128

Epoch: 5| Step: 11
Training loss: 1.2657716274261475
Validation loss: 1.9240793883800507

Epoch: 163| Step: 0
Training loss: 0.8090624809265137
Validation loss: 1.9665348480145137

Epoch: 5| Step: 1
Training loss: 1.000842809677124
Validation loss: 1.9641879200935364

Epoch: 5| Step: 2
Training loss: 0.7855075597763062
Validation loss: 1.9280665169159572

Epoch: 5| Step: 3
Training loss: 0.69414222240448
Validation loss: 1.9339582920074463

Epoch: 5| Step: 4
Training loss: 0.6363536715507507
Validation loss: 1.979329119126002

Epoch: 5| Step: 5
Training loss: 1.325347661972046
Validation loss: 1.9584621489048004

Epoch: 5| Step: 6
Training loss: 0.6831415891647339
Validation loss: 1.9876810361941655

Epoch: 5| Step: 7
Training loss: 0.9079016447067261
Validation loss: 1.8883694310983021

Epoch: 5| Step: 8
Training loss: 0.77443528175354
Validation loss: 1.9752140988906224

Epoch: 5| Step: 9
Training loss: 1.4107692241668701
Validation loss: 1.973533848921458

Epoch: 5| Step: 10
Training loss: 0.8388336896896362
Validation loss: 1.9576933930317562

Epoch: 5| Step: 11
Training loss: 1.5846326351165771
Validation loss: 2.003452385465304

Epoch: 164| Step: 0
Training loss: 0.9819530248641968
Validation loss: 2.0165752867857614

Epoch: 5| Step: 1
Training loss: 0.8687392473220825
Validation loss: 1.9300440500179927

Epoch: 5| Step: 2
Training loss: 1.2052619457244873
Validation loss: 1.9735889186461766

Epoch: 5| Step: 3
Training loss: 1.445373773574829
Validation loss: 2.002381051580111

Epoch: 5| Step: 4
Training loss: 0.5444769263267517
Validation loss: 1.9569802780946095

Epoch: 5| Step: 5
Training loss: 1.1507325172424316
Validation loss: 1.9873845626910527

Epoch: 5| Step: 6
Training loss: 0.7521462440490723
Validation loss: 1.9892574548721313

Epoch: 5| Step: 7
Training loss: 0.772606611251831
Validation loss: 1.9738847712675731

Epoch: 5| Step: 8
Training loss: 0.8147103190422058
Validation loss: 1.9776566872994106

Epoch: 5| Step: 9
Training loss: 0.9766947627067566
Validation loss: 1.9362502694129944

Epoch: 5| Step: 10
Training loss: 0.8724854588508606
Validation loss: 1.9857839345932007

Epoch: 5| Step: 11
Training loss: 0.7115440964698792
Validation loss: 1.957083950440089

Epoch: 165| Step: 0
Training loss: 1.1954853534698486
Validation loss: 1.9767453074455261

Epoch: 5| Step: 1
Training loss: 0.7240933775901794
Validation loss: 1.9516305327415466

Epoch: 5| Step: 2
Training loss: 0.9544442296028137
Validation loss: 1.9493754754463832

Epoch: 5| Step: 3
Training loss: 1.250393033027649
Validation loss: 1.977832704782486

Epoch: 5| Step: 4
Training loss: 0.9758439064025879
Validation loss: 2.0298737635215125

Epoch: 5| Step: 5
Training loss: 1.0226234197616577
Validation loss: 2.0191375513871512

Epoch: 5| Step: 6
Training loss: 0.9927774667739868
Validation loss: 2.0097156862417855

Epoch: 5| Step: 7
Training loss: 1.0772850513458252
Validation loss: 1.9998187273740768

Epoch: 5| Step: 8
Training loss: 0.7205724120140076
Validation loss: 2.0413584858179092

Epoch: 5| Step: 9
Training loss: 0.6968657970428467
Validation loss: 1.9757121801376343

Epoch: 5| Step: 10
Training loss: 0.7300383448600769
Validation loss: 1.945477917790413

Epoch: 5| Step: 11
Training loss: 0.48647719621658325
Validation loss: 1.9513794084390004

Epoch: 166| Step: 0
Training loss: 0.7750476598739624
Validation loss: 1.9710314224163692

Epoch: 5| Step: 1
Training loss: 1.0366809368133545
Validation loss: 1.92413995663325

Epoch: 5| Step: 2
Training loss: 0.9748696088790894
Validation loss: 1.9396577527125676

Epoch: 5| Step: 3
Training loss: 0.7641469240188599
Validation loss: 1.9717853218317032

Epoch: 5| Step: 4
Training loss: 0.7393064498901367
Validation loss: 1.9646626561880112

Epoch: 5| Step: 5
Training loss: 0.7814931869506836
Validation loss: 1.9749988317489624

Epoch: 5| Step: 6
Training loss: 1.0380860567092896
Validation loss: 1.9540921747684479

Epoch: 5| Step: 7
Training loss: 0.6288801431655884
Validation loss: 1.8836281696955364

Epoch: 5| Step: 8
Training loss: 1.3768258094787598
Validation loss: 1.8968803882598877

Epoch: 5| Step: 9
Training loss: 1.2575938701629639
Validation loss: 1.9350205113490422

Epoch: 5| Step: 10
Training loss: 0.8850005865097046
Validation loss: 1.9477644264698029

Epoch: 5| Step: 11
Training loss: 0.5736708045005798
Validation loss: 1.867389862736066

Epoch: 167| Step: 0
Training loss: 1.0258111953735352
Validation loss: 1.895566816131274

Epoch: 5| Step: 1
Training loss: 0.8423539996147156
Validation loss: 1.9978702714045842

Epoch: 5| Step: 2
Training loss: 0.669093132019043
Validation loss: 2.0255573838949203

Epoch: 5| Step: 3
Training loss: 1.2217462062835693
Validation loss: 1.9733736167351406

Epoch: 5| Step: 4
Training loss: 0.7486177086830139
Validation loss: 2.0022246539592743

Epoch: 5| Step: 5
Training loss: 0.5516884922981262
Validation loss: 1.9572638124227524

Epoch: 5| Step: 6
Training loss: 1.0170451402664185
Validation loss: 1.9927409986654918

Epoch: 5| Step: 7
Training loss: 0.8815044164657593
Validation loss: 1.9213139365116756

Epoch: 5| Step: 8
Training loss: 1.2604804039001465
Validation loss: 1.9670573224623997

Epoch: 5| Step: 9
Training loss: 0.9811380505561829
Validation loss: 1.9314444263776143

Epoch: 5| Step: 10
Training loss: 0.9325114488601685
Validation loss: 1.9170668025811513

Epoch: 5| Step: 11
Training loss: 0.7561217546463013
Validation loss: 1.944338858127594

Epoch: 168| Step: 0
Training loss: 1.2125927209854126
Validation loss: 1.9314070343971252

Epoch: 5| Step: 1
Training loss: 1.2337815761566162
Validation loss: 2.016015569368998

Epoch: 5| Step: 2
Training loss: 0.6230538487434387
Validation loss: 1.9756624450286229

Epoch: 5| Step: 3
Training loss: 0.8995720148086548
Validation loss: 2.021267607808113

Epoch: 5| Step: 4
Training loss: 0.6827114820480347
Validation loss: 1.9441641569137573

Epoch: 5| Step: 5
Training loss: 0.9148085713386536
Validation loss: 1.9642592171827953

Epoch: 5| Step: 6
Training loss: 1.4141958951950073
Validation loss: 2.001063033938408

Epoch: 5| Step: 7
Training loss: 0.5566941499710083
Validation loss: 1.9382738173007965

Epoch: 5| Step: 8
Training loss: 1.0244196653366089
Validation loss: 1.992799311876297

Epoch: 5| Step: 9
Training loss: 0.8559831380844116
Validation loss: 1.9707040637731552

Epoch: 5| Step: 10
Training loss: 0.7041770219802856
Validation loss: 1.9767195731401443

Epoch: 5| Step: 11
Training loss: 0.7766192555427551
Validation loss: 1.9285030315319698

Epoch: 169| Step: 0
Training loss: 1.0716934204101562
Validation loss: 1.9709311723709106

Epoch: 5| Step: 1
Training loss: 1.1691211462020874
Validation loss: 1.923814743757248

Epoch: 5| Step: 2
Training loss: 0.7335270643234253
Validation loss: 2.0235972305138907

Epoch: 5| Step: 3
Training loss: 1.0605382919311523
Validation loss: 1.9859844744205475

Epoch: 5| Step: 4
Training loss: 1.133650779724121
Validation loss: 2.023430864016215

Epoch: 5| Step: 5
Training loss: 0.7041292786598206
Validation loss: 1.9777611941099167

Epoch: 5| Step: 6
Training loss: 1.330134630203247
Validation loss: 1.925408621629079

Epoch: 5| Step: 7
Training loss: 0.6181823015213013
Validation loss: 1.9771835803985596

Epoch: 5| Step: 8
Training loss: 0.9948972463607788
Validation loss: 1.9105155070622761

Epoch: 5| Step: 9
Training loss: 0.6429433822631836
Validation loss: 1.976905922094981

Epoch: 5| Step: 10
Training loss: 0.707809329032898
Validation loss: 1.955047105749448

Epoch: 5| Step: 11
Training loss: 0.797603964805603
Validation loss: 1.9791478564341862

Epoch: 170| Step: 0
Training loss: 0.9822477102279663
Validation loss: 1.9504418820142746

Epoch: 5| Step: 1
Training loss: 0.5843953490257263
Validation loss: 1.9400697847207387

Epoch: 5| Step: 2
Training loss: 0.9072540402412415
Validation loss: 1.9195823222398758

Epoch: 5| Step: 3
Training loss: 0.7722086906433105
Validation loss: 1.9784697592258453

Epoch: 5| Step: 4
Training loss: 0.9345965385437012
Validation loss: 1.9871162474155426

Epoch: 5| Step: 5
Training loss: 1.1398197412490845
Validation loss: 1.9333715587854385

Epoch: 5| Step: 6
Training loss: 0.7242189049720764
Validation loss: 1.926304782430331

Epoch: 5| Step: 7
Training loss: 0.9933453798294067
Validation loss: 1.9529444972674053

Epoch: 5| Step: 8
Training loss: 0.8079498410224915
Validation loss: 2.033427879214287

Epoch: 5| Step: 9
Training loss: 1.2287895679473877
Validation loss: 1.9917787710825603

Epoch: 5| Step: 10
Training loss: 0.9897996783256531
Validation loss: 2.026211296518644

Epoch: 5| Step: 11
Training loss: 1.2755087614059448
Validation loss: 2.056272024909655

Epoch: 171| Step: 0
Training loss: 0.8943597674369812
Validation loss: 1.9503219574689865

Epoch: 5| Step: 1
Training loss: 1.4041545391082764
Validation loss: 2.0039082070191703

Epoch: 5| Step: 2
Training loss: 0.6196907758712769
Validation loss: 2.04628649353981

Epoch: 5| Step: 3
Training loss: 0.6900151371955872
Validation loss: 2.0765607953071594

Epoch: 5| Step: 4
Training loss: 0.9547584652900696
Validation loss: 2.0619885375102363

Epoch: 5| Step: 5
Training loss: 0.622384786605835
Validation loss: 2.0813073168198266

Epoch: 5| Step: 6
Training loss: 1.2022778987884521
Validation loss: 1.9700610886017482

Epoch: 5| Step: 7
Training loss: 0.8119659423828125
Validation loss: 2.022168959180514

Epoch: 5| Step: 8
Training loss: 0.5667603015899658
Validation loss: 1.978360190987587

Epoch: 5| Step: 9
Training loss: 0.9605712890625
Validation loss: 2.0364667425553002

Epoch: 5| Step: 10
Training loss: 0.8027330636978149
Validation loss: 2.0021738559007645

Epoch: 5| Step: 11
Training loss: 0.36448895931243896
Validation loss: 1.9699926873048146

Epoch: 172| Step: 0
Training loss: 0.5711084604263306
Validation loss: 1.9947332839171092

Epoch: 5| Step: 1
Training loss: 0.848590075969696
Validation loss: 1.96611288189888

Epoch: 5| Step: 2
Training loss: 1.0394253730773926
Validation loss: 1.985026980439822

Epoch: 5| Step: 3
Training loss: 0.7252579927444458
Validation loss: 1.9674199024836223

Epoch: 5| Step: 4
Training loss: 0.6424806714057922
Validation loss: 1.9890153408050537

Epoch: 5| Step: 5
Training loss: 0.8463605642318726
Validation loss: 1.9393764634927113

Epoch: 5| Step: 6
Training loss: 1.0309784412384033
Validation loss: 1.9711208591858547

Epoch: 5| Step: 7
Training loss: 0.7630274891853333
Validation loss: 1.98783640563488

Epoch: 5| Step: 8
Training loss: 1.0045439004898071
Validation loss: 1.9228670944770176

Epoch: 5| Step: 9
Training loss: 0.8175975680351257
Validation loss: 1.910194565852483

Epoch: 5| Step: 10
Training loss: 0.9977455139160156
Validation loss: 1.980367789665858

Epoch: 5| Step: 11
Training loss: 1.6058813333511353
Validation loss: 1.9418920824925106

Epoch: 173| Step: 0
Training loss: 0.530280351638794
Validation loss: 1.9506099273761113

Epoch: 5| Step: 1
Training loss: 0.9602454304695129
Validation loss: 1.9759057015180588

Epoch: 5| Step: 2
Training loss: 0.6711708903312683
Validation loss: 1.92675119638443

Epoch: 5| Step: 3
Training loss: 0.6805763244628906
Validation loss: 1.9738121430079143

Epoch: 5| Step: 4
Training loss: 0.7434213757514954
Validation loss: 1.9865628530581791

Epoch: 5| Step: 5
Training loss: 1.0347553491592407
Validation loss: 1.9944627980391185

Epoch: 5| Step: 6
Training loss: 1.1576555967330933
Validation loss: 2.013146996498108

Epoch: 5| Step: 7
Training loss: 0.8662263751029968
Validation loss: 1.9615279684464137

Epoch: 5| Step: 8
Training loss: 0.9020165205001831
Validation loss: 2.002407486240069

Epoch: 5| Step: 9
Training loss: 0.7767228484153748
Validation loss: 1.9614584644635518

Epoch: 5| Step: 10
Training loss: 1.325217366218567
Validation loss: 1.9505673944950104

Epoch: 5| Step: 11
Training loss: 0.12846505641937256
Validation loss: 1.958876942594846

Epoch: 174| Step: 0
Training loss: 0.839142918586731
Validation loss: 1.9872551163037617

Epoch: 5| Step: 1
Training loss: 1.0417035818099976
Validation loss: 2.000235309203466

Epoch: 5| Step: 2
Training loss: 0.6916587948799133
Validation loss: 2.020219271381696

Epoch: 5| Step: 3
Training loss: 0.44505295157432556
Validation loss: 2.010127678513527

Epoch: 5| Step: 4
Training loss: 1.2102982997894287
Validation loss: 2.0225118150313697

Epoch: 5| Step: 5
Training loss: 0.6477950215339661
Validation loss: 1.9215660691261292

Epoch: 5| Step: 6
Training loss: 0.7288332581520081
Validation loss: 2.001899058620135

Epoch: 5| Step: 7
Training loss: 1.120789885520935
Validation loss: 2.031505063176155

Epoch: 5| Step: 8
Training loss: 0.7554413676261902
Validation loss: 1.9974397718906403

Epoch: 5| Step: 9
Training loss: 0.8186604380607605
Validation loss: 1.9807637234528859

Epoch: 5| Step: 10
Training loss: 1.2632931470870972
Validation loss: 1.9644282658894856

Epoch: 5| Step: 11
Training loss: 0.4800106883049011
Validation loss: 1.9560380230347316

Epoch: 175| Step: 0
Training loss: 0.8328884243965149
Validation loss: 1.992732971906662

Epoch: 5| Step: 1
Training loss: 0.6175926923751831
Validation loss: 1.9914195487896602

Epoch: 5| Step: 2
Training loss: 0.6325405836105347
Validation loss: 1.971986581881841

Epoch: 5| Step: 3
Training loss: 0.7157624959945679
Validation loss: 1.9856065958738327

Epoch: 5| Step: 4
Training loss: 0.8972077369689941
Validation loss: 2.0303575744231543

Epoch: 5| Step: 5
Training loss: 1.3283805847167969
Validation loss: 1.979315881927808

Epoch: 5| Step: 6
Training loss: 0.759033739566803
Validation loss: 2.040555382768313

Epoch: 5| Step: 7
Training loss: 0.7587603330612183
Validation loss: 1.9837017456690471

Epoch: 5| Step: 8
Training loss: 1.1023603677749634
Validation loss: 1.9803241739670436

Epoch: 5| Step: 9
Training loss: 0.8312886953353882
Validation loss: 2.039787913362185

Epoch: 5| Step: 10
Training loss: 0.9723247289657593
Validation loss: 1.9684289942185085

Epoch: 5| Step: 11
Training loss: 1.0649334192276
Validation loss: 2.01443013548851

Epoch: 176| Step: 0
Training loss: 1.3210523128509521
Validation loss: 1.9417855540911357

Epoch: 5| Step: 1
Training loss: 0.3177562654018402
Validation loss: 1.9920107126235962

Epoch: 5| Step: 2
Training loss: 0.9338387250900269
Validation loss: 2.0207483619451523

Epoch: 5| Step: 3
Training loss: 0.7389936447143555
Validation loss: 1.9290163666009903

Epoch: 5| Step: 4
Training loss: 0.8646446466445923
Validation loss: 1.9504559238751729

Epoch: 5| Step: 5
Training loss: 1.1236317157745361
Validation loss: 1.9811944762865703

Epoch: 5| Step: 6
Training loss: 0.7246730327606201
Validation loss: 1.989936739206314

Epoch: 5| Step: 7
Training loss: 0.5770068168640137
Validation loss: 1.9825220108032227

Epoch: 5| Step: 8
Training loss: 1.1271378993988037
Validation loss: 2.0288435568412146

Epoch: 5| Step: 9
Training loss: 0.8798618316650391
Validation loss: 2.0362772345542908

Epoch: 5| Step: 10
Training loss: 0.561631977558136
Validation loss: 1.9552606145540874

Epoch: 5| Step: 11
Training loss: 0.22892308235168457
Validation loss: 1.991372287273407

Epoch: 177| Step: 0
Training loss: 0.5883098244667053
Validation loss: 1.9383819550275803

Epoch: 5| Step: 1
Training loss: 1.105444312095642
Validation loss: 1.9725333253542583

Epoch: 5| Step: 2
Training loss: 0.9379498362541199
Validation loss: 1.9467664510011673

Epoch: 5| Step: 3
Training loss: 1.1196166276931763
Validation loss: 2.0127288599809012

Epoch: 5| Step: 4
Training loss: 0.6422150731086731
Validation loss: 2.0433954248825708

Epoch: 5| Step: 5
Training loss: 0.522083580493927
Validation loss: 1.970294748743375

Epoch: 5| Step: 6
Training loss: 0.9634525179862976
Validation loss: 2.072695702314377

Epoch: 5| Step: 7
Training loss: 0.8586977124214172
Validation loss: 2.040241315960884

Epoch: 5| Step: 8
Training loss: 0.6332175135612488
Validation loss: 2.050140385826429

Epoch: 5| Step: 9
Training loss: 0.8066099882125854
Validation loss: 1.9678408255179722

Epoch: 5| Step: 10
Training loss: 0.8138105273246765
Validation loss: 1.9758478651444118

Epoch: 5| Step: 11
Training loss: 0.2690510153770447
Validation loss: 2.0377380549907684

Epoch: 178| Step: 0
Training loss: 1.16831374168396
Validation loss: 2.003676394621531

Epoch: 5| Step: 1
Training loss: 0.4851815104484558
Validation loss: 2.0028140197197595

Epoch: 5| Step: 2
Training loss: 0.8666152954101562
Validation loss: 2.0023890137672424

Epoch: 5| Step: 3
Training loss: 0.6378830671310425
Validation loss: 1.9832326571146648

Epoch: 5| Step: 4
Training loss: 0.8374059796333313
Validation loss: 2.023357172807058

Epoch: 5| Step: 5
Training loss: 0.8354326486587524
Validation loss: 2.007645587126414

Epoch: 5| Step: 6
Training loss: 0.7963014841079712
Validation loss: 2.04298626879851

Epoch: 5| Step: 7
Training loss: 0.8785295486450195
Validation loss: 1.9800511598587036

Epoch: 5| Step: 8
Training loss: 0.361772358417511
Validation loss: 2.0034505824247995

Epoch: 5| Step: 9
Training loss: 1.2641875743865967
Validation loss: 1.9836320281028748

Epoch: 5| Step: 10
Training loss: 1.1488057374954224
Validation loss: 1.9240096757809322

Epoch: 5| Step: 11
Training loss: 1.3650708198547363
Validation loss: 1.992887829740842

Epoch: 179| Step: 0
Training loss: 1.0364584922790527
Validation loss: 1.965533286333084

Epoch: 5| Step: 1
Training loss: 0.8538655042648315
Validation loss: 1.9300166418155034

Epoch: 5| Step: 2
Training loss: 1.0369033813476562
Validation loss: 2.009290501475334

Epoch: 5| Step: 3
Training loss: 0.758998692035675
Validation loss: 1.958518882592519

Epoch: 5| Step: 4
Training loss: 0.6241000294685364
Validation loss: 1.9369516173998516

Epoch: 5| Step: 5
Training loss: 0.5169302821159363
Validation loss: 1.9767112284898758

Epoch: 5| Step: 6
Training loss: 0.9758092761039734
Validation loss: 1.923667460680008

Epoch: 5| Step: 7
Training loss: 0.5694054365158081
Validation loss: 1.9670521020889282

Epoch: 5| Step: 8
Training loss: 0.5974608659744263
Validation loss: 1.9954197605450947

Epoch: 5| Step: 9
Training loss: 0.8985490798950195
Validation loss: 1.9817399978637695

Epoch: 5| Step: 10
Training loss: 0.8563525080680847
Validation loss: 2.044690748055776

Epoch: 5| Step: 11
Training loss: 2.957890272140503
Validation loss: 1.9704373826583226

Epoch: 180| Step: 0
Training loss: 0.9213196635246277
Validation loss: 1.9950794577598572

Epoch: 5| Step: 1
Training loss: 0.8270496129989624
Validation loss: 1.9456491370995839

Epoch: 5| Step: 2
Training loss: 1.0033702850341797
Validation loss: 1.9791326771179836

Epoch: 5| Step: 3
Training loss: 1.0133261680603027
Validation loss: 1.9215207149585087

Epoch: 5| Step: 4
Training loss: 0.5125361680984497
Validation loss: 1.9884442488352458

Epoch: 5| Step: 5
Training loss: 0.6380765438079834
Validation loss: 1.9526947190364201

Epoch: 5| Step: 6
Training loss: 0.9132221341133118
Validation loss: 1.9502542664607365

Epoch: 5| Step: 7
Training loss: 0.8778492212295532
Validation loss: 1.9884594877560933

Epoch: 5| Step: 8
Training loss: 0.9273673295974731
Validation loss: 1.968969518939654

Epoch: 5| Step: 9
Training loss: 0.6498202085494995
Validation loss: 1.972762440641721

Epoch: 5| Step: 10
Training loss: 0.7962511777877808
Validation loss: 2.038489247361819

Epoch: 5| Step: 11
Training loss: 0.4762756824493408
Validation loss: 1.98756339152654

Epoch: 181| Step: 0
Training loss: 0.5550106167793274
Validation loss: 1.999893456697464

Epoch: 5| Step: 1
Training loss: 0.7780284285545349
Validation loss: 2.0036358733971915

Epoch: 5| Step: 2
Training loss: 0.9630159139633179
Validation loss: 1.9530444890260696

Epoch: 5| Step: 3
Training loss: 0.9781836271286011
Validation loss: 1.9561934222777684

Epoch: 5| Step: 4
Training loss: 0.8981372714042664
Validation loss: 1.9879446029663086

Epoch: 5| Step: 5
Training loss: 0.827614426612854
Validation loss: 1.9421395013729732

Epoch: 5| Step: 6
Training loss: 0.8230393528938293
Validation loss: 2.012547641992569

Epoch: 5| Step: 7
Training loss: 0.9507333040237427
Validation loss: 2.037878846128782

Epoch: 5| Step: 8
Training loss: 0.9739810228347778
Validation loss: 1.9872918725013733

Epoch: 5| Step: 9
Training loss: 0.8433570861816406
Validation loss: 1.970597376426061

Epoch: 5| Step: 10
Training loss: 0.6096030473709106
Validation loss: 2.0009572903315225

Epoch: 5| Step: 11
Training loss: 1.1031076908111572
Validation loss: 1.9990368088086445

Epoch: 182| Step: 0
Training loss: 0.9806803464889526
Validation loss: 1.9877522786458333

Epoch: 5| Step: 1
Training loss: 0.890957236289978
Validation loss: 1.954812874396642

Epoch: 5| Step: 2
Training loss: 0.5466755032539368
Validation loss: 2.0219426999489465

Epoch: 5| Step: 3
Training loss: 1.106794834136963
Validation loss: 2.0371625473101935

Epoch: 5| Step: 4
Training loss: 0.6815409660339355
Validation loss: 1.9792009145021439

Epoch: 5| Step: 5
Training loss: 0.7244038581848145
Validation loss: 1.9974288543065388

Epoch: 5| Step: 6
Training loss: 0.9706277847290039
Validation loss: 2.013210659225782

Epoch: 5| Step: 7
Training loss: 0.9131101369857788
Validation loss: 2.049782464901606

Epoch: 5| Step: 8
Training loss: 0.892787754535675
Validation loss: 2.0165449678897858

Epoch: 5| Step: 9
Training loss: 0.9968258142471313
Validation loss: 2.039232204357783

Epoch: 5| Step: 10
Training loss: 0.9943119883537292
Validation loss: 2.0267189840475717

Epoch: 5| Step: 11
Training loss: 1.6208269596099854
Validation loss: 1.9434778143962224

Epoch: 183| Step: 0
Training loss: 0.6112571358680725
Validation loss: 2.0491019934415817

Epoch: 5| Step: 1
Training loss: 1.515151858329773
Validation loss: 1.9761489629745483

Epoch: 5| Step: 2
Training loss: 0.5922015309333801
Validation loss: 2.0271703600883484

Epoch: 5| Step: 3
Training loss: 0.760425865650177
Validation loss: 1.9820039421319962

Epoch: 5| Step: 4
Training loss: 0.8142361640930176
Validation loss: 1.9987627963225048

Epoch: 5| Step: 5
Training loss: 0.4754430651664734
Validation loss: 2.031291907032331

Epoch: 5| Step: 6
Training loss: 0.9680513143539429
Validation loss: 2.027838259935379

Epoch: 5| Step: 7
Training loss: 0.7187919616699219
Validation loss: 2.0114546716213226

Epoch: 5| Step: 8
Training loss: 1.0881016254425049
Validation loss: 2.0022668292125068

Epoch: 5| Step: 9
Training loss: 0.8671334385871887
Validation loss: 2.024869456887245

Epoch: 5| Step: 10
Training loss: 0.7089749574661255
Validation loss: 1.9865356336037319

Epoch: 5| Step: 11
Training loss: 1.524034023284912
Validation loss: 1.9963655024766922

Epoch: 184| Step: 0
Training loss: 0.6181584596633911
Validation loss: 1.9751280148824055

Epoch: 5| Step: 1
Training loss: 1.1182384490966797
Validation loss: 1.9673117647568386

Epoch: 5| Step: 2
Training loss: 0.7013880014419556
Validation loss: 1.9518133749564488

Epoch: 5| Step: 3
Training loss: 0.5336490869522095
Validation loss: 1.9704913248618443

Epoch: 5| Step: 4
Training loss: 0.43745431303977966
Validation loss: 2.019731745123863

Epoch: 5| Step: 5
Training loss: 1.0303339958190918
Validation loss: 2.0133448094129562

Epoch: 5| Step: 6
Training loss: 0.6572324633598328
Validation loss: 1.9671331942081451

Epoch: 5| Step: 7
Training loss: 0.783145546913147
Validation loss: 1.9802939345439274

Epoch: 5| Step: 8
Training loss: 0.8963096737861633
Validation loss: 1.91977791984876

Epoch: 5| Step: 9
Training loss: 1.2481410503387451
Validation loss: 1.932607427239418

Epoch: 5| Step: 10
Training loss: 0.984929084777832
Validation loss: 1.9998013029495876

Epoch: 5| Step: 11
Training loss: 0.8130419254302979
Validation loss: 2.031645640730858

Epoch: 185| Step: 0
Training loss: 0.533719003200531
Validation loss: 1.9676666011412938

Epoch: 5| Step: 1
Training loss: 0.8693920373916626
Validation loss: 1.9926782349745433

Epoch: 5| Step: 2
Training loss: 1.0690807104110718
Validation loss: 2.0058101465304694

Epoch: 5| Step: 3
Training loss: 0.7971312999725342
Validation loss: 2.0251277685165405

Epoch: 5| Step: 4
Training loss: 0.7912142872810364
Validation loss: 1.982057238618533

Epoch: 5| Step: 5
Training loss: 0.7947701215744019
Validation loss: 1.9676782041788101

Epoch: 5| Step: 6
Training loss: 0.5418299436569214
Validation loss: 1.9737172722816467

Epoch: 5| Step: 7
Training loss: 0.6480737924575806
Validation loss: 2.0360127041737237

Epoch: 5| Step: 8
Training loss: 0.6697052717208862
Validation loss: 2.0406567504008613

Epoch: 5| Step: 9
Training loss: 0.6910649538040161
Validation loss: 2.0262474914391837

Epoch: 5| Step: 10
Training loss: 1.1687748432159424
Validation loss: 2.0193317333857217

Epoch: 5| Step: 11
Training loss: 0.32198643684387207
Validation loss: 2.006812661886215

Epoch: 186| Step: 0
Training loss: 0.5882772207260132
Validation loss: 1.9885801772276561

Epoch: 5| Step: 1
Training loss: 0.9595062136650085
Validation loss: 2.0215120911598206

Epoch: 5| Step: 2
Training loss: 0.7950951457023621
Validation loss: 1.9922295461098354

Epoch: 5| Step: 3
Training loss: 0.859218418598175
Validation loss: 2.03608929614226

Epoch: 5| Step: 4
Training loss: 1.2421162128448486
Validation loss: 1.9842516581217449

Epoch: 5| Step: 5
Training loss: 0.7564330101013184
Validation loss: 2.0104121218125024

Epoch: 5| Step: 6
Training loss: 0.41264429688453674
Validation loss: 2.0138561179240546

Epoch: 5| Step: 7
Training loss: 1.0013996362686157
Validation loss: 2.009488672018051

Epoch: 5| Step: 8
Training loss: 0.5323010683059692
Validation loss: 2.0590505401293435

Epoch: 5| Step: 9
Training loss: 0.886627197265625
Validation loss: 2.0148950616518655

Epoch: 5| Step: 10
Training loss: 0.7863910794258118
Validation loss: 2.017977694670359

Epoch: 5| Step: 11
Training loss: 0.3091229200363159
Validation loss: 2.040643254915873

Epoch: 187| Step: 0
Training loss: 0.5908991098403931
Validation loss: 2.0260521521170936

Epoch: 5| Step: 1
Training loss: 0.8506292104721069
Validation loss: 2.014458417892456

Epoch: 5| Step: 2
Training loss: 1.1569459438323975
Validation loss: 2.098196968436241

Epoch: 5| Step: 3
Training loss: 0.6491550803184509
Validation loss: 1.99685999751091

Epoch: 5| Step: 4
Training loss: 0.6321556568145752
Validation loss: 2.013607387741407

Epoch: 5| Step: 5
Training loss: 0.6634213924407959
Validation loss: 2.0264272491137185

Epoch: 5| Step: 6
Training loss: 0.5011552572250366
Validation loss: 2.0079399943351746

Epoch: 5| Step: 7
Training loss: 0.8602752685546875
Validation loss: 2.019631346066793

Epoch: 5| Step: 8
Training loss: 0.5141671299934387
Validation loss: 2.0077232718467712

Epoch: 5| Step: 9
Training loss: 0.49494972825050354
Validation loss: 2.063019091884295

Epoch: 5| Step: 10
Training loss: 1.5255683660507202
Validation loss: 1.9524671385685604

Epoch: 5| Step: 11
Training loss: 1.087073564529419
Validation loss: 1.9649172673622768

Epoch: 188| Step: 0
Training loss: 0.6584922075271606
Validation loss: 2.0378031631310782

Epoch: 5| Step: 1
Training loss: 0.7341357469558716
Validation loss: 1.9926688174406688

Epoch: 5| Step: 2
Training loss: 0.8661704063415527
Validation loss: 1.9747457653284073

Epoch: 5| Step: 3
Training loss: 0.47394734621047974
Validation loss: 2.0087377230326333

Epoch: 5| Step: 4
Training loss: 0.789970874786377
Validation loss: 1.9853779673576355

Epoch: 5| Step: 5
Training loss: 0.5335715413093567
Validation loss: 2.015772288044294

Epoch: 5| Step: 6
Training loss: 1.6090290546417236
Validation loss: 2.015063484509786

Epoch: 5| Step: 7
Training loss: 0.6883679628372192
Validation loss: 2.036840115984281

Epoch: 5| Step: 8
Training loss: 0.8296035528182983
Validation loss: 2.044925237695376

Epoch: 5| Step: 9
Training loss: 0.5211833119392395
Validation loss: 2.0288354754447937

Epoch: 5| Step: 10
Training loss: 0.7972834706306458
Validation loss: 2.0125578939914703

Epoch: 5| Step: 11
Training loss: 0.2459954023361206
Validation loss: 2.058905025323232

Epoch: 189| Step: 0
Training loss: 0.9887675046920776
Validation loss: 2.037501802047094

Epoch: 5| Step: 1
Training loss: 0.9258792996406555
Validation loss: 2.0432706822951636

Epoch: 5| Step: 2
Training loss: 0.48309049010276794
Validation loss: 1.990991214911143

Epoch: 5| Step: 3
Training loss: 0.6129758954048157
Validation loss: 2.0181873043378196

Epoch: 5| Step: 4
Training loss: 0.5682077407836914
Validation loss: 1.9941181689500809

Epoch: 5| Step: 5
Training loss: 0.6903042793273926
Validation loss: 2.1001439293225608

Epoch: 5| Step: 6
Training loss: 1.0130716562271118
Validation loss: 2.0186273604631424

Epoch: 5| Step: 7
Training loss: 0.6764873266220093
Validation loss: 2.0517812420924506

Epoch: 5| Step: 8
Training loss: 1.3252413272857666
Validation loss: 1.958161508043607

Epoch: 5| Step: 9
Training loss: 0.5347991585731506
Validation loss: 1.9982632547616959

Epoch: 5| Step: 10
Training loss: 0.7067397832870483
Validation loss: 1.9755754222472508

Epoch: 5| Step: 11
Training loss: 0.11109578609466553
Validation loss: 2.0282697478930154

Epoch: 190| Step: 0
Training loss: 0.5924287438392639
Validation loss: 2.066807637612025

Epoch: 5| Step: 1
Training loss: 1.2514426708221436
Validation loss: 2.115956485271454

Epoch: 5| Step: 2
Training loss: 0.4882587492465973
Validation loss: 2.029790088534355

Epoch: 5| Step: 3
Training loss: 0.9253951907157898
Validation loss: 2.0120710531870523

Epoch: 5| Step: 4
Training loss: 0.5277804732322693
Validation loss: 1.9645147671302159

Epoch: 5| Step: 5
Training loss: 0.6646004915237427
Validation loss: 1.950450191895167

Epoch: 5| Step: 6
Training loss: 1.019243836402893
Validation loss: 1.9882801175117493

Epoch: 5| Step: 7
Training loss: 0.9330651164054871
Validation loss: 1.939166655143102

Epoch: 5| Step: 8
Training loss: 0.8203528523445129
Validation loss: 1.9697116315364838

Epoch: 5| Step: 9
Training loss: 0.5172406435012817
Validation loss: 1.9470040102799733

Epoch: 5| Step: 10
Training loss: 0.6377552151679993
Validation loss: 1.9584610263506572

Epoch: 5| Step: 11
Training loss: 1.2924515008926392
Validation loss: 1.9950891931851704

Epoch: 191| Step: 0
Training loss: 0.6862319707870483
Validation loss: 1.963841939965884

Epoch: 5| Step: 1
Training loss: 0.9116552472114563
Validation loss: 2.019231100877126

Epoch: 5| Step: 2
Training loss: 0.48134392499923706
Validation loss: 1.9795409093300502

Epoch: 5| Step: 3
Training loss: 0.578313946723938
Validation loss: 1.9534041434526443

Epoch: 5| Step: 4
Training loss: 1.2741565704345703
Validation loss: 1.9446279058853786

Epoch: 5| Step: 5
Training loss: 0.6676836013793945
Validation loss: 1.9801142315069835

Epoch: 5| Step: 6
Training loss: 1.0252118110656738
Validation loss: 2.0192509988943734

Epoch: 5| Step: 7
Training loss: 0.9157724380493164
Validation loss: 1.980156848827998

Epoch: 5| Step: 8
Training loss: 0.7993727922439575
Validation loss: 1.9435859769582748

Epoch: 5| Step: 9
Training loss: 0.3626731038093567
Validation loss: 1.9507089306910832

Epoch: 5| Step: 10
Training loss: 0.6298667192459106
Validation loss: 1.9911905477444332

Epoch: 5| Step: 11
Training loss: 0.500879168510437
Validation loss: 1.991879825790723

Epoch: 192| Step: 0
Training loss: 0.5025254487991333
Validation loss: 1.9510264943043392

Epoch: 5| Step: 1
Training loss: 1.1454826593399048
Validation loss: 1.9687186032533646

Epoch: 5| Step: 2
Training loss: 1.1246494054794312
Validation loss: 2.011552929878235

Epoch: 5| Step: 3
Training loss: 0.7175179123878479
Validation loss: 1.9622347056865692

Epoch: 5| Step: 4
Training loss: 0.9523738622665405
Validation loss: 1.9664134283860524

Epoch: 5| Step: 5
Training loss: 0.45340022444725037
Validation loss: 1.9639037003119786

Epoch: 5| Step: 6
Training loss: 0.46526044607162476
Validation loss: 1.9817049702008565

Epoch: 5| Step: 7
Training loss: 0.9894115328788757
Validation loss: 1.9822742144266765

Epoch: 5| Step: 8
Training loss: 0.6704564690589905
Validation loss: 1.9945098757743835

Epoch: 5| Step: 9
Training loss: 0.5559403300285339
Validation loss: 1.9980194369951885

Epoch: 5| Step: 10
Training loss: 0.7663766145706177
Validation loss: 1.939256027340889

Epoch: 5| Step: 11
Training loss: 0.5331518650054932
Validation loss: 1.99214402337869

Epoch: 193| Step: 0
Training loss: 0.39069223403930664
Validation loss: 2.0067929228146872

Epoch: 5| Step: 1
Training loss: 0.21954020857810974
Validation loss: 1.963526338338852

Epoch: 5| Step: 2
Training loss: 0.6714078187942505
Validation loss: 1.991505816578865

Epoch: 5| Step: 3
Training loss: 0.9180771112442017
Validation loss: 1.9883188605308533

Epoch: 5| Step: 4
Training loss: 0.47310829162597656
Validation loss: 1.9774286299943924

Epoch: 5| Step: 5
Training loss: 0.814230740070343
Validation loss: 1.9991100033124287

Epoch: 5| Step: 6
Training loss: 0.6202534437179565
Validation loss: 1.9604031095902126

Epoch: 5| Step: 7
Training loss: 1.1634734869003296
Validation loss: 2.0244761953751245

Epoch: 5| Step: 8
Training loss: 0.7822650074958801
Validation loss: 2.0405166198809943

Epoch: 5| Step: 9
Training loss: 1.0050665140151978
Validation loss: 2.0116233428319297

Epoch: 5| Step: 10
Training loss: 0.6480829119682312
Validation loss: 2.088172753651937

Epoch: 5| Step: 11
Training loss: 0.7128783464431763
Validation loss: 1.964161217212677

Epoch: 194| Step: 0
Training loss: 0.4250738024711609
Validation loss: 2.0418585538864136

Epoch: 5| Step: 1
Training loss: 0.7869992256164551
Validation loss: 1.9903690765301387

Epoch: 5| Step: 2
Training loss: 0.9075541496276855
Validation loss: 1.9858257174491882

Epoch: 5| Step: 3
Training loss: 1.5499614477157593
Validation loss: 2.0117485423882804

Epoch: 5| Step: 4
Training loss: 0.6656308174133301
Validation loss: 1.96337428689003

Epoch: 5| Step: 5
Training loss: 0.5078037977218628
Validation loss: 2.000501036643982

Epoch: 5| Step: 6
Training loss: 0.3833490014076233
Validation loss: 2.0009931127230325

Epoch: 5| Step: 7
Training loss: 0.7946773767471313
Validation loss: 1.9568350464105606

Epoch: 5| Step: 8
Training loss: 0.6983601450920105
Validation loss: 2.0680993497371674

Epoch: 5| Step: 9
Training loss: 0.7388020753860474
Validation loss: 2.024696578582128

Epoch: 5| Step: 10
Training loss: 0.5255197286605835
Validation loss: 2.010474200050036

Epoch: 5| Step: 11
Training loss: 1.2004706859588623
Validation loss: 2.0329136500755944

Epoch: 195| Step: 0
Training loss: 0.8577858209609985
Validation loss: 1.9904787639776866

Epoch: 5| Step: 1
Training loss: 0.8203733563423157
Validation loss: 2.025270789861679

Epoch: 5| Step: 2
Training loss: 0.9994133114814758
Validation loss: 2.0006383260091147

Epoch: 5| Step: 3
Training loss: 1.0524790287017822
Validation loss: 1.9786131928364437

Epoch: 5| Step: 4
Training loss: 0.6094650030136108
Validation loss: 1.94937768081824

Epoch: 5| Step: 5
Training loss: 0.6209596395492554
Validation loss: 1.9471462567647297

Epoch: 5| Step: 6
Training loss: 0.7855793833732605
Validation loss: 1.9456893851359685

Epoch: 5| Step: 7
Training loss: 0.5136895179748535
Validation loss: 2.003670558333397

Epoch: 5| Step: 8
Training loss: 0.43180131912231445
Validation loss: 1.975181629260381

Epoch: 5| Step: 9
Training loss: 0.7634161710739136
Validation loss: 1.9876875976721446

Epoch: 5| Step: 10
Training loss: 0.5964472889900208
Validation loss: 2.0263978838920593

Epoch: 5| Step: 11
Training loss: 0.14303243160247803
Validation loss: 2.034823109706243

Epoch: 196| Step: 0
Training loss: 0.7125087976455688
Validation loss: 2.0352742820978165

Epoch: 5| Step: 1
Training loss: 0.6728563904762268
Validation loss: 2.0282841523488364

Epoch: 5| Step: 2
Training loss: 0.9057325124740601
Validation loss: 2.0039832442998886

Epoch: 5| Step: 3
Training loss: 0.7916314005851746
Validation loss: 2.0343411217133203

Epoch: 5| Step: 4
Training loss: 0.6600433588027954
Validation loss: 2.0240586747725806

Epoch: 5| Step: 5
Training loss: 0.7737765312194824
Validation loss: 2.028678516546885

Epoch: 5| Step: 6
Training loss: 0.7013236880302429
Validation loss: 2.0215231279532113

Epoch: 5| Step: 7
Training loss: 0.405853271484375
Validation loss: 2.028797368208567

Epoch: 5| Step: 8
Training loss: 0.7172166705131531
Validation loss: 1.9923803706963856

Epoch: 5| Step: 9
Training loss: 0.7763479351997375
Validation loss: 2.0318608631690345

Epoch: 5| Step: 10
Training loss: 0.7030490636825562
Validation loss: 1.9958056261142094

Epoch: 5| Step: 11
Training loss: 0.38705113530158997
Validation loss: 2.0222917596499124

Epoch: 197| Step: 0
Training loss: 0.6547613143920898
Validation loss: 2.0345228910446167

Epoch: 5| Step: 1
Training loss: 0.6967250108718872
Validation loss: 2.0829310764869056

Epoch: 5| Step: 2
Training loss: 0.784569263458252
Validation loss: 2.0242454558610916

Epoch: 5| Step: 3
Training loss: 0.6029456257820129
Validation loss: 2.013329188028971

Epoch: 5| Step: 4
Training loss: 0.8875471949577332
Validation loss: 2.0361223965883255

Epoch: 5| Step: 5
Training loss: 0.34497928619384766
Validation loss: 2.057403638958931

Epoch: 5| Step: 6
Training loss: 1.5510804653167725
Validation loss: 1.9826264629761379

Epoch: 5| Step: 7
Training loss: 0.6127333045005798
Validation loss: 1.9814090877771378

Epoch: 5| Step: 8
Training loss: 0.6805053353309631
Validation loss: 2.01959798236688

Epoch: 5| Step: 9
Training loss: 0.6554710865020752
Validation loss: 2.0673716912666955

Epoch: 5| Step: 10
Training loss: 0.37824586033821106
Validation loss: 2.098603139321009

Epoch: 5| Step: 11
Training loss: 1.3854451179504395
Validation loss: 2.0549029807249704

Epoch: 198| Step: 0
Training loss: 0.5799964666366577
Validation loss: 2.0376088122526803

Epoch: 5| Step: 1
Training loss: 0.7328779101371765
Validation loss: 2.037235826253891

Epoch: 5| Step: 2
Training loss: 0.6335495710372925
Validation loss: 2.0284990668296814

Epoch: 5| Step: 3
Training loss: 0.4396301209926605
Validation loss: 2.002626826365789

Epoch: 5| Step: 4
Training loss: 0.707001268863678
Validation loss: 2.0573779245217643

Epoch: 5| Step: 5
Training loss: 0.7798387408256531
Validation loss: 2.0459196964899697

Epoch: 5| Step: 6
Training loss: 0.5593960285186768
Validation loss: 1.9389952421188354

Epoch: 5| Step: 7
Training loss: 0.8095785975456238
Validation loss: 2.0175258765618005

Epoch: 5| Step: 8
Training loss: 0.8645160794258118
Validation loss: 2.0040009319782257

Epoch: 5| Step: 9
Training loss: 0.8188545107841492
Validation loss: 2.0519182731707892

Epoch: 5| Step: 10
Training loss: 0.9092937707901001
Validation loss: 2.0477693925301232

Epoch: 5| Step: 11
Training loss: 1.535822868347168
Validation loss: 2.046093692382177

Epoch: 199| Step: 0
Training loss: 0.6222183108329773
Validation loss: 1.932518720626831

Epoch: 5| Step: 1
Training loss: 0.6781025528907776
Validation loss: 2.026910508672396

Epoch: 5| Step: 2
Training loss: 0.7194148302078247
Validation loss: 2.064476097623507

Epoch: 5| Step: 3
Training loss: 0.8518213033676147
Validation loss: 2.0571239540974298

Epoch: 5| Step: 4
Training loss: 1.0175247192382812
Validation loss: 2.0703852524360022

Epoch: 5| Step: 5
Training loss: 0.5664840340614319
Validation loss: 2.026096055905024

Epoch: 5| Step: 6
Training loss: 0.6198839545249939
Validation loss: 2.020762324333191

Epoch: 5| Step: 7
Training loss: 1.2108536958694458
Validation loss: 2.103843246897062

Epoch: 5| Step: 8
Training loss: 0.522319495677948
Validation loss: 2.1106531222661338

Epoch: 5| Step: 9
Training loss: 0.7376304268836975
Validation loss: 2.0740053802728653

Epoch: 5| Step: 10
Training loss: 0.6692795753479004
Validation loss: 2.0650468319654465

Epoch: 5| Step: 11
Training loss: 0.4731936454772949
Validation loss: 2.0577243069807687

Epoch: 200| Step: 0
Training loss: 0.2793479263782501
Validation loss: 2.0596897900104523

Epoch: 5| Step: 1
Training loss: 0.5815179944038391
Validation loss: 2.0379426578680673

Epoch: 5| Step: 2
Training loss: 0.9856733083724976
Validation loss: 2.000376269221306

Epoch: 5| Step: 3
Training loss: 0.691881537437439
Validation loss: 1.9970490088065465

Epoch: 5| Step: 4
Training loss: 0.8262500762939453
Validation loss: 2.0351227273543677

Epoch: 5| Step: 5
Training loss: 0.7332725524902344
Validation loss: 2.0321186780929565

Epoch: 5| Step: 6
Training loss: 0.7877908945083618
Validation loss: 2.019894073406855

Epoch: 5| Step: 7
Training loss: 0.790926456451416
Validation loss: 1.965969830751419

Epoch: 5| Step: 8
Training loss: 1.1251622438430786
Validation loss: 2.040654718875885

Epoch: 5| Step: 9
Training loss: 0.538560152053833
Validation loss: 1.985220675667127

Epoch: 5| Step: 10
Training loss: 0.42312726378440857
Validation loss: 2.023410588502884

Epoch: 5| Step: 11
Training loss: 1.123967170715332
Validation loss: 2.035648619135221

Epoch: 201| Step: 0
Training loss: 0.7388029098510742
Validation loss: 1.9626869559288025

Epoch: 5| Step: 1
Training loss: 0.6629935503005981
Validation loss: 2.0050002882877984

Epoch: 5| Step: 2
Training loss: 0.7351446151733398
Validation loss: 2.038357143600782

Epoch: 5| Step: 3
Training loss: 0.694088339805603
Validation loss: 1.9758790632088978

Epoch: 5| Step: 4
Training loss: 0.4769260287284851
Validation loss: 1.992790937423706

Epoch: 5| Step: 5
Training loss: 0.6442795991897583
Validation loss: 2.0034564485152564

Epoch: 5| Step: 6
Training loss: 0.9074430465698242
Validation loss: 2.0866100589434304

Epoch: 5| Step: 7
Training loss: 0.8109432458877563
Validation loss: 2.069645807147026

Epoch: 5| Step: 8
Training loss: 0.5898883938789368
Validation loss: 2.0151624331871667

Epoch: 5| Step: 9
Training loss: 0.6626976132392883
Validation loss: 2.0721475134293237

Epoch: 5| Step: 10
Training loss: 0.8316642642021179
Validation loss: 1.9917510996262233

Epoch: 5| Step: 11
Training loss: 0.4330838918685913
Validation loss: 2.04677215218544

Epoch: 202| Step: 0
Training loss: 0.6747807264328003
Validation loss: 2.071947236855825

Epoch: 5| Step: 1
Training loss: 1.1020169258117676
Validation loss: 2.075356756647428

Epoch: 5| Step: 2
Training loss: 0.4572843015193939
Validation loss: 2.0659652252991996

Epoch: 5| Step: 3
Training loss: 0.7264460325241089
Validation loss: 2.079077531894048

Epoch: 5| Step: 4
Training loss: 0.9145641326904297
Validation loss: 2.07521091401577

Epoch: 5| Step: 5
Training loss: 0.468583881855011
Validation loss: 2.040709833304087

Epoch: 5| Step: 6
Training loss: 0.9472463726997375
Validation loss: 2.09520793457826

Epoch: 5| Step: 7
Training loss: 0.5836802124977112
Validation loss: 2.0707091291745505

Epoch: 5| Step: 8
Training loss: 0.6570470929145813
Validation loss: 2.134411151210467

Epoch: 5| Step: 9
Training loss: 0.73652184009552
Validation loss: 2.1298717061678567

Epoch: 5| Step: 10
Training loss: 0.7767106890678406
Validation loss: 2.094777683417002

Epoch: 5| Step: 11
Training loss: 0.7170671224594116
Validation loss: 2.0371972024440765

Epoch: 203| Step: 0
Training loss: 0.8849414587020874
Validation loss: 2.11300420264403

Epoch: 5| Step: 1
Training loss: 0.9048812985420227
Validation loss: 2.130080461502075

Epoch: 5| Step: 2
Training loss: 0.49834108352661133
Validation loss: 2.106560245156288

Epoch: 5| Step: 3
Training loss: 0.47075343132019043
Validation loss: 2.0574561655521393

Epoch: 5| Step: 4
Training loss: 0.7172978520393372
Validation loss: 2.040859505534172

Epoch: 5| Step: 5
Training loss: 0.5526535511016846
Validation loss: 2.0947236071030297

Epoch: 5| Step: 6
Training loss: 0.8752735257148743
Validation loss: 2.086100528637568

Epoch: 5| Step: 7
Training loss: 0.4069007337093353
Validation loss: 2.144323413570722

Epoch: 5| Step: 8
Training loss: 0.8122469186782837
Validation loss: 2.0666507134834924

Epoch: 5| Step: 9
Training loss: 0.46693676710128784
Validation loss: 2.0741330732901893

Epoch: 5| Step: 10
Training loss: 0.8562114834785461
Validation loss: 2.0143314003944397

Epoch: 5| Step: 11
Training loss: 0.8392754197120667
Validation loss: 2.0779131253560386

Epoch: 204| Step: 0
Training loss: 0.8864104151725769
Validation loss: 2.060948764284452

Epoch: 5| Step: 1
Training loss: 0.7300685048103333
Validation loss: 2.0202347238858542

Epoch: 5| Step: 2
Training loss: 0.8471364974975586
Validation loss: 2.0218061606089273

Epoch: 5| Step: 3
Training loss: 0.8581948280334473
Validation loss: 1.9876642227172852

Epoch: 5| Step: 4
Training loss: 0.5446789860725403
Validation loss: 2.0132404416799545

Epoch: 5| Step: 5
Training loss: 0.6537467837333679
Validation loss: 2.0044858853022256

Epoch: 5| Step: 6
Training loss: 0.8560149073600769
Validation loss: 2.055114731192589

Epoch: 5| Step: 7
Training loss: 0.5387677550315857
Validation loss: 2.011814375718435

Epoch: 5| Step: 8
Training loss: 0.46285659074783325
Validation loss: 2.0411345958709717

Epoch: 5| Step: 9
Training loss: 0.7365631461143494
Validation loss: 2.05460416773955

Epoch: 5| Step: 10
Training loss: 0.49593597650527954
Validation loss: 1.984674448768298

Epoch: 5| Step: 11
Training loss: 0.2764114737510681
Validation loss: 2.0463277449210486

Epoch: 205| Step: 0
Training loss: 0.37363311648368835
Validation loss: 2.1149984846512475

Epoch: 5| Step: 1
Training loss: 0.8760434985160828
Validation loss: 2.0063385715087256

Epoch: 5| Step: 2
Training loss: 0.5840291976928711
Validation loss: 2.042381172378858

Epoch: 5| Step: 3
Training loss: 0.7595879435539246
Validation loss: 2.051750068863233

Epoch: 5| Step: 4
Training loss: 0.5823749303817749
Validation loss: 2.0135868738094964

Epoch: 5| Step: 5
Training loss: 0.838411808013916
Validation loss: 2.0053668220837912

Epoch: 5| Step: 6
Training loss: 0.46032676100730896
Validation loss: 2.0680900663137436

Epoch: 5| Step: 7
Training loss: 0.8157280087471008
Validation loss: 2.0780721257130303

Epoch: 5| Step: 8
Training loss: 0.5690892934799194
Validation loss: 2.122152552008629

Epoch: 5| Step: 9
Training loss: 0.8178947567939758
Validation loss: 2.0896328141291938

Epoch: 5| Step: 10
Training loss: 1.181470274925232
Validation loss: 2.0813399851322174

Epoch: 5| Step: 11
Training loss: 0.2582089304924011
Validation loss: 2.037996639808019

Epoch: 206| Step: 0
Training loss: 0.47749391198158264
Validation loss: 2.0603023717800775

Epoch: 5| Step: 1
Training loss: 0.718256413936615
Validation loss: 2.0344949464003244

Epoch: 5| Step: 2
Training loss: 0.7064110040664673
Validation loss: 2.008758783340454

Epoch: 5| Step: 3
Training loss: 0.9496728777885437
Validation loss: 2.0714978724718094

Epoch: 5| Step: 4
Training loss: 0.6492142677307129
Validation loss: 2.073787902792295

Epoch: 5| Step: 5
Training loss: 0.8881255984306335
Validation loss: 2.1326280186573663

Epoch: 5| Step: 6
Training loss: 0.7860422134399414
Validation loss: 2.053329994281133

Epoch: 5| Step: 7
Training loss: 0.5463454127311707
Validation loss: 2.0821047127246857

Epoch: 5| Step: 8
Training loss: 0.8228161931037903
Validation loss: 2.0849200785160065

Epoch: 5| Step: 9
Training loss: 0.5657154321670532
Validation loss: 2.0476121505101523

Epoch: 5| Step: 10
Training loss: 0.6539003849029541
Validation loss: 2.043084462483724

Epoch: 5| Step: 11
Training loss: 0.7906012535095215
Validation loss: 2.0657934745152793

Epoch: 207| Step: 0
Training loss: 0.9032865762710571
Validation loss: 2.0981382727622986

Epoch: 5| Step: 1
Training loss: 0.41416651010513306
Validation loss: 2.0935744792222977

Epoch: 5| Step: 2
Training loss: 0.4777287542819977
Validation loss: 2.107988655567169

Epoch: 5| Step: 3
Training loss: 1.1906105279922485
Validation loss: 2.036761224269867

Epoch: 5| Step: 4
Training loss: 0.681300699710846
Validation loss: 2.043053780992826

Epoch: 5| Step: 5
Training loss: 0.7552953362464905
Validation loss: 2.097299878795942

Epoch: 5| Step: 6
Training loss: 0.8317066431045532
Validation loss: 2.085854798555374

Epoch: 5| Step: 7
Training loss: 0.7896454930305481
Validation loss: 2.08699664970239

Epoch: 5| Step: 8
Training loss: 0.9003779292106628
Validation loss: 2.0635662774244943

Epoch: 5| Step: 9
Training loss: 0.744269847869873
Validation loss: 2.060266142090162

Epoch: 5| Step: 10
Training loss: 0.5865338444709778
Validation loss: 2.0537726879119873

Epoch: 5| Step: 11
Training loss: 0.787405252456665
Validation loss: 2.081318750977516

Epoch: 208| Step: 0
Training loss: 0.6487337350845337
Validation loss: 2.06720407307148

Epoch: 5| Step: 1
Training loss: 0.7974660992622375
Validation loss: 2.116522034009298

Epoch: 5| Step: 2
Training loss: 0.45117196440696716
Validation loss: 2.0895034074783325

Epoch: 5| Step: 3
Training loss: 0.9002472162246704
Validation loss: 2.1114358653624854

Epoch: 5| Step: 4
Training loss: 0.4039057791233063
Validation loss: 2.0814297099908194

Epoch: 5| Step: 5
Training loss: 0.39621394872665405
Validation loss: 2.112801174322764

Epoch: 5| Step: 6
Training loss: 0.6814637184143066
Validation loss: 2.1053088257710137

Epoch: 5| Step: 7
Training loss: 0.700442373752594
Validation loss: 2.0404732475678125

Epoch: 5| Step: 8
Training loss: 0.8562183380126953
Validation loss: 2.0914820382992425

Epoch: 5| Step: 9
Training loss: 0.48696404695510864
Validation loss: 2.088155115644137

Epoch: 5| Step: 10
Training loss: 1.1922969818115234
Validation loss: 2.0571366449197135

Epoch: 5| Step: 11
Training loss: 0.27355074882507324
Validation loss: 2.0378718078136444

Epoch: 209| Step: 0
Training loss: 0.67055743932724
Validation loss: 2.0553665111462274

Epoch: 5| Step: 1
Training loss: 0.4498845636844635
Validation loss: 2.0645413945118585

Epoch: 5| Step: 2
Training loss: 0.3652431070804596
Validation loss: 2.004681020975113

Epoch: 5| Step: 3
Training loss: 1.0468976497650146
Validation loss: 2.08066034813722

Epoch: 5| Step: 4
Training loss: 0.6156338453292847
Validation loss: 2.0313634276390076

Epoch: 5| Step: 5
Training loss: 0.5960550308227539
Validation loss: 2.0279133170843124

Epoch: 5| Step: 6
Training loss: 0.6266261339187622
Validation loss: 2.009434680143992

Epoch: 5| Step: 7
Training loss: 0.5284010171890259
Validation loss: 2.0385681688785553

Epoch: 5| Step: 8
Training loss: 0.8087859153747559
Validation loss: 2.0432316412528357

Epoch: 5| Step: 9
Training loss: 0.7352163791656494
Validation loss: 2.0712524553140006

Epoch: 5| Step: 10
Training loss: 0.45049095153808594
Validation loss: 2.043203646938006

Epoch: 5| Step: 11
Training loss: 0.8263161182403564
Validation loss: 2.0756384829680123

Epoch: 210| Step: 0
Training loss: 0.8452274203300476
Validation loss: 2.0198412040869393

Epoch: 5| Step: 1
Training loss: 0.3746716380119324
Validation loss: 2.069006676475207

Epoch: 5| Step: 2
Training loss: 0.5212920308113098
Validation loss: 2.066090553998947

Epoch: 5| Step: 3
Training loss: 0.951010525226593
Validation loss: 2.060005620121956

Epoch: 5| Step: 4
Training loss: 0.4471115171909332
Validation loss: 2.07398913304011

Epoch: 5| Step: 5
Training loss: 0.6206161379814148
Validation loss: 2.0966375718514123

Epoch: 5| Step: 6
Training loss: 0.8245071172714233
Validation loss: 2.077899763981501

Epoch: 5| Step: 7
Training loss: 0.4871671199798584
Validation loss: 2.0741509397824607

Epoch: 5| Step: 8
Training loss: 0.6382375955581665
Validation loss: 1.9981046319007874

Epoch: 5| Step: 9
Training loss: 0.4996337294578552
Validation loss: 2.06889271736145

Epoch: 5| Step: 10
Training loss: 0.9676381349563599
Validation loss: 2.025793810685476

Epoch: 5| Step: 11
Training loss: 0.450950026512146
Validation loss: 2.0412530402342477

Epoch: 211| Step: 0
Training loss: 0.446240097284317
Validation loss: 2.051500360171

Epoch: 5| Step: 1
Training loss: 0.9215426445007324
Validation loss: 2.076044887304306

Epoch: 5| Step: 2
Training loss: 0.5050786733627319
Validation loss: 2.017699753244718

Epoch: 5| Step: 3
Training loss: 0.33868253231048584
Validation loss: 2.0338201274474463

Epoch: 5| Step: 4
Training loss: 0.5257246494293213
Validation loss: 2.060906638701757

Epoch: 5| Step: 5
Training loss: 0.8868274688720703
Validation loss: 2.0703276495138803

Epoch: 5| Step: 6
Training loss: 0.6015608906745911
Validation loss: 2.000111386179924

Epoch: 5| Step: 7
Training loss: 0.512473464012146
Validation loss: 2.061402147014936

Epoch: 5| Step: 8
Training loss: 0.8775409460067749
Validation loss: 2.0438257604837418

Epoch: 5| Step: 9
Training loss: 0.5183885097503662
Validation loss: 1.9953319728374481

Epoch: 5| Step: 10
Training loss: 0.5454211235046387
Validation loss: 2.050539493560791

Epoch: 5| Step: 11
Training loss: 2.1669631004333496
Validation loss: 2.091603269179662

Epoch: 212| Step: 0
Training loss: 1.1182035207748413
Validation loss: 2.0336770514647164

Epoch: 5| Step: 1
Training loss: 0.6015669703483582
Validation loss: 2.0779046565294266

Epoch: 5| Step: 2
Training loss: 0.7065819501876831
Validation loss: 2.060247913002968

Epoch: 5| Step: 3
Training loss: 0.7533017992973328
Validation loss: 2.0337842603524527

Epoch: 5| Step: 4
Training loss: 0.3955363631248474
Validation loss: 2.105309839049975

Epoch: 5| Step: 5
Training loss: 0.5902714133262634
Validation loss: 2.0467128853003183

Epoch: 5| Step: 6
Training loss: 0.9110279083251953
Validation loss: 2.0739219238360724

Epoch: 5| Step: 7
Training loss: 0.7633669972419739
Validation loss: 2.0949062456687293

Epoch: 5| Step: 8
Training loss: 0.3876047730445862
Validation loss: 2.0883645663658776

Epoch: 5| Step: 9
Training loss: 0.537882924079895
Validation loss: 2.111164703965187

Epoch: 5| Step: 10
Training loss: 0.600164532661438
Validation loss: 2.091386303305626

Epoch: 5| Step: 11
Training loss: 0.044600725173950195
Validation loss: 2.078533743818601

Epoch: 213| Step: 0
Training loss: 0.7745620012283325
Validation loss: 2.070767879486084

Epoch: 5| Step: 1
Training loss: 0.4149414598941803
Validation loss: 2.1297804514567056

Epoch: 5| Step: 2
Training loss: 0.7065810561180115
Validation loss: 2.1169072737296424

Epoch: 5| Step: 3
Training loss: 0.4287681579589844
Validation loss: 2.1037799566984177

Epoch: 5| Step: 4
Training loss: 0.8653039932250977
Validation loss: 2.1548507809638977

Epoch: 5| Step: 5
Training loss: 0.688534677028656
Validation loss: 2.130131781101227

Epoch: 5| Step: 6
Training loss: 1.0217021703720093
Validation loss: 2.1216492553551993

Epoch: 5| Step: 7
Training loss: 0.8256121873855591
Validation loss: 2.0967679719130197

Epoch: 5| Step: 8
Training loss: 0.4737017750740051
Validation loss: 2.1114345540603003

Epoch: 5| Step: 9
Training loss: 0.33324986696243286
Validation loss: 2.066517228881518

Epoch: 5| Step: 10
Training loss: 0.763229489326477
Validation loss: 2.1034660836060843

Epoch: 5| Step: 11
Training loss: 1.1593363285064697
Validation loss: 2.084097698330879

Epoch: 214| Step: 0
Training loss: 0.4323154091835022
Validation loss: 2.096019377311071

Epoch: 5| Step: 1
Training loss: 1.2243115901947021
Validation loss: 2.075423618157705

Epoch: 5| Step: 2
Training loss: 0.6912174224853516
Validation loss: 2.1181786557038627

Epoch: 5| Step: 3
Training loss: 0.6921740770339966
Validation loss: 2.10855300227801

Epoch: 5| Step: 4
Training loss: 0.6552192568778992
Validation loss: 2.042560706535975

Epoch: 5| Step: 5
Training loss: 0.7477866411209106
Validation loss: 2.0751545627911887

Epoch: 5| Step: 6
Training loss: 1.0629924535751343
Validation loss: 2.079767271876335

Epoch: 5| Step: 7
Training loss: 0.4749213755130768
Validation loss: 2.0436673065026603

Epoch: 5| Step: 8
Training loss: 0.5032934546470642
Validation loss: 2.047657231489817

Epoch: 5| Step: 9
Training loss: 0.6832491159439087
Validation loss: 2.0297641654809317

Epoch: 5| Step: 10
Training loss: 0.5245674252510071
Validation loss: 2.0472547809282937

Epoch: 5| Step: 11
Training loss: 0.4012424945831299
Validation loss: 2.048646330833435

Epoch: 215| Step: 0
Training loss: 0.8843178749084473
Validation loss: 2.071285585562388

Epoch: 5| Step: 1
Training loss: 0.6045259237289429
Validation loss: 2.0376849124828973

Epoch: 5| Step: 2
Training loss: 0.8523834347724915
Validation loss: 1.988666946689288

Epoch: 5| Step: 3
Training loss: 0.5099108219146729
Validation loss: 2.0190111696720123

Epoch: 5| Step: 4
Training loss: 0.6968779563903809
Validation loss: 1.9926433712244034

Epoch: 5| Step: 5
Training loss: 0.5302709937095642
Validation loss: 2.027154877781868

Epoch: 5| Step: 6
Training loss: 0.96852046251297
Validation loss: 1.9985817323128383

Epoch: 5| Step: 7
Training loss: 0.4324837625026703
Validation loss: 2.064507558941841

Epoch: 5| Step: 8
Training loss: 0.6211450695991516
Validation loss: 2.0292072941859565

Epoch: 5| Step: 9
Training loss: 0.3317641615867615
Validation loss: 2.0195274899403253

Epoch: 5| Step: 10
Training loss: 0.8008047342300415
Validation loss: 2.0645311375459037

Epoch: 5| Step: 11
Training loss: 0.15629935264587402
Validation loss: 2.0182015349467597

Epoch: 216| Step: 0
Training loss: 0.6068904995918274
Validation loss: 2.0454798539479575

Epoch: 5| Step: 1
Training loss: 0.6489840745925903
Validation loss: 2.0024987111488977

Epoch: 5| Step: 2
Training loss: 1.0381313562393188
Validation loss: 2.061058203379313

Epoch: 5| Step: 3
Training loss: 0.8172116279602051
Validation loss: 2.0855727841456733

Epoch: 5| Step: 4
Training loss: 0.4862174987792969
Validation loss: 2.0331841160853705

Epoch: 5| Step: 5
Training loss: 0.4827146530151367
Validation loss: 2.0505947967370353

Epoch: 5| Step: 6
Training loss: 0.46680229902267456
Validation loss: 2.084603726863861

Epoch: 5| Step: 7
Training loss: 0.6050877571105957
Validation loss: 2.0773511479298272

Epoch: 5| Step: 8
Training loss: 0.6687270998954773
Validation loss: 2.055935507019361

Epoch: 5| Step: 9
Training loss: 0.6797963380813599
Validation loss: 2.049410248796145

Epoch: 5| Step: 10
Training loss: 0.6258578300476074
Validation loss: 2.0650987029075623

Epoch: 5| Step: 11
Training loss: 0.2304587960243225
Validation loss: 2.1036743024984994

Epoch: 217| Step: 0
Training loss: 0.5152284502983093
Validation loss: 2.0793286512295404

Epoch: 5| Step: 1
Training loss: 0.980660617351532
Validation loss: 2.0851809730132422

Epoch: 5| Step: 2
Training loss: 0.9047706723213196
Validation loss: 2.0609533290068307

Epoch: 5| Step: 3
Training loss: 0.831934928894043
Validation loss: 2.0531920045614243

Epoch: 5| Step: 4
Training loss: 0.7508906126022339
Validation loss: 2.081139420469602

Epoch: 5| Step: 5
Training loss: 0.4810730516910553
Validation loss: 2.060105914870898

Epoch: 5| Step: 6
Training loss: 0.2500995397567749
Validation loss: 2.0805804828802743

Epoch: 5| Step: 7
Training loss: 0.5545483827590942
Validation loss: 2.0762566725413003

Epoch: 5| Step: 8
Training loss: 0.38911938667297363
Validation loss: 2.046284005045891

Epoch: 5| Step: 9
Training loss: 0.7731026411056519
Validation loss: 2.126900394757589

Epoch: 5| Step: 10
Training loss: 0.6551893353462219
Validation loss: 2.0330716371536255

Epoch: 5| Step: 11
Training loss: 0.37746211886405945
Validation loss: 2.056072562932968

Epoch: 218| Step: 0
Training loss: 0.6480478048324585
Validation loss: 2.058644930521647

Epoch: 5| Step: 1
Training loss: 0.392865389585495
Validation loss: 2.0534654359022775

Epoch: 5| Step: 2
Training loss: 0.36755090951919556
Validation loss: 2.036651834845543

Epoch: 5| Step: 3
Training loss: 0.46121034026145935
Validation loss: 2.090436185399691

Epoch: 5| Step: 4
Training loss: 0.4152345657348633
Validation loss: 2.0234982520341873

Epoch: 5| Step: 5
Training loss: 0.3786027133464813
Validation loss: 2.070526992281278

Epoch: 5| Step: 6
Training loss: 0.9278534054756165
Validation loss: 2.0525504300991693

Epoch: 5| Step: 7
Training loss: 0.6416076421737671
Validation loss: 2.0488780786593757

Epoch: 5| Step: 8
Training loss: 0.8849852681159973
Validation loss: 2.0016682545344033

Epoch: 5| Step: 9
Training loss: 1.1554971933364868
Validation loss: 2.000420714418093

Epoch: 5| Step: 10
Training loss: 0.5501208305358887
Validation loss: 2.0450634757677713

Epoch: 5| Step: 11
Training loss: 0.20792925357818604
Validation loss: 2.0652582993110022

Epoch: 219| Step: 0
Training loss: 0.40893954038619995
Validation loss: 2.0453288902839026

Epoch: 5| Step: 1
Training loss: 0.47661828994750977
Validation loss: 2.040352533260981

Epoch: 5| Step: 2
Training loss: 0.8292531967163086
Validation loss: 2.008328676223755

Epoch: 5| Step: 3
Training loss: 0.7713638544082642
Validation loss: 2.0413482387860618

Epoch: 5| Step: 4
Training loss: 0.8096135854721069
Validation loss: 2.0208734770615897

Epoch: 5| Step: 5
Training loss: 0.4132355749607086
Validation loss: 2.083935931324959

Epoch: 5| Step: 6
Training loss: 0.8429826498031616
Validation loss: 2.110771889487902

Epoch: 5| Step: 7
Training loss: 0.7516834735870361
Validation loss: 2.0309362212816873

Epoch: 5| Step: 8
Training loss: 0.4409761428833008
Validation loss: 2.0802452117204666

Epoch: 5| Step: 9
Training loss: 0.51604825258255
Validation loss: 2.0637427618106208

Epoch: 5| Step: 10
Training loss: 0.5717416405677795
Validation loss: 2.1039451311031976

Epoch: 5| Step: 11
Training loss: 0.22068142890930176
Validation loss: 2.0916923930247626

Epoch: 220| Step: 0
Training loss: 0.46635180711746216
Validation loss: 2.032640650868416

Epoch: 5| Step: 1
Training loss: 0.6303712725639343
Validation loss: 2.0553742994864783

Epoch: 5| Step: 2
Training loss: 0.6989682912826538
Validation loss: 2.0918948451677957

Epoch: 5| Step: 3
Training loss: 1.02325439453125
Validation loss: 2.042299047112465

Epoch: 5| Step: 4
Training loss: 0.7457237839698792
Validation loss: 1.999241645137469

Epoch: 5| Step: 5
Training loss: 0.5090652704238892
Validation loss: 1.9672372688849766

Epoch: 5| Step: 6
Training loss: 0.5545610189437866
Validation loss: 2.0400502483050027

Epoch: 5| Step: 7
Training loss: 0.7374542355537415
Validation loss: 2.0265070696671805

Epoch: 5| Step: 8
Training loss: 0.40734153985977173
Validation loss: 2.0594304154316583

Epoch: 5| Step: 9
Training loss: 0.6100775599479675
Validation loss: 2.0252012461423874

Epoch: 5| Step: 10
Training loss: 0.42780572175979614
Validation loss: 2.0742343167463937

Epoch: 5| Step: 11
Training loss: 0.8888681530952454
Validation loss: 1.9810993125041325

Epoch: 221| Step: 0
Training loss: 0.4298263490200043
Validation loss: 2.0701447625954947

Epoch: 5| Step: 1
Training loss: 0.5195292830467224
Validation loss: 2.061978653073311

Epoch: 5| Step: 2
Training loss: 0.6827602982521057
Validation loss: 2.08635022242864

Epoch: 5| Step: 3
Training loss: 0.6232998371124268
Validation loss: 2.012321333090464

Epoch: 5| Step: 4
Training loss: 0.8466496467590332
Validation loss: 2.0396293302377067

Epoch: 5| Step: 5
Training loss: 0.5474846959114075
Validation loss: 2.016821935772896

Epoch: 5| Step: 6
Training loss: 0.6467453241348267
Validation loss: 2.0466137131055198

Epoch: 5| Step: 7
Training loss: 0.5295524597167969
Validation loss: 1.9824285556872685

Epoch: 5| Step: 8
Training loss: 0.4866928458213806
Validation loss: 2.048860793312391

Epoch: 5| Step: 9
Training loss: 0.6604617834091187
Validation loss: 2.082039291659991

Epoch: 5| Step: 10
Training loss: 0.7799608707427979
Validation loss: 2.0571637004613876

Epoch: 5| Step: 11
Training loss: 0.3177608251571655
Validation loss: 2.0423554281393685

Epoch: 222| Step: 0
Training loss: 0.8482087254524231
Validation loss: 2.060685550173124

Epoch: 5| Step: 1
Training loss: 0.5095049142837524
Validation loss: 2.071287920077642

Epoch: 5| Step: 2
Training loss: 0.48095378279685974
Validation loss: 2.0099573532740274

Epoch: 5| Step: 3
Training loss: 0.4472272992134094
Validation loss: 2.0072586884101233

Epoch: 5| Step: 4
Training loss: 0.5953251123428345
Validation loss: 1.9940396845340729

Epoch: 5| Step: 5
Training loss: 0.7543528079986572
Validation loss: 2.047911594311396

Epoch: 5| Step: 6
Training loss: 0.6505869626998901
Validation loss: 2.0601176967223487

Epoch: 5| Step: 7
Training loss: 0.38533076643943787
Validation loss: 2.0578408539295197

Epoch: 5| Step: 8
Training loss: 0.8221456408500671
Validation loss: 2.0643868992726007

Epoch: 5| Step: 9
Training loss: 0.971612274646759
Validation loss: 2.037564386924108

Epoch: 5| Step: 10
Training loss: 0.570930004119873
Validation loss: 2.1481410562992096

Epoch: 5| Step: 11
Training loss: 0.6291279792785645
Validation loss: 2.046172246336937

Epoch: 223| Step: 0
Training loss: 0.45751839876174927
Validation loss: 1.9966250707705815

Epoch: 5| Step: 1
Training loss: 0.40054941177368164
Validation loss: 2.073898176352183

Epoch: 5| Step: 2
Training loss: 0.5721989274024963
Validation loss: 2.1043893893559775

Epoch: 5| Step: 3
Training loss: 1.021936058998108
Validation loss: 2.0191931823889413

Epoch: 5| Step: 4
Training loss: 0.6307122707366943
Validation loss: 2.0797994832197824

Epoch: 5| Step: 5
Training loss: 0.3960460126399994
Validation loss: 2.0110506266355515

Epoch: 5| Step: 6
Training loss: 0.8626338243484497
Validation loss: 2.0573910673459372

Epoch: 5| Step: 7
Training loss: 0.4925174117088318
Validation loss: 2.070427487293879

Epoch: 5| Step: 8
Training loss: 0.6006444096565247
Validation loss: 2.0508147229750953

Epoch: 5| Step: 9
Training loss: 0.7308942675590515
Validation loss: 2.0382221241792045

Epoch: 5| Step: 10
Training loss: 0.5676853060722351
Validation loss: 2.062165076533953

Epoch: 5| Step: 11
Training loss: 0.6459044218063354
Validation loss: 2.0654035061597824

Epoch: 224| Step: 0
Training loss: 0.5875449180603027
Validation loss: 2.005511353413264

Epoch: 5| Step: 1
Training loss: 0.8436307907104492
Validation loss: 2.0553585092226663

Epoch: 5| Step: 2
Training loss: 0.5676015615463257
Validation loss: 2.074734186132749

Epoch: 5| Step: 3
Training loss: 0.6737387776374817
Validation loss: 2.040484994649887

Epoch: 5| Step: 4
Training loss: 0.7973499298095703
Validation loss: 2.036471967895826

Epoch: 5| Step: 5
Training loss: 0.3897905945777893
Validation loss: 2.0697449843088784

Epoch: 5| Step: 6
Training loss: 0.6353758573532104
Validation loss: 1.9818213830391567

Epoch: 5| Step: 7
Training loss: 0.571626603603363
Validation loss: 2.064209297299385

Epoch: 5| Step: 8
Training loss: 0.6441572904586792
Validation loss: 2.063014646371206

Epoch: 5| Step: 9
Training loss: 0.4553638994693756
Validation loss: 2.0621476769447327

Epoch: 5| Step: 10
Training loss: 0.4134191870689392
Validation loss: 2.052497406800588

Epoch: 5| Step: 11
Training loss: 0.8639998435974121
Validation loss: 2.0765435000260672

Epoch: 225| Step: 0
Training loss: 0.520964503288269
Validation loss: 2.10749559601148

Epoch: 5| Step: 1
Training loss: 0.4771270751953125
Validation loss: 2.0038427313168845

Epoch: 5| Step: 2
Training loss: 0.8571707010269165
Validation loss: 2.0651655544837317

Epoch: 5| Step: 3
Training loss: 0.5296791195869446
Validation loss: 2.026563669244448

Epoch: 5| Step: 4
Training loss: 0.6640863418579102
Validation loss: 2.040992707014084

Epoch: 5| Step: 5
Training loss: 0.5399581789970398
Validation loss: 2.065350686510404

Epoch: 5| Step: 6
Training loss: 0.5259591341018677
Validation loss: 2.075069045027097

Epoch: 5| Step: 7
Training loss: 0.29276424646377563
Validation loss: 2.030068134268125

Epoch: 5| Step: 8
Training loss: 0.5922747850418091
Validation loss: 2.056653286019961

Epoch: 5| Step: 9
Training loss: 0.6365591287612915
Validation loss: 2.044080138206482

Epoch: 5| Step: 10
Training loss: 0.9178754687309265
Validation loss: 2.0299117316802344

Epoch: 5| Step: 11
Training loss: 1.0040780305862427
Validation loss: 2.0497316966454187

Epoch: 226| Step: 0
Training loss: 0.6096572875976562
Validation loss: 2.0403097669283548

Epoch: 5| Step: 1
Training loss: 0.7188084721565247
Validation loss: 2.0514393945535025

Epoch: 5| Step: 2
Training loss: 0.5148301124572754
Validation loss: 2.023424302538236

Epoch: 5| Step: 3
Training loss: 0.5163978338241577
Validation loss: 2.06339023510615

Epoch: 5| Step: 4
Training loss: 0.6731364727020264
Validation loss: 2.0589688817660012

Epoch: 5| Step: 5
Training loss: 0.3804375231266022
Validation loss: 2.091673105955124

Epoch: 5| Step: 6
Training loss: 0.5736879110336304
Validation loss: 2.0761533081531525

Epoch: 5| Step: 7
Training loss: 0.6771365404129028
Validation loss: 2.116831198334694

Epoch: 5| Step: 8
Training loss: 0.5170297026634216
Validation loss: 2.1059755384922028

Epoch: 5| Step: 9
Training loss: 0.5829558372497559
Validation loss: 2.084721008936564

Epoch: 5| Step: 10
Training loss: 0.9100180864334106
Validation loss: 2.0938619722922645

Epoch: 5| Step: 11
Training loss: 0.3798191547393799
Validation loss: 2.131090372800827

Epoch: 227| Step: 0
Training loss: 1.1276699304580688
Validation loss: 2.109490007162094

Epoch: 5| Step: 1
Training loss: 0.40973788499832153
Validation loss: 2.090098867813746

Epoch: 5| Step: 2
Training loss: 0.5669949054718018
Validation loss: 2.095567842324575

Epoch: 5| Step: 3
Training loss: 0.7358182668685913
Validation loss: 2.1405738840500512

Epoch: 5| Step: 4
Training loss: 0.6424480676651001
Validation loss: 2.1758146037658057

Epoch: 5| Step: 5
Training loss: 0.4646853804588318
Validation loss: 2.159357766310374

Epoch: 5| Step: 6
Training loss: 0.5503508448600769
Validation loss: 2.1588050574064255

Epoch: 5| Step: 7
Training loss: 0.8402972221374512
Validation loss: 2.0810627390940986

Epoch: 5| Step: 8
Training loss: 0.6337629556655884
Validation loss: 2.074397032459577

Epoch: 5| Step: 9
Training loss: 0.6031007170677185
Validation loss: 2.066659947236379

Epoch: 5| Step: 10
Training loss: 0.31017613410949707
Validation loss: 1.9976202249526978

Epoch: 5| Step: 11
Training loss: 0.2921915650367737
Validation loss: 2.062066674232483

Epoch: 228| Step: 0
Training loss: 0.7490135431289673
Validation loss: 2.063785324494044

Epoch: 5| Step: 1
Training loss: 1.446427583694458
Validation loss: 2.135454297065735

Epoch: 5| Step: 2
Training loss: 1.0641355514526367
Validation loss: 2.1359909723202386

Epoch: 5| Step: 3
Training loss: 0.7747337818145752
Validation loss: 2.1230681190888085

Epoch: 5| Step: 4
Training loss: 0.7568986415863037
Validation loss: 2.1384173383315406

Epoch: 5| Step: 5
Training loss: 0.6925753951072693
Validation loss: 2.0432492146889367

Epoch: 5| Step: 6
Training loss: 0.38767629861831665
Validation loss: 2.0004736930131912

Epoch: 5| Step: 7
Training loss: 1.0288127660751343
Validation loss: 2.032925526301066

Epoch: 5| Step: 8
Training loss: 0.900850772857666
Validation loss: 2.006745368242264

Epoch: 5| Step: 9
Training loss: 0.43803438544273376
Validation loss: 2.1393652657667794

Epoch: 5| Step: 10
Training loss: 0.2980629801750183
Validation loss: 2.056251441438993

Epoch: 5| Step: 11
Training loss: 0.5859159231185913
Validation loss: 2.0443849017222724

Epoch: 229| Step: 0
Training loss: 0.5823163986206055
Validation loss: 2.0528187851111093

Epoch: 5| Step: 1
Training loss: 0.6346797347068787
Validation loss: 2.056941971182823

Epoch: 5| Step: 2
Training loss: 0.8088691830635071
Validation loss: 2.020453562339147

Epoch: 5| Step: 3
Training loss: 0.4939810633659363
Validation loss: 2.0122960259517035

Epoch: 5| Step: 4
Training loss: 0.6288880109786987
Validation loss: 2.06849534312884

Epoch: 5| Step: 5
Training loss: 0.7943600416183472
Validation loss: 2.083059087395668

Epoch: 5| Step: 6
Training loss: 0.6944503784179688
Validation loss: 2.0793360074361167

Epoch: 5| Step: 7
Training loss: 0.43373268842697144
Validation loss: 2.0380618423223495

Epoch: 5| Step: 8
Training loss: 0.7965877652168274
Validation loss: 2.065195550521215

Epoch: 5| Step: 9
Training loss: 0.6117636561393738
Validation loss: 2.038474534948667

Epoch: 5| Step: 10
Training loss: 0.5262298583984375
Validation loss: 2.000634322563807

Epoch: 5| Step: 11
Training loss: 0.6164512634277344
Validation loss: 2.088140164812406

Epoch: 230| Step: 0
Training loss: 0.4895015358924866
Validation loss: 2.0960568686326346

Epoch: 5| Step: 1
Training loss: 0.9969331622123718
Validation loss: 2.03380911052227

Epoch: 5| Step: 2
Training loss: 0.3828471601009369
Validation loss: 2.060881500442823

Epoch: 5| Step: 3
Training loss: 0.5832809805870056
Validation loss: 2.0396058609088263

Epoch: 5| Step: 4
Training loss: 0.5719789266586304
Validation loss: 2.077331840991974

Epoch: 5| Step: 5
Training loss: 0.7799383401870728
Validation loss: 2.069682866334915

Epoch: 5| Step: 6
Training loss: 0.5992535352706909
Validation loss: 2.0402140617370605

Epoch: 5| Step: 7
Training loss: 0.5052987933158875
Validation loss: 2.053630918264389

Epoch: 5| Step: 8
Training loss: 0.46344462037086487
Validation loss: 2.051958918571472

Epoch: 5| Step: 9
Training loss: 0.7496396899223328
Validation loss: 2.011549264192581

Epoch: 5| Step: 10
Training loss: 0.5060313940048218
Validation loss: 1.9973548750082653

Epoch: 5| Step: 11
Training loss: 0.23892879486083984
Validation loss: 2.056195855140686

Epoch: 231| Step: 0
Training loss: 0.5586925148963928
Validation loss: 2.084087550640106

Epoch: 5| Step: 1
Training loss: 0.7799166440963745
Validation loss: 2.112952967484792

Epoch: 5| Step: 2
Training loss: 0.542441725730896
Validation loss: 2.13576503098011

Epoch: 5| Step: 3
Training loss: 0.6387923955917358
Validation loss: 2.059475600719452

Epoch: 5| Step: 4
Training loss: 1.0008862018585205
Validation loss: 2.077980488538742

Epoch: 5| Step: 5
Training loss: 0.805498480796814
Validation loss: 2.0670219262441

Epoch: 5| Step: 6
Training loss: 0.7516393065452576
Validation loss: 2.0452036758263907

Epoch: 5| Step: 7
Training loss: 0.5633589625358582
Validation loss: 2.020403598745664

Epoch: 5| Step: 8
Training loss: 0.8143365979194641
Validation loss: 2.0547925581534705

Epoch: 5| Step: 9
Training loss: 0.45029839873313904
Validation loss: 1.991265594959259

Epoch: 5| Step: 10
Training loss: 0.5426580905914307
Validation loss: 2.0538717856009803

Epoch: 5| Step: 11
Training loss: 0.5097696781158447
Validation loss: 2.0690292666355767

Epoch: 232| Step: 0
Training loss: 0.602617621421814
Validation loss: 2.077822099129359

Epoch: 5| Step: 1
Training loss: 0.4616311192512512
Validation loss: 2.071356082955996

Epoch: 5| Step: 2
Training loss: 0.29479295015335083
Validation loss: 2.0574684838453927

Epoch: 5| Step: 3
Training loss: 0.467934787273407
Validation loss: 2.058655947446823

Epoch: 5| Step: 4
Training loss: 0.8616191148757935
Validation loss: 2.0821157842874527

Epoch: 5| Step: 5
Training loss: 0.3452575206756592
Validation loss: 2.0644691586494446

Epoch: 5| Step: 6
Training loss: 0.7722383737564087
Validation loss: 2.0262747953335443

Epoch: 5| Step: 7
Training loss: 0.5208736658096313
Validation loss: 2.061323935786883

Epoch: 5| Step: 8
Training loss: 0.5337088108062744
Validation loss: 2.08284522096316

Epoch: 5| Step: 9
Training loss: 0.8718105554580688
Validation loss: 2.04578660428524

Epoch: 5| Step: 10
Training loss: 0.38499197363853455
Validation loss: 2.0263056556383767

Epoch: 5| Step: 11
Training loss: 1.392298936843872
Validation loss: 2.0612181772788367

Epoch: 233| Step: 0
Training loss: 0.2911025881767273
Validation loss: 2.044919013977051

Epoch: 5| Step: 1
Training loss: 0.805125892162323
Validation loss: 1.9980786740779877

Epoch: 5| Step: 2
Training loss: 0.6945423483848572
Validation loss: 2.0356723070144653

Epoch: 5| Step: 3
Training loss: 0.5982564091682434
Validation loss: 2.0181772907574973

Epoch: 5| Step: 4
Training loss: 0.5358515977859497
Validation loss: 2.0272399286429086

Epoch: 5| Step: 5
Training loss: 0.7686425447463989
Validation loss: 2.0557836294174194

Epoch: 5| Step: 6
Training loss: 0.2970236837863922
Validation loss: 2.0746241907278695

Epoch: 5| Step: 7
Training loss: 0.40236276388168335
Validation loss: 2.0845093379418054

Epoch: 5| Step: 8
Training loss: 0.6537960767745972
Validation loss: 2.0344320635000863

Epoch: 5| Step: 9
Training loss: 0.7643720507621765
Validation loss: 2.0610127051671348

Epoch: 5| Step: 10
Training loss: 0.7597397565841675
Validation loss: 2.081536422173182

Epoch: 5| Step: 11
Training loss: 0.5165441036224365
Validation loss: 2.070550615588824

Epoch: 234| Step: 0
Training loss: 0.5700041651725769
Validation loss: 2.0532964169979095

Epoch: 5| Step: 1
Training loss: 0.4502640664577484
Validation loss: 2.0256681938966117

Epoch: 5| Step: 2
Training loss: 0.7067510485649109
Validation loss: 2.0483266512552896

Epoch: 5| Step: 3
Training loss: 0.41661596298217773
Validation loss: 2.029181867837906

Epoch: 5| Step: 4
Training loss: 0.7774001955986023
Validation loss: 2.027713567018509

Epoch: 5| Step: 5
Training loss: 0.44900935888290405
Validation loss: 2.0241762449344

Epoch: 5| Step: 6
Training loss: 0.34020107984542847
Validation loss: 2.0825047294298806

Epoch: 5| Step: 7
Training loss: 0.6187256574630737
Validation loss: 2.02240922053655

Epoch: 5| Step: 8
Training loss: 0.47240743041038513
Validation loss: 2.0732156534989676

Epoch: 5| Step: 9
Training loss: 0.7347577810287476
Validation loss: 2.1316609581311545

Epoch: 5| Step: 10
Training loss: 0.6880877017974854
Validation loss: 2.0407327810923257

Epoch: 5| Step: 11
Training loss: 0.7951635122299194
Validation loss: 2.031841143965721

Epoch: 235| Step: 0
Training loss: 0.7758320569992065
Validation loss: 2.0332693060239158

Epoch: 5| Step: 1
Training loss: 0.4197996258735657
Validation loss: 2.072588970263799

Epoch: 5| Step: 2
Training loss: 0.45832666754722595
Validation loss: 2.1343469818433127

Epoch: 5| Step: 3
Training loss: 0.790846586227417
Validation loss: 2.0627236316601434

Epoch: 5| Step: 4
Training loss: 0.5752122402191162
Validation loss: 2.1331321696440377

Epoch: 5| Step: 5
Training loss: 0.6347835659980774
Validation loss: 2.0899887482325235

Epoch: 5| Step: 6
Training loss: 0.5505314469337463
Validation loss: 2.0492576211690903

Epoch: 5| Step: 7
Training loss: 0.8304563760757446
Validation loss: 2.052689323822657

Epoch: 5| Step: 8
Training loss: 0.5517615675926208
Validation loss: 2.0785721192757287

Epoch: 5| Step: 9
Training loss: 0.4965645670890808
Validation loss: 2.057520021994909

Epoch: 5| Step: 10
Training loss: 0.3907603621482849
Validation loss: 2.076074709494909

Epoch: 5| Step: 11
Training loss: 0.5753263235092163
Validation loss: 2.0623662372430167

Epoch: 236| Step: 0
Training loss: 0.6011239290237427
Validation loss: 2.0356720785299935

Epoch: 5| Step: 1
Training loss: 0.8487319946289062
Validation loss: 2.039139156540235

Epoch: 5| Step: 2
Training loss: 0.3014810085296631
Validation loss: 2.077809140086174

Epoch: 5| Step: 3
Training loss: 0.5214816331863403
Validation loss: 2.071713864803314

Epoch: 5| Step: 4
Training loss: 0.3112953305244446
Validation loss: 2.056787610054016

Epoch: 5| Step: 5
Training loss: 0.6523935198783875
Validation loss: 2.0754998475313187

Epoch: 5| Step: 6
Training loss: 0.5582343935966492
Validation loss: 2.069342086712519

Epoch: 5| Step: 7
Training loss: 0.7473476529121399
Validation loss: 2.1015726874272027

Epoch: 5| Step: 8
Training loss: 0.4356609284877777
Validation loss: 2.073948616782824

Epoch: 5| Step: 9
Training loss: 0.5792793035507202
Validation loss: 2.0903135339419046

Epoch: 5| Step: 10
Training loss: 0.6162317991256714
Validation loss: 2.0540451953808465

Epoch: 5| Step: 11
Training loss: 0.5346967577934265
Validation loss: 2.069586301843325

Epoch: 237| Step: 0
Training loss: 0.6230234503746033
Validation loss: 2.1304998844861984

Epoch: 5| Step: 1
Training loss: 0.8671232461929321
Validation loss: 2.0815985202789307

Epoch: 5| Step: 2
Training loss: 0.8973802328109741
Validation loss: 2.0647421032190323

Epoch: 5| Step: 3
Training loss: 0.4090270400047302
Validation loss: 2.127675950527191

Epoch: 5| Step: 4
Training loss: 0.5521476864814758
Validation loss: 2.098228375116984

Epoch: 5| Step: 5
Training loss: 0.6306727528572083
Validation loss: 2.0887361417214074

Epoch: 5| Step: 6
Training loss: 0.5221097469329834
Validation loss: 2.0898886869351068

Epoch: 5| Step: 7
Training loss: 0.5174477696418762
Validation loss: 2.0345183312892914

Epoch: 5| Step: 8
Training loss: 0.43760547041893005
Validation loss: 2.0638065536816916

Epoch: 5| Step: 9
Training loss: 0.314759224653244
Validation loss: 2.023716608683268

Epoch: 5| Step: 10
Training loss: 0.5893905758857727
Validation loss: 2.063247491916021

Epoch: 5| Step: 11
Training loss: 0.7753695249557495
Validation loss: 2.1010735780000687

Epoch: 238| Step: 0
Training loss: 0.6028718948364258
Validation loss: 2.0974296728769937

Epoch: 5| Step: 1
Training loss: 0.9163262248039246
Validation loss: 2.1047257582346597

Epoch: 5| Step: 2
Training loss: 0.277604877948761
Validation loss: 2.0459860066572824

Epoch: 5| Step: 3
Training loss: 0.4717109799385071
Validation loss: 2.0462277283271155

Epoch: 5| Step: 4
Training loss: 0.7940940856933594
Validation loss: 2.0733805000782013

Epoch: 5| Step: 5
Training loss: 0.4779999256134033
Validation loss: 2.0165026982625327

Epoch: 5| Step: 6
Training loss: 0.778290867805481
Validation loss: 2.0788673162460327

Epoch: 5| Step: 7
Training loss: 0.3679891526699066
Validation loss: 2.082505777478218

Epoch: 5| Step: 8
Training loss: 0.44301706552505493
Validation loss: 2.0725279996792474

Epoch: 5| Step: 9
Training loss: 0.49530354142189026
Validation loss: 2.050104116400083

Epoch: 5| Step: 10
Training loss: 0.5954708456993103
Validation loss: 2.0560406843821206

Epoch: 5| Step: 11
Training loss: 0.5015004873275757
Validation loss: 2.0464578370253244

Epoch: 239| Step: 0
Training loss: 0.5659374594688416
Validation loss: 2.043744603792826

Epoch: 5| Step: 1
Training loss: 0.618404746055603
Validation loss: 2.0192344337701797

Epoch: 5| Step: 2
Training loss: 0.6106331944465637
Validation loss: 2.0301905274391174

Epoch: 5| Step: 3
Training loss: 0.4367142617702484
Validation loss: 2.0358481456836066

Epoch: 5| Step: 4
Training loss: 0.6033129692077637
Validation loss: 1.980490932861964

Epoch: 5| Step: 5
Training loss: 0.5821119546890259
Validation loss: 2.0530684490998587

Epoch: 5| Step: 6
Training loss: 0.5217186212539673
Validation loss: 2.0524476915597916

Epoch: 5| Step: 7
Training loss: 0.5094815492630005
Validation loss: 2.0767107903957367

Epoch: 5| Step: 8
Training loss: 0.7465159893035889
Validation loss: 2.0682458182175956

Epoch: 5| Step: 9
Training loss: 0.6674302220344543
Validation loss: 2.0497311651706696

Epoch: 5| Step: 10
Training loss: 0.35389381647109985
Validation loss: 2.06624865035216

Epoch: 5| Step: 11
Training loss: 0.7007415294647217
Validation loss: 2.0353837261597314

Epoch: 240| Step: 0
Training loss: 0.7110446095466614
Validation loss: 2.006457050641378

Epoch: 5| Step: 1
Training loss: 0.9641337394714355
Validation loss: 2.033657446503639

Epoch: 5| Step: 2
Training loss: 0.6614711880683899
Validation loss: 2.01015567779541

Epoch: 5| Step: 3
Training loss: 0.4188430905342102
Validation loss: 2.0109231770038605

Epoch: 5| Step: 4
Training loss: 0.3813152611255646
Validation loss: 1.9667154600222905

Epoch: 5| Step: 5
Training loss: 0.5010389089584351
Validation loss: 2.080410117904345

Epoch: 5| Step: 6
Training loss: 0.7332037687301636
Validation loss: 2.044061948855718

Epoch: 5| Step: 7
Training loss: 0.5194090008735657
Validation loss: 2.0585994571447372

Epoch: 5| Step: 8
Training loss: 0.5971946120262146
Validation loss: 2.0442350059747696

Epoch: 5| Step: 9
Training loss: 0.5510183572769165
Validation loss: 1.9992051819960277

Epoch: 5| Step: 10
Training loss: 0.3284388780593872
Validation loss: 2.037577673792839

Epoch: 5| Step: 11
Training loss: 0.25516295433044434
Validation loss: 2.0240360448757806

Epoch: 241| Step: 0
Training loss: 0.4046669900417328
Validation loss: 2.0996216883262

Epoch: 5| Step: 1
Training loss: 0.6200218200683594
Validation loss: 2.0491783817609153

Epoch: 5| Step: 2
Training loss: 0.9814416170120239
Validation loss: 2.048828919728597

Epoch: 5| Step: 3
Training loss: 0.8495122790336609
Validation loss: 2.07718326151371

Epoch: 5| Step: 4
Training loss: 0.30223190784454346
Validation loss: 2.0375974476337433

Epoch: 5| Step: 5
Training loss: 0.45652905106544495
Validation loss: 2.0187405993541083

Epoch: 5| Step: 6
Training loss: 0.40439480543136597
Validation loss: 2.086872488260269

Epoch: 5| Step: 7
Training loss: 0.7168213725090027
Validation loss: 2.044550210237503

Epoch: 5| Step: 8
Training loss: 0.6788535118103027
Validation loss: 2.1106916964054108

Epoch: 5| Step: 9
Training loss: 0.6250869035720825
Validation loss: 2.0926119635502496

Epoch: 5| Step: 10
Training loss: 0.45744675397872925
Validation loss: 2.0660033772389093

Epoch: 5| Step: 11
Training loss: 0.6059752702713013
Validation loss: 2.0313124110301337

Epoch: 242| Step: 0
Training loss: 0.3054334819316864
Validation loss: 2.0532657504081726

Epoch: 5| Step: 1
Training loss: 0.6298654079437256
Validation loss: 2.077458530664444

Epoch: 5| Step: 2
Training loss: 0.6591454744338989
Validation loss: 2.1017972578605018

Epoch: 5| Step: 3
Training loss: 0.7224735021591187
Validation loss: 2.0854753454526267

Epoch: 5| Step: 4
Training loss: 0.7751314640045166
Validation loss: 2.0423532724380493

Epoch: 5| Step: 5
Training loss: 0.4932372570037842
Validation loss: 2.082266996304194

Epoch: 5| Step: 6
Training loss: 0.9227988123893738
Validation loss: 2.0771736601988473

Epoch: 5| Step: 7
Training loss: 0.4645542502403259
Validation loss: 2.172925055027008

Epoch: 5| Step: 8
Training loss: 0.7935954332351685
Validation loss: 2.0763760805130005

Epoch: 5| Step: 9
Training loss: 0.7306052446365356
Validation loss: 2.054938996831576

Epoch: 5| Step: 10
Training loss: 0.671833872795105
Validation loss: 2.0606585989395776

Epoch: 5| Step: 11
Training loss: 0.5629366636276245
Validation loss: 2.0366155256827674

Epoch: 243| Step: 0
Training loss: 0.522568941116333
Validation loss: 2.0289443731307983

Epoch: 5| Step: 1
Training loss: 0.5358510613441467
Validation loss: 2.050517643491427

Epoch: 5| Step: 2
Training loss: 0.529671311378479
Validation loss: 2.082398826877276

Epoch: 5| Step: 3
Training loss: 0.9793848991394043
Validation loss: 2.036285236477852

Epoch: 5| Step: 4
Training loss: 0.42344099283218384
Validation loss: 2.0168652633825936

Epoch: 5| Step: 5
Training loss: 0.7147039771080017
Validation loss: 2.040893922249476

Epoch: 5| Step: 6
Training loss: 0.5866829752922058
Validation loss: 2.0112338413794837

Epoch: 5| Step: 7
Training loss: 0.49704456329345703
Validation loss: 2.069737200935682

Epoch: 5| Step: 8
Training loss: 0.29442691802978516
Validation loss: 2.0841353436311087

Epoch: 5| Step: 9
Training loss: 0.6093382239341736
Validation loss: 2.0769254018863044

Epoch: 5| Step: 10
Training loss: 0.6149206161499023
Validation loss: 2.059977114200592

Epoch: 5| Step: 11
Training loss: 0.2561853229999542
Validation loss: 2.0263676891724267

Epoch: 244| Step: 0
Training loss: 0.5137332677841187
Validation loss: 2.0441558907429376

Epoch: 5| Step: 1
Training loss: 0.5879806876182556
Validation loss: 2.0127360026041665

Epoch: 5| Step: 2
Training loss: 0.5920788049697876
Validation loss: 2.111876353621483

Epoch: 5| Step: 3
Training loss: 0.42102813720703125
Validation loss: 2.080694610873858

Epoch: 5| Step: 4
Training loss: 0.6949297189712524
Validation loss: 2.01922008395195

Epoch: 5| Step: 5
Training loss: 0.32515949010849
Validation loss: 2.083356499671936

Epoch: 5| Step: 6
Training loss: 1.0211385488510132
Validation loss: 2.0848094125588736

Epoch: 5| Step: 7
Training loss: 0.508419930934906
Validation loss: 2.0454373906056085

Epoch: 5| Step: 8
Training loss: 0.5401331186294556
Validation loss: 2.1272811194260917

Epoch: 5| Step: 9
Training loss: 0.722179651260376
Validation loss: 2.1551349063714347

Epoch: 5| Step: 10
Training loss: 0.34441429376602173
Validation loss: 2.0859921077887216

Epoch: 5| Step: 11
Training loss: 1.019145131111145
Validation loss: 2.1233879228432975

Epoch: 245| Step: 0
Training loss: 0.5352197289466858
Validation loss: 2.1583381791909537

Epoch: 5| Step: 1
Training loss: 0.5249158143997192
Validation loss: 2.1009756674369178

Epoch: 5| Step: 2
Training loss: 0.34102654457092285
Validation loss: 2.0982072750727334

Epoch: 5| Step: 3
Training loss: 0.45588263869285583
Validation loss: 2.0968400786320367

Epoch: 5| Step: 4
Training loss: 0.8907437324523926
Validation loss: 2.0877972841262817

Epoch: 5| Step: 5
Training loss: 0.6124410033226013
Validation loss: 2.080102269848188

Epoch: 5| Step: 6
Training loss: 0.4589489996433258
Validation loss: 2.070108180244764

Epoch: 5| Step: 7
Training loss: 0.4019691050052643
Validation loss: 2.019576375683149

Epoch: 5| Step: 8
Training loss: 0.5137621164321899
Validation loss: 2.0636186599731445

Epoch: 5| Step: 9
Training loss: 0.6482256650924683
Validation loss: 2.048390512665113

Epoch: 5| Step: 10
Training loss: 0.552000880241394
Validation loss: 2.0742425620555878

Epoch: 5| Step: 11
Training loss: 0.950795590877533
Validation loss: 2.0687268127997718

Epoch: 246| Step: 0
Training loss: 0.6172674894332886
Validation loss: 1.996477022767067

Epoch: 5| Step: 1
Training loss: 0.6251963376998901
Validation loss: 2.0422953367233276

Epoch: 5| Step: 2
Training loss: 0.6097162961959839
Validation loss: 2.01632392903169

Epoch: 5| Step: 3
Training loss: 0.37131065130233765
Validation loss: 2.073421224951744

Epoch: 5| Step: 4
Training loss: 0.5513818860054016
Validation loss: 2.067485734820366

Epoch: 5| Step: 5
Training loss: 0.5152280926704407
Validation loss: 2.0169807821512222

Epoch: 5| Step: 6
Training loss: 0.8132030367851257
Validation loss: 2.081722135345141

Epoch: 5| Step: 7
Training loss: 0.6310449838638306
Validation loss: 2.066764692465464

Epoch: 5| Step: 8
Training loss: 0.5871535539627075
Validation loss: 2.0416370878616967

Epoch: 5| Step: 9
Training loss: 0.5507331490516663
Validation loss: 2.0339373548825583

Epoch: 5| Step: 10
Training loss: 0.5829758048057556
Validation loss: 2.0186350842316947

Epoch: 5| Step: 11
Training loss: 0.40340113639831543
Validation loss: 2.0526074866453805

Epoch: 247| Step: 0
Training loss: 1.043792486190796
Validation loss: 2.1730392277240753

Epoch: 5| Step: 1
Training loss: 0.8822695016860962
Validation loss: 2.1855477144320807

Epoch: 5| Step: 2
Training loss: 0.8757092356681824
Validation loss: 2.2036221673091254

Epoch: 5| Step: 3
Training loss: 0.9574141502380371
Validation loss: 2.129787355661392

Epoch: 5| Step: 4
Training loss: 0.5438030958175659
Validation loss: 2.0882175117731094

Epoch: 5| Step: 5
Training loss: 0.46162208914756775
Validation loss: 2.0569091786940894

Epoch: 5| Step: 6
Training loss: 0.6307767629623413
Validation loss: 2.077233776450157

Epoch: 5| Step: 7
Training loss: 0.9098262786865234
Validation loss: 2.066177641352018

Epoch: 5| Step: 8
Training loss: 0.6554642915725708
Validation loss: 2.0600179930528006

Epoch: 5| Step: 9
Training loss: 0.4525555968284607
Validation loss: 2.055750777324041

Epoch: 5| Step: 10
Training loss: 0.7831665873527527
Validation loss: 2.0541152358055115

Epoch: 5| Step: 11
Training loss: 0.4212177097797394
Validation loss: 2.0671547750631967

Epoch: 248| Step: 0
Training loss: 0.3805460035800934
Validation loss: 2.075850263237953

Epoch: 5| Step: 1
Training loss: 0.4793781340122223
Validation loss: 2.042394573489825

Epoch: 5| Step: 2
Training loss: 0.7187870740890503
Validation loss: 2.1016480873028436

Epoch: 5| Step: 3
Training loss: 0.6056861877441406
Validation loss: 2.066557228565216

Epoch: 5| Step: 4
Training loss: 0.5383018255233765
Validation loss: 2.032655119895935

Epoch: 5| Step: 5
Training loss: 0.44725775718688965
Validation loss: 2.061412071188291

Epoch: 5| Step: 6
Training loss: 0.5621411204338074
Validation loss: 2.0123701790968576

Epoch: 5| Step: 7
Training loss: 0.41794222593307495
Validation loss: 2.0756869266430535

Epoch: 5| Step: 8
Training loss: 0.6475884914398193
Validation loss: 2.061437706152598

Epoch: 5| Step: 9
Training loss: 0.6163585782051086
Validation loss: 2.1447106351455054

Epoch: 5| Step: 10
Training loss: 0.6563526391983032
Validation loss: 2.104629228512446

Epoch: 5| Step: 11
Training loss: 0.2917520999908447
Validation loss: 2.116159066557884

Epoch: 249| Step: 0
Training loss: 0.3759015202522278
Validation loss: 2.1424995561440787

Epoch: 5| Step: 1
Training loss: 0.4334520697593689
Validation loss: 2.0965508421262107

Epoch: 5| Step: 2
Training loss: 0.2565484046936035
Validation loss: 2.0273113499085107

Epoch: 5| Step: 3
Training loss: 0.49708184599876404
Validation loss: 2.024208744366964

Epoch: 5| Step: 4
Training loss: 0.43105751276016235
Validation loss: 2.1225824803113937

Epoch: 5| Step: 5
Training loss: 0.8475359082221985
Validation loss: 2.124691347281138

Epoch: 5| Step: 6
Training loss: 0.4893549382686615
Validation loss: 2.147142087419828

Epoch: 5| Step: 7
Training loss: 1.1574045419692993
Validation loss: 2.0984442780415216

Epoch: 5| Step: 8
Training loss: 0.7966761589050293
Validation loss: 2.138340483109156

Epoch: 5| Step: 9
Training loss: 0.5372876524925232
Validation loss: 2.087740788857142

Epoch: 5| Step: 10
Training loss: 0.4603749215602875
Validation loss: 2.081365322073301

Epoch: 5| Step: 11
Training loss: 0.3360775113105774
Validation loss: 2.07170732319355

Epoch: 250| Step: 0
Training loss: 0.5130205750465393
Validation loss: 2.1226904640595117

Epoch: 5| Step: 1
Training loss: 0.6255635023117065
Validation loss: 2.092437371611595

Epoch: 5| Step: 2
Training loss: 0.3495710492134094
Validation loss: 2.1402107377847037

Epoch: 5| Step: 3
Training loss: 0.530302882194519
Validation loss: 2.0607405652602515

Epoch: 5| Step: 4
Training loss: 0.5159185528755188
Validation loss: 2.118058835466703

Epoch: 5| Step: 5
Training loss: 0.630853533744812
Validation loss: 2.0360297660032907

Epoch: 5| Step: 6
Training loss: 0.37052059173583984
Validation loss: 2.1213379502296448

Epoch: 5| Step: 7
Training loss: 0.32922273874282837
Validation loss: 2.0731299618879953

Epoch: 5| Step: 8
Training loss: 0.644311249256134
Validation loss: 2.0826403349637985

Epoch: 5| Step: 9
Training loss: 0.6408097147941589
Validation loss: 2.0820720742146173

Epoch: 5| Step: 10
Training loss: 0.6320767402648926
Validation loss: 2.075431694587072

Epoch: 5| Step: 11
Training loss: 0.8002258539199829
Validation loss: 2.1319270630677543

Testing loss: 1.9453748558922637
