Epoch: 1| Step: 0
Training loss: 5.516120520964588
Validation loss: 6.147963250695887

Epoch: 5| Step: 1
Training loss: 6.007778212272117
Validation loss: 6.118970628137069

Epoch: 5| Step: 2
Training loss: 6.4179883644329
Validation loss: 6.085653733447514

Epoch: 5| Step: 3
Training loss: 6.62007188141397
Validation loss: 6.053864762387264

Epoch: 5| Step: 4
Training loss: 5.795037402475824
Validation loss: 6.025797360632503

Epoch: 5| Step: 5
Training loss: 6.522146496973103
Validation loss: 5.99815077895086

Epoch: 5| Step: 6
Training loss: 5.660981449185077
Validation loss: 5.966376486795557

Epoch: 5| Step: 7
Training loss: 5.407846204139588
Validation loss: 5.939672949186369

Epoch: 5| Step: 8
Training loss: 6.175365841796687
Validation loss: 5.912047338060467

Epoch: 5| Step: 9
Training loss: 6.3783988120083315
Validation loss: 5.881902724829569

Epoch: 5| Step: 10
Training loss: 6.666808444740796
Validation loss: 5.852617549810215

Epoch: 5| Step: 11
Training loss: 5.3062621351267305
Validation loss: 5.828905211886876

Epoch: 2| Step: 0
Training loss: 5.42690797645736
Validation loss: 5.796942313763978

Epoch: 5| Step: 1
Training loss: 6.020294834153616
Validation loss: 5.765927996853736

Epoch: 5| Step: 2
Training loss: 5.320540503099021
Validation loss: 5.736090671091349

Epoch: 5| Step: 3
Training loss: 5.2025747380531975
Validation loss: 5.702644376664968

Epoch: 5| Step: 4
Training loss: 5.824986326013323
Validation loss: 5.670946295643408

Epoch: 5| Step: 5
Training loss: 4.982740558764037
Validation loss: 5.637392831645076

Epoch: 5| Step: 6
Training loss: 6.024642566509587
Validation loss: 5.599458583987573

Epoch: 5| Step: 7
Training loss: 6.001497399717704
Validation loss: 5.565805845840522

Epoch: 5| Step: 8
Training loss: 6.087746817659056
Validation loss: 5.527196350648457

Epoch: 5| Step: 9
Training loss: 5.486388616612046
Validation loss: 5.488525493793716

Epoch: 5| Step: 10
Training loss: 6.304594925551758
Validation loss: 5.448287683791449

Epoch: 5| Step: 11
Training loss: 6.544687274313012
Validation loss: 5.40250221253573

Epoch: 3| Step: 0
Training loss: 5.070973404658316
Validation loss: 5.3611030276582925

Epoch: 5| Step: 1
Training loss: 5.587210642172869
Validation loss: 5.309028141755493

Epoch: 5| Step: 2
Training loss: 4.959179760575843
Validation loss: 5.262704773374874

Epoch: 5| Step: 3
Training loss: 5.927427723225523
Validation loss: 5.216003928981658

Epoch: 5| Step: 4
Training loss: 5.0540652238435975
Validation loss: 5.159139128171813

Epoch: 5| Step: 5
Training loss: 4.741629603843896
Validation loss: 5.102854449732645

Epoch: 5| Step: 6
Training loss: 4.904960705894308
Validation loss: 5.0509519378544505

Epoch: 5| Step: 7
Training loss: 5.598497475279674
Validation loss: 4.989264773378104

Epoch: 5| Step: 8
Training loss: 4.8388063860017105
Validation loss: 4.929263717886889

Epoch: 5| Step: 9
Training loss: 5.232455411193387
Validation loss: 4.867849118252401

Epoch: 5| Step: 10
Training loss: 5.185563059061374
Validation loss: 4.795270371834665

Epoch: 5| Step: 11
Training loss: 4.403507542558337
Validation loss: 4.72657104995837

Epoch: 4| Step: 0
Training loss: 5.409289966181553
Validation loss: 4.656623074394189

Epoch: 5| Step: 1
Training loss: 4.263600969620564
Validation loss: 4.568150505084835

Epoch: 5| Step: 2
Training loss: 4.53964171924249
Validation loss: 4.493109805752274

Epoch: 5| Step: 3
Training loss: 4.160489551642471
Validation loss: 4.419602716767312

Epoch: 5| Step: 4
Training loss: 4.874411131676855
Validation loss: 4.333636794407462

Epoch: 5| Step: 5
Training loss: 4.078171302269474
Validation loss: 4.235103047223276

Epoch: 5| Step: 6
Training loss: 4.403915327846773
Validation loss: 4.1449147681265

Epoch: 5| Step: 7
Training loss: 4.165090695203117
Validation loss: 4.056221526623493

Epoch: 5| Step: 8
Training loss: 3.6812668183076926
Validation loss: 3.9487845423935446

Epoch: 5| Step: 9
Training loss: 3.9485263538212947
Validation loss: 3.8452253224063573

Epoch: 5| Step: 10
Training loss: 3.9367047672435986
Validation loss: 3.753506748034007

Epoch: 5| Step: 11
Training loss: 4.1673651046294475
Validation loss: 3.6442959659428165

Epoch: 5| Step: 0
Training loss: 3.7125349922971447
Validation loss: 3.545669429201905

Epoch: 5| Step: 1
Training loss: 3.252457643155406
Validation loss: 3.4396736844028153

Epoch: 5| Step: 2
Training loss: 3.338117186668064
Validation loss: 3.3446675732090982

Epoch: 5| Step: 3
Training loss: 2.9509889658324453
Validation loss: 3.2353212197973944

Epoch: 5| Step: 4
Training loss: 3.345544351439133
Validation loss: 3.139234007065933

Epoch: 5| Step: 5
Training loss: 3.6048980294248643
Validation loss: 3.059999736347478

Epoch: 5| Step: 6
Training loss: 2.7466456155834447
Validation loss: 2.9530747962734467

Epoch: 5| Step: 7
Training loss: 3.1475635006462674
Validation loss: 2.8693942656216818

Epoch: 5| Step: 8
Training loss: 3.429278859882983
Validation loss: 2.8111899503754327

Epoch: 5| Step: 9
Training loss: 2.390059061318225
Validation loss: 2.7268029974938917

Epoch: 5| Step: 10
Training loss: 2.7380626988501326
Validation loss: 2.664983793314358

Epoch: 5| Step: 11
Training loss: 0.8940197677560322
Validation loss: 2.6266348531372983

Epoch: 6| Step: 0
Training loss: 2.7049690968269524
Validation loss: 2.6021476942786337

Epoch: 5| Step: 1
Training loss: 2.5342286092339545
Validation loss: 2.6045216140448293

Epoch: 5| Step: 2
Training loss: 3.007869254233223
Validation loss: 2.5821567452963046

Epoch: 5| Step: 3
Training loss: 2.46089739085618
Validation loss: 2.605400298066309

Epoch: 5| Step: 4
Training loss: 3.0362359953015905
Validation loss: 2.6146961405660596

Epoch: 5| Step: 5
Training loss: 2.8007758019472813
Validation loss: 2.64690242904749

Epoch: 5| Step: 6
Training loss: 2.3560833737982048
Validation loss: 2.640354025967923

Epoch: 5| Step: 7
Training loss: 3.6606575247055813
Validation loss: 2.6779380848844525

Epoch: 5| Step: 8
Training loss: 2.2594347343093397
Validation loss: 2.6858685184102944

Epoch: 5| Step: 9
Training loss: 2.316415204550304
Validation loss: 2.65502261433546

Epoch: 5| Step: 10
Training loss: 2.3111996474281957
Validation loss: 2.658695501412518

Epoch: 5| Step: 11
Training loss: 1.9786691408390367
Validation loss: 2.6723868194013702

Epoch: 7| Step: 0
Training loss: 2.6194918835756864
Validation loss: 2.6701464610880508

Epoch: 5| Step: 1
Training loss: 2.5184848238783313
Validation loss: 2.6820468062451464

Epoch: 5| Step: 2
Training loss: 2.8552256009677897
Validation loss: 2.7000721724601044

Epoch: 5| Step: 3
Training loss: 2.725576140366663
Validation loss: 2.6899476825933797

Epoch: 5| Step: 4
Training loss: 2.8439034221470165
Validation loss: 2.681872538193043

Epoch: 5| Step: 5
Training loss: 2.94208104472298
Validation loss: 2.6988937800608563

Epoch: 5| Step: 6
Training loss: 3.0935400689309094
Validation loss: 2.6880367984949287

Epoch: 5| Step: 7
Training loss: 2.849222304663861
Validation loss: 2.6888413150071213

Epoch: 5| Step: 8
Training loss: 2.9252652170300424
Validation loss: 2.6503879637998837

Epoch: 5| Step: 9
Training loss: 2.2418560354612715
Validation loss: 2.617883253850176

Epoch: 5| Step: 10
Training loss: 2.422462244517103
Validation loss: 2.6219826833430546

Epoch: 5| Step: 11
Training loss: 3.141617803083993
Validation loss: 2.5926599797426793

Epoch: 8| Step: 0
Training loss: 2.593578378905414
Validation loss: 2.580345338262338

Epoch: 5| Step: 1
Training loss: 3.235655158088233
Validation loss: 2.574868575078562

Epoch: 5| Step: 2
Training loss: 2.4060494475575096
Validation loss: 2.572172452397306

Epoch: 5| Step: 3
Training loss: 2.5606014382654267
Validation loss: 2.5772261622904655

Epoch: 5| Step: 4
Training loss: 2.3063251431429945
Validation loss: 2.584721262905055

Epoch: 5| Step: 5
Training loss: 3.4353156345394424
Validation loss: 2.584015092309136

Epoch: 5| Step: 6
Training loss: 2.564305297588554
Validation loss: 2.5921713072991706

Epoch: 5| Step: 7
Training loss: 2.237571830235867
Validation loss: 2.6185739934522605

Epoch: 5| Step: 8
Training loss: 2.361487346168618
Validation loss: 2.61344574627717

Epoch: 5| Step: 9
Training loss: 2.4153881198665124
Validation loss: 2.6188940946316124

Epoch: 5| Step: 10
Training loss: 2.7003715471421237
Validation loss: 2.6201957229254593

Epoch: 5| Step: 11
Training loss: 4.107501280883664
Validation loss: 2.6113208018361673

Epoch: 9| Step: 0
Training loss: 2.169301875801737
Validation loss: 2.617438206597569

Epoch: 5| Step: 1
Training loss: 2.8358478794701956
Validation loss: 2.608811399465075

Epoch: 5| Step: 2
Training loss: 2.4859794378189837
Validation loss: 2.596240552267615

Epoch: 5| Step: 3
Training loss: 2.6361651256169525
Validation loss: 2.6004108518517013

Epoch: 5| Step: 4
Training loss: 3.258312744960147
Validation loss: 2.592060710986296

Epoch: 5| Step: 5
Training loss: 2.8803513521874966
Validation loss: 2.5811743879904956

Epoch: 5| Step: 6
Training loss: 2.960142003596706
Validation loss: 2.56889188441149

Epoch: 5| Step: 7
Training loss: 1.9987627016848408
Validation loss: 2.571617027313745

Epoch: 5| Step: 8
Training loss: 2.6174329044811158
Validation loss: 2.5941284853385

Epoch: 5| Step: 9
Training loss: 2.7299606003206307
Validation loss: 2.5839416392726506

Epoch: 5| Step: 10
Training loss: 2.827145991876101
Validation loss: 2.5717129819691626

Epoch: 5| Step: 11
Training loss: 1.1456852325904805
Validation loss: 2.5569194139483384

Epoch: 10| Step: 0
Training loss: 2.419847784378296
Validation loss: 2.578525184629423

Epoch: 5| Step: 1
Training loss: 3.506335654886943
Validation loss: 2.5582391760136214

Epoch: 5| Step: 2
Training loss: 2.4110683403186672
Validation loss: 2.575891741256302

Epoch: 5| Step: 3
Training loss: 2.5822060391682613
Validation loss: 2.563254280262369

Epoch: 5| Step: 4
Training loss: 2.5707404525358446
Validation loss: 2.5833443088964887

Epoch: 5| Step: 5
Training loss: 2.9667803203228877
Validation loss: 2.577090878631064

Epoch: 5| Step: 6
Training loss: 2.418886962482552
Validation loss: 2.5933707009698446

Epoch: 5| Step: 7
Training loss: 2.6868594981046052
Validation loss: 2.57335792778258

Epoch: 5| Step: 8
Training loss: 2.35038418571626
Validation loss: 2.567958813121863

Epoch: 5| Step: 9
Training loss: 2.9114797155769967
Validation loss: 2.554956392841758

Epoch: 5| Step: 10
Training loss: 2.0826096867391652
Validation loss: 2.552747329955342

Epoch: 5| Step: 11
Training loss: 1.9167635796412812
Validation loss: 2.559201288286163

Epoch: 11| Step: 0
Training loss: 2.1215788284821913
Validation loss: 2.574578483425926

Epoch: 5| Step: 1
Training loss: 2.4805187310417205
Validation loss: 2.5687380280722323

Epoch: 5| Step: 2
Training loss: 2.726770081583672
Validation loss: 2.563710833789242

Epoch: 5| Step: 3
Training loss: 2.53612660791742
Validation loss: 2.570459800294821

Epoch: 5| Step: 4
Training loss: 2.264304466823166
Validation loss: 2.5582939574124213

Epoch: 5| Step: 5
Training loss: 2.8948277618877594
Validation loss: 2.5842914009641698

Epoch: 5| Step: 6
Training loss: 2.670878531261514
Validation loss: 2.571472679118153

Epoch: 5| Step: 7
Training loss: 3.415764076912511
Validation loss: 2.561420077430847

Epoch: 5| Step: 8
Training loss: 2.482468935492655
Validation loss: 2.579570238023374

Epoch: 5| Step: 9
Training loss: 2.1051573231094878
Validation loss: 2.578790468969952

Epoch: 5| Step: 10
Training loss: 2.9376423578059137
Validation loss: 2.5824596878689374

Epoch: 5| Step: 11
Training loss: 3.0611575551403063
Validation loss: 2.569141859561097

Epoch: 12| Step: 0
Training loss: 2.4841096364457362
Validation loss: 2.5459422137134586

Epoch: 5| Step: 1
Training loss: 3.006294957576226
Validation loss: 2.553135457789817

Epoch: 5| Step: 2
Training loss: 3.045082229982224
Validation loss: 2.5350987643879104

Epoch: 5| Step: 3
Training loss: 2.3484523140750326
Validation loss: 2.547274170157136

Epoch: 5| Step: 4
Training loss: 2.282214862106293
Validation loss: 2.5466566206719774

Epoch: 5| Step: 5
Training loss: 2.1987523182243542
Validation loss: 2.5647231630703033

Epoch: 5| Step: 6
Training loss: 2.476468923828538
Validation loss: 2.5474832896619506

Epoch: 5| Step: 7
Training loss: 3.063903798258906
Validation loss: 2.567273458418174

Epoch: 5| Step: 8
Training loss: 2.6658326473952667
Validation loss: 2.5589862900926077

Epoch: 5| Step: 9
Training loss: 2.7016254300785336
Validation loss: 2.530654589950381

Epoch: 5| Step: 10
Training loss: 2.540096506703377
Validation loss: 2.552557626105508

Epoch: 5| Step: 11
Training loss: 1.3833183182433852
Validation loss: 2.5468380970221864

Epoch: 13| Step: 0
Training loss: 2.95728666746965
Validation loss: 2.5594139939203346

Epoch: 5| Step: 1
Training loss: 2.464057712393048
Validation loss: 2.5445131689500338

Epoch: 5| Step: 2
Training loss: 2.265959826753864
Validation loss: 2.5529911891776753

Epoch: 5| Step: 3
Training loss: 2.4843528314717003
Validation loss: 2.56060764173714

Epoch: 5| Step: 4
Training loss: 2.5358721129425006
Validation loss: 2.5489101235949505

Epoch: 5| Step: 5
Training loss: 2.3960022134277104
Validation loss: 2.546373528567977

Epoch: 5| Step: 6
Training loss: 2.973484961431104
Validation loss: 2.530284454113637

Epoch: 5| Step: 7
Training loss: 2.52293121644499
Validation loss: 2.5457808283642755

Epoch: 5| Step: 8
Training loss: 3.0957966209757424
Validation loss: 2.5470594717670214

Epoch: 5| Step: 9
Training loss: 2.5948457356724033
Validation loss: 2.5337004632911087

Epoch: 5| Step: 10
Training loss: 2.647924412901858
Validation loss: 2.541500908235754

Epoch: 5| Step: 11
Training loss: 0.9998887715469648
Validation loss: 2.5496033289869677

Epoch: 14| Step: 0
Training loss: 2.5348690205280646
Validation loss: 2.5552517212456154

Epoch: 5| Step: 1
Training loss: 2.4437777544479706
Validation loss: 2.5599198028177006

Epoch: 5| Step: 2
Training loss: 2.479017226472856
Validation loss: 2.550156077115044

Epoch: 5| Step: 3
Training loss: 2.5394658633929086
Validation loss: 2.5343505429374664

Epoch: 5| Step: 4
Training loss: 2.474427563522594
Validation loss: 2.5377267033135187

Epoch: 5| Step: 5
Training loss: 3.186456846195475
Validation loss: 2.540917166176313

Epoch: 5| Step: 6
Training loss: 2.690257675847664
Validation loss: 2.5451292205761065

Epoch: 5| Step: 7
Training loss: 2.2170007821969118
Validation loss: 2.546027473522726

Epoch: 5| Step: 8
Training loss: 2.0740140249942387
Validation loss: 2.5240275634977496

Epoch: 5| Step: 9
Training loss: 2.8234141194188793
Validation loss: 2.5479758424715366

Epoch: 5| Step: 10
Training loss: 3.023371417286946
Validation loss: 2.5462533078915794

Epoch: 5| Step: 11
Training loss: 2.9150022571483007
Validation loss: 2.533227499337482

Epoch: 15| Step: 0
Training loss: 2.272772727858542
Validation loss: 2.5517489402354947

Epoch: 5| Step: 1
Training loss: 2.410076220403221
Validation loss: 2.5470450818427093

Epoch: 5| Step: 2
Training loss: 2.914800719161067
Validation loss: 2.559371690200696

Epoch: 5| Step: 3
Training loss: 2.4799709030720964
Validation loss: 2.5615289212729415

Epoch: 5| Step: 4
Training loss: 2.5086150504377827
Validation loss: 2.5476079794872915

Epoch: 5| Step: 5
Training loss: 1.8216970523674478
Validation loss: 2.535840499066339

Epoch: 5| Step: 6
Training loss: 2.80064725887866
Validation loss: 2.5517662993235337

Epoch: 5| Step: 7
Training loss: 2.7116207613944634
Validation loss: 2.5684617016113847

Epoch: 5| Step: 8
Training loss: 2.146212226477508
Validation loss: 2.548892904849336

Epoch: 5| Step: 9
Training loss: 2.5224673647324236
Validation loss: 2.553983418288854

Epoch: 5| Step: 10
Training loss: 3.6511714257415204
Validation loss: 2.5588688127432557

Epoch: 5| Step: 11
Training loss: 3.0903819853587176
Validation loss: 2.5627922147355746

Epoch: 16| Step: 0
Training loss: 3.0538841030111183
Validation loss: 2.5578740745781

Epoch: 5| Step: 1
Training loss: 2.8529001103459293
Validation loss: 2.5285310427810863

Epoch: 5| Step: 2
Training loss: 2.6199202660811185
Validation loss: 2.532845528018769

Epoch: 5| Step: 3
Training loss: 2.2717648150184604
Validation loss: 2.52807685561012

Epoch: 5| Step: 4
Training loss: 2.5303049089247933
Validation loss: 2.527750060228778

Epoch: 5| Step: 5
Training loss: 2.648138608917784
Validation loss: 2.5342096090540975

Epoch: 5| Step: 6
Training loss: 2.5217196164956066
Validation loss: 2.538805755937089

Epoch: 5| Step: 7
Training loss: 2.855958993056366
Validation loss: 2.530331299705561

Epoch: 5| Step: 8
Training loss: 2.6361590660332777
Validation loss: 2.520099660546434

Epoch: 5| Step: 9
Training loss: 2.3824566684877353
Validation loss: 2.5340965967883

Epoch: 5| Step: 10
Training loss: 2.3233501446123475
Validation loss: 2.5442272066705436

Epoch: 5| Step: 11
Training loss: 1.8641707178696239
Validation loss: 2.5442584313071173

Epoch: 17| Step: 0
Training loss: 3.007121058664317
Validation loss: 2.5303872682934534

Epoch: 5| Step: 1
Training loss: 2.824484320641782
Validation loss: 2.519799762779582

Epoch: 5| Step: 2
Training loss: 2.1859398864340416
Validation loss: 2.526918091420322

Epoch: 5| Step: 3
Training loss: 2.6487469787724445
Validation loss: 2.533502496830054

Epoch: 5| Step: 4
Training loss: 2.39493755235271
Validation loss: 2.5145371574791215

Epoch: 5| Step: 5
Training loss: 2.7867993487783727
Validation loss: 2.5161350949363

Epoch: 5| Step: 6
Training loss: 2.7513687888762464
Validation loss: 2.5321163492360843

Epoch: 5| Step: 7
Training loss: 2.2144168933563044
Validation loss: 2.52688523328761

Epoch: 5| Step: 8
Training loss: 2.672797417501682
Validation loss: 2.518304570570496

Epoch: 5| Step: 9
Training loss: 2.442775006933113
Validation loss: 2.539920294210676

Epoch: 5| Step: 10
Training loss: 2.519167378491011
Validation loss: 2.505891632720824

Epoch: 5| Step: 11
Training loss: 2.039719632834991
Validation loss: 2.522160788772625

Epoch: 18| Step: 0
Training loss: 2.820208095826595
Validation loss: 2.5108776117829286

Epoch: 5| Step: 1
Training loss: 1.84211930398681
Validation loss: 2.5109000050677484

Epoch: 5| Step: 2
Training loss: 2.650685484415773
Validation loss: 2.5135048961729574

Epoch: 5| Step: 3
Training loss: 3.1060185551528203
Validation loss: 2.536551829552923

Epoch: 5| Step: 4
Training loss: 1.8664241491316143
Validation loss: 2.51867223876741

Epoch: 5| Step: 5
Training loss: 2.502751362282856
Validation loss: 2.5181504598558018

Epoch: 5| Step: 6
Training loss: 2.5229828132591345
Validation loss: 2.524436780383402

Epoch: 5| Step: 7
Training loss: 2.0848609918228624
Validation loss: 2.509660806211112

Epoch: 5| Step: 8
Training loss: 2.631469565176221
Validation loss: 2.5324811060879435

Epoch: 5| Step: 9
Training loss: 3.2312152558161373
Validation loss: 2.5147524834992985

Epoch: 5| Step: 10
Training loss: 2.716690160107588
Validation loss: 2.5219413723379347

Epoch: 5| Step: 11
Training loss: 2.5354588685066775
Validation loss: 2.526784934320254

Epoch: 19| Step: 0
Training loss: 2.5664540000433242
Validation loss: 2.527851444843077

Epoch: 5| Step: 1
Training loss: 2.783322794165236
Validation loss: 2.528461287836086

Epoch: 5| Step: 2
Training loss: 1.9484904119164148
Validation loss: 2.5381906313388454

Epoch: 5| Step: 3
Training loss: 3.030199321070322
Validation loss: 2.540500847730049

Epoch: 5| Step: 4
Training loss: 3.0137620616973675
Validation loss: 2.5222171592299816

Epoch: 5| Step: 5
Training loss: 2.7787026730521296
Validation loss: 2.5251664123368434

Epoch: 5| Step: 6
Training loss: 2.7762878385161147
Validation loss: 2.5149633868366665

Epoch: 5| Step: 7
Training loss: 2.4990669416641196
Validation loss: 2.5304496268978514

Epoch: 5| Step: 8
Training loss: 2.310995385694003
Validation loss: 2.504133022789005

Epoch: 5| Step: 9
Training loss: 2.0178743571476723
Validation loss: 2.537391993380375

Epoch: 5| Step: 10
Training loss: 2.2255408369100196
Validation loss: 2.531254462249967

Epoch: 5| Step: 11
Training loss: 2.9624410953379594
Validation loss: 2.5108465734103818

Epoch: 20| Step: 0
Training loss: 2.240120496574317
Validation loss: 2.517448277919169

Epoch: 5| Step: 1
Training loss: 2.496999656802495
Validation loss: 2.506415690163756

Epoch: 5| Step: 2
Training loss: 2.8011773120687455
Validation loss: 2.5274092731108797

Epoch: 5| Step: 3
Training loss: 3.146204608624661
Validation loss: 2.5284488076093234

Epoch: 5| Step: 4
Training loss: 1.9620480982944204
Validation loss: 2.5176309639708077

Epoch: 5| Step: 5
Training loss: 3.0699653720456004
Validation loss: 2.5334042185248173

Epoch: 5| Step: 6
Training loss: 2.5896883496457668
Validation loss: 2.5131946536548906

Epoch: 5| Step: 7
Training loss: 1.8334528566181914
Validation loss: 2.5210031867273837

Epoch: 5| Step: 8
Training loss: 2.5782820220293257
Validation loss: 2.5150324753521995

Epoch: 5| Step: 9
Training loss: 2.9094250470864957
Validation loss: 2.5182517536232587

Epoch: 5| Step: 10
Training loss: 2.15340014112941
Validation loss: 2.4968554270410435

Epoch: 5| Step: 11
Training loss: 2.9342238642209577
Validation loss: 2.4915685572706674

Epoch: 21| Step: 0
Training loss: 1.790573414963254
Validation loss: 2.497994174555473

Epoch: 5| Step: 1
Training loss: 2.5081576766379112
Validation loss: 2.49952254504456

Epoch: 5| Step: 2
Training loss: 2.577888061733031
Validation loss: 2.4962801060288196

Epoch: 5| Step: 3
Training loss: 2.9796919104028876
Validation loss: 2.5106209847232415

Epoch: 5| Step: 4
Training loss: 2.6079368054275234
Validation loss: 2.5052212313652444

Epoch: 5| Step: 5
Training loss: 2.605109560341103
Validation loss: 2.5195288093811357

Epoch: 5| Step: 6
Training loss: 2.490729596132632
Validation loss: 2.524984194765889

Epoch: 5| Step: 7
Training loss: 2.8784361498180053
Validation loss: 2.527190465666338

Epoch: 5| Step: 8
Training loss: 2.525654672034438
Validation loss: 2.509137527500808

Epoch: 5| Step: 9
Training loss: 2.7413434851726866
Validation loss: 2.523650188950608

Epoch: 5| Step: 10
Training loss: 2.2755184546979397
Validation loss: 2.5140111497147735

Epoch: 5| Step: 11
Training loss: 2.740921902206066
Validation loss: 2.4857025757979927

Epoch: 22| Step: 0
Training loss: 2.484617305431455
Validation loss: 2.486646825078019

Epoch: 5| Step: 1
Training loss: 1.63363969647937
Validation loss: 2.502314886600968

Epoch: 5| Step: 2
Training loss: 3.2803823141260615
Validation loss: 2.5008118225281817

Epoch: 5| Step: 3
Training loss: 2.9684033643231835
Validation loss: 2.501479140446896

Epoch: 5| Step: 4
Training loss: 2.1288877713862604
Validation loss: 2.4863813284200713

Epoch: 5| Step: 5
Training loss: 2.0910553174284163
Validation loss: 2.5178107841479225

Epoch: 5| Step: 6
Training loss: 2.1991919724238462
Validation loss: 2.4956801245403684

Epoch: 5| Step: 7
Training loss: 2.3624960359408913
Validation loss: 2.5063135216734023

Epoch: 5| Step: 8
Training loss: 2.8365820790584135
Validation loss: 2.5047059312103817

Epoch: 5| Step: 9
Training loss: 2.7467575030753415
Validation loss: 2.493837537798628

Epoch: 5| Step: 10
Training loss: 2.6960818754435962
Validation loss: 2.491550200641825

Epoch: 5| Step: 11
Training loss: 2.8097191520251337
Validation loss: 2.507799297072217

Epoch: 23| Step: 0
Training loss: 2.1827352675343907
Validation loss: 2.503786477940342

Epoch: 5| Step: 1
Training loss: 2.516506822406655
Validation loss: 2.513463295970171

Epoch: 5| Step: 2
Training loss: 2.811176412458039
Validation loss: 2.5273689767953256

Epoch: 5| Step: 3
Training loss: 2.403795451876655
Validation loss: 2.51387811312172

Epoch: 5| Step: 4
Training loss: 3.10367832993695
Validation loss: 2.5390988097895804

Epoch: 5| Step: 5
Training loss: 2.729230826596789
Validation loss: 2.527290096037717

Epoch: 5| Step: 6
Training loss: 2.2517931468612344
Validation loss: 2.51520852379119

Epoch: 5| Step: 7
Training loss: 2.560214349147415
Validation loss: 2.5222566004707807

Epoch: 5| Step: 8
Training loss: 2.763268625340029
Validation loss: 2.5078734829183515

Epoch: 5| Step: 9
Training loss: 2.3419022460851147
Validation loss: 2.5092553120878307

Epoch: 5| Step: 10
Training loss: 2.3495516369607357
Validation loss: 2.5144411543562715

Epoch: 5| Step: 11
Training loss: 2.0751937040434942
Validation loss: 2.490474490887398

Epoch: 24| Step: 0
Training loss: 2.6979094889384543
Validation loss: 2.5096224574557056

Epoch: 5| Step: 1
Training loss: 2.5054985613189813
Validation loss: 2.510918588177387

Epoch: 5| Step: 2
Training loss: 2.440245036344167
Validation loss: 2.4863077798646764

Epoch: 5| Step: 3
Training loss: 1.7579875265510023
Validation loss: 2.5000268179726652

Epoch: 5| Step: 4
Training loss: 2.1676505740266077
Validation loss: 2.5225440708333204

Epoch: 5| Step: 5
Training loss: 2.2565710753344086
Validation loss: 2.498609279208748

Epoch: 5| Step: 6
Training loss: 1.9469351990334012
Validation loss: 2.4925800958962503

Epoch: 5| Step: 7
Training loss: 2.9358191043517246
Validation loss: 2.4846303356760946

Epoch: 5| Step: 8
Training loss: 3.1750523480282538
Validation loss: 2.502792324861717

Epoch: 5| Step: 9
Training loss: 2.4373121922840024
Validation loss: 2.502276929458831

Epoch: 5| Step: 10
Training loss: 3.349323227117967
Validation loss: 2.481962864355657

Epoch: 5| Step: 11
Training loss: 1.5611028146504464
Validation loss: 2.508249603238501

Epoch: 25| Step: 0
Training loss: 2.979973388143419
Validation loss: 2.4822335920905427

Epoch: 5| Step: 1
Training loss: 2.712657371913198
Validation loss: 2.4857539142919407

Epoch: 5| Step: 2
Training loss: 2.8288684521130265
Validation loss: 2.4938299771759893

Epoch: 5| Step: 3
Training loss: 2.68447803659277
Validation loss: 2.5040193632367926

Epoch: 5| Step: 4
Training loss: 2.8846933902072456
Validation loss: 2.477565574278603

Epoch: 5| Step: 5
Training loss: 2.3111777778428637
Validation loss: 2.4891995622342615

Epoch: 5| Step: 6
Training loss: 2.3704221676204815
Validation loss: 2.4688892003342553

Epoch: 5| Step: 7
Training loss: 2.120588772905868
Validation loss: 2.4717407862078478

Epoch: 5| Step: 8
Training loss: 2.055786419124299
Validation loss: 2.48509265123135

Epoch: 5| Step: 9
Training loss: 2.1041219221840564
Validation loss: 2.492695444735024

Epoch: 5| Step: 10
Training loss: 2.509826421928993
Validation loss: 2.49858907780932

Epoch: 5| Step: 11
Training loss: 2.4506969706156387
Validation loss: 2.470958924653129

Epoch: 26| Step: 0
Training loss: 2.5577020154055035
Validation loss: 2.489641046586646

Epoch: 5| Step: 1
Training loss: 2.4916098950743026
Validation loss: 2.4944635320118183

Epoch: 5| Step: 2
Training loss: 2.6327412309820244
Validation loss: 2.4837926745960286

Epoch: 5| Step: 3
Training loss: 2.272149733941878
Validation loss: 2.4848986219812783

Epoch: 5| Step: 4
Training loss: 2.2984776517367855
Validation loss: 2.4954680373434623

Epoch: 5| Step: 5
Training loss: 2.4134617524025646
Validation loss: 2.4875518192791564

Epoch: 5| Step: 6
Training loss: 1.845934591967512
Validation loss: 2.471594688574739

Epoch: 5| Step: 7
Training loss: 2.925110030753818
Validation loss: 2.478854044803247

Epoch: 5| Step: 8
Training loss: 2.8002237060282327
Validation loss: 2.5007659374571873

Epoch: 5| Step: 9
Training loss: 3.199536802623588
Validation loss: 2.495718500449504

Epoch: 5| Step: 10
Training loss: 2.028742489615763
Validation loss: 2.5098771047015442

Epoch: 5| Step: 11
Training loss: 2.1957791195666854
Validation loss: 2.5020386489914084

Epoch: 27| Step: 0
Training loss: 2.3072357056133916
Validation loss: 2.5057433079920672

Epoch: 5| Step: 1
Training loss: 2.9947382560058338
Validation loss: 2.4860151083368978

Epoch: 5| Step: 2
Training loss: 2.965667409161502
Validation loss: 2.5049406663386735

Epoch: 5| Step: 3
Training loss: 2.318292631298887
Validation loss: 2.5230271524439147

Epoch: 5| Step: 4
Training loss: 2.8395948970015334
Validation loss: 2.5156471219877026

Epoch: 5| Step: 5
Training loss: 2.729026053108941
Validation loss: 2.5268273707991438

Epoch: 5| Step: 6
Training loss: 1.944685992118181
Validation loss: 2.4991149726572

Epoch: 5| Step: 7
Training loss: 2.060579619667252
Validation loss: 2.522499719218984

Epoch: 5| Step: 8
Training loss: 2.412581301095014
Validation loss: 2.497616442236948

Epoch: 5| Step: 9
Training loss: 2.5928416672402026
Validation loss: 2.521182730922669

Epoch: 5| Step: 10
Training loss: 2.412099886114939
Validation loss: 2.5118352765095686

Epoch: 5| Step: 11
Training loss: 1.8608270953504207
Validation loss: 2.5153264249603473

Epoch: 28| Step: 0
Training loss: 2.644934844600872
Validation loss: 2.484928573257323

Epoch: 5| Step: 1
Training loss: 2.2491105758873573
Validation loss: 2.4838149921071366

Epoch: 5| Step: 2
Training loss: 2.712600242063358
Validation loss: 2.494980541451512

Epoch: 5| Step: 3
Training loss: 2.4859280320520125
Validation loss: 2.477748488597956

Epoch: 5| Step: 4
Training loss: 2.820244447515835
Validation loss: 2.4590860173612588

Epoch: 5| Step: 5
Training loss: 2.336333480494614
Validation loss: 2.478071797791175

Epoch: 5| Step: 6
Training loss: 2.232482215152654
Validation loss: 2.508016100706573

Epoch: 5| Step: 7
Training loss: 2.514673088471407
Validation loss: 2.4711278055364763

Epoch: 5| Step: 8
Training loss: 2.2601785373215204
Validation loss: 2.47065676920832

Epoch: 5| Step: 9
Training loss: 2.4182024274327207
Validation loss: 2.4935722808802874

Epoch: 5| Step: 10
Training loss: 2.508588153995627
Validation loss: 2.499953968895889

Epoch: 5| Step: 11
Training loss: 3.7088960513525815
Validation loss: 2.483681723992603

Epoch: 29| Step: 0
Training loss: 2.2339216719430772
Validation loss: 2.4672148112129655

Epoch: 5| Step: 1
Training loss: 1.9789291507014832
Validation loss: 2.467170205839818

Epoch: 5| Step: 2
Training loss: 2.3920800262766746
Validation loss: 2.481413962025914

Epoch: 5| Step: 3
Training loss: 2.5007036172626256
Validation loss: 2.4816166762154093

Epoch: 5| Step: 4
Training loss: 2.7707604611405907
Validation loss: 2.5131205576873454

Epoch: 5| Step: 5
Training loss: 2.9177757515972482
Validation loss: 2.496497028628944

Epoch: 5| Step: 6
Training loss: 2.3316835179332367
Validation loss: 2.5142126363745887

Epoch: 5| Step: 7
Training loss: 2.280480032798506
Validation loss: 2.4835415807770436

Epoch: 5| Step: 8
Training loss: 3.181931212510714
Validation loss: 2.5128189295696877

Epoch: 5| Step: 9
Training loss: 2.097608285138887
Validation loss: 2.4892341410111376

Epoch: 5| Step: 10
Training loss: 2.4129394091552814
Validation loss: 2.5122002495568188

Epoch: 5| Step: 11
Training loss: 3.018152156414587
Validation loss: 2.529161156507478

Epoch: 30| Step: 0
Training loss: 2.5228940774256503
Validation loss: 2.4969687363492117

Epoch: 5| Step: 1
Training loss: 2.7062981123314627
Validation loss: 2.522084329009247

Epoch: 5| Step: 2
Training loss: 2.2945850401078234
Validation loss: 2.520156226897537

Epoch: 5| Step: 3
Training loss: 2.0979312879803556
Validation loss: 2.5128506037848193

Epoch: 5| Step: 4
Training loss: 2.434877011367482
Validation loss: 2.4986925719765414

Epoch: 5| Step: 5
Training loss: 2.0784522924612325
Validation loss: 2.491879891651571

Epoch: 5| Step: 6
Training loss: 2.252144745004995
Validation loss: 2.505211510263016

Epoch: 5| Step: 7
Training loss: 2.3488843501606644
Validation loss: 2.4978761472960445

Epoch: 5| Step: 8
Training loss: 2.6309381259383255
Validation loss: 2.4924405466760646

Epoch: 5| Step: 9
Training loss: 2.47568484377742
Validation loss: 2.473357580760987

Epoch: 5| Step: 10
Training loss: 3.06413801334593
Validation loss: 2.484064496627775

Epoch: 5| Step: 11
Training loss: 4.2017211838700605
Validation loss: 2.4737978284201296

Epoch: 31| Step: 0
Training loss: 2.3718329947349432
Validation loss: 2.4857396510412424

Epoch: 5| Step: 1
Training loss: 2.429299571969228
Validation loss: 2.465227213118624

Epoch: 5| Step: 2
Training loss: 2.32729708908752
Validation loss: 2.474732124718526

Epoch: 5| Step: 3
Training loss: 2.746710630669939
Validation loss: 2.475937683276866

Epoch: 5| Step: 4
Training loss: 2.467582909641455
Validation loss: 2.4961318449437573

Epoch: 5| Step: 5
Training loss: 1.918702150425417
Validation loss: 2.4895168292900594

Epoch: 5| Step: 6
Training loss: 2.585569234481333
Validation loss: 2.498644560694319

Epoch: 5| Step: 7
Training loss: 2.7192609460331036
Validation loss: 2.512463642603796

Epoch: 5| Step: 8
Training loss: 2.5974482632313536
Validation loss: 2.4910874365432054

Epoch: 5| Step: 9
Training loss: 2.8706941287576755
Validation loss: 2.4694029511936217

Epoch: 5| Step: 10
Training loss: 2.45581888390277
Validation loss: 2.4709253706255847

Epoch: 5| Step: 11
Training loss: 2.759920692271902
Validation loss: 2.4829842495436005

Epoch: 32| Step: 0
Training loss: 2.482592537068587
Validation loss: 2.482190737404622

Epoch: 5| Step: 1
Training loss: 2.587227398799368
Validation loss: 2.476662005041039

Epoch: 5| Step: 2
Training loss: 2.546913755157111
Validation loss: 2.4966742368408488

Epoch: 5| Step: 3
Training loss: 2.174117871876543
Validation loss: 2.4675247838000534

Epoch: 5| Step: 4
Training loss: 2.6147373858252525
Validation loss: 2.504729204629843

Epoch: 5| Step: 5
Training loss: 2.204191666613347
Validation loss: 2.512578687495301

Epoch: 5| Step: 6
Training loss: 3.0864194083272483
Validation loss: 2.465495890309979

Epoch: 5| Step: 7
Training loss: 2.8111688642721853
Validation loss: 2.4670935679152945

Epoch: 5| Step: 8
Training loss: 2.098767432026267
Validation loss: 2.475605287294427

Epoch: 5| Step: 9
Training loss: 2.1741735795675
Validation loss: 2.473307386724489

Epoch: 5| Step: 10
Training loss: 2.525701587764677
Validation loss: 2.474522174361627

Epoch: 5| Step: 11
Training loss: 1.3211990179152366
Validation loss: 2.4473594572442456

Epoch: 33| Step: 0
Training loss: 2.132078051306756
Validation loss: 2.4684733626136595

Epoch: 5| Step: 1
Training loss: 1.9978497390224106
Validation loss: 2.4741163477711905

Epoch: 5| Step: 2
Training loss: 2.0791193368706526
Validation loss: 2.4720659480428475

Epoch: 5| Step: 3
Training loss: 2.5615167359567312
Validation loss: 2.4987644718775845

Epoch: 5| Step: 4
Training loss: 2.3745335572619286
Validation loss: 2.5152599946583574

Epoch: 5| Step: 5
Training loss: 2.7649837979054133
Validation loss: 2.5251108178285784

Epoch: 5| Step: 6
Training loss: 2.3111128899779363
Validation loss: 2.50767096400329

Epoch: 5| Step: 7
Training loss: 2.1850914911105956
Validation loss: 2.509289066178197

Epoch: 5| Step: 8
Training loss: 2.666854871625195
Validation loss: 2.5413168773304298

Epoch: 5| Step: 9
Training loss: 3.1536653719148986
Validation loss: 2.510974360418784

Epoch: 5| Step: 10
Training loss: 2.5448824337108213
Validation loss: 2.503966494910166

Epoch: 5| Step: 11
Training loss: 3.93669980107596
Validation loss: 2.512371368025481

Epoch: 34| Step: 0
Training loss: 2.135155700616525
Validation loss: 2.486459928836212

Epoch: 5| Step: 1
Training loss: 2.3384904976211898
Validation loss: 2.5047067165133368

Epoch: 5| Step: 2
Training loss: 2.9627557571686096
Validation loss: 2.4833081451894485

Epoch: 5| Step: 3
Training loss: 2.248905127424401
Validation loss: 2.473523434342835

Epoch: 5| Step: 4
Training loss: 2.9923133923214347
Validation loss: 2.473535916588874

Epoch: 5| Step: 5
Training loss: 2.475545873073238
Validation loss: 2.4613044828445774

Epoch: 5| Step: 6
Training loss: 2.6065078790729626
Validation loss: 2.43547883151566

Epoch: 5| Step: 7
Training loss: 2.1217180601349654
Validation loss: 2.4639020472058957

Epoch: 5| Step: 8
Training loss: 2.559808573718361
Validation loss: 2.4841249727996386

Epoch: 5| Step: 9
Training loss: 2.1902068692747965
Validation loss: 2.454596974828118

Epoch: 5| Step: 10
Training loss: 2.159203096605351
Validation loss: 2.4686179105615116

Epoch: 5| Step: 11
Training loss: 2.9722160584889927
Validation loss: 2.4494289833220515

Epoch: 35| Step: 0
Training loss: 2.6303624375524683
Validation loss: 2.469384634960948

Epoch: 5| Step: 1
Training loss: 2.4354812870203437
Validation loss: 2.481187491025915

Epoch: 5| Step: 2
Training loss: 2.431731220074408
Validation loss: 2.470896296934566

Epoch: 5| Step: 3
Training loss: 2.2485573700212442
Validation loss: 2.480219422472746

Epoch: 5| Step: 4
Training loss: 2.686250618019938
Validation loss: 2.491126505299363

Epoch: 5| Step: 5
Training loss: 2.569202403676742
Validation loss: 2.4630956400589756

Epoch: 5| Step: 6
Training loss: 2.2098324443768265
Validation loss: 2.4787070098005004

Epoch: 5| Step: 7
Training loss: 2.2133732510992448
Validation loss: 2.4824287100316913

Epoch: 5| Step: 8
Training loss: 3.2671592795103255
Validation loss: 2.484065042509543

Epoch: 5| Step: 9
Training loss: 1.8142039740807296
Validation loss: 2.5029679006615617

Epoch: 5| Step: 10
Training loss: 2.4373562110158296
Validation loss: 2.4680817339406897

Epoch: 5| Step: 11
Training loss: 3.242557219601174
Validation loss: 2.472481715916116

Epoch: 36| Step: 0
Training loss: 2.3191962334569722
Validation loss: 2.4664675023783595

Epoch: 5| Step: 1
Training loss: 2.8175425783340167
Validation loss: 2.474629475091174

Epoch: 5| Step: 2
Training loss: 2.517923477906841
Validation loss: 2.4322573327875308

Epoch: 5| Step: 3
Training loss: 2.834980616696682
Validation loss: 2.4608346826782386

Epoch: 5| Step: 4
Training loss: 2.46436499829431
Validation loss: 2.4447339747713404

Epoch: 5| Step: 5
Training loss: 2.3233620483214765
Validation loss: 2.4724933034229526

Epoch: 5| Step: 6
Training loss: 2.1753495779495764
Validation loss: 2.456005640469203

Epoch: 5| Step: 7
Training loss: 2.9626113870661346
Validation loss: 2.4620119484196503

Epoch: 5| Step: 8
Training loss: 2.589772495307959
Validation loss: 2.4822978967440905

Epoch: 5| Step: 9
Training loss: 2.065347497625934
Validation loss: 2.46226230464937

Epoch: 5| Step: 10
Training loss: 2.062892298525287
Validation loss: 2.4777414061091587

Epoch: 5| Step: 11
Training loss: 1.9383622988600056
Validation loss: 2.450758634995339

Epoch: 37| Step: 0
Training loss: 2.6600400924529373
Validation loss: 2.487629671886273

Epoch: 5| Step: 1
Training loss: 1.888702991943284
Validation loss: 2.4809069108821062

Epoch: 5| Step: 2
Training loss: 2.011186073667128
Validation loss: 2.48444990528994

Epoch: 5| Step: 3
Training loss: 2.333529861438952
Validation loss: 2.507794757435624

Epoch: 5| Step: 4
Training loss: 2.678106881684628
Validation loss: 2.5055654486676797

Epoch: 5| Step: 5
Training loss: 2.392787478882715
Validation loss: 2.499625829670415

Epoch: 5| Step: 6
Training loss: 2.3577007896700635
Validation loss: 2.5162663047111935

Epoch: 5| Step: 7
Training loss: 2.8276941803785256
Validation loss: 2.5213614940372673

Epoch: 5| Step: 8
Training loss: 2.3426977211347313
Validation loss: 2.521940233946005

Epoch: 5| Step: 9
Training loss: 2.7873895152823556
Validation loss: 2.488459091179084

Epoch: 5| Step: 10
Training loss: 2.7600481087182094
Validation loss: 2.4483536891554145

Epoch: 5| Step: 11
Training loss: 1.5818730781510344
Validation loss: 2.5091419043618215

Epoch: 38| Step: 0
Training loss: 2.37005039241993
Validation loss: 2.4829023142903037

Epoch: 5| Step: 1
Training loss: 3.026979249729984
Validation loss: 2.4865742951355037

Epoch: 5| Step: 2
Training loss: 2.522712248992548
Validation loss: 2.4965048915525556

Epoch: 5| Step: 3
Training loss: 1.4903672385326807
Validation loss: 2.4964130696834688

Epoch: 5| Step: 4
Training loss: 2.4139650195541575
Validation loss: 2.4680643175666432

Epoch: 5| Step: 5
Training loss: 2.9580018480151984
Validation loss: 2.484375787730862

Epoch: 5| Step: 6
Training loss: 2.4215757123542643
Validation loss: 2.466198435581235

Epoch: 5| Step: 7
Training loss: 2.226072665760179
Validation loss: 2.4740910598219816

Epoch: 5| Step: 8
Training loss: 2.0337858363618415
Validation loss: 2.47452140958862

Epoch: 5| Step: 9
Training loss: 2.97024883781971
Validation loss: 2.4598132436568507

Epoch: 5| Step: 10
Training loss: 2.2313876155013483
Validation loss: 2.4857547895069563

Epoch: 5| Step: 11
Training loss: 2.6046910075969
Validation loss: 2.461206415409479

Epoch: 39| Step: 0
Training loss: 2.6877191143757493
Validation loss: 2.459873857682025

Epoch: 5| Step: 1
Training loss: 2.3397095503238665
Validation loss: 2.459357785007536

Epoch: 5| Step: 2
Training loss: 2.052163550137082
Validation loss: 2.4602697929927606

Epoch: 5| Step: 3
Training loss: 2.66119113683218
Validation loss: 2.501085077682499

Epoch: 5| Step: 4
Training loss: 2.585649364818607
Validation loss: 2.48879339875159

Epoch: 5| Step: 5
Training loss: 2.5547460146860868
Validation loss: 2.4671917979529328

Epoch: 5| Step: 6
Training loss: 1.9683720059300904
Validation loss: 2.4886854313589106

Epoch: 5| Step: 7
Training loss: 2.1265837433571684
Validation loss: 2.482780876782515

Epoch: 5| Step: 8
Training loss: 2.5008225041627123
Validation loss: 2.4942940804420477

Epoch: 5| Step: 9
Training loss: 2.8189398048255625
Validation loss: 2.480964302763568

Epoch: 5| Step: 10
Training loss: 2.4002486855092364
Validation loss: 2.490519153542763

Epoch: 5| Step: 11
Training loss: 3.0220709183940775
Validation loss: 2.5089896579611386

Epoch: 40| Step: 0
Training loss: 2.5809200048217424
Validation loss: 2.468896833310544

Epoch: 5| Step: 1
Training loss: 2.226501892335757
Validation loss: 2.4536861458202837

Epoch: 5| Step: 2
Training loss: 1.9653858324351772
Validation loss: 2.457145718575036

Epoch: 5| Step: 3
Training loss: 2.2363947562740107
Validation loss: 2.4792468007277253

Epoch: 5| Step: 4
Training loss: 2.4878815669791634
Validation loss: 2.4704788528398907

Epoch: 5| Step: 5
Training loss: 2.3807232812377404
Validation loss: 2.4728765444780056

Epoch: 5| Step: 6
Training loss: 2.9077907292915706
Validation loss: 2.4866615345555068

Epoch: 5| Step: 7
Training loss: 2.4079066927121793
Validation loss: 2.481577619868357

Epoch: 5| Step: 8
Training loss: 2.67524390846659
Validation loss: 2.4795015787390255

Epoch: 5| Step: 9
Training loss: 2.803847333193961
Validation loss: 2.480612370696036

Epoch: 5| Step: 10
Training loss: 1.9606112630531303
Validation loss: 2.4681397460422287

Epoch: 5| Step: 11
Training loss: 2.4460380867077185
Validation loss: 2.4544516294889487

Epoch: 41| Step: 0
Training loss: 2.3915279902041053
Validation loss: 2.4634989895393677

Epoch: 5| Step: 1
Training loss: 2.189215287316154
Validation loss: 2.4499919386815425

Epoch: 5| Step: 2
Training loss: 2.5069174431931507
Validation loss: 2.4802345625894864

Epoch: 5| Step: 3
Training loss: 2.7472495282646854
Validation loss: 2.4716969095949146

Epoch: 5| Step: 4
Training loss: 2.627960261603315
Validation loss: 2.4752556153474434

Epoch: 5| Step: 5
Training loss: 2.4401186057484234
Validation loss: 2.4775481443798797

Epoch: 5| Step: 6
Training loss: 2.2017729377751563
Validation loss: 2.4647718520844912

Epoch: 5| Step: 7
Training loss: 2.3514698301793397
Validation loss: 2.469221971360037

Epoch: 5| Step: 8
Training loss: 3.0082680889743854
Validation loss: 2.4804177827179488

Epoch: 5| Step: 9
Training loss: 1.9468971140969489
Validation loss: 2.444882754262617

Epoch: 5| Step: 10
Training loss: 2.412455990246601
Validation loss: 2.4668676547912516

Epoch: 5| Step: 11
Training loss: 2.2514173493994307
Validation loss: 2.4526509881925613

Epoch: 42| Step: 0
Training loss: 2.206329936451633
Validation loss: 2.4642996855090287

Epoch: 5| Step: 1
Training loss: 1.9527437372015641
Validation loss: 2.468285504838715

Epoch: 5| Step: 2
Training loss: 2.9489370855771715
Validation loss: 2.4451562021048163

Epoch: 5| Step: 3
Training loss: 2.110900553303035
Validation loss: 2.4658674883972114

Epoch: 5| Step: 4
Training loss: 3.209466379084935
Validation loss: 2.4582035965279774

Epoch: 5| Step: 5
Training loss: 1.7815556180346312
Validation loss: 2.499005811419681

Epoch: 5| Step: 6
Training loss: 2.9762968810906028
Validation loss: 2.489377629122829

Epoch: 5| Step: 7
Training loss: 2.0324986068138986
Validation loss: 2.4572079468119417

Epoch: 5| Step: 8
Training loss: 2.488534767734252
Validation loss: 2.504135633129288

Epoch: 5| Step: 9
Training loss: 1.9825427389649157
Validation loss: 2.448492271980843

Epoch: 5| Step: 10
Training loss: 3.000036875180271
Validation loss: 2.451725323572038

Epoch: 5| Step: 11
Training loss: 0.8263633632368561
Validation loss: 2.4794258588583467

Epoch: 43| Step: 0
Training loss: 2.2410791296004287
Validation loss: 2.4581288936974386

Epoch: 5| Step: 1
Training loss: 2.3514588798936216
Validation loss: 2.4700986703284333

Epoch: 5| Step: 2
Training loss: 2.153236716241541
Validation loss: 2.4892274942767885

Epoch: 5| Step: 3
Training loss: 2.6726396147013163
Validation loss: 2.4786580683360864

Epoch: 5| Step: 4
Training loss: 1.8598384119415658
Validation loss: 2.4552000142472954

Epoch: 5| Step: 5
Training loss: 2.4314078468526863
Validation loss: 2.4731073073572993

Epoch: 5| Step: 6
Training loss: 2.6591664179801127
Validation loss: 2.4538174277634788

Epoch: 5| Step: 7
Training loss: 2.401552246707231
Validation loss: 2.4647916333894972

Epoch: 5| Step: 8
Training loss: 2.543387429831542
Validation loss: 2.471716149165575

Epoch: 5| Step: 9
Training loss: 2.8185931007718206
Validation loss: 2.457829954582912

Epoch: 5| Step: 10
Training loss: 2.323628634381488
Validation loss: 2.4697838562051255

Epoch: 5| Step: 11
Training loss: 2.6903148370449723
Validation loss: 2.476428259932797

Epoch: 44| Step: 0
Training loss: 2.05149483028005
Validation loss: 2.461759290782062

Epoch: 5| Step: 1
Training loss: 2.8303943612675972
Validation loss: 2.4973564834332156

Epoch: 5| Step: 2
Training loss: 2.6310103499855253
Validation loss: 2.4580077397524946

Epoch: 5| Step: 3
Training loss: 2.300820834429747
Validation loss: 2.4834230586511645

Epoch: 5| Step: 4
Training loss: 2.0780984977236896
Validation loss: 2.4944357501987415

Epoch: 5| Step: 5
Training loss: 2.3786578870890693
Validation loss: 2.468742382665544

Epoch: 5| Step: 6
Training loss: 2.6108271960752427
Validation loss: 2.4619561161140147

Epoch: 5| Step: 7
Training loss: 2.978255143579265
Validation loss: 2.4648683025832003

Epoch: 5| Step: 8
Training loss: 1.797074547343804
Validation loss: 2.438127110987296

Epoch: 5| Step: 9
Training loss: 2.1327387199635672
Validation loss: 2.4386670709493723

Epoch: 5| Step: 10
Training loss: 2.6977809051957804
Validation loss: 2.492732308369833

Epoch: 5| Step: 11
Training loss: 2.065933144535522
Validation loss: 2.4462580411749935

Epoch: 45| Step: 0
Training loss: 2.221837326996623
Validation loss: 2.4357018807650253

Epoch: 5| Step: 1
Training loss: 2.21848231030561
Validation loss: 2.4298123024046197

Epoch: 5| Step: 2
Training loss: 2.294922082779246
Validation loss: 2.4846271251005287

Epoch: 5| Step: 3
Training loss: 2.014039709940336
Validation loss: 2.450986561856265

Epoch: 5| Step: 4
Training loss: 2.836777743874139
Validation loss: 2.451212378340762

Epoch: 5| Step: 5
Training loss: 2.9240761691816903
Validation loss: 2.473777366176471

Epoch: 5| Step: 6
Training loss: 2.677691636693946
Validation loss: 2.4641369926305163

Epoch: 5| Step: 7
Training loss: 2.109731912440679
Validation loss: 2.468922375644722

Epoch: 5| Step: 8
Training loss: 2.0951949869609345
Validation loss: 2.431957133375211

Epoch: 5| Step: 9
Training loss: 2.559719158503557
Validation loss: 2.481584949610435

Epoch: 5| Step: 10
Training loss: 2.464236805906343
Validation loss: 2.473793415127453

Epoch: 5| Step: 11
Training loss: 2.160311315672197
Validation loss: 2.4299882618825994

Epoch: 46| Step: 0
Training loss: 2.185467675131666
Validation loss: 2.4763077004141945

Epoch: 5| Step: 1
Training loss: 2.39935623117883
Validation loss: 2.4735105785274496

Epoch: 5| Step: 2
Training loss: 2.3428106841687972
Validation loss: 2.484229475433648

Epoch: 5| Step: 3
Training loss: 2.159007424013591
Validation loss: 2.4680045849504033

Epoch: 5| Step: 4
Training loss: 2.714676095739426
Validation loss: 2.478718161417745

Epoch: 5| Step: 5
Training loss: 2.9697299343843895
Validation loss: 2.4823210080731557

Epoch: 5| Step: 6
Training loss: 2.4542989655236402
Validation loss: 2.4961343681361763

Epoch: 5| Step: 7
Training loss: 2.2848777666516034
Validation loss: 2.469115290597058

Epoch: 5| Step: 8
Training loss: 2.209540367142724
Validation loss: 2.4809762550674823

Epoch: 5| Step: 9
Training loss: 2.5155599834499025
Validation loss: 2.476730601705714

Epoch: 5| Step: 10
Training loss: 2.190258031301988
Validation loss: 2.491349658421024

Epoch: 5| Step: 11
Training loss: 2.806160117836043
Validation loss: 2.487513341340753

Epoch: 47| Step: 0
Training loss: 2.4720220972943827
Validation loss: 2.4604476340237618

Epoch: 5| Step: 1
Training loss: 2.556266086966114
Validation loss: 2.4835413487784077

Epoch: 5| Step: 2
Training loss: 2.2642135959329925
Validation loss: 2.4533354553527915

Epoch: 5| Step: 3
Training loss: 2.48345507978316
Validation loss: 2.467245118086643

Epoch: 5| Step: 4
Training loss: 2.3125013402986507
Validation loss: 2.4417511475131604

Epoch: 5| Step: 5
Training loss: 2.4657212039179206
Validation loss: 2.485505564576804

Epoch: 5| Step: 6
Training loss: 2.773518219968602
Validation loss: 2.456059379396198

Epoch: 5| Step: 7
Training loss: 1.7348744815858899
Validation loss: 2.47907535534418

Epoch: 5| Step: 8
Training loss: 2.035913835272338
Validation loss: 2.4803776601651424

Epoch: 5| Step: 9
Training loss: 2.7958360159378333
Validation loss: 2.4703945685951205

Epoch: 5| Step: 10
Training loss: 2.5199248723532786
Validation loss: 2.474329393902318

Epoch: 5| Step: 11
Training loss: 1.6417152778412323
Validation loss: 2.485289795113631

Epoch: 48| Step: 0
Training loss: 2.6729736746231287
Validation loss: 2.4884987760488055

Epoch: 5| Step: 1
Training loss: 2.2126193170648527
Validation loss: 2.467487177205159

Epoch: 5| Step: 2
Training loss: 2.3000302603016385
Validation loss: 2.476278663840362

Epoch: 5| Step: 3
Training loss: 2.60692147585976
Validation loss: 2.479470592323105

Epoch: 5| Step: 4
Training loss: 2.117160585802466
Validation loss: 2.4644922327234084

Epoch: 5| Step: 5
Training loss: 2.276581572882795
Validation loss: 2.46387343293118

Epoch: 5| Step: 6
Training loss: 3.110248078880946
Validation loss: 2.4860104549947164

Epoch: 5| Step: 7
Training loss: 2.328870206014582
Validation loss: 2.4474509722845426

Epoch: 5| Step: 8
Training loss: 2.698757811301351
Validation loss: 2.452577290874109

Epoch: 5| Step: 9
Training loss: 2.387993454992887
Validation loss: 2.458312773349154

Epoch: 5| Step: 10
Training loss: 1.8618845953410776
Validation loss: 2.4460116718353744

Epoch: 5| Step: 11
Training loss: 1.5060757928041517
Validation loss: 2.4399307023758254

Epoch: 49| Step: 0
Training loss: 2.1543637193562093
Validation loss: 2.456066065332793

Epoch: 5| Step: 1
Training loss: 2.8034796278886738
Validation loss: 2.479862537548014

Epoch: 5| Step: 2
Training loss: 2.304212204366487
Validation loss: 2.4677246475378234

Epoch: 5| Step: 3
Training loss: 2.641931786054346
Validation loss: 2.4420567411406684

Epoch: 5| Step: 4
Training loss: 2.9730397602377585
Validation loss: 2.464206963938401

Epoch: 5| Step: 5
Training loss: 2.1723947246228277
Validation loss: 2.446619584323928

Epoch: 5| Step: 6
Training loss: 3.1857607715301555
Validation loss: 2.436505917860099

Epoch: 5| Step: 7
Training loss: 2.57818991839431
Validation loss: 2.4676242949857703

Epoch: 5| Step: 8
Training loss: 1.8921200224407777
Validation loss: 2.4705958608228924

Epoch: 5| Step: 9
Training loss: 1.7322316715802997
Validation loss: 2.428084262586357

Epoch: 5| Step: 10
Training loss: 1.994398677617234
Validation loss: 2.4267974502324883

Epoch: 5| Step: 11
Training loss: 1.1636405026297219
Validation loss: 2.4882536267274875

Epoch: 50| Step: 0
Training loss: 2.4501120171921835
Validation loss: 2.4381837048993185

Epoch: 5| Step: 1
Training loss: 2.6021095594230315
Validation loss: 2.4626076737695657

Epoch: 5| Step: 2
Training loss: 2.0853507256030563
Validation loss: 2.476078403303617

Epoch: 5| Step: 3
Training loss: 2.2241460168574765
Validation loss: 2.4531748537800855

Epoch: 5| Step: 4
Training loss: 2.529432798290339
Validation loss: 2.4258757617371547

Epoch: 5| Step: 5
Training loss: 1.7287409231481348
Validation loss: 2.4904506554522534

Epoch: 5| Step: 6
Training loss: 2.665378547536214
Validation loss: 2.4841885566728052

Epoch: 5| Step: 7
Training loss: 2.1492704129431646
Validation loss: 2.4847021227424597

Epoch: 5| Step: 8
Training loss: 3.1458020408707665
Validation loss: 2.4878026600837058

Epoch: 5| Step: 9
Training loss: 2.0099905349736336
Validation loss: 2.505955421468346

Epoch: 5| Step: 10
Training loss: 2.4264030212542007
Validation loss: 2.449181876343543

Epoch: 5| Step: 11
Training loss: 3.164701722178007
Validation loss: 2.442193387106424

Epoch: 51| Step: 0
Training loss: 2.2380581889424334
Validation loss: 2.47362878043349

Epoch: 5| Step: 1
Training loss: 2.4535981712065835
Validation loss: 2.5029891264157675

Epoch: 5| Step: 2
Training loss: 2.099227458905979
Validation loss: 2.4968268402955127

Epoch: 5| Step: 3
Training loss: 2.3617630550911652
Validation loss: 2.5045255866083767

Epoch: 5| Step: 4
Training loss: 2.389457267843699
Validation loss: 2.53938692025471

Epoch: 5| Step: 5
Training loss: 2.7949143682201774
Validation loss: 2.5337926825146595

Epoch: 5| Step: 6
Training loss: 2.1813893664414157
Validation loss: 2.525471545636819

Epoch: 5| Step: 7
Training loss: 2.676491302059927
Validation loss: 2.507452803313692

Epoch: 5| Step: 8
Training loss: 2.241978014155043
Validation loss: 2.5423348140100384

Epoch: 5| Step: 9
Training loss: 1.923705802940218
Validation loss: 2.500748148870592

Epoch: 5| Step: 10
Training loss: 3.0017729924200567
Validation loss: 2.4904726440531992

Epoch: 5| Step: 11
Training loss: 2.836583423879841
Validation loss: 2.47592500249445

Epoch: 52| Step: 0
Training loss: 2.5535464290344074
Validation loss: 2.4743715376194175

Epoch: 5| Step: 1
Training loss: 2.1902753390363996
Validation loss: 2.469051793319096

Epoch: 5| Step: 2
Training loss: 2.7487098962235743
Validation loss: 2.4462879904251644

Epoch: 5| Step: 3
Training loss: 2.5794174191587373
Validation loss: 2.4822225663245026

Epoch: 5| Step: 4
Training loss: 2.361948895637204
Validation loss: 2.4603429530248158

Epoch: 5| Step: 5
Training loss: 2.41815707408529
Validation loss: 2.5100212115459164

Epoch: 5| Step: 6
Training loss: 2.640229867117767
Validation loss: 2.512757924349109

Epoch: 5| Step: 7
Training loss: 2.6560657212904597
Validation loss: 2.4857968474214953

Epoch: 5| Step: 8
Training loss: 2.5069403632199174
Validation loss: 2.484995910339265

Epoch: 5| Step: 9
Training loss: 2.580874739517891
Validation loss: 2.447861274471287

Epoch: 5| Step: 10
Training loss: 1.7255122930574651
Validation loss: 2.4825739660125286

Epoch: 5| Step: 11
Training loss: 1.63431731609131
Validation loss: 2.4586637761128083

Epoch: 53| Step: 0
Training loss: 2.0485686073276197
Validation loss: 2.4705388231894867

Epoch: 5| Step: 1
Training loss: 2.3571072220688953
Validation loss: 2.4479829001428106

Epoch: 5| Step: 2
Training loss: 2.16121466921626
Validation loss: 2.4998289248425096

Epoch: 5| Step: 3
Training loss: 2.446574412623975
Validation loss: 2.493285105847848

Epoch: 5| Step: 4
Training loss: 2.638050878767285
Validation loss: 2.482878980312714

Epoch: 5| Step: 5
Training loss: 2.412967272951138
Validation loss: 2.4955056342871065

Epoch: 5| Step: 6
Training loss: 2.9873583197416718
Validation loss: 2.4941627304304395

Epoch: 5| Step: 7
Training loss: 2.1221017707919065
Validation loss: 2.497582263902732

Epoch: 5| Step: 8
Training loss: 2.060499319097253
Validation loss: 2.5043929128479854

Epoch: 5| Step: 9
Training loss: 2.4428453766229525
Validation loss: 2.4938727951729667

Epoch: 5| Step: 10
Training loss: 2.3362262253957358
Validation loss: 2.429142885816933

Epoch: 5| Step: 11
Training loss: 3.1380054689825285
Validation loss: 2.5020484320508922

Epoch: 54| Step: 0
Training loss: 2.499157000509532
Validation loss: 2.4789471101644396

Epoch: 5| Step: 1
Training loss: 2.21186189232074
Validation loss: 2.4940292385304965

Epoch: 5| Step: 2
Training loss: 3.007151979523832
Validation loss: 2.4646394889820846

Epoch: 5| Step: 3
Training loss: 2.4770485193508054
Validation loss: 2.4587803181038157

Epoch: 5| Step: 4
Training loss: 2.655835646680294
Validation loss: 2.471230351381685

Epoch: 5| Step: 5
Training loss: 2.066613920625676
Validation loss: 2.4759701883935574

Epoch: 5| Step: 6
Training loss: 2.348090564839801
Validation loss: 2.438794678640997

Epoch: 5| Step: 7
Training loss: 1.9233634581209325
Validation loss: 2.4784007585670675

Epoch: 5| Step: 8
Training loss: 2.7425955009697836
Validation loss: 2.4555798131536677

Epoch: 5| Step: 9
Training loss: 2.375113032813415
Validation loss: 2.448440346942375

Epoch: 5| Step: 10
Training loss: 1.806862647358417
Validation loss: 2.4676576000219512

Epoch: 5| Step: 11
Training loss: 2.015269403362102
Validation loss: 2.4471395530610245

Epoch: 55| Step: 0
Training loss: 2.6435155453442225
Validation loss: 2.502716908742006

Epoch: 5| Step: 1
Training loss: 2.297457770290525
Validation loss: 2.4883887019728794

Epoch: 5| Step: 2
Training loss: 2.480041947779138
Validation loss: 2.503650078883313

Epoch: 5| Step: 3
Training loss: 2.124654292988762
Validation loss: 2.497045857739041

Epoch: 5| Step: 4
Training loss: 2.2280410943410605
Validation loss: 2.51443791072996

Epoch: 5| Step: 5
Training loss: 2.6376941374430465
Validation loss: 2.520969786510723

Epoch: 5| Step: 6
Training loss: 2.3393148547305445
Validation loss: 2.517025476786476

Epoch: 5| Step: 7
Training loss: 2.42850045893859
Validation loss: 2.504910062030703

Epoch: 5| Step: 8
Training loss: 2.5295519372479514
Validation loss: 2.522136526086209

Epoch: 5| Step: 9
Training loss: 2.444888727195309
Validation loss: 2.5793767106081584

Epoch: 5| Step: 10
Training loss: 2.0954494127208063
Validation loss: 2.5258112274665865

Epoch: 5| Step: 11
Training loss: 2.825452606268124
Validation loss: 2.48359000001816

Epoch: 56| Step: 0
Training loss: 2.5538320246447923
Validation loss: 2.471069421366013

Epoch: 5| Step: 1
Training loss: 2.9513318304393117
Validation loss: 2.504554263969927

Epoch: 5| Step: 2
Training loss: 2.5986793281666882
Validation loss: 2.429880488214464

Epoch: 5| Step: 3
Training loss: 2.2275308209993856
Validation loss: 2.4352516988634716

Epoch: 5| Step: 4
Training loss: 1.9548041488030488
Validation loss: 2.4531849248414725

Epoch: 5| Step: 5
Training loss: 2.442586238279645
Validation loss: 2.459981217855379

Epoch: 5| Step: 6
Training loss: 2.137503805770609
Validation loss: 2.4544412459041602

Epoch: 5| Step: 7
Training loss: 2.537551947000894
Validation loss: 2.471499855134108

Epoch: 5| Step: 8
Training loss: 2.2110501857118874
Validation loss: 2.4937939264735816

Epoch: 5| Step: 9
Training loss: 2.4502081568515472
Validation loss: 2.4772564650771485

Epoch: 5| Step: 10
Training loss: 1.9140172836256788
Validation loss: 2.468763262878074

Epoch: 5| Step: 11
Training loss: 1.4311690028563846
Validation loss: 2.4802298963993383

Epoch: 57| Step: 0
Training loss: 2.645700846881863
Validation loss: 2.466025454608694

Epoch: 5| Step: 1
Training loss: 2.650873195089054
Validation loss: 2.4825927691558896

Epoch: 5| Step: 2
Training loss: 1.647302100953936
Validation loss: 2.461151047175801

Epoch: 5| Step: 3
Training loss: 1.9063929519833591
Validation loss: 2.4710285057952617

Epoch: 5| Step: 4
Training loss: 2.190922484830007
Validation loss: 2.5100929907655654

Epoch: 5| Step: 5
Training loss: 2.789612787920711
Validation loss: 2.525771859432077

Epoch: 5| Step: 6
Training loss: 2.650637003073829
Validation loss: 2.552721832485854

Epoch: 5| Step: 7
Training loss: 2.101980855489817
Validation loss: 2.5517718235297413

Epoch: 5| Step: 8
Training loss: 2.839316800642221
Validation loss: 2.5530597038744003

Epoch: 5| Step: 9
Training loss: 2.4604417089554724
Validation loss: 2.517026893674627

Epoch: 5| Step: 10
Training loss: 2.764512608842112
Validation loss: 2.5020107765910957

Epoch: 5| Step: 11
Training loss: 1.0123684244259088
Validation loss: 2.4933344315481403

Epoch: 58| Step: 0
Training loss: 2.008784552361855
Validation loss: 2.4746819063760817

Epoch: 5| Step: 1
Training loss: 2.5149745692641527
Validation loss: 2.4735648006181084

Epoch: 5| Step: 2
Training loss: 2.120491518406185
Validation loss: 2.495682047131332

Epoch: 5| Step: 3
Training loss: 1.9990562358004895
Validation loss: 2.483394541295463

Epoch: 5| Step: 4
Training loss: 2.065773187305218
Validation loss: 2.45521034809257

Epoch: 5| Step: 5
Training loss: 2.5817279031516596
Validation loss: 2.4754820551698584

Epoch: 5| Step: 6
Training loss: 2.272443731133828
Validation loss: 2.4612748979452523

Epoch: 5| Step: 7
Training loss: 2.4327182327656685
Validation loss: 2.463217136602487

Epoch: 5| Step: 8
Training loss: 2.1322718343727143
Validation loss: 2.483975568286737

Epoch: 5| Step: 9
Training loss: 2.4523519281917534
Validation loss: 2.4752379404191673

Epoch: 5| Step: 10
Training loss: 2.9851205903044633
Validation loss: 2.4961986370466223

Epoch: 5| Step: 11
Training loss: 2.8184927778599818
Validation loss: 2.4720711480341935

Epoch: 59| Step: 0
Training loss: 2.825768516454886
Validation loss: 2.4931356346500926

Epoch: 5| Step: 1
Training loss: 2.1475986021984066
Validation loss: 2.4581166282334723

Epoch: 5| Step: 2
Training loss: 2.2195230131389203
Validation loss: 2.4404237484309506

Epoch: 5| Step: 3
Training loss: 2.0085910816390045
Validation loss: 2.457303556181985

Epoch: 5| Step: 4
Training loss: 2.502126742792921
Validation loss: 2.4593009189498263

Epoch: 5| Step: 5
Training loss: 2.8761650710185376
Validation loss: 2.4344033353476187

Epoch: 5| Step: 6
Training loss: 2.548832427857958
Validation loss: 2.4613525403943917

Epoch: 5| Step: 7
Training loss: 2.7219782988154795
Validation loss: 2.465029335189168

Epoch: 5| Step: 8
Training loss: 1.0214381016011331
Validation loss: 2.4545821177174654

Epoch: 5| Step: 9
Training loss: 2.4609041726413947
Validation loss: 2.4540963770564557

Epoch: 5| Step: 10
Training loss: 2.218075716960409
Validation loss: 2.4952139460545735

Epoch: 5| Step: 11
Training loss: 1.58335862223189
Validation loss: 2.4504956451213347

Epoch: 60| Step: 0
Training loss: 2.1772578654684294
Validation loss: 2.449821986004776

Epoch: 5| Step: 1
Training loss: 2.3442047695187225
Validation loss: 2.4773863135235934

Epoch: 5| Step: 2
Training loss: 2.6137393840645355
Validation loss: 2.483903260298108

Epoch: 5| Step: 3
Training loss: 2.5369299751033494
Validation loss: 2.479752150223426

Epoch: 5| Step: 4
Training loss: 1.859883535389518
Validation loss: 2.4823263706711347

Epoch: 5| Step: 5
Training loss: 2.4963733116565567
Validation loss: 2.4597976830295476

Epoch: 5| Step: 6
Training loss: 2.6573371906236574
Validation loss: 2.4789074326801015

Epoch: 5| Step: 7
Training loss: 2.4090979430421506
Validation loss: 2.4608245904441857

Epoch: 5| Step: 8
Training loss: 2.3552153848044513
Validation loss: 2.463427830674347

Epoch: 5| Step: 9
Training loss: 2.033179672355133
Validation loss: 2.458350025271197

Epoch: 5| Step: 10
Training loss: 1.9553193849524995
Validation loss: 2.469691209802774

Epoch: 5| Step: 11
Training loss: 3.427281537261965
Validation loss: 2.484015372776217

Epoch: 61| Step: 0
Training loss: 2.1103845511651156
Validation loss: 2.511090753337626

Epoch: 5| Step: 1
Training loss: 2.7409159872324
Validation loss: 2.500897959534389

Epoch: 5| Step: 2
Training loss: 2.734438911780982
Validation loss: 2.465028736731731

Epoch: 5| Step: 3
Training loss: 2.0320729862606997
Validation loss: 2.4606587327772234

Epoch: 5| Step: 4
Training loss: 2.384421483857899
Validation loss: 2.4592902185480514

Epoch: 5| Step: 5
Training loss: 2.4939922626194853
Validation loss: 2.439318158152646

Epoch: 5| Step: 6
Training loss: 2.4155992474484838
Validation loss: 2.4726655707803853

Epoch: 5| Step: 7
Training loss: 2.068551174416925
Validation loss: 2.4347560060440534

Epoch: 5| Step: 8
Training loss: 2.4094481579550124
Validation loss: 2.4632833693560046

Epoch: 5| Step: 9
Training loss: 2.52106120653311
Validation loss: 2.4548126558692163

Epoch: 5| Step: 10
Training loss: 1.8063546279118519
Validation loss: 2.4347748439056742

Epoch: 5| Step: 11
Training loss: 2.491878478404445
Validation loss: 2.4702976783727633

Epoch: 62| Step: 0
Training loss: 2.293328486075195
Validation loss: 2.4875845979397657

Epoch: 5| Step: 1
Training loss: 3.1748194064946405
Validation loss: 2.4861615393110235

Epoch: 5| Step: 2
Training loss: 2.568278983710957
Validation loss: 2.4505268681958947

Epoch: 5| Step: 3
Training loss: 2.074553784110628
Validation loss: 2.4576561420725294

Epoch: 5| Step: 4
Training loss: 2.3094945399171714
Validation loss: 2.479803894330313

Epoch: 5| Step: 5
Training loss: 1.9937624222419266
Validation loss: 2.4890432423694553

Epoch: 5| Step: 6
Training loss: 1.522151697842402
Validation loss: 2.4614225565510788

Epoch: 5| Step: 7
Training loss: 1.8435844735019602
Validation loss: 2.5085464663164347

Epoch: 5| Step: 8
Training loss: 2.872081934267544
Validation loss: 2.5082462110048156

Epoch: 5| Step: 9
Training loss: 2.3978164316058383
Validation loss: 2.504951972824627

Epoch: 5| Step: 10
Training loss: 2.0902642228147137
Validation loss: 2.510385296785202

Epoch: 5| Step: 11
Training loss: 2.315395192468955
Validation loss: 2.521709216410835

Epoch: 63| Step: 0
Training loss: 2.5860783748919878
Validation loss: 2.459830197480284

Epoch: 5| Step: 1
Training loss: 2.663656791155369
Validation loss: 2.482430999042782

Epoch: 5| Step: 2
Training loss: 2.3210183043080694
Validation loss: 2.4949266135737806

Epoch: 5| Step: 3
Training loss: 2.1863509293689654
Validation loss: 2.5204456454205713

Epoch: 5| Step: 4
Training loss: 1.7845556805689144
Validation loss: 2.4706074611955793

Epoch: 5| Step: 5
Training loss: 1.8454960459643814
Validation loss: 2.473648378464027

Epoch: 5| Step: 6
Training loss: 2.312017957604439
Validation loss: 2.501248620074348

Epoch: 5| Step: 7
Training loss: 2.1644795701016
Validation loss: 2.487406957825571

Epoch: 5| Step: 8
Training loss: 2.972956197396077
Validation loss: 2.463976756434193

Epoch: 5| Step: 9
Training loss: 2.4796511286259695
Validation loss: 2.485660508295225

Epoch: 5| Step: 10
Training loss: 2.234655189285909
Validation loss: 2.477937791831684

Epoch: 5| Step: 11
Training loss: 2.496528217549669
Validation loss: 2.49633604812865

Epoch: 64| Step: 0
Training loss: 2.181680622605035
Validation loss: 2.4841374657595408

Epoch: 5| Step: 1
Training loss: 3.008557195250695
Validation loss: 2.447089803661035

Epoch: 5| Step: 2
Training loss: 2.0764150826947123
Validation loss: 2.4293476615292002

Epoch: 5| Step: 3
Training loss: 2.5679837608536977
Validation loss: 2.4960064462309517

Epoch: 5| Step: 4
Training loss: 2.030965462342606
Validation loss: 2.4600413270066

Epoch: 5| Step: 5
Training loss: 2.198894144769116
Validation loss: 2.485290766423957

Epoch: 5| Step: 6
Training loss: 2.2226248204266748
Validation loss: 2.4803687929052933

Epoch: 5| Step: 7
Training loss: 2.606202898583298
Validation loss: 2.4872607419590436

Epoch: 5| Step: 8
Training loss: 1.9788763201378254
Validation loss: 2.4815389332030358

Epoch: 5| Step: 9
Training loss: 2.111085438432807
Validation loss: 2.492721070000554

Epoch: 5| Step: 10
Training loss: 2.532285690352871
Validation loss: 2.4873390989166047

Epoch: 5| Step: 11
Training loss: 1.254407550748657
Validation loss: 2.4832439847101577

Epoch: 65| Step: 0
Training loss: 2.2365664958931486
Validation loss: 2.468513805422015

Epoch: 5| Step: 1
Training loss: 2.1005019450897167
Validation loss: 2.4986154616551683

Epoch: 5| Step: 2
Training loss: 2.9311610877373533
Validation loss: 2.4842332683577024

Epoch: 5| Step: 3
Training loss: 2.468660666865469
Validation loss: 2.440388708036426

Epoch: 5| Step: 4
Training loss: 2.563091395915233
Validation loss: 2.4683971756499075

Epoch: 5| Step: 5
Training loss: 2.1414020548031005
Validation loss: 2.4928422663652445

Epoch: 5| Step: 6
Training loss: 2.3986365021396994
Validation loss: 2.4699342679789678

Epoch: 5| Step: 7
Training loss: 2.192765356728341
Validation loss: 2.466679561963612

Epoch: 5| Step: 8
Training loss: 1.8782540376991226
Validation loss: 2.486655819762055

Epoch: 5| Step: 9
Training loss: 2.370743400418924
Validation loss: 2.4659437494888046

Epoch: 5| Step: 10
Training loss: 2.2087824262862883
Validation loss: 2.454322474077662

Epoch: 5| Step: 11
Training loss: 1.9313528928537682
Validation loss: 2.447400259103377

Epoch: 66| Step: 0
Training loss: 1.7068320011853497
Validation loss: 2.4910833290442183

Epoch: 5| Step: 1
Training loss: 2.4255228442467094
Validation loss: 2.4776249160095554

Epoch: 5| Step: 2
Training loss: 2.361641004104834
Validation loss: 2.4610823452421107

Epoch: 5| Step: 3
Training loss: 2.496934441729042
Validation loss: 2.504398644683746

Epoch: 5| Step: 4
Training loss: 2.533631793644329
Validation loss: 2.468405546631972

Epoch: 5| Step: 5
Training loss: 1.9415074404589394
Validation loss: 2.4712868424394587

Epoch: 5| Step: 6
Training loss: 2.7528093899698365
Validation loss: 2.492596452218492

Epoch: 5| Step: 7
Training loss: 1.9432566860039295
Validation loss: 2.469437732754161

Epoch: 5| Step: 8
Training loss: 2.2432783178278553
Validation loss: 2.4931370312462673

Epoch: 5| Step: 9
Training loss: 2.6718826739998534
Validation loss: 2.4951562767674584

Epoch: 5| Step: 10
Training loss: 2.3085099929616417
Validation loss: 2.495293595957625

Epoch: 5| Step: 11
Training loss: 2.3913361731963376
Validation loss: 2.50880251363987

Epoch: 67| Step: 0
Training loss: 2.344708462875269
Validation loss: 2.4755149695703325

Epoch: 5| Step: 1
Training loss: 2.5293230799197532
Validation loss: 2.4853053839989485

Epoch: 5| Step: 2
Training loss: 1.7446927246584
Validation loss: 2.463631389723377

Epoch: 5| Step: 3
Training loss: 2.2165028112364844
Validation loss: 2.478163713984208

Epoch: 5| Step: 4
Training loss: 1.9634967532362977
Validation loss: 2.469980942997538

Epoch: 5| Step: 5
Training loss: 2.5601175910049423
Validation loss: 2.4620682555730258

Epoch: 5| Step: 6
Training loss: 1.9018736460139043
Validation loss: 2.4450120670252256

Epoch: 5| Step: 7
Training loss: 2.2476743759044937
Validation loss: 2.4355317752373122

Epoch: 5| Step: 8
Training loss: 2.765444561088304
Validation loss: 2.4273330712797168

Epoch: 5| Step: 9
Training loss: 2.473096088262602
Validation loss: 2.4415216973029614

Epoch: 5| Step: 10
Training loss: 2.7961760771814874
Validation loss: 2.4646217862889066

Epoch: 5| Step: 11
Training loss: 2.337304573253528
Validation loss: 2.490802346077538

Epoch: 68| Step: 0
Training loss: 2.254353655700068
Validation loss: 2.491225799472351

Epoch: 5| Step: 1
Training loss: 1.8336846347384557
Validation loss: 2.479722875556287

Epoch: 5| Step: 2
Training loss: 2.2701928755033314
Validation loss: 2.524341820790573

Epoch: 5| Step: 3
Training loss: 2.1128280068990613
Validation loss: 2.539993819582171

Epoch: 5| Step: 4
Training loss: 2.387576184879707
Validation loss: 2.545739394628017

Epoch: 5| Step: 5
Training loss: 2.7036324614550145
Validation loss: 2.5873568194237584

Epoch: 5| Step: 6
Training loss: 2.4630987456054267
Validation loss: 2.5734134894530403

Epoch: 5| Step: 7
Training loss: 1.4829898997430389
Validation loss: 2.586646456309719

Epoch: 5| Step: 8
Training loss: 2.428485339906868
Validation loss: 2.5951189503697605

Epoch: 5| Step: 9
Training loss: 2.7372454590229744
Validation loss: 2.566294833648089

Epoch: 5| Step: 10
Training loss: 2.890086190809474
Validation loss: 2.5254842687220203

Epoch: 5| Step: 11
Training loss: 2.4507866666938867
Validation loss: 2.5084491408873872

Epoch: 69| Step: 0
Training loss: 2.4788950816761592
Validation loss: 2.4297002524218088

Epoch: 5| Step: 1
Training loss: 1.8004118898459749
Validation loss: 2.468451735429757

Epoch: 5| Step: 2
Training loss: 2.375681026593934
Validation loss: 2.4863594814339995

Epoch: 5| Step: 3
Training loss: 2.02622387482676
Validation loss: 2.478362294878494

Epoch: 5| Step: 4
Training loss: 2.821661122138819
Validation loss: 2.51031877529975

Epoch: 5| Step: 5
Training loss: 2.5157570182325593
Validation loss: 2.4826794562474728

Epoch: 5| Step: 6
Training loss: 2.488567725058852
Validation loss: 2.4823158655709285

Epoch: 5| Step: 7
Training loss: 2.3725871830026577
Validation loss: 2.5075841742307694

Epoch: 5| Step: 8
Training loss: 2.225452239978274
Validation loss: 2.4881663193602055

Epoch: 5| Step: 9
Training loss: 3.0509003482874797
Validation loss: 2.4567903522888432

Epoch: 5| Step: 10
Training loss: 1.575990801198613
Validation loss: 2.4594444569656235

Epoch: 5| Step: 11
Training loss: 2.111173075329875
Validation loss: 2.468652103591614

Epoch: 70| Step: 0
Training loss: 2.3959715651288023
Validation loss: 2.470694492410448

Epoch: 5| Step: 1
Training loss: 1.9734753409508168
Validation loss: 2.4974373716865093

Epoch: 5| Step: 2
Training loss: 1.531784120165043
Validation loss: 2.4781319291417603

Epoch: 5| Step: 3
Training loss: 1.9647191275479017
Validation loss: 2.5159794536000795

Epoch: 5| Step: 4
Training loss: 2.6028627920725036
Validation loss: 2.4687404551905

Epoch: 5| Step: 5
Training loss: 2.366244590982823
Validation loss: 2.4823215003121097

Epoch: 5| Step: 6
Training loss: 2.0795817611261396
Validation loss: 2.459764651202968

Epoch: 5| Step: 7
Training loss: 2.456859103481091
Validation loss: 2.493289588231681

Epoch: 5| Step: 8
Training loss: 2.4974934410031997
Validation loss: 2.5187702537839254

Epoch: 5| Step: 9
Training loss: 2.585167162155403
Validation loss: 2.511708553722642

Epoch: 5| Step: 10
Training loss: 2.55291845450368
Validation loss: 2.534096232211803

Epoch: 5| Step: 11
Training loss: 2.456685198019968
Validation loss: 2.4841844057752684

Epoch: 71| Step: 0
Training loss: 1.946535453761594
Validation loss: 2.5105835805041448

Epoch: 5| Step: 1
Training loss: 2.884635534949715
Validation loss: 2.4671240252623527

Epoch: 5| Step: 2
Training loss: 2.1026966764106234
Validation loss: 2.5016059207741788

Epoch: 5| Step: 3
Training loss: 2.2500530872440008
Validation loss: 2.4676491701423124

Epoch: 5| Step: 4
Training loss: 2.487990908848384
Validation loss: 2.464388838118121

Epoch: 5| Step: 5
Training loss: 2.4005187507124313
Validation loss: 2.4351929909972903

Epoch: 5| Step: 6
Training loss: 2.319473371750476
Validation loss: 2.437863469534168

Epoch: 5| Step: 7
Training loss: 2.2163732989459968
Validation loss: 2.4435502426769293

Epoch: 5| Step: 8
Training loss: 2.3699484860579996
Validation loss: 2.480885332024107

Epoch: 5| Step: 9
Training loss: 1.644493048217406
Validation loss: 2.4634060341809767

Epoch: 5| Step: 10
Training loss: 2.8100822228996765
Validation loss: 2.431324005961886

Epoch: 5| Step: 11
Training loss: 1.5570027350203859
Validation loss: 2.4809674179759655

Epoch: 72| Step: 0
Training loss: 2.641712122946261
Validation loss: 2.437667791998101

Epoch: 5| Step: 1
Training loss: 1.8946745198928434
Validation loss: 2.477414655437622

Epoch: 5| Step: 2
Training loss: 2.682000232653853
Validation loss: 2.4794265720359023

Epoch: 5| Step: 3
Training loss: 1.8561210048051178
Validation loss: 2.474459016563053

Epoch: 5| Step: 4
Training loss: 2.380241332600986
Validation loss: 2.5345984395312957

Epoch: 5| Step: 5
Training loss: 2.110858423882343
Validation loss: 2.4688203737232133

Epoch: 5| Step: 6
Training loss: 2.020000941776774
Validation loss: 2.5252228986285803

Epoch: 5| Step: 7
Training loss: 2.51869904724532
Validation loss: 2.5626323324629863

Epoch: 5| Step: 8
Training loss: 2.6343942299861602
Validation loss: 2.5308031857323323

Epoch: 5| Step: 9
Training loss: 1.673697289569176
Validation loss: 2.5377839610751365

Epoch: 5| Step: 10
Training loss: 2.8416438425290393
Validation loss: 2.5157983495089584

Epoch: 5| Step: 11
Training loss: 1.0339809439284782
Validation loss: 2.479026992186439

Epoch: 73| Step: 0
Training loss: 2.710533177898767
Validation loss: 2.5251274512641166

Epoch: 5| Step: 1
Training loss: 2.374831745813343
Validation loss: 2.5088122663641235

Epoch: 5| Step: 2
Training loss: 1.5644487054693348
Validation loss: 2.4916497849261448

Epoch: 5| Step: 3
Training loss: 1.8621762115858467
Validation loss: 2.496852504722786

Epoch: 5| Step: 4
Training loss: 2.2111381736240876
Validation loss: 2.4915648612357253

Epoch: 5| Step: 5
Training loss: 2.254330177041318
Validation loss: 2.4802264037602813

Epoch: 5| Step: 6
Training loss: 2.414211231575751
Validation loss: 2.513304157130948

Epoch: 5| Step: 7
Training loss: 2.2437947855865605
Validation loss: 2.4872010669609033

Epoch: 5| Step: 8
Training loss: 2.4858603205949246
Validation loss: 2.5150033210279963

Epoch: 5| Step: 9
Training loss: 1.959922071678829
Validation loss: 2.487802819808708

Epoch: 5| Step: 10
Training loss: 2.550252535413849
Validation loss: 2.4706283738962225

Epoch: 5| Step: 11
Training loss: 1.9399729912637664
Validation loss: 2.456803659512672

Epoch: 74| Step: 0
Training loss: 2.0325979601912025
Validation loss: 2.456285319992447

Epoch: 5| Step: 1
Training loss: 2.193155661385192
Validation loss: 2.499114628815334

Epoch: 5| Step: 2
Training loss: 2.080995914196749
Validation loss: 2.4755636039895212

Epoch: 5| Step: 3
Training loss: 2.448157559709813
Validation loss: 2.4538481106206826

Epoch: 5| Step: 4
Training loss: 2.164676179874163
Validation loss: 2.471572903813676

Epoch: 5| Step: 5
Training loss: 2.2052707908938154
Validation loss: 2.501064697682827

Epoch: 5| Step: 6
Training loss: 1.9301904185150476
Validation loss: 2.4600414017130623

Epoch: 5| Step: 7
Training loss: 2.590783502494818
Validation loss: 2.4815421317612536

Epoch: 5| Step: 8
Training loss: 2.410077506437528
Validation loss: 2.460490504041664

Epoch: 5| Step: 9
Training loss: 2.6507252402533927
Validation loss: 2.485659700988665

Epoch: 5| Step: 10
Training loss: 2.369134687524763
Validation loss: 2.4421363084878203

Epoch: 5| Step: 11
Training loss: 2.4480418612883974
Validation loss: 2.4690142864294473

Epoch: 75| Step: 0
Training loss: 2.3106535679746214
Validation loss: 2.490487997067358

Epoch: 5| Step: 1
Training loss: 2.305221650891994
Validation loss: 2.4835506087071435

Epoch: 5| Step: 2
Training loss: 1.8531870093432317
Validation loss: 2.5061754962378053

Epoch: 5| Step: 3
Training loss: 2.781137528449184
Validation loss: 2.5611499664881068

Epoch: 5| Step: 4
Training loss: 2.257061579346347
Validation loss: 2.531276726287278

Epoch: 5| Step: 5
Training loss: 2.4642939853726857
Validation loss: 2.559658085418048

Epoch: 5| Step: 6
Training loss: 2.1305611713815633
Validation loss: 2.5582628691368323

Epoch: 5| Step: 7
Training loss: 2.228746808403327
Validation loss: 2.543729298231661

Epoch: 5| Step: 8
Training loss: 2.7536765577693307
Validation loss: 2.530375741755083

Epoch: 5| Step: 9
Training loss: 1.9115944033497512
Validation loss: 2.5469098000986534

Epoch: 5| Step: 10
Training loss: 2.178481339103968
Validation loss: 2.531978773063493

Epoch: 5| Step: 11
Training loss: 1.3900335961679657
Validation loss: 2.4760914744715747

Epoch: 76| Step: 0
Training loss: 2.0120515122237297
Validation loss: 2.4589615291294695

Epoch: 5| Step: 1
Training loss: 2.090514002477779
Validation loss: 2.457212626398972

Epoch: 5| Step: 2
Training loss: 1.9882775926837373
Validation loss: 2.4649508574399435

Epoch: 5| Step: 3
Training loss: 2.424061827724059
Validation loss: 2.4581832388677616

Epoch: 5| Step: 4
Training loss: 2.442663348230387
Validation loss: 2.4514532365959663

Epoch: 5| Step: 5
Training loss: 2.490819764987835
Validation loss: 2.530588071325522

Epoch: 5| Step: 6
Training loss: 2.5177485820397716
Validation loss: 2.478800130777395

Epoch: 5| Step: 7
Training loss: 2.668163376239755
Validation loss: 2.4411871300594035

Epoch: 5| Step: 8
Training loss: 2.0090871839123943
Validation loss: 2.4549106205922633

Epoch: 5| Step: 9
Training loss: 2.5005151217956296
Validation loss: 2.4648488624547946

Epoch: 5| Step: 10
Training loss: 1.9464222144226817
Validation loss: 2.4342720919181167

Epoch: 5| Step: 11
Training loss: 1.1030493367211767
Validation loss: 2.4754162972918765

Epoch: 77| Step: 0
Training loss: 2.049318674889291
Validation loss: 2.462498043917994

Epoch: 5| Step: 1
Training loss: 2.061361865818762
Validation loss: 2.4632962099881923

Epoch: 5| Step: 2
Training loss: 1.8400563888616766
Validation loss: 2.482140858068834

Epoch: 5| Step: 3
Training loss: 2.3304167866708236
Validation loss: 2.5280444683676233

Epoch: 5| Step: 4
Training loss: 2.343639727223557
Validation loss: 2.483131901414346

Epoch: 5| Step: 5
Training loss: 2.352556493812548
Validation loss: 2.550600700745623

Epoch: 5| Step: 6
Training loss: 2.4289791141647017
Validation loss: 2.543931199789409

Epoch: 5| Step: 7
Training loss: 2.538705090529841
Validation loss: 2.6008414643011952

Epoch: 5| Step: 8
Training loss: 2.659022600827497
Validation loss: 2.6040271391047662

Epoch: 5| Step: 9
Training loss: 1.8925885179547264
Validation loss: 2.569933415974694

Epoch: 5| Step: 10
Training loss: 2.445993931797888
Validation loss: 2.562789501336156

Epoch: 5| Step: 11
Training loss: 2.2232850698735436
Validation loss: 2.4977255448779716

Epoch: 78| Step: 0
Training loss: 1.9945128389577882
Validation loss: 2.4858018028871793

Epoch: 5| Step: 1
Training loss: 2.1185579826193606
Validation loss: 2.4199330655737983

Epoch: 5| Step: 2
Training loss: 2.938145505715527
Validation loss: 2.4530253420468178

Epoch: 5| Step: 3
Training loss: 2.435397194772831
Validation loss: 2.46348396432627

Epoch: 5| Step: 4
Training loss: 2.8846482632059307
Validation loss: 2.4554396823121785

Epoch: 5| Step: 5
Training loss: 2.035478855563907
Validation loss: 2.491875532309835

Epoch: 5| Step: 6
Training loss: 2.1236744280431648
Validation loss: 2.4852344377920277

Epoch: 5| Step: 7
Training loss: 2.000612403570179
Validation loss: 2.5037377271511723

Epoch: 5| Step: 8
Training loss: 1.9913158828746367
Validation loss: 2.45354325683271

Epoch: 5| Step: 9
Training loss: 2.372527692852252
Validation loss: 2.5058523818741323

Epoch: 5| Step: 10
Training loss: 2.0393606384501166
Validation loss: 2.4279847429009296

Epoch: 5| Step: 11
Training loss: 2.4066663109452398
Validation loss: 2.4703120508903336

Epoch: 79| Step: 0
Training loss: 2.2653600077384266
Validation loss: 2.4813728707268385

Epoch: 5| Step: 1
Training loss: 2.084661657933455
Validation loss: 2.476986986077323

Epoch: 5| Step: 2
Training loss: 2.719113818851536
Validation loss: 2.4899879443337674

Epoch: 5| Step: 3
Training loss: 1.7006978930546577
Validation loss: 2.473521779677435

Epoch: 5| Step: 4
Training loss: 1.9658531796417225
Validation loss: 2.5504728503728766

Epoch: 5| Step: 5
Training loss: 2.2898849728276174
Validation loss: 2.5484111693312483

Epoch: 5| Step: 6
Training loss: 1.9525516736645097
Validation loss: 2.4956392920206087

Epoch: 5| Step: 7
Training loss: 1.9575091176411397
Validation loss: 2.54119093669174

Epoch: 5| Step: 8
Training loss: 1.9885346676473672
Validation loss: 2.487343384334757

Epoch: 5| Step: 9
Training loss: 2.4963477159227487
Validation loss: 2.5161508480509776

Epoch: 5| Step: 10
Training loss: 2.8000018153865924
Validation loss: 2.5276308206195313

Epoch: 5| Step: 11
Training loss: 2.617084284782591
Validation loss: 2.5261499925700575

Epoch: 80| Step: 0
Training loss: 2.0845753083070466
Validation loss: 2.5173373860669885

Epoch: 5| Step: 1
Training loss: 2.1775178125925203
Validation loss: 2.5262963366517672

Epoch: 5| Step: 2
Training loss: 2.413899931634252
Validation loss: 2.513565073063731

Epoch: 5| Step: 3
Training loss: 1.7605142810852257
Validation loss: 2.512306207961218

Epoch: 5| Step: 4
Training loss: 2.2201560494847477
Validation loss: 2.491840904473956

Epoch: 5| Step: 5
Training loss: 2.3594980776181385
Validation loss: 2.4266056210071536

Epoch: 5| Step: 6
Training loss: 2.246553642625868
Validation loss: 2.5211636757686535

Epoch: 5| Step: 7
Training loss: 1.5231676694131568
Validation loss: 2.4888738927526597

Epoch: 5| Step: 8
Training loss: 2.158414114050391
Validation loss: 2.4276374783235903

Epoch: 5| Step: 9
Training loss: 2.731315514239242
Validation loss: 2.435438009407325

Epoch: 5| Step: 10
Training loss: 2.6594235479672865
Validation loss: 2.4862183104359548

Epoch: 5| Step: 11
Training loss: 2.055852523464678
Validation loss: 2.480825215355103

Epoch: 81| Step: 0
Training loss: 2.8118332814354217
Validation loss: 2.4767932964809645

Epoch: 5| Step: 1
Training loss: 2.0732312626669884
Validation loss: 2.4720074333212385

Epoch: 5| Step: 2
Training loss: 2.65711099470756
Validation loss: 2.516432938448529

Epoch: 5| Step: 3
Training loss: 1.5305643687578157
Validation loss: 2.5231159977771602

Epoch: 5| Step: 4
Training loss: 2.156485392672488
Validation loss: 2.513104044404629

Epoch: 5| Step: 5
Training loss: 2.1031154864749304
Validation loss: 2.509626847325388

Epoch: 5| Step: 6
Training loss: 2.0117865393614838
Validation loss: 2.5465747718704153

Epoch: 5| Step: 7
Training loss: 2.420747654548225
Validation loss: 2.5009146487451903

Epoch: 5| Step: 8
Training loss: 2.10268533767477
Validation loss: 2.4999964356397015

Epoch: 5| Step: 9
Training loss: 1.8623959659477014
Validation loss: 2.4875298228305187

Epoch: 5| Step: 10
Training loss: 2.194322030023796
Validation loss: 2.4900178802727884

Epoch: 5| Step: 11
Training loss: 2.8961034049651917
Validation loss: 2.4705402707593875

Epoch: 82| Step: 0
Training loss: 2.020278408768947
Validation loss: 2.4854275255267138

Epoch: 5| Step: 1
Training loss: 2.126919496548895
Validation loss: 2.475445921861514

Epoch: 5| Step: 2
Training loss: 2.0344293215013813
Validation loss: 2.4824699199118014

Epoch: 5| Step: 3
Training loss: 2.0917040949457903
Validation loss: 2.4487506636157326

Epoch: 5| Step: 4
Training loss: 2.0120382407101705
Validation loss: 2.4926965327182153

Epoch: 5| Step: 5
Training loss: 2.068164214669994
Validation loss: 2.477733523734392

Epoch: 5| Step: 6
Training loss: 2.8315053727807804
Validation loss: 2.488337282101853

Epoch: 5| Step: 7
Training loss: 2.919497578390757
Validation loss: 2.4535533385285158

Epoch: 5| Step: 8
Training loss: 2.595434170603359
Validation loss: 2.4400797177409315

Epoch: 5| Step: 9
Training loss: 1.7872781309068875
Validation loss: 2.468754518883026

Epoch: 5| Step: 10
Training loss: 1.7176478233189691
Validation loss: 2.4424517902821186

Epoch: 5| Step: 11
Training loss: 1.6367163464658292
Validation loss: 2.487430780492412

Epoch: 83| Step: 0
Training loss: 1.8706327439851103
Validation loss: 2.5104629280186015

Epoch: 5| Step: 1
Training loss: 1.6262554307593315
Validation loss: 2.4796562365920956

Epoch: 5| Step: 2
Training loss: 3.114818313223044
Validation loss: 2.477772125480983

Epoch: 5| Step: 3
Training loss: 1.61193155722702
Validation loss: 2.5408081470399324

Epoch: 5| Step: 4
Training loss: 1.3878578343209844
Validation loss: 2.506752509113493

Epoch: 5| Step: 5
Training loss: 2.4634905454292766
Validation loss: 2.532112351448424

Epoch: 5| Step: 6
Training loss: 2.6285887210437076
Validation loss: 2.5413926881072006

Epoch: 5| Step: 7
Training loss: 2.4718671989076686
Validation loss: 2.5039723150035016

Epoch: 5| Step: 8
Training loss: 2.332713476226862
Validation loss: 2.516648573973548

Epoch: 5| Step: 9
Training loss: 2.325859862444736
Validation loss: 2.522948242250311

Epoch: 5| Step: 10
Training loss: 1.5303659027734053
Validation loss: 2.4946570721809116

Epoch: 5| Step: 11
Training loss: 2.3686067965659223
Validation loss: 2.4743825060293845

Epoch: 84| Step: 0
Training loss: 2.0008370316850046
Validation loss: 2.422551173498654

Epoch: 5| Step: 1
Training loss: 1.6851083266757172
Validation loss: 2.4914016102360557

Epoch: 5| Step: 2
Training loss: 2.1406638705768857
Validation loss: 2.480000827738537

Epoch: 5| Step: 3
Training loss: 2.9257256740695405
Validation loss: 2.4725680945713457

Epoch: 5| Step: 4
Training loss: 1.840218151574071
Validation loss: 2.455890291550402

Epoch: 5| Step: 5
Training loss: 1.8357932176101661
Validation loss: 2.475405317410098

Epoch: 5| Step: 6
Training loss: 2.2827705645772833
Validation loss: 2.459677249410675

Epoch: 5| Step: 7
Training loss: 1.8926202633539393
Validation loss: 2.4954680293817435

Epoch: 5| Step: 8
Training loss: 2.5543056750988207
Validation loss: 2.5010586801691956

Epoch: 5| Step: 9
Training loss: 2.1824668747178553
Validation loss: 2.485023509860363

Epoch: 5| Step: 10
Training loss: 2.510096950406389
Validation loss: 2.5128884051650298

Epoch: 5| Step: 11
Training loss: 1.793449387299086
Validation loss: 2.49998950558685

Epoch: 85| Step: 0
Training loss: 2.3672372542084585
Validation loss: 2.4893845049151233

Epoch: 5| Step: 1
Training loss: 2.19390128719849
Validation loss: 2.4836556934792986

Epoch: 5| Step: 2
Training loss: 2.0081480465755837
Validation loss: 2.45045217863116

Epoch: 5| Step: 3
Training loss: 2.4700249385733075
Validation loss: 2.436286846490306

Epoch: 5| Step: 4
Training loss: 2.37892088235699
Validation loss: 2.480943509221242

Epoch: 5| Step: 5
Training loss: 2.202292643559983
Validation loss: 2.4834172664023044

Epoch: 5| Step: 6
Training loss: 2.1730647498998
Validation loss: 2.517073172986744

Epoch: 5| Step: 7
Training loss: 1.9890678963059838
Validation loss: 2.490189184638984

Epoch: 5| Step: 8
Training loss: 2.137302688504274
Validation loss: 2.520460768562008

Epoch: 5| Step: 9
Training loss: 1.4028596062079481
Validation loss: 2.4684040817121597

Epoch: 5| Step: 10
Training loss: 2.113767670163335
Validation loss: 2.4544805478749665

Epoch: 5| Step: 11
Training loss: 3.4236086281609874
Validation loss: 2.5036549593338093

Epoch: 86| Step: 0
Training loss: 2.4271746333117528
Validation loss: 2.46445775221316

Epoch: 5| Step: 1
Training loss: 2.542997251664393
Validation loss: 2.4563395704676916

Epoch: 5| Step: 2
Training loss: 2.0845645572422424
Validation loss: 2.5104064182742385

Epoch: 5| Step: 3
Training loss: 1.9943548642262465
Validation loss: 2.45857101977823

Epoch: 5| Step: 4
Training loss: 2.188999969656688
Validation loss: 2.5287053225296736

Epoch: 5| Step: 5
Training loss: 2.0253941564427986
Validation loss: 2.484681212549575

Epoch: 5| Step: 6
Training loss: 1.9631870937880742
Validation loss: 2.4931891251193488

Epoch: 5| Step: 7
Training loss: 2.0551263028798434
Validation loss: 2.4961466338396443

Epoch: 5| Step: 8
Training loss: 2.2930417414782536
Validation loss: 2.4800259773178253

Epoch: 5| Step: 9
Training loss: 2.1344462973441938
Validation loss: 2.4633516731685017

Epoch: 5| Step: 10
Training loss: 2.7139617145736206
Validation loss: 2.479596598929491

Epoch: 5| Step: 11
Training loss: 1.914107902144081
Validation loss: 2.5062528813156093

Epoch: 87| Step: 0
Training loss: 2.160757467475689
Validation loss: 2.498840194131538

Epoch: 5| Step: 1
Training loss: 1.832961962395229
Validation loss: 2.528755340143116

Epoch: 5| Step: 2
Training loss: 2.1709766313796615
Validation loss: 2.6253352253926274

Epoch: 5| Step: 3
Training loss: 1.6825589498137616
Validation loss: 2.626110962000497

Epoch: 5| Step: 4
Training loss: 2.345117805628927
Validation loss: 2.7084155119141347

Epoch: 5| Step: 5
Training loss: 2.1496748256961307
Validation loss: 2.706566231673679

Epoch: 5| Step: 6
Training loss: 2.707650954528452
Validation loss: 2.774080991641465

Epoch: 5| Step: 7
Training loss: 2.057958284049791
Validation loss: 2.713217103893505

Epoch: 5| Step: 8
Training loss: 2.6300905912628774
Validation loss: 2.6296555659016754

Epoch: 5| Step: 9
Training loss: 1.77647999326143
Validation loss: 2.5784629099411434

Epoch: 5| Step: 10
Training loss: 2.7330875526582763
Validation loss: 2.521840994919589

Epoch: 5| Step: 11
Training loss: 1.9892920302461758
Validation loss: 2.4361644411599044

Epoch: 88| Step: 0
Training loss: 2.147302612185991
Validation loss: 2.468224083135269

Epoch: 5| Step: 1
Training loss: 1.7548207912619427
Validation loss: 2.479582849131901

Epoch: 5| Step: 2
Training loss: 2.188878415282226
Validation loss: 2.4582006504869374

Epoch: 5| Step: 3
Training loss: 2.0915581916959636
Validation loss: 2.5341833880231492

Epoch: 5| Step: 4
Training loss: 2.418960392596565
Validation loss: 2.5109821780078834

Epoch: 5| Step: 5
Training loss: 2.1196213137497915
Validation loss: 2.5153913152448326

Epoch: 5| Step: 6
Training loss: 2.410314718567163
Validation loss: 2.520937934523315

Epoch: 5| Step: 7
Training loss: 2.3268760044650056
Validation loss: 2.472939435382161

Epoch: 5| Step: 8
Training loss: 2.313995187258187
Validation loss: 2.4426522353562334

Epoch: 5| Step: 9
Training loss: 2.705899705306803
Validation loss: 2.4727501673085306

Epoch: 5| Step: 10
Training loss: 2.2082108037772246
Validation loss: 2.4730134859604327

Epoch: 5| Step: 11
Training loss: 0.9126204176054805
Validation loss: 2.456880792277633

Epoch: 89| Step: 0
Training loss: 1.7569134935242023
Validation loss: 2.50129103703652

Epoch: 5| Step: 1
Training loss: 2.7941181085426727
Validation loss: 2.49315018829936

Epoch: 5| Step: 2
Training loss: 1.4426839484438911
Validation loss: 2.542531485204755

Epoch: 5| Step: 3
Training loss: 2.0985802119760426
Validation loss: 2.5061532728059217

Epoch: 5| Step: 4
Training loss: 2.511124180119282
Validation loss: 2.4965722148326006

Epoch: 5| Step: 5
Training loss: 1.5791650498649488
Validation loss: 2.5561315827739555

Epoch: 5| Step: 6
Training loss: 2.2050489317293622
Validation loss: 2.5205170627420803

Epoch: 5| Step: 7
Training loss: 2.063181215552926
Validation loss: 2.455179269548763

Epoch: 5| Step: 8
Training loss: 2.057484742452197
Validation loss: 2.487061884970733

Epoch: 5| Step: 9
Training loss: 2.4453498423104705
Validation loss: 2.530451106934197

Epoch: 5| Step: 10
Training loss: 2.3968505579611104
Validation loss: 2.5047085250889025

Epoch: 5| Step: 11
Training loss: 1.353843792301816
Validation loss: 2.4949267768244314

Epoch: 90| Step: 0
Training loss: 1.9274284328726254
Validation loss: 2.555434550366805

Epoch: 5| Step: 1
Training loss: 1.9761391288063541
Validation loss: 2.5105944104935114

Epoch: 5| Step: 2
Training loss: 2.8354804561333617
Validation loss: 2.512663920987637

Epoch: 5| Step: 3
Training loss: 2.0816973048028
Validation loss: 2.484104977534601

Epoch: 5| Step: 4
Training loss: 1.6496325314861422
Validation loss: 2.552723011632688

Epoch: 5| Step: 5
Training loss: 1.7449136795729372
Validation loss: 2.5105721173625692

Epoch: 5| Step: 6
Training loss: 1.924201053936056
Validation loss: 2.4853974243809063

Epoch: 5| Step: 7
Training loss: 1.8511311475270595
Validation loss: 2.459516508594905

Epoch: 5| Step: 8
Training loss: 2.2042132997056716
Validation loss: 2.4647619371897354

Epoch: 5| Step: 9
Training loss: 2.245160514343787
Validation loss: 2.4832254625313586

Epoch: 5| Step: 10
Training loss: 2.362109286177545
Validation loss: 2.4890907164668756

Epoch: 5| Step: 11
Training loss: 3.8379348558201887
Validation loss: 2.508099924731043

Epoch: 91| Step: 0
Training loss: 1.8872571220511174
Validation loss: 2.4647256749361817

Epoch: 5| Step: 1
Training loss: 2.0881703745146103
Validation loss: 2.4866242013962365

Epoch: 5| Step: 2
Training loss: 2.0411821945337802
Validation loss: 2.538917944289974

Epoch: 5| Step: 3
Training loss: 2.787209287802707
Validation loss: 2.4520796109487

Epoch: 5| Step: 4
Training loss: 2.091730082894315
Validation loss: 2.4845290106294335

Epoch: 5| Step: 5
Training loss: 1.999816111217097
Validation loss: 2.473186775491926

Epoch: 5| Step: 6
Training loss: 1.7848978001591407
Validation loss: 2.4620970360807197

Epoch: 5| Step: 7
Training loss: 2.25750054444975
Validation loss: 2.4434843694609647

Epoch: 5| Step: 8
Training loss: 1.8765909438951336
Validation loss: 2.4727392679895055

Epoch: 5| Step: 9
Training loss: 2.1457380502033168
Validation loss: 2.4952891709191234

Epoch: 5| Step: 10
Training loss: 2.4473803859390153
Validation loss: 2.467111856864461

Epoch: 5| Step: 11
Training loss: 2.0011380057416535
Validation loss: 2.517379149156744

Epoch: 92| Step: 0
Training loss: 2.132715243962169
Validation loss: 2.5179778877397863

Epoch: 5| Step: 1
Training loss: 1.8933109718779746
Validation loss: 2.516752598465952

Epoch: 5| Step: 2
Training loss: 2.364626868655245
Validation loss: 2.5504819023511285

Epoch: 5| Step: 3
Training loss: 1.8003080660727828
Validation loss: 2.5147460800028094

Epoch: 5| Step: 4
Training loss: 2.5858399525478895
Validation loss: 2.554628225682975

Epoch: 5| Step: 5
Training loss: 2.619665356442008
Validation loss: 2.562286651072525

Epoch: 5| Step: 6
Training loss: 2.325433186199725
Validation loss: 2.543892961525983

Epoch: 5| Step: 7
Training loss: 1.9018299576073008
Validation loss: 2.5499846697951116

Epoch: 5| Step: 8
Training loss: 1.966389163961887
Validation loss: 2.510884741256762

Epoch: 5| Step: 9
Training loss: 2.2598691239060367
Validation loss: 2.4820282806900638

Epoch: 5| Step: 10
Training loss: 1.7065227807505832
Validation loss: 2.490921085392756

Epoch: 5| Step: 11
Training loss: 1.369360542865246
Validation loss: 2.5098233227461657

Epoch: 93| Step: 0
Training loss: 2.660314165937327
Validation loss: 2.5315287322748823

Epoch: 5| Step: 1
Training loss: 2.008914986216311
Validation loss: 2.486079137360911

Epoch: 5| Step: 2
Training loss: 1.9544202858240975
Validation loss: 2.4616465964841097

Epoch: 5| Step: 3
Training loss: 2.3277940962995087
Validation loss: 2.455653913901669

Epoch: 5| Step: 4
Training loss: 1.6303214459487312
Validation loss: 2.4789901291210996

Epoch: 5| Step: 5
Training loss: 2.1871447683455743
Validation loss: 2.4698953707860296

Epoch: 5| Step: 6
Training loss: 2.0414988260632496
Validation loss: 2.497964121442277

Epoch: 5| Step: 7
Training loss: 2.110534801233279
Validation loss: 2.5136121314476885

Epoch: 5| Step: 8
Training loss: 1.5991839354303115
Validation loss: 2.5354283543873457

Epoch: 5| Step: 9
Training loss: 2.524768017980404
Validation loss: 2.4969347480751822

Epoch: 5| Step: 10
Training loss: 2.1058301739303547
Validation loss: 2.47283721550881

Epoch: 5| Step: 11
Training loss: 1.225490076943934
Validation loss: 2.4821492107162366

Epoch: 94| Step: 0
Training loss: 2.0945355663945175
Validation loss: 2.523558524175275

Epoch: 5| Step: 1
Training loss: 2.473838390989821
Validation loss: 2.4748844956248393

Epoch: 5| Step: 2
Training loss: 2.164595114927076
Validation loss: 2.5197372707147982

Epoch: 5| Step: 3
Training loss: 2.465484197389163
Validation loss: 2.5449115970586518

Epoch: 5| Step: 4
Training loss: 1.4501457437077745
Validation loss: 2.5104625679241206

Epoch: 5| Step: 5
Training loss: 1.958116850825355
Validation loss: 2.516954844493219

Epoch: 5| Step: 6
Training loss: 2.209887467535653
Validation loss: 2.4889453658428184

Epoch: 5| Step: 7
Training loss: 1.6712074729741395
Validation loss: 2.4822964200128936

Epoch: 5| Step: 8
Training loss: 2.1008999712598175
Validation loss: 2.5068720463390033

Epoch: 5| Step: 9
Training loss: 2.0302694448163
Validation loss: 2.5117773481289882

Epoch: 5| Step: 10
Training loss: 2.3930004011919808
Validation loss: 2.488900778721706

Epoch: 5| Step: 11
Training loss: 1.6149782579688676
Validation loss: 2.4733935116270036

Epoch: 95| Step: 0
Training loss: 1.5781564992650396
Validation loss: 2.4427539005109806

Epoch: 5| Step: 1
Training loss: 1.622324795542889
Validation loss: 2.482501429121689

Epoch: 5| Step: 2
Training loss: 1.9838884012345193
Validation loss: 2.498583447947195

Epoch: 5| Step: 3
Training loss: 2.475033260854081
Validation loss: 2.5095103370272205

Epoch: 5| Step: 4
Training loss: 2.3408934415073634
Validation loss: 2.533188136754221

Epoch: 5| Step: 5
Training loss: 1.7976107873850151
Validation loss: 2.470579065316766

Epoch: 5| Step: 6
Training loss: 2.3964861657618615
Validation loss: 2.483574816357734

Epoch: 5| Step: 7
Training loss: 2.281788697064331
Validation loss: 2.45143520769541

Epoch: 5| Step: 8
Training loss: 2.257701725865774
Validation loss: 2.526130597361445

Epoch: 5| Step: 9
Training loss: 2.2076754279757895
Validation loss: 2.4796894721680562

Epoch: 5| Step: 10
Training loss: 1.7434757413497466
Validation loss: 2.5087187289303934

Epoch: 5| Step: 11
Training loss: 1.1902417104136345
Validation loss: 2.472327459089148

Epoch: 96| Step: 0
Training loss: 2.0107041253910287
Validation loss: 2.4784583607925526

Epoch: 5| Step: 1
Training loss: 1.7827662656708299
Validation loss: 2.5063405257608586

Epoch: 5| Step: 2
Training loss: 2.339370705195242
Validation loss: 2.5257955267365335

Epoch: 5| Step: 3
Training loss: 1.8266337906995254
Validation loss: 2.5237781109755026

Epoch: 5| Step: 4
Training loss: 2.305788662882971
Validation loss: 2.5356745530507268

Epoch: 5| Step: 5
Training loss: 1.9752260296082553
Validation loss: 2.5224153753565073

Epoch: 5| Step: 6
Training loss: 1.8930223886382058
Validation loss: 2.5014208848664805

Epoch: 5| Step: 7
Training loss: 1.8385558591588438
Validation loss: 2.5010418707738813

Epoch: 5| Step: 8
Training loss: 2.0638226978383565
Validation loss: 2.4829011539982453

Epoch: 5| Step: 9
Training loss: 2.4814237903680993
Validation loss: 2.5262375326350743

Epoch: 5| Step: 10
Training loss: 2.2603653463933715
Validation loss: 2.506076179970964

Epoch: 5| Step: 11
Training loss: 0.9566446574489456
Validation loss: 2.5107687997316424

Epoch: 97| Step: 0
Training loss: 2.1496100537844764
Validation loss: 2.5173026191376136

Epoch: 5| Step: 1
Training loss: 2.2295161415982108
Validation loss: 2.571300668348562

Epoch: 5| Step: 2
Training loss: 1.555883589663163
Validation loss: 2.5565695950690563

Epoch: 5| Step: 3
Training loss: 2.2900599887436743
Validation loss: 2.5444324068574122

Epoch: 5| Step: 4
Training loss: 2.1598189299241253
Validation loss: 2.6091611549938967

Epoch: 5| Step: 5
Training loss: 1.8638290143933292
Validation loss: 2.5667601853730826

Epoch: 5| Step: 6
Training loss: 2.381466945267426
Validation loss: 2.5950481735687485

Epoch: 5| Step: 7
Training loss: 1.580486230758261
Validation loss: 2.5779453099370846

Epoch: 5| Step: 8
Training loss: 2.2923722539188764
Validation loss: 2.551706852034813

Epoch: 5| Step: 9
Training loss: 1.9785444251898796
Validation loss: 2.4925248367184274

Epoch: 5| Step: 10
Training loss: 1.4101581520638358
Validation loss: 2.5066826118011134

Epoch: 5| Step: 11
Training loss: 3.7063433990803847
Validation loss: 2.4931102347922924

Epoch: 98| Step: 0
Training loss: 2.1450512642947808
Validation loss: 2.512866729333335

Epoch: 5| Step: 1
Training loss: 2.1911064935708198
Validation loss: 2.4843343815392065

Epoch: 5| Step: 2
Training loss: 2.294325678873805
Validation loss: 2.523175234791807

Epoch: 5| Step: 3
Training loss: 2.6232974571124092
Validation loss: 2.4889012656679923

Epoch: 5| Step: 4
Training loss: 1.7635604806321943
Validation loss: 2.489438528906703

Epoch: 5| Step: 5
Training loss: 1.8582911177260695
Validation loss: 2.458768395272816

Epoch: 5| Step: 6
Training loss: 2.1156127253166463
Validation loss: 2.485448493391352

Epoch: 5| Step: 7
Training loss: 1.808084107143257
Validation loss: 2.511542085136882

Epoch: 5| Step: 8
Training loss: 2.3356067844381836
Validation loss: 2.487592381210803

Epoch: 5| Step: 9
Training loss: 1.8566096281790483
Validation loss: 2.551023420178004

Epoch: 5| Step: 10
Training loss: 1.3595869841757011
Validation loss: 2.4535728499337752

Epoch: 5| Step: 11
Training loss: 1.8586300551727817
Validation loss: 2.503541557823302

Epoch: 99| Step: 0
Training loss: 2.3274175605965706
Validation loss: 2.451667308005537

Epoch: 5| Step: 1
Training loss: 1.4118471020783063
Validation loss: 2.575236337889729

Epoch: 5| Step: 2
Training loss: 2.217366499123852
Validation loss: 2.580527852377022

Epoch: 5| Step: 3
Training loss: 2.0907474453454453
Validation loss: 2.5947875356826353

Epoch: 5| Step: 4
Training loss: 2.120208611750865
Validation loss: 2.5374750623119655

Epoch: 5| Step: 5
Training loss: 2.1858597191475924
Validation loss: 2.5405721040343803

Epoch: 5| Step: 6
Training loss: 1.7238352367635634
Validation loss: 2.5557043285936683

Epoch: 5| Step: 7
Training loss: 1.8858687419098517
Validation loss: 2.5124074763885185

Epoch: 5| Step: 8
Training loss: 1.656564862534386
Validation loss: 2.5527370679549763

Epoch: 5| Step: 9
Training loss: 2.580114071268566
Validation loss: 2.531411334575156

Epoch: 5| Step: 10
Training loss: 2.0220789527911123
Validation loss: 2.4897325955154885

Epoch: 5| Step: 11
Training loss: 2.2977012134395225
Validation loss: 2.4725532891972573

Epoch: 100| Step: 0
Training loss: 1.8516778708781936
Validation loss: 2.526835300530926

Epoch: 5| Step: 1
Training loss: 1.739543602160388
Validation loss: 2.50300970109621

Epoch: 5| Step: 2
Training loss: 2.109333292230894
Validation loss: 2.509552630182267

Epoch: 5| Step: 3
Training loss: 1.8394336931907895
Validation loss: 2.522260806869892

Epoch: 5| Step: 4
Training loss: 1.6609090377364202
Validation loss: 2.474885591437893

Epoch: 5| Step: 5
Training loss: 2.725944995635858
Validation loss: 2.5245579612738416

Epoch: 5| Step: 6
Training loss: 2.1516640588619977
Validation loss: 2.5018320841002675

Epoch: 5| Step: 7
Training loss: 2.0935925097091377
Validation loss: 2.473458668627655

Epoch: 5| Step: 8
Training loss: 1.958702789789364
Validation loss: 2.5302517614070474

Epoch: 5| Step: 9
Training loss: 1.9796711596602667
Validation loss: 2.4981589810386806

Epoch: 5| Step: 10
Training loss: 1.7261671761567283
Validation loss: 2.4941013067218734

Epoch: 5| Step: 11
Training loss: 1.846052897578826
Validation loss: 2.484917171666232

Epoch: 101| Step: 0
Training loss: 1.978328413546111
Validation loss: 2.460134421613436

Epoch: 5| Step: 1
Training loss: 1.4822579797101132
Validation loss: 2.47071175755939

Epoch: 5| Step: 2
Training loss: 2.2161646004288236
Validation loss: 2.5037800146567966

Epoch: 5| Step: 3
Training loss: 2.0106322678567135
Validation loss: 2.528738805212137

Epoch: 5| Step: 4
Training loss: 1.7470301905503338
Validation loss: 2.53734789347025

Epoch: 5| Step: 5
Training loss: 2.435428325885137
Validation loss: 2.5664600190559343

Epoch: 5| Step: 6
Training loss: 1.7047756490460328
Validation loss: 2.4966382789356087

Epoch: 5| Step: 7
Training loss: 1.6751372693878297
Validation loss: 2.5025351624332033

Epoch: 5| Step: 8
Training loss: 1.9794144993928113
Validation loss: 2.4919214036842052

Epoch: 5| Step: 9
Training loss: 2.4098045550037144
Validation loss: 2.5038066731141346

Epoch: 5| Step: 10
Training loss: 2.020036704230393
Validation loss: 2.5469367072464175

Epoch: 5| Step: 11
Training loss: 2.073877798675788
Validation loss: 2.5240943179861035

Epoch: 102| Step: 0
Training loss: 2.1479432803360456
Validation loss: 2.545326319829315

Epoch: 5| Step: 1
Training loss: 1.7087263337556555
Validation loss: 2.5575755881720412

Epoch: 5| Step: 2
Training loss: 1.5108291413546586
Validation loss: 2.618464451610289

Epoch: 5| Step: 3
Training loss: 1.9161390601167438
Validation loss: 2.5722907800586143

Epoch: 5| Step: 4
Training loss: 2.261204900001873
Validation loss: 2.6145095371505973

Epoch: 5| Step: 5
Training loss: 2.243346655675243
Validation loss: 2.6021684278914132

Epoch: 5| Step: 6
Training loss: 1.8891256392838873
Validation loss: 2.571584979824498

Epoch: 5| Step: 7
Training loss: 1.7340233248645522
Validation loss: 2.5621496054039268

Epoch: 5| Step: 8
Training loss: 1.714649232854853
Validation loss: 2.497909522238582

Epoch: 5| Step: 9
Training loss: 2.5090680648432224
Validation loss: 2.5142954359457503

Epoch: 5| Step: 10
Training loss: 2.404550422791814
Validation loss: 2.5300511201523896

Epoch: 5| Step: 11
Training loss: 2.139805769261214
Validation loss: 2.475971235579631

Epoch: 103| Step: 0
Training loss: 2.1132589116916645
Validation loss: 2.44239092284916

Epoch: 5| Step: 1
Training loss: 1.8627849053724566
Validation loss: 2.5069826284044336

Epoch: 5| Step: 2
Training loss: 1.9683278554613515
Validation loss: 2.51890354272218

Epoch: 5| Step: 3
Training loss: 2.05869717130066
Validation loss: 2.4660856339634236

Epoch: 5| Step: 4
Training loss: 2.1108260073749907
Validation loss: 2.5411094083297514

Epoch: 5| Step: 5
Training loss: 1.9790303501232578
Validation loss: 2.5419623262906144

Epoch: 5| Step: 6
Training loss: 2.347689052358971
Validation loss: 2.5193662998506956

Epoch: 5| Step: 7
Training loss: 1.7846473953585027
Validation loss: 2.4994019508291934

Epoch: 5| Step: 8
Training loss: 2.0457716435948603
Validation loss: 2.5495600442393633

Epoch: 5| Step: 9
Training loss: 2.2018294617239604
Validation loss: 2.5757221005711637

Epoch: 5| Step: 10
Training loss: 1.5982828939923357
Validation loss: 2.56427271707851

Epoch: 5| Step: 11
Training loss: 1.5799590680095776
Validation loss: 2.610143803316865

Epoch: 104| Step: 0
Training loss: 2.0661197456525224
Validation loss: 2.577733938825354

Epoch: 5| Step: 1
Training loss: 1.952930959599452
Validation loss: 2.592425847147194

Epoch: 5| Step: 2
Training loss: 1.6627918818958611
Validation loss: 2.6372031362677024

Epoch: 5| Step: 3
Training loss: 1.8662740476148676
Validation loss: 2.5867776706367454

Epoch: 5| Step: 4
Training loss: 2.034807933207143
Validation loss: 2.5445396680871273

Epoch: 5| Step: 5
Training loss: 2.032969290032761
Validation loss: 2.5468670273482465

Epoch: 5| Step: 6
Training loss: 1.9870360546709402
Validation loss: 2.490866096502748

Epoch: 5| Step: 7
Training loss: 1.6687145129370229
Validation loss: 2.543270231893628

Epoch: 5| Step: 8
Training loss: 2.285129227437715
Validation loss: 2.4996774226931096

Epoch: 5| Step: 9
Training loss: 2.0235806565475634
Validation loss: 2.454137876489631

Epoch: 5| Step: 10
Training loss: 2.126647310716962
Validation loss: 2.519852894205649

Epoch: 5| Step: 11
Training loss: 1.4215739843307578
Validation loss: 2.450762252725881

Epoch: 105| Step: 0
Training loss: 2.120445531777429
Validation loss: 2.4941047102279827

Epoch: 5| Step: 1
Training loss: 1.8015994118633631
Validation loss: 2.5410156601855243

Epoch: 5| Step: 2
Training loss: 1.9694629165555517
Validation loss: 2.543496385283189

Epoch: 5| Step: 3
Training loss: 2.3055213583538285
Validation loss: 2.4895828152633404

Epoch: 5| Step: 4
Training loss: 1.5840363782067317
Validation loss: 2.4851988659950006

Epoch: 5| Step: 5
Training loss: 2.0853007627042817
Validation loss: 2.468124000437703

Epoch: 5| Step: 6
Training loss: 2.0448000342388477
Validation loss: 2.5270625669963214

Epoch: 5| Step: 7
Training loss: 1.9765424161953644
Validation loss: 2.522648214510724

Epoch: 5| Step: 8
Training loss: 2.159901277970503
Validation loss: 2.5568841051343476

Epoch: 5| Step: 9
Training loss: 1.8811208002582356
Validation loss: 2.5217158661669523

Epoch: 5| Step: 10
Training loss: 1.7242286063060777
Validation loss: 2.5513324288093835

Epoch: 5| Step: 11
Training loss: 1.0561205135633487
Validation loss: 2.5961728595470315

Epoch: 106| Step: 0
Training loss: 2.284939643179581
Validation loss: 2.5507393016160242

Epoch: 5| Step: 1
Training loss: 1.8652419165014427
Validation loss: 2.6411915571983697

Epoch: 5| Step: 2
Training loss: 2.1694970594932603
Validation loss: 2.6500836810509054

Epoch: 5| Step: 3
Training loss: 2.0292138090930476
Validation loss: 2.561212095846164

Epoch: 5| Step: 4
Training loss: 1.2565742226115266
Validation loss: 2.5563601035645838

Epoch: 5| Step: 5
Training loss: 2.0542607897795104
Validation loss: 2.5115746812254884

Epoch: 5| Step: 6
Training loss: 2.4957790982356474
Validation loss: 2.492753940095454

Epoch: 5| Step: 7
Training loss: 1.9666030318530985
Validation loss: 2.4610729483008145

Epoch: 5| Step: 8
Training loss: 2.035123682036078
Validation loss: 2.5128031476599535

Epoch: 5| Step: 9
Training loss: 1.8515288917291999
Validation loss: 2.4900570156790587

Epoch: 5| Step: 10
Training loss: 1.806224482266968
Validation loss: 2.521132255727473

Epoch: 5| Step: 11
Training loss: 1.8187276465231905
Validation loss: 2.4969316806335664

Epoch: 107| Step: 0
Training loss: 1.560213552309954
Validation loss: 2.49778927172484

Epoch: 5| Step: 1
Training loss: 1.6297258469485467
Validation loss: 2.562062935656202

Epoch: 5| Step: 2
Training loss: 1.8165082349141681
Validation loss: 2.565158265732614

Epoch: 5| Step: 3
Training loss: 2.2518125227139074
Validation loss: 2.6314813774931474

Epoch: 5| Step: 4
Training loss: 2.141819752764578
Validation loss: 2.590324706253879

Epoch: 5| Step: 5
Training loss: 2.3253716694722333
Validation loss: 2.6136686325908314

Epoch: 5| Step: 6
Training loss: 1.9915108522679277
Validation loss: 2.653112634331201

Epoch: 5| Step: 7
Training loss: 1.8817335020730477
Validation loss: 2.630015633703405

Epoch: 5| Step: 8
Training loss: 2.533835515224477
Validation loss: 2.6025345125331554

Epoch: 5| Step: 9
Training loss: 1.7044640273094196
Validation loss: 2.583612109083372

Epoch: 5| Step: 10
Training loss: 1.6323884112088116
Validation loss: 2.53460673297008

Epoch: 5| Step: 11
Training loss: 0.33819941925112323
Validation loss: 2.547663010930715

Epoch: 108| Step: 0
Training loss: 1.6873526332228228
Validation loss: 2.494486164243509

Epoch: 5| Step: 1
Training loss: 1.8538798706904318
Validation loss: 2.5140577611410313

Epoch: 5| Step: 2
Training loss: 1.7474909233981757
Validation loss: 2.496292834633127

Epoch: 5| Step: 3
Training loss: 2.173298760160583
Validation loss: 2.5549058772241806

Epoch: 5| Step: 4
Training loss: 1.7981611873099963
Validation loss: 2.58669750804392

Epoch: 5| Step: 5
Training loss: 1.8793439137279488
Validation loss: 2.531736386040003

Epoch: 5| Step: 6
Training loss: 1.5954898985922819
Validation loss: 2.506679060906178

Epoch: 5| Step: 7
Training loss: 1.8397960616165705
Validation loss: 2.5582526059621578

Epoch: 5| Step: 8
Training loss: 2.0474580123750927
Validation loss: 2.5243321772563116

Epoch: 5| Step: 9
Training loss: 2.872627440332231
Validation loss: 2.577847055422541

Epoch: 5| Step: 10
Training loss: 1.422588211435261
Validation loss: 2.561854591347279

Epoch: 5| Step: 11
Training loss: 2.2468620246862723
Validation loss: 2.5636213996781696

Epoch: 109| Step: 0
Training loss: 1.4519101058256187
Validation loss: 2.527126635070132

Epoch: 5| Step: 1
Training loss: 1.7572892830257232
Validation loss: 2.477164924268151

Epoch: 5| Step: 2
Training loss: 1.6092807779229772
Validation loss: 2.5066551080861665

Epoch: 5| Step: 3
Training loss: 1.9534815958648524
Validation loss: 2.4980960828176224

Epoch: 5| Step: 4
Training loss: 1.763617057413078
Validation loss: 2.4954699640786813

Epoch: 5| Step: 5
Training loss: 1.5339263570881512
Validation loss: 2.523569924390469

Epoch: 5| Step: 6
Training loss: 1.9290063559356756
Validation loss: 2.554158936707176

Epoch: 5| Step: 7
Training loss: 2.1559129534472854
Validation loss: 2.556762828388273

Epoch: 5| Step: 8
Training loss: 2.2630698692941156
Validation loss: 2.580503353141356

Epoch: 5| Step: 9
Training loss: 2.051469611035572
Validation loss: 2.521801661418081

Epoch: 5| Step: 10
Training loss: 1.6558599192624504
Validation loss: 2.5092286640093877

Epoch: 5| Step: 11
Training loss: 3.9806441248780056
Validation loss: 2.554919622143605

Epoch: 110| Step: 0
Training loss: 1.96134123882323
Validation loss: 2.6530629991371857

Epoch: 5| Step: 1
Training loss: 1.9791646723151615
Validation loss: 2.686748669453946

Epoch: 5| Step: 2
Training loss: 1.6862197540715136
Validation loss: 2.6341002811653937

Epoch: 5| Step: 3
Training loss: 1.7009830829960997
Validation loss: 2.6547408884602604

Epoch: 5| Step: 4
Training loss: 2.413908919600167
Validation loss: 2.6600932759408606

Epoch: 5| Step: 5
Training loss: 1.926485501596926
Validation loss: 2.5867611321568313

Epoch: 5| Step: 6
Training loss: 1.6117664827498341
Validation loss: 2.6043033824637374

Epoch: 5| Step: 7
Training loss: 2.086313506680321
Validation loss: 2.6101332798114276

Epoch: 5| Step: 8
Training loss: 1.8013376299093655
Validation loss: 2.4944387111908273

Epoch: 5| Step: 9
Training loss: 2.4418701707661867
Validation loss: 2.5081500245173634

Epoch: 5| Step: 10
Training loss: 1.4095572681518502
Validation loss: 2.5192115975204095

Epoch: 5| Step: 11
Training loss: 1.950003364755711
Validation loss: 2.540688136130757

Epoch: 111| Step: 0
Training loss: 1.9821232312383348
Validation loss: 2.555670550052317

Epoch: 5| Step: 1
Training loss: 1.8769126673376089
Validation loss: 2.564373792790126

Epoch: 5| Step: 2
Training loss: 1.712613125705281
Validation loss: 2.5161896302987308

Epoch: 5| Step: 3
Training loss: 1.4570322317984292
Validation loss: 2.60659937845718

Epoch: 5| Step: 4
Training loss: 1.340104592070331
Validation loss: 2.679116673000627

Epoch: 5| Step: 5
Training loss: 2.712416891064162
Validation loss: 2.693177303497721

Epoch: 5| Step: 6
Training loss: 1.9364570148443694
Validation loss: 2.6535122469345134

Epoch: 5| Step: 7
Training loss: 1.873558316697803
Validation loss: 2.6476589134955573

Epoch: 5| Step: 8
Training loss: 2.011973066828447
Validation loss: 2.614960956026722

Epoch: 5| Step: 9
Training loss: 1.7930922787733299
Validation loss: 2.5445010270801083

Epoch: 5| Step: 10
Training loss: 1.8702136301217278
Validation loss: 2.5106097908182936

Epoch: 5| Step: 11
Training loss: 2.59829864589725
Validation loss: 2.466584994654419

Epoch: 112| Step: 0
Training loss: 1.3098454652156382
Validation loss: 2.499795885495528

Epoch: 5| Step: 1
Training loss: 1.791543364902568
Validation loss: 2.5274586796362217

Epoch: 5| Step: 2
Training loss: 2.0106489874132523
Validation loss: 2.5380675728732727

Epoch: 5| Step: 3
Training loss: 2.052741343797638
Validation loss: 2.596058461686718

Epoch: 5| Step: 4
Training loss: 2.1711377326433405
Validation loss: 2.538603517177765

Epoch: 5| Step: 5
Training loss: 2.2704879661431008
Validation loss: 2.550547796980236

Epoch: 5| Step: 6
Training loss: 1.8865482103186675
Validation loss: 2.5194820073956397

Epoch: 5| Step: 7
Training loss: 1.7208700802676535
Validation loss: 2.5381247877195876

Epoch: 5| Step: 8
Training loss: 2.241707142271855
Validation loss: 2.5235278031732515

Epoch: 5| Step: 9
Training loss: 1.866552396523737
Validation loss: 2.5821115593821484

Epoch: 5| Step: 10
Training loss: 2.0845917779158105
Validation loss: 2.583458491082788

Epoch: 5| Step: 11
Training loss: 1.5845080919814476
Validation loss: 2.6436102431131325

Epoch: 113| Step: 0
Training loss: 2.006972794147383
Validation loss: 2.6325015517384496

Epoch: 5| Step: 1
Training loss: 1.8885353457188507
Validation loss: 2.656550816724642

Epoch: 5| Step: 2
Training loss: 1.2224937550359878
Validation loss: 2.5588041845081113

Epoch: 5| Step: 3
Training loss: 1.5401246718932742
Validation loss: 2.5646952746948086

Epoch: 5| Step: 4
Training loss: 1.5472532638291023
Validation loss: 2.5552898361844996

Epoch: 5| Step: 5
Training loss: 1.9883359290737828
Validation loss: 2.5473721843883435

Epoch: 5| Step: 6
Training loss: 1.8599524362696878
Validation loss: 2.5797908756854886

Epoch: 5| Step: 7
Training loss: 1.9027309141243096
Validation loss: 2.440999811546238

Epoch: 5| Step: 8
Training loss: 1.8572949226708861
Validation loss: 2.5480468390538515

Epoch: 5| Step: 9
Training loss: 1.9233529835407341
Validation loss: 2.534261423114632

Epoch: 5| Step: 10
Training loss: 2.4465321189756914
Validation loss: 2.535900745293938

Epoch: 5| Step: 11
Training loss: 0.7476278779995414
Validation loss: 2.516504923620826

Epoch: 114| Step: 0
Training loss: 1.511431447409341
Validation loss: 2.4954028180712053

Epoch: 5| Step: 1
Training loss: 1.6989395087544283
Validation loss: 2.5095578475026246

Epoch: 5| Step: 2
Training loss: 1.8323384822425905
Validation loss: 2.498780368294709

Epoch: 5| Step: 3
Training loss: 1.8279824486605674
Validation loss: 2.4789943127599603

Epoch: 5| Step: 4
Training loss: 1.9415488852713225
Validation loss: 2.5714048559240656

Epoch: 5| Step: 5
Training loss: 1.5688019124594728
Validation loss: 2.5278710881822146

Epoch: 5| Step: 6
Training loss: 1.551940561508226
Validation loss: 2.5285703933939225

Epoch: 5| Step: 7
Training loss: 2.0341964479251313
Validation loss: 2.579132334111412

Epoch: 5| Step: 8
Training loss: 2.119511191318534
Validation loss: 2.628770266412602

Epoch: 5| Step: 9
Training loss: 2.508119083096226
Validation loss: 2.613722706425256

Epoch: 5| Step: 10
Training loss: 1.784551004524736
Validation loss: 2.6125009281211553

Epoch: 5| Step: 11
Training loss: 1.3837681286183416
Validation loss: 2.529874062683152

Epoch: 115| Step: 0
Training loss: 1.7072483509551237
Validation loss: 2.568680849250594

Epoch: 5| Step: 1
Training loss: 2.311718061059641
Validation loss: 2.570193217407444

Epoch: 5| Step: 2
Training loss: 1.4254460188895068
Validation loss: 2.5992493718136642

Epoch: 5| Step: 3
Training loss: 2.0190157499865737
Validation loss: 2.586285801045573

Epoch: 5| Step: 4
Training loss: 1.3610001419313962
Validation loss: 2.622865918228829

Epoch: 5| Step: 5
Training loss: 1.710699613572528
Validation loss: 2.4925448919760154

Epoch: 5| Step: 6
Training loss: 1.7191312887176187
Validation loss: 2.525823754156414

Epoch: 5| Step: 7
Training loss: 1.8248290648164693
Validation loss: 2.5382670873245092

Epoch: 5| Step: 8
Training loss: 1.4616543240317854
Validation loss: 2.519615043804164

Epoch: 5| Step: 9
Training loss: 1.7943782543550144
Validation loss: 2.513092341748034

Epoch: 5| Step: 10
Training loss: 2.0420182243303593
Validation loss: 2.549497856926265

Epoch: 5| Step: 11
Training loss: 2.178160867710418
Validation loss: 2.5918471315441938

Epoch: 116| Step: 0
Training loss: 1.4532075263759048
Validation loss: 2.5219144683358725

Epoch: 5| Step: 1
Training loss: 1.9911654973703443
Validation loss: 2.5372974775328028

Epoch: 5| Step: 2
Training loss: 1.988501695804386
Validation loss: 2.553493625203164

Epoch: 5| Step: 3
Training loss: 1.6157520207364862
Validation loss: 2.5150688654468922

Epoch: 5| Step: 4
Training loss: 2.1351539140026214
Validation loss: 2.6016065576620258

Epoch: 5| Step: 5
Training loss: 1.656881176143087
Validation loss: 2.5380570362456885

Epoch: 5| Step: 6
Training loss: 1.7320102688658947
Validation loss: 2.5517075177586808

Epoch: 5| Step: 7
Training loss: 1.6882329691170932
Validation loss: 2.5710213021096084

Epoch: 5| Step: 8
Training loss: 1.4930320067606286
Validation loss: 2.5804751656437426

Epoch: 5| Step: 9
Training loss: 1.8644197132913958
Validation loss: 2.570475995353066

Epoch: 5| Step: 10
Training loss: 1.8271584197056625
Validation loss: 2.529659729291299

Epoch: 5| Step: 11
Training loss: 1.726186305700316
Validation loss: 2.5570840375769905

Epoch: 117| Step: 0
Training loss: 1.5008753765401512
Validation loss: 2.539462397457278

Epoch: 5| Step: 1
Training loss: 1.652538964393612
Validation loss: 2.5816464928585194

Epoch: 5| Step: 2
Training loss: 1.6532784201490804
Validation loss: 2.5045833138420557

Epoch: 5| Step: 3
Training loss: 1.6779243619237305
Validation loss: 2.5494973270027934

Epoch: 5| Step: 4
Training loss: 2.7499439927379976
Validation loss: 2.57181947817381

Epoch: 5| Step: 5
Training loss: 1.5187842094430386
Validation loss: 2.540980622981198

Epoch: 5| Step: 6
Training loss: 1.6627593332962733
Validation loss: 2.4778338637713744

Epoch: 5| Step: 7
Training loss: 1.4806191561749849
Validation loss: 2.486250950848433

Epoch: 5| Step: 8
Training loss: 1.8710429079160475
Validation loss: 2.5342371704403

Epoch: 5| Step: 9
Training loss: 1.7763320223120482
Validation loss: 2.556444133826568

Epoch: 5| Step: 10
Training loss: 1.802727167150237
Validation loss: 2.4619719495856507

Epoch: 5| Step: 11
Training loss: 2.3175877457584106
Validation loss: 2.6170447998619273

Epoch: 118| Step: 0
Training loss: 1.7707233245188925
Validation loss: 2.613958391729891

Epoch: 5| Step: 1
Training loss: 1.7504932525862114
Validation loss: 2.5129285778972936

Epoch: 5| Step: 2
Training loss: 1.3258501654243215
Validation loss: 2.5195587590413715

Epoch: 5| Step: 3
Training loss: 1.5674733168477035
Validation loss: 2.508372441385094

Epoch: 5| Step: 4
Training loss: 1.578155366208853
Validation loss: 2.506651788993531

Epoch: 5| Step: 5
Training loss: 1.2203487278522052
Validation loss: 2.5290750884979283

Epoch: 5| Step: 6
Training loss: 1.544129835342474
Validation loss: 2.6036385929022

Epoch: 5| Step: 7
Training loss: 2.37335559736303
Validation loss: 2.5649931029982413

Epoch: 5| Step: 8
Training loss: 2.01800278573274
Validation loss: 2.628332199141992

Epoch: 5| Step: 9
Training loss: 1.6164325665875545
Validation loss: 2.6484696602908286

Epoch: 5| Step: 10
Training loss: 2.0833824024779592
Validation loss: 2.6641932256848593

Epoch: 5| Step: 11
Training loss: 2.1103136023020452
Validation loss: 2.5926157336457445

Epoch: 119| Step: 0
Training loss: 1.8506451358234373
Validation loss: 2.643541516169154

Epoch: 5| Step: 1
Training loss: 1.3905624632757585
Validation loss: 2.5761051434446025

Epoch: 5| Step: 2
Training loss: 1.668401157335581
Validation loss: 2.590955021156786

Epoch: 5| Step: 3
Training loss: 1.6708920164893428
Validation loss: 2.5522313263210896

Epoch: 5| Step: 4
Training loss: 2.0575301663862913
Validation loss: 2.6137922212245464

Epoch: 5| Step: 5
Training loss: 1.7172362163599744
Validation loss: 2.571489271498949

Epoch: 5| Step: 6
Training loss: 2.5082826738110526
Validation loss: 2.534364217068099

Epoch: 5| Step: 7
Training loss: 1.7319135640537235
Validation loss: 2.495180984945555

Epoch: 5| Step: 8
Training loss: 1.2325874616374846
Validation loss: 2.5419661249091616

Epoch: 5| Step: 9
Training loss: 1.7355215046307806
Validation loss: 2.576814364585673

Epoch: 5| Step: 10
Training loss: 1.632571407935364
Validation loss: 2.592301209208993

Epoch: 5| Step: 11
Training loss: 1.7380845547949326
Validation loss: 2.6227510256550883

Epoch: 120| Step: 0
Training loss: 1.0594551551224984
Validation loss: 2.65171682582683

Epoch: 5| Step: 1
Training loss: 1.9794399139774046
Validation loss: 2.5614086672722762

Epoch: 5| Step: 2
Training loss: 2.434290313227049
Validation loss: 2.539719141634775

Epoch: 5| Step: 3
Training loss: 1.1579096456074398
Validation loss: 2.527414351375838

Epoch: 5| Step: 4
Training loss: 1.839417426410371
Validation loss: 2.5517968205106643

Epoch: 5| Step: 5
Training loss: 1.43826514073954
Validation loss: 2.4979549547134523

Epoch: 5| Step: 6
Training loss: 1.862404927124965
Validation loss: 2.483660353233212

Epoch: 5| Step: 7
Training loss: 1.8621537417933438
Validation loss: 2.576011658517003

Epoch: 5| Step: 8
Training loss: 1.9820666366022517
Validation loss: 2.5583152211715112

Epoch: 5| Step: 9
Training loss: 1.406018725556744
Validation loss: 2.5912511922352355

Epoch: 5| Step: 10
Training loss: 1.6698962471763383
Validation loss: 2.566514599824292

Epoch: 5| Step: 11
Training loss: 2.568256796757399
Validation loss: 2.5570391797716767

Epoch: 121| Step: 0
Training loss: 1.483615721207932
Validation loss: 2.5665129664049133

Epoch: 5| Step: 1
Training loss: 1.6333216553225158
Validation loss: 2.632229175336586

Epoch: 5| Step: 2
Training loss: 1.5902328577411546
Validation loss: 2.5969097011189444

Epoch: 5| Step: 3
Training loss: 2.4276245779802466
Validation loss: 2.641734629327398

Epoch: 5| Step: 4
Training loss: 1.0786316275601335
Validation loss: 2.5323132491411418

Epoch: 5| Step: 5
Training loss: 1.9169273890204113
Validation loss: 2.575878046538932

Epoch: 5| Step: 6
Training loss: 1.5402610488195636
Validation loss: 2.6124784702953154

Epoch: 5| Step: 7
Training loss: 1.2669698375402452
Validation loss: 2.597778218018406

Epoch: 5| Step: 8
Training loss: 1.7712227187549265
Validation loss: 2.644139961959809

Epoch: 5| Step: 9
Training loss: 1.9078375662391813
Validation loss: 2.601252307288952

Epoch: 5| Step: 10
Training loss: 1.8568054524137425
Validation loss: 2.5822651882642718

Epoch: 5| Step: 11
Training loss: 0.8453793864132858
Validation loss: 2.5714023215982507

Epoch: 122| Step: 0
Training loss: 1.2523880082732355
Validation loss: 2.5502630372360033

Epoch: 5| Step: 1
Training loss: 1.8750888803396986
Validation loss: 2.576540087958477

Epoch: 5| Step: 2
Training loss: 1.6354991219826385
Validation loss: 2.5188209498456593

Epoch: 5| Step: 3
Training loss: 1.8532168566628175
Validation loss: 2.597200316378123

Epoch: 5| Step: 4
Training loss: 1.7134599598552338
Validation loss: 2.559013584626128

Epoch: 5| Step: 5
Training loss: 1.6546326423751523
Validation loss: 2.5561803136714425

Epoch: 5| Step: 6
Training loss: 1.6698507014940442
Validation loss: 2.6348377893743873

Epoch: 5| Step: 7
Training loss: 1.6609904269149847
Validation loss: 2.593133650169432

Epoch: 5| Step: 8
Training loss: 1.6555751649319645
Validation loss: 2.6806803051399135

Epoch: 5| Step: 9
Training loss: 1.859059860066027
Validation loss: 2.6114542000312695

Epoch: 5| Step: 10
Training loss: 1.4794089517375928
Validation loss: 2.5851500619364836

Epoch: 5| Step: 11
Training loss: 2.199980744364307
Validation loss: 2.584028828479535

Epoch: 123| Step: 0
Training loss: 1.6694847203983858
Validation loss: 2.5517694137471083

Epoch: 5| Step: 1
Training loss: 2.3729667995427532
Validation loss: 2.6396652147759814

Epoch: 5| Step: 2
Training loss: 1.6149087967526907
Validation loss: 2.56280769850057

Epoch: 5| Step: 3
Training loss: 1.6072942374854338
Validation loss: 2.6023888521342964

Epoch: 5| Step: 4
Training loss: 1.8369728577861242
Validation loss: 2.6107026185319278

Epoch: 5| Step: 5
Training loss: 2.101640891275807
Validation loss: 2.572803897677254

Epoch: 5| Step: 6
Training loss: 0.9207874283776695
Validation loss: 2.5693812552978863

Epoch: 5| Step: 7
Training loss: 1.2988446456891038
Validation loss: 2.564202030282263

Epoch: 5| Step: 8
Training loss: 1.9272132486077225
Validation loss: 2.5951252244492

Epoch: 5| Step: 9
Training loss: 1.473142912816065
Validation loss: 2.591283594555616

Epoch: 5| Step: 10
Training loss: 1.5869231520172378
Validation loss: 2.659011796294605

Epoch: 5| Step: 11
Training loss: 1.3115188928043933
Validation loss: 2.6768050191363644

Epoch: 124| Step: 0
Training loss: 1.5100864005475085
Validation loss: 2.645516764608177

Epoch: 5| Step: 1
Training loss: 1.8089715880170842
Validation loss: 2.6497270338556413

Epoch: 5| Step: 2
Training loss: 1.124926246768625
Validation loss: 2.6883490315452168

Epoch: 5| Step: 3
Training loss: 1.8653155404051882
Validation loss: 2.6356314218545553

Epoch: 5| Step: 4
Training loss: 1.565051551311045
Validation loss: 2.6066069016308573

Epoch: 5| Step: 5
Training loss: 1.6218684907462857
Validation loss: 2.5605352592059303

Epoch: 5| Step: 6
Training loss: 1.4470042457281014
Validation loss: 2.508849964266354

Epoch: 5| Step: 7
Training loss: 1.891357154004152
Validation loss: 2.6727815655356135

Epoch: 5| Step: 8
Training loss: 1.2212263039014846
Validation loss: 2.5660196919940588

Epoch: 5| Step: 9
Training loss: 1.617287379327166
Validation loss: 2.603160523916003

Epoch: 5| Step: 10
Training loss: 2.589263805052421
Validation loss: 2.5657186220831116

Epoch: 5| Step: 11
Training loss: 1.3576945737631552
Validation loss: 2.602956812517286

Epoch: 125| Step: 0
Training loss: 2.0837910212991075
Validation loss: 2.5718149511126023

Epoch: 5| Step: 1
Training loss: 1.4929412216451228
Validation loss: 2.6046162268107973

Epoch: 5| Step: 2
Training loss: 1.746655538077004
Validation loss: 2.6091980750432144

Epoch: 5| Step: 3
Training loss: 1.4359990452308988
Validation loss: 2.668104567638305

Epoch: 5| Step: 4
Training loss: 1.8393332386622878
Validation loss: 2.7301851015195315

Epoch: 5| Step: 5
Training loss: 1.9957033734891703
Validation loss: 2.6986579846174474

Epoch: 5| Step: 6
Training loss: 1.496586332579463
Validation loss: 2.698334725342082

Epoch: 5| Step: 7
Training loss: 1.8878672008927924
Validation loss: 2.6735942507015418

Epoch: 5| Step: 8
Training loss: 1.3235114805403123
Validation loss: 2.5820281220617693

Epoch: 5| Step: 9
Training loss: 1.1045247283108397
Validation loss: 2.6095587423965685

Epoch: 5| Step: 10
Training loss: 1.811285532832514
Validation loss: 2.5853269419033684

Epoch: 5| Step: 11
Training loss: 2.5983548021031124
Validation loss: 2.549986434570083

Epoch: 126| Step: 0
Training loss: 1.3096033102112532
Validation loss: 2.6060445245602146

Epoch: 5| Step: 1
Training loss: 1.670266634504975
Validation loss: 2.5666294281495783

Epoch: 5| Step: 2
Training loss: 1.4252415301772683
Validation loss: 2.6320195650056655

Epoch: 5| Step: 3
Training loss: 1.7930843673362444
Validation loss: 2.563664815136308

Epoch: 5| Step: 4
Training loss: 2.378921684127375
Validation loss: 2.5642646203120316

Epoch: 5| Step: 5
Training loss: 1.770791924684361
Validation loss: 2.6121816255573607

Epoch: 5| Step: 6
Training loss: 0.9841531776087377
Validation loss: 2.7084588290751936

Epoch: 5| Step: 7
Training loss: 1.5976729636961944
Validation loss: 2.621529453408981

Epoch: 5| Step: 8
Training loss: 1.5947415876177136
Validation loss: 2.6963144771156946

Epoch: 5| Step: 9
Training loss: 1.4316622744142409
Validation loss: 2.6474302696516476

Epoch: 5| Step: 10
Training loss: 1.799377490058811
Validation loss: 2.59065686824817

Epoch: 5| Step: 11
Training loss: 1.8976892951359063
Validation loss: 2.6578874664528573

Epoch: 127| Step: 0
Training loss: 1.5185410281238565
Validation loss: 2.608453770732211

Epoch: 5| Step: 1
Training loss: 1.9620385593315521
Validation loss: 2.5710205216065414

Epoch: 5| Step: 2
Training loss: 1.7465111150467063
Validation loss: 2.5729205727386684

Epoch: 5| Step: 3
Training loss: 1.2139067148538427
Validation loss: 2.6113787817101444

Epoch: 5| Step: 4
Training loss: 1.3335097265786335
Validation loss: 2.6095265784180968

Epoch: 5| Step: 5
Training loss: 1.7401244260432018
Validation loss: 2.595347360724773

Epoch: 5| Step: 6
Training loss: 1.8371405373164347
Validation loss: 2.6357488096214534

Epoch: 5| Step: 7
Training loss: 1.663373204417846
Validation loss: 2.6602627606385347

Epoch: 5| Step: 8
Training loss: 1.3518705513114233
Validation loss: 2.634241408750256

Epoch: 5| Step: 9
Training loss: 2.2316858074382555
Validation loss: 2.6440981158525463

Epoch: 5| Step: 10
Training loss: 1.1116311677491177
Validation loss: 2.618075388139865

Epoch: 5| Step: 11
Training loss: 1.6977591022173868
Validation loss: 2.537644120212375

Epoch: 128| Step: 0
Training loss: 1.7027238845939607
Validation loss: 2.6167985921351953

Epoch: 5| Step: 1
Training loss: 1.4524405723666334
Validation loss: 2.657682739265749

Epoch: 5| Step: 2
Training loss: 2.115658140838563
Validation loss: 2.641288658878592

Epoch: 5| Step: 3
Training loss: 1.190426182604818
Validation loss: 2.6303879264225443

Epoch: 5| Step: 4
Training loss: 1.1110567589552651
Validation loss: 2.594620635129678

Epoch: 5| Step: 5
Training loss: 1.7302082632096576
Validation loss: 2.593965575057176

Epoch: 5| Step: 6
Training loss: 1.236782285849924
Validation loss: 2.5576875047508083

Epoch: 5| Step: 7
Training loss: 1.5126610315525297
Validation loss: 2.5832706810419253

Epoch: 5| Step: 8
Training loss: 1.8444670882935195
Validation loss: 2.627981562712582

Epoch: 5| Step: 9
Training loss: 1.4638881974497124
Validation loss: 2.6730970707343253

Epoch: 5| Step: 10
Training loss: 1.898253757705697
Validation loss: 2.604811730918646

Epoch: 5| Step: 11
Training loss: 0.9406070720193423
Validation loss: 2.5863360993815916

Epoch: 129| Step: 0
Training loss: 1.2947453857563571
Validation loss: 2.6028566625925253

Epoch: 5| Step: 1
Training loss: 1.6655335707199999
Validation loss: 2.635036487574035

Epoch: 5| Step: 2
Training loss: 1.2702137682319148
Validation loss: 2.7047302646734392

Epoch: 5| Step: 3
Training loss: 2.2126826755089755
Validation loss: 2.653490802602556

Epoch: 5| Step: 4
Training loss: 1.6747634037368067
Validation loss: 2.715302956803944

Epoch: 5| Step: 5
Training loss: 1.1946404256883503
Validation loss: 2.661435369154864

Epoch: 5| Step: 6
Training loss: 1.5556932579505003
Validation loss: 2.582314895539768

Epoch: 5| Step: 7
Training loss: 1.5866314351687583
Validation loss: 2.5532275392134633

Epoch: 5| Step: 8
Training loss: 1.5209612161179715
Validation loss: 2.5938171546546025

Epoch: 5| Step: 9
Training loss: 1.637399536428902
Validation loss: 2.5746306503235625

Epoch: 5| Step: 10
Training loss: 1.4316768459510336
Validation loss: 2.573368582374987

Epoch: 5| Step: 11
Training loss: 2.153180688323347
Validation loss: 2.5124270447534567

Epoch: 130| Step: 0
Training loss: 1.7024188896497188
Validation loss: 2.5799831244867995

Epoch: 5| Step: 1
Training loss: 1.4280761643622102
Validation loss: 2.573950811941432

Epoch: 5| Step: 2
Training loss: 1.318358922887654
Validation loss: 2.581526845043845

Epoch: 5| Step: 3
Training loss: 1.6689268839953157
Validation loss: 2.534577298194548

Epoch: 5| Step: 4
Training loss: 2.0919783199200763
Validation loss: 2.580381646545165

Epoch: 5| Step: 5
Training loss: 1.3434817911439574
Validation loss: 2.582868639364138

Epoch: 5| Step: 6
Training loss: 2.168682468912971
Validation loss: 2.6337696150628807

Epoch: 5| Step: 7
Training loss: 1.2034106225177463
Validation loss: 2.5896135614359213

Epoch: 5| Step: 8
Training loss: 1.7853555714122273
Validation loss: 2.636269042671466

Epoch: 5| Step: 9
Training loss: 1.3439401891206297
Validation loss: 2.6879529737601517

Epoch: 5| Step: 10
Training loss: 1.459577284196099
Validation loss: 2.6569998187724417

Epoch: 5| Step: 11
Training loss: 1.1688664281451442
Validation loss: 2.686212456732097

Epoch: 131| Step: 0
Training loss: 1.924475298625137
Validation loss: 2.6432139779893173

Epoch: 5| Step: 1
Training loss: 1.202150569514128
Validation loss: 2.626688546585394

Epoch: 5| Step: 2
Training loss: 1.2360624537136427
Validation loss: 2.573777260786495

Epoch: 5| Step: 3
Training loss: 1.7645439957246463
Validation loss: 2.607294399083761

Epoch: 5| Step: 4
Training loss: 1.5180479522790777
Validation loss: 2.5932027630145904

Epoch: 5| Step: 5
Training loss: 1.0732667345705664
Validation loss: 2.591863513004582

Epoch: 5| Step: 6
Training loss: 1.2830366377917723
Validation loss: 2.5375345376519025

Epoch: 5| Step: 7
Training loss: 1.4250685491303423
Validation loss: 2.559545740744372

Epoch: 5| Step: 8
Training loss: 1.3575967140942509
Validation loss: 2.5474672116548893

Epoch: 5| Step: 9
Training loss: 1.6921191398077835
Validation loss: 2.559017905295756

Epoch: 5| Step: 10
Training loss: 1.868405571266154
Validation loss: 2.6014197523267786

Epoch: 5| Step: 11
Training loss: 1.5894168214924735
Validation loss: 2.5534018334939477

Epoch: 132| Step: 0
Training loss: 1.5282882540816987
Validation loss: 2.6132071522089944

Epoch: 5| Step: 1
Training loss: 1.5557275101821335
Validation loss: 2.599943674987411

Epoch: 5| Step: 2
Training loss: 1.480121340288126
Validation loss: 2.6045966149492266

Epoch: 5| Step: 3
Training loss: 1.2541201875423784
Validation loss: 2.6078395475642373

Epoch: 5| Step: 4
Training loss: 1.796871152127334
Validation loss: 2.602625800447375

Epoch: 5| Step: 5
Training loss: 0.9609810113747669
Validation loss: 2.6915387516412723

Epoch: 5| Step: 6
Training loss: 1.842160461072042
Validation loss: 2.6399757632975716

Epoch: 5| Step: 7
Training loss: 1.3118805558885291
Validation loss: 2.5863458823807384

Epoch: 5| Step: 8
Training loss: 1.2518923264141006
Validation loss: 2.693722098133002

Epoch: 5| Step: 9
Training loss: 2.0529478417639884
Validation loss: 2.595655254748304

Epoch: 5| Step: 10
Training loss: 1.5368456680955136
Validation loss: 2.6560122477024506

Epoch: 5| Step: 11
Training loss: 1.3707047043642049
Validation loss: 2.628451857424252

Epoch: 133| Step: 0
Training loss: 2.058383648626777
Validation loss: 2.61665241218337

Epoch: 5| Step: 1
Training loss: 1.029014534201634
Validation loss: 2.637265127580697

Epoch: 5| Step: 2
Training loss: 1.1458851484663055
Validation loss: 2.634307391655552

Epoch: 5| Step: 3
Training loss: 1.467149552412114
Validation loss: 2.627315725947848

Epoch: 5| Step: 4
Training loss: 1.0415627364127746
Validation loss: 2.5942335022836183

Epoch: 5| Step: 5
Training loss: 1.4615827145421378
Validation loss: 2.677224279223556

Epoch: 5| Step: 6
Training loss: 1.2483289993747368
Validation loss: 2.6616632540670393

Epoch: 5| Step: 7
Training loss: 1.883129932031209
Validation loss: 2.6541418086873585

Epoch: 5| Step: 8
Training loss: 1.5059398030969757
Validation loss: 2.6429138402659613

Epoch: 5| Step: 9
Training loss: 1.699291289085645
Validation loss: 2.7127124058640852

Epoch: 5| Step: 10
Training loss: 1.5841994509982678
Validation loss: 2.6766168445207628

Epoch: 5| Step: 11
Training loss: 2.1128233803168626
Validation loss: 2.6510190806647707

Epoch: 134| Step: 0
Training loss: 2.1667270162931844
Validation loss: 2.587934124658976

Epoch: 5| Step: 1
Training loss: 0.7967298038820827
Validation loss: 2.5480477338086995

Epoch: 5| Step: 2
Training loss: 1.3961573077710845
Validation loss: 2.608221233008546

Epoch: 5| Step: 3
Training loss: 1.713318931071288
Validation loss: 2.591161915075854

Epoch: 5| Step: 4
Training loss: 1.546821207980026
Validation loss: 2.589184622991361

Epoch: 5| Step: 5
Training loss: 1.1307445724798988
Validation loss: 2.5967686104585477

Epoch: 5| Step: 6
Training loss: 1.7825258604637537
Validation loss: 2.6368538565223885

Epoch: 5| Step: 7
Training loss: 1.4313155113452722
Validation loss: 2.662716392146934

Epoch: 5| Step: 8
Training loss: 1.06617292709226
Validation loss: 2.6167486971147955

Epoch: 5| Step: 9
Training loss: 1.3663550758266698
Validation loss: 2.672111147582076

Epoch: 5| Step: 10
Training loss: 1.2237935976672976
Validation loss: 2.673248536569757

Epoch: 5| Step: 11
Training loss: 1.7702923415838443
Validation loss: 2.6763951360779945

Epoch: 135| Step: 0
Training loss: 1.7583003066638834
Validation loss: 2.73928500437939

Epoch: 5| Step: 1
Training loss: 1.8420098708485764
Validation loss: 2.6593105691619785

Epoch: 5| Step: 2
Training loss: 1.6334026675527031
Validation loss: 2.703139747917502

Epoch: 5| Step: 3
Training loss: 0.98171249472656
Validation loss: 2.6906673965628753

Epoch: 5| Step: 4
Training loss: 1.775220134677824
Validation loss: 2.7393711549426003

Epoch: 5| Step: 5
Training loss: 1.584422172130065
Validation loss: 2.762623050302436

Epoch: 5| Step: 6
Training loss: 1.2951786482875323
Validation loss: 2.5961918615934243

Epoch: 5| Step: 7
Training loss: 1.3880059084587875
Validation loss: 2.5745757978824697

Epoch: 5| Step: 8
Training loss: 1.1784599940971174
Validation loss: 2.645278254176706

Epoch: 5| Step: 9
Training loss: 1.7661078138954978
Validation loss: 2.586921884849648

Epoch: 5| Step: 10
Training loss: 1.7243327246167794
Validation loss: 2.5625466443290312

Epoch: 5| Step: 11
Training loss: 1.5535251738955258
Validation loss: 2.5669844627772074

Epoch: 136| Step: 0
Training loss: 1.5502408332769002
Validation loss: 2.634223590027812

Epoch: 5| Step: 1
Training loss: 2.1287631205469713
Validation loss: 2.6381469174248604

Epoch: 5| Step: 2
Training loss: 1.3255667338140213
Validation loss: 2.578078171275847

Epoch: 5| Step: 3
Training loss: 1.4710827422375934
Validation loss: 2.7012104722154944

Epoch: 5| Step: 4
Training loss: 1.1796376299895928
Validation loss: 2.6801601730766014

Epoch: 5| Step: 5
Training loss: 1.562402569594177
Validation loss: 2.7909067540683306

Epoch: 5| Step: 6
Training loss: 1.3300476518856839
Validation loss: 2.694739054984795

Epoch: 5| Step: 7
Training loss: 1.247358821991437
Validation loss: 2.6838257276135136

Epoch: 5| Step: 8
Training loss: 1.4319920544377256
Validation loss: 2.709486075371685

Epoch: 5| Step: 9
Training loss: 1.332597360543138
Validation loss: 2.639743917518716

Epoch: 5| Step: 10
Training loss: 1.4620658882312867
Validation loss: 2.638628293159164

Epoch: 5| Step: 11
Training loss: 0.7959643003207502
Validation loss: 2.6110984113454285

Epoch: 137| Step: 0
Training loss: 1.3907518650435347
Validation loss: 2.562790873541364

Epoch: 5| Step: 1
Training loss: 1.156457109202678
Validation loss: 2.6005371562848625

Epoch: 5| Step: 2
Training loss: 2.2708459089671735
Validation loss: 2.627022611131567

Epoch: 5| Step: 3
Training loss: 1.2598612904264948
Validation loss: 2.627101049784478

Epoch: 5| Step: 4
Training loss: 1.4252823466277278
Validation loss: 2.6996061669946383

Epoch: 5| Step: 5
Training loss: 1.2849967880802609
Validation loss: 2.5433426722229684

Epoch: 5| Step: 6
Training loss: 1.8677646910005785
Validation loss: 2.569435600030701

Epoch: 5| Step: 7
Training loss: 1.3881751351060223
Validation loss: 2.6498252661096133

Epoch: 5| Step: 8
Training loss: 1.0872491832316953
Validation loss: 2.631572378499633

Epoch: 5| Step: 9
Training loss: 0.9759583091899241
Validation loss: 2.6268856072996387

Epoch: 5| Step: 10
Training loss: 1.5325995745521261
Validation loss: 2.6099629187172586

Epoch: 5| Step: 11
Training loss: 0.6630965668805285
Validation loss: 2.5858655652569755

Epoch: 138| Step: 0
Training loss: 1.4056416361202972
Validation loss: 2.6300865384346

Epoch: 5| Step: 1
Training loss: 1.502106141628405
Validation loss: 2.691376025690418

Epoch: 5| Step: 2
Training loss: 1.1099322893780905
Validation loss: 2.602368689060339

Epoch: 5| Step: 3
Training loss: 1.9285656219980334
Validation loss: 2.6768966150787943

Epoch: 5| Step: 4
Training loss: 1.1530135971882132
Validation loss: 2.6719635842791356

Epoch: 5| Step: 5
Training loss: 0.7963265420244341
Validation loss: 2.6726684358912407

Epoch: 5| Step: 6
Training loss: 1.4408877714399737
Validation loss: 2.5892003843970492

Epoch: 5| Step: 7
Training loss: 1.5798993852424983
Validation loss: 2.6727559977701922

Epoch: 5| Step: 8
Training loss: 1.0797291859420006
Validation loss: 2.663304706834612

Epoch: 5| Step: 9
Training loss: 1.4479672356792421
Validation loss: 2.6131524632551253

Epoch: 5| Step: 10
Training loss: 1.8055547966914742
Validation loss: 2.6287000668799267

Epoch: 5| Step: 11
Training loss: 0.9966396855260696
Validation loss: 2.590810239647433

Epoch: 139| Step: 0
Training loss: 1.3574806255552727
Validation loss: 2.7371609727538226

Epoch: 5| Step: 1
Training loss: 0.9681509380670751
Validation loss: 2.6548642115223258

Epoch: 5| Step: 2
Training loss: 1.2276778768562235
Validation loss: 2.6902358597423195

Epoch: 5| Step: 3
Training loss: 1.437723971623953
Validation loss: 2.580102306775325

Epoch: 5| Step: 4
Training loss: 1.0682650843545576
Validation loss: 2.6688170045694477

Epoch: 5| Step: 5
Training loss: 1.1387843604823786
Validation loss: 2.603330421967126

Epoch: 5| Step: 6
Training loss: 1.522616355847032
Validation loss: 2.615233581102216

Epoch: 5| Step: 7
Training loss: 1.9866601597062807
Validation loss: 2.600651804058496

Epoch: 5| Step: 8
Training loss: 1.116957313992405
Validation loss: 2.654107666008607

Epoch: 5| Step: 9
Training loss: 1.3555234958465505
Validation loss: 2.637526769336488

Epoch: 5| Step: 10
Training loss: 1.5481083124498802
Validation loss: 2.5953364021108545

Epoch: 5| Step: 11
Training loss: 1.7611326608766709
Validation loss: 2.6041239976566213

Epoch: 140| Step: 0
Training loss: 1.919247575788916
Validation loss: 2.604118016106432

Epoch: 5| Step: 1
Training loss: 1.380829806732911
Validation loss: 2.6585044232283184

Epoch: 5| Step: 2
Training loss: 1.5784941892954971
Validation loss: 2.5873973294711234

Epoch: 5| Step: 3
Training loss: 1.3642552784682533
Validation loss: 2.6779570761684957

Epoch: 5| Step: 4
Training loss: 1.4643324302903855
Validation loss: 2.6083102042926702

Epoch: 5| Step: 5
Training loss: 0.9791438052707817
Validation loss: 2.6439673208943053

Epoch: 5| Step: 6
Training loss: 1.5553199593440052
Validation loss: 2.6999384743544583

Epoch: 5| Step: 7
Training loss: 1.1547088146178202
Validation loss: 2.6117095554565384

Epoch: 5| Step: 8
Training loss: 1.681969941577107
Validation loss: 2.6300336433538423

Epoch: 5| Step: 9
Training loss: 1.245175492660606
Validation loss: 2.663832530576957

Epoch: 5| Step: 10
Training loss: 1.0492405710912367
Validation loss: 2.650987266077295

Epoch: 5| Step: 11
Training loss: 1.4022726821955613
Validation loss: 2.6605438812646756

Epoch: 141| Step: 0
Training loss: 1.2239578679942877
Validation loss: 2.7614915854170263

Epoch: 5| Step: 1
Training loss: 1.233411002076244
Validation loss: 2.7639126370611544

Epoch: 5| Step: 2
Training loss: 1.8598090554742701
Validation loss: 2.7227217576525935

Epoch: 5| Step: 3
Training loss: 1.432403402882965
Validation loss: 2.6731557360560267

Epoch: 5| Step: 4
Training loss: 1.168578738144089
Validation loss: 2.7042120399743776

Epoch: 5| Step: 5
Training loss: 1.5312115411405192
Validation loss: 2.6733570152904087

Epoch: 5| Step: 6
Training loss: 1.266127215925536
Validation loss: 2.661695885305801

Epoch: 5| Step: 7
Training loss: 0.9608710971622499
Validation loss: 2.6068553332880544

Epoch: 5| Step: 8
Training loss: 1.4407567160544341
Validation loss: 2.581749372153897

Epoch: 5| Step: 9
Training loss: 1.8950148132469933
Validation loss: 2.651187418070624

Epoch: 5| Step: 10
Training loss: 1.3445117476898085
Validation loss: 2.6675917851078803

Epoch: 5| Step: 11
Training loss: 1.1125475155402202
Validation loss: 2.7023123840882075

Epoch: 142| Step: 0
Training loss: 0.9470769005985089
Validation loss: 2.6316306482954253

Epoch: 5| Step: 1
Training loss: 0.9418595358446692
Validation loss: 2.732457391354917

Epoch: 5| Step: 2
Training loss: 1.3718936249809037
Validation loss: 2.6878954611218577

Epoch: 5| Step: 3
Training loss: 1.5238153233659029
Validation loss: 2.725493122098217

Epoch: 5| Step: 4
Training loss: 1.250015067963382
Validation loss: 2.7313605595317916

Epoch: 5| Step: 5
Training loss: 1.7277170179108852
Validation loss: 2.7111731508349086

Epoch: 5| Step: 6
Training loss: 1.1069039238586824
Validation loss: 2.661223542419523

Epoch: 5| Step: 7
Training loss: 1.8645591592198385
Validation loss: 2.654888484801627

Epoch: 5| Step: 8
Training loss: 1.2115423353247374
Validation loss: 2.607663356538099

Epoch: 5| Step: 9
Training loss: 0.8382199936071677
Validation loss: 2.6610238727820943

Epoch: 5| Step: 10
Training loss: 1.4728184618263658
Validation loss: 2.7334116301332334

Epoch: 5| Step: 11
Training loss: 1.1158318464076016
Validation loss: 2.6205411462084616

Epoch: 143| Step: 0
Training loss: 1.2840835129148136
Validation loss: 2.6093315570131153

Epoch: 5| Step: 1
Training loss: 0.9277476420206806
Validation loss: 2.587788655893258

Epoch: 5| Step: 2
Training loss: 1.2394302284297107
Validation loss: 2.694087102851644

Epoch: 5| Step: 3
Training loss: 1.2889247473893417
Validation loss: 2.7940348406726314

Epoch: 5| Step: 4
Training loss: 1.7327769710107699
Validation loss: 2.7061725188360386

Epoch: 5| Step: 5
Training loss: 1.4441642530229977
Validation loss: 2.788136058563966

Epoch: 5| Step: 6
Training loss: 1.0306548510890365
Validation loss: 2.669801498635106

Epoch: 5| Step: 7
Training loss: 1.5099851934704929
Validation loss: 2.6589190107478258

Epoch: 5| Step: 8
Training loss: 1.3712901439371803
Validation loss: 2.6303813833334386

Epoch: 5| Step: 9
Training loss: 1.4086404192868718
Validation loss: 2.59508817691971

Epoch: 5| Step: 10
Training loss: 1.2593177649883813
Validation loss: 2.6360857319076327

Epoch: 5| Step: 11
Training loss: 1.3660563121710836
Validation loss: 2.671453424103295

Epoch: 144| Step: 0
Training loss: 1.4455333644060535
Validation loss: 2.686997041287276

Epoch: 5| Step: 1
Training loss: 1.2670817527439169
Validation loss: 2.659376514671961

Epoch: 5| Step: 2
Training loss: 1.4023020108527704
Validation loss: 2.6580297678435145

Epoch: 5| Step: 3
Training loss: 1.4551859361276185
Validation loss: 2.599892264359281

Epoch: 5| Step: 4
Training loss: 1.1128680616871833
Validation loss: 2.7071211810492755

Epoch: 5| Step: 5
Training loss: 1.339935833405254
Validation loss: 2.7602737293783366

Epoch: 5| Step: 6
Training loss: 1.0693419016493209
Validation loss: 2.6264151058864336

Epoch: 5| Step: 7
Training loss: 1.7138795683758647
Validation loss: 2.71942786100845

Epoch: 5| Step: 8
Training loss: 1.1192827650416144
Validation loss: 2.7038043019377596

Epoch: 5| Step: 9
Training loss: 1.4851792415502785
Validation loss: 2.711737218889349

Epoch: 5| Step: 10
Training loss: 1.4726525263650703
Validation loss: 2.7022927607247187

Epoch: 5| Step: 11
Training loss: 0.6721634134883397
Validation loss: 2.670282366995364

Epoch: 145| Step: 0
Training loss: 0.6126747290838668
Validation loss: 2.690086351146711

Epoch: 5| Step: 1
Training loss: 1.9013761530950344
Validation loss: 2.672170574354859

Epoch: 5| Step: 2
Training loss: 1.5896441360117346
Validation loss: 2.611966146713672

Epoch: 5| Step: 3
Training loss: 0.9193510969673592
Validation loss: 2.5553190751356785

Epoch: 5| Step: 4
Training loss: 1.6077987952060695
Validation loss: 2.6033334861511923

Epoch: 5| Step: 5
Training loss: 1.16682985844717
Validation loss: 2.6564190642464753

Epoch: 5| Step: 6
Training loss: 1.4189157397554932
Validation loss: 2.7102558367310676

Epoch: 5| Step: 7
Training loss: 0.9344578658392628
Validation loss: 2.6347700175066566

Epoch: 5| Step: 8
Training loss: 1.314623885378139
Validation loss: 2.6595587673264904

Epoch: 5| Step: 9
Training loss: 1.4930574767028908
Validation loss: 2.6690607251848206

Epoch: 5| Step: 10
Training loss: 1.0681287108524833
Validation loss: 2.72549749960091

Epoch: 5| Step: 11
Training loss: 0.5822718078375099
Validation loss: 2.6584505315933344

Epoch: 146| Step: 0
Training loss: 1.3078388826723975
Validation loss: 2.6937741704093914

Epoch: 5| Step: 1
Training loss: 1.1963693770871455
Validation loss: 2.703672699025336

Epoch: 5| Step: 2
Training loss: 1.058333811922541
Validation loss: 2.6603721945522496

Epoch: 5| Step: 3
Training loss: 0.8624324509526571
Validation loss: 2.6780532101742884

Epoch: 5| Step: 4
Training loss: 1.0164168572073942
Validation loss: 2.6400710546258708

Epoch: 5| Step: 5
Training loss: 1.259574461634506
Validation loss: 2.6592863455853952

Epoch: 5| Step: 6
Training loss: 1.9297316696733533
Validation loss: 2.6378272093159514

Epoch: 5| Step: 7
Training loss: 1.597828004740546
Validation loss: 2.6721191034481118

Epoch: 5| Step: 8
Training loss: 1.448973190191228
Validation loss: 2.624530572394732

Epoch: 5| Step: 9
Training loss: 1.333913463310729
Validation loss: 2.6950239496989328

Epoch: 5| Step: 10
Training loss: 1.1413913399455553
Validation loss: 2.645079487818284

Epoch: 5| Step: 11
Training loss: 0.7232735136965333
Validation loss: 2.728881006845786

Epoch: 147| Step: 0
Training loss: 1.3287427475337485
Validation loss: 2.641730925282866

Epoch: 5| Step: 1
Training loss: 1.42474729070692
Validation loss: 2.7464197326179898

Epoch: 5| Step: 2
Training loss: 1.1380396767925007
Validation loss: 2.6754144570326126

Epoch: 5| Step: 3
Training loss: 1.2004419109140108
Validation loss: 2.7033823144413107

Epoch: 5| Step: 4
Training loss: 1.843476485315286
Validation loss: 2.718217998646642

Epoch: 5| Step: 5
Training loss: 0.7369412164161684
Validation loss: 2.698367619967169

Epoch: 5| Step: 6
Training loss: 1.4201755638122917
Validation loss: 2.7024289633395386

Epoch: 5| Step: 7
Training loss: 1.6284378073426116
Validation loss: 2.617800239460506

Epoch: 5| Step: 8
Training loss: 0.8838512082669514
Validation loss: 2.647749624878591

Epoch: 5| Step: 9
Training loss: 1.0412016911651558
Validation loss: 2.665834693218702

Epoch: 5| Step: 10
Training loss: 1.0940487045032856
Validation loss: 2.6456889816515172

Epoch: 5| Step: 11
Training loss: 0.5720705604748043
Validation loss: 2.668750493885623

Epoch: 148| Step: 0
Training loss: 1.274845257886894
Validation loss: 2.659203331139772

Epoch: 5| Step: 1
Training loss: 1.1853986015798148
Validation loss: 2.6978615947881055

Epoch: 5| Step: 2
Training loss: 0.8570282538751968
Validation loss: 2.7339534034869626

Epoch: 5| Step: 3
Training loss: 1.0557529295605848
Validation loss: 2.716123839911381

Epoch: 5| Step: 4
Training loss: 2.136990768719711
Validation loss: 2.7358103990034097

Epoch: 5| Step: 5
Training loss: 1.7419423157462273
Validation loss: 2.73290462742107

Epoch: 5| Step: 6
Training loss: 1.0159852196038839
Validation loss: 2.7182257318532868

Epoch: 5| Step: 7
Training loss: 1.0556604489415489
Validation loss: 2.608384940111169

Epoch: 5| Step: 8
Training loss: 1.1760895283738437
Validation loss: 2.5930651599399908

Epoch: 5| Step: 9
Training loss: 1.317396431096792
Validation loss: 2.5858290362396663

Epoch: 5| Step: 10
Training loss: 1.1023688104648024
Validation loss: 2.665068817624888

Epoch: 5| Step: 11
Training loss: 1.047837284840549
Validation loss: 2.754185821555083

Epoch: 149| Step: 0
Training loss: 1.080354955146313
Validation loss: 2.668846425377415

Epoch: 5| Step: 1
Training loss: 1.571997654037084
Validation loss: 2.683886212696115

Epoch: 5| Step: 2
Training loss: 0.9985547947526335
Validation loss: 2.645140269261232

Epoch: 5| Step: 3
Training loss: 0.9708463689777531
Validation loss: 2.74751501442576

Epoch: 5| Step: 4
Training loss: 0.7986094728167403
Validation loss: 2.6134659303223153

Epoch: 5| Step: 5
Training loss: 1.4746373458129494
Validation loss: 2.58967547975223

Epoch: 5| Step: 6
Training loss: 1.1042189255829387
Validation loss: 2.644080442454801

Epoch: 5| Step: 7
Training loss: 1.8005736390627016
Validation loss: 2.685672519403404

Epoch: 5| Step: 8
Training loss: 1.308972659694665
Validation loss: 2.6164721199219363

Epoch: 5| Step: 9
Training loss: 0.9614120800152149
Validation loss: 2.7157021535339783

Epoch: 5| Step: 10
Training loss: 1.4607476095728107
Validation loss: 2.6837128155173624

Epoch: 5| Step: 11
Training loss: 0.3886013254517054
Validation loss: 2.6599145220225786

Epoch: 150| Step: 0
Training loss: 1.3621473871019016
Validation loss: 2.7346064478695404

Epoch: 5| Step: 1
Training loss: 1.1532253707581155
Validation loss: 2.635576003363026

Epoch: 5| Step: 2
Training loss: 1.910155750734853
Validation loss: 2.7100013120467423

Epoch: 5| Step: 3
Training loss: 1.0031273933928746
Validation loss: 2.632526778386522

Epoch: 5| Step: 4
Training loss: 1.2689013517708214
Validation loss: 2.6897081057098755

Epoch: 5| Step: 5
Training loss: 1.3701632567400661
Validation loss: 2.7269254222483297

Epoch: 5| Step: 6
Training loss: 1.2813820189403882
Validation loss: 2.7243100274192695

Epoch: 5| Step: 7
Training loss: 0.8301131297191797
Validation loss: 2.712212369980391

Epoch: 5| Step: 8
Training loss: 1.1649800211294343
Validation loss: 2.716369368564542

Epoch: 5| Step: 9
Training loss: 0.8659052949311108
Validation loss: 2.6573790712435885

Epoch: 5| Step: 10
Training loss: 1.0039266740079515
Validation loss: 2.7130671078260553

Epoch: 5| Step: 11
Training loss: 0.7344203691468932
Validation loss: 2.753035409013063

Epoch: 151| Step: 0
Training loss: 0.9535469621996486
Validation loss: 2.6509308270339655

Epoch: 5| Step: 1
Training loss: 1.3691245171963933
Validation loss: 2.6326651338562503

Epoch: 5| Step: 2
Training loss: 0.8011093583957136
Validation loss: 2.747504716978458

Epoch: 5| Step: 3
Training loss: 0.6617711196227085
Validation loss: 2.7170134402522867

Epoch: 5| Step: 4
Training loss: 1.4459227227419873
Validation loss: 2.733029446824862

Epoch: 5| Step: 5
Training loss: 1.1463905309062445
Validation loss: 2.667239423178267

Epoch: 5| Step: 6
Training loss: 0.9083621962508329
Validation loss: 2.7481262585982145

Epoch: 5| Step: 7
Training loss: 2.0599735854594172
Validation loss: 2.6757456310713787

Epoch: 5| Step: 8
Training loss: 1.2035563797877098
Validation loss: 2.7292192881124224

Epoch: 5| Step: 9
Training loss: 1.4724363775060785
Validation loss: 2.6965543051625462

Epoch: 5| Step: 10
Training loss: 0.8075924630860609
Validation loss: 2.6724894599718603

Epoch: 5| Step: 11
Training loss: 1.399206536099679
Validation loss: 2.689314170762355

Epoch: 152| Step: 0
Training loss: 1.8491989050873279
Validation loss: 2.6875563955673774

Epoch: 5| Step: 1
Training loss: 1.060767893654436
Validation loss: 2.803102773452807

Epoch: 5| Step: 2
Training loss: 1.1663202498070002
Validation loss: 2.8110258194918147

Epoch: 5| Step: 3
Training loss: 1.12457553485335
Validation loss: 2.673871244570957

Epoch: 5| Step: 4
Training loss: 1.2687292294610792
Validation loss: 2.6911864926885665

Epoch: 5| Step: 5
Training loss: 1.4349206921131283
Validation loss: 2.706094136496051

Epoch: 5| Step: 6
Training loss: 1.1087804463710116
Validation loss: 2.660193793600912

Epoch: 5| Step: 7
Training loss: 0.8371973971372442
Validation loss: 2.6939464442882395

Epoch: 5| Step: 8
Training loss: 0.8296503737596916
Validation loss: 2.703834883321107

Epoch: 5| Step: 9
Training loss: 1.2895918712836616
Validation loss: 2.687795617234947

Epoch: 5| Step: 10
Training loss: 1.0946644366396896
Validation loss: 2.6373872978453714

Epoch: 5| Step: 11
Training loss: 0.449737978521715
Validation loss: 2.741931798303312

Epoch: 153| Step: 0
Training loss: 1.3064961945178688
Validation loss: 2.6889012291511687

Epoch: 5| Step: 1
Training loss: 1.260182345759253
Validation loss: 2.7448348790530637

Epoch: 5| Step: 2
Training loss: 1.1615133343775652
Validation loss: 2.7198439658922355

Epoch: 5| Step: 3
Training loss: 0.48063594731238835
Validation loss: 2.547986823483566

Epoch: 5| Step: 4
Training loss: 0.9808344671868896
Validation loss: 2.6151550144179647

Epoch: 5| Step: 5
Training loss: 1.107754396709239
Validation loss: 2.6789019650165162

Epoch: 5| Step: 6
Training loss: 1.2903050300823533
Validation loss: 2.6878353249770415

Epoch: 5| Step: 7
Training loss: 1.1815852380808012
Validation loss: 2.6478840297445423

Epoch: 5| Step: 8
Training loss: 1.0918127069024868
Validation loss: 2.761759076505242

Epoch: 5| Step: 9
Training loss: 1.9051552427419514
Validation loss: 2.6553492421268956

Epoch: 5| Step: 10
Training loss: 0.87126048592123
Validation loss: 2.7204387104541414

Epoch: 5| Step: 11
Training loss: 0.7279898456661785
Validation loss: 2.6767590038097895

Epoch: 154| Step: 0
Training loss: 1.9887408791362273
Validation loss: 2.756629675782661

Epoch: 5| Step: 1
Training loss: 1.0357531859698546
Validation loss: 2.7080199219242282

Epoch: 5| Step: 2
Training loss: 1.3795505563722466
Validation loss: 2.6872845533790275

Epoch: 5| Step: 3
Training loss: 1.154202684926103
Validation loss: 2.737951199842979

Epoch: 5| Step: 4
Training loss: 0.7845082811899535
Validation loss: 2.6557348499784665

Epoch: 5| Step: 5
Training loss: 1.0456184133446476
Validation loss: 2.6765580175228263

Epoch: 5| Step: 6
Training loss: 1.164620643295585
Validation loss: 2.676342747937284

Epoch: 5| Step: 7
Training loss: 1.139869125951789
Validation loss: 2.6831741078939797

Epoch: 5| Step: 8
Training loss: 1.131057906306803
Validation loss: 2.68771712586744

Epoch: 5| Step: 9
Training loss: 1.0885225990973855
Validation loss: 2.70276715182988

Epoch: 5| Step: 10
Training loss: 0.9963677721279453
Validation loss: 2.686224013531695

Epoch: 5| Step: 11
Training loss: 0.41995576233860143
Validation loss: 2.702301789401228

Epoch: 155| Step: 0
Training loss: 1.7000578113150606
Validation loss: 2.7461753279613883

Epoch: 5| Step: 1
Training loss: 0.9957602148200118
Validation loss: 2.7408671737148356

Epoch: 5| Step: 2
Training loss: 1.006857841246041
Validation loss: 2.7104116583935975

Epoch: 5| Step: 3
Training loss: 1.1695188105042043
Validation loss: 2.76469064363876

Epoch: 5| Step: 4
Training loss: 1.0055613844850693
Validation loss: 2.7009702300601752

Epoch: 5| Step: 5
Training loss: 1.0819672383127432
Validation loss: 2.666361472179214

Epoch: 5| Step: 6
Training loss: 1.1230989925067179
Validation loss: 2.6710443451038874

Epoch: 5| Step: 7
Training loss: 1.270265994563812
Validation loss: 2.7218585166037874

Epoch: 5| Step: 8
Training loss: 1.1862263123023418
Validation loss: 2.6609505369890334

Epoch: 5| Step: 9
Training loss: 0.8189880578284775
Validation loss: 2.663669236467118

Epoch: 5| Step: 10
Training loss: 1.0794451826700262
Validation loss: 2.605768909922636

Epoch: 5| Step: 11
Training loss: 1.0786009581014295
Validation loss: 2.68447041710175

Epoch: 156| Step: 0
Training loss: 1.4191299601877863
Validation loss: 2.675181998838278

Epoch: 5| Step: 1
Training loss: 0.868311351386837
Validation loss: 2.6638680179192926

Epoch: 5| Step: 2
Training loss: 0.703302954300927
Validation loss: 2.6544047397593915

Epoch: 5| Step: 3
Training loss: 0.7970006507095495
Validation loss: 2.5592035377429645

Epoch: 5| Step: 4
Training loss: 1.0836728309867492
Validation loss: 2.6835275352190253

Epoch: 5| Step: 5
Training loss: 1.5280946412610565
Validation loss: 2.7582851685662706

Epoch: 5| Step: 6
Training loss: 1.3045391066900942
Validation loss: 2.7662978494271915

Epoch: 5| Step: 7
Training loss: 1.9164884180305688
Validation loss: 2.70890814965711

Epoch: 5| Step: 8
Training loss: 0.9076734741699076
Validation loss: 2.7126464660642697

Epoch: 5| Step: 9
Training loss: 0.9950492319071026
Validation loss: 2.744624195503156

Epoch: 5| Step: 10
Training loss: 1.1946725565908483
Validation loss: 2.712868974423967

Epoch: 5| Step: 11
Training loss: 0.8834662253503746
Validation loss: 2.5989838766449442

Epoch: 157| Step: 0
Training loss: 1.2552871468310132
Validation loss: 2.587172398737192

Epoch: 5| Step: 1
Training loss: 0.8653908409400086
Validation loss: 2.639043616616338

Epoch: 5| Step: 2
Training loss: 0.9215095571559464
Validation loss: 2.6303497194618823

Epoch: 5| Step: 3
Training loss: 1.7433832281909576
Validation loss: 2.6732588190489612

Epoch: 5| Step: 4
Training loss: 1.167420427604472
Validation loss: 2.7931903493330834

Epoch: 5| Step: 5
Training loss: 0.7686792682269283
Validation loss: 2.683882222595583

Epoch: 5| Step: 6
Training loss: 1.2051749661947249
Validation loss: 2.7691688174907982

Epoch: 5| Step: 7
Training loss: 0.5724848825216171
Validation loss: 2.780009160792857

Epoch: 5| Step: 8
Training loss: 0.9818587765485517
Validation loss: 2.717122690759794

Epoch: 5| Step: 9
Training loss: 1.0149861600712142
Validation loss: 2.7173324631111515

Epoch: 5| Step: 10
Training loss: 0.7650505168292017
Validation loss: 2.708203596284448

Epoch: 5| Step: 11
Training loss: 2.4007058615598926
Validation loss: 2.6606325123712007

Epoch: 158| Step: 0
Training loss: 1.090441140140858
Validation loss: 2.6969887538183217

Epoch: 5| Step: 1
Training loss: 1.1313173094899533
Validation loss: 2.5980092088500895

Epoch: 5| Step: 2
Training loss: 0.8970375432117805
Validation loss: 2.67353215424399

Epoch: 5| Step: 3
Training loss: 0.8793526427159156
Validation loss: 2.6869532154592592

Epoch: 5| Step: 4
Training loss: 0.9924603485046818
Validation loss: 2.7110819159746287

Epoch: 5| Step: 5
Training loss: 1.088635174447824
Validation loss: 2.7260906026080143

Epoch: 5| Step: 6
Training loss: 1.341285485956303
Validation loss: 2.665378219552217

Epoch: 5| Step: 7
Training loss: 0.999969303136792
Validation loss: 2.7404016909065168

Epoch: 5| Step: 8
Training loss: 0.9696983494644933
Validation loss: 2.7003779040886364

Epoch: 5| Step: 9
Training loss: 1.8227138806129786
Validation loss: 2.6903257669547185

Epoch: 5| Step: 10
Training loss: 1.1270709579455878
Validation loss: 2.6613746500514166

Epoch: 5| Step: 11
Training loss: 1.1252749954664674
Validation loss: 2.6795072652484917

Epoch: 159| Step: 0
Training loss: 0.838016420538083
Validation loss: 2.7308217422147005

Epoch: 5| Step: 1
Training loss: 0.8085713775045984
Validation loss: 2.6850133155454694

Epoch: 5| Step: 2
Training loss: 1.172728215194361
Validation loss: 2.7010901883071794

Epoch: 5| Step: 3
Training loss: 0.8008873101686481
Validation loss: 2.699353267631951

Epoch: 5| Step: 4
Training loss: 1.844215463623904
Validation loss: 2.597853505382151

Epoch: 5| Step: 5
Training loss: 1.2098761060039465
Validation loss: 2.7434084928115854

Epoch: 5| Step: 6
Training loss: 0.9188622853698467
Validation loss: 2.7197333417405036

Epoch: 5| Step: 7
Training loss: 1.0160604863747265
Validation loss: 2.6389164523029254

Epoch: 5| Step: 8
Training loss: 1.2600748318445791
Validation loss: 2.690499402554728

Epoch: 5| Step: 9
Training loss: 0.8414722356539548
Validation loss: 2.7582523906467706

Epoch: 5| Step: 10
Training loss: 1.3778590908120107
Validation loss: 2.682121252306778

Epoch: 5| Step: 11
Training loss: 0.4102015515695668
Validation loss: 2.732652743050079

Epoch: 160| Step: 0
Training loss: 0.7460146158003624
Validation loss: 2.7195782843028065

Epoch: 5| Step: 1
Training loss: 1.222022382818413
Validation loss: 2.7227987893372774

Epoch: 5| Step: 2
Training loss: 1.607349491459562
Validation loss: 2.702442718866889

Epoch: 5| Step: 3
Training loss: 1.3057737568303303
Validation loss: 2.7252152875555837

Epoch: 5| Step: 4
Training loss: 1.0428538741379665
Validation loss: 2.643856993780519

Epoch: 5| Step: 5
Training loss: 1.0504075417481025
Validation loss: 2.6282863027670222

Epoch: 5| Step: 6
Training loss: 1.0508775631467349
Validation loss: 2.68698380562242

Epoch: 5| Step: 7
Training loss: 1.0893335276077856
Validation loss: 2.648018315242783

Epoch: 5| Step: 8
Training loss: 1.0230522304189367
Validation loss: 2.730904762190281

Epoch: 5| Step: 9
Training loss: 0.8121173030728676
Validation loss: 2.7040580561407497

Epoch: 5| Step: 10
Training loss: 1.1568670430623353
Validation loss: 2.883621023182276

Epoch: 5| Step: 11
Training loss: 0.2481769160816847
Validation loss: 2.8120848066667397

Epoch: 161| Step: 0
Training loss: 1.3337538870528691
Validation loss: 2.8253902328943097

Epoch: 5| Step: 1
Training loss: 0.8641465627329891
Validation loss: 2.8848887533273277

Epoch: 5| Step: 2
Training loss: 0.9545358315721773
Validation loss: 2.82706663093515

Epoch: 5| Step: 3
Training loss: 1.1736910671759064
Validation loss: 2.72612468188337

Epoch: 5| Step: 4
Training loss: 0.8918403230594122
Validation loss: 2.674115890202346

Epoch: 5| Step: 5
Training loss: 0.9398902304453217
Validation loss: 2.673083513532711

Epoch: 5| Step: 6
Training loss: 1.2124864085900613
Validation loss: 2.5850302995926495

Epoch: 5| Step: 7
Training loss: 1.2207109374750003
Validation loss: 2.680094340500109

Epoch: 5| Step: 8
Training loss: 1.7543029336563507
Validation loss: 2.7981780726574685

Epoch: 5| Step: 9
Training loss: 1.105377894465811
Validation loss: 2.6788093751850095

Epoch: 5| Step: 10
Training loss: 1.1469734877205373
Validation loss: 2.7914686589453734

Epoch: 5| Step: 11
Training loss: 0.28778469046604116
Validation loss: 2.6809293836838424

Epoch: 162| Step: 0
Training loss: 0.7252144562125709
Validation loss: 2.759212869595091

Epoch: 5| Step: 1
Training loss: 0.9773725583155384
Validation loss: 2.6137821019763123

Epoch: 5| Step: 2
Training loss: 1.7802462510352188
Validation loss: 2.7102189847873848

Epoch: 5| Step: 3
Training loss: 1.0394409752400544
Validation loss: 2.7986273470603007

Epoch: 5| Step: 4
Training loss: 1.0111121638494003
Validation loss: 2.7633201528076867

Epoch: 5| Step: 5
Training loss: 1.070882826278584
Validation loss: 2.824348939152276

Epoch: 5| Step: 6
Training loss: 0.7087741676798497
Validation loss: 2.706698780276458

Epoch: 5| Step: 7
Training loss: 0.9208829682265487
Validation loss: 2.6952363671501534

Epoch: 5| Step: 8
Training loss: 0.9543216260213476
Validation loss: 2.744443811069275

Epoch: 5| Step: 9
Training loss: 1.1498542921389343
Validation loss: 2.6434394539805064

Epoch: 5| Step: 10
Training loss: 1.1273644290119285
Validation loss: 2.7901250416298353

Epoch: 5| Step: 11
Training loss: 0.9186175062699505
Validation loss: 2.6782474633745523

Epoch: 163| Step: 0
Training loss: 1.136334908295675
Validation loss: 2.6475056684695693

Epoch: 5| Step: 1
Training loss: 1.723091468415595
Validation loss: 2.725988843262965

Epoch: 5| Step: 2
Training loss: 0.9183195701809338
Validation loss: 2.6425478271642175

Epoch: 5| Step: 3
Training loss: 1.1178303183014477
Validation loss: 2.700486444433947

Epoch: 5| Step: 4
Training loss: 0.9272130525396008
Validation loss: 2.638291979854424

Epoch: 5| Step: 5
Training loss: 1.1198303866530508
Validation loss: 2.903160928285562

Epoch: 5| Step: 6
Training loss: 1.0727218463397503
Validation loss: 2.819581205567266

Epoch: 5| Step: 7
Training loss: 1.0253767902712532
Validation loss: 2.8188610621731063

Epoch: 5| Step: 8
Training loss: 0.9536201566652428
Validation loss: 2.76207947702024

Epoch: 5| Step: 9
Training loss: 0.8441866698410325
Validation loss: 2.7376935167586365

Epoch: 5| Step: 10
Training loss: 0.930092186563154
Validation loss: 2.6370983839476994

Epoch: 5| Step: 11
Training loss: 0.6289723521495394
Validation loss: 2.696732063380685

Epoch: 164| Step: 0
Training loss: 1.0070915304746557
Validation loss: 2.7866082171952584

Epoch: 5| Step: 1
Training loss: 1.038096387492969
Validation loss: 2.7030009092392207

Epoch: 5| Step: 2
Training loss: 1.0173391109050849
Validation loss: 2.716507761692048

Epoch: 5| Step: 3
Training loss: 0.8697567930863622
Validation loss: 2.6870440236739412

Epoch: 5| Step: 4
Training loss: 1.0292536746374825
Validation loss: 2.661491133804407

Epoch: 5| Step: 5
Training loss: 1.1969843622746157
Validation loss: 2.700289770018243

Epoch: 5| Step: 6
Training loss: 1.1306977098828574
Validation loss: 2.7092421999617793

Epoch: 5| Step: 7
Training loss: 1.0823212383049903
Validation loss: 2.8087074988918044

Epoch: 5| Step: 8
Training loss: 1.7562637627221882
Validation loss: 2.88236028334311

Epoch: 5| Step: 9
Training loss: 1.0300193147792711
Validation loss: 2.812372522644067

Epoch: 5| Step: 10
Training loss: 1.056158890265194
Validation loss: 2.833883061559946

Epoch: 5| Step: 11
Training loss: 2.2541626465409603
Validation loss: 2.761575352508381

Epoch: 165| Step: 0
Training loss: 1.0469159360255182
Validation loss: 2.652975775839714

Epoch: 5| Step: 1
Training loss: 0.9790118818838155
Validation loss: 2.6932931863767746

Epoch: 5| Step: 2
Training loss: 1.2123242221325932
Validation loss: 2.8075704182585572

Epoch: 5| Step: 3
Training loss: 1.508278809224067
Validation loss: 2.7362576170865114

Epoch: 5| Step: 4
Training loss: 1.0031572806134774
Validation loss: 2.7658181778562567

Epoch: 5| Step: 5
Training loss: 1.1148670881110165
Validation loss: 2.6256377868292553

Epoch: 5| Step: 6
Training loss: 1.3761428071979347
Validation loss: 2.715428230435065

Epoch: 5| Step: 7
Training loss: 0.7216729975533546
Validation loss: 2.870303083614436

Epoch: 5| Step: 8
Training loss: 0.9945164178190244
Validation loss: 2.867785232977981

Epoch: 5| Step: 9
Training loss: 1.6713779459262534
Validation loss: 2.906959057521244

Epoch: 5| Step: 10
Training loss: 1.0196944066011633
Validation loss: 2.9639417526862095

Epoch: 5| Step: 11
Training loss: 0.603450932168047
Validation loss: 2.968519653619566

Epoch: 166| Step: 0
Training loss: 1.3532125290539
Validation loss: 2.8664860226764874

Epoch: 5| Step: 1
Training loss: 1.9870811092945253
Validation loss: 2.8003910135112897

Epoch: 5| Step: 2
Training loss: 0.8269781412513169
Validation loss: 2.787086545533937

Epoch: 5| Step: 3
Training loss: 0.833989306397342
Validation loss: 2.6452945901647866

Epoch: 5| Step: 4
Training loss: 0.8825763622886639
Validation loss: 2.663201495933122

Epoch: 5| Step: 5
Training loss: 0.7641159288569039
Validation loss: 2.6909570157568274

Epoch: 5| Step: 6
Training loss: 0.8200832228180974
Validation loss: 2.671271934639379

Epoch: 5| Step: 7
Training loss: 0.8505186279853842
Validation loss: 2.684416365832105

Epoch: 5| Step: 8
Training loss: 0.9209971369969108
Validation loss: 2.634240684690233

Epoch: 5| Step: 9
Training loss: 0.91935845552725
Validation loss: 2.6959970535569737

Epoch: 5| Step: 10
Training loss: 0.966848013710246
Validation loss: 2.636418741371781

Epoch: 5| Step: 11
Training loss: 1.212516935957777
Validation loss: 2.750788712827712

Epoch: 167| Step: 0
Training loss: 0.8678807760818661
Validation loss: 2.7213651824192824

Epoch: 5| Step: 1
Training loss: 1.086084589156041
Validation loss: 2.7335556437542037

Epoch: 5| Step: 2
Training loss: 0.8710973423084035
Validation loss: 2.8363782051602584

Epoch: 5| Step: 3
Training loss: 0.9517355938405574
Validation loss: 2.7970503427109468

Epoch: 5| Step: 4
Training loss: 0.9425849974374215
Validation loss: 2.8191397034538435

Epoch: 5| Step: 5
Training loss: 1.1403405344290691
Validation loss: 2.703155730556085

Epoch: 5| Step: 6
Training loss: 1.06861955170063
Validation loss: 2.737142241628926

Epoch: 5| Step: 7
Training loss: 0.6714547639523695
Validation loss: 2.767140022012693

Epoch: 5| Step: 8
Training loss: 1.0998622678012617
Validation loss: 2.682791329420478

Epoch: 5| Step: 9
Training loss: 1.015337918128643
Validation loss: 2.7261275060129293

Epoch: 5| Step: 10
Training loss: 1.6236134262148223
Validation loss: 2.70521303063123

Epoch: 5| Step: 11
Training loss: 1.0557220471290596
Validation loss: 2.6541819637632282

Epoch: 168| Step: 0
Training loss: 0.7396507680174781
Validation loss: 2.7907668782129633

Epoch: 5| Step: 1
Training loss: 1.6673549264142344
Validation loss: 2.746122666663867

Epoch: 5| Step: 2
Training loss: 0.5616724761875627
Validation loss: 2.7373617445059257

Epoch: 5| Step: 3
Training loss: 0.8671867439335457
Validation loss: 2.825100836177952

Epoch: 5| Step: 4
Training loss: 1.0703770973036226
Validation loss: 2.731486446001339

Epoch: 5| Step: 5
Training loss: 1.0676868839745592
Validation loss: 2.825274659198637

Epoch: 5| Step: 6
Training loss: 0.9518254284840781
Validation loss: 2.8228982183456544

Epoch: 5| Step: 7
Training loss: 1.0000732514255433
Validation loss: 2.691907071124108

Epoch: 5| Step: 8
Training loss: 0.9544436603822203
Validation loss: 2.7225342937139296

Epoch: 5| Step: 9
Training loss: 0.5353937109492691
Validation loss: 2.721736754517316

Epoch: 5| Step: 10
Training loss: 1.04262459895409
Validation loss: 2.7002391809322632

Epoch: 5| Step: 11
Training loss: 0.5142359084561733
Validation loss: 2.732474914864921

Epoch: 169| Step: 0
Training loss: 0.7027087144900601
Validation loss: 2.679578057844825

Epoch: 5| Step: 1
Training loss: 0.9127469499422642
Validation loss: 2.6979764111849485

Epoch: 5| Step: 2
Training loss: 1.1000194157707543
Validation loss: 2.621670977293263

Epoch: 5| Step: 3
Training loss: 0.7792535067085616
Validation loss: 2.750937305730515

Epoch: 5| Step: 4
Training loss: 1.9153292454083841
Validation loss: 2.724237430757522

Epoch: 5| Step: 5
Training loss: 0.9331616155718538
Validation loss: 2.715715530899926

Epoch: 5| Step: 6
Training loss: 0.9275759913117081
Validation loss: 2.7877851494314556

Epoch: 5| Step: 7
Training loss: 0.8623598454807216
Validation loss: 2.808243387906209

Epoch: 5| Step: 8
Training loss: 0.8088545816243997
Validation loss: 2.7137693332830963

Epoch: 5| Step: 9
Training loss: 0.7389303915976856
Validation loss: 2.712594532674413

Epoch: 5| Step: 10
Training loss: 1.0476304929384679
Validation loss: 2.7109568299292373

Epoch: 5| Step: 11
Training loss: 0.8253404839482732
Validation loss: 2.594395756287338

Epoch: 170| Step: 0
Training loss: 0.7259647412552533
Validation loss: 2.7316660732162354

Epoch: 5| Step: 1
Training loss: 0.7472383596867109
Validation loss: 2.7452852190254737

Epoch: 5| Step: 2
Training loss: 1.3169969993389128
Validation loss: 2.782329981854394

Epoch: 5| Step: 3
Training loss: 0.9731843426298998
Validation loss: 2.7678684216077625

Epoch: 5| Step: 4
Training loss: 0.7943067115226395
Validation loss: 2.7992568573916135

Epoch: 5| Step: 5
Training loss: 0.9467104199085976
Validation loss: 2.731679059654722

Epoch: 5| Step: 6
Training loss: 0.7815847823952552
Validation loss: 2.797357485620851

Epoch: 5| Step: 7
Training loss: 0.7857247567098368
Validation loss: 2.7054394495588494

Epoch: 5| Step: 8
Training loss: 1.492775127285654
Validation loss: 2.755625995403066

Epoch: 5| Step: 9
Training loss: 0.9339863737652115
Validation loss: 2.839196576969643

Epoch: 5| Step: 10
Training loss: 1.1924625904285355
Validation loss: 2.9519147966598993

Epoch: 5| Step: 11
Training loss: 1.279870756300038
Validation loss: 2.806251744933177

Epoch: 171| Step: 0
Training loss: 0.9191064156238747
Validation loss: 2.732702154073214

Epoch: 5| Step: 1
Training loss: 0.6875330093435489
Validation loss: 2.7651353427731524

Epoch: 5| Step: 2
Training loss: 0.8210998752703077
Validation loss: 2.7252882791848503

Epoch: 5| Step: 3
Training loss: 1.011007581872932
Validation loss: 2.682663942940311

Epoch: 5| Step: 4
Training loss: 1.0216192152839003
Validation loss: 2.7408731721557733

Epoch: 5| Step: 5
Training loss: 1.782895181729544
Validation loss: 2.757925155543209

Epoch: 5| Step: 6
Training loss: 0.7156881962487053
Validation loss: 2.6935688699894706

Epoch: 5| Step: 7
Training loss: 0.9164359748878113
Validation loss: 2.709576568379982

Epoch: 5| Step: 8
Training loss: 1.001283775264734
Validation loss: 2.761763277823449

Epoch: 5| Step: 9
Training loss: 1.3082833904201923
Validation loss: 2.7688088849237698

Epoch: 5| Step: 10
Training loss: 0.8874149698169639
Validation loss: 2.8060956942268356

Epoch: 5| Step: 11
Training loss: 1.5869942137210693
Validation loss: 2.7283746714354753

Epoch: 172| Step: 0
Training loss: 0.7760899078599671
Validation loss: 2.7623948776301197

Epoch: 5| Step: 1
Training loss: 0.956014038094596
Validation loss: 2.7412127186880744

Epoch: 5| Step: 2
Training loss: 0.8500350061388823
Validation loss: 2.7192759644531126

Epoch: 5| Step: 3
Training loss: 0.8360989494924854
Validation loss: 2.718370217438128

Epoch: 5| Step: 4
Training loss: 1.6218507768589783
Validation loss: 2.7502083049256236

Epoch: 5| Step: 5
Training loss: 1.1257610925462136
Validation loss: 2.6891489514867843

Epoch: 5| Step: 6
Training loss: 0.8030532240799866
Validation loss: 2.8250111496685633

Epoch: 5| Step: 7
Training loss: 0.9276977853084707
Validation loss: 2.853596551484335

Epoch: 5| Step: 8
Training loss: 0.9927659038383185
Validation loss: 2.901138342862221

Epoch: 5| Step: 9
Training loss: 1.0693784104364747
Validation loss: 2.7982651968967387

Epoch: 5| Step: 10
Training loss: 1.3190137355369795
Validation loss: 2.8368648627649775

Epoch: 5| Step: 11
Training loss: 0.2340218267256422
Validation loss: 2.754106349303818

Epoch: 173| Step: 0
Training loss: 0.826796852161559
Validation loss: 2.780602151089908

Epoch: 5| Step: 1
Training loss: 0.9080282719785779
Validation loss: 2.692563683309546

Epoch: 5| Step: 2
Training loss: 0.8018919150753017
Validation loss: 2.7803375840589246

Epoch: 5| Step: 3
Training loss: 0.8108555952690277
Validation loss: 2.718138476177768

Epoch: 5| Step: 4
Training loss: 1.0698233273187752
Validation loss: 2.7502691288950243

Epoch: 5| Step: 5
Training loss: 0.7125378297500566
Validation loss: 2.668719441598508

Epoch: 5| Step: 6
Training loss: 0.9771156575455501
Validation loss: 2.801112685196385

Epoch: 5| Step: 7
Training loss: 1.6253014798369279
Validation loss: 2.7003871157484642

Epoch: 5| Step: 8
Training loss: 0.938360296345329
Validation loss: 2.8081902756651047

Epoch: 5| Step: 9
Training loss: 0.8666435804104325
Validation loss: 2.7916452611036138

Epoch: 5| Step: 10
Training loss: 1.022227904717458
Validation loss: 2.7784727496099753

Epoch: 5| Step: 11
Training loss: 0.7598065755050992
Validation loss: 2.74922742250561

Epoch: 174| Step: 0
Training loss: 1.6376317648253276
Validation loss: 2.7242206984449995

Epoch: 5| Step: 1
Training loss: 0.7724779901177571
Validation loss: 2.6172499388273502

Epoch: 5| Step: 2
Training loss: 1.1191215580086604
Validation loss: 2.7617533860109735

Epoch: 5| Step: 3
Training loss: 0.969566647039439
Validation loss: 2.6955963501298474

Epoch: 5| Step: 4
Training loss: 0.6753673278073459
Validation loss: 2.7490836336220363

Epoch: 5| Step: 5
Training loss: 0.9291176532140301
Validation loss: 2.691898727206138

Epoch: 5| Step: 6
Training loss: 0.7343112836751882
Validation loss: 2.6874138759149955

Epoch: 5| Step: 7
Training loss: 1.1803187519258374
Validation loss: 2.6924531853884996

Epoch: 5| Step: 8
Training loss: 0.9305840665014392
Validation loss: 2.656292344672079

Epoch: 5| Step: 9
Training loss: 0.7686612395861167
Validation loss: 2.7415919150700687

Epoch: 5| Step: 10
Training loss: 0.7272579187543647
Validation loss: 2.6804922580383046

Epoch: 5| Step: 11
Training loss: 0.4384301719678485
Validation loss: 2.687575232022049

Epoch: 175| Step: 0
Training loss: 0.8983444165647217
Validation loss: 2.7742799831469576

Epoch: 5| Step: 1
Training loss: 0.8385721915871256
Validation loss: 2.7785524259036074

Epoch: 5| Step: 2
Training loss: 1.1454653524739462
Validation loss: 2.7790871043066767

Epoch: 5| Step: 3
Training loss: 0.6379712195795915
Validation loss: 2.6986885819860658

Epoch: 5| Step: 4
Training loss: 0.7309465528614977
Validation loss: 2.5816681837943904

Epoch: 5| Step: 5
Training loss: 0.812949459764266
Validation loss: 2.6641014111195154

Epoch: 5| Step: 6
Training loss: 1.6842013012953387
Validation loss: 2.7303613578840835

Epoch: 5| Step: 7
Training loss: 0.7447135101783279
Validation loss: 2.6535611287312992

Epoch: 5| Step: 8
Training loss: 0.9771625658836595
Validation loss: 2.7546890553055134

Epoch: 5| Step: 9
Training loss: 0.8069397969603597
Validation loss: 2.7150094363655697

Epoch: 5| Step: 10
Training loss: 0.9190366985353194
Validation loss: 2.7249414567462447

Epoch: 5| Step: 11
Training loss: 0.6043010649877971
Validation loss: 2.8092676449844745

Epoch: 176| Step: 0
Training loss: 1.0776937976925927
Validation loss: 2.7848141260802217

Epoch: 5| Step: 1
Training loss: 0.8278205599883889
Validation loss: 2.8065976374304396

Epoch: 5| Step: 2
Training loss: 0.6342975005367468
Validation loss: 2.691201990770992

Epoch: 5| Step: 3
Training loss: 0.9702191441540955
Validation loss: 2.8216468106224823

Epoch: 5| Step: 4
Training loss: 0.9674843549818801
Validation loss: 2.7825315001956206

Epoch: 5| Step: 5
Training loss: 1.5480254547924277
Validation loss: 2.840387385900446

Epoch: 5| Step: 6
Training loss: 0.6663420204612808
Validation loss: 2.6590253990897503

Epoch: 5| Step: 7
Training loss: 0.6369534159518957
Validation loss: 2.801803079697917

Epoch: 5| Step: 8
Training loss: 1.0049763479343838
Validation loss: 2.7399719939227625

Epoch: 5| Step: 9
Training loss: 0.5540279174098547
Validation loss: 2.738289057148657

Epoch: 5| Step: 10
Training loss: 0.84308704186147
Validation loss: 2.7085808579723336

Epoch: 5| Step: 11
Training loss: 0.298813663706202
Validation loss: 2.722335833062309

Epoch: 177| Step: 0
Training loss: 1.6381920349540346
Validation loss: 2.7241567839669525

Epoch: 5| Step: 1
Training loss: 1.0568510117563474
Validation loss: 2.800524488355311

Epoch: 5| Step: 2
Training loss: 0.7913901113689111
Validation loss: 2.804770798716868

Epoch: 5| Step: 3
Training loss: 0.7680534463554181
Validation loss: 2.699177879248572

Epoch: 5| Step: 4
Training loss: 0.8864653305034557
Validation loss: 2.7079764399985082

Epoch: 5| Step: 5
Training loss: 0.9345758292454892
Validation loss: 2.6999653631508225

Epoch: 5| Step: 6
Training loss: 0.7631266957732034
Validation loss: 2.8488676915693962

Epoch: 5| Step: 7
Training loss: 0.765881203582877
Validation loss: 2.693701213622057

Epoch: 5| Step: 8
Training loss: 0.9967647611119679
Validation loss: 2.7249264659059285

Epoch: 5| Step: 9
Training loss: 0.9905970885378995
Validation loss: 2.8001534411416964

Epoch: 5| Step: 10
Training loss: 0.8121211562556718
Validation loss: 2.7148472554941208

Epoch: 5| Step: 11
Training loss: 0.613928143894158
Validation loss: 2.855696808648319

Epoch: 178| Step: 0
Training loss: 0.7576231965832
Validation loss: 2.7374363610231383

Epoch: 5| Step: 1
Training loss: 0.762921366973126
Validation loss: 2.7674688597193273

Epoch: 5| Step: 2
Training loss: 0.8226822909646913
Validation loss: 2.6890068893696655

Epoch: 5| Step: 3
Training loss: 0.8879064596285522
Validation loss: 2.71991288501708

Epoch: 5| Step: 4
Training loss: 1.5346849800451148
Validation loss: 2.7017054220489345

Epoch: 5| Step: 5
Training loss: 1.0392594688558614
Validation loss: 2.7505199814973125

Epoch: 5| Step: 6
Training loss: 0.7746268866286572
Validation loss: 2.72326901735967

Epoch: 5| Step: 7
Training loss: 0.46540750249767004
Validation loss: 2.7773591518198595

Epoch: 5| Step: 8
Training loss: 1.0116131701666835
Validation loss: 2.72911481710981

Epoch: 5| Step: 9
Training loss: 1.0115003902493005
Validation loss: 2.878484390523479

Epoch: 5| Step: 10
Training loss: 1.148488880487271
Validation loss: 2.757815972488998

Epoch: 5| Step: 11
Training loss: 0.3642623941987322
Validation loss: 2.7661816203874703

Epoch: 179| Step: 0
Training loss: 0.6422908801844118
Validation loss: 2.7799188092723206

Epoch: 5| Step: 1
Training loss: 1.0387076438779
Validation loss: 2.69482431090914

Epoch: 5| Step: 2
Training loss: 1.5527870409209064
Validation loss: 2.7286527394872797

Epoch: 5| Step: 3
Training loss: 0.9430799998575341
Validation loss: 2.8297949053164864

Epoch: 5| Step: 4
Training loss: 0.7310758301767943
Validation loss: 2.676872290865887

Epoch: 5| Step: 5
Training loss: 0.617269389840278
Validation loss: 2.734300837646387

Epoch: 5| Step: 6
Training loss: 0.7284479186476116
Validation loss: 2.81986772335781

Epoch: 5| Step: 7
Training loss: 0.8641951543648739
Validation loss: 2.7216529110313474

Epoch: 5| Step: 8
Training loss: 0.7919250911414543
Validation loss: 2.831857469861287

Epoch: 5| Step: 9
Training loss: 0.8559424773924924
Validation loss: 2.734889387158132

Epoch: 5| Step: 10
Training loss: 1.1253925274478995
Validation loss: 2.7646752449046597

Epoch: 5| Step: 11
Training loss: 1.3360570664467315
Validation loss: 2.754689466418399

Epoch: 180| Step: 0
Training loss: 0.9204091524882624
Validation loss: 2.701010967030646

Epoch: 5| Step: 1
Training loss: 0.8790571295190734
Validation loss: 2.793541248040902

Epoch: 5| Step: 2
Training loss: 0.8252266240245724
Validation loss: 2.7367585465607407

Epoch: 5| Step: 3
Training loss: 0.7926132081578485
Validation loss: 2.7533983055242905

Epoch: 5| Step: 4
Training loss: 1.7000930816748365
Validation loss: 2.7774267671592128

Epoch: 5| Step: 5
Training loss: 0.7448465198155657
Validation loss: 2.695167696099166

Epoch: 5| Step: 6
Training loss: 0.7527195579127594
Validation loss: 2.758638937137189

Epoch: 5| Step: 7
Training loss: 1.0008279234152082
Validation loss: 2.7630654288578147

Epoch: 5| Step: 8
Training loss: 0.4800154090186242
Validation loss: 2.8889070818758174

Epoch: 5| Step: 9
Training loss: 0.7040919542649081
Validation loss: 2.7817488269450887

Epoch: 5| Step: 10
Training loss: 0.8916283025836841
Validation loss: 2.7808896985075022

Epoch: 5| Step: 11
Training loss: 0.7320708794385777
Validation loss: 2.760265800863879

Epoch: 181| Step: 0
Training loss: 0.6740567248030258
Validation loss: 2.820803401418205

Epoch: 5| Step: 1
Training loss: 0.8911888278657275
Validation loss: 2.7718498664642564

Epoch: 5| Step: 2
Training loss: 0.7831506878048854
Validation loss: 2.8072861769887343

Epoch: 5| Step: 3
Training loss: 0.673490246081221
Validation loss: 2.6301800370661437

Epoch: 5| Step: 4
Training loss: 0.6786823513679873
Validation loss: 2.74950359300151

Epoch: 5| Step: 5
Training loss: 0.6884889209260376
Validation loss: 2.7769939382940483

Epoch: 5| Step: 6
Training loss: 0.5910648060749927
Validation loss: 2.7773648532614725

Epoch: 5| Step: 7
Training loss: 0.9349754993778169
Validation loss: 2.8258169320824016

Epoch: 5| Step: 8
Training loss: 1.6565537803893926
Validation loss: 2.7094246585142105

Epoch: 5| Step: 9
Training loss: 0.8448767026976365
Validation loss: 2.846270708615515

Epoch: 5| Step: 10
Training loss: 0.9671959563888604
Validation loss: 2.842502718700226

Epoch: 5| Step: 11
Training loss: 0.4168220369417967
Validation loss: 2.7891905512118096

Epoch: 182| Step: 0
Training loss: 0.7535710355438674
Validation loss: 2.8673240462798524

Epoch: 5| Step: 1
Training loss: 1.0229238720942437
Validation loss: 2.899800856510596

Epoch: 5| Step: 2
Training loss: 0.761215943888548
Validation loss: 2.910427710653954

Epoch: 5| Step: 3
Training loss: 0.9263012548311933
Validation loss: 2.876273108296555

Epoch: 5| Step: 4
Training loss: 0.5730607689627374
Validation loss: 2.7653743177693384

Epoch: 5| Step: 5
Training loss: 0.7412811768715374
Validation loss: 2.7488991166636985

Epoch: 5| Step: 6
Training loss: 0.747937625247782
Validation loss: 2.77843568335513

Epoch: 5| Step: 7
Training loss: 0.7313606814226645
Validation loss: 2.7898676161651887

Epoch: 5| Step: 8
Training loss: 1.726343753818357
Validation loss: 2.7678182386046166

Epoch: 5| Step: 9
Training loss: 1.191257505042981
Validation loss: 2.8119890208011897

Epoch: 5| Step: 10
Training loss: 0.741474250593308
Validation loss: 2.790912342407346

Epoch: 5| Step: 11
Training loss: 0.8582914978004461
Validation loss: 2.836605968805584

Epoch: 183| Step: 0
Training loss: 0.6932323715590623
Validation loss: 2.7726289277904

Epoch: 5| Step: 1
Training loss: 0.7646197122413154
Validation loss: 2.807072662181105

Epoch: 5| Step: 2
Training loss: 1.1207207780407007
Validation loss: 2.9109900080254807

Epoch: 5| Step: 3
Training loss: 0.9268732190002492
Validation loss: 2.754093410904697

Epoch: 5| Step: 4
Training loss: 0.707799673069482
Validation loss: 2.7425573032626325

Epoch: 5| Step: 5
Training loss: 0.6773376622965914
Validation loss: 2.8101596843920147

Epoch: 5| Step: 6
Training loss: 0.5915560342442397
Validation loss: 2.7235114908444613

Epoch: 5| Step: 7
Training loss: 0.9483411837444515
Validation loss: 2.6645713424611652

Epoch: 5| Step: 8
Training loss: 0.8630415639802823
Validation loss: 2.7325583099630695

Epoch: 5| Step: 9
Training loss: 1.6252801360238145
Validation loss: 2.8154156936260684

Epoch: 5| Step: 10
Training loss: 1.0605742449240774
Validation loss: 2.8063819782003296

Epoch: 5| Step: 11
Training loss: 0.5818880148148144
Validation loss: 2.7790507147038053

Epoch: 184| Step: 0
Training loss: 0.6381972763124144
Validation loss: 2.7944444150357994

Epoch: 5| Step: 1
Training loss: 0.7921374995536808
Validation loss: 2.794844673631317

Epoch: 5| Step: 2
Training loss: 0.908156395807245
Validation loss: 2.800999940131315

Epoch: 5| Step: 3
Training loss: 0.6684701164530881
Validation loss: 2.7987260748854474

Epoch: 5| Step: 4
Training loss: 0.6803453046593371
Validation loss: 2.8889102729949405

Epoch: 5| Step: 5
Training loss: 0.6312075855622455
Validation loss: 2.6882141184718535

Epoch: 5| Step: 6
Training loss: 1.0525786615547439
Validation loss: 2.7071390905730293

Epoch: 5| Step: 7
Training loss: 0.9510875876051426
Validation loss: 2.7823273040324854

Epoch: 5| Step: 8
Training loss: 1.590716073477309
Validation loss: 2.720973977844453

Epoch: 5| Step: 9
Training loss: 0.8241138481891134
Validation loss: 2.698378395768905

Epoch: 5| Step: 10
Training loss: 0.5934600624106243
Validation loss: 2.6607420654864353

Epoch: 5| Step: 11
Training loss: 0.7636949774718456
Validation loss: 2.6734617477794793

Epoch: 185| Step: 0
Training loss: 1.423107242062983
Validation loss: 2.7409937344106843

Epoch: 5| Step: 1
Training loss: 1.0486902469531054
Validation loss: 2.8575178970261494

Epoch: 5| Step: 2
Training loss: 0.5613523006874208
Validation loss: 2.800599592871567

Epoch: 5| Step: 3
Training loss: 0.618741987157244
Validation loss: 2.7770183066738974

Epoch: 5| Step: 4
Training loss: 0.7681031894303246
Validation loss: 2.716080370681354

Epoch: 5| Step: 5
Training loss: 1.0481717064129201
Validation loss: 2.7190716140349394

Epoch: 5| Step: 6
Training loss: 0.7539355810913064
Validation loss: 2.7573362412913123

Epoch: 5| Step: 7
Training loss: 0.6006922185877414
Validation loss: 2.711054236017627

Epoch: 5| Step: 8
Training loss: 0.6226544714008425
Validation loss: 2.756824943366511

Epoch: 5| Step: 9
Training loss: 0.9255695986347051
Validation loss: 2.7352533074259515

Epoch: 5| Step: 10
Training loss: 0.8677336201793726
Validation loss: 2.7729167753850588

Epoch: 5| Step: 11
Training loss: 0.354726939592349
Validation loss: 2.7087492929049

Epoch: 186| Step: 0
Training loss: 0.525277419816654
Validation loss: 2.716601657504034

Epoch: 5| Step: 1
Training loss: 0.8114173351568601
Validation loss: 2.7458911131846544

Epoch: 5| Step: 2
Training loss: 0.6106479016931937
Validation loss: 2.797429456042956

Epoch: 5| Step: 3
Training loss: 0.8670883809397505
Validation loss: 2.7290507915639814

Epoch: 5| Step: 4
Training loss: 0.5600851463402421
Validation loss: 2.8294465224816454

Epoch: 5| Step: 5
Training loss: 1.6824628744804822
Validation loss: 2.7734452260944047

Epoch: 5| Step: 6
Training loss: 0.6731773440411553
Validation loss: 2.7326030802908474

Epoch: 5| Step: 7
Training loss: 0.9666503795260172
Validation loss: 2.777280153099916

Epoch: 5| Step: 8
Training loss: 0.6288488373702515
Validation loss: 2.765077737947903

Epoch: 5| Step: 9
Training loss: 0.5772467463332676
Validation loss: 2.791648840965941

Epoch: 5| Step: 10
Training loss: 0.6356356717604476
Validation loss: 2.78342069433551

Epoch: 5| Step: 11
Training loss: 0.5321344978429379
Validation loss: 2.775481442480779

Epoch: 187| Step: 0
Training loss: 0.6818107239719918
Validation loss: 2.8360158455836006

Epoch: 5| Step: 1
Training loss: 0.7698869222122617
Validation loss: 2.7519322600520164

Epoch: 5| Step: 2
Training loss: 0.9248981045970288
Validation loss: 2.8547702636024073

Epoch: 5| Step: 3
Training loss: 1.5418464538628445
Validation loss: 2.8040552444956486

Epoch: 5| Step: 4
Training loss: 0.7843509548802757
Validation loss: 2.7620522685732243

Epoch: 5| Step: 5
Training loss: 0.9780581807966198
Validation loss: 2.6947672711715542

Epoch: 5| Step: 6
Training loss: 0.42753559876176395
Validation loss: 2.7329595371747013

Epoch: 5| Step: 7
Training loss: 0.7142695637988782
Validation loss: 2.8354235061592914

Epoch: 5| Step: 8
Training loss: 0.820475135303264
Validation loss: 2.839134799454478

Epoch: 5| Step: 9
Training loss: 0.45243643369521364
Validation loss: 2.767930580225547

Epoch: 5| Step: 10
Training loss: 0.7586592436783764
Validation loss: 2.7676993024738774

Epoch: 5| Step: 11
Training loss: 0.5983897924704548
Validation loss: 2.7335405148125616

Epoch: 188| Step: 0
Training loss: 0.7551302683153465
Validation loss: 2.72110260282864

Epoch: 5| Step: 1
Training loss: 0.7308284261604716
Validation loss: 2.7838088133887964

Epoch: 5| Step: 2
Training loss: 0.5076113375788653
Validation loss: 2.689578010727166

Epoch: 5| Step: 3
Training loss: 0.69192015951069
Validation loss: 2.8753772156419175

Epoch: 5| Step: 4
Training loss: 1.052047080494947
Validation loss: 2.7886448217061948

Epoch: 5| Step: 5
Training loss: 0.6696045905487392
Validation loss: 2.767279979266912

Epoch: 5| Step: 6
Training loss: 0.6519204553792053
Validation loss: 2.7655492150794405

Epoch: 5| Step: 7
Training loss: 1.0571438477761919
Validation loss: 2.855980277177463

Epoch: 5| Step: 8
Training loss: 1.4691400213019732
Validation loss: 2.7852432608332727

Epoch: 5| Step: 9
Training loss: 0.8105300717737765
Validation loss: 2.748802263793172

Epoch: 5| Step: 10
Training loss: 0.6711114936587876
Validation loss: 2.770382384960524

Epoch: 5| Step: 11
Training loss: 0.4347850826053104
Validation loss: 2.651915252036021

Epoch: 189| Step: 0
Training loss: 1.560105587247022
Validation loss: 2.761787154714279

Epoch: 5| Step: 1
Training loss: 0.7556602353698882
Validation loss: 2.7927447195835544

Epoch: 5| Step: 2
Training loss: 0.7707861336012627
Validation loss: 2.7585340858042047

Epoch: 5| Step: 3
Training loss: 0.786286105735458
Validation loss: 2.7719656248878697

Epoch: 5| Step: 4
Training loss: 0.5378100731732298
Validation loss: 2.7427089336687747

Epoch: 5| Step: 5
Training loss: 0.8036892078006836
Validation loss: 2.7918484021335956

Epoch: 5| Step: 6
Training loss: 0.5403985039662055
Validation loss: 2.730237406188107

Epoch: 5| Step: 7
Training loss: 0.9399312283844253
Validation loss: 2.695286007073715

Epoch: 5| Step: 8
Training loss: 0.6814728888466747
Validation loss: 2.7062397506613753

Epoch: 5| Step: 9
Training loss: 0.7395617163995792
Validation loss: 2.7661734538254668

Epoch: 5| Step: 10
Training loss: 0.9315126599092945
Validation loss: 2.7652613585750134

Epoch: 5| Step: 11
Training loss: 0.15593867280477006
Validation loss: 2.836381406344459

Epoch: 190| Step: 0
Training loss: 0.893941759998813
Validation loss: 2.7896214449565098

Epoch: 5| Step: 1
Training loss: 0.5701396889344752
Validation loss: 2.713646009322011

Epoch: 5| Step: 2
Training loss: 0.9169256899186676
Validation loss: 2.696251304884353

Epoch: 5| Step: 3
Training loss: 1.5345081776549903
Validation loss: 2.716944520705996

Epoch: 5| Step: 4
Training loss: 0.7275405371734216
Validation loss: 2.8026324671207474

Epoch: 5| Step: 5
Training loss: 0.5421413456953
Validation loss: 2.76340063985971

Epoch: 5| Step: 6
Training loss: 0.7715998309696382
Validation loss: 2.809795757322873

Epoch: 5| Step: 7
Training loss: 0.8810917786672382
Validation loss: 2.7921727715722677

Epoch: 5| Step: 8
Training loss: 0.4854123021885987
Validation loss: 2.7896553000828863

Epoch: 5| Step: 9
Training loss: 0.6193919108109868
Validation loss: 2.743151829367359

Epoch: 5| Step: 10
Training loss: 0.5842568772824895
Validation loss: 2.8152636689560926

Epoch: 5| Step: 11
Training loss: 0.46342993757748924
Validation loss: 2.777921123912076

Epoch: 191| Step: 0
Training loss: 0.7734450137611472
Validation loss: 2.8198230456064928

Epoch: 5| Step: 1
Training loss: 0.7883730983248496
Validation loss: 2.779039311576956

Epoch: 5| Step: 2
Training loss: 0.5197019941794132
Validation loss: 2.830957936316576

Epoch: 5| Step: 3
Training loss: 0.6010536171723939
Validation loss: 2.804228257149523

Epoch: 5| Step: 4
Training loss: 0.6315941325801782
Validation loss: 2.801378740594786

Epoch: 5| Step: 5
Training loss: 0.6636555490624343
Validation loss: 2.7428224015170364

Epoch: 5| Step: 6
Training loss: 0.7305951748545301
Validation loss: 2.764714930022331

Epoch: 5| Step: 7
Training loss: 0.8016651020973256
Validation loss: 2.76507871875608

Epoch: 5| Step: 8
Training loss: 0.9923257506162737
Validation loss: 2.7737758662888856

Epoch: 5| Step: 9
Training loss: 0.6943438994947747
Validation loss: 2.7312928258242968

Epoch: 5| Step: 10
Training loss: 1.4660049108758668
Validation loss: 2.788603138427183

Epoch: 5| Step: 11
Training loss: 0.732811663856924
Validation loss: 2.7983172727566616

Epoch: 192| Step: 0
Training loss: 0.6944118624567207
Validation loss: 2.6923862808236563

Epoch: 5| Step: 1
Training loss: 0.5038606194232869
Validation loss: 2.7163363847368607

Epoch: 5| Step: 2
Training loss: 1.5396095504214773
Validation loss: 2.7927688224745992

Epoch: 5| Step: 3
Training loss: 0.65650891691342
Validation loss: 2.808838113439121

Epoch: 5| Step: 4
Training loss: 0.8577442996737091
Validation loss: 2.8285038485310636

Epoch: 5| Step: 5
Training loss: 0.7064359487641242
Validation loss: 2.7632728998591722

Epoch: 5| Step: 6
Training loss: 0.7050434008895003
Validation loss: 2.7407279953258112

Epoch: 5| Step: 7
Training loss: 0.5762603174638885
Validation loss: 2.8496326761946795

Epoch: 5| Step: 8
Training loss: 0.6563052880748517
Validation loss: 2.7594483038560815

Epoch: 5| Step: 9
Training loss: 0.7887401488908635
Validation loss: 2.834581185649922

Epoch: 5| Step: 10
Training loss: 0.8243356052382286
Validation loss: 2.706709111850603

Epoch: 5| Step: 11
Training loss: 0.4688323107613456
Validation loss: 2.8240194571331774

Epoch: 193| Step: 0
Training loss: 0.5756928343674319
Validation loss: 2.73741603864813

Epoch: 5| Step: 1
Training loss: 1.538494489390286
Validation loss: 2.698751678760755

Epoch: 5| Step: 2
Training loss: 0.8343934389284343
Validation loss: 2.800497139070259

Epoch: 5| Step: 3
Training loss: 0.6326068025816003
Validation loss: 2.8344163203986503

Epoch: 5| Step: 4
Training loss: 0.577571346037298
Validation loss: 2.8511709249229815

Epoch: 5| Step: 5
Training loss: 0.7806740354311811
Validation loss: 2.7967413900560016

Epoch: 5| Step: 6
Training loss: 0.9517143003152737
Validation loss: 2.776226350081565

Epoch: 5| Step: 7
Training loss: 0.7753847059509203
Validation loss: 2.7939401426759702

Epoch: 5| Step: 8
Training loss: 0.6588354045221937
Validation loss: 2.8014925944990523

Epoch: 5| Step: 9
Training loss: 0.6376160927325928
Validation loss: 2.7849409672024033

Epoch: 5| Step: 10
Training loss: 0.6708900417818697
Validation loss: 2.764751533464413

Epoch: 5| Step: 11
Training loss: 0.4897461393894467
Validation loss: 2.765727944622311

Epoch: 194| Step: 0
Training loss: 0.8971833805426798
Validation loss: 2.77708726459596

Epoch: 5| Step: 1
Training loss: 0.47355204414624896
Validation loss: 2.7427984500794773

Epoch: 5| Step: 2
Training loss: 0.6257780953659952
Validation loss: 2.753776532808821

Epoch: 5| Step: 3
Training loss: 0.5649116000503348
Validation loss: 2.878812028368739

Epoch: 5| Step: 4
Training loss: 0.5583307140440732
Validation loss: 2.8030313155084947

Epoch: 5| Step: 5
Training loss: 1.4304499859831843
Validation loss: 2.8479168549830374

Epoch: 5| Step: 6
Training loss: 0.756887087170251
Validation loss: 2.7602974644001

Epoch: 5| Step: 7
Training loss: 0.9147869076160156
Validation loss: 2.7922782951497225

Epoch: 5| Step: 8
Training loss: 0.7593958722295489
Validation loss: 2.8111597470543828

Epoch: 5| Step: 9
Training loss: 0.5855261057808768
Validation loss: 2.8044487684225445

Epoch: 5| Step: 10
Training loss: 0.8010646783692417
Validation loss: 2.803010387763868

Epoch: 5| Step: 11
Training loss: 1.0121291811973174
Validation loss: 2.8102188820284733

Epoch: 195| Step: 0
Training loss: 0.7265410881579082
Validation loss: 2.8178699127425704

Epoch: 5| Step: 1
Training loss: 1.5614115166172093
Validation loss: 2.7241253786428836

Epoch: 5| Step: 2
Training loss: 0.7472807942997916
Validation loss: 2.794128635956204

Epoch: 5| Step: 3
Training loss: 0.6477901260553295
Validation loss: 2.8016893802412732

Epoch: 5| Step: 4
Training loss: 0.7093940160950127
Validation loss: 2.8187409211186645

Epoch: 5| Step: 5
Training loss: 0.8928789095268976
Validation loss: 2.865358779449719

Epoch: 5| Step: 6
Training loss: 0.8134667440602699
Validation loss: 2.7300741286163692

Epoch: 5| Step: 7
Training loss: 0.737911636433041
Validation loss: 2.833256539304507

Epoch: 5| Step: 8
Training loss: 0.5469382930641322
Validation loss: 2.790103746482633

Epoch: 5| Step: 9
Training loss: 0.8418768116818923
Validation loss: 2.7151554724575893

Epoch: 5| Step: 10
Training loss: 0.7017943188296838
Validation loss: 2.7867457137653946

Epoch: 5| Step: 11
Training loss: 0.5347147881897997
Validation loss: 2.818756001586615

Epoch: 196| Step: 0
Training loss: 0.6324756573527424
Validation loss: 2.797837771858283

Epoch: 5| Step: 1
Training loss: 0.5015952768044112
Validation loss: 2.8133322649956733

Epoch: 5| Step: 2
Training loss: 0.875850230349496
Validation loss: 2.7223475247909987

Epoch: 5| Step: 3
Training loss: 0.7052858844378154
Validation loss: 2.7208724451880695

Epoch: 5| Step: 4
Training loss: 1.4734950421485815
Validation loss: 2.759523021548285

Epoch: 5| Step: 5
Training loss: 0.8949411777261191
Validation loss: 2.7772623650224104

Epoch: 5| Step: 6
Training loss: 0.706951769160272
Validation loss: 2.8014158259794484

Epoch: 5| Step: 7
Training loss: 0.9632017240468466
Validation loss: 2.811896729230953

Epoch: 5| Step: 8
Training loss: 0.7502446570303096
Validation loss: 2.749211808882711

Epoch: 5| Step: 9
Training loss: 0.8000096395031013
Validation loss: 2.8099995023301614

Epoch: 5| Step: 10
Training loss: 0.4914756349906155
Validation loss: 2.8257962926144855

Epoch: 5| Step: 11
Training loss: 0.9092885739920752
Validation loss: 2.777715576720535

Epoch: 197| Step: 0
Training loss: 0.6753652317442823
Validation loss: 2.621113873256217

Epoch: 5| Step: 1
Training loss: 0.7432771413744476
Validation loss: 2.778722621973329

Epoch: 5| Step: 2
Training loss: 0.9101660077140904
Validation loss: 2.8264063043914374

Epoch: 5| Step: 3
Training loss: 1.5268653842468656
Validation loss: 2.7023541338087793

Epoch: 5| Step: 4
Training loss: 0.692512338679869
Validation loss: 2.8021978168191986

Epoch: 5| Step: 5
Training loss: 0.6104583402692727
Validation loss: 2.7776017281586975

Epoch: 5| Step: 6
Training loss: 0.6196764964532514
Validation loss: 2.8060354395731286

Epoch: 5| Step: 7
Training loss: 0.5473810851496498
Validation loss: 2.7628105340012974

Epoch: 5| Step: 8
Training loss: 0.761451791786522
Validation loss: 2.8142576588778385

Epoch: 5| Step: 9
Training loss: 0.6729950551139018
Validation loss: 2.846185444783994

Epoch: 5| Step: 10
Training loss: 0.7850952883915132
Validation loss: 2.8660319231788356

Epoch: 5| Step: 11
Training loss: 0.9707001469219124
Validation loss: 2.8283341894184075

Epoch: 198| Step: 0
Training loss: 1.3532088291199293
Validation loss: 2.7751513133450683

Epoch: 5| Step: 1
Training loss: 0.8113479516330091
Validation loss: 2.7969065829576993

Epoch: 5| Step: 2
Training loss: 0.7434102877382512
Validation loss: 2.8716366105454134

Epoch: 5| Step: 3
Training loss: 0.9858731873056553
Validation loss: 2.851651814773413

Epoch: 5| Step: 4
Training loss: 0.7639118412692556
Validation loss: 2.8839071171915935

Epoch: 5| Step: 5
Training loss: 0.8692942622832783
Validation loss: 2.70195317088446

Epoch: 5| Step: 6
Training loss: 0.7452806366001381
Validation loss: 2.720803926439447

Epoch: 5| Step: 7
Training loss: 0.9073243186030109
Validation loss: 2.8000004671868433

Epoch: 5| Step: 8
Training loss: 0.6570719385418957
Validation loss: 2.741954561720746

Epoch: 5| Step: 9
Training loss: 0.8439518369225174
Validation loss: 2.8920746235637775

Epoch: 5| Step: 10
Training loss: 0.643036235544733
Validation loss: 2.7631899212373066

Epoch: 5| Step: 11
Training loss: 1.1229804774020062
Validation loss: 2.77676015982889

Epoch: 199| Step: 0
Training loss: 0.5555481479733726
Validation loss: 2.7822582189067377

Epoch: 5| Step: 1
Training loss: 0.5737368579265255
Validation loss: 2.690839249118159

Epoch: 5| Step: 2
Training loss: 0.8732125553913007
Validation loss: 2.812487821199398

Epoch: 5| Step: 3
Training loss: 0.472027352350755
Validation loss: 2.786309519326427

Epoch: 5| Step: 4
Training loss: 1.4438550043935015
Validation loss: 2.6554401771390115

Epoch: 5| Step: 5
Training loss: 0.6289926789408068
Validation loss: 2.738224926857699

Epoch: 5| Step: 6
Training loss: 0.746117636413078
Validation loss: 2.7600226043038134

Epoch: 5| Step: 7
Training loss: 0.8475972871445343
Validation loss: 2.7239496888606443

Epoch: 5| Step: 8
Training loss: 0.7951821690699785
Validation loss: 2.7699810034138372

Epoch: 5| Step: 9
Training loss: 0.7297824756966653
Validation loss: 2.807064717212984

Epoch: 5| Step: 10
Training loss: 0.9521519431025209
Validation loss: 2.7733945995469327

Epoch: 5| Step: 11
Training loss: 0.6440466706442131
Validation loss: 2.799563509831222

Epoch: 200| Step: 0
Training loss: 1.5539618097175976
Validation loss: 2.7895216684075916

Epoch: 5| Step: 1
Training loss: 0.6921702544257675
Validation loss: 2.807071526175905

Epoch: 5| Step: 2
Training loss: 0.5725506798413446
Validation loss: 2.6641823750035702

Epoch: 5| Step: 3
Training loss: 0.5874520119892588
Validation loss: 2.706326079528916

Epoch: 5| Step: 4
Training loss: 0.5052353828765788
Validation loss: 2.7798563898223123

Epoch: 5| Step: 5
Training loss: 0.695789580673282
Validation loss: 2.733735189515485

Epoch: 5| Step: 6
Training loss: 0.586122636156935
Validation loss: 2.7099439245841253

Epoch: 5| Step: 7
Training loss: 0.9647980961056487
Validation loss: 2.736704562440179

Epoch: 5| Step: 8
Training loss: 0.9097503936003578
Validation loss: 2.7017397408915267

Epoch: 5| Step: 9
Training loss: 0.6159018634645936
Validation loss: 2.7239006077695893

Epoch: 5| Step: 10
Training loss: 0.5722193520231186
Validation loss: 2.6860103248900504

Epoch: 5| Step: 11
Training loss: 0.41247383381476227
Validation loss: 2.7785958616606963

Epoch: 201| Step: 0
Training loss: 0.6874433624172983
Validation loss: 2.843185096217954

Epoch: 5| Step: 1
Training loss: 0.689186974179742
Validation loss: 2.7635487056105243

Epoch: 5| Step: 2
Training loss: 0.698551178968015
Validation loss: 2.7805046482953957

Epoch: 5| Step: 3
Training loss: 0.6250124214845366
Validation loss: 2.783041730517836

Epoch: 5| Step: 4
Training loss: 0.8235027946049533
Validation loss: 2.730517829450286

Epoch: 5| Step: 5
Training loss: 0.6543591370067156
Validation loss: 2.7504894948015695

Epoch: 5| Step: 6
Training loss: 1.475402941865743
Validation loss: 2.7901571068800957

Epoch: 5| Step: 7
Training loss: 0.7843264089784785
Validation loss: 2.7434620010203683

Epoch: 5| Step: 8
Training loss: 0.8625157271900125
Validation loss: 2.756213325175755

Epoch: 5| Step: 9
Training loss: 0.5433426262737555
Validation loss: 2.750648115107618

Epoch: 5| Step: 10
Training loss: 0.7238237589803775
Validation loss: 2.7572291354265803

Epoch: 5| Step: 11
Training loss: 0.9939855068577825
Validation loss: 2.8030572189136937

Epoch: 202| Step: 0
Training loss: 0.6963574133839857
Validation loss: 2.7827675925902113

Epoch: 5| Step: 1
Training loss: 0.4985266375584472
Validation loss: 2.7187252737799015

Epoch: 5| Step: 2
Training loss: 1.4090260549482216
Validation loss: 2.767307667606404

Epoch: 5| Step: 3
Training loss: 0.9254478787914304
Validation loss: 2.709213641347208

Epoch: 5| Step: 4
Training loss: 0.5266815266092216
Validation loss: 2.7407756913331744

Epoch: 5| Step: 5
Training loss: 0.48043579670859826
Validation loss: 2.7667782780145567

Epoch: 5| Step: 6
Training loss: 0.7250809690051617
Validation loss: 2.7376205220393195

Epoch: 5| Step: 7
Training loss: 0.5267693110630016
Validation loss: 2.7641385748130283

Epoch: 5| Step: 8
Training loss: 0.8904056948311746
Validation loss: 2.7991181689387306

Epoch: 5| Step: 9
Training loss: 0.7794500979513573
Validation loss: 2.8001968149995022

Epoch: 5| Step: 10
Training loss: 0.8420474925114233
Validation loss: 2.737828781903326

Epoch: 5| Step: 11
Training loss: 0.5605681412015633
Validation loss: 2.7082150702454015

Epoch: 203| Step: 0
Training loss: 0.6635122824669696
Validation loss: 2.7919118379761914

Epoch: 5| Step: 1
Training loss: 0.7195560662280085
Validation loss: 2.703827680276371

Epoch: 5| Step: 2
Training loss: 0.5736777683159511
Validation loss: 2.757967345705792

Epoch: 5| Step: 3
Training loss: 0.6294555161009219
Validation loss: 2.6991111045678413

Epoch: 5| Step: 4
Training loss: 0.8971307290244951
Validation loss: 2.7646279198951835

Epoch: 5| Step: 5
Training loss: 0.771472245133084
Validation loss: 2.7723131793238522

Epoch: 5| Step: 6
Training loss: 0.8331414279906331
Validation loss: 2.7548565102103315

Epoch: 5| Step: 7
Training loss: 1.51536494904775
Validation loss: 2.6949185567255656

Epoch: 5| Step: 8
Training loss: 0.7171870113196609
Validation loss: 2.7088902976695923

Epoch: 5| Step: 9
Training loss: 0.579362549920656
Validation loss: 2.7601980026776975

Epoch: 5| Step: 10
Training loss: 0.36396651087226356
Validation loss: 2.754728583168182

Epoch: 5| Step: 11
Training loss: 0.46784861046218934
Validation loss: 2.7060112841294033

Epoch: 204| Step: 0
Training loss: 0.7219457897139334
Validation loss: 2.7055468248467527

Epoch: 5| Step: 1
Training loss: 0.39142745563984
Validation loss: 2.7844549743435567

Epoch: 5| Step: 2
Training loss: 0.6964777708141632
Validation loss: 2.7672115128873735

Epoch: 5| Step: 3
Training loss: 0.6082549193763844
Validation loss: 2.78633386327995

Epoch: 5| Step: 4
Training loss: 0.606507794145347
Validation loss: 2.7028498647389343

Epoch: 5| Step: 5
Training loss: 0.6145738477028772
Validation loss: 2.8072188101935507

Epoch: 5| Step: 6
Training loss: 0.6601254382645796
Validation loss: 2.7482555990655704

Epoch: 5| Step: 7
Training loss: 0.6569155315594382
Validation loss: 2.7955031875610827

Epoch: 5| Step: 8
Training loss: 0.6809663908432965
Validation loss: 2.8091383058147437

Epoch: 5| Step: 9
Training loss: 0.9250974101248782
Validation loss: 2.8290388868256553

Epoch: 5| Step: 10
Training loss: 0.573720521231915
Validation loss: 2.7455391864259915

Epoch: 5| Step: 11
Training loss: 2.8468657810635585
Validation loss: 2.8216105826219975

Epoch: 205| Step: 0
Training loss: 0.5812610932798992
Validation loss: 2.7745561877750813

Epoch: 5| Step: 1
Training loss: 0.5906697735643732
Validation loss: 2.834898419402078

Epoch: 5| Step: 2
Training loss: 1.031680277445486
Validation loss: 2.7887521067060934

Epoch: 5| Step: 3
Training loss: 0.7726823607565981
Validation loss: 2.7999018162304457

Epoch: 5| Step: 4
Training loss: 0.5276507296512055
Validation loss: 2.8025764447419514

Epoch: 5| Step: 5
Training loss: 0.7030723340125584
Validation loss: 2.73726040054335

Epoch: 5| Step: 6
Training loss: 0.7034182043153283
Validation loss: 2.7701742970776726

Epoch: 5| Step: 7
Training loss: 0.7358374946825063
Validation loss: 2.7564562631704566

Epoch: 5| Step: 8
Training loss: 1.4141228594464084
Validation loss: 2.8025265500310876

Epoch: 5| Step: 9
Training loss: 0.877458456528658
Validation loss: 2.782275671551733

Epoch: 5| Step: 10
Training loss: 0.567220352734669
Validation loss: 2.7300693763807056

Epoch: 5| Step: 11
Training loss: 0.23786818550399905
Validation loss: 2.8163210978974957

Epoch: 206| Step: 0
Training loss: 0.7523198014009848
Validation loss: 2.802338958387317

Epoch: 5| Step: 1
Training loss: 0.8028025725787711
Validation loss: 2.7899622494355185

Epoch: 5| Step: 2
Training loss: 0.5640608008192681
Validation loss: 2.84212666943286

Epoch: 5| Step: 3
Training loss: 0.721714498999184
Validation loss: 2.85801580744221

Epoch: 5| Step: 4
Training loss: 0.7562173000863913
Validation loss: 2.691190507027163

Epoch: 5| Step: 5
Training loss: 0.4470345845743109
Validation loss: 2.704019710816918

Epoch: 5| Step: 6
Training loss: 0.6388253310512052
Validation loss: 2.7109910518109728

Epoch: 5| Step: 7
Training loss: 0.8118362650099481
Validation loss: 2.6338083513793777

Epoch: 5| Step: 8
Training loss: 0.8450966437787159
Validation loss: 2.730385192844151

Epoch: 5| Step: 9
Training loss: 0.665023108919787
Validation loss: 2.742853494973586

Epoch: 5| Step: 10
Training loss: 1.4216710877135488
Validation loss: 2.6985932106988044

Epoch: 5| Step: 11
Training loss: 0.5449739656879622
Validation loss: 2.862064998382124

Epoch: 207| Step: 0
Training loss: 0.49343643975944235
Validation loss: 2.7706437344802954

Epoch: 5| Step: 1
Training loss: 0.6884176459027449
Validation loss: 2.7985163335525143

Epoch: 5| Step: 2
Training loss: 0.9058783854488016
Validation loss: 2.7212447270681204

Epoch: 5| Step: 3
Training loss: 0.7141380787591097
Validation loss: 2.7988749125497123

Epoch: 5| Step: 4
Training loss: 0.8494173380985287
Validation loss: 2.833819457499855

Epoch: 5| Step: 5
Training loss: 0.7683391341475202
Validation loss: 2.8076955307796965

Epoch: 5| Step: 6
Training loss: 0.5563522394924596
Validation loss: 2.719452657552969

Epoch: 5| Step: 7
Training loss: 0.7908595932023116
Validation loss: 2.7901900582939936

Epoch: 5| Step: 8
Training loss: 0.543770890547115
Validation loss: 2.7526746191694587

Epoch: 5| Step: 9
Training loss: 1.4450654514629573
Validation loss: 2.769526970792333

Epoch: 5| Step: 10
Training loss: 0.7038955916297436
Validation loss: 2.738482792104041

Epoch: 5| Step: 11
Training loss: 0.5199735379363429
Validation loss: 2.7718148118530093

Epoch: 208| Step: 0
Training loss: 0.5398387847981204
Validation loss: 2.7439468948924834

Epoch: 5| Step: 1
Training loss: 0.743219481317991
Validation loss: 2.875171200174541

Epoch: 5| Step: 2
Training loss: 1.0118739182181935
Validation loss: 2.834704179094782

Epoch: 5| Step: 3
Training loss: 0.8515003776639055
Validation loss: 2.836718477126388

Epoch: 5| Step: 4
Training loss: 0.43273225033443885
Validation loss: 2.7135011458834106

Epoch: 5| Step: 5
Training loss: 0.6195610375958072
Validation loss: 2.7480948849993676

Epoch: 5| Step: 6
Training loss: 0.6214960582697155
Validation loss: 2.771114476121659

Epoch: 5| Step: 7
Training loss: 0.4783222975715017
Validation loss: 2.784794342082728

Epoch: 5| Step: 8
Training loss: 1.3411849179791662
Validation loss: 2.8150880773733253

Epoch: 5| Step: 9
Training loss: 0.9077450817503365
Validation loss: 2.751163890212647

Epoch: 5| Step: 10
Training loss: 0.7658620194993888
Validation loss: 2.823586461300534

Epoch: 5| Step: 11
Training loss: 0.31331777859100607
Validation loss: 2.760136476127912

Epoch: 209| Step: 0
Training loss: 0.5531051524421469
Validation loss: 2.8201785526890477

Epoch: 5| Step: 1
Training loss: 0.8208553516190948
Validation loss: 2.754566227174044

Epoch: 5| Step: 2
Training loss: 0.6420955527164215
Validation loss: 2.838278757688025

Epoch: 5| Step: 3
Training loss: 0.7663895818081858
Validation loss: 2.819100543101888

Epoch: 5| Step: 4
Training loss: 0.6890448206841494
Validation loss: 2.7186031484588504

Epoch: 5| Step: 5
Training loss: 0.5308733895468036
Validation loss: 2.760483673769921

Epoch: 5| Step: 6
Training loss: 0.6037047747146573
Validation loss: 2.744226243028549

Epoch: 5| Step: 7
Training loss: 0.7048134135147078
Validation loss: 2.794061997221632

Epoch: 5| Step: 8
Training loss: 0.7662993205814568
Validation loss: 2.7863736017957335

Epoch: 5| Step: 9
Training loss: 0.450015563828151
Validation loss: 2.706204220602629

Epoch: 5| Step: 10
Training loss: 1.4554447813000582
Validation loss: 2.8226551178733623

Epoch: 5| Step: 11
Training loss: 0.2394865227413383
Validation loss: 2.743082347905351

Epoch: 210| Step: 0
Training loss: 1.4623328088904795
Validation loss: 2.7650449004330246

Epoch: 5| Step: 1
Training loss: 0.9078915625596005
Validation loss: 2.7231063762579826

Epoch: 5| Step: 2
Training loss: 0.6617529030445438
Validation loss: 2.754830964943896

Epoch: 5| Step: 3
Training loss: 0.6614549491575482
Validation loss: 2.6995859370214412

Epoch: 5| Step: 4
Training loss: 0.4883230267772668
Validation loss: 2.8171387388749105

Epoch: 5| Step: 5
Training loss: 0.6781144409412369
Validation loss: 2.7554983167916016

Epoch: 5| Step: 6
Training loss: 0.6480586082495422
Validation loss: 2.763669297719232

Epoch: 5| Step: 7
Training loss: 0.37919835501431737
Validation loss: 2.7973185068618824

Epoch: 5| Step: 8
Training loss: 0.6055751337912122
Validation loss: 2.78475289012123

Epoch: 5| Step: 9
Training loss: 0.5479678542252466
Validation loss: 2.7510869955661446

Epoch: 5| Step: 10
Training loss: 0.6223009241967417
Validation loss: 2.738574042744944

Epoch: 5| Step: 11
Training loss: 0.7203688014073389
Validation loss: 2.7560534644320733

Epoch: 211| Step: 0
Training loss: 0.477809384836704
Validation loss: 2.810519704539382

Epoch: 5| Step: 1
Training loss: 0.4342174683476792
Validation loss: 2.776534465590305

Epoch: 5| Step: 2
Training loss: 0.5610055674958333
Validation loss: 2.828759004682795

Epoch: 5| Step: 3
Training loss: 0.738397457927552
Validation loss: 2.833734663888305

Epoch: 5| Step: 4
Training loss: 0.6762753482940251
Validation loss: 2.724041958771895

Epoch: 5| Step: 5
Training loss: 0.7195829457817808
Validation loss: 2.762046830448305

Epoch: 5| Step: 6
Training loss: 0.4510081270652889
Validation loss: 2.7565721274585724

Epoch: 5| Step: 7
Training loss: 0.8838069344921208
Validation loss: 2.809586513535779

Epoch: 5| Step: 8
Training loss: 0.5651338953264398
Validation loss: 2.7507320751766557

Epoch: 5| Step: 9
Training loss: 1.4211365175863406
Validation loss: 2.7846716217957073

Epoch: 5| Step: 10
Training loss: 0.5857953216987165
Validation loss: 2.785100514557355

Epoch: 5| Step: 11
Training loss: 0.8002908833484117
Validation loss: 2.817317640585447

Epoch: 212| Step: 0
Training loss: 0.6819860681553916
Validation loss: 2.759810299521885

Epoch: 5| Step: 1
Training loss: 0.604646998781481
Validation loss: 2.7701017458450203

Epoch: 5| Step: 2
Training loss: 0.5735403971641265
Validation loss: 2.829767919668857

Epoch: 5| Step: 3
Training loss: 0.43947018060435755
Validation loss: 2.78796157693178

Epoch: 5| Step: 4
Training loss: 0.6119584803771208
Validation loss: 2.7678594596548387

Epoch: 5| Step: 5
Training loss: 1.381692378806107
Validation loss: 2.7481440870582152

Epoch: 5| Step: 6
Training loss: 0.6572709996701865
Validation loss: 2.8513719852157258

Epoch: 5| Step: 7
Training loss: 0.670267777629401
Validation loss: 2.8977031720077737

Epoch: 5| Step: 8
Training loss: 0.8288627792881903
Validation loss: 2.804425761301373

Epoch: 5| Step: 9
Training loss: 0.7709594485927984
Validation loss: 2.7404465469727333

Epoch: 5| Step: 10
Training loss: 0.7734306026883312
Validation loss: 2.7312656562176043

Epoch: 5| Step: 11
Training loss: 0.195671048076795
Validation loss: 2.7608971495487205

Epoch: 213| Step: 0
Training loss: 0.5236025023518618
Validation loss: 2.778065708787822

Epoch: 5| Step: 1
Training loss: 0.5631604555846259
Validation loss: 2.7470682367686976

Epoch: 5| Step: 2
Training loss: 0.8074471641828522
Validation loss: 2.704658738366635

Epoch: 5| Step: 3
Training loss: 0.7495022552588635
Validation loss: 2.6850361841310306

Epoch: 5| Step: 4
Training loss: 0.6535261710821468
Validation loss: 2.675600195186591

Epoch: 5| Step: 5
Training loss: 0.7505016635950039
Validation loss: 2.7350987230483956

Epoch: 5| Step: 6
Training loss: 0.5208036573220821
Validation loss: 2.7517993650309704

Epoch: 5| Step: 7
Training loss: 1.2330122076421794
Validation loss: 2.769383088001564

Epoch: 5| Step: 8
Training loss: 0.6970196244570741
Validation loss: 2.77431460556657

Epoch: 5| Step: 9
Training loss: 0.7240560223285947
Validation loss: 2.7349862605289696

Epoch: 5| Step: 10
Training loss: 0.45655528985191357
Validation loss: 2.7964948434887322

Epoch: 5| Step: 11
Training loss: 0.9849178089182883
Validation loss: 2.8466839658902416

Epoch: 214| Step: 0
Training loss: 0.3834213358822717
Validation loss: 2.7425353616621417

Epoch: 5| Step: 1
Training loss: 0.8360478693749985
Validation loss: 2.7834852002070587

Epoch: 5| Step: 2
Training loss: 0.3935347331930491
Validation loss: 2.651696966654712

Epoch: 5| Step: 3
Training loss: 0.6271114446563804
Validation loss: 2.7412462203914005

Epoch: 5| Step: 4
Training loss: 0.6518432844644866
Validation loss: 2.744340509666924

Epoch: 5| Step: 5
Training loss: 0.7140539423390121
Validation loss: 2.7830513146474294

Epoch: 5| Step: 6
Training loss: 1.2791644078751458
Validation loss: 2.7403764567809294

Epoch: 5| Step: 7
Training loss: 0.4738101745123707
Validation loss: 2.813995694771261

Epoch: 5| Step: 8
Training loss: 0.6545385569121109
Validation loss: 2.671743144300947

Epoch: 5| Step: 9
Training loss: 0.7327471201673159
Validation loss: 2.793465999986058

Epoch: 5| Step: 10
Training loss: 0.5535918146326235
Validation loss: 2.8433613948305627

Epoch: 5| Step: 11
Training loss: 0.6650067068062931
Validation loss: 2.6921719374071262

Epoch: 215| Step: 0
Training loss: 0.6254649578573219
Validation loss: 2.7866966050614463

Epoch: 5| Step: 1
Training loss: 0.6411361051100821
Validation loss: 2.826934180873347

Epoch: 5| Step: 2
Training loss: 0.416916476306774
Validation loss: 2.73348090313291

Epoch: 5| Step: 3
Training loss: 0.6238260210607279
Validation loss: 2.7290526589515

Epoch: 5| Step: 4
Training loss: 0.8087323940666081
Validation loss: 2.751337037027687

Epoch: 5| Step: 5
Training loss: 0.6662024182904757
Validation loss: 2.752723742979176

Epoch: 5| Step: 6
Training loss: 0.5649369222319618
Validation loss: 2.796468943239679

Epoch: 5| Step: 7
Training loss: 1.3107212365672585
Validation loss: 2.8735149217539755

Epoch: 5| Step: 8
Training loss: 0.6972003767328235
Validation loss: 2.738098428657205

Epoch: 5| Step: 9
Training loss: 0.3371198053613944
Validation loss: 2.7904513558148354

Epoch: 5| Step: 10
Training loss: 0.6941417309822541
Validation loss: 2.8739001409361697

Epoch: 5| Step: 11
Training loss: 0.6857795863762591
Validation loss: 2.824441594098975

Epoch: 216| Step: 0
Training loss: 0.5723337126447161
Validation loss: 2.838869894223475

Epoch: 5| Step: 1
Training loss: 0.6440503262438679
Validation loss: 2.8566042498851205

Epoch: 5| Step: 2
Training loss: 1.2518688536563087
Validation loss: 2.7413310554767985

Epoch: 5| Step: 3
Training loss: 0.6569055053639936
Validation loss: 2.8279598251076323

Epoch: 5| Step: 4
Training loss: 0.535027314406851
Validation loss: 2.792528636197005

Epoch: 5| Step: 5
Training loss: 0.5823811241134128
Validation loss: 2.7496210978755276

Epoch: 5| Step: 6
Training loss: 0.40294687194717715
Validation loss: 2.7713513009703488

Epoch: 5| Step: 7
Training loss: 0.7411236818443102
Validation loss: 2.7731281806492527

Epoch: 5| Step: 8
Training loss: 0.5579923046121498
Validation loss: 2.7819721627363583

Epoch: 5| Step: 9
Training loss: 0.5438883013614412
Validation loss: 2.783055408863306

Epoch: 5| Step: 10
Training loss: 0.7528007980837023
Validation loss: 2.7454242749402327

Epoch: 5| Step: 11
Training loss: 0.49315898628266197
Validation loss: 2.8029423830332596

Epoch: 217| Step: 0
Training loss: 0.5504476470323852
Validation loss: 2.756311932341572

Epoch: 5| Step: 1
Training loss: 0.6010229738084456
Validation loss: 2.804938568098711

Epoch: 5| Step: 2
Training loss: 0.554508637079816
Validation loss: 2.7265793035621546

Epoch: 5| Step: 3
Training loss: 0.5531984679143657
Validation loss: 2.740372306051335

Epoch: 5| Step: 4
Training loss: 0.7391344015296729
Validation loss: 2.8435208189841457

Epoch: 5| Step: 5
Training loss: 0.5783010163287869
Validation loss: 2.7856554080751903

Epoch: 5| Step: 6
Training loss: 0.5943614922882936
Validation loss: 2.8003239278237686

Epoch: 5| Step: 7
Training loss: 0.6380497880450894
Validation loss: 2.822611501370516

Epoch: 5| Step: 8
Training loss: 0.3903959174767911
Validation loss: 2.7812594474317707

Epoch: 5| Step: 9
Training loss: 1.3509642318773925
Validation loss: 2.792411858941509

Epoch: 5| Step: 10
Training loss: 0.5768223339849992
Validation loss: 2.845155099826678

Epoch: 5| Step: 11
Training loss: 1.0875540577398761
Validation loss: 2.8041235623346146

Epoch: 218| Step: 0
Training loss: 0.4014871979402825
Validation loss: 2.732468876174268

Epoch: 5| Step: 1
Training loss: 0.5988510256853163
Validation loss: 2.9129637145761595

Epoch: 5| Step: 2
Training loss: 1.2089990667334805
Validation loss: 2.796746355788605

Epoch: 5| Step: 3
Training loss: 0.8437364365229264
Validation loss: 2.8295455617569223

Epoch: 5| Step: 4
Training loss: 0.5680011524890571
Validation loss: 2.8414921967558517

Epoch: 5| Step: 5
Training loss: 0.4516199042452197
Validation loss: 2.8704937608550622

Epoch: 5| Step: 6
Training loss: 0.5559901402014297
Validation loss: 2.8344034892385

Epoch: 5| Step: 7
Training loss: 0.4912201594251144
Validation loss: 2.7893837815851015

Epoch: 5| Step: 8
Training loss: 0.7561669327694304
Validation loss: 2.815119822997045

Epoch: 5| Step: 9
Training loss: 0.5975659620114725
Validation loss: 2.756455023414259

Epoch: 5| Step: 10
Training loss: 0.5698343388852692
Validation loss: 2.845300777340628

Epoch: 5| Step: 11
Training loss: 0.3735879499239664
Validation loss: 2.8108737871188323

Epoch: 219| Step: 0
Training loss: 0.4540025008244053
Validation loss: 2.873852877579203

Epoch: 5| Step: 1
Training loss: 0.4833124103484397
Validation loss: 2.8086145689382356

Epoch: 5| Step: 2
Training loss: 0.4518757733329181
Validation loss: 2.8359362214280845

Epoch: 5| Step: 3
Training loss: 0.46859850024709065
Validation loss: 2.826141954820312

Epoch: 5| Step: 4
Training loss: 0.5559802504983827
Validation loss: 2.772967109727696

Epoch: 5| Step: 5
Training loss: 1.3113055016160118
Validation loss: 2.7752196196405894

Epoch: 5| Step: 6
Training loss: 0.7816879189522861
Validation loss: 2.7638920313265096

Epoch: 5| Step: 7
Training loss: 0.3307302342295
Validation loss: 2.790002370665852

Epoch: 5| Step: 8
Training loss: 0.4922909854906266
Validation loss: 2.7461221113770735

Epoch: 5| Step: 9
Training loss: 0.565592055652217
Validation loss: 2.813334298898281

Epoch: 5| Step: 10
Training loss: 0.8040775098115032
Validation loss: 2.7081836707994063

Epoch: 5| Step: 11
Training loss: 0.24841157130124086
Validation loss: 2.747290244340884

Epoch: 220| Step: 0
Training loss: 0.6910151436881141
Validation loss: 2.7994169870021217

Epoch: 5| Step: 1
Training loss: 0.45121877187103615
Validation loss: 2.7885165209961094

Epoch: 5| Step: 2
Training loss: 0.6146698799187226
Validation loss: 2.741218181836547

Epoch: 5| Step: 3
Training loss: 0.4642086498916944
Validation loss: 2.7708602464176746

Epoch: 5| Step: 4
Training loss: 0.5853786091861248
Validation loss: 2.791275460792924

Epoch: 5| Step: 5
Training loss: 1.235532001088645
Validation loss: 2.7651669038452846

Epoch: 5| Step: 6
Training loss: 0.5949569781962293
Validation loss: 2.8142133544895005

Epoch: 5| Step: 7
Training loss: 0.614603209308844
Validation loss: 2.7639792011964848

Epoch: 5| Step: 8
Training loss: 0.6422395364882346
Validation loss: 2.767333668474747

Epoch: 5| Step: 9
Training loss: 0.6529954407607276
Validation loss: 2.7910175007590703

Epoch: 5| Step: 10
Training loss: 0.6443538074726953
Validation loss: 2.8221693891509396

Epoch: 5| Step: 11
Training loss: 0.23278226079988915
Validation loss: 2.7302789581219002

Epoch: 221| Step: 0
Training loss: 0.5145951013596547
Validation loss: 2.8134355119444443

Epoch: 5| Step: 1
Training loss: 0.7015959326035707
Validation loss: 2.7015572450232597

Epoch: 5| Step: 2
Training loss: 1.282073477375644
Validation loss: 2.718097349002689

Epoch: 5| Step: 3
Training loss: 0.5529759825928464
Validation loss: 2.7307554793898468

Epoch: 5| Step: 4
Training loss: 0.42635906454641115
Validation loss: 2.8215102648965473

Epoch: 5| Step: 5
Training loss: 0.5923783872837156
Validation loss: 2.80991461567557

Epoch: 5| Step: 6
Training loss: 0.5522648464968536
Validation loss: 2.791633443255131

Epoch: 5| Step: 7
Training loss: 0.5437775769311063
Validation loss: 2.8100804128940413

Epoch: 5| Step: 8
Training loss: 0.6936200363839526
Validation loss: 2.742019343858151

Epoch: 5| Step: 9
Training loss: 0.7298642273277915
Validation loss: 2.8328669926262107

Epoch: 5| Step: 10
Training loss: 0.7744867932872577
Validation loss: 2.7601993487243512

Epoch: 5| Step: 11
Training loss: 0.6855636768510065
Validation loss: 2.782174956714666

Epoch: 222| Step: 0
Training loss: 0.6972513277527431
Validation loss: 2.765590466357358

Epoch: 5| Step: 1
Training loss: 0.47847194861558173
Validation loss: 2.7627345208552008

Epoch: 5| Step: 2
Training loss: 0.6109741453609892
Validation loss: 2.7827752749312764

Epoch: 5| Step: 3
Training loss: 0.8016488562275559
Validation loss: 2.714344002446203

Epoch: 5| Step: 4
Training loss: 1.3038316306492732
Validation loss: 2.7475719823308262

Epoch: 5| Step: 5
Training loss: 0.5493273110896771
Validation loss: 2.7466441869413782

Epoch: 5| Step: 6
Training loss: 0.6447667703048683
Validation loss: 2.878831959925751

Epoch: 5| Step: 7
Training loss: 0.7174857257127576
Validation loss: 2.8354074842840133

Epoch: 5| Step: 8
Training loss: 0.6903549650297602
Validation loss: 2.801433967780728

Epoch: 5| Step: 9
Training loss: 0.8979766990850093
Validation loss: 2.768791727708864

Epoch: 5| Step: 10
Training loss: 0.42791726718081663
Validation loss: 2.7894512087296275

Epoch: 5| Step: 11
Training loss: 0.5340017967479639
Validation loss: 2.7384602827823397

Epoch: 223| Step: 0
Training loss: 0.5148241586387382
Validation loss: 2.7514086966101403

Epoch: 5| Step: 1
Training loss: 0.5793653019460693
Validation loss: 2.7364411858257487

Epoch: 5| Step: 2
Training loss: 0.44530135692909684
Validation loss: 2.7727598051838434

Epoch: 5| Step: 3
Training loss: 0.5578355511943325
Validation loss: 2.7705028571092485

Epoch: 5| Step: 4
Training loss: 1.321354471802316
Validation loss: 2.757096223686224

Epoch: 5| Step: 5
Training loss: 0.4029984933645137
Validation loss: 2.7899145468633884

Epoch: 5| Step: 6
Training loss: 0.7340466597249877
Validation loss: 2.737728239005999

Epoch: 5| Step: 7
Training loss: 0.5557986936065185
Validation loss: 2.762876718389849

Epoch: 5| Step: 8
Training loss: 0.6713578873425932
Validation loss: 2.7900170901844983

Epoch: 5| Step: 9
Training loss: 0.5381909664274108
Validation loss: 2.7972837216962456

Epoch: 5| Step: 10
Training loss: 0.4680952267416258
Validation loss: 2.877080589521473

Epoch: 5| Step: 11
Training loss: 0.45269167668291943
Validation loss: 2.7804949267674433

Epoch: 224| Step: 0
Training loss: 0.7319387648223562
Validation loss: 2.784601521009973

Epoch: 5| Step: 1
Training loss: 0.6191283745260714
Validation loss: 2.7694834968241397

Epoch: 5| Step: 2
Training loss: 0.667553912282278
Validation loss: 2.7655474154407176

Epoch: 5| Step: 3
Training loss: 0.44856536451224754
Validation loss: 2.7696870187016316

Epoch: 5| Step: 4
Training loss: 0.5160419339007457
Validation loss: 2.7347316872606395

Epoch: 5| Step: 5
Training loss: 0.6952925046981754
Validation loss: 2.7415013392196603

Epoch: 5| Step: 6
Training loss: 0.6502381567046976
Validation loss: 2.7787603028781818

Epoch: 5| Step: 7
Training loss: 1.2428360211796594
Validation loss: 2.730406000510501

Epoch: 5| Step: 8
Training loss: 0.6056923976200661
Validation loss: 2.780681076867671

Epoch: 5| Step: 9
Training loss: 0.5642464599312407
Validation loss: 2.7818495107863

Epoch: 5| Step: 10
Training loss: 0.6775036069907703
Validation loss: 2.7972098066662006

Epoch: 5| Step: 11
Training loss: 0.5027606865341309
Validation loss: 2.7736045249827233

Epoch: 225| Step: 0
Training loss: 0.5287558123311935
Validation loss: 2.7923942704250386

Epoch: 5| Step: 1
Training loss: 0.6307881554241421
Validation loss: 2.749695403396272

Epoch: 5| Step: 2
Training loss: 1.381566191855802
Validation loss: 2.788674022073307

Epoch: 5| Step: 3
Training loss: 0.5516497210736081
Validation loss: 2.8075801875675674

Epoch: 5| Step: 4
Training loss: 0.8473845015512369
Validation loss: 2.811101435032963

Epoch: 5| Step: 5
Training loss: 0.7259119464319524
Validation loss: 2.752749084055154

Epoch: 5| Step: 6
Training loss: 0.5331453005558104
Validation loss: 2.8104375411932216

Epoch: 5| Step: 7
Training loss: 0.5163985432152178
Validation loss: 2.7908812504555414

Epoch: 5| Step: 8
Training loss: 0.5258069285772408
Validation loss: 2.7910476373073925

Epoch: 5| Step: 9
Training loss: 0.6867948947739522
Validation loss: 2.826981272831193

Epoch: 5| Step: 10
Training loss: 0.5917435423736777
Validation loss: 2.7967910682970794

Epoch: 5| Step: 11
Training loss: 0.48549858644929883
Validation loss: 2.877702410417585

Epoch: 226| Step: 0
Training loss: 0.5267994084552581
Validation loss: 2.84986190600764

Epoch: 5| Step: 1
Training loss: 0.4722110921897576
Validation loss: 2.789554673622906

Epoch: 5| Step: 2
Training loss: 0.504931272324532
Validation loss: 2.7150624175709486

Epoch: 5| Step: 3
Training loss: 0.664432871138139
Validation loss: 2.8009708753563145

Epoch: 5| Step: 4
Training loss: 0.5886523106190008
Validation loss: 2.787109282328072

Epoch: 5| Step: 5
Training loss: 0.5787709210530096
Validation loss: 2.755266958140606

Epoch: 5| Step: 6
Training loss: 0.7057352781324414
Validation loss: 2.789726919040484

Epoch: 5| Step: 7
Training loss: 0.4774063331547499
Validation loss: 2.788809696284128

Epoch: 5| Step: 8
Training loss: 1.2609359155051711
Validation loss: 2.7924014353397406

Epoch: 5| Step: 9
Training loss: 0.5914055062091539
Validation loss: 2.8627864450008107

Epoch: 5| Step: 10
Training loss: 0.4251144156996128
Validation loss: 2.783525989388299

Epoch: 5| Step: 11
Training loss: 0.7510202938289077
Validation loss: 2.8936715232803385

Epoch: 227| Step: 0
Training loss: 0.4849434716178653
Validation loss: 2.7724933969483834

Epoch: 5| Step: 1
Training loss: 0.39581629649524636
Validation loss: 2.7125785873385007

Epoch: 5| Step: 2
Training loss: 0.6753858611345375
Validation loss: 2.7921829683266703

Epoch: 5| Step: 3
Training loss: 0.48650242083595063
Validation loss: 2.833205126685377

Epoch: 5| Step: 4
Training loss: 0.606205522734399
Validation loss: 2.7490704186300063

Epoch: 5| Step: 5
Training loss: 0.46857606521820777
Validation loss: 2.793778589743843

Epoch: 5| Step: 6
Training loss: 0.6502673745435543
Validation loss: 2.800652934193816

Epoch: 5| Step: 7
Training loss: 0.42019107085581275
Validation loss: 2.789965017847429

Epoch: 5| Step: 8
Training loss: 0.5578161041827194
Validation loss: 2.819661837659781

Epoch: 5| Step: 9
Training loss: 0.6512143986758547
Validation loss: 2.8490865819170654

Epoch: 5| Step: 10
Training loss: 0.648430008442817
Validation loss: 2.8457099008577695

Epoch: 5| Step: 11
Training loss: 2.600546515320333
Validation loss: 2.822404041877876

Epoch: 228| Step: 0
Training loss: 0.34983509385243133
Validation loss: 2.7769348194010672

Epoch: 5| Step: 1
Training loss: 0.660348288689582
Validation loss: 2.8227774115323223

Epoch: 5| Step: 2
Training loss: 0.5800334515050691
Validation loss: 2.728976677452579

Epoch: 5| Step: 3
Training loss: 0.6076699636475932
Validation loss: 2.8097186747159975

Epoch: 5| Step: 4
Training loss: 1.2800755118656812
Validation loss: 2.748029056754295

Epoch: 5| Step: 5
Training loss: 0.4663100796820647
Validation loss: 2.792456850744758

Epoch: 5| Step: 6
Training loss: 0.6438759911954816
Validation loss: 2.8828601264637745

Epoch: 5| Step: 7
Training loss: 0.5854695295130659
Validation loss: 2.7676666073327247

Epoch: 5| Step: 8
Training loss: 0.5169701514251315
Validation loss: 2.7470478988584714

Epoch: 5| Step: 9
Training loss: 0.5500209782674396
Validation loss: 2.7532250971067254

Epoch: 5| Step: 10
Training loss: 0.7831303664965081
Validation loss: 2.7971327430270274

Epoch: 5| Step: 11
Training loss: 0.8977495296076554
Validation loss: 2.694528821452097

Epoch: 229| Step: 0
Training loss: 0.5091585951673667
Validation loss: 2.747419815802496

Epoch: 5| Step: 1
Training loss: 0.43194398533298234
Validation loss: 2.7594119252736418

Epoch: 5| Step: 2
Training loss: 0.5316891257805035
Validation loss: 2.7430463063745383

Epoch: 5| Step: 3
Training loss: 0.4822806024071844
Validation loss: 2.8160669666495335

Epoch: 5| Step: 4
Training loss: 1.1528173475610821
Validation loss: 2.790295137059508

Epoch: 5| Step: 5
Training loss: 0.6010791769063377
Validation loss: 2.7802043442157376

Epoch: 5| Step: 6
Training loss: 0.436329963017676
Validation loss: 2.812700066691473

Epoch: 5| Step: 7
Training loss: 0.5296278759642163
Validation loss: 2.8435551118967206

Epoch: 5| Step: 8
Training loss: 0.6792231321752911
Validation loss: 2.74970245196565

Epoch: 5| Step: 9
Training loss: 0.4691277094833147
Validation loss: 2.769734825755178

Epoch: 5| Step: 10
Training loss: 0.43607115730416907
Validation loss: 2.735831002007741

Epoch: 5| Step: 11
Training loss: 0.5701760951963755
Validation loss: 2.8278938922627312

Epoch: 230| Step: 0
Training loss: 0.43614135679151417
Validation loss: 2.751513610064687

Epoch: 5| Step: 1
Training loss: 0.5772446037509451
Validation loss: 2.8176819676113487

Epoch: 5| Step: 2
Training loss: 0.5345542473237952
Validation loss: 2.66086337810805

Epoch: 5| Step: 3
Training loss: 1.2383689969618965
Validation loss: 2.819547241171227

Epoch: 5| Step: 4
Training loss: 0.5409051665323285
Validation loss: 2.737647370939703

Epoch: 5| Step: 5
Training loss: 0.5255519803523497
Validation loss: 2.8063044195130695

Epoch: 5| Step: 6
Training loss: 0.45446636354451597
Validation loss: 2.7708444140984723

Epoch: 5| Step: 7
Training loss: 0.7012045169978607
Validation loss: 2.841696759499951

Epoch: 5| Step: 8
Training loss: 0.7066377419349138
Validation loss: 2.7957756751909257

Epoch: 5| Step: 9
Training loss: 0.6064582368760429
Validation loss: 2.694998592949608

Epoch: 5| Step: 10
Training loss: 0.5010879125156942
Validation loss: 2.812213565227883

Epoch: 5| Step: 11
Training loss: 0.7590244865714527
Validation loss: 2.8119444510350733

Epoch: 231| Step: 0
Training loss: 0.5456659849139697
Validation loss: 2.772638211120415

Epoch: 5| Step: 1
Training loss: 0.5327659183846756
Validation loss: 2.7698278227979913

Epoch: 5| Step: 2
Training loss: 1.2278785205857776
Validation loss: 2.776248277677677

Epoch: 5| Step: 3
Training loss: 0.6475941102481063
Validation loss: 2.7686020620016665

Epoch: 5| Step: 4
Training loss: 0.47644634081892256
Validation loss: 2.771209570550076

Epoch: 5| Step: 5
Training loss: 0.43721935944156515
Validation loss: 2.79402937946515

Epoch: 5| Step: 6
Training loss: 0.3322211900351794
Validation loss: 2.770515639991357

Epoch: 5| Step: 7
Training loss: 0.6977312259178015
Validation loss: 2.774747827315678

Epoch: 5| Step: 8
Training loss: 0.614046748883857
Validation loss: 2.784046128413596

Epoch: 5| Step: 9
Training loss: 0.42050476427475036
Validation loss: 2.8230755023447003

Epoch: 5| Step: 10
Training loss: 0.6413617201110372
Validation loss: 2.7359327039199117

Epoch: 5| Step: 11
Training loss: 0.10012604380687395
Validation loss: 2.7771708331354326

Epoch: 232| Step: 0
Training loss: 0.48673338646105796
Validation loss: 2.774830789676649

Epoch: 5| Step: 1
Training loss: 1.1532937482056635
Validation loss: 2.780753741477574

Epoch: 5| Step: 2
Training loss: 0.6958968889217614
Validation loss: 2.7643051679954516

Epoch: 5| Step: 3
Training loss: 0.5423167863328904
Validation loss: 2.730850862426033

Epoch: 5| Step: 4
Training loss: 0.6271340652762578
Validation loss: 2.7987222130154086

Epoch: 5| Step: 5
Training loss: 0.4415073447799183
Validation loss: 2.789530535837641

Epoch: 5| Step: 6
Training loss: 0.5889713075106338
Validation loss: 2.848326992584397

Epoch: 5| Step: 7
Training loss: 0.6444862581213009
Validation loss: 2.6893789760883196

Epoch: 5| Step: 8
Training loss: 0.3319066430935275
Validation loss: 2.726226308621453

Epoch: 5| Step: 9
Training loss: 0.5076705734284617
Validation loss: 2.7263381960474464

Epoch: 5| Step: 10
Training loss: 0.5046765553613397
Validation loss: 2.7679964699228834

Epoch: 5| Step: 11
Training loss: 0.8317068479447078
Validation loss: 2.649917755260208

Epoch: 233| Step: 0
Training loss: 0.6730903899239425
Validation loss: 2.7652901125235285

Epoch: 5| Step: 1
Training loss: 0.4107678893750708
Validation loss: 2.754167761684629

Epoch: 5| Step: 2
Training loss: 0.6624980224723812
Validation loss: 2.797163186596778

Epoch: 5| Step: 3
Training loss: 0.7964180777039866
Validation loss: 2.7289163654269872

Epoch: 5| Step: 4
Training loss: 0.4657437563511978
Validation loss: 2.724590069008522

Epoch: 5| Step: 5
Training loss: 0.5562380757286027
Validation loss: 2.757637115607525

Epoch: 5| Step: 6
Training loss: 1.2932414893757602
Validation loss: 2.781263319262212

Epoch: 5| Step: 7
Training loss: 0.4313755516064195
Validation loss: 2.8016622089798333

Epoch: 5| Step: 8
Training loss: 0.5048991335328181
Validation loss: 2.8064188169409645

Epoch: 5| Step: 9
Training loss: 0.6491600744584415
Validation loss: 2.7865830806485388

Epoch: 5| Step: 10
Training loss: 0.7998669126196855
Validation loss: 2.872890434440445

Epoch: 5| Step: 11
Training loss: 0.3400885588125222
Validation loss: 2.772556247306876

Epoch: 234| Step: 0
Training loss: 0.4859528529940153
Validation loss: 2.8202938103871125

Epoch: 5| Step: 1
Training loss: 0.43675921940148327
Validation loss: 2.792937840999843

Epoch: 5| Step: 2
Training loss: 0.4607303768259649
Validation loss: 2.741585236985613

Epoch: 5| Step: 3
Training loss: 0.6448172426055816
Validation loss: 2.7945810994831843

Epoch: 5| Step: 4
Training loss: 0.4300348958283017
Validation loss: 2.7832038745544496

Epoch: 5| Step: 5
Training loss: 1.1850441584829767
Validation loss: 2.7506359622098064

Epoch: 5| Step: 6
Training loss: 0.7276846720768244
Validation loss: 2.819136436881796

Epoch: 5| Step: 7
Training loss: 0.4188651695156607
Validation loss: 2.7400135940135644

Epoch: 5| Step: 8
Training loss: 0.576272625923736
Validation loss: 2.8172202060611338

Epoch: 5| Step: 9
Training loss: 0.5469659184764694
Validation loss: 2.790088642887303

Epoch: 5| Step: 10
Training loss: 0.44906326588543466
Validation loss: 2.860164922336218

Epoch: 5| Step: 11
Training loss: 0.31041202376347604
Validation loss: 2.768078837913814

Epoch: 235| Step: 0
Training loss: 0.47402368521163246
Validation loss: 2.799061423190723

Epoch: 5| Step: 1
Training loss: 0.36293704636277585
Validation loss: 2.7342269984563647

Epoch: 5| Step: 2
Training loss: 0.3898561158445528
Validation loss: 2.7850315410270734

Epoch: 5| Step: 3
Training loss: 0.49725113673053845
Validation loss: 2.830907952290292

Epoch: 5| Step: 4
Training loss: 0.5622629089841112
Validation loss: 2.7418943322703546

Epoch: 5| Step: 5
Training loss: 0.71751579798941
Validation loss: 2.8451422280609155

Epoch: 5| Step: 6
Training loss: 0.5114849517432125
Validation loss: 2.7612853944477753

Epoch: 5| Step: 7
Training loss: 0.5550100436461725
Validation loss: 2.7986238045216583

Epoch: 5| Step: 8
Training loss: 1.1062082573725434
Validation loss: 2.792533598748657

Epoch: 5| Step: 9
Training loss: 0.5984831182557642
Validation loss: 2.8646266702783962

Epoch: 5| Step: 10
Training loss: 0.7106651790670723
Validation loss: 2.819777433549471

Epoch: 5| Step: 11
Training loss: 0.2387926835456869
Validation loss: 2.7859954710994552

Epoch: 236| Step: 0
Training loss: 0.5880881196396148
Validation loss: 2.757767811125855

Epoch: 5| Step: 1
Training loss: 0.5946948414127396
Validation loss: 2.838419932050277

Epoch: 5| Step: 2
Training loss: 0.4858718324797958
Validation loss: 2.7847622792942714

Epoch: 5| Step: 3
Training loss: 0.43169459700283924
Validation loss: 2.842554878788787

Epoch: 5| Step: 4
Training loss: 0.5854273037153371
Validation loss: 2.839547482462702

Epoch: 5| Step: 5
Training loss: 0.6432072768302666
Validation loss: 2.7651040112716987

Epoch: 5| Step: 6
Training loss: 0.4449408134468892
Validation loss: 2.830890248525385

Epoch: 5| Step: 7
Training loss: 1.287215047617004
Validation loss: 2.8209407279298726

Epoch: 5| Step: 8
Training loss: 0.4965472213862507
Validation loss: 2.8365318053937103

Epoch: 5| Step: 9
Training loss: 0.7482373664877888
Validation loss: 2.8262322486838496

Epoch: 5| Step: 10
Training loss: 0.5509837163969861
Validation loss: 2.830882047556527

Epoch: 5| Step: 11
Training loss: 0.5598322070734011
Validation loss: 2.8827651932305827

Epoch: 237| Step: 0
Training loss: 0.5600968790978427
Validation loss: 2.8071593228051026

Epoch: 5| Step: 1
Training loss: 0.5258068718980257
Validation loss: 2.715929033082385

Epoch: 5| Step: 2
Training loss: 0.48912619154697484
Validation loss: 2.7729646270658823

Epoch: 5| Step: 3
Training loss: 0.4637280385968688
Validation loss: 2.7811765768239165

Epoch: 5| Step: 4
Training loss: 0.44113988350643196
Validation loss: 2.7334141487196124

Epoch: 5| Step: 5
Training loss: 0.6050218224727589
Validation loss: 2.823430803970422

Epoch: 5| Step: 6
Training loss: 1.2296714015813348
Validation loss: 2.720846712294706

Epoch: 5| Step: 7
Training loss: 0.6088420297823252
Validation loss: 2.7434203373456563

Epoch: 5| Step: 8
Training loss: 0.5436480821264648
Validation loss: 2.749672480066469

Epoch: 5| Step: 9
Training loss: 0.47417343589306327
Validation loss: 2.8032676233803455

Epoch: 5| Step: 10
Training loss: 0.395090405645007
Validation loss: 2.752049159478648

Epoch: 5| Step: 11
Training loss: 0.32271569930491134
Validation loss: 2.7364999488906303

Epoch: 238| Step: 0
Training loss: 0.3100363055050493
Validation loss: 2.778629204015955

Epoch: 5| Step: 1
Training loss: 0.347292527657494
Validation loss: 2.773589023516361

Epoch: 5| Step: 2
Training loss: 0.5389533554376142
Validation loss: 2.7222081950911874

Epoch: 5| Step: 3
Training loss: 0.6762528951092868
Validation loss: 2.7642033940891158

Epoch: 5| Step: 4
Training loss: 0.37682850413298036
Validation loss: 2.7496163703911485

Epoch: 5| Step: 5
Training loss: 0.4134279102646298
Validation loss: 2.8255137934208845

Epoch: 5| Step: 6
Training loss: 0.34529394514195144
Validation loss: 2.7044172413842356

Epoch: 5| Step: 7
Training loss: 0.4969929633074169
Validation loss: 2.7857204933964845

Epoch: 5| Step: 8
Training loss: 0.5645063962514898
Validation loss: 2.84051820493403

Epoch: 5| Step: 9
Training loss: 1.2658331899954685
Validation loss: 2.8207518216916427

Epoch: 5| Step: 10
Training loss: 0.3448270051638871
Validation loss: 2.750756936226321

Epoch: 5| Step: 11
Training loss: 0.24759317190441515
Validation loss: 2.8292867195901823

Epoch: 239| Step: 0
Training loss: 1.1933306052178538
Validation loss: 2.6888583579959495

Epoch: 5| Step: 1
Training loss: 0.5479730209649695
Validation loss: 2.830864189224217

Epoch: 5| Step: 2
Training loss: 0.4951965148097512
Validation loss: 2.7458497902681396

Epoch: 5| Step: 3
Training loss: 0.5021226055039739
Validation loss: 2.7971549577737482

Epoch: 5| Step: 4
Training loss: 0.4003588035778021
Validation loss: 2.8174446967439417

Epoch: 5| Step: 5
Training loss: 0.47387324257547153
Validation loss: 2.827546466222979

Epoch: 5| Step: 6
Training loss: 0.431242366391497
Validation loss: 2.82811069660539

Epoch: 5| Step: 7
Training loss: 0.6801481987590364
Validation loss: 2.8419488820325016

Epoch: 5| Step: 8
Training loss: 0.4443983767727891
Validation loss: 2.8309051274155053

Epoch: 5| Step: 9
Training loss: 0.39129084105809564
Validation loss: 2.894457662988069

Epoch: 5| Step: 10
Training loss: 0.43933999194789936
Validation loss: 2.8134138424048287

Epoch: 5| Step: 11
Training loss: 0.3744989465079877
Validation loss: 2.86935933636103

Epoch: 240| Step: 0
Training loss: 0.477288069029489
Validation loss: 2.776814230987255

Epoch: 5| Step: 1
Training loss: 0.6348494958488443
Validation loss: 2.7493830588476227

Epoch: 5| Step: 2
Training loss: 0.5284956889540602
Validation loss: 2.8407011438760126

Epoch: 5| Step: 3
Training loss: 0.5775077463018574
Validation loss: 2.8576938988999463

Epoch: 5| Step: 4
Training loss: 0.4886245588757819
Validation loss: 2.8076361101038056

Epoch: 5| Step: 5
Training loss: 0.3260194913596935
Validation loss: 2.7964514441837403

Epoch: 5| Step: 6
Training loss: 0.49474304027201665
Validation loss: 2.7075815856995424

Epoch: 5| Step: 7
Training loss: 0.4701467684610287
Validation loss: 2.7653017842996235

Epoch: 5| Step: 8
Training loss: 0.5400258454124721
Validation loss: 2.8086821180085066

Epoch: 5| Step: 9
Training loss: 0.38938435948911604
Validation loss: 2.6976842276894306

Epoch: 5| Step: 10
Training loss: 1.1711418401553986
Validation loss: 2.8103503418531672

Epoch: 5| Step: 11
Training loss: 0.387866887867389
Validation loss: 2.8250565576658864

Epoch: 241| Step: 0
Training loss: 0.519820799485778
Validation loss: 2.6908047451010053

Epoch: 5| Step: 1
Training loss: 0.40057988229654723
Validation loss: 2.753857417834776

Epoch: 5| Step: 2
Training loss: 0.4616820416001961
Validation loss: 2.7910789160451803

Epoch: 5| Step: 3
Training loss: 0.5018476382786136
Validation loss: 2.803743205233042

Epoch: 5| Step: 4
Training loss: 0.5233301650496065
Validation loss: 2.7545493382833706

Epoch: 5| Step: 5
Training loss: 0.44101944576260604
Validation loss: 2.8895710853879986

Epoch: 5| Step: 6
Training loss: 0.40952366684722896
Validation loss: 2.728442373819367

Epoch: 5| Step: 7
Training loss: 1.1686335684159936
Validation loss: 2.800418832084985

Epoch: 5| Step: 8
Training loss: 0.515267161265382
Validation loss: 2.7640884714468035

Epoch: 5| Step: 9
Training loss: 0.6789060024177618
Validation loss: 2.8215474448015567

Epoch: 5| Step: 10
Training loss: 0.4612296035567873
Validation loss: 2.7997121326594723

Epoch: 5| Step: 11
Training loss: 0.28995063024427054
Validation loss: 2.821126998132165

Epoch: 242| Step: 0
Training loss: 0.507401108995939
Validation loss: 2.8429866332109905

Epoch: 5| Step: 1
Training loss: 0.43844779415104285
Validation loss: 2.8698726730313986

Epoch: 5| Step: 2
Training loss: 0.4215169199345197
Validation loss: 2.8456105339575735

Epoch: 5| Step: 3
Training loss: 0.5133574651282914
Validation loss: 2.808691289248794

Epoch: 5| Step: 4
Training loss: 1.1730470518251146
Validation loss: 2.8854322685526825

Epoch: 5| Step: 5
Training loss: 0.5285341179228085
Validation loss: 2.8053652228786867

Epoch: 5| Step: 6
Training loss: 0.42628005321752205
Validation loss: 2.7718263163801664

Epoch: 5| Step: 7
Training loss: 0.5034021621131766
Validation loss: 2.800163505951648

Epoch: 5| Step: 8
Training loss: 0.55105924692456
Validation loss: 2.8957215374468803

Epoch: 5| Step: 9
Training loss: 0.6844297256536772
Validation loss: 2.886458337417395

Epoch: 5| Step: 10
Training loss: 0.43421077642707373
Validation loss: 2.875178490502216

Epoch: 5| Step: 11
Training loss: 0.698434656465959
Validation loss: 2.8837571013690724

Epoch: 243| Step: 0
Training loss: 0.42140917314838766
Validation loss: 2.824257406741388

Epoch: 5| Step: 1
Training loss: 0.41911371221112487
Validation loss: 2.7931781112345693

Epoch: 5| Step: 2
Training loss: 0.5426406417873478
Validation loss: 2.795734993663849

Epoch: 5| Step: 3
Training loss: 0.680160818051773
Validation loss: 2.884988523501219

Epoch: 5| Step: 4
Training loss: 0.4026664439795733
Validation loss: 2.812186704069527

Epoch: 5| Step: 5
Training loss: 0.4602461981173443
Validation loss: 2.7499239361965153

Epoch: 5| Step: 6
Training loss: 0.3857815686174748
Validation loss: 2.7337170163446736

Epoch: 5| Step: 7
Training loss: 1.1414288862570006
Validation loss: 2.8445692873378383

Epoch: 5| Step: 8
Training loss: 0.48765169375612527
Validation loss: 2.875747469470723

Epoch: 5| Step: 9
Training loss: 0.6879730331214794
Validation loss: 2.7673637255043775

Epoch: 5| Step: 10
Training loss: 0.44780731714607575
Validation loss: 2.81702156064805

Epoch: 5| Step: 11
Training loss: 0.8089428208093695
Validation loss: 2.8747958684406267

Epoch: 244| Step: 0
Training loss: 0.5122240207352764
Validation loss: 2.759600678284331

Epoch: 5| Step: 1
Training loss: 0.3983402320465268
Validation loss: 2.8004636136613965

Epoch: 5| Step: 2
Training loss: 0.7504611584360629
Validation loss: 2.8045116040001123

Epoch: 5| Step: 3
Training loss: 0.29166018387992276
Validation loss: 2.7622673428636904

Epoch: 5| Step: 4
Training loss: 0.5148409459872725
Validation loss: 2.715546536674739

Epoch: 5| Step: 5
Training loss: 0.4787229439184217
Validation loss: 2.849091226289911

Epoch: 5| Step: 6
Training loss: 0.589144816832027
Validation loss: 2.8481133141723314

Epoch: 5| Step: 7
Training loss: 0.415065988901367
Validation loss: 2.8248087828126733

Epoch: 5| Step: 8
Training loss: 1.1188471277792895
Validation loss: 2.7839145754952845

Epoch: 5| Step: 9
Training loss: 0.45168039637398394
Validation loss: 2.8140347143506883

Epoch: 5| Step: 10
Training loss: 0.4358912248559121
Validation loss: 2.818722161171769

Epoch: 5| Step: 11
Training loss: 0.708507535120402
Validation loss: 2.7784498348783915

Epoch: 245| Step: 0
Training loss: 1.1587544716231268
Validation loss: 2.805853456999631

Epoch: 5| Step: 1
Training loss: 0.4839813417057924
Validation loss: 2.751968867462449

Epoch: 5| Step: 2
Training loss: 0.517939632051871
Validation loss: 2.87769275833857

Epoch: 5| Step: 3
Training loss: 0.5849237955621549
Validation loss: 2.77277200084081

Epoch: 5| Step: 4
Training loss: 0.3186924368174272
Validation loss: 2.8186168804157483

Epoch: 5| Step: 5
Training loss: 0.5710127463863839
Validation loss: 2.7281590280817607

Epoch: 5| Step: 6
Training loss: 0.5359581834900188
Validation loss: 2.859879662843107

Epoch: 5| Step: 7
Training loss: 0.4845287632686176
Validation loss: 2.826421481034934

Epoch: 5| Step: 8
Training loss: 0.6105169697745432
Validation loss: 2.766055107795628

Epoch: 5| Step: 9
Training loss: 0.4793859702127037
Validation loss: 2.800621959247909

Epoch: 5| Step: 10
Training loss: 0.43228946440108945
Validation loss: 2.827056528375248

Epoch: 5| Step: 11
Training loss: 0.3383054997692272
Validation loss: 2.8371364311571403

Epoch: 246| Step: 0
Training loss: 0.6029486106717997
Validation loss: 2.8440557601933243

Epoch: 5| Step: 1
Training loss: 0.43682369684061984
Validation loss: 2.7343833596238007

Epoch: 5| Step: 2
Training loss: 0.5700381677380439
Validation loss: 2.773525358429259

Epoch: 5| Step: 3
Training loss: 0.3854966359900856
Validation loss: 2.818018155272538

Epoch: 5| Step: 4
Training loss: 0.46958878493113293
Validation loss: 2.815244631772628

Epoch: 5| Step: 5
Training loss: 0.5546469337780969
Validation loss: 2.8354115834822395

Epoch: 5| Step: 6
Training loss: 0.48854346291944545
Validation loss: 2.7444497727352246

Epoch: 5| Step: 7
Training loss: 0.5260628579532673
Validation loss: 2.8212808089742403

Epoch: 5| Step: 8
Training loss: 1.1348732455723547
Validation loss: 2.7814210024780444

Epoch: 5| Step: 9
Training loss: 0.3480339677260474
Validation loss: 2.8250980441766465

Epoch: 5| Step: 10
Training loss: 0.29188584142150575
Validation loss: 2.831450374269212

Epoch: 5| Step: 11
Training loss: 0.6314938074398792
Validation loss: 2.782079119450355

Epoch: 247| Step: 0
Training loss: 0.415633621700035
Validation loss: 2.762983882176388

Epoch: 5| Step: 1
Training loss: 0.4718921885612455
Validation loss: 2.781810986095095

Epoch: 5| Step: 2
Training loss: 0.6393576390509407
Validation loss: 2.808880543291704

Epoch: 5| Step: 3
Training loss: 0.4064598091909472
Validation loss: 2.787322590689162

Epoch: 5| Step: 4
Training loss: 0.4216686733233284
Validation loss: 2.7976805203601307

Epoch: 5| Step: 5
Training loss: 0.579558656877018
Validation loss: 2.786522307805353

Epoch: 5| Step: 6
Training loss: 1.0475898693199346
Validation loss: 2.7526147866863755

Epoch: 5| Step: 7
Training loss: 0.44394782586315595
Validation loss: 2.831056619191506

Epoch: 5| Step: 8
Training loss: 0.5402155996329964
Validation loss: 2.718096954284051

Epoch: 5| Step: 9
Training loss: 0.4101920884233361
Validation loss: 2.835203567969178

Epoch: 5| Step: 10
Training loss: 0.5708385288623946
Validation loss: 2.823524628987052

Epoch: 5| Step: 11
Training loss: 0.3931822611978674
Validation loss: 2.8255941015257298

Epoch: 248| Step: 0
Training loss: 0.5051553901643807
Validation loss: 2.8207531317987886

Epoch: 5| Step: 1
Training loss: 0.5005374940076777
Validation loss: 2.827455803255625

Epoch: 5| Step: 2
Training loss: 0.5679709559086881
Validation loss: 2.760248867668908

Epoch: 5| Step: 3
Training loss: 0.6329015504322297
Validation loss: 2.8390745951748815

Epoch: 5| Step: 4
Training loss: 0.5185308073763009
Validation loss: 2.832657103388899

Epoch: 5| Step: 5
Training loss: 0.44353343890890445
Validation loss: 2.7588201452434085

Epoch: 5| Step: 6
Training loss: 0.6497505864885244
Validation loss: 2.868469644558885

Epoch: 5| Step: 7
Training loss: 1.0738459269580345
Validation loss: 2.833947831489413

Epoch: 5| Step: 8
Training loss: 0.5356355734174341
Validation loss: 2.7387848126665273

Epoch: 5| Step: 9
Training loss: 0.569747828157645
Validation loss: 2.742025495563677

Epoch: 5| Step: 10
Training loss: 0.47132449469424176
Validation loss: 2.7470575633625023

Epoch: 5| Step: 11
Training loss: 0.5167999175220754
Validation loss: 2.8505014892977494

Epoch: 249| Step: 0
Training loss: 0.4744110320910444
Validation loss: 2.7864300319387105

Epoch: 5| Step: 1
Training loss: 0.5007805394303017
Validation loss: 2.774287293315285

Epoch: 5| Step: 2
Training loss: 0.5083125659994647
Validation loss: 2.7620035588492216

Epoch: 5| Step: 3
Training loss: 0.6256979859543903
Validation loss: 2.7445750262610233

Epoch: 5| Step: 4
Training loss: 0.5943334373198393
Validation loss: 2.773064397511225

Epoch: 5| Step: 5
Training loss: 0.5491559552994161
Validation loss: 2.7609630739689566

Epoch: 5| Step: 6
Training loss: 0.40896908750627253
Validation loss: 2.7436592340481845

Epoch: 5| Step: 7
Training loss: 0.5066921199137655
Validation loss: 2.8346512665113455

Epoch: 5| Step: 8
Training loss: 1.0889159597926508
Validation loss: 2.740750855731723

Epoch: 5| Step: 9
Training loss: 0.4911048274015212
Validation loss: 2.824163489990459

Epoch: 5| Step: 10
Training loss: 0.5689645278781552
Validation loss: 2.850835076832138

Epoch: 5| Step: 11
Training loss: 0.38555414952427297
Validation loss: 2.8350074300831216

Epoch: 250| Step: 0
Training loss: 0.3814392370627921
Validation loss: 2.8447212928961503

Epoch: 5| Step: 1
Training loss: 0.34475358851669596
Validation loss: 2.768709779193216

Epoch: 5| Step: 2
Training loss: 0.4096925930402055
Validation loss: 2.8123558749252218

Epoch: 5| Step: 3
Training loss: 0.35829327363086644
Validation loss: 2.753265984598994

Epoch: 5| Step: 4
Training loss: 1.0343911852535523
Validation loss: 2.824581205642318

Epoch: 5| Step: 5
Training loss: 0.3406233560015001
Validation loss: 2.762563841428735

Epoch: 5| Step: 6
Training loss: 0.5610258601309089
Validation loss: 2.783640134533606

Epoch: 5| Step: 7
Training loss: 0.743158207593354
Validation loss: 2.7568540735804685

Epoch: 5| Step: 8
Training loss: 0.4995316159339784
Validation loss: 2.6994584801040915

Epoch: 5| Step: 9
Training loss: 0.5794738807782288
Validation loss: 2.75866731718256

Epoch: 5| Step: 10
Training loss: 0.5250383067914952
Validation loss: 2.810415958115074

Epoch: 5| Step: 11
Training loss: 0.5741427364769922
Validation loss: 2.859106687036913

Testing loss: 2.5317290215617896
