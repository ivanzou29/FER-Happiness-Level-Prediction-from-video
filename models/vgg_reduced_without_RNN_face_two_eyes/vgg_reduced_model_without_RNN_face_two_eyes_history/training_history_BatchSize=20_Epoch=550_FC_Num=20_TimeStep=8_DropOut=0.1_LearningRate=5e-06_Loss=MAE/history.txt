Epoch: 1| Step: 0
Training loss: 4.464421272277832
Validation loss: 4.027024934689204

Epoch: 5| Step: 1
Training loss: 4.393490791320801
Validation loss: 4.002619435389836

Epoch: 5| Step: 2
Training loss: 4.512803554534912
Validation loss: 3.979584892590841

Epoch: 5| Step: 3
Training loss: 4.126511096954346
Validation loss: 3.9572646220525107

Epoch: 5| Step: 4
Training loss: 4.007114410400391
Validation loss: 3.9358529150485992

Epoch: 5| Step: 5
Training loss: 3.4100093841552734
Validation loss: 3.9131417274475098

Epoch: 5| Step: 6
Training loss: 2.7592673301696777
Validation loss: 3.893901377916336

Epoch: 5| Step: 7
Training loss: 4.397100448608398
Validation loss: 3.8740877509117126

Epoch: 5| Step: 8
Training loss: 4.328615665435791
Validation loss: 3.852716604868571

Epoch: 5| Step: 9
Training loss: 4.135437965393066
Validation loss: 3.8318825165430703

Epoch: 5| Step: 10
Training loss: 4.357448577880859
Validation loss: 3.8120547334353128

Epoch: 5| Step: 11
Training loss: 2.6552977561950684
Validation loss: 3.7873512705167136

Epoch: 2| Step: 0
Training loss: 4.121983528137207
Validation loss: 3.7677265405654907

Epoch: 5| Step: 1
Training loss: 4.056613445281982
Validation loss: 3.744723548491796

Epoch: 5| Step: 2
Training loss: 3.721353530883789
Validation loss: 3.720831344525019

Epoch: 5| Step: 3
Training loss: 3.7537474632263184
Validation loss: 3.699788918097814

Epoch: 5| Step: 4
Training loss: 3.579279661178589
Validation loss: 3.6716053585211434

Epoch: 5| Step: 5
Training loss: 4.074902057647705
Validation loss: 3.6451985935370126

Epoch: 5| Step: 6
Training loss: 3.890301465988159
Validation loss: 3.618569552898407

Epoch: 5| Step: 7
Training loss: 4.034058570861816
Validation loss: 3.5861630042394004

Epoch: 5| Step: 8
Training loss: 2.45693039894104
Validation loss: 3.562277227640152

Epoch: 5| Step: 9
Training loss: 3.9710605144500732
Validation loss: 3.5289815862973533

Epoch: 5| Step: 10
Training loss: 3.7486820220947266
Validation loss: 3.503584752480189

Epoch: 5| Step: 11
Training loss: 5.14710807800293
Validation loss: 3.465318779150645

Epoch: 3| Step: 0
Training loss: 3.1538336277008057
Validation loss: 3.437670568625132

Epoch: 5| Step: 1
Training loss: 2.937035322189331
Validation loss: 3.398827701807022

Epoch: 5| Step: 2
Training loss: 3.8583931922912598
Validation loss: 3.36617241303126

Epoch: 5| Step: 3
Training loss: 3.6888351440429688
Validation loss: 3.3263548016548157

Epoch: 5| Step: 4
Training loss: 3.137939691543579
Validation loss: 3.293778399626414

Epoch: 5| Step: 5
Training loss: 3.4986233711242676
Validation loss: 3.258199771245321

Epoch: 5| Step: 6
Training loss: 2.529153347015381
Validation loss: 3.2176688412825265

Epoch: 5| Step: 7
Training loss: 3.1902756690979004
Validation loss: 3.174758325020472

Epoch: 5| Step: 8
Training loss: 3.8597800731658936
Validation loss: 3.140074700117111

Epoch: 5| Step: 9
Training loss: 3.6996636390686035
Validation loss: 3.0918863713741302

Epoch: 5| Step: 10
Training loss: 3.3992676734924316
Validation loss: 3.049858272075653

Epoch: 5| Step: 11
Training loss: 3.9924983978271484
Validation loss: 3.0035840968290963

Epoch: 4| Step: 0
Training loss: 3.3092403411865234
Validation loss: 2.959530850251516

Epoch: 5| Step: 1
Training loss: 3.3283801078796387
Validation loss: 2.903288553158442

Epoch: 5| Step: 2
Training loss: 3.244072675704956
Validation loss: 2.853910247484843

Epoch: 5| Step: 3
Training loss: 2.5758655071258545
Validation loss: 2.8037573794523873

Epoch: 5| Step: 4
Training loss: 3.2360503673553467
Validation loss: 2.750377833843231

Epoch: 5| Step: 5
Training loss: 3.0803964138031006
Validation loss: 2.6995480060577393

Epoch: 5| Step: 6
Training loss: 2.9982903003692627
Validation loss: 2.6410168011983237

Epoch: 5| Step: 7
Training loss: 2.8831076622009277
Validation loss: 2.580614517132441

Epoch: 5| Step: 8
Training loss: 2.288780689239502
Validation loss: 2.5301211178302765

Epoch: 5| Step: 9
Training loss: 2.4104437828063965
Validation loss: 2.4632004847129187

Epoch: 5| Step: 10
Training loss: 2.05981183052063
Validation loss: 2.4134179453055062

Epoch: 5| Step: 11
Training loss: 1.9937024116516113
Validation loss: 2.357572684685389

Epoch: 5| Step: 0
Training loss: 1.7377893924713135
Validation loss: 2.3172925412654877

Epoch: 5| Step: 1
Training loss: 2.8776228427886963
Validation loss: 2.28576922416687

Epoch: 5| Step: 2
Training loss: 2.497051954269409
Validation loss: 2.256441871325175

Epoch: 5| Step: 3
Training loss: 1.7219867706298828
Validation loss: 2.2193899154663086

Epoch: 5| Step: 4
Training loss: 2.4466419219970703
Validation loss: 2.1888126929601035

Epoch: 5| Step: 5
Training loss: 2.243389844894409
Validation loss: 2.160485620299975

Epoch: 5| Step: 6
Training loss: 2.6869261264801025
Validation loss: 2.114112436771393

Epoch: 5| Step: 7
Training loss: 2.243176221847534
Validation loss: 2.093308985233307

Epoch: 5| Step: 8
Training loss: 1.7484886646270752
Validation loss: 2.0628105302651725

Epoch: 5| Step: 9
Training loss: 2.0256779193878174
Validation loss: 2.051818067828814

Epoch: 5| Step: 10
Training loss: 1.9487899541854858
Validation loss: 2.049705316623052

Epoch: 5| Step: 11
Training loss: 3.474686622619629
Validation loss: 2.0473198940356574

Epoch: 6| Step: 0
Training loss: 1.5238792896270752
Validation loss: 2.0388060559829078

Epoch: 5| Step: 1
Training loss: 2.033459186553955
Validation loss: 2.050718367099762

Epoch: 5| Step: 2
Training loss: 1.6029846668243408
Validation loss: 2.0455533613761268

Epoch: 5| Step: 3
Training loss: 1.8570657968521118
Validation loss: 2.0626066476106644

Epoch: 5| Step: 4
Training loss: 1.8698304891586304
Validation loss: 2.065824881196022

Epoch: 5| Step: 5
Training loss: 2.540093183517456
Validation loss: 2.0802737176418304

Epoch: 5| Step: 6
Training loss: 3.3900630474090576
Validation loss: 2.089783305923144

Epoch: 5| Step: 7
Training loss: 1.8802763223648071
Validation loss: 2.0848545829455056

Epoch: 5| Step: 8
Training loss: 2.0619444847106934
Validation loss: 2.0821847965319953

Epoch: 5| Step: 9
Training loss: 2.3957290649414062
Validation loss: 2.0687289287646613

Epoch: 5| Step: 10
Training loss: 2.5059285163879395
Validation loss: 2.049173260728518

Epoch: 5| Step: 11
Training loss: 2.173715114593506
Validation loss: 2.0511118521293006

Epoch: 7| Step: 0
Training loss: 2.159996509552002
Validation loss: 2.0535880625247955

Epoch: 5| Step: 1
Training loss: 2.2111318111419678
Validation loss: 2.061872194210688

Epoch: 5| Step: 2
Training loss: 1.708041787147522
Validation loss: 2.030803377429644

Epoch: 5| Step: 3
Training loss: 2.344925880432129
Validation loss: 2.0217933853467307

Epoch: 5| Step: 4
Training loss: 1.8949893712997437
Validation loss: 2.019909938176473

Epoch: 5| Step: 5
Training loss: 2.2307815551757812
Validation loss: 2.0343804508447647

Epoch: 5| Step: 6
Training loss: 1.7772976160049438
Validation loss: 2.0275468279918036

Epoch: 5| Step: 7
Training loss: 2.135244131088257
Validation loss: 2.0224919815858207

Epoch: 5| Step: 8
Training loss: 2.2345664501190186
Validation loss: 2.037273878852526

Epoch: 5| Step: 9
Training loss: 2.1201634407043457
Validation loss: 2.031685764590899

Epoch: 5| Step: 10
Training loss: 2.153851270675659
Validation loss: 2.051165133714676

Epoch: 5| Step: 11
Training loss: 2.3979392051696777
Validation loss: 2.0266741514205933

Epoch: 8| Step: 0
Training loss: 2.257378101348877
Validation loss: 2.0309259494145713

Epoch: 5| Step: 1
Training loss: 2.226619243621826
Validation loss: 2.031850973765055

Epoch: 5| Step: 2
Training loss: 2.3927929401397705
Validation loss: 2.0263521720965705

Epoch: 5| Step: 3
Training loss: 1.4426581859588623
Validation loss: 2.0342894246180854

Epoch: 5| Step: 4
Training loss: 1.940301537513733
Validation loss: 2.0257351994514465

Epoch: 5| Step: 5
Training loss: 1.7206037044525146
Validation loss: 2.025395621856054

Epoch: 5| Step: 6
Training loss: 2.1311633586883545
Validation loss: 2.02261654039224

Epoch: 5| Step: 7
Training loss: 1.7439286708831787
Validation loss: 2.027202785015106

Epoch: 5| Step: 8
Training loss: 2.1634953022003174
Validation loss: 2.0351998706658683

Epoch: 5| Step: 9
Training loss: 2.508054256439209
Validation loss: 2.037956401705742

Epoch: 5| Step: 10
Training loss: 2.5275731086730957
Validation loss: 2.025291512409846

Epoch: 5| Step: 11
Training loss: 2.284639835357666
Validation loss: 2.029202530781428

Epoch: 9| Step: 0
Training loss: 2.465533971786499
Validation loss: 2.0234554956356683

Epoch: 5| Step: 1
Training loss: 2.3567612171173096
Validation loss: 2.01696814596653

Epoch: 5| Step: 2
Training loss: 2.2518622875213623
Validation loss: 2.0190000583728156

Epoch: 5| Step: 3
Training loss: 1.9307342767715454
Validation loss: 2.0258691360553107

Epoch: 5| Step: 4
Training loss: 1.5994237661361694
Validation loss: 2.004336232940356

Epoch: 5| Step: 5
Training loss: 2.046363353729248
Validation loss: 2.019100879629453

Epoch: 5| Step: 6
Training loss: 1.9128443002700806
Validation loss: 2.026173268755277

Epoch: 5| Step: 7
Training loss: 2.4585602283477783
Validation loss: 2.0282794137795768

Epoch: 5| Step: 8
Training loss: 1.668372392654419
Validation loss: 2.008693426847458

Epoch: 5| Step: 9
Training loss: 2.286400318145752
Validation loss: 2.021488850315412

Epoch: 5| Step: 10
Training loss: 1.8729664087295532
Validation loss: 2.0150330712397895

Epoch: 5| Step: 11
Training loss: 2.3442864418029785
Validation loss: 2.00046414633592

Epoch: 10| Step: 0
Training loss: 1.838029146194458
Validation loss: 2.0273419270912805

Epoch: 5| Step: 1
Training loss: 2.1783525943756104
Validation loss: 2.015515834093094

Epoch: 5| Step: 2
Training loss: 2.1891610622406006
Validation loss: 2.019653340180715

Epoch: 5| Step: 3
Training loss: 2.4768261909484863
Validation loss: 2.0020226538181305

Epoch: 5| Step: 4
Training loss: 1.554081678390503
Validation loss: 2.0146831423044205

Epoch: 5| Step: 5
Training loss: 1.8632376194000244
Validation loss: 2.020703539252281

Epoch: 5| Step: 6
Training loss: 2.250422716140747
Validation loss: 2.0274911423524222

Epoch: 5| Step: 7
Training loss: 1.8147834539413452
Validation loss: 2.010913242896398

Epoch: 5| Step: 8
Training loss: 2.7736637592315674
Validation loss: 2.009295552968979

Epoch: 5| Step: 9
Training loss: 2.1739463806152344
Validation loss: 2.0094215124845505

Epoch: 5| Step: 10
Training loss: 1.849013090133667
Validation loss: 2.0227479288975396

Epoch: 5| Step: 11
Training loss: 1.5470740795135498
Validation loss: 2.009610498944918

Epoch: 11| Step: 0
Training loss: 2.0862858295440674
Validation loss: 2.005958919723829

Epoch: 5| Step: 1
Training loss: 1.6099971532821655
Validation loss: 2.015317509571711

Epoch: 5| Step: 2
Training loss: 2.1171023845672607
Validation loss: 2.0078906416893005

Epoch: 5| Step: 3
Training loss: 2.227881908416748
Validation loss: 2.0190798292557397

Epoch: 5| Step: 4
Training loss: 2.816255569458008
Validation loss: 2.0086268484592438

Epoch: 5| Step: 5
Training loss: 1.8464233875274658
Validation loss: 2.0437268366416297

Epoch: 5| Step: 6
Training loss: 1.9215564727783203
Validation loss: 2.0138939221700034

Epoch: 5| Step: 7
Training loss: 2.291940450668335
Validation loss: 2.0213363021612167

Epoch: 5| Step: 8
Training loss: 1.7634693384170532
Validation loss: 2.023457184433937

Epoch: 5| Step: 9
Training loss: 2.1015372276306152
Validation loss: 2.0148085951805115

Epoch: 5| Step: 10
Training loss: 2.07649564743042
Validation loss: 2.0177624424298606

Epoch: 5| Step: 11
Training loss: 2.0301222801208496
Validation loss: 2.0117270400126777

Epoch: 12| Step: 0
Training loss: 2.337249279022217
Validation loss: 1.9990736097097397

Epoch: 5| Step: 1
Training loss: 2.507546901702881
Validation loss: 2.0068218310674033

Epoch: 5| Step: 2
Training loss: 2.4393980503082275
Validation loss: 1.9987775435050328

Epoch: 5| Step: 3
Training loss: 2.5583503246307373
Validation loss: 1.9988449811935425

Epoch: 5| Step: 4
Training loss: 1.86734139919281
Validation loss: 2.0037332624197006

Epoch: 5| Step: 5
Training loss: 2.0882530212402344
Validation loss: 2.0020650227864585

Epoch: 5| Step: 6
Training loss: 2.0480597019195557
Validation loss: 2.002697691321373

Epoch: 5| Step: 7
Training loss: 1.8041629791259766
Validation loss: 2.022785857319832

Epoch: 5| Step: 8
Training loss: 1.5722661018371582
Validation loss: 1.993978927532832

Epoch: 5| Step: 9
Training loss: 1.6803900003433228
Validation loss: 2.012963210542997

Epoch: 5| Step: 10
Training loss: 1.6982228755950928
Validation loss: 2.0030484050512314

Epoch: 5| Step: 11
Training loss: 2.10860538482666
Validation loss: 2.0105531165997186

Epoch: 13| Step: 0
Training loss: 1.9565913677215576
Validation loss: 1.9947451998790104

Epoch: 5| Step: 1
Training loss: 2.106557846069336
Validation loss: 1.9929226239522297

Epoch: 5| Step: 2
Training loss: 2.1349432468414307
Validation loss: 2.0012965401013694

Epoch: 5| Step: 3
Training loss: 2.378535747528076
Validation loss: 2.010076582431793

Epoch: 5| Step: 4
Training loss: 2.003842830657959
Validation loss: 2.003738150000572

Epoch: 5| Step: 5
Training loss: 2.049079179763794
Validation loss: 2.0026169220606485

Epoch: 5| Step: 6
Training loss: 2.1697731018066406
Validation loss: 2.018939142425855

Epoch: 5| Step: 7
Training loss: 2.0557925701141357
Validation loss: 2.0175061573584876

Epoch: 5| Step: 8
Training loss: 2.1445178985595703
Validation loss: 2.0111071368058524

Epoch: 5| Step: 9
Training loss: 1.4285072088241577
Validation loss: 2.0013288060824075

Epoch: 5| Step: 10
Training loss: 1.9920835494995117
Validation loss: 2.000600755214691

Epoch: 5| Step: 11
Training loss: 2.0616421699523926
Validation loss: 2.000175545612971

Epoch: 14| Step: 0
Training loss: 2.5659396648406982
Validation loss: 1.99307615061601

Epoch: 5| Step: 1
Training loss: 2.0426456928253174
Validation loss: 2.0020404706398645

Epoch: 5| Step: 2
Training loss: 1.77866530418396
Validation loss: 1.9965939472119014

Epoch: 5| Step: 3
Training loss: 1.8845579624176025
Validation loss: 1.9938530524571736

Epoch: 5| Step: 4
Training loss: 1.833505630493164
Validation loss: 1.9943135778109233

Epoch: 5| Step: 5
Training loss: 2.4852182865142822
Validation loss: 2.0031201243400574

Epoch: 5| Step: 6
Training loss: 2.1171927452087402
Validation loss: 1.9986307968695958

Epoch: 5| Step: 7
Training loss: 1.6267725229263306
Validation loss: 1.988895187775294

Epoch: 5| Step: 8
Training loss: 2.015270709991455
Validation loss: 1.9843287120262783

Epoch: 5| Step: 9
Training loss: 1.855691909790039
Validation loss: 1.9913416008154552

Epoch: 5| Step: 10
Training loss: 2.3125386238098145
Validation loss: 1.9854031205177307

Epoch: 5| Step: 11
Training loss: 0.8496612310409546
Validation loss: 1.990850364168485

Epoch: 15| Step: 0
Training loss: 2.1491854190826416
Validation loss: 1.9841658224662144

Epoch: 5| Step: 1
Training loss: 2.296027183532715
Validation loss: 1.994369313120842

Epoch: 5| Step: 2
Training loss: 1.7927404642105103
Validation loss: 1.9861940642197926

Epoch: 5| Step: 3
Training loss: 1.8062633275985718
Validation loss: 1.9838487307230632

Epoch: 5| Step: 4
Training loss: 2.510538101196289
Validation loss: 1.9825400809446971

Epoch: 5| Step: 5
Training loss: 2.2387447357177734
Validation loss: 1.9839273244142532

Epoch: 5| Step: 6
Training loss: 1.984156847000122
Validation loss: 1.9826475878556569

Epoch: 5| Step: 7
Training loss: 1.6193733215332031
Validation loss: 1.9740190158287685

Epoch: 5| Step: 8
Training loss: 1.6493316888809204
Validation loss: 1.993660752971967

Epoch: 5| Step: 9
Training loss: 2.333383560180664
Validation loss: 1.9814356813828151

Epoch: 5| Step: 10
Training loss: 1.7696059942245483
Validation loss: 1.9740712493658066

Epoch: 5| Step: 11
Training loss: 2.373891830444336
Validation loss: 1.9797770927349727

Epoch: 16| Step: 0
Training loss: 1.4780476093292236
Validation loss: 1.9850987295309703

Epoch: 5| Step: 1
Training loss: 2.3969478607177734
Validation loss: 1.9985899577538173

Epoch: 5| Step: 2
Training loss: 2.2103123664855957
Validation loss: 1.9797320812940598

Epoch: 5| Step: 3
Training loss: 1.8831470012664795
Validation loss: 1.980361446738243

Epoch: 5| Step: 4
Training loss: 2.2849934101104736
Validation loss: 1.9891621669133503

Epoch: 5| Step: 5
Training loss: 1.78859543800354
Validation loss: 1.9838155458370845

Epoch: 5| Step: 6
Training loss: 1.5928670167922974
Validation loss: 1.9768852641185124

Epoch: 5| Step: 7
Training loss: 2.331071138381958
Validation loss: 1.9884784022967021

Epoch: 5| Step: 8
Training loss: 2.017185926437378
Validation loss: 1.9880482405424118

Epoch: 5| Step: 9
Training loss: 1.7941710948944092
Validation loss: 1.9837619711955388

Epoch: 5| Step: 10
Training loss: 2.5280609130859375
Validation loss: 1.9821363190809886

Epoch: 5| Step: 11
Training loss: 1.6242178678512573
Validation loss: 1.9819932480653126

Epoch: 17| Step: 0
Training loss: 1.6650292873382568
Validation loss: 1.9783575733502705

Epoch: 5| Step: 1
Training loss: 2.548941135406494
Validation loss: 1.9587028821309407

Epoch: 5| Step: 2
Training loss: 2.106027126312256
Validation loss: 1.9808669487635295

Epoch: 5| Step: 3
Training loss: 2.1748757362365723
Validation loss: 1.966550201177597

Epoch: 5| Step: 4
Training loss: 2.471665143966675
Validation loss: 1.9861257920662563

Epoch: 5| Step: 5
Training loss: 1.8873956203460693
Validation loss: 1.9782030334075291

Epoch: 5| Step: 6
Training loss: 2.0691628456115723
Validation loss: 1.9915162374575932

Epoch: 5| Step: 7
Training loss: 1.5444083213806152
Validation loss: 1.9782308389743168

Epoch: 5| Step: 8
Training loss: 2.1147310733795166
Validation loss: 1.9783152441183727

Epoch: 5| Step: 9
Training loss: 2.028057336807251
Validation loss: 1.9723080893357594

Epoch: 5| Step: 10
Training loss: 1.74700927734375
Validation loss: 1.9731810688972473

Epoch: 5| Step: 11
Training loss: 0.9402108192443848
Validation loss: 1.975980818271637

Epoch: 18| Step: 0
Training loss: 2.6919102668762207
Validation loss: 1.993337815006574

Epoch: 5| Step: 1
Training loss: 1.8898566961288452
Validation loss: 1.9951695054769516

Epoch: 5| Step: 2
Training loss: 1.6714251041412354
Validation loss: 1.9820700486501057

Epoch: 5| Step: 3
Training loss: 2.227046489715576
Validation loss: 1.9811390191316605

Epoch: 5| Step: 4
Training loss: 2.091353416442871
Validation loss: 1.9887711356083553

Epoch: 5| Step: 5
Training loss: 1.9016224145889282
Validation loss: 1.977565348148346

Epoch: 5| Step: 6
Training loss: 1.5079877376556396
Validation loss: 1.9850755979617436

Epoch: 5| Step: 7
Training loss: 2.305525302886963
Validation loss: 1.9928387304147084

Epoch: 5| Step: 8
Training loss: 1.4256889820098877
Validation loss: 1.996127073963483

Epoch: 5| Step: 9
Training loss: 1.9259440898895264
Validation loss: 1.9816949864228566

Epoch: 5| Step: 10
Training loss: 2.26377534866333
Validation loss: 1.9975908249616623

Epoch: 5| Step: 11
Training loss: 2.46553373336792
Validation loss: 1.9863754908243816

Epoch: 19| Step: 0
Training loss: 2.1270225048065186
Validation loss: 1.984778384367625

Epoch: 5| Step: 1
Training loss: 2.0560507774353027
Validation loss: 1.9761615792910259

Epoch: 5| Step: 2
Training loss: 1.6104938983917236
Validation loss: 1.98415411512057

Epoch: 5| Step: 3
Training loss: 2.284397602081299
Validation loss: 1.977530653278033

Epoch: 5| Step: 4
Training loss: 2.0802345275878906
Validation loss: 1.9815115531285603

Epoch: 5| Step: 5
Training loss: 1.736098051071167
Validation loss: 1.9748440285523732

Epoch: 5| Step: 6
Training loss: 2.018096446990967
Validation loss: 1.9791801820198696

Epoch: 5| Step: 7
Training loss: 2.2434325218200684
Validation loss: 1.979434847831726

Epoch: 5| Step: 8
Training loss: 2.014991521835327
Validation loss: 1.9713256160418193

Epoch: 5| Step: 9
Training loss: 1.8487193584442139
Validation loss: 1.9598235835631688

Epoch: 5| Step: 10
Training loss: 2.149172306060791
Validation loss: 1.969228560725848

Epoch: 5| Step: 11
Training loss: 2.099773645401001
Validation loss: 1.973624810576439

Epoch: 20| Step: 0
Training loss: 2.3551013469696045
Validation loss: 1.9749788691600163

Epoch: 5| Step: 1
Training loss: 1.5139862298965454
Validation loss: 1.948164279262225

Epoch: 5| Step: 2
Training loss: 1.9886119365692139
Validation loss: 1.9702305148045223

Epoch: 5| Step: 3
Training loss: 1.5035936832427979
Validation loss: 1.9838667313257854

Epoch: 5| Step: 4
Training loss: 1.908661127090454
Validation loss: 1.9842544893423717

Epoch: 5| Step: 5
Training loss: 2.1956844329833984
Validation loss: 1.9839736719926198

Epoch: 5| Step: 6
Training loss: 1.846025824546814
Validation loss: 1.9972511877616246

Epoch: 5| Step: 7
Training loss: 1.9063680171966553
Validation loss: 2.000918666521708

Epoch: 5| Step: 8
Training loss: 1.9229049682617188
Validation loss: 1.9964357962210972

Epoch: 5| Step: 9
Training loss: 2.947166681289673
Validation loss: 2.0014728605747223

Epoch: 5| Step: 10
Training loss: 1.992687463760376
Validation loss: 1.988000790278117

Epoch: 5| Step: 11
Training loss: 2.1034393310546875
Validation loss: 1.9804914246002834

Epoch: 21| Step: 0
Training loss: 1.8533375263214111
Validation loss: 1.9771460791428883

Epoch: 5| Step: 1
Training loss: 1.3784961700439453
Validation loss: 1.9740482519070308

Epoch: 5| Step: 2
Training loss: 1.8426024913787842
Validation loss: 1.9732628266016643

Epoch: 5| Step: 3
Training loss: 1.8775030374526978
Validation loss: 1.9678995211919148

Epoch: 5| Step: 4
Training loss: 2.4275455474853516
Validation loss: 1.9660216768582661

Epoch: 5| Step: 5
Training loss: 2.070335865020752
Validation loss: 1.9775177091360092

Epoch: 5| Step: 6
Training loss: 2.09435772895813
Validation loss: 1.965895672639211

Epoch: 5| Step: 7
Training loss: 1.982750654220581
Validation loss: 1.9596669375896454

Epoch: 5| Step: 8
Training loss: 2.1293222904205322
Validation loss: 1.9667906264464061

Epoch: 5| Step: 9
Training loss: 1.7387691736221313
Validation loss: 1.9839223523934681

Epoch: 5| Step: 10
Training loss: 2.1281850337982178
Validation loss: 1.9660212695598602

Epoch: 5| Step: 11
Training loss: 4.06850528717041
Validation loss: 1.9758095939954121

Epoch: 22| Step: 0
Training loss: 2.2247154712677
Validation loss: 1.9773080895344417

Epoch: 5| Step: 1
Training loss: 2.3182120323181152
Validation loss: 1.9698120305935543

Epoch: 5| Step: 2
Training loss: 1.4662097692489624
Validation loss: 1.9736334284146626

Epoch: 5| Step: 3
Training loss: 2.054877996444702
Validation loss: 1.9536887506643932

Epoch: 5| Step: 4
Training loss: 2.092136859893799
Validation loss: 1.9756432871023815

Epoch: 5| Step: 5
Training loss: 2.15907621383667
Validation loss: 1.9595762491226196

Epoch: 5| Step: 6
Training loss: 2.058056592941284
Validation loss: 1.9723312159379323

Epoch: 5| Step: 7
Training loss: 1.586834192276001
Validation loss: 1.9805046220620472

Epoch: 5| Step: 8
Training loss: 2.1941113471984863
Validation loss: 1.971056491136551

Epoch: 5| Step: 9
Training loss: 1.951238989830017
Validation loss: 1.9641537169615428

Epoch: 5| Step: 10
Training loss: 1.9468631744384766
Validation loss: 1.9543682833512623

Epoch: 5| Step: 11
Training loss: 1.9796544313430786
Validation loss: 1.9599870244661968

Epoch: 23| Step: 0
Training loss: 2.0162665843963623
Validation loss: 1.9620454609394073

Epoch: 5| Step: 1
Training loss: 1.7865359783172607
Validation loss: 1.9833668073018391

Epoch: 5| Step: 2
Training loss: 2.0067245960235596
Validation loss: 1.9890089134375255

Epoch: 5| Step: 3
Training loss: 2.366328239440918
Validation loss: 1.9639566093683243

Epoch: 5| Step: 4
Training loss: 1.4187676906585693
Validation loss: 1.955645889043808

Epoch: 5| Step: 5
Training loss: 2.4202892780303955
Validation loss: 1.9788051098585129

Epoch: 5| Step: 6
Training loss: 2.137160539627075
Validation loss: 1.9620475520690281

Epoch: 5| Step: 7
Training loss: 1.9780429601669312
Validation loss: 1.9731433590253193

Epoch: 5| Step: 8
Training loss: 1.9716132879257202
Validation loss: 1.9731855889161427

Epoch: 5| Step: 9
Training loss: 1.8206186294555664
Validation loss: 1.9744339734315872

Epoch: 5| Step: 10
Training loss: 1.67597234249115
Validation loss: 1.9813688198725383

Epoch: 5| Step: 11
Training loss: 2.777500629425049
Validation loss: 1.9861351450284321

Epoch: 24| Step: 0
Training loss: 2.178616762161255
Validation loss: 1.9750440766414006

Epoch: 5| Step: 1
Training loss: 1.7813113927841187
Validation loss: 1.97676054139932

Epoch: 5| Step: 2
Training loss: 2.2805652618408203
Validation loss: 1.9810823102792103

Epoch: 5| Step: 3
Training loss: 1.933445692062378
Validation loss: 1.9916718155145645

Epoch: 5| Step: 4
Training loss: 1.3141475915908813
Validation loss: 1.9661676287651062

Epoch: 5| Step: 5
Training loss: 2.228494644165039
Validation loss: 1.9778991589943569

Epoch: 5| Step: 6
Training loss: 1.426391363143921
Validation loss: 1.9747827400763829

Epoch: 5| Step: 7
Training loss: 2.087307929992676
Validation loss: 1.9726384083429973

Epoch: 5| Step: 8
Training loss: 1.730991005897522
Validation loss: 1.968017116189003

Epoch: 5| Step: 9
Training loss: 2.5247631072998047
Validation loss: 1.9553296516338985

Epoch: 5| Step: 10
Training loss: 2.1289632320404053
Validation loss: 1.960513527194659

Epoch: 5| Step: 11
Training loss: 2.3642609119415283
Validation loss: 1.958004171649615

Epoch: 25| Step: 0
Training loss: 1.3714659214019775
Validation loss: 1.9807386994361877

Epoch: 5| Step: 1
Training loss: 1.6214882135391235
Validation loss: 1.962609812617302

Epoch: 5| Step: 2
Training loss: 1.9381887912750244
Validation loss: 1.9685471554597218

Epoch: 5| Step: 3
Training loss: 1.9076805114746094
Validation loss: 1.976372629404068

Epoch: 5| Step: 4
Training loss: 1.7523329257965088
Validation loss: 1.9818795025348663

Epoch: 5| Step: 5
Training loss: 1.6500333547592163
Validation loss: 1.9621035655339558

Epoch: 5| Step: 6
Training loss: 2.4744479656219482
Validation loss: 1.9816319743792217

Epoch: 5| Step: 7
Training loss: 2.7647202014923096
Validation loss: 1.9930045306682587

Epoch: 5| Step: 8
Training loss: 1.7035290002822876
Validation loss: 1.9721754789352417

Epoch: 5| Step: 9
Training loss: 2.2816901206970215
Validation loss: 1.9543571869532268

Epoch: 5| Step: 10
Training loss: 2.1577537059783936
Validation loss: 1.961204042037328

Epoch: 5| Step: 11
Training loss: 2.693653106689453
Validation loss: 1.9413312673568726

Epoch: 26| Step: 0
Training loss: 1.8577800989151
Validation loss: 1.9654717793067296

Epoch: 5| Step: 1
Training loss: 1.8044166564941406
Validation loss: 1.9668755928675334

Epoch: 5| Step: 2
Training loss: 1.703376054763794
Validation loss: 1.9404260367155075

Epoch: 5| Step: 3
Training loss: 1.9440267086029053
Validation loss: 1.9461776713530223

Epoch: 5| Step: 4
Training loss: 2.1430130004882812
Validation loss: 1.9667121420303981

Epoch: 5| Step: 5
Training loss: 2.2750368118286133
Validation loss: 1.976413791378339

Epoch: 5| Step: 6
Training loss: 2.1345386505126953
Validation loss: 1.9611871838569641

Epoch: 5| Step: 7
Training loss: 2.3131136894226074
Validation loss: 1.9556910246610641

Epoch: 5| Step: 8
Training loss: 1.5727379322052002
Validation loss: 1.9699223289887111

Epoch: 5| Step: 9
Training loss: 1.6715567111968994
Validation loss: 1.9642611145973206

Epoch: 5| Step: 10
Training loss: 2.012692928314209
Validation loss: 1.9762286841869354

Epoch: 5| Step: 11
Training loss: 3.1907196044921875
Validation loss: 1.9665168921152751

Epoch: 27| Step: 0
Training loss: 1.5208028554916382
Validation loss: 1.9864002217849095

Epoch: 5| Step: 1
Training loss: 2.3161919116973877
Validation loss: 1.9722927113374074

Epoch: 5| Step: 2
Training loss: 1.7604938745498657
Validation loss: 1.9755038022994995

Epoch: 5| Step: 3
Training loss: 1.982267141342163
Validation loss: 1.9816666742165883

Epoch: 5| Step: 4
Training loss: 1.6976810693740845
Validation loss: 1.9717268447081249

Epoch: 5| Step: 5
Training loss: 1.7557865381240845
Validation loss: 1.980935623248418

Epoch: 5| Step: 6
Training loss: 2.3862295150756836
Validation loss: 1.9905715584754944

Epoch: 5| Step: 7
Training loss: 2.191878080368042
Validation loss: 1.9916980465253193

Epoch: 5| Step: 8
Training loss: 2.605879068374634
Validation loss: 1.972962702314059

Epoch: 5| Step: 9
Training loss: 1.5849637985229492
Validation loss: 1.9689021954933803

Epoch: 5| Step: 10
Training loss: 1.922120451927185
Validation loss: 1.9724867244561513

Epoch: 5| Step: 11
Training loss: 1.5245187282562256
Validation loss: 1.9648549258708954

Epoch: 28| Step: 0
Training loss: 1.6383426189422607
Validation loss: 1.9658818344275157

Epoch: 5| Step: 1
Training loss: 2.1332099437713623
Validation loss: 1.9640190054972966

Epoch: 5| Step: 2
Training loss: 1.6206365823745728
Validation loss: 1.959969197710355

Epoch: 5| Step: 3
Training loss: 1.5522254705429077
Validation loss: 1.9667580127716064

Epoch: 5| Step: 4
Training loss: 2.1282105445861816
Validation loss: 1.961907962958018

Epoch: 5| Step: 5
Training loss: 1.8166688680648804
Validation loss: 1.9712567577759426

Epoch: 5| Step: 6
Training loss: 2.6697468757629395
Validation loss: 1.9759339193503063

Epoch: 5| Step: 7
Training loss: 1.5115575790405273
Validation loss: 1.9664076219002407

Epoch: 5| Step: 8
Training loss: 2.1906425952911377
Validation loss: 1.9673170099655788

Epoch: 5| Step: 9
Training loss: 1.9784997701644897
Validation loss: 1.9617418150107067

Epoch: 5| Step: 10
Training loss: 2.5763676166534424
Validation loss: 1.9782012303670247

Epoch: 5| Step: 11
Training loss: 1.4399793148040771
Validation loss: 1.9689444303512573

Epoch: 29| Step: 0
Training loss: 1.7987391948699951
Validation loss: 1.989550640185674

Epoch: 5| Step: 1
Training loss: 2.263927698135376
Validation loss: 1.9853187302748363

Epoch: 5| Step: 2
Training loss: 2.3623578548431396
Validation loss: 1.983481804529826

Epoch: 5| Step: 3
Training loss: 1.9991363286972046
Validation loss: 1.9761839459339778

Epoch: 5| Step: 4
Training loss: 1.8359920978546143
Validation loss: 1.9699354668458302

Epoch: 5| Step: 5
Training loss: 2.1302378177642822
Validation loss: 1.9705578982830048

Epoch: 5| Step: 6
Training loss: 2.0250096321105957
Validation loss: 1.9552731464306514

Epoch: 5| Step: 7
Training loss: 1.457951307296753
Validation loss: 1.9607531527678173

Epoch: 5| Step: 8
Training loss: 1.9636662006378174
Validation loss: 1.9508902976910274

Epoch: 5| Step: 9
Training loss: 2.3577282428741455
Validation loss: 1.9652762015660603

Epoch: 5| Step: 10
Training loss: 1.436410665512085
Validation loss: 1.9646878689527512

Epoch: 5| Step: 11
Training loss: 2.253180503845215
Validation loss: 1.963562513391177

Epoch: 30| Step: 0
Training loss: 2.331754207611084
Validation loss: 1.968897894024849

Epoch: 5| Step: 1
Training loss: 1.8036302328109741
Validation loss: 1.9918479373057683

Epoch: 5| Step: 2
Training loss: 1.908726453781128
Validation loss: 1.9745075702667236

Epoch: 5| Step: 3
Training loss: 2.157062530517578
Validation loss: 1.9737056891123455

Epoch: 5| Step: 4
Training loss: 2.433898448944092
Validation loss: 1.98728613058726

Epoch: 5| Step: 5
Training loss: 2.407317638397217
Validation loss: 1.9962068398793538

Epoch: 5| Step: 6
Training loss: 1.615685224533081
Validation loss: 1.993225226799647

Epoch: 5| Step: 7
Training loss: 1.4052648544311523
Validation loss: 1.9691172987222672

Epoch: 5| Step: 8
Training loss: 1.8952624797821045
Validation loss: 1.9802588572104771

Epoch: 5| Step: 9
Training loss: 1.9296563863754272
Validation loss: 1.9801201870044072

Epoch: 5| Step: 10
Training loss: 1.6969064474105835
Validation loss: 1.954904168844223

Epoch: 5| Step: 11
Training loss: 1.3848236799240112
Validation loss: 1.9777400195598602

Epoch: 31| Step: 0
Training loss: 2.439748525619507
Validation loss: 1.9622749487559001

Epoch: 5| Step: 1
Training loss: 2.1107122898101807
Validation loss: 1.9624504645665486

Epoch: 5| Step: 2
Training loss: 2.349773406982422
Validation loss: 1.9740721732378006

Epoch: 5| Step: 3
Training loss: 2.1812853813171387
Validation loss: 1.9708406031131744

Epoch: 5| Step: 4
Training loss: 2.040428638458252
Validation loss: 1.967955509821574

Epoch: 5| Step: 5
Training loss: 1.6037193536758423
Validation loss: 1.9551684508721034

Epoch: 5| Step: 6
Training loss: 2.0339112281799316
Validation loss: 1.969384362300237

Epoch: 5| Step: 7
Training loss: 1.4571043252944946
Validation loss: 1.9564437866210938

Epoch: 5| Step: 8
Training loss: 1.577027440071106
Validation loss: 1.9665808926026027

Epoch: 5| Step: 9
Training loss: 1.9673984050750732
Validation loss: 1.9840851426124573

Epoch: 5| Step: 10
Training loss: 1.8045371770858765
Validation loss: 1.968435525894165

Epoch: 5| Step: 11
Training loss: 1.980724811553955
Validation loss: 1.962118407090505

Epoch: 32| Step: 0
Training loss: 2.364943265914917
Validation loss: 1.9660479575395584

Epoch: 5| Step: 1
Training loss: 1.6185516119003296
Validation loss: 1.965410202741623

Epoch: 5| Step: 2
Training loss: 1.7587820291519165
Validation loss: 1.9623318761587143

Epoch: 5| Step: 3
Training loss: 2.0108351707458496
Validation loss: 1.966706742842992

Epoch: 5| Step: 4
Training loss: 2.113785982131958
Validation loss: 1.9677976618210475

Epoch: 5| Step: 5
Training loss: 1.8039112091064453
Validation loss: 1.9601139773925145

Epoch: 5| Step: 6
Training loss: 1.6227744817733765
Validation loss: 1.952761063973109

Epoch: 5| Step: 7
Training loss: 1.9599800109863281
Validation loss: 1.9602811733881633

Epoch: 5| Step: 8
Training loss: 2.029087543487549
Validation loss: 1.9839443564414978

Epoch: 5| Step: 9
Training loss: 2.258822441101074
Validation loss: 1.9585720698038738

Epoch: 5| Step: 10
Training loss: 1.7493953704833984
Validation loss: 1.9829104989767075

Epoch: 5| Step: 11
Training loss: 2.0740253925323486
Validation loss: 1.9677462875843048

Epoch: 33| Step: 0
Training loss: 2.065141201019287
Validation loss: 1.9723425259192784

Epoch: 5| Step: 1
Training loss: 2.2264585494995117
Validation loss: 1.9640080233414967

Epoch: 5| Step: 2
Training loss: 1.7365844249725342
Validation loss: 1.9674457212289174

Epoch: 5| Step: 3
Training loss: 1.929104208946228
Validation loss: 1.9592825025320053

Epoch: 5| Step: 4
Training loss: 1.881525993347168
Validation loss: 1.9609704862038295

Epoch: 5| Step: 5
Training loss: 2.184046745300293
Validation loss: 1.9673038572072983

Epoch: 5| Step: 6
Training loss: 1.8070528507232666
Validation loss: 1.97159443795681

Epoch: 5| Step: 7
Training loss: 2.0356411933898926
Validation loss: 1.9591023822625477

Epoch: 5| Step: 8
Training loss: 1.5858672857284546
Validation loss: 1.9522874802350998

Epoch: 5| Step: 9
Training loss: 1.5482852458953857
Validation loss: 1.9484940717617671

Epoch: 5| Step: 10
Training loss: 2.3124663829803467
Validation loss: 1.9655112971862156

Epoch: 5| Step: 11
Training loss: 2.3150954246520996
Validation loss: 1.9463941901922226

Epoch: 34| Step: 0
Training loss: 2.256680965423584
Validation loss: 1.9632788350184758

Epoch: 5| Step: 1
Training loss: 1.8244903087615967
Validation loss: 1.9699020981788635

Epoch: 5| Step: 2
Training loss: 1.840606927871704
Validation loss: 1.9672923584779103

Epoch: 5| Step: 3
Training loss: 1.667859435081482
Validation loss: 1.9768920292456944

Epoch: 5| Step: 4
Training loss: 1.546979546546936
Validation loss: 1.9718050559361775

Epoch: 5| Step: 5
Training loss: 2.105684757232666
Validation loss: 1.9918243338664372

Epoch: 5| Step: 6
Training loss: 1.9105727672576904
Validation loss: 1.9921477337678273

Epoch: 5| Step: 7
Training loss: 2.326627016067505
Validation loss: 1.9899601687987645

Epoch: 5| Step: 8
Training loss: 1.7991644144058228
Validation loss: 1.992764522631963

Epoch: 5| Step: 9
Training loss: 1.9673397541046143
Validation loss: 2.0006626894076667

Epoch: 5| Step: 10
Training loss: 2.1443543434143066
Validation loss: 1.9816392759482067

Epoch: 5| Step: 11
Training loss: 2.29447340965271
Validation loss: 1.991440976659457

Epoch: 35| Step: 0
Training loss: 1.8126195669174194
Validation loss: 1.9802020341157913

Epoch: 5| Step: 1
Training loss: 1.5060464143753052
Validation loss: 1.9795831243197124

Epoch: 5| Step: 2
Training loss: 2.539524555206299
Validation loss: 1.9693322976430256

Epoch: 5| Step: 3
Training loss: 1.4939641952514648
Validation loss: 1.9589853634436925

Epoch: 5| Step: 4
Training loss: 1.881039023399353
Validation loss: 1.9560545831918716

Epoch: 5| Step: 5
Training loss: 2.1246354579925537
Validation loss: 1.9661349554856618

Epoch: 5| Step: 6
Training loss: 2.2514255046844482
Validation loss: 1.9657956262429555

Epoch: 5| Step: 7
Training loss: 2.123674154281616
Validation loss: 1.9585206657648087

Epoch: 5| Step: 8
Training loss: 2.0155882835388184
Validation loss: 1.9578237235546112

Epoch: 5| Step: 9
Training loss: 1.6927849054336548
Validation loss: 1.9522976527611415

Epoch: 5| Step: 10
Training loss: 1.7002578973770142
Validation loss: 1.9546509087085724

Epoch: 5| Step: 11
Training loss: 3.638190269470215
Validation loss: 1.9630889346202214

Epoch: 36| Step: 0
Training loss: 1.5798782110214233
Validation loss: 1.9562284350395203

Epoch: 5| Step: 1
Training loss: 1.9690660238265991
Validation loss: 1.9589679539203644

Epoch: 5| Step: 2
Training loss: 1.7986434698104858
Validation loss: 1.9813313782215118

Epoch: 5| Step: 3
Training loss: 2.0556869506835938
Validation loss: 1.9615229417880375

Epoch: 5| Step: 4
Training loss: 1.6598182916641235
Validation loss: 1.9662660012642543

Epoch: 5| Step: 5
Training loss: 1.7238805294036865
Validation loss: 1.9621291210254033

Epoch: 5| Step: 6
Training loss: 2.1538803577423096
Validation loss: 1.9803633193174999

Epoch: 5| Step: 7
Training loss: 2.038328170776367
Validation loss: 1.9842618256807327

Epoch: 5| Step: 8
Training loss: 2.1393463611602783
Validation loss: 1.9817879845698674

Epoch: 5| Step: 9
Training loss: 2.2212231159210205
Validation loss: 1.9980219850937526

Epoch: 5| Step: 10
Training loss: 2.246885061264038
Validation loss: 1.9882927934328716

Epoch: 5| Step: 11
Training loss: 1.4413278102874756
Validation loss: 1.9859789609909058

Epoch: 37| Step: 0
Training loss: 1.2710044384002686
Validation loss: 1.9876368989547093

Epoch: 5| Step: 1
Training loss: 1.260706901550293
Validation loss: 1.9823849201202393

Epoch: 5| Step: 2
Training loss: 2.1633737087249756
Validation loss: 1.9558181713024776

Epoch: 5| Step: 3
Training loss: 2.5171923637390137
Validation loss: 1.9700779219468434

Epoch: 5| Step: 4
Training loss: 2.141608476638794
Validation loss: 1.9660865813493729

Epoch: 5| Step: 5
Training loss: 1.9380515813827515
Validation loss: 1.9509220272302628

Epoch: 5| Step: 6
Training loss: 2.1271157264709473
Validation loss: 1.9592081606388092

Epoch: 5| Step: 7
Training loss: 1.5104615688323975
Validation loss: 1.9605076760053635

Epoch: 5| Step: 8
Training loss: 2.173152208328247
Validation loss: 1.9678208380937576

Epoch: 5| Step: 9
Training loss: 2.278517246246338
Validation loss: 1.9679020096858342

Epoch: 5| Step: 10
Training loss: 2.0298023223876953
Validation loss: 1.9666790316502254

Epoch: 5| Step: 11
Training loss: 0.8449715375900269
Validation loss: 1.963788112004598

Epoch: 38| Step: 0
Training loss: 1.8468420505523682
Validation loss: 1.9569633603096008

Epoch: 5| Step: 1
Training loss: 2.0047521591186523
Validation loss: 1.967603216568629

Epoch: 5| Step: 2
Training loss: 1.4563848972320557
Validation loss: 1.959934189915657

Epoch: 5| Step: 3
Training loss: 2.5359725952148438
Validation loss: 1.9618850300709407

Epoch: 5| Step: 4
Training loss: 1.2897415161132812
Validation loss: 1.9607987801233928

Epoch: 5| Step: 5
Training loss: 1.504429578781128
Validation loss: 1.9514534523089726

Epoch: 5| Step: 6
Training loss: 1.5057803392410278
Validation loss: 1.9667644848426182

Epoch: 5| Step: 7
Training loss: 2.2859702110290527
Validation loss: 1.980627770225207

Epoch: 5| Step: 8
Training loss: 2.2746801376342773
Validation loss: 1.957616165280342

Epoch: 5| Step: 9
Training loss: 2.3694984912872314
Validation loss: 1.9771479318539302

Epoch: 5| Step: 10
Training loss: 2.1222801208496094
Validation loss: 1.9540709058443706

Epoch: 5| Step: 11
Training loss: 1.6087799072265625
Validation loss: 1.9614019493261974

Epoch: 39| Step: 0
Training loss: 1.6075150966644287
Validation loss: 1.9713148921728134

Epoch: 5| Step: 1
Training loss: 2.150073766708374
Validation loss: 1.9669426133235295

Epoch: 5| Step: 2
Training loss: 1.2784359455108643
Validation loss: 1.9644589225451152

Epoch: 5| Step: 3
Training loss: 1.818937063217163
Validation loss: 1.9544557730356853

Epoch: 5| Step: 4
Training loss: 1.8366897106170654
Validation loss: 1.9671697914600372

Epoch: 5| Step: 5
Training loss: 1.9324042797088623
Validation loss: 1.9562554061412811

Epoch: 5| Step: 6
Training loss: 1.8638875484466553
Validation loss: 1.949005052447319

Epoch: 5| Step: 7
Training loss: 2.024538516998291
Validation loss: 1.9629101554552715

Epoch: 5| Step: 8
Training loss: 2.3593034744262695
Validation loss: 1.9617569595575333

Epoch: 5| Step: 9
Training loss: 1.815812349319458
Validation loss: 1.953329046567281

Epoch: 5| Step: 10
Training loss: 2.401960849761963
Validation loss: 1.965834066271782

Epoch: 5| Step: 11
Training loss: 1.7449184656143188
Validation loss: 1.970205361644427

Epoch: 40| Step: 0
Training loss: 2.2836854457855225
Validation loss: 1.9823198020458221

Epoch: 5| Step: 1
Training loss: 3.041093111038208
Validation loss: 1.946209008495013

Epoch: 5| Step: 2
Training loss: 1.3638063669204712
Validation loss: 1.973415310184161

Epoch: 5| Step: 3
Training loss: 1.885981559753418
Validation loss: 1.9590797573328018

Epoch: 5| Step: 4
Training loss: 2.352673292160034
Validation loss: 1.949258993069331

Epoch: 5| Step: 5
Training loss: 1.547120451927185
Validation loss: 1.964888537923495

Epoch: 5| Step: 6
Training loss: 2.028226852416992
Validation loss: 1.9645565450191498

Epoch: 5| Step: 7
Training loss: 1.7119290828704834
Validation loss: 1.9514440943797429

Epoch: 5| Step: 8
Training loss: 1.685887098312378
Validation loss: 1.9576307634512584

Epoch: 5| Step: 9
Training loss: 1.7062017917633057
Validation loss: 1.9366319278875987

Epoch: 5| Step: 10
Training loss: 1.5555200576782227
Validation loss: 1.9520127177238464

Epoch: 5| Step: 11
Training loss: 1.240438461303711
Validation loss: 1.966874212026596

Epoch: 41| Step: 0
Training loss: 2.681267261505127
Validation loss: 1.9583367258310318

Epoch: 5| Step: 1
Training loss: 1.679782509803772
Validation loss: 1.9616352667411168

Epoch: 5| Step: 2
Training loss: 1.9234836101531982
Validation loss: 1.95932740966479

Epoch: 5| Step: 3
Training loss: 1.9807323217391968
Validation loss: 1.965234602491061

Epoch: 5| Step: 4
Training loss: 1.9122507572174072
Validation loss: 1.9603792428970337

Epoch: 5| Step: 5
Training loss: 1.9139467477798462
Validation loss: 1.9550327360630035

Epoch: 5| Step: 6
Training loss: 1.9330205917358398
Validation loss: 1.9507097552220027

Epoch: 5| Step: 7
Training loss: 1.5653390884399414
Validation loss: 1.988959367076556

Epoch: 5| Step: 8
Training loss: 1.6416890621185303
Validation loss: 1.9504965643088024

Epoch: 5| Step: 9
Training loss: 2.1010990142822266
Validation loss: 1.965573678414027

Epoch: 5| Step: 10
Training loss: 1.8070557117462158
Validation loss: 1.950695405403773

Epoch: 5| Step: 11
Training loss: 2.091447591781616
Validation loss: 1.967329536875089

Epoch: 42| Step: 0
Training loss: 2.166891098022461
Validation loss: 1.9694070667028427

Epoch: 5| Step: 1
Training loss: 1.8794227838516235
Validation loss: 1.962049439549446

Epoch: 5| Step: 2
Training loss: 1.5796223878860474
Validation loss: 1.9558396091063817

Epoch: 5| Step: 3
Training loss: 2.3430614471435547
Validation loss: 1.9637974003950756

Epoch: 5| Step: 4
Training loss: 2.3305296897888184
Validation loss: 1.9648078233003616

Epoch: 5| Step: 5
Training loss: 1.986725091934204
Validation loss: 1.962701087196668

Epoch: 5| Step: 6
Training loss: 2.3775885105133057
Validation loss: 1.9434804320335388

Epoch: 5| Step: 7
Training loss: 1.3479390144348145
Validation loss: 1.957761491338412

Epoch: 5| Step: 8
Training loss: 1.9320728778839111
Validation loss: 1.962414637207985

Epoch: 5| Step: 9
Training loss: 1.2630012035369873
Validation loss: 1.949088583389918

Epoch: 5| Step: 10
Training loss: 1.8062036037445068
Validation loss: 1.9591976255178452

Epoch: 5| Step: 11
Training loss: 1.803696632385254
Validation loss: 1.9658280958731968

Epoch: 43| Step: 0
Training loss: 1.9728542566299438
Validation loss: 1.9759831130504608

Epoch: 5| Step: 1
Training loss: 1.948664903640747
Validation loss: 1.9710791011651356

Epoch: 5| Step: 2
Training loss: 1.9701534509658813
Validation loss: 1.961215967933337

Epoch: 5| Step: 3
Training loss: 1.3455719947814941
Validation loss: 1.9633109718561172

Epoch: 5| Step: 4
Training loss: 2.502840042114258
Validation loss: 1.9645248701175053

Epoch: 5| Step: 5
Training loss: 1.5844475030899048
Validation loss: 1.9573390285174053

Epoch: 5| Step: 6
Training loss: 1.8172229528427124
Validation loss: 1.963334654768308

Epoch: 5| Step: 7
Training loss: 2.1135761737823486
Validation loss: 1.9610729366540909

Epoch: 5| Step: 8
Training loss: 1.5104734897613525
Validation loss: 1.9486970255772273

Epoch: 5| Step: 9
Training loss: 1.7305853366851807
Validation loss: 1.9562588731447856

Epoch: 5| Step: 10
Training loss: 2.183795213699341
Validation loss: 1.9638876567284267

Epoch: 5| Step: 11
Training loss: 3.2248878479003906
Validation loss: 1.9567458977301915

Epoch: 44| Step: 0
Training loss: 1.3920649290084839
Validation loss: 1.9535696456829708

Epoch: 5| Step: 1
Training loss: 1.734209656715393
Validation loss: 1.9457614868879318

Epoch: 5| Step: 2
Training loss: 2.3594043254852295
Validation loss: 1.9554913292328517

Epoch: 5| Step: 3
Training loss: 1.9589523077011108
Validation loss: 1.977357213695844

Epoch: 5| Step: 4
Training loss: 1.966070532798767
Validation loss: 1.9516661117474239

Epoch: 5| Step: 5
Training loss: 1.9985215663909912
Validation loss: 1.9635689904292424

Epoch: 5| Step: 6
Training loss: 1.8535568714141846
Validation loss: 1.940171256661415

Epoch: 5| Step: 7
Training loss: 1.8954594135284424
Validation loss: 1.9644711116949718

Epoch: 5| Step: 8
Training loss: 2.0044844150543213
Validation loss: 1.9572585821151733

Epoch: 5| Step: 9
Training loss: 1.7903438806533813
Validation loss: 1.948944017291069

Epoch: 5| Step: 10
Training loss: 2.1306474208831787
Validation loss: 1.9693377912044525

Epoch: 5| Step: 11
Training loss: 1.269911766052246
Validation loss: 1.9912127653757732

Epoch: 45| Step: 0
Training loss: 1.5433299541473389
Validation loss: 1.9718588888645172

Epoch: 5| Step: 1
Training loss: 1.8760112524032593
Validation loss: 1.971891110142072

Epoch: 5| Step: 2
Training loss: 2.1951491832733154
Validation loss: 1.9643990049759548

Epoch: 5| Step: 3
Training loss: 1.4911701679229736
Validation loss: 1.9563935895760853

Epoch: 5| Step: 4
Training loss: 1.5591487884521484
Validation loss: 1.9540886332591374

Epoch: 5| Step: 5
Training loss: 2.202606678009033
Validation loss: 1.9413347989320755

Epoch: 5| Step: 6
Training loss: 2.3164877891540527
Validation loss: 1.970844437678655

Epoch: 5| Step: 7
Training loss: 1.715636968612671
Validation loss: 1.942167470852534

Epoch: 5| Step: 8
Training loss: 2.474031686782837
Validation loss: 1.9527808477481206

Epoch: 5| Step: 9
Training loss: 1.828721046447754
Validation loss: 1.9603271484375

Epoch: 5| Step: 10
Training loss: 1.859458565711975
Validation loss: 1.9688868125279744

Epoch: 5| Step: 11
Training loss: 1.0395817756652832
Validation loss: 1.9692624260981877

Epoch: 46| Step: 0
Training loss: 2.0623021125793457
Validation loss: 1.9794689218203227

Epoch: 5| Step: 1
Training loss: 1.6265510320663452
Validation loss: 1.9781579424937565

Epoch: 5| Step: 2
Training loss: 1.4143282175064087
Validation loss: 1.9691247989734013

Epoch: 5| Step: 3
Training loss: 2.131626605987549
Validation loss: 1.9507970561583836

Epoch: 5| Step: 4
Training loss: 2.0525715351104736
Validation loss: 1.976434846719106

Epoch: 5| Step: 5
Training loss: 1.6957817077636719
Validation loss: 1.9603806088368099

Epoch: 5| Step: 6
Training loss: 1.5415797233581543
Validation loss: 1.9715535293022792

Epoch: 5| Step: 7
Training loss: 1.7036125659942627
Validation loss: 1.949284424384435

Epoch: 5| Step: 8
Training loss: 1.550516963005066
Validation loss: 1.9459374745686848

Epoch: 5| Step: 9
Training loss: 2.2639646530151367
Validation loss: 1.9479975154002507

Epoch: 5| Step: 10
Training loss: 2.662205457687378
Validation loss: 1.9536783049503963

Epoch: 5| Step: 11
Training loss: 1.7130885124206543
Validation loss: 1.9604249149560928

Epoch: 47| Step: 0
Training loss: 2.4048657417297363
Validation loss: 1.9743300278981526

Epoch: 5| Step: 1
Training loss: 1.3610039949417114
Validation loss: 1.9634605050086975

Epoch: 5| Step: 2
Training loss: 1.772223711013794
Validation loss: 1.9512721796830494

Epoch: 5| Step: 3
Training loss: 1.8548434972763062
Validation loss: 1.940198188026746

Epoch: 5| Step: 4
Training loss: 1.4919379949569702
Validation loss: 1.9581234057744343

Epoch: 5| Step: 5
Training loss: 2.3184027671813965
Validation loss: 1.9492138028144836

Epoch: 5| Step: 6
Training loss: 1.9079411029815674
Validation loss: 1.9505420078833897

Epoch: 5| Step: 7
Training loss: 1.537549614906311
Validation loss: 1.9615569909413655

Epoch: 5| Step: 8
Training loss: 2.4057815074920654
Validation loss: 1.9364480276902516

Epoch: 5| Step: 9
Training loss: 2.5841541290283203
Validation loss: 1.967760518193245

Epoch: 5| Step: 10
Training loss: 1.3608201742172241
Validation loss: 1.9499391665061314

Epoch: 5| Step: 11
Training loss: 0.9934768676757812
Validation loss: 1.9349407802025478

Epoch: 48| Step: 0
Training loss: 1.8984479904174805
Validation loss: 1.9581251641114552

Epoch: 5| Step: 1
Training loss: 2.0409860610961914
Validation loss: 1.970015287399292

Epoch: 5| Step: 2
Training loss: 1.6511375904083252
Validation loss: 1.968788594007492

Epoch: 5| Step: 3
Training loss: 2.3156561851501465
Validation loss: 1.9747545371452968

Epoch: 5| Step: 4
Training loss: 2.2160801887512207
Validation loss: 1.974512110153834

Epoch: 5| Step: 5
Training loss: 1.6053270101547241
Validation loss: 1.9712108721335728

Epoch: 5| Step: 6
Training loss: 2.3211159706115723
Validation loss: 1.9640815258026123

Epoch: 5| Step: 7
Training loss: 2.0012998580932617
Validation loss: 2.005348891019821

Epoch: 5| Step: 8
Training loss: 1.453641653060913
Validation loss: 1.9821326931317647

Epoch: 5| Step: 9
Training loss: 1.775620460510254
Validation loss: 1.97476264834404

Epoch: 5| Step: 10
Training loss: 1.5674128532409668
Validation loss: 1.971359168489774

Epoch: 5| Step: 11
Training loss: 1.276322603225708
Validation loss: 1.9670626322428386

Epoch: 49| Step: 0
Training loss: 1.6983457803726196
Validation loss: 1.9676721890767415

Epoch: 5| Step: 1
Training loss: 1.8727195262908936
Validation loss: 1.9548955510059993

Epoch: 5| Step: 2
Training loss: 1.6974518299102783
Validation loss: 1.9460694392522175

Epoch: 5| Step: 3
Training loss: 1.5879526138305664
Validation loss: 1.9537523239850998

Epoch: 5| Step: 4
Training loss: 2.019937753677368
Validation loss: 1.954017514983813

Epoch: 5| Step: 5
Training loss: 2.0523571968078613
Validation loss: 1.9752384473880131

Epoch: 5| Step: 6
Training loss: 1.6469459533691406
Validation loss: 1.9474744300047557

Epoch: 5| Step: 7
Training loss: 1.9467365741729736
Validation loss: 1.9714731027682622

Epoch: 5| Step: 8
Training loss: 2.3483126163482666
Validation loss: 1.964108904202779

Epoch: 5| Step: 9
Training loss: 2.14148211479187
Validation loss: 1.9702941725651424

Epoch: 5| Step: 10
Training loss: 1.7321970462799072
Validation loss: 1.9550490925709407

Epoch: 5| Step: 11
Training loss: 1.7536886930465698
Validation loss: 1.9538754274447758

Epoch: 50| Step: 0
Training loss: 2.0377907752990723
Validation loss: 1.9434159596761067

Epoch: 5| Step: 1
Training loss: 1.641772985458374
Validation loss: 1.9669779886802037

Epoch: 5| Step: 2
Training loss: 1.8464998006820679
Validation loss: 1.9494061867396038

Epoch: 5| Step: 3
Training loss: 2.1640372276306152
Validation loss: 1.9412301033735275

Epoch: 5| Step: 4
Training loss: 1.3185657262802124
Validation loss: 1.9625448832909267

Epoch: 5| Step: 5
Training loss: 1.279375672340393
Validation loss: 1.9800768345594406

Epoch: 5| Step: 6
Training loss: 2.050931215286255
Validation loss: 1.9702060371637344

Epoch: 5| Step: 7
Training loss: 1.8518593311309814
Validation loss: 1.9760896414518356

Epoch: 5| Step: 8
Training loss: 2.865394115447998
Validation loss: 1.9618862171967824

Epoch: 5| Step: 9
Training loss: 1.974424123764038
Validation loss: 1.9785188436508179

Epoch: 5| Step: 10
Training loss: 1.8957068920135498
Validation loss: 1.9763317902882893

Epoch: 5| Step: 11
Training loss: 0.7790193557739258
Validation loss: 1.961629758278529

Epoch: 51| Step: 0
Training loss: 1.867761254310608
Validation loss: 1.9593183348576229

Epoch: 5| Step: 1
Training loss: 2.1046206951141357
Validation loss: 1.9564122011264165

Epoch: 5| Step: 2
Training loss: 2.1071391105651855
Validation loss: 1.9809395770231883

Epoch: 5| Step: 3
Training loss: 1.9537487030029297
Validation loss: 1.9655179381370544

Epoch: 5| Step: 4
Training loss: 1.9326107501983643
Validation loss: 1.9556035896142323

Epoch: 5| Step: 5
Training loss: 1.249282717704773
Validation loss: 1.9551763584216435

Epoch: 5| Step: 6
Training loss: 2.0813887119293213
Validation loss: 1.961869592467944

Epoch: 5| Step: 7
Training loss: 1.4292994737625122
Validation loss: 1.9573862204949062

Epoch: 5| Step: 8
Training loss: 1.7415739297866821
Validation loss: 1.9584353019793828

Epoch: 5| Step: 9
Training loss: 2.5134458541870117
Validation loss: 1.947897384564082

Epoch: 5| Step: 10
Training loss: 1.5877193212509155
Validation loss: 1.9343904207150142

Epoch: 5| Step: 11
Training loss: 2.068350076675415
Validation loss: 1.9509912778933842

Epoch: 52| Step: 0
Training loss: 1.4949853420257568
Validation loss: 1.950719878077507

Epoch: 5| Step: 1
Training loss: 1.3536479473114014
Validation loss: 1.983295202255249

Epoch: 5| Step: 2
Training loss: 2.0121920108795166
Validation loss: 2.0016267051299415

Epoch: 5| Step: 3
Training loss: 1.8026033639907837
Validation loss: 2.0278818060954413

Epoch: 5| Step: 4
Training loss: 2.428117036819458
Validation loss: 2.0154929210742316

Epoch: 5| Step: 5
Training loss: 1.9350694417953491
Validation loss: 2.030957649151484

Epoch: 5| Step: 6
Training loss: 1.9707202911376953
Validation loss: 2.0092019140720367

Epoch: 5| Step: 7
Training loss: 1.9957987070083618
Validation loss: 1.9948922445376713

Epoch: 5| Step: 8
Training loss: 1.7781816720962524
Validation loss: 2.009844700495402

Epoch: 5| Step: 9
Training loss: 2.2435548305511475
Validation loss: 1.990269735455513

Epoch: 5| Step: 10
Training loss: 1.8868194818496704
Validation loss: 1.9348552425702412

Epoch: 5| Step: 11
Training loss: 1.1125602722167969
Validation loss: 1.97701033949852

Epoch: 53| Step: 0
Training loss: 1.8937852382659912
Validation loss: 1.9469757427771885

Epoch: 5| Step: 1
Training loss: 1.8117488622665405
Validation loss: 1.957514504591624

Epoch: 5| Step: 2
Training loss: 1.6329463720321655
Validation loss: 1.9387612988551457

Epoch: 5| Step: 3
Training loss: 1.8079006671905518
Validation loss: 1.970092053214709

Epoch: 5| Step: 4
Training loss: 1.590898871421814
Validation loss: 1.9507563958565395

Epoch: 5| Step: 5
Training loss: 1.492652177810669
Validation loss: 1.9547168960173924

Epoch: 5| Step: 6
Training loss: 2.4375643730163574
Validation loss: 1.954145297408104

Epoch: 5| Step: 7
Training loss: 1.6100800037384033
Validation loss: 1.9483022441466649

Epoch: 5| Step: 8
Training loss: 2.3883185386657715
Validation loss: 1.953938161333402

Epoch: 5| Step: 9
Training loss: 2.076032876968384
Validation loss: 1.9519502818584442

Epoch: 5| Step: 10
Training loss: 1.950871229171753
Validation loss: 1.976599782705307

Epoch: 5| Step: 11
Training loss: 1.1653231382369995
Validation loss: 1.9641297956307728

Epoch: 54| Step: 0
Training loss: 1.570253610610962
Validation loss: 1.971878985563914

Epoch: 5| Step: 1
Training loss: 1.545438528060913
Validation loss: 1.9760491450627644

Epoch: 5| Step: 2
Training loss: 2.2131524085998535
Validation loss: 1.9860050926605861

Epoch: 5| Step: 3
Training loss: 1.9686921834945679
Validation loss: 1.972699721654256

Epoch: 5| Step: 4
Training loss: 2.3269848823547363
Validation loss: 1.9494470059871674

Epoch: 5| Step: 5
Training loss: 2.1569790840148926
Validation loss: 1.9319553921620052

Epoch: 5| Step: 6
Training loss: 2.0233333110809326
Validation loss: 1.9467250059048335

Epoch: 5| Step: 7
Training loss: 1.7490971088409424
Validation loss: 1.9455493489901226

Epoch: 5| Step: 8
Training loss: 1.754776954650879
Validation loss: 1.9658707678318024

Epoch: 5| Step: 9
Training loss: 1.4862031936645508
Validation loss: 1.9421787510315578

Epoch: 5| Step: 10
Training loss: 2.043154239654541
Validation loss: 1.9555362810691197

Epoch: 5| Step: 11
Training loss: 2.0057930946350098
Validation loss: 1.9486753443876903

Epoch: 55| Step: 0
Training loss: 1.6355241537094116
Validation loss: 1.953191841642062

Epoch: 5| Step: 1
Training loss: 1.3152453899383545
Validation loss: 1.9563101331392925

Epoch: 5| Step: 2
Training loss: 1.6454250812530518
Validation loss: 1.9792312284310658

Epoch: 5| Step: 3
Training loss: 2.9424915313720703
Validation loss: 1.9632135182619095

Epoch: 5| Step: 4
Training loss: 1.7932817935943604
Validation loss: 1.9756164352099101

Epoch: 5| Step: 5
Training loss: 1.836655616760254
Validation loss: 1.9748817433913548

Epoch: 5| Step: 6
Training loss: 1.593444585800171
Validation loss: 1.9606260657310486

Epoch: 5| Step: 7
Training loss: 1.5957374572753906
Validation loss: 1.9729876816272736

Epoch: 5| Step: 8
Training loss: 1.7696449756622314
Validation loss: 1.9521142840385437

Epoch: 5| Step: 9
Training loss: 2.12190580368042
Validation loss: 1.9527618288993835

Epoch: 5| Step: 10
Training loss: 2.0831212997436523
Validation loss: 1.9609084675709407

Epoch: 5| Step: 11
Training loss: 1.9404027462005615
Validation loss: 1.9481286406517029

Epoch: 56| Step: 0
Training loss: 2.2961463928222656
Validation loss: 1.9644104888041813

Epoch: 5| Step: 1
Training loss: 1.6698973178863525
Validation loss: 1.9721582333246868

Epoch: 5| Step: 2
Training loss: 1.898474931716919
Validation loss: 1.9981427987416585

Epoch: 5| Step: 3
Training loss: 1.8735520839691162
Validation loss: 1.9802441596984863

Epoch: 5| Step: 4
Training loss: 2.022919178009033
Validation loss: 1.9838270197312038

Epoch: 5| Step: 5
Training loss: 1.548864722251892
Validation loss: 2.001885344584783

Epoch: 5| Step: 6
Training loss: 1.9367964267730713
Validation loss: 1.986249382297198

Epoch: 5| Step: 7
Training loss: 2.2433247566223145
Validation loss: 1.9683373073736827

Epoch: 5| Step: 8
Training loss: 1.732604742050171
Validation loss: 1.9561141580343246

Epoch: 5| Step: 9
Training loss: 1.2041574716567993
Validation loss: 1.9377097090085347

Epoch: 5| Step: 10
Training loss: 1.9780628681182861
Validation loss: 1.9323512961467106

Epoch: 5| Step: 11
Training loss: 1.8358733654022217
Validation loss: 1.9637318601210911

Epoch: 57| Step: 0
Training loss: 1.784332275390625
Validation loss: 1.954651951789856

Epoch: 5| Step: 1
Training loss: 2.2458088397979736
Validation loss: 1.950834835569064

Epoch: 5| Step: 2
Training loss: 1.4133942127227783
Validation loss: 1.9542087266842525

Epoch: 5| Step: 3
Training loss: 2.1576924324035645
Validation loss: 1.9486212581396103

Epoch: 5| Step: 4
Training loss: 1.2796200513839722
Validation loss: 1.9280026356379192

Epoch: 5| Step: 5
Training loss: 1.4949675798416138
Validation loss: 1.959721177816391

Epoch: 5| Step: 6
Training loss: 2.0454373359680176
Validation loss: 1.9693504522244136

Epoch: 5| Step: 7
Training loss: 2.142009735107422
Validation loss: 1.9640192687511444

Epoch: 5| Step: 8
Training loss: 1.9179222583770752
Validation loss: 1.9538151522477467

Epoch: 5| Step: 9
Training loss: 1.6132612228393555
Validation loss: 1.9649728337923686

Epoch: 5| Step: 10
Training loss: 1.8675248622894287
Validation loss: 1.9794278393189113

Epoch: 5| Step: 11
Training loss: 2.1493420600891113
Validation loss: 1.9833480616410573

Epoch: 58| Step: 0
Training loss: 2.0423781871795654
Validation loss: 1.9694301684697468

Epoch: 5| Step: 1
Training loss: 1.7918808460235596
Validation loss: 1.936150590578715

Epoch: 5| Step: 2
Training loss: 1.9030288457870483
Validation loss: 1.9663217167059581

Epoch: 5| Step: 3
Training loss: 2.159231185913086
Validation loss: 1.9617405782143276

Epoch: 5| Step: 4
Training loss: 1.6277517080307007
Validation loss: 1.9492416381835938

Epoch: 5| Step: 5
Training loss: 1.420201063156128
Validation loss: 1.955983191728592

Epoch: 5| Step: 6
Training loss: 1.8578243255615234
Validation loss: 1.9552578181028366

Epoch: 5| Step: 7
Training loss: 1.8530833721160889
Validation loss: 1.9667872488498688

Epoch: 5| Step: 8
Training loss: 1.8240001201629639
Validation loss: 1.953315297762553

Epoch: 5| Step: 9
Training loss: 2.11255145072937
Validation loss: 1.9447611023982365

Epoch: 5| Step: 10
Training loss: 1.936663269996643
Validation loss: 1.9526515503724415

Epoch: 5| Step: 11
Training loss: 0.9413232803344727
Validation loss: 1.9471284945805867

Epoch: 59| Step: 0
Training loss: 2.288313865661621
Validation loss: 1.9466770191987355

Epoch: 5| Step: 1
Training loss: 2.0458931922912598
Validation loss: 1.9630774557590485

Epoch: 5| Step: 2
Training loss: 2.1136138439178467
Validation loss: 1.9769952843586605

Epoch: 5| Step: 3
Training loss: 2.6821064949035645
Validation loss: 1.9607181896766026

Epoch: 5| Step: 4
Training loss: 1.3242073059082031
Validation loss: 1.9658278872569401

Epoch: 5| Step: 5
Training loss: 1.6776431798934937
Validation loss: 1.9688115616639454

Epoch: 5| Step: 6
Training loss: 1.4891818761825562
Validation loss: 1.9670963784058888

Epoch: 5| Step: 7
Training loss: 1.549281358718872
Validation loss: 1.9995551357666652

Epoch: 5| Step: 8
Training loss: 1.791714072227478
Validation loss: 1.9886562178532283

Epoch: 5| Step: 9
Training loss: 1.046039342880249
Validation loss: 1.9817348221937816

Epoch: 5| Step: 10
Training loss: 1.6100504398345947
Validation loss: 1.9795010934273403

Epoch: 5| Step: 11
Training loss: 3.9143033027648926
Validation loss: 1.9824561377366383

Epoch: 60| Step: 0
Training loss: 1.911617636680603
Validation loss: 1.9848405967156093

Epoch: 5| Step: 1
Training loss: 1.9391069412231445
Validation loss: 1.974495271841685

Epoch: 5| Step: 2
Training loss: 1.8049952983856201
Validation loss: 1.964975818991661

Epoch: 5| Step: 3
Training loss: 1.7612335681915283
Validation loss: 1.971832608183225

Epoch: 5| Step: 4
Training loss: 2.0780017375946045
Validation loss: 1.972713773449262

Epoch: 5| Step: 5
Training loss: 1.7513082027435303
Validation loss: 1.9632183114687602

Epoch: 5| Step: 6
Training loss: 1.4598782062530518
Validation loss: 1.940065324306488

Epoch: 5| Step: 7
Training loss: 2.1828505992889404
Validation loss: 1.9537387092908223

Epoch: 5| Step: 8
Training loss: 1.4711487293243408
Validation loss: 1.9645414749781291

Epoch: 5| Step: 9
Training loss: 2.201765775680542
Validation loss: 1.962540363272031

Epoch: 5| Step: 10
Training loss: 1.1506747007369995
Validation loss: 1.9484525819619496

Epoch: 5| Step: 11
Training loss: 3.241987705230713
Validation loss: 1.9659948100646336

Epoch: 61| Step: 0
Training loss: 2.071662425994873
Validation loss: 1.9743778308232625

Epoch: 5| Step: 1
Training loss: 2.4291510581970215
Validation loss: 1.9710003733634949

Epoch: 5| Step: 2
Training loss: 1.4782483577728271
Validation loss: 1.9738123069206874

Epoch: 5| Step: 3
Training loss: 1.6767120361328125
Validation loss: 1.963685115178426

Epoch: 5| Step: 4
Training loss: 2.2747931480407715
Validation loss: 1.9863075415293376

Epoch: 5| Step: 5
Training loss: 1.6927692890167236
Validation loss: 1.9671785285075505

Epoch: 5| Step: 6
Training loss: 2.075460433959961
Validation loss: 1.9917963991562526

Epoch: 5| Step: 7
Training loss: 2.119121551513672
Validation loss: 1.9643507649501164

Epoch: 5| Step: 8
Training loss: 1.4803407192230225
Validation loss: 1.9633571406205494

Epoch: 5| Step: 9
Training loss: 1.550715684890747
Validation loss: 1.9722036669651668

Epoch: 5| Step: 10
Training loss: 1.2824269533157349
Validation loss: 1.9661705245574315

Epoch: 5| Step: 11
Training loss: 1.195456862449646
Validation loss: 1.9522573004166286

Epoch: 62| Step: 0
Training loss: 1.9090797901153564
Validation loss: 1.9677027016878128

Epoch: 5| Step: 1
Training loss: 1.8698034286499023
Validation loss: 1.9571014046669006

Epoch: 5| Step: 2
Training loss: 2.097438097000122
Validation loss: 1.9937290598948796

Epoch: 5| Step: 3
Training loss: 1.62644362449646
Validation loss: 1.991992602745692

Epoch: 5| Step: 4
Training loss: 1.3123795986175537
Validation loss: 1.9811506817738216

Epoch: 5| Step: 5
Training loss: 1.6538257598876953
Validation loss: 2.012056698401769

Epoch: 5| Step: 6
Training loss: 2.0049331188201904
Validation loss: 1.9946967860062916

Epoch: 5| Step: 7
Training loss: 2.0405819416046143
Validation loss: 1.972914735476176

Epoch: 5| Step: 8
Training loss: 1.8301500082015991
Validation loss: 1.9704938282569249

Epoch: 5| Step: 9
Training loss: 2.235494613647461
Validation loss: 1.9731507748365402

Epoch: 5| Step: 10
Training loss: 1.4286905527114868
Validation loss: 1.9464781830708187

Epoch: 5| Step: 11
Training loss: 1.1098836660385132
Validation loss: 1.9375693500041962

Epoch: 63| Step: 0
Training loss: 2.5927186012268066
Validation loss: 1.9594085117181141

Epoch: 5| Step: 1
Training loss: 1.5193387269973755
Validation loss: 1.9698200225830078

Epoch: 5| Step: 2
Training loss: 1.4720618724822998
Validation loss: 1.9553149739901226

Epoch: 5| Step: 3
Training loss: 2.0364036560058594
Validation loss: 1.94398166735967

Epoch: 5| Step: 4
Training loss: 2.8380954265594482
Validation loss: 1.9334057321151097

Epoch: 5| Step: 5
Training loss: 1.4280580282211304
Validation loss: 1.9445145676533382

Epoch: 5| Step: 6
Training loss: 1.5938494205474854
Validation loss: 1.948992446064949

Epoch: 5| Step: 7
Training loss: 1.3582533597946167
Validation loss: 1.9356923550367355

Epoch: 5| Step: 8
Training loss: 2.01771879196167
Validation loss: 1.9545312722524006

Epoch: 5| Step: 9
Training loss: 1.6027984619140625
Validation loss: 1.926777069767316

Epoch: 5| Step: 10
Training loss: 1.1873177289962769
Validation loss: 1.9575669368108113

Epoch: 5| Step: 11
Training loss: 2.4713797569274902
Validation loss: 1.9710073322057724

Epoch: 64| Step: 0
Training loss: 2.2949280738830566
Validation loss: 2.003029386202494

Epoch: 5| Step: 1
Training loss: 2.0350146293640137
Validation loss: 1.9659999012947083

Epoch: 5| Step: 2
Training loss: 1.6528791189193726
Validation loss: 1.976664995153745

Epoch: 5| Step: 3
Training loss: 1.5787110328674316
Validation loss: 1.9707383463780086

Epoch: 5| Step: 4
Training loss: 1.1386330127716064
Validation loss: 1.9728968143463135

Epoch: 5| Step: 5
Training loss: 1.5815956592559814
Validation loss: 1.9793656418720882

Epoch: 5| Step: 6
Training loss: 1.969325304031372
Validation loss: 1.9931682000557582

Epoch: 5| Step: 7
Training loss: 1.8452059030532837
Validation loss: 1.9827821006377537

Epoch: 5| Step: 8
Training loss: 2.0989036560058594
Validation loss: 1.9776403109232585

Epoch: 5| Step: 9
Training loss: 2.32612681388855
Validation loss: 1.95870137711366

Epoch: 5| Step: 10
Training loss: 1.433855414390564
Validation loss: 1.9513070036967595

Epoch: 5| Step: 11
Training loss: 1.513858675956726
Validation loss: 1.9558266748984654

Epoch: 65| Step: 0
Training loss: 1.7881991863250732
Validation loss: 1.9682779063781102

Epoch: 5| Step: 1
Training loss: 1.7783889770507812
Validation loss: 1.9808618028958638

Epoch: 5| Step: 2
Training loss: 2.315333843231201
Validation loss: 1.9631229887406032

Epoch: 5| Step: 3
Training loss: 1.8381000757217407
Validation loss: 1.9577662746111553

Epoch: 5| Step: 4
Training loss: 1.7442737817764282
Validation loss: 1.9456321150064468

Epoch: 5| Step: 5
Training loss: 1.9538681507110596
Validation loss: 1.946969633301099

Epoch: 5| Step: 6
Training loss: 1.6692489385604858
Validation loss: 1.9512016028165817

Epoch: 5| Step: 7
Training loss: 2.1758384704589844
Validation loss: 1.959472268819809

Epoch: 5| Step: 8
Training loss: 1.8070850372314453
Validation loss: 1.9651616464058559

Epoch: 5| Step: 9
Training loss: 1.1513959169387817
Validation loss: 1.9574962705373764

Epoch: 5| Step: 10
Training loss: 1.5268316268920898
Validation loss: 1.9462667802969615

Epoch: 5| Step: 11
Training loss: 2.0328280925750732
Validation loss: 1.961526816089948

Epoch: 66| Step: 0
Training loss: 2.182346820831299
Validation loss: 2.000965048869451

Epoch: 5| Step: 1
Training loss: 1.7148330211639404
Validation loss: 1.9807467957337697

Epoch: 5| Step: 2
Training loss: 1.7039639949798584
Validation loss: 1.977991297841072

Epoch: 5| Step: 3
Training loss: 1.8651771545410156
Validation loss: 1.9508825540542603

Epoch: 5| Step: 4
Training loss: 1.4681068658828735
Validation loss: 1.9434132625659306

Epoch: 5| Step: 5
Training loss: 1.8107742071151733
Validation loss: 1.9346949607133865

Epoch: 5| Step: 6
Training loss: 1.5220330953598022
Validation loss: 1.9388557026783626

Epoch: 5| Step: 7
Training loss: 2.2382962703704834
Validation loss: 1.952235276500384

Epoch: 5| Step: 8
Training loss: 1.7138862609863281
Validation loss: 1.9626173774401348

Epoch: 5| Step: 9
Training loss: 1.5122860670089722
Validation loss: 1.9737884849309921

Epoch: 5| Step: 10
Training loss: 2.093032121658325
Validation loss: 1.9554131130377452

Epoch: 5| Step: 11
Training loss: 1.724898338317871
Validation loss: 1.9658894042174022

Epoch: 67| Step: 0
Training loss: 2.099727153778076
Validation loss: 1.9849196126063664

Epoch: 5| Step: 1
Training loss: 2.0000996589660645
Validation loss: 1.9742804567019145

Epoch: 5| Step: 2
Training loss: 1.8388700485229492
Validation loss: 1.9775335838397343

Epoch: 5| Step: 3
Training loss: 1.5383983850479126
Validation loss: 2.0126321017742157

Epoch: 5| Step: 4
Training loss: 1.298474669456482
Validation loss: 2.0228026111920676

Epoch: 5| Step: 5
Training loss: 1.8438775539398193
Validation loss: 2.0109643191099167

Epoch: 5| Step: 6
Training loss: 1.869581937789917
Validation loss: 2.0129780769348145

Epoch: 5| Step: 7
Training loss: 2.0458312034606934
Validation loss: 2.0115843762954078

Epoch: 5| Step: 8
Training loss: 1.5289013385772705
Validation loss: 2.0439665814240775

Epoch: 5| Step: 9
Training loss: 1.9925512075424194
Validation loss: 1.9728464682896931

Epoch: 5| Step: 10
Training loss: 1.978695273399353
Validation loss: 1.9733652373154957

Epoch: 5| Step: 11
Training loss: 0.91659015417099
Validation loss: 1.9603400280078251

Epoch: 68| Step: 0
Training loss: 1.6351773738861084
Validation loss: 1.9434110174576442

Epoch: 5| Step: 1
Training loss: 1.9677753448486328
Validation loss: 1.959698552886645

Epoch: 5| Step: 2
Training loss: 2.723371982574463
Validation loss: 1.9651087870200474

Epoch: 5| Step: 3
Training loss: 1.4191783666610718
Validation loss: 1.9498696823914845

Epoch: 5| Step: 4
Training loss: 1.7705237865447998
Validation loss: 1.970382625857989

Epoch: 5| Step: 5
Training loss: 1.6496191024780273
Validation loss: 1.9583248098691304

Epoch: 5| Step: 6
Training loss: 2.044323444366455
Validation loss: 1.9786190390586853

Epoch: 5| Step: 7
Training loss: 1.986907958984375
Validation loss: 1.9521075834830601

Epoch: 5| Step: 8
Training loss: 1.9557349681854248
Validation loss: 1.9506274660428364

Epoch: 5| Step: 9
Training loss: 1.2262797355651855
Validation loss: 1.9536835551261902

Epoch: 5| Step: 10
Training loss: 1.685752511024475
Validation loss: 1.9445753296216328

Epoch: 5| Step: 11
Training loss: 0.216863751411438
Validation loss: 1.96526604394118

Epoch: 69| Step: 0
Training loss: 1.6099793910980225
Validation loss: 1.9578850666681926

Epoch: 5| Step: 1
Training loss: 1.4898865222930908
Validation loss: 1.9697812845309575

Epoch: 5| Step: 2
Training loss: 1.37081778049469
Validation loss: 1.967424253622691

Epoch: 5| Step: 3
Training loss: 1.5126864910125732
Validation loss: 1.9839058369398117

Epoch: 5| Step: 4
Training loss: 1.886996865272522
Validation loss: 1.992189000050227

Epoch: 5| Step: 5
Training loss: 2.4333767890930176
Validation loss: 1.9867963294188182

Epoch: 5| Step: 6
Training loss: 2.3648910522460938
Validation loss: 1.9807979663213093

Epoch: 5| Step: 7
Training loss: 1.6127021312713623
Validation loss: 1.999850332736969

Epoch: 5| Step: 8
Training loss: 1.6920654773712158
Validation loss: 1.9774499932924907

Epoch: 5| Step: 9
Training loss: 2.0955119132995605
Validation loss: 1.987937331199646

Epoch: 5| Step: 10
Training loss: 1.3253943920135498
Validation loss: 1.9728810737530391

Epoch: 5| Step: 11
Training loss: 1.8226933479309082
Validation loss: 1.9764219572146733

Epoch: 70| Step: 0
Training loss: 1.973738670349121
Validation loss: 1.940156156818072

Epoch: 5| Step: 1
Training loss: 1.555332899093628
Validation loss: 1.957126756509145

Epoch: 5| Step: 2
Training loss: 2.3287041187286377
Validation loss: 1.9478462239106495

Epoch: 5| Step: 3
Training loss: 1.5086253881454468
Validation loss: 1.9776880244414012

Epoch: 5| Step: 4
Training loss: 2.192814350128174
Validation loss: 1.9921041031678517

Epoch: 5| Step: 5
Training loss: 1.8594814538955688
Validation loss: 1.9972447504599888

Epoch: 5| Step: 6
Training loss: 1.025720238685608
Validation loss: 1.972930942972501

Epoch: 5| Step: 7
Training loss: 1.6553494930267334
Validation loss: 1.9954961985349655

Epoch: 5| Step: 8
Training loss: 2.147296905517578
Validation loss: 1.9679352343082428

Epoch: 5| Step: 9
Training loss: 1.5557525157928467
Validation loss: 1.959461917479833

Epoch: 5| Step: 10
Training loss: 1.520552396774292
Validation loss: 1.9695565452178319

Epoch: 5| Step: 11
Training loss: 1.7905347347259521
Validation loss: 1.988027219971021

Epoch: 71| Step: 0
Training loss: 1.2542644739151
Validation loss: 1.967054843902588

Epoch: 5| Step: 1
Training loss: 1.3553383350372314
Validation loss: 1.9638155301411946

Epoch: 5| Step: 2
Training loss: 1.7171701192855835
Validation loss: 1.9758452077706654

Epoch: 5| Step: 3
Training loss: 2.2597360610961914
Validation loss: 1.9847560475269954

Epoch: 5| Step: 4
Training loss: 1.7591397762298584
Validation loss: 1.9831910332043965

Epoch: 5| Step: 5
Training loss: 1.6452970504760742
Validation loss: 1.9790142724911373

Epoch: 5| Step: 6
Training loss: 1.6791448593139648
Validation loss: 1.9807761559883754

Epoch: 5| Step: 7
Training loss: 1.772382378578186
Validation loss: 1.9850300351778667

Epoch: 5| Step: 8
Training loss: 1.9008371829986572
Validation loss: 1.9753982325394948

Epoch: 5| Step: 9
Training loss: 1.847813367843628
Validation loss: 1.990151196718216

Epoch: 5| Step: 10
Training loss: 1.8561747074127197
Validation loss: 1.975345363219579

Epoch: 5| Step: 11
Training loss: 1.8140774965286255
Validation loss: 1.9627789556980133

Epoch: 72| Step: 0
Training loss: 2.4956815242767334
Validation loss: 1.9566567987203598

Epoch: 5| Step: 1
Training loss: 1.6289749145507812
Validation loss: 1.961401288708051

Epoch: 5| Step: 2
Training loss: 1.442169427871704
Validation loss: 1.96510345240434

Epoch: 5| Step: 3
Training loss: 1.0588948726654053
Validation loss: 1.9634009550015132

Epoch: 5| Step: 4
Training loss: 1.7826683521270752
Validation loss: 1.9857222686211269

Epoch: 5| Step: 5
Training loss: 1.5278446674346924
Validation loss: 1.961405833562215

Epoch: 5| Step: 6
Training loss: 1.6768261194229126
Validation loss: 1.9651512453953426

Epoch: 5| Step: 7
Training loss: 2.079822063446045
Validation loss: 1.9757762551307678

Epoch: 5| Step: 8
Training loss: 1.545178771018982
Validation loss: 1.9543801546096802

Epoch: 5| Step: 9
Training loss: 1.8981812000274658
Validation loss: 1.9487222929795582

Epoch: 5| Step: 10
Training loss: 2.10200834274292
Validation loss: 1.9647152076164882

Epoch: 5| Step: 11
Training loss: 2.1314988136291504
Validation loss: 1.9413918405771255

Epoch: 73| Step: 0
Training loss: 2.548276901245117
Validation loss: 1.9658687661091487

Epoch: 5| Step: 1
Training loss: 1.6940282583236694
Validation loss: 1.975096841653188

Epoch: 5| Step: 2
Training loss: 1.9021368026733398
Validation loss: 1.9519859304030736

Epoch: 5| Step: 3
Training loss: 1.3894522190093994
Validation loss: 2.0010138799746833

Epoch: 5| Step: 4
Training loss: 1.520490288734436
Validation loss: 1.9812303831179936

Epoch: 5| Step: 5
Training loss: 1.9869426488876343
Validation loss: 1.962094282110532

Epoch: 5| Step: 6
Training loss: 1.974724531173706
Validation loss: 1.9702580819527309

Epoch: 5| Step: 7
Training loss: 1.8939621448516846
Validation loss: 1.9802646040916443

Epoch: 5| Step: 8
Training loss: 0.9390827417373657
Validation loss: 1.9763587514559429

Epoch: 5| Step: 9
Training loss: 1.917459487915039
Validation loss: 1.9775738765796025

Epoch: 5| Step: 10
Training loss: 1.4154938459396362
Validation loss: 1.9754924525817235

Epoch: 5| Step: 11
Training loss: 0.3809523582458496
Validation loss: 1.9757461547851562

Epoch: 74| Step: 0
Training loss: 1.2258126735687256
Validation loss: 1.9735295524199803

Epoch: 5| Step: 1
Training loss: 1.3081086874008179
Validation loss: 1.9635347773631413

Epoch: 5| Step: 2
Training loss: 2.1400487422943115
Validation loss: 1.9569909026225407

Epoch: 5| Step: 3
Training loss: 2.289543628692627
Validation loss: 1.998773232102394

Epoch: 5| Step: 4
Training loss: 1.471152901649475
Validation loss: 1.9717487494150798

Epoch: 5| Step: 5
Training loss: 1.9216582775115967
Validation loss: 1.9630878418684006

Epoch: 5| Step: 6
Training loss: 1.7264134883880615
Validation loss: 1.969548761844635

Epoch: 5| Step: 7
Training loss: 1.9730966091156006
Validation loss: 1.984676371018092

Epoch: 5| Step: 8
Training loss: 1.4788483381271362
Validation loss: 1.9851695746183395

Epoch: 5| Step: 9
Training loss: 1.5316847562789917
Validation loss: 1.981917639573415

Epoch: 5| Step: 10
Training loss: 2.033487319946289
Validation loss: 1.956138516465823

Epoch: 5| Step: 11
Training loss: 0.49145448207855225
Validation loss: 1.999391679962476

Epoch: 75| Step: 0
Training loss: 1.8157761096954346
Validation loss: 1.959616134564082

Epoch: 5| Step: 1
Training loss: 2.088135242462158
Validation loss: 1.9696616629759471

Epoch: 5| Step: 2
Training loss: 1.7870099544525146
Validation loss: 1.961555744210879

Epoch: 5| Step: 3
Training loss: 1.3661044836044312
Validation loss: 2.0315674295028052

Epoch: 5| Step: 4
Training loss: 2.0972468852996826
Validation loss: 2.0011188437541327

Epoch: 5| Step: 5
Training loss: 2.0315005779266357
Validation loss: 1.9881194531917572

Epoch: 5| Step: 6
Training loss: 1.580410361289978
Validation loss: 1.9679797738790512

Epoch: 5| Step: 7
Training loss: 1.1592868566513062
Validation loss: 1.958925485610962

Epoch: 5| Step: 8
Training loss: 1.7879838943481445
Validation loss: 1.9546623180309932

Epoch: 5| Step: 9
Training loss: 1.4408749341964722
Validation loss: 1.983917201558749

Epoch: 5| Step: 10
Training loss: 1.2881191968917847
Validation loss: 1.9760472824176152

Epoch: 5| Step: 11
Training loss: 3.7465920448303223
Validation loss: 1.952682803074519

Epoch: 76| Step: 0
Training loss: 1.8242063522338867
Validation loss: 1.9371523708105087

Epoch: 5| Step: 1
Training loss: 0.9262877702713013
Validation loss: 1.93813622991244

Epoch: 5| Step: 2
Training loss: 1.943334937095642
Validation loss: 1.9661330878734589

Epoch: 5| Step: 3
Training loss: 1.837836503982544
Validation loss: 1.9723897228638332

Epoch: 5| Step: 4
Training loss: 1.86785089969635
Validation loss: 1.9768943240245183

Epoch: 5| Step: 5
Training loss: 1.307254433631897
Validation loss: 1.9532244553168614

Epoch: 5| Step: 6
Training loss: 2.2481791973114014
Validation loss: 1.9549817889928818

Epoch: 5| Step: 7
Training loss: 1.7041822671890259
Validation loss: 1.961179032921791

Epoch: 5| Step: 8
Training loss: 1.9658763408660889
Validation loss: 1.9879539509614308

Epoch: 5| Step: 9
Training loss: 1.8006610870361328
Validation loss: 1.990470066666603

Epoch: 5| Step: 10
Training loss: 1.3386001586914062
Validation loss: 2.004560927549998

Epoch: 5| Step: 11
Training loss: 1.377175211906433
Validation loss: 1.9594613562027614

Epoch: 77| Step: 0
Training loss: 2.019303798675537
Validation loss: 1.9969194531440735

Epoch: 5| Step: 1
Training loss: 1.469813585281372
Validation loss: 1.9608538349469502

Epoch: 5| Step: 2
Training loss: 1.8247458934783936
Validation loss: 1.996143748362859

Epoch: 5| Step: 3
Training loss: 1.6381378173828125
Validation loss: 1.9719328631957371

Epoch: 5| Step: 4
Training loss: 1.8357166051864624
Validation loss: 1.9311937391757965

Epoch: 5| Step: 5
Training loss: 1.4461848735809326
Validation loss: 1.9826487551132839

Epoch: 5| Step: 6
Training loss: 1.8684864044189453
Validation loss: 1.9407558292150497

Epoch: 5| Step: 7
Training loss: 1.3490369319915771
Validation loss: 1.9652262777090073

Epoch: 5| Step: 8
Training loss: 1.7296898365020752
Validation loss: 1.9433553318182628

Epoch: 5| Step: 9
Training loss: 1.9191423654556274
Validation loss: 1.9466354896624882

Epoch: 5| Step: 10
Training loss: 1.7735633850097656
Validation loss: 1.9744455615679424

Epoch: 5| Step: 11
Training loss: 1.5075374841690063
Validation loss: 1.9623376180728276

Epoch: 78| Step: 0
Training loss: 1.6553294658660889
Validation loss: 1.9796647528807323

Epoch: 5| Step: 1
Training loss: 1.7359139919281006
Validation loss: 2.0054934869209924

Epoch: 5| Step: 2
Training loss: 1.2071901559829712
Validation loss: 2.0084116756916046

Epoch: 5| Step: 3
Training loss: 1.7885328531265259
Validation loss: 2.0046168714761734

Epoch: 5| Step: 4
Training loss: 1.8579394817352295
Validation loss: 2.0094706465800605

Epoch: 5| Step: 5
Training loss: 1.5989477634429932
Validation loss: 1.9939312587181728

Epoch: 5| Step: 6
Training loss: 1.5346585512161255
Validation loss: 2.0310368885596595

Epoch: 5| Step: 7
Training loss: 1.3566458225250244
Validation loss: 1.9689629177252452

Epoch: 5| Step: 8
Training loss: 1.8730236291885376
Validation loss: 1.96282297372818

Epoch: 5| Step: 9
Training loss: 2.0715012550354004
Validation loss: 1.9766432295242946

Epoch: 5| Step: 10
Training loss: 1.8265540599822998
Validation loss: 1.9709166934092839

Epoch: 5| Step: 11
Training loss: 1.878705620765686
Validation loss: 1.9770403504371643

Epoch: 79| Step: 0
Training loss: 1.5664920806884766
Validation loss: 1.9652429322401683

Epoch: 5| Step: 1
Training loss: 1.3786232471466064
Validation loss: 1.9572976777950923

Epoch: 5| Step: 2
Training loss: 1.5959774255752563
Validation loss: 1.9474083483219147

Epoch: 5| Step: 3
Training loss: 1.7801589965820312
Validation loss: 1.9408869942029316

Epoch: 5| Step: 4
Training loss: 1.3233433961868286
Validation loss: 1.9749083667993546

Epoch: 5| Step: 5
Training loss: 1.4485992193222046
Validation loss: 1.9868815690279007

Epoch: 5| Step: 6
Training loss: 2.135450839996338
Validation loss: 1.9618057856957118

Epoch: 5| Step: 7
Training loss: 1.877780556678772
Validation loss: 1.964669664700826

Epoch: 5| Step: 8
Training loss: 1.3615260124206543
Validation loss: 1.9674925655126572

Epoch: 5| Step: 9
Training loss: 2.3938019275665283
Validation loss: 1.9789731800556183

Epoch: 5| Step: 10
Training loss: 1.339179277420044
Validation loss: 1.9868686000506084

Epoch: 5| Step: 11
Training loss: 2.8120033740997314
Validation loss: 1.9749607592821121

Epoch: 80| Step: 0
Training loss: 1.9486230611801147
Validation loss: 1.9710907687743504

Epoch: 5| Step: 1
Training loss: 1.410768747329712
Validation loss: 1.9738396753867467

Epoch: 5| Step: 2
Training loss: 2.039180278778076
Validation loss: 1.971513753135999

Epoch: 5| Step: 3
Training loss: 1.5026402473449707
Validation loss: 2.008366967240969

Epoch: 5| Step: 4
Training loss: 1.4142265319824219
Validation loss: 1.99108324944973

Epoch: 5| Step: 5
Training loss: 1.3057562112808228
Validation loss: 1.975583200653394

Epoch: 5| Step: 6
Training loss: 1.9198929071426392
Validation loss: 1.9788438280423482

Epoch: 5| Step: 7
Training loss: 1.612253189086914
Validation loss: 1.9682371417681377

Epoch: 5| Step: 8
Training loss: 1.7241452932357788
Validation loss: 1.969109018643697

Epoch: 5| Step: 9
Training loss: 1.0686733722686768
Validation loss: 1.9906714707612991

Epoch: 5| Step: 10
Training loss: 1.870144248008728
Validation loss: 1.9762383947769802

Epoch: 5| Step: 11
Training loss: 2.976597309112549
Validation loss: 1.9713790069023769

Epoch: 81| Step: 0
Training loss: 1.68781316280365
Validation loss: 1.9565722992022831

Epoch: 5| Step: 1
Training loss: 1.4863038063049316
Validation loss: 1.9601105252901714

Epoch: 5| Step: 2
Training loss: 1.731313705444336
Validation loss: 1.9867943773667018

Epoch: 5| Step: 3
Training loss: 1.674094557762146
Validation loss: 1.9782811105251312

Epoch: 5| Step: 4
Training loss: 0.9567087292671204
Validation loss: 1.9932828843593597

Epoch: 5| Step: 5
Training loss: 1.69732666015625
Validation loss: 2.0196010867754617

Epoch: 5| Step: 6
Training loss: 1.3548513650894165
Validation loss: 2.008618086576462

Epoch: 5| Step: 7
Training loss: 1.5933712720870972
Validation loss: 2.0096024572849274

Epoch: 5| Step: 8
Training loss: 1.5706359148025513
Validation loss: 1.9772570033868153

Epoch: 5| Step: 9
Training loss: 1.9070873260498047
Validation loss: 1.9782715837160747

Epoch: 5| Step: 10
Training loss: 1.9826167821884155
Validation loss: 1.957930564880371

Epoch: 5| Step: 11
Training loss: 1.7366256713867188
Validation loss: 1.9631311545769374

Epoch: 82| Step: 0
Training loss: 1.963269829750061
Validation loss: 1.9499770055214565

Epoch: 5| Step: 1
Training loss: 1.5841569900512695
Validation loss: 1.97166674832503

Epoch: 5| Step: 2
Training loss: 1.554303526878357
Validation loss: 1.9445477724075317

Epoch: 5| Step: 3
Training loss: 2.1097354888916016
Validation loss: 1.9691982964674632

Epoch: 5| Step: 4
Training loss: 1.6819908618927002
Validation loss: 1.9320408900578816

Epoch: 5| Step: 5
Training loss: 1.2772290706634521
Validation loss: 1.9281362891197205

Epoch: 5| Step: 6
Training loss: 1.853872537612915
Validation loss: 1.9610335727532704

Epoch: 5| Step: 7
Training loss: 1.9389339685440063
Validation loss: 1.9769319494565327

Epoch: 5| Step: 8
Training loss: 1.2146217823028564
Validation loss: 1.9505256464083989

Epoch: 5| Step: 9
Training loss: 1.8609282970428467
Validation loss: 1.9686522136131923

Epoch: 5| Step: 10
Training loss: 1.8375396728515625
Validation loss: 2.006806487838427

Epoch: 5| Step: 11
Training loss: 0.3239988088607788
Validation loss: 2.0051670422156653

Epoch: 83| Step: 0
Training loss: 2.299562931060791
Validation loss: 2.0231730242570243

Epoch: 5| Step: 1
Training loss: 1.1499011516571045
Validation loss: 2.054496556520462

Epoch: 5| Step: 2
Training loss: 1.9892486333847046
Validation loss: 2.047766620914141

Epoch: 5| Step: 3
Training loss: 1.3860516548156738
Validation loss: 2.0382225016752877

Epoch: 5| Step: 4
Training loss: 1.5648117065429688
Validation loss: 2.0398582170406976

Epoch: 5| Step: 5
Training loss: 1.4624370336532593
Validation loss: 1.9723275353511174

Epoch: 5| Step: 6
Training loss: 1.3942381143569946
Validation loss: 1.9593135565519333

Epoch: 5| Step: 7
Training loss: 1.8471647500991821
Validation loss: 1.964123676220576

Epoch: 5| Step: 8
Training loss: 1.7342884540557861
Validation loss: 1.9579826295375824

Epoch: 5| Step: 9
Training loss: 1.962424874305725
Validation loss: 1.9482870747645695

Epoch: 5| Step: 10
Training loss: 1.8046289682388306
Validation loss: 1.9982931911945343

Epoch: 5| Step: 11
Training loss: 0.5734779834747314
Validation loss: 1.9594773103793461

Epoch: 84| Step: 0
Training loss: 1.6137094497680664
Validation loss: 1.9747153023878734

Epoch: 5| Step: 1
Training loss: 1.4745614528656006
Validation loss: 1.9801214635372162

Epoch: 5| Step: 2
Training loss: 1.9697694778442383
Validation loss: 1.964054599404335

Epoch: 5| Step: 3
Training loss: 1.8568779230117798
Validation loss: 1.9796223193407059

Epoch: 5| Step: 4
Training loss: 1.1080892086029053
Validation loss: 1.9396602312723796

Epoch: 5| Step: 5
Training loss: 1.7606585025787354
Validation loss: 1.989869053165118

Epoch: 5| Step: 6
Training loss: 1.6907440423965454
Validation loss: 1.9605413128932316

Epoch: 5| Step: 7
Training loss: 1.61106276512146
Validation loss: 1.9716113607088726

Epoch: 5| Step: 8
Training loss: 1.4160263538360596
Validation loss: 2.023113081852595

Epoch: 5| Step: 9
Training loss: 1.4855034351348877
Validation loss: 2.0160633424917855

Epoch: 5| Step: 10
Training loss: 1.4666404724121094
Validation loss: 2.0292088240385056

Epoch: 5| Step: 11
Training loss: 2.218454360961914
Validation loss: 1.985907033085823

Epoch: 85| Step: 0
Training loss: 1.825079321861267
Validation loss: 2.0033844262361526

Epoch: 5| Step: 1
Training loss: 1.3648502826690674
Validation loss: 1.987512653072675

Epoch: 5| Step: 2
Training loss: 1.1921350955963135
Validation loss: 1.9706108570098877

Epoch: 5| Step: 3
Training loss: 1.4908604621887207
Validation loss: 1.984009563922882

Epoch: 5| Step: 4
Training loss: 1.7642548084259033
Validation loss: 1.9832595040400822

Epoch: 5| Step: 5
Training loss: 1.8495242595672607
Validation loss: 1.9926403909921646

Epoch: 5| Step: 6
Training loss: 1.8421920537948608
Validation loss: 1.9698635588089626

Epoch: 5| Step: 7
Training loss: 1.9703969955444336
Validation loss: 1.972502052783966

Epoch: 5| Step: 8
Training loss: 1.731419324874878
Validation loss: 1.99146169424057

Epoch: 5| Step: 9
Training loss: 1.0970996618270874
Validation loss: 1.9481294651826222

Epoch: 5| Step: 10
Training loss: 1.33022141456604
Validation loss: 1.9640009552240372

Epoch: 5| Step: 11
Training loss: 1.305275321006775
Validation loss: 2.002215325832367

Epoch: 86| Step: 0
Training loss: 2.072518825531006
Validation loss: 2.0096537371476493

Epoch: 5| Step: 1
Training loss: 1.3944790363311768
Validation loss: 1.9703681816657383

Epoch: 5| Step: 2
Training loss: 1.130863904953003
Validation loss: 2.0064746340115867

Epoch: 5| Step: 3
Training loss: 1.752478837966919
Validation loss: 1.9682723184426625

Epoch: 5| Step: 4
Training loss: 1.4873435497283936
Validation loss: 1.9457441717386246

Epoch: 5| Step: 5
Training loss: 1.7020190954208374
Validation loss: 1.969633013010025

Epoch: 5| Step: 6
Training loss: 1.654975175857544
Validation loss: 1.9311944742997487

Epoch: 5| Step: 7
Training loss: 1.7366275787353516
Validation loss: 1.956949050227801

Epoch: 5| Step: 8
Training loss: 1.0003068447113037
Validation loss: 1.97148264447848

Epoch: 5| Step: 9
Training loss: 1.7274796962738037
Validation loss: 1.9806210746367772

Epoch: 5| Step: 10
Training loss: 2.002009153366089
Validation loss: 1.9980074067910512

Epoch: 5| Step: 11
Training loss: 0.6276570558547974
Validation loss: 1.9817312955856323

Epoch: 87| Step: 0
Training loss: 1.866228461265564
Validation loss: 1.9776466935873032

Epoch: 5| Step: 1
Training loss: 1.8468011617660522
Validation loss: 1.9945038557052612

Epoch: 5| Step: 2
Training loss: 1.0754036903381348
Validation loss: 2.007473260164261

Epoch: 5| Step: 3
Training loss: 1.9228168725967407
Validation loss: 2.0096724033355713

Epoch: 5| Step: 4
Training loss: 1.2835572957992554
Validation loss: 2.0002512484788895

Epoch: 5| Step: 5
Training loss: 1.5273253917694092
Validation loss: 1.9707468748092651

Epoch: 5| Step: 6
Training loss: 1.4721827507019043
Validation loss: 1.9709307948748271

Epoch: 5| Step: 7
Training loss: 1.8864049911499023
Validation loss: 1.9793560256560643

Epoch: 5| Step: 8
Training loss: 1.4226722717285156
Validation loss: 1.9669546633958817

Epoch: 5| Step: 9
Training loss: 0.9753007888793945
Validation loss: 1.9698502123355865

Epoch: 5| Step: 10
Training loss: 1.5207465887069702
Validation loss: 1.9562085022528966

Epoch: 5| Step: 11
Training loss: 2.9233458042144775
Validation loss: 1.9791024376948674

Epoch: 88| Step: 0
Training loss: 1.1949374675750732
Validation loss: 1.9748044709364574

Epoch: 5| Step: 1
Training loss: 1.8339817523956299
Validation loss: 1.939669817686081

Epoch: 5| Step: 2
Training loss: 1.5109901428222656
Validation loss: 1.9844380815823872

Epoch: 5| Step: 3
Training loss: 1.5453155040740967
Validation loss: 1.9783599028984706

Epoch: 5| Step: 4
Training loss: 1.6183431148529053
Validation loss: 1.940372258424759

Epoch: 5| Step: 5
Training loss: 1.3176435232162476
Validation loss: 1.9465377281109493

Epoch: 5| Step: 6
Training loss: 2.0002212524414062
Validation loss: 1.9752384722232819

Epoch: 5| Step: 7
Training loss: 1.6731479167938232
Validation loss: 1.9777273188034694

Epoch: 5| Step: 8
Training loss: 1.5300195217132568
Validation loss: 1.9694776087999344

Epoch: 5| Step: 9
Training loss: 1.2839457988739014
Validation loss: 2.0144255260626474

Epoch: 5| Step: 10
Training loss: 1.9356372356414795
Validation loss: 2.0251705894867578

Epoch: 5| Step: 11
Training loss: 1.1862419843673706
Validation loss: 2.0242384870847068

Epoch: 89| Step: 0
Training loss: 1.378881812095642
Validation loss: 2.0120059003432593

Epoch: 5| Step: 1
Training loss: 1.3592716455459595
Validation loss: 2.0481510957082114

Epoch: 5| Step: 2
Training loss: 1.7077438831329346
Validation loss: 2.052737240990003

Epoch: 5| Step: 3
Training loss: 1.5227723121643066
Validation loss: 2.018236815929413

Epoch: 5| Step: 4
Training loss: 1.5199744701385498
Validation loss: 1.9902817110220592

Epoch: 5| Step: 5
Training loss: 1.9594171047210693
Validation loss: 1.9787363906701405

Epoch: 5| Step: 6
Training loss: 1.0839064121246338
Validation loss: 1.9892032742500305

Epoch: 5| Step: 7
Training loss: 1.6949583292007446
Validation loss: 2.0030518223841987

Epoch: 5| Step: 8
Training loss: 1.6600338220596313
Validation loss: 1.9671934694051743

Epoch: 5| Step: 9
Training loss: 1.7409465312957764
Validation loss: 1.960789347688357

Epoch: 5| Step: 10
Training loss: 2.066850185394287
Validation loss: 1.9680333336194356

Epoch: 5| Step: 11
Training loss: 0.7984327077865601
Validation loss: 1.972422406077385

Epoch: 90| Step: 0
Training loss: 1.1757307052612305
Validation loss: 1.9768830686807632

Epoch: 5| Step: 1
Training loss: 1.5130784511566162
Validation loss: 1.9702909688154857

Epoch: 5| Step: 2
Training loss: 1.629858374595642
Validation loss: 1.9898208230733871

Epoch: 5| Step: 3
Training loss: 1.4981451034545898
Validation loss: 1.9587202270825703

Epoch: 5| Step: 4
Training loss: 1.5503228902816772
Validation loss: 1.9806063175201416

Epoch: 5| Step: 5
Training loss: 1.5371841192245483
Validation loss: 1.965500185887019

Epoch: 5| Step: 6
Training loss: 1.3574867248535156
Validation loss: 2.022158587972323

Epoch: 5| Step: 7
Training loss: 1.659299612045288
Validation loss: 2.064836328228315

Epoch: 5| Step: 8
Training loss: 1.8579156398773193
Validation loss: 2.0278956294059753

Epoch: 5| Step: 9
Training loss: 1.7152268886566162
Validation loss: 2.0317226896683374

Epoch: 5| Step: 10
Training loss: 1.4943125247955322
Validation loss: 1.9807262023289998

Epoch: 5| Step: 11
Training loss: 2.4363694190979004
Validation loss: 1.9908406337102253

Epoch: 91| Step: 0
Training loss: 1.651249885559082
Validation loss: 1.943511555592219

Epoch: 5| Step: 1
Training loss: 1.4076621532440186
Validation loss: 1.9598048677047093

Epoch: 5| Step: 2
Training loss: 1.7301890850067139
Validation loss: 1.9687991539637248

Epoch: 5| Step: 3
Training loss: 1.7056303024291992
Validation loss: 1.9568189332882564

Epoch: 5| Step: 4
Training loss: 1.3122361898422241
Validation loss: 1.973345473408699

Epoch: 5| Step: 5
Training loss: 1.8459346294403076
Validation loss: 1.9558998197317123

Epoch: 5| Step: 6
Training loss: 1.4825359582901
Validation loss: 1.9656432966391246

Epoch: 5| Step: 7
Training loss: 1.6734912395477295
Validation loss: 1.9954460561275482

Epoch: 5| Step: 8
Training loss: 1.6099001169204712
Validation loss: 1.9667988419532776

Epoch: 5| Step: 9
Training loss: 1.010441541671753
Validation loss: 2.0371802002191544

Epoch: 5| Step: 10
Training loss: 1.764134168624878
Validation loss: 2.013734598954519

Epoch: 5| Step: 11
Training loss: 2.5865602493286133
Validation loss: 2.0861656765143075

Epoch: 92| Step: 0
Training loss: 1.5275728702545166
Validation loss: 1.9942461947600048

Epoch: 5| Step: 1
Training loss: 1.7790390253067017
Validation loss: 1.9585219373305638

Epoch: 5| Step: 2
Training loss: 1.2129230499267578
Validation loss: 1.999599148829778

Epoch: 5| Step: 3
Training loss: 1.6463091373443604
Validation loss: 1.9750765611728032

Epoch: 5| Step: 4
Training loss: 1.3383493423461914
Validation loss: 1.9946413189172745

Epoch: 5| Step: 5
Training loss: 1.7380421161651611
Validation loss: 1.991919259230296

Epoch: 5| Step: 6
Training loss: 1.8589756488800049
Validation loss: 1.978496104478836

Epoch: 5| Step: 7
Training loss: 1.4443756341934204
Validation loss: 1.9732360045115154

Epoch: 5| Step: 8
Training loss: 1.1400223970413208
Validation loss: 1.9645562718311946

Epoch: 5| Step: 9
Training loss: 1.6550254821777344
Validation loss: 1.972637762626012

Epoch: 5| Step: 10
Training loss: 1.4918830394744873
Validation loss: 2.012678717573484

Epoch: 5| Step: 11
Training loss: 1.4531117677688599
Validation loss: 2.035928656657537

Epoch: 93| Step: 0
Training loss: 1.1497818231582642
Validation loss: 2.024056166410446

Epoch: 5| Step: 1
Training loss: 1.748842477798462
Validation loss: 2.064614882071813

Epoch: 5| Step: 2
Training loss: 0.964120090007782
Validation loss: 2.0727101862430573

Epoch: 5| Step: 3
Training loss: 1.1167199611663818
Validation loss: 2.0294186025857925

Epoch: 5| Step: 4
Training loss: 1.7507598400115967
Validation loss: 2.0194777051607766

Epoch: 5| Step: 5
Training loss: 1.8779815435409546
Validation loss: 2.0259623676538467

Epoch: 5| Step: 6
Training loss: 2.174112319946289
Validation loss: 2.0087540298700333

Epoch: 5| Step: 7
Training loss: 1.618370771408081
Validation loss: 1.9881362815697987

Epoch: 5| Step: 8
Training loss: 1.3541370630264282
Validation loss: 1.9779226680596669

Epoch: 5| Step: 9
Training loss: 1.1764805316925049
Validation loss: 1.9507830788691838

Epoch: 5| Step: 10
Training loss: 1.458247184753418
Validation loss: 1.954326182603836

Epoch: 5| Step: 11
Training loss: 1.0574982166290283
Validation loss: 1.984897221128146

Epoch: 94| Step: 0
Training loss: 1.6934239864349365
Validation loss: 1.9949298451344173

Epoch: 5| Step: 1
Training loss: 1.3484926223754883
Validation loss: 2.004142075777054

Epoch: 5| Step: 2
Training loss: 1.7126960754394531
Validation loss: 2.00827989478906

Epoch: 5| Step: 3
Training loss: 1.4163134098052979
Validation loss: 1.9996953457593918

Epoch: 5| Step: 4
Training loss: 1.1857964992523193
Validation loss: 2.0218320389588675

Epoch: 5| Step: 5
Training loss: 1.2095054388046265
Validation loss: 1.978852113087972

Epoch: 5| Step: 6
Training loss: 1.9131113290786743
Validation loss: 2.0528834660847983

Epoch: 5| Step: 7
Training loss: 1.6248600482940674
Validation loss: 2.03241503238678

Epoch: 5| Step: 8
Training loss: 0.9899337887763977
Validation loss: 1.9626173774401348

Epoch: 5| Step: 9
Training loss: 1.2355382442474365
Validation loss: 2.0153962820768356

Epoch: 5| Step: 10
Training loss: 2.0706958770751953
Validation loss: 1.9579385221004486

Epoch: 5| Step: 11
Training loss: 0.9787537455558777
Validation loss: 1.970531036456426

Epoch: 95| Step: 0
Training loss: 1.3597774505615234
Validation loss: 1.967112864057223

Epoch: 5| Step: 1
Training loss: 1.5810874700546265
Validation loss: 1.9663355400164921

Epoch: 5| Step: 2
Training loss: 2.05352783203125
Validation loss: 2.0054123799006143

Epoch: 5| Step: 3
Training loss: 1.2912036180496216
Validation loss: 1.9778107901414235

Epoch: 5| Step: 4
Training loss: 2.043097734451294
Validation loss: 2.012196193138758

Epoch: 5| Step: 5
Training loss: 2.0684826374053955
Validation loss: 1.9861265917619069

Epoch: 5| Step: 6
Training loss: 1.0749828815460205
Validation loss: 1.9786108533541362

Epoch: 5| Step: 7
Training loss: 1.2875422239303589
Validation loss: 1.9952867577473323

Epoch: 5| Step: 8
Training loss: 1.3256065845489502
Validation loss: 2.032272939880689

Epoch: 5| Step: 9
Training loss: 1.4164862632751465
Validation loss: 2.056659703453382

Epoch: 5| Step: 10
Training loss: 1.9328426122665405
Validation loss: 2.0498133997122445

Epoch: 5| Step: 11
Training loss: 0.8519569635391235
Validation loss: 2.063770910104116

Epoch: 96| Step: 0
Training loss: 1.3444876670837402
Validation loss: 2.0638156135876975

Epoch: 5| Step: 1
Training loss: 1.1187442541122437
Validation loss: 2.0509624580542245

Epoch: 5| Step: 2
Training loss: 1.6742267608642578
Validation loss: 2.0132550597190857

Epoch: 5| Step: 3
Training loss: 1.9902633428573608
Validation loss: 2.012260710199674

Epoch: 5| Step: 4
Training loss: 1.7886070013046265
Validation loss: 2.0105402072270713

Epoch: 5| Step: 5
Training loss: 1.195157766342163
Validation loss: 1.9757607132196426

Epoch: 5| Step: 6
Training loss: 1.4240407943725586
Validation loss: 1.9584335287412007

Epoch: 5| Step: 7
Training loss: 1.4242017269134521
Validation loss: 1.9760353714227676

Epoch: 5| Step: 8
Training loss: 1.7060139179229736
Validation loss: 1.9995888471603394

Epoch: 5| Step: 9
Training loss: 1.9709526300430298
Validation loss: 1.9738201349973679

Epoch: 5| Step: 10
Training loss: 1.103873610496521
Validation loss: 2.006059835354487

Epoch: 5| Step: 11
Training loss: 0.5515974760055542
Validation loss: 1.978616937994957

Epoch: 97| Step: 0
Training loss: 1.448175072669983
Validation loss: 1.9954276035229366

Epoch: 5| Step: 1
Training loss: 1.1979061365127563
Validation loss: 2.0446983128786087

Epoch: 5| Step: 2
Training loss: 1.8982031345367432
Validation loss: 2.029377887646357

Epoch: 5| Step: 3
Training loss: 1.4608559608459473
Validation loss: 2.00769134859244

Epoch: 5| Step: 4
Training loss: 1.447704553604126
Validation loss: 2.046630342801412

Epoch: 5| Step: 5
Training loss: 1.3824008703231812
Validation loss: 2.0074154188235602

Epoch: 5| Step: 6
Training loss: 1.171665906906128
Validation loss: 2.007989232738813

Epoch: 5| Step: 7
Training loss: 1.273622751235962
Validation loss: 1.9862529585758846

Epoch: 5| Step: 8
Training loss: 1.8500080108642578
Validation loss: 1.9797009428342183

Epoch: 5| Step: 9
Training loss: 1.6076574325561523
Validation loss: 1.9746560057004292

Epoch: 5| Step: 10
Training loss: 1.3845558166503906
Validation loss: 1.9961521526177723

Epoch: 5| Step: 11
Training loss: 1.7014024257659912
Validation loss: 1.9777031640211742

Epoch: 98| Step: 0
Training loss: 1.6956367492675781
Validation loss: 1.9992809146642685

Epoch: 5| Step: 1
Training loss: 1.4492006301879883
Validation loss: 1.9777512351671855

Epoch: 5| Step: 2
Training loss: 1.776889443397522
Validation loss: 2.01801997423172

Epoch: 5| Step: 3
Training loss: 1.3259652853012085
Validation loss: 1.9795620491107304

Epoch: 5| Step: 4
Training loss: 2.0745348930358887
Validation loss: 1.9915632506211598

Epoch: 5| Step: 5
Training loss: 1.2781827449798584
Validation loss: 2.0253479033708572

Epoch: 5| Step: 6
Training loss: 1.5131943225860596
Validation loss: 2.034731184442838

Epoch: 5| Step: 7
Training loss: 1.3759753704071045
Validation loss: 2.023316517472267

Epoch: 5| Step: 8
Training loss: 1.1126344203948975
Validation loss: 1.9972801407178242

Epoch: 5| Step: 9
Training loss: 1.3718974590301514
Validation loss: 1.9948812524477642

Epoch: 5| Step: 10
Training loss: 0.7896744012832642
Validation loss: 1.9701456278562546

Epoch: 5| Step: 11
Training loss: 0.6270496845245361
Validation loss: 2.0155355582634606

Epoch: 99| Step: 0
Training loss: 1.5792261362075806
Validation loss: 1.94291353225708

Epoch: 5| Step: 1
Training loss: 1.6138675212860107
Validation loss: 1.9630255997180939

Epoch: 5| Step: 2
Training loss: 1.750311255455017
Validation loss: 1.9642941504716873

Epoch: 5| Step: 3
Training loss: 1.2344017028808594
Validation loss: 2.001073266069094

Epoch: 5| Step: 4
Training loss: 1.8766672611236572
Validation loss: 1.998581329981486

Epoch: 5| Step: 5
Training loss: 1.172021508216858
Validation loss: 1.995906298359235

Epoch: 5| Step: 6
Training loss: 1.1422123908996582
Validation loss: 2.023029421766599

Epoch: 5| Step: 7
Training loss: 1.5729248523712158
Validation loss: 2.0273242394129434

Epoch: 5| Step: 8
Training loss: 1.0523061752319336
Validation loss: 2.0203714271386466

Epoch: 5| Step: 9
Training loss: 1.4662868976593018
Validation loss: 2.0178602834542594

Epoch: 5| Step: 10
Training loss: 1.5321564674377441
Validation loss: 2.009797841310501

Epoch: 5| Step: 11
Training loss: 0.7248594760894775
Validation loss: 1.9989270369211833

Epoch: 100| Step: 0
Training loss: 0.9491604566574097
Validation loss: 1.9893831213315327

Epoch: 5| Step: 1
Training loss: 1.5779975652694702
Validation loss: 2.002373903989792

Epoch: 5| Step: 2
Training loss: 1.5125658512115479
Validation loss: 1.995437557498614

Epoch: 5| Step: 3
Training loss: 1.3762317895889282
Validation loss: 1.9909032434225082

Epoch: 5| Step: 4
Training loss: 1.6635541915893555
Validation loss: 1.9796653191248577

Epoch: 5| Step: 5
Training loss: 1.2075990438461304
Validation loss: 1.990902264912923

Epoch: 5| Step: 6
Training loss: 1.3882797956466675
Validation loss: 1.976583148042361

Epoch: 5| Step: 7
Training loss: 1.6444886922836304
Validation loss: 1.999632939696312

Epoch: 5| Step: 8
Training loss: 0.9658924341201782
Validation loss: 1.9851034084955852

Epoch: 5| Step: 9
Training loss: 1.4781038761138916
Validation loss: 2.001437768340111

Epoch: 5| Step: 10
Training loss: 1.8267494440078735
Validation loss: 2.0081708133220673

Epoch: 5| Step: 11
Training loss: 1.270414113998413
Validation loss: 2.0019404888153076

Epoch: 101| Step: 0
Training loss: 1.201189398765564
Validation loss: 2.066426396369934

Epoch: 5| Step: 1
Training loss: 1.9343674182891846
Validation loss: 2.0405565996964774

Epoch: 5| Step: 2
Training loss: 1.8867905139923096
Validation loss: 2.0295381049315133

Epoch: 5| Step: 3
Training loss: 1.1229350566864014
Validation loss: 2.04301247994105

Epoch: 5| Step: 4
Training loss: 1.748231291770935
Validation loss: 2.0213104536135993

Epoch: 5| Step: 5
Training loss: 1.316502332687378
Validation loss: 2.0233340511719384

Epoch: 5| Step: 6
Training loss: 0.9929198026657104
Validation loss: 1.9507265438636143

Epoch: 5| Step: 7
Training loss: 1.58841872215271
Validation loss: 1.990721772114436

Epoch: 5| Step: 8
Training loss: 1.3330957889556885
Validation loss: 1.9427562654018402

Epoch: 5| Step: 9
Training loss: 1.1912429332733154
Validation loss: 1.9737752725680668

Epoch: 5| Step: 10
Training loss: 1.7225173711776733
Validation loss: 1.9463933954636257

Epoch: 5| Step: 11
Training loss: 1.83171546459198
Validation loss: 1.9855930308500926

Epoch: 102| Step: 0
Training loss: 0.6933655738830566
Validation loss: 1.9796142379442851

Epoch: 5| Step: 1
Training loss: 1.1107393503189087
Validation loss: 2.0459018548329673

Epoch: 5| Step: 2
Training loss: 1.250084638595581
Validation loss: 2.0517581403255463

Epoch: 5| Step: 3
Training loss: 1.7803869247436523
Validation loss: 2.0268714129924774

Epoch: 5| Step: 4
Training loss: 1.5411089658737183
Validation loss: 2.006830101211866

Epoch: 5| Step: 5
Training loss: 1.353351354598999
Validation loss: 2.032594248652458

Epoch: 5| Step: 6
Training loss: 1.222983479499817
Validation loss: 2.0251945356527963

Epoch: 5| Step: 7
Training loss: 1.9845237731933594
Validation loss: 2.0139408260583878

Epoch: 5| Step: 8
Training loss: 1.4607802629470825
Validation loss: 1.9951041142145793

Epoch: 5| Step: 9
Training loss: 1.3309003114700317
Validation loss: 1.9768125315507252

Epoch: 5| Step: 10
Training loss: 1.757642388343811
Validation loss: 1.957448810338974

Epoch: 5| Step: 11
Training loss: 1.472614049911499
Validation loss: 1.981444959839185

Epoch: 103| Step: 0
Training loss: 1.656467080116272
Validation loss: 1.9642457167307537

Epoch: 5| Step: 1
Training loss: 0.6564240455627441
Validation loss: 1.9817217737436295

Epoch: 5| Step: 2
Training loss: 1.6358591318130493
Validation loss: 1.9812952478726704

Epoch: 5| Step: 3
Training loss: 1.856452226638794
Validation loss: 2.0418109198411307

Epoch: 5| Step: 4
Training loss: 1.0705246925354004
Validation loss: 2.0141729712486267

Epoch: 5| Step: 5
Training loss: 1.5167373418807983
Validation loss: 2.0106030454238257

Epoch: 5| Step: 6
Training loss: 1.3655906915664673
Validation loss: 2.0224499106407166

Epoch: 5| Step: 7
Training loss: 1.3508527278900146
Validation loss: 2.025944327314695

Epoch: 5| Step: 8
Training loss: 1.0816659927368164
Validation loss: 1.9482532391945522

Epoch: 5| Step: 9
Training loss: 1.7860920429229736
Validation loss: 1.9957496871550877

Epoch: 5| Step: 10
Training loss: 1.1576560735702515
Validation loss: 2.0073317090670266

Epoch: 5| Step: 11
Training loss: 0.8411625623703003
Validation loss: 1.9920181632041931

Epoch: 104| Step: 0
Training loss: 1.7960469722747803
Validation loss: 1.987545241912206

Epoch: 5| Step: 1
Training loss: 1.534409523010254
Validation loss: 2.0336120078961053

Epoch: 5| Step: 2
Training loss: 1.2366750240325928
Validation loss: 2.0141570220390954

Epoch: 5| Step: 3
Training loss: 1.111895203590393
Validation loss: 2.022677709658941

Epoch: 5| Step: 4
Training loss: 1.0704500675201416
Validation loss: 2.0234116315841675

Epoch: 5| Step: 5
Training loss: 1.6117722988128662
Validation loss: 2.032548740506172

Epoch: 5| Step: 6
Training loss: 1.0253909826278687
Validation loss: 2.0143748025099435

Epoch: 5| Step: 7
Training loss: 0.9202070236206055
Validation loss: 2.0334494411945343

Epoch: 5| Step: 8
Training loss: 1.2357215881347656
Validation loss: 1.9988930722077687

Epoch: 5| Step: 9
Training loss: 1.1857564449310303
Validation loss: 2.045874605576197

Epoch: 5| Step: 10
Training loss: 2.118184804916382
Validation loss: 1.975407525897026

Epoch: 5| Step: 11
Training loss: 1.8337613344192505
Validation loss: 1.9954101691643398

Epoch: 105| Step: 0
Training loss: 0.8571226000785828
Validation loss: 2.036019558707873

Epoch: 5| Step: 1
Training loss: 0.7672728300094604
Validation loss: 2.050240953763326

Epoch: 5| Step: 2
Training loss: 2.0640170574188232
Validation loss: 2.0057497769594193

Epoch: 5| Step: 3
Training loss: 1.8850082159042358
Validation loss: 2.0149679481983185

Epoch: 5| Step: 4
Training loss: 1.2266275882720947
Validation loss: 2.0281922817230225

Epoch: 5| Step: 5
Training loss: 1.3434621095657349
Validation loss: 2.0575707852840424

Epoch: 5| Step: 6
Training loss: 1.418672800064087
Validation loss: 2.0125233232975006

Epoch: 5| Step: 7
Training loss: 1.0478415489196777
Validation loss: 2.0440332889556885

Epoch: 5| Step: 8
Training loss: 1.9011166095733643
Validation loss: 1.9777331004540126

Epoch: 5| Step: 9
Training loss: 0.9141312837600708
Validation loss: 1.9566149562597275

Epoch: 5| Step: 10
Training loss: 1.5570800304412842
Validation loss: 1.9507238417863846

Epoch: 5| Step: 11
Training loss: 1.3169769048690796
Validation loss: 2.0057878494262695

Epoch: 106| Step: 0
Training loss: 1.4124276638031006
Validation loss: 1.9917081147432327

Epoch: 5| Step: 1
Training loss: 1.5712324380874634
Validation loss: 1.9966141780217488

Epoch: 5| Step: 2
Training loss: 1.4329473972320557
Validation loss: 1.983305886387825

Epoch: 5| Step: 3
Training loss: 1.1249271631240845
Validation loss: 2.062969297170639

Epoch: 5| Step: 4
Training loss: 1.2365421056747437
Validation loss: 2.0239059229691825

Epoch: 5| Step: 5
Training loss: 1.621649146080017
Validation loss: 2.055005927880605

Epoch: 5| Step: 6
Training loss: 1.9973347187042236
Validation loss: 2.077815885345141

Epoch: 5| Step: 7
Training loss: 0.9494625329971313
Validation loss: 2.02693310379982

Epoch: 5| Step: 8
Training loss: 1.3584973812103271
Validation loss: 2.0249313712120056

Epoch: 5| Step: 9
Training loss: 1.3027899265289307
Validation loss: 1.9870041062434514

Epoch: 5| Step: 10
Training loss: 0.9952648878097534
Validation loss: 2.029887373248736

Epoch: 5| Step: 11
Training loss: 1.3607442378997803
Validation loss: 2.023070921500524

Epoch: 107| Step: 0
Training loss: 1.2558746337890625
Validation loss: 1.9871061543623607

Epoch: 5| Step: 1
Training loss: 1.4266092777252197
Validation loss: 2.0023523469765983

Epoch: 5| Step: 2
Training loss: 1.326952576637268
Validation loss: 1.9903348137935002

Epoch: 5| Step: 3
Training loss: 1.9668306112289429
Validation loss: 2.0126974135637283

Epoch: 5| Step: 4
Training loss: 1.045813798904419
Validation loss: 1.976237823565801

Epoch: 5| Step: 5
Training loss: 1.8762973546981812
Validation loss: 2.0110091865062714

Epoch: 5| Step: 6
Training loss: 0.9923518300056458
Validation loss: 2.0139985432227454

Epoch: 5| Step: 7
Training loss: 1.3101246356964111
Validation loss: 1.956189900636673

Epoch: 5| Step: 8
Training loss: 0.8808869123458862
Validation loss: 2.0306065132220588

Epoch: 5| Step: 9
Training loss: 1.1779062747955322
Validation loss: 2.0453551610310874

Epoch: 5| Step: 10
Training loss: 1.5846821069717407
Validation loss: 2.0497876902421317

Epoch: 5| Step: 11
Training loss: 1.6348084211349487
Validation loss: 2.0426287601391473

Epoch: 108| Step: 0
Training loss: 1.4869661331176758
Validation loss: 2.107640807827314

Epoch: 5| Step: 1
Training loss: 1.446131944656372
Validation loss: 2.0664228002230325

Epoch: 5| Step: 2
Training loss: 1.2311134338378906
Validation loss: 2.019270266095797

Epoch: 5| Step: 3
Training loss: 0.7243815660476685
Validation loss: 2.0527376433213553

Epoch: 5| Step: 4
Training loss: 2.073408842086792
Validation loss: 2.03489218155543

Epoch: 5| Step: 5
Training loss: 1.6277706623077393
Validation loss: 1.965318610270818

Epoch: 5| Step: 6
Training loss: 0.8037513494491577
Validation loss: 1.9702688505252202

Epoch: 5| Step: 7
Training loss: 1.224471926689148
Validation loss: 1.9525218904018402

Epoch: 5| Step: 8
Training loss: 1.586279273033142
Validation loss: 1.9915498395760853

Epoch: 5| Step: 9
Training loss: 0.9648126363754272
Validation loss: 2.0052177160978317

Epoch: 5| Step: 10
Training loss: 2.0640220642089844
Validation loss: 1.9626351495583851

Epoch: 5| Step: 11
Training loss: 0.5284732580184937
Validation loss: 2.0960508584976196

Epoch: 109| Step: 0
Training loss: 0.9127956628799438
Validation loss: 2.033664201696714

Epoch: 5| Step: 1
Training loss: 1.0679097175598145
Validation loss: 2.051318570971489

Epoch: 5| Step: 2
Training loss: 1.2929928302764893
Validation loss: 2.0117274125417075

Epoch: 5| Step: 3
Training loss: 1.7232916355133057
Validation loss: 1.9893647382656734

Epoch: 5| Step: 4
Training loss: 1.2340564727783203
Validation loss: 1.9961811204751332

Epoch: 5| Step: 5
Training loss: 1.1019389629364014
Validation loss: 2.0272529969612756

Epoch: 5| Step: 6
Training loss: 1.0934505462646484
Validation loss: 2.0286279817422233

Epoch: 5| Step: 7
Training loss: 1.182320237159729
Validation loss: 2.0468100855747857

Epoch: 5| Step: 8
Training loss: 1.3194012641906738
Validation loss: 2.0057643006245294

Epoch: 5| Step: 9
Training loss: 1.2293449640274048
Validation loss: 1.9795956363280613

Epoch: 5| Step: 10
Training loss: 1.8736242055892944
Validation loss: 2.0249775499105453

Epoch: 5| Step: 11
Training loss: 2.4595515727996826
Validation loss: 2.0127317806084952

Epoch: 110| Step: 0
Training loss: 1.1477829217910767
Validation loss: 2.069596529006958

Epoch: 5| Step: 1
Training loss: 1.3040887117385864
Validation loss: 2.0684972405433655

Epoch: 5| Step: 2
Training loss: 0.8879594802856445
Validation loss: 2.079679772257805

Epoch: 5| Step: 3
Training loss: 1.4480541944503784
Validation loss: 2.053925837079684

Epoch: 5| Step: 4
Training loss: 1.6969407796859741
Validation loss: 2.067076856891314

Epoch: 5| Step: 5
Training loss: 1.425675630569458
Validation loss: 2.0228240936994553

Epoch: 5| Step: 6
Training loss: 1.3311575651168823
Validation loss: 1.9705261041720707

Epoch: 5| Step: 7
Training loss: 1.5636324882507324
Validation loss: 2.0137972136338553

Epoch: 5| Step: 8
Training loss: 1.404709815979004
Validation loss: 1.9270063241322835

Epoch: 5| Step: 9
Training loss: 1.4375702142715454
Validation loss: 1.9859680732091267

Epoch: 5| Step: 10
Training loss: 1.2516343593597412
Validation loss: 1.9457056472698848

Epoch: 5| Step: 11
Training loss: 0.3755025863647461
Validation loss: 1.9889276921749115

Epoch: 111| Step: 0
Training loss: 1.6637519598007202
Validation loss: 2.059637561440468

Epoch: 5| Step: 1
Training loss: 1.33087956905365
Validation loss: 2.1253613978624344

Epoch: 5| Step: 2
Training loss: 1.3017127513885498
Validation loss: 2.1444166054328284

Epoch: 5| Step: 3
Training loss: 1.1453771591186523
Validation loss: 2.114946648478508

Epoch: 5| Step: 4
Training loss: 1.2004165649414062
Validation loss: 2.042649914820989

Epoch: 5| Step: 5
Training loss: 1.153903603553772
Validation loss: 2.051454817255338

Epoch: 5| Step: 6
Training loss: 0.8955866098403931
Validation loss: 2.0279801239569983

Epoch: 5| Step: 7
Training loss: 1.5946797132492065
Validation loss: 2.0172215501467385

Epoch: 5| Step: 8
Training loss: 0.9233149290084839
Validation loss: 2.0135480066140494

Epoch: 5| Step: 9
Training loss: 1.4087578058242798
Validation loss: 1.9856977115074794

Epoch: 5| Step: 10
Training loss: 2.243030309677124
Validation loss: 1.9930892537037532

Epoch: 5| Step: 11
Training loss: 1.5629658699035645
Validation loss: 2.0292439460754395

Epoch: 112| Step: 0
Training loss: 1.5355699062347412
Validation loss: 1.9807087033987045

Epoch: 5| Step: 1
Training loss: 1.8222938776016235
Validation loss: 1.9481359620889027

Epoch: 5| Step: 2
Training loss: 1.1958467960357666
Validation loss: 1.9413589090108871

Epoch: 5| Step: 3
Training loss: 1.2947232723236084
Validation loss: 1.9556645254294078

Epoch: 5| Step: 4
Training loss: 1.4073032140731812
Validation loss: 1.9527547905842464

Epoch: 5| Step: 5
Training loss: 1.61067795753479
Validation loss: 1.9858538458744686

Epoch: 5| Step: 6
Training loss: 1.445114254951477
Validation loss: 2.0303380290667215

Epoch: 5| Step: 7
Training loss: 1.2093089818954468
Validation loss: 2.071713204185168

Epoch: 5| Step: 8
Training loss: 1.1802306175231934
Validation loss: 2.1037893344958625

Epoch: 5| Step: 9
Training loss: 1.3583968877792358
Validation loss: 2.110506698489189

Epoch: 5| Step: 10
Training loss: 1.0648260116577148
Validation loss: 2.054549887776375

Epoch: 5| Step: 11
Training loss: 1.2922773361206055
Validation loss: 2.0349848717451096

Epoch: 113| Step: 0
Training loss: 1.6039879322052002
Validation loss: 1.997455100218455

Epoch: 5| Step: 1
Training loss: 1.3186962604522705
Validation loss: 1.9674972196420033

Epoch: 5| Step: 2
Training loss: 1.5793360471725464
Validation loss: 1.9317903916041057

Epoch: 5| Step: 3
Training loss: 1.3990201950073242
Validation loss: 1.9758345832427342

Epoch: 5| Step: 4
Training loss: 1.5065735578536987
Validation loss: 1.977699746688207

Epoch: 5| Step: 5
Training loss: 1.305381178855896
Validation loss: 1.9945284873247147

Epoch: 5| Step: 6
Training loss: 1.0194021463394165
Validation loss: 1.9944730053345363

Epoch: 5| Step: 7
Training loss: 0.7421519160270691
Validation loss: 2.0331510305404663

Epoch: 5| Step: 8
Training loss: 1.384472131729126
Validation loss: 2.0402492036422095

Epoch: 5| Step: 9
Training loss: 0.772418200969696
Validation loss: 2.007746527592341

Epoch: 5| Step: 10
Training loss: 1.3601773977279663
Validation loss: 2.016961266597112

Epoch: 5| Step: 11
Training loss: 1.5290799140930176
Validation loss: 2.0033790667851767

Epoch: 114| Step: 0
Training loss: 1.5569984912872314
Validation loss: 2.0471629401048026

Epoch: 5| Step: 1
Training loss: 1.2785924673080444
Validation loss: 2.046170557538668

Epoch: 5| Step: 2
Training loss: 1.088881492614746
Validation loss: 2.0247422407070794

Epoch: 5| Step: 3
Training loss: 1.4167900085449219
Validation loss: 1.9769585678974788

Epoch: 5| Step: 4
Training loss: 1.260312557220459
Validation loss: 1.9899192253748577

Epoch: 5| Step: 5
Training loss: 1.1906466484069824
Validation loss: 2.0006437053283057

Epoch: 5| Step: 6
Training loss: 1.2545298337936401
Validation loss: 1.941475008924802

Epoch: 5| Step: 7
Training loss: 1.3356029987335205
Validation loss: 1.9757154782613118

Epoch: 5| Step: 8
Training loss: 0.9676520228385925
Validation loss: 2.03597026069959

Epoch: 5| Step: 9
Training loss: 1.347926378250122
Validation loss: 2.0459033052126565

Epoch: 5| Step: 10
Training loss: 1.2517699003219604
Validation loss: 2.0114636520544686

Epoch: 5| Step: 11
Training loss: 1.4535621404647827
Validation loss: 2.114001527428627

Epoch: 115| Step: 0
Training loss: 1.9450536966323853
Validation loss: 2.0690266539653144

Epoch: 5| Step: 1
Training loss: 0.9384661912918091
Validation loss: 2.0516744951407113

Epoch: 5| Step: 2
Training loss: 1.3113130331039429
Validation loss: 2.0410056759913764

Epoch: 5| Step: 3
Training loss: 1.289786696434021
Validation loss: 1.9049706210692723

Epoch: 5| Step: 4
Training loss: 1.2135981321334839
Validation loss: 1.9494004646937053

Epoch: 5| Step: 5
Training loss: 1.8393083810806274
Validation loss: 1.9550781150658925

Epoch: 5| Step: 6
Training loss: 1.1353073120117188
Validation loss: 1.9668571203947067

Epoch: 5| Step: 7
Training loss: 1.4776008129119873
Validation loss: 1.9964560965696971

Epoch: 5| Step: 8
Training loss: 0.6133479475975037
Validation loss: 1.9955739279588063

Epoch: 5| Step: 9
Training loss: 1.2704441547393799
Validation loss: 2.0131640483935676

Epoch: 5| Step: 10
Training loss: 0.9054762721061707
Validation loss: 2.056915740172068

Epoch: 5| Step: 11
Training loss: 0.4568777084350586
Validation loss: 2.0595014741023383

Epoch: 116| Step: 0
Training loss: 1.0137317180633545
Validation loss: 2.059744492173195

Epoch: 5| Step: 1
Training loss: 1.2777196168899536
Validation loss: 2.0800640483697257

Epoch: 5| Step: 2
Training loss: 0.8415974378585815
Validation loss: 1.999539037545522

Epoch: 5| Step: 3
Training loss: 1.7628250122070312
Validation loss: 1.992412120103836

Epoch: 5| Step: 4
Training loss: 0.8539587259292603
Validation loss: 2.020778422554334

Epoch: 5| Step: 5
Training loss: 1.1685526371002197
Validation loss: 1.9571814487377803

Epoch: 5| Step: 6
Training loss: 1.030187726020813
Validation loss: 2.004627620180448

Epoch: 5| Step: 7
Training loss: 1.3081367015838623
Validation loss: 1.9865175584952037

Epoch: 5| Step: 8
Training loss: 0.9221574068069458
Validation loss: 2.0025250613689423

Epoch: 5| Step: 9
Training loss: 0.9733627438545227
Validation loss: 2.090356225768725

Epoch: 5| Step: 10
Training loss: 2.1164002418518066
Validation loss: 2.0582540233929953

Epoch: 5| Step: 11
Training loss: 2.8554463386535645
Validation loss: 2.060055136680603

Epoch: 117| Step: 0
Training loss: 1.4673312902450562
Validation loss: 2.060267652074496

Epoch: 5| Step: 1
Training loss: 0.7615126967430115
Validation loss: 2.034310753146807

Epoch: 5| Step: 2
Training loss: 0.9251641035079956
Validation loss: 1.9930192828178406

Epoch: 5| Step: 3
Training loss: 1.1147109270095825
Validation loss: 1.9877360314130783

Epoch: 5| Step: 4
Training loss: 1.269081473350525
Validation loss: 1.9838144928216934

Epoch: 5| Step: 5
Training loss: 1.4861012697219849
Validation loss: 1.993676707148552

Epoch: 5| Step: 6
Training loss: 1.500912070274353
Validation loss: 1.9873052388429642

Epoch: 5| Step: 7
Training loss: 1.6710764169692993
Validation loss: 2.0172224839528403

Epoch: 5| Step: 8
Training loss: 1.165066123008728
Validation loss: 2.0365658154090247

Epoch: 5| Step: 9
Training loss: 0.9972994923591614
Validation loss: 2.0792464911937714

Epoch: 5| Step: 10
Training loss: 0.9977718591690063
Validation loss: 2.052016034722328

Epoch: 5| Step: 11
Training loss: 2.802259922027588
Validation loss: 2.063777650396029

Epoch: 118| Step: 0
Training loss: 1.7793948650360107
Validation loss: 2.0414183040459952

Epoch: 5| Step: 1
Training loss: 1.0848411321640015
Validation loss: 1.9898138890663783

Epoch: 5| Step: 2
Training loss: 1.4690675735473633
Validation loss: 1.9927766621112823

Epoch: 5| Step: 3
Training loss: 1.380645513534546
Validation loss: 2.013545667131742

Epoch: 5| Step: 4
Training loss: 1.16826593875885
Validation loss: 1.9950602402289708

Epoch: 5| Step: 5
Training loss: 0.9437127113342285
Validation loss: 2.040703962246577

Epoch: 5| Step: 6
Training loss: 1.1925151348114014
Validation loss: 1.975739856561025

Epoch: 5| Step: 7
Training loss: 0.9950917363166809
Validation loss: 1.985147312283516

Epoch: 5| Step: 8
Training loss: 1.1589710712432861
Validation loss: 1.9948652734359105

Epoch: 5| Step: 9
Training loss: 1.0572583675384521
Validation loss: 1.9979256490866344

Epoch: 5| Step: 10
Training loss: 0.9386485815048218
Validation loss: 2.0299443850914636

Epoch: 5| Step: 11
Training loss: 1.6264175176620483
Validation loss: 2.024756222963333

Epoch: 119| Step: 0
Training loss: 1.6129096746444702
Validation loss: 1.9812311480442684

Epoch: 5| Step: 1
Training loss: 0.8315081596374512
Validation loss: 1.9898794144392014

Epoch: 5| Step: 2
Training loss: 1.3602406978607178
Validation loss: 1.9785869965950649

Epoch: 5| Step: 3
Training loss: 1.430424451828003
Validation loss: 1.9612272679805756

Epoch: 5| Step: 4
Training loss: 0.9838468432426453
Validation loss: 1.9258442719777424

Epoch: 5| Step: 5
Training loss: 0.9935077428817749
Validation loss: 1.9706904689470928

Epoch: 5| Step: 6
Training loss: 0.8226186037063599
Validation loss: 2.02030973136425

Epoch: 5| Step: 7
Training loss: 1.457632064819336
Validation loss: 2.0588646878798804

Epoch: 5| Step: 8
Training loss: 1.060030221939087
Validation loss: 2.028048098087311

Epoch: 5| Step: 9
Training loss: 1.098708987236023
Validation loss: 2.113174016276995

Epoch: 5| Step: 10
Training loss: 1.4563241004943848
Validation loss: 2.041942755381266

Epoch: 5| Step: 11
Training loss: 1.9972796440124512
Validation loss: 2.0482016603151956

Epoch: 120| Step: 0
Training loss: 1.2313969135284424
Validation loss: 1.9619528949260712

Epoch: 5| Step: 1
Training loss: 1.1573952436447144
Validation loss: 2.015356178085009

Epoch: 5| Step: 2
Training loss: 1.4663283824920654
Validation loss: 2.0013655920823417

Epoch: 5| Step: 3
Training loss: 1.399646520614624
Validation loss: 1.9707790861527126

Epoch: 5| Step: 4
Training loss: 1.0055197477340698
Validation loss: 1.9710890501737595

Epoch: 5| Step: 5
Training loss: 1.097839117050171
Validation loss: 2.0112296839555106

Epoch: 5| Step: 6
Training loss: 1.1618611812591553
Validation loss: 2.0460136036078134

Epoch: 5| Step: 7
Training loss: 1.1905772686004639
Validation loss: 2.078379193941752

Epoch: 5| Step: 8
Training loss: 1.1286085844039917
Validation loss: 2.0438831547896066

Epoch: 5| Step: 9
Training loss: 1.16990327835083
Validation loss: 2.0804094274838767

Epoch: 5| Step: 10
Training loss: 1.2943308353424072
Validation loss: 2.0379615326722464

Epoch: 5| Step: 11
Training loss: 0.5391414165496826
Validation loss: 2.0316540400187173

Epoch: 121| Step: 0
Training loss: 0.8057066202163696
Validation loss: 1.9722565909226735

Epoch: 5| Step: 1
Training loss: 1.222851276397705
Validation loss: 2.01653483013312

Epoch: 5| Step: 2
Training loss: 1.040391445159912
Validation loss: 1.9914007484912872

Epoch: 5| Step: 3
Training loss: 1.5355408191680908
Validation loss: 1.9895651191473007

Epoch: 5| Step: 4
Training loss: 1.373222827911377
Validation loss: 2.005853151281675

Epoch: 5| Step: 5
Training loss: 1.0990077257156372
Validation loss: 2.0223771979411445

Epoch: 5| Step: 6
Training loss: 1.011831521987915
Validation loss: 2.073004578550657

Epoch: 5| Step: 7
Training loss: 1.3825151920318604
Validation loss: 2.0822964111963906

Epoch: 5| Step: 8
Training loss: 1.2385947704315186
Validation loss: 2.0812863359848657

Epoch: 5| Step: 9
Training loss: 0.8998159170150757
Validation loss: 2.1303498645623526

Epoch: 5| Step: 10
Training loss: 1.1606767177581787
Validation loss: 2.071391890446345

Epoch: 5| Step: 11
Training loss: 1.3251184225082397
Validation loss: 2.045317987600962

Epoch: 122| Step: 0
Training loss: 1.70687997341156
Validation loss: 2.0716827114423118

Epoch: 5| Step: 1
Training loss: 1.5123240947723389
Validation loss: 2.008884390195211

Epoch: 5| Step: 2
Training loss: 1.4183648824691772
Validation loss: 1.9786182244618733

Epoch: 5| Step: 3
Training loss: 1.0302280187606812
Validation loss: 1.976387470960617

Epoch: 5| Step: 4
Training loss: 1.0684916973114014
Validation loss: 1.9633909563223522

Epoch: 5| Step: 5
Training loss: 1.2392714023590088
Validation loss: 1.998317946990331

Epoch: 5| Step: 6
Training loss: 1.1776068210601807
Validation loss: 2.032957295576731

Epoch: 5| Step: 7
Training loss: 0.7906912565231323
Validation loss: 2.028064399957657

Epoch: 5| Step: 8
Training loss: 1.2008494138717651
Validation loss: 2.02545898159345

Epoch: 5| Step: 9
Training loss: 0.8029767870903015
Validation loss: 2.0257603029410043

Epoch: 5| Step: 10
Training loss: 1.1540098190307617
Validation loss: 2.029530629515648

Epoch: 5| Step: 11
Training loss: 0.4267521798610687
Validation loss: 2.0469013104836145

Epoch: 123| Step: 0
Training loss: 1.1672756671905518
Validation loss: 2.053726856907209

Epoch: 5| Step: 1
Training loss: 1.2904026508331299
Validation loss: 2.0079241196314492

Epoch: 5| Step: 2
Training loss: 1.2788612842559814
Validation loss: 2.0156663904587426

Epoch: 5| Step: 3
Training loss: 1.161590337753296
Validation loss: 1.971811259786288

Epoch: 5| Step: 4
Training loss: 1.2259665727615356
Validation loss: 1.9673999299605687

Epoch: 5| Step: 5
Training loss: 0.7275274991989136
Validation loss: 1.9710322668155034

Epoch: 5| Step: 6
Training loss: 1.3508665561676025
Validation loss: 2.04674831032753

Epoch: 5| Step: 7
Training loss: 0.6873091459274292
Validation loss: 2.0514880269765854

Epoch: 5| Step: 8
Training loss: 1.2864651679992676
Validation loss: 2.08407195409139

Epoch: 5| Step: 9
Training loss: 1.6132242679595947
Validation loss: 2.056859682003657

Epoch: 5| Step: 10
Training loss: 1.1784327030181885
Validation loss: 2.0466351409753165

Epoch: 5| Step: 11
Training loss: 1.3855345249176025
Validation loss: 2.0360981673002243

Epoch: 124| Step: 0
Training loss: 0.879643440246582
Validation loss: 2.01343401769797

Epoch: 5| Step: 1
Training loss: 1.6240503787994385
Validation loss: 2.0006712277730307

Epoch: 5| Step: 2
Training loss: 1.4688889980316162
Validation loss: 1.9544936567544937

Epoch: 5| Step: 3
Training loss: 1.2676559686660767
Validation loss: 1.944166784485181

Epoch: 5| Step: 4
Training loss: 1.4220483303070068
Validation loss: 1.9986395239830017

Epoch: 5| Step: 5
Training loss: 0.9932346343994141
Validation loss: 1.956712727745374

Epoch: 5| Step: 6
Training loss: 1.184313178062439
Validation loss: 1.994612102707227

Epoch: 5| Step: 7
Training loss: 0.8003652691841125
Validation loss: 2.047243222594261

Epoch: 5| Step: 8
Training loss: 1.5251760482788086
Validation loss: 2.0550202429294586

Epoch: 5| Step: 9
Training loss: 1.1847374439239502
Validation loss: 2.0705135812362037

Epoch: 5| Step: 10
Training loss: 1.1600309610366821
Validation loss: 2.082076574365298

Epoch: 5| Step: 11
Training loss: 2.2346181869506836
Validation loss: 2.052342012524605

Epoch: 125| Step: 0
Training loss: 0.6441744565963745
Validation loss: 2.0124849726756415

Epoch: 5| Step: 1
Training loss: 1.2304408550262451
Validation loss: 1.9528494427601497

Epoch: 5| Step: 2
Training loss: 0.7733780145645142
Validation loss: 1.9745746006568272

Epoch: 5| Step: 3
Training loss: 1.4182597398757935
Validation loss: 1.945970858136813

Epoch: 5| Step: 4
Training loss: 1.34287428855896
Validation loss: 1.9901279757420223

Epoch: 5| Step: 5
Training loss: 1.4593796730041504
Validation loss: 2.0027439296245575

Epoch: 5| Step: 6
Training loss: 1.6441354751586914
Validation loss: 2.041466563940048

Epoch: 5| Step: 7
Training loss: 1.1352756023406982
Validation loss: 1.9991646707057953

Epoch: 5| Step: 8
Training loss: 0.7370737791061401
Validation loss: 2.041814004381498

Epoch: 5| Step: 9
Training loss: 1.0618977546691895
Validation loss: 2.100499058763186

Epoch: 5| Step: 10
Training loss: 1.0744547843933105
Validation loss: 2.0361665387948356

Epoch: 5| Step: 11
Training loss: 1.2724523544311523
Validation loss: 2.0075053671995797

Epoch: 126| Step: 0
Training loss: 1.025526523590088
Validation loss: 2.0127712935209274

Epoch: 5| Step: 1
Training loss: 0.9601141214370728
Validation loss: 2.0892486770947776

Epoch: 5| Step: 2
Training loss: 1.2012856006622314
Validation loss: 1.9982236574093502

Epoch: 5| Step: 3
Training loss: 1.0243669748306274
Validation loss: 2.019588420788447

Epoch: 5| Step: 4
Training loss: 1.097938060760498
Validation loss: 2.043266619245211

Epoch: 5| Step: 5
Training loss: 1.1791695356369019
Validation loss: 2.01869830985864

Epoch: 5| Step: 6
Training loss: 0.9630498886108398
Validation loss: 2.0341284225384393

Epoch: 5| Step: 7
Training loss: 1.2494580745697021
Validation loss: 1.9884089330832164

Epoch: 5| Step: 8
Training loss: 0.986904501914978
Validation loss: 2.0252167781194053

Epoch: 5| Step: 9
Training loss: 1.249969244003296
Validation loss: 2.031798059741656

Epoch: 5| Step: 10
Training loss: 1.2995551824569702
Validation loss: 2.089779128630956

Epoch: 5| Step: 11
Training loss: 1.40776526927948
Validation loss: 2.091180036465327

Epoch: 127| Step: 0
Training loss: 0.5807194709777832
Validation loss: 2.0397479633490243

Epoch: 5| Step: 1
Training loss: 0.9112812280654907
Validation loss: 2.072559823592504

Epoch: 5| Step: 2
Training loss: 1.2730928659439087
Validation loss: 1.9865254859129589

Epoch: 5| Step: 3
Training loss: 1.5459167957305908
Validation loss: 1.9451187203327815

Epoch: 5| Step: 4
Training loss: 0.7527948617935181
Validation loss: 1.9646746317545574

Epoch: 5| Step: 5
Training loss: 0.9247537851333618
Validation loss: 1.9710368712743123

Epoch: 5| Step: 6
Training loss: 2.002084255218506
Validation loss: 1.947659194469452

Epoch: 5| Step: 7
Training loss: 1.059238076210022
Validation loss: 2.0080430010954538

Epoch: 5| Step: 8
Training loss: 0.9379509091377258
Validation loss: 2.003788491090139

Epoch: 5| Step: 9
Training loss: 1.373093843460083
Validation loss: 2.0655649850765863

Epoch: 5| Step: 10
Training loss: 1.2032228708267212
Validation loss: 2.1082154909769693

Epoch: 5| Step: 11
Training loss: 2.1944565773010254
Validation loss: 2.107075343529383

Epoch: 128| Step: 0
Training loss: 1.2535227537155151
Validation loss: 2.110192875067393

Epoch: 5| Step: 1
Training loss: 1.0673646926879883
Validation loss: 2.1018951137860618

Epoch: 5| Step: 2
Training loss: 0.8965227007865906
Validation loss: 2.080047905445099

Epoch: 5| Step: 3
Training loss: 0.9157606363296509
Validation loss: 2.062113811572393

Epoch: 5| Step: 4
Training loss: 0.7312735319137573
Validation loss: 2.0516041964292526

Epoch: 5| Step: 5
Training loss: 1.488337516784668
Validation loss: 1.9791520138581593

Epoch: 5| Step: 6
Training loss: 1.5600063800811768
Validation loss: 2.0403901586929956

Epoch: 5| Step: 7
Training loss: 1.3891010284423828
Validation loss: 1.9782058944304783

Epoch: 5| Step: 8
Training loss: 1.3379554748535156
Validation loss: 1.9952994883060455

Epoch: 5| Step: 9
Training loss: 0.7958928346633911
Validation loss: 2.011874422430992

Epoch: 5| Step: 10
Training loss: 1.1141889095306396
Validation loss: 2.067198986808459

Epoch: 5| Step: 11
Training loss: 0.6817836761474609
Validation loss: 2.0717085798581443

Epoch: 129| Step: 0
Training loss: 1.3674863576889038
Validation loss: 2.0768548399209976

Epoch: 5| Step: 1
Training loss: 0.997894287109375
Validation loss: 2.0454007536172867

Epoch: 5| Step: 2
Training loss: 0.8331348299980164
Validation loss: 2.0242675840854645

Epoch: 5| Step: 3
Training loss: 0.9305794835090637
Validation loss: 2.0267634242773056

Epoch: 5| Step: 4
Training loss: 0.9404256939888
Validation loss: 2.0794244408607483

Epoch: 5| Step: 5
Training loss: 1.2350014448165894
Validation loss: 2.030969962477684

Epoch: 5| Step: 6
Training loss: 1.030443549156189
Validation loss: 2.03131410976251

Epoch: 5| Step: 7
Training loss: 1.2451486587524414
Validation loss: 2.0903128534555435

Epoch: 5| Step: 8
Training loss: 0.8669278025627136
Validation loss: 2.086617410182953

Epoch: 5| Step: 9
Training loss: 1.2014875411987305
Validation loss: 2.093967547019323

Epoch: 5| Step: 10
Training loss: 1.1082643270492554
Validation loss: 2.0914362023274102

Epoch: 5| Step: 11
Training loss: 0.9002068042755127
Validation loss: 2.0413430531819663

Epoch: 130| Step: 0
Training loss: 0.959528923034668
Validation loss: 2.0436432510614395

Epoch: 5| Step: 1
Training loss: 1.4795787334442139
Validation loss: 2.1160224229097366

Epoch: 5| Step: 2
Training loss: 0.7111564874649048
Validation loss: 2.0962807685136795

Epoch: 5| Step: 3
Training loss: 1.2984110116958618
Validation loss: 2.1170029441515603

Epoch: 5| Step: 4
Training loss: 1.5990455150604248
Validation loss: 1.9951899945735931

Epoch: 5| Step: 5
Training loss: 1.1995513439178467
Validation loss: 1.9954218218723934

Epoch: 5| Step: 6
Training loss: 0.9086629748344421
Validation loss: 2.0375430385271707

Epoch: 5| Step: 7
Training loss: 1.1892818212509155
Validation loss: 1.9878667891025543

Epoch: 5| Step: 8
Training loss: 1.1599146127700806
Validation loss: 2.0075592597325644

Epoch: 5| Step: 9
Training loss: 0.9900997281074524
Validation loss: 1.9817679623762767

Epoch: 5| Step: 10
Training loss: 0.923957347869873
Validation loss: 2.028413141767184

Epoch: 5| Step: 11
Training loss: 0.9198433756828308
Validation loss: 2.0689146469036737

Epoch: 131| Step: 0
Training loss: 1.4089386463165283
Validation loss: 2.090915784239769

Epoch: 5| Step: 1
Training loss: 1.0218786001205444
Validation loss: 2.14084559182326

Epoch: 5| Step: 2
Training loss: 0.814428985118866
Validation loss: 2.1070476770401

Epoch: 5| Step: 3
Training loss: 1.2330576181411743
Validation loss: 2.0835364013910294

Epoch: 5| Step: 4
Training loss: 1.0749475955963135
Validation loss: 2.0520920107762017

Epoch: 5| Step: 5
Training loss: 1.044012427330017
Validation loss: 2.024741197625796

Epoch: 5| Step: 6
Training loss: 1.107301950454712
Validation loss: 2.024926632642746

Epoch: 5| Step: 7
Training loss: 1.0007870197296143
Validation loss: 2.0031834046045938

Epoch: 5| Step: 8
Training loss: 0.9671831130981445
Validation loss: 1.9839426924784977

Epoch: 5| Step: 9
Training loss: 1.11844801902771
Validation loss: 1.9708881427844365

Epoch: 5| Step: 10
Training loss: 1.101473331451416
Validation loss: 2.011763334274292

Epoch: 5| Step: 11
Training loss: 0.3387860059738159
Validation loss: 2.040378232796987

Epoch: 132| Step: 0
Training loss: 0.9746635556221008
Validation loss: 2.0579960644245148

Epoch: 5| Step: 1
Training loss: 1.0981606245040894
Validation loss: 2.080174282193184

Epoch: 5| Step: 2
Training loss: 0.7822628021240234
Validation loss: 2.0460154910882316

Epoch: 5| Step: 3
Training loss: 0.8941813707351685
Validation loss: 2.0585469802220664

Epoch: 5| Step: 4
Training loss: 0.8508201837539673
Validation loss: 2.0219497233629227

Epoch: 5| Step: 5
Training loss: 1.4805171489715576
Validation loss: 2.057828346888224

Epoch: 5| Step: 6
Training loss: 1.3218488693237305
Validation loss: 2.062800168991089

Epoch: 5| Step: 7
Training loss: 0.8726991415023804
Validation loss: 2.0420864472786584

Epoch: 5| Step: 8
Training loss: 1.1619075536727905
Validation loss: 2.035262569785118

Epoch: 5| Step: 9
Training loss: 1.052995204925537
Validation loss: 2.000786925355593

Epoch: 5| Step: 10
Training loss: 1.2363922595977783
Validation loss: 2.0505473216374717

Epoch: 5| Step: 11
Training loss: 1.1693860292434692
Validation loss: 2.0133105466763177

Epoch: 133| Step: 0
Training loss: 0.8401861190795898
Validation loss: 1.9997280339399974

Epoch: 5| Step: 1
Training loss: 0.6843036413192749
Validation loss: 2.0501443097988763

Epoch: 5| Step: 2
Training loss: 0.8470025062561035
Validation loss: 2.0183564027150473

Epoch: 5| Step: 3
Training loss: 1.0199508666992188
Validation loss: 2.006725013256073

Epoch: 5| Step: 4
Training loss: 0.48709145188331604
Validation loss: 2.025598203142484

Epoch: 5| Step: 5
Training loss: 1.1887941360473633
Validation loss: 2.041122615337372

Epoch: 5| Step: 6
Training loss: 1.372792363166809
Validation loss: 2.077734554807345

Epoch: 5| Step: 7
Training loss: 1.273129940032959
Validation loss: 2.009494334459305

Epoch: 5| Step: 8
Training loss: 1.1374913454055786
Validation loss: 2.0276157756646476

Epoch: 5| Step: 9
Training loss: 1.6345548629760742
Validation loss: 2.022807151079178

Epoch: 5| Step: 10
Training loss: 1.0997040271759033
Validation loss: 1.9842315862576168

Epoch: 5| Step: 11
Training loss: 1.0097696781158447
Validation loss: 1.9781122903029125

Epoch: 134| Step: 0
Training loss: 0.9397351145744324
Validation loss: 2.064327900608381

Epoch: 5| Step: 1
Training loss: 0.9401671290397644
Validation loss: 2.0792543391386666

Epoch: 5| Step: 2
Training loss: 1.039167881011963
Validation loss: 2.177469144264857

Epoch: 5| Step: 3
Training loss: 0.8886913061141968
Validation loss: 2.188898280262947

Epoch: 5| Step: 4
Training loss: 1.0993907451629639
Validation loss: 2.1342076659202576

Epoch: 5| Step: 5
Training loss: 0.7291684746742249
Validation loss: 2.1040130058924356

Epoch: 5| Step: 6
Training loss: 1.059213399887085
Validation loss: 2.1002545853455863

Epoch: 5| Step: 7
Training loss: 0.7939419150352478
Validation loss: 2.0657412807146707

Epoch: 5| Step: 8
Training loss: 1.304513692855835
Validation loss: 2.051225244998932

Epoch: 5| Step: 9
Training loss: 1.9294769763946533
Validation loss: 1.9934786409139633

Epoch: 5| Step: 10
Training loss: 1.0013656616210938
Validation loss: 2.0453928510348

Epoch: 5| Step: 11
Training loss: 0.7963837385177612
Validation loss: 2.04873518149058

Epoch: 135| Step: 0
Training loss: 1.400492787361145
Validation loss: 2.0416207114855447

Epoch: 5| Step: 1
Training loss: 0.9630475044250488
Validation loss: 1.9887389640013378

Epoch: 5| Step: 2
Training loss: 1.7241675853729248
Validation loss: 2.0621047914028168

Epoch: 5| Step: 3
Training loss: 1.5037083625793457
Validation loss: 2.097443789243698

Epoch: 5| Step: 4
Training loss: 0.6703082323074341
Validation loss: 2.158376639087995

Epoch: 5| Step: 5
Training loss: 1.2231051921844482
Validation loss: 2.184557015697161

Epoch: 5| Step: 6
Training loss: 0.9295171499252319
Validation loss: 2.1763538320859275

Epoch: 5| Step: 7
Training loss: 1.064016342163086
Validation loss: 2.144603376587232

Epoch: 5| Step: 8
Training loss: 0.7671841382980347
Validation loss: 2.1184853663047156

Epoch: 5| Step: 9
Training loss: 1.0569708347320557
Validation loss: 1.9957111775875092

Epoch: 5| Step: 10
Training loss: 0.8605782389640808
Validation loss: 1.9958529869715373

Epoch: 5| Step: 11
Training loss: 0.30796825885772705
Validation loss: 2.020434627930323

Epoch: 136| Step: 0
Training loss: 1.1048400402069092
Validation loss: 1.9660900980234146

Epoch: 5| Step: 1
Training loss: 0.961502194404602
Validation loss: 1.994533012310664

Epoch: 5| Step: 2
Training loss: 0.9586294293403625
Validation loss: 1.9824193517367046

Epoch: 5| Step: 3
Training loss: 1.0155137777328491
Validation loss: 2.051661267876625

Epoch: 5| Step: 4
Training loss: 1.0069271326065063
Validation loss: 2.0742903600136438

Epoch: 5| Step: 5
Training loss: 1.1287918090820312
Validation loss: 2.091908097267151

Epoch: 5| Step: 6
Training loss: 0.8635139465332031
Validation loss: 2.054769699772199

Epoch: 5| Step: 7
Training loss: 1.0601146221160889
Validation loss: 2.0397533923387527

Epoch: 5| Step: 8
Training loss: 0.9738140106201172
Validation loss: 2.020924538373947

Epoch: 5| Step: 9
Training loss: 0.9601389169692993
Validation loss: 2.0434721310933432

Epoch: 5| Step: 10
Training loss: 1.1996650695800781
Validation loss: 2.0315886785586676

Epoch: 5| Step: 11
Training loss: 1.6159816980361938
Validation loss: 2.027888774871826

Epoch: 137| Step: 0
Training loss: 1.2360248565673828
Validation loss: 2.030195400118828

Epoch: 5| Step: 1
Training loss: 1.6150639057159424
Validation loss: 2.018889680504799

Epoch: 5| Step: 2
Training loss: 0.7663236856460571
Validation loss: 2.0179943343003592

Epoch: 5| Step: 3
Training loss: 1.263905644416809
Validation loss: 2.0114887903134027

Epoch: 5| Step: 4
Training loss: 0.6398349404335022
Validation loss: 2.019704674681028

Epoch: 5| Step: 5
Training loss: 0.5646814703941345
Validation loss: 2.0554897487163544

Epoch: 5| Step: 6
Training loss: 0.7973832488059998
Validation loss: 2.076482981443405

Epoch: 5| Step: 7
Training loss: 1.3985590934753418
Validation loss: 2.129358649253845

Epoch: 5| Step: 8
Training loss: 1.291520357131958
Validation loss: 2.124684378504753

Epoch: 5| Step: 9
Training loss: 1.5033414363861084
Validation loss: 2.0485358039538064

Epoch: 5| Step: 10
Training loss: 0.602082371711731
Validation loss: 2.055550217628479

Epoch: 5| Step: 11
Training loss: 1.991471767425537
Validation loss: 2.0190934389829636

Epoch: 138| Step: 0
Training loss: 1.1909855604171753
Validation loss: 1.9741556495428085

Epoch: 5| Step: 1
Training loss: 1.1908661127090454
Validation loss: 2.0507333874702454

Epoch: 5| Step: 2
Training loss: 1.9276123046875
Validation loss: 2.0420561879873276

Epoch: 5| Step: 3
Training loss: 1.671522855758667
Validation loss: 1.9922430713971455

Epoch: 5| Step: 4
Training loss: 1.069430947303772
Validation loss: 1.9994517763455708

Epoch: 5| Step: 5
Training loss: 0.9201879501342773
Validation loss: 2.0257981518904367

Epoch: 5| Step: 6
Training loss: 0.9518429040908813
Validation loss: 1.9819535066684086

Epoch: 5| Step: 7
Training loss: 0.8476921319961548
Validation loss: 1.999981587131818

Epoch: 5| Step: 8
Training loss: 1.1682913303375244
Validation loss: 2.068730428814888

Epoch: 5| Step: 9
Training loss: 0.8992315530776978
Validation loss: 2.0593796322743096

Epoch: 5| Step: 10
Training loss: 1.2330831289291382
Validation loss: 2.1077980448802314

Epoch: 5| Step: 11
Training loss: 0.46131861209869385
Validation loss: 2.0337240397930145

Epoch: 139| Step: 0
Training loss: 0.5976067781448364
Validation loss: 2.089286208152771

Epoch: 5| Step: 1
Training loss: 0.5601627230644226
Validation loss: 2.0014815628528595

Epoch: 5| Step: 2
Training loss: 0.8596897125244141
Validation loss: 2.0285799304644265

Epoch: 5| Step: 3
Training loss: 1.3678746223449707
Validation loss: 1.9703247447808583

Epoch: 5| Step: 4
Training loss: 1.1617825031280518
Validation loss: 1.9725800901651382

Epoch: 5| Step: 5
Training loss: 1.4804106950759888
Validation loss: 2.0130355954170227

Epoch: 5| Step: 6
Training loss: 1.091977596282959
Validation loss: 2.0258295883735022

Epoch: 5| Step: 7
Training loss: 1.2372872829437256
Validation loss: 2.0591108997662864

Epoch: 5| Step: 8
Training loss: 0.8564454913139343
Validation loss: 2.0359308222929635

Epoch: 5| Step: 9
Training loss: 0.9842782020568848
Validation loss: 2.0450069308280945

Epoch: 5| Step: 10
Training loss: 0.9419944882392883
Validation loss: 1.993196114897728

Epoch: 5| Step: 11
Training loss: 0.6718747615814209
Validation loss: 2.0511812518040338

Epoch: 140| Step: 0
Training loss: 0.9804830551147461
Validation loss: 2.063886101047198

Epoch: 5| Step: 1
Training loss: 0.8569038510322571
Validation loss: 2.05794965227445

Epoch: 5| Step: 2
Training loss: 0.9493234753608704
Validation loss: 2.031767879923185

Epoch: 5| Step: 3
Training loss: 0.8804497718811035
Validation loss: 2.01754958430926

Epoch: 5| Step: 4
Training loss: 0.8396450281143188
Validation loss: 2.0054216434558234

Epoch: 5| Step: 5
Training loss: 1.0014407634735107
Validation loss: 2.0448423624038696

Epoch: 5| Step: 6
Training loss: 1.3747310638427734
Validation loss: 2.0187346786260605

Epoch: 5| Step: 7
Training loss: 1.0362240076065063
Validation loss: 2.0113818496465683

Epoch: 5| Step: 8
Training loss: 1.0489639043807983
Validation loss: 1.9938465058803558

Epoch: 5| Step: 9
Training loss: 1.0299924612045288
Validation loss: 2.0005978544553122

Epoch: 5| Step: 10
Training loss: 0.6644490957260132
Validation loss: 1.9972542822360992

Epoch: 5| Step: 11
Training loss: 0.8907525539398193
Validation loss: 2.019442150990168

Epoch: 141| Step: 0
Training loss: 0.8690112829208374
Validation loss: 2.0490686694780984

Epoch: 5| Step: 1
Training loss: 1.1096585988998413
Validation loss: 2.0944310128688812

Epoch: 5| Step: 2
Training loss: 0.9186300039291382
Validation loss: 2.0241203159093857

Epoch: 5| Step: 3
Training loss: 0.6562784314155579
Validation loss: 2.0533742060263953

Epoch: 5| Step: 4
Training loss: 1.5666252374649048
Validation loss: 2.0142618070046105

Epoch: 5| Step: 5
Training loss: 0.48483332991600037
Validation loss: 1.9843071103096008

Epoch: 5| Step: 6
Training loss: 1.3802673816680908
Validation loss: 2.026873528957367

Epoch: 5| Step: 7
Training loss: 1.0792067050933838
Validation loss: 2.018572822213173

Epoch: 5| Step: 8
Training loss: 0.8404590487480164
Validation loss: 2.037531395753225

Epoch: 5| Step: 9
Training loss: 0.9829039573669434
Validation loss: 2.02303783595562

Epoch: 5| Step: 10
Training loss: 0.927228569984436
Validation loss: 2.070865402619044

Epoch: 5| Step: 11
Training loss: 0.8633756041526794
Validation loss: 2.0721340825160346

Epoch: 142| Step: 0
Training loss: 0.9794011116027832
Validation loss: 2.09457761545976

Epoch: 5| Step: 1
Training loss: 1.085052251815796
Validation loss: 2.1533749451239905

Epoch: 5| Step: 2
Training loss: 0.9608492851257324
Validation loss: 2.1325153509775796

Epoch: 5| Step: 3
Training loss: 0.7072508931159973
Validation loss: 2.077285279830297

Epoch: 5| Step: 4
Training loss: 0.8326576948165894
Validation loss: 2.0700417955716452

Epoch: 5| Step: 5
Training loss: 0.8436848521232605
Validation loss: 2.0235382268826165

Epoch: 5| Step: 6
Training loss: 0.9536064863204956
Validation loss: 2.039159898956617

Epoch: 5| Step: 7
Training loss: 1.1271759271621704
Validation loss: 2.0221606691678367

Epoch: 5| Step: 8
Training loss: 1.2251954078674316
Validation loss: 2.031203786532084

Epoch: 5| Step: 9
Training loss: 1.186376929283142
Validation loss: 2.0522714108228683

Epoch: 5| Step: 10
Training loss: 1.07826828956604
Validation loss: 2.1179193506638208

Epoch: 5| Step: 11
Training loss: 1.2438387870788574
Validation loss: 2.121075322230657

Epoch: 143| Step: 0
Training loss: 1.045854926109314
Validation loss: 2.060489376386007

Epoch: 5| Step: 1
Training loss: 1.174531102180481
Validation loss: 2.077652891476949

Epoch: 5| Step: 2
Training loss: 1.1310065984725952
Validation loss: 2.0107140839099884

Epoch: 5| Step: 3
Training loss: 0.7670506238937378
Validation loss: 2.0431445986032486

Epoch: 5| Step: 4
Training loss: 0.6062421798706055
Validation loss: 2.073088750243187

Epoch: 5| Step: 5
Training loss: 1.2281982898712158
Validation loss: 2.0455001244942346

Epoch: 5| Step: 6
Training loss: 0.8001667857170105
Validation loss: 2.0495478262503943

Epoch: 5| Step: 7
Training loss: 0.9750421643257141
Validation loss: 2.0806715885798135

Epoch: 5| Step: 8
Training loss: 0.7451983690261841
Validation loss: 2.060409516096115

Epoch: 5| Step: 9
Training loss: 0.4839819073677063
Validation loss: 2.1146056999762854

Epoch: 5| Step: 10
Training loss: 1.3006298542022705
Validation loss: 2.0850964784622192

Epoch: 5| Step: 11
Training loss: 2.304633617401123
Validation loss: 2.06556698679924

Epoch: 144| Step: 0
Training loss: 1.1549866199493408
Validation loss: 2.011869415640831

Epoch: 5| Step: 1
Training loss: 0.7665305733680725
Validation loss: 2.1164305359125137

Epoch: 5| Step: 2
Training loss: 1.084476113319397
Validation loss: 2.1100613673528037

Epoch: 5| Step: 3
Training loss: 1.0557957887649536
Validation loss: 2.115795527895292

Epoch: 5| Step: 4
Training loss: 0.6767252087593079
Validation loss: 2.101581484079361

Epoch: 5| Step: 5
Training loss: 0.850781261920929
Validation loss: 2.051139160990715

Epoch: 5| Step: 6
Training loss: 1.1145024299621582
Validation loss: 2.029177432258924

Epoch: 5| Step: 7
Training loss: 0.6925432682037354
Validation loss: 2.0226856569449105

Epoch: 5| Step: 8
Training loss: 1.2976096868515015
Validation loss: 1.9967933893203735

Epoch: 5| Step: 9
Training loss: 0.682756245136261
Validation loss: 2.0377625226974487

Epoch: 5| Step: 10
Training loss: 1.086841344833374
Validation loss: 2.0235009094079337

Epoch: 5| Step: 11
Training loss: 0.748687744140625
Validation loss: 2.047556554277738

Epoch: 145| Step: 0
Training loss: 0.8650795221328735
Validation loss: 2.0581487814585366

Epoch: 5| Step: 1
Training loss: 0.7138577699661255
Validation loss: 2.1077109525601068

Epoch: 5| Step: 2
Training loss: 1.3642441034317017
Validation loss: 2.168258080879847

Epoch: 5| Step: 3
Training loss: 1.0754663944244385
Validation loss: 2.1502989729245505

Epoch: 5| Step: 4
Training loss: 0.7274243235588074
Validation loss: 2.1312018831570945

Epoch: 5| Step: 5
Training loss: 0.8552819490432739
Validation loss: 2.0812934090693793

Epoch: 5| Step: 6
Training loss: 0.5496733784675598
Validation loss: 2.0666658679644265

Epoch: 5| Step: 7
Training loss: 1.369250774383545
Validation loss: 2.096483771999677

Epoch: 5| Step: 8
Training loss: 0.8381038904190063
Validation loss: 2.0389354477326074

Epoch: 5| Step: 9
Training loss: 0.7419216632843018
Validation loss: 2.0408877432346344

Epoch: 5| Step: 10
Training loss: 1.241858720779419
Validation loss: 2.032271866997083

Epoch: 5| Step: 11
Training loss: 0.4245007038116455
Validation loss: 1.9885940899451573

Epoch: 146| Step: 0
Training loss: 0.8286922574043274
Validation loss: 1.957631419102351

Epoch: 5| Step: 1
Training loss: 1.255590796470642
Validation loss: 2.031195273001989

Epoch: 5| Step: 2
Training loss: 0.8285053372383118
Validation loss: 2.0235255459944406

Epoch: 5| Step: 3
Training loss: 0.8580244183540344
Validation loss: 2.0434716741243997

Epoch: 5| Step: 4
Training loss: 0.5306673049926758
Validation loss: 2.098698854446411

Epoch: 5| Step: 5
Training loss: 1.1155939102172852
Validation loss: 2.076922337214152

Epoch: 5| Step: 6
Training loss: 1.0186210870742798
Validation loss: 2.0383088439702988

Epoch: 5| Step: 7
Training loss: 1.1191561222076416
Validation loss: 2.056273266673088

Epoch: 5| Step: 8
Training loss: 0.7201082706451416
Validation loss: 2.0636490086714425

Epoch: 5| Step: 9
Training loss: 1.4225870370864868
Validation loss: 1.981439878543218

Epoch: 5| Step: 10
Training loss: 0.8314365148544312
Validation loss: 1.9206643253564835

Epoch: 5| Step: 11
Training loss: 1.7414164543151855
Validation loss: 1.9682179739077885

Epoch: 147| Step: 0
Training loss: 0.7416828870773315
Validation loss: 1.977842668692271

Epoch: 5| Step: 1
Training loss: 1.0238447189331055
Validation loss: 1.942945346236229

Epoch: 5| Step: 2
Training loss: 1.6733230352401733
Validation loss: 2.0063153256972632

Epoch: 5| Step: 3
Training loss: 0.614221453666687
Validation loss: 1.9924119214216869

Epoch: 5| Step: 4
Training loss: 0.6103512644767761
Validation loss: 2.006205305457115

Epoch: 5| Step: 5
Training loss: 0.8875441551208496
Validation loss: 2.0247555573781333

Epoch: 5| Step: 6
Training loss: 1.2253458499908447
Validation loss: 2.0265985131263733

Epoch: 5| Step: 7
Training loss: 0.4641450345516205
Validation loss: 2.0331257780392966

Epoch: 5| Step: 8
Training loss: 0.4946652352809906
Validation loss: 1.981863444050153

Epoch: 5| Step: 9
Training loss: 1.293007493019104
Validation loss: 2.0459722777207694

Epoch: 5| Step: 10
Training loss: 0.9943197965621948
Validation loss: 2.077236771583557

Epoch: 5| Step: 11
Training loss: 0.34263384342193604
Validation loss: 1.9914151430130005

Epoch: 148| Step: 0
Training loss: 0.9635434150695801
Validation loss: 1.9823040862878163

Epoch: 5| Step: 1
Training loss: 1.0642035007476807
Validation loss: 1.9995397080977757

Epoch: 5| Step: 2
Training loss: 1.0629922151565552
Validation loss: 1.9630120148261387

Epoch: 5| Step: 3
Training loss: 1.1964805126190186
Validation loss: 2.0180680602788925

Epoch: 5| Step: 4
Training loss: 0.7853944897651672
Validation loss: 2.0291923880577087

Epoch: 5| Step: 5
Training loss: 0.9452810287475586
Validation loss: 2.069484238823255

Epoch: 5| Step: 6
Training loss: 0.8361775279045105
Validation loss: 2.1075027038653693

Epoch: 5| Step: 7
Training loss: 0.6285359263420105
Validation loss: 2.1046932339668274

Epoch: 5| Step: 8
Training loss: 1.607029914855957
Validation loss: 2.1190663228432336

Epoch: 5| Step: 9
Training loss: 0.713437557220459
Validation loss: 2.0523036420345306

Epoch: 5| Step: 10
Training loss: 0.5412901043891907
Validation loss: 2.0965435206890106

Epoch: 5| Step: 11
Training loss: 1.7648543119430542
Validation loss: 2.0549543301264444

Epoch: 149| Step: 0
Training loss: 1.0298120975494385
Validation loss: 2.0263253251711526

Epoch: 5| Step: 1
Training loss: 1.194120168685913
Validation loss: 2.054280564188957

Epoch: 5| Step: 2
Training loss: 0.8657737970352173
Validation loss: 2.0481925904750824

Epoch: 5| Step: 3
Training loss: 0.6921639442443848
Validation loss: 2.042189752062162

Epoch: 5| Step: 4
Training loss: 0.995439350605011
Validation loss: 2.052990516026815

Epoch: 5| Step: 5
Training loss: 0.9002161026000977
Validation loss: 2.059414198001226

Epoch: 5| Step: 6
Training loss: 1.1248136758804321
Validation loss: 2.1048925817012787

Epoch: 5| Step: 7
Training loss: 0.7961798906326294
Validation loss: 2.096312945087751

Epoch: 5| Step: 8
Training loss: 1.251557469367981
Validation loss: 2.069484993815422

Epoch: 5| Step: 9
Training loss: 0.7557124495506287
Validation loss: 2.1092230528593063

Epoch: 5| Step: 10
Training loss: 0.576240599155426
Validation loss: 2.0358007152875266

Epoch: 5| Step: 11
Training loss: 0.4323234558105469
Validation loss: 2.0428960422674813

Epoch: 150| Step: 0
Training loss: 0.6929125785827637
Validation loss: 2.006801337003708

Epoch: 5| Step: 1
Training loss: 0.6629144549369812
Validation loss: 2.085426246126493

Epoch: 5| Step: 2
Training loss: 0.7640094757080078
Validation loss: 2.0647770315408707

Epoch: 5| Step: 3
Training loss: 0.6579369306564331
Validation loss: 2.1331494549910226

Epoch: 5| Step: 4
Training loss: 1.324486494064331
Validation loss: 2.070366462071737

Epoch: 5| Step: 5
Training loss: 1.0241425037384033
Validation loss: 2.0926759193340936

Epoch: 5| Step: 6
Training loss: 1.2753548622131348
Validation loss: 2.077912305792173

Epoch: 5| Step: 7
Training loss: 0.7815699577331543
Validation loss: 2.0784769654273987

Epoch: 5| Step: 8
Training loss: 0.565167248249054
Validation loss: 2.0332076648871102

Epoch: 5| Step: 9
Training loss: 1.0112165212631226
Validation loss: 2.0671416322390237

Epoch: 5| Step: 10
Training loss: 1.2017686367034912
Validation loss: 2.002431040008863

Epoch: 5| Step: 11
Training loss: 0.5775336027145386
Validation loss: 1.9810057679812114

Epoch: 151| Step: 0
Training loss: 0.7007797360420227
Validation loss: 2.032765671610832

Epoch: 5| Step: 1
Training loss: 0.7164468765258789
Validation loss: 2.0344462792078652

Epoch: 5| Step: 2
Training loss: 0.713710606098175
Validation loss: 2.025799716512362

Epoch: 5| Step: 3
Training loss: 0.9210255742073059
Validation loss: 2.052168687184652

Epoch: 5| Step: 4
Training loss: 1.0160343647003174
Validation loss: 2.045600727200508

Epoch: 5| Step: 5
Training loss: 0.8975362777709961
Validation loss: 2.060041973988215

Epoch: 5| Step: 6
Training loss: 0.9527700543403625
Validation loss: 2.0324543168147406

Epoch: 5| Step: 7
Training loss: 0.8220311403274536
Validation loss: 2.056669607758522

Epoch: 5| Step: 8
Training loss: 1.132830262184143
Validation loss: 2.0557036896546683

Epoch: 5| Step: 9
Training loss: 0.6105164289474487
Validation loss: 2.0607137233018875

Epoch: 5| Step: 10
Training loss: 1.058443307876587
Validation loss: 2.0196086963017783

Epoch: 5| Step: 11
Training loss: 1.809693694114685
Validation loss: 1.9942037761211395

Epoch: 152| Step: 0
Training loss: 1.2036956548690796
Validation loss: 2.0675073017676673

Epoch: 5| Step: 1
Training loss: 0.837145209312439
Validation loss: 2.0175326416889825

Epoch: 5| Step: 2
Training loss: 1.1406196355819702
Validation loss: 2.095912456512451

Epoch: 5| Step: 3
Training loss: 0.6360956430435181
Validation loss: 2.013143022855123

Epoch: 5| Step: 4
Training loss: 0.787720263004303
Validation loss: 1.9898363947868347

Epoch: 5| Step: 5
Training loss: 0.6847438216209412
Validation loss: 2.0547453264395394

Epoch: 5| Step: 6
Training loss: 1.3730756044387817
Validation loss: 1.9987102250258129

Epoch: 5| Step: 7
Training loss: 0.8860006332397461
Validation loss: 2.007789591948191

Epoch: 5| Step: 8
Training loss: 0.8531684875488281
Validation loss: 1.9612949391206105

Epoch: 5| Step: 9
Training loss: 0.5427612662315369
Validation loss: 2.034205973148346

Epoch: 5| Step: 10
Training loss: 0.7988818287849426
Validation loss: 2.0709169109662375

Epoch: 5| Step: 11
Training loss: 0.19666039943695068
Validation loss: 2.026822512348493

Epoch: 153| Step: 0
Training loss: 1.0144771337509155
Validation loss: 2.0293612480163574

Epoch: 5| Step: 1
Training loss: 0.7752219438552856
Validation loss: 1.9839023848374684

Epoch: 5| Step: 2
Training loss: 1.035160779953003
Validation loss: 2.022656947374344

Epoch: 5| Step: 3
Training loss: 0.95623779296875
Validation loss: 1.9742000500361125

Epoch: 5| Step: 4
Training loss: 0.8388087153434753
Validation loss: 2.030843729774157

Epoch: 5| Step: 5
Training loss: 0.9634626507759094
Validation loss: 1.99885293841362

Epoch: 5| Step: 6
Training loss: 0.6385067701339722
Validation loss: 2.047909508148829

Epoch: 5| Step: 7
Training loss: 1.045215368270874
Validation loss: 2.103245422244072

Epoch: 5| Step: 8
Training loss: 0.9835724830627441
Validation loss: 2.1193481236696243

Epoch: 5| Step: 9
Training loss: 0.8942897915840149
Validation loss: 2.125982145468394

Epoch: 5| Step: 10
Training loss: 0.9457340240478516
Validation loss: 2.121140201886495

Epoch: 5| Step: 11
Training loss: 1.0687854290008545
Validation loss: 2.1222890665133796

Epoch: 154| Step: 0
Training loss: 0.7304919362068176
Validation loss: 2.092441047231356

Epoch: 5| Step: 1
Training loss: 0.8420788645744324
Validation loss: 2.0971767206986747

Epoch: 5| Step: 2
Training loss: 0.9671646952629089
Validation loss: 2.020543083548546

Epoch: 5| Step: 3
Training loss: 0.9418871998786926
Validation loss: 2.072665532430013

Epoch: 5| Step: 4
Training loss: 1.1653960943222046
Validation loss: 2.0653957376877465

Epoch: 5| Step: 5
Training loss: 0.853239893913269
Validation loss: 2.014317055543264

Epoch: 5| Step: 6
Training loss: 0.8124018907546997
Validation loss: 2.099614535768827

Epoch: 5| Step: 7
Training loss: 0.9213944673538208
Validation loss: 2.112755020459493

Epoch: 5| Step: 8
Training loss: 1.0472148656845093
Validation loss: 2.1046025454998016

Epoch: 5| Step: 9
Training loss: 0.9710897207260132
Validation loss: 2.092842827240626

Epoch: 5| Step: 10
Training loss: 0.5364225506782532
Validation loss: 2.028232862552007

Epoch: 5| Step: 11
Training loss: 0.28932905197143555
Validation loss: 2.01410149037838

Epoch: 155| Step: 0
Training loss: 0.7299314737319946
Validation loss: 2.0831127613782883

Epoch: 5| Step: 1
Training loss: 0.9323498010635376
Validation loss: 2.1182272136211395

Epoch: 5| Step: 2
Training loss: 1.198488473892212
Validation loss: 2.1339694062868753

Epoch: 5| Step: 3
Training loss: 0.8061183094978333
Validation loss: 2.1102522760629654

Epoch: 5| Step: 4
Training loss: 0.9039576649665833
Validation loss: 2.1067570547262826

Epoch: 5| Step: 5
Training loss: 0.6510512232780457
Validation loss: 2.0715823272864022

Epoch: 5| Step: 6
Training loss: 0.7273966670036316
Validation loss: 2.060349464416504

Epoch: 5| Step: 7
Training loss: 0.7849302291870117
Validation loss: 2.0922252535820007

Epoch: 5| Step: 8
Training loss: 1.2766056060791016
Validation loss: 2.0438450425863266

Epoch: 5| Step: 9
Training loss: 0.8964807391166687
Validation loss: 2.063317467768987

Epoch: 5| Step: 10
Training loss: 0.7950688004493713
Validation loss: 2.0368303805589676

Epoch: 5| Step: 11
Training loss: 0.2771645784378052
Validation loss: 2.0515956034262977

Epoch: 156| Step: 0
Training loss: 0.5213385820388794
Validation loss: 2.0648789405822754

Epoch: 5| Step: 1
Training loss: 1.1119314432144165
Validation loss: 1.9800265580415726

Epoch: 5| Step: 2
Training loss: 0.8533509969711304
Validation loss: 1.992561548948288

Epoch: 5| Step: 3
Training loss: 1.1508331298828125
Validation loss: 2.0129084388415017

Epoch: 5| Step: 4
Training loss: 1.0510985851287842
Validation loss: 2.037047122915586

Epoch: 5| Step: 5
Training loss: 0.9264186024665833
Validation loss: 2.1274601370096207

Epoch: 5| Step: 6
Training loss: 1.0350526571273804
Validation loss: 2.078448454538981

Epoch: 5| Step: 7
Training loss: 0.9399453997612
Validation loss: 2.173687845468521

Epoch: 5| Step: 8
Training loss: 0.8048790693283081
Validation loss: 2.0536374747753143

Epoch: 5| Step: 9
Training loss: 0.8753619194030762
Validation loss: 2.029425020019213

Epoch: 5| Step: 10
Training loss: 0.5265441536903381
Validation loss: 2.0160149335861206

Epoch: 5| Step: 11
Training loss: 2.033597230911255
Validation loss: 2.042513757944107

Epoch: 157| Step: 0
Training loss: 0.8369199633598328
Validation loss: 2.0182825922966003

Epoch: 5| Step: 1
Training loss: 0.6511582136154175
Validation loss: 2.0537534803152084

Epoch: 5| Step: 2
Training loss: 0.8347424268722534
Validation loss: 2.0246833811203637

Epoch: 5| Step: 3
Training loss: 0.6804825663566589
Validation loss: 2.076980327566465

Epoch: 5| Step: 4
Training loss: 0.8959605097770691
Validation loss: 2.1222502340873084

Epoch: 5| Step: 5
Training loss: 0.8327978849411011
Validation loss: 2.08881776034832

Epoch: 5| Step: 6
Training loss: 0.9018629789352417
Validation loss: 2.110149269302686

Epoch: 5| Step: 7
Training loss: 0.9470660090446472
Validation loss: 2.0698237816492715

Epoch: 5| Step: 8
Training loss: 0.8670727014541626
Validation loss: 2.071077694495519

Epoch: 5| Step: 9
Training loss: 0.8165912628173828
Validation loss: 2.0329482356707254

Epoch: 5| Step: 10
Training loss: 1.0911223888397217
Validation loss: 2.0448203086853027

Epoch: 5| Step: 11
Training loss: 1.2825134992599487
Validation loss: 2.007957696914673

Epoch: 158| Step: 0
Training loss: 0.7632371783256531
Validation loss: 2.038132111231486

Epoch: 5| Step: 1
Training loss: 0.7048670053482056
Validation loss: 2.0533812095721564

Epoch: 5| Step: 2
Training loss: 0.631636381149292
Validation loss: 2.0217661013205848

Epoch: 5| Step: 3
Training loss: 1.1686208248138428
Validation loss: 2.093923255801201

Epoch: 5| Step: 4
Training loss: 0.800011932849884
Validation loss: 2.082451273997625

Epoch: 5| Step: 5
Training loss: 0.6908982396125793
Validation loss: 2.1417928834756217

Epoch: 5| Step: 6
Training loss: 1.3399217128753662
Validation loss: 2.1407537758350372

Epoch: 5| Step: 7
Training loss: 0.7234018445014954
Validation loss: 2.0901403029759726

Epoch: 5| Step: 8
Training loss: 0.8843534588813782
Validation loss: 2.041540985306104

Epoch: 5| Step: 9
Training loss: 0.8420397639274597
Validation loss: 2.0070730447769165

Epoch: 5| Step: 10
Training loss: 1.023196816444397
Validation loss: 2.0518635908762612

Epoch: 5| Step: 11
Training loss: 0.5385774374008179
Validation loss: 2.044447054465612

Epoch: 159| Step: 0
Training loss: 0.8575679063796997
Validation loss: 2.1095700015624366

Epoch: 5| Step: 1
Training loss: 0.9638621211051941
Validation loss: 2.1378518640995026

Epoch: 5| Step: 2
Training loss: 0.9856050610542297
Validation loss: 2.1597429315249124

Epoch: 5| Step: 3
Training loss: 0.7813905477523804
Validation loss: 2.098236545920372

Epoch: 5| Step: 4
Training loss: 0.7840328216552734
Validation loss: 2.1309011528889337

Epoch: 5| Step: 5
Training loss: 0.5765301585197449
Validation loss: 2.047008534272512

Epoch: 5| Step: 6
Training loss: 0.7201734185218811
Validation loss: 2.041767100493113

Epoch: 5| Step: 7
Training loss: 1.1246904134750366
Validation loss: 2.0466972390810647

Epoch: 5| Step: 8
Training loss: 0.6635966300964355
Validation loss: 2.016515612602234

Epoch: 5| Step: 9
Training loss: 0.9140575528144836
Validation loss: 2.030593514442444

Epoch: 5| Step: 10
Training loss: 0.7715542912483215
Validation loss: 2.0816649297873178

Epoch: 5| Step: 11
Training loss: 0.9289841651916504
Validation loss: 2.0415771305561066

Epoch: 160| Step: 0
Training loss: 0.5214256048202515
Validation loss: 2.0316832760969796

Epoch: 5| Step: 1
Training loss: 0.7819117903709412
Validation loss: 2.1086656550566354

Epoch: 5| Step: 2
Training loss: 0.8607436418533325
Validation loss: 2.0525022149086

Epoch: 5| Step: 3
Training loss: 0.4249519407749176
Validation loss: 2.0658566852410636

Epoch: 5| Step: 4
Training loss: 1.2451527118682861
Validation loss: 2.0451213816801705

Epoch: 5| Step: 5
Training loss: 0.9573267698287964
Validation loss: 2.0834691474835076

Epoch: 5| Step: 6
Training loss: 1.3158618211746216
Validation loss: 2.082269534468651

Epoch: 5| Step: 7
Training loss: 0.7892810106277466
Validation loss: 2.047353073954582

Epoch: 5| Step: 8
Training loss: 0.8731161952018738
Validation loss: 2.0345895191033683

Epoch: 5| Step: 9
Training loss: 0.7504888772964478
Validation loss: 2.050128241380056

Epoch: 5| Step: 10
Training loss: 0.6585626602172852
Validation loss: 2.016113261381785

Epoch: 5| Step: 11
Training loss: 0.7081466913223267
Validation loss: 2.0838438173135123

Epoch: 161| Step: 0
Training loss: 0.9870752096176147
Validation loss: 2.0123667418956757

Epoch: 5| Step: 1
Training loss: 0.3834031820297241
Validation loss: 2.0588140040636063

Epoch: 5| Step: 2
Training loss: 1.473004937171936
Validation loss: 2.073313355445862

Epoch: 5| Step: 3
Training loss: 0.7618943452835083
Validation loss: 2.0176093131303787

Epoch: 5| Step: 4
Training loss: 1.0086493492126465
Validation loss: 2.1072113315264382

Epoch: 5| Step: 5
Training loss: 0.8504680395126343
Validation loss: 2.0488627006610236

Epoch: 5| Step: 6
Training loss: 0.7113586664199829
Validation loss: 2.020719518264135

Epoch: 5| Step: 7
Training loss: 0.7395383715629578
Validation loss: 2.01488604148229

Epoch: 5| Step: 8
Training loss: 0.8813811540603638
Validation loss: 1.9940071403980255

Epoch: 5| Step: 9
Training loss: 0.7291667461395264
Validation loss: 1.9837264567613602

Epoch: 5| Step: 10
Training loss: 0.5944233536720276
Validation loss: 2.0167111853758493

Epoch: 5| Step: 11
Training loss: 0.43462085723876953
Validation loss: 2.0456575651963553

Epoch: 162| Step: 0
Training loss: 0.6781708002090454
Validation loss: 2.032860333720843

Epoch: 5| Step: 1
Training loss: 0.6738362312316895
Validation loss: 2.056388000647227

Epoch: 5| Step: 2
Training loss: 1.08357572555542
Validation loss: 2.0263141145308814

Epoch: 5| Step: 3
Training loss: 0.6995476484298706
Validation loss: 1.9899622996648152

Epoch: 5| Step: 4
Training loss: 0.6279621124267578
Validation loss: 2.028205861647924

Epoch: 5| Step: 5
Training loss: 1.3795197010040283
Validation loss: 1.9847126255432765

Epoch: 5| Step: 6
Training loss: 0.7102229595184326
Validation loss: 2.0749943554401398

Epoch: 5| Step: 7
Training loss: 0.6412155628204346
Validation loss: 2.05756646891435

Epoch: 5| Step: 8
Training loss: 0.836530327796936
Validation loss: 2.0757565001646676

Epoch: 5| Step: 9
Training loss: 0.5279825925827026
Validation loss: 2.0697535624106727

Epoch: 5| Step: 10
Training loss: 0.6589639782905579
Validation loss: 2.0593916475772858

Epoch: 5| Step: 11
Training loss: 2.0615155696868896
Validation loss: 2.0750250220298767

Epoch: 163| Step: 0
Training loss: 0.5546067357063293
Validation loss: 2.0719443758328757

Epoch: 5| Step: 1
Training loss: 0.3421117663383484
Validation loss: 2.001500904560089

Epoch: 5| Step: 2
Training loss: 0.8044437170028687
Validation loss: 2.0387824376424155

Epoch: 5| Step: 3
Training loss: 1.0364482402801514
Validation loss: 2.0053069442510605

Epoch: 5| Step: 4
Training loss: 0.5734454393386841
Validation loss: 2.005473410089811

Epoch: 5| Step: 5
Training loss: 0.7399430274963379
Validation loss: 2.073269953330358

Epoch: 5| Step: 6
Training loss: 0.8037059903144836
Validation loss: 2.0546313325564065

Epoch: 5| Step: 7
Training loss: 0.8177682757377625
Validation loss: 2.121507316827774

Epoch: 5| Step: 8
Training loss: 1.4416208267211914
Validation loss: 2.1138839224974313

Epoch: 5| Step: 9
Training loss: 0.7595633268356323
Validation loss: 2.1301596264044442

Epoch: 5| Step: 10
Training loss: 0.971129298210144
Validation loss: 2.0806217243274054

Epoch: 5| Step: 11
Training loss: 1.1310089826583862
Validation loss: 2.0880405455827713

Epoch: 164| Step: 0
Training loss: 0.954583466053009
Validation loss: 2.0176611145337424

Epoch: 5| Step: 1
Training loss: 1.0647753477096558
Validation loss: 2.063331961631775

Epoch: 5| Step: 2
Training loss: 0.9688714742660522
Validation loss: 1.9977167298396428

Epoch: 5| Step: 3
Training loss: 0.69499671459198
Validation loss: 2.013945917288462

Epoch: 5| Step: 4
Training loss: 0.7473919987678528
Validation loss: 2.0392440458138785

Epoch: 5| Step: 5
Training loss: 0.5840370059013367
Validation loss: 2.1607500265041986

Epoch: 5| Step: 6
Training loss: 0.7580431699752808
Validation loss: 2.1079255739847818

Epoch: 5| Step: 7
Training loss: 0.7562700510025024
Validation loss: 2.147058909138044

Epoch: 5| Step: 8
Training loss: 0.9064787030220032
Validation loss: 2.1153201162815094

Epoch: 5| Step: 9
Training loss: 0.8962286114692688
Validation loss: 2.073116973042488

Epoch: 5| Step: 10
Training loss: 0.8212016820907593
Validation loss: 2.055915743112564

Epoch: 5| Step: 11
Training loss: 0.7929137945175171
Validation loss: 2.034177581469218

Epoch: 165| Step: 0
Training loss: 0.604022204875946
Validation loss: 2.110787515838941

Epoch: 5| Step: 1
Training loss: 0.5425841212272644
Validation loss: 2.0539527783791223

Epoch: 5| Step: 2
Training loss: 0.8187217712402344
Validation loss: 2.083255315820376

Epoch: 5| Step: 3
Training loss: 0.6193704605102539
Validation loss: 2.129876827200254

Epoch: 5| Step: 4
Training loss: 1.0735890865325928
Validation loss: 2.12803316116333

Epoch: 5| Step: 5
Training loss: 0.5418709516525269
Validation loss: 2.054894511898359

Epoch: 5| Step: 6
Training loss: 1.149458885192871
Validation loss: 2.06174307068189

Epoch: 5| Step: 7
Training loss: 0.5462936162948608
Validation loss: 2.0489846567312875

Epoch: 5| Step: 8
Training loss: 0.8174077868461609
Validation loss: 2.0346214522918067

Epoch: 5| Step: 9
Training loss: 1.0719096660614014
Validation loss: 2.060726583003998

Epoch: 5| Step: 10
Training loss: 0.8311125040054321
Validation loss: 2.0477663030227027

Epoch: 5| Step: 11
Training loss: 1.2758315801620483
Validation loss: 2.0632822463909783

Epoch: 166| Step: 0
Training loss: 0.868869423866272
Validation loss: 2.1701467633247375

Epoch: 5| Step: 1
Training loss: 0.7348129749298096
Validation loss: 2.080639988183975

Epoch: 5| Step: 2
Training loss: 0.8553813099861145
Validation loss: 2.0327747563521066

Epoch: 5| Step: 3
Training loss: 0.7844914197921753
Validation loss: 2.024449576934179

Epoch: 5| Step: 4
Training loss: 0.934435248374939
Validation loss: 2.0095103780428567

Epoch: 5| Step: 5
Training loss: 0.6844820976257324
Validation loss: 2.0341855734586716

Epoch: 5| Step: 6
Training loss: 0.614766001701355
Validation loss: 2.03930401802063

Epoch: 5| Step: 7
Training loss: 0.8741840124130249
Validation loss: 2.0534319827953973

Epoch: 5| Step: 8
Training loss: 1.0911128520965576
Validation loss: 2.1262107640504837

Epoch: 5| Step: 9
Training loss: 0.6546965837478638
Validation loss: 2.137667099634806

Epoch: 5| Step: 10
Training loss: 0.6494549512863159
Validation loss: 2.1562798569599786

Epoch: 5| Step: 11
Training loss: 0.30771076679229736
Validation loss: 2.1507397840420404

Epoch: 167| Step: 0
Training loss: 0.6579493284225464
Validation loss: 2.111788625518481

Epoch: 5| Step: 1
Training loss: 0.7151028513908386
Validation loss: 2.065957029660543

Epoch: 5| Step: 2
Training loss: 0.8076082468032837
Validation loss: 2.0687073171138763

Epoch: 5| Step: 3
Training loss: 0.8059016466140747
Validation loss: 2.0447148581345878

Epoch: 5| Step: 4
Training loss: 0.877299427986145
Validation loss: 2.0344365437825522

Epoch: 5| Step: 5
Training loss: 1.1861021518707275
Validation loss: 2.0860240111748376

Epoch: 5| Step: 6
Training loss: 0.8257462382316589
Validation loss: 2.058694218595823

Epoch: 5| Step: 7
Training loss: 0.7408415079116821
Validation loss: 2.0508512258529663

Epoch: 5| Step: 8
Training loss: 0.6170781254768372
Validation loss: 2.0720947782198587

Epoch: 5| Step: 9
Training loss: 0.7985003590583801
Validation loss: 2.082489167650541

Epoch: 5| Step: 10
Training loss: 0.7862321734428406
Validation loss: 2.146785100301107

Epoch: 5| Step: 11
Training loss: 0.11079725623130798
Validation loss: 2.123483528693517

Epoch: 168| Step: 0
Training loss: 1.3030356168746948
Validation loss: 2.097129210829735

Epoch: 5| Step: 1
Training loss: 0.7147812843322754
Validation loss: 2.031917984286944

Epoch: 5| Step: 2
Training loss: 1.081484079360962
Validation loss: 1.99687060713768

Epoch: 5| Step: 3
Training loss: 0.5777720212936401
Validation loss: 2.047816182176272

Epoch: 5| Step: 4
Training loss: 0.8000327348709106
Validation loss: 2.051364322503408

Epoch: 5| Step: 5
Training loss: 0.6730027198791504
Validation loss: 2.0663533061742783

Epoch: 5| Step: 6
Training loss: 0.6977449655532837
Validation loss: 2.0588469356298447

Epoch: 5| Step: 7
Training loss: 0.7120000123977661
Validation loss: 2.0812195936838784

Epoch: 5| Step: 8
Training loss: 0.3379858136177063
Validation loss: 2.112802346547445

Epoch: 5| Step: 9
Training loss: 0.6541474461555481
Validation loss: 2.1177608221769333

Epoch: 5| Step: 10
Training loss: 0.6438353657722473
Validation loss: 2.0787047495444617

Epoch: 5| Step: 11
Training loss: 1.3261234760284424
Validation loss: 2.0542270690202713

Epoch: 169| Step: 0
Training loss: 0.772574782371521
Validation loss: 2.0760810722907386

Epoch: 5| Step: 1
Training loss: 0.3714037835597992
Validation loss: 2.052276983857155

Epoch: 5| Step: 2
Training loss: 0.6438714861869812
Validation loss: 2.078869024912516

Epoch: 5| Step: 3
Training loss: 0.6703705787658691
Validation loss: 2.039863179127375

Epoch: 5| Step: 4
Training loss: 0.9263384938240051
Validation loss: 2.1506598045428595

Epoch: 5| Step: 5
Training loss: 0.8733140230178833
Validation loss: 2.1515084902445474

Epoch: 5| Step: 6
Training loss: 0.8378259539604187
Validation loss: 2.132377967238426

Epoch: 5| Step: 7
Training loss: 0.6425763964653015
Validation loss: 2.103440726796786

Epoch: 5| Step: 8
Training loss: 0.5570493936538696
Validation loss: 2.0695189187924066

Epoch: 5| Step: 9
Training loss: 0.8827936053276062
Validation loss: 2.0415428976217904

Epoch: 5| Step: 10
Training loss: 0.610228419303894
Validation loss: 2.041866640249888

Epoch: 5| Step: 11
Training loss: 3.173661708831787
Validation loss: 2.0297133127848306

Epoch: 170| Step: 0
Training loss: 0.6794427633285522
Validation loss: 2.0184366603692374

Epoch: 5| Step: 1
Training loss: 0.7787209749221802
Validation loss: 2.0167872409025827

Epoch: 5| Step: 2
Training loss: 0.9657663106918335
Validation loss: 2.0325655887524285

Epoch: 5| Step: 3
Training loss: 0.5647128224372864
Validation loss: 2.0615053673585257

Epoch: 5| Step: 4
Training loss: 0.49668484926223755
Validation loss: 2.052558660507202

Epoch: 5| Step: 5
Training loss: 1.0353540182113647
Validation loss: 2.0917700876792273

Epoch: 5| Step: 6
Training loss: 0.6086951494216919
Validation loss: 2.0722796569267907

Epoch: 5| Step: 7
Training loss: 0.4906724989414215
Validation loss: 2.0632551411787667

Epoch: 5| Step: 8
Training loss: 0.9399374723434448
Validation loss: 2.1044949938853583

Epoch: 5| Step: 9
Training loss: 1.196305513381958
Validation loss: 2.1185335914293923

Epoch: 5| Step: 10
Training loss: 0.5235625505447388
Validation loss: 2.092825412750244

Epoch: 5| Step: 11
Training loss: 0.6536938548088074
Validation loss: 2.0283157378435135

Epoch: 171| Step: 0
Training loss: 0.606275200843811
Validation loss: 1.9628977328538895

Epoch: 5| Step: 1
Training loss: 0.6249755024909973
Validation loss: 2.036935562888781

Epoch: 5| Step: 2
Training loss: 0.7226414680480957
Validation loss: 2.0426106800635657

Epoch: 5| Step: 3
Training loss: 0.8987577557563782
Validation loss: 2.0717350294192634

Epoch: 5| Step: 4
Training loss: 0.5770732760429382
Validation loss: 2.107808147867521

Epoch: 5| Step: 5
Training loss: 0.6030255556106567
Validation loss: 2.1813681224981942

Epoch: 5| Step: 6
Training loss: 1.1532669067382812
Validation loss: 2.1470172305901847

Epoch: 5| Step: 7
Training loss: 0.6620742082595825
Validation loss: 2.1142877340316772

Epoch: 5| Step: 8
Training loss: 1.0546519756317139
Validation loss: 2.119835997621218

Epoch: 5| Step: 9
Training loss: 0.8371078372001648
Validation loss: 2.09501218299071

Epoch: 5| Step: 10
Training loss: 0.6065898537635803
Validation loss: 2.0417126019795737

Epoch: 5| Step: 11
Training loss: 0.1708792746067047
Validation loss: 2.042698269089063

Epoch: 172| Step: 0
Training loss: 1.1715682744979858
Validation loss: 2.0630012303590775

Epoch: 5| Step: 1
Training loss: 0.4826257824897766
Validation loss: 2.044100026289622

Epoch: 5| Step: 2
Training loss: 0.954390823841095
Validation loss: 2.0804642339547477

Epoch: 5| Step: 3
Training loss: 0.7656905055046082
Validation loss: 2.078305830558141

Epoch: 5| Step: 4
Training loss: 0.5606310963630676
Validation loss: 2.1124507784843445

Epoch: 5| Step: 5
Training loss: 0.6215887665748596
Validation loss: 2.1112862527370453

Epoch: 5| Step: 6
Training loss: 0.9119220972061157
Validation loss: 2.12909243007501

Epoch: 5| Step: 7
Training loss: 0.44585856795310974
Validation loss: 2.103518525759379

Epoch: 5| Step: 8
Training loss: 0.8565189242362976
Validation loss: 2.1080260425806046

Epoch: 5| Step: 9
Training loss: 0.6641882658004761
Validation loss: 2.1026729742685952

Epoch: 5| Step: 10
Training loss: 0.6742780804634094
Validation loss: 2.0709397246440253

Epoch: 5| Step: 11
Training loss: 0.33200299739837646
Validation loss: 2.0775794188181558

Epoch: 173| Step: 0
Training loss: 0.8515275716781616
Validation loss: 2.052877018849055

Epoch: 5| Step: 1
Training loss: 0.7138057947158813
Validation loss: 2.018233930071195

Epoch: 5| Step: 2
Training loss: 0.36105647683143616
Validation loss: 2.0193961362044015

Epoch: 5| Step: 3
Training loss: 1.0687167644500732
Validation loss: 2.044878294070562

Epoch: 5| Step: 4
Training loss: 0.9957500696182251
Validation loss: 2.094068333506584

Epoch: 5| Step: 5
Training loss: 0.6307443976402283
Validation loss: 2.110706110795339

Epoch: 5| Step: 6
Training loss: 0.5644367337226868
Validation loss: 2.1036626746257148

Epoch: 5| Step: 7
Training loss: 0.9906657338142395
Validation loss: 2.10161791741848

Epoch: 5| Step: 8
Training loss: 0.766604483127594
Validation loss: 2.0442680567502975

Epoch: 5| Step: 9
Training loss: 0.7633828520774841
Validation loss: 2.031787320971489

Epoch: 5| Step: 10
Training loss: 0.7472522258758545
Validation loss: 2.016382952531179

Epoch: 5| Step: 11
Training loss: 0.5019120573997498
Validation loss: 2.0473971416552863

Epoch: 174| Step: 0
Training loss: 0.5796072483062744
Validation loss: 2.015856385231018

Epoch: 5| Step: 1
Training loss: 0.6649095416069031
Validation loss: 2.0454660256703696

Epoch: 5| Step: 2
Training loss: 0.5466155409812927
Validation loss: 2.0774086813131967

Epoch: 5| Step: 3
Training loss: 1.1511331796646118
Validation loss: 2.0705722173055015

Epoch: 5| Step: 4
Training loss: 0.6576495170593262
Validation loss: 2.0847563495238624

Epoch: 5| Step: 5
Training loss: 0.6536532640457153
Validation loss: 2.1230252335468927

Epoch: 5| Step: 6
Training loss: 0.8888967633247375
Validation loss: 2.080030078689257

Epoch: 5| Step: 7
Training loss: 0.673189640045166
Validation loss: 2.0299553871154785

Epoch: 5| Step: 8
Training loss: 0.400526762008667
Validation loss: 2.0669546922047934

Epoch: 5| Step: 9
Training loss: 0.5347244739532471
Validation loss: 2.001843179265658

Epoch: 5| Step: 10
Training loss: 1.1811985969543457
Validation loss: 2.038501729567846

Epoch: 5| Step: 11
Training loss: 0.19564765691757202
Validation loss: 2.068992296854655

Epoch: 175| Step: 0
Training loss: 0.6418169140815735
Validation loss: 2.0259560445944467

Epoch: 5| Step: 1
Training loss: 0.820347785949707
Validation loss: 2.0903797298669815

Epoch: 5| Step: 2
Training loss: 0.9555057287216187
Validation loss: 2.1124997039635978

Epoch: 5| Step: 3
Training loss: 0.7537180185317993
Validation loss: 2.1063893735408783

Epoch: 5| Step: 4
Training loss: 0.6230573654174805
Validation loss: 2.054655000567436

Epoch: 5| Step: 5
Training loss: 0.9209920167922974
Validation loss: 2.0733515173196793

Epoch: 5| Step: 6
Training loss: 0.8499729037284851
Validation loss: 2.0404429187377295

Epoch: 5| Step: 7
Training loss: 0.5392046570777893
Validation loss: 2.0595825910568237

Epoch: 5| Step: 8
Training loss: 0.6837400794029236
Validation loss: 2.044380078713099

Epoch: 5| Step: 9
Training loss: 0.4442117214202881
Validation loss: 2.0486060281594596

Epoch: 5| Step: 10
Training loss: 0.7106359004974365
Validation loss: 2.1010910123586655

Epoch: 5| Step: 11
Training loss: 1.0653835535049438
Validation loss: 2.04690974454085

Epoch: 176| Step: 0
Training loss: 0.7246464490890503
Validation loss: 2.122966239849726

Epoch: 5| Step: 1
Training loss: 0.8122803568840027
Validation loss: 2.132992992798487

Epoch: 5| Step: 2
Training loss: 0.4432293772697449
Validation loss: 2.116662005583445

Epoch: 5| Step: 3
Training loss: 0.7668805122375488
Validation loss: 2.0663670202096305

Epoch: 5| Step: 4
Training loss: 0.728606104850769
Validation loss: 2.068011298775673

Epoch: 5| Step: 5
Training loss: 0.7027449607849121
Validation loss: 1.9848110377788544

Epoch: 5| Step: 6
Training loss: 0.8162258267402649
Validation loss: 2.025608072678248

Epoch: 5| Step: 7
Training loss: 0.7386533617973328
Validation loss: 2.0344962030649185

Epoch: 5| Step: 8
Training loss: 0.7068732380867004
Validation loss: 2.0939673086007438

Epoch: 5| Step: 9
Training loss: 0.7553200721740723
Validation loss: 2.1488419671853385

Epoch: 5| Step: 10
Training loss: 0.7938796877861023
Validation loss: 2.1802863528331122

Epoch: 5| Step: 11
Training loss: 0.9781748652458191
Validation loss: 2.1541393597920737

Epoch: 177| Step: 0
Training loss: 0.5711313486099243
Validation loss: 2.0929201344648996

Epoch: 5| Step: 1
Training loss: 0.5539653897285461
Validation loss: 2.091584508617719

Epoch: 5| Step: 2
Training loss: 0.6427898406982422
Validation loss: 2.0629937797784805

Epoch: 5| Step: 3
Training loss: 0.850030243396759
Validation loss: 2.0231544027725854

Epoch: 5| Step: 4
Training loss: 0.8741042017936707
Validation loss: 1.991018404563268

Epoch: 5| Step: 5
Training loss: 0.8794310688972473
Validation loss: 1.9832045237223308

Epoch: 5| Step: 6
Training loss: 0.8050925135612488
Validation loss: 2.0320433229207993

Epoch: 5| Step: 7
Training loss: 1.0295053720474243
Validation loss: 2.1153532713651657

Epoch: 5| Step: 8
Training loss: 0.7974075078964233
Validation loss: 2.0420304934183755

Epoch: 5| Step: 9
Training loss: 0.5496048331260681
Validation loss: 2.1653442879517875

Epoch: 5| Step: 10
Training loss: 1.164374589920044
Validation loss: 2.191533923149109

Epoch: 5| Step: 11
Training loss: 0.7686259150505066
Validation loss: 2.135321249564489

Epoch: 178| Step: 0
Training loss: 0.8654043078422546
Validation loss: 2.1221350183089576

Epoch: 5| Step: 1
Training loss: 0.648080050945282
Validation loss: 2.051392341653506

Epoch: 5| Step: 2
Training loss: 0.5510037541389465
Validation loss: 2.0704446335633597

Epoch: 5| Step: 3
Training loss: 0.5012682676315308
Validation loss: 2.0272950877745948

Epoch: 5| Step: 4
Training loss: 0.7235106825828552
Validation loss: 2.007951373855273

Epoch: 5| Step: 5
Training loss: 0.9408210515975952
Validation loss: 2.0289610624313354

Epoch: 5| Step: 6
Training loss: 0.49109211564064026
Validation loss: 2.0968614568312964

Epoch: 5| Step: 7
Training loss: 0.5972038507461548
Validation loss: 2.0419280429681144

Epoch: 5| Step: 8
Training loss: 0.868759274482727
Validation loss: 2.077482064565023

Epoch: 5| Step: 9
Training loss: 0.7256803512573242
Validation loss: 2.1416113475958505

Epoch: 5| Step: 10
Training loss: 0.8404310345649719
Validation loss: 2.139402170976003

Epoch: 5| Step: 11
Training loss: 0.29847562313079834
Validation loss: 2.187060405810674

Epoch: 179| Step: 0
Training loss: 1.0956199169158936
Validation loss: 2.1163089722394943

Epoch: 5| Step: 1
Training loss: 0.8339725732803345
Validation loss: 2.072134325901667

Epoch: 5| Step: 2
Training loss: 0.8902498483657837
Validation loss: 2.051405429840088

Epoch: 5| Step: 3
Training loss: 0.48248186707496643
Validation loss: 2.0868057161569595

Epoch: 5| Step: 4
Training loss: 0.3569132685661316
Validation loss: 2.1018570164839425

Epoch: 5| Step: 5
Training loss: 0.3165559768676758
Validation loss: 2.0522350519895554

Epoch: 5| Step: 6
Training loss: 0.8763057589530945
Validation loss: 2.0743078688780465

Epoch: 5| Step: 7
Training loss: 0.6675165891647339
Validation loss: 2.091241712371508

Epoch: 5| Step: 8
Training loss: 0.4610075056552887
Validation loss: 2.1051023503144584

Epoch: 5| Step: 9
Training loss: 0.7981556057929993
Validation loss: 2.1249526143074036

Epoch: 5| Step: 10
Training loss: 0.5735873579978943
Validation loss: 2.081426387031873

Epoch: 5| Step: 11
Training loss: 0.8977066874504089
Validation loss: 2.0266824762026467

Epoch: 180| Step: 0
Training loss: 0.5820804238319397
Validation loss: 2.10077832142512

Epoch: 5| Step: 1
Training loss: 0.8332117795944214
Validation loss: 2.0999200691779456

Epoch: 5| Step: 2
Training loss: 1.1449159383773804
Validation loss: 2.0947279880444207

Epoch: 5| Step: 3
Training loss: 0.7427035570144653
Validation loss: 2.1027982234954834

Epoch: 5| Step: 4
Training loss: 0.659145176410675
Validation loss: 2.081432953476906

Epoch: 5| Step: 5
Training loss: 0.2903037667274475
Validation loss: 2.0374386509259543

Epoch: 5| Step: 6
Training loss: 0.41644614934921265
Validation loss: 2.1624742299318314

Epoch: 5| Step: 7
Training loss: 0.6168593764305115
Validation loss: 2.1112988541523614

Epoch: 5| Step: 8
Training loss: 0.6189797520637512
Validation loss: 2.102825785676638

Epoch: 5| Step: 9
Training loss: 0.7810370326042175
Validation loss: 2.029998073975245

Epoch: 5| Step: 10
Training loss: 0.7944045662879944
Validation loss: 2.04603219528993

Epoch: 5| Step: 11
Training loss: 0.8667499423027039
Validation loss: 2.051367943485578

Epoch: 181| Step: 0
Training loss: 0.45201605558395386
Validation loss: 2.085699831446012

Epoch: 5| Step: 1
Training loss: 0.9082058668136597
Validation loss: 2.120169058442116

Epoch: 5| Step: 2
Training loss: 0.7191786170005798
Validation loss: 2.131862292687098

Epoch: 5| Step: 3
Training loss: 0.6393500566482544
Validation loss: 2.1492871145407357

Epoch: 5| Step: 4
Training loss: 0.8553068041801453
Validation loss: 2.092624674240748

Epoch: 5| Step: 5
Training loss: 0.6527355909347534
Validation loss: 2.107056458791097

Epoch: 5| Step: 6
Training loss: 0.577467143535614
Validation loss: 2.0482612599929175

Epoch: 5| Step: 7
Training loss: 0.7861119508743286
Validation loss: 2.07526504000028

Epoch: 5| Step: 8
Training loss: 1.0184292793273926
Validation loss: 2.064359520872434

Epoch: 5| Step: 9
Training loss: 0.4826507568359375
Validation loss: 2.0679239680369697

Epoch: 5| Step: 10
Training loss: 0.4649774432182312
Validation loss: 2.031233380238215

Epoch: 5| Step: 11
Training loss: 0.5726020336151123
Validation loss: 2.0821010023355484

Epoch: 182| Step: 0
Training loss: 0.422384649515152
Validation loss: 2.05294431746006

Epoch: 5| Step: 1
Training loss: 0.835254967212677
Validation loss: 2.1211197674274445

Epoch: 5| Step: 2
Training loss: 0.6220505237579346
Validation loss: 2.145825872818629

Epoch: 5| Step: 3
Training loss: 0.7004191279411316
Validation loss: 2.0851206878821054

Epoch: 5| Step: 4
Training loss: 0.6304649114608765
Validation loss: 2.078004370133082

Epoch: 5| Step: 5
Training loss: 0.6157741546630859
Validation loss: 2.10189921160539

Epoch: 5| Step: 6
Training loss: 0.580705463886261
Validation loss: 2.037098988890648

Epoch: 5| Step: 7
Training loss: 0.9869073033332825
Validation loss: 2.038918286561966

Epoch: 5| Step: 8
Training loss: 0.8654192090034485
Validation loss: 2.0247193376223245

Epoch: 5| Step: 9
Training loss: 0.2891046404838562
Validation loss: 2.0560716539621353

Epoch: 5| Step: 10
Training loss: 0.7878371477127075
Validation loss: 2.067296713590622

Epoch: 5| Step: 11
Training loss: 0.12023234367370605
Validation loss: 2.0587549209594727

Epoch: 183| Step: 0
Training loss: 0.9924152493476868
Validation loss: 2.0368026345968246

Epoch: 5| Step: 1
Training loss: 0.7276987433433533
Validation loss: 2.076387951771418

Epoch: 5| Step: 2
Training loss: 0.7060525417327881
Validation loss: 2.0922839691241584

Epoch: 5| Step: 3
Training loss: 0.38576942682266235
Validation loss: 2.1091035703818

Epoch: 5| Step: 4
Training loss: 0.7289184331893921
Validation loss: 2.045856162905693

Epoch: 5| Step: 5
Training loss: 0.8203588724136353
Validation loss: 2.0232947965463004

Epoch: 5| Step: 6
Training loss: 0.9437874555587769
Validation loss: 2.064858302474022

Epoch: 5| Step: 7
Training loss: 0.5928678512573242
Validation loss: 2.0698424180348716

Epoch: 5| Step: 8
Training loss: 0.4770437180995941
Validation loss: 2.08437646428744

Epoch: 5| Step: 9
Training loss: 0.5005659461021423
Validation loss: 2.021090259154638

Epoch: 5| Step: 10
Training loss: 0.5679560899734497
Validation loss: 2.074223428964615

Epoch: 5| Step: 11
Training loss: 0.8350926041603088
Validation loss: 2.0930296381314597

Epoch: 184| Step: 0
Training loss: 0.36847957968711853
Validation loss: 2.0871578007936478

Epoch: 5| Step: 1
Training loss: 0.6847378015518188
Validation loss: 2.1141132911046348

Epoch: 5| Step: 2
Training loss: 0.7369199991226196
Validation loss: 2.1218203554550805

Epoch: 5| Step: 3
Training loss: 0.7242633104324341
Validation loss: 2.12276054918766

Epoch: 5| Step: 4
Training loss: 0.7190583348274231
Validation loss: 2.0848691910505295

Epoch: 5| Step: 5
Training loss: 0.4737067222595215
Validation loss: 2.0938668499390283

Epoch: 5| Step: 6
Training loss: 0.7510538697242737
Validation loss: 2.0945076793432236

Epoch: 5| Step: 7
Training loss: 0.8445531725883484
Validation loss: 2.0927594800790152

Epoch: 5| Step: 8
Training loss: 0.7107780575752258
Validation loss: 2.051878516872724

Epoch: 5| Step: 9
Training loss: 0.39676716923713684
Validation loss: 2.124358852704366

Epoch: 5| Step: 10
Training loss: 0.43745845556259155
Validation loss: 2.099210868279139

Epoch: 5| Step: 11
Training loss: 0.6400066614151001
Validation loss: 2.122540240486463

Epoch: 185| Step: 0
Training loss: 0.7836631536483765
Validation loss: 2.1019338915745416

Epoch: 5| Step: 1
Training loss: 0.35693320631980896
Validation loss: 2.106762543320656

Epoch: 5| Step: 2
Training loss: 0.4629397392272949
Validation loss: 2.0783322155475616

Epoch: 5| Step: 3
Training loss: 0.9652317762374878
Validation loss: 2.0684214929739633

Epoch: 5| Step: 4
Training loss: 1.1646487712860107
Validation loss: 2.106343458096186

Epoch: 5| Step: 5
Training loss: 0.47101959586143494
Validation loss: 2.136178026596705

Epoch: 5| Step: 6
Training loss: 0.5344632863998413
Validation loss: 2.12551041940848

Epoch: 5| Step: 7
Training loss: 0.7046698331832886
Validation loss: 2.0884238481521606

Epoch: 5| Step: 8
Training loss: 0.4682200849056244
Validation loss: 2.0767651349306107

Epoch: 5| Step: 9
Training loss: 0.6375944018363953
Validation loss: 2.0249923318624496

Epoch: 5| Step: 10
Training loss: 0.7286643981933594
Validation loss: 2.028998469312986

Epoch: 5| Step: 11
Training loss: 0.38578110933303833
Validation loss: 2.0314825971921286

Epoch: 186| Step: 0
Training loss: 0.7713936567306519
Validation loss: 2.009512613217036

Epoch: 5| Step: 1
Training loss: 0.6555290818214417
Validation loss: 2.048967331647873

Epoch: 5| Step: 2
Training loss: 0.6133482456207275
Validation loss: 2.1104689041773477

Epoch: 5| Step: 3
Training loss: 0.6136766672134399
Validation loss: 2.082901895046234

Epoch: 5| Step: 4
Training loss: 0.7748373746871948
Validation loss: 2.111872653166453

Epoch: 5| Step: 5
Training loss: 0.3234108090400696
Validation loss: 2.1198702603578568

Epoch: 5| Step: 6
Training loss: 0.6451378464698792
Validation loss: 2.0900223354498544

Epoch: 5| Step: 7
Training loss: 0.5411263108253479
Validation loss: 2.0543461988369622

Epoch: 5| Step: 8
Training loss: 0.7403541803359985
Validation loss: 2.0390750964482627

Epoch: 5| Step: 9
Training loss: 0.517184317111969
Validation loss: 2.037246808409691

Epoch: 5| Step: 10
Training loss: 1.1152758598327637
Validation loss: 2.0333575904369354

Epoch: 5| Step: 11
Training loss: 0.7461349964141846
Validation loss: 2.0446448673804603

Epoch: 187| Step: 0
Training loss: 0.5907927751541138
Validation loss: 2.0844670484463372

Epoch: 5| Step: 1
Training loss: 0.5433864593505859
Validation loss: 2.1143019994099936

Epoch: 5| Step: 2
Training loss: 1.070720911026001
Validation loss: 2.157128930091858

Epoch: 5| Step: 3
Training loss: 0.5842455625534058
Validation loss: 2.122826407353083

Epoch: 5| Step: 4
Training loss: 0.3365137577056885
Validation loss: 2.111698349316915

Epoch: 5| Step: 5
Training loss: 0.5274560451507568
Validation loss: 2.104409654935201

Epoch: 5| Step: 6
Training loss: 1.2465177774429321
Validation loss: 2.0623078296581903

Epoch: 5| Step: 7
Training loss: 0.7650420069694519
Validation loss: 2.0512254188458123

Epoch: 5| Step: 8
Training loss: 0.6865532398223877
Validation loss: 2.0446165949106216

Epoch: 5| Step: 9
Training loss: 0.5763884782791138
Validation loss: 2.061183755596479

Epoch: 5| Step: 10
Training loss: 0.655572235584259
Validation loss: 2.1215833673874536

Epoch: 5| Step: 11
Training loss: 0.653698742389679
Validation loss: 2.123660792907079

Epoch: 188| Step: 0
Training loss: 0.5008814930915833
Validation loss: 2.0580225040515265

Epoch: 5| Step: 1
Training loss: 1.0201213359832764
Validation loss: 2.159671902656555

Epoch: 5| Step: 2
Training loss: 0.7768272161483765
Validation loss: 2.120933766166369

Epoch: 5| Step: 3
Training loss: 0.5716303586959839
Validation loss: 2.0928644289573035

Epoch: 5| Step: 4
Training loss: 0.7412164807319641
Validation loss: 2.0240742564201355

Epoch: 5| Step: 5
Training loss: 0.4821358621120453
Validation loss: 2.061323657631874

Epoch: 5| Step: 6
Training loss: 0.7536327838897705
Validation loss: 2.032589385906855

Epoch: 5| Step: 7
Training loss: 0.6537027955055237
Validation loss: 2.065760354200999

Epoch: 5| Step: 8
Training loss: 0.7060529589653015
Validation loss: 2.0970352490743003

Epoch: 5| Step: 9
Training loss: 0.7257707118988037
Validation loss: 2.1140469113985696

Epoch: 5| Step: 10
Training loss: 0.6914081573486328
Validation loss: 2.1308135191599527

Epoch: 5| Step: 11
Training loss: 0.6276654005050659
Validation loss: 2.1713716139396033

Epoch: 189| Step: 0
Training loss: 0.5447778701782227
Validation loss: 2.12264646589756

Epoch: 5| Step: 1
Training loss: 0.6009843945503235
Validation loss: 2.1426651924848557

Epoch: 5| Step: 2
Training loss: 0.3468441665172577
Validation loss: 2.067060649394989

Epoch: 5| Step: 3
Training loss: 0.7555543780326843
Validation loss: 2.068318466345469

Epoch: 5| Step: 4
Training loss: 0.8275452852249146
Validation loss: 2.0512698541084924

Epoch: 5| Step: 5
Training loss: 0.8444290161132812
Validation loss: 2.0717920859654746

Epoch: 5| Step: 6
Training loss: 0.6341472864151001
Validation loss: 2.0833582331736884

Epoch: 5| Step: 7
Training loss: 0.7549334764480591
Validation loss: 2.0292332619428635

Epoch: 5| Step: 8
Training loss: 0.670598566532135
Validation loss: 2.11647666990757

Epoch: 5| Step: 9
Training loss: 0.457462877035141
Validation loss: 2.0683484226465225

Epoch: 5| Step: 10
Training loss: 0.5750522613525391
Validation loss: 2.057582418123881

Epoch: 5| Step: 11
Training loss: 0.8395558595657349
Validation loss: 2.1057480623324714

Epoch: 190| Step: 0
Training loss: 0.45467057824134827
Validation loss: 2.0678945581118264

Epoch: 5| Step: 1
Training loss: 0.4186447560787201
Validation loss: 2.101690505941709

Epoch: 5| Step: 2
Training loss: 0.6610602140426636
Validation loss: 2.0275172144174576

Epoch: 5| Step: 3
Training loss: 0.9826798439025879
Validation loss: 2.047988146543503

Epoch: 5| Step: 4
Training loss: 0.5383367538452148
Validation loss: 2.050599694252014

Epoch: 5| Step: 5
Training loss: 0.606664776802063
Validation loss: 2.0443859001000724

Epoch: 5| Step: 6
Training loss: 0.7331193685531616
Validation loss: 2.085020199418068

Epoch: 5| Step: 7
Training loss: 0.6850446462631226
Validation loss: 2.0690927952528

Epoch: 5| Step: 8
Training loss: 0.5098320245742798
Validation loss: 2.0928817441066108

Epoch: 5| Step: 9
Training loss: 1.1469311714172363
Validation loss: 2.073170393705368

Epoch: 5| Step: 10
Training loss: 0.39067184925079346
Validation loss: 2.114850789308548

Epoch: 5| Step: 11
Training loss: 0.3580828905105591
Validation loss: 2.151738087336222

Epoch: 191| Step: 0
Training loss: 1.1393632888793945
Validation loss: 2.14086223145326

Epoch: 5| Step: 1
Training loss: 0.6220712661743164
Validation loss: 2.107727507750193

Epoch: 5| Step: 2
Training loss: 0.8757893443107605
Validation loss: 2.121409753958384

Epoch: 5| Step: 3
Training loss: 0.6853058338165283
Validation loss: 2.1086621582508087

Epoch: 5| Step: 4
Training loss: 0.5988509654998779
Validation loss: 2.029064585765203

Epoch: 5| Step: 5
Training loss: 0.717119574546814
Validation loss: 2.014027585585912

Epoch: 5| Step: 6
Training loss: 0.4918075203895569
Validation loss: 1.9942790667215984

Epoch: 5| Step: 7
Training loss: 0.761121392250061
Validation loss: 2.071971451242765

Epoch: 5| Step: 8
Training loss: 0.6468912363052368
Validation loss: 2.092431495587031

Epoch: 5| Step: 9
Training loss: 0.6597168445587158
Validation loss: 2.056681906183561

Epoch: 5| Step: 10
Training loss: 0.7192087173461914
Validation loss: 2.0868072509765625

Epoch: 5| Step: 11
Training loss: 0.7270931005477905
Validation loss: 2.0986812710762024

Epoch: 192| Step: 0
Training loss: 0.4612899720668793
Validation loss: 2.138571341832479

Epoch: 5| Step: 1
Training loss: 0.36090168356895447
Validation loss: 2.0933532416820526

Epoch: 5| Step: 2
Training loss: 0.8336723446846008
Validation loss: 2.036672751108805

Epoch: 5| Step: 3
Training loss: 0.8147051930427551
Validation loss: 2.062223792076111

Epoch: 5| Step: 4
Training loss: 0.6498817205429077
Validation loss: 1.9992964913447697

Epoch: 5| Step: 5
Training loss: 0.5957018136978149
Validation loss: 2.0527264724175134

Epoch: 5| Step: 6
Training loss: 0.5756931900978088
Validation loss: 2.055597652991613

Epoch: 5| Step: 7
Training loss: 0.6367290019989014
Validation loss: 2.0858020981152854

Epoch: 5| Step: 8
Training loss: 0.6573987007141113
Validation loss: 2.0958569049835205

Epoch: 5| Step: 9
Training loss: 0.645241379737854
Validation loss: 2.1420075396696725

Epoch: 5| Step: 10
Training loss: 0.6514977216720581
Validation loss: 2.147552231947581

Epoch: 5| Step: 11
Training loss: 0.947002649307251
Validation loss: 2.091198200980822

Epoch: 193| Step: 0
Training loss: 0.3568645417690277
Validation loss: 2.1250684509674707

Epoch: 5| Step: 1
Training loss: 0.8272289037704468
Validation loss: 2.0942823539177575

Epoch: 5| Step: 2
Training loss: 0.6493245363235474
Validation loss: 2.067761073509852

Epoch: 5| Step: 3
Training loss: 0.6593480110168457
Validation loss: 2.0645580838123956

Epoch: 5| Step: 4
Training loss: 0.6732364892959595
Validation loss: 2.0849498162666955

Epoch: 5| Step: 5
Training loss: 0.9953061938285828
Validation loss: 2.090083787838618

Epoch: 5| Step: 6
Training loss: 0.5236415863037109
Validation loss: 2.049839586019516

Epoch: 5| Step: 7
Training loss: 0.5146277546882629
Validation loss: 2.0632649461428323

Epoch: 5| Step: 8
Training loss: 0.6202033162117004
Validation loss: 2.081769978006681

Epoch: 5| Step: 9
Training loss: 0.5891546010971069
Validation loss: 2.047168438633283

Epoch: 5| Step: 10
Training loss: 0.5175021290779114
Validation loss: 2.1500233312447867

Epoch: 5| Step: 11
Training loss: 0.9724012017250061
Validation loss: 2.038152555624644

Epoch: 194| Step: 0
Training loss: 0.5687590837478638
Validation loss: 2.0895588944355645

Epoch: 5| Step: 1
Training loss: 0.6264345645904541
Validation loss: 2.0975685666004815

Epoch: 5| Step: 2
Training loss: 0.6659005880355835
Validation loss: 2.1078198701143265

Epoch: 5| Step: 3
Training loss: 0.6974848508834839
Validation loss: 2.0408586213986077

Epoch: 5| Step: 4
Training loss: 0.6751500964164734
Validation loss: 2.0577762772639594

Epoch: 5| Step: 5
Training loss: 0.5444543361663818
Validation loss: 2.1559587021668754

Epoch: 5| Step: 6
Training loss: 0.7172214388847351
Validation loss: 2.107852061589559

Epoch: 5| Step: 7
Training loss: 0.5233587026596069
Validation loss: 2.0814234415690103

Epoch: 5| Step: 8
Training loss: 0.5810450315475464
Validation loss: 2.048723260561625

Epoch: 5| Step: 9
Training loss: 0.4116676449775696
Validation loss: 2.117592841386795

Epoch: 5| Step: 10
Training loss: 0.8809383511543274
Validation loss: 2.0583068976799646

Epoch: 5| Step: 11
Training loss: 0.9251135587692261
Validation loss: 2.022103796402613

Epoch: 195| Step: 0
Training loss: 0.37478557229042053
Validation loss: 2.052024861176809

Epoch: 5| Step: 1
Training loss: 0.6427172422409058
Validation loss: 2.1322590162356696

Epoch: 5| Step: 2
Training loss: 0.5161280632019043
Validation loss: 2.125177393356959

Epoch: 5| Step: 3
Training loss: 0.8578656315803528
Validation loss: 2.091588651140531

Epoch: 5| Step: 4
Training loss: 1.0246522426605225
Validation loss: 2.1640584468841553

Epoch: 5| Step: 5
Training loss: 0.39575690031051636
Validation loss: 2.08513842523098

Epoch: 5| Step: 6
Training loss: 0.5190668106079102
Validation loss: 2.072919557491938

Epoch: 5| Step: 7
Training loss: 0.9874347448348999
Validation loss: 2.1004937986532846

Epoch: 5| Step: 8
Training loss: 0.6834934949874878
Validation loss: 2.039410258332888

Epoch: 5| Step: 9
Training loss: 0.7258742451667786
Validation loss: 2.0539028545220694

Epoch: 5| Step: 10
Training loss: 0.7068449258804321
Validation loss: 2.0793057878812156

Epoch: 5| Step: 11
Training loss: 0.2593148946762085
Validation loss: 2.0876087794701257

Epoch: 196| Step: 0
Training loss: 0.31559547781944275
Validation loss: 2.1551976054906845

Epoch: 5| Step: 1
Training loss: 0.6606243848800659
Validation loss: 2.2044441451629004

Epoch: 5| Step: 2
Training loss: 0.8436543345451355
Validation loss: 2.2592370907465615

Epoch: 5| Step: 3
Training loss: 0.9113801121711731
Validation loss: 2.272448097666105

Epoch: 5| Step: 4
Training loss: 0.7309525609016418
Validation loss: 2.145667960246404

Epoch: 5| Step: 5
Training loss: 0.7760353684425354
Validation loss: 2.141573722163836

Epoch: 5| Step: 6
Training loss: 0.5775130987167358
Validation loss: 2.102716699242592

Epoch: 5| Step: 7
Training loss: 1.0187081098556519
Validation loss: 2.0955584893623986

Epoch: 5| Step: 8
Training loss: 0.9334694147109985
Validation loss: 2.0683936874071756

Epoch: 5| Step: 9
Training loss: 0.7813893556594849
Validation loss: 2.071811387936274

Epoch: 5| Step: 10
Training loss: 0.7573334574699402
Validation loss: 2.0536845376094184

Epoch: 5| Step: 11
Training loss: 0.5973498225212097
Validation loss: 2.095165049036344

Epoch: 197| Step: 0
Training loss: 0.5218067765235901
Validation loss: 2.149909103910128

Epoch: 5| Step: 1
Training loss: 0.8769282102584839
Validation loss: 2.169724866747856

Epoch: 5| Step: 2
Training loss: 0.5405656099319458
Validation loss: 2.153241142630577

Epoch: 5| Step: 3
Training loss: 0.5124775767326355
Validation loss: 2.1834629575411477

Epoch: 5| Step: 4
Training loss: 0.7790759801864624
Validation loss: 2.1658972750107446

Epoch: 5| Step: 5
Training loss: 0.7051908373832703
Validation loss: 2.0735488732655845

Epoch: 5| Step: 6
Training loss: 1.1218070983886719
Validation loss: 2.038407181700071

Epoch: 5| Step: 7
Training loss: 0.6092278361320496
Validation loss: 2.0238248805205026

Epoch: 5| Step: 8
Training loss: 0.9042820930480957
Validation loss: 2.0799744923909507

Epoch: 5| Step: 9
Training loss: 0.8030999898910522
Validation loss: 2.064673667152723

Epoch: 5| Step: 10
Training loss: 0.7292783856391907
Validation loss: 2.055669516324997

Epoch: 5| Step: 11
Training loss: 0.515888512134552
Validation loss: 2.0669209708770118

Epoch: 198| Step: 0
Training loss: 0.47945404052734375
Validation loss: 2.059883773326874

Epoch: 5| Step: 1
Training loss: 0.8017141222953796
Validation loss: 2.1379112700621286

Epoch: 5| Step: 2
Training loss: 0.7717252969741821
Validation loss: 2.166331246495247

Epoch: 5| Step: 3
Training loss: 1.1165920495986938
Validation loss: 2.190845529238383

Epoch: 5| Step: 4
Training loss: 0.7627072334289551
Validation loss: 2.144087235132853

Epoch: 5| Step: 5
Training loss: 0.5444180965423584
Validation loss: 2.057371124625206

Epoch: 5| Step: 6
Training loss: 0.7036571502685547
Validation loss: 2.012856140732765

Epoch: 5| Step: 7
Training loss: 0.7409226894378662
Validation loss: 2.042290156086286

Epoch: 5| Step: 8
Training loss: 1.2057222127914429
Validation loss: 2.0162198593219123

Epoch: 5| Step: 9
Training loss: 0.42585498094558716
Validation loss: 2.0231346786022186

Epoch: 5| Step: 10
Training loss: 0.7076602578163147
Validation loss: 2.0221427977085114

Epoch: 5| Step: 11
Training loss: 0.26998674869537354
Validation loss: 2.0680660406748452

Epoch: 199| Step: 0
Training loss: 0.2834359109401703
Validation loss: 2.0566710432370505

Epoch: 5| Step: 1
Training loss: 0.7132017016410828
Validation loss: 2.0906555900971093

Epoch: 5| Step: 2
Training loss: 0.8454940915107727
Validation loss: 2.22127295533816

Epoch: 5| Step: 3
Training loss: 0.9404894709587097
Validation loss: 2.1746188004811606

Epoch: 5| Step: 4
Training loss: 0.6546753644943237
Validation loss: 2.1435149063666663

Epoch: 5| Step: 5
Training loss: 0.44096413254737854
Validation loss: 2.067608361442884

Epoch: 5| Step: 6
Training loss: 0.44557109475135803
Validation loss: 2.0754364331563315

Epoch: 5| Step: 7
Training loss: 0.9020494222640991
Validation loss: 2.03543529411157

Epoch: 5| Step: 8
Training loss: 0.7134990096092224
Validation loss: 2.0271274149417877

Epoch: 5| Step: 9
Training loss: 1.1957346200942993
Validation loss: 2.025880684455236

Epoch: 5| Step: 10
Training loss: 0.7936081886291504
Validation loss: 2.0262806018193564

Epoch: 5| Step: 11
Training loss: 0.7835431098937988
Validation loss: 2.033647283911705

Epoch: 200| Step: 0
Training loss: 0.6793424487113953
Validation loss: 2.0519572595755258

Epoch: 5| Step: 1
Training loss: 0.8990778923034668
Validation loss: 2.096271817882856

Epoch: 5| Step: 2
Training loss: 0.6938932538032532
Validation loss: 2.0993486096461615

Epoch: 5| Step: 3
Training loss: 0.5393791794776917
Validation loss: 2.157353863120079

Epoch: 5| Step: 4
Training loss: 0.5601854920387268
Validation loss: 2.1081870049238205

Epoch: 5| Step: 5
Training loss: 0.8906124234199524
Validation loss: 2.0899444123109183

Epoch: 5| Step: 6
Training loss: 0.4239540100097656
Validation loss: 2.0739306608835855

Epoch: 5| Step: 7
Training loss: 0.5021899342536926
Validation loss: 2.0588120917479196

Epoch: 5| Step: 8
Training loss: 0.7210968136787415
Validation loss: 2.0048504918813705

Epoch: 5| Step: 9
Training loss: 0.6813812255859375
Validation loss: 2.0650035738945007

Epoch: 5| Step: 10
Training loss: 0.756561279296875
Validation loss: 2.015626465280851

Epoch: 5| Step: 11
Training loss: 0.293484091758728
Validation loss: 2.0746554881334305

Epoch: 201| Step: 0
Training loss: 0.31875282526016235
Validation loss: 2.0483562548955283

Epoch: 5| Step: 1
Training loss: 0.5378517508506775
Validation loss: 2.0453606148560843

Epoch: 5| Step: 2
Training loss: 0.5934301018714905
Validation loss: 2.120980749527613

Epoch: 5| Step: 3
Training loss: 0.669777512550354
Validation loss: 2.0905759086211524

Epoch: 5| Step: 4
Training loss: 0.44035062193870544
Validation loss: 2.1020806630452475

Epoch: 5| Step: 5
Training loss: 0.8125013113021851
Validation loss: 2.0775552491346994

Epoch: 5| Step: 6
Training loss: 0.7756094932556152
Validation loss: 2.0570788184801736

Epoch: 5| Step: 7
Training loss: 0.6502906680107117
Validation loss: 2.0271926472584405

Epoch: 5| Step: 8
Training loss: 0.572433590888977
Validation loss: 2.026270697514216

Epoch: 5| Step: 9
Training loss: 0.6528041958808899
Validation loss: 2.0394356002410254

Epoch: 5| Step: 10
Training loss: 0.5240864157676697
Validation loss: 2.0970984200636544

Epoch: 5| Step: 11
Training loss: 0.503785252571106
Validation loss: 2.0414569973945618

Epoch: 202| Step: 0
Training loss: 0.8876526951789856
Validation loss: 2.0562243262926736

Epoch: 5| Step: 1
Training loss: 0.3873381018638611
Validation loss: 2.083266705274582

Epoch: 5| Step: 2
Training loss: 0.38507235050201416
Validation loss: 2.1345330427090325

Epoch: 5| Step: 3
Training loss: 0.6687947511672974
Validation loss: 2.0888071258862815

Epoch: 5| Step: 4
Training loss: 0.44742828607559204
Validation loss: 2.0798599322636924

Epoch: 5| Step: 5
Training loss: 0.7036365270614624
Validation loss: 2.0890468607346215

Epoch: 5| Step: 6
Training loss: 0.9373950958251953
Validation loss: 2.0590504656235376

Epoch: 5| Step: 7
Training loss: 0.39701730012893677
Validation loss: 2.019588569800059

Epoch: 5| Step: 8
Training loss: 0.5522691011428833
Validation loss: 2.0944498678048453

Epoch: 5| Step: 9
Training loss: 0.3815285563468933
Validation loss: 2.1236268679300943

Epoch: 5| Step: 10
Training loss: 0.5743674039840698
Validation loss: 2.0907433182001114

Epoch: 5| Step: 11
Training loss: 0.5759604573249817
Validation loss: 2.1201600978771844

Epoch: 203| Step: 0
Training loss: 0.6437045335769653
Validation loss: 2.1237531503041587

Epoch: 5| Step: 1
Training loss: 0.5198229551315308
Validation loss: 2.102078447739283

Epoch: 5| Step: 2
Training loss: 0.4198555052280426
Validation loss: 2.0455553183952966

Epoch: 5| Step: 3
Training loss: 0.3809082508087158
Validation loss: 2.057306776444117

Epoch: 5| Step: 4
Training loss: 0.8728235363960266
Validation loss: 2.032499526937803

Epoch: 5| Step: 5
Training loss: 0.7281833291053772
Validation loss: 2.0993658552567163

Epoch: 5| Step: 6
Training loss: 0.3266538083553314
Validation loss: 2.073780283331871

Epoch: 5| Step: 7
Training loss: 0.5081809163093567
Validation loss: 2.094563608368238

Epoch: 5| Step: 8
Training loss: 0.6289436221122742
Validation loss: 2.094710956017176

Epoch: 5| Step: 9
Training loss: 0.585523784160614
Validation loss: 2.078001474340757

Epoch: 5| Step: 10
Training loss: 0.7142320275306702
Validation loss: 2.107232694824537

Epoch: 5| Step: 11
Training loss: 0.8349936008453369
Validation loss: 2.082127163807551

Epoch: 204| Step: 0
Training loss: 0.48525896668434143
Validation loss: 2.087320029735565

Epoch: 5| Step: 1
Training loss: 0.7625185251235962
Validation loss: 2.0364330261945724

Epoch: 5| Step: 2
Training loss: 0.25946545600891113
Validation loss: 2.109112208088239

Epoch: 5| Step: 3
Training loss: 0.8436832427978516
Validation loss: 2.0526209473609924

Epoch: 5| Step: 4
Training loss: 0.4941729009151459
Validation loss: 2.125105232000351

Epoch: 5| Step: 5
Training loss: 0.37652215361595154
Validation loss: 2.087553088863691

Epoch: 5| Step: 6
Training loss: 0.653252124786377
Validation loss: 2.0783751706282296

Epoch: 5| Step: 7
Training loss: 0.4927058219909668
Validation loss: 2.0807919204235077

Epoch: 5| Step: 8
Training loss: 0.639300525188446
Validation loss: 2.0876954396565757

Epoch: 5| Step: 9
Training loss: 0.7009076476097107
Validation loss: 2.0428623259067535

Epoch: 5| Step: 10
Training loss: 0.5647369623184204
Validation loss: 2.1127471228440604

Epoch: 5| Step: 11
Training loss: 0.9846470355987549
Validation loss: 2.095116049051285

Epoch: 205| Step: 0
Training loss: 0.3561379909515381
Validation loss: 2.1490118354558945

Epoch: 5| Step: 1
Training loss: 0.38090187311172485
Validation loss: 2.0519165694713593

Epoch: 5| Step: 2
Training loss: 0.5301377773284912
Validation loss: 2.060490921139717

Epoch: 5| Step: 3
Training loss: 0.41814184188842773
Validation loss: 2.0958325813213983

Epoch: 5| Step: 4
Training loss: 0.7419235110282898
Validation loss: 2.1165034423271814

Epoch: 5| Step: 5
Training loss: 0.6581372022628784
Validation loss: 2.1490318725506463

Epoch: 5| Step: 6
Training loss: 0.573975682258606
Validation loss: 2.1035447120666504

Epoch: 5| Step: 7
Training loss: 0.7861214876174927
Validation loss: 2.105385492245356

Epoch: 5| Step: 8
Training loss: 0.38023075461387634
Validation loss: 2.0750872045755386

Epoch: 5| Step: 9
Training loss: 0.6507450342178345
Validation loss: 2.073216035962105

Epoch: 5| Step: 10
Training loss: 0.5588811635971069
Validation loss: 2.069443623224894

Epoch: 5| Step: 11
Training loss: 0.536628007888794
Validation loss: 2.094857762257258

Epoch: 206| Step: 0
Training loss: 0.41428500413894653
Validation loss: 2.1092195908228555

Epoch: 5| Step: 1
Training loss: 0.5076860189437866
Validation loss: 2.0887464930613837

Epoch: 5| Step: 2
Training loss: 1.2223725318908691
Validation loss: 2.0680406242609024

Epoch: 5| Step: 3
Training loss: 0.4116511344909668
Validation loss: 2.1293035050233207

Epoch: 5| Step: 4
Training loss: 0.4603263735771179
Validation loss: 2.0860087672869363

Epoch: 5| Step: 5
Training loss: 0.6475779414176941
Validation loss: 2.133347729841868

Epoch: 5| Step: 6
Training loss: 0.4240085184574127
Validation loss: 2.145458539326986

Epoch: 5| Step: 7
Training loss: 0.8539565801620483
Validation loss: 2.1607984950145087

Epoch: 5| Step: 8
Training loss: 0.5582385063171387
Validation loss: 2.1438638319571814

Epoch: 5| Step: 9
Training loss: 0.444868266582489
Validation loss: 2.10250856479009

Epoch: 5| Step: 10
Training loss: 0.37182074785232544
Validation loss: 2.1390129079421363

Epoch: 5| Step: 11
Training loss: 0.20993417501449585
Validation loss: 2.0504586895306907

Epoch: 207| Step: 0
Training loss: 0.6399272680282593
Validation loss: 2.074612786372503

Epoch: 5| Step: 1
Training loss: 0.39813733100891113
Validation loss: 2.0957442969083786

Epoch: 5| Step: 2
Training loss: 0.6115439534187317
Validation loss: 2.0746554285287857

Epoch: 5| Step: 3
Training loss: 0.4214763641357422
Validation loss: 2.0970411598682404

Epoch: 5| Step: 4
Training loss: 0.31640103459358215
Validation loss: 2.1344181348880134

Epoch: 5| Step: 5
Training loss: 1.0853935480117798
Validation loss: 2.158452421426773

Epoch: 5| Step: 6
Training loss: 0.5423041582107544
Validation loss: 2.144855414827665

Epoch: 5| Step: 7
Training loss: 0.8774426579475403
Validation loss: 2.1528573036193848

Epoch: 5| Step: 8
Training loss: 0.492790549993515
Validation loss: 2.1306182742118835

Epoch: 5| Step: 9
Training loss: 0.46539339423179626
Validation loss: 2.089694172143936

Epoch: 5| Step: 10
Training loss: 0.5928388833999634
Validation loss: 2.069812163710594

Epoch: 5| Step: 11
Training loss: 0.13387060165405273
Validation loss: 2.039678613344828

Epoch: 208| Step: 0
Training loss: 0.6408151984214783
Validation loss: 2.0833911995093026

Epoch: 5| Step: 1
Training loss: 0.6030244827270508
Validation loss: 2.0357986092567444

Epoch: 5| Step: 2
Training loss: 0.7810325026512146
Validation loss: 1.9804922689994175

Epoch: 5| Step: 3
Training loss: 0.4084256589412689
Validation loss: 2.063373660047849

Epoch: 5| Step: 4
Training loss: 0.30674558877944946
Validation loss: 2.090799738963445

Epoch: 5| Step: 5
Training loss: 0.8159209489822388
Validation loss: 2.1139242202043533

Epoch: 5| Step: 6
Training loss: 0.9679682850837708
Validation loss: 2.143944720427195

Epoch: 5| Step: 7
Training loss: 0.5815228223800659
Validation loss: 2.1684463024139404

Epoch: 5| Step: 8
Training loss: 0.7977613210678101
Validation loss: 2.0869200428326926

Epoch: 5| Step: 9
Training loss: 0.40750932693481445
Validation loss: 2.0779665460189185

Epoch: 5| Step: 10
Training loss: 0.6040934324264526
Validation loss: 2.040211612979571

Epoch: 5| Step: 11
Training loss: 0.3389573097229004
Validation loss: 2.0104112277428308

Epoch: 209| Step: 0
Training loss: 0.4305996000766754
Validation loss: 2.030400092403094

Epoch: 5| Step: 1
Training loss: 0.38355690240859985
Validation loss: 2.068525875608126

Epoch: 5| Step: 2
Training loss: 0.6064434051513672
Validation loss: 2.121136953433355

Epoch: 5| Step: 3
Training loss: 0.6194105744361877
Validation loss: 2.119605913758278

Epoch: 5| Step: 4
Training loss: 0.8020654916763306
Validation loss: 2.0872436265150704

Epoch: 5| Step: 5
Training loss: 0.7022159099578857
Validation loss: 2.0696877588828406

Epoch: 5| Step: 6
Training loss: 0.41426461935043335
Validation loss: 2.0654020806153617

Epoch: 5| Step: 7
Training loss: 0.7518043518066406
Validation loss: 2.045013835032781

Epoch: 5| Step: 8
Training loss: 0.5428908467292786
Validation loss: 2.000125323732694

Epoch: 5| Step: 9
Training loss: 0.8358413577079773
Validation loss: 2.0663717538118362

Epoch: 5| Step: 10
Training loss: 0.46340709924697876
Validation loss: 2.01121058066686

Epoch: 5| Step: 11
Training loss: 1.0181771516799927
Validation loss: 2.0252888848384223

Epoch: 210| Step: 0
Training loss: 0.4022466242313385
Validation loss: 2.045409699281057

Epoch: 5| Step: 1
Training loss: 0.6333366632461548
Validation loss: 2.1070628315210342

Epoch: 5| Step: 2
Training loss: 0.62347412109375
Validation loss: 2.0744092017412186

Epoch: 5| Step: 3
Training loss: 0.6756414175033569
Validation loss: 2.1380290190378823

Epoch: 5| Step: 4
Training loss: 0.7262504696846008
Validation loss: 2.1490700393915176

Epoch: 5| Step: 5
Training loss: 0.8308650255203247
Validation loss: 2.070024917523066

Epoch: 5| Step: 6
Training loss: 0.3893057107925415
Validation loss: 2.079301650325457

Epoch: 5| Step: 7
Training loss: 0.3414456844329834
Validation loss: 2.057629848519961

Epoch: 5| Step: 8
Training loss: 0.8080393075942993
Validation loss: 2.0898643930753074

Epoch: 5| Step: 9
Training loss: 0.5303744077682495
Validation loss: 2.055534233649572

Epoch: 5| Step: 10
Training loss: 0.6599407196044922
Validation loss: 2.054627741376559

Epoch: 5| Step: 11
Training loss: 0.5004078149795532
Validation loss: 2.1227462689081826

Epoch: 211| Step: 0
Training loss: 0.7495326399803162
Validation loss: 2.0445008923610053

Epoch: 5| Step: 1
Training loss: 1.1157937049865723
Validation loss: 2.0980407843987146

Epoch: 5| Step: 2
Training loss: 0.7278425693511963
Validation loss: 2.123005429903666

Epoch: 5| Step: 3
Training loss: 0.608095109462738
Validation loss: 2.149571026364962

Epoch: 5| Step: 4
Training loss: 0.48281049728393555
Validation loss: 2.099967380364736

Epoch: 5| Step: 5
Training loss: 0.35869258642196655
Validation loss: 2.0787597000598907

Epoch: 5| Step: 6
Training loss: 0.5710328221321106
Validation loss: 2.103632539510727

Epoch: 5| Step: 7
Training loss: 0.3058926463127136
Validation loss: 2.0999744633833566

Epoch: 5| Step: 8
Training loss: 0.4743412137031555
Validation loss: 2.068204015493393

Epoch: 5| Step: 9
Training loss: 0.4882887899875641
Validation loss: 2.0930453638235726

Epoch: 5| Step: 10
Training loss: 0.5136088132858276
Validation loss: 2.1655759612719216

Epoch: 5| Step: 11
Training loss: 0.5541608929634094
Validation loss: 2.139228900273641

Epoch: 212| Step: 0
Training loss: 0.5255078077316284
Validation loss: 2.103767623504003

Epoch: 5| Step: 1
Training loss: 0.7788146734237671
Validation loss: 2.0853929867347083

Epoch: 5| Step: 2
Training loss: 0.5203863382339478
Validation loss: 2.1279900272687278

Epoch: 5| Step: 3
Training loss: 0.5192939639091492
Validation loss: 2.127291386326154

Epoch: 5| Step: 4
Training loss: 0.6626025438308716
Validation loss: 2.0401919335126877

Epoch: 5| Step: 5
Training loss: 0.5710656642913818
Validation loss: 2.085826575756073

Epoch: 5| Step: 6
Training loss: 0.41138744354248047
Validation loss: 2.029621804753939

Epoch: 5| Step: 7
Training loss: 0.43213194608688354
Validation loss: 2.0609144220749536

Epoch: 5| Step: 8
Training loss: 0.46893763542175293
Validation loss: 2.0097057272990546

Epoch: 5| Step: 9
Training loss: 0.42692938446998596
Validation loss: 2.0611061255137124

Epoch: 5| Step: 10
Training loss: 0.40539437532424927
Validation loss: 2.101312533020973

Epoch: 5| Step: 11
Training loss: 1.8939995765686035
Validation loss: 2.1471034487088523

Epoch: 213| Step: 0
Training loss: 0.3916529715061188
Validation loss: 2.093858167529106

Epoch: 5| Step: 1
Training loss: 0.5643630027770996
Validation loss: 2.149584025144577

Epoch: 5| Step: 2
Training loss: 0.5230493545532227
Validation loss: 2.0735919773578644

Epoch: 5| Step: 3
Training loss: 0.5599824786186218
Validation loss: 2.0465843429168067

Epoch: 5| Step: 4
Training loss: 0.37569183111190796
Validation loss: 2.0600568701823554

Epoch: 5| Step: 5
Training loss: 0.7165454030036926
Validation loss: 2.0477422773838043

Epoch: 5| Step: 6
Training loss: 0.7373169660568237
Validation loss: 2.0606525242328644

Epoch: 5| Step: 7
Training loss: 0.6375619769096375
Validation loss: 2.0790171871582666

Epoch: 5| Step: 8
Training loss: 0.855928897857666
Validation loss: 2.0908661782741547

Epoch: 5| Step: 9
Training loss: 0.5527323484420776
Validation loss: 2.1076013644536338

Epoch: 5| Step: 10
Training loss: 0.5376391410827637
Validation loss: 2.1242633362611136

Epoch: 5| Step: 11
Training loss: 0.31952932476997375
Validation loss: 2.121174012621244

Epoch: 214| Step: 0
Training loss: 0.6057780385017395
Validation loss: 2.0582441786924996

Epoch: 5| Step: 1
Training loss: 0.6240507364273071
Validation loss: 2.0665288319190345

Epoch: 5| Step: 2
Training loss: 0.4318670332431793
Validation loss: 2.118090331554413

Epoch: 5| Step: 3
Training loss: 0.3958252966403961
Validation loss: 2.0272286335627236

Epoch: 5| Step: 4
Training loss: 0.7293281555175781
Validation loss: 2.093524028857549

Epoch: 5| Step: 5
Training loss: 0.6587013602256775
Validation loss: 2.05533496538798

Epoch: 5| Step: 6
Training loss: 0.4198315739631653
Validation loss: 2.082193692525228

Epoch: 5| Step: 7
Training loss: 0.381216824054718
Validation loss: 2.082136998573939

Epoch: 5| Step: 8
Training loss: 0.6964912414550781
Validation loss: 2.103979448477427

Epoch: 5| Step: 9
Training loss: 0.5378985404968262
Validation loss: 2.1315817882617316

Epoch: 5| Step: 10
Training loss: 0.713010311126709
Validation loss: 2.038692052165667

Epoch: 5| Step: 11
Training loss: 0.6642342805862427
Validation loss: 2.0858063846826553

Epoch: 215| Step: 0
Training loss: 0.48943576216697693
Validation loss: 2.069920132557551

Epoch: 5| Step: 1
Training loss: 0.6321840286254883
Validation loss: 2.0423083007335663

Epoch: 5| Step: 2
Training loss: 0.521654486656189
Validation loss: 2.0542743504047394

Epoch: 5| Step: 3
Training loss: 0.7091237902641296
Validation loss: 2.0654536137978234

Epoch: 5| Step: 4
Training loss: 0.4471830725669861
Validation loss: 2.090194344520569

Epoch: 5| Step: 5
Training loss: 0.6785231828689575
Validation loss: 2.07819139957428

Epoch: 5| Step: 6
Training loss: 0.6763842701911926
Validation loss: 2.064388950665792

Epoch: 5| Step: 7
Training loss: 0.2767931818962097
Validation loss: 2.084781304001808

Epoch: 5| Step: 8
Training loss: 0.9012695550918579
Validation loss: 2.097739820679029

Epoch: 5| Step: 9
Training loss: 0.26382914185523987
Validation loss: 2.0586243172486625

Epoch: 5| Step: 10
Training loss: 0.39490804076194763
Validation loss: 2.0623618761698403

Epoch: 5| Step: 11
Training loss: 0.3301566243171692
Validation loss: 2.118600939710935

Epoch: 216| Step: 0
Training loss: 0.5292011499404907
Validation loss: 2.0529823005199432

Epoch: 5| Step: 1
Training loss: 0.42767268419265747
Validation loss: 2.017478575309118

Epoch: 5| Step: 2
Training loss: 0.7346609234809875
Validation loss: 2.0295750945806503

Epoch: 5| Step: 3
Training loss: 0.6751725673675537
Validation loss: 2.095910961429278

Epoch: 5| Step: 4
Training loss: 0.4044463038444519
Validation loss: 2.107560654481252

Epoch: 5| Step: 5
Training loss: 0.3618704080581665
Validation loss: 2.0782025158405304

Epoch: 5| Step: 6
Training loss: 0.7851142883300781
Validation loss: 2.1424019932746887

Epoch: 5| Step: 7
Training loss: 0.6119572520256042
Validation loss: 2.1511274576187134

Epoch: 5| Step: 8
Training loss: 0.736330509185791
Validation loss: 2.141644145051638

Epoch: 5| Step: 9
Training loss: 0.3835716247558594
Validation loss: 2.1210178087155023

Epoch: 5| Step: 10
Training loss: 0.39165249466896057
Validation loss: 2.1209966590007148

Epoch: 5| Step: 11
Training loss: 0.1112716794013977
Validation loss: 2.0749542166789374

Epoch: 217| Step: 0
Training loss: 0.5193015336990356
Validation loss: 2.039441098769506

Epoch: 5| Step: 1
Training loss: 0.345348984003067
Validation loss: 2.0486101607481637

Epoch: 5| Step: 2
Training loss: 0.7375083565711975
Validation loss: 2.016372541586558

Epoch: 5| Step: 3
Training loss: 0.6058980226516724
Validation loss: 2.102534035841624

Epoch: 5| Step: 4
Training loss: 0.477029025554657
Validation loss: 2.120914767185847

Epoch: 5| Step: 5
Training loss: 0.5503587126731873
Validation loss: 2.1332194854815802

Epoch: 5| Step: 6
Training loss: 0.3971606194972992
Validation loss: 2.1106838981310525

Epoch: 5| Step: 7
Training loss: 0.4729219377040863
Validation loss: 2.089467932780584

Epoch: 5| Step: 8
Training loss: 0.5185140371322632
Validation loss: 2.0314402282238007

Epoch: 5| Step: 9
Training loss: 0.47120580077171326
Validation loss: 2.0575212885936103

Epoch: 5| Step: 10
Training loss: 0.8089431524276733
Validation loss: 2.0457118153572083

Epoch: 5| Step: 11
Training loss: 0.27281153202056885
Validation loss: 2.0969778249661126

Epoch: 218| Step: 0
Training loss: 0.3399103879928589
Validation loss: 2.048683931430181

Epoch: 5| Step: 1
Training loss: 0.7759472131729126
Validation loss: 2.079683095216751

Epoch: 5| Step: 2
Training loss: 0.3250427842140198
Validation loss: 2.0318498760461807

Epoch: 5| Step: 3
Training loss: 0.5131995677947998
Validation loss: 2.059011404712995

Epoch: 5| Step: 4
Training loss: 0.5315105319023132
Validation loss: 2.0318663914998374

Epoch: 5| Step: 5
Training loss: 0.6843427419662476
Validation loss: 2.033063525954882

Epoch: 5| Step: 6
Training loss: 0.4240770936012268
Validation loss: 2.044949159026146

Epoch: 5| Step: 7
Training loss: 0.9595742225646973
Validation loss: 2.03377694884936

Epoch: 5| Step: 8
Training loss: 0.40402698516845703
Validation loss: 2.093675514062246

Epoch: 5| Step: 9
Training loss: 0.6206850409507751
Validation loss: 2.046931897600492

Epoch: 5| Step: 10
Training loss: 0.5095720291137695
Validation loss: 2.0928355952103934

Epoch: 5| Step: 11
Training loss: 0.1696290373802185
Validation loss: 2.092408994833628

Epoch: 219| Step: 0
Training loss: 0.47871941328048706
Validation loss: 2.1206037402153015

Epoch: 5| Step: 1
Training loss: 0.4890657365322113
Validation loss: 2.0218634555737176

Epoch: 5| Step: 2
Training loss: 0.5893769264221191
Validation loss: 2.0770258655150733

Epoch: 5| Step: 3
Training loss: 0.6365534067153931
Validation loss: 2.0403421272834144

Epoch: 5| Step: 4
Training loss: 0.8148238062858582
Validation loss: 2.062617748975754

Epoch: 5| Step: 5
Training loss: 0.24670584499835968
Validation loss: 2.0724972585837045

Epoch: 5| Step: 6
Training loss: 0.3547171652317047
Validation loss: 2.0981209675470986

Epoch: 5| Step: 7
Training loss: 0.7249851822853088
Validation loss: 2.047235185901324

Epoch: 5| Step: 8
Training loss: 0.4135156273841858
Validation loss: 2.055852343638738

Epoch: 5| Step: 9
Training loss: 0.5164669752120972
Validation loss: 2.1140691538651786

Epoch: 5| Step: 10
Training loss: 0.4434065818786621
Validation loss: 2.0807718386252723

Epoch: 5| Step: 11
Training loss: 0.08903706073760986
Validation loss: 2.1127909372250238

Epoch: 220| Step: 0
Training loss: 1.0504192113876343
Validation loss: 2.0562646438678107

Epoch: 5| Step: 1
Training loss: 0.6852189302444458
Validation loss: 2.079196125268936

Epoch: 5| Step: 2
Training loss: 0.2547333836555481
Validation loss: 2.069439192612966

Epoch: 5| Step: 3
Training loss: 0.2558949589729309
Validation loss: 2.1211789896090827

Epoch: 5| Step: 4
Training loss: 0.47010383009910583
Validation loss: 2.0854764133691788

Epoch: 5| Step: 5
Training loss: 0.6727519035339355
Validation loss: 2.091255853573481

Epoch: 5| Step: 6
Training loss: 0.32286402583122253
Validation loss: 2.041756898164749

Epoch: 5| Step: 7
Training loss: 0.4828163683414459
Validation loss: 2.101626306772232

Epoch: 5| Step: 8
Training loss: 0.33695244789123535
Validation loss: 2.0579067915678024

Epoch: 5| Step: 9
Training loss: 0.3906480371952057
Validation loss: 2.04181961218516

Epoch: 5| Step: 10
Training loss: 0.6185917258262634
Validation loss: 2.070196658372879

Epoch: 5| Step: 11
Training loss: 0.43841853737831116
Validation loss: 2.073913852373759

Epoch: 221| Step: 0
Training loss: 0.5241767764091492
Validation loss: 2.0414514938990274

Epoch: 5| Step: 1
Training loss: 0.4321599006652832
Validation loss: 2.0569132566452026

Epoch: 5| Step: 2
Training loss: 0.41771572828292847
Validation loss: 2.037043576439222

Epoch: 5| Step: 3
Training loss: 0.3871902823448181
Validation loss: 2.061753277977308

Epoch: 5| Step: 4
Training loss: 0.34572169184684753
Validation loss: 2.014560123284658

Epoch: 5| Step: 5
Training loss: 0.6612895727157593
Validation loss: 2.102248733242353

Epoch: 5| Step: 6
Training loss: 0.3897762894630432
Validation loss: 2.044773747523626

Epoch: 5| Step: 7
Training loss: 0.29345637559890747
Validation loss: 2.101206809282303

Epoch: 5| Step: 8
Training loss: 0.7717707753181458
Validation loss: 2.129967133204142

Epoch: 5| Step: 9
Training loss: 0.5520159602165222
Validation loss: 2.074961339433988

Epoch: 5| Step: 10
Training loss: 0.7569347620010376
Validation loss: 2.070735270778338

Epoch: 5| Step: 11
Training loss: 0.2719062566757202
Validation loss: 2.1597643742958703

Epoch: 222| Step: 0
Training loss: 0.43494272232055664
Validation loss: 2.020948867003123

Epoch: 5| Step: 1
Training loss: 0.4532889425754547
Validation loss: 2.0425755232572556

Epoch: 5| Step: 2
Training loss: 0.50121009349823
Validation loss: 2.0231886903444924

Epoch: 5| Step: 3
Training loss: 0.6654387712478638
Validation loss: 2.0885820587476096

Epoch: 5| Step: 4
Training loss: 0.6065007448196411
Validation loss: 2.0200216670831046

Epoch: 5| Step: 5
Training loss: 0.554848313331604
Validation loss: 2.0212025145689645

Epoch: 5| Step: 6
Training loss: 0.7080367803573608
Validation loss: 2.103660136461258

Epoch: 5| Step: 7
Training loss: 0.6500070691108704
Validation loss: 2.097652167081833

Epoch: 5| Step: 8
Training loss: 0.27406781911849976
Validation loss: 2.0884553094704947

Epoch: 5| Step: 9
Training loss: 0.397614061832428
Validation loss: 2.133790617187818

Epoch: 5| Step: 10
Training loss: 0.3635123074054718
Validation loss: 2.1033253272374473

Epoch: 5| Step: 11
Training loss: 1.9291847944259644
Validation loss: 2.0443470925092697

Epoch: 223| Step: 0
Training loss: 0.5357120633125305
Validation loss: 2.0854798505703607

Epoch: 5| Step: 1
Training loss: 0.5974555611610413
Validation loss: 2.0330908447504044

Epoch: 5| Step: 2
Training loss: 0.5997411608695984
Validation loss: 2.07711161673069

Epoch: 5| Step: 3
Training loss: 0.33405494689941406
Validation loss: 2.0601448317368827

Epoch: 5| Step: 4
Training loss: 0.6022006273269653
Validation loss: 2.130016247431437

Epoch: 5| Step: 5
Training loss: 0.2716030478477478
Validation loss: 2.083634674549103

Epoch: 5| Step: 6
Training loss: 0.2819240391254425
Validation loss: 2.118122398853302

Epoch: 5| Step: 7
Training loss: 0.6254445910453796
Validation loss: 2.064243495464325

Epoch: 5| Step: 8
Training loss: 0.4118232727050781
Validation loss: 2.136810968319575

Epoch: 5| Step: 9
Training loss: 0.6716510057449341
Validation loss: 2.073574682076772

Epoch: 5| Step: 10
Training loss: 0.4231947362422943
Validation loss: 2.062747652331988

Epoch: 5| Step: 11
Training loss: 0.9672718048095703
Validation loss: 2.073370407025019

Epoch: 224| Step: 0
Training loss: 0.4683776795864105
Validation loss: 2.0840064038832984

Epoch: 5| Step: 1
Training loss: 0.4773940145969391
Validation loss: 2.0859177311261496

Epoch: 5| Step: 2
Training loss: 0.350261390209198
Validation loss: 2.096863100926081

Epoch: 5| Step: 3
Training loss: 0.5199496150016785
Validation loss: 2.0980722506841025

Epoch: 5| Step: 4
Training loss: 0.5109505653381348
Validation loss: 2.0448423475027084

Epoch: 5| Step: 5
Training loss: 0.4561857283115387
Validation loss: 2.054411455988884

Epoch: 5| Step: 6
Training loss: 0.3986700177192688
Validation loss: 2.1014835983514786

Epoch: 5| Step: 7
Training loss: 1.0170271396636963
Validation loss: 2.056018834312757

Epoch: 5| Step: 8
Training loss: 0.39821290969848633
Validation loss: 2.0838128278652825

Epoch: 5| Step: 9
Training loss: 0.4178789258003235
Validation loss: 2.0732559710741043

Epoch: 5| Step: 10
Training loss: 0.6069357395172119
Validation loss: 2.065729334950447

Epoch: 5| Step: 11
Training loss: 0.7376298904418945
Validation loss: 2.089986026287079

Epoch: 225| Step: 0
Training loss: 0.8729340434074402
Validation loss: 2.0780795762936273

Epoch: 5| Step: 1
Training loss: 0.23395855724811554
Validation loss: 2.1009641587734222

Epoch: 5| Step: 2
Training loss: 0.3393899202346802
Validation loss: 2.0742520143588385

Epoch: 5| Step: 3
Training loss: 0.730387806892395
Validation loss: 2.0763910710811615

Epoch: 5| Step: 4
Training loss: 0.48434457182884216
Validation loss: 2.113626023133596

Epoch: 5| Step: 5
Training loss: 0.636388897895813
Validation loss: 2.0701890091101327

Epoch: 5| Step: 6
Training loss: 0.6944758296012878
Validation loss: 2.0713726381460824

Epoch: 5| Step: 7
Training loss: 0.24726906418800354
Validation loss: 2.074329594771067

Epoch: 5| Step: 8
Training loss: 0.4520823061466217
Validation loss: 2.0672564158837

Epoch: 5| Step: 9
Training loss: 0.2950766384601593
Validation loss: 2.0734733790159225

Epoch: 5| Step: 10
Training loss: 0.3185233473777771
Validation loss: 2.148653974135717

Epoch: 5| Step: 11
Training loss: 0.7507805228233337
Validation loss: 2.0994504938522973

Epoch: 226| Step: 0
Training loss: 0.5562562942504883
Validation loss: 2.123486205935478

Epoch: 5| Step: 1
Training loss: 0.479607492685318
Validation loss: 2.0815268009901047

Epoch: 5| Step: 2
Training loss: 0.6095870733261108
Validation loss: 2.081668794155121

Epoch: 5| Step: 3
Training loss: 0.6809097528457642
Validation loss: 2.096712370713552

Epoch: 5| Step: 4
Training loss: 0.4343182444572449
Validation loss: 2.1207128961881003

Epoch: 5| Step: 5
Training loss: 0.5611890554428101
Validation loss: 2.163004537423452

Epoch: 5| Step: 6
Training loss: 0.3028483986854553
Validation loss: 2.0987882763147354

Epoch: 5| Step: 7
Training loss: 0.33864378929138184
Validation loss: 2.1191070675849915

Epoch: 5| Step: 8
Training loss: 0.5489012002944946
Validation loss: 2.0552583783864975

Epoch: 5| Step: 9
Training loss: 0.40950313210487366
Validation loss: 2.109066074093183

Epoch: 5| Step: 10
Training loss: 0.4162416458129883
Validation loss: 2.0468015521764755

Epoch: 5| Step: 11
Training loss: 0.3801133632659912
Validation loss: 2.0743974447250366

Epoch: 227| Step: 0
Training loss: 0.5879563689231873
Validation loss: 2.053400988380114

Epoch: 5| Step: 1
Training loss: 0.6149660348892212
Validation loss: 2.0976029137770333

Epoch: 5| Step: 2
Training loss: 0.7395674586296082
Validation loss: 2.088125079870224

Epoch: 5| Step: 3
Training loss: 0.4740545153617859
Validation loss: 2.0800169557332993

Epoch: 5| Step: 4
Training loss: 0.3982292413711548
Validation loss: 2.066266114513079

Epoch: 5| Step: 5
Training loss: 0.404348760843277
Validation loss: 2.084153642257055

Epoch: 5| Step: 6
Training loss: 0.5607053637504578
Validation loss: 2.0241851806640625

Epoch: 5| Step: 7
Training loss: 0.40069037675857544
Validation loss: 2.0581689924001694

Epoch: 5| Step: 8
Training loss: 0.4097948968410492
Validation loss: 2.0945150951544442

Epoch: 5| Step: 9
Training loss: 0.5040287971496582
Validation loss: 2.048771947622299

Epoch: 5| Step: 10
Training loss: 0.45171746611595154
Validation loss: 2.115617190798124

Epoch: 5| Step: 11
Training loss: 0.23018693923950195
Validation loss: 2.1258113235235214

Epoch: 228| Step: 0
Training loss: 0.40654516220092773
Validation loss: 2.0404115418593087

Epoch: 5| Step: 1
Training loss: 0.3452901542186737
Validation loss: 2.1088168571392694

Epoch: 5| Step: 2
Training loss: 0.4549175202846527
Validation loss: 2.1212328672409058

Epoch: 5| Step: 3
Training loss: 0.23985040187835693
Validation loss: 2.0604761441548667

Epoch: 5| Step: 4
Training loss: 0.35368210077285767
Validation loss: 2.0560381561517715

Epoch: 5| Step: 5
Training loss: 0.6225013732910156
Validation loss: 2.083956003189087

Epoch: 5| Step: 6
Training loss: 0.630699098110199
Validation loss: 2.0788277884324393

Epoch: 5| Step: 7
Training loss: 0.5024040937423706
Validation loss: 2.1322622696558633

Epoch: 5| Step: 8
Training loss: 0.7903889417648315
Validation loss: 2.097427507241567

Epoch: 5| Step: 9
Training loss: 0.654065728187561
Validation loss: 2.131396179397901

Epoch: 5| Step: 10
Training loss: 0.48314589262008667
Validation loss: 2.076069305340449

Epoch: 5| Step: 11
Training loss: 0.3120516538619995
Validation loss: 2.0581026871999106

Epoch: 229| Step: 0
Training loss: 0.5223290324211121
Validation loss: 2.072781746586164

Epoch: 5| Step: 1
Training loss: 0.4040919840335846
Validation loss: 2.0527240335941315

Epoch: 5| Step: 2
Training loss: 0.3864266276359558
Validation loss: 2.066640759507815

Epoch: 5| Step: 3
Training loss: 0.43189993500709534
Validation loss: 2.0451256036758423

Epoch: 5| Step: 4
Training loss: 0.5089963674545288
Validation loss: 2.1225340912739434

Epoch: 5| Step: 5
Training loss: 0.6925216913223267
Validation loss: 2.122409542401632

Epoch: 5| Step: 6
Training loss: 0.7137091159820557
Validation loss: 2.1057506650686264

Epoch: 5| Step: 7
Training loss: 0.7895018458366394
Validation loss: 2.1474800606568656

Epoch: 5| Step: 8
Training loss: 0.8759576678276062
Validation loss: 2.1083221385876336

Epoch: 5| Step: 9
Training loss: 0.25207391381263733
Validation loss: 2.1052106668551764

Epoch: 5| Step: 10
Training loss: 0.35509005188941956
Validation loss: 2.148989443977674

Epoch: 5| Step: 11
Training loss: 0.5882552862167358
Validation loss: 2.135624642173449

Epoch: 230| Step: 0
Training loss: 0.4837709069252014
Validation loss: 2.0794515212376914

Epoch: 5| Step: 1
Training loss: 0.2595217525959015
Validation loss: 2.079596529404322

Epoch: 5| Step: 2
Training loss: 0.3234357535839081
Validation loss: 2.150329758723577

Epoch: 5| Step: 3
Training loss: 0.7806147933006287
Validation loss: 2.158440808455149

Epoch: 5| Step: 4
Training loss: 0.5768698453903198
Validation loss: 2.134570653239886

Epoch: 5| Step: 5
Training loss: 0.37799638509750366
Validation loss: 2.1227883100509644

Epoch: 5| Step: 6
Training loss: 0.5050464272499084
Validation loss: 2.0869403034448624

Epoch: 5| Step: 7
Training loss: 0.4430469572544098
Validation loss: 2.0567814062039056

Epoch: 5| Step: 8
Training loss: 0.7145897150039673
Validation loss: 2.105181391040484

Epoch: 5| Step: 9
Training loss: 0.8540218472480774
Validation loss: 2.0955565373102822

Epoch: 5| Step: 10
Training loss: 0.5157997012138367
Validation loss: 2.0528238167365394

Epoch: 5| Step: 11
Training loss: 0.3800382614135742
Validation loss: 2.058566381533941

Epoch: 231| Step: 0
Training loss: 0.568906307220459
Validation loss: 2.136984422802925

Epoch: 5| Step: 1
Training loss: 0.6130679845809937
Validation loss: 2.1109881351391473

Epoch: 5| Step: 2
Training loss: 0.5078493356704712
Validation loss: 2.149582361181577

Epoch: 5| Step: 3
Training loss: 0.6182476282119751
Validation loss: 2.183899993697802

Epoch: 5| Step: 4
Training loss: 0.41584745049476624
Validation loss: 2.172590767343839

Epoch: 5| Step: 5
Training loss: 0.5636876225471497
Validation loss: 2.127745678027471

Epoch: 5| Step: 6
Training loss: 0.44011372327804565
Validation loss: 2.0889184921979904

Epoch: 5| Step: 7
Training loss: 0.8737972378730774
Validation loss: 2.1053737054268518

Epoch: 5| Step: 8
Training loss: 0.26140105724334717
Validation loss: 2.111864780386289

Epoch: 5| Step: 9
Training loss: 0.3122292459011078
Validation loss: 2.0903522272904715

Epoch: 5| Step: 10
Training loss: 0.45880526304244995
Validation loss: 2.064947341879209

Epoch: 5| Step: 11
Training loss: 0.44734299182891846
Validation loss: 2.07810611029466

Epoch: 232| Step: 0
Training loss: 0.5542779564857483
Validation loss: 2.150968944032987

Epoch: 5| Step: 1
Training loss: 0.6091464757919312
Validation loss: 2.1752503166596093

Epoch: 5| Step: 2
Training loss: 0.7990655899047852
Validation loss: 2.1390937119722366

Epoch: 5| Step: 3
Training loss: 0.4461103081703186
Validation loss: 2.1510938803354898

Epoch: 5| Step: 4
Training loss: 0.3462928831577301
Validation loss: 2.117569779356321

Epoch: 5| Step: 5
Training loss: 0.5599525570869446
Validation loss: 2.106724331776301

Epoch: 5| Step: 6
Training loss: 0.4601244330406189
Validation loss: 2.111023018757502

Epoch: 5| Step: 7
Training loss: 0.44423049688339233
Validation loss: 2.0754742473363876

Epoch: 5| Step: 8
Training loss: 0.5474804639816284
Validation loss: 2.0938256879647574

Epoch: 5| Step: 9
Training loss: 0.48416852951049805
Validation loss: 2.077235405643781

Epoch: 5| Step: 10
Training loss: 0.34617623686790466
Validation loss: 2.118106931447983

Epoch: 5| Step: 11
Training loss: 0.3426024913787842
Validation loss: 2.1375343799591064

Epoch: 233| Step: 0
Training loss: 0.7326348423957825
Validation loss: 2.1045228838920593

Epoch: 5| Step: 1
Training loss: 0.5025967359542847
Validation loss: 2.1037856141726174

Epoch: 5| Step: 2
Training loss: 0.3142227232456207
Validation loss: 2.0874381164709725

Epoch: 5| Step: 3
Training loss: 0.40762147307395935
Validation loss: 2.1094763527313867

Epoch: 5| Step: 4
Training loss: 0.40207386016845703
Validation loss: 2.0816198190053306

Epoch: 5| Step: 5
Training loss: 0.8735232353210449
Validation loss: 2.0444549322128296

Epoch: 5| Step: 6
Training loss: 0.4598734378814697
Validation loss: 2.0247517824172974

Epoch: 5| Step: 7
Training loss: 0.36071324348449707
Validation loss: 2.0609633525212607

Epoch: 5| Step: 8
Training loss: 0.8022962808609009
Validation loss: 2.0551284899314246

Epoch: 5| Step: 9
Training loss: 0.4910106062889099
Validation loss: 2.116413190960884

Epoch: 5| Step: 10
Training loss: 0.1888512372970581
Validation loss: 2.0783297270536423

Epoch: 5| Step: 11
Training loss: 0.11573523283004761
Validation loss: 2.1045959989229837

Epoch: 234| Step: 0
Training loss: 0.24280016124248505
Validation loss: 2.1025956571102142

Epoch: 5| Step: 1
Training loss: 0.748899519443512
Validation loss: 2.0874879360198975

Epoch: 5| Step: 2
Training loss: 0.22279179096221924
Validation loss: 2.0680218587319055

Epoch: 5| Step: 3
Training loss: 0.7023806571960449
Validation loss: 2.073876991868019

Epoch: 5| Step: 4
Training loss: 0.28854840993881226
Validation loss: 2.0391231179237366

Epoch: 5| Step: 5
Training loss: 0.6359105110168457
Validation loss: 2.098080798983574

Epoch: 5| Step: 6
Training loss: 0.4370211660861969
Validation loss: 2.1111471354961395

Epoch: 5| Step: 7
Training loss: 0.33721810579299927
Validation loss: 2.069037069876989

Epoch: 5| Step: 8
Training loss: 0.4643779397010803
Validation loss: 2.0788199305534363

Epoch: 5| Step: 9
Training loss: 0.3373689353466034
Validation loss: 2.0796757886807122

Epoch: 5| Step: 10
Training loss: 0.39099252223968506
Validation loss: 2.108150323232015

Epoch: 5| Step: 11
Training loss: 1.9680461883544922
Validation loss: 2.058776025970777

Epoch: 235| Step: 0
Training loss: 0.7380171418190002
Validation loss: 2.0818209648132324

Epoch: 5| Step: 1
Training loss: 0.3363690972328186
Validation loss: 2.1019704043865204

Epoch: 5| Step: 2
Training loss: 0.6002452373504639
Validation loss: 2.0400580565134683

Epoch: 5| Step: 3
Training loss: 0.2758970856666565
Validation loss: 2.0779369125763574

Epoch: 5| Step: 4
Training loss: 0.3909481167793274
Validation loss: 2.1283777306477227

Epoch: 5| Step: 5
Training loss: 0.29561489820480347
Validation loss: 2.0792175928751626

Epoch: 5| Step: 6
Training loss: 0.5997948050498962
Validation loss: 2.119760031501452

Epoch: 5| Step: 7
Training loss: 0.6393545866012573
Validation loss: 2.0560051749149957

Epoch: 5| Step: 8
Training loss: 0.5266232490539551
Validation loss: 2.1225724120934806

Epoch: 5| Step: 9
Training loss: 0.37035712599754333
Validation loss: 2.0898144940535226

Epoch: 5| Step: 10
Training loss: 0.48883676528930664
Validation loss: 2.0883392840623856

Epoch: 5| Step: 11
Training loss: 0.21646592020988464
Validation loss: 2.1008915354808173

Epoch: 236| Step: 0
Training loss: 0.4476669430732727
Validation loss: 2.1278513967990875

Epoch: 5| Step: 1
Training loss: 0.35921287536621094
Validation loss: 2.0324771801630654

Epoch: 5| Step: 2
Training loss: 0.9111536145210266
Validation loss: 2.1052191058794656

Epoch: 5| Step: 3
Training loss: 0.273556649684906
Validation loss: 2.10484587152799

Epoch: 5| Step: 4
Training loss: 0.39026063680648804
Validation loss: 2.1323312719662986

Epoch: 5| Step: 5
Training loss: 0.5208832025527954
Validation loss: 2.128186588486036

Epoch: 5| Step: 6
Training loss: 0.5902562141418457
Validation loss: 2.1484385579824448

Epoch: 5| Step: 7
Training loss: 0.5020568370819092
Validation loss: 2.10636659959952

Epoch: 5| Step: 8
Training loss: 0.3801785409450531
Validation loss: 2.156848907470703

Epoch: 5| Step: 9
Training loss: 0.4862384796142578
Validation loss: 2.107455164194107

Epoch: 5| Step: 10
Training loss: 0.48414236307144165
Validation loss: 2.148488645752271

Epoch: 5| Step: 11
Training loss: 0.5015069842338562
Validation loss: 2.123414784669876

Epoch: 237| Step: 0
Training loss: 0.3749547600746155
Validation loss: 2.1012842108805976

Epoch: 5| Step: 1
Training loss: 0.5037339925765991
Validation loss: 2.060161367058754

Epoch: 5| Step: 2
Training loss: 0.6694550514221191
Validation loss: 2.140978768467903

Epoch: 5| Step: 3
Training loss: 0.4114069938659668
Validation loss: 2.105868404110273

Epoch: 5| Step: 4
Training loss: 0.33677011728286743
Validation loss: 2.1216688752174377

Epoch: 5| Step: 5
Training loss: 0.5048255324363708
Validation loss: 2.113391717274984

Epoch: 5| Step: 6
Training loss: 0.542934775352478
Validation loss: 2.091104954481125

Epoch: 5| Step: 7
Training loss: 0.390910267829895
Validation loss: 2.1092705925305686

Epoch: 5| Step: 8
Training loss: 0.6407171487808228
Validation loss: 2.0902067770560584

Epoch: 5| Step: 9
Training loss: 0.7425994873046875
Validation loss: 2.134623572230339

Epoch: 5| Step: 10
Training loss: 0.27237668633461
Validation loss: 2.054351488749186

Epoch: 5| Step: 11
Training loss: 0.536260187625885
Validation loss: 2.120096524556478

Epoch: 238| Step: 0
Training loss: 0.8099504709243774
Validation loss: 2.06695748368899

Epoch: 5| Step: 1
Training loss: 0.3803988993167877
Validation loss: 2.1259855926036835

Epoch: 5| Step: 2
Training loss: 0.5405163764953613
Validation loss: 2.083773856361707

Epoch: 5| Step: 3
Training loss: 0.5789781212806702
Validation loss: 2.118461012840271

Epoch: 5| Step: 4
Training loss: 0.6520287394523621
Validation loss: 2.1724680413802466

Epoch: 5| Step: 5
Training loss: 0.5475268363952637
Validation loss: 2.102650374174118

Epoch: 5| Step: 6
Training loss: 0.7046371698379517
Validation loss: 2.1063958605130515

Epoch: 5| Step: 7
Training loss: 0.45027822256088257
Validation loss: 2.096115678548813

Epoch: 5| Step: 8
Training loss: 0.3481765687465668
Validation loss: 2.1301611761252084

Epoch: 5| Step: 9
Training loss: 0.4094364047050476
Validation loss: 2.050332337617874

Epoch: 5| Step: 10
Training loss: 0.3072185516357422
Validation loss: 2.094839930534363

Epoch: 5| Step: 11
Training loss: 0.21555045247077942
Validation loss: 2.086767628788948

Epoch: 239| Step: 0
Training loss: 0.5057803988456726
Validation loss: 2.054982582728068

Epoch: 5| Step: 1
Training loss: 0.6181577444076538
Validation loss: 2.0509266008933387

Epoch: 5| Step: 2
Training loss: 0.8530631065368652
Validation loss: 2.105374197165171

Epoch: 5| Step: 3
Training loss: 0.6058196425437927
Validation loss: 2.1099038372437158

Epoch: 5| Step: 4
Training loss: 0.2727369964122772
Validation loss: 2.171152745683988

Epoch: 5| Step: 5
Training loss: 0.46904364228248596
Validation loss: 2.121835599342982

Epoch: 5| Step: 6
Training loss: 0.5140039920806885
Validation loss: 2.110361243287722

Epoch: 5| Step: 7
Training loss: 0.3460187315940857
Validation loss: 2.111246183514595

Epoch: 5| Step: 8
Training loss: 0.2933247685432434
Validation loss: 2.0621099223693213

Epoch: 5| Step: 9
Training loss: 0.4025196433067322
Validation loss: 2.0660735070705414

Epoch: 5| Step: 10
Training loss: 0.32137882709503174
Validation loss: 2.0902206550041833

Epoch: 5| Step: 11
Training loss: 0.29088878631591797
Validation loss: 2.056535914540291

Epoch: 240| Step: 0
Training loss: 0.6020196080207825
Validation loss: 2.0578148712714515

Epoch: 5| Step: 1
Training loss: 0.3004876971244812
Validation loss: 2.114235540231069

Epoch: 5| Step: 2
Training loss: 0.5213037133216858
Validation loss: 2.119944835702578

Epoch: 5| Step: 3
Training loss: 0.509151816368103
Validation loss: 2.1084823111693063

Epoch: 5| Step: 4
Training loss: 0.3446933627128601
Validation loss: 2.123651996254921

Epoch: 5| Step: 5
Training loss: 0.3067440390586853
Validation loss: 2.07921539247036

Epoch: 5| Step: 6
Training loss: 0.6279934644699097
Validation loss: 2.0677344352006912

Epoch: 5| Step: 7
Training loss: 0.4599881172180176
Validation loss: 2.1109868586063385

Epoch: 5| Step: 8
Training loss: 0.5142296552658081
Validation loss: 2.081296294927597

Epoch: 5| Step: 9
Training loss: 0.9745892286300659
Validation loss: 2.0501528729995093

Epoch: 5| Step: 10
Training loss: 0.495901882648468
Validation loss: 2.0713696777820587

Epoch: 5| Step: 11
Training loss: 0.6336498856544495
Validation loss: 2.130125274260839

Epoch: 241| Step: 0
Training loss: 0.5896129608154297
Validation loss: 2.1126455614964166

Epoch: 5| Step: 1
Training loss: 0.6117054224014282
Validation loss: 2.1233484794696174

Epoch: 5| Step: 2
Training loss: 0.6026932001113892
Validation loss: 2.11920432249705

Epoch: 5| Step: 3
Training loss: 0.717267632484436
Validation loss: 2.140889585018158

Epoch: 5| Step: 4
Training loss: 0.43227434158325195
Validation loss: 2.095974857608477

Epoch: 5| Step: 5
Training loss: 0.4555891156196594
Validation loss: 2.0835410753885903

Epoch: 5| Step: 6
Training loss: 0.433144748210907
Validation loss: 2.0843596160411835

Epoch: 5| Step: 7
Training loss: 0.2883872985839844
Validation loss: 2.0495580285787582

Epoch: 5| Step: 8
Training loss: 0.49009865522384644
Validation loss: 2.0809686730305352

Epoch: 5| Step: 9
Training loss: 0.4304583668708801
Validation loss: 2.091152156392733

Epoch: 5| Step: 10
Training loss: 0.5292419195175171
Validation loss: 2.0597545504570007

Epoch: 5| Step: 11
Training loss: 0.2200266271829605
Validation loss: 2.085332900285721

Epoch: 242| Step: 0
Training loss: 0.569444477558136
Validation loss: 2.0865126003821692

Epoch: 5| Step: 1
Training loss: 0.44001826643943787
Validation loss: 2.092515836159388

Epoch: 5| Step: 2
Training loss: 0.36718064546585083
Validation loss: 2.0700328648090363

Epoch: 5| Step: 3
Training loss: 0.6358447670936584
Validation loss: 2.1014792372783027

Epoch: 5| Step: 4
Training loss: 0.35261836647987366
Validation loss: 2.0485284328460693

Epoch: 5| Step: 5
Training loss: 0.48168841004371643
Validation loss: 2.045824865500132

Epoch: 5| Step: 6
Training loss: 0.602669358253479
Validation loss: 2.0348342855771384

Epoch: 5| Step: 7
Training loss: 0.5748825073242188
Validation loss: 2.083515470226606

Epoch: 5| Step: 8
Training loss: 0.39626747369766235
Validation loss: 2.064716791113218

Epoch: 5| Step: 9
Training loss: 0.4007036089897156
Validation loss: 2.1139120161533356

Epoch: 5| Step: 10
Training loss: 0.39036017656326294
Validation loss: 2.0945580502351127

Epoch: 5| Step: 11
Training loss: 0.26048263907432556
Validation loss: 2.0820894092321396

Epoch: 243| Step: 0
Training loss: 0.5712660551071167
Validation loss: 2.101166675488154

Epoch: 5| Step: 1
Training loss: 0.3298853933811188
Validation loss: 2.108354240655899

Epoch: 5| Step: 2
Training loss: 0.5558996796607971
Validation loss: 2.1326458950837455

Epoch: 5| Step: 3
Training loss: 0.5586825609207153
Validation loss: 2.084092323978742

Epoch: 5| Step: 4
Training loss: 0.5661969184875488
Validation loss: 2.050097867846489

Epoch: 5| Step: 5
Training loss: 0.35481053590774536
Validation loss: 2.0506426990032196

Epoch: 5| Step: 6
Training loss: 0.7253325581550598
Validation loss: 2.0916346361239753

Epoch: 5| Step: 7
Training loss: 0.4597984850406647
Validation loss: 2.0758771101633706

Epoch: 5| Step: 8
Training loss: 0.4911724030971527
Validation loss: 2.0814113368590674

Epoch: 5| Step: 9
Training loss: 0.3822256922721863
Validation loss: 2.0844485809405646

Epoch: 5| Step: 10
Training loss: 0.28769099712371826
Validation loss: 2.099599709113439

Epoch: 5| Step: 11
Training loss: 0.25648990273475647
Validation loss: 2.1111878057320914

Epoch: 244| Step: 0
Training loss: 0.7452644109725952
Validation loss: 2.0573268979787827

Epoch: 5| Step: 1
Training loss: 0.23881468176841736
Validation loss: 2.0734511564175286

Epoch: 5| Step: 2
Training loss: 0.7797170281410217
Validation loss: 2.0389912128448486

Epoch: 5| Step: 3
Training loss: 0.5842524766921997
Validation loss: 2.0767710208892822

Epoch: 5| Step: 4
Training loss: 0.2953190207481384
Validation loss: 2.0562951366106668

Epoch: 5| Step: 5
Training loss: 0.33252954483032227
Validation loss: 2.090830072760582

Epoch: 5| Step: 6
Training loss: 0.24631977081298828
Validation loss: 2.0953884770472846

Epoch: 5| Step: 7
Training loss: 0.297897607088089
Validation loss: 2.05657130976518

Epoch: 5| Step: 8
Training loss: 0.324452668428421
Validation loss: 2.1031057834625244

Epoch: 5| Step: 9
Training loss: 0.3302585184574127
Validation loss: 2.098045289516449

Epoch: 5| Step: 10
Training loss: 0.8293758630752563
Validation loss: 2.0601634085178375

Epoch: 5| Step: 11
Training loss: 0.15869641304016113
Validation loss: 2.04511795938015

Epoch: 245| Step: 0
Training loss: 0.3753815293312073
Validation loss: 2.0691262235244117

Epoch: 5| Step: 1
Training loss: 0.4223082959651947
Validation loss: 2.0601011464993157

Epoch: 5| Step: 2
Training loss: 0.581858217716217
Validation loss: 2.085209106405576

Epoch: 5| Step: 3
Training loss: 0.41073328256607056
Validation loss: 2.059843430916468

Epoch: 5| Step: 4
Training loss: 0.528822660446167
Validation loss: 2.0591776371002197

Epoch: 5| Step: 5
Training loss: 0.4797007143497467
Validation loss: 2.0713884433110556

Epoch: 5| Step: 6
Training loss: 0.30884885787963867
Validation loss: 2.0750228414932885

Epoch: 5| Step: 7
Training loss: 0.21009516716003418
Validation loss: 2.1427283535401025

Epoch: 5| Step: 8
Training loss: 0.32862433791160583
Validation loss: 2.059810603658358

Epoch: 5| Step: 9
Training loss: 0.5033351182937622
Validation loss: 2.054152031739553

Epoch: 5| Step: 10
Training loss: 0.5574000477790833
Validation loss: 2.0742765913407006

Epoch: 5| Step: 11
Training loss: 0.24690306186676025
Validation loss: 2.042351628343264

Epoch: 246| Step: 0
Training loss: 0.5209638476371765
Validation loss: 2.1056135296821594

Epoch: 5| Step: 1
Training loss: 0.4906581938266754
Validation loss: 2.0989700257778168

Epoch: 5| Step: 2
Training loss: 0.5474655032157898
Validation loss: 2.1026759296655655

Epoch: 5| Step: 3
Training loss: 0.39003339409828186
Validation loss: 2.137265905737877

Epoch: 5| Step: 4
Training loss: 0.3386555314064026
Validation loss: 2.0944906125466027

Epoch: 5| Step: 5
Training loss: 0.393381267786026
Validation loss: 2.117642263571421

Epoch: 5| Step: 6
Training loss: 0.43784427642822266
Validation loss: 2.1573564310868583

Epoch: 5| Step: 7
Training loss: 0.42432135343551636
Validation loss: 2.0708373288313546

Epoch: 5| Step: 8
Training loss: 0.47274741530418396
Validation loss: 2.1561891436576843

Epoch: 5| Step: 9
Training loss: 0.9050273895263672
Validation loss: 2.0830500970284143

Epoch: 5| Step: 10
Training loss: 0.494086354970932
Validation loss: 2.091930463910103

Epoch: 5| Step: 11
Training loss: 0.2568751871585846
Validation loss: 2.0583195239305496

Epoch: 247| Step: 0
Training loss: 0.3424217998981476
Validation loss: 2.102367639541626

Epoch: 5| Step: 1
Training loss: 0.8581110239028931
Validation loss: 2.143661066889763

Epoch: 5| Step: 2
Training loss: 0.5582359433174133
Validation loss: 2.1236773331960044

Epoch: 5| Step: 3
Training loss: 0.37387382984161377
Validation loss: 2.126534720261892

Epoch: 5| Step: 4
Training loss: 0.2653668522834778
Validation loss: 2.118513504664103

Epoch: 5| Step: 5
Training loss: 0.48064571619033813
Validation loss: 2.118956834077835

Epoch: 5| Step: 6
Training loss: 0.28220871090888977
Validation loss: 2.069946830471357

Epoch: 5| Step: 7
Training loss: 0.4500207304954529
Validation loss: 2.0716600815455117

Epoch: 5| Step: 8
Training loss: 0.36398062109947205
Validation loss: 2.0233225226402283

Epoch: 5| Step: 9
Training loss: 0.6478875875473022
Validation loss: 2.0208983023961387

Epoch: 5| Step: 10
Training loss: 0.7524542212486267
Validation loss: 2.0912387867768607

Epoch: 5| Step: 11
Training loss: 0.30400991439819336
Validation loss: 2.077303801973661

Epoch: 248| Step: 0
Training loss: 0.927290141582489
Validation loss: 2.0278057803710303

Epoch: 5| Step: 1
Training loss: 0.21270222961902618
Validation loss: 2.0130295058091483

Epoch: 5| Step: 2
Training loss: 0.33080989122390747
Validation loss: 2.0700115164120994

Epoch: 5| Step: 3
Training loss: 0.43990761041641235
Validation loss: 2.074847290913264

Epoch: 5| Step: 4
Training loss: 0.45491528511047363
Validation loss: 2.0345120628674827

Epoch: 5| Step: 5
Training loss: 0.44821128249168396
Validation loss: 2.0041894863049188

Epoch: 5| Step: 6
Training loss: 0.7519820332527161
Validation loss: 2.037348667780558

Epoch: 5| Step: 7
Training loss: 0.3789386749267578
Validation loss: 2.062489757935206

Epoch: 5| Step: 8
Training loss: 0.27085426449775696
Validation loss: 2.0067629516124725

Epoch: 5| Step: 9
Training loss: 0.2505217492580414
Validation loss: 2.0305323948462806

Epoch: 5| Step: 10
Training loss: 0.5953570604324341
Validation loss: 2.0314542601505914

Epoch: 5| Step: 11
Training loss: 0.7878082394599915
Validation loss: 2.020174354314804

Epoch: 249| Step: 0
Training loss: 0.2733794152736664
Validation loss: 2.060455307364464

Epoch: 5| Step: 1
Training loss: 0.3750205338001251
Validation loss: 2.0353266497453055

Epoch: 5| Step: 2
Training loss: 0.6370672583580017
Validation loss: 2.084466834863027

Epoch: 5| Step: 3
Training loss: 0.31269264221191406
Validation loss: 2.0584201415379844

Epoch: 5| Step: 4
Training loss: 0.3430580794811249
Validation loss: 2.0249977658192315

Epoch: 5| Step: 5
Training loss: 0.2561103105545044
Validation loss: 2.0015272001425424

Epoch: 5| Step: 6
Training loss: 0.46685856580734253
Validation loss: 2.047342225909233

Epoch: 5| Step: 7
Training loss: 0.4980687201023102
Validation loss: 2.060348962744077

Epoch: 5| Step: 8
Training loss: 0.47621339559555054
Validation loss: 2.0616913636525473

Epoch: 5| Step: 9
Training loss: 0.7822967767715454
Validation loss: 2.040169974168142

Epoch: 5| Step: 10
Training loss: 0.42300716042518616
Validation loss: 2.12607911725839

Epoch: 5| Step: 11
Training loss: 0.2614472508430481
Validation loss: 2.044369419415792

Epoch: 250| Step: 0
Training loss: 0.36457833647727966
Validation loss: 2.126623049378395

Epoch: 5| Step: 1
Training loss: 0.6584572792053223
Validation loss: 2.1586673110723495

Epoch: 5| Step: 2
Training loss: 0.6769814491271973
Validation loss: 2.144255002339681

Epoch: 5| Step: 3
Training loss: 0.28128936886787415
Validation loss: 2.062448740005493

Epoch: 5| Step: 4
Training loss: 0.22214071452617645
Validation loss: 2.0804827213287354

Epoch: 5| Step: 5
Training loss: 0.47730693221092224
Validation loss: 2.0351924349864325

Epoch: 5| Step: 6
Training loss: 0.5006707906723022
Validation loss: 2.064704234401385

Epoch: 5| Step: 7
Training loss: 0.5460706949234009
Validation loss: 2.0741656174262366

Epoch: 5| Step: 8
Training loss: 0.7769729495048523
Validation loss: 2.0734822203715644

Epoch: 5| Step: 9
Training loss: 0.40879935026168823
Validation loss: 2.0531679143508277

Epoch: 5| Step: 10
Training loss: 0.4411107003688812
Validation loss: 2.0569734325011573

Epoch: 5| Step: 11
Training loss: 1.0097851753234863
Validation loss: 2.134354129433632

Epoch: 251| Step: 0
Training loss: 0.42109960317611694
Validation loss: 2.0993461509545646

Epoch: 5| Step: 1
Training loss: 0.4392636716365814
Validation loss: 2.088838592171669

Epoch: 5| Step: 2
Training loss: 0.20084092020988464
Validation loss: 2.060944681366285

Epoch: 5| Step: 3
Training loss: 0.4267982840538025
Validation loss: 2.0857788225015006

Epoch: 5| Step: 4
Training loss: 0.48414865136146545
Validation loss: 2.046260048945745

Epoch: 5| Step: 5
Training loss: 0.46983569860458374
Validation loss: 2.0204294323921204

Epoch: 5| Step: 6
Training loss: 0.8467897176742554
Validation loss: 2.0195439656575522

Epoch: 5| Step: 7
Training loss: 0.47419100999832153
Validation loss: 2.1029434551795325

Epoch: 5| Step: 8
Training loss: 0.5729674100875854
Validation loss: 2.1366235514481864

Epoch: 5| Step: 9
Training loss: 0.6536750793457031
Validation loss: 2.1019821614027023

Epoch: 5| Step: 10
Training loss: 0.33203911781311035
Validation loss: 2.1356769452492395

Epoch: 5| Step: 11
Training loss: 0.31568580865859985
Validation loss: 2.1196437180042267

Epoch: 252| Step: 0
Training loss: 0.3006777763366699
Validation loss: 2.1023374696572623

Epoch: 5| Step: 1
Training loss: 0.8588030934333801
Validation loss: 2.098040218154589

Epoch: 5| Step: 2
Training loss: 0.6112314462661743
Validation loss: 2.114604130387306

Epoch: 5| Step: 3
Training loss: 0.24779948592185974
Validation loss: 2.0874238858620324

Epoch: 5| Step: 4
Training loss: 0.3657703399658203
Validation loss: 2.1099895536899567

Epoch: 5| Step: 5
Training loss: 0.408684641122818
Validation loss: 2.088430240750313

Epoch: 5| Step: 6
Training loss: 0.4009474217891693
Validation loss: 2.1343033661444983

Epoch: 5| Step: 7
Training loss: 0.3715711236000061
Validation loss: 2.1326763133207955

Epoch: 5| Step: 8
Training loss: 0.434440940618515
Validation loss: 2.1145930836598077

Epoch: 5| Step: 9
Training loss: 0.35757046937942505
Validation loss: 2.1264034062623978

Epoch: 5| Step: 10
Training loss: 1.0345712900161743
Validation loss: 2.0960684468348822

Epoch: 5| Step: 11
Training loss: 0.4257374405860901
Validation loss: 2.0519024779399238

Epoch: 253| Step: 0
Training loss: 0.5888915061950684
Validation loss: 2.0617080132166543

Epoch: 5| Step: 1
Training loss: 0.7094441652297974
Validation loss: 2.082723225156466

Epoch: 5| Step: 2
Training loss: 0.2548961639404297
Validation loss: 2.093407725294431

Epoch: 5| Step: 3
Training loss: 0.22371526062488556
Validation loss: 2.066177025437355

Epoch: 5| Step: 4
Training loss: 0.4759686589241028
Validation loss: 2.07764325539271

Epoch: 5| Step: 5
Training loss: 0.4451712667942047
Validation loss: 2.16577119131883

Epoch: 5| Step: 6
Training loss: 0.3489435613155365
Validation loss: 2.1305547108252845

Epoch: 5| Step: 7
Training loss: 0.49337393045425415
Validation loss: 2.078096096714338

Epoch: 5| Step: 8
Training loss: 0.37642616033554077
Validation loss: 2.012054974834124

Epoch: 5| Step: 9
Training loss: 0.49165964126586914
Validation loss: 2.064516926805178

Epoch: 5| Step: 10
Training loss: 0.5726832151412964
Validation loss: 2.067953253785769

Epoch: 5| Step: 11
Training loss: 0.20330190658569336
Validation loss: 2.058818062146505

Epoch: 254| Step: 0
Training loss: 0.35985007882118225
Validation loss: 2.0808557271957397

Epoch: 5| Step: 1
Training loss: 0.6583895683288574
Validation loss: 2.0779075970252356

Epoch: 5| Step: 2
Training loss: 0.42181363701820374
Validation loss: 2.0492366751035056

Epoch: 5| Step: 3
Training loss: 0.4120705723762512
Validation loss: 2.0774351060390472

Epoch: 5| Step: 4
Training loss: 0.47192373871803284
Validation loss: 2.0575641244649887

Epoch: 5| Step: 5
Training loss: 0.6396844983100891
Validation loss: 2.0480036536852517

Epoch: 5| Step: 6
Training loss: 0.2405969798564911
Validation loss: 2.0624934136867523

Epoch: 5| Step: 7
Training loss: 0.212803453207016
Validation loss: 2.0154288907845817

Epoch: 5| Step: 8
Training loss: 0.4314207434654236
Validation loss: 2.0800485809644065

Epoch: 5| Step: 9
Training loss: 0.3980786204338074
Validation loss: 2.073135087887446

Epoch: 5| Step: 10
Training loss: 0.5489681959152222
Validation loss: 2.0083927512168884

Epoch: 5| Step: 11
Training loss: 0.3865436315536499
Validation loss: 2.059388299783071

Epoch: 255| Step: 0
Training loss: 0.2868649661540985
Validation loss: 2.087117816011111

Epoch: 5| Step: 1
Training loss: 0.3442193567752838
Validation loss: 2.0937126874923706

Epoch: 5| Step: 2
Training loss: 0.5090322494506836
Validation loss: 2.079637130101522

Epoch: 5| Step: 3
Training loss: 0.7675870656967163
Validation loss: 2.140403221050898

Epoch: 5| Step: 4
Training loss: 0.6397194266319275
Validation loss: 2.090698152780533

Epoch: 5| Step: 5
Training loss: 0.3585830330848694
Validation loss: 2.070261374115944

Epoch: 5| Step: 6
Training loss: 0.5691864490509033
Validation loss: 2.076604276895523

Epoch: 5| Step: 7
Training loss: 0.48318371176719666
Validation loss: 2.0933670699596405

Epoch: 5| Step: 8
Training loss: 0.3620131015777588
Validation loss: 2.0951969971259436

Epoch: 5| Step: 9
Training loss: 0.3640597462654114
Validation loss: 2.0578290820121765

Epoch: 5| Step: 10
Training loss: 0.3235781490802765
Validation loss: 2.054809272289276

Epoch: 5| Step: 11
Training loss: 0.7999979257583618
Validation loss: 2.0464452455441156

Epoch: 256| Step: 0
Training loss: 0.3247663676738739
Validation loss: 2.0406558165947595

Epoch: 5| Step: 1
Training loss: 0.37971049547195435
Validation loss: 2.0680586447318396

Epoch: 5| Step: 2
Training loss: 0.7931249141693115
Validation loss: 2.121710737546285

Epoch: 5| Step: 3
Training loss: 0.5565235614776611
Validation loss: 2.076396187146505

Epoch: 5| Step: 4
Training loss: 0.40718308091163635
Validation loss: 2.0973967611789703

Epoch: 5| Step: 5
Training loss: 0.31468433141708374
Validation loss: 2.0722877283891044

Epoch: 5| Step: 6
Training loss: 0.2889045178890228
Validation loss: 2.076638475060463

Epoch: 5| Step: 7
Training loss: 0.4214010238647461
Validation loss: 2.0561487277348838

Epoch: 5| Step: 8
Training loss: 0.5343638062477112
Validation loss: 2.04087141652902

Epoch: 5| Step: 9
Training loss: 0.5011849403381348
Validation loss: 2.0301554600397744

Epoch: 5| Step: 10
Training loss: 0.3724072575569153
Validation loss: 2.047324632604917

Epoch: 5| Step: 11
Training loss: 1.1066621541976929
Validation loss: 2.0852035085360208

Epoch: 257| Step: 0
Training loss: 0.3253101706504822
Validation loss: 2.0790182749430337

Epoch: 5| Step: 1
Training loss: 0.7523372769355774
Validation loss: 2.115156521399816

Epoch: 5| Step: 2
Training loss: 0.630851149559021
Validation loss: 2.1743658035993576

Epoch: 5| Step: 3
Training loss: 0.6502981781959534
Validation loss: 2.15070973833402

Epoch: 5| Step: 4
Training loss: 0.36870241165161133
Validation loss: 2.0635481228431067

Epoch: 5| Step: 5
Training loss: 0.5024257302284241
Validation loss: 2.0742552131414413

Epoch: 5| Step: 6
Training loss: 0.5389414429664612
Validation loss: 2.04865570863088

Epoch: 5| Step: 7
Training loss: 0.3634980618953705
Validation loss: 2.1017092963059745

Epoch: 5| Step: 8
Training loss: 0.296448290348053
Validation loss: 2.0744591057300568

Epoch: 5| Step: 9
Training loss: 0.35520023107528687
Validation loss: 2.0640248159567514

Epoch: 5| Step: 10
Training loss: 0.3619217872619629
Validation loss: 2.0206704636414847

Epoch: 5| Step: 11
Training loss: 0.3685251474380493
Validation loss: 2.062658021847407

Epoch: 258| Step: 0
Training loss: 0.7051592469215393
Validation loss: 2.0787579665581384

Epoch: 5| Step: 1
Training loss: 0.2434203177690506
Validation loss: 2.08564630150795

Epoch: 5| Step: 2
Training loss: 0.5519812107086182
Validation loss: 2.0415059874455133

Epoch: 5| Step: 3
Training loss: 0.23105506598949432
Validation loss: 2.0803778767585754

Epoch: 5| Step: 4
Training loss: 0.3243810534477234
Validation loss: 2.053968275586764

Epoch: 5| Step: 5
Training loss: 0.9843000173568726
Validation loss: 2.0655441830555596

Epoch: 5| Step: 6
Training loss: 0.2808074355125427
Validation loss: 2.0493716398874917

Epoch: 5| Step: 7
Training loss: 0.4828719198703766
Validation loss: 2.080016151070595

Epoch: 5| Step: 8
Training loss: 0.35000237822532654
Validation loss: 2.050538510084152

Epoch: 5| Step: 9
Training loss: 0.2231748104095459
Validation loss: 2.0629545897245407

Epoch: 5| Step: 10
Training loss: 0.28973156213760376
Validation loss: 2.097791572411855

Epoch: 5| Step: 11
Training loss: 0.7930431365966797
Validation loss: 2.1204647223154702

Epoch: 259| Step: 0
Training loss: 0.5801981091499329
Validation loss: 2.1152280519406

Epoch: 5| Step: 1
Training loss: 0.6864255666732788
Validation loss: 2.0913994759321213

Epoch: 5| Step: 2
Training loss: 0.5133599042892456
Validation loss: 2.117589528361956

Epoch: 5| Step: 3
Training loss: 0.3002081513404846
Validation loss: 2.0570360273122787

Epoch: 5| Step: 4
Training loss: 0.396409809589386
Validation loss: 2.065546582142512

Epoch: 5| Step: 5
Training loss: 0.20981521904468536
Validation loss: 2.098320643107096

Epoch: 5| Step: 6
Training loss: 0.4151768684387207
Validation loss: 2.060169736544291

Epoch: 5| Step: 7
Training loss: 0.2123388797044754
Validation loss: 2.0951413015524545

Epoch: 5| Step: 8
Training loss: 0.2724475562572479
Validation loss: 2.0479064931472144

Epoch: 5| Step: 9
Training loss: 0.48316192626953125
Validation loss: 2.0210316628217697

Epoch: 5| Step: 10
Training loss: 0.5818073749542236
Validation loss: 2.0583312263091407

Epoch: 5| Step: 11
Training loss: 0.9791673421859741
Validation loss: 2.060031165679296

Epoch: 260| Step: 0
Training loss: 0.3974922299385071
Validation loss: 2.0404297709465027

Epoch: 5| Step: 1
Training loss: 0.35556015372276306
Validation loss: 2.0753833750883737

Epoch: 5| Step: 2
Training loss: 0.3366892337799072
Validation loss: 2.0535331716140113

Epoch: 5| Step: 3
Training loss: 0.28579649329185486
Validation loss: 2.0402573297421136

Epoch: 5| Step: 4
Training loss: 0.4979206621646881
Validation loss: 2.109602858622869

Epoch: 5| Step: 5
Training loss: 0.8071334958076477
Validation loss: 2.053785820802053

Epoch: 5| Step: 6
Training loss: 0.5299903154373169
Validation loss: 2.061575179298719

Epoch: 5| Step: 7
Training loss: 0.3408866226673126
Validation loss: 2.0460647344589233

Epoch: 5| Step: 8
Training loss: 0.2600247263908386
Validation loss: 2.071721782286962

Epoch: 5| Step: 9
Training loss: 0.8301132917404175
Validation loss: 2.138137141863505

Epoch: 5| Step: 10
Training loss: 0.3398938477039337
Validation loss: 2.1349191466967263

Epoch: 5| Step: 11
Training loss: 0.3646916151046753
Validation loss: 2.1462168196837106

Epoch: 261| Step: 0
Training loss: 0.48903828859329224
Validation loss: 2.1370928436517715

Epoch: 5| Step: 1
Training loss: 0.2899583876132965
Validation loss: 2.0917282104492188

Epoch: 5| Step: 2
Training loss: 0.2727169692516327
Validation loss: 2.08957846959432

Epoch: 5| Step: 3
Training loss: 0.7555927038192749
Validation loss: 2.092717707157135

Epoch: 5| Step: 4
Training loss: 0.5326229333877563
Validation loss: 2.0351103295882544

Epoch: 5| Step: 5
Training loss: 0.676200270652771
Validation loss: 2.0661452809969583

Epoch: 5| Step: 6
Training loss: 0.5691183805465698
Validation loss: 2.08224123219649

Epoch: 5| Step: 7
Training loss: 0.34606534242630005
Validation loss: 2.090040107568105

Epoch: 5| Step: 8
Training loss: 0.6749123334884644
Validation loss: 2.096727798382441

Epoch: 5| Step: 9
Training loss: 0.5778566002845764
Validation loss: 2.161528338988622

Epoch: 5| Step: 10
Training loss: 0.5176621675491333
Validation loss: 2.1383410592873893

Epoch: 5| Step: 11
Training loss: 0.6873602867126465
Validation loss: 2.0868437737226486

Epoch: 262| Step: 0
Training loss: 0.4234631657600403
Validation loss: 2.088225503762563

Epoch: 5| Step: 1
Training loss: 0.5250980257987976
Validation loss: 2.0578060994545617

Epoch: 5| Step: 2
Training loss: 0.5547629594802856
Validation loss: 2.044499456882477

Epoch: 5| Step: 3
Training loss: 0.4604189991950989
Validation loss: 2.0633176267147064

Epoch: 5| Step: 4
Training loss: 0.5371292233467102
Validation loss: 2.0206115444501243

Epoch: 5| Step: 5
Training loss: 0.49676522612571716
Validation loss: 2.0129804412523904

Epoch: 5| Step: 6
Training loss: 0.3804686367511749
Validation loss: 2.0667471637328467

Epoch: 5| Step: 7
Training loss: 0.3201388716697693
Validation loss: 2.129678353667259

Epoch: 5| Step: 8
Training loss: 0.5005103349685669
Validation loss: 2.161237215002378

Epoch: 5| Step: 9
Training loss: 0.41311711072921753
Validation loss: 2.120997056365013

Epoch: 5| Step: 10
Training loss: 0.7462280988693237
Validation loss: 2.104501575231552

Epoch: 5| Step: 11
Training loss: 1.4861397743225098
Validation loss: 2.049629052480062

Epoch: 263| Step: 0
Training loss: 0.2802557051181793
Validation loss: 2.069836656252543

Epoch: 5| Step: 1
Training loss: 0.47273167967796326
Validation loss: 2.074415589372317

Epoch: 5| Step: 2
Training loss: 0.36411577463150024
Validation loss: 2.053007577856382

Epoch: 5| Step: 3
Training loss: 0.47740039229393005
Validation loss: 2.0503337432940802

Epoch: 5| Step: 4
Training loss: 0.5849906206130981
Validation loss: 2.0766662110884986

Epoch: 5| Step: 5
Training loss: 0.27115583419799805
Validation loss: 2.0004954983790717

Epoch: 5| Step: 6
Training loss: 0.547073483467102
Validation loss: 2.0714187026023865

Epoch: 5| Step: 7
Training loss: 0.19933031499385834
Validation loss: 2.0308380822340646

Epoch: 5| Step: 8
Training loss: 0.5911799669265747
Validation loss: 2.0718085914850235

Epoch: 5| Step: 9
Training loss: 0.36716338992118835
Validation loss: 2.0618408719698587

Epoch: 5| Step: 10
Training loss: 0.6223201155662537
Validation loss: 2.0927448918422065

Epoch: 5| Step: 11
Training loss: 0.3208058476448059
Validation loss: 2.070176288485527

Epoch: 264| Step: 0
Training loss: 0.5253806710243225
Validation loss: 2.060667102535566

Epoch: 5| Step: 1
Training loss: 0.4104824662208557
Validation loss: 2.091523975133896

Epoch: 5| Step: 2
Training loss: 0.38734734058380127
Validation loss: 2.0811003297567368

Epoch: 5| Step: 3
Training loss: 0.390118807554245
Validation loss: 2.020401398340861

Epoch: 5| Step: 4
Training loss: 0.3916723132133484
Validation loss: 2.0701046685377755

Epoch: 5| Step: 5
Training loss: 0.2862303853034973
Validation loss: 2.0721921970446906

Epoch: 5| Step: 6
Training loss: 0.6970309019088745
Validation loss: 2.09610881904761

Epoch: 5| Step: 7
Training loss: 0.349546879529953
Validation loss: 2.0415372600158057

Epoch: 5| Step: 8
Training loss: 0.5491541028022766
Validation loss: 2.0931662718454995

Epoch: 5| Step: 9
Training loss: 0.6085965633392334
Validation loss: 2.0805152505636215

Epoch: 5| Step: 10
Training loss: 0.4112098813056946
Validation loss: 2.087374488512675

Epoch: 5| Step: 11
Training loss: 0.8640378713607788
Validation loss: 2.023976410428683

Epoch: 265| Step: 0
Training loss: 0.35193508863449097
Validation loss: 2.0803981771071753

Epoch: 5| Step: 1
Training loss: 0.30028319358825684
Validation loss: 2.0648079266150794

Epoch: 5| Step: 2
Training loss: 0.589117169380188
Validation loss: 2.069910700122515

Epoch: 5| Step: 3
Training loss: 0.47499561309814453
Validation loss: 2.0763416240612664

Epoch: 5| Step: 4
Training loss: 0.23048385977745056
Validation loss: 2.096079389254252

Epoch: 5| Step: 5
Training loss: 0.522921621799469
Validation loss: 2.0404877066612244

Epoch: 5| Step: 6
Training loss: 0.6952529549598694
Validation loss: 2.0027025789022446

Epoch: 5| Step: 7
Training loss: 0.6171832084655762
Validation loss: 2.0319738537073135

Epoch: 5| Step: 8
Training loss: 0.24826177954673767
Validation loss: 2.016555666923523

Epoch: 5| Step: 9
Training loss: 0.191152423620224
Validation loss: 2.0603170494238534

Epoch: 5| Step: 10
Training loss: 0.41053372621536255
Validation loss: 2.022132451335589

Epoch: 5| Step: 11
Training loss: 0.33723926544189453
Validation loss: 2.0649962971607843

Epoch: 266| Step: 0
Training loss: 0.7610229253768921
Validation loss: 2.0745827108621597

Epoch: 5| Step: 1
Training loss: 0.23895898461341858
Validation loss: 2.1094702581564584

Epoch: 5| Step: 2
Training loss: 0.31886884570121765
Validation loss: 2.08855007092158

Epoch: 5| Step: 3
Training loss: 0.19650574028491974
Validation loss: 2.0608422607183456

Epoch: 5| Step: 4
Training loss: 0.45856794714927673
Validation loss: 2.048685530821482

Epoch: 5| Step: 5
Training loss: 0.5481619238853455
Validation loss: 2.014075676600138

Epoch: 5| Step: 6
Training loss: 0.8642804026603699
Validation loss: 2.0130513509114585

Epoch: 5| Step: 7
Training loss: 0.4551723003387451
Validation loss: 2.0005503793557486

Epoch: 5| Step: 8
Training loss: 0.23521466553211212
Validation loss: 2.021324545145035

Epoch: 5| Step: 9
Training loss: 0.4459245800971985
Validation loss: 2.0855261186758676

Epoch: 5| Step: 10
Training loss: 0.29631680250167847
Validation loss: 2.0548406591018042

Epoch: 5| Step: 11
Training loss: 0.2596704065799713
Validation loss: 2.0931782325108848

Epoch: 267| Step: 0
Training loss: 0.5901305675506592
Validation loss: 2.111578310529391

Epoch: 5| Step: 1
Training loss: 0.2304258644580841
Validation loss: 2.076655546824137

Epoch: 5| Step: 2
Training loss: 0.6791143417358398
Validation loss: 2.0406078894933066

Epoch: 5| Step: 3
Training loss: 0.6197525262832642
Validation loss: 2.0208858797947564

Epoch: 5| Step: 4
Training loss: 0.1552310436964035
Validation loss: 2.0571096489826837

Epoch: 5| Step: 5
Training loss: 0.448218435049057
Validation loss: 2.0881220002969108

Epoch: 5| Step: 6
Training loss: 0.3103804886341095
Validation loss: 2.021409605940183

Epoch: 5| Step: 7
Training loss: 0.34258022904396057
Validation loss: 2.0518619815508523

Epoch: 5| Step: 8
Training loss: 0.24038013815879822
Validation loss: 2.0524868915478387

Epoch: 5| Step: 9
Training loss: 0.610693097114563
Validation loss: 2.1101307421922684

Epoch: 5| Step: 10
Training loss: 0.4883325695991516
Validation loss: 2.064959079027176

Epoch: 5| Step: 11
Training loss: 1.1680934429168701
Validation loss: 2.0960862139860788

Epoch: 268| Step: 0
Training loss: 0.5438259243965149
Validation loss: 2.134189893802007

Epoch: 5| Step: 1
Training loss: 0.2593438923358917
Validation loss: 2.1210868706305823

Epoch: 5| Step: 2
Training loss: 0.4907073378562927
Validation loss: 2.0736636569102607

Epoch: 5| Step: 3
Training loss: 0.4530482292175293
Validation loss: 2.0357406040032706

Epoch: 5| Step: 4
Training loss: 0.3499670922756195
Validation loss: 2.056949625412623

Epoch: 5| Step: 5
Training loss: 0.6117085218429565
Validation loss: 2.0856285393238068

Epoch: 5| Step: 6
Training loss: 0.749430775642395
Validation loss: 2.0335600078105927

Epoch: 5| Step: 7
Training loss: 0.5031110644340515
Validation loss: 2.080974822243055

Epoch: 5| Step: 8
Training loss: 0.2845373749732971
Validation loss: 2.084506948788961

Epoch: 5| Step: 9
Training loss: 0.3449147343635559
Validation loss: 2.0983792394399643

Epoch: 5| Step: 10
Training loss: 0.39170390367507935
Validation loss: 2.1497539430856705

Epoch: 5| Step: 11
Training loss: 0.20327001810073853
Validation loss: 2.1562337627013526

Epoch: 269| Step: 0
Training loss: 1.0824750661849976
Validation loss: 2.1649816830952964

Epoch: 5| Step: 1
Training loss: 0.552324652671814
Validation loss: 2.137176513671875

Epoch: 5| Step: 2
Training loss: 0.19503673911094666
Validation loss: 2.0643684367338815

Epoch: 5| Step: 3
Training loss: 0.29039883613586426
Validation loss: 2.0770096431175866

Epoch: 5| Step: 4
Training loss: 0.4890589118003845
Validation loss: 2.0379245529572168

Epoch: 5| Step: 5
Training loss: 0.5475805401802063
Validation loss: 2.0205089449882507

Epoch: 5| Step: 6
Training loss: 0.2851220965385437
Validation loss: 2.039510801434517

Epoch: 5| Step: 7
Training loss: 0.5936926603317261
Validation loss: 2.0516778777043023

Epoch: 5| Step: 8
Training loss: 0.24059417843818665
Validation loss: 2.054410273830096

Epoch: 5| Step: 9
Training loss: 0.3592032790184021
Validation loss: 2.0887076556682587

Epoch: 5| Step: 10
Training loss: 0.4315888285636902
Validation loss: 2.070356676975886

Epoch: 5| Step: 11
Training loss: 0.12623971700668335
Validation loss: 2.0337124317884445

Epoch: 270| Step: 0
Training loss: 0.26583585143089294
Validation loss: 2.08487735191981

Epoch: 5| Step: 1
Training loss: 0.3010888695716858
Validation loss: 2.1098361164331436

Epoch: 5| Step: 2
Training loss: 0.5694769024848938
Validation loss: 2.063644071420034

Epoch: 5| Step: 3
Training loss: 0.4085591435432434
Validation loss: 2.0375873098770776

Epoch: 5| Step: 4
Training loss: 0.33291640877723694
Validation loss: 2.004378249247869

Epoch: 5| Step: 5
Training loss: 0.5487641096115112
Validation loss: 2.0932688117027283

Epoch: 5| Step: 6
Training loss: 0.32081207633018494
Validation loss: 2.0135970612366996

Epoch: 5| Step: 7
Training loss: 0.384645938873291
Validation loss: 2.0614901234706244

Epoch: 5| Step: 8
Training loss: 0.5289185643196106
Validation loss: 2.044564222296079

Epoch: 5| Step: 9
Training loss: 0.2668248116970062
Validation loss: 2.0563306907812753

Epoch: 5| Step: 10
Training loss: 0.654706597328186
Validation loss: 2.0505898147821426

Epoch: 5| Step: 11
Training loss: 0.1643577218055725
Validation loss: 2.089168041944504

Epoch: 271| Step: 0
Training loss: 0.612242579460144
Validation loss: 2.085397640864054

Epoch: 5| Step: 1
Training loss: 0.15838339924812317
Validation loss: 2.0357641528050103

Epoch: 5| Step: 2
Training loss: 0.19416357576847076
Validation loss: 2.070374925931295

Epoch: 5| Step: 3
Training loss: 0.34344401955604553
Validation loss: 2.04075925052166

Epoch: 5| Step: 4
Training loss: 0.23713068664073944
Validation loss: 2.0772305876016617

Epoch: 5| Step: 5
Training loss: 0.3151474893093109
Validation loss: 2.042602856953939

Epoch: 5| Step: 6
Training loss: 0.3917725682258606
Validation loss: 2.0696138441562653

Epoch: 5| Step: 7
Training loss: 0.5500994920730591
Validation loss: 1.9918641398350398

Epoch: 5| Step: 8
Training loss: 0.6632077097892761
Validation loss: 2.017732342084249

Epoch: 5| Step: 9
Training loss: 0.39798909425735474
Validation loss: 2.0639885663986206

Epoch: 5| Step: 10
Training loss: 0.34518998861312866
Validation loss: 2.0543337961037955

Epoch: 5| Step: 11
Training loss: 0.4771193265914917
Validation loss: 2.0419542839129767

Epoch: 272| Step: 0
Training loss: 0.2996627688407898
Validation loss: 2.072559580206871

Epoch: 5| Step: 1
Training loss: 0.4071876108646393
Validation loss: 2.0834137946367264

Epoch: 5| Step: 2
Training loss: 0.43534621596336365
Validation loss: 2.0799572517474494

Epoch: 5| Step: 3
Training loss: 0.43377724289894104
Validation loss: 2.107489734888077

Epoch: 5| Step: 4
Training loss: 0.3333950936794281
Validation loss: 2.0518423120180764

Epoch: 5| Step: 5
Training loss: 0.41887226700782776
Validation loss: 2.0980015893777213

Epoch: 5| Step: 6
Training loss: 0.7068377733230591
Validation loss: 2.0917087346315384

Epoch: 5| Step: 7
Training loss: 0.3843003809452057
Validation loss: 2.0484597980976105

Epoch: 5| Step: 8
Training loss: 0.329346239566803
Validation loss: 2.0788987229267755

Epoch: 5| Step: 9
Training loss: 0.33227771520614624
Validation loss: 2.1023400723934174

Epoch: 5| Step: 10
Training loss: 0.35085105895996094
Validation loss: 2.075554832816124

Epoch: 5| Step: 11
Training loss: 0.2535129189491272
Validation loss: 2.0602490504582724

Epoch: 273| Step: 0
Training loss: 0.2821751534938812
Validation loss: 2.116680527726809

Epoch: 5| Step: 1
Training loss: 0.37562572956085205
Validation loss: 2.0711509933074317

Epoch: 5| Step: 2
Training loss: 0.5815312266349792
Validation loss: 2.0879463652769723

Epoch: 5| Step: 3
Training loss: 0.41701823472976685
Validation loss: 2.1151759773492813

Epoch: 5| Step: 4
Training loss: 0.5512259602546692
Validation loss: 2.044075240691503

Epoch: 5| Step: 5
Training loss: 0.5848941802978516
Validation loss: 2.0777407934268317

Epoch: 5| Step: 6
Training loss: 0.6909915804862976
Validation loss: 2.0196675807237625

Epoch: 5| Step: 7
Training loss: 0.5388460159301758
Validation loss: 2.0440199226140976

Epoch: 5| Step: 8
Training loss: 0.22519496083259583
Validation loss: 2.0943147937456765

Epoch: 5| Step: 9
Training loss: 0.24779653549194336
Validation loss: 2.0995645026365914

Epoch: 5| Step: 10
Training loss: 0.3682946562767029
Validation loss: 2.0929886599381766

Epoch: 5| Step: 11
Training loss: 0.5637801885604858
Validation loss: 2.0958326856295266

Epoch: 274| Step: 0
Training loss: 0.40076160430908203
Validation loss: 2.1317426363627114

Epoch: 5| Step: 1
Training loss: 0.7241631746292114
Validation loss: 2.078654577334722

Epoch: 5| Step: 2
Training loss: 0.3356897830963135
Validation loss: 2.031712328394254

Epoch: 5| Step: 3
Training loss: 0.39936363697052
Validation loss: 2.0269116262594857

Epoch: 5| Step: 4
Training loss: 0.5627943873405457
Validation loss: 2.0652964264154434

Epoch: 5| Step: 5
Training loss: 0.30399030447006226
Validation loss: 2.0537712424993515

Epoch: 5| Step: 6
Training loss: 0.4606700837612152
Validation loss: 2.033475528160731

Epoch: 5| Step: 7
Training loss: 0.3689475655555725
Validation loss: 2.0957797169685364

Epoch: 5| Step: 8
Training loss: 0.26076698303222656
Validation loss: 2.0879627466201782

Epoch: 5| Step: 9
Training loss: 0.3081950545310974
Validation loss: 2.071798155705134

Epoch: 5| Step: 10
Training loss: 0.4028785228729248
Validation loss: 2.1016770203908286

Epoch: 5| Step: 11
Training loss: 0.440945029258728
Validation loss: 2.0924014896154404

Epoch: 275| Step: 0
Training loss: 0.4397432804107666
Validation loss: 2.108469848831495

Epoch: 5| Step: 1
Training loss: 0.4231143593788147
Validation loss: 2.09471203883489

Epoch: 5| Step: 2
Training loss: 0.32242536544799805
Validation loss: 2.112397780021032

Epoch: 5| Step: 3
Training loss: 0.491593599319458
Validation loss: 2.0458874901135764

Epoch: 5| Step: 4
Training loss: 0.4575793147087097
Validation loss: 2.041654278834661

Epoch: 5| Step: 5
Training loss: 0.4937329888343811
Validation loss: 2.107315773765246

Epoch: 5| Step: 6
Training loss: 0.4986611008644104
Validation loss: 2.0634767760833106

Epoch: 5| Step: 7
Training loss: 0.3836689889431
Validation loss: 2.065017431974411

Epoch: 5| Step: 8
Training loss: 0.47875794768333435
Validation loss: 2.0542549987634025

Epoch: 5| Step: 9
Training loss: 0.30649980902671814
Validation loss: 2.0532623579104743

Epoch: 5| Step: 10
Training loss: 0.3329991400241852
Validation loss: 2.066090057293574

Epoch: 5| Step: 11
Training loss: 0.27347344160079956
Validation loss: 2.0845694740613303

Epoch: 276| Step: 0
Training loss: 0.32815441489219666
Validation loss: 2.0684715459744134

Epoch: 5| Step: 1
Training loss: 0.25204533338546753
Validation loss: 2.1359270413716636

Epoch: 5| Step: 2
Training loss: 0.42249375581741333
Validation loss: 2.113263820608457

Epoch: 5| Step: 3
Training loss: 0.7465507388114929
Validation loss: 2.089400996764501

Epoch: 5| Step: 4
Training loss: 0.3524107336997986
Validation loss: 2.062781815727552

Epoch: 5| Step: 5
Training loss: 0.26614513993263245
Validation loss: 2.0736732433239617

Epoch: 5| Step: 6
Training loss: 0.26438334584236145
Validation loss: 2.0799334943294525

Epoch: 5| Step: 7
Training loss: 0.357077419757843
Validation loss: 2.059736281633377

Epoch: 5| Step: 8
Training loss: 0.31445690989494324
Validation loss: 2.0787969330946603

Epoch: 5| Step: 9
Training loss: 0.3036343455314636
Validation loss: 2.1157953341801963

Epoch: 5| Step: 10
Training loss: 0.6735143065452576
Validation loss: 2.102363338073095

Epoch: 5| Step: 11
Training loss: 1.64395272731781
Validation loss: 2.0504129379987717

Epoch: 277| Step: 0
Training loss: 0.48810309171676636
Validation loss: 2.0792290965716043

Epoch: 5| Step: 1
Training loss: 0.2924858629703522
Validation loss: 2.0321051528056464

Epoch: 5| Step: 2
Training loss: 0.3873249888420105
Validation loss: 2.0646512607733407

Epoch: 5| Step: 3
Training loss: 0.4219636917114258
Validation loss: 2.0578312973181405

Epoch: 5| Step: 4
Training loss: 0.9264510869979858
Validation loss: 2.0420719335476556

Epoch: 5| Step: 5
Training loss: 0.2800263464450836
Validation loss: 2.049410954117775

Epoch: 5| Step: 6
Training loss: 0.25892797112464905
Validation loss: 2.0794928272565207

Epoch: 5| Step: 7
Training loss: 0.2739184498786926
Validation loss: 2.066903069615364

Epoch: 5| Step: 8
Training loss: 0.2753799855709076
Validation loss: 2.081912562251091

Epoch: 5| Step: 9
Training loss: 0.9384291768074036
Validation loss: 2.090917939941088

Epoch: 5| Step: 10
Training loss: 0.23482279479503632
Validation loss: 2.1089702347914376

Epoch: 5| Step: 11
Training loss: 0.2736239433288574
Validation loss: 2.065033773581187

Epoch: 278| Step: 0
Training loss: 0.2060709297657013
Validation loss: 2.038736934463183

Epoch: 5| Step: 1
Training loss: 0.49153071641921997
Validation loss: 2.0169350057840347

Epoch: 5| Step: 2
Training loss: 0.28842225670814514
Validation loss: 2.069706733028094

Epoch: 5| Step: 3
Training loss: 0.7970361709594727
Validation loss: 2.071379527449608

Epoch: 5| Step: 4
Training loss: 0.5213125944137573
Validation loss: 2.0503272265195847

Epoch: 5| Step: 5
Training loss: 0.21028709411621094
Validation loss: 2.030070409178734

Epoch: 5| Step: 6
Training loss: 0.4315429627895355
Validation loss: 2.03942908346653

Epoch: 5| Step: 7
Training loss: 0.5980420112609863
Validation loss: 2.0519083042939505

Epoch: 5| Step: 8
Training loss: 0.47429853677749634
Validation loss: 2.0236712247133255

Epoch: 5| Step: 9
Training loss: 0.25057756900787354
Validation loss: 2.059840351343155

Epoch: 5| Step: 10
Training loss: 0.34058600664138794
Validation loss: 2.041062737504641

Epoch: 5| Step: 11
Training loss: 0.2815859317779541
Validation loss: 2.0696749538183212

Epoch: 279| Step: 0
Training loss: 0.28343361616134644
Validation loss: 2.0756882975498834

Epoch: 5| Step: 1
Training loss: 0.49031171202659607
Validation loss: 2.1092731952667236

Epoch: 5| Step: 2
Training loss: 0.7237871885299683
Validation loss: 2.0556035240491233

Epoch: 5| Step: 3
Training loss: 0.2319195717573166
Validation loss: 2.0747990111509957

Epoch: 5| Step: 4
Training loss: 0.2613133192062378
Validation loss: 2.0424602578083673

Epoch: 5| Step: 5
Training loss: 0.7211796641349792
Validation loss: 2.06232317785422

Epoch: 5| Step: 6
Training loss: 0.4332989752292633
Validation loss: 2.0543869733810425

Epoch: 5| Step: 7
Training loss: 0.4503664970397949
Validation loss: 2.043456867337227

Epoch: 5| Step: 8
Training loss: 0.33875390887260437
Validation loss: 2.0584133863449097

Epoch: 5| Step: 9
Training loss: 0.4313804507255554
Validation loss: 2.0731545190016427

Epoch: 5| Step: 10
Training loss: 0.2085806429386139
Validation loss: 2.0386546750863395

Epoch: 5| Step: 11
Training loss: 0.1668146848678589
Validation loss: 2.06296776731809

Epoch: 280| Step: 0
Training loss: 0.37677061557769775
Validation loss: 2.115024834871292

Epoch: 5| Step: 1
Training loss: 0.3148322105407715
Validation loss: 2.1186755498250327

Epoch: 5| Step: 2
Training loss: 0.5031765103340149
Validation loss: 2.108623350660006

Epoch: 5| Step: 3
Training loss: 0.780646026134491
Validation loss: 2.0544326404730477

Epoch: 5| Step: 4
Training loss: 0.33989855647087097
Validation loss: 2.026310980319977

Epoch: 5| Step: 5
Training loss: 0.29934263229370117
Validation loss: 2.0316310971975327

Epoch: 5| Step: 6
Training loss: 0.3439008295536041
Validation loss: 2.0352525413036346

Epoch: 5| Step: 7
Training loss: 0.37343868613243103
Validation loss: 2.0344879229863486

Epoch: 5| Step: 8
Training loss: 0.640423595905304
Validation loss: 2.054221987724304

Epoch: 5| Step: 9
Training loss: 0.3822273313999176
Validation loss: 2.0922362953424454

Epoch: 5| Step: 10
Training loss: 0.39580675959587097
Validation loss: 2.0376580903927484

Epoch: 5| Step: 11
Training loss: 0.23983001708984375
Validation loss: 2.0940187523762384

Epoch: 281| Step: 0
Training loss: 0.39497074484825134
Validation loss: 2.0561988850434623

Epoch: 5| Step: 1
Training loss: 0.45580893754959106
Validation loss: 2.1038615504900613

Epoch: 5| Step: 2
Training loss: 0.4648422300815582
Validation loss: 2.080793251593908

Epoch: 5| Step: 3
Training loss: 0.6216182112693787
Validation loss: 2.079681615034739

Epoch: 5| Step: 4
Training loss: 0.20214274525642395
Validation loss: 2.086506888270378

Epoch: 5| Step: 5
Training loss: 0.5196093320846558
Validation loss: 2.0817216436068215

Epoch: 5| Step: 6
Training loss: 0.45733919739723206
Validation loss: 2.064425547917684

Epoch: 5| Step: 7
Training loss: 0.2942975163459778
Validation loss: 2.0327189515034356

Epoch: 5| Step: 8
Training loss: 0.22620482742786407
Validation loss: 2.0599872221549353

Epoch: 5| Step: 9
Training loss: 0.5426822900772095
Validation loss: 2.0427969694137573

Epoch: 5| Step: 10
Training loss: 0.4114409387111664
Validation loss: 2.0569109370311103

Epoch: 5| Step: 11
Training loss: 0.7626965045928955
Validation loss: 2.094486956795057

Epoch: 282| Step: 0
Training loss: 0.2997637093067169
Validation loss: 2.0704961071411767

Epoch: 5| Step: 1
Training loss: 0.698971152305603
Validation loss: 2.081165000796318

Epoch: 5| Step: 2
Training loss: 0.36543408036231995
Validation loss: 2.071593483289083

Epoch: 5| Step: 3
Training loss: 0.22826921939849854
Validation loss: 2.068686311443647

Epoch: 5| Step: 4
Training loss: 0.3672358989715576
Validation loss: 2.0847122768561044

Epoch: 5| Step: 5
Training loss: 0.14689287543296814
Validation loss: 2.086929644147555

Epoch: 5| Step: 6
Training loss: 0.4921835958957672
Validation loss: 2.058987557888031

Epoch: 5| Step: 7
Training loss: 0.592276930809021
Validation loss: 2.066700577735901

Epoch: 5| Step: 8
Training loss: 0.31807777285575867
Validation loss: 2.081188604235649

Epoch: 5| Step: 9
Training loss: 0.40318888425827026
Validation loss: 2.0716228087743125

Epoch: 5| Step: 10
Training loss: 0.2750605642795563
Validation loss: 2.084080398082733

Epoch: 5| Step: 11
Training loss: 0.2588239014148712
Validation loss: 2.0550221502780914

Epoch: 283| Step: 0
Training loss: 0.28411921858787537
Validation loss: 2.0607638359069824

Epoch: 5| Step: 1
Training loss: 0.43220406770706177
Validation loss: 2.0943831553061805

Epoch: 5| Step: 2
Training loss: 0.4970870912075043
Validation loss: 2.092075372735659

Epoch: 5| Step: 3
Training loss: 0.1944829225540161
Validation loss: 2.0601909458637238

Epoch: 5| Step: 4
Training loss: 0.40202903747558594
Validation loss: 2.05765800178051

Epoch: 5| Step: 5
Training loss: 0.29357409477233887
Validation loss: 2.072006811698278

Epoch: 5| Step: 6
Training loss: 0.5002384185791016
Validation loss: 2.050518279274305

Epoch: 5| Step: 7
Training loss: 0.42627421021461487
Validation loss: 2.0973529666662216

Epoch: 5| Step: 8
Training loss: 0.4536920487880707
Validation loss: 2.0724225292603173

Epoch: 5| Step: 9
Training loss: 0.6239431500434875
Validation loss: 2.0940485099951425

Epoch: 5| Step: 10
Training loss: 0.34003379940986633
Validation loss: 2.0678542455037436

Epoch: 5| Step: 11
Training loss: 0.19067531824111938
Validation loss: 2.0848349034786224

Epoch: 284| Step: 0
Training loss: 0.46393880248069763
Validation loss: 2.037722816069921

Epoch: 5| Step: 1
Training loss: 0.3388768434524536
Validation loss: 2.0465393662452698

Epoch: 5| Step: 2
Training loss: 0.8547824025154114
Validation loss: 2.026671980818113

Epoch: 5| Step: 3
Training loss: 0.2550570070743561
Validation loss: 2.0515744338432946

Epoch: 5| Step: 4
Training loss: 0.45845240354537964
Validation loss: 2.066472520430883

Epoch: 5| Step: 5
Training loss: 0.25501078367233276
Validation loss: 2.0303211510181427

Epoch: 5| Step: 6
Training loss: 0.36142486333847046
Validation loss: 2.055683434009552

Epoch: 5| Step: 7
Training loss: 0.20605996251106262
Validation loss: 2.026764005422592

Epoch: 5| Step: 8
Training loss: 0.40471333265304565
Validation loss: 2.067782700061798

Epoch: 5| Step: 9
Training loss: 0.30179068446159363
Validation loss: 2.0738004446029663

Epoch: 5| Step: 10
Training loss: 0.3637855052947998
Validation loss: 2.075311372677485

Epoch: 5| Step: 11
Training loss: 0.2821890711784363
Validation loss: 2.048965742190679

Epoch: 285| Step: 0
Training loss: 0.35826343297958374
Validation loss: 2.037888397773107

Epoch: 5| Step: 1
Training loss: 0.543533444404602
Validation loss: 2.035250892241796

Epoch: 5| Step: 2
Training loss: 0.22673079371452332
Validation loss: 2.028985937436422

Epoch: 5| Step: 3
Training loss: 0.40297824144363403
Validation loss: 2.055937170982361

Epoch: 5| Step: 4
Training loss: 0.29517683386802673
Validation loss: 2.1114528328180313

Epoch: 5| Step: 5
Training loss: 0.5916544795036316
Validation loss: 2.0657936880985894

Epoch: 5| Step: 6
Training loss: 0.2522375285625458
Validation loss: 2.123576502005259

Epoch: 5| Step: 7
Training loss: 0.5822013020515442
Validation loss: 2.0858858128388724

Epoch: 5| Step: 8
Training loss: 0.3332235813140869
Validation loss: 2.0360795855522156

Epoch: 5| Step: 9
Training loss: 0.4776289463043213
Validation loss: 2.0558525025844574

Epoch: 5| Step: 10
Training loss: 0.45832452178001404
Validation loss: 2.058168957630793

Epoch: 5| Step: 11
Training loss: 0.5138038396835327
Validation loss: 2.0488052467505136

Epoch: 286| Step: 0
Training loss: 0.3383505940437317
Validation loss: 2.0753908455371857

Epoch: 5| Step: 1
Training loss: 0.3716621696949005
Validation loss: 2.055487707257271

Epoch: 5| Step: 2
Training loss: 0.4006187319755554
Validation loss: 2.0785316626230874

Epoch: 5| Step: 3
Training loss: 0.389480322599411
Validation loss: 2.094185953338941

Epoch: 5| Step: 4
Training loss: 0.8963832855224609
Validation loss: 2.0839462727308273

Epoch: 5| Step: 5
Training loss: 0.6292137503623962
Validation loss: 2.0294012973705926

Epoch: 5| Step: 6
Training loss: 0.33032524585723877
Validation loss: 2.136589099963506

Epoch: 5| Step: 7
Training loss: 0.4785154461860657
Validation loss: 2.0337774008512497

Epoch: 5| Step: 8
Training loss: 0.24382826685905457
Validation loss: 2.0746332506338754

Epoch: 5| Step: 9
Training loss: 0.2541734278202057
Validation loss: 2.093374306956927

Epoch: 5| Step: 10
Training loss: 0.5882866382598877
Validation loss: 2.085939879218737

Epoch: 5| Step: 11
Training loss: 0.1743873953819275
Validation loss: 2.061779941121737

Epoch: 287| Step: 0
Training loss: 0.26636725664138794
Validation loss: 2.1017414232095084

Epoch: 5| Step: 1
Training loss: 0.3880500793457031
Validation loss: 2.1049047708511353

Epoch: 5| Step: 2
Training loss: 0.4365813136100769
Validation loss: 2.1197980841000876

Epoch: 5| Step: 3
Training loss: 0.7930399179458618
Validation loss: 2.1972065220276513

Epoch: 5| Step: 4
Training loss: 0.3436060845851898
Validation loss: 2.155917222301165

Epoch: 5| Step: 5
Training loss: 0.34629201889038086
Validation loss: 2.094189335902532

Epoch: 5| Step: 6
Training loss: 0.29383617639541626
Validation loss: 2.0650337040424347

Epoch: 5| Step: 7
Training loss: 0.2881189286708832
Validation loss: 2.084230567018191

Epoch: 5| Step: 8
Training loss: 0.5880627632141113
Validation loss: 2.078947052359581

Epoch: 5| Step: 9
Training loss: 0.6762980818748474
Validation loss: 2.0704666674137115

Epoch: 5| Step: 10
Training loss: 0.6091709733009338
Validation loss: 2.037463362018267

Epoch: 5| Step: 11
Training loss: 0.16586312651634216
Validation loss: 2.042352467775345

Epoch: 288| Step: 0
Training loss: 0.5545132756233215
Validation loss: 2.0421435236930847

Epoch: 5| Step: 1
Training loss: 0.19203391671180725
Validation loss: 2.070731888214747

Epoch: 5| Step: 2
Training loss: 0.7662041783332825
Validation loss: 2.0734287848075232

Epoch: 5| Step: 3
Training loss: 0.3801364600658417
Validation loss: 2.068183327714602

Epoch: 5| Step: 4
Training loss: 0.36518579721450806
Validation loss: 2.097928668061892

Epoch: 5| Step: 5
Training loss: 0.4553184509277344
Validation loss: 2.0457575768232346

Epoch: 5| Step: 6
Training loss: 0.3385787904262543
Validation loss: 2.0773484905560813

Epoch: 5| Step: 7
Training loss: 0.32261985540390015
Validation loss: 2.0129711478948593

Epoch: 5| Step: 8
Training loss: 0.2896840572357178
Validation loss: 2.0449856420358024

Epoch: 5| Step: 9
Training loss: 0.41656094789505005
Validation loss: 2.052790900071462

Epoch: 5| Step: 10
Training loss: 0.29364246129989624
Validation loss: 2.0649837404489517

Epoch: 5| Step: 11
Training loss: 0.12028449773788452
Validation loss: 2.081595852971077

Epoch: 289| Step: 0
Training loss: 0.3099706172943115
Validation loss: 2.110362082719803

Epoch: 5| Step: 1
Training loss: 0.27944105863571167
Validation loss: 2.06686236957709

Epoch: 5| Step: 2
Training loss: 0.635110080242157
Validation loss: 2.0742862671613693

Epoch: 5| Step: 3
Training loss: 0.3444964289665222
Validation loss: 2.0713222920894623

Epoch: 5| Step: 4
Training loss: 0.25257930159568787
Validation loss: 2.059047078092893

Epoch: 5| Step: 5
Training loss: 0.5941234827041626
Validation loss: 2.044911965727806

Epoch: 5| Step: 6
Training loss: 0.18054485321044922
Validation loss: 2.0702853252490363

Epoch: 5| Step: 7
Training loss: 0.6486706733703613
Validation loss: 2.0786758214235306

Epoch: 5| Step: 8
Training loss: 0.26638227701187134
Validation loss: 2.066067467133204

Epoch: 5| Step: 9
Training loss: 0.2829541563987732
Validation loss: 2.085165242354075

Epoch: 5| Step: 10
Training loss: 0.1975179761648178
Validation loss: 2.1015879263480506

Epoch: 5| Step: 11
Training loss: 0.7209075093269348
Validation loss: 2.0416056762139

Epoch: 290| Step: 0
Training loss: 0.6328485012054443
Validation loss: 2.0423284272352853

Epoch: 5| Step: 1
Training loss: 0.46696051955223083
Validation loss: 2.0948383162419

Epoch: 5| Step: 2
Training loss: 0.21382233500480652
Validation loss: 2.072998876372973

Epoch: 5| Step: 3
Training loss: 0.30172839760780334
Validation loss: 2.054311126470566

Epoch: 5| Step: 4
Training loss: 0.19485318660736084
Validation loss: 2.056763082742691

Epoch: 5| Step: 5
Training loss: 0.41053134202957153
Validation loss: 2.0609363516171775

Epoch: 5| Step: 6
Training loss: 0.4211575984954834
Validation loss: 2.0522212237119675

Epoch: 5| Step: 7
Training loss: 0.3611163794994354
Validation loss: 2.095629781484604

Epoch: 5| Step: 8
Training loss: 0.6578620076179504
Validation loss: 2.07229737440745

Epoch: 5| Step: 9
Training loss: 0.4204055666923523
Validation loss: 2.1040495932102203

Epoch: 5| Step: 10
Training loss: 0.4256770610809326
Validation loss: 2.037374258041382

Epoch: 5| Step: 11
Training loss: 0.19032976031303406
Validation loss: 2.0645744601885476

Epoch: 291| Step: 0
Training loss: 0.39519989490509033
Validation loss: 2.087514340877533

Epoch: 5| Step: 1
Training loss: 0.2736853063106537
Validation loss: 2.031945546468099

Epoch: 5| Step: 2
Training loss: 0.1983719915151596
Validation loss: 2.072606697678566

Epoch: 5| Step: 3
Training loss: 0.27921128273010254
Validation loss: 2.052219480276108

Epoch: 5| Step: 4
Training loss: 0.3669014573097229
Validation loss: 2.084979618589083

Epoch: 5| Step: 5
Training loss: 0.5830757021903992
Validation loss: 2.0525555511315665

Epoch: 5| Step: 6
Training loss: 0.2734568119049072
Validation loss: 2.0712976406017938

Epoch: 5| Step: 7
Training loss: 0.586044430732727
Validation loss: 2.078317408760389

Epoch: 5| Step: 8
Training loss: 0.4560781419277191
Validation loss: 2.157490680615107

Epoch: 5| Step: 9
Training loss: 0.4895416796207428
Validation loss: 2.0738471001386642

Epoch: 5| Step: 10
Training loss: 0.26361751556396484
Validation loss: 2.071493665377299

Epoch: 5| Step: 11
Training loss: 0.19580543041229248
Validation loss: 2.047045335173607

Epoch: 292| Step: 0
Training loss: 0.3563805818557739
Validation loss: 2.0655811180671058

Epoch: 5| Step: 1
Training loss: 0.3536762595176697
Validation loss: 2.0421881477038064

Epoch: 5| Step: 2
Training loss: 0.32541826367378235
Validation loss: 2.0766271352767944

Epoch: 5| Step: 3
Training loss: 0.42878228425979614
Validation loss: 2.0585133781035743

Epoch: 5| Step: 4
Training loss: 0.4977753758430481
Validation loss: 2.025335962573687

Epoch: 5| Step: 5
Training loss: 0.25346246361732483
Validation loss: 2.073792318503062

Epoch: 5| Step: 6
Training loss: 0.9011355638504028
Validation loss: 2.076433847347895

Epoch: 5| Step: 7
Training loss: 0.6546839475631714
Validation loss: 2.101074447234472

Epoch: 5| Step: 8
Training loss: 0.3674187660217285
Validation loss: 2.1071231762568154

Epoch: 5| Step: 9
Training loss: 0.2940860688686371
Validation loss: 2.1327783465385437

Epoch: 5| Step: 10
Training loss: 0.36613279581069946
Validation loss: 2.0704147617022195

Epoch: 5| Step: 11
Training loss: 0.33181798458099365
Validation loss: 2.040233706434568

Epoch: 293| Step: 0
Training loss: 0.16163048148155212
Validation loss: 2.0168484846750894

Epoch: 5| Step: 1
Training loss: 0.6519302129745483
Validation loss: 2.0893373638391495

Epoch: 5| Step: 2
Training loss: 0.29336297512054443
Validation loss: 2.046089828014374

Epoch: 5| Step: 3
Training loss: 0.4310692846775055
Validation loss: 2.0807287146647773

Epoch: 5| Step: 4
Training loss: 0.35086360573768616
Validation loss: 2.0575361847877502

Epoch: 5| Step: 5
Training loss: 0.35544416308403015
Validation loss: 2.0611611157655716

Epoch: 5| Step: 6
Training loss: 0.23524050414562225
Validation loss: 2.0716221233208976

Epoch: 5| Step: 7
Training loss: 0.3204677104949951
Validation loss: 2.077304636438688

Epoch: 5| Step: 8
Training loss: 0.4363631308078766
Validation loss: 2.0900660902261734

Epoch: 5| Step: 9
Training loss: 0.37674611806869507
Validation loss: 2.0145762860774994

Epoch: 5| Step: 10
Training loss: 0.6011559367179871
Validation loss: 2.074150194724401

Epoch: 5| Step: 11
Training loss: 0.1878422647714615
Validation loss: 2.0449160436789193

Epoch: 294| Step: 0
Training loss: 0.19601044058799744
Validation loss: 2.0292882919311523

Epoch: 5| Step: 1
Training loss: 0.594791054725647
Validation loss: 2.063409606615702

Epoch: 5| Step: 2
Training loss: 0.40646275877952576
Validation loss: 2.0657271395126977

Epoch: 5| Step: 3
Training loss: 0.26456087827682495
Validation loss: 2.0472014248371124

Epoch: 5| Step: 4
Training loss: 0.45143041014671326
Validation loss: 2.0561260680357614

Epoch: 5| Step: 5
Training loss: 0.5036017298698425
Validation loss: 2.0238638718922934

Epoch: 5| Step: 6
Training loss: 0.36339259147644043
Validation loss: 2.023880958557129

Epoch: 5| Step: 7
Training loss: 0.29077330231666565
Validation loss: 2.0766614377498627

Epoch: 5| Step: 8
Training loss: 0.458667129278183
Validation loss: 2.0560252716143927

Epoch: 5| Step: 9
Training loss: 0.17523694038391113
Validation loss: 2.0893581807613373

Epoch: 5| Step: 10
Training loss: 0.4926597476005554
Validation loss: 2.046679750084877

Epoch: 5| Step: 11
Training loss: 0.27550452947616577
Validation loss: 2.02584537367026

Epoch: 295| Step: 0
Training loss: 0.4989745616912842
Validation loss: 2.0602337419986725

Epoch: 5| Step: 1
Training loss: 0.5746738910675049
Validation loss: 2.0450929701328278

Epoch: 5| Step: 2
Training loss: 0.31605857610702515
Validation loss: 2.0049466341733932

Epoch: 5| Step: 3
Training loss: 0.36327606439590454
Validation loss: 2.06570003926754

Epoch: 5| Step: 4
Training loss: 0.2858770489692688
Validation loss: 2.0409028828144073

Epoch: 5| Step: 5
Training loss: 0.29310154914855957
Validation loss: 2.071028341849645

Epoch: 5| Step: 6
Training loss: 0.4117962718009949
Validation loss: 2.0373101780811944

Epoch: 5| Step: 7
Training loss: 0.2464294731616974
Validation loss: 2.044480413198471

Epoch: 5| Step: 8
Training loss: 0.4842776358127594
Validation loss: 2.048518324891726

Epoch: 5| Step: 9
Training loss: 0.22913555800914764
Validation loss: 2.035764326651891

Epoch: 5| Step: 10
Training loss: 0.39734309911727905
Validation loss: 2.009283890326818

Epoch: 5| Step: 11
Training loss: 0.7990107536315918
Validation loss: 2.0500383973121643

Epoch: 296| Step: 0
Training loss: 0.7601696252822876
Validation loss: 2.0456040700276694

Epoch: 5| Step: 1
Training loss: 0.5108656883239746
Validation loss: 1.96522722641627

Epoch: 5| Step: 2
Training loss: 0.19844166934490204
Validation loss: 1.9945591290791829

Epoch: 5| Step: 3
Training loss: 0.23091597855091095
Validation loss: 2.037632495164871

Epoch: 5| Step: 4
Training loss: 0.41933995485305786
Validation loss: 2.0004326601823172

Epoch: 5| Step: 5
Training loss: 0.4007102847099304
Validation loss: 2.0372428943713508

Epoch: 5| Step: 6
Training loss: 0.4260343611240387
Validation loss: 2.0344361811876297

Epoch: 5| Step: 7
Training loss: 0.47849854826927185
Validation loss: 2.0435664355754852

Epoch: 5| Step: 8
Training loss: 0.3368673026561737
Validation loss: 2.058547630906105

Epoch: 5| Step: 9
Training loss: 0.2358894646167755
Validation loss: 2.029497280716896

Epoch: 5| Step: 10
Training loss: 0.20096977055072784
Validation loss: 2.0444338619709015

Epoch: 5| Step: 11
Training loss: 0.3150777816772461
Validation loss: 2.041510949532191

Epoch: 297| Step: 0
Training loss: 0.24514050781726837
Validation loss: 2.025006244579951

Epoch: 5| Step: 1
Training loss: 0.8725466728210449
Validation loss: 2.0049377431472144

Epoch: 5| Step: 2
Training loss: 0.49474865198135376
Validation loss: 1.9997029155492783

Epoch: 5| Step: 3
Training loss: 0.31790003180503845
Validation loss: 2.0578480462233224

Epoch: 5| Step: 4
Training loss: 0.4336255192756653
Validation loss: 2.0434430042902627

Epoch: 5| Step: 5
Training loss: 0.5594504475593567
Validation loss: 2.0680519888798394

Epoch: 5| Step: 6
Training loss: 0.5269768834114075
Validation loss: 2.0934593876202903

Epoch: 5| Step: 7
Training loss: 0.27311939001083374
Validation loss: 2.0511472821235657

Epoch: 5| Step: 8
Training loss: 0.312673419713974
Validation loss: 2.0743622382481894

Epoch: 5| Step: 9
Training loss: 0.2751132547855377
Validation loss: 2.0614557365576425

Epoch: 5| Step: 10
Training loss: 0.2514933943748474
Validation loss: 2.0434151540199914

Epoch: 5| Step: 11
Training loss: 0.15154552459716797
Validation loss: 2.0607868830362954

Epoch: 298| Step: 0
Training loss: 0.6420903205871582
Validation loss: 2.0172963440418243

Epoch: 5| Step: 1
Training loss: 0.4410823881626129
Validation loss: 2.0441472878058753

Epoch: 5| Step: 2
Training loss: 0.5888046622276306
Validation loss: 2.06546388566494

Epoch: 5| Step: 3
Training loss: 0.40340685844421387
Validation loss: 2.0630173136790595

Epoch: 5| Step: 4
Training loss: 0.29206281900405884
Validation loss: 2.0374687810738883

Epoch: 5| Step: 5
Training loss: 0.34395870566368103
Validation loss: 2.0888714641332626

Epoch: 5| Step: 6
Training loss: 0.2727499008178711
Validation loss: 2.0713558942079544

Epoch: 5| Step: 7
Training loss: 0.441850483417511
Validation loss: 2.0860865712165833

Epoch: 5| Step: 8
Training loss: 0.21341732144355774
Validation loss: 2.0822690278291702

Epoch: 5| Step: 9
Training loss: 0.5672749280929565
Validation loss: 2.029849906762441

Epoch: 5| Step: 10
Training loss: 0.21810872852802277
Validation loss: 2.032467097043991

Epoch: 5| Step: 11
Training loss: 0.19231534004211426
Validation loss: 2.0217035859823227

Epoch: 299| Step: 0
Training loss: 0.46342867612838745
Validation loss: 2.0536539455254874

Epoch: 5| Step: 1
Training loss: 0.3357413113117218
Validation loss: 2.018192266424497

Epoch: 5| Step: 2
Training loss: 0.29694145917892456
Validation loss: 2.0747025460004807

Epoch: 5| Step: 3
Training loss: 0.3818610608577728
Validation loss: 2.021593521038691

Epoch: 5| Step: 4
Training loss: 0.6836762428283691
Validation loss: 2.0658296992381415

Epoch: 5| Step: 5
Training loss: 0.274169921875
Validation loss: 2.0358892728885016

Epoch: 5| Step: 6
Training loss: 0.1609349548816681
Validation loss: 2.038644274075826

Epoch: 5| Step: 7
Training loss: 0.3283834159374237
Validation loss: 2.0373954474925995

Epoch: 5| Step: 8
Training loss: 0.48103657364845276
Validation loss: 2.073671872417132

Epoch: 5| Step: 9
Training loss: 0.36035987734794617
Validation loss: 2.0611498107512793

Epoch: 5| Step: 10
Training loss: 0.3389498293399811
Validation loss: 2.06471519668897

Epoch: 5| Step: 11
Training loss: 0.21454524993896484
Validation loss: 2.094348972042402

Epoch: 300| Step: 0
Training loss: 0.32425788044929504
Validation loss: 2.0640083849430084

Epoch: 5| Step: 1
Training loss: 0.3645254969596863
Validation loss: 2.099277506271998

Epoch: 5| Step: 2
Training loss: 0.3409704566001892
Validation loss: 2.0181250274181366

Epoch: 5| Step: 3
Training loss: 0.26933854818344116
Validation loss: 2.0766326189041138

Epoch: 5| Step: 4
Training loss: 0.42698612809181213
Validation loss: 2.0324699133634567

Epoch: 5| Step: 5
Training loss: 0.3205791115760803
Validation loss: 2.019172822435697

Epoch: 5| Step: 6
Training loss: 0.4508887231349945
Validation loss: 2.0318581263224282

Epoch: 5| Step: 7
Training loss: 0.3690546154975891
Validation loss: 2.0582560350497565

Epoch: 5| Step: 8
Training loss: 0.7027534246444702
Validation loss: 2.0418582757314048

Epoch: 5| Step: 9
Training loss: 0.3732334077358246
Validation loss: 2.0515351990858712

Epoch: 5| Step: 10
Training loss: 0.27890175580978394
Validation loss: 2.031423861781756

Epoch: 5| Step: 11
Training loss: 0.18279683589935303
Validation loss: 2.057159960269928

Epoch: 301| Step: 0
Training loss: 0.3536846339702606
Validation loss: 2.0780071864525476

Epoch: 5| Step: 1
Training loss: 0.36629539728164673
Validation loss: 2.109437202413877

Epoch: 5| Step: 2
Training loss: 0.6927812099456787
Validation loss: 2.081264982620875

Epoch: 5| Step: 3
Training loss: 0.29756027460098267
Validation loss: 2.0720759481191635

Epoch: 5| Step: 4
Training loss: 0.36616629362106323
Validation loss: 2.0594239085912704

Epoch: 5| Step: 5
Training loss: 0.2877276539802551
Validation loss: 2.0100483944018683

Epoch: 5| Step: 6
Training loss: 0.5980923771858215
Validation loss: 2.020239159464836

Epoch: 5| Step: 7
Training loss: 0.3913770616054535
Validation loss: 2.0289835830529532

Epoch: 5| Step: 8
Training loss: 0.4237343370914459
Validation loss: 2.0481814642747245

Epoch: 5| Step: 9
Training loss: 0.4738346040248871
Validation loss: 2.0349339793125787

Epoch: 5| Step: 10
Training loss: 0.29290539026260376
Validation loss: 2.046100159486135

Epoch: 5| Step: 11
Training loss: 0.31946706771850586
Validation loss: 2.0690916180610657

Epoch: 302| Step: 0
Training loss: 0.4258565306663513
Validation loss: 2.1185275465250015

Epoch: 5| Step: 1
Training loss: 0.3773631453514099
Validation loss: 2.1047121981779733

Epoch: 5| Step: 2
Training loss: 0.6428330540657043
Validation loss: 2.051327774922053

Epoch: 5| Step: 3
Training loss: 0.23192758858203888
Validation loss: 2.0421500702699027

Epoch: 5| Step: 4
Training loss: 0.2920348644256592
Validation loss: 2.039057875672976

Epoch: 5| Step: 5
Training loss: 0.3905963897705078
Validation loss: 2.0263742556174598

Epoch: 5| Step: 6
Training loss: 0.321265310049057
Validation loss: 2.019042452176412

Epoch: 5| Step: 7
Training loss: 0.35772496461868286
Validation loss: 2.015331586201986

Epoch: 5| Step: 8
Training loss: 0.38496631383895874
Validation loss: 2.0049474189678826

Epoch: 5| Step: 9
Training loss: 0.6584919095039368
Validation loss: 2.0307432810465493

Epoch: 5| Step: 10
Training loss: 0.6053888201713562
Validation loss: 2.0506729036569595

Epoch: 5| Step: 11
Training loss: 0.29322534799575806
Validation loss: 2.0567047148942947

Epoch: 303| Step: 0
Training loss: 0.6846457719802856
Validation loss: 2.0358082056045532

Epoch: 5| Step: 1
Training loss: 0.34677332639694214
Validation loss: 2.067789872487386

Epoch: 5| Step: 2
Training loss: 0.29132330417633057
Validation loss: 2.0566509862740836

Epoch: 5| Step: 3
Training loss: 0.2565804719924927
Validation loss: 2.0575214078029

Epoch: 5| Step: 4
Training loss: 0.630547821521759
Validation loss: 2.0360403060913086

Epoch: 5| Step: 5
Training loss: 0.38726893067359924
Validation loss: 1.9908730735381444

Epoch: 5| Step: 6
Training loss: 0.48738613724708557
Validation loss: 2.032173365354538

Epoch: 5| Step: 7
Training loss: 0.35806161165237427
Validation loss: 2.034359777967135

Epoch: 5| Step: 8
Training loss: 0.35227447748184204
Validation loss: 2.085240676999092

Epoch: 5| Step: 9
Training loss: 0.3346455693244934
Validation loss: 2.0594786604245505

Epoch: 5| Step: 10
Training loss: 0.4828925132751465
Validation loss: 2.0435072084267936

Epoch: 5| Step: 11
Training loss: 0.13187241554260254
Validation loss: 2.0467701057593026

Epoch: 304| Step: 0
Training loss: 0.5982199907302856
Validation loss: 2.009286572535833

Epoch: 5| Step: 1
Training loss: 0.39385515451431274
Validation loss: 2.0059675872325897

Epoch: 5| Step: 2
Training loss: 0.42987552285194397
Validation loss: 2.033222715059916

Epoch: 5| Step: 3
Training loss: 0.4253880977630615
Validation loss: 2.025967920819918

Epoch: 5| Step: 4
Training loss: 0.26926055550575256
Validation loss: 2.048565298318863

Epoch: 5| Step: 5
Training loss: 0.4284523129463196
Validation loss: 2.0756248285373053

Epoch: 5| Step: 6
Training loss: 0.5120964050292969
Validation loss: 2.0813118716080985

Epoch: 5| Step: 7
Training loss: 0.23259225487709045
Validation loss: 2.063690423965454

Epoch: 5| Step: 8
Training loss: 0.23823018372058868
Validation loss: 2.0423476298650107

Epoch: 5| Step: 9
Training loss: 0.22072987258434296
Validation loss: 2.0418561150630317

Epoch: 5| Step: 10
Training loss: 0.38788488507270813
Validation loss: 2.089225326975187

Epoch: 5| Step: 11
Training loss: 0.2061901092529297
Validation loss: 2.025026688973109

Epoch: 305| Step: 0
Training loss: 0.21023783087730408
Validation loss: 2.0319206913312278

Epoch: 5| Step: 1
Training loss: 0.1736360788345337
Validation loss: 2.0772222181161246

Epoch: 5| Step: 2
Training loss: 0.35617297887802124
Validation loss: 2.0537093579769135

Epoch: 5| Step: 3
Training loss: 0.2997424304485321
Validation loss: 2.0576210021972656

Epoch: 5| Step: 4
Training loss: 0.31492531299591064
Validation loss: 2.092404474814733

Epoch: 5| Step: 5
Training loss: 0.2668527066707611
Validation loss: 2.0788346777359643

Epoch: 5| Step: 6
Training loss: 0.35706549882888794
Validation loss: 2.050885503490766

Epoch: 5| Step: 7
Training loss: 0.43325868248939514
Validation loss: 2.1058995922406516

Epoch: 5| Step: 8
Training loss: 0.6765773892402649
Validation loss: 2.0963552544514337

Epoch: 5| Step: 9
Training loss: 0.42744866013526917
Validation loss: 2.066135436296463

Epoch: 5| Step: 10
Training loss: 0.4259147047996521
Validation loss: 2.065838356812795

Epoch: 5| Step: 11
Training loss: 0.40162593126296997
Validation loss: 2.0735174417495728

Epoch: 306| Step: 0
Training loss: 0.4211302399635315
Validation loss: 2.0935476322968802

Epoch: 5| Step: 1
Training loss: 0.3809671700000763
Validation loss: 2.09994209309419

Epoch: 5| Step: 2
Training loss: 0.4310290217399597
Validation loss: 2.1036425481239953

Epoch: 5| Step: 3
Training loss: 0.20752303302288055
Validation loss: 2.0769435266653695

Epoch: 5| Step: 4
Training loss: 0.4930476248264313
Validation loss: 2.0906390945116677

Epoch: 5| Step: 5
Training loss: 0.4280449450016022
Validation loss: 2.0714635948340097

Epoch: 5| Step: 6
Training loss: 0.3180888593196869
Validation loss: 2.1236276427904763

Epoch: 5| Step: 7
Training loss: 0.337753027677536
Validation loss: 2.112349192301432

Epoch: 5| Step: 8
Training loss: 0.34504780173301697
Validation loss: 2.0529651592175164

Epoch: 5| Step: 9
Training loss: 0.21960338950157166
Validation loss: 2.094839572906494

Epoch: 5| Step: 10
Training loss: 0.2736627161502838
Validation loss: 2.0897519290447235

Epoch: 5| Step: 11
Training loss: 2.5441482067108154
Validation loss: 2.079180588324865

Epoch: 307| Step: 0
Training loss: 0.19749903678894043
Validation loss: 2.039193252722422

Epoch: 5| Step: 1
Training loss: 0.9372738003730774
Validation loss: 2.0467700362205505

Epoch: 5| Step: 2
Training loss: 0.5030726790428162
Validation loss: 2.0744451185067496

Epoch: 5| Step: 3
Training loss: 0.3610273003578186
Validation loss: 2.0777982672055564

Epoch: 5| Step: 4
Training loss: 0.35888415575027466
Validation loss: 2.0955376625061035

Epoch: 5| Step: 5
Training loss: 0.36201345920562744
Validation loss: 2.0637467006842294

Epoch: 5| Step: 6
Training loss: 0.20509251952171326
Validation loss: 2.127722521622976

Epoch: 5| Step: 7
Training loss: 0.2478559911251068
Validation loss: 2.082755610346794

Epoch: 5| Step: 8
Training loss: 0.23261423408985138
Validation loss: 2.0976281662782035

Epoch: 5| Step: 9
Training loss: 0.270912766456604
Validation loss: 2.1161098033189774

Epoch: 5| Step: 10
Training loss: 0.5063605308532715
Validation loss: 2.0605572213729224

Epoch: 5| Step: 11
Training loss: 0.3491817116737366
Validation loss: 2.0728999972343445

Epoch: 308| Step: 0
Training loss: 0.5993594527244568
Validation loss: 2.0430640429258347

Epoch: 5| Step: 1
Training loss: 0.4930386543273926
Validation loss: 2.072598874568939

Epoch: 5| Step: 2
Training loss: 0.3354925215244293
Validation loss: 2.0352035015821457

Epoch: 5| Step: 3
Training loss: 0.20153002440929413
Validation loss: 2.0613156060377755

Epoch: 5| Step: 4
Training loss: 0.24492183327674866
Validation loss: 2.0418972273667655

Epoch: 5| Step: 5
Training loss: 0.24155263602733612
Validation loss: 2.028233682115873

Epoch: 5| Step: 6
Training loss: 0.2791459858417511
Validation loss: 2.0893946439027786

Epoch: 5| Step: 7
Training loss: 0.21574802696704865
Validation loss: 2.0726904620726905

Epoch: 5| Step: 8
Training loss: 0.34957966208457947
Validation loss: 2.09037779768308

Epoch: 5| Step: 9
Training loss: 0.3020550608634949
Validation loss: 2.099720890323321

Epoch: 5| Step: 10
Training loss: 0.6686128377914429
Validation loss: 2.0350378106037774

Epoch: 5| Step: 11
Training loss: 0.18389856815338135
Validation loss: 2.084408606092135

Epoch: 309| Step: 0
Training loss: 0.5154067873954773
Validation loss: 2.1000142941872277

Epoch: 5| Step: 1
Training loss: 0.35858336091041565
Validation loss: 2.0871312816937766

Epoch: 5| Step: 2
Training loss: 0.5289973020553589
Validation loss: 2.068069895108541

Epoch: 5| Step: 3
Training loss: 0.27660036087036133
Validation loss: 2.079708124200503

Epoch: 5| Step: 4
Training loss: 0.3547290861606598
Validation loss: 2.064143796761831

Epoch: 5| Step: 5
Training loss: 0.29780834913253784
Validation loss: 2.073136106133461

Epoch: 5| Step: 6
Training loss: 0.2007920742034912
Validation loss: 2.053157518307368

Epoch: 5| Step: 7
Training loss: 0.6014623641967773
Validation loss: 2.0970232039690018

Epoch: 5| Step: 8
Training loss: 0.3298036456108093
Validation loss: 2.066859722137451

Epoch: 5| Step: 9
Training loss: 0.2260868102312088
Validation loss: 2.0552010436852775

Epoch: 5| Step: 10
Training loss: 0.37795719504356384
Validation loss: 2.04620198905468

Epoch: 5| Step: 11
Training loss: 0.19505929946899414
Validation loss: 2.0473388334115348

Epoch: 310| Step: 0
Training loss: 0.25213485956192017
Validation loss: 2.078339532017708

Epoch: 5| Step: 1
Training loss: 0.31893956661224365
Validation loss: 2.042524869243304

Epoch: 5| Step: 2
Training loss: 0.31111210584640503
Validation loss: 2.0897882531086602

Epoch: 5| Step: 3
Training loss: 0.356650173664093
Validation loss: 2.047471339503924

Epoch: 5| Step: 4
Training loss: 0.5458598136901855
Validation loss: 2.059735099474589

Epoch: 5| Step: 5
Training loss: 0.36233288049697876
Validation loss: 2.1021530578533807

Epoch: 5| Step: 6
Training loss: 0.39433932304382324
Validation loss: 2.087639515598615

Epoch: 5| Step: 7
Training loss: 0.3825506567955017
Validation loss: 2.106493517756462

Epoch: 5| Step: 8
Training loss: 0.5546492338180542
Validation loss: 2.0476156771183014

Epoch: 5| Step: 9
Training loss: 0.23514363169670105
Validation loss: 2.050572464863459

Epoch: 5| Step: 10
Training loss: 0.3951493799686432
Validation loss: 2.071109334627787

Epoch: 5| Step: 11
Training loss: 0.8507798314094543
Validation loss: 2.040240705013275

Epoch: 311| Step: 0
Training loss: 0.396259605884552
Validation loss: 2.114488899707794

Epoch: 5| Step: 1
Training loss: 0.3757343888282776
Validation loss: 2.012619356314341

Epoch: 5| Step: 2
Training loss: 0.32223835587501526
Validation loss: 2.103730077544848

Epoch: 5| Step: 3
Training loss: 0.22744469344615936
Validation loss: 2.0477051635583243

Epoch: 5| Step: 4
Training loss: 0.29769331216812134
Validation loss: 2.0846352577209473

Epoch: 5| Step: 5
Training loss: 0.4833872318267822
Validation loss: 2.0938445230325065

Epoch: 5| Step: 6
Training loss: 0.2739018499851227
Validation loss: 2.030234843492508

Epoch: 5| Step: 7
Training loss: 0.5347878336906433
Validation loss: 2.030298257867495

Epoch: 5| Step: 8
Training loss: 0.6120397448539734
Validation loss: 2.0446660965681076

Epoch: 5| Step: 9
Training loss: 0.584966778755188
Validation loss: 2.0801708499590554

Epoch: 5| Step: 10
Training loss: 0.2027880698442459
Validation loss: 2.0509534776210785

Epoch: 5| Step: 11
Training loss: 0.7419928312301636
Validation loss: 2.0373208969831467

Epoch: 312| Step: 0
Training loss: 0.3277522623538971
Validation loss: 2.0837959398825965

Epoch: 5| Step: 1
Training loss: 0.387634813785553
Validation loss: 2.0768148551384606

Epoch: 5| Step: 2
Training loss: 0.2742554545402527
Validation loss: 2.05887978275617

Epoch: 5| Step: 3
Training loss: 0.3703247904777527
Validation loss: 2.056682606538137

Epoch: 5| Step: 4
Training loss: 0.2687050700187683
Validation loss: 2.079212466875712

Epoch: 5| Step: 5
Training loss: 0.20031723380088806
Validation loss: 2.0402883738279343

Epoch: 5| Step: 6
Training loss: 0.3490862250328064
Validation loss: 1.9976371824741364

Epoch: 5| Step: 7
Training loss: 0.5501096844673157
Validation loss: 2.045445238550504

Epoch: 5| Step: 8
Training loss: 0.5886786580085754
Validation loss: 2.0403772244850793

Epoch: 5| Step: 9
Training loss: 0.31013327836990356
Validation loss: 2.0603808760643005

Epoch: 5| Step: 10
Training loss: 0.41525739431381226
Validation loss: 2.046116163333257

Epoch: 5| Step: 11
Training loss: 1.0361456871032715
Validation loss: 2.0283363858858743

Epoch: 313| Step: 0
Training loss: 0.4089908003807068
Validation loss: 2.0368302017450333

Epoch: 5| Step: 1
Training loss: 0.3260829448699951
Validation loss: 2.0180379350980124

Epoch: 5| Step: 2
Training loss: 0.276317834854126
Validation loss: 2.0296100825071335

Epoch: 5| Step: 3
Training loss: 0.2986988425254822
Validation loss: 2.0311487366755805

Epoch: 5| Step: 4
Training loss: 0.28273099660873413
Validation loss: 2.098660414417585

Epoch: 5| Step: 5
Training loss: 0.5848929286003113
Validation loss: 2.014086127281189

Epoch: 5| Step: 6
Training loss: 0.5428891777992249
Validation loss: 2.039149363835653

Epoch: 5| Step: 7
Training loss: 0.27632468938827515
Validation loss: 2.054002126057943

Epoch: 5| Step: 8
Training loss: 0.32640713453292847
Validation loss: 2.0268101394176483

Epoch: 5| Step: 9
Training loss: 0.35275524854660034
Validation loss: 2.0405441174904504

Epoch: 5| Step: 10
Training loss: 0.3888299763202667
Validation loss: 2.036053334673246

Epoch: 5| Step: 11
Training loss: 0.5003774166107178
Validation loss: 2.0847411255041757

Epoch: 314| Step: 0
Training loss: 0.24481642246246338
Validation loss: 2.0620204458634057

Epoch: 5| Step: 1
Training loss: 0.6844373345375061
Validation loss: 2.0677565783262253

Epoch: 5| Step: 2
Training loss: 0.23987612128257751
Validation loss: 2.057612737019857

Epoch: 5| Step: 3
Training loss: 0.28675514459609985
Validation loss: 2.073094050089518

Epoch: 5| Step: 4
Training loss: 0.26985791325569153
Validation loss: 2.0860905100901923

Epoch: 5| Step: 5
Training loss: 0.2916472852230072
Validation loss: 2.094420542319616

Epoch: 5| Step: 6
Training loss: 0.5748456120491028
Validation loss: 2.0612011700868607

Epoch: 5| Step: 7
Training loss: 0.25914472341537476
Validation loss: 2.083288237452507

Epoch: 5| Step: 8
Training loss: 0.4156491160392761
Validation loss: 2.0522915770610175

Epoch: 5| Step: 9
Training loss: 0.38147759437561035
Validation loss: 2.0693573156992593

Epoch: 5| Step: 10
Training loss: 0.37483108043670654
Validation loss: 2.0849989553292594

Epoch: 5| Step: 11
Training loss: 0.21738559007644653
Validation loss: 2.0579894930124283

Epoch: 315| Step: 0
Training loss: 0.5339585542678833
Validation loss: 2.067756235599518

Epoch: 5| Step: 1
Training loss: 0.19123874604701996
Validation loss: 2.096703603863716

Epoch: 5| Step: 2
Training loss: 0.35575777292251587
Validation loss: 2.070460706949234

Epoch: 5| Step: 3
Training loss: 0.35998034477233887
Validation loss: 2.1134305397669473

Epoch: 5| Step: 4
Training loss: 0.35095304250717163
Validation loss: 2.1172767331202826

Epoch: 5| Step: 5
Training loss: 0.13089770078659058
Validation loss: 2.0817072043816247

Epoch: 5| Step: 6
Training loss: 0.5233538746833801
Validation loss: 2.0654108623663583

Epoch: 5| Step: 7
Training loss: 0.772446870803833
Validation loss: 2.0704706062873206

Epoch: 5| Step: 8
Training loss: 0.22250767052173615
Validation loss: 2.0609067181746163

Epoch: 5| Step: 9
Training loss: 0.21416601538658142
Validation loss: 2.0879538158575692

Epoch: 5| Step: 10
Training loss: 0.2980712056159973
Validation loss: 2.083921194076538

Epoch: 5| Step: 11
Training loss: 0.14029639959335327
Validation loss: 2.0746399015188217

Epoch: 316| Step: 0
Training loss: 0.4125429093837738
Validation loss: 2.1013207683960595

Epoch: 5| Step: 1
Training loss: 0.25496092438697815
Validation loss: 2.085908050338427

Epoch: 5| Step: 2
Training loss: 0.475314199924469
Validation loss: 2.074649309118589

Epoch: 5| Step: 3
Training loss: 0.1794053465127945
Validation loss: 2.0673615485429764

Epoch: 5| Step: 4
Training loss: 0.3141079843044281
Validation loss: 2.0353437860806785

Epoch: 5| Step: 5
Training loss: 0.27334481477737427
Validation loss: 2.0939129690329232

Epoch: 5| Step: 6
Training loss: 0.6245511770248413
Validation loss: 2.048329159617424

Epoch: 5| Step: 7
Training loss: 0.47546911239624023
Validation loss: 2.092399080594381

Epoch: 5| Step: 8
Training loss: 0.352118581533432
Validation loss: 2.0498551776011786

Epoch: 5| Step: 9
Training loss: 0.20101097226142883
Validation loss: 2.0625959436098733

Epoch: 5| Step: 10
Training loss: 0.38619205355644226
Validation loss: 2.0990507304668427

Epoch: 5| Step: 11
Training loss: 0.13311773538589478
Validation loss: 2.101709316174189

Epoch: 317| Step: 0
Training loss: 0.37217798829078674
Validation loss: 2.0997557242711387

Epoch: 5| Step: 1
Training loss: 0.260014146566391
Validation loss: 2.1017190168301263

Epoch: 5| Step: 2
Training loss: 0.3060630261898041
Validation loss: 2.0882765700419745

Epoch: 5| Step: 3
Training loss: 0.27935871481895447
Validation loss: 2.081304371356964

Epoch: 5| Step: 4
Training loss: 0.4341757893562317
Validation loss: 2.0768660058577857

Epoch: 5| Step: 5
Training loss: 0.7604349851608276
Validation loss: 2.0613288432359695

Epoch: 5| Step: 6
Training loss: 0.27618756890296936
Validation loss: 2.0360801021258035

Epoch: 5| Step: 7
Training loss: 0.5828148126602173
Validation loss: 2.069845656553904

Epoch: 5| Step: 8
Training loss: 0.2686561942100525
Validation loss: 2.0631564458211265

Epoch: 5| Step: 9
Training loss: 0.4682237207889557
Validation loss: 2.080697536468506

Epoch: 5| Step: 10
Training loss: 0.21653804183006287
Validation loss: 2.0833158691724143

Epoch: 5| Step: 11
Training loss: 0.2683267593383789
Validation loss: 2.0760828653971353

Epoch: 318| Step: 0
Training loss: 0.2396085560321808
Validation loss: 2.0764572819073996

Epoch: 5| Step: 1
Training loss: 0.2895519733428955
Validation loss: 2.0476645131905875

Epoch: 5| Step: 2
Training loss: 0.28213080763816833
Validation loss: 2.08070341249307

Epoch: 5| Step: 3
Training loss: 0.7184457182884216
Validation loss: 2.0725719134012857

Epoch: 5| Step: 4
Training loss: 0.6258645057678223
Validation loss: 2.085585042834282

Epoch: 5| Step: 5
Training loss: 0.20609256625175476
Validation loss: 2.100898583730062

Epoch: 5| Step: 6
Training loss: 0.3929370045661926
Validation loss: 2.0728705326716104

Epoch: 5| Step: 7
Training loss: 0.5361058115959167
Validation loss: 2.075474147995313

Epoch: 5| Step: 8
Training loss: 0.312656044960022
Validation loss: 2.0863478084405265

Epoch: 5| Step: 9
Training loss: 0.24628038704395294
Validation loss: 2.0834266245365143

Epoch: 5| Step: 10
Training loss: 0.3599490225315094
Validation loss: 2.0964719305435815

Epoch: 5| Step: 11
Training loss: 0.3013624846935272
Validation loss: 2.0917914360761642

Epoch: 319| Step: 0
Training loss: 0.28482359647750854
Validation loss: 2.020328318079313

Epoch: 5| Step: 1
Training loss: 0.5322779417037964
Validation loss: 2.024716004729271

Epoch: 5| Step: 2
Training loss: 0.35538044571876526
Validation loss: 2.0562141239643097

Epoch: 5| Step: 3
Training loss: 0.34775444865226746
Validation loss: 2.0251711110273996

Epoch: 5| Step: 4
Training loss: 0.22020161151885986
Validation loss: 2.03444442152977

Epoch: 5| Step: 5
Training loss: 0.24584726989269257
Validation loss: 2.086300407846769

Epoch: 5| Step: 6
Training loss: 0.31034785509109497
Validation loss: 2.0452581644058228

Epoch: 5| Step: 7
Training loss: 0.6211726069450378
Validation loss: 2.103424608707428

Epoch: 5| Step: 8
Training loss: 0.23951676487922668
Validation loss: 2.1189817686875663

Epoch: 5| Step: 9
Training loss: 0.2456531822681427
Validation loss: 2.0460227876901627

Epoch: 5| Step: 10
Training loss: 0.5725796222686768
Validation loss: 2.0417371690273285

Epoch: 5| Step: 11
Training loss: 0.5389851331710815
Validation loss: 2.014707788825035

Epoch: 320| Step: 0
Training loss: 0.4298769533634186
Validation loss: 2.0286546697219214

Epoch: 5| Step: 1
Training loss: 0.4225528836250305
Validation loss: 2.0726357648770013

Epoch: 5| Step: 2
Training loss: 0.5384474992752075
Validation loss: 2.0457894851764045

Epoch: 5| Step: 3
Training loss: 0.5915781259536743
Validation loss: 2.0303271959225335

Epoch: 5| Step: 4
Training loss: 0.27321261167526245
Validation loss: 2.047725588083267

Epoch: 5| Step: 5
Training loss: 0.4645081162452698
Validation loss: 2.0731771190961203

Epoch: 5| Step: 6
Training loss: 0.20775365829467773
Validation loss: 2.1410817901293435

Epoch: 5| Step: 7
Training loss: 0.298903226852417
Validation loss: 2.116095448533694

Epoch: 5| Step: 8
Training loss: 0.3422664999961853
Validation loss: 2.0800003707408905

Epoch: 5| Step: 9
Training loss: 0.2460828274488449
Validation loss: 2.1053342620531716

Epoch: 5| Step: 10
Training loss: 0.27303990721702576
Validation loss: 2.02159254749616

Epoch: 5| Step: 11
Training loss: 0.2520993947982788
Validation loss: 2.034713566303253

Epoch: 321| Step: 0
Training loss: 0.36753183603286743
Validation loss: 2.054844011863073

Epoch: 5| Step: 1
Training loss: 0.3614692986011505
Validation loss: 2.0699521799882254

Epoch: 5| Step: 2
Training loss: 0.30535560846328735
Validation loss: 2.053161079684893

Epoch: 5| Step: 3
Training loss: 0.30629581212997437
Validation loss: 2.0112810532251992

Epoch: 5| Step: 4
Training loss: 0.38917165994644165
Validation loss: 2.0311900824308395

Epoch: 5| Step: 5
Training loss: 0.3457382321357727
Validation loss: 2.0925217419862747

Epoch: 5| Step: 6
Training loss: 0.4567095637321472
Validation loss: 2.082341745495796

Epoch: 5| Step: 7
Training loss: 0.3001024127006531
Validation loss: 2.1008893698453903

Epoch: 5| Step: 8
Training loss: 0.3478723466396332
Validation loss: 2.0834217419226966

Epoch: 5| Step: 9
Training loss: 0.7072915434837341
Validation loss: 2.0633686234553656

Epoch: 5| Step: 10
Training loss: 0.3790958523750305
Validation loss: 2.0536359697580338

Epoch: 5| Step: 11
Training loss: 0.2305457592010498
Validation loss: 2.049469068646431

Epoch: 322| Step: 0
Training loss: 0.2520020604133606
Validation loss: 2.0537297825018563

Epoch: 5| Step: 1
Training loss: 0.4227845072746277
Validation loss: 2.051999052365621

Epoch: 5| Step: 2
Training loss: 0.5007374882698059
Validation loss: 2.02498559653759

Epoch: 5| Step: 3
Training loss: 0.32314860820770264
Validation loss: 2.0153195758660636

Epoch: 5| Step: 4
Training loss: 0.46431437134742737
Validation loss: 2.028360923131307

Epoch: 5| Step: 5
Training loss: 0.37509751319885254
Validation loss: 2.0651006499926248

Epoch: 5| Step: 6
Training loss: 0.2400473654270172
Validation loss: 2.0873917639255524

Epoch: 5| Step: 7
Training loss: 0.42329472303390503
Validation loss: 2.039234767357508

Epoch: 5| Step: 8
Training loss: 0.32309970259666443
Validation loss: 2.0870129615068436

Epoch: 5| Step: 9
Training loss: 0.49553003907203674
Validation loss: 2.070970962444941

Epoch: 5| Step: 10
Training loss: 0.5194157361984253
Validation loss: 2.0879432410001755

Epoch: 5| Step: 11
Training loss: 0.3917052447795868
Validation loss: 2.0658658295869827

Epoch: 323| Step: 0
Training loss: 0.27967914938926697
Validation loss: 2.072051376104355

Epoch: 5| Step: 1
Training loss: 0.6023364067077637
Validation loss: 2.046555961171786

Epoch: 5| Step: 2
Training loss: 0.36749401688575745
Validation loss: 2.017268950740496

Epoch: 5| Step: 3
Training loss: 0.30082330107688904
Validation loss: 2.074595550696055

Epoch: 5| Step: 4
Training loss: 0.4435512125492096
Validation loss: 2.0419384837150574

Epoch: 5| Step: 5
Training loss: 0.4762134552001953
Validation loss: 2.0391174058119454

Epoch: 5| Step: 6
Training loss: 0.21226859092712402
Validation loss: 2.0581346352895102

Epoch: 5| Step: 7
Training loss: 0.534207820892334
Validation loss: 2.08000610768795

Epoch: 5| Step: 8
Training loss: 0.25592970848083496
Validation loss: 2.0642861078182855

Epoch: 5| Step: 9
Training loss: 0.566210925579071
Validation loss: 2.0920885453621545

Epoch: 5| Step: 10
Training loss: 0.31219416856765747
Validation loss: 2.067420189579328

Epoch: 5| Step: 11
Training loss: 0.21076726913452148
Validation loss: 2.0503189067045846

Epoch: 324| Step: 0
Training loss: 0.4333503842353821
Validation loss: 2.0964623043934503

Epoch: 5| Step: 1
Training loss: 0.3969135880470276
Validation loss: 2.0412272959947586

Epoch: 5| Step: 2
Training loss: 0.5287761688232422
Validation loss: 2.058701604604721

Epoch: 5| Step: 3
Training loss: 0.3010469973087311
Validation loss: 2.0173421849807105

Epoch: 5| Step: 4
Training loss: 0.29437384009361267
Validation loss: 2.0526102830966315

Epoch: 5| Step: 5
Training loss: 0.3368874192237854
Validation loss: 2.056993489464124

Epoch: 5| Step: 6
Training loss: 0.44940370321273804
Validation loss: 2.067535455028216

Epoch: 5| Step: 7
Training loss: 0.2658190131187439
Validation loss: 2.0706018954515457

Epoch: 5| Step: 8
Training loss: 0.30280134081840515
Validation loss: 2.0831828713417053

Epoch: 5| Step: 9
Training loss: 0.7505542635917664
Validation loss: 2.0296039432287216

Epoch: 5| Step: 10
Training loss: 0.2383439987897873
Validation loss: 2.0564983735481897

Epoch: 5| Step: 11
Training loss: 0.5426364541053772
Validation loss: 2.0173716644446054

Epoch: 325| Step: 0
Training loss: 0.28133589029312134
Validation loss: 2.0302278250455856

Epoch: 5| Step: 1
Training loss: 0.3941161036491394
Validation loss: 2.0272191911935806

Epoch: 5| Step: 2
Training loss: 0.26299557089805603
Validation loss: 2.036784455180168

Epoch: 5| Step: 3
Training loss: 0.31900888681411743
Validation loss: 2.023946076631546

Epoch: 5| Step: 4
Training loss: 0.15222042798995972
Validation loss: 2.0505324453115463

Epoch: 5| Step: 5
Training loss: 0.22346213459968567
Validation loss: 2.052862529953321

Epoch: 5| Step: 6
Training loss: 0.29396873712539673
Validation loss: 2.030347396930059

Epoch: 5| Step: 7
Training loss: 0.7538654208183289
Validation loss: 2.0394876102606454

Epoch: 5| Step: 8
Training loss: 0.22166800498962402
Validation loss: 2.062674567103386

Epoch: 5| Step: 9
Training loss: 0.5617836713790894
Validation loss: 2.052519902586937

Epoch: 5| Step: 10
Training loss: 0.4138203561306
Validation loss: 2.0715715934832892

Epoch: 5| Step: 11
Training loss: 0.11621719598770142
Validation loss: 2.0516181588172913

Epoch: 326| Step: 0
Training loss: 0.7474476099014282
Validation loss: 2.024677644173304

Epoch: 5| Step: 1
Training loss: 0.3463609516620636
Validation loss: 2.0731331507364907

Epoch: 5| Step: 2
Training loss: 0.2504398226737976
Validation loss: 2.0348729391892753

Epoch: 5| Step: 3
Training loss: 0.47501879930496216
Validation loss: 2.040653705596924

Epoch: 5| Step: 4
Training loss: 0.364889532327652
Validation loss: 2.034468208750089

Epoch: 5| Step: 5
Training loss: 0.2708593010902405
Validation loss: 2.0482443471749625

Epoch: 5| Step: 6
Training loss: 0.2944929003715515
Validation loss: 2.0738952110211053

Epoch: 5| Step: 7
Training loss: 0.20629706978797913
Validation loss: 2.0266952564318976

Epoch: 5| Step: 8
Training loss: 0.2672891616821289
Validation loss: 2.0349660168091455

Epoch: 5| Step: 9
Training loss: 0.15396125614643097
Validation loss: 2.076384579141935

Epoch: 5| Step: 10
Training loss: 0.48746412992477417
Validation loss: 2.0161310185988746

Epoch: 5| Step: 11
Training loss: 0.27249467372894287
Validation loss: 2.084830512603124

Epoch: 327| Step: 0
Training loss: 0.37508147954940796
Validation loss: 2.0448033114274344

Epoch: 5| Step: 1
Training loss: 0.2893964350223541
Validation loss: 2.0783729205528894

Epoch: 5| Step: 2
Training loss: 0.19351758062839508
Validation loss: 2.040080204606056

Epoch: 5| Step: 3
Training loss: 0.2647525668144226
Validation loss: 2.061959703763326

Epoch: 5| Step: 4
Training loss: 0.5616388916969299
Validation loss: 2.0363936871290207

Epoch: 5| Step: 5
Training loss: 0.24791085720062256
Validation loss: 2.0725505550702414

Epoch: 5| Step: 6
Training loss: 0.3679618835449219
Validation loss: 2.0456170539061227

Epoch: 5| Step: 7
Training loss: 0.41192445158958435
Validation loss: 2.036293829480807

Epoch: 5| Step: 8
Training loss: 0.2723827362060547
Validation loss: 2.058493713537852

Epoch: 5| Step: 9
Training loss: 0.2754118740558624
Validation loss: 2.08981421093146

Epoch: 5| Step: 10
Training loss: 0.7036011815071106
Validation loss: 2.0563335865736008

Epoch: 5| Step: 11
Training loss: 0.22456645965576172
Validation loss: 2.0921482294797897

Epoch: 328| Step: 0
Training loss: 0.2520779073238373
Validation loss: 2.030663172403971

Epoch: 5| Step: 1
Training loss: 0.5532668232917786
Validation loss: 2.0666633745034537

Epoch: 5| Step: 2
Training loss: 0.42634034156799316
Validation loss: 2.059452017148336

Epoch: 5| Step: 3
Training loss: 0.3276654779911041
Validation loss: 2.0053972800572715

Epoch: 5| Step: 4
Training loss: 0.2988725006580353
Validation loss: 2.0560931116342545

Epoch: 5| Step: 5
Training loss: 0.22164921462535858
Validation loss: 2.0246318876743317

Epoch: 5| Step: 6
Training loss: 0.3637080788612366
Validation loss: 2.0239712794621787

Epoch: 5| Step: 7
Training loss: 0.5933902859687805
Validation loss: 2.0615286976099014

Epoch: 5| Step: 8
Training loss: 0.3101438879966736
Validation loss: 2.056027422348658

Epoch: 5| Step: 9
Training loss: 0.2541475296020508
Validation loss: 2.008897289633751

Epoch: 5| Step: 10
Training loss: 0.33720558881759644
Validation loss: 2.053488497932752

Epoch: 5| Step: 11
Training loss: 0.2847806215286255
Validation loss: 2.0761322528123856

Epoch: 329| Step: 0
Training loss: 0.42951732873916626
Validation loss: 2.060799926519394

Epoch: 5| Step: 1
Training loss: 0.4391666352748871
Validation loss: 2.027460823456446

Epoch: 5| Step: 2
Training loss: 0.3224110007286072
Validation loss: 2.0205602844556174

Epoch: 5| Step: 3
Training loss: 0.39642831683158875
Validation loss: 2.0087167471647263

Epoch: 5| Step: 4
Training loss: 0.33033257722854614
Validation loss: 2.0147934208313623

Epoch: 5| Step: 5
Training loss: 0.27901723980903625
Validation loss: 2.0194920202096305

Epoch: 5| Step: 6
Training loss: 0.3250395357608795
Validation loss: 2.056525965531667

Epoch: 5| Step: 7
Training loss: 0.3160783350467682
Validation loss: 2.0347062597672143

Epoch: 5| Step: 8
Training loss: 0.2197609841823578
Validation loss: 2.0323900332053504

Epoch: 5| Step: 9
Training loss: 0.27945584058761597
Validation loss: 2.042274922132492

Epoch: 5| Step: 10
Training loss: 0.26203614473342896
Validation loss: 2.0166853815317154

Epoch: 5| Step: 11
Training loss: 1.667943000793457
Validation loss: 2.0093088249365487

Epoch: 330| Step: 0
Training loss: 0.378276526927948
Validation loss: 2.0046153316895166

Epoch: 5| Step: 1
Training loss: 0.2263425588607788
Validation loss: 2.053060074647268

Epoch: 5| Step: 2
Training loss: 0.21246735751628876
Validation loss: 1.9968314518531163

Epoch: 5| Step: 3
Training loss: 0.3256841003894806
Validation loss: 2.0558671057224274

Epoch: 5| Step: 4
Training loss: 0.36922043561935425
Validation loss: 2.0718397994836173

Epoch: 5| Step: 5
Training loss: 0.44444403052330017
Validation loss: 2.0722694098949432

Epoch: 5| Step: 6
Training loss: 0.5646230578422546
Validation loss: 2.1233691573143005

Epoch: 5| Step: 7
Training loss: 0.33915361762046814
Validation loss: 2.0941144873698554

Epoch: 5| Step: 8
Training loss: 0.4047800600528717
Validation loss: 2.07257242500782

Epoch: 5| Step: 9
Training loss: 0.3520304560661316
Validation loss: 2.0404616047938666

Epoch: 5| Step: 10
Training loss: 0.29222992062568665
Validation loss: 2.060729290048281

Epoch: 5| Step: 11
Training loss: 0.14720118045806885
Validation loss: 2.0539114425579705

Epoch: 331| Step: 0
Training loss: 0.1690429002046585
Validation loss: 2.03898752729098

Epoch: 5| Step: 1
Training loss: 0.4079236090183258
Validation loss: 2.071085343758265

Epoch: 5| Step: 2
Training loss: 0.2964140772819519
Validation loss: 2.069784258802732

Epoch: 5| Step: 3
Training loss: 0.5229312181472778
Validation loss: 2.048981433113416

Epoch: 5| Step: 4
Training loss: 0.546980082988739
Validation loss: 2.037461375196775

Epoch: 5| Step: 5
Training loss: 0.3114401698112488
Validation loss: 2.0521523356437683

Epoch: 5| Step: 6
Training loss: 0.2315625697374344
Validation loss: 2.083732252319654

Epoch: 5| Step: 7
Training loss: 0.44617781043052673
Validation loss: 2.040890634059906

Epoch: 5| Step: 8
Training loss: 0.5140812993049622
Validation loss: 2.069010451436043

Epoch: 5| Step: 9
Training loss: 0.16304925084114075
Validation loss: 2.078375354409218

Epoch: 5| Step: 10
Training loss: 0.21485579013824463
Validation loss: 2.0644859075546265

Epoch: 5| Step: 11
Training loss: 0.17732390761375427
Validation loss: 2.080521990855535

Epoch: 332| Step: 0
Training loss: 0.44591084122657776
Validation loss: 2.130219871799151

Epoch: 5| Step: 1
Training loss: 0.6281883120536804
Validation loss: 2.1329315453767776

Epoch: 5| Step: 2
Training loss: 0.32508182525634766
Validation loss: 2.0590559343496957

Epoch: 5| Step: 3
Training loss: 0.395259290933609
Validation loss: 2.0894524355729422

Epoch: 5| Step: 4
Training loss: 0.23097284138202667
Validation loss: 2.0622395674387612

Epoch: 5| Step: 5
Training loss: 0.2377306967973709
Validation loss: 2.0321247378985086

Epoch: 5| Step: 6
Training loss: 0.2769675850868225
Validation loss: 2.0459231535593667

Epoch: 5| Step: 7
Training loss: 0.2740577161312103
Validation loss: 2.0534324000279107

Epoch: 5| Step: 8
Training loss: 0.4657418727874756
Validation loss: 2.0699665546417236

Epoch: 5| Step: 9
Training loss: 0.45634227991104126
Validation loss: 2.0732384026050568

Epoch: 5| Step: 10
Training loss: 0.2835836410522461
Validation loss: 2.0996872037649155

Epoch: 5| Step: 11
Training loss: 0.488086998462677
Validation loss: 2.0656850586334863

Epoch: 333| Step: 0
Training loss: 0.4543624818325043
Validation loss: 2.093724548816681

Epoch: 5| Step: 1
Training loss: 0.6939378380775452
Validation loss: 2.095966244737307

Epoch: 5| Step: 2
Training loss: 0.192417174577713
Validation loss: 2.0695383101701736

Epoch: 5| Step: 3
Training loss: 0.3050916790962219
Validation loss: 2.049199258287748

Epoch: 5| Step: 4
Training loss: 0.18049843609333038
Validation loss: 2.0903868675231934

Epoch: 5| Step: 5
Training loss: 0.4308184087276459
Validation loss: 2.0540169775485992

Epoch: 5| Step: 6
Training loss: 0.4120486378669739
Validation loss: 2.061558653910955

Epoch: 5| Step: 7
Training loss: 0.31747445464134216
Validation loss: 2.0626851320266724

Epoch: 5| Step: 8
Training loss: 0.2818506360054016
Validation loss: 2.0807995746533074

Epoch: 5| Step: 9
Training loss: 0.518052339553833
Validation loss: 2.053145801027616

Epoch: 5| Step: 10
Training loss: 0.38423222303390503
Validation loss: 2.0733413994312286

Epoch: 5| Step: 11
Training loss: 0.1851975917816162
Validation loss: 2.091893663009008

Epoch: 334| Step: 0
Training loss: 0.41758713126182556
Validation loss: 2.058164194226265

Epoch: 5| Step: 1
Training loss: 0.5491480827331543
Validation loss: 2.06869109471639

Epoch: 5| Step: 2
Training loss: 0.7079015374183655
Validation loss: 2.058132827281952

Epoch: 5| Step: 3
Training loss: 0.20613884925842285
Validation loss: 2.030730277299881

Epoch: 5| Step: 4
Training loss: 0.286520779132843
Validation loss: 2.0611350685358047

Epoch: 5| Step: 5
Training loss: 0.4104219377040863
Validation loss: 2.0414718687534332

Epoch: 5| Step: 6
Training loss: 0.25756531953811646
Validation loss: 1.9977762003739674

Epoch: 5| Step: 7
Training loss: 0.2624223530292511
Validation loss: 2.010527397195498

Epoch: 5| Step: 8
Training loss: 0.2807270884513855
Validation loss: 2.025856241583824

Epoch: 5| Step: 9
Training loss: 0.21822407841682434
Validation loss: 2.053496633966764

Epoch: 5| Step: 10
Training loss: 0.23217444121837616
Validation loss: 2.0273868391911187

Epoch: 5| Step: 11
Training loss: 0.16453686356544495
Validation loss: 2.057728240887324

Epoch: 335| Step: 0
Training loss: 0.22655358910560608
Validation loss: 2.059822216629982

Epoch: 5| Step: 1
Training loss: 0.2227066457271576
Validation loss: 2.096654241283735

Epoch: 5| Step: 2
Training loss: 0.3009970486164093
Validation loss: 2.047256370385488

Epoch: 5| Step: 3
Training loss: 0.21105387806892395
Validation loss: 2.05183536807696

Epoch: 5| Step: 4
Training loss: 0.24272385239601135
Validation loss: 2.0363135635852814

Epoch: 5| Step: 5
Training loss: 0.36215248703956604
Validation loss: 2.0769075651963553

Epoch: 5| Step: 6
Training loss: 0.3154776990413666
Validation loss: 2.0322322795788446

Epoch: 5| Step: 7
Training loss: 0.5688887238502502
Validation loss: 2.0641177594661713

Epoch: 5| Step: 8
Training loss: 0.44717374444007874
Validation loss: 2.05811915298303

Epoch: 5| Step: 9
Training loss: 0.43462935090065
Validation loss: 2.0794740517934165

Epoch: 5| Step: 10
Training loss: 0.32073554396629333
Validation loss: 2.030229846636454

Epoch: 5| Step: 11
Training loss: 0.20846553146839142
Validation loss: 2.0378196388483047

Epoch: 336| Step: 0
Training loss: 0.3287418484687805
Validation loss: 2.0788470009962716

Epoch: 5| Step: 1
Training loss: 0.283109188079834
Validation loss: 2.0253866066535315

Epoch: 5| Step: 2
Training loss: 0.2925802171230316
Validation loss: 2.0563493818044662

Epoch: 5| Step: 3
Training loss: 0.2450970709323883
Validation loss: 2.051275357604027

Epoch: 5| Step: 4
Training loss: 0.3924921154975891
Validation loss: 2.085770398378372

Epoch: 5| Step: 5
Training loss: 0.37244099378585815
Validation loss: 2.0302225798368454

Epoch: 5| Step: 6
Training loss: 0.1954919993877411
Validation loss: 1.9994510213534038

Epoch: 5| Step: 7
Training loss: 0.38987481594085693
Validation loss: 2.0217803766330085

Epoch: 5| Step: 8
Training loss: 0.20726755261421204
Validation loss: 2.0105838974316916

Epoch: 5| Step: 9
Training loss: 0.19771793484687805
Validation loss: 2.02565199136734

Epoch: 5| Step: 10
Training loss: 0.6871854066848755
Validation loss: 2.0390182038148246

Epoch: 5| Step: 11
Training loss: 0.334555059671402
Validation loss: 2.0318963726361594

Epoch: 337| Step: 0
Training loss: 0.2074573040008545
Validation loss: 2.04204331835111

Epoch: 5| Step: 1
Training loss: 0.3233405351638794
Validation loss: 2.081093207001686

Epoch: 5| Step: 2
Training loss: 0.34820258617401123
Validation loss: 2.0940057983001075

Epoch: 5| Step: 3
Training loss: 0.5463818311691284
Validation loss: 2.028524026274681

Epoch: 5| Step: 4
Training loss: 0.3749370574951172
Validation loss: 2.0400088727474213

Epoch: 5| Step: 5
Training loss: 0.3034525513648987
Validation loss: 2.0725603053967157

Epoch: 5| Step: 6
Training loss: 0.5253196358680725
Validation loss: 2.060247376561165

Epoch: 5| Step: 7
Training loss: 0.1566874384880066
Validation loss: 2.0467297385136285

Epoch: 5| Step: 8
Training loss: 0.21495619416236877
Validation loss: 2.073333218693733

Epoch: 5| Step: 9
Training loss: 0.3600562810897827
Validation loss: 2.055166850487391

Epoch: 5| Step: 10
Training loss: 0.3025992810726166
Validation loss: 2.1201625615358353

Epoch: 5| Step: 11
Training loss: 0.7169862985610962
Validation loss: 2.0816345661878586

Epoch: 338| Step: 0
Training loss: 0.2530774474143982
Validation loss: 2.077727441986402

Epoch: 5| Step: 1
Training loss: 0.2192593365907669
Validation loss: 2.0029356380303702

Epoch: 5| Step: 2
Training loss: 0.46571531891822815
Validation loss: 2.076120754082998

Epoch: 5| Step: 3
Training loss: 0.30413222312927246
Validation loss: 2.084040363629659

Epoch: 5| Step: 4
Training loss: 0.6175531148910522
Validation loss: 2.0401844133933387

Epoch: 5| Step: 5
Training loss: 0.4062790274620056
Validation loss: 2.0605017046133676

Epoch: 5| Step: 6
Training loss: 0.2248101532459259
Validation loss: 2.009628117084503

Epoch: 5| Step: 7
Training loss: 0.26411306858062744
Validation loss: 2.0444377064704895

Epoch: 5| Step: 8
Training loss: 0.3359783887863159
Validation loss: 2.0984283139308295

Epoch: 5| Step: 9
Training loss: 0.27088332176208496
Validation loss: 2.073471168677012

Epoch: 5| Step: 10
Training loss: 0.30989450216293335
Validation loss: 2.0306998242934546

Epoch: 5| Step: 11
Training loss: 0.8889304399490356
Validation loss: 2.0409213304519653

Epoch: 339| Step: 0
Training loss: 0.43845024704933167
Validation loss: 2.022968754172325

Epoch: 5| Step: 1
Training loss: 0.3454674780368805
Validation loss: 2.1051203409830728

Epoch: 5| Step: 2
Training loss: 0.4238935112953186
Validation loss: 2.0450135121742883

Epoch: 5| Step: 3
Training loss: 0.3876447081565857
Validation loss: 2.0754149754842124

Epoch: 5| Step: 4
Training loss: 0.2292162925004959
Validation loss: 1.9936534563700359

Epoch: 5| Step: 5
Training loss: 0.31825149059295654
Validation loss: 2.0353933920462928

Epoch: 5| Step: 6
Training loss: 0.2594190835952759
Validation loss: 2.023193041483561

Epoch: 5| Step: 7
Training loss: 0.37271949648857117
Validation loss: 2.0380159268776574

Epoch: 5| Step: 8
Training loss: 0.2908891439437866
Validation loss: 2.0827352106571198

Epoch: 5| Step: 9
Training loss: 0.3042566776275635
Validation loss: 2.0240218738714852

Epoch: 5| Step: 10
Training loss: 0.2588287591934204
Validation loss: 2.053038020928701

Epoch: 5| Step: 11
Training loss: 0.384036123752594
Validation loss: 2.0647652596235275

Epoch: 340| Step: 0
Training loss: 0.5012961626052856
Validation loss: 2.0164798547824225

Epoch: 5| Step: 1
Training loss: 0.2258351743221283
Validation loss: 2.0360862016677856

Epoch: 5| Step: 2
Training loss: 0.26338741183280945
Validation loss: 2.0530608743429184

Epoch: 5| Step: 3
Training loss: 0.2992219924926758
Validation loss: 2.081444283326467

Epoch: 5| Step: 4
Training loss: 0.48586612939834595
Validation loss: 2.054861197868983

Epoch: 5| Step: 5
Training loss: 0.3969113528728485
Validation loss: 2.079440956314405

Epoch: 5| Step: 6
Training loss: 0.22710227966308594
Validation loss: 2.0600574215253196

Epoch: 5| Step: 7
Training loss: 0.3209574222564697
Validation loss: 2.0906447718540826

Epoch: 5| Step: 8
Training loss: 0.18821211159229279
Validation loss: 2.055122748017311

Epoch: 5| Step: 9
Training loss: 0.47220104932785034
Validation loss: 2.1113197902838388

Epoch: 5| Step: 10
Training loss: 0.34087926149368286
Validation loss: 2.0866806904474893

Epoch: 5| Step: 11
Training loss: 0.21172797679901123
Validation loss: 2.1068531374136605

Epoch: 341| Step: 0
Training loss: 0.6756046414375305
Validation loss: 2.0899864037831626

Epoch: 5| Step: 1
Training loss: 0.31798362731933594
Validation loss: 2.1039312183856964

Epoch: 5| Step: 2
Training loss: 0.264366090297699
Validation loss: 2.06185353298982

Epoch: 5| Step: 3
Training loss: 0.2950896620750427
Validation loss: 2.084860220551491

Epoch: 5| Step: 4
Training loss: 0.1981898844242096
Validation loss: 2.0604351609945297

Epoch: 5| Step: 5
Training loss: 0.2569490373134613
Validation loss: 2.0657028754552207

Epoch: 5| Step: 6
Training loss: 0.4122161865234375
Validation loss: 2.076811134815216

Epoch: 5| Step: 7
Training loss: 0.4001498222351074
Validation loss: 2.0843815008799234

Epoch: 5| Step: 8
Training loss: 0.34625160694122314
Validation loss: 2.0724943727254868

Epoch: 5| Step: 9
Training loss: 0.24812383949756622
Validation loss: 2.055920069416364

Epoch: 5| Step: 10
Training loss: 0.3444024920463562
Validation loss: 2.1168619642655053

Epoch: 5| Step: 11
Training loss: 0.5256901979446411
Validation loss: 2.045299862821897

Epoch: 342| Step: 0
Training loss: 0.28078287839889526
Validation loss: 2.0971207867066064

Epoch: 5| Step: 1
Training loss: 0.2180110663175583
Validation loss: 2.039559379220009

Epoch: 5| Step: 2
Training loss: 0.30006200075149536
Validation loss: 2.061743145187696

Epoch: 5| Step: 3
Training loss: 0.3029925525188446
Validation loss: 2.1098391811052957

Epoch: 5| Step: 4
Training loss: 0.3679478168487549
Validation loss: 2.0853278239568076

Epoch: 5| Step: 5
Training loss: 0.233046293258667
Validation loss: 2.061100661754608

Epoch: 5| Step: 6
Training loss: 0.2654772996902466
Validation loss: 2.0318923940261207

Epoch: 5| Step: 7
Training loss: 0.5371254682540894
Validation loss: 2.0241035719712577

Epoch: 5| Step: 8
Training loss: 0.25750547647476196
Validation loss: 2.0676452169815698

Epoch: 5| Step: 9
Training loss: 0.4880340099334717
Validation loss: 2.014015699426333

Epoch: 5| Step: 10
Training loss: 0.4208761751651764
Validation loss: 2.047867019971212

Epoch: 5| Step: 11
Training loss: 0.14976662397384644
Validation loss: 2.0384259124596915

Epoch: 343| Step: 0
Training loss: 0.26485270261764526
Validation loss: 2.0245467126369476

Epoch: 5| Step: 1
Training loss: 0.31859907507896423
Validation loss: 2.049940804640452

Epoch: 5| Step: 2
Training loss: 0.2086397111415863
Validation loss: 2.0746910671393075

Epoch: 5| Step: 3
Training loss: 0.24260663986206055
Validation loss: 2.04316845536232

Epoch: 5| Step: 4
Training loss: 0.4144412875175476
Validation loss: 2.013284519314766

Epoch: 5| Step: 5
Training loss: 0.2694929242134094
Validation loss: 2.0263073643048606

Epoch: 5| Step: 6
Training loss: 0.36752572655677795
Validation loss: 2.0888047913710275

Epoch: 5| Step: 7
Training loss: 0.4860517084598541
Validation loss: 2.0451813538869223

Epoch: 5| Step: 8
Training loss: 0.21388188004493713
Validation loss: 2.0539613316456475

Epoch: 5| Step: 9
Training loss: 0.35537004470825195
Validation loss: 2.0086576342582703

Epoch: 5| Step: 10
Training loss: 0.3779965341091156
Validation loss: 1.9983408500750859

Epoch: 5| Step: 11
Training loss: 1.0185108184814453
Validation loss: 2.0598645359277725

Epoch: 344| Step: 0
Training loss: 0.41236749291419983
Validation loss: 2.0352817475795746

Epoch: 5| Step: 1
Training loss: 0.24570265412330627
Validation loss: 2.0428555011749268

Epoch: 5| Step: 2
Training loss: 0.21013085544109344
Validation loss: 2.022055799762408

Epoch: 5| Step: 3
Training loss: 0.25050944089889526
Validation loss: 2.045848533511162

Epoch: 5| Step: 4
Training loss: 0.16704735159873962
Validation loss: 2.04158715903759

Epoch: 5| Step: 5
Training loss: 0.17969387769699097
Validation loss: 2.053501139084498

Epoch: 5| Step: 6
Training loss: 0.1517934501171112
Validation loss: 2.0988759994506836

Epoch: 5| Step: 7
Training loss: 0.5618796348571777
Validation loss: 2.0793954133987427

Epoch: 5| Step: 8
Training loss: 0.2540910840034485
Validation loss: 2.0913014858961105

Epoch: 5| Step: 9
Training loss: 0.22631964087486267
Validation loss: 2.040825883547465

Epoch: 5| Step: 10
Training loss: 0.6418654322624207
Validation loss: 2.0966585328181586

Epoch: 5| Step: 11
Training loss: 0.29447394609451294
Validation loss: 2.0503066082795462

Epoch: 345| Step: 0
Training loss: 0.23062464594841003
Validation loss: 2.0391061206658683

Epoch: 5| Step: 1
Training loss: 0.2473333775997162
Validation loss: 2.1014362970987954

Epoch: 5| Step: 2
Training loss: 0.34431153535842896
Validation loss: 2.0272557884454727

Epoch: 5| Step: 3
Training loss: 0.4185512661933899
Validation loss: 2.085049311319987

Epoch: 5| Step: 4
Training loss: 0.3158779740333557
Validation loss: 2.0478820403416953

Epoch: 5| Step: 5
Training loss: 0.5444756150245667
Validation loss: 2.0474631786346436

Epoch: 5| Step: 6
Training loss: 0.41323551535606384
Validation loss: 2.0722675919532776

Epoch: 5| Step: 7
Training loss: 0.2971455156803131
Validation loss: 2.067922050754229

Epoch: 5| Step: 8
Training loss: 0.5412294268608093
Validation loss: 2.0954120755195618

Epoch: 5| Step: 9
Training loss: 0.1841549128293991
Validation loss: 2.0402007400989532

Epoch: 5| Step: 10
Training loss: 0.1886817216873169
Validation loss: 2.064780275026957

Epoch: 5| Step: 11
Training loss: 0.3089430332183838
Validation loss: 2.0761419236660004

Epoch: 346| Step: 0
Training loss: 0.3470250070095062
Validation loss: 2.073037097851435

Epoch: 5| Step: 1
Training loss: 0.5557171702384949
Validation loss: 2.069180573026339

Epoch: 5| Step: 2
Training loss: 0.3825162649154663
Validation loss: 1.9925546646118164

Epoch: 5| Step: 3
Training loss: 0.3161427974700928
Validation loss: 2.035407841205597

Epoch: 5| Step: 4
Training loss: 0.2132875919342041
Validation loss: 2.025462488333384

Epoch: 5| Step: 5
Training loss: 0.23543767631053925
Validation loss: 2.0324337780475616

Epoch: 5| Step: 6
Training loss: 0.3880079388618469
Validation loss: 2.006698260704676

Epoch: 5| Step: 7
Training loss: 0.3731246888637543
Validation loss: 2.0318195521831512

Epoch: 5| Step: 8
Training loss: 0.194398432970047
Validation loss: 2.0591072936852775

Epoch: 5| Step: 9
Training loss: 0.183574840426445
Validation loss: 2.057299723227819

Epoch: 5| Step: 10
Training loss: 0.640609085559845
Validation loss: 2.084959248701731

Epoch: 5| Step: 11
Training loss: 0.14079421758651733
Validation loss: 2.055744191010793

Epoch: 347| Step: 0
Training loss: 0.457587331533432
Validation loss: 2.076015661160151

Epoch: 5| Step: 1
Training loss: 0.21585097908973694
Validation loss: 2.0712410112222037

Epoch: 5| Step: 2
Training loss: 0.27585744857788086
Validation loss: 2.0390469233194985

Epoch: 5| Step: 3
Training loss: 0.4819665849208832
Validation loss: 2.09614597260952

Epoch: 5| Step: 4
Training loss: 0.44060778617858887
Validation loss: 2.0516281127929688

Epoch: 5| Step: 5
Training loss: 0.2625729739665985
Validation loss: 2.066608265042305

Epoch: 5| Step: 6
Training loss: 0.2895379066467285
Validation loss: 2.0202134251594543

Epoch: 5| Step: 7
Training loss: 0.5689250826835632
Validation loss: 2.0684604545434317

Epoch: 5| Step: 8
Training loss: 0.17841626703739166
Validation loss: 2.02555022140344

Epoch: 5| Step: 9
Training loss: 0.256435751914978
Validation loss: 2.0296443502108255

Epoch: 5| Step: 10
Training loss: 0.301555335521698
Validation loss: 2.0701713114976883

Epoch: 5| Step: 11
Training loss: 0.1742696762084961
Validation loss: 2.035771628220876

Epoch: 348| Step: 0
Training loss: 0.3158526122570038
Validation loss: 2.036838491757711

Epoch: 5| Step: 1
Training loss: 0.2110685408115387
Validation loss: 2.034762183825175

Epoch: 5| Step: 2
Training loss: 0.27948352694511414
Validation loss: 2.098024199406306

Epoch: 5| Step: 3
Training loss: 0.20297101140022278
Validation loss: 2.064469317595164

Epoch: 5| Step: 4
Training loss: 0.48506203293800354
Validation loss: 2.0377959311008453

Epoch: 5| Step: 5
Training loss: 0.33322709798812866
Validation loss: 2.0496613681316376

Epoch: 5| Step: 6
Training loss: 0.29021745920181274
Validation loss: 2.074357494711876

Epoch: 5| Step: 7
Training loss: 0.3896735608577728
Validation loss: 2.1290947645902634

Epoch: 5| Step: 8
Training loss: 0.6418880224227905
Validation loss: 2.0985831220944724

Epoch: 5| Step: 9
Training loss: 0.5154000520706177
Validation loss: 2.064230293035507

Epoch: 5| Step: 10
Training loss: 0.31229934096336365
Validation loss: 2.04160741964976

Epoch: 5| Step: 11
Training loss: 0.2685840129852295
Validation loss: 2.041714757680893

Epoch: 349| Step: 0
Training loss: 0.3729615807533264
Validation loss: 2.019065871834755

Epoch: 5| Step: 1
Training loss: 0.5872294306755066
Validation loss: 2.0278954406579337

Epoch: 5| Step: 2
Training loss: 0.5191648602485657
Validation loss: 2.005495791633924

Epoch: 5| Step: 3
Training loss: 0.3413350284099579
Validation loss: 2.0491712987422943

Epoch: 5| Step: 4
Training loss: 0.28108927607536316
Validation loss: 2.037545477350553

Epoch: 5| Step: 5
Training loss: 0.39316830039024353
Validation loss: 2.063409835100174

Epoch: 5| Step: 6
Training loss: 0.4055876135826111
Validation loss: 2.052916924158732

Epoch: 5| Step: 7
Training loss: 0.27790454030036926
Validation loss: 2.048410510023435

Epoch: 5| Step: 8
Training loss: 0.3302462697029114
Validation loss: 2.044849236806234

Epoch: 5| Step: 9
Training loss: 0.6052236557006836
Validation loss: 2.025290166338285

Epoch: 5| Step: 10
Training loss: 0.22736620903015137
Validation loss: 2.0370442469914756

Epoch: 5| Step: 11
Training loss: 0.5265366435050964
Validation loss: 2.0391577978928885

Epoch: 350| Step: 0
Training loss: 0.23753924667835236
Validation loss: 2.045703798532486

Epoch: 5| Step: 1
Training loss: 0.45471152663230896
Validation loss: 2.050466696421305

Epoch: 5| Step: 2
Training loss: 0.42693644762039185
Validation loss: 2.0405180354913077

Epoch: 5| Step: 3
Training loss: 0.3844597339630127
Validation loss: 2.0437456369400024

Epoch: 5| Step: 4
Training loss: 0.5305972695350647
Validation loss: 2.0282591780026755

Epoch: 5| Step: 5
Training loss: 0.3110009431838989
Validation loss: 2.035084530711174

Epoch: 5| Step: 6
Training loss: 0.21436341106891632
Validation loss: 2.0636715441942215

Epoch: 5| Step: 7
Training loss: 0.3481687307357788
Validation loss: 2.0674474984407425

Epoch: 5| Step: 8
Training loss: 0.3588539659976959
Validation loss: 2.0767541279395423

Epoch: 5| Step: 9
Training loss: 0.31714165210723877
Validation loss: 2.033926089604696

Epoch: 5| Step: 10
Training loss: 0.35541895031929016
Validation loss: 2.034365713596344

Epoch: 5| Step: 11
Training loss: 0.9169507622718811
Validation loss: 2.069260055820147

Epoch: 351| Step: 0
Training loss: 0.3640207052230835
Validation loss: 2.0898424287637076

Epoch: 5| Step: 1
Training loss: 0.38201478123664856
Validation loss: 2.007328157623609

Epoch: 5| Step: 2
Training loss: 0.2598046362400055
Validation loss: 2.0328493465979895

Epoch: 5| Step: 3
Training loss: 0.37453508377075195
Validation loss: 2.0166881630818048

Epoch: 5| Step: 4
Training loss: 0.5026966333389282
Validation loss: 2.093500872453054

Epoch: 5| Step: 5
Training loss: 0.24450306594371796
Validation loss: 2.0816548268000283

Epoch: 5| Step: 6
Training loss: 0.3165544271469116
Validation loss: 2.0760266482830048

Epoch: 5| Step: 7
Training loss: 0.19163616001605988
Validation loss: 2.0516635477542877

Epoch: 5| Step: 8
Training loss: 0.3686799108982086
Validation loss: 2.0932951966921487

Epoch: 5| Step: 9
Training loss: 0.2243407666683197
Validation loss: 2.0203647961219153

Epoch: 5| Step: 10
Training loss: 0.3491979241371155
Validation loss: 2.006011794010798

Epoch: 5| Step: 11
Training loss: 0.1104360818862915
Validation loss: 2.074925651152929

Epoch: 352| Step: 0
Training loss: 0.2967900037765503
Validation loss: 2.054436127344767

Epoch: 5| Step: 1
Training loss: 0.41787225008010864
Validation loss: 2.039863998691241

Epoch: 5| Step: 2
Training loss: 0.25118839740753174
Validation loss: 2.025658751527468

Epoch: 5| Step: 3
Training loss: 0.2143009454011917
Validation loss: 2.054585794607798

Epoch: 5| Step: 4
Training loss: 0.3315736651420593
Validation loss: 2.0683558136224747

Epoch: 5| Step: 5
Training loss: 0.7171382904052734
Validation loss: 2.0318386803070703

Epoch: 5| Step: 6
Training loss: 0.3558056950569153
Validation loss: 2.101519604523977

Epoch: 5| Step: 7
Training loss: 0.13459090888500214
Validation loss: 2.035698572794596

Epoch: 5| Step: 8
Training loss: 0.20766131579875946
Validation loss: 2.0521867920955024

Epoch: 5| Step: 9
Training loss: 0.39338570833206177
Validation loss: 2.0502453446388245

Epoch: 5| Step: 10
Training loss: 0.272799015045166
Validation loss: 2.042806029319763

Epoch: 5| Step: 11
Training loss: 0.19437143206596375
Validation loss: 2.0489505728085837

Epoch: 353| Step: 0
Training loss: 0.20673993229866028
Validation loss: 2.0265527417262397

Epoch: 5| Step: 1
Training loss: 0.32059088349342346
Validation loss: 2.065481315056483

Epoch: 5| Step: 2
Training loss: 0.2645423710346222
Validation loss: 2.1172321687142053

Epoch: 5| Step: 3
Training loss: 0.26483824849128723
Validation loss: 2.0587842762470245

Epoch: 5| Step: 4
Training loss: 0.6032931804656982
Validation loss: 2.095303530494372

Epoch: 5| Step: 5
Training loss: 0.21772727370262146
Validation loss: 2.0748188893000283

Epoch: 5| Step: 6
Training loss: 0.21410202980041504
Validation loss: 2.0518582264582315

Epoch: 5| Step: 7
Training loss: 0.46174755692481995
Validation loss: 2.0474358151356378

Epoch: 5| Step: 8
Training loss: 0.2817874550819397
Validation loss: 2.060403843720754

Epoch: 5| Step: 9
Training loss: 0.3306315541267395
Validation loss: 2.0536689112583795

Epoch: 5| Step: 10
Training loss: 0.5648695230484009
Validation loss: 2.088769962390264

Epoch: 5| Step: 11
Training loss: 0.47025465965270996
Validation loss: 2.075987622141838

Epoch: 354| Step: 0
Training loss: 0.6272076368331909
Validation loss: 2.0834458619356155

Epoch: 5| Step: 1
Training loss: 0.3889240026473999
Validation loss: 2.061184545358022

Epoch: 5| Step: 2
Training loss: 0.25346046686172485
Validation loss: 2.0749233663082123

Epoch: 5| Step: 3
Training loss: 0.4885355830192566
Validation loss: 2.055912420153618

Epoch: 5| Step: 4
Training loss: 0.32425540685653687
Validation loss: 2.0687993466854095

Epoch: 5| Step: 5
Training loss: 0.3163168430328369
Validation loss: 2.057160198688507

Epoch: 5| Step: 6
Training loss: 0.23651710152626038
Validation loss: 2.0403774678707123

Epoch: 5| Step: 7
Training loss: 0.3298046588897705
Validation loss: 2.0748532911141715

Epoch: 5| Step: 8
Training loss: 0.22093737125396729
Validation loss: 2.0109226206938424

Epoch: 5| Step: 9
Training loss: 0.3697547912597656
Validation loss: 2.0622947911421456

Epoch: 5| Step: 10
Training loss: 0.31145745515823364
Validation loss: 2.051756208141645

Epoch: 5| Step: 11
Training loss: 0.3300246000289917
Validation loss: 2.0793185184399285

Epoch: 355| Step: 0
Training loss: 0.3486352562904358
Validation loss: 2.0762129376331964

Epoch: 5| Step: 1
Training loss: 0.3865358233451843
Validation loss: 2.0326891392469406

Epoch: 5| Step: 2
Training loss: 0.8387438654899597
Validation loss: 2.0101599295934043

Epoch: 5| Step: 3
Training loss: 0.42448681592941284
Validation loss: 2.0388913303613663

Epoch: 5| Step: 4
Training loss: 0.3114246428012848
Validation loss: 2.1056885023911796

Epoch: 5| Step: 5
Training loss: 0.20470423996448517
Validation loss: 2.083040341734886

Epoch: 5| Step: 6
Training loss: 0.1904040277004242
Validation loss: 2.069053813815117

Epoch: 5| Step: 7
Training loss: 0.32677239179611206
Validation loss: 2.070846105615298

Epoch: 5| Step: 8
Training loss: 0.32221031188964844
Validation loss: 2.0950895100831985

Epoch: 5| Step: 9
Training loss: 0.47560104727745056
Validation loss: 2.0779952754577002

Epoch: 5| Step: 10
Training loss: 0.43205350637435913
Validation loss: 2.0851865708827972

Epoch: 5| Step: 11
Training loss: 0.08227558434009552
Validation loss: 2.075928916533788

Epoch: 356| Step: 0
Training loss: 0.5252424478530884
Validation loss: 2.0601622561613717

Epoch: 5| Step: 1
Training loss: 0.2532828748226166
Validation loss: 2.06594055891037

Epoch: 5| Step: 2
Training loss: 0.20075640082359314
Validation loss: 2.024207850297292

Epoch: 5| Step: 3
Training loss: 0.22897930443286896
Validation loss: 2.053112546602885

Epoch: 5| Step: 4
Training loss: 0.5026251077651978
Validation loss: 2.060482159256935

Epoch: 5| Step: 5
Training loss: 0.30976930260658264
Validation loss: 2.0876587380965552

Epoch: 5| Step: 6
Training loss: 0.3640877306461334
Validation loss: 2.045157720645269

Epoch: 5| Step: 7
Training loss: 0.3366314470767975
Validation loss: 2.076466883222262

Epoch: 5| Step: 8
Training loss: 0.3110291659832001
Validation loss: 2.0329557806253433

Epoch: 5| Step: 9
Training loss: 0.16793598234653473
Validation loss: 1.9940458337465923

Epoch: 5| Step: 10
Training loss: 0.351484477519989
Validation loss: 2.0343183279037476

Epoch: 5| Step: 11
Training loss: 0.11748284101486206
Validation loss: 2.095128426949183

Epoch: 357| Step: 0
Training loss: 0.3447972536087036
Validation loss: 2.0848596890767417

Epoch: 5| Step: 1
Training loss: 0.2776525616645813
Validation loss: 2.061593915025393

Epoch: 5| Step: 2
Training loss: 0.315396249294281
Validation loss: 2.0876134683688483

Epoch: 5| Step: 3
Training loss: 0.24314391613006592
Validation loss: 2.0309912661711373

Epoch: 5| Step: 4
Training loss: 0.2028389424085617
Validation loss: 2.0636066993077598

Epoch: 5| Step: 5
Training loss: 0.22315199673175812
Validation loss: 2.087178722023964

Epoch: 5| Step: 6
Training loss: 0.2946087718009949
Validation loss: 2.042357256015142

Epoch: 5| Step: 7
Training loss: 0.5059245228767395
Validation loss: 2.0141902963320413

Epoch: 5| Step: 8
Training loss: 0.2636588513851166
Validation loss: 2.0342234472433725

Epoch: 5| Step: 9
Training loss: 0.5068203806877136
Validation loss: 2.036037420233091

Epoch: 5| Step: 10
Training loss: 0.4574929177761078
Validation loss: 2.081162785490354

Epoch: 5| Step: 11
Training loss: 0.1897726058959961
Validation loss: 2.0811278323332467

Epoch: 358| Step: 0
Training loss: 0.48825564980506897
Validation loss: 2.097969258824984

Epoch: 5| Step: 1
Training loss: 0.3327829837799072
Validation loss: 2.088859329620997

Epoch: 5| Step: 2
Training loss: 0.31682974100112915
Validation loss: 2.0748047629992166

Epoch: 5| Step: 3
Training loss: 0.44869160652160645
Validation loss: 2.075195461511612

Epoch: 5| Step: 4
Training loss: 0.23748484253883362
Validation loss: 2.059236670533816

Epoch: 5| Step: 5
Training loss: 0.2601306140422821
Validation loss: 2.039052282770475

Epoch: 5| Step: 6
Training loss: 0.19520166516304016
Validation loss: 2.0537509818871817

Epoch: 5| Step: 7
Training loss: 0.17628684639930725
Validation loss: 2.030815437436104

Epoch: 5| Step: 8
Training loss: 0.2258255034685135
Validation loss: 2.0703018655379615

Epoch: 5| Step: 9
Training loss: 0.4125548303127289
Validation loss: 2.1131799618403115

Epoch: 5| Step: 10
Training loss: 0.20782852172851562
Validation loss: 2.033589785297712

Epoch: 5| Step: 11
Training loss: 0.8901503086090088
Validation loss: 2.0750163247187934

Epoch: 359| Step: 0
Training loss: 0.3954763412475586
Validation loss: 2.0533143281936646

Epoch: 5| Step: 1
Training loss: 0.26644963026046753
Validation loss: 2.0452342331409454

Epoch: 5| Step: 2
Training loss: 0.41842547059059143
Validation loss: 2.088744347294172

Epoch: 5| Step: 3
Training loss: 0.226997971534729
Validation loss: 2.046528548002243

Epoch: 5| Step: 4
Training loss: 0.47673743963241577
Validation loss: 2.0937876999378204

Epoch: 5| Step: 5
Training loss: 0.18984223902225494
Validation loss: 2.1020135432481766

Epoch: 5| Step: 6
Training loss: 0.5309366583824158
Validation loss: 2.0862176219622293

Epoch: 5| Step: 7
Training loss: 0.22783029079437256
Validation loss: 2.0478282471497855

Epoch: 5| Step: 8
Training loss: 0.24192123115062714
Validation loss: 2.0760360608498254

Epoch: 5| Step: 9
Training loss: 0.30769962072372437
Validation loss: 2.0605174799760184

Epoch: 5| Step: 10
Training loss: 0.25647273659706116
Validation loss: 2.094277262687683

Epoch: 5| Step: 11
Training loss: 0.03876572847366333
Validation loss: 2.0559973071018853

Epoch: 360| Step: 0
Training loss: 0.31780266761779785
Validation loss: 2.0687243143717446

Epoch: 5| Step: 1
Training loss: 0.25432443618774414
Validation loss: 2.0818875283002853

Epoch: 5| Step: 2
Training loss: 0.6056210398674011
Validation loss: 2.06904344757398

Epoch: 5| Step: 3
Training loss: 0.281724750995636
Validation loss: 2.0606820583343506

Epoch: 5| Step: 4
Training loss: 0.21546313166618347
Validation loss: 2.044246325890223

Epoch: 5| Step: 5
Training loss: 0.2450416535139084
Validation loss: 2.0622820258140564

Epoch: 5| Step: 6
Training loss: 0.28468888998031616
Validation loss: 2.0569118708372116

Epoch: 5| Step: 7
Training loss: 0.4048064351081848
Validation loss: 2.026540622115135

Epoch: 5| Step: 8
Training loss: 0.27268701791763306
Validation loss: 2.0645025769869485

Epoch: 5| Step: 9
Training loss: 0.32278260588645935
Validation loss: 2.0550422966480255

Epoch: 5| Step: 10
Training loss: 0.34617888927459717
Validation loss: 2.0691000322500863

Epoch: 5| Step: 11
Training loss: 0.24544084072113037
Validation loss: 2.033831626176834

Epoch: 361| Step: 0
Training loss: 0.28730911016464233
Validation loss: 2.080447276433309

Epoch: 5| Step: 1
Training loss: 0.3321141004562378
Validation loss: 2.0987954239050546

Epoch: 5| Step: 2
Training loss: 0.24302873015403748
Validation loss: 2.0448912481466928

Epoch: 5| Step: 3
Training loss: 0.3220345973968506
Validation loss: 2.007400249441465

Epoch: 5| Step: 4
Training loss: 0.31188562512397766
Validation loss: 2.0572613726059594

Epoch: 5| Step: 5
Training loss: 0.5536448359489441
Validation loss: 2.0697752783695855

Epoch: 5| Step: 6
Training loss: 0.1964460164308548
Validation loss: 2.069005494316419

Epoch: 5| Step: 7
Training loss: 0.19241146743297577
Validation loss: 2.0417133271694183

Epoch: 5| Step: 8
Training loss: 0.37536174058914185
Validation loss: 2.050574744741122

Epoch: 5| Step: 9
Training loss: 0.3329029679298401
Validation loss: 2.066759705543518

Epoch: 5| Step: 10
Training loss: 0.364319384098053
Validation loss: 2.1005789091189704

Epoch: 5| Step: 11
Training loss: 0.20412935316562653
Validation loss: 2.0346162666877112

Epoch: 362| Step: 0
Training loss: 0.4980255663394928
Validation loss: 2.050917685031891

Epoch: 5| Step: 1
Training loss: 0.5271204710006714
Validation loss: 2.059998353322347

Epoch: 5| Step: 2
Training loss: 0.3936464786529541
Validation loss: 2.0697434147198996

Epoch: 5| Step: 3
Training loss: 0.36758026480674744
Validation loss: 2.02598737180233

Epoch: 5| Step: 4
Training loss: 0.25808244943618774
Validation loss: 2.079992026090622

Epoch: 5| Step: 5
Training loss: 0.2844313979148865
Validation loss: 2.0119516303141913

Epoch: 5| Step: 6
Training loss: 0.31429868936538696
Validation loss: 2.0325846572717032

Epoch: 5| Step: 7
Training loss: 0.199575737118721
Validation loss: 2.0281970699628196

Epoch: 5| Step: 8
Training loss: 0.3702360987663269
Validation loss: 2.0670221696297326

Epoch: 5| Step: 9
Training loss: 0.28351879119873047
Validation loss: 2.071376850207647

Epoch: 5| Step: 10
Training loss: 0.3952389359474182
Validation loss: 2.084053019682566

Epoch: 5| Step: 11
Training loss: 0.38690608739852905
Validation loss: 2.067267874876658

Epoch: 363| Step: 0
Training loss: 0.2776804566383362
Validation loss: 2.046136731902758

Epoch: 5| Step: 1
Training loss: 0.38852939009666443
Validation loss: 2.051407312353452

Epoch: 5| Step: 2
Training loss: 0.2963373064994812
Validation loss: 2.0748768895864487

Epoch: 5| Step: 3
Training loss: 0.27909308671951294
Validation loss: 2.0480385770400367

Epoch: 5| Step: 4
Training loss: 0.3597230911254883
Validation loss: 2.0563131918509803

Epoch: 5| Step: 5
Training loss: 0.48843345046043396
Validation loss: 2.0831443667411804

Epoch: 5| Step: 6
Training loss: 0.38834601640701294
Validation loss: 2.0660762737194696

Epoch: 5| Step: 7
Training loss: 0.6432638168334961
Validation loss: 2.1515416403611503

Epoch: 5| Step: 8
Training loss: 0.336458295583725
Validation loss: 2.0865806192159653

Epoch: 5| Step: 9
Training loss: 0.39474648237228394
Validation loss: 2.098687022924423

Epoch: 5| Step: 10
Training loss: 0.25947660207748413
Validation loss: 2.058380588889122

Epoch: 5| Step: 11
Training loss: 0.3353229761123657
Validation loss: 2.0919435818990073

Epoch: 364| Step: 0
Training loss: 0.2582102417945862
Validation loss: 2.0766044159730277

Epoch: 5| Step: 1
Training loss: 0.4222249984741211
Validation loss: 2.089596023162206

Epoch: 5| Step: 2
Training loss: 0.2807648777961731
Validation loss: 2.0840625862280526

Epoch: 5| Step: 3
Training loss: 0.5132931470870972
Validation loss: 2.0713030894597373

Epoch: 5| Step: 4
Training loss: 0.5664623975753784
Validation loss: 2.0643651634454727

Epoch: 5| Step: 5
Training loss: 0.27969226241111755
Validation loss: 2.0231228470802307

Epoch: 5| Step: 6
Training loss: 0.30794745683670044
Validation loss: 2.04672110080719

Epoch: 5| Step: 7
Training loss: 0.20099851489067078
Validation loss: 2.1338023642698922

Epoch: 5| Step: 8
Training loss: 0.3363620638847351
Validation loss: 2.0948542108138404

Epoch: 5| Step: 9
Training loss: 0.3332465589046478
Validation loss: 2.116347605983416

Epoch: 5| Step: 10
Training loss: 0.20502038300037384
Validation loss: 2.0970045725504556

Epoch: 5| Step: 11
Training loss: 1.8257957696914673
Validation loss: 2.0651510258515677

Epoch: 365| Step: 0
Training loss: 0.20403042435646057
Validation loss: 2.0702268878618875

Epoch: 5| Step: 1
Training loss: 0.5124422907829285
Validation loss: 2.078021069367727

Epoch: 5| Step: 2
Training loss: 0.3691478669643402
Validation loss: 2.003877207636833

Epoch: 5| Step: 3
Training loss: 0.41301313042640686
Validation loss: 2.068040981888771

Epoch: 5| Step: 4
Training loss: 0.2893253266811371
Validation loss: 2.0623717407385507

Epoch: 5| Step: 5
Training loss: 0.4525756239891052
Validation loss: 2.0840881317853928

Epoch: 5| Step: 6
Training loss: 0.2111995965242386
Validation loss: 2.0776379257440567

Epoch: 5| Step: 7
Training loss: 0.21356216073036194
Validation loss: 2.0968560775121055

Epoch: 5| Step: 8
Training loss: 0.5224139094352722
Validation loss: 2.083878551920255

Epoch: 5| Step: 9
Training loss: 0.5815976858139038
Validation loss: 2.095293790102005

Epoch: 5| Step: 10
Training loss: 0.2982257008552551
Validation loss: 2.0819378842910132

Epoch: 5| Step: 11
Training loss: 0.2744326591491699
Validation loss: 2.0541190057992935

Epoch: 366| Step: 0
Training loss: 0.38379278779029846
Validation loss: 2.0722345213095346

Epoch: 5| Step: 1
Training loss: 0.3471289277076721
Validation loss: 2.032641048232714

Epoch: 5| Step: 2
Training loss: 0.6184984445571899
Validation loss: 1.9719775567452114

Epoch: 5| Step: 3
Training loss: 0.4210735261440277
Validation loss: 2.013014261921247

Epoch: 5| Step: 4
Training loss: 0.4013943672180176
Validation loss: 2.069528505206108

Epoch: 5| Step: 5
Training loss: 0.2898983359336853
Validation loss: 2.0527629454930625

Epoch: 5| Step: 6
Training loss: 0.21802373230457306
Validation loss: 2.040293167034785

Epoch: 5| Step: 7
Training loss: 0.2662290930747986
Validation loss: 2.027699967225393

Epoch: 5| Step: 8
Training loss: 0.2655225694179535
Validation loss: 2.0835913121700287

Epoch: 5| Step: 9
Training loss: 0.3097740113735199
Validation loss: 2.0560928086439767

Epoch: 5| Step: 10
Training loss: 0.2978385388851166
Validation loss: 2.0297746062278748

Epoch: 5| Step: 11
Training loss: 0.37331223487854004
Validation loss: 2.0439828683932624

Epoch: 367| Step: 0
Training loss: 0.1615859568119049
Validation loss: 2.0619914531707764

Epoch: 5| Step: 1
Training loss: 0.36207032203674316
Validation loss: 2.049048279722532

Epoch: 5| Step: 2
Training loss: 0.3335171043872833
Validation loss: 2.03398135304451

Epoch: 5| Step: 3
Training loss: 0.5427103042602539
Validation loss: 2.0690588603417077

Epoch: 5| Step: 4
Training loss: 0.34068435430526733
Validation loss: 2.0204352736473083

Epoch: 5| Step: 5
Training loss: 0.23948955535888672
Validation loss: 2.068176880478859

Epoch: 5| Step: 6
Training loss: 0.5520331263542175
Validation loss: 2.0975030809640884

Epoch: 5| Step: 7
Training loss: 0.3459819257259369
Validation loss: 2.058713912963867

Epoch: 5| Step: 8
Training loss: 0.2862994968891144
Validation loss: 2.0718315740426383

Epoch: 5| Step: 9
Training loss: 0.4560614228248596
Validation loss: 2.042957067489624

Epoch: 5| Step: 10
Training loss: 0.3087649643421173
Validation loss: 2.086771642168363

Epoch: 5| Step: 11
Training loss: 0.2712579369544983
Validation loss: 2.068012237548828

Epoch: 368| Step: 0
Training loss: 0.28658348321914673
Validation loss: 2.0277516146500907

Epoch: 5| Step: 1
Training loss: 0.6694600582122803
Validation loss: 2.0412364453077316

Epoch: 5| Step: 2
Training loss: 0.541806697845459
Validation loss: 2.0335316161314645

Epoch: 5| Step: 3
Training loss: 0.6877544522285461
Validation loss: 2.04704816142718

Epoch: 5| Step: 4
Training loss: 0.6308685541152954
Validation loss: 2.019434243440628

Epoch: 5| Step: 5
Training loss: 0.47430020570755005
Validation loss: 2.0071505258480706

Epoch: 5| Step: 6
Training loss: 0.3634967505931854
Validation loss: 2.0040814330180488

Epoch: 5| Step: 7
Training loss: 0.305257111787796
Validation loss: 2.027179261048635

Epoch: 5| Step: 8
Training loss: 0.32954543828964233
Validation loss: 2.0090995331605277

Epoch: 5| Step: 9
Training loss: 0.3350366950035095
Validation loss: 2.076686605811119

Epoch: 5| Step: 10
Training loss: 0.4047676622867584
Validation loss: 2.0942230025927224

Epoch: 5| Step: 11
Training loss: 0.12231045961380005
Validation loss: 2.051449403166771

Epoch: 369| Step: 0
Training loss: 0.8482991456985474
Validation loss: 2.0891700933376947

Epoch: 5| Step: 1
Training loss: 0.16946181654930115
Validation loss: 2.0455867449442544

Epoch: 5| Step: 2
Training loss: 0.23483724892139435
Validation loss: 2.02437915901343

Epoch: 5| Step: 3
Training loss: 0.40509048104286194
Validation loss: 2.0086441288391748

Epoch: 5| Step: 4
Training loss: 0.40563708543777466
Validation loss: 2.0134344001611075

Epoch: 5| Step: 5
Training loss: 0.38884902000427246
Validation loss: 2.0373476097981134

Epoch: 5| Step: 6
Training loss: 0.2902735769748688
Validation loss: 1.9891955306132634

Epoch: 5| Step: 7
Training loss: 0.21943922340869904
Validation loss: 2.0509585539499917

Epoch: 5| Step: 8
Training loss: 0.28241172432899475
Validation loss: 2.019868219892184

Epoch: 5| Step: 9
Training loss: 0.2504671514034271
Validation loss: 2.057735393444697

Epoch: 5| Step: 10
Training loss: 0.24015405774116516
Validation loss: 2.0042352279027305

Epoch: 5| Step: 11
Training loss: 0.1601046323776245
Validation loss: 1.9921345561742783

Epoch: 370| Step: 0
Training loss: 0.1432184875011444
Validation loss: 2.0049052983522415

Epoch: 5| Step: 1
Training loss: 0.3657570779323578
Validation loss: 2.053363621234894

Epoch: 5| Step: 2
Training loss: 0.2523714601993561
Validation loss: 2.0780025919278464

Epoch: 5| Step: 3
Training loss: 0.24265992641448975
Validation loss: 2.053239623705546

Epoch: 5| Step: 4
Training loss: 0.42479515075683594
Validation loss: 2.039111668864886

Epoch: 5| Step: 5
Training loss: 0.5339128375053406
Validation loss: 2.0476660827795663

Epoch: 5| Step: 6
Training loss: 0.30419689416885376
Validation loss: 2.059460828701655

Epoch: 5| Step: 7
Training loss: 0.25765934586524963
Validation loss: 2.0354450245698295

Epoch: 5| Step: 8
Training loss: 0.207526296377182
Validation loss: 2.0574535181125007

Epoch: 5| Step: 9
Training loss: 0.16861918568611145
Validation loss: 2.0784232169389725

Epoch: 5| Step: 10
Training loss: 0.5588504672050476
Validation loss: 2.02862415711085

Epoch: 5| Step: 11
Training loss: 0.2178441733121872
Validation loss: 2.064793477455775

Epoch: 371| Step: 0
Training loss: 0.6107799410820007
Validation loss: 2.053583468000094

Epoch: 5| Step: 1
Training loss: 0.32936760783195496
Validation loss: 2.0742123822371163

Epoch: 5| Step: 2
Training loss: 0.19103017449378967
Validation loss: 2.0632622291644416

Epoch: 5| Step: 3
Training loss: 0.31692254543304443
Validation loss: 2.077544113000234

Epoch: 5| Step: 4
Training loss: 0.2899709939956665
Validation loss: 2.0725055237611136

Epoch: 5| Step: 5
Training loss: 0.18508198857307434
Validation loss: 2.107293034593264

Epoch: 5| Step: 6
Training loss: 0.4598468244075775
Validation loss: 2.0795960128307343

Epoch: 5| Step: 7
Training loss: 0.24623794853687286
Validation loss: 2.049995626012484

Epoch: 5| Step: 8
Training loss: 0.19643640518188477
Validation loss: 2.0745858500401178

Epoch: 5| Step: 9
Training loss: 0.2534927725791931
Validation loss: 2.0480381747086844

Epoch: 5| Step: 10
Training loss: 0.258737713098526
Validation loss: 2.0528607716163

Epoch: 5| Step: 11
Training loss: 0.5534608364105225
Validation loss: 2.071018988887469

Epoch: 372| Step: 0
Training loss: 0.15771277248859406
Validation loss: 2.086053450902303

Epoch: 5| Step: 1
Training loss: 0.2670428156852722
Validation loss: 2.0338949461778006

Epoch: 5| Step: 2
Training loss: 0.23335787653923035
Validation loss: 2.082525541385015

Epoch: 5| Step: 3
Training loss: 0.24271002411842346
Validation loss: 2.029676924149195

Epoch: 5| Step: 4
Training loss: 0.22494474053382874
Validation loss: 2.0315815756718316

Epoch: 5| Step: 5
Training loss: 0.2913384437561035
Validation loss: 2.065533146262169

Epoch: 5| Step: 6
Training loss: 0.35590505599975586
Validation loss: 2.0707420855760574

Epoch: 5| Step: 7
Training loss: 0.2888779044151306
Validation loss: 2.059444392720858

Epoch: 5| Step: 8
Training loss: 0.25320950150489807
Validation loss: 2.0665942976872125

Epoch: 5| Step: 9
Training loss: 0.7685444355010986
Validation loss: 2.0892147372166314

Epoch: 5| Step: 10
Training loss: 0.21860739588737488
Validation loss: 2.088470200697581

Epoch: 5| Step: 11
Training loss: 0.23995137214660645
Validation loss: 2.064021294315656

Epoch: 373| Step: 0
Training loss: 0.23807677626609802
Validation loss: 2.060747876763344

Epoch: 5| Step: 1
Training loss: 0.3998869061470032
Validation loss: 2.0418727099895477

Epoch: 5| Step: 2
Training loss: 0.13759654760360718
Validation loss: 2.0621643910805383

Epoch: 5| Step: 3
Training loss: 0.31943172216415405
Validation loss: 2.037347470720609

Epoch: 5| Step: 4
Training loss: 0.2774113416671753
Validation loss: 2.077921231587728

Epoch: 5| Step: 5
Training loss: 0.7251314520835876
Validation loss: 2.108867257833481

Epoch: 5| Step: 6
Training loss: 0.2834315896034241
Validation loss: 2.072673017779986

Epoch: 5| Step: 7
Training loss: 0.26766499876976013
Validation loss: 2.087410738070806

Epoch: 5| Step: 8
Training loss: 0.2683037221431732
Validation loss: 2.0814929703871408

Epoch: 5| Step: 9
Training loss: 0.21738114953041077
Validation loss: 2.0365749994913735

Epoch: 5| Step: 10
Training loss: 0.29555851221084595
Validation loss: 2.035287236173948

Epoch: 5| Step: 11
Training loss: 0.12284350395202637
Validation loss: 2.0456709067026773

Epoch: 374| Step: 0
Training loss: 0.14802804589271545
Validation loss: 2.079419031739235

Epoch: 5| Step: 1
Training loss: 0.41300544142723083
Validation loss: 2.026090587178866

Epoch: 5| Step: 2
Training loss: 0.5608296394348145
Validation loss: 2.0274577935536704

Epoch: 5| Step: 3
Training loss: 0.22002747654914856
Validation loss: 2.0225463658571243

Epoch: 5| Step: 4
Training loss: 0.31845980882644653
Validation loss: 2.008033369978269

Epoch: 5| Step: 5
Training loss: 0.3494853973388672
Validation loss: 2.070061519742012

Epoch: 5| Step: 6
Training loss: 0.250736802816391
Validation loss: 2.0390540411074958

Epoch: 5| Step: 7
Training loss: 0.4557262361049652
Validation loss: 2.004906957348188

Epoch: 5| Step: 8
Training loss: 0.20360882580280304
Validation loss: 2.046617180109024

Epoch: 5| Step: 9
Training loss: 0.33772069215774536
Validation loss: 2.039340446392695

Epoch: 5| Step: 10
Training loss: 0.27999064326286316
Validation loss: 2.0226808885733285

Epoch: 5| Step: 11
Training loss: 0.16729950904846191
Validation loss: 2.0800988227128983

Epoch: 375| Step: 0
Training loss: 0.3071172535419464
Validation loss: 2.025897632042567

Epoch: 5| Step: 1
Training loss: 0.2478584498167038
Validation loss: 2.042977139353752

Epoch: 5| Step: 2
Training loss: 0.36900410056114197
Validation loss: 2.0812321851650872

Epoch: 5| Step: 3
Training loss: 0.25890833139419556
Validation loss: 2.0388227651516595

Epoch: 5| Step: 4
Training loss: 0.4862731993198395
Validation loss: 2.0718038777510324

Epoch: 5| Step: 5
Training loss: 0.5358222723007202
Validation loss: 2.0600220461686454

Epoch: 5| Step: 6
Training loss: 0.15839435160160065
Validation loss: 2.1077421406904855

Epoch: 5| Step: 7
Training loss: 0.28177905082702637
Validation loss: 2.0226438343524933

Epoch: 5| Step: 8
Training loss: 0.27052441239356995
Validation loss: 2.063284754753113

Epoch: 5| Step: 9
Training loss: 0.22266753017902374
Validation loss: 2.055359795689583

Epoch: 5| Step: 10
Training loss: 0.23625507950782776
Validation loss: 2.0208443154891333

Epoch: 5| Step: 11
Training loss: 0.41755008697509766
Validation loss: 2.1281767884890237

Epoch: 376| Step: 0
Training loss: 0.19868192076683044
Validation loss: 2.0518976052602134

Epoch: 5| Step: 1
Training loss: 0.2066805064678192
Validation loss: 2.048464442292849

Epoch: 5| Step: 2
Training loss: 0.3636620044708252
Validation loss: 2.065188785394033

Epoch: 5| Step: 3
Training loss: 0.21501338481903076
Validation loss: 2.0577624241511026

Epoch: 5| Step: 4
Training loss: 0.22892160713672638
Validation loss: 2.0654324193795524

Epoch: 5| Step: 5
Training loss: 0.2781451940536499
Validation loss: 2.068469097216924

Epoch: 5| Step: 6
Training loss: 0.24484053254127502
Validation loss: 2.019819051027298

Epoch: 5| Step: 7
Training loss: 0.5549012422561646
Validation loss: 2.0331956247488656

Epoch: 5| Step: 8
Training loss: 0.38025158643722534
Validation loss: 2.053670605023702

Epoch: 5| Step: 9
Training loss: 0.4203064441680908
Validation loss: 2.0501784831285477

Epoch: 5| Step: 10
Training loss: 0.3129432797431946
Validation loss: 2.050771797696749

Epoch: 5| Step: 11
Training loss: 0.28104355931282043
Validation loss: 2.0279623369375863

Epoch: 377| Step: 0
Training loss: 0.3614620268344879
Validation loss: 2.035000200072924

Epoch: 5| Step: 1
Training loss: 0.32372599840164185
Validation loss: 2.041148687402407

Epoch: 5| Step: 2
Training loss: 0.1915648877620697
Validation loss: 2.043507844209671

Epoch: 5| Step: 3
Training loss: 0.1953485757112503
Validation loss: 2.024076188604037

Epoch: 5| Step: 4
Training loss: 0.230695441365242
Validation loss: 2.0259010742108026

Epoch: 5| Step: 5
Training loss: 0.1748225837945938
Validation loss: 2.0326629678408303

Epoch: 5| Step: 6
Training loss: 0.3101244866847992
Validation loss: 1.9705994427204132

Epoch: 5| Step: 7
Training loss: 0.3053183853626251
Validation loss: 2.032975286245346

Epoch: 5| Step: 8
Training loss: 0.3907761871814728
Validation loss: 2.056432401140531

Epoch: 5| Step: 9
Training loss: 0.5357464551925659
Validation loss: 2.0240088552236557

Epoch: 5| Step: 10
Training loss: 0.581128716468811
Validation loss: 2.06269878645738

Epoch: 5| Step: 11
Training loss: 0.33464109897613525
Validation loss: 2.0822295447190604

Epoch: 378| Step: 0
Training loss: 0.682000994682312
Validation loss: 2.0777289420366287

Epoch: 5| Step: 1
Training loss: 0.38686591386795044
Validation loss: 2.0910162329673767

Epoch: 5| Step: 2
Training loss: 0.33087894320487976
Validation loss: 2.043174440662066

Epoch: 5| Step: 3
Training loss: 0.36793649196624756
Validation loss: 2.03290726741155

Epoch: 5| Step: 4
Training loss: 0.37140053510665894
Validation loss: 2.0260832210381827

Epoch: 5| Step: 5
Training loss: 0.41084203124046326
Validation loss: 2.043645272652308

Epoch: 5| Step: 6
Training loss: 0.4491627812385559
Validation loss: 2.0325912535190582

Epoch: 5| Step: 7
Training loss: 0.3129752278327942
Validation loss: 2.040069301923116

Epoch: 5| Step: 8
Training loss: 0.3824891746044159
Validation loss: 2.0598519295454025

Epoch: 5| Step: 9
Training loss: 0.16922679543495178
Validation loss: 2.0719639708598456

Epoch: 5| Step: 10
Training loss: 0.20363345742225647
Validation loss: 2.054548278450966

Epoch: 5| Step: 11
Training loss: 0.3618937134742737
Validation loss: 2.0519953022400537

Epoch: 379| Step: 0
Training loss: 0.21958331763744354
Validation loss: 2.0642731885115304

Epoch: 5| Step: 1
Training loss: 0.273057758808136
Validation loss: 2.034141555428505

Epoch: 5| Step: 2
Training loss: 0.29364222288131714
Validation loss: 2.1103027909994125

Epoch: 5| Step: 3
Training loss: 0.22286686301231384
Validation loss: 2.03165872891744

Epoch: 5| Step: 4
Training loss: 0.36348432302474976
Validation loss: 2.0673564076423645

Epoch: 5| Step: 5
Training loss: 0.34345152974128723
Validation loss: 2.028468976418177

Epoch: 5| Step: 6
Training loss: 0.495579332113266
Validation loss: 2.051173602541288

Epoch: 5| Step: 7
Training loss: 0.6429208517074585
Validation loss: 2.0600691636403403

Epoch: 5| Step: 8
Training loss: 0.5499693751335144
Validation loss: 2.0449530432621636

Epoch: 5| Step: 9
Training loss: 0.16322457790374756
Validation loss: 2.04233252008756

Epoch: 5| Step: 10
Training loss: 0.3251121938228607
Validation loss: 2.036749934156736

Epoch: 5| Step: 11
Training loss: 0.23662027716636658
Validation loss: 2.0874836246172586

Epoch: 380| Step: 0
Training loss: 0.40147870779037476
Validation loss: 2.0627866039673486

Epoch: 5| Step: 1
Training loss: 0.30937451124191284
Validation loss: 2.0668892711400986

Epoch: 5| Step: 2
Training loss: 0.37666743993759155
Validation loss: 2.072350745399793

Epoch: 5| Step: 3
Training loss: 0.23366352915763855
Validation loss: 2.050138701995214

Epoch: 5| Step: 4
Training loss: 0.21871857345104218
Validation loss: 2.0145774334669113

Epoch: 5| Step: 5
Training loss: 0.29688453674316406
Validation loss: 2.0660334676504135

Epoch: 5| Step: 6
Training loss: 0.2883445620536804
Validation loss: 2.0416339288155236

Epoch: 5| Step: 7
Training loss: 0.27922192215919495
Validation loss: 2.0658893088499704

Epoch: 5| Step: 8
Training loss: 0.8791291117668152
Validation loss: 2.0554165790478387

Epoch: 5| Step: 9
Training loss: 0.3742617964744568
Validation loss: 2.0223939766486487

Epoch: 5| Step: 10
Training loss: 0.15846610069274902
Validation loss: 2.02466356754303

Epoch: 5| Step: 11
Training loss: 0.44776877760887146
Validation loss: 2.086895525455475

Epoch: 381| Step: 0
Training loss: 0.255729615688324
Validation loss: 2.0454044193029404

Epoch: 5| Step: 1
Training loss: 0.17480503022670746
Validation loss: 2.045165886481603

Epoch: 5| Step: 2
Training loss: 0.2365376502275467
Validation loss: 2.093153183658918

Epoch: 5| Step: 3
Training loss: 0.25347405672073364
Validation loss: 2.103521009286245

Epoch: 5| Step: 4
Training loss: 0.49799853563308716
Validation loss: 2.0389295667409897

Epoch: 5| Step: 5
Training loss: 0.22774672508239746
Validation loss: 2.040223151445389

Epoch: 5| Step: 6
Training loss: 0.37267714738845825
Validation loss: 2.064737632870674

Epoch: 5| Step: 7
Training loss: 0.5711711049079895
Validation loss: 2.042201201121012

Epoch: 5| Step: 8
Training loss: 0.24318337440490723
Validation loss: 2.049656401077906

Epoch: 5| Step: 9
Training loss: 0.2958245575428009
Validation loss: 2.084136242667834

Epoch: 5| Step: 10
Training loss: 0.21617431938648224
Validation loss: 2.018278330564499

Epoch: 5| Step: 11
Training loss: 0.0651392936706543
Validation loss: 2.0506635904312134

Epoch: 382| Step: 0
Training loss: 0.4675477147102356
Validation loss: 2.06166572868824

Epoch: 5| Step: 1
Training loss: 0.2522197961807251
Validation loss: 2.0664659440517426

Epoch: 5| Step: 2
Training loss: 0.29477351903915405
Validation loss: 2.068086802959442

Epoch: 5| Step: 3
Training loss: 0.22927002608776093
Validation loss: 2.058895712097486

Epoch: 5| Step: 4
Training loss: 0.30394214391708374
Validation loss: 2.0352604587872825

Epoch: 5| Step: 5
Training loss: 0.20768249034881592
Validation loss: 2.0731611102819443

Epoch: 5| Step: 6
Training loss: 0.2546972632408142
Validation loss: 2.0823224037885666

Epoch: 5| Step: 7
Training loss: 0.38000044226646423
Validation loss: 2.0742617348829904

Epoch: 5| Step: 8
Training loss: 0.5503765940666199
Validation loss: 2.075873096783956

Epoch: 5| Step: 9
Training loss: 0.2692872881889343
Validation loss: 2.0810402731100717

Epoch: 5| Step: 10
Training loss: 0.2626248002052307
Validation loss: 2.053666522105535

Epoch: 5| Step: 11
Training loss: 0.1680682897567749
Validation loss: 1.9964690059423447

Epoch: 383| Step: 0
Training loss: 0.2642865478992462
Validation loss: 2.058778464794159

Epoch: 5| Step: 1
Training loss: 0.34929007291793823
Validation loss: 2.068231994907061

Epoch: 5| Step: 2
Training loss: 0.3909332752227783
Validation loss: 2.0501629114151

Epoch: 5| Step: 3
Training loss: 0.1866629421710968
Validation loss: 2.1003192563851676

Epoch: 5| Step: 4
Training loss: 0.8212167620658875
Validation loss: 2.0586797446012497

Epoch: 5| Step: 5
Training loss: 0.20292992889881134
Validation loss: 2.0820022424062095

Epoch: 5| Step: 6
Training loss: 0.26436111330986023
Validation loss: 2.0698602398236594

Epoch: 5| Step: 7
Training loss: 0.22018639743328094
Validation loss: 2.024568478266398

Epoch: 5| Step: 8
Training loss: 0.31799522042274475
Validation loss: 2.042712872227033

Epoch: 5| Step: 9
Training loss: 0.19333696365356445
Validation loss: 2.065219536423683

Epoch: 5| Step: 10
Training loss: 0.1618572175502777
Validation loss: 2.0364394237597785

Epoch: 5| Step: 11
Training loss: 0.29741695523262024
Validation loss: 2.080853377779325

Epoch: 384| Step: 0
Training loss: 0.21705488860607147
Validation loss: 2.113219658533732

Epoch: 5| Step: 1
Training loss: 0.19553224742412567
Validation loss: 2.0564958254496255

Epoch: 5| Step: 2
Training loss: 0.20162717998027802
Validation loss: 2.070922330021858

Epoch: 5| Step: 3
Training loss: 0.1770578771829605
Validation loss: 2.0641107658545175

Epoch: 5| Step: 4
Training loss: 0.4885309338569641
Validation loss: 2.0388077100118003

Epoch: 5| Step: 5
Training loss: 0.3748524785041809
Validation loss: 2.0816115736961365

Epoch: 5| Step: 6
Training loss: 0.4513201117515564
Validation loss: 2.0758501986662545

Epoch: 5| Step: 7
Training loss: 0.5504049062728882
Validation loss: 2.0710745553175607

Epoch: 5| Step: 8
Training loss: 0.2773045301437378
Validation loss: 2.064839387933413

Epoch: 5| Step: 9
Training loss: 0.28419578075408936
Validation loss: 2.0490299314260483

Epoch: 5| Step: 10
Training loss: 0.2971634268760681
Validation loss: 2.1043930053710938

Epoch: 5| Step: 11
Training loss: 0.36152637004852295
Validation loss: 2.0751243978738785

Epoch: 385| Step: 0
Training loss: 0.3222242295742035
Validation loss: 2.0438297390937805

Epoch: 5| Step: 1
Training loss: 0.302362322807312
Validation loss: 2.0268671760956445

Epoch: 5| Step: 2
Training loss: 0.20635256171226501
Validation loss: 2.060303916533788

Epoch: 5| Step: 3
Training loss: 0.22885394096374512
Validation loss: 2.071650822957357

Epoch: 5| Step: 4
Training loss: 0.3203195035457611
Validation loss: 2.0353461106618247

Epoch: 5| Step: 5
Training loss: 0.19228193163871765
Validation loss: 2.066359266638756

Epoch: 5| Step: 6
Training loss: 0.1868058741092682
Validation loss: 2.0169317026933036

Epoch: 5| Step: 7
Training loss: 0.300953209400177
Validation loss: 2.055731768409411

Epoch: 5| Step: 8
Training loss: 0.23062312602996826
Validation loss: 2.0444918423891068

Epoch: 5| Step: 9
Training loss: 0.3019527792930603
Validation loss: 2.0371474027633667

Epoch: 5| Step: 10
Training loss: 0.6274069547653198
Validation loss: 2.024045924345652

Epoch: 5| Step: 11
Training loss: 0.09925292432308197
Validation loss: 2.010928491751353

Epoch: 386| Step: 0
Training loss: 0.2514232099056244
Validation loss: 2.0419245610634484

Epoch: 5| Step: 1
Training loss: 0.3519212603569031
Validation loss: 2.0641848047574363

Epoch: 5| Step: 2
Training loss: 0.25544843077659607
Validation loss: 2.065134361386299

Epoch: 5| Step: 3
Training loss: 0.5149233937263489
Validation loss: 2.025461117426554

Epoch: 5| Step: 4
Training loss: 0.23306164145469666
Validation loss: 2.0302770336469016

Epoch: 5| Step: 5
Training loss: 0.21220532059669495
Validation loss: 2.0207538157701492

Epoch: 5| Step: 6
Training loss: 0.4124840795993805
Validation loss: 2.069563274582227

Epoch: 5| Step: 7
Training loss: 0.4063335359096527
Validation loss: 2.0429700861374536

Epoch: 5| Step: 8
Training loss: 0.2538105845451355
Validation loss: 2.0310781399408975

Epoch: 5| Step: 9
Training loss: 0.22940945625305176
Validation loss: 2.093863765398661

Epoch: 5| Step: 10
Training loss: 0.20474660396575928
Validation loss: 2.0816997786362967

Epoch: 5| Step: 11
Training loss: 0.5014005303382874
Validation loss: 2.082883487145106

Epoch: 387| Step: 0
Training loss: 0.254432737827301
Validation loss: 2.091967612504959

Epoch: 5| Step: 1
Training loss: 0.20347170531749725
Validation loss: 2.044157718618711

Epoch: 5| Step: 2
Training loss: 0.19964054226875305
Validation loss: 2.029443437854449

Epoch: 5| Step: 3
Training loss: 0.41383591294288635
Validation loss: 2.0671447664499283

Epoch: 5| Step: 4
Training loss: 0.3041219413280487
Validation loss: 2.103782425324122

Epoch: 5| Step: 5
Training loss: 0.15024077892303467
Validation loss: 2.0825118025143943

Epoch: 5| Step: 6
Training loss: 0.18900318443775177
Validation loss: 2.07877878844738

Epoch: 5| Step: 7
Training loss: 0.603857159614563
Validation loss: 2.0967090725898743

Epoch: 5| Step: 8
Training loss: 0.45748576521873474
Validation loss: 2.093499427040418

Epoch: 5| Step: 9
Training loss: 0.28099894523620605
Validation loss: 2.0676129360993705

Epoch: 5| Step: 10
Training loss: 0.1550646275281906
Validation loss: 2.1095658044020333

Epoch: 5| Step: 11
Training loss: 0.22915013134479523
Validation loss: 2.0450140287478766

Epoch: 388| Step: 0
Training loss: 0.35687780380249023
Validation loss: 2.0937215834856033

Epoch: 5| Step: 1
Training loss: 0.21834318339824677
Validation loss: 2.0154433051745095

Epoch: 5| Step: 2
Training loss: 0.3410901725292206
Validation loss: 2.0714982400337854

Epoch: 5| Step: 3
Training loss: 0.5557323694229126
Validation loss: 2.078553467988968

Epoch: 5| Step: 4
Training loss: 0.30566346645355225
Validation loss: 2.093319535255432

Epoch: 5| Step: 5
Training loss: 0.18239609897136688
Validation loss: 2.0809819300969443

Epoch: 5| Step: 6
Training loss: 0.2592024505138397
Validation loss: 2.097695822517077

Epoch: 5| Step: 7
Training loss: 0.1739283800125122
Validation loss: 2.013106197118759

Epoch: 5| Step: 8
Training loss: 0.3261949121952057
Validation loss: 2.032069151600202

Epoch: 5| Step: 9
Training loss: 0.19277189671993256
Validation loss: 2.0862515419721603

Epoch: 5| Step: 10
Training loss: 0.3017813563346863
Validation loss: 2.048061197002729

Epoch: 5| Step: 11
Training loss: 0.14583873748779297
Validation loss: 2.0402657240629196

Epoch: 389| Step: 0
Training loss: 0.19808781147003174
Validation loss: 2.0222104291121163

Epoch: 5| Step: 1
Training loss: 0.21759995818138123
Validation loss: 2.0031240582466125

Epoch: 5| Step: 2
Training loss: 0.43654704093933105
Validation loss: 2.047894070545832

Epoch: 5| Step: 3
Training loss: 0.4937557280063629
Validation loss: 2.029672255118688

Epoch: 5| Step: 4
Training loss: 0.1738588809967041
Validation loss: 2.0970807572205863

Epoch: 5| Step: 5
Training loss: 0.2497619390487671
Validation loss: 2.043657958507538

Epoch: 5| Step: 6
Training loss: 0.23949506878852844
Validation loss: 2.024105727672577

Epoch: 5| Step: 7
Training loss: 0.4984235167503357
Validation loss: 2.056928967436155

Epoch: 5| Step: 8
Training loss: 0.4148079454898834
Validation loss: 2.052369107802709

Epoch: 5| Step: 9
Training loss: 0.23855933547019958
Validation loss: 2.0525682916243873

Epoch: 5| Step: 10
Training loss: 0.2522398829460144
Validation loss: 2.073196386297544

Epoch: 5| Step: 11
Training loss: 0.11335331201553345
Validation loss: 2.026929035782814

Epoch: 390| Step: 0
Training loss: 0.347628653049469
Validation loss: 2.068916459878286

Epoch: 5| Step: 1
Training loss: 0.2899976968765259
Validation loss: 2.057597110668818

Epoch: 5| Step: 2
Training loss: 0.331116259098053
Validation loss: 2.0804139375686646

Epoch: 5| Step: 3
Training loss: 0.29477471113204956
Validation loss: 2.0696332504351935

Epoch: 5| Step: 4
Training loss: 0.16057756543159485
Validation loss: 2.066002205014229

Epoch: 5| Step: 5
Training loss: 0.2187768518924713
Validation loss: 2.0487233301003775

Epoch: 5| Step: 6
Training loss: 0.17169776558876038
Validation loss: 2.0572042912244797

Epoch: 5| Step: 7
Training loss: 0.2347080260515213
Validation loss: 2.0776611467202506

Epoch: 5| Step: 8
Training loss: 0.4863170087337494
Validation loss: 2.075426404674848

Epoch: 5| Step: 9
Training loss: 0.17356888949871063
Validation loss: 2.080289433399836

Epoch: 5| Step: 10
Training loss: 0.2585735619068146
Validation loss: 2.0964928219715753

Epoch: 5| Step: 11
Training loss: 0.9527762532234192
Validation loss: 2.0749787439902625

Epoch: 391| Step: 0
Training loss: 0.2606416940689087
Validation loss: 2.0790847142537436

Epoch: 5| Step: 1
Training loss: 0.3042367994785309
Validation loss: 2.096163402001063

Epoch: 5| Step: 2
Training loss: 0.477790892124176
Validation loss: 2.0967470159133277

Epoch: 5| Step: 3
Training loss: 0.5653697848320007
Validation loss: 2.050891642769178

Epoch: 5| Step: 4
Training loss: 0.3334652781486511
Validation loss: 2.0663751463095346

Epoch: 5| Step: 5
Training loss: 0.16769751906394958
Validation loss: 2.0840481420358024

Epoch: 5| Step: 6
Training loss: 0.22234006226062775
Validation loss: 2.0607483436663947

Epoch: 5| Step: 7
Training loss: 0.3115445375442505
Validation loss: 2.0779569894075394

Epoch: 5| Step: 8
Training loss: 0.25820392370224
Validation loss: 2.0678505897521973

Epoch: 5| Step: 9
Training loss: 0.37930968403816223
Validation loss: 2.096965233484904

Epoch: 5| Step: 10
Training loss: 0.38242319226264954
Validation loss: 2.083193083604177

Epoch: 5| Step: 11
Training loss: 0.3706291913986206
Validation loss: 2.0446847677230835

Epoch: 392| Step: 0
Training loss: 0.21761396527290344
Validation loss: 2.0600954741239548

Epoch: 5| Step: 1
Training loss: 0.461475670337677
Validation loss: 2.0483587433894477

Epoch: 5| Step: 2
Training loss: 0.4060136675834656
Validation loss: 2.0849126180013022

Epoch: 5| Step: 3
Training loss: 0.40594345331192017
Validation loss: 2.0645534694194794

Epoch: 5| Step: 4
Training loss: 0.6046729683876038
Validation loss: 2.0732414225737252

Epoch: 5| Step: 5
Training loss: 0.24900925159454346
Validation loss: 2.0437286496162415

Epoch: 5| Step: 6
Training loss: 0.2535772919654846
Validation loss: 2.0864530255397162

Epoch: 5| Step: 7
Training loss: 0.5793659090995789
Validation loss: 2.053220530351003

Epoch: 5| Step: 8
Training loss: 0.5083931088447571
Validation loss: 2.0665225883324942

Epoch: 5| Step: 9
Training loss: 0.3207031190395355
Validation loss: 2.0744336346785226

Epoch: 5| Step: 10
Training loss: 0.1949421912431717
Validation loss: 2.054220790664355

Epoch: 5| Step: 11
Training loss: 0.1643815040588379
Validation loss: 2.0903368492921195

Epoch: 393| Step: 0
Training loss: 0.19150812923908234
Validation loss: 1.9963469008604686

Epoch: 5| Step: 1
Training loss: 0.2639947831630707
Validation loss: 2.0496567289034524

Epoch: 5| Step: 2
Training loss: 0.309767484664917
Validation loss: 2.063323602080345

Epoch: 5| Step: 3
Training loss: 0.2978389859199524
Validation loss: 2.039749508102735

Epoch: 5| Step: 4
Training loss: 0.358853816986084
Validation loss: 2.0572251876195273

Epoch: 5| Step: 5
Training loss: 0.2049103081226349
Validation loss: 2.0833646257718406

Epoch: 5| Step: 6
Training loss: 0.18923699855804443
Validation loss: 2.0707015643517175

Epoch: 5| Step: 7
Training loss: 0.6249486207962036
Validation loss: 2.0761529952287674

Epoch: 5| Step: 8
Training loss: 0.2765467166900635
Validation loss: 2.0382639517386756

Epoch: 5| Step: 9
Training loss: 0.33858662843704224
Validation loss: 2.1404014229774475

Epoch: 5| Step: 10
Training loss: 0.3464464545249939
Validation loss: 2.0833905090888343

Epoch: 5| Step: 11
Training loss: 0.8446817398071289
Validation loss: 2.038598448038101

Epoch: 394| Step: 0
Training loss: 0.21224403381347656
Validation loss: 2.0717401603857675

Epoch: 5| Step: 1
Training loss: 0.28315025568008423
Validation loss: 2.054003342986107

Epoch: 5| Step: 2
Training loss: 0.2965638339519501
Validation loss: 2.0124966353178024

Epoch: 5| Step: 3
Training loss: 0.3784896433353424
Validation loss: 2.0636706203222275

Epoch: 5| Step: 4
Training loss: 0.28858837485313416
Validation loss: 2.0310883124669394

Epoch: 5| Step: 5
Training loss: 0.18681780993938446
Validation loss: 2.062517295281092

Epoch: 5| Step: 6
Training loss: 0.27740344405174255
Validation loss: 2.0307396998008094

Epoch: 5| Step: 7
Training loss: 0.7964428663253784
Validation loss: 2.101011728247007

Epoch: 5| Step: 8
Training loss: 0.3739226758480072
Validation loss: 2.088121384382248

Epoch: 5| Step: 9
Training loss: 0.24296176433563232
Validation loss: 2.0531538228193917

Epoch: 5| Step: 10
Training loss: 0.2511144280433655
Validation loss: 2.061604748169581

Epoch: 5| Step: 11
Training loss: 0.18678534030914307
Validation loss: 2.0731641252835593

Epoch: 395| Step: 0
Training loss: 0.23141618072986603
Validation loss: 2.0202631851037345

Epoch: 5| Step: 1
Training loss: 0.3435368835926056
Validation loss: 2.0684246122837067

Epoch: 5| Step: 2
Training loss: 0.2758479118347168
Validation loss: 2.0481678545475006

Epoch: 5| Step: 3
Training loss: 0.21528315544128418
Validation loss: 2.097405875722567

Epoch: 5| Step: 4
Training loss: 0.3624219000339508
Validation loss: 2.0483659505844116

Epoch: 5| Step: 5
Training loss: 0.2052314579486847
Validation loss: 2.050792341430982

Epoch: 5| Step: 6
Training loss: 0.6987929344177246
Validation loss: 2.023716479539871

Epoch: 5| Step: 7
Training loss: 0.23105549812316895
Validation loss: 2.058794920643171

Epoch: 5| Step: 8
Training loss: 0.2740793824195862
Validation loss: 2.0188847482204437

Epoch: 5| Step: 9
Training loss: 0.2657403349876404
Validation loss: 2.0397823254267373

Epoch: 5| Step: 10
Training loss: 0.17976248264312744
Validation loss: 2.073740621407827

Epoch: 5| Step: 11
Training loss: 0.13698989152908325
Validation loss: 2.0698690712451935

Epoch: 396| Step: 0
Training loss: 0.17386116087436676
Validation loss: 2.074259400367737

Epoch: 5| Step: 1
Training loss: 0.28575316071510315
Validation loss: 2.1187498519817987

Epoch: 5| Step: 2
Training loss: 0.1965896189212799
Validation loss: 2.0705097864071527

Epoch: 5| Step: 3
Training loss: 0.5924748182296753
Validation loss: 2.0417569230000177

Epoch: 5| Step: 4
Training loss: 0.40074053406715393
Validation loss: 2.067854101459185

Epoch: 5| Step: 5
Training loss: 0.21669378876686096
Validation loss: 2.0658384511868157

Epoch: 5| Step: 6
Training loss: 0.39525699615478516
Validation loss: 2.0818195591370263

Epoch: 5| Step: 7
Training loss: 0.24431738257408142
Validation loss: 2.09559657673041

Epoch: 5| Step: 8
Training loss: 0.22571715712547302
Validation loss: 2.030237396558126

Epoch: 5| Step: 9
Training loss: 0.3414323031902313
Validation loss: 2.04288083811601

Epoch: 5| Step: 10
Training loss: 0.15496911108493805
Validation loss: 2.027529716491699

Epoch: 5| Step: 11
Training loss: 0.40691184997558594
Validation loss: 2.0263434102137885

Epoch: 397| Step: 0
Training loss: 0.5230028629302979
Validation loss: 2.051138937473297

Epoch: 5| Step: 1
Training loss: 0.3667316138744354
Validation loss: 2.056647260983785

Epoch: 5| Step: 2
Training loss: 0.37284719944000244
Validation loss: 2.106378282109896

Epoch: 5| Step: 3
Training loss: 0.4105216860771179
Validation loss: 2.1040102541446686

Epoch: 5| Step: 4
Training loss: 0.21215757727622986
Validation loss: 2.109081953763962

Epoch: 5| Step: 5
Training loss: 0.3157070279121399
Validation loss: 2.0624962200721106

Epoch: 5| Step: 6
Training loss: 0.20759102702140808
Validation loss: 2.067663366595904

Epoch: 5| Step: 7
Training loss: 0.2855727970600128
Validation loss: 2.047438388069471

Epoch: 5| Step: 8
Training loss: 0.2794193625450134
Validation loss: 2.0624891221523285

Epoch: 5| Step: 9
Training loss: 0.5653969049453735
Validation loss: 2.0479324062665305

Epoch: 5| Step: 10
Training loss: 0.24560847878456116
Validation loss: 2.0611341694990792

Epoch: 5| Step: 11
Training loss: 0.2086842656135559
Validation loss: 2.0484927147626877

Epoch: 398| Step: 0
Training loss: 0.3478681743144989
Validation loss: 2.060915152231852

Epoch: 5| Step: 1
Training loss: 0.2614983320236206
Validation loss: 2.0939846485853195

Epoch: 5| Step: 2
Training loss: 0.26487958431243896
Validation loss: 2.08930870393912

Epoch: 5| Step: 3
Training loss: 0.35915452241897583
Validation loss: 2.060577223698298

Epoch: 5| Step: 4
Training loss: 0.6395150423049927
Validation loss: 2.06258354584376

Epoch: 5| Step: 5
Training loss: 0.25949105620384216
Validation loss: 2.0351096938053765

Epoch: 5| Step: 6
Training loss: 0.35614487528800964
Validation loss: 2.0315173963705697

Epoch: 5| Step: 7
Training loss: 0.2717021703720093
Validation loss: 2.0332121004660926

Epoch: 5| Step: 8
Training loss: 0.2284884750843048
Validation loss: 2.0590531677007675

Epoch: 5| Step: 9
Training loss: 0.20577850937843323
Validation loss: 2.0380168110132217

Epoch: 5| Step: 10
Training loss: 0.2106267511844635
Validation loss: 2.0620867013931274

Epoch: 5| Step: 11
Training loss: 0.27613377571105957
Validation loss: 1.9948915640513103

Epoch: 399| Step: 0
Training loss: 0.24976582825183868
Validation loss: 2.0115606834491095

Epoch: 5| Step: 1
Training loss: 0.4948189854621887
Validation loss: 2.095363954703013

Epoch: 5| Step: 2
Training loss: 0.32788464426994324
Validation loss: 2.0210214803616204

Epoch: 5| Step: 3
Training loss: 0.27024680376052856
Validation loss: 1.998138005534808

Epoch: 5| Step: 4
Training loss: 0.20257103443145752
Validation loss: 2.0509473929802575

Epoch: 5| Step: 5
Training loss: 0.22774717211723328
Validation loss: 2.0359221597512565

Epoch: 5| Step: 6
Training loss: 0.20841118693351746
Validation loss: 2.047860875725746

Epoch: 5| Step: 7
Training loss: 0.2883337140083313
Validation loss: 2.0128850688536963

Epoch: 5| Step: 8
Training loss: 0.39275047183036804
Validation loss: 2.0375852237145105

Epoch: 5| Step: 9
Training loss: 0.22604529559612274
Validation loss: 2.016298105319341

Epoch: 5| Step: 10
Training loss: 0.34578609466552734
Validation loss: 2.055805121858915

Epoch: 5| Step: 11
Training loss: 0.8547753691673279
Validation loss: 2.0559140344460807

Epoch: 400| Step: 0
Training loss: 0.16960415244102478
Validation loss: 2.025859907269478

Epoch: 5| Step: 1
Training loss: 0.19615110754966736
Validation loss: 2.0702759673198066

Epoch: 5| Step: 2
Training loss: 0.18299530446529388
Validation loss: 2.0155862669150033

Epoch: 5| Step: 3
Training loss: 0.21540193259716034
Validation loss: 2.0598951627810798

Epoch: 5| Step: 4
Training loss: 0.2474328577518463
Validation loss: 2.058367689450582

Epoch: 5| Step: 5
Training loss: 0.29114967584609985
Validation loss: 2.0504838128884635

Epoch: 5| Step: 6
Training loss: 0.3264380395412445
Validation loss: 2.0260877261559167

Epoch: 5| Step: 7
Training loss: 0.2594706416130066
Validation loss: 2.019152676065763

Epoch: 5| Step: 8
Training loss: 0.27738314867019653
Validation loss: 2.018586814403534

Epoch: 5| Step: 9
Training loss: 0.5655953288078308
Validation loss: 2.0726460615793862

Epoch: 5| Step: 10
Training loss: 0.4548026919364929
Validation loss: 2.055252576867739

Epoch: 5| Step: 11
Training loss: 0.19682776927947998
Validation loss: 2.0170991172393165

Epoch: 401| Step: 0
Training loss: 0.18825837969779968
Validation loss: 2.0768274664878845

Epoch: 5| Step: 1
Training loss: 0.17514967918395996
Validation loss: 2.0638283789157867

Epoch: 5| Step: 2
Training loss: 0.29098233580589294
Validation loss: 2.05085951089859

Epoch: 5| Step: 3
Training loss: 0.40080395340919495
Validation loss: 2.0878331859906516

Epoch: 5| Step: 4
Training loss: 0.17045050859451294
Validation loss: 2.088636875152588

Epoch: 5| Step: 5
Training loss: 0.36201053857803345
Validation loss: 2.0652304689089456

Epoch: 5| Step: 6
Training loss: 0.22516486048698425
Validation loss: 1.9988812357187271

Epoch: 5| Step: 7
Training loss: 0.5400656461715698
Validation loss: 2.071053311228752

Epoch: 5| Step: 8
Training loss: 0.2267533242702484
Validation loss: 2.080500895778338

Epoch: 5| Step: 9
Training loss: 0.4079098701477051
Validation loss: 2.0434874445199966

Epoch: 5| Step: 10
Training loss: 0.2822669446468353
Validation loss: 2.0519801129897437

Epoch: 5| Step: 11
Training loss: 0.2011629045009613
Validation loss: 2.0630351404349008

Epoch: 402| Step: 0
Training loss: 0.19231966137886047
Validation loss: 2.046107371648153

Epoch: 5| Step: 1
Training loss: 0.2982878088951111
Validation loss: 2.083173776666323

Epoch: 5| Step: 2
Training loss: 0.4139438569545746
Validation loss: 2.0521829575300217

Epoch: 5| Step: 3
Training loss: 0.4094749093055725
Validation loss: 2.07783779501915

Epoch: 5| Step: 4
Training loss: 0.31996673345565796
Validation loss: 2.041770711541176

Epoch: 5| Step: 5
Training loss: 0.26817622780799866
Validation loss: 2.0583380510409675

Epoch: 5| Step: 6
Training loss: 0.18173840641975403
Validation loss: 2.0347892493009567

Epoch: 5| Step: 7
Training loss: 0.21998214721679688
Validation loss: 2.045787344376246

Epoch: 5| Step: 8
Training loss: 0.22648367285728455
Validation loss: 2.0831156969070435

Epoch: 5| Step: 9
Training loss: 0.5779021382331848
Validation loss: 2.04476036131382

Epoch: 5| Step: 10
Training loss: 0.26494985818862915
Validation loss: 2.0577077865600586

Epoch: 5| Step: 11
Training loss: 0.2073161005973816
Validation loss: 2.090043584505717

Epoch: 403| Step: 0
Training loss: 0.2752703130245209
Validation loss: 2.0352340191602707

Epoch: 5| Step: 1
Training loss: 0.2945891320705414
Validation loss: 2.0858179231484733

Epoch: 5| Step: 2
Training loss: 0.1909867823123932
Validation loss: 2.067340393861135

Epoch: 5| Step: 3
Training loss: 0.19271528720855713
Validation loss: 2.1246398786703744

Epoch: 5| Step: 4
Training loss: 0.29244229197502136
Validation loss: 2.0675426026185355

Epoch: 5| Step: 5
Training loss: 0.19305509328842163
Validation loss: 2.0350096772114434

Epoch: 5| Step: 6
Training loss: 0.2526341378688812
Validation loss: 2.035424510637919

Epoch: 5| Step: 7
Training loss: 0.3183884024620056
Validation loss: 2.024610181649526

Epoch: 5| Step: 8
Training loss: 0.751015305519104
Validation loss: 2.046036884188652

Epoch: 5| Step: 9
Training loss: 0.23914623260498047
Validation loss: 2.052732467651367

Epoch: 5| Step: 10
Training loss: 0.37395909428596497
Validation loss: 2.0422467986742654

Epoch: 5| Step: 11
Training loss: 0.32190263271331787
Validation loss: 2.105550467967987

Epoch: 404| Step: 0
Training loss: 0.34614670276641846
Validation loss: 2.0761825939019523

Epoch: 5| Step: 1
Training loss: 0.5900516510009766
Validation loss: 2.055981015165647

Epoch: 5| Step: 2
Training loss: 0.3145807087421417
Validation loss: 2.112470582127571

Epoch: 5| Step: 3
Training loss: 0.27796345949172974
Validation loss: 2.0127663960059485

Epoch: 5| Step: 4
Training loss: 0.1681332141160965
Validation loss: 2.07346577445666

Epoch: 5| Step: 5
Training loss: 0.34080371260643005
Validation loss: 2.0361449917157493

Epoch: 5| Step: 6
Training loss: 0.31115394830703735
Validation loss: 2.06642014781634

Epoch: 5| Step: 7
Training loss: 0.5984670519828796
Validation loss: 2.033738980690638

Epoch: 5| Step: 8
Training loss: 0.2603286802768707
Validation loss: 2.0624001920223236

Epoch: 5| Step: 9
Training loss: 0.5046601891517639
Validation loss: 2.028019612034162

Epoch: 5| Step: 10
Training loss: 0.2481742799282074
Validation loss: 2.0498449554045997

Epoch: 5| Step: 11
Training loss: 0.4025120139122009
Validation loss: 2.1286398569742837

Epoch: 405| Step: 0
Training loss: 0.30010339617729187
Validation loss: 2.0786491135756173

Epoch: 5| Step: 1
Training loss: 0.18157382309436798
Validation loss: 2.0672092686096826

Epoch: 5| Step: 2
Training loss: 0.31663960218429565
Validation loss: 2.0699842969576516

Epoch: 5| Step: 3
Training loss: 0.3046923875808716
Validation loss: 2.0717609226703644

Epoch: 5| Step: 4
Training loss: 0.3320741653442383
Validation loss: 2.055250217517217

Epoch: 5| Step: 5
Training loss: 0.21847841143608093
Validation loss: 2.0480356961488724

Epoch: 5| Step: 6
Training loss: 0.1324567198753357
Validation loss: 2.0098590503136315

Epoch: 5| Step: 7
Training loss: 0.20364944636821747
Validation loss: 2.077324246366819

Epoch: 5| Step: 8
Training loss: 0.13890928030014038
Validation loss: 2.0316251317660012

Epoch: 5| Step: 9
Training loss: 0.28299978375434875
Validation loss: 2.0579781780640283

Epoch: 5| Step: 10
Training loss: 0.6648330688476562
Validation loss: 2.034749080737432

Epoch: 5| Step: 11
Training loss: 0.14275938272476196
Validation loss: 2.0461408297220864

Epoch: 406| Step: 0
Training loss: 0.17003507912158966
Validation loss: 2.0591032902399697

Epoch: 5| Step: 1
Training loss: 0.2573915123939514
Validation loss: 2.0802582701047263

Epoch: 5| Step: 2
Training loss: 0.5879546999931335
Validation loss: 2.0606549878915152

Epoch: 5| Step: 3
Training loss: 0.17541523277759552
Validation loss: 2.0790058821439743

Epoch: 5| Step: 4
Training loss: 0.26629891991615295
Validation loss: 2.0719531575838723

Epoch: 5| Step: 5
Training loss: 0.31727975606918335
Validation loss: 2.0354567021131516

Epoch: 5| Step: 6
Training loss: 0.25966939330101013
Validation loss: 2.0356826335191727

Epoch: 5| Step: 7
Training loss: 0.3028414249420166
Validation loss: 2.048223922650019

Epoch: 5| Step: 8
Training loss: 0.345763236284256
Validation loss: 2.0659725119670234

Epoch: 5| Step: 9
Training loss: 0.22718293964862823
Validation loss: 2.085732157031695

Epoch: 5| Step: 10
Training loss: 0.32428720593452454
Validation loss: 2.077766234676043

Epoch: 5| Step: 11
Training loss: 0.07124757766723633
Validation loss: 2.0714793304602304

Epoch: 407| Step: 0
Training loss: 0.3523067235946655
Validation loss: 2.0990438212951026

Epoch: 5| Step: 1
Training loss: 0.3772844672203064
Validation loss: 2.0853148996829987

Epoch: 5| Step: 2
Training loss: 0.4025249481201172
Validation loss: 2.106883446375529

Epoch: 5| Step: 3
Training loss: 0.23759999871253967
Validation loss: 2.1034303307533264

Epoch: 5| Step: 4
Training loss: 0.3407975733280182
Validation loss: 2.0625523825486503

Epoch: 5| Step: 5
Training loss: 0.25470319390296936
Validation loss: 2.0380850235621133

Epoch: 5| Step: 6
Training loss: 0.6396439671516418
Validation loss: 2.0520430455605188

Epoch: 5| Step: 7
Training loss: 0.30950361490249634
Validation loss: 2.053649733463923

Epoch: 5| Step: 8
Training loss: 0.2360132485628128
Validation loss: 2.062884454925855

Epoch: 5| Step: 9
Training loss: 0.19700683653354645
Validation loss: 2.065815190474192

Epoch: 5| Step: 10
Training loss: 0.32456523180007935
Validation loss: 2.0959483087062836

Epoch: 5| Step: 11
Training loss: 0.2885245084762573
Validation loss: 2.123283768693606

Epoch: 408| Step: 0
Training loss: 0.26941078901290894
Validation loss: 2.078275680541992

Epoch: 5| Step: 1
Training loss: 0.47686710953712463
Validation loss: 2.138813465833664

Epoch: 5| Step: 2
Training loss: 0.47309380769729614
Validation loss: 2.107755000392596

Epoch: 5| Step: 3
Training loss: 0.27431952953338623
Validation loss: 2.056152194738388

Epoch: 5| Step: 4
Training loss: 0.36836162209510803
Validation loss: 2.0709940095742545

Epoch: 5| Step: 5
Training loss: 0.3254181742668152
Validation loss: 2.0036071886618934

Epoch: 5| Step: 6
Training loss: 0.6195236444473267
Validation loss: 2.0425905336936316

Epoch: 5| Step: 7
Training loss: 0.37919527292251587
Validation loss: 2.0792652666568756

Epoch: 5| Step: 8
Training loss: 0.2223643809556961
Validation loss: 2.0669514735539756

Epoch: 5| Step: 9
Training loss: 0.3571354150772095
Validation loss: 2.03840334713459

Epoch: 5| Step: 10
Training loss: 0.19241903722286224
Validation loss: 2.071817750732104

Epoch: 5| Step: 11
Training loss: 0.059117913246154785
Validation loss: 2.056660463412603

Epoch: 409| Step: 0
Training loss: 0.4439362585544586
Validation loss: 2.07675934334596

Epoch: 5| Step: 1
Training loss: 0.2957291603088379
Validation loss: 2.0545254002014794

Epoch: 5| Step: 2
Training loss: 0.2904534339904785
Validation loss: 2.076369891564051

Epoch: 5| Step: 3
Training loss: 0.3425385653972626
Validation loss: 2.0930583824714026

Epoch: 5| Step: 4
Training loss: 0.2864683270454407
Validation loss: 2.0723436127106347

Epoch: 5| Step: 5
Training loss: 0.2753191590309143
Validation loss: 2.063201685746511

Epoch: 5| Step: 6
Training loss: 0.5639668107032776
Validation loss: 2.0357734113931656

Epoch: 5| Step: 7
Training loss: 0.36868026852607727
Validation loss: 2.0202784339586892

Epoch: 5| Step: 8
Training loss: 0.36398425698280334
Validation loss: 2.016069625814756

Epoch: 5| Step: 9
Training loss: 0.17748871445655823
Validation loss: 2.0402173896630607

Epoch: 5| Step: 10
Training loss: 0.3897593915462494
Validation loss: 2.0919282734394073

Epoch: 5| Step: 11
Training loss: 0.1803499162197113
Validation loss: 2.061448151866595

Epoch: 410| Step: 0
Training loss: 0.4415087103843689
Validation loss: 2.0679040451844535

Epoch: 5| Step: 1
Training loss: 0.362907350063324
Validation loss: 2.126153180996577

Epoch: 5| Step: 2
Training loss: 0.26042813062667847
Validation loss: 2.0770909835894904

Epoch: 5| Step: 3
Training loss: 0.35371100902557373
Validation loss: 2.0461052656173706

Epoch: 5| Step: 4
Training loss: 0.24944472312927246
Validation loss: 2.062631939848264

Epoch: 5| Step: 5
Training loss: 0.17272765934467316
Validation loss: 2.1061202635367713

Epoch: 5| Step: 6
Training loss: 0.6954039931297302
Validation loss: 2.0706388652324677

Epoch: 5| Step: 7
Training loss: 0.38562148809432983
Validation loss: 2.0245411147673926

Epoch: 5| Step: 8
Training loss: 0.23743438720703125
Validation loss: 2.0584839234749475

Epoch: 5| Step: 9
Training loss: 0.24224944412708282
Validation loss: 2.0655222733815513

Epoch: 5| Step: 10
Training loss: 0.28490954637527466
Validation loss: 2.0785608887672424

Epoch: 5| Step: 11
Training loss: 0.07255810499191284
Validation loss: 2.0608358681201935

Epoch: 411| Step: 0
Training loss: 0.22900287806987762
Validation loss: 2.037342314918836

Epoch: 5| Step: 1
Training loss: 0.3555986285209656
Validation loss: 2.034622256954511

Epoch: 5| Step: 2
Training loss: 0.24185223877429962
Validation loss: 2.080735137065252

Epoch: 5| Step: 3
Training loss: 0.1756359189748764
Validation loss: 2.074884911378225

Epoch: 5| Step: 4
Training loss: 0.5054118037223816
Validation loss: 2.037971501549085

Epoch: 5| Step: 5
Training loss: 0.26304545998573303
Validation loss: 2.078769236803055

Epoch: 5| Step: 6
Training loss: 0.4746781885623932
Validation loss: 2.0438507298628488

Epoch: 5| Step: 7
Training loss: 0.22926144301891327
Validation loss: 2.0208186904589334

Epoch: 5| Step: 8
Training loss: 0.3577718734741211
Validation loss: 2.057385911544164

Epoch: 5| Step: 9
Training loss: 0.13630977272987366
Validation loss: 2.0729612012704215

Epoch: 5| Step: 10
Training loss: 0.3306026756763458
Validation loss: 2.059404124816259

Epoch: 5| Step: 11
Training loss: 0.686832070350647
Validation loss: 2.029864246646563

Epoch: 412| Step: 0
Training loss: 0.35337015986442566
Validation loss: 2.064184014995893

Epoch: 5| Step: 1
Training loss: 0.3069639801979065
Validation loss: 2.071396624048551

Epoch: 5| Step: 2
Training loss: 0.2038557529449463
Validation loss: 2.0608384360869727

Epoch: 5| Step: 3
Training loss: 0.32743358612060547
Validation loss: 2.023157383004824

Epoch: 5| Step: 4
Training loss: 0.18746939301490784
Validation loss: 2.0617460707823434

Epoch: 5| Step: 5
Training loss: 0.588927686214447
Validation loss: 2.0397273153066635

Epoch: 5| Step: 6
Training loss: 0.3972524106502533
Validation loss: 2.0307526290416718

Epoch: 5| Step: 7
Training loss: 0.34959810972213745
Validation loss: 1.9980529149373372

Epoch: 5| Step: 8
Training loss: 0.25906842947006226
Validation loss: 2.0315353075663247

Epoch: 5| Step: 9
Training loss: 0.3034846782684326
Validation loss: 2.049446870883306

Epoch: 5| Step: 10
Training loss: 0.24210278689861298
Validation loss: 2.02129735549291

Epoch: 5| Step: 11
Training loss: 0.18996691703796387
Validation loss: 2.087823430697123

Epoch: 413| Step: 0
Training loss: 0.2568434774875641
Validation loss: 2.060380498568217

Epoch: 5| Step: 1
Training loss: 0.2673605978488922
Validation loss: 2.101295327146848

Epoch: 5| Step: 2
Training loss: 0.469679594039917
Validation loss: 2.0626785506804786

Epoch: 5| Step: 3
Training loss: 0.20105242729187012
Validation loss: 2.038773943980535

Epoch: 5| Step: 4
Training loss: 0.38749200105667114
Validation loss: 2.073002884785334

Epoch: 5| Step: 5
Training loss: 0.24338555335998535
Validation loss: 2.058068037033081

Epoch: 5| Step: 6
Training loss: 0.2287285029888153
Validation loss: 2.0496517519156137

Epoch: 5| Step: 7
Training loss: 0.4888240396976471
Validation loss: 2.069107174873352

Epoch: 5| Step: 8
Training loss: 0.1847759485244751
Validation loss: 2.0847696314255395

Epoch: 5| Step: 9
Training loss: 0.17611120641231537
Validation loss: 2.084696109096209

Epoch: 5| Step: 10
Training loss: 0.23928327858448029
Validation loss: 2.0822900533676147

Epoch: 5| Step: 11
Training loss: 0.11872845888137817
Validation loss: 2.0401835590600967

Epoch: 414| Step: 0
Training loss: 0.26905950903892517
Validation loss: 2.0618038872877755

Epoch: 5| Step: 1
Training loss: 0.30018728971481323
Validation loss: 2.0179638316233954

Epoch: 5| Step: 2
Training loss: 0.729568362236023
Validation loss: 2.078759173552195

Epoch: 5| Step: 3
Training loss: 0.14971239864826202
Validation loss: 2.0343991766373315

Epoch: 5| Step: 4
Training loss: 0.1650805026292801
Validation loss: 2.0554282118876777

Epoch: 5| Step: 5
Training loss: 0.39614954590797424
Validation loss: 2.0702156821886697

Epoch: 5| Step: 6
Training loss: 0.21027317643165588
Validation loss: 2.0498939206202826

Epoch: 5| Step: 7
Training loss: 0.24309611320495605
Validation loss: 2.074190676212311

Epoch: 5| Step: 8
Training loss: 0.2326929122209549
Validation loss: 2.0548341820637384

Epoch: 5| Step: 9
Training loss: 0.3489930033683777
Validation loss: 2.0501015534003577

Epoch: 5| Step: 10
Training loss: 0.22970132529735565
Validation loss: 2.034227525194486

Epoch: 5| Step: 11
Training loss: 0.09246955811977386
Validation loss: 2.053771565357844

Epoch: 415| Step: 0
Training loss: 0.3171938359737396
Validation loss: 2.0648121933142343

Epoch: 5| Step: 1
Training loss: 0.16871827840805054
Validation loss: 2.0991618931293488

Epoch: 5| Step: 2
Training loss: 0.2935835123062134
Validation loss: 2.04972176750501

Epoch: 5| Step: 3
Training loss: 0.3158169686794281
Validation loss: 2.045362189412117

Epoch: 5| Step: 4
Training loss: 0.35388487577438354
Validation loss: 2.0544250309467316

Epoch: 5| Step: 5
Training loss: 0.4935050904750824
Validation loss: 2.06892820696036

Epoch: 5| Step: 6
Training loss: 0.18423514068126678
Validation loss: 2.0293248345454535

Epoch: 5| Step: 7
Training loss: 0.2850527763366699
Validation loss: 2.0741405387719474

Epoch: 5| Step: 8
Training loss: 0.22792677581310272
Validation loss: 2.0735459427038827

Epoch: 5| Step: 9
Training loss: 0.3109714090824127
Validation loss: 2.080102493365606

Epoch: 5| Step: 10
Training loss: 0.26320165395736694
Validation loss: 2.050937607884407

Epoch: 5| Step: 11
Training loss: 0.1723238229751587
Validation loss: 2.083880806962649

Epoch: 416| Step: 0
Training loss: 0.2513299286365509
Validation loss: 2.085380161801974

Epoch: 5| Step: 1
Training loss: 0.2452172040939331
Validation loss: 2.038984398047129

Epoch: 5| Step: 2
Training loss: 0.18403343856334686
Validation loss: 2.0389243066310883

Epoch: 5| Step: 3
Training loss: 0.35185685753822327
Validation loss: 2.051010847091675

Epoch: 5| Step: 4
Training loss: 0.2599107623100281
Validation loss: 2.070851152141889

Epoch: 5| Step: 5
Training loss: 0.1898106038570404
Validation loss: 2.0260371963183084

Epoch: 5| Step: 6
Training loss: 0.7027930021286011
Validation loss: 2.0204208145538964

Epoch: 5| Step: 7
Training loss: 0.3110615909099579
Validation loss: 2.0313990463813147

Epoch: 5| Step: 8
Training loss: 0.24511423707008362
Validation loss: 2.054873526096344

Epoch: 5| Step: 9
Training loss: 0.5129830241203308
Validation loss: 2.077497144540151

Epoch: 5| Step: 10
Training loss: 0.226612851023674
Validation loss: 2.048775459329287

Epoch: 5| Step: 11
Training loss: 0.14457416534423828
Validation loss: 2.06163027882576

Epoch: 417| Step: 0
Training loss: 0.1876557618379593
Validation loss: 2.0370633552471795

Epoch: 5| Step: 1
Training loss: 0.6348060965538025
Validation loss: 2.0497565815846124

Epoch: 5| Step: 2
Training loss: 0.3571133315563202
Validation loss: 2.0348059038321176

Epoch: 5| Step: 3
Training loss: 0.24096505343914032
Validation loss: 2.0418377021948495

Epoch: 5| Step: 4
Training loss: 0.17613744735717773
Validation loss: 2.045757452646891

Epoch: 5| Step: 5
Training loss: 0.3156791925430298
Validation loss: 2.0653329541285834

Epoch: 5| Step: 6
Training loss: 0.3400830626487732
Validation loss: 2.0437848965326944

Epoch: 5| Step: 7
Training loss: 0.4220944941043854
Validation loss: 2.0544746120770774

Epoch: 5| Step: 8
Training loss: 0.271506130695343
Validation loss: 2.0552739948034286

Epoch: 5| Step: 9
Training loss: 0.2382895052433014
Validation loss: 2.0218730767567954

Epoch: 5| Step: 10
Training loss: 0.22303196787834167
Validation loss: 2.0388836562633514

Epoch: 5| Step: 11
Training loss: 0.13426446914672852
Validation loss: 2.012326419353485

Epoch: 418| Step: 0
Training loss: 0.5335673093795776
Validation loss: 2.066461975375811

Epoch: 5| Step: 1
Training loss: 0.2334783524274826
Validation loss: 2.0591517835855484

Epoch: 5| Step: 2
Training loss: 0.5070947408676147
Validation loss: 2.0635074327389398

Epoch: 5| Step: 3
Training loss: 0.45572376251220703
Validation loss: 2.036856532096863

Epoch: 5| Step: 4
Training loss: 0.31217870116233826
Validation loss: 2.085421696305275

Epoch: 5| Step: 5
Training loss: 0.24641120433807373
Validation loss: 2.0338701655467353

Epoch: 5| Step: 6
Training loss: 0.2756420969963074
Validation loss: 2.056749646862348

Epoch: 5| Step: 7
Training loss: 0.25674644112586975
Validation loss: 2.089944834510485

Epoch: 5| Step: 8
Training loss: 0.32761892676353455
Validation loss: 2.062545488278071

Epoch: 5| Step: 9
Training loss: 0.31034916639328003
Validation loss: 2.0854184329509735

Epoch: 5| Step: 10
Training loss: 0.1708112210035324
Validation loss: 1.9957932829856873

Epoch: 5| Step: 11
Training loss: 0.16230103373527527
Validation loss: 2.0567088524500527

Epoch: 419| Step: 0
Training loss: 0.23253655433654785
Validation loss: 2.0883214871088662

Epoch: 5| Step: 1
Training loss: 0.287997305393219
Validation loss: 2.038649226228396

Epoch: 5| Step: 2
Training loss: 0.27392831444740295
Validation loss: 2.0508055090904236

Epoch: 5| Step: 3
Training loss: 0.24807524681091309
Validation loss: 2.0415175507465997

Epoch: 5| Step: 4
Training loss: 0.224513441324234
Validation loss: 2.067175954580307

Epoch: 5| Step: 5
Training loss: 0.23723554611206055
Validation loss: 2.107138137022654

Epoch: 5| Step: 6
Training loss: 0.18826594948768616
Validation loss: 2.041587914029757

Epoch: 5| Step: 7
Training loss: 0.4150119721889496
Validation loss: 2.0205400933821998

Epoch: 5| Step: 8
Training loss: 0.18341168761253357
Validation loss: 2.085734119017919

Epoch: 5| Step: 9
Training loss: 0.5003277659416199
Validation loss: 2.071268007159233

Epoch: 5| Step: 10
Training loss: 0.34867846965789795
Validation loss: 2.057408188780149

Epoch: 5| Step: 11
Training loss: 0.30440008640289307
Validation loss: 2.0735873778661094

Epoch: 420| Step: 0
Training loss: 0.33929821848869324
Validation loss: 2.0034409960110984

Epoch: 5| Step: 1
Training loss: 0.22200849652290344
Validation loss: 2.0058323542277017

Epoch: 5| Step: 2
Training loss: 0.3325645923614502
Validation loss: 2.021035427848498

Epoch: 5| Step: 3
Training loss: 0.2205154448747635
Validation loss: 2.0545825262864432

Epoch: 5| Step: 4
Training loss: 0.19610485434532166
Validation loss: 2.0003326634565988

Epoch: 5| Step: 5
Training loss: 0.2903769314289093
Validation loss: 2.032170613606771

Epoch: 5| Step: 6
Training loss: 0.19843153655529022
Validation loss: 2.0683920880158744

Epoch: 5| Step: 7
Training loss: 0.46269455552101135
Validation loss: 2.0434727172056832

Epoch: 5| Step: 8
Training loss: 0.1788720041513443
Validation loss: 2.0874252319335938

Epoch: 5| Step: 9
Training loss: 0.27321529388427734
Validation loss: 2.0525836845239005

Epoch: 5| Step: 10
Training loss: 0.23353926837444305
Validation loss: 2.0525490641593933

Epoch: 5| Step: 11
Training loss: 0.15617740154266357
Validation loss: 2.054140165448189

Epoch: 421| Step: 0
Training loss: 0.19644315540790558
Validation loss: 2.0571228563785553

Epoch: 5| Step: 1
Training loss: 0.2709016501903534
Validation loss: 2.0660060147444406

Epoch: 5| Step: 2
Training loss: 0.3386034667491913
Validation loss: 2.0902277578910193

Epoch: 5| Step: 3
Training loss: 0.20807480812072754
Validation loss: 2.079584310452143

Epoch: 5| Step: 4
Training loss: 0.22826142609119415
Validation loss: 2.0707735319932303

Epoch: 5| Step: 5
Training loss: 0.19125410914421082
Validation loss: 2.0332966297864914

Epoch: 5| Step: 6
Training loss: 0.16881345212459564
Validation loss: 2.065231208999952

Epoch: 5| Step: 7
Training loss: 0.602408230304718
Validation loss: 2.0413664976755777

Epoch: 5| Step: 8
Training loss: 0.2512768805027008
Validation loss: 2.076323459545771

Epoch: 5| Step: 9
Training loss: 0.19598306715488434
Validation loss: 2.0768799086411796

Epoch: 5| Step: 10
Training loss: 0.2987648844718933
Validation loss: 2.1049752036730447

Epoch: 5| Step: 11
Training loss: 0.14893373847007751
Validation loss: 2.0561669766902924

Epoch: 422| Step: 0
Training loss: 0.24927034974098206
Validation loss: 2.0402022252480188

Epoch: 5| Step: 1
Training loss: 0.13307973742485046
Validation loss: 2.080657030145327

Epoch: 5| Step: 2
Training loss: 0.2910321354866028
Validation loss: 2.074125642577807

Epoch: 5| Step: 3
Training loss: 0.21913361549377441
Validation loss: 2.0607662300268808

Epoch: 5| Step: 4
Training loss: 0.6517478227615356
Validation loss: 2.0481749027967453

Epoch: 5| Step: 5
Training loss: 0.5571615099906921
Validation loss: 2.0636497884988785

Epoch: 5| Step: 6
Training loss: 0.23351511359214783
Validation loss: 2.03603687385718

Epoch: 5| Step: 7
Training loss: 0.26741862297058105
Validation loss: 2.024355803926786

Epoch: 5| Step: 8
Training loss: 0.1886286437511444
Validation loss: 2.0553703904151917

Epoch: 5| Step: 9
Training loss: 0.2548552453517914
Validation loss: 2.0478522032499313

Epoch: 5| Step: 10
Training loss: 0.23473505675792694
Validation loss: 2.023267870148023

Epoch: 5| Step: 11
Training loss: 0.2579706311225891
Validation loss: 2.0370981792608895

Epoch: 423| Step: 0
Training loss: 0.5138995051383972
Validation loss: 2.032497306664785

Epoch: 5| Step: 1
Training loss: 0.19951516389846802
Validation loss: 2.025608390569687

Epoch: 5| Step: 2
Training loss: 0.29985132813453674
Validation loss: 2.016010602315267

Epoch: 5| Step: 3
Training loss: 0.16225682199001312
Validation loss: 2.0108622858921685

Epoch: 5| Step: 4
Training loss: 0.21565988659858704
Validation loss: 2.0764074275890985

Epoch: 5| Step: 5
Training loss: 0.47259169816970825
Validation loss: 2.0696608821551004

Epoch: 5| Step: 6
Training loss: 0.2647547423839569
Validation loss: 2.0622317492961884

Epoch: 5| Step: 7
Training loss: 0.22925111651420593
Validation loss: 2.0456833640734353

Epoch: 5| Step: 8
Training loss: 0.2677299976348877
Validation loss: 2.059357355038325

Epoch: 5| Step: 9
Training loss: 0.20721404254436493
Validation loss: 2.0592401226361594

Epoch: 5| Step: 10
Training loss: 0.2526318430900574
Validation loss: 2.0399661660194397

Epoch: 5| Step: 11
Training loss: 0.2563944458961487
Validation loss: 2.011872465411822

Epoch: 424| Step: 0
Training loss: 0.2945174276828766
Validation loss: 2.0540354748566947

Epoch: 5| Step: 1
Training loss: 0.18456120789051056
Validation loss: 2.0303659041722617

Epoch: 5| Step: 2
Training loss: 0.2852160632610321
Validation loss: 2.0799753914276757

Epoch: 5| Step: 3
Training loss: 0.20610646903514862
Validation loss: 2.0378384987513223

Epoch: 5| Step: 4
Training loss: 0.23001953959465027
Validation loss: 2.0757466554641724

Epoch: 5| Step: 5
Training loss: 0.1710258424282074
Validation loss: 2.057840218146642

Epoch: 5| Step: 6
Training loss: 0.22503891587257385
Validation loss: 2.0645158340533576

Epoch: 5| Step: 7
Training loss: 0.16844116151332855
Validation loss: 2.02685476342837

Epoch: 5| Step: 8
Training loss: 0.25370901823043823
Validation loss: 2.0533114820718765

Epoch: 5| Step: 9
Training loss: 0.731009840965271
Validation loss: 2.0438797722260156

Epoch: 5| Step: 10
Training loss: 0.2954198718070984
Validation loss: 2.026799887418747

Epoch: 5| Step: 11
Training loss: 0.7961181998252869
Validation loss: 2.0578728516896567

Epoch: 425| Step: 0
Training loss: 0.16912654042243958
Validation loss: 2.046113908290863

Epoch: 5| Step: 1
Training loss: 0.16107967495918274
Validation loss: 2.0946501344442368

Epoch: 5| Step: 2
Training loss: 0.5924068093299866
Validation loss: 2.0609350949525833

Epoch: 5| Step: 3
Training loss: 0.21855130791664124
Validation loss: 2.017470141251882

Epoch: 5| Step: 4
Training loss: 0.39297226071357727
Validation loss: 2.081262638171514

Epoch: 5| Step: 5
Training loss: 0.2436353862285614
Validation loss: 2.0528971751530967

Epoch: 5| Step: 6
Training loss: 0.17046213150024414
Validation loss: 2.101023385922114

Epoch: 5| Step: 7
Training loss: 0.31674161553382874
Validation loss: 2.0625653117895126

Epoch: 5| Step: 8
Training loss: 0.23950371146202087
Validation loss: 2.0647226125001907

Epoch: 5| Step: 9
Training loss: 0.2999979853630066
Validation loss: 2.0631388624509177

Epoch: 5| Step: 10
Training loss: 0.23325204849243164
Validation loss: 2.046339919169744

Epoch: 5| Step: 11
Training loss: 0.22965866327285767
Validation loss: 2.0418596267700195

Epoch: 426| Step: 0
Training loss: 0.2631164491176605
Validation loss: 2.0364141861597695

Epoch: 5| Step: 1
Training loss: 0.18100222945213318
Validation loss: 2.065434788664182

Epoch: 5| Step: 2
Training loss: 0.31184065341949463
Validation loss: 2.0501569161812463

Epoch: 5| Step: 3
Training loss: 0.22241362929344177
Validation loss: 2.0557669599850974

Epoch: 5| Step: 4
Training loss: 0.36257821321487427
Validation loss: 2.0278643568356833

Epoch: 5| Step: 5
Training loss: 0.3240669369697571
Validation loss: 2.012133543690046

Epoch: 5| Step: 6
Training loss: 0.12543539702892303
Validation loss: 2.058080976208051

Epoch: 5| Step: 7
Training loss: 0.2526833117008209
Validation loss: 2.0577115764220557

Epoch: 5| Step: 8
Training loss: 0.6726704835891724
Validation loss: 2.0558950901031494

Epoch: 5| Step: 9
Training loss: 0.37365299463272095
Validation loss: 2.107145756483078

Epoch: 5| Step: 10
Training loss: 0.23219850659370422
Validation loss: 2.0760598182678223

Epoch: 5| Step: 11
Training loss: 0.36136364936828613
Validation loss: 2.0378639499346414

Epoch: 427| Step: 0
Training loss: 0.5125566124916077
Validation loss: 2.0232771734396615

Epoch: 5| Step: 1
Training loss: 0.5047028660774231
Validation loss: 2.062600905696551

Epoch: 5| Step: 2
Training loss: 0.24569158256053925
Validation loss: 2.0730811605850854

Epoch: 5| Step: 3
Training loss: 0.38712888956069946
Validation loss: 2.05749241511027

Epoch: 5| Step: 4
Training loss: 0.23488947749137878
Validation loss: 2.017272566755613

Epoch: 5| Step: 5
Training loss: 0.17845192551612854
Validation loss: 2.018478900194168

Epoch: 5| Step: 6
Training loss: 0.3584529757499695
Validation loss: 2.0946684082349143

Epoch: 5| Step: 7
Training loss: 0.22101381421089172
Validation loss: 2.061822240551313

Epoch: 5| Step: 8
Training loss: 0.2316710203886032
Validation loss: 2.0607986450195312

Epoch: 5| Step: 9
Training loss: 0.23979035019874573
Validation loss: 2.0745552281538644

Epoch: 5| Step: 10
Training loss: 0.21587684750556946
Validation loss: 2.0888981272776923

Epoch: 5| Step: 11
Training loss: 0.16814637184143066
Validation loss: 2.037965511282285

Epoch: 428| Step: 0
Training loss: 0.2663924992084503
Validation loss: 2.1077676117420197

Epoch: 5| Step: 1
Training loss: 0.21140789985656738
Validation loss: 2.0305032432079315

Epoch: 5| Step: 2
Training loss: 0.5054415464401245
Validation loss: 2.041674961646398

Epoch: 5| Step: 3
Training loss: 0.4360697269439697
Validation loss: 1.9983809739351273

Epoch: 5| Step: 4
Training loss: 0.19130493700504303
Validation loss: 2.045490115880966

Epoch: 5| Step: 5
Training loss: 0.19584998488426208
Validation loss: 2.015279899040858

Epoch: 5| Step: 6
Training loss: 0.1654006540775299
Validation loss: 2.0621987134218216

Epoch: 5| Step: 7
Training loss: 0.3270993232727051
Validation loss: 2.026312733689944

Epoch: 5| Step: 8
Training loss: 0.22981567680835724
Validation loss: 2.0377005537350974

Epoch: 5| Step: 9
Training loss: 0.17751604318618774
Validation loss: 2.019752378265063

Epoch: 5| Step: 10
Training loss: 0.163816899061203
Validation loss: 2.07098126411438

Epoch: 5| Step: 11
Training loss: 0.1621401309967041
Validation loss: 2.0704509367545447

Epoch: 429| Step: 0
Training loss: 0.23213717341423035
Validation loss: 2.0321525434652963

Epoch: 5| Step: 1
Training loss: 0.554187536239624
Validation loss: 2.0024980853001275

Epoch: 5| Step: 2
Training loss: 0.2107989341020584
Validation loss: 2.031863177816073

Epoch: 5| Step: 3
Training loss: 0.22846193611621857
Validation loss: 1.986014852921168

Epoch: 5| Step: 4
Training loss: 0.2949734330177307
Validation loss: 2.036257430911064

Epoch: 5| Step: 5
Training loss: 0.2625235617160797
Validation loss: 2.0427260051170983

Epoch: 5| Step: 6
Training loss: 0.26705265045166016
Validation loss: 2.017144108812014

Epoch: 5| Step: 7
Training loss: 0.24746355414390564
Validation loss: 2.059039294719696

Epoch: 5| Step: 8
Training loss: 0.2808644771575928
Validation loss: 2.057367747028669

Epoch: 5| Step: 9
Training loss: 0.5717276334762573
Validation loss: 2.0397713432709375

Epoch: 5| Step: 10
Training loss: 0.21531233191490173
Validation loss: 2.0632827132940292

Epoch: 5| Step: 11
Training loss: 0.23842793703079224
Validation loss: 2.0178927977879844

Epoch: 430| Step: 0
Training loss: 0.3387400507926941
Validation loss: 2.030726278821627

Epoch: 5| Step: 1
Training loss: 0.20370714366436005
Validation loss: 2.0221097419659295

Epoch: 5| Step: 2
Training loss: 0.21839039027690887
Validation loss: 2.028176948428154

Epoch: 5| Step: 3
Training loss: 0.19598448276519775
Validation loss: 2.077210714419683

Epoch: 5| Step: 4
Training loss: 0.48312196135520935
Validation loss: 2.0648769438266754

Epoch: 5| Step: 5
Training loss: 0.19099470973014832
Validation loss: 2.0133106658856073

Epoch: 5| Step: 6
Training loss: 0.2575799822807312
Validation loss: 2.0482024649779

Epoch: 5| Step: 7
Training loss: 0.48612818121910095
Validation loss: 2.0090745786825814

Epoch: 5| Step: 8
Training loss: 0.14722813665866852
Validation loss: 2.0364895115296044

Epoch: 5| Step: 9
Training loss: 0.2196209877729416
Validation loss: 2.072922190030416

Epoch: 5| Step: 10
Training loss: 0.21838264167308807
Validation loss: 2.016189754009247

Epoch: 5| Step: 11
Training loss: 0.17466241121292114
Validation loss: 2.0001809348662696

Epoch: 431| Step: 0
Training loss: 0.18389269709587097
Validation loss: 2.0209111869335175

Epoch: 5| Step: 1
Training loss: 0.31417316198349
Validation loss: 1.9996337443590164

Epoch: 5| Step: 2
Training loss: 0.19165419042110443
Validation loss: 2.039506549636523

Epoch: 5| Step: 3
Training loss: 0.5803704261779785
Validation loss: 2.031689981619517

Epoch: 5| Step: 4
Training loss: 0.3510066568851471
Validation loss: 2.04946660498778

Epoch: 5| Step: 5
Training loss: 0.21034586429595947
Validation loss: 2.0389405687650046

Epoch: 5| Step: 6
Training loss: 0.4206518232822418
Validation loss: 2.0184839318195977

Epoch: 5| Step: 7
Training loss: 0.2874201834201813
Validation loss: 2.0446055779854455

Epoch: 5| Step: 8
Training loss: 0.22014160454273224
Validation loss: 2.02227546274662

Epoch: 5| Step: 9
Training loss: 0.19697073101997375
Validation loss: 2.0259129802385965

Epoch: 5| Step: 10
Training loss: 0.20192837715148926
Validation loss: 2.034262095888456

Epoch: 5| Step: 11
Training loss: 0.2388206422328949
Validation loss: 2.0416287730137506

Epoch: 432| Step: 0
Training loss: 0.3101925253868103
Validation loss: 2.001376430193583

Epoch: 5| Step: 1
Training loss: 0.43803873658180237
Validation loss: 2.0353939483563104

Epoch: 5| Step: 2
Training loss: 0.4508852958679199
Validation loss: 2.0481399496396384

Epoch: 5| Step: 3
Training loss: 0.3019263744354248
Validation loss: 2.0184801667928696

Epoch: 5| Step: 4
Training loss: 0.25042101740837097
Validation loss: 2.0483414381742477

Epoch: 5| Step: 5
Training loss: 0.2503111958503723
Validation loss: 2.0647886991500854

Epoch: 5| Step: 6
Training loss: 0.2751839756965637
Validation loss: 2.0610605974992118

Epoch: 5| Step: 7
Training loss: 0.16353555023670197
Validation loss: 2.0460226436456046

Epoch: 5| Step: 8
Training loss: 0.1766168177127838
Validation loss: 2.018294577797254

Epoch: 5| Step: 9
Training loss: 0.276338130235672
Validation loss: 2.017868479092916

Epoch: 5| Step: 10
Training loss: 0.19679301977157593
Validation loss: 2.031338115533193

Epoch: 5| Step: 11
Training loss: 0.1784219741821289
Validation loss: 2.0559613406658173

Epoch: 433| Step: 0
Training loss: 0.3182050883769989
Validation loss: 2.0429129799207053

Epoch: 5| Step: 1
Training loss: 0.21211811900138855
Validation loss: 2.026713788509369

Epoch: 5| Step: 2
Training loss: 0.15170934796333313
Validation loss: 2.012679527203242

Epoch: 5| Step: 3
Training loss: 0.6228777170181274
Validation loss: 2.045504798491796

Epoch: 5| Step: 4
Training loss: 0.26111894845962524
Validation loss: 2.0461151003837585

Epoch: 5| Step: 5
Training loss: 0.3983786404132843
Validation loss: 2.0349171111981073

Epoch: 5| Step: 6
Training loss: 0.33795037865638733
Validation loss: 1.9962768803040187

Epoch: 5| Step: 7
Training loss: 0.2627108097076416
Validation loss: 2.0108270992835364

Epoch: 5| Step: 8
Training loss: 0.2913348078727722
Validation loss: 2.046234960357348

Epoch: 5| Step: 9
Training loss: 0.18481646478176117
Validation loss: 2.0172785967588425

Epoch: 5| Step: 10
Training loss: 0.16165556013584137
Validation loss: 2.0482581754525504

Epoch: 5| Step: 11
Training loss: 0.9438863396644592
Validation loss: 2.0791200945774713

Epoch: 434| Step: 0
Training loss: 0.36293262243270874
Validation loss: 2.0293933053811393

Epoch: 5| Step: 1
Training loss: 0.2729831337928772
Validation loss: 2.012139638264974

Epoch: 5| Step: 2
Training loss: 0.23507976531982422
Validation loss: 2.045769527554512

Epoch: 5| Step: 3
Training loss: 0.24148765206336975
Validation loss: 2.0616843551397324

Epoch: 5| Step: 4
Training loss: 0.3066933751106262
Validation loss: 2.0661855985720954

Epoch: 5| Step: 5
Training loss: 0.21164235472679138
Validation loss: 2.0243663589159646

Epoch: 5| Step: 6
Training loss: 0.2680032253265381
Validation loss: 2.0505003233750663

Epoch: 5| Step: 7
Training loss: 0.4786303639411926
Validation loss: 2.046100621422132

Epoch: 5| Step: 8
Training loss: 0.14453008770942688
Validation loss: 2.0437261164188385

Epoch: 5| Step: 9
Training loss: 0.2937633991241455
Validation loss: 2.0334579795598984

Epoch: 5| Step: 10
Training loss: 0.27073290944099426
Validation loss: 2.0519529481728873

Epoch: 5| Step: 11
Training loss: 0.1808105707168579
Validation loss: 2.0886084338029227

Epoch: 435| Step: 0
Training loss: 0.28986936807632446
Validation loss: 2.0601525704065957

Epoch: 5| Step: 1
Training loss: 0.18451693654060364
Validation loss: 2.0636406987905502

Epoch: 5| Step: 2
Training loss: 0.37912294268608093
Validation loss: 2.0436097234487534

Epoch: 5| Step: 3
Training loss: 0.23746034502983093
Validation loss: 2.072715386748314

Epoch: 5| Step: 4
Training loss: 0.5759601593017578
Validation loss: 2.005554288625717

Epoch: 5| Step: 5
Training loss: 0.4646109640598297
Validation loss: 2.09868715206782

Epoch: 5| Step: 6
Training loss: 0.24719420075416565
Validation loss: 2.060487444202105

Epoch: 5| Step: 7
Training loss: 0.2280118763446808
Validation loss: 2.0503406822681427

Epoch: 5| Step: 8
Training loss: 0.2881268262863159
Validation loss: 2.015797739227613

Epoch: 5| Step: 9
Training loss: 0.25703710317611694
Validation loss: 2.066736047466596

Epoch: 5| Step: 10
Training loss: 0.17054684460163116
Validation loss: 2.034581780433655

Epoch: 5| Step: 11
Training loss: 0.40744900703430176
Validation loss: 2.0377024710178375

Epoch: 436| Step: 0
Training loss: 0.2295217216014862
Validation loss: 2.05326380332311

Epoch: 5| Step: 1
Training loss: 0.21737349033355713
Validation loss: 2.0301186392704644

Epoch: 5| Step: 2
Training loss: 0.1941773146390915
Validation loss: 2.0777787963549295

Epoch: 5| Step: 3
Training loss: 0.5503872632980347
Validation loss: 2.068689445654551

Epoch: 5| Step: 4
Training loss: 0.34581151604652405
Validation loss: 2.03850120306015

Epoch: 5| Step: 5
Training loss: 0.2702261805534363
Validation loss: 2.0551459143559136

Epoch: 5| Step: 6
Training loss: 0.33936628699302673
Validation loss: 2.057490532596906

Epoch: 5| Step: 7
Training loss: 0.17280313372612
Validation loss: 2.0368210126956305

Epoch: 5| Step: 8
Training loss: 0.280833899974823
Validation loss: 2.061422978838285

Epoch: 5| Step: 9
Training loss: 0.2558639645576477
Validation loss: 2.056755244731903

Epoch: 5| Step: 10
Training loss: 0.18740157783031464
Validation loss: 2.0414709796508155

Epoch: 5| Step: 11
Training loss: 0.18841883540153503
Validation loss: 2.0589713156223297

Epoch: 437| Step: 0
Training loss: 0.2081877440214157
Validation loss: 2.065355891982714

Epoch: 5| Step: 1
Training loss: 0.3542209267616272
Validation loss: 2.02207904557387

Epoch: 5| Step: 2
Training loss: 0.25343456864356995
Validation loss: 2.067024886608124

Epoch: 5| Step: 3
Training loss: 0.4445249140262604
Validation loss: 2.0418150325616202

Epoch: 5| Step: 4
Training loss: 0.23584012687206268
Validation loss: 2.067696968714396

Epoch: 5| Step: 5
Training loss: 0.17309102416038513
Validation loss: 1.9958633333444595

Epoch: 5| Step: 6
Training loss: 0.24691495299339294
Validation loss: 2.0335281739632287

Epoch: 5| Step: 7
Training loss: 0.4688393175601959
Validation loss: 2.063796321551005

Epoch: 5| Step: 8
Training loss: 0.22844061255455017
Validation loss: 2.031002312898636

Epoch: 5| Step: 9
Training loss: 0.2067914754152298
Validation loss: 2.0140669643878937

Epoch: 5| Step: 10
Training loss: 0.3160794675350189
Validation loss: 2.0413132160902023

Epoch: 5| Step: 11
Training loss: 0.5368629097938538
Validation loss: 2.016332055131594

Epoch: 438| Step: 0
Training loss: 0.15278294682502747
Validation loss: 2.0208979497353234

Epoch: 5| Step: 1
Training loss: 0.23311534523963928
Validation loss: 2.0648039281368256

Epoch: 5| Step: 2
Training loss: 0.4195345938205719
Validation loss: 2.0212509085734687

Epoch: 5| Step: 3
Training loss: 0.21342642605304718
Validation loss: 2.021551022926966

Epoch: 5| Step: 4
Training loss: 0.450136661529541
Validation loss: 2.0231837034225464

Epoch: 5| Step: 5
Training loss: 0.21944423019886017
Validation loss: 2.0193757911523185

Epoch: 5| Step: 6
Training loss: 0.15650518238544464
Validation loss: 2.025861233472824

Epoch: 5| Step: 7
Training loss: 0.34664297103881836
Validation loss: 1.9990530560413997

Epoch: 5| Step: 8
Training loss: 0.2242722064256668
Validation loss: 2.049083650112152

Epoch: 5| Step: 9
Training loss: 0.19446395337581635
Validation loss: 2.0243373115857444

Epoch: 5| Step: 10
Training loss: 0.2785237431526184
Validation loss: 2.068974862496058

Epoch: 5| Step: 11
Training loss: 1.020804524421692
Validation loss: 2.0502943843603134

Epoch: 439| Step: 0
Training loss: 0.22000069916248322
Validation loss: 2.043816645940145

Epoch: 5| Step: 1
Training loss: 0.6105534434318542
Validation loss: 2.068852663040161

Epoch: 5| Step: 2
Training loss: 0.18054088950157166
Validation loss: 2.051119342446327

Epoch: 5| Step: 3
Training loss: 0.21954289078712463
Validation loss: 2.060737361510595

Epoch: 5| Step: 4
Training loss: 0.20117530226707458
Validation loss: 2.0154502292474112

Epoch: 5| Step: 5
Training loss: 0.36307603120803833
Validation loss: 2.0443022598822913

Epoch: 5| Step: 6
Training loss: 0.2506468892097473
Validation loss: 2.0443820357322693

Epoch: 5| Step: 7
Training loss: 0.2708450257778168
Validation loss: 2.061570088068644

Epoch: 5| Step: 8
Training loss: 0.25764864683151245
Validation loss: 2.0572504301865897

Epoch: 5| Step: 9
Training loss: 0.37286967039108276
Validation loss: 2.061013162136078

Epoch: 5| Step: 10
Training loss: 0.23730358481407166
Validation loss: 2.070888012647629

Epoch: 5| Step: 11
Training loss: 0.20261678099632263
Validation loss: 2.0929192503293357

Epoch: 440| Step: 0
Training loss: 0.48062068223953247
Validation loss: 2.0611135959625244

Epoch: 5| Step: 1
Training loss: 0.27038222551345825
Validation loss: 2.039514273405075

Epoch: 5| Step: 2
Training loss: 0.19443801045417786
Validation loss: 2.0707786778608956

Epoch: 5| Step: 3
Training loss: 0.3883814811706543
Validation loss: 2.0054916391770043

Epoch: 5| Step: 4
Training loss: 0.2521175444126129
Validation loss: 2.0565512776374817

Epoch: 5| Step: 5
Training loss: 0.5104056000709534
Validation loss: 2.0425315548976264

Epoch: 5| Step: 6
Training loss: 0.20236214995384216
Validation loss: 2.0375562657912574

Epoch: 5| Step: 7
Training loss: 0.22597023844718933
Validation loss: 2.0869739999373755

Epoch: 5| Step: 8
Training loss: 0.273948609828949
Validation loss: 2.0898671398560205

Epoch: 5| Step: 9
Training loss: 0.2784937918186188
Validation loss: 2.089507132768631

Epoch: 5| Step: 10
Training loss: 0.29895707964897156
Validation loss: 2.0709204375743866

Epoch: 5| Step: 11
Training loss: 0.18628203868865967
Validation loss: 2.0359971821308136

Epoch: 441| Step: 0
Training loss: 0.21260008215904236
Validation loss: 2.0701079865296683

Epoch: 5| Step: 1
Training loss: 0.29436808824539185
Validation loss: 2.079187805453936

Epoch: 5| Step: 2
Training loss: 0.2580999732017517
Validation loss: 2.048260579506556

Epoch: 5| Step: 3
Training loss: 0.2915413975715637
Validation loss: 2.016943633556366

Epoch: 5| Step: 4
Training loss: 0.19758310914039612
Validation loss: 2.053682799140612

Epoch: 5| Step: 5
Training loss: 0.19553278386592865
Validation loss: 2.0236170490582785

Epoch: 5| Step: 6
Training loss: 0.4087122082710266
Validation loss: 2.026924436291059

Epoch: 5| Step: 7
Training loss: 0.2657642066478729
Validation loss: 2.04212187230587

Epoch: 5| Step: 8
Training loss: 0.19722004234790802
Validation loss: 2.066005751490593

Epoch: 5| Step: 9
Training loss: 0.49149078130722046
Validation loss: 2.0778093387683234

Epoch: 5| Step: 10
Training loss: 0.24107393622398376
Validation loss: 2.0455407053232193

Epoch: 5| Step: 11
Training loss: 0.1310705542564392
Validation loss: 2.0494966159264245

Epoch: 442| Step: 0
Training loss: 0.1616864949464798
Validation loss: 2.015891661246618

Epoch: 5| Step: 1
Training loss: 0.19171348214149475
Validation loss: 2.025703693429629

Epoch: 5| Step: 2
Training loss: 0.5221538543701172
Validation loss: 2.0831629782915115

Epoch: 5| Step: 3
Training loss: 0.18264666199684143
Validation loss: 2.0275567869345346

Epoch: 5| Step: 4
Training loss: 0.27779290080070496
Validation loss: 2.020440941055616

Epoch: 5| Step: 5
Training loss: 0.2901095747947693
Validation loss: 2.0571577648321786

Epoch: 5| Step: 6
Training loss: 0.299553245306015
Validation loss: 2.0491617619991302

Epoch: 5| Step: 7
Training loss: 0.28488457202911377
Validation loss: 2.072777643799782

Epoch: 5| Step: 8
Training loss: 0.2967931628227234
Validation loss: 2.045760249098142

Epoch: 5| Step: 9
Training loss: 0.31720319390296936
Validation loss: 2.0627578794956207

Epoch: 5| Step: 10
Training loss: 0.2764289081096649
Validation loss: 2.0229283372561135

Epoch: 5| Step: 11
Training loss: 0.35765349864959717
Validation loss: 2.0544462352991104

Epoch: 443| Step: 0
Training loss: 0.3207343816757202
Validation loss: 2.0498159428437552

Epoch: 5| Step: 1
Training loss: 0.2253502905368805
Validation loss: 2.0851153333981833

Epoch: 5| Step: 2
Training loss: 0.23363323509693146
Validation loss: 2.0520083010196686

Epoch: 5| Step: 3
Training loss: 0.21102750301361084
Validation loss: 2.038845350344976

Epoch: 5| Step: 4
Training loss: 0.428122341632843
Validation loss: 2.059211661418279

Epoch: 5| Step: 5
Training loss: 0.3168613016605377
Validation loss: 2.0383457938830056

Epoch: 5| Step: 6
Training loss: 0.20062820613384247
Validation loss: 2.097556526462237

Epoch: 5| Step: 7
Training loss: 0.2024516612291336
Validation loss: 2.054280494650205

Epoch: 5| Step: 8
Training loss: 0.2414036989212036
Validation loss: 2.0325130025545755

Epoch: 5| Step: 9
Training loss: 0.46913570165634155
Validation loss: 2.066513881087303

Epoch: 5| Step: 10
Training loss: 0.20640940964221954
Validation loss: 2.050878663857778

Epoch: 5| Step: 11
Training loss: 0.28699052333831787
Validation loss: 2.0490023493766785

Epoch: 444| Step: 0
Training loss: 0.6035075187683105
Validation loss: 2.058049271504084

Epoch: 5| Step: 1
Training loss: 0.30003243684768677
Validation loss: 2.055706093708674

Epoch: 5| Step: 2
Training loss: 0.41679126024246216
Validation loss: 2.0413435449202857

Epoch: 5| Step: 3
Training loss: 0.2958095073699951
Validation loss: 2.0263671477635703

Epoch: 5| Step: 4
Training loss: 0.26275089383125305
Validation loss: 2.049469530582428

Epoch: 5| Step: 5
Training loss: 0.26517558097839355
Validation loss: 2.0126908918221793

Epoch: 5| Step: 6
Training loss: 0.3066158890724182
Validation loss: 2.01456684867541

Epoch: 5| Step: 7
Training loss: 0.31083863973617554
Validation loss: 2.0013454357783

Epoch: 5| Step: 8
Training loss: 0.19842305779457092
Validation loss: 2.0772918363412223

Epoch: 5| Step: 9
Training loss: 0.31870022416114807
Validation loss: 2.035897637406985

Epoch: 5| Step: 10
Training loss: 0.17743222415447235
Validation loss: 2.0293037792046866

Epoch: 5| Step: 11
Training loss: 0.3527415990829468
Validation loss: 2.0611422260602317

Epoch: 445| Step: 0
Training loss: 0.26134592294692993
Validation loss: 2.0629451324542365

Epoch: 5| Step: 1
Training loss: 0.4512052536010742
Validation loss: 2.058836062749227

Epoch: 5| Step: 2
Training loss: 0.18724021315574646
Validation loss: 2.062466541926066

Epoch: 5| Step: 3
Training loss: 0.2322782725095749
Validation loss: 2.1090252151091895

Epoch: 5| Step: 4
Training loss: 0.25396233797073364
Validation loss: 2.0699458767970405

Epoch: 5| Step: 5
Training loss: 0.5744487047195435
Validation loss: 2.0691178888082504

Epoch: 5| Step: 6
Training loss: 0.19582240283489227
Validation loss: 2.0754535496234894

Epoch: 5| Step: 7
Training loss: 0.22885040938854218
Validation loss: 2.0204354524612427

Epoch: 5| Step: 8
Training loss: 0.30299076437950134
Validation loss: 2.086718335747719

Epoch: 5| Step: 9
Training loss: 0.22167344391345978
Validation loss: 2.0526009450356164

Epoch: 5| Step: 10
Training loss: 0.276627779006958
Validation loss: 2.0345501750707626

Epoch: 5| Step: 11
Training loss: 0.136766254901886
Validation loss: 2.041958356897036

Epoch: 446| Step: 0
Training loss: 0.23477406799793243
Validation loss: 2.0677002370357513

Epoch: 5| Step: 1
Training loss: 0.29908260703086853
Validation loss: 2.0495691150426865

Epoch: 5| Step: 2
Training loss: 0.45715126395225525
Validation loss: 2.042911892135938

Epoch: 5| Step: 3
Training loss: 0.248578742146492
Validation loss: 2.043696184953054

Epoch: 5| Step: 4
Training loss: 0.25211015343666077
Validation loss: 2.028215989470482

Epoch: 5| Step: 5
Training loss: 0.5385873913764954
Validation loss: 1.9904169241587322

Epoch: 5| Step: 6
Training loss: 0.1690901517868042
Validation loss: 2.0183414270480475

Epoch: 5| Step: 7
Training loss: 0.32263773679733276
Validation loss: 2.0065950949986777

Epoch: 5| Step: 8
Training loss: 0.1713099479675293
Validation loss: 2.0407629857460656

Epoch: 5| Step: 9
Training loss: 0.23712721467018127
Validation loss: 2.0119865983724594

Epoch: 5| Step: 10
Training loss: 0.20666857063770294
Validation loss: 2.0394121011098227

Epoch: 5| Step: 11
Training loss: 0.2830365300178528
Validation loss: 2.0273738304773965

Epoch: 447| Step: 0
Training loss: 0.23839311301708221
Validation loss: 2.056221589446068

Epoch: 5| Step: 1
Training loss: 0.31913629174232483
Validation loss: 2.0158695677916207

Epoch: 5| Step: 2
Training loss: 0.21457788348197937
Validation loss: 2.025278553366661

Epoch: 5| Step: 3
Training loss: 0.45899438858032227
Validation loss: 2.0243385583162308

Epoch: 5| Step: 4
Training loss: 0.189907506108284
Validation loss: 2.0093287328879037

Epoch: 5| Step: 5
Training loss: 0.3073844313621521
Validation loss: 1.9980438202619553

Epoch: 5| Step: 6
Training loss: 0.3641993999481201
Validation loss: 2.007483755548795

Epoch: 5| Step: 7
Training loss: 0.2173040807247162
Validation loss: 2.0408662259578705

Epoch: 5| Step: 8
Training loss: 0.23874524235725403
Validation loss: 2.0117025822401047

Epoch: 5| Step: 9
Training loss: 0.271290123462677
Validation loss: 2.02454682191213

Epoch: 5| Step: 10
Training loss: 0.3041263222694397
Validation loss: 2.034122407436371

Epoch: 5| Step: 11
Training loss: 0.23187685012817383
Validation loss: 2.0625909864902496

Epoch: 448| Step: 0
Training loss: 0.3091747760772705
Validation loss: 2.0878200431664786

Epoch: 5| Step: 1
Training loss: 0.18581290543079376
Validation loss: 2.0434715350468955

Epoch: 5| Step: 2
Training loss: 0.5483022928237915
Validation loss: 2.007384419441223

Epoch: 5| Step: 3
Training loss: 0.283942312002182
Validation loss: 2.0355619490146637

Epoch: 5| Step: 4
Training loss: 0.17965246737003326
Validation loss: 2.0521844824155173

Epoch: 5| Step: 5
Training loss: 0.1875515878200531
Validation loss: 2.0378317733605704

Epoch: 5| Step: 6
Training loss: 0.3589862287044525
Validation loss: 2.024199108282725

Epoch: 5| Step: 7
Training loss: 0.18632780015468597
Validation loss: 2.05165662864844

Epoch: 5| Step: 8
Training loss: 0.333547443151474
Validation loss: 2.0377093454202018

Epoch: 5| Step: 9
Training loss: 0.11937160789966583
Validation loss: 2.075269361337026

Epoch: 5| Step: 10
Training loss: 0.17208071053028107
Validation loss: 2.061767856280009

Epoch: 5| Step: 11
Training loss: 0.1522233486175537
Validation loss: 2.0465004046758017

Epoch: 449| Step: 0
Training loss: 0.2218003273010254
Validation loss: 2.0316044638554254

Epoch: 5| Step: 1
Training loss: 0.22564084827899933
Validation loss: 2.0564668029546738

Epoch: 5| Step: 2
Training loss: 0.3625773787498474
Validation loss: 2.053702101111412

Epoch: 5| Step: 3
Training loss: 0.27672165632247925
Validation loss: 2.0640622675418854

Epoch: 5| Step: 4
Training loss: 0.21866092085838318
Validation loss: 2.0138989786307016

Epoch: 5| Step: 5
Training loss: 0.21839646995067596
Validation loss: 2.0207397043704987

Epoch: 5| Step: 6
Training loss: 0.2596290111541748
Validation loss: 2.075791666905085

Epoch: 5| Step: 7
Training loss: 0.21377845108509064
Validation loss: 2.082441126306852

Epoch: 5| Step: 8
Training loss: 0.48410406708717346
Validation loss: 2.020842577020327

Epoch: 5| Step: 9
Training loss: 0.29503053426742554
Validation loss: 2.028620883822441

Epoch: 5| Step: 10
Training loss: 0.20450451970100403
Validation loss: 2.080295334259669

Epoch: 5| Step: 11
Training loss: 0.09551745653152466
Validation loss: 2.0675394783417382

Epoch: 450| Step: 0
Training loss: 0.1929471492767334
Validation loss: 2.020909160375595

Epoch: 5| Step: 1
Training loss: 0.1960126757621765
Validation loss: 2.016961673895518

Epoch: 5| Step: 2
Training loss: 0.17545533180236816
Validation loss: 2.0281441062688828

Epoch: 5| Step: 3
Training loss: 0.32111313939094543
Validation loss: 2.054955164591471

Epoch: 5| Step: 4
Training loss: 0.1431313306093216
Validation loss: 2.0156457076470056

Epoch: 5| Step: 5
Training loss: 0.26713818311691284
Validation loss: 2.0890838305155435

Epoch: 5| Step: 6
Training loss: 0.176376074552536
Validation loss: 2.04268408815066

Epoch: 5| Step: 7
Training loss: 0.27290815114974976
Validation loss: 2.060781568288803

Epoch: 5| Step: 8
Training loss: 0.753592848777771
Validation loss: 2.0570104718208313

Epoch: 5| Step: 9
Training loss: 0.20144081115722656
Validation loss: 2.0213150729735694

Epoch: 5| Step: 10
Training loss: 0.317602276802063
Validation loss: 2.035840312639872

Epoch: 5| Step: 11
Training loss: 0.1634022444486618
Validation loss: 2.0766924222310386

Epoch: 451| Step: 0
Training loss: 0.23399615287780762
Validation loss: 2.0405871669451394

Epoch: 5| Step: 1
Training loss: 0.19454944133758545
Validation loss: 2.0665463556845984

Epoch: 5| Step: 2
Training loss: 0.2177153080701828
Validation loss: 2.055948590238889

Epoch: 5| Step: 3
Training loss: 0.37001821398735046
Validation loss: 2.0494437565406165

Epoch: 5| Step: 4
Training loss: 0.2661479115486145
Validation loss: 2.072602798541387

Epoch: 5| Step: 5
Training loss: 0.21224315464496613
Validation loss: 2.050225183367729

Epoch: 5| Step: 6
Training loss: 0.1520601063966751
Validation loss: 2.068031887213389

Epoch: 5| Step: 7
Training loss: 0.4636760652065277
Validation loss: 2.024892181158066

Epoch: 5| Step: 8
Training loss: 0.19848492741584778
Validation loss: 2.0511624415715537

Epoch: 5| Step: 9
Training loss: 0.5984241962432861
Validation loss: 2.0202884475390115

Epoch: 5| Step: 10
Training loss: 0.3077503740787506
Validation loss: 2.040707528591156

Epoch: 5| Step: 11
Training loss: 0.25980424880981445
Validation loss: 2.063198526700338

Epoch: 452| Step: 0
Training loss: 0.2485189437866211
Validation loss: 2.0395273168881736

Epoch: 5| Step: 1
Training loss: 0.27275970578193665
Validation loss: 2.0707164853811264

Epoch: 5| Step: 2
Training loss: 0.2409956157207489
Validation loss: 2.075502018133799

Epoch: 5| Step: 3
Training loss: 0.22044730186462402
Validation loss: 2.046190152565638

Epoch: 5| Step: 4
Training loss: 0.4281930923461914
Validation loss: 2.061674108107885

Epoch: 5| Step: 5
Training loss: 0.3369925618171692
Validation loss: 2.0612335155407586

Epoch: 5| Step: 6
Training loss: 0.3558703362941742
Validation loss: 2.0965488950411477

Epoch: 5| Step: 7
Training loss: 0.5179802179336548
Validation loss: 2.0392823119958243

Epoch: 5| Step: 8
Training loss: 0.2997351586818695
Validation loss: 2.0783466696739197

Epoch: 5| Step: 9
Training loss: 0.2874288856983185
Validation loss: 2.045584499835968

Epoch: 5| Step: 10
Training loss: 0.17584100365638733
Validation loss: 2.0717546989520392

Epoch: 5| Step: 11
Training loss: 0.19742260873317719
Validation loss: 2.0249943137168884

Epoch: 453| Step: 0
Training loss: 0.3741261661052704
Validation loss: 2.0270656843980155

Epoch: 5| Step: 1
Training loss: 0.25453343987464905
Validation loss: 2.0261938820282617

Epoch: 5| Step: 2
Training loss: 0.21858175098896027
Validation loss: 2.050986314813296

Epoch: 5| Step: 3
Training loss: 0.19828322529792786
Validation loss: 2.052211289604505

Epoch: 5| Step: 4
Training loss: 0.199203222990036
Validation loss: 2.0473742882410684

Epoch: 5| Step: 5
Training loss: 0.3943988084793091
Validation loss: 2.026120295127233

Epoch: 5| Step: 6
Training loss: 0.5887064933776855
Validation loss: 2.0634936143954596

Epoch: 5| Step: 7
Training loss: 0.2064010351896286
Validation loss: 2.011747727791468

Epoch: 5| Step: 8
Training loss: 0.2516435384750366
Validation loss: 2.0248339225848517

Epoch: 5| Step: 9
Training loss: 0.31856784224510193
Validation loss: 2.0409354915221534

Epoch: 5| Step: 10
Training loss: 0.25855308771133423
Validation loss: 1.9816162039836247

Epoch: 5| Step: 11
Training loss: 0.3851589858531952
Validation loss: 2.0562096486488977

Epoch: 454| Step: 0
Training loss: 0.20052294433116913
Validation loss: 2.025070458650589

Epoch: 5| Step: 1
Training loss: 0.20425724983215332
Validation loss: 2.068396051724752

Epoch: 5| Step: 2
Training loss: 0.4980649948120117
Validation loss: 2.0310445427894592

Epoch: 5| Step: 3
Training loss: 0.1815185248851776
Validation loss: 2.01648256679376

Epoch: 5| Step: 4
Training loss: 0.2515416145324707
Validation loss: 2.0803113679091134

Epoch: 5| Step: 5
Training loss: 0.35768765211105347
Validation loss: 2.03008001546065

Epoch: 5| Step: 6
Training loss: 0.2882417142391205
Validation loss: 2.0567756593227386

Epoch: 5| Step: 7
Training loss: 0.22081437706947327
Validation loss: 2.045099059740702

Epoch: 5| Step: 8
Training loss: 0.31176379323005676
Validation loss: 2.0363028248151145

Epoch: 5| Step: 9
Training loss: 0.304515540599823
Validation loss: 2.024031236767769

Epoch: 5| Step: 10
Training loss: 0.22167129814624786
Validation loss: 2.0309491803248725

Epoch: 5| Step: 11
Training loss: 0.20042544603347778
Validation loss: 2.0422178357839584

Epoch: 455| Step: 0
Training loss: 0.16243742406368256
Validation loss: 2.0747480740149817

Epoch: 5| Step: 1
Training loss: 0.17547406256198883
Validation loss: 2.0090807527303696

Epoch: 5| Step: 2
Training loss: 0.276106059551239
Validation loss: 2.03314545750618

Epoch: 5| Step: 3
Training loss: 0.1729017198085785
Validation loss: 2.031392758091291

Epoch: 5| Step: 4
Training loss: 0.4683194160461426
Validation loss: 2.0713570415973663

Epoch: 5| Step: 5
Training loss: 0.26409608125686646
Validation loss: 2.043316528201103

Epoch: 5| Step: 6
Training loss: 0.2313801348209381
Validation loss: 2.0549555917580924

Epoch: 5| Step: 7
Training loss: 0.3279650807380676
Validation loss: 2.0140446374813714

Epoch: 5| Step: 8
Training loss: 0.200495645403862
Validation loss: 2.017635613679886

Epoch: 5| Step: 9
Training loss: 0.17699143290519714
Validation loss: 2.0493737558523812

Epoch: 5| Step: 10
Training loss: 0.3358480930328369
Validation loss: 2.0062010188897452

Epoch: 5| Step: 11
Training loss: 0.2012317180633545
Validation loss: 2.0652176241079965

Epoch: 456| Step: 0
Training loss: 0.19715635478496552
Validation loss: 2.0264557103315988

Epoch: 5| Step: 1
Training loss: 0.34406885504722595
Validation loss: 2.03633343676726

Epoch: 5| Step: 2
Training loss: 0.14021845161914825
Validation loss: 2.018759270509084

Epoch: 5| Step: 3
Training loss: 0.5994107723236084
Validation loss: 2.039575532078743

Epoch: 5| Step: 4
Training loss: 0.3068252503871918
Validation loss: 2.0303371846675873

Epoch: 5| Step: 5
Training loss: 0.2721865773200989
Validation loss: 2.011474534869194

Epoch: 5| Step: 6
Training loss: 0.18456269800662994
Validation loss: 2.0253106405337653

Epoch: 5| Step: 7
Training loss: 0.17930321395397186
Validation loss: 1.9939890205860138

Epoch: 5| Step: 8
Training loss: 0.20696166157722473
Validation loss: 2.0134508510430655

Epoch: 5| Step: 9
Training loss: 0.1699930876493454
Validation loss: 2.0393994400898614

Epoch: 5| Step: 10
Training loss: 0.35900554060935974
Validation loss: 1.9902515262365341

Epoch: 5| Step: 11
Training loss: 0.12447118759155273
Validation loss: 2.0251502146323523

Epoch: 457| Step: 0
Training loss: 0.24128346145153046
Validation loss: 1.9907568097114563

Epoch: 5| Step: 1
Training loss: 0.20258653163909912
Validation loss: 1.9786659528811772

Epoch: 5| Step: 2
Training loss: 0.5481995344161987
Validation loss: 2.0254287471373877

Epoch: 5| Step: 3
Training loss: 0.20108279585838318
Validation loss: 2.0412257065375647

Epoch: 5| Step: 4
Training loss: 0.21865037083625793
Validation loss: 2.0140069077412286

Epoch: 5| Step: 5
Training loss: 0.2102418839931488
Validation loss: 2.022660573323568

Epoch: 5| Step: 6
Training loss: 0.2720350921154022
Validation loss: 2.0465534826119742

Epoch: 5| Step: 7
Training loss: 0.21745948493480682
Validation loss: 2.004004885752996

Epoch: 5| Step: 8
Training loss: 0.5477884411811829
Validation loss: 2.057349363962809

Epoch: 5| Step: 9
Training loss: 0.11814574897289276
Validation loss: 2.0519476433595023

Epoch: 5| Step: 10
Training loss: 0.28085675835609436
Validation loss: 2.0398992896080017

Epoch: 5| Step: 11
Training loss: 0.19274723529815674
Validation loss: 2.0419708589712777

Epoch: 458| Step: 0
Training loss: 0.5020161271095276
Validation loss: 2.029059906800588

Epoch: 5| Step: 1
Training loss: 0.19542957842350006
Validation loss: 2.0162333796421685

Epoch: 5| Step: 2
Training loss: 0.2855130732059479
Validation loss: 2.001405676205953

Epoch: 5| Step: 3
Training loss: 0.23830954730510712
Validation loss: 2.044305697083473

Epoch: 5| Step: 4
Training loss: 0.28890466690063477
Validation loss: 2.038885071873665

Epoch: 5| Step: 5
Training loss: 0.21719031035900116
Validation loss: 2.0836196690797806

Epoch: 5| Step: 6
Training loss: 0.3951976001262665
Validation loss: 2.0762944420178733

Epoch: 5| Step: 7
Training loss: 0.32029929757118225
Validation loss: 2.055306906501452

Epoch: 5| Step: 8
Training loss: 0.19852833449840546
Validation loss: 2.068434710303942

Epoch: 5| Step: 9
Training loss: 0.27135348320007324
Validation loss: 2.0675383309523263

Epoch: 5| Step: 10
Training loss: 0.30490419268608093
Validation loss: 2.0459327747424445

Epoch: 5| Step: 11
Training loss: 0.2303907871246338
Validation loss: 2.0621632238229117

Epoch: 459| Step: 0
Training loss: 0.4452577531337738
Validation loss: 2.060078884164492

Epoch: 5| Step: 1
Training loss: 0.2620324194431305
Validation loss: 2.0628253469864526

Epoch: 5| Step: 2
Training loss: 0.23178252577781677
Validation loss: 2.049927403529485

Epoch: 5| Step: 3
Training loss: 0.3274611234664917
Validation loss: 2.040511096517245

Epoch: 5| Step: 4
Training loss: 0.18962372839450836
Validation loss: 2.040900448958079

Epoch: 5| Step: 5
Training loss: 0.4876823425292969
Validation loss: 2.028904229402542

Epoch: 5| Step: 6
Training loss: 0.23954720795154572
Validation loss: 2.049968803922335

Epoch: 5| Step: 7
Training loss: 0.22603361308574677
Validation loss: 2.058370212713877

Epoch: 5| Step: 8
Training loss: 0.3219107985496521
Validation loss: 2.056394954522451

Epoch: 5| Step: 9
Training loss: 0.2889288067817688
Validation loss: 2.09439218044281

Epoch: 5| Step: 10
Training loss: 0.40895041823387146
Validation loss: 2.047821049888929

Epoch: 5| Step: 11
Training loss: 0.3487687110900879
Validation loss: 2.046751861770948

Epoch: 460| Step: 0
Training loss: 0.28724899888038635
Validation loss: 1.987199420730273

Epoch: 5| Step: 1
Training loss: 0.10662071406841278
Validation loss: 1.9999924500783284

Epoch: 5| Step: 2
Training loss: 0.2136317789554596
Validation loss: 2.0070887158314386

Epoch: 5| Step: 3
Training loss: 0.248280331492424
Validation loss: 2.07529583076636

Epoch: 5| Step: 4
Training loss: 0.2782284617424011
Validation loss: 2.0400463292996087

Epoch: 5| Step: 5
Training loss: 0.5625497698783875
Validation loss: 2.0586039423942566

Epoch: 5| Step: 6
Training loss: 0.5062239170074463
Validation loss: 2.0394247323274612

Epoch: 5| Step: 7
Training loss: 0.15684327483177185
Validation loss: 2.037315552433332

Epoch: 5| Step: 8
Training loss: 0.266814649105072
Validation loss: 1.9993987083435059

Epoch: 5| Step: 9
Training loss: 0.23260542750358582
Validation loss: 2.0660482893387475

Epoch: 5| Step: 10
Training loss: 0.22328200936317444
Validation loss: 2.037951906522115

Epoch: 5| Step: 11
Training loss: 0.12418361753225327
Validation loss: 2.007897973060608

Epoch: 461| Step: 0
Training loss: 0.3166906237602234
Validation loss: 2.0573198795318604

Epoch: 5| Step: 1
Training loss: 0.4956435263156891
Validation loss: 2.018690913915634

Epoch: 5| Step: 2
Training loss: 0.1818006932735443
Validation loss: 2.045495942234993

Epoch: 5| Step: 3
Training loss: 0.19675295054912567
Validation loss: 2.080990821123123

Epoch: 5| Step: 4
Training loss: 0.21881508827209473
Validation loss: 2.03625879685084

Epoch: 5| Step: 5
Training loss: 0.3035929501056671
Validation loss: 2.0625383059183755

Epoch: 5| Step: 6
Training loss: 0.28892144560813904
Validation loss: 2.0730745991071067

Epoch: 5| Step: 7
Training loss: 0.28576067090034485
Validation loss: 2.045104886094729

Epoch: 5| Step: 8
Training loss: 0.2104910910129547
Validation loss: 2.0923488487799964

Epoch: 5| Step: 9
Training loss: 0.16584189236164093
Validation loss: 2.049069474140803

Epoch: 5| Step: 10
Training loss: 0.1847534030675888
Validation loss: 2.047541171312332

Epoch: 5| Step: 11
Training loss: 0.5023691058158875
Validation loss: 2.048280566930771

Epoch: 462| Step: 0
Training loss: 0.30579763650894165
Validation loss: 2.0258573591709137

Epoch: 5| Step: 1
Training loss: 0.2500782907009125
Validation loss: 2.0394045313199363

Epoch: 5| Step: 2
Training loss: 0.44410425424575806
Validation loss: 2.069844792286555

Epoch: 5| Step: 3
Training loss: 0.1675911247730255
Validation loss: 2.035164867838224

Epoch: 5| Step: 4
Training loss: 0.21086688339710236
Validation loss: 2.0518392622470856

Epoch: 5| Step: 5
Training loss: 0.30757108330726624
Validation loss: 1.992899586757024

Epoch: 5| Step: 6
Training loss: 0.24615521728992462
Validation loss: 2.0584142804145813

Epoch: 5| Step: 7
Training loss: 0.40755051374435425
Validation loss: 2.046046197414398

Epoch: 5| Step: 8
Training loss: 0.18198446929454803
Validation loss: 2.0218164374430976

Epoch: 5| Step: 9
Training loss: 0.35246869921684265
Validation loss: 2.058139572540919

Epoch: 5| Step: 10
Training loss: 0.19911208748817444
Validation loss: 2.0317715853452682

Epoch: 5| Step: 11
Training loss: 0.13091230392456055
Validation loss: 2.052653416991234

Epoch: 463| Step: 0
Training loss: 0.24792635440826416
Validation loss: 2.0322471211353936

Epoch: 5| Step: 1
Training loss: 0.3233354091644287
Validation loss: 2.0469390749931335

Epoch: 5| Step: 2
Training loss: 0.31440937519073486
Validation loss: 2.068535327911377

Epoch: 5| Step: 3
Training loss: 0.20114055275917053
Validation loss: 2.012487828731537

Epoch: 5| Step: 4
Training loss: 0.21479249000549316
Validation loss: 2.060172657171885

Epoch: 5| Step: 5
Training loss: 0.23494434356689453
Validation loss: 2.0667561690012612

Epoch: 5| Step: 6
Training loss: 0.15546798706054688
Validation loss: 2.0789778232574463

Epoch: 5| Step: 7
Training loss: 0.5107960104942322
Validation loss: 2.0398461321989694

Epoch: 5| Step: 8
Training loss: 0.4611496031284332
Validation loss: 2.0438711096843085

Epoch: 5| Step: 9
Training loss: 0.23094542324543
Validation loss: 2.041834682226181

Epoch: 5| Step: 10
Training loss: 0.2348438948392868
Validation loss: 2.0582692126433053

Epoch: 5| Step: 11
Training loss: 0.20275525748729706
Validation loss: 2.0564689884583154

Epoch: 464| Step: 0
Training loss: 0.1884796917438507
Validation loss: 2.0494748701651893

Epoch: 5| Step: 1
Training loss: 0.22806748747825623
Validation loss: 2.043550968170166

Epoch: 5| Step: 2
Training loss: 0.2437053620815277
Validation loss: 2.0202289472023645

Epoch: 5| Step: 3
Training loss: 0.29674825072288513
Validation loss: 2.0384863366683326

Epoch: 5| Step: 4
Training loss: 0.24909064173698425
Validation loss: 2.0194763441880546

Epoch: 5| Step: 5
Training loss: 0.5464903116226196
Validation loss: 2.000508959094683

Epoch: 5| Step: 6
Training loss: 0.2217346727848053
Validation loss: 1.995967075228691

Epoch: 5| Step: 7
Training loss: 0.22814035415649414
Validation loss: 2.0037392526865005

Epoch: 5| Step: 8
Training loss: 0.4721839427947998
Validation loss: 2.0136673947175345

Epoch: 5| Step: 9
Training loss: 0.19316129386425018
Validation loss: 2.0137418061494827

Epoch: 5| Step: 10
Training loss: 0.15058156847953796
Validation loss: 2.0356601079305015

Epoch: 5| Step: 11
Training loss: 0.09150907397270203
Validation loss: 2.0436434596776962

Epoch: 465| Step: 0
Training loss: 0.23886480927467346
Validation loss: 2.0366614858309426

Epoch: 5| Step: 1
Training loss: 0.25693443417549133
Validation loss: 2.0302778482437134

Epoch: 5| Step: 2
Training loss: 0.23062372207641602
Validation loss: 2.0319466392199197

Epoch: 5| Step: 3
Training loss: 0.2760464549064636
Validation loss: 2.0302867939074836

Epoch: 5| Step: 4
Training loss: 0.17458374798297882
Validation loss: 2.04451684653759

Epoch: 5| Step: 5
Training loss: 0.14515231549739838
Validation loss: 2.041851580142975

Epoch: 5| Step: 6
Training loss: 0.34993448853492737
Validation loss: 2.071348915497462

Epoch: 5| Step: 7
Training loss: 0.5030008554458618
Validation loss: 2.057726005713145

Epoch: 5| Step: 8
Training loss: 0.180688738822937
Validation loss: 2.0313082933425903

Epoch: 5| Step: 9
Training loss: 0.3723882734775543
Validation loss: 2.0553556034962335

Epoch: 5| Step: 10
Training loss: 0.18645155429840088
Validation loss: 2.0937577237685523

Epoch: 5| Step: 11
Training loss: 0.10277581214904785
Validation loss: 2.0604386081298194

Epoch: 466| Step: 0
Training loss: 0.2234482765197754
Validation loss: 2.0199190576871238

Epoch: 5| Step: 1
Training loss: 0.3805397152900696
Validation loss: 2.078176826238632

Epoch: 5| Step: 2
Training loss: 0.19736453890800476
Validation loss: 2.070912609497706

Epoch: 5| Step: 3
Training loss: 0.3256010115146637
Validation loss: 2.0607996582984924

Epoch: 5| Step: 4
Training loss: 0.2655922472476959
Validation loss: 2.047810271382332

Epoch: 5| Step: 5
Training loss: 0.442988783121109
Validation loss: 2.0735723227262497

Epoch: 5| Step: 6
Training loss: 0.15234453976154327
Validation loss: 2.051331048210462

Epoch: 5| Step: 7
Training loss: 0.18060258030891418
Validation loss: 2.0487117916345596

Epoch: 5| Step: 8
Training loss: 0.16734082996845245
Validation loss: 2.0770909239848456

Epoch: 5| Step: 9
Training loss: 0.281893789768219
Validation loss: 2.050733139117559

Epoch: 5| Step: 10
Training loss: 0.17409691214561462
Validation loss: 2.107556387782097

Epoch: 5| Step: 11
Training loss: 0.34493783116340637
Validation loss: 2.0710856964190802

Epoch: 467| Step: 0
Training loss: 0.192744642496109
Validation loss: 2.0950796206792197

Epoch: 5| Step: 1
Training loss: 0.5484772324562073
Validation loss: 2.105284884572029

Epoch: 5| Step: 2
Training loss: 0.37179192900657654
Validation loss: 2.054166153073311

Epoch: 5| Step: 3
Training loss: 0.1721022129058838
Validation loss: 2.0496598184108734

Epoch: 5| Step: 4
Training loss: 0.15143077075481415
Validation loss: 2.060572395722071

Epoch: 5| Step: 5
Training loss: 0.19902794063091278
Validation loss: 2.0336570789416633

Epoch: 5| Step: 6
Training loss: 0.180876687169075
Validation loss: 2.047434945901235

Epoch: 5| Step: 7
Training loss: 0.21392886340618134
Validation loss: 2.0611833383639655

Epoch: 5| Step: 8
Training loss: 0.3990168869495392
Validation loss: 2.066874439517657

Epoch: 5| Step: 9
Training loss: 0.14652910828590393
Validation loss: 2.052825858195623

Epoch: 5| Step: 10
Training loss: 0.19241639971733093
Validation loss: 2.03453196088473

Epoch: 5| Step: 11
Training loss: 0.5965697169303894
Validation loss: 2.0131400525569916

Epoch: 468| Step: 0
Training loss: 0.38214346766471863
Validation loss: 2.0278012255827584

Epoch: 5| Step: 1
Training loss: 0.3451380431652069
Validation loss: 2.066960205634435

Epoch: 5| Step: 2
Training loss: 0.5064394474029541
Validation loss: 2.0608379195133844

Epoch: 5| Step: 3
Training loss: 0.21896901726722717
Validation loss: 2.030929073691368

Epoch: 5| Step: 4
Training loss: 0.15660534799098969
Validation loss: 2.0752276927232742

Epoch: 5| Step: 5
Training loss: 0.17621752619743347
Validation loss: 2.0684028218189874

Epoch: 5| Step: 6
Training loss: 0.17249831557273865
Validation loss: 2.044008811314901

Epoch: 5| Step: 7
Training loss: 0.26497042179107666
Validation loss: 2.066061496734619

Epoch: 5| Step: 8
Training loss: 0.19908279180526733
Validation loss: 2.047382175922394

Epoch: 5| Step: 9
Training loss: 0.21146170794963837
Validation loss: 2.075969581802686

Epoch: 5| Step: 10
Training loss: 0.1862274706363678
Validation loss: 2.060828318198522

Epoch: 5| Step: 11
Training loss: 0.7933495044708252
Validation loss: 2.035726378361384

Epoch: 469| Step: 0
Training loss: 0.1969613879919052
Validation loss: 2.0512300233046212

Epoch: 5| Step: 1
Training loss: 0.24248714745044708
Validation loss: 2.0381400187810264

Epoch: 5| Step: 2
Training loss: 0.25028181076049805
Validation loss: 2.020615443587303

Epoch: 5| Step: 3
Training loss: 0.6919624209403992
Validation loss: 2.036723996202151

Epoch: 5| Step: 4
Training loss: 0.2889992594718933
Validation loss: 2.09410068889459

Epoch: 5| Step: 5
Training loss: 0.2114705741405487
Validation loss: 2.0128666758537292

Epoch: 5| Step: 6
Training loss: 0.2678142488002777
Validation loss: 2.037956972916921

Epoch: 5| Step: 7
Training loss: 0.1801438182592392
Validation loss: 2.0441980808973312

Epoch: 5| Step: 8
Training loss: 0.17328594624996185
Validation loss: 2.0793783565362296

Epoch: 5| Step: 9
Training loss: 0.1744956523180008
Validation loss: 2.094049255053202

Epoch: 5| Step: 10
Training loss: 0.10157470405101776
Validation loss: 2.0689190278450647

Epoch: 5| Step: 11
Training loss: 0.13384521007537842
Validation loss: 2.041925628980001

Epoch: 470| Step: 0
Training loss: 0.2275335043668747
Validation loss: 2.0366457253694534

Epoch: 5| Step: 1
Training loss: 0.18133491277694702
Validation loss: 2.0856000433365502

Epoch: 5| Step: 2
Training loss: 0.39989691972732544
Validation loss: 2.034025897582372

Epoch: 5| Step: 3
Training loss: 0.5872713923454285
Validation loss: 2.0668740272521973

Epoch: 5| Step: 4
Training loss: 0.23655001819133759
Validation loss: 2.0849307427803674

Epoch: 5| Step: 5
Training loss: 0.19005678594112396
Validation loss: 2.074107900261879

Epoch: 5| Step: 6
Training loss: 0.22808018326759338
Validation loss: 2.03585055967172

Epoch: 5| Step: 7
Training loss: 0.38786351680755615
Validation loss: 2.0394585877656937

Epoch: 5| Step: 8
Training loss: 0.24756665527820587
Validation loss: 2.0733384738365808

Epoch: 5| Step: 9
Training loss: 0.1730356216430664
Validation loss: 2.032452419400215

Epoch: 5| Step: 10
Training loss: 0.23950839042663574
Validation loss: 2.022163068254789

Epoch: 5| Step: 11
Training loss: 0.35736334323883057
Validation loss: 2.0343682368596396

Epoch: 471| Step: 0
Training loss: 0.20230360329151154
Validation loss: 2.0039917081594467

Epoch: 5| Step: 1
Training loss: 0.2695310115814209
Validation loss: 2.016751706600189

Epoch: 5| Step: 2
Training loss: 0.24289695918560028
Validation loss: 2.004078115026156

Epoch: 5| Step: 3
Training loss: 0.243578240275383
Validation loss: 2.024277081092199

Epoch: 5| Step: 4
Training loss: 0.2590940594673157
Validation loss: 2.0469966729482016

Epoch: 5| Step: 5
Training loss: 0.2250339537858963
Validation loss: 2.0384481300910315

Epoch: 5| Step: 6
Training loss: 0.4296819567680359
Validation loss: 2.046662991245588

Epoch: 5| Step: 7
Training loss: 0.22796806693077087
Validation loss: 2.0507230311632156

Epoch: 5| Step: 8
Training loss: 0.655636191368103
Validation loss: 2.0326095620791116

Epoch: 5| Step: 9
Training loss: 0.17893460392951965
Validation loss: 2.0301011353731155

Epoch: 5| Step: 10
Training loss: 0.20584797859191895
Validation loss: 1.9994690616925557

Epoch: 5| Step: 11
Training loss: 0.361000120639801
Validation loss: 2.017920210957527

Epoch: 472| Step: 0
Training loss: 0.16562922298908234
Validation loss: 2.010325863957405

Epoch: 5| Step: 1
Training loss: 0.267278254032135
Validation loss: 2.019880165656408

Epoch: 5| Step: 2
Training loss: 0.5170902609825134
Validation loss: 2.0251830567916236

Epoch: 5| Step: 3
Training loss: 0.18481765687465668
Validation loss: 2.020417799552282

Epoch: 5| Step: 4
Training loss: 0.27525651454925537
Validation loss: 2.043433507283529

Epoch: 5| Step: 5
Training loss: 0.33920755982398987
Validation loss: 2.033080001672109

Epoch: 5| Step: 6
Training loss: 0.19796648621559143
Validation loss: 2.03845343987147

Epoch: 5| Step: 7
Training loss: 0.37589120864868164
Validation loss: 2.04285421470801

Epoch: 5| Step: 8
Training loss: 0.19212336838245392
Validation loss: 2.0482295801242194

Epoch: 5| Step: 9
Training loss: 0.218431755900383
Validation loss: 2.0191655258337655

Epoch: 5| Step: 10
Training loss: 0.26760491728782654
Validation loss: 2.032553260525068

Epoch: 5| Step: 11
Training loss: 0.1355801820755005
Validation loss: 2.0322327415148416

Epoch: 473| Step: 0
Training loss: 0.2746206820011139
Validation loss: 2.0231310526529946

Epoch: 5| Step: 1
Training loss: 0.4139103293418884
Validation loss: 2.056696260968844

Epoch: 5| Step: 2
Training loss: 0.39164358377456665
Validation loss: 2.0088583578666053

Epoch: 5| Step: 3
Training loss: 0.2765381336212158
Validation loss: 2.045770972967148

Epoch: 5| Step: 4
Training loss: 0.45024165511131287
Validation loss: 2.0433794955412545

Epoch: 5| Step: 5
Training loss: 0.25738757848739624
Validation loss: 2.057975192864736

Epoch: 5| Step: 6
Training loss: 0.2887919843196869
Validation loss: 2.0872239669164023

Epoch: 5| Step: 7
Training loss: 0.5330060720443726
Validation loss: 2.0718015929063163

Epoch: 5| Step: 8
Training loss: 0.21185120940208435
Validation loss: 2.0750447710355124

Epoch: 5| Step: 9
Training loss: 0.3060840964317322
Validation loss: 2.0476315716902413

Epoch: 5| Step: 10
Training loss: 0.19941028952598572
Validation loss: 2.0359342843294144

Epoch: 5| Step: 11
Training loss: 0.3052815794944763
Validation loss: 2.0396837989489236

Epoch: 474| Step: 0
Training loss: 0.6345981955528259
Validation loss: 2.0358497699101767

Epoch: 5| Step: 1
Training loss: 0.2346520721912384
Validation loss: 2.0711991439263024

Epoch: 5| Step: 2
Training loss: 0.12034467607736588
Validation loss: 2.0329691668351493

Epoch: 5| Step: 3
Training loss: 0.26712408661842346
Validation loss: 2.038930907845497

Epoch: 5| Step: 4
Training loss: 0.1499422937631607
Validation loss: 2.0520482063293457

Epoch: 5| Step: 5
Training loss: 0.13276101648807526
Validation loss: 2.077069232861201

Epoch: 5| Step: 6
Training loss: 0.16560983657836914
Validation loss: 2.030902619163195

Epoch: 5| Step: 7
Training loss: 0.33096998929977417
Validation loss: 2.041405732433001

Epoch: 5| Step: 8
Training loss: 0.15682633221149445
Validation loss: 2.0693526566028595

Epoch: 5| Step: 9
Training loss: 0.305745393037796
Validation loss: 2.0613824327786765

Epoch: 5| Step: 10
Training loss: 0.15197452902793884
Validation loss: 2.0667146742343903

Epoch: 5| Step: 11
Training loss: 0.5515192151069641
Validation loss: 2.054491509993871

Epoch: 475| Step: 0
Training loss: 0.24153217673301697
Validation loss: 2.0620883107185364

Epoch: 5| Step: 1
Training loss: 0.18946446478366852
Validation loss: 2.0887045164903006

Epoch: 5| Step: 2
Training loss: 0.276593416929245
Validation loss: 2.09910586476326

Epoch: 5| Step: 3
Training loss: 0.14346179366111755
Validation loss: 2.082161774237951

Epoch: 5| Step: 4
Training loss: 0.203281968832016
Validation loss: 2.0580988625685372

Epoch: 5| Step: 5
Training loss: 0.2393222153186798
Validation loss: 2.0828193773825965

Epoch: 5| Step: 6
Training loss: 0.2207912653684616
Validation loss: 2.054011419415474

Epoch: 5| Step: 7
Training loss: 0.46295157074928284
Validation loss: 2.0388775765895844

Epoch: 5| Step: 8
Training loss: 0.23164410889148712
Validation loss: 2.0845298866430917

Epoch: 5| Step: 9
Training loss: 0.20508739352226257
Validation loss: 2.0517981747786203

Epoch: 5| Step: 10
Training loss: 0.30186909437179565
Validation loss: 2.043156107266744

Epoch: 5| Step: 11
Training loss: 0.20330023765563965
Validation loss: 2.0750109205643334

Epoch: 476| Step: 0
Training loss: 0.21607565879821777
Validation loss: 2.0907686750094094

Epoch: 5| Step: 1
Training loss: 0.1976502388715744
Validation loss: 2.033749853571256

Epoch: 5| Step: 2
Training loss: 0.1751389503479004
Validation loss: 2.0557020554939904

Epoch: 5| Step: 3
Training loss: 0.13031736016273499
Validation loss: 2.0688536862532296

Epoch: 5| Step: 4
Training loss: 0.2953445315361023
Validation loss: 2.0367938429117203

Epoch: 5| Step: 5
Training loss: 0.23709455132484436
Validation loss: 2.0902233173449836

Epoch: 5| Step: 6
Training loss: 0.49482160806655884
Validation loss: 2.0381852239370346

Epoch: 5| Step: 7
Training loss: 0.2428639680147171
Validation loss: 2.0715288867553077

Epoch: 5| Step: 8
Training loss: 0.17737671732902527
Validation loss: 2.050087109208107

Epoch: 5| Step: 9
Training loss: 0.4273920953273773
Validation loss: 2.067608952522278

Epoch: 5| Step: 10
Training loss: 0.2927631139755249
Validation loss: 2.057175079981486

Epoch: 5| Step: 11
Training loss: 0.21815812587738037
Validation loss: 2.058486133813858

Epoch: 477| Step: 0
Training loss: 0.2167855203151703
Validation loss: 2.043332263827324

Epoch: 5| Step: 1
Training loss: 0.18000242114067078
Validation loss: 2.0713947216669717

Epoch: 5| Step: 2
Training loss: 0.4684537947177887
Validation loss: 2.0920904825131097

Epoch: 5| Step: 3
Training loss: 0.33763352036476135
Validation loss: 2.0579873075087867

Epoch: 5| Step: 4
Training loss: 0.23449191451072693
Validation loss: 2.0699255019426346

Epoch: 5| Step: 5
Training loss: 0.18620078265666962
Validation loss: 2.0505824089050293

Epoch: 5| Step: 6
Training loss: 0.10420067608356476
Validation loss: 2.039852192004522

Epoch: 5| Step: 7
Training loss: 0.3813919425010681
Validation loss: 2.026033247510592

Epoch: 5| Step: 8
Training loss: 0.31878799200057983
Validation loss: 2.0736389656861625

Epoch: 5| Step: 9
Training loss: 0.29911452531814575
Validation loss: 2.056198994318644

Epoch: 5| Step: 10
Training loss: 0.33832618594169617
Validation loss: 2.0878192484378815

Epoch: 5| Step: 11
Training loss: 0.2675650417804718
Validation loss: 2.0435651441415152

Epoch: 478| Step: 0
Training loss: 0.16362138092517853
Validation loss: 2.074869155883789

Epoch: 5| Step: 1
Training loss: 0.27407389879226685
Validation loss: 2.0246798992156982

Epoch: 5| Step: 2
Training loss: 0.1934177726507187
Validation loss: 2.0177684177954993

Epoch: 5| Step: 3
Training loss: 0.17631939053535461
Validation loss: 2.0808330178260803

Epoch: 5| Step: 4
Training loss: 0.1169222816824913
Validation loss: 2.048712725440661

Epoch: 5| Step: 5
Training loss: 0.24486038088798523
Validation loss: 2.044493228197098

Epoch: 5| Step: 6
Training loss: 0.230790376663208
Validation loss: 2.024504154920578

Epoch: 5| Step: 7
Training loss: 0.49667757749557495
Validation loss: 2.04997311035792

Epoch: 5| Step: 8
Training loss: 0.3682214915752411
Validation loss: 2.061887656648954

Epoch: 5| Step: 9
Training loss: 0.3648480772972107
Validation loss: 2.048960109551748

Epoch: 5| Step: 10
Training loss: 0.2545167803764343
Validation loss: 2.099830850958824

Epoch: 5| Step: 11
Training loss: 0.1837211400270462
Validation loss: 2.0716102768977485

Epoch: 479| Step: 0
Training loss: 0.28924307227134705
Validation loss: 2.078923930724462

Epoch: 5| Step: 1
Training loss: 0.2154405564069748
Validation loss: 2.056068783005079

Epoch: 5| Step: 2
Training loss: 0.22577837109565735
Validation loss: 2.0664947082599006

Epoch: 5| Step: 3
Training loss: 0.47069430351257324
Validation loss: 2.0526579866806665

Epoch: 5| Step: 4
Training loss: 0.16110804677009583
Validation loss: 2.0413157045841217

Epoch: 5| Step: 5
Training loss: 0.15159711241722107
Validation loss: 2.0736083587010703

Epoch: 5| Step: 6
Training loss: 0.26053452491760254
Validation loss: 2.0557633688052497

Epoch: 5| Step: 7
Training loss: 0.20195750892162323
Validation loss: 2.040001794695854

Epoch: 5| Step: 8
Training loss: 0.2957668602466583
Validation loss: 2.049066891272863

Epoch: 5| Step: 9
Training loss: 0.27445319294929504
Validation loss: 2.0944566130638123

Epoch: 5| Step: 10
Training loss: 0.34772223234176636
Validation loss: 2.085011218984922

Epoch: 5| Step: 11
Training loss: 0.18608438968658447
Validation loss: 2.0634023497502008

Epoch: 480| Step: 0
Training loss: 0.26253658533096313
Validation loss: 2.083745355407397

Epoch: 5| Step: 1
Training loss: 0.27118921279907227
Validation loss: 2.046726996699969

Epoch: 5| Step: 2
Training loss: 0.3273842930793762
Validation loss: 2.0676707873741784

Epoch: 5| Step: 3
Training loss: 0.2901551425457001
Validation loss: 2.048029055198034

Epoch: 5| Step: 4
Training loss: 0.29571446776390076
Validation loss: 2.0585245887438455

Epoch: 5| Step: 5
Training loss: 0.3521997928619385
Validation loss: 2.0406375974416733

Epoch: 5| Step: 6
Training loss: 0.23113003373146057
Validation loss: 2.029101009170214

Epoch: 5| Step: 7
Training loss: 0.3583272695541382
Validation loss: 2.0420953035354614

Epoch: 5| Step: 8
Training loss: 0.6023626327514648
Validation loss: 2.0816294848918915

Epoch: 5| Step: 9
Training loss: 0.35178861021995544
Validation loss: 2.0443098644415536

Epoch: 5| Step: 10
Training loss: 0.14632156491279602
Validation loss: 2.0286364406347275

Epoch: 5| Step: 11
Training loss: 0.23893189430236816
Validation loss: 2.092277228832245

Epoch: 481| Step: 0
Training loss: 0.23106649518013
Validation loss: 2.0576483607292175

Epoch: 5| Step: 1
Training loss: 0.23774680495262146
Validation loss: 2.052817697326342

Epoch: 5| Step: 2
Training loss: 0.1474127322435379
Validation loss: 2.0707263896862664

Epoch: 5| Step: 3
Training loss: 0.5541661977767944
Validation loss: 2.0431033422549567

Epoch: 5| Step: 4
Training loss: 0.2944752871990204
Validation loss: 2.091299811999003

Epoch: 5| Step: 5
Training loss: 0.15422751009464264
Validation loss: 2.046350265542666

Epoch: 5| Step: 6
Training loss: 0.1532866656780243
Validation loss: 2.0499147325754166

Epoch: 5| Step: 7
Training loss: 0.21603640913963318
Validation loss: 2.0312036871910095

Epoch: 5| Step: 8
Training loss: 0.21912458539009094
Validation loss: 2.0668919732173285

Epoch: 5| Step: 9
Training loss: 0.1736036092042923
Validation loss: 2.0600344091653824

Epoch: 5| Step: 10
Training loss: 0.34895166754722595
Validation loss: 2.075489486257235

Epoch: 5| Step: 11
Training loss: 0.22744160890579224
Validation loss: 2.0665391385555267

Epoch: 482| Step: 0
Training loss: 0.15211811661720276
Validation loss: 2.0614579617977142

Epoch: 5| Step: 1
Training loss: 0.21045055985450745
Validation loss: 2.0732699036598206

Epoch: 5| Step: 2
Training loss: 0.17776302993297577
Validation loss: 2.062278389930725

Epoch: 5| Step: 3
Training loss: 0.2751946747303009
Validation loss: 2.0384619732697806

Epoch: 5| Step: 4
Training loss: 0.19839124381542206
Validation loss: 2.080063611268997

Epoch: 5| Step: 5
Training loss: 0.47453221678733826
Validation loss: 2.071423868338267

Epoch: 5| Step: 6
Training loss: 0.2213953733444214
Validation loss: 2.057010610898336

Epoch: 5| Step: 7
Training loss: 0.5267540216445923
Validation loss: 2.094754343231519

Epoch: 5| Step: 8
Training loss: 0.26156920194625854
Validation loss: 2.051989883184433

Epoch: 5| Step: 9
Training loss: 0.24779577553272247
Validation loss: 2.089287439982096

Epoch: 5| Step: 10
Training loss: 0.3036178946495056
Validation loss: 2.066869412859281

Epoch: 5| Step: 11
Training loss: 0.12441003322601318
Validation loss: 2.0254373997449875

Epoch: 483| Step: 0
Training loss: 0.3621070384979248
Validation loss: 2.087489520510038

Epoch: 5| Step: 1
Training loss: 0.31469041109085083
Validation loss: 2.081451470653216

Epoch: 5| Step: 2
Training loss: 0.45447808504104614
Validation loss: 2.017484019200007

Epoch: 5| Step: 3
Training loss: 0.403400182723999
Validation loss: 2.0847102453311286

Epoch: 5| Step: 4
Training loss: 0.2475326508283615
Validation loss: 2.0882318218549094

Epoch: 5| Step: 5
Training loss: 0.34138092398643494
Validation loss: 2.0744436283906302

Epoch: 5| Step: 6
Training loss: 0.31417378783226013
Validation loss: 2.0254201094309487

Epoch: 5| Step: 7
Training loss: 0.2962372899055481
Validation loss: 2.0671062767505646

Epoch: 5| Step: 8
Training loss: 0.30886998772621155
Validation loss: 2.1161246597766876

Epoch: 5| Step: 9
Training loss: 0.338469535112381
Validation loss: 2.0934667736291885

Epoch: 5| Step: 10
Training loss: 0.6082991361618042
Validation loss: 2.074668765068054

Epoch: 5| Step: 11
Training loss: 0.2606297731399536
Validation loss: 2.0468582212924957

Epoch: 484| Step: 0
Training loss: 0.29178476333618164
Validation loss: 2.0562364558378854

Epoch: 5| Step: 1
Training loss: 0.24994292855262756
Validation loss: 2.0179728666941323

Epoch: 5| Step: 2
Training loss: 0.30417412519454956
Validation loss: 2.092697968085607

Epoch: 5| Step: 3
Training loss: 0.3036629557609558
Validation loss: 2.099616448084513

Epoch: 5| Step: 4
Training loss: 0.3278871774673462
Validation loss: 2.0912849406401315

Epoch: 5| Step: 5
Training loss: 0.227918341755867
Validation loss: 2.095474640528361

Epoch: 5| Step: 6
Training loss: 0.2002890408039093
Validation loss: 2.0663923919200897

Epoch: 5| Step: 7
Training loss: 0.49332961440086365
Validation loss: 2.0889892081419625

Epoch: 5| Step: 8
Training loss: 0.4616765081882477
Validation loss: 2.124957337975502

Epoch: 5| Step: 9
Training loss: 0.3809641897678375
Validation loss: 2.0704406847556434

Epoch: 5| Step: 10
Training loss: 0.27370166778564453
Validation loss: 2.0827570855617523

Epoch: 5| Step: 11
Training loss: 0.38413292169570923
Validation loss: 2.112507144610087

Epoch: 485| Step: 0
Training loss: 0.18610914051532745
Validation loss: 2.0604186157385507

Epoch: 5| Step: 1
Training loss: 0.15907928347587585
Validation loss: 2.0512567261854806

Epoch: 5| Step: 2
Training loss: 0.29790443181991577
Validation loss: 2.0777130126953125

Epoch: 5| Step: 3
Training loss: 0.7030051946640015
Validation loss: 2.06833545366923

Epoch: 5| Step: 4
Training loss: 0.29565367102622986
Validation loss: 2.045914188027382

Epoch: 5| Step: 5
Training loss: 0.32421204447746277
Validation loss: 2.1019674042860665

Epoch: 5| Step: 6
Training loss: 0.23800607025623322
Validation loss: 2.047147730986277

Epoch: 5| Step: 7
Training loss: 0.1379006952047348
Validation loss: 2.0462719599405923

Epoch: 5| Step: 8
Training loss: 0.1886579692363739
Validation loss: 2.02858197192351

Epoch: 5| Step: 9
Training loss: 0.3109268546104431
Validation loss: 2.069416801134745

Epoch: 5| Step: 10
Training loss: 0.3142918646335602
Validation loss: 2.0492945363124213

Epoch: 5| Step: 11
Training loss: 0.8149306774139404
Validation loss: 2.0632243851820626

Epoch: 486| Step: 0
Training loss: 0.19319479167461395
Validation loss: 2.022722711165746

Epoch: 5| Step: 1
Training loss: 0.29291054606437683
Validation loss: 2.0580457796653113

Epoch: 5| Step: 2
Training loss: 0.19413220882415771
Validation loss: 2.054143706957499

Epoch: 5| Step: 3
Training loss: 0.2044203281402588
Validation loss: 2.0325153966744742

Epoch: 5| Step: 4
Training loss: 0.2349507063627243
Validation loss: 2.0341469943523407

Epoch: 5| Step: 5
Training loss: 0.23554781079292297
Validation loss: 2.0199990222851434

Epoch: 5| Step: 6
Training loss: 0.24417278170585632
Validation loss: 2.0371922850608826

Epoch: 5| Step: 7
Training loss: 0.5906631946563721
Validation loss: 2.0554743061463037

Epoch: 5| Step: 8
Training loss: 0.2007763683795929
Validation loss: 2.0212369710206985

Epoch: 5| Step: 9
Training loss: 0.3127574920654297
Validation loss: 2.0674796601136527

Epoch: 5| Step: 10
Training loss: 0.25402650237083435
Validation loss: 1.9886520902315776

Epoch: 5| Step: 11
Training loss: 0.09078729152679443
Validation loss: 2.0396128247181573

Epoch: 487| Step: 0
Training loss: 0.26429063081741333
Validation loss: 2.051175758242607

Epoch: 5| Step: 1
Training loss: 0.2681804299354553
Validation loss: 2.04710853099823

Epoch: 5| Step: 2
Training loss: 0.2307921200990677
Validation loss: 2.0372265676657357

Epoch: 5| Step: 3
Training loss: 0.20381316542625427
Validation loss: 2.028044879436493

Epoch: 5| Step: 4
Training loss: 0.305609792470932
Validation loss: 2.0416224946578345

Epoch: 5| Step: 5
Training loss: 0.18692746758460999
Validation loss: 2.027182554205259

Epoch: 5| Step: 6
Training loss: 0.46339893341064453
Validation loss: 2.040720005830129

Epoch: 5| Step: 7
Training loss: 0.19137561321258545
Validation loss: 2.026517445842425

Epoch: 5| Step: 8
Training loss: 0.18050821125507355
Validation loss: 2.0137305160363517

Epoch: 5| Step: 9
Training loss: 0.29661187529563904
Validation loss: 2.0681294600168862

Epoch: 5| Step: 10
Training loss: 0.23309648036956787
Validation loss: 2.042379523317019

Epoch: 5| Step: 11
Training loss: 0.40002110600471497
Validation loss: 2.0138340493043265

Epoch: 488| Step: 0
Training loss: 0.34920820593833923
Validation loss: 2.024179776509603

Epoch: 5| Step: 1
Training loss: 0.22721457481384277
Validation loss: 2.017167533437411

Epoch: 5| Step: 2
Training loss: 0.2063574343919754
Validation loss: 2.0281785825888314

Epoch: 5| Step: 3
Training loss: 0.1750589907169342
Validation loss: 2.0665467778841653

Epoch: 5| Step: 4
Training loss: 0.17080603539943695
Validation loss: 2.0443634390830994

Epoch: 5| Step: 5
Training loss: 0.5323613882064819
Validation loss: 2.093537747859955

Epoch: 5| Step: 6
Training loss: 0.2386784851551056
Validation loss: 2.0582829465468726

Epoch: 5| Step: 7
Training loss: 0.24482011795043945
Validation loss: 2.0211473802725473

Epoch: 5| Step: 8
Training loss: 0.1697465479373932
Validation loss: 2.0199108719825745

Epoch: 5| Step: 9
Training loss: 0.12869061529636383
Validation loss: 2.067544942100843

Epoch: 5| Step: 10
Training loss: 0.12964017689228058
Validation loss: 2.059435173869133

Epoch: 5| Step: 11
Training loss: 0.6316884756088257
Validation loss: 2.034115528066953

Epoch: 489| Step: 0
Training loss: 0.2264111340045929
Validation loss: 2.0378628025452294

Epoch: 5| Step: 1
Training loss: 0.16383852064609528
Validation loss: 2.067022348443667

Epoch: 5| Step: 2
Training loss: 0.21094092726707458
Validation loss: 2.0849903325239816

Epoch: 5| Step: 3
Training loss: 0.22004716098308563
Validation loss: 2.0889745901028314

Epoch: 5| Step: 4
Training loss: 0.3136325776576996
Validation loss: 2.0919991383949914

Epoch: 5| Step: 5
Training loss: 0.1834334135055542
Validation loss: 2.0667911569277444

Epoch: 5| Step: 6
Training loss: 0.5558996200561523
Validation loss: 2.076913113395373

Epoch: 5| Step: 7
Training loss: 0.3304261565208435
Validation loss: 2.0455598334471383

Epoch: 5| Step: 8
Training loss: 0.23436975479125977
Validation loss: 2.0686322848002114

Epoch: 5| Step: 9
Training loss: 0.3151880204677582
Validation loss: 2.008233686288198

Epoch: 5| Step: 10
Training loss: 0.2382560670375824
Validation loss: 2.053393309315046

Epoch: 5| Step: 11
Training loss: 0.28595662117004395
Validation loss: 2.0816207230091095

Epoch: 490| Step: 0
Training loss: 0.1810643970966339
Validation loss: 2.048421854774157

Epoch: 5| Step: 1
Training loss: 0.2335442751646042
Validation loss: 2.073025102416674

Epoch: 5| Step: 2
Training loss: 0.18337973952293396
Validation loss: 2.0624165336290994

Epoch: 5| Step: 3
Training loss: 0.1725379079580307
Validation loss: 2.0814209977785745

Epoch: 5| Step: 4
Training loss: 0.32624387741088867
Validation loss: 2.067970037460327

Epoch: 5| Step: 5
Training loss: 0.49604400992393494
Validation loss: 2.0379589398701987

Epoch: 5| Step: 6
Training loss: 0.3047448992729187
Validation loss: 2.0548113832871118

Epoch: 5| Step: 7
Training loss: 0.18919865787029266
Validation loss: 2.042868028084437

Epoch: 5| Step: 8
Training loss: 0.20222172141075134
Validation loss: 2.0397502730290094

Epoch: 5| Step: 9
Training loss: 0.1202019453048706
Validation loss: 2.0339254438877106

Epoch: 5| Step: 10
Training loss: 0.3408820331096649
Validation loss: 2.027227893471718

Epoch: 5| Step: 11
Training loss: 0.16456890106201172
Validation loss: 2.0730753242969513

Epoch: 491| Step: 0
Training loss: 0.23118968307971954
Validation loss: 2.0530350555976233

Epoch: 5| Step: 1
Training loss: 0.20447561144828796
Validation loss: 2.0556192100048065

Epoch: 5| Step: 2
Training loss: 0.2582273483276367
Validation loss: 2.0393753399451575

Epoch: 5| Step: 3
Training loss: 0.1916264295578003
Validation loss: 2.002539277076721

Epoch: 5| Step: 4
Training loss: 0.301342636346817
Validation loss: 2.0241010983784995

Epoch: 5| Step: 5
Training loss: 0.4940560758113861
Validation loss: 2.090800002217293

Epoch: 5| Step: 6
Training loss: 0.1288459300994873
Validation loss: 2.05566868185997

Epoch: 5| Step: 7
Training loss: 0.1648397445678711
Validation loss: 2.0458026230335236

Epoch: 5| Step: 8
Training loss: 0.23120121657848358
Validation loss: 2.0550763408342996

Epoch: 5| Step: 9
Training loss: 0.19729262590408325
Validation loss: 2.031708170970281

Epoch: 5| Step: 10
Training loss: 0.21003517508506775
Validation loss: 2.0230351289113364

Epoch: 5| Step: 11
Training loss: 0.2495983988046646
Validation loss: 2.079349641998609

Epoch: 492| Step: 0
Training loss: 0.19994188845157623
Validation loss: 2.0408547619978585

Epoch: 5| Step: 1
Training loss: 0.4535145163536072
Validation loss: 2.0620229492584863

Epoch: 5| Step: 2
Training loss: 0.22532224655151367
Validation loss: 2.0437210500240326

Epoch: 5| Step: 3
Training loss: 0.3867146968841553
Validation loss: 2.0444805324077606

Epoch: 5| Step: 4
Training loss: 0.14991030097007751
Validation loss: 2.0422106881936393

Epoch: 5| Step: 5
Training loss: 0.15309295058250427
Validation loss: 2.0181506226460137

Epoch: 5| Step: 6
Training loss: 0.3076004385948181
Validation loss: 2.0700437476237616

Epoch: 5| Step: 7
Training loss: 0.2768070697784424
Validation loss: 2.0652284721533456

Epoch: 5| Step: 8
Training loss: 0.2073110044002533
Validation loss: 2.0263834297657013

Epoch: 5| Step: 9
Training loss: 0.24272653460502625
Validation loss: 2.021965151031812

Epoch: 5| Step: 10
Training loss: 0.23771190643310547
Validation loss: 2.0208629071712494

Epoch: 5| Step: 11
Training loss: 0.13256634771823883
Validation loss: 2.0619117269913354

Epoch: 493| Step: 0
Training loss: 0.25144413113594055
Validation loss: 2.060262898604075

Epoch: 5| Step: 1
Training loss: 0.2034618854522705
Validation loss: 2.044438978036245

Epoch: 5| Step: 2
Training loss: 0.32823866605758667
Validation loss: 2.038818766673406

Epoch: 5| Step: 3
Training loss: 0.20781603455543518
Validation loss: 2.059846286972364

Epoch: 5| Step: 4
Training loss: 0.3351590037345886
Validation loss: 2.0719469785690308

Epoch: 5| Step: 5
Training loss: 0.20485743880271912
Validation loss: 2.026001771291097

Epoch: 5| Step: 6
Training loss: 0.2628675699234009
Validation loss: 2.0507865746816

Epoch: 5| Step: 7
Training loss: 0.21538183093070984
Validation loss: 2.0497026989857354

Epoch: 5| Step: 8
Training loss: 0.3309459090232849
Validation loss: 2.0434331943591437

Epoch: 5| Step: 9
Training loss: 0.19993746280670166
Validation loss: 2.084351748228073

Epoch: 5| Step: 10
Training loss: 0.469207763671875
Validation loss: 2.0348373552163443

Epoch: 5| Step: 11
Training loss: 0.19564691185951233
Validation loss: 2.035032028953234

Epoch: 494| Step: 0
Training loss: 0.157452791929245
Validation loss: 2.068414260943731

Epoch: 5| Step: 1
Training loss: 0.2606888711452484
Validation loss: 2.0377589414517083

Epoch: 5| Step: 2
Training loss: 0.12694677710533142
Validation loss: 2.0293327222267785

Epoch: 5| Step: 3
Training loss: 0.2071494162082672
Validation loss: 2.011259694894155

Epoch: 5| Step: 4
Training loss: 0.20691032707691193
Validation loss: 2.0386426548163095

Epoch: 5| Step: 5
Training loss: 0.3377705216407776
Validation loss: 2.018942415714264

Epoch: 5| Step: 6
Training loss: 0.3684593737125397
Validation loss: 2.0247854689757028

Epoch: 5| Step: 7
Training loss: 0.20939116179943085
Validation loss: 2.023469756046931

Epoch: 5| Step: 8
Training loss: 0.22592289745807648
Validation loss: 2.037743479013443

Epoch: 5| Step: 9
Training loss: 0.31579485535621643
Validation loss: 2.0331614265839257

Epoch: 5| Step: 10
Training loss: 0.5244972109794617
Validation loss: 2.016505445043246

Epoch: 5| Step: 11
Training loss: 0.3141888380050659
Validation loss: 2.0355747987826667

Epoch: 495| Step: 0
Training loss: 0.22649574279785156
Validation loss: 2.054667204618454

Epoch: 5| Step: 1
Training loss: 0.3159477114677429
Validation loss: 2.02717657883962

Epoch: 5| Step: 2
Training loss: 0.24899645149707794
Validation loss: 2.0413093020518622

Epoch: 5| Step: 3
Training loss: 0.30732688307762146
Validation loss: 2.047712961832682

Epoch: 5| Step: 4
Training loss: 0.16919240355491638
Validation loss: 2.084359029928843

Epoch: 5| Step: 5
Training loss: 0.13778898119926453
Validation loss: 2.031537358959516

Epoch: 5| Step: 6
Training loss: 0.40465736389160156
Validation loss: 2.0654883484045663

Epoch: 5| Step: 7
Training loss: 0.5507097840309143
Validation loss: 2.030019611120224

Epoch: 5| Step: 8
Training loss: 0.3660653531551361
Validation loss: 2.043320725361506

Epoch: 5| Step: 9
Training loss: 0.2986808121204376
Validation loss: 2.034744848807653

Epoch: 5| Step: 10
Training loss: 0.3814955949783325
Validation loss: 2.0161058555046716

Epoch: 5| Step: 11
Training loss: 0.28618139028549194
Validation loss: 2.0345992892980576

Epoch: 496| Step: 0
Training loss: 0.2950049340724945
Validation loss: 2.054869885245959

Epoch: 5| Step: 1
Training loss: 0.2508033514022827
Validation loss: 2.0744450290997825

Epoch: 5| Step: 2
Training loss: 0.35764986276626587
Validation loss: 2.1098653425772986

Epoch: 5| Step: 3
Training loss: 0.2741578221321106
Validation loss: 2.040821904937426

Epoch: 5| Step: 4
Training loss: 0.22054600715637207
Validation loss: 2.033703938126564

Epoch: 5| Step: 5
Training loss: 0.23705562949180603
Validation loss: 2.0480915208657584

Epoch: 5| Step: 6
Training loss: 0.17194920778274536
Validation loss: 2.050528178612391

Epoch: 5| Step: 7
Training loss: 0.5774291157722473
Validation loss: 2.0593390266100564

Epoch: 5| Step: 8
Training loss: 0.3832866847515106
Validation loss: 2.059801052014033

Epoch: 5| Step: 9
Training loss: 0.2869107127189636
Validation loss: 2.041609192887942

Epoch: 5| Step: 10
Training loss: 0.12541979551315308
Validation loss: 2.0922098060448966

Epoch: 5| Step: 11
Training loss: 0.1964065134525299
Validation loss: 2.036501015226046

Epoch: 497| Step: 0
Training loss: 0.3042915463447571
Validation loss: 2.0766305526097617

Epoch: 5| Step: 1
Training loss: 0.27109721302986145
Validation loss: 2.0773846556742988

Epoch: 5| Step: 2
Training loss: 0.3435278534889221
Validation loss: 2.0416672974824905

Epoch: 5| Step: 3
Training loss: 0.2732160687446594
Validation loss: 2.0697053223848343

Epoch: 5| Step: 4
Training loss: 0.25395864248275757
Validation loss: 2.058964158097903

Epoch: 5| Step: 5
Training loss: 0.311442494392395
Validation loss: 2.063670660058657

Epoch: 5| Step: 6
Training loss: 0.4543660283088684
Validation loss: 2.047160545984904

Epoch: 5| Step: 7
Training loss: 0.1781916320323944
Validation loss: 2.0705565263827643

Epoch: 5| Step: 8
Training loss: 0.20184120535850525
Validation loss: 2.0837826629479728

Epoch: 5| Step: 9
Training loss: 0.16904523968696594
Validation loss: 2.0800104637940726

Epoch: 5| Step: 10
Training loss: 0.20375780761241913
Validation loss: 2.0485457430283227

Epoch: 5| Step: 11
Training loss: 0.07572489976882935
Validation loss: 2.061435545484225

Epoch: 498| Step: 0
Training loss: 0.16740934550762177
Validation loss: 2.0429013669490814

Epoch: 5| Step: 1
Training loss: 0.17389866709709167
Validation loss: 2.0576849430799484

Epoch: 5| Step: 2
Training loss: 0.20808467268943787
Validation loss: 2.0471611469984055

Epoch: 5| Step: 3
Training loss: 0.307891309261322
Validation loss: 2.100996712843577

Epoch: 5| Step: 4
Training loss: 0.198385089635849
Validation loss: 2.045752083261808

Epoch: 5| Step: 5
Training loss: 0.40519237518310547
Validation loss: 2.0338385701179504

Epoch: 5| Step: 6
Training loss: 0.4164871573448181
Validation loss: 2.0864491959412894

Epoch: 5| Step: 7
Training loss: 0.19151917099952698
Validation loss: 2.039080331722895

Epoch: 5| Step: 8
Training loss: 0.22886128723621368
Validation loss: 2.056198467810949

Epoch: 5| Step: 9
Training loss: 0.21411089599132538
Validation loss: 2.0394860605398812

Epoch: 5| Step: 10
Training loss: 0.16801002621650696
Validation loss: 2.0408114989598594

Epoch: 5| Step: 11
Training loss: 0.10248219966888428
Validation loss: 2.0556541879971824

Epoch: 499| Step: 0
Training loss: 0.22138747572898865
Validation loss: 2.024192581574122

Epoch: 5| Step: 1
Training loss: 0.4137665331363678
Validation loss: 2.0429794043302536

Epoch: 5| Step: 2
Training loss: 0.2617594599723816
Validation loss: 2.034611905614535

Epoch: 5| Step: 3
Training loss: 0.2829563021659851
Validation loss: 2.058442468444506

Epoch: 5| Step: 4
Training loss: 0.15480276942253113
Validation loss: 2.0546729465325675

Epoch: 5| Step: 5
Training loss: 0.293489545583725
Validation loss: 2.034689580400785

Epoch: 5| Step: 6
Training loss: 0.1745237410068512
Validation loss: 2.0275827745596566

Epoch: 5| Step: 7
Training loss: 0.1572054922580719
Validation loss: 2.0493425826231637

Epoch: 5| Step: 8
Training loss: 0.2175407111644745
Validation loss: 2.0352844099203744

Epoch: 5| Step: 9
Training loss: 0.12341304123401642
Validation loss: 2.049806773662567

Epoch: 5| Step: 10
Training loss: 0.5008200407028198
Validation loss: 2.059568782647451

Epoch: 5| Step: 11
Training loss: 0.13321053981781006
Validation loss: 2.0395448307196298

Epoch: 500| Step: 0
Training loss: 0.249907448887825
Validation loss: 2.019485726952553

Epoch: 5| Step: 1
Training loss: 0.1858455240726471
Validation loss: 2.0463552276293435

Epoch: 5| Step: 2
Training loss: 0.32021382451057434
Validation loss: 2.052632614970207

Epoch: 5| Step: 3
Training loss: 0.44184789061546326
Validation loss: 2.061206673582395

Epoch: 5| Step: 4
Training loss: 0.21073678135871887
Validation loss: 2.027574678262075

Epoch: 5| Step: 5
Training loss: 0.1928137242794037
Validation loss: 2.0923274407784143

Epoch: 5| Step: 6
Training loss: 0.22872118651866913
Validation loss: 2.0549725691477456

Epoch: 5| Step: 7
Training loss: 0.1661636382341385
Validation loss: 2.0612588028113046

Epoch: 5| Step: 8
Training loss: 0.27501365542411804
Validation loss: 2.053481092055639

Epoch: 5| Step: 9
Training loss: 0.1651252806186676
Validation loss: 2.067114363114039

Epoch: 5| Step: 10
Training loss: 0.2205781191587448
Validation loss: 2.047313764691353

Epoch: 5| Step: 11
Training loss: 0.1525253802537918
Validation loss: 2.041229729851087

Epoch: 501| Step: 0
Training loss: 0.18626321852207184
Validation loss: 2.027672906716665

Epoch: 5| Step: 1
Training loss: 0.20904572308063507
Validation loss: 2.065462743242582

Epoch: 5| Step: 2
Training loss: 0.16885152459144592
Validation loss: 2.033200055360794

Epoch: 5| Step: 3
Training loss: 0.1797381341457367
Validation loss: 2.0674874583880105

Epoch: 5| Step: 4
Training loss: 0.2899855077266693
Validation loss: 2.0146070073048272

Epoch: 5| Step: 5
Training loss: 0.20650863647460938
Validation loss: 2.0241791953643165

Epoch: 5| Step: 6
Training loss: 0.21979708969593048
Validation loss: 2.0443657437960305

Epoch: 5| Step: 7
Training loss: 0.2082374542951584
Validation loss: 2.0484753946463266

Epoch: 5| Step: 8
Training loss: 0.531494140625
Validation loss: 2.0579769959052405

Epoch: 5| Step: 9
Training loss: 0.3177110254764557
Validation loss: 2.006157840291659

Epoch: 5| Step: 10
Training loss: 0.30993059277534485
Validation loss: 2.021915818254153

Epoch: 5| Step: 11
Training loss: 0.21884766221046448
Validation loss: 2.0309527268012366

Epoch: 502| Step: 0
Training loss: 0.2917611300945282
Validation loss: 2.049912209312121

Epoch: 5| Step: 1
Training loss: 0.14459547400474548
Validation loss: 2.025117963552475

Epoch: 5| Step: 2
Training loss: 0.4736039638519287
Validation loss: 2.0567369858423867

Epoch: 5| Step: 3
Training loss: 0.2515750527381897
Validation loss: 2.038472836216291

Epoch: 5| Step: 4
Training loss: 0.2749754786491394
Validation loss: 2.0341135760148368

Epoch: 5| Step: 5
Training loss: 0.17633052170276642
Validation loss: 2.0364323556423187

Epoch: 5| Step: 6
Training loss: 0.2984408438205719
Validation loss: 2.038815125823021

Epoch: 5| Step: 7
Training loss: 0.14439328014850616
Validation loss: 2.0526000410318375

Epoch: 5| Step: 8
Training loss: 0.26526710391044617
Validation loss: 2.037385900815328

Epoch: 5| Step: 9
Training loss: 0.22074806690216064
Validation loss: 2.055136109391848

Epoch: 5| Step: 10
Training loss: 0.18369342386722565
Validation loss: 2.018677602211634

Epoch: 5| Step: 11
Training loss: 0.21488964557647705
Validation loss: 2.0536997467279434

Epoch: 503| Step: 0
Training loss: 0.1364203542470932
Validation loss: 2.0250467161337533

Epoch: 5| Step: 1
Training loss: 0.18240907788276672
Validation loss: 2.053058077891668

Epoch: 5| Step: 2
Training loss: 0.47759881615638733
Validation loss: 2.053426822026571

Epoch: 5| Step: 3
Training loss: 0.272935688495636
Validation loss: 2.0596069941918054

Epoch: 5| Step: 4
Training loss: 0.2003587782382965
Validation loss: 2.0758657505114875

Epoch: 5| Step: 5
Training loss: 0.21004550158977509
Validation loss: 2.0432517329851785

Epoch: 5| Step: 6
Training loss: 0.19359977543354034
Validation loss: 2.0797475427389145

Epoch: 5| Step: 7
Training loss: 0.24107666313648224
Validation loss: 2.0295253892739615

Epoch: 5| Step: 8
Training loss: 0.24026063084602356
Validation loss: 2.047835052013397

Epoch: 5| Step: 9
Training loss: 0.17877449095249176
Validation loss: 2.041501611471176

Epoch: 5| Step: 10
Training loss: 0.3704656958580017
Validation loss: 2.0456872383753457

Epoch: 5| Step: 11
Training loss: 0.14386355876922607
Validation loss: 2.058342695236206

Epoch: 504| Step: 0
Training loss: 0.27841824293136597
Validation loss: 2.0247518569231033

Epoch: 5| Step: 1
Training loss: 0.20246127247810364
Validation loss: 2.0527273863554

Epoch: 5| Step: 2
Training loss: 0.27469149231910706
Validation loss: 2.0651678989330926

Epoch: 5| Step: 3
Training loss: 0.22382614016532898
Validation loss: 2.0655507991711297

Epoch: 5| Step: 4
Training loss: 0.6361122131347656
Validation loss: 2.036961237589518

Epoch: 5| Step: 5
Training loss: 0.19055470824241638
Validation loss: 2.0380811045567193

Epoch: 5| Step: 6
Training loss: 0.22403952479362488
Validation loss: 2.043293053905169

Epoch: 5| Step: 7
Training loss: 0.2036662995815277
Validation loss: 2.0506898015737534

Epoch: 5| Step: 8
Training loss: 0.3397732377052307
Validation loss: 2.0567588756481805

Epoch: 5| Step: 9
Training loss: 0.16178646683692932
Validation loss: 2.061036561926206

Epoch: 5| Step: 10
Training loss: 0.24066157639026642
Validation loss: 2.009387488166491

Epoch: 5| Step: 11
Training loss: 0.17493291199207306
Validation loss: 2.078819786508878

Epoch: 505| Step: 0
Training loss: 0.17767134308815002
Validation loss: 2.0555751572052636

Epoch: 5| Step: 1
Training loss: 0.16274769604206085
Validation loss: 2.054868926604589

Epoch: 5| Step: 2
Training loss: 0.2780194878578186
Validation loss: 2.034246489405632

Epoch: 5| Step: 3
Training loss: 0.273806631565094
Validation loss: 2.0654435654481254

Epoch: 5| Step: 4
Training loss: 0.1770389825105667
Validation loss: 2.0454163253307343

Epoch: 5| Step: 5
Training loss: 0.19354531168937683
Validation loss: 2.0649247467517853

Epoch: 5| Step: 6
Training loss: 0.4670736789703369
Validation loss: 2.0526843816041946

Epoch: 5| Step: 7
Training loss: 0.2916186451911926
Validation loss: 2.059846878051758

Epoch: 5| Step: 8
Training loss: 0.1395660936832428
Validation loss: 2.055914575854937

Epoch: 5| Step: 9
Training loss: 0.2883142828941345
Validation loss: 2.0647130409876504

Epoch: 5| Step: 10
Training loss: 0.2382649928331375
Validation loss: 2.089972505966822

Epoch: 5| Step: 11
Training loss: 0.2437942922115326
Validation loss: 2.0831252535184226

Epoch: 506| Step: 0
Training loss: 0.22425198554992676
Validation loss: 2.0545643270015717

Epoch: 5| Step: 1
Training loss: 0.22819705307483673
Validation loss: 2.0589876025915146

Epoch: 5| Step: 2
Training loss: 0.24588747322559357
Validation loss: 2.044998566309611

Epoch: 5| Step: 3
Training loss: 0.2300657480955124
Validation loss: 2.0342750201622644

Epoch: 5| Step: 4
Training loss: 0.23014430701732635
Validation loss: 2.0682606299718223

Epoch: 5| Step: 5
Training loss: 0.28918275237083435
Validation loss: 2.023352106412252

Epoch: 5| Step: 6
Training loss: 0.19859099388122559
Validation loss: 2.0026201804478965

Epoch: 5| Step: 7
Training loss: 0.1947767436504364
Validation loss: 2.036860098441442

Epoch: 5| Step: 8
Training loss: 0.41656988859176636
Validation loss: 2.048491597175598

Epoch: 5| Step: 9
Training loss: 0.21720552444458008
Validation loss: 2.0453564822673798

Epoch: 5| Step: 10
Training loss: 0.14476777613162994
Validation loss: 2.055395315090815

Epoch: 5| Step: 11
Training loss: 0.19752752780914307
Validation loss: 2.0508404274781546

Epoch: 507| Step: 0
Training loss: 0.38891473412513733
Validation loss: 2.044792130589485

Epoch: 5| Step: 1
Training loss: 0.1864696741104126
Validation loss: 2.049349228541056

Epoch: 5| Step: 2
Training loss: 0.10530523210763931
Validation loss: 2.05838210384051

Epoch: 5| Step: 3
Training loss: 0.16418364644050598
Validation loss: 2.0221513509750366

Epoch: 5| Step: 4
Training loss: 0.18315429985523224
Validation loss: 2.0501407931248345

Epoch: 5| Step: 5
Training loss: 0.1753518432378769
Validation loss: 2.06581349670887

Epoch: 5| Step: 6
Training loss: 0.22690877318382263
Validation loss: 2.027779499689738

Epoch: 5| Step: 7
Training loss: 0.3855862617492676
Validation loss: 2.035524914662043

Epoch: 5| Step: 8
Training loss: 0.45996928215026855
Validation loss: 2.0659090677897134

Epoch: 5| Step: 9
Training loss: 0.20024070143699646
Validation loss: 2.0378060042858124

Epoch: 5| Step: 10
Training loss: 0.2005215883255005
Validation loss: 2.0566761642694473

Epoch: 5| Step: 11
Training loss: 0.3836318254470825
Validation loss: 2.0479534367720285

Epoch: 508| Step: 0
Training loss: 0.20240418612957
Validation loss: 2.0770294020573297

Epoch: 5| Step: 1
Training loss: 0.24838122725486755
Validation loss: 2.069099341829618

Epoch: 5| Step: 2
Training loss: 0.16861966252326965
Validation loss: 2.064815198381742

Epoch: 5| Step: 3
Training loss: 0.13922373950481415
Validation loss: 2.0529868602752686

Epoch: 5| Step: 4
Training loss: 0.4253544807434082
Validation loss: 2.086613416671753

Epoch: 5| Step: 5
Training loss: 0.506293535232544
Validation loss: 2.0679214348395667

Epoch: 5| Step: 6
Training loss: 0.2514309883117676
Validation loss: 2.050073822339376

Epoch: 5| Step: 7
Training loss: 0.19686493277549744
Validation loss: 2.053910012046496

Epoch: 5| Step: 8
Training loss: 0.21066853404045105
Validation loss: 2.0408273885647454

Epoch: 5| Step: 9
Training loss: 0.13946834206581116
Validation loss: 2.0361861288547516

Epoch: 5| Step: 10
Training loss: 0.23642897605895996
Validation loss: 2.0545120586951575

Epoch: 5| Step: 11
Training loss: 0.1581404209136963
Validation loss: 2.0760251382986703

Epoch: 509| Step: 0
Training loss: 0.1312064677476883
Validation loss: 2.0469686885674796

Epoch: 5| Step: 1
Training loss: 0.2603427469730377
Validation loss: 2.064930165807406

Epoch: 5| Step: 2
Training loss: 0.5187228918075562
Validation loss: 2.0250230928262076

Epoch: 5| Step: 3
Training loss: 0.17825506627559662
Validation loss: 2.0280356407165527

Epoch: 5| Step: 4
Training loss: 0.1234615296125412
Validation loss: 2.069943775733312

Epoch: 5| Step: 5
Training loss: 0.20361442863941193
Validation loss: 2.019306947787603

Epoch: 5| Step: 6
Training loss: 0.2743934690952301
Validation loss: 2.029283657670021

Epoch: 5| Step: 7
Training loss: 0.24021688103675842
Validation loss: 2.0359673152367272

Epoch: 5| Step: 8
Training loss: 0.18604139983654022
Validation loss: 2.0643648703893027

Epoch: 5| Step: 9
Training loss: 0.16633877158164978
Validation loss: 2.0375722299019494

Epoch: 5| Step: 10
Training loss: 0.3531438410282135
Validation loss: 2.0295871694882712

Epoch: 5| Step: 11
Training loss: 0.28476405143737793
Validation loss: 2.07317907611529

Epoch: 510| Step: 0
Training loss: 0.1605795919895172
Validation loss: 2.047312210003535

Epoch: 5| Step: 1
Training loss: 0.19449546933174133
Validation loss: 2.0484217703342438

Epoch: 5| Step: 2
Training loss: 0.2370360642671585
Validation loss: 2.042556583881378

Epoch: 5| Step: 3
Training loss: 0.21990080177783966
Validation loss: 2.0961513171593347

Epoch: 5| Step: 4
Training loss: 0.25257277488708496
Validation loss: 2.0494471738735833

Epoch: 5| Step: 5
Training loss: 0.4941743314266205
Validation loss: 2.0973980675141015

Epoch: 5| Step: 6
Training loss: 0.23506371676921844
Validation loss: 2.0630756517251334

Epoch: 5| Step: 7
Training loss: 0.2932252883911133
Validation loss: 2.0544433097044625

Epoch: 5| Step: 8
Training loss: 0.29532021284103394
Validation loss: 2.06693301598231

Epoch: 5| Step: 9
Training loss: 0.2532345652580261
Validation loss: 2.052606071035067

Epoch: 5| Step: 10
Training loss: 0.20081141591072083
Validation loss: 2.0640731354554496

Epoch: 5| Step: 11
Training loss: 0.7569291591644287
Validation loss: 2.0463668555021286

Epoch: 511| Step: 0
Training loss: 0.27028191089630127
Validation loss: 2.0408100287119546

Epoch: 5| Step: 1
Training loss: 0.20319929718971252
Validation loss: 2.0400687058766684

Epoch: 5| Step: 2
Training loss: 0.2140926569700241
Validation loss: 2.0715915312369666

Epoch: 5| Step: 3
Training loss: 0.18848197162151337
Validation loss: 2.0769857267538705

Epoch: 5| Step: 4
Training loss: 0.4546700417995453
Validation loss: 2.0381557941436768

Epoch: 5| Step: 5
Training loss: 0.2664739489555359
Validation loss: 2.0509124298890433

Epoch: 5| Step: 6
Training loss: 0.29739347100257874
Validation loss: 2.0605344027280807

Epoch: 5| Step: 7
Training loss: 0.22002799808979034
Validation loss: 2.060442720850309

Epoch: 5| Step: 8
Training loss: 0.24934491515159607
Validation loss: 2.063934251666069

Epoch: 5| Step: 9
Training loss: 0.1769447773694992
Validation loss: 2.046030953526497

Epoch: 5| Step: 10
Training loss: 0.16278782486915588
Validation loss: 2.029355635245641

Epoch: 5| Step: 11
Training loss: 0.16864746809005737
Validation loss: 2.0639394422372184

Epoch: 512| Step: 0
Training loss: 0.5697418451309204
Validation loss: 2.046649545431137

Epoch: 5| Step: 1
Training loss: 0.1666828989982605
Validation loss: 2.075823520620664

Epoch: 5| Step: 2
Training loss: 0.2550828158855438
Validation loss: 2.0561545193195343

Epoch: 5| Step: 3
Training loss: 0.3589027523994446
Validation loss: 2.0320219695568085

Epoch: 5| Step: 4
Training loss: 0.21836547553539276
Validation loss: 2.0233808755874634

Epoch: 5| Step: 5
Training loss: 0.2961884140968323
Validation loss: 2.0388274242480597

Epoch: 5| Step: 6
Training loss: 0.13069020211696625
Validation loss: 2.0558570325374603

Epoch: 5| Step: 7
Training loss: 0.16992537677288055
Validation loss: 2.0761403193076453

Epoch: 5| Step: 8
Training loss: 0.23496440052986145
Validation loss: 2.044724335273107

Epoch: 5| Step: 9
Training loss: 0.233615443110466
Validation loss: 2.063590149084727

Epoch: 5| Step: 10
Training loss: 0.17653648555278778
Validation loss: 2.034653584162394

Epoch: 5| Step: 11
Training loss: 0.16690629720687866
Validation loss: 2.04792890449365

Epoch: 513| Step: 0
Training loss: 0.2065165489912033
Validation loss: 2.023147761821747

Epoch: 5| Step: 1
Training loss: 0.17311027646064758
Validation loss: 2.004847521583239

Epoch: 5| Step: 2
Training loss: 0.4103030562400818
Validation loss: 2.0263257225354514

Epoch: 5| Step: 3
Training loss: 0.2451130896806717
Validation loss: 2.0698767950137458

Epoch: 5| Step: 4
Training loss: 0.35798951983451843
Validation loss: 2.0220177272955575

Epoch: 5| Step: 5
Training loss: 0.22033986449241638
Validation loss: 2.016337881485621

Epoch: 5| Step: 6
Training loss: 0.14366886019706726
Validation loss: 2.048705463608106

Epoch: 5| Step: 7
Training loss: 0.2885687053203583
Validation loss: 2.074437235792478

Epoch: 5| Step: 8
Training loss: 0.22367680072784424
Validation loss: 2.0759912033875785

Epoch: 5| Step: 9
Training loss: 0.22832171618938446
Validation loss: 2.0818577210108438

Epoch: 5| Step: 10
Training loss: 0.504665732383728
Validation loss: 2.068245008587837

Epoch: 5| Step: 11
Training loss: 0.32213467359542847
Validation loss: 2.076002856095632

Epoch: 514| Step: 0
Training loss: 0.1757676601409912
Validation loss: 2.0419426461060843

Epoch: 5| Step: 1
Training loss: 0.5196002721786499
Validation loss: 2.0496009588241577

Epoch: 5| Step: 2
Training loss: 0.2940100431442261
Validation loss: 2.0500095089276633

Epoch: 5| Step: 3
Training loss: 0.19074979424476624
Validation loss: 2.075109193722407

Epoch: 5| Step: 4
Training loss: 0.23564374446868896
Validation loss: 2.020835349957148

Epoch: 5| Step: 5
Training loss: 0.17909224331378937
Validation loss: 2.0437011371056237

Epoch: 5| Step: 6
Training loss: 0.3532719314098358
Validation loss: 2.041839763522148

Epoch: 5| Step: 7
Training loss: 0.27114930748939514
Validation loss: 2.001135841012001

Epoch: 5| Step: 8
Training loss: 0.18354029953479767
Validation loss: 2.0395345240831375

Epoch: 5| Step: 9
Training loss: 0.19476886093616486
Validation loss: 2.0704533557097116

Epoch: 5| Step: 10
Training loss: 0.1124563217163086
Validation loss: 2.0084135880072913

Epoch: 5| Step: 11
Training loss: 0.3547642230987549
Validation loss: 2.006149098277092

Epoch: 515| Step: 0
Training loss: 0.5067494511604309
Validation loss: 2.0563865999380746

Epoch: 5| Step: 1
Training loss: 0.2888888716697693
Validation loss: 2.0822486827770867

Epoch: 5| Step: 2
Training loss: 0.20283731818199158
Validation loss: 2.093522926171621

Epoch: 5| Step: 3
Training loss: 0.1673698127269745
Validation loss: 2.078407655159632

Epoch: 5| Step: 4
Training loss: 0.24673013389110565
Validation loss: 2.010508139928182

Epoch: 5| Step: 5
Training loss: 0.2610244154930115
Validation loss: 2.0328999112049737

Epoch: 5| Step: 6
Training loss: 0.2550751864910126
Validation loss: 2.0530515809853873

Epoch: 5| Step: 7
Training loss: 0.19628457725048065
Validation loss: 2.0662723580996194

Epoch: 5| Step: 8
Training loss: 0.1588253527879715
Validation loss: 2.0472598175207772

Epoch: 5| Step: 9
Training loss: 0.12554535269737244
Validation loss: 2.0486199259757996

Epoch: 5| Step: 10
Training loss: 0.25947755575180054
Validation loss: 2.0333162347475686

Epoch: 5| Step: 11
Training loss: 0.12898339331150055
Validation loss: 2.033527205387751

Epoch: 516| Step: 0
Training loss: 0.2516228258609772
Validation loss: 2.0623828073342643

Epoch: 5| Step: 1
Training loss: 0.173405721783638
Validation loss: 2.0433548390865326

Epoch: 5| Step: 2
Training loss: 0.23238742351531982
Validation loss: 2.0593759616216025

Epoch: 5| Step: 3
Training loss: 0.4609307646751404
Validation loss: 2.0852603713671365

Epoch: 5| Step: 4
Training loss: 0.19592396914958954
Validation loss: 2.0507755925258

Epoch: 5| Step: 5
Training loss: 0.1377878487110138
Validation loss: 2.040324072043101

Epoch: 5| Step: 6
Training loss: 0.2569954991340637
Validation loss: 2.0576817144950232

Epoch: 5| Step: 7
Training loss: 0.19965043663978577
Validation loss: 2.0122035145759583

Epoch: 5| Step: 8
Training loss: 0.1855374574661255
Validation loss: 2.0414533615112305

Epoch: 5| Step: 9
Training loss: 0.24227266013622284
Validation loss: 2.069387118021647

Epoch: 5| Step: 10
Training loss: 0.15958237648010254
Validation loss: 2.0888794163862863

Epoch: 5| Step: 11
Training loss: 0.14447921514511108
Validation loss: 2.0477831065654755

Epoch: 517| Step: 0
Training loss: 0.19442179799079895
Validation loss: 2.0635124196608863

Epoch: 5| Step: 1
Training loss: 0.22644242644309998
Validation loss: 2.1029001573721566

Epoch: 5| Step: 2
Training loss: 0.1844516396522522
Validation loss: 2.048906698822975

Epoch: 5| Step: 3
Training loss: 0.2954716384410858
Validation loss: 2.0418242464462915

Epoch: 5| Step: 4
Training loss: 0.18795336782932281
Validation loss: 2.0719636380672455

Epoch: 5| Step: 5
Training loss: 0.24696609377861023
Validation loss: 2.0659512976805368

Epoch: 5| Step: 6
Training loss: 0.21106286346912384
Validation loss: 2.053474252422651

Epoch: 5| Step: 7
Training loss: 0.23319995403289795
Validation loss: 2.0299205432335534

Epoch: 5| Step: 8
Training loss: 0.46288102865219116
Validation loss: 2.0536673863728843

Epoch: 5| Step: 9
Training loss: 0.2661975920200348
Validation loss: 2.0256789376338324

Epoch: 5| Step: 10
Training loss: 0.24347682297229767
Validation loss: 2.053404991825422

Epoch: 5| Step: 11
Training loss: 0.13305425643920898
Validation loss: 2.074195057153702

Epoch: 518| Step: 0
Training loss: 0.200367733836174
Validation loss: 2.024423440297445

Epoch: 5| Step: 1
Training loss: 0.19841119647026062
Validation loss: 2.0512920916080475

Epoch: 5| Step: 2
Training loss: 0.44845685362815857
Validation loss: 2.0505136797825494

Epoch: 5| Step: 3
Training loss: 0.19854781031608582
Validation loss: 2.040162980556488

Epoch: 5| Step: 4
Training loss: 0.21534991264343262
Validation loss: 2.041694790124893

Epoch: 5| Step: 5
Training loss: 0.1795407086610794
Validation loss: 2.0156066715717316

Epoch: 5| Step: 6
Training loss: 0.1665615737438202
Validation loss: 2.0370095521211624

Epoch: 5| Step: 7
Training loss: 0.21734976768493652
Validation loss: 2.056764394044876

Epoch: 5| Step: 8
Training loss: 0.24177026748657227
Validation loss: 2.079186404744784

Epoch: 5| Step: 9
Training loss: 0.19158461689949036
Validation loss: 2.080348938703537

Epoch: 5| Step: 10
Training loss: 0.16799232363700867
Validation loss: 2.0322900215784707

Epoch: 5| Step: 11
Training loss: 0.45779258012771606
Validation loss: 2.0633085320393243

Epoch: 519| Step: 0
Training loss: 0.15883532166481018
Validation loss: 2.0380924195051193

Epoch: 5| Step: 1
Training loss: 0.2021971195936203
Validation loss: 2.060034150878588

Epoch: 5| Step: 2
Training loss: 0.5206351280212402
Validation loss: 2.01398533085982

Epoch: 5| Step: 3
Training loss: 0.236343652009964
Validation loss: 1.9989029218753178

Epoch: 5| Step: 4
Training loss: 0.2257348597049713
Validation loss: 2.065848231315613

Epoch: 5| Step: 5
Training loss: 0.35118499398231506
Validation loss: 2.0260511140028634

Epoch: 5| Step: 6
Training loss: 0.2540605664253235
Validation loss: 2.1073737492163978

Epoch: 5| Step: 7
Training loss: 0.33251893520355225
Validation loss: 2.0609344244003296

Epoch: 5| Step: 8
Training loss: 0.2341863214969635
Validation loss: 2.027579660216967

Epoch: 5| Step: 9
Training loss: 0.17513258755207062
Validation loss: 2.039949268102646

Epoch: 5| Step: 10
Training loss: 0.16135120391845703
Validation loss: 2.0731186320384345

Epoch: 5| Step: 11
Training loss: 0.09239047765731812
Validation loss: 2.0742163012425103

Epoch: 520| Step: 0
Training loss: 0.16284868121147156
Validation loss: 2.057809829711914

Epoch: 5| Step: 1
Training loss: 0.24513788521289825
Validation loss: 2.036000207066536

Epoch: 5| Step: 2
Training loss: 0.3109196722507477
Validation loss: 2.023489241798719

Epoch: 5| Step: 3
Training loss: 0.17024031281471252
Validation loss: 2.068564216295878

Epoch: 5| Step: 4
Training loss: 0.2321043759584427
Validation loss: 2.033619463443756

Epoch: 5| Step: 5
Training loss: 0.10116977989673615
Validation loss: 2.0427743246157966

Epoch: 5| Step: 6
Training loss: 0.20483943819999695
Validation loss: 2.0678966293732324

Epoch: 5| Step: 7
Training loss: 0.1726178228855133
Validation loss: 2.0573646078507104

Epoch: 5| Step: 8
Training loss: 0.19887536764144897
Validation loss: 2.072505161166191

Epoch: 5| Step: 9
Training loss: 0.25780901312828064
Validation loss: 2.083015958468119

Epoch: 5| Step: 10
Training loss: 0.6076925992965698
Validation loss: 2.0438333402077355

Epoch: 5| Step: 11
Training loss: 0.12918007373809814
Validation loss: 2.0346854279438653

Epoch: 521| Step: 0
Training loss: 0.2326461374759674
Validation loss: 2.0445791631937027

Epoch: 5| Step: 1
Training loss: 0.3233562111854553
Validation loss: 2.0451463013887405

Epoch: 5| Step: 2
Training loss: 0.2017398178577423
Validation loss: 2.067718207836151

Epoch: 5| Step: 3
Training loss: 0.2961772084236145
Validation loss: 2.0274636894464493

Epoch: 5| Step: 4
Training loss: 0.20552530884742737
Validation loss: 2.0129521091779075

Epoch: 5| Step: 5
Training loss: 0.4267329275608063
Validation loss: 2.040072818597158

Epoch: 5| Step: 6
Training loss: 0.22591371834278107
Validation loss: 2.0290367007255554

Epoch: 5| Step: 7
Training loss: 0.17107275128364563
Validation loss: 2.0310248782237372

Epoch: 5| Step: 8
Training loss: 0.19449098408222198
Validation loss: 2.010451222459475

Epoch: 5| Step: 9
Training loss: 0.29432687163352966
Validation loss: 2.070219506820043

Epoch: 5| Step: 10
Training loss: 0.16175146400928497
Validation loss: 2.072294811407725

Epoch: 5| Step: 11
Training loss: 0.17781293392181396
Validation loss: 2.0431796262661615

Epoch: 522| Step: 0
Training loss: 0.2038065493106842
Validation loss: 2.079328238964081

Epoch: 5| Step: 1
Training loss: 0.12495549023151398
Validation loss: 2.0334898432095847

Epoch: 5| Step: 2
Training loss: 0.22334246337413788
Validation loss: 2.074031502008438

Epoch: 5| Step: 3
Training loss: 0.36609798669815063
Validation loss: 2.094559594988823

Epoch: 5| Step: 4
Training loss: 0.32514381408691406
Validation loss: 2.0526331812143326

Epoch: 5| Step: 5
Training loss: 0.2286292016506195
Validation loss: 2.1080489257971444

Epoch: 5| Step: 6
Training loss: 0.24364395439624786
Validation loss: 2.068474287788073

Epoch: 5| Step: 7
Training loss: 0.21745817363262177
Validation loss: 2.060640831788381

Epoch: 5| Step: 8
Training loss: 0.22373107075691223
Validation loss: 2.0457144528627396

Epoch: 5| Step: 9
Training loss: 0.269133985042572
Validation loss: 2.09504642089208

Epoch: 5| Step: 10
Training loss: 0.4883086085319519
Validation loss: 2.0955244998137155

Epoch: 5| Step: 11
Training loss: 0.35674870014190674
Validation loss: 2.0864378412564597

Epoch: 523| Step: 0
Training loss: 0.19638113677501678
Validation loss: 2.0972671757141748

Epoch: 5| Step: 1
Training loss: 0.3468135595321655
Validation loss: 2.0468916843334832

Epoch: 5| Step: 2
Training loss: 0.22013401985168457
Validation loss: 2.0916036119063697

Epoch: 5| Step: 3
Training loss: 0.45196181535720825
Validation loss: 2.0505794882774353

Epoch: 5| Step: 4
Training loss: 0.15925860404968262
Validation loss: 2.0818003167708716

Epoch: 5| Step: 5
Training loss: 0.18135018646717072
Validation loss: 2.0296148558457694

Epoch: 5| Step: 6
Training loss: 0.1946665495634079
Validation loss: 2.0663024385770163

Epoch: 5| Step: 7
Training loss: 0.19724856317043304
Validation loss: 2.0508321772019067

Epoch: 5| Step: 8
Training loss: 0.16341575980186462
Validation loss: 2.0460490783055625

Epoch: 5| Step: 9
Training loss: 0.25825339555740356
Validation loss: 2.079368477066358

Epoch: 5| Step: 10
Training loss: 0.29729777574539185
Validation loss: 2.0727731585502625

Epoch: 5| Step: 11
Training loss: 0.24252426624298096
Validation loss: 2.0260829279820123

Epoch: 524| Step: 0
Training loss: 0.17914029955863953
Validation loss: 2.0870398183663688

Epoch: 5| Step: 1
Training loss: 0.3524024188518524
Validation loss: 2.0714967399835587

Epoch: 5| Step: 2
Training loss: 0.3687151074409485
Validation loss: 2.066054339210192

Epoch: 5| Step: 3
Training loss: 0.19898991286754608
Validation loss: 2.0609935373067856

Epoch: 5| Step: 4
Training loss: 0.23331113159656525
Validation loss: 2.0234039773543677

Epoch: 5| Step: 5
Training loss: 0.18308958411216736
Validation loss: 2.040713166197141

Epoch: 5| Step: 6
Training loss: 0.1804361492395401
Validation loss: 2.072808489203453

Epoch: 5| Step: 7
Training loss: 0.1541503220796585
Validation loss: 2.007115826010704

Epoch: 5| Step: 8
Training loss: 0.21936137974262238
Validation loss: 2.040074442823728

Epoch: 5| Step: 9
Training loss: 0.23867793381214142
Validation loss: 2.038247217734655

Epoch: 5| Step: 10
Training loss: 0.48526477813720703
Validation loss: 2.018334304292997

Epoch: 5| Step: 11
Training loss: 0.05643415451049805
Validation loss: 2.025412787993749

Epoch: 525| Step: 0
Training loss: 0.2587626576423645
Validation loss: 2.0292239437500634

Epoch: 5| Step: 1
Training loss: 0.44700759649276733
Validation loss: 2.039056604107221

Epoch: 5| Step: 2
Training loss: 0.1669139564037323
Validation loss: 2.046998699506124

Epoch: 5| Step: 3
Training loss: 0.15332189202308655
Validation loss: 2.044294868906339

Epoch: 5| Step: 4
Training loss: 0.22368326783180237
Validation loss: 2.0299740384022393

Epoch: 5| Step: 5
Training loss: 0.19422319531440735
Validation loss: 2.039694348971049

Epoch: 5| Step: 6
Training loss: 0.21640801429748535
Validation loss: 2.072794407606125

Epoch: 5| Step: 7
Training loss: 0.29831117391586304
Validation loss: 2.041489690542221

Epoch: 5| Step: 8
Training loss: 0.3076392412185669
Validation loss: 2.048394044240316

Epoch: 5| Step: 9
Training loss: 0.23748306930065155
Validation loss: 2.0612616886695228

Epoch: 5| Step: 10
Training loss: 0.21408681571483612
Validation loss: 2.0542046576738358

Epoch: 5| Step: 11
Training loss: 0.3029552102088928
Validation loss: 2.071078951160113

Epoch: 526| Step: 0
Training loss: 0.1145506277680397
Validation loss: 2.0465414772431054

Epoch: 5| Step: 1
Training loss: 0.19392576813697815
Validation loss: 2.0294403384129205

Epoch: 5| Step: 2
Training loss: 0.27289849519729614
Validation loss: 2.0355388621489205

Epoch: 5| Step: 3
Training loss: 0.3529869019985199
Validation loss: 2.0275081197420755

Epoch: 5| Step: 4
Training loss: 0.23047380149364471
Validation loss: 2.071344236532847

Epoch: 5| Step: 5
Training loss: 0.1217307597398758
Validation loss: 2.0442894796530404

Epoch: 5| Step: 6
Training loss: 0.14824242889881134
Validation loss: 2.060048128167788

Epoch: 5| Step: 7
Training loss: 0.15250709652900696
Validation loss: 2.0304916352033615

Epoch: 5| Step: 8
Training loss: 0.4836711883544922
Validation loss: 2.0489253302415213

Epoch: 5| Step: 9
Training loss: 0.2615998387336731
Validation loss: 2.0547502438227334

Epoch: 5| Step: 10
Training loss: 0.21143774688243866
Validation loss: 2.04724628229936

Epoch: 5| Step: 11
Training loss: 0.20909756422042847
Validation loss: 2.061677942673365

Epoch: 527| Step: 0
Training loss: 0.6318680047988892
Validation loss: 2.0375163604815802

Epoch: 5| Step: 1
Training loss: 0.18988193571567535
Validation loss: 2.0565962940454483

Epoch: 5| Step: 2
Training loss: 0.15847235918045044
Validation loss: 2.0471220711867013

Epoch: 5| Step: 3
Training loss: 0.1911686658859253
Validation loss: 2.1053675214449563

Epoch: 5| Step: 4
Training loss: 0.17081817984580994
Validation loss: 2.0910477489233017

Epoch: 5| Step: 5
Training loss: 0.22506467998027802
Validation loss: 2.0437198082605996

Epoch: 5| Step: 6
Training loss: 0.223486989736557
Validation loss: 2.0597567657629647

Epoch: 5| Step: 7
Training loss: 0.23016560077667236
Validation loss: 2.0393694738547006

Epoch: 5| Step: 8
Training loss: 0.22367215156555176
Validation loss: 2.0425668011109033

Epoch: 5| Step: 9
Training loss: 0.24199309945106506
Validation loss: 2.0424052278200784

Epoch: 5| Step: 10
Training loss: 0.35145407915115356
Validation loss: 2.0509807020425797

Epoch: 5| Step: 11
Training loss: 0.16208040714263916
Validation loss: 2.0435670018196106

Epoch: 528| Step: 0
Training loss: 0.17619766294956207
Validation loss: 2.053135871887207

Epoch: 5| Step: 1
Training loss: 0.16946934163570404
Validation loss: 2.037900244196256

Epoch: 5| Step: 2
Training loss: 0.24570083618164062
Validation loss: 2.0654020806153617

Epoch: 5| Step: 3
Training loss: 0.45270633697509766
Validation loss: 2.023361692825953

Epoch: 5| Step: 4
Training loss: 0.16356568038463593
Validation loss: 2.069225162267685

Epoch: 5| Step: 5
Training loss: 0.29355570673942566
Validation loss: 2.0390721013148627

Epoch: 5| Step: 6
Training loss: 0.18798992037773132
Validation loss: 2.0291318545738855

Epoch: 5| Step: 7
Training loss: 0.2821525037288666
Validation loss: 2.0351701180140176

Epoch: 5| Step: 8
Training loss: 0.18119169771671295
Validation loss: 2.0674663186073303

Epoch: 5| Step: 9
Training loss: 0.24681873619556427
Validation loss: 2.0539714048306146

Epoch: 5| Step: 10
Training loss: 0.22226731479167938
Validation loss: 2.063243418931961

Epoch: 5| Step: 11
Training loss: 0.20617711544036865
Validation loss: 2.0428219189246497

Epoch: 529| Step: 0
Training loss: 0.1798752099275589
Validation loss: 2.020232011874517

Epoch: 5| Step: 1
Training loss: 0.1798262894153595
Validation loss: 2.0158601154883704

Epoch: 5| Step: 2
Training loss: 0.15776877105236053
Validation loss: 2.0494282841682434

Epoch: 5| Step: 3
Training loss: 0.3711041510105133
Validation loss: 2.056364585955938

Epoch: 5| Step: 4
Training loss: 0.17113643884658813
Validation loss: 2.044877588748932

Epoch: 5| Step: 5
Training loss: 0.2227143496274948
Validation loss: 2.0673106809457145

Epoch: 5| Step: 6
Training loss: 0.2756783664226532
Validation loss: 2.0366342465082803

Epoch: 5| Step: 7
Training loss: 0.42389577627182007
Validation loss: 2.042520061135292

Epoch: 5| Step: 8
Training loss: 0.18876667320728302
Validation loss: 2.0040411402781806

Epoch: 5| Step: 9
Training loss: 0.1954871267080307
Validation loss: 2.04479027291139

Epoch: 5| Step: 10
Training loss: 0.15406900644302368
Validation loss: 2.0566711127758026

Epoch: 5| Step: 11
Training loss: 0.1718360185623169
Validation loss: 2.07023919125398

Epoch: 530| Step: 0
Training loss: 0.21524524688720703
Validation loss: 2.0608380337556205

Epoch: 5| Step: 1
Training loss: 0.5884112119674683
Validation loss: 2.034610981742541

Epoch: 5| Step: 2
Training loss: 0.19742460548877716
Validation loss: 2.051870842774709

Epoch: 5| Step: 3
Training loss: 0.3499087393283844
Validation loss: 2.0386976301670074

Epoch: 5| Step: 4
Training loss: 0.21951785683631897
Validation loss: 2.048794532815615

Epoch: 5| Step: 5
Training loss: 0.20636644959449768
Validation loss: 2.058009053270022

Epoch: 5| Step: 6
Training loss: 0.24328339099884033
Validation loss: 2.0616221725940704

Epoch: 5| Step: 7
Training loss: 0.19769835472106934
Validation loss: 2.0325323790311813

Epoch: 5| Step: 8
Training loss: 0.1918337345123291
Validation loss: 2.064337114493052

Epoch: 5| Step: 9
Training loss: 0.2735748887062073
Validation loss: 2.061885525782903

Epoch: 5| Step: 10
Training loss: 0.25010672211647034
Validation loss: 2.0030206441879272

Epoch: 5| Step: 11
Training loss: 0.17037327587604523
Validation loss: 2.0367450614770255

Epoch: 531| Step: 0
Training loss: 0.33887553215026855
Validation loss: 2.0544914255539575

Epoch: 5| Step: 1
Training loss: 0.263255774974823
Validation loss: 2.0565412590901055

Epoch: 5| Step: 2
Training loss: 0.226490780711174
Validation loss: 2.0462135871251426

Epoch: 5| Step: 3
Training loss: 0.1981554627418518
Validation loss: 2.0405774464209876

Epoch: 5| Step: 4
Training loss: 0.1420774608850479
Validation loss: 2.0626049041748047

Epoch: 5| Step: 5
Training loss: 0.19474825263023376
Validation loss: 2.0086771150430045

Epoch: 5| Step: 6
Training loss: 0.22572609782218933
Validation loss: 2.0188908775647483

Epoch: 5| Step: 7
Training loss: 0.17360122501850128
Validation loss: 2.05976993838946

Epoch: 5| Step: 8
Training loss: 0.17633739113807678
Validation loss: 2.0372438728809357

Epoch: 5| Step: 9
Training loss: 0.4568718373775482
Validation loss: 2.036798670887947

Epoch: 5| Step: 10
Training loss: 0.3008634150028229
Validation loss: 2.051089346408844

Epoch: 5| Step: 11
Training loss: 0.20899975299835205
Validation loss: 2.0299041916926703

Epoch: 532| Step: 0
Training loss: 0.11072783172130585
Validation loss: 2.0478784640630088

Epoch: 5| Step: 1
Training loss: 0.17323020100593567
Validation loss: 2.0238856921593347

Epoch: 5| Step: 2
Training loss: 0.20746049284934998
Validation loss: 2.094455301761627

Epoch: 5| Step: 3
Training loss: 0.18565605580806732
Validation loss: 2.0613383750120797

Epoch: 5| Step: 4
Training loss: 0.48196935653686523
Validation loss: 2.06696488459905

Epoch: 5| Step: 5
Training loss: 0.23036420345306396
Validation loss: 2.0857168237368264

Epoch: 5| Step: 6
Training loss: 0.2581329345703125
Validation loss: 2.026878774166107

Epoch: 5| Step: 7
Training loss: 0.17347964644432068
Validation loss: 2.0322090884049735

Epoch: 5| Step: 8
Training loss: 0.28879788517951965
Validation loss: 2.0366219182809195

Epoch: 5| Step: 9
Training loss: 0.31856173276901245
Validation loss: 2.057726557056109

Epoch: 5| Step: 10
Training loss: 0.17028751969337463
Validation loss: 1.9980514099200566

Epoch: 5| Step: 11
Training loss: 0.15757083892822266
Validation loss: 2.0711473723252616

Epoch: 533| Step: 0
Training loss: 0.1545737087726593
Validation loss: 2.0400120417277017

Epoch: 5| Step: 1
Training loss: 0.1494373083114624
Validation loss: 2.030567099650701

Epoch: 5| Step: 2
Training loss: 0.24463224411010742
Validation loss: 2.0488764444986978

Epoch: 5| Step: 3
Training loss: 0.13734698295593262
Validation loss: 2.048465609550476

Epoch: 5| Step: 4
Training loss: 0.201984241604805
Validation loss: 2.0412916938463845

Epoch: 5| Step: 5
Training loss: 0.27622902393341064
Validation loss: 2.055822417140007

Epoch: 5| Step: 6
Training loss: 0.13179153203964233
Validation loss: 2.069061910112699

Epoch: 5| Step: 7
Training loss: 0.35048454999923706
Validation loss: 2.0747972329457602

Epoch: 5| Step: 8
Training loss: 0.14195743203163147
Validation loss: 2.080263684193293

Epoch: 5| Step: 9
Training loss: 0.21003195643424988
Validation loss: 2.043687184651693

Epoch: 5| Step: 10
Training loss: 0.5312719941139221
Validation loss: 2.0975222140550613

Epoch: 5| Step: 11
Training loss: 0.20515406131744385
Validation loss: 2.0642521927754083

Epoch: 534| Step: 0
Training loss: 0.2547481060028076
Validation loss: 2.0444738964239755

Epoch: 5| Step: 1
Training loss: 0.23726224899291992
Validation loss: 2.0549769600232444

Epoch: 5| Step: 2
Training loss: 0.1314329206943512
Validation loss: 2.0402936041355133

Epoch: 5| Step: 3
Training loss: 0.33017855882644653
Validation loss: 2.0372247795263925

Epoch: 5| Step: 4
Training loss: 0.19166535139083862
Validation loss: 2.0287767251332602

Epoch: 5| Step: 5
Training loss: 0.22493354976177216
Validation loss: 2.065051034092903

Epoch: 5| Step: 6
Training loss: 0.19776551425457
Validation loss: 2.0361118217309317

Epoch: 5| Step: 7
Training loss: 0.13720911741256714
Validation loss: 2.0723894983530045

Epoch: 5| Step: 8
Training loss: 0.3028934895992279
Validation loss: 2.029051582018534

Epoch: 5| Step: 9
Training loss: 0.4945007264614105
Validation loss: 2.063164601723353

Epoch: 5| Step: 10
Training loss: 0.167618066072464
Validation loss: 2.0199883182843528

Epoch: 5| Step: 11
Training loss: 0.1576688289642334
Validation loss: 2.0949599891901016

Epoch: 535| Step: 0
Training loss: 0.26897236704826355
Validation loss: 2.054702306787173

Epoch: 5| Step: 1
Training loss: 0.2270597219467163
Validation loss: 2.070692295829455

Epoch: 5| Step: 2
Training loss: 0.1881447732448578
Validation loss: 2.056163042783737

Epoch: 5| Step: 3
Training loss: 0.24830718338489532
Validation loss: 2.0540831287701926

Epoch: 5| Step: 4
Training loss: 0.17662730813026428
Validation loss: 2.05595755080382

Epoch: 5| Step: 5
Training loss: 0.16740331053733826
Validation loss: 2.0495814432700477

Epoch: 5| Step: 6
Training loss: 0.3924967050552368
Validation loss: 2.0754293352365494

Epoch: 5| Step: 7
Training loss: 0.18284527957439423
Validation loss: 2.064272170265516

Epoch: 5| Step: 8
Training loss: 0.551735520362854
Validation loss: 2.049916923046112

Epoch: 5| Step: 9
Training loss: 0.2246284931898117
Validation loss: 2.0775046596924462

Epoch: 5| Step: 10
Training loss: 0.18821486830711365
Validation loss: 2.0328713059425354

Epoch: 5| Step: 11
Training loss: 0.19890281558036804
Validation loss: 2.0294435123602548

Epoch: 536| Step: 0
Training loss: 0.33587130904197693
Validation loss: 2.036526838938395

Epoch: 5| Step: 1
Training loss: 0.4582758843898773
Validation loss: 2.037749449412028

Epoch: 5| Step: 2
Training loss: 0.20890268683433533
Validation loss: 2.0546908924976983

Epoch: 5| Step: 3
Training loss: 0.23652271926403046
Validation loss: 2.0746700117985406

Epoch: 5| Step: 4
Training loss: 0.176660418510437
Validation loss: 2.036148597796758

Epoch: 5| Step: 5
Training loss: 0.16171877086162567
Validation loss: 2.0398333768049874

Epoch: 5| Step: 6
Training loss: 0.23803512752056122
Validation loss: 2.058627019325892

Epoch: 5| Step: 7
Training loss: 0.3075559437274933
Validation loss: 2.072254796822866

Epoch: 5| Step: 8
Training loss: 0.16407719254493713
Validation loss: 2.0674902896086373

Epoch: 5| Step: 9
Training loss: 0.21944460272789001
Validation loss: 2.0196361988782883

Epoch: 5| Step: 10
Training loss: 0.14210061728954315
Validation loss: 2.0644413083791733

Epoch: 5| Step: 11
Training loss: 0.11149466037750244
Validation loss: 2.0433393120765686

Epoch: 537| Step: 0
Training loss: 0.1202758327126503
Validation loss: 2.0597090671459832

Epoch: 5| Step: 1
Training loss: 0.21210721135139465
Validation loss: 2.0562622596820197

Epoch: 5| Step: 2
Training loss: 0.33723825216293335
Validation loss: 2.071323494116465

Epoch: 5| Step: 3
Training loss: 0.22631926834583282
Validation loss: 2.0517140924930573

Epoch: 5| Step: 4
Training loss: 0.18571153283119202
Validation loss: 2.034709095954895

Epoch: 5| Step: 5
Training loss: 0.19638609886169434
Validation loss: 2.063741465409597

Epoch: 5| Step: 6
Training loss: 0.4244367182254791
Validation loss: 2.046793674429258

Epoch: 5| Step: 7
Training loss: 0.22040407359600067
Validation loss: 2.060926695664724

Epoch: 5| Step: 8
Training loss: 0.17467822134494781
Validation loss: 2.04175133506457

Epoch: 5| Step: 9
Training loss: 0.2059999406337738
Validation loss: 2.0567451119422913

Epoch: 5| Step: 10
Training loss: 0.20199236273765564
Validation loss: 2.0639601349830627

Epoch: 5| Step: 11
Training loss: 0.7028597593307495
Validation loss: 2.070921838283539

Epoch: 538| Step: 0
Training loss: 0.26801300048828125
Validation loss: 2.0690917571385703

Epoch: 5| Step: 1
Training loss: 0.18549996614456177
Validation loss: 2.0587052752574286

Epoch: 5| Step: 2
Training loss: 0.3435909152030945
Validation loss: 2.0417782217264175

Epoch: 5| Step: 3
Training loss: 0.48411473631858826
Validation loss: 2.0409908990065255

Epoch: 5| Step: 4
Training loss: 0.16528251767158508
Validation loss: 2.052432134747505

Epoch: 5| Step: 5
Training loss: 0.2942579388618469
Validation loss: 2.047668218612671

Epoch: 5| Step: 6
Training loss: 0.211188405752182
Validation loss: 2.0720916787783303

Epoch: 5| Step: 7
Training loss: 0.2032492607831955
Validation loss: 2.049461101492246

Epoch: 5| Step: 8
Training loss: 0.22296854853630066
Validation loss: 2.044835865497589

Epoch: 5| Step: 9
Training loss: 0.1734474152326584
Validation loss: 2.051981935898463

Epoch: 5| Step: 10
Training loss: 0.25544023513793945
Validation loss: 2.066277946035067

Epoch: 5| Step: 11
Training loss: 0.4040650725364685
Validation loss: 2.073184683918953

Epoch: 539| Step: 0
Training loss: 0.1675969809293747
Validation loss: 2.0592571596304574

Epoch: 5| Step: 1
Training loss: 0.2757004201412201
Validation loss: 2.0650007824103036

Epoch: 5| Step: 2
Training loss: 0.22548992931842804
Validation loss: 2.024582842985789

Epoch: 5| Step: 3
Training loss: 0.1791013777256012
Validation loss: 2.0520516435305276

Epoch: 5| Step: 4
Training loss: 0.48121556639671326
Validation loss: 2.0214588046073914

Epoch: 5| Step: 5
Training loss: 0.11098277568817139
Validation loss: 2.0183092852433524

Epoch: 5| Step: 6
Training loss: 0.21182003617286682
Validation loss: 2.01744977136453

Epoch: 5| Step: 7
Training loss: 0.242594912648201
Validation loss: 2.024315426747004

Epoch: 5| Step: 8
Training loss: 0.19311726093292236
Validation loss: 2.03367147843043

Epoch: 5| Step: 9
Training loss: 0.33875423669815063
Validation loss: 2.028439233700434

Epoch: 5| Step: 10
Training loss: 0.20343844592571259
Validation loss: 2.0423458268245063

Epoch: 5| Step: 11
Training loss: 0.24105960130691528
Validation loss: 2.02957151333491

Epoch: 540| Step: 0
Training loss: 0.1866457313299179
Validation loss: 2.0394278516372046

Epoch: 5| Step: 1
Training loss: 0.2750662863254547
Validation loss: 2.039228543639183

Epoch: 5| Step: 2
Training loss: 0.17196552455425262
Validation loss: 2.0351093212763467

Epoch: 5| Step: 3
Training loss: 0.25834688544273376
Validation loss: 2.059056212504705

Epoch: 5| Step: 4
Training loss: 0.2314162701368332
Validation loss: 2.0574971735477448

Epoch: 5| Step: 5
Training loss: 0.23447923362255096
Validation loss: 2.067919835448265

Epoch: 5| Step: 6
Training loss: 0.24099500477313995
Validation loss: 2.0454651365677514

Epoch: 5| Step: 7
Training loss: 0.18027035892009735
Validation loss: 2.0483348121245704

Epoch: 5| Step: 8
Training loss: 0.1866922229528427
Validation loss: 2.0403894831736884

Epoch: 5| Step: 9
Training loss: 0.22990712523460388
Validation loss: 2.065920223792394

Epoch: 5| Step: 10
Training loss: 0.3940882682800293
Validation loss: 2.0556086897850037

Epoch: 5| Step: 11
Training loss: 0.19493383169174194
Validation loss: 2.0791093160708747

Epoch: 541| Step: 0
Training loss: 0.34688788652420044
Validation loss: 2.055256793896357

Epoch: 5| Step: 1
Training loss: 0.28779539465904236
Validation loss: 2.089607740441958

Epoch: 5| Step: 2
Training loss: 0.24730882048606873
Validation loss: 2.050976182023684

Epoch: 5| Step: 3
Training loss: 0.17819471657276154
Validation loss: 2.0624099522829056

Epoch: 5| Step: 4
Training loss: 0.13425171375274658
Validation loss: 2.0407761484384537

Epoch: 5| Step: 5
Training loss: 0.16784784197807312
Validation loss: 2.0678103119134903

Epoch: 5| Step: 6
Training loss: 0.17366690933704376
Validation loss: 2.066150908668836

Epoch: 5| Step: 7
Training loss: 0.15572914481163025
Validation loss: 2.0483300387859344

Epoch: 5| Step: 8
Training loss: 0.4392126202583313
Validation loss: 2.0390992611646652

Epoch: 5| Step: 9
Training loss: 0.18556857109069824
Validation loss: 2.0627508809169135

Epoch: 5| Step: 10
Training loss: 0.23974475264549255
Validation loss: 2.076182926694552

Epoch: 5| Step: 11
Training loss: 0.2231941521167755
Validation loss: 2.0255593061447144

Epoch: 542| Step: 0
Training loss: 0.17334917187690735
Validation loss: 2.0565330932537713

Epoch: 5| Step: 1
Training loss: 0.18668915331363678
Validation loss: 2.0367873360713324

Epoch: 5| Step: 2
Training loss: 0.19415625929832458
Validation loss: 2.0795662850141525

Epoch: 5| Step: 3
Training loss: 0.11698007583618164
Validation loss: 2.0541453460852304

Epoch: 5| Step: 4
Training loss: 0.1652291715145111
Validation loss: 2.014695500334104

Epoch: 5| Step: 5
Training loss: 0.5714617967605591
Validation loss: 2.055834045012792

Epoch: 5| Step: 6
Training loss: 0.19699783623218536
Validation loss: 2.0393692702054977

Epoch: 5| Step: 7
Training loss: 0.22318999469280243
Validation loss: 2.0329347401857376

Epoch: 5| Step: 8
Training loss: 0.15900854766368866
Validation loss: 2.053468440969785

Epoch: 5| Step: 9
Training loss: 0.2226654589176178
Validation loss: 2.072118033965429

Epoch: 5| Step: 10
Training loss: 0.34398379921913147
Validation loss: 2.0884245336055756

Epoch: 5| Step: 11
Training loss: 0.1763799786567688
Validation loss: 2.0679647773504257

Epoch: 543| Step: 0
Training loss: 0.21286499500274658
Validation loss: 2.0595788657665253

Epoch: 5| Step: 1
Training loss: 0.1894747018814087
Validation loss: 2.090311586856842

Epoch: 5| Step: 2
Training loss: 0.458843857049942
Validation loss: 2.066514457265536

Epoch: 5| Step: 3
Training loss: 0.159414142370224
Validation loss: 2.0711865226427713

Epoch: 5| Step: 4
Training loss: 0.24430963397026062
Validation loss: 2.070475826660792

Epoch: 5| Step: 5
Training loss: 0.23382163047790527
Validation loss: 2.0779308080673218

Epoch: 5| Step: 6
Training loss: 0.14700058102607727
Validation loss: 2.057090317209562

Epoch: 5| Step: 7
Training loss: 0.24162538349628448
Validation loss: 2.059493273496628

Epoch: 5| Step: 8
Training loss: 0.16392387449741364
Validation loss: 2.0711150666077933

Epoch: 5| Step: 9
Training loss: 0.27462977170944214
Validation loss: 2.0616889844338098

Epoch: 5| Step: 10
Training loss: 0.2721203565597534
Validation loss: 2.075870712598165

Epoch: 5| Step: 11
Training loss: 0.2010386884212494
Validation loss: 2.0563370188077292

Epoch: 544| Step: 0
Training loss: 0.24460597336292267
Validation loss: 2.064977318048477

Epoch: 5| Step: 1
Training loss: 0.33740973472595215
Validation loss: 2.0852536658445993

Epoch: 5| Step: 2
Training loss: 0.255683571100235
Validation loss: 2.07732001443704

Epoch: 5| Step: 3
Training loss: 0.4397037923336029
Validation loss: 2.090233971675237

Epoch: 5| Step: 4
Training loss: 0.21394555270671844
Validation loss: 2.0660234689712524

Epoch: 5| Step: 5
Training loss: 0.39363551139831543
Validation loss: 2.060221344232559

Epoch: 5| Step: 6
Training loss: 0.3563104271888733
Validation loss: 2.031915932893753

Epoch: 5| Step: 7
Training loss: 0.24357149004936218
Validation loss: 2.037698596715927

Epoch: 5| Step: 8
Training loss: 0.15931281447410583
Validation loss: 2.0640847186247506

Epoch: 5| Step: 9
Training loss: 0.21211747825145721
Validation loss: 2.077521195014318

Epoch: 5| Step: 10
Training loss: 0.2926914095878601
Validation loss: 2.0674384236335754

Epoch: 5| Step: 11
Training loss: 0.24774706363677979
Validation loss: 2.078293278813362

Epoch: 545| Step: 0
Training loss: 0.24338781833648682
Validation loss: 2.0799188762903214

Epoch: 5| Step: 1
Training loss: 0.21390633285045624
Validation loss: 2.089724828799566

Epoch: 5| Step: 2
Training loss: 0.17068246006965637
Validation loss: 2.0156864722569785

Epoch: 5| Step: 3
Training loss: 0.5259500741958618
Validation loss: 2.0509386559327445

Epoch: 5| Step: 4
Training loss: 0.2748791575431824
Validation loss: 2.086231624086698

Epoch: 5| Step: 5
Training loss: 0.1652352213859558
Validation loss: 2.055052990714709

Epoch: 5| Step: 6
Training loss: 0.28312137722969055
Validation loss: 2.043571725487709

Epoch: 5| Step: 7
Training loss: 0.1480308622121811
Validation loss: 2.02862681945165

Epoch: 5| Step: 8
Training loss: 0.20987701416015625
Validation loss: 2.014983057975769

Epoch: 5| Step: 9
Training loss: 0.20507454872131348
Validation loss: 2.0783418516318

Epoch: 5| Step: 10
Training loss: 0.184294193983078
Validation loss: 2.0441924929618835

Epoch: 5| Step: 11
Training loss: 0.15052923560142517
Validation loss: 2.041297271847725

Epoch: 546| Step: 0
Training loss: 0.21690425276756287
Validation loss: 2.099285508195559

Epoch: 5| Step: 1
Training loss: 0.13323386013507843
Validation loss: 2.03935976823171

Epoch: 5| Step: 2
Training loss: 0.1569000780582428
Validation loss: 2.058407465616862

Epoch: 5| Step: 3
Training loss: 0.19963112473487854
Validation loss: 2.043959081172943

Epoch: 5| Step: 4
Training loss: 0.42056387662887573
Validation loss: 2.02593624095122

Epoch: 5| Step: 5
Training loss: 0.1434641033411026
Validation loss: 2.0635605504115424

Epoch: 5| Step: 6
Training loss: 0.18772481381893158
Validation loss: 2.072789947191874

Epoch: 5| Step: 7
Training loss: 0.16443060338497162
Validation loss: 2.0540621081988015

Epoch: 5| Step: 8
Training loss: 0.22041592001914978
Validation loss: 2.0555240561564765

Epoch: 5| Step: 9
Training loss: 0.178593710064888
Validation loss: 2.045848215619723

Epoch: 5| Step: 10
Training loss: 0.32147303223609924
Validation loss: 2.02986079454422

Epoch: 5| Step: 11
Training loss: 0.18317431211471558
Validation loss: 2.0754095762968063

Epoch: 547| Step: 0
Training loss: 0.17015527188777924
Validation loss: 2.02942264576753

Epoch: 5| Step: 1
Training loss: 0.14881078898906708
Validation loss: 2.0836758563915887

Epoch: 5| Step: 2
Training loss: 0.18148395419120789
Validation loss: 2.054888074596723

Epoch: 5| Step: 3
Training loss: 0.34068822860717773
Validation loss: 2.0685001015663147

Epoch: 5| Step: 4
Training loss: 0.3168566823005676
Validation loss: 2.059364467859268

Epoch: 5| Step: 5
Training loss: 0.13635195791721344
Validation loss: 2.050463934739431

Epoch: 5| Step: 6
Training loss: 0.26119619607925415
Validation loss: 2.0824212034543357

Epoch: 5| Step: 7
Training loss: 0.15171054005622864
Validation loss: 2.060350313782692

Epoch: 5| Step: 8
Training loss: 0.4590311050415039
Validation loss: 2.043944483002027

Epoch: 5| Step: 9
Training loss: 0.1676548570394516
Validation loss: 2.0687213391065598

Epoch: 5| Step: 10
Training loss: 0.2793029248714447
Validation loss: 2.070935606956482

Epoch: 5| Step: 11
Training loss: 0.19526052474975586
Validation loss: 2.080546592672666

Epoch: 548| Step: 0
Training loss: 0.16748671233654022
Validation loss: 2.0481672336657843

Epoch: 5| Step: 1
Training loss: 0.15674230456352234
Validation loss: 2.0818000932534537

Epoch: 5| Step: 2
Training loss: 0.14709977805614471
Validation loss: 2.0939992318550744

Epoch: 5| Step: 3
Training loss: 0.10832645744085312
Validation loss: 2.100047101577123

Epoch: 5| Step: 4
Training loss: 0.2441694289445877
Validation loss: 2.0962849905093512

Epoch: 5| Step: 5
Training loss: 0.2023911476135254
Validation loss: 2.108883942166964

Epoch: 5| Step: 6
Training loss: 0.40592890977859497
Validation loss: 2.0567599882682166

Epoch: 5| Step: 7
Training loss: 0.1682901680469513
Validation loss: 2.0810060103734336

Epoch: 5| Step: 8
Training loss: 0.21184802055358887
Validation loss: 2.080167402823766

Epoch: 5| Step: 9
Training loss: 0.20088621973991394
Validation loss: 2.073076441884041

Epoch: 5| Step: 10
Training loss: 0.57490074634552
Validation loss: 2.0892530977725983

Epoch: 5| Step: 11
Training loss: 0.15414535999298096
Validation loss: 2.0615799874067307

Epoch: 549| Step: 0
Training loss: 0.5093168020248413
Validation loss: 2.0680133253335953

Epoch: 5| Step: 1
Training loss: 0.19676318764686584
Validation loss: 2.1146769573291144

Epoch: 5| Step: 2
Training loss: 0.22998082637786865
Validation loss: 2.0642442256212234

Epoch: 5| Step: 3
Training loss: 0.19122307002544403
Validation loss: 2.0408219595750174

Epoch: 5| Step: 4
Training loss: 0.13466593623161316
Validation loss: 2.06033518910408

Epoch: 5| Step: 5
Training loss: 0.2709124684333801
Validation loss: 2.080275376637777

Epoch: 5| Step: 6
Training loss: 0.186977818608284
Validation loss: 2.068467140197754

Epoch: 5| Step: 7
Training loss: 0.25714755058288574
Validation loss: 2.0794923454523087

Epoch: 5| Step: 8
Training loss: 0.2816121578216553
Validation loss: 2.066903014977773

Epoch: 5| Step: 9
Training loss: 0.1610628068447113
Validation loss: 2.0333351691563926

Epoch: 5| Step: 10
Training loss: 0.1319364309310913
Validation loss: 2.0984238584836326

Epoch: 5| Step: 11
Training loss: 0.31280311942100525
Validation loss: 2.042210395137469

Epoch: 550| Step: 0
Training loss: 0.15645162761211395
Validation loss: 2.047870953877767

Epoch: 5| Step: 1
Training loss: 0.5225337743759155
Validation loss: 2.0463262448708215

Epoch: 5| Step: 2
Training loss: 0.2332955300807953
Validation loss: 2.0664809296528497

Epoch: 5| Step: 3
Training loss: 0.20789845287799835
Validation loss: 2.0525545924901962

Epoch: 5| Step: 4
Training loss: 0.16660436987876892
Validation loss: 2.034213955203692

Epoch: 5| Step: 5
Training loss: 0.2637067437171936
Validation loss: 2.0536243518193564

Epoch: 5| Step: 6
Training loss: 0.2319512814283371
Validation loss: 2.0733211239178977

Epoch: 5| Step: 7
Training loss: 0.17611084878444672
Validation loss: 2.0222423374652863

Epoch: 5| Step: 8
Training loss: 0.2042953073978424
Validation loss: 2.068309689561526

Epoch: 5| Step: 9
Training loss: 0.25429654121398926
Validation loss: 2.0203210016091666

Epoch: 5| Step: 10
Training loss: 0.2692168354988098
Validation loss: 2.0852555880943933

Epoch: 5| Step: 11
Training loss: 0.030461221933364868
Validation loss: 2.0699913601080575

Testing loss: 1.9852859193472554
