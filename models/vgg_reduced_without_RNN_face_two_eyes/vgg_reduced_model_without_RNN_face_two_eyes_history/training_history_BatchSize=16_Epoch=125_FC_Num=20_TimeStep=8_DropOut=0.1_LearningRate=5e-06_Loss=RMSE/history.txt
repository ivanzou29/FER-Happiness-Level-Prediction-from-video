Epoch: 1| Step: 0
Training loss: 7.062845677381037
Validation loss: 7.035482847719365

Epoch: 6| Step: 1
Training loss: 7.259267737080186
Validation loss: 7.003536557143896

Epoch: 6| Step: 2
Training loss: 6.941106735061746
Validation loss: 6.973918372436934

Epoch: 6| Step: 3
Training loss: 7.075303616428657
Validation loss: 6.94494646249948

Epoch: 6| Step: 4
Training loss: 7.49489546954227
Validation loss: 6.915907423639378

Epoch: 6| Step: 5
Training loss: 7.302132062617884
Validation loss: 6.888302596926867

Epoch: 6| Step: 6
Training loss: 5.952486099041084
Validation loss: 6.858283602726209

Epoch: 6| Step: 7
Training loss: 7.153195991347155
Validation loss: 6.829802585651221

Epoch: 6| Step: 8
Training loss: 6.723548772282515
Validation loss: 6.803206985299707

Epoch: 6| Step: 9
Training loss: 6.703544407952746
Validation loss: 6.770804192896026

Epoch: 6| Step: 10
Training loss: 6.100941019485616
Validation loss: 6.7393199116454365

Epoch: 6| Step: 11
Training loss: 7.187254793711335
Validation loss: 6.707832301919438

Epoch: 6| Step: 12
Training loss: 7.164742440641021
Validation loss: 6.67388971360044

Epoch: 6| Step: 13
Training loss: 6.989160046407356
Validation loss: 6.6416543319887555

Epoch: 2| Step: 0
Training loss: 6.1062115920858995
Validation loss: 6.605103106448374

Epoch: 6| Step: 1
Training loss: 7.3462086559129895
Validation loss: 6.567595377794479

Epoch: 6| Step: 2
Training loss: 6.411129763065726
Validation loss: 6.525499017373351

Epoch: 6| Step: 3
Training loss: 7.6383624949333155
Validation loss: 6.48805685036145

Epoch: 6| Step: 4
Training loss: 6.079184942324775
Validation loss: 6.444424260133434

Epoch: 6| Step: 5
Training loss: 6.4781991250507724
Validation loss: 6.397631944212769

Epoch: 6| Step: 6
Training loss: 5.694189811327146
Validation loss: 6.35467262963546

Epoch: 6| Step: 7
Training loss: 6.0407576655439605
Validation loss: 6.303796994434208

Epoch: 6| Step: 8
Training loss: 6.177761235813404
Validation loss: 6.255614137045864

Epoch: 6| Step: 9
Training loss: 6.446457935624143
Validation loss: 6.208384554180178

Epoch: 6| Step: 10
Training loss: 5.608661914437256
Validation loss: 6.159401333935017

Epoch: 6| Step: 11
Training loss: 7.223370283120637
Validation loss: 6.103954723788522

Epoch: 6| Step: 12
Training loss: 6.531727166518212
Validation loss: 6.049464812133767

Epoch: 6| Step: 13
Training loss: 5.72257059182906
Validation loss: 5.990092362597689

Epoch: 3| Step: 0
Training loss: 7.113872203967049
Validation loss: 5.926050007810292

Epoch: 6| Step: 1
Training loss: 6.09300188216245
Validation loss: 5.867700898878915

Epoch: 6| Step: 2
Training loss: 5.533271721799466
Validation loss: 5.799978681503228

Epoch: 6| Step: 3
Training loss: 6.138665660790682
Validation loss: 5.73597848701433

Epoch: 6| Step: 4
Training loss: 5.472495752631814
Validation loss: 5.662893731559629

Epoch: 6| Step: 5
Training loss: 5.850034873401998
Validation loss: 5.593955492617493

Epoch: 6| Step: 6
Training loss: 5.315025178234217
Validation loss: 5.509282053601399

Epoch: 6| Step: 7
Training loss: 6.033576160974783
Validation loss: 5.436057385362329

Epoch: 6| Step: 8
Training loss: 5.465599329578975
Validation loss: 5.345189813348702

Epoch: 6| Step: 9
Training loss: 5.238656095310755
Validation loss: 5.264203552306887

Epoch: 6| Step: 10
Training loss: 5.355459668174739
Validation loss: 5.169967468621757

Epoch: 6| Step: 11
Training loss: 4.39923056030314
Validation loss: 5.0786697486760595

Epoch: 6| Step: 12
Training loss: 3.7284289150636383
Validation loss: 4.981719869408467

Epoch: 6| Step: 13
Training loss: 5.077933064281398
Validation loss: 4.879927598280661

Epoch: 4| Step: 0
Training loss: 5.285090026666133
Validation loss: 4.779578022546383

Epoch: 6| Step: 1
Training loss: 5.223157654619451
Validation loss: 4.670032899292775

Epoch: 6| Step: 2
Training loss: 4.507380896257306
Validation loss: 4.56551265103986

Epoch: 6| Step: 3
Training loss: 4.080291523335713
Validation loss: 4.442925946122427

Epoch: 6| Step: 4
Training loss: 4.197246539044554
Validation loss: 4.315840289035478

Epoch: 6| Step: 5
Training loss: 3.9485814215119803
Validation loss: 4.200270599397671

Epoch: 6| Step: 6
Training loss: 4.516261494799022
Validation loss: 4.071022640474227

Epoch: 6| Step: 7
Training loss: 4.0982575970808925
Validation loss: 3.9439024970812815

Epoch: 6| Step: 8
Training loss: 3.762671360916825
Validation loss: 3.8070566476211796

Epoch: 6| Step: 9
Training loss: 3.382824622434255
Validation loss: 3.676694480212075

Epoch: 6| Step: 10
Training loss: 2.984919952648356
Validation loss: 3.545929590899248

Epoch: 6| Step: 11
Training loss: 3.7737344502561125
Validation loss: 3.4457116966197163

Epoch: 6| Step: 12
Training loss: 3.611862844488625
Validation loss: 3.3125714228385563

Epoch: 6| Step: 13
Training loss: 3.5787627472219112
Validation loss: 3.2178972713431424

Epoch: 5| Step: 0
Training loss: 3.433040986685094
Validation loss: 3.1088334063957705

Epoch: 6| Step: 1
Training loss: 3.271154804994674
Validation loss: 3.0405400336516206

Epoch: 6| Step: 2
Training loss: 2.3996261981099303
Validation loss: 2.972513657440389

Epoch: 6| Step: 3
Training loss: 3.2044829676701188
Validation loss: 2.9159903605057163

Epoch: 6| Step: 4
Training loss: 2.3706676722496884
Validation loss: 2.8468848196530985

Epoch: 6| Step: 5
Training loss: 3.099549685349974
Validation loss: 2.8264657733112912

Epoch: 6| Step: 6
Training loss: 3.4218960417357476
Validation loss: 2.800692121931099

Epoch: 6| Step: 7
Training loss: 2.755179123221864
Validation loss: 2.812003437994261

Epoch: 6| Step: 8
Training loss: 2.774707600077921
Validation loss: 2.8177533995196886

Epoch: 6| Step: 9
Training loss: 2.4166905193686365
Validation loss: 2.8161966401931795

Epoch: 6| Step: 10
Training loss: 2.5169232732379228
Validation loss: 2.843624496485181

Epoch: 6| Step: 11
Training loss: 2.574293954587165
Validation loss: 2.8798843440701463

Epoch: 6| Step: 12
Training loss: 3.0997324428151884
Validation loss: 2.860298660707733

Epoch: 6| Step: 13
Training loss: 3.2506378721610525
Validation loss: 2.8784059446092862

Epoch: 6| Step: 0
Training loss: 2.305302941859824
Validation loss: 2.8697718338647413

Epoch: 6| Step: 1
Training loss: 3.5615870326530152
Validation loss: 2.8787149118153215

Epoch: 6| Step: 2
Training loss: 2.8512546320856273
Validation loss: 2.850270017581882

Epoch: 6| Step: 3
Training loss: 3.1333990523027353
Validation loss: 2.8581518812574767

Epoch: 6| Step: 4
Training loss: 2.5503654666874462
Validation loss: 2.8232730251102867

Epoch: 6| Step: 5
Training loss: 2.7543757910886373
Validation loss: 2.83307595112423

Epoch: 6| Step: 6
Training loss: 2.7849206597414384
Validation loss: 2.7919438115425805

Epoch: 6| Step: 7
Training loss: 2.3367830615183602
Validation loss: 2.742800043709521

Epoch: 6| Step: 8
Training loss: 2.9918875680902137
Validation loss: 2.775637489272997

Epoch: 6| Step: 9
Training loss: 2.4085582214566124
Validation loss: 2.772726363586034

Epoch: 6| Step: 10
Training loss: 3.0060614703220048
Validation loss: 2.7326928768509453

Epoch: 6| Step: 11
Training loss: 2.4960957558493995
Validation loss: 2.750456685379614

Epoch: 6| Step: 12
Training loss: 3.8140648303870646
Validation loss: 2.753275048175493

Epoch: 6| Step: 13
Training loss: 3.0224386926180595
Validation loss: 2.748972686425587

Epoch: 7| Step: 0
Training loss: 2.578552395622438
Validation loss: 2.7576923434239737

Epoch: 6| Step: 1
Training loss: 3.02506624259614
Validation loss: 2.755853881397895

Epoch: 6| Step: 2
Training loss: 3.0805385054435708
Validation loss: 2.7379579883832648

Epoch: 6| Step: 3
Training loss: 1.5543407264308404
Validation loss: 2.729587381758114

Epoch: 6| Step: 4
Training loss: 3.0027419910852906
Validation loss: 2.7445363620298173

Epoch: 6| Step: 5
Training loss: 3.044281623675452
Validation loss: 2.7453260438426126

Epoch: 6| Step: 6
Training loss: 3.0967688425848476
Validation loss: 2.743205961833378

Epoch: 6| Step: 7
Training loss: 2.3525060237276345
Validation loss: 2.7382029450993253

Epoch: 6| Step: 8
Training loss: 2.796765543751186
Validation loss: 2.7419806001140627

Epoch: 6| Step: 9
Training loss: 2.2756265804428817
Validation loss: 2.7527515055556147

Epoch: 6| Step: 10
Training loss: 2.934618409027655
Validation loss: 2.7410614947787977

Epoch: 6| Step: 11
Training loss: 3.4611686818774348
Validation loss: 2.7447328844719006

Epoch: 6| Step: 12
Training loss: 3.2399662359856696
Validation loss: 2.762656650158068

Epoch: 6| Step: 13
Training loss: 2.0124429824997527
Validation loss: 2.738689426650079

Epoch: 8| Step: 0
Training loss: 2.6157148630618225
Validation loss: 2.736585221520977

Epoch: 6| Step: 1
Training loss: 2.564445129521523
Validation loss: 2.7088042412247177

Epoch: 6| Step: 2
Training loss: 2.7038818358272794
Validation loss: 2.728522921247291

Epoch: 6| Step: 3
Training loss: 2.597502602070156
Validation loss: 2.691283246732848

Epoch: 6| Step: 4
Training loss: 3.3581786398523596
Validation loss: 2.7137027089856662

Epoch: 6| Step: 5
Training loss: 2.7402606508785654
Validation loss: 2.69395307821274

Epoch: 6| Step: 6
Training loss: 3.218233233698946
Validation loss: 2.7328369319834924

Epoch: 6| Step: 7
Training loss: 2.396056344530435
Validation loss: 2.699095484434978

Epoch: 6| Step: 8
Training loss: 2.23881058483692
Validation loss: 2.688617887799654

Epoch: 6| Step: 9
Training loss: 3.04450826423314
Validation loss: 2.7134042706304284

Epoch: 6| Step: 10
Training loss: 2.198337737573816
Validation loss: 2.692825142683649

Epoch: 6| Step: 11
Training loss: 3.0916269126728544
Validation loss: 2.6946090443685513

Epoch: 6| Step: 12
Training loss: 3.116017210368078
Validation loss: 2.6971563252174544

Epoch: 6| Step: 13
Training loss: 2.7577235393926744
Validation loss: 2.687324636489598

Epoch: 9| Step: 0
Training loss: 2.354483479025268
Validation loss: 2.6849672078001396

Epoch: 6| Step: 1
Training loss: 3.3441958976841355
Validation loss: 2.696671265958519

Epoch: 6| Step: 2
Training loss: 2.8027911987924323
Validation loss: 2.719372805880403

Epoch: 6| Step: 3
Training loss: 2.7635312533239325
Validation loss: 2.6706942055381093

Epoch: 6| Step: 4
Training loss: 2.460677263336116
Validation loss: 2.6673528314980763

Epoch: 6| Step: 5
Training loss: 2.7887229392167785
Validation loss: 2.7072410483849163

Epoch: 6| Step: 6
Training loss: 2.513239896776183
Validation loss: 2.6630317730041337

Epoch: 6| Step: 7
Training loss: 2.9199684164873583
Validation loss: 2.6821557365467688

Epoch: 6| Step: 8
Training loss: 2.006478070281606
Validation loss: 2.6591059197859503

Epoch: 6| Step: 9
Training loss: 2.778280065476283
Validation loss: 2.690364109908597

Epoch: 6| Step: 10
Training loss: 3.099530609033873
Validation loss: 2.6611358287922506

Epoch: 6| Step: 11
Training loss: 2.6494781340160922
Validation loss: 2.6922388214692567

Epoch: 6| Step: 12
Training loss: 2.7178936190526857
Validation loss: 2.6705292106535015

Epoch: 6| Step: 13
Training loss: 2.6078055224545285
Validation loss: 2.6746349988864786

Epoch: 10| Step: 0
Training loss: 2.264166316356592
Validation loss: 2.6508296639461917

Epoch: 6| Step: 1
Training loss: 2.3359926147082914
Validation loss: 2.6640528047595913

Epoch: 6| Step: 2
Training loss: 2.071664505474327
Validation loss: 2.6453379570295064

Epoch: 6| Step: 3
Training loss: 2.3268973166609515
Validation loss: 2.6388950738220904

Epoch: 6| Step: 4
Training loss: 2.113361801332777
Validation loss: 2.6832810339559865

Epoch: 6| Step: 5
Training loss: 2.958042470754783
Validation loss: 2.6641794367358784

Epoch: 6| Step: 6
Training loss: 3.1684926607571575
Validation loss: 2.633085272569515

Epoch: 6| Step: 7
Training loss: 2.6727361351012515
Validation loss: 2.676380871787868

Epoch: 6| Step: 8
Training loss: 3.101029588092572
Validation loss: 2.642269201987505

Epoch: 6| Step: 9
Training loss: 2.869056196639002
Validation loss: 2.6528421269901155

Epoch: 6| Step: 10
Training loss: 2.903658952669119
Validation loss: 2.6395747486949404

Epoch: 6| Step: 11
Training loss: 3.145801586134086
Validation loss: 2.6551610023307695

Epoch: 6| Step: 12
Training loss: 2.5864828865728415
Validation loss: 2.660152605215779

Epoch: 6| Step: 13
Training loss: 2.7903220701101596
Validation loss: 2.6480180226238006

Epoch: 11| Step: 0
Training loss: 1.8441653026375235
Validation loss: 2.645333555783306

Epoch: 6| Step: 1
Training loss: 3.4859634678863856
Validation loss: 2.6138799159343815

Epoch: 6| Step: 2
Training loss: 2.249429842446496
Validation loss: 2.647605382678872

Epoch: 6| Step: 3
Training loss: 2.9873157013424785
Validation loss: 2.636384195837536

Epoch: 6| Step: 4
Training loss: 2.2710889503262943
Validation loss: 2.6183167863254573

Epoch: 6| Step: 5
Training loss: 2.6250282467730135
Validation loss: 2.6328720402989143

Epoch: 6| Step: 6
Training loss: 3.127016256291972
Validation loss: 2.6401722988343677

Epoch: 6| Step: 7
Training loss: 2.0950782320624484
Validation loss: 2.628010265069981

Epoch: 6| Step: 8
Training loss: 3.09791484970385
Validation loss: 2.6303714487592385

Epoch: 6| Step: 9
Training loss: 2.4313531299674547
Validation loss: 2.6379511912807154

Epoch: 6| Step: 10
Training loss: 3.1767381490995343
Validation loss: 2.6046761789974053

Epoch: 6| Step: 11
Training loss: 2.5031167629073074
Validation loss: 2.632256061377056

Epoch: 6| Step: 12
Training loss: 2.2675294435517848
Validation loss: 2.632236768670621

Epoch: 6| Step: 13
Training loss: 2.4537092351417917
Validation loss: 2.622075616605048

Epoch: 12| Step: 0
Training loss: 3.367387168257072
Validation loss: 2.6273722752657807

Epoch: 6| Step: 1
Training loss: 2.577999782411316
Validation loss: 2.60269079475801

Epoch: 6| Step: 2
Training loss: 2.4069294156104695
Validation loss: 2.6205594484218855

Epoch: 6| Step: 3
Training loss: 2.254734779544243
Validation loss: 2.5825893704958016

Epoch: 6| Step: 4
Training loss: 2.0123633675959685
Validation loss: 2.6350852898698958

Epoch: 6| Step: 5
Training loss: 2.7798611034027267
Validation loss: 2.6240146695023543

Epoch: 6| Step: 6
Training loss: 2.6238494349698036
Validation loss: 2.5967202242599114

Epoch: 6| Step: 7
Training loss: 2.8935535339497362
Validation loss: 2.600439323697811

Epoch: 6| Step: 8
Training loss: 3.0711960625327395
Validation loss: 2.625842186386146

Epoch: 6| Step: 9
Training loss: 2.498896068980884
Validation loss: 2.5929527972601183

Epoch: 6| Step: 10
Training loss: 2.40167435414736
Validation loss: 2.633612491401792

Epoch: 6| Step: 11
Training loss: 2.7701729487057243
Validation loss: 2.5859388983377936

Epoch: 6| Step: 12
Training loss: 2.756270801699246
Validation loss: 2.5833281906650996

Epoch: 6| Step: 13
Training loss: 2.303317836519805
Validation loss: 2.579014218271838

Epoch: 13| Step: 0
Training loss: 3.068578176874086
Validation loss: 2.592388178572826

Epoch: 6| Step: 1
Training loss: 2.6799592083345973
Validation loss: 2.5818646214169685

Epoch: 6| Step: 2
Training loss: 2.8206982969552574
Validation loss: 2.5882319156954896

Epoch: 6| Step: 3
Training loss: 2.4340763011623876
Validation loss: 2.5920679390965295

Epoch: 6| Step: 4
Training loss: 2.638458265895829
Validation loss: 2.5762316292211564

Epoch: 6| Step: 5
Training loss: 2.8767618502903805
Validation loss: 2.634882957083694

Epoch: 6| Step: 6
Training loss: 2.120272932477567
Validation loss: 2.5766151399712003

Epoch: 6| Step: 7
Training loss: 2.214556317121256
Validation loss: 2.5573828085968726

Epoch: 6| Step: 8
Training loss: 2.6758507489833883
Validation loss: 2.610037797517755

Epoch: 6| Step: 9
Training loss: 2.41337136063025
Validation loss: 2.616102428305308

Epoch: 6| Step: 10
Training loss: 1.9999511235940584
Validation loss: 2.6241682642276376

Epoch: 6| Step: 11
Training loss: 2.998290528576242
Validation loss: 2.5932957967756356

Epoch: 6| Step: 12
Training loss: 2.7172579123886944
Validation loss: 2.6187873846767844

Epoch: 6| Step: 13
Training loss: 2.9130780804662733
Validation loss: 2.599604651764234

Epoch: 14| Step: 0
Training loss: 2.8056683963539015
Validation loss: 2.6344576109591964

Epoch: 6| Step: 1
Training loss: 2.976222221568511
Validation loss: 2.6068896108745427

Epoch: 6| Step: 2
Training loss: 3.0579229912850785
Validation loss: 2.585865861067493

Epoch: 6| Step: 3
Training loss: 1.9727201848008633
Validation loss: 2.5923502412051453

Epoch: 6| Step: 4
Training loss: 1.9441619289366083
Validation loss: 2.5904830059286095

Epoch: 6| Step: 5
Training loss: 2.70469893128587
Validation loss: 2.593435751021159

Epoch: 6| Step: 6
Training loss: 2.596728349898954
Validation loss: 2.6094274001656435

Epoch: 6| Step: 7
Training loss: 2.5959814193718955
Validation loss: 2.5720770980888745

Epoch: 6| Step: 8
Training loss: 2.9400365713011767
Validation loss: 2.6191358307849795

Epoch: 6| Step: 9
Training loss: 2.3336249805017046
Validation loss: 2.5761880399338053

Epoch: 6| Step: 10
Training loss: 2.5541814367003126
Validation loss: 2.606471351597326

Epoch: 6| Step: 11
Training loss: 2.5874656932970646
Validation loss: 2.596054286850089

Epoch: 6| Step: 12
Training loss: 2.7121897506836388
Validation loss: 2.583479267018219

Epoch: 6| Step: 13
Training loss: 2.5926412027837693
Validation loss: 2.5796313576429952

Epoch: 15| Step: 0
Training loss: 2.550456892482717
Validation loss: 2.5894987050041127

Epoch: 6| Step: 1
Training loss: 2.1981966343569765
Validation loss: 2.5745294332307824

Epoch: 6| Step: 2
Training loss: 1.380013904432378
Validation loss: 2.5927887939458136

Epoch: 6| Step: 3
Training loss: 2.7447283241061644
Validation loss: 2.6082404634032073

Epoch: 6| Step: 4
Training loss: 2.241236574778476
Validation loss: 2.5819296381622

Epoch: 6| Step: 5
Training loss: 3.9296248868955654
Validation loss: 2.579539317591095

Epoch: 6| Step: 6
Training loss: 2.989033044728758
Validation loss: 2.6067234203944114

Epoch: 6| Step: 7
Training loss: 2.826971841149008
Validation loss: 2.5772582475598904

Epoch: 6| Step: 8
Training loss: 2.550839573892933
Validation loss: 2.595941988496186

Epoch: 6| Step: 9
Training loss: 2.8623291764241556
Validation loss: 2.5732952771148194

Epoch: 6| Step: 10
Training loss: 1.9203235597967085
Validation loss: 2.587702338128797

Epoch: 6| Step: 11
Training loss: 1.9781340130303837
Validation loss: 2.6049910092580015

Epoch: 6| Step: 12
Training loss: 2.8123282486078116
Validation loss: 2.555249470253783

Epoch: 6| Step: 13
Training loss: 2.1374746934608484
Validation loss: 2.569745125804635

Epoch: 16| Step: 0
Training loss: 2.5348990240809153
Validation loss: 2.563051978417314

Epoch: 6| Step: 1
Training loss: 3.2011271875694183
Validation loss: 2.573768109329985

Epoch: 6| Step: 2
Training loss: 1.815265781499478
Validation loss: 2.5597680112657932

Epoch: 6| Step: 3
Training loss: 2.273222922984142
Validation loss: 2.586096936369266

Epoch: 6| Step: 4
Training loss: 2.8802475515573227
Validation loss: 2.5535023902556704

Epoch: 6| Step: 5
Training loss: 2.998581869000354
Validation loss: 2.5760759630297003

Epoch: 6| Step: 6
Training loss: 2.5566857598431922
Validation loss: 2.5809676018181293

Epoch: 6| Step: 7
Training loss: 2.511801995637655
Validation loss: 2.5500680920603847

Epoch: 6| Step: 8
Training loss: 2.916266786320165
Validation loss: 2.534562365108483

Epoch: 6| Step: 9
Training loss: 1.9847773947439047
Validation loss: 2.5809379875520437

Epoch: 6| Step: 10
Training loss: 2.405077561934013
Validation loss: 2.5627212894071776

Epoch: 6| Step: 11
Training loss: 2.8724987925766814
Validation loss: 2.576953367401246

Epoch: 6| Step: 12
Training loss: 2.4210510821304774
Validation loss: 2.54573809127672

Epoch: 6| Step: 13
Training loss: 2.52238371491237
Validation loss: 2.547133356575906

Epoch: 17| Step: 0
Training loss: 2.839690444355367
Validation loss: 2.5908712781563237

Epoch: 6| Step: 1
Training loss: 1.9916947896187576
Validation loss: 2.5650575172068137

Epoch: 6| Step: 2
Training loss: 2.0036808950557536
Validation loss: 2.5348914997123093

Epoch: 6| Step: 3
Training loss: 2.7643295961222343
Validation loss: 2.53962471239543

Epoch: 6| Step: 4
Training loss: 2.4774072211299134
Validation loss: 2.5411385367923933

Epoch: 6| Step: 5
Training loss: 2.195736338471611
Validation loss: 2.5374597547812963

Epoch: 6| Step: 6
Training loss: 2.5161102016555237
Validation loss: 2.5697888011836505

Epoch: 6| Step: 7
Training loss: 2.9753170261242454
Validation loss: 2.5304431178683173

Epoch: 6| Step: 8
Training loss: 2.402255619572484
Validation loss: 2.5473267480288717

Epoch: 6| Step: 9
Training loss: 1.750599826466959
Validation loss: 2.5446048909018457

Epoch: 6| Step: 10
Training loss: 3.320134847039628
Validation loss: 2.5517047419615237

Epoch: 6| Step: 11
Training loss: 3.483015265537293
Validation loss: 2.540441566968001

Epoch: 6| Step: 12
Training loss: 2.8337725317639357
Validation loss: 2.56021743777348

Epoch: 6| Step: 13
Training loss: 1.4250948154962522
Validation loss: 2.559219283885214

Epoch: 18| Step: 0
Training loss: 2.2855374531803534
Validation loss: 2.588083980222647

Epoch: 6| Step: 1
Training loss: 2.4305400763124716
Validation loss: 2.5414841591601958

Epoch: 6| Step: 2
Training loss: 1.4921627342206105
Validation loss: 2.534280493464094

Epoch: 6| Step: 3
Training loss: 2.9224436813423242
Validation loss: 2.5376672755386434

Epoch: 6| Step: 4
Training loss: 3.367573939405893
Validation loss: 2.5331957053980507

Epoch: 6| Step: 5
Training loss: 3.029810927632638
Validation loss: 2.5269176314565893

Epoch: 6| Step: 6
Training loss: 2.7566870102906273
Validation loss: 2.51566600568692

Epoch: 6| Step: 7
Training loss: 2.3168399398369606
Validation loss: 2.531903900644472

Epoch: 6| Step: 8
Training loss: 2.4503276450165044
Validation loss: 2.5417782389014927

Epoch: 6| Step: 9
Training loss: 2.3370073095035138
Validation loss: 2.54363306512519

Epoch: 6| Step: 10
Training loss: 2.9212681757272136
Validation loss: 2.5763589532237785

Epoch: 6| Step: 11
Training loss: 3.116647162010917
Validation loss: 2.521373207563056

Epoch: 6| Step: 12
Training loss: 2.107848116359579
Validation loss: 2.5497793631998746

Epoch: 6| Step: 13
Training loss: 1.5888782915830486
Validation loss: 2.5259104638912393

Epoch: 19| Step: 0
Training loss: 2.1994355604718154
Validation loss: 2.5462830992719527

Epoch: 6| Step: 1
Training loss: 2.0405555608130688
Validation loss: 2.5655517703968687

Epoch: 6| Step: 2
Training loss: 2.225177856366128
Validation loss: 2.521653141881354

Epoch: 6| Step: 3
Training loss: 2.987552888154699
Validation loss: 2.523300198657013

Epoch: 6| Step: 4
Training loss: 1.989603438616988
Validation loss: 2.531722444627623

Epoch: 6| Step: 5
Training loss: 2.7098748050782713
Validation loss: 2.546802192068557

Epoch: 6| Step: 6
Training loss: 2.6600354317047743
Validation loss: 2.5747551829427304

Epoch: 6| Step: 7
Training loss: 2.4476858693074015
Validation loss: 2.5718693216723905

Epoch: 6| Step: 8
Training loss: 3.198491163972973
Validation loss: 2.5231677089273834

Epoch: 6| Step: 9
Training loss: 1.9426588473183368
Validation loss: 2.5581174761470993

Epoch: 6| Step: 10
Training loss: 2.844889485872626
Validation loss: 2.5388511374115645

Epoch: 6| Step: 11
Training loss: 2.7076826536608367
Validation loss: 2.5323255789047496

Epoch: 6| Step: 12
Training loss: 3.134069328578334
Validation loss: 2.548072642565907

Epoch: 6| Step: 13
Training loss: 2.199396752967807
Validation loss: 2.539552173835379

Epoch: 20| Step: 0
Training loss: 2.309264419654361
Validation loss: 2.5784664660034897

Epoch: 6| Step: 1
Training loss: 2.3822973476175933
Validation loss: 2.5837717658413215

Epoch: 6| Step: 2
Training loss: 2.9971993407078306
Validation loss: 2.547640289596667

Epoch: 6| Step: 3
Training loss: 2.809283472931598
Validation loss: 2.565645628709525

Epoch: 6| Step: 4
Training loss: 1.802671421063566
Validation loss: 2.592019626116821

Epoch: 6| Step: 5
Training loss: 2.0026074340423268
Validation loss: 2.5818194188470356

Epoch: 6| Step: 6
Training loss: 2.4134951421682067
Validation loss: 2.5998262830312147

Epoch: 6| Step: 7
Training loss: 2.6890552367711322
Validation loss: 2.5834034069360814

Epoch: 6| Step: 8
Training loss: 2.862416468571752
Validation loss: 2.5878427484270263

Epoch: 6| Step: 9
Training loss: 2.5250869887069456
Validation loss: 2.5286999482880295

Epoch: 6| Step: 10
Training loss: 2.4553193404024847
Validation loss: 2.5507957687860476

Epoch: 6| Step: 11
Training loss: 1.8108830309650479
Validation loss: 2.558296166894521

Epoch: 6| Step: 12
Training loss: 3.0972549159249376
Validation loss: 2.5632266588258603

Epoch: 6| Step: 13
Training loss: 2.9253165636176006
Validation loss: 2.533604551110548

Epoch: 21| Step: 0
Training loss: 2.7805920797822807
Validation loss: 2.537181168994788

Epoch: 6| Step: 1
Training loss: 3.0400376508288565
Validation loss: 2.5294676105702543

Epoch: 6| Step: 2
Training loss: 2.9890056056317538
Validation loss: 2.5778976648457705

Epoch: 6| Step: 3
Training loss: 2.450044289013454
Validation loss: 2.5343051729880086

Epoch: 6| Step: 4
Training loss: 2.0385450386197506
Validation loss: 2.5447772539511133

Epoch: 6| Step: 5
Training loss: 2.238183250745125
Validation loss: 2.550794865258855

Epoch: 6| Step: 6
Training loss: 2.1532478995052178
Validation loss: 2.512308386712686

Epoch: 6| Step: 7
Training loss: 2.585891953727011
Validation loss: 2.5306013084553154

Epoch: 6| Step: 8
Training loss: 2.2058984060264337
Validation loss: 2.5374742597455158

Epoch: 6| Step: 9
Training loss: 2.52939113603313
Validation loss: 2.5413032699283122

Epoch: 6| Step: 10
Training loss: 2.6758944967766647
Validation loss: 2.5450784318401136

Epoch: 6| Step: 11
Training loss: 2.272010381513706
Validation loss: 2.5331636188988287

Epoch: 6| Step: 12
Training loss: 2.717523232284385
Validation loss: 2.5827416747394767

Epoch: 6| Step: 13
Training loss: 2.570099146374004
Validation loss: 2.5908698824806216

Epoch: 22| Step: 0
Training loss: 3.322097980411637
Validation loss: 2.52145247829522

Epoch: 6| Step: 1
Training loss: 2.183023395330835
Validation loss: 2.5088093995502097

Epoch: 6| Step: 2
Training loss: 2.2991754339183945
Validation loss: 2.519646330972622

Epoch: 6| Step: 3
Training loss: 2.3310315722696613
Validation loss: 2.572914483896995

Epoch: 6| Step: 4
Training loss: 3.378216376467095
Validation loss: 2.5558842180441905

Epoch: 6| Step: 5
Training loss: 2.5996727480712276
Validation loss: 2.5191975217295206

Epoch: 6| Step: 6
Training loss: 2.4669295733619916
Validation loss: 2.5495916906091933

Epoch: 6| Step: 7
Training loss: 2.2056843926855714
Validation loss: 2.5473286823372345

Epoch: 6| Step: 8
Training loss: 2.191279606551139
Validation loss: 2.5563434984787072

Epoch: 6| Step: 9
Training loss: 2.1813890385514014
Validation loss: 2.499956090859413

Epoch: 6| Step: 10
Training loss: 2.5549390943102277
Validation loss: 2.5692796264803164

Epoch: 6| Step: 11
Training loss: 2.7217753447936985
Validation loss: 2.5375553920569223

Epoch: 6| Step: 12
Training loss: 2.2447832878882807
Validation loss: 2.5433845082488675

Epoch: 6| Step: 13
Training loss: 2.3835330061422746
Validation loss: 2.5947250770121437

Epoch: 23| Step: 0
Training loss: 1.8500229756758602
Validation loss: 2.5786880571892734

Epoch: 6| Step: 1
Training loss: 2.5761383725432423
Validation loss: 2.5854710199471334

Epoch: 6| Step: 2
Training loss: 2.6136027367882577
Validation loss: 2.6128485625056945

Epoch: 6| Step: 3
Training loss: 2.5142670751475267
Validation loss: 2.62406467243974

Epoch: 6| Step: 4
Training loss: 2.5678731828018457
Validation loss: 2.581538258637182

Epoch: 6| Step: 5
Training loss: 2.1893731952543276
Validation loss: 2.632510189581288

Epoch: 6| Step: 6
Training loss: 3.4884119297680494
Validation loss: 2.5914109188693684

Epoch: 6| Step: 7
Training loss: 2.3077519103447206
Validation loss: 2.6164111527945355

Epoch: 6| Step: 8
Training loss: 2.5502008359022
Validation loss: 2.5496575069428364

Epoch: 6| Step: 9
Training loss: 2.163159894862931
Validation loss: 2.514798030415957

Epoch: 6| Step: 10
Training loss: 2.290973373504788
Validation loss: 2.510400880207323

Epoch: 6| Step: 11
Training loss: 2.877200238400697
Validation loss: 2.514777670690642

Epoch: 6| Step: 12
Training loss: 2.7220170134013375
Validation loss: 2.5263935014504253

Epoch: 6| Step: 13
Training loss: 2.7227520481151304
Validation loss: 2.5363672123912067

Epoch: 24| Step: 0
Training loss: 2.6749417735384986
Validation loss: 2.5590964253047535

Epoch: 6| Step: 1
Training loss: 3.054697178193588
Validation loss: 2.569867050081661

Epoch: 6| Step: 2
Training loss: 2.813687815442967
Validation loss: 2.5470724828875775

Epoch: 6| Step: 3
Training loss: 2.5166812361575492
Validation loss: 2.503119509242874

Epoch: 6| Step: 4
Training loss: 1.380451147445428
Validation loss: 2.544613885674756

Epoch: 6| Step: 5
Training loss: 2.252079744244967
Validation loss: 2.5291292152166664

Epoch: 6| Step: 6
Training loss: 2.325853404449747
Validation loss: 2.5480913249486816

Epoch: 6| Step: 7
Training loss: 2.4192727167281642
Validation loss: 2.5465322626640368

Epoch: 6| Step: 8
Training loss: 2.351253349792593
Validation loss: 2.5325704356544367

Epoch: 6| Step: 9
Training loss: 2.5933571023840583
Validation loss: 2.5564027213664544

Epoch: 6| Step: 10
Training loss: 2.223561402633014
Validation loss: 2.5605310225705296

Epoch: 6| Step: 11
Training loss: 2.895879310590541
Validation loss: 2.512046282401109

Epoch: 6| Step: 12
Training loss: 2.3780070893460308
Validation loss: 2.5502162461435547

Epoch: 6| Step: 13
Training loss: 2.859828391895449
Validation loss: 2.5318372225824977

Epoch: 25| Step: 0
Training loss: 2.5414213051688637
Validation loss: 2.5311027138641156

Epoch: 6| Step: 1
Training loss: 2.118168564858055
Validation loss: 2.5240127805304646

Epoch: 6| Step: 2
Training loss: 2.467470054560705
Validation loss: 2.4918550929350816

Epoch: 6| Step: 3
Training loss: 2.761923085036046
Validation loss: 2.5393282394241248

Epoch: 6| Step: 4
Training loss: 2.1386560448186964
Validation loss: 2.520318795858688

Epoch: 6| Step: 5
Training loss: 2.7288967513545144
Validation loss: 2.5346268628674156

Epoch: 6| Step: 6
Training loss: 2.222207290546267
Validation loss: 2.519989721098125

Epoch: 6| Step: 7
Training loss: 2.2058919210787433
Validation loss: 2.5270882014966483

Epoch: 6| Step: 8
Training loss: 2.9654696360532027
Validation loss: 2.518880834092159

Epoch: 6| Step: 9
Training loss: 2.8303754925401634
Validation loss: 2.5195738717350404

Epoch: 6| Step: 10
Training loss: 1.9025131244181666
Validation loss: 2.5550587157901385

Epoch: 6| Step: 11
Training loss: 2.3162730598434087
Validation loss: 2.533122684688845

Epoch: 6| Step: 12
Training loss: 2.3846963408432122
Validation loss: 2.5535971271544144

Epoch: 6| Step: 13
Training loss: 2.720435047840294
Validation loss: 2.5248280365932185

Epoch: 26| Step: 0
Training loss: 2.8782968277227776
Validation loss: 2.5115696619063095

Epoch: 6| Step: 1
Training loss: 2.232768835304165
Validation loss: 2.5204349129406776

Epoch: 6| Step: 2
Training loss: 2.6898190450960318
Validation loss: 2.503545932563507

Epoch: 6| Step: 3
Training loss: 2.619951934664759
Validation loss: 2.532001273984021

Epoch: 6| Step: 4
Training loss: 2.52347708750754
Validation loss: 2.519198168440785

Epoch: 6| Step: 5
Training loss: 2.194835353055045
Validation loss: 2.5479003932762785

Epoch: 6| Step: 6
Training loss: 2.421534557410225
Validation loss: 2.504920170972022

Epoch: 6| Step: 7
Training loss: 3.0015323222369448
Validation loss: 2.515131931674366

Epoch: 6| Step: 8
Training loss: 2.4056944763188683
Validation loss: 2.5218308316900475

Epoch: 6| Step: 9
Training loss: 2.0603330383712013
Validation loss: 2.570171611290927

Epoch: 6| Step: 10
Training loss: 1.9340898590199143
Validation loss: 2.562841532207515

Epoch: 6| Step: 11
Training loss: 2.901037648790044
Validation loss: 2.574321507442027

Epoch: 6| Step: 12
Training loss: 2.3191437009148794
Validation loss: 2.5518574725005445

Epoch: 6| Step: 13
Training loss: 2.3770995647423443
Validation loss: 2.564822532309642

Epoch: 27| Step: 0
Training loss: 2.632561827365569
Validation loss: 2.5190475985366247

Epoch: 6| Step: 1
Training loss: 2.955008093085397
Validation loss: 2.5032994114710436

Epoch: 6| Step: 2
Training loss: 2.8627902620899066
Validation loss: 2.539589898526283

Epoch: 6| Step: 3
Training loss: 2.7752463875752125
Validation loss: 2.497207592077496

Epoch: 6| Step: 4
Training loss: 2.3959596241269963
Validation loss: 2.5084197674768416

Epoch: 6| Step: 5
Training loss: 2.199953867688706
Validation loss: 2.495694378745818

Epoch: 6| Step: 6
Training loss: 2.3730584289520684
Validation loss: 2.512427736701336

Epoch: 6| Step: 7
Training loss: 2.1360792915257285
Validation loss: 2.5419494492441452

Epoch: 6| Step: 8
Training loss: 2.490139301953516
Validation loss: 2.5385285270850724

Epoch: 6| Step: 9
Training loss: 2.814915954527717
Validation loss: 2.541715220211682

Epoch: 6| Step: 10
Training loss: 2.210840229819774
Validation loss: 2.554003905005321

Epoch: 6| Step: 11
Training loss: 2.5369460454909034
Validation loss: 2.5377759598630654

Epoch: 6| Step: 12
Training loss: 2.022870547721266
Validation loss: 2.522023264305474

Epoch: 6| Step: 13
Training loss: 2.23094971075963
Validation loss: 2.509448705076138

Epoch: 28| Step: 0
Training loss: 2.6785716411045537
Validation loss: 2.4944509991708608

Epoch: 6| Step: 1
Training loss: 2.6362629814425227
Validation loss: 2.53113745607954

Epoch: 6| Step: 2
Training loss: 2.4543395710664284
Validation loss: 2.5276397578900567

Epoch: 6| Step: 3
Training loss: 2.6614191359727197
Validation loss: 2.567316862419835

Epoch: 6| Step: 4
Training loss: 2.519127060754157
Validation loss: 2.6041193741636754

Epoch: 6| Step: 5
Training loss: 2.446899094347268
Validation loss: 2.5938373918632913

Epoch: 6| Step: 6
Training loss: 2.168748210279622
Validation loss: 2.594520148108321

Epoch: 6| Step: 7
Training loss: 2.31019745713534
Validation loss: 2.583750634687789

Epoch: 6| Step: 8
Training loss: 2.2917856936899668
Validation loss: 2.5826162809502917

Epoch: 6| Step: 9
Training loss: 2.3828780368484814
Validation loss: 2.561705210173838

Epoch: 6| Step: 10
Training loss: 2.244975519875187
Validation loss: 2.558032988232422

Epoch: 6| Step: 11
Training loss: 2.686234464533896
Validation loss: 2.5503718625488285

Epoch: 6| Step: 12
Training loss: 2.203092858911992
Validation loss: 2.518523305909691

Epoch: 6| Step: 13
Training loss: 3.180073782586705
Validation loss: 2.5113360092095496

Epoch: 29| Step: 0
Training loss: 2.4889714168686745
Validation loss: 2.5287034211179997

Epoch: 6| Step: 1
Training loss: 2.6866711957560465
Validation loss: 2.493206346060889

Epoch: 6| Step: 2
Training loss: 2.4650739510916475
Validation loss: 2.5228209318041133

Epoch: 6| Step: 3
Training loss: 2.5584659923077275
Validation loss: 2.490155626435629

Epoch: 6| Step: 4
Training loss: 2.146476377657986
Validation loss: 2.5040338873504955

Epoch: 6| Step: 5
Training loss: 2.774942167212151
Validation loss: 2.4883305151996464

Epoch: 6| Step: 6
Training loss: 2.1850155481968123
Validation loss: 2.4784620924054095

Epoch: 6| Step: 7
Training loss: 2.513111635982307
Validation loss: 2.480023009131967

Epoch: 6| Step: 8
Training loss: 2.5873646097190686
Validation loss: 2.4977642393546606

Epoch: 6| Step: 9
Training loss: 2.959092665097659
Validation loss: 2.4752477932841717

Epoch: 6| Step: 10
Training loss: 2.0337173735024354
Validation loss: 2.4967964787046584

Epoch: 6| Step: 11
Training loss: 1.9899341480343473
Validation loss: 2.4851561783669958

Epoch: 6| Step: 12
Training loss: 1.935526673551238
Validation loss: 2.5324138587292464

Epoch: 6| Step: 13
Training loss: 3.3707163434814404
Validation loss: 2.486674350346548

Epoch: 30| Step: 0
Training loss: 2.524701725933509
Validation loss: 2.5033465636225865

Epoch: 6| Step: 1
Training loss: 2.3393724377613268
Validation loss: 2.4891762952700285

Epoch: 6| Step: 2
Training loss: 2.7404984274227906
Validation loss: 2.537254589722528

Epoch: 6| Step: 3
Training loss: 2.4968866035277744
Validation loss: 2.500105076806869

Epoch: 6| Step: 4
Training loss: 2.4873704426060064
Validation loss: 2.547824245865465

Epoch: 6| Step: 5
Training loss: 2.099389750504638
Validation loss: 2.5673589539655692

Epoch: 6| Step: 6
Training loss: 2.053897604302006
Validation loss: 2.5612442537326747

Epoch: 6| Step: 7
Training loss: 2.162176088098193
Validation loss: 2.522067600665223

Epoch: 6| Step: 8
Training loss: 2.7414939416278896
Validation loss: 2.5506424060399926

Epoch: 6| Step: 9
Training loss: 1.6026551032027376
Validation loss: 2.4827181251407264

Epoch: 6| Step: 10
Training loss: 2.465211481149143
Validation loss: 2.5388332165606387

Epoch: 6| Step: 11
Training loss: 2.2163999765150684
Validation loss: 2.549289050756434

Epoch: 6| Step: 12
Training loss: 2.8544288756128813
Validation loss: 2.5431119270079323

Epoch: 6| Step: 13
Training loss: 2.7917591383312956
Validation loss: 2.5596249431556637

Epoch: 31| Step: 0
Training loss: 2.8809785462639605
Validation loss: 2.5317397958474457

Epoch: 6| Step: 1
Training loss: 2.803382336085792
Validation loss: 2.4771194393348805

Epoch: 6| Step: 2
Training loss: 2.5165816673762484
Validation loss: 2.5221042634414936

Epoch: 6| Step: 3
Training loss: 2.419097883258679
Validation loss: 2.5194966947172124

Epoch: 6| Step: 4
Training loss: 2.271767543680905
Validation loss: 2.4927876147553216

Epoch: 6| Step: 5
Training loss: 2.123184325989834
Validation loss: 2.506356883445415

Epoch: 6| Step: 6
Training loss: 2.307754389832571
Validation loss: 2.486470536286084

Epoch: 6| Step: 7
Training loss: 2.2233044796986854
Validation loss: 2.4925275628400243

Epoch: 6| Step: 8
Training loss: 2.2053516579819576
Validation loss: 2.5026488893914354

Epoch: 6| Step: 9
Training loss: 2.664727002273041
Validation loss: 2.5416055786629523

Epoch: 6| Step: 10
Training loss: 2.8081694429685617
Validation loss: 2.4982361134026387

Epoch: 6| Step: 11
Training loss: 2.6975014464027125
Validation loss: 2.490243901253225

Epoch: 6| Step: 12
Training loss: 2.3034752712690234
Validation loss: 2.517311320780765

Epoch: 6| Step: 13
Training loss: 2.1645545813150435
Validation loss: 2.508332698659299

Epoch: 32| Step: 0
Training loss: 2.72313573219228
Validation loss: 2.5474934675378123

Epoch: 6| Step: 1
Training loss: 2.396292556758904
Validation loss: 2.5325120362136677

Epoch: 6| Step: 2
Training loss: 2.885780357456952
Validation loss: 2.5342627284483688

Epoch: 6| Step: 3
Training loss: 2.976254745152779
Validation loss: 2.531738469593773

Epoch: 6| Step: 4
Training loss: 1.9995924415176916
Validation loss: 2.573252950666334

Epoch: 6| Step: 5
Training loss: 2.4996026677051946
Validation loss: 2.5640590003635

Epoch: 6| Step: 6
Training loss: 2.9717982654312056
Validation loss: 2.5414702438582815

Epoch: 6| Step: 7
Training loss: 2.0685608561274984
Validation loss: 2.5260222653827

Epoch: 6| Step: 8
Training loss: 2.292366845643359
Validation loss: 2.563026033078517

Epoch: 6| Step: 9
Training loss: 1.9595903731499582
Validation loss: 2.5525892080696226

Epoch: 6| Step: 10
Training loss: 2.5150163755395667
Validation loss: 2.5632317746468587

Epoch: 6| Step: 11
Training loss: 2.767270563086257
Validation loss: 2.5397460173983597

Epoch: 6| Step: 12
Training loss: 2.005092336759249
Validation loss: 2.5073752967908716

Epoch: 6| Step: 13
Training loss: 1.9294086208447876
Validation loss: 2.5260505099322024

Epoch: 33| Step: 0
Training loss: 1.8530111963023392
Validation loss: 2.5097663453889005

Epoch: 6| Step: 1
Training loss: 2.790878345912073
Validation loss: 2.539684020047428

Epoch: 6| Step: 2
Training loss: 2.6349653277206126
Validation loss: 2.494349356181525

Epoch: 6| Step: 3
Training loss: 3.1675066252219892
Validation loss: 2.550987605286238

Epoch: 6| Step: 4
Training loss: 2.4316904330993196
Validation loss: 2.525316229931853

Epoch: 6| Step: 5
Training loss: 1.800362958341678
Validation loss: 2.5515912003157655

Epoch: 6| Step: 6
Training loss: 1.56914860498072
Validation loss: 2.55087474049963

Epoch: 6| Step: 7
Training loss: 2.30329806584668
Validation loss: 2.545190421764227

Epoch: 6| Step: 8
Training loss: 2.2987833205064527
Validation loss: 2.5576118040956732

Epoch: 6| Step: 9
Training loss: 2.7246688781584947
Validation loss: 2.570782658053304

Epoch: 6| Step: 10
Training loss: 1.630145070693884
Validation loss: 2.5507372180045556

Epoch: 6| Step: 11
Training loss: 2.4036468693216775
Validation loss: 2.565006735769925

Epoch: 6| Step: 12
Training loss: 2.985230008821164
Validation loss: 2.5685158414767413

Epoch: 6| Step: 13
Training loss: 3.038546246217963
Validation loss: 2.5885852270215715

Epoch: 34| Step: 0
Training loss: 2.4427333307241126
Validation loss: 2.5256012260578635

Epoch: 6| Step: 1
Training loss: 2.4353165261396748
Validation loss: 2.507197129279698

Epoch: 6| Step: 2
Training loss: 2.759085299360632
Validation loss: 2.555798194833591

Epoch: 6| Step: 3
Training loss: 2.0294279876736994
Validation loss: 2.541893969726813

Epoch: 6| Step: 4
Training loss: 2.623857431161472
Validation loss: 2.575080322198025

Epoch: 6| Step: 5
Training loss: 2.6682475490310407
Validation loss: 2.569210500348386

Epoch: 6| Step: 6
Training loss: 2.479810444140275
Validation loss: 2.5544220672743805

Epoch: 6| Step: 7
Training loss: 2.012444167221561
Validation loss: 2.558252598195835

Epoch: 6| Step: 8
Training loss: 2.65193337143618
Validation loss: 2.52190408481117

Epoch: 6| Step: 9
Training loss: 2.592406510936187
Validation loss: 2.492746240689207

Epoch: 6| Step: 10
Training loss: 3.1885628517707447
Validation loss: 2.5139289809437826

Epoch: 6| Step: 11
Training loss: 2.241518565488841
Validation loss: 2.473110597157372

Epoch: 6| Step: 12
Training loss: 2.0423304069269372
Validation loss: 2.486162554234125

Epoch: 6| Step: 13
Training loss: 2.1542368903848574
Validation loss: 2.495757620103003

Epoch: 35| Step: 0
Training loss: 2.5533783617688957
Validation loss: 2.533276080647396

Epoch: 6| Step: 1
Training loss: 1.6203125323715868
Validation loss: 2.538493823410794

Epoch: 6| Step: 2
Training loss: 2.2906792565304355
Validation loss: 2.569837130074958

Epoch: 6| Step: 3
Training loss: 2.2345933073941406
Validation loss: 2.6188602548725246

Epoch: 6| Step: 4
Training loss: 2.9209018657514987
Validation loss: 2.674165543266418

Epoch: 6| Step: 5
Training loss: 2.323699226337699
Validation loss: 2.6621991424837343

Epoch: 6| Step: 6
Training loss: 2.350476391168798
Validation loss: 2.621856957344352

Epoch: 6| Step: 7
Training loss: 2.550799382891617
Validation loss: 2.6429158192580653

Epoch: 6| Step: 8
Training loss: 2.9661196650868193
Validation loss: 2.602568545481648

Epoch: 6| Step: 9
Training loss: 2.901405480593394
Validation loss: 2.5408433430133486

Epoch: 6| Step: 10
Training loss: 2.0254107541414763
Validation loss: 2.54484844126214

Epoch: 6| Step: 11
Training loss: 1.9479119883870404
Validation loss: 2.508566920175493

Epoch: 6| Step: 12
Training loss: 2.7126582508245676
Validation loss: 2.4829946958039937

Epoch: 6| Step: 13
Training loss: 2.7007776553323453
Validation loss: 2.4819299113849

Epoch: 36| Step: 0
Training loss: 2.4942553321312624
Validation loss: 2.511372622959384

Epoch: 6| Step: 1
Training loss: 2.3405702510690016
Validation loss: 2.5078231953900874

Epoch: 6| Step: 2
Training loss: 2.5525023654848322
Validation loss: 2.488593001625918

Epoch: 6| Step: 3
Training loss: 2.0997728860749922
Validation loss: 2.5144090418763585

Epoch: 6| Step: 4
Training loss: 2.650108957749767
Validation loss: 2.50522842452042

Epoch: 6| Step: 5
Training loss: 2.060321119334705
Validation loss: 2.5015402023080964

Epoch: 6| Step: 6
Training loss: 3.0473521323627373
Validation loss: 2.5003227502388445

Epoch: 6| Step: 7
Training loss: 2.14662898846054
Validation loss: 2.4985692221514877

Epoch: 6| Step: 8
Training loss: 2.3816057995688107
Validation loss: 2.485771570396452

Epoch: 6| Step: 9
Training loss: 1.9453451621136315
Validation loss: 2.4990819039958327

Epoch: 6| Step: 10
Training loss: 3.0369322697557783
Validation loss: 2.483570592435695

Epoch: 6| Step: 11
Training loss: 2.8643670202714677
Validation loss: 2.5156752302948107

Epoch: 6| Step: 12
Training loss: 2.1885549998493805
Validation loss: 2.512181264672891

Epoch: 6| Step: 13
Training loss: 2.039100149691327
Validation loss: 2.55899361550659

Epoch: 37| Step: 0
Training loss: 3.094064715783124
Validation loss: 2.51802504513349

Epoch: 6| Step: 1
Training loss: 2.7967478121176677
Validation loss: 2.5652920546034284

Epoch: 6| Step: 2
Training loss: 2.0927900704396185
Validation loss: 2.5241302232282896

Epoch: 6| Step: 3
Training loss: 1.677980700207957
Validation loss: 2.5022633320787393

Epoch: 6| Step: 4
Training loss: 2.627219760225259
Validation loss: 2.5437227724134956

Epoch: 6| Step: 5
Training loss: 2.7512164459886144
Validation loss: 2.5321246233418195

Epoch: 6| Step: 6
Training loss: 2.772898189063717
Validation loss: 2.511029470737934

Epoch: 6| Step: 7
Training loss: 2.5152831230291675
Validation loss: 2.4944332372356532

Epoch: 6| Step: 8
Training loss: 2.1422053163150667
Validation loss: 2.53620753265719

Epoch: 6| Step: 9
Training loss: 2.312963284660819
Validation loss: 2.5029516835560295

Epoch: 6| Step: 10
Training loss: 2.1972562933829622
Validation loss: 2.5319586181894915

Epoch: 6| Step: 11
Training loss: 2.8597065050746058
Validation loss: 2.4771451134406126

Epoch: 6| Step: 12
Training loss: 1.6771850397139207
Validation loss: 2.5070173323987843

Epoch: 6| Step: 13
Training loss: 2.049441643015536
Validation loss: 2.5117338742700106

Epoch: 38| Step: 0
Training loss: 2.6088389685557405
Validation loss: 2.4864346026175252

Epoch: 6| Step: 1
Training loss: 2.376696231848973
Validation loss: 2.492117263936284

Epoch: 6| Step: 2
Training loss: 2.165977979905621
Validation loss: 2.5609218110493632

Epoch: 6| Step: 3
Training loss: 2.5328808464039674
Validation loss: 2.5485836140751457

Epoch: 6| Step: 4
Training loss: 3.0248889051482153
Validation loss: 2.546001620019206

Epoch: 6| Step: 5
Training loss: 2.6295675775084844
Validation loss: 2.4923945612974645

Epoch: 6| Step: 6
Training loss: 2.0160482982344963
Validation loss: 2.541153579786633

Epoch: 6| Step: 7
Training loss: 2.5181305532993066
Validation loss: 2.4920820096289913

Epoch: 6| Step: 8
Training loss: 2.467952937612569
Validation loss: 2.5232276789904633

Epoch: 6| Step: 9
Training loss: 2.0857550723423297
Validation loss: 2.519701385667955

Epoch: 6| Step: 10
Training loss: 1.8098960455658786
Validation loss: 2.4990331767107223

Epoch: 6| Step: 11
Training loss: 2.440321243276332
Validation loss: 2.509007502938287

Epoch: 6| Step: 12
Training loss: 3.150452378502012
Validation loss: 2.4912825867824395

Epoch: 6| Step: 13
Training loss: 1.924500943182429
Validation loss: 2.5031801977274672

Epoch: 39| Step: 0
Training loss: 1.5392386243708696
Validation loss: 2.533141234187667

Epoch: 6| Step: 1
Training loss: 1.8141542317856916
Validation loss: 2.524392985410278

Epoch: 6| Step: 2
Training loss: 2.831235408113784
Validation loss: 2.5319697451750027

Epoch: 6| Step: 3
Training loss: 2.9906464036835305
Validation loss: 2.5923295938468853

Epoch: 6| Step: 4
Training loss: 1.9231489967631787
Validation loss: 2.6292997597581422

Epoch: 6| Step: 5
Training loss: 1.6881858703417865
Validation loss: 2.5876298113217193

Epoch: 6| Step: 6
Training loss: 3.0109635926537903
Validation loss: 2.545572162182526

Epoch: 6| Step: 7
Training loss: 1.9879250797607286
Validation loss: 2.5796715769593077

Epoch: 6| Step: 8
Training loss: 2.5073824599948242
Validation loss: 2.5961398562663915

Epoch: 6| Step: 9
Training loss: 2.063448601103146
Validation loss: 2.583074038833778

Epoch: 6| Step: 10
Training loss: 3.2632078141051806
Validation loss: 2.5198384888677383

Epoch: 6| Step: 11
Training loss: 1.5341019832326976
Validation loss: 2.5710701642209868

Epoch: 6| Step: 12
Training loss: 2.904294248065389
Validation loss: 2.536667869315278

Epoch: 6| Step: 13
Training loss: 2.429708695395895
Validation loss: 2.502162339940103

Epoch: 40| Step: 0
Training loss: 2.133930737573558
Validation loss: 2.490543776096717

Epoch: 6| Step: 1
Training loss: 2.0037831051115096
Validation loss: 2.4900549969861605

Epoch: 6| Step: 2
Training loss: 2.976828575757395
Validation loss: 2.49965540577316

Epoch: 6| Step: 3
Training loss: 2.492003239722924
Validation loss: 2.470540335095808

Epoch: 6| Step: 4
Training loss: 2.462102898660767
Validation loss: 2.5395520956002655

Epoch: 6| Step: 5
Training loss: 2.1068929126830143
Validation loss: 2.5104854991124053

Epoch: 6| Step: 6
Training loss: 1.9414190219021539
Validation loss: 2.4449374690312515

Epoch: 6| Step: 7
Training loss: 2.3938141537826914
Validation loss: 2.501260646229941

Epoch: 6| Step: 8
Training loss: 2.273447462761407
Validation loss: 2.520040187641395

Epoch: 6| Step: 9
Training loss: 2.8501466345291555
Validation loss: 2.491190265373855

Epoch: 6| Step: 10
Training loss: 2.106727124968288
Validation loss: 2.5221186006950758

Epoch: 6| Step: 11
Training loss: 1.9969670425239876
Validation loss: 2.488130877316268

Epoch: 6| Step: 12
Training loss: 2.7378131286738805
Validation loss: 2.5139821455596394

Epoch: 6| Step: 13
Training loss: 2.65767613441806
Validation loss: 2.4981757104183866

Epoch: 41| Step: 0
Training loss: 2.2231831923218373
Validation loss: 2.4967844151316565

Epoch: 6| Step: 1
Training loss: 2.747591611325849
Validation loss: 2.513024164438099

Epoch: 6| Step: 2
Training loss: 2.582431410167599
Validation loss: 2.5635428283845845

Epoch: 6| Step: 3
Training loss: 1.6722592776738772
Validation loss: 2.578440097857923

Epoch: 6| Step: 4
Training loss: 1.9100002857028289
Validation loss: 2.6117004722528474

Epoch: 6| Step: 5
Training loss: 1.9655118682277875
Validation loss: 2.6589877511945414

Epoch: 6| Step: 6
Training loss: 2.9440063494530913
Validation loss: 2.667879280909903

Epoch: 6| Step: 7
Training loss: 2.4260537797607165
Validation loss: 2.6759460918207356

Epoch: 6| Step: 8
Training loss: 2.6251376887949776
Validation loss: 2.608438647422174

Epoch: 6| Step: 9
Training loss: 2.20963715504698
Validation loss: 2.589583516651576

Epoch: 6| Step: 10
Training loss: 2.726354028115405
Validation loss: 2.5308623468391707

Epoch: 6| Step: 11
Training loss: 2.2805650283651846
Validation loss: 2.5008358670655833

Epoch: 6| Step: 12
Training loss: 2.2050186568182375
Validation loss: 2.5173136885696135

Epoch: 6| Step: 13
Training loss: 2.885145282492101
Validation loss: 2.5089877534863683

Epoch: 42| Step: 0
Training loss: 3.1167977072627036
Validation loss: 2.516991538327462

Epoch: 6| Step: 1
Training loss: 2.165257533660316
Validation loss: 2.4960970612425872

Epoch: 6| Step: 2
Training loss: 2.0259023845688513
Validation loss: 2.4922976494406703

Epoch: 6| Step: 3
Training loss: 2.5575756114771764
Validation loss: 2.515199992606476

Epoch: 6| Step: 4
Training loss: 1.966548233453299
Validation loss: 2.4840414915013485

Epoch: 6| Step: 5
Training loss: 2.6228356294079127
Validation loss: 2.5286294220936263

Epoch: 6| Step: 6
Training loss: 2.1915919587295702
Validation loss: 2.4892975764230756

Epoch: 6| Step: 7
Training loss: 2.0834736077449896
Validation loss: 2.4936471329890977

Epoch: 6| Step: 8
Training loss: 2.5431634737574678
Validation loss: 2.468723973004245

Epoch: 6| Step: 9
Training loss: 2.044062188712281
Validation loss: 2.5212498365435896

Epoch: 6| Step: 10
Training loss: 2.668797734211113
Validation loss: 2.533142167541524

Epoch: 6| Step: 11
Training loss: 2.7142874387864677
Validation loss: 2.505866288819541

Epoch: 6| Step: 12
Training loss: 2.1200944713920067
Validation loss: 2.507040330762021

Epoch: 6| Step: 13
Training loss: 2.5106525442233023
Validation loss: 2.576377816075068

Epoch: 43| Step: 0
Training loss: 2.4367699141052137
Validation loss: 2.583284098145747

Epoch: 6| Step: 1
Training loss: 2.5707775495300016
Validation loss: 2.5370289097478134

Epoch: 6| Step: 2
Training loss: 2.579295684430571
Validation loss: 2.559878287476759

Epoch: 6| Step: 3
Training loss: 2.246416204774993
Validation loss: 2.504700755343837

Epoch: 6| Step: 4
Training loss: 1.5000499081256182
Validation loss: 2.5564035685080455

Epoch: 6| Step: 5
Training loss: 1.9205592543983514
Validation loss: 2.495217373921215

Epoch: 6| Step: 6
Training loss: 2.7520395865032814
Validation loss: 2.4947371480210427

Epoch: 6| Step: 7
Training loss: 2.9027580694556754
Validation loss: 2.5208038112918865

Epoch: 6| Step: 8
Training loss: 2.850207364753436
Validation loss: 2.5063570736965093

Epoch: 6| Step: 9
Training loss: 1.906123297811225
Validation loss: 2.5265616337309362

Epoch: 6| Step: 10
Training loss: 2.703603007658939
Validation loss: 2.486076731831861

Epoch: 6| Step: 11
Training loss: 2.354036873359305
Validation loss: 2.5003031387919883

Epoch: 6| Step: 12
Training loss: 2.5745678029721475
Validation loss: 2.5321045834033225

Epoch: 6| Step: 13
Training loss: 2.1178225307443763
Validation loss: 2.5380017064907707

Epoch: 44| Step: 0
Training loss: 2.258980630353383
Validation loss: 2.4997509991302715

Epoch: 6| Step: 1
Training loss: 2.206497965161915
Validation loss: 2.5473821872201907

Epoch: 6| Step: 2
Training loss: 1.722886396678015
Validation loss: 2.50406286391565

Epoch: 6| Step: 3
Training loss: 2.4692310878534975
Validation loss: 2.4938527983954666

Epoch: 6| Step: 4
Training loss: 2.637936188123413
Validation loss: 2.490020343832738

Epoch: 6| Step: 5
Training loss: 2.3210841478825177
Validation loss: 2.497519589812845

Epoch: 6| Step: 6
Training loss: 2.759268659916547
Validation loss: 2.5287074910800853

Epoch: 6| Step: 7
Training loss: 2.1668664277740355
Validation loss: 2.4702530160651373

Epoch: 6| Step: 8
Training loss: 2.450129630104331
Validation loss: 2.489675900535333

Epoch: 6| Step: 9
Training loss: 2.9431654493493316
Validation loss: 2.4814878597963053

Epoch: 6| Step: 10
Training loss: 2.4516975477474996
Validation loss: 2.504190326669878

Epoch: 6| Step: 11
Training loss: 1.8890029001733701
Validation loss: 2.4982648550076916

Epoch: 6| Step: 12
Training loss: 2.3255299692234344
Validation loss: 2.4858230113694257

Epoch: 6| Step: 13
Training loss: 2.8787164302033053
Validation loss: 2.5670958608073877

Epoch: 45| Step: 0
Training loss: 2.145857826265961
Validation loss: 2.5426558044667

Epoch: 6| Step: 1
Training loss: 2.2446973623011037
Validation loss: 2.5851868368740853

Epoch: 6| Step: 2
Training loss: 2.664488459119179
Validation loss: 2.5845580095027

Epoch: 6| Step: 3
Training loss: 1.6847926427106348
Validation loss: 2.559737026272752

Epoch: 6| Step: 4
Training loss: 2.5919612553550015
Validation loss: 2.6042906515488533

Epoch: 6| Step: 5
Training loss: 2.819047385216363
Validation loss: 2.588582356451028

Epoch: 6| Step: 6
Training loss: 2.341449880463942
Validation loss: 2.538487624599007

Epoch: 6| Step: 7
Training loss: 2.0147009808950394
Validation loss: 2.5810039282897828

Epoch: 6| Step: 8
Training loss: 2.503291442899868
Validation loss: 2.576877376886222

Epoch: 6| Step: 9
Training loss: 2.471964035649079
Validation loss: 2.5420820074031587

Epoch: 6| Step: 10
Training loss: 2.004869136772951
Validation loss: 2.548976694115496

Epoch: 6| Step: 11
Training loss: 2.5589781960098463
Validation loss: 2.5214505044369657

Epoch: 6| Step: 12
Training loss: 2.350111707102059
Validation loss: 2.4966058578861317

Epoch: 6| Step: 13
Training loss: 2.283008159213497
Validation loss: 2.524547195121355

Epoch: 46| Step: 0
Training loss: 2.807820050415688
Validation loss: 2.492900144596767

Epoch: 6| Step: 1
Training loss: 1.8029978054411995
Validation loss: 2.4959708966113276

Epoch: 6| Step: 2
Training loss: 2.0844599030230326
Validation loss: 2.472437056899651

Epoch: 6| Step: 3
Training loss: 2.349175543938037
Validation loss: 2.499836185174526

Epoch: 6| Step: 4
Training loss: 2.3887451360264738
Validation loss: 2.465225085440098

Epoch: 6| Step: 5
Training loss: 2.2062286808183393
Validation loss: 2.5099520563331574

Epoch: 6| Step: 6
Training loss: 2.8125584914165183
Validation loss: 2.512199209563767

Epoch: 6| Step: 7
Training loss: 2.2563711667481856
Validation loss: 2.499026299639334

Epoch: 6| Step: 8
Training loss: 2.3567706759682845
Validation loss: 2.5249834236381474

Epoch: 6| Step: 9
Training loss: 2.2643773293753005
Validation loss: 2.5041821308473065

Epoch: 6| Step: 10
Training loss: 2.8241263937721497
Validation loss: 2.4916442310849902

Epoch: 6| Step: 11
Training loss: 2.5093760147187685
Validation loss: 2.4780463938615043

Epoch: 6| Step: 12
Training loss: 2.632475426714069
Validation loss: 2.5244369968181695

Epoch: 6| Step: 13
Training loss: 1.6328564505616743
Validation loss: 2.4831795125297424

Epoch: 47| Step: 0
Training loss: 2.220887457478519
Validation loss: 2.462908614413344

Epoch: 6| Step: 1
Training loss: 1.9420982677925172
Validation loss: 2.514095797257997

Epoch: 6| Step: 2
Training loss: 2.272808813886461
Validation loss: 2.502646936427598

Epoch: 6| Step: 3
Training loss: 2.598015001807241
Validation loss: 2.505434756974707

Epoch: 6| Step: 4
Training loss: 2.036577252154138
Validation loss: 2.531837552171211

Epoch: 6| Step: 5
Training loss: 2.815057143042999
Validation loss: 2.5140165948717135

Epoch: 6| Step: 6
Training loss: 2.0828770964464915
Validation loss: 2.5057138632163847

Epoch: 6| Step: 7
Training loss: 2.2132264275566134
Validation loss: 2.525813634483708

Epoch: 6| Step: 8
Training loss: 3.003879899205782
Validation loss: 2.506220675809799

Epoch: 6| Step: 9
Training loss: 2.731319966063852
Validation loss: 2.499402690103528

Epoch: 6| Step: 10
Training loss: 2.2278284589795416
Validation loss: 2.5364993886477545

Epoch: 6| Step: 11
Training loss: 2.4318053408067373
Validation loss: 2.5492689275250595

Epoch: 6| Step: 12
Training loss: 2.1226059386433835
Validation loss: 2.5156795582669913

Epoch: 6| Step: 13
Training loss: 2.0029865853845523
Validation loss: 2.531833204735686

Epoch: 48| Step: 0
Training loss: 1.6330008512215577
Validation loss: 2.535089093197057

Epoch: 6| Step: 1
Training loss: 2.6692675979718707
Validation loss: 2.5658851067313675

Epoch: 6| Step: 2
Training loss: 2.3899266837458466
Validation loss: 2.4947462031310734

Epoch: 6| Step: 3
Training loss: 2.1811059417810177
Validation loss: 2.5294759522502863

Epoch: 6| Step: 4
Training loss: 1.66694541825319
Validation loss: 2.512073616362943

Epoch: 6| Step: 5
Training loss: 2.767503951430838
Validation loss: 2.534897832724041

Epoch: 6| Step: 6
Training loss: 1.6331714436364886
Validation loss: 2.5483951049746096

Epoch: 6| Step: 7
Training loss: 1.6668048165603522
Validation loss: 2.4669567145972735

Epoch: 6| Step: 8
Training loss: 2.885966903792834
Validation loss: 2.5238840753198386

Epoch: 6| Step: 9
Training loss: 2.2733445820385616
Validation loss: 2.483170399238411

Epoch: 6| Step: 10
Training loss: 2.9651435228062475
Validation loss: 2.4991423884280257

Epoch: 6| Step: 11
Training loss: 2.1755982464134695
Validation loss: 2.546192327329091

Epoch: 6| Step: 12
Training loss: 2.8751751390268603
Validation loss: 2.4730446396462447

Epoch: 6| Step: 13
Training loss: 2.199630021283076
Validation loss: 2.525073581038906

Epoch: 49| Step: 0
Training loss: 2.0656724286657964
Validation loss: 2.5218363623828313

Epoch: 6| Step: 1
Training loss: 2.3559494919730404
Validation loss: 2.5039211199354106

Epoch: 6| Step: 2
Training loss: 2.100539855593443
Validation loss: 2.539081186079077

Epoch: 6| Step: 3
Training loss: 2.0923965406648497
Validation loss: 2.5322042636598123

Epoch: 6| Step: 4
Training loss: 2.5355491392518967
Validation loss: 2.6166311099639366

Epoch: 6| Step: 5
Training loss: 1.2679502531666256
Validation loss: 2.6307728580181577

Epoch: 6| Step: 6
Training loss: 2.530227831507174
Validation loss: 2.611546311622917

Epoch: 6| Step: 7
Training loss: 2.7111045060398684
Validation loss: 2.575838843995585

Epoch: 6| Step: 8
Training loss: 2.7525427073700413
Validation loss: 2.5482934539581907

Epoch: 6| Step: 9
Training loss: 1.4428614272360205
Validation loss: 2.4959376867913625

Epoch: 6| Step: 10
Training loss: 3.288762674687841
Validation loss: 2.526120353076197

Epoch: 6| Step: 11
Training loss: 2.3971204092428673
Validation loss: 2.4557411999911607

Epoch: 6| Step: 12
Training loss: 2.7303248464404093
Validation loss: 2.488538184841483

Epoch: 6| Step: 13
Training loss: 2.4473169660853116
Validation loss: 2.466253765017611

Epoch: 50| Step: 0
Training loss: 2.1319657765445434
Validation loss: 2.457640555661075

Epoch: 6| Step: 1
Training loss: 2.1428439480511554
Validation loss: 2.5187850754080685

Epoch: 6| Step: 2
Training loss: 1.837085251484515
Validation loss: 2.4840475062477148

Epoch: 6| Step: 3
Training loss: 2.348381247896864
Validation loss: 2.4986908345853474

Epoch: 6| Step: 4
Training loss: 2.23090503921757
Validation loss: 2.516610515254375

Epoch: 6| Step: 5
Training loss: 2.436747899543105
Validation loss: 2.5350165659271027

Epoch: 6| Step: 6
Training loss: 2.1792230145358045
Validation loss: 2.5385969625301525

Epoch: 6| Step: 7
Training loss: 2.0324839438617133
Validation loss: 2.5214440470335977

Epoch: 6| Step: 8
Training loss: 2.9578832006292024
Validation loss: 2.5316124173903014

Epoch: 6| Step: 9
Training loss: 2.743365955630056
Validation loss: 2.5266621931920503

Epoch: 6| Step: 10
Training loss: 2.5329572783315037
Validation loss: 2.551274920249492

Epoch: 6| Step: 11
Training loss: 2.425989998943851
Validation loss: 2.538049208113664

Epoch: 6| Step: 12
Training loss: 2.219316544532394
Validation loss: 2.4777648766737252

Epoch: 6| Step: 13
Training loss: 2.290212817402112
Validation loss: 2.5125652368025064

Epoch: 51| Step: 0
Training loss: 2.0989202175670982
Validation loss: 2.5031105161732805

Epoch: 6| Step: 1
Training loss: 1.7031175805726437
Validation loss: 2.514710909860618

Epoch: 6| Step: 2
Training loss: 1.97816806161784
Validation loss: 2.5620740520983123

Epoch: 6| Step: 3
Training loss: 2.1299354235392363
Validation loss: 2.5107654207930947

Epoch: 6| Step: 4
Training loss: 2.308301671587937
Validation loss: 2.5289653074706413

Epoch: 6| Step: 5
Training loss: 2.5157594822543135
Validation loss: 2.513716477218475

Epoch: 6| Step: 6
Training loss: 2.912475153608309
Validation loss: 2.4768442821948193

Epoch: 6| Step: 7
Training loss: 2.088987713475889
Validation loss: 2.468399183883289

Epoch: 6| Step: 8
Training loss: 1.7381942898718952
Validation loss: 2.5183545975215504

Epoch: 6| Step: 9
Training loss: 2.583215669803106
Validation loss: 2.470230817319005

Epoch: 6| Step: 10
Training loss: 2.2053211710055196
Validation loss: 2.512025299270857

Epoch: 6| Step: 11
Training loss: 3.1638792385199377
Validation loss: 2.481017220801897

Epoch: 6| Step: 12
Training loss: 1.6660224225709435
Validation loss: 2.466648559460894

Epoch: 6| Step: 13
Training loss: 2.6880826983729937
Validation loss: 2.5002265827496295

Epoch: 52| Step: 0
Training loss: 2.665508873255867
Validation loss: 2.49395889898724

Epoch: 6| Step: 1
Training loss: 2.192274496210691
Validation loss: 2.522957188233333

Epoch: 6| Step: 2
Training loss: 2.642945032241671
Validation loss: 2.4683858546564097

Epoch: 6| Step: 3
Training loss: 2.1612686135244523
Validation loss: 2.489189744639513

Epoch: 6| Step: 4
Training loss: 2.233837142977898
Validation loss: 2.5125542611103553

Epoch: 6| Step: 5
Training loss: 2.637925703938747
Validation loss: 2.5306819859296614

Epoch: 6| Step: 6
Training loss: 2.161255706726624
Validation loss: 2.5464446439460646

Epoch: 6| Step: 7
Training loss: 2.1329237241703374
Validation loss: 2.4945940060183074

Epoch: 6| Step: 8
Training loss: 2.2913442442679246
Validation loss: 2.4850032339964097

Epoch: 6| Step: 9
Training loss: 2.648867051840314
Validation loss: 2.507152561649746

Epoch: 6| Step: 10
Training loss: 2.272778182759986
Validation loss: 2.5444054205186406

Epoch: 6| Step: 11
Training loss: 2.230591458287281
Validation loss: 2.4879199873144446

Epoch: 6| Step: 12
Training loss: 1.8811425365284833
Validation loss: 2.5321408340765768

Epoch: 6| Step: 13
Training loss: 1.874204721275068
Validation loss: 2.5439268027307658

Epoch: 53| Step: 0
Training loss: 2.485918633121464
Validation loss: 2.547431136184149

Epoch: 6| Step: 1
Training loss: 2.3867892740322203
Validation loss: 2.50799206559256

Epoch: 6| Step: 2
Training loss: 2.365762716137217
Validation loss: 2.5459493737587504

Epoch: 6| Step: 3
Training loss: 1.6874683518444316
Validation loss: 2.5299182575324326

Epoch: 6| Step: 4
Training loss: 2.778248742762274
Validation loss: 2.4836552055045633

Epoch: 6| Step: 5
Training loss: 2.485788195314583
Validation loss: 2.4859103530817768

Epoch: 6| Step: 6
Training loss: 1.9608649738167547
Validation loss: 2.5530317659136323

Epoch: 6| Step: 7
Training loss: 2.3323931389276127
Validation loss: 2.5053938217386147

Epoch: 6| Step: 8
Training loss: 1.9197718580124061
Validation loss: 2.5079954086578056

Epoch: 6| Step: 9
Training loss: 2.244694282089199
Validation loss: 2.555779428857855

Epoch: 6| Step: 10
Training loss: 2.080033881204931
Validation loss: 2.4889994352868046

Epoch: 6| Step: 11
Training loss: 2.2831672032567707
Validation loss: 2.5428864465257823

Epoch: 6| Step: 12
Training loss: 2.8993747563330157
Validation loss: 2.5056295272140474

Epoch: 6| Step: 13
Training loss: 2.0102372427085955
Validation loss: 2.487942467447496

Epoch: 54| Step: 0
Training loss: 2.48643542565377
Validation loss: 2.5076942772495263

Epoch: 6| Step: 1
Training loss: 2.2640613290008402
Validation loss: 2.5182522151698317

Epoch: 6| Step: 2
Training loss: 1.9318181063402131
Validation loss: 2.534453056942755

Epoch: 6| Step: 3
Training loss: 2.5971348748390923
Validation loss: 2.493774897069466

Epoch: 6| Step: 4
Training loss: 1.8369228884025077
Validation loss: 2.5482911617348183

Epoch: 6| Step: 5
Training loss: 2.2872555211232286
Validation loss: 2.5405745166175087

Epoch: 6| Step: 6
Training loss: 2.020011682382171
Validation loss: 2.5271142681479075

Epoch: 6| Step: 7
Training loss: 2.6624905151771343
Validation loss: 2.564040566055549

Epoch: 6| Step: 8
Training loss: 2.820930814725612
Validation loss: 2.5091237634010164

Epoch: 6| Step: 9
Training loss: 2.2338932825210946
Validation loss: 2.5177338095530675

Epoch: 6| Step: 10
Training loss: 2.2518353923582746
Validation loss: 2.5150117304321715

Epoch: 6| Step: 11
Training loss: 2.9479175652995724
Validation loss: 2.472024235197151

Epoch: 6| Step: 12
Training loss: 1.9573172780936727
Validation loss: 2.4894291472206795

Epoch: 6| Step: 13
Training loss: 2.216207632659253
Validation loss: 2.5501260115460958

Epoch: 55| Step: 0
Training loss: 1.9783113605764857
Validation loss: 2.484541753454797

Epoch: 6| Step: 1
Training loss: 2.826683815313299
Validation loss: 2.545825429946777

Epoch: 6| Step: 2
Training loss: 2.3805593375086063
Validation loss: 2.499073174654848

Epoch: 6| Step: 3
Training loss: 3.0137345313075126
Validation loss: 2.548709544106612

Epoch: 6| Step: 4
Training loss: 2.283859641497381
Validation loss: 2.4885965623598394

Epoch: 6| Step: 5
Training loss: 2.5195957855712603
Validation loss: 2.5397108766251213

Epoch: 6| Step: 6
Training loss: 2.137353778321702
Validation loss: 2.504400068715648

Epoch: 6| Step: 7
Training loss: 2.306900978737905
Validation loss: 2.5759908686307216

Epoch: 6| Step: 8
Training loss: 2.1590299515583555
Validation loss: 2.5432508695948353

Epoch: 6| Step: 9
Training loss: 2.2955270561762515
Validation loss: 2.5303635791586845

Epoch: 6| Step: 10
Training loss: 2.7148592063408934
Validation loss: 2.544137353171157

Epoch: 6| Step: 11
Training loss: 1.7162328147166697
Validation loss: 2.548143893756547

Epoch: 6| Step: 12
Training loss: 1.8303115028247068
Validation loss: 2.5367490900745504

Epoch: 6| Step: 13
Training loss: 1.9943661015861058
Validation loss: 2.5113122115681987

Epoch: 56| Step: 0
Training loss: 2.426010145608014
Validation loss: 2.4789401092445034

Epoch: 6| Step: 1
Training loss: 2.051553519026658
Validation loss: 2.503749007327841

Epoch: 6| Step: 2
Training loss: 2.2684765989909788
Validation loss: 2.5051931723111456

Epoch: 6| Step: 3
Training loss: 2.5210111781246614
Validation loss: 2.5059495068755733

Epoch: 6| Step: 4
Training loss: 2.6166779434868213
Validation loss: 2.4967778740406588

Epoch: 6| Step: 5
Training loss: 2.1759143836554737
Validation loss: 2.5255306447985078

Epoch: 6| Step: 6
Training loss: 2.702964998482226
Validation loss: 2.5002502792963957

Epoch: 6| Step: 7
Training loss: 1.4494886943774945
Validation loss: 2.4524141808497153

Epoch: 6| Step: 8
Training loss: 2.453787258679561
Validation loss: 2.503780399518224

Epoch: 6| Step: 9
Training loss: 2.046513765797194
Validation loss: 2.4964876694892046

Epoch: 6| Step: 10
Training loss: 2.316683927878789
Validation loss: 2.4804518170917693

Epoch: 6| Step: 11
Training loss: 2.426990447224795
Validation loss: 2.564680118010213

Epoch: 6| Step: 12
Training loss: 1.8713348169668578
Validation loss: 2.5626849596215506

Epoch: 6| Step: 13
Training loss: 2.6307305047432026
Validation loss: 2.551081952708541

Epoch: 57| Step: 0
Training loss: 2.1131201381226883
Validation loss: 2.57706870586548

Epoch: 6| Step: 1
Training loss: 1.4227377820520095
Validation loss: 2.6060017770193684

Epoch: 6| Step: 2
Training loss: 1.5098967698791623
Validation loss: 2.647595342012634

Epoch: 6| Step: 3
Training loss: 2.428085142223341
Validation loss: 2.6297611246665182

Epoch: 6| Step: 4
Training loss: 3.049012046021975
Validation loss: 2.6521355870790964

Epoch: 6| Step: 5
Training loss: 1.8161937302171076
Validation loss: 2.628317734481138

Epoch: 6| Step: 6
Training loss: 1.9446864825182764
Validation loss: 2.613772100509938

Epoch: 6| Step: 7
Training loss: 1.8074494072256009
Validation loss: 2.5590042212092317

Epoch: 6| Step: 8
Training loss: 2.0497967782124684
Validation loss: 2.5710824356286075

Epoch: 6| Step: 9
Training loss: 2.508252637036136
Validation loss: 2.5478289793141227

Epoch: 6| Step: 10
Training loss: 2.002016005110048
Validation loss: 2.532247346850864

Epoch: 6| Step: 11
Training loss: 2.641188882968262
Validation loss: 2.4942575943577503

Epoch: 6| Step: 12
Training loss: 2.810038527906746
Validation loss: 2.493075460734077

Epoch: 6| Step: 13
Training loss: 2.4244142080442335
Validation loss: 2.4291670426836807

Epoch: 58| Step: 0
Training loss: 3.0796203079519238
Validation loss: 2.5158525762825543

Epoch: 6| Step: 1
Training loss: 1.5576240754647859
Validation loss: 2.509749127245955

Epoch: 6| Step: 2
Training loss: 2.287655134099815
Validation loss: 2.5102122185320033

Epoch: 6| Step: 3
Training loss: 2.5226357901916905
Validation loss: 2.587603167997229

Epoch: 6| Step: 4
Training loss: 2.1609297017848377
Validation loss: 2.511851036816152

Epoch: 6| Step: 5
Training loss: 1.7669619334491682
Validation loss: 2.523934369531702

Epoch: 6| Step: 6
Training loss: 2.3519874771718996
Validation loss: 2.5013139768466965

Epoch: 6| Step: 7
Training loss: 2.597123124333773
Validation loss: 2.5481766415015557

Epoch: 6| Step: 8
Training loss: 2.8967619214420437
Validation loss: 2.488126980537138

Epoch: 6| Step: 9
Training loss: 1.6021977351118248
Validation loss: 2.4853659998506257

Epoch: 6| Step: 10
Training loss: 1.832127615340212
Validation loss: 2.4705539663370852

Epoch: 6| Step: 11
Training loss: 2.2780378536934163
Validation loss: 2.500689761057281

Epoch: 6| Step: 12
Training loss: 2.50806879653146
Validation loss: 2.583962922645149

Epoch: 6| Step: 13
Training loss: 2.192200107225531
Validation loss: 2.571551711203185

Epoch: 59| Step: 0
Training loss: 2.6334493076362593
Validation loss: 2.583335312463146

Epoch: 6| Step: 1
Training loss: 2.795794656621514
Validation loss: 2.5419362086803923

Epoch: 6| Step: 2
Training loss: 1.7598722470040677
Validation loss: 2.5987965769811714

Epoch: 6| Step: 3
Training loss: 2.221050949838239
Validation loss: 2.5702413531720922

Epoch: 6| Step: 4
Training loss: 2.104021753539558
Validation loss: 2.5462444437572174

Epoch: 6| Step: 5
Training loss: 2.595533010908891
Validation loss: 2.6076437256880083

Epoch: 6| Step: 6
Training loss: 2.4334953863798936
Validation loss: 2.519926969615395

Epoch: 6| Step: 7
Training loss: 1.7335502794410371
Validation loss: 2.4765639440490173

Epoch: 6| Step: 8
Training loss: 2.193150443285258
Validation loss: 2.5114157549807317

Epoch: 6| Step: 9
Training loss: 2.1796599355615967
Validation loss: 2.482776679518216

Epoch: 6| Step: 10
Training loss: 2.609958423561051
Validation loss: 2.5109166297765313

Epoch: 6| Step: 11
Training loss: 2.003925286215625
Validation loss: 2.4935675838743814

Epoch: 6| Step: 12
Training loss: 1.9530865474730417
Validation loss: 2.4494718008209793

Epoch: 6| Step: 13
Training loss: 2.164068118752577
Validation loss: 2.471906133392172

Epoch: 60| Step: 0
Training loss: 2.1007114658419246
Validation loss: 2.470816540031124

Epoch: 6| Step: 1
Training loss: 2.299866577093206
Validation loss: 2.510655329797033

Epoch: 6| Step: 2
Training loss: 1.8351401038046227
Validation loss: 2.5008900965200023

Epoch: 6| Step: 3
Training loss: 1.9274191555183215
Validation loss: 2.5379209642170872

Epoch: 6| Step: 4
Training loss: 2.6396485278220942
Validation loss: 2.525803093934244

Epoch: 6| Step: 5
Training loss: 1.981791218382516
Validation loss: 2.60462565128373

Epoch: 6| Step: 6
Training loss: 2.8152519326094563
Validation loss: 2.6696949890072164

Epoch: 6| Step: 7
Training loss: 2.6458607068986186
Validation loss: 2.6624217420368814

Epoch: 6| Step: 8
Training loss: 2.1237946626076867
Validation loss: 2.719353649020809

Epoch: 6| Step: 9
Training loss: 2.14654435411537
Validation loss: 2.611896096477763

Epoch: 6| Step: 10
Training loss: 2.7586017808389456
Validation loss: 2.5920180930867

Epoch: 6| Step: 11
Training loss: 2.4740158127916967
Validation loss: 2.5496472753652744

Epoch: 6| Step: 12
Training loss: 1.8741246405345262
Validation loss: 2.5895221063603646

Epoch: 6| Step: 13
Training loss: 1.882935832562634
Validation loss: 2.49217783767597

Epoch: 61| Step: 0
Training loss: 2.0778417179086084
Validation loss: 2.5174987164885234

Epoch: 6| Step: 1
Training loss: 2.5145100083257206
Validation loss: 2.505900635631096

Epoch: 6| Step: 2
Training loss: 1.7297571238880913
Validation loss: 2.585941894773377

Epoch: 6| Step: 3
Training loss: 2.313548597806063
Validation loss: 2.5758176863298052

Epoch: 6| Step: 4
Training loss: 2.3451844975296963
Validation loss: 2.5667162378486617

Epoch: 6| Step: 5
Training loss: 2.782357584692424
Validation loss: 2.538987253492386

Epoch: 6| Step: 6
Training loss: 2.339656459336987
Validation loss: 2.532165173523129

Epoch: 6| Step: 7
Training loss: 2.086208368780835
Validation loss: 2.5163316701618332

Epoch: 6| Step: 8
Training loss: 2.1887332164876887
Validation loss: 2.5139851408271214

Epoch: 6| Step: 9
Training loss: 2.8129878998464632
Validation loss: 2.5190654471914553

Epoch: 6| Step: 10
Training loss: 2.2073183666256813
Validation loss: 2.501920232822147

Epoch: 6| Step: 11
Training loss: 1.8333761325811095
Validation loss: 2.4816486906327575

Epoch: 6| Step: 12
Training loss: 2.5274292166407735
Validation loss: 2.589139095471044

Epoch: 6| Step: 13
Training loss: 1.617190079986431
Validation loss: 2.6239554582504105

Epoch: 62| Step: 0
Training loss: 2.235186662837046
Validation loss: 2.696305258910782

Epoch: 6| Step: 1
Training loss: 1.642073146566165
Validation loss: 2.69267335398008

Epoch: 6| Step: 2
Training loss: 1.5166182262244545
Validation loss: 2.8030480965761098

Epoch: 6| Step: 3
Training loss: 1.607489138339591
Validation loss: 2.8042879094463493

Epoch: 6| Step: 4
Training loss: 3.093732120963174
Validation loss: 2.8088551392150665

Epoch: 6| Step: 5
Training loss: 2.538817032906213
Validation loss: 2.7675813339742446

Epoch: 6| Step: 6
Training loss: 3.094283549221596
Validation loss: 2.681217331527958

Epoch: 6| Step: 7
Training loss: 1.9465553572372563
Validation loss: 2.590343490417043

Epoch: 6| Step: 8
Training loss: 2.099954663650143
Validation loss: 2.4797244579795623

Epoch: 6| Step: 9
Training loss: 2.7960480048079344
Validation loss: 2.4540877346262007

Epoch: 6| Step: 10
Training loss: 2.4409158687197157
Validation loss: 2.4990517566343926

Epoch: 6| Step: 11
Training loss: 2.747588400698569
Validation loss: 2.482516747399292

Epoch: 6| Step: 12
Training loss: 1.5973558213386896
Validation loss: 2.4930531145495336

Epoch: 6| Step: 13
Training loss: 2.0927982729365135
Validation loss: 2.5264346469227967

Epoch: 63| Step: 0
Training loss: 2.2891003081548607
Validation loss: 2.512214813368656

Epoch: 6| Step: 1
Training loss: 2.197594050975867
Validation loss: 2.57149836152853

Epoch: 6| Step: 2
Training loss: 2.1730464273576073
Validation loss: 2.489350971779893

Epoch: 6| Step: 3
Training loss: 2.895656186913014
Validation loss: 2.517819949606176

Epoch: 6| Step: 4
Training loss: 2.2143921299163343
Validation loss: 2.5047764607458443

Epoch: 6| Step: 5
Training loss: 2.323583897671139
Validation loss: 2.447652572562512

Epoch: 6| Step: 6
Training loss: 2.414463639494882
Validation loss: 2.5177678997762194

Epoch: 6| Step: 7
Training loss: 2.242119871176301
Validation loss: 2.5120401765101983

Epoch: 6| Step: 8
Training loss: 2.9037070685574045
Validation loss: 2.513008526127908

Epoch: 6| Step: 9
Training loss: 1.8293352604059758
Validation loss: 2.5758225611701397

Epoch: 6| Step: 10
Training loss: 2.336434506008396
Validation loss: 2.6335335639285975

Epoch: 6| Step: 11
Training loss: 2.236593358998373
Validation loss: 2.5977524894918047

Epoch: 6| Step: 12
Training loss: 1.5454729450119915
Validation loss: 2.5538988052808893

Epoch: 6| Step: 13
Training loss: 1.9655048934072106
Validation loss: 2.598775736192194

Epoch: 64| Step: 0
Training loss: 2.4481451915368937
Validation loss: 2.61967392663823

Epoch: 6| Step: 1
Training loss: 2.3803262716132583
Validation loss: 2.6351934999407396

Epoch: 6| Step: 2
Training loss: 2.256717191813295
Validation loss: 2.5747369949812926

Epoch: 6| Step: 3
Training loss: 1.6290382679377922
Validation loss: 2.5227822790623984

Epoch: 6| Step: 4
Training loss: 1.3201145723500136
Validation loss: 2.5347982270386935

Epoch: 6| Step: 5
Training loss: 1.142206115153486
Validation loss: 2.5397989310381117

Epoch: 6| Step: 6
Training loss: 1.8681520021949642
Validation loss: 2.5589759133574184

Epoch: 6| Step: 7
Training loss: 2.216617687898434
Validation loss: 2.5068831103128786

Epoch: 6| Step: 8
Training loss: 2.202180267577612
Validation loss: 2.4767765630553704

Epoch: 6| Step: 9
Training loss: 2.198672726538184
Validation loss: 2.488083668384435

Epoch: 6| Step: 10
Training loss: 2.4756949556863503
Validation loss: 2.5361967062830555

Epoch: 6| Step: 11
Training loss: 1.7284187936330946
Validation loss: 2.5210051491142687

Epoch: 6| Step: 12
Training loss: 2.8393126021189126
Validation loss: 2.469560675167661

Epoch: 6| Step: 13
Training loss: 3.0636799932953767
Validation loss: 2.5056284250229806

Epoch: 65| Step: 0
Training loss: 2.966287655854602
Validation loss: 2.4801895184679763

Epoch: 6| Step: 1
Training loss: 3.068037670615442
Validation loss: 2.518406406438952

Epoch: 6| Step: 2
Training loss: 1.8733917968876654
Validation loss: 2.4204244391978214

Epoch: 6| Step: 3
Training loss: 1.6487819799831298
Validation loss: 2.520884983594993

Epoch: 6| Step: 4
Training loss: 1.7289213749585532
Validation loss: 2.505567121819723

Epoch: 6| Step: 5
Training loss: 2.452745736319542
Validation loss: 2.494977698560896

Epoch: 6| Step: 6
Training loss: 2.437382230603465
Validation loss: 2.489077262571227

Epoch: 6| Step: 7
Training loss: 2.0962616388660895
Validation loss: 2.467798927053716

Epoch: 6| Step: 8
Training loss: 1.734893240268693
Validation loss: 2.5285461018489293

Epoch: 6| Step: 9
Training loss: 1.7732580152927686
Validation loss: 2.5421337313476693

Epoch: 6| Step: 10
Training loss: 2.3435958811632442
Validation loss: 2.55370447219993

Epoch: 6| Step: 11
Training loss: 2.2735847346814166
Validation loss: 2.5972553144535158

Epoch: 6| Step: 12
Training loss: 1.9037077163539102
Validation loss: 2.565305476672205

Epoch: 6| Step: 13
Training loss: 2.3632172883260782
Validation loss: 2.595898186764939

Epoch: 66| Step: 0
Training loss: 2.8331458272784844
Validation loss: 2.5867030613426443

Epoch: 6| Step: 1
Training loss: 1.5881580911106519
Validation loss: 2.5241349932384725

Epoch: 6| Step: 2
Training loss: 2.0024882573653784
Validation loss: 2.533465604926184

Epoch: 6| Step: 3
Training loss: 2.354755249263827
Validation loss: 2.4880140671143267

Epoch: 6| Step: 4
Training loss: 2.24522582160921
Validation loss: 2.513098449035508

Epoch: 6| Step: 5
Training loss: 2.777606592201725
Validation loss: 2.5181717706639892

Epoch: 6| Step: 6
Training loss: 2.08370452117261
Validation loss: 2.432363624788066

Epoch: 6| Step: 7
Training loss: 1.3735182754667214
Validation loss: 2.4400225733927083

Epoch: 6| Step: 8
Training loss: 1.5896726324047201
Validation loss: 2.516196681552283

Epoch: 6| Step: 9
Training loss: 2.2574579825139964
Validation loss: 2.506042521348138

Epoch: 6| Step: 10
Training loss: 2.327160936482905
Validation loss: 2.435843630375361

Epoch: 6| Step: 11
Training loss: 2.3370083296908537
Validation loss: 2.4082125632376212

Epoch: 6| Step: 12
Training loss: 2.2329211006421867
Validation loss: 2.438813572883867

Epoch: 6| Step: 13
Training loss: 2.028542225011544
Validation loss: 2.4936378746989827

Epoch: 67| Step: 0
Training loss: 2.4260444436904347
Validation loss: 2.451540927536764

Epoch: 6| Step: 1
Training loss: 2.307349474823549
Validation loss: 2.5151762947193315

Epoch: 6| Step: 2
Training loss: 1.5880560043942566
Validation loss: 2.538750622497412

Epoch: 6| Step: 3
Training loss: 2.5083252569767738
Validation loss: 2.5109770111222685

Epoch: 6| Step: 4
Training loss: 2.4993006681782117
Validation loss: 2.4948065378360407

Epoch: 6| Step: 5
Training loss: 2.2880102870416468
Validation loss: 2.5028910450973165

Epoch: 6| Step: 6
Training loss: 2.001541497316135
Validation loss: 2.4780828259901333

Epoch: 6| Step: 7
Training loss: 1.7211846880409667
Validation loss: 2.4700276895276057

Epoch: 6| Step: 8
Training loss: 2.0590085619636813
Validation loss: 2.5119353537654154

Epoch: 6| Step: 9
Training loss: 1.9603888363404944
Validation loss: 2.564112907749489

Epoch: 6| Step: 10
Training loss: 2.136459418534763
Validation loss: 2.5751536190788817

Epoch: 6| Step: 11
Training loss: 1.9539062768447306
Validation loss: 2.485305987566645

Epoch: 6| Step: 12
Training loss: 2.1774295610669485
Validation loss: 2.5166669705582323

Epoch: 6| Step: 13
Training loss: 2.3884963987186363
Validation loss: 2.512587962975192

Epoch: 68| Step: 0
Training loss: 1.6888462630478156
Validation loss: 2.5610412539399525

Epoch: 6| Step: 1
Training loss: 2.254323408373567
Validation loss: 2.4848421485318584

Epoch: 6| Step: 2
Training loss: 2.101682411374866
Validation loss: 2.5328540664453154

Epoch: 6| Step: 3
Training loss: 2.2449901755612873
Validation loss: 2.5123338672883184

Epoch: 6| Step: 4
Training loss: 2.2845781687343547
Validation loss: 2.5388341869505653

Epoch: 6| Step: 5
Training loss: 1.9631999061573568
Validation loss: 2.6099897410506596

Epoch: 6| Step: 6
Training loss: 2.389753993313866
Validation loss: 2.6361001426389086

Epoch: 6| Step: 7
Training loss: 2.1424106473329103
Validation loss: 2.55795916970072

Epoch: 6| Step: 8
Training loss: 1.8685758528692447
Validation loss: 2.4609258782652272

Epoch: 6| Step: 9
Training loss: 2.024089457815476
Validation loss: 2.50204130122073

Epoch: 6| Step: 10
Training loss: 2.1267233199861586
Validation loss: 2.489373287347512

Epoch: 6| Step: 11
Training loss: 1.7946597832570887
Validation loss: 2.4361917294142157

Epoch: 6| Step: 12
Training loss: 2.3707765873004756
Validation loss: 2.45184328324335

Epoch: 6| Step: 13
Training loss: 2.938033846780302
Validation loss: 2.4913236821072493

Epoch: 69| Step: 0
Training loss: 2.310838256933408
Validation loss: 2.469123136111137

Epoch: 6| Step: 1
Training loss: 2.5660037765891395
Validation loss: 2.5133852969454953

Epoch: 6| Step: 2
Training loss: 2.3859011784095303
Validation loss: 2.5173213444049822

Epoch: 6| Step: 3
Training loss: 2.1176917119710046
Validation loss: 2.4937020924236024

Epoch: 6| Step: 4
Training loss: 2.3408596272642375
Validation loss: 2.5195316127412126

Epoch: 6| Step: 5
Training loss: 1.9607861221062044
Validation loss: 2.507107390946135

Epoch: 6| Step: 6
Training loss: 1.7834828753770824
Validation loss: 2.5048215465724795

Epoch: 6| Step: 7
Training loss: 2.773709823778154
Validation loss: 2.5455649971737158

Epoch: 6| Step: 8
Training loss: 2.3398370249146887
Validation loss: 2.5270701618485534

Epoch: 6| Step: 9
Training loss: 1.9127208756700171
Validation loss: 2.5258709617168784

Epoch: 6| Step: 10
Training loss: 2.427771693070985
Validation loss: 2.476282627404908

Epoch: 6| Step: 11
Training loss: 2.169618381045975
Validation loss: 2.553570035374503

Epoch: 6| Step: 12
Training loss: 1.9948478737291973
Validation loss: 2.4916294553353233

Epoch: 6| Step: 13
Training loss: 1.6208582695593035
Validation loss: 2.4685432653341195

Epoch: 70| Step: 0
Training loss: 1.896335207006117
Validation loss: 2.5105683266401004

Epoch: 6| Step: 1
Training loss: 1.9406447576969832
Validation loss: 2.4913053874742745

Epoch: 6| Step: 2
Training loss: 2.582789230472632
Validation loss: 2.5185417972711606

Epoch: 6| Step: 3
Training loss: 3.1897111590929956
Validation loss: 2.5224900331983964

Epoch: 6| Step: 4
Training loss: 1.891561418145748
Validation loss: 2.5642933966464274

Epoch: 6| Step: 5
Training loss: 2.422495903901376
Validation loss: 2.6124012771765313

Epoch: 6| Step: 6
Training loss: 1.5894942965721675
Validation loss: 2.4853917246673127

Epoch: 6| Step: 7
Training loss: 1.724416374216227
Validation loss: 2.4712159600853614

Epoch: 6| Step: 8
Training loss: 2.0212518972978906
Validation loss: 2.5169915067529183

Epoch: 6| Step: 9
Training loss: 2.069196753076395
Validation loss: 2.4684416984847255

Epoch: 6| Step: 10
Training loss: 2.0048752016721103
Validation loss: 2.5121364216571194

Epoch: 6| Step: 11
Training loss: 1.8337131742538495
Validation loss: 2.4908504108070275

Epoch: 6| Step: 12
Training loss: 1.953172973043651
Validation loss: 2.4455382351587165

Epoch: 6| Step: 13
Training loss: 2.1988005706367217
Validation loss: 2.436125326918627

Epoch: 71| Step: 0
Training loss: 2.237605393980342
Validation loss: 2.433027092288011

Epoch: 6| Step: 1
Training loss: 2.6807144910728007
Validation loss: 2.513172921172331

Epoch: 6| Step: 2
Training loss: 2.585634427015396
Validation loss: 2.51562771688437

Epoch: 6| Step: 3
Training loss: 1.9489624833498276
Validation loss: 2.480870780504161

Epoch: 6| Step: 4
Training loss: 2.118763917410273
Validation loss: 2.5168934343078306

Epoch: 6| Step: 5
Training loss: 1.9174327839555547
Validation loss: 2.506458887668722

Epoch: 6| Step: 6
Training loss: 1.5737024411869696
Validation loss: 2.4824161764580213

Epoch: 6| Step: 7
Training loss: 1.829150181423043
Validation loss: 2.465167919511004

Epoch: 6| Step: 8
Training loss: 1.6410786319469612
Validation loss: 2.523574132537

Epoch: 6| Step: 9
Training loss: 2.100799081541559
Validation loss: 2.612871884003964

Epoch: 6| Step: 10
Training loss: 2.6146484812691413
Validation loss: 2.592291916209518

Epoch: 6| Step: 11
Training loss: 1.2897609783488422
Validation loss: 2.585577994535538

Epoch: 6| Step: 12
Training loss: 2.4067585395367472
Validation loss: 2.592556598453836

Epoch: 6| Step: 13
Training loss: 2.2554180820060594
Validation loss: 2.655432983109678

Epoch: 72| Step: 0
Training loss: 1.3182631167839511
Validation loss: 2.539109919178597

Epoch: 6| Step: 1
Training loss: 2.006605208375647
Validation loss: 2.462637613779162

Epoch: 6| Step: 2
Training loss: 2.240625349015511
Validation loss: 2.529557215426392

Epoch: 6| Step: 3
Training loss: 2.619432630767378
Validation loss: 2.5263605185294016

Epoch: 6| Step: 4
Training loss: 2.1831634042825527
Validation loss: 2.4908554838422323

Epoch: 6| Step: 5
Training loss: 1.8298894730006066
Validation loss: 2.476206403897659

Epoch: 6| Step: 6
Training loss: 2.198533922153659
Validation loss: 2.4977674211124836

Epoch: 6| Step: 7
Training loss: 3.0048134652889256
Validation loss: 2.507964996106293

Epoch: 6| Step: 8
Training loss: 1.9813101220861367
Validation loss: 2.4771520833409166

Epoch: 6| Step: 9
Training loss: 2.1809467793529755
Validation loss: 2.4310760128523987

Epoch: 6| Step: 10
Training loss: 1.9090026617296385
Validation loss: 2.4336157686024245

Epoch: 6| Step: 11
Training loss: 2.326570439885556
Validation loss: 2.5020614231324463

Epoch: 6| Step: 12
Training loss: 2.297146943271042
Validation loss: 2.524220395360686

Epoch: 6| Step: 13
Training loss: 1.472420347225805
Validation loss: 2.601389759885261

Epoch: 73| Step: 0
Training loss: 2.267304317690626
Validation loss: 2.6205792516670785

Epoch: 6| Step: 1
Training loss: 2.2604813691004066
Validation loss: 2.6477761282092844

Epoch: 6| Step: 2
Training loss: 2.278274267510496
Validation loss: 2.6346292990671016

Epoch: 6| Step: 3
Training loss: 2.0971808720681335
Validation loss: 2.6098820846541604

Epoch: 6| Step: 4
Training loss: 1.7944988295965025
Validation loss: 2.611212914987061

Epoch: 6| Step: 5
Training loss: 2.0586481829111594
Validation loss: 2.5820212005712073

Epoch: 6| Step: 6
Training loss: 2.83946072226723
Validation loss: 2.5765782195583906

Epoch: 6| Step: 7
Training loss: 1.598631246539207
Validation loss: 2.4790668520882617

Epoch: 6| Step: 8
Training loss: 1.7838032142063596
Validation loss: 2.5196630872196444

Epoch: 6| Step: 9
Training loss: 2.096138232623243
Validation loss: 2.449823608017189

Epoch: 6| Step: 10
Training loss: 2.2171549906911294
Validation loss: 2.5153227598859655

Epoch: 6| Step: 11
Training loss: 2.522958243479238
Validation loss: 2.4585823374789326

Epoch: 6| Step: 12
Training loss: 2.2487210771567736
Validation loss: 2.47948133785022

Epoch: 6| Step: 13
Training loss: 1.5434045876243383
Validation loss: 2.456076383400073

Epoch: 74| Step: 0
Training loss: 2.2916505524039863
Validation loss: 2.5015327841022095

Epoch: 6| Step: 1
Training loss: 2.4272319000571976
Validation loss: 2.5378194416841975

Epoch: 6| Step: 2
Training loss: 2.7947178199008023
Validation loss: 2.4805981539715827

Epoch: 6| Step: 3
Training loss: 2.0866784769197286
Validation loss: 2.565501804158616

Epoch: 6| Step: 4
Training loss: 1.6869414076113085
Validation loss: 2.506849062283036

Epoch: 6| Step: 5
Training loss: 2.575975296352236
Validation loss: 2.60600625231645

Epoch: 6| Step: 6
Training loss: 1.990608517085991
Validation loss: 2.568196810568364

Epoch: 6| Step: 7
Training loss: 1.9224512740410384
Validation loss: 2.5543727389204984

Epoch: 6| Step: 8
Training loss: 1.8346881917524325
Validation loss: 2.543944156619619

Epoch: 6| Step: 9
Training loss: 1.9424551082023986
Validation loss: 2.5600971958961445

Epoch: 6| Step: 10
Training loss: 2.2877696686096063
Validation loss: 2.4731532396399825

Epoch: 6| Step: 11
Training loss: 2.473105535924678
Validation loss: 2.492294149797489

Epoch: 6| Step: 12
Training loss: 1.6567104347377943
Validation loss: 2.4483316976006404

Epoch: 6| Step: 13
Training loss: 1.7886334700250899
Validation loss: 2.48983701639788

Epoch: 75| Step: 0
Training loss: 2.2104864839918483
Validation loss: 2.4657148221556358

Epoch: 6| Step: 1
Training loss: 2.284843123411823
Validation loss: 2.4491784327188593

Epoch: 6| Step: 2
Training loss: 2.244997184768645
Validation loss: 2.441131022897867

Epoch: 6| Step: 3
Training loss: 2.3021093398706602
Validation loss: 2.5040457335059596

Epoch: 6| Step: 4
Training loss: 1.9906538501607123
Validation loss: 2.4819265652310065

Epoch: 6| Step: 5
Training loss: 1.439861182833289
Validation loss: 2.486638699272863

Epoch: 6| Step: 6
Training loss: 1.8663489721362583
Validation loss: 2.4847918226746772

Epoch: 6| Step: 7
Training loss: 2.206147845877763
Validation loss: 2.505690361065529

Epoch: 6| Step: 8
Training loss: 1.726265169666769
Validation loss: 2.5361963537592422

Epoch: 6| Step: 9
Training loss: 2.2237224468649224
Validation loss: 2.499407618593506

Epoch: 6| Step: 10
Training loss: 1.5574648026213687
Validation loss: 2.5241912881232422

Epoch: 6| Step: 11
Training loss: 2.6772480084031316
Validation loss: 2.5825556666408422

Epoch: 6| Step: 12
Training loss: 1.603770599351871
Validation loss: 2.6118383601006423

Epoch: 6| Step: 13
Training loss: 1.818807020309487
Validation loss: 2.5624294038677853

Epoch: 76| Step: 0
Training loss: 2.028045591613112
Validation loss: 2.62219522890199

Epoch: 6| Step: 1
Training loss: 1.4425354542994813
Validation loss: 2.5849709601280635

Epoch: 6| Step: 2
Training loss: 2.507808031690188
Validation loss: 2.5701374121863876

Epoch: 6| Step: 3
Training loss: 2.193950189656179
Validation loss: 2.6211662453007727

Epoch: 6| Step: 4
Training loss: 2.298152023625471
Validation loss: 2.519557146437086

Epoch: 6| Step: 5
Training loss: 1.7503408372570823
Validation loss: 2.516540376597622

Epoch: 6| Step: 6
Training loss: 2.0188690811796985
Validation loss: 2.5197121173296835

Epoch: 6| Step: 7
Training loss: 2.744088060411815
Validation loss: 2.4954317157177144

Epoch: 6| Step: 8
Training loss: 2.438974570254004
Validation loss: 2.494737809037223

Epoch: 6| Step: 9
Training loss: 1.4745138983732815
Validation loss: 2.5615799035109417

Epoch: 6| Step: 10
Training loss: 2.1620811453667486
Validation loss: 2.5136353579746022

Epoch: 6| Step: 11
Training loss: 1.983878246216987
Validation loss: 2.41822607327905

Epoch: 6| Step: 12
Training loss: 2.3593506464427607
Validation loss: 2.4708012457099415

Epoch: 6| Step: 13
Training loss: 1.9191188743472178
Validation loss: 2.527355534065678

Epoch: 77| Step: 0
Training loss: 1.8318200223463
Validation loss: 2.491205306914738

Epoch: 6| Step: 1
Training loss: 2.099199746560163
Validation loss: 2.5064778643719534

Epoch: 6| Step: 2
Training loss: 1.9457623677787619
Validation loss: 2.5903040580904952

Epoch: 6| Step: 3
Training loss: 2.4383383067409077
Validation loss: 2.63507845873387

Epoch: 6| Step: 4
Training loss: 1.892971505774343
Validation loss: 2.6195501187088

Epoch: 6| Step: 5
Training loss: 2.2882970369835673
Validation loss: 2.572757968306917

Epoch: 6| Step: 6
Training loss: 1.8390507700115775
Validation loss: 2.5766241232414138

Epoch: 6| Step: 7
Training loss: 2.0156087948643027
Validation loss: 2.4762255643010915

Epoch: 6| Step: 8
Training loss: 1.948045580129
Validation loss: 2.441761139570718

Epoch: 6| Step: 9
Training loss: 2.476848405285659
Validation loss: 2.4663866214899546

Epoch: 6| Step: 10
Training loss: 1.8125868151689768
Validation loss: 2.4662383618396797

Epoch: 6| Step: 11
Training loss: 1.860575248506718
Validation loss: 2.4594172227297664

Epoch: 6| Step: 12
Training loss: 2.6368919937298685
Validation loss: 2.5245212711710656

Epoch: 6| Step: 13
Training loss: 2.134960169186121
Validation loss: 2.620280731439271

Epoch: 78| Step: 0
Training loss: 2.448430227963884
Validation loss: 2.548585633183171

Epoch: 6| Step: 1
Training loss: 1.9758619190187772
Validation loss: 2.5150946458889245

Epoch: 6| Step: 2
Training loss: 2.2874787876834097
Validation loss: 2.575014908756688

Epoch: 6| Step: 3
Training loss: 1.701787651025456
Validation loss: 2.6057773085198366

Epoch: 6| Step: 4
Training loss: 2.9310167882745013
Validation loss: 2.625369288187495

Epoch: 6| Step: 5
Training loss: 1.5020582859245426
Validation loss: 2.594645671088468

Epoch: 6| Step: 6
Training loss: 1.254685299540071
Validation loss: 2.571966410202505

Epoch: 6| Step: 7
Training loss: 1.6392591331219362
Validation loss: 2.50519045997213

Epoch: 6| Step: 8
Training loss: 1.9671584462754101
Validation loss: 2.5233817788222614

Epoch: 6| Step: 9
Training loss: 2.0877672949426214
Validation loss: 2.5392358182782933

Epoch: 6| Step: 10
Training loss: 1.5363008924951824
Validation loss: 2.5295763801483755

Epoch: 6| Step: 11
Training loss: 1.884739060288829
Validation loss: 2.4779516710274545

Epoch: 6| Step: 12
Training loss: 2.7209211427813145
Validation loss: 2.4527115848067913

Epoch: 6| Step: 13
Training loss: 1.7688183558974244
Validation loss: 2.5571171506133537

Epoch: 79| Step: 0
Training loss: 1.119986489078227
Validation loss: 2.5363789467004048

Epoch: 6| Step: 1
Training loss: 2.4338039840095105
Validation loss: 2.5025142504006554

Epoch: 6| Step: 2
Training loss: 2.3989694608054
Validation loss: 2.4628784598872673

Epoch: 6| Step: 3
Training loss: 2.0285886496114176
Validation loss: 2.464283858931049

Epoch: 6| Step: 4
Training loss: 1.6951156009649506
Validation loss: 2.5102271223466555

Epoch: 6| Step: 5
Training loss: 1.7438766433503547
Validation loss: 2.4526768009698436

Epoch: 6| Step: 6
Training loss: 2.0646463265866966
Validation loss: 2.4559099623684704

Epoch: 6| Step: 7
Training loss: 1.8227361171865
Validation loss: 2.47531956751323

Epoch: 6| Step: 8
Training loss: 2.128848685789985
Validation loss: 2.4759209701485108

Epoch: 6| Step: 9
Training loss: 2.3508747907532883
Validation loss: 2.552754735537108

Epoch: 6| Step: 10
Training loss: 2.4203577026322796
Validation loss: 2.545154302312425

Epoch: 6| Step: 11
Training loss: 1.9336026278205285
Validation loss: 2.527474008433456

Epoch: 6| Step: 12
Training loss: 2.4229241836531834
Validation loss: 2.5327492343814955

Epoch: 6| Step: 13
Training loss: 1.88669549836863
Validation loss: 2.538359355889139

Epoch: 80| Step: 0
Training loss: 1.6053318977037982
Validation loss: 2.530608099719823

Epoch: 6| Step: 1
Training loss: 1.9648886461228783
Validation loss: 2.54607299159467

Epoch: 6| Step: 2
Training loss: 2.0216593938425715
Validation loss: 2.4998528993562603

Epoch: 6| Step: 3
Training loss: 2.1013996954611533
Validation loss: 2.4833264247320286

Epoch: 6| Step: 4
Training loss: 2.551554867790847
Validation loss: 2.5363987178702794

Epoch: 6| Step: 5
Training loss: 1.9712214019965102
Validation loss: 2.504612878999488

Epoch: 6| Step: 6
Training loss: 2.687011940575018
Validation loss: 2.506103456165519

Epoch: 6| Step: 7
Training loss: 1.569244325120409
Validation loss: 2.492919049175522

Epoch: 6| Step: 8
Training loss: 1.3066287646019077
Validation loss: 2.505429285236427

Epoch: 6| Step: 9
Training loss: 2.767004326434074
Validation loss: 2.5878512781378893

Epoch: 6| Step: 10
Training loss: 1.8671604298181532
Validation loss: 2.537891356507385

Epoch: 6| Step: 11
Training loss: 1.6257778653462935
Validation loss: 2.5044908242875294

Epoch: 6| Step: 12
Training loss: 2.0045455299586603
Validation loss: 2.507973694498093

Epoch: 6| Step: 13
Training loss: 1.5783530344366268
Validation loss: 2.6005966333371546

Epoch: 81| Step: 0
Training loss: 2.399983457667243
Validation loss: 2.585668152210923

Epoch: 6| Step: 1
Training loss: 1.8046320126413042
Validation loss: 2.5689576973833237

Epoch: 6| Step: 2
Training loss: 2.4365293086101607
Validation loss: 2.5703579203912534

Epoch: 6| Step: 3
Training loss: 1.4414739825454175
Validation loss: 2.5895422390300853

Epoch: 6| Step: 4
Training loss: 2.0326645840569215
Validation loss: 2.60265984746979

Epoch: 6| Step: 5
Training loss: 1.8082870322187523
Validation loss: 2.495183373734849

Epoch: 6| Step: 6
Training loss: 2.0511915977109547
Validation loss: 2.5454085639262236

Epoch: 6| Step: 7
Training loss: 1.9427910208469654
Validation loss: 2.5333891569646014

Epoch: 6| Step: 8
Training loss: 2.5737539517194916
Validation loss: 2.556366332872747

Epoch: 6| Step: 9
Training loss: 1.86968597141709
Validation loss: 2.502517973930248

Epoch: 6| Step: 10
Training loss: 1.8550142715398652
Validation loss: 2.5561660703079787

Epoch: 6| Step: 11
Training loss: 1.8541832255220554
Validation loss: 2.4256450719280576

Epoch: 6| Step: 12
Training loss: 1.8931892597202524
Validation loss: 2.4701288935586856

Epoch: 6| Step: 13
Training loss: 2.027863834534951
Validation loss: 2.5448960493001618

Epoch: 82| Step: 0
Training loss: 2.0485890906348363
Validation loss: 2.511224977993017

Epoch: 6| Step: 1
Training loss: 2.3217672289639033
Validation loss: 2.484696101584499

Epoch: 6| Step: 2
Training loss: 1.914330164041519
Validation loss: 2.5056458379992756

Epoch: 6| Step: 3
Training loss: 2.1271560053751615
Validation loss: 2.5753971503439455

Epoch: 6| Step: 4
Training loss: 1.931091477390992
Validation loss: 2.5534720606338865

Epoch: 6| Step: 5
Training loss: 1.9089814924698796
Validation loss: 2.628421196441587

Epoch: 6| Step: 6
Training loss: 2.5843194699577556
Validation loss: 2.562536968181635

Epoch: 6| Step: 7
Training loss: 1.3684274336920932
Validation loss: 2.5997644727350346

Epoch: 6| Step: 8
Training loss: 1.9771667280654022
Validation loss: 2.5418274208470155

Epoch: 6| Step: 9
Training loss: 1.7519382914209682
Validation loss: 2.5129091122686122

Epoch: 6| Step: 10
Training loss: 1.7624541310503365
Validation loss: 2.503821123077611

Epoch: 6| Step: 11
Training loss: 2.2424176991817917
Validation loss: 2.4965269919653443

Epoch: 6| Step: 12
Training loss: 1.7926956001936338
Validation loss: 2.5281831977473606

Epoch: 6| Step: 13
Training loss: 2.178077020759784
Validation loss: 2.498556530987572

Epoch: 83| Step: 0
Training loss: 1.8477953481434586
Validation loss: 2.5007836067453164

Epoch: 6| Step: 1
Training loss: 1.6252609190175786
Validation loss: 2.459480201316309

Epoch: 6| Step: 2
Training loss: 1.9252706164098419
Validation loss: 2.4627534977902874

Epoch: 6| Step: 3
Training loss: 1.4944551024752162
Validation loss: 2.5040107026831198

Epoch: 6| Step: 4
Training loss: 2.060664892206793
Validation loss: 2.4662071523861147

Epoch: 6| Step: 5
Training loss: 2.1336535238345817
Validation loss: 2.5542354669893323

Epoch: 6| Step: 6
Training loss: 1.8689179641615485
Validation loss: 2.5450879870071033

Epoch: 6| Step: 7
Training loss: 2.1355302982025366
Validation loss: 2.524482164380499

Epoch: 6| Step: 8
Training loss: 2.2698293677238257
Validation loss: 2.598790048006564

Epoch: 6| Step: 9
Training loss: 2.539152079249129
Validation loss: 2.659489320717666

Epoch: 6| Step: 10
Training loss: 1.936242218297463
Validation loss: 2.6430304291275246

Epoch: 6| Step: 11
Training loss: 2.0819218877014762
Validation loss: 2.614866679569459

Epoch: 6| Step: 12
Training loss: 1.7192821719182763
Validation loss: 2.6429650736952444

Epoch: 6| Step: 13
Training loss: 1.7759059581945982
Validation loss: 2.5955914697487623

Epoch: 84| Step: 0
Training loss: 2.1480819130450697
Validation loss: 2.5415742237185426

Epoch: 6| Step: 1
Training loss: 2.2883076643794884
Validation loss: 2.4932232560969005

Epoch: 6| Step: 2
Training loss: 2.101702717354143
Validation loss: 2.4432947611225297

Epoch: 6| Step: 3
Training loss: 1.7477697056797263
Validation loss: 2.4759573051600676

Epoch: 6| Step: 4
Training loss: 1.1981290159123337
Validation loss: 2.4496957090421696

Epoch: 6| Step: 5
Training loss: 2.1696086008461246
Validation loss: 2.5112863408711377

Epoch: 6| Step: 6
Training loss: 2.262198125606391
Validation loss: 2.446776466772942

Epoch: 6| Step: 7
Training loss: 1.9670700292683472
Validation loss: 2.475380584405882

Epoch: 6| Step: 8
Training loss: 1.6498888325088605
Validation loss: 2.515178775108648

Epoch: 6| Step: 9
Training loss: 2.4643760273655784
Validation loss: 2.5024180003986705

Epoch: 6| Step: 10
Training loss: 1.879093089499431
Validation loss: 2.4515896829913846

Epoch: 6| Step: 11
Training loss: 2.2173438115899815
Validation loss: 2.5191658169005393

Epoch: 6| Step: 12
Training loss: 1.4670065413773203
Validation loss: 2.4887636875789743

Epoch: 6| Step: 13
Training loss: 1.3929836544110268
Validation loss: 2.641776441425224

Epoch: 85| Step: 0
Training loss: 1.973531577917639
Validation loss: 2.5908322909764006

Epoch: 6| Step: 1
Training loss: 1.408691744746493
Validation loss: 2.6032641614433936

Epoch: 6| Step: 2
Training loss: 2.390576729879305
Validation loss: 2.6414207297884187

Epoch: 6| Step: 3
Training loss: 2.2876112572134364
Validation loss: 2.602431601762438

Epoch: 6| Step: 4
Training loss: 2.0373025950656136
Validation loss: 2.6921610149926507

Epoch: 6| Step: 5
Training loss: 1.5507456585621764
Validation loss: 2.621916897984202

Epoch: 6| Step: 6
Training loss: 2.1898287775002103
Validation loss: 2.539622780042618

Epoch: 6| Step: 7
Training loss: 2.4665418962763286
Validation loss: 2.512470874332881

Epoch: 6| Step: 8
Training loss: 1.639808306190585
Validation loss: 2.45034421851191

Epoch: 6| Step: 9
Training loss: 1.7151435468338292
Validation loss: 2.521586177001057

Epoch: 6| Step: 10
Training loss: 2.0137986773166903
Validation loss: 2.473141044671983

Epoch: 6| Step: 11
Training loss: 1.9564281760294795
Validation loss: 2.5915846614395313

Epoch: 6| Step: 12
Training loss: 1.7560115828859832
Validation loss: 2.5085729632392066

Epoch: 6| Step: 13
Training loss: 1.8847181245026365
Validation loss: 2.550946481989461

Epoch: 86| Step: 0
Training loss: 2.0271540499744662
Validation loss: 2.5854684609863896

Epoch: 6| Step: 1
Training loss: 2.391119513134492
Validation loss: 2.5448748607884353

Epoch: 6| Step: 2
Training loss: 2.038361761477657
Validation loss: 2.514761024102799

Epoch: 6| Step: 3
Training loss: 1.810358163161246
Validation loss: 2.5063218056530823

Epoch: 6| Step: 4
Training loss: 1.8646093469719565
Validation loss: 2.486140153905865

Epoch: 6| Step: 5
Training loss: 2.05104072019272
Validation loss: 2.5001917447626747

Epoch: 6| Step: 6
Training loss: 1.8262681578687152
Validation loss: 2.5223092311559387

Epoch: 6| Step: 7
Training loss: 1.2310389090895721
Validation loss: 2.499924801649193

Epoch: 6| Step: 8
Training loss: 1.6156853227403318
Validation loss: 2.4601362669944726

Epoch: 6| Step: 9
Training loss: 2.002441822973774
Validation loss: 2.5000835484213355

Epoch: 6| Step: 10
Training loss: 1.3096768579799316
Validation loss: 2.592298745130316

Epoch: 6| Step: 11
Training loss: 2.339152391601029
Validation loss: 2.6718683744649554

Epoch: 6| Step: 12
Training loss: 1.3617137652780296
Validation loss: 2.6378914944774268

Epoch: 6| Step: 13
Training loss: 1.988341684678289
Validation loss: 2.6315772746315043

Epoch: 87| Step: 0
Training loss: 2.443882923462437
Validation loss: 2.6242759856584064

Epoch: 6| Step: 1
Training loss: 1.5950005804557104
Validation loss: 2.5468783232310326

Epoch: 6| Step: 2
Training loss: 1.573901274593794
Validation loss: 2.5801971585202828

Epoch: 6| Step: 3
Training loss: 1.9170748303672607
Validation loss: 2.497676978066521

Epoch: 6| Step: 4
Training loss: 1.6995004705398684
Validation loss: 2.486804517968099

Epoch: 6| Step: 5
Training loss: 1.9432294485854864
Validation loss: 2.4983278881503113

Epoch: 6| Step: 6
Training loss: 1.4209950836977117
Validation loss: 2.4530324412254867

Epoch: 6| Step: 7
Training loss: 1.857218028213513
Validation loss: 2.4704553050121145

Epoch: 6| Step: 8
Training loss: 1.6622636411912937
Validation loss: 2.5023997948140964

Epoch: 6| Step: 9
Training loss: 1.543316688420376
Validation loss: 2.503943670650807

Epoch: 6| Step: 10
Training loss: 2.401921528254632
Validation loss: 2.5039693474320392

Epoch: 6| Step: 11
Training loss: 1.4713297974135364
Validation loss: 2.488616856849179

Epoch: 6| Step: 12
Training loss: 2.2008321748745154
Validation loss: 2.47872360394983

Epoch: 6| Step: 13
Training loss: 2.4439721867466218
Validation loss: 2.58961633879624

Epoch: 88| Step: 0
Training loss: 1.4359917399028073
Validation loss: 2.657450625277038

Epoch: 6| Step: 1
Training loss: 1.7790348266186076
Validation loss: 2.730219126047757

Epoch: 6| Step: 2
Training loss: 2.1827619193134713
Validation loss: 2.7521588492494904

Epoch: 6| Step: 3
Training loss: 2.0922169552952443
Validation loss: 2.6658895423148974

Epoch: 6| Step: 4
Training loss: 1.6759954995798219
Validation loss: 2.664823197899064

Epoch: 6| Step: 5
Training loss: 1.7169256064417642
Validation loss: 2.593774052397342

Epoch: 6| Step: 6
Training loss: 1.84495550282895
Validation loss: 2.5207548418251706

Epoch: 6| Step: 7
Training loss: 2.1823298800695405
Validation loss: 2.5055775730474825

Epoch: 6| Step: 8
Training loss: 1.5827365386298855
Validation loss: 2.5594248346453785

Epoch: 6| Step: 9
Training loss: 1.9967553522265835
Validation loss: 2.5517528527561146

Epoch: 6| Step: 10
Training loss: 2.3321275547404325
Validation loss: 2.510302645255827

Epoch: 6| Step: 11
Training loss: 2.020807036658062
Validation loss: 2.458762330808298

Epoch: 6| Step: 12
Training loss: 1.77786736792419
Validation loss: 2.5801826049688272

Epoch: 6| Step: 13
Training loss: 1.3053167961256305
Validation loss: 2.591187018956929

Epoch: 89| Step: 0
Training loss: 2.3115092036554783
Validation loss: 2.5570876330825967

Epoch: 6| Step: 1
Training loss: 1.7910532973392814
Validation loss: 2.467901574992014

Epoch: 6| Step: 2
Training loss: 2.390101157246303
Validation loss: 2.5171564941264686

Epoch: 6| Step: 3
Training loss: 1.8227913804370095
Validation loss: 2.552224047667602

Epoch: 6| Step: 4
Training loss: 1.7352082596377836
Validation loss: 2.5320834761705266

Epoch: 6| Step: 5
Training loss: 1.756710944996017
Validation loss: 2.5649086401658563

Epoch: 6| Step: 6
Training loss: 1.7269213549494429
Validation loss: 2.535753615680042

Epoch: 6| Step: 7
Training loss: 1.5704933176271938
Validation loss: 2.50440240904487

Epoch: 6| Step: 8
Training loss: 1.5490757863250475
Validation loss: 2.502333346879311

Epoch: 6| Step: 9
Training loss: 1.9486978022036547
Validation loss: 2.5499050627594557

Epoch: 6| Step: 10
Training loss: 1.9148950128685482
Validation loss: 2.6160867226542774

Epoch: 6| Step: 11
Training loss: 1.5430341875710536
Validation loss: 2.596257127933577

Epoch: 6| Step: 12
Training loss: 1.8341590221314472
Validation loss: 2.587897104699042

Epoch: 6| Step: 13
Training loss: 1.7073111228307516
Validation loss: 2.5215507831491157

Epoch: 90| Step: 0
Training loss: 2.324521751848516
Validation loss: 2.5244638188449575

Epoch: 6| Step: 1
Training loss: 1.3019605909351502
Validation loss: 2.53595414264927

Epoch: 6| Step: 2
Training loss: 1.3711706938713237
Validation loss: 2.557868035361591

Epoch: 6| Step: 3
Training loss: 1.7626554109490042
Validation loss: 2.598215219881105

Epoch: 6| Step: 4
Training loss: 1.987108045592181
Validation loss: 2.437409537829357

Epoch: 6| Step: 5
Training loss: 1.3047861301808776
Validation loss: 2.590159017745445

Epoch: 6| Step: 6
Training loss: 1.6764684304104394
Validation loss: 2.5249970599745954

Epoch: 6| Step: 7
Training loss: 1.8842809498661723
Validation loss: 2.49288122393469

Epoch: 6| Step: 8
Training loss: 2.3645504404432547
Validation loss: 2.51636956926496

Epoch: 6| Step: 9
Training loss: 1.8938614437939183
Validation loss: 2.508099548454057

Epoch: 6| Step: 10
Training loss: 1.8346315324758904
Validation loss: 2.513984650836379

Epoch: 6| Step: 11
Training loss: 2.1000047320358006
Validation loss: 2.5584446754415517

Epoch: 6| Step: 12
Training loss: 1.7117435873119586
Validation loss: 2.52463568397746

Epoch: 6| Step: 13
Training loss: 1.7121900041216902
Validation loss: 2.4932407397741447

Epoch: 91| Step: 0
Training loss: 2.141392368409437
Validation loss: 2.610161759782609

Epoch: 6| Step: 1
Training loss: 1.4214754486432684
Validation loss: 2.580554564902074

Epoch: 6| Step: 2
Training loss: 2.08414419288929
Validation loss: 2.637164374476613

Epoch: 6| Step: 3
Training loss: 2.2056913106132607
Validation loss: 2.639181310502445

Epoch: 6| Step: 4
Training loss: 1.1785358087102888
Validation loss: 2.6861966543461246

Epoch: 6| Step: 5
Training loss: 1.5994150045981168
Validation loss: 2.579234021488011

Epoch: 6| Step: 6
Training loss: 1.9778691371909667
Validation loss: 2.5965096679973723

Epoch: 6| Step: 7
Training loss: 1.4138098222266964
Validation loss: 2.542686169340329

Epoch: 6| Step: 8
Training loss: 1.6815658357761192
Validation loss: 2.586746888203044

Epoch: 6| Step: 9
Training loss: 2.0751730237773622
Validation loss: 2.531262715625614

Epoch: 6| Step: 10
Training loss: 1.7084233175009658
Validation loss: 2.4872761227869993

Epoch: 6| Step: 11
Training loss: 1.790489061132027
Validation loss: 2.4896912385122363

Epoch: 6| Step: 12
Training loss: 2.2866650417681704
Validation loss: 2.5757105609271536

Epoch: 6| Step: 13
Training loss: 1.564393384080951
Validation loss: 2.4892793307516055

Epoch: 92| Step: 0
Training loss: 1.668095603961136
Validation loss: 2.4723141209051

Epoch: 6| Step: 1
Training loss: 2.0391270419023866
Validation loss: 2.54484445957216

Epoch: 6| Step: 2
Training loss: 1.8630528979856553
Validation loss: 2.523961220515404

Epoch: 6| Step: 3
Training loss: 2.1455068123788634
Validation loss: 2.5142923857331527

Epoch: 6| Step: 4
Training loss: 1.3065099265929163
Validation loss: 2.5171301388652485

Epoch: 6| Step: 5
Training loss: 2.666316446512742
Validation loss: 2.5907742692364724

Epoch: 6| Step: 6
Training loss: 1.3502355687924608
Validation loss: 2.6184089657086593

Epoch: 6| Step: 7
Training loss: 2.1407368206138364
Validation loss: 2.689036115139735

Epoch: 6| Step: 8
Training loss: 1.7056367883103645
Validation loss: 2.710509472567077

Epoch: 6| Step: 9
Training loss: 1.490319565804054
Validation loss: 2.6922344968962637

Epoch: 6| Step: 10
Training loss: 1.5810536319194284
Validation loss: 2.536153392490363

Epoch: 6| Step: 11
Training loss: 1.7243913488936913
Validation loss: 2.570431042752253

Epoch: 6| Step: 12
Training loss: 1.0258380022931752
Validation loss: 2.5122222474838827

Epoch: 6| Step: 13
Training loss: 1.6404401402549762
Validation loss: 2.538789892967905

Epoch: 93| Step: 0
Training loss: 1.6834873245482642
Validation loss: 2.5023175782371294

Epoch: 6| Step: 1
Training loss: 2.028188422905671
Validation loss: 2.467095251051904

Epoch: 6| Step: 2
Training loss: 1.6075242891745851
Validation loss: 2.535595323406038

Epoch: 6| Step: 3
Training loss: 1.4410331263814637
Validation loss: 2.5716121522272264

Epoch: 6| Step: 4
Training loss: 1.8562879179604237
Validation loss: 2.544706080263977

Epoch: 6| Step: 5
Training loss: 2.0626617137049705
Validation loss: 2.4572066510802206

Epoch: 6| Step: 6
Training loss: 1.6570406052443583
Validation loss: 2.5272096561979396

Epoch: 6| Step: 7
Training loss: 1.689097743059267
Validation loss: 2.5333610648176643

Epoch: 6| Step: 8
Training loss: 1.2695540206040838
Validation loss: 2.5299631152021256

Epoch: 6| Step: 9
Training loss: 1.800176357530809
Validation loss: 2.7563473679232944

Epoch: 6| Step: 10
Training loss: 1.5491476607255505
Validation loss: 2.6956012515873344

Epoch: 6| Step: 11
Training loss: 2.317565730704891
Validation loss: 2.799145279719637

Epoch: 6| Step: 12
Training loss: 1.8854509283785044
Validation loss: 2.7470301862385926

Epoch: 6| Step: 13
Training loss: 1.9780459660896719
Validation loss: 2.666245462014625

Epoch: 94| Step: 0
Training loss: 1.8292304063378197
Validation loss: 2.6362974456646437

Epoch: 6| Step: 1
Training loss: 1.2702872974105686
Validation loss: 2.5798867265591365

Epoch: 6| Step: 2
Training loss: 1.5414837221764177
Validation loss: 2.4653922960311347

Epoch: 6| Step: 3
Training loss: 1.578080280539039
Validation loss: 2.5258173787280045

Epoch: 6| Step: 4
Training loss: 1.7878609832980206
Validation loss: 2.4675258546999403

Epoch: 6| Step: 5
Training loss: 1.745360628043336
Validation loss: 2.5675132992061687

Epoch: 6| Step: 6
Training loss: 1.8429201489193634
Validation loss: 2.5147130983798305

Epoch: 6| Step: 7
Training loss: 2.025264430735971
Validation loss: 2.448503388778297

Epoch: 6| Step: 8
Training loss: 2.352498220023476
Validation loss: 2.5331296966506684

Epoch: 6| Step: 9
Training loss: 1.556217226962585
Validation loss: 2.49466872791706

Epoch: 6| Step: 10
Training loss: 2.4365617951640037
Validation loss: 2.570570897000537

Epoch: 6| Step: 11
Training loss: 1.6875435152447853
Validation loss: 2.7170842062423173

Epoch: 6| Step: 12
Training loss: 1.9095109657038658
Validation loss: 2.726808873861963

Epoch: 6| Step: 13
Training loss: 1.1025477122667786
Validation loss: 2.8075983072281847

Epoch: 95| Step: 0
Training loss: 1.6077261320444378
Validation loss: 2.774714273629412

Epoch: 6| Step: 1
Training loss: 1.77956544961639
Validation loss: 2.7223590851025805

Epoch: 6| Step: 2
Training loss: 1.7667475145062574
Validation loss: 2.666084588617918

Epoch: 6| Step: 3
Training loss: 1.8237406003943806
Validation loss: 2.6591990537074826

Epoch: 6| Step: 4
Training loss: 2.1542961003015946
Validation loss: 2.632115272697357

Epoch: 6| Step: 5
Training loss: 1.3690845951473338
Validation loss: 2.517145775248489

Epoch: 6| Step: 6
Training loss: 1.1925154728555425
Validation loss: 2.542137873594476

Epoch: 6| Step: 7
Training loss: 1.5640348906466748
Validation loss: 2.468240186306198

Epoch: 6| Step: 8
Training loss: 1.9314986158420817
Validation loss: 2.4706885698012884

Epoch: 6| Step: 9
Training loss: 2.372256551618732
Validation loss: 2.5181752737932808

Epoch: 6| Step: 10
Training loss: 1.5776000707839115
Validation loss: 2.4810297294105514

Epoch: 6| Step: 11
Training loss: 1.531368640273971
Validation loss: 2.5000883563640457

Epoch: 6| Step: 12
Training loss: 1.9420855617394464
Validation loss: 2.5468008736586696

Epoch: 6| Step: 13
Training loss: 2.1615932437816556
Validation loss: 2.5807029550852736

Epoch: 96| Step: 0
Training loss: 1.9206455919556533
Validation loss: 2.744723445230305

Epoch: 6| Step: 1
Training loss: 2.0639229691938876
Validation loss: 2.7510396841596467

Epoch: 6| Step: 2
Training loss: 1.3294940399833988
Validation loss: 2.6926101037019188

Epoch: 6| Step: 3
Training loss: 1.5744103251238826
Validation loss: 2.6455322204417677

Epoch: 6| Step: 4
Training loss: 1.54385319723925
Validation loss: 2.505155540327734

Epoch: 6| Step: 5
Training loss: 1.420745904345015
Validation loss: 2.5772031426751965

Epoch: 6| Step: 6
Training loss: 2.2659785553876195
Validation loss: 2.554588028179586

Epoch: 6| Step: 7
Training loss: 1.7085482842039252
Validation loss: 2.534768363381706

Epoch: 6| Step: 8
Training loss: 1.7355051568387985
Validation loss: 2.5328903848328643

Epoch: 6| Step: 9
Training loss: 2.062308331455726
Validation loss: 2.515333676104704

Epoch: 6| Step: 10
Training loss: 1.8242214292714867
Validation loss: 2.5054431152301126

Epoch: 6| Step: 11
Training loss: 1.677744890919459
Validation loss: 2.532482043607769

Epoch: 6| Step: 12
Training loss: 1.441925120844673
Validation loss: 2.5146976680936395

Epoch: 6| Step: 13
Training loss: 1.8975485144885351
Validation loss: 2.5713112696504714

Epoch: 97| Step: 0
Training loss: 2.374274293551718
Validation loss: 2.588470401716767

Epoch: 6| Step: 1
Training loss: 1.4397996669071034
Validation loss: 2.6745185638665885

Epoch: 6| Step: 2
Training loss: 1.5307125783330588
Validation loss: 2.6558165551876427

Epoch: 6| Step: 3
Training loss: 1.9753982673543955
Validation loss: 2.62991277463031

Epoch: 6| Step: 4
Training loss: 1.2024476758077334
Validation loss: 2.594554669064768

Epoch: 6| Step: 5
Training loss: 1.3870150827056695
Validation loss: 2.6376484905947044

Epoch: 6| Step: 6
Training loss: 1.9582468243693356
Validation loss: 2.5354289656136793

Epoch: 6| Step: 7
Training loss: 2.245106249463623
Validation loss: 2.4670285045439297

Epoch: 6| Step: 8
Training loss: 1.678348593138968
Validation loss: 2.6375060462581037

Epoch: 6| Step: 9
Training loss: 1.495989285400086
Validation loss: 2.5409256735696037

Epoch: 6| Step: 10
Training loss: 1.2097239165957867
Validation loss: 2.5361032935926495

Epoch: 6| Step: 11
Training loss: 2.3024486982530488
Validation loss: 2.4628834372649253

Epoch: 6| Step: 12
Training loss: 1.5413823338087345
Validation loss: 2.5229267906617943

Epoch: 6| Step: 13
Training loss: 1.6436047333902402
Validation loss: 2.518432077768922

Epoch: 98| Step: 0
Training loss: 1.313990972252756
Validation loss: 2.5130945119120796

Epoch: 6| Step: 1
Training loss: 2.275245079002512
Validation loss: 2.568728483532268

Epoch: 6| Step: 2
Training loss: 0.9409490084316503
Validation loss: 2.566023443385026

Epoch: 6| Step: 3
Training loss: 1.462017292666676
Validation loss: 2.508736722347474

Epoch: 6| Step: 4
Training loss: 2.234104166756215
Validation loss: 2.5414896627192527

Epoch: 6| Step: 5
Training loss: 1.6675601789376053
Validation loss: 2.5543327046287003

Epoch: 6| Step: 6
Training loss: 1.311556931420903
Validation loss: 2.539491611312888

Epoch: 6| Step: 7
Training loss: 1.796105394163878
Validation loss: 2.550885901804122

Epoch: 6| Step: 8
Training loss: 1.6645467707215547
Validation loss: 2.588377194517076

Epoch: 6| Step: 9
Training loss: 2.031128395548667
Validation loss: 2.6636625644147984

Epoch: 6| Step: 10
Training loss: 1.7646123632259725
Validation loss: 2.5288972948929467

Epoch: 6| Step: 11
Training loss: 1.0365693433855985
Validation loss: 2.5859655741755194

Epoch: 6| Step: 12
Training loss: 1.9116916843208502
Validation loss: 2.674507717932296

Epoch: 6| Step: 13
Training loss: 1.2235876076546204
Validation loss: 2.5476800157299673

Epoch: 99| Step: 0
Training loss: 2.0945792762176256
Validation loss: 2.5340310976227336

Epoch: 6| Step: 1
Training loss: 1.7945971439073138
Validation loss: 2.532912387403975

Epoch: 6| Step: 2
Training loss: 1.9225916573014399
Validation loss: 2.5864816421603583

Epoch: 6| Step: 3
Training loss: 0.9711621310279437
Validation loss: 2.549087733351602

Epoch: 6| Step: 4
Training loss: 1.4351589379365903
Validation loss: 2.599828774364964

Epoch: 6| Step: 5
Training loss: 1.4209137905903781
Validation loss: 2.583294857928155

Epoch: 6| Step: 6
Training loss: 1.4938623106804336
Validation loss: 2.5872991382570754

Epoch: 6| Step: 7
Training loss: 1.8923592928100934
Validation loss: 2.5354601144528988

Epoch: 6| Step: 8
Training loss: 1.6270633215982204
Validation loss: 2.67380390848247

Epoch: 6| Step: 9
Training loss: 1.6856337223244564
Validation loss: 2.5564931540897096

Epoch: 6| Step: 10
Training loss: 2.130993860687907
Validation loss: 2.52689157457095

Epoch: 6| Step: 11
Training loss: 1.6281604843519497
Validation loss: 2.5503827456037422

Epoch: 6| Step: 12
Training loss: 1.341898063386844
Validation loss: 2.5801763061047023

Epoch: 6| Step: 13
Training loss: 1.2774380523681939
Validation loss: 2.604487091696443

Epoch: 100| Step: 0
Training loss: 1.3777639179831533
Validation loss: 2.6680692967485684

Epoch: 6| Step: 1
Training loss: 1.7218923107460926
Validation loss: 2.6027098942574387

Epoch: 6| Step: 2
Training loss: 1.5551482624871014
Validation loss: 2.6730725762993903

Epoch: 6| Step: 3
Training loss: 1.3381464135898924
Validation loss: 2.6343142625014715

Epoch: 6| Step: 4
Training loss: 2.0896014206757325
Validation loss: 2.6321768818806843

Epoch: 6| Step: 5
Training loss: 1.3928405172103342
Validation loss: 2.586902680305391

Epoch: 6| Step: 6
Training loss: 2.05736561573896
Validation loss: 2.5780715166189316

Epoch: 6| Step: 7
Training loss: 0.9827880783564348
Validation loss: 2.594383836383639

Epoch: 6| Step: 8
Training loss: 1.697123461213868
Validation loss: 2.619856776091367

Epoch: 6| Step: 9
Training loss: 1.6257039526070596
Validation loss: 2.4903991724473866

Epoch: 6| Step: 10
Training loss: 1.765776231078612
Validation loss: 2.5198612834832685

Epoch: 6| Step: 11
Training loss: 1.5111051196247574
Validation loss: 2.4994859325849674

Epoch: 6| Step: 12
Training loss: 2.5812161496508312
Validation loss: 2.5847138259230213

Epoch: 6| Step: 13
Training loss: 1.3320047146567684
Validation loss: 2.591739043505919

Epoch: 101| Step: 0
Training loss: 2.132448493720104
Validation loss: 2.759046514420657

Epoch: 6| Step: 1
Training loss: 1.5067103018954542
Validation loss: 2.6925833775778867

Epoch: 6| Step: 2
Training loss: 1.5631540836769087
Validation loss: 2.7321883695571145

Epoch: 6| Step: 3
Training loss: 1.6260369733522346
Validation loss: 2.6466828631939228

Epoch: 6| Step: 4
Training loss: 1.2870656586373341
Validation loss: 2.5893751116448827

Epoch: 6| Step: 5
Training loss: 2.2097302702890325
Validation loss: 2.503836628327327

Epoch: 6| Step: 6
Training loss: 1.2046220556312037
Validation loss: 2.5354478665398843

Epoch: 6| Step: 7
Training loss: 1.91457020779643
Validation loss: 2.5096710701830047

Epoch: 6| Step: 8
Training loss: 2.1355409043310423
Validation loss: 2.525853467924171

Epoch: 6| Step: 9
Training loss: 1.4233852372692881
Validation loss: 2.510072697755663

Epoch: 6| Step: 10
Training loss: 1.6919068615396653
Validation loss: 2.5329144974444233

Epoch: 6| Step: 11
Training loss: 1.4055696749114142
Validation loss: 2.5325690392300046

Epoch: 6| Step: 12
Training loss: 1.7162418444746026
Validation loss: 2.5512051894548136

Epoch: 6| Step: 13
Training loss: 1.3585607786822713
Validation loss: 2.696924834897871

Epoch: 102| Step: 0
Training loss: 1.716048180479514
Validation loss: 2.696857507147255

Epoch: 6| Step: 1
Training loss: 1.445103563207629
Validation loss: 2.7211626682102197

Epoch: 6| Step: 2
Training loss: 1.8296088041326397
Validation loss: 2.794978310268274

Epoch: 6| Step: 3
Training loss: 1.4525161616202644
Validation loss: 2.615604327935582

Epoch: 6| Step: 4
Training loss: 1.428969739835138
Validation loss: 2.609807783773243

Epoch: 6| Step: 5
Training loss: 1.5779545002603743
Validation loss: 2.547583304051758

Epoch: 6| Step: 6
Training loss: 0.9444875664465624
Validation loss: 2.563746327571635

Epoch: 6| Step: 7
Training loss: 1.4191770843434106
Validation loss: 2.6213352416171594

Epoch: 6| Step: 8
Training loss: 1.6276806948154487
Validation loss: 2.631404375635452

Epoch: 6| Step: 9
Training loss: 1.543047630128709
Validation loss: 2.5947872676886092

Epoch: 6| Step: 10
Training loss: 1.7632330837609267
Validation loss: 2.649589175642635

Epoch: 6| Step: 11
Training loss: 1.395808471154611
Validation loss: 2.531715059924947

Epoch: 6| Step: 12
Training loss: 1.5616884031109584
Validation loss: 2.618757181453645

Epoch: 6| Step: 13
Training loss: 2.2728586410355853
Validation loss: 2.5518224362252444

Epoch: 103| Step: 0
Training loss: 2.114099256107161
Validation loss: 2.505165097080971

Epoch: 6| Step: 1
Training loss: 1.042369827724277
Validation loss: 2.5292080464714677

Epoch: 6| Step: 2
Training loss: 1.9762244255828805
Validation loss: 2.522652550209556

Epoch: 6| Step: 3
Training loss: 1.4746004015921095
Validation loss: 2.572085355651479

Epoch: 6| Step: 4
Training loss: 1.0214328497588412
Validation loss: 2.6445758239205137

Epoch: 6| Step: 5
Training loss: 1.676626352478997
Validation loss: 2.643507773963999

Epoch: 6| Step: 6
Training loss: 1.2680672053238
Validation loss: 2.6861501896893243

Epoch: 6| Step: 7
Training loss: 1.662825791983843
Validation loss: 2.8188110328038336

Epoch: 6| Step: 8
Training loss: 1.8792217410095422
Validation loss: 2.7573209041654123

Epoch: 6| Step: 9
Training loss: 1.5683773130006244
Validation loss: 2.634089219780004

Epoch: 6| Step: 10
Training loss: 1.7852757787441844
Validation loss: 2.6232132810374145

Epoch: 6| Step: 11
Training loss: 2.1103082923389653
Validation loss: 2.548950472997454

Epoch: 6| Step: 12
Training loss: 1.4792826790603177
Validation loss: 2.5380153589928733

Epoch: 6| Step: 13
Training loss: 1.6483238868069836
Validation loss: 2.516495327032692

Epoch: 104| Step: 0
Training loss: 1.356446454986245
Validation loss: 2.56730757572002

Epoch: 6| Step: 1
Training loss: 1.8288804148169584
Validation loss: 2.553130294501715

Epoch: 6| Step: 2
Training loss: 1.3749836140436547
Validation loss: 2.560087231103537

Epoch: 6| Step: 3
Training loss: 1.237957259190674
Validation loss: 2.547070961806771

Epoch: 6| Step: 4
Training loss: 1.6341200708142631
Validation loss: 2.554221652270374

Epoch: 6| Step: 5
Training loss: 1.5177545432668544
Validation loss: 2.6889855027465885

Epoch: 6| Step: 6
Training loss: 2.0399928984798916
Validation loss: 2.697518305782679

Epoch: 6| Step: 7
Training loss: 1.7209816056753058
Validation loss: 2.55225775505415

Epoch: 6| Step: 8
Training loss: 1.9772821254765967
Validation loss: 2.630175332847522

Epoch: 6| Step: 9
Training loss: 1.4165878086955546
Validation loss: 2.6373095493346703

Epoch: 6| Step: 10
Training loss: 1.1183623425453992
Validation loss: 2.6331252035953865

Epoch: 6| Step: 11
Training loss: 1.5335690590128626
Validation loss: 2.6406395063434447

Epoch: 6| Step: 12
Training loss: 1.2945539086890652
Validation loss: 2.535282439474449

Epoch: 6| Step: 13
Training loss: 1.3743470115292444
Validation loss: 2.641201956956381

Epoch: 105| Step: 0
Training loss: 1.0830184344363296
Validation loss: 2.5474073169683136

Epoch: 6| Step: 1
Training loss: 1.5986325887914092
Validation loss: 2.589659494910161

Epoch: 6| Step: 2
Training loss: 1.68033285828528
Validation loss: 2.526737853920363

Epoch: 6| Step: 3
Training loss: 1.4275177714348957
Validation loss: 2.6480391361258353

Epoch: 6| Step: 4
Training loss: 1.210316061718401
Validation loss: 2.6322880797115795

Epoch: 6| Step: 5
Training loss: 1.6960832100869758
Validation loss: 2.6366506760840154

Epoch: 6| Step: 6
Training loss: 1.476649851965197
Validation loss: 2.691773676049175

Epoch: 6| Step: 7
Training loss: 1.8948895616986616
Validation loss: 2.570288235782701

Epoch: 6| Step: 8
Training loss: 0.8288787075000653
Validation loss: 2.5246131449545386

Epoch: 6| Step: 9
Training loss: 1.492799483624417
Validation loss: 2.5499857683968927

Epoch: 6| Step: 10
Training loss: 2.3515226544524457
Validation loss: 2.633994405999757

Epoch: 6| Step: 11
Training loss: 2.245450081854165
Validation loss: 2.5554247617652948

Epoch: 6| Step: 12
Training loss: 1.3104297568552359
Validation loss: 2.579710470952596

Epoch: 6| Step: 13
Training loss: 1.4506932081419455
Validation loss: 2.5276801677926666

Epoch: 106| Step: 0
Training loss: 2.039322642835913
Validation loss: 2.597350199555865

Epoch: 6| Step: 1
Training loss: 1.0719595717272474
Validation loss: 2.569587056323413

Epoch: 6| Step: 2
Training loss: 0.9611037195861049
Validation loss: 2.606639760952538

Epoch: 6| Step: 3
Training loss: 1.5156999549814876
Validation loss: 2.735208889192208

Epoch: 6| Step: 4
Training loss: 1.7638547682111088
Validation loss: 2.7382954131380037

Epoch: 6| Step: 5
Training loss: 1.2117850506252181
Validation loss: 2.731182072520029

Epoch: 6| Step: 6
Training loss: 1.1442241582204822
Validation loss: 2.6252472776171136

Epoch: 6| Step: 7
Training loss: 1.3597989353043913
Validation loss: 2.6299585406343824

Epoch: 6| Step: 8
Training loss: 2.3249829486508786
Validation loss: 2.5888497203197836

Epoch: 6| Step: 9
Training loss: 1.8561081597695053
Validation loss: 2.592977661595629

Epoch: 6| Step: 10
Training loss: 1.438898318655437
Validation loss: 2.5793179612985475

Epoch: 6| Step: 11
Training loss: 1.2325378460132
Validation loss: 2.4951452961611835

Epoch: 6| Step: 12
Training loss: 1.3383541445857878
Validation loss: 2.5671634727896846

Epoch: 6| Step: 13
Training loss: 1.5273384425858874
Validation loss: 2.567131493534652

Epoch: 107| Step: 0
Training loss: 1.3599341108685856
Validation loss: 2.64447463184868

Epoch: 6| Step: 1
Training loss: 1.0603105763025258
Validation loss: 2.5703854226818703

Epoch: 6| Step: 2
Training loss: 1.2096389699280792
Validation loss: 2.542357145126497

Epoch: 6| Step: 3
Training loss: 1.5873662216408806
Validation loss: 2.601373476601823

Epoch: 6| Step: 4
Training loss: 1.5061054746058848
Validation loss: 2.6173081858883203

Epoch: 6| Step: 5
Training loss: 2.3438011672474643
Validation loss: 2.6339981925821054

Epoch: 6| Step: 6
Training loss: 1.4992530870506027
Validation loss: 2.749909139345917

Epoch: 6| Step: 7
Training loss: 1.4325664279841122
Validation loss: 2.7532138540223556

Epoch: 6| Step: 8
Training loss: 1.5097702835623066
Validation loss: 2.7750772849195036

Epoch: 6| Step: 9
Training loss: 1.429923032943456
Validation loss: 2.719042444395197

Epoch: 6| Step: 10
Training loss: 1.90581276053381
Validation loss: 2.61609753738734

Epoch: 6| Step: 11
Training loss: 1.6544758633432082
Validation loss: 2.6314928273489744

Epoch: 6| Step: 12
Training loss: 0.9947703227737602
Validation loss: 2.5883558937099926

Epoch: 6| Step: 13
Training loss: 1.8911417105281445
Validation loss: 2.6175532147166707

Epoch: 108| Step: 0
Training loss: 1.6644800226508676
Validation loss: 2.576895125683141

Epoch: 6| Step: 1
Training loss: 1.2277911404610828
Validation loss: 2.664862228384661

Epoch: 6| Step: 2
Training loss: 1.4607071312407036
Validation loss: 2.571298087558538

Epoch: 6| Step: 3
Training loss: 1.374774697658567
Validation loss: 2.5662726566375533

Epoch: 6| Step: 4
Training loss: 1.0522796271483867
Validation loss: 2.621757366465076

Epoch: 6| Step: 5
Training loss: 1.7398445557625408
Validation loss: 2.674109314798531

Epoch: 6| Step: 6
Training loss: 1.5999717441686467
Validation loss: 2.738256464332221

Epoch: 6| Step: 7
Training loss: 1.278116907966199
Validation loss: 2.630270873481345

Epoch: 6| Step: 8
Training loss: 1.4031262353156755
Validation loss: 2.7036358418601854

Epoch: 6| Step: 9
Training loss: 2.29801321048774
Validation loss: 2.6406117877215847

Epoch: 6| Step: 10
Training loss: 1.7311860055491801
Validation loss: 2.6634738902058315

Epoch: 6| Step: 11
Training loss: 1.6033630670234438
Validation loss: 2.5648583515459236

Epoch: 6| Step: 12
Training loss: 1.5733902409870697
Validation loss: 2.5984479648962764

Epoch: 6| Step: 13
Training loss: 1.3030617915862455
Validation loss: 2.6118592335837554

Epoch: 109| Step: 0
Training loss: 1.2984067764044285
Validation loss: 2.510856516018142

Epoch: 6| Step: 1
Training loss: 1.2345540846313474
Validation loss: 2.499192775103619

Epoch: 6| Step: 2
Training loss: 1.628153455489249
Validation loss: 2.542550657624767

Epoch: 6| Step: 3
Training loss: 2.158040726709579
Validation loss: 2.7048809985005247

Epoch: 6| Step: 4
Training loss: 1.2917809692178748
Validation loss: 2.65889073171453

Epoch: 6| Step: 5
Training loss: 1.0426180246264107
Validation loss: 2.6788796411028812

Epoch: 6| Step: 6
Training loss: 1.8125418296459557
Validation loss: 2.691583990199265

Epoch: 6| Step: 7
Training loss: 1.1460316168566302
Validation loss: 2.667792400528517

Epoch: 6| Step: 8
Training loss: 1.5758130351668493
Validation loss: 2.670347732778768

Epoch: 6| Step: 9
Training loss: 1.0261247023597013
Validation loss: 2.59049095172059

Epoch: 6| Step: 10
Training loss: 1.3542513698594192
Validation loss: 2.6574413245952555

Epoch: 6| Step: 11
Training loss: 1.760959165451688
Validation loss: 2.5764218031525044

Epoch: 6| Step: 12
Training loss: 1.6174752536867643
Validation loss: 2.5842500618775355

Epoch: 6| Step: 13
Training loss: 1.1267909523356596
Validation loss: 2.612203987058295

Epoch: 110| Step: 0
Training loss: 1.7581331087827914
Validation loss: 2.5314852522801514

Epoch: 6| Step: 1
Training loss: 1.2939243991529283
Validation loss: 2.574972440825206

Epoch: 6| Step: 2
Training loss: 0.898726740179314
Validation loss: 2.6425994473706322

Epoch: 6| Step: 3
Training loss: 1.3833703677647158
Validation loss: 2.538293121363356

Epoch: 6| Step: 4
Training loss: 1.3990564095588447
Validation loss: 2.569300520935667

Epoch: 6| Step: 5
Training loss: 1.5024827437592052
Validation loss: 2.5942776154850247

Epoch: 6| Step: 6
Training loss: 1.412409453739105
Validation loss: 2.6351613208772102

Epoch: 6| Step: 7
Training loss: 1.2675346755000316
Validation loss: 2.6734287585099406

Epoch: 6| Step: 8
Training loss: 1.2569783447967688
Validation loss: 2.525754197795156

Epoch: 6| Step: 9
Training loss: 1.5429317421639794
Validation loss: 2.6736811208985425

Epoch: 6| Step: 10
Training loss: 1.2725379434560686
Validation loss: 2.694710499342654

Epoch: 6| Step: 11
Training loss: 2.4394605528059454
Validation loss: 2.81978972178574

Epoch: 6| Step: 12
Training loss: 1.2093582191584484
Validation loss: 2.816106758295761

Epoch: 6| Step: 13
Training loss: 1.5885503883330845
Validation loss: 2.7828667759800862

Epoch: 111| Step: 0
Training loss: 1.758961484295453
Validation loss: 2.7528446685520076

Epoch: 6| Step: 1
Training loss: 1.4784589426521226
Validation loss: 2.703980106644558

Epoch: 6| Step: 2
Training loss: 1.9896837245784917
Validation loss: 2.620848824758994

Epoch: 6| Step: 3
Training loss: 1.0987202113673555
Validation loss: 2.5814934120835478

Epoch: 6| Step: 4
Training loss: 1.4934618236973962
Validation loss: 2.62049791487201

Epoch: 6| Step: 5
Training loss: 1.448694674181791
Validation loss: 2.5415217144599036

Epoch: 6| Step: 6
Training loss: 1.4732850854548423
Validation loss: 2.6531177228596414

Epoch: 6| Step: 7
Training loss: 1.2336095053963387
Validation loss: 2.6408511033026567

Epoch: 6| Step: 8
Training loss: 1.1013294270998821
Validation loss: 2.610960168624048

Epoch: 6| Step: 9
Training loss: 1.437794199153221
Validation loss: 2.6748187113618616

Epoch: 6| Step: 10
Training loss: 1.0239877168172014
Validation loss: 2.639808347926946

Epoch: 6| Step: 11
Training loss: 1.6069759524432707
Validation loss: 2.6336641679249895

Epoch: 6| Step: 12
Training loss: 1.466474190277733
Validation loss: 2.6976227373136337

Epoch: 6| Step: 13
Training loss: 1.4364414463982387
Validation loss: 2.6357956012007464

Epoch: 112| Step: 0
Training loss: 1.9053871828633342
Validation loss: 2.6728538594011297

Epoch: 6| Step: 1
Training loss: 1.1528896267312672
Validation loss: 2.6386434429753676

Epoch: 6| Step: 2
Training loss: 1.4809331241115584
Validation loss: 2.667354753252688

Epoch: 6| Step: 3
Training loss: 1.1996027924864174
Validation loss: 2.708549121672043

Epoch: 6| Step: 4
Training loss: 1.460262693522723
Validation loss: 2.693467751900466

Epoch: 6| Step: 5
Training loss: 1.1872366563019425
Validation loss: 2.793189776729263

Epoch: 6| Step: 6
Training loss: 0.9263141241283939
Validation loss: 2.755831012899804

Epoch: 6| Step: 7
Training loss: 1.5365314875714666
Validation loss: 2.686327863475688

Epoch: 6| Step: 8
Training loss: 1.7682433841753604
Validation loss: 2.659379469452751

Epoch: 6| Step: 9
Training loss: 1.3129730280468597
Validation loss: 2.6029275972729047

Epoch: 6| Step: 10
Training loss: 0.9353362863806259
Validation loss: 2.6162760651576935

Epoch: 6| Step: 11
Training loss: 1.7348828646120638
Validation loss: 2.5635293428346198

Epoch: 6| Step: 12
Training loss: 1.5549941790799913
Validation loss: 2.616940910906909

Epoch: 6| Step: 13
Training loss: 1.4575246839576004
Validation loss: 2.5155147346672133

Epoch: 113| Step: 0
Training loss: 1.4316394592530213
Validation loss: 2.563815298800347

Epoch: 6| Step: 1
Training loss: 1.8091939832305213
Validation loss: 2.5972511989135305

Epoch: 6| Step: 2
Training loss: 1.3747644222631676
Validation loss: 2.627750968549921

Epoch: 6| Step: 3
Training loss: 1.3822923964513114
Validation loss: 2.7199270835387215

Epoch: 6| Step: 4
Training loss: 1.5452253234156894
Validation loss: 2.6973940123346702

Epoch: 6| Step: 5
Training loss: 1.1102211103075743
Validation loss: 2.8110879108248934

Epoch: 6| Step: 6
Training loss: 1.4416840241697433
Validation loss: 2.7802595596672797

Epoch: 6| Step: 7
Training loss: 1.689748184810408
Validation loss: 2.7398387707658767

Epoch: 6| Step: 8
Training loss: 1.2799479684089141
Validation loss: 2.64072580540126

Epoch: 6| Step: 9
Training loss: 1.409733420934602
Validation loss: 2.593975210562055

Epoch: 6| Step: 10
Training loss: 1.659043385619569
Validation loss: 2.6254474470469997

Epoch: 6| Step: 11
Training loss: 1.4290921999082575
Validation loss: 2.605142781743266

Epoch: 6| Step: 12
Training loss: 1.591539233367389
Validation loss: 2.5993288090814803

Epoch: 6| Step: 13
Training loss: 1.1628956931416683
Validation loss: 2.5771579200191455

Epoch: 114| Step: 0
Training loss: 1.724619812463992
Validation loss: 2.7010743994052886

Epoch: 6| Step: 1
Training loss: 1.2966635658076717
Validation loss: 2.6732235901520762

Epoch: 6| Step: 2
Training loss: 1.5154214309367164
Validation loss: 2.760595025592256

Epoch: 6| Step: 3
Training loss: 2.062592475436329
Validation loss: 2.7645794603732208

Epoch: 6| Step: 4
Training loss: 1.4277931545697815
Validation loss: 2.6815598066561157

Epoch: 6| Step: 5
Training loss: 1.323212457864829
Validation loss: 2.7701590346164346

Epoch: 6| Step: 6
Training loss: 1.1297904383189419
Validation loss: 2.6241495934766146

Epoch: 6| Step: 7
Training loss: 1.502563669947092
Validation loss: 2.56040568172208

Epoch: 6| Step: 8
Training loss: 1.3317300674152723
Validation loss: 2.6268746327676697

Epoch: 6| Step: 9
Training loss: 1.4615281486919591
Validation loss: 2.5653831575489474

Epoch: 6| Step: 10
Training loss: 1.4950542773086866
Validation loss: 2.549490866603378

Epoch: 6| Step: 11
Training loss: 1.252255407728756
Validation loss: 2.5915498555916554

Epoch: 6| Step: 12
Training loss: 1.363076443303642
Validation loss: 2.641083024911236

Epoch: 6| Step: 13
Training loss: 1.041647713806664
Validation loss: 2.656943810301078

Epoch: 115| Step: 0
Training loss: 0.7932987372150418
Validation loss: 2.6500539282343776

Epoch: 6| Step: 1
Training loss: 1.5473622797261275
Validation loss: 2.749424874247274

Epoch: 6| Step: 2
Training loss: 1.333329940831319
Validation loss: 2.709507443169264

Epoch: 6| Step: 3
Training loss: 1.6749021985552892
Validation loss: 2.7123898473543897

Epoch: 6| Step: 4
Training loss: 1.0326736910942087
Validation loss: 2.7355160612093727

Epoch: 6| Step: 5
Training loss: 1.5962113466414691
Validation loss: 2.681574121193754

Epoch: 6| Step: 6
Training loss: 1.2975583401832842
Validation loss: 2.64103861020479

Epoch: 6| Step: 7
Training loss: 1.9892086721501647
Validation loss: 2.647053509802461

Epoch: 6| Step: 8
Training loss: 1.0083771535846398
Validation loss: 2.6744569197450354

Epoch: 6| Step: 9
Training loss: 1.3791764726703157
Validation loss: 2.5540889929389956

Epoch: 6| Step: 10
Training loss: 0.9938346226967608
Validation loss: 2.624625376051571

Epoch: 6| Step: 11
Training loss: 1.649371059076213
Validation loss: 2.6062443316159403

Epoch: 6| Step: 12
Training loss: 1.3507608671398994
Validation loss: 2.564701886591258

Epoch: 6| Step: 13
Training loss: 1.3390043426312201
Validation loss: 2.619983557365597

Epoch: 116| Step: 0
Training loss: 1.2286589376675994
Validation loss: 2.657664771200828

Epoch: 6| Step: 1
Training loss: 1.7300549565665475
Validation loss: 2.6765761927907468

Epoch: 6| Step: 2
Training loss: 1.631050656002719
Validation loss: 2.703882600022679

Epoch: 6| Step: 3
Training loss: 1.2236833736997548
Validation loss: 2.732121016340581

Epoch: 6| Step: 4
Training loss: 1.3463943544313655
Validation loss: 2.585473686489118

Epoch: 6| Step: 5
Training loss: 1.892226053564932
Validation loss: 2.660934401648661

Epoch: 6| Step: 6
Training loss: 1.158532801727218
Validation loss: 2.647419181409074

Epoch: 6| Step: 7
Training loss: 1.03746937396336
Validation loss: 2.5520562670044455

Epoch: 6| Step: 8
Training loss: 1.3964891553676921
Validation loss: 2.5810593061229015

Epoch: 6| Step: 9
Training loss: 1.1040099530600658
Validation loss: 2.609071481682932

Epoch: 6| Step: 10
Training loss: 1.0757560688249206
Validation loss: 2.6393867011973517

Epoch: 6| Step: 11
Training loss: 1.1097010818290542
Validation loss: 2.555242931091824

Epoch: 6| Step: 12
Training loss: 1.168539360770915
Validation loss: 2.592292720965429

Epoch: 6| Step: 13
Training loss: 1.7078870640119004
Validation loss: 2.6553507535583147

Epoch: 117| Step: 0
Training loss: 1.5691644068029942
Validation loss: 2.592220912761696

Epoch: 6| Step: 1
Training loss: 1.2768927661707279
Validation loss: 2.6990645825109074

Epoch: 6| Step: 2
Training loss: 1.1137746687874714
Validation loss: 2.715889781807328

Epoch: 6| Step: 3
Training loss: 1.212241768621598
Validation loss: 2.779179248657418

Epoch: 6| Step: 4
Training loss: 0.9468733771785515
Validation loss: 2.627906189653632

Epoch: 6| Step: 5
Training loss: 0.8827111515170941
Validation loss: 2.690056789654328

Epoch: 6| Step: 6
Training loss: 1.2304655529162334
Validation loss: 2.6362751453370716

Epoch: 6| Step: 7
Training loss: 1.1254267413015477
Validation loss: 2.6583501853129694

Epoch: 6| Step: 8
Training loss: 1.306719448295132
Validation loss: 2.683987547416813

Epoch: 6| Step: 9
Training loss: 2.108089026769884
Validation loss: 2.6155326204078513

Epoch: 6| Step: 10
Training loss: 1.1637953893412507
Validation loss: 2.6293318745436243

Epoch: 6| Step: 11
Training loss: 1.4191604524671626
Validation loss: 2.673420538998043

Epoch: 6| Step: 12
Training loss: 1.801192495260715
Validation loss: 2.7162374674236855

Epoch: 6| Step: 13
Training loss: 1.354801640437428
Validation loss: 2.719360005430829

Epoch: 118| Step: 0
Training loss: 1.209512770737922
Validation loss: 2.6842751116924974

Epoch: 6| Step: 1
Training loss: 1.0916230911313325
Validation loss: 2.692294538469285

Epoch: 6| Step: 2
Training loss: 1.2858615783305405
Validation loss: 2.635831179582277

Epoch: 6| Step: 3
Training loss: 1.955582682223935
Validation loss: 2.8543576828645896

Epoch: 6| Step: 4
Training loss: 1.4009530655121474
Validation loss: 2.8785430389229485

Epoch: 6| Step: 5
Training loss: 0.9323599735291396
Validation loss: 2.7646639172313674

Epoch: 6| Step: 6
Training loss: 1.1982855132212789
Validation loss: 2.749730169178571

Epoch: 6| Step: 7
Training loss: 1.3717680139903954
Validation loss: 2.7560120812203417

Epoch: 6| Step: 8
Training loss: 0.981391563651823
Validation loss: 2.5829519918427852

Epoch: 6| Step: 9
Training loss: 1.2210176352649669
Validation loss: 2.575783639323783

Epoch: 6| Step: 10
Training loss: 0.9238506741826373
Validation loss: 2.6325721480085145

Epoch: 6| Step: 11
Training loss: 1.5479157154735794
Validation loss: 2.688673702004565

Epoch: 6| Step: 12
Training loss: 1.3560210759907787
Validation loss: 2.5858086191812304

Epoch: 6| Step: 13
Training loss: 1.4321805968712338
Validation loss: 2.657127923430293

Epoch: 119| Step: 0
Training loss: 1.1944615944412331
Validation loss: 2.589896376560814

Epoch: 6| Step: 1
Training loss: 1.2331030847658262
Validation loss: 2.6007882188890985

Epoch: 6| Step: 2
Training loss: 1.191428362531732
Validation loss: 2.7031175469973796

Epoch: 6| Step: 3
Training loss: 0.8787388620986619
Validation loss: 2.7690228352907553

Epoch: 6| Step: 4
Training loss: 1.4373608397421531
Validation loss: 2.762935631121762

Epoch: 6| Step: 5
Training loss: 1.6953604555159345
Validation loss: 2.901711903007117

Epoch: 6| Step: 6
Training loss: 1.3843202291637395
Validation loss: 2.8764272823459636

Epoch: 6| Step: 7
Training loss: 1.2199085793089754
Validation loss: 2.6961468128637396

Epoch: 6| Step: 8
Training loss: 1.4468845375356378
Validation loss: 2.699784789515358

Epoch: 6| Step: 9
Training loss: 1.37459710027055
Validation loss: 2.6587557922357576

Epoch: 6| Step: 10
Training loss: 1.3683322582558155
Validation loss: 2.672236100273374

Epoch: 6| Step: 11
Training loss: 1.4107088818369005
Validation loss: 2.6390993424759883

Epoch: 6| Step: 12
Training loss: 2.182222812874363
Validation loss: 2.6217532439182856

Epoch: 6| Step: 13
Training loss: 1.1448182667264557
Validation loss: 2.6123238992430236

Epoch: 120| Step: 0
Training loss: 1.2497654217911054
Validation loss: 2.7090003854965587

Epoch: 6| Step: 1
Training loss: 1.5494378947256378
Validation loss: 2.720781137589875

Epoch: 6| Step: 2
Training loss: 1.1536718441662306
Validation loss: 2.832653599901138

Epoch: 6| Step: 3
Training loss: 1.7629535686634126
Validation loss: 2.818329696164152

Epoch: 6| Step: 4
Training loss: 1.665461422329433
Validation loss: 2.739209448148871

Epoch: 6| Step: 5
Training loss: 1.873793340872655
Validation loss: 2.7030285797856863

Epoch: 6| Step: 6
Training loss: 1.1002935581369904
Validation loss: 2.6737315548496414

Epoch: 6| Step: 7
Training loss: 1.1992005088984483
Validation loss: 2.539195099327047

Epoch: 6| Step: 8
Training loss: 1.5441983888390176
Validation loss: 2.6290488806657106

Epoch: 6| Step: 9
Training loss: 1.597443732045289
Validation loss: 2.644595154328705

Epoch: 6| Step: 10
Training loss: 1.0205806432407019
Validation loss: 2.6527443584669395

Epoch: 6| Step: 11
Training loss: 1.308337468345247
Validation loss: 2.6479160541940896

Epoch: 6| Step: 12
Training loss: 1.1876199561316012
Validation loss: 2.6162974803812356

Epoch: 6| Step: 13
Training loss: 1.1580359610078197
Validation loss: 2.817864480102019

Epoch: 121| Step: 0
Training loss: 1.3083321836592043
Validation loss: 2.8361619452432176

Epoch: 6| Step: 1
Training loss: 1.1679767110802048
Validation loss: 2.854780358563519

Epoch: 6| Step: 2
Training loss: 1.5327960403289698
Validation loss: 2.807436489316475

Epoch: 6| Step: 3
Training loss: 1.9997733106889082
Validation loss: 2.7013651093060416

Epoch: 6| Step: 4
Training loss: 1.4360121615221617
Validation loss: 2.685982075887767

Epoch: 6| Step: 5
Training loss: 1.1496446972837633
Validation loss: 2.5785515018211975

Epoch: 6| Step: 6
Training loss: 1.2919378406169333
Validation loss: 2.677810797701006

Epoch: 6| Step: 7
Training loss: 1.709408011108993
Validation loss: 2.707563090224826

Epoch: 6| Step: 8
Training loss: 1.5185994328717203
Validation loss: 2.6411437629195604

Epoch: 6| Step: 9
Training loss: 1.7799033713097885
Validation loss: 2.6452287799275016

Epoch: 6| Step: 10
Training loss: 1.0518243993509597
Validation loss: 2.5922501145446617

Epoch: 6| Step: 11
Training loss: 1.3344234341624273
Validation loss: 2.713762451288565

Epoch: 6| Step: 12
Training loss: 1.25238815105161
Validation loss: 2.8447638021524786

Epoch: 6| Step: 13
Training loss: 1.1980252866289358
Validation loss: 2.8815622625270527

Epoch: 122| Step: 0
Training loss: 2.2031066028016224
Validation loss: 2.880190407189614

Epoch: 6| Step: 1
Training loss: 1.3972038923004566
Validation loss: 2.970351606978129

Epoch: 6| Step: 2
Training loss: 0.8644302110009587
Validation loss: 2.8365184514659147

Epoch: 6| Step: 3
Training loss: 1.262438589434312
Validation loss: 2.8143889124028947

Epoch: 6| Step: 4
Training loss: 0.9344569409524289
Validation loss: 2.6866880121716226

Epoch: 6| Step: 5
Training loss: 1.7058398106533876
Validation loss: 2.6771316350792413

Epoch: 6| Step: 6
Training loss: 1.2160959934692783
Validation loss: 2.635329397111104

Epoch: 6| Step: 7
Training loss: 1.135511248554263
Validation loss: 2.5871224814441103

Epoch: 6| Step: 8
Training loss: 1.6337644731366487
Validation loss: 2.615225805449459

Epoch: 6| Step: 9
Training loss: 1.0869262365600225
Validation loss: 2.601585601917905

Epoch: 6| Step: 10
Training loss: 1.2531301407934512
Validation loss: 2.605333354278214

Epoch: 6| Step: 11
Training loss: 1.1299426327549822
Validation loss: 2.5942462461744062

Epoch: 6| Step: 12
Training loss: 1.2898144002956715
Validation loss: 2.624762463797141

Epoch: 6| Step: 13
Training loss: 0.8742223076496568
Validation loss: 2.654821707491621

Epoch: 123| Step: 0
Training loss: 1.7458964328090767
Validation loss: 2.6632581225467424

Epoch: 6| Step: 1
Training loss: 1.0105426093720369
Validation loss: 2.6523471058827566

Epoch: 6| Step: 2
Training loss: 1.070723406026568
Validation loss: 2.7018744014139577

Epoch: 6| Step: 3
Training loss: 1.295420923055284
Validation loss: 2.724998980414057

Epoch: 6| Step: 4
Training loss: 1.4142658234996146
Validation loss: 2.6660137469945306

Epoch: 6| Step: 5
Training loss: 1.2283981097225152
Validation loss: 2.6311619808066458

Epoch: 6| Step: 6
Training loss: 1.45868881071102
Validation loss: 2.59970901951743

Epoch: 6| Step: 7
Training loss: 1.1248127463585784
Validation loss: 2.6176570034699633

Epoch: 6| Step: 8
Training loss: 1.4061723475739178
Validation loss: 2.590996303109609

Epoch: 6| Step: 9
Training loss: 1.8195715448119794
Validation loss: 2.629309824951937

Epoch: 6| Step: 10
Training loss: 1.3231802950527727
Validation loss: 2.6427892359548295

Epoch: 6| Step: 11
Training loss: 0.7902058919166071
Validation loss: 2.7192178155630424

Epoch: 6| Step: 12
Training loss: 1.0770430733825769
Validation loss: 2.6801856850355215

Epoch: 6| Step: 13
Training loss: 1.256305241674972
Validation loss: 2.7097688440739374

Epoch: 124| Step: 0
Training loss: 1.2155322610739243
Validation loss: 2.7059171511590607

Epoch: 6| Step: 1
Training loss: 1.1557895671549867
Validation loss: 2.676018608313667

Epoch: 6| Step: 2
Training loss: 1.020470022569598
Validation loss: 2.662071460986585

Epoch: 6| Step: 3
Training loss: 1.1460003586613758
Validation loss: 2.669710676969391

Epoch: 6| Step: 4
Training loss: 1.3108263698392113
Validation loss: 2.703918913751247

Epoch: 6| Step: 5
Training loss: 0.9170539680769901
Validation loss: 2.619585629520792

Epoch: 6| Step: 6
Training loss: 0.9865797873750478
Validation loss: 2.6092459366911043

Epoch: 6| Step: 7
Training loss: 1.2222124945850705
Validation loss: 2.6527429204473703

Epoch: 6| Step: 8
Training loss: 1.0122477794197957
Validation loss: 2.6535556741709003

Epoch: 6| Step: 9
Training loss: 1.9258781857496687
Validation loss: 2.6942532139414705

Epoch: 6| Step: 10
Training loss: 1.2336020645141643
Validation loss: 2.6982987083049785

Epoch: 6| Step: 11
Training loss: 1.53141020890413
Validation loss: 2.7651018556685907

Epoch: 6| Step: 12
Training loss: 1.3838741300571709
Validation loss: 2.9150719960800138

Epoch: 6| Step: 13
Training loss: 1.7459604779956093
Validation loss: 2.8682002081632065

Epoch: 125| Step: 0
Training loss: 2.0213381212189536
Validation loss: 2.800141258309593

Epoch: 6| Step: 1
Training loss: 1.095808109143019
Validation loss: 2.6894475696278257

Epoch: 6| Step: 2
Training loss: 1.4383316122393222
Validation loss: 2.6690036447670935

Epoch: 6| Step: 3
Training loss: 1.2630898787774831
Validation loss: 2.6278981831000725

Epoch: 6| Step: 4
Training loss: 1.2763995025676833
Validation loss: 2.6321134459879687

Epoch: 6| Step: 5
Training loss: 0.9808767009558477
Validation loss: 2.673734542067234

Epoch: 6| Step: 6
Training loss: 1.3323822901338707
Validation loss: 2.710889700432455

Epoch: 6| Step: 7
Training loss: 1.402229750736122
Validation loss: 2.6563919029478913

Epoch: 6| Step: 8
Training loss: 0.9980560421755943
Validation loss: 2.6735438810430647

Epoch: 6| Step: 9
Training loss: 0.8323375872252623
Validation loss: 2.6863989163874056

Epoch: 6| Step: 10
Training loss: 0.8918300640866346
Validation loss: 2.6587299065069003

Epoch: 6| Step: 11
Training loss: 1.0862442242081425
Validation loss: 2.79232097663193

Epoch: 6| Step: 12
Training loss: 1.626643670042004
Validation loss: 2.8068703009051403

Epoch: 6| Step: 13
Training loss: 1.4887929922665615
Validation loss: 2.804620669391325

Testing loss: 2.3445668000653836
