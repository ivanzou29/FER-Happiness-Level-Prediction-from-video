Epoch: 1| Step: 0
Training loss: 4.648879804324757
Validation loss: 3.9061727408299887
Epoch: 5| Step: 1
Training loss: 4.044983646468217
Validation loss: 3.8936929211795186
Epoch: 5| Step: 2
Training loss: 4.220888853068858
Validation loss: 3.9028854113333775
Epoch: 5| Step: 3
Training loss: 4.417890607039912
Validation loss: 3.9027194502689375
Epoch: 5| Step: 4
Training loss: 4.6154430728046885
Validation loss: 3.8819903672572793
Epoch: 5| Step: 5
Training loss: 4.0386511705751325
Validation loss: 3.8872958919477094
Epoch: 5| Step: 6
Training loss: 4.4629207551636085
Validation loss: 3.8728052963044326
Epoch: 5| Step: 7
Training loss: 4.475594780463934
Validation loss: 3.870123828890905
Epoch: 5| Step: 8
Training loss: 4.077690949123352
Validation loss: 3.8759840030151005
Epoch: 5| Step: 9
Training loss: 4.19288221042146
Validation loss: 3.8781187819720033
Epoch: 2| Step: 0
Training loss: 4.667203781462227
Validation loss: 3.8672572702919044
Epoch: 5| Step: 1
Training loss: 4.841874479385138
Validation loss: 3.863893611669803
Epoch: 5| Step: 2
Training loss: 3.5974793033388894
Validation loss: 3.8360673969744954
Epoch: 5| Step: 3
Training loss: 4.135185843815321
Validation loss: 3.859552318842452
Epoch: 5| Step: 4
Training loss: 4.18141301269258
Validation loss: 3.8545971655179456
Epoch: 5| Step: 5
Training loss: 4.0981777793856375
Validation loss: 3.8476374358731826
Epoch: 5| Step: 6
Training loss: 4.128905326099708
Validation loss: 3.8521511599800786
Epoch: 5| Step: 7
Training loss: 4.675824081492422
Validation loss: 3.85017776217168
Epoch: 5| Step: 8
Training loss: 4.315920150795989
Validation loss: 3.827075413746473
Epoch: 5| Step: 9
Training loss: 4.1311779575731995
Validation loss: 3.809762735175957
Epoch: 3| Step: 0
Training loss: 4.1093269606418525
Validation loss: 3.8245588551887937
Epoch: 5| Step: 1
Training loss: 4.186663188163462
Validation loss: 3.8063922679989863
Epoch: 5| Step: 2
Training loss: 4.111780891043109
Validation loss: 3.8309028465970054
Epoch: 5| Step: 3
Training loss: 4.195475939190123
Validation loss: 3.8263655345931618
Epoch: 5| Step: 4
Training loss: 3.7498728412685667
Validation loss: 3.7968658670173725
Epoch: 5| Step: 5
Training loss: 4.2268989132953925
Validation loss: 3.8044292321630513
Epoch: 5| Step: 6
Training loss: 4.611507220023843
Validation loss: 3.7702538168956323
Epoch: 5| Step: 7
Training loss: 4.396208013443055
Validation loss: 3.8109640242045146
Epoch: 5| Step: 8
Training loss: 4.732683641323656
Validation loss: 3.8040122810009023
Epoch: 5| Step: 9
Training loss: 4.147696276177182
Validation loss: 3.7839351770220726
Epoch: 4| Step: 0
Training loss: 3.671169781430289
Validation loss: 3.783652327288571
Epoch: 5| Step: 1
Training loss: 4.658565073726305
Validation loss: 3.788909385012047
Epoch: 5| Step: 2
Training loss: 4.424405401766399
Validation loss: 3.777595149870707
Epoch: 5| Step: 3
Training loss: 3.6672932060620016
Validation loss: 3.7503312789441527
Epoch: 5| Step: 4
Training loss: 4.221449828745595
Validation loss: 3.7649923576932305
Epoch: 5| Step: 5
Training loss: 4.262535681253585
Validation loss: 3.746481126053331
Epoch: 5| Step: 6
Training loss: 4.285138890831977
Validation loss: 3.7629559039901914
Epoch: 5| Step: 7
Training loss: 4.548994166945942
Validation loss: 3.755330142310727
Epoch: 5| Step: 8
Training loss: 4.137011985003488
Validation loss: 3.7471496117158396
Epoch: 5| Step: 9
Training loss: 4.155400698513918
Validation loss: 3.7444664875814966
Epoch: 5| Step: 0
Training loss: 4.542373158978165
Validation loss: 3.7321711936498265
Epoch: 5| Step: 1
Training loss: 4.002190943549897
Validation loss: 3.7433411240846546
Epoch: 5| Step: 2
Training loss: 3.849845828647936
Validation loss: 3.7261172558033877
Epoch: 5| Step: 3
Training loss: 4.188685918242102
Validation loss: 3.729094623119724
Epoch: 5| Step: 4
Training loss: 4.210962865183345
Validation loss: 3.721917842247777
Epoch: 5| Step: 5
Training loss: 4.27900202408734
Validation loss: 3.69952294746848
Epoch: 5| Step: 6
Training loss: 4.115614878440002
Validation loss: 3.718940225599956
Epoch: 5| Step: 7
Training loss: 4.3161994435751865
Validation loss: 3.713481597454779
Epoch: 5| Step: 8
Training loss: 3.938711070961247
Validation loss: 3.6840080533576236
Epoch: 5| Step: 9
Training loss: 4.213436821700768
Validation loss: 3.68058470022328
Epoch: 6| Step: 0
Training loss: 3.541722794630306
Validation loss: 3.684384298443448
Epoch: 5| Step: 1
Training loss: 4.122561572131534
Validation loss: 3.686309745655065
Epoch: 5| Step: 2
Training loss: 4.592336839530075
Validation loss: 3.6701131424661018
Epoch: 5| Step: 3
Training loss: 3.81464438244594
Validation loss: 3.675679104280096
Epoch: 5| Step: 4
Training loss: 4.546733631151762
Validation loss: 3.6681008473591388
Epoch: 5| Step: 5
Training loss: 4.158486589093432
Validation loss: 3.6545052628825463
Epoch: 5| Step: 6
Training loss: 4.115346536796133
Validation loss: 3.65843450046498
Epoch: 5| Step: 7
Training loss: 4.048427681596305
Validation loss: 3.636971663744152
Epoch: 5| Step: 8
Training loss: 4.362354203987774
Validation loss: 3.6412629022094687
Epoch: 5| Step: 9
Training loss: 3.7495015130920653
Validation loss: 3.630716586822539
Epoch: 7| Step: 0
Training loss: 3.734844609185333
Validation loss: 3.6277617714054102
Epoch: 5| Step: 1
Training loss: 3.523456717225171
Validation loss: 3.62025663603908
Epoch: 5| Step: 2
Training loss: 4.008330729927175
Validation loss: 3.6253748308027176
Epoch: 5| Step: 3
Training loss: 4.621163297566785
Validation loss: 3.5851313968276255
Epoch: 5| Step: 4
Training loss: 3.883574811988627
Validation loss: 3.614515739666442
Epoch: 5| Step: 5
Training loss: 3.7225781139327427
Validation loss: 3.5889146063919695
Epoch: 5| Step: 6
Training loss: 4.366368088936838
Validation loss: 3.6041769302708446
Epoch: 5| Step: 7
Training loss: 3.8888832697752065
Validation loss: 3.5606632871296293
Epoch: 5| Step: 8
Training loss: 4.365066149582887
Validation loss: 3.5797127003853206
Epoch: 5| Step: 9
Training loss: 4.352802750489387
Validation loss: 3.5748731270879133
Epoch: 8| Step: 0
Training loss: 3.9241580473153803
Validation loss: 3.5723306228036282
Epoch: 5| Step: 1
Training loss: 3.925887164305091
Validation loss: 3.5546410703296027
Epoch: 5| Step: 2
Training loss: 4.199570751961732
Validation loss: 3.5560373750765435
Epoch: 5| Step: 3
Training loss: 3.8212008389301433
Validation loss: 3.5526953689211522
Epoch: 5| Step: 4
Training loss: 4.339420493677383
Validation loss: 3.5347002739886544
Epoch: 5| Step: 5
Training loss: 3.793904213701139
Validation loss: 3.542077599752327
Epoch: 5| Step: 6
Training loss: 4.044602392999348
Validation loss: 3.534956908643819
Epoch: 5| Step: 7
Training loss: 3.7200330556405805
Validation loss: 3.519686984076088
Epoch: 5| Step: 8
Training loss: 4.259510842477983
Validation loss: 3.496626675776194
Epoch: 5| Step: 9
Training loss: 3.959014606407453
Validation loss: 3.512793029786322
Epoch: 9| Step: 0
Training loss: 3.444653367983711
Validation loss: 3.49389700917108
Epoch: 5| Step: 1
Training loss: 4.07674317315947
Validation loss: 3.4906326706697794
Epoch: 5| Step: 2
Training loss: 3.343104790444442
Validation loss: 3.4627617331361726
Epoch: 5| Step: 3
Training loss: 4.3342673444408035
Validation loss: 3.488452538706141
Epoch: 5| Step: 4
Training loss: 3.816217704808729
Validation loss: 3.4732645738530863
Epoch: 5| Step: 5
Training loss: 3.8966833537070493
Validation loss: 3.463453005557014
Epoch: 5| Step: 6
Training loss: 4.067422085832304
Validation loss: 3.4552959988151333
Epoch: 5| Step: 7
Training loss: 3.875719311309026
Validation loss: 3.453751102001934
Epoch: 5| Step: 8
Training loss: 3.75970791859124
Validation loss: 3.438422175783502
Epoch: 5| Step: 9
Training loss: 4.5699078763862655
Validation loss: 3.435677986922027
Epoch: 10| Step: 0
Training loss: 3.689718968924478
Validation loss: 3.419313083601493
Epoch: 5| Step: 1
Training loss: 4.4440693114169285
Validation loss: 3.3905479709847683
Epoch: 5| Step: 2
Training loss: 3.4985082717150036
Validation loss: 3.417986517273895
Epoch: 5| Step: 3
Training loss: 4.141490917711202
Validation loss: 3.407461335267984
Epoch: 5| Step: 4
Training loss: 4.32586236195288
Validation loss: 3.3969609536590544
Epoch: 5| Step: 5
Training loss: 3.4245533672846826
Validation loss: 3.363897147808791
Epoch: 5| Step: 6
Training loss: 3.8419690231750465
Validation loss: 3.366089063566557
Epoch: 5| Step: 7
Training loss: 3.9131512523404774
Validation loss: 3.3696060063638735
Epoch: 5| Step: 8
Training loss: 4.172665867511384
Validation loss: 3.3557372529160934
Epoch: 5| Step: 9
Training loss: 2.953468908236372
Validation loss: 3.3477045446162843
Epoch: 11| Step: 0
Training loss: 3.568284007311629
Validation loss: 3.3435670974112552
Epoch: 5| Step: 1
Training loss: 4.003133976589028
Validation loss: 3.335654658213965
Epoch: 5| Step: 2
Training loss: 3.8753495827773925
Validation loss: 3.3246514345386653
Epoch: 5| Step: 3
Training loss: 3.8648255196059074
Validation loss: 3.2927873189209262
Epoch: 5| Step: 4
Training loss: 3.7231790789893027
Validation loss: 3.3024355061576665
Epoch: 5| Step: 5
Training loss: 3.6731505430773423
Validation loss: 3.3019615783015324
Epoch: 5| Step: 6
Training loss: 3.536028978729604
Validation loss: 3.282843918711764
Epoch: 5| Step: 7
Training loss: 3.7385635189687187
Validation loss: 3.285278799275973
Epoch: 5| Step: 8
Training loss: 3.5299620853797777
Validation loss: 3.2642494523680092
Epoch: 5| Step: 9
Training loss: 4.251151882476191
Validation loss: 3.2696329506097945
Epoch: 12| Step: 0
Training loss: 3.8907610398373493
Validation loss: 3.2516796583949046
Epoch: 5| Step: 1
Training loss: 3.2824335779237703
Validation loss: 3.2431445390451534
Epoch: 5| Step: 2
Training loss: 3.5824466909527164
Validation loss: 3.228519075402582
Epoch: 5| Step: 3
Training loss: 3.940515362683841
Validation loss: 3.224091727096866
Epoch: 5| Step: 4
Training loss: 3.821109243988215
Validation loss: 3.211304427271734
Epoch: 5| Step: 5
Training loss: 3.8149162515269652
Validation loss: 3.197988707874964
Epoch: 5| Step: 6
Training loss: 3.500185552855583
Validation loss: 3.1853191680111355
Epoch: 5| Step: 7
Training loss: 3.7812474778852643
Validation loss: 3.152582640142084
Epoch: 5| Step: 8
Training loss: 3.2448684087325073
Validation loss: 3.160411619052978
Epoch: 5| Step: 9
Training loss: 3.968130108338392
Validation loss: 3.1588489890489146
Epoch: 13| Step: 0
Training loss: 3.2335466439059495
Validation loss: 3.1340104999370793
Epoch: 5| Step: 1
Training loss: 3.9429961099085435
Validation loss: 3.1254949110290084
Epoch: 5| Step: 2
Training loss: 3.7332338001970347
Validation loss: 3.1152066269435466
Epoch: 5| Step: 3
Training loss: 3.4087536211487657
Validation loss: 3.1146069467635673
Epoch: 5| Step: 4
Training loss: 3.3626017842256233
Validation loss: 3.102528519223512
Epoch: 5| Step: 5
Training loss: 3.701493559775443
Validation loss: 3.085497717376341
Epoch: 5| Step: 6
Training loss: 3.497647993816339
Validation loss: 3.064193048218625
Epoch: 5| Step: 7
Training loss: 3.8142998621123576
Validation loss: 3.0445021669593566
Epoch: 5| Step: 8
Training loss: 3.416730802600844
Validation loss: 3.0448198871047643
Epoch: 5| Step: 9
Training loss: 3.7105355456651443
Validation loss: 3.035132578319212
Epoch: 14| Step: 0
Training loss: 3.2904047096179783
Validation loss: 3.0169413903529625
Epoch: 5| Step: 1
Training loss: 3.5242323560373854
Validation loss: 3.0055693221644795
Epoch: 5| Step: 2
Training loss: 3.6634658945921474
Validation loss: 2.995918660789923
Epoch: 5| Step: 3
Training loss: 3.2972829846513907
Validation loss: 2.982125516771144
Epoch: 5| Step: 4
Training loss: 3.9248630038122156
Validation loss: 2.97217289281669
Epoch: 5| Step: 5
Training loss: 3.247635201098495
Validation loss: 2.9620199885237306
Epoch: 5| Step: 6
Training loss: 3.3835186298410482
Validation loss: 2.949008517937921
Epoch: 5| Step: 7
Training loss: 3.6026355526773783
Validation loss: 2.9368956740919083
Epoch: 5| Step: 8
Training loss: 3.2692201527902136
Validation loss: 2.926006748208978
Epoch: 5| Step: 9
Training loss: 3.5244072977214103
Validation loss: 2.8742502805858066
Epoch: 15| Step: 0
Training loss: 3.938645090384542
Validation loss: 2.8955172177677344
Epoch: 5| Step: 1
Training loss: 3.549859895762228
Validation loss: 2.8809859681775065
Epoch: 5| Step: 2
Training loss: 3.7197800179524068
Validation loss: 2.859705170802004
Epoch: 5| Step: 3
Training loss: 4.002452098743266
Validation loss: 2.8507796458214356
Epoch: 5| Step: 4
Training loss: 2.712427702612668
Validation loss: 2.8309952523887723
Epoch: 5| Step: 5
Training loss: 2.843484719447503
Validation loss: 2.823870147268247
Epoch: 5| Step: 6
Training loss: 2.970379191637704
Validation loss: 2.808591775807068
Epoch: 5| Step: 7
Training loss: 2.9080667047419175
Validation loss: 2.7845789810834414
Epoch: 5| Step: 8
Training loss: 3.3259648579514676
Validation loss: 2.7814900791600397
Epoch: 5| Step: 9
Training loss: 3.3039399873026243
Validation loss: 2.742305998741868
Epoch: 16| Step: 0
Training loss: 3.133101528467136
Validation loss: 2.743112088138756
Epoch: 5| Step: 1
Training loss: 3.4392062027617283
Validation loss: 2.718339590722841
Epoch: 5| Step: 2
Training loss: 2.91115787345595
Validation loss: 2.72209545432112
Epoch: 5| Step: 3
Training loss: 3.8237419103890398
Validation loss: 2.6724570754879866
Epoch: 5| Step: 4
Training loss: 3.0148123006769407
Validation loss: 2.6961689030273237
Epoch: 5| Step: 5
Training loss: 2.9589474716655046
Validation loss: 2.685900559178256
Epoch: 5| Step: 6
Training loss: 3.525039748380312
Validation loss: 2.650462150710581
Epoch: 5| Step: 7
Training loss: 3.1233433719285055
Validation loss: 2.642257385237348
Epoch: 5| Step: 8
Training loss: 3.3446622655772535
Validation loss: 2.6325679723038604
Epoch: 5| Step: 9
Training loss: 2.706635505406067
Validation loss: 2.599283475539284
Epoch: 17| Step: 0
Training loss: 3.3715545586883082
Validation loss: 2.597519993243876
Epoch: 5| Step: 1
Training loss: 3.418656041390168
Validation loss: 2.5844340906576413
Epoch: 5| Step: 2
Training loss: 3.2790781735440357
Validation loss: 2.55832505833998
Epoch: 5| Step: 3
Training loss: 3.0417913820661204
Validation loss: 2.556196753660688
Epoch: 5| Step: 4
Training loss: 3.150574671080919
Validation loss: 2.5359463212777786
Epoch: 5| Step: 5
Training loss: 2.6006061067561843
Validation loss: 2.5062734368669615
Epoch: 5| Step: 6
Training loss: 3.1626880815991414
Validation loss: 2.4961538217792296
Epoch: 5| Step: 7
Training loss: 2.788071742247138
Validation loss: 2.4816782966642585
Epoch: 5| Step: 8
Training loss: 2.79353141185551
Validation loss: 2.471090034322967
Epoch: 5| Step: 9
Training loss: 3.0696703989243255
Validation loss: 2.461430565100218
Epoch: 18| Step: 0
Training loss: 2.961589972841671
Validation loss: 2.4467898035731945
Epoch: 5| Step: 1
Training loss: 3.0405492602615647
Validation loss: 2.4321237549004953
Epoch: 5| Step: 2
Training loss: 2.903499162787147
Validation loss: 2.416359936394335
Epoch: 5| Step: 3
Training loss: 3.4266811393798293
Validation loss: 2.3884948168537603
Epoch: 5| Step: 4
Training loss: 2.545266702613473
Validation loss: 2.3864739252759453
Epoch: 5| Step: 5
Training loss: 2.9568862778717264
Validation loss: 2.366618245889829
Epoch: 5| Step: 6
Training loss: 2.863772486744532
Validation loss: 2.360685420007618
Epoch: 5| Step: 7
Training loss: 2.9554934414652227
Validation loss: 2.3479929446437042
Epoch: 5| Step: 8
Training loss: 2.354544032636369
Validation loss: 2.3207436844939404
Epoch: 5| Step: 9
Training loss: 3.051725781081898
Validation loss: 2.3075200998218857
Epoch: 19| Step: 0
Training loss: 2.950467321590172
Validation loss: 2.300279376794195
Epoch: 5| Step: 1
Training loss: 2.591141457609894
Validation loss: 2.255023486930469
Epoch: 5| Step: 2
Training loss: 2.9193736094277725
Validation loss: 2.2803324470334974
Epoch: 5| Step: 3
Training loss: 3.107936353790313
Validation loss: 2.2315015219486076
Epoch: 5| Step: 4
Training loss: 2.681983609086144
Validation loss: 2.2516534868172484
Epoch: 5| Step: 5
Training loss: 2.8367653051037256
Validation loss: 2.23549332498423
Epoch: 5| Step: 6
Training loss: 2.540225657554145
Validation loss: 2.2378605171390222
Epoch: 5| Step: 7
Training loss: 2.960646159551639
Validation loss: 2.2052562293651636
Epoch: 5| Step: 8
Training loss: 2.689304189775951
Validation loss: 2.2015803837994072
Epoch: 5| Step: 9
Training loss: 2.48770206723341
Validation loss: 2.1860969582232834
Epoch: 20| Step: 0
Training loss: 3.0310678329000824
Validation loss: 2.1868370974050917
Epoch: 5| Step: 1
Training loss: 2.4450051598991758
Validation loss: 2.183848208651829
Epoch: 5| Step: 2
Training loss: 2.8734821791128615
Validation loss: 2.1750667585182013
Epoch: 5| Step: 3
Training loss: 2.267752339244667
Validation loss: 2.163427856445406
Epoch: 5| Step: 4
Training loss: 2.639164085985164
Validation loss: 2.146682473043608
Epoch: 5| Step: 5
Training loss: 3.0519009341439336
Validation loss: 2.1424838372285393
Epoch: 5| Step: 6
Training loss: 2.1819000499711176
Validation loss: 2.130159306653806
Epoch: 5| Step: 7
Training loss: 2.5751414287949115
Validation loss: 2.1179157681959127
Epoch: 5| Step: 8
Training loss: 2.832280430848055
Validation loss: 2.11751922829629
Epoch: 5| Step: 9
Training loss: 2.6160992081988543
Validation loss: 2.111225451909305
Epoch: 21| Step: 0
Training loss: 2.726538453091712
Validation loss: 2.0982299295703615
Epoch: 5| Step: 1
Training loss: 2.693638378406249
Validation loss: 2.1002088723342007
Epoch: 5| Step: 2
Training loss: 2.4751134056542963
Validation loss: 2.099545067193806
Epoch: 5| Step: 3
Training loss: 2.747438277990905
Validation loss: 2.0916154409557097
Epoch: 5| Step: 4
Training loss: 2.586645115962493
Validation loss: 2.0861959500791505
Epoch: 5| Step: 5
Training loss: 2.3389672881110406
Validation loss: 2.0845938850679975
Epoch: 5| Step: 6
Training loss: 2.551949903672102
Validation loss: 2.060661318855831
Epoch: 5| Step: 7
Training loss: 2.658259809507669
Validation loss: 2.08781067407136
Epoch: 5| Step: 8
Training loss: 2.1256703833984756
Validation loss: 2.084107869959677
Epoch: 5| Step: 9
Training loss: 2.8766968736650202
Validation loss: 2.068816133531101
Epoch: 22| Step: 0
Training loss: 2.5934414967369266
Validation loss: 2.0771096505741635
Epoch: 5| Step: 1
Training loss: 2.284790635815833
Validation loss: 2.065804256350984
Epoch: 5| Step: 2
Training loss: 2.237443004713376
Validation loss: 2.0753309492157075
Epoch: 5| Step: 3
Training loss: 2.1332223798787084
Validation loss: 2.068309281275034
Epoch: 5| Step: 4
Training loss: 2.795864156978544
Validation loss: 2.072462591479957
Epoch: 5| Step: 5
Training loss: 2.097560091851536
Validation loss: 2.0837767215728418
Epoch: 5| Step: 6
Training loss: 3.0917327160904677
Validation loss: 2.0721434137717307
Epoch: 5| Step: 7
Training loss: 2.774171372151149
Validation loss: 2.0858150232986916
Epoch: 5| Step: 8
Training loss: 2.5439863615330203
Validation loss: 2.0629159580909375
Epoch: 5| Step: 9
Training loss: 2.6631031266634473
Validation loss: 2.0660442230639635
Epoch: 23| Step: 0
Training loss: 2.2499995761447082
Validation loss: 2.08001114861522
Epoch: 5| Step: 1
Training loss: 2.7322392433325446
Validation loss: 2.081712360713852
Epoch: 5| Step: 2
Training loss: 2.2871596202983175
Validation loss: 2.081394033676754
Epoch: 5| Step: 3
Training loss: 2.500518935704135
Validation loss: 2.084345076065136
Epoch: 5| Step: 4
Training loss: 2.9260475434764506
Validation loss: 2.0819142350463222
Epoch: 5| Step: 5
Training loss: 2.235248314975777
Validation loss: 2.0897655511106343
Epoch: 5| Step: 6
Training loss: 2.847724233477765
Validation loss: 2.064878464749927
Epoch: 5| Step: 7
Training loss: 2.605987359953854
Validation loss: 2.0891738938786704
Epoch: 5| Step: 8
Training loss: 2.0141766689664027
Validation loss: 2.0880958565344083
Epoch: 5| Step: 9
Training loss: 2.643186511868475
Validation loss: 2.1134008836962463
Epoch: 24| Step: 0
Training loss: 2.298700450634938
Validation loss: 2.0872570664342143
Epoch: 5| Step: 1
Training loss: 2.678275578827048
Validation loss: 2.0989179636790016
Epoch: 5| Step: 2
Training loss: 2.2902526885967216
Validation loss: 2.1077267466585723
Epoch: 5| Step: 3
Training loss: 2.818249061207347
Validation loss: 2.0553924754362023
Epoch: 5| Step: 4
Training loss: 2.4193406165125397
Validation loss: 2.099186550956757
Epoch: 5| Step: 5
Training loss: 2.4711770790467162
Validation loss: 2.1025533567538677
Epoch: 5| Step: 6
Training loss: 2.7267169198190775
Validation loss: 2.110180795056083
Epoch: 5| Step: 7
Training loss: 2.679593988238326
Validation loss: 2.0850909822213346
Epoch: 5| Step: 8
Training loss: 2.346227125199617
Validation loss: 2.1080668864182797
Epoch: 5| Step: 9
Training loss: 2.3963886667802763
Validation loss: 2.1018459728273045
Epoch: 25| Step: 0
Training loss: 2.170320022822635
Validation loss: 2.0961847079389786
Epoch: 5| Step: 1
Training loss: 2.8890444171642886
Validation loss: 2.110853177959777
Epoch: 5| Step: 2
Training loss: 2.1741409008194963
Validation loss: 2.0988982916970684
Epoch: 5| Step: 3
Training loss: 2.305398811874686
Validation loss: 2.1131953190819237
Epoch: 5| Step: 4
Training loss: 2.5600175696008494
Validation loss: 2.1112671116821433
Epoch: 5| Step: 5
Training loss: 2.884181413529229
Validation loss: 2.1118465006350156
Epoch: 5| Step: 6
Training loss: 2.0633425292188647
Validation loss: 2.095232320380518
Epoch: 5| Step: 7
Training loss: 2.860371067010574
Validation loss: 2.0910934471815183
Epoch: 5| Step: 8
Training loss: 2.498413536238363
Validation loss: 2.0673763986461604
Epoch: 5| Step: 9
Training loss: 2.520508190865915
Validation loss: 2.1233048138185464
Epoch: 26| Step: 0
Training loss: 2.5439917034817614
Validation loss: 2.105179780883645
Epoch: 5| Step: 1
Training loss: 3.1428891650958914
Validation loss: 2.093196858515185
Epoch: 5| Step: 2
Training loss: 2.5710249727891727
Validation loss: 2.0927304560611732
Epoch: 5| Step: 3
Training loss: 2.292826711489217
Validation loss: 2.0923271937665087
Epoch: 5| Step: 4
Training loss: 2.3782771739820783
Validation loss: 2.1037118742495373
Epoch: 5| Step: 5
Training loss: 2.430091554463274
Validation loss: 2.1014867024366475
Epoch: 5| Step: 6
Training loss: 2.575912450955306
Validation loss: 2.1223228663206934
Epoch: 5| Step: 7
Training loss: 2.387790670226466
Validation loss: 2.1067818683319026
Epoch: 5| Step: 8
Training loss: 2.161103025593978
Validation loss: 2.096215144031397
Epoch: 5| Step: 9
Training loss: 2.5001889157442485
Validation loss: 2.09611361168786
Epoch: 27| Step: 0
Training loss: 2.4711030779604313
Validation loss: 2.091547051263794
Epoch: 5| Step: 1
Training loss: 2.4295952586238596
Validation loss: 2.074489862444497
Epoch: 5| Step: 2
Training loss: 2.5292753829926657
Validation loss: 2.091274024787254
Epoch: 5| Step: 3
Training loss: 2.8929427468956943
Validation loss: 2.0995996601751856
Epoch: 5| Step: 4
Training loss: 2.3289572233183837
Validation loss: 2.10957794229206
Epoch: 5| Step: 5
Training loss: 2.351481692931323
Validation loss: 2.0836252012979513
Epoch: 5| Step: 6
Training loss: 2.5279201693364137
Validation loss: 2.0885228962639877
Epoch: 5| Step: 7
Training loss: 2.122502823143689
Validation loss: 2.101896506079095
Epoch: 5| Step: 8
Training loss: 2.24042391120752
Validation loss: 2.0852132058409842
Epoch: 5| Step: 9
Training loss: 3.072572919509499
Validation loss: 2.1103220035524894
Epoch: 28| Step: 0
Training loss: 2.277564533713746
Validation loss: 2.099260955448905
Epoch: 5| Step: 1
Training loss: 2.327580535511498
Validation loss: 2.1130472028046565
Epoch: 5| Step: 2
Training loss: 2.639127498569335
Validation loss: 2.086708221039014
Epoch: 5| Step: 3
Training loss: 2.0144344628553097
Validation loss: 2.0909881062131044
Epoch: 5| Step: 4
Training loss: 2.6825463528996703
Validation loss: 2.0978586526125067
Epoch: 5| Step: 5
Training loss: 2.7662801020553474
Validation loss: 2.0884645548036906
Epoch: 5| Step: 6
Training loss: 2.3834568840850126
Validation loss: 2.1156358119357273
Epoch: 5| Step: 7
Training loss: 2.2671316464653715
Validation loss: 2.106113808548724
Epoch: 5| Step: 8
Training loss: 3.177560455683562
Validation loss: 2.0890267123528203
Epoch: 5| Step: 9
Training loss: 2.337174308240793
Validation loss: 2.0979034957274347
Epoch: 29| Step: 0
Training loss: 2.583953557367721
Validation loss: 2.11056236095407
Epoch: 5| Step: 1
Training loss: 2.315447810056662
Validation loss: 2.1012667533568234
Epoch: 5| Step: 2
Training loss: 2.512063294980013
Validation loss: 2.0924767029057527
Epoch: 5| Step: 3
Training loss: 2.2296217932105162
Validation loss: 2.1012958707952616
Epoch: 5| Step: 4
Training loss: 2.482260421917003
Validation loss: 2.0987841632279656
Epoch: 5| Step: 5
Training loss: 2.6025761642817393
Validation loss: 2.090426434292931
Epoch: 5| Step: 6
Training loss: 2.9090221678675
Validation loss: 2.0989374536775105
Epoch: 5| Step: 7
Training loss: 2.2548943375152093
Validation loss: 2.0967521291348894
Epoch: 5| Step: 8
Training loss: 2.9510581236350233
Validation loss: 2.0921111380855204
Epoch: 5| Step: 9
Training loss: 2.1917426247240406
Validation loss: 2.0946766007265767
Epoch: 30| Step: 0
Training loss: 1.885091454996593
Validation loss: 2.0868003894793685
Epoch: 5| Step: 1
Training loss: 2.6670449306506585
Validation loss: 2.094778406319343
Epoch: 5| Step: 2
Training loss: 2.432799869570718
Validation loss: 2.0820761855276575
Epoch: 5| Step: 3
Training loss: 2.2351535961104703
Validation loss: 2.0850296218229976
Epoch: 5| Step: 4
Training loss: 2.827422165343233
Validation loss: 2.0976520421701723
Epoch: 5| Step: 5
Training loss: 2.2989102643035704
Validation loss: 2.09596181562494
Epoch: 5| Step: 6
Training loss: 2.634140630503066
Validation loss: 2.095063362845277
Epoch: 5| Step: 7
Training loss: 2.665114477536611
Validation loss: 2.0986749149559367
Epoch: 5| Step: 8
Training loss: 2.840694252907373
Validation loss: 2.0933134102720428
Epoch: 5| Step: 9
Training loss: 2.393068647899251
Validation loss: 2.0905524034482466
Epoch: 31| Step: 0
Training loss: 2.5864865737174254
Validation loss: 2.083186496686429
Epoch: 5| Step: 1
Training loss: 2.607364451029653
Validation loss: 2.082292436674774
Epoch: 5| Step: 2
Training loss: 2.720996498562692
Validation loss: 2.106264816818075
Epoch: 5| Step: 3
Training loss: 2.3329390351611345
Validation loss: 2.100074012932402
Epoch: 5| Step: 4
Training loss: 2.749869430216596
Validation loss: 2.10990922057653
Epoch: 5| Step: 5
Training loss: 2.1175389297311638
Validation loss: 2.1010025194628783
Epoch: 5| Step: 6
Training loss: 2.4432939967397282
Validation loss: 2.091012262247911
Epoch: 5| Step: 7
Training loss: 2.3797668002986576
Validation loss: 2.0947484402507355
Epoch: 5| Step: 8
Training loss: 2.6254955005741594
Validation loss: 2.098835587206848
Epoch: 5| Step: 9
Training loss: 2.390465026689
Validation loss: 2.09174335482209
Epoch: 32| Step: 0
Training loss: 2.5003863989721746
Validation loss: 2.0952238705228097
Epoch: 5| Step: 1
Training loss: 2.6206468181215894
Validation loss: 2.0959835272256786
Epoch: 5| Step: 2
Training loss: 2.673764101965883
Validation loss: 2.0879049160099687
Epoch: 5| Step: 3
Training loss: 2.2059610928712496
Validation loss: 2.1037769602529774
Epoch: 5| Step: 4
Training loss: 2.0789144063543725
Validation loss: 2.061231719828015
Epoch: 5| Step: 5
Training loss: 2.12355194120249
Validation loss: 2.0993598119583767
Epoch: 5| Step: 6
Training loss: 2.7478063677404068
Validation loss: 2.089634760660717
Epoch: 5| Step: 7
Training loss: 3.418016182706592
Validation loss: 2.100705535943917
Epoch: 5| Step: 8
Training loss: 2.1468322305430934
Validation loss: 2.0889944355680226
Epoch: 5| Step: 9
Training loss: 2.2585304465142886
Validation loss: 2.0975091912361035
Epoch: 33| Step: 0
Training loss: 2.3756751054649863
Validation loss: 2.10433137263738
Epoch: 5| Step: 1
Training loss: 2.501426099290643
Validation loss: 2.076581629073448
Epoch: 5| Step: 2
Training loss: 2.6421439412574106
Validation loss: 2.076281338096236
Epoch: 5| Step: 3
Training loss: 2.867372096301326
Validation loss: 2.073035863096559
Epoch: 5| Step: 4
Training loss: 2.2314028946665854
Validation loss: 2.0931650570784295
Epoch: 5| Step: 5
Training loss: 2.4580332254968575
Validation loss: 2.070622779675224
Epoch: 5| Step: 6
Training loss: 2.3407573667616273
Validation loss: 2.0930980845141307
Epoch: 5| Step: 7
Training loss: 2.608080331477904
Validation loss: 2.0887577213615844
Epoch: 5| Step: 8
Training loss: 2.6090109565478485
Validation loss: 2.0805014624526983
Epoch: 5| Step: 9
Training loss: 2.320232967978819
Validation loss: 2.056144026458321
Epoch: 34| Step: 0
Training loss: 2.9457319451725508
Validation loss: 2.09263374870106
Epoch: 5| Step: 1
Training loss: 2.3882534256332235
Validation loss: 2.0933734052877555
Epoch: 5| Step: 2
Training loss: 2.499724945196119
Validation loss: 2.066875162251446
Epoch: 5| Step: 3
Training loss: 2.5745082570867988
Validation loss: 2.0924119838461306
Epoch: 5| Step: 4
Training loss: 2.7028137204205733
Validation loss: 2.0963933435427298
Epoch: 5| Step: 5
Training loss: 2.1120535339231985
Validation loss: 2.1027427076539267
Epoch: 5| Step: 6
Training loss: 2.0995868912313598
Validation loss: 2.0846853772053326
Epoch: 5| Step: 7
Training loss: 2.5069489225122736
Validation loss: 2.089326781471134
Epoch: 5| Step: 8
Training loss: 2.6613322388003944
Validation loss: 2.078105622824004
Epoch: 5| Step: 9
Training loss: 2.3459799775474877
Validation loss: 2.0932068860575965
Epoch: 35| Step: 0
Training loss: 2.2575602142989015
Validation loss: 2.0974542550600694
Epoch: 5| Step: 1
Training loss: 2.5153046398061356
Validation loss: 2.0938950871459685
Epoch: 5| Step: 2
Training loss: 2.3358838129412676
Validation loss: 2.0963702859827067
Epoch: 5| Step: 3
Training loss: 2.1545573792092836
Validation loss: 2.1023476583927336
Epoch: 5| Step: 4
Training loss: 2.376127477353699
Validation loss: 2.100793459605859
Epoch: 5| Step: 5
Training loss: 2.6832953096937837
Validation loss: 2.0849712278371246
Epoch: 5| Step: 6
Training loss: 2.5769837598958767
Validation loss: 2.081460975101565
Epoch: 5| Step: 7
Training loss: 2.7613405996632565
Validation loss: 2.0765349034544944
Epoch: 5| Step: 8
Training loss: 2.081655615152914
Validation loss: 2.09468127110844
Epoch: 5| Step: 9
Training loss: 3.0170551920980047
Validation loss: 2.0950361953229946
Epoch: 36| Step: 0
Training loss: 2.277895512161379
Validation loss: 2.0987196120263176
Epoch: 5| Step: 1
Training loss: 2.5842069153745655
Validation loss: 2.0969959236623943
Epoch: 5| Step: 2
Training loss: 2.087167213091187
Validation loss: 2.1017660097451505
Epoch: 5| Step: 3
Training loss: 2.381072462777655
Validation loss: 2.0933575266316726
Epoch: 5| Step: 4
Training loss: 2.6572213584683513
Validation loss: 2.10196287938773
Epoch: 5| Step: 5
Training loss: 2.2232525768035605
Validation loss: 2.1008349922818987
Epoch: 5| Step: 6
Training loss: 2.624562908294394
Validation loss: 2.079170174785515
Epoch: 5| Step: 7
Training loss: 2.6491978096928874
Validation loss: 2.07610848483295
Epoch: 5| Step: 8
Training loss: 2.7752541193724056
Validation loss: 2.0862632213628323
Epoch: 5| Step: 9
Training loss: 2.6302965407483905
Validation loss: 2.0965096621050185
Epoch: 37| Step: 0
Training loss: 2.4895550927086045
Validation loss: 2.102550912687579
Epoch: 5| Step: 1
Training loss: 2.6058170022951885
Validation loss: 2.1012893557271988
Epoch: 5| Step: 2
Training loss: 2.331645786754527
Validation loss: 2.08636552302622
Epoch: 5| Step: 3
Training loss: 2.9385570491012682
Validation loss: 2.075830951742167
Epoch: 5| Step: 4
Training loss: 2.466214966870768
Validation loss: 2.0817490235221383
Epoch: 5| Step: 5
Training loss: 2.2401667936419782
Validation loss: 2.0825043050424323
Epoch: 5| Step: 6
Training loss: 2.7616203322942874
Validation loss: 2.0844700041456923
Epoch: 5| Step: 7
Training loss: 2.328800180317365
Validation loss: 2.0955136556589395
Epoch: 5| Step: 8
Training loss: 2.534535101220989
Validation loss: 2.095678245978006
Epoch: 5| Step: 9
Training loss: 2.2140068612548043
Validation loss: 2.0641301778911254
Epoch: 38| Step: 0
Training loss: 2.147961373022699
Validation loss: 2.071855376919437
Epoch: 5| Step: 1
Training loss: 2.212420070950139
Validation loss: 2.0711542648640693
Epoch: 5| Step: 2
Training loss: 2.44601089205621
Validation loss: 2.077813911215047
Epoch: 5| Step: 3
Training loss: 2.514290876429696
Validation loss: 2.0833869597746695
Epoch: 5| Step: 4
Training loss: 2.599961713362277
Validation loss: 2.0585068571054643
Epoch: 5| Step: 5
Training loss: 2.527095257719692
Validation loss: 2.0777778477054203
Epoch: 5| Step: 6
Training loss: 2.6783107412730973
Validation loss: 2.0923335389255278
Epoch: 5| Step: 7
Training loss: 2.2242647863674567
Validation loss: 2.090576603750548
Epoch: 5| Step: 8
Training loss: 2.516037616891253
Validation loss: 2.090981467926075
Epoch: 5| Step: 9
Training loss: 2.9698439339371623
Validation loss: 2.083162345831571
Epoch: 39| Step: 0
Training loss: 2.2701898298839454
Validation loss: 2.0721158367981727
Epoch: 5| Step: 1
Training loss: 2.2529946637384617
Validation loss: 2.080588099051339
Epoch: 5| Step: 2
Training loss: 2.67093619645956
Validation loss: 2.0981227652353116
Epoch: 5| Step: 3
Training loss: 2.906218497813138
Validation loss: 2.07673585528707
Epoch: 5| Step: 4
Training loss: 2.555470011380478
Validation loss: 2.0874591342623496
Epoch: 5| Step: 5
Training loss: 2.2198215100128924
Validation loss: 2.073395282512057
Epoch: 5| Step: 6
Training loss: 2.5198055620718423
Validation loss: 2.070778836144152
Epoch: 5| Step: 7
Training loss: 3.092237006239785
Validation loss: 2.0761958565254393
Epoch: 5| Step: 8
Training loss: 2.0297932022445475
Validation loss: 2.073038594209871
Epoch: 5| Step: 9
Training loss: 2.226636597588328
Validation loss: 2.0780271793846525
Epoch: 40| Step: 0
Training loss: 2.44760229378169
Validation loss: 2.089031662687264
Epoch: 5| Step: 1
Training loss: 2.8025274858309404
Validation loss: 2.103926086750272
Epoch: 5| Step: 2
Training loss: 2.9023555791313447
Validation loss: 2.0882656424140853
Epoch: 5| Step: 3
Training loss: 2.5585316890731877
Validation loss: 2.0881913154199703
Epoch: 5| Step: 4
Training loss: 2.204886523590087
Validation loss: 2.062928502027453
Epoch: 5| Step: 5
Training loss: 2.374821706403879
Validation loss: 2.0650303603854163
Epoch: 5| Step: 6
Training loss: 2.540874691338107
Validation loss: 2.0889454834642858
Epoch: 5| Step: 7
Training loss: 1.9492983754011475
Validation loss: 2.085731318361237
Epoch: 5| Step: 8
Training loss: 2.1144244756049124
Validation loss: 2.086031670604511
Epoch: 5| Step: 9
Training loss: 2.853576784829689
Validation loss: 2.085715018623026
Epoch: 41| Step: 0
Training loss: 2.7353725684495553
Validation loss: 2.0836541150126004
Epoch: 5| Step: 1
Training loss: 2.134709894093269
Validation loss: 2.0841082791468177
Epoch: 5| Step: 2
Training loss: 2.105480300220522
Validation loss: 2.0939266647046075
Epoch: 5| Step: 3
Training loss: 2.035334075949257
Validation loss: 2.0812049237671313
Epoch: 5| Step: 4
Training loss: 2.028819816549134
Validation loss: 2.0749236131384254
Epoch: 5| Step: 5
Training loss: 2.3507867591821245
Validation loss: 2.0908490006683498
Epoch: 5| Step: 6
Training loss: 2.540099885733708
Validation loss: 2.0893601568697857
Epoch: 5| Step: 7
Training loss: 2.853000226170223
Validation loss: 2.0798785432994547
Epoch: 5| Step: 8
Training loss: 2.8022466467780207
Validation loss: 2.075714396026971
Epoch: 5| Step: 9
Training loss: 3.094143004453226
Validation loss: 2.063628997838005
Epoch: 42| Step: 0
Training loss: 2.663034548401775
Validation loss: 2.081281314897106
Epoch: 5| Step: 1
Training loss: 2.3581516555343227
Validation loss: 2.0827705172346804
Epoch: 5| Step: 2
Training loss: 2.644421258213894
Validation loss: 2.0809791065932086
Epoch: 5| Step: 3
Training loss: 2.7608794969943595
Validation loss: 2.079780543746812
Epoch: 5| Step: 4
Training loss: 2.152780588893354
Validation loss: 2.0714149102052666
Epoch: 5| Step: 5
Training loss: 2.663044486092188
Validation loss: 2.0829250921502336
Epoch: 5| Step: 6
Training loss: 2.8295124507454177
Validation loss: 2.0772798027562116
Epoch: 5| Step: 7
Training loss: 2.3105918641277263
Validation loss: 2.063260058687565
Epoch: 5| Step: 8
Training loss: 2.348816545243159
Validation loss: 2.0683404697331373
Epoch: 5| Step: 9
Training loss: 2.0533885258320694
Validation loss: 2.0741146757320656
Epoch: 43| Step: 0
Training loss: 2.4816674407418065
Validation loss: 2.062260616799767
Epoch: 5| Step: 1
Training loss: 2.1151586291839504
Validation loss: 2.0727860877614646
Epoch: 5| Step: 2
Training loss: 2.284324351113227
Validation loss: 2.0726015916307183
Epoch: 5| Step: 3
Training loss: 2.6358513655775884
Validation loss: 2.0643032936222947
Epoch: 5| Step: 4
Training loss: 2.105985050912748
Validation loss: 2.061025769918504
Epoch: 5| Step: 5
Training loss: 3.061874948670168
Validation loss: 2.080471557269512
Epoch: 5| Step: 6
Training loss: 2.6448642628099015
Validation loss: 2.0756517223822604
Epoch: 5| Step: 7
Training loss: 2.5677011320826906
Validation loss: 2.0776738841926354
Epoch: 5| Step: 8
Training loss: 2.324548213912482
Validation loss: 2.0646604870789944
Epoch: 5| Step: 9
Training loss: 2.491691229028318
Validation loss: 2.0912085114119807
Epoch: 44| Step: 0
Training loss: 2.5058765009401136
Validation loss: 2.087582311207021
Epoch: 5| Step: 1
Training loss: 2.4105358844927505
Validation loss: 2.0680027440678064
Epoch: 5| Step: 2
Training loss: 2.442484137055065
Validation loss: 2.0738115411504903
Epoch: 5| Step: 3
Training loss: 2.3926859430426073
Validation loss: 2.068757187252668
Epoch: 5| Step: 4
Training loss: 2.3219448731127135
Validation loss: 2.0537364622444803
Epoch: 5| Step: 5
Training loss: 2.6530775086159153
Validation loss: 2.0858801660283026
Epoch: 5| Step: 6
Training loss: 2.5184700557101705
Validation loss: 2.079390424303347
Epoch: 5| Step: 7
Training loss: 2.264965303336319
Validation loss: 2.0863922494266367
Epoch: 5| Step: 8
Training loss: 2.7000142097099227
Validation loss: 2.073505305444942
Epoch: 5| Step: 9
Training loss: 2.6229292558444177
Validation loss: 2.057512007671892
Epoch: 45| Step: 0
Training loss: 2.3539696219922224
Validation loss: 2.0835379841228705
Epoch: 5| Step: 1
Training loss: 2.847863711739396
Validation loss: 2.0873495331038283
Epoch: 5| Step: 2
Training loss: 2.3756052551011004
Validation loss: 2.0787475425191198
Epoch: 5| Step: 3
Training loss: 2.447185932149666
Validation loss: 2.0664837122444033
Epoch: 5| Step: 4
Training loss: 2.4322588398996556
Validation loss: 2.0571021002547982
Epoch: 5| Step: 5
Training loss: 2.0374165757775637
Validation loss: 2.066837894293373
Epoch: 5| Step: 6
Training loss: 2.579634715694929
Validation loss: 2.0632938384501
Epoch: 5| Step: 7
Training loss: 2.6270679321160295
Validation loss: 2.0769834052458536
Epoch: 5| Step: 8
Training loss: 2.130906815179976
Validation loss: 2.076628008073709
Epoch: 5| Step: 9
Training loss: 2.8432955535966604
Validation loss: 2.0567260589685907
Epoch: 46| Step: 0
Training loss: 2.0767990126873426
Validation loss: 2.0468156335508554
Epoch: 5| Step: 1
Training loss: 2.9507433455832626
Validation loss: 2.068298404704534
Epoch: 5| Step: 2
Training loss: 2.7773863283480265
Validation loss: 2.081885729485627
Epoch: 5| Step: 3
Training loss: 2.2358336055990993
Validation loss: 2.08679141599064
Epoch: 5| Step: 4
Training loss: 2.0474139952616235
Validation loss: 2.0780321624796576
Epoch: 5| Step: 5
Training loss: 2.3835686156261473
Validation loss: 2.068024031459187
Epoch: 5| Step: 6
Training loss: 2.448399943810462
Validation loss: 2.0768042286369033
Epoch: 5| Step: 7
Training loss: 2.6936401486401653
Validation loss: 2.0946830440667408
Epoch: 5| Step: 8
Training loss: 2.3569567078412663
Validation loss: 2.081503377009114
Epoch: 5| Step: 9
Training loss: 2.7215620384342945
Validation loss: 2.0450985903655923
Epoch: 47| Step: 0
Training loss: 2.1550720978113787
Validation loss: 2.0780284008434946
Epoch: 5| Step: 1
Training loss: 2.6204241879521506
Validation loss: 2.0737967731724223
Epoch: 5| Step: 2
Training loss: 2.502881297083919
Validation loss: 2.0697820349240974
Epoch: 5| Step: 3
Training loss: 2.441180067647748
Validation loss: 2.0841525932098737
Epoch: 5| Step: 4
Training loss: 2.552957771642348
Validation loss: 2.078003312976343
Epoch: 5| Step: 5
Training loss: 2.4302736415554844
Validation loss: 2.072656946578575
Epoch: 5| Step: 6
Training loss: 2.483568936464299
Validation loss: 2.075881971646893
Epoch: 5| Step: 7
Training loss: 2.4158732218857955
Validation loss: 2.061429342654472
Epoch: 5| Step: 8
Training loss: 2.57932267546586
Validation loss: 2.0786196369671033
Epoch: 5| Step: 9
Training loss: 2.6179229158574517
Validation loss: 2.056760481212788
Epoch: 48| Step: 0
Training loss: 2.6348731243127412
Validation loss: 2.0555165251752516
Epoch: 5| Step: 1
Training loss: 2.532186452692845
Validation loss: 2.080161828120433
Epoch: 5| Step: 2
Training loss: 2.4370086370290824
Validation loss: 2.0619216039185426
Epoch: 5| Step: 3
Training loss: 2.401898300927424
Validation loss: 2.068493129415953
Epoch: 5| Step: 4
Training loss: 2.312216767157962
Validation loss: 2.06511255802219
Epoch: 5| Step: 5
Training loss: 2.750587574002744
Validation loss: 2.062521921126974
Epoch: 5| Step: 6
Training loss: 2.598059693177107
Validation loss: 2.058594130158569
Epoch: 5| Step: 7
Training loss: 2.447062588220609
Validation loss: 2.0574877677329786
Epoch: 5| Step: 8
Training loss: 2.077822785164869
Validation loss: 2.057769567114348
Epoch: 5| Step: 9
Training loss: 2.5283581261958394
Validation loss: 2.0572750183791224
Epoch: 49| Step: 0
Training loss: 2.4866855840841233
Validation loss: 2.0712203100640214
Epoch: 5| Step: 1
Training loss: 2.497922797324129
Validation loss: 2.0765591743347356
Epoch: 5| Step: 2
Training loss: 2.529899331001137
Validation loss: 2.05338440044037
Epoch: 5| Step: 3
Training loss: 2.6946229799074333
Validation loss: 2.0636883678714906
Epoch: 5| Step: 4
Training loss: 2.5629910254468307
Validation loss: 2.0726635864408407
Epoch: 5| Step: 5
Training loss: 2.647645184765901
Validation loss: 2.062261327011255
Epoch: 5| Step: 6
Training loss: 2.026806240085883
Validation loss: 2.070702318991126
Epoch: 5| Step: 7
Training loss: 2.2396770605538845
Validation loss: 2.065860711527411
Epoch: 5| Step: 8
Training loss: 2.43576075785635
Validation loss: 2.0732710389602684
Epoch: 5| Step: 9
Training loss: 2.6201247401062875
Validation loss: 2.0619136267792837
Epoch: 50| Step: 0
Training loss: 1.9992816350183948
Validation loss: 2.0730228554870305
Epoch: 5| Step: 1
Training loss: 1.9300273642304833
Validation loss: 2.061637841143475
Epoch: 5| Step: 2
Training loss: 3.055025282035642
Validation loss: 2.0579130887157846
Epoch: 5| Step: 3
Training loss: 2.3647342471279504
Validation loss: 2.0446269089811433
Epoch: 5| Step: 4
Training loss: 2.745084617853079
Validation loss: 2.0534496297311797
Epoch: 5| Step: 5
Training loss: 2.5252227609402316
Validation loss: 2.0670902812767045
Epoch: 5| Step: 6
Training loss: 2.242023315798474
Validation loss: 2.0706246615135377
Epoch: 5| Step: 7
Training loss: 3.0797577995587364
Validation loss: 2.076014715782147
Epoch: 5| Step: 8
Training loss: 2.33612468058843
Validation loss: 2.055787506938163
Epoch: 5| Step: 9
Training loss: 2.2153196008681184
Validation loss: 2.0845617773102507
Epoch: 51| Step: 0
Training loss: 2.4853074345296635
Validation loss: 2.0891011091121254
Epoch: 5| Step: 1
Training loss: 2.1020942780959913
Validation loss: 2.0664272255753287
Epoch: 5| Step: 2
Training loss: 2.289304961295141
Validation loss: 2.071880296153181
Epoch: 5| Step: 3
Training loss: 2.5129642987521685
Validation loss: 2.0754539487099137
Epoch: 5| Step: 4
Training loss: 2.058320173872711
Validation loss: 2.0522771058457825
Epoch: 5| Step: 5
Training loss: 2.550384911302759
Validation loss: 2.072219676922882
Epoch: 5| Step: 6
Training loss: 3.1250137328799816
Validation loss: 2.0395114014905262
Epoch: 5| Step: 7
Training loss: 2.295509814979876
Validation loss: 2.079808555642982
Epoch: 5| Step: 8
Training loss: 2.5649768675119824
Validation loss: 2.0723566625730556
Epoch: 5| Step: 9
Training loss: 2.6139727078262966
Validation loss: 2.064296602273322
Epoch: 52| Step: 0
Training loss: 2.522993208093985
Validation loss: 2.0800397108772364
Epoch: 5| Step: 1
Training loss: 2.5587009087173507
Validation loss: 2.079974114185099
Epoch: 5| Step: 2
Training loss: 2.5301417055514692
Validation loss: 2.0676500415956856
Epoch: 5| Step: 3
Training loss: 2.18002994814259
Validation loss: 2.0862372422651414
Epoch: 5| Step: 4
Training loss: 2.4007899772368733
Validation loss: 2.0649423462551537
Epoch: 5| Step: 5
Training loss: 2.3623553519396463
Validation loss: 2.060581059928309
Epoch: 5| Step: 6
Training loss: 2.3629793841301745
Validation loss: 2.058250541442038
Epoch: 5| Step: 7
Training loss: 2.3556134889584057
Validation loss: 2.060914480474218
Epoch: 5| Step: 8
Training loss: 2.6367626949462952
Validation loss: 2.069785001115396
Epoch: 5| Step: 9
Training loss: 2.743049855501286
Validation loss: 2.0565793230476057
Epoch: 53| Step: 0
Training loss: 2.896714513256955
Validation loss: 2.066116232520027
Epoch: 5| Step: 1
Training loss: 2.569099487884792
Validation loss: 2.053268565518284
Epoch: 5| Step: 2
Training loss: 2.5190614720711446
Validation loss: 2.0608895095655275
Epoch: 5| Step: 3
Training loss: 2.1079871238952235
Validation loss: 2.065681686839943
Epoch: 5| Step: 4
Training loss: 2.446638631304918
Validation loss: 2.0470430555745596
Epoch: 5| Step: 5
Training loss: 2.704793514331487
Validation loss: 2.055610452646524
Epoch: 5| Step: 6
Training loss: 2.3288372409632796
Validation loss: 2.049766216507242
Epoch: 5| Step: 7
Training loss: 2.607520078031313
Validation loss: 2.0744364300931237
Epoch: 5| Step: 8
Training loss: 2.2277407021844877
Validation loss: 2.0600045369000353
Epoch: 5| Step: 9
Training loss: 2.279889367247013
Validation loss: 2.0694088656532297
Epoch: 54| Step: 0
Training loss: 2.4324618381435417
Validation loss: 2.053142990586802
Epoch: 5| Step: 1
Training loss: 1.9852311097329485
Validation loss: 2.0636802841474697
Epoch: 5| Step: 2
Training loss: 2.4273434828361213
Validation loss: 2.0640364934015865
Epoch: 5| Step: 3
Training loss: 2.1001594709972347
Validation loss: 2.071202428137286
Epoch: 5| Step: 4
Training loss: 3.0019373995704743
Validation loss: 2.0529259144678775
Epoch: 5| Step: 5
Training loss: 2.6090745581621135
Validation loss: 2.066641829674491
Epoch: 5| Step: 6
Training loss: 2.7521348816064912
Validation loss: 2.0272772978156404
Epoch: 5| Step: 7
Training loss: 2.4112080608258495
Validation loss: 2.0625602581642846
Epoch: 5| Step: 8
Training loss: 2.275894777168568
Validation loss: 2.040521831928858
Epoch: 5| Step: 9
Training loss: 2.573428042683366
Validation loss: 2.0403245429086287
Epoch: 55| Step: 0
Training loss: 2.5438319087607373
Validation loss: 2.069040775252466
Epoch: 5| Step: 1
Training loss: 2.6227911784054103
Validation loss: 2.0609576815510904
Epoch: 5| Step: 2
Training loss: 2.927321147195148
Validation loss: 2.0582476828027967
Epoch: 5| Step: 3
Training loss: 2.2564105793034606
Validation loss: 2.041961313153516
Epoch: 5| Step: 4
Training loss: 2.2600308512379566
Validation loss: 2.0681898302847106
Epoch: 5| Step: 5
Training loss: 2.55170483539654
Validation loss: 2.046918607797108
Epoch: 5| Step: 6
Training loss: 2.505697719387477
Validation loss: 2.0596688726118666
Epoch: 5| Step: 7
Training loss: 2.4655514047370084
Validation loss: 2.0619605663084335
Epoch: 5| Step: 8
Training loss: 2.329490824225884
Validation loss: 2.0674155208929985
Epoch: 5| Step: 9
Training loss: 2.135260996533077
Validation loss: 2.0590451067991453
Epoch: 56| Step: 0
Training loss: 2.6747619915187206
Validation loss: 2.0639304678230874
Epoch: 5| Step: 1
Training loss: 2.32077648520117
Validation loss: 2.0513634913776313
Epoch: 5| Step: 2
Training loss: 2.469134337048037
Validation loss: 2.0599711725122
Epoch: 5| Step: 3
Training loss: 2.308116056588657
Validation loss: 2.061967993601193
Epoch: 5| Step: 4
Training loss: 2.340450049102208
Validation loss: 2.045102223710662
Epoch: 5| Step: 5
Training loss: 2.29521503280498
Validation loss: 2.070212271756586
Epoch: 5| Step: 6
Training loss: 2.797765408932055
Validation loss: 2.0499115673141515
Epoch: 5| Step: 7
Training loss: 2.411198172874999
Validation loss: 2.0615016336264844
Epoch: 5| Step: 8
Training loss: 2.709246809059651
Validation loss: 2.0638318173373125
Epoch: 5| Step: 9
Training loss: 2.2944811328769776
Validation loss: 2.0554044010171424
Epoch: 57| Step: 0
Training loss: 2.37411783800384
Validation loss: 2.0542444956959756
Epoch: 5| Step: 1
Training loss: 2.2029843116371337
Validation loss: 2.0630227267619587
Epoch: 5| Step: 2
Training loss: 2.490192152675145
Validation loss: 2.0435981015234463
Epoch: 5| Step: 3
Training loss: 2.6413264499762685
Validation loss: 2.0584952451068075
Epoch: 5| Step: 4
Training loss: 3.043874662067087
Validation loss: 2.0572428409905523
Epoch: 5| Step: 5
Training loss: 2.6996576198086073
Validation loss: 2.0628266355011426
Epoch: 5| Step: 6
Training loss: 1.8825729027724079
Validation loss: 2.057980070292488
Epoch: 5| Step: 7
Training loss: 2.298446014201812
Validation loss: 2.0746695094056635
Epoch: 5| Step: 8
Training loss: 2.3398444632654902
Validation loss: 2.067307453724504
Epoch: 5| Step: 9
Training loss: 2.5808407438289027
Validation loss: 2.066322148329752
Epoch: 58| Step: 0
Training loss: 2.2362066910602922
Validation loss: 2.066159498845389
Epoch: 5| Step: 1
Training loss: 2.7669386680210915
Validation loss: 2.0656597062330504
Epoch: 5| Step: 2
Training loss: 2.150443177789378
Validation loss: 2.064210347778635
Epoch: 5| Step: 3
Training loss: 2.3812338680812246
Validation loss: 2.079118080814716
Epoch: 5| Step: 4
Training loss: 2.3661505817016097
Validation loss: 2.067448214488891
Epoch: 5| Step: 5
Training loss: 2.699106128512707
Validation loss: 2.065805653259912
Epoch: 5| Step: 6
Training loss: 2.6266204736814283
Validation loss: 2.0704894901142787
Epoch: 5| Step: 7
Training loss: 1.9684525522448981
Validation loss: 2.0539122251966506
Epoch: 5| Step: 8
Training loss: 3.03638801471474
Validation loss: 2.066684342490454
Epoch: 5| Step: 9
Training loss: 2.24719720686905
Validation loss: 2.079511231130519
Epoch: 59| Step: 0
Training loss: 2.150416790684361
Validation loss: 2.0274105657157224
Epoch: 5| Step: 1
Training loss: 2.433136090249186
Validation loss: 2.0711586014226713
Epoch: 5| Step: 2
Training loss: 2.490215035157744
Validation loss: 2.04651096699362
Epoch: 5| Step: 3
Training loss: 2.4720483306801975
Validation loss: 2.038386137123267
Epoch: 5| Step: 4
Training loss: 2.4616756240519906
Validation loss: 2.060855903032461
Epoch: 5| Step: 5
Training loss: 2.3616098089200515
Validation loss: 2.0634541451945116
Epoch: 5| Step: 6
Training loss: 2.321832948614515
Validation loss: 2.0367060684129745
Epoch: 5| Step: 7
Training loss: 2.559620425575335
Validation loss: 2.048339430732627
Epoch: 5| Step: 8
Training loss: 2.571286837138232
Validation loss: 2.052108046288862
Epoch: 5| Step: 9
Training loss: 2.7576143447533865
Validation loss: 2.0396173862315496
Epoch: 60| Step: 0
Training loss: 2.128576074596978
Validation loss: 2.056892420855231
Epoch: 5| Step: 1
Training loss: 2.41186383808496
Validation loss: 2.0607647709984063
Epoch: 5| Step: 2
Training loss: 2.416049768920516
Validation loss: 2.052395430871359
Epoch: 5| Step: 3
Training loss: 2.7175094580463806
Validation loss: 2.051088737570688
Epoch: 5| Step: 4
Training loss: 2.469723087186167
Validation loss: 2.0583848070169353
Epoch: 5| Step: 5
Training loss: 2.5146097539500327
Validation loss: 2.0431431825041044
Epoch: 5| Step: 6
Training loss: 2.573014992342227
Validation loss: 2.0533682506399242
Epoch: 5| Step: 7
Training loss: 2.355972565120421
Validation loss: 2.062023857664688
Epoch: 5| Step: 8
Training loss: 2.5841443624295577
Validation loss: 2.0402025896338207
Epoch: 5| Step: 9
Training loss: 2.4753615298313782
Validation loss: 2.0553320268220254
Epoch: 61| Step: 0
Training loss: 2.5542589113920657
Validation loss: 2.0206778061073964
Epoch: 5| Step: 1
Training loss: 2.006641684827623
Validation loss: 2.053974410494186
Epoch: 5| Step: 2
Training loss: 2.4056721773821383
Validation loss: 2.0462878419376818
Epoch: 5| Step: 3
Training loss: 2.3281938171456673
Validation loss: 2.052036995867431
Epoch: 5| Step: 4
Training loss: 2.537961562699048
Validation loss: 2.05871975096765
Epoch: 5| Step: 5
Training loss: 2.571340245289109
Validation loss: 2.048969522221686
Epoch: 5| Step: 6
Training loss: 2.9673971205555794
Validation loss: 2.0522075588718254
Epoch: 5| Step: 7
Training loss: 2.4873856829728185
Validation loss: 2.0344063486922845
Epoch: 5| Step: 8
Training loss: 2.0613224251389832
Validation loss: 2.0609648193327503
Epoch: 5| Step: 9
Training loss: 2.5890270573751835
Validation loss: 2.041770635723591
Epoch: 62| Step: 0
Training loss: 2.579648579165811
Validation loss: 2.049223721771687
Epoch: 5| Step: 1
Training loss: 2.372597533332567
Validation loss: 2.0510726273970867
Epoch: 5| Step: 2
Training loss: 2.6268173466304416
Validation loss: 2.052023537985525
Epoch: 5| Step: 3
Training loss: 2.362318211580242
Validation loss: 2.0564464503668343
Epoch: 5| Step: 4
Training loss: 2.7467790293935037
Validation loss: 2.045336629523816
Epoch: 5| Step: 5
Training loss: 2.0370482804087655
Validation loss: 2.0419321695016497
Epoch: 5| Step: 6
Training loss: 2.5947632246833603
Validation loss: 2.0456394768967243
Epoch: 5| Step: 7
Training loss: 2.1181725044135025
Validation loss: 2.040691469282675
Epoch: 5| Step: 8
Training loss: 2.6348537602822915
Validation loss: 2.0676413828222544
Epoch: 5| Step: 9
Training loss: 2.4834543117608416
Validation loss: 2.0372350598511764
Epoch: 63| Step: 0
Training loss: 2.921434991518375
Validation loss: 2.0514546138582888
Epoch: 5| Step: 1
Training loss: 2.3465207824371954
Validation loss: 2.0408383365140192
Epoch: 5| Step: 2
Training loss: 2.3073735506038826
Validation loss: 2.0558779108843512
Epoch: 5| Step: 3
Training loss: 2.241281146776112
Validation loss: 2.049018125022727
Epoch: 5| Step: 4
Training loss: 2.9000493012545547
Validation loss: 2.0538329023981134
Epoch: 5| Step: 5
Training loss: 2.559373762901296
Validation loss: 2.0497819046720673
Epoch: 5| Step: 6
Training loss: 2.359932940871964
Validation loss: 2.0558475585215152
Epoch: 5| Step: 7
Training loss: 1.9809877216010592
Validation loss: 2.054899440861405
Epoch: 5| Step: 8
Training loss: 2.5555235634980455
Validation loss: 2.0419351001738697
Epoch: 5| Step: 9
Training loss: 2.29085296287559
Validation loss: 2.056848980768074
Epoch: 64| Step: 0
Training loss: 2.413235322040405
Validation loss: 2.0441040668047785
Epoch: 5| Step: 1
Training loss: 2.9779275482464276
Validation loss: 2.0528925777606726
Epoch: 5| Step: 2
Training loss: 2.0512645914789664
Validation loss: 2.0538956333558698
Epoch: 5| Step: 3
Training loss: 2.51265441647758
Validation loss: 2.0341231350121367
Epoch: 5| Step: 4
Training loss: 2.6052321937156786
Validation loss: 2.0546973221521996
Epoch: 5| Step: 5
Training loss: 2.303006868684293
Validation loss: 2.0456583819710783
Epoch: 5| Step: 6
Training loss: 2.3811329409845223
Validation loss: 2.055790431884956
Epoch: 5| Step: 7
Training loss: 2.0256811244478574
Validation loss: 2.0309257118574777
Epoch: 5| Step: 8
Training loss: 2.613367190466083
Validation loss: 2.0646444837191478
Epoch: 5| Step: 9
Training loss: 2.5372042854769647
Validation loss: 2.043667784284274
Epoch: 65| Step: 0
Training loss: 2.782900716849473
Validation loss: 2.049029568323598
Epoch: 5| Step: 1
Training loss: 1.9568787779964991
Validation loss: 2.0570496213035425
Epoch: 5| Step: 2
Training loss: 2.2795587828851676
Validation loss: 2.0547049677634526
Epoch: 5| Step: 3
Training loss: 2.9613378249123885
Validation loss: 2.0555791601416766
Epoch: 5| Step: 4
Training loss: 1.9883174031086588
Validation loss: 2.052959892247769
Epoch: 5| Step: 5
Training loss: 2.4210446810973716
Validation loss: 2.0497136062937744
Epoch: 5| Step: 6
Training loss: 2.4347197497884157
Validation loss: 2.06357104096385
Epoch: 5| Step: 7
Training loss: 2.564839853265773
Validation loss: 2.0593812360253283
Epoch: 5| Step: 8
Training loss: 2.658038984243883
Validation loss: 2.0549017653026813
Epoch: 5| Step: 9
Training loss: 2.2790847326564956
Validation loss: 2.0407511981681234
Epoch: 66| Step: 0
Training loss: 2.513056990341951
Validation loss: 2.0589382013238864
Epoch: 5| Step: 1
Training loss: 2.2057426539297347
Validation loss: 2.0583956222404227
Epoch: 5| Step: 2
Training loss: 2.726981406836358
Validation loss: 2.05467253712964
Epoch: 5| Step: 3
Training loss: 2.3828909438932118
Validation loss: 2.0393611598836476
Epoch: 5| Step: 4
Training loss: 2.8188440615910086
Validation loss: 2.041382447123327
Epoch: 5| Step: 5
Training loss: 2.435340609530817
Validation loss: 2.040097339012535
Epoch: 5| Step: 6
Training loss: 2.306764655852485
Validation loss: 2.067770895558592
Epoch: 5| Step: 7
Training loss: 2.219266804426849
Validation loss: 2.0379259217813543
Epoch: 5| Step: 8
Training loss: 2.3383154359632417
Validation loss: 2.044655259514722
Epoch: 5| Step: 9
Training loss: 2.581445947926834
Validation loss: 2.0542427640901284
Epoch: 67| Step: 0
Training loss: 2.602978203745626
Validation loss: 2.0407177680408837
Epoch: 5| Step: 1
Training loss: 2.6207793682548544
Validation loss: 2.059189637464667
Epoch: 5| Step: 2
Training loss: 2.304265801594819
Validation loss: 2.0498429402747265
Epoch: 5| Step: 3
Training loss: 2.264680863017109
Validation loss: 2.0516168936025263
Epoch: 5| Step: 4
Training loss: 2.4237757945348104
Validation loss: 2.0541308179368705
Epoch: 5| Step: 5
Training loss: 2.380419120108459
Validation loss: 2.043803064528713
Epoch: 5| Step: 6
Training loss: 2.352904282308684
Validation loss: 2.0479387252497623
Epoch: 5| Step: 7
Training loss: 2.8473102793735645
Validation loss: 2.02905570185928
Epoch: 5| Step: 8
Training loss: 2.26322157086192
Validation loss: 2.036576060775676
Epoch: 5| Step: 9
Training loss: 2.453286912762257
Validation loss: 2.0554163699130505
Epoch: 68| Step: 0
Training loss: 2.3187883810892305
Validation loss: 2.0395343156703465
Epoch: 5| Step: 1
Training loss: 2.604885785313592
Validation loss: 2.0405423554629256
Epoch: 5| Step: 2
Training loss: 2.0345708843566204
Validation loss: 2.027420685770579
Epoch: 5| Step: 3
Training loss: 2.4064287391762504
Validation loss: 2.058138792235096
Epoch: 5| Step: 4
Training loss: 2.5170738833908395
Validation loss: 2.051892599444958
Epoch: 5| Step: 5
Training loss: 2.0012862122766166
Validation loss: 2.0410444538596813
Epoch: 5| Step: 6
Training loss: 1.9986542107756156
Validation loss: 2.0421078920256845
Epoch: 5| Step: 7
Training loss: 2.7336232923212536
Validation loss: 2.0468569698345727
Epoch: 5| Step: 8
Training loss: 2.9591526096976595
Validation loss: 2.049201446400077
Epoch: 5| Step: 9
Training loss: 2.7777056451544766
Validation loss: 2.0521599531004555
Epoch: 69| Step: 0
Training loss: 2.4385326838881256
Validation loss: 2.0404239798041925
Epoch: 5| Step: 1
Training loss: 2.4937421679075005
Validation loss: 2.0413704944553346
Epoch: 5| Step: 2
Training loss: 2.345041351604458
Validation loss: 2.044336768802966
Epoch: 5| Step: 3
Training loss: 2.180894087034
Validation loss: 2.041918902720748
Epoch: 5| Step: 4
Training loss: 2.7125734345652166
Validation loss: 2.0328537364683736
Epoch: 5| Step: 5
Training loss: 2.2517602181171554
Validation loss: 2.0484314018173997
Epoch: 5| Step: 6
Training loss: 2.33552246489324
Validation loss: 2.0276221350963257
Epoch: 5| Step: 7
Training loss: 2.520922467466046
Validation loss: 2.020870749520054
Epoch: 5| Step: 8
Training loss: 2.146866435515577
Validation loss: 2.04294614743276
Epoch: 5| Step: 9
Training loss: 2.9542983211850222
Validation loss: 2.045157564640147
Epoch: 70| Step: 0
Training loss: 2.424981075881581
Validation loss: 2.0440982109054793
Epoch: 5| Step: 1
Training loss: 2.518606941950163
Validation loss: 2.0507126119946126
Epoch: 5| Step: 2
Training loss: 2.1753071622888513
Validation loss: 2.0431026559212153
Epoch: 5| Step: 3
Training loss: 2.4965285040498144
Validation loss: 2.047981614495866
Epoch: 5| Step: 4
Training loss: 2.7703961096731615
Validation loss: 2.0474296075091853
Epoch: 5| Step: 5
Training loss: 2.1182935014767046
Validation loss: 2.062218059014059
Epoch: 5| Step: 6
Training loss: 2.5491077021296853
Validation loss: 2.060339881820341
Epoch: 5| Step: 7
Training loss: 2.5959865624854417
Validation loss: 2.052535695737899
Epoch: 5| Step: 8
Training loss: 2.4630106594956227
Validation loss: 2.0446168681309875
Epoch: 5| Step: 9
Training loss: 2.3609041222990657
Validation loss: 2.069150107231053
Epoch: 71| Step: 0
Training loss: 2.8772779645191426
Validation loss: 2.0444751214379084
Epoch: 5| Step: 1
Training loss: 2.6678954710608203
Validation loss: 2.0464152701065434
Epoch: 5| Step: 2
Training loss: 2.1986211096811443
Validation loss: 2.054055536651108
Epoch: 5| Step: 3
Training loss: 2.2845745161314133
Validation loss: 2.0597835020560584
Epoch: 5| Step: 4
Training loss: 2.0743231163421023
Validation loss: 2.0365910252338093
Epoch: 5| Step: 5
Training loss: 2.8652154028640795
Validation loss: 2.0457569469577406
Epoch: 5| Step: 6
Training loss: 2.3235152518237885
Validation loss: 2.0387665470266723
Epoch: 5| Step: 7
Training loss: 2.678233917407387
Validation loss: 2.0468193526942238
Epoch: 5| Step: 8
Training loss: 2.0249487929286394
Validation loss: 2.033864873897635
Epoch: 5| Step: 9
Training loss: 2.366154108376587
Validation loss: 2.036477441052773
Epoch: 72| Step: 0
Training loss: 2.8844325364678025
Validation loss: 2.0322079268730913
Epoch: 5| Step: 1
Training loss: 2.3274511603814982
Validation loss: 2.046748290446483
Epoch: 5| Step: 2
Training loss: 2.147465600480954
Validation loss: 2.0396179588432894
Epoch: 5| Step: 3
Training loss: 2.416592750295852
Validation loss: 2.0389205811143802
Epoch: 5| Step: 4
Training loss: 2.2646502272322055
Validation loss: 2.051334354940825
Epoch: 5| Step: 5
Training loss: 2.50257264328129
Validation loss: 2.034377483694297
Epoch: 5| Step: 6
Training loss: 2.666523174557855
Validation loss: 2.0357937959994348
Epoch: 5| Step: 7
Training loss: 2.7052882364248494
Validation loss: 2.0503026161458098
Epoch: 5| Step: 8
Training loss: 2.4412730432410203
Validation loss: 2.068167791548961
Epoch: 5| Step: 9
Training loss: 2.0728929093371713
Validation loss: 2.029851051002313
Epoch: 73| Step: 0
Training loss: 2.0302692099523085
Validation loss: 2.0501574164976186
Epoch: 5| Step: 1
Training loss: 2.4314152011788694
Validation loss: 2.0426994192540193
Epoch: 5| Step: 2
Training loss: 2.5098818978416655
Validation loss: 2.0604161378223895
Epoch: 5| Step: 3
Training loss: 2.8044980976045917
Validation loss: 2.0338711864147982
Epoch: 5| Step: 4
Training loss: 2.2071492121407017
Validation loss: 2.0356829976448254
Epoch: 5| Step: 5
Training loss: 2.423847404360271
Validation loss: 2.052058918068681
Epoch: 5| Step: 6
Training loss: 2.4823919094867266
Validation loss: 2.059950247104768
Epoch: 5| Step: 7
Training loss: 2.4829754996164493
Validation loss: 2.049642370750337
Epoch: 5| Step: 8
Training loss: 2.645931532431708
Validation loss: 2.0482499017691316
Epoch: 5| Step: 9
Training loss: 2.386125806211321
Validation loss: 2.0543961664704473
Epoch: 74| Step: 0
Training loss: 2.3566285373169715
Validation loss: 2.0482146531033703
Epoch: 5| Step: 1
Training loss: 2.3702690789426835
Validation loss: 2.047324186385588
Epoch: 5| Step: 2
Training loss: 2.6064272008433114
Validation loss: 2.0489916925582996
Epoch: 5| Step: 3
Training loss: 2.23411473178889
Validation loss: 2.0263931060902785
Epoch: 5| Step: 4
Training loss: 2.008614465286933
Validation loss: 2.0522140326297675
Epoch: 5| Step: 5
Training loss: 2.5312212718699145
Validation loss: 2.050881312471717
Epoch: 5| Step: 6
Training loss: 2.4021250059202544
Validation loss: 2.040941399518937
Epoch: 5| Step: 7
Training loss: 2.278212628556498
Validation loss: 2.0523829392826825
Epoch: 5| Step: 8
Training loss: 2.5202448344503616
Validation loss: 2.043058240623604
Epoch: 5| Step: 9
Training loss: 3.062884559620477
Validation loss: 2.047578211897425
Epoch: 75| Step: 0
Training loss: 2.5322614932933485
Validation loss: 2.049762737041549
Epoch: 5| Step: 1
Training loss: 2.4212685102504574
Validation loss: 2.0573667168697365
Epoch: 5| Step: 2
Training loss: 2.3955991768782536
Validation loss: 2.044590500641862
Epoch: 5| Step: 3
Training loss: 2.1821445849494077
Validation loss: 2.0464853644278973
Epoch: 5| Step: 4
Training loss: 2.71826693748657
Validation loss: 2.0577753288817293
Epoch: 5| Step: 5
Training loss: 2.817113864166949
Validation loss: 2.0314549188213027
Epoch: 5| Step: 6
Training loss: 2.468984085767157
Validation loss: 2.0288824042102855
Epoch: 5| Step: 7
Training loss: 2.269146097038397
Validation loss: 2.0481027895857893
Epoch: 5| Step: 8
Training loss: 2.3294147784677683
Validation loss: 2.0504398186374724
Epoch: 5| Step: 9
Training loss: 2.261715271309663
Validation loss: 2.0394602690780697
Epoch: 76| Step: 0
Training loss: 2.636910981129227
Validation loss: 2.033123648573323
Epoch: 5| Step: 1
Training loss: 2.1636521814582634
Validation loss: 2.0293453898350777
Epoch: 5| Step: 2
Training loss: 2.753372292123683
Validation loss: 2.0193500664921684
Epoch: 5| Step: 3
Training loss: 2.5118286678296275
Validation loss: 2.04084109926973
Epoch: 5| Step: 4
Training loss: 2.4065991433235214
Validation loss: 2.027621296711592
Epoch: 5| Step: 5
Training loss: 2.491586451265221
Validation loss: 2.0271057036753
Epoch: 5| Step: 6
Training loss: 2.367637062818216
Validation loss: 2.042689315101895
Epoch: 5| Step: 7
Training loss: 2.5249130611749186
Validation loss: 2.0462160227642046
Epoch: 5| Step: 8
Training loss: 2.488077343980469
Validation loss: 2.0188194502609806
Epoch: 5| Step: 9
Training loss: 2.000925088558283
Validation loss: 2.0402926532214436
Epoch: 77| Step: 0
Training loss: 2.585771538056192
Validation loss: 2.029069141924501
Epoch: 5| Step: 1
Training loss: 2.160459969606805
Validation loss: 2.023917471379016
Epoch: 5| Step: 2
Training loss: 2.4527036462940623
Validation loss: 2.033115636400326
Epoch: 5| Step: 3
Training loss: 2.2681627464569827
Validation loss: 2.0434536207591787
Epoch: 5| Step: 4
Training loss: 2.521000207679313
Validation loss: 2.040958043794604
Epoch: 5| Step: 5
Training loss: 2.3749405702885165
Validation loss: 2.0160524675666105
Epoch: 5| Step: 6
Training loss: 2.4704139027542795
Validation loss: 2.0438223621727327
Epoch: 5| Step: 7
Training loss: 2.5584212616297632
Validation loss: 2.0335089998798743
Epoch: 5| Step: 8
Training loss: 1.9921067763784757
Validation loss: 2.050639828690528
Epoch: 5| Step: 9
Training loss: 2.9899431780771155
Validation loss: 2.0518607654429224
Epoch: 78| Step: 0
Training loss: 2.9747882671502857
Validation loss: 2.0444362742566256
Epoch: 5| Step: 1
Training loss: 2.406535144110991
Validation loss: 2.033168615870546
Epoch: 5| Step: 2
Training loss: 2.658315864991899
Validation loss: 2.0143459830354544
Epoch: 5| Step: 3
Training loss: 2.2123081016295276
Validation loss: 2.0225550866628086
Epoch: 5| Step: 4
Training loss: 2.457742609290181
Validation loss: 2.0289822675120264
Epoch: 5| Step: 5
Training loss: 2.612916108353736
Validation loss: 2.030578568832683
Epoch: 5| Step: 6
Training loss: 2.414823541769568
Validation loss: 2.0419993362078395
Epoch: 5| Step: 7
Training loss: 2.3560306517804275
Validation loss: 2.014917549942863
Epoch: 5| Step: 8
Training loss: 2.153907277214572
Validation loss: 2.030219487104766
Epoch: 5| Step: 9
Training loss: 2.0289817469919402
Validation loss: 2.03040402740425
Epoch: 79| Step: 0
Training loss: 2.0472382667196887
Validation loss: 2.0193116965248943
Epoch: 5| Step: 1
Training loss: 2.331211987714768
Validation loss: 2.023883193420823
Epoch: 5| Step: 2
Training loss: 2.3220960139648166
Validation loss: 2.015412079805474
Epoch: 5| Step: 3
Training loss: 2.7620621485254264
Validation loss: 2.0249358630767307
Epoch: 5| Step: 4
Training loss: 2.4483239883372616
Validation loss: 2.0348460662416095
Epoch: 5| Step: 5
Training loss: 2.6084318912236033
Validation loss: 2.033842745694471
Epoch: 5| Step: 6
Training loss: 2.889767741337866
Validation loss: 2.0325169508292986
Epoch: 5| Step: 7
Training loss: 2.5534434424613512
Validation loss: 2.0309569013789948
Epoch: 5| Step: 8
Training loss: 2.2309779239042777
Validation loss: 2.0479358404838695
Epoch: 5| Step: 9
Training loss: 2.0831350867996914
Validation loss: 2.03462590824583
Epoch: 80| Step: 0
Training loss: 2.2742094322126407
Validation loss: 2.022841905576879
Epoch: 5| Step: 1
Training loss: 2.5882713642386386
Validation loss: 2.048637176196
Epoch: 5| Step: 2
Training loss: 2.8485007374785805
Validation loss: 2.043301969681649
Epoch: 5| Step: 3
Training loss: 2.6488889236347073
Validation loss: 2.0264598069985573
Epoch: 5| Step: 4
Training loss: 2.4480990294578007
Validation loss: 2.042266544583133
Epoch: 5| Step: 5
Training loss: 2.5025894106384583
Validation loss: 2.049138354313048
Epoch: 5| Step: 6
Training loss: 2.2093580016004286
Validation loss: 2.033918000900693
Epoch: 5| Step: 7
Training loss: 2.3176531724402096
Validation loss: 2.044413750459987
Epoch: 5| Step: 8
Training loss: 2.4517322644401003
Validation loss: 2.031756421693395
Epoch: 5| Step: 9
Training loss: 1.9886661898865716
Validation loss: 2.0399102726636746
Epoch: 81| Step: 0
Training loss: 2.6675935763504954
Validation loss: 2.0213917784167874
Epoch: 5| Step: 1
Training loss: 2.4110861395594076
Validation loss: 2.051888319032194
Epoch: 5| Step: 2
Training loss: 2.416871840438178
Validation loss: 2.048264697016498
Epoch: 5| Step: 3
Training loss: 2.2233328970928232
Validation loss: 2.0325906521411747
Epoch: 5| Step: 4
Training loss: 2.4316638623701436
Validation loss: 2.025687650127962
Epoch: 5| Step: 5
Training loss: 2.295448119517619
Validation loss: 2.048145055619369
Epoch: 5| Step: 6
Training loss: 2.3140972910138915
Validation loss: 2.0159694811740914
Epoch: 5| Step: 7
Training loss: 2.6372896155747583
Validation loss: 2.037754478024128
Epoch: 5| Step: 8
Training loss: 2.566166743188216
Validation loss: 2.0272407106725456
Epoch: 5| Step: 9
Training loss: 2.4403190938826547
Validation loss: 2.031606057724454
Epoch: 82| Step: 0
Training loss: 1.9604523199111523
Validation loss: 2.0233129350967185
Epoch: 5| Step: 1
Training loss: 2.2977719793711797
Validation loss: 2.046530032092961
Epoch: 5| Step: 2
Training loss: 2.3980097187281166
Validation loss: 2.0183737940050483
Epoch: 5| Step: 3
Training loss: 2.7044988239135557
Validation loss: 2.034692879841055
Epoch: 5| Step: 4
Training loss: 2.104366204900804
Validation loss: 2.0484400535291125
Epoch: 5| Step: 5
Training loss: 2.2367905584247936
Validation loss: 2.0438414584202795
Epoch: 5| Step: 6
Training loss: 2.7775186089305186
Validation loss: 2.0429710591434174
Epoch: 5| Step: 7
Training loss: 2.6329488747251633
Validation loss: 2.051699057482661
Epoch: 5| Step: 8
Training loss: 2.166382025092481
Validation loss: 2.048363546662117
Epoch: 5| Step: 9
Training loss: 2.989372821976947
Validation loss: 2.0454602996282
Epoch: 83| Step: 0
Training loss: 2.716287659806647
Validation loss: 2.048683735442249
Epoch: 5| Step: 1
Training loss: 2.7045459871167736
Validation loss: 2.045929037653564
Epoch: 5| Step: 2
Training loss: 2.3436984247255004
Validation loss: 2.0373762836916813
Epoch: 5| Step: 3
Training loss: 2.3347529339010626
Validation loss: 2.056389803953711
Epoch: 5| Step: 4
Training loss: 2.175462682335109
Validation loss: 2.0164494934644788
Epoch: 5| Step: 5
Training loss: 2.3726194397071496
Validation loss: 2.05290219933568
Epoch: 5| Step: 6
Training loss: 2.270600216533671
Validation loss: 2.038696167830019
Epoch: 5| Step: 7
Training loss: 2.407896395143207
Validation loss: 2.040933118931479
Epoch: 5| Step: 8
Training loss: 2.66520026737391
Validation loss: 2.037763149603566
Epoch: 5| Step: 9
Training loss: 2.269267134145039
Validation loss: 2.0100758001477628
Epoch: 84| Step: 0
Training loss: 2.2761864052382883
Validation loss: 2.046066109592964
Epoch: 5| Step: 1
Training loss: 2.800437661434558
Validation loss: 2.0399570463347105
Epoch: 5| Step: 2
Training loss: 2.5969835830187202
Validation loss: 2.0200037578258354
Epoch: 5| Step: 3
Training loss: 2.3896719834352846
Validation loss: 2.031454224208743
Epoch: 5| Step: 4
Training loss: 2.2664231571591236
Validation loss: 2.023569347174676
Epoch: 5| Step: 5
Training loss: 2.6223432629697383
Validation loss: 2.0300870953753427
Epoch: 5| Step: 6
Training loss: 2.6426486776312568
Validation loss: 2.0305569033210316
Epoch: 5| Step: 7
Training loss: 2.5358455056023606
Validation loss: 2.0134475910006198
Epoch: 5| Step: 8
Training loss: 2.1238900820205764
Validation loss: 2.0193308711927926
Epoch: 5| Step: 9
Training loss: 2.085799994919199
Validation loss: 2.0220730170298236
Epoch: 85| Step: 0
Training loss: 2.0624028963292087
Validation loss: 2.0346537949386487
Epoch: 5| Step: 1
Training loss: 2.5512850907868834
Validation loss: 2.02132900680622
Epoch: 5| Step: 2
Training loss: 2.628573936555981
Validation loss: 2.0031872562115507
Epoch: 5| Step: 3
Training loss: 2.074485517398411
Validation loss: 2.026825157729922
Epoch: 5| Step: 4
Training loss: 2.1946007059960917
Validation loss: 2.024631495684807
Epoch: 5| Step: 5
Training loss: 2.5519007611007987
Validation loss: 2.022712679207311
Epoch: 5| Step: 6
Training loss: 2.5779264431411417
Validation loss: 2.030770232481114
Epoch: 5| Step: 7
Training loss: 2.2047783890339128
Validation loss: 2.015527410023322
Epoch: 5| Step: 8
Training loss: 2.5870046574536287
Validation loss: 2.0259400536176853
Epoch: 5| Step: 9
Training loss: 2.781652185742547
Validation loss: 2.0245075848789584
Epoch: 86| Step: 0
Training loss: 2.591321704717044
Validation loss: 2.019741726373718
Epoch: 5| Step: 1
Training loss: 2.438695369951293
Validation loss: 2.0298469247351996
Epoch: 5| Step: 2
Training loss: 2.1147631739417894
Validation loss: 2.04042310569522
Epoch: 5| Step: 3
Training loss: 2.2940259637535685
Validation loss: 2.030774240723776
Epoch: 5| Step: 4
Training loss: 2.918490974646281
Validation loss: 2.0278163232355393
Epoch: 5| Step: 5
Training loss: 2.1456204898296796
Validation loss: 2.0347295866601103
Epoch: 5| Step: 6
Training loss: 2.1663952315085035
Validation loss: 2.03134901622857
Epoch: 5| Step: 7
Training loss: 1.933843423156183
Validation loss: 2.0331380070387706
Epoch: 5| Step: 8
Training loss: 2.6679927886282075
Validation loss: 2.032888232130148
Epoch: 5| Step: 9
Training loss: 2.857213939055015
Validation loss: 2.017828321631818
Epoch: 87| Step: 0
Training loss: 2.9780790215352413
Validation loss: 2.0373733039148916
Epoch: 5| Step: 1
Training loss: 2.4313130230813216
Validation loss: 2.030601158841873
Epoch: 5| Step: 2
Training loss: 2.5738017507114512
Validation loss: 2.0359884400699277
Epoch: 5| Step: 3
Training loss: 2.3079154475242682
Validation loss: 2.0342342440603876
Epoch: 5| Step: 4
Training loss: 2.1001543624094077
Validation loss: 2.0306789453249348
Epoch: 5| Step: 5
Training loss: 2.0579870151447492
Validation loss: 2.0311124697816028
Epoch: 5| Step: 6
Training loss: 2.646769941062246
Validation loss: 2.018016844920636
Epoch: 5| Step: 7
Training loss: 2.446422970698751
Validation loss: 2.0251857502636064
Epoch: 5| Step: 8
Training loss: 2.3321230565183795
Validation loss: 2.0224267997325067
Epoch: 5| Step: 9
Training loss: 2.360993291371116
Validation loss: 2.0255532182609852
Epoch: 88| Step: 0
Training loss: 1.4584432106404863
Validation loss: 2.0292913543956637
Epoch: 5| Step: 1
Training loss: 2.7417276110924136
Validation loss: 2.010188099651479
Epoch: 5| Step: 2
Training loss: 2.908431352277066
Validation loss: 2.0315169576010264
Epoch: 5| Step: 3
Training loss: 2.948805783897519
Validation loss: 2.033957349924394
Epoch: 5| Step: 4
Training loss: 2.1364954634747058
Validation loss: 2.0074641001413616
Epoch: 5| Step: 5
Training loss: 2.1871577403843654
Validation loss: 2.0271351936092485
Epoch: 5| Step: 6
Training loss: 2.5684677971411616
Validation loss: 2.0355054311476763
Epoch: 5| Step: 7
Training loss: 2.3175844538010884
Validation loss: 2.043318043632048
Epoch: 5| Step: 8
Training loss: 2.463461994928634
Validation loss: 2.0241513750764253
Epoch: 5| Step: 9
Training loss: 2.178187137631422
Validation loss: 2.0354762898382
Epoch: 89| Step: 0
Training loss: 2.270458668822997
Validation loss: 2.0378250240342974
Epoch: 5| Step: 1
Training loss: 2.4211161747522008
Validation loss: 2.041510764450405
Epoch: 5| Step: 2
Training loss: 2.1677184364221502
Validation loss: 2.0188669326491624
Epoch: 5| Step: 3
Training loss: 2.4417833693110538
Validation loss: 2.0373849576866996
Epoch: 5| Step: 4
Training loss: 2.15356410715991
Validation loss: 2.047053493350155
Epoch: 5| Step: 5
Training loss: 2.744246533070825
Validation loss: 2.0331534623103567
Epoch: 5| Step: 6
Training loss: 2.2207647497908405
Validation loss: 2.0319642068792203
Epoch: 5| Step: 7
Training loss: 2.3097524042910784
Validation loss: 2.0293101925770003
Epoch: 5| Step: 8
Training loss: 2.94834213870818
Validation loss: 2.037167583002793
Epoch: 5| Step: 9
Training loss: 2.5564265966622854
Validation loss: 2.0370074974357357
Epoch: 90| Step: 0
Training loss: 2.2413547577765374
Validation loss: 2.053554553484713
Epoch: 5| Step: 1
Training loss: 2.6215790755506947
Validation loss: 2.029226771253887
Epoch: 5| Step: 2
Training loss: 2.4586762226867878
Validation loss: 2.0372848803614905
Epoch: 5| Step: 3
Training loss: 2.3692391446629593
Validation loss: 2.042799516529558
Epoch: 5| Step: 4
Training loss: 2.883810723388426
Validation loss: 2.0424368216701043
Epoch: 5| Step: 5
Training loss: 2.5375329677901863
Validation loss: 2.024680308545034
Epoch: 5| Step: 6
Training loss: 2.6440705161451623
Validation loss: 2.0087250816354354
Epoch: 5| Step: 7
Training loss: 1.9044565613135034
Validation loss: 2.0164000313066124
Epoch: 5| Step: 8
Training loss: 2.149328539480128
Validation loss: 2.0393322547312547
Epoch: 5| Step: 9
Training loss: 2.3534637572085404
Validation loss: 2.023469802122992
Epoch: 91| Step: 0
Training loss: 2.341799420251171
Validation loss: 2.0438338387920907
Epoch: 5| Step: 1
Training loss: 2.546767343691423
Validation loss: 2.0382195481824703
Epoch: 5| Step: 2
Training loss: 2.2480534504546537
Validation loss: 2.0265611642330748
Epoch: 5| Step: 3
Training loss: 2.2428902511652176
Validation loss: 2.016782974274562
Epoch: 5| Step: 4
Training loss: 2.201507082499544
Validation loss: 2.0370620604242142
Epoch: 5| Step: 5
Training loss: 2.4699878727850715
Validation loss: 2.032962998457913
Epoch: 5| Step: 6
Training loss: 2.637444199970681
Validation loss: 2.033766557552209
Epoch: 5| Step: 7
Training loss: 2.8297246129062974
Validation loss: 2.013692341979672
Epoch: 5| Step: 8
Training loss: 2.746414013958142
Validation loss: 2.031663730646847
Epoch: 5| Step: 9
Training loss: 1.8974789683868913
Validation loss: 2.029458524061235
Epoch: 92| Step: 0
Training loss: 2.430360755985794
Validation loss: 2.01676775198809
Epoch: 5| Step: 1
Training loss: 2.857756443214311
Validation loss: 2.024301166768624
Epoch: 5| Step: 2
Training loss: 2.630305605055954
Validation loss: 2.023336407603917
Epoch: 5| Step: 3
Training loss: 2.6361005496354055
Validation loss: 2.02869067382692
Epoch: 5| Step: 4
Training loss: 2.472093370439642
Validation loss: 2.032138240431371
Epoch: 5| Step: 5
Training loss: 2.213217917309435
Validation loss: 2.0246541062645136
Epoch: 5| Step: 6
Training loss: 2.208091926575358
Validation loss: 2.0225226826594516
Epoch: 5| Step: 7
Training loss: 2.022703059580503
Validation loss: 1.9877341805582205
Epoch: 5| Step: 8
Training loss: 2.1650025016646874
Validation loss: 2.0341875583363556
Epoch: 5| Step: 9
Training loss: 2.5071301824414673
Validation loss: 2.014379062899132
Epoch: 93| Step: 0
Training loss: 2.4971434485892137
Validation loss: 2.0291809181800495
Epoch: 5| Step: 1
Training loss: 2.45169735325484
Validation loss: 2.0213525737774343
Epoch: 5| Step: 2
Training loss: 2.833237216291516
Validation loss: 2.020168059961357
Epoch: 5| Step: 3
Training loss: 2.524632032417573
Validation loss: 2.0283901823018757
Epoch: 5| Step: 4
Training loss: 2.5073220792499393
Validation loss: 2.0057371688169376
Epoch: 5| Step: 5
Training loss: 2.0939872948844975
Validation loss: 2.033584233413512
Epoch: 5| Step: 6
Training loss: 2.1075069491632723
Validation loss: 2.0325286984323188
Epoch: 5| Step: 7
Training loss: 2.7165348192606276
Validation loss: 2.0316165178616106
Epoch: 5| Step: 8
Training loss: 2.060809049153452
Validation loss: 2.0404839707677347
Epoch: 5| Step: 9
Training loss: 2.37596211270267
Validation loss: 2.012065536326832
Epoch: 94| Step: 0
Training loss: 2.27787782351144
Validation loss: 2.0281937490322455
Epoch: 5| Step: 1
Training loss: 2.332555561773607
Validation loss: 2.0411051670233147
Epoch: 5| Step: 2
Training loss: 2.534645628679121
Validation loss: 2.019478854334244
Epoch: 5| Step: 3
Training loss: 2.2224419193810157
Validation loss: 2.03497519639998
Epoch: 5| Step: 4
Training loss: 2.3862911659234824
Validation loss: 2.0314961383524626
Epoch: 5| Step: 5
Training loss: 2.1059139538292198
Validation loss: 2.0449508950569575
Epoch: 5| Step: 6
Training loss: 2.3393547043772234
Validation loss: 2.024892682961594
Epoch: 5| Step: 7
Training loss: 2.6082397549776366
Validation loss: 2.0280592004798943
Epoch: 5| Step: 8
Training loss: 2.7839548909325584
Validation loss: 2.0143892139244417
Epoch: 5| Step: 9
Training loss: 2.60296373176881
Validation loss: 2.0394741665248253
Epoch: 95| Step: 0
Training loss: 2.55611769280179
Validation loss: 2.0363459465764917
Epoch: 5| Step: 1
Training loss: 2.3717339796681456
Validation loss: 2.040203002363766
Epoch: 5| Step: 2
Training loss: 2.2692697607467904
Validation loss: 2.048662248033009
Epoch: 5| Step: 3
Training loss: 2.5053171833418517
Validation loss: 2.0242180264807996
Epoch: 5| Step: 4
Training loss: 2.703231897610847
Validation loss: 2.0190487502690875
Epoch: 5| Step: 5
Training loss: 2.212707673579649
Validation loss: 2.029287410222588
Epoch: 5| Step: 6
Training loss: 2.129957139206317
Validation loss: 2.0227923958334113
Epoch: 5| Step: 7
Training loss: 2.579856522289204
Validation loss: 2.0160944009358546
Epoch: 5| Step: 8
Training loss: 2.658953917323172
Validation loss: 2.0145523864054096
Epoch: 5| Step: 9
Training loss: 2.2083688649132114
Validation loss: 2.0094435641678343
Epoch: 96| Step: 0
Training loss: 2.8718971425926516
Validation loss: 2.0239283498199336
Epoch: 5| Step: 1
Training loss: 2.684385135795811
Validation loss: 2.0215413098545554
Epoch: 5| Step: 2
Training loss: 1.901456716160696
Validation loss: 2.016886007280945
Epoch: 5| Step: 3
Training loss: 2.335678035143135
Validation loss: 2.0280174700896785
Epoch: 5| Step: 4
Training loss: 2.8034090406406103
Validation loss: 2.0104491298823737
Epoch: 5| Step: 5
Training loss: 2.249487712608639
Validation loss: 2.026229596869804
Epoch: 5| Step: 6
Training loss: 2.028584771141215
Validation loss: 2.023289496712341
Epoch: 5| Step: 7
Training loss: 1.83116848604709
Validation loss: 2.0210716763231726
Epoch: 5| Step: 8
Training loss: 2.7581994322884573
Validation loss: 2.026903359521756
Epoch: 5| Step: 9
Training loss: 2.466164212559522
Validation loss: 2.0271749722886105
Epoch: 97| Step: 0
Training loss: 2.410433118055731
Validation loss: 2.0123694723322316
Epoch: 5| Step: 1
Training loss: 2.4304298174592933
Validation loss: 2.028320694419554
Epoch: 5| Step: 2
Training loss: 2.2748936974139453
Validation loss: 2.030353213732711
Epoch: 5| Step: 3
Training loss: 2.2545171534532273
Validation loss: 2.0364003817755947
Epoch: 5| Step: 4
Training loss: 2.437549883992261
Validation loss: 2.02877496681478
Epoch: 5| Step: 5
Training loss: 2.71513687856582
Validation loss: 2.015879051680953
Epoch: 5| Step: 6
Training loss: 2.3929699137127844
Validation loss: 2.025437704315363
Epoch: 5| Step: 7
Training loss: 2.502058897976399
Validation loss: 2.017187269718023
Epoch: 5| Step: 8
Training loss: 2.51299304584432
Validation loss: 2.0259666477034615
Epoch: 5| Step: 9
Training loss: 2.3128464928932746
Validation loss: 2.032843392691064
Epoch: 98| Step: 0
Training loss: 2.395646947714897
Validation loss: 2.0208433457836414
Epoch: 5| Step: 1
Training loss: 2.117970789757467
Validation loss: 2.0203579568189274
Epoch: 5| Step: 2
Training loss: 2.238386700927296
Validation loss: 2.0280147342217365
Epoch: 5| Step: 3
Training loss: 2.3071278211803006
Validation loss: 2.0274506342789422
Epoch: 5| Step: 4
Training loss: 2.2688469437833803
Validation loss: 2.0237871872511057
Epoch: 5| Step: 5
Training loss: 1.982034820204584
Validation loss: 2.029952529178158
Epoch: 5| Step: 6
Training loss: 2.353403986265597
Validation loss: 2.030498286124986
Epoch: 5| Step: 7
Training loss: 2.9008829745726605
Validation loss: 2.0110094765744795
Epoch: 5| Step: 8
Training loss: 2.657478138357335
Validation loss: 2.0413625962657758
Epoch: 5| Step: 9
Training loss: 2.799291664172556
Validation loss: 2.036739042890239
Epoch: 99| Step: 0
Training loss: 2.5378995608994024
Validation loss: 2.0243572152166265
Epoch: 5| Step: 1
Training loss: 2.472355491341734
Validation loss: 2.0389340822965423
Epoch: 5| Step: 2
Training loss: 2.3392206804892965
Validation loss: 2.025478632051668
Epoch: 5| Step: 3
Training loss: 2.4550582168730917
Validation loss: 2.0359433952223047
Epoch: 5| Step: 4
Training loss: 2.3350165857873684
Validation loss: 2.020150415202137
Epoch: 5| Step: 5
Training loss: 2.6142997638583947
Validation loss: 2.0411319729188837
Epoch: 5| Step: 6
Training loss: 2.229877667514265
Validation loss: 2.0351616749693098
Epoch: 5| Step: 7
Training loss: 2.2007251411411164
Validation loss: 2.0338524224840677
Epoch: 5| Step: 8
Training loss: 2.132481923177649
Validation loss: 2.0146105612289307
Epoch: 5| Step: 9
Training loss: 2.788330836989461
Validation loss: 2.0199601597679764
Epoch: 100| Step: 0
Training loss: 1.8924626648821958
Validation loss: 2.039986671314967
Epoch: 5| Step: 1
Training loss: 2.37316713381625
Validation loss: 2.024351977185437
Epoch: 5| Step: 2
Training loss: 2.39597872970132
Validation loss: 2.0212827669901063
Epoch: 5| Step: 3
Training loss: 2.239534090668821
Validation loss: 2.029480978390519
Epoch: 5| Step: 4
Training loss: 3.139638109916918
Validation loss: 2.03874068095497
Epoch: 5| Step: 5
Training loss: 2.4567055782029787
Validation loss: 2.0285217089912604
Epoch: 5| Step: 6
Training loss: 2.7208407901897353
Validation loss: 2.016196688812581
Epoch: 5| Step: 7
Training loss: 2.312897519148229
Validation loss: 2.03848897633662
Epoch: 5| Step: 8
Training loss: 2.3468007895042295
Validation loss: 2.003915631601525
Epoch: 5| Step: 9
Training loss: 2.116299263414005
Validation loss: 2.0095075111290743
