Epoch: 1| Step: 0
Training loss: 8.243223239129048
Validation loss: 8.683019566739828

Epoch: 5| Step: 1
Training loss: 9.040038165796785
Validation loss: 8.651872797449055

Epoch: 5| Step: 2
Training loss: 8.176472233252698
Validation loss: 8.619902223798096

Epoch: 5| Step: 3
Training loss: 8.544077413629728
Validation loss: 8.591089916635072

Epoch: 5| Step: 4
Training loss: 8.780645274996166
Validation loss: 8.56432917007529

Epoch: 5| Step: 5
Training loss: 8.836349356283344
Validation loss: 8.536453076388726

Epoch: 5| Step: 6
Training loss: 8.42144513846732
Validation loss: 8.51069077260837

Epoch: 5| Step: 7
Training loss: 9.588248498935755
Validation loss: 8.488645365255564

Epoch: 5| Step: 8
Training loss: 8.633571622449248
Validation loss: 8.460982783118016

Epoch: 5| Step: 9
Training loss: 7.929306968240165
Validation loss: 8.436517502837507

Epoch: 5| Step: 10
Training loss: 8.91047134745346
Validation loss: 8.409586994509485

Epoch: 5| Step: 11
Training loss: 7.54633413078672
Validation loss: 8.382324375186585

Epoch: 2| Step: 0
Training loss: 7.945889342306848
Validation loss: 8.356041873003404

Epoch: 5| Step: 1
Training loss: 7.9133167875781645
Validation loss: 8.32767345547483

Epoch: 5| Step: 2
Training loss: 8.673195898133649
Validation loss: 8.299099017652544

Epoch: 5| Step: 3
Training loss: 9.037378469153904
Validation loss: 8.26703344795287

Epoch: 5| Step: 4
Training loss: 8.24168300440615
Validation loss: 8.240228617237337

Epoch: 5| Step: 5
Training loss: 8.83418452162447
Validation loss: 8.205258850611102

Epoch: 5| Step: 6
Training loss: 8.162259164619202
Validation loss: 8.172513072556816

Epoch: 5| Step: 7
Training loss: 8.309001444510816
Validation loss: 8.14202048848366

Epoch: 5| Step: 8
Training loss: 8.53565099753148
Validation loss: 8.105329539624067

Epoch: 5| Step: 9
Training loss: 7.44906204770943
Validation loss: 8.06754676323778

Epoch: 5| Step: 10
Training loss: 8.230782523237036
Validation loss: 8.031793093594315

Epoch: 5| Step: 11
Training loss: 7.087344062610224
Validation loss: 7.9963424089856705

Epoch: 3| Step: 0
Training loss: 8.32185055839797
Validation loss: 7.955042340005905

Epoch: 5| Step: 1
Training loss: 7.332997343284743
Validation loss: 7.912283654491933

Epoch: 5| Step: 2
Training loss: 8.362503977776052
Validation loss: 7.87170580431871

Epoch: 5| Step: 3
Training loss: 8.145282489334221
Validation loss: 7.8266343799696285

Epoch: 5| Step: 4
Training loss: 7.942377949498234
Validation loss: 7.784842911517404

Epoch: 5| Step: 5
Training loss: 7.3652418850233525
Validation loss: 7.736781763729702

Epoch: 5| Step: 6
Training loss: 7.935835536144778
Validation loss: 7.687007485096378

Epoch: 5| Step: 7
Training loss: 7.2642844655469485
Validation loss: 7.639726311606433

Epoch: 5| Step: 8
Training loss: 8.109247989431669
Validation loss: 7.587311378996044

Epoch: 5| Step: 9
Training loss: 8.079221905550131
Validation loss: 7.534453358421396

Epoch: 5| Step: 10
Training loss: 6.859352754804476
Validation loss: 7.482085353579625

Epoch: 5| Step: 11
Training loss: 8.202438587352963
Validation loss: 7.4236304097826284

Epoch: 4| Step: 0
Training loss: 7.030144769906225
Validation loss: 7.364478316001196

Epoch: 5| Step: 1
Training loss: 7.426524807838155
Validation loss: 7.298042176786599

Epoch: 5| Step: 2
Training loss: 7.952000626562082
Validation loss: 7.23715095183442

Epoch: 5| Step: 3
Training loss: 6.569848587404871
Validation loss: 7.164680379432331

Epoch: 5| Step: 4
Training loss: 6.6948780466358135
Validation loss: 7.1020552852752274

Epoch: 5| Step: 5
Training loss: 7.373648050822101
Validation loss: 7.033149869463484

Epoch: 5| Step: 6
Training loss: 7.276988865977906
Validation loss: 6.968572240823201

Epoch: 5| Step: 7
Training loss: 6.732552195395198
Validation loss: 6.884480465153146

Epoch: 5| Step: 8
Training loss: 7.622424581873386
Validation loss: 6.80278582448065

Epoch: 5| Step: 9
Training loss: 7.128258211127857
Validation loss: 6.726547270730649

Epoch: 5| Step: 10
Training loss: 6.281365996091572
Validation loss: 6.64941134942744

Epoch: 5| Step: 11
Training loss: 5.932490755468626
Validation loss: 6.555506682707656

Epoch: 5| Step: 0
Training loss: 6.501308016115692
Validation loss: 6.47087871153232

Epoch: 5| Step: 1
Training loss: 6.358520750364231
Validation loss: 6.371289750543292

Epoch: 5| Step: 2
Training loss: 6.6187132750618884
Validation loss: 6.2780686478010646

Epoch: 5| Step: 3
Training loss: 6.060722483759381
Validation loss: 6.1959814646119185

Epoch: 5| Step: 4
Training loss: 5.612651410003986
Validation loss: 6.087431541856913

Epoch: 5| Step: 5
Training loss: 5.873445995230289
Validation loss: 5.993112883054805

Epoch: 5| Step: 6
Training loss: 5.584733056883775
Validation loss: 5.887411089075296

Epoch: 5| Step: 7
Training loss: 6.3327192042227205
Validation loss: 5.765847288841579

Epoch: 5| Step: 8
Training loss: 5.875018829964837
Validation loss: 5.669977730758325

Epoch: 5| Step: 9
Training loss: 6.077791101850604
Validation loss: 5.535787621318515

Epoch: 5| Step: 10
Training loss: 5.394263059895261
Validation loss: 5.409133480269745

Epoch: 5| Step: 11
Training loss: 4.734362913815018
Validation loss: 5.292950259243244

Epoch: 6| Step: 0
Training loss: 5.316736843080475
Validation loss: 5.143369280359254

Epoch: 5| Step: 1
Training loss: 5.156451597029664
Validation loss: 5.010680672186124

Epoch: 5| Step: 2
Training loss: 4.017537296219373
Validation loss: 4.86575052878944

Epoch: 5| Step: 3
Training loss: 4.558982852127884
Validation loss: 4.726333335176068

Epoch: 5| Step: 4
Training loss: 4.0531845100169335
Validation loss: 4.58559360546956

Epoch: 5| Step: 5
Training loss: 4.446968400393864
Validation loss: 4.459837145918358

Epoch: 5| Step: 6
Training loss: 4.9279995067150315
Validation loss: 4.284478606036315

Epoch: 5| Step: 7
Training loss: 4.955834643360198
Validation loss: 4.134334593998575

Epoch: 5| Step: 8
Training loss: 3.7726913567428477
Validation loss: 3.987985139789781

Epoch: 5| Step: 9
Training loss: 3.722584134310993
Validation loss: 3.84714056648301

Epoch: 5| Step: 10
Training loss: 3.8069066776253444
Validation loss: 3.691117710361467

Epoch: 5| Step: 11
Training loss: 3.4280098046392933
Validation loss: 3.562041509694147

Epoch: 7| Step: 0
Training loss: 3.838941838779056
Validation loss: 3.423730135420513

Epoch: 5| Step: 1
Training loss: 3.4179920479116688
Validation loss: 3.2750060876153952

Epoch: 5| Step: 2
Training loss: 2.8690689940109526
Validation loss: 3.153104936796137

Epoch: 5| Step: 3
Training loss: 2.6678569541284722
Validation loss: 3.0656626518547854

Epoch: 5| Step: 4
Training loss: 3.054016820155542
Validation loss: 3.0155204827309783

Epoch: 5| Step: 5
Training loss: 3.1135566235452443
Validation loss: 2.956525536802622

Epoch: 5| Step: 6
Training loss: 3.0477863220448627
Validation loss: 2.9520636641108027

Epoch: 5| Step: 7
Training loss: 2.729331285787441
Validation loss: 2.926106223107995

Epoch: 5| Step: 8
Training loss: 3.4244375170748276
Validation loss: 2.917455199915632

Epoch: 5| Step: 9
Training loss: 3.229222270527866
Validation loss: 2.9824191869737344

Epoch: 5| Step: 10
Training loss: 2.8768056092314724
Validation loss: 2.943723575476141

Epoch: 5| Step: 11
Training loss: 3.3171043784480965
Validation loss: 2.9738572443646274

Epoch: 8| Step: 0
Training loss: 3.3002706821285708
Validation loss: 3.0438068461609213

Epoch: 5| Step: 1
Training loss: 2.7777008385069455
Validation loss: 3.05303907999099

Epoch: 5| Step: 2
Training loss: 3.067770024161293
Validation loss: 3.077724901973862

Epoch: 5| Step: 3
Training loss: 3.1960087323123196
Validation loss: 3.105634301849108

Epoch: 5| Step: 4
Training loss: 2.7415922991590764
Validation loss: 3.108610234868371

Epoch: 5| Step: 5
Training loss: 2.276402378669425
Validation loss: 3.099471353760243

Epoch: 5| Step: 6
Training loss: 3.760697048791041
Validation loss: 3.06694268395975

Epoch: 5| Step: 7
Training loss: 2.7220559901996393
Validation loss: 3.0354109615899807

Epoch: 5| Step: 8
Training loss: 3.054374190943739
Validation loss: 3.029677537046239

Epoch: 5| Step: 9
Training loss: 3.041401646882755
Validation loss: 2.985566638623411

Epoch: 5| Step: 10
Training loss: 3.856588863773862
Validation loss: 2.9797525641157763

Epoch: 5| Step: 11
Training loss: 4.709423220361645
Validation loss: 2.914771190712534

Epoch: 9| Step: 0
Training loss: 3.1368941736632903
Validation loss: 2.904030447948278

Epoch: 5| Step: 1
Training loss: 2.832664429486939
Validation loss: 2.8867988833402145

Epoch: 5| Step: 2
Training loss: 3.267164533653887
Validation loss: 2.8392698852900984

Epoch: 5| Step: 3
Training loss: 2.527426292333268
Validation loss: 2.8521658341870904

Epoch: 5| Step: 4
Training loss: 3.9626261405241636
Validation loss: 2.8582356515955394

Epoch: 5| Step: 5
Training loss: 2.5920884658998946
Validation loss: 2.878832926133456

Epoch: 5| Step: 6
Training loss: 2.851994897118239
Validation loss: 2.856281632735855

Epoch: 5| Step: 7
Training loss: 1.971566078423436
Validation loss: 2.880425444428232

Epoch: 5| Step: 8
Training loss: 3.0094932715129534
Validation loss: 2.890437712916965

Epoch: 5| Step: 9
Training loss: 2.5681282200518076
Validation loss: 2.9071139483712183

Epoch: 5| Step: 10
Training loss: 3.264435912120319
Validation loss: 2.8801920834589363

Epoch: 5| Step: 11
Training loss: 1.6972482765988017
Validation loss: 2.899602308080127

Epoch: 10| Step: 0
Training loss: 2.741953348014734
Validation loss: 2.8659021821052315

Epoch: 5| Step: 1
Training loss: 3.1404582876111546
Validation loss: 2.9126377219135438

Epoch: 5| Step: 2
Training loss: 3.118115891569272
Validation loss: 2.8769714879738095

Epoch: 5| Step: 3
Training loss: 2.3338910072198193
Validation loss: 2.8688909890761183

Epoch: 5| Step: 4
Training loss: 2.8854938225925433
Validation loss: 2.887066449814109

Epoch: 5| Step: 5
Training loss: 2.3324217605143582
Validation loss: 2.883053122577604

Epoch: 5| Step: 6
Training loss: 3.7159023120469383
Validation loss: 2.865733201408386

Epoch: 5| Step: 7
Training loss: 2.990884601801605
Validation loss: 2.837621442853933

Epoch: 5| Step: 8
Training loss: 2.9112846491034623
Validation loss: 2.860260411185576

Epoch: 5| Step: 9
Training loss: 3.356875745240198
Validation loss: 2.842634943099424

Epoch: 5| Step: 10
Training loss: 2.3915395545631353
Validation loss: 2.82228527304246

Epoch: 5| Step: 11
Training loss: 2.8816494546894345
Validation loss: 2.8382230714028838

Epoch: 11| Step: 0
Training loss: 2.744597503531325
Validation loss: 2.8150680720826333

Epoch: 5| Step: 1
Training loss: 3.2056868566122065
Validation loss: 2.82534398991908

Epoch: 5| Step: 2
Training loss: 2.7040212391295704
Validation loss: 2.811691637783796

Epoch: 5| Step: 3
Training loss: 3.0497160357252233
Validation loss: 2.840317096816308

Epoch: 5| Step: 4
Training loss: 3.0023519515382873
Validation loss: 2.8252952813804275

Epoch: 5| Step: 5
Training loss: 2.620254586932689
Validation loss: 2.8235404966364097

Epoch: 5| Step: 6
Training loss: 2.3849905596852157
Validation loss: 2.8249707977225946

Epoch: 5| Step: 7
Training loss: 2.401449790796652
Validation loss: 2.84179549069715

Epoch: 5| Step: 8
Training loss: 3.406040290186542
Validation loss: 2.841881365137276

Epoch: 5| Step: 9
Training loss: 3.026364824085476
Validation loss: 2.863461237684852

Epoch: 5| Step: 10
Training loss: 3.036221389729941
Validation loss: 2.8136438939884605

Epoch: 5| Step: 11
Training loss: 3.2402370239026244
Validation loss: 2.7823107300427457

Epoch: 12| Step: 0
Training loss: 2.6830210956223293
Validation loss: 2.777173455119376

Epoch: 5| Step: 1
Training loss: 2.8646007375477445
Validation loss: 2.788471540429739

Epoch: 5| Step: 2
Training loss: 2.7114215165895916
Validation loss: 2.8118338255119184

Epoch: 5| Step: 3
Training loss: 2.6819853870127446
Validation loss: 2.796635978046885

Epoch: 5| Step: 4
Training loss: 3.013436744007054
Validation loss: 2.8183959584936074

Epoch: 5| Step: 5
Training loss: 2.4049428386596756
Validation loss: 2.849199341802982

Epoch: 5| Step: 6
Training loss: 2.758033289729894
Validation loss: 2.7949572546936885

Epoch: 5| Step: 7
Training loss: 2.716958782272313
Validation loss: 2.773202271851141

Epoch: 5| Step: 8
Training loss: 2.387923565585407
Validation loss: 2.8051457787777627

Epoch: 5| Step: 9
Training loss: 3.4461298035867634
Validation loss: 2.8548781083726706

Epoch: 5| Step: 10
Training loss: 3.347019486643262
Validation loss: 2.8010166642101777

Epoch: 5| Step: 11
Training loss: 3.4874739615175887
Validation loss: 2.7905793272768427

Epoch: 13| Step: 0
Training loss: 3.5114005923816527
Validation loss: 2.7486014386112303

Epoch: 5| Step: 1
Training loss: 2.6605134743741967
Validation loss: 2.787957992334842

Epoch: 5| Step: 2
Training loss: 2.869587156528544
Validation loss: 2.797003201435909

Epoch: 5| Step: 3
Training loss: 2.5574399719949765
Validation loss: 2.8397253467445562

Epoch: 5| Step: 4
Training loss: 2.696763772980407
Validation loss: 2.8385763685339236

Epoch: 5| Step: 5
Training loss: 2.9175224320334636
Validation loss: 2.8170810584145767

Epoch: 5| Step: 6
Training loss: 2.523314292899708
Validation loss: 2.830981882296751

Epoch: 5| Step: 7
Training loss: 2.979313257696779
Validation loss: 2.8628152985981266

Epoch: 5| Step: 8
Training loss: 2.4867664079716376
Validation loss: 2.8010020645612475

Epoch: 5| Step: 9
Training loss: 2.8186632231826945
Validation loss: 2.81009008863328

Epoch: 5| Step: 10
Training loss: 3.075529756891073
Validation loss: 2.814895796261566

Epoch: 5| Step: 11
Training loss: 4.393907507817598
Validation loss: 2.793767520528155

Epoch: 14| Step: 0
Training loss: 3.2402464422055286
Validation loss: 2.798332502339618

Epoch: 5| Step: 1
Training loss: 3.091190705245519
Validation loss: 2.7751907967510054

Epoch: 5| Step: 2
Training loss: 2.7816928125260842
Validation loss: 2.7617298325635957

Epoch: 5| Step: 3
Training loss: 2.2994301006976454
Validation loss: 2.7464241744277955

Epoch: 5| Step: 4
Training loss: 2.745281158945764
Validation loss: 2.808797504389462

Epoch: 5| Step: 5
Training loss: 2.9286360417857633
Validation loss: 2.7818061972544297

Epoch: 5| Step: 6
Training loss: 2.580668726167454
Validation loss: 2.719572122002433

Epoch: 5| Step: 7
Training loss: 2.726913123553929
Validation loss: 2.7595539376291875

Epoch: 5| Step: 8
Training loss: 2.6567531333582513
Validation loss: 2.780095478700675

Epoch: 5| Step: 9
Training loss: 3.16253700687031
Validation loss: 2.767806397982222

Epoch: 5| Step: 10
Training loss: 2.5113377022512395
Validation loss: 2.7864382353916453

Epoch: 5| Step: 11
Training loss: 3.8235947564526587
Validation loss: 2.743962455205583

Epoch: 15| Step: 0
Training loss: 2.8479968208766726
Validation loss: 2.7962154910840527

Epoch: 5| Step: 1
Training loss: 3.1783876503709036
Validation loss: 2.7598374220860435

Epoch: 5| Step: 2
Training loss: 2.124906874467371
Validation loss: 2.7551131253056758

Epoch: 5| Step: 3
Training loss: 2.570795726861722
Validation loss: 2.773817038199426

Epoch: 5| Step: 4
Training loss: 3.1647068450779456
Validation loss: 2.7194623050572924

Epoch: 5| Step: 5
Training loss: 2.9989865498586203
Validation loss: 2.735106742677426

Epoch: 5| Step: 6
Training loss: 2.7951370892147067
Validation loss: 2.7960152290192815

Epoch: 5| Step: 7
Training loss: 2.5236815343434063
Validation loss: 2.7700906824309173

Epoch: 5| Step: 8
Training loss: 2.9716942893680853
Validation loss: 2.749649596287053

Epoch: 5| Step: 9
Training loss: 2.4877872665384846
Validation loss: 2.7299991762360296

Epoch: 5| Step: 10
Training loss: 2.8894207069565954
Validation loss: 2.694847733973954

Epoch: 5| Step: 11
Training loss: 2.5538841174249853
Validation loss: 2.7755469847053384

Epoch: 16| Step: 0
Training loss: 2.3387378250694115
Validation loss: 2.7218175624330323

Epoch: 5| Step: 1
Training loss: 2.8384484138686332
Validation loss: 2.77825029460368

Epoch: 5| Step: 2
Training loss: 2.593157964953383
Validation loss: 2.6805860645872714

Epoch: 5| Step: 3
Training loss: 3.316864018024028
Validation loss: 2.762656599816124

Epoch: 5| Step: 4
Training loss: 2.684527238963058
Validation loss: 2.7451746575089055

Epoch: 5| Step: 5
Training loss: 1.8315772691777843
Validation loss: 2.7407034275167166

Epoch: 5| Step: 6
Training loss: 2.4782885003240893
Validation loss: 2.7299733619822595

Epoch: 5| Step: 7
Training loss: 2.9357310711298252
Validation loss: 2.7553470458872367

Epoch: 5| Step: 8
Training loss: 2.886113290436107
Validation loss: 2.769288565795519

Epoch: 5| Step: 9
Training loss: 3.4488967624254356
Validation loss: 2.7974954197573103

Epoch: 5| Step: 10
Training loss: 2.389026082212264
Validation loss: 2.780933872930263

Epoch: 5| Step: 11
Training loss: 3.90220970251971
Validation loss: 2.7556282918046193

Epoch: 17| Step: 0
Training loss: 2.780809860549582
Validation loss: 2.6921930293496694

Epoch: 5| Step: 1
Training loss: 1.957135226291502
Validation loss: 2.667666148594851

Epoch: 5| Step: 2
Training loss: 3.195941592641239
Validation loss: 2.788328731407279

Epoch: 5| Step: 3
Training loss: 2.6043260347557093
Validation loss: 2.683608142531001

Epoch: 5| Step: 4
Training loss: 2.740705388454978
Validation loss: 2.743363667069712

Epoch: 5| Step: 5
Training loss: 3.0600699300816223
Validation loss: 2.7329948120927523

Epoch: 5| Step: 6
Training loss: 2.914188003905536
Validation loss: 2.7154804096132206

Epoch: 5| Step: 7
Training loss: 3.037049399025973
Validation loss: 2.722618777775688

Epoch: 5| Step: 8
Training loss: 2.207494744438231
Validation loss: 2.738944560571238

Epoch: 5| Step: 9
Training loss: 2.747988832426076
Validation loss: 2.732661482380831

Epoch: 5| Step: 10
Training loss: 2.2614730148038005
Validation loss: 2.7438323765280934

Epoch: 5| Step: 11
Training loss: 3.294859066439746
Validation loss: 2.7531944635629397

Epoch: 18| Step: 0
Training loss: 2.9203944407520015
Validation loss: 2.7899115024452272

Epoch: 5| Step: 1
Training loss: 2.1520941670955365
Validation loss: 2.7577213059747727

Epoch: 5| Step: 2
Training loss: 3.1960067927416063
Validation loss: 2.784530729911648

Epoch: 5| Step: 3
Training loss: 2.8838652882640847
Validation loss: 2.720901299475278

Epoch: 5| Step: 4
Training loss: 2.915785538320841
Validation loss: 2.682233155485801

Epoch: 5| Step: 5
Training loss: 2.192007815228752
Validation loss: 2.7511174503640943

Epoch: 5| Step: 6
Training loss: 2.670244221179896
Validation loss: 2.710818054470046

Epoch: 5| Step: 7
Training loss: 2.736685163905474
Validation loss: 2.770228041358123

Epoch: 5| Step: 8
Training loss: 2.8064810880740465
Validation loss: 2.7103314890416774

Epoch: 5| Step: 9
Training loss: 2.907366958421384
Validation loss: 2.7257456243506075

Epoch: 5| Step: 10
Training loss: 2.165187612073673
Validation loss: 2.7399082148335427

Epoch: 5| Step: 11
Training loss: 2.6190179146077126
Validation loss: 2.7396540626610815

Epoch: 19| Step: 0
Training loss: 2.6119208793690953
Validation loss: 2.696404542698618

Epoch: 5| Step: 1
Training loss: 2.4943801657313283
Validation loss: 2.7120428003257615

Epoch: 5| Step: 2
Training loss: 3.1173228757904226
Validation loss: 2.754881348463605

Epoch: 5| Step: 3
Training loss: 2.2300342998518263
Validation loss: 2.8343616868014516

Epoch: 5| Step: 4
Training loss: 2.7475283525998133
Validation loss: 2.670676127869176

Epoch: 5| Step: 5
Training loss: 2.7432061284154483
Validation loss: 2.716333093280698

Epoch: 5| Step: 6
Training loss: 2.8567624690380535
Validation loss: 2.7579039395512175

Epoch: 5| Step: 7
Training loss: 2.4153750903508553
Validation loss: 2.7604060094855574

Epoch: 5| Step: 8
Training loss: 3.3183590876066678
Validation loss: 2.7059900539264277

Epoch: 5| Step: 9
Training loss: 1.7665887413592933
Validation loss: 2.763312290554047

Epoch: 5| Step: 10
Training loss: 2.9460982430645597
Validation loss: 2.696572702998382

Epoch: 5| Step: 11
Training loss: 2.8319945444819603
Validation loss: 2.7137719176871733

Epoch: 20| Step: 0
Training loss: 2.805398070024792
Validation loss: 2.729222467570318

Epoch: 5| Step: 1
Training loss: 2.9502814595064684
Validation loss: 2.7713833074262952

Epoch: 5| Step: 2
Training loss: 2.8893244936599083
Validation loss: 2.807338018276509

Epoch: 5| Step: 3
Training loss: 2.775363822662631
Validation loss: 2.782363747182316

Epoch: 5| Step: 4
Training loss: 2.498064245382824
Validation loss: 2.743848820893016

Epoch: 5| Step: 5
Training loss: 2.791106343380014
Validation loss: 2.7066153224665825

Epoch: 5| Step: 6
Training loss: 2.5868917588812965
Validation loss: 2.7152908835185574

Epoch: 5| Step: 7
Training loss: 2.116910684091652
Validation loss: 2.747078011496656

Epoch: 5| Step: 8
Training loss: 2.722876738236312
Validation loss: 2.712631410940199

Epoch: 5| Step: 9
Training loss: 3.2439530678398625
Validation loss: 2.6416118779101483

Epoch: 5| Step: 10
Training loss: 2.1895972960728933
Validation loss: 2.720838157733264

Epoch: 5| Step: 11
Training loss: 1.6825481805803855
Validation loss: 2.6903466481284335

Epoch: 21| Step: 0
Training loss: 2.8172836312698437
Validation loss: 2.745860491885073

Epoch: 5| Step: 1
Training loss: 2.6326528438528194
Validation loss: 2.633646699864792

Epoch: 5| Step: 2
Training loss: 2.9212523424223233
Validation loss: 2.770038330545104

Epoch: 5| Step: 3
Training loss: 2.1537875060072
Validation loss: 2.758840137110182

Epoch: 5| Step: 4
Training loss: 2.9937010440526803
Validation loss: 2.788493906114894

Epoch: 5| Step: 5
Training loss: 2.65558023423557
Validation loss: 2.6665458720137427

Epoch: 5| Step: 6
Training loss: 2.6585351426903188
Validation loss: 2.7246405559838403

Epoch: 5| Step: 7
Training loss: 2.540259352081236
Validation loss: 2.6852032657784326

Epoch: 5| Step: 8
Training loss: 2.799177447479314
Validation loss: 2.7400589059962313

Epoch: 5| Step: 9
Training loss: 2.081817100633656
Validation loss: 2.7741586311806836

Epoch: 5| Step: 10
Training loss: 2.745366267381756
Validation loss: 2.8052363978720978

Epoch: 5| Step: 11
Training loss: 2.556012664447148
Validation loss: 2.705769114831226

Epoch: 22| Step: 0
Training loss: 2.8760601245288293
Validation loss: 2.7196456814969445

Epoch: 5| Step: 1
Training loss: 2.0836886166580135
Validation loss: 2.617964569425418

Epoch: 5| Step: 2
Training loss: 3.3669198409968484
Validation loss: 2.75539599586585

Epoch: 5| Step: 3
Training loss: 2.734209502525132
Validation loss: 2.7084806414426392

Epoch: 5| Step: 4
Training loss: 2.7282844068660683
Validation loss: 2.7200956230032807

Epoch: 5| Step: 5
Training loss: 2.59396205173167
Validation loss: 2.800804010402502

Epoch: 5| Step: 6
Training loss: 3.1535915849945964
Validation loss: 2.750947518105657

Epoch: 5| Step: 7
Training loss: 2.4396858195976683
Validation loss: 2.714225845091935

Epoch: 5| Step: 8
Training loss: 2.109801411797542
Validation loss: 2.670524497533266

Epoch: 5| Step: 9
Training loss: 2.432499965812785
Validation loss: 2.7033414166057623

Epoch: 5| Step: 10
Training loss: 2.2138156018264894
Validation loss: 2.699031604364619

Epoch: 5| Step: 11
Training loss: 2.0249920032484607
Validation loss: 2.75132173145149

Epoch: 23| Step: 0
Training loss: 2.614059446416281
Validation loss: 2.793157113221345

Epoch: 5| Step: 1
Training loss: 2.3234054552958434
Validation loss: 2.7132986451688024

Epoch: 5| Step: 2
Training loss: 2.336978233977108
Validation loss: 2.7835225703863458

Epoch: 5| Step: 3
Training loss: 2.0499408852962633
Validation loss: 2.7112466304248666

Epoch: 5| Step: 4
Training loss: 3.241946291855765
Validation loss: 2.8285590518419856

Epoch: 5| Step: 5
Training loss: 2.4135510541733054
Validation loss: 2.7832540085809163

Epoch: 5| Step: 6
Training loss: 2.628816282821629
Validation loss: 2.7489877629605

Epoch: 5| Step: 7
Training loss: 3.3831483881219646
Validation loss: 2.761923390764722

Epoch: 5| Step: 8
Training loss: 3.2838810136359613
Validation loss: 2.7717314223154936

Epoch: 5| Step: 9
Training loss: 1.6546443137493911
Validation loss: 2.666144313664024

Epoch: 5| Step: 10
Training loss: 2.1554632548379344
Validation loss: 2.7506694087331343

Epoch: 5| Step: 11
Training loss: 4.353196664235348
Validation loss: 2.6856311095927787

Epoch: 24| Step: 0
Training loss: 2.9108671203393928
Validation loss: 2.778339667048917

Epoch: 5| Step: 1
Training loss: 2.4014550526892378
Validation loss: 2.7422226362884556

Epoch: 5| Step: 2
Training loss: 2.693883190712366
Validation loss: 2.6847211014395045

Epoch: 5| Step: 3
Training loss: 3.079726678685184
Validation loss: 2.7604782757391684

Epoch: 5| Step: 4
Training loss: 2.060299711183386
Validation loss: 2.788003832782289

Epoch: 5| Step: 5
Training loss: 3.3519292599626778
Validation loss: 2.7432259823908787

Epoch: 5| Step: 6
Training loss: 2.3941223890718244
Validation loss: 2.7839398645973414

Epoch: 5| Step: 7
Training loss: 2.7471513732818966
Validation loss: 2.7180270662527324

Epoch: 5| Step: 8
Training loss: 2.0041528739639642
Validation loss: 2.740462997154698

Epoch: 5| Step: 9
Training loss: 2.5772524195108466
Validation loss: 2.7377499052620213

Epoch: 5| Step: 10
Training loss: 2.3524543363738477
Validation loss: 2.6249135548117923

Epoch: 5| Step: 11
Training loss: 3.160424219942633
Validation loss: 2.736630753621471

Epoch: 25| Step: 0
Training loss: 2.3666397317061043
Validation loss: 2.78427541856551

Epoch: 5| Step: 1
Training loss: 2.330250224483116
Validation loss: 2.6860697696140448

Epoch: 5| Step: 2
Training loss: 2.0190769178864376
Validation loss: 2.7234474101700616

Epoch: 5| Step: 3
Training loss: 2.5280679552505596
Validation loss: 2.6817159473114343

Epoch: 5| Step: 4
Training loss: 3.0084392736771868
Validation loss: 2.732516778148109

Epoch: 5| Step: 5
Training loss: 2.568886126324636
Validation loss: 2.6840147625661195

Epoch: 5| Step: 6
Training loss: 2.4651755035629206
Validation loss: 2.6644930114131884

Epoch: 5| Step: 7
Training loss: 2.7167103449892807
Validation loss: 2.6718834064492683

Epoch: 5| Step: 8
Training loss: 2.4701293761621574
Validation loss: 2.698471900825216

Epoch: 5| Step: 9
Training loss: 2.9159402396798666
Validation loss: 2.676221869729312

Epoch: 5| Step: 10
Training loss: 3.3934044762169133
Validation loss: 2.698706887969641

Epoch: 5| Step: 11
Training loss: 1.9340999672743506
Validation loss: 2.7572998888858478

Epoch: 26| Step: 0
Training loss: 2.3425819029275856
Validation loss: 2.6970531242722187

Epoch: 5| Step: 1
Training loss: 2.597674606373112
Validation loss: 2.6788824186231994

Epoch: 5| Step: 2
Training loss: 2.415886347402728
Validation loss: 2.668243866899275

Epoch: 5| Step: 3
Training loss: 2.8933083116823544
Validation loss: 2.7250658461871717

Epoch: 5| Step: 4
Training loss: 2.836521561434259
Validation loss: 2.700409265541498

Epoch: 5| Step: 5
Training loss: 3.0225115794929462
Validation loss: 2.7030735525479628

Epoch: 5| Step: 6
Training loss: 2.1437833555423667
Validation loss: 2.731363560100181

Epoch: 5| Step: 7
Training loss: 2.948400846333344
Validation loss: 2.766896591317702

Epoch: 5| Step: 8
Training loss: 2.6546537202927816
Validation loss: 2.687614756359357

Epoch: 5| Step: 9
Training loss: 2.3781407319399466
Validation loss: 2.7079783512663043

Epoch: 5| Step: 10
Training loss: 2.3936919441852216
Validation loss: 2.672613818840878

Epoch: 5| Step: 11
Training loss: 2.6946279347483344
Validation loss: 2.713591413475137

Epoch: 27| Step: 0
Training loss: 1.9511881265354851
Validation loss: 2.6938198950860954

Epoch: 5| Step: 1
Training loss: 2.701982819141851
Validation loss: 2.744495510987442

Epoch: 5| Step: 2
Training loss: 2.7730047183789384
Validation loss: 2.6868417103679416

Epoch: 5| Step: 3
Training loss: 2.7840841190630434
Validation loss: 2.735325206778068

Epoch: 5| Step: 4
Training loss: 3.079001984345657
Validation loss: 2.8033532960111396

Epoch: 5| Step: 5
Training loss: 2.2497465202812466
Validation loss: 2.7404685469844674

Epoch: 5| Step: 6
Training loss: 2.1567346885051863
Validation loss: 2.780803430259485

Epoch: 5| Step: 7
Training loss: 3.1814675187427173
Validation loss: 2.761511414050231

Epoch: 5| Step: 8
Training loss: 2.5225768142059293
Validation loss: 2.7395612778640057

Epoch: 5| Step: 9
Training loss: 2.58995108863865
Validation loss: 2.694277705703624

Epoch: 5| Step: 10
Training loss: 2.7188049837011468
Validation loss: 2.7263662418826864

Epoch: 5| Step: 11
Training loss: 2.6587019430605023
Validation loss: 2.6527259899552322

Epoch: 28| Step: 0
Training loss: 2.4779774567792483
Validation loss: 2.6809388882014282

Epoch: 5| Step: 1
Training loss: 2.5083359026552476
Validation loss: 2.7409168389603997

Epoch: 5| Step: 2
Training loss: 2.523937636377289
Validation loss: 2.681534229973159

Epoch: 5| Step: 3
Training loss: 2.4399966633883317
Validation loss: 2.8004173067176636

Epoch: 5| Step: 4
Training loss: 2.303614686747764
Validation loss: 2.7894719853493872

Epoch: 5| Step: 5
Training loss: 2.736112990488955
Validation loss: 2.8069209040940772

Epoch: 5| Step: 6
Training loss: 3.0847757591225045
Validation loss: 2.7333256842537206

Epoch: 5| Step: 7
Training loss: 2.5098171124947304
Validation loss: 2.7463682968052985

Epoch: 5| Step: 8
Training loss: 3.045105248998469
Validation loss: 2.648303955972291

Epoch: 5| Step: 9
Training loss: 2.608832023000131
Validation loss: 2.7519542584891834

Epoch: 5| Step: 10
Training loss: 2.9207048163843403
Validation loss: 2.676410729090893

Epoch: 5| Step: 11
Training loss: 2.1348430204191304
Validation loss: 2.673162243196917

Epoch: 29| Step: 0
Training loss: 2.1754955604137938
Validation loss: 2.7048839072454505

Epoch: 5| Step: 1
Training loss: 2.8172587507888736
Validation loss: 2.6909489826853297

Epoch: 5| Step: 2
Training loss: 2.90710633490274
Validation loss: 2.780148609549435

Epoch: 5| Step: 3
Training loss: 3.0467782812173025
Validation loss: 2.798215104607033

Epoch: 5| Step: 4
Training loss: 2.88932102794107
Validation loss: 2.7871146180875024

Epoch: 5| Step: 5
Training loss: 2.521687186998714
Validation loss: 2.8060219865360367

Epoch: 5| Step: 6
Training loss: 3.5495311857326692
Validation loss: 2.775288375270278

Epoch: 5| Step: 7
Training loss: 2.191301475916929
Validation loss: 2.7342447413344857

Epoch: 5| Step: 8
Training loss: 2.6164314658361456
Validation loss: 2.631004708969153

Epoch: 5| Step: 9
Training loss: 2.2277039931337757
Validation loss: 2.715804868944782

Epoch: 5| Step: 10
Training loss: 1.4343578163065118
Validation loss: 2.637073788699194

Epoch: 5| Step: 11
Training loss: 2.8452667551066004
Validation loss: 2.665662003797334

Epoch: 30| Step: 0
Training loss: 2.6805801906562725
Validation loss: 2.650081720531635

Epoch: 5| Step: 1
Training loss: 2.3346712386614645
Validation loss: 2.7035698974758855

Epoch: 5| Step: 2
Training loss: 2.6431629692520184
Validation loss: 2.7445140507614583

Epoch: 5| Step: 3
Training loss: 3.033607745770734
Validation loss: 2.7967554986809375

Epoch: 5| Step: 4
Training loss: 2.150893815126394
Validation loss: 2.7900153668583174

Epoch: 5| Step: 5
Training loss: 2.191075808384913
Validation loss: 2.7265858726629157

Epoch: 5| Step: 6
Training loss: 2.712251284399018
Validation loss: 2.739484576099995

Epoch: 5| Step: 7
Training loss: 2.703343553472815
Validation loss: 2.769953822371884

Epoch: 5| Step: 8
Training loss: 2.304243452322962
Validation loss: 2.756409883655507

Epoch: 5| Step: 9
Training loss: 3.232346787977965
Validation loss: 2.7273726257176816

Epoch: 5| Step: 10
Training loss: 2.766277774993696
Validation loss: 2.712493662379958

Epoch: 5| Step: 11
Training loss: 3.6348015702984853
Validation loss: 2.6514297356203165

Epoch: 31| Step: 0
Training loss: 3.076705372884782
Validation loss: 2.6854308798043673

Epoch: 5| Step: 1
Training loss: 2.3023290948883552
Validation loss: 2.6900968019151397

Epoch: 5| Step: 2
Training loss: 2.949604337635167
Validation loss: 2.667549241811244

Epoch: 5| Step: 3
Training loss: 1.407129182430984
Validation loss: 2.6801378781759015

Epoch: 5| Step: 4
Training loss: 2.5674725179863627
Validation loss: 2.6695649532385763

Epoch: 5| Step: 5
Training loss: 2.390069735000484
Validation loss: 2.6667442509173274

Epoch: 5| Step: 6
Training loss: 2.6521687288362785
Validation loss: 2.698101174858562

Epoch: 5| Step: 7
Training loss: 2.8116984602738517
Validation loss: 2.679134782707216

Epoch: 5| Step: 8
Training loss: 2.460573102826707
Validation loss: 2.6299848417502814

Epoch: 5| Step: 9
Training loss: 2.083164386256749
Validation loss: 2.7383753569463094

Epoch: 5| Step: 10
Training loss: 2.886593208112479
Validation loss: 2.727780271454772

Epoch: 5| Step: 11
Training loss: 3.6376854813206076
Validation loss: 2.663266578574971

Epoch: 32| Step: 0
Training loss: 2.2640948159680416
Validation loss: 2.6445889788308374

Epoch: 5| Step: 1
Training loss: 1.9747982066918432
Validation loss: 2.6777118929552883

Epoch: 5| Step: 2
Training loss: 2.488690927935817
Validation loss: 2.6497134208168664

Epoch: 5| Step: 3
Training loss: 2.7701879242041496
Validation loss: 2.7359906391681723

Epoch: 5| Step: 4
Training loss: 2.7056511337487974
Validation loss: 2.758546376764614

Epoch: 5| Step: 5
Training loss: 2.427056657592698
Validation loss: 2.7803342147310173

Epoch: 5| Step: 6
Training loss: 2.9878194215229747
Validation loss: 2.715566016706397

Epoch: 5| Step: 7
Training loss: 2.8357791068241185
Validation loss: 2.677782736725742

Epoch: 5| Step: 8
Training loss: 2.84289152161568
Validation loss: 2.753254258191815

Epoch: 5| Step: 9
Training loss: 2.3761629971425062
Validation loss: 2.7696430702036055

Epoch: 5| Step: 10
Training loss: 2.3065793306248055
Validation loss: 2.7736760820381727

Epoch: 5| Step: 11
Training loss: 2.6951262921129007
Validation loss: 2.6561823481004123

Epoch: 33| Step: 0
Training loss: 3.0798122990374344
Validation loss: 2.6660192505901494

Epoch: 5| Step: 1
Training loss: 2.857527005392574
Validation loss: 2.7721586368293663

Epoch: 5| Step: 2
Training loss: 2.9929668317971374
Validation loss: 2.8605158011883476

Epoch: 5| Step: 3
Training loss: 1.9281620683615488
Validation loss: 2.787103044787398

Epoch: 5| Step: 4
Training loss: 2.9283108744866415
Validation loss: 2.8152161304512036

Epoch: 5| Step: 5
Training loss: 2.92524011392588
Validation loss: 2.8273143098142914

Epoch: 5| Step: 6
Training loss: 2.816760163946783
Validation loss: 2.7944374828765928

Epoch: 5| Step: 7
Training loss: 2.4745093658880495
Validation loss: 2.799589612098084

Epoch: 5| Step: 8
Training loss: 2.5822875664665497
Validation loss: 2.797235126504004

Epoch: 5| Step: 9
Training loss: 1.861484260855263
Validation loss: 2.6830175207763616

Epoch: 5| Step: 10
Training loss: 2.2488884829448357
Validation loss: 2.7288988991532883

Epoch: 5| Step: 11
Training loss: 2.7965264982335256
Validation loss: 2.7463231033911435

Epoch: 34| Step: 0
Training loss: 2.2637313821786367
Validation loss: 2.627699300494953

Epoch: 5| Step: 1
Training loss: 2.4557603420788134
Validation loss: 2.7612904455280254

Epoch: 5| Step: 2
Training loss: 2.4058484819985986
Validation loss: 2.739435145983953

Epoch: 5| Step: 3
Training loss: 2.357329840076384
Validation loss: 2.748862381638948

Epoch: 5| Step: 4
Training loss: 3.5330083739599587
Validation loss: 2.710113150872566

Epoch: 5| Step: 5
Training loss: 2.7905366992543303
Validation loss: 2.6705655761697225

Epoch: 5| Step: 6
Training loss: 2.50429947215832
Validation loss: 2.6943669452751835

Epoch: 5| Step: 7
Training loss: 2.42216962437388
Validation loss: 2.7098665421458596

Epoch: 5| Step: 8
Training loss: 2.635581080518777
Validation loss: 2.754235942756112

Epoch: 5| Step: 9
Training loss: 2.4724938699397514
Validation loss: 2.7599332470123756

Epoch: 5| Step: 10
Training loss: 2.185937595980944
Validation loss: 2.681027854780898

Epoch: 5| Step: 11
Training loss: 0.8565463590440685
Validation loss: 2.711631799591725

Epoch: 35| Step: 0
Training loss: 1.794560010959391
Validation loss: 2.722434831661903

Epoch: 5| Step: 1
Training loss: 1.9658980527117895
Validation loss: 2.6837673177398758

Epoch: 5| Step: 2
Training loss: 2.676827286128708
Validation loss: 2.65582881280949

Epoch: 5| Step: 3
Training loss: 2.5678498781716526
Validation loss: 2.725249301227344

Epoch: 5| Step: 4
Training loss: 2.923300655389684
Validation loss: 2.721792349452873

Epoch: 5| Step: 5
Training loss: 2.6713778384602676
Validation loss: 2.7411377465207765

Epoch: 5| Step: 6
Training loss: 2.5177082415827865
Validation loss: 2.726949516745359

Epoch: 5| Step: 7
Training loss: 2.679537577091368
Validation loss: 2.7133954582924553

Epoch: 5| Step: 8
Training loss: 3.2115675407860818
Validation loss: 2.760267672326449

Epoch: 5| Step: 9
Training loss: 1.9095966791059353
Validation loss: 2.7131188271256117

Epoch: 5| Step: 10
Training loss: 2.4066956342748447
Validation loss: 2.723368883025417

Epoch: 5| Step: 11
Training loss: 2.0598443013210526
Validation loss: 2.696478741569148

Epoch: 36| Step: 0
Training loss: 2.6668587158506987
Validation loss: 2.778298572886534

Epoch: 5| Step: 1
Training loss: 2.2516502050912894
Validation loss: 2.6632945500447667

Epoch: 5| Step: 2
Training loss: 2.302668627964341
Validation loss: 2.6279104764385712

Epoch: 5| Step: 3
Training loss: 2.746173103238698
Validation loss: 2.701665074284049

Epoch: 5| Step: 4
Training loss: 2.6616119121476425
Validation loss: 2.6224906295618657

Epoch: 5| Step: 5
Training loss: 2.102007850625053
Validation loss: 2.5749986400106843

Epoch: 5| Step: 6
Training loss: 2.3708426579815516
Validation loss: 2.7262944524220174

Epoch: 5| Step: 7
Training loss: 3.002795506402573
Validation loss: 2.7101401293280536

Epoch: 5| Step: 8
Training loss: 2.7400440848764918
Validation loss: 2.641347417634122

Epoch: 5| Step: 9
Training loss: 2.7813634099233244
Validation loss: 2.644274148318457

Epoch: 5| Step: 10
Training loss: 2.6658652015141433
Validation loss: 2.7027228539538273

Epoch: 5| Step: 11
Training loss: 2.369912973729575
Validation loss: 2.7625486178312957

Epoch: 37| Step: 0
Training loss: 2.867885078575077
Validation loss: 2.6591722831758413

Epoch: 5| Step: 1
Training loss: 2.742857674544714
Validation loss: 2.7707512288847926

Epoch: 5| Step: 2
Training loss: 2.102170721480188
Validation loss: 2.6683055205288535

Epoch: 5| Step: 3
Training loss: 2.1928502729298516
Validation loss: 2.7399025841030467

Epoch: 5| Step: 4
Training loss: 3.2115599685574336
Validation loss: 2.8262280658723933

Epoch: 5| Step: 5
Training loss: 2.414830156755154
Validation loss: 2.6643825200823574

Epoch: 5| Step: 6
Training loss: 2.3058072748103027
Validation loss: 2.6966422702921955

Epoch: 5| Step: 7
Training loss: 2.311973099350765
Validation loss: 2.7394489042615033

Epoch: 5| Step: 8
Training loss: 2.7548849760991594
Validation loss: 2.6450726224019165

Epoch: 5| Step: 9
Training loss: 2.5202944050734684
Validation loss: 2.6893230029070696

Epoch: 5| Step: 10
Training loss: 2.5315043945575733
Validation loss: 2.710181982058086

Epoch: 5| Step: 11
Training loss: 2.0624123756984396
Validation loss: 2.7574794989694458

Epoch: 38| Step: 0
Training loss: 3.1965695172750386
Validation loss: 2.6653635645896903

Epoch: 5| Step: 1
Training loss: 2.646329958306405
Validation loss: 2.6698949329251223

Epoch: 5| Step: 2
Training loss: 2.0064707031544686
Validation loss: 2.704857574175469

Epoch: 5| Step: 3
Training loss: 3.094415304144537
Validation loss: 2.6972843015752948

Epoch: 5| Step: 4
Training loss: 1.9381059498913238
Validation loss: 2.670405681004404

Epoch: 5| Step: 5
Training loss: 2.394077376247366
Validation loss: 2.703502312642002

Epoch: 5| Step: 6
Training loss: 2.815433413542453
Validation loss: 2.7270078723415216

Epoch: 5| Step: 7
Training loss: 2.547645686273043
Validation loss: 2.6944917617872948

Epoch: 5| Step: 8
Training loss: 2.3823042530772045
Validation loss: 2.6684723784112125

Epoch: 5| Step: 9
Training loss: 2.658991845900653
Validation loss: 2.706172184783487

Epoch: 5| Step: 10
Training loss: 1.3758780103685022
Validation loss: 2.658996149818528

Epoch: 5| Step: 11
Training loss: 2.776423434594457
Validation loss: 2.7061664251236683

Epoch: 39| Step: 0
Training loss: 1.7209161459860567
Validation loss: 2.687360397675596

Epoch: 5| Step: 1
Training loss: 1.8355014364329936
Validation loss: 2.6155434944035805

Epoch: 5| Step: 2
Training loss: 2.5626823546491435
Validation loss: 2.7346422010385485

Epoch: 5| Step: 3
Training loss: 2.515631539472527
Validation loss: 2.7505547549156835

Epoch: 5| Step: 4
Training loss: 1.9418957590123727
Validation loss: 2.6834443970218405

Epoch: 5| Step: 5
Training loss: 3.2186382978000854
Validation loss: 2.796032329324212

Epoch: 5| Step: 6
Training loss: 3.098002891819924
Validation loss: 2.731420199301851

Epoch: 5| Step: 7
Training loss: 2.851228877369374
Validation loss: 2.7807266764544214

Epoch: 5| Step: 8
Training loss: 2.6781351024744278
Validation loss: 2.668342940162109

Epoch: 5| Step: 9
Training loss: 2.839877667545906
Validation loss: 2.7092427756410986

Epoch: 5| Step: 10
Training loss: 2.5665432735193483
Validation loss: 2.6595311599766394

Epoch: 5| Step: 11
Training loss: 1.4499458072663955
Validation loss: 2.6240085894315173

Epoch: 40| Step: 0
Training loss: 2.2260932293996594
Validation loss: 2.6522760509003

Epoch: 5| Step: 1
Training loss: 2.6197556378798708
Validation loss: 2.6636746218342195

Epoch: 5| Step: 2
Training loss: 2.4109465108766113
Validation loss: 2.6313515259221196

Epoch: 5| Step: 3
Training loss: 2.450381451709226
Validation loss: 2.6848526157831514

Epoch: 5| Step: 4
Training loss: 2.7714901387085504
Validation loss: 2.7360455704975872

Epoch: 5| Step: 5
Training loss: 2.4347405096821517
Validation loss: 2.688993323716576

Epoch: 5| Step: 6
Training loss: 2.312119117506189
Validation loss: 2.6541706585716835

Epoch: 5| Step: 7
Training loss: 3.364385089210719
Validation loss: 2.662594675192653

Epoch: 5| Step: 8
Training loss: 2.2278708378525467
Validation loss: 2.674526282282082

Epoch: 5| Step: 9
Training loss: 2.742304351142826
Validation loss: 2.7118652141541304

Epoch: 5| Step: 10
Training loss: 2.414930662814395
Validation loss: 2.7066132891160892

Epoch: 5| Step: 11
Training loss: 1.356861772863719
Validation loss: 2.703733772567749

Epoch: 41| Step: 0
Training loss: 2.7015117616229722
Validation loss: 2.7196272388450264

Epoch: 5| Step: 1
Training loss: 2.2238697567407786
Validation loss: 2.7276554194387908

Epoch: 5| Step: 2
Training loss: 2.7809050271045557
Validation loss: 2.674407175513449

Epoch: 5| Step: 3
Training loss: 2.9425545891403275
Validation loss: 2.7254260262396306

Epoch: 5| Step: 4
Training loss: 2.360464690736419
Validation loss: 2.6855508607777003

Epoch: 5| Step: 5
Training loss: 2.5635339465303413
Validation loss: 2.682453644438779

Epoch: 5| Step: 6
Training loss: 2.725766303430646
Validation loss: 2.7147011552498483

Epoch: 5| Step: 7
Training loss: 1.9863678544683965
Validation loss: 2.6696665338747287

Epoch: 5| Step: 8
Training loss: 3.303606293836742
Validation loss: 2.681497564942886

Epoch: 5| Step: 9
Training loss: 1.8415371174651438
Validation loss: 2.743752349137073

Epoch: 5| Step: 10
Training loss: 2.027919562563511
Validation loss: 2.7418939228620802

Epoch: 5| Step: 11
Training loss: 2.7070635728984316
Validation loss: 2.661116655866474

Epoch: 42| Step: 0
Training loss: 2.7891590945829927
Validation loss: 2.721540425815141

Epoch: 5| Step: 1
Training loss: 2.8597161761748957
Validation loss: 2.7145895603388586

Epoch: 5| Step: 2
Training loss: 2.322797375910377
Validation loss: 2.6496386603303677

Epoch: 5| Step: 3
Training loss: 2.241357736205434
Validation loss: 2.669152404515011

Epoch: 5| Step: 4
Training loss: 2.676710159673652
Validation loss: 2.71548800428346

Epoch: 5| Step: 5
Training loss: 2.153393055212642
Validation loss: 2.723715342204445

Epoch: 5| Step: 6
Training loss: 2.0645985186724425
Validation loss: 2.6515764635085923

Epoch: 5| Step: 7
Training loss: 2.458589044838553
Validation loss: 2.6571609730110293

Epoch: 5| Step: 8
Training loss: 2.1765506828956735
Validation loss: 2.7101231725203996

Epoch: 5| Step: 9
Training loss: 3.0190691477137053
Validation loss: 2.688569820738958

Epoch: 5| Step: 10
Training loss: 2.4103336114402754
Validation loss: 2.7263442191672196

Epoch: 5| Step: 11
Training loss: 3.6260959678528386
Validation loss: 2.694459914843618

Epoch: 43| Step: 0
Training loss: 2.703240893751587
Validation loss: 2.6894433255226016

Epoch: 5| Step: 1
Training loss: 1.639109611016008
Validation loss: 2.7495642013296546

Epoch: 5| Step: 2
Training loss: 2.4398750080863216
Validation loss: 2.7986059692978196

Epoch: 5| Step: 3
Training loss: 2.723525314972561
Validation loss: 2.8273496214724947

Epoch: 5| Step: 4
Training loss: 2.258116493747547
Validation loss: 2.77813064294277

Epoch: 5| Step: 5
Training loss: 3.2316670899360567
Validation loss: 2.8198853060888576

Epoch: 5| Step: 6
Training loss: 3.229887867448575
Validation loss: 2.740442142599191

Epoch: 5| Step: 7
Training loss: 1.7808775930776037
Validation loss: 2.71492376049524

Epoch: 5| Step: 8
Training loss: 2.855220590811222
Validation loss: 2.733773243402232

Epoch: 5| Step: 9
Training loss: 2.168956414769255
Validation loss: 2.6912392212409295

Epoch: 5| Step: 10
Training loss: 2.4264769117167555
Validation loss: 2.704958865110898

Epoch: 5| Step: 11
Training loss: 2.4017437441456413
Validation loss: 2.6759733015132947

Epoch: 44| Step: 0
Training loss: 2.408135604221214
Validation loss: 2.7531179972865183

Epoch: 5| Step: 1
Training loss: 2.7321100063824475
Validation loss: 2.7583842382795076

Epoch: 5| Step: 2
Training loss: 2.226828790100106
Validation loss: 2.6849080457634718

Epoch: 5| Step: 3
Training loss: 2.574787268138044
Validation loss: 2.7031103144781494

Epoch: 5| Step: 4
Training loss: 2.960799000100166
Validation loss: 2.7474659963510457

Epoch: 5| Step: 5
Training loss: 2.2347438481134496
Validation loss: 2.6941122358774323

Epoch: 5| Step: 6
Training loss: 2.5463782452070185
Validation loss: 2.6774150640382803

Epoch: 5| Step: 7
Training loss: 2.498254261848069
Validation loss: 2.7147634517220363

Epoch: 5| Step: 8
Training loss: 1.925574920310144
Validation loss: 2.733835094373507

Epoch: 5| Step: 9
Training loss: 2.9718653344800434
Validation loss: 2.703490855424985

Epoch: 5| Step: 10
Training loss: 2.7443739822375384
Validation loss: 2.695923810548031

Epoch: 5| Step: 11
Training loss: 1.385331784662061
Validation loss: 2.62866682763909

Epoch: 45| Step: 0
Training loss: 2.1538862457840784
Validation loss: 2.662568912599298

Epoch: 5| Step: 1
Training loss: 2.574342484459852
Validation loss: 2.7497859170697856

Epoch: 5| Step: 2
Training loss: 1.7837050401118004
Validation loss: 2.699970109503327

Epoch: 5| Step: 3
Training loss: 2.0115393104893684
Validation loss: 2.7603905922479957

Epoch: 5| Step: 4
Training loss: 2.736515624152449
Validation loss: 2.7180393686063256

Epoch: 5| Step: 5
Training loss: 1.9173875848874535
Validation loss: 2.714509759570973

Epoch: 5| Step: 6
Training loss: 2.7024839666492637
Validation loss: 2.658162068337933

Epoch: 5| Step: 7
Training loss: 2.3211859398107886
Validation loss: 2.6902522292231748

Epoch: 5| Step: 8
Training loss: 2.6000412167436635
Validation loss: 2.686968758292958

Epoch: 5| Step: 9
Training loss: 3.378711355244497
Validation loss: 2.6839083247041544

Epoch: 5| Step: 10
Training loss: 2.3458786516797887
Validation loss: 2.6957624640330087

Epoch: 5| Step: 11
Training loss: 3.4796893855938986
Validation loss: 2.708483671026107

Epoch: 46| Step: 0
Training loss: 2.4344386904101163
Validation loss: 2.6567147390674135

Epoch: 5| Step: 1
Training loss: 2.2438546073989527
Validation loss: 2.7466191584585555

Epoch: 5| Step: 2
Training loss: 2.591304775455897
Validation loss: 2.745852742442494

Epoch: 5| Step: 3
Training loss: 2.540914476332802
Validation loss: 2.7324890281163796

Epoch: 5| Step: 4
Training loss: 2.1032611547782114
Validation loss: 2.760468019451657

Epoch: 5| Step: 5
Training loss: 2.404200386943616
Validation loss: 2.689317088956414

Epoch: 5| Step: 6
Training loss: 2.6648241671444057
Validation loss: 2.7608403990271606

Epoch: 5| Step: 7
Training loss: 2.303274982594735
Validation loss: 2.715831110499704

Epoch: 5| Step: 8
Training loss: 2.8131321514507417
Validation loss: 2.638114394059891

Epoch: 5| Step: 9
Training loss: 2.8832469912557697
Validation loss: 2.6517484256177113

Epoch: 5| Step: 10
Training loss: 2.315811569790626
Validation loss: 2.6584143665623006

Epoch: 5| Step: 11
Training loss: 1.8857707609661996
Validation loss: 2.7221089473877633

Epoch: 47| Step: 0
Training loss: 3.0045908134246373
Validation loss: 2.6773131095053855

Epoch: 5| Step: 1
Training loss: 2.377140686609252
Validation loss: 2.687236872810697

Epoch: 5| Step: 2
Training loss: 2.5229712843922094
Validation loss: 2.678277826566841

Epoch: 5| Step: 3
Training loss: 2.032880979259775
Validation loss: 2.7148616543186304

Epoch: 5| Step: 4
Training loss: 2.400766143105791
Validation loss: 2.681104819050792

Epoch: 5| Step: 5
Training loss: 2.236984543059301
Validation loss: 2.684405304541927

Epoch: 5| Step: 6
Training loss: 2.070277030209127
Validation loss: 2.6787040396061617

Epoch: 5| Step: 7
Training loss: 2.9446988465710837
Validation loss: 2.637680315419714

Epoch: 5| Step: 8
Training loss: 3.179265924573286
Validation loss: 2.6610294016306018

Epoch: 5| Step: 9
Training loss: 1.867148490721726
Validation loss: 2.618662032574705

Epoch: 5| Step: 10
Training loss: 2.328269493176257
Validation loss: 2.626126038389963

Epoch: 5| Step: 11
Training loss: 1.4964544991797226
Validation loss: 2.585988250726137

Epoch: 48| Step: 0
Training loss: 1.9538737578437806
Validation loss: 2.6321691260869713

Epoch: 5| Step: 1
Training loss: 2.829043918768977
Validation loss: 2.631927341438044

Epoch: 5| Step: 2
Training loss: 2.8992004213033877
Validation loss: 2.6753850750339483

Epoch: 5| Step: 3
Training loss: 2.5943505384761902
Validation loss: 2.6465842553091115

Epoch: 5| Step: 4
Training loss: 2.00933008692546
Validation loss: 2.727217525437682

Epoch: 5| Step: 5
Training loss: 3.1274003537630555
Validation loss: 2.5622256450013547

Epoch: 5| Step: 6
Training loss: 1.9155637497934401
Validation loss: 2.7061242202825095

Epoch: 5| Step: 7
Training loss: 2.1641430340596473
Validation loss: 2.632402729629549

Epoch: 5| Step: 8
Training loss: 2.1652398057236715
Validation loss: 2.6274587492059394

Epoch: 5| Step: 9
Training loss: 2.6819535619483172
Validation loss: 2.697556992100527

Epoch: 5| Step: 10
Training loss: 2.1109806307686068
Validation loss: 2.6802678791127406

Epoch: 5| Step: 11
Training loss: 2.217380262064452
Validation loss: 2.692823205904238

Epoch: 49| Step: 0
Training loss: 2.243432632995759
Validation loss: 2.6474200894834774

Epoch: 5| Step: 1
Training loss: 2.5190599577379476
Validation loss: 2.714542882700391

Epoch: 5| Step: 2
Training loss: 2.2391289775001484
Validation loss: 2.6740535049432816

Epoch: 5| Step: 3
Training loss: 2.2841983711225513
Validation loss: 2.7140098992731514

Epoch: 5| Step: 4
Training loss: 1.9154910614832725
Validation loss: 2.718742768873632

Epoch: 5| Step: 5
Training loss: 3.077450596082037
Validation loss: 2.712190710327297

Epoch: 5| Step: 6
Training loss: 2.917676714437901
Validation loss: 2.6898781988335054

Epoch: 5| Step: 7
Training loss: 1.9555564089554072
Validation loss: 2.654068694459858

Epoch: 5| Step: 8
Training loss: 2.187889500409794
Validation loss: 2.7552146418787093

Epoch: 5| Step: 9
Training loss: 1.9962405992452597
Validation loss: 2.676550505389112

Epoch: 5| Step: 10
Training loss: 2.599027664595082
Validation loss: 2.715765645138686

Epoch: 5| Step: 11
Training loss: 4.143969757558867
Validation loss: 2.6869194490456803

Epoch: 50| Step: 0
Training loss: 3.1156438002406546
Validation loss: 2.706505277103852

Epoch: 5| Step: 1
Training loss: 2.750305678978216
Validation loss: 2.7218917437394987

Epoch: 5| Step: 2
Training loss: 1.672671547204615
Validation loss: 2.65027764158501

Epoch: 5| Step: 3
Training loss: 2.541248777044915
Validation loss: 2.696663621978157

Epoch: 5| Step: 4
Training loss: 2.5628414391785155
Validation loss: 2.752500275257592

Epoch: 5| Step: 5
Training loss: 2.9129212627357353
Validation loss: 2.7601741444316903

Epoch: 5| Step: 6
Training loss: 1.8155551023701901
Validation loss: 2.717318325977029

Epoch: 5| Step: 7
Training loss: 2.1237412258638275
Validation loss: 2.7512084047130245

Epoch: 5| Step: 8
Training loss: 2.222595535816744
Validation loss: 2.686573112691356

Epoch: 5| Step: 9
Training loss: 1.7776233495092082
Validation loss: 2.632348163986196

Epoch: 5| Step: 10
Training loss: 3.0279982911360843
Validation loss: 2.664307598872493

Epoch: 5| Step: 11
Training loss: 1.4811694417044468
Validation loss: 2.712338780740796

Epoch: 51| Step: 0
Training loss: 2.8379175089056967
Validation loss: 2.6813445940796883

Epoch: 5| Step: 1
Training loss: 2.577234287718426
Validation loss: 2.708778210316873

Epoch: 5| Step: 2
Training loss: 2.424559846239735
Validation loss: 2.6858960547734583

Epoch: 5| Step: 3
Training loss: 2.271485004769367
Validation loss: 2.6461958611797125

Epoch: 5| Step: 4
Training loss: 2.8412944546203662
Validation loss: 2.712403515741946

Epoch: 5| Step: 5
Training loss: 2.123700922892345
Validation loss: 2.6926033484076575

Epoch: 5| Step: 6
Training loss: 2.2579203121223688
Validation loss: 2.6378194701354962

Epoch: 5| Step: 7
Training loss: 2.914813152102536
Validation loss: 2.7039567296238207

Epoch: 5| Step: 8
Training loss: 1.7053128809523896
Validation loss: 2.644194919191992

Epoch: 5| Step: 9
Training loss: 2.579904577871129
Validation loss: 2.7184289179949066

Epoch: 5| Step: 10
Training loss: 1.9501831482196055
Validation loss: 2.722014772583421

Epoch: 5| Step: 11
Training loss: 1.7836922750776354
Validation loss: 2.6541223980931252

Epoch: 52| Step: 0
Training loss: 3.025972471688079
Validation loss: 2.6143678573837916

Epoch: 5| Step: 1
Training loss: 2.3946896573763508
Validation loss: 2.7765133917964326

Epoch: 5| Step: 2
Training loss: 2.4535113959723147
Validation loss: 2.632778061849997

Epoch: 5| Step: 3
Training loss: 1.9156664920065813
Validation loss: 2.811381605094677

Epoch: 5| Step: 4
Training loss: 3.0469435464044268
Validation loss: 2.7993455414337385

Epoch: 5| Step: 5
Training loss: 2.3754893350941906
Validation loss: 2.8050300969783146

Epoch: 5| Step: 6
Training loss: 2.0487269984799186
Validation loss: 2.73240855761126

Epoch: 5| Step: 7
Training loss: 1.9458873466275948
Validation loss: 2.7223348514510928

Epoch: 5| Step: 8
Training loss: 2.6129031513659227
Validation loss: 2.7143716122574424

Epoch: 5| Step: 9
Training loss: 2.301968279649017
Validation loss: 2.693571685839909

Epoch: 5| Step: 10
Training loss: 2.5531515467931656
Validation loss: 2.652676366251261

Epoch: 5| Step: 11
Training loss: 2.2137983704359954
Validation loss: 2.7025097898446524

Epoch: 53| Step: 0
Training loss: 2.680822282301355
Validation loss: 2.6972627743340634

Epoch: 5| Step: 1
Training loss: 2.918472512101843
Validation loss: 2.6376513491952744

Epoch: 5| Step: 2
Training loss: 2.1362856577692453
Validation loss: 2.652401548494644

Epoch: 5| Step: 3
Training loss: 2.438502765678197
Validation loss: 2.641410996572808

Epoch: 5| Step: 4
Training loss: 2.409638731063124
Validation loss: 2.69007418684427

Epoch: 5| Step: 5
Training loss: 2.1276020499833286
Validation loss: 2.696890287182837

Epoch: 5| Step: 6
Training loss: 2.083814705231376
Validation loss: 2.736478476032132

Epoch: 5| Step: 7
Training loss: 2.2882347302772867
Validation loss: 2.6551416777580905

Epoch: 5| Step: 8
Training loss: 2.9075250597305993
Validation loss: 2.719672685930776

Epoch: 5| Step: 9
Training loss: 2.34208111155559
Validation loss: 2.7057968855685104

Epoch: 5| Step: 10
Training loss: 2.14147186234448
Validation loss: 2.6941068154823697

Epoch: 5| Step: 11
Training loss: 3.023490333588359
Validation loss: 2.739996753195303

Epoch: 54| Step: 0
Training loss: 2.296421239756873
Validation loss: 2.6677854036525996

Epoch: 5| Step: 1
Training loss: 2.4784371293716623
Validation loss: 2.6630440272581994

Epoch: 5| Step: 2
Training loss: 2.5940854878217565
Validation loss: 2.7258085540135784

Epoch: 5| Step: 3
Training loss: 2.0812696026402997
Validation loss: 2.6802319751106487

Epoch: 5| Step: 4
Training loss: 2.305592504713382
Validation loss: 2.781505094395188

Epoch: 5| Step: 5
Training loss: 2.5011483416089897
Validation loss: 2.7098456867443295

Epoch: 5| Step: 6
Training loss: 2.3857657719873973
Validation loss: 2.6810684204861435

Epoch: 5| Step: 7
Training loss: 3.010860335623744
Validation loss: 2.675240269384597

Epoch: 5| Step: 8
Training loss: 2.178762697761727
Validation loss: 2.6292078564093

Epoch: 5| Step: 9
Training loss: 2.359744011524716
Validation loss: 2.74630055704694

Epoch: 5| Step: 10
Training loss: 1.951282517176272
Validation loss: 2.740123693071168

Epoch: 5| Step: 11
Training loss: 2.3602081242618294
Validation loss: 2.701916523732797

Epoch: 55| Step: 0
Training loss: 2.1659144660848804
Validation loss: 2.6391313794190734

Epoch: 5| Step: 1
Training loss: 1.8754778570964539
Validation loss: 2.7600953448914844

Epoch: 5| Step: 2
Training loss: 2.5293536205627722
Validation loss: 2.7453443174738394

Epoch: 5| Step: 3
Training loss: 2.3491647859394202
Validation loss: 2.652736080481638

Epoch: 5| Step: 4
Training loss: 2.637281298496598
Validation loss: 2.746993203815056

Epoch: 5| Step: 5
Training loss: 2.6101425777968954
Validation loss: 2.771904958041986

Epoch: 5| Step: 6
Training loss: 2.3246394954647296
Validation loss: 2.7546943240370587

Epoch: 5| Step: 7
Training loss: 3.030682225488527
Validation loss: 2.572253247238266

Epoch: 5| Step: 8
Training loss: 2.2018275126464326
Validation loss: 2.674058078103769

Epoch: 5| Step: 9
Training loss: 2.0964682854023806
Validation loss: 2.645701391329447

Epoch: 5| Step: 10
Training loss: 2.5147425839475672
Validation loss: 2.6427000684437254

Epoch: 5| Step: 11
Training loss: 0.5403805251623306
Validation loss: 2.657162838580309

Epoch: 56| Step: 0
Training loss: 2.7427637956408093
Validation loss: 2.7223571401419773

Epoch: 5| Step: 1
Training loss: 1.450011250024759
Validation loss: 2.6989108479095387

Epoch: 5| Step: 2
Training loss: 2.8431597086527254
Validation loss: 2.7424440291091035

Epoch: 5| Step: 3
Training loss: 2.17448060422077
Validation loss: 2.6957410683582843

Epoch: 5| Step: 4
Training loss: 1.9359598498713038
Validation loss: 2.6456175263068955

Epoch: 5| Step: 5
Training loss: 2.461275398429453
Validation loss: 2.7743124750236974

Epoch: 5| Step: 6
Training loss: 2.2178862058860283
Validation loss: 2.751699782063852

Epoch: 5| Step: 7
Training loss: 2.5005205566134885
Validation loss: 2.7115939918393073

Epoch: 5| Step: 8
Training loss: 2.5112236804636763
Validation loss: 2.753682210840811

Epoch: 5| Step: 9
Training loss: 2.7830777109901472
Validation loss: 2.7477468486329695

Epoch: 5| Step: 10
Training loss: 2.113139318752207
Validation loss: 2.7722261711711274

Epoch: 5| Step: 11
Training loss: 1.3736021999862507
Validation loss: 2.6915977051899227

Epoch: 57| Step: 0
Training loss: 1.7485937190215628
Validation loss: 2.6559609349357656

Epoch: 5| Step: 1
Training loss: 2.5265631907502826
Validation loss: 2.705904008040074

Epoch: 5| Step: 2
Training loss: 2.164307177651689
Validation loss: 2.7989990295775544

Epoch: 5| Step: 3
Training loss: 2.508436273973963
Validation loss: 2.681075108507034

Epoch: 5| Step: 4
Training loss: 2.2558481719824632
Validation loss: 2.7131235541288796

Epoch: 5| Step: 5
Training loss: 2.5033087768907967
Validation loss: 2.632082104892232

Epoch: 5| Step: 6
Training loss: 2.430617470331121
Validation loss: 2.6463617425449892

Epoch: 5| Step: 7
Training loss: 2.4114739326208694
Validation loss: 2.7222288900951113

Epoch: 5| Step: 8
Training loss: 1.8252262053674027
Validation loss: 2.6024035258066784

Epoch: 5| Step: 9
Training loss: 2.3758892603026935
Validation loss: 2.651387217746335

Epoch: 5| Step: 10
Training loss: 3.0204568211728064
Validation loss: 2.6469424631347973

Epoch: 5| Step: 11
Training loss: 2.101485013419605
Validation loss: 2.733266838406601

Epoch: 58| Step: 0
Training loss: 2.0034099358349495
Validation loss: 2.7589018762078568

Epoch: 5| Step: 1
Training loss: 2.6661825833424286
Validation loss: 2.7094315661927624

Epoch: 5| Step: 2
Training loss: 2.3026756686815317
Validation loss: 2.678649145088816

Epoch: 5| Step: 3
Training loss: 2.5953411139760196
Validation loss: 2.669890174035695

Epoch: 5| Step: 4
Training loss: 2.577737120146951
Validation loss: 2.6612336772503533

Epoch: 5| Step: 5
Training loss: 1.8510892883025478
Validation loss: 2.703315937597355

Epoch: 5| Step: 6
Training loss: 2.6245352015664554
Validation loss: 2.696557911796644

Epoch: 5| Step: 7
Training loss: 2.907443714072637
Validation loss: 2.6946458775371793

Epoch: 5| Step: 8
Training loss: 1.607860630453106
Validation loss: 2.7255863457131246

Epoch: 5| Step: 9
Training loss: 2.189124893508235
Validation loss: 2.723063164418169

Epoch: 5| Step: 10
Training loss: 2.32084726663878
Validation loss: 2.7188635835269785

Epoch: 5| Step: 11
Training loss: 2.919828789799697
Validation loss: 2.742481563700881

Epoch: 59| Step: 0
Training loss: 1.6927762374951603
Validation loss: 2.7278658858533618

Epoch: 5| Step: 1
Training loss: 2.951343301657861
Validation loss: 2.758233294925049

Epoch: 5| Step: 2
Training loss: 2.6896322796005023
Validation loss: 2.660601861930937

Epoch: 5| Step: 3
Training loss: 2.5526598428412655
Validation loss: 2.739887276289143

Epoch: 5| Step: 4
Training loss: 2.5443692664969904
Validation loss: 2.7646693609881634

Epoch: 5| Step: 5
Training loss: 1.9022232424813998
Validation loss: 2.860183778623565

Epoch: 5| Step: 6
Training loss: 2.700627932115449
Validation loss: 2.8114161451598756

Epoch: 5| Step: 7
Training loss: 2.6928195204858545
Validation loss: 2.7388327710231897

Epoch: 5| Step: 8
Training loss: 2.2704042735128795
Validation loss: 2.708454823825694

Epoch: 5| Step: 9
Training loss: 2.033048801630096
Validation loss: 2.7589003278862423

Epoch: 5| Step: 10
Training loss: 1.684790661539786
Validation loss: 2.66716345366693

Epoch: 5| Step: 11
Training loss: 3.042941640554387
Validation loss: 2.722283402120913

Epoch: 60| Step: 0
Training loss: 2.5305598695701716
Validation loss: 2.750678430304272

Epoch: 5| Step: 1
Training loss: 2.2715755847780232
Validation loss: 2.624364151465498

Epoch: 5| Step: 2
Training loss: 2.333757384686466
Validation loss: 2.7134681308518047

Epoch: 5| Step: 3
Training loss: 2.083299776442798
Validation loss: 2.6005636097981752

Epoch: 5| Step: 4
Training loss: 2.322588898894469
Validation loss: 2.622061878950881

Epoch: 5| Step: 5
Training loss: 2.4090401462552533
Validation loss: 2.727193750215708

Epoch: 5| Step: 6
Training loss: 2.455346334854713
Validation loss: 2.664501161528654

Epoch: 5| Step: 7
Training loss: 2.4472230510250808
Validation loss: 2.6483651810546243

Epoch: 5| Step: 8
Training loss: 2.2988164053904216
Validation loss: 2.6197275655701833

Epoch: 5| Step: 9
Training loss: 2.7324122768885215
Validation loss: 2.7607503629315335

Epoch: 5| Step: 10
Training loss: 2.6291263482518334
Validation loss: 2.770316704411408

Epoch: 5| Step: 11
Training loss: 1.8324952666467422
Validation loss: 2.6949589925947715

Epoch: 61| Step: 0
Training loss: 2.576534451065395
Validation loss: 2.714337612330569

Epoch: 5| Step: 1
Training loss: 2.4333298051712724
Validation loss: 2.6795884087186814

Epoch: 5| Step: 2
Training loss: 2.2337644583175997
Validation loss: 2.5762981145747155

Epoch: 5| Step: 3
Training loss: 2.6020599897654426
Validation loss: 2.7458788704943187

Epoch: 5| Step: 4
Training loss: 1.9523576373415024
Validation loss: 2.693280770987704

Epoch: 5| Step: 5
Training loss: 2.0082335271873233
Validation loss: 2.667969252668699

Epoch: 5| Step: 6
Training loss: 2.318478665580925
Validation loss: 2.690788884770927

Epoch: 5| Step: 7
Training loss: 2.559340320021498
Validation loss: 2.6335522662267516

Epoch: 5| Step: 8
Training loss: 2.4296661081629636
Validation loss: 2.639027938330377

Epoch: 5| Step: 9
Training loss: 2.0429119153258952
Validation loss: 2.7477813209208852

Epoch: 5| Step: 10
Training loss: 2.641115944272668
Validation loss: 2.6876180571123744

Epoch: 5| Step: 11
Training loss: 2.121053396722786
Validation loss: 2.6164661419220376

Epoch: 62| Step: 0
Training loss: 2.3600432605334496
Validation loss: 2.6002975496873124

Epoch: 5| Step: 1
Training loss: 2.3208276452954193
Validation loss: 2.7002035976694394

Epoch: 5| Step: 2
Training loss: 2.5366625902675337
Validation loss: 2.5846011232395942

Epoch: 5| Step: 3
Training loss: 2.1718304307055765
Validation loss: 2.616649610368655

Epoch: 5| Step: 4
Training loss: 2.4462034899579033
Validation loss: 2.6246811468749445

Epoch: 5| Step: 5
Training loss: 2.6914476189389127
Validation loss: 2.754169096250708

Epoch: 5| Step: 6
Training loss: 2.2482040443130873
Validation loss: 2.708850053254676

Epoch: 5| Step: 7
Training loss: 2.6391554134583886
Validation loss: 2.6568970696175698

Epoch: 5| Step: 8
Training loss: 2.319658386302666
Validation loss: 2.663169002508141

Epoch: 5| Step: 9
Training loss: 2.313282499148757
Validation loss: 2.6701782594602195

Epoch: 5| Step: 10
Training loss: 2.456802139152855
Validation loss: 2.6988408789823595

Epoch: 5| Step: 11
Training loss: 2.7871569366781004
Validation loss: 2.7044318830765564

Epoch: 63| Step: 0
Training loss: 2.4663198558041968
Validation loss: 2.7047777654114356

Epoch: 5| Step: 1
Training loss: 2.403196602140328
Validation loss: 2.7099461350595164

Epoch: 5| Step: 2
Training loss: 2.1805704714298004
Validation loss: 2.688016960044179

Epoch: 5| Step: 3
Training loss: 2.1902067604181457
Validation loss: 2.618826839530577

Epoch: 5| Step: 4
Training loss: 2.3846980404786464
Validation loss: 2.7717400491828945

Epoch: 5| Step: 5
Training loss: 2.7691935991172754
Validation loss: 2.679275240015706

Epoch: 5| Step: 6
Training loss: 2.360475094221643
Validation loss: 2.644521148827634

Epoch: 5| Step: 7
Training loss: 2.4791141686103604
Validation loss: 2.6932104750524193

Epoch: 5| Step: 8
Training loss: 2.6369312342045137
Validation loss: 2.6268545857871466

Epoch: 5| Step: 9
Training loss: 1.9295054361425463
Validation loss: 2.7095666437008035

Epoch: 5| Step: 10
Training loss: 2.089582936777196
Validation loss: 2.713544747954295

Epoch: 5| Step: 11
Training loss: 3.2009026982714217
Validation loss: 2.6576978066299146

Epoch: 64| Step: 0
Training loss: 2.095518248012335
Validation loss: 2.689095138331044

Epoch: 5| Step: 1
Training loss: 2.4542251355428206
Validation loss: 2.653853505961477

Epoch: 5| Step: 2
Training loss: 3.027133939302093
Validation loss: 2.7754439890861082

Epoch: 5| Step: 3
Training loss: 3.1233268836520387
Validation loss: 2.8266313746552

Epoch: 5| Step: 4
Training loss: 2.228424364606794
Validation loss: 2.8076102135613112

Epoch: 5| Step: 5
Training loss: 2.070079747198045
Validation loss: 2.821436674702524

Epoch: 5| Step: 6
Training loss: 2.2922716787076367
Validation loss: 2.7497807870537843

Epoch: 5| Step: 7
Training loss: 2.450078542579223
Validation loss: 2.757712862197843

Epoch: 5| Step: 8
Training loss: 2.126587443096852
Validation loss: 2.731114498068128

Epoch: 5| Step: 9
Training loss: 2.24978043226627
Validation loss: 2.615378602096138

Epoch: 5| Step: 10
Training loss: 2.1593146176321603
Validation loss: 2.7182590764866976

Epoch: 5| Step: 11
Training loss: 1.7017402268867854
Validation loss: 2.6897280794213607

Epoch: 65| Step: 0
Training loss: 2.8552919012117637
Validation loss: 2.6979382279662447

Epoch: 5| Step: 1
Training loss: 1.4656960411179156
Validation loss: 2.685165383726007

Epoch: 5| Step: 2
Training loss: 2.4415603466993616
Validation loss: 2.682876439222229

Epoch: 5| Step: 3
Training loss: 2.76666852154344
Validation loss: 2.600197602979278

Epoch: 5| Step: 4
Training loss: 2.245595860237788
Validation loss: 2.688540937228266

Epoch: 5| Step: 5
Training loss: 2.396052762362894
Validation loss: 2.7142691903041576

Epoch: 5| Step: 6
Training loss: 2.259821858938656
Validation loss: 2.705418864800129

Epoch: 5| Step: 7
Training loss: 2.429146366023653
Validation loss: 2.6239996510203545

Epoch: 5| Step: 8
Training loss: 1.9686893272133468
Validation loss: 2.6573225922518984

Epoch: 5| Step: 9
Training loss: 2.7193897415424386
Validation loss: 2.6441006631565114

Epoch: 5| Step: 10
Training loss: 2.02904167443085
Validation loss: 2.637031856831462

Epoch: 5| Step: 11
Training loss: 1.3569968456942865
Validation loss: 2.6661484383651506

Epoch: 66| Step: 0
Training loss: 2.2366136127135783
Validation loss: 2.7015745608000064

Epoch: 5| Step: 1
Training loss: 1.9023235092809563
Validation loss: 2.6855199343168104

Epoch: 5| Step: 2
Training loss: 1.9827248027096522
Validation loss: 2.658127887603772

Epoch: 5| Step: 3
Training loss: 1.9995312141334391
Validation loss: 2.6510017232127843

Epoch: 5| Step: 4
Training loss: 2.7011553694192476
Validation loss: 2.6711848224571817

Epoch: 5| Step: 5
Training loss: 2.5362923402669164
Validation loss: 2.5774888573537353

Epoch: 5| Step: 6
Training loss: 2.2096463264790946
Validation loss: 2.573499306000465

Epoch: 5| Step: 7
Training loss: 2.77941559720955
Validation loss: 2.6449243881580973

Epoch: 5| Step: 8
Training loss: 1.9048407927139628
Validation loss: 2.628747769964158

Epoch: 5| Step: 9
Training loss: 2.3518821524400546
Validation loss: 2.737808520497025

Epoch: 5| Step: 10
Training loss: 2.785180475629871
Validation loss: 2.6786406189444176

Epoch: 5| Step: 11
Training loss: 1.97283850101792
Validation loss: 2.694555067438422

Epoch: 67| Step: 0
Training loss: 2.1650130735359414
Validation loss: 2.6738630189887425

Epoch: 5| Step: 1
Training loss: 2.1595391880444557
Validation loss: 2.6609414538721654

Epoch: 5| Step: 2
Training loss: 2.2489295108344654
Validation loss: 2.586493360354184

Epoch: 5| Step: 3
Training loss: 1.6363867375159264
Validation loss: 2.697319783397422

Epoch: 5| Step: 4
Training loss: 1.8385600736595353
Validation loss: 2.611416396991322

Epoch: 5| Step: 5
Training loss: 2.2964678552704645
Validation loss: 2.619504853481654

Epoch: 5| Step: 6
Training loss: 2.441543453175949
Validation loss: 2.6928947108764336

Epoch: 5| Step: 7
Training loss: 2.4631893451748903
Validation loss: 2.6225636051963206

Epoch: 5| Step: 8
Training loss: 2.4336738879386597
Validation loss: 2.6881823338893573

Epoch: 5| Step: 9
Training loss: 2.676486313643614
Validation loss: 2.656980485140493

Epoch: 5| Step: 10
Training loss: 2.604267352383005
Validation loss: 2.6748710513601344

Epoch: 5| Step: 11
Training loss: 1.7946819688863542
Validation loss: 2.628287958270722

Epoch: 68| Step: 0
Training loss: 2.4193456424005113
Validation loss: 2.659483676606901

Epoch: 5| Step: 1
Training loss: 1.6654798891793878
Validation loss: 2.7699467392619908

Epoch: 5| Step: 2
Training loss: 2.426863915562767
Validation loss: 2.7249400896375224

Epoch: 5| Step: 3
Training loss: 2.605511391904147
Validation loss: 2.741489082361301

Epoch: 5| Step: 4
Training loss: 2.611231526062489
Validation loss: 2.771440849293974

Epoch: 5| Step: 5
Training loss: 2.4674581696927205
Validation loss: 2.7719148315469333

Epoch: 5| Step: 6
Training loss: 2.3516451292000213
Validation loss: 2.7207233604377863

Epoch: 5| Step: 7
Training loss: 2.26553681300623
Validation loss: 2.7300383338169834

Epoch: 5| Step: 8
Training loss: 2.3618899450866495
Validation loss: 2.5929102112637974

Epoch: 5| Step: 9
Training loss: 1.951955582527658
Validation loss: 2.6161428463798746

Epoch: 5| Step: 10
Training loss: 2.7085645332444104
Validation loss: 2.613139503637655

Epoch: 5| Step: 11
Training loss: 2.1803358200814107
Validation loss: 2.6818254096446137

Epoch: 69| Step: 0
Training loss: 1.4260286299465113
Validation loss: 2.7301047414032658

Epoch: 5| Step: 1
Training loss: 2.629728327596851
Validation loss: 2.740587504937647

Epoch: 5| Step: 2
Training loss: 2.1976890867989285
Validation loss: 2.754670645319108

Epoch: 5| Step: 3
Training loss: 2.0534592354970536
Validation loss: 2.6130564221812502

Epoch: 5| Step: 4
Training loss: 2.4494028219992163
Validation loss: 2.6137349334104982

Epoch: 5| Step: 5
Training loss: 2.3416492456985036
Validation loss: 2.660828108302035

Epoch: 5| Step: 6
Training loss: 2.2530469396774975
Validation loss: 2.6205612111593877

Epoch: 5| Step: 7
Training loss: 2.348080512633891
Validation loss: 2.6382183661255927

Epoch: 5| Step: 8
Training loss: 3.0422569294409447
Validation loss: 2.60331785991953

Epoch: 5| Step: 9
Training loss: 2.355460652452914
Validation loss: 2.689073349736676

Epoch: 5| Step: 10
Training loss: 1.7284218283166763
Validation loss: 2.6296490512121613

Epoch: 5| Step: 11
Training loss: 2.786389862835494
Validation loss: 2.6772102976475813

Epoch: 70| Step: 0
Training loss: 1.8625421557680082
Validation loss: 2.648786613687762

Epoch: 5| Step: 1
Training loss: 2.1666910341310857
Validation loss: 2.695553522805234

Epoch: 5| Step: 2
Training loss: 2.3240117341498747
Validation loss: 2.6587398845735453

Epoch: 5| Step: 3
Training loss: 2.5763423420784797
Validation loss: 2.762553706157714

Epoch: 5| Step: 4
Training loss: 2.106117049642406
Validation loss: 2.6079256749722575

Epoch: 5| Step: 5
Training loss: 2.2255615125908528
Validation loss: 2.59971000921794

Epoch: 5| Step: 6
Training loss: 2.2636118396239757
Validation loss: 2.6641352169072623

Epoch: 5| Step: 7
Training loss: 1.7841587075856675
Validation loss: 2.6080728887341187

Epoch: 5| Step: 8
Training loss: 2.1886839796007633
Validation loss: 2.5930394497778564

Epoch: 5| Step: 9
Training loss: 2.858675678389612
Validation loss: 2.7215899911332215

Epoch: 5| Step: 10
Training loss: 1.9004002852160047
Validation loss: 2.6423905055321115

Epoch: 5| Step: 11
Training loss: 2.2691299162415155
Validation loss: 2.7220347647015335

Epoch: 71| Step: 0
Training loss: 2.3344005006268014
Validation loss: 2.7303794296855797

Epoch: 5| Step: 1
Training loss: 2.173883182071758
Validation loss: 2.673816347432954

Epoch: 5| Step: 2
Training loss: 2.429103965233595
Validation loss: 2.5993636024899685

Epoch: 5| Step: 3
Training loss: 1.9855061708698811
Validation loss: 2.7122278376541815

Epoch: 5| Step: 4
Training loss: 2.6736858990490417
Validation loss: 2.7064211599656027

Epoch: 5| Step: 5
Training loss: 2.6832949542821463
Validation loss: 2.683451501147794

Epoch: 5| Step: 6
Training loss: 1.6988976186089069
Validation loss: 2.690957300014892

Epoch: 5| Step: 7
Training loss: 1.7050788940567783
Validation loss: 2.668882629574084

Epoch: 5| Step: 8
Training loss: 2.3431512703673176
Validation loss: 2.6592547494467484

Epoch: 5| Step: 9
Training loss: 1.9775044605383256
Validation loss: 2.57577681675565

Epoch: 5| Step: 10
Training loss: 3.203490148060884
Validation loss: 2.763284835403269

Epoch: 5| Step: 11
Training loss: 0.9176588468743851
Validation loss: 2.651643981910489

Epoch: 72| Step: 0
Training loss: 2.09346814891783
Validation loss: 2.631611841742821

Epoch: 5| Step: 1
Training loss: 2.7304536439753364
Validation loss: 2.5955203938993185

Epoch: 5| Step: 2
Training loss: 2.631502363194835
Validation loss: 2.6169345980243492

Epoch: 5| Step: 3
Training loss: 1.98923036596646
Validation loss: 2.6364966367252416

Epoch: 5| Step: 4
Training loss: 1.6757266162422833
Validation loss: 2.66490912758451

Epoch: 5| Step: 5
Training loss: 2.628197493670303
Validation loss: 2.707464898088244

Epoch: 5| Step: 6
Training loss: 2.248739631293896
Validation loss: 2.6523081103380397

Epoch: 5| Step: 7
Training loss: 2.3291010506747343
Validation loss: 2.6325670990116463

Epoch: 5| Step: 8
Training loss: 2.020657194136556
Validation loss: 2.6654221820928288

Epoch: 5| Step: 9
Training loss: 1.9769396516332893
Validation loss: 2.672419851271128

Epoch: 5| Step: 10
Training loss: 2.903072958686121
Validation loss: 2.5922745180920663

Epoch: 5| Step: 11
Training loss: 1.9373679577533143
Validation loss: 2.657201349768984

Epoch: 73| Step: 0
Training loss: 2.48199713770281
Validation loss: 2.6423326497181927

Epoch: 5| Step: 1
Training loss: 1.999738318490133
Validation loss: 2.603805148144555

Epoch: 5| Step: 2
Training loss: 2.743329106679498
Validation loss: 2.71368784641925

Epoch: 5| Step: 3
Training loss: 1.9303667980954315
Validation loss: 2.5703304332660233

Epoch: 5| Step: 4
Training loss: 1.7038898675368017
Validation loss: 2.587619806670366

Epoch: 5| Step: 5
Training loss: 2.6078949345564246
Validation loss: 2.665892381812084

Epoch: 5| Step: 6
Training loss: 2.201467553413611
Validation loss: 2.672494177061089

Epoch: 5| Step: 7
Training loss: 2.0965710893001015
Validation loss: 2.703699772977137

Epoch: 5| Step: 8
Training loss: 2.5783929858944066
Validation loss: 2.6458225675549087

Epoch: 5| Step: 9
Training loss: 2.1093613235595408
Validation loss: 2.6646472889430486

Epoch: 5| Step: 10
Training loss: 1.8539858383411485
Validation loss: 2.688630062385759

Epoch: 5| Step: 11
Training loss: 1.9243738320258208
Validation loss: 2.6914375738896537

Epoch: 74| Step: 0
Training loss: 1.739596368737026
Validation loss: 2.709150515052228

Epoch: 5| Step: 1
Training loss: 2.7874073064471423
Validation loss: 2.6684288756341408

Epoch: 5| Step: 2
Training loss: 2.1464433883072163
Validation loss: 2.5964521901646878

Epoch: 5| Step: 3
Training loss: 2.020820014621327
Validation loss: 2.7065614711957866

Epoch: 5| Step: 4
Training loss: 2.5211427251777225
Validation loss: 2.6730253446273897

Epoch: 5| Step: 5
Training loss: 2.2004032502370023
Validation loss: 2.7232297806816392

Epoch: 5| Step: 6
Training loss: 1.7441085009377177
Validation loss: 2.720965122479772

Epoch: 5| Step: 7
Training loss: 2.2112219529774912
Validation loss: 2.6522066327151013

Epoch: 5| Step: 8
Training loss: 2.226891637199836
Validation loss: 2.564562541237987

Epoch: 5| Step: 9
Training loss: 2.733274576284423
Validation loss: 2.696015506781856

Epoch: 5| Step: 10
Training loss: 2.150578988649261
Validation loss: 2.70142972850465

Epoch: 5| Step: 11
Training loss: 2.9007700456792773
Validation loss: 2.6455074031956722

Epoch: 75| Step: 0
Training loss: 1.9484417729457082
Validation loss: 2.5984504996055047

Epoch: 5| Step: 1
Training loss: 2.004084826389224
Validation loss: 2.6973717714896104

Epoch: 5| Step: 2
Training loss: 1.8705256800312504
Validation loss: 2.7363206644113083

Epoch: 5| Step: 3
Training loss: 1.962216450319241
Validation loss: 2.800724310941255

Epoch: 5| Step: 4
Training loss: 1.9747053626753188
Validation loss: 2.875415495550867

Epoch: 5| Step: 5
Training loss: 2.401434997867049
Validation loss: 2.851504721556974

Epoch: 5| Step: 6
Training loss: 2.3706304609747217
Validation loss: 2.8675890995562705

Epoch: 5| Step: 7
Training loss: 2.210172163527457
Validation loss: 3.029622070120115

Epoch: 5| Step: 8
Training loss: 2.8033490826061915
Validation loss: 2.7855750540812685

Epoch: 5| Step: 9
Training loss: 2.524561014823353
Validation loss: 2.7017759878227037

Epoch: 5| Step: 10
Training loss: 2.7087639881964614
Validation loss: 2.650579241059543

Epoch: 5| Step: 11
Training loss: 2.1077723313357706
Validation loss: 2.7160553897320687

Epoch: 76| Step: 0
Training loss: 2.4800122419178208
Validation loss: 2.7651910279733913

Epoch: 5| Step: 1
Training loss: 2.705843049566386
Validation loss: 2.7839398645973414

Epoch: 5| Step: 2
Training loss: 2.154233902177697
Validation loss: 2.956154942479603

Epoch: 5| Step: 3
Training loss: 1.6672517544234806
Validation loss: 3.002636168486662

Epoch: 5| Step: 4
Training loss: 2.8954006027264265
Validation loss: 2.9533625478587617

Epoch: 5| Step: 5
Training loss: 2.7148961782538774
Validation loss: 2.911733704148057

Epoch: 5| Step: 6
Training loss: 2.4520074522020314
Validation loss: 2.8107590797377413

Epoch: 5| Step: 7
Training loss: 2.415096518283887
Validation loss: 2.6960440780793546

Epoch: 5| Step: 8
Training loss: 2.7611836261637905
Validation loss: 2.6364944023479473

Epoch: 5| Step: 9
Training loss: 2.1527063856968556
Validation loss: 2.6368839805542326

Epoch: 5| Step: 10
Training loss: 2.319080166818171
Validation loss: 2.686891830739461

Epoch: 5| Step: 11
Training loss: 1.7864755642637338
Validation loss: 2.7115402247904767

Epoch: 77| Step: 0
Training loss: 2.276497056972144
Validation loss: 2.8266434872455855

Epoch: 5| Step: 1
Training loss: 3.2170319647892196
Validation loss: 2.919617401204836

Epoch: 5| Step: 2
Training loss: 2.472847351114019
Validation loss: 2.883684007638887

Epoch: 5| Step: 3
Training loss: 2.2328523369365993
Validation loss: 2.8657369833738824

Epoch: 5| Step: 4
Training loss: 2.6635479472094623
Validation loss: 2.7543567045576673

Epoch: 5| Step: 5
Training loss: 2.5939828239642853
Validation loss: 2.7041925442774555

Epoch: 5| Step: 6
Training loss: 1.8561759805531561
Validation loss: 2.6870185287697073

Epoch: 5| Step: 7
Training loss: 1.9196939886133448
Validation loss: 2.6520860534638038

Epoch: 5| Step: 8
Training loss: 2.3171477136263703
Validation loss: 2.6335684259917755

Epoch: 5| Step: 9
Training loss: 1.6212137568532277
Validation loss: 2.6272868609765716

Epoch: 5| Step: 10
Training loss: 2.1266076233818225
Validation loss: 2.624355581444449

Epoch: 5| Step: 11
Training loss: 3.0859679401683002
Validation loss: 2.671817619049635

Epoch: 78| Step: 0
Training loss: 2.76369076779651
Validation loss: 2.630289791595762

Epoch: 5| Step: 1
Training loss: 2.632531668969751
Validation loss: 2.571148766286708

Epoch: 5| Step: 2
Training loss: 2.2501056434413758
Validation loss: 2.6190785346848737

Epoch: 5| Step: 3
Training loss: 1.6067444867694927
Validation loss: 2.6598050207248676

Epoch: 5| Step: 4
Training loss: 2.021238332324303
Validation loss: 2.693262044518681

Epoch: 5| Step: 5
Training loss: 2.0153367183849102
Validation loss: 2.6475483687487844

Epoch: 5| Step: 6
Training loss: 2.2809233758240577
Validation loss: 2.6306387193521

Epoch: 5| Step: 7
Training loss: 2.2467367031526986
Validation loss: 2.620964937792304

Epoch: 5| Step: 8
Training loss: 2.473044703917514
Validation loss: 2.64829159225001

Epoch: 5| Step: 9
Training loss: 2.0277770650621436
Validation loss: 2.6431997225519868

Epoch: 5| Step: 10
Training loss: 2.0523814906152364
Validation loss: 2.706950070410277

Epoch: 5| Step: 11
Training loss: 1.5373842025197302
Validation loss: 2.69514029869596

Epoch: 79| Step: 0
Training loss: 2.9141362976056815
Validation loss: 2.5953389360312835

Epoch: 5| Step: 1
Training loss: 1.8881690096532389
Validation loss: 2.6826569107904783

Epoch: 5| Step: 2
Training loss: 1.999404997533513
Validation loss: 2.7231413027433176

Epoch: 5| Step: 3
Training loss: 2.4518816281320723
Validation loss: 2.758065043729223

Epoch: 5| Step: 4
Training loss: 2.3778556921880467
Validation loss: 2.70677381633638

Epoch: 5| Step: 5
Training loss: 2.3758617644636506
Validation loss: 2.598412803674761

Epoch: 5| Step: 6
Training loss: 2.069944989675915
Validation loss: 2.730841302445857

Epoch: 5| Step: 7
Training loss: 1.9028867224747132
Validation loss: 2.683909394396609

Epoch: 5| Step: 8
Training loss: 2.1542159728476897
Validation loss: 2.7321509335324605

Epoch: 5| Step: 9
Training loss: 1.8617043530239266
Validation loss: 2.6897887420126265

Epoch: 5| Step: 10
Training loss: 1.8661759321841231
Validation loss: 2.6431414766595633

Epoch: 5| Step: 11
Training loss: 2.9959775660939263
Validation loss: 2.6448390374004855

Epoch: 80| Step: 0
Training loss: 2.4856815381390693
Validation loss: 2.7032118583057367

Epoch: 5| Step: 1
Training loss: 1.3456515231710025
Validation loss: 2.5732908877662988

Epoch: 5| Step: 2
Training loss: 1.8005476860123677
Validation loss: 2.630767269358302

Epoch: 5| Step: 3
Training loss: 2.41770438134099
Validation loss: 2.6727666761238282

Epoch: 5| Step: 4
Training loss: 2.2700898472822364
Validation loss: 2.6824055706147316

Epoch: 5| Step: 5
Training loss: 2.1694405723251755
Validation loss: 2.7002213452114963

Epoch: 5| Step: 6
Training loss: 2.201597076209478
Validation loss: 2.6798495363230055

Epoch: 5| Step: 7
Training loss: 2.7628744639686222
Validation loss: 2.604114949030726

Epoch: 5| Step: 8
Training loss: 2.3381453576893123
Validation loss: 2.6848606596948152

Epoch: 5| Step: 9
Training loss: 2.6019806396972154
Validation loss: 2.6470138039012228

Epoch: 5| Step: 10
Training loss: 1.9399456462914588
Validation loss: 2.655253118559097

Epoch: 5| Step: 11
Training loss: 1.4917753758945225
Validation loss: 2.692894109568224

Epoch: 81| Step: 0
Training loss: 2.32667250414811
Validation loss: 2.7327954662003697

Epoch: 5| Step: 1
Training loss: 2.5678586058268555
Validation loss: 2.6950063374916065

Epoch: 5| Step: 2
Training loss: 2.2941132634611523
Validation loss: 2.656922240368601

Epoch: 5| Step: 3
Training loss: 1.4865258946221152
Validation loss: 2.5630023045300656

Epoch: 5| Step: 4
Training loss: 2.711497751878316
Validation loss: 2.7043240080162922

Epoch: 5| Step: 5
Training loss: 2.2227868978655496
Validation loss: 2.6411935017493633

Epoch: 5| Step: 6
Training loss: 1.9690702874157253
Validation loss: 2.6711006157768136

Epoch: 5| Step: 7
Training loss: 1.9496097516545043
Validation loss: 2.631365713412781

Epoch: 5| Step: 8
Training loss: 2.0157695393155253
Validation loss: 2.7002482679806694

Epoch: 5| Step: 9
Training loss: 2.2288230797579733
Validation loss: 2.6917558691185715

Epoch: 5| Step: 10
Training loss: 2.130814507254198
Validation loss: 2.650192496967603

Epoch: 5| Step: 11
Training loss: 1.3909213146878419
Validation loss: 2.6577861495284405

Epoch: 82| Step: 0
Training loss: 1.275523951339597
Validation loss: 2.7860548683956132

Epoch: 5| Step: 1
Training loss: 2.2541927902578864
Validation loss: 2.7230832400420346

Epoch: 5| Step: 2
Training loss: 1.9943102728018227
Validation loss: 2.7101013147235724

Epoch: 5| Step: 3
Training loss: 2.5593596964507843
Validation loss: 2.703142415984687

Epoch: 5| Step: 4
Training loss: 1.5345639549493642
Validation loss: 2.6610769470137097

Epoch: 5| Step: 5
Training loss: 2.7750179462024396
Validation loss: 2.6477977276272964

Epoch: 5| Step: 6
Training loss: 2.5080475979232304
Validation loss: 2.65745496533485

Epoch: 5| Step: 7
Training loss: 2.0674907528210347
Validation loss: 2.6545405141558125

Epoch: 5| Step: 8
Training loss: 2.2225361072538
Validation loss: 2.644098645601803

Epoch: 5| Step: 9
Training loss: 2.5783716257215383
Validation loss: 2.710489237842728

Epoch: 5| Step: 10
Training loss: 1.8369093250495463
Validation loss: 2.664713137797718

Epoch: 5| Step: 11
Training loss: 1.8734989515698168
Validation loss: 2.703328850764389

Epoch: 83| Step: 0
Training loss: 1.800261515587559
Validation loss: 2.7296119804686154

Epoch: 5| Step: 1
Training loss: 2.102383931660903
Validation loss: 2.6706359139161484

Epoch: 5| Step: 2
Training loss: 1.9973040530236275
Validation loss: 2.605753283046272

Epoch: 5| Step: 3
Training loss: 2.1377946840125763
Validation loss: 2.720259901221496

Epoch: 5| Step: 4
Training loss: 2.094756610361412
Validation loss: 2.818084682261643

Epoch: 5| Step: 5
Training loss: 2.2835522883145893
Validation loss: 2.6650724650044366

Epoch: 5| Step: 6
Training loss: 2.571933131065068
Validation loss: 2.8017413782732707

Epoch: 5| Step: 7
Training loss: 2.186236316252035
Validation loss: 2.7222881314566165

Epoch: 5| Step: 8
Training loss: 1.9328724141807012
Validation loss: 2.6581711871124885

Epoch: 5| Step: 9
Training loss: 1.9824186879400183
Validation loss: 2.6751025153507872

Epoch: 5| Step: 10
Training loss: 2.5047240446759855
Validation loss: 2.654877985241732

Epoch: 5| Step: 11
Training loss: 1.090213453146087
Validation loss: 2.561892034159607

Epoch: 84| Step: 0
Training loss: 1.9494185412192753
Validation loss: 2.623515333664848

Epoch: 5| Step: 1
Training loss: 1.9603654855444845
Validation loss: 2.584915835192805

Epoch: 5| Step: 2
Training loss: 2.3685063380228466
Validation loss: 2.670826775090998

Epoch: 5| Step: 3
Training loss: 2.8553381601679217
Validation loss: 2.755391125062864

Epoch: 5| Step: 4
Training loss: 2.0291560016746075
Validation loss: 2.757059785243566

Epoch: 5| Step: 5
Training loss: 2.0590738681254184
Validation loss: 2.753305049411137

Epoch: 5| Step: 6
Training loss: 2.288134702585338
Validation loss: 2.6335231037107825

Epoch: 5| Step: 7
Training loss: 2.03939255421899
Validation loss: 2.731627837233485

Epoch: 5| Step: 8
Training loss: 2.0189774895859016
Validation loss: 2.6398561927251545

Epoch: 5| Step: 9
Training loss: 2.3209705382995582
Validation loss: 2.633470849151595

Epoch: 5| Step: 10
Training loss: 2.044570790696709
Validation loss: 2.5918634248500654

Epoch: 5| Step: 11
Training loss: 0.769360053678806
Validation loss: 2.6914188106042607

Epoch: 85| Step: 0
Training loss: 2.2965834036776474
Validation loss: 2.8698027011130725

Epoch: 5| Step: 1
Training loss: 2.251740735932516
Validation loss: 2.8161900296678457

Epoch: 5| Step: 2
Training loss: 1.7104167406993607
Validation loss: 2.8752908214040276

Epoch: 5| Step: 3
Training loss: 1.9179158562788272
Validation loss: 2.740491318931209

Epoch: 5| Step: 4
Training loss: 3.0271978921515967
Validation loss: 2.8299114247525377

Epoch: 5| Step: 5
Training loss: 1.939264662883522
Validation loss: 2.6659116470871402

Epoch: 5| Step: 6
Training loss: 1.9772169514864169
Validation loss: 2.622467196622727

Epoch: 5| Step: 7
Training loss: 2.3299116409312863
Validation loss: 2.6068246450341803

Epoch: 5| Step: 8
Training loss: 1.6542180390472196
Validation loss: 2.5749985589946185

Epoch: 5| Step: 9
Training loss: 2.2914673342855885
Validation loss: 2.6670760992764846

Epoch: 5| Step: 10
Training loss: 2.4487102656039705
Validation loss: 2.6806451848934008

Epoch: 5| Step: 11
Training loss: 1.3694531224233546
Validation loss: 2.6086320637961267

Epoch: 86| Step: 0
Training loss: 2.781348323155598
Validation loss: 2.6325689669152035

Epoch: 5| Step: 1
Training loss: 2.117013846732775
Validation loss: 2.7283352988202427

Epoch: 5| Step: 2
Training loss: 1.432994748571108
Validation loss: 2.677101077059315

Epoch: 5| Step: 3
Training loss: 1.6081920831878953
Validation loss: 2.6635870896216964

Epoch: 5| Step: 4
Training loss: 2.3580452917212678
Validation loss: 2.59672600096448

Epoch: 5| Step: 5
Training loss: 2.4999490732727976
Validation loss: 2.705859152076726

Epoch: 5| Step: 6
Training loss: 1.7990379252568445
Validation loss: 2.678425108758142

Epoch: 5| Step: 7
Training loss: 1.941331581813595
Validation loss: 2.592390688550804

Epoch: 5| Step: 8
Training loss: 1.7907958982710805
Validation loss: 2.6713759976929983

Epoch: 5| Step: 9
Training loss: 2.4178786253271616
Validation loss: 2.6868933318220343

Epoch: 5| Step: 10
Training loss: 2.397305000656845
Validation loss: 2.629246505022847

Epoch: 5| Step: 11
Training loss: 2.209803961262332
Validation loss: 2.682270121565031

Epoch: 87| Step: 0
Training loss: 2.5329473008954944
Validation loss: 2.6198354847595007

Epoch: 5| Step: 1
Training loss: 2.213732028330352
Validation loss: 2.7551606624255474

Epoch: 5| Step: 2
Training loss: 2.3204514176112676
Validation loss: 2.7801482093477654

Epoch: 5| Step: 3
Training loss: 2.286382258256826
Validation loss: 2.7191083459993695

Epoch: 5| Step: 4
Training loss: 1.9205291501678092
Validation loss: 2.670617339262125

Epoch: 5| Step: 5
Training loss: 2.699741075604321
Validation loss: 2.5185244221796026

Epoch: 5| Step: 6
Training loss: 1.8009891679597967
Validation loss: 2.6350856404740814

Epoch: 5| Step: 7
Training loss: 1.7864963167858832
Validation loss: 2.684968487964885

Epoch: 5| Step: 8
Training loss: 2.369072192179422
Validation loss: 2.6846440391736324

Epoch: 5| Step: 9
Training loss: 1.6518245810277272
Validation loss: 2.6813462575782467

Epoch: 5| Step: 10
Training loss: 2.189892359836085
Validation loss: 2.6229625734751245

Epoch: 5| Step: 11
Training loss: 1.7584055260516762
Validation loss: 2.608787257232045

Epoch: 88| Step: 0
Training loss: 1.3875253400121095
Validation loss: 2.6137583800244917

Epoch: 5| Step: 1
Training loss: 2.160775783884162
Validation loss: 2.6664129014765385

Epoch: 5| Step: 2
Training loss: 3.021357015183045
Validation loss: 2.5501274879537794

Epoch: 5| Step: 3
Training loss: 2.4845502299764193
Validation loss: 2.599219858826505

Epoch: 5| Step: 4
Training loss: 1.947915231904778
Validation loss: 2.6223446570475564

Epoch: 5| Step: 5
Training loss: 1.5905599644523933
Validation loss: 2.587839170700149

Epoch: 5| Step: 6
Training loss: 2.2279102195169416
Validation loss: 2.7192074219161695

Epoch: 5| Step: 7
Training loss: 2.2328101593923613
Validation loss: 2.6615027755540326

Epoch: 5| Step: 8
Training loss: 1.5843895935951493
Validation loss: 2.622557555852891

Epoch: 5| Step: 9
Training loss: 1.8754481733662134
Validation loss: 2.6217363936987033

Epoch: 5| Step: 10
Training loss: 2.272208494452202
Validation loss: 2.6426149653770565

Epoch: 5| Step: 11
Training loss: 2.05789769256283
Validation loss: 2.6340225940330053

Epoch: 89| Step: 0
Training loss: 1.6607916121052368
Validation loss: 2.7046185521961323

Epoch: 5| Step: 1
Training loss: 1.99121129670638
Validation loss: 2.7203340154502147

Epoch: 5| Step: 2
Training loss: 1.9928514757871745
Validation loss: 2.7301210756025807

Epoch: 5| Step: 3
Training loss: 2.7007818043834857
Validation loss: 2.7193677061651336

Epoch: 5| Step: 4
Training loss: 2.2226802777699497
Validation loss: 2.6314058479674367

Epoch: 5| Step: 5
Training loss: 1.9086905318653664
Validation loss: 2.712131164161433

Epoch: 5| Step: 6
Training loss: 2.091843947335963
Validation loss: 2.687340593046158

Epoch: 5| Step: 7
Training loss: 2.2033558176752677
Validation loss: 2.6661571274165627

Epoch: 5| Step: 8
Training loss: 1.6599820393429447
Validation loss: 2.7309141437035045

Epoch: 5| Step: 9
Training loss: 2.146248440883561
Validation loss: 2.669282614829262

Epoch: 5| Step: 10
Training loss: 2.2147731332437375
Validation loss: 2.6126283401164447

Epoch: 5| Step: 11
Training loss: 2.818235440876724
Validation loss: 2.664685222227646

Epoch: 90| Step: 0
Training loss: 2.4090563769998155
Validation loss: 2.6022673368997586

Epoch: 5| Step: 1
Training loss: 2.2136168942103547
Validation loss: 2.6670838727524893

Epoch: 5| Step: 2
Training loss: 2.4043479436785433
Validation loss: 2.705652336202222

Epoch: 5| Step: 3
Training loss: 1.7357826362979993
Validation loss: 2.737173816983363

Epoch: 5| Step: 4
Training loss: 1.6533472787873942
Validation loss: 2.695230230282917

Epoch: 5| Step: 5
Training loss: 2.38638028556003
Validation loss: 2.6415868358001777

Epoch: 5| Step: 6
Training loss: 2.3511659408218124
Validation loss: 2.6788593120881288

Epoch: 5| Step: 7
Training loss: 2.070354187743614
Validation loss: 2.595306090565759

Epoch: 5| Step: 8
Training loss: 2.0850176551126247
Validation loss: 2.71197881496528

Epoch: 5| Step: 9
Training loss: 1.911915349419196
Validation loss: 2.708013648948428

Epoch: 5| Step: 10
Training loss: 1.781197865041074
Validation loss: 2.748239654596961

Epoch: 5| Step: 11
Training loss: 2.1612597883718774
Validation loss: 2.532738883509483

Epoch: 91| Step: 0
Training loss: 1.696280769850556
Validation loss: 2.6931804019366754

Epoch: 5| Step: 1
Training loss: 2.1185767764057157
Validation loss: 2.712510098967379

Epoch: 5| Step: 2
Training loss: 2.055498666520221
Validation loss: 2.671022420419655

Epoch: 5| Step: 3
Training loss: 2.5301019396241995
Validation loss: 2.647802833873547

Epoch: 5| Step: 4
Training loss: 1.928418935569876
Validation loss: 2.6472494898565118

Epoch: 5| Step: 5
Training loss: 2.326362300992895
Validation loss: 2.6310719397334643

Epoch: 5| Step: 6
Training loss: 2.527989866514056
Validation loss: 2.5473830178629404

Epoch: 5| Step: 7
Training loss: 1.7634156168733002
Validation loss: 2.6469102354980882

Epoch: 5| Step: 8
Training loss: 2.0272677780352213
Validation loss: 2.7229597231771727

Epoch: 5| Step: 9
Training loss: 1.8361787028847742
Validation loss: 2.7186012556230166

Epoch: 5| Step: 10
Training loss: 1.9021796247740106
Validation loss: 2.7161329359929094

Epoch: 5| Step: 11
Training loss: 2.31452523292208
Validation loss: 2.7527602496446124

Epoch: 92| Step: 0
Training loss: 2.3417605285114633
Validation loss: 2.6874491294955147

Epoch: 5| Step: 1
Training loss: 1.67754095559075
Validation loss: 2.687369949683613

Epoch: 5| Step: 2
Training loss: 2.771835509215676
Validation loss: 2.647965722088598

Epoch: 5| Step: 3
Training loss: 2.10536128461683
Validation loss: 2.785754235459182

Epoch: 5| Step: 4
Training loss: 2.4728652841639085
Validation loss: 2.67493154209396

Epoch: 5| Step: 5
Training loss: 1.67103783869292
Validation loss: 2.6884230573627543

Epoch: 5| Step: 6
Training loss: 1.9400859925786418
Validation loss: 2.6137456134471697

Epoch: 5| Step: 7
Training loss: 1.948258402286064
Validation loss: 2.747217410593048

Epoch: 5| Step: 8
Training loss: 1.787758831144789
Validation loss: 2.6250717630113707

Epoch: 5| Step: 9
Training loss: 1.2993726922437203
Validation loss: 2.727642708846545

Epoch: 5| Step: 10
Training loss: 2.4346534540368703
Validation loss: 2.648961847062705

Epoch: 5| Step: 11
Training loss: 1.4220961514035082
Validation loss: 2.6317440736458155

Epoch: 93| Step: 0
Training loss: 2.350343711553475
Validation loss: 2.7159921572775194

Epoch: 5| Step: 1
Training loss: 1.9367804267790827
Validation loss: 2.6479878433039485

Epoch: 5| Step: 2
Training loss: 2.5736489019783364
Validation loss: 2.7174216895063226

Epoch: 5| Step: 3
Training loss: 2.2335974133872765
Validation loss: 2.7126579505298816

Epoch: 5| Step: 4
Training loss: 2.0147077262316366
Validation loss: 2.742785034575313

Epoch: 5| Step: 5
Training loss: 1.717666145517596
Validation loss: 2.7885854012032376

Epoch: 5| Step: 6
Training loss: 2.3648523074078116
Validation loss: 2.7105049902276512

Epoch: 5| Step: 7
Training loss: 1.882349487610061
Validation loss: 2.7276772749633658

Epoch: 5| Step: 8
Training loss: 2.264083443091326
Validation loss: 2.787685463955044

Epoch: 5| Step: 9
Training loss: 1.7692236222406665
Validation loss: 2.7091952321840456

Epoch: 5| Step: 10
Training loss: 2.158290726622857
Validation loss: 2.6456082328399035

Epoch: 5| Step: 11
Training loss: 0.7942780082670403
Validation loss: 2.7173879946121846

Epoch: 94| Step: 0
Training loss: 1.6280410627814832
Validation loss: 2.667810374856345

Epoch: 5| Step: 1
Training loss: 1.8240926237430752
Validation loss: 2.7459566670872473

Epoch: 5| Step: 2
Training loss: 2.148651112427467
Validation loss: 2.6755930442241356

Epoch: 5| Step: 3
Training loss: 1.7521595572796045
Validation loss: 2.6630177728695177

Epoch: 5| Step: 4
Training loss: 2.368108085678638
Validation loss: 2.757440911204939

Epoch: 5| Step: 5
Training loss: 2.329513443010053
Validation loss: 2.6870374688151974

Epoch: 5| Step: 6
Training loss: 2.2906595849396583
Validation loss: 2.7150343537601374

Epoch: 5| Step: 7
Training loss: 1.9049279052628914
Validation loss: 2.6572949541929676

Epoch: 5| Step: 8
Training loss: 2.313143254073813
Validation loss: 2.711390026041572

Epoch: 5| Step: 9
Training loss: 1.9596640414727429
Validation loss: 2.759642040079987

Epoch: 5| Step: 10
Training loss: 2.202644458064573
Validation loss: 2.6083392945019384

Epoch: 5| Step: 11
Training loss: 1.6382454463919323
Validation loss: 2.7378402623327522

Epoch: 95| Step: 0
Training loss: 1.6153912727512212
Validation loss: 2.6642449727590414

Epoch: 5| Step: 1
Training loss: 2.257702993093466
Validation loss: 2.653067410027114

Epoch: 5| Step: 2
Training loss: 1.9090793436905606
Validation loss: 2.6552257844559217

Epoch: 5| Step: 3
Training loss: 2.2335978403551
Validation loss: 2.6342057278160755

Epoch: 5| Step: 4
Training loss: 2.423582102964195
Validation loss: 2.7767070285417415

Epoch: 5| Step: 5
Training loss: 2.40031881201696
Validation loss: 2.6911570263371383

Epoch: 5| Step: 6
Training loss: 2.025708547891872
Validation loss: 2.666896390457378

Epoch: 5| Step: 7
Training loss: 1.558165603763551
Validation loss: 2.6437765610114403

Epoch: 5| Step: 8
Training loss: 1.7440264793713114
Validation loss: 2.6898406097514913

Epoch: 5| Step: 9
Training loss: 2.3578499418790817
Validation loss: 2.6454062129615408

Epoch: 5| Step: 10
Training loss: 2.1621902023411015
Validation loss: 2.7422738129597954

Epoch: 5| Step: 11
Training loss: 0.9749410978278142
Validation loss: 2.6529511255832587

Epoch: 96| Step: 0
Training loss: 1.8670785145894973
Validation loss: 2.7501078028211934

Epoch: 5| Step: 1
Training loss: 2.0000367161241632
Validation loss: 2.671631043434224

Epoch: 5| Step: 2
Training loss: 1.7622632456095122
Validation loss: 2.724109843594904

Epoch: 5| Step: 3
Training loss: 1.9438090201981737
Validation loss: 2.784950947874597

Epoch: 5| Step: 4
Training loss: 2.0403192965884656
Validation loss: 2.7546238751058967

Epoch: 5| Step: 5
Training loss: 1.3054238257448758
Validation loss: 2.741439891314161

Epoch: 5| Step: 6
Training loss: 2.204347095664397
Validation loss: 2.7016392338219126

Epoch: 5| Step: 7
Training loss: 1.777633006274278
Validation loss: 2.7892317662668966

Epoch: 5| Step: 8
Training loss: 2.258769852044877
Validation loss: 2.6826743522657033

Epoch: 5| Step: 9
Training loss: 1.960296039606449
Validation loss: 2.6739973744265617

Epoch: 5| Step: 10
Training loss: 2.59390322680757
Validation loss: 2.6738652407157915

Epoch: 5| Step: 11
Training loss: 2.053641977934605
Validation loss: 2.6566673867156068

Epoch: 97| Step: 0
Training loss: 2.0300161282128877
Validation loss: 2.7110918241140083

Epoch: 5| Step: 1
Training loss: 2.0066199416152255
Validation loss: 2.7038194466271332

Epoch: 5| Step: 2
Training loss: 2.1483076576531475
Validation loss: 2.674158726519237

Epoch: 5| Step: 3
Training loss: 2.71746725755775
Validation loss: 2.7940243057947285

Epoch: 5| Step: 4
Training loss: 1.9797555816914687
Validation loss: 2.638690845826965

Epoch: 5| Step: 5
Training loss: 1.8264524193348137
Validation loss: 2.7270764738151554

Epoch: 5| Step: 6
Training loss: 2.1627612005818366
Validation loss: 2.6933151473853227

Epoch: 5| Step: 7
Training loss: 1.805250600183163
Validation loss: 2.66175113319021

Epoch: 5| Step: 8
Training loss: 2.044625946755542
Validation loss: 2.7052304625508814

Epoch: 5| Step: 9
Training loss: 1.7849603123887596
Validation loss: 2.6656553702731816

Epoch: 5| Step: 10
Training loss: 1.7004345983475655
Validation loss: 2.6957021532958447

Epoch: 5| Step: 11
Training loss: 1.565339826549816
Validation loss: 2.8438700626166056

Epoch: 98| Step: 0
Training loss: 2.181661607441623
Validation loss: 2.660584290694608

Epoch: 5| Step: 1
Training loss: 2.444606203689949
Validation loss: 2.751296091983384

Epoch: 5| Step: 2
Training loss: 2.2885362456345337
Validation loss: 2.687900550327604

Epoch: 5| Step: 3
Training loss: 1.7350626776419547
Validation loss: 2.700161763190322

Epoch: 5| Step: 4
Training loss: 2.0778619126451208
Validation loss: 2.7791822083213558

Epoch: 5| Step: 5
Training loss: 1.5647501193301132
Validation loss: 2.7588408932838555

Epoch: 5| Step: 6
Training loss: 1.848856046471036
Validation loss: 2.742312317096923

Epoch: 5| Step: 7
Training loss: 1.362568491342899
Validation loss: 2.7523388128699255

Epoch: 5| Step: 8
Training loss: 2.6270491458403753
Validation loss: 2.6558288838788444

Epoch: 5| Step: 9
Training loss: 1.5314709251002745
Validation loss: 2.6397385284897603

Epoch: 5| Step: 10
Training loss: 1.7606022377695885
Validation loss: 2.8648233775508607

Epoch: 5| Step: 11
Training loss: 2.3264569957373245
Validation loss: 2.761107104103674

Epoch: 99| Step: 0
Training loss: 1.9866035142990945
Validation loss: 2.7457883727445234

Epoch: 5| Step: 1
Training loss: 1.5879297380685968
Validation loss: 2.7424162165218426

Epoch: 5| Step: 2
Training loss: 2.5444746817560224
Validation loss: 2.853051522330016

Epoch: 5| Step: 3
Training loss: 1.801840646385196
Validation loss: 2.8002639959688436

Epoch: 5| Step: 4
Training loss: 2.342486027988385
Validation loss: 2.8263335024670955

Epoch: 5| Step: 5
Training loss: 2.286104967158752
Validation loss: 2.790454214522331

Epoch: 5| Step: 6
Training loss: 1.984495745011562
Validation loss: 2.9090527620656945

Epoch: 5| Step: 7
Training loss: 1.8317200613989297
Validation loss: 2.7679471182958153

Epoch: 5| Step: 8
Training loss: 2.317074143871059
Validation loss: 2.6642060842442845

Epoch: 5| Step: 9
Training loss: 1.5155713573283354
Validation loss: 2.6426388812734394

Epoch: 5| Step: 10
Training loss: 1.7624291047251033
Validation loss: 2.595790083715225

Epoch: 5| Step: 11
Training loss: 2.109403708933684
Validation loss: 2.789095012001579

Epoch: 100| Step: 0
Training loss: 1.952194724743577
Validation loss: 2.703461870433387

Epoch: 5| Step: 1
Training loss: 2.2045229541520546
Validation loss: 2.77462115751845

Epoch: 5| Step: 2
Training loss: 1.7300724583264049
Validation loss: 2.785259014871415

Epoch: 5| Step: 3
Training loss: 2.365019255352065
Validation loss: 2.866175456480018

Epoch: 5| Step: 4
Training loss: 2.234722617258443
Validation loss: 2.7993919441770405

Epoch: 5| Step: 5
Training loss: 2.2771447227232438
Validation loss: 2.830181933408471

Epoch: 5| Step: 6
Training loss: 2.225742764741102
Validation loss: 2.7952848421352265

Epoch: 5| Step: 7
Training loss: 1.6094015915534872
Validation loss: 2.716698398629045

Epoch: 5| Step: 8
Training loss: 2.206514605251013
Validation loss: 2.6537479958726573

Epoch: 5| Step: 9
Training loss: 1.7205981634993763
Validation loss: 2.633076613976362

Epoch: 5| Step: 10
Training loss: 1.8772066482982206
Validation loss: 2.781947734193025

Epoch: 5| Step: 11
Training loss: 2.379818495553252
Validation loss: 2.7987629292098446

Epoch: 101| Step: 0
Training loss: 2.242857935821143
Validation loss: 2.905822845569877

Epoch: 5| Step: 1
Training loss: 2.4822161429427623
Validation loss: 2.832094515389794

Epoch: 5| Step: 2
Training loss: 2.0008412022603386
Validation loss: 2.880245164816222

Epoch: 5| Step: 3
Training loss: 1.692408804190376
Validation loss: 2.893288438649387

Epoch: 5| Step: 4
Training loss: 1.9281655924031254
Validation loss: 2.8503113601660544

Epoch: 5| Step: 5
Training loss: 1.8202590607096845
Validation loss: 2.7492832492446886

Epoch: 5| Step: 6
Training loss: 2.193403615530844
Validation loss: 2.7815888159181

Epoch: 5| Step: 7
Training loss: 1.5686358710488428
Validation loss: 2.699362641035603

Epoch: 5| Step: 8
Training loss: 1.430634981973004
Validation loss: 2.6791890925531274

Epoch: 5| Step: 9
Training loss: 2.568248998786778
Validation loss: 2.7087222565874796

Epoch: 5| Step: 10
Training loss: 2.468478224075881
Validation loss: 2.7617730832724123

Epoch: 5| Step: 11
Training loss: 1.4182717075848494
Validation loss: 2.817802576873467

Epoch: 102| Step: 0
Training loss: 2.2313382513293907
Validation loss: 2.770263169837889

Epoch: 5| Step: 1
Training loss: 1.941572646564745
Validation loss: 2.7461645335177027

Epoch: 5| Step: 2
Training loss: 2.11945224703309
Validation loss: 2.6346356110275653

Epoch: 5| Step: 3
Training loss: 1.8569167099013855
Validation loss: 2.730832055279461

Epoch: 5| Step: 4
Training loss: 1.3220368811502423
Validation loss: 2.7795625310820955

Epoch: 5| Step: 5
Training loss: 2.3026037073958228
Validation loss: 2.70774531705748

Epoch: 5| Step: 6
Training loss: 2.0296832571359738
Validation loss: 2.7840877086477103

Epoch: 5| Step: 7
Training loss: 1.6314113025643673
Validation loss: 2.735879317150973

Epoch: 5| Step: 8
Training loss: 2.2204737884548074
Validation loss: 2.711203302843353

Epoch: 5| Step: 9
Training loss: 2.2393825943754453
Validation loss: 2.7290285648222268

Epoch: 5| Step: 10
Training loss: 2.2655396544068034
Validation loss: 2.7489161486832234

Epoch: 5| Step: 11
Training loss: 1.403304851874211
Validation loss: 2.7886570975108085

Epoch: 103| Step: 0
Training loss: 3.0273371345693847
Validation loss: 2.5991816619040145

Epoch: 5| Step: 1
Training loss: 1.6694348076690162
Validation loss: 2.7240149465966357

Epoch: 5| Step: 2
Training loss: 1.617300794383138
Validation loss: 2.7807024691830877

Epoch: 5| Step: 3
Training loss: 2.354770031693253
Validation loss: 2.6746950306953328

Epoch: 5| Step: 4
Training loss: 2.042886940246244
Validation loss: 2.713008053249626

Epoch: 5| Step: 5
Training loss: 1.7372460872723012
Validation loss: 2.7218672869427403

Epoch: 5| Step: 6
Training loss: 1.8955451690435978
Validation loss: 2.7121105825751255

Epoch: 5| Step: 7
Training loss: 1.612863481939467
Validation loss: 2.6073545030517034

Epoch: 5| Step: 8
Training loss: 1.9817759997935045
Validation loss: 2.6300488389004735

Epoch: 5| Step: 9
Training loss: 1.9866982624349159
Validation loss: 2.7950061080754414

Epoch: 5| Step: 10
Training loss: 1.3778489681962773
Validation loss: 2.660430968705949

Epoch: 5| Step: 11
Training loss: 2.2444076976768534
Validation loss: 2.6945288767536435

Epoch: 104| Step: 0
Training loss: 1.4671211950820422
Validation loss: 2.60688317076205

Epoch: 5| Step: 1
Training loss: 2.69170361386226
Validation loss: 2.6422505012338724

Epoch: 5| Step: 2
Training loss: 2.1814498066589034
Validation loss: 2.6809924722995295

Epoch: 5| Step: 3
Training loss: 2.0296816126126482
Validation loss: 2.6726374662947787

Epoch: 5| Step: 4
Training loss: 1.906533829867842
Validation loss: 2.64310035704903

Epoch: 5| Step: 5
Training loss: 1.5213177140398357
Validation loss: 2.6055758719701676

Epoch: 5| Step: 6
Training loss: 1.9292062630376328
Validation loss: 2.6486300358137576

Epoch: 5| Step: 7
Training loss: 2.308429847746947
Validation loss: 2.7821381004644246

Epoch: 5| Step: 8
Training loss: 1.9638214181871319
Validation loss: 2.704802053528017

Epoch: 5| Step: 9
Training loss: 1.3306425580272399
Validation loss: 2.7190711683088304

Epoch: 5| Step: 10
Training loss: 1.8329349070435814
Validation loss: 2.7826530653617794

Epoch: 5| Step: 11
Training loss: 1.6846021566283664
Validation loss: 2.767717588110341

Epoch: 105| Step: 0
Training loss: 1.944507355656227
Validation loss: 2.689754896702726

Epoch: 5| Step: 1
Training loss: 1.5812020094754773
Validation loss: 2.7027724188622666

Epoch: 5| Step: 2
Training loss: 1.9714104977365667
Validation loss: 2.7082673150354792

Epoch: 5| Step: 3
Training loss: 2.1176181932270928
Validation loss: 2.71279532089158

Epoch: 5| Step: 4
Training loss: 2.051618597653876
Validation loss: 2.7509623671492576

Epoch: 5| Step: 5
Training loss: 2.8827709825622345
Validation loss: 2.74692118493414

Epoch: 5| Step: 6
Training loss: 1.7662591386195514
Validation loss: 2.765562480643717

Epoch: 5| Step: 7
Training loss: 1.8494115641113062
Validation loss: 2.7836664075252537

Epoch: 5| Step: 8
Training loss: 2.074728463112268
Validation loss: 2.7074948345556558

Epoch: 5| Step: 9
Training loss: 1.1289467457830542
Validation loss: 2.707165474841514

Epoch: 5| Step: 10
Training loss: 1.499941824738579
Validation loss: 2.710126271745978

Epoch: 5| Step: 11
Training loss: 2.2849766848186426
Validation loss: 2.75509257635288

Epoch: 106| Step: 0
Training loss: 2.0765148608022455
Validation loss: 2.7537838414901064

Epoch: 5| Step: 1
Training loss: 1.7852224258410918
Validation loss: 2.670952948293527

Epoch: 5| Step: 2
Training loss: 1.3126781433553725
Validation loss: 2.6567466795067096

Epoch: 5| Step: 3
Training loss: 1.629846754183783
Validation loss: 2.6953487596514636

Epoch: 5| Step: 4
Training loss: 1.8818839541665322
Validation loss: 2.6384799491229374

Epoch: 5| Step: 5
Training loss: 2.0781188046929504
Validation loss: 2.709997855270072

Epoch: 5| Step: 6
Training loss: 1.8190392883528963
Validation loss: 2.7399177395522187

Epoch: 5| Step: 7
Training loss: 2.070981014929103
Validation loss: 2.6563828192022823

Epoch: 5| Step: 8
Training loss: 2.3062211445809795
Validation loss: 2.6659042279232303

Epoch: 5| Step: 9
Training loss: 2.1427099835864363
Validation loss: 2.6036568307895513

Epoch: 5| Step: 10
Training loss: 2.0450192257973066
Validation loss: 2.6980214166128196

Epoch: 5| Step: 11
Training loss: 2.897096061296364
Validation loss: 2.7273355570392996

Epoch: 107| Step: 0
Training loss: 1.4446958308853342
Validation loss: 2.6371519886646566

Epoch: 5| Step: 1
Training loss: 1.7237767318854755
Validation loss: 2.6706857879062555

Epoch: 5| Step: 2
Training loss: 2.33649185390183
Validation loss: 2.6724760037692867

Epoch: 5| Step: 3
Training loss: 1.73573174549137
Validation loss: 2.743919731109771

Epoch: 5| Step: 4
Training loss: 2.6559479485604847
Validation loss: 2.68472236322042

Epoch: 5| Step: 5
Training loss: 1.5847938059312685
Validation loss: 2.8018175209395997

Epoch: 5| Step: 6
Training loss: 2.0767310493902347
Validation loss: 2.609593768666665

Epoch: 5| Step: 7
Training loss: 2.514333452663278
Validation loss: 2.5916923764436746

Epoch: 5| Step: 8
Training loss: 1.9195844444943488
Validation loss: 2.586207326773904

Epoch: 5| Step: 9
Training loss: 1.915899275145022
Validation loss: 2.6716587098083076

Epoch: 5| Step: 10
Training loss: 1.6192939786912255
Validation loss: 2.7128279193307696

Epoch: 5| Step: 11
Training loss: 0.7332450208446112
Validation loss: 2.740832295510859

Epoch: 108| Step: 0
Training loss: 2.622508728769211
Validation loss: 2.754267448383875

Epoch: 5| Step: 1
Training loss: 1.7085868678327187
Validation loss: 2.784713802710722

Epoch: 5| Step: 2
Training loss: 1.8179154227992274
Validation loss: 2.7638350475653857

Epoch: 5| Step: 3
Training loss: 2.16623597877398
Validation loss: 2.825278864518514

Epoch: 5| Step: 4
Training loss: 1.7130593159165952
Validation loss: 2.697508664498778

Epoch: 5| Step: 5
Training loss: 1.7733628849684002
Validation loss: 2.7357623912952804

Epoch: 5| Step: 6
Training loss: 2.0329331686928573
Validation loss: 2.729989798856314

Epoch: 5| Step: 7
Training loss: 1.8110975561759366
Validation loss: 2.608182425190912

Epoch: 5| Step: 8
Training loss: 2.4390045804289238
Validation loss: 2.7671368484269827

Epoch: 5| Step: 9
Training loss: 1.9504737865306878
Validation loss: 2.70354951527609

Epoch: 5| Step: 10
Training loss: 1.8301039849635372
Validation loss: 2.7444095249041593

Epoch: 5| Step: 11
Training loss: 1.396692305870492
Validation loss: 2.721612347975542

Epoch: 109| Step: 0
Training loss: 1.8120769138475383
Validation loss: 2.7250085754726228

Epoch: 5| Step: 1
Training loss: 2.1452197583428307
Validation loss: 2.704724549690417

Epoch: 5| Step: 2
Training loss: 1.9362840220723536
Validation loss: 2.704737863819178

Epoch: 5| Step: 3
Training loss: 1.7022682624875947
Validation loss: 2.732521489772306

Epoch: 5| Step: 4
Training loss: 2.130371933105639
Validation loss: 2.6590246967224656

Epoch: 5| Step: 5
Training loss: 2.45699592892438
Validation loss: 2.6787551688949742

Epoch: 5| Step: 6
Training loss: 2.417170329609345
Validation loss: 2.748325932912847

Epoch: 5| Step: 7
Training loss: 1.3708581966630524
Validation loss: 2.7656155135284775

Epoch: 5| Step: 8
Training loss: 1.6376974962250648
Validation loss: 2.713412423939657

Epoch: 5| Step: 9
Training loss: 1.915820190541686
Validation loss: 2.651665340026038

Epoch: 5| Step: 10
Training loss: 1.2073127887360346
Validation loss: 2.6338578477928944

Epoch: 5| Step: 11
Training loss: 1.6694456614939308
Validation loss: 2.7809825011352887

Epoch: 110| Step: 0
Training loss: 1.5245564581806401
Validation loss: 2.8082289867843726

Epoch: 5| Step: 1
Training loss: 2.3115786186049254
Validation loss: 2.7910008787135316

Epoch: 5| Step: 2
Training loss: 1.8980120900435318
Validation loss: 2.7342183567773994

Epoch: 5| Step: 3
Training loss: 1.5364144873963206
Validation loss: 2.693945367518519

Epoch: 5| Step: 4
Training loss: 1.7284372775323036
Validation loss: 2.687624610555119

Epoch: 5| Step: 5
Training loss: 2.132835080652559
Validation loss: 2.740577794055949

Epoch: 5| Step: 6
Training loss: 1.9560570033607734
Validation loss: 2.7527948828930398

Epoch: 5| Step: 7
Training loss: 1.7971663529079367
Validation loss: 2.7024888850220843

Epoch: 5| Step: 8
Training loss: 1.5403744290688306
Validation loss: 2.724435481238578

Epoch: 5| Step: 9
Training loss: 2.005995109742309
Validation loss: 2.5963453651720325

Epoch: 5| Step: 10
Training loss: 2.119238391501973
Validation loss: 2.703950428852081

Epoch: 5| Step: 11
Training loss: 2.7854971870951846
Validation loss: 2.729404465796048

Epoch: 111| Step: 0
Training loss: 1.862095165418533
Validation loss: 2.695520074195154

Epoch: 5| Step: 1
Training loss: 1.2069113465045944
Validation loss: 2.6204949806954794

Epoch: 5| Step: 2
Training loss: 1.4352199052327634
Validation loss: 2.6385293164863404

Epoch: 5| Step: 3
Training loss: 2.0425842973736583
Validation loss: 2.830006095016979

Epoch: 5| Step: 4
Training loss: 1.7116353601838474
Validation loss: 2.630912706589292

Epoch: 5| Step: 5
Training loss: 1.2659508556451515
Validation loss: 2.643231893954569

Epoch: 5| Step: 6
Training loss: 2.198823774790565
Validation loss: 2.7024773352863876

Epoch: 5| Step: 7
Training loss: 1.7058878196334681
Validation loss: 2.7153049726715164

Epoch: 5| Step: 8
Training loss: 1.3594163033360152
Validation loss: 2.699748604161675

Epoch: 5| Step: 9
Training loss: 2.3363166424842703
Validation loss: 2.7382654215908007

Epoch: 5| Step: 10
Training loss: 2.6749776037116435
Validation loss: 2.713130525619831

Epoch: 5| Step: 11
Training loss: 1.2460084126588007
Validation loss: 2.804181714794561

Epoch: 112| Step: 0
Training loss: 2.1879404986867117
Validation loss: 2.760592628964579

Epoch: 5| Step: 1
Training loss: 1.3194654106125163
Validation loss: 2.76369832703565

Epoch: 5| Step: 2
Training loss: 1.7116580647689177
Validation loss: 2.71643130495945

Epoch: 5| Step: 3
Training loss: 1.7283428558386473
Validation loss: 2.728901403702944

Epoch: 5| Step: 4
Training loss: 1.795678644384773
Validation loss: 2.748193049660848

Epoch: 5| Step: 5
Training loss: 1.9384503648654816
Validation loss: 2.662909007259649

Epoch: 5| Step: 6
Training loss: 1.830367449156558
Validation loss: 2.7075814426086735

Epoch: 5| Step: 7
Training loss: 1.9704622966505505
Validation loss: 2.7481271984631466

Epoch: 5| Step: 8
Training loss: 1.629771636224743
Validation loss: 2.7016209182909634

Epoch: 5| Step: 9
Training loss: 2.0565382595978363
Validation loss: 2.68412510082824

Epoch: 5| Step: 10
Training loss: 1.4978858035555194
Validation loss: 2.7285230595990972

Epoch: 5| Step: 11
Training loss: 1.7660571894387815
Validation loss: 2.7043173444312023

Epoch: 113| Step: 0
Training loss: 1.724334936889831
Validation loss: 2.8020119900230207

Epoch: 5| Step: 1
Training loss: 1.6157941482511642
Validation loss: 2.786917979515054

Epoch: 5| Step: 2
Training loss: 1.7909109236835912
Validation loss: 2.7631460761263265

Epoch: 5| Step: 3
Training loss: 1.9644282301688638
Validation loss: 2.7318064114872387

Epoch: 5| Step: 4
Training loss: 1.9110920180000301
Validation loss: 2.7395764787150645

Epoch: 5| Step: 5
Training loss: 1.7089033183902549
Validation loss: 2.677354774122173

Epoch: 5| Step: 6
Training loss: 2.1234850251505364
Validation loss: 2.718568057699209

Epoch: 5| Step: 7
Training loss: 1.3416271296691908
Validation loss: 2.698986615781564

Epoch: 5| Step: 8
Training loss: 1.7374594814049409
Validation loss: 2.7140045698619835

Epoch: 5| Step: 9
Training loss: 1.8704532809323287
Validation loss: 2.7041698560612644

Epoch: 5| Step: 10
Training loss: 2.0064771196860756
Validation loss: 2.8071020459814138

Epoch: 5| Step: 11
Training loss: 1.02316362050592
Validation loss: 2.724644340555116

Epoch: 114| Step: 0
Training loss: 1.8090496106659728
Validation loss: 2.6437046218476707

Epoch: 5| Step: 1
Training loss: 1.540008176930505
Validation loss: 2.75562073566294

Epoch: 5| Step: 2
Training loss: 1.5379137118357746
Validation loss: 2.7125174675655916

Epoch: 5| Step: 3
Training loss: 1.4974736555581123
Validation loss: 2.7707000081293836

Epoch: 5| Step: 4
Training loss: 2.301359094357693
Validation loss: 2.717076363757638

Epoch: 5| Step: 5
Training loss: 1.668899955155489
Validation loss: 2.6895416511144377

Epoch: 5| Step: 6
Training loss: 1.650230553442943
Validation loss: 2.7266553591534164

Epoch: 5| Step: 7
Training loss: 2.107343811908573
Validation loss: 2.742380655265796

Epoch: 5| Step: 8
Training loss: 2.232765204727568
Validation loss: 2.741586168222457

Epoch: 5| Step: 9
Training loss: 1.6392454614336471
Validation loss: 2.852561932308533

Epoch: 5| Step: 10
Training loss: 2.0486202807320018
Validation loss: 2.646199138514762

Epoch: 5| Step: 11
Training loss: 1.508043973084293
Validation loss: 2.7023623608943343

Epoch: 115| Step: 0
Training loss: 1.7661169936415573
Validation loss: 2.733840548645587

Epoch: 5| Step: 1
Training loss: 1.822398942361647
Validation loss: 2.7592455676990997

Epoch: 5| Step: 2
Training loss: 2.4238678639218207
Validation loss: 2.732917753373415

Epoch: 5| Step: 3
Training loss: 2.0250200247068837
Validation loss: 2.7103297150484944

Epoch: 5| Step: 4
Training loss: 1.6051791410207354
Validation loss: 2.783637322359526

Epoch: 5| Step: 5
Training loss: 1.3646209168051144
Validation loss: 2.693709681032908

Epoch: 5| Step: 6
Training loss: 1.9124213832080246
Validation loss: 2.703220501721282

Epoch: 5| Step: 7
Training loss: 1.5484477823264415
Validation loss: 2.800367270661528

Epoch: 5| Step: 8
Training loss: 1.6325677569641945
Validation loss: 2.759194698613791

Epoch: 5| Step: 9
Training loss: 1.2144220239602306
Validation loss: 2.7533801575051275

Epoch: 5| Step: 10
Training loss: 1.5286370384920775
Validation loss: 2.6783579205387573

Epoch: 5| Step: 11
Training loss: 2.1567658622762407
Validation loss: 2.7690023429238915

Epoch: 116| Step: 0
Training loss: 1.8127537911411888
Validation loss: 2.680296610863359

Epoch: 5| Step: 1
Training loss: 2.4401400036590677
Validation loss: 2.6755722187007143

Epoch: 5| Step: 2
Training loss: 1.297072567885382
Validation loss: 2.6968755124571584

Epoch: 5| Step: 3
Training loss: 1.3154979707911756
Validation loss: 2.6568365907910136

Epoch: 5| Step: 4
Training loss: 1.4624287547176862
Validation loss: 2.7485709703924157

Epoch: 5| Step: 5
Training loss: 1.7981135204957783
Validation loss: 2.7108346478009215

Epoch: 5| Step: 6
Training loss: 1.8781259546261613
Validation loss: 2.627838881676944

Epoch: 5| Step: 7
Training loss: 1.98346473060909
Validation loss: 2.6859580836044588

Epoch: 5| Step: 8
Training loss: 2.1623466657840376
Validation loss: 2.7695667747009063

Epoch: 5| Step: 9
Training loss: 1.6917708710896207
Validation loss: 2.780734035766096

Epoch: 5| Step: 10
Training loss: 1.5645709999434783
Validation loss: 2.671784866032216

Epoch: 5| Step: 11
Training loss: 1.3885783876264868
Validation loss: 2.777336195708784

Epoch: 117| Step: 0
Training loss: 1.5984307163128137
Validation loss: 2.7514390214793183

Epoch: 5| Step: 1
Training loss: 2.0091626566790586
Validation loss: 2.6925376171446564

Epoch: 5| Step: 2
Training loss: 2.73593470095628
Validation loss: 2.7374505212745377

Epoch: 5| Step: 3
Training loss: 1.7011287784482596
Validation loss: 2.7169198749487684

Epoch: 5| Step: 4
Training loss: 1.6769075321279265
Validation loss: 2.8319150738619365

Epoch: 5| Step: 5
Training loss: 1.5006488350433433
Validation loss: 2.76750664718528

Epoch: 5| Step: 6
Training loss: 1.5291611573469128
Validation loss: 2.660779811766076

Epoch: 5| Step: 7
Training loss: 1.5774941269271028
Validation loss: 2.74993781539661

Epoch: 5| Step: 8
Training loss: 1.995583724763788
Validation loss: 2.8712078149675095

Epoch: 5| Step: 9
Training loss: 1.5319094113889857
Validation loss: 2.679703166534033

Epoch: 5| Step: 10
Training loss: 1.6380595175860664
Validation loss: 2.9053229182969056

Epoch: 5| Step: 11
Training loss: 2.0990899157554614
Validation loss: 2.6488038206370734

Epoch: 118| Step: 0
Training loss: 1.7768704968535274
Validation loss: 2.893510543275368

Epoch: 5| Step: 1
Training loss: 1.8205576719281393
Validation loss: 2.7214802884652993

Epoch: 5| Step: 2
Training loss: 1.875605803216347
Validation loss: 2.7491153464528773

Epoch: 5| Step: 3
Training loss: 1.819867976189451
Validation loss: 2.7575846353686337

Epoch: 5| Step: 4
Training loss: 1.2155667327802455
Validation loss: 2.7677336411090168

Epoch: 5| Step: 5
Training loss: 1.3302590223356623
Validation loss: 2.7350513057847956

Epoch: 5| Step: 6
Training loss: 1.5014982688098624
Validation loss: 2.727610622532151

Epoch: 5| Step: 7
Training loss: 1.8793038246979363
Validation loss: 2.6607579145088303

Epoch: 5| Step: 8
Training loss: 1.993561992331025
Validation loss: 2.7058460196900698

Epoch: 5| Step: 9
Training loss: 2.2799133147107185
Validation loss: 2.7340765544963084

Epoch: 5| Step: 10
Training loss: 1.4975285037325925
Validation loss: 2.8023006905603824

Epoch: 5| Step: 11
Training loss: 0.8617523255987745
Validation loss: 2.6861968170671653

Epoch: 119| Step: 0
Training loss: 1.4937797958403016
Validation loss: 2.779390978208592

Epoch: 5| Step: 1
Training loss: 1.8766006631011913
Validation loss: 2.7990529728061126

Epoch: 5| Step: 2
Training loss: 1.836978568486274
Validation loss: 2.7093636692547904

Epoch: 5| Step: 3
Training loss: 1.5608121529503431
Validation loss: 2.8490834403362464

Epoch: 5| Step: 4
Training loss: 1.53701716028883
Validation loss: 2.7832709445832897

Epoch: 5| Step: 5
Training loss: 1.9238930628316935
Validation loss: 2.647171894027936

Epoch: 5| Step: 6
Training loss: 1.6562173948137566
Validation loss: 2.8330776938413247

Epoch: 5| Step: 7
Training loss: 1.8005137875873076
Validation loss: 2.8285314257364425

Epoch: 5| Step: 8
Training loss: 1.7063547011449245
Validation loss: 2.685078328267006

Epoch: 5| Step: 9
Training loss: 1.8876853346622615
Validation loss: 2.7289778314057904

Epoch: 5| Step: 10
Training loss: 2.3513250389475586
Validation loss: 2.7097970687305186

Epoch: 5| Step: 11
Training loss: 1.6961101993306082
Validation loss: 2.7543775547466716

Epoch: 120| Step: 0
Training loss: 2.284812340574303
Validation loss: 2.6794691228533125

Epoch: 5| Step: 1
Training loss: 1.9134133620034728
Validation loss: 2.8186498127942157

Epoch: 5| Step: 2
Training loss: 1.8557931716791678
Validation loss: 2.6765568743734036

Epoch: 5| Step: 3
Training loss: 1.2757991119087455
Validation loss: 2.8716402947920976

Epoch: 5| Step: 4
Training loss: 1.5541342512880318
Validation loss: 2.7803473382937898

Epoch: 5| Step: 5
Training loss: 1.5522609924772572
Validation loss: 2.695246757405828

Epoch: 5| Step: 6
Training loss: 1.4359915738721916
Validation loss: 2.67875093010005

Epoch: 5| Step: 7
Training loss: 1.7264949733595776
Validation loss: 2.7573004401201535

Epoch: 5| Step: 8
Training loss: 1.6804709802929325
Validation loss: 2.8734951918595892

Epoch: 5| Step: 9
Training loss: 1.7331259413894424
Validation loss: 2.787668896876934

Epoch: 5| Step: 10
Training loss: 1.8144813100147106
Validation loss: 2.802796221149313

Epoch: 5| Step: 11
Training loss: 1.4022729797357434
Validation loss: 2.8434330236098755

Epoch: 121| Step: 0
Training loss: 1.2889695567523125
Validation loss: 2.7788893149947267

Epoch: 5| Step: 1
Training loss: 2.3754551100105625
Validation loss: 2.8380670774858463

Epoch: 5| Step: 2
Training loss: 1.4189977353960372
Validation loss: 2.798197840132425

Epoch: 5| Step: 3
Training loss: 1.2466821028948822
Validation loss: 2.836439373771595

Epoch: 5| Step: 4
Training loss: 2.0664413247259543
Validation loss: 2.8662722770023743

Epoch: 5| Step: 5
Training loss: 1.2385814314935013
Validation loss: 2.9408310441339465

Epoch: 5| Step: 6
Training loss: 1.8489625599414352
Validation loss: 2.803096163944074

Epoch: 5| Step: 7
Training loss: 1.4141099616247261
Validation loss: 2.710967749904166

Epoch: 5| Step: 8
Training loss: 1.6649538616855868
Validation loss: 2.738418557519698

Epoch: 5| Step: 9
Training loss: 2.4695083805366056
Validation loss: 2.84341410515095

Epoch: 5| Step: 10
Training loss: 1.4257905306579375
Validation loss: 2.7963034438299665

Epoch: 5| Step: 11
Training loss: 1.3440180666367714
Validation loss: 2.782440348720101

Epoch: 122| Step: 0
Training loss: 1.3883902777953188
Validation loss: 2.824442466362815

Epoch: 5| Step: 1
Training loss: 2.7453747780802424
Validation loss: 2.849200175107729

Epoch: 5| Step: 2
Training loss: 1.8286321213774115
Validation loss: 2.8204230606514575

Epoch: 5| Step: 3
Training loss: 1.5239893769522255
Validation loss: 2.714250795299906

Epoch: 5| Step: 4
Training loss: 1.4592252274633042
Validation loss: 2.722140879588915

Epoch: 5| Step: 5
Training loss: 1.7097287023059804
Validation loss: 2.7134939410405194

Epoch: 5| Step: 6
Training loss: 1.5707073569270427
Validation loss: 2.7327295802226548

Epoch: 5| Step: 7
Training loss: 2.02674024709762
Validation loss: 2.765920878242484

Epoch: 5| Step: 8
Training loss: 1.7413667533163897
Validation loss: 2.6860722475276884

Epoch: 5| Step: 9
Training loss: 1.6145846295095183
Validation loss: 2.7406032981868766

Epoch: 5| Step: 10
Training loss: 1.5834513001248076
Validation loss: 2.7338671439709428

Epoch: 5| Step: 11
Training loss: 1.0107061554756505
Validation loss: 2.7667127758132604

Epoch: 123| Step: 0
Training loss: 1.6896837727537506
Validation loss: 2.697619511405422

Epoch: 5| Step: 1
Training loss: 2.2531864067947525
Validation loss: 2.7874827964605373

Epoch: 5| Step: 2
Training loss: 1.4208810706896153
Validation loss: 2.8103191450480125

Epoch: 5| Step: 3
Training loss: 2.2887378241039604
Validation loss: 2.7643448835815705

Epoch: 5| Step: 4
Training loss: 1.337049367339905
Validation loss: 2.662594346865732

Epoch: 5| Step: 5
Training loss: 1.3760236051164851
Validation loss: 2.74484795157374

Epoch: 5| Step: 6
Training loss: 1.9831949164337337
Validation loss: 2.7251009480562955

Epoch: 5| Step: 7
Training loss: 1.4879427948025619
Validation loss: 2.785301069192461

Epoch: 5| Step: 8
Training loss: 1.6138898611293775
Validation loss: 2.7644498882460717

Epoch: 5| Step: 9
Training loss: 1.5921858049108524
Validation loss: 2.7173467500600004

Epoch: 5| Step: 10
Training loss: 1.3243737144157934
Validation loss: 2.8750243185922173

Epoch: 5| Step: 11
Training loss: 1.7474837605563616
Validation loss: 2.7604750765012933

Epoch: 124| Step: 0
Training loss: 1.7909111233740638
Validation loss: 2.894680003926907

Epoch: 5| Step: 1
Training loss: 2.2627811868347782
Validation loss: 2.8906548953873124

Epoch: 5| Step: 2
Training loss: 1.70894426571236
Validation loss: 2.840272380483816

Epoch: 5| Step: 3
Training loss: 1.627385442660264
Validation loss: 2.8403070973471425

Epoch: 5| Step: 4
Training loss: 1.1902582860384612
Validation loss: 2.77289271130569

Epoch: 5| Step: 5
Training loss: 1.7931465276873164
Validation loss: 2.7895111271689337

Epoch: 5| Step: 6
Training loss: 1.45506067457552
Validation loss: 2.767994072525802

Epoch: 5| Step: 7
Training loss: 1.8729667447544756
Validation loss: 2.741239693670559

Epoch: 5| Step: 8
Training loss: 1.3759205077796601
Validation loss: 2.7948792616720994

Epoch: 5| Step: 9
Training loss: 1.475680860070428
Validation loss: 2.8832398901573364

Epoch: 5| Step: 10
Training loss: 1.4770414998417067
Validation loss: 2.8705309534672567

Epoch: 5| Step: 11
Training loss: 1.9208319710197777
Validation loss: 2.7233617425895504

Epoch: 125| Step: 0
Training loss: 0.9131476559919125
Validation loss: 2.797520550580488

Epoch: 5| Step: 1
Training loss: 1.9329348896228662
Validation loss: 2.823920625082873

Epoch: 5| Step: 2
Training loss: 1.335535892554106
Validation loss: 2.757718805985492

Epoch: 5| Step: 3
Training loss: 1.668038288605519
Validation loss: 2.824623332188946

Epoch: 5| Step: 4
Training loss: 2.550116225941105
Validation loss: 2.661652572222683

Epoch: 5| Step: 5
Training loss: 1.5993096859211862
Validation loss: 2.824935484461752

Epoch: 5| Step: 6
Training loss: 1.3137697254300709
Validation loss: 2.8283341297084097

Epoch: 5| Step: 7
Training loss: 1.756388787049668
Validation loss: 2.818611146110602

Epoch: 5| Step: 8
Training loss: 1.298094899577462
Validation loss: 2.8034332290212634

Epoch: 5| Step: 9
Training loss: 1.4505038668486616
Validation loss: 2.7908661581869176

Epoch: 5| Step: 10
Training loss: 1.4907976638310958
Validation loss: 2.8591826362037875

Epoch: 5| Step: 11
Training loss: 2.4698018597655693
Validation loss: 2.844711619707945

Epoch: 126| Step: 0
Training loss: 1.9445229272292635
Validation loss: 2.771004927252807

Epoch: 5| Step: 1
Training loss: 1.4439823112355403
Validation loss: 2.9129341947886407

Epoch: 5| Step: 2
Training loss: 2.5640404885676356
Validation loss: 2.815868282216006

Epoch: 5| Step: 3
Training loss: 1.9181584965530245
Validation loss: 2.7468174125123275

Epoch: 5| Step: 4
Training loss: 1.7315858287991874
Validation loss: 3.000949146539859

Epoch: 5| Step: 5
Training loss: 1.0130881096761644
Validation loss: 2.856423691018374

Epoch: 5| Step: 6
Training loss: 1.5520855009674024
Validation loss: 2.8222779587208873

Epoch: 5| Step: 7
Training loss: 1.7348969507533514
Validation loss: 2.8439349334445665

Epoch: 5| Step: 8
Training loss: 1.5536610651074167
Validation loss: 2.715021649942318

Epoch: 5| Step: 9
Training loss: 1.2094539291293411
Validation loss: 2.7703653145862206

Epoch: 5| Step: 10
Training loss: 1.7422713186859415
Validation loss: 2.8057829259312372

Epoch: 5| Step: 11
Training loss: 1.7061460805693596
Validation loss: 2.7729956727173537

Epoch: 127| Step: 0
Training loss: 1.3725763114184633
Validation loss: 2.847616198013438

Epoch: 5| Step: 1
Training loss: 1.6177070262319864
Validation loss: 2.776827968628711

Epoch: 5| Step: 2
Training loss: 2.2255156615988962
Validation loss: 2.7875498241196994

Epoch: 5| Step: 3
Training loss: 1.5042632236644409
Validation loss: 2.8294680271033092

Epoch: 5| Step: 4
Training loss: 2.3994534108495214
Validation loss: 2.8793132257952556

Epoch: 5| Step: 5
Training loss: 1.465995884799776
Validation loss: 2.750260644178318

Epoch: 5| Step: 6
Training loss: 1.612854538613396
Validation loss: 2.734419889535734

Epoch: 5| Step: 7
Training loss: 1.9468882968993464
Validation loss: 2.7879869754150435

Epoch: 5| Step: 8
Training loss: 1.3206470223724092
Validation loss: 2.762730468440017

Epoch: 5| Step: 9
Training loss: 1.3269041845747997
Validation loss: 2.7899270378448797

Epoch: 5| Step: 10
Training loss: 1.4396279382857047
Validation loss: 2.866454398859063

Epoch: 5| Step: 11
Training loss: 1.167986407194342
Validation loss: 2.88003629316646

Epoch: 128| Step: 0
Training loss: 1.911655828128721
Validation loss: 2.956995766887488

Epoch: 5| Step: 1
Training loss: 1.298905586858328
Validation loss: 2.6988000503605902

Epoch: 5| Step: 2
Training loss: 1.0436560834102142
Validation loss: 2.84491185498135

Epoch: 5| Step: 3
Training loss: 2.037766084673294
Validation loss: 2.7788426735588567

Epoch: 5| Step: 4
Training loss: 1.4017546965314747
Validation loss: 2.8653377418101025

Epoch: 5| Step: 5
Training loss: 1.8211528491916922
Validation loss: 2.969768540180726

Epoch: 5| Step: 6
Training loss: 1.920781390411141
Validation loss: 2.82816372804487

Epoch: 5| Step: 7
Training loss: 1.0379353770240476
Validation loss: 2.8403967730356317

Epoch: 5| Step: 8
Training loss: 2.095766150103682
Validation loss: 2.7520163108948528

Epoch: 5| Step: 9
Training loss: 1.5589620590046493
Validation loss: 2.7765455605743843

Epoch: 5| Step: 10
Training loss: 1.512444925487757
Validation loss: 2.7873300822747766

Epoch: 5| Step: 11
Training loss: 1.778118727527141
Validation loss: 2.868773469572671

Epoch: 129| Step: 0
Training loss: 1.8856142969684342
Validation loss: 2.891554090322124

Epoch: 5| Step: 1
Training loss: 1.4313307526974866
Validation loss: 2.791135436134361

Epoch: 5| Step: 2
Training loss: 1.5137810255504758
Validation loss: 2.806188990801319

Epoch: 5| Step: 3
Training loss: 1.3264083089732748
Validation loss: 2.6924791638209506

Epoch: 5| Step: 4
Training loss: 1.372229733148389
Validation loss: 2.7766015750766604

Epoch: 5| Step: 5
Training loss: 1.4216450935029823
Validation loss: 2.824035557688054

Epoch: 5| Step: 6
Training loss: 1.851009044742589
Validation loss: 2.745602339018525

Epoch: 5| Step: 7
Training loss: 1.4924510303687375
Validation loss: 2.8016127589480337

Epoch: 5| Step: 8
Training loss: 1.3047285701660543
Validation loss: 2.780377547620926

Epoch: 5| Step: 9
Training loss: 2.3622824836182628
Validation loss: 2.815957857752009

Epoch: 5| Step: 10
Training loss: 1.4347286877030498
Validation loss: 2.7717989814022244

Epoch: 5| Step: 11
Training loss: 0.9461547630286531
Validation loss: 2.858251222278168

Epoch: 130| Step: 0
Training loss: 1.4363046734980378
Validation loss: 2.8505032353015083

Epoch: 5| Step: 1
Training loss: 1.4382158238637075
Validation loss: 2.814125061328181

Epoch: 5| Step: 2
Training loss: 1.7353465477866135
Validation loss: 2.745759099806838

Epoch: 5| Step: 3
Training loss: 1.5673848660179306
Validation loss: 2.7975890777116965

Epoch: 5| Step: 4
Training loss: 1.4562653274711828
Validation loss: 2.728960773233853

Epoch: 5| Step: 5
Training loss: 2.090795339535879
Validation loss: 2.8293153354833063

Epoch: 5| Step: 6
Training loss: 1.6035921959013193
Validation loss: 2.8694778531579126

Epoch: 5| Step: 7
Training loss: 1.182275119391218
Validation loss: 2.732397876022413

Epoch: 5| Step: 8
Training loss: 1.4482385657195105
Validation loss: 2.7072812910322686

Epoch: 5| Step: 9
Training loss: 1.4194679426689751
Validation loss: 2.7527116100715503

Epoch: 5| Step: 10
Training loss: 1.7392925620958337
Validation loss: 2.8070956016020654

Epoch: 5| Step: 11
Training loss: 1.3876484078433857
Validation loss: 2.7504000011606275

Epoch: 131| Step: 0
Training loss: 1.4800557791018991
Validation loss: 2.817246402146574

Epoch: 5| Step: 1
Training loss: 1.554094594489414
Validation loss: 2.8089287973188526

Epoch: 5| Step: 2
Training loss: 1.420397986933303
Validation loss: 2.7560752894014717

Epoch: 5| Step: 3
Training loss: 1.6392620419770738
Validation loss: 2.8230719482580864

Epoch: 5| Step: 4
Training loss: 1.6467421070892498
Validation loss: 2.837262127130074

Epoch: 5| Step: 5
Training loss: 1.487456806741832
Validation loss: 2.755523062735748

Epoch: 5| Step: 6
Training loss: 1.383739182482497
Validation loss: 2.8881886499123643

Epoch: 5| Step: 7
Training loss: 1.4411852494026238
Validation loss: 2.8955506362878944

Epoch: 5| Step: 8
Training loss: 1.9840440248826963
Validation loss: 2.7743544052389715

Epoch: 5| Step: 9
Training loss: 1.4754638621378469
Validation loss: 2.7830561620270355

Epoch: 5| Step: 10
Training loss: 2.3216303412814967
Validation loss: 2.7483375429935113

Epoch: 5| Step: 11
Training loss: 0.9636968985943568
Validation loss: 2.8407464322138773

Epoch: 132| Step: 0
Training loss: 1.9100790495766697
Validation loss: 2.7590570856391854

Epoch: 5| Step: 1
Training loss: 1.816106431068875
Validation loss: 2.8346983248882744

Epoch: 5| Step: 2
Training loss: 1.409224141372094
Validation loss: 2.811919230084781

Epoch: 5| Step: 3
Training loss: 1.7029598050976777
Validation loss: 2.7594986390711065

Epoch: 5| Step: 4
Training loss: 1.4774706434505902
Validation loss: 2.794189414016992

Epoch: 5| Step: 5
Training loss: 1.3057337238043054
Validation loss: 2.8400162999039087

Epoch: 5| Step: 6
Training loss: 1.5676765903372671
Validation loss: 2.9269821764932558

Epoch: 5| Step: 7
Training loss: 1.1183804098663346
Validation loss: 2.789579188681143

Epoch: 5| Step: 8
Training loss: 2.2562408785226156
Validation loss: 2.8421362116070843

Epoch: 5| Step: 9
Training loss: 1.2766841853776605
Validation loss: 2.9200382375336456

Epoch: 5| Step: 10
Training loss: 1.2233442619331039
Validation loss: 2.972290758479631

Epoch: 5| Step: 11
Training loss: 1.6991260722526065
Validation loss: 2.8009930241963343

Epoch: 133| Step: 0
Training loss: 2.028295040202752
Validation loss: 2.8561227817431347

Epoch: 5| Step: 1
Training loss: 1.3002048624452116
Validation loss: 2.913211275465586

Epoch: 5| Step: 2
Training loss: 1.3243367640478627
Validation loss: 2.8202515874679603

Epoch: 5| Step: 3
Training loss: 2.169272310974668
Validation loss: 2.8464403037637243

Epoch: 5| Step: 4
Training loss: 1.4642468673258313
Validation loss: 2.8181633232310133

Epoch: 5| Step: 5
Training loss: 1.8675198438782525
Validation loss: 2.912005925190621

Epoch: 5| Step: 6
Training loss: 1.456336461721669
Validation loss: 2.7265523019507025

Epoch: 5| Step: 7
Training loss: 1.3629469584627814
Validation loss: 2.863788967386401

Epoch: 5| Step: 8
Training loss: 1.5664604348873234
Validation loss: 2.7625284370408645

Epoch: 5| Step: 9
Training loss: 1.4149226317804662
Validation loss: 2.779967022844301

Epoch: 5| Step: 10
Training loss: 1.4784803902825607
Validation loss: 2.7405840686161422

Epoch: 5| Step: 11
Training loss: 1.4849601796780587
Validation loss: 2.7931809173595417

Epoch: 134| Step: 0
Training loss: 1.3626743485078072
Validation loss: 2.865084120007586

Epoch: 5| Step: 1
Training loss: 1.519423218640264
Validation loss: 2.9000088938214956

Epoch: 5| Step: 2
Training loss: 2.215968685638125
Validation loss: 2.872345832580886

Epoch: 5| Step: 3
Training loss: 1.68166373455194
Validation loss: 2.878034199936712

Epoch: 5| Step: 4
Training loss: 1.6543581972612766
Validation loss: 2.840062349451043

Epoch: 5| Step: 5
Training loss: 1.5403077949982982
Validation loss: 2.7918936129506706

Epoch: 5| Step: 6
Training loss: 1.5243479038034047
Validation loss: 2.8422118033694206

Epoch: 5| Step: 7
Training loss: 1.8481567221155062
Validation loss: 2.856143129020227

Epoch: 5| Step: 8
Training loss: 1.4051322733562992
Validation loss: 2.846023471720966

Epoch: 5| Step: 9
Training loss: 1.3871095778202736
Validation loss: 2.7917496339131547

Epoch: 5| Step: 10
Training loss: 1.2818684829702485
Validation loss: 2.856587877329501

Epoch: 5| Step: 11
Training loss: 1.5671377400402764
Validation loss: 2.7824578323550795

Epoch: 135| Step: 0
Training loss: 1.428176080971344
Validation loss: 2.8242629712988134

Epoch: 5| Step: 1
Training loss: 2.189775754517348
Validation loss: 2.851677837390821

Epoch: 5| Step: 2
Training loss: 1.667141282532306
Validation loss: 2.7936081161142434

Epoch: 5| Step: 3
Training loss: 1.4492231919048335
Validation loss: 2.9400761684349415

Epoch: 5| Step: 4
Training loss: 1.4436243043819081
Validation loss: 2.888343838835679

Epoch: 5| Step: 5
Training loss: 1.8415336218485285
Validation loss: 2.9121670153324795

Epoch: 5| Step: 6
Training loss: 1.5682225529904892
Validation loss: 2.856686017363348

Epoch: 5| Step: 7
Training loss: 1.350634217519874
Validation loss: 2.879151463686989

Epoch: 5| Step: 8
Training loss: 1.6317187574810879
Validation loss: 2.81210250871317

Epoch: 5| Step: 9
Training loss: 1.428861535792537
Validation loss: 2.918209040500498

Epoch: 5| Step: 10
Training loss: 1.4607982875162138
Validation loss: 2.866055881133817

Epoch: 5| Step: 11
Training loss: 1.124268611944761
Validation loss: 2.8000500521273426

Epoch: 136| Step: 0
Training loss: 1.4474558840339022
Validation loss: 2.8477396139563265

Epoch: 5| Step: 1
Training loss: 1.4767243634671126
Validation loss: 2.8778059300363448

Epoch: 5| Step: 2
Training loss: 1.5620368271026306
Validation loss: 2.820776629101045

Epoch: 5| Step: 3
Training loss: 1.3410540749971065
Validation loss: 2.8689241130685423

Epoch: 5| Step: 4
Training loss: 1.1431463931393306
Validation loss: 2.803938688662919

Epoch: 5| Step: 5
Training loss: 1.4161470339078912
Validation loss: 2.91720065723647

Epoch: 5| Step: 6
Training loss: 1.5653123341608064
Validation loss: 2.8503335647409673

Epoch: 5| Step: 7
Training loss: 1.2559850460790212
Validation loss: 2.8502639635719524

Epoch: 5| Step: 8
Training loss: 1.9898698077912607
Validation loss: 2.8444337686530416

Epoch: 5| Step: 9
Training loss: 1.483516726068796
Validation loss: 2.861051460578422

Epoch: 5| Step: 10
Training loss: 1.6100673482562835
Validation loss: 2.8769617436649586

Epoch: 5| Step: 11
Training loss: 1.5367732959059524
Validation loss: 2.736143793490729

Epoch: 137| Step: 0
Training loss: 1.6212257423439063
Validation loss: 2.764911185925473

Epoch: 5| Step: 1
Training loss: 1.199616207897088
Validation loss: 2.8997315588116224

Epoch: 5| Step: 2
Training loss: 1.1764409948581929
Validation loss: 2.9180398853215532

Epoch: 5| Step: 3
Training loss: 1.4688458512866212
Validation loss: 2.937381359842847

Epoch: 5| Step: 4
Training loss: 1.6572439701962138
Validation loss: 2.940275598916714

Epoch: 5| Step: 5
Training loss: 1.079313480057554
Validation loss: 2.989371283362256

Epoch: 5| Step: 6
Training loss: 0.9845822434023134
Validation loss: 2.821785426839233

Epoch: 5| Step: 7
Training loss: 1.3256168243285584
Validation loss: 2.846947318790564

Epoch: 5| Step: 8
Training loss: 2.4697420082800914
Validation loss: 2.749262606130154

Epoch: 5| Step: 9
Training loss: 1.9756085049919019
Validation loss: 2.9837631310689536

Epoch: 5| Step: 10
Training loss: 1.6476455159965893
Validation loss: 2.964381751987704

Epoch: 5| Step: 11
Training loss: 1.4708810321252679
Validation loss: 2.873708970682823

Epoch: 138| Step: 0
Training loss: 1.4292742022363039
Validation loss: 2.902837859271685

Epoch: 5| Step: 1
Training loss: 1.4509999313249315
Validation loss: 2.870144579465611

Epoch: 5| Step: 2
Training loss: 1.3597440985838947
Validation loss: 2.8329934110278723

Epoch: 5| Step: 3
Training loss: 1.6197078801734426
Validation loss: 2.955866158737545

Epoch: 5| Step: 4
Training loss: 1.536381201235834
Validation loss: 2.730963738961419

Epoch: 5| Step: 5
Training loss: 2.109925035889658
Validation loss: 2.9720121965051103

Epoch: 5| Step: 6
Training loss: 1.4344855504868859
Validation loss: 2.9719756989478165

Epoch: 5| Step: 7
Training loss: 2.084417467957198
Validation loss: 2.9139579774658118

Epoch: 5| Step: 8
Training loss: 1.2739798672161753
Validation loss: 2.86347803235019

Epoch: 5| Step: 9
Training loss: 1.3354151189659225
Validation loss: 2.8157138828780415

Epoch: 5| Step: 10
Training loss: 1.2220955925183625
Validation loss: 2.7476442281998557

Epoch: 5| Step: 11
Training loss: 1.1902243833807933
Validation loss: 2.9547019596374766

Epoch: 139| Step: 0
Training loss: 1.7982010302283045
Validation loss: 3.0237049835458047

Epoch: 5| Step: 1
Training loss: 1.7936863346298773
Validation loss: 3.061769580021664

Epoch: 5| Step: 2
Training loss: 1.679246143640472
Validation loss: 3.053318555976959

Epoch: 5| Step: 3
Training loss: 1.5822221805599888
Validation loss: 2.8694845936471243

Epoch: 5| Step: 4
Training loss: 0.9860108422327407
Validation loss: 2.948383184302295

Epoch: 5| Step: 5
Training loss: 2.190542883973258
Validation loss: 2.7434391342374322

Epoch: 5| Step: 6
Training loss: 1.2177705007607933
Validation loss: 2.844952465323982

Epoch: 5| Step: 7
Training loss: 1.515527545116054
Validation loss: 2.8383492057484916

Epoch: 5| Step: 8
Training loss: 1.4416532640808049
Validation loss: 2.935267073206233

Epoch: 5| Step: 9
Training loss: 2.5003613210879005
Validation loss: 2.8899458250547103

Epoch: 5| Step: 10
Training loss: 1.1524415572733409
Validation loss: 2.905368462726208

Epoch: 5| Step: 11
Training loss: 1.7158284412380371
Validation loss: 2.900527368612263

Epoch: 140| Step: 0
Training loss: 1.2705991039273563
Validation loss: 2.904572211089998

Epoch: 5| Step: 1
Training loss: 1.7346921063834282
Validation loss: 2.830399032802526

Epoch: 5| Step: 2
Training loss: 1.2487771728736214
Validation loss: 2.7893130121360032

Epoch: 5| Step: 3
Training loss: 1.2145987015150501
Validation loss: 2.8453718667677483

Epoch: 5| Step: 4
Training loss: 1.453629928970214
Validation loss: 2.7628510531156985

Epoch: 5| Step: 5
Training loss: 1.1982172657956154
Validation loss: 2.714768874784788

Epoch: 5| Step: 6
Training loss: 1.5866943207235544
Validation loss: 2.8588265203908017

Epoch: 5| Step: 7
Training loss: 1.784891054584691
Validation loss: 2.8858288850363554

Epoch: 5| Step: 8
Training loss: 1.5330970678883549
Validation loss: 2.863861344413951

Epoch: 5| Step: 9
Training loss: 2.0408426165833666
Validation loss: 2.803613359628304

Epoch: 5| Step: 10
Training loss: 1.2405204863449961
Validation loss: 2.7774203254598313

Epoch: 5| Step: 11
Training loss: 1.2804353962174013
Validation loss: 2.6669744646732974

Epoch: 141| Step: 0
Training loss: 1.5794564097911337
Validation loss: 2.8392840589933774

Epoch: 5| Step: 1
Training loss: 2.420035962239552
Validation loss: 2.8633914386802903

Epoch: 5| Step: 2
Training loss: 1.897696896114204
Validation loss: 2.8870001876389666

Epoch: 5| Step: 3
Training loss: 1.6102947828879097
Validation loss: 2.7653917153168583

Epoch: 5| Step: 4
Training loss: 1.4593547059961838
Validation loss: 2.927351651954353

Epoch: 5| Step: 5
Training loss: 1.2752959375444042
Validation loss: 2.8035459116652977

Epoch: 5| Step: 6
Training loss: 1.5838632784272657
Validation loss: 2.7887911909484786

Epoch: 5| Step: 7
Training loss: 0.801929785327968
Validation loss: 2.8511533295564444

Epoch: 5| Step: 8
Training loss: 1.29767841134161
Validation loss: 2.867152422587322

Epoch: 5| Step: 9
Training loss: 1.5218144304884533
Validation loss: 2.8655765245082185

Epoch: 5| Step: 10
Training loss: 1.5369302143543038
Validation loss: 2.8319270007359303

Epoch: 5| Step: 11
Training loss: 1.0351298202883341
Validation loss: 2.829154858028467

Epoch: 142| Step: 0
Training loss: 1.5243894292782723
Validation loss: 2.829079640744347

Epoch: 5| Step: 1
Training loss: 1.2811777978417427
Validation loss: 2.866940791770411

Epoch: 5| Step: 2
Training loss: 1.0116517622874697
Validation loss: 2.790413398452158

Epoch: 5| Step: 3
Training loss: 1.5065151820084077
Validation loss: 2.850039144018516

Epoch: 5| Step: 4
Training loss: 1.1263607590519857
Validation loss: 2.8372572743233535

Epoch: 5| Step: 5
Training loss: 2.175695777186729
Validation loss: 2.8895023709107193

Epoch: 5| Step: 6
Training loss: 1.2885000215470441
Validation loss: 2.748489788831036

Epoch: 5| Step: 7
Training loss: 1.3001906970347468
Validation loss: 2.768678140102409

Epoch: 5| Step: 8
Training loss: 1.268542142105619
Validation loss: 2.8472762514947862

Epoch: 5| Step: 9
Training loss: 1.5104329952365863
Validation loss: 2.6984702000259255

Epoch: 5| Step: 10
Training loss: 1.2030625265175856
Validation loss: 2.685498945328685

Epoch: 5| Step: 11
Training loss: 2.100443488930185
Validation loss: 2.7488077787161553

Epoch: 143| Step: 0
Training loss: 1.6903168515561764
Validation loss: 2.7622773623041574

Epoch: 5| Step: 1
Training loss: 1.3041799780234358
Validation loss: 2.834795305856179

Epoch: 5| Step: 2
Training loss: 1.0149828127641394
Validation loss: 2.7833668692980242

Epoch: 5| Step: 3
Training loss: 1.7842815100768568
Validation loss: 2.783879530065249

Epoch: 5| Step: 4
Training loss: 2.0284355031686703
Validation loss: 2.7700472173097865

Epoch: 5| Step: 5
Training loss: 1.2733196367822028
Validation loss: 2.7182845817122008

Epoch: 5| Step: 6
Training loss: 0.9241334438859247
Validation loss: 2.6318768197908424

Epoch: 5| Step: 7
Training loss: 1.3874813508163706
Validation loss: 2.755671367905503

Epoch: 5| Step: 8
Training loss: 1.4319575064443957
Validation loss: 2.783723895334949

Epoch: 5| Step: 9
Training loss: 1.273415547749222
Validation loss: 2.7261078354342674

Epoch: 5| Step: 10
Training loss: 1.1099468422954126
Validation loss: 2.822392528809122

Epoch: 5| Step: 11
Training loss: 1.5631073343589705
Validation loss: 2.842350650415703

Epoch: 144| Step: 0
Training loss: 1.5132082518309975
Validation loss: 2.850284648924117

Epoch: 5| Step: 1
Training loss: 1.076976330064031
Validation loss: 2.819135665166811

Epoch: 5| Step: 2
Training loss: 1.4964996663713577
Validation loss: 2.87566219526596

Epoch: 5| Step: 3
Training loss: 1.5764098714514092
Validation loss: 2.9066998294282267

Epoch: 5| Step: 4
Training loss: 1.1577218456531198
Validation loss: 2.955378081634855

Epoch: 5| Step: 5
Training loss: 1.2809028155099715
Validation loss: 2.811337472697722

Epoch: 5| Step: 6
Training loss: 1.8008788903631852
Validation loss: 2.857016652234846

Epoch: 5| Step: 7
Training loss: 1.2679302743279108
Validation loss: 2.7680769358441575

Epoch: 5| Step: 8
Training loss: 1.908598406954255
Validation loss: 2.917918881045931

Epoch: 5| Step: 9
Training loss: 0.9431697109840859
Validation loss: 2.841150034975091

Epoch: 5| Step: 10
Training loss: 0.9287230032569261
Validation loss: 2.879751753301534

Epoch: 5| Step: 11
Training loss: 1.190403751031288
Validation loss: 2.8710243510813886

Epoch: 145| Step: 0
Training loss: 1.5713265404460668
Validation loss: 2.802084140470216

Epoch: 5| Step: 1
Training loss: 2.0011288318253024
Validation loss: 2.7672090825008007

Epoch: 5| Step: 2
Training loss: 1.3126898582832167
Validation loss: 2.797826448852667

Epoch: 5| Step: 3
Training loss: 1.0988442721843388
Validation loss: 2.9604987940893994

Epoch: 5| Step: 4
Training loss: 1.4433509506372046
Validation loss: 2.7253887378988084

Epoch: 5| Step: 5
Training loss: 1.465555003107208
Validation loss: 2.7131804056756095

Epoch: 5| Step: 6
Training loss: 0.9125653256587528
Validation loss: 2.911376110319366

Epoch: 5| Step: 7
Training loss: 1.4113374871841686
Validation loss: 2.864167052568534

Epoch: 5| Step: 8
Training loss: 0.9937478059468551
Validation loss: 2.7582917089769463

Epoch: 5| Step: 9
Training loss: 1.486056048520951
Validation loss: 2.845130239616367

Epoch: 5| Step: 10
Training loss: 1.5430179636386123
Validation loss: 2.7636763501889288

Epoch: 5| Step: 11
Training loss: 0.6569466072563966
Validation loss: 2.76341471379858

Epoch: 146| Step: 0
Training loss: 1.0659388261852218
Validation loss: 2.835501617197988

Epoch: 5| Step: 1
Training loss: 1.1956110064200607
Validation loss: 2.872648984809785

Epoch: 5| Step: 2
Training loss: 1.30031694253329
Validation loss: 2.784932966230279

Epoch: 5| Step: 3
Training loss: 0.9890119542709875
Validation loss: 2.8243533252329813

Epoch: 5| Step: 4
Training loss: 2.1253492404951912
Validation loss: 2.871213911314376

Epoch: 5| Step: 5
Training loss: 1.1853385126310405
Validation loss: 2.9023471727860173

Epoch: 5| Step: 6
Training loss: 1.5560136822439719
Validation loss: 2.752582623347221

Epoch: 5| Step: 7
Training loss: 1.5224883423908586
Validation loss: 2.781007498981032

Epoch: 5| Step: 8
Training loss: 1.2401425785725602
Validation loss: 2.8890796585907617

Epoch: 5| Step: 9
Training loss: 1.6636117673980075
Validation loss: 2.8286313153444955

Epoch: 5| Step: 10
Training loss: 1.2616186899480737
Validation loss: 2.8371128032358457

Epoch: 5| Step: 11
Training loss: 1.425502467661434
Validation loss: 2.8331589972397855

Epoch: 147| Step: 0
Training loss: 1.5739795891239377
Validation loss: 2.991148473619007

Epoch: 5| Step: 1
Training loss: 1.3304603240395347
Validation loss: 2.963094071888836

Epoch: 5| Step: 2
Training loss: 0.9424730326895059
Validation loss: 2.9721044328162476

Epoch: 5| Step: 3
Training loss: 1.0744319080062805
Validation loss: 2.842771082197564

Epoch: 5| Step: 4
Training loss: 1.2308138893122311
Validation loss: 2.7628483923703597

Epoch: 5| Step: 5
Training loss: 1.7666465032374539
Validation loss: 2.846086649467441

Epoch: 5| Step: 6
Training loss: 1.4432553884913446
Validation loss: 2.858804590276395

Epoch: 5| Step: 7
Training loss: 1.9804888541801953
Validation loss: 2.9108810000244

Epoch: 5| Step: 8
Training loss: 0.9764673720757315
Validation loss: 2.938609623835951

Epoch: 5| Step: 9
Training loss: 1.5042529214377656
Validation loss: 2.836603403508504

Epoch: 5| Step: 10
Training loss: 1.0310842785470342
Validation loss: 2.866768154068509

Epoch: 5| Step: 11
Training loss: 1.0501144165188676
Validation loss: 2.7915380659421563

Epoch: 148| Step: 0
Training loss: 1.201814358709359
Validation loss: 2.8566629440998526

Epoch: 5| Step: 1
Training loss: 1.781424530580596
Validation loss: 2.9653578133741827

Epoch: 5| Step: 2
Training loss: 2.1109092501564914
Validation loss: 2.8806842987827808

Epoch: 5| Step: 3
Training loss: 1.2143837404353754
Validation loss: 2.805043887675038

Epoch: 5| Step: 4
Training loss: 1.413789754455328
Validation loss: 2.9116375662694707

Epoch: 5| Step: 5
Training loss: 1.229224408404481
Validation loss: 2.9368934140328635

Epoch: 5| Step: 6
Training loss: 0.8912657056069351
Validation loss: 2.9364268594989955

Epoch: 5| Step: 7
Training loss: 1.1882761878031811
Validation loss: 2.8858006488108723

Epoch: 5| Step: 8
Training loss: 1.5265855395043633
Validation loss: 2.9595586339095434

Epoch: 5| Step: 9
Training loss: 1.1189072716842396
Validation loss: 2.889235256951728

Epoch: 5| Step: 10
Training loss: 0.9117217455294185
Validation loss: 2.785716870254906

Epoch: 5| Step: 11
Training loss: 0.9262038606279441
Validation loss: 2.8740519916352962

Epoch: 149| Step: 0
Training loss: 1.638853442712146
Validation loss: 2.781101697904002

Epoch: 5| Step: 1
Training loss: 1.30098298945584
Validation loss: 2.7644182183681223

Epoch: 5| Step: 2
Training loss: 0.9755387700528466
Validation loss: 2.991807649570363

Epoch: 5| Step: 3
Training loss: 2.0332549543856255
Validation loss: 2.8835772195289002

Epoch: 5| Step: 4
Training loss: 1.036662837161466
Validation loss: 2.848789504149594

Epoch: 5| Step: 5
Training loss: 1.044620306402738
Validation loss: 2.857187111545884

Epoch: 5| Step: 6
Training loss: 1.55475374780336
Validation loss: 2.8529611057868736

Epoch: 5| Step: 7
Training loss: 1.2689033246532138
Validation loss: 2.748007706519134

Epoch: 5| Step: 8
Training loss: 0.8562612477141573
Validation loss: 2.8820669593711736

Epoch: 5| Step: 9
Training loss: 1.0827722319014086
Validation loss: 2.8644294396879584

Epoch: 5| Step: 10
Training loss: 1.4488378471486456
Validation loss: 2.864470834545958

Epoch: 5| Step: 11
Training loss: 0.309553248178825
Validation loss: 2.9059172511602895

Epoch: 150| Step: 0
Training loss: 1.4416306897269995
Validation loss: 2.783953538530027

Epoch: 5| Step: 1
Training loss: 1.5107431343928837
Validation loss: 2.910942875926606

Epoch: 5| Step: 2
Training loss: 1.3146582977555357
Validation loss: 2.9731771553259843

Epoch: 5| Step: 3
Training loss: 1.107543777134497
Validation loss: 2.8760514962538313

Epoch: 5| Step: 4
Training loss: 1.2484985393932693
Validation loss: 2.8781725579611495

Epoch: 5| Step: 5
Training loss: 0.9069401645186188
Validation loss: 2.835230512391881

Epoch: 5| Step: 6
Training loss: 1.2466779911747476
Validation loss: 2.870588601582934

Epoch: 5| Step: 7
Training loss: 1.386843909404636
Validation loss: 2.8582381192763444

Epoch: 5| Step: 8
Training loss: 1.484931680796767
Validation loss: 2.8964737291541267

Epoch: 5| Step: 9
Training loss: 1.1928885822052553
Validation loss: 2.8326839072064254

Epoch: 5| Step: 10
Training loss: 1.8664205085142687
Validation loss: 2.8569438062455

Epoch: 5| Step: 11
Training loss: 1.1160011661755884
Validation loss: 2.9053383084275444

Epoch: 151| Step: 0
Training loss: 1.6046852743250373
Validation loss: 2.766223591251669

Epoch: 5| Step: 1
Training loss: 1.8575508722703962
Validation loss: 2.9389733211244864

Epoch: 5| Step: 2
Training loss: 1.1661387622931794
Validation loss: 2.9448896824695123

Epoch: 5| Step: 3
Training loss: 1.1780759401503405
Validation loss: 2.908614758663177

Epoch: 5| Step: 4
Training loss: 1.1508971363771474
Validation loss: 2.9373551630607087

Epoch: 5| Step: 5
Training loss: 1.185738712984944
Validation loss: 2.901926906630031

Epoch: 5| Step: 6
Training loss: 1.0590580558965015
Validation loss: 2.9546178310928277

Epoch: 5| Step: 7
Training loss: 1.56368706433983
Validation loss: 2.9606455354499794

Epoch: 5| Step: 8
Training loss: 1.0585726352289109
Validation loss: 2.8857356984194085

Epoch: 5| Step: 9
Training loss: 0.9296066505474918
Validation loss: 2.8461497211005082

Epoch: 5| Step: 10
Training loss: 1.146022931220692
Validation loss: 2.8684738177216755

Epoch: 5| Step: 11
Training loss: 2.781902793825995
Validation loss: 2.9110559084158116

Epoch: 152| Step: 0
Training loss: 0.6663335002441286
Validation loss: 2.8500393496691365

Epoch: 5| Step: 1
Training loss: 1.5239728720495789
Validation loss: 2.9052623656673657

Epoch: 5| Step: 2
Training loss: 1.4208387853941067
Validation loss: 2.8486244987058718

Epoch: 5| Step: 3
Training loss: 1.2408523581852287
Validation loss: 2.9324532165654706

Epoch: 5| Step: 4
Training loss: 1.0238764746004145
Validation loss: 2.86435802209417

Epoch: 5| Step: 5
Training loss: 1.2129092007748727
Validation loss: 2.843201196554734

Epoch: 5| Step: 6
Training loss: 2.0795333793732995
Validation loss: 2.872374254677659

Epoch: 5| Step: 7
Training loss: 1.5417573060205438
Validation loss: 2.9287724672379163

Epoch: 5| Step: 8
Training loss: 1.2440866791005185
Validation loss: 2.8043422256219768

Epoch: 5| Step: 9
Training loss: 1.1998753443186032
Validation loss: 2.8295993018136256

Epoch: 5| Step: 10
Training loss: 1.0533586961573849
Validation loss: 2.7786535938062804

Epoch: 5| Step: 11
Training loss: 1.1062254455772413
Validation loss: 2.879193630221061

Epoch: 153| Step: 0
Training loss: 1.4250391871100228
Validation loss: 2.8248582030749723

Epoch: 5| Step: 1
Training loss: 1.9199240481732043
Validation loss: 2.8365627541842597

Epoch: 5| Step: 2
Training loss: 0.9956025651605986
Validation loss: 2.881576066175

Epoch: 5| Step: 3
Training loss: 0.9588332668984961
Validation loss: 3.022133827893871

Epoch: 5| Step: 4
Training loss: 1.089002332297806
Validation loss: 2.761827915449535

Epoch: 5| Step: 5
Training loss: 1.3806125360895936
Validation loss: 2.9239248813137544

Epoch: 5| Step: 6
Training loss: 1.306852725480879
Validation loss: 2.9018817840295306

Epoch: 5| Step: 7
Training loss: 0.9345004734264662
Validation loss: 2.8814752056293558

Epoch: 5| Step: 8
Training loss: 1.0699221602317983
Validation loss: 2.849833147842232

Epoch: 5| Step: 9
Training loss: 1.448614524056224
Validation loss: 2.9441021760556776

Epoch: 5| Step: 10
Training loss: 1.0019827498133198
Validation loss: 2.898182126814158

Epoch: 5| Step: 11
Training loss: 1.0363330989046793
Validation loss: 2.849115902008757

Epoch: 154| Step: 0
Training loss: 1.2403390434733086
Validation loss: 2.8673119548288732

Epoch: 5| Step: 1
Training loss: 1.050625700941879
Validation loss: 2.8599416695884257

Epoch: 5| Step: 2
Training loss: 1.3909842209349517
Validation loss: 2.900071840931055

Epoch: 5| Step: 3
Training loss: 0.944302610580486
Validation loss: 2.8198383598468473

Epoch: 5| Step: 4
Training loss: 1.2984013135804673
Validation loss: 2.834234596877045

Epoch: 5| Step: 5
Training loss: 0.9475734564456798
Validation loss: 2.961825315691041

Epoch: 5| Step: 6
Training loss: 1.648407343728717
Validation loss: 2.9242261650907997

Epoch: 5| Step: 7
Training loss: 1.0876354966213369
Validation loss: 2.957288837509889

Epoch: 5| Step: 8
Training loss: 1.2283731690309014
Validation loss: 2.914623322438637

Epoch: 5| Step: 9
Training loss: 2.0554678127818797
Validation loss: 2.9342865343879163

Epoch: 5| Step: 10
Training loss: 1.1966077979403589
Validation loss: 2.9455135657961264

Epoch: 5| Step: 11
Training loss: 0.9163006499733931
Validation loss: 2.8667835709850102

Epoch: 155| Step: 0
Training loss: 1.178774044240663
Validation loss: 2.9216087682405276

Epoch: 5| Step: 1
Training loss: 1.5016097332276694
Validation loss: 2.8756735261546633

Epoch: 5| Step: 2
Training loss: 1.3251277987908778
Validation loss: 2.997368098488872

Epoch: 5| Step: 3
Training loss: 1.283930045691117
Validation loss: 2.9335284812090365

Epoch: 5| Step: 4
Training loss: 0.8896068642844575
Validation loss: 2.9152364914244204

Epoch: 5| Step: 5
Training loss: 1.0842351949752744
Validation loss: 2.8866040125694155

Epoch: 5| Step: 6
Training loss: 1.009527122915405
Validation loss: 2.9353909767295585

Epoch: 5| Step: 7
Training loss: 1.200655346972919
Validation loss: 2.9491884882639625

Epoch: 5| Step: 8
Training loss: 1.2772804267889422
Validation loss: 2.9020952175651953

Epoch: 5| Step: 9
Training loss: 1.2106543917576327
Validation loss: 2.9519729654647304

Epoch: 5| Step: 10
Training loss: 1.3563414740588058
Validation loss: 2.8799010291633165

Epoch: 5| Step: 11
Training loss: 3.7075605265846403
Validation loss: 2.824117768638109

Epoch: 156| Step: 0
Training loss: 1.0955848562020571
Validation loss: 2.9330911929712054

Epoch: 5| Step: 1
Training loss: 1.0352989242405157
Validation loss: 2.9251850031629263

Epoch: 5| Step: 2
Training loss: 1.9524448278547208
Validation loss: 3.031900067445635

Epoch: 5| Step: 3
Training loss: 1.1465170756522853
Validation loss: 2.953022674187147

Epoch: 5| Step: 4
Training loss: 0.9940738917887948
Validation loss: 2.846610475094632

Epoch: 5| Step: 5
Training loss: 1.205664098094777
Validation loss: 2.8623842167377673

Epoch: 5| Step: 6
Training loss: 1.3219678535044481
Validation loss: 2.8862960705577865

Epoch: 5| Step: 7
Training loss: 1.3195405768905588
Validation loss: 2.879057981580775

Epoch: 5| Step: 8
Training loss: 1.2781869980528169
Validation loss: 2.954925358351863

Epoch: 5| Step: 9
Training loss: 1.1184513439292667
Validation loss: 2.9024044730473126

Epoch: 5| Step: 10
Training loss: 1.049255795368062
Validation loss: 2.8541178884770004

Epoch: 5| Step: 11
Training loss: 1.5363993574127706
Validation loss: 2.8385768024941456

Epoch: 157| Step: 0
Training loss: 1.1364308939883754
Validation loss: 2.8860489064241026

Epoch: 5| Step: 1
Training loss: 1.916793556435952
Validation loss: 2.9010628928338824

Epoch: 5| Step: 2
Training loss: 0.8566273546908758
Validation loss: 2.860436028991277

Epoch: 5| Step: 3
Training loss: 1.7345062756044107
Validation loss: 2.901043812575765

Epoch: 5| Step: 4
Training loss: 1.6161272931999904
Validation loss: 2.921556482616591

Epoch: 5| Step: 5
Training loss: 1.161661885761145
Validation loss: 2.9717140425594253

Epoch: 5| Step: 6
Training loss: 1.1365612746812384
Validation loss: 2.9845755344942067

Epoch: 5| Step: 7
Training loss: 1.0333041338230333
Validation loss: 2.8945097722995445

Epoch: 5| Step: 8
Training loss: 1.0330651809534817
Validation loss: 3.011879220291857

Epoch: 5| Step: 9
Training loss: 1.0751577815990296
Validation loss: 2.9568991990632205

Epoch: 5| Step: 10
Training loss: 0.9911305061367321
Validation loss: 2.9177123454587393

Epoch: 5| Step: 11
Training loss: 1.0266597196624678
Validation loss: 2.9361641260924904

Epoch: 158| Step: 0
Training loss: 1.0804709191069548
Validation loss: 3.0496328799986663

Epoch: 5| Step: 1
Training loss: 0.952432662405874
Validation loss: 2.960524319662942

Epoch: 5| Step: 2
Training loss: 1.488941756934096
Validation loss: 2.817866034804246

Epoch: 5| Step: 3
Training loss: 0.845963083534925
Validation loss: 2.809049552536543

Epoch: 5| Step: 4
Training loss: 1.7937565155442627
Validation loss: 2.920742005640463

Epoch: 5| Step: 5
Training loss: 0.784180789628448
Validation loss: 2.9375564082796695

Epoch: 5| Step: 6
Training loss: 1.6061872744651187
Validation loss: 2.949084779504916

Epoch: 5| Step: 7
Training loss: 0.8907788461687206
Validation loss: 2.8969024816016766

Epoch: 5| Step: 8
Training loss: 0.9099393921884907
Validation loss: 2.8796740146099733

Epoch: 5| Step: 9
Training loss: 1.1939016255854678
Validation loss: 2.8971493747103483

Epoch: 5| Step: 10
Training loss: 1.2477896220772735
Validation loss: 2.7830342773618413

Epoch: 5| Step: 11
Training loss: 1.0338609184345744
Validation loss: 2.847666938807029

Epoch: 159| Step: 0
Training loss: 2.1444692133701255
Validation loss: 2.907174144644351

Epoch: 5| Step: 1
Training loss: 0.7689051913413233
Validation loss: 2.874634170062431

Epoch: 5| Step: 2
Training loss: 1.158254072281389
Validation loss: 2.918106998435194

Epoch: 5| Step: 3
Training loss: 1.285476644632476
Validation loss: 2.875326248676155

Epoch: 5| Step: 4
Training loss: 0.9669658474695083
Validation loss: 2.9782931051880053

Epoch: 5| Step: 5
Training loss: 0.9963502441477929
Validation loss: 2.8253782819424433

Epoch: 5| Step: 6
Training loss: 0.9616430220239751
Validation loss: 2.9238737922861557

Epoch: 5| Step: 7
Training loss: 0.8299981291876242
Validation loss: 3.027616971720171

Epoch: 5| Step: 8
Training loss: 0.9702424274395782
Validation loss: 2.89200756242123

Epoch: 5| Step: 9
Training loss: 1.3622264114916676
Validation loss: 2.8826730448031492

Epoch: 5| Step: 10
Training loss: 1.148663660733686
Validation loss: 3.014118539735152

Epoch: 5| Step: 11
Training loss: 1.7932982962611572
Validation loss: 2.8981056674633034

Epoch: 160| Step: 0
Training loss: 0.8510962793639338
Validation loss: 2.9263807292917616

Epoch: 5| Step: 1
Training loss: 0.981064725502116
Validation loss: 3.0001839640956347

Epoch: 5| Step: 2
Training loss: 1.9702104268266785
Validation loss: 2.90598240170704

Epoch: 5| Step: 3
Training loss: 1.0457879870995803
Validation loss: 2.9234662678273455

Epoch: 5| Step: 4
Training loss: 1.1176043713023358
Validation loss: 3.027007365252546

Epoch: 5| Step: 5
Training loss: 0.9434411939439357
Validation loss: 3.046037144675965

Epoch: 5| Step: 6
Training loss: 1.0685788893220627
Validation loss: 3.0266410619189026

Epoch: 5| Step: 7
Training loss: 1.4140425201184732
Validation loss: 2.9660533168298033

Epoch: 5| Step: 8
Training loss: 1.0149422331283315
Validation loss: 2.986080025479075

Epoch: 5| Step: 9
Training loss: 1.5546245466358775
Validation loss: 2.9034555324352636

Epoch: 5| Step: 10
Training loss: 1.4303452276444877
Validation loss: 3.091789269694013

Epoch: 5| Step: 11
Training loss: 1.38090771883196
Validation loss: 2.9494967500132327

Epoch: 161| Step: 0
Training loss: 1.050603348090768
Validation loss: 3.0007072681277664

Epoch: 5| Step: 1
Training loss: 1.4150056170294787
Validation loss: 2.977669230620973

Epoch: 5| Step: 2
Training loss: 0.9221395985679887
Validation loss: 2.970457633277291

Epoch: 5| Step: 3
Training loss: 0.9626716225437959
Validation loss: 2.984867408167576

Epoch: 5| Step: 4
Training loss: 1.0434493197136956
Validation loss: 2.8704051327281

Epoch: 5| Step: 5
Training loss: 1.9245958374612686
Validation loss: 2.9057999812812985

Epoch: 5| Step: 6
Training loss: 1.4058024223982981
Validation loss: 3.011128359072093

Epoch: 5| Step: 7
Training loss: 0.9822629037787656
Validation loss: 2.9433549603768943

Epoch: 5| Step: 8
Training loss: 0.9671483797657053
Validation loss: 2.9177036428816736

Epoch: 5| Step: 9
Training loss: 1.106079633708641
Validation loss: 2.932290676290685

Epoch: 5| Step: 10
Training loss: 1.103205598474921
Validation loss: 3.024860362699881

Epoch: 5| Step: 11
Training loss: 1.1185943708379444
Validation loss: 3.0095122121531555

Epoch: 162| Step: 0
Training loss: 1.2036333867806048
Validation loss: 3.042603297359432

Epoch: 5| Step: 1
Training loss: 0.892268955767926
Validation loss: 2.9561548920723624

Epoch: 5| Step: 2
Training loss: 0.9363414917820504
Validation loss: 2.939202109736852

Epoch: 5| Step: 3
Training loss: 1.4599726137440696
Validation loss: 2.9377522766056416

Epoch: 5| Step: 4
Training loss: 0.8058218876546234
Validation loss: 3.02046920072533

Epoch: 5| Step: 5
Training loss: 0.7734354963180328
Validation loss: 2.8937084420215626

Epoch: 5| Step: 6
Training loss: 1.2610768199848157
Validation loss: 2.912970811421322

Epoch: 5| Step: 7
Training loss: 1.0189864065706755
Validation loss: 3.0781779825262583

Epoch: 5| Step: 8
Training loss: 1.2270159035221744
Validation loss: 2.978174682448282

Epoch: 5| Step: 9
Training loss: 1.1275048450780327
Validation loss: 2.936838919401787

Epoch: 5| Step: 10
Training loss: 1.9720933167622445
Validation loss: 3.020779159761696

Epoch: 5| Step: 11
Training loss: 0.45179510626462355
Validation loss: 2.8930032036982567

Epoch: 163| Step: 0
Training loss: 0.8990265283690995
Validation loss: 2.9202345800779437

Epoch: 5| Step: 1
Training loss: 1.023434995691861
Validation loss: 2.91331982118636

Epoch: 5| Step: 2
Training loss: 1.0311342232187959
Validation loss: 3.01164762723851

Epoch: 5| Step: 3
Training loss: 1.4171774261352095
Validation loss: 2.7870190380117106

Epoch: 5| Step: 4
Training loss: 1.1424938725113107
Validation loss: 2.8713592787116506

Epoch: 5| Step: 5
Training loss: 1.0656484069938317
Validation loss: 2.937666462179033

Epoch: 5| Step: 6
Training loss: 1.1291987690227365
Validation loss: 2.9544383598416175

Epoch: 5| Step: 7
Training loss: 1.864262800175033
Validation loss: 2.971297606526942

Epoch: 5| Step: 8
Training loss: 0.7972872920365269
Validation loss: 2.855170850613289

Epoch: 5| Step: 9
Training loss: 0.997101307834605
Validation loss: 2.9555822708441033

Epoch: 5| Step: 10
Training loss: 0.7450351894951812
Validation loss: 3.0072989186348247

Epoch: 5| Step: 11
Training loss: 0.25146462153452714
Validation loss: 2.824138153037663

Epoch: 164| Step: 0
Training loss: 1.0425136301809963
Validation loss: 3.025622371091162

Epoch: 5| Step: 1
Training loss: 0.8903049764050843
Validation loss: 2.9451810164915226

Epoch: 5| Step: 2
Training loss: 1.364616854695157
Validation loss: 2.951305515133934

Epoch: 5| Step: 3
Training loss: 0.9439691819579485
Validation loss: 2.9025707575387325

Epoch: 5| Step: 4
Training loss: 0.7233194967637043
Validation loss: 3.057231230953477

Epoch: 5| Step: 5
Training loss: 0.9254007322017889
Validation loss: 2.9774193819440016

Epoch: 5| Step: 6
Training loss: 1.709934794314893
Validation loss: 2.847117536579316

Epoch: 5| Step: 7
Training loss: 0.7034503819672769
Validation loss: 2.8704382496302614

Epoch: 5| Step: 8
Training loss: 0.6402971778030553
Validation loss: 2.9236584216830743

Epoch: 5| Step: 9
Training loss: 1.1519686330823118
Validation loss: 2.953021301655597

Epoch: 5| Step: 10
Training loss: 1.2667303086070265
Validation loss: 2.9982546292203547

Epoch: 5| Step: 11
Training loss: 0.7878933166548711
Validation loss: 2.9199753193977127

Epoch: 165| Step: 0
Training loss: 1.0000758142342552
Validation loss: 2.8947414162305347

Epoch: 5| Step: 1
Training loss: 1.5304259593642378
Validation loss: 2.9483561250029613

Epoch: 5| Step: 2
Training loss: 0.8956404559657909
Validation loss: 2.905756529064797

Epoch: 5| Step: 3
Training loss: 1.1648508768867847
Validation loss: 2.9764783151491256

Epoch: 5| Step: 4
Training loss: 0.9018448280156983
Validation loss: 2.9775993630490207

Epoch: 5| Step: 5
Training loss: 1.2235229637725331
Validation loss: 2.954299437566205

Epoch: 5| Step: 6
Training loss: 0.817546723223401
Validation loss: 2.9379321044298425

Epoch: 5| Step: 7
Training loss: 1.1672588729995028
Validation loss: 2.922191657112784

Epoch: 5| Step: 8
Training loss: 0.8817945029155088
Validation loss: 3.0347300966326998

Epoch: 5| Step: 9
Training loss: 1.7728953604159425
Validation loss: 2.974986118663598

Epoch: 5| Step: 10
Training loss: 1.1844485378333813
Validation loss: 2.8998254021888155

Epoch: 5| Step: 11
Training loss: 1.1515588705970992
Validation loss: 3.04486873466966

Epoch: 166| Step: 0
Training loss: 0.9054670569179396
Validation loss: 2.8903580482180584

Epoch: 5| Step: 1
Training loss: 0.8575358043569314
Validation loss: 2.9001918223671725

Epoch: 5| Step: 2
Training loss: 0.7376737971724705
Validation loss: 2.9927256094494425

Epoch: 5| Step: 3
Training loss: 1.0665690538823653
Validation loss: 2.9695490012858947

Epoch: 5| Step: 4
Training loss: 1.8381657490758117
Validation loss: 3.1162952749199953

Epoch: 5| Step: 5
Training loss: 1.2327295756523111
Validation loss: 3.098069511769853

Epoch: 5| Step: 6
Training loss: 1.3886759096669148
Validation loss: 2.9942430452570363

Epoch: 5| Step: 7
Training loss: 1.2421091882744058
Validation loss: 2.877841992569028

Epoch: 5| Step: 8
Training loss: 0.9795737874355472
Validation loss: 2.9626595413932506

Epoch: 5| Step: 9
Training loss: 0.8970347192481577
Validation loss: 3.0014523494061787

Epoch: 5| Step: 10
Training loss: 0.7687985180066459
Validation loss: 3.0924211852942793

Epoch: 5| Step: 11
Training loss: 1.5833520720862078
Validation loss: 2.9812857731686186

Epoch: 167| Step: 0
Training loss: 0.9426460491420761
Validation loss: 3.041611479341302

Epoch: 5| Step: 1
Training loss: 1.2664548249197924
Validation loss: 3.060948575778543

Epoch: 5| Step: 2
Training loss: 1.0055962375773813
Validation loss: 2.8796217023784214

Epoch: 5| Step: 3
Training loss: 1.2096919883855648
Validation loss: 2.973897934460088

Epoch: 5| Step: 4
Training loss: 0.8378634859682853
Validation loss: 3.019558582782616

Epoch: 5| Step: 5
Training loss: 1.0034611527926127
Validation loss: 2.987729844890864

Epoch: 5| Step: 6
Training loss: 0.8607120862682848
Validation loss: 3.004035923758687

Epoch: 5| Step: 7
Training loss: 0.8403885604579128
Validation loss: 2.964486182241267

Epoch: 5| Step: 8
Training loss: 1.364696478581576
Validation loss: 3.025676978892152

Epoch: 5| Step: 9
Training loss: 1.9604749399970522
Validation loss: 2.9804890483199995

Epoch: 5| Step: 10
Training loss: 0.924227348023226
Validation loss: 3.1708178582902025

Epoch: 5| Step: 11
Training loss: 0.8264624262840544
Validation loss: 2.9695270424893065

Epoch: 168| Step: 0
Training loss: 1.0853965015454106
Validation loss: 3.0649270541548033

Epoch: 5| Step: 1
Training loss: 1.0643553522685503
Validation loss: 3.0061232542097693

Epoch: 5| Step: 2
Training loss: 0.8200027971103692
Validation loss: 2.9984873627211943

Epoch: 5| Step: 3
Training loss: 0.809915687505755
Validation loss: 2.8952586829667926

Epoch: 5| Step: 4
Training loss: 1.218553331597233
Validation loss: 3.0734124748117475

Epoch: 5| Step: 5
Training loss: 1.221254709365495
Validation loss: 2.8884526105694115

Epoch: 5| Step: 6
Training loss: 1.187949798123744
Validation loss: 2.9294994616032968

Epoch: 5| Step: 7
Training loss: 1.7158690843505884
Validation loss: 3.1120129773632224

Epoch: 5| Step: 8
Training loss: 1.1214240248920306
Validation loss: 3.0300596888961056

Epoch: 5| Step: 9
Training loss: 1.0046466516523154
Validation loss: 3.0153235876165687

Epoch: 5| Step: 10
Training loss: 1.4665476743516523
Validation loss: 3.0737934941341374

Epoch: 5| Step: 11
Training loss: 0.41438615493374303
Validation loss: 3.00801202351728

Epoch: 169| Step: 0
Training loss: 1.0858891428328012
Validation loss: 2.927739081231581

Epoch: 5| Step: 1
Training loss: 1.8401571926060436
Validation loss: 2.919370529872636

Epoch: 5| Step: 2
Training loss: 1.3647960564982338
Validation loss: 3.016714199141301

Epoch: 5| Step: 3
Training loss: 1.0653278081839765
Validation loss: 2.9041639792285308

Epoch: 5| Step: 4
Training loss: 1.114644069739942
Validation loss: 2.9896933416846005

Epoch: 5| Step: 5
Training loss: 1.222319096401107
Validation loss: 3.002226824290622

Epoch: 5| Step: 6
Training loss: 0.920225380885064
Validation loss: 3.072962157133645

Epoch: 5| Step: 7
Training loss: 1.0495245129401833
Validation loss: 3.070592124960198

Epoch: 5| Step: 8
Training loss: 0.6329497671188214
Validation loss: 2.9704800065735464

Epoch: 5| Step: 9
Training loss: 0.8596077343769846
Validation loss: 3.0367094768136904

Epoch: 5| Step: 10
Training loss: 1.1399355855946927
Validation loss: 2.9884700208558725

Epoch: 5| Step: 11
Training loss: 1.0808592691204322
Validation loss: 2.967614046908508

Epoch: 170| Step: 0
Training loss: 0.8752093064786215
Validation loss: 3.08538753260514

Epoch: 5| Step: 1
Training loss: 0.8392436877920377
Validation loss: 3.0060996624054868

Epoch: 5| Step: 2
Training loss: 0.8204703769438869
Validation loss: 2.9845114039327134

Epoch: 5| Step: 3
Training loss: 1.127178149838926
Validation loss: 2.906630378359551

Epoch: 5| Step: 4
Training loss: 1.0153420274173997
Validation loss: 2.968533293862419

Epoch: 5| Step: 5
Training loss: 0.6979257146524014
Validation loss: 2.997292386194087

Epoch: 5| Step: 6
Training loss: 1.257774305059883
Validation loss: 2.8589288158450117

Epoch: 5| Step: 7
Training loss: 1.8659798775024394
Validation loss: 2.9479401298820327

Epoch: 5| Step: 8
Training loss: 1.000594320118788
Validation loss: 2.9124388274943716

Epoch: 5| Step: 9
Training loss: 0.9175051878177004
Validation loss: 3.01033494875828

Epoch: 5| Step: 10
Training loss: 1.163953942478998
Validation loss: 3.0308215864326398

Epoch: 5| Step: 11
Training loss: 0.8578594368633636
Validation loss: 3.0494222931590054

Epoch: 171| Step: 0
Training loss: 1.0294034204224984
Validation loss: 3.0239024466040254

Epoch: 5| Step: 1
Training loss: 0.9922386817046326
Validation loss: 2.9301138266737192

Epoch: 5| Step: 2
Training loss: 1.8249863637127337
Validation loss: 3.017222697735722

Epoch: 5| Step: 3
Training loss: 1.1308704962043559
Validation loss: 2.931896455239416

Epoch: 5| Step: 4
Training loss: 0.9826792385562213
Validation loss: 3.0403233211530085

Epoch: 5| Step: 5
Training loss: 0.8974373599536563
Validation loss: 2.9101067080110403

Epoch: 5| Step: 6
Training loss: 0.6998954354253032
Validation loss: 3.0755374250144794

Epoch: 5| Step: 7
Training loss: 0.9672283404329203
Validation loss: 3.0227071880545497

Epoch: 5| Step: 8
Training loss: 1.3501889078989076
Validation loss: 2.992378119231025

Epoch: 5| Step: 9
Training loss: 1.0446677781370766
Validation loss: 3.000471544956248

Epoch: 5| Step: 10
Training loss: 1.1281107175139542
Validation loss: 3.0576059005563097

Epoch: 5| Step: 11
Training loss: 0.9790302073306241
Validation loss: 3.029633599035132

Epoch: 172| Step: 0
Training loss: 0.9662373474595521
Validation loss: 2.9989719980627934

Epoch: 5| Step: 1
Training loss: 0.8120379968406579
Validation loss: 2.9188646492778285

Epoch: 5| Step: 2
Training loss: 1.7948907262114642
Validation loss: 2.969842475519813

Epoch: 5| Step: 3
Training loss: 0.9713236554273939
Validation loss: 2.9981690024685026

Epoch: 5| Step: 4
Training loss: 0.9233186377435781
Validation loss: 3.0813285661576186

Epoch: 5| Step: 5
Training loss: 1.0623803912886747
Validation loss: 3.0497543684226125

Epoch: 5| Step: 6
Training loss: 0.9441631675873103
Validation loss: 3.0080336419261373

Epoch: 5| Step: 7
Training loss: 0.8852833292174983
Validation loss: 2.9912499767632386

Epoch: 5| Step: 8
Training loss: 1.2813114058503525
Validation loss: 2.997052652226805

Epoch: 5| Step: 9
Training loss: 0.9215363349188259
Validation loss: 2.936911669448974

Epoch: 5| Step: 10
Training loss: 0.8395792344957989
Validation loss: 2.9786720843469343

Epoch: 5| Step: 11
Training loss: 0.4624056146298567
Validation loss: 2.913760853990882

Epoch: 173| Step: 0
Training loss: 0.8380310723386745
Validation loss: 2.9549817029404823

Epoch: 5| Step: 1
Training loss: 0.7546377635544315
Validation loss: 2.96786649172524

Epoch: 5| Step: 2
Training loss: 0.5892551086990893
Validation loss: 2.86210441951636

Epoch: 5| Step: 3
Training loss: 0.8303142615641671
Validation loss: 2.88506058562653

Epoch: 5| Step: 4
Training loss: 0.9721599063127038
Validation loss: 3.0033058753771282

Epoch: 5| Step: 5
Training loss: 1.3768722185755276
Validation loss: 3.0392103249130398

Epoch: 5| Step: 6
Training loss: 1.0122183372650053
Validation loss: 3.04118642325322

Epoch: 5| Step: 7
Training loss: 0.8987122157169806
Validation loss: 2.977116197031387

Epoch: 5| Step: 8
Training loss: 0.8751424264795135
Validation loss: 3.0005547520532985

Epoch: 5| Step: 9
Training loss: 1.243942604295583
Validation loss: 3.079885840839322

Epoch: 5| Step: 10
Training loss: 1.8854261436715989
Validation loss: 3.02783374061448

Epoch: 5| Step: 11
Training loss: 0.5948485200859541
Validation loss: 3.042558439158997

Epoch: 174| Step: 0
Training loss: 0.958217337402242
Validation loss: 2.9626820372868905

Epoch: 5| Step: 1
Training loss: 0.910270192622982
Validation loss: 3.027026970809663

Epoch: 5| Step: 2
Training loss: 0.8297124079469482
Validation loss: 2.942996098224466

Epoch: 5| Step: 3
Training loss: 1.0132286558126753
Validation loss: 2.975020395470812

Epoch: 5| Step: 4
Training loss: 0.7322389908389849
Validation loss: 2.9497707465096092

Epoch: 5| Step: 5
Training loss: 0.9931419767701641
Validation loss: 3.0374595546515266

Epoch: 5| Step: 6
Training loss: 1.2955056280045514
Validation loss: 2.823424312417906

Epoch: 5| Step: 7
Training loss: 1.761164135975357
Validation loss: 2.9248070650510303

Epoch: 5| Step: 8
Training loss: 0.9473782816486671
Validation loss: 2.9897771079148185

Epoch: 5| Step: 9
Training loss: 0.8366548544086615
Validation loss: 2.92472012694261

Epoch: 5| Step: 10
Training loss: 1.0805364536524504
Validation loss: 2.9860465576281574

Epoch: 5| Step: 11
Training loss: 1.8106156123177686
Validation loss: 2.9413555034500174

Epoch: 175| Step: 0
Training loss: 0.7331253945430074
Validation loss: 2.9949441666406

Epoch: 5| Step: 1
Training loss: 0.9859220972082218
Validation loss: 2.8877652567998546

Epoch: 5| Step: 2
Training loss: 0.7992245686040521
Validation loss: 3.002718462041073

Epoch: 5| Step: 3
Training loss: 0.8376288727632503
Validation loss: 3.0471307630867184

Epoch: 5| Step: 4
Training loss: 2.025213927283591
Validation loss: 3.0752591509798526

Epoch: 5| Step: 5
Training loss: 0.9800288516780041
Validation loss: 3.062459536693836

Epoch: 5| Step: 6
Training loss: 0.6525931880805843
Validation loss: 2.982119618413122

Epoch: 5| Step: 7
Training loss: 0.7996024783255874
Validation loss: 2.9865101171890887

Epoch: 5| Step: 8
Training loss: 0.9291138361692921
Validation loss: 2.9935485758809994

Epoch: 5| Step: 9
Training loss: 1.0644461815283859
Validation loss: 3.095122890066359

Epoch: 5| Step: 10
Training loss: 0.661781680054603
Validation loss: 2.922525513665156

Epoch: 5| Step: 11
Training loss: 1.4190736779514268
Validation loss: 2.9882525241111058

Epoch: 176| Step: 0
Training loss: 0.7632078434172245
Validation loss: 3.037814971961541

Epoch: 5| Step: 1
Training loss: 1.4472675194772942
Validation loss: 3.0740045636866458

Epoch: 5| Step: 2
Training loss: 1.0170028729918643
Validation loss: 3.0777313122663683

Epoch: 5| Step: 3
Training loss: 0.8600688907288003
Validation loss: 3.0696355867829452

Epoch: 5| Step: 4
Training loss: 1.1095500861608933
Validation loss: 3.0263254335716794

Epoch: 5| Step: 5
Training loss: 0.9898129983052731
Validation loss: 3.1600857645480147

Epoch: 5| Step: 6
Training loss: 1.0549329683965984
Validation loss: 2.9995905245704324

Epoch: 5| Step: 7
Training loss: 1.8956588063934285
Validation loss: 2.9180153430655618

Epoch: 5| Step: 8
Training loss: 0.8225106714594114
Validation loss: 2.9520563651131604

Epoch: 5| Step: 9
Training loss: 0.9936199810934538
Validation loss: 2.972038034325352

Epoch: 5| Step: 10
Training loss: 1.1555232779924258
Validation loss: 3.018169423330227

Epoch: 5| Step: 11
Training loss: 0.7662820915733101
Validation loss: 2.941148058471234

Epoch: 177| Step: 0
Training loss: 1.0103734914987146
Validation loss: 2.9736620972041687

Epoch: 5| Step: 1
Training loss: 0.7543524572991205
Validation loss: 3.009500840521325

Epoch: 5| Step: 2
Training loss: 1.2009826014812492
Validation loss: 2.92134094117403

Epoch: 5| Step: 3
Training loss: 0.8955945354639118
Validation loss: 3.1079197326336816

Epoch: 5| Step: 4
Training loss: 1.6888457689441383
Validation loss: 3.003360468868517

Epoch: 5| Step: 5
Training loss: 1.0150769442252907
Validation loss: 3.015064780423439

Epoch: 5| Step: 6
Training loss: 1.1176125844784857
Validation loss: 3.0653113416965843

Epoch: 5| Step: 7
Training loss: 0.9060282600365864
Validation loss: 3.007683854427675

Epoch: 5| Step: 8
Training loss: 0.9963669047095586
Validation loss: 3.026752638994466

Epoch: 5| Step: 9
Training loss: 1.1404108342857942
Validation loss: 3.0398937484301305

Epoch: 5| Step: 10
Training loss: 0.780655023991588
Validation loss: 3.1253928827634323

Epoch: 5| Step: 11
Training loss: 0.28095855447291945
Validation loss: 3.1099528633544233

Epoch: 178| Step: 0
Training loss: 0.8641595644522602
Validation loss: 2.9929198920021767

Epoch: 5| Step: 1
Training loss: 1.2863206313511844
Validation loss: 3.03670814864959

Epoch: 5| Step: 2
Training loss: 0.8413180872668805
Validation loss: 3.019674836462855

Epoch: 5| Step: 3
Training loss: 1.4025049143550403
Validation loss: 2.9660107238828175

Epoch: 5| Step: 4
Training loss: 0.9625012459684952
Validation loss: 2.9563885204022204

Epoch: 5| Step: 5
Training loss: 1.9233863904346364
Validation loss: 2.951302680956836

Epoch: 5| Step: 6
Training loss: 0.7403149321915884
Validation loss: 2.9823918402491207

Epoch: 5| Step: 7
Training loss: 0.8728508441176908
Validation loss: 3.0766625149319315

Epoch: 5| Step: 8
Training loss: 0.6617327493855389
Validation loss: 3.109981282868848

Epoch: 5| Step: 9
Training loss: 0.8803444856757937
Validation loss: 2.8774612678961367

Epoch: 5| Step: 10
Training loss: 0.8748084948644891
Validation loss: 3.046724113575581

Epoch: 5| Step: 11
Training loss: 0.74956408389193
Validation loss: 3.0392512709854036

Epoch: 179| Step: 0
Training loss: 0.8662046412913261
Validation loss: 2.9669477948829983

Epoch: 5| Step: 1
Training loss: 1.078552714106985
Validation loss: 3.0025709282170423

Epoch: 5| Step: 2
Training loss: 1.8905402550738473
Validation loss: 3.104563346368059

Epoch: 5| Step: 3
Training loss: 0.8930502880179052
Validation loss: 3.107981508549186

Epoch: 5| Step: 4
Training loss: 0.8664172420371994
Validation loss: 3.1196355902723156

Epoch: 5| Step: 5
Training loss: 1.2385760897939821
Validation loss: 3.0483274470279924

Epoch: 5| Step: 6
Training loss: 0.8757741092387368
Validation loss: 3.1390334852544526

Epoch: 5| Step: 7
Training loss: 1.4030261066479373
Validation loss: 3.0048898608588184

Epoch: 5| Step: 8
Training loss: 0.9290524726170007
Validation loss: 2.953627208950784

Epoch: 5| Step: 9
Training loss: 0.5186934348370267
Validation loss: 3.0854946317659513

Epoch: 5| Step: 10
Training loss: 0.909804575026123
Validation loss: 3.0116006091638057

Epoch: 5| Step: 11
Training loss: 0.9137443901860444
Validation loss: 2.9448286176768947

Epoch: 180| Step: 0
Training loss: 0.7576303951472247
Validation loss: 2.984178360191117

Epoch: 5| Step: 1
Training loss: 1.0419341824661625
Validation loss: 2.950963108665712

Epoch: 5| Step: 2
Training loss: 0.9444673085873347
Validation loss: 3.015877787218566

Epoch: 5| Step: 3
Training loss: 1.0340263678105084
Validation loss: 2.878611480101154

Epoch: 5| Step: 4
Training loss: 1.1397265200764133
Validation loss: 2.9710665649165415

Epoch: 5| Step: 5
Training loss: 0.6245365808949922
Validation loss: 2.963466979674006

Epoch: 5| Step: 6
Training loss: 0.6359101057596057
Validation loss: 2.909623526131185

Epoch: 5| Step: 7
Training loss: 0.8673078436300766
Validation loss: 2.9480023163842874

Epoch: 5| Step: 8
Training loss: 1.2387365713459833
Validation loss: 2.9782470548688793

Epoch: 5| Step: 9
Training loss: 0.7425331114119568
Validation loss: 2.9052887526677473

Epoch: 5| Step: 10
Training loss: 1.6888283340504089
Validation loss: 3.0062448354823426

Epoch: 5| Step: 11
Training loss: 0.6638760922163848
Validation loss: 3.074577617582223

Epoch: 181| Step: 0
Training loss: 1.1228079632933663
Validation loss: 2.9581684158366306

Epoch: 5| Step: 1
Training loss: 1.1093112766070634
Validation loss: 3.027536795419062

Epoch: 5| Step: 2
Training loss: 1.1446035837484296
Validation loss: 3.0068988320608714

Epoch: 5| Step: 3
Training loss: 0.8513095024923741
Validation loss: 3.008715427169936

Epoch: 5| Step: 4
Training loss: 0.5977255338514308
Validation loss: 2.994053311203964

Epoch: 5| Step: 5
Training loss: 0.8813652734237356
Validation loss: 2.9309790582974875

Epoch: 5| Step: 6
Training loss: 1.0888484115008132
Validation loss: 2.9179329382670476

Epoch: 5| Step: 7
Training loss: 0.8977326655253337
Validation loss: 3.0120607619777364

Epoch: 5| Step: 8
Training loss: 0.9627507787209499
Validation loss: 2.9968454312432735

Epoch: 5| Step: 9
Training loss: 1.785227367228277
Validation loss: 3.026556645277587

Epoch: 5| Step: 10
Training loss: 1.0257572935376411
Validation loss: 3.1496957642102745

Epoch: 5| Step: 11
Training loss: 0.8943937104278684
Validation loss: 2.9788120476645865

Epoch: 182| Step: 0
Training loss: 0.8167201629620611
Validation loss: 3.0324596206941226

Epoch: 5| Step: 1
Training loss: 0.7939616033893296
Validation loss: 3.0499964448251484

Epoch: 5| Step: 2
Training loss: 0.8394756131290844
Validation loss: 3.004826451482659

Epoch: 5| Step: 3
Training loss: 1.8876219931077662
Validation loss: 2.9445923212293064

Epoch: 5| Step: 4
Training loss: 0.9284963911517402
Validation loss: 2.980101776529217

Epoch: 5| Step: 5
Training loss: 1.2533549585319879
Validation loss: 3.0476607589212428

Epoch: 5| Step: 6
Training loss: 0.9113172730782038
Validation loss: 3.083927990730343

Epoch: 5| Step: 7
Training loss: 0.9637620553575057
Validation loss: 3.0132360071068187

Epoch: 5| Step: 8
Training loss: 0.7835932114543186
Validation loss: 3.049859171753349

Epoch: 5| Step: 9
Training loss: 0.7272020212124389
Validation loss: 3.0112007114487938

Epoch: 5| Step: 10
Training loss: 0.88499346698354
Validation loss: 2.950282186815702

Epoch: 5| Step: 11
Training loss: 0.5268192932889307
Validation loss: 3.131716180440083

Epoch: 183| Step: 0
Training loss: 1.7700154902971115
Validation loss: 3.1525899545922815

Epoch: 5| Step: 1
Training loss: 0.9095929739932362
Validation loss: 2.9683394365678084

Epoch: 5| Step: 2
Training loss: 0.7013317765273316
Validation loss: 2.9040588643951524

Epoch: 5| Step: 3
Training loss: 0.8199748116206694
Validation loss: 2.9627727735731755

Epoch: 5| Step: 4
Training loss: 0.7584443358689712
Validation loss: 3.118856720891745

Epoch: 5| Step: 5
Training loss: 0.7992305721180478
Validation loss: 2.9947336384776673

Epoch: 5| Step: 6
Training loss: 1.0532327862828499
Validation loss: 3.011145728947667

Epoch: 5| Step: 7
Training loss: 0.9114565422403812
Validation loss: 2.980060491102613

Epoch: 5| Step: 8
Training loss: 0.9455992208674492
Validation loss: 2.9029403148717443

Epoch: 5| Step: 9
Training loss: 1.1549679117575675
Validation loss: 3.084105096491218

Epoch: 5| Step: 10
Training loss: 0.6595988657438451
Validation loss: 3.030367155733171

Epoch: 5| Step: 11
Training loss: 1.5323624754242244
Validation loss: 3.1511891995195676

Epoch: 184| Step: 0
Training loss: 0.7528885212886973
Validation loss: 3.076385396984598

Epoch: 5| Step: 1
Training loss: 0.8602302110630289
Validation loss: 2.923239577998168

Epoch: 5| Step: 2
Training loss: 0.9423859116893664
Validation loss: 2.90234809693755

Epoch: 5| Step: 3
Training loss: 0.8171544639080341
Validation loss: 3.0503691567129456

Epoch: 5| Step: 4
Training loss: 0.7333567844961596
Validation loss: 3.106708456704525

Epoch: 5| Step: 5
Training loss: 1.8661571516892743
Validation loss: 2.8810791138720417

Epoch: 5| Step: 6
Training loss: 0.6760152290437421
Validation loss: 3.00964225501344

Epoch: 5| Step: 7
Training loss: 1.1965689444598775
Validation loss: 3.0588498128120296

Epoch: 5| Step: 8
Training loss: 0.7133625715345172
Validation loss: 2.9316151020820547

Epoch: 5| Step: 9
Training loss: 0.8150122756267554
Validation loss: 2.939791874255108

Epoch: 5| Step: 10
Training loss: 0.9360096211101957
Validation loss: 2.9095499281804984

Epoch: 5| Step: 11
Training loss: 0.7805487728239004
Validation loss: 2.9490317582224574

Epoch: 185| Step: 0
Training loss: 0.8886334421419796
Validation loss: 3.0473225028556246

Epoch: 5| Step: 1
Training loss: 1.9125176871485414
Validation loss: 2.973827824621178

Epoch: 5| Step: 2
Training loss: 0.9972712419876915
Validation loss: 2.883191983988262

Epoch: 5| Step: 3
Training loss: 0.8655737562194813
Validation loss: 2.9632546945728513

Epoch: 5| Step: 4
Training loss: 0.850931686398319
Validation loss: 2.9650182861098755

Epoch: 5| Step: 5
Training loss: 1.0086402746413312
Validation loss: 2.9987692792017504

Epoch: 5| Step: 6
Training loss: 0.8926969152823518
Validation loss: 2.9100010568085946

Epoch: 5| Step: 7
Training loss: 0.7224406977672744
Validation loss: 3.0355524747930462

Epoch: 5| Step: 8
Training loss: 0.775002677974381
Validation loss: 3.083767168780446

Epoch: 5| Step: 9
Training loss: 0.7992384400091063
Validation loss: 2.9479680152347996

Epoch: 5| Step: 10
Training loss: 0.8325569748498626
Validation loss: 2.9928757164088657

Epoch: 5| Step: 11
Training loss: 1.0743096330517783
Validation loss: 2.995256873224348

Epoch: 186| Step: 0
Training loss: 0.7611846616419419
Validation loss: 3.0042607760051343

Epoch: 5| Step: 1
Training loss: 1.0086042266230666
Validation loss: 2.939200953822664

Epoch: 5| Step: 2
Training loss: 1.0486118654889782
Validation loss: 3.0645937866060318

Epoch: 5| Step: 3
Training loss: 1.283988816613667
Validation loss: 3.119323518089122

Epoch: 5| Step: 4
Training loss: 1.1798973654708464
Validation loss: 3.09574923155071

Epoch: 5| Step: 5
Training loss: 0.9042871198684144
Validation loss: 3.0869343946125825

Epoch: 5| Step: 6
Training loss: 1.0756403723443377
Validation loss: 2.9937522355922774

Epoch: 5| Step: 7
Training loss: 0.9089983996008958
Validation loss: 2.9783412828127656

Epoch: 5| Step: 8
Training loss: 0.5476048639980107
Validation loss: 3.0849297499682757

Epoch: 5| Step: 9
Training loss: 0.9426347623045632
Validation loss: 3.1962347401898796

Epoch: 5| Step: 10
Training loss: 1.76123818484933
Validation loss: 3.066699936848688

Epoch: 5| Step: 11
Training loss: 0.8362407668991024
Validation loss: 2.980682502037806

Epoch: 187| Step: 0
Training loss: 1.2919996611709859
Validation loss: 3.171179978716954

Epoch: 5| Step: 1
Training loss: 0.9085837602271184
Validation loss: 2.921008765321

Epoch: 5| Step: 2
Training loss: 0.993853124629912
Validation loss: 2.9456826710156316

Epoch: 5| Step: 3
Training loss: 0.8318447924946736
Validation loss: 3.071887174668219

Epoch: 5| Step: 4
Training loss: 0.778653216034625
Validation loss: 3.0403391453769992

Epoch: 5| Step: 5
Training loss: 0.7346421019799753
Validation loss: 3.015631258995927

Epoch: 5| Step: 6
Training loss: 1.2223537180466217
Validation loss: 2.9944540889494635

Epoch: 5| Step: 7
Training loss: 1.8804959176751281
Validation loss: 3.1069553999370636

Epoch: 5| Step: 8
Training loss: 0.9068684605179295
Validation loss: 3.046486482547364

Epoch: 5| Step: 9
Training loss: 0.6194402408979919
Validation loss: 3.1247347973507313

Epoch: 5| Step: 10
Training loss: 0.6246452755418914
Validation loss: 2.8475991597882615

Epoch: 5| Step: 11
Training loss: 0.3926713937069817
Validation loss: 3.0737332482157473

Epoch: 188| Step: 0
Training loss: 1.2805000994919482
Validation loss: 3.0171056383703894

Epoch: 5| Step: 1
Training loss: 0.854601346264258
Validation loss: 3.00236346274489

Epoch: 5| Step: 2
Training loss: 0.6673991356768911
Validation loss: 2.9743702342136884

Epoch: 5| Step: 3
Training loss: 0.6637813870683209
Validation loss: 2.979265339202117

Epoch: 5| Step: 4
Training loss: 1.2004109275086603
Validation loss: 3.011221957268152

Epoch: 5| Step: 5
Training loss: 1.7286705852811812
Validation loss: 2.969345026450422

Epoch: 5| Step: 6
Training loss: 0.9311180008394608
Validation loss: 2.944042576250478

Epoch: 5| Step: 7
Training loss: 1.0771478841439535
Validation loss: 3.018681958223493

Epoch: 5| Step: 8
Training loss: 0.6902727868748061
Validation loss: 3.0733347215066646

Epoch: 5| Step: 9
Training loss: 1.0026499684098242
Validation loss: 3.1068951863515784

Epoch: 5| Step: 10
Training loss: 0.7732452770228282
Validation loss: 3.1125265217357105

Epoch: 5| Step: 11
Training loss: 0.7780690092601565
Validation loss: 3.001944497864835

Epoch: 189| Step: 0
Training loss: 0.7815710552468785
Validation loss: 2.918277722418339

Epoch: 5| Step: 1
Training loss: 0.8008429526771151
Validation loss: 2.96675291985235

Epoch: 5| Step: 2
Training loss: 0.8626757954001957
Validation loss: 3.132418543524492

Epoch: 5| Step: 3
Training loss: 0.9073723059000836
Validation loss: 3.0973427554959665

Epoch: 5| Step: 4
Training loss: 1.2062875376182438
Validation loss: 2.8060310921250378

Epoch: 5| Step: 5
Training loss: 0.8204710670893244
Validation loss: 3.0309041537119317

Epoch: 5| Step: 6
Training loss: 0.7039873133648735
Validation loss: 2.978474607758473

Epoch: 5| Step: 7
Training loss: 0.9328745861254453
Validation loss: 3.054017610585963

Epoch: 5| Step: 8
Training loss: 1.6577853158345341
Validation loss: 3.0551207219769925

Epoch: 5| Step: 9
Training loss: 1.1601411452417911
Validation loss: 3.0429213638109225

Epoch: 5| Step: 10
Training loss: 1.1276913345627755
Validation loss: 3.050337700179717

Epoch: 5| Step: 11
Training loss: 0.6021765015354426
Validation loss: 2.884152501576742

Epoch: 190| Step: 0
Training loss: 0.745563858160182
Validation loss: 2.962253207779737

Epoch: 5| Step: 1
Training loss: 0.6060387174399713
Validation loss: 2.937381099431884

Epoch: 5| Step: 2
Training loss: 0.7657734863161678
Validation loss: 2.9827954537764003

Epoch: 5| Step: 3
Training loss: 1.7143065842992973
Validation loss: 2.8626950276664807

Epoch: 5| Step: 4
Training loss: 1.2260379033880349
Validation loss: 2.842095907062597

Epoch: 5| Step: 5
Training loss: 1.0658786013258181
Validation loss: 3.0180950392816364

Epoch: 5| Step: 6
Training loss: 0.8847506018704202
Validation loss: 2.9744785452893105

Epoch: 5| Step: 7
Training loss: 0.8128527462450346
Validation loss: 2.9751354010407254

Epoch: 5| Step: 8
Training loss: 0.8469937455938344
Validation loss: 3.1533268337471765

Epoch: 5| Step: 9
Training loss: 0.8312697171619093
Validation loss: 2.9904845548555232

Epoch: 5| Step: 10
Training loss: 0.7580923369966989
Validation loss: 2.9582636225013386

Epoch: 5| Step: 11
Training loss: 0.6781777901911047
Validation loss: 3.0329698979371953

Epoch: 191| Step: 0
Training loss: 0.9062785768936116
Validation loss: 2.9253308739411312

Epoch: 5| Step: 1
Training loss: 0.5274025778276721
Validation loss: 3.0300882413812547

Epoch: 5| Step: 2
Training loss: 0.9674994487908738
Validation loss: 2.877778403874513

Epoch: 5| Step: 3
Training loss: 1.1384045138149619
Validation loss: 3.013905211056305

Epoch: 5| Step: 4
Training loss: 0.7899921719247749
Validation loss: 3.046933706647216

Epoch: 5| Step: 5
Training loss: 0.8215690797677974
Validation loss: 3.002094415215805

Epoch: 5| Step: 6
Training loss: 0.7182241672473729
Validation loss: 2.946993866482071

Epoch: 5| Step: 7
Training loss: 1.705559207126769
Validation loss: 3.0487192261964697

Epoch: 5| Step: 8
Training loss: 0.8159954735078739
Validation loss: 3.0613660042827764

Epoch: 5| Step: 9
Training loss: 0.7135362601713491
Validation loss: 2.940969893269303

Epoch: 5| Step: 10
Training loss: 0.9141189036124958
Validation loss: 3.00524876642822

Epoch: 5| Step: 11
Training loss: 1.5366677955049572
Validation loss: 3.126854174809757

Epoch: 192| Step: 0
Training loss: 0.7578308653818213
Validation loss: 3.0576339618876993

Epoch: 5| Step: 1
Training loss: 0.8029277410833902
Validation loss: 2.9162751559477735

Epoch: 5| Step: 2
Training loss: 0.879725536384626
Validation loss: 3.0184115052241784

Epoch: 5| Step: 3
Training loss: 1.051953537491506
Validation loss: 3.01734530014697

Epoch: 5| Step: 4
Training loss: 0.7000672291079219
Validation loss: 2.9665435354704286

Epoch: 5| Step: 5
Training loss: 0.960154982365019
Validation loss: 3.019596824575501

Epoch: 5| Step: 6
Training loss: 1.7441384378485727
Validation loss: 3.104233655697447

Epoch: 5| Step: 7
Training loss: 0.9075941443673448
Validation loss: 2.9861508223877333

Epoch: 5| Step: 8
Training loss: 0.8988834103819582
Validation loss: 2.9625111762102923

Epoch: 5| Step: 9
Training loss: 1.0713014141194854
Validation loss: 2.9989776425647086

Epoch: 5| Step: 10
Training loss: 0.7134986270444902
Validation loss: 3.010125058096102

Epoch: 5| Step: 11
Training loss: 0.9889343576449456
Validation loss: 2.9761978486741802

Epoch: 193| Step: 0
Training loss: 0.7496478128045497
Validation loss: 2.9698353841224954

Epoch: 5| Step: 1
Training loss: 0.6890073637409662
Validation loss: 2.889522410939819

Epoch: 5| Step: 2
Training loss: 1.3621485685634132
Validation loss: 2.9865062287109896

Epoch: 5| Step: 3
Training loss: 0.9485468743243675
Validation loss: 3.0167772335177214

Epoch: 5| Step: 4
Training loss: 0.7807494658176086
Validation loss: 3.055132870024507

Epoch: 5| Step: 5
Training loss: 1.7285531422482132
Validation loss: 3.0997347374707567

Epoch: 5| Step: 6
Training loss: 0.7646934135529495
Validation loss: 2.904071442526568

Epoch: 5| Step: 7
Training loss: 1.1712434211147214
Validation loss: 2.9346044452732363

Epoch: 5| Step: 8
Training loss: 0.6624097339747084
Validation loss: 2.9880604963688397

Epoch: 5| Step: 9
Training loss: 0.8391059651118804
Validation loss: 2.9343255218624478

Epoch: 5| Step: 10
Training loss: 0.7913431878680118
Validation loss: 2.9372873905698293

Epoch: 5| Step: 11
Training loss: 0.4884876730416812
Validation loss: 2.8790895187173984

Epoch: 194| Step: 0
Training loss: 0.8065878640716406
Validation loss: 2.9777586094801163

Epoch: 5| Step: 1
Training loss: 0.8980369670200228
Validation loss: 2.8695886901318777

Epoch: 5| Step: 2
Training loss: 0.6714469521986467
Validation loss: 2.998899367215295

Epoch: 5| Step: 3
Training loss: 0.8236446098439805
Validation loss: 2.9000322662126035

Epoch: 5| Step: 4
Training loss: 1.1989006092660215
Validation loss: 2.8689447469825664

Epoch: 5| Step: 5
Training loss: 0.7705009276417292
Validation loss: 2.988970103267381

Epoch: 5| Step: 6
Training loss: 0.9770017932848056
Validation loss: 2.9246803694570622

Epoch: 5| Step: 7
Training loss: 0.9768752550941178
Validation loss: 2.9947632907131245

Epoch: 5| Step: 8
Training loss: 1.5739949637626918
Validation loss: 3.010930945787355

Epoch: 5| Step: 9
Training loss: 0.696703259299506
Validation loss: 2.9744099721117077

Epoch: 5| Step: 10
Training loss: 1.057516077338759
Validation loss: 2.8841982149810486

Epoch: 5| Step: 11
Training loss: 1.0832982546677918
Validation loss: 2.9310106129557734

Epoch: 195| Step: 0
Training loss: 1.0129614308387171
Validation loss: 2.9590599125955452

Epoch: 5| Step: 1
Training loss: 0.9277822702994495
Validation loss: 2.950499250305551

Epoch: 5| Step: 2
Training loss: 1.1268578130392028
Validation loss: 2.951167805313546

Epoch: 5| Step: 3
Training loss: 0.8513480800191869
Validation loss: 2.9402969788184814

Epoch: 5| Step: 4
Training loss: 0.5674847562145782
Validation loss: 2.9395772103007722

Epoch: 5| Step: 5
Training loss: 0.721906035445581
Validation loss: 2.9390666618905823

Epoch: 5| Step: 6
Training loss: 0.9288982278719682
Validation loss: 2.951512338761686

Epoch: 5| Step: 7
Training loss: 0.7502354014043153
Validation loss: 2.9148578632210396

Epoch: 5| Step: 8
Training loss: 0.7075780366516563
Validation loss: 2.951615952128418

Epoch: 5| Step: 9
Training loss: 0.802696134301469
Validation loss: 3.001360650915076

Epoch: 5| Step: 10
Training loss: 1.6904342007810922
Validation loss: 2.887552074827024

Epoch: 5| Step: 11
Training loss: 0.8643907003018076
Validation loss: 2.897638925524748

Epoch: 196| Step: 0
Training loss: 1.2042451573346384
Validation loss: 3.1017502792744445

Epoch: 5| Step: 1
Training loss: 0.6075152849699899
Validation loss: 2.916161038076982

Epoch: 5| Step: 2
Training loss: 0.7901296669741172
Validation loss: 2.9767600667271794

Epoch: 5| Step: 3
Training loss: 0.6587646534138683
Validation loss: 2.9894806360201507

Epoch: 5| Step: 4
Training loss: 0.6691161223032321
Validation loss: 3.0401443673977155

Epoch: 5| Step: 5
Training loss: 0.7423065491614694
Validation loss: 2.9186557640203445

Epoch: 5| Step: 6
Training loss: 0.8382723278982253
Validation loss: 3.0344597939175184

Epoch: 5| Step: 7
Training loss: 1.6002011351524268
Validation loss: 2.8978724241593143

Epoch: 5| Step: 8
Training loss: 1.066060272098174
Validation loss: 2.9144750069607706

Epoch: 5| Step: 9
Training loss: 0.7469009107620176
Validation loss: 2.9524174469990005

Epoch: 5| Step: 10
Training loss: 0.5699561325141557
Validation loss: 3.1273176690388818

Epoch: 5| Step: 11
Training loss: 1.1029596869467455
Validation loss: 3.0224691182376584

Epoch: 197| Step: 0
Training loss: 1.0832080157252442
Validation loss: 2.9648366332439906

Epoch: 5| Step: 1
Training loss: 0.6751409153961395
Validation loss: 3.041797636208448

Epoch: 5| Step: 2
Training loss: 0.9369143246063254
Validation loss: 3.0144618266692995

Epoch: 5| Step: 3
Training loss: 0.7169267916075454
Validation loss: 3.0322616435881624

Epoch: 5| Step: 4
Training loss: 1.7287198910466783
Validation loss: 2.9750943371964875

Epoch: 5| Step: 5
Training loss: 0.7596313044022933
Validation loss: 2.9929641067733073

Epoch: 5| Step: 6
Training loss: 0.9728596792474088
Validation loss: 3.0190654887268944

Epoch: 5| Step: 7
Training loss: 0.8404705104181817
Validation loss: 3.0474352851278126

Epoch: 5| Step: 8
Training loss: 0.7463947507832129
Validation loss: 2.889811537096338

Epoch: 5| Step: 9
Training loss: 0.7198097874467011
Validation loss: 2.9745244235095534

Epoch: 5| Step: 10
Training loss: 1.1019103130149803
Validation loss: 3.11325133535451

Epoch: 5| Step: 11
Training loss: 0.6755579982074313
Validation loss: 3.040173495030818

Epoch: 198| Step: 0
Training loss: 1.6399769547634355
Validation loss: 2.9370722831301372

Epoch: 5| Step: 1
Training loss: 0.8223122336617775
Validation loss: 3.076799878800853

Epoch: 5| Step: 2
Training loss: 1.0710759468185014
Validation loss: 2.900202988914065

Epoch: 5| Step: 3
Training loss: 0.6757446896580421
Validation loss: 2.9684014701376813

Epoch: 5| Step: 4
Training loss: 0.703483723155942
Validation loss: 2.972268184908592

Epoch: 5| Step: 5
Training loss: 0.8207776521944834
Validation loss: 3.0490814436097002

Epoch: 5| Step: 6
Training loss: 0.9095892060725606
Validation loss: 3.049169846681026

Epoch: 5| Step: 7
Training loss: 0.7698526631004422
Validation loss: 2.989762162410375

Epoch: 5| Step: 8
Training loss: 1.0143965701326514
Validation loss: 3.0104730671193867

Epoch: 5| Step: 9
Training loss: 0.769672671263104
Validation loss: 3.00290712260217

Epoch: 5| Step: 10
Training loss: 0.9501732316935954
Validation loss: 2.989797107129032

Epoch: 5| Step: 11
Training loss: 0.33133628144374205
Validation loss: 2.9206068819576427

Epoch: 199| Step: 0
Training loss: 0.7594162007524405
Validation loss: 2.863957275411149

Epoch: 5| Step: 1
Training loss: 1.84101690967757
Validation loss: 2.9382553955498567

Epoch: 5| Step: 2
Training loss: 0.6471228083425498
Validation loss: 2.9996465401910215

Epoch: 5| Step: 3
Training loss: 0.7772260413834589
Validation loss: 2.963149469946831

Epoch: 5| Step: 4
Training loss: 0.632472311816102
Validation loss: 2.967352792649994

Epoch: 5| Step: 5
Training loss: 0.7932923506988884
Validation loss: 2.9803868053765483

Epoch: 5| Step: 6
Training loss: 0.7467559751534012
Validation loss: 2.955413100138592

Epoch: 5| Step: 7
Training loss: 0.6203066799169439
Validation loss: 3.015701813452488

Epoch: 5| Step: 8
Training loss: 0.7979114001094493
Validation loss: 2.9559515153825715

Epoch: 5| Step: 9
Training loss: 0.6396151934422323
Validation loss: 2.9350401812678024

Epoch: 5| Step: 10
Training loss: 1.206932187258971
Validation loss: 2.9993216091946318

Epoch: 5| Step: 11
Training loss: 0.9607531362934524
Validation loss: 2.9370750058934982

Epoch: 200| Step: 0
Training loss: 0.7620477210543468
Validation loss: 2.9858137593828604

Epoch: 5| Step: 1
Training loss: 0.6946257939906488
Validation loss: 2.9593026941550504

Epoch: 5| Step: 2
Training loss: 0.6386789677310671
Validation loss: 3.0448824113462543

Epoch: 5| Step: 3
Training loss: 0.9637544482928777
Validation loss: 3.0932122093841086

Epoch: 5| Step: 4
Training loss: 0.685367267262377
Validation loss: 2.935765704748393

Epoch: 5| Step: 5
Training loss: 1.6821805683059077
Validation loss: 2.9548678864370137

Epoch: 5| Step: 6
Training loss: 1.1413666391255495
Validation loss: 3.030092791918964

Epoch: 5| Step: 7
Training loss: 0.8233180978333218
Validation loss: 3.047909474619691

Epoch: 5| Step: 8
Training loss: 0.6835104973369933
Validation loss: 3.0713884961195252

Epoch: 5| Step: 9
Training loss: 0.6571929605631727
Validation loss: 2.9609649844810586

Epoch: 5| Step: 10
Training loss: 0.7311815262385885
Validation loss: 3.0747960189680668

Epoch: 5| Step: 11
Training loss: 0.660470221982371
Validation loss: 3.164221002195761

Epoch: 201| Step: 0
Training loss: 0.7377395257080243
Validation loss: 2.9334875833439185

Epoch: 5| Step: 1
Training loss: 0.6302179672093348
Validation loss: 2.951145231748157

Epoch: 5| Step: 2
Training loss: 0.8077255969645634
Validation loss: 2.942169441684996

Epoch: 5| Step: 3
Training loss: 1.7020886268984758
Validation loss: 2.9691289057611385

Epoch: 5| Step: 4
Training loss: 0.8076769288925502
Validation loss: 2.952187989954556

Epoch: 5| Step: 5
Training loss: 0.9536700644436463
Validation loss: 3.0481957336315832

Epoch: 5| Step: 6
Training loss: 0.8754896769217299
Validation loss: 2.927074786453168

Epoch: 5| Step: 7
Training loss: 0.854578469416185
Validation loss: 3.012617990417586

Epoch: 5| Step: 8
Training loss: 0.8690891550661433
Validation loss: 2.9382541074059536

Epoch: 5| Step: 9
Training loss: 0.5234298990181708
Validation loss: 2.990089590735569

Epoch: 5| Step: 10
Training loss: 0.9035614516613719
Validation loss: 2.964960168857223

Epoch: 5| Step: 11
Training loss: 0.9554965111106364
Validation loss: 2.965553821879279

Epoch: 202| Step: 0
Training loss: 0.9456708875012206
Validation loss: 2.8741309728799695

Epoch: 5| Step: 1
Training loss: 1.689503222477965
Validation loss: 2.949664091123834

Epoch: 5| Step: 2
Training loss: 0.653328637496298
Validation loss: 2.9238413553696674

Epoch: 5| Step: 3
Training loss: 0.6077459274353257
Validation loss: 2.9687019996778066

Epoch: 5| Step: 4
Training loss: 0.7573178830302959
Validation loss: 2.9533018802639206

Epoch: 5| Step: 5
Training loss: 0.7930995288363125
Validation loss: 2.932530650309035

Epoch: 5| Step: 6
Training loss: 0.9237567962788784
Validation loss: 2.934518687745699

Epoch: 5| Step: 7
Training loss: 0.5882535555578475
Validation loss: 2.9456842155879888

Epoch: 5| Step: 8
Training loss: 0.9140151247968445
Validation loss: 2.968441612555917

Epoch: 5| Step: 9
Training loss: 1.0140066310733464
Validation loss: 2.9549041616160387

Epoch: 5| Step: 10
Training loss: 0.5079542989092126
Validation loss: 2.9826001087184606

Epoch: 5| Step: 11
Training loss: 0.8757572303493099
Validation loss: 3.0333353846057483

Epoch: 203| Step: 0
Training loss: 0.8096318238821689
Validation loss: 2.936278917953244

Epoch: 5| Step: 1
Training loss: 0.7210570089417639
Validation loss: 2.9503677117439344

Epoch: 5| Step: 2
Training loss: 1.861439112169291
Validation loss: 2.9583724896879726

Epoch: 5| Step: 3
Training loss: 0.8442444588747917
Validation loss: 3.0302302785380153

Epoch: 5| Step: 4
Training loss: 0.6790112167353295
Validation loss: 3.021086167026023

Epoch: 5| Step: 5
Training loss: 0.8020812856144383
Validation loss: 3.009823391983201

Epoch: 5| Step: 6
Training loss: 0.9121753088831376
Validation loss: 2.939825588213809

Epoch: 5| Step: 7
Training loss: 0.7722649982856982
Validation loss: 3.0465857539677086

Epoch: 5| Step: 8
Training loss: 0.6106745239290938
Validation loss: 3.009322582513279

Epoch: 5| Step: 9
Training loss: 0.6000914732425955
Validation loss: 2.954871369411434

Epoch: 5| Step: 10
Training loss: 0.8531000797418806
Validation loss: 3.0614880492351824

Epoch: 5| Step: 11
Training loss: 1.0506714263588746
Validation loss: 3.017938757357411

Epoch: 204| Step: 0
Training loss: 1.5843740941031912
Validation loss: 2.9159815165182907

Epoch: 5| Step: 1
Training loss: 0.8255383021354576
Validation loss: 2.994967498040394

Epoch: 5| Step: 2
Training loss: 0.7431944992509621
Validation loss: 3.04741616293103

Epoch: 5| Step: 3
Training loss: 0.5874385933539651
Validation loss: 3.0719736085356613

Epoch: 5| Step: 4
Training loss: 1.200632063980411
Validation loss: 2.932154943057839

Epoch: 5| Step: 5
Training loss: 0.7379563035305072
Validation loss: 3.0410173302206505

Epoch: 5| Step: 6
Training loss: 0.8037144601774828
Validation loss: 3.0187162884448284

Epoch: 5| Step: 7
Training loss: 0.9273626285421412
Validation loss: 3.0525262801986246

Epoch: 5| Step: 8
Training loss: 0.9963104909818326
Validation loss: 2.9916341085619256

Epoch: 5| Step: 9
Training loss: 0.798741939903987
Validation loss: 3.1073054769995347

Epoch: 5| Step: 10
Training loss: 0.9535437117600438
Validation loss: 2.955487606355817

Epoch: 5| Step: 11
Training loss: 0.853014102477099
Validation loss: 3.062105056053062

Epoch: 205| Step: 0
Training loss: 0.7467831128150625
Validation loss: 3.074769900921436

Epoch: 5| Step: 1
Training loss: 0.8427423181899459
Validation loss: 3.097887015355801

Epoch: 5| Step: 2
Training loss: 0.601823873834139
Validation loss: 2.8972386762526265

Epoch: 5| Step: 3
Training loss: 1.016378563306645
Validation loss: 2.9934487768010523

Epoch: 5| Step: 4
Training loss: 0.8439984132516779
Validation loss: 3.013336439866037

Epoch: 5| Step: 5
Training loss: 1.1075616980388807
Validation loss: 3.0082750732631096

Epoch: 5| Step: 6
Training loss: 0.5887194395941592
Validation loss: 3.045654427344269

Epoch: 5| Step: 7
Training loss: 0.5172270537864484
Validation loss: 2.969714078466135

Epoch: 5| Step: 8
Training loss: 0.9495506491287196
Validation loss: 3.092847355259493

Epoch: 5| Step: 9
Training loss: 1.652031257966378
Validation loss: 3.079237286751969

Epoch: 5| Step: 10
Training loss: 0.5577991676340085
Validation loss: 2.934600850230434

Epoch: 5| Step: 11
Training loss: 1.017486099504377
Validation loss: 3.0167034177666645

Epoch: 206| Step: 0
Training loss: 0.7181101729254254
Validation loss: 3.0262507510325465

Epoch: 5| Step: 1
Training loss: 0.8558260724453965
Validation loss: 3.018880286212279

Epoch: 5| Step: 2
Training loss: 0.6849736700079252
Validation loss: 3.0375364340649638

Epoch: 5| Step: 3
Training loss: 0.7240275388796491
Validation loss: 3.080056267215092

Epoch: 5| Step: 4
Training loss: 0.7504640971191833
Validation loss: 3.167956084489884

Epoch: 5| Step: 5
Training loss: 0.7402578063316184
Validation loss: 3.0760028869392544

Epoch: 5| Step: 6
Training loss: 1.6932225859588563
Validation loss: 3.0297848086955046

Epoch: 5| Step: 7
Training loss: 1.1070220602296152
Validation loss: 3.0492764097980327

Epoch: 5| Step: 8
Training loss: 0.5889552668907816
Validation loss: 3.0916638485277876

Epoch: 5| Step: 9
Training loss: 0.6068636669039678
Validation loss: 2.9522956847596755

Epoch: 5| Step: 10
Training loss: 0.4790598674286276
Validation loss: 2.923188626522164

Epoch: 5| Step: 11
Training loss: 0.5028239907610721
Validation loss: 3.007198512175333

Epoch: 207| Step: 0
Training loss: 0.7707954517713338
Validation loss: 2.939415479653432

Epoch: 5| Step: 1
Training loss: 1.6164348527858403
Validation loss: 2.928124637393393

Epoch: 5| Step: 2
Training loss: 0.8183520187010881
Validation loss: 2.9195667880219953

Epoch: 5| Step: 3
Training loss: 0.7152689101977076
Validation loss: 3.0309142880505195

Epoch: 5| Step: 4
Training loss: 0.5361583543818322
Validation loss: 3.06529884184703

Epoch: 5| Step: 5
Training loss: 0.6380359621914191
Validation loss: 2.993018872305954

Epoch: 5| Step: 6
Training loss: 0.8328952154196391
Validation loss: 3.0595871508577672

Epoch: 5| Step: 7
Training loss: 0.5256337450640348
Validation loss: 3.061121094958168

Epoch: 5| Step: 8
Training loss: 0.6569909726383466
Validation loss: 3.071651435340986

Epoch: 5| Step: 9
Training loss: 0.53696855953284
Validation loss: 3.0100123630050115

Epoch: 5| Step: 10
Training loss: 0.8600117838407094
Validation loss: 3.0611254500824243

Epoch: 5| Step: 11
Training loss: 2.1143169015992336
Validation loss: 3.013333347547019

Epoch: 208| Step: 0
Training loss: 0.8008288113495826
Validation loss: 2.830299079225522

Epoch: 5| Step: 1
Training loss: 0.5615717328076281
Validation loss: 3.036237591963765

Epoch: 5| Step: 2
Training loss: 0.9898815843295969
Validation loss: 2.9716709992207258

Epoch: 5| Step: 3
Training loss: 0.8346155712765739
Validation loss: 3.123652711355408

Epoch: 5| Step: 4
Training loss: 0.690034119031978
Validation loss: 3.097025874081426

Epoch: 5| Step: 5
Training loss: 0.7535333056869756
Validation loss: 2.9879454579896976

Epoch: 5| Step: 6
Training loss: 0.5907902229150286
Validation loss: 2.9541835737798245

Epoch: 5| Step: 7
Training loss: 1.6271225931443296
Validation loss: 3.0094817281608717

Epoch: 5| Step: 8
Training loss: 0.7232502738300732
Validation loss: 2.916814202028616

Epoch: 5| Step: 9
Training loss: 0.5839606442940484
Validation loss: 3.1153421030580986

Epoch: 5| Step: 10
Training loss: 0.5703145379853088
Validation loss: 2.953967456978861

Epoch: 5| Step: 11
Training loss: 0.7130866630339451
Validation loss: 3.0243692137107145

Epoch: 209| Step: 0
Training loss: 0.6519557918542037
Validation loss: 3.037413338417862

Epoch: 5| Step: 1
Training loss: 0.772480690724049
Validation loss: 3.0585120926273333

Epoch: 5| Step: 2
Training loss: 0.5583465669496526
Validation loss: 3.09680961465441

Epoch: 5| Step: 3
Training loss: 0.5439230676345175
Validation loss: 3.026135672434836

Epoch: 5| Step: 4
Training loss: 0.5851223425215019
Validation loss: 2.907218224912115

Epoch: 5| Step: 5
Training loss: 1.2080643562769577
Validation loss: 3.00539356081777

Epoch: 5| Step: 6
Training loss: 0.7523294671308192
Validation loss: 2.9838859563514526

Epoch: 5| Step: 7
Training loss: 1.664514113201653
Validation loss: 2.982418590744532

Epoch: 5| Step: 8
Training loss: 0.6072439196766302
Validation loss: 2.973842225533438

Epoch: 5| Step: 9
Training loss: 0.6865149289902154
Validation loss: 2.9825876219466916

Epoch: 5| Step: 10
Training loss: 0.9032012696053676
Validation loss: 3.0670627158574586

Epoch: 5| Step: 11
Training loss: 0.7771545640004572
Validation loss: 3.046988059660549

Epoch: 210| Step: 0
Training loss: 0.6533472486112094
Validation loss: 3.090557724825096

Epoch: 5| Step: 1
Training loss: 0.7540991343686627
Validation loss: 3.1564663287265815

Epoch: 5| Step: 2
Training loss: 0.7968164310249142
Validation loss: 2.9909370538585467

Epoch: 5| Step: 3
Training loss: 0.8726628288765553
Validation loss: 3.000986897212534

Epoch: 5| Step: 4
Training loss: 0.709284863227945
Validation loss: 3.0302531579458076

Epoch: 5| Step: 5
Training loss: 0.8502662311878957
Validation loss: 3.0289071228115296

Epoch: 5| Step: 6
Training loss: 0.6996898875295872
Validation loss: 3.1082942464602135

Epoch: 5| Step: 7
Training loss: 0.8409480087661326
Validation loss: 3.0164024721201175

Epoch: 5| Step: 8
Training loss: 0.8828708325584337
Validation loss: 3.091595917703657

Epoch: 5| Step: 9
Training loss: 0.5920142853985078
Validation loss: 2.9985888957277074

Epoch: 5| Step: 10
Training loss: 1.9265910645383744
Validation loss: 3.007189226184043

Epoch: 5| Step: 11
Training loss: 0.1629437666365771
Validation loss: 2.9191733533162134

Epoch: 211| Step: 0
Training loss: 0.7090171617225252
Validation loss: 3.009327834576076

Epoch: 5| Step: 1
Training loss: 0.4299257138313267
Validation loss: 3.071372605457604

Epoch: 5| Step: 2
Training loss: 0.6988602896847774
Validation loss: 2.9457744367683882

Epoch: 5| Step: 3
Training loss: 0.7888663019683922
Validation loss: 3.039670855539105

Epoch: 5| Step: 4
Training loss: 0.5661274717196536
Validation loss: 2.940857287646531

Epoch: 5| Step: 5
Training loss: 1.590345748640756
Validation loss: 3.044347448285021

Epoch: 5| Step: 6
Training loss: 0.6709859865860044
Validation loss: 2.9387997666827146

Epoch: 5| Step: 7
Training loss: 0.7689883258116993
Validation loss: 2.980165368634553

Epoch: 5| Step: 8
Training loss: 0.6586481961045988
Validation loss: 3.037510319418836

Epoch: 5| Step: 9
Training loss: 0.9686845941921486
Validation loss: 2.9818147392316514

Epoch: 5| Step: 10
Training loss: 0.7208747142607954
Validation loss: 3.010733087315367

Epoch: 5| Step: 11
Training loss: 0.14277419234883829
Validation loss: 3.0135792033792352

Epoch: 212| Step: 0
Training loss: 0.8138166909496269
Validation loss: 3.022051477916972

Epoch: 5| Step: 1
Training loss: 0.9862467212888419
Validation loss: 3.0934876449522797

Epoch: 5| Step: 2
Training loss: 0.8010102479591071
Validation loss: 2.985454221055792

Epoch: 5| Step: 3
Training loss: 0.8474619770241485
Validation loss: 3.0103809966159734

Epoch: 5| Step: 4
Training loss: 1.520951340508332
Validation loss: 2.959412016564914

Epoch: 5| Step: 5
Training loss: 0.8358020137904093
Validation loss: 2.932234576648044

Epoch: 5| Step: 6
Training loss: 0.6789924970656126
Validation loss: 2.9731483703778947

Epoch: 5| Step: 7
Training loss: 0.7115227941425859
Validation loss: 2.9980506722988474

Epoch: 5| Step: 8
Training loss: 0.4132626924152191
Validation loss: 3.0588720007520025

Epoch: 5| Step: 9
Training loss: 0.5435502759759249
Validation loss: 3.063103324472528

Epoch: 5| Step: 10
Training loss: 0.7918136903532709
Validation loss: 3.069499661283158

Epoch: 5| Step: 11
Training loss: 0.6870472674468785
Validation loss: 2.9868866502335476

Epoch: 213| Step: 0
Training loss: 1.0177097930949794
Validation loss: 2.941142840029544

Epoch: 5| Step: 1
Training loss: 0.9278807514561783
Validation loss: 3.0349818391900736

Epoch: 5| Step: 2
Training loss: 0.6833094414356697
Validation loss: 2.9460086623753137

Epoch: 5| Step: 3
Training loss: 0.6917427235652492
Validation loss: 2.896901590005099

Epoch: 5| Step: 4
Training loss: 0.5880067020021339
Validation loss: 3.0030463301999037

Epoch: 5| Step: 5
Training loss: 0.7528810794641233
Validation loss: 2.990996562845042

Epoch: 5| Step: 6
Training loss: 0.6259705398912574
Validation loss: 3.020677422194176

Epoch: 5| Step: 7
Training loss: 0.758117810912612
Validation loss: 3.0454256180588937

Epoch: 5| Step: 8
Training loss: 0.6083649799093138
Validation loss: 2.987068648301999

Epoch: 5| Step: 9
Training loss: 1.872740655873954
Validation loss: 3.0801259425968275

Epoch: 5| Step: 10
Training loss: 0.767220411352233
Validation loss: 3.0783347366576277

Epoch: 5| Step: 11
Training loss: 0.8119117367885261
Validation loss: 3.0285357452266113

Epoch: 214| Step: 0
Training loss: 1.5849431871888062
Validation loss: 3.1155095663467147

Epoch: 5| Step: 1
Training loss: 0.6234918279089334
Validation loss: 3.043028955349622

Epoch: 5| Step: 2
Training loss: 0.8086552619572772
Validation loss: 3.087587313118871

Epoch: 5| Step: 3
Training loss: 0.837919292537521
Validation loss: 3.0482033597108824

Epoch: 5| Step: 4
Training loss: 0.4943163412332897
Validation loss: 2.938128919776672

Epoch: 5| Step: 5
Training loss: 0.6853087356679695
Validation loss: 3.053839745573645

Epoch: 5| Step: 6
Training loss: 0.6036192672277154
Validation loss: 2.9834329206655887

Epoch: 5| Step: 7
Training loss: 0.5981556918601644
Validation loss: 3.05346289280878

Epoch: 5| Step: 8
Training loss: 0.7247503508520576
Validation loss: 3.055043420113666

Epoch: 5| Step: 9
Training loss: 1.151479312785439
Validation loss: 3.0268689183125432

Epoch: 5| Step: 10
Training loss: 0.6953251441063085
Validation loss: 2.9439824690821603

Epoch: 5| Step: 11
Training loss: 0.6102909149556303
Validation loss: 2.9751535152982824

Epoch: 215| Step: 0
Training loss: 0.48186329306644804
Validation loss: 3.0160936426280185

Epoch: 5| Step: 1
Training loss: 0.7352961991785543
Validation loss: 2.9651224996264807

Epoch: 5| Step: 2
Training loss: 0.817109092904201
Validation loss: 3.0049748134403824

Epoch: 5| Step: 3
Training loss: 1.6355155218420518
Validation loss: 3.031390216376603

Epoch: 5| Step: 4
Training loss: 0.8115121999024507
Validation loss: 2.965847418456802

Epoch: 5| Step: 5
Training loss: 0.7802534996034902
Validation loss: 3.095456266137492

Epoch: 5| Step: 6
Training loss: 0.5367358486777967
Validation loss: 3.0110964134153986

Epoch: 5| Step: 7
Training loss: 0.8052923651336764
Validation loss: 3.0073719990175944

Epoch: 5| Step: 8
Training loss: 0.8004536772840382
Validation loss: 3.0302085201560174

Epoch: 5| Step: 9
Training loss: 0.6678735542503044
Validation loss: 3.0428755896512527

Epoch: 5| Step: 10
Training loss: 0.633777824031835
Validation loss: 3.0247551529946564

Epoch: 5| Step: 11
Training loss: 1.9109393739730118
Validation loss: 2.991222262425934

Epoch: 216| Step: 0
Training loss: 0.9331468286535305
Validation loss: 3.048346566767165

Epoch: 5| Step: 1
Training loss: 1.196556590781237
Validation loss: 3.114981129396775

Epoch: 5| Step: 2
Training loss: 0.8128968516766191
Validation loss: 3.077252963191609

Epoch: 5| Step: 3
Training loss: 0.6414906770291853
Validation loss: 2.930822781471591

Epoch: 5| Step: 4
Training loss: 0.701193572747336
Validation loss: 3.0599625643765225

Epoch: 5| Step: 5
Training loss: 1.6626157964089316
Validation loss: 2.956303132690653

Epoch: 5| Step: 6
Training loss: 1.056922748012703
Validation loss: 3.016900453325124

Epoch: 5| Step: 7
Training loss: 0.7576076584659501
Validation loss: 3.0456632764093996

Epoch: 5| Step: 8
Training loss: 0.5610110125812251
Validation loss: 3.0430916992734662

Epoch: 5| Step: 9
Training loss: 1.0502754894524136
Validation loss: 3.033948647442738

Epoch: 5| Step: 10
Training loss: 0.7884572417712916
Validation loss: 3.091867100297048

Epoch: 5| Step: 11
Training loss: 0.4729827509793555
Validation loss: 3.016614030322598

Epoch: 217| Step: 0
Training loss: 0.729245799175792
Validation loss: 3.0383861838494433

Epoch: 5| Step: 1
Training loss: 0.7927193836807086
Validation loss: 2.9543996680467055

Epoch: 5| Step: 2
Training loss: 0.6389801494637305
Validation loss: 2.9014127974475947

Epoch: 5| Step: 3
Training loss: 0.7339117333977044
Validation loss: 2.9825022615209393

Epoch: 5| Step: 4
Training loss: 0.6380542019792008
Validation loss: 2.9553926867341276

Epoch: 5| Step: 5
Training loss: 0.5427145053954313
Validation loss: 2.986886098132921

Epoch: 5| Step: 6
Training loss: 1.6008795794125652
Validation loss: 2.9259653411250115

Epoch: 5| Step: 7
Training loss: 0.6154523433097417
Validation loss: 3.000467101793936

Epoch: 5| Step: 8
Training loss: 0.665281904026828
Validation loss: 3.1166509964917886

Epoch: 5| Step: 9
Training loss: 0.5792078496392508
Validation loss: 3.0524332716029856

Epoch: 5| Step: 10
Training loss: 1.0388708296366111
Validation loss: 3.0934256855682887

Epoch: 5| Step: 11
Training loss: 0.4177246807194197
Validation loss: 3.013788873260131

Epoch: 218| Step: 0
Training loss: 0.5514011546910496
Validation loss: 2.975654740639301

Epoch: 5| Step: 1
Training loss: 1.8294191914633677
Validation loss: 3.079526988607233

Epoch: 5| Step: 2
Training loss: 0.5159654938042479
Validation loss: 3.1481809708784296

Epoch: 5| Step: 3
Training loss: 0.4838751089972509
Validation loss: 3.0008726340960794

Epoch: 5| Step: 4
Training loss: 0.7085682722430093
Validation loss: 2.998534079529089

Epoch: 5| Step: 5
Training loss: 0.5918260321657798
Validation loss: 3.0465274645190696

Epoch: 5| Step: 6
Training loss: 0.497087459605705
Validation loss: 2.9693158831767366

Epoch: 5| Step: 7
Training loss: 0.5245019991721136
Validation loss: 3.0313539782122354

Epoch: 5| Step: 8
Training loss: 0.8233130301225716
Validation loss: 3.0772597747679717

Epoch: 5| Step: 9
Training loss: 0.7513651741462944
Validation loss: 2.9985018009131403

Epoch: 5| Step: 10
Training loss: 0.9160223921991503
Validation loss: 2.9982557822474187

Epoch: 5| Step: 11
Training loss: 0.6565716273214894
Validation loss: 3.0567644543087495

Epoch: 219| Step: 0
Training loss: 0.8513267610757269
Validation loss: 3.081310505430921

Epoch: 5| Step: 1
Training loss: 0.7375178351104589
Validation loss: 3.0232342250020943

Epoch: 5| Step: 2
Training loss: 0.933486996217373
Validation loss: 2.990584014377879

Epoch: 5| Step: 3
Training loss: 0.6556290458939832
Validation loss: 3.0273576338254804

Epoch: 5| Step: 4
Training loss: 0.5887230843872904
Validation loss: 3.0068799674649154

Epoch: 5| Step: 5
Training loss: 1.7650428419884219
Validation loss: 2.984377593060976

Epoch: 5| Step: 6
Training loss: 0.6777587798284069
Validation loss: 3.052930097108308

Epoch: 5| Step: 7
Training loss: 0.5610897080847645
Validation loss: 3.0441038718448943

Epoch: 5| Step: 8
Training loss: 0.6130604437576672
Validation loss: 2.968181699600963

Epoch: 5| Step: 9
Training loss: 0.7541785662504371
Validation loss: 3.0255862214455203

Epoch: 5| Step: 10
Training loss: 0.6377413676106474
Validation loss: 3.1059428111103005

Epoch: 5| Step: 11
Training loss: 1.0918966667414387
Validation loss: 2.9923848683840033

Epoch: 220| Step: 0
Training loss: 0.8152557370248071
Validation loss: 3.042019155187864

Epoch: 5| Step: 1
Training loss: 0.6875058520674895
Validation loss: 3.095648998344874

Epoch: 5| Step: 2
Training loss: 0.5053739833288465
Validation loss: 3.0231402807169587

Epoch: 5| Step: 3
Training loss: 0.5850485097709829
Validation loss: 3.0275822896192697

Epoch: 5| Step: 4
Training loss: 0.8491321144024973
Validation loss: 3.0151906927840266

Epoch: 5| Step: 5
Training loss: 0.9964209524059677
Validation loss: 3.1580241476383546

Epoch: 5| Step: 6
Training loss: 0.739130369461403
Validation loss: 3.0015256267495554

Epoch: 5| Step: 7
Training loss: 0.6559092681610313
Validation loss: 3.059035839676863

Epoch: 5| Step: 8
Training loss: 0.7765318497993154
Validation loss: 2.9300231266627965

Epoch: 5| Step: 9
Training loss: 0.7108403653031428
Validation loss: 2.8982761026226678

Epoch: 5| Step: 10
Training loss: 1.61785845267761
Validation loss: 2.9189634759669016

Epoch: 5| Step: 11
Training loss: 0.5459799935933879
Validation loss: 2.964797028385779

Epoch: 221| Step: 0
Training loss: 0.5293955130357757
Validation loss: 2.9732059734075

Epoch: 5| Step: 1
Training loss: 0.6775459225423602
Validation loss: 2.9401987272902264

Epoch: 5| Step: 2
Training loss: 1.5154082939721476
Validation loss: 3.0386854164994475

Epoch: 5| Step: 3
Training loss: 0.963270070056745
Validation loss: 3.0350231074354834

Epoch: 5| Step: 4
Training loss: 0.8397183346809967
Validation loss: 2.96097846493528

Epoch: 5| Step: 5
Training loss: 0.5705749743825097
Validation loss: 3.136136201608545

Epoch: 5| Step: 6
Training loss: 0.7063258535447552
Validation loss: 3.0509071926508082

Epoch: 5| Step: 7
Training loss: 0.5263854467731799
Validation loss: 2.9888885313151627

Epoch: 5| Step: 8
Training loss: 0.6130279212181067
Validation loss: 3.00019593393724

Epoch: 5| Step: 9
Training loss: 0.8405486231712233
Validation loss: 2.8402491913693506

Epoch: 5| Step: 10
Training loss: 0.5513271305074718
Validation loss: 3.0272811850368804

Epoch: 5| Step: 11
Training loss: 1.1085920660477928
Validation loss: 2.899930677325303

Epoch: 222| Step: 0
Training loss: 0.7889672401260565
Validation loss: 3.0232630834615755

Epoch: 5| Step: 1
Training loss: 0.6826862087473278
Validation loss: 3.0313022943292145

Epoch: 5| Step: 2
Training loss: 0.7337520067099794
Validation loss: 3.030969416685663

Epoch: 5| Step: 3
Training loss: 0.6075853820736243
Validation loss: 2.9420629935882188

Epoch: 5| Step: 4
Training loss: 0.5433556255592407
Validation loss: 3.000542618104587

Epoch: 5| Step: 5
Training loss: 0.8146223445894126
Validation loss: 3.097772859845468

Epoch: 5| Step: 6
Training loss: 0.7569452416029844
Validation loss: 2.923728293916876

Epoch: 5| Step: 7
Training loss: 0.695237745059747
Validation loss: 2.9730264113249927

Epoch: 5| Step: 8
Training loss: 1.6197405579119972
Validation loss: 2.993334418422641

Epoch: 5| Step: 9
Training loss: 0.8757569240761338
Validation loss: 3.073478884370661

Epoch: 5| Step: 10
Training loss: 0.8786732004392566
Validation loss: 3.055035261568769

Epoch: 5| Step: 11
Training loss: 0.6631962006120137
Validation loss: 2.9970166286592272

Epoch: 223| Step: 0
Training loss: 0.5423725889600278
Validation loss: 2.965742294194754

Epoch: 5| Step: 1
Training loss: 0.613805558900592
Validation loss: 3.1031431211036575

Epoch: 5| Step: 2
Training loss: 0.580075607551224
Validation loss: 3.0772715707038865

Epoch: 5| Step: 3
Training loss: 0.6748957703614847
Validation loss: 2.9335139772123244

Epoch: 5| Step: 4
Training loss: 0.9970953300244288
Validation loss: 3.205739810201834

Epoch: 5| Step: 5
Training loss: 0.6585043831826375
Validation loss: 3.1164106773025613

Epoch: 5| Step: 6
Training loss: 0.6716221178235424
Validation loss: 3.021133504401626

Epoch: 5| Step: 7
Training loss: 0.5940100702610592
Validation loss: 3.0962149404543653

Epoch: 5| Step: 8
Training loss: 1.5631326539021146
Validation loss: 3.018839978653475

Epoch: 5| Step: 9
Training loss: 0.8336314184800041
Validation loss: 3.021866024468185

Epoch: 5| Step: 10
Training loss: 0.9253587040160022
Validation loss: 3.0964166438689644

Epoch: 5| Step: 11
Training loss: 0.7630828771439504
Validation loss: 2.9914922811285436

Epoch: 224| Step: 0
Training loss: 0.6712880564935431
Validation loss: 3.0492218271680276

Epoch: 5| Step: 1
Training loss: 0.5234968806504493
Validation loss: 3.038041470385236

Epoch: 5| Step: 2
Training loss: 0.6251092338473176
Validation loss: 2.9656451000501214

Epoch: 5| Step: 3
Training loss: 0.7797125756888935
Validation loss: 3.038587220854937

Epoch: 5| Step: 4
Training loss: 0.48562456278247373
Validation loss: 3.094052110557013

Epoch: 5| Step: 5
Training loss: 0.725291874110314
Validation loss: 3.002954339647286

Epoch: 5| Step: 6
Training loss: 0.806346183776435
Validation loss: 3.0067264957794397

Epoch: 5| Step: 7
Training loss: 0.7716889315442272
Validation loss: 2.860384021321767

Epoch: 5| Step: 8
Training loss: 1.440140496658561
Validation loss: 3.0211872397761703

Epoch: 5| Step: 9
Training loss: 0.7301517145369875
Validation loss: 3.072013010357275

Epoch: 5| Step: 10
Training loss: 0.9716524513299687
Validation loss: 3.023780924820403

Epoch: 5| Step: 11
Training loss: 0.7471997516669446
Validation loss: 3.0926602977972313

Epoch: 225| Step: 0
Training loss: 1.6424549614524535
Validation loss: 3.1238735234950052

Epoch: 5| Step: 1
Training loss: 0.5036938241726556
Validation loss: 3.004447385596973

Epoch: 5| Step: 2
Training loss: 0.7557934478475757
Validation loss: 2.9197628356421075

Epoch: 5| Step: 3
Training loss: 0.5776201569866599
Validation loss: 3.0882054779049692

Epoch: 5| Step: 4
Training loss: 0.5626248644947498
Validation loss: 3.038476921876485

Epoch: 5| Step: 5
Training loss: 1.1104232241572318
Validation loss: 2.9737487369484965

Epoch: 5| Step: 6
Training loss: 0.5603789765920804
Validation loss: 3.0314081878286263

Epoch: 5| Step: 7
Training loss: 0.6552559044392545
Validation loss: 3.0263617253836372

Epoch: 5| Step: 8
Training loss: 0.6376536707696254
Validation loss: 2.9550895346122714

Epoch: 5| Step: 9
Training loss: 0.5278410650533596
Validation loss: 3.1173214513158887

Epoch: 5| Step: 10
Training loss: 0.7811299804050134
Validation loss: 3.030323276894657

Epoch: 5| Step: 11
Training loss: 0.18275583073568033
Validation loss: 2.9188328407887787

Epoch: 226| Step: 0
Training loss: 1.5583518086662473
Validation loss: 3.0457658036587114

Epoch: 5| Step: 1
Training loss: 0.6646079347854279
Validation loss: 3.030391479776349

Epoch: 5| Step: 2
Training loss: 0.810070476939192
Validation loss: 2.9172049071179624

Epoch: 5| Step: 3
Training loss: 0.47430309569932794
Validation loss: 2.990128455268

Epoch: 5| Step: 4
Training loss: 0.4677909258478164
Validation loss: 2.9490516564736877

Epoch: 5| Step: 5
Training loss: 0.572975785644211
Validation loss: 3.0647779024771182

Epoch: 5| Step: 6
Training loss: 0.7375780823962831
Validation loss: 2.9870363023254956

Epoch: 5| Step: 7
Training loss: 0.5992572011136988
Validation loss: 2.9469814243563968

Epoch: 5| Step: 8
Training loss: 0.7004242633117904
Validation loss: 2.998803684999136

Epoch: 5| Step: 9
Training loss: 0.9161592220494095
Validation loss: 3.081026513826797

Epoch: 5| Step: 10
Training loss: 0.6435224093734532
Validation loss: 3.115795927546724

Epoch: 5| Step: 11
Training loss: 0.6495636961217633
Validation loss: 2.9954205303314914

Epoch: 227| Step: 0
Training loss: 0.6941308685802065
Validation loss: 2.9902550820983933

Epoch: 5| Step: 1
Training loss: 0.7050680862515204
Validation loss: 3.001163670898833

Epoch: 5| Step: 2
Training loss: 1.0428469011658617
Validation loss: 2.927584572408477

Epoch: 5| Step: 3
Training loss: 1.5731792188719478
Validation loss: 3.0234896468890593

Epoch: 5| Step: 4
Training loss: 0.6775515526868117
Validation loss: 3.04585514932709

Epoch: 5| Step: 5
Training loss: 0.5552840181859526
Validation loss: 2.9789728466199463

Epoch: 5| Step: 6
Training loss: 0.7717233408459057
Validation loss: 2.940533066385763

Epoch: 5| Step: 7
Training loss: 0.7323700746656137
Validation loss: 3.005395246584803

Epoch: 5| Step: 8
Training loss: 0.3315139892677291
Validation loss: 3.00640842974616

Epoch: 5| Step: 9
Training loss: 0.7145043906897146
Validation loss: 3.0130111520535294

Epoch: 5| Step: 10
Training loss: 0.7484409499437302
Validation loss: 3.021900446724484

Epoch: 5| Step: 11
Training loss: 1.135647508212357
Validation loss: 3.0788982956215754

Epoch: 228| Step: 0
Training loss: 0.5940182230591284
Validation loss: 3.047472834827204

Epoch: 5| Step: 1
Training loss: 0.5634727808463467
Validation loss: 2.9415284697532655

Epoch: 5| Step: 2
Training loss: 0.5319093651433516
Validation loss: 2.980851315085165

Epoch: 5| Step: 3
Training loss: 0.7142956409445772
Validation loss: 3.04420615139206

Epoch: 5| Step: 4
Training loss: 0.5440413494698854
Validation loss: 2.964172042594784

Epoch: 5| Step: 5
Training loss: 0.8981886477604746
Validation loss: 2.9608219463041023

Epoch: 5| Step: 6
Training loss: 1.0389718037653717
Validation loss: 2.9632518081281907

Epoch: 5| Step: 7
Training loss: 0.71938287818499
Validation loss: 3.016682227017296

Epoch: 5| Step: 8
Training loss: 0.6038433530755158
Validation loss: 2.9325695866022143

Epoch: 5| Step: 9
Training loss: 1.5936654760349223
Validation loss: 2.9677475491618783

Epoch: 5| Step: 10
Training loss: 0.6399117663030636
Validation loss: 3.0349128655018514

Epoch: 5| Step: 11
Training loss: 0.8614043809692986
Validation loss: 2.9645025888805825

Epoch: 229| Step: 0
Training loss: 0.8894335490381516
Validation loss: 3.026221085622591

Epoch: 5| Step: 1
Training loss: 1.0842379986409065
Validation loss: 3.0328335214443505

Epoch: 5| Step: 2
Training loss: 0.7379393012741358
Validation loss: 3.023141798859046

Epoch: 5| Step: 3
Training loss: 0.5293432968446686
Validation loss: 3.0232342857916237

Epoch: 5| Step: 4
Training loss: 0.7736936973337746
Validation loss: 2.9568248594445135

Epoch: 5| Step: 5
Training loss: 1.5000901195157248
Validation loss: 3.169122989730389

Epoch: 5| Step: 6
Training loss: 0.8073329955976281
Validation loss: 2.9670997416485374

Epoch: 5| Step: 7
Training loss: 0.6482333585822335
Validation loss: 3.1143686397047867

Epoch: 5| Step: 8
Training loss: 0.5740886203428096
Validation loss: 3.057199650061549

Epoch: 5| Step: 9
Training loss: 0.6620409094596702
Validation loss: 3.068221816183254

Epoch: 5| Step: 10
Training loss: 0.5646945740552748
Validation loss: 3.1396640047485374

Epoch: 5| Step: 11
Training loss: 1.2391440096547326
Validation loss: 3.038522670757526

Epoch: 230| Step: 0
Training loss: 0.7374256969457534
Validation loss: 3.2229304588103314

Epoch: 5| Step: 1
Training loss: 0.7514538184752036
Validation loss: 3.043164662757976

Epoch: 5| Step: 2
Training loss: 0.5905987789247358
Validation loss: 3.09136984360802

Epoch: 5| Step: 3
Training loss: 0.7520964646888179
Validation loss: 3.117011795892181

Epoch: 5| Step: 4
Training loss: 0.703777709639011
Validation loss: 3.09597960961266

Epoch: 5| Step: 5
Training loss: 0.4523268938629928
Validation loss: 3.173141239273226

Epoch: 5| Step: 6
Training loss: 0.9633108773358605
Validation loss: 3.058561838892165

Epoch: 5| Step: 7
Training loss: 0.5750841638916251
Validation loss: 3.0274845705812563

Epoch: 5| Step: 8
Training loss: 0.5077903449287385
Validation loss: 3.014144712031903

Epoch: 5| Step: 9
Training loss: 0.7128761185515711
Validation loss: 3.029763201219808

Epoch: 5| Step: 10
Training loss: 1.6486479999957586
Validation loss: 3.055006187836436

Epoch: 5| Step: 11
Training loss: 0.42397040514743456
Validation loss: 3.026755290930805

Epoch: 231| Step: 0
Training loss: 0.4956937814587965
Validation loss: 3.0237949005668394

Epoch: 5| Step: 1
Training loss: 0.7499638389770898
Validation loss: 3.103694676139043

Epoch: 5| Step: 2
Training loss: 0.685661871413322
Validation loss: 3.019168591815027

Epoch: 5| Step: 3
Training loss: 0.7641458820801409
Validation loss: 3.050627398061093

Epoch: 5| Step: 4
Training loss: 0.6393575225186461
Validation loss: 2.974494646330796

Epoch: 5| Step: 5
Training loss: 0.4528721564348674
Validation loss: 3.0717139859331315

Epoch: 5| Step: 6
Training loss: 0.46837092012329146
Validation loss: 2.953444788200673

Epoch: 5| Step: 7
Training loss: 0.9910241162361486
Validation loss: 2.964324480168225

Epoch: 5| Step: 8
Training loss: 0.4681711278325774
Validation loss: 3.044633405950692

Epoch: 5| Step: 9
Training loss: 1.5698575551718932
Validation loss: 2.980932878692699

Epoch: 5| Step: 10
Training loss: 0.6380243781374076
Validation loss: 3.1474485934642056

Epoch: 5| Step: 11
Training loss: 0.6762838534274249
Validation loss: 3.0134932538620496

Epoch: 232| Step: 0
Training loss: 0.4396024153697291
Validation loss: 2.9376502641162006

Epoch: 5| Step: 1
Training loss: 0.6876280621985906
Validation loss: 3.102113231252688

Epoch: 5| Step: 2
Training loss: 0.6391087242514666
Validation loss: 3.0109236080295934

Epoch: 5| Step: 3
Training loss: 0.8482302994041058
Validation loss: 3.0252446992543622

Epoch: 5| Step: 4
Training loss: 1.0934494150476863
Validation loss: 2.894716511716588

Epoch: 5| Step: 5
Training loss: 0.7902941392219069
Validation loss: 3.003861081792834

Epoch: 5| Step: 6
Training loss: 0.7897283935827547
Validation loss: 2.996322145671656

Epoch: 5| Step: 7
Training loss: 0.6550648751053374
Validation loss: 3.005171761821886

Epoch: 5| Step: 8
Training loss: 0.5381437848630436
Validation loss: 3.0105726648234703

Epoch: 5| Step: 9
Training loss: 0.43540319288052964
Validation loss: 3.011694090429302

Epoch: 5| Step: 10
Training loss: 1.5517238567615124
Validation loss: 3.0168428778336085

Epoch: 5| Step: 11
Training loss: 0.27240810087064665
Validation loss: 2.8977917948479224

Epoch: 233| Step: 0
Training loss: 0.5751914265473839
Validation loss: 3.0267007649457307

Epoch: 5| Step: 1
Training loss: 0.6863686616376014
Validation loss: 2.948398339557814

Epoch: 5| Step: 2
Training loss: 0.7605156028521368
Validation loss: 2.933032151811956

Epoch: 5| Step: 3
Training loss: 1.5319824024215636
Validation loss: 2.96246722789402

Epoch: 5| Step: 4
Training loss: 0.6027502743891657
Validation loss: 2.998049399906052

Epoch: 5| Step: 5
Training loss: 0.43335674441199196
Validation loss: 3.0361926953355116

Epoch: 5| Step: 6
Training loss: 0.6876542611885391
Validation loss: 2.9505556356471185

Epoch: 5| Step: 7
Training loss: 0.6363682396446664
Validation loss: 2.9498357266415427

Epoch: 5| Step: 8
Training loss: 0.6252513856777133
Validation loss: 2.94113171070064

Epoch: 5| Step: 9
Training loss: 1.0381756202808523
Validation loss: 3.0955610208557434

Epoch: 5| Step: 10
Training loss: 0.7314923708029621
Validation loss: 2.9889043220746325

Epoch: 5| Step: 11
Training loss: 0.4220309675626011
Validation loss: 2.9999576207982317

Epoch: 234| Step: 0
Training loss: 1.5638157454589205
Validation loss: 3.0669621864666508

Epoch: 5| Step: 1
Training loss: 0.8853760018079799
Validation loss: 3.0076827050149624

Epoch: 5| Step: 2
Training loss: 0.7727254036253492
Validation loss: 3.0747842943058474

Epoch: 5| Step: 3
Training loss: 0.9672078809917185
Validation loss: 3.0530287718014297

Epoch: 5| Step: 4
Training loss: 0.886210627898598
Validation loss: 3.05158231266203

Epoch: 5| Step: 5
Training loss: 0.5038207817045284
Validation loss: 2.894856539769537

Epoch: 5| Step: 6
Training loss: 0.6930430160688519
Validation loss: 2.8603761132948056

Epoch: 5| Step: 7
Training loss: 0.45189344824861377
Validation loss: 3.0466075616824053

Epoch: 5| Step: 8
Training loss: 0.7776707100592105
Validation loss: 3.0106834911556186

Epoch: 5| Step: 9
Training loss: 0.7746196151725981
Validation loss: 3.051236768670665

Epoch: 5| Step: 10
Training loss: 0.6958692657497572
Validation loss: 3.0039292373075313

Epoch: 5| Step: 11
Training loss: 0.6338723338106232
Validation loss: 2.986165343514167

Epoch: 235| Step: 0
Training loss: 0.4046471778193801
Validation loss: 2.9585150049510425

Epoch: 5| Step: 1
Training loss: 1.4757308636328854
Validation loss: 2.9823451537144634

Epoch: 5| Step: 2
Training loss: 0.5846246379943341
Validation loss: 3.0174078439610947

Epoch: 5| Step: 3
Training loss: 0.8730579691273757
Validation loss: 2.917149392553184

Epoch: 5| Step: 4
Training loss: 0.854886244239046
Validation loss: 3.037033708126571

Epoch: 5| Step: 5
Training loss: 0.7814286218532587
Validation loss: 3.0063981268878273

Epoch: 5| Step: 6
Training loss: 0.7304663020618241
Validation loss: 2.927819520315754

Epoch: 5| Step: 7
Training loss: 0.6488559016483529
Validation loss: 2.923488565797836

Epoch: 5| Step: 8
Training loss: 0.7312989846149345
Validation loss: 3.042313139074143

Epoch: 5| Step: 9
Training loss: 0.5695492850170482
Validation loss: 2.9829024931259247

Epoch: 5| Step: 10
Training loss: 0.64925096801433
Validation loss: 3.0447236608914396

Epoch: 5| Step: 11
Training loss: 0.49141156628860855
Validation loss: 3.083278627597657

Epoch: 236| Step: 0
Training loss: 0.6504950453872295
Validation loss: 3.0682100372590155

Epoch: 5| Step: 1
Training loss: 0.667670601677817
Validation loss: 3.0732050334735943

Epoch: 5| Step: 2
Training loss: 0.48315790530684166
Validation loss: 3.045437093671367

Epoch: 5| Step: 3
Training loss: 0.6918101451081374
Validation loss: 2.9744602031545226

Epoch: 5| Step: 4
Training loss: 1.0077583239284216
Validation loss: 3.032042897795161

Epoch: 5| Step: 5
Training loss: 0.7692519712277194
Validation loss: 2.923135125327081

Epoch: 5| Step: 6
Training loss: 0.9283649108819255
Validation loss: 3.0850939052320245

Epoch: 5| Step: 7
Training loss: 0.5089935360462471
Validation loss: 3.0007769750730002

Epoch: 5| Step: 8
Training loss: 0.6130081589219608
Validation loss: 2.99139236363286

Epoch: 5| Step: 9
Training loss: 0.5951262385422162
Validation loss: 2.930668926732841

Epoch: 5| Step: 10
Training loss: 1.491913615551212
Validation loss: 3.0882549259998093

Epoch: 5| Step: 11
Training loss: 0.5006776925787008
Validation loss: 3.037837306996811

Epoch: 237| Step: 0
Training loss: 0.5579488806603843
Validation loss: 2.947355871923386

Epoch: 5| Step: 1
Training loss: 0.5596340336227072
Validation loss: 2.980014571435877

Epoch: 5| Step: 2
Training loss: 0.6683600768504201
Validation loss: 3.1091428283453038

Epoch: 5| Step: 3
Training loss: 0.6490279806817811
Validation loss: 3.1228321503409995

Epoch: 5| Step: 4
Training loss: 0.6127722261725329
Validation loss: 2.9482531114047132

Epoch: 5| Step: 5
Training loss: 0.9833751020342971
Validation loss: 2.916267951324714

Epoch: 5| Step: 6
Training loss: 0.5656453250162761
Validation loss: 3.0271498718527416

Epoch: 5| Step: 7
Training loss: 0.6303708573628285
Validation loss: 3.127565319615151

Epoch: 5| Step: 8
Training loss: 0.5281474735060542
Validation loss: 3.0108557230242465

Epoch: 5| Step: 9
Training loss: 0.6692784280506864
Validation loss: 3.0254377242826824

Epoch: 5| Step: 10
Training loss: 1.5531214201672936
Validation loss: 2.9337637810125394

Epoch: 5| Step: 11
Training loss: 0.6551004741498117
Validation loss: 3.0054372549328012

Epoch: 238| Step: 0
Training loss: 0.6670978512714075
Validation loss: 3.0530067268663577

Epoch: 5| Step: 1
Training loss: 1.548950421386433
Validation loss: 3.1240141934934496

Epoch: 5| Step: 2
Training loss: 0.6660576412785794
Validation loss: 2.9862978002065965

Epoch: 5| Step: 3
Training loss: 0.9420604411373292
Validation loss: 3.012938249665719

Epoch: 5| Step: 4
Training loss: 0.6861450758874292
Validation loss: 2.9846985593291397

Epoch: 5| Step: 5
Training loss: 0.43868972592537064
Validation loss: 3.0062236205785555

Epoch: 5| Step: 6
Training loss: 0.544741993956012
Validation loss: 2.8851334447757373

Epoch: 5| Step: 7
Training loss: 0.6081931072333752
Validation loss: 2.9579051686215836

Epoch: 5| Step: 8
Training loss: 0.5880988883242959
Validation loss: 2.897158245325335

Epoch: 5| Step: 9
Training loss: 0.6922774349023663
Validation loss: 2.987868173675895

Epoch: 5| Step: 10
Training loss: 0.5583526250960453
Validation loss: 2.9346076103967276

Epoch: 5| Step: 11
Training loss: 0.35166426351405605
Validation loss: 3.019915741740844

Epoch: 239| Step: 0
Training loss: 0.6079255986837564
Validation loss: 3.070849137975083

Epoch: 5| Step: 1
Training loss: 0.6947187395918186
Validation loss: 3.029164629274826

Epoch: 5| Step: 2
Training loss: 0.5633925138890898
Validation loss: 3.000514353925192

Epoch: 5| Step: 3
Training loss: 0.4962188382778381
Validation loss: 3.084342041921722

Epoch: 5| Step: 4
Training loss: 0.645552133028402
Validation loss: 3.0450294774136712

Epoch: 5| Step: 5
Training loss: 1.5600517165341374
Validation loss: 2.9918986115467905

Epoch: 5| Step: 6
Training loss: 0.927134719596072
Validation loss: 2.9733168226868476

Epoch: 5| Step: 7
Training loss: 0.5268186144449635
Validation loss: 2.9413423907004193

Epoch: 5| Step: 8
Training loss: 0.5643283745736907
Validation loss: 3.0249009151624704

Epoch: 5| Step: 9
Training loss: 0.5389216142180255
Validation loss: 3.0061402531482635

Epoch: 5| Step: 10
Training loss: 0.7095075206237029
Validation loss: 3.0839295014968955

Epoch: 5| Step: 11
Training loss: 0.5346355829054371
Validation loss: 3.023902922957179

Epoch: 240| Step: 0
Training loss: 0.9188862213043255
Validation loss: 2.919771076165628

Epoch: 5| Step: 1
Training loss: 0.39014389929053805
Validation loss: 2.984817977970006

Epoch: 5| Step: 2
Training loss: 0.6164135969954609
Validation loss: 2.968731194152162

Epoch: 5| Step: 3
Training loss: 0.7832465409495623
Validation loss: 3.1332946621929856

Epoch: 5| Step: 4
Training loss: 1.5549481810739532
Validation loss: 3.0940149800656758

Epoch: 5| Step: 5
Training loss: 0.7804424690045015
Validation loss: 3.038526473052589

Epoch: 5| Step: 6
Training loss: 0.6494898242784701
Validation loss: 3.1241152909752934

Epoch: 5| Step: 7
Training loss: 0.7165403816679078
Validation loss: 2.924176457206517

Epoch: 5| Step: 8
Training loss: 0.6094785015533092
Validation loss: 3.0551361476478958

Epoch: 5| Step: 9
Training loss: 0.6101102794566557
Validation loss: 3.0402825790335606

Epoch: 5| Step: 10
Training loss: 0.5163125165166553
Validation loss: 3.086472972655342

Epoch: 5| Step: 11
Training loss: 0.3092596378443599
Validation loss: 3.021844761436467

Epoch: 241| Step: 0
Training loss: 0.6257513060531368
Validation loss: 3.0597923856523006

Epoch: 5| Step: 1
Training loss: 0.6297559270288331
Validation loss: 3.018844105192918

Epoch: 5| Step: 2
Training loss: 0.7098818056694208
Validation loss: 2.991222926643133

Epoch: 5| Step: 3
Training loss: 0.7128302979745458
Validation loss: 2.9551483367828495

Epoch: 5| Step: 4
Training loss: 0.6735023042516224
Validation loss: 2.909214756722143

Epoch: 5| Step: 5
Training loss: 1.420898018014328
Validation loss: 2.9576241618153998

Epoch: 5| Step: 6
Training loss: 0.7467486318518892
Validation loss: 2.957467386727489

Epoch: 5| Step: 7
Training loss: 0.8513877059308771
Validation loss: 3.0995256508390767

Epoch: 5| Step: 8
Training loss: 0.525171482372611
Validation loss: 2.9780726569300193

Epoch: 5| Step: 9
Training loss: 0.6906593296960503
Validation loss: 3.0096947795526523

Epoch: 5| Step: 10
Training loss: 0.997812799823452
Validation loss: 2.9350031190278325

Epoch: 5| Step: 11
Training loss: 0.373528015467387
Validation loss: 2.996407934606334

Epoch: 242| Step: 0
Training loss: 0.5128117601667108
Validation loss: 3.1216721426499445

Epoch: 5| Step: 1
Training loss: 0.7281867709173799
Validation loss: 2.9942027743086084

Epoch: 5| Step: 2
Training loss: 0.6938018891114451
Validation loss: 2.954130771797312

Epoch: 5| Step: 3
Training loss: 0.8327631350660649
Validation loss: 2.9518435050785943

Epoch: 5| Step: 4
Training loss: 0.5625604755953009
Validation loss: 3.0862494749602063

Epoch: 5| Step: 5
Training loss: 0.6744125264556564
Validation loss: 3.0421555770664654

Epoch: 5| Step: 6
Training loss: 1.6188217971963068
Validation loss: 3.0033772056019936

Epoch: 5| Step: 7
Training loss: 0.7371229743612712
Validation loss: 3.0648297965193754

Epoch: 5| Step: 8
Training loss: 0.6182061010834073
Validation loss: 3.0066538110600582

Epoch: 5| Step: 9
Training loss: 1.0556759194017875
Validation loss: 3.0130343171754617

Epoch: 5| Step: 10
Training loss: 0.4864972291653835
Validation loss: 3.0302638452156594

Epoch: 5| Step: 11
Training loss: 0.4411200211444776
Validation loss: 2.979042528584985

Epoch: 243| Step: 0
Training loss: 0.5970391222612746
Validation loss: 2.9854137550192505

Epoch: 5| Step: 1
Training loss: 0.83989115736474
Validation loss: 3.0588590426508717

Epoch: 5| Step: 2
Training loss: 0.786039169136351
Validation loss: 3.000456954010332

Epoch: 5| Step: 3
Training loss: 0.4086809054430545
Validation loss: 2.974044131607432

Epoch: 5| Step: 4
Training loss: 0.5937277639140387
Validation loss: 3.0142304056800557

Epoch: 5| Step: 5
Training loss: 0.7864599838407936
Validation loss: 3.044949984711294

Epoch: 5| Step: 6
Training loss: 0.508622008445419
Validation loss: 3.071442390500049

Epoch: 5| Step: 7
Training loss: 0.5494425039730685
Validation loss: 3.0220580983437455

Epoch: 5| Step: 8
Training loss: 0.5850627473044772
Validation loss: 3.073419547016438

Epoch: 5| Step: 9
Training loss: 0.64626645105994
Validation loss: 2.8864795033341535

Epoch: 5| Step: 10
Training loss: 1.4852159226262387
Validation loss: 3.0539162614251185

Epoch: 5| Step: 11
Training loss: 0.41273853673214084
Validation loss: 2.9438546010282054

Epoch: 244| Step: 0
Training loss: 0.6264706713196532
Validation loss: 2.9914476294987637

Epoch: 5| Step: 1
Training loss: 0.742092367399623
Validation loss: 3.026340090185248

Epoch: 5| Step: 2
Training loss: 0.6485787203413668
Validation loss: 3.036699561367677

Epoch: 5| Step: 3
Training loss: 0.6825525037600957
Validation loss: 3.066817898666704

Epoch: 5| Step: 4
Training loss: 0.5415696430120442
Validation loss: 3.0710420073506937

Epoch: 5| Step: 5
Training loss: 0.6861936121497362
Validation loss: 3.097900701677085

Epoch: 5| Step: 6
Training loss: 0.6768043799294114
Validation loss: 2.9723720941062943

Epoch: 5| Step: 7
Training loss: 1.5767475575321865
Validation loss: 2.974067119249954

Epoch: 5| Step: 8
Training loss: 0.7552230088134426
Validation loss: 2.9165862322115985

Epoch: 5| Step: 9
Training loss: 0.7155871252173669
Validation loss: 2.963301795856733

Epoch: 5| Step: 10
Training loss: 0.8791379835020793
Validation loss: 3.013103475181904

Epoch: 5| Step: 11
Training loss: 0.6846706082912499
Validation loss: 3.05164378693228

Epoch: 245| Step: 0
Training loss: 0.7146853912549253
Validation loss: 2.948698965587506

Epoch: 5| Step: 1
Training loss: 0.48898333618716827
Validation loss: 3.079429275909783

Epoch: 5| Step: 2
Training loss: 0.856392870768753
Validation loss: 3.0181838068654367

Epoch: 5| Step: 3
Training loss: 0.6608851545090183
Validation loss: 3.130491254506824

Epoch: 5| Step: 4
Training loss: 0.49099517391225955
Validation loss: 2.9943751744892855

Epoch: 5| Step: 5
Training loss: 0.605188070889288
Validation loss: 3.0290927256585363

Epoch: 5| Step: 6
Training loss: 0.5852940650476753
Validation loss: 3.0303922599782758

Epoch: 5| Step: 7
Training loss: 0.8204325270261948
Validation loss: 3.1132313538066487

Epoch: 5| Step: 8
Training loss: 0.6313986820332859
Validation loss: 2.9202709418874715

Epoch: 5| Step: 9
Training loss: 0.8051682304736157
Validation loss: 3.023669422070043

Epoch: 5| Step: 10
Training loss: 0.6227634945436838
Validation loss: 3.0019927757488856

Epoch: 5| Step: 11
Training loss: 3.178238222099019
Validation loss: 3.10484984046572

Epoch: 246| Step: 0
Training loss: 1.7602099536164846
Validation loss: 3.0249859658485825

Epoch: 5| Step: 1
Training loss: 0.69044274475614
Validation loss: 3.0408542388513804

Epoch: 5| Step: 2
Training loss: 0.4799524339810703
Validation loss: 3.0880670692112386

Epoch: 5| Step: 3
Training loss: 0.704252525790895
Validation loss: 3.1717870415078377

Epoch: 5| Step: 4
Training loss: 0.5690921110842119
Validation loss: 2.976127302339464

Epoch: 5| Step: 5
Training loss: 0.5309887411931874
Validation loss: 3.145858209818992

Epoch: 5| Step: 6
Training loss: 0.444865772303815
Validation loss: 3.0249130499247245

Epoch: 5| Step: 7
Training loss: 0.9164900537337186
Validation loss: 3.0225106657884924

Epoch: 5| Step: 8
Training loss: 0.6942871119505042
Validation loss: 3.11702200721965

Epoch: 5| Step: 9
Training loss: 0.5745642524392914
Validation loss: 3.07702706857395

Epoch: 5| Step: 10
Training loss: 0.595569908380243
Validation loss: 3.0853338206414316

Epoch: 5| Step: 11
Training loss: 0.5532214711000655
Validation loss: 3.0027193685346614

Epoch: 247| Step: 0
Training loss: 0.9821846525786365
Validation loss: 3.0555432707125383

Epoch: 5| Step: 1
Training loss: 1.440842929335249
Validation loss: 3.1510802316538826

Epoch: 5| Step: 2
Training loss: 0.632090097335436
Validation loss: 3.0892399818118226

Epoch: 5| Step: 3
Training loss: 0.7797011089475093
Validation loss: 3.0357940769528318

Epoch: 5| Step: 4
Training loss: 0.8167596079690632
Validation loss: 3.07351657162579

Epoch: 5| Step: 5
Training loss: 0.5761705042935894
Validation loss: 3.0482611087177527

Epoch: 5| Step: 6
Training loss: 0.6003778857118702
Validation loss: 3.026261459002202

Epoch: 5| Step: 7
Training loss: 0.8982179456385441
Validation loss: 2.9912421822356086

Epoch: 5| Step: 8
Training loss: 0.6139408622027508
Validation loss: 3.0817354815395297

Epoch: 5| Step: 9
Training loss: 0.6463650596206929
Validation loss: 3.0386250760506055

Epoch: 5| Step: 10
Training loss: 0.5841293410195618
Validation loss: 3.1011842197502935

Epoch: 5| Step: 11
Training loss: 0.6009093119595688
Validation loss: 2.97456299379741

Epoch: 248| Step: 0
Training loss: 1.5097338832267235
Validation loss: 2.994296005805869

Epoch: 5| Step: 1
Training loss: 0.5772632155559776
Validation loss: 2.938010654973955

Epoch: 5| Step: 2
Training loss: 0.5442899916591285
Validation loss: 3.090397151446348

Epoch: 5| Step: 3
Training loss: 0.4527440607385953
Validation loss: 2.9690717857372757

Epoch: 5| Step: 4
Training loss: 0.7964632054874302
Validation loss: 2.9955753837884145

Epoch: 5| Step: 5
Training loss: 0.8398344527328772
Validation loss: 2.911870570106082

Epoch: 5| Step: 6
Training loss: 0.8312693227945731
Validation loss: 3.0419322718745407

Epoch: 5| Step: 7
Training loss: 0.6526120941662956
Validation loss: 2.9862598106166707

Epoch: 5| Step: 8
Training loss: 0.6959288790391109
Validation loss: 3.097157156312622

Epoch: 5| Step: 9
Training loss: 0.585565067184249
Validation loss: 2.9346153962474744

Epoch: 5| Step: 10
Training loss: 0.622730258386779
Validation loss: 3.0214443323317357

Epoch: 5| Step: 11
Training loss: 0.6875907231206039
Validation loss: 3.021041321445445

Epoch: 249| Step: 0
Training loss: 0.7334305391765562
Validation loss: 3.0638900184360276

Epoch: 5| Step: 1
Training loss: 0.6279364744208211
Validation loss: 2.9724480200549355

Epoch: 5| Step: 2
Training loss: 0.5957679838298773
Validation loss: 3.0266188346308347

Epoch: 5| Step: 3
Training loss: 0.5330483068597631
Validation loss: 2.9364810792967386

Epoch: 5| Step: 4
Training loss: 0.9775995470173937
Validation loss: 3.0414876210194235

Epoch: 5| Step: 5
Training loss: 0.7325777015225111
Validation loss: 2.998876116094784

Epoch: 5| Step: 6
Training loss: 0.6436766999373256
Validation loss: 3.037082530533703

Epoch: 5| Step: 7
Training loss: 1.4595509033056058
Validation loss: 3.0764815111092942

Epoch: 5| Step: 8
Training loss: 0.3906065745776519
Validation loss: 3.036702597179067

Epoch: 5| Step: 9
Training loss: 0.6734013187044315
Validation loss: 2.999579890293739

Epoch: 5| Step: 10
Training loss: 0.5035926375227384
Validation loss: 3.0434586730851416

Epoch: 5| Step: 11
Training loss: 0.3672695271200113
Validation loss: 3.0820077622054107

Epoch: 250| Step: 0
Training loss: 0.5354617840748206
Validation loss: 3.0261311914504407

Epoch: 5| Step: 1
Training loss: 0.5199906462048167
Validation loss: 3.0232155691306195

Epoch: 5| Step: 2
Training loss: 0.4293884797458232
Validation loss: 2.9948116213368685

Epoch: 5| Step: 3
Training loss: 0.8662677389313036
Validation loss: 2.9888594323597153

Epoch: 5| Step: 4
Training loss: 0.6246741160513793
Validation loss: 3.030684008635841

Epoch: 5| Step: 5
Training loss: 0.5268432219799248
Validation loss: 2.998633404577664

Epoch: 5| Step: 6
Training loss: 0.8342306233625882
Validation loss: 2.9986899316868856

Epoch: 5| Step: 7
Training loss: 1.5276055855478365
Validation loss: 3.0766756192256524

Epoch: 5| Step: 8
Training loss: 0.5603884163960163
Validation loss: 3.0519790740101915

Epoch: 5| Step: 9
Training loss: 0.4543297963173807
Validation loss: 3.0596809290096956

Epoch: 5| Step: 10
Training loss: 0.6510765422380779
Validation loss: 3.0475825930849685

Epoch: 5| Step: 11
Training loss: 0.42291100769140477
Validation loss: 3.0486919430497457

Epoch: 251| Step: 0
Training loss: 0.5226253642947942
Validation loss: 2.9707212027476846

Epoch: 5| Step: 1
Training loss: 0.462292087062503
Validation loss: 3.1167180019288585

Epoch: 5| Step: 2
Training loss: 0.874826141523598
Validation loss: 3.014471182530791

Epoch: 5| Step: 3
Training loss: 0.6520917714175273
Validation loss: 3.1165450859494945

Epoch: 5| Step: 4
Training loss: 0.5202476609987237
Validation loss: 3.148657984305922

Epoch: 5| Step: 5
Training loss: 1.4617141046659217
Validation loss: 3.131268013542579

Epoch: 5| Step: 6
Training loss: 0.6245885209734847
Validation loss: 3.10430803979767

Epoch: 5| Step: 7
Training loss: 0.5493826457458278
Validation loss: 3.0538578061158264

Epoch: 5| Step: 8
Training loss: 0.635118357148593
Validation loss: 3.034332359949382

Epoch: 5| Step: 9
Training loss: 0.6407695700179292
Validation loss: 3.1004769117355613

Epoch: 5| Step: 10
Training loss: 0.5593825153293513
Validation loss: 3.0514344880807163

Epoch: 5| Step: 11
Training loss: 0.457668398288559
Validation loss: 3.017202636664977

Epoch: 252| Step: 0
Training loss: 0.47162097067872216
Validation loss: 2.9946242321588934

Epoch: 5| Step: 1
Training loss: 0.5351262606272009
Validation loss: 2.9013470683582065

Epoch: 5| Step: 2
Training loss: 0.5553333122719757
Validation loss: 3.0181347149521227

Epoch: 5| Step: 3
Training loss: 0.7912468089661576
Validation loss: 2.9854092961016487

Epoch: 5| Step: 4
Training loss: 1.0126341577823796
Validation loss: 2.9956807129935523

Epoch: 5| Step: 5
Training loss: 0.6417220886455706
Validation loss: 3.011167651468107

Epoch: 5| Step: 6
Training loss: 0.6161147343280882
Validation loss: 3.0509144375001154

Epoch: 5| Step: 7
Training loss: 1.4742841147126848
Validation loss: 3.050071054032239

Epoch: 5| Step: 8
Training loss: 0.6226726592042381
Validation loss: 3.0149792917108726

Epoch: 5| Step: 9
Training loss: 0.6473055231555013
Validation loss: 2.9985716154483395

Epoch: 5| Step: 10
Training loss: 0.48945845032494606
Validation loss: 2.943412002332619

Epoch: 5| Step: 11
Training loss: 0.14175630204422765
Validation loss: 3.0260905077478593

Epoch: 253| Step: 0
Training loss: 0.7523300613314703
Validation loss: 3.0627027431511666

Epoch: 5| Step: 1
Training loss: 0.5342360890406652
Validation loss: 3.0644410852179935

Epoch: 5| Step: 2
Training loss: 1.514825196961634
Validation loss: 2.988209509559776

Epoch: 5| Step: 3
Training loss: 0.3502138336100697
Validation loss: 3.0207668932919844

Epoch: 5| Step: 4
Training loss: 0.37984833156344305
Validation loss: 3.13882627742394

Epoch: 5| Step: 5
Training loss: 0.7647629380517479
Validation loss: 3.0930981447024335

Epoch: 5| Step: 6
Training loss: 0.5181751766227907
Validation loss: 3.098058295245925

Epoch: 5| Step: 7
Training loss: 0.5988730217812005
Validation loss: 3.062169524287105

Epoch: 5| Step: 8
Training loss: 0.7488364890302566
Validation loss: 3.0662349482997704

Epoch: 5| Step: 9
Training loss: 0.6522774805455235
Validation loss: 3.088412397401575

Epoch: 5| Step: 10
Training loss: 0.8357752704959163
Validation loss: 3.025389567687554

Epoch: 5| Step: 11
Training loss: 0.43255356434892556
Validation loss: 2.963577918360022

Epoch: 254| Step: 0
Training loss: 1.5160353586809088
Validation loss: 2.989672471200698

Epoch: 5| Step: 1
Training loss: 0.749363112240023
Validation loss: 3.0350101489788215

Epoch: 5| Step: 2
Training loss: 0.6896070357183943
Validation loss: 3.0649265679715394

Epoch: 5| Step: 3
Training loss: 0.5321721880373772
Validation loss: 3.0027374718821602

Epoch: 5| Step: 4
Training loss: 0.8025412965410619
Validation loss: 2.9673061272810863

Epoch: 5| Step: 5
Training loss: 0.7477992671396726
Validation loss: 3.115103883312225

Epoch: 5| Step: 6
Training loss: 0.4209075891336228
Validation loss: 3.0804860794930513

Epoch: 5| Step: 7
Training loss: 0.5606611181934128
Validation loss: 3.0785310545187246

Epoch: 5| Step: 8
Training loss: 0.6011797194932684
Validation loss: 2.8881036914511835

Epoch: 5| Step: 9
Training loss: 0.7073409103157912
Validation loss: 2.9774785605447986

Epoch: 5| Step: 10
Training loss: 0.6867931590382749
Validation loss: 3.0029414015957583

Epoch: 5| Step: 11
Training loss: 0.801769484180612
Validation loss: 3.112235343103928

Epoch: 255| Step: 0
Training loss: 1.6180905386981783
Validation loss: 3.0464572294039707

Epoch: 5| Step: 1
Training loss: 0.5673980710838885
Validation loss: 3.0635076603736358

Epoch: 5| Step: 2
Training loss: 0.7649055526124905
Validation loss: 2.9040086984202

Epoch: 5| Step: 3
Training loss: 0.6458306825234761
Validation loss: 3.016462453539044

Epoch: 5| Step: 4
Training loss: 0.4569578682439214
Validation loss: 3.030647040892932

Epoch: 5| Step: 5
Training loss: 0.6650730522085082
Validation loss: 3.2198866840133133

Epoch: 5| Step: 6
Training loss: 0.48711552130424335
Validation loss: 3.0282158725463293

Epoch: 5| Step: 7
Training loss: 0.7108327767510451
Validation loss: 3.0233018599911463

Epoch: 5| Step: 8
Training loss: 0.6664491288588041
Validation loss: 2.957534149286627

Epoch: 5| Step: 9
Training loss: 0.441538461785443
Validation loss: 3.00569055523968

Epoch: 5| Step: 10
Training loss: 0.8367282300566988
Validation loss: 3.0046452215628605

Epoch: 5| Step: 11
Training loss: 0.3702278475036068
Validation loss: 3.10236797235249

Epoch: 256| Step: 0
Training loss: 0.43651988734224706
Validation loss: 3.0577975520160248

Epoch: 5| Step: 1
Training loss: 0.61975435470553
Validation loss: 3.0690690581079414

Epoch: 5| Step: 2
Training loss: 1.0207380847221454
Validation loss: 2.9660865983192046

Epoch: 5| Step: 3
Training loss: 0.7803104473021323
Validation loss: 3.024149466709459

Epoch: 5| Step: 4
Training loss: 1.5511905312647052
Validation loss: 3.09961439395491

Epoch: 5| Step: 5
Training loss: 0.6745915607691304
Validation loss: 3.0598571850655856

Epoch: 5| Step: 6
Training loss: 0.5771441257786938
Validation loss: 3.0955209383619158

Epoch: 5| Step: 7
Training loss: 0.4516475366427466
Validation loss: 3.0372423966726267

Epoch: 5| Step: 8
Training loss: 0.6001979163697128
Validation loss: 3.0877456647099017

Epoch: 5| Step: 9
Training loss: 0.6959617669440047
Validation loss: 3.1500879447003567

Epoch: 5| Step: 10
Training loss: 0.5468894684103799
Validation loss: 2.9417295442908826

Epoch: 5| Step: 11
Training loss: 0.8229844673007346
Validation loss: 2.9826463616104473

Epoch: 257| Step: 0
Training loss: 0.835088637552856
Validation loss: 2.979918672888809

Epoch: 5| Step: 1
Training loss: 0.7573037160118586
Validation loss: 3.018264610119721

Epoch: 5| Step: 2
Training loss: 0.6076362207142212
Validation loss: 3.1406523670123905

Epoch: 5| Step: 3
Training loss: 0.4080412511786765
Validation loss: 2.954364593817865

Epoch: 5| Step: 4
Training loss: 0.8125567416405254
Validation loss: 3.1034819895428276

Epoch: 5| Step: 5
Training loss: 0.5629222662435678
Validation loss: 3.0664440760132132

Epoch: 5| Step: 6
Training loss: 0.6402290330050694
Validation loss: 3.077293648416452

Epoch: 5| Step: 7
Training loss: 0.6059686381467942
Validation loss: 2.9190544107178917

Epoch: 5| Step: 8
Training loss: 1.4466201228171063
Validation loss: 3.0004174485108686

Epoch: 5| Step: 9
Training loss: 0.6521797430859388
Validation loss: 3.0824569807791704

Epoch: 5| Step: 10
Training loss: 0.5771569059367085
Validation loss: 3.058394875847037

Epoch: 5| Step: 11
Training loss: 0.7240023062179253
Validation loss: 2.9195918174138757

Epoch: 258| Step: 0
Training loss: 0.491607566557371
Validation loss: 3.0294529546507802

Epoch: 5| Step: 1
Training loss: 0.5765602483938028
Validation loss: 3.133778744137028

Epoch: 5| Step: 2
Training loss: 0.6389741328172177
Validation loss: 2.9315985012226107

Epoch: 5| Step: 3
Training loss: 0.8056921011929704
Validation loss: 3.007824885355233

Epoch: 5| Step: 4
Training loss: 0.590370322122321
Validation loss: 2.9701602229871193

Epoch: 5| Step: 5
Training loss: 0.644354177484493
Validation loss: 2.9382536442149636

Epoch: 5| Step: 6
Training loss: 0.46529762164860183
Validation loss: 3.1264264252686407

Epoch: 5| Step: 7
Training loss: 0.9047816647556419
Validation loss: 2.9884088227211367

Epoch: 5| Step: 8
Training loss: 0.5145908156969379
Validation loss: 3.026332697877489

Epoch: 5| Step: 9
Training loss: 0.7374208876640272
Validation loss: 3.0782745376642042

Epoch: 5| Step: 10
Training loss: 1.464809000238866
Validation loss: 3.026435548466329

Epoch: 5| Step: 11
Training loss: 0.7963635168198194
Validation loss: 3.020760904737336

Epoch: 259| Step: 0
Training loss: 0.4295572256793754
Validation loss: 3.054676745331573

Epoch: 5| Step: 1
Training loss: 0.6307936595785567
Validation loss: 3.0127065698546263

Epoch: 5| Step: 2
Training loss: 0.5674379358089323
Validation loss: 3.0828376620761477

Epoch: 5| Step: 3
Training loss: 0.516390261496355
Validation loss: 2.88230971902962

Epoch: 5| Step: 4
Training loss: 0.624987029894718
Validation loss: 2.9890558539511267

Epoch: 5| Step: 5
Training loss: 0.5460495031765502
Validation loss: 2.9678997394932893

Epoch: 5| Step: 6
Training loss: 0.7353541157590758
Validation loss: 3.0160118671840626

Epoch: 5| Step: 7
Training loss: 0.9016715183820893
Validation loss: 2.9678797768188865

Epoch: 5| Step: 8
Training loss: 0.5591794124899723
Validation loss: 2.9950344396403787

Epoch: 5| Step: 9
Training loss: 0.6585326685698519
Validation loss: 2.9453328820829476

Epoch: 5| Step: 10
Training loss: 1.479383327394617
Validation loss: 3.0159965016180754

Epoch: 5| Step: 11
Training loss: 0.5900179372097496
Validation loss: 3.0170716355484273

Epoch: 260| Step: 0
Training loss: 0.7504108019156056
Validation loss: 2.8873500314385434

Epoch: 5| Step: 1
Training loss: 0.4780998603594396
Validation loss: 2.906159050861719

Epoch: 5| Step: 2
Training loss: 0.8562766662677672
Validation loss: 3.030833959704392

Epoch: 5| Step: 3
Training loss: 0.7442483098168189
Validation loss: 3.0143559211698236

Epoch: 5| Step: 4
Training loss: 1.446133602011565
Validation loss: 2.997244357411415

Epoch: 5| Step: 5
Training loss: 0.6900158711695118
Validation loss: 2.933392920394597

Epoch: 5| Step: 6
Training loss: 0.640849051024407
Validation loss: 2.9751903611942923

Epoch: 5| Step: 7
Training loss: 0.563673913731262
Validation loss: 2.918371847653082

Epoch: 5| Step: 8
Training loss: 0.395471378108184
Validation loss: 3.053706389626001

Epoch: 5| Step: 9
Training loss: 0.5624554669447762
Validation loss: 3.006311122830712

Epoch: 5| Step: 10
Training loss: 0.5020631602760323
Validation loss: 3.068118384804779

Epoch: 5| Step: 11
Training loss: 0.7707942531748576
Validation loss: 3.0541942812897243

Epoch: 261| Step: 0
Training loss: 0.6125135780308637
Validation loss: 2.9802496593338508

Epoch: 5| Step: 1
Training loss: 0.540927204935448
Validation loss: 2.957132163902165

Epoch: 5| Step: 2
Training loss: 0.8363731176183837
Validation loss: 3.0752321259051745

Epoch: 5| Step: 3
Training loss: 0.7683857558841009
Validation loss: 3.0067840931820995

Epoch: 5| Step: 4
Training loss: 0.5531999494129883
Validation loss: 3.050062022334193

Epoch: 5| Step: 5
Training loss: 0.5264776393529139
Validation loss: 2.9915572648955804

Epoch: 5| Step: 6
Training loss: 1.509783785415923
Validation loss: 3.113227087528538

Epoch: 5| Step: 7
Training loss: 0.5150888140492303
Validation loss: 2.988332969866204

Epoch: 5| Step: 8
Training loss: 0.34619585042449463
Validation loss: 2.9552779280372294

Epoch: 5| Step: 9
Training loss: 0.5583291394042977
Validation loss: 3.0231556296898323

Epoch: 5| Step: 10
Training loss: 0.7553718039195514
Validation loss: 2.9684152983333747

Epoch: 5| Step: 11
Training loss: 0.718671752982757
Validation loss: 3.010922049083701

Epoch: 262| Step: 0
Training loss: 1.409272611836241
Validation loss: 3.1268135276321574

Epoch: 5| Step: 1
Training loss: 0.43104933893975855
Validation loss: 2.996389673664624

Epoch: 5| Step: 2
Training loss: 0.5601287771215528
Validation loss: 3.015856024106977

Epoch: 5| Step: 3
Training loss: 0.7095722042009174
Validation loss: 3.094693210302112

Epoch: 5| Step: 4
Training loss: 0.46303285755497076
Validation loss: 3.085472490388217

Epoch: 5| Step: 5
Training loss: 0.6442569033186644
Validation loss: 3.14072135916647

Epoch: 5| Step: 6
Training loss: 0.6227791668460217
Validation loss: 3.0804415859076353

Epoch: 5| Step: 7
Training loss: 0.5091666725874597
Validation loss: 3.0133103132968637

Epoch: 5| Step: 8
Training loss: 0.6400849461806037
Validation loss: 3.076727612870936

Epoch: 5| Step: 9
Training loss: 0.7057106794537636
Validation loss: 3.0192075212855474

Epoch: 5| Step: 10
Training loss: 0.9267370706051987
Validation loss: 3.0475594754318167

Epoch: 5| Step: 11
Training loss: 1.129810063848176
Validation loss: 3.034932099210715

Epoch: 263| Step: 0
Training loss: 0.629999312635077
Validation loss: 2.9589263859974357

Epoch: 5| Step: 1
Training loss: 0.8696463838563389
Validation loss: 2.96496227967326

Epoch: 5| Step: 2
Training loss: 0.663803633554254
Validation loss: 3.0276986486310276

Epoch: 5| Step: 3
Training loss: 0.5996333313172912
Validation loss: 3.00740838576948

Epoch: 5| Step: 4
Training loss: 0.46320462743110474
Validation loss: 3.073044335681976

Epoch: 5| Step: 5
Training loss: 1.516951147933672
Validation loss: 2.92225991907894

Epoch: 5| Step: 6
Training loss: 0.5926914315475952
Validation loss: 2.9475914985857337

Epoch: 5| Step: 7
Training loss: 0.4900402885534184
Validation loss: 3.0069910521317578

Epoch: 5| Step: 8
Training loss: 0.8592374865009473
Validation loss: 2.995087104267343

Epoch: 5| Step: 9
Training loss: 0.5706774184268452
Validation loss: 2.854356078431881

Epoch: 5| Step: 10
Training loss: 0.6443055653648031
Validation loss: 2.8838444269663555

Epoch: 5| Step: 11
Training loss: 0.4706585178369997
Validation loss: 2.9977424657567537

Epoch: 264| Step: 0
Training loss: 0.6660267893283364
Validation loss: 2.955444343500404

Epoch: 5| Step: 1
Training loss: 0.6679633514007671
Validation loss: 2.9798974672488754

Epoch: 5| Step: 2
Training loss: 1.7195577630681542
Validation loss: 2.9517165968226133

Epoch: 5| Step: 3
Training loss: 0.4792985233692032
Validation loss: 2.9483358581629915

Epoch: 5| Step: 4
Training loss: 0.5963004947369864
Validation loss: 2.95773728616438

Epoch: 5| Step: 5
Training loss: 0.5285526124539803
Validation loss: 2.979660171146086

Epoch: 5| Step: 6
Training loss: 0.5280442001110223
Validation loss: 3.073382110691325

Epoch: 5| Step: 7
Training loss: 0.3149706449908676
Validation loss: 3.002009599527153

Epoch: 5| Step: 8
Training loss: 0.5563444989546541
Validation loss: 3.081652893256036

Epoch: 5| Step: 9
Training loss: 0.47026283597589663
Validation loss: 3.0702399713622532

Epoch: 5| Step: 10
Training loss: 0.5631003355156331
Validation loss: 2.9534661164977933

Epoch: 5| Step: 11
Training loss: 0.7894097498888676
Validation loss: 3.1160382898717955

Epoch: 265| Step: 0
Training loss: 0.6668398949947736
Validation loss: 3.0810645891726707

Epoch: 5| Step: 1
Training loss: 0.6649205218411055
Validation loss: 2.8962652767054546

Epoch: 5| Step: 2
Training loss: 0.5668916398269555
Validation loss: 3.0726218303036434

Epoch: 5| Step: 3
Training loss: 0.5024466259447045
Validation loss: 3.0357655257754463

Epoch: 5| Step: 4
Training loss: 1.4596648359325701
Validation loss: 3.082694468596704

Epoch: 5| Step: 5
Training loss: 0.4513748505031409
Validation loss: 3.0558676622881324

Epoch: 5| Step: 6
Training loss: 0.48344427334578277
Validation loss: 3.0329268330283417

Epoch: 5| Step: 7
Training loss: 0.34172050712841856
Validation loss: 3.014112472054002

Epoch: 5| Step: 8
Training loss: 0.8969575385417126
Validation loss: 2.940848214423591

Epoch: 5| Step: 9
Training loss: 0.6609616755399611
Validation loss: 2.9602738226285386

Epoch: 5| Step: 10
Training loss: 0.7172055028180923
Validation loss: 3.022962508236315

Epoch: 5| Step: 11
Training loss: 0.5795561628831338
Validation loss: 2.9915913717593554

Epoch: 266| Step: 0
Training loss: 0.7315857043327997
Validation loss: 3.0096165518837714

Epoch: 5| Step: 1
Training loss: 0.6557906904943058
Validation loss: 3.022149477817356

Epoch: 5| Step: 2
Training loss: 0.7236009763234491
Validation loss: 2.937439701462463

Epoch: 5| Step: 3
Training loss: 0.36684738802614947
Validation loss: 3.0023208224205065

Epoch: 5| Step: 4
Training loss: 0.5585862539361952
Validation loss: 2.9636081370769434

Epoch: 5| Step: 5
Training loss: 0.37299102844514587
Validation loss: 2.946528196508377

Epoch: 5| Step: 6
Training loss: 0.3260608986838448
Validation loss: 3.0577605222125355

Epoch: 5| Step: 7
Training loss: 0.583073342376958
Validation loss: 3.001889938189188

Epoch: 5| Step: 8
Training loss: 0.7676600055847295
Validation loss: 3.097189949539402

Epoch: 5| Step: 9
Training loss: 0.5652837746208619
Validation loss: 3.109979784757735

Epoch: 5| Step: 10
Training loss: 1.5932135333561734
Validation loss: 2.966628909719061

Epoch: 5| Step: 11
Training loss: 0.48064642621561643
Validation loss: 2.979874297889516

Epoch: 267| Step: 0
Training loss: 0.6343114783519095
Validation loss: 3.0034919787120358

Epoch: 5| Step: 1
Training loss: 0.5701353764809777
Validation loss: 3.0143714961290544

Epoch: 5| Step: 2
Training loss: 0.4793290367621412
Validation loss: 3.107672392926793

Epoch: 5| Step: 3
Training loss: 0.6083987803940396
Validation loss: 3.0581382227116136

Epoch: 5| Step: 4
Training loss: 0.467728327923449
Validation loss: 3.0660349918783667

Epoch: 5| Step: 5
Training loss: 0.584664347611761
Validation loss: 3.053040967218895

Epoch: 5| Step: 6
Training loss: 0.6096625016648796
Validation loss: 3.0420221269092487

Epoch: 5| Step: 7
Training loss: 0.5859494525961879
Validation loss: 2.985929041247827

Epoch: 5| Step: 8
Training loss: 1.4112756148683825
Validation loss: 3.0607865074814002

Epoch: 5| Step: 9
Training loss: 0.5637271264504526
Validation loss: 3.088798587313489

Epoch: 5| Step: 10
Training loss: 0.8566690324560171
Validation loss: 3.0177862167622744

Epoch: 5| Step: 11
Training loss: 0.3149691783872973
Validation loss: 2.9911469857352433

Epoch: 268| Step: 0
Training loss: 0.5336116022611563
Validation loss: 3.053297118297707

Epoch: 5| Step: 1
Training loss: 0.38631570408431537
Validation loss: 3.1196793274350645

Epoch: 5| Step: 2
Training loss: 0.8395513690956634
Validation loss: 3.1117939796838763

Epoch: 5| Step: 3
Training loss: 0.5267365527362463
Validation loss: 3.067048564788618

Epoch: 5| Step: 4
Training loss: 0.3971869534264382
Validation loss: 3.0080036548461675

Epoch: 5| Step: 5
Training loss: 0.6594567288916128
Validation loss: 3.0826763063055123

Epoch: 5| Step: 6
Training loss: 0.6223270958221958
Validation loss: 3.0435058550664746

Epoch: 5| Step: 7
Training loss: 0.5440118499001675
Validation loss: 3.0185551383689626

Epoch: 5| Step: 8
Training loss: 0.40641119399944575
Validation loss: 2.936627945067352

Epoch: 5| Step: 9
Training loss: 0.7333662937805528
Validation loss: 3.0168403851209415

Epoch: 5| Step: 10
Training loss: 1.4879260502867158
Validation loss: 2.924249248802513

Epoch: 5| Step: 11
Training loss: 0.5864320829308582
Validation loss: 2.9281654473180856

Epoch: 269| Step: 0
Training loss: 0.6582442816932529
Validation loss: 2.879793883449324

Epoch: 5| Step: 1
Training loss: 0.6318053955997938
Validation loss: 2.998293696048382

Epoch: 5| Step: 2
Training loss: 0.5950728787740193
Validation loss: 3.1202456006611863

Epoch: 5| Step: 3
Training loss: 0.5385294503966794
Validation loss: 2.9700594640916322

Epoch: 5| Step: 4
Training loss: 0.6518733447191942
Validation loss: 3.078083777111299

Epoch: 5| Step: 5
Training loss: 0.8552218912763686
Validation loss: 3.1213760089200218

Epoch: 5| Step: 6
Training loss: 0.5135611062951899
Validation loss: 3.0626443841854623

Epoch: 5| Step: 7
Training loss: 0.5238803299869612
Validation loss: 3.070206945285732

Epoch: 5| Step: 8
Training loss: 0.49312892070995695
Validation loss: 2.9886525739954743

Epoch: 5| Step: 9
Training loss: 0.5368741161796569
Validation loss: 3.002963347621098

Epoch: 5| Step: 10
Training loss: 1.4770403699271497
Validation loss: 3.0844482240549134

Epoch: 5| Step: 11
Training loss: 0.23900516171447897
Validation loss: 3.1005550513143407

Epoch: 270| Step: 0
Training loss: 0.6966608240104631
Validation loss: 3.0786633964652412

Epoch: 5| Step: 1
Training loss: 0.4806919509876053
Validation loss: 3.01675022459136

Epoch: 5| Step: 2
Training loss: 0.5668163524938005
Validation loss: 3.033087589628771

Epoch: 5| Step: 3
Training loss: 0.8464361454312673
Validation loss: 3.1671518510425347

Epoch: 5| Step: 4
Training loss: 0.4102145017402617
Validation loss: 3.0425027074987256

Epoch: 5| Step: 5
Training loss: 1.5540557037640612
Validation loss: 3.0895772916323616

Epoch: 5| Step: 6
Training loss: 0.5506490995262056
Validation loss: 3.026890113231488

Epoch: 5| Step: 7
Training loss: 0.5147903507307959
Validation loss: 3.081205624098987

Epoch: 5| Step: 8
Training loss: 0.5807224381631532
Validation loss: 3.097821100185143

Epoch: 5| Step: 9
Training loss: 0.5289075482351128
Validation loss: 3.0253985843836957

Epoch: 5| Step: 10
Training loss: 0.5073605800664985
Validation loss: 3.0631629200406754

Epoch: 5| Step: 11
Training loss: 0.49993024279838444
Validation loss: 2.9920506126492725

Epoch: 271| Step: 0
Training loss: 0.5777417020610374
Validation loss: 3.0142884529181395

Epoch: 5| Step: 1
Training loss: 0.47870633742924945
Validation loss: 3.0942053347396636

Epoch: 5| Step: 2
Training loss: 0.5721009053196284
Validation loss: 3.074852509308347

Epoch: 5| Step: 3
Training loss: 0.514257872770185
Validation loss: 3.0492304606322356

Epoch: 5| Step: 4
Training loss: 0.7511741269177561
Validation loss: 2.9621796363661534

Epoch: 5| Step: 5
Training loss: 0.6749035642753894
Validation loss: 3.0520025976046234

Epoch: 5| Step: 6
Training loss: 0.5441401353602455
Validation loss: 3.0569969058981474

Epoch: 5| Step: 7
Training loss: 1.4569934502574189
Validation loss: 2.9602215923884287

Epoch: 5| Step: 8
Training loss: 0.6412987538816194
Validation loss: 3.0313672046353246

Epoch: 5| Step: 9
Training loss: 0.4882127179689617
Validation loss: 2.9907185506987126

Epoch: 5| Step: 10
Training loss: 0.45895746030419987
Validation loss: 2.866305542163854

Epoch: 5| Step: 11
Training loss: 0.12124674499581635
Validation loss: 3.038798326452992

Epoch: 272| Step: 0
Training loss: 0.7696037839214583
Validation loss: 3.089304153902907

Epoch: 5| Step: 1
Training loss: 0.47050300871224554
Validation loss: 3.0907000525824175

Epoch: 5| Step: 2
Training loss: 0.7420763434441983
Validation loss: 2.935750511350005

Epoch: 5| Step: 3
Training loss: 0.5209828511836961
Validation loss: 2.982880322907726

Epoch: 5| Step: 4
Training loss: 0.5601048604251349
Validation loss: 2.924480303489258

Epoch: 5| Step: 5
Training loss: 0.5588166385741001
Validation loss: 2.982996237657497

Epoch: 5| Step: 6
Training loss: 0.5982071076960889
Validation loss: 3.0072467585664664

Epoch: 5| Step: 7
Training loss: 0.43958092420680184
Validation loss: 3.0723024573425146

Epoch: 5| Step: 8
Training loss: 0.4623436573334008
Validation loss: 2.925026015630593

Epoch: 5| Step: 9
Training loss: 1.3565523944329825
Validation loss: 2.9254741634870345

Epoch: 5| Step: 10
Training loss: 0.5291462363657059
Validation loss: 3.1120048213310945

Epoch: 5| Step: 11
Training loss: 0.8605042061290094
Validation loss: 2.9230291497648393

Epoch: 273| Step: 0
Training loss: 0.5317514241033153
Validation loss: 2.991483965867356

Epoch: 5| Step: 1
Training loss: 0.6728679948414125
Validation loss: 3.03986388936492

Epoch: 5| Step: 2
Training loss: 0.3853235604832697
Validation loss: 2.949933280028684

Epoch: 5| Step: 3
Training loss: 0.8674955078800216
Validation loss: 2.910006245751686

Epoch: 5| Step: 4
Training loss: 1.4533830639149659
Validation loss: 3.035943935961404

Epoch: 5| Step: 5
Training loss: 0.4882749023024897
Validation loss: 3.015439563116274

Epoch: 5| Step: 6
Training loss: 0.44112789188127827
Validation loss: 2.9537534364649924

Epoch: 5| Step: 7
Training loss: 0.5466060522054967
Validation loss: 2.999477215091905

Epoch: 5| Step: 8
Training loss: 0.5336890888076543
Validation loss: 3.010618458268836

Epoch: 5| Step: 9
Training loss: 0.35898066737737416
Validation loss: 3.031610536272403

Epoch: 5| Step: 10
Training loss: 0.5630038971401866
Validation loss: 3.0323280370731096

Epoch: 5| Step: 11
Training loss: 0.8519434995251793
Validation loss: 2.98025493929831

Epoch: 274| Step: 0
Training loss: 0.46186842904688397
Validation loss: 3.050911187902419

Epoch: 5| Step: 1
Training loss: 0.7080493993713103
Validation loss: 2.964735556041066

Epoch: 5| Step: 2
Training loss: 0.9087451588896578
Validation loss: 3.1018610793751944

Epoch: 5| Step: 3
Training loss: 0.4851976914451538
Validation loss: 2.990797146446908

Epoch: 5| Step: 4
Training loss: 0.5662805351967293
Validation loss: 2.9435101297302624

Epoch: 5| Step: 5
Training loss: 0.8475897978299627
Validation loss: 3.0677717404162403

Epoch: 5| Step: 6
Training loss: 1.4363071634123663
Validation loss: 3.0282752230413195

Epoch: 5| Step: 7
Training loss: 0.4196934633264507
Validation loss: 3.074728923830932

Epoch: 5| Step: 8
Training loss: 0.6810109637802088
Validation loss: 3.046027386785393

Epoch: 5| Step: 9
Training loss: 0.6811064236383522
Validation loss: 3.0088510974306883

Epoch: 5| Step: 10
Training loss: 0.7477095119594221
Validation loss: 3.0171794212334557

Epoch: 5| Step: 11
Training loss: 0.2779268662717651
Validation loss: 3.0424888242173074

Epoch: 275| Step: 0
Training loss: 0.6495088206977755
Validation loss: 3.037370006176264

Epoch: 5| Step: 1
Training loss: 1.4043265433752086
Validation loss: 3.074469475739229

Epoch: 5| Step: 2
Training loss: 0.6544910655158617
Validation loss: 2.9278008858707594

Epoch: 5| Step: 3
Training loss: 0.5456914628789059
Validation loss: 3.0932513101588808

Epoch: 5| Step: 4
Training loss: 0.6094819244085926
Validation loss: 2.9851335556763647

Epoch: 5| Step: 5
Training loss: 0.40197865115005216
Validation loss: 2.993660360970684

Epoch: 5| Step: 6
Training loss: 0.588531373083069
Validation loss: 2.990781933670626

Epoch: 5| Step: 7
Training loss: 0.4133628836702582
Validation loss: 2.979773517414595

Epoch: 5| Step: 8
Training loss: 0.4634341658191264
Validation loss: 3.0045866507779624

Epoch: 5| Step: 9
Training loss: 0.8515584753098878
Validation loss: 3.042389082797579

Epoch: 5| Step: 10
Training loss: 0.585726916300764
Validation loss: 3.0272515789480146

Epoch: 5| Step: 11
Training loss: 0.6931295954394576
Validation loss: 3.0403743779135626

Epoch: 276| Step: 0
Training loss: 0.4308061084347897
Validation loss: 3.078648585601869

Epoch: 5| Step: 1
Training loss: 0.6944177850268458
Validation loss: 2.925437431692792

Epoch: 5| Step: 2
Training loss: 1.4233066770899905
Validation loss: 2.976781194601023

Epoch: 5| Step: 3
Training loss: 0.6987435414966054
Validation loss: 3.0099148260519484

Epoch: 5| Step: 4
Training loss: 0.4194351214024676
Validation loss: 2.9068532457797347

Epoch: 5| Step: 5
Training loss: 0.48374672104958844
Validation loss: 2.9938815494801405

Epoch: 5| Step: 6
Training loss: 0.4830248535457318
Validation loss: 2.8916413281802775

Epoch: 5| Step: 7
Training loss: 0.745143344964976
Validation loss: 3.0677295364571124

Epoch: 5| Step: 8
Training loss: 0.6026820132243057
Validation loss: 3.033583038177558

Epoch: 5| Step: 9
Training loss: 0.47826335251629165
Validation loss: 2.9948114189933985

Epoch: 5| Step: 10
Training loss: 0.8483485545820733
Validation loss: 3.0428381529872586

Epoch: 5| Step: 11
Training loss: 0.3503745459159987
Validation loss: 3.0445566502765247

Epoch: 277| Step: 0
Training loss: 0.5238167257298953
Validation loss: 2.995236738000001

Epoch: 5| Step: 1
Training loss: 0.77227194459806
Validation loss: 3.1423954156837883

Epoch: 5| Step: 2
Training loss: 0.7432337564078502
Validation loss: 3.09912340488551

Epoch: 5| Step: 3
Training loss: 0.6251359314919073
Validation loss: 2.9817128049487382

Epoch: 5| Step: 4
Training loss: 1.0230165737073647
Validation loss: 2.916743401244609

Epoch: 5| Step: 5
Training loss: 1.4550566601290107
Validation loss: 3.052878397779874

Epoch: 5| Step: 6
Training loss: 0.7228885586539097
Validation loss: 2.940750751515912

Epoch: 5| Step: 7
Training loss: 0.6434491408167234
Validation loss: 2.935571693692819

Epoch: 5| Step: 8
Training loss: 0.6278314825124711
Validation loss: 2.9965612783630746

Epoch: 5| Step: 9
Training loss: 0.6417320501984749
Validation loss: 2.9673082933417847

Epoch: 5| Step: 10
Training loss: 0.43762676922817256
Validation loss: 2.975388239390107

Epoch: 5| Step: 11
Training loss: 0.48748503808756805
Validation loss: 3.059121496824311

Epoch: 278| Step: 0
Training loss: 0.6604206300690753
Validation loss: 3.0351331817129985

Epoch: 5| Step: 1
Training loss: 0.47727478453163885
Validation loss: 3.0210091616443124

Epoch: 5| Step: 2
Training loss: 0.6267206111434277
Validation loss: 3.024048552096445

Epoch: 5| Step: 3
Training loss: 0.4490183507656907
Validation loss: 2.9312178077909206

Epoch: 5| Step: 4
Training loss: 0.770740198402802
Validation loss: 2.978329678760742

Epoch: 5| Step: 5
Training loss: 0.45256697066930135
Validation loss: 2.978953871874491

Epoch: 5| Step: 6
Training loss: 0.544490465691973
Validation loss: 3.0512827364592634

Epoch: 5| Step: 7
Training loss: 0.6367274090698829
Validation loss: 2.977568255404731

Epoch: 5| Step: 8
Training loss: 0.672301268089854
Validation loss: 3.0070796750891113

Epoch: 5| Step: 9
Training loss: 1.5879518841965703
Validation loss: 3.0512286422723798

Epoch: 5| Step: 10
Training loss: 0.4243900423937419
Validation loss: 2.920896777789496

Epoch: 5| Step: 11
Training loss: 0.6781005969249267
Validation loss: 2.9777535686252152

Epoch: 279| Step: 0
Training loss: 0.6891720336565162
Validation loss: 2.954917394045006

Epoch: 5| Step: 1
Training loss: 0.5052913879343852
Validation loss: 3.0065353786819466

Epoch: 5| Step: 2
Training loss: 0.559616433151961
Validation loss: 2.9496066716206646

Epoch: 5| Step: 3
Training loss: 0.6497413212224822
Validation loss: 2.948396789668651

Epoch: 5| Step: 4
Training loss: 0.4354651507012273
Validation loss: 3.0349185839096466

Epoch: 5| Step: 5
Training loss: 0.5855476099458832
Validation loss: 2.9250758075671817

Epoch: 5| Step: 6
Training loss: 0.4997711104771324
Validation loss: 3.0555914299958955

Epoch: 5| Step: 7
Training loss: 0.9057987010222975
Validation loss: 2.9581059057276473

Epoch: 5| Step: 8
Training loss: 1.4316924165150111
Validation loss: 2.9311910475582383

Epoch: 5| Step: 9
Training loss: 0.4114906040847847
Validation loss: 2.948857111368752

Epoch: 5| Step: 10
Training loss: 0.5301233293434592
Validation loss: 2.8999129427525445

Epoch: 5| Step: 11
Training loss: 0.5336493277474116
Validation loss: 2.9924514428333935

Epoch: 280| Step: 0
Training loss: 0.5507613915725483
Validation loss: 3.0224931541619866

Epoch: 5| Step: 1
Training loss: 0.46953334522255874
Validation loss: 3.011949315132888

Epoch: 5| Step: 2
Training loss: 1.533650521283286
Validation loss: 3.0125803788991683

Epoch: 5| Step: 3
Training loss: 0.5535175180772971
Validation loss: 3.016300316865317

Epoch: 5| Step: 4
Training loss: 0.5727039520255203
Validation loss: 2.9923940608851427

Epoch: 5| Step: 5
Training loss: 0.4698200410392717
Validation loss: 2.935365892534742

Epoch: 5| Step: 6
Training loss: 0.4940771733131241
Validation loss: 2.8953819483418775

Epoch: 5| Step: 7
Training loss: 0.8749085106021848
Validation loss: 2.9499675953696296

Epoch: 5| Step: 8
Training loss: 0.6950513370681898
Validation loss: 2.9596515436344277

Epoch: 5| Step: 9
Training loss: 0.4234243482398329
Validation loss: 3.0320485888519997

Epoch: 5| Step: 10
Training loss: 0.49105486656102554
Validation loss: 2.9490347461688673

Epoch: 5| Step: 11
Training loss: 0.2210263274140976
Validation loss: 2.990276612943391

Epoch: 281| Step: 0
Training loss: 1.496219958367873
Validation loss: 3.0183155232874226

Epoch: 5| Step: 1
Training loss: 0.40606753212933044
Validation loss: 2.999244298393047

Epoch: 5| Step: 2
Training loss: 0.6153133281122916
Validation loss: 2.994324222517147

Epoch: 5| Step: 3
Training loss: 0.4956059949148608
Validation loss: 3.0166763554903966

Epoch: 5| Step: 4
Training loss: 0.498542613721884
Validation loss: 2.9752102447664606

Epoch: 5| Step: 5
Training loss: 0.6060086703986401
Validation loss: 3.0486223475993324

Epoch: 5| Step: 6
Training loss: 0.6688059417999105
Validation loss: 2.9368549342071053

Epoch: 5| Step: 7
Training loss: 0.5056882885625148
Validation loss: 3.0447924351742888

Epoch: 5| Step: 8
Training loss: 0.341562299614906
Validation loss: 3.025575767189554

Epoch: 5| Step: 9
Training loss: 0.6905758715110178
Validation loss: 2.9833847853061544

Epoch: 5| Step: 10
Training loss: 0.6514335724317786
Validation loss: 3.04224177806666

Epoch: 5| Step: 11
Training loss: 0.9312675576827046
Validation loss: 3.0143573844152924

Epoch: 282| Step: 0
Training loss: 0.6273743827438282
Validation loss: 2.9342443741123176

Epoch: 5| Step: 1
Training loss: 0.6453974827188624
Validation loss: 3.073955073797104

Epoch: 5| Step: 2
Training loss: 0.6704559199417555
Validation loss: 3.02968660655934

Epoch: 5| Step: 3
Training loss: 0.7090528050546271
Validation loss: 2.899142574569484

Epoch: 5| Step: 4
Training loss: 0.7303426297085237
Validation loss: 3.1194297992486693

Epoch: 5| Step: 5
Training loss: 0.779505689748243
Validation loss: 3.0385565446906346

Epoch: 5| Step: 6
Training loss: 0.638898919955117
Validation loss: 2.995612820816034

Epoch: 5| Step: 7
Training loss: 0.45891115943846517
Validation loss: 2.9499938821998564

Epoch: 5| Step: 8
Training loss: 1.3845757917913781
Validation loss: 2.9255183109822447

Epoch: 5| Step: 9
Training loss: 0.4932201391385549
Validation loss: 2.959860412038453

Epoch: 5| Step: 10
Training loss: 0.6376969248355502
Validation loss: 2.935234332372375

Epoch: 5| Step: 11
Training loss: 0.5470314074692858
Validation loss: 2.9951134727180526

Epoch: 283| Step: 0
Training loss: 0.6437157066247716
Validation loss: 3.0019239111103246

Epoch: 5| Step: 1
Training loss: 0.5773033540915382
Validation loss: 2.981367816369777

Epoch: 5| Step: 2
Training loss: 0.38453834133437464
Validation loss: 2.974448593980902

Epoch: 5| Step: 3
Training loss: 0.5411063163018551
Validation loss: 3.080980164381809

Epoch: 5| Step: 4
Training loss: 0.7564816537839826
Validation loss: 3.0948485694172754

Epoch: 5| Step: 5
Training loss: 0.5352843750771086
Validation loss: 2.9898049652319174

Epoch: 5| Step: 6
Training loss: 0.556042319543121
Validation loss: 3.0175962511359757

Epoch: 5| Step: 7
Training loss: 0.7886241412820946
Validation loss: 3.043782058171008

Epoch: 5| Step: 8
Training loss: 0.44754419438876797
Validation loss: 3.0187439675596632

Epoch: 5| Step: 9
Training loss: 0.44909241599910166
Validation loss: 2.9989166456061005

Epoch: 5| Step: 10
Training loss: 1.4454427299594583
Validation loss: 2.988453383464196

Epoch: 5| Step: 11
Training loss: 0.506190718017327
Validation loss: 3.028729036106173

Epoch: 284| Step: 0
Training loss: 0.5288751195764553
Validation loss: 3.0033080022430227

Epoch: 5| Step: 1
Training loss: 0.5004918837999154
Validation loss: 3.041635220291065

Epoch: 5| Step: 2
Training loss: 0.5726467594958006
Validation loss: 3.0049398567868946

Epoch: 5| Step: 3
Training loss: 0.680021423219759
Validation loss: 2.9590546115978644

Epoch: 5| Step: 4
Training loss: 0.8555658363747067
Validation loss: 3.035018701762816

Epoch: 5| Step: 5
Training loss: 0.4221605817795779
Validation loss: 3.034668283009839

Epoch: 5| Step: 6
Training loss: 0.6973840308431151
Validation loss: 3.154685507690748

Epoch: 5| Step: 7
Training loss: 1.3946254922774148
Validation loss: 3.0093843324595113

Epoch: 5| Step: 8
Training loss: 0.6244843978811202
Validation loss: 3.0650485165237367

Epoch: 5| Step: 9
Training loss: 0.6350174859034852
Validation loss: 3.011835124879938

Epoch: 5| Step: 10
Training loss: 0.6259891550401329
Validation loss: 2.970128950467529

Epoch: 5| Step: 11
Training loss: 1.0445384240028917
Validation loss: 3.042504317197764

Epoch: 285| Step: 0
Training loss: 0.5092365252191999
Validation loss: 3.0648210838271255

Epoch: 5| Step: 1
Training loss: 0.5623737299443318
Validation loss: 3.1229412386239064

Epoch: 5| Step: 2
Training loss: 1.4099663265752522
Validation loss: 2.9476951722595772

Epoch: 5| Step: 3
Training loss: 0.5190306237691441
Validation loss: 3.038390833123482

Epoch: 5| Step: 4
Training loss: 0.7196598513779501
Validation loss: 2.9255372146402263

Epoch: 5| Step: 5
Training loss: 0.5870344955602363
Validation loss: 3.1341164080058883

Epoch: 5| Step: 6
Training loss: 0.34765285318836847
Validation loss: 3.0755347117800764

Epoch: 5| Step: 7
Training loss: 0.49964045471919544
Validation loss: 2.9471331702067594

Epoch: 5| Step: 8
Training loss: 0.39603332645531414
Validation loss: 3.0189144266128145

Epoch: 5| Step: 9
Training loss: 0.5917141293127954
Validation loss: 3.007876919803795

Epoch: 5| Step: 10
Training loss: 0.6480703118554567
Validation loss: 3.008674428725322

Epoch: 5| Step: 11
Training loss: 0.6529382977273106
Validation loss: 2.9200527540323113

Epoch: 286| Step: 0
Training loss: 0.6219080499272507
Validation loss: 2.88933257688283

Epoch: 5| Step: 1
Training loss: 1.365471378650835
Validation loss: 3.041178273265722

Epoch: 5| Step: 2
Training loss: 0.5641373803901635
Validation loss: 3.1294041339474767

Epoch: 5| Step: 3
Training loss: 0.43217757646003746
Validation loss: 2.974931525396053

Epoch: 5| Step: 4
Training loss: 0.53610604641498
Validation loss: 2.9784663895670227

Epoch: 5| Step: 5
Training loss: 0.46239568912990536
Validation loss: 3.07685311338007

Epoch: 5| Step: 6
Training loss: 0.566175190065916
Validation loss: 2.971456481928381

Epoch: 5| Step: 7
Training loss: 0.44685236400014355
Validation loss: 2.9987128463464012

Epoch: 5| Step: 8
Training loss: 0.4704640204610934
Validation loss: 2.96766036264772

Epoch: 5| Step: 9
Training loss: 0.8156022854269241
Validation loss: 2.9869194434973543

Epoch: 5| Step: 10
Training loss: 0.5290742525619334
Validation loss: 3.012932670883814

Epoch: 5| Step: 11
Training loss: 0.37089714062118995
Validation loss: 3.0863255027505896

Epoch: 287| Step: 0
Training loss: 0.5748180194725372
Validation loss: 2.9527145955004928

Epoch: 5| Step: 1
Training loss: 0.45200436234900965
Validation loss: 2.9386805637550117

Epoch: 5| Step: 2
Training loss: 0.40824324123256434
Validation loss: 2.9675672350076887

Epoch: 5| Step: 3
Training loss: 0.6800755675485236
Validation loss: 3.0575312542767006

Epoch: 5| Step: 4
Training loss: 0.5126422091639259
Validation loss: 3.0293525479167243

Epoch: 5| Step: 5
Training loss: 0.552465636362774
Validation loss: 3.055694388115871

Epoch: 5| Step: 6
Training loss: 0.7372955119591524
Validation loss: 2.993705417617001

Epoch: 5| Step: 7
Training loss: 1.4248319627165724
Validation loss: 2.9124390389716512

Epoch: 5| Step: 8
Training loss: 0.4565536416178106
Validation loss: 2.9609327894993656

Epoch: 5| Step: 9
Training loss: 0.5205583100577946
Validation loss: 3.0378797790822936

Epoch: 5| Step: 10
Training loss: 0.5372543694117444
Validation loss: 3.0943299979667547

Epoch: 5| Step: 11
Training loss: 1.0498009969956934
Validation loss: 2.8915130350891123

Epoch: 288| Step: 0
Training loss: 0.4182386507294663
Validation loss: 3.115325039906493

Epoch: 5| Step: 1
Training loss: 0.6480349474654872
Validation loss: 3.0548834367955533

Epoch: 5| Step: 2
Training loss: 0.43450599794560896
Validation loss: 3.041306063862659

Epoch: 5| Step: 3
Training loss: 0.40370682491427917
Validation loss: 3.058566347066831

Epoch: 5| Step: 4
Training loss: 1.390142121219086
Validation loss: 3.076031684708582

Epoch: 5| Step: 5
Training loss: 0.586007253945341
Validation loss: 3.1291052968897985

Epoch: 5| Step: 6
Training loss: 0.44998829482007907
Validation loss: 3.0006658556884176

Epoch: 5| Step: 7
Training loss: 0.6514844431421364
Validation loss: 3.091706072786671

Epoch: 5| Step: 8
Training loss: 0.9110667704599694
Validation loss: 3.183676720534596

Epoch: 5| Step: 9
Training loss: 0.41048240409477527
Validation loss: 3.1629805359371668

Epoch: 5| Step: 10
Training loss: 0.6161517856941329
Validation loss: 3.067345587500381

Epoch: 5| Step: 11
Training loss: 0.1880329722997152
Validation loss: 3.0952923747908345

Epoch: 289| Step: 0
Training loss: 0.660017055305558
Validation loss: 3.1534518847164046

Epoch: 5| Step: 1
Training loss: 0.45275472442209425
Validation loss: 3.2259298417086906

Epoch: 5| Step: 2
Training loss: 0.6507716852517899
Validation loss: 3.1327552821894886

Epoch: 5| Step: 3
Training loss: 0.49010759211230626
Validation loss: 3.141921191862769

Epoch: 5| Step: 4
Training loss: 0.5169523666950467
Validation loss: 3.06250053684723

Epoch: 5| Step: 5
Training loss: 1.388760677883737
Validation loss: 3.2333886889425285

Epoch: 5| Step: 6
Training loss: 0.589807724010408
Validation loss: 3.0878903998017555

Epoch: 5| Step: 7
Training loss: 0.8531390653575608
Validation loss: 3.123170444253832

Epoch: 5| Step: 8
Training loss: 0.6563944430561783
Validation loss: 3.0385654634667003

Epoch: 5| Step: 9
Training loss: 0.47313177605315754
Validation loss: 2.9157638355929794

Epoch: 5| Step: 10
Training loss: 0.43335373567577745
Validation loss: 3.004735672581609

Epoch: 5| Step: 11
Training loss: 0.229707860044274
Validation loss: 3.181536144135811

Epoch: 290| Step: 0
Training loss: 0.5256984617174125
Validation loss: 3.18678593740472

Epoch: 5| Step: 1
Training loss: 1.3796203752478031
Validation loss: 3.0860792747154084

Epoch: 5| Step: 2
Training loss: 0.6967234921513221
Validation loss: 3.2050697408686983

Epoch: 5| Step: 3
Training loss: 0.5623962253635842
Validation loss: 3.104534432474856

Epoch: 5| Step: 4
Training loss: 0.37161471289579207
Validation loss: 3.1123346272035834

Epoch: 5| Step: 5
Training loss: 0.5896939219987802
Validation loss: 3.014213636928978

Epoch: 5| Step: 6
Training loss: 0.7080749479888777
Validation loss: 3.0774620232923295

Epoch: 5| Step: 7
Training loss: 0.5720370881137766
Validation loss: 3.067368653191976

Epoch: 5| Step: 8
Training loss: 0.6789601259616606
Validation loss: 3.089433555205027

Epoch: 5| Step: 9
Training loss: 0.7850485201133685
Validation loss: 3.096596336466042

Epoch: 5| Step: 10
Training loss: 0.5532129325584532
Validation loss: 3.0222445704799266

Epoch: 5| Step: 11
Training loss: 0.5745992113740677
Validation loss: 3.070590866450947

Epoch: 291| Step: 0
Training loss: 0.6621886349389727
Validation loss: 3.1164013597117397

Epoch: 5| Step: 1
Training loss: 0.4137041592630237
Validation loss: 3.1186930909248973

Epoch: 5| Step: 2
Training loss: 0.7490744442836896
Validation loss: 3.0543956080538264

Epoch: 5| Step: 3
Training loss: 1.4661896486211723
Validation loss: 3.0073815074133416

Epoch: 5| Step: 4
Training loss: 0.37525107005663744
Validation loss: 3.0979137530096152

Epoch: 5| Step: 5
Training loss: 0.45285068627375297
Validation loss: 3.0559755456919246

Epoch: 5| Step: 6
Training loss: 0.31456576870941055
Validation loss: 3.072341630225498

Epoch: 5| Step: 7
Training loss: 0.546236837520934
Validation loss: 3.0235256474646053

Epoch: 5| Step: 8
Training loss: 0.48444710471699254
Validation loss: 3.095559528602464

Epoch: 5| Step: 9
Training loss: 0.5766871847331896
Validation loss: 2.9840691794239698

Epoch: 5| Step: 10
Training loss: 0.5793346174090165
Validation loss: 3.024503469043806

Epoch: 5| Step: 11
Training loss: 0.6380486203325451
Validation loss: 2.9954615244626464

Epoch: 292| Step: 0
Training loss: 0.4568784735530622
Validation loss: 3.1726414172650803

Epoch: 5| Step: 1
Training loss: 0.614147716171191
Validation loss: 2.97955234849862

Epoch: 5| Step: 2
Training loss: 0.6771579016680702
Validation loss: 3.073747258624012

Epoch: 5| Step: 3
Training loss: 0.5178517895689633
Validation loss: 3.0373200207568676

Epoch: 5| Step: 4
Training loss: 0.6233240784461211
Validation loss: 2.98536277654919

Epoch: 5| Step: 5
Training loss: 0.3884741505451613
Validation loss: 2.9536952556380562

Epoch: 5| Step: 6
Training loss: 0.821757397378435
Validation loss: 3.0337948914769077

Epoch: 5| Step: 7
Training loss: 0.6897182009059899
Validation loss: 3.042467450631529

Epoch: 5| Step: 8
Training loss: 1.4201471079262336
Validation loss: 3.044962943279112

Epoch: 5| Step: 9
Training loss: 0.5351459752788031
Validation loss: 3.048652661797587

Epoch: 5| Step: 10
Training loss: 0.47249006076733313
Validation loss: 3.0691613813108423

Epoch: 5| Step: 11
Training loss: 1.5176550257774182
Validation loss: 3.1011730625419234

Epoch: 293| Step: 0
Training loss: 0.6366168215556074
Validation loss: 3.0874041971022828

Epoch: 5| Step: 1
Training loss: 0.4824457201296317
Validation loss: 2.9890535208578353

Epoch: 5| Step: 2
Training loss: 0.5289428484156203
Validation loss: 3.1581305890864604

Epoch: 5| Step: 3
Training loss: 0.724023093384794
Validation loss: 3.1460015723523016

Epoch: 5| Step: 4
Training loss: 0.4800478634713141
Validation loss: 3.0644263871539748

Epoch: 5| Step: 5
Training loss: 0.4696967736075524
Validation loss: 3.069337801761286

Epoch: 5| Step: 6
Training loss: 0.5142769386568358
Validation loss: 2.992018904887192

Epoch: 5| Step: 7
Training loss: 0.49720498529614077
Validation loss: 3.1693711318499784

Epoch: 5| Step: 8
Training loss: 0.5127619818073782
Validation loss: 3.0163037157288413

Epoch: 5| Step: 9
Training loss: 1.377158811100307
Validation loss: 3.0177782899707566

Epoch: 5| Step: 10
Training loss: 0.5812427376734388
Validation loss: 2.9683370470312562

Epoch: 5| Step: 11
Training loss: 0.27510620201414265
Validation loss: 2.9683958511597957

Epoch: 294| Step: 0
Training loss: 0.5508303789452962
Validation loss: 3.006859751490695

Epoch: 5| Step: 1
Training loss: 0.5051587529449331
Validation loss: 3.0567449614863764

Epoch: 5| Step: 2
Training loss: 0.769516300888863
Validation loss: 2.9072035999051167

Epoch: 5| Step: 3
Training loss: 0.4872110311222031
Validation loss: 3.086233899010269

Epoch: 5| Step: 4
Training loss: 1.404729954096029
Validation loss: 3.047945848396104

Epoch: 5| Step: 5
Training loss: 0.4776717549641111
Validation loss: 2.983693316299053

Epoch: 5| Step: 6
Training loss: 0.814760986982103
Validation loss: 3.0659138796477783

Epoch: 5| Step: 7
Training loss: 0.42542465396124357
Validation loss: 3.004418017409615

Epoch: 5| Step: 8
Training loss: 0.5782411561727523
Validation loss: 3.1247587460534527

Epoch: 5| Step: 9
Training loss: 0.7274329600955751
Validation loss: 3.0828966957088517

Epoch: 5| Step: 10
Training loss: 0.579101999935609
Validation loss: 3.1592270373452016

Epoch: 5| Step: 11
Training loss: 0.621008525255444
Validation loss: 3.051907330321637

Epoch: 295| Step: 0
Training loss: 0.6673430696955995
Validation loss: 3.1339163512153525

Epoch: 5| Step: 1
Training loss: 0.5478595590262831
Validation loss: 3.0831575998711545

Epoch: 5| Step: 2
Training loss: 0.6857029663795061
Validation loss: 3.0684394850250016

Epoch: 5| Step: 3
Training loss: 0.4637114253285384
Validation loss: 3.0589259208024244

Epoch: 5| Step: 4
Training loss: 0.6189867905561562
Validation loss: 3.0901164285397327

Epoch: 5| Step: 5
Training loss: 0.47502290896333965
Validation loss: 3.034624869014216

Epoch: 5| Step: 6
Training loss: 1.3962527209659248
Validation loss: 3.0350429066982594

Epoch: 5| Step: 7
Training loss: 0.7050330446155433
Validation loss: 2.9534181822711223

Epoch: 5| Step: 8
Training loss: 0.5993628476594537
Validation loss: 3.055692040882335

Epoch: 5| Step: 9
Training loss: 0.5548040240758604
Validation loss: 3.0989917892231573

Epoch: 5| Step: 10
Training loss: 0.5928099870804456
Validation loss: 3.0449340506867495

Epoch: 5| Step: 11
Training loss: 0.4636914693392815
Validation loss: 2.9346227216986205

Epoch: 296| Step: 0
Training loss: 0.6370835926445416
Validation loss: 2.9783278008946668

Epoch: 5| Step: 1
Training loss: 0.5149634770525567
Validation loss: 3.0024869729976227

Epoch: 5| Step: 2
Training loss: 0.7108833795425554
Validation loss: 3.0284171090498924

Epoch: 5| Step: 3
Training loss: 0.3526308357637542
Validation loss: 3.0650329722020246

Epoch: 5| Step: 4
Training loss: 0.5448810739863453
Validation loss: 2.9827130701602487

Epoch: 5| Step: 5
Training loss: 1.3546364287326997
Validation loss: 3.074674037000894

Epoch: 5| Step: 6
Training loss: 0.6353992058486346
Validation loss: 2.999952259611047

Epoch: 5| Step: 7
Training loss: 0.47324378957567764
Validation loss: 2.970431684724583

Epoch: 5| Step: 8
Training loss: 0.4941094128548042
Validation loss: 3.0614582417840586

Epoch: 5| Step: 9
Training loss: 0.6158600063337676
Validation loss: 2.964732835225395

Epoch: 5| Step: 10
Training loss: 0.7087492750053129
Validation loss: 3.045014721537824

Epoch: 5| Step: 11
Training loss: 0.6833465347139096
Validation loss: 3.0747752511974484

Epoch: 297| Step: 0
Training loss: 0.7098039666056141
Validation loss: 2.9252709460226756

Epoch: 5| Step: 1
Training loss: 0.432650769310235
Validation loss: 2.959974815196

Epoch: 5| Step: 2
Training loss: 0.4273217357704762
Validation loss: 3.0972613307002432

Epoch: 5| Step: 3
Training loss: 0.8056101278111648
Validation loss: 3.086374556097192

Epoch: 5| Step: 4
Training loss: 1.4723834283407602
Validation loss: 3.152939728686604

Epoch: 5| Step: 5
Training loss: 0.6072465944222148
Validation loss: 3.031296025087357

Epoch: 5| Step: 6
Training loss: 0.6277852463301412
Validation loss: 3.0279957288687167

Epoch: 5| Step: 7
Training loss: 0.7674987208327776
Validation loss: 3.0785080305113186

Epoch: 5| Step: 8
Training loss: 0.5823009813231333
Validation loss: 3.0870463990459585

Epoch: 5| Step: 9
Training loss: 0.5988117840373134
Validation loss: 3.0965084340149898

Epoch: 5| Step: 10
Training loss: 0.48999386849265036
Validation loss: 3.0943366371139067

Epoch: 5| Step: 11
Training loss: 0.27583755588372755
Validation loss: 3.1074964704976864

Epoch: 298| Step: 0
Training loss: 0.4796029019388879
Validation loss: 3.179705520566321

Epoch: 5| Step: 1
Training loss: 1.3285737121140504
Validation loss: 3.1160872389134266

Epoch: 5| Step: 2
Training loss: 0.6189490903508557
Validation loss: 3.1057659846636603

Epoch: 5| Step: 3
Training loss: 0.45002347765713213
Validation loss: 3.1325018927752883

Epoch: 5| Step: 4
Training loss: 0.5567066354260551
Validation loss: 3.0012700319819854

Epoch: 5| Step: 5
Training loss: 0.42119577265385943
Validation loss: 3.0245455305910585

Epoch: 5| Step: 6
Training loss: 0.5510426164942189
Validation loss: 3.073286791779696

Epoch: 5| Step: 7
Training loss: 0.5647247611219821
Validation loss: 3.0419309263964647

Epoch: 5| Step: 8
Training loss: 0.7301304487702006
Validation loss: 3.0337646416592543

Epoch: 5| Step: 9
Training loss: 0.924515385880878
Validation loss: 3.1137605152235883

Epoch: 5| Step: 10
Training loss: 0.5013435313607081
Validation loss: 3.004391932319746

Epoch: 5| Step: 11
Training loss: 0.7088295843798266
Validation loss: 3.141173967933222

Epoch: 299| Step: 0
Training loss: 0.5995602665277716
Validation loss: 3.08624462096316

Epoch: 5| Step: 1
Training loss: 0.4905185104021323
Validation loss: 2.999739956844022

Epoch: 5| Step: 2
Training loss: 0.6268338479162753
Validation loss: 2.992873724857253

Epoch: 5| Step: 3
Training loss: 0.6674883269242993
Validation loss: 3.1132629023848506

Epoch: 5| Step: 4
Training loss: 0.6858734917809207
Validation loss: 3.1300026174895907

Epoch: 5| Step: 5
Training loss: 1.41416568274268
Validation loss: 3.0253071979720154

Epoch: 5| Step: 6
Training loss: 0.4346138921595839
Validation loss: 3.0384223904551626

Epoch: 5| Step: 7
Training loss: 0.6511949028240936
Validation loss: 3.03949803726619

Epoch: 5| Step: 8
Training loss: 0.6419176690350776
Validation loss: 3.0208684009402003

Epoch: 5| Step: 9
Training loss: 0.6405413270596765
Validation loss: 3.1131046425358586

Epoch: 5| Step: 10
Training loss: 0.4473629474950918
Validation loss: 3.0800276780174998

Epoch: 5| Step: 11
Training loss: 0.3587098600613783
Validation loss: 3.0664365600902133

Epoch: 300| Step: 0
Training loss: 0.46996062032609454
Validation loss: 2.9947186016070746

Epoch: 5| Step: 1
Training loss: 1.3658493905154445
Validation loss: 3.12449765936217

Epoch: 5| Step: 2
Training loss: 0.6564534643927462
Validation loss: 3.0078735477477982

Epoch: 5| Step: 3
Training loss: 0.6393407882606167
Validation loss: 2.9844470523038718

Epoch: 5| Step: 4
Training loss: 0.46967491452835675
Validation loss: 3.120574080356569

Epoch: 5| Step: 5
Training loss: 0.6594567966799593
Validation loss: 2.956516750228891

Epoch: 5| Step: 6
Training loss: 0.3147231891096668
Validation loss: 2.947779623065508

Epoch: 5| Step: 7
Training loss: 0.7839858408155361
Validation loss: 3.103131970938452

Epoch: 5| Step: 8
Training loss: 0.4417464709008723
Validation loss: 3.137835733275572

Epoch: 5| Step: 9
Training loss: 0.5716004655929549
Validation loss: 3.0032111869720937

Epoch: 5| Step: 10
Training loss: 0.44216389744719786
Validation loss: 3.0439823080259703

Epoch: 5| Step: 11
Training loss: 0.41929057372951944
Validation loss: 2.9971153046251393

Epoch: 301| Step: 0
Training loss: 0.5881854360501874
Validation loss: 3.0914454048510747

Epoch: 5| Step: 1
Training loss: 0.554837649802532
Validation loss: 2.9636660294453967

Epoch: 5| Step: 2
Training loss: 0.5313403108913236
Validation loss: 3.1217312406445354

Epoch: 5| Step: 3
Training loss: 0.576335043351766
Validation loss: 3.067255541551518

Epoch: 5| Step: 4
Training loss: 0.5630365567712848
Validation loss: 2.982115710885196

Epoch: 5| Step: 5
Training loss: 0.40246250659155797
Validation loss: 3.085053248814052

Epoch: 5| Step: 6
Training loss: 1.448063310108504
Validation loss: 3.1363202321285066

Epoch: 5| Step: 7
Training loss: 0.5887028605628623
Validation loss: 3.0412612159261916

Epoch: 5| Step: 8
Training loss: 0.48717208005960233
Validation loss: 3.0436611440640706

Epoch: 5| Step: 9
Training loss: 0.7629023819118552
Validation loss: 3.0149953708644777

Epoch: 5| Step: 10
Training loss: 0.6486997418790785
Validation loss: 3.0748899891152504

Epoch: 5| Step: 11
Training loss: 0.22502333599509847
Validation loss: 3.0196271932936396

Epoch: 302| Step: 0
Training loss: 0.39097245975612893
Validation loss: 3.0402381081043353

Epoch: 5| Step: 1
Training loss: 0.4275578696417431
Validation loss: 3.0637917778510833

Epoch: 5| Step: 2
Training loss: 0.5101448490101494
Validation loss: 2.9283025765762343

Epoch: 5| Step: 3
Training loss: 0.3989223073857124
Validation loss: 2.974981924611165

Epoch: 5| Step: 4
Training loss: 0.5664545762065029
Validation loss: 3.028960762914158

Epoch: 5| Step: 5
Training loss: 0.6852920362876231
Validation loss: 2.9602933600721184

Epoch: 5| Step: 6
Training loss: 0.4860775466714893
Validation loss: 2.9869597960123655

Epoch: 5| Step: 7
Training loss: 0.4373699062930615
Validation loss: 3.0670719533704935

Epoch: 5| Step: 8
Training loss: 1.4517545082386216
Validation loss: 3.033432590953145

Epoch: 5| Step: 9
Training loss: 0.47297969501737325
Validation loss: 2.969255043036423

Epoch: 5| Step: 10
Training loss: 0.5524832758378904
Validation loss: 2.987974768652514

Epoch: 5| Step: 11
Training loss: 0.6091257710521444
Validation loss: 2.9991611493399

Epoch: 303| Step: 0
Training loss: 0.4935181809915185
Validation loss: 3.0406627054153827

Epoch: 5| Step: 1
Training loss: 0.5354095193803952
Validation loss: 3.0689855786843716

Epoch: 5| Step: 2
Training loss: 0.5455355179986786
Validation loss: 2.9999504350170523

Epoch: 5| Step: 3
Training loss: 0.678669375237935
Validation loss: 3.102040161966483

Epoch: 5| Step: 4
Training loss: 0.4970868151010667
Validation loss: 3.0807091375598987

Epoch: 5| Step: 5
Training loss: 0.5854200494290651
Validation loss: 2.959816927811562

Epoch: 5| Step: 6
Training loss: 1.4088333560819197
Validation loss: 3.1295789074162843

Epoch: 5| Step: 7
Training loss: 0.6814422318707909
Validation loss: 3.1331957061873785

Epoch: 5| Step: 8
Training loss: 0.639846328525215
Validation loss: 3.085143042560513

Epoch: 5| Step: 9
Training loss: 0.6093033234917414
Validation loss: 3.1097887041921957

Epoch: 5| Step: 10
Training loss: 0.6575142172810153
Validation loss: 2.9971893508985494

Epoch: 5| Step: 11
Training loss: 0.529170087993505
Validation loss: 3.040936677463713

Epoch: 304| Step: 0
Training loss: 0.5196964890281254
Validation loss: 3.040857433858846

Epoch: 5| Step: 1
Training loss: 0.4759233284516679
Validation loss: 3.0384822870171044

Epoch: 5| Step: 2
Training loss: 0.5633592665316042
Validation loss: 3.073574404179604

Epoch: 5| Step: 3
Training loss: 0.6070887642693634
Validation loss: 2.933562703990598

Epoch: 5| Step: 4
Training loss: 0.6601475822285996
Validation loss: 3.074384307604248

Epoch: 5| Step: 5
Training loss: 1.3846312378318146
Validation loss: 3.0082168637569473

Epoch: 5| Step: 6
Training loss: 0.4930571336303076
Validation loss: 2.992189907009926

Epoch: 5| Step: 7
Training loss: 0.6921360022545517
Validation loss: 3.07368496918477

Epoch: 5| Step: 8
Training loss: 0.6196939300495912
Validation loss: 3.006761230122142

Epoch: 5| Step: 9
Training loss: 0.8008470833861919
Validation loss: 3.0100454884795704

Epoch: 5| Step: 10
Training loss: 0.550005942009126
Validation loss: 3.0343294265315714

Epoch: 5| Step: 11
Training loss: 0.39876307480999845
Validation loss: 2.9756542732547167

Epoch: 305| Step: 0
Training loss: 0.5614988371394575
Validation loss: 3.017737062418643

Epoch: 5| Step: 1
Training loss: 0.9297045858399943
Validation loss: 2.9588656293587334

Epoch: 5| Step: 2
Training loss: 0.6324479972434891
Validation loss: 2.966106834300371

Epoch: 5| Step: 3
Training loss: 0.6521564146126935
Validation loss: 3.0132599946995677

Epoch: 5| Step: 4
Training loss: 1.3993017413789666
Validation loss: 2.9224660924908394

Epoch: 5| Step: 5
Training loss: 0.5648195338037596
Validation loss: 3.043135720447798

Epoch: 5| Step: 6
Training loss: 0.6565738741630718
Validation loss: 3.0152265651150536

Epoch: 5| Step: 7
Training loss: 0.5410152669416544
Validation loss: 2.9947370253291234

Epoch: 5| Step: 8
Training loss: 0.45287964196054364
Validation loss: 2.9579685259368196

Epoch: 5| Step: 9
Training loss: 0.5937555212466873
Validation loss: 3.0185160178310886

Epoch: 5| Step: 10
Training loss: 0.5175668967126708
Validation loss: 2.9795042037929944

Epoch: 5| Step: 11
Training loss: 0.2602118624566732
Validation loss: 2.853165901227952

Epoch: 306| Step: 0
Training loss: 1.529803780333688
Validation loss: 2.9147018740263326

Epoch: 5| Step: 1
Training loss: 0.5600911856815393
Validation loss: 2.9017408317196938

Epoch: 5| Step: 2
Training loss: 0.37166763903543404
Validation loss: 2.9775349254252035

Epoch: 5| Step: 3
Training loss: 0.43346085101142695
Validation loss: 3.025268516103896

Epoch: 5| Step: 4
Training loss: 0.48369333539085535
Validation loss: 2.870749171333223

Epoch: 5| Step: 5
Training loss: 0.5454979862539603
Validation loss: 2.9550687357368237

Epoch: 5| Step: 6
Training loss: 0.3540446922221155
Validation loss: 2.986913387080912

Epoch: 5| Step: 7
Training loss: 0.5028831682634636
Validation loss: 3.0114546716527717

Epoch: 5| Step: 8
Training loss: 0.39721503371660394
Validation loss: 3.015665768889668

Epoch: 5| Step: 9
Training loss: 0.7096101295562096
Validation loss: 3.0292460021045886

Epoch: 5| Step: 10
Training loss: 0.5033826251346435
Validation loss: 2.9781172389022394

Epoch: 5| Step: 11
Training loss: 0.4002233388385544
Validation loss: 2.9640265181573984

Epoch: 307| Step: 0
Training loss: 0.5636058374795011
Validation loss: 2.957378768489178

Epoch: 5| Step: 1
Training loss: 0.5280085576368186
Validation loss: 2.921695730928335

Epoch: 5| Step: 2
Training loss: 0.41356101347143176
Validation loss: 3.0187848062134335

Epoch: 5| Step: 3
Training loss: 0.44058201221686233
Validation loss: 2.911465279167684

Epoch: 5| Step: 4
Training loss: 0.6513266944023053
Validation loss: 3.039811091989844

Epoch: 5| Step: 5
Training loss: 0.5724750695360014
Validation loss: 3.047973643405062

Epoch: 5| Step: 6
Training loss: 0.47992182050254745
Validation loss: 2.9448282837095157

Epoch: 5| Step: 7
Training loss: 0.5828392769233497
Validation loss: 3.000586611298173

Epoch: 5| Step: 8
Training loss: 1.386366592608738
Validation loss: 2.9825635042435135

Epoch: 5| Step: 9
Training loss: 0.4098381625575215
Validation loss: 3.0294178639920952

Epoch: 5| Step: 10
Training loss: 0.41978862333811645
Validation loss: 3.0044406437022935

Epoch: 5| Step: 11
Training loss: 0.2744360945467318
Validation loss: 3.0563286667823286

Epoch: 308| Step: 0
Training loss: 0.6369403851218878
Validation loss: 2.9956687383750333

Epoch: 5| Step: 1
Training loss: 0.4650621942745476
Validation loss: 3.0808310772680585

Epoch: 5| Step: 2
Training loss: 1.3472992797435126
Validation loss: 3.0034609705592343

Epoch: 5| Step: 3
Training loss: 0.5825206312119618
Validation loss: 3.033934472894431

Epoch: 5| Step: 4
Training loss: 0.5386293578433053
Validation loss: 2.990935692082985

Epoch: 5| Step: 5
Training loss: 0.5247203138676981
Validation loss: 3.0268274765332572

Epoch: 5| Step: 6
Training loss: 0.5891530875413142
Validation loss: 3.069694485963695

Epoch: 5| Step: 7
Training loss: 0.650943418083081
Validation loss: 3.0910274972522536

Epoch: 5| Step: 8
Training loss: 0.40590645863031843
Validation loss: 3.0703065983761664

Epoch: 5| Step: 9
Training loss: 0.31166860134030866
Validation loss: 2.965813626828329

Epoch: 5| Step: 10
Training loss: 0.5852702601436365
Validation loss: 3.089549816247316

Epoch: 5| Step: 11
Training loss: 0.8379662753012963
Validation loss: 2.9825453250752596

Epoch: 309| Step: 0
Training loss: 0.4548008118847417
Validation loss: 2.994601647803265

Epoch: 5| Step: 1
Training loss: 0.6716210084814656
Validation loss: 3.028160270587863

Epoch: 5| Step: 2
Training loss: 0.46988510343116996
Validation loss: 3.0066846871646598

Epoch: 5| Step: 3
Training loss: 0.6240790496068245
Validation loss: 2.969264537994415

Epoch: 5| Step: 4
Training loss: 0.40496628853519145
Validation loss: 2.863621218397247

Epoch: 5| Step: 5
Training loss: 1.5572115857341773
Validation loss: 2.9388158299579956

Epoch: 5| Step: 6
Training loss: 0.6844000502578543
Validation loss: 3.0374983592611104

Epoch: 5| Step: 7
Training loss: 0.43697008328854015
Validation loss: 3.027883183810498

Epoch: 5| Step: 8
Training loss: 0.7541332397289007
Validation loss: 2.9605624381588838

Epoch: 5| Step: 9
Training loss: 0.6824974861028855
Validation loss: 3.0109416488515937

Epoch: 5| Step: 10
Training loss: 0.5577928096170338
Validation loss: 3.0660883129217917

Epoch: 5| Step: 11
Training loss: 0.7936967411345878
Validation loss: 3.0900693088513393

Epoch: 310| Step: 0
Training loss: 0.6483300131448819
Validation loss: 3.0726980303987053

Epoch: 5| Step: 1
Training loss: 0.452128399596486
Validation loss: 3.071119407896623

Epoch: 5| Step: 2
Training loss: 0.3834100458192145
Validation loss: 2.9741415823593615

Epoch: 5| Step: 3
Training loss: 0.7062133146564932
Validation loss: 2.884020096700031

Epoch: 5| Step: 4
Training loss: 0.5261842200877853
Validation loss: 3.093973803533006

Epoch: 5| Step: 5
Training loss: 1.3874610740768738
Validation loss: 3.054503702811597

Epoch: 5| Step: 6
Training loss: 0.5168107588121998
Validation loss: 3.09970010593806

Epoch: 5| Step: 7
Training loss: 0.44323520349977896
Validation loss: 3.043829368950778

Epoch: 5| Step: 8
Training loss: 0.6161429825687537
Validation loss: 2.9743640553870976

Epoch: 5| Step: 9
Training loss: 0.45661085307472693
Validation loss: 3.2006266581352203

Epoch: 5| Step: 10
Training loss: 0.4183538392000785
Validation loss: 3.1057498796637963

Epoch: 5| Step: 11
Training loss: 0.7103148028449252
Validation loss: 3.098261975606737

Epoch: 311| Step: 0
Training loss: 0.45497678684399595
Validation loss: 3.069582437392839

Epoch: 5| Step: 1
Training loss: 0.564508798354978
Validation loss: 2.945865417307549

Epoch: 5| Step: 2
Training loss: 0.5541934109690178
Validation loss: 3.0491317672761777

Epoch: 5| Step: 3
Training loss: 0.6289303697972083
Validation loss: 3.0535008043340492

Epoch: 5| Step: 4
Training loss: 0.5531619948607176
Validation loss: 3.0436718005736325

Epoch: 5| Step: 5
Training loss: 0.453584503804947
Validation loss: 3.006943733287685

Epoch: 5| Step: 6
Training loss: 1.6133368900485807
Validation loss: 2.9883961441458533

Epoch: 5| Step: 7
Training loss: 0.5458596203810153
Validation loss: 2.945532857137802

Epoch: 5| Step: 8
Training loss: 0.6272825522400959
Validation loss: 3.032381814861341

Epoch: 5| Step: 9
Training loss: 0.5174061327495973
Validation loss: 3.0285578206799606

Epoch: 5| Step: 10
Training loss: 0.5613826940209277
Validation loss: 3.0537819849526087

Epoch: 5| Step: 11
Training loss: 0.4387275979716105
Validation loss: 3.1299394670854777

Epoch: 312| Step: 0
Training loss: 0.4684450588163602
Validation loss: 3.023265883037863

Epoch: 5| Step: 1
Training loss: 0.34883316010774473
Validation loss: 3.0896181682510058

Epoch: 5| Step: 2
Training loss: 0.4563774910563406
Validation loss: 3.066057506904933

Epoch: 5| Step: 3
Training loss: 0.5936123035781697
Validation loss: 3.049784003619305

Epoch: 5| Step: 4
Training loss: 1.4430218664615522
Validation loss: 3.0963864764599074

Epoch: 5| Step: 5
Training loss: 0.5750912117139497
Validation loss: 3.0891243233328622

Epoch: 5| Step: 6
Training loss: 0.5656303616264357
Validation loss: 3.0410946456191033

Epoch: 5| Step: 7
Training loss: 0.4872714931519397
Validation loss: 3.0684070903160743

Epoch: 5| Step: 8
Training loss: 0.40208951083891376
Validation loss: 3.061940690302961

Epoch: 5| Step: 9
Training loss: 0.5814163236660315
Validation loss: 3.045243336606714

Epoch: 5| Step: 10
Training loss: 0.5228798016120904
Validation loss: 3.016310042479135

Epoch: 5| Step: 11
Training loss: 0.6239073500610406
Validation loss: 2.914801434874597

Epoch: 313| Step: 0
Training loss: 0.5020516740412213
Validation loss: 3.0739327297266885

Epoch: 5| Step: 1
Training loss: 0.5224040918530982
Validation loss: 3.062700667262168

Epoch: 5| Step: 2
Training loss: 0.3835728742586704
Validation loss: 2.97281357912378

Epoch: 5| Step: 3
Training loss: 0.47102626614517623
Validation loss: 3.0760304413429282

Epoch: 5| Step: 4
Training loss: 1.3130957749903414
Validation loss: 3.0310306469706076

Epoch: 5| Step: 5
Training loss: 0.7221552581390723
Validation loss: 3.0022255371231767

Epoch: 5| Step: 6
Training loss: 0.4551467188928399
Validation loss: 3.0278872225654263

Epoch: 5| Step: 7
Training loss: 0.5006239395511364
Validation loss: 3.051983477984588

Epoch: 5| Step: 8
Training loss: 0.5666371631187845
Validation loss: 3.0731241457880225

Epoch: 5| Step: 9
Training loss: 0.31494821940304946
Validation loss: 2.999555799924254

Epoch: 5| Step: 10
Training loss: 0.3668028257169633
Validation loss: 2.969431163208794

Epoch: 5| Step: 11
Training loss: 0.48188447557031466
Validation loss: 2.99792912652716

Epoch: 314| Step: 0
Training loss: 0.3725112344980625
Validation loss: 2.986878365387517

Epoch: 5| Step: 1
Training loss: 0.5634170315664248
Validation loss: 2.9972048625987378

Epoch: 5| Step: 2
Training loss: 0.35651367786031396
Validation loss: 2.9935915070790213

Epoch: 5| Step: 3
Training loss: 1.5445810899425783
Validation loss: 3.0168977334553135

Epoch: 5| Step: 4
Training loss: 0.5257042725032234
Validation loss: 3.0302754634809834

Epoch: 5| Step: 5
Training loss: 0.4396314810046561
Validation loss: 3.088764322027175

Epoch: 5| Step: 6
Training loss: 0.45160187216316605
Validation loss: 2.9671524835910494

Epoch: 5| Step: 7
Training loss: 0.5569024256707696
Validation loss: 3.0473415734813156

Epoch: 5| Step: 8
Training loss: 0.5700794423106279
Validation loss: 3.0261395132733218

Epoch: 5| Step: 9
Training loss: 0.5620044803898963
Validation loss: 2.987865264461781

Epoch: 5| Step: 10
Training loss: 0.5429308761450831
Validation loss: 3.0581269246972465

Epoch: 5| Step: 11
Training loss: 0.6747999839784409
Validation loss: 2.952377567869801

Epoch: 315| Step: 0
Training loss: 1.4014091246174891
Validation loss: 3.0026991080068273

Epoch: 5| Step: 1
Training loss: 0.6237037090332513
Validation loss: 3.0467789137597685

Epoch: 5| Step: 2
Training loss: 0.5281492509860624
Validation loss: 3.073235279742586

Epoch: 5| Step: 3
Training loss: 0.711188094021098
Validation loss: 2.973865000946585

Epoch: 5| Step: 4
Training loss: 0.36510748877580707
Validation loss: 2.914116256395308

Epoch: 5| Step: 5
Training loss: 0.37006919368494323
Validation loss: 2.9119342160267907

Epoch: 5| Step: 6
Training loss: 0.48643351565761717
Validation loss: 3.0216986019875747

Epoch: 5| Step: 7
Training loss: 0.7636782750790799
Validation loss: 2.985688997098785

Epoch: 5| Step: 8
Training loss: 0.5190409878309888
Validation loss: 2.9724167114472846

Epoch: 5| Step: 9
Training loss: 0.47780913534532843
Validation loss: 3.0051648331286542

Epoch: 5| Step: 10
Training loss: 0.3336216591052805
Validation loss: 3.0439866354549103

Epoch: 5| Step: 11
Training loss: 0.6351135239535652
Validation loss: 2.9683216120513296

Epoch: 316| Step: 0
Training loss: 0.6265774132911055
Validation loss: 3.004440137811597

Epoch: 5| Step: 1
Training loss: 0.6980265250972773
Validation loss: 3.030036935890647

Epoch: 5| Step: 2
Training loss: 0.6879002099828875
Validation loss: 3.0578147639969737

Epoch: 5| Step: 3
Training loss: 0.8788155402951682
Validation loss: 2.989665882065267

Epoch: 5| Step: 4
Training loss: 0.513849699041047
Validation loss: 3.0038377268713794

Epoch: 5| Step: 5
Training loss: 0.5121791311980298
Validation loss: 2.925247768493728

Epoch: 5| Step: 6
Training loss: 0.6729474490735737
Validation loss: 2.989805709507822

Epoch: 5| Step: 7
Training loss: 1.4606362098456298
Validation loss: 2.9692884994130297

Epoch: 5| Step: 8
Training loss: 0.656384340795519
Validation loss: 2.970326878223405

Epoch: 5| Step: 9
Training loss: 0.7578462809476022
Validation loss: 2.9608377525417575

Epoch: 5| Step: 10
Training loss: 0.4105763236970741
Validation loss: 2.889464432338105

Epoch: 5| Step: 11
Training loss: 0.4965568393555077
Validation loss: 2.9949170802296807

Epoch: 317| Step: 0
Training loss: 1.4164183155856755
Validation loss: 2.9653647412768263

Epoch: 5| Step: 1
Training loss: 0.5369193555918614
Validation loss: 2.9417194944362435

Epoch: 5| Step: 2
Training loss: 0.6209426312169787
Validation loss: 2.9662846417500055

Epoch: 5| Step: 3
Training loss: 0.7468667544624031
Validation loss: 2.9319923286487253

Epoch: 5| Step: 4
Training loss: 0.5951098129571722
Validation loss: 2.8935983160812926

Epoch: 5| Step: 5
Training loss: 0.38630775806829
Validation loss: 2.975719549477989

Epoch: 5| Step: 6
Training loss: 0.5287659012317598
Validation loss: 2.8916566330976594

Epoch: 5| Step: 7
Training loss: 0.39224202206426345
Validation loss: 2.9728842542165017

Epoch: 5| Step: 8
Training loss: 0.7131924343070485
Validation loss: 2.9539995462756883

Epoch: 5| Step: 9
Training loss: 0.47667517658898
Validation loss: 2.9251354474172815

Epoch: 5| Step: 10
Training loss: 0.5788067844208766
Validation loss: 2.9602086219373116

Epoch: 5| Step: 11
Training loss: 0.7187052588427939
Validation loss: 3.0091228388705122

Epoch: 318| Step: 0
Training loss: 0.49007974138788435
Validation loss: 2.990322145801345

Epoch: 5| Step: 1
Training loss: 0.7039203807500553
Validation loss: 2.9990869695686686

Epoch: 5| Step: 2
Training loss: 0.6488609310264412
Validation loss: 3.0004506766040095

Epoch: 5| Step: 3
Training loss: 0.6211540144947149
Validation loss: 2.8596822542299387

Epoch: 5| Step: 4
Training loss: 0.513343473985551
Validation loss: 2.9999919334938956

Epoch: 5| Step: 5
Training loss: 0.4749677584397026
Validation loss: 3.073269530688748

Epoch: 5| Step: 6
Training loss: 0.6399418281776158
Validation loss: 2.969866656388355

Epoch: 5| Step: 7
Training loss: 1.3339788791437164
Validation loss: 3.059594800493737

Epoch: 5| Step: 8
Training loss: 0.500663734013891
Validation loss: 2.9563251157845625

Epoch: 5| Step: 9
Training loss: 0.6334411183250602
Validation loss: 2.987023794189467

Epoch: 5| Step: 10
Training loss: 0.5517949184667669
Validation loss: 2.9519303780026314

Epoch: 5| Step: 11
Training loss: 0.5086330240441232
Validation loss: 2.9113584557031618

Epoch: 319| Step: 0
Training loss: 0.5798490438011491
Validation loss: 3.021043603528754

Epoch: 5| Step: 1
Training loss: 1.4090626880191315
Validation loss: 2.979370518136793

Epoch: 5| Step: 2
Training loss: 0.6595513320464627
Validation loss: 3.0514784182000407

Epoch: 5| Step: 3
Training loss: 0.6191499149816887
Validation loss: 3.0121998351150228

Epoch: 5| Step: 4
Training loss: 0.5206735143233594
Validation loss: 2.9296682128271376

Epoch: 5| Step: 5
Training loss: 0.5529197678506559
Validation loss: 3.040095639909885

Epoch: 5| Step: 6
Training loss: 0.8730634649351824
Validation loss: 2.9872297444066667

Epoch: 5| Step: 7
Training loss: 0.561044983408412
Validation loss: 3.019796664937938

Epoch: 5| Step: 8
Training loss: 0.6873984261818551
Validation loss: 2.925944892031685

Epoch: 5| Step: 9
Training loss: 0.3814209929808398
Validation loss: 2.903571651634463

Epoch: 5| Step: 10
Training loss: 0.578472316648311
Validation loss: 2.9407061469367406

Epoch: 5| Step: 11
Training loss: 0.543611598762099
Validation loss: 3.082640832167689

Epoch: 320| Step: 0
Training loss: 0.7431872410612174
Validation loss: 3.0723199728402477

Epoch: 5| Step: 1
Training loss: 1.407370650613625
Validation loss: 3.051637829672629

Epoch: 5| Step: 2
Training loss: 0.4162564185223294
Validation loss: 2.9721464638151116

Epoch: 5| Step: 3
Training loss: 0.473011907644373
Validation loss: 3.0455597573733075

Epoch: 5| Step: 4
Training loss: 0.3762403479317093
Validation loss: 2.990735663768482

Epoch: 5| Step: 5
Training loss: 0.8002811638157521
Validation loss: 3.029319866395691

Epoch: 5| Step: 6
Training loss: 0.3926924543770972
Validation loss: 3.03827496860908

Epoch: 5| Step: 7
Training loss: 0.541678535502565
Validation loss: 3.0955684660656555

Epoch: 5| Step: 8
Training loss: 0.5161178141153979
Validation loss: 3.053818984926522

Epoch: 5| Step: 9
Training loss: 0.7428020543000713
Validation loss: 3.068877236550707

Epoch: 5| Step: 10
Training loss: 0.31178573997608566
Validation loss: 2.9644796410068106

Epoch: 5| Step: 11
Training loss: 0.5168317199170516
Validation loss: 3.0735132037097865

Epoch: 321| Step: 0
Training loss: 0.5730464672667048
Validation loss: 3.001335509052728

Epoch: 5| Step: 1
Training loss: 0.5704178386236858
Validation loss: 2.989341428098841

Epoch: 5| Step: 2
Training loss: 0.7070866557799828
Validation loss: 3.04110781987814

Epoch: 5| Step: 3
Training loss: 0.4256712745236873
Validation loss: 3.0114887906758465

Epoch: 5| Step: 4
Training loss: 0.5010700993655736
Validation loss: 3.05270436167022

Epoch: 5| Step: 5
Training loss: 0.4653476900586255
Validation loss: 3.0653817605603093

Epoch: 5| Step: 6
Training loss: 0.840507387066387
Validation loss: 3.0386354331028973

Epoch: 5| Step: 7
Training loss: 0.6569519602937294
Validation loss: 3.1188020850898823

Epoch: 5| Step: 8
Training loss: 0.591184242333929
Validation loss: 3.021836102329659

Epoch: 5| Step: 9
Training loss: 0.4942775431084778
Validation loss: 2.9146351358165172

Epoch: 5| Step: 10
Training loss: 1.2905993923205332
Validation loss: 3.048517068345569

Epoch: 5| Step: 11
Training loss: 0.4927390353803641
Validation loss: 3.0291436306437385

Epoch: 322| Step: 0
Training loss: 0.4646115083518793
Validation loss: 3.060284445684782

Epoch: 5| Step: 1
Training loss: 1.3126065347213864
Validation loss: 3.0293396898167146

Epoch: 5| Step: 2
Training loss: 0.5329930936319386
Validation loss: 3.011852639104676

Epoch: 5| Step: 3
Training loss: 0.6406865206695982
Validation loss: 3.085874210787086

Epoch: 5| Step: 4
Training loss: 0.6910514567795989
Validation loss: 3.084097874851776

Epoch: 5| Step: 5
Training loss: 0.43765293581769005
Validation loss: 3.107798484999514

Epoch: 5| Step: 6
Training loss: 0.5836787620222877
Validation loss: 3.046162396427367

Epoch: 5| Step: 7
Training loss: 0.607749605234411
Validation loss: 3.1012717910702152

Epoch: 5| Step: 8
Training loss: 0.8254599242900207
Validation loss: 3.0005781358384334

Epoch: 5| Step: 9
Training loss: 0.6192123900978974
Validation loss: 2.999814133714401

Epoch: 5| Step: 10
Training loss: 0.4708412094498335
Validation loss: 3.0002457133969433

Epoch: 5| Step: 11
Training loss: 0.32783134126292307
Validation loss: 3.0325012115409007

Epoch: 323| Step: 0
Training loss: 0.6666602765214159
Validation loss: 3.0318704868005995

Epoch: 5| Step: 1
Training loss: 1.4565208707048127
Validation loss: 3.090151874725402

Epoch: 5| Step: 2
Training loss: 0.5924939623255474
Validation loss: 2.9777402375078594

Epoch: 5| Step: 3
Training loss: 0.42820522225013724
Validation loss: 3.012554506280999

Epoch: 5| Step: 4
Training loss: 0.32135086856470624
Validation loss: 3.104504724737041

Epoch: 5| Step: 5
Training loss: 0.5531366185406634
Validation loss: 3.071809715852726

Epoch: 5| Step: 6
Training loss: 0.5205634625943861
Validation loss: 3.035481501384106

Epoch: 5| Step: 7
Training loss: 0.5685217975943445
Validation loss: 3.069603143207547

Epoch: 5| Step: 8
Training loss: 0.5015723123511586
Validation loss: 3.0314127363849273

Epoch: 5| Step: 9
Training loss: 0.43095433147664436
Validation loss: 3.0646688832302043

Epoch: 5| Step: 10
Training loss: 0.6607110440421391
Validation loss: 2.998532012223856

Epoch: 5| Step: 11
Training loss: 0.7088526243426164
Validation loss: 3.13025172812309

Epoch: 324| Step: 0
Training loss: 0.5435458622228667
Validation loss: 3.0477811199580476

Epoch: 5| Step: 1
Training loss: 0.4221472568094815
Validation loss: 3.0245819784226997

Epoch: 5| Step: 2
Training loss: 0.39015747702592385
Validation loss: 3.034351482752017

Epoch: 5| Step: 3
Training loss: 1.343602460701436
Validation loss: 3.0038541434621457

Epoch: 5| Step: 4
Training loss: 0.5435739890045966
Validation loss: 2.990056609640634

Epoch: 5| Step: 5
Training loss: 0.9354870484402109
Validation loss: 3.038219756732432

Epoch: 5| Step: 6
Training loss: 0.40977783912223
Validation loss: 3.0338058937172514

Epoch: 5| Step: 7
Training loss: 0.5328950935403474
Validation loss: 3.0503233966151417

Epoch: 5| Step: 8
Training loss: 0.4945333375329286
Validation loss: 2.8890271693741614

Epoch: 5| Step: 9
Training loss: 0.6506369184562178
Validation loss: 2.978463784689107

Epoch: 5| Step: 10
Training loss: 0.34418671133762524
Validation loss: 2.990659531115272

Epoch: 5| Step: 11
Training loss: 0.5135813005898104
Validation loss: 2.9581465589413516

Epoch: 325| Step: 0
Training loss: 0.46704983740300315
Validation loss: 2.982384448929349

Epoch: 5| Step: 1
Training loss: 0.5087049125449931
Validation loss: 2.9991919634650395

Epoch: 5| Step: 2
Training loss: 0.3977978939362649
Validation loss: 3.089110778215221

Epoch: 5| Step: 3
Training loss: 1.3259909145394941
Validation loss: 2.9780033058688717

Epoch: 5| Step: 4
Training loss: 0.5846228028248592
Validation loss: 2.99527740298759

Epoch: 5| Step: 5
Training loss: 0.6572534745531898
Validation loss: 3.0440147994914395

Epoch: 5| Step: 6
Training loss: 0.45216376194206637
Validation loss: 3.004308044521288

Epoch: 5| Step: 7
Training loss: 0.6278621702544712
Validation loss: 3.035798119908739

Epoch: 5| Step: 8
Training loss: 0.4631051801643858
Validation loss: 2.987999653897697

Epoch: 5| Step: 9
Training loss: 0.4944092242937057
Validation loss: 3.1066708427426373

Epoch: 5| Step: 10
Training loss: 0.43694114754580826
Validation loss: 3.073897594203864

Epoch: 5| Step: 11
Training loss: 0.7922461087368143
Validation loss: 2.980739156273133

Epoch: 326| Step: 0
Training loss: 0.3982925712440026
Validation loss: 3.082018192652

Epoch: 5| Step: 1
Training loss: 0.496630565930892
Validation loss: 2.972043927188731

Epoch: 5| Step: 2
Training loss: 0.6383296971512192
Validation loss: 2.985204474864877

Epoch: 5| Step: 3
Training loss: 0.5361501555425775
Validation loss: 2.981937644767935

Epoch: 5| Step: 4
Training loss: 0.5363053841433887
Validation loss: 2.995750603221056

Epoch: 5| Step: 5
Training loss: 1.45975393403404
Validation loss: 2.973104218437139

Epoch: 5| Step: 6
Training loss: 0.5012616393053105
Validation loss: 3.059103438131737

Epoch: 5| Step: 7
Training loss: 0.6282433754131099
Validation loss: 3.064104380070938

Epoch: 5| Step: 8
Training loss: 0.8064383560290831
Validation loss: 2.99277119798997

Epoch: 5| Step: 9
Training loss: 0.7083741812054204
Validation loss: 3.0890949304808193

Epoch: 5| Step: 10
Training loss: 0.4366223694661751
Validation loss: 3.089213464933176

Epoch: 5| Step: 11
Training loss: 0.123079030815589
Validation loss: 3.0651539960822682

Epoch: 327| Step: 0
Training loss: 0.5533900601061312
Validation loss: 3.0168957610542444

Epoch: 5| Step: 1
Training loss: 0.7177227806848132
Validation loss: 3.1059338651186073

Epoch: 5| Step: 2
Training loss: 0.37154240841841585
Validation loss: 3.048624038789567

Epoch: 5| Step: 3
Training loss: 0.721567891176354
Validation loss: 3.055458316315358

Epoch: 5| Step: 4
Training loss: 1.2752475161682482
Validation loss: 2.9991008152736325

Epoch: 5| Step: 5
Training loss: 0.47334080769397635
Validation loss: 3.0587935433187377

Epoch: 5| Step: 6
Training loss: 0.45454819567352356
Validation loss: 3.03049348783546

Epoch: 5| Step: 7
Training loss: 0.6559950469545298
Validation loss: 3.0335591228695358

Epoch: 5| Step: 8
Training loss: 0.4364898805286433
Validation loss: 3.0497742577169777

Epoch: 5| Step: 9
Training loss: 0.7488910105392532
Validation loss: 2.9874989900627185

Epoch: 5| Step: 10
Training loss: 0.5065492322573851
Validation loss: 3.0638341365660913

Epoch: 5| Step: 11
Training loss: 0.17994799597849295
Validation loss: 2.979691493660635

Epoch: 328| Step: 0
Training loss: 0.6886431769732996
Validation loss: 3.054584524202737

Epoch: 5| Step: 1
Training loss: 1.3414988179779248
Validation loss: 3.0948955617743645

Epoch: 5| Step: 2
Training loss: 0.577475260002335
Validation loss: 3.0420114254330404

Epoch: 5| Step: 3
Training loss: 0.6355065115483253
Validation loss: 2.997341557642985

Epoch: 5| Step: 4
Training loss: 0.4548229599096271
Validation loss: 3.0767438697858225

Epoch: 5| Step: 5
Training loss: 0.6618048043350736
Validation loss: 3.0166826188910902

Epoch: 5| Step: 6
Training loss: 0.5405691073857699
Validation loss: 3.043655344165545

Epoch: 5| Step: 7
Training loss: 0.35767915981473686
Validation loss: 2.9898555224096914

Epoch: 5| Step: 8
Training loss: 0.6402357826426907
Validation loss: 3.017543883885548

Epoch: 5| Step: 9
Training loss: 0.5477795885104277
Validation loss: 2.9854988924474943

Epoch: 5| Step: 10
Training loss: 0.48713390591423605
Validation loss: 3.048599169400481

Epoch: 5| Step: 11
Training loss: 0.5616868021956342
Validation loss: 2.963865484816404

Epoch: 329| Step: 0
Training loss: 0.42885366510055056
Validation loss: 2.967659786885523

Epoch: 5| Step: 1
Training loss: 0.40533761125362416
Validation loss: 3.012481876440127

Epoch: 5| Step: 2
Training loss: 0.4943987809066649
Validation loss: 3.0814495077534

Epoch: 5| Step: 3
Training loss: 0.521643225089348
Validation loss: 3.068095742435381

Epoch: 5| Step: 4
Training loss: 1.3321500037274445
Validation loss: 2.989670510743363

Epoch: 5| Step: 5
Training loss: 0.678188622474181
Validation loss: 3.067613708167951

Epoch: 5| Step: 6
Training loss: 0.5106921782362763
Validation loss: 3.048839470506013

Epoch: 5| Step: 7
Training loss: 0.5064268133077978
Validation loss: 3.1021451683021604

Epoch: 5| Step: 8
Training loss: 0.6825009357529818
Validation loss: 3.0463552765309703

Epoch: 5| Step: 9
Training loss: 0.40753734631041294
Validation loss: 2.9740970242969453

Epoch: 5| Step: 10
Training loss: 0.3959955293061059
Validation loss: 3.0684050797996814

Epoch: 5| Step: 11
Training loss: 0.4293374109264598
Validation loss: 3.0474290523349508

Epoch: 330| Step: 0
Training loss: 0.6274592653100384
Validation loss: 3.095105205117993

Epoch: 5| Step: 1
Training loss: 0.533573315565654
Validation loss: 2.954047830896932

Epoch: 5| Step: 2
Training loss: 0.6246075828769876
Validation loss: 3.0256497604805834

Epoch: 5| Step: 3
Training loss: 0.4281630436499109
Validation loss: 2.9877416185809365

Epoch: 5| Step: 4
Training loss: 0.4616562202312615
Validation loss: 3.0236113972231276

Epoch: 5| Step: 5
Training loss: 0.466990713949204
Validation loss: 3.002345815408542

Epoch: 5| Step: 6
Training loss: 0.6951838385024185
Validation loss: 3.0518000322600374

Epoch: 5| Step: 7
Training loss: 0.4806779080551016
Validation loss: 3.1107055047473184

Epoch: 5| Step: 8
Training loss: 0.371753467607776
Validation loss: 3.0837882464557165

Epoch: 5| Step: 9
Training loss: 1.329269006231291
Validation loss: 3.0982655154133965

Epoch: 5| Step: 10
Training loss: 0.4557661822590685
Validation loss: 3.0126761148872574

Epoch: 5| Step: 11
Training loss: 0.433054339327167
Validation loss: 2.9517994753402226

Epoch: 331| Step: 0
Training loss: 0.6507571450631476
Validation loss: 3.082715160459161

Epoch: 5| Step: 1
Training loss: 0.3783374134584524
Validation loss: 2.973570864678914

Epoch: 5| Step: 2
Training loss: 0.594861571173003
Validation loss: 3.021650458129513

Epoch: 5| Step: 3
Training loss: 0.4577395501457061
Validation loss: 3.012449298790767

Epoch: 5| Step: 4
Training loss: 0.6217946829758997
Validation loss: 2.9823923598725344

Epoch: 5| Step: 5
Training loss: 0.47670352912742414
Validation loss: 2.962968044489128

Epoch: 5| Step: 6
Training loss: 0.5759216023660814
Validation loss: 3.011829586933446

Epoch: 5| Step: 7
Training loss: 0.3349493486273662
Validation loss: 3.0274499722785517

Epoch: 5| Step: 8
Training loss: 0.4999338046601539
Validation loss: 2.9612353534907916

Epoch: 5| Step: 9
Training loss: 1.2804401443386364
Validation loss: 3.0513374157054476

Epoch: 5| Step: 10
Training loss: 0.43278600012564483
Validation loss: 3.069771244139492

Epoch: 5| Step: 11
Training loss: 0.586613125696962
Validation loss: 3.056531442270502

Epoch: 332| Step: 0
Training loss: 0.7177529260727868
Validation loss: 2.977432924695396

Epoch: 5| Step: 1
Training loss: 0.5333446273005259
Validation loss: 2.9261759316501106

Epoch: 5| Step: 2
Training loss: 0.6628198553286017
Validation loss: 3.0423365447543356

Epoch: 5| Step: 3
Training loss: 0.45442006416328573
Validation loss: 3.0276415245699586

Epoch: 5| Step: 4
Training loss: 0.5573995937286391
Validation loss: 3.0381983596534328

Epoch: 5| Step: 5
Training loss: 0.31986537988797314
Validation loss: 2.981014989924202

Epoch: 5| Step: 6
Training loss: 1.3391416617533525
Validation loss: 3.0630559643682815

Epoch: 5| Step: 7
Training loss: 0.5432804228562692
Validation loss: 3.056023597392546

Epoch: 5| Step: 8
Training loss: 0.39672128524060346
Validation loss: 3.018924663721771

Epoch: 5| Step: 9
Training loss: 0.5677685895200394
Validation loss: 3.0115054327546162

Epoch: 5| Step: 10
Training loss: 0.5803234981384157
Validation loss: 3.0206270914815754

Epoch: 5| Step: 11
Training loss: 0.9351459193475701
Validation loss: 3.022128870917379

Epoch: 333| Step: 0
Training loss: 0.4768106564901048
Validation loss: 3.0495379980044253

Epoch: 5| Step: 1
Training loss: 1.3331269263402485
Validation loss: 3.0762646599556818

Epoch: 5| Step: 2
Training loss: 0.8523580002751703
Validation loss: 3.0040745615673212

Epoch: 5| Step: 3
Training loss: 0.9083332255710457
Validation loss: 3.0864081237155907

Epoch: 5| Step: 4
Training loss: 0.7339144947026649
Validation loss: 3.074350395437646

Epoch: 5| Step: 5
Training loss: 0.3884642156496352
Validation loss: 2.957784848118366

Epoch: 5| Step: 6
Training loss: 0.5461296451761339
Validation loss: 3.0502834589621513

Epoch: 5| Step: 7
Training loss: 0.6341161838853338
Validation loss: 3.0359215477304917

Epoch: 5| Step: 8
Training loss: 0.45754068462117176
Validation loss: 2.977486244301206

Epoch: 5| Step: 9
Training loss: 0.5202115989198596
Validation loss: 2.986127136000185

Epoch: 5| Step: 10
Training loss: 0.433628802558015
Validation loss: 3.0920444661696105

Epoch: 5| Step: 11
Training loss: 0.5254774624558524
Validation loss: 3.063377426597699

Epoch: 334| Step: 0
Training loss: 0.6286124259797128
Validation loss: 3.006579399831916

Epoch: 5| Step: 1
Training loss: 0.5201688310379929
Validation loss: 3.058007175523212

Epoch: 5| Step: 2
Training loss: 0.4608932409212585
Validation loss: 3.037882784283587

Epoch: 5| Step: 3
Training loss: 0.566249983705432
Validation loss: 2.9907494385227253

Epoch: 5| Step: 4
Training loss: 0.483838676585199
Validation loss: 2.9810040094546357

Epoch: 5| Step: 5
Training loss: 0.5100866892477339
Validation loss: 2.970243155445725

Epoch: 5| Step: 6
Training loss: 0.48680149924087357
Validation loss: 2.9943408306064345

Epoch: 5| Step: 7
Training loss: 1.2640104002524706
Validation loss: 3.0856999044255606

Epoch: 5| Step: 8
Training loss: 0.5068263528906183
Validation loss: 3.090879476502269

Epoch: 5| Step: 9
Training loss: 0.5252768808210733
Validation loss: 3.040830338259604

Epoch: 5| Step: 10
Training loss: 0.5548077305258619
Validation loss: 3.0268454258458775

Epoch: 5| Step: 11
Training loss: 0.3111167692848297
Validation loss: 3.0254255817742375

Epoch: 335| Step: 0
Training loss: 0.502375028357276
Validation loss: 2.964835437064397

Epoch: 5| Step: 1
Training loss: 0.7609226468181673
Validation loss: 2.935405679582475

Epoch: 5| Step: 2
Training loss: 0.47764477018138535
Validation loss: 2.9084156403649644

Epoch: 5| Step: 3
Training loss: 0.46637365077101417
Validation loss: 2.9423492291299396

Epoch: 5| Step: 4
Training loss: 1.2749757895321492
Validation loss: 3.034217460175389

Epoch: 5| Step: 5
Training loss: 0.28685176736590745
Validation loss: 3.0625034773411115

Epoch: 5| Step: 6
Training loss: 0.40201366180008175
Validation loss: 2.9876897621273635

Epoch: 5| Step: 7
Training loss: 0.5390655959772961
Validation loss: 3.017970699711584

Epoch: 5| Step: 8
Training loss: 0.632119611827659
Validation loss: 2.996441989572885

Epoch: 5| Step: 9
Training loss: 0.44420378679587635
Validation loss: 3.0095467691067754

Epoch: 5| Step: 10
Training loss: 0.7115530346629129
Validation loss: 3.006331656411714

Epoch: 5| Step: 11
Training loss: 0.3778269822884397
Validation loss: 3.0295446521225773

Epoch: 336| Step: 0
Training loss: 0.47034614924203594
Validation loss: 2.9591733127280517

Epoch: 5| Step: 1
Training loss: 0.549420264704386
Validation loss: 2.948878540222571

Epoch: 5| Step: 2
Training loss: 0.5323971816092938
Validation loss: 2.9771332614912884

Epoch: 5| Step: 3
Training loss: 0.4200321141522088
Validation loss: 3.013260851866748

Epoch: 5| Step: 4
Training loss: 0.6922088533642666
Validation loss: 2.9777792398655167

Epoch: 5| Step: 5
Training loss: 0.4959071251377521
Validation loss: 3.0561195847575404

Epoch: 5| Step: 6
Training loss: 0.6179810263551273
Validation loss: 2.959432090066278

Epoch: 5| Step: 7
Training loss: 0.4412690008357221
Validation loss: 2.9069808259831835

Epoch: 5| Step: 8
Training loss: 0.43413424097446823
Validation loss: 3.0272176211754585

Epoch: 5| Step: 9
Training loss: 0.42365590125374375
Validation loss: 2.9919715219077796

Epoch: 5| Step: 10
Training loss: 0.4715888210304721
Validation loss: 2.996277201315137

Epoch: 5| Step: 11
Training loss: 2.772279739505205
Validation loss: 3.0342937636705902

Epoch: 337| Step: 0
Training loss: 0.48335688248628755
Validation loss: 2.999428469470179

Epoch: 5| Step: 1
Training loss: 0.5411499352493959
Validation loss: 2.978874370045203

Epoch: 5| Step: 2
Training loss: 0.6922902205394053
Validation loss: 2.982235869190913

Epoch: 5| Step: 3
Training loss: 1.233921692099331
Validation loss: 3.0763656377571493

Epoch: 5| Step: 4
Training loss: 0.5474033800422168
Validation loss: 2.9812541974969156

Epoch: 5| Step: 5
Training loss: 0.40001921756594816
Validation loss: 3.0383383305704355

Epoch: 5| Step: 6
Training loss: 0.5312038008853358
Validation loss: 3.0493738931042853

Epoch: 5| Step: 7
Training loss: 0.6239190768044219
Validation loss: 3.0695819195838663

Epoch: 5| Step: 8
Training loss: 0.5358615877089398
Validation loss: 3.066345811965038

Epoch: 5| Step: 9
Training loss: 0.4246805119167601
Validation loss: 3.0426565458197383

Epoch: 5| Step: 10
Training loss: 0.5079908497936206
Validation loss: 2.889588732165459

Epoch: 5| Step: 11
Training loss: 0.5320061463470632
Validation loss: 3.006772271812399

Epoch: 338| Step: 0
Training loss: 1.2081995374772454
Validation loss: 3.1155531350446632

Epoch: 5| Step: 1
Training loss: 0.5628088791819188
Validation loss: 3.1283423828088277

Epoch: 5| Step: 2
Training loss: 0.5310998031123118
Validation loss: 3.0488231788414297

Epoch: 5| Step: 3
Training loss: 0.3589105092162526
Validation loss: 3.0395871308590388

Epoch: 5| Step: 4
Training loss: 0.5014773834354442
Validation loss: 3.077409528791286

Epoch: 5| Step: 5
Training loss: 0.44717836153408325
Validation loss: 2.975984325308265

Epoch: 5| Step: 6
Training loss: 0.472767462139101
Validation loss: 3.0438543295294274

Epoch: 5| Step: 7
Training loss: 0.3706867194288902
Validation loss: 2.898463602968152

Epoch: 5| Step: 8
Training loss: 0.43195310993163505
Validation loss: 3.0336103393195404

Epoch: 5| Step: 9
Training loss: 0.3778900993174741
Validation loss: 3.0175841824204306

Epoch: 5| Step: 10
Training loss: 0.7724820796036086
Validation loss: 2.9508169429075712

Epoch: 5| Step: 11
Training loss: 0.3439011674892778
Validation loss: 3.003432690844762

Epoch: 339| Step: 0
Training loss: 0.34700513795585947
Validation loss: 3.007306080250586

Epoch: 5| Step: 1
Training loss: 0.4279232566137871
Validation loss: 2.962117764270212

Epoch: 5| Step: 2
Training loss: 1.2671364130712426
Validation loss: 3.0758593881926846

Epoch: 5| Step: 3
Training loss: 0.4365466152242137
Validation loss: 3.000633454335073

Epoch: 5| Step: 4
Training loss: 0.40817342768791703
Validation loss: 2.991487286661337

Epoch: 5| Step: 5
Training loss: 0.48799091099459335
Validation loss: 3.0971884997679324

Epoch: 5| Step: 6
Training loss: 0.5945791177615787
Validation loss: 3.086755825944223

Epoch: 5| Step: 7
Training loss: 0.4262284021974669
Validation loss: 2.9413779950990655

Epoch: 5| Step: 8
Training loss: 0.3359215311202758
Validation loss: 3.0464098061715306

Epoch: 5| Step: 9
Training loss: 0.6183958658523104
Validation loss: 3.053105236394266

Epoch: 5| Step: 10
Training loss: 0.9140745634929445
Validation loss: 2.970259858049042

Epoch: 5| Step: 11
Training loss: 0.2571498852149697
Validation loss: 3.092524253572274

Epoch: 340| Step: 0
Training loss: 0.42234754588192136
Validation loss: 3.042528136072847

Epoch: 5| Step: 1
Training loss: 0.47480909438855773
Validation loss: 2.9164637097634487

Epoch: 5| Step: 2
Training loss: 0.6018337529944315
Validation loss: 3.0508629286899707

Epoch: 5| Step: 3
Training loss: 0.4499806784084548
Validation loss: 3.0353903661743553

Epoch: 5| Step: 4
Training loss: 0.4487475204133621
Validation loss: 3.1557053136902575

Epoch: 5| Step: 5
Training loss: 0.7786715491565823
Validation loss: 3.0665660840795588

Epoch: 5| Step: 6
Training loss: 0.5375974622235827
Validation loss: 2.9443464305346985

Epoch: 5| Step: 7
Training loss: 1.2622636498272102
Validation loss: 3.0695045903058613

Epoch: 5| Step: 8
Training loss: 0.3053299415315311
Validation loss: 2.9917251389048203

Epoch: 5| Step: 9
Training loss: 0.44193614110466645
Validation loss: 3.1227050810517505

Epoch: 5| Step: 10
Training loss: 0.38069892829321317
Validation loss: 3.0028640797795783

Epoch: 5| Step: 11
Training loss: 0.21957110521722797
Validation loss: 3.1028067513648683

Epoch: 341| Step: 0
Training loss: 1.2189417957120094
Validation loss: 3.036441679702203

Epoch: 5| Step: 1
Training loss: 0.503856952237083
Validation loss: 3.059237737567002

Epoch: 5| Step: 2
Training loss: 0.5122407478457622
Validation loss: 3.042579616203927

Epoch: 5| Step: 3
Training loss: 0.5241054713829943
Validation loss: 3.0225512399161154

Epoch: 5| Step: 4
Training loss: 0.4769404429156349
Validation loss: 3.0647849881239417

Epoch: 5| Step: 5
Training loss: 0.5090204690122577
Validation loss: 3.0598982736564264

Epoch: 5| Step: 6
Training loss: 0.4166649599835093
Validation loss: 3.044421788049734

Epoch: 5| Step: 7
Training loss: 0.6862383232790914
Validation loss: 3.0453628308837875

Epoch: 5| Step: 8
Training loss: 0.4340145200188014
Validation loss: 3.112696960963249

Epoch: 5| Step: 9
Training loss: 0.4621745175697779
Validation loss: 3.114082402460632

Epoch: 5| Step: 10
Training loss: 0.4504672571713908
Validation loss: 3.105030807868515

Epoch: 5| Step: 11
Training loss: 0.45403494397512445
Validation loss: 3.0985596899939893

Epoch: 342| Step: 0
Training loss: 1.3430759602394589
Validation loss: 3.162876682439999

Epoch: 5| Step: 1
Training loss: 0.48579842088940534
Validation loss: 3.149892213783736

Epoch: 5| Step: 2
Training loss: 0.4210389471398808
Validation loss: 3.048175084459556

Epoch: 5| Step: 3
Training loss: 0.5364215122166227
Validation loss: 3.008886718485873

Epoch: 5| Step: 4
Training loss: 0.7288498099208096
Validation loss: 3.095193843887662

Epoch: 5| Step: 5
Training loss: 0.550423742831667
Validation loss: 3.048565983830513

Epoch: 5| Step: 6
Training loss: 0.6753279648633658
Validation loss: 3.090882147340714

Epoch: 5| Step: 7
Training loss: 0.5443385293527251
Validation loss: 3.088396230857617

Epoch: 5| Step: 8
Training loss: 0.4245573354098367
Validation loss: 3.0490393556273774

Epoch: 5| Step: 9
Training loss: 0.5548043463768434
Validation loss: 3.002012511579909

Epoch: 5| Step: 10
Training loss: 0.561714312412523
Validation loss: 3.010779317156081

Epoch: 5| Step: 11
Training loss: 0.2739227213153165
Validation loss: 3.0052972093967787

Epoch: 343| Step: 0
Training loss: 0.44435501896056323
Validation loss: 3.034568323825177

Epoch: 5| Step: 1
Training loss: 0.36825876004637165
Validation loss: 2.9444595471230737

Epoch: 5| Step: 2
Training loss: 0.6561202874736625
Validation loss: 3.103510833217986

Epoch: 5| Step: 3
Training loss: 0.32301723800933285
Validation loss: 3.124084840922141

Epoch: 5| Step: 4
Training loss: 0.4677474904678609
Validation loss: 3.0911009650548005

Epoch: 5| Step: 5
Training loss: 1.2339013555071472
Validation loss: 3.065183317101854

Epoch: 5| Step: 6
Training loss: 0.3985343329251232
Validation loss: 2.9956170357271246

Epoch: 5| Step: 7
Training loss: 0.40498764808091864
Validation loss: 3.065649916884291

Epoch: 5| Step: 8
Training loss: 0.5159032533255784
Validation loss: 3.049391651065101

Epoch: 5| Step: 9
Training loss: 0.42904814924675144
Validation loss: 2.9983962792522907

Epoch: 5| Step: 10
Training loss: 0.4680462959246491
Validation loss: 2.9802496393339677

Epoch: 5| Step: 11
Training loss: 0.662131070031963
Validation loss: 2.952325245043086

Epoch: 344| Step: 0
Training loss: 0.5992301462375423
Validation loss: 3.0629706961728353

Epoch: 5| Step: 1
Training loss: 0.5598204953865344
Validation loss: 3.0256457745551266

Epoch: 5| Step: 2
Training loss: 0.6951890471514183
Validation loss: 3.001604614677242

Epoch: 5| Step: 3
Training loss: 0.5772045385781714
Validation loss: 3.063834678043118

Epoch: 5| Step: 4
Training loss: 0.6363720330158125
Validation loss: 3.0736835309505657

Epoch: 5| Step: 5
Training loss: 0.4199082660687688
Validation loss: 3.0320785084984356

Epoch: 5| Step: 6
Training loss: 0.3336944883593281
Validation loss: 3.0431799760209843

Epoch: 5| Step: 7
Training loss: 0.7342531224834795
Validation loss: 2.989187222112235

Epoch: 5| Step: 8
Training loss: 1.351378411782453
Validation loss: 2.971783115853154

Epoch: 5| Step: 9
Training loss: 0.4727092902318293
Validation loss: 3.048596953564566

Epoch: 5| Step: 10
Training loss: 0.4412553411111878
Validation loss: 2.9485267854752255

Epoch: 5| Step: 11
Training loss: 0.9471191922297088
Validation loss: 3.0037857580470817

Epoch: 345| Step: 0
Training loss: 0.618304268362942
Validation loss: 3.004975345688158

Epoch: 5| Step: 1
Training loss: 0.5207188734805203
Validation loss: 2.9507218073886468

Epoch: 5| Step: 2
Training loss: 1.2327333954354451
Validation loss: 3.0973723138318543

Epoch: 5| Step: 3
Training loss: 0.6080980615637958
Validation loss: 3.0180144322751543

Epoch: 5| Step: 4
Training loss: 0.5456085254152733
Validation loss: 2.9942090979914906

Epoch: 5| Step: 5
Training loss: 0.48213514695234344
Validation loss: 2.9373548214796408

Epoch: 5| Step: 6
Training loss: 0.3348100728425347
Validation loss: 2.9060740400527503

Epoch: 5| Step: 7
Training loss: 0.4942949981195598
Validation loss: 3.0168123263201667

Epoch: 5| Step: 8
Training loss: 0.5702699096662545
Validation loss: 3.008979458693251

Epoch: 5| Step: 9
Training loss: 0.532363006180824
Validation loss: 3.047801204657728

Epoch: 5| Step: 10
Training loss: 0.7567698591365613
Validation loss: 3.0836484249742266

Epoch: 5| Step: 11
Training loss: 0.44895837950503414
Validation loss: 2.967538573066067

Epoch: 346| Step: 0
Training loss: 0.4133673897231008
Validation loss: 3.0672440795551106

Epoch: 5| Step: 1
Training loss: 0.4398624463622029
Validation loss: 2.9979099503354214

Epoch: 5| Step: 2
Training loss: 0.6582881748026287
Validation loss: 2.9363296896496576

Epoch: 5| Step: 3
Training loss: 0.4322996157945597
Validation loss: 3.0415952665405523

Epoch: 5| Step: 4
Training loss: 0.5872937844941799
Validation loss: 2.986799812863243

Epoch: 5| Step: 5
Training loss: 1.3013310917075451
Validation loss: 2.9572033884529385

Epoch: 5| Step: 6
Training loss: 0.5456634179362111
Validation loss: 2.966708368015445

Epoch: 5| Step: 7
Training loss: 0.6633602917487073
Validation loss: 3.0365295772580794

Epoch: 5| Step: 8
Training loss: 0.37806835144302464
Validation loss: 2.97038127853654

Epoch: 5| Step: 9
Training loss: 0.3569202551064974
Validation loss: 2.979665735542333

Epoch: 5| Step: 10
Training loss: 0.6303657277393729
Validation loss: 2.9969086614315392

Epoch: 5| Step: 11
Training loss: 0.14717460774291174
Validation loss: 2.975655274793022

Epoch: 347| Step: 0
Training loss: 0.47540069669713386
Validation loss: 3.015031103840405

Epoch: 5| Step: 1
Training loss: 0.5764551274668072
Validation loss: 3.0037038674570966

Epoch: 5| Step: 2
Training loss: 0.7083780096961821
Validation loss: 3.026409859944731

Epoch: 5| Step: 3
Training loss: 0.3904531863966386
Validation loss: 3.0067179385079426

Epoch: 5| Step: 4
Training loss: 0.5850122394259523
Validation loss: 2.9252100354233543

Epoch: 5| Step: 5
Training loss: 0.5071469567265592
Validation loss: 3.070181490341236

Epoch: 5| Step: 6
Training loss: 0.43699949449885306
Validation loss: 2.9121939776672243

Epoch: 5| Step: 7
Training loss: 0.4721940673432012
Validation loss: 3.1451596281824488

Epoch: 5| Step: 8
Training loss: 0.4948881172403526
Validation loss: 2.923730753889231

Epoch: 5| Step: 9
Training loss: 1.2870297211932844
Validation loss: 3.0669142575624853

Epoch: 5| Step: 10
Training loss: 0.6119372224975618
Validation loss: 3.059151330291316

Epoch: 5| Step: 11
Training loss: 0.1963624200342739
Validation loss: 2.9798883395429097

Epoch: 348| Step: 0
Training loss: 0.6293247323290324
Validation loss: 2.989250664140092

Epoch: 5| Step: 1
Training loss: 0.4925446652476386
Validation loss: 2.9516371287248804

Epoch: 5| Step: 2
Training loss: 0.3786462107800365
Validation loss: 2.900663790699275

Epoch: 5| Step: 3
Training loss: 0.7583199208159878
Validation loss: 2.9805084232541295

Epoch: 5| Step: 4
Training loss: 1.2942302807519122
Validation loss: 2.9325273982548916

Epoch: 5| Step: 5
Training loss: 0.5112080245752273
Validation loss: 2.9308710852447555

Epoch: 5| Step: 6
Training loss: 0.5468736103585162
Validation loss: 3.0272177852552904

Epoch: 5| Step: 7
Training loss: 0.4557051207238596
Validation loss: 3.0751232834528417

Epoch: 5| Step: 8
Training loss: 0.47003376327135904
Validation loss: 3.034256319343528

Epoch: 5| Step: 9
Training loss: 0.48984019325340067
Validation loss: 3.110860102514738

Epoch: 5| Step: 10
Training loss: 0.4148229238164021
Validation loss: 2.9754993479121206

Epoch: 5| Step: 11
Training loss: 0.4713027901513667
Validation loss: 3.0393552434855584

Epoch: 349| Step: 0
Training loss: 0.6832049762925398
Validation loss: 3.0233711741398492

Epoch: 5| Step: 1
Training loss: 0.4293699478285296
Validation loss: 3.0113653560304177

Epoch: 5| Step: 2
Training loss: 1.3278612211486223
Validation loss: 3.0517316209813563

Epoch: 5| Step: 3
Training loss: 0.39464086010864713
Validation loss: 3.023633689330746

Epoch: 5| Step: 4
Training loss: 0.34916596024327223
Validation loss: 3.0041380628704633

Epoch: 5| Step: 5
Training loss: 0.46297608564463666
Validation loss: 3.0059596047681083

Epoch: 5| Step: 6
Training loss: 0.4564176173167451
Validation loss: 2.979118878085758

Epoch: 5| Step: 7
Training loss: 0.4641069294632265
Validation loss: 2.985628400767003

Epoch: 5| Step: 8
Training loss: 0.40335154931979184
Validation loss: 3.0998483848924896

Epoch: 5| Step: 9
Training loss: 0.4997521322509253
Validation loss: 2.984905724993581

Epoch: 5| Step: 10
Training loss: 0.45863104673461097
Validation loss: 3.001452359335479

Epoch: 5| Step: 11
Training loss: 0.46676281282014953
Validation loss: 3.0001065480331937

Epoch: 350| Step: 0
Training loss: 1.2639415518067547
Validation loss: 2.893627494130359

Epoch: 5| Step: 1
Training loss: 0.39796372837692207
Validation loss: 2.986625302324921

Epoch: 5| Step: 2
Training loss: 0.46369333322005
Validation loss: 2.9416950889507505

Epoch: 5| Step: 3
Training loss: 0.4587510834974752
Validation loss: 2.9791727543926507

Epoch: 5| Step: 4
Training loss: 0.5863997861006348
Validation loss: 3.0506317974739856

Epoch: 5| Step: 5
Training loss: 0.40950698326546936
Validation loss: 2.9966519833329848

Epoch: 5| Step: 6
Training loss: 0.9178377423242595
Validation loss: 3.025326978729406

Epoch: 5| Step: 7
Training loss: 0.44566817886333276
Validation loss: 3.017371019747821

Epoch: 5| Step: 8
Training loss: 0.3349376258856979
Validation loss: 3.0942949848980077

Epoch: 5| Step: 9
Training loss: 0.4221606700230111
Validation loss: 2.9953809550911368

Epoch: 5| Step: 10
Training loss: 0.5530678649531773
Validation loss: 3.059877810594225

Epoch: 5| Step: 11
Training loss: 0.6512786942382381
Validation loss: 2.997412985060223

Epoch: 351| Step: 0
Training loss: 0.6021568780308096
Validation loss: 3.0614367540206193

Epoch: 5| Step: 1
Training loss: 0.41180258445711504
Validation loss: 2.938212362447323

Epoch: 5| Step: 2
Training loss: 0.7091419475728421
Validation loss: 3.076547537980864

Epoch: 5| Step: 3
Training loss: 0.5683750530584347
Validation loss: 3.0228028727977265

Epoch: 5| Step: 4
Training loss: 0.47299363571446074
Validation loss: 2.9927426562723842

Epoch: 5| Step: 5
Training loss: 0.5745097350780601
Validation loss: 2.9779505092476453

Epoch: 5| Step: 6
Training loss: 0.4477167644508625
Validation loss: 3.049345882813896

Epoch: 5| Step: 7
Training loss: 0.579175870351137
Validation loss: 2.9537667211338317

Epoch: 5| Step: 8
Training loss: 1.301207280772397
Validation loss: 2.9644069927917296

Epoch: 5| Step: 9
Training loss: 0.5043062795741643
Validation loss: 2.9852784937854397

Epoch: 5| Step: 10
Training loss: 0.6525659924967108
Validation loss: 2.9747186257898326

Epoch: 5| Step: 11
Training loss: 0.18967407163320146
Validation loss: 3.021607896005681

Epoch: 352| Step: 0
Training loss: 0.5735727685942552
Validation loss: 2.9857925091056283

Epoch: 5| Step: 1
Training loss: 1.33470824500387
Validation loss: 3.011855445988852

Epoch: 5| Step: 2
Training loss: 0.5401879048582636
Validation loss: 3.01004084492849

Epoch: 5| Step: 3
Training loss: 0.6471264235385257
Validation loss: 2.9801331310701844

Epoch: 5| Step: 4
Training loss: 0.6511485863945096
Validation loss: 3.016071899189461

Epoch: 5| Step: 5
Training loss: 0.4153933998404089
Validation loss: 3.0184173404641634

Epoch: 5| Step: 6
Training loss: 0.5430734656920682
Validation loss: 3.0032696225013162

Epoch: 5| Step: 7
Training loss: 0.46491814667135156
Validation loss: 3.047954048732329

Epoch: 5| Step: 8
Training loss: 0.39045856744953733
Validation loss: 3.0228069314859694

Epoch: 5| Step: 9
Training loss: 0.42420158983793266
Validation loss: 2.9669410682245276

Epoch: 5| Step: 10
Training loss: 0.31883155583482575
Validation loss: 2.916013693377704

Epoch: 5| Step: 11
Training loss: 0.407184077180425
Validation loss: 2.9557828296153623

Epoch: 353| Step: 0
Training loss: 1.2457213607702162
Validation loss: 3.0191893620488677

Epoch: 5| Step: 1
Training loss: 0.5334492209811131
Validation loss: 3.0225547796501426

Epoch: 5| Step: 2
Training loss: 0.4167784381996707
Validation loss: 3.012051624550358

Epoch: 5| Step: 3
Training loss: 0.3852379702522326
Validation loss: 3.0154447715809125

Epoch: 5| Step: 4
Training loss: 0.7289503094439691
Validation loss: 2.951732798466812

Epoch: 5| Step: 5
Training loss: 0.5135959815756441
Validation loss: 3.0187760034076976

Epoch: 5| Step: 6
Training loss: 0.43752019699343697
Validation loss: 2.973393279117809

Epoch: 5| Step: 7
Training loss: 0.5471119775945785
Validation loss: 3.0981820499281705

Epoch: 5| Step: 8
Training loss: 0.6815501374352645
Validation loss: 3.0477679908423165

Epoch: 5| Step: 9
Training loss: 0.4200597847100298
Validation loss: 3.0680347597102307

Epoch: 5| Step: 10
Training loss: 0.5899962676463635
Validation loss: 2.9934820822474792

Epoch: 5| Step: 11
Training loss: 0.6417462840372055
Validation loss: 3.028413720501228

Epoch: 354| Step: 0
Training loss: 0.4368291206991189
Validation loss: 2.9056803750094815

Epoch: 5| Step: 1
Training loss: 0.4864353842975395
Validation loss: 2.9469598401270236

Epoch: 5| Step: 2
Training loss: 1.2112752135873777
Validation loss: 3.012789844614649

Epoch: 5| Step: 3
Training loss: 0.39969867368563483
Validation loss: 2.959614430442794

Epoch: 5| Step: 4
Training loss: 0.4691097150874502
Validation loss: 3.0595716502209744

Epoch: 5| Step: 5
Training loss: 0.5187567193388949
Validation loss: 3.017579981732337

Epoch: 5| Step: 6
Training loss: 0.3584403239623676
Validation loss: 3.0777785885682016

Epoch: 5| Step: 7
Training loss: 0.7131226044597059
Validation loss: 3.085066814966512

Epoch: 5| Step: 8
Training loss: 0.5002015124990207
Validation loss: 3.0269498179098457

Epoch: 5| Step: 9
Training loss: 0.7448848897216935
Validation loss: 3.0467389459473884

Epoch: 5| Step: 10
Training loss: 0.661452966703336
Validation loss: 3.0182402015113485

Epoch: 5| Step: 11
Training loss: 0.4531828909100205
Validation loss: 3.049216155131633

Epoch: 355| Step: 0
Training loss: 0.39054701980432466
Validation loss: 3.0165959114572556

Epoch: 5| Step: 1
Training loss: 0.6135544866788762
Validation loss: 2.9797132308587777

Epoch: 5| Step: 2
Training loss: 0.7343973196980137
Validation loss: 2.9507285457715513

Epoch: 5| Step: 3
Training loss: 1.271819133609458
Validation loss: 3.0630443374691128

Epoch: 5| Step: 4
Training loss: 0.3961964017136098
Validation loss: 2.969906377611857

Epoch: 5| Step: 5
Training loss: 0.39935664204893256
Validation loss: 2.9826564467572916

Epoch: 5| Step: 6
Training loss: 0.5078912527200469
Validation loss: 3.0890966252403897

Epoch: 5| Step: 7
Training loss: 0.44175561228211047
Validation loss: 3.021687180876772

Epoch: 5| Step: 8
Training loss: 0.5244353732249043
Validation loss: 2.96910536797439

Epoch: 5| Step: 9
Training loss: 0.6758501756390587
Validation loss: 3.071031898685023

Epoch: 5| Step: 10
Training loss: 0.5140079805630346
Validation loss: 3.0476852317826495

Epoch: 5| Step: 11
Training loss: 0.7685048960900192
Validation loss: 3.0616555509398355

Epoch: 356| Step: 0
Training loss: 0.532591892113176
Validation loss: 2.9120723074710066

Epoch: 5| Step: 1
Training loss: 0.7263261143887463
Validation loss: 3.075757599238193

Epoch: 5| Step: 2
Training loss: 0.5318099885200486
Validation loss: 3.0622663668310537

Epoch: 5| Step: 3
Training loss: 0.412766028365086
Validation loss: 3.0069759311941193

Epoch: 5| Step: 4
Training loss: 0.5370374874211149
Validation loss: 3.008891159119877

Epoch: 5| Step: 5
Training loss: 0.525839093046287
Validation loss: 3.0779179150007465

Epoch: 5| Step: 6
Training loss: 0.3673325515915871
Validation loss: 3.0240767342864245

Epoch: 5| Step: 7
Training loss: 0.4932546098129239
Validation loss: 3.1853552752297025

Epoch: 5| Step: 8
Training loss: 0.42028344135449186
Validation loss: 3.0435902552947973

Epoch: 5| Step: 9
Training loss: 0.6546819208676732
Validation loss: 3.0001456834600293

Epoch: 5| Step: 10
Training loss: 1.313334154541869
Validation loss: 2.990961575676765

Epoch: 5| Step: 11
Training loss: 0.3302453086059214
Validation loss: 3.077949644796593

Epoch: 357| Step: 0
Training loss: 0.41512387475007967
Validation loss: 3.00891562706078

Epoch: 5| Step: 1
Training loss: 0.8671782209570076
Validation loss: 2.977452272806154

Epoch: 5| Step: 2
Training loss: 0.4609779243200219
Validation loss: 3.0546110229805157

Epoch: 5| Step: 3
Training loss: 0.4496663890122098
Validation loss: 3.0470351087448178

Epoch: 5| Step: 4
Training loss: 0.40860214078905344
Validation loss: 2.991542796507698

Epoch: 5| Step: 5
Training loss: 0.5832356019121253
Validation loss: 3.019175355112404

Epoch: 5| Step: 6
Training loss: 0.5224319592576941
Validation loss: 3.0456235288035454

Epoch: 5| Step: 7
Training loss: 0.352960751743893
Validation loss: 2.972314525049419

Epoch: 5| Step: 8
Training loss: 1.2610375895240744
Validation loss: 2.954347461733226

Epoch: 5| Step: 9
Training loss: 0.6372510639045607
Validation loss: 2.9238590501310533

Epoch: 5| Step: 10
Training loss: 0.45673801111356466
Validation loss: 3.0325010968851283

Epoch: 5| Step: 11
Training loss: 0.4408978260124254
Validation loss: 2.9437016231398094

Epoch: 358| Step: 0
Training loss: 0.4615780210887763
Validation loss: 2.964592723246269

Epoch: 5| Step: 1
Training loss: 0.3942503353956848
Validation loss: 2.968234529416207

Epoch: 5| Step: 2
Training loss: 0.4497015141947055
Validation loss: 3.0829097847815112

Epoch: 5| Step: 3
Training loss: 0.43808067478483237
Validation loss: 2.980363036514511

Epoch: 5| Step: 4
Training loss: 0.6424073569229847
Validation loss: 2.948695835803545

Epoch: 5| Step: 5
Training loss: 0.4576438970907602
Validation loss: 3.047738766296743

Epoch: 5| Step: 6
Training loss: 1.2834365609172305
Validation loss: 2.9203614787509733

Epoch: 5| Step: 7
Training loss: 0.4931974494132571
Validation loss: 2.9863837141107017

Epoch: 5| Step: 8
Training loss: 0.36295182663625664
Validation loss: 2.918347920911993

Epoch: 5| Step: 9
Training loss: 0.5189920653451459
Validation loss: 3.006491938429999

Epoch: 5| Step: 10
Training loss: 0.4654065739907093
Validation loss: 3.0319416659681195

Epoch: 5| Step: 11
Training loss: 0.27757022905486717
Validation loss: 2.9653221953909545

Epoch: 359| Step: 0
Training loss: 0.5758529556324428
Validation loss: 2.9669024524231618

Epoch: 5| Step: 1
Training loss: 0.5386575200392938
Validation loss: 2.937923870888458

Epoch: 5| Step: 2
Training loss: 0.5075543554446659
Validation loss: 3.0432314124820765

Epoch: 5| Step: 3
Training loss: 1.3221735281263531
Validation loss: 2.9760821431288913

Epoch: 5| Step: 4
Training loss: 0.3765621430644643
Validation loss: 3.006631042827324

Epoch: 5| Step: 5
Training loss: 0.41217890148434594
Validation loss: 2.983675160662041

Epoch: 5| Step: 6
Training loss: 0.553975629026024
Validation loss: 2.9408620032792676

Epoch: 5| Step: 7
Training loss: 0.5485773022477716
Validation loss: 2.982958698902844

Epoch: 5| Step: 8
Training loss: 0.4058204727693939
Validation loss: 2.938723167449458

Epoch: 5| Step: 9
Training loss: 0.52530476602447
Validation loss: 3.026325683046547

Epoch: 5| Step: 10
Training loss: 0.4660336148034414
Validation loss: 2.9477949701448023

Epoch: 5| Step: 11
Training loss: 0.5542519162032642
Validation loss: 3.0337179630905284

Epoch: 360| Step: 0
Training loss: 0.43584449076669923
Validation loss: 3.143468028645042

Epoch: 5| Step: 1
Training loss: 0.3943415648468392
Validation loss: 3.101816165393516

Epoch: 5| Step: 2
Training loss: 0.3375331994787907
Validation loss: 3.0829039556075672

Epoch: 5| Step: 3
Training loss: 0.460052157223203
Validation loss: 3.0818159755855916

Epoch: 5| Step: 4
Training loss: 0.55927515151039
Validation loss: 3.0426446679252255

Epoch: 5| Step: 5
Training loss: 1.1711487108888703
Validation loss: 3.078398987634992

Epoch: 5| Step: 6
Training loss: 0.44502191934285934
Validation loss: 2.9965024036960304

Epoch: 5| Step: 7
Training loss: 0.6777440930639942
Validation loss: 3.07237213073027

Epoch: 5| Step: 8
Training loss: 0.36071705051614317
Validation loss: 3.0064735371786755

Epoch: 5| Step: 9
Training loss: 0.5004563930866524
Validation loss: 3.038053601709137

Epoch: 5| Step: 10
Training loss: 0.29907295071270384
Validation loss: 3.0729271527558635

Epoch: 5| Step: 11
Training loss: 0.7476990291909046
Validation loss: 3.0369403133786617

Epoch: 361| Step: 0
Training loss: 0.4449236661290529
Validation loss: 3.0840693360041382

Epoch: 5| Step: 1
Training loss: 0.6613334002118243
Validation loss: 3.0056678623383086

Epoch: 5| Step: 2
Training loss: 0.37567104460439593
Validation loss: 2.9501840152837753

Epoch: 5| Step: 3
Training loss: 1.3829065495636537
Validation loss: 3.0055794225071435

Epoch: 5| Step: 4
Training loss: 0.5544732983130706
Validation loss: 3.056110873237848

Epoch: 5| Step: 5
Training loss: 0.35980238586888985
Validation loss: 2.9969945462766674

Epoch: 5| Step: 6
Training loss: 0.50612197599405
Validation loss: 3.032633121773162

Epoch: 5| Step: 7
Training loss: 0.43062127694456936
Validation loss: 3.0125083168727516

Epoch: 5| Step: 8
Training loss: 0.4316392958952865
Validation loss: 3.0961093640052053

Epoch: 5| Step: 9
Training loss: 0.40291127668100407
Validation loss: 2.8772539446382184

Epoch: 5| Step: 10
Training loss: 0.455506479261191
Validation loss: 2.973617772490787

Epoch: 5| Step: 11
Training loss: 0.538327060959161
Validation loss: 3.020282433141939

Epoch: 362| Step: 0
Training loss: 1.3649228767992665
Validation loss: 2.999400476314504

Epoch: 5| Step: 1
Training loss: 0.4989107008346312
Validation loss: 2.981025540467784

Epoch: 5| Step: 2
Training loss: 0.5287601804542306
Validation loss: 2.979729016899444

Epoch: 5| Step: 3
Training loss: 0.5544236858712366
Validation loss: 2.9751808951648826

Epoch: 5| Step: 4
Training loss: 0.4202185359139265
Validation loss: 3.0094852799662277

Epoch: 5| Step: 5
Training loss: 0.4340139191852132
Validation loss: 2.980693806975044

Epoch: 5| Step: 6
Training loss: 0.5792917386404118
Validation loss: 3.000604164693735

Epoch: 5| Step: 7
Training loss: 0.4912386937575395
Validation loss: 3.0240495868825144

Epoch: 5| Step: 8
Training loss: 0.3451491944993727
Validation loss: 3.002094842084382

Epoch: 5| Step: 9
Training loss: 0.5740462842134737
Validation loss: 3.023209289691181

Epoch: 5| Step: 10
Training loss: 0.5925728522954434
Validation loss: 3.001370686417961

Epoch: 5| Step: 11
Training loss: 0.4022202533702423
Validation loss: 2.997596677099221

Epoch: 363| Step: 0
Training loss: 1.3023707212551197
Validation loss: 2.994595746252185

Epoch: 5| Step: 1
Training loss: 0.601704048248552
Validation loss: 3.0464112703255553

Epoch: 5| Step: 2
Training loss: 0.4503657086801202
Validation loss: 2.991329352259794

Epoch: 5| Step: 3
Training loss: 0.4751500633010092
Validation loss: 2.990816202166892

Epoch: 5| Step: 4
Training loss: 0.525889305359039
Validation loss: 3.130514616535433

Epoch: 5| Step: 5
Training loss: 0.536354866666986
Validation loss: 3.049807136983353

Epoch: 5| Step: 6
Training loss: 0.4091668138322481
Validation loss: 2.9527858021283104

Epoch: 5| Step: 7
Training loss: 0.3966374782867969
Validation loss: 2.9091835768922176

Epoch: 5| Step: 8
Training loss: 0.46538547397111146
Validation loss: 3.008037135995966

Epoch: 5| Step: 9
Training loss: 0.5569960145653641
Validation loss: 3.020234309468923

Epoch: 5| Step: 10
Training loss: 0.73486332180492
Validation loss: 2.97697547323904

Epoch: 5| Step: 11
Training loss: 0.3344086411745967
Validation loss: 2.9668893236728344

Epoch: 364| Step: 0
Training loss: 0.3504579145616252
Validation loss: 3.0479082849682393

Epoch: 5| Step: 1
Training loss: 1.2628529650108014
Validation loss: 2.958554848360728

Epoch: 5| Step: 2
Training loss: 0.5682575619668947
Validation loss: 2.998136782877166

Epoch: 5| Step: 3
Training loss: 0.48153447375969005
Validation loss: 3.0051850869498904

Epoch: 5| Step: 4
Training loss: 0.4411478721124166
Validation loss: 2.9804274596574345

Epoch: 5| Step: 5
Training loss: 0.5188204269401011
Validation loss: 2.9943659582116338

Epoch: 5| Step: 6
Training loss: 0.4866345524098984
Validation loss: 3.085141297329354

Epoch: 5| Step: 7
Training loss: 0.5398464859756499
Validation loss: 3.010314165282075

Epoch: 5| Step: 8
Training loss: 0.721252397503496
Validation loss: 2.8996561715311446

Epoch: 5| Step: 9
Training loss: 0.38687866449546404
Validation loss: 3.0487748572522406

Epoch: 5| Step: 10
Training loss: 0.5011314762331677
Validation loss: 2.990609113756675

Epoch: 5| Step: 11
Training loss: 0.43993171909857176
Validation loss: 3.004294143455294

Epoch: 365| Step: 0
Training loss: 0.4537643657333341
Validation loss: 2.9399576998173966

Epoch: 5| Step: 1
Training loss: 0.4393689731982227
Validation loss: 3.03841597242928

Epoch: 5| Step: 2
Training loss: 0.595628577398743
Validation loss: 3.0025491215914486

Epoch: 5| Step: 3
Training loss: 0.4593175125481831
Validation loss: 3.042599774419663

Epoch: 5| Step: 4
Training loss: 0.31842692074034296
Validation loss: 2.995512871631128

Epoch: 5| Step: 5
Training loss: 0.554950490581881
Validation loss: 2.9874761789295285

Epoch: 5| Step: 6
Training loss: 1.2610528091971103
Validation loss: 3.083008514942326

Epoch: 5| Step: 7
Training loss: 0.380587280108192
Validation loss: 3.0697329834108804

Epoch: 5| Step: 8
Training loss: 0.5946429214166568
Validation loss: 3.016124183306126

Epoch: 5| Step: 9
Training loss: 0.5666398454611073
Validation loss: 3.018069773500715

Epoch: 5| Step: 10
Training loss: 0.4142831358482898
Validation loss: 3.0011304424245595

Epoch: 5| Step: 11
Training loss: 0.2165973019675359
Validation loss: 3.0362927253714562

Epoch: 366| Step: 0
Training loss: 0.5465204451943045
Validation loss: 3.013257413306164

Epoch: 5| Step: 1
Training loss: 1.2829892054227832
Validation loss: 3.02048699377651

Epoch: 5| Step: 2
Training loss: 0.5336246710512886
Validation loss: 2.9470253912426556

Epoch: 5| Step: 3
Training loss: 0.570552827547298
Validation loss: 2.913451760579817

Epoch: 5| Step: 4
Training loss: 0.39919459648746736
Validation loss: 2.965623397076371

Epoch: 5| Step: 5
Training loss: 0.3876726542657157
Validation loss: 2.966979110977238

Epoch: 5| Step: 6
Training loss: 0.5591287251925527
Validation loss: 3.042393836972266

Epoch: 5| Step: 7
Training loss: 0.6778857587002417
Validation loss: 3.0829886080514606

Epoch: 5| Step: 8
Training loss: 0.6944025922455503
Validation loss: 3.1036101563518774

Epoch: 5| Step: 9
Training loss: 0.542631909291064
Validation loss: 3.028306772611222

Epoch: 5| Step: 10
Training loss: 0.38515584299557365
Validation loss: 2.9659011255365706

Epoch: 5| Step: 11
Training loss: 0.47453131642119767
Validation loss: 2.9935391214438534

Epoch: 367| Step: 0
Training loss: 0.7433052881221839
Validation loss: 2.929506372574742

Epoch: 5| Step: 1
Training loss: 0.5409155246936288
Validation loss: 3.038800542895704

Epoch: 5| Step: 2
Training loss: 0.5386351951188442
Validation loss: 2.9764480969328266

Epoch: 5| Step: 3
Training loss: 0.35515824055145334
Validation loss: 3.0559936001131858

Epoch: 5| Step: 4
Training loss: 0.4030628259899722
Validation loss: 3.012413357112618

Epoch: 5| Step: 5
Training loss: 0.6335303391264853
Validation loss: 2.999013463704219

Epoch: 5| Step: 6
Training loss: 1.2990521918891065
Validation loss: 3.0411095185138817

Epoch: 5| Step: 7
Training loss: 0.40862287268051317
Validation loss: 2.997592589247775

Epoch: 5| Step: 8
Training loss: 0.3626657419470493
Validation loss: 3.0422733542291227

Epoch: 5| Step: 9
Training loss: 0.4075394121664166
Validation loss: 3.0554055803272004

Epoch: 5| Step: 10
Training loss: 0.46096837215163716
Validation loss: 2.934616184986854

Epoch: 5| Step: 11
Training loss: 0.33492743766690863
Validation loss: 2.9647045412750295

Epoch: 368| Step: 0
Training loss: 0.4728523036946251
Validation loss: 3.1220964421322437

Epoch: 5| Step: 1
Training loss: 1.3211781750575555
Validation loss: 2.977358251953575

Epoch: 5| Step: 2
Training loss: 0.4790722159578054
Validation loss: 2.9859922597332993

Epoch: 5| Step: 3
Training loss: 0.5853746126439607
Validation loss: 2.955420190847689

Epoch: 5| Step: 4
Training loss: 0.6628284431924903
Validation loss: 3.043345182001614

Epoch: 5| Step: 5
Training loss: 0.46815351045419484
Validation loss: 2.9320521767873458

Epoch: 5| Step: 6
Training loss: 0.42134788926599587
Validation loss: 3.0820596852378817

Epoch: 5| Step: 7
Training loss: 0.43791114697787287
Validation loss: 2.99228941608562

Epoch: 5| Step: 8
Training loss: 0.5018685711250561
Validation loss: 2.973190420031244

Epoch: 5| Step: 9
Training loss: 0.3686560220092782
Validation loss: 2.9074624414059924

Epoch: 5| Step: 10
Training loss: 0.46046664547835725
Validation loss: 2.9674231826847235

Epoch: 5| Step: 11
Training loss: 0.3456490684530937
Validation loss: 3.068955530067762

Epoch: 369| Step: 0
Training loss: 0.6661849268183503
Validation loss: 3.0916162061729064

Epoch: 5| Step: 1
Training loss: 1.2153191326310546
Validation loss: 3.0788333323098445

Epoch: 5| Step: 2
Training loss: 0.43036587657670294
Validation loss: 3.0245167714080314

Epoch: 5| Step: 3
Training loss: 0.41118684898333047
Validation loss: 3.0584411907839635

Epoch: 5| Step: 4
Training loss: 0.4045506109597271
Validation loss: 2.9428633736247063

Epoch: 5| Step: 5
Training loss: 0.43033892063541623
Validation loss: 3.0690637302528927

Epoch: 5| Step: 6
Training loss: 0.5433709281170332
Validation loss: 2.9821766650728487

Epoch: 5| Step: 7
Training loss: 0.48387139812893853
Validation loss: 2.989289233842119

Epoch: 5| Step: 8
Training loss: 0.45680348516293834
Validation loss: 3.106038800587348

Epoch: 5| Step: 9
Training loss: 0.5264982155971593
Validation loss: 2.986484264868373

Epoch: 5| Step: 10
Training loss: 0.5236354567430059
Validation loss: 3.009964408473986

Epoch: 5| Step: 11
Training loss: 0.5383753335835256
Validation loss: 3.0287628588558952

Epoch: 370| Step: 0
Training loss: 1.2099838932005704
Validation loss: 3.01057729765506

Epoch: 5| Step: 1
Training loss: 0.5348233489264327
Validation loss: 3.034669484398715

Epoch: 5| Step: 2
Training loss: 0.4697656912576009
Validation loss: 3.05110343895752

Epoch: 5| Step: 3
Training loss: 0.37430412576874555
Validation loss: 3.0590165675435723

Epoch: 5| Step: 4
Training loss: 0.48070758992959006
Validation loss: 3.006826442246344

Epoch: 5| Step: 5
Training loss: 0.4116574019124412
Validation loss: 3.013143846291615

Epoch: 5| Step: 6
Training loss: 0.5517901385804962
Validation loss: 3.0720864656191726

Epoch: 5| Step: 7
Training loss: 0.4907427427821171
Validation loss: 3.0676143331757673

Epoch: 5| Step: 8
Training loss: 0.615071714182019
Validation loss: 2.9546965331462816

Epoch: 5| Step: 9
Training loss: 0.4501186148294696
Validation loss: 3.069439641786695

Epoch: 5| Step: 10
Training loss: 0.6666374994891134
Validation loss: 3.0734027262616035

Epoch: 5| Step: 11
Training loss: 0.6177915442023599
Validation loss: 3.118459386287802

Epoch: 371| Step: 0
Training loss: 0.5777214033361283
Validation loss: 2.9958042235324154

Epoch: 5| Step: 1
Training loss: 0.5310502798859276
Validation loss: 3.0403601679746055

Epoch: 5| Step: 2
Training loss: 0.6987508348313259
Validation loss: 3.0263937232663753

Epoch: 5| Step: 3
Training loss: 0.42971193070750563
Validation loss: 3.0549201193822197

Epoch: 5| Step: 4
Training loss: 1.24478458524895
Validation loss: 3.032783690546176

Epoch: 5| Step: 5
Training loss: 0.3829199192599414
Validation loss: 3.027857258222068

Epoch: 5| Step: 6
Training loss: 0.5965222339819075
Validation loss: 2.985846145219826

Epoch: 5| Step: 7
Training loss: 0.35495481962496417
Validation loss: 3.0636194609451968

Epoch: 5| Step: 8
Training loss: 0.5304612025761953
Validation loss: 3.1167642597653455

Epoch: 5| Step: 9
Training loss: 0.4776142427829933
Validation loss: 3.0956167664300622

Epoch: 5| Step: 10
Training loss: 0.4538597201268128
Validation loss: 3.0699665013752333

Epoch: 5| Step: 11
Training loss: 0.5448719945248429
Validation loss: 3.0062786600566875

Epoch: 372| Step: 0
Training loss: 0.4434738683538924
Validation loss: 3.0484622114213935

Epoch: 5| Step: 1
Training loss: 0.37188191287243094
Validation loss: 2.961155698011935

Epoch: 5| Step: 2
Training loss: 0.45907340302318633
Validation loss: 3.023226994325281

Epoch: 5| Step: 3
Training loss: 1.2805395715386652
Validation loss: 2.989544367563976

Epoch: 5| Step: 4
Training loss: 0.5613310111017434
Validation loss: 2.9764409912352487

Epoch: 5| Step: 5
Training loss: 0.6023607036416313
Validation loss: 3.0937494444926883

Epoch: 5| Step: 6
Training loss: 0.44173196573798973
Validation loss: 3.0198557993059514

Epoch: 5| Step: 7
Training loss: 0.46751806180915645
Validation loss: 2.9846261469700908

Epoch: 5| Step: 8
Training loss: 0.5530622877788104
Validation loss: 3.0827958512730738

Epoch: 5| Step: 9
Training loss: 0.5267904982222608
Validation loss: 2.999608938239734

Epoch: 5| Step: 10
Training loss: 0.42233637905992183
Validation loss: 2.9980441247718286

Epoch: 5| Step: 11
Training loss: 0.33558437728474744
Validation loss: 2.9824325737868502

Epoch: 373| Step: 0
Training loss: 0.3817172048805248
Validation loss: 3.070612283684605

Epoch: 5| Step: 1
Training loss: 0.4941508476798153
Validation loss: 3.055046372662608

Epoch: 5| Step: 2
Training loss: 0.39161539410067797
Validation loss: 2.988167062875721

Epoch: 5| Step: 3
Training loss: 0.3647459711894247
Validation loss: 3.1122814313651856

Epoch: 5| Step: 4
Training loss: 0.3981786897110039
Validation loss: 3.0375608315152203

Epoch: 5| Step: 5
Training loss: 0.5063126642980098
Validation loss: 3.0251981946158253

Epoch: 5| Step: 6
Training loss: 0.42370853406861547
Validation loss: 3.0067021454873295

Epoch: 5| Step: 7
Training loss: 1.2538012879550469
Validation loss: 2.9782272449406397

Epoch: 5| Step: 8
Training loss: 0.5838709947632029
Validation loss: 3.040392848447755

Epoch: 5| Step: 9
Training loss: 0.6489997402552128
Validation loss: 3.040149977936135

Epoch: 5| Step: 10
Training loss: 0.47611475062836994
Validation loss: 2.9976566056539715

Epoch: 5| Step: 11
Training loss: 0.5585103539588846
Validation loss: 3.037683473155711

Epoch: 374| Step: 0
Training loss: 0.35910341117729105
Validation loss: 2.972849204258779

Epoch: 5| Step: 1
Training loss: 1.2356831343100358
Validation loss: 2.9829962010248052

Epoch: 5| Step: 2
Training loss: 0.6901087682798503
Validation loss: 3.069526908355565

Epoch: 5| Step: 3
Training loss: 0.7607572698505902
Validation loss: 2.9921357720587496

Epoch: 5| Step: 4
Training loss: 0.2544684714496507
Validation loss: 2.943123288000525

Epoch: 5| Step: 5
Training loss: 0.6157030530527047
Validation loss: 3.106235187247026

Epoch: 5| Step: 6
Training loss: 0.6093212495231
Validation loss: 3.164185199006806

Epoch: 5| Step: 7
Training loss: 0.6173773123602652
Validation loss: 3.0998249968487017

Epoch: 5| Step: 8
Training loss: 0.4951194447121717
Validation loss: 3.109051746709337

Epoch: 5| Step: 9
Training loss: 0.47623552768474786
Validation loss: 3.039104137772835

Epoch: 5| Step: 10
Training loss: 0.4876889260102665
Validation loss: 2.984297579947796

Epoch: 5| Step: 11
Training loss: 0.48519452814773245
Validation loss: 2.923398163158898

Epoch: 375| Step: 0
Training loss: 0.5611535222194938
Validation loss: 3.024255636941709

Epoch: 5| Step: 1
Training loss: 0.4375958678250074
Validation loss: 2.9535608525036587

Epoch: 5| Step: 2
Training loss: 0.5880975707546398
Validation loss: 3.024648468226071

Epoch: 5| Step: 3
Training loss: 0.5711857107201027
Validation loss: 2.952199834724685

Epoch: 5| Step: 4
Training loss: 1.3412850415717534
Validation loss: 2.9904871060779548

Epoch: 5| Step: 5
Training loss: 0.5902514027954907
Validation loss: 2.9660057769388164

Epoch: 5| Step: 6
Training loss: 0.4344883187768328
Validation loss: 3.0741027041049533

Epoch: 5| Step: 7
Training loss: 0.41609409648839296
Validation loss: 3.0347001212911047

Epoch: 5| Step: 8
Training loss: 0.549937095079209
Validation loss: 3.0033508600890704

Epoch: 5| Step: 9
Training loss: 0.48117492697110653
Validation loss: 3.00967753663274

Epoch: 5| Step: 10
Training loss: 0.5239159120054995
Validation loss: 3.0624885039859833

Epoch: 5| Step: 11
Training loss: 0.5548831702032819
Validation loss: 3.0106424139225467

Epoch: 376| Step: 0
Training loss: 0.5329106685110981
Validation loss: 3.044117822818276

Epoch: 5| Step: 1
Training loss: 0.48645466762961376
Validation loss: 3.0346806831533395

Epoch: 5| Step: 2
Training loss: 1.195278740699099
Validation loss: 3.0126243677756044

Epoch: 5| Step: 3
Training loss: 0.39262640357290385
Validation loss: 3.014437634432108

Epoch: 5| Step: 4
Training loss: 0.3563221548860381
Validation loss: 2.9818401356379747

Epoch: 5| Step: 5
Training loss: 0.5510401286468483
Validation loss: 2.994296367432657

Epoch: 5| Step: 6
Training loss: 0.453844518616589
Validation loss: 3.0591997055473295

Epoch: 5| Step: 7
Training loss: 0.349564469506349
Validation loss: 3.0127695759709234

Epoch: 5| Step: 8
Training loss: 0.4672250738950217
Validation loss: 2.973872176267953

Epoch: 5| Step: 9
Training loss: 0.36622700973845723
Validation loss: 3.0771009352139043

Epoch: 5| Step: 10
Training loss: 0.5403014333815044
Validation loss: 3.055376649926845

Epoch: 5| Step: 11
Training loss: 0.3995321607523396
Validation loss: 3.05814393667136

Epoch: 377| Step: 0
Training loss: 1.2978940430083366
Validation loss: 3.058764565392493

Epoch: 5| Step: 1
Training loss: 0.34287638626207795
Validation loss: 3.0868665528012893

Epoch: 5| Step: 2
Training loss: 0.3510694118802042
Validation loss: 2.988563627311052

Epoch: 5| Step: 3
Training loss: 0.5198205988240334
Validation loss: 3.1145087502181537

Epoch: 5| Step: 4
Training loss: 0.5102886863426893
Validation loss: 2.9459046460862925

Epoch: 5| Step: 5
Training loss: 0.3372039653374664
Validation loss: 3.0888924080575553

Epoch: 5| Step: 6
Training loss: 0.44446788128345055
Validation loss: 3.0559195125929595

Epoch: 5| Step: 7
Training loss: 0.5773898683125497
Validation loss: 3.005576414753548

Epoch: 5| Step: 8
Training loss: 0.5067482874351587
Validation loss: 3.008977903692332

Epoch: 5| Step: 9
Training loss: 0.4526454591370166
Validation loss: 3.001364533387685

Epoch: 5| Step: 10
Training loss: 0.4461797167089405
Validation loss: 2.9614494371006614

Epoch: 5| Step: 11
Training loss: 0.31002283565952216
Validation loss: 2.9758336834483146

Epoch: 378| Step: 0
Training loss: 0.3560500788638886
Validation loss: 2.9320545857306652

Epoch: 5| Step: 1
Training loss: 0.41692231997791535
Validation loss: 2.9912561140676766

Epoch: 5| Step: 2
Training loss: 0.4269372139607129
Validation loss: 2.9826048582743674

Epoch: 5| Step: 3
Training loss: 0.4109015459932574
Validation loss: 3.066512084559989

Epoch: 5| Step: 4
Training loss: 0.4495616930643193
Validation loss: 3.016462180195361

Epoch: 5| Step: 5
Training loss: 0.4005536003582401
Validation loss: 3.0506561455533387

Epoch: 5| Step: 6
Training loss: 0.39408308957041893
Validation loss: 2.889281591343642

Epoch: 5| Step: 7
Training loss: 0.6351541826465553
Validation loss: 3.0041167801794657

Epoch: 5| Step: 8
Training loss: 1.3054210405289648
Validation loss: 2.987488778278126

Epoch: 5| Step: 9
Training loss: 0.5400730005123527
Validation loss: 2.898808495837576

Epoch: 5| Step: 10
Training loss: 0.4266097730774387
Validation loss: 2.9110374021288474

Epoch: 5| Step: 11
Training loss: 0.43079343137236054
Validation loss: 3.000878311437393

Epoch: 379| Step: 0
Training loss: 0.535042827309158
Validation loss: 3.0040709769096523

Epoch: 5| Step: 1
Training loss: 0.41026815068705713
Validation loss: 2.9771372823362947

Epoch: 5| Step: 2
Training loss: 0.45796327028669714
Validation loss: 2.994463699737367

Epoch: 5| Step: 3
Training loss: 0.6190063619795132
Validation loss: 2.9536781297609873

Epoch: 5| Step: 4
Training loss: 0.5936405683360847
Validation loss: 2.9364997702971474

Epoch: 5| Step: 5
Training loss: 1.2073250817235097
Validation loss: 2.9725321452651445

Epoch: 5| Step: 6
Training loss: 0.4424831285062086
Validation loss: 3.0314437240623624

Epoch: 5| Step: 7
Training loss: 0.47086163776133133
Validation loss: 3.041887305805476

Epoch: 5| Step: 8
Training loss: 0.4879855519436555
Validation loss: 2.9696564846432323

Epoch: 5| Step: 9
Training loss: 0.4275947586802639
Validation loss: 2.9519860932499427

Epoch: 5| Step: 10
Training loss: 0.531912726869634
Validation loss: 2.93673676186481

Epoch: 5| Step: 11
Training loss: 0.2508824836354139
Validation loss: 2.9834753514607755

Epoch: 380| Step: 0
Training loss: 0.3538793515726437
Validation loss: 2.977747216668834

Epoch: 5| Step: 1
Training loss: 0.3905925165021558
Validation loss: 3.0104383954030665

Epoch: 5| Step: 2
Training loss: 0.35287448005827143
Validation loss: 2.987025836201957

Epoch: 5| Step: 3
Training loss: 0.40900342691053776
Validation loss: 3.009270058079985

Epoch: 5| Step: 4
Training loss: 0.5449855862907559
Validation loss: 3.0542605167522283

Epoch: 5| Step: 5
Training loss: 0.5221732229749999
Validation loss: 3.052259955432941

Epoch: 5| Step: 6
Training loss: 0.5577217444953292
Validation loss: 3.103719715396221

Epoch: 5| Step: 7
Training loss: 0.5557332724860791
Validation loss: 2.992549517438817

Epoch: 5| Step: 8
Training loss: 1.1984712837162417
Validation loss: 3.0511444403123487

Epoch: 5| Step: 9
Training loss: 0.3277562203475343
Validation loss: 2.9801738088119816

Epoch: 5| Step: 10
Training loss: 0.34092933638018386
Validation loss: 3.054530296605879

Epoch: 5| Step: 11
Training loss: 0.26889604548010987
Validation loss: 3.003661057643277

Epoch: 381| Step: 0
Training loss: 0.3592996518300867
Validation loss: 2.966818857352223

Epoch: 5| Step: 1
Training loss: 0.44165590703501917
Validation loss: 3.0366070821630715

Epoch: 5| Step: 2
Training loss: 0.5958290342251419
Validation loss: 2.996283828959217

Epoch: 5| Step: 3
Training loss: 0.48565667308094046
Validation loss: 2.9924327925760017

Epoch: 5| Step: 4
Training loss: 0.3029283578869326
Validation loss: 3.010225333939066

Epoch: 5| Step: 5
Training loss: 1.3108784331517473
Validation loss: 3.022252904648176

Epoch: 5| Step: 6
Training loss: 0.4270794701595348
Validation loss: 3.027061199825797

Epoch: 5| Step: 7
Training loss: 0.3861387122113073
Validation loss: 3.034332484357664

Epoch: 5| Step: 8
Training loss: 0.5479615452980503
Validation loss: 2.999270396786976

Epoch: 5| Step: 9
Training loss: 0.5250818132050477
Validation loss: 2.941833985102669

Epoch: 5| Step: 10
Training loss: 0.4091773021692201
Validation loss: 3.090202574344682

Epoch: 5| Step: 11
Training loss: 0.42387811743878795
Validation loss: 3.0648303248552

Epoch: 382| Step: 0
Training loss: 0.33082246090313777
Validation loss: 3.019620583986445

Epoch: 5| Step: 1
Training loss: 1.2261974982203003
Validation loss: 2.978304562620935

Epoch: 5| Step: 2
Training loss: 0.41102118347156663
Validation loss: 2.9867226552309925

Epoch: 5| Step: 3
Training loss: 0.3143608597633576
Validation loss: 2.9875624845666002

Epoch: 5| Step: 4
Training loss: 0.5324033111224256
Validation loss: 3.0391127476791775

Epoch: 5| Step: 5
Training loss: 0.5488498181165804
Validation loss: 2.9514740394326435

Epoch: 5| Step: 6
Training loss: 0.40190207673452444
Validation loss: 3.006539971476338

Epoch: 5| Step: 7
Training loss: 0.6338028634424671
Validation loss: 2.9879259251458326

Epoch: 5| Step: 8
Training loss: 0.49896804293089475
Validation loss: 3.0296451606959507

Epoch: 5| Step: 9
Training loss: 0.3900228436822373
Validation loss: 2.959875857578748

Epoch: 5| Step: 10
Training loss: 0.6466594124867241
Validation loss: 2.984039833727673

Epoch: 5| Step: 11
Training loss: 0.21675987615271525
Validation loss: 3.040168979187649

Epoch: 383| Step: 0
Training loss: 0.4076349785527118
Validation loss: 2.968354600374679

Epoch: 5| Step: 1
Training loss: 0.5230944633914297
Validation loss: 3.0800789506709947

Epoch: 5| Step: 2
Training loss: 0.5757328753291245
Validation loss: 3.0670691873018368

Epoch: 5| Step: 3
Training loss: 0.43106786779485506
Validation loss: 3.094778538567685

Epoch: 5| Step: 4
Training loss: 0.5259818398727572
Validation loss: 3.007640645455714

Epoch: 5| Step: 5
Training loss: 0.44062805783448505
Validation loss: 3.0308791618686213

Epoch: 5| Step: 6
Training loss: 0.4320215124098637
Validation loss: 3.050435201676038

Epoch: 5| Step: 7
Training loss: 0.5558164149697369
Validation loss: 2.9745423477846713

Epoch: 5| Step: 8
Training loss: 0.4854557838832468
Validation loss: 2.9723817194769624

Epoch: 5| Step: 9
Training loss: 1.3838847685179612
Validation loss: 3.091875863687849

Epoch: 5| Step: 10
Training loss: 0.4611418642789954
Validation loss: 3.0422233220234567

Epoch: 5| Step: 11
Training loss: 0.2853710332411825
Validation loss: 3.0122900559910692

Epoch: 384| Step: 0
Training loss: 0.5446858322109267
Validation loss: 3.0140748396337926

Epoch: 5| Step: 1
Training loss: 0.3955986577947062
Validation loss: 2.936455395469175

Epoch: 5| Step: 2
Training loss: 0.29548577215745797
Validation loss: 2.9157087978410985

Epoch: 5| Step: 3
Training loss: 0.40509036421793654
Validation loss: 3.032186245611852

Epoch: 5| Step: 4
Training loss: 0.5961515396123239
Validation loss: 3.10132143763767

Epoch: 5| Step: 5
Training loss: 0.526372226556498
Validation loss: 2.939443405321174

Epoch: 5| Step: 6
Training loss: 0.41353627721059566
Validation loss: 3.020318294334741

Epoch: 5| Step: 7
Training loss: 0.5185300314693586
Validation loss: 3.030244040953605

Epoch: 5| Step: 8
Training loss: 0.5895816144704756
Validation loss: 2.978816106262562

Epoch: 5| Step: 9
Training loss: 0.4022298484979954
Validation loss: 3.0323431642711673

Epoch: 5| Step: 10
Training loss: 0.37499946355781333
Validation loss: 3.0762583919246893

Epoch: 5| Step: 11
Training loss: 2.5557886019700855
Validation loss: 2.973103125823662

Epoch: 385| Step: 0
Training loss: 0.2913714032648727
Validation loss: 3.0008341785157113

Epoch: 5| Step: 1
Training loss: 0.5798184619632817
Validation loss: 3.131472534881103

Epoch: 5| Step: 2
Training loss: 0.4130084819638545
Validation loss: 3.1321616444032285

Epoch: 5| Step: 3
Training loss: 0.4269180695293956
Validation loss: 3.0215239075316616

Epoch: 5| Step: 4
Training loss: 0.45738855072782353
Validation loss: 3.0578302897834266

Epoch: 5| Step: 5
Training loss: 0.5888570654965474
Validation loss: 3.0573125976071296

Epoch: 5| Step: 6
Training loss: 0.49586929289733606
Validation loss: 3.0270750390026895

Epoch: 5| Step: 7
Training loss: 1.155070141070332
Validation loss: 3.1080396331083175

Epoch: 5| Step: 8
Training loss: 0.41917352751671577
Validation loss: 3.072311818138755

Epoch: 5| Step: 9
Training loss: 0.5284742036025669
Validation loss: 3.040834225875488

Epoch: 5| Step: 10
Training loss: 0.44350740087456086
Validation loss: 2.9655517014347854

Epoch: 5| Step: 11
Training loss: 0.15658061692687683
Validation loss: 3.1297891032472873

Epoch: 386| Step: 0
Training loss: 0.4306502567076574
Validation loss: 3.0577582772784644

Epoch: 5| Step: 1
Training loss: 0.5748607135083269
Validation loss: 3.1607105034709853

Epoch: 5| Step: 2
Training loss: 0.4501476138450719
Validation loss: 3.0081798213579036

Epoch: 5| Step: 3
Training loss: 0.40901852804878325
Validation loss: 3.0400663383412967

Epoch: 5| Step: 4
Training loss: 0.4447987085390982
Validation loss: 2.9873166923202756

Epoch: 5| Step: 5
Training loss: 0.3887433892022215
Validation loss: 3.0713513196690814

Epoch: 5| Step: 6
Training loss: 0.5411570395177369
Validation loss: 3.0549167439717864

Epoch: 5| Step: 7
Training loss: 0.3094403327969408
Validation loss: 3.080348784867789

Epoch: 5| Step: 8
Training loss: 0.60269242225353
Validation loss: 2.9776263667830354

Epoch: 5| Step: 9
Training loss: 1.234557850489206
Validation loss: 3.0450707987054124

Epoch: 5| Step: 10
Training loss: 0.5522458239216571
Validation loss: 3.0519491834528387

Epoch: 5| Step: 11
Training loss: 0.5032159379554689
Validation loss: 3.185802512608934

Epoch: 387| Step: 0
Training loss: 0.30519636161074115
Validation loss: 3.0850143983464755

Epoch: 5| Step: 1
Training loss: 0.5166425778813403
Validation loss: 3.0372944046686032

Epoch: 5| Step: 2
Training loss: 0.34605291956695283
Validation loss: 2.984213633277331

Epoch: 5| Step: 3
Training loss: 0.5248762541208821
Validation loss: 2.9292702678701894

Epoch: 5| Step: 4
Training loss: 0.3045790308053975
Validation loss: 3.0788647493761183

Epoch: 5| Step: 5
Training loss: 1.2676131092292875
Validation loss: 2.9740358243467893

Epoch: 5| Step: 6
Training loss: 0.3499652819784823
Validation loss: 3.0363033717524

Epoch: 5| Step: 7
Training loss: 0.4042281677540977
Validation loss: 2.960913018064182

Epoch: 5| Step: 8
Training loss: 0.3985734034616059
Validation loss: 2.9433046001289727

Epoch: 5| Step: 9
Training loss: 0.7083696795469572
Validation loss: 3.031161421697466

Epoch: 5| Step: 10
Training loss: 0.5191017038696932
Validation loss: 2.9773177342715886

Epoch: 5| Step: 11
Training loss: 0.27489180061896856
Validation loss: 2.9457928091352636

Epoch: 388| Step: 0
Training loss: 0.4186777002634408
Validation loss: 3.090822742334649

Epoch: 5| Step: 1
Training loss: 0.4776499176853508
Validation loss: 2.9167510253196243

Epoch: 5| Step: 2
Training loss: 0.3611580525764463
Validation loss: 3.066935635688913

Epoch: 5| Step: 3
Training loss: 1.2595653759207028
Validation loss: 3.004626131216254

Epoch: 5| Step: 4
Training loss: 0.48403404910736053
Validation loss: 2.9912321592469215

Epoch: 5| Step: 5
Training loss: 0.36663882879584947
Validation loss: 2.999624235408903

Epoch: 5| Step: 6
Training loss: 0.5282248588822166
Validation loss: 2.972317272347019

Epoch: 5| Step: 7
Training loss: 0.41162958283455064
Validation loss: 3.0939631372623877

Epoch: 5| Step: 8
Training loss: 0.38381596827652126
Validation loss: 3.0305847948879046

Epoch: 5| Step: 9
Training loss: 0.5184237787271594
Validation loss: 2.960074846791657

Epoch: 5| Step: 10
Training loss: 0.5191005269359691
Validation loss: 2.921038635419566

Epoch: 5| Step: 11
Training loss: 0.5198261886579421
Validation loss: 3.00097761848283

Epoch: 389| Step: 0
Training loss: 0.41824294392595823
Validation loss: 2.9523512988983684

Epoch: 5| Step: 1
Training loss: 0.45144082182277734
Validation loss: 2.9485456359580686

Epoch: 5| Step: 2
Training loss: 0.4915639166499324
Validation loss: 3.053394964510936

Epoch: 5| Step: 3
Training loss: 0.46074871464496725
Validation loss: 2.975979001047837

Epoch: 5| Step: 4
Training loss: 0.4590153785136407
Validation loss: 2.9572904566410423

Epoch: 5| Step: 5
Training loss: 1.190750391807708
Validation loss: 3.0757358399426216

Epoch: 5| Step: 6
Training loss: 0.6113921305631973
Validation loss: 3.0432160603057516

Epoch: 5| Step: 7
Training loss: 0.47661412068938125
Validation loss: 3.073498216115602

Epoch: 5| Step: 8
Training loss: 0.5569278444504776
Validation loss: 3.051555781073009

Epoch: 5| Step: 9
Training loss: 0.42423011244701675
Validation loss: 2.9806053127002055

Epoch: 5| Step: 10
Training loss: 0.5588164519151165
Validation loss: 2.9312262702908622

Epoch: 5| Step: 11
Training loss: 0.5586271742844365
Validation loss: 3.003110805931778

Epoch: 390| Step: 0
Training loss: 0.40013015462384877
Validation loss: 2.934382658092945

Epoch: 5| Step: 1
Training loss: 0.5863782877751617
Validation loss: 2.95409052570898

Epoch: 5| Step: 2
Training loss: 0.3453070855902902
Validation loss: 3.035823282320646

Epoch: 5| Step: 3
Training loss: 0.39295709642001164
Validation loss: 3.0072475877171247

Epoch: 5| Step: 4
Training loss: 0.6694727022974688
Validation loss: 3.0793358120554895

Epoch: 5| Step: 5
Training loss: 0.5592853559556553
Validation loss: 2.991103813535602

Epoch: 5| Step: 6
Training loss: 0.5250472183791758
Validation loss: 3.1046857890492503

Epoch: 5| Step: 7
Training loss: 0.4516218014489543
Validation loss: 2.954819349618157

Epoch: 5| Step: 8
Training loss: 1.272622953743934
Validation loss: 2.9894518950718303

Epoch: 5| Step: 9
Training loss: 0.5863206754918995
Validation loss: 2.9828452005753667

Epoch: 5| Step: 10
Training loss: 0.5355644896522946
Validation loss: 3.0383768231586834

Epoch: 5| Step: 11
Training loss: 0.561668682387194
Validation loss: 3.0080537509359937

Epoch: 391| Step: 0
Training loss: 0.3101162834264818
Validation loss: 2.9749096263654478

Epoch: 5| Step: 1
Training loss: 0.5605032235936784
Validation loss: 3.173954033334889

Epoch: 5| Step: 2
Training loss: 0.5854857928867757
Validation loss: 3.0655114684630034

Epoch: 5| Step: 3
Training loss: 0.6785024199136915
Validation loss: 3.028839204649819

Epoch: 5| Step: 4
Training loss: 1.155660014800616
Validation loss: 2.9627474685515214

Epoch: 5| Step: 5
Training loss: 0.4093126613531
Validation loss: 3.0472688599684923

Epoch: 5| Step: 6
Training loss: 0.447853684617882
Validation loss: 2.9927326416283595

Epoch: 5| Step: 7
Training loss: 0.45536382654237634
Validation loss: 3.0317127818360623

Epoch: 5| Step: 8
Training loss: 0.42734661554634584
Validation loss: 3.001292294743505

Epoch: 5| Step: 9
Training loss: 0.4207824936772951
Validation loss: 3.0815377978593452

Epoch: 5| Step: 10
Training loss: 0.4004792650310601
Validation loss: 2.9889159415741013

Epoch: 5| Step: 11
Training loss: 0.38952929365062355
Validation loss: 2.9712725780540237

Epoch: 392| Step: 0
Training loss: 0.5927917125719137
Validation loss: 2.8801373317214938

Epoch: 5| Step: 1
Training loss: 0.36967985943390175
Validation loss: 3.0243996987408734

Epoch: 5| Step: 2
Training loss: 0.4562929825589485
Validation loss: 2.9471859222818844

Epoch: 5| Step: 3
Training loss: 1.1963790921958422
Validation loss: 3.066619668000927

Epoch: 5| Step: 4
Training loss: 0.28121514899174527
Validation loss: 2.966411707044834

Epoch: 5| Step: 5
Training loss: 0.4847949576283243
Validation loss: 3.036541407099251

Epoch: 5| Step: 6
Training loss: 0.39309817357557253
Validation loss: 2.993473347734204

Epoch: 5| Step: 7
Training loss: 0.5739652372476942
Validation loss: 2.9849419779226256

Epoch: 5| Step: 8
Training loss: 0.44825053155317557
Validation loss: 3.040208314505133

Epoch: 5| Step: 9
Training loss: 0.3972987375928735
Validation loss: 2.9950878538642423

Epoch: 5| Step: 10
Training loss: 0.49532160404635184
Validation loss: 3.038433536143903

Epoch: 5| Step: 11
Training loss: 0.546991199682393
Validation loss: 2.9821986506474585

Epoch: 393| Step: 0
Training loss: 0.5683978352855801
Validation loss: 2.9837961883869344

Epoch: 5| Step: 1
Training loss: 0.46120992788839343
Validation loss: 3.05136705506117

Epoch: 5| Step: 2
Training loss: 0.4607387857930092
Validation loss: 2.9805507523641275

Epoch: 5| Step: 3
Training loss: 0.3701952446831535
Validation loss: 2.9355343538999916

Epoch: 5| Step: 4
Training loss: 0.7598400716910265
Validation loss: 3.0993165372809277

Epoch: 5| Step: 5
Training loss: 0.4237975887425764
Validation loss: 2.978439600240055

Epoch: 5| Step: 6
Training loss: 1.2119503584474665
Validation loss: 2.9301996859953907

Epoch: 5| Step: 7
Training loss: 0.29138444404729286
Validation loss: 3.046735069126467

Epoch: 5| Step: 8
Training loss: 0.48085262501470044
Validation loss: 2.985920623992441

Epoch: 5| Step: 9
Training loss: 0.448087860999852
Validation loss: 2.9145500688833716

Epoch: 5| Step: 10
Training loss: 0.4981141736805697
Validation loss: 3.0667925354447427

Epoch: 5| Step: 11
Training loss: 0.1647476241442607
Validation loss: 2.928583108220198

Epoch: 394| Step: 0
Training loss: 0.519819308853826
Validation loss: 2.987655105315287

Epoch: 5| Step: 1
Training loss: 1.2431855900317186
Validation loss: 3.0152722483456906

Epoch: 5| Step: 2
Training loss: 0.38477135668518
Validation loss: 3.0097245253377247

Epoch: 5| Step: 3
Training loss: 0.38583000245863924
Validation loss: 2.95456527895601

Epoch: 5| Step: 4
Training loss: 0.44994625393130144
Validation loss: 2.9644078439781354

Epoch: 5| Step: 5
Training loss: 0.6029180636210714
Validation loss: 2.977058159116888

Epoch: 5| Step: 6
Training loss: 0.5329611092777155
Validation loss: 3.058428302315947

Epoch: 5| Step: 7
Training loss: 0.5985552689329721
Validation loss: 3.040055626712665

Epoch: 5| Step: 8
Training loss: 0.4081129677241697
Validation loss: 2.9560588008674307

Epoch: 5| Step: 9
Training loss: 0.5530089919426707
Validation loss: 2.8799740257405406

Epoch: 5| Step: 10
Training loss: 0.34980591518712756
Validation loss: 3.033677397504826

Epoch: 5| Step: 11
Training loss: 0.4962118413749222
Validation loss: 2.9459425221179796

Epoch: 395| Step: 0
Training loss: 0.29114347887992253
Validation loss: 3.048567922706723

Epoch: 5| Step: 1
Training loss: 0.5415370095181318
Validation loss: 2.9923664401393926

Epoch: 5| Step: 2
Training loss: 0.4076189670788934
Validation loss: 2.9471814358641812

Epoch: 5| Step: 3
Training loss: 0.4156925935205191
Validation loss: 3.0642633162537454

Epoch: 5| Step: 4
Training loss: 0.40239422675962555
Validation loss: 3.008866661265503

Epoch: 5| Step: 5
Training loss: 0.5211634988158863
Validation loss: 2.9909957856520903

Epoch: 5| Step: 6
Training loss: 0.4139497711468527
Validation loss: 3.0490461324899067

Epoch: 5| Step: 7
Training loss: 0.4913548738340953
Validation loss: 2.98628831948729

Epoch: 5| Step: 8
Training loss: 0.3978947327179153
Validation loss: 2.958335558572568

Epoch: 5| Step: 9
Training loss: 1.2621803502227178
Validation loss: 2.9851424710008065

Epoch: 5| Step: 10
Training loss: 0.39309961403784366
Validation loss: 2.8554077628981336

Epoch: 5| Step: 11
Training loss: 0.5074204325196611
Validation loss: 3.0307780321142186

Epoch: 396| Step: 0
Training loss: 0.4092433033292163
Validation loss: 2.843739673749459

Epoch: 5| Step: 1
Training loss: 0.3057971579264008
Validation loss: 2.9387746913018122

Epoch: 5| Step: 2
Training loss: 0.4694556646711622
Validation loss: 2.917009198420462

Epoch: 5| Step: 3
Training loss: 0.32720035881125403
Validation loss: 2.9165240162070374

Epoch: 5| Step: 4
Training loss: 0.49730849040094083
Validation loss: 2.970460960855937

Epoch: 5| Step: 5
Training loss: 0.47397256836805907
Validation loss: 2.9961703811653324

Epoch: 5| Step: 6
Training loss: 0.38965122919827383
Validation loss: 2.985650507324408

Epoch: 5| Step: 7
Training loss: 1.1533925601510917
Validation loss: 2.9299694247760724

Epoch: 5| Step: 8
Training loss: 0.5444043891497867
Validation loss: 2.9558345030893514

Epoch: 5| Step: 9
Training loss: 0.4623522303333037
Validation loss: 3.061207128608545

Epoch: 5| Step: 10
Training loss: 0.6566372364689743
Validation loss: 2.971418098655697

Epoch: 5| Step: 11
Training loss: 0.33384046744668466
Validation loss: 3.034568232163042

Epoch: 397| Step: 0
Training loss: 0.5744631500178706
Validation loss: 3.0264912904296533

Epoch: 5| Step: 1
Training loss: 0.33729529442268624
Validation loss: 2.9385301122987033

Epoch: 5| Step: 2
Training loss: 0.5147757038074036
Validation loss: 2.960750953078697

Epoch: 5| Step: 3
Training loss: 0.644044634605029
Validation loss: 3.033383686875637

Epoch: 5| Step: 4
Training loss: 0.561240534628254
Validation loss: 3.05104044302858

Epoch: 5| Step: 5
Training loss: 1.1496728493953843
Validation loss: 2.8230490506838857

Epoch: 5| Step: 6
Training loss: 0.47572006746726253
Validation loss: 3.0259398849799903

Epoch: 5| Step: 7
Training loss: 0.38511386351810334
Validation loss: 3.0323922472912685

Epoch: 5| Step: 8
Training loss: 0.6491559196761107
Validation loss: 2.9633086983947976

Epoch: 5| Step: 9
Training loss: 0.47413212520757797
Validation loss: 2.949401802630473

Epoch: 5| Step: 10
Training loss: 0.5880735499288205
Validation loss: 3.0130325005035337

Epoch: 5| Step: 11
Training loss: 0.38609284506197344
Validation loss: 3.0387999577288323

Epoch: 398| Step: 0
Training loss: 0.5767716212029289
Validation loss: 2.9769251845264577

Epoch: 5| Step: 1
Training loss: 0.29763296892327396
Validation loss: 2.9794382836271067

Epoch: 5| Step: 2
Training loss: 1.1638100369513766
Validation loss: 3.0001804840580357

Epoch: 5| Step: 3
Training loss: 0.45595779860075114
Validation loss: 2.940784444347641

Epoch: 5| Step: 4
Training loss: 0.34367884636442375
Validation loss: 3.017719842407977

Epoch: 5| Step: 5
Training loss: 0.39074983509423894
Validation loss: 3.031158000166046

Epoch: 5| Step: 6
Training loss: 0.27989309202857576
Validation loss: 3.049345941453991

Epoch: 5| Step: 7
Training loss: 0.522103188931996
Validation loss: 3.082306173139399

Epoch: 5| Step: 8
Training loss: 0.6558979770553597
Validation loss: 3.055707401900118

Epoch: 5| Step: 9
Training loss: 0.4952297045223739
Validation loss: 3.0114433601365183

Epoch: 5| Step: 10
Training loss: 0.34015465907301756
Validation loss: 3.0612059116732375

Epoch: 5| Step: 11
Training loss: 0.38496823470865155
Validation loss: 3.1535033086968345

Epoch: 399| Step: 0
Training loss: 1.1607577630168975
Validation loss: 3.062656246143979

Epoch: 5| Step: 1
Training loss: 0.3917187636641328
Validation loss: 3.0553648409906113

Epoch: 5| Step: 2
Training loss: 0.5177658892080962
Validation loss: 3.0253673804588486

Epoch: 5| Step: 3
Training loss: 0.3728035138015244
Validation loss: 3.0101623339723127

Epoch: 5| Step: 4
Training loss: 0.40920352183552916
Validation loss: 3.066368391123194

Epoch: 5| Step: 5
Training loss: 0.39578102000365745
Validation loss: 3.137360408610873

Epoch: 5| Step: 6
Training loss: 0.536707835523747
Validation loss: 3.0576014461983267

Epoch: 5| Step: 7
Training loss: 0.36360930940247893
Validation loss: 3.067984383451521

Epoch: 5| Step: 8
Training loss: 0.6139919269571553
Validation loss: 3.0653383310864086

Epoch: 5| Step: 9
Training loss: 0.49005517305944885
Validation loss: 2.98381440987416

Epoch: 5| Step: 10
Training loss: 0.43194174296354415
Validation loss: 3.036544129003087

Epoch: 5| Step: 11
Training loss: 0.5444994967819985
Validation loss: 3.0429686651201284

Epoch: 400| Step: 0
Training loss: 0.46970330892570494
Validation loss: 3.065411043753494

Epoch: 5| Step: 1
Training loss: 0.40701526310253067
Validation loss: 3.0498330193029246

Epoch: 5| Step: 2
Training loss: 0.35864284819196135
Validation loss: 2.9608016238745565

Epoch: 5| Step: 3
Training loss: 0.35862874211472734
Validation loss: 3.0897357180711045

Epoch: 5| Step: 4
Training loss: 0.40745724518106585
Validation loss: 2.9518020061508934

Epoch: 5| Step: 5
Training loss: 0.31615025560699606
Validation loss: 3.021289762457041

Epoch: 5| Step: 6
Training loss: 0.41684264599386306
Validation loss: 3.0816881112081007

Epoch: 5| Step: 7
Training loss: 0.3957088948287641
Validation loss: 3.085640077704132

Epoch: 5| Step: 8
Training loss: 0.2447325359446599
Validation loss: 3.034474823734194

Epoch: 5| Step: 9
Training loss: 1.163320727475865
Validation loss: 2.998581623843138

Epoch: 5| Step: 10
Training loss: 0.6991000794024471
Validation loss: 2.977042664240543

Epoch: 5| Step: 11
Training loss: 0.4694612193762766
Validation loss: 2.9560886931818455

Epoch: 401| Step: 0
Training loss: 0.4689305593512588
Validation loss: 3.075072244762094

Epoch: 5| Step: 1
Training loss: 0.4788231464860982
Validation loss: 3.0723462345827373

Epoch: 5| Step: 2
Training loss: 0.45489786531824233
Validation loss: 3.0013777728132087

Epoch: 5| Step: 3
Training loss: 0.46067676605276936
Validation loss: 3.049678630913032

Epoch: 5| Step: 4
Training loss: 1.1605921995492128
Validation loss: 2.971881753865031

Epoch: 5| Step: 5
Training loss: 0.4449306992885727
Validation loss: 3.149589100786293

Epoch: 5| Step: 6
Training loss: 0.5699240524323606
Validation loss: 2.9729739807599347

Epoch: 5| Step: 7
Training loss: 0.48251462345989665
Validation loss: 3.0583470790322

Epoch: 5| Step: 8
Training loss: 0.3761132524391992
Validation loss: 2.986152708641137

Epoch: 5| Step: 9
Training loss: 0.5381381360886391
Validation loss: 3.0489153298665532

Epoch: 5| Step: 10
Training loss: 0.33161289561957435
Validation loss: 3.1376220301976807

Epoch: 5| Step: 11
Training loss: 0.5265467519697445
Validation loss: 3.007135822092993

Epoch: 402| Step: 0
Training loss: 0.4615730171839129
Validation loss: 3.0792755390753834

Epoch: 5| Step: 1
Training loss: 0.46761888088983716
Validation loss: 3.0869891921751034

Epoch: 5| Step: 2
Training loss: 0.45767070996176346
Validation loss: 3.100193605606954

Epoch: 5| Step: 3
Training loss: 0.5289448204232622
Validation loss: 3.098773121575065

Epoch: 5| Step: 4
Training loss: 0.3707009495308557
Validation loss: 3.084162862555992

Epoch: 5| Step: 5
Training loss: 0.607427615417635
Validation loss: 3.0637915897905716

Epoch: 5| Step: 6
Training loss: 0.4219387500774369
Validation loss: 3.034796053126279

Epoch: 5| Step: 7
Training loss: 0.3552262034167413
Validation loss: 3.1512324735181076

Epoch: 5| Step: 8
Training loss: 0.33630638052266776
Validation loss: 3.075531720759377

Epoch: 5| Step: 9
Training loss: 0.6898159984912242
Validation loss: 3.03889509980518

Epoch: 5| Step: 10
Training loss: 1.1486776710628144
Validation loss: 3.0846718522583996

Epoch: 5| Step: 11
Training loss: 0.32697519298535815
Validation loss: 3.083932049504479

Epoch: 403| Step: 0
Training loss: 0.3782100770938206
Validation loss: 3.0807967007937003

Epoch: 5| Step: 1
Training loss: 0.3961376120755515
Validation loss: 3.003513662729802

Epoch: 5| Step: 2
Training loss: 0.4951740962020785
Validation loss: 2.9735417594812548

Epoch: 5| Step: 3
Training loss: 0.5335518391851056
Validation loss: 2.990132726083189

Epoch: 5| Step: 4
Training loss: 1.2566468423364079
Validation loss: 3.020784164993205

Epoch: 5| Step: 5
Training loss: 0.39446450603685934
Validation loss: 3.106199825452178

Epoch: 5| Step: 6
Training loss: 0.37652979190331026
Validation loss: 3.0403690814598296

Epoch: 5| Step: 7
Training loss: 0.6715514268845336
Validation loss: 3.0502436803706376

Epoch: 5| Step: 8
Training loss: 0.4306748230988973
Validation loss: 3.007474014920965

Epoch: 5| Step: 9
Training loss: 0.31507603333202433
Validation loss: 3.0722577870360523

Epoch: 5| Step: 10
Training loss: 0.37737375223055225
Validation loss: 3.059539901918319

Epoch: 5| Step: 11
Training loss: 0.5394376472169748
Validation loss: 2.9627472304881475

Epoch: 404| Step: 0
Training loss: 0.3949661313095465
Validation loss: 3.029903958532751

Epoch: 5| Step: 1
Training loss: 0.4124744118354572
Validation loss: 2.978364760950486

Epoch: 5| Step: 2
Training loss: 0.4324390742216362
Validation loss: 3.0102425308198235

Epoch: 5| Step: 3
Training loss: 0.517052754484962
Validation loss: 2.982460186605445

Epoch: 5| Step: 4
Training loss: 0.451829439348819
Validation loss: 2.946955420784598

Epoch: 5| Step: 5
Training loss: 0.465356960209289
Validation loss: 2.942273357055009

Epoch: 5| Step: 6
Training loss: 0.41636753868534143
Validation loss: 3.04563446548111

Epoch: 5| Step: 7
Training loss: 0.5109027150763487
Validation loss: 2.983874280642816

Epoch: 5| Step: 8
Training loss: 0.2979466771080215
Validation loss: 3.0411807264305892

Epoch: 5| Step: 9
Training loss: 0.3096010932902444
Validation loss: 2.9619831664504055

Epoch: 5| Step: 10
Training loss: 1.1660547297835753
Validation loss: 3.0071019509998784

Epoch: 5| Step: 11
Training loss: 0.7114760486487955
Validation loss: 2.9077255611825383

Epoch: 405| Step: 0
Training loss: 0.4380820013542068
Validation loss: 2.967293787065862

Epoch: 5| Step: 1
Training loss: 0.5199854306784262
Validation loss: 2.9794854791599685

Epoch: 5| Step: 2
Training loss: 0.43438342930141466
Validation loss: 3.056599161112621

Epoch: 5| Step: 3
Training loss: 0.6596259972740269
Validation loss: 3.021428682043732

Epoch: 5| Step: 4
Training loss: 0.5292322323447085
Validation loss: 3.0306717101425895

Epoch: 5| Step: 5
Training loss: 0.4640814677770821
Validation loss: 2.999009518563621

Epoch: 5| Step: 6
Training loss: 0.46907235823303506
Validation loss: 3.0529696975249165

Epoch: 5| Step: 7
Training loss: 0.7257707855817068
Validation loss: 3.0153179852442387

Epoch: 5| Step: 8
Training loss: 0.5362040988243978
Validation loss: 3.0525635036712284

Epoch: 5| Step: 9
Training loss: 0.6956932868240475
Validation loss: 2.949001752268078

Epoch: 5| Step: 10
Training loss: 0.3943734183786056
Validation loss: 2.9776123378166237

Epoch: 5| Step: 11
Training loss: 2.5812535579185814
Validation loss: 2.933206325232409

Epoch: 406| Step: 0
Training loss: 0.47587376213463844
Validation loss: 2.957168787550655

Epoch: 5| Step: 1
Training loss: 0.7615223166689142
Validation loss: 3.026865258908448

Epoch: 5| Step: 2
Training loss: 0.34882029132654563
Validation loss: 3.006901855010517

Epoch: 5| Step: 3
Training loss: 0.49082640504831687
Validation loss: 3.013333723372741

Epoch: 5| Step: 4
Training loss: 0.40665419351621634
Validation loss: 2.9661192631836224

Epoch: 5| Step: 5
Training loss: 0.5148053156351537
Validation loss: 3.0427991944698243

Epoch: 5| Step: 6
Training loss: 0.3378391336886581
Validation loss: 2.9763853165563603

Epoch: 5| Step: 7
Training loss: 0.4361199342472272
Validation loss: 2.9845250409874207

Epoch: 5| Step: 8
Training loss: 0.4635268559036394
Validation loss: 3.0579764732666264

Epoch: 5| Step: 9
Training loss: 0.5154309341051321
Validation loss: 3.1026706621618767

Epoch: 5| Step: 10
Training loss: 1.109610196823485
Validation loss: 2.9919331527986186

Epoch: 5| Step: 11
Training loss: 0.2848008436237388
Validation loss: 3.0366901856637707

Epoch: 407| Step: 0
Training loss: 0.5195872914770993
Validation loss: 2.9838003966847486

Epoch: 5| Step: 1
Training loss: 0.6446762384271489
Validation loss: 3.0594663516087044

Epoch: 5| Step: 2
Training loss: 0.638070246022172
Validation loss: 2.985002668061121

Epoch: 5| Step: 3
Training loss: 0.4798631340342438
Validation loss: 3.0322066498377467

Epoch: 5| Step: 4
Training loss: 0.5424208312125522
Validation loss: 3.0998691481230423

Epoch: 5| Step: 5
Training loss: 1.0847319353563953
Validation loss: 3.0432286998237665

Epoch: 5| Step: 6
Training loss: 0.7024532287951922
Validation loss: 3.13556137997222

Epoch: 5| Step: 7
Training loss: 0.8483639412987238
Validation loss: 3.011639496271351

Epoch: 5| Step: 8
Training loss: 0.531891547639333
Validation loss: 3.051583777589673

Epoch: 5| Step: 9
Training loss: 0.5128665311199211
Validation loss: 3.0006088294698157

Epoch: 5| Step: 10
Training loss: 0.5474325879718577
Validation loss: 3.091694499007918

Epoch: 5| Step: 11
Training loss: 0.224749720305395
Validation loss: 3.1211415630524786

Epoch: 408| Step: 0
Training loss: 1.1229674203381006
Validation loss: 3.0158897244178613

Epoch: 5| Step: 1
Training loss: 0.5814307782833226
Validation loss: 3.0548593256528607

Epoch: 5| Step: 2
Training loss: 0.4544510511692333
Validation loss: 3.0549179536568793

Epoch: 5| Step: 3
Training loss: 0.6444526855674426
Validation loss: 3.11650038996408

Epoch: 5| Step: 4
Training loss: 0.5436297996345958
Validation loss: 3.086494743157302

Epoch: 5| Step: 5
Training loss: 0.43586136279530635
Validation loss: 3.009030720449872

Epoch: 5| Step: 6
Training loss: 0.4524922392374585
Validation loss: 3.0989506066917882

Epoch: 5| Step: 7
Training loss: 0.5347142865746709
Validation loss: 3.1057761849868113

Epoch: 5| Step: 8
Training loss: 0.40007391708595513
Validation loss: 3.091904748162152

Epoch: 5| Step: 9
Training loss: 0.46671837182503784
Validation loss: 3.054209597798903

Epoch: 5| Step: 10
Training loss: 0.3298729478931959
Validation loss: 3.084779791018301

Epoch: 5| Step: 11
Training loss: 0.3508965224258701
Validation loss: 3.0533493831544467

Epoch: 409| Step: 0
Training loss: 0.4210376553515044
Validation loss: 3.050821431864497

Epoch: 5| Step: 1
Training loss: 0.45224185909495435
Validation loss: 3.0985353271974216

Epoch: 5| Step: 2
Training loss: 0.35903039249195245
Validation loss: 3.041110769623831

Epoch: 5| Step: 3
Training loss: 0.501525370093992
Validation loss: 3.0084506922485086

Epoch: 5| Step: 4
Training loss: 0.4553333598158304
Validation loss: 3.092378334734932

Epoch: 5| Step: 5
Training loss: 1.0932559396131867
Validation loss: 3.043429426744021

Epoch: 5| Step: 6
Training loss: 0.25666164968178173
Validation loss: 3.1112198843749463

Epoch: 5| Step: 7
Training loss: 0.5503777994539106
Validation loss: 3.1029493208549574

Epoch: 5| Step: 8
Training loss: 0.454723334457046
Validation loss: 3.072288553516527

Epoch: 5| Step: 9
Training loss: 0.3478614972777234
Validation loss: 3.076211931886187

Epoch: 5| Step: 10
Training loss: 0.3414551034363037
Validation loss: 3.013887656021647

Epoch: 5| Step: 11
Training loss: 0.7797036316450828
Validation loss: 3.0450306518778345

Epoch: 410| Step: 0
Training loss: 0.33522490396235816
Validation loss: 3.0966152832879095

Epoch: 5| Step: 1
Training loss: 0.4379026399405229
Validation loss: 3.1132537349185436

Epoch: 5| Step: 2
Training loss: 1.1049271190135592
Validation loss: 2.9849726027014682

Epoch: 5| Step: 3
Training loss: 0.5088804313053101
Validation loss: 3.0432830798372157

Epoch: 5| Step: 4
Training loss: 0.6764977245729555
Validation loss: 3.1176739968753053

Epoch: 5| Step: 5
Training loss: 0.4986974917045622
Validation loss: 3.123856573725425

Epoch: 5| Step: 6
Training loss: 0.33215439700590377
Validation loss: 2.9955819367114294

Epoch: 5| Step: 7
Training loss: 0.3552944468640016
Validation loss: 3.064335085117228

Epoch: 5| Step: 8
Training loss: 0.7479286996905934
Validation loss: 3.0133898428577237

Epoch: 5| Step: 9
Training loss: 0.5899990205837461
Validation loss: 3.159646023307765

Epoch: 5| Step: 10
Training loss: 0.520802541458357
Validation loss: 3.000239372637649

Epoch: 5| Step: 11
Training loss: 0.4357090464205508
Validation loss: 2.9930291249661285

Epoch: 411| Step: 0
Training loss: 1.2207950160726002
Validation loss: 3.0117116582500847

Epoch: 5| Step: 1
Training loss: 0.4072129867083816
Validation loss: 3.1172314595347146

Epoch: 5| Step: 2
Training loss: 0.6122964618136427
Validation loss: 3.06024269681149

Epoch: 5| Step: 3
Training loss: 0.5667129738436802
Validation loss: 3.098899332120628

Epoch: 5| Step: 4
Training loss: 0.5970228741000121
Validation loss: 3.025094356194977

Epoch: 5| Step: 5
Training loss: 0.6074987283151763
Validation loss: 3.006111473201638

Epoch: 5| Step: 6
Training loss: 0.27268819321258586
Validation loss: 2.954187407284032

Epoch: 5| Step: 7
Training loss: 0.5261572594372121
Validation loss: 3.0737280189397342

Epoch: 5| Step: 8
Training loss: 0.48568692508438166
Validation loss: 2.979649879152725

Epoch: 5| Step: 9
Training loss: 0.32643001871594574
Validation loss: 3.030620873437213

Epoch: 5| Step: 10
Training loss: 0.48049570023541044
Validation loss: 3.08661209652108

Epoch: 5| Step: 11
Training loss: 0.2523692487228568
Validation loss: 3.0167714576715716

Epoch: 412| Step: 0
Training loss: 0.4281983319706613
Validation loss: 3.045522510273981

Epoch: 5| Step: 1
Training loss: 0.5879949939637948
Validation loss: 2.9937859590795806

Epoch: 5| Step: 2
Training loss: 0.4370943641301005
Validation loss: 3.062220554188331

Epoch: 5| Step: 3
Training loss: 0.5911423743282626
Validation loss: 2.927598505173585

Epoch: 5| Step: 4
Training loss: 0.6102050117028051
Validation loss: 3.106003407771429

Epoch: 5| Step: 5
Training loss: 1.1029621187727585
Validation loss: 3.0429578722986674

Epoch: 5| Step: 6
Training loss: 0.5907739542278833
Validation loss: 3.0863254995318403

Epoch: 5| Step: 7
Training loss: 0.5425859103320562
Validation loss: 3.0567468431763842

Epoch: 5| Step: 8
Training loss: 0.6421340753093316
Validation loss: 3.0022449802415268

Epoch: 5| Step: 9
Training loss: 0.5381849028312365
Validation loss: 2.9141030568700232

Epoch: 5| Step: 10
Training loss: 0.4502239590548233
Validation loss: 3.0083113880008665

Epoch: 5| Step: 11
Training loss: 0.30948145460560406
Validation loss: 2.9703013198323736

Epoch: 413| Step: 0
Training loss: 0.6130669577809162
Validation loss: 2.9885674499555397

Epoch: 5| Step: 1
Training loss: 0.5694742705383143
Validation loss: 3.005014255720484

Epoch: 5| Step: 2
Training loss: 0.48656588031964154
Validation loss: 3.0775376742278078

Epoch: 5| Step: 3
Training loss: 0.3941454181058343
Validation loss: 3.0541123176325646

Epoch: 5| Step: 4
Training loss: 0.4835214323532407
Validation loss: 3.0077199451028354

Epoch: 5| Step: 5
Training loss: 1.124748731739205
Validation loss: 3.0175459381658456

Epoch: 5| Step: 6
Training loss: 0.7071852964062648
Validation loss: 3.044193786786069

Epoch: 5| Step: 7
Training loss: 0.4646443492297452
Validation loss: 3.0449931568858104

Epoch: 5| Step: 8
Training loss: 0.5909543224342858
Validation loss: 3.0067248471023853

Epoch: 5| Step: 9
Training loss: 0.640621208551864
Validation loss: 2.9942774698862147

Epoch: 5| Step: 10
Training loss: 0.46410134278160503
Validation loss: 2.9703954152309184

Epoch: 5| Step: 11
Training loss: 0.6655376878523663
Validation loss: 3.0414797804957483

Epoch: 414| Step: 0
Training loss: 0.4185493216123906
Validation loss: 2.9796040331747795

Epoch: 5| Step: 1
Training loss: 0.46355273379998024
Validation loss: 2.986949815192957

Epoch: 5| Step: 2
Training loss: 0.325690124995272
Validation loss: 3.0391204096254336

Epoch: 5| Step: 3
Training loss: 0.6272260363058029
Validation loss: 2.927362487532102

Epoch: 5| Step: 4
Training loss: 0.5211507465812857
Validation loss: 3.110598318711006

Epoch: 5| Step: 5
Training loss: 0.44370859315596933
Validation loss: 2.9912612749730254

Epoch: 5| Step: 6
Training loss: 0.3562735156613424
Validation loss: 3.035808373710848

Epoch: 5| Step: 7
Training loss: 0.3950999099189696
Validation loss: 3.007586393899121

Epoch: 5| Step: 8
Training loss: 1.1430956589492973
Validation loss: 2.9850760763198028

Epoch: 5| Step: 9
Training loss: 0.43756208660453294
Validation loss: 3.0725419974502515

Epoch: 5| Step: 10
Training loss: 0.3754179135822979
Validation loss: 2.9133645995507873

Epoch: 5| Step: 11
Training loss: 0.43873644563327663
Validation loss: 3.0388578658193177

Epoch: 415| Step: 0
Training loss: 0.4716364206882116
Validation loss: 3.025771658642774

Epoch: 5| Step: 1
Training loss: 1.1727637417682846
Validation loss: 3.0943336867403106

Epoch: 5| Step: 2
Training loss: 0.5413590866177502
Validation loss: 2.9910300583408347

Epoch: 5| Step: 3
Training loss: 0.5003143157068266
Validation loss: 3.1694089827548995

Epoch: 5| Step: 4
Training loss: 0.5214873467407133
Validation loss: 3.086050895828713

Epoch: 5| Step: 5
Training loss: 0.4747719819743567
Validation loss: 2.984072967877399

Epoch: 5| Step: 6
Training loss: 0.4714537843705871
Validation loss: 3.044873798179225

Epoch: 5| Step: 7
Training loss: 0.3576078087635771
Validation loss: 3.063092184227629

Epoch: 5| Step: 8
Training loss: 0.4896630076921312
Validation loss: 3.09796025795572

Epoch: 5| Step: 9
Training loss: 0.36229695520092875
Validation loss: 3.0236892332542022

Epoch: 5| Step: 10
Training loss: 0.38653818404030427
Validation loss: 3.0269710778996113

Epoch: 5| Step: 11
Training loss: 0.5065661761687623
Validation loss: 3.017701335148745

Epoch: 416| Step: 0
Training loss: 0.35177707481702286
Validation loss: 3.0843433560155953

Epoch: 5| Step: 1
Training loss: 0.4839017463452336
Validation loss: 3.0315714891766614

Epoch: 5| Step: 2
Training loss: 0.4981380154860897
Validation loss: 2.956305088392883

Epoch: 5| Step: 3
Training loss: 1.1021007548483397
Validation loss: 3.0967093644433876

Epoch: 5| Step: 4
Training loss: 0.38908054202732933
Validation loss: 3.149954800180567

Epoch: 5| Step: 5
Training loss: 0.4278900350970927
Validation loss: 3.022071897975174

Epoch: 5| Step: 6
Training loss: 0.5856411502365876
Validation loss: 3.060178230186579

Epoch: 5| Step: 7
Training loss: 0.3098215112866652
Validation loss: 3.0463103953153015

Epoch: 5| Step: 8
Training loss: 0.46091263914144714
Validation loss: 3.08550508584095

Epoch: 5| Step: 9
Training loss: 0.35922366563271874
Validation loss: 3.0771875583781294

Epoch: 5| Step: 10
Training loss: 0.49974928470940133
Validation loss: 3.1508894555186058

Epoch: 5| Step: 11
Training loss: 0.46583016503109054
Validation loss: 3.0111375669331437

Epoch: 417| Step: 0
Training loss: 0.6640536363795524
Validation loss: 3.0591017429927403

Epoch: 5| Step: 1
Training loss: 0.4691902636234089
Validation loss: 3.0562780553184044

Epoch: 5| Step: 2
Training loss: 0.38773284269234176
Validation loss: 3.046028978315133

Epoch: 5| Step: 3
Training loss: 0.3518325827866293
Validation loss: 3.0401386947636033

Epoch: 5| Step: 4
Training loss: 0.4014901671220985
Validation loss: 3.0052462145149463

Epoch: 5| Step: 5
Training loss: 0.6593583380596244
Validation loss: 3.0276333840574345

Epoch: 5| Step: 6
Training loss: 0.5832313607414151
Validation loss: 3.0239111195048727

Epoch: 5| Step: 7
Training loss: 1.1049736720612335
Validation loss: 3.0041923171776763

Epoch: 5| Step: 8
Training loss: 0.4209486008775475
Validation loss: 2.937595365883615

Epoch: 5| Step: 9
Training loss: 0.4866443969119852
Validation loss: 2.9786191961906487

Epoch: 5| Step: 10
Training loss: 0.5324736415356939
Validation loss: 3.012009593016836

Epoch: 5| Step: 11
Training loss: 0.5179307420229172
Validation loss: 3.0750854155971723

Epoch: 418| Step: 0
Training loss: 0.5535867541692377
Validation loss: 3.046249775438453

Epoch: 5| Step: 1
Training loss: 0.4794404260235034
Validation loss: 2.984871804659781

Epoch: 5| Step: 2
Training loss: 0.5118880537834879
Validation loss: 2.9787094603455997

Epoch: 5| Step: 3
Training loss: 0.42958733518249154
Validation loss: 2.914969411387406

Epoch: 5| Step: 4
Training loss: 0.5298944176015757
Validation loss: 3.001302687947619

Epoch: 5| Step: 5
Training loss: 0.5221861785287533
Validation loss: 2.9752851600647587

Epoch: 5| Step: 6
Training loss: 0.527956853429425
Validation loss: 3.029733721029838

Epoch: 5| Step: 7
Training loss: 0.4517523594125968
Validation loss: 2.9765485828304588

Epoch: 5| Step: 8
Training loss: 0.37074409877456066
Validation loss: 2.9566913209462116

Epoch: 5| Step: 9
Training loss: 0.3244624313684203
Validation loss: 3.033955277925969

Epoch: 5| Step: 10
Training loss: 1.1308813010611873
Validation loss: 2.951124997527209

Epoch: 5| Step: 11
Training loss: 0.67298336426805
Validation loss: 2.9609357352406684

Epoch: 419| Step: 0
Training loss: 1.1159244680378142
Validation loss: 2.9923527093468727

Epoch: 5| Step: 1
Training loss: 0.5210320729324851
Validation loss: 3.0180111801689495

Epoch: 5| Step: 2
Training loss: 0.4541482880866353
Validation loss: 3.0443706621172946

Epoch: 5| Step: 3
Training loss: 0.39383534157529265
Validation loss: 3.030392417329901

Epoch: 5| Step: 4
Training loss: 0.4719450147109054
Validation loss: 2.9633110986908133

Epoch: 5| Step: 5
Training loss: 0.49016178399154986
Validation loss: 2.954055047627938

Epoch: 5| Step: 6
Training loss: 0.5054787341492308
Validation loss: 2.9671283107356135

Epoch: 5| Step: 7
Training loss: 0.46796532758629916
Validation loss: 3.016803461779159

Epoch: 5| Step: 8
Training loss: 0.42336017071455045
Validation loss: 2.9452745720186115

Epoch: 5| Step: 9
Training loss: 0.5156078335765485
Validation loss: 3.067395504651251

Epoch: 5| Step: 10
Training loss: 0.7649986273934012
Validation loss: 2.947331984986097

Epoch: 5| Step: 11
Training loss: 0.3264134363430607
Validation loss: 2.965457964883791

Epoch: 420| Step: 0
Training loss: 0.7102643693425744
Validation loss: 3.028774948626119

Epoch: 5| Step: 1
Training loss: 0.5634783343150084
Validation loss: 2.9879911194622126

Epoch: 5| Step: 2
Training loss: 1.18939068509783
Validation loss: 2.9544510967186044

Epoch: 5| Step: 3
Training loss: 0.6372989515162758
Validation loss: 3.0403657421733383

Epoch: 5| Step: 4
Training loss: 0.6513018482385268
Validation loss: 3.0553849993894584

Epoch: 5| Step: 5
Training loss: 0.7032760034114165
Validation loss: 3.083022931085733

Epoch: 5| Step: 6
Training loss: 0.46327640858994396
Validation loss: 3.0583205346680753

Epoch: 5| Step: 7
Training loss: 0.5435093445803661
Validation loss: 2.963929864345353

Epoch: 5| Step: 8
Training loss: 0.48590233175699965
Validation loss: 2.990610940728114

Epoch: 5| Step: 9
Training loss: 0.5030815709959264
Validation loss: 2.955246830822723

Epoch: 5| Step: 10
Training loss: 0.4747645434501749
Validation loss: 2.945545194086925

Epoch: 5| Step: 11
Training loss: 0.9485885663205857
Validation loss: 3.001884471246425

Epoch: 421| Step: 0
Training loss: 0.5810945385001594
Validation loss: 2.9600692522801513

Epoch: 5| Step: 1
Training loss: 0.49884504798854595
Validation loss: 2.9537941546266984

Epoch: 5| Step: 2
Training loss: 1.1870412442337819
Validation loss: 3.1013315244520028

Epoch: 5| Step: 3
Training loss: 0.47178566573361297
Validation loss: 3.0208593345487724

Epoch: 5| Step: 4
Training loss: 0.6124245558226372
Validation loss: 3.078905306827814

Epoch: 5| Step: 5
Training loss: 0.518408774556778
Validation loss: 2.97561572712767

Epoch: 5| Step: 6
Training loss: 0.6185067960786702
Validation loss: 3.044606618035633

Epoch: 5| Step: 7
Training loss: 0.4233172101544882
Validation loss: 3.034200471205873

Epoch: 5| Step: 8
Training loss: 0.6707882631061
Validation loss: 3.023992094945835

Epoch: 5| Step: 9
Training loss: 0.45624990593896186
Validation loss: 2.8892600608659977

Epoch: 5| Step: 10
Training loss: 0.4039357733497034
Validation loss: 2.992653892562767

Epoch: 5| Step: 11
Training loss: 0.30344423316061775
Validation loss: 2.9617638051463224

Epoch: 422| Step: 0
Training loss: 0.479098498291468
Validation loss: 3.0655957878087174

Epoch: 5| Step: 1
Training loss: 0.5018246853739027
Validation loss: 2.9438446157952987

Epoch: 5| Step: 2
Training loss: 0.541687310876898
Validation loss: 2.9800395331544705

Epoch: 5| Step: 3
Training loss: 1.160060994254714
Validation loss: 2.9779575913280896

Epoch: 5| Step: 4
Training loss: 0.409731908816617
Validation loss: 3.1075840493495375

Epoch: 5| Step: 5
Training loss: 0.4074205627127678
Validation loss: 3.0641289939324716

Epoch: 5| Step: 6
Training loss: 0.4976760680655686
Validation loss: 3.054168780709056

Epoch: 5| Step: 7
Training loss: 0.44193300532829816
Validation loss: 3.0566042506904534

Epoch: 5| Step: 8
Training loss: 0.7173277009378886
Validation loss: 3.0773366735137646

Epoch: 5| Step: 9
Training loss: 0.37073579891425124
Validation loss: 3.0118956359295663

Epoch: 5| Step: 10
Training loss: 0.6810737591877267
Validation loss: 3.0594082036617793

Epoch: 5| Step: 11
Training loss: 0.5235402020718417
Validation loss: 2.987455798398045

Epoch: 423| Step: 0
Training loss: 0.5117963193384683
Validation loss: 3.0598248066335496

Epoch: 5| Step: 1
Training loss: 1.2129621745703683
Validation loss: 2.967672162400693

Epoch: 5| Step: 2
Training loss: 0.26583029723351953
Validation loss: 3.100198514668296

Epoch: 5| Step: 3
Training loss: 0.3371429108418752
Validation loss: 3.0131967350886426

Epoch: 5| Step: 4
Training loss: 0.4422201737642501
Validation loss: 2.9654046836029533

Epoch: 5| Step: 5
Training loss: 0.5865483215520685
Validation loss: 3.013428453036723

Epoch: 5| Step: 6
Training loss: 0.5182876330291112
Validation loss: 3.0729798369730466

Epoch: 5| Step: 7
Training loss: 0.5419144583286601
Validation loss: 3.0032078989887956

Epoch: 5| Step: 8
Training loss: 0.43218626514514924
Validation loss: 3.1005481114921194

Epoch: 5| Step: 9
Training loss: 0.6057858036904219
Validation loss: 3.0408100572383274

Epoch: 5| Step: 10
Training loss: 0.3863478143532691
Validation loss: 3.0575269037800914

Epoch: 5| Step: 11
Training loss: 0.3782415360186402
Validation loss: 2.9851045798560665

Epoch: 424| Step: 0
Training loss: 0.3579316802793151
Validation loss: 2.9890920366049936

Epoch: 5| Step: 1
Training loss: 0.44600516540375795
Validation loss: 2.9695177624737465

Epoch: 5| Step: 2
Training loss: 1.1017267632264027
Validation loss: 2.9915587758202773

Epoch: 5| Step: 3
Training loss: 0.3000761412316864
Validation loss: 3.0533365935737855

Epoch: 5| Step: 4
Training loss: 0.49943937223329615
Validation loss: 3.0578569261185464

Epoch: 5| Step: 5
Training loss: 0.6019662270181434
Validation loss: 3.069490340456936

Epoch: 5| Step: 6
Training loss: 0.5178533434141241
Validation loss: 2.955187751600639

Epoch: 5| Step: 7
Training loss: 0.46580615711896844
Validation loss: 3.028302663886785

Epoch: 5| Step: 8
Training loss: 0.5267014158933493
Validation loss: 2.9891090027853755

Epoch: 5| Step: 9
Training loss: 0.33597717494440865
Validation loss: 2.9986784395067643

Epoch: 5| Step: 10
Training loss: 0.38859540100728596
Validation loss: 3.041801627095682

Epoch: 5| Step: 11
Training loss: 0.26356105594904294
Validation loss: 3.0324930316596546

Epoch: 425| Step: 0
Training loss: 0.5520463847146042
Validation loss: 3.02408797883794

Epoch: 5| Step: 1
Training loss: 0.5356181858924611
Validation loss: 3.004975580406091

Epoch: 5| Step: 2
Training loss: 0.6178299421241881
Validation loss: 3.104640080794255

Epoch: 5| Step: 3
Training loss: 1.1182726411699961
Validation loss: 3.0244345355836986

Epoch: 5| Step: 4
Training loss: 0.5279409629642268
Validation loss: 3.008083681374567

Epoch: 5| Step: 5
Training loss: 0.6287406087215717
Validation loss: 3.0773969973802644

Epoch: 5| Step: 6
Training loss: 0.5035531041155423
Validation loss: 3.008787655977083

Epoch: 5| Step: 7
Training loss: 0.5881969882960622
Validation loss: 3.0572722508573764

Epoch: 5| Step: 8
Training loss: 0.46901326733756654
Validation loss: 3.0515780676232875

Epoch: 5| Step: 9
Training loss: 0.40689801838069556
Validation loss: 3.051175605271224

Epoch: 5| Step: 10
Training loss: 0.3553995127896762
Validation loss: 2.9363076786521796

Epoch: 5| Step: 11
Training loss: 0.3934358744023367
Validation loss: 3.02485166624741

Epoch: 426| Step: 0
Training loss: 0.6723621066435704
Validation loss: 2.996858770189303

Epoch: 5| Step: 1
Training loss: 0.5595553464369416
Validation loss: 3.030024939676763

Epoch: 5| Step: 2
Training loss: 0.3216142718767931
Validation loss: 3.0017368467903793

Epoch: 5| Step: 3
Training loss: 0.5200148891188049
Validation loss: 3.0112656327915066

Epoch: 5| Step: 4
Training loss: 0.4753807768981018
Validation loss: 3.00689097568135

Epoch: 5| Step: 5
Training loss: 0.49689425065277937
Validation loss: 3.0087053369224375

Epoch: 5| Step: 6
Training loss: 1.183238917376443
Validation loss: 2.9963709252508424

Epoch: 5| Step: 7
Training loss: 0.4111161398508478
Validation loss: 3.0813149674267986

Epoch: 5| Step: 8
Training loss: 0.6480385805671866
Validation loss: 2.982744607074481

Epoch: 5| Step: 9
Training loss: 0.453930155900962
Validation loss: 3.0321934663908556

Epoch: 5| Step: 10
Training loss: 0.6100324361025642
Validation loss: 2.9580212325468316

Epoch: 5| Step: 11
Training loss: 0.40771316253863704
Validation loss: 2.993574971157508

Epoch: 427| Step: 0
Training loss: 0.5699412300112466
Validation loss: 2.9580971943719607

Epoch: 5| Step: 1
Training loss: 0.4741321880641507
Validation loss: 2.9611736092752206

Epoch: 5| Step: 2
Training loss: 0.4643785729662291
Validation loss: 2.9398734331892236

Epoch: 5| Step: 3
Training loss: 0.4188851266591387
Validation loss: 3.0068804266920366

Epoch: 5| Step: 4
Training loss: 0.552363402625369
Validation loss: 3.0376033172775423

Epoch: 5| Step: 5
Training loss: 0.5998389832689064
Validation loss: 3.032425701586604

Epoch: 5| Step: 6
Training loss: 0.25161888071247857
Validation loss: 2.962277296336241

Epoch: 5| Step: 7
Training loss: 0.35726362383407345
Validation loss: 3.0698317328510214

Epoch: 5| Step: 8
Training loss: 1.1021481303232006
Validation loss: 2.965818232440439

Epoch: 5| Step: 9
Training loss: 0.42553458812183387
Validation loss: 3.030922639349348

Epoch: 5| Step: 10
Training loss: 0.4013023416896668
Validation loss: 2.9750217144438125

Epoch: 5| Step: 11
Training loss: 0.35717750491945166
Validation loss: 3.003053095072851

Epoch: 428| Step: 0
Training loss: 0.4188857491928849
Validation loss: 3.0791710755897794

Epoch: 5| Step: 1
Training loss: 0.39458485985044056
Validation loss: 3.011122466818037

Epoch: 5| Step: 2
Training loss: 0.39668836185018513
Validation loss: 3.102854855813378

Epoch: 5| Step: 3
Training loss: 0.4240881653892277
Validation loss: 3.037466376972786

Epoch: 5| Step: 4
Training loss: 1.0120513251561731
Validation loss: 3.0421759176923624

Epoch: 5| Step: 5
Training loss: 0.34283554297020874
Validation loss: 3.0076214287910026

Epoch: 5| Step: 6
Training loss: 0.6223874324300784
Validation loss: 3.0120307968510547

Epoch: 5| Step: 7
Training loss: 0.5282249435118573
Validation loss: 3.0636508978383676

Epoch: 5| Step: 8
Training loss: 0.379813102072621
Validation loss: 3.0251577216664085

Epoch: 5| Step: 9
Training loss: 0.48776701742642475
Validation loss: 3.0816679282277812

Epoch: 5| Step: 10
Training loss: 0.4728418726599873
Validation loss: 3.044918194879311

Epoch: 5| Step: 11
Training loss: 0.33433059682768895
Validation loss: 3.0529377927101695

Epoch: 429| Step: 0
Training loss: 0.619336455268848
Validation loss: 2.947363897108906

Epoch: 5| Step: 1
Training loss: 0.5421932363069266
Validation loss: 2.980512552868568

Epoch: 5| Step: 2
Training loss: 0.3823381911022934
Validation loss: 2.9576911777791373

Epoch: 5| Step: 3
Training loss: 0.26008938568754614
Validation loss: 3.10762241626733

Epoch: 5| Step: 4
Training loss: 0.5006920971714729
Validation loss: 2.9900085709469195

Epoch: 5| Step: 5
Training loss: 0.5628476128435306
Validation loss: 2.989842118993028

Epoch: 5| Step: 6
Training loss: 0.44277759645963016
Validation loss: 3.029860381187203

Epoch: 5| Step: 7
Training loss: 0.378498979326482
Validation loss: 2.957609629873823

Epoch: 5| Step: 8
Training loss: 1.1314808351829706
Validation loss: 3.0161540171905736

Epoch: 5| Step: 9
Training loss: 0.4308788257126914
Validation loss: 3.03240145938043

Epoch: 5| Step: 10
Training loss: 0.4522973262439213
Validation loss: 2.9424265408698176

Epoch: 5| Step: 11
Training loss: 0.3699834979733326
Validation loss: 2.9667034691142335

Epoch: 430| Step: 0
Training loss: 0.43144819017782887
Validation loss: 3.04954801503989

Epoch: 5| Step: 1
Training loss: 0.36833977996066686
Validation loss: 2.947871946977398

Epoch: 5| Step: 2
Training loss: 0.38364885404448706
Validation loss: 3.063266379292643

Epoch: 5| Step: 3
Training loss: 0.399530780778534
Validation loss: 2.9821053207668515

Epoch: 5| Step: 4
Training loss: 1.0852845239040418
Validation loss: 2.9606107197640545

Epoch: 5| Step: 5
Training loss: 0.3546387550703705
Validation loss: 3.0945937743207064

Epoch: 5| Step: 6
Training loss: 0.42439450158773884
Validation loss: 3.04445692276244

Epoch: 5| Step: 7
Training loss: 0.5169936136500595
Validation loss: 3.058467185177581

Epoch: 5| Step: 8
Training loss: 0.3997987233338098
Validation loss: 2.890442198050868

Epoch: 5| Step: 9
Training loss: 0.5160466117709217
Validation loss: 3.022057342287797

Epoch: 5| Step: 10
Training loss: 0.4146022517553957
Validation loss: 2.99835822428164

Epoch: 5| Step: 11
Training loss: 0.47979037147884934
Validation loss: 2.897604004186733

Epoch: 431| Step: 0
Training loss: 0.9991740153352381
Validation loss: 2.990055430195123

Epoch: 5| Step: 1
Training loss: 0.5476107688662065
Validation loss: 3.022453785499077

Epoch: 5| Step: 2
Training loss: 0.39663077221411236
Validation loss: 3.006620628393193

Epoch: 5| Step: 3
Training loss: 0.4547018533912187
Validation loss: 2.9837032281048788

Epoch: 5| Step: 4
Training loss: 0.582706546101053
Validation loss: 3.049912280504536

Epoch: 5| Step: 5
Training loss: 0.5268959121807614
Validation loss: 3.0864940736941247

Epoch: 5| Step: 6
Training loss: 0.43234366559964243
Validation loss: 3.043907004555811

Epoch: 5| Step: 7
Training loss: 0.39676342619837734
Validation loss: 2.9579071870759313

Epoch: 5| Step: 8
Training loss: 0.4462643372345597
Validation loss: 2.9990556343161408

Epoch: 5| Step: 9
Training loss: 0.5353296374925388
Validation loss: 3.1088876837578177

Epoch: 5| Step: 10
Training loss: 0.47371526570677275
Validation loss: 3.079076594057809

Epoch: 5| Step: 11
Training loss: 0.4230986615411572
Validation loss: 3.0018678056137094

Epoch: 432| Step: 0
Training loss: 0.4472991231176308
Validation loss: 3.0602152388503847

Epoch: 5| Step: 1
Training loss: 0.3261639599782017
Validation loss: 3.0596336782716045

Epoch: 5| Step: 2
Training loss: 0.5951845006429545
Validation loss: 3.0631037104075056

Epoch: 5| Step: 3
Training loss: 0.3785176594997407
Validation loss: 3.046729653306979

Epoch: 5| Step: 4
Training loss: 0.6424339155803568
Validation loss: 2.9913273563576803

Epoch: 5| Step: 5
Training loss: 1.1287581930781996
Validation loss: 2.98702726627502

Epoch: 5| Step: 6
Training loss: 0.5763160913014418
Validation loss: 3.0066863788158034

Epoch: 5| Step: 7
Training loss: 0.6098897178423655
Validation loss: 3.09478644307784

Epoch: 5| Step: 8
Training loss: 0.5401098608478887
Validation loss: 3.00131917136314

Epoch: 5| Step: 9
Training loss: 0.40665593407036094
Validation loss: 3.062797252994747

Epoch: 5| Step: 10
Training loss: 0.42354931428381176
Validation loss: 3.007166719676363

Epoch: 5| Step: 11
Training loss: 0.2508902197128551
Validation loss: 2.969527520874326

Epoch: 433| Step: 0
Training loss: 0.5435988248942897
Validation loss: 3.0357575608489467

Epoch: 5| Step: 1
Training loss: 0.5338288712129942
Validation loss: 3.0095272510290014

Epoch: 5| Step: 2
Training loss: 1.1981381695281785
Validation loss: 2.936801573733945

Epoch: 5| Step: 3
Training loss: 0.3990584378196306
Validation loss: 3.003031358109062

Epoch: 5| Step: 4
Training loss: 0.4751413605554566
Validation loss: 2.922229167396534

Epoch: 5| Step: 5
Training loss: 0.4762677391132727
Validation loss: 3.011888772178732

Epoch: 5| Step: 6
Training loss: 0.5008572739429286
Validation loss: 2.946589623903343

Epoch: 5| Step: 7
Training loss: 0.5302678734924771
Validation loss: 2.9965418514089674

Epoch: 5| Step: 8
Training loss: 0.3563094833974339
Validation loss: 3.0544163517721836

Epoch: 5| Step: 9
Training loss: 0.4949494929989203
Validation loss: 3.031838666315089

Epoch: 5| Step: 10
Training loss: 0.27675637653330964
Validation loss: 2.995756083015519

Epoch: 5| Step: 11
Training loss: 0.747362306664745
Validation loss: 3.0351452166513466

Epoch: 434| Step: 0
Training loss: 0.3941115233430791
Validation loss: 3.007612755158223

Epoch: 5| Step: 1
Training loss: 0.41708349796041666
Validation loss: 2.9885221330215512

Epoch: 5| Step: 2
Training loss: 0.4856048168863364
Validation loss: 3.0970970120421524

Epoch: 5| Step: 3
Training loss: 0.4136346369796865
Validation loss: 2.9343830440304

Epoch: 5| Step: 4
Training loss: 0.3557750932900432
Validation loss: 3.0592016961352217

Epoch: 5| Step: 5
Training loss: 0.4746661054198469
Validation loss: 3.0601885467557217

Epoch: 5| Step: 6
Training loss: 0.6217845937295121
Validation loss: 3.0431160391279124

Epoch: 5| Step: 7
Training loss: 1.084647420913682
Validation loss: 2.9883696266685864

Epoch: 5| Step: 8
Training loss: 0.41526666122762523
Validation loss: 2.9862742746611217

Epoch: 5| Step: 9
Training loss: 0.418038852552652
Validation loss: 2.9627656451365767

Epoch: 5| Step: 10
Training loss: 0.5804115133702575
Validation loss: 2.9691939206085483

Epoch: 5| Step: 11
Training loss: 0.6579647594757567
Validation loss: 3.061564425853676

Epoch: 435| Step: 0
Training loss: 0.28079889466001584
Validation loss: 3.003195173731784

Epoch: 5| Step: 1
Training loss: 0.4696758345971916
Validation loss: 3.006465887855391

Epoch: 5| Step: 2
Training loss: 1.0978519360294463
Validation loss: 3.072945692711938

Epoch: 5| Step: 3
Training loss: 0.5523636454191903
Validation loss: 3.0360639958411375

Epoch: 5| Step: 4
Training loss: 0.5272894937366741
Validation loss: 3.0486618182359044

Epoch: 5| Step: 5
Training loss: 0.5866150816496142
Validation loss: 2.9709640361600846

Epoch: 5| Step: 6
Training loss: 0.676749115154532
Validation loss: 2.9808853211604864

Epoch: 5| Step: 7
Training loss: 0.3869671649877296
Validation loss: 3.0584802001558353

Epoch: 5| Step: 8
Training loss: 0.6050532237987853
Validation loss: 2.98923466916593

Epoch: 5| Step: 9
Training loss: 0.5296131329389747
Validation loss: 3.080648946268507

Epoch: 5| Step: 10
Training loss: 0.4077244009393984
Validation loss: 3.0692287243881986

Epoch: 5| Step: 11
Training loss: 0.18500346870005752
Validation loss: 2.998796281127486

Epoch: 436| Step: 0
Training loss: 0.35928864063400007
Validation loss: 2.9406430595564985

Epoch: 5| Step: 1
Training loss: 0.3558253710650287
Validation loss: 3.0108293241697117

Epoch: 5| Step: 2
Training loss: 0.6820988030641683
Validation loss: 3.065548443526948

Epoch: 5| Step: 3
Training loss: 0.4363203152168508
Validation loss: 3.073720753527885

Epoch: 5| Step: 4
Training loss: 0.6052682359982162
Validation loss: 3.015973662280588

Epoch: 5| Step: 5
Training loss: 1.1068353731373737
Validation loss: 3.057482206049014

Epoch: 5| Step: 6
Training loss: 0.36038807422951685
Validation loss: 3.0783480968407027

Epoch: 5| Step: 7
Training loss: 0.4574155088742342
Validation loss: 2.9667208111211822

Epoch: 5| Step: 8
Training loss: 0.43212961315377385
Validation loss: 3.092073580388048

Epoch: 5| Step: 9
Training loss: 0.46826787632303596
Validation loss: 3.062318692711685

Epoch: 5| Step: 10
Training loss: 0.40367426823371155
Validation loss: 3.0234702943901097

Epoch: 5| Step: 11
Training loss: 0.32740156714653307
Validation loss: 3.0983960173102014

Epoch: 437| Step: 0
Training loss: 0.33073288121978467
Validation loss: 3.0039944150079516

Epoch: 5| Step: 1
Training loss: 0.4505809861379484
Validation loss: 3.085935768094764

Epoch: 5| Step: 2
Training loss: 0.39143147187431265
Validation loss: 2.988847340671608

Epoch: 5| Step: 3
Training loss: 0.48149743097873693
Validation loss: 3.0499201596081633

Epoch: 5| Step: 4
Training loss: 0.37208767347307103
Validation loss: 3.0391884837314542

Epoch: 5| Step: 5
Training loss: 0.4583246725159985
Validation loss: 3.0340295219770477

Epoch: 5| Step: 6
Training loss: 0.4053140826698056
Validation loss: 3.0455895866904408

Epoch: 5| Step: 7
Training loss: 0.5505519687313556
Validation loss: 2.915458965037377

Epoch: 5| Step: 8
Training loss: 0.4561067506532297
Validation loss: 2.9955260341136754

Epoch: 5| Step: 9
Training loss: 1.0960316429025452
Validation loss: 3.0326520390933127

Epoch: 5| Step: 10
Training loss: 0.46254818961680205
Validation loss: 3.010373571718799

Epoch: 5| Step: 11
Training loss: 0.6296918949324057
Validation loss: 3.037495788655024

Epoch: 438| Step: 0
Training loss: 0.5364057058303255
Validation loss: 3.001178063114792

Epoch: 5| Step: 1
Training loss: 0.316824436517511
Validation loss: 2.9582300263263037

Epoch: 5| Step: 2
Training loss: 1.182037286938406
Validation loss: 2.9578923324287576

Epoch: 5| Step: 3
Training loss: 0.5055476520634342
Validation loss: 3.010740626810391

Epoch: 5| Step: 4
Training loss: 0.4191553794062865
Validation loss: 3.0080106859845888

Epoch: 5| Step: 5
Training loss: 0.3444269839962102
Validation loss: 2.9569304166438886

Epoch: 5| Step: 6
Training loss: 0.4729065035541601
Validation loss: 3.0506742477375592

Epoch: 5| Step: 7
Training loss: 0.5548814246520505
Validation loss: 3.054703975024922

Epoch: 5| Step: 8
Training loss: 0.4552866412997026
Validation loss: 3.045849736835302

Epoch: 5| Step: 9
Training loss: 0.3779851986040849
Validation loss: 2.958473660046696

Epoch: 5| Step: 10
Training loss: 0.43941341644600435
Validation loss: 2.9989185702059697

Epoch: 5| Step: 11
Training loss: 0.44372365497237176
Validation loss: 3.0284137598648355

Epoch: 439| Step: 0
Training loss: 0.39794463172562444
Validation loss: 3.047385882070868

Epoch: 5| Step: 1
Training loss: 0.5209347975763204
Validation loss: 3.0091016591134436

Epoch: 5| Step: 2
Training loss: 0.4747187955332851
Validation loss: 3.0702303874624586

Epoch: 5| Step: 3
Training loss: 0.42042070080939137
Validation loss: 3.002277880384567

Epoch: 5| Step: 4
Training loss: 1.0399322311622792
Validation loss: 3.0056771563349427

Epoch: 5| Step: 5
Training loss: 0.48858967005017706
Validation loss: 3.02422156012288

Epoch: 5| Step: 6
Training loss: 0.2677410632039169
Validation loss: 2.9646791019550616

Epoch: 5| Step: 7
Training loss: 0.3760832994227046
Validation loss: 3.0048220048416834

Epoch: 5| Step: 8
Training loss: 0.6030893394324355
Validation loss: 3.0411116418072246

Epoch: 5| Step: 9
Training loss: 0.3480904578633634
Validation loss: 3.049899385309209

Epoch: 5| Step: 10
Training loss: 0.3901123115629791
Validation loss: 2.995521089484157

Epoch: 5| Step: 11
Training loss: 0.6091633942807969
Validation loss: 2.9964236128024653

Epoch: 440| Step: 0
Training loss: 0.4933238157866393
Validation loss: 2.9750070187141264

Epoch: 5| Step: 1
Training loss: 0.48418271955161646
Validation loss: 2.9281399280353484

Epoch: 5| Step: 2
Training loss: 0.5300120065786609
Validation loss: 3.0450613297000437

Epoch: 5| Step: 3
Training loss: 0.33745804146160846
Validation loss: 3.0795369339020673

Epoch: 5| Step: 4
Training loss: 0.42769948390285595
Validation loss: 3.0639390905344075

Epoch: 5| Step: 5
Training loss: 0.3835176862520242
Validation loss: 3.0509082378638377

Epoch: 5| Step: 6
Training loss: 0.3619172525857154
Validation loss: 3.0407984759565787

Epoch: 5| Step: 7
Training loss: 0.6075843029632735
Validation loss: 2.9883502561625837

Epoch: 5| Step: 8
Training loss: 0.2885611542456967
Validation loss: 3.049204589487684

Epoch: 5| Step: 9
Training loss: 1.2282649089142097
Validation loss: 2.936256784777965

Epoch: 5| Step: 10
Training loss: 0.5141806168212004
Validation loss: 3.00565851212564

Epoch: 5| Step: 11
Training loss: 0.2843246090436747
Validation loss: 3.0322578498180364

Epoch: 441| Step: 0
Training loss: 0.6241032843331149
Validation loss: 3.0067005992206015

Epoch: 5| Step: 1
Training loss: 0.4020372352792078
Validation loss: 2.9801942858097688

Epoch: 5| Step: 2
Training loss: 1.053657650594524
Validation loss: 3.0029035563998976

Epoch: 5| Step: 3
Training loss: 0.35237096440337623
Validation loss: 2.9970857485807367

Epoch: 5| Step: 4
Training loss: 0.3178479586150003
Validation loss: 2.967457222125383

Epoch: 5| Step: 5
Training loss: 0.4420710595692498
Validation loss: 2.976846719757393

Epoch: 5| Step: 6
Training loss: 0.3347454879562066
Validation loss: 3.056644625757624

Epoch: 5| Step: 7
Training loss: 0.4424426815119155
Validation loss: 3.0192684768229743

Epoch: 5| Step: 8
Training loss: 0.377582992310806
Validation loss: 2.9584225800085853

Epoch: 5| Step: 9
Training loss: 0.3151080614695219
Validation loss: 3.032632053882826

Epoch: 5| Step: 10
Training loss: 0.35111197108142966
Validation loss: 3.055551281598502

Epoch: 5| Step: 11
Training loss: 0.28809535124317515
Validation loss: 3.120838554303259

Epoch: 442| Step: 0
Training loss: 0.463913571899646
Validation loss: 2.968372391226556

Epoch: 5| Step: 1
Training loss: 0.4774593294508741
Validation loss: 2.9440273040912515

Epoch: 5| Step: 2
Training loss: 0.39203718504018376
Validation loss: 3.087151310416386

Epoch: 5| Step: 3
Training loss: 0.3471175531406567
Validation loss: 3.0274283153248893

Epoch: 5| Step: 4
Training loss: 0.41482107384266964
Validation loss: 3.044574955133925

Epoch: 5| Step: 5
Training loss: 0.452037031319361
Validation loss: 3.043880233093428

Epoch: 5| Step: 6
Training loss: 0.3429004944506296
Validation loss: 2.9500625279098456

Epoch: 5| Step: 7
Training loss: 0.46032036670351656
Validation loss: 2.949825616844093

Epoch: 5| Step: 8
Training loss: 0.4218938434772352
Validation loss: 3.043741176313056

Epoch: 5| Step: 9
Training loss: 0.3632778454692831
Validation loss: 2.9769258335799513

Epoch: 5| Step: 10
Training loss: 1.163345372038437
Validation loss: 3.0644598191502017

Epoch: 5| Step: 11
Training loss: 0.45076419526998396
Validation loss: 2.956257878992658

Epoch: 443| Step: 0
Training loss: 0.3924600793801213
Validation loss: 3.0445579782796854

Epoch: 5| Step: 1
Training loss: 0.3957025119366279
Validation loss: 2.943037964354885

Epoch: 5| Step: 2
Training loss: 0.6394254339394225
Validation loss: 3.0702000096674573

Epoch: 5| Step: 3
Training loss: 0.37705879509191814
Validation loss: 2.8950884647776483

Epoch: 5| Step: 4
Training loss: 0.44184251342121234
Validation loss: 3.0261713953273452

Epoch: 5| Step: 5
Training loss: 0.3797296249506317
Validation loss: 2.9218994027408995

Epoch: 5| Step: 6
Training loss: 0.689724531056751
Validation loss: 3.0596061385437885

Epoch: 5| Step: 7
Training loss: 0.5161358296964341
Validation loss: 2.9570083583683124

Epoch: 5| Step: 8
Training loss: 0.3513044787985776
Validation loss: 2.9636318593080513

Epoch: 5| Step: 9
Training loss: 1.0084452454015649
Validation loss: 2.938505305070098

Epoch: 5| Step: 10
Training loss: 0.43473284821461067
Validation loss: 2.954884060716892

Epoch: 5| Step: 11
Training loss: 0.35262163415727044
Validation loss: 2.9692787402269163

Epoch: 444| Step: 0
Training loss: 0.4810649924930462
Validation loss: 3.048447609028755

Epoch: 5| Step: 1
Training loss: 0.35161118700077343
Validation loss: 3.043239178310006

Epoch: 5| Step: 2
Training loss: 0.42281737861158847
Validation loss: 2.9800697149532334

Epoch: 5| Step: 3
Training loss: 0.5113448604354174
Validation loss: 3.07010807524841

Epoch: 5| Step: 4
Training loss: 0.49409348937776815
Validation loss: 2.9916707813656136

Epoch: 5| Step: 5
Training loss: 0.4384347262739998
Validation loss: 2.9841950413902123

Epoch: 5| Step: 6
Training loss: 0.34375378216483427
Validation loss: 2.9420264182595646

Epoch: 5| Step: 7
Training loss: 0.3251123866751498
Validation loss: 3.0101890059892695

Epoch: 5| Step: 8
Training loss: 0.5796283815164752
Validation loss: 2.9474686033859396

Epoch: 5| Step: 9
Training loss: 1.092173612012415
Validation loss: 3.0007565954934075

Epoch: 5| Step: 10
Training loss: 0.38044203364824897
Validation loss: 3.017616233873103

Epoch: 5| Step: 11
Training loss: 0.2841047076645578
Validation loss: 2.9674779073893904

Epoch: 445| Step: 0
Training loss: 0.37776572838006467
Validation loss: 3.0489343546889

Epoch: 5| Step: 1
Training loss: 0.42395595960710175
Validation loss: 3.037696657303328

Epoch: 5| Step: 2
Training loss: 0.28675082908184585
Validation loss: 3.027207333352212

Epoch: 5| Step: 3
Training loss: 0.3834573996742292
Validation loss: 3.0363878053268434

Epoch: 5| Step: 4
Training loss: 0.34702870168355715
Validation loss: 2.911942852264385

Epoch: 5| Step: 5
Training loss: 0.48986312973891927
Validation loss: 3.0592637836423955

Epoch: 5| Step: 6
Training loss: 0.42580627227891993
Validation loss: 3.142108705943692

Epoch: 5| Step: 7
Training loss: 0.35561761778022694
Validation loss: 3.0043370765116166

Epoch: 5| Step: 8
Training loss: 0.3170103499215117
Validation loss: 3.087012976743442

Epoch: 5| Step: 9
Training loss: 1.0824641934963581
Validation loss: 2.985804955857519

Epoch: 5| Step: 10
Training loss: 0.5331542163817025
Validation loss: 2.987922407557999

Epoch: 5| Step: 11
Training loss: 0.709161321244077
Validation loss: 2.983585895782039

Epoch: 446| Step: 0
Training loss: 0.33200663307038436
Validation loss: 3.050702831971632

Epoch: 5| Step: 1
Training loss: 0.28685355954052066
Validation loss: 2.987860872374307

Epoch: 5| Step: 2
Training loss: 0.3744541407443428
Validation loss: 3.0436703954831597

Epoch: 5| Step: 3
Training loss: 0.41833004532556606
Validation loss: 3.025320152018488

Epoch: 5| Step: 4
Training loss: 0.45476721100955775
Validation loss: 2.977705718443905

Epoch: 5| Step: 5
Training loss: 0.5463910550106501
Validation loss: 2.9979971750056076

Epoch: 5| Step: 6
Training loss: 0.3150154440741982
Validation loss: 3.0317388907167913

Epoch: 5| Step: 7
Training loss: 1.0838696118338442
Validation loss: 3.0241603824991325

Epoch: 5| Step: 8
Training loss: 0.428722477021163
Validation loss: 3.025967330588599

Epoch: 5| Step: 9
Training loss: 0.5410740128832677
Validation loss: 2.968178483260654

Epoch: 5| Step: 10
Training loss: 0.456889693027844
Validation loss: 3.0759389702360878

Epoch: 5| Step: 11
Training loss: 0.5402948970365188
Validation loss: 3.0298516974466976

Epoch: 447| Step: 0
Training loss: 0.5320774814499992
Validation loss: 3.053323237823749

Epoch: 5| Step: 1
Training loss: 0.538135643963434
Validation loss: 3.0350709278841235

Epoch: 5| Step: 2
Training loss: 0.38806248341045935
Validation loss: 3.0551343104883935

Epoch: 5| Step: 3
Training loss: 0.36700039012404867
Validation loss: 3.0905208143230634

Epoch: 5| Step: 4
Training loss: 0.42565896964389355
Validation loss: 3.0822723094559685

Epoch: 5| Step: 5
Training loss: 0.386679213843714
Validation loss: 3.0321097907915875

Epoch: 5| Step: 6
Training loss: 0.3751962068975016
Validation loss: 3.0620424616531623

Epoch: 5| Step: 7
Training loss: 1.0543862937046526
Validation loss: 2.964084700637175

Epoch: 5| Step: 8
Training loss: 0.3322185549031699
Validation loss: 3.110438575505649

Epoch: 5| Step: 9
Training loss: 0.39985268905205773
Validation loss: 3.0884593654600807

Epoch: 5| Step: 10
Training loss: 0.49238857824270404
Validation loss: 3.122564660673633

Epoch: 5| Step: 11
Training loss: 0.6630836453068122
Validation loss: 3.049555559556097

Epoch: 448| Step: 0
Training loss: 0.5749079143344356
Validation loss: 3.0591346583973222

Epoch: 5| Step: 1
Training loss: 0.39624076086398324
Validation loss: 3.1202767917842014

Epoch: 5| Step: 2
Training loss: 0.4471808440634786
Validation loss: 3.1041839564991873

Epoch: 5| Step: 3
Training loss: 0.8120938533090473
Validation loss: 3.0269012029263136

Epoch: 5| Step: 4
Training loss: 0.4994605253504643
Validation loss: 3.0891256225290586

Epoch: 5| Step: 5
Training loss: 0.3906592163359029
Validation loss: 3.080841408515097

Epoch: 5| Step: 6
Training loss: 0.6114779157822549
Validation loss: 3.0630251570430382

Epoch: 5| Step: 7
Training loss: 0.4381882839236676
Validation loss: 2.983760507509449

Epoch: 5| Step: 8
Training loss: 0.8338529317935248
Validation loss: 2.9745874869563464

Epoch: 5| Step: 9
Training loss: 1.1173060961110528
Validation loss: 3.0649702593328687

Epoch: 5| Step: 10
Training loss: 0.4316371209878366
Validation loss: 3.0582855348637086

Epoch: 5| Step: 11
Training loss: 0.29368289373763007
Validation loss: 3.0008482627864512

Epoch: 449| Step: 0
Training loss: 0.4957853094320077
Validation loss: 3.0442354196403607

Epoch: 5| Step: 1
Training loss: 0.51879716222159
Validation loss: 3.1213188360769184

Epoch: 5| Step: 2
Training loss: 0.3424374272972513
Validation loss: 2.972324311032202

Epoch: 5| Step: 3
Training loss: 1.0617006885600706
Validation loss: 3.0925675614618946

Epoch: 5| Step: 4
Training loss: 0.5952922967801654
Validation loss: 3.0799295973781953

Epoch: 5| Step: 5
Training loss: 0.43579091304489337
Validation loss: 3.0451572890808962

Epoch: 5| Step: 6
Training loss: 0.37642801107081575
Validation loss: 2.9456626319707255

Epoch: 5| Step: 7
Training loss: 0.641837554218252
Validation loss: 2.966943529198908

Epoch: 5| Step: 8
Training loss: 0.5089675678045746
Validation loss: 3.035024796384082

Epoch: 5| Step: 9
Training loss: 0.34424423320846265
Validation loss: 3.0023528349811164

Epoch: 5| Step: 10
Training loss: 0.5050222768685698
Validation loss: 3.0301901809674963

Epoch: 5| Step: 11
Training loss: 0.38930109743281577
Validation loss: 3.0048858870675588

Epoch: 450| Step: 0
Training loss: 0.3461265772283843
Validation loss: 3.029807088169554

Epoch: 5| Step: 1
Training loss: 1.077503744061331
Validation loss: 3.0068032557284927

Epoch: 5| Step: 2
Training loss: 0.36842646468236956
Validation loss: 3.0135766881882793

Epoch: 5| Step: 3
Training loss: 0.42665468973371695
Validation loss: 2.9437678879871316

Epoch: 5| Step: 4
Training loss: 0.582170098659484
Validation loss: 3.0080750982416276

Epoch: 5| Step: 5
Training loss: 0.47875011693091496
Validation loss: 3.0184891626886894

Epoch: 5| Step: 6
Training loss: 0.48273173894377003
Validation loss: 3.006005666773978

Epoch: 5| Step: 7
Training loss: 0.5226056335298865
Validation loss: 3.0544399411571588

Epoch: 5| Step: 8
Training loss: 0.3950147970361491
Validation loss: 3.057704937679946

Epoch: 5| Step: 9
Training loss: 0.7067877418633828
Validation loss: 3.0414038287653784

Epoch: 5| Step: 10
Training loss: 0.502273754030949
Validation loss: 3.0012229340792027

Epoch: 5| Step: 11
Training loss: 0.3814970888624199
Validation loss: 3.019843430397289

Testing loss: 2.925084907553354
