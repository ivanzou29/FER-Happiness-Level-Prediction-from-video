Epoch: 1| Step: 0
Training loss: 7.291896387750412
Validation loss: 7.244586169863025
Epoch: 9| Step: 1
Training loss: 7.068060652277776
Validation loss: 7.236534403592721
Epoch: 9| Step: 2
Training loss: 7.181268262715436
Validation loss: 7.228865120048721
Epoch: 9| Step: 3
Training loss: 7.661758123082527
Validation loss: 7.213248222264884
Epoch: 9| Step: 4
Training loss: 6.987827070903484
Validation loss: 7.2189613988456305
Epoch: 9| Step: 5
Training loss: 7.485962255441352
Validation loss: 7.207851396262796
Epoch: 9| Step: 6
Training loss: 8.253851713911171
Validation loss: 7.199765476538925
Epoch: 9| Step: 7
Training loss: 7.844722368373863
Validation loss: 7.198641958190246
Epoch: 9| Step: 8
Training loss: 7.782948503912305
Validation loss: 7.196438114003846
Epoch: 9| Step: 9
Training loss: 7.58687729519103
Validation loss: 7.2009609910017085
Epoch: 9| Step: 10
Training loss: 7.895512100435601
Validation loss: 7.176567193053064
Epoch: 9| Step: 11
Training loss: 7.2372271392460155
Validation loss: 7.183230009235986
Epoch: 9| Step: 12
Training loss: 7.363966366087581
Validation loss: 7.164375732363236
Epoch: 9| Step: 13
Training loss: 7.865175688879643
Validation loss: 7.177603380148123
Epoch: 9| Step: 14
Training loss: 7.033831448867269
Validation loss: 7.178094652317606
Epoch: 9| Step: 15
Training loss: 6.45636422276894
Validation loss: 7.159103308583026
Epoch: 9| Step: 16
Training loss: 8.43550549704774
Validation loss: 7.155202595873856
Epoch: 9| Step: 17
Training loss: 8.011310211731521
Validation loss: 7.1421076872177895
Epoch: 9| Step: 18
Training loss: 7.7434068753114795
Validation loss: 7.157133829323395
Epoch: 9| Step: 19
Training loss: 6.680886679638555
Validation loss: 7.146642746722766
Epoch: 2| Step: 0
Training loss: 7.479827199969679
Validation loss: 7.145609401563678
Epoch: 9| Step: 1
Training loss: 7.763916318871895
Validation loss: 7.146631593152519
Epoch: 9| Step: 2
Training loss: 8.151763032593058
Validation loss: 7.095837799880965
Epoch: 9| Step: 3
Training loss: 7.086761662207471
Validation loss: 7.116771875363799
Epoch: 9| Step: 4
Training loss: 6.489071388523289
Validation loss: 7.129600259437553
Epoch: 9| Step: 5
Training loss: 7.9762234218760195
Validation loss: 7.1098588618448
Epoch: 9| Step: 6
Training loss: 7.288932185832707
Validation loss: 7.111897847805609
Epoch: 9| Step: 7
Training loss: 7.797535228105412
Validation loss: 7.1077980849717095
Epoch: 9| Step: 8
Training loss: 6.728869389284997
Validation loss: 7.1122100717607415
Epoch: 9| Step: 9
Training loss: 7.025118311635788
Validation loss: 7.093512547332596
Epoch: 9| Step: 10
Training loss: 7.8430802868662814
Validation loss: 7.081269539506091
Epoch: 9| Step: 11
Training loss: 7.35184944395504
Validation loss: 7.082596708082085
Epoch: 9| Step: 12
Training loss: 7.751315835797126
Validation loss: 7.086060087945197
Epoch: 9| Step: 13
Training loss: 7.755644680751079
Validation loss: 7.066933424354516
Epoch: 9| Step: 14
Training loss: 8.06304362039028
Validation loss: 7.068626790198339
Epoch: 9| Step: 15
Training loss: 6.056099255775187
Validation loss: 7.074769151779441
Epoch: 9| Step: 16
Training loss: 7.759464268626023
Validation loss: 7.076204323502602
Epoch: 9| Step: 17
Training loss: 6.491814374243067
Validation loss: 7.071700554680717
Epoch: 9| Step: 18
Training loss: 6.846077301204136
Validation loss: 7.068130271179066
Epoch: 9| Step: 19
Training loss: 8.210267073158928
Validation loss: 7.047984225479093
Epoch: 3| Step: 0
Training loss: 7.738620155611839
Validation loss: 7.036109227956379
Epoch: 9| Step: 1
Training loss: 6.373032509369343
Validation loss: 7.054321189641652
Epoch: 9| Step: 2
Training loss: 8.275531910745176
Validation loss: 7.032841863226191
Epoch: 9| Step: 3
Training loss: 7.527528215176177
Validation loss: 7.037638435273424
Epoch: 9| Step: 4
Training loss: 6.203540086670964
Validation loss: 7.029035128885561
Epoch: 9| Step: 5
Training loss: 6.650099800909799
Validation loss: 7.032555097684369
Epoch: 9| Step: 6
Training loss: 7.369288673804367
Validation loss: 7.030192854929062
Epoch: 9| Step: 7
Training loss: 6.918030784324491
Validation loss: 6.997125880670293
Epoch: 9| Step: 8
Training loss: 6.688938449635175
Validation loss: 7.020285592805597
Epoch: 9| Step: 9
Training loss: 7.5608286626478955
Validation loss: 7.008897742960065
Epoch: 9| Step: 10
Training loss: 7.950462990000714
Validation loss: 7.0145566521026845
Epoch: 9| Step: 11
Training loss: 7.481778198054444
Validation loss: 6.999333237247536
Epoch: 9| Step: 12
Training loss: 7.619014704724016
Validation loss: 6.990730708127504
Epoch: 9| Step: 13
Training loss: 6.774555892746425
Validation loss: 6.9853674472391925
Epoch: 9| Step: 14
Training loss: 7.435355766932701
Validation loss: 6.987332059814647
Epoch: 9| Step: 15
Training loss: 7.6249609774232
Validation loss: 6.984952293561487
Epoch: 9| Step: 16
Training loss: 7.302369493508704
Validation loss: 6.987433371293785
Epoch: 9| Step: 17
Training loss: 8.272708042972253
Validation loss: 6.982379039569309
Epoch: 9| Step: 18
Training loss: 7.375291204360754
Validation loss: 6.967418766392378
Epoch: 9| Step: 19
Training loss: 7.261133524360625
Validation loss: 6.9758723031473755
Epoch: 4| Step: 0
Training loss: 6.897877861642711
Validation loss: 6.958240682340473
Epoch: 9| Step: 1
Training loss: 7.717116704331449
Validation loss: 6.9680856529724355
Epoch: 9| Step: 2
Training loss: 7.330652122476655
Validation loss: 6.948555844904972
Epoch: 9| Step: 3
Training loss: 7.642695670975041
Validation loss: 6.960985149119634
Epoch: 9| Step: 4
Training loss: 7.6472912748746165
Validation loss: 6.943491651065208
Epoch: 9| Step: 5
Training loss: 7.051935176523301
Validation loss: 6.951608501044851
Epoch: 9| Step: 6
Training loss: 7.017420481634576
Validation loss: 6.9471905202491175
Epoch: 9| Step: 7
Training loss: 6.202039801466499
Validation loss: 6.936210628249892
Epoch: 9| Step: 8
Training loss: 7.577096519287428
Validation loss: 6.929665426375049
Epoch: 9| Step: 9
Training loss: 6.659996733335318
Validation loss: 6.929257407236503
Epoch: 9| Step: 10
Training loss: 7.658226038444425
Validation loss: 6.918242881066358
Epoch: 9| Step: 11
Training loss: 7.232574568415822
Validation loss: 6.910976148691594
Epoch: 9| Step: 12
Training loss: 7.0528522862962655
Validation loss: 6.922405452218533
Epoch: 9| Step: 13
Training loss: 8.666483754893223
Validation loss: 6.908063034958211
Epoch: 9| Step: 14
Training loss: 7.457326156835561
Validation loss: 6.90705750382412
Epoch: 9| Step: 15
Training loss: 6.4279423844913115
Validation loss: 6.909343193280173
Epoch: 9| Step: 16
Training loss: 7.711609042993714
Validation loss: 6.89857403699005
Epoch: 9| Step: 17
Training loss: 8.010792128581526
Validation loss: 6.896473165657991
Epoch: 9| Step: 18
Training loss: 5.214781388613551
Validation loss: 6.885436349241481
Epoch: 9| Step: 19
Training loss: 7.37185705424506
Validation loss: 6.884594116206123
Epoch: 5| Step: 0
Training loss: 7.536899331421537
Validation loss: 6.883608185460867
Epoch: 9| Step: 1
Training loss: 7.275307518401177
Validation loss: 6.868857544966159
Epoch: 9| Step: 2
Training loss: 7.297707226363548
Validation loss: 6.861303362408437
Epoch: 9| Step: 3
Training loss: 6.937917885781277
Validation loss: 6.87152393803321
Epoch: 9| Step: 4
Training loss: 8.39716014995453
Validation loss: 6.86990300204396
Epoch: 9| Step: 5
Training loss: 6.498921818443894
Validation loss: 6.859124948420129
Epoch: 9| Step: 6
Training loss: 6.182719840627225
Validation loss: 6.839032987037345
Epoch: 9| Step: 7
Training loss: 7.050988732663972
Validation loss: 6.845912614336951
Epoch: 9| Step: 8
Training loss: 6.350455212233836
Validation loss: 6.839143102689923
Epoch: 9| Step: 9
Training loss: 7.556862487454491
Validation loss: 6.840147997010483
Epoch: 9| Step: 10
Training loss: 7.004918958697518
Validation loss: 6.822440789211235
Epoch: 9| Step: 11
Training loss: 6.978608278929416
Validation loss: 6.823022746023266
Epoch: 9| Step: 12
Training loss: 7.034296757429418
Validation loss: 6.819536607761806
Epoch: 9| Step: 13
Training loss: 6.948746097438023
Validation loss: 6.800461703123864
Epoch: 9| Step: 14
Training loss: 6.7519390005637625
Validation loss: 6.803688079443671
Epoch: 9| Step: 15
Training loss: 8.04830985007853
Validation loss: 6.811948820632114
Epoch: 9| Step: 16
Training loss: 7.384362436510684
Validation loss: 6.782385278837394
Epoch: 9| Step: 17
Training loss: 8.029554611148614
Validation loss: 6.763090782899879
Epoch: 9| Step: 18
Training loss: 6.39649093511114
Validation loss: 6.77086586814879
Epoch: 9| Step: 19
Training loss: 7.252458878893355
Validation loss: 6.776484337215116
Epoch: 6| Step: 0
Training loss: 7.424026209620546
Validation loss: 6.77242839108536
Epoch: 9| Step: 1
Training loss: 8.103189156098463
Validation loss: 6.761181828774913
Epoch: 9| Step: 2
Training loss: 6.6622433611196765
Validation loss: 6.744000502655519
Epoch: 9| Step: 3
Training loss: 7.1405352497094885
Validation loss: 6.75068016517159
Epoch: 9| Step: 4
Training loss: 6.241536628105331
Validation loss: 6.735484769692432
Epoch: 9| Step: 5
Training loss: 7.262231965625898
Validation loss: 6.731955047138127
Epoch: 9| Step: 6
Training loss: 6.297068249787394
Validation loss: 6.709009393093511
Epoch: 9| Step: 7
Training loss: 7.763299912473165
Validation loss: 6.7117070762778885
Epoch: 9| Step: 8
Training loss: 7.452017583886705
Validation loss: 6.68850303431174
Epoch: 9| Step: 9
Training loss: 6.199757158999569
Validation loss: 6.6964859578959555
Epoch: 9| Step: 10
Training loss: 7.612348222393953
Validation loss: 6.694769943386479
Epoch: 9| Step: 11
Training loss: 7.131137546786041
Validation loss: 6.690475182040637
Epoch: 9| Step: 12
Training loss: 7.2090777709169505
Validation loss: 6.672969870845821
Epoch: 9| Step: 13
Training loss: 7.458655266944121
Validation loss: 6.653887753774063
Epoch: 9| Step: 14
Training loss: 7.455043585769479
Validation loss: 6.647939187011028
Epoch: 9| Step: 15
Training loss: 6.907327283148903
Validation loss: 6.654077647884512
Epoch: 9| Step: 16
Training loss: 5.9518384769836885
Validation loss: 6.63546418134859
Epoch: 9| Step: 17
Training loss: 6.653410543224388
Validation loss: 6.639637781286662
Epoch: 9| Step: 18
Training loss: 7.258243478188912
Validation loss: 6.629161592792262
Epoch: 9| Step: 19
Training loss: 6.249215649025672
Validation loss: 6.62572842055295
Epoch: 7| Step: 0
Training loss: 7.1620209591965525
Validation loss: 6.600949654015303
Epoch: 9| Step: 1
Training loss: 8.13810822869739
Validation loss: 6.604721375244489
Epoch: 9| Step: 2
Training loss: 7.229500827889778
Validation loss: 6.5954287351287135
Epoch: 9| Step: 3
Training loss: 6.008971183170692
Validation loss: 6.582146219932115
Epoch: 9| Step: 4
Training loss: 7.375050172796761
Validation loss: 6.575791791606802
Epoch: 9| Step: 5
Training loss: 6.783347653585529
Validation loss: 6.546119905192601
Epoch: 9| Step: 6
Training loss: 6.706557171018135
Validation loss: 6.551476345480012
Epoch: 9| Step: 7
Training loss: 6.999428862023762
Validation loss: 6.537514871896938
Epoch: 9| Step: 8
Training loss: 6.316002204725522
Validation loss: 6.526346544228712
Epoch: 9| Step: 9
Training loss: 6.564818054606532
Validation loss: 6.511209220732227
Epoch: 9| Step: 10
Training loss: 6.854176004358982
Validation loss: 6.507205243916175
Epoch: 9| Step: 11
Training loss: 6.491926901828273
Validation loss: 6.505981533758101
Epoch: 9| Step: 12
Training loss: 7.421813322112141
Validation loss: 6.49329416624132
Epoch: 9| Step: 13
Training loss: 6.824353745713279
Validation loss: 6.463326906019544
Epoch: 9| Step: 14
Training loss: 6.013374363377925
Validation loss: 6.453500407152431
Epoch: 9| Step: 15
Training loss: 7.6596413088648445
Validation loss: 6.458013622965978
Epoch: 9| Step: 16
Training loss: 6.652935223540287
Validation loss: 6.420710241372075
Epoch: 9| Step: 17
Training loss: 6.101448712527342
Validation loss: 6.425837334637716
Epoch: 9| Step: 18
Training loss: 7.246803631416713
Validation loss: 6.42866267529208
Epoch: 9| Step: 19
Training loss: 6.446242534698963
Validation loss: 6.393093012282301
Epoch: 8| Step: 0
Training loss: 6.542144887497059
Validation loss: 6.40396672228914
Epoch: 9| Step: 1
Training loss: 7.134918269736543
Validation loss: 6.395107204435059
Epoch: 9| Step: 2
Training loss: 6.697625311590155
Validation loss: 6.369348570783722
Epoch: 9| Step: 3
Training loss: 7.650588577666218
Validation loss: 6.352594786806273
Epoch: 9| Step: 4
Training loss: 5.450504230656849
Validation loss: 6.352690029937254
Epoch: 9| Step: 5
Training loss: 7.13111962643068
Validation loss: 6.322353497950894
Epoch: 9| Step: 6
Training loss: 6.007522000555487
Validation loss: 6.312595714844719
Epoch: 9| Step: 7
Training loss: 6.448933050341969
Validation loss: 6.300418901668055
Epoch: 9| Step: 8
Training loss: 6.55230094738315
Validation loss: 6.279589307031297
Epoch: 9| Step: 9
Training loss: 7.235945133673905
Validation loss: 6.27561978064531
Epoch: 9| Step: 10
Training loss: 6.629990047947936
Validation loss: 6.268541778838464
Epoch: 9| Step: 11
Training loss: 5.461051885146372
Validation loss: 6.231127176262586
Epoch: 9| Step: 12
Training loss: 6.11887785453595
Validation loss: 6.231485952351504
Epoch: 9| Step: 13
Training loss: 6.56715678340128
Validation loss: 6.218424343126879
Epoch: 9| Step: 14
Training loss: 7.060597931610004
Validation loss: 6.197845371558281
Epoch: 9| Step: 15
Training loss: 5.4949310526110535
Validation loss: 6.184620821731019
Epoch: 9| Step: 16
Training loss: 7.637796888808793
Validation loss: 6.152514107784249
Epoch: 9| Step: 17
Training loss: 6.970288572973671
Validation loss: 6.131570385728627
Epoch: 9| Step: 18
Training loss: 6.721639889941932
Validation loss: 6.125897674397374
Epoch: 9| Step: 19
Training loss: 6.63629741801934
Validation loss: 6.087672604418732
Epoch: 9| Step: 0
Training loss: 6.473236739396864
Validation loss: 6.090180793863234
Epoch: 9| Step: 1
Training loss: 6.489274786588974
Validation loss: 6.087745214154906
Epoch: 9| Step: 2
Training loss: 6.829534948107512
Validation loss: 6.06961682241102
Epoch: 9| Step: 3
Training loss: 6.271857835929584
Validation loss: 6.052468473150837
Epoch: 9| Step: 4
Training loss: 6.159898015949171
Validation loss: 6.030449382560624
Epoch: 9| Step: 5
Training loss: 6.3306038981547434
Validation loss: 6.008171328352316
Epoch: 9| Step: 6
Training loss: 6.040124560454904
Validation loss: 5.977177762637599
Epoch: 9| Step: 7
Training loss: 7.31101074703837
Validation loss: 5.962101643344033
Epoch: 9| Step: 8
Training loss: 6.190476751502155
Validation loss: 5.946186777083658
Epoch: 9| Step: 9
Training loss: 6.80496050596864
Validation loss: 5.912973146637404
Epoch: 9| Step: 10
Training loss: 5.999202357360564
Validation loss: 5.908421756752566
Epoch: 9| Step: 11
Training loss: 5.819840584895238
Validation loss: 5.889086612218935
Epoch: 9| Step: 12
Training loss: 5.3829019702402
Validation loss: 5.852997495576913
Epoch: 9| Step: 13
Training loss: 6.857041642032401
Validation loss: 5.842351520054315
Epoch: 9| Step: 14
Training loss: 5.545292330329267
Validation loss: 5.820035602827988
Epoch: 9| Step: 15
Training loss: 6.068083089844263
Validation loss: 5.788951271095304
Epoch: 9| Step: 16
Training loss: 6.672260353698667
Validation loss: 5.780011499350618
Epoch: 9| Step: 17
Training loss: 6.3827793302572955
Validation loss: 5.768437210465337
Epoch: 9| Step: 18
Training loss: 6.407158615061335
Validation loss: 5.742703862158597
Epoch: 9| Step: 19
Training loss: 6.059399628060445
Validation loss: 5.71404877562037
Epoch: 10| Step: 0
Training loss: 5.308133114442829
Validation loss: 5.701602067829175
Epoch: 9| Step: 1
Training loss: 5.257231681677533
Validation loss: 5.653319286674643
Epoch: 9| Step: 2
Training loss: 5.867615949527742
Validation loss: 5.641217603191182
Epoch: 9| Step: 3
Training loss: 5.788063447025859
Validation loss: 5.625795473012266
Epoch: 9| Step: 4
Training loss: 6.952526418230383
Validation loss: 5.598813714350868
Epoch: 9| Step: 5
Training loss: 5.261512304842476
Validation loss: 5.567851496336
Epoch: 9| Step: 6
Training loss: 5.500088084122424
Validation loss: 5.550020963627694
Epoch: 9| Step: 7
Training loss: 6.91012340341614
Validation loss: 5.509808428817991
Epoch: 9| Step: 8
Training loss: 5.17676085216733
Validation loss: 5.465171322694252
Epoch: 9| Step: 9
Training loss: 6.544758675412315
Validation loss: 5.4710331247729895
Epoch: 9| Step: 10
Training loss: 6.137852477229032
Validation loss: 5.421019171177551
Epoch: 9| Step: 11
Training loss: 6.656900723308876
Validation loss: 5.410040178056875
Epoch: 9| Step: 12
Training loss: 5.83271571931579
Validation loss: 5.386732295530774
Epoch: 9| Step: 13
Training loss: 6.053939911003819
Validation loss: 5.35214139847134
Epoch: 9| Step: 14
Training loss: 5.633411814727945
Validation loss: 5.311492199220405
Epoch: 9| Step: 15
Training loss: 5.991622798725486
Validation loss: 5.305765457111487
Epoch: 9| Step: 16
Training loss: 5.197710765768893
Validation loss: 5.260335156239739
Epoch: 9| Step: 17
Training loss: 5.6618166344857075
Validation loss: 5.245824786685153
Epoch: 9| Step: 18
Training loss: 5.426927306799505
Validation loss: 5.201565006829973
Epoch: 9| Step: 19
Training loss: 6.011365933441599
Validation loss: 5.179317919308875
Epoch: 11| Step: 0
Training loss: 5.025829167065702
Validation loss: 5.14995694807713
Epoch: 9| Step: 1
Training loss: 6.17420594828168
Validation loss: 5.116016623060375
Epoch: 9| Step: 2
Training loss: 5.126723581170959
Validation loss: 5.066896581494353
Epoch: 9| Step: 3
Training loss: 6.093387534292104
Validation loss: 5.048452088200806
Epoch: 9| Step: 4
Training loss: 4.784372544241287
Validation loss: 5.013701168401266
Epoch: 9| Step: 5
Training loss: 5.7354608905647035
Validation loss: 4.981651341029707
Epoch: 9| Step: 6
Training loss: 5.312379723477607
Validation loss: 4.937775954675823
Epoch: 9| Step: 7
Training loss: 4.840790465884133
Validation loss: 4.913091910221135
Epoch: 9| Step: 8
Training loss: 5.717090470125824
Validation loss: 4.891954623631337
Epoch: 9| Step: 9
Training loss: 4.7609253770844795
Validation loss: 4.858945608998787
Epoch: 9| Step: 10
Training loss: 5.187291152610689
Validation loss: 4.808880222358435
Epoch: 9| Step: 11
Training loss: 5.30966146593288
Validation loss: 4.754436013043895
Epoch: 9| Step: 12
Training loss: 4.363290866988059
Validation loss: 4.746693933144804
Epoch: 9| Step: 13
Training loss: 5.806551607016113
Validation loss: 4.719078478852106
Epoch: 9| Step: 14
Training loss: 5.382126098629866
Validation loss: 4.64346450698114
Epoch: 9| Step: 15
Training loss: 5.013556413320378
Validation loss: 4.621790908407191
Epoch: 9| Step: 16
Training loss: 5.772094405154985
Validation loss: 4.611889761266535
Epoch: 9| Step: 17
Training loss: 5.2116552313295
Validation loss: 4.578848885617118
Epoch: 9| Step: 18
Training loss: 5.371151278101008
Validation loss: 4.542549669710992
Epoch: 9| Step: 19
Training loss: 5.048427284015507
Validation loss: 4.504562135649631
Epoch: 12| Step: 0
Training loss: 4.8376603762831225
Validation loss: 4.457287675871933
Epoch: 9| Step: 1
Training loss: 4.673917904225474
Validation loss: 4.432750239956404
Epoch: 9| Step: 2
Training loss: 5.193418504622958
Validation loss: 4.39192082000312
Epoch: 9| Step: 3
Training loss: 4.22857245920235
Validation loss: 4.330324035464623
Epoch: 9| Step: 4
Training loss: 4.576370267519823
Validation loss: 4.306891718336278
Epoch: 9| Step: 5
Training loss: 4.528584294689824
Validation loss: 4.2821842224055695
Epoch: 9| Step: 6
Training loss: 4.163163021769049
Validation loss: 4.227140883571013
Epoch: 9| Step: 7
Training loss: 5.415582969048976
Validation loss: 4.191019596548958
Epoch: 9| Step: 8
Training loss: 5.147522354410921
Validation loss: 4.144701054994281
Epoch: 9| Step: 9
Training loss: 3.7754201794141973
Validation loss: 4.127065209094952
Epoch: 9| Step: 10
Training loss: 4.715313398962942
Validation loss: 4.047881038012517
Epoch: 9| Step: 11
Training loss: 4.837442931003711
Validation loss: 4.038067745118156
Epoch: 9| Step: 12
Training loss: 4.826078802281927
Validation loss: 3.9513541270944197
Epoch: 9| Step: 13
Training loss: 4.542875333237196
Validation loss: 3.9266552163630335
Epoch: 9| Step: 14
Training loss: 4.219299280648119
Validation loss: 3.9207213589675023
Epoch: 9| Step: 15
Training loss: 4.915567479945967
Validation loss: 3.901159713452395
Epoch: 9| Step: 16
Training loss: 4.084866968834624
Validation loss: 3.8387627158796103
Epoch: 9| Step: 17
Training loss: 4.343916416410849
Validation loss: 3.8141852156705354
Epoch: 9| Step: 18
Training loss: 4.960300386623486
Validation loss: 3.7687292299041943
Epoch: 9| Step: 19
Training loss: 4.864414950063007
Validation loss: 3.7407852733652023
Epoch: 13| Step: 0
Training loss: 4.494098184012987
Validation loss: 3.6919907256812396
Epoch: 9| Step: 1
Training loss: 3.9507031165029463
Validation loss: 3.6282274235575547
Epoch: 9| Step: 2
Training loss: 4.2915014340094855
Validation loss: 3.6292451472863188
Epoch: 9| Step: 3
Training loss: 3.320536814573583
Validation loss: 3.556997896231327
Epoch: 9| Step: 4
Training loss: 3.6371637352793793
Validation loss: 3.5245667699683993
Epoch: 9| Step: 5
Training loss: 4.8652959243146086
Validation loss: 3.5174810473261395
Epoch: 9| Step: 6
Training loss: 3.7539410544855065
Validation loss: 3.4623888399601834
Epoch: 9| Step: 7
Training loss: 4.754537322662205
Validation loss: 3.4345120164518814
Epoch: 9| Step: 8
Training loss: 4.219552422964607
Validation loss: 3.3634011485482964
Epoch: 9| Step: 9
Training loss: 3.936066381654534
Validation loss: 3.3412227115639435
Epoch: 9| Step: 10
Training loss: 3.604957684865104
Validation loss: 3.309682910130277
Epoch: 9| Step: 11
Training loss: 2.6176110679285216
Validation loss: 3.2677204830142528
Epoch: 9| Step: 12
Training loss: 4.794695331015386
Validation loss: 3.2525455449997303
Epoch: 9| Step: 13
Training loss: 3.371336325960627
Validation loss: 3.2069262542630126
Epoch: 9| Step: 14
Training loss: 3.6725016607043184
Validation loss: 3.1892811063279423
Epoch: 9| Step: 15
Training loss: 4.8725544590888985
Validation loss: 3.1563657925126174
Epoch: 9| Step: 16
Training loss: 3.707055046559883
Validation loss: 3.1361410066562434
Epoch: 9| Step: 17
Training loss: 3.7037288640191988
Validation loss: 3.1018578187732477
Epoch: 9| Step: 18
Training loss: 3.8984027624015956
Validation loss: 3.0402800670661527
Epoch: 9| Step: 19
Training loss: 2.9511177467012426
Validation loss: 3.010872558661601
Epoch: 14| Step: 0
Training loss: 3.180561217442285
Validation loss: 2.9662101276811583
Epoch: 9| Step: 1
Training loss: 3.4397600547143967
Validation loss: 2.943403113833014
Epoch: 9| Step: 2
Training loss: 3.806299764874733
Validation loss: 2.9065690094197136
Epoch: 9| Step: 3
Training loss: 3.932805002150059
Validation loss: 2.910920123217267
Epoch: 9| Step: 4
Training loss: 3.550685902271125
Validation loss: 2.8918151441664115
Epoch: 9| Step: 5
Training loss: 2.7819300473795496
Validation loss: 2.8636860897870697
Epoch: 9| Step: 6
Training loss: 2.929005780059019
Validation loss: 2.7766306633240085
Epoch: 9| Step: 7
Training loss: 2.836968352804531
Validation loss: 2.8031226862057186
Epoch: 9| Step: 8
Training loss: 2.735986027921727
Validation loss: 2.7640872605710034
Epoch: 9| Step: 9
Training loss: 2.8083224318054087
Validation loss: 2.7449877344557483
Epoch: 9| Step: 10
Training loss: 4.346688792712604
Validation loss: 2.7122058607695543
Epoch: 9| Step: 11
Training loss: 4.114266041299924
Validation loss: 2.695725692135361
Epoch: 9| Step: 12
Training loss: 2.9100834984614408
Validation loss: 2.6711296733150864
Epoch: 9| Step: 13
Training loss: 3.6361664415123878
Validation loss: 2.64658536338687
Epoch: 9| Step: 14
Training loss: 2.93507382457629
Validation loss: 2.6559639435620253
Epoch: 9| Step: 15
Training loss: 2.97256465575257
Validation loss: 2.621673729359151
Epoch: 9| Step: 16
Training loss: 2.8553712256772816
Validation loss: 2.587466718112834
Epoch: 9| Step: 17
Training loss: 2.8982657409940726
Validation loss: 2.5820128518372414
Epoch: 9| Step: 18
Training loss: 3.911204133830048
Validation loss: 2.56066133061829
Epoch: 9| Step: 19
Training loss: 4.446837366498455
Validation loss: 2.557923824060658
Epoch: 15| Step: 0
Training loss: 2.4682227428766166
Validation loss: 2.5530243174082408
Epoch: 9| Step: 1
Training loss: 3.7281641687092666
Validation loss: 2.5618693483397053
Epoch: 9| Step: 2
Training loss: 3.1096453525192906
Validation loss: 2.533236357360425
Epoch: 9| Step: 3
Training loss: 2.8549326590430986
Validation loss: 2.541588344785005
Epoch: 9| Step: 4
Training loss: 3.4322097297732825
Validation loss: 2.50857135494598
Epoch: 9| Step: 5
Training loss: 1.7584931136780921
Validation loss: 2.498559150975623
Epoch: 9| Step: 6
Training loss: 2.7117505352209292
Validation loss: 2.5260948249706305
Epoch: 9| Step: 7
Training loss: 2.9854609725514636
Validation loss: 2.468032514837357
Epoch: 9| Step: 8
Training loss: 3.7116205169133694
Validation loss: 2.4609956718669084
Epoch: 9| Step: 9
Training loss: 2.7616091089997954
Validation loss: 2.5157223727177795
Epoch: 9| Step: 10
Training loss: 3.099405994725699
Validation loss: 2.457690775373959
Epoch: 9| Step: 11
Training loss: 3.004114349657461
Validation loss: 2.4881954404740507
Epoch: 9| Step: 12
Training loss: 3.447332987789072
Validation loss: 2.4935216061089576
Epoch: 9| Step: 13
Training loss: 3.4209565624076377
Validation loss: 2.443892785080269
Epoch: 9| Step: 14
Training loss: 3.5570194853301764
Validation loss: 2.425473126992936
Epoch: 9| Step: 15
Training loss: 3.2920062376869406
Validation loss: 2.4501060860115764
Epoch: 9| Step: 16
Training loss: 3.309739744206097
Validation loss: 2.448707312977404
Epoch: 9| Step: 17
Training loss: 2.579834527320404
Validation loss: 2.470371434345577
Epoch: 9| Step: 18
Training loss: 3.368345411135239
Validation loss: 2.450470448907167
Epoch: 9| Step: 19
Training loss: 2.4856172730630544
Validation loss: 2.454236487941215
Epoch: 16| Step: 0
Training loss: 2.8819813757883006
Validation loss: 2.50686906752472
Epoch: 9| Step: 1
Training loss: 2.372206601169125
Validation loss: 2.4340741492994002
Epoch: 9| Step: 2
Training loss: 2.251391298560923
Validation loss: 2.42126365880098
Epoch: 9| Step: 3
Training loss: 2.66713128413361
Validation loss: 2.5011838451296415
Epoch: 9| Step: 4
Training loss: 2.6746025217959337
Validation loss: 2.455841150420838
Epoch: 9| Step: 5
Training loss: 2.298504932277948
Validation loss: 2.4385002084647427
Epoch: 9| Step: 6
Training loss: 3.3806139561054356
Validation loss: 2.430718804834095
Epoch: 9| Step: 7
Training loss: 3.8311391991777803
Validation loss: 2.501705335009011
Epoch: 9| Step: 8
Training loss: 3.456157198827596
Validation loss: 2.4686888804865577
Epoch: 9| Step: 9
Training loss: 3.605788525652001
Validation loss: 2.48000261861725
Epoch: 9| Step: 10
Training loss: 2.8504838967690636
Validation loss: 2.440856652882652
Epoch: 9| Step: 11
Training loss: 2.5955135370943907
Validation loss: 2.4202338010746978
Epoch: 9| Step: 12
Training loss: 3.8408268924349307
Validation loss: 2.4616094518648493
Epoch: 9| Step: 13
Training loss: 3.3782016967761948
Validation loss: 2.483265918255553
Epoch: 9| Step: 14
Training loss: 1.8153091234677132
Validation loss: 2.5258306400087007
Epoch: 9| Step: 15
Training loss: 2.91152999507672
Validation loss: 2.4179527305216117
Epoch: 9| Step: 16
Training loss: 3.2298484492695665
Validation loss: 2.4346601655441398
Epoch: 9| Step: 17
Training loss: 3.0498458072896386
Validation loss: 2.4444378714024295
Epoch: 9| Step: 18
Training loss: 3.1610797150506635
Validation loss: 2.479028610268367
Epoch: 9| Step: 19
Training loss: 3.277386816239688
Validation loss: 2.5175643536415007
Epoch: 17| Step: 0
Training loss: 2.0871701830873652
Validation loss: 2.462352618611993
Epoch: 9| Step: 1
Training loss: 2.7089349127491475
Validation loss: 2.491755313986846
Epoch: 9| Step: 2
Training loss: 3.534401896380308
Validation loss: 2.490626485537439
Epoch: 9| Step: 3
Training loss: 3.5477460556239526
Validation loss: 2.479171824830389
Epoch: 9| Step: 4
Training loss: 2.337338234918956
Validation loss: 2.4763882006302427
Epoch: 9| Step: 5
Training loss: 3.1339328503453343
Validation loss: 2.4865427694083517
Epoch: 9| Step: 6
Training loss: 1.9678123905690117
Validation loss: 2.471441085150108
Epoch: 9| Step: 7
Training loss: 3.05818916071063
Validation loss: 2.437601471751088
Epoch: 9| Step: 8
Training loss: 3.1466753171812645
Validation loss: 2.4751480437928235
Epoch: 9| Step: 9
Training loss: 2.988789593710744
Validation loss: 2.4631268567889397
Epoch: 9| Step: 10
Training loss: 2.717355743341376
Validation loss: 2.4205299293340166
Epoch: 9| Step: 11
Training loss: 3.5291213650068416
Validation loss: 2.4854524735319194
Epoch: 9| Step: 12
Training loss: 3.068378955916993
Validation loss: 2.494822392955087
Epoch: 9| Step: 13
Training loss: 2.9068445397411016
Validation loss: 2.5116562428602345
Epoch: 9| Step: 14
Training loss: 2.817330006545859
Validation loss: 2.443385835195365
Epoch: 9| Step: 15
Training loss: 3.02179557119953
Validation loss: 2.450104672016974
Epoch: 9| Step: 16
Training loss: 3.499669195618318
Validation loss: 2.529292910038023
Epoch: 9| Step: 17
Training loss: 2.3527861291626313
Validation loss: 2.4997261828120765
Epoch: 9| Step: 18
Training loss: 3.8147095077928563
Validation loss: 2.454727385095388
Epoch: 9| Step: 19
Training loss: 3.0328534791232626
Validation loss: 2.4356618125634792
Epoch: 18| Step: 0
Training loss: 2.633185295177036
Validation loss: 2.4967929003186486
Epoch: 9| Step: 1
Training loss: 2.9938908999740232
Validation loss: 2.491149679447155
Epoch: 9| Step: 2
Training loss: 2.2594427539168898
Validation loss: 2.497072485492928
Epoch: 9| Step: 3
Training loss: 3.2376332848408533
Validation loss: 2.4697799260697817
Epoch: 9| Step: 4
Training loss: 2.546453242105045
Validation loss: 2.5107292223808493
Epoch: 9| Step: 5
Training loss: 3.137859588321394
Validation loss: 2.478761526779864
Epoch: 9| Step: 6
Training loss: 3.0387094483833654
Validation loss: 2.480174517245292
Epoch: 9| Step: 7
Training loss: 3.347000681051613
Validation loss: 2.4998189784549862
Epoch: 9| Step: 8
Training loss: 3.3485324207118845
Validation loss: 2.4785481866339243
Epoch: 9| Step: 9
Training loss: 3.137442879327833
Validation loss: 2.477197534937111
Epoch: 9| Step: 10
Training loss: 2.188248315608944
Validation loss: 2.476257660276162
Epoch: 9| Step: 11
Training loss: 2.810843933821352
Validation loss: 2.4614440391005763
Epoch: 9| Step: 12
Training loss: 3.340113864259825
Validation loss: 2.49905665664426
Epoch: 9| Step: 13
Training loss: 2.818053801976634
Validation loss: 2.4644281429321158
Epoch: 9| Step: 14
Training loss: 3.6006803611415372
Validation loss: 2.449210704053195
Epoch: 9| Step: 15
Training loss: 2.700461690776833
Validation loss: 2.4919395508766358
Epoch: 9| Step: 16
Training loss: 2.9276353489757336
Validation loss: 2.5159432008264457
Epoch: 9| Step: 17
Training loss: 2.3867912718498068
Validation loss: 2.4373615416058745
Epoch: 9| Step: 18
Training loss: 3.816438485422331
Validation loss: 2.456669649136746
Epoch: 9| Step: 19
Training loss: 2.936868640335059
Validation loss: 2.4549798832965863
Epoch: 19| Step: 0
Training loss: 2.8452523423632625
Validation loss: 2.443402887012032
Epoch: 9| Step: 1
Training loss: 2.7651077907584254
Validation loss: 2.5045018981393232
Epoch: 9| Step: 2
Training loss: 2.939140024333921
Validation loss: 2.439817539231447
Epoch: 9| Step: 3
Training loss: 3.609315153344145
Validation loss: 2.446548499818572
Epoch: 9| Step: 4
Training loss: 2.264581690006543
Validation loss: 2.492863969747396
Epoch: 9| Step: 5
Training loss: 2.82344857210016
Validation loss: 2.4634416763721534
Epoch: 9| Step: 6
Training loss: 3.305462829685522
Validation loss: 2.4563831564173184
Epoch: 9| Step: 7
Training loss: 3.3186216110424267
Validation loss: 2.462519177750079
Epoch: 9| Step: 8
Training loss: 2.844647444080852
Validation loss: 2.432695564776448
Epoch: 9| Step: 9
Training loss: 3.448196415150398
Validation loss: 2.480986253768443
Epoch: 9| Step: 10
Training loss: 2.8167697285714333
Validation loss: 2.5267976301853285
Epoch: 9| Step: 11
Training loss: 3.003498898034285
Validation loss: 2.4701902872481414
Epoch: 9| Step: 12
Training loss: 3.1859981514254256
Validation loss: 2.4970658744880874
Epoch: 9| Step: 13
Training loss: 2.9247921339985186
Validation loss: 2.4702735699484233
Epoch: 9| Step: 14
Training loss: 3.1555380443152785
Validation loss: 2.474631977345386
Epoch: 9| Step: 15
Training loss: 2.603939036275364
Validation loss: 2.469802620003936
Epoch: 9| Step: 16
Training loss: 2.4571289625281927
Validation loss: 2.4934846027644486
Epoch: 9| Step: 17
Training loss: 3.157035050157404
Validation loss: 2.4222570078079144
Epoch: 9| Step: 18
Training loss: 2.806561367373211
Validation loss: 2.450287318608822
Epoch: 9| Step: 19
Training loss: 2.9731329436694254
Validation loss: 2.4631432596681964
Epoch: 20| Step: 0
Training loss: 3.300505316221628
Validation loss: 2.4432187767907525
Epoch: 9| Step: 1
Training loss: 2.3223662358619666
Validation loss: 2.466665168827476
Epoch: 9| Step: 2
Training loss: 2.9898643937505893
Validation loss: 2.481480204286638
Epoch: 9| Step: 3
Training loss: 2.83062145001304
Validation loss: 2.4875277890831664
Epoch: 9| Step: 4
Training loss: 1.992687805782606
Validation loss: 2.4325808512770886
Epoch: 9| Step: 5
Training loss: 3.1329462874234486
Validation loss: 2.4684646664175767
Epoch: 9| Step: 6
Training loss: 3.006810088137914
Validation loss: 2.5189493380565295
Epoch: 9| Step: 7
Training loss: 2.6237172216773232
Validation loss: 2.475005637130242
Epoch: 9| Step: 8
Training loss: 2.5493064460786323
Validation loss: 2.4924879778045614
Epoch: 9| Step: 9
Training loss: 2.9072629742429235
Validation loss: 2.4784610233503166
Epoch: 9| Step: 10
Training loss: 2.824375259051614
Validation loss: 2.4593409588358175
Epoch: 9| Step: 11
Training loss: 3.1978087432907856
Validation loss: 2.482658738755961
Epoch: 9| Step: 12
Training loss: 3.3853451452280807
Validation loss: 2.5072273623792527
Epoch: 9| Step: 13
Training loss: 4.3530792387277515
Validation loss: 2.462313756781725
Epoch: 9| Step: 14
Training loss: 3.10396085393938
Validation loss: 2.484877254393685
Epoch: 9| Step: 15
Training loss: 2.6986915526216415
Validation loss: 2.4866470299361754
Epoch: 9| Step: 16
Training loss: 2.642002265703961
Validation loss: 2.510857154071547
Epoch: 9| Step: 17
Training loss: 3.115163657602512
Validation loss: 2.478062708134284
Epoch: 9| Step: 18
Training loss: 2.920793465756265
Validation loss: 2.4746425685214772
Epoch: 9| Step: 19
Training loss: 2.62470161921985
Validation loss: 2.447314080951646
Epoch: 21| Step: 0
Training loss: 2.36096632893783
Validation loss: 2.478569516325879
Epoch: 9| Step: 1
Training loss: 2.274397290218321
Validation loss: 2.4922461407315355
Epoch: 9| Step: 2
Training loss: 2.4352194069586575
Validation loss: 2.484807561775393
Epoch: 9| Step: 3
Training loss: 2.972744472964013
Validation loss: 2.500884684951204
Epoch: 9| Step: 4
Training loss: 2.8189933418068094
Validation loss: 2.4480227608762504
Epoch: 9| Step: 5
Training loss: 4.4640777277862
Validation loss: 2.4497121813197777
Epoch: 9| Step: 6
Training loss: 3.336834753365028
Validation loss: 2.393065195199435
Epoch: 9| Step: 7
Training loss: 3.346768024348456
Validation loss: 2.458063098176165
Epoch: 9| Step: 8
Training loss: 2.9466245445704544
Validation loss: 2.457956928860439
Epoch: 9| Step: 9
Training loss: 3.267028652947085
Validation loss: 2.446660185834557
Epoch: 9| Step: 10
Training loss: 2.0882327135855494
Validation loss: 2.4458306805959023
Epoch: 9| Step: 11
Training loss: 3.1341088863754742
Validation loss: 2.419395628453447
Epoch: 9| Step: 12
Training loss: 3.058371427404439
Validation loss: 2.449773313918693
Epoch: 9| Step: 13
Training loss: 2.153534658407749
Validation loss: 2.462112353810508
Epoch: 9| Step: 14
Training loss: 2.8699136605384687
Validation loss: 2.446836376163695
Epoch: 9| Step: 15
Training loss: 3.2440950596024933
Validation loss: 2.4453027754845547
Epoch: 9| Step: 16
Training loss: 2.8016151878563975
Validation loss: 2.414115816086043
Epoch: 9| Step: 17
Training loss: 3.205091514768649
Validation loss: 2.4264052143856394
Epoch: 9| Step: 18
Training loss: 2.7342020906546542
Validation loss: 2.405224502636163
Epoch: 9| Step: 19
Training loss: 2.796704676039805
Validation loss: 2.4669930777511824
Epoch: 22| Step: 0
Training loss: 2.479768717348561
Validation loss: 2.4176590147672785
Epoch: 9| Step: 1
Training loss: 3.381402195239312
Validation loss: 2.4667408965940254
Epoch: 9| Step: 2
Training loss: 3.1453149802155056
Validation loss: 2.438556119126084
Epoch: 9| Step: 3
Training loss: 2.437497848118541
Validation loss: 2.424609170228514
Epoch: 9| Step: 4
Training loss: 2.4971743827917363
Validation loss: 2.41208064479945
Epoch: 9| Step: 5
Training loss: 2.8129349266306782
Validation loss: 2.463273157583041
Epoch: 9| Step: 6
Training loss: 2.9595758935884153
Validation loss: 2.4326544677038493
Epoch: 9| Step: 7
Training loss: 3.664872915606874
Validation loss: 2.473764061508523
Epoch: 9| Step: 8
Training loss: 2.303182440239449
Validation loss: 2.443748372756949
Epoch: 9| Step: 9
Training loss: 1.8867665160393756
Validation loss: 2.376046684270507
Epoch: 9| Step: 10
Training loss: 2.7878948941224144
Validation loss: 2.433547374218657
Epoch: 9| Step: 11
Training loss: 3.4534108315490006
Validation loss: 2.4338351566707166
Epoch: 9| Step: 12
Training loss: 3.0977406051329495
Validation loss: 2.4295015067282066
Epoch: 9| Step: 13
Training loss: 3.1548631094904933
Validation loss: 2.441004890985307
Epoch: 9| Step: 14
Training loss: 2.726392680566213
Validation loss: 2.4253576380710276
Epoch: 9| Step: 15
Training loss: 3.137705494507678
Validation loss: 2.474697621461299
Epoch: 9| Step: 16
Training loss: 3.1107237684478553
Validation loss: 2.4804707724413775
Epoch: 9| Step: 17
Training loss: 3.2558743133842967
Validation loss: 2.391785577366023
Epoch: 9| Step: 18
Training loss: 3.338692235700464
Validation loss: 2.4762713700725127
Epoch: 9| Step: 19
Training loss: 2.5022052575314184
Validation loss: 2.431624851880573
Epoch: 23| Step: 0
Training loss: 2.258459928936166
Validation loss: 2.4907223299305774
Epoch: 9| Step: 1
Training loss: 2.72214042341725
Validation loss: 2.4659382652243167
Epoch: 9| Step: 2
Training loss: 3.2129436082732368
Validation loss: 2.425580331197555
Epoch: 9| Step: 3
Training loss: 3.046918506800758
Validation loss: 2.40501015140993
Epoch: 9| Step: 4
Training loss: 2.620212184962522
Validation loss: 2.4114499102953295
Epoch: 9| Step: 5
Training loss: 3.5712771792340576
Validation loss: 2.4291245826829266
Epoch: 9| Step: 6
Training loss: 2.8364274203413453
Validation loss: 2.4374165163293915
Epoch: 9| Step: 7
Training loss: 2.1059062552748777
Validation loss: 2.454991368158449
Epoch: 9| Step: 8
Training loss: 3.4899070172097035
Validation loss: 2.3964251495962348
Epoch: 9| Step: 9
Training loss: 2.937722218001416
Validation loss: 2.4218759889825225
Epoch: 9| Step: 10
Training loss: 3.533273707792427
Validation loss: 2.406588005389082
Epoch: 9| Step: 11
Training loss: 3.334661950131568
Validation loss: 2.403266535734477
Epoch: 9| Step: 12
Training loss: 2.031921393135591
Validation loss: 2.4168447169974003
Epoch: 9| Step: 13
Training loss: 2.949436204990223
Validation loss: 2.4273918363402367
Epoch: 9| Step: 14
Training loss: 2.8523983083212565
Validation loss: 2.461852190962847
Epoch: 9| Step: 15
Training loss: 2.6277084909578816
Validation loss: 2.4149313445506686
Epoch: 9| Step: 16
Training loss: 2.8321807611396435
Validation loss: 2.4222971221850367
Epoch: 9| Step: 17
Training loss: 3.437124613292309
Validation loss: 2.413512004093073
Epoch: 9| Step: 18
Training loss: 3.2190756031270005
Validation loss: 2.416223191835137
Epoch: 9| Step: 19
Training loss: 2.307207391604833
Validation loss: 2.38271945194192
Epoch: 24| Step: 0
Training loss: 2.3396880491288425
Validation loss: 2.4319037074982277
Epoch: 9| Step: 1
Training loss: 1.8515661054487575
Validation loss: 2.430026841795911
Epoch: 9| Step: 2
Training loss: 2.9314888667728525
Validation loss: 2.4405884708186756
Epoch: 9| Step: 3
Training loss: 3.64547445801611
Validation loss: 2.4348595499045245
Epoch: 9| Step: 4
Training loss: 2.6776963557487408
Validation loss: 2.3728627870281023
Epoch: 9| Step: 5
Training loss: 3.318657963225479
Validation loss: 2.3929110691592608
Epoch: 9| Step: 6
Training loss: 3.3324510996293553
Validation loss: 2.40688406575913
Epoch: 9| Step: 7
Training loss: 2.2084550164244487
Validation loss: 2.43330916508036
Epoch: 9| Step: 8
Training loss: 3.36180204500609
Validation loss: 2.4575363513729966
Epoch: 9| Step: 9
Training loss: 3.4910766746473216
Validation loss: 2.4389991660580135
Epoch: 9| Step: 10
Training loss: 3.408088817701684
Validation loss: 2.4056081756702237
Epoch: 9| Step: 11
Training loss: 2.1009714649773734
Validation loss: 2.424370958376515
Epoch: 9| Step: 12
Training loss: 2.7495820854990782
Validation loss: 2.420635345511314
Epoch: 9| Step: 13
Training loss: 3.107793818092102
Validation loss: 2.412780496009674
Epoch: 9| Step: 14
Training loss: 2.9033006038054565
Validation loss: 2.454879938627814
Epoch: 9| Step: 15
Training loss: 2.465773901172137
Validation loss: 2.3796642231937577
Epoch: 9| Step: 16
Training loss: 2.647766838566945
Validation loss: 2.413887019968469
Epoch: 9| Step: 17
Training loss: 2.5480791299530794
Validation loss: 2.379211832518993
Epoch: 9| Step: 18
Training loss: 3.2108240409166795
Validation loss: 2.4305834055103386
Epoch: 9| Step: 19
Training loss: 3.2673115003015005
Validation loss: 2.4237556399356026
Epoch: 25| Step: 0
Training loss: 2.74048981458208
Validation loss: 2.3822744573853147
Epoch: 9| Step: 1
Training loss: 2.887514492510472
Validation loss: 2.4329450253810503
Epoch: 9| Step: 2
Training loss: 2.960192906305517
Validation loss: 2.440479475265168
Epoch: 9| Step: 3
Training loss: 2.2567808969042784
Validation loss: 2.3786464160097633
Epoch: 9| Step: 4
Training loss: 1.8184643970158205
Validation loss: 2.4093214238208374
Epoch: 9| Step: 5
Training loss: 2.8673649454947054
Validation loss: 2.419000660323457
Epoch: 9| Step: 6
Training loss: 3.1333768341074912
Validation loss: 2.4481250042178297
Epoch: 9| Step: 7
Training loss: 1.5048537403147788
Validation loss: 2.4605271469583174
Epoch: 9| Step: 8
Training loss: 2.609364766540562
Validation loss: 2.416804312329407
Epoch: 9| Step: 9
Training loss: 3.0186752152114082
Validation loss: 2.3721156810951656
Epoch: 9| Step: 10
Training loss: 3.7843713409128936
Validation loss: 2.415140380671105
Epoch: 9| Step: 11
Training loss: 2.7169257873183
Validation loss: 2.386637245361777
Epoch: 9| Step: 12
Training loss: 3.11042008975727
Validation loss: 2.4255445138492555
Epoch: 9| Step: 13
Training loss: 3.3362988314265443
Validation loss: 2.439117207855894
Epoch: 9| Step: 14
Training loss: 3.246330830974524
Validation loss: 2.4596588088800284
Epoch: 9| Step: 15
Training loss: 2.1667873153351858
Validation loss: 2.3980901685559153
Epoch: 9| Step: 16
Training loss: 3.0869271924645627
Validation loss: 2.3898644145316874
Epoch: 9| Step: 17
Training loss: 2.9543982289052533
Validation loss: 2.4498509217468616
Epoch: 9| Step: 18
Training loss: 3.6198376696108205
Validation loss: 2.411854709350705
Epoch: 9| Step: 19
Training loss: 3.317023158123977
Validation loss: 2.390030347655828
Epoch: 26| Step: 0
Training loss: 2.3908127854338357
Validation loss: 2.3860960807696383
Epoch: 9| Step: 1
Training loss: 3.0357503616369232
Validation loss: 2.4413313397002705
Epoch: 9| Step: 2
Training loss: 3.5817322517829155
Validation loss: 2.405194037990557
Epoch: 9| Step: 3
Training loss: 2.8549535367428396
Validation loss: 2.406204907632091
Epoch: 9| Step: 4
Training loss: 2.9552825635144266
Validation loss: 2.415324139485823
Epoch: 9| Step: 5
Training loss: 3.2621453103374836
Validation loss: 2.385154471901522
Epoch: 9| Step: 6
Training loss: 2.2997556515141215
Validation loss: 2.3979247538059614
Epoch: 9| Step: 7
Training loss: 2.751784092711783
Validation loss: 2.431037408256177
Epoch: 9| Step: 8
Training loss: 3.461925081523366
Validation loss: 2.444407687561798
Epoch: 9| Step: 9
Training loss: 2.7209435744878787
Validation loss: 2.3731796024056306
Epoch: 9| Step: 10
Training loss: 3.4595489816584677
Validation loss: 2.3777495831601914
Epoch: 9| Step: 11
Training loss: 2.210555188449368
Validation loss: 2.4340013679238743
Epoch: 9| Step: 12
Training loss: 2.409344157653599
Validation loss: 2.3835579930309905
Epoch: 9| Step: 13
Training loss: 2.0154799771441647
Validation loss: 2.423860201079106
Epoch: 9| Step: 14
Training loss: 2.9836185155631294
Validation loss: 2.4349163359814834
Epoch: 9| Step: 15
Training loss: 2.8301980866569743
Validation loss: 2.373750663550618
Epoch: 9| Step: 16
Training loss: 3.2404115523816714
Validation loss: 2.398804708975371
Epoch: 9| Step: 17
Training loss: 3.5393516304528516
Validation loss: 2.3821455343456965
Epoch: 9| Step: 18
Training loss: 2.2491986649130897
Validation loss: 2.393561436651593
Epoch: 9| Step: 19
Training loss: 3.279777705172886
Validation loss: 2.389828506087215
Epoch: 27| Step: 0
Training loss: 3.0676590419537604
Validation loss: 2.4309077167790814
Epoch: 9| Step: 1
Training loss: 2.9271740520352054
Validation loss: 2.3864640202059437
Epoch: 9| Step: 2
Training loss: 3.139981180122492
Validation loss: 2.3642699329791106
Epoch: 9| Step: 3
Training loss: 2.9459326619871002
Validation loss: 2.413023816683761
Epoch: 9| Step: 4
Training loss: 2.2065801919126042
Validation loss: 2.385905014600439
Epoch: 9| Step: 5
Training loss: 2.1457926058067702
Validation loss: 2.4127344181031147
Epoch: 9| Step: 6
Training loss: 3.4719936566888197
Validation loss: 2.433652022980303
Epoch: 9| Step: 7
Training loss: 3.270627802973909
Validation loss: 2.4048335369691625
Epoch: 9| Step: 8
Training loss: 2.3671611117160576
Validation loss: 2.3755520995877744
Epoch: 9| Step: 9
Training loss: 3.2171649178022257
Validation loss: 2.3728324263208234
Epoch: 9| Step: 10
Training loss: 2.9394729157348713
Validation loss: 2.385002143747285
Epoch: 9| Step: 11
Training loss: 2.6825536408620603
Validation loss: 2.4293687997932576
Epoch: 9| Step: 12
Training loss: 2.2995092117115106
Validation loss: 2.387396305770636
Epoch: 9| Step: 13
Training loss: 2.37007272471943
Validation loss: 2.397337118120679
Epoch: 9| Step: 14
Training loss: 1.7198706008230502
Validation loss: 2.435657307104915
Epoch: 9| Step: 15
Training loss: 3.662165233948986
Validation loss: 2.4154854001784787
Epoch: 9| Step: 16
Training loss: 3.528597755620734
Validation loss: 2.390869730607049
Epoch: 9| Step: 17
Training loss: 3.1172662787174916
Validation loss: 2.4040600222132995
Epoch: 9| Step: 18
Training loss: 2.9439606738988364
Validation loss: 2.390952590268997
Epoch: 9| Step: 19
Training loss: 2.726067877995604
Validation loss: 2.3958787908249866
Epoch: 28| Step: 0
Training loss: 2.5725060468626735
Validation loss: 2.4289303392769233
Epoch: 9| Step: 1
Training loss: 2.422075029541915
Validation loss: 2.367676095039856
Epoch: 9| Step: 2
Training loss: 2.7292928496642705
Validation loss: 2.371842110447547
Epoch: 9| Step: 3
Training loss: 2.8257201703098622
Validation loss: 2.378019606865102
Epoch: 9| Step: 4
Training loss: 3.2314882526328788
Validation loss: 2.40274723034382
Epoch: 9| Step: 5
Training loss: 3.7291933765555916
Validation loss: 2.3719394117941826
Epoch: 9| Step: 6
Training loss: 2.9080122660256214
Validation loss: 2.398904876138136
Epoch: 9| Step: 7
Training loss: 3.284586926273244
Validation loss: 2.393378764200012
Epoch: 9| Step: 8
Training loss: 2.717087862404594
Validation loss: 2.3347893235177
Epoch: 9| Step: 9
Training loss: 3.6204231571281724
Validation loss: 2.4153259773560016
Epoch: 9| Step: 10
Training loss: 3.330128241466724
Validation loss: 2.362722996577294
Epoch: 9| Step: 11
Training loss: 2.757083872214277
Validation loss: 2.4008629293430928
Epoch: 9| Step: 12
Training loss: 2.723404418954502
Validation loss: 2.391095188108639
Epoch: 9| Step: 13
Training loss: 2.0040989833302523
Validation loss: 2.34517711834987
Epoch: 9| Step: 14
Training loss: 2.5678667763708
Validation loss: 2.4130504806755932
Epoch: 9| Step: 15
Training loss: 3.3644524106908853
Validation loss: 2.433079922147669
Epoch: 9| Step: 16
Training loss: 2.185578183247323
Validation loss: 2.4183276943114276
Epoch: 9| Step: 17
Training loss: 2.972927968343003
Validation loss: 2.3870130303699617
Epoch: 9| Step: 18
Training loss: 2.77728305755701
Validation loss: 2.3365835888260578
Epoch: 9| Step: 19
Training loss: 2.447368793185281
Validation loss: 2.373876868043704
Epoch: 29| Step: 0
Training loss: 3.4443017424142517
Validation loss: 2.340149754027978
Epoch: 9| Step: 1
Training loss: 2.835413188124033
Validation loss: 2.3753273334136398
Epoch: 9| Step: 2
Training loss: 3.517224842146143
Validation loss: 2.3925172464434112
Epoch: 9| Step: 3
Training loss: 2.7649573258319693
Validation loss: 2.384242170474372
Epoch: 9| Step: 4
Training loss: 2.0830135354322463
Validation loss: 2.3627840011033787
Epoch: 9| Step: 5
Training loss: 3.0460805003799427
Validation loss: 2.352883115897725
Epoch: 9| Step: 6
Training loss: 2.2850391847017764
Validation loss: 2.405097325529976
Epoch: 9| Step: 7
Training loss: 2.8473554957349103
Validation loss: 2.3779415431732924
Epoch: 9| Step: 8
Training loss: 3.2888353137930824
Validation loss: 2.4243696292438632
Epoch: 9| Step: 9
Training loss: 2.654689644671781
Validation loss: 2.370359092166179
Epoch: 9| Step: 10
Training loss: 2.3774935030522513
Validation loss: 2.388330208354831
Epoch: 9| Step: 11
Training loss: 2.7407211339046857
Validation loss: 2.376352160667704
Epoch: 9| Step: 12
Training loss: 3.220366729324145
Validation loss: 2.370077282436942
Epoch: 9| Step: 13
Training loss: 2.778588296472719
Validation loss: 2.368625840896499
Epoch: 9| Step: 14
Training loss: 2.001972775246549
Validation loss: 2.3858690735009374
Epoch: 9| Step: 15
Training loss: 2.3504244563093057
Validation loss: 2.4245931305522617
Epoch: 9| Step: 16
Training loss: 2.880040766904309
Validation loss: 2.3750972644666066
Epoch: 9| Step: 17
Training loss: 3.6139849663122505
Validation loss: 2.3864239468812762
Epoch: 9| Step: 18
Training loss: 3.4699590826782707
Validation loss: 2.3878795388048104
Epoch: 9| Step: 19
Training loss: 2.4631622430889135
Validation loss: 2.41318500154171
Epoch: 30| Step: 0
Training loss: 2.4335137073952984
Validation loss: 2.341763158852418
Epoch: 9| Step: 1
Training loss: 3.251481232184352
Validation loss: 2.4110990245557646
Epoch: 9| Step: 2
Training loss: 3.0204323513448026
Validation loss: 2.398413479683876
Epoch: 9| Step: 3
Training loss: 2.5854651258805976
Validation loss: 2.365433157092884
Epoch: 9| Step: 4
Training loss: 2.7811074381091263
Validation loss: 2.363367335656534
Epoch: 9| Step: 5
Training loss: 3.5018256739216915
Validation loss: 2.3705748958825894
Epoch: 9| Step: 6
Training loss: 2.0344585020680475
Validation loss: 2.365566194968078
Epoch: 9| Step: 7
Training loss: 2.9398430752557023
Validation loss: 2.354288441169228
Epoch: 9| Step: 8
Training loss: 2.9704340926420953
Validation loss: 2.374756159803973
Epoch: 9| Step: 9
Training loss: 2.524200229700802
Validation loss: 2.331367351856891
Epoch: 9| Step: 10
Training loss: 3.6544328396171766
Validation loss: 2.388261310020151
Epoch: 9| Step: 11
Training loss: 2.5819115776919106
Validation loss: 2.3806848080244283
Epoch: 9| Step: 12
Training loss: 2.719975074906307
Validation loss: 2.380328097470547
Epoch: 9| Step: 13
Training loss: 2.3823235682419948
Validation loss: 2.3802538875444674
Epoch: 9| Step: 14
Training loss: 2.7778486391142
Validation loss: 2.355664998932242
Epoch: 9| Step: 15
Training loss: 2.912327963532832
Validation loss: 2.3342048072631005
Epoch: 9| Step: 16
Training loss: 2.0550858144175783
Validation loss: 2.340301063854179
Epoch: 9| Step: 17
Training loss: 2.0267907125172524
Validation loss: 2.3510526660623503
Epoch: 9| Step: 18
Training loss: 4.1778151837381055
Validation loss: 2.383673842010505
Epoch: 9| Step: 19
Training loss: 2.6797857238740015
Validation loss: 2.347301283388082
Epoch: 31| Step: 0
Training loss: 2.837934647262651
Validation loss: 2.3534054233623767
Epoch: 9| Step: 1
Training loss: 2.43293197230678
Validation loss: 2.3713420543366253
Epoch: 9| Step: 2
Training loss: 2.945611346638306
Validation loss: 2.3645330228412647
Epoch: 9| Step: 3
Training loss: 2.6769804780153503
Validation loss: 2.3822056555531104
Epoch: 9| Step: 4
Training loss: 3.39547705780399
Validation loss: 2.393517606509178
Epoch: 9| Step: 5
Training loss: 2.476971132278861
Validation loss: 2.4057486213984833
Epoch: 9| Step: 6
Training loss: 2.478733206503071
Validation loss: 2.3819048429921956
Epoch: 9| Step: 7
Training loss: 3.2390374380964824
Validation loss: 2.397884920605273
Epoch: 9| Step: 8
Training loss: 2.3355922890430185
Validation loss: 2.3875025300427213
Epoch: 9| Step: 9
Training loss: 1.717752687503476
Validation loss: 2.3612395067633924
Epoch: 9| Step: 10
Training loss: 2.6583512914483514
Validation loss: 2.438460205254758
Epoch: 9| Step: 11
Training loss: 2.7486069358659897
Validation loss: 2.3649626534194788
Epoch: 9| Step: 12
Training loss: 2.0004021717074236
Validation loss: 2.395001479276736
Epoch: 9| Step: 13
Training loss: 3.012634692208182
Validation loss: 2.3804003562119784
Epoch: 9| Step: 14
Training loss: 2.720215851689927
Validation loss: 2.34345356834486
Epoch: 9| Step: 15
Training loss: 4.295059097824917
Validation loss: 2.4131775952487287
Epoch: 9| Step: 16
Training loss: 2.9690092274775233
Validation loss: 2.3454854598591806
Epoch: 9| Step: 17
Training loss: 2.7919348023352413
Validation loss: 2.4223700645073953
Epoch: 9| Step: 18
Training loss: 3.023184990010648
Validation loss: 2.388771635456637
Epoch: 9| Step: 19
Training loss: 3.131251376640946
Validation loss: 2.352594375360485
Epoch: 32| Step: 0
Training loss: 2.5902728937788786
Validation loss: 2.385085164482801
Epoch: 9| Step: 1
Training loss: 2.21537943825667
Validation loss: 2.358541184741023
Epoch: 9| Step: 2
Training loss: 3.533446312543595
Validation loss: 2.3800255711930323
Epoch: 9| Step: 3
Training loss: 2.6616631495628296
Validation loss: 2.3567897692894224
Epoch: 9| Step: 4
Training loss: 2.6403589058156043
Validation loss: 2.358892112495203
Epoch: 9| Step: 5
Training loss: 2.564489569190774
Validation loss: 2.371414539047211
Epoch: 9| Step: 6
Training loss: 3.7255278296582492
Validation loss: 2.3338047870166116
Epoch: 9| Step: 7
Training loss: 2.747001834236924
Validation loss: 2.3570618593306705
Epoch: 9| Step: 8
Training loss: 2.8240022906113107
Validation loss: 2.3469045668612907
Epoch: 9| Step: 9
Training loss: 2.635811204490753
Validation loss: 2.3158183302370636
Epoch: 9| Step: 10
Training loss: 2.5359799497275057
Validation loss: 2.359355406640519
Epoch: 9| Step: 11
Training loss: 2.8432326632257667
Validation loss: 2.2866428115193305
Epoch: 9| Step: 12
Training loss: 2.8906622806928706
Validation loss: 2.3255765229109375
Epoch: 9| Step: 13
Training loss: 2.3893619766299516
Validation loss: 2.3596989732208327
Epoch: 9| Step: 14
Training loss: 3.9135543280159686
Validation loss: 2.3552132591651675
Epoch: 9| Step: 15
Training loss: 3.0641170047501167
Validation loss: 2.356796146652129
Epoch: 9| Step: 16
Training loss: 2.6184458881502866
Validation loss: 2.3758258014071076
Epoch: 9| Step: 17
Training loss: 2.2424366244373375
Validation loss: 2.363981364524068
Epoch: 9| Step: 18
Training loss: 2.777514660347636
Validation loss: 2.3648508090456777
Epoch: 9| Step: 19
Training loss: 2.5404553158484227
Validation loss: 2.397566333441463
Epoch: 33| Step: 0
Training loss: 3.3980754791013577
Validation loss: 2.3385988914973783
Epoch: 9| Step: 1
Training loss: 2.7105837544440416
Validation loss: 2.3393409322790455
Epoch: 9| Step: 2
Training loss: 2.2607783600980325
Validation loss: 2.2941212527190853
Epoch: 9| Step: 3
Training loss: 2.1329217121263064
Validation loss: 2.3902286073076997
Epoch: 9| Step: 4
Training loss: 3.02360025603597
Validation loss: 2.361743548219556
Epoch: 9| Step: 5
Training loss: 3.4743025045419413
Validation loss: 2.370590720362268
Epoch: 9| Step: 6
Training loss: 3.35422991264534
Validation loss: 2.3374164922559473
Epoch: 9| Step: 7
Training loss: 2.767142186798143
Validation loss: 2.366101601742155
Epoch: 9| Step: 8
Training loss: 2.356719183311936
Validation loss: 2.34728686835139
Epoch: 9| Step: 9
Training loss: 3.141882194053984
Validation loss: 2.330177213903099
Epoch: 9| Step: 10
Training loss: 3.1215486923005575
Validation loss: 2.348759798872051
Epoch: 9| Step: 11
Training loss: 2.866261512011215
Validation loss: 2.3154749153522824
Epoch: 9| Step: 12
Training loss: 3.2300490783647575
Validation loss: 2.34296234673458
Epoch: 9| Step: 13
Training loss: 2.303942543796869
Validation loss: 2.3620388531013483
Epoch: 9| Step: 14
Training loss: 2.0303808847154325
Validation loss: 2.379017906096372
Epoch: 9| Step: 15
Training loss: 2.1068679039042655
Validation loss: 2.3639131490384946
Epoch: 9| Step: 16
Training loss: 2.4061521039592852
Validation loss: 2.3679956199250154
Epoch: 9| Step: 17
Training loss: 2.8118297202048432
Validation loss: 2.314748256690612
Epoch: 9| Step: 18
Training loss: 3.29999080425484
Validation loss: 2.3748873035232316
Epoch: 9| Step: 19
Training loss: 2.9847041243173162
Validation loss: 2.3005017307648514
Epoch: 34| Step: 0
Training loss: 3.116401745421663
Validation loss: 2.3637056895666317
Epoch: 9| Step: 1
Training loss: 2.1966444434439283
Validation loss: 2.3809828332585337
Epoch: 9| Step: 2
Training loss: 3.3783679687752026
Validation loss: 2.3849884131019765
Epoch: 9| Step: 3
Training loss: 2.3469269646429485
Validation loss: 2.37151158852562
Epoch: 9| Step: 4
Training loss: 2.288494365089285
Validation loss: 2.323586003524987
Epoch: 9| Step: 5
Training loss: 3.452449818881093
Validation loss: 2.3303434880258176
Epoch: 9| Step: 6
Training loss: 2.6698724034713477
Validation loss: 2.3462608314133324
Epoch: 9| Step: 7
Training loss: 3.078538895872267
Validation loss: 2.3323641915898694
Epoch: 9| Step: 8
Training loss: 3.0000435508110037
Validation loss: 2.3098529302845168
Epoch: 9| Step: 9
Training loss: 3.409480111995704
Validation loss: 2.3420288869754495
Epoch: 9| Step: 10
Training loss: 2.281125836063424
Validation loss: 2.3596590122208805
Epoch: 9| Step: 11
Training loss: 3.478690398429064
Validation loss: 2.3430246647476247
Epoch: 9| Step: 12
Training loss: 2.5860448163862895
Validation loss: 2.313202415604497
Epoch: 9| Step: 13
Training loss: 2.6654110177521755
Validation loss: 2.250041942129519
Epoch: 9| Step: 14
Training loss: 2.6024002696633164
Validation loss: 2.281507106091854
Epoch: 9| Step: 15
Training loss: 2.70775177409322
Validation loss: 2.3326243933368986
Epoch: 9| Step: 16
Training loss: 2.6546673716140696
Validation loss: 2.31811315431536
Epoch: 9| Step: 17
Training loss: 3.08883307091695
Validation loss: 2.309883811740382
Epoch: 9| Step: 18
Training loss: 1.9324119578412207
Validation loss: 2.3073259381355022
Epoch: 9| Step: 19
Training loss: 2.420716827092796
Validation loss: 2.3302654979496675
Epoch: 35| Step: 0
Training loss: 2.2218820735427136
Validation loss: 2.337299537441883
Epoch: 9| Step: 1
Training loss: 2.1010203743572684
Validation loss: 2.3219219975079493
Epoch: 9| Step: 2
Training loss: 2.8882086474637148
Validation loss: 2.3225703715931263
Epoch: 9| Step: 3
Training loss: 2.921887402839652
Validation loss: 2.331773392789738
Epoch: 9| Step: 4
Training loss: 2.121516345448205
Validation loss: 2.3633018162810893
Epoch: 9| Step: 5
Training loss: 2.1791877857398103
Validation loss: 2.352920852724522
Epoch: 9| Step: 6
Training loss: 2.6376608740752094
Validation loss: 2.365872835201601
Epoch: 9| Step: 7
Training loss: 2.256738849633053
Validation loss: 2.3570582962451976
Epoch: 9| Step: 8
Training loss: 2.7127769891325997
Validation loss: 2.373557912652377
Epoch: 9| Step: 9
Training loss: 2.6157627156052565
Validation loss: 2.3556534916558487
Epoch: 9| Step: 10
Training loss: 2.6575052324819506
Validation loss: 2.393909939853104
Epoch: 9| Step: 11
Training loss: 3.313347474137749
Validation loss: 2.366934186756262
Epoch: 9| Step: 12
Training loss: 2.1371341280653287
Validation loss: 2.3608352965973776
Epoch: 9| Step: 13
Training loss: 3.2696913813272923
Validation loss: 2.346882315862185
Epoch: 9| Step: 14
Training loss: 3.4710211664475983
Validation loss: 2.352090469650664
Epoch: 9| Step: 15
Training loss: 3.704203388273816
Validation loss: 2.3108819968592162
Epoch: 9| Step: 16
Training loss: 3.3912994135945125
Validation loss: 2.338093326903666
Epoch: 9| Step: 17
Training loss: 3.738017329004899
Validation loss: 2.393633870056278
Epoch: 9| Step: 18
Training loss: 2.244403448559279
Validation loss: 2.3655714513334263
Epoch: 9| Step: 19
Training loss: 2.382131510495312
Validation loss: 2.3262883142225617
Epoch: 36| Step: 0
Training loss: 2.1022002092830427
Validation loss: 2.3336158844547645
Epoch: 9| Step: 1
Training loss: 3.3195439425302324
Validation loss: 2.3205782797856433
Epoch: 9| Step: 2
Training loss: 2.9108369786366826
Validation loss: 2.346689173298332
Epoch: 9| Step: 3
Training loss: 4.020064575283975
Validation loss: 2.34326547671427
Epoch: 9| Step: 4
Training loss: 2.734189970023168
Validation loss: 2.31631811944522
Epoch: 9| Step: 5
Training loss: 2.897501915313114
Validation loss: 2.33649864454109
Epoch: 9| Step: 6
Training loss: 2.9252952100668472
Validation loss: 2.33858174905682
Epoch: 9| Step: 7
Training loss: 2.802913519154991
Validation loss: 2.358145186997141
Epoch: 9| Step: 8
Training loss: 2.9177849033762935
Validation loss: 2.336182453341997
Epoch: 9| Step: 9
Training loss: 3.0395844705085815
Validation loss: 2.3412886158388733
Epoch: 9| Step: 10
Training loss: 3.004211965811078
Validation loss: 2.315289930509172
Epoch: 9| Step: 11
Training loss: 2.770529326394703
Validation loss: 2.365815792841526
Epoch: 9| Step: 12
Training loss: 2.5031923892204473
Validation loss: 2.3354676935112364
Epoch: 9| Step: 13
Training loss: 2.389703710218452
Validation loss: 2.3149436796672194
Epoch: 9| Step: 14
Training loss: 1.5973234319640057
Validation loss: 2.331686735865107
Epoch: 9| Step: 15
Training loss: 2.728256879592481
Validation loss: 2.2947881483714396
Epoch: 9| Step: 16
Training loss: 2.828913794683653
Validation loss: 2.3563621803883406
Epoch: 9| Step: 17
Training loss: 1.9647432760406818
Validation loss: 2.335359812928611
Epoch: 9| Step: 18
Training loss: 3.059388273091499
Validation loss: 2.248125244317049
Epoch: 9| Step: 19
Training loss: 2.5354622537176246
Validation loss: 2.3413397237407656
Epoch: 37| Step: 0
Training loss: 2.9325545866715923
Validation loss: 2.34297389124085
Epoch: 9| Step: 1
Training loss: 2.55075638716587
Validation loss: 2.3165809395786963
Epoch: 9| Step: 2
Training loss: 2.5827117807974003
Validation loss: 2.3451605969444156
Epoch: 9| Step: 3
Training loss: 2.8923595276322343
Validation loss: 2.2927888192094823
Epoch: 9| Step: 4
Training loss: 2.5913817843000198
Validation loss: 2.2959265476665722
Epoch: 9| Step: 5
Training loss: 2.3709559895498535
Validation loss: 2.358486157716356
Epoch: 9| Step: 6
Training loss: 2.9881821559856543
Validation loss: 2.341601047801424
Epoch: 9| Step: 7
Training loss: 3.216160742021155
Validation loss: 2.325631344149912
Epoch: 9| Step: 8
Training loss: 3.222356165005723
Validation loss: 2.3443361702750356
Epoch: 9| Step: 9
Training loss: 2.043682608237015
Validation loss: 2.3771774057749777
Epoch: 9| Step: 10
Training loss: 3.0147657998696955
Validation loss: 2.3415993885848465
Epoch: 9| Step: 11
Training loss: 3.3256752418432236
Validation loss: 2.3315649939325116
Epoch: 9| Step: 12
Training loss: 2.232723879807334
Validation loss: 2.3213352512991277
Epoch: 9| Step: 13
Training loss: 2.471457143928683
Validation loss: 2.3524459311846786
Epoch: 9| Step: 14
Training loss: 2.461793974535457
Validation loss: 2.3608457992784766
Epoch: 9| Step: 15
Training loss: 2.812496778698242
Validation loss: 2.3200730736793487
Epoch: 9| Step: 16
Training loss: 2.7498830423626353
Validation loss: 2.318464274695334
Epoch: 9| Step: 17
Training loss: 2.4650468697260686
Validation loss: 2.324442402064675
Epoch: 9| Step: 18
Training loss: 3.0063807659299275
Validation loss: 2.265415516257806
Epoch: 9| Step: 19
Training loss: 3.2976202099965124
Validation loss: 2.337380906116243
Epoch: 38| Step: 0
Training loss: 2.2256422851713995
Validation loss: 2.34724166366195
Epoch: 9| Step: 1
Training loss: 3.0777060906255227
Validation loss: 2.3393194223510925
Epoch: 9| Step: 2
Training loss: 3.5783310210373442
Validation loss: 2.369510529565163
Epoch: 9| Step: 3
Training loss: 2.1079191482065855
Validation loss: 2.330197024864778
Epoch: 9| Step: 4
Training loss: 2.98158509232602
Validation loss: 2.3465871199387385
Epoch: 9| Step: 5
Training loss: 2.358586969204759
Validation loss: 2.316381391416207
Epoch: 9| Step: 6
Training loss: 2.6600806943943818
Validation loss: 2.3587055103739702
Epoch: 9| Step: 7
Training loss: 3.4225719560815175
Validation loss: 2.311514950285208
Epoch: 9| Step: 8
Training loss: 1.9195215966335537
Validation loss: 2.3381862547132464
Epoch: 9| Step: 9
Training loss: 2.46096762986888
Validation loss: 2.3612497325911046
Epoch: 9| Step: 10
Training loss: 3.00464080440997
Validation loss: 2.322787009601158
Epoch: 9| Step: 11
Training loss: 2.6853954147630423
Validation loss: 2.3238125171207984
Epoch: 9| Step: 12
Training loss: 2.8707720310289675
Validation loss: 2.3460706580338577
Epoch: 9| Step: 13
Training loss: 3.2977000284440816
Validation loss: 2.3712417571125455
Epoch: 9| Step: 14
Training loss: 2.1979317566653447
Validation loss: 2.3850420461387607
Epoch: 9| Step: 15
Training loss: 2.9999443684823985
Validation loss: 2.315564563096592
Epoch: 9| Step: 16
Training loss: 3.413528645063484
Validation loss: 2.3191112685970303
Epoch: 9| Step: 17
Training loss: 1.9605884013288075
Validation loss: 2.3265205037241583
Epoch: 9| Step: 18
Training loss: 2.7358701269545858
Validation loss: 2.300477967814346
Epoch: 9| Step: 19
Training loss: 2.780550836700321
Validation loss: 2.308434883786678
Epoch: 39| Step: 0
Training loss: 2.258512078375164
Validation loss: 2.327047772171924
Epoch: 9| Step: 1
Training loss: 2.7266852670919626
Validation loss: 2.311893303886857
Epoch: 9| Step: 2
Training loss: 2.9194580526263643
Validation loss: 2.2771416869320746
Epoch: 9| Step: 3
Training loss: 2.3357302978886705
Validation loss: 2.3021921560946317
Epoch: 9| Step: 4
Training loss: 2.889675004894345
Validation loss: 2.338029605448976
Epoch: 9| Step: 5
Training loss: 2.41266668267666
Validation loss: 2.2907818669940396
Epoch: 9| Step: 6
Training loss: 2.7727944071753483
Validation loss: 2.3377380649149972
Epoch: 9| Step: 7
Training loss: 3.420000791047657
Validation loss: 2.292465459774358
Epoch: 9| Step: 8
Training loss: 3.615759549155553
Validation loss: 2.281635240264499
Epoch: 9| Step: 9
Training loss: 2.3375727310697245
Validation loss: 2.2908021265028875
Epoch: 9| Step: 10
Training loss: 3.076570844663169
Validation loss: 2.300394922936024
Epoch: 9| Step: 11
Training loss: 2.462675903543947
Validation loss: 2.280541023890468
Epoch: 9| Step: 12
Training loss: 2.3135002653518764
Validation loss: 2.3490486730071827
Epoch: 9| Step: 13
Training loss: 3.3035878184733085
Validation loss: 2.316607192845047
Epoch: 9| Step: 14
Training loss: 2.687565292629825
Validation loss: 2.337644606838175
Epoch: 9| Step: 15
Training loss: 2.5542372560522013
Validation loss: 2.329651167586982
Epoch: 9| Step: 16
Training loss: 2.4979243244714464
Validation loss: 2.2868135545540738
Epoch: 9| Step: 17
Training loss: 3.273365538905477
Validation loss: 2.3265889981359167
Epoch: 9| Step: 18
Training loss: 2.5417599478525355
Validation loss: 2.3200885694730675
Epoch: 9| Step: 19
Training loss: 2.788839208389222
Validation loss: 2.3280781391533876
Epoch: 40| Step: 0
Training loss: 2.5616590469071636
Validation loss: 2.3174271344052935
Epoch: 9| Step: 1
Training loss: 2.8299886559033243
Validation loss: 2.293973341200344
Epoch: 9| Step: 2
Training loss: 3.2564630068999123
Validation loss: 2.3381019005442116
Epoch: 9| Step: 3
Training loss: 3.1979080514864275
Validation loss: 2.2739724284187304
Epoch: 9| Step: 4
Training loss: 2.866571926798843
Validation loss: 2.3323352213220194
Epoch: 9| Step: 5
Training loss: 2.996681921569672
Validation loss: 2.3433434940481273
Epoch: 9| Step: 6
Training loss: 2.0450821807316313
Validation loss: 2.329693938876765
Epoch: 9| Step: 7
Training loss: 2.376353029027231
Validation loss: 2.3035296163917947
Epoch: 9| Step: 8
Training loss: 3.138412683273541
Validation loss: 2.3337406913936785
Epoch: 9| Step: 9
Training loss: 2.4477899937962913
Validation loss: 2.2866660768837272
Epoch: 9| Step: 10
Training loss: 2.6236470686889346
Validation loss: 2.283599108024031
Epoch: 9| Step: 11
Training loss: 2.616796481401112
Validation loss: 2.3122285843811197
Epoch: 9| Step: 12
Training loss: 3.0198878069115427
Validation loss: 2.304055787546513
Epoch: 9| Step: 13
Training loss: 2.8537452182403884
Validation loss: 2.3289274560010376
Epoch: 9| Step: 14
Training loss: 2.7926245417267763
Validation loss: 2.3090444277075366
Epoch: 9| Step: 15
Training loss: 2.3909957697953375
Validation loss: 2.2772369378002058
Epoch: 9| Step: 16
Training loss: 2.33740392477294
Validation loss: 2.3331668538474353
Epoch: 9| Step: 17
Training loss: 2.682210285223766
Validation loss: 2.292296924413755
Epoch: 9| Step: 18
Training loss: 3.1035076354916042
Validation loss: 2.2943762788821207
Epoch: 9| Step: 19
Training loss: 2.2473876410755294
Validation loss: 2.3231851536539527
Epoch: 41| Step: 0
Training loss: 3.4959825892331318
Validation loss: 2.2988313130836304
Epoch: 9| Step: 1
Training loss: 2.136666975492474
Validation loss: 2.320817959739516
Epoch: 9| Step: 2
Training loss: 2.1370211148466205
Validation loss: 2.304144722744264
Epoch: 9| Step: 3
Training loss: 3.018694960445853
Validation loss: 2.324130753638824
Epoch: 9| Step: 4
Training loss: 2.7082816974901642
Validation loss: 2.3348342095713472
Epoch: 9| Step: 5
Training loss: 2.405495364273289
Validation loss: 2.3426063661160152
Epoch: 9| Step: 6
Training loss: 3.041596207172772
Validation loss: 2.3325372138365514
Epoch: 9| Step: 7
Training loss: 3.2809924796639396
Validation loss: 2.325126553438103
Epoch: 9| Step: 8
Training loss: 2.6218296160765453
Validation loss: 2.304671446775711
Epoch: 9| Step: 9
Training loss: 2.6597963781507556
Validation loss: 2.321487274932608
Epoch: 9| Step: 10
Training loss: 2.2323020442330406
Validation loss: 2.3334437059301893
Epoch: 9| Step: 11
Training loss: 2.090192705058796
Validation loss: 2.300517262772563
Epoch: 9| Step: 12
Training loss: 3.115630179107249
Validation loss: 2.300623808518752
Epoch: 9| Step: 13
Training loss: 3.2891184604985546
Validation loss: 2.3188187812563545
Epoch: 9| Step: 14
Training loss: 3.129787287690095
Validation loss: 2.28478945605401
Epoch: 9| Step: 15
Training loss: 2.2389658468486053
Validation loss: 2.3090406723265486
Epoch: 9| Step: 16
Training loss: 2.8458096936548656
Validation loss: 2.3576032315973787
Epoch: 9| Step: 17
Training loss: 2.964908724790342
Validation loss: 2.3080532986037134
Epoch: 9| Step: 18
Training loss: 2.0697050535001082
Validation loss: 2.318004690056086
Epoch: 9| Step: 19
Training loss: 2.8131371518143604
Validation loss: 2.3586027839941957
Epoch: 42| Step: 0
Training loss: 3.2181627052574213
Validation loss: 2.3101541413088214
Epoch: 9| Step: 1
Training loss: 2.3294813058483372
Validation loss: 2.3119716248480784
Epoch: 9| Step: 2
Training loss: 2.0635138822864545
Validation loss: 2.3026031848263133
Epoch: 9| Step: 3
Training loss: 3.7742619531930743
Validation loss: 2.315499366767869
Epoch: 9| Step: 4
Training loss: 2.8322871651613117
Validation loss: 2.349010861822434
Epoch: 9| Step: 5
Training loss: 2.3912704693426146
Validation loss: 2.376387523283894
Epoch: 9| Step: 6
Training loss: 2.71688866751607
Validation loss: 2.4135379597990223
Epoch: 9| Step: 7
Training loss: 2.1971779496396766
Validation loss: 2.3592759135730104
Epoch: 9| Step: 8
Training loss: 3.347717498254612
Validation loss: 2.379701139202398
Epoch: 9| Step: 9
Training loss: 2.8754326867954156
Validation loss: 2.405378510737074
Epoch: 9| Step: 10
Training loss: 2.532085422123515
Validation loss: 2.32070926352006
Epoch: 9| Step: 11
Training loss: 2.6251276076044903
Validation loss: 2.3694644599696066
Epoch: 9| Step: 12
Training loss: 2.9480516562316303
Validation loss: 2.2981188169336515
Epoch: 9| Step: 13
Training loss: 2.6389244969514287
Validation loss: 2.336459267817854
Epoch: 9| Step: 14
Training loss: 2.552956650972195
Validation loss: 2.3419556606290257
Epoch: 9| Step: 15
Training loss: 2.2275786640906565
Validation loss: 2.3211624656744356
Epoch: 9| Step: 16
Training loss: 3.1664086956218966
Validation loss: 2.325275103147335
Epoch: 9| Step: 17
Training loss: 3.0399686349957316
Validation loss: 2.272899549432375
Epoch: 9| Step: 18
Training loss: 2.089826409098616
Validation loss: 2.316743978902389
Epoch: 9| Step: 19
Training loss: 3.0340220567257323
Validation loss: 2.308506934036274
Epoch: 43| Step: 0
Training loss: 3.447183183327231
Validation loss: 2.3133866238966205
Epoch: 9| Step: 1
Training loss: 3.1719142366434787
Validation loss: 2.3031314972976036
Epoch: 9| Step: 2
Training loss: 2.8508090761415152
Validation loss: 2.293875817147146
Epoch: 9| Step: 3
Training loss: 2.3424343231015965
Validation loss: 2.3270388961244857
Epoch: 9| Step: 4
Training loss: 2.7681395742584374
Validation loss: 2.3151834301857135
Epoch: 9| Step: 5
Training loss: 2.7777887301758906
Validation loss: 2.3017119195134614
Epoch: 9| Step: 6
Training loss: 1.862426433774479
Validation loss: 2.344060938919057
Epoch: 9| Step: 7
Training loss: 3.2300468639835977
Validation loss: 2.3034354380021504
Epoch: 9| Step: 8
Training loss: 2.8960653710653506
Validation loss: 2.276580992904219
Epoch: 9| Step: 9
Training loss: 3.396616621113604
Validation loss: 2.2619342881074225
Epoch: 9| Step: 10
Training loss: 2.719058315290101
Validation loss: 2.308300536814588
Epoch: 9| Step: 11
Training loss: 3.0272334909356724
Validation loss: 2.296671799720824
Epoch: 9| Step: 12
Training loss: 3.0279907322770754
Validation loss: 2.2806831794006963
Epoch: 9| Step: 13
Training loss: 2.154755115623788
Validation loss: 2.291809562674775
Epoch: 9| Step: 14
Training loss: 2.4367802853411096
Validation loss: 2.334178233058855
Epoch: 9| Step: 15
Training loss: 2.21828917969809
Validation loss: 2.2451907413998753
Epoch: 9| Step: 16
Training loss: 2.2899551473831026
Validation loss: 2.28717552467091
Epoch: 9| Step: 17
Training loss: 2.318928109703363
Validation loss: 2.292631360417692
Epoch: 9| Step: 18
Training loss: 2.075083062221464
Validation loss: 2.261424421698207
Epoch: 9| Step: 19
Training loss: 3.1518421175767766
Validation loss: 2.2860240502242073
Epoch: 44| Step: 0
Training loss: 3.4436285700219593
Validation loss: 2.3315115514815803
Epoch: 9| Step: 1
Training loss: 2.4511594247691777
Validation loss: 2.2789252563979847
Epoch: 9| Step: 2
Training loss: 2.418506272922005
Validation loss: 2.2849923370282554
Epoch: 9| Step: 3
Training loss: 2.8982023981785856
Validation loss: 2.3087265844305978
Epoch: 9| Step: 4
Training loss: 2.8534838748447524
Validation loss: 2.2984544208617206
Epoch: 9| Step: 5
Training loss: 1.3207866110896533
Validation loss: 2.3134849482786914
Epoch: 9| Step: 6
Training loss: 2.592480912023331
Validation loss: 2.2547120831977825
Epoch: 9| Step: 7
Training loss: 2.545438396415016
Validation loss: 2.3085291911248746
Epoch: 9| Step: 8
Training loss: 3.288091013184752
Validation loss: 2.31976700843188
Epoch: 9| Step: 9
Training loss: 2.1865276900569968
Validation loss: 2.3037461008108076
Epoch: 9| Step: 10
Training loss: 2.970441958492368
Validation loss: 2.266263298231587
Epoch: 9| Step: 11
Training loss: 2.1128164968465493
Validation loss: 2.280926004785513
Epoch: 9| Step: 12
Training loss: 2.657456606405681
Validation loss: 2.289679465593283
Epoch: 9| Step: 13
Training loss: 2.4601617468405763
Validation loss: 2.302613840796958
Epoch: 9| Step: 14
Training loss: 2.7385958981915
Validation loss: 2.3369564072820523
Epoch: 9| Step: 15
Training loss: 3.0852946324054695
Validation loss: 2.297707994813205
Epoch: 9| Step: 16
Training loss: 2.723073743994895
Validation loss: 2.289395699679929
Epoch: 9| Step: 17
Training loss: 3.457062560548534
Validation loss: 2.288214990048226
Epoch: 9| Step: 18
Training loss: 2.0479962721209573
Validation loss: 2.2948427876165667
Epoch: 9| Step: 19
Training loss: 3.498844228377171
Validation loss: 2.275020752875001
Epoch: 45| Step: 0
Training loss: 2.7384447601302218
Validation loss: 2.2975847196092256
Epoch: 9| Step: 1
Training loss: 2.1095469086850445
Validation loss: 2.310315443540386
Epoch: 9| Step: 2
Training loss: 2.254742075681904
Validation loss: 2.292110371784415
Epoch: 9| Step: 3
Training loss: 2.116809881676858
Validation loss: 2.273829427788602
Epoch: 9| Step: 4
Training loss: 3.361217046982576
Validation loss: 2.3060901697587712
Epoch: 9| Step: 5
Training loss: 2.9095930335338265
Validation loss: 2.3116098879405143
Epoch: 9| Step: 6
Training loss: 2.178445769980929
Validation loss: 2.3036785527835737
Epoch: 9| Step: 7
Training loss: 2.7208768045672933
Validation loss: 2.3040840278943335
Epoch: 9| Step: 8
Training loss: 2.1663331606531706
Validation loss: 2.30982301419886
Epoch: 9| Step: 9
Training loss: 3.4619215003446193
Validation loss: 2.3129802653193434
Epoch: 9| Step: 10
Training loss: 3.4858604651761698
Validation loss: 2.285781679201966
Epoch: 9| Step: 11
Training loss: 1.958769066674599
Validation loss: 2.295071189581842
Epoch: 9| Step: 12
Training loss: 2.6413977581385235
Validation loss: 2.300103928201759
Epoch: 9| Step: 13
Training loss: 2.8961863862856694
Validation loss: 2.3067015131107893
Epoch: 9| Step: 14
Training loss: 2.593752298009383
Validation loss: 2.3024045827314104
Epoch: 9| Step: 15
Training loss: 2.4015848092983187
Validation loss: 2.2722606579336473
Epoch: 9| Step: 16
Training loss: 3.2866474627178155
Validation loss: 2.2688959702514877
Epoch: 9| Step: 17
Training loss: 2.6639191261708395
Validation loss: 2.2992733305364705
Epoch: 9| Step: 18
Training loss: 3.0654415095144767
Validation loss: 2.327333882117445
Epoch: 9| Step: 19
Training loss: 2.915394332936132
Validation loss: 2.309665718142837
Epoch: 46| Step: 0
Training loss: 2.8534813682385027
Validation loss: 2.3209461844052766
Epoch: 9| Step: 1
Training loss: 3.5195729785608956
Validation loss: 2.298901146797106
Epoch: 9| Step: 2
Training loss: 2.339060351333192
Validation loss: 2.308873506253939
Epoch: 9| Step: 3
Training loss: 2.4627360235663183
Validation loss: 2.2837988711560975
Epoch: 9| Step: 4
Training loss: 2.503014368477035
Validation loss: 2.3670444092344116
Epoch: 9| Step: 5
Training loss: 3.398706184376956
Validation loss: 2.3346711621547165
Epoch: 9| Step: 6
Training loss: 3.042027769906261
Validation loss: 2.3056732837782032
Epoch: 9| Step: 7
Training loss: 2.0106806474692043
Validation loss: 2.360666658932631
Epoch: 9| Step: 8
Training loss: 2.5313764940844865
Validation loss: 2.3131740190489998
Epoch: 9| Step: 9
Training loss: 3.231466118615022
Validation loss: 2.3743531115491816
Epoch: 9| Step: 10
Training loss: 2.3885470066823267
Validation loss: 2.3421107640032
Epoch: 9| Step: 11
Training loss: 3.079538708116064
Validation loss: 2.312909057793566
Epoch: 9| Step: 12
Training loss: 2.7795147572492938
Validation loss: 2.3402302526851133
Epoch: 9| Step: 13
Training loss: 2.2156470724063637
Validation loss: 2.3105201768192303
Epoch: 9| Step: 14
Training loss: 2.086407097809367
Validation loss: 2.2544617660396664
Epoch: 9| Step: 15
Training loss: 2.913120802831501
Validation loss: 2.2997026062779558
Epoch: 9| Step: 16
Training loss: 2.9201534319765083
Validation loss: 2.284267216204549
Epoch: 9| Step: 17
Training loss: 2.1060235419628524
Validation loss: 2.3152623154716325
Epoch: 9| Step: 18
Training loss: 3.036361788768341
Validation loss: 2.2861604889721234
Epoch: 9| Step: 19
Training loss: 2.879873540274154
Validation loss: 2.2748802041922698
Epoch: 47| Step: 0
Training loss: 2.3541248846706777
Validation loss: 2.299953015625459
Epoch: 9| Step: 1
Training loss: 2.2306955626387635
Validation loss: 2.2866583288477327
Epoch: 9| Step: 2
Training loss: 2.9092903231417404
Validation loss: 2.303999994561512
Epoch: 9| Step: 3
Training loss: 3.2972611476875477
Validation loss: 2.2998124606742136
Epoch: 9| Step: 4
Training loss: 3.314315010749358
Validation loss: 2.2802167068270074
Epoch: 9| Step: 5
Training loss: 2.856436464996982
Validation loss: 2.242366030044782
Epoch: 9| Step: 6
Training loss: 2.492122828681866
Validation loss: 2.2998991035478955
Epoch: 9| Step: 7
Training loss: 2.666196622747907
Validation loss: 2.279712889919692
Epoch: 9| Step: 8
Training loss: 2.5657852327257697
Validation loss: 2.2939517603622077
Epoch: 9| Step: 9
Training loss: 2.917100074900562
Validation loss: 2.3357827049069373
Epoch: 9| Step: 10
Training loss: 3.192923326498224
Validation loss: 2.2890467239053978
Epoch: 9| Step: 11
Training loss: 3.0425150659167763
Validation loss: 2.3091747098169546
Epoch: 9| Step: 12
Training loss: 1.9338926142137642
Validation loss: 2.263182882165276
Epoch: 9| Step: 13
Training loss: 2.3030922751515077
Validation loss: 2.2642935036647303
Epoch: 9| Step: 14
Training loss: 3.5339488291120214
Validation loss: 2.3129715810697564
Epoch: 9| Step: 15
Training loss: 2.2491222364859946
Validation loss: 2.3491046388231847
Epoch: 9| Step: 16
Training loss: 3.0521246654502345
Validation loss: 2.282936663925364
Epoch: 9| Step: 17
Training loss: 1.4629095302933952
Validation loss: 2.3064696489488323
Epoch: 9| Step: 18
Training loss: 2.8166407303678764
Validation loss: 2.2954658536925656
Epoch: 9| Step: 19
Training loss: 1.6127350924135067
Validation loss: 2.313451093766723
Epoch: 48| Step: 0
Training loss: 2.822048508895632
Validation loss: 2.3565007948953594
Epoch: 9| Step: 1
Training loss: 3.008220218916502
Validation loss: 2.371809389360088
Epoch: 9| Step: 2
Training loss: 2.6489505777209224
Validation loss: 2.249145676109311
Epoch: 9| Step: 3
Training loss: 2.7847951518524234
Validation loss: 2.262000343850392
Epoch: 9| Step: 4
Training loss: 3.6076164420323655
Validation loss: 2.365221921708352
Epoch: 9| Step: 5
Training loss: 3.1934839066887863
Validation loss: 2.2945059606225646
Epoch: 9| Step: 6
Training loss: 3.04595651721037
Validation loss: 2.2902953687148364
Epoch: 9| Step: 7
Training loss: 2.4001125984799296
Validation loss: 2.3024182872068253
Epoch: 9| Step: 8
Training loss: 2.7234710393647115
Validation loss: 2.2991590737264787
Epoch: 9| Step: 9
Training loss: 2.447245555895863
Validation loss: 2.306534549169957
Epoch: 9| Step: 10
Training loss: 2.9697776220536585
Validation loss: 2.31153541904733
Epoch: 9| Step: 11
Training loss: 2.047834680985199
Validation loss: 2.3212146274057455
Epoch: 9| Step: 12
Training loss: 2.4273663684587983
Validation loss: 2.2994468550334966
Epoch: 9| Step: 13
Training loss: 2.679680026296976
Validation loss: 2.2577685812483144
Epoch: 9| Step: 14
Training loss: 2.0518025498231287
Validation loss: 2.3067441798360897
Epoch: 9| Step: 15
Training loss: 2.337162882928597
Validation loss: 2.2791738510361808
Epoch: 9| Step: 16
Training loss: 3.3109752096609326
Validation loss: 2.297874539084062
Epoch: 9| Step: 17
Training loss: 2.543702566093563
Validation loss: 2.2988683002590102
Epoch: 9| Step: 18
Training loss: 2.208103047965509
Validation loss: 2.286542746492669
Epoch: 9| Step: 19
Training loss: 2.2501270470248307
Validation loss: 2.245409780486912
Epoch: 49| Step: 0
Training loss: 2.4461742503621378
Validation loss: 2.2730317973524508
Epoch: 9| Step: 1
Training loss: 3.0036427316549865
Validation loss: 2.278752841840649
Epoch: 9| Step: 2
Training loss: 3.0609375997001003
Validation loss: 2.315518621284368
Epoch: 9| Step: 3
Training loss: 2.0473697442995116
Validation loss: 2.3017466686317953
Epoch: 9| Step: 4
Training loss: 3.277207709343157
Validation loss: 2.3476636585265878
Epoch: 9| Step: 5
Training loss: 1.559001744918385
Validation loss: 2.344105966307078
Epoch: 9| Step: 6
Training loss: 3.688427307430264
Validation loss: 2.355929646988497
Epoch: 9| Step: 7
Training loss: 3.5343498195354948
Validation loss: 2.2949521861589974
Epoch: 9| Step: 8
Training loss: 2.909847862749973
Validation loss: 2.2912986716948165
Epoch: 9| Step: 9
Training loss: 2.3946326080327256
Validation loss: 2.2607242295907857
Epoch: 9| Step: 10
Training loss: 3.4021570655945044
Validation loss: 2.3015489261820328
Epoch: 9| Step: 11
Training loss: 3.133835775253669
Validation loss: 2.266710176338879
Epoch: 9| Step: 12
Training loss: 1.8971362265587524
Validation loss: 2.288946494080461
Epoch: 9| Step: 13
Training loss: 3.0547717929146705
Validation loss: 2.261293323245913
Epoch: 9| Step: 14
Training loss: 2.373172759810481
Validation loss: 2.341186281247096
Epoch: 9| Step: 15
Training loss: 1.9937199700943038
Validation loss: 2.284999421100261
Epoch: 9| Step: 16
Training loss: 2.939783223522808
Validation loss: 2.3512936571434495
Epoch: 9| Step: 17
Training loss: 1.9870245358814944
Validation loss: 2.269787419882166
Epoch: 9| Step: 18
Training loss: 2.099444715563736
Validation loss: 2.297306589857139
Epoch: 9| Step: 19
Training loss: 2.5255010806398377
Validation loss: 2.3524344403677517
Epoch: 50| Step: 0
Training loss: 2.2928683049363605
Validation loss: 2.3649216141358638
Epoch: 9| Step: 1
Training loss: 3.1895652513014325
Validation loss: 2.33027751027748
Epoch: 9| Step: 2
Training loss: 2.387104808595135
Validation loss: 2.3228300253665943
Epoch: 9| Step: 3
Training loss: 3.0141885923882397
Validation loss: 2.3413759583112137
Epoch: 9| Step: 4
Training loss: 2.9014518260647737
Validation loss: 2.3333186815612907
Epoch: 9| Step: 5
Training loss: 3.1331363805461074
Validation loss: 2.313627696533997
Epoch: 9| Step: 6
Training loss: 2.881161431463505
Validation loss: 2.322291485488328
Epoch: 9| Step: 7
Training loss: 3.356732273792827
Validation loss: 2.3129255232963013
Epoch: 9| Step: 8
Training loss: 2.056218030501323
Validation loss: 2.3363516212837454
Epoch: 9| Step: 9
Training loss: 2.490496692679016
Validation loss: 2.3036274375335744
Epoch: 9| Step: 10
Training loss: 3.2805358109475318
Validation loss: 2.280035845898322
Epoch: 9| Step: 11
Training loss: 2.381919218126872
Validation loss: 2.298854214947398
Epoch: 9| Step: 12
Training loss: 2.318952476524456
Validation loss: 2.2651737641469887
Epoch: 9| Step: 13
Training loss: 1.2296421726117746
Validation loss: 2.251391252104536
Epoch: 9| Step: 14
Training loss: 2.376087742723447
Validation loss: 2.318227302186314
Epoch: 9| Step: 15
Training loss: 2.5445578864498044
Validation loss: 2.319083211305386
Epoch: 9| Step: 16
Training loss: 2.9054242673557753
Validation loss: 2.3152072364224345
Epoch: 9| Step: 17
Training loss: 3.2809805623193475
Validation loss: 2.321120431533117
Epoch: 9| Step: 18
Training loss: 2.5796637364753825
Validation loss: 2.3012557798096247
Epoch: 9| Step: 19
Training loss: 2.6742771348477943
Validation loss: 2.3068215948111908
Epoch: 51| Step: 0
Training loss: 3.0423359243493993
Validation loss: 2.296182959595939
Epoch: 9| Step: 1
Training loss: 2.1259310309633954
Validation loss: 2.292845585765789
Epoch: 9| Step: 2
Training loss: 2.3279480322841457
Validation loss: 2.3062279803228547
Epoch: 9| Step: 3
Training loss: 2.574959030566164
Validation loss: 2.269444035578324
Epoch: 9| Step: 4
Training loss: 2.639715545964136
Validation loss: 2.326338812197277
Epoch: 9| Step: 5
Training loss: 2.085113248242312
Validation loss: 2.3497683084397174
Epoch: 9| Step: 6
Training loss: 2.551326488972456
Validation loss: 2.286047723400199
Epoch: 9| Step: 7
Training loss: 3.244482785989777
Validation loss: 2.283650889608357
Epoch: 9| Step: 8
Training loss: 3.154886990078411
Validation loss: 2.3149813597783213
Epoch: 9| Step: 9
Training loss: 3.012083513903053
Validation loss: 2.332810595951408
Epoch: 9| Step: 10
Training loss: 2.567228838633617
Validation loss: 2.306498700174853
Epoch: 9| Step: 11
Training loss: 2.217911790289049
Validation loss: 2.3500920268155534
Epoch: 9| Step: 12
Training loss: 3.3674007622611177
Validation loss: 2.3266561718911647
Epoch: 9| Step: 13
Training loss: 3.1794175541892447
Validation loss: 2.317881941647295
Epoch: 9| Step: 14
Training loss: 2.894831385734073
Validation loss: 2.3195960180559814
Epoch: 9| Step: 15
Training loss: 2.789803970040487
Validation loss: 2.292832806184507
Epoch: 9| Step: 16
Training loss: 2.9592657276511325
Validation loss: 2.334118094380029
Epoch: 9| Step: 17
Training loss: 1.9865079815212379
Validation loss: 2.2991722833312003
Epoch: 9| Step: 18
Training loss: 2.2961148411942807
Validation loss: 2.3289177607781326
Epoch: 9| Step: 19
Training loss: 2.299263886123075
Validation loss: 2.3369935138662465
Epoch: 52| Step: 0
Training loss: 3.7889739036033885
Validation loss: 2.2400670689213245
Epoch: 9| Step: 1
Training loss: 2.5200302694410093
Validation loss: 2.302620536895613
Epoch: 9| Step: 2
Training loss: 2.0245202897388936
Validation loss: 2.2861108973163162
Epoch: 9| Step: 3
Training loss: 2.1388910329348345
Validation loss: 2.2765283644477257
Epoch: 9| Step: 4
Training loss: 2.0880463758850474
Validation loss: 2.258137424390273
Epoch: 9| Step: 5
Training loss: 3.5383211079292085
Validation loss: 2.3382326573228958
Epoch: 9| Step: 6
Training loss: 2.939805120639609
Validation loss: 2.276984558161387
Epoch: 9| Step: 7
Training loss: 2.0048020649000464
Validation loss: 2.2624206460928304
Epoch: 9| Step: 8
Training loss: 3.1674066649357013
Validation loss: 2.285840546047139
Epoch: 9| Step: 9
Training loss: 2.8993142336615905
Validation loss: 2.2640255828860596
Epoch: 9| Step: 10
Training loss: 2.584439861032597
Validation loss: 2.2561783484284677
Epoch: 9| Step: 11
Training loss: 3.034932681850096
Validation loss: 2.275659170928345
Epoch: 9| Step: 12
Training loss: 2.40789758332649
Validation loss: 2.2764793942854227
Epoch: 9| Step: 13
Training loss: 2.61616901678807
Validation loss: 2.2716934158165714
Epoch: 9| Step: 14
Training loss: 2.8329228122481998
Validation loss: 2.2970077312428363
Epoch: 9| Step: 15
Training loss: 2.837651347018574
Validation loss: 2.233526869235082
Epoch: 9| Step: 16
Training loss: 1.8944571254426374
Validation loss: 2.2674684680706143
Epoch: 9| Step: 17
Training loss: 2.13470185263992
Validation loss: 2.2619739479385212
Epoch: 9| Step: 18
Training loss: 2.8609433068342045
Validation loss: 2.272280576474629
Epoch: 9| Step: 19
Training loss: 2.8524551457615495
Validation loss: 2.2557327913612357
Epoch: 53| Step: 0
Training loss: 3.5375055589396336
Validation loss: 2.271571846377103
Epoch: 9| Step: 1
Training loss: 2.592061055912481
Validation loss: 2.2417239757399923
Epoch: 9| Step: 2
Training loss: 2.953599841175096
Validation loss: 2.2992996794389757
Epoch: 9| Step: 3
Training loss: 2.79731900404335
Validation loss: 2.2830788881993613
Epoch: 9| Step: 4
Training loss: 2.1439218124181796
Validation loss: 2.2710148110370625
Epoch: 9| Step: 5
Training loss: 2.811167083236613
Validation loss: 2.331757042262369
Epoch: 9| Step: 6
Training loss: 2.63467712479934
Validation loss: 2.29692630799428
Epoch: 9| Step: 7
Training loss: 2.610124583139291
Validation loss: 2.333679867053272
Epoch: 9| Step: 8
Training loss: 3.2023207236265034
Validation loss: 2.2967256087219226
Epoch: 9| Step: 9
Training loss: 2.240368573826221
Validation loss: 2.327492190652414
Epoch: 9| Step: 10
Training loss: 2.778728241966133
Validation loss: 2.2765097379663417
Epoch: 9| Step: 11
Training loss: 2.9208494620392575
Validation loss: 2.293251366786014
Epoch: 9| Step: 12
Training loss: 2.705833973964298
Validation loss: 2.293962189896584
Epoch: 9| Step: 13
Training loss: 2.483436839188934
Validation loss: 2.3559812973096457
Epoch: 9| Step: 14
Training loss: 2.08294325673524
Validation loss: 2.316386267665809
Epoch: 9| Step: 15
Training loss: 2.8040412009418816
Validation loss: 2.3180598245706387
Epoch: 9| Step: 16
Training loss: 2.6333265397028467
Validation loss: 2.308356693292611
Epoch: 9| Step: 17
Training loss: 2.338342047811281
Validation loss: 2.2903869141008175
Epoch: 9| Step: 18
Training loss: 2.4478451224619566
Validation loss: 2.3380675336001904
Epoch: 9| Step: 19
Training loss: 2.476128765837622
Validation loss: 2.3091445397801698
Epoch: 54| Step: 0
Training loss: 2.3700831866251946
Validation loss: 2.285589340682182
Epoch: 9| Step: 1
Training loss: 2.7781346049534292
Validation loss: 2.3225577014741163
Epoch: 9| Step: 2
Training loss: 2.2080141832545754
Validation loss: 2.263979937084036
Epoch: 9| Step: 3
Training loss: 2.324689339833045
Validation loss: 2.330868010642336
Epoch: 9| Step: 4
Training loss: 2.5904295476018775
Validation loss: 2.2105096833131395
Epoch: 9| Step: 5
Training loss: 2.8353336416436137
Validation loss: 2.298826047099213
Epoch: 9| Step: 6
Training loss: 2.920851421073454
Validation loss: 2.3021266985462425
Epoch: 9| Step: 7
Training loss: 2.7073866045339576
Validation loss: 2.293261384423341
Epoch: 9| Step: 8
Training loss: 2.948618199926947
Validation loss: 2.2625354066960965
Epoch: 9| Step: 9
Training loss: 2.3758319602203235
Validation loss: 2.23936726220552
Epoch: 9| Step: 10
Training loss: 2.501141573620967
Validation loss: 2.2749158602892896
Epoch: 9| Step: 11
Training loss: 3.0772367638465914
Validation loss: 2.230201122421484
Epoch: 9| Step: 12
Training loss: 2.368564016645116
Validation loss: 2.2800215877579233
Epoch: 9| Step: 13
Training loss: 2.627909365050555
Validation loss: 2.309498952652328
Epoch: 9| Step: 14
Training loss: 3.5463583145569273
Validation loss: 2.2953051482027154
Epoch: 9| Step: 15
Training loss: 2.8809348507062205
Validation loss: 2.274480656854598
Epoch: 9| Step: 16
Training loss: 3.1638671814714643
Validation loss: 2.231751303609277
Epoch: 9| Step: 17
Training loss: 2.0129724836444405
Validation loss: 2.266448815376771
Epoch: 9| Step: 18
Training loss: 2.537830981387037
Validation loss: 2.2699382357828273
Epoch: 9| Step: 19
Training loss: 2.6173882706340934
Validation loss: 2.2202444417405505
Epoch: 55| Step: 0
Training loss: 2.339030485883329
Validation loss: 2.2689152442765406
Epoch: 9| Step: 1
Training loss: 2.179248615229006
Validation loss: 2.307695221639847
Epoch: 9| Step: 2
Training loss: 3.6736194119342622
Validation loss: 2.27503751289308
Epoch: 9| Step: 3
Training loss: 2.617675735709872
Validation loss: 2.277714515030121
Epoch: 9| Step: 4
Training loss: 2.2048168855438535
Validation loss: 2.2669853375776547
Epoch: 9| Step: 5
Training loss: 1.790021614285189
Validation loss: 2.318579018950279
Epoch: 9| Step: 6
Training loss: 2.629604207270697
Validation loss: 2.273226658665647
Epoch: 9| Step: 7
Training loss: 2.9414174357045777
Validation loss: 2.328269672089799
Epoch: 9| Step: 8
Training loss: 3.0459630922021392
Validation loss: 2.281253636755257
Epoch: 9| Step: 9
Training loss: 2.7105652831195073
Validation loss: 2.275823296738811
Epoch: 9| Step: 10
Training loss: 1.9988607499749769
Validation loss: 2.2592203700499027
Epoch: 9| Step: 11
Training loss: 2.9154862512935873
Validation loss: 2.280578393785513
Epoch: 9| Step: 12
Training loss: 2.605595484086253
Validation loss: 2.2544743187176794
Epoch: 9| Step: 13
Training loss: 3.2846852077112847
Validation loss: 2.300909894843896
Epoch: 9| Step: 14
Training loss: 2.839878171268783
Validation loss: 2.2894446400837114
Epoch: 9| Step: 15
Training loss: 2.1992978882991387
Validation loss: 2.3014999659323125
Epoch: 9| Step: 16
Training loss: 2.065538537874937
Validation loss: 2.2797350442964115
Epoch: 9| Step: 17
Training loss: 3.188599041723019
Validation loss: 2.319486210833741
Epoch: 9| Step: 18
Training loss: 2.7843420435606596
Validation loss: 2.279924887627185
Epoch: 9| Step: 19
Training loss: 3.0224320664513664
Validation loss: 2.3347853430459433
Epoch: 56| Step: 0
Training loss: 2.3557262374811363
Validation loss: 2.2682573688287566
Epoch: 9| Step: 1
Training loss: 2.9274376126490123
Validation loss: 2.3299574605888034
Epoch: 9| Step: 2
Training loss: 2.7530433114410697
Validation loss: 2.296040191449562
Epoch: 9| Step: 3
Training loss: 2.1796859686514556
Validation loss: 2.283191947735867
Epoch: 9| Step: 4
Training loss: 3.084361927194149
Validation loss: 2.3085357303598877
Epoch: 9| Step: 5
Training loss: 2.365361582755434
Validation loss: 2.267445269748526
Epoch: 9| Step: 6
Training loss: 2.8484881825000232
Validation loss: 2.313561881534126
Epoch: 9| Step: 7
Training loss: 2.2563186508259294
Validation loss: 2.2893869103540267
Epoch: 9| Step: 8
Training loss: 3.2027671055773568
Validation loss: 2.263179012223987
Epoch: 9| Step: 9
Training loss: 2.3181267407108126
Validation loss: 2.282645286662138
Epoch: 9| Step: 10
Training loss: 2.870924341303046
Validation loss: 2.272270083422008
Epoch: 9| Step: 11
Training loss: 2.8013345977796087
Validation loss: 2.284681844516975
Epoch: 9| Step: 12
Training loss: 3.055316206680208
Validation loss: 2.2951335992754824
Epoch: 9| Step: 13
Training loss: 2.494320904004888
Validation loss: 2.297287044309193
Epoch: 9| Step: 14
Training loss: 3.260350983336901
Validation loss: 2.3033246526487967
Epoch: 9| Step: 15
Training loss: 2.625084648584012
Validation loss: 2.26372241325398
Epoch: 9| Step: 16
Training loss: 2.1124114610525413
Validation loss: 2.312571837095006
Epoch: 9| Step: 17
Training loss: 2.740935558787685
Validation loss: 2.309194551974606
Epoch: 9| Step: 18
Training loss: 2.3948707526578623
Validation loss: 2.280057080737088
Epoch: 9| Step: 19
Training loss: 2.626926351077547
Validation loss: 2.320882394687162
Epoch: 57| Step: 0
Training loss: 3.052374781384205
Validation loss: 2.305587533285681
Epoch: 9| Step: 1
Training loss: 2.670066355191475
Validation loss: 2.260391293426518
Epoch: 9| Step: 2
Training loss: 3.323056081559775
Validation loss: 2.267687286763663
Epoch: 9| Step: 3
Training loss: 2.054198812525958
Validation loss: 2.2892257683188335
Epoch: 9| Step: 4
Training loss: 2.8772047130956064
Validation loss: 2.2920091118399646
Epoch: 9| Step: 5
Training loss: 1.8423508976889973
Validation loss: 2.251849702402199
Epoch: 9| Step: 6
Training loss: 2.925968179473673
Validation loss: 2.3125326014794867
Epoch: 9| Step: 7
Training loss: 3.3752393284465017
Validation loss: 2.3354865714680226
Epoch: 9| Step: 8
Training loss: 2.3088845523275006
Validation loss: 2.2872613356627998
Epoch: 9| Step: 9
Training loss: 2.710725539658152
Validation loss: 2.2924945227396134
Epoch: 9| Step: 10
Training loss: 2.593148954680326
Validation loss: 2.3297222526442614
Epoch: 9| Step: 11
Training loss: 2.870761068363806
Validation loss: 2.3162261203076833
Epoch: 9| Step: 12
Training loss: 2.349146010069092
Validation loss: 2.330786285867523
Epoch: 9| Step: 13
Training loss: 3.390221918995006
Validation loss: 2.333329213791026
Epoch: 9| Step: 14
Training loss: 2.323407712846793
Validation loss: 2.3068889722427963
Epoch: 9| Step: 15
Training loss: 2.4971125140034784
Validation loss: 2.30047052809481
Epoch: 9| Step: 16
Training loss: 2.3998278834296993
Validation loss: 2.318612237398079
Epoch: 9| Step: 17
Training loss: 2.8158214030634463
Validation loss: 2.306552820833198
Epoch: 9| Step: 18
Training loss: 1.8536380771590095
Validation loss: 2.279500792726811
Epoch: 9| Step: 19
Training loss: 2.456537193999747
Validation loss: 2.2752134462637215
Epoch: 58| Step: 0
Training loss: 3.284968276661788
Validation loss: 2.241324616864551
Epoch: 9| Step: 1
Training loss: 3.2959524011785972
Validation loss: 2.2891422321339414
Epoch: 9| Step: 2
Training loss: 2.6229308920048577
Validation loss: 2.2565616207642045
Epoch: 9| Step: 3
Training loss: 3.1462640193828437
Validation loss: 2.2578429341890494
Epoch: 9| Step: 4
Training loss: 2.68478105202878
Validation loss: 2.2563873711517117
Epoch: 9| Step: 5
Training loss: 2.6081796980716
Validation loss: 2.289739889692356
Epoch: 9| Step: 6
Training loss: 2.6361013636282102
Validation loss: 2.2978656195278817
Epoch: 9| Step: 7
Training loss: 2.2576817669358085
Validation loss: 2.2790166490381636
Epoch: 9| Step: 8
Training loss: 1.8783913142685826
Validation loss: 2.242205587359707
Epoch: 9| Step: 9
Training loss: 1.909552418259272
Validation loss: 2.244269197190232
Epoch: 9| Step: 10
Training loss: 2.8661957982457924
Validation loss: 2.233510670575943
Epoch: 9| Step: 11
Training loss: 2.680227153033472
Validation loss: 2.2524681315106383
Epoch: 9| Step: 12
Training loss: 2.36027398571833
Validation loss: 2.292239601222136
Epoch: 9| Step: 13
Training loss: 2.179095334793523
Validation loss: 2.309510570479755
Epoch: 9| Step: 14
Training loss: 2.7314937561343657
Validation loss: 2.2659114022130304
Epoch: 9| Step: 15
Training loss: 2.476626422430177
Validation loss: 2.2824146821853146
Epoch: 9| Step: 16
Training loss: 2.439726179736629
Validation loss: 2.2850016285298396
Epoch: 9| Step: 17
Training loss: 2.7633329904860533
Validation loss: 2.3246159818082672
Epoch: 9| Step: 18
Training loss: 3.0257691847769714
Validation loss: 2.277035574933381
Epoch: 9| Step: 19
Training loss: 2.817492906346568
Validation loss: 2.2993206961434765
Epoch: 59| Step: 0
Training loss: 2.889902880399632
Validation loss: 2.2526165601711896
Epoch: 9| Step: 1
Training loss: 1.7191955682442668
Validation loss: 2.3075998128786948
Epoch: 9| Step: 2
Training loss: 2.4203368193732597
Validation loss: 2.3046363560957936
Epoch: 9| Step: 3
Training loss: 2.8182478768333845
Validation loss: 2.289930014330241
Epoch: 9| Step: 4
Training loss: 1.605742568080665
Validation loss: 2.2965949720313428
Epoch: 9| Step: 5
Training loss: 2.9452870820666317
Validation loss: 2.2580280551137593
Epoch: 9| Step: 6
Training loss: 2.473665390071206
Validation loss: 2.2998858368463275
Epoch: 9| Step: 7
Training loss: 2.1495751160697933
Validation loss: 2.2557011330460695
Epoch: 9| Step: 8
Training loss: 2.2979177586220585
Validation loss: 2.2743373692740523
Epoch: 9| Step: 9
Training loss: 2.171779712809676
Validation loss: 2.3167270369271518
Epoch: 9| Step: 10
Training loss: 3.0488403241868367
Validation loss: 2.2504653998433293
Epoch: 9| Step: 11
Training loss: 2.7333185389358716
Validation loss: 2.294948028246838
Epoch: 9| Step: 12
Training loss: 2.7165630796689246
Validation loss: 2.290969585035748
Epoch: 9| Step: 13
Training loss: 2.9738029443839022
Validation loss: 2.2197811999344257
Epoch: 9| Step: 14
Training loss: 2.8013813221903394
Validation loss: 2.26735899892299
Epoch: 9| Step: 15
Training loss: 3.0432470387831647
Validation loss: 2.2446371432579744
Epoch: 9| Step: 16
Training loss: 3.1016449040533063
Validation loss: 2.2967040930352036
Epoch: 9| Step: 17
Training loss: 3.0549392791557435
Validation loss: 2.2778003075252418
Epoch: 9| Step: 18
Training loss: 2.8807191769381815
Validation loss: 2.253667417189718
Epoch: 9| Step: 19
Training loss: 2.900950203805804
Validation loss: 2.2734830680271036
Epoch: 60| Step: 0
Training loss: 2.888053121062375
Validation loss: 2.30009552885569
Epoch: 9| Step: 1
Training loss: 2.894122343228296
Validation loss: 2.229914525251074
Epoch: 9| Step: 2
Training loss: 2.6073582330716287
Validation loss: 2.265481216157017
Epoch: 9| Step: 3
Training loss: 2.9225746989758448
Validation loss: 2.299309800870215
Epoch: 9| Step: 4
Training loss: 1.871492665876999
Validation loss: 2.2457088901113877
Epoch: 9| Step: 5
Training loss: 2.815698119303249
Validation loss: 2.253915189529217
Epoch: 9| Step: 6
Training loss: 1.9760211912014993
Validation loss: 2.2530027614036277
Epoch: 9| Step: 7
Training loss: 2.3723553438775804
Validation loss: 2.287244531843283
Epoch: 9| Step: 8
Training loss: 3.049222227891624
Validation loss: 2.2613364512006586
Epoch: 9| Step: 9
Training loss: 2.4386487356930706
Validation loss: 2.2053031421535554
Epoch: 9| Step: 10
Training loss: 2.1512462774196868
Validation loss: 2.24911580301941
Epoch: 9| Step: 11
Training loss: 2.2404297641198445
Validation loss: 2.2596961884703166
Epoch: 9| Step: 12
Training loss: 2.885000003702306
Validation loss: 2.2518513501827018
Epoch: 9| Step: 13
Training loss: 2.9020417622374954
Validation loss: 2.319582937633885
Epoch: 9| Step: 14
Training loss: 2.48378780311264
Validation loss: 2.2641954597647644
Epoch: 9| Step: 15
Training loss: 3.1101600767685578
Validation loss: 2.2742565716992553
Epoch: 9| Step: 16
Training loss: 2.2488839242442284
Validation loss: 2.2370343600818274
Epoch: 9| Step: 17
Training loss: 2.436816388638766
Validation loss: 2.2982071475141277
Epoch: 9| Step: 18
Training loss: 2.1625697086101963
Validation loss: 2.2484619918343265
Epoch: 9| Step: 19
Training loss: 4.056940823404316
Validation loss: 2.298395020536986
Epoch: 61| Step: 0
Training loss: 2.3830454227858406
Validation loss: 2.3118402667694506
Epoch: 9| Step: 1
Training loss: 2.934089791409379
Validation loss: 2.3195645263262863
Epoch: 9| Step: 2
Training loss: 2.886602458753684
Validation loss: 2.2729807144574994
Epoch: 9| Step: 3
Training loss: 2.6847872682828777
Validation loss: 2.288356376470716
Epoch: 9| Step: 4
Training loss: 3.0439114756901815
Validation loss: 2.2445173971983934
Epoch: 9| Step: 5
Training loss: 2.5728126123883093
Validation loss: 2.233274102521069
Epoch: 9| Step: 6
Training loss: 1.925249626025887
Validation loss: 2.281146937036752
Epoch: 9| Step: 7
Training loss: 3.3585138681002467
Validation loss: 2.263047565380855
Epoch: 9| Step: 8
Training loss: 3.3902548311040306
Validation loss: 2.253039128540785
Epoch: 9| Step: 9
Training loss: 3.3868677091124066
Validation loss: 2.253804303058866
Epoch: 9| Step: 10
Training loss: 2.6879351951076025
Validation loss: 2.243046314906291
Epoch: 9| Step: 11
Training loss: 2.801580296474255
Validation loss: 2.2405992871923237
Epoch: 9| Step: 12
Training loss: 2.3176099663480314
Validation loss: 2.286171017801277
Epoch: 9| Step: 13
Training loss: 2.513096267016057
Validation loss: 2.328183543985161
Epoch: 9| Step: 14
Training loss: 1.923007228395363
Validation loss: 2.2377407930575073
Epoch: 9| Step: 15
Training loss: 2.3085708229746693
Validation loss: 2.2469952271362286
Epoch: 9| Step: 16
Training loss: 2.008226047779052
Validation loss: 2.2731504457761984
Epoch: 9| Step: 17
Training loss: 2.7574576779089437
Validation loss: 2.327264397336761
Epoch: 9| Step: 18
Training loss: 2.370203796992175
Validation loss: 2.271835606604647
Epoch: 9| Step: 19
Training loss: 2.858817958249214
Validation loss: 2.2508928633313356
Epoch: 62| Step: 0
Training loss: 1.881640437472419
Validation loss: 2.263332032804065
Epoch: 9| Step: 1
Training loss: 2.833347619712565
Validation loss: 2.276812551315424
Epoch: 9| Step: 2
Training loss: 3.047525659191833
Validation loss: 2.3003541759581183
Epoch: 9| Step: 3
Training loss: 2.126273166501135
Validation loss: 2.2648024103705358
Epoch: 9| Step: 4
Training loss: 2.973716516679057
Validation loss: 2.29377212399396
Epoch: 9| Step: 5
Training loss: 2.8640818393884704
Validation loss: 2.326853155876886
Epoch: 9| Step: 6
Training loss: 2.436293768139736
Validation loss: 2.278635569696258
Epoch: 9| Step: 7
Training loss: 2.1509944611943155
Validation loss: 2.328804574250547
Epoch: 9| Step: 8
Training loss: 3.412191546127054
Validation loss: 2.312467628512616
Epoch: 9| Step: 9
Training loss: 2.544780033400922
Validation loss: 2.3120023749441825
Epoch: 9| Step: 10
Training loss: 2.4884724925281647
Validation loss: 2.3140414135011027
Epoch: 9| Step: 11
Training loss: 2.4143190710515587
Validation loss: 2.330474947661088
Epoch: 9| Step: 12
Training loss: 3.017831736156996
Validation loss: 2.3035159943177823
Epoch: 9| Step: 13
Training loss: 3.372605215909922
Validation loss: 2.3432772379567077
Epoch: 9| Step: 14
Training loss: 2.366110175707468
Validation loss: 2.31292668535965
Epoch: 9| Step: 15
Training loss: 2.4140887706524654
Validation loss: 2.289090017800016
Epoch: 9| Step: 16
Training loss: 2.38210949142139
Validation loss: 2.287648157563704
Epoch: 9| Step: 17
Training loss: 2.8951878182687487
Validation loss: 2.278940609666076
Epoch: 9| Step: 18
Training loss: 2.213000086933036
Validation loss: 2.279873346282514
Epoch: 9| Step: 19
Training loss: 2.9405365528260075
Validation loss: 2.3162135805112385
Epoch: 63| Step: 0
Training loss: 3.6944235766848452
Validation loss: 2.311742677871212
Epoch: 9| Step: 1
Training loss: 3.334864709675032
Validation loss: 2.313157383434478
Epoch: 9| Step: 2
Training loss: 2.8427866886607167
Validation loss: 2.2645574393693284
Epoch: 9| Step: 3
Training loss: 2.934274891536088
Validation loss: 2.3272725019522364
Epoch: 9| Step: 4
Training loss: 2.4151290956984393
Validation loss: 2.29158984474188
Epoch: 9| Step: 5
Training loss: 3.1271263517758126
Validation loss: 2.29707903193641
Epoch: 9| Step: 6
Training loss: 1.8504145157866019
Validation loss: 2.3136165627296204
Epoch: 9| Step: 7
Training loss: 2.443121077445827
Validation loss: 2.2449850844534867
Epoch: 9| Step: 8
Training loss: 2.9054308321335927
Validation loss: 2.2673345709244757
Epoch: 9| Step: 9
Training loss: 2.5256402289883213
Validation loss: 2.2936709534762483
Epoch: 9| Step: 10
Training loss: 2.4228607140659992
Validation loss: 2.2791777872959553
Epoch: 9| Step: 11
Training loss: 2.8088799809597638
Validation loss: 2.2577662739971593
Epoch: 9| Step: 12
Training loss: 2.795488749236336
Validation loss: 2.272707340623194
Epoch: 9| Step: 13
Training loss: 2.177507739398223
Validation loss: 2.325516749313366
Epoch: 9| Step: 14
Training loss: 2.241608122825745
Validation loss: 2.3371719990209345
Epoch: 9| Step: 15
Training loss: 2.6485404835711375
Validation loss: 2.237778616698412
Epoch: 9| Step: 16
Training loss: 2.622839356349353
Validation loss: 2.307137788023361
Epoch: 9| Step: 17
Training loss: 1.8567262905461783
Validation loss: 2.2656446569631905
Epoch: 9| Step: 18
Training loss: 3.1577918186482585
Validation loss: 2.2626065575054874
Epoch: 9| Step: 19
Training loss: 2.0284672382239384
Validation loss: 2.3083211840571853
Epoch: 64| Step: 0
Training loss: 3.067528158616682
Validation loss: 2.255215134186785
Epoch: 9| Step: 1
Training loss: 2.657300853426755
Validation loss: 2.258336956842287
Epoch: 9| Step: 2
Training loss: 2.5810440646359623
Validation loss: 2.2803057872023147
Epoch: 9| Step: 3
Training loss: 2.434350742517942
Validation loss: 2.2674164595588233
Epoch: 9| Step: 4
Training loss: 1.8765143319204445
Validation loss: 2.2688156404389765
Epoch: 9| Step: 5
Training loss: 2.027699345620664
Validation loss: 2.2536911443667815
Epoch: 9| Step: 6
Training loss: 2.612600560055319
Validation loss: 2.269375677779142
Epoch: 9| Step: 7
Training loss: 2.9627155209463902
Validation loss: 2.2776909936216914
Epoch: 9| Step: 8
Training loss: 2.8136809518782337
Validation loss: 2.2817212290583915
Epoch: 9| Step: 9
Training loss: 3.1138818943997393
Validation loss: 2.3018357903036546
Epoch: 9| Step: 10
Training loss: 2.9548930370510194
Validation loss: 2.29533804623447
Epoch: 9| Step: 11
Training loss: 3.0143467857563775
Validation loss: 2.21789908662267
Epoch: 9| Step: 12
Training loss: 2.8158052308448074
Validation loss: 2.2955316860832378
Epoch: 9| Step: 13
Training loss: 2.3379712899552527
Validation loss: 2.223156077082898
Epoch: 9| Step: 14
Training loss: 2.7861857818692006
Validation loss: 2.291524385382883
Epoch: 9| Step: 15
Training loss: 2.7013642855594093
Validation loss: 2.2510166540754972
Epoch: 9| Step: 16
Training loss: 2.5611199174933232
Validation loss: 2.287753346536718
Epoch: 9| Step: 17
Training loss: 1.9323588425577514
Validation loss: 2.2673090414139936
Epoch: 9| Step: 18
Training loss: 2.7270937514100044
Validation loss: 2.2472254345274614
Epoch: 9| Step: 19
Training loss: 3.0924889662845683
Validation loss: 2.226601590700987
Epoch: 65| Step: 0
Training loss: 2.1630277397645004
Validation loss: 2.257538711870937
Epoch: 9| Step: 1
Training loss: 3.3554303807650565
Validation loss: 2.2299863714453503
Epoch: 9| Step: 2
Training loss: 2.6616639557380544
Validation loss: 2.2689868406824267
Epoch: 9| Step: 3
Training loss: 3.1309831943408173
Validation loss: 2.225015612505214
Epoch: 9| Step: 4
Training loss: 2.490984013240055
Validation loss: 2.2176603061750786
Epoch: 9| Step: 5
Training loss: 2.849932311743308
Validation loss: 2.2717411881422573
Epoch: 9| Step: 6
Training loss: 3.2086611658690227
Validation loss: 2.2583372333325493
Epoch: 9| Step: 7
Training loss: 1.9423900544658232
Validation loss: 2.2663308838852334
Epoch: 9| Step: 8
Training loss: 2.9882905049897532
Validation loss: 2.26515100880942
Epoch: 9| Step: 9
Training loss: 2.852851471841067
Validation loss: 2.235045620933987
Epoch: 9| Step: 10
Training loss: 2.5053331710154896
Validation loss: 2.2335678096552356
Epoch: 9| Step: 11
Training loss: 2.333940960468346
Validation loss: 2.3044849809453387
Epoch: 9| Step: 12
Training loss: 2.1359380938313572
Validation loss: 2.238589667998212
Epoch: 9| Step: 13
Training loss: 1.8739574076841259
Validation loss: 2.274150898559229
Epoch: 9| Step: 14
Training loss: 2.80451867065635
Validation loss: 2.3014412237225277
Epoch: 9| Step: 15
Training loss: 3.0938757668565473
Validation loss: 2.26596565466694
Epoch: 9| Step: 16
Training loss: 2.4447040227375303
Validation loss: 2.2354500103497306
Epoch: 9| Step: 17
Training loss: 1.5660909968084307
Validation loss: 2.2556630322121256
Epoch: 9| Step: 18
Training loss: 3.2616577873700394
Validation loss: 2.233945195380041
Epoch: 9| Step: 19
Training loss: 2.3986714898202837
Validation loss: 2.2673451855019673
Epoch: 66| Step: 0
Training loss: 2.3829131558530205
Validation loss: 2.2808508795832054
Epoch: 9| Step: 1
Training loss: 1.7065431084585065
Validation loss: 2.226605275981369
Epoch: 9| Step: 2
Training loss: 2.369376501808908
Validation loss: 2.2172241716587586
Epoch: 9| Step: 3
Training loss: 2.3400196143086323
Validation loss: 2.3059982680875484
Epoch: 9| Step: 4
Training loss: 1.9284609089322144
Validation loss: 2.2596066342236574
Epoch: 9| Step: 5
Training loss: 2.8610191412735073
Validation loss: 2.3256893282879587
Epoch: 9| Step: 6
Training loss: 2.540601903381091
Validation loss: 2.258279159608049
Epoch: 9| Step: 7
Training loss: 2.5921156916407297
Validation loss: 2.2754761139421404
Epoch: 9| Step: 8
Training loss: 3.002427390663437
Validation loss: 2.2793732025640496
Epoch: 9| Step: 9
Training loss: 2.9325243426757335
Validation loss: 2.260080259946918
Epoch: 9| Step: 10
Training loss: 3.1753511970503947
Validation loss: 2.2918822198206312
Epoch: 9| Step: 11
Training loss: 2.537558899745528
Validation loss: 2.299913418419851
Epoch: 9| Step: 12
Training loss: 2.860823134298467
Validation loss: 2.317454225717371
Epoch: 9| Step: 13
Training loss: 3.5804776781950105
Validation loss: 2.2281669530051023
Epoch: 9| Step: 14
Training loss: 1.9503717777220935
Validation loss: 2.2416469816930187
Epoch: 9| Step: 15
Training loss: 3.344963637811516
Validation loss: 2.270949589161856
Epoch: 9| Step: 16
Training loss: 2.7883906049332348
Validation loss: 2.2665076151115837
Epoch: 9| Step: 17
Training loss: 1.9337643326546894
Validation loss: 2.285574015519185
Epoch: 9| Step: 18
Training loss: 2.8122093898253167
Validation loss: 2.2731062232975914
Epoch: 9| Step: 19
Training loss: 2.303519052985197
Validation loss: 2.2668998998683882
Epoch: 67| Step: 0
Training loss: 2.6871745777495946
Validation loss: 2.297415670736721
Epoch: 9| Step: 1
Training loss: 2.564748103542577
Validation loss: 2.2356416110533948
Epoch: 9| Step: 2
Training loss: 2.6995696572567085
Validation loss: 2.2707819499518775
Epoch: 9| Step: 3
Training loss: 2.6217247648242323
Validation loss: 2.2386807275959897
Epoch: 9| Step: 4
Training loss: 3.390435138783494
Validation loss: 2.2569611703723433
Epoch: 9| Step: 5
Training loss: 2.3118192340841754
Validation loss: 2.269949015185145
Epoch: 9| Step: 6
Training loss: 3.123621827450124
Validation loss: 2.280997482992158
Epoch: 9| Step: 7
Training loss: 3.242111168387974
Validation loss: 2.246537773948528
Epoch: 9| Step: 8
Training loss: 2.8556327303078164
Validation loss: 2.2846279644881147
Epoch: 9| Step: 9
Training loss: 2.454978291401959
Validation loss: 2.3085558228112677
Epoch: 9| Step: 10
Training loss: 2.5076782570913814
Validation loss: 2.267765438477214
Epoch: 9| Step: 11
Training loss: 2.296168835097912
Validation loss: 2.29984805775174
Epoch: 9| Step: 12
Training loss: 2.980140437970885
Validation loss: 2.243422793140667
Epoch: 9| Step: 13
Training loss: 1.6173991926285327
Validation loss: 2.2911475384595277
Epoch: 9| Step: 14
Training loss: 2.037168595211241
Validation loss: 2.358203862559307
Epoch: 9| Step: 15
Training loss: 2.2908744020505485
Validation loss: 2.2760995954022616
Epoch: 9| Step: 16
Training loss: 2.654313133027149
Validation loss: 2.3110630683423987
Epoch: 9| Step: 17
Training loss: 2.971558055964625
Validation loss: 2.2692985442609563
Epoch: 9| Step: 18
Training loss: 2.5748420852089993
Validation loss: 2.2597607535794144
Epoch: 9| Step: 19
Training loss: 2.4132469799687155
Validation loss: 2.2300102483451694
Epoch: 68| Step: 0
Training loss: 2.712173751688963
Validation loss: 2.3049330261570824
Epoch: 9| Step: 1
Training loss: 2.665494025211368
Validation loss: 2.2612708967479844
Epoch: 9| Step: 2
Training loss: 2.3933391248301756
Validation loss: 2.270834387194734
Epoch: 9| Step: 3
Training loss: 3.0282326064068887
Validation loss: 2.263046398692681
Epoch: 9| Step: 4
Training loss: 1.5821971665022485
Validation loss: 2.267136865652411
Epoch: 9| Step: 5
Training loss: 3.233789658216636
Validation loss: 2.2449486043911313
Epoch: 9| Step: 6
Training loss: 2.554644009747841
Validation loss: 2.2742437612260766
Epoch: 9| Step: 7
Training loss: 3.483525193937089
Validation loss: 2.2125574562905426
Epoch: 9| Step: 8
Training loss: 2.981398771080807
Validation loss: 2.2379905275259304
Epoch: 9| Step: 9
Training loss: 2.34993426454198
Validation loss: 2.2590357455471084
Epoch: 9| Step: 10
Training loss: 2.465425208135339
Validation loss: 2.2402842101061484
Epoch: 9| Step: 11
Training loss: 3.240153435264697
Validation loss: 2.274946539369095
Epoch: 9| Step: 12
Training loss: 2.312074570571904
Validation loss: 2.2463641741181277
Epoch: 9| Step: 13
Training loss: 2.392050822792957
Validation loss: 2.2804534747674183
Epoch: 9| Step: 14
Training loss: 1.6909358050920025
Validation loss: 2.2609984894415764
Epoch: 9| Step: 15
Training loss: 2.7696556418479474
Validation loss: 2.2395946569210294
Epoch: 9| Step: 16
Training loss: 2.07029142548973
Validation loss: 2.2192945532495307
Epoch: 9| Step: 17
Training loss: 2.5666321723238434
Validation loss: 2.252227042506877
Epoch: 9| Step: 18
Training loss: 2.757613826003688
Validation loss: 2.2310337692629245
Epoch: 9| Step: 19
Training loss: 2.9687368292265406
Validation loss: 2.2420839590583226
Epoch: 69| Step: 0
Training loss: 2.5623918836161983
Validation loss: 2.246738158675718
Epoch: 9| Step: 1
Training loss: 2.499673631345626
Validation loss: 2.266003458530001
Epoch: 9| Step: 2
Training loss: 3.068113359657286
Validation loss: 2.2798855872520827
Epoch: 9| Step: 3
Training loss: 2.822849812484322
Validation loss: 2.295538244359306
Epoch: 9| Step: 4
Training loss: 2.2734402266548295
Validation loss: 2.2644813124466063
Epoch: 9| Step: 5
Training loss: 2.7865236839165446
Validation loss: 2.2920821792380073
Epoch: 9| Step: 6
Training loss: 2.312574436948619
Validation loss: 2.2896072973969064
Epoch: 9| Step: 7
Training loss: 2.8204123355176436
Validation loss: 2.26467717452204
Epoch: 9| Step: 8
Training loss: 2.888371594486151
Validation loss: 2.2223571037695424
Epoch: 9| Step: 9
Training loss: 2.955757219402715
Validation loss: 2.263218435881043
Epoch: 9| Step: 10
Training loss: 2.752038893435899
Validation loss: 2.2911140536930854
Epoch: 9| Step: 11
Training loss: 2.8185941158251935
Validation loss: 2.286407342606351
Epoch: 9| Step: 12
Training loss: 1.8651561461016664
Validation loss: 2.2901583539083963
Epoch: 9| Step: 13
Training loss: 2.6603975116594785
Validation loss: 2.3366365824884796
Epoch: 9| Step: 14
Training loss: 1.9648103805954296
Validation loss: 2.288064342409456
Epoch: 9| Step: 15
Training loss: 2.7637260512578607
Validation loss: 2.2664499722523956
Epoch: 9| Step: 16
Training loss: 3.2849764054610855
Validation loss: 2.266100210309708
Epoch: 9| Step: 17
Training loss: 2.7716382705081064
Validation loss: 2.2515610913412134
Epoch: 9| Step: 18
Training loss: 2.5557808592436233
Validation loss: 2.294174835286695
Epoch: 9| Step: 19
Training loss: 2.537065959321082
Validation loss: 2.3099235087260706
Epoch: 70| Step: 0
Training loss: 2.5603307520763945
Validation loss: 2.289929637777423
Epoch: 9| Step: 1
Training loss: 2.4721014717225747
Validation loss: 2.2949571418618473
Epoch: 9| Step: 2
Training loss: 1.335896095392732
Validation loss: 2.2583556865080046
Epoch: 9| Step: 3
Training loss: 3.1917436064235343
Validation loss: 2.2636463907736957
Epoch: 9| Step: 4
Training loss: 2.2156726826646898
Validation loss: 2.3280277149216047
Epoch: 9| Step: 5
Training loss: 2.697724874348877
Validation loss: 2.3158676288767435
Epoch: 9| Step: 6
Training loss: 2.397964580022957
Validation loss: 2.255910789463883
Epoch: 9| Step: 7
Training loss: 2.5791732968772587
Validation loss: 2.3142756956653496
Epoch: 9| Step: 8
Training loss: 3.042657682020522
Validation loss: 2.293032048341897
Epoch: 9| Step: 9
Training loss: 2.1734830543027726
Validation loss: 2.29472077188207
Epoch: 9| Step: 10
Training loss: 3.2459403872842048
Validation loss: 2.3004747083919783
Epoch: 9| Step: 11
Training loss: 2.9508385258560437
Validation loss: 2.2559646070373462
Epoch: 9| Step: 12
Training loss: 2.579022615402361
Validation loss: 2.2462039405121024
Epoch: 9| Step: 13
Training loss: 3.2408053106102033
Validation loss: 2.2689325625962242
Epoch: 9| Step: 14
Training loss: 2.3072503791599623
Validation loss: 2.237551874331775
Epoch: 9| Step: 15
Training loss: 2.669106281449805
Validation loss: 2.256122780198433
Epoch: 9| Step: 16
Training loss: 1.8432679273488155
Validation loss: 2.282730188381269
Epoch: 9| Step: 17
Training loss: 2.7499313345919574
Validation loss: 2.2799887781855754
Epoch: 9| Step: 18
Training loss: 2.951118554593597
Validation loss: 2.239759701858374
Epoch: 9| Step: 19
Training loss: 2.7501796316953184
Validation loss: 2.2369384468937565
Epoch: 71| Step: 0
Training loss: 2.4215197887191016
Validation loss: 2.2123831439768358
Epoch: 9| Step: 1
Training loss: 2.550280394752293
Validation loss: 2.268945788406972
Epoch: 9| Step: 2
Training loss: 2.1503647916179314
Validation loss: 2.268075678066504
Epoch: 9| Step: 3
Training loss: 2.3571031761132173
Validation loss: 2.2565371602817845
Epoch: 9| Step: 4
Training loss: 2.269526207503004
Validation loss: 2.2985578177445545
Epoch: 9| Step: 5
Training loss: 2.431313317266269
Validation loss: 2.237735365429035
Epoch: 9| Step: 6
Training loss: 2.696069229708658
Validation loss: 2.261418100643102
Epoch: 9| Step: 7
Training loss: 3.3700515356000267
Validation loss: 2.2520063344542587
Epoch: 9| Step: 8
Training loss: 3.0073417790651664
Validation loss: 2.237789573808826
Epoch: 9| Step: 9
Training loss: 3.350352675819094
Validation loss: 2.2548127516983203
Epoch: 9| Step: 10
Training loss: 2.54549159759951
Validation loss: 2.345656065836142
Epoch: 9| Step: 11
Training loss: 2.672580291284173
Validation loss: 2.2385079429260832
Epoch: 9| Step: 12
Training loss: 2.7729547644638814
Validation loss: 2.288773336529541
Epoch: 9| Step: 13
Training loss: 2.419246995122032
Validation loss: 2.2617188387598635
Epoch: 9| Step: 14
Training loss: 2.432639239443655
Validation loss: 2.2590362028691136
Epoch: 9| Step: 15
Training loss: 2.254243028890359
Validation loss: 2.3316954332537962
Epoch: 9| Step: 16
Training loss: 2.925229355386721
Validation loss: 2.306249500687444
Epoch: 9| Step: 17
Training loss: 2.6258405520397328
Validation loss: 2.286458692583716
Epoch: 9| Step: 18
Training loss: 2.432252370338567
Validation loss: 2.284462317934158
Epoch: 9| Step: 19
Training loss: 2.8645905835609007
Validation loss: 2.270863224126633
Epoch: 72| Step: 0
Training loss: 2.6381988214296554
Validation loss: 2.2732450523035395
Epoch: 9| Step: 1
Training loss: 2.2778594020495144
Validation loss: 2.2636428562305455
Epoch: 9| Step: 2
Training loss: 1.9083028277273006
Validation loss: 2.2379922859704706
Epoch: 9| Step: 3
Training loss: 2.063558364741551
Validation loss: 2.2763708862249743
Epoch: 9| Step: 4
Training loss: 2.792761734979896
Validation loss: 2.2897004869797453
Epoch: 9| Step: 5
Training loss: 2.4173328752946848
Validation loss: 2.2997980713854327
Epoch: 9| Step: 6
Training loss: 2.0599129375096483
Validation loss: 2.2448821878301133
Epoch: 9| Step: 7
Training loss: 3.203948124516801
Validation loss: 2.2680233832091705
Epoch: 9| Step: 8
Training loss: 1.7958104836528914
Validation loss: 2.2928712076034663
Epoch: 9| Step: 9
Training loss: 2.4190243587584233
Validation loss: 2.275013697536729
Epoch: 9| Step: 10
Training loss: 2.462616362944846
Validation loss: 2.2779058818925932
Epoch: 9| Step: 11
Training loss: 2.668268100370827
Validation loss: 2.2682433434171285
Epoch: 9| Step: 12
Training loss: 3.5529930016416236
Validation loss: 2.2912085695719235
Epoch: 9| Step: 13
Training loss: 2.517863065873033
Validation loss: 2.309711325012665
Epoch: 9| Step: 14
Training loss: 2.745672983244802
Validation loss: 2.2770470720356
Epoch: 9| Step: 15
Training loss: 2.5321440824881947
Validation loss: 2.2848860785559206
Epoch: 9| Step: 16
Training loss: 2.461358315955132
Validation loss: 2.2659987709671516
Epoch: 9| Step: 17
Training loss: 2.4505957910557457
Validation loss: 2.269410352446384
Epoch: 9| Step: 18
Training loss: 3.636887100863021
Validation loss: 2.3284621357594792
Epoch: 9| Step: 19
Training loss: 3.0641204283829624
Validation loss: 2.249260845774099
Epoch: 73| Step: 0
Training loss: 2.1793586729032675
Validation loss: 2.2910763277609134
Epoch: 9| Step: 1
Training loss: 2.698589864470389
Validation loss: 2.2266415098207353
Epoch: 9| Step: 2
Training loss: 2.389719473683644
Validation loss: 2.242462937348222
Epoch: 9| Step: 3
Training loss: 2.810778281604553
Validation loss: 2.3025020061348402
Epoch: 9| Step: 4
Training loss: 2.5882078962354904
Validation loss: 2.260335484880126
Epoch: 9| Step: 5
Training loss: 2.3943002412019116
Validation loss: 2.236365290482504
Epoch: 9| Step: 6
Training loss: 2.096763491899049
Validation loss: 2.257024556143235
Epoch: 9| Step: 7
Training loss: 2.916242750332974
Validation loss: 2.2396459610528288
Epoch: 9| Step: 8
Training loss: 2.896609652813773
Validation loss: 2.2464130150758463
Epoch: 9| Step: 9
Training loss: 3.5297702625935097
Validation loss: 2.271394034814449
Epoch: 9| Step: 10
Training loss: 2.7915400765787886
Validation loss: 2.29803437472004
Epoch: 9| Step: 11
Training loss: 2.568341087595303
Validation loss: 2.2553138268462614
Epoch: 9| Step: 12
Training loss: 2.276088781036486
Validation loss: 2.2751492725047893
Epoch: 9| Step: 13
Training loss: 1.985226425978242
Validation loss: 2.2551481024835147
Epoch: 9| Step: 14
Training loss: 3.286048214689294
Validation loss: 2.2667621827403783
Epoch: 9| Step: 15
Training loss: 2.7997370732701596
Validation loss: 2.2096721754363404
Epoch: 9| Step: 16
Training loss: 2.1261398399921063
Validation loss: 2.2710747337568553
Epoch: 9| Step: 17
Training loss: 2.3259363319427866
Validation loss: 2.2832226209399438
Epoch: 9| Step: 18
Training loss: 3.2466401559529343
Validation loss: 2.253052362045767
Epoch: 9| Step: 19
Training loss: 2.264463350497656
Validation loss: 2.204385233704554
Epoch: 74| Step: 0
Training loss: 1.8194015908796122
Validation loss: 2.2837988845172013
Epoch: 9| Step: 1
Training loss: 2.870381169543808
Validation loss: 2.224457742198201
Epoch: 9| Step: 2
Training loss: 2.1988039320012773
Validation loss: 2.2366546591436527
Epoch: 9| Step: 3
Training loss: 2.717941339304689
Validation loss: 2.2901000896543726
Epoch: 9| Step: 4
Training loss: 2.770403166533557
Validation loss: 2.287486049559662
Epoch: 9| Step: 5
Training loss: 2.227312035470295
Validation loss: 2.2542212468864755
Epoch: 9| Step: 6
Training loss: 1.564712255307598
Validation loss: 2.307203665269527
Epoch: 9| Step: 7
Training loss: 2.8376390801177007
Validation loss: 2.3119407050913843
Epoch: 9| Step: 8
Training loss: 2.9078515674850722
Validation loss: 2.2521622364696636
Epoch: 9| Step: 9
Training loss: 2.6640749396875534
Validation loss: 2.2520290777567946
Epoch: 9| Step: 10
Training loss: 2.8246615789477323
Validation loss: 2.230260733490899
Epoch: 9| Step: 11
Training loss: 3.103646527093045
Validation loss: 2.271489019953175
Epoch: 9| Step: 12
Training loss: 2.604317795500802
Validation loss: 2.275918201997258
Epoch: 9| Step: 13
Training loss: 3.1572970929042024
Validation loss: 2.28636469749052
Epoch: 9| Step: 14
Training loss: 2.744737271102269
Validation loss: 2.2552293161335877
Epoch: 9| Step: 15
Training loss: 1.7047356505197737
Validation loss: 2.235307364712647
Epoch: 9| Step: 16
Training loss: 3.1925907248179883
Validation loss: 2.3174855590115935
Epoch: 9| Step: 17
Training loss: 3.221735634365691
Validation loss: 2.3184442496470017
Epoch: 9| Step: 18
Training loss: 2.0405650248337963
Validation loss: 2.3032162227120923
Epoch: 9| Step: 19
Training loss: 2.081543484177012
Validation loss: 2.2911751920760794
Epoch: 75| Step: 0
Training loss: 3.07829307445836
Validation loss: 2.289412818236134
Epoch: 9| Step: 1
Training loss: 2.341637027684134
Validation loss: 2.2737990827307857
Epoch: 9| Step: 2
Training loss: 2.53324453633268
Validation loss: 2.2664148448419628
Epoch: 9| Step: 3
Training loss: 2.5358964635851042
Validation loss: 2.2666075990784553
Epoch: 9| Step: 4
Training loss: 2.1345552024896395
Validation loss: 2.2153552059088977
Epoch: 9| Step: 5
Training loss: 2.239866324591397
Validation loss: 2.283303882405098
Epoch: 9| Step: 6
Training loss: 3.2457566068996777
Validation loss: 2.2394257711974532
Epoch: 9| Step: 7
Training loss: 2.869740858972505
Validation loss: 2.213316833599635
Epoch: 9| Step: 8
Training loss: 2.837186680102574
Validation loss: 2.256609737198478
Epoch: 9| Step: 9
Training loss: 3.7836209264894194
Validation loss: 2.2182122214862887
Epoch: 9| Step: 10
Training loss: 2.505469823396344
Validation loss: 2.2228796670543134
Epoch: 9| Step: 11
Training loss: 1.9583269957852454
Validation loss: 2.2236668443121843
Epoch: 9| Step: 12
Training loss: 1.8740748348214995
Validation loss: 2.2463277806325466
Epoch: 9| Step: 13
Training loss: 2.554175836029106
Validation loss: 2.2718491329076262
Epoch: 9| Step: 14
Training loss: 3.0110685881192407
Validation loss: 2.251016908375144
Epoch: 9| Step: 15
Training loss: 3.084083019222733
Validation loss: 2.256160725474983
Epoch: 9| Step: 16
Training loss: 2.5002121835310303
Validation loss: 2.2414895023066714
Epoch: 9| Step: 17
Training loss: 2.3418126555126664
Validation loss: 2.2579704288896165
Epoch: 9| Step: 18
Training loss: 2.7067779378459496
Validation loss: 2.2836759592609344
Epoch: 9| Step: 19
Training loss: 1.7826865577177686
Validation loss: 2.246934448782567
Epoch: 76| Step: 0
Training loss: 2.1259146573152905
Validation loss: 2.3007146786946824
Epoch: 9| Step: 1
Training loss: 3.3476371631055932
Validation loss: 2.2907880770850246
Epoch: 9| Step: 2
Training loss: 2.9549215997664984
Validation loss: 2.2520002526434695
Epoch: 9| Step: 3
Training loss: 2.0042798026886914
Validation loss: 2.2556316212574328
Epoch: 9| Step: 4
Training loss: 3.0472296092723266
Validation loss: 2.2307598336169376
Epoch: 9| Step: 5
Training loss: 3.425123649648412
Validation loss: 2.269786904773131
Epoch: 9| Step: 6
Training loss: 2.9303947713977636
Validation loss: 2.232487637468607
Epoch: 9| Step: 7
Training loss: 2.646004338382731
Validation loss: 2.1881142644105656
Epoch: 9| Step: 8
Training loss: 2.2789707032178996
Validation loss: 2.2802093463244866
Epoch: 9| Step: 9
Training loss: 2.896213387631225
Validation loss: 2.1915428805873702
Epoch: 9| Step: 10
Training loss: 2.5528391646553343
Validation loss: 2.287286979679939
Epoch: 9| Step: 11
Training loss: 2.1747904358676506
Validation loss: 2.2049561189561593
Epoch: 9| Step: 12
Training loss: 2.9017244605002603
Validation loss: 2.2032657544768695
Epoch: 9| Step: 13
Training loss: 2.068106689003159
Validation loss: 2.1702858876367985
Epoch: 9| Step: 14
Training loss: 2.5285392657582846
Validation loss: 2.2542871967217057
Epoch: 9| Step: 15
Training loss: 1.8998452449817487
Validation loss: 2.2600513392878767
Epoch: 9| Step: 16
Training loss: 2.4001345517270574
Validation loss: 2.234708115576698
Epoch: 9| Step: 17
Training loss: 2.528669384035755
Validation loss: 2.2517537864867667
Epoch: 9| Step: 18
Training loss: 2.3730735997080554
Validation loss: 2.2497717731484044
Epoch: 9| Step: 19
Training loss: 2.822043017415712
Validation loss: 2.231898248784652
Epoch: 77| Step: 0
Training loss: 3.11878119627003
Validation loss: 2.274441480180001
Epoch: 9| Step: 1
Training loss: 2.025985703925318
Validation loss: 2.290570314173816
Epoch: 9| Step: 2
Training loss: 2.2213293851578433
Validation loss: 2.28358006506582
Epoch: 9| Step: 3
Training loss: 2.2488884829448357
Validation loss: 2.3227982741652866
Epoch: 9| Step: 4
Training loss: 1.8660949958465565
Validation loss: 2.316640951006809
Epoch: 9| Step: 5
Training loss: 3.2365724037448347
Validation loss: 2.3481003903369864
Epoch: 9| Step: 6
Training loss: 2.462567083539081
Validation loss: 2.262479030343326
Epoch: 9| Step: 7
Training loss: 2.6083494443873207
Validation loss: 2.286958315506151
Epoch: 9| Step: 8
Training loss: 2.9821104075654468
Validation loss: 2.3299927341256765
Epoch: 9| Step: 9
Training loss: 2.3854872402984486
Validation loss: 2.349190621347145
Epoch: 9| Step: 10
Training loss: 2.3204107295863574
Validation loss: 2.346850563214968
Epoch: 9| Step: 11
Training loss: 2.496254212858707
Validation loss: 2.3157872893115714
Epoch: 9| Step: 12
Training loss: 3.3763077639370036
Validation loss: 2.3578030070275156
Epoch: 9| Step: 13
Training loss: 2.5057039041672278
Validation loss: 2.366342882103062
Epoch: 9| Step: 14
Training loss: 2.4610701267895294
Validation loss: 2.328463868690781
Epoch: 9| Step: 15
Training loss: 3.1313403088001475
Validation loss: 2.3034575426783443
Epoch: 9| Step: 16
Training loss: 2.6993340165387125
Validation loss: 2.306454189916924
Epoch: 9| Step: 17
Training loss: 3.046557600655423
Validation loss: 2.3508775443304297
Epoch: 9| Step: 18
Training loss: 2.7698745407172285
Validation loss: 2.2958318013652415
Epoch: 9| Step: 19
Training loss: 2.2040498564354936
Validation loss: 2.225792186046581
Epoch: 78| Step: 0
Training loss: 2.103904808545389
Validation loss: 2.2801607787493894
Epoch: 9| Step: 1
Training loss: 2.54343289360007
Validation loss: 2.2939192182602137
Epoch: 9| Step: 2
Training loss: 1.831515306646779
Validation loss: 2.2862435659667044
Epoch: 9| Step: 3
Training loss: 2.8138392332850017
Validation loss: 2.225435160075498
Epoch: 9| Step: 4
Training loss: 2.176212288640962
Validation loss: 2.2698413291887927
Epoch: 9| Step: 5
Training loss: 2.6796096479044893
Validation loss: 2.20552245221679
Epoch: 9| Step: 6
Training loss: 3.102872403746352
Validation loss: 2.2493738215864805
Epoch: 9| Step: 7
Training loss: 2.5040326019638797
Validation loss: 2.2161627872804543
Epoch: 9| Step: 8
Training loss: 2.340734449203547
Validation loss: 2.2338717086470656
Epoch: 9| Step: 9
Training loss: 2.229950478863509
Validation loss: 2.2112058657285742
Epoch: 9| Step: 10
Training loss: 2.8520993916124717
Validation loss: 2.220985593322967
Epoch: 9| Step: 11
Training loss: 2.88851340209324
Validation loss: 2.2314083789634167
Epoch: 9| Step: 12
Training loss: 3.2077626963529084
Validation loss: 2.2312123027428865
Epoch: 9| Step: 13
Training loss: 3.0609503737486103
Validation loss: 2.2053742032532195
Epoch: 9| Step: 14
Training loss: 2.468079101568489
Validation loss: 2.2258697210885194
Epoch: 9| Step: 15
Training loss: 2.34226372959308
Validation loss: 2.261270009536389
Epoch: 9| Step: 16
Training loss: 2.6828682486552213
Validation loss: 2.2201683757803927
Epoch: 9| Step: 17
Training loss: 3.0115335014160753
Validation loss: 2.233991489707166
Epoch: 9| Step: 18
Training loss: 2.688345665175204
Validation loss: 2.2165335428612782
Epoch: 9| Step: 19
Training loss: 2.643299982534797
Validation loss: 2.186922203941506
Epoch: 79| Step: 0
Training loss: 2.0927138540354306
Validation loss: 2.2186650631239084
Epoch: 9| Step: 1
Training loss: 2.1865781749094255
Validation loss: 2.2465589795725314
Epoch: 9| Step: 2
Training loss: 2.4291695291056272
Validation loss: 2.238749590835568
Epoch: 9| Step: 3
Training loss: 2.216804833754986
Validation loss: 2.258528462434012
Epoch: 9| Step: 4
Training loss: 2.802586865946231
Validation loss: 2.233004727929497
Epoch: 9| Step: 5
Training loss: 2.7126269614044394
Validation loss: 2.2706273069659546
Epoch: 9| Step: 6
Training loss: 1.7058508521396245
Validation loss: 2.229847378074137
Epoch: 9| Step: 7
Training loss: 2.2718706007630205
Validation loss: 2.244516000294617
Epoch: 9| Step: 8
Training loss: 2.5494413960782376
Validation loss: 2.2680508262820895
Epoch: 9| Step: 9
Training loss: 3.0101550207425145
Validation loss: 2.285386676074305
Epoch: 9| Step: 10
Training loss: 2.471271337977565
Validation loss: 2.2592703876299067
Epoch: 9| Step: 11
Training loss: 2.985456660114393
Validation loss: 2.2335822530398537
Epoch: 9| Step: 12
Training loss: 2.494328933095443
Validation loss: 2.263557687389524
Epoch: 9| Step: 13
Training loss: 2.6987889081474576
Validation loss: 2.3040050189026795
Epoch: 9| Step: 14
Training loss: 2.265141507879853
Validation loss: 2.2619114046572144
Epoch: 9| Step: 15
Training loss: 2.4769221384672746
Validation loss: 2.289534907389684
Epoch: 9| Step: 16
Training loss: 2.2255724395570278
Validation loss: 2.2747822851622908
Epoch: 9| Step: 17
Training loss: 3.225659112334156
Validation loss: 2.3258100773941552
Epoch: 9| Step: 18
Training loss: 3.3219286048561787
Validation loss: 2.278747860368481
Epoch: 9| Step: 19
Training loss: 3.3572831139064494
Validation loss: 2.2770495305968113
Epoch: 80| Step: 0
Training loss: 2.3518206179066965
Validation loss: 2.2962041731689116
Epoch: 9| Step: 1
Training loss: 2.9028045575996986
Validation loss: 2.286130216698144
Epoch: 9| Step: 2
Training loss: 2.5748428259722367
Validation loss: 2.2850290682049184
Epoch: 9| Step: 3
Training loss: 2.8970108016855938
Validation loss: 2.272200679120138
Epoch: 9| Step: 4
Training loss: 3.1015560428734736
Validation loss: 2.332941195984819
Epoch: 9| Step: 5
Training loss: 3.1859140377481014
Validation loss: 2.347492076561204
Epoch: 9| Step: 6
Training loss: 2.992932737288642
Validation loss: 2.283953344965614
Epoch: 9| Step: 7
Training loss: 2.6000866068573907
Validation loss: 2.3343920339826303
Epoch: 9| Step: 8
Training loss: 2.8504830603545366
Validation loss: 2.305637164333263
Epoch: 9| Step: 9
Training loss: 2.8121376651909915
Validation loss: 2.3037683981937125
Epoch: 9| Step: 10
Training loss: 2.070858980425534
Validation loss: 2.25550828470466
Epoch: 9| Step: 11
Training loss: 2.2041458037554245
Validation loss: 2.349447330119202
Epoch: 9| Step: 12
Training loss: 2.514147970526038
Validation loss: 2.236328571763718
Epoch: 9| Step: 13
Training loss: 2.1692515384202165
Validation loss: 2.278548034760642
Epoch: 9| Step: 14
Training loss: 2.409433414132092
Validation loss: 2.270407355555087
Epoch: 9| Step: 15
Training loss: 2.79919422680831
Validation loss: 2.211040252873779
Epoch: 9| Step: 16
Training loss: 2.830307260824137
Validation loss: 2.237310899227473
Epoch: 9| Step: 17
Training loss: 2.2253358908871506
Validation loss: 2.230511002458191
Epoch: 9| Step: 18
Training loss: 2.7425606411234114
Validation loss: 2.257976034980851
Epoch: 9| Step: 19
Training loss: 1.812754119948331
Validation loss: 2.2699831346634403
Epoch: 81| Step: 0
Training loss: 2.187912275428218
Validation loss: 2.2133415626661095
Epoch: 9| Step: 1
Training loss: 2.563113627581795
Validation loss: 2.262000134625741
Epoch: 9| Step: 2
Training loss: 2.7152279369292738
Validation loss: 2.2306895028860247
Epoch: 9| Step: 3
Training loss: 2.4234636572207706
Validation loss: 2.2388448949813626
Epoch: 9| Step: 4
Training loss: 3.0329713947822494
Validation loss: 2.2535023284009927
Epoch: 9| Step: 5
Training loss: 1.9737427391609639
Validation loss: 2.2111050348535786
Epoch: 9| Step: 6
Training loss: 2.5519508379323517
Validation loss: 2.2018111174999353
Epoch: 9| Step: 7
Training loss: 2.7556590893566915
Validation loss: 2.21084025868054
Epoch: 9| Step: 8
Training loss: 2.6074870697900527
Validation loss: 2.2531629425666244
Epoch: 9| Step: 9
Training loss: 2.556963079180741
Validation loss: 2.198037192012994
Epoch: 9| Step: 10
Training loss: 2.618785950771279
Validation loss: 2.253218992875306
Epoch: 9| Step: 11
Training loss: 2.261027545098109
Validation loss: 2.2250399672259062
Epoch: 9| Step: 12
Training loss: 2.8991854543169446
Validation loss: 2.2673341443828354
Epoch: 9| Step: 13
Training loss: 2.612621366611212
Validation loss: 2.230635239388075
Epoch: 9| Step: 14
Training loss: 2.6888395120572635
Validation loss: 2.2293490763027273
Epoch: 9| Step: 15
Training loss: 2.8368611158462773
Validation loss: 2.236251234677006
Epoch: 9| Step: 16
Training loss: 2.9227504132807027
Validation loss: 2.2866408821956012
Epoch: 9| Step: 17
Training loss: 2.420094284553883
Validation loss: 2.2253479961263825
Epoch: 9| Step: 18
Training loss: 2.5191860228600502
Validation loss: 2.3011672670933376
Epoch: 9| Step: 19
Training loss: 2.7753057500436933
Validation loss: 2.2857525784004675
Epoch: 82| Step: 0
Training loss: 2.6017903179506114
Validation loss: 2.292839905755765
Epoch: 9| Step: 1
Training loss: 2.5081545397465974
Validation loss: 2.270068904325639
Epoch: 9| Step: 2
Training loss: 3.3880067903705093
Validation loss: 2.227183950420232
Epoch: 9| Step: 3
Training loss: 2.636232865387756
Validation loss: 2.3162524667804614
Epoch: 9| Step: 4
Training loss: 2.737297196910461
Validation loss: 2.2667108596340686
Epoch: 9| Step: 5
Training loss: 2.1388883576936046
Validation loss: 2.2958325093647307
Epoch: 9| Step: 6
Training loss: 2.6279833960741654
Validation loss: 2.2621768059155425
Epoch: 9| Step: 7
Training loss: 3.2373351773168264
Validation loss: 2.238713224339828
Epoch: 9| Step: 8
Training loss: 2.176911367046345
Validation loss: 2.330445393528139
Epoch: 9| Step: 9
Training loss: 2.4940327954862456
Validation loss: 2.323973577710641
Epoch: 9| Step: 10
Training loss: 1.609252776902834
Validation loss: 2.272956507907636
Epoch: 9| Step: 11
Training loss: 2.983879327803909
Validation loss: 2.2614837629634463
Epoch: 9| Step: 12
Training loss: 2.2004063924491657
Validation loss: 2.2477422602837556
Epoch: 9| Step: 13
Training loss: 2.9683032854184686
Validation loss: 2.285856532524662
Epoch: 9| Step: 14
Training loss: 1.554229515516243
Validation loss: 2.261644025181833
Epoch: 9| Step: 15
Training loss: 2.4771313901388496
Validation loss: 2.27621254306609
Epoch: 9| Step: 16
Training loss: 2.482422835427135
Validation loss: 2.2909287011685864
Epoch: 9| Step: 17
Training loss: 3.0661011367908713
Validation loss: 2.243975262881479
Epoch: 9| Step: 18
Training loss: 2.4416961741915735
Validation loss: 2.245589965253179
Epoch: 9| Step: 19
Training loss: 3.2153932419311246
Validation loss: 2.2595101299826807
Epoch: 83| Step: 0
Training loss: 2.0369054851375163
Validation loss: 2.2785676256039644
Epoch: 9| Step: 1
Training loss: 2.6716486070878855
Validation loss: 2.2783768568704836
Epoch: 9| Step: 2
Training loss: 2.8955555698000848
Validation loss: 2.285411600589789
Epoch: 9| Step: 3
Training loss: 2.3707759839067757
Validation loss: 2.2646567086506155
Epoch: 9| Step: 4
Training loss: 3.185181915501667
Validation loss: 2.270267339970207
Epoch: 9| Step: 5
Training loss: 2.4617536856479507
Validation loss: 2.264236803724606
Epoch: 9| Step: 6
Training loss: 2.905573612381516
Validation loss: 2.2512807131144768
Epoch: 9| Step: 7
Training loss: 2.6237245821800705
Validation loss: 2.2271848526947724
Epoch: 9| Step: 8
Training loss: 2.7629833644348194
Validation loss: 2.2049502023674328
Epoch: 9| Step: 9
Training loss: 2.560899374156123
Validation loss: 2.2635458328618943
Epoch: 9| Step: 10
Training loss: 2.660003164762751
Validation loss: 2.245285555291646
Epoch: 9| Step: 11
Training loss: 2.83533919147048
Validation loss: 2.2321351357949317
Epoch: 9| Step: 12
Training loss: 2.9913054677664164
Validation loss: 2.2749056638722887
Epoch: 9| Step: 13
Training loss: 3.210464628349425
Validation loss: 2.20930282213226
Epoch: 9| Step: 14
Training loss: 2.614574619800491
Validation loss: 2.2400871137456666
Epoch: 9| Step: 15
Training loss: 2.7904035832819547
Validation loss: 2.2654457080270207
Epoch: 9| Step: 16
Training loss: 2.105992862388637
Validation loss: 2.233078435397382
Epoch: 9| Step: 17
Training loss: 2.1301177611057045
Validation loss: 2.2298800363080415
Epoch: 9| Step: 18
Training loss: 1.9842979836724604
Validation loss: 2.2643203664050158
Epoch: 9| Step: 19
Training loss: 2.0698181713796124
Validation loss: 2.2245776025331017
Epoch: 84| Step: 0
Training loss: 2.2462226100943603
Validation loss: 2.230865189774261
Epoch: 9| Step: 1
Training loss: 2.39348077679388
Validation loss: 2.263329930738064
Epoch: 9| Step: 2
Training loss: 2.2317100584879412
Validation loss: 2.3060944384253736
Epoch: 9| Step: 3
Training loss: 3.215537236297782
Validation loss: 2.2899593365986557
Epoch: 9| Step: 4
Training loss: 2.6115738974890026
Validation loss: 2.3343958097561566
Epoch: 9| Step: 5
Training loss: 2.479294867099293
Validation loss: 2.301565223864838
Epoch: 9| Step: 6
Training loss: 2.3302111399847827
Validation loss: 2.3040442506953918
Epoch: 9| Step: 7
Training loss: 2.13402994921761
Validation loss: 2.326042592383522
Epoch: 9| Step: 8
Training loss: 2.090725664529254
Validation loss: 2.2584753055184494
Epoch: 9| Step: 9
Training loss: 2.3914979824254647
Validation loss: 2.33659316614805
Epoch: 9| Step: 10
Training loss: 2.969450215531409
Validation loss: 2.3340594312342655
Epoch: 9| Step: 11
Training loss: 2.054495682846216
Validation loss: 2.2542393213539302
Epoch: 9| Step: 12
Training loss: 2.7063990703870964
Validation loss: 2.2868281345697232
Epoch: 9| Step: 13
Training loss: 2.164442118596249
Validation loss: 2.3167422070174397
Epoch: 9| Step: 14
Training loss: 3.178991293080164
Validation loss: 2.2723392292625175
Epoch: 9| Step: 15
Training loss: 2.2702125143991845
Validation loss: 2.3381428859507376
Epoch: 9| Step: 16
Training loss: 3.1256797051328835
Validation loss: 2.315179515439898
Epoch: 9| Step: 17
Training loss: 2.5298246915489426
Validation loss: 2.274183057139045
Epoch: 9| Step: 18
Training loss: 3.450638510178904
Validation loss: 2.2537849777121877
Epoch: 9| Step: 19
Training loss: 3.244723511659238
Validation loss: 2.2504861628523574
Epoch: 85| Step: 0
Training loss: 2.2574297834694486
Validation loss: 2.2864983752747894
Epoch: 9| Step: 1
Training loss: 2.4454688853996913
Validation loss: 2.2393832253335497
Epoch: 9| Step: 2
Training loss: 2.275128970839644
Validation loss: 2.222857138991146
Epoch: 9| Step: 3
Training loss: 2.0851826534264655
Validation loss: 2.2467095389617673
Epoch: 9| Step: 4
Training loss: 2.976248176378687
Validation loss: 2.2865484769013382
Epoch: 9| Step: 5
Training loss: 2.704905193874477
Validation loss: 2.2354214356685955
Epoch: 9| Step: 6
Training loss: 2.339794839847743
Validation loss: 2.2357160842493644
Epoch: 9| Step: 7
Training loss: 2.9063681301596693
Validation loss: 2.2237735705550823
Epoch: 9| Step: 8
Training loss: 2.9821283162254426
Validation loss: 2.2364800572531838
Epoch: 9| Step: 9
Training loss: 2.425808769721113
Validation loss: 2.279520625636548
Epoch: 9| Step: 10
Training loss: 2.7761338572316396
Validation loss: 2.2689793637576163
Epoch: 9| Step: 11
Training loss: 2.2930519309869815
Validation loss: 2.2663479154187556
Epoch: 9| Step: 12
Training loss: 1.459032989876756
Validation loss: 2.2646548854540263
Epoch: 9| Step: 13
Training loss: 2.551868808579064
Validation loss: 2.220854667462011
Epoch: 9| Step: 14
Training loss: 3.188062281661914
Validation loss: 2.2982086181958516
Epoch: 9| Step: 15
Training loss: 2.318827555302828
Validation loss: 2.2344269468813964
Epoch: 9| Step: 16
Training loss: 2.235460777831092
Validation loss: 2.2455688534562155
Epoch: 9| Step: 17
Training loss: 2.7873091114867927
Validation loss: 2.2623373470843786
Epoch: 9| Step: 18
Training loss: 3.21475149140478
Validation loss: 2.2566679207506404
Epoch: 9| Step: 19
Training loss: 2.95091722097865
Validation loss: 2.2715814497930653
Epoch: 86| Step: 0
Training loss: 2.407130786158821
Validation loss: 2.236610622205509
Epoch: 9| Step: 1
Training loss: 2.9551002315039776
Validation loss: 2.2407208321985146
Epoch: 9| Step: 2
Training loss: 2.188023095938289
Validation loss: 2.2424335498444816
Epoch: 9| Step: 3
Training loss: 2.7532940989078094
Validation loss: 2.2536859989086238
Epoch: 9| Step: 4
Training loss: 2.0092929473308163
Validation loss: 2.2484954813432454
Epoch: 9| Step: 5
Training loss: 3.44082120497058
Validation loss: 2.2120983688496585
Epoch: 9| Step: 6
Training loss: 3.4448618345417037
Validation loss: 2.261321024462832
Epoch: 9| Step: 7
Training loss: 2.983407228147851
Validation loss: 2.290517585122587
Epoch: 9| Step: 8
Training loss: 2.5483500883733767
Validation loss: 2.2896308570377357
Epoch: 9| Step: 9
Training loss: 2.9832576237738313
Validation loss: 2.249913822136982
Epoch: 9| Step: 10
Training loss: 2.224897223681315
Validation loss: 2.2449314944361323
Epoch: 9| Step: 11
Training loss: 2.8085679436401336
Validation loss: 2.26829203602679
Epoch: 9| Step: 12
Training loss: 2.369700995307092
Validation loss: 2.2308459270646708
Epoch: 9| Step: 13
Training loss: 1.3896038292207813
Validation loss: 2.2384136868469224
Epoch: 9| Step: 14
Training loss: 2.1404637185479043
Validation loss: 2.236792300567325
Epoch: 9| Step: 15
Training loss: 2.293106100982366
Validation loss: 2.2178900760388967
Epoch: 9| Step: 16
Training loss: 2.4517677585895705
Validation loss: 2.256456951802121
Epoch: 9| Step: 17
Training loss: 2.5498362918737443
Validation loss: 2.2022873587540843
Epoch: 9| Step: 18
Training loss: 2.539660855727685
Validation loss: 2.219487338383839
Epoch: 9| Step: 19
Training loss: 2.8227320724511276
Validation loss: 2.205550289678983
Epoch: 87| Step: 0
Training loss: 1.914685206423569
Validation loss: 2.245240155612019
Epoch: 9| Step: 1
Training loss: 1.9626009751116387
Validation loss: 2.287390866041271
Epoch: 9| Step: 2
Training loss: 2.023592438528393
Validation loss: 2.261799075762577
Epoch: 9| Step: 3
Training loss: 1.9804372088988615
Validation loss: 2.2540508040040934
Epoch: 9| Step: 4
Training loss: 2.1388759846593923
Validation loss: 2.273659344488018
Epoch: 9| Step: 5
Training loss: 3.0773429070670337
Validation loss: 2.3027636552521518
Epoch: 9| Step: 6
Training loss: 2.6653840039913406
Validation loss: 2.244168777565694
Epoch: 9| Step: 7
Training loss: 2.880898106201507
Validation loss: 2.2600044414588587
Epoch: 9| Step: 8
Training loss: 2.15731243551496
Validation loss: 2.2302713286575955
Epoch: 9| Step: 9
Training loss: 2.782924619426198
Validation loss: 2.2663576429279537
Epoch: 9| Step: 10
Training loss: 2.5226857863817966
Validation loss: 2.258114336105592
Epoch: 9| Step: 11
Training loss: 3.0852006636142204
Validation loss: 2.2482237531468554
Epoch: 9| Step: 12
Training loss: 2.415873715327572
Validation loss: 2.3433096957120365
Epoch: 9| Step: 13
Training loss: 2.976109748108777
Validation loss: 2.2649408933805106
Epoch: 9| Step: 14
Training loss: 2.5721190808377283
Validation loss: 2.288343512493976
Epoch: 9| Step: 15
Training loss: 2.7124016845043077
Validation loss: 2.335341400939835
Epoch: 9| Step: 16
Training loss: 2.508304345691087
Validation loss: 2.2722830493694577
Epoch: 9| Step: 17
Training loss: 3.114257046928802
Validation loss: 2.2179541620773295
Epoch: 9| Step: 18
Training loss: 2.307645496480505
Validation loss: 2.278380549996973
Epoch: 9| Step: 19
Training loss: 3.464192188331963
Validation loss: 2.256728802405958
Epoch: 88| Step: 0
Training loss: 2.532244451645738
Validation loss: 2.2418182982422503
Epoch: 9| Step: 1
Training loss: 2.0372268774536937
Validation loss: 2.240217443767993
Epoch: 9| Step: 2
Training loss: 2.8523296003740386
Validation loss: 2.2590237173884584
Epoch: 9| Step: 3
Training loss: 2.9042036173662216
Validation loss: 2.2016024461649466
Epoch: 9| Step: 4
Training loss: 3.7837861438508202
Validation loss: 2.2338614596177693
Epoch: 9| Step: 5
Training loss: 2.479625648731905
Validation loss: 2.2556963214003125
Epoch: 9| Step: 6
Training loss: 2.7186823869387586
Validation loss: 2.2391944220621713
Epoch: 9| Step: 7
Training loss: 2.1006721964797337
Validation loss: 2.2218242665956045
Epoch: 9| Step: 8
Training loss: 3.1094305138927836
Validation loss: 2.2189917681786286
Epoch: 9| Step: 9
Training loss: 2.4014259632142143
Validation loss: 2.230293260302958
Epoch: 9| Step: 10
Training loss: 1.6700980467196345
Validation loss: 2.258964276106734
Epoch: 9| Step: 11
Training loss: 2.8847586826042058
Validation loss: 2.240808896049297
Epoch: 9| Step: 12
Training loss: 2.1357351546309102
Validation loss: 2.2529083785219965
Epoch: 9| Step: 13
Training loss: 2.669846506457252
Validation loss: 2.2590353766306617
Epoch: 9| Step: 14
Training loss: 2.5919315444006954
Validation loss: 2.2103583618989617
Epoch: 9| Step: 15
Training loss: 2.182433446194938
Validation loss: 2.221946712553346
Epoch: 9| Step: 16
Training loss: 2.4136909272972566
Validation loss: 2.2402943609371735
Epoch: 9| Step: 17
Training loss: 2.8690927604074195
Validation loss: 2.212861589253116
Epoch: 9| Step: 18
Training loss: 2.7883421237379085
Validation loss: 2.2311193974012355
Epoch: 9| Step: 19
Training loss: 2.450023756106675
Validation loss: 2.2184631946422515
Epoch: 89| Step: 0
Training loss: 2.883316946993738
Validation loss: 2.237014525794996
Epoch: 9| Step: 1
Training loss: 2.2492027989703365
Validation loss: 2.2407660817748702
Epoch: 9| Step: 2
Training loss: 2.125983739796107
Validation loss: 2.2549065569086832
Epoch: 9| Step: 3
Training loss: 2.5414400677170907
Validation loss: 2.2928284003423336
Epoch: 9| Step: 4
Training loss: 2.9144162533478846
Validation loss: 2.277892642120479
Epoch: 9| Step: 5
Training loss: 3.2435829193068186
Validation loss: 2.2676266620385364
Epoch: 9| Step: 6
Training loss: 2.5373341473277247
Validation loss: 2.245822142229995
Epoch: 9| Step: 7
Training loss: 2.4851973030467422
Validation loss: 2.2416394859641082
Epoch: 9| Step: 8
Training loss: 2.287719853576588
Validation loss: 2.260145357270702
Epoch: 9| Step: 9
Training loss: 3.359891629969145
Validation loss: 2.240422647916048
Epoch: 9| Step: 10
Training loss: 3.4780592536024777
Validation loss: 2.2318467778802913
Epoch: 9| Step: 11
Training loss: 2.743607894936601
Validation loss: 2.281260597263168
Epoch: 9| Step: 12
Training loss: 2.1257542786154184
Validation loss: 2.2483848145149095
Epoch: 9| Step: 13
Training loss: 2.225575010600096
Validation loss: 2.273287232537003
Epoch: 9| Step: 14
Training loss: 2.0714244231760364
Validation loss: 2.2554035185570775
Epoch: 9| Step: 15
Training loss: 1.6583359017024766
Validation loss: 2.2432287349792475
Epoch: 9| Step: 16
Training loss: 2.9390775624385594
Validation loss: 2.2772731051159494
Epoch: 9| Step: 17
Training loss: 2.379868286238751
Validation loss: 2.2285173630954023
Epoch: 9| Step: 18
Training loss: 1.9142631581285043
Validation loss: 2.219079269462467
Epoch: 9| Step: 19
Training loss: 2.6946253688497195
Validation loss: 2.2714234478033433
Epoch: 90| Step: 0
Training loss: 1.63864437621258
Validation loss: 2.225146989432957
Epoch: 9| Step: 1
Training loss: 1.5173234369919515
Validation loss: 2.230933150502593
Epoch: 9| Step: 2
Training loss: 2.8896306157569724
Validation loss: 2.2499535150929693
Epoch: 9| Step: 3
Training loss: 2.6352170383602025
Validation loss: 2.248569264492849
Epoch: 9| Step: 4
Training loss: 3.0163453185619424
Validation loss: 2.26252864498464
Epoch: 9| Step: 5
Training loss: 2.621195988714862
Validation loss: 2.296544168980508
Epoch: 9| Step: 6
Training loss: 2.3462788481201433
Validation loss: 2.264582719424027
Epoch: 9| Step: 7
Training loss: 2.156514580015535
Validation loss: 2.269474147839976
Epoch: 9| Step: 8
Training loss: 2.3500616917730395
Validation loss: 2.2787737146655433
Epoch: 9| Step: 9
Training loss: 2.07347677002481
Validation loss: 2.266641231711537
Epoch: 9| Step: 10
Training loss: 2.787171649838607
Validation loss: 2.262693113940705
Epoch: 9| Step: 11
Training loss: 2.8279725766073067
Validation loss: 2.2814409005261567
Epoch: 9| Step: 12
Training loss: 1.9042854817367507
Validation loss: 2.247621946409264
Epoch: 9| Step: 13
Training loss: 2.6931570086344276
Validation loss: 2.2737717533442576
Epoch: 9| Step: 14
Training loss: 3.2772564518319616
Validation loss: 2.242472402339783
Epoch: 9| Step: 15
Training loss: 2.7352535907124538
Validation loss: 2.2926488980428545
Epoch: 9| Step: 16
Training loss: 3.03297186643568
Validation loss: 2.287859075000941
Epoch: 9| Step: 17
Training loss: 2.8643195753334982
Validation loss: 2.24916459109824
Epoch: 9| Step: 18
Training loss: 2.4166072531225935
Validation loss: 2.2897113169458385
Epoch: 9| Step: 19
Training loss: 2.6228737166819314
Validation loss: 2.2575928589894403
Epoch: 91| Step: 0
Training loss: 2.9887490697944625
Validation loss: 2.2822368000323623
Epoch: 9| Step: 1
Training loss: 2.3702466479051325
Validation loss: 2.240525258781274
Epoch: 9| Step: 2
Training loss: 2.6831583838759627
Validation loss: 2.2617861641868284
Epoch: 9| Step: 3
Training loss: 2.972402634497861
Validation loss: 2.1853639696719407
Epoch: 9| Step: 4
Training loss: 2.9897377603412565
Validation loss: 2.221854290113304
Epoch: 9| Step: 5
Training loss: 2.448502772081367
Validation loss: 2.237575983934143
Epoch: 9| Step: 6
Training loss: 2.3075312252556377
Validation loss: 2.2392063632857924
Epoch: 9| Step: 7
Training loss: 2.275005206427014
Validation loss: 2.23145613200038
Epoch: 9| Step: 8
Training loss: 2.3623795735985906
Validation loss: 2.220737011269416
Epoch: 9| Step: 9
Training loss: 2.5041054394981104
Validation loss: 2.2447922917939933
Epoch: 9| Step: 10
Training loss: 1.8950514246422376
Validation loss: 2.2579017490023197
Epoch: 9| Step: 11
Training loss: 1.8771752137769089
Validation loss: 2.297592169187992
Epoch: 9| Step: 12
Training loss: 3.674070570316262
Validation loss: 2.2497169260294947
Epoch: 9| Step: 13
Training loss: 2.056275193080375
Validation loss: 2.244457402300649
Epoch: 9| Step: 14
Training loss: 2.18732288188505
Validation loss: 2.27947562868838
Epoch: 9| Step: 15
Training loss: 2.6870595881644825
Validation loss: 2.255270710387469
Epoch: 9| Step: 16
Training loss: 3.2775721692040314
Validation loss: 2.302267174436099
Epoch: 9| Step: 17
Training loss: 3.046342226056021
Validation loss: 2.2468428663782785
Epoch: 9| Step: 18
Training loss: 2.3552917110279283
Validation loss: 2.2502043243667287
Epoch: 9| Step: 19
Training loss: 2.5695953760122117
Validation loss: 2.279813625249775
Epoch: 92| Step: 0
Training loss: 2.607344334053015
Validation loss: 2.2570865681403656
Epoch: 9| Step: 1
Training loss: 2.4411535025421145
Validation loss: 2.2818263999334802
Epoch: 9| Step: 2
Training loss: 2.0257499765967872
Validation loss: 2.2137160126232356
Epoch: 9| Step: 3
Training loss: 2.1746287281126992
Validation loss: 2.2813742126675765
Epoch: 9| Step: 4
Training loss: 3.6103382229010395
Validation loss: 2.263845168567004
Epoch: 9| Step: 5
Training loss: 2.5907258937869675
Validation loss: 2.2532238637969106
Epoch: 9| Step: 6
Training loss: 2.1324254617487926
Validation loss: 2.2021678256836403
Epoch: 9| Step: 7
Training loss: 2.2143106239429553
Validation loss: 2.2382384368027357
Epoch: 9| Step: 8
Training loss: 2.669323154339864
Validation loss: 2.222000456156817
Epoch: 9| Step: 9
Training loss: 3.242198089214635
Validation loss: 2.215813807896071
Epoch: 9| Step: 10
Training loss: 2.8604397485018924
Validation loss: 2.238649975814602
Epoch: 9| Step: 11
Training loss: 2.6311903124493194
Validation loss: 2.2498038023665736
Epoch: 9| Step: 12
Training loss: 2.9630925933861705
Validation loss: 2.28356718515832
Epoch: 9| Step: 13
Training loss: 2.864349540648911
Validation loss: 2.2506919792603104
Epoch: 9| Step: 14
Training loss: 2.1751741010767662
Validation loss: 2.21829356033291
Epoch: 9| Step: 15
Training loss: 2.6424795105571963
Validation loss: 2.2331711112373034
Epoch: 9| Step: 16
Training loss: 2.7283869107469174
Validation loss: 2.237460333296512
Epoch: 9| Step: 17
Training loss: 2.1950416262075056
Validation loss: 2.216510741143357
Epoch: 9| Step: 18
Training loss: 1.910685709649219
Validation loss: 2.244098207799435
Epoch: 9| Step: 19
Training loss: 2.1480226428296527
Validation loss: 2.1722480767665
Epoch: 93| Step: 0
Training loss: 3.3825948526259717
Validation loss: 2.2394942828120667
Epoch: 9| Step: 1
Training loss: 3.0017885598598495
Validation loss: 2.2389599877248334
Epoch: 9| Step: 2
Training loss: 2.497389097605755
Validation loss: 2.2447667603821007
Epoch: 9| Step: 3
Training loss: 2.9703488511736222
Validation loss: 2.286989532773347
Epoch: 9| Step: 4
Training loss: 2.7161009587609906
Validation loss: 2.293083094269296
Epoch: 9| Step: 5
Training loss: 2.427054692919357
Validation loss: 2.2810395422882235
Epoch: 9| Step: 6
Training loss: 2.978815142471103
Validation loss: 2.254895371899908
Epoch: 9| Step: 7
Training loss: 2.1140135449974338
Validation loss: 2.285456133116506
Epoch: 9| Step: 8
Training loss: 2.2531478901836564
Validation loss: 2.2609834270600766
Epoch: 9| Step: 9
Training loss: 1.852412419069983
Validation loss: 2.2971017004258583
Epoch: 9| Step: 10
Training loss: 2.890755315369144
Validation loss: 2.25455905300513
Epoch: 9| Step: 11
Training loss: 1.8707220229896755
Validation loss: 2.2551185844167136
Epoch: 9| Step: 12
Training loss: 2.637045154854705
Validation loss: 2.2893517741151532
Epoch: 9| Step: 13
Training loss: 2.6245318404025166
Validation loss: 2.220011069685397
Epoch: 9| Step: 14
Training loss: 2.193004657599517
Validation loss: 2.2750583632428585
Epoch: 9| Step: 15
Training loss: 2.7028633828985456
Validation loss: 2.2673923579765063
Epoch: 9| Step: 16
Training loss: 2.472152875672992
Validation loss: 2.2506214345871745
Epoch: 9| Step: 17
Training loss: 2.064749791132497
Validation loss: 2.201379517440692
Epoch: 9| Step: 18
Training loss: 2.9836284242879088
Validation loss: 2.2233192038673
Epoch: 9| Step: 19
Training loss: 2.771755084311384
Validation loss: 2.238210542870764
Epoch: 94| Step: 0
Training loss: 2.1313207530697533
Validation loss: 2.21922960440248
Epoch: 9| Step: 1
Training loss: 2.602451481875337
Validation loss: 2.2790058855235675
Epoch: 9| Step: 2
Training loss: 2.3695084175496453
Validation loss: 2.2733972723871863
Epoch: 9| Step: 3
Training loss: 2.773310268868615
Validation loss: 2.2277246533011343
Epoch: 9| Step: 4
Training loss: 1.4783937109165268
Validation loss: 2.2918802099801856
Epoch: 9| Step: 5
Training loss: 2.4817784974072263
Validation loss: 2.2952247674445543
Epoch: 9| Step: 6
Training loss: 3.293699208398185
Validation loss: 2.279703125756578
Epoch: 9| Step: 7
Training loss: 2.5148029761373083
Validation loss: 2.2900205154589535
Epoch: 9| Step: 8
Training loss: 2.2356717274949194
Validation loss: 2.201760999425092
Epoch: 9| Step: 9
Training loss: 2.671159793542715
Validation loss: 2.2790032402845983
Epoch: 9| Step: 10
Training loss: 3.0088472246183837
Validation loss: 2.2764236576243757
Epoch: 9| Step: 11
Training loss: 3.220545591962969
Validation loss: 2.283937134932312
Epoch: 9| Step: 12
Training loss: 2.625583129781425
Validation loss: 2.3056997744830605
Epoch: 9| Step: 13
Training loss: 2.726827876339355
Validation loss: 2.319706612472059
Epoch: 9| Step: 14
Training loss: 2.7820447150667547
Validation loss: 2.2963024978960713
Epoch: 9| Step: 15
Training loss: 2.365311587496418
Validation loss: 2.302887235751744
Epoch: 9| Step: 16
Training loss: 2.2300582481269546
Validation loss: 2.2879195090468976
Epoch: 9| Step: 17
Training loss: 2.2935447164450506
Validation loss: 2.2736960274946467
Epoch: 9| Step: 18
Training loss: 2.16835153310626
Validation loss: 2.2339946183046613
Epoch: 9| Step: 19
Training loss: 2.8892106178651575
Validation loss: 2.214312847257969
Epoch: 95| Step: 0
Training loss: 2.8997122128511994
Validation loss: 2.2229525065988374
Epoch: 9| Step: 1
Training loss: 2.983417137574372
Validation loss: 2.238178638133451
Epoch: 9| Step: 2
Training loss: 2.8289770033742085
Validation loss: 2.2618796730309545
Epoch: 9| Step: 3
Training loss: 2.568186707004795
Validation loss: 2.226009804844123
Epoch: 9| Step: 4
Training loss: 2.856520932492628
Validation loss: 2.2292384792925213
Epoch: 9| Step: 5
Training loss: 2.5297675795718533
Validation loss: 2.2328275661016455
Epoch: 9| Step: 6
Training loss: 2.436560620958759
Validation loss: 2.2383698306233373
Epoch: 9| Step: 7
Training loss: 2.7057029470740455
Validation loss: 2.2357229482012286
Epoch: 9| Step: 8
Training loss: 2.687341020007044
Validation loss: 2.2306935913707724
Epoch: 9| Step: 9
Training loss: 2.624595701781293
Validation loss: 2.2222344282871327
Epoch: 9| Step: 10
Training loss: 3.3987801214681297
Validation loss: 2.2427220557104746
Epoch: 9| Step: 11
Training loss: 2.658434788393239
Validation loss: 2.1342248248932973
Epoch: 9| Step: 12
Training loss: 2.201807155511362
Validation loss: 2.194397108058753
Epoch: 9| Step: 13
Training loss: 1.842596436749823
Validation loss: 2.166543485420192
Epoch: 9| Step: 14
Training loss: 1.855175501086499
Validation loss: 2.187395546212045
Epoch: 9| Step: 15
Training loss: 3.0036138384782824
Validation loss: 2.2108031858465647
Epoch: 9| Step: 16
Training loss: 2.0692262498949683
Validation loss: 2.2375172789006768
Epoch: 9| Step: 17
Training loss: 2.3409599482170758
Validation loss: 2.2169304374406975
Epoch: 9| Step: 18
Training loss: 1.9455077291671878
Validation loss: 2.260194938172416
Epoch: 9| Step: 19
Training loss: 3.0254029186927434
Validation loss: 2.2359850120780616
Epoch: 96| Step: 0
Training loss: 3.1294767738281246
Validation loss: 2.2324508141590726
Epoch: 9| Step: 1
Training loss: 1.8180089955123082
Validation loss: 2.2647482622233235
Epoch: 9| Step: 2
Training loss: 2.365470943700629
Validation loss: 2.2325591281877317
Epoch: 9| Step: 3
Training loss: 2.4914015723561644
Validation loss: 2.284556985260413
Epoch: 9| Step: 4
Training loss: 2.4002651743624246
Validation loss: 2.283164081187423
Epoch: 9| Step: 5
Training loss: 2.6728106193486805
Validation loss: 2.2425709863184258
Epoch: 9| Step: 6
Training loss: 2.3950416805009196
Validation loss: 2.237745849269562
Epoch: 9| Step: 7
Training loss: 2.4105766337821386
Validation loss: 2.2066105629428914
Epoch: 9| Step: 8
Training loss: 2.0275246129735094
Validation loss: 2.298422566248108
Epoch: 9| Step: 9
Training loss: 3.2662860986033797
Validation loss: 2.2310028400421467
Epoch: 9| Step: 10
Training loss: 2.1449093233518313
Validation loss: 2.232925524188303
Epoch: 9| Step: 11
Training loss: 3.3127910558119678
Validation loss: 2.2722080069528308
Epoch: 9| Step: 12
Training loss: 2.5354282133350936
Validation loss: 2.2343876147477864
Epoch: 9| Step: 13
Training loss: 2.4395661033936236
Validation loss: 2.2499832579824863
Epoch: 9| Step: 14
Training loss: 2.6148662236789124
Validation loss: 2.258542800513923
Epoch: 9| Step: 15
Training loss: 2.8744735235725734
Validation loss: 2.234832790111404
Epoch: 9| Step: 16
Training loss: 2.5945080488178984
Validation loss: 2.228086568549463
Epoch: 9| Step: 17
Training loss: 2.899890627936112
Validation loss: 2.2678546217218343
Epoch: 9| Step: 18
Training loss: 2.5121569688737577
Validation loss: 2.2559694519319526
Epoch: 9| Step: 19
Training loss: 2.1487813778417575
Validation loss: 2.27122843776798
Epoch: 97| Step: 0
Training loss: 2.886555544481511
Validation loss: 2.2398913320384706
Epoch: 9| Step: 1
Training loss: 2.1701750105500746
Validation loss: 2.28271533538839
Epoch: 9| Step: 2
Training loss: 2.8461540037777673
Validation loss: 2.247478983877535
Epoch: 9| Step: 3
Training loss: 2.4969918272643192
Validation loss: 2.2936897057407917
Epoch: 9| Step: 4
Training loss: 2.8773114407931817
Validation loss: 2.2429379809163614
Epoch: 9| Step: 5
Training loss: 2.341458637413912
Validation loss: 2.2716647466455795
Epoch: 9| Step: 6
Training loss: 3.0687553203715336
Validation loss: 2.280800468231808
Epoch: 9| Step: 7
Training loss: 2.4976781553585177
Validation loss: 2.2502339691869833
Epoch: 9| Step: 8
Training loss: 3.0742435672441744
Validation loss: 2.2838517986737186
Epoch: 9| Step: 9
Training loss: 1.994392879720342
Validation loss: 2.2645239758906683
Epoch: 9| Step: 10
Training loss: 3.052112479390795
Validation loss: 2.3125590776505534
Epoch: 9| Step: 11
Training loss: 2.211478339051006
Validation loss: 2.275973399871652
Epoch: 9| Step: 12
Training loss: 2.7256670249213144
Validation loss: 2.26446234484088
Epoch: 9| Step: 13
Training loss: 2.809635823228249
Validation loss: 2.2125202876900443
Epoch: 9| Step: 14
Training loss: 2.5652927903793583
Validation loss: 2.218756350216784
Epoch: 9| Step: 15
Training loss: 2.2244315675004325
Validation loss: 2.252547854575602
Epoch: 9| Step: 16
Training loss: 2.057277193300223
Validation loss: 2.2369745990319623
Epoch: 9| Step: 17
Training loss: 3.0315414760494868
Validation loss: 2.249030888306007
Epoch: 9| Step: 18
Training loss: 1.7765324679799654
Validation loss: 2.1898071129024794
Epoch: 9| Step: 19
Training loss: 2.076040383999038
Validation loss: 2.2255048683377368
Epoch: 98| Step: 0
Training loss: 3.281209018996317
Validation loss: 2.231828887923424
Epoch: 9| Step: 1
Training loss: 3.140053160879512
Validation loss: 2.2392473088160703
Epoch: 9| Step: 2
Training loss: 2.4842105067276083
Validation loss: 2.2520555667701303
Epoch: 9| Step: 3
Training loss: 2.5615602956745844
Validation loss: 2.1786951570270445
Epoch: 9| Step: 4
Training loss: 1.9674373671027725
Validation loss: 2.2619041244159286
Epoch: 9| Step: 5
Training loss: 2.5569779979966136
Validation loss: 2.2666146751592557
Epoch: 9| Step: 6
Training loss: 2.1394881968037813
Validation loss: 2.1735819057285117
Epoch: 9| Step: 7
Training loss: 2.524229321093135
Validation loss: 2.1693380913978504
Epoch: 9| Step: 8
Training loss: 2.548645621010375
Validation loss: 2.2684743399657346
Epoch: 9| Step: 9
Training loss: 2.3111667398131943
Validation loss: 2.313950428630288
Epoch: 9| Step: 10
Training loss: 2.582450059406023
Validation loss: 2.227715643064438
Epoch: 9| Step: 11
Training loss: 2.4964849556504567
Validation loss: 2.2629891724211744
Epoch: 9| Step: 12
Training loss: 1.4486629931939765
Validation loss: 2.198941128701762
Epoch: 9| Step: 13
Training loss: 3.8390311451408956
Validation loss: 2.2431504216004714
Epoch: 9| Step: 14
Training loss: 2.6024338921057653
Validation loss: 2.2356673959615776
Epoch: 9| Step: 15
Training loss: 2.858147362830729
Validation loss: 2.258473125961607
Epoch: 9| Step: 16
Training loss: 2.414064178960025
Validation loss: 2.2656642367652946
Epoch: 9| Step: 17
Training loss: 2.4188272311081245
Validation loss: 2.2602975837243284
Epoch: 9| Step: 18
Training loss: 2.2945567778069016
Validation loss: 2.268219803810405
Epoch: 9| Step: 19
Training loss: 1.8110926195512524
Validation loss: 2.26714799196026
Epoch: 99| Step: 0
Training loss: 2.849723159996958
Validation loss: 2.2951743258931687
Epoch: 9| Step: 1
Training loss: 3.4746442324523326
Validation loss: 2.244698772573069
Epoch: 9| Step: 2
Training loss: 3.0722566229802952
Validation loss: 2.2389511021154433
Epoch: 9| Step: 3
Training loss: 2.2223918201048822
Validation loss: 2.2426637622035686
Epoch: 9| Step: 4
Training loss: 1.9327238958429256
Validation loss: 2.1924272449099753
Epoch: 9| Step: 5
Training loss: 2.8004204638723627
Validation loss: 2.254193322326932
Epoch: 9| Step: 6
Training loss: 2.6523795258885987
Validation loss: 2.2421613186444307
Epoch: 9| Step: 7
Training loss: 2.8836127930381603
Validation loss: 2.229059238627538
Epoch: 9| Step: 8
Training loss: 1.9673895601058218
Validation loss: 2.2412315148642947
Epoch: 9| Step: 9
Training loss: 2.8215827934235853
Validation loss: 2.247132265948444
Epoch: 9| Step: 10
Training loss: 2.5972296113460462
Validation loss: 2.2505394244740455
Epoch: 9| Step: 11
Training loss: 2.399907956742546
Validation loss: 2.2481543167372204
Epoch: 9| Step: 12
Training loss: 2.3275244021340136
Validation loss: 2.249632451537242
Epoch: 9| Step: 13
Training loss: 2.428768855172404
Validation loss: 2.2651816621900775
Epoch: 9| Step: 14
Training loss: 1.961604457064352
Validation loss: 2.2588712035383556
Epoch: 9| Step: 15
Training loss: 3.176918267303083
Validation loss: 2.2452321930311387
Epoch: 9| Step: 16
Training loss: 2.166202740029909
Validation loss: 2.230915506453756
Epoch: 9| Step: 17
Training loss: 2.1846886143649487
Validation loss: 2.2914587245777613
Epoch: 9| Step: 18
Training loss: 2.6538809590093306
Validation loss: 2.246343183606444
Epoch: 9| Step: 19
Training loss: 2.1562077614890374
Validation loss: 2.215595163699071
Epoch: 100| Step: 0
Training loss: 2.299240243897474
Validation loss: 2.228278951633212
Epoch: 9| Step: 1
Training loss: 2.1372299559150036
Validation loss: 2.2765612746121056
Epoch: 9| Step: 2
Training loss: 3.236748013742771
Validation loss: 2.2021447053723655
Epoch: 9| Step: 3
Training loss: 2.741303478020257
Validation loss: 2.2245832723765564
Epoch: 9| Step: 4
Training loss: 3.117824250392483
Validation loss: 2.2410293011901805
Epoch: 9| Step: 5
Training loss: 2.4924256979256523
Validation loss: 2.2667231502070035
Epoch: 9| Step: 6
Training loss: 2.8977935157860775
Validation loss: 2.270955712385359
Epoch: 9| Step: 7
Training loss: 3.279445769773418
Validation loss: 2.3035476693411874
Epoch: 9| Step: 8
Training loss: 1.4694690161855808
Validation loss: 2.242733867657103
Epoch: 9| Step: 9
Training loss: 2.8108038980266166
Validation loss: 2.2571122622418476
Epoch: 9| Step: 10
Training loss: 2.880817663892954
Validation loss: 2.3098476691054515
Epoch: 9| Step: 11
Training loss: 2.6808108096786762
Validation loss: 2.2870660987742784
Epoch: 9| Step: 12
Training loss: 2.035021757342276
Validation loss: 2.2434124519237177
Epoch: 9| Step: 13
Training loss: 3.0937395191978405
Validation loss: 2.2857145903552554
Epoch: 9| Step: 14
Training loss: 1.3912550966729842
Validation loss: 2.280004915372091
Epoch: 9| Step: 15
Training loss: 2.437275802865445
Validation loss: 2.2782122149254094
Epoch: 9| Step: 16
Training loss: 2.6012328342822744
Validation loss: 2.2536016622506567
Epoch: 9| Step: 17
Training loss: 2.4216697359776678
Validation loss: 2.214816185309108
Epoch: 9| Step: 18
Training loss: 2.1936434988921816
Validation loss: 2.22323495019008
Epoch: 9| Step: 19
Training loss: 2.288427271275084
Validation loss: 2.313804402000796
