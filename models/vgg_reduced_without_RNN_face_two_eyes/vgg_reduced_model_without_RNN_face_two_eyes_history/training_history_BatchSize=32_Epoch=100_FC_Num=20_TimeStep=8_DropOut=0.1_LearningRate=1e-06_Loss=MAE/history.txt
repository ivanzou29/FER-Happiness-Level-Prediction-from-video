Epoch: 1| Step: 0
Training loss: 6.900051593780518
Validation loss: 6.323264677747548
Epoch: 5| Step: 1
Training loss: 6.06768798828125
Validation loss: 6.3170502340193275
Epoch: 5| Step: 2
Training loss: 6.087011337280273
Validation loss: 6.3115706958359095
Epoch: 5| Step: 3
Training loss: 6.253815650939941
Validation loss: 6.304215571863188
Epoch: 5| Step: 4
Training loss: 6.07985258102417
Validation loss: 6.297561278446115
Epoch: 5| Step: 5
Training loss: 6.856768608093262
Validation loss: 6.291119256465555
Epoch: 5| Step: 6
Training loss: 6.24354887008667
Validation loss: 6.2843773313563505
Epoch: 5| Step: 7
Training loss: 6.898982524871826
Validation loss: 6.279295122023109
Epoch: 5| Step: 8
Training loss: 6.416144371032715
Validation loss: 6.272850513458252
Epoch: 5| Step: 9
Training loss: 6.579575538635254
Validation loss: 6.265526798989275
Epoch: 2| Step: 0
Training loss: 6.400671005249023
Validation loss: 6.259558934959577
Epoch: 5| Step: 1
Training loss: 6.20355224609375
Validation loss: 6.253727659047079
Epoch: 5| Step: 2
Training loss: 6.476922988891602
Validation loss: 6.246325805032853
Epoch: 5| Step: 3
Training loss: 7.158804416656494
Validation loss: 6.240902458163474
Epoch: 5| Step: 4
Training loss: 5.978484630584717
Validation loss: 6.233895483634455
Epoch: 5| Step: 5
Training loss: 6.848090171813965
Validation loss: 6.228145239164504
Epoch: 5| Step: 6
Training loss: 6.038387298583984
Validation loss: 6.220291686572617
Epoch: 5| Step: 7
Training loss: 6.515382766723633
Validation loss: 6.215884164082918
Epoch: 5| Step: 8
Training loss: 5.838216304779053
Validation loss: 6.20826409703536
Epoch: 5| Step: 9
Training loss: 6.303792476654053
Validation loss: 6.202740079207386
Epoch: 3| Step: 0
Training loss: 6.283357620239258
Validation loss: 6.1955356838034215
Epoch: 5| Step: 1
Training loss: 6.699782371520996
Validation loss: 6.19164286071448
Epoch: 5| Step: 2
Training loss: 6.210762023925781
Validation loss: 6.183953384701296
Epoch: 5| Step: 3
Training loss: 6.7810516357421875
Validation loss: 6.178790185091307
Epoch: 5| Step: 4
Training loss: 6.02855110168457
Validation loss: 6.171647253653986
Epoch: 5| Step: 5
Training loss: 6.584965705871582
Validation loss: 6.165118327243722
Epoch: 5| Step: 6
Training loss: 6.119009017944336
Validation loss: 6.15771978364574
Epoch: 5| Step: 7
Training loss: 5.862764358520508
Validation loss: 6.151847787898221
Epoch: 5| Step: 8
Training loss: 6.2861127853393555
Validation loss: 6.144624596877064
Epoch: 5| Step: 9
Training loss: 6.3017802238464355
Validation loss: 6.139332829619483
Epoch: 4| Step: 0
Training loss: 6.2838897705078125
Validation loss: 6.131777989778588
Epoch: 5| Step: 1
Training loss: 6.321599960327148
Validation loss: 6.126129695837446
Epoch: 5| Step: 2
Training loss: 5.319892883300781
Validation loss: 6.120235371075088
Epoch: 5| Step: 3
Training loss: 6.089573860168457
Validation loss: 6.112774965574416
Epoch: 5| Step: 4
Training loss: 6.594931602478027
Validation loss: 6.106040611541529
Epoch: 5| Step: 5
Training loss: 6.514553070068359
Validation loss: 6.099774813480514
Epoch: 5| Step: 6
Training loss: 6.67990255355835
Validation loss: 6.093837117119659
Epoch: 5| Step: 7
Training loss: 6.6721720695495605
Validation loss: 6.08526694002769
Epoch: 5| Step: 8
Training loss: 5.239577293395996
Validation loss: 6.07939604203478
Epoch: 5| Step: 9
Training loss: 6.820335865020752
Validation loss: 6.07137001161095
Epoch: 5| Step: 0
Training loss: 6.301326751708984
Validation loss: 6.064273419140054
Epoch: 5| Step: 1
Training loss: 6.243616104125977
Validation loss: 6.058843972871629
Epoch: 5| Step: 2
Training loss: 6.040460109710693
Validation loss: 6.051389443788597
Epoch: 5| Step: 3
Training loss: 6.357457160949707
Validation loss: 6.044903779201371
Epoch: 5| Step: 4
Training loss: 5.8913774490356445
Validation loss: 6.03763447905616
Epoch: 5| Step: 5
Training loss: 5.828226089477539
Validation loss: 6.028595625925407
Epoch: 5| Step: 6
Training loss: 6.242857456207275
Validation loss: 6.021882859922999
Epoch: 5| Step: 7
Training loss: 6.21900749206543
Validation loss: 6.014511098106988
Epoch: 5| Step: 8
Training loss: 6.176274299621582
Validation loss: 6.007525560667189
Epoch: 5| Step: 9
Training loss: 6.552056312561035
Validation loss: 5.9980641474826735
Epoch: 6| Step: 0
Training loss: 6.735832214355469
Validation loss: 5.991841635258078
Epoch: 5| Step: 1
Training loss: 5.789797782897949
Validation loss: 5.983641765100493
Epoch: 5| Step: 2
Training loss: 6.538887977600098
Validation loss: 5.976385559109475
Epoch: 5| Step: 3
Training loss: 6.405474662780762
Validation loss: 5.96843786033795
Epoch: 5| Step: 4
Training loss: 5.528810501098633
Validation loss: 5.959302394510173
Epoch: 5| Step: 5
Training loss: 6.622016906738281
Validation loss: 5.9532372934355156
Epoch: 5| Step: 6
Training loss: 6.122348785400391
Validation loss: 5.940604158442655
Epoch: 5| Step: 7
Training loss: 5.780920028686523
Validation loss: 5.934727517820948
Epoch: 5| Step: 8
Training loss: 5.708552360534668
Validation loss: 5.926525325226269
Epoch: 5| Step: 9
Training loss: 5.869884967803955
Validation loss: 5.915672302246094
Epoch: 7| Step: 0
Training loss: 6.405166149139404
Validation loss: 5.907756980374563
Epoch: 5| Step: 1
Training loss: 6.28926944732666
Validation loss: 5.900367366324226
Epoch: 5| Step: 2
Training loss: 6.111171722412109
Validation loss: 5.889176447614491
Epoch: 5| Step: 3
Training loss: 5.020991325378418
Validation loss: 5.882260435776745
Epoch: 5| Step: 4
Training loss: 6.337003707885742
Validation loss: 5.8722760317136915
Epoch: 5| Step: 5
Training loss: 6.242344856262207
Validation loss: 5.862942369721776
Epoch: 5| Step: 6
Training loss: 5.771553039550781
Validation loss: 5.854163557505436
Epoch: 5| Step: 7
Training loss: 6.206199645996094
Validation loss: 5.844450274817378
Epoch: 5| Step: 8
Training loss: 6.122269630432129
Validation loss: 5.833977246456009
Epoch: 5| Step: 9
Training loss: 5.740504264831543
Validation loss: 5.822760715759058
Epoch: 8| Step: 0
Training loss: 6.552959442138672
Validation loss: 5.815262101537032
Epoch: 5| Step: 1
Training loss: 6.106687545776367
Validation loss: 5.805610824831955
Epoch: 5| Step: 2
Training loss: 5.481290817260742
Validation loss: 5.795785958818395
Epoch: 5| Step: 3
Training loss: 5.536118507385254
Validation loss: 5.786409127626488
Epoch: 5| Step: 4
Training loss: 5.721166133880615
Validation loss: 5.774824753082056
Epoch: 5| Step: 5
Training loss: 6.23634672164917
Validation loss: 5.765151092474409
Epoch: 5| Step: 6
Training loss: 6.514257431030273
Validation loss: 5.754494876312695
Epoch: 5| Step: 7
Training loss: 5.582108497619629
Validation loss: 5.743258634059549
Epoch: 5| Step: 8
Training loss: 5.815911293029785
Validation loss: 5.732395144675276
Epoch: 5| Step: 9
Training loss: 5.765734672546387
Validation loss: 5.72155926038893
Epoch: 9| Step: 0
Training loss: 5.9148969650268555
Validation loss: 5.709154420619388
Epoch: 5| Step: 1
Training loss: 5.702770233154297
Validation loss: 5.702781001440913
Epoch: 5| Step: 2
Training loss: 6.325148582458496
Validation loss: 5.688681804876533
Epoch: 5| Step: 3
Training loss: 4.747304916381836
Validation loss: 5.677131313214199
Epoch: 5| Step: 4
Training loss: 6.087350845336914
Validation loss: 5.666107898135837
Epoch: 5| Step: 5
Training loss: 6.328085899353027
Validation loss: 5.656493804437651
Epoch: 5| Step: 6
Training loss: 5.738252639770508
Validation loss: 5.643052855841548
Epoch: 5| Step: 7
Training loss: 5.357792377471924
Validation loss: 5.627751624841484
Epoch: 5| Step: 8
Training loss: 6.293684005737305
Validation loss: 5.616937445222045
Epoch: 5| Step: 9
Training loss: 5.745136737823486
Validation loss: 5.603997717658393
Epoch: 10| Step: 0
Training loss: 5.904822826385498
Validation loss: 5.592918056378261
Epoch: 5| Step: 1
Training loss: 5.367166996002197
Validation loss: 5.5813688785909745
Epoch: 5| Step: 2
Training loss: 5.413664817810059
Validation loss: 5.565876134007954
Epoch: 5| Step: 3
Training loss: 5.6579132080078125
Validation loss: 5.553864448190593
Epoch: 5| Step: 4
Training loss: 6.210070610046387
Validation loss: 5.540034945920217
Epoch: 5| Step: 5
Training loss: 5.197092056274414
Validation loss: 5.529825642812166
Epoch: 5| Step: 6
Training loss: 6.270235061645508
Validation loss: 5.512217463349267
Epoch: 5| Step: 7
Training loss: 5.871955871582031
Validation loss: 5.4988248845656145
Epoch: 5| Step: 8
Training loss: 5.387162208557129
Validation loss: 5.4835491694992395
Epoch: 5| Step: 9
Training loss: 5.759380340576172
Validation loss: 5.471802893302423
Epoch: 11| Step: 0
Training loss: 6.460697174072266
Validation loss: 5.456519065143393
Epoch: 5| Step: 1
Training loss: 5.510066986083984
Validation loss: 5.443653405141488
Epoch: 5| Step: 2
Training loss: 6.038221836090088
Validation loss: 5.424125685108652
Epoch: 5| Step: 3
Training loss: 5.284391403198242
Validation loss: 5.412702423205479
Epoch: 5| Step: 4
Training loss: 5.466741561889648
Validation loss: 5.396925113183989
Epoch: 5| Step: 5
Training loss: 5.5869669914245605
Validation loss: 5.379508649702553
Epoch: 5| Step: 6
Training loss: 5.39301872253418
Validation loss: 5.365905092774535
Epoch: 5| Step: 7
Training loss: 5.990126132965088
Validation loss: 5.349547574846007
Epoch: 5| Step: 8
Training loss: 4.734194755554199
Validation loss: 5.331635976009232
Epoch: 5| Step: 9
Training loss: 5.200523376464844
Validation loss: 5.313727413150047
Epoch: 12| Step: 0
Training loss: 5.572516441345215
Validation loss: 5.301321156590962
Epoch: 5| Step: 1
Training loss: 5.747204780578613
Validation loss: 5.285330734664588
Epoch: 5| Step: 2
Training loss: 5.13117790222168
Validation loss: 5.2662344390539815
Epoch: 5| Step: 3
Training loss: 4.035436630249023
Validation loss: 5.25177197833713
Epoch: 5| Step: 4
Training loss: 6.079301357269287
Validation loss: 5.234573343674914
Epoch: 5| Step: 5
Training loss: 5.882906913757324
Validation loss: 5.218874193781572
Epoch: 5| Step: 6
Training loss: 5.448234558105469
Validation loss: 5.204955166192364
Epoch: 5| Step: 7
Training loss: 5.043636322021484
Validation loss: 5.182409893694541
Epoch: 5| Step: 8
Training loss: 5.525343894958496
Validation loss: 5.16343595655702
Epoch: 5| Step: 9
Training loss: 5.58192253112793
Validation loss: 5.144757387449416
Epoch: 13| Step: 0
Training loss: 5.782937049865723
Validation loss: 5.120506434131869
Epoch: 5| Step: 1
Training loss: 5.46145486831665
Validation loss: 5.108055890035287
Epoch: 5| Step: 2
Training loss: 5.14415979385376
Validation loss: 5.0834065718616515
Epoch: 5| Step: 3
Training loss: 5.964846611022949
Validation loss: 5.06316841592034
Epoch: 5| Step: 4
Training loss: 5.847865581512451
Validation loss: 5.045017225279225
Epoch: 5| Step: 5
Training loss: 5.690113544464111
Validation loss: 5.0276663251918
Epoch: 5| Step: 6
Training loss: 5.138115882873535
Validation loss: 5.005741311491822
Epoch: 5| Step: 7
Training loss: 3.7691245079040527
Validation loss: 4.982705912144064
Epoch: 5| Step: 8
Training loss: 5.202842712402344
Validation loss: 4.966735634014761
Epoch: 5| Step: 9
Training loss: 4.2817864418029785
Validation loss: 4.942973033987361
Epoch: 14| Step: 0
Training loss: 5.327215194702148
Validation loss: 4.920424169773678
Epoch: 5| Step: 1
Training loss: 5.876689910888672
Validation loss: 4.904546617603988
Epoch: 5| Step: 2
Training loss: 5.16141939163208
Validation loss: 4.878605424071387
Epoch: 5| Step: 3
Training loss: 4.613289833068848
Validation loss: 4.857238580854677
Epoch: 5| Step: 4
Training loss: 4.2655029296875
Validation loss: 4.832339400010143
Epoch: 5| Step: 5
Training loss: 5.538116455078125
Validation loss: 4.806708071729262
Epoch: 5| Step: 6
Training loss: 4.344204902648926
Validation loss: 4.788959530617693
Epoch: 5| Step: 7
Training loss: 5.596560478210449
Validation loss: 4.7628774985992655
Epoch: 5| Step: 8
Training loss: 4.748491287231445
Validation loss: 4.7414140907122935
Epoch: 5| Step: 9
Training loss: 4.774805068969727
Validation loss: 4.719900981985408
Epoch: 15| Step: 0
Training loss: 5.017983436584473
Validation loss: 4.687105374370548
Epoch: 5| Step: 1
Training loss: 5.333136558532715
Validation loss: 4.6620487206273795
Epoch: 5| Step: 2
Training loss: 4.569194793701172
Validation loss: 4.6379154054381
Epoch: 5| Step: 3
Training loss: 4.592607498168945
Validation loss: 4.610227252082002
Epoch: 5| Step: 4
Training loss: 4.817440986633301
Validation loss: 4.583308727621175
Epoch: 5| Step: 5
Training loss: 5.08348274230957
Validation loss: 4.560772230299257
Epoch: 5| Step: 6
Training loss: 5.132168292999268
Validation loss: 4.52909706650878
Epoch: 5| Step: 7
Training loss: 3.8944923877716064
Validation loss: 4.504883947989923
Epoch: 5| Step: 8
Training loss: 4.66292667388916
Validation loss: 4.479191934462074
Epoch: 5| Step: 9
Training loss: 4.879324436187744
Validation loss: 4.444056929444238
Epoch: 16| Step: 0
Training loss: 4.26305627822876
Validation loss: 4.422825991678581
Epoch: 5| Step: 1
Training loss: 4.476035118103027
Validation loss: 4.3853606268656335
Epoch: 5| Step: 2
Training loss: 4.696574687957764
Validation loss: 4.356767498331962
Epoch: 5| Step: 3
Training loss: 4.6785888671875
Validation loss: 4.3279159669395835
Epoch: 5| Step: 4
Training loss: 4.206521987915039
Validation loss: 4.296011566258163
Epoch: 5| Step: 5
Training loss: 5.143319606781006
Validation loss: 4.265522641243694
Epoch: 5| Step: 6
Training loss: 5.189167499542236
Validation loss: 4.22541244081456
Epoch: 5| Step: 7
Training loss: 4.204750061035156
Validation loss: 4.204728925828453
Epoch: 5| Step: 8
Training loss: 4.102331638336182
Validation loss: 4.166217064685958
Epoch: 5| Step: 9
Training loss: 4.412622451782227
Validation loss: 4.133998894862992
Epoch: 17| Step: 0
Training loss: 3.689537525177002
Validation loss: 4.104902185124459
Epoch: 5| Step: 1
Training loss: 5.099994659423828
Validation loss: 4.072053979626663
Epoch: 5| Step: 2
Training loss: 3.8771700859069824
Validation loss: 4.0434206578371334
Epoch: 5| Step: 3
Training loss: 4.30711555480957
Validation loss: 3.9964413625730884
Epoch: 5| Step: 4
Training loss: 3.976120710372925
Validation loss: 3.958503380096216
Epoch: 5| Step: 5
Training loss: 4.888920307159424
Validation loss: 3.924307687677068
Epoch: 5| Step: 6
Training loss: 4.229576110839844
Validation loss: 3.88405490093094
Epoch: 5| Step: 7
Training loss: 3.9562368392944336
Validation loss: 3.8587979052564223
Epoch: 5| Step: 8
Training loss: 3.979274034500122
Validation loss: 3.8150722037116402
Epoch: 5| Step: 9
Training loss: 4.529303550720215
Validation loss: 3.790489793681412
Epoch: 18| Step: 0
Training loss: 3.353442430496216
Validation loss: 3.7513699291421356
Epoch: 5| Step: 1
Training loss: 4.031232833862305
Validation loss: 3.706758656947733
Epoch: 5| Step: 2
Training loss: 4.191318511962891
Validation loss: 3.669034397001747
Epoch: 5| Step: 3
Training loss: 4.2543840408325195
Validation loss: 3.626147345673266
Epoch: 5| Step: 4
Training loss: 3.942646026611328
Validation loss: 3.5839017055017486
Epoch: 5| Step: 5
Training loss: 4.039935111999512
Validation loss: 3.55182108947699
Epoch: 5| Step: 6
Training loss: 4.13260555267334
Validation loss: 3.5190142590364966
Epoch: 5| Step: 7
Training loss: 3.918825149536133
Validation loss: 3.4734493965725246
Epoch: 5| Step: 8
Training loss: 3.6824636459350586
Validation loss: 3.433814456994585
Epoch: 5| Step: 9
Training loss: 4.016992092132568
Validation loss: 3.3962378982159733
Epoch: 19| Step: 0
Training loss: 3.971254348754883
Validation loss: 3.353996640486683
Epoch: 5| Step: 1
Training loss: 4.651984214782715
Validation loss: 3.3209490364404033
Epoch: 5| Step: 2
Training loss: 3.8038949966430664
Validation loss: 3.276169270920239
Epoch: 5| Step: 3
Training loss: 3.2149839401245117
Validation loss: 3.238899116035846
Epoch: 5| Step: 4
Training loss: 3.69683837890625
Validation loss: 3.203810278460276
Epoch: 5| Step: 5
Training loss: 3.449479579925537
Validation loss: 3.154805181695403
Epoch: 5| Step: 6
Training loss: 3.1896581649780273
Validation loss: 3.109066098714046
Epoch: 5| Step: 7
Training loss: 3.4757742881774902
Validation loss: 3.0867339235415563
Epoch: 5| Step: 8
Training loss: 2.9981560707092285
Validation loss: 3.044872741905048
Epoch: 5| Step: 9
Training loss: 3.967259168624878
Validation loss: 2.998348646026721
Epoch: 20| Step: 0
Training loss: 4.153052806854248
Validation loss: 2.9668054614993307
Epoch: 5| Step: 1
Training loss: 2.6153218746185303
Validation loss: 2.9238918788141484
Epoch: 5| Step: 2
Training loss: 3.181812047958374
Validation loss: 2.888290075947055
Epoch: 5| Step: 3
Training loss: 3.871025562286377
Validation loss: 2.8507439026729666
Epoch: 5| Step: 4
Training loss: 3.58648943901062
Validation loss: 2.8151158463183066
Epoch: 5| Step: 5
Training loss: 3.4529409408569336
Validation loss: 2.780141106612391
Epoch: 5| Step: 6
Training loss: 3.2451958656311035
Validation loss: 2.753593637788896
Epoch: 5| Step: 7
Training loss: 3.1335432529449463
Validation loss: 2.7104608275049884
Epoch: 5| Step: 8
Training loss: 3.0489342212677
Validation loss: 2.6831535967133884
Epoch: 5| Step: 9
Training loss: 2.980701446533203
Validation loss: 2.6456363578494506
Epoch: 21| Step: 0
Training loss: 3.4444448947906494
Validation loss: 2.611389338541374
Epoch: 5| Step: 1
Training loss: 3.2041149139404297
Validation loss: 2.5731742090458494
Epoch: 5| Step: 2
Training loss: 2.877033233642578
Validation loss: 2.5414700808284953
Epoch: 5| Step: 3
Training loss: 3.0373940467834473
Validation loss: 2.5173307717275275
Epoch: 5| Step: 4
Training loss: 3.0497183799743652
Validation loss: 2.4839029895315927
Epoch: 5| Step: 5
Training loss: 3.0451462268829346
Validation loss: 2.4526445376787254
Epoch: 5| Step: 6
Training loss: 2.9472622871398926
Validation loss: 2.435793234289979
Epoch: 5| Step: 7
Training loss: 3.343168020248413
Validation loss: 2.4008034913659952
Epoch: 5| Step: 8
Training loss: 2.4164605140686035
Validation loss: 2.366834496422637
Epoch: 5| Step: 9
Training loss: 2.806342363357544
Validation loss: 2.3414931297302246
Epoch: 22| Step: 0
Training loss: 3.3825321197509766
Validation loss: 2.324568470604986
Epoch: 5| Step: 1
Training loss: 2.7076282501220703
Validation loss: 2.291089690846505
Epoch: 5| Step: 2
Training loss: 2.639946460723877
Validation loss: 2.277940642919472
Epoch: 5| Step: 3
Training loss: 3.124363899230957
Validation loss: 2.233918701144431
Epoch: 5| Step: 4
Training loss: 2.0941224098205566
Validation loss: 2.224505216955281
Epoch: 5| Step: 5
Training loss: 2.8442702293395996
Validation loss: 2.1758319919915508
Epoch: 5| Step: 6
Training loss: 2.5171070098876953
Validation loss: 2.1686322414617742
Epoch: 5| Step: 7
Training loss: 2.782013416290283
Validation loss: 2.1538276380772214
Epoch: 5| Step: 8
Training loss: 2.6905417442321777
Validation loss: 2.130197765158235
Epoch: 5| Step: 9
Training loss: 2.6139039993286133
Validation loss: 2.0923559013888133
Epoch: 23| Step: 0
Training loss: 2.7962427139282227
Validation loss: 2.0601863089225274
Epoch: 5| Step: 1
Training loss: 2.344122886657715
Validation loss: 2.070275886453313
Epoch: 5| Step: 2
Training loss: 2.389601230621338
Validation loss: 2.0427739928952224
Epoch: 5| Step: 3
Training loss: 2.297123432159424
Validation loss: 2.0270564436054914
Epoch: 5| Step: 4
Training loss: 2.66489839553833
Validation loss: 2.015264952783104
Epoch: 5| Step: 5
Training loss: 2.754870891571045
Validation loss: 2.0088041823544946
Epoch: 5| Step: 6
Training loss: 2.4001786708831787
Validation loss: 1.9714261087582265
Epoch: 5| Step: 7
Training loss: 2.4750866889953613
Validation loss: 1.9809832144126618
Epoch: 5| Step: 8
Training loss: 2.4647116661071777
Validation loss: 1.959588346721457
Epoch: 5| Step: 9
Training loss: 2.3931195735931396
Validation loss: 1.950195891394032
Epoch: 24| Step: 0
Training loss: 2.2470803260803223
Validation loss: 1.9439576186722132
Epoch: 5| Step: 1
Training loss: 2.342153549194336
Validation loss: 1.923951227030308
Epoch: 5| Step: 2
Training loss: 2.188768148422241
Validation loss: 1.92853551459827
Epoch: 5| Step: 3
Training loss: 2.704634428024292
Validation loss: 1.9195642145417577
Epoch: 5| Step: 4
Training loss: 2.5638763904571533
Validation loss: 1.9195846430689312
Epoch: 5| Step: 5
Training loss: 2.4992737770080566
Validation loss: 1.904952171037523
Epoch: 5| Step: 6
Training loss: 2.511892080307007
Validation loss: 1.905932080831459
Epoch: 5| Step: 7
Training loss: 1.9525957107543945
Validation loss: 1.9170311346328517
Epoch: 5| Step: 8
Training loss: 2.6727724075317383
Validation loss: 1.8947323337733317
Epoch: 5| Step: 9
Training loss: 2.02009916305542
Validation loss: 1.902546342328298
Epoch: 25| Step: 0
Training loss: 2.4173569679260254
Validation loss: 1.8823961576969503
Epoch: 5| Step: 1
Training loss: 1.8380571603775024
Validation loss: 1.8953570564873785
Epoch: 5| Step: 2
Training loss: 2.657163143157959
Validation loss: 1.8989133071556366
Epoch: 5| Step: 3
Training loss: 2.6437642574310303
Validation loss: 1.8923846826278905
Epoch: 5| Step: 4
Training loss: 2.103653907775879
Validation loss: 1.8967063135380366
Epoch: 5| Step: 5
Training loss: 2.8123042583465576
Validation loss: 1.8851654966958136
Epoch: 5| Step: 6
Training loss: 2.554340124130249
Validation loss: 1.8908131465637426
Epoch: 5| Step: 7
Training loss: 1.927040457725525
Validation loss: 1.9111977078074174
Epoch: 5| Step: 8
Training loss: 2.4727556705474854
Validation loss: 1.9134880407251043
Epoch: 5| Step: 9
Training loss: 1.608623743057251
Validation loss: 1.9045204292956015
Epoch: 26| Step: 0
Training loss: 2.596834659576416
Validation loss: 1.941929796616808
Epoch: 5| Step: 1
Training loss: 2.1818017959594727
Validation loss: 1.92290058410425
Epoch: 5| Step: 2
Training loss: 2.012150764465332
Validation loss: 1.9238266138721714
Epoch: 5| Step: 3
Training loss: 2.1226563453674316
Validation loss: 1.9452159850717448
Epoch: 5| Step: 4
Training loss: 2.1048576831817627
Validation loss: 1.9577705748647236
Epoch: 5| Step: 5
Training loss: 2.4386730194091797
Validation loss: 1.9308586682347084
Epoch: 5| Step: 6
Training loss: 2.0291247367858887
Validation loss: 1.9596999480569963
Epoch: 5| Step: 7
Training loss: 2.229464292526245
Validation loss: 1.9449542289157566
Epoch: 5| Step: 8
Training loss: 2.8256478309631348
Validation loss: 1.9622886523926
Epoch: 5| Step: 9
Training loss: 2.176781177520752
Validation loss: 1.950772410674061
Epoch: 27| Step: 0
Training loss: 2.623624801635742
Validation loss: 1.9464016055031645
Epoch: 5| Step: 1
Training loss: 2.5511975288391113
Validation loss: 1.9744711196679863
Epoch: 5| Step: 2
Training loss: 2.2595577239990234
Validation loss: 1.976186671702982
Epoch: 5| Step: 3
Training loss: 2.002061367034912
Validation loss: 1.9574798722918942
Epoch: 5| Step: 4
Training loss: 2.480915069580078
Validation loss: 1.989207435854905
Epoch: 5| Step: 5
Training loss: 2.25187087059021
Validation loss: 1.9846177186897334
Epoch: 5| Step: 6
Training loss: 2.274406909942627
Validation loss: 1.9714575053976595
Epoch: 5| Step: 7
Training loss: 2.2315611839294434
Validation loss: 1.9854163840520296
Epoch: 5| Step: 8
Training loss: 2.2102322578430176
Validation loss: 1.9929004384459352
Epoch: 5| Step: 9
Training loss: 1.8830238580703735
Validation loss: 1.9629760268780825
Epoch: 28| Step: 0
Training loss: 3.018771171569824
Validation loss: 2.0068249813944314
Epoch: 5| Step: 1
Training loss: 2.1970739364624023
Validation loss: 1.9951019741648393
Epoch: 5| Step: 2
Training loss: 2.060894012451172
Validation loss: 1.9880056818612188
Epoch: 5| Step: 3
Training loss: 2.1878550052642822
Validation loss: 1.9859211736445805
Epoch: 5| Step: 4
Training loss: 2.680972099304199
Validation loss: 2.0012238025665283
Epoch: 5| Step: 5
Training loss: 1.9593379497528076
Validation loss: 1.979693937644684
Epoch: 5| Step: 6
Training loss: 1.7766870260238647
Validation loss: 2.008665206621019
Epoch: 5| Step: 7
Training loss: 2.5631096363067627
Validation loss: 2.002570807504997
Epoch: 5| Step: 8
Training loss: 2.3037376403808594
Validation loss: 1.985083809859461
Epoch: 5| Step: 9
Training loss: 1.9435851573944092
Validation loss: 1.9728283607702461
Epoch: 29| Step: 0
Training loss: 2.1750993728637695
Validation loss: 1.9970769419086922
Epoch: 5| Step: 1
Training loss: 2.0904970169067383
Validation loss: 1.9971730589009018
Epoch: 5| Step: 2
Training loss: 2.234137535095215
Validation loss: 1.9643244314536774
Epoch: 5| Step: 3
Training loss: 2.6613683700561523
Validation loss: 1.9869345074934925
Epoch: 5| Step: 4
Training loss: 1.9726057052612305
Validation loss: 1.9858441112710417
Epoch: 5| Step: 5
Training loss: 2.459462881088257
Validation loss: 1.9861358652869574
Epoch: 5| Step: 6
Training loss: 2.0217504501342773
Validation loss: 1.9733036902311036
Epoch: 5| Step: 7
Training loss: 2.5290322303771973
Validation loss: 1.9599775118793514
Epoch: 5| Step: 8
Training loss: 2.171556234359741
Validation loss: 1.9550248907624388
Epoch: 5| Step: 9
Training loss: 2.353262186050415
Validation loss: 1.9736185399748438
Epoch: 30| Step: 0
Training loss: 2.332179069519043
Validation loss: 1.9534224649127439
Epoch: 5| Step: 1
Training loss: 2.139505386352539
Validation loss: 1.9740262288841413
Epoch: 5| Step: 2
Training loss: 1.7899702787399292
Validation loss: 1.9769446489622267
Epoch: 5| Step: 3
Training loss: 2.1459527015686035
Validation loss: 1.961868665201201
Epoch: 5| Step: 4
Training loss: 2.2494215965270996
Validation loss: 1.9766276260074094
Epoch: 5| Step: 5
Training loss: 2.6454367637634277
Validation loss: 1.9708814054941959
Epoch: 5| Step: 6
Training loss: 1.8636479377746582
Validation loss: 1.9643370316182966
Epoch: 5| Step: 7
Training loss: 2.34489107131958
Validation loss: 1.9674234767611936
Epoch: 5| Step: 8
Training loss: 2.8105921745300293
Validation loss: 1.9610577761698111
Epoch: 5| Step: 9
Training loss: 2.1369380950927734
Validation loss: 1.9536377251577035
Epoch: 31| Step: 0
Training loss: 2.4168691635131836
Validation loss: 1.924986877887369
Epoch: 5| Step: 1
Training loss: 1.9115341901779175
Validation loss: 1.9463770329523429
Epoch: 5| Step: 2
Training loss: 2.406123638153076
Validation loss: 1.9674740086356513
Epoch: 5| Step: 3
Training loss: 2.4583539962768555
Validation loss: 1.9616792785177986
Epoch: 5| Step: 4
Training loss: 2.333599805831909
Validation loss: 1.9637437106894076
Epoch: 5| Step: 5
Training loss: 1.9256969690322876
Validation loss: 1.9643642396378003
Epoch: 5| Step: 6
Training loss: 2.5839648246765137
Validation loss: 1.9753321126210603
Epoch: 5| Step: 7
Training loss: 2.467604637145996
Validation loss: 1.960088877369174
Epoch: 5| Step: 8
Training loss: 2.008239984512329
Validation loss: 1.9552133452120444
Epoch: 5| Step: 9
Training loss: 2.013214588165283
Validation loss: 1.9458821634594485
Epoch: 32| Step: 0
Training loss: 1.67844557762146
Validation loss: 1.9565792632617538
Epoch: 5| Step: 1
Training loss: 2.6407573223114014
Validation loss: 1.961645726677325
Epoch: 5| Step: 2
Training loss: 2.436781644821167
Validation loss: 1.9377289384389096
Epoch: 5| Step: 3
Training loss: 2.2899277210235596
Validation loss: 1.9651959611357546
Epoch: 5| Step: 4
Training loss: 1.8700697422027588
Validation loss: 1.9615856683511528
Epoch: 5| Step: 5
Training loss: 2.1546826362609863
Validation loss: 1.938317554460155
Epoch: 5| Step: 6
Training loss: 2.3351902961730957
Validation loss: 1.9632072654559458
Epoch: 5| Step: 7
Training loss: 2.3478000164031982
Validation loss: 1.9671149459674204
Epoch: 5| Step: 8
Training loss: 2.002091407775879
Validation loss: 1.9649772300994655
Epoch: 5| Step: 9
Training loss: 2.6097683906555176
Validation loss: 1.9636380976910213
Epoch: 33| Step: 0
Training loss: 1.9718700647354126
Validation loss: 1.9667440215460688
Epoch: 5| Step: 1
Training loss: 2.126206398010254
Validation loss: 1.947998156650461
Epoch: 5| Step: 2
Training loss: 1.9100730419158936
Validation loss: 1.9608186714940792
Epoch: 5| Step: 3
Training loss: 2.2484099864959717
Validation loss: 1.9513801190492919
Epoch: 5| Step: 4
Training loss: 1.6566462516784668
Validation loss: 1.98471119935564
Epoch: 5| Step: 5
Training loss: 2.879420518875122
Validation loss: 1.956595248455624
Epoch: 5| Step: 6
Training loss: 2.2538375854492188
Validation loss: 1.9369144010886872
Epoch: 5| Step: 7
Training loss: 2.597486972808838
Validation loss: 1.9628732170132424
Epoch: 5| Step: 8
Training loss: 2.198927879333496
Validation loss: 1.9444717691956663
Epoch: 5| Step: 9
Training loss: 2.528867244720459
Validation loss: 1.9584189370381746
Epoch: 34| Step: 0
Training loss: 1.9020872116088867
Validation loss: 1.9535877258657552
Epoch: 5| Step: 1
Training loss: 2.5194549560546875
Validation loss: 1.9407872416132645
Epoch: 5| Step: 2
Training loss: 2.1510021686553955
Validation loss: 1.961808872737473
Epoch: 5| Step: 3
Training loss: 1.8140881061553955
Validation loss: 1.981625924007498
Epoch: 5| Step: 4
Training loss: 2.165008068084717
Validation loss: 1.9507832672956178
Epoch: 5| Step: 5
Training loss: 2.5334572792053223
Validation loss: 1.982498572027083
Epoch: 5| Step: 6
Training loss: 2.5121045112609863
Validation loss: 1.9526096076416455
Epoch: 5| Step: 7
Training loss: 1.595362663269043
Validation loss: 1.9600871466904235
Epoch: 5| Step: 8
Training loss: 2.3423478603363037
Validation loss: 1.9710634612351012
Epoch: 5| Step: 9
Training loss: 2.7904624938964844
Validation loss: 1.9732107815982627
Epoch: 35| Step: 0
Training loss: 2.3838999271392822
Validation loss: 1.9704095554008758
Epoch: 5| Step: 1
Training loss: 1.919691562652588
Validation loss: 1.9605280941338847
Epoch: 5| Step: 2
Training loss: 2.883211851119995
Validation loss: 1.9935590277472846
Epoch: 5| Step: 3
Training loss: 2.2132930755615234
Validation loss: 1.963002284653753
Epoch: 5| Step: 4
Training loss: 2.2362406253814697
Validation loss: 1.99941390366863
Epoch: 5| Step: 5
Training loss: 2.5310420989990234
Validation loss: 1.9737964285363396
Epoch: 5| Step: 6
Training loss: 2.2178988456726074
Validation loss: 1.9741882248748122
Epoch: 5| Step: 7
Training loss: 1.8141405582427979
Validation loss: 1.9660323712465575
Epoch: 5| Step: 8
Training loss: 2.3154208660125732
Validation loss: 1.9543104643444362
Epoch: 5| Step: 9
Training loss: 1.646941900253296
Validation loss: 1.9743226929534254
Epoch: 36| Step: 0
Training loss: 2.819648027420044
Validation loss: 1.9613769654747393
Epoch: 5| Step: 1
Training loss: 2.168351650238037
Validation loss: 1.9541187011938301
Epoch: 5| Step: 2
Training loss: 1.8478763103485107
Validation loss: 1.946443423092794
Epoch: 5| Step: 3
Training loss: 2.0651044845581055
Validation loss: 1.9601584261269878
Epoch: 5| Step: 4
Training loss: 2.2228810787200928
Validation loss: 1.9609091187552583
Epoch: 5| Step: 5
Training loss: 2.2259466648101807
Validation loss: 1.9616806970225822
Epoch: 5| Step: 6
Training loss: 2.3032491207122803
Validation loss: 1.9524780880633017
Epoch: 5| Step: 7
Training loss: 1.972084879875183
Validation loss: 1.967634624714474
Epoch: 5| Step: 8
Training loss: 2.2391347885131836
Validation loss: 1.9484511742488944
Epoch: 5| Step: 9
Training loss: 2.3497657775878906
Validation loss: 1.944991084311506
Epoch: 37| Step: 0
Training loss: 2.059439182281494
Validation loss: 1.953699401814303
Epoch: 5| Step: 1
Training loss: 2.738436460494995
Validation loss: 1.9385486052190657
Epoch: 5| Step: 2
Training loss: 2.1734824180603027
Validation loss: 1.9571612198575794
Epoch: 5| Step: 3
Training loss: 2.161935806274414
Validation loss: 1.9427681475234546
Epoch: 5| Step: 4
Training loss: 1.7990041971206665
Validation loss: 1.9230003031037695
Epoch: 5| Step: 5
Training loss: 2.304978132247925
Validation loss: 1.9616222776097358
Epoch: 5| Step: 6
Training loss: 2.531353712081909
Validation loss: 1.958918839049854
Epoch: 5| Step: 7
Training loss: 1.763514518737793
Validation loss: 1.9441717923116342
Epoch: 5| Step: 8
Training loss: 2.1149508953094482
Validation loss: 1.9409619715573976
Epoch: 5| Step: 9
Training loss: 2.459829330444336
Validation loss: 1.9589959057114965
Epoch: 38| Step: 0
Training loss: 2.1694350242614746
Validation loss: 1.9558350842633694
Epoch: 5| Step: 1
Training loss: 1.546454668045044
Validation loss: 1.954688026750688
Epoch: 5| Step: 2
Training loss: 2.44130802154541
Validation loss: 1.9510045411775438
Epoch: 5| Step: 3
Training loss: 2.5371479988098145
Validation loss: 1.9284599453425235
Epoch: 5| Step: 4
Training loss: 2.337307929992676
Validation loss: 1.9465415923715494
Epoch: 5| Step: 5
Training loss: 1.8917183876037598
Validation loss: 1.9389425884905478
Epoch: 5| Step: 6
Training loss: 2.4488606452941895
Validation loss: 1.9413495526896964
Epoch: 5| Step: 7
Training loss: 2.712980270385742
Validation loss: 1.9345452819796776
Epoch: 5| Step: 8
Training loss: 2.04787015914917
Validation loss: 1.9398288975516669
Epoch: 5| Step: 9
Training loss: 2.000638723373413
Validation loss: 1.9297110099586652
Epoch: 39| Step: 0
Training loss: 2.2051842212677
Validation loss: 1.9367836585147775
Epoch: 5| Step: 1
Training loss: 2.552907943725586
Validation loss: 1.9370587335216056
Epoch: 5| Step: 2
Training loss: 1.7303571701049805
Validation loss: 1.9475420584781564
Epoch: 5| Step: 3
Training loss: 2.5258355140686035
Validation loss: 1.9367068122616775
Epoch: 5| Step: 4
Training loss: 2.1849350929260254
Validation loss: 1.9217987780948338
Epoch: 5| Step: 5
Training loss: 1.9705963134765625
Validation loss: 1.930543441566632
Epoch: 5| Step: 6
Training loss: 2.406097888946533
Validation loss: 1.9430753207035203
Epoch: 5| Step: 7
Training loss: 2.228527545928955
Validation loss: 1.9368493471214239
Epoch: 5| Step: 8
Training loss: 2.210732936859131
Validation loss: 1.9157350629353695
Epoch: 5| Step: 9
Training loss: 1.9016534090042114
Validation loss: 1.918694990144359
Epoch: 40| Step: 0
Training loss: 2.2255191802978516
Validation loss: 1.9132464034951848
Epoch: 5| Step: 1
Training loss: 1.736708402633667
Validation loss: 1.949361529281671
Epoch: 5| Step: 2
Training loss: 1.8750009536743164
Validation loss: 1.9529743923557747
Epoch: 5| Step: 3
Training loss: 2.3769969940185547
Validation loss: 1.944601734765142
Epoch: 5| Step: 4
Training loss: 1.9462401866912842
Validation loss: 1.952250340859667
Epoch: 5| Step: 5
Training loss: 2.9494361877441406
Validation loss: 1.9386120940283906
Epoch: 5| Step: 6
Training loss: 1.7954716682434082
Validation loss: 1.9646727618553657
Epoch: 5| Step: 7
Training loss: 2.5936341285705566
Validation loss: 1.9410828780784881
Epoch: 5| Step: 8
Training loss: 2.4475250244140625
Validation loss: 1.9344217768675989
Epoch: 5| Step: 9
Training loss: 2.0058794021606445
Validation loss: 1.9486572802495614
Epoch: 41| Step: 0
Training loss: 2.0429439544677734
Validation loss: 1.9476651948132961
Epoch: 5| Step: 1
Training loss: 2.207035779953003
Validation loss: 1.950868217207545
Epoch: 5| Step: 2
Training loss: 2.4745020866394043
Validation loss: 1.9349855819194437
Epoch: 5| Step: 3
Training loss: 2.0996150970458984
Validation loss: 1.9612539517793723
Epoch: 5| Step: 4
Training loss: 2.4316811561584473
Validation loss: 1.9308420239592627
Epoch: 5| Step: 5
Training loss: 1.5124402046203613
Validation loss: 1.9079158700627388
Epoch: 5| Step: 6
Training loss: 2.455442428588867
Validation loss: 1.946906024603535
Epoch: 5| Step: 7
Training loss: 2.262350559234619
Validation loss: 1.957284486551079
Epoch: 5| Step: 8
Training loss: 1.899106502532959
Validation loss: 1.9488328789635527
Epoch: 5| Step: 9
Training loss: 2.4726099967956543
Validation loss: 1.9408869992057196
Epoch: 42| Step: 0
Training loss: 1.9908714294433594
Validation loss: 1.9564407180539138
Epoch: 5| Step: 1
Training loss: 2.437765598297119
Validation loss: 1.9479825728231197
Epoch: 5| Step: 2
Training loss: 2.0772018432617188
Validation loss: 1.9403297575257665
Epoch: 5| Step: 3
Training loss: 2.209751605987549
Validation loss: 1.9338742726140743
Epoch: 5| Step: 4
Training loss: 2.0416252613067627
Validation loss: 1.9411764127745046
Epoch: 5| Step: 5
Training loss: 2.430184841156006
Validation loss: 1.930379085403552
Epoch: 5| Step: 6
Training loss: 2.187833786010742
Validation loss: 1.9210735327905888
Epoch: 5| Step: 7
Training loss: 2.4790847301483154
Validation loss: 1.9206634931427111
Epoch: 5| Step: 8
Training loss: 1.6845884323120117
Validation loss: 1.9227005277606224
Epoch: 5| Step: 9
Training loss: 2.32246994972229
Validation loss: 1.9281850127007465
Epoch: 43| Step: 0
Training loss: 1.6754997968673706
Validation loss: 1.9215542978520015
Epoch: 5| Step: 1
Training loss: 2.548274040222168
Validation loss: 1.9191780639209335
Epoch: 5| Step: 2
Training loss: 2.1947879791259766
Validation loss: 1.9201241217071203
Epoch: 5| Step: 3
Training loss: 1.8818055391311646
Validation loss: 1.9181401755312364
Epoch: 5| Step: 4
Training loss: 1.6863187551498413
Validation loss: 1.9152209913130287
Epoch: 5| Step: 5
Training loss: 2.168982982635498
Validation loss: 1.9140448201474527
Epoch: 5| Step: 6
Training loss: 2.203782320022583
Validation loss: 1.926656491464848
Epoch: 5| Step: 7
Training loss: 2.2973556518554688
Validation loss: 1.9042252739556402
Epoch: 5| Step: 8
Training loss: 2.771625518798828
Validation loss: 1.928745264629666
Epoch: 5| Step: 9
Training loss: 2.3336079120635986
Validation loss: 1.9062457393399246
Epoch: 44| Step: 0
Training loss: 1.8588581085205078
Validation loss: 1.9250151905224477
Epoch: 5| Step: 1
Training loss: 2.1576919555664062
Validation loss: 1.9373377544416799
Epoch: 5| Step: 2
Training loss: 2.377025604248047
Validation loss: 1.921523373761623
Epoch: 5| Step: 3
Training loss: 2.0549707412719727
Validation loss: 1.9071299849654273
Epoch: 5| Step: 4
Training loss: 2.355246067047119
Validation loss: 1.9276177076984653
Epoch: 5| Step: 5
Training loss: 2.073829412460327
Validation loss: 1.9077660805887455
Epoch: 5| Step: 6
Training loss: 2.1209073066711426
Validation loss: 1.9072589771353083
Epoch: 5| Step: 7
Training loss: 2.5673904418945312
Validation loss: 1.9463219694096408
Epoch: 5| Step: 8
Training loss: 1.9721156358718872
Validation loss: 1.9121293078223578
Epoch: 5| Step: 9
Training loss: 2.1523208618164062
Validation loss: 1.9212744639074202
Epoch: 45| Step: 0
Training loss: 2.5592105388641357
Validation loss: 1.908497237473083
Epoch: 5| Step: 1
Training loss: 2.378690004348755
Validation loss: 1.9250588202648025
Epoch: 5| Step: 2
Training loss: 2.1572585105895996
Validation loss: 1.9027976337954295
Epoch: 5| Step: 3
Training loss: 2.2338833808898926
Validation loss: 1.9154453860770027
Epoch: 5| Step: 4
Training loss: 2.2682199478149414
Validation loss: 1.91916062763269
Epoch: 5| Step: 5
Training loss: 2.06976580619812
Validation loss: 1.9202340035129795
Epoch: 5| Step: 6
Training loss: 2.0704872608184814
Validation loss: 1.9262481490485102
Epoch: 5| Step: 7
Training loss: 1.9053133726119995
Validation loss: 1.9427095574440716
Epoch: 5| Step: 8
Training loss: 2.0293128490448
Validation loss: 1.943589821136255
Epoch: 5| Step: 9
Training loss: 1.9293551445007324
Validation loss: 1.95165132018302
Epoch: 46| Step: 0
Training loss: 2.4532437324523926
Validation loss: 1.9390011511260656
Epoch: 5| Step: 1
Training loss: 1.7708048820495605
Validation loss: 1.9421879696331437
Epoch: 5| Step: 2
Training loss: 1.9517267942428589
Validation loss: 1.9070501516191223
Epoch: 5| Step: 3
Training loss: 1.9314477443695068
Validation loss: 1.8835930832855994
Epoch: 5| Step: 4
Training loss: 2.632960319519043
Validation loss: 1.9136182258455017
Epoch: 5| Step: 5
Training loss: 2.1418161392211914
Validation loss: 1.9326667348257929
Epoch: 5| Step: 6
Training loss: 2.929257392883301
Validation loss: 1.935514685918959
Epoch: 5| Step: 7
Training loss: 1.9668238162994385
Validation loss: 1.9288466079629583
Epoch: 5| Step: 8
Training loss: 1.9135167598724365
Validation loss: 1.9374614825351633
Epoch: 5| Step: 9
Training loss: 1.916260004043579
Validation loss: 1.9335620008784233
Epoch: 47| Step: 0
Training loss: 2.0069708824157715
Validation loss: 1.9160071902995488
Epoch: 5| Step: 1
Training loss: 2.617421865463257
Validation loss: 1.9308030382334758
Epoch: 5| Step: 2
Training loss: 2.515986442565918
Validation loss: 1.9294479647986322
Epoch: 5| Step: 3
Training loss: 1.9915651082992554
Validation loss: 1.9376345847150405
Epoch: 5| Step: 4
Training loss: 2.286184310913086
Validation loss: 1.9203001543772307
Epoch: 5| Step: 5
Training loss: 2.049767017364502
Validation loss: 1.916926023771437
Epoch: 5| Step: 6
Training loss: 1.9028056859970093
Validation loss: 1.9232009837953308
Epoch: 5| Step: 7
Training loss: 1.9650278091430664
Validation loss: 1.923584118163843
Epoch: 5| Step: 8
Training loss: 2.03033709526062
Validation loss: 1.9460537896739494
Epoch: 5| Step: 9
Training loss: 2.18847918510437
Validation loss: 1.9280891521371526
Epoch: 48| Step: 0
Training loss: 2.1045591831207275
Validation loss: 1.9449777671759076
Epoch: 5| Step: 1
Training loss: 2.183183431625366
Validation loss: 1.9358697555048003
Epoch: 5| Step: 2
Training loss: 2.2757320404052734
Validation loss: 1.9439511359166757
Epoch: 5| Step: 3
Training loss: 2.4981136322021484
Validation loss: 1.9464164980881506
Epoch: 5| Step: 4
Training loss: 1.6415616273880005
Validation loss: 1.9626397863566447
Epoch: 5| Step: 5
Training loss: 2.720010757446289
Validation loss: 1.93586517409455
Epoch: 5| Step: 6
Training loss: 2.0036282539367676
Validation loss: 1.9509855448770865
Epoch: 5| Step: 7
Training loss: 1.9034653902053833
Validation loss: 1.9519504874730282
Epoch: 5| Step: 8
Training loss: 2.252808094024658
Validation loss: 1.945738665491557
Epoch: 5| Step: 9
Training loss: 1.9729758501052856
Validation loss: 1.9748810426794368
Epoch: 49| Step: 0
Training loss: 2.317042827606201
Validation loss: 1.9687701352208637
Epoch: 5| Step: 1
Training loss: 2.31289005279541
Validation loss: 1.9376838841884256
Epoch: 5| Step: 2
Training loss: 2.077511787414551
Validation loss: 1.9370942390222343
Epoch: 5| Step: 3
Training loss: 1.906437635421753
Validation loss: 1.9521093317073026
Epoch: 5| Step: 4
Training loss: 1.8530012369155884
Validation loss: 1.952184047630365
Epoch: 5| Step: 5
Training loss: 1.849415898323059
Validation loss: 1.9393320109346788
Epoch: 5| Step: 6
Training loss: 2.5006511211395264
Validation loss: 1.9466446003467917
Epoch: 5| Step: 7
Training loss: 2.620544672012329
Validation loss: 1.9220958322072201
Epoch: 5| Step: 8
Training loss: 2.031114101409912
Validation loss: 1.9452279060006998
Epoch: 5| Step: 9
Training loss: 2.0643060207366943
Validation loss: 1.9411476464580288
Epoch: 50| Step: 0
Training loss: 1.7545626163482666
Validation loss: 1.9587124603257762
Epoch: 5| Step: 1
Training loss: 2.172208786010742
Validation loss: 1.9461622409683337
Epoch: 5| Step: 2
Training loss: 2.240133285522461
Validation loss: 1.9458000265437065
Epoch: 5| Step: 3
Training loss: 1.9547405242919922
Validation loss: 1.9435685349882936
Epoch: 5| Step: 4
Training loss: 2.1286191940307617
Validation loss: 1.952916008105381
Epoch: 5| Step: 5
Training loss: 2.373518943786621
Validation loss: 1.9413276113194526
Epoch: 5| Step: 6
Training loss: 2.4272680282592773
Validation loss: 1.9640137497469676
Epoch: 5| Step: 7
Training loss: 2.4906482696533203
Validation loss: 1.934678527091047
Epoch: 5| Step: 8
Training loss: 2.0940394401550293
Validation loss: 1.917403926094659
Epoch: 5| Step: 9
Training loss: 1.8604850769042969
Validation loss: 1.9333075362143757
Epoch: 51| Step: 0
Training loss: 1.8564188480377197
Validation loss: 1.9420196795635085
Epoch: 5| Step: 1
Training loss: 2.1288163661956787
Validation loss: 1.9235441744756356
Epoch: 5| Step: 2
Training loss: 1.7042303085327148
Validation loss: 1.934265056102396
Epoch: 5| Step: 3
Training loss: 2.3409645557403564
Validation loss: 1.947357845820969
Epoch: 5| Step: 4
Training loss: 2.0967559814453125
Validation loss: 1.9112515946943982
Epoch: 5| Step: 5
Training loss: 2.0702872276306152
Validation loss: 1.9401691808975001
Epoch: 5| Step: 6
Training loss: 2.145846366882324
Validation loss: 1.9375291702558668
Epoch: 5| Step: 7
Training loss: 2.3443281650543213
Validation loss: 1.9438977653174092
Epoch: 5| Step: 8
Training loss: 2.3948237895965576
Validation loss: 1.9370121544213603
Epoch: 5| Step: 9
Training loss: 2.4762825965881348
Validation loss: 1.9482854407468289
Epoch: 52| Step: 0
Training loss: 2.0767059326171875
Validation loss: 1.947639628279981
Epoch: 5| Step: 1
Training loss: 2.5205636024475098
Validation loss: 1.9136211108818328
Epoch: 5| Step: 2
Training loss: 2.089618682861328
Validation loss: 1.9188244840224011
Epoch: 5| Step: 3
Training loss: 1.8174021244049072
Validation loss: 1.9591192847533192
Epoch: 5| Step: 4
Training loss: 2.277662515640259
Validation loss: 1.9276823148452977
Epoch: 5| Step: 5
Training loss: 1.9930694103240967
Validation loss: 1.9704973114480218
Epoch: 5| Step: 6
Training loss: 2.0018301010131836
Validation loss: 1.9317706240166863
Epoch: 5| Step: 7
Training loss: 1.822082757949829
Validation loss: 1.9583593109528796
Epoch: 5| Step: 8
Training loss: 2.2654480934143066
Validation loss: 1.9314899701866315
Epoch: 5| Step: 9
Training loss: 2.4494173526763916
Validation loss: 1.9629076573488524
Epoch: 53| Step: 0
Training loss: 1.798792839050293
Validation loss: 1.9449817208077411
Epoch: 5| Step: 1
Training loss: 1.8430618047714233
Validation loss: 1.9392369239450358
Epoch: 5| Step: 2
Training loss: 2.6008172035217285
Validation loss: 1.9477465684465367
Epoch: 5| Step: 3
Training loss: 2.2357354164123535
Validation loss: 1.9398655771351547
Epoch: 5| Step: 4
Training loss: 2.1556427478790283
Validation loss: 1.964861703433579
Epoch: 5| Step: 5
Training loss: 2.188551902770996
Validation loss: 1.9571816458118905
Epoch: 5| Step: 6
Training loss: 1.8720052242279053
Validation loss: 1.954855636727038
Epoch: 5| Step: 7
Training loss: 2.2400286197662354
Validation loss: 1.9533135282049934
Epoch: 5| Step: 8
Training loss: 2.174351215362549
Validation loss: 1.9393971189320516
Epoch: 5| Step: 9
Training loss: 2.014441967010498
Validation loss: 1.9520935188952109
Epoch: 54| Step: 0
Training loss: 2.2549633979797363
Validation loss: 1.93426478852471
Epoch: 5| Step: 1
Training loss: 1.821869134902954
Validation loss: 1.940107692059853
Epoch: 5| Step: 2
Training loss: 2.5607101917266846
Validation loss: 1.9122633942597205
Epoch: 5| Step: 3
Training loss: 1.8359692096710205
Validation loss: 1.9136513943294826
Epoch: 5| Step: 4
Training loss: 2.238483428955078
Validation loss: 1.9148467135943954
Epoch: 5| Step: 5
Training loss: 2.1826953887939453
Validation loss: 1.901804973753236
Epoch: 5| Step: 6
Training loss: 2.0049781799316406
Validation loss: 1.8980187031862548
Epoch: 5| Step: 7
Training loss: 2.2453365325927734
Validation loss: 1.912297171654461
Epoch: 5| Step: 8
Training loss: 2.0571532249450684
Validation loss: 1.9349617443496374
Epoch: 5| Step: 9
Training loss: 2.161522388458252
Validation loss: 1.9110577449524144
Epoch: 55| Step: 0
Training loss: 2.599717140197754
Validation loss: 1.8944589628590096
Epoch: 5| Step: 1
Training loss: 1.71142578125
Validation loss: 1.9212359987574517
Epoch: 5| Step: 2
Training loss: 2.242258071899414
Validation loss: 1.9233807591225605
Epoch: 5| Step: 3
Training loss: 1.9796452522277832
Validation loss: 1.9202605580254424
Epoch: 5| Step: 4
Training loss: 2.2026257514953613
Validation loss: 1.921460994713598
Epoch: 5| Step: 5
Training loss: 1.8703538179397583
Validation loss: 1.9372141721437304
Epoch: 5| Step: 6
Training loss: 1.7375249862670898
Validation loss: 1.9135512233638077
Epoch: 5| Step: 7
Training loss: 2.2971534729003906
Validation loss: 1.92897947486356
Epoch: 5| Step: 8
Training loss: 2.6026058197021484
Validation loss: 1.903631721469138
Epoch: 5| Step: 9
Training loss: 1.94215726852417
Validation loss: 1.9048161746786654
Epoch: 56| Step: 0
Training loss: 2.368253231048584
Validation loss: 1.9465102454741223
Epoch: 5| Step: 1
Training loss: 2.3040859699249268
Validation loss: 1.9433700815379191
Epoch: 5| Step: 2
Training loss: 2.069091320037842
Validation loss: 1.9201509437972692
Epoch: 5| Step: 3
Training loss: 2.1159138679504395
Validation loss: 1.9454466970704443
Epoch: 5| Step: 4
Training loss: 2.2672181129455566
Validation loss: 1.9037675540224255
Epoch: 5| Step: 5
Training loss: 1.935051679611206
Validation loss: 1.9540930583322649
Epoch: 5| Step: 6
Training loss: 1.8615527153015137
Validation loss: 1.9529313277855194
Epoch: 5| Step: 7
Training loss: 2.2243242263793945
Validation loss: 1.9344922690082798
Epoch: 5| Step: 8
Training loss: 1.621297836303711
Validation loss: 1.9574137711696487
Epoch: 5| Step: 9
Training loss: 2.375959873199463
Validation loss: 1.975813448857918
Epoch: 57| Step: 0
Training loss: 2.0286865234375
Validation loss: 1.946912027091431
Epoch: 5| Step: 1
Training loss: 1.9236019849777222
Validation loss: 1.94189886223498
Epoch: 5| Step: 2
Training loss: 2.18534517288208
Validation loss: 1.9210987965837658
Epoch: 5| Step: 3
Training loss: 1.7149527072906494
Validation loss: 1.9544132939345544
Epoch: 5| Step: 4
Training loss: 2.0489094257354736
Validation loss: 1.9603476421438533
Epoch: 5| Step: 5
Training loss: 2.6656675338745117
Validation loss: 1.9474319202436818
Epoch: 5| Step: 6
Training loss: 2.0652916431427
Validation loss: 1.9416984208196186
Epoch: 5| Step: 7
Training loss: 2.273099184036255
Validation loss: 1.9446318321090807
Epoch: 5| Step: 8
Training loss: 2.362098217010498
Validation loss: 1.9236468805683602
Epoch: 5| Step: 9
Training loss: 1.9714627265930176
Validation loss: 1.915299475621834
Epoch: 58| Step: 0
Training loss: 1.894777536392212
Validation loss: 1.9349476776534704
Epoch: 5| Step: 1
Training loss: 1.6411255598068237
Validation loss: 1.922527280642832
Epoch: 5| Step: 2
Training loss: 2.289592742919922
Validation loss: 1.8999331331939149
Epoch: 5| Step: 3
Training loss: 2.259294271469116
Validation loss: 1.9334253235686598
Epoch: 5| Step: 4
Training loss: 2.290503740310669
Validation loss: 1.93766858937929
Epoch: 5| Step: 5
Training loss: 2.1884713172912598
Validation loss: 1.9352307405403193
Epoch: 5| Step: 6
Training loss: 2.1527481079101562
Validation loss: 1.9279754856507556
Epoch: 5| Step: 7
Training loss: 2.3639276027679443
Validation loss: 1.9114432394933358
Epoch: 5| Step: 8
Training loss: 2.108150005340576
Validation loss: 1.9183356761932373
Epoch: 5| Step: 9
Training loss: 1.8494884967803955
Validation loss: 1.9238800710911372
Epoch: 59| Step: 0
Training loss: 1.73014497756958
Validation loss: 1.9343746171580802
Epoch: 5| Step: 1
Training loss: 1.9359668493270874
Validation loss: 1.93064647784336
Epoch: 5| Step: 2
Training loss: 2.0100150108337402
Validation loss: 1.937411191652147
Epoch: 5| Step: 3
Training loss: 2.743175745010376
Validation loss: 1.9376385683636013
Epoch: 5| Step: 4
Training loss: 1.9826502799987793
Validation loss: 1.934428353961423
Epoch: 5| Step: 5
Training loss: 2.386295795440674
Validation loss: 1.9336774434974726
Epoch: 5| Step: 6
Training loss: 2.252711772918701
Validation loss: 1.9368781108650373
Epoch: 5| Step: 7
Training loss: 2.3249497413635254
Validation loss: 1.9166303864485925
Epoch: 5| Step: 8
Training loss: 2.125175952911377
Validation loss: 1.9319006264638559
Epoch: 5| Step: 9
Training loss: 1.5905885696411133
Validation loss: 1.9368912118801969
Epoch: 60| Step: 0
Training loss: 2.1839942932128906
Validation loss: 1.9284675635879847
Epoch: 5| Step: 1
Training loss: 1.708503007888794
Validation loss: 1.930140033042688
Epoch: 5| Step: 2
Training loss: 2.5504770278930664
Validation loss: 1.9209576253410723
Epoch: 5| Step: 3
Training loss: 1.8610222339630127
Validation loss: 1.912574020221079
Epoch: 5| Step: 4
Training loss: 1.959801197052002
Validation loss: 1.9538316452245919
Epoch: 5| Step: 5
Training loss: 2.6111621856689453
Validation loss: 1.9121327734679627
Epoch: 5| Step: 6
Training loss: 2.217970132827759
Validation loss: 1.9049282108279442
Epoch: 5| Step: 7
Training loss: 2.1761646270751953
Validation loss: 1.9035013785465158
Epoch: 5| Step: 8
Training loss: 1.768458366394043
Validation loss: 1.899977016792023
Epoch: 5| Step: 9
Training loss: 1.944209098815918
Validation loss: 1.9089794639203188
Epoch: 61| Step: 0
Training loss: 1.792739987373352
Validation loss: 1.929065376734562
Epoch: 5| Step: 1
Training loss: 2.238901138305664
Validation loss: 1.9220873554833502
Epoch: 5| Step: 2
Training loss: 1.8941891193389893
Validation loss: 1.9569234179078245
Epoch: 5| Step: 3
Training loss: 2.3097407817840576
Validation loss: 1.926259780101639
Epoch: 5| Step: 4
Training loss: 2.0272014141082764
Validation loss: 1.908856069441322
Epoch: 5| Step: 5
Training loss: 2.442396640777588
Validation loss: 1.9329156035141979
Epoch: 5| Step: 6
Training loss: 1.9952595233917236
Validation loss: 1.948748652883571
Epoch: 5| Step: 7
Training loss: 2.1026923656463623
Validation loss: 1.9577191622137167
Epoch: 5| Step: 8
Training loss: 2.18911075592041
Validation loss: 1.938841947548681
Epoch: 5| Step: 9
Training loss: 2.041285514831543
Validation loss: 1.949449847928054
Epoch: 62| Step: 0
Training loss: 1.9334323406219482
Validation loss: 1.9219632912025177
Epoch: 5| Step: 1
Training loss: 2.4738354682922363
Validation loss: 1.938409617478899
Epoch: 5| Step: 2
Training loss: 2.014944076538086
Validation loss: 1.9409164439002387
Epoch: 5| Step: 3
Training loss: 1.9212207794189453
Validation loss: 1.9586864718430335
Epoch: 5| Step: 4
Training loss: 1.8315645456314087
Validation loss: 1.952378721545926
Epoch: 5| Step: 5
Training loss: 2.756004810333252
Validation loss: 1.9351629601965705
Epoch: 5| Step: 6
Training loss: 1.9436465501785278
Validation loss: 1.950599428561094
Epoch: 5| Step: 7
Training loss: 2.0698609352111816
Validation loss: 1.916441847094529
Epoch: 5| Step: 8
Training loss: 2.149240255355835
Validation loss: 1.8978300214671402
Epoch: 5| Step: 9
Training loss: 1.962799310684204
Validation loss: 1.9549261100000614
Epoch: 63| Step: 0
Training loss: 1.6353377103805542
Validation loss: 1.9477163407442382
Epoch: 5| Step: 1
Training loss: 1.5205212831497192
Validation loss: 1.9277245912620489
Epoch: 5| Step: 2
Training loss: 2.3122377395629883
Validation loss: 1.944275080728874
Epoch: 5| Step: 3
Training loss: 1.8990199565887451
Validation loss: 1.9301795101851869
Epoch: 5| Step: 4
Training loss: 2.020068883895874
Validation loss: 1.9502827272140721
Epoch: 5| Step: 5
Training loss: 1.8142644166946411
Validation loss: 1.92668474235123
Epoch: 5| Step: 6
Training loss: 2.276601791381836
Validation loss: 1.929519751946703
Epoch: 5| Step: 7
Training loss: 2.712390899658203
Validation loss: 1.941575438856221
Epoch: 5| Step: 8
Training loss: 2.543485641479492
Validation loss: 1.926143133383003
Epoch: 5| Step: 9
Training loss: 2.083430767059326
Validation loss: 1.9008359548856886
Epoch: 64| Step: 0
Training loss: 2.274993419647217
Validation loss: 1.897004133505787
Epoch: 5| Step: 1
Training loss: 2.251051187515259
Validation loss: 1.91732591690777
Epoch: 5| Step: 2
Training loss: 2.25350284576416
Validation loss: 1.9471153063739803
Epoch: 5| Step: 3
Training loss: 2.069492816925049
Validation loss: 1.9483483935431611
Epoch: 5| Step: 4
Training loss: 2.133450984954834
Validation loss: 1.93737767926223
Epoch: 5| Step: 5
Training loss: 1.9638291597366333
Validation loss: 1.9421367911126117
Epoch: 5| Step: 6
Training loss: 1.8454041481018066
Validation loss: 1.9260875261087211
Epoch: 5| Step: 7
Training loss: 1.6177482604980469
Validation loss: 1.9388291852937327
Epoch: 5| Step: 8
Training loss: 2.4284262657165527
Validation loss: 1.9506272566404275
Epoch: 5| Step: 9
Training loss: 2.0839850902557373
Validation loss: 1.9156223303980107
Epoch: 65| Step: 0
Training loss: 2.218848943710327
Validation loss: 1.932308603533738
Epoch: 5| Step: 1
Training loss: 2.26112699508667
Validation loss: 1.9199219487553878
Epoch: 5| Step: 2
Training loss: 1.8031400442123413
Validation loss: 1.95790214075459
Epoch: 5| Step: 3
Training loss: 1.96620774269104
Validation loss: 1.9401455903224807
Epoch: 5| Step: 4
Training loss: 2.407367706298828
Validation loss: 1.9203569383072339
Epoch: 5| Step: 5
Training loss: 1.715920090675354
Validation loss: 1.9218490947064737
Epoch: 5| Step: 6
Training loss: 2.135122299194336
Validation loss: 1.9148070589243937
Epoch: 5| Step: 7
Training loss: 2.3287575244903564
Validation loss: 1.8978990393576862
Epoch: 5| Step: 8
Training loss: 2.041576385498047
Validation loss: 1.9045078334190864
Epoch: 5| Step: 9
Training loss: 2.0042457580566406
Validation loss: 1.9171790519206644
Epoch: 66| Step: 0
Training loss: 2.293088436126709
Validation loss: 1.899635647698272
Epoch: 5| Step: 1
Training loss: 1.5002164840698242
Validation loss: 1.8979125829051724
Epoch: 5| Step: 2
Training loss: 1.9414349794387817
Validation loss: 1.9065063136944669
Epoch: 5| Step: 3
Training loss: 2.0821540355682373
Validation loss: 1.912628724420671
Epoch: 5| Step: 4
Training loss: 2.2861123085021973
Validation loss: 1.8986326258817166
Epoch: 5| Step: 5
Training loss: 2.3846242427825928
Validation loss: 1.8747295981688465
Epoch: 5| Step: 6
Training loss: 1.9852933883666992
Validation loss: 1.9225475530830218
Epoch: 5| Step: 7
Training loss: 1.9188116788864136
Validation loss: 1.9056877858347172
Epoch: 5| Step: 8
Training loss: 2.0978493690490723
Validation loss: 1.9256844709245422
Epoch: 5| Step: 9
Training loss: 2.3467345237731934
Validation loss: 1.9368559079204533
Epoch: 67| Step: 0
Training loss: 2.1280369758605957
Validation loss: 1.9355775966918727
Epoch: 5| Step: 1
Training loss: 1.6785402297973633
Validation loss: 1.8908580507305885
Epoch: 5| Step: 2
Training loss: 2.323976516723633
Validation loss: 1.9063438571614326
Epoch: 5| Step: 3
Training loss: 1.8129932880401611
Validation loss: 1.9052998487897914
Epoch: 5| Step: 4
Training loss: 2.2084951400756836
Validation loss: 1.9260887842384173
Epoch: 5| Step: 5
Training loss: 2.2794687747955322
Validation loss: 1.8968502325977352
Epoch: 5| Step: 6
Training loss: 2.389824867248535
Validation loss: 1.9164084238971737
Epoch: 5| Step: 7
Training loss: 1.5334408283233643
Validation loss: 1.9212841378699104
Epoch: 5| Step: 8
Training loss: 2.4761977195739746
Validation loss: 1.9185775441231487
Epoch: 5| Step: 9
Training loss: 2.059573173522949
Validation loss: 1.9331907256901693
Epoch: 68| Step: 0
Training loss: 2.0378615856170654
Validation loss: 1.9321568972772831
Epoch: 5| Step: 1
Training loss: 1.9069371223449707
Validation loss: 1.9051301856692746
Epoch: 5| Step: 2
Training loss: 1.9191639423370361
Validation loss: 1.9254290320032792
Epoch: 5| Step: 3
Training loss: 2.2694787979125977
Validation loss: 1.9122548146213558
Epoch: 5| Step: 4
Training loss: 2.195956230163574
Validation loss: 1.9524494135122505
Epoch: 5| Step: 5
Training loss: 2.1660356521606445
Validation loss: 1.9346021310888606
Epoch: 5| Step: 6
Training loss: 2.054980993270874
Validation loss: 1.9180688120478349
Epoch: 5| Step: 7
Training loss: 2.242542266845703
Validation loss: 1.9416884775642012
Epoch: 5| Step: 8
Training loss: 2.349834442138672
Validation loss: 1.9352812200999088
Epoch: 5| Step: 9
Training loss: 1.7575384378433228
Validation loss: 1.9404522858077673
Epoch: 69| Step: 0
Training loss: 1.8552303314208984
Validation loss: 1.9141841071972745
Epoch: 5| Step: 1
Training loss: 1.911220908164978
Validation loss: 1.9275522309241535
Epoch: 5| Step: 2
Training loss: 2.422584295272827
Validation loss: 1.9486039919818905
Epoch: 5| Step: 3
Training loss: 1.9112025499343872
Validation loss: 1.9365253328419418
Epoch: 5| Step: 4
Training loss: 2.2748022079467773
Validation loss: 1.9484736164696783
Epoch: 5| Step: 5
Training loss: 2.1715526580810547
Validation loss: 1.9532451372352435
Epoch: 5| Step: 6
Training loss: 2.0742239952087402
Validation loss: 1.9530152005257366
Epoch: 5| Step: 7
Training loss: 1.714876413345337
Validation loss: 1.9359220532204608
Epoch: 5| Step: 8
Training loss: 2.178544521331787
Validation loss: 1.918046405847124
Epoch: 5| Step: 9
Training loss: 2.32218074798584
Validation loss: 1.915733615271479
Epoch: 70| Step: 0
Training loss: 2.176511526107788
Validation loss: 1.9273978771923257
Epoch: 5| Step: 1
Training loss: 2.2117111682891846
Validation loss: 1.9288156598591977
Epoch: 5| Step: 2
Training loss: 2.0167417526245117
Validation loss: 1.8833427274827477
Epoch: 5| Step: 3
Training loss: 1.9007787704467773
Validation loss: 1.9225005777619726
Epoch: 5| Step: 4
Training loss: 2.0688443183898926
Validation loss: 1.918632894968815
Epoch: 5| Step: 5
Training loss: 2.0806589126586914
Validation loss: 1.9240177741153635
Epoch: 5| Step: 6
Training loss: 2.1766815185546875
Validation loss: 1.8831459155185617
Epoch: 5| Step: 7
Training loss: 2.1292805671691895
Validation loss: 1.9006690430126603
Epoch: 5| Step: 8
Training loss: 1.9946821928024292
Validation loss: 1.8980842374211593
Epoch: 5| Step: 9
Training loss: 2.029994487762451
Validation loss: 1.9006108894622584
Epoch: 71| Step: 0
Training loss: 2.770247459411621
Validation loss: 1.8705742950919722
Epoch: 5| Step: 1
Training loss: 2.1609742641448975
Validation loss: 1.873441506632798
Epoch: 5| Step: 2
Training loss: 1.9790370464324951
Validation loss: 1.8763610030249727
Epoch: 5| Step: 3
Training loss: 1.6634953022003174
Validation loss: 1.8710895004889947
Epoch: 5| Step: 4
Training loss: 1.9998942613601685
Validation loss: 1.8944628624607334
Epoch: 5| Step: 5
Training loss: 2.368870258331299
Validation loss: 1.8792958679816705
Epoch: 5| Step: 6
Training loss: 2.120286464691162
Validation loss: 1.8951317269167454
Epoch: 5| Step: 7
Training loss: 1.7040460109710693
Validation loss: 1.8684009527988572
Epoch: 5| Step: 8
Training loss: 2.0668458938598633
Validation loss: 1.8905728292122161
Epoch: 5| Step: 9
Training loss: 2.024528980255127
Validation loss: 1.8914791088310077
Epoch: 72| Step: 0
Training loss: 2.2507433891296387
Validation loss: 1.893793982567547
Epoch: 5| Step: 1
Training loss: 1.946941614151001
Validation loss: 1.8999613583516732
Epoch: 5| Step: 2
Training loss: 2.535431146621704
Validation loss: 1.8771444053101025
Epoch: 5| Step: 3
Training loss: 1.978739619255066
Validation loss: 1.8825625224079159
Epoch: 5| Step: 4
Training loss: 2.3365519046783447
Validation loss: 1.8727829782225245
Epoch: 5| Step: 5
Training loss: 2.109159469604492
Validation loss: 1.9075312099868444
Epoch: 5| Step: 6
Training loss: 1.7517189979553223
Validation loss: 1.8747553928292913
Epoch: 5| Step: 7
Training loss: 1.8524010181427002
Validation loss: 1.9018004883965143
Epoch: 5| Step: 8
Training loss: 2.282951831817627
Validation loss: 1.895084055207616
Epoch: 5| Step: 9
Training loss: 1.7278105020523071
Validation loss: 1.911409911491888
Epoch: 73| Step: 0
Training loss: 1.9821226596832275
Validation loss: 1.9011411924156354
Epoch: 5| Step: 1
Training loss: 2.047595977783203
Validation loss: 1.9126534153231614
Epoch: 5| Step: 2
Training loss: 1.98978590965271
Validation loss: 1.8962156017907232
Epoch: 5| Step: 3
Training loss: 1.7503187656402588
Validation loss: 1.916434976694395
Epoch: 5| Step: 4
Training loss: 2.491765260696411
Validation loss: 1.9124913541533106
Epoch: 5| Step: 5
Training loss: 2.229069709777832
Validation loss: 1.930474868781275
Epoch: 5| Step: 6
Training loss: 2.205510139465332
Validation loss: 1.9052687686124294
Epoch: 5| Step: 7
Training loss: 2.371108055114746
Validation loss: 1.9012475468271928
Epoch: 5| Step: 8
Training loss: 1.5348515510559082
Validation loss: 1.8956170836798578
Epoch: 5| Step: 9
Training loss: 2.118882656097412
Validation loss: 1.9166980527287765
Epoch: 74| Step: 0
Training loss: 1.7434533834457397
Validation loss: 1.891093693191199
Epoch: 5| Step: 1
Training loss: 2.2600138187408447
Validation loss: 1.8897464901423282
Epoch: 5| Step: 2
Training loss: 2.312021255493164
Validation loss: 1.9374881605450198
Epoch: 5| Step: 3
Training loss: 2.06213641166687
Validation loss: 1.9521633189359158
Epoch: 5| Step: 4
Training loss: 2.1456899642944336
Validation loss: 1.9406766273992524
Epoch: 5| Step: 5
Training loss: 1.997362732887268
Validation loss: 1.9048991452018134
Epoch: 5| Step: 6
Training loss: 2.017118453979492
Validation loss: 1.9187945616331032
Epoch: 5| Step: 7
Training loss: 2.1414060592651367
Validation loss: 1.9448386010506171
Epoch: 5| Step: 8
Training loss: 1.9554694890975952
Validation loss: 1.9238342003856632
Epoch: 5| Step: 9
Training loss: 2.054978370666504
Validation loss: 1.9206590326569921
Epoch: 75| Step: 0
Training loss: 1.8625478744506836
Validation loss: 1.9232589924078194
Epoch: 5| Step: 1
Training loss: 2.4397811889648438
Validation loss: 1.9144291243107199
Epoch: 5| Step: 2
Training loss: 2.4523234367370605
Validation loss: 1.921819182608625
Epoch: 5| Step: 3
Training loss: 1.6481995582580566
Validation loss: 1.934523964099747
Epoch: 5| Step: 4
Training loss: 2.4371814727783203
Validation loss: 1.9188595615702568
Epoch: 5| Step: 5
Training loss: 2.3465006351470947
Validation loss: 1.8920278377670179
Epoch: 5| Step: 6
Training loss: 1.6969475746154785
Validation loss: 1.9154247963171211
Epoch: 5| Step: 7
Training loss: 1.7633838653564453
Validation loss: 1.9019673145074638
Epoch: 5| Step: 8
Training loss: 1.8649554252624512
Validation loss: 1.9013537914632894
Epoch: 5| Step: 9
Training loss: 2.141512155532837
Validation loss: 1.8825304611123723
Epoch: 76| Step: 0
Training loss: 2.223928213119507
Validation loss: 1.9153936612520286
Epoch: 5| Step: 1
Training loss: 2.1685574054718018
Validation loss: 1.9147879777194785
Epoch: 5| Step: 2
Training loss: 2.2792506217956543
Validation loss: 1.9008392258513747
Epoch: 5| Step: 3
Training loss: 1.9779064655303955
Validation loss: 1.9178316550289127
Epoch: 5| Step: 4
Training loss: 2.0235354900360107
Validation loss: 1.9222526250125693
Epoch: 5| Step: 5
Training loss: 1.5405948162078857
Validation loss: 1.9160151850405356
Epoch: 5| Step: 6
Training loss: 1.976288080215454
Validation loss: 1.9103635352292507
Epoch: 5| Step: 7
Training loss: 2.6619434356689453
Validation loss: 1.928810914643377
Epoch: 5| Step: 8
Training loss: 2.1537725925445557
Validation loss: 1.9281226773913815
Epoch: 5| Step: 9
Training loss: 1.797163486480713
Validation loss: 1.9226305399009649
Epoch: 77| Step: 0
Training loss: 1.9995352029800415
Validation loss: 1.917503109081186
Epoch: 5| Step: 1
Training loss: 2.667405366897583
Validation loss: 1.9385695431729872
Epoch: 5| Step: 2
Training loss: 1.8922488689422607
Validation loss: 1.9368804144344742
Epoch: 5| Step: 3
Training loss: 1.8909062147140503
Validation loss: 1.9289714380991545
Epoch: 5| Step: 4
Training loss: 2.1320407390594482
Validation loss: 1.9584883357123506
Epoch: 5| Step: 5
Training loss: 1.7152776718139648
Validation loss: 1.9330186706652743
Epoch: 5| Step: 6
Training loss: 2.372938632965088
Validation loss: 1.9363533215557072
Epoch: 5| Step: 7
Training loss: 1.9234431982040405
Validation loss: 1.9493078730946822
Epoch: 5| Step: 8
Training loss: 2.103013038635254
Validation loss: 1.9265487245518527
Epoch: 5| Step: 9
Training loss: 2.084617853164673
Validation loss: 1.9294813176710828
Epoch: 78| Step: 0
Training loss: 2.2394416332244873
Validation loss: 1.9394567999050771
Epoch: 5| Step: 1
Training loss: 1.9471690654754639
Validation loss: 1.9159112019504574
Epoch: 5| Step: 2
Training loss: 2.1130008697509766
Validation loss: 1.925920434992948
Epoch: 5| Step: 3
Training loss: 1.4709556102752686
Validation loss: 1.9077935501825896
Epoch: 5| Step: 4
Training loss: 2.1935105323791504
Validation loss: 1.9140908589466012
Epoch: 5| Step: 5
Training loss: 1.9091743230819702
Validation loss: 1.9237029192258985
Epoch: 5| Step: 6
Training loss: 2.241072177886963
Validation loss: 1.9296958154911616
Epoch: 5| Step: 7
Training loss: 2.2089362144470215
Validation loss: 1.9255757803539577
Epoch: 5| Step: 8
Training loss: 2.021245002746582
Validation loss: 1.9251158005899662
Epoch: 5| Step: 9
Training loss: 2.1540520191192627
Validation loss: 1.9173172695173635
Epoch: 79| Step: 0
Training loss: 1.9161386489868164
Validation loss: 1.8869037748240738
Epoch: 5| Step: 1
Training loss: 1.945582628250122
Validation loss: 1.8796775143781155
Epoch: 5| Step: 2
Training loss: 1.841223120689392
Validation loss: 1.8543084902729061
Epoch: 5| Step: 3
Training loss: 1.6958028078079224
Validation loss: 1.8620166126772655
Epoch: 5| Step: 4
Training loss: 1.906159520149231
Validation loss: 1.8752413653641296
Epoch: 5| Step: 5
Training loss: 2.096885919570923
Validation loss: 1.8761303098939306
Epoch: 5| Step: 6
Training loss: 2.066889524459839
Validation loss: 1.8893433989380761
Epoch: 5| Step: 7
Training loss: 2.4661922454833984
Validation loss: 1.8862444599755377
Epoch: 5| Step: 8
Training loss: 2.3145830631256104
Validation loss: 1.877648147747671
Epoch: 5| Step: 9
Training loss: 2.1970744132995605
Validation loss: 1.903326789252192
Epoch: 80| Step: 0
Training loss: 1.8850421905517578
Validation loss: 1.8989012172753863
Epoch: 5| Step: 1
Training loss: 2.605607032775879
Validation loss: 1.9063774518829455
Epoch: 5| Step: 2
Training loss: 2.6860649585723877
Validation loss: 1.884661729387242
Epoch: 5| Step: 3
Training loss: 2.090524435043335
Validation loss: 1.907237953419308
Epoch: 5| Step: 4
Training loss: 1.7476680278778076
Validation loss: 1.9161521676632998
Epoch: 5| Step: 5
Training loss: 2.114201307296753
Validation loss: 1.9141778285554845
Epoch: 5| Step: 6
Training loss: 1.946168303489685
Validation loss: 1.92205127194631
Epoch: 5| Step: 7
Training loss: 1.8692066669464111
Validation loss: 1.90309208074062
Epoch: 5| Step: 8
Training loss: 1.9636279344558716
Validation loss: 1.902981041146697
Epoch: 5| Step: 9
Training loss: 1.6649255752563477
Validation loss: 1.9054408982503328
Epoch: 81| Step: 0
Training loss: 1.5554922819137573
Validation loss: 1.8893909848851265
Epoch: 5| Step: 1
Training loss: 1.8671542406082153
Validation loss: 1.9004502570886406
Epoch: 5| Step: 2
Training loss: 2.176690101623535
Validation loss: 1.922961420292477
Epoch: 5| Step: 3
Training loss: 2.331878185272217
Validation loss: 1.8875407160614892
Epoch: 5| Step: 4
Training loss: 2.2716896533966064
Validation loss: 1.906320944106836
Epoch: 5| Step: 5
Training loss: 2.117133617401123
Validation loss: 1.9011677580771686
Epoch: 5| Step: 6
Training loss: 2.386594772338867
Validation loss: 1.8952808105688301
Epoch: 5| Step: 7
Training loss: 1.7184544801712036
Validation loss: 1.9116674370045283
Epoch: 5| Step: 8
Training loss: 2.1083197593688965
Validation loss: 1.8822875837627933
Epoch: 5| Step: 9
Training loss: 1.9283924102783203
Validation loss: 1.9049746492783801
Epoch: 82| Step: 0
Training loss: 1.9993113279342651
Validation loss: 1.9018510022609354
Epoch: 5| Step: 1
Training loss: 2.3766674995422363
Validation loss: 1.8938044498292663
Epoch: 5| Step: 2
Training loss: 2.3695733547210693
Validation loss: 1.8797908378161972
Epoch: 5| Step: 3
Training loss: 1.5280051231384277
Validation loss: 1.9211251486977228
Epoch: 5| Step: 4
Training loss: 1.8821048736572266
Validation loss: 1.8947560607100562
Epoch: 5| Step: 5
Training loss: 1.5939480066299438
Validation loss: 1.9023661081739467
Epoch: 5| Step: 6
Training loss: 2.0200278759002686
Validation loss: 1.9199075921833944
Epoch: 5| Step: 7
Training loss: 2.1819941997528076
Validation loss: 1.8877113980355023
Epoch: 5| Step: 8
Training loss: 2.3625307083129883
Validation loss: 1.901898802613183
Epoch: 5| Step: 9
Training loss: 2.2437610626220703
Validation loss: 1.9186594880742134
Epoch: 83| Step: 0
Training loss: 1.9570918083190918
Validation loss: 1.9033515521948285
Epoch: 5| Step: 1
Training loss: 2.193000316619873
Validation loss: 1.9190131331519258
Epoch: 5| Step: 2
Training loss: 1.8640984296798706
Validation loss: 1.945427596140251
Epoch: 5| Step: 3
Training loss: 1.9911398887634277
Validation loss: 1.9059434631745593
Epoch: 5| Step: 4
Training loss: 2.049501895904541
Validation loss: 1.9295760530362027
Epoch: 5| Step: 5
Training loss: 2.3844292163848877
Validation loss: 1.936894659515765
Epoch: 5| Step: 6
Training loss: 1.7636027336120605
Validation loss: 1.9079650374625226
Epoch: 5| Step: 7
Training loss: 1.9179285764694214
Validation loss: 1.9125156076691991
Epoch: 5| Step: 8
Training loss: 2.0402040481567383
Validation loss: 1.917875307069408
Epoch: 5| Step: 9
Training loss: 2.3004565238952637
Validation loss: 1.9133460453088336
Epoch: 84| Step: 0
Training loss: 2.066495418548584
Validation loss: 1.8988777030286172
Epoch: 5| Step: 1
Training loss: 2.144134998321533
Validation loss: 1.8773820323052166
Epoch: 5| Step: 2
Training loss: 2.4532437324523926
Validation loss: 1.8791035533808975
Epoch: 5| Step: 3
Training loss: 1.6109182834625244
Validation loss: 1.865945015022223
Epoch: 5| Step: 4
Training loss: 1.933846116065979
Validation loss: 1.8598095255789997
Epoch: 5| Step: 5
Training loss: 1.7613283395767212
Validation loss: 1.8624444573903256
Epoch: 5| Step: 6
Training loss: 2.3880648612976074
Validation loss: 1.8850654234989084
Epoch: 5| Step: 7
Training loss: 1.7715846300125122
Validation loss: 1.875178814791947
Epoch: 5| Step: 8
Training loss: 2.5594253540039062
Validation loss: 1.8541846215296134
Epoch: 5| Step: 9
Training loss: 1.88760507106781
Validation loss: 1.8533454138597996
Epoch: 85| Step: 0
Training loss: 1.7243661880493164
Validation loss: 1.87062898385439
Epoch: 5| Step: 1
Training loss: 2.1969563961029053
Validation loss: 1.87191059177728
Epoch: 5| Step: 2
Training loss: 1.8154959678649902
Validation loss: 1.8875175225648948
Epoch: 5| Step: 3
Training loss: 2.4025659561157227
Validation loss: 1.8661798041501492
Epoch: 5| Step: 4
Training loss: 1.7580642700195312
Validation loss: 1.9021780447994205
Epoch: 5| Step: 5
Training loss: 2.328789472579956
Validation loss: 1.8709249059073358
Epoch: 5| Step: 6
Training loss: 1.9118191003799438
Validation loss: 1.8703559739984197
Epoch: 5| Step: 7
Training loss: 2.0612902641296387
Validation loss: 1.871852568585238
Epoch: 5| Step: 8
Training loss: 1.9480396509170532
Validation loss: 1.8753946410666267
Epoch: 5| Step: 9
Training loss: 2.334449529647827
Validation loss: 1.8707156978922783
Epoch: 86| Step: 0
Training loss: 1.993998408317566
Validation loss: 1.8819295999815138
Epoch: 5| Step: 1
Training loss: 1.9951075315475464
Validation loss: 1.8812050390586579
Epoch: 5| Step: 2
Training loss: 2.2951865196228027
Validation loss: 1.8821431681406584
Epoch: 5| Step: 3
Training loss: 1.9958322048187256
Validation loss: 1.9222658641046757
Epoch: 5| Step: 4
Training loss: 2.180233955383301
Validation loss: 1.9278626201821745
Epoch: 5| Step: 5
Training loss: 1.7412045001983643
Validation loss: 1.9171109937077804
Epoch: 5| Step: 6
Training loss: 2.459325075149536
Validation loss: 1.9376898532291111
Epoch: 5| Step: 7
Training loss: 2.080112934112549
Validation loss: 1.9609085089868779
Epoch: 5| Step: 8
Training loss: 1.734360694885254
Validation loss: 1.9194752672593371
Epoch: 5| Step: 9
Training loss: 1.9677467346191406
Validation loss: 1.9189000944439456
Epoch: 87| Step: 0
Training loss: 2.2694525718688965
Validation loss: 1.9420117714422211
Epoch: 5| Step: 1
Training loss: 1.724550485610962
Validation loss: 1.9409517075518052
Epoch: 5| Step: 2
Training loss: 2.0698204040527344
Validation loss: 1.9281080832584299
Epoch: 5| Step: 3
Training loss: 1.70021653175354
Validation loss: 1.9069964645577848
Epoch: 5| Step: 4
Training loss: 2.0076894760131836
Validation loss: 1.908014837786448
Epoch: 5| Step: 5
Training loss: 2.126190185546875
Validation loss: 1.883861811898595
Epoch: 5| Step: 6
Training loss: 2.3356385231018066
Validation loss: 1.9080264388228492
Epoch: 5| Step: 7
Training loss: 1.7422183752059937
Validation loss: 1.8956192903381457
Epoch: 5| Step: 8
Training loss: 2.4470744132995605
Validation loss: 1.8902884250064549
Epoch: 5| Step: 9
Training loss: 2.0508108139038086
Validation loss: 1.8856114260584331
Epoch: 88| Step: 0
Training loss: 1.7881919145584106
Validation loss: 1.908662507859923
Epoch: 5| Step: 1
Training loss: 1.4380574226379395
Validation loss: 1.8783379295747058
Epoch: 5| Step: 2
Training loss: 1.8183037042617798
Validation loss: 1.8915519834422378
Epoch: 5| Step: 3
Training loss: 2.4303367137908936
Validation loss: 1.8922573834014453
Epoch: 5| Step: 4
Training loss: 2.2338905334472656
Validation loss: 1.880894251864591
Epoch: 5| Step: 5
Training loss: 2.4207024574279785
Validation loss: 1.8922976401212404
Epoch: 5| Step: 6
Training loss: 2.3207051753997803
Validation loss: 1.888561855117194
Epoch: 5| Step: 7
Training loss: 1.7525559663772583
Validation loss: 1.8845246164061182
Epoch: 5| Step: 8
Training loss: 1.9784518480300903
Validation loss: 1.870015644341064
Epoch: 5| Step: 9
Training loss: 2.2090115547180176
Validation loss: 1.8661373870835887
Epoch: 89| Step: 0
Training loss: 1.8910038471221924
Validation loss: 1.8765254672482716
Epoch: 5| Step: 1
Training loss: 1.971530556678772
Validation loss: 1.889973010948236
Epoch: 5| Step: 2
Training loss: 1.9084358215332031
Validation loss: 1.883432396881872
Epoch: 5| Step: 3
Training loss: 1.908416509628296
Validation loss: 1.8957124716943974
Epoch: 5| Step: 4
Training loss: 1.6969608068466187
Validation loss: 1.855701803303451
Epoch: 5| Step: 5
Training loss: 2.190547466278076
Validation loss: 1.894610229156
Epoch: 5| Step: 6
Training loss: 2.5093677043914795
Validation loss: 1.8986272177250265
Epoch: 5| Step: 7
Training loss: 2.4200754165649414
Validation loss: 1.9250985221039476
Epoch: 5| Step: 8
Training loss: 2.1644105911254883
Validation loss: 1.9045610882395463
Epoch: 5| Step: 9
Training loss: 1.7477672100067139
Validation loss: 1.896821383949664
Epoch: 90| Step: 0
Training loss: 1.599402666091919
Validation loss: 1.890184407611545
Epoch: 5| Step: 1
Training loss: 2.4506704807281494
Validation loss: 1.8945793779633886
Epoch: 5| Step: 2
Training loss: 2.012843608856201
Validation loss: 1.874469700477106
Epoch: 5| Step: 3
Training loss: 1.5861144065856934
Validation loss: 1.8865042521799211
Epoch: 5| Step: 4
Training loss: 1.8797550201416016
Validation loss: 1.8861596086900012
Epoch: 5| Step: 5
Training loss: 2.329312324523926
Validation loss: 1.8979104422836852
Epoch: 5| Step: 6
Training loss: 2.0189104080200195
Validation loss: 1.8939703488521438
Epoch: 5| Step: 7
Training loss: 2.500324249267578
Validation loss: 1.89097579177335
Epoch: 5| Step: 8
Training loss: 1.9802573919296265
Validation loss: 1.9136581446627061
Epoch: 5| Step: 9
Training loss: 2.0745508670806885
Validation loss: 1.88362696959818
Epoch: 91| Step: 0
Training loss: 2.0045652389526367
Validation loss: 1.8888882149895319
Epoch: 5| Step: 1
Training loss: 2.4966824054718018
Validation loss: 1.8935021942467998
Epoch: 5| Step: 2
Training loss: 2.0214900970458984
Validation loss: 1.8981720440679317
Epoch: 5| Step: 3
Training loss: 2.032984733581543
Validation loss: 1.9138403230433843
Epoch: 5| Step: 4
Training loss: 1.7375967502593994
Validation loss: 1.8874720540835703
Epoch: 5| Step: 5
Training loss: 2.0825881958007812
Validation loss: 1.8955437125061914
Epoch: 5| Step: 6
Training loss: 2.0090293884277344
Validation loss: 1.9160498252017892
Epoch: 5| Step: 7
Training loss: 2.0081543922424316
Validation loss: 1.8964174342670028
Epoch: 5| Step: 8
Training loss: 1.9063434600830078
Validation loss: 1.8974834586218965
Epoch: 5| Step: 9
Training loss: 2.024444103240967
Validation loss: 1.8960932493209839
Epoch: 92| Step: 0
Training loss: 1.5681610107421875
Validation loss: 1.923592982532309
Epoch: 5| Step: 1
Training loss: 2.338238000869751
Validation loss: 1.92261219882279
Epoch: 5| Step: 2
Training loss: 1.9773298501968384
Validation loss: 1.8803880111776667
Epoch: 5| Step: 3
Training loss: 2.423962354660034
Validation loss: 1.9001002517535532
Epoch: 5| Step: 4
Training loss: 1.8147464990615845
Validation loss: 1.897984876907129
Epoch: 5| Step: 5
Training loss: 2.479375123977661
Validation loss: 1.8575466082250471
Epoch: 5| Step: 6
Training loss: 1.9384303092956543
Validation loss: 1.8869092001331795
Epoch: 5| Step: 7
Training loss: 2.5645017623901367
Validation loss: 1.8439630904643656
Epoch: 5| Step: 8
Training loss: 1.9112491607666016
Validation loss: 1.8959505558013916
Epoch: 5| Step: 9
Training loss: 1.4654700756072998
Validation loss: 1.8517559629550082
Epoch: 93| Step: 0
Training loss: 2.527803897857666
Validation loss: 1.8710222518701347
Epoch: 5| Step: 1
Training loss: 1.9000359773635864
Validation loss: 1.8611987271754862
Epoch: 5| Step: 2
Training loss: 1.9665789604187012
Validation loss: 1.8670540696425404
Epoch: 5| Step: 3
Training loss: 2.0515522956848145
Validation loss: 1.8865807116460458
Epoch: 5| Step: 4
Training loss: 2.525216817855835
Validation loss: 1.8939873760552715
Epoch: 5| Step: 5
Training loss: 1.6052732467651367
Validation loss: 1.9128494863029863
Epoch: 5| Step: 6
Training loss: 2.194251537322998
Validation loss: 1.9206565764310548
Epoch: 5| Step: 7
Training loss: 1.8065464496612549
Validation loss: 1.9409241204639134
Epoch: 5| Step: 8
Training loss: 2.0551400184631348
Validation loss: 1.9316660611749552
Epoch: 5| Step: 9
Training loss: 1.795161485671997
Validation loss: 1.9471241827491377
Epoch: 94| Step: 0
Training loss: 2.163569927215576
Validation loss: 1.9460510658703263
Epoch: 5| Step: 1
Training loss: 2.2088239192962646
Validation loss: 1.9501573559191587
Epoch: 5| Step: 2
Training loss: 2.3452110290527344
Validation loss: 1.9327968504789064
Epoch: 5| Step: 3
Training loss: 1.5836143493652344
Validation loss: 1.9408081546961833
Epoch: 5| Step: 4
Training loss: 2.2439939975738525
Validation loss: 1.9246668232430657
Epoch: 5| Step: 5
Training loss: 1.979095458984375
Validation loss: 1.92659200867303
Epoch: 5| Step: 6
Training loss: 2.106503486633301
Validation loss: 1.9076483086716356
Epoch: 5| Step: 7
Training loss: 1.7781727313995361
Validation loss: 1.8999004792824066
Epoch: 5| Step: 8
Training loss: 2.3963770866394043
Validation loss: 1.876699022251925
Epoch: 5| Step: 9
Training loss: 1.4475774765014648
Validation loss: 1.9083824723744565
Epoch: 95| Step: 0
Training loss: 1.8042495250701904
Validation loss: 1.8594748545036042
Epoch: 5| Step: 1
Training loss: 2.289320230484009
Validation loss: 1.9057431581209032
Epoch: 5| Step: 2
Training loss: 2.0489611625671387
Validation loss: 1.8743158132909872
Epoch: 5| Step: 3
Training loss: 1.744335651397705
Validation loss: 1.8998206673766211
Epoch: 5| Step: 4
Training loss: 1.774851679801941
Validation loss: 1.9153536240831555
Epoch: 5| Step: 5
Training loss: 1.8850228786468506
Validation loss: 1.8894925674946188
Epoch: 5| Step: 6
Training loss: 1.7799794673919678
Validation loss: 1.8569544905381237
Epoch: 5| Step: 7
Training loss: 1.8959063291549683
Validation loss: 1.9183862037795911
Epoch: 5| Step: 8
Training loss: 2.5122859477996826
Validation loss: 1.9044689437468274
Epoch: 5| Step: 9
Training loss: 2.5550312995910645
Validation loss: 1.9201180163047296
Epoch: 96| Step: 0
Training loss: 2.2754416465759277
Validation loss: 1.879848469075539
Epoch: 5| Step: 1
Training loss: 1.9741971492767334
Validation loss: 1.870774859147106
Epoch: 5| Step: 2
Training loss: 1.8896409273147583
Validation loss: 1.9243986821003098
Epoch: 5| Step: 3
Training loss: 2.2609734535217285
Validation loss: 1.9013551139145446
Epoch: 5| Step: 4
Training loss: 2.2276954650878906
Validation loss: 1.882639716855056
Epoch: 5| Step: 5
Training loss: 2.2343032360076904
Validation loss: 1.8992558366103138
Epoch: 5| Step: 6
Training loss: 1.979467749595642
Validation loss: 1.8938506601525724
Epoch: 5| Step: 7
Training loss: 1.766392707824707
Validation loss: 1.8904056240328782
Epoch: 5| Step: 8
Training loss: 1.5508127212524414
Validation loss: 1.8788095584018625
Epoch: 5| Step: 9
Training loss: 2.0342109203338623
Validation loss: 1.8952878087544613
Epoch: 97| Step: 0
Training loss: 1.8402247428894043
Validation loss: 1.8791228232623862
Epoch: 5| Step: 1
Training loss: 1.8770416975021362
Validation loss: 1.9031115461596482
Epoch: 5| Step: 2
Training loss: 2.18095326423645
Validation loss: 1.8708810994950988
Epoch: 5| Step: 3
Training loss: 2.1345577239990234
Validation loss: 1.8749617929938887
Epoch: 5| Step: 4
Training loss: 2.047468662261963
Validation loss: 1.8628937194673278
Epoch: 5| Step: 5
Training loss: 1.734533429145813
Validation loss: 1.8307667893471478
Epoch: 5| Step: 6
Training loss: 2.0852503776550293
Validation loss: 1.889690608429394
Epoch: 5| Step: 7
Training loss: 2.1268718242645264
Validation loss: 1.8807472582343672
Epoch: 5| Step: 8
Training loss: 2.187256097793579
Validation loss: 1.870519114055222
Epoch: 5| Step: 9
Training loss: 2.0555343627929688
Validation loss: 1.8505906509838517
Epoch: 98| Step: 0
Training loss: 2.036457061767578
Validation loss: 1.8415353332492088
Epoch: 5| Step: 1
Training loss: 1.7253296375274658
Validation loss: 1.8431998602777935
Epoch: 5| Step: 2
Training loss: 1.576148271560669
Validation loss: 1.8691520116312041
Epoch: 5| Step: 3
Training loss: 2.251863956451416
Validation loss: 1.873958856081791
Epoch: 5| Step: 4
Training loss: 2.4033520221710205
Validation loss: 1.8718598566466955
Epoch: 5| Step: 5
Training loss: 2.065666913986206
Validation loss: 1.8666169128829626
Epoch: 5| Step: 6
Training loss: 2.2559666633605957
Validation loss: 1.8898362067105958
Epoch: 5| Step: 7
Training loss: 2.386375665664673
Validation loss: 1.8911536417419104
Epoch: 5| Step: 8
Training loss: 2.205686092376709
Validation loss: 1.8746473094542249
Epoch: 5| Step: 9
Training loss: 1.3903071880340576
Validation loss: 1.8814069744494322
Epoch: 99| Step: 0
Training loss: 1.9224647283554077
Validation loss: 1.880659364967895
Epoch: 5| Step: 1
Training loss: 1.7884457111358643
Validation loss: 1.8866196004606837
Epoch: 5| Step: 2
Training loss: 2.4699456691741943
Validation loss: 1.8907428422420145
Epoch: 5| Step: 3
Training loss: 2.167301654815674
Validation loss: 1.8737462390241006
Epoch: 5| Step: 4
Training loss: 1.9506560564041138
Validation loss: 1.8904665691389455
Epoch: 5| Step: 5
Training loss: 1.7918343544006348
Validation loss: 1.8875706667522731
Epoch: 5| Step: 6
Training loss: 2.119464159011841
Validation loss: 1.877094653870562
Epoch: 5| Step: 7
Training loss: 2.137476682662964
Validation loss: 1.868551796288799
Epoch: 5| Step: 8
Training loss: 2.099519729614258
Validation loss: 1.8580075236533184
Epoch: 5| Step: 9
Training loss: 1.7911956310272217
Validation loss: 1.8861419614270436
Epoch: 100| Step: 0
Training loss: 2.0810976028442383
Validation loss: 1.8756079939629535
Epoch: 5| Step: 1
Training loss: 2.0611987113952637
Validation loss: 1.8647485679859737
Epoch: 5| Step: 2
Training loss: 2.335366725921631
Validation loss: 1.8625135481786386
Epoch: 5| Step: 3
Training loss: 2.11188006401062
Validation loss: 1.8731890762452599
Epoch: 5| Step: 4
Training loss: 2.0285871028900146
Validation loss: 1.8752470445289886
Epoch: 5| Step: 5
Training loss: 1.6668260097503662
Validation loss: 1.9207767977131356
Epoch: 5| Step: 6
Training loss: 2.131722927093506
Validation loss: 1.9008546647408027
Epoch: 5| Step: 7
Training loss: 1.847352385520935
Validation loss: 1.902253537726917
Epoch: 5| Step: 8
Training loss: 1.3651096820831299
Validation loss: 1.9050518308612083
Epoch: 5| Step: 9
Training loss: 2.6640982627868652
Validation loss: 1.9065983346897921
