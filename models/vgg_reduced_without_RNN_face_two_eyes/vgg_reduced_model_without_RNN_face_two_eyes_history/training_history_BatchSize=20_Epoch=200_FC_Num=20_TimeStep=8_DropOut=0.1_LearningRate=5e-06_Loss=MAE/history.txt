Epoch: 1| Step: 0
Training loss: 8.880517959594727
Validation loss: 8.145480732123056

Epoch: 5| Step: 1
Training loss: 8.08984088897705
Validation loss: 8.115293165047964

Epoch: 5| Step: 2
Training loss: 9.230384826660156
Validation loss: 8.087201714515686

Epoch: 5| Step: 3
Training loss: 7.38080358505249
Validation loss: 8.060774286588034

Epoch: 5| Step: 4
Training loss: 7.243902683258057
Validation loss: 8.034846444924673

Epoch: 5| Step: 5
Training loss: 9.12160587310791
Validation loss: 8.00858082373937

Epoch: 5| Step: 6
Training loss: 8.467934608459473
Validation loss: 7.986948211987813

Epoch: 5| Step: 7
Training loss: 7.339888095855713
Validation loss: 7.962220748265584

Epoch: 5| Step: 8
Training loss: 7.588992118835449
Validation loss: 7.93753304084142

Epoch: 5| Step: 9
Training loss: 7.607758522033691
Validation loss: 7.911938369274139

Epoch: 5| Step: 10
Training loss: 7.8104448318481445
Validation loss: 7.887121200561523

Epoch: 5| Step: 11
Training loss: 8.779014587402344
Validation loss: 7.863185286521912

Epoch: 2| Step: 0
Training loss: 9.577421188354492
Validation loss: 7.83577420314153

Epoch: 5| Step: 1
Training loss: 6.9925127029418945
Validation loss: 7.806896070639293

Epoch: 5| Step: 2
Training loss: 7.643558502197266
Validation loss: 7.783047258853912

Epoch: 5| Step: 3
Training loss: 7.251133918762207
Validation loss: 7.751494248708089

Epoch: 5| Step: 4
Training loss: 7.628970146179199
Validation loss: 7.724153300126393

Epoch: 5| Step: 5
Training loss: 9.188592910766602
Validation loss: 7.693406085173289

Epoch: 5| Step: 6
Training loss: 7.846235752105713
Validation loss: 7.65968386332194

Epoch: 5| Step: 7
Training loss: 8.343973159790039
Validation loss: 7.631555438041687

Epoch: 5| Step: 8
Training loss: 6.971305847167969
Validation loss: 7.596879084904988

Epoch: 5| Step: 9
Training loss: 7.156715393066406
Validation loss: 7.5636066198349

Epoch: 5| Step: 10
Training loss: 7.2247419357299805
Validation loss: 7.527334908644359

Epoch: 5| Step: 11
Training loss: 5.233767509460449
Validation loss: 7.490009605884552

Epoch: 3| Step: 0
Training loss: 8.046903610229492
Validation loss: 7.454487542311351

Epoch: 5| Step: 1
Training loss: 8.551152229309082
Validation loss: 7.418488641579946

Epoch: 5| Step: 2
Training loss: 7.340083122253418
Validation loss: 7.380516151587169

Epoch: 5| Step: 3
Training loss: 7.554600715637207
Validation loss: 7.333788096904755

Epoch: 5| Step: 4
Training loss: 6.780575752258301
Validation loss: 7.290864487489064

Epoch: 5| Step: 5
Training loss: 7.045083522796631
Validation loss: 7.247788190841675

Epoch: 5| Step: 6
Training loss: 6.465705871582031
Validation loss: 7.200676838556926

Epoch: 5| Step: 7
Training loss: 6.549489498138428
Validation loss: 7.151340703169505

Epoch: 5| Step: 8
Training loss: 7.606528282165527
Validation loss: 7.105463286240895

Epoch: 5| Step: 9
Training loss: 7.553990364074707
Validation loss: 7.05442198117574

Epoch: 5| Step: 10
Training loss: 6.771573066711426
Validation loss: 6.997155010700226

Epoch: 5| Step: 11
Training loss: 7.421111583709717
Validation loss: 6.9379517038663225

Epoch: 4| Step: 0
Training loss: 7.173283576965332
Validation loss: 6.879812955856323

Epoch: 5| Step: 1
Training loss: 6.437670707702637
Validation loss: 6.812735438346863

Epoch: 5| Step: 2
Training loss: 7.328339576721191
Validation loss: 6.7479555408159895

Epoch: 5| Step: 3
Training loss: 7.881567478179932
Validation loss: 6.680203437805176

Epoch: 5| Step: 4
Training loss: 7.024336338043213
Validation loss: 6.610893885294597

Epoch: 5| Step: 5
Training loss: 5.594717979431152
Validation loss: 6.531227191289266

Epoch: 5| Step: 6
Training loss: 6.414180755615234
Validation loss: 6.449402987957001

Epoch: 5| Step: 7
Training loss: 5.8867974281311035
Validation loss: 6.369929214318593

Epoch: 5| Step: 8
Training loss: 6.263246536254883
Validation loss: 6.279541969299316

Epoch: 5| Step: 9
Training loss: 6.174521446228027
Validation loss: 6.18562509616216

Epoch: 5| Step: 10
Training loss: 5.994318962097168
Validation loss: 6.090252955754598

Epoch: 5| Step: 11
Training loss: 6.3314385414123535
Validation loss: 5.97860989967982

Epoch: 5| Step: 0
Training loss: 5.7260637283325195
Validation loss: 5.887133220831553

Epoch: 5| Step: 1
Training loss: 6.225205898284912
Validation loss: 5.765626847743988

Epoch: 5| Step: 2
Training loss: 5.425816535949707
Validation loss: 5.649478296438853

Epoch: 5| Step: 3
Training loss: 4.580756187438965
Validation loss: 5.519702752431233

Epoch: 5| Step: 4
Training loss: 5.45236349105835
Validation loss: 5.396709710359573

Epoch: 5| Step: 5
Training loss: 5.153378486633301
Validation loss: 5.251467605431874

Epoch: 5| Step: 6
Training loss: 3.810427188873291
Validation loss: 5.123205324014028

Epoch: 5| Step: 7
Training loss: 5.428675651550293
Validation loss: 4.967452526092529

Epoch: 5| Step: 8
Training loss: 5.035379886627197
Validation loss: 4.798685749371846

Epoch: 5| Step: 9
Training loss: 5.419065952301025
Validation loss: 4.635405162970225

Epoch: 5| Step: 10
Training loss: 5.265576362609863
Validation loss: 4.459097385406494

Epoch: 5| Step: 11
Training loss: 4.629446029663086
Validation loss: 4.295670072237651

Epoch: 6| Step: 0
Training loss: 4.087296962738037
Validation loss: 4.114547689755757

Epoch: 5| Step: 1
Training loss: 3.7837653160095215
Validation loss: 3.9898897111415863

Epoch: 5| Step: 2
Training loss: 3.8651652336120605
Validation loss: 3.8256747921307883

Epoch: 5| Step: 3
Training loss: 3.5837509632110596
Validation loss: 3.711685766776403

Epoch: 5| Step: 4
Training loss: 3.689197540283203
Validation loss: 3.5357057452201843

Epoch: 5| Step: 5
Training loss: 3.994673252105713
Validation loss: 3.4033812085787454

Epoch: 5| Step: 6
Training loss: 3.4898681640625
Validation loss: 3.2608352601528168

Epoch: 5| Step: 7
Training loss: 2.3990001678466797
Validation loss: 3.150027026732763

Epoch: 5| Step: 8
Training loss: 2.5235965251922607
Validation loss: 2.990724345048269

Epoch: 5| Step: 9
Training loss: 2.992318630218506
Validation loss: 2.853156258662542

Epoch: 5| Step: 10
Training loss: 1.9981796741485596
Validation loss: 2.8040978809197745

Epoch: 5| Step: 11
Training loss: 2.778744697570801
Validation loss: 2.7425949474175773

Epoch: 7| Step: 0
Training loss: 3.0517070293426514
Validation loss: 2.688813050587972

Epoch: 5| Step: 1
Training loss: 2.98291277885437
Validation loss: 2.7038504083951316

Epoch: 5| Step: 2
Training loss: 2.8700146675109863
Validation loss: 2.683975030978521

Epoch: 5| Step: 3
Training loss: 2.922600269317627
Validation loss: 2.646100252866745

Epoch: 5| Step: 4
Training loss: 2.6771113872528076
Validation loss: 2.6434185206890106

Epoch: 5| Step: 5
Training loss: 2.446136951446533
Validation loss: 2.6447886725266776

Epoch: 5| Step: 6
Training loss: 3.5454018115997314
Validation loss: 2.6522967716058097

Epoch: 5| Step: 7
Training loss: 2.3893516063690186
Validation loss: 2.64990825454394

Epoch: 5| Step: 8
Training loss: 1.9766285419464111
Validation loss: 2.684405654668808

Epoch: 5| Step: 9
Training loss: 2.1949551105499268
Validation loss: 2.640130857626597

Epoch: 5| Step: 10
Training loss: 3.117657423019409
Validation loss: 2.640610088904699

Epoch: 5| Step: 11
Training loss: 3.1297171115875244
Validation loss: 2.640415986378988

Epoch: 8| Step: 0
Training loss: 2.324049472808838
Validation loss: 2.627906401952108

Epoch: 5| Step: 1
Training loss: 2.925632953643799
Validation loss: 2.6071719328562417

Epoch: 5| Step: 2
Training loss: 2.67578125
Validation loss: 2.623566354314486

Epoch: 5| Step: 3
Training loss: 2.1614902019500732
Validation loss: 2.5863594760497413

Epoch: 5| Step: 4
Training loss: 2.920219898223877
Validation loss: 2.578655183315277

Epoch: 5| Step: 5
Training loss: 2.617341995239258
Validation loss: 2.641116142272949

Epoch: 5| Step: 6
Training loss: 2.411163330078125
Validation loss: 2.5805052618185678

Epoch: 5| Step: 7
Training loss: 2.5999529361724854
Validation loss: 2.669614613056183

Epoch: 5| Step: 8
Training loss: 2.2313597202301025
Validation loss: 2.6599990129470825

Epoch: 5| Step: 9
Training loss: 3.725710391998291
Validation loss: 2.6965801417827606

Epoch: 5| Step: 10
Training loss: 2.811738967895508
Validation loss: 2.7662043372790017

Epoch: 5| Step: 11
Training loss: 2.290571689605713
Validation loss: 2.7481211920579276

Epoch: 9| Step: 0
Training loss: 2.569767951965332
Validation loss: 2.7381506860256195

Epoch: 5| Step: 1
Training loss: 2.5766260623931885
Validation loss: 2.7305159171422324

Epoch: 5| Step: 2
Training loss: 2.091628074645996
Validation loss: 2.6990494430065155

Epoch: 5| Step: 3
Training loss: 2.628962993621826
Validation loss: 2.6814633210500083

Epoch: 5| Step: 4
Training loss: 2.6853842735290527
Validation loss: 2.7083619435628257

Epoch: 5| Step: 5
Training loss: 3.1195743083953857
Validation loss: 2.6441150903701782

Epoch: 5| Step: 6
Training loss: 2.7649471759796143
Validation loss: 2.6124997586011887

Epoch: 5| Step: 7
Training loss: 2.3324365615844727
Validation loss: 2.6457545161247253

Epoch: 5| Step: 8
Training loss: 2.5467238426208496
Validation loss: 2.6179397801558175

Epoch: 5| Step: 9
Training loss: 2.30220365524292
Validation loss: 2.5951313575108848

Epoch: 5| Step: 10
Training loss: 2.465756893157959
Validation loss: 2.587512324253718

Epoch: 5| Step: 11
Training loss: 2.9629154205322266
Validation loss: 2.5668848752975464

Epoch: 10| Step: 0
Training loss: 2.909661054611206
Validation loss: 2.582895745833715

Epoch: 5| Step: 1
Training loss: 2.2922146320343018
Validation loss: 2.585263321797053

Epoch: 5| Step: 2
Training loss: 3.0328361988067627
Validation loss: 2.5589014490445456

Epoch: 5| Step: 3
Training loss: 3.321662425994873
Validation loss: 2.5668441553910575

Epoch: 5| Step: 4
Training loss: 1.7011533975601196
Validation loss: 2.593979150056839

Epoch: 5| Step: 5
Training loss: 2.094447374343872
Validation loss: 2.571823169787725

Epoch: 5| Step: 6
Training loss: 2.9439868927001953
Validation loss: 2.5708327988783517

Epoch: 5| Step: 7
Training loss: 2.0318846702575684
Validation loss: 2.6031036376953125

Epoch: 5| Step: 8
Training loss: 2.7179152965545654
Validation loss: 2.581216126680374

Epoch: 5| Step: 9
Training loss: 2.731849193572998
Validation loss: 2.5712806781133017

Epoch: 5| Step: 10
Training loss: 1.8016650676727295
Validation loss: 2.6001230478286743

Epoch: 5| Step: 11
Training loss: 2.6624755859375
Validation loss: 2.5538804729779563

Epoch: 11| Step: 0
Training loss: 2.5792202949523926
Validation loss: 2.569298505783081

Epoch: 5| Step: 1
Training loss: 2.4229445457458496
Validation loss: 2.5030927062034607

Epoch: 5| Step: 2
Training loss: 2.6392364501953125
Validation loss: 2.488807459672292

Epoch: 5| Step: 3
Training loss: 1.8120338916778564
Validation loss: 2.553420106569926

Epoch: 5| Step: 4
Training loss: 2.4224510192871094
Validation loss: 2.4908440311749778

Epoch: 5| Step: 5
Training loss: 2.2854721546173096
Validation loss: 2.4805427889029183

Epoch: 5| Step: 6
Training loss: 2.242185115814209
Validation loss: 2.4890396197636924

Epoch: 5| Step: 7
Training loss: 2.8004136085510254
Validation loss: 2.4656975666681924

Epoch: 5| Step: 8
Training loss: 2.263347625732422
Validation loss: 2.439068208138148

Epoch: 5| Step: 9
Training loss: 2.970139980316162
Validation loss: 2.4869175851345062

Epoch: 5| Step: 10
Training loss: 2.6366138458251953
Validation loss: 2.4861187239487967

Epoch: 5| Step: 11
Training loss: 3.125443458557129
Validation loss: 2.458396007617315

Epoch: 12| Step: 0
Training loss: 2.602673292160034
Validation loss: 2.4814751346906028

Epoch: 5| Step: 1
Training loss: 1.8844192028045654
Validation loss: 2.5110722482204437

Epoch: 5| Step: 2
Training loss: 2.128366470336914
Validation loss: 2.5029558340708413

Epoch: 5| Step: 3
Training loss: 2.3018999099731445
Validation loss: 2.4918861091136932

Epoch: 5| Step: 4
Training loss: 2.348048686981201
Validation loss: 2.4798546731472015

Epoch: 5| Step: 5
Training loss: 2.8783178329467773
Validation loss: 2.503764440615972

Epoch: 5| Step: 6
Training loss: 2.578101396560669
Validation loss: 2.484379857778549

Epoch: 5| Step: 7
Training loss: 2.106045961380005
Validation loss: 2.4844623108704886

Epoch: 5| Step: 8
Training loss: 2.5646204948425293
Validation loss: 2.4911965131759644

Epoch: 5| Step: 9
Training loss: 2.718219757080078
Validation loss: 2.5025972624619803

Epoch: 5| Step: 10
Training loss: 2.3892874717712402
Validation loss: 2.470498204231262

Epoch: 5| Step: 11
Training loss: 2.4941086769104004
Validation loss: 2.4751238326231637

Epoch: 13| Step: 0
Training loss: 2.538269281387329
Validation loss: 2.428230235973994

Epoch: 5| Step: 1
Training loss: 1.616173505783081
Validation loss: 2.344744215408961

Epoch: 5| Step: 2
Training loss: 2.5520050525665283
Validation loss: 2.3503255347410836

Epoch: 5| Step: 3
Training loss: 2.1521363258361816
Validation loss: 2.4173627495765686

Epoch: 5| Step: 4
Training loss: 2.3603854179382324
Validation loss: 2.3236844738324485

Epoch: 5| Step: 5
Training loss: 2.4127800464630127
Validation loss: 2.401002844174703

Epoch: 5| Step: 6
Training loss: 2.303866147994995
Validation loss: 2.395235682527224

Epoch: 5| Step: 7
Training loss: 2.31972336769104
Validation loss: 2.3242613623539605

Epoch: 5| Step: 8
Training loss: 2.7720632553100586
Validation loss: 2.401650538047155

Epoch: 5| Step: 9
Training loss: 2.5268688201904297
Validation loss: 2.3826568822065988

Epoch: 5| Step: 10
Training loss: 2.501784086227417
Validation loss: 2.397119383017222

Epoch: 5| Step: 11
Training loss: 3.0649189949035645
Validation loss: 2.4790691634019217

Epoch: 14| Step: 0
Training loss: 2.422684907913208
Validation loss: 2.416699379682541

Epoch: 5| Step: 1
Training loss: 2.271752119064331
Validation loss: 2.4126471281051636

Epoch: 5| Step: 2
Training loss: 2.301358938217163
Validation loss: 2.36988831559817

Epoch: 5| Step: 3
Training loss: 1.9452396631240845
Validation loss: 2.383884976307551

Epoch: 5| Step: 4
Training loss: 2.2259416580200195
Validation loss: 2.308218906323115

Epoch: 5| Step: 5
Training loss: 1.7845321893692017
Validation loss: 2.280804455280304

Epoch: 5| Step: 6
Training loss: 2.324059009552002
Validation loss: 2.3260546227296195

Epoch: 5| Step: 7
Training loss: 1.5015980005264282
Validation loss: 2.3197437028090158

Epoch: 5| Step: 8
Training loss: 2.696938991546631
Validation loss: 2.270146210988363

Epoch: 5| Step: 9
Training loss: 2.6039226055145264
Validation loss: 2.311986873547236

Epoch: 5| Step: 10
Training loss: 2.6020619869232178
Validation loss: 2.334234595298767

Epoch: 5| Step: 11
Training loss: 3.9224228858947754
Validation loss: 2.33381849527359

Epoch: 15| Step: 0
Training loss: 2.6720688343048096
Validation loss: 2.31199703613917

Epoch: 5| Step: 1
Training loss: 2.5152058601379395
Validation loss: 2.347623606522878

Epoch: 5| Step: 2
Training loss: 3.0579311847686768
Validation loss: 2.296347518761953

Epoch: 5| Step: 3
Training loss: 2.2638020515441895
Validation loss: 2.2917640109856925

Epoch: 5| Step: 4
Training loss: 1.540012240409851
Validation loss: 2.2734802961349487

Epoch: 5| Step: 5
Training loss: 1.7704994678497314
Validation loss: 2.269538844625155

Epoch: 5| Step: 6
Training loss: 2.4118614196777344
Validation loss: 2.296562602122625

Epoch: 5| Step: 7
Training loss: 2.151946544647217
Validation loss: 2.27712948123614

Epoch: 5| Step: 8
Training loss: 1.9190337657928467
Validation loss: 2.264262576897939

Epoch: 5| Step: 9
Training loss: 2.1219725608825684
Validation loss: 2.2429124961296716

Epoch: 5| Step: 10
Training loss: 2.4979426860809326
Validation loss: 2.2039605726798377

Epoch: 5| Step: 11
Training loss: 1.7604047060012817
Validation loss: 2.2326184809207916

Epoch: 16| Step: 0
Training loss: 2.144212245941162
Validation loss: 2.310625344514847

Epoch: 5| Step: 1
Training loss: 2.135986804962158
Validation loss: 2.251759395003319

Epoch: 5| Step: 2
Training loss: 2.170747756958008
Validation loss: 2.2822117110093436

Epoch: 5| Step: 3
Training loss: 2.722719669342041
Validation loss: 2.3339903255303702

Epoch: 5| Step: 4
Training loss: 2.615227222442627
Validation loss: 2.286532551050186

Epoch: 5| Step: 5
Training loss: 2.0550084114074707
Validation loss: 2.2960959325234094

Epoch: 5| Step: 6
Training loss: 1.9453403949737549
Validation loss: 2.2609054148197174

Epoch: 5| Step: 7
Training loss: 2.0467801094055176
Validation loss: 2.2721351186434426

Epoch: 5| Step: 8
Training loss: 1.7927284240722656
Validation loss: 2.284019857645035

Epoch: 5| Step: 9
Training loss: 2.559380054473877
Validation loss: 2.305802504221598

Epoch: 5| Step: 10
Training loss: 2.2458643913269043
Validation loss: 2.3123503228028617

Epoch: 5| Step: 11
Training loss: 1.9494391679763794
Validation loss: 2.2387505869070687

Epoch: 17| Step: 0
Training loss: 1.968544363975525
Validation loss: 2.2018332481384277

Epoch: 5| Step: 1
Training loss: 2.6266720294952393
Validation loss: 2.263011703888575

Epoch: 5| Step: 2
Training loss: 2.1959354877471924
Validation loss: 2.237637927134832

Epoch: 5| Step: 3
Training loss: 2.406184196472168
Validation loss: 2.260468006134033

Epoch: 5| Step: 4
Training loss: 2.4326844215393066
Validation loss: 2.2739891558885574

Epoch: 5| Step: 5
Training loss: 2.6853199005126953
Validation loss: 2.226459632317225

Epoch: 5| Step: 6
Training loss: 2.129345655441284
Validation loss: 2.2150579442580542

Epoch: 5| Step: 7
Training loss: 1.5585206747055054
Validation loss: 2.1384911785523095

Epoch: 5| Step: 8
Training loss: 2.4181275367736816
Validation loss: 2.1883711318174996

Epoch: 5| Step: 9
Training loss: 2.059555768966675
Validation loss: 2.1979080537954965

Epoch: 5| Step: 10
Training loss: 1.764517068862915
Validation loss: 2.205813412865003

Epoch: 5| Step: 11
Training loss: 0.9100680351257324
Validation loss: 2.1786645303169885

Epoch: 18| Step: 0
Training loss: 1.8488922119140625
Validation loss: 2.153757154941559

Epoch: 5| Step: 1
Training loss: 2.585892915725708
Validation loss: 2.19934344291687

Epoch: 5| Step: 2
Training loss: 1.65994131565094
Validation loss: 2.1566989521185556

Epoch: 5| Step: 3
Training loss: 2.7373125553131104
Validation loss: 2.2138382295767465

Epoch: 5| Step: 4
Training loss: 1.8158721923828125
Validation loss: 2.2114154994487762

Epoch: 5| Step: 5
Training loss: 2.194640874862671
Validation loss: 2.2242168684800467

Epoch: 5| Step: 6
Training loss: 2.201388120651245
Validation loss: 2.191792219877243

Epoch: 5| Step: 7
Training loss: 2.3161919116973877
Validation loss: 2.1661863923072815

Epoch: 5| Step: 8
Training loss: 2.000929355621338
Validation loss: 2.2757520924011865

Epoch: 5| Step: 9
Training loss: 2.4353721141815186
Validation loss: 2.2393793761730194

Epoch: 5| Step: 10
Training loss: 2.0553154945373535
Validation loss: 2.2147795458634696

Epoch: 5| Step: 11
Training loss: 2.727078914642334
Validation loss: 2.187121421098709

Epoch: 19| Step: 0
Training loss: 2.074768543243408
Validation loss: 2.124100168546041

Epoch: 5| Step: 1
Training loss: 2.349280834197998
Validation loss: 2.161787653962771

Epoch: 5| Step: 2
Training loss: 1.8088133335113525
Validation loss: 2.2917604049046836

Epoch: 5| Step: 3
Training loss: 1.9515091180801392
Validation loss: 2.1724497179190316

Epoch: 5| Step: 4
Training loss: 1.806695580482483
Validation loss: 2.2029373347759247

Epoch: 5| Step: 5
Training loss: 2.5498440265655518
Validation loss: 2.1777527978022895

Epoch: 5| Step: 6
Training loss: 3.316542148590088
Validation loss: 2.200908506910006

Epoch: 5| Step: 7
Training loss: 1.9836242198944092
Validation loss: 2.1169185688098273

Epoch: 5| Step: 8
Training loss: 2.166210889816284
Validation loss: 2.104636624455452

Epoch: 5| Step: 9
Training loss: 1.980455994606018
Validation loss: 2.1865044931570687

Epoch: 5| Step: 10
Training loss: 1.8584951162338257
Validation loss: 2.1944565822680793

Epoch: 5| Step: 11
Training loss: 1.8713423013687134
Validation loss: 2.223333477973938

Epoch: 20| Step: 0
Training loss: 2.234323501586914
Validation loss: 2.2166306376457214

Epoch: 5| Step: 1
Training loss: 1.6688108444213867
Validation loss: 2.277512490749359

Epoch: 5| Step: 2
Training loss: 2.1108193397521973
Validation loss: 2.2708950539429984

Epoch: 5| Step: 3
Training loss: 2.3896422386169434
Validation loss: 2.2105227212111154

Epoch: 5| Step: 4
Training loss: 2.5472769737243652
Validation loss: 2.2229418456554413

Epoch: 5| Step: 5
Training loss: 1.716557264328003
Validation loss: 2.2066479275623956

Epoch: 5| Step: 6
Training loss: 1.9846502542495728
Validation loss: 2.188545048236847

Epoch: 5| Step: 7
Training loss: 2.1299996376037598
Validation loss: 2.2293601433436074

Epoch: 5| Step: 8
Training loss: 2.1376585960388184
Validation loss: 2.1565334598223367

Epoch: 5| Step: 9
Training loss: 2.072399854660034
Validation loss: 2.140621244907379

Epoch: 5| Step: 10
Training loss: 2.021425247192383
Validation loss: 2.180006672938665

Epoch: 5| Step: 11
Training loss: 3.1775951385498047
Validation loss: 2.1537229965130487

Epoch: 21| Step: 0
Training loss: 2.249021291732788
Validation loss: 2.2543598810831704

Epoch: 5| Step: 1
Training loss: 1.8334591388702393
Validation loss: 2.308387190103531

Epoch: 5| Step: 2
Training loss: 2.3354334831237793
Validation loss: 2.2644710391759872

Epoch: 5| Step: 3
Training loss: 2.6463563442230225
Validation loss: 2.2608545621236167

Epoch: 5| Step: 4
Training loss: 2.8672144412994385
Validation loss: 2.2636304845412574

Epoch: 5| Step: 5
Training loss: 2.2459635734558105
Validation loss: 2.1626618256171546

Epoch: 5| Step: 6
Training loss: 1.9069797992706299
Validation loss: 2.113471880555153

Epoch: 5| Step: 7
Training loss: 2.4109020233154297
Validation loss: 2.127899259328842

Epoch: 5| Step: 8
Training loss: 1.6894924640655518
Validation loss: 2.2328238735596337

Epoch: 5| Step: 9
Training loss: 1.8406703472137451
Validation loss: 2.1864470640818277

Epoch: 5| Step: 10
Training loss: 2.4365499019622803
Validation loss: 2.222565472126007

Epoch: 5| Step: 11
Training loss: 2.169926166534424
Validation loss: 2.2134189307689667

Epoch: 22| Step: 0
Training loss: 1.9803581237792969
Validation loss: 2.243029862642288

Epoch: 5| Step: 1
Training loss: 1.7812564373016357
Validation loss: 2.1976361920436225

Epoch: 5| Step: 2
Training loss: 2.3841769695281982
Validation loss: 2.204296439886093

Epoch: 5| Step: 3
Training loss: 2.5108485221862793
Validation loss: 2.1889848162730536

Epoch: 5| Step: 4
Training loss: 1.98721182346344
Validation loss: 2.1502612630526223

Epoch: 5| Step: 5
Training loss: 1.6266635656356812
Validation loss: 2.1035211235284805

Epoch: 5| Step: 6
Training loss: 1.730031967163086
Validation loss: 2.1931778689225516

Epoch: 5| Step: 7
Training loss: 2.415897846221924
Validation loss: 2.1834563314914703

Epoch: 5| Step: 8
Training loss: 2.4059853553771973
Validation loss: 2.1336380491654077

Epoch: 5| Step: 9
Training loss: 2.248671770095825
Validation loss: 2.2150210539499917

Epoch: 5| Step: 10
Training loss: 2.141885757446289
Validation loss: 2.1742287377516427

Epoch: 5| Step: 11
Training loss: 1.706366777420044
Validation loss: 2.1633537809054055

Epoch: 23| Step: 0
Training loss: 2.114649772644043
Validation loss: 2.1459156771500907

Epoch: 5| Step: 1
Training loss: 2.393704652786255
Validation loss: 2.134737273057302

Epoch: 5| Step: 2
Training loss: 2.3422389030456543
Validation loss: 2.218997299671173

Epoch: 5| Step: 3
Training loss: 1.8544203042984009
Validation loss: 2.2505597124497094

Epoch: 5| Step: 4
Training loss: 1.9420509338378906
Validation loss: 2.1978109876314798

Epoch: 5| Step: 5
Training loss: 2.155831813812256
Validation loss: 2.184690445661545

Epoch: 5| Step: 6
Training loss: 1.6902475357055664
Validation loss: 2.2171103407939277

Epoch: 5| Step: 7
Training loss: 2.3260364532470703
Validation loss: 2.156181280811628

Epoch: 5| Step: 8
Training loss: 2.0006296634674072
Validation loss: 2.1234154254198074

Epoch: 5| Step: 9
Training loss: 2.3441734313964844
Validation loss: 2.192390372355779

Epoch: 5| Step: 10
Training loss: 2.028724193572998
Validation loss: 2.2127283265193305

Epoch: 5| Step: 11
Training loss: 2.536050319671631
Validation loss: 2.11740905046463

Epoch: 24| Step: 0
Training loss: 2.1088976860046387
Validation loss: 2.2216552247603736

Epoch: 5| Step: 1
Training loss: 1.8447344303131104
Validation loss: 2.1978960037231445

Epoch: 5| Step: 2
Training loss: 1.935288667678833
Validation loss: 2.281030684709549

Epoch: 5| Step: 3
Training loss: 1.4338645935058594
Validation loss: 2.2970484594504037

Epoch: 5| Step: 4
Training loss: 1.8735225200653076
Validation loss: 2.1508502066135406

Epoch: 5| Step: 5
Training loss: 2.231102466583252
Validation loss: 2.179034640391668

Epoch: 5| Step: 6
Training loss: 2.282492160797119
Validation loss: 2.219268341859182

Epoch: 5| Step: 7
Training loss: 2.0131280422210693
Validation loss: 2.1923836171627045

Epoch: 5| Step: 8
Training loss: 1.9345149993896484
Validation loss: 2.150286157925924

Epoch: 5| Step: 9
Training loss: 2.052572250366211
Validation loss: 2.1818313946326575

Epoch: 5| Step: 10
Training loss: 3.1967594623565674
Validation loss: 2.116912454366684

Epoch: 5| Step: 11
Training loss: 2.813753366470337
Validation loss: 2.2502773702144623

Epoch: 25| Step: 0
Training loss: 2.3904049396514893
Validation loss: 2.208026041587194

Epoch: 5| Step: 1
Training loss: 2.357522487640381
Validation loss: 2.1425236662228904

Epoch: 5| Step: 2
Training loss: 1.6383079290390015
Validation loss: 2.273728390534719

Epoch: 5| Step: 3
Training loss: 1.8888790607452393
Validation loss: 2.28534164528052

Epoch: 5| Step: 4
Training loss: 3.392730712890625
Validation loss: 2.1873507549365363

Epoch: 5| Step: 5
Training loss: 2.026365280151367
Validation loss: 2.2049048940340676

Epoch: 5| Step: 6
Training loss: 2.121854066848755
Validation loss: 2.215327282746633

Epoch: 5| Step: 7
Training loss: 1.5998437404632568
Validation loss: 2.1581448713938394

Epoch: 5| Step: 8
Training loss: 2.0643718242645264
Validation loss: 2.142205332716306

Epoch: 5| Step: 9
Training loss: 1.8127609491348267
Validation loss: 2.183629418412844

Epoch: 5| Step: 10
Training loss: 1.8845268487930298
Validation loss: 2.1258561660846076

Epoch: 5| Step: 11
Training loss: 2.9077367782592773
Validation loss: 2.253117566307386

Epoch: 26| Step: 0
Training loss: 3.09232497215271
Validation loss: 2.1403122742970786

Epoch: 5| Step: 1
Training loss: 2.233717441558838
Validation loss: 2.1517991522947946

Epoch: 5| Step: 2
Training loss: 2.0847487449645996
Validation loss: 2.173474212487539

Epoch: 5| Step: 3
Training loss: 1.9659522771835327
Validation loss: 2.1254323522249856

Epoch: 5| Step: 4
Training loss: 1.9171663522720337
Validation loss: 2.225226193666458

Epoch: 5| Step: 5
Training loss: 1.5146658420562744
Validation loss: 2.2056241631507874

Epoch: 5| Step: 6
Training loss: 2.4630141258239746
Validation loss: 2.189059793949127

Epoch: 5| Step: 7
Training loss: 2.1574127674102783
Validation loss: 2.212230682373047

Epoch: 5| Step: 8
Training loss: 2.01332688331604
Validation loss: 2.2146088927984238

Epoch: 5| Step: 9
Training loss: 1.8044277429580688
Validation loss: 2.163608804345131

Epoch: 5| Step: 10
Training loss: 2.095463275909424
Validation loss: 2.1995435853799186

Epoch: 5| Step: 11
Training loss: 1.2181334495544434
Validation loss: 2.171226213375727

Epoch: 27| Step: 0
Training loss: 2.0947301387786865
Validation loss: 2.2097149789333344

Epoch: 5| Step: 1
Training loss: 1.615965485572815
Validation loss: 2.1862955739100776

Epoch: 5| Step: 2
Training loss: 1.8191038370132446
Validation loss: 2.157983273267746

Epoch: 5| Step: 3
Training loss: 2.3722305297851562
Validation loss: 2.1748064110676446

Epoch: 5| Step: 4
Training loss: 2.3986146450042725
Validation loss: 2.193817396958669

Epoch: 5| Step: 5
Training loss: 3.1649467945098877
Validation loss: 2.1647921750942865

Epoch: 5| Step: 6
Training loss: 2.328209400177002
Validation loss: 2.217466334501902

Epoch: 5| Step: 7
Training loss: 1.8322910070419312
Validation loss: 2.156916360060374

Epoch: 5| Step: 8
Training loss: 1.3007020950317383
Validation loss: 2.2242804765701294

Epoch: 5| Step: 9
Training loss: 2.02238392829895
Validation loss: 2.10471319158872

Epoch: 5| Step: 10
Training loss: 1.8560092449188232
Validation loss: 2.1453822751839957

Epoch: 5| Step: 11
Training loss: 4.110500812530518
Validation loss: 2.1677785019079843

Epoch: 28| Step: 0
Training loss: 2.0799965858459473
Validation loss: 2.2257871280113855

Epoch: 5| Step: 1
Training loss: 1.7182047367095947
Validation loss: 2.214176600178083

Epoch: 5| Step: 2
Training loss: 1.9333629608154297
Validation loss: 2.154181122779846

Epoch: 5| Step: 3
Training loss: 2.1034016609191895
Validation loss: 2.1351015170415244

Epoch: 5| Step: 4
Training loss: 2.0848395824432373
Validation loss: 2.1624046862125397

Epoch: 5| Step: 5
Training loss: 2.0053153038024902
Validation loss: 2.118621826171875

Epoch: 5| Step: 6
Training loss: 2.132765054702759
Validation loss: 2.1897930204868317

Epoch: 5| Step: 7
Training loss: 1.815938949584961
Validation loss: 2.1094382852315903

Epoch: 5| Step: 8
Training loss: 1.920760154724121
Validation loss: 2.196141724785169

Epoch: 5| Step: 9
Training loss: 2.1317412853240967
Validation loss: 2.197888488570849

Epoch: 5| Step: 10
Training loss: 2.7253708839416504
Validation loss: 2.170168017347654

Epoch: 5| Step: 11
Training loss: 1.4497990608215332
Validation loss: 2.184687465429306

Epoch: 29| Step: 0
Training loss: 1.5573780536651611
Validation loss: 2.1501718113819757

Epoch: 5| Step: 1
Training loss: 2.2177581787109375
Validation loss: 2.167213206489881

Epoch: 5| Step: 2
Training loss: 1.9092304706573486
Validation loss: 2.1929663022359214

Epoch: 5| Step: 3
Training loss: 1.8450939655303955
Validation loss: 2.2087196707725525

Epoch: 5| Step: 4
Training loss: 1.640385627746582
Validation loss: 2.144663651784261

Epoch: 5| Step: 5
Training loss: 2.4847521781921387
Validation loss: 2.1430960992972055

Epoch: 5| Step: 6
Training loss: 2.181915760040283
Validation loss: 2.1470150699218116

Epoch: 5| Step: 7
Training loss: 2.2033896446228027
Validation loss: 2.1933711568514505

Epoch: 5| Step: 8
Training loss: 2.369576930999756
Validation loss: 2.166753888130188

Epoch: 5| Step: 9
Training loss: 1.7953803539276123
Validation loss: 2.2018782695134482

Epoch: 5| Step: 10
Training loss: 1.5398433208465576
Validation loss: 2.1912818948427835

Epoch: 5| Step: 11
Training loss: 3.362109661102295
Validation loss: 2.1601537466049194

Epoch: 30| Step: 0
Training loss: 1.2321285009384155
Validation loss: 2.164771229028702

Epoch: 5| Step: 1
Training loss: 2.856604814529419
Validation loss: 2.1464753846327462

Epoch: 5| Step: 2
Training loss: 2.5144829750061035
Validation loss: 2.218387469649315

Epoch: 5| Step: 3
Training loss: 1.4354076385498047
Validation loss: 2.1559924433628717

Epoch: 5| Step: 4
Training loss: 2.420687198638916
Validation loss: 2.158913870652517

Epoch: 5| Step: 5
Training loss: 2.3194165229797363
Validation loss: 2.1087799568971

Epoch: 5| Step: 6
Training loss: 2.2319273948669434
Validation loss: 2.101435974240303

Epoch: 5| Step: 7
Training loss: 1.9930320978164673
Validation loss: 2.127569700280825

Epoch: 5| Step: 8
Training loss: 1.38396418094635
Validation loss: 2.15893225868543

Epoch: 5| Step: 9
Training loss: 2.387474536895752
Validation loss: 2.1980029890934625

Epoch: 5| Step: 10
Training loss: 1.6426509618759155
Validation loss: 2.2044683545827866

Epoch: 5| Step: 11
Training loss: 1.4745930433273315
Validation loss: 2.158762569228808

Epoch: 31| Step: 0
Training loss: 1.9435027837753296
Validation loss: 2.1635203659534454

Epoch: 5| Step: 1
Training loss: 2.6820993423461914
Validation loss: 2.12784181535244

Epoch: 5| Step: 2
Training loss: 2.46801495552063
Validation loss: 2.2245297531286874

Epoch: 5| Step: 3
Training loss: 2.153547763824463
Validation loss: 2.2027119447787604

Epoch: 5| Step: 4
Training loss: 1.353906273841858
Validation loss: 2.255317807197571

Epoch: 5| Step: 5
Training loss: 1.94489324092865
Validation loss: 2.276641617218653

Epoch: 5| Step: 6
Training loss: 1.9811179637908936
Validation loss: 2.277397632598877

Epoch: 5| Step: 7
Training loss: 2.079810380935669
Validation loss: 2.27461077272892

Epoch: 5| Step: 8
Training loss: 2.4849467277526855
Validation loss: 2.249042416612307

Epoch: 5| Step: 9
Training loss: 1.6750339269638062
Validation loss: 2.188091908891996

Epoch: 5| Step: 10
Training loss: 2.1288869380950928
Validation loss: 2.1247982184092202

Epoch: 5| Step: 11
Training loss: 2.016047477722168
Validation loss: 2.1631603290637336

Epoch: 32| Step: 0
Training loss: 1.933448076248169
Validation loss: 2.257556766271591

Epoch: 5| Step: 1
Training loss: 2.009153366088867
Validation loss: 2.316397100687027

Epoch: 5| Step: 2
Training loss: 2.1583025455474854
Validation loss: 2.3738218744595847

Epoch: 5| Step: 3
Training loss: 2.69401478767395
Validation loss: 2.453177273273468

Epoch: 5| Step: 4
Training loss: 1.6990506649017334
Validation loss: 2.5277061661084494

Epoch: 5| Step: 5
Training loss: 2.5177910327911377
Validation loss: 2.422215928634008

Epoch: 5| Step: 6
Training loss: 2.4540481567382812
Validation loss: 2.292931785186132

Epoch: 5| Step: 7
Training loss: 2.5040440559387207
Validation loss: 2.2286846339702606

Epoch: 5| Step: 8
Training loss: 2.5157644748687744
Validation loss: 2.1400225212176642

Epoch: 5| Step: 9
Training loss: 2.189516544342041
Validation loss: 2.1306348393360772

Epoch: 5| Step: 10
Training loss: 1.8436588048934937
Validation loss: 2.185508261124293

Epoch: 5| Step: 11
Training loss: 1.9188926219940186
Validation loss: 2.189050624767939

Epoch: 33| Step: 0
Training loss: 1.946886420249939
Validation loss: 2.252869814634323

Epoch: 5| Step: 1
Training loss: 2.001887083053589
Validation loss: 2.219573607047399

Epoch: 5| Step: 2
Training loss: 1.9994350671768188
Validation loss: 2.2772631645202637

Epoch: 5| Step: 3
Training loss: 1.860342264175415
Validation loss: 2.2293783773978553

Epoch: 5| Step: 4
Training loss: 2.573117971420288
Validation loss: 2.2908524672190347

Epoch: 5| Step: 5
Training loss: 2.3266472816467285
Validation loss: 2.2377367317676544

Epoch: 5| Step: 6
Training loss: 1.7357242107391357
Validation loss: 2.2125733544429145

Epoch: 5| Step: 7
Training loss: 2.5076241493225098
Validation loss: 2.182274510463079

Epoch: 5| Step: 8
Training loss: 1.918294906616211
Validation loss: 2.121617913246155

Epoch: 5| Step: 9
Training loss: 1.9766254425048828
Validation loss: 2.169818172852198

Epoch: 5| Step: 10
Training loss: 1.9104171991348267
Validation loss: 2.1539964328209558

Epoch: 5| Step: 11
Training loss: 2.0618042945861816
Validation loss: 2.142571752270063

Epoch: 34| Step: 0
Training loss: 2.360814332962036
Validation loss: 2.2313537995020547

Epoch: 5| Step: 1
Training loss: 2.017148494720459
Validation loss: 2.2128986616929374

Epoch: 5| Step: 2
Training loss: 2.0747158527374268
Validation loss: 2.211238851149877

Epoch: 5| Step: 3
Training loss: 2.1088690757751465
Validation loss: 2.20306329925855

Epoch: 5| Step: 4
Training loss: 2.092930316925049
Validation loss: 2.1574241866668067

Epoch: 5| Step: 5
Training loss: 2.1198458671569824
Validation loss: 2.1099331130584082

Epoch: 5| Step: 6
Training loss: 1.7444210052490234
Validation loss: 2.124363233645757

Epoch: 5| Step: 7
Training loss: 2.2416696548461914
Validation loss: 2.170038123925527

Epoch: 5| Step: 8
Training loss: 1.989579439163208
Validation loss: 2.193188647429148

Epoch: 5| Step: 9
Training loss: 2.2894537448883057
Validation loss: 2.1976947089036307

Epoch: 5| Step: 10
Training loss: 1.3587112426757812
Validation loss: 2.2105299532413483

Epoch: 5| Step: 11
Training loss: 2.3684580326080322
Validation loss: 2.0664578825235367

Epoch: 35| Step: 0
Training loss: 1.8985878229141235
Validation loss: 2.1809262335300446

Epoch: 5| Step: 1
Training loss: 1.8015873432159424
Validation loss: 2.192312096556028

Epoch: 5| Step: 2
Training loss: 2.257925510406494
Validation loss: 2.20399076739947

Epoch: 5| Step: 3
Training loss: 2.156135320663452
Validation loss: 2.2511447171370187

Epoch: 5| Step: 4
Training loss: 2.5600204467773438
Validation loss: 2.283794159690539

Epoch: 5| Step: 5
Training loss: 2.027005672454834
Validation loss: 2.265739386280378

Epoch: 5| Step: 6
Training loss: 1.6116807460784912
Validation loss: 2.23580830792586

Epoch: 5| Step: 7
Training loss: 1.7166461944580078
Validation loss: 2.125178317228953

Epoch: 5| Step: 8
Training loss: 2.293609619140625
Validation loss: 2.1505672683318457

Epoch: 5| Step: 9
Training loss: 2.7411069869995117
Validation loss: 2.174247538050016

Epoch: 5| Step: 10
Training loss: 1.9991645812988281
Validation loss: 2.1429035564263663

Epoch: 5| Step: 11
Training loss: 1.9911863803863525
Validation loss: 2.1719457457462945

Epoch: 36| Step: 0
Training loss: 2.0836098194122314
Validation loss: 2.135574614008268

Epoch: 5| Step: 1
Training loss: 1.8701817989349365
Validation loss: 2.1481199661890664

Epoch: 5| Step: 2
Training loss: 1.9237686395645142
Validation loss: 2.2107010086377463

Epoch: 5| Step: 3
Training loss: 1.9301754236221313
Validation loss: 2.1705716848373413

Epoch: 5| Step: 4
Training loss: 2.1036155223846436
Validation loss: 2.1640625844399133

Epoch: 5| Step: 5
Training loss: 2.2350668907165527
Validation loss: 2.1593499233325324

Epoch: 5| Step: 6
Training loss: 1.9454139471054077
Validation loss: 2.1571275293827057

Epoch: 5| Step: 7
Training loss: 1.954284429550171
Validation loss: 2.134800215562185

Epoch: 5| Step: 8
Training loss: 2.029486656188965
Validation loss: 2.1554466088612876

Epoch: 5| Step: 9
Training loss: 2.122624397277832
Validation loss: 2.0425001929203668

Epoch: 5| Step: 10
Training loss: 1.6611583232879639
Validation loss: 2.105710322658221

Epoch: 5| Step: 11
Training loss: 2.864546775817871
Validation loss: 2.1596674223740897

Epoch: 37| Step: 0
Training loss: 2.080296039581299
Validation loss: 2.18011744817098

Epoch: 5| Step: 1
Training loss: 1.918013572692871
Validation loss: 2.133706440528234

Epoch: 5| Step: 2
Training loss: 2.112096071243286
Validation loss: 2.3080047965049744

Epoch: 5| Step: 3
Training loss: 1.4760072231292725
Validation loss: 2.207459862033526

Epoch: 5| Step: 4
Training loss: 2.3334083557128906
Validation loss: 2.22502671678861

Epoch: 5| Step: 5
Training loss: 1.8585752248764038
Validation loss: 2.194225167234739

Epoch: 5| Step: 6
Training loss: 2.063490152359009
Validation loss: 2.117560550570488

Epoch: 5| Step: 7
Training loss: 1.9895216226577759
Validation loss: 2.177517900864283

Epoch: 5| Step: 8
Training loss: 2.148940324783325
Validation loss: 2.153884927431742

Epoch: 5| Step: 9
Training loss: 2.4137799739837646
Validation loss: 2.2008052468299866

Epoch: 5| Step: 10
Training loss: 2.093107223510742
Validation loss: 2.211580072840055

Epoch: 5| Step: 11
Training loss: 1.3127409219741821
Validation loss: 2.1638069401184716

Epoch: 38| Step: 0
Training loss: 2.194547176361084
Validation loss: 2.2101006309191384

Epoch: 5| Step: 1
Training loss: 1.897012710571289
Validation loss: 2.1839767148097358

Epoch: 5| Step: 2
Training loss: 1.5837525129318237
Validation loss: 2.1252341866493225

Epoch: 5| Step: 3
Training loss: 2.5279529094696045
Validation loss: 2.142136091987292

Epoch: 5| Step: 4
Training loss: 1.6662384271621704
Validation loss: 2.0625888059536615

Epoch: 5| Step: 5
Training loss: 1.9761463403701782
Validation loss: 2.054214979211489

Epoch: 5| Step: 6
Training loss: 1.9693872928619385
Validation loss: 2.190911586085955

Epoch: 5| Step: 7
Training loss: 2.357510805130005
Validation loss: 2.185494909683863

Epoch: 5| Step: 8
Training loss: 2.0577518939971924
Validation loss: 2.1675386180480323

Epoch: 5| Step: 9
Training loss: 2.0130257606506348
Validation loss: 2.192431335647901

Epoch: 5| Step: 10
Training loss: 1.7663275003433228
Validation loss: 2.1801919837792716

Epoch: 5| Step: 11
Training loss: 2.2491047382354736
Validation loss: 2.09362098077933

Epoch: 39| Step: 0
Training loss: 1.894232988357544
Validation loss: 2.0780527343352637

Epoch: 5| Step: 1
Training loss: 1.6024709939956665
Validation loss: 2.1892912487188974

Epoch: 5| Step: 2
Training loss: 1.8756529092788696
Validation loss: 2.193169747789701

Epoch: 5| Step: 3
Training loss: 1.8810335397720337
Validation loss: 2.0293843895196915

Epoch: 5| Step: 4
Training loss: 1.6971304416656494
Validation loss: 2.1969511955976486

Epoch: 5| Step: 5
Training loss: 1.612642526626587
Validation loss: 2.0960560242335

Epoch: 5| Step: 6
Training loss: 2.0047390460968018
Validation loss: 2.1347911606232324

Epoch: 5| Step: 7
Training loss: 2.203357219696045
Validation loss: 2.1719466845194497

Epoch: 5| Step: 8
Training loss: 2.354973316192627
Validation loss: 2.120562026898066

Epoch: 5| Step: 9
Training loss: 2.3233959674835205
Validation loss: 2.1513022730747857

Epoch: 5| Step: 10
Training loss: 1.999016523361206
Validation loss: 2.1020280867815018

Epoch: 5| Step: 11
Training loss: 1.0626006126403809
Validation loss: 2.103129302461942

Epoch: 40| Step: 0
Training loss: 1.9789321422576904
Validation loss: 2.0634760657946267

Epoch: 5| Step: 1
Training loss: 1.8867695331573486
Validation loss: 2.143995225429535

Epoch: 5| Step: 2
Training loss: 2.1312994956970215
Validation loss: 2.1752711087465286

Epoch: 5| Step: 3
Training loss: 2.602788209915161
Validation loss: 2.121244177222252

Epoch: 5| Step: 4
Training loss: 2.365692615509033
Validation loss: 2.116032953063647

Epoch: 5| Step: 5
Training loss: 2.0461061000823975
Validation loss: 2.145753636956215

Epoch: 5| Step: 6
Training loss: 1.4207780361175537
Validation loss: 2.1376010179519653

Epoch: 5| Step: 7
Training loss: 2.1717143058776855
Validation loss: 2.111194392045339

Epoch: 5| Step: 8
Training loss: 1.8387763500213623
Validation loss: 2.129850059747696

Epoch: 5| Step: 9
Training loss: 1.4364871978759766
Validation loss: 2.1583344439665475

Epoch: 5| Step: 10
Training loss: 1.6312649250030518
Validation loss: 2.123961851000786

Epoch: 5| Step: 11
Training loss: 1.6052918434143066
Validation loss: 2.2286719580491385

Epoch: 41| Step: 0
Training loss: 2.3956809043884277
Validation loss: 2.127423644065857

Epoch: 5| Step: 1
Training loss: 1.8010517358779907
Validation loss: 2.1816392640272775

Epoch: 5| Step: 2
Training loss: 2.1848411560058594
Validation loss: 2.143946369489034

Epoch: 5| Step: 3
Training loss: 2.0059287548065186
Validation loss: 2.0941149443387985

Epoch: 5| Step: 4
Training loss: 1.9972467422485352
Validation loss: 2.2144309282302856

Epoch: 5| Step: 5
Training loss: 1.8674354553222656
Validation loss: 2.0818095604578652

Epoch: 5| Step: 6
Training loss: 2.777468204498291
Validation loss: 2.093565364678701

Epoch: 5| Step: 7
Training loss: 1.5320907831192017
Validation loss: 2.18228609363238

Epoch: 5| Step: 8
Training loss: 1.476364016532898
Validation loss: 2.10042172173659

Epoch: 5| Step: 9
Training loss: 1.5786432027816772
Validation loss: 2.1966715653737388

Epoch: 5| Step: 10
Training loss: 1.5257536172866821
Validation loss: 2.178419217467308

Epoch: 5| Step: 11
Training loss: 2.1370046138763428
Validation loss: 2.2417846024036407

Epoch: 42| Step: 0
Training loss: 1.9515979290008545
Validation loss: 2.1493865698575974

Epoch: 5| Step: 1
Training loss: 1.5570423603057861
Validation loss: 2.2044021983941398

Epoch: 5| Step: 2
Training loss: 1.4831870794296265
Validation loss: 2.17496990164121

Epoch: 5| Step: 3
Training loss: 2.191732883453369
Validation loss: 2.1171510169903436

Epoch: 5| Step: 4
Training loss: 1.9997682571411133
Validation loss: 2.1796991924444833

Epoch: 5| Step: 5
Training loss: 2.220830202102661
Validation loss: 2.0935440361499786

Epoch: 5| Step: 6
Training loss: 1.6935875415802002
Validation loss: 2.1763396859169006

Epoch: 5| Step: 7
Training loss: 2.214421510696411
Validation loss: 2.153239354491234

Epoch: 5| Step: 8
Training loss: 2.162135601043701
Validation loss: 2.123691668113073

Epoch: 5| Step: 9
Training loss: 1.9408237934112549
Validation loss: 2.1572094162305198

Epoch: 5| Step: 10
Training loss: 1.8704936504364014
Validation loss: 2.162336821357409

Epoch: 5| Step: 11
Training loss: 1.928288459777832
Validation loss: 2.1736784974733987

Epoch: 43| Step: 0
Training loss: 1.519500970840454
Validation loss: 2.1479233354330063

Epoch: 5| Step: 1
Training loss: 2.938962936401367
Validation loss: 2.16524509092172

Epoch: 5| Step: 2
Training loss: 1.1616227626800537
Validation loss: 2.1842323740323386

Epoch: 5| Step: 3
Training loss: 1.6117732524871826
Validation loss: 2.1402742067972818

Epoch: 5| Step: 4
Training loss: 2.4218335151672363
Validation loss: 2.139039675394694

Epoch: 5| Step: 5
Training loss: 1.6992638111114502
Validation loss: 2.161102215449015

Epoch: 5| Step: 6
Training loss: 1.2878332138061523
Validation loss: 2.1388729164997735

Epoch: 5| Step: 7
Training loss: 1.808314561843872
Validation loss: 2.248022864262263

Epoch: 5| Step: 8
Training loss: 1.9128185510635376
Validation loss: 2.1895536134640374

Epoch: 5| Step: 9
Training loss: 2.7812156677246094
Validation loss: 2.2012083331743875

Epoch: 5| Step: 10
Training loss: 2.1337339878082275
Validation loss: 2.167542407910029

Epoch: 5| Step: 11
Training loss: 1.2210630178451538
Validation loss: 2.1934527456760406

Epoch: 44| Step: 0
Training loss: 1.9119230508804321
Validation loss: 2.2218418021996817

Epoch: 5| Step: 1
Training loss: 1.7342462539672852
Validation loss: 2.0928431252638497

Epoch: 5| Step: 2
Training loss: 1.950270652770996
Validation loss: 2.1875866850217185

Epoch: 5| Step: 3
Training loss: 2.184190273284912
Validation loss: 2.1541425635417304

Epoch: 5| Step: 4
Training loss: 1.4809285402297974
Validation loss: 2.1188123474518457

Epoch: 5| Step: 5
Training loss: 2.2370009422302246
Validation loss: 2.2128027230501175

Epoch: 5| Step: 6
Training loss: 1.9946712255477905
Validation loss: 2.207857703169187

Epoch: 5| Step: 7
Training loss: 1.518464207649231
Validation loss: 2.206565707921982

Epoch: 5| Step: 8
Training loss: 1.986800193786621
Validation loss: 2.135186488429705

Epoch: 5| Step: 9
Training loss: 2.528651714324951
Validation loss: 2.11776531736056

Epoch: 5| Step: 10
Training loss: 1.9114606380462646
Validation loss: 2.1615220655997596

Epoch: 5| Step: 11
Training loss: 1.0475752353668213
Validation loss: 2.172425369421641

Epoch: 45| Step: 0
Training loss: 2.229029893875122
Validation loss: 2.271851122379303

Epoch: 5| Step: 1
Training loss: 1.9382922649383545
Validation loss: 2.2476335962613425

Epoch: 5| Step: 2
Training loss: 1.3795350790023804
Validation loss: 2.1706311255693436

Epoch: 5| Step: 3
Training loss: 1.814672827720642
Validation loss: 2.2245083351929984

Epoch: 5| Step: 4
Training loss: 2.167396306991577
Validation loss: 2.1530510584513345

Epoch: 5| Step: 5
Training loss: 1.2720401287078857
Validation loss: 2.170066853364309

Epoch: 5| Step: 6
Training loss: 1.6205756664276123
Validation loss: 2.1393699844678244

Epoch: 5| Step: 7
Training loss: 2.152163505554199
Validation loss: 2.103616644938787

Epoch: 5| Step: 8
Training loss: 2.8188323974609375
Validation loss: 2.200042242805163

Epoch: 5| Step: 9
Training loss: 1.7408397197723389
Validation loss: 2.199534704287847

Epoch: 5| Step: 10
Training loss: 1.4858858585357666
Validation loss: 2.1516892164945602

Epoch: 5| Step: 11
Training loss: 2.12217378616333
Validation loss: 2.204721877972285

Epoch: 46| Step: 0
Training loss: 2.3075191974639893
Validation loss: 2.1454527427752814

Epoch: 5| Step: 1
Training loss: 1.819209098815918
Validation loss: 2.1555452992518744

Epoch: 5| Step: 2
Training loss: 2.2100043296813965
Validation loss: 2.1859370321035385

Epoch: 5| Step: 3
Training loss: 1.933616042137146
Validation loss: 2.2076944013436637

Epoch: 5| Step: 4
Training loss: 2.218615770339966
Validation loss: 2.1406865070263543

Epoch: 5| Step: 5
Training loss: 1.3433468341827393
Validation loss: 2.184920698404312

Epoch: 5| Step: 6
Training loss: 1.516631841659546
Validation loss: 2.132278695702553

Epoch: 5| Step: 7
Training loss: 1.7697054147720337
Validation loss: 2.15281210343043

Epoch: 5| Step: 8
Training loss: 1.7211525440216064
Validation loss: 2.164768308401108

Epoch: 5| Step: 9
Training loss: 1.829819917678833
Validation loss: 2.2565059761206308

Epoch: 5| Step: 10
Training loss: 2.5857152938842773
Validation loss: 2.2717310885588327

Epoch: 5| Step: 11
Training loss: 2.5524144172668457
Validation loss: 2.2224826216697693

Epoch: 47| Step: 0
Training loss: 1.5129601955413818
Validation loss: 2.16227779785792

Epoch: 5| Step: 1
Training loss: 1.4334642887115479
Validation loss: 2.199780692656835

Epoch: 5| Step: 2
Training loss: 1.4811766147613525
Validation loss: 2.160946716864904

Epoch: 5| Step: 3
Training loss: 1.8694751262664795
Validation loss: 2.1742330143849053

Epoch: 5| Step: 4
Training loss: 2.012549877166748
Validation loss: 2.2025987207889557

Epoch: 5| Step: 5
Training loss: 2.1224007606506348
Validation loss: 2.2153744995594025

Epoch: 5| Step: 6
Training loss: 1.9095379114151
Validation loss: 2.208202376961708

Epoch: 5| Step: 7
Training loss: 1.6315944194793701
Validation loss: 2.2140699277321496

Epoch: 5| Step: 8
Training loss: 2.558533191680908
Validation loss: 2.2397795816262565

Epoch: 5| Step: 9
Training loss: 2.4259064197540283
Validation loss: 2.2669139256079993

Epoch: 5| Step: 10
Training loss: 1.6614716053009033
Validation loss: 2.154191037019094

Epoch: 5| Step: 11
Training loss: 2.0231285095214844
Validation loss: 2.215959976116816

Epoch: 48| Step: 0
Training loss: 1.1766057014465332
Validation loss: 2.1988720297813416

Epoch: 5| Step: 1
Training loss: 1.9188610315322876
Validation loss: 2.1449675112962723

Epoch: 5| Step: 2
Training loss: 1.8231761455535889
Validation loss: 2.2337184995412827

Epoch: 5| Step: 3
Training loss: 1.9324957132339478
Validation loss: 2.1190642565488815

Epoch: 5| Step: 4
Training loss: 1.8917919397354126
Validation loss: 2.1904232849677405

Epoch: 5| Step: 5
Training loss: 2.3065433502197266
Validation loss: 2.1657894949118295

Epoch: 5| Step: 6
Training loss: 1.4202131032943726
Validation loss: 2.237059240539869

Epoch: 5| Step: 7
Training loss: 1.8568099737167358
Validation loss: 2.22550575931867

Epoch: 5| Step: 8
Training loss: 2.1402437686920166
Validation loss: 2.1119524091482162

Epoch: 5| Step: 9
Training loss: 2.089386463165283
Validation loss: 2.1889964590469995

Epoch: 5| Step: 10
Training loss: 2.1028425693511963
Validation loss: 2.1735793252786

Epoch: 5| Step: 11
Training loss: 2.289501667022705
Validation loss: 2.187925805648168

Epoch: 49| Step: 0
Training loss: 1.8932594060897827
Validation loss: 2.1002161353826523

Epoch: 5| Step: 1
Training loss: 1.9093230962753296
Validation loss: 2.218099981546402

Epoch: 5| Step: 2
Training loss: 2.143383502960205
Validation loss: 2.1414953718582788

Epoch: 5| Step: 3
Training loss: 1.8702996969223022
Validation loss: 2.241440251469612

Epoch: 5| Step: 4
Training loss: 2.1550540924072266
Validation loss: 2.1328794161478677

Epoch: 5| Step: 5
Training loss: 1.9180349111557007
Validation loss: 2.2058201084534326

Epoch: 5| Step: 6
Training loss: 1.7442588806152344
Validation loss: 2.1951569318771362

Epoch: 5| Step: 7
Training loss: 1.7303053140640259
Validation loss: 2.1990585774183273

Epoch: 5| Step: 8
Training loss: 2.075045108795166
Validation loss: 2.22410149872303

Epoch: 5| Step: 9
Training loss: 1.6700170040130615
Validation loss: 2.20473505059878

Epoch: 5| Step: 10
Training loss: 1.17129647731781
Validation loss: 2.0805972069501877

Epoch: 5| Step: 11
Training loss: 2.9765753746032715
Validation loss: 2.1332713266213736

Epoch: 50| Step: 0
Training loss: 1.6855920553207397
Validation loss: 2.2093877096970878

Epoch: 5| Step: 1
Training loss: 1.9331672191619873
Validation loss: 2.2517299155394235

Epoch: 5| Step: 2
Training loss: 1.3773577213287354
Validation loss: 2.2428228855133057

Epoch: 5| Step: 3
Training loss: 1.9409382343292236
Validation loss: 2.2292592972517014

Epoch: 5| Step: 4
Training loss: 1.8728965520858765
Validation loss: 2.162216146787008

Epoch: 5| Step: 5
Training loss: 1.2350645065307617
Validation loss: 2.2544498095909753

Epoch: 5| Step: 6
Training loss: 1.8061459064483643
Validation loss: 2.186316102743149

Epoch: 5| Step: 7
Training loss: 2.7456893920898438
Validation loss: 2.12885782122612

Epoch: 5| Step: 8
Training loss: 1.7022117376327515
Validation loss: 2.1225643704334893

Epoch: 5| Step: 9
Training loss: 1.7161344289779663
Validation loss: 2.1539902885754905

Epoch: 5| Step: 10
Training loss: 1.7841545343399048
Validation loss: 2.110569109519323

Epoch: 5| Step: 11
Training loss: 2.2907803058624268
Validation loss: 2.1918984055519104

Epoch: 51| Step: 0
Training loss: 2.7892918586730957
Validation loss: 2.2124806294838586

Epoch: 5| Step: 1
Training loss: 1.893471121788025
Validation loss: 2.1871654937664666

Epoch: 5| Step: 2
Training loss: 2.214478015899658
Validation loss: 2.2608213076988855

Epoch: 5| Step: 3
Training loss: 1.9724925756454468
Validation loss: 2.222751865784327

Epoch: 5| Step: 4
Training loss: 1.3464590311050415
Validation loss: 2.2058977832396827

Epoch: 5| Step: 5
Training loss: 1.7786182165145874
Validation loss: 2.1039377401272454

Epoch: 5| Step: 6
Training loss: 2.27565336227417
Validation loss: 2.1969339003165564

Epoch: 5| Step: 7
Training loss: 1.6878516674041748
Validation loss: 2.1638407607873282

Epoch: 5| Step: 8
Training loss: 1.5105698108673096
Validation loss: 2.1314073503017426

Epoch: 5| Step: 9
Training loss: 1.7756767272949219
Validation loss: 2.106064587831497

Epoch: 5| Step: 10
Training loss: 2.315924644470215
Validation loss: 2.110971982280413

Epoch: 5| Step: 11
Training loss: 1.7207773923873901
Validation loss: 2.1111762722333274

Epoch: 52| Step: 0
Training loss: 2.0797057151794434
Validation loss: 2.132709493239721

Epoch: 5| Step: 1
Training loss: 2.022242307662964
Validation loss: 2.181142886479696

Epoch: 5| Step: 2
Training loss: 1.5472919940948486
Validation loss: 2.135735789934794

Epoch: 5| Step: 3
Training loss: 2.0832672119140625
Validation loss: 2.1665162195762

Epoch: 5| Step: 4
Training loss: 1.95681893825531
Validation loss: 2.183702275156975

Epoch: 5| Step: 5
Training loss: 1.6770737171173096
Validation loss: 2.2133762190739312

Epoch: 5| Step: 6
Training loss: 1.6931394338607788
Validation loss: 2.093705420692762

Epoch: 5| Step: 7
Training loss: 1.651411771774292
Validation loss: 2.131570120652517

Epoch: 5| Step: 8
Training loss: 2.242612600326538
Validation loss: 2.156365474065145

Epoch: 5| Step: 9
Training loss: 1.9148660898208618
Validation loss: 2.1820218116045

Epoch: 5| Step: 10
Training loss: 1.2217917442321777
Validation loss: 2.1232321858406067

Epoch: 5| Step: 11
Training loss: 2.45139741897583
Validation loss: 2.1395094891389212

Epoch: 53| Step: 0
Training loss: 1.6013857126235962
Validation loss: 2.1501348266998925

Epoch: 5| Step: 1
Training loss: 1.4127981662750244
Validation loss: 2.1882950365543365

Epoch: 5| Step: 2
Training loss: 2.195189952850342
Validation loss: 2.1996619502703347

Epoch: 5| Step: 3
Training loss: 1.9799493551254272
Validation loss: 2.1117375046014786

Epoch: 5| Step: 4
Training loss: 1.4794188737869263
Validation loss: 2.180388629436493

Epoch: 5| Step: 5
Training loss: 2.5481619834899902
Validation loss: 2.1201647222042084

Epoch: 5| Step: 6
Training loss: 1.9305169582366943
Validation loss: 2.1049589763085046

Epoch: 5| Step: 7
Training loss: 1.1939185857772827
Validation loss: 2.209595580895742

Epoch: 5| Step: 8
Training loss: 1.3432013988494873
Validation loss: 2.1908654272556305

Epoch: 5| Step: 9
Training loss: 1.8211028575897217
Validation loss: 2.1566525946060815

Epoch: 5| Step: 10
Training loss: 1.8222488164901733
Validation loss: 2.1485414107640586

Epoch: 5| Step: 11
Training loss: 2.6191318035125732
Validation loss: 2.193597753842672

Epoch: 54| Step: 0
Training loss: 1.8353703022003174
Validation loss: 2.141373241941134

Epoch: 5| Step: 1
Training loss: 2.353881359100342
Validation loss: 2.200918957591057

Epoch: 5| Step: 2
Training loss: 2.2178962230682373
Validation loss: 2.153236538171768

Epoch: 5| Step: 3
Training loss: 1.7150471210479736
Validation loss: 2.1707632591327033

Epoch: 5| Step: 4
Training loss: 1.6917473077774048
Validation loss: 2.1427768220504126

Epoch: 5| Step: 5
Training loss: 1.649816870689392
Validation loss: 2.1476542949676514

Epoch: 5| Step: 6
Training loss: 1.5141336917877197
Validation loss: 2.140474612514178

Epoch: 5| Step: 7
Training loss: 1.8199926614761353
Validation loss: 2.169715682665507

Epoch: 5| Step: 8
Training loss: 2.0345559120178223
Validation loss: 2.1779310206572213

Epoch: 5| Step: 9
Training loss: 1.3024667501449585
Validation loss: 2.0596056828896203

Epoch: 5| Step: 10
Training loss: 1.7504303455352783
Validation loss: 2.1772832671801248

Epoch: 5| Step: 11
Training loss: 1.7793495655059814
Validation loss: 2.11642620464166

Epoch: 55| Step: 0
Training loss: 1.4539568424224854
Validation loss: 2.2014634013175964

Epoch: 5| Step: 1
Training loss: 2.4293112754821777
Validation loss: 2.257283493876457

Epoch: 5| Step: 2
Training loss: 2.0338025093078613
Validation loss: 2.166280205051104

Epoch: 5| Step: 3
Training loss: 1.8456566333770752
Validation loss: 2.217465172211329

Epoch: 5| Step: 4
Training loss: 1.562687635421753
Validation loss: 2.298069049914678

Epoch: 5| Step: 5
Training loss: 1.6424115896224976
Validation loss: 2.1627816557884216

Epoch: 5| Step: 6
Training loss: 2.052231550216675
Validation loss: 2.139185776313146

Epoch: 5| Step: 7
Training loss: 2.049345016479492
Validation loss: 2.1606977383295694

Epoch: 5| Step: 8
Training loss: 1.8310558795928955
Validation loss: 2.2519397536913552

Epoch: 5| Step: 9
Training loss: 1.9077316522598267
Validation loss: 2.216304987668991

Epoch: 5| Step: 10
Training loss: 2.318408489227295
Validation loss: 2.2500911255677543

Epoch: 5| Step: 11
Training loss: 3.2796621322631836
Validation loss: 2.3221735060214996

Epoch: 56| Step: 0
Training loss: 2.274048328399658
Validation loss: 2.29008279244105

Epoch: 5| Step: 1
Training loss: 2.160332441329956
Validation loss: 2.1789695421854653

Epoch: 5| Step: 2
Training loss: 1.3784687519073486
Validation loss: 2.1498530904452005

Epoch: 5| Step: 3
Training loss: 1.8862545490264893
Validation loss: 2.116684839129448

Epoch: 5| Step: 4
Training loss: 2.1418724060058594
Validation loss: 2.1958107203245163

Epoch: 5| Step: 5
Training loss: 1.7365570068359375
Validation loss: 2.181002199649811

Epoch: 5| Step: 6
Training loss: 2.343444347381592
Validation loss: 2.14036891857783

Epoch: 5| Step: 7
Training loss: 1.9476311206817627
Validation loss: 2.116878628730774

Epoch: 5| Step: 8
Training loss: 2.1171185970306396
Validation loss: 2.0953929076592126

Epoch: 5| Step: 9
Training loss: 1.617561936378479
Validation loss: 2.091214214762052

Epoch: 5| Step: 10
Training loss: 2.065849781036377
Validation loss: 2.090990071495374

Epoch: 5| Step: 11
Training loss: 2.531193256378174
Validation loss: 2.167331263422966

Epoch: 57| Step: 0
Training loss: 1.6432949304580688
Validation loss: 2.0854842414458594

Epoch: 5| Step: 1
Training loss: 0.9990644454956055
Validation loss: 2.1233781774838767

Epoch: 5| Step: 2
Training loss: 2.127408266067505
Validation loss: 2.146585335334142

Epoch: 5| Step: 3
Training loss: 2.11867356300354
Validation loss: 2.209166948994001

Epoch: 5| Step: 4
Training loss: 1.613883376121521
Validation loss: 2.1759017407894135

Epoch: 5| Step: 5
Training loss: 1.4958182573318481
Validation loss: 2.172608956694603

Epoch: 5| Step: 6
Training loss: 2.0857982635498047
Validation loss: 2.1462064385414124

Epoch: 5| Step: 7
Training loss: 2.135283946990967
Validation loss: 2.1405886511007943

Epoch: 5| Step: 8
Training loss: 1.7731866836547852
Validation loss: 2.149456466237704

Epoch: 5| Step: 9
Training loss: 2.372610569000244
Validation loss: 2.1084885001182556

Epoch: 5| Step: 10
Training loss: 1.5341542959213257
Validation loss: 2.149925261735916

Epoch: 5| Step: 11
Training loss: 1.6194356679916382
Validation loss: 2.219482938448588

Epoch: 58| Step: 0
Training loss: 1.309915542602539
Validation loss: 2.148355265458425

Epoch: 5| Step: 1
Training loss: 1.9664487838745117
Validation loss: 2.172438328464826

Epoch: 5| Step: 2
Training loss: 1.8579142093658447
Validation loss: 2.1288840770721436

Epoch: 5| Step: 3
Training loss: 1.8646841049194336
Validation loss: 2.2273548245429993

Epoch: 5| Step: 4
Training loss: 1.909376859664917
Validation loss: 2.222421939174334

Epoch: 5| Step: 5
Training loss: 2.2616381645202637
Validation loss: 2.1977640092372894

Epoch: 5| Step: 6
Training loss: 1.9964481592178345
Validation loss: 2.167495181163152

Epoch: 5| Step: 7
Training loss: 1.6782928705215454
Validation loss: 2.1573740988969803

Epoch: 5| Step: 8
Training loss: 1.530403733253479
Validation loss: 2.1239226907491684

Epoch: 5| Step: 9
Training loss: 2.048363208770752
Validation loss: 2.115509877602259

Epoch: 5| Step: 10
Training loss: 1.634856939315796
Validation loss: 2.1274720827738443

Epoch: 5| Step: 11
Training loss: 1.5437983274459839
Validation loss: 2.22079170246919

Epoch: 59| Step: 0
Training loss: 1.491506814956665
Validation loss: 2.199628750483195

Epoch: 5| Step: 1
Training loss: 1.974839448928833
Validation loss: 2.203564648826917

Epoch: 5| Step: 2
Training loss: 1.2675361633300781
Validation loss: 2.208479662736257

Epoch: 5| Step: 3
Training loss: 1.268405556678772
Validation loss: 2.137328416109085

Epoch: 5| Step: 4
Training loss: 2.1544930934906006
Validation loss: 2.2330129146575928

Epoch: 5| Step: 5
Training loss: 2.0040364265441895
Validation loss: 2.1553137501080832

Epoch: 5| Step: 6
Training loss: 1.8089174032211304
Validation loss: 2.1274601817131042

Epoch: 5| Step: 7
Training loss: 1.8185522556304932
Validation loss: 2.1920428772767386

Epoch: 5| Step: 8
Training loss: 2.293700933456421
Validation loss: 2.18560066819191

Epoch: 5| Step: 9
Training loss: 1.9092090129852295
Validation loss: 2.151512468854586

Epoch: 5| Step: 10
Training loss: 1.4952819347381592
Validation loss: 2.1624015867710114

Epoch: 5| Step: 11
Training loss: 2.036208152770996
Validation loss: 2.2384203424056373

Epoch: 60| Step: 0
Training loss: 2.1372063159942627
Validation loss: 2.1387866934140525

Epoch: 5| Step: 1
Training loss: 2.1861186027526855
Validation loss: 2.154258926709493

Epoch: 5| Step: 2
Training loss: 1.790178656578064
Validation loss: 2.0658674041430154

Epoch: 5| Step: 3
Training loss: 1.4611680507659912
Validation loss: 2.253897955020269

Epoch: 5| Step: 4
Training loss: 1.1557461023330688
Validation loss: 2.2655557493368783

Epoch: 5| Step: 5
Training loss: 1.986694574356079
Validation loss: 2.1629753410816193

Epoch: 5| Step: 6
Training loss: 2.1330082416534424
Validation loss: 2.221239517132441

Epoch: 5| Step: 7
Training loss: 1.653540849685669
Validation loss: 2.2174917509158454

Epoch: 5| Step: 8
Training loss: 2.0423898696899414
Validation loss: 2.209788183371226

Epoch: 5| Step: 9
Training loss: 1.6036980152130127
Validation loss: 2.2205060521761575

Epoch: 5| Step: 10
Training loss: 2.061854839324951
Validation loss: 2.1286180317401886

Epoch: 5| Step: 11
Training loss: 1.3342193365097046
Validation loss: 2.143158088127772

Epoch: 61| Step: 0
Training loss: 2.17374587059021
Validation loss: 2.151283636689186

Epoch: 5| Step: 1
Training loss: 1.5656960010528564
Validation loss: 2.1977107177178064

Epoch: 5| Step: 2
Training loss: 1.8097827434539795
Validation loss: 2.1228627810875573

Epoch: 5| Step: 3
Training loss: 1.5935461521148682
Validation loss: 2.2263546039660773

Epoch: 5| Step: 4
Training loss: 2.082617998123169
Validation loss: 2.170104751984278

Epoch: 5| Step: 5
Training loss: 1.926731824874878
Validation loss: 2.20584899187088

Epoch: 5| Step: 6
Training loss: 1.713707685470581
Validation loss: 2.200209304690361

Epoch: 5| Step: 7
Training loss: 1.661914587020874
Validation loss: 2.1956612020730972

Epoch: 5| Step: 8
Training loss: 1.746448278427124
Validation loss: 2.1697515745957694

Epoch: 5| Step: 9
Training loss: 2.2820005416870117
Validation loss: 2.1788971225420632

Epoch: 5| Step: 10
Training loss: 1.1853317022323608
Validation loss: 2.198443149526914

Epoch: 5| Step: 11
Training loss: 2.0458154678344727
Validation loss: 2.1956982910633087

Epoch: 62| Step: 0
Training loss: 1.2307660579681396
Validation loss: 2.0799231827259064

Epoch: 5| Step: 1
Training loss: 2.2788515090942383
Validation loss: 2.0526338120301566

Epoch: 5| Step: 2
Training loss: 1.3835914134979248
Validation loss: 2.1710152129332223

Epoch: 5| Step: 3
Training loss: 1.415094017982483
Validation loss: 2.151814098159472

Epoch: 5| Step: 4
Training loss: 2.045367479324341
Validation loss: 2.16010012725989

Epoch: 5| Step: 5
Training loss: 1.8475910425186157
Validation loss: 2.1788710753122964

Epoch: 5| Step: 6
Training loss: 2.173781156539917
Validation loss: 2.125529021024704

Epoch: 5| Step: 7
Training loss: 1.379884958267212
Validation loss: 2.142597829302152

Epoch: 5| Step: 8
Training loss: 1.6990658044815063
Validation loss: 2.1528708388408027

Epoch: 5| Step: 9
Training loss: 1.6243149042129517
Validation loss: 2.1564928789933524

Epoch: 5| Step: 10
Training loss: 1.6395728588104248
Validation loss: 2.1865331629912057

Epoch: 5| Step: 11
Training loss: 1.022108554840088
Validation loss: 2.1304857432842255

Epoch: 63| Step: 0
Training loss: 1.328150749206543
Validation loss: 2.1366207202275596

Epoch: 5| Step: 1
Training loss: 1.8289577960968018
Validation loss: 2.175873582561811

Epoch: 5| Step: 2
Training loss: 2.0316574573516846
Validation loss: 2.1325667649507523

Epoch: 5| Step: 3
Training loss: 1.819300889968872
Validation loss: 2.276603877544403

Epoch: 5| Step: 4
Training loss: 1.4358800649642944
Validation loss: 2.219238892197609

Epoch: 5| Step: 5
Training loss: 1.595518946647644
Validation loss: 2.2137660483519235

Epoch: 5| Step: 6
Training loss: 1.3569929599761963
Validation loss: 2.141295393308004

Epoch: 5| Step: 7
Training loss: 1.8940823078155518
Validation loss: 2.1492981960376105

Epoch: 5| Step: 8
Training loss: 2.032733201980591
Validation loss: 2.1335797905921936

Epoch: 5| Step: 9
Training loss: 1.8642942905426025
Validation loss: 2.181414614121119

Epoch: 5| Step: 10
Training loss: 1.8657360076904297
Validation loss: 2.2207391361395517

Epoch: 5| Step: 11
Training loss: 2.2913289070129395
Validation loss: 2.1459082464377084

Epoch: 64| Step: 0
Training loss: 1.522933840751648
Validation loss: 2.217154343922933

Epoch: 5| Step: 1
Training loss: 2.2653145790100098
Validation loss: 2.1286094337701797

Epoch: 5| Step: 2
Training loss: 1.5747686624526978
Validation loss: 2.1412829806407294

Epoch: 5| Step: 3
Training loss: 1.6508419513702393
Validation loss: 2.081111028790474

Epoch: 5| Step: 4
Training loss: 2.014554977416992
Validation loss: 2.1607387413581214

Epoch: 5| Step: 5
Training loss: 1.6473623514175415
Validation loss: 2.121787885824839

Epoch: 5| Step: 6
Training loss: 1.5716688632965088
Validation loss: 2.2316168596347175

Epoch: 5| Step: 7
Training loss: 1.7110605239868164
Validation loss: 2.1463273564974465

Epoch: 5| Step: 8
Training loss: 1.9074039459228516
Validation loss: 2.141610930363337

Epoch: 5| Step: 9
Training loss: 1.5521838665008545
Validation loss: 2.1833510398864746

Epoch: 5| Step: 10
Training loss: 1.5464932918548584
Validation loss: 2.175504888097445

Epoch: 5| Step: 11
Training loss: 3.188812732696533
Validation loss: 2.2120752880970636

Epoch: 65| Step: 0
Training loss: 1.5542595386505127
Validation loss: 2.1942143738269806

Epoch: 5| Step: 1
Training loss: 1.3646984100341797
Validation loss: 2.1756944010655084

Epoch: 5| Step: 2
Training loss: 1.6397273540496826
Validation loss: 2.3584600587685904

Epoch: 5| Step: 3
Training loss: 2.1073031425476074
Validation loss: 2.2767696479956308

Epoch: 5| Step: 4
Training loss: 2.516878128051758
Validation loss: 2.310050994157791

Epoch: 5| Step: 5
Training loss: 2.072369337081909
Validation loss: 2.2478800813357034

Epoch: 5| Step: 6
Training loss: 2.185804843902588
Validation loss: 2.2051287790139518

Epoch: 5| Step: 7
Training loss: 1.9545446634292603
Validation loss: 2.1987152049938836

Epoch: 5| Step: 8
Training loss: 1.860257863998413
Validation loss: 2.2643210341533027

Epoch: 5| Step: 9
Training loss: 1.5142898559570312
Validation loss: 2.2091608494520187

Epoch: 5| Step: 10
Training loss: 2.1283316612243652
Validation loss: 2.271208236614863

Epoch: 5| Step: 11
Training loss: 1.778136968612671
Validation loss: 2.306004007657369

Epoch: 66| Step: 0
Training loss: 1.4087215662002563
Validation loss: 2.254622668027878

Epoch: 5| Step: 1
Training loss: 2.1103978157043457
Validation loss: 2.335579534371694

Epoch: 5| Step: 2
Training loss: 1.3679144382476807
Validation loss: 2.140668049454689

Epoch: 5| Step: 3
Training loss: 1.9694322347640991
Validation loss: 2.116591140627861

Epoch: 5| Step: 4
Training loss: 2.225912094116211
Validation loss: 2.1097175578276315

Epoch: 5| Step: 5
Training loss: 2.013622999191284
Validation loss: 2.135793556769689

Epoch: 5| Step: 6
Training loss: 2.0303475856781006
Validation loss: 2.1402728259563446

Epoch: 5| Step: 7
Training loss: 1.6838390827178955
Validation loss: 2.263418177763621

Epoch: 5| Step: 8
Training loss: 1.824175238609314
Validation loss: 2.2165095806121826

Epoch: 5| Step: 9
Training loss: 1.556393027305603
Validation loss: 2.1947735399007797

Epoch: 5| Step: 10
Training loss: 2.069551467895508
Validation loss: 2.174508661031723

Epoch: 5| Step: 11
Training loss: 2.2840943336486816
Validation loss: 2.1683644155661264

Epoch: 67| Step: 0
Training loss: 1.5370336771011353
Validation loss: 2.1348803440729776

Epoch: 5| Step: 1
Training loss: 1.752039909362793
Validation loss: 2.1340084125598273

Epoch: 5| Step: 2
Training loss: 1.9405559301376343
Validation loss: 2.19302432735761

Epoch: 5| Step: 3
Training loss: 1.616127371788025
Validation loss: 2.224393750230471

Epoch: 5| Step: 4
Training loss: 1.9969091415405273
Validation loss: 2.1690006653467813

Epoch: 5| Step: 5
Training loss: 1.2174010276794434
Validation loss: 2.1516622453927994

Epoch: 5| Step: 6
Training loss: 1.9325382709503174
Validation loss: 2.1717228293418884

Epoch: 5| Step: 7
Training loss: 2.154580593109131
Validation loss: 2.1383763551712036

Epoch: 5| Step: 8
Training loss: 2.063988208770752
Validation loss: 2.052841310699781

Epoch: 5| Step: 9
Training loss: 1.7217010259628296
Validation loss: 2.0694390734036765

Epoch: 5| Step: 10
Training loss: 1.6094833612442017
Validation loss: 2.118957002957662

Epoch: 5| Step: 11
Training loss: 2.9033827781677246
Validation loss: 2.1806582609812417

Epoch: 68| Step: 0
Training loss: 1.7989848852157593
Validation loss: 2.1933441360791526

Epoch: 5| Step: 1
Training loss: 2.3528501987457275
Validation loss: 2.2189408938090005

Epoch: 5| Step: 2
Training loss: 1.528314471244812
Validation loss: 2.171683738629023

Epoch: 5| Step: 3
Training loss: 1.7718003988265991
Validation loss: 2.102740337451299

Epoch: 5| Step: 4
Training loss: 1.9504112005233765
Validation loss: 2.124540537595749

Epoch: 5| Step: 5
Training loss: 1.9876556396484375
Validation loss: 2.077658792336782

Epoch: 5| Step: 6
Training loss: 1.2609554529190063
Validation loss: 2.035425985852877

Epoch: 5| Step: 7
Training loss: 2.1777586936950684
Validation loss: 2.1626823991537094

Epoch: 5| Step: 8
Training loss: 1.9802919626235962
Validation loss: 2.084207351009051

Epoch: 5| Step: 9
Training loss: 1.5637218952178955
Validation loss: 2.125042036175728

Epoch: 5| Step: 10
Training loss: 1.426626443862915
Validation loss: 2.04413640499115

Epoch: 5| Step: 11
Training loss: 1.601184368133545
Validation loss: 2.174989700317383

Epoch: 69| Step: 0
Training loss: 1.2370398044586182
Validation loss: 2.1417118459939957

Epoch: 5| Step: 1
Training loss: 1.574068307876587
Validation loss: 2.0775083353122077

Epoch: 5| Step: 2
Training loss: 1.6000477075576782
Validation loss: 2.1383255223433175

Epoch: 5| Step: 3
Training loss: 1.1946773529052734
Validation loss: 2.197277933359146

Epoch: 5| Step: 4
Training loss: 2.0148167610168457
Validation loss: 2.1063682635625205

Epoch: 5| Step: 5
Training loss: 2.1885838508605957
Validation loss: 2.1895559479792914

Epoch: 5| Step: 6
Training loss: 1.5811785459518433
Validation loss: 2.097916374603907

Epoch: 5| Step: 7
Training loss: 1.665764570236206
Validation loss: 2.093289683262507

Epoch: 5| Step: 8
Training loss: 2.5227208137512207
Validation loss: 2.146372770269712

Epoch: 5| Step: 9
Training loss: 2.1281216144561768
Validation loss: 2.2221525510152182

Epoch: 5| Step: 10
Training loss: 1.2763681411743164
Validation loss: 2.084771747390429

Epoch: 5| Step: 11
Training loss: 2.0595703125
Validation loss: 2.163262516260147

Epoch: 70| Step: 0
Training loss: 1.2666834592819214
Validation loss: 2.21612016359965

Epoch: 5| Step: 1
Training loss: 1.6595195531845093
Validation loss: 2.147702470421791

Epoch: 5| Step: 2
Training loss: 1.3363345861434937
Validation loss: 2.10877725481987

Epoch: 5| Step: 3
Training loss: 1.9731069803237915
Validation loss: 2.130779375632604

Epoch: 5| Step: 4
Training loss: 1.7846782207489014
Validation loss: 2.0708613892396293

Epoch: 5| Step: 5
Training loss: 1.8276026248931885
Validation loss: 2.1432771931091943

Epoch: 5| Step: 6
Training loss: 1.0292894840240479
Validation loss: 2.1644992530345917

Epoch: 5| Step: 7
Training loss: 1.9375789165496826
Validation loss: 2.0881304889917374

Epoch: 5| Step: 8
Training loss: 1.8969014883041382
Validation loss: 2.036940182248751

Epoch: 5| Step: 9
Training loss: 1.9264049530029297
Validation loss: 2.1754695971806846

Epoch: 5| Step: 10
Training loss: 2.222304105758667
Validation loss: 2.266365647315979

Epoch: 5| Step: 11
Training loss: 1.010623574256897
Validation loss: 2.056698049108187

Epoch: 71| Step: 0
Training loss: 1.5991508960723877
Validation loss: 2.2237358589967093

Epoch: 5| Step: 1
Training loss: 1.5314816236495972
Validation loss: 2.171205480893453

Epoch: 5| Step: 2
Training loss: 1.974652886390686
Validation loss: 2.1187968254089355

Epoch: 5| Step: 3
Training loss: 1.419377326965332
Validation loss: 2.153590758641561

Epoch: 5| Step: 4
Training loss: 1.9841874837875366
Validation loss: 2.1130694846312204

Epoch: 5| Step: 5
Training loss: 1.9337905645370483
Validation loss: 2.2467241833607354

Epoch: 5| Step: 6
Training loss: 2.290029764175415
Validation loss: 2.1890792747338614

Epoch: 5| Step: 7
Training loss: 1.7794917821884155
Validation loss: 2.2417149990797043

Epoch: 5| Step: 8
Training loss: 1.8096935749053955
Validation loss: 2.1832468758026757

Epoch: 5| Step: 9
Training loss: 1.5982507467269897
Validation loss: 2.233047381043434

Epoch: 5| Step: 10
Training loss: 1.3071891069412231
Validation loss: 2.09281795223554

Epoch: 5| Step: 11
Training loss: 1.6414965391159058
Validation loss: 2.1754405051469803

Epoch: 72| Step: 0
Training loss: 1.3140422105789185
Validation loss: 2.2253006299336753

Epoch: 5| Step: 1
Training loss: 1.9697498083114624
Validation loss: 2.173777769009272

Epoch: 5| Step: 2
Training loss: 1.5450019836425781
Validation loss: 2.2189277162154517

Epoch: 5| Step: 3
Training loss: 1.511005163192749
Validation loss: 2.196282237768173

Epoch: 5| Step: 4
Training loss: 1.769592046737671
Validation loss: 2.1771702021360397

Epoch: 5| Step: 5
Training loss: 1.4907351732254028
Validation loss: 2.1556949416796365

Epoch: 5| Step: 6
Training loss: 1.5457755327224731
Validation loss: 2.1581575075785318

Epoch: 5| Step: 7
Training loss: 1.303818702697754
Validation loss: 2.1299842248360314

Epoch: 5| Step: 8
Training loss: 1.7649478912353516
Validation loss: 2.1300217459599176

Epoch: 5| Step: 9
Training loss: 1.9421899318695068
Validation loss: 2.1588408201932907

Epoch: 5| Step: 10
Training loss: 2.1797852516174316
Validation loss: 2.161318158109983

Epoch: 5| Step: 11
Training loss: 1.821669578552246
Validation loss: 2.205255458752314

Epoch: 73| Step: 0
Training loss: 1.5290307998657227
Validation loss: 2.184462303916613

Epoch: 5| Step: 1
Training loss: 1.5521546602249146
Validation loss: 2.196903501947721

Epoch: 5| Step: 2
Training loss: 1.6728630065917969
Validation loss: 2.185708155234655

Epoch: 5| Step: 3
Training loss: 1.959934949874878
Validation loss: 2.233463486035665

Epoch: 5| Step: 4
Training loss: 1.9759635925292969
Validation loss: 2.168729598323504

Epoch: 5| Step: 5
Training loss: 1.3352711200714111
Validation loss: 2.1716250826915107

Epoch: 5| Step: 6
Training loss: 1.8967387676239014
Validation loss: 2.134535402059555

Epoch: 5| Step: 7
Training loss: 2.4942078590393066
Validation loss: 2.1642836531003318

Epoch: 5| Step: 8
Training loss: 1.5709412097930908
Validation loss: 2.1947154899438224

Epoch: 5| Step: 9
Training loss: 1.5623053312301636
Validation loss: 2.0881556222836175

Epoch: 5| Step: 10
Training loss: 2.097547769546509
Validation loss: 2.174370030562083

Epoch: 5| Step: 11
Training loss: 1.8398536443710327
Validation loss: 2.2319510032733283

Epoch: 74| Step: 0
Training loss: 1.2929573059082031
Validation loss: 2.1643777936697006

Epoch: 5| Step: 1
Training loss: 2.168278932571411
Validation loss: 2.1199842194716134

Epoch: 5| Step: 2
Training loss: 1.4955698251724243
Validation loss: 2.2096587171157203

Epoch: 5| Step: 3
Training loss: 1.6043857336044312
Validation loss: 2.1801514277855554

Epoch: 5| Step: 4
Training loss: 1.8741559982299805
Validation loss: 2.1891488830248513

Epoch: 5| Step: 5
Training loss: 1.648508071899414
Validation loss: 2.211085150639216

Epoch: 5| Step: 6
Training loss: 1.7140175104141235
Validation loss: 2.186520646015803

Epoch: 5| Step: 7
Training loss: 1.6374645233154297
Validation loss: 2.223022152980169

Epoch: 5| Step: 8
Training loss: 1.849229097366333
Validation loss: 2.192452241977056

Epoch: 5| Step: 9
Training loss: 1.7773700952529907
Validation loss: 2.1045680244763694

Epoch: 5| Step: 10
Training loss: 2.0189476013183594
Validation loss: 2.0855311850706735

Epoch: 5| Step: 11
Training loss: 0.5373916029930115
Validation loss: 2.175240238507589

Epoch: 75| Step: 0
Training loss: 1.8231548070907593
Validation loss: 2.154938206076622

Epoch: 5| Step: 1
Training loss: 1.4600309133529663
Validation loss: 2.1608736465374627

Epoch: 5| Step: 2
Training loss: 1.4737926721572876
Validation loss: 2.1338838189840317

Epoch: 5| Step: 3
Training loss: 1.190176010131836
Validation loss: 2.1837312479813895

Epoch: 5| Step: 4
Training loss: 2.241154193878174
Validation loss: 2.1628969808419547

Epoch: 5| Step: 5
Training loss: 1.849041223526001
Validation loss: 2.0938203185796738

Epoch: 5| Step: 6
Training loss: 1.5646902322769165
Validation loss: 2.096857542792956

Epoch: 5| Step: 7
Training loss: 2.0183498859405518
Validation loss: 2.1569954305887222

Epoch: 5| Step: 8
Training loss: 1.459981083869934
Validation loss: 2.1718701968590417

Epoch: 5| Step: 9
Training loss: 1.480826497077942
Validation loss: 2.1597316016753516

Epoch: 5| Step: 10
Training loss: 1.8259061574935913
Validation loss: 2.0777945518493652

Epoch: 5| Step: 11
Training loss: 1.125612735748291
Validation loss: 2.104257086912791

Epoch: 76| Step: 0
Training loss: 1.9817378520965576
Validation loss: 2.1287280370791755

Epoch: 5| Step: 1
Training loss: 1.5149431228637695
Validation loss: 2.1245233168204627

Epoch: 5| Step: 2
Training loss: 1.7671550512313843
Validation loss: 2.1419518142938614

Epoch: 5| Step: 3
Training loss: 1.9679847955703735
Validation loss: 2.216781417528788

Epoch: 5| Step: 4
Training loss: 0.9549716114997864
Validation loss: 2.210349455475807

Epoch: 5| Step: 5
Training loss: 1.672423005104065
Validation loss: 2.1806064397096634

Epoch: 5| Step: 6
Training loss: 1.3936748504638672
Validation loss: 2.1900947093963623

Epoch: 5| Step: 7
Training loss: 1.3337726593017578
Validation loss: 2.1363093058268228

Epoch: 5| Step: 8
Training loss: 1.3530006408691406
Validation loss: 2.1148408899704614

Epoch: 5| Step: 9
Training loss: 2.185708522796631
Validation loss: 2.1700342694918313

Epoch: 5| Step: 10
Training loss: 1.8955923318862915
Validation loss: 2.1779675434033074

Epoch: 5| Step: 11
Training loss: 2.712681770324707
Validation loss: 2.193874011437098

Epoch: 77| Step: 0
Training loss: 1.7062476873397827
Validation loss: 2.1053942988316217

Epoch: 5| Step: 1
Training loss: 1.6767078638076782
Validation loss: 2.1268580506245294

Epoch: 5| Step: 2
Training loss: 1.4890743494033813
Validation loss: 2.1221946676572165

Epoch: 5| Step: 3
Training loss: 1.6516196727752686
Validation loss: 2.1117787957191467

Epoch: 5| Step: 4
Training loss: 1.869624376296997
Validation loss: 2.1626260429620743

Epoch: 5| Step: 5
Training loss: 1.6071903705596924
Validation loss: 2.2273045778274536

Epoch: 5| Step: 6
Training loss: 1.6397345066070557
Validation loss: 2.224016860127449

Epoch: 5| Step: 7
Training loss: 1.6003859043121338
Validation loss: 2.133749599258105

Epoch: 5| Step: 8
Training loss: 1.987839937210083
Validation loss: 2.1377708266178765

Epoch: 5| Step: 9
Training loss: 1.704643964767456
Validation loss: 2.0969143559535346

Epoch: 5| Step: 10
Training loss: 1.5375478267669678
Validation loss: 2.1198616921901703

Epoch: 5| Step: 11
Training loss: 1.336953043937683
Validation loss: 2.187480022509893

Epoch: 78| Step: 0
Training loss: 1.5064173936843872
Validation loss: 2.1994107415278754

Epoch: 5| Step: 1
Training loss: 1.6969401836395264
Validation loss: 2.0847127785285315

Epoch: 5| Step: 2
Training loss: 2.000795364379883
Validation loss: 2.1485969175895057

Epoch: 5| Step: 3
Training loss: 1.3933502435684204
Validation loss: 2.188452993830045

Epoch: 5| Step: 4
Training loss: 1.5617542266845703
Validation loss: 2.0845935295025506

Epoch: 5| Step: 5
Training loss: 2.115709066390991
Validation loss: 2.1723753958940506

Epoch: 5| Step: 6
Training loss: 1.5998287200927734
Validation loss: 2.215917870402336

Epoch: 5| Step: 7
Training loss: 1.4253480434417725
Validation loss: 2.207831601301829

Epoch: 5| Step: 8
Training loss: 1.3817684650421143
Validation loss: 2.261296182870865

Epoch: 5| Step: 9
Training loss: 1.6207656860351562
Validation loss: 2.1849456628163657

Epoch: 5| Step: 10
Training loss: 2.18668794631958
Validation loss: 2.196384827295939

Epoch: 5| Step: 11
Training loss: 1.229645848274231
Validation loss: 2.1021219541629157

Epoch: 79| Step: 0
Training loss: 2.46563458442688
Validation loss: 2.1858795136213303

Epoch: 5| Step: 1
Training loss: 2.054691791534424
Validation loss: 2.2227039833863578

Epoch: 5| Step: 2
Training loss: 1.7714779376983643
Validation loss: 2.2577490309874215

Epoch: 5| Step: 3
Training loss: 1.6560041904449463
Validation loss: 2.185471544663111

Epoch: 5| Step: 4
Training loss: 1.8836387395858765
Validation loss: 2.1804373363653817

Epoch: 5| Step: 5
Training loss: 1.4306257963180542
Validation loss: 2.0670951704184213

Epoch: 5| Step: 6
Training loss: 1.2290763854980469
Validation loss: 2.081651896238327

Epoch: 5| Step: 7
Training loss: 1.8981441259384155
Validation loss: 2.1682107349236808

Epoch: 5| Step: 8
Training loss: 1.8831875324249268
Validation loss: 2.189887469013532

Epoch: 5| Step: 9
Training loss: 2.095139503479004
Validation loss: 2.2109581331411996

Epoch: 5| Step: 10
Training loss: 1.1306488513946533
Validation loss: 2.1542528917392096

Epoch: 5| Step: 11
Training loss: 0.9508696794509888
Validation loss: 2.1856037974357605

Epoch: 80| Step: 0
Training loss: 1.4736908674240112
Validation loss: 2.1863964150349298

Epoch: 5| Step: 1
Training loss: 1.8622500896453857
Validation loss: 2.163898527622223

Epoch: 5| Step: 2
Training loss: 1.278062105178833
Validation loss: 2.1907686392466226

Epoch: 5| Step: 3
Training loss: 1.845754623413086
Validation loss: 2.1012892623742423

Epoch: 5| Step: 4
Training loss: 2.094910144805908
Validation loss: 2.1282883286476135

Epoch: 5| Step: 5
Training loss: 1.5992116928100586
Validation loss: 2.1664086182912192

Epoch: 5| Step: 6
Training loss: 1.4128503799438477
Validation loss: 2.134539549549421

Epoch: 5| Step: 7
Training loss: 1.6228477954864502
Validation loss: 2.049928997953733

Epoch: 5| Step: 8
Training loss: 1.6760860681533813
Validation loss: 2.183806985616684

Epoch: 5| Step: 9
Training loss: 1.442808747291565
Validation loss: 2.1101487477620444

Epoch: 5| Step: 10
Training loss: 1.5408432483673096
Validation loss: 2.0747130513191223

Epoch: 5| Step: 11
Training loss: 1.8192601203918457
Validation loss: 2.198989823460579

Epoch: 81| Step: 0
Training loss: 1.8264840841293335
Validation loss: 2.156786486506462

Epoch: 5| Step: 1
Training loss: 1.412501573562622
Validation loss: 2.1720510522524514

Epoch: 5| Step: 2
Training loss: 1.1227115392684937
Validation loss: 2.0794629752635956

Epoch: 5| Step: 3
Training loss: 2.013761281967163
Validation loss: 2.1069308668375015

Epoch: 5| Step: 4
Training loss: 1.1251819133758545
Validation loss: 2.15495731929938

Epoch: 5| Step: 5
Training loss: 1.4711555242538452
Validation loss: 2.1134888033072152

Epoch: 5| Step: 6
Training loss: 1.9541847705841064
Validation loss: 2.2093719094991684

Epoch: 5| Step: 7
Training loss: 2.064765214920044
Validation loss: 2.145588974157969

Epoch: 5| Step: 8
Training loss: 1.2875405550003052
Validation loss: 2.091591348250707

Epoch: 5| Step: 9
Training loss: 1.434239149093628
Validation loss: 2.1362794836362204

Epoch: 5| Step: 10
Training loss: 1.8511600494384766
Validation loss: 2.144561544060707

Epoch: 5| Step: 11
Training loss: 3.0416173934936523
Validation loss: 2.1367375453313193

Epoch: 82| Step: 0
Training loss: 1.7060878276824951
Validation loss: 2.175460308790207

Epoch: 5| Step: 1
Training loss: 1.8771522045135498
Validation loss: 2.170076568921407

Epoch: 5| Step: 2
Training loss: 1.6886036396026611
Validation loss: 2.2451890856027603

Epoch: 5| Step: 3
Training loss: 1.3121532201766968
Validation loss: 2.2064566612243652

Epoch: 5| Step: 4
Training loss: 1.93385910987854
Validation loss: 2.152680108944575

Epoch: 5| Step: 5
Training loss: 1.2296162843704224
Validation loss: 2.115340684851011

Epoch: 5| Step: 6
Training loss: 1.6227705478668213
Validation loss: 2.2129832158486047

Epoch: 5| Step: 7
Training loss: 1.5122581720352173
Validation loss: 2.1500121603409448

Epoch: 5| Step: 8
Training loss: 2.2950987815856934
Validation loss: 2.1531683206558228

Epoch: 5| Step: 9
Training loss: 1.6188240051269531
Validation loss: 2.1343030631542206

Epoch: 5| Step: 10
Training loss: 1.2402584552764893
Validation loss: 2.0882963438828788

Epoch: 5| Step: 11
Training loss: 1.0021159648895264
Validation loss: 2.2038701623678207

Epoch: 83| Step: 0
Training loss: 1.7009966373443604
Validation loss: 2.127124269803365

Epoch: 5| Step: 1
Training loss: 1.4429817199707031
Validation loss: 2.1035547902186713

Epoch: 5| Step: 2
Training loss: 1.33119797706604
Validation loss: 2.0815369884173074

Epoch: 5| Step: 3
Training loss: 1.7974122762680054
Validation loss: 2.144990086555481

Epoch: 5| Step: 4
Training loss: 1.4667562246322632
Validation loss: 2.29988224307696

Epoch: 5| Step: 5
Training loss: 1.70162832736969
Validation loss: 2.14616551498572

Epoch: 5| Step: 6
Training loss: 1.58351731300354
Validation loss: 2.189497028787931

Epoch: 5| Step: 7
Training loss: 1.768294334411621
Validation loss: 2.0722427715857825

Epoch: 5| Step: 8
Training loss: 2.0292062759399414
Validation loss: 2.184523344039917

Epoch: 5| Step: 9
Training loss: 1.231675148010254
Validation loss: 2.176710029443105

Epoch: 5| Step: 10
Training loss: 1.286350131034851
Validation loss: 2.1787301997343698

Epoch: 5| Step: 11
Training loss: 0.8694435358047485
Validation loss: 2.2119233310222626

Epoch: 84| Step: 0
Training loss: 1.4894788265228271
Validation loss: 2.25296580294768

Epoch: 5| Step: 1
Training loss: 2.415675640106201
Validation loss: 2.3597221076488495

Epoch: 5| Step: 2
Training loss: 2.1922309398651123
Validation loss: 2.3846448858579

Epoch: 5| Step: 3
Training loss: 1.6464065313339233
Validation loss: 2.3316929837067923

Epoch: 5| Step: 4
Training loss: 1.6749992370605469
Validation loss: 2.261425713698069

Epoch: 5| Step: 5
Training loss: 1.1755746603012085
Validation loss: 2.2159599463144937

Epoch: 5| Step: 6
Training loss: 1.8542630672454834
Validation loss: 2.0882765849431357

Epoch: 5| Step: 7
Training loss: 1.6055023670196533
Validation loss: 2.188746561606725

Epoch: 5| Step: 8
Training loss: 1.7058881521224976
Validation loss: 2.200009564558665

Epoch: 5| Step: 9
Training loss: 1.8600490093231201
Validation loss: 2.2037265996138253

Epoch: 5| Step: 10
Training loss: 1.8329744338989258
Validation loss: 2.1735937893390656

Epoch: 5| Step: 11
Training loss: 1.916031837463379
Validation loss: 2.186722586552302

Epoch: 85| Step: 0
Training loss: 1.925011396408081
Validation loss: 2.1317832867304483

Epoch: 5| Step: 1
Training loss: 1.8305755853652954
Validation loss: 2.0872912853956223

Epoch: 5| Step: 2
Training loss: 2.0285277366638184
Validation loss: 2.1233370105425515

Epoch: 5| Step: 3
Training loss: 1.494986653327942
Validation loss: 2.116471529006958

Epoch: 5| Step: 4
Training loss: 1.9613548517227173
Validation loss: 2.201786627372106

Epoch: 5| Step: 5
Training loss: 1.803755760192871
Validation loss: 2.207765817642212

Epoch: 5| Step: 6
Training loss: 2.0236902236938477
Validation loss: 2.059913953145345

Epoch: 5| Step: 7
Training loss: 1.3700206279754639
Validation loss: 2.2485717634359994

Epoch: 5| Step: 8
Training loss: 1.0177514553070068
Validation loss: 2.0922314325968423

Epoch: 5| Step: 9
Training loss: 1.8712103366851807
Validation loss: 2.055934647719065

Epoch: 5| Step: 10
Training loss: 1.433983564376831
Validation loss: 2.115580677986145

Epoch: 5| Step: 11
Training loss: 0.6495919227600098
Validation loss: 2.140301580230395

Epoch: 86| Step: 0
Training loss: 1.4078361988067627
Validation loss: 2.0404940992593765

Epoch: 5| Step: 1
Training loss: 1.2338621616363525
Validation loss: 2.1750774880250296

Epoch: 5| Step: 2
Training loss: 1.7158868312835693
Validation loss: 2.054276799162229

Epoch: 5| Step: 3
Training loss: 1.8517554998397827
Validation loss: 2.0725281784931817

Epoch: 5| Step: 4
Training loss: 1.7409824132919312
Validation loss: 2.06011962890625

Epoch: 5| Step: 5
Training loss: 0.988500714302063
Validation loss: 2.079129988948504

Epoch: 5| Step: 6
Training loss: 1.4845781326293945
Validation loss: 2.120394935210546

Epoch: 5| Step: 7
Training loss: 1.9024171829223633
Validation loss: 2.152155354619026

Epoch: 5| Step: 8
Training loss: 1.5121958255767822
Validation loss: 2.112063705921173

Epoch: 5| Step: 9
Training loss: 1.358707308769226
Validation loss: 2.1291464368502298

Epoch: 5| Step: 10
Training loss: 1.8917179107666016
Validation loss: 2.1046372652053833

Epoch: 5| Step: 11
Training loss: 2.34291410446167
Validation loss: 2.0672097901503244

Epoch: 87| Step: 0
Training loss: 1.0632281303405762
Validation loss: 2.1194620529810586

Epoch: 5| Step: 1
Training loss: 1.1392920017242432
Validation loss: 2.0665177355209985

Epoch: 5| Step: 2
Training loss: 1.7971765995025635
Validation loss: 2.2242940862973533

Epoch: 5| Step: 3
Training loss: 2.072218894958496
Validation loss: 2.1482676217953363

Epoch: 5| Step: 4
Training loss: 1.7008126974105835
Validation loss: 2.1683498273293176

Epoch: 5| Step: 5
Training loss: 1.6008636951446533
Validation loss: 2.1679980556170144

Epoch: 5| Step: 6
Training loss: 1.2364474534988403
Validation loss: 2.201298544804255

Epoch: 5| Step: 7
Training loss: 1.683833360671997
Validation loss: 2.129737913608551

Epoch: 5| Step: 8
Training loss: 2.0862083435058594
Validation loss: 2.155527720848719

Epoch: 5| Step: 9
Training loss: 1.9177192449569702
Validation loss: 2.107267906268438

Epoch: 5| Step: 10
Training loss: 0.938718318939209
Validation loss: 2.143336276213328

Epoch: 5| Step: 11
Training loss: 1.4282623529434204
Validation loss: 2.1587073604265847

Epoch: 88| Step: 0
Training loss: 1.6342315673828125
Validation loss: 2.155077869693438

Epoch: 5| Step: 1
Training loss: 1.6254040002822876
Validation loss: 2.10697133342425

Epoch: 5| Step: 2
Training loss: 1.5266587734222412
Validation loss: 2.1714557260274887

Epoch: 5| Step: 3
Training loss: 1.6767654418945312
Validation loss: 2.185996284087499

Epoch: 5| Step: 4
Training loss: 1.5590516328811646
Validation loss: 2.0482425143321357

Epoch: 5| Step: 5
Training loss: 1.1357136964797974
Validation loss: 2.172718584537506

Epoch: 5| Step: 6
Training loss: 1.0929648876190186
Validation loss: 2.1663067638874054

Epoch: 5| Step: 7
Training loss: 1.9190422296524048
Validation loss: 2.249027192592621

Epoch: 5| Step: 8
Training loss: 1.0828192234039307
Validation loss: 2.2128537197907767

Epoch: 5| Step: 9
Training loss: 1.2150944471359253
Validation loss: 2.104076941808065

Epoch: 5| Step: 10
Training loss: 1.6589305400848389
Validation loss: 2.149242401123047

Epoch: 5| Step: 11
Training loss: 3.25057315826416
Validation loss: 2.0705635646979013

Epoch: 89| Step: 0
Training loss: 1.421492576599121
Validation loss: 2.2113038698832193

Epoch: 5| Step: 1
Training loss: 1.2301239967346191
Validation loss: 2.248718778292338

Epoch: 5| Step: 2
Training loss: 2.1720805168151855
Validation loss: 2.077250118056933

Epoch: 5| Step: 3
Training loss: 1.7563397884368896
Validation loss: 2.099810933073362

Epoch: 5| Step: 4
Training loss: 1.7124478816986084
Validation loss: 2.165931910276413

Epoch: 5| Step: 5
Training loss: 1.5747814178466797
Validation loss: 2.2150650521119437

Epoch: 5| Step: 6
Training loss: 0.9514832496643066
Validation loss: 2.2004375010728836

Epoch: 5| Step: 7
Training loss: 1.3696092367172241
Validation loss: 2.201732342441877

Epoch: 5| Step: 8
Training loss: 1.8838790655136108
Validation loss: 2.1542077511548996

Epoch: 5| Step: 9
Training loss: 1.8122961521148682
Validation loss: 2.0456580271323523

Epoch: 5| Step: 10
Training loss: 1.0214815139770508
Validation loss: 2.195005163550377

Epoch: 5| Step: 11
Training loss: 0.6802394986152649
Validation loss: 2.130424569050471

Epoch: 90| Step: 0
Training loss: 1.6635888814926147
Validation loss: 2.0723090022802353

Epoch: 5| Step: 1
Training loss: 1.9529154300689697
Validation loss: 2.11078879237175

Epoch: 5| Step: 2
Training loss: 1.0764482021331787
Validation loss: 2.1858147581418357

Epoch: 5| Step: 3
Training loss: 1.9059569835662842
Validation loss: 2.1594902773698172

Epoch: 5| Step: 4
Training loss: 1.392507791519165
Validation loss: 2.1126773407061896

Epoch: 5| Step: 5
Training loss: 0.74174964427948
Validation loss: 2.156114339828491

Epoch: 5| Step: 6
Training loss: 1.475811243057251
Validation loss: 2.0436516205469766

Epoch: 5| Step: 7
Training loss: 1.5235788822174072
Validation loss: 2.1996434926986694

Epoch: 5| Step: 8
Training loss: 1.7058836221694946
Validation loss: 2.134934186935425

Epoch: 5| Step: 9
Training loss: 1.4532434940338135
Validation loss: 2.0543044805526733

Epoch: 5| Step: 10
Training loss: 1.3565620183944702
Validation loss: 2.10202419757843

Epoch: 5| Step: 11
Training loss: 0.8574795722961426
Validation loss: 2.1155099322398505

Epoch: 91| Step: 0
Training loss: 1.4513211250305176
Validation loss: 2.142376124858856

Epoch: 5| Step: 1
Training loss: 0.7773154973983765
Validation loss: 2.2271066109339395

Epoch: 5| Step: 2
Training loss: 1.7378170490264893
Validation loss: 2.1911835074424744

Epoch: 5| Step: 3
Training loss: 1.3648920059204102
Validation loss: 2.217596650123596

Epoch: 5| Step: 4
Training loss: 1.6203569173812866
Validation loss: 2.139324297507604

Epoch: 5| Step: 5
Training loss: 1.7567189931869507
Validation loss: 2.1934276819229126

Epoch: 5| Step: 6
Training loss: 1.8444011211395264
Validation loss: 2.3183930615584054

Epoch: 5| Step: 7
Training loss: 1.0821512937545776
Validation loss: 2.161428610483805

Epoch: 5| Step: 8
Training loss: 0.7880295515060425
Validation loss: 2.2204249799251556

Epoch: 5| Step: 9
Training loss: 2.1426913738250732
Validation loss: 2.168819174170494

Epoch: 5| Step: 10
Training loss: 1.639891266822815
Validation loss: 2.1051135460535684

Epoch: 5| Step: 11
Training loss: 2.7001209259033203
Validation loss: 2.2405433108409247

Epoch: 92| Step: 0
Training loss: 1.1609456539154053
Validation loss: 2.1630238642295203

Epoch: 5| Step: 1
Training loss: 1.1614869832992554
Validation loss: 2.0752896865208945

Epoch: 5| Step: 2
Training loss: 1.5569589138031006
Validation loss: 2.202157517274221

Epoch: 5| Step: 3
Training loss: 1.5785177946090698
Validation loss: 2.1937269965807595

Epoch: 5| Step: 4
Training loss: 1.3832519054412842
Validation loss: 2.2242926259835563

Epoch: 5| Step: 5
Training loss: 1.6036523580551147
Validation loss: 2.216459314028422

Epoch: 5| Step: 6
Training loss: 2.16837739944458
Validation loss: 2.209395637114843

Epoch: 5| Step: 7
Training loss: 1.8067047595977783
Validation loss: 2.1427722175916037

Epoch: 5| Step: 8
Training loss: 1.6363105773925781
Validation loss: 2.229430769880613

Epoch: 5| Step: 9
Training loss: 1.5711036920547485
Validation loss: 2.266648123661677

Epoch: 5| Step: 10
Training loss: 1.1092100143432617
Validation loss: 2.279446134964625

Epoch: 5| Step: 11
Training loss: 0.6245937347412109
Validation loss: 2.2066806058088937

Epoch: 93| Step: 0
Training loss: 1.4136605262756348
Validation loss: 2.197671815752983

Epoch: 5| Step: 1
Training loss: 1.1383663415908813
Validation loss: 2.211590602993965

Epoch: 5| Step: 2
Training loss: 1.2110892534255981
Validation loss: 2.230041027069092

Epoch: 5| Step: 3
Training loss: 2.2209019660949707
Validation loss: 2.191517010331154

Epoch: 5| Step: 4
Training loss: 1.7925535440444946
Validation loss: 2.1576939721902213

Epoch: 5| Step: 5
Training loss: 1.1791081428527832
Validation loss: 2.2651185592015586

Epoch: 5| Step: 6
Training loss: 1.6025731563568115
Validation loss: 2.165013998746872

Epoch: 5| Step: 7
Training loss: 0.9066932797431946
Validation loss: 2.2206152280171714

Epoch: 5| Step: 8
Training loss: 1.2147458791732788
Validation loss: 2.13700536886851

Epoch: 5| Step: 9
Training loss: 1.4171028137207031
Validation loss: 2.093384941418966

Epoch: 5| Step: 10
Training loss: 2.2378334999084473
Validation loss: 2.0691146651903787

Epoch: 5| Step: 11
Training loss: 1.9955464601516724
Validation loss: 2.173643479744593

Epoch: 94| Step: 0
Training loss: 1.261570930480957
Validation loss: 2.067951728900274

Epoch: 5| Step: 1
Training loss: 1.405448079109192
Validation loss: 2.120889032880465

Epoch: 5| Step: 2
Training loss: 1.7166221141815186
Validation loss: 2.1266425947348275

Epoch: 5| Step: 3
Training loss: 1.0078730583190918
Validation loss: 2.132467349370321

Epoch: 5| Step: 4
Training loss: 1.34011971950531
Validation loss: 2.1069422215223312

Epoch: 5| Step: 5
Training loss: 1.9621553421020508
Validation loss: 2.141619771718979

Epoch: 5| Step: 6
Training loss: 0.9801734089851379
Validation loss: 2.0683620870113373

Epoch: 5| Step: 7
Training loss: 1.1512380838394165
Validation loss: 2.054978385567665

Epoch: 5| Step: 8
Training loss: 1.6531398296356201
Validation loss: 2.165000041325887

Epoch: 5| Step: 9
Training loss: 1.418516755104065
Validation loss: 2.251395588119825

Epoch: 5| Step: 10
Training loss: 1.8412128686904907
Validation loss: 2.168295755982399

Epoch: 5| Step: 11
Training loss: 2.344817876815796
Validation loss: 2.1335006753603616

Epoch: 95| Step: 0
Training loss: 0.9957252740859985
Validation loss: 2.196882242957751

Epoch: 5| Step: 1
Training loss: 1.6722357273101807
Validation loss: 2.1555498093366623

Epoch: 5| Step: 2
Training loss: 1.6391617059707642
Validation loss: 2.1575751155614853

Epoch: 5| Step: 3
Training loss: 1.1937766075134277
Validation loss: 2.2335023979345956

Epoch: 5| Step: 4
Training loss: 2.1829867362976074
Validation loss: 2.155921717484792

Epoch: 5| Step: 5
Training loss: 1.3200105428695679
Validation loss: 2.0859639098246894

Epoch: 5| Step: 6
Training loss: 1.272890329360962
Validation loss: 2.2491348485151925

Epoch: 5| Step: 7
Training loss: 1.4471714496612549
Validation loss: 2.143494134147962

Epoch: 5| Step: 8
Training loss: 0.8493038415908813
Validation loss: 2.1544849425554276

Epoch: 5| Step: 9
Training loss: 1.450000524520874
Validation loss: 2.2691258688767753

Epoch: 5| Step: 10
Training loss: 1.782218337059021
Validation loss: 2.1502646009127298

Epoch: 5| Step: 11
Training loss: 2.440675735473633
Validation loss: 2.182243471344312

Epoch: 96| Step: 0
Training loss: 1.2773088216781616
Validation loss: 2.1963380624850593

Epoch: 5| Step: 1
Training loss: 1.4106271266937256
Validation loss: 2.204736828804016

Epoch: 5| Step: 2
Training loss: 1.0689009428024292
Validation loss: 2.156595140695572

Epoch: 5| Step: 3
Training loss: 1.275001883506775
Validation loss: 2.219704454143842

Epoch: 5| Step: 4
Training loss: 1.4303364753723145
Validation loss: 2.083961144089699

Epoch: 5| Step: 5
Training loss: 1.5308611392974854
Validation loss: 2.063644309838613

Epoch: 5| Step: 6
Training loss: 1.5091654062271118
Validation loss: 2.106576532125473

Epoch: 5| Step: 7
Training loss: 1.6904865503311157
Validation loss: 2.1626004427671432

Epoch: 5| Step: 8
Training loss: 1.623394250869751
Validation loss: 2.101600080728531

Epoch: 5| Step: 9
Training loss: 1.5534781217575073
Validation loss: 2.111099660396576

Epoch: 5| Step: 10
Training loss: 1.4856735467910767
Validation loss: 2.15072729686896

Epoch: 5| Step: 11
Training loss: 2.151198387145996
Validation loss: 2.1500708609819412

Epoch: 97| Step: 0
Training loss: 1.1638206243515015
Validation loss: 2.1405985206365585

Epoch: 5| Step: 1
Training loss: 1.5351073741912842
Validation loss: 2.2170650909344354

Epoch: 5| Step: 2
Training loss: 1.342840552330017
Validation loss: 2.175936828056971

Epoch: 5| Step: 3
Training loss: 1.3043159246444702
Validation loss: 2.1962975710630417

Epoch: 5| Step: 4
Training loss: 1.8582944869995117
Validation loss: 2.180518165230751

Epoch: 5| Step: 5
Training loss: 1.6243880987167358
Validation loss: 2.1770963072776794

Epoch: 5| Step: 6
Training loss: 1.2108179330825806
Validation loss: 2.216785177588463

Epoch: 5| Step: 7
Training loss: 1.6779676675796509
Validation loss: 2.0631776303052902

Epoch: 5| Step: 8
Training loss: 1.323819875717163
Validation loss: 2.144764333963394

Epoch: 5| Step: 9
Training loss: 1.4784237146377563
Validation loss: 2.1532045553127923

Epoch: 5| Step: 10
Training loss: 1.2679803371429443
Validation loss: 2.097169647614161

Epoch: 5| Step: 11
Training loss: 1.9961042404174805
Validation loss: 2.1878036161263785

Epoch: 98| Step: 0
Training loss: 1.8721479177474976
Validation loss: 2.2460920810699463

Epoch: 5| Step: 1
Training loss: 1.6311521530151367
Validation loss: 2.321407437324524

Epoch: 5| Step: 2
Training loss: 1.8641462326049805
Validation loss: 2.316212390859922

Epoch: 5| Step: 3
Training loss: 0.9658719897270203
Validation loss: 2.2186399549245834

Epoch: 5| Step: 4
Training loss: 1.6637003421783447
Validation loss: 2.1619502305984497

Epoch: 5| Step: 5
Training loss: 1.1203566789627075
Validation loss: 2.1686765402555466

Epoch: 5| Step: 6
Training loss: 1.8153871297836304
Validation loss: 2.1460300783316293

Epoch: 5| Step: 7
Training loss: 1.5895568132400513
Validation loss: 2.1589801907539368

Epoch: 5| Step: 8
Training loss: 1.4971786737442017
Validation loss: 2.1921713749567666

Epoch: 5| Step: 9
Training loss: 2.0215630531311035
Validation loss: 2.308051278193792

Epoch: 5| Step: 10
Training loss: 1.1557530164718628
Validation loss: 2.1396300345659256

Epoch: 5| Step: 11
Training loss: 1.4491863250732422
Validation loss: 2.0688004742066064

Epoch: 99| Step: 0
Training loss: 0.8907028436660767
Validation loss: 2.155955741802851

Epoch: 5| Step: 1
Training loss: 1.4233572483062744
Validation loss: 2.202740972240766

Epoch: 5| Step: 2
Training loss: 1.8353281021118164
Validation loss: 2.231607273221016

Epoch: 5| Step: 3
Training loss: 1.6546379327774048
Validation loss: 2.2441758612791696

Epoch: 5| Step: 4
Training loss: 1.4647159576416016
Validation loss: 2.188296968738238

Epoch: 5| Step: 5
Training loss: 1.4235212802886963
Validation loss: 2.0964881976445517

Epoch: 5| Step: 6
Training loss: 0.9849861264228821
Validation loss: 2.2255607346693673

Epoch: 5| Step: 7
Training loss: 1.4645864963531494
Validation loss: 2.1069524685541787

Epoch: 5| Step: 8
Training loss: 1.8006412982940674
Validation loss: 2.1351488480965295

Epoch: 5| Step: 9
Training loss: 1.2778642177581787
Validation loss: 2.0507610787947974

Epoch: 5| Step: 10
Training loss: 1.1311638355255127
Validation loss: 2.0768908162911734

Epoch: 5| Step: 11
Training loss: 2.3685555458068848
Validation loss: 2.068271358807882

Epoch: 100| Step: 0
Training loss: 1.6692603826522827
Validation loss: 2.1507708728313446

Epoch: 5| Step: 1
Training loss: 1.2845540046691895
Validation loss: 2.1929025252660117

Epoch: 5| Step: 2
Training loss: 1.6778167486190796
Validation loss: 2.15874811510245

Epoch: 5| Step: 3
Training loss: 1.5135911703109741
Validation loss: 2.199644242723783

Epoch: 5| Step: 4
Training loss: 1.10698664188385
Validation loss: 2.144890859723091

Epoch: 5| Step: 5
Training loss: 0.731958270072937
Validation loss: 2.1022247970104218

Epoch: 5| Step: 6
Training loss: 1.2814995050430298
Validation loss: 2.0975176244974136

Epoch: 5| Step: 7
Training loss: 1.459890604019165
Validation loss: 2.126934473713239

Epoch: 5| Step: 8
Training loss: 1.730682611465454
Validation loss: 2.2208162397146225

Epoch: 5| Step: 9
Training loss: 2.1826846599578857
Validation loss: 2.176766683657964

Epoch: 5| Step: 10
Training loss: 1.087924599647522
Validation loss: 2.0912640194098153

Epoch: 5| Step: 11
Training loss: 1.5821144580841064
Validation loss: 2.2451070745786033

Epoch: 101| Step: 0
Training loss: 1.9926416873931885
Validation loss: 2.068130056063334

Epoch: 5| Step: 1
Training loss: 1.1316289901733398
Validation loss: 2.0573604752620063

Epoch: 5| Step: 2
Training loss: 1.2020336389541626
Validation loss: 2.1327420522769294

Epoch: 5| Step: 3
Training loss: 1.5843617916107178
Validation loss: 2.0829021583000817

Epoch: 5| Step: 4
Training loss: 1.7367706298828125
Validation loss: 2.049666464328766

Epoch: 5| Step: 5
Training loss: 1.4814250469207764
Validation loss: 2.1808936347564063

Epoch: 5| Step: 6
Training loss: 1.3206775188446045
Validation loss: 2.1171180605888367

Epoch: 5| Step: 7
Training loss: 1.8347084522247314
Validation loss: 2.1672808875640235

Epoch: 5| Step: 8
Training loss: 1.8399925231933594
Validation loss: 2.138415848215421

Epoch: 5| Step: 9
Training loss: 1.148599624633789
Validation loss: 2.1741490165392556

Epoch: 5| Step: 10
Training loss: 1.1904886960983276
Validation loss: 2.1486791918675103

Epoch: 5| Step: 11
Training loss: 1.4232101440429688
Validation loss: 2.150388096769651

Epoch: 102| Step: 0
Training loss: 1.3551782369613647
Validation loss: 2.128666564822197

Epoch: 5| Step: 1
Training loss: 1.0487180948257446
Validation loss: 2.200701981782913

Epoch: 5| Step: 2
Training loss: 1.1710008382797241
Validation loss: 2.1362895170847573

Epoch: 5| Step: 3
Training loss: 1.9962427616119385
Validation loss: 2.1997770915428796

Epoch: 5| Step: 4
Training loss: 1.419132947921753
Validation loss: 2.1721796840429306

Epoch: 5| Step: 5
Training loss: 1.3449593782424927
Validation loss: 2.133325388034185

Epoch: 5| Step: 6
Training loss: 1.1136642694473267
Validation loss: 2.091477558016777

Epoch: 5| Step: 7
Training loss: 1.22700834274292
Validation loss: 2.044735699892044

Epoch: 5| Step: 8
Training loss: 1.6795371770858765
Validation loss: 2.143660123149554

Epoch: 5| Step: 9
Training loss: 1.4906648397445679
Validation loss: 2.05085418621699

Epoch: 5| Step: 10
Training loss: 1.1360044479370117
Validation loss: 2.1175641417503357

Epoch: 5| Step: 11
Training loss: 1.945814609527588
Validation loss: 2.1454177300135293

Epoch: 103| Step: 0
Training loss: 1.1119556427001953
Validation loss: 2.2811095118522644

Epoch: 5| Step: 1
Training loss: 1.406123399734497
Validation loss: 2.2605514377355576

Epoch: 5| Step: 2
Training loss: 1.541471242904663
Validation loss: 2.275255729754766

Epoch: 5| Step: 3
Training loss: 1.9504209756851196
Validation loss: 2.2601794600486755

Epoch: 5| Step: 4
Training loss: 1.2266395092010498
Validation loss: 2.2384376525878906

Epoch: 5| Step: 5
Training loss: 1.5579841136932373
Validation loss: 2.1072595665852227

Epoch: 5| Step: 6
Training loss: 1.079125165939331
Validation loss: 2.1530974706014

Epoch: 5| Step: 7
Training loss: 1.2808302640914917
Validation loss: 2.124452749888102

Epoch: 5| Step: 8
Training loss: 1.9308102130889893
Validation loss: 2.132534051934878

Epoch: 5| Step: 9
Training loss: 1.5531461238861084
Validation loss: 2.1423279146353402

Epoch: 5| Step: 10
Training loss: 1.8920118808746338
Validation loss: 2.1118841667970023

Epoch: 5| Step: 11
Training loss: 0.3840981125831604
Validation loss: 2.1704885959625244

Epoch: 104| Step: 0
Training loss: 1.975293755531311
Validation loss: 2.199024905761083

Epoch: 5| Step: 1
Training loss: 1.5904027223587036
Validation loss: 2.1643656392892203

Epoch: 5| Step: 2
Training loss: 1.073411226272583
Validation loss: 2.1550711691379547

Epoch: 5| Step: 3
Training loss: 1.7942882776260376
Validation loss: 2.2279039273659387

Epoch: 5| Step: 4
Training loss: 1.1840969324111938
Validation loss: 2.118497187892596

Epoch: 5| Step: 5
Training loss: 1.2035950422286987
Validation loss: 2.179539109269778

Epoch: 5| Step: 6
Training loss: 1.5292803049087524
Validation loss: 2.0976067582766214

Epoch: 5| Step: 7
Training loss: 1.5404936075210571
Validation loss: 2.135480230053266

Epoch: 5| Step: 8
Training loss: 1.0213552713394165
Validation loss: 2.085316985845566

Epoch: 5| Step: 9
Training loss: 1.2659649848937988
Validation loss: 2.1024044851462045

Epoch: 5| Step: 10
Training loss: 1.0661695003509521
Validation loss: 2.0548120687405267

Epoch: 5| Step: 11
Training loss: 1.3833372592926025
Validation loss: 2.0770529409249625

Epoch: 105| Step: 0
Training loss: 1.142301321029663
Validation loss: 2.0457986891269684

Epoch: 5| Step: 1
Training loss: 1.3840845823287964
Validation loss: 2.1025871286789575

Epoch: 5| Step: 2
Training loss: 1.6488044261932373
Validation loss: 2.1555496652921042

Epoch: 5| Step: 3
Training loss: 0.9010528326034546
Validation loss: 2.107968419790268

Epoch: 5| Step: 4
Training loss: 1.0079642534255981
Validation loss: 2.161734734972318

Epoch: 5| Step: 5
Training loss: 1.9809328317642212
Validation loss: 2.1609771102666855

Epoch: 5| Step: 6
Training loss: 1.5959484577178955
Validation loss: 2.0879463305075965

Epoch: 5| Step: 7
Training loss: 1.100856065750122
Validation loss: 2.1238161822160087

Epoch: 5| Step: 8
Training loss: 1.275596261024475
Validation loss: 2.2102795243263245

Epoch: 5| Step: 9
Training loss: 1.6097171306610107
Validation loss: 2.0975865175326667

Epoch: 5| Step: 10
Training loss: 1.7091076374053955
Validation loss: 2.1025595913330712

Epoch: 5| Step: 11
Training loss: 0.6097502708435059
Validation loss: 2.0943417996168137

Epoch: 106| Step: 0
Training loss: 1.534024953842163
Validation loss: 2.1284305651982627

Epoch: 5| Step: 1
Training loss: 1.347448706626892
Validation loss: 2.2172237982352576

Epoch: 5| Step: 2
Training loss: 1.4526160955429077
Validation loss: 2.226026659210523

Epoch: 5| Step: 3
Training loss: 1.007920503616333
Validation loss: 2.21915195385615

Epoch: 5| Step: 4
Training loss: 1.7187172174453735
Validation loss: 2.0479090213775635

Epoch: 5| Step: 5
Training loss: 1.6270811557769775
Validation loss: 2.17800564567248

Epoch: 5| Step: 6
Training loss: 1.6222789287567139
Validation loss: 2.115501970052719

Epoch: 5| Step: 7
Training loss: 1.5406696796417236
Validation loss: 2.1127840826908746

Epoch: 5| Step: 8
Training loss: 1.3868666887283325
Validation loss: 2.1133531828721366

Epoch: 5| Step: 9
Training loss: 1.7193739414215088
Validation loss: 2.148031105597814

Epoch: 5| Step: 10
Training loss: 1.011171579360962
Validation loss: 2.1363811045885086

Epoch: 5| Step: 11
Training loss: 1.004387378692627
Validation loss: 2.1014427840709686

Epoch: 107| Step: 0
Training loss: 1.1942329406738281
Validation loss: 2.077252765496572

Epoch: 5| Step: 1
Training loss: 1.7429304122924805
Validation loss: 2.056851680080096

Epoch: 5| Step: 2
Training loss: 1.1037994623184204
Validation loss: 2.0977929830551147

Epoch: 5| Step: 3
Training loss: 1.231471061706543
Validation loss: 2.141810600956281

Epoch: 5| Step: 4
Training loss: 1.0812263488769531
Validation loss: 2.20879557232062

Epoch: 5| Step: 5
Training loss: 1.277046799659729
Validation loss: 2.1568716963132224

Epoch: 5| Step: 6
Training loss: 1.533239722251892
Validation loss: 2.1170054276784263

Epoch: 5| Step: 7
Training loss: 1.3912465572357178
Validation loss: 2.060620203614235

Epoch: 5| Step: 8
Training loss: 1.241621732711792
Validation loss: 2.141367480158806

Epoch: 5| Step: 9
Training loss: 1.3206160068511963
Validation loss: 2.036297475298246

Epoch: 5| Step: 10
Training loss: 1.3774445056915283
Validation loss: 2.216795722643534

Epoch: 5| Step: 11
Training loss: 1.7009079456329346
Validation loss: 2.0892787724733353

Epoch: 108| Step: 0
Training loss: 1.6618465185165405
Validation loss: 2.1448869158824286

Epoch: 5| Step: 1
Training loss: 1.8304446935653687
Validation loss: 2.1075533827145896

Epoch: 5| Step: 2
Training loss: 1.268329381942749
Validation loss: 2.00655331214269

Epoch: 5| Step: 3
Training loss: 0.92803955078125
Validation loss: 2.2092971752087274

Epoch: 5| Step: 4
Training loss: 1.5361104011535645
Validation loss: 2.2145303388436637

Epoch: 5| Step: 5
Training loss: 0.8288829922676086
Validation loss: 2.1518345872561135

Epoch: 5| Step: 6
Training loss: 1.7545194625854492
Validation loss: 2.2916989078124366

Epoch: 5| Step: 7
Training loss: 1.087883710861206
Validation loss: 2.1821036636829376

Epoch: 5| Step: 8
Training loss: 1.4815162420272827
Validation loss: 2.065329894423485

Epoch: 5| Step: 9
Training loss: 1.276771903038025
Validation loss: 2.074317385752996

Epoch: 5| Step: 10
Training loss: 1.1158519983291626
Validation loss: 2.163425693909327

Epoch: 5| Step: 11
Training loss: 2.523191452026367
Validation loss: 2.1511764526367188

Epoch: 109| Step: 0
Training loss: 1.892748236656189
Validation loss: 2.298623353242874

Epoch: 5| Step: 1
Training loss: 1.9940303564071655
Validation loss: 2.360552350680033

Epoch: 5| Step: 2
Training loss: 2.2990882396698
Validation loss: 2.384441554546356

Epoch: 5| Step: 3
Training loss: 1.9388214349746704
Validation loss: 2.231742317477862

Epoch: 5| Step: 4
Training loss: 1.2308717966079712
Validation loss: 2.096415544549624

Epoch: 5| Step: 5
Training loss: 1.324630618095398
Validation loss: 2.126364971200625

Epoch: 5| Step: 6
Training loss: 1.0057423114776611
Validation loss: 2.214470108350118

Epoch: 5| Step: 7
Training loss: 1.4382569789886475
Validation loss: 2.209744075934092

Epoch: 5| Step: 8
Training loss: 1.0811134576797485
Validation loss: 2.300349920988083

Epoch: 5| Step: 9
Training loss: 1.4913833141326904
Validation loss: 2.355401630202929

Epoch: 5| Step: 10
Training loss: 1.3614559173583984
Validation loss: 2.285992761452993

Epoch: 5| Step: 11
Training loss: 1.7406283617019653
Validation loss: 2.2408788402875266

Epoch: 110| Step: 0
Training loss: 1.0100752115249634
Validation loss: 2.1112522184848785

Epoch: 5| Step: 1
Training loss: 1.4494349956512451
Validation loss: 2.117184335986773

Epoch: 5| Step: 2
Training loss: 1.6934436559677124
Validation loss: 2.2207688689231873

Epoch: 5| Step: 3
Training loss: 1.4204702377319336
Validation loss: 2.2153034110864005

Epoch: 5| Step: 4
Training loss: 1.9902160167694092
Validation loss: 2.2916287978490195

Epoch: 5| Step: 5
Training loss: 1.626660704612732
Validation loss: 2.1600560198227563

Epoch: 5| Step: 6
Training loss: 1.5656942129135132
Validation loss: 2.154724210500717

Epoch: 5| Step: 7
Training loss: 1.0813853740692139
Validation loss: 2.123453219731649

Epoch: 5| Step: 8
Training loss: 1.195094108581543
Validation loss: 2.097863271832466

Epoch: 5| Step: 9
Training loss: 2.3223440647125244
Validation loss: 2.115204945206642

Epoch: 5| Step: 10
Training loss: 0.8025447130203247
Validation loss: 2.176644335190455

Epoch: 5| Step: 11
Training loss: 1.1436409950256348
Validation loss: 2.1633603970209756

Epoch: 111| Step: 0
Training loss: 1.8425203561782837
Validation loss: 2.1665593336025872

Epoch: 5| Step: 1
Training loss: 1.5382046699523926
Validation loss: 2.214870090285937

Epoch: 5| Step: 2
Training loss: 1.3900195360183716
Validation loss: 2.24138813217481

Epoch: 5| Step: 3
Training loss: 1.3054113388061523
Validation loss: 2.1733613510926566

Epoch: 5| Step: 4
Training loss: 1.2958238124847412
Validation loss: 2.1724631935358047

Epoch: 5| Step: 5
Training loss: 0.9202313423156738
Validation loss: 2.155204559365908

Epoch: 5| Step: 6
Training loss: 1.0259768962860107
Validation loss: 2.1080101132392883

Epoch: 5| Step: 7
Training loss: 1.4037784337997437
Validation loss: 2.102850705385208

Epoch: 5| Step: 8
Training loss: 1.3597955703735352
Validation loss: 2.225837786992391

Epoch: 5| Step: 9
Training loss: 1.6673431396484375
Validation loss: 2.126453494032224

Epoch: 5| Step: 10
Training loss: 1.2429466247558594
Validation loss: 2.2096623380978904

Epoch: 5| Step: 11
Training loss: 1.8091415166854858
Validation loss: 2.128239577015241

Epoch: 112| Step: 0
Training loss: 1.1115942001342773
Validation loss: 2.175835038224856

Epoch: 5| Step: 1
Training loss: 1.8218352794647217
Validation loss: 2.2109918196996055

Epoch: 5| Step: 2
Training loss: 0.8683754801750183
Validation loss: 2.1742489834626517

Epoch: 5| Step: 3
Training loss: 0.9252606630325317
Validation loss: 2.13212543229262

Epoch: 5| Step: 4
Training loss: 1.2411617040634155
Validation loss: 2.116888771454493

Epoch: 5| Step: 5
Training loss: 1.711686372756958
Validation loss: 2.177776242295901

Epoch: 5| Step: 6
Training loss: 0.9386430978775024
Validation loss: 2.113889361421267

Epoch: 5| Step: 7
Training loss: 1.570730209350586
Validation loss: 2.150860791405042

Epoch: 5| Step: 8
Training loss: 1.2475178241729736
Validation loss: 2.2867813209692636

Epoch: 5| Step: 9
Training loss: 1.4921385049819946
Validation loss: 2.2629553576310477

Epoch: 5| Step: 10
Training loss: 1.6946830749511719
Validation loss: 2.102141559123993

Epoch: 5| Step: 11
Training loss: 0.9748721122741699
Validation loss: 2.129388451576233

Epoch: 113| Step: 0
Training loss: 2.1932613849639893
Validation loss: 2.094900836547216

Epoch: 5| Step: 1
Training loss: 1.2555903196334839
Validation loss: 2.058937286337217

Epoch: 5| Step: 2
Training loss: 1.0144392251968384
Validation loss: 2.0987510979175568

Epoch: 5| Step: 3
Training loss: 1.1027694940567017
Validation loss: 2.1313537061214447

Epoch: 5| Step: 4
Training loss: 1.4855338335037231
Validation loss: 2.118629664182663

Epoch: 5| Step: 5
Training loss: 1.7927277088165283
Validation loss: 2.12889763712883

Epoch: 5| Step: 6
Training loss: 1.1182730197906494
Validation loss: 2.1170392582813897

Epoch: 5| Step: 7
Training loss: 1.3996816873550415
Validation loss: 2.1292891105016074

Epoch: 5| Step: 8
Training loss: 1.3559980392456055
Validation loss: 2.135261982679367

Epoch: 5| Step: 9
Training loss: 1.2824082374572754
Validation loss: 2.1286390821139016

Epoch: 5| Step: 10
Training loss: 0.7259065508842468
Validation loss: 2.1571664164463678

Epoch: 5| Step: 11
Training loss: 1.9696508646011353
Validation loss: 2.1587151090304055

Epoch: 114| Step: 0
Training loss: 1.0820671319961548
Validation loss: 2.1271019130945206

Epoch: 5| Step: 1
Training loss: 1.2476794719696045
Validation loss: 2.1696568032105765

Epoch: 5| Step: 2
Training loss: 1.2461003065109253
Validation loss: 2.0699218958616257

Epoch: 5| Step: 3
Training loss: 1.128217101097107
Validation loss: 2.1209121644496918

Epoch: 5| Step: 4
Training loss: 1.1244170665740967
Validation loss: 2.1534982870022454

Epoch: 5| Step: 5
Training loss: 1.0087058544158936
Validation loss: 2.1638196110725403

Epoch: 5| Step: 6
Training loss: 1.6527154445648193
Validation loss: 2.138570169607798

Epoch: 5| Step: 7
Training loss: 1.0876719951629639
Validation loss: 2.173744151989619

Epoch: 5| Step: 8
Training loss: 1.4889944791793823
Validation loss: 2.1784645120302835

Epoch: 5| Step: 9
Training loss: 1.6154747009277344
Validation loss: 2.1632373680671058

Epoch: 5| Step: 10
Training loss: 1.295087218284607
Validation loss: 2.210949639479319

Epoch: 5| Step: 11
Training loss: 1.0881235599517822
Validation loss: 2.243598073720932

Epoch: 115| Step: 0
Training loss: 1.5229864120483398
Validation loss: 2.1681986898183823

Epoch: 5| Step: 1
Training loss: 0.8547667264938354
Validation loss: 2.2454912066459656

Epoch: 5| Step: 2
Training loss: 1.7175967693328857
Validation loss: 2.1328794260819754

Epoch: 5| Step: 3
Training loss: 1.2080729007720947
Validation loss: 2.1165078630050025

Epoch: 5| Step: 4
Training loss: 1.057565450668335
Validation loss: 2.1101092795530954

Epoch: 5| Step: 5
Training loss: 1.3979440927505493
Validation loss: 2.1603281994660697

Epoch: 5| Step: 6
Training loss: 1.831178903579712
Validation loss: 2.2228695452213287

Epoch: 5| Step: 7
Training loss: 1.1612675189971924
Validation loss: 2.1384322742621102

Epoch: 5| Step: 8
Training loss: 1.129326581954956
Validation loss: 2.157300442457199

Epoch: 5| Step: 9
Training loss: 1.277527093887329
Validation loss: 2.161947871247927

Epoch: 5| Step: 10
Training loss: 1.1452231407165527
Validation loss: 2.2655391494433084

Epoch: 5| Step: 11
Training loss: 0.7913857698440552
Validation loss: 2.201152811447779

Epoch: 116| Step: 0
Training loss: 1.5654001235961914
Validation loss: 2.218283091982206

Epoch: 5| Step: 1
Training loss: 1.329413652420044
Validation loss: 2.171746551990509

Epoch: 5| Step: 2
Training loss: 1.3246992826461792
Validation loss: 2.142617409427961

Epoch: 5| Step: 3
Training loss: 1.5686323642730713
Validation loss: 2.149118329087893

Epoch: 5| Step: 4
Training loss: 1.3060829639434814
Validation loss: 2.147848645846049

Epoch: 5| Step: 5
Training loss: 1.0214813947677612
Validation loss: 2.1726868798335395

Epoch: 5| Step: 6
Training loss: 1.6168521642684937
Validation loss: 2.109333579738935

Epoch: 5| Step: 7
Training loss: 1.1747783422470093
Validation loss: 2.211690276861191

Epoch: 5| Step: 8
Training loss: 1.1918060779571533
Validation loss: 2.1022986620664597

Epoch: 5| Step: 9
Training loss: 1.0378081798553467
Validation loss: 2.2077833662430444

Epoch: 5| Step: 10
Training loss: 1.1267818212509155
Validation loss: 2.239197254180908

Epoch: 5| Step: 11
Training loss: 0.38312840461730957
Validation loss: 2.284965087970098

Epoch: 117| Step: 0
Training loss: 1.6579803228378296
Validation loss: 2.146493931611379

Epoch: 5| Step: 1
Training loss: 1.765068769454956
Validation loss: 2.2575999349355698

Epoch: 5| Step: 2
Training loss: 0.9870039224624634
Validation loss: 2.2104783256848655

Epoch: 5| Step: 3
Training loss: 1.3449194431304932
Validation loss: 2.2545200188954673

Epoch: 5| Step: 4
Training loss: 1.2466458082199097
Validation loss: 2.1894180377324424

Epoch: 5| Step: 5
Training loss: 1.3301645517349243
Validation loss: 2.1811430901288986

Epoch: 5| Step: 6
Training loss: 0.7212277054786682
Validation loss: 2.230648304025332

Epoch: 5| Step: 7
Training loss: 1.5818270444869995
Validation loss: 2.1254443923632302

Epoch: 5| Step: 8
Training loss: 1.4290592670440674
Validation loss: 2.189854015906652

Epoch: 5| Step: 9
Training loss: 0.8964599370956421
Validation loss: 2.2696680972973504

Epoch: 5| Step: 10
Training loss: 1.2528778314590454
Validation loss: 2.281089181701342

Epoch: 5| Step: 11
Training loss: 1.2372901439666748
Validation loss: 2.268806129693985

Epoch: 118| Step: 0
Training loss: 0.8278277516365051
Validation loss: 2.2798072596391044

Epoch: 5| Step: 1
Training loss: 1.470726728439331
Validation loss: 2.1943224569161734

Epoch: 5| Step: 2
Training loss: 1.5540649890899658
Validation loss: 2.25275157392025

Epoch: 5| Step: 3
Training loss: 1.02753746509552
Validation loss: 2.2230462531248727

Epoch: 5| Step: 4
Training loss: 1.333664059638977
Validation loss: 2.172550678253174

Epoch: 5| Step: 5
Training loss: 1.2238730192184448
Validation loss: 2.218307852745056

Epoch: 5| Step: 6
Training loss: 1.2988674640655518
Validation loss: 2.1963071525096893

Epoch: 5| Step: 7
Training loss: 1.313204050064087
Validation loss: 2.246161868174871

Epoch: 5| Step: 8
Training loss: 1.278139591217041
Validation loss: 2.149007886648178

Epoch: 5| Step: 9
Training loss: 1.2198854684829712
Validation loss: 2.243575766682625

Epoch: 5| Step: 10
Training loss: 1.2659401893615723
Validation loss: 2.1462445656458535

Epoch: 5| Step: 11
Training loss: 1.934830665588379
Validation loss: 2.1896212299664817

Epoch: 119| Step: 0
Training loss: 0.9648066759109497
Validation loss: 2.174589514732361

Epoch: 5| Step: 1
Training loss: 1.3478195667266846
Validation loss: 2.123158633708954

Epoch: 5| Step: 2
Training loss: 1.2211819887161255
Validation loss: 2.1294975330432258

Epoch: 5| Step: 3
Training loss: 1.4051225185394287
Validation loss: 2.0883539567391076

Epoch: 5| Step: 4
Training loss: 1.4955885410308838
Validation loss: 2.161844660838445

Epoch: 5| Step: 5
Training loss: 1.1970469951629639
Validation loss: 2.221361060937246

Epoch: 5| Step: 6
Training loss: 1.1757056713104248
Validation loss: 2.1699057618776956

Epoch: 5| Step: 7
Training loss: 1.053781509399414
Validation loss: 2.220128188530604

Epoch: 5| Step: 8
Training loss: 1.2184709310531616
Validation loss: 2.200405389070511

Epoch: 5| Step: 9
Training loss: 1.3068631887435913
Validation loss: 2.0857100784778595

Epoch: 5| Step: 10
Training loss: 1.3564447164535522
Validation loss: 2.220328003168106

Epoch: 5| Step: 11
Training loss: 0.9575847387313843
Validation loss: 2.120903084675471

Epoch: 120| Step: 0
Training loss: 1.0823023319244385
Validation loss: 2.211401934425036

Epoch: 5| Step: 1
Training loss: 1.0678287744522095
Validation loss: 2.1706888526678085

Epoch: 5| Step: 2
Training loss: 1.3381446599960327
Validation loss: 2.213077738881111

Epoch: 5| Step: 3
Training loss: 1.4503545761108398
Validation loss: 2.1813583274682364

Epoch: 5| Step: 4
Training loss: 1.4683525562286377
Validation loss: 2.1357061664263406

Epoch: 5| Step: 5
Training loss: 1.835995078086853
Validation loss: 2.2106529076894126

Epoch: 5| Step: 6
Training loss: 0.9035570025444031
Validation loss: 2.195112486680349

Epoch: 5| Step: 7
Training loss: 0.7769595980644226
Validation loss: 2.1529783457517624

Epoch: 5| Step: 8
Training loss: 1.1667070388793945
Validation loss: 2.175359472632408

Epoch: 5| Step: 9
Training loss: 0.9341861009597778
Validation loss: 2.151200776298841

Epoch: 5| Step: 10
Training loss: 1.6931114196777344
Validation loss: 2.1624084413051605

Epoch: 5| Step: 11
Training loss: 0.8867793083190918
Validation loss: 2.1186610807975135

Epoch: 121| Step: 0
Training loss: 1.5190542936325073
Validation loss: 2.0700011253356934

Epoch: 5| Step: 1
Training loss: 0.8100675344467163
Validation loss: 2.2057264198859534

Epoch: 5| Step: 2
Training loss: 0.9882470965385437
Validation loss: 2.1167170057694116

Epoch: 5| Step: 3
Training loss: 1.4187819957733154
Validation loss: 2.1858132680257163

Epoch: 5| Step: 4
Training loss: 1.1615111827850342
Validation loss: 2.0724916011095047

Epoch: 5| Step: 5
Training loss: 1.5194110870361328
Validation loss: 2.1686536371707916

Epoch: 5| Step: 6
Training loss: 0.8694078326225281
Validation loss: 2.060976520180702

Epoch: 5| Step: 7
Training loss: 1.7987432479858398
Validation loss: 2.239252433180809

Epoch: 5| Step: 8
Training loss: 1.4570255279541016
Validation loss: 2.1979745626449585

Epoch: 5| Step: 9
Training loss: 1.0923362970352173
Validation loss: 2.091883177558581

Epoch: 5| Step: 10
Training loss: 1.3192572593688965
Validation loss: 2.2135237207015357

Epoch: 5| Step: 11
Training loss: 1.5448764562606812
Validation loss: 2.279454534252485

Epoch: 122| Step: 0
Training loss: 0.6304022669792175
Validation loss: 2.088364044825236

Epoch: 5| Step: 1
Training loss: 1.536977767944336
Validation loss: 2.123581046859423

Epoch: 5| Step: 2
Training loss: 1.3234045505523682
Validation loss: 2.1507258216540017

Epoch: 5| Step: 3
Training loss: 1.6117470264434814
Validation loss: 2.0664246579011283

Epoch: 5| Step: 4
Training loss: 1.1670262813568115
Validation loss: 2.1337872743606567

Epoch: 5| Step: 5
Training loss: 0.7509934306144714
Validation loss: 2.1075439353783927

Epoch: 5| Step: 6
Training loss: 1.1307698488235474
Validation loss: 2.2789912720521293

Epoch: 5| Step: 7
Training loss: 1.6761795282363892
Validation loss: 2.2304444015026093

Epoch: 5| Step: 8
Training loss: 1.2168104648590088
Validation loss: 2.2246832251548767

Epoch: 5| Step: 9
Training loss: 1.0964562892913818
Validation loss: 2.100810428460439

Epoch: 5| Step: 10
Training loss: 1.7912219762802124
Validation loss: 2.146073962251345

Epoch: 5| Step: 11
Training loss: 1.0066661834716797
Validation loss: 2.0769988944133124

Epoch: 123| Step: 0
Training loss: 1.393648624420166
Validation loss: 2.2066149612267814

Epoch: 5| Step: 1
Training loss: 1.1815134286880493
Validation loss: 2.0812164594729743

Epoch: 5| Step: 2
Training loss: 1.0243418216705322
Validation loss: 2.153453936179479

Epoch: 5| Step: 3
Training loss: 1.4069840908050537
Validation loss: 2.1007726987202964

Epoch: 5| Step: 4
Training loss: 0.6688283681869507
Validation loss: 2.2354010393222175

Epoch: 5| Step: 5
Training loss: 1.3371269702911377
Validation loss: 2.1363798479239144

Epoch: 5| Step: 6
Training loss: 1.4284794330596924
Validation loss: 2.2396120677391687

Epoch: 5| Step: 7
Training loss: 1.156172752380371
Validation loss: 2.230417857567469

Epoch: 5| Step: 8
Training loss: 1.326313853263855
Validation loss: 2.176239162683487

Epoch: 5| Step: 9
Training loss: 1.9279870986938477
Validation loss: 2.2186284412940345

Epoch: 5| Step: 10
Training loss: 1.2993284463882446
Validation loss: 2.1407285978396735

Epoch: 5| Step: 11
Training loss: 1.0062904357910156
Validation loss: 2.1480337580045066

Epoch: 124| Step: 0
Training loss: 1.9711382389068604
Validation loss: 2.1588140378395715

Epoch: 5| Step: 1
Training loss: 1.6104787588119507
Validation loss: 2.2431071996688843

Epoch: 5| Step: 2
Training loss: 1.7614786624908447
Validation loss: 2.190196067094803

Epoch: 5| Step: 3
Training loss: 1.8305599689483643
Validation loss: 2.177117774883906

Epoch: 5| Step: 4
Training loss: 1.7351948022842407
Validation loss: 2.050323118766149

Epoch: 5| Step: 5
Training loss: 0.8526426553726196
Validation loss: 2.2053362230459848

Epoch: 5| Step: 6
Training loss: 1.0396695137023926
Validation loss: 2.2857800722122192

Epoch: 5| Step: 7
Training loss: 1.0364797115325928
Validation loss: 2.2426913380622864

Epoch: 5| Step: 8
Training loss: 1.5391730070114136
Validation loss: 2.338167816400528

Epoch: 5| Step: 9
Training loss: 1.7346677780151367
Validation loss: 2.3170222491025925

Epoch: 5| Step: 10
Training loss: 1.3329582214355469
Validation loss: 2.218697855869929

Epoch: 5| Step: 11
Training loss: 1.166090488433838
Validation loss: 2.137805466850599

Epoch: 125| Step: 0
Training loss: 1.1963245868682861
Validation loss: 2.115438466270765

Epoch: 5| Step: 1
Training loss: 1.5921143293380737
Validation loss: 2.086265424887339

Epoch: 5| Step: 2
Training loss: 1.8557687997817993
Validation loss: 2.3694457709789276

Epoch: 5| Step: 3
Training loss: 1.9006016254425049
Validation loss: 2.3404784947633743

Epoch: 5| Step: 4
Training loss: 2.083315372467041
Validation loss: 2.297337517142296

Epoch: 5| Step: 5
Training loss: 1.746219277381897
Validation loss: 2.255438730120659

Epoch: 5| Step: 6
Training loss: 1.2793171405792236
Validation loss: 2.164083609978358

Epoch: 5| Step: 7
Training loss: 1.745792031288147
Validation loss: 2.115552539626757

Epoch: 5| Step: 8
Training loss: 1.1711952686309814
Validation loss: 2.249449700117111

Epoch: 5| Step: 9
Training loss: 1.1224288940429688
Validation loss: 2.2902221977710724

Epoch: 5| Step: 10
Training loss: 1.1659351587295532
Validation loss: 2.3667820741732917

Epoch: 5| Step: 11
Training loss: 2.3288967609405518
Validation loss: 2.2702695727348328

Epoch: 126| Step: 0
Training loss: 1.315015196800232
Validation loss: 2.15495158235232

Epoch: 5| Step: 1
Training loss: 2.0035653114318848
Validation loss: 2.1929967800776162

Epoch: 5| Step: 2
Training loss: 0.9451162219047546
Validation loss: 2.1347109576066337

Epoch: 5| Step: 3
Training loss: 1.6075255870819092
Validation loss: 2.0919686953226724

Epoch: 5| Step: 4
Training loss: 1.5247114896774292
Validation loss: 2.04581385354201

Epoch: 5| Step: 5
Training loss: 1.524099349975586
Validation loss: 2.135068878531456

Epoch: 5| Step: 6
Training loss: 1.0789177417755127
Validation loss: 2.136112466454506

Epoch: 5| Step: 7
Training loss: 1.2350263595581055
Validation loss: 2.1188012063503265

Epoch: 5| Step: 8
Training loss: 1.1298187971115112
Validation loss: 2.0662499219179153

Epoch: 5| Step: 9
Training loss: 1.2323448657989502
Validation loss: 2.1220830380916595

Epoch: 5| Step: 10
Training loss: 1.2624248266220093
Validation loss: 2.1096068074305854

Epoch: 5| Step: 11
Training loss: 1.2180373668670654
Validation loss: 2.234029144048691

Epoch: 127| Step: 0
Training loss: 1.3105332851409912
Validation loss: 2.1591094583272934

Epoch: 5| Step: 1
Training loss: 1.0798041820526123
Validation loss: 2.1310083915789924

Epoch: 5| Step: 2
Training loss: 1.7933597564697266
Validation loss: 2.113713433345159

Epoch: 5| Step: 3
Training loss: 1.3912041187286377
Validation loss: 2.1653109192848206

Epoch: 5| Step: 4
Training loss: 1.2709203958511353
Validation loss: 2.0424589018026986

Epoch: 5| Step: 5
Training loss: 1.1862115859985352
Validation loss: 2.1426574985186257

Epoch: 5| Step: 6
Training loss: 0.9744844436645508
Validation loss: 2.186216582854589

Epoch: 5| Step: 7
Training loss: 1.30923330783844
Validation loss: 2.072170610229174

Epoch: 5| Step: 8
Training loss: 0.9503015279769897
Validation loss: 2.144015441338221

Epoch: 5| Step: 9
Training loss: 1.0839048624038696
Validation loss: 2.0730555107196174

Epoch: 5| Step: 10
Training loss: 0.888459324836731
Validation loss: 2.144857948025068

Epoch: 5| Step: 11
Training loss: 1.3273028135299683
Validation loss: 2.1078014771143594

Epoch: 128| Step: 0
Training loss: 1.425594687461853
Validation loss: 2.0912539760271707

Epoch: 5| Step: 1
Training loss: 1.17275869846344
Validation loss: 2.0682596365610757

Epoch: 5| Step: 2
Training loss: 0.8854435682296753
Validation loss: 2.1490947802861533

Epoch: 5| Step: 3
Training loss: 1.5393733978271484
Validation loss: 2.164254665374756

Epoch: 5| Step: 4
Training loss: 1.5353342294692993
Validation loss: 2.186545501152674

Epoch: 5| Step: 5
Training loss: 1.1076349020004272
Validation loss: 2.1880182375510535

Epoch: 5| Step: 6
Training loss: 1.285480260848999
Validation loss: 2.171047722299894

Epoch: 5| Step: 7
Training loss: 0.9639380574226379
Validation loss: 2.175050064921379

Epoch: 5| Step: 8
Training loss: 1.1158030033111572
Validation loss: 2.1890858858823776

Epoch: 5| Step: 9
Training loss: 0.9874991178512573
Validation loss: 2.058866411447525

Epoch: 5| Step: 10
Training loss: 1.4902496337890625
Validation loss: 2.126883347829183

Epoch: 5| Step: 11
Training loss: 0.5033233165740967
Validation loss: 2.1186202665170035

Epoch: 129| Step: 0
Training loss: 1.0834341049194336
Validation loss: 2.183425545692444

Epoch: 5| Step: 1
Training loss: 0.8871235847473145
Validation loss: 2.088416506846746

Epoch: 5| Step: 2
Training loss: 0.9396036863327026
Validation loss: 2.147411863009135

Epoch: 5| Step: 3
Training loss: 1.052422285079956
Validation loss: 2.085259427626928

Epoch: 5| Step: 4
Training loss: 1.2804938554763794
Validation loss: 2.2174504498640695

Epoch: 5| Step: 5
Training loss: 1.448344349861145
Validation loss: 2.0953567028045654

Epoch: 5| Step: 6
Training loss: 1.2031893730163574
Validation loss: 2.139563192923864

Epoch: 5| Step: 7
Training loss: 1.470361351966858
Validation loss: 2.155976116657257

Epoch: 5| Step: 8
Training loss: 1.3441059589385986
Validation loss: 2.1131238540013633

Epoch: 5| Step: 9
Training loss: 1.221239686012268
Validation loss: 2.097415789961815

Epoch: 5| Step: 10
Training loss: 1.2068992853164673
Validation loss: 2.189010734359423

Epoch: 5| Step: 11
Training loss: 1.2617731094360352
Validation loss: 2.194382607936859

Epoch: 130| Step: 0
Training loss: 1.1176316738128662
Validation loss: 2.2193414519230523

Epoch: 5| Step: 1
Training loss: 1.5097391605377197
Validation loss: 2.235754281282425

Epoch: 5| Step: 2
Training loss: 0.9991732835769653
Validation loss: 2.1769680877526603

Epoch: 5| Step: 3
Training loss: 0.9741405248641968
Validation loss: 2.2113620787858963

Epoch: 5| Step: 4
Training loss: 1.0281236171722412
Validation loss: 2.056683291991552

Epoch: 5| Step: 5
Training loss: 1.1435140371322632
Validation loss: 2.119110385576884

Epoch: 5| Step: 6
Training loss: 1.0427074432373047
Validation loss: 2.128829518953959

Epoch: 5| Step: 7
Training loss: 1.112630844116211
Validation loss: 2.0829046914974847

Epoch: 5| Step: 8
Training loss: 1.487486720085144
Validation loss: 2.15669580300649

Epoch: 5| Step: 9
Training loss: 1.3177987337112427
Validation loss: 2.1776463637749353

Epoch: 5| Step: 10
Training loss: 1.3291575908660889
Validation loss: 2.0885999351739883

Epoch: 5| Step: 11
Training loss: 0.555578351020813
Validation loss: 2.214716841777166

Epoch: 131| Step: 0
Training loss: 1.0531407594680786
Validation loss: 2.2403161575396857

Epoch: 5| Step: 1
Training loss: 1.614384651184082
Validation loss: 2.2348208328088126

Epoch: 5| Step: 2
Training loss: 1.3181664943695068
Validation loss: 2.349522809187571

Epoch: 5| Step: 3
Training loss: 1.0636427402496338
Validation loss: 2.1509584486484528

Epoch: 5| Step: 4
Training loss: 1.4098566770553589
Validation loss: 2.160755713780721

Epoch: 5| Step: 5
Training loss: 1.1397600173950195
Validation loss: 2.0586349815130234

Epoch: 5| Step: 6
Training loss: 1.0565801858901978
Validation loss: 2.075240045785904

Epoch: 5| Step: 7
Training loss: 1.1659818887710571
Validation loss: 2.1677677432696023

Epoch: 5| Step: 8
Training loss: 0.9940625429153442
Validation loss: 2.0536851286888123

Epoch: 5| Step: 9
Training loss: 1.3698604106903076
Validation loss: 2.135891596476237

Epoch: 5| Step: 10
Training loss: 0.9102482795715332
Validation loss: 2.0752667039632797

Epoch: 5| Step: 11
Training loss: 1.0072182416915894
Validation loss: 2.1721164931853614

Epoch: 132| Step: 0
Training loss: 1.054048776626587
Validation loss: 2.1578877568244934

Epoch: 5| Step: 1
Training loss: 1.57285737991333
Validation loss: 2.119150588909785

Epoch: 5| Step: 2
Training loss: 1.3014875650405884
Validation loss: 2.119735926389694

Epoch: 5| Step: 3
Training loss: 1.1672427654266357
Validation loss: 2.059696242213249

Epoch: 5| Step: 4
Training loss: 1.429360270500183
Validation loss: 2.176036794980367

Epoch: 5| Step: 5
Training loss: 1.1557471752166748
Validation loss: 2.1028081526358924

Epoch: 5| Step: 6
Training loss: 1.0228480100631714
Validation loss: 2.228423555692037

Epoch: 5| Step: 7
Training loss: 1.0692460536956787
Validation loss: 2.1914374629656472

Epoch: 5| Step: 8
Training loss: 1.203661561012268
Validation loss: 2.063227131962776

Epoch: 5| Step: 9
Training loss: 0.6988690495491028
Validation loss: 2.205479939778646

Epoch: 5| Step: 10
Training loss: 0.9814580082893372
Validation loss: 2.204177295168241

Epoch: 5| Step: 11
Training loss: 2.117265462875366
Validation loss: 2.2745266060034433

Epoch: 133| Step: 0
Training loss: 1.386273980140686
Validation loss: 2.1025713284810386

Epoch: 5| Step: 1
Training loss: 1.1934891939163208
Validation loss: 2.1171540021896362

Epoch: 5| Step: 2
Training loss: 1.0175549983978271
Validation loss: 2.0654667615890503

Epoch: 5| Step: 3
Training loss: 0.6329662799835205
Validation loss: 2.1017237355311713

Epoch: 5| Step: 4
Training loss: 0.9595052599906921
Validation loss: 2.0687482804059982

Epoch: 5| Step: 5
Training loss: 1.493093729019165
Validation loss: 2.114509070912997

Epoch: 5| Step: 6
Training loss: 1.6775083541870117
Validation loss: 2.1929320196310678

Epoch: 5| Step: 7
Training loss: 0.9403591156005859
Validation loss: 2.1384095400571823

Epoch: 5| Step: 8
Training loss: 1.305988073348999
Validation loss: 2.1894438713788986

Epoch: 5| Step: 9
Training loss: 1.2790371179580688
Validation loss: 2.2748415221770606

Epoch: 5| Step: 10
Training loss: 0.8867025375366211
Validation loss: 2.1948039333025613

Epoch: 5| Step: 11
Training loss: 0.3465985059738159
Validation loss: 2.2138314048449197

Epoch: 134| Step: 0
Training loss: 0.9887251853942871
Validation loss: 2.2199882119894028

Epoch: 5| Step: 1
Training loss: 1.058885931968689
Validation loss: 2.2274267077445984

Epoch: 5| Step: 2
Training loss: 1.0605214834213257
Validation loss: 2.168082113067309

Epoch: 5| Step: 3
Training loss: 1.214172124862671
Validation loss: 2.2014658550421395

Epoch: 5| Step: 4
Training loss: 1.3113527297973633
Validation loss: 2.1617594162623086

Epoch: 5| Step: 5
Training loss: 1.1989595890045166
Validation loss: 2.2006474832693734

Epoch: 5| Step: 6
Training loss: 1.2761881351470947
Validation loss: 2.1471476405858994

Epoch: 5| Step: 7
Training loss: 0.8976006507873535
Validation loss: 2.148688788215319

Epoch: 5| Step: 8
Training loss: 0.9650871157646179
Validation loss: 2.1545057594776154

Epoch: 5| Step: 9
Training loss: 1.0604634284973145
Validation loss: 2.1417094618082047

Epoch: 5| Step: 10
Training loss: 1.4591058492660522
Validation loss: 2.1093123853206635

Epoch: 5| Step: 11
Training loss: 0.6330506801605225
Validation loss: 2.176757261157036

Epoch: 135| Step: 0
Training loss: 0.9536210298538208
Validation loss: 2.1674761374791465

Epoch: 5| Step: 1
Training loss: 1.094002366065979
Validation loss: 2.203527480363846

Epoch: 5| Step: 2
Training loss: 1.4131559133529663
Validation loss: 2.1231181422869363

Epoch: 5| Step: 3
Training loss: 0.8904498815536499
Validation loss: 2.240868921081225

Epoch: 5| Step: 4
Training loss: 1.504067063331604
Validation loss: 2.222327987353007

Epoch: 5| Step: 5
Training loss: 1.290496587753296
Validation loss: 2.176399126648903

Epoch: 5| Step: 6
Training loss: 0.8898110389709473
Validation loss: 2.1767196456591287

Epoch: 5| Step: 7
Training loss: 1.437347412109375
Validation loss: 2.187160457173983

Epoch: 5| Step: 8
Training loss: 1.3807880878448486
Validation loss: 2.1266591350237527

Epoch: 5| Step: 9
Training loss: 1.1337261199951172
Validation loss: 2.082334483663241

Epoch: 5| Step: 10
Training loss: 1.1514909267425537
Validation loss: 2.131545384724935

Epoch: 5| Step: 11
Training loss: 1.455187439918518
Validation loss: 2.1437819997469583

Epoch: 136| Step: 0
Training loss: 1.4785932302474976
Validation loss: 2.099702000617981

Epoch: 5| Step: 1
Training loss: 1.1361162662506104
Validation loss: 2.2013682623704276

Epoch: 5| Step: 2
Training loss: 1.1181161403656006
Validation loss: 2.114733561873436

Epoch: 5| Step: 3
Training loss: 1.0591844320297241
Validation loss: 2.2028490751981735

Epoch: 5| Step: 4
Training loss: 0.9480926394462585
Validation loss: 2.099936157464981

Epoch: 5| Step: 5
Training loss: 0.8565998077392578
Validation loss: 2.104479670524597

Epoch: 5| Step: 6
Training loss: 1.1779762506484985
Validation loss: 2.1489139596621194

Epoch: 5| Step: 7
Training loss: 1.0444815158843994
Validation loss: 2.1350444853305817

Epoch: 5| Step: 8
Training loss: 0.7225824594497681
Validation loss: 2.122499336798986

Epoch: 5| Step: 9
Training loss: 1.465275764465332
Validation loss: 2.156223644812902

Epoch: 5| Step: 10
Training loss: 1.3042997121810913
Validation loss: 2.133083333571752

Epoch: 5| Step: 11
Training loss: 0.5334084033966064
Validation loss: 2.1561993459860482

Epoch: 137| Step: 0
Training loss: 1.0074234008789062
Validation loss: 2.0784172217051187

Epoch: 5| Step: 1
Training loss: 0.6729643940925598
Validation loss: 2.14033550520738

Epoch: 5| Step: 2
Training loss: 1.0869477987289429
Validation loss: 2.2063331256310144

Epoch: 5| Step: 3
Training loss: 0.6456976532936096
Validation loss: 2.1749716301759086

Epoch: 5| Step: 4
Training loss: 1.271356463432312
Validation loss: 2.2003751496473947

Epoch: 5| Step: 5
Training loss: 1.375922441482544
Validation loss: 2.201092153787613

Epoch: 5| Step: 6
Training loss: 1.3842339515686035
Validation loss: 2.153464158376058

Epoch: 5| Step: 7
Training loss: 1.1885783672332764
Validation loss: 2.261552006006241

Epoch: 5| Step: 8
Training loss: 1.1755751371383667
Validation loss: 2.149294783671697

Epoch: 5| Step: 9
Training loss: 1.5278096199035645
Validation loss: 2.1004275182882943

Epoch: 5| Step: 10
Training loss: 0.5481362342834473
Validation loss: 2.105588654677073

Epoch: 5| Step: 11
Training loss: 0.942977786064148
Validation loss: 2.1015723447004953

Epoch: 138| Step: 0
Training loss: 0.8726950883865356
Validation loss: 2.175333857536316

Epoch: 5| Step: 1
Training loss: 1.0789066553115845
Validation loss: 2.1055253446102142

Epoch: 5| Step: 2
Training loss: 0.8754317164421082
Validation loss: 2.065229515234629

Epoch: 5| Step: 3
Training loss: 0.8642460107803345
Validation loss: 2.127195194363594

Epoch: 5| Step: 4
Training loss: 0.9349263906478882
Validation loss: 2.1312286804119744

Epoch: 5| Step: 5
Training loss: 1.4975618124008179
Validation loss: 2.1091106832027435

Epoch: 5| Step: 6
Training loss: 1.3325531482696533
Validation loss: 2.1360274056593576

Epoch: 5| Step: 7
Training loss: 1.3299150466918945
Validation loss: 2.1356618801752725

Epoch: 5| Step: 8
Training loss: 0.8262103796005249
Validation loss: 2.162844568490982

Epoch: 5| Step: 9
Training loss: 0.9891802072525024
Validation loss: 2.175051083167394

Epoch: 5| Step: 10
Training loss: 1.0133144855499268
Validation loss: 2.142777070403099

Epoch: 5| Step: 11
Training loss: 2.0695910453796387
Validation loss: 2.1607134689887366

Epoch: 139| Step: 0
Training loss: 1.0759475231170654
Validation loss: 2.1262398262818656

Epoch: 5| Step: 1
Training loss: 0.9709525108337402
Validation loss: 2.189485793312391

Epoch: 5| Step: 2
Training loss: 0.703346848487854
Validation loss: 2.2009063363075256

Epoch: 5| Step: 3
Training loss: 0.8024080395698547
Validation loss: 2.168923477331797

Epoch: 5| Step: 4
Training loss: 1.4313879013061523
Validation loss: 2.167486091454824

Epoch: 5| Step: 5
Training loss: 1.0472538471221924
Validation loss: 2.141032059987386

Epoch: 5| Step: 6
Training loss: 1.2133277654647827
Validation loss: 2.152412176132202

Epoch: 5| Step: 7
Training loss: 1.2957603931427002
Validation loss: 2.1038052290678024

Epoch: 5| Step: 8
Training loss: 1.274200677871704
Validation loss: 2.1203597833712897

Epoch: 5| Step: 9
Training loss: 0.6812824010848999
Validation loss: 2.173976590236028

Epoch: 5| Step: 10
Training loss: 1.5043631792068481
Validation loss: 2.153745656212171

Epoch: 5| Step: 11
Training loss: 1.2788673639297485
Validation loss: 2.1676299571990967

Epoch: 140| Step: 0
Training loss: 1.2376582622528076
Validation loss: 2.1514118711153665

Epoch: 5| Step: 1
Training loss: 0.844561755657196
Validation loss: 2.1849933564662933

Epoch: 5| Step: 2
Training loss: 1.0779211521148682
Validation loss: 2.1725384344657264

Epoch: 5| Step: 3
Training loss: 0.9406160116195679
Validation loss: 2.1630923599004745

Epoch: 5| Step: 4
Training loss: 1.1702989339828491
Validation loss: 2.1080684512853622

Epoch: 5| Step: 5
Training loss: 0.922930896282196
Validation loss: 2.1951633989810944

Epoch: 5| Step: 6
Training loss: 0.9825787544250488
Validation loss: 2.02505990366141

Epoch: 5| Step: 7
Training loss: 1.0828732252120972
Validation loss: 2.2104976375897727

Epoch: 5| Step: 8
Training loss: 1.2265598773956299
Validation loss: 2.1730174173911414

Epoch: 5| Step: 9
Training loss: 1.1385527849197388
Validation loss: 2.177560657262802

Epoch: 5| Step: 10
Training loss: 1.206325888633728
Validation loss: 2.125687822699547

Epoch: 5| Step: 11
Training loss: 0.766200065612793
Validation loss: 2.1712718109289804

Epoch: 141| Step: 0
Training loss: 1.436755895614624
Validation loss: 2.190555696686109

Epoch: 5| Step: 1
Training loss: 0.9099076986312866
Validation loss: 2.2053312559922538

Epoch: 5| Step: 2
Training loss: 0.9098612070083618
Validation loss: 2.158176446954409

Epoch: 5| Step: 3
Training loss: 1.084594964981079
Validation loss: 2.1999809245268502

Epoch: 5| Step: 4
Training loss: 0.7744051218032837
Validation loss: 2.160264313220978

Epoch: 5| Step: 5
Training loss: 0.7997593879699707
Validation loss: 2.2437258263429007

Epoch: 5| Step: 6
Training loss: 1.473889946937561
Validation loss: 2.1340211232503257

Epoch: 5| Step: 7
Training loss: 0.9332020878791809
Validation loss: 2.149358779191971

Epoch: 5| Step: 8
Training loss: 1.6098905801773071
Validation loss: 2.119877432783445

Epoch: 5| Step: 9
Training loss: 1.0389041900634766
Validation loss: 2.149067069093386

Epoch: 5| Step: 10
Training loss: 0.860243022441864
Validation loss: 2.108111326893171

Epoch: 5| Step: 11
Training loss: 0.9360241293907166
Validation loss: 2.1723560144503913

Epoch: 142| Step: 0
Training loss: 1.2939388751983643
Validation loss: 2.2553383509318032

Epoch: 5| Step: 1
Training loss: 1.4829095602035522
Validation loss: 2.2300312370061874

Epoch: 5| Step: 2
Training loss: 1.1242204904556274
Validation loss: 2.20334155857563

Epoch: 5| Step: 3
Training loss: 0.7890797853469849
Validation loss: 2.1780888438224792

Epoch: 5| Step: 4
Training loss: 1.158512830734253
Validation loss: 2.0854856818914413

Epoch: 5| Step: 5
Training loss: 1.1682971715927124
Validation loss: 2.076147178808848

Epoch: 5| Step: 6
Training loss: 0.9608138799667358
Validation loss: 2.106892635424932

Epoch: 5| Step: 7
Training loss: 0.9820523262023926
Validation loss: 2.1127152144908905

Epoch: 5| Step: 8
Training loss: 1.056633710861206
Validation loss: 2.1217017571131387

Epoch: 5| Step: 9
Training loss: 1.253209114074707
Validation loss: 2.1603681395451226

Epoch: 5| Step: 10
Training loss: 1.2412434816360474
Validation loss: 2.1274117678403854

Epoch: 5| Step: 11
Training loss: 0.3801790475845337
Validation loss: 2.069755439956983

Epoch: 143| Step: 0
Training loss: 1.6691181659698486
Validation loss: 2.1198309113581977

Epoch: 5| Step: 1
Training loss: 1.117815613746643
Validation loss: 2.0871655543645224

Epoch: 5| Step: 2
Training loss: 1.3973095417022705
Validation loss: 2.219900891184807

Epoch: 5| Step: 3
Training loss: 0.8354263305664062
Validation loss: 2.1818766593933105

Epoch: 5| Step: 4
Training loss: 1.4166204929351807
Validation loss: 2.182994470000267

Epoch: 5| Step: 5
Training loss: 0.8905172348022461
Validation loss: 2.212583581606547

Epoch: 5| Step: 6
Training loss: 0.6369715929031372
Validation loss: 2.1479557206233344

Epoch: 5| Step: 7
Training loss: 1.0461328029632568
Validation loss: 2.107417722543081

Epoch: 5| Step: 8
Training loss: 1.1002432107925415
Validation loss: 2.145342896382014

Epoch: 5| Step: 9
Training loss: 0.9003146886825562
Validation loss: 2.182433843612671

Epoch: 5| Step: 10
Training loss: 1.3802915811538696
Validation loss: 2.0915673077106476

Epoch: 5| Step: 11
Training loss: 0.6067348122596741
Validation loss: 2.1926036973794303

Epoch: 144| Step: 0
Training loss: 0.8591732978820801
Validation loss: 2.0788961946964264

Epoch: 5| Step: 1
Training loss: 1.1738269329071045
Validation loss: 2.0264503955841064

Epoch: 5| Step: 2
Training loss: 0.8954706192016602
Validation loss: 2.0755045115947723

Epoch: 5| Step: 3
Training loss: 1.1880509853363037
Validation loss: 2.2409503161907196

Epoch: 5| Step: 4
Training loss: 0.9595464468002319
Validation loss: 2.2445152203241983

Epoch: 5| Step: 5
Training loss: 1.3234288692474365
Validation loss: 2.0465762267510095

Epoch: 5| Step: 6
Training loss: 1.7441734075546265
Validation loss: 2.1321227103471756

Epoch: 5| Step: 7
Training loss: 1.1482857465744019
Validation loss: 2.1596013804276786

Epoch: 5| Step: 8
Training loss: 1.1697356700897217
Validation loss: 2.1355235328276954

Epoch: 5| Step: 9
Training loss: 0.7154833078384399
Validation loss: 2.177094891667366

Epoch: 5| Step: 10
Training loss: 0.9380241632461548
Validation loss: 2.1341506441434226

Epoch: 5| Step: 11
Training loss: 1.3316266536712646
Validation loss: 2.157823324203491

Epoch: 145| Step: 0
Training loss: 1.254407286643982
Validation loss: 2.2159198373556137

Epoch: 5| Step: 1
Training loss: 0.7379371523857117
Validation loss: 2.134768635034561

Epoch: 5| Step: 2
Training loss: 1.2409611940383911
Validation loss: 2.2055055648088455

Epoch: 5| Step: 3
Training loss: 0.9631456136703491
Validation loss: 2.199825346469879

Epoch: 5| Step: 4
Training loss: 1.189622402191162
Validation loss: 2.2131381233533225

Epoch: 5| Step: 5
Training loss: 0.8995484113693237
Validation loss: 2.2049537350734076

Epoch: 5| Step: 6
Training loss: 0.9863061904907227
Validation loss: 2.1565073430538177

Epoch: 5| Step: 7
Training loss: 1.0495525598526
Validation loss: 2.0565072844425836

Epoch: 5| Step: 8
Training loss: 0.7223460674285889
Validation loss: 2.1156983276208243

Epoch: 5| Step: 9
Training loss: 0.9321813583374023
Validation loss: 2.0682200143734613

Epoch: 5| Step: 10
Training loss: 1.4550000429153442
Validation loss: 2.106631944576899

Epoch: 5| Step: 11
Training loss: 1.8332200050354004
Validation loss: 2.1065595944722495

Epoch: 146| Step: 0
Training loss: 0.8956054449081421
Validation loss: 2.116954172650973

Epoch: 5| Step: 1
Training loss: 1.0630614757537842
Validation loss: 2.2325809399286904

Epoch: 5| Step: 2
Training loss: 1.0594305992126465
Validation loss: 2.0973949829737344

Epoch: 5| Step: 3
Training loss: 1.0532680749893188
Validation loss: 2.2451364596684775

Epoch: 5| Step: 4
Training loss: 1.24656081199646
Validation loss: 2.2550160189469657

Epoch: 5| Step: 5
Training loss: 1.1694040298461914
Validation loss: 2.1972265193859735

Epoch: 5| Step: 6
Training loss: 0.704498291015625
Validation loss: 2.214770570397377

Epoch: 5| Step: 7
Training loss: 1.5155166387557983
Validation loss: 2.1520699659983316

Epoch: 5| Step: 8
Training loss: 1.1717671155929565
Validation loss: 2.134414220849673

Epoch: 5| Step: 9
Training loss: 0.9243794679641724
Validation loss: 2.1201069305340448

Epoch: 5| Step: 10
Training loss: 1.3001585006713867
Validation loss: 2.14266366759936

Epoch: 5| Step: 11
Training loss: 1.2013981342315674
Validation loss: 2.256845861673355

Epoch: 147| Step: 0
Training loss: 1.2088147401809692
Validation loss: 2.155378798643748

Epoch: 5| Step: 1
Training loss: 1.2407233715057373
Validation loss: 2.13767538468043

Epoch: 5| Step: 2
Training loss: 0.6845398545265198
Validation loss: 2.1997355620066323

Epoch: 5| Step: 3
Training loss: 0.9138129949569702
Validation loss: 2.13606396317482

Epoch: 5| Step: 4
Training loss: 1.0514060258865356
Validation loss: 2.2822673271099725

Epoch: 5| Step: 5
Training loss: 1.050959825515747
Validation loss: 2.224091519912084

Epoch: 5| Step: 6
Training loss: 1.2242881059646606
Validation loss: 2.155483454465866

Epoch: 5| Step: 7
Training loss: 1.0733305215835571
Validation loss: 2.187355081240336

Epoch: 5| Step: 8
Training loss: 0.9395403861999512
Validation loss: 2.129931077361107

Epoch: 5| Step: 9
Training loss: 0.9914437532424927
Validation loss: 2.15935909251372

Epoch: 5| Step: 10
Training loss: 1.171653151512146
Validation loss: 2.203771953781446

Epoch: 5| Step: 11
Training loss: 0.2558581829071045
Validation loss: 2.1402667264143624

Epoch: 148| Step: 0
Training loss: 0.7479952573776245
Validation loss: 2.092783123254776

Epoch: 5| Step: 1
Training loss: 1.3273721933364868
Validation loss: 2.223152314623197

Epoch: 5| Step: 2
Training loss: 1.0521581172943115
Validation loss: 2.2114221652348838

Epoch: 5| Step: 3
Training loss: 0.8278999328613281
Validation loss: 2.1061013489961624

Epoch: 5| Step: 4
Training loss: 1.0638401508331299
Validation loss: 2.167469784617424

Epoch: 5| Step: 5
Training loss: 0.9664987325668335
Validation loss: 2.1556650400161743

Epoch: 5| Step: 6
Training loss: 1.4096429347991943
Validation loss: 2.031560113032659

Epoch: 5| Step: 7
Training loss: 1.1092783212661743
Validation loss: 2.1198381086190543

Epoch: 5| Step: 8
Training loss: 1.4700729846954346
Validation loss: 2.1990430504083633

Epoch: 5| Step: 9
Training loss: 1.40260910987854
Validation loss: 2.0163901646931968

Epoch: 5| Step: 10
Training loss: 0.8766018152236938
Validation loss: 2.121198892593384

Epoch: 5| Step: 11
Training loss: 0.9382116794586182
Validation loss: 2.043955465157827

Epoch: 149| Step: 0
Training loss: 0.9713393449783325
Validation loss: 2.2049118181069693

Epoch: 5| Step: 1
Training loss: 1.1522181034088135
Validation loss: 2.1682030856609344

Epoch: 5| Step: 2
Training loss: 1.063140630722046
Validation loss: 2.199391861756643

Epoch: 5| Step: 3
Training loss: 0.7311574220657349
Validation loss: 2.1895161469777427

Epoch: 5| Step: 4
Training loss: 0.839974045753479
Validation loss: 2.106563523411751

Epoch: 5| Step: 5
Training loss: 0.6164306402206421
Validation loss: 2.16361266374588

Epoch: 5| Step: 6
Training loss: 1.3226289749145508
Validation loss: 2.2351371397574744

Epoch: 5| Step: 7
Training loss: 1.3399101495742798
Validation loss: 2.2593593498071036

Epoch: 5| Step: 8
Training loss: 1.1224578619003296
Validation loss: 2.2013913045326867

Epoch: 5| Step: 9
Training loss: 1.2818353176116943
Validation loss: 2.1563026010990143

Epoch: 5| Step: 10
Training loss: 1.3319286108016968
Validation loss: 2.0756780157486596

Epoch: 5| Step: 11
Training loss: 0.9983829259872437
Validation loss: 2.144242987036705

Epoch: 150| Step: 0
Training loss: 1.1156563758850098
Validation loss: 2.227457642555237

Epoch: 5| Step: 1
Training loss: 0.6470574140548706
Validation loss: 2.2673213680585227

Epoch: 5| Step: 2
Training loss: 1.4803909063339233
Validation loss: 2.1802541067202887

Epoch: 5| Step: 3
Training loss: 0.8209457397460938
Validation loss: 2.1349095503489175

Epoch: 5| Step: 4
Training loss: 1.0564539432525635
Validation loss: 2.2152438312768936

Epoch: 5| Step: 5
Training loss: 1.0419633388519287
Validation loss: 2.2466582357883453

Epoch: 5| Step: 6
Training loss: 1.236280918121338
Validation loss: 2.1798962205648422

Epoch: 5| Step: 7
Training loss: 0.8141902685165405
Validation loss: 2.2157053699096045

Epoch: 5| Step: 8
Training loss: 1.206691026687622
Validation loss: 2.181205357114474

Epoch: 5| Step: 9
Training loss: 0.9885272979736328
Validation loss: 2.1861029316981635

Epoch: 5| Step: 10
Training loss: 0.8796655535697937
Validation loss: 2.12476780017217

Epoch: 5| Step: 11
Training loss: 0.9503155946731567
Validation loss: 2.1314569115638733

Epoch: 151| Step: 0
Training loss: 1.306449294090271
Validation loss: 2.1924036045869193

Epoch: 5| Step: 1
Training loss: 1.503078818321228
Validation loss: 2.2536130448182425

Epoch: 5| Step: 2
Training loss: 0.9084335565567017
Validation loss: 2.1135304073492684

Epoch: 5| Step: 3
Training loss: 1.1453596353530884
Validation loss: 2.186553955078125

Epoch: 5| Step: 4
Training loss: 0.8412542343139648
Validation loss: 2.2120983401934304

Epoch: 5| Step: 5
Training loss: 1.0407518148422241
Validation loss: 2.2361369729042053

Epoch: 5| Step: 6
Training loss: 1.5170570611953735
Validation loss: 2.149287482102712

Epoch: 5| Step: 7
Training loss: 0.9536564946174622
Validation loss: 2.171069865425428

Epoch: 5| Step: 8
Training loss: 0.776796817779541
Validation loss: 2.253606383999189

Epoch: 5| Step: 9
Training loss: 0.7405346035957336
Validation loss: 2.1492997904618583

Epoch: 5| Step: 10
Training loss: 0.6577209234237671
Validation loss: 2.208995153506597

Epoch: 5| Step: 11
Training loss: 0.7087178826332092
Validation loss: 2.168323576450348

Epoch: 152| Step: 0
Training loss: 1.0364478826522827
Validation loss: 2.1493192464113235

Epoch: 5| Step: 1
Training loss: 0.9640880823135376
Validation loss: 2.125680536031723

Epoch: 5| Step: 2
Training loss: 1.4919122457504272
Validation loss: 2.2176664570967355

Epoch: 5| Step: 3
Training loss: 1.2484638690948486
Validation loss: 2.1335196296374

Epoch: 5| Step: 4
Training loss: 0.9912447929382324
Validation loss: 2.2332582970460257

Epoch: 5| Step: 5
Training loss: 0.7709754705429077
Validation loss: 2.262653201818466

Epoch: 5| Step: 6
Training loss: 1.2567428350448608
Validation loss: 2.1373109767834344

Epoch: 5| Step: 7
Training loss: 0.7840149998664856
Validation loss: 2.258438507715861

Epoch: 5| Step: 8
Training loss: 1.020702838897705
Validation loss: 2.2010682821273804

Epoch: 5| Step: 9
Training loss: 0.8275247812271118
Validation loss: 2.197222794095675

Epoch: 5| Step: 10
Training loss: 0.6773974299430847
Validation loss: 2.2502032220363617

Epoch: 5| Step: 11
Training loss: 1.4598801136016846
Validation loss: 2.162286256750425

Epoch: 153| Step: 0
Training loss: 1.3533523082733154
Validation loss: 2.096066693464915

Epoch: 5| Step: 1
Training loss: 1.4603170156478882
Validation loss: 2.1845380663871765

Epoch: 5| Step: 2
Training loss: 1.1727136373519897
Validation loss: 2.1648574471473694

Epoch: 5| Step: 3
Training loss: 1.502301573753357
Validation loss: 2.1633574068546295

Epoch: 5| Step: 4
Training loss: 0.8132442235946655
Validation loss: 2.117416282494863

Epoch: 5| Step: 5
Training loss: 0.7761651277542114
Validation loss: 2.2260261525710425

Epoch: 5| Step: 6
Training loss: 0.9407118558883667
Validation loss: 2.2607116798559823

Epoch: 5| Step: 7
Training loss: 1.0721555948257446
Validation loss: 2.333739141623179

Epoch: 5| Step: 8
Training loss: 1.1789958477020264
Validation loss: 2.156525954604149

Epoch: 5| Step: 9
Training loss: 0.7792049646377563
Validation loss: 2.131277710199356

Epoch: 5| Step: 10
Training loss: 1.083512783050537
Validation loss: 2.140983293453852

Epoch: 5| Step: 11
Training loss: 2.178605556488037
Validation loss: 2.204825167854627

Epoch: 154| Step: 0
Training loss: 0.8933509588241577
Validation loss: 2.1786776085694632

Epoch: 5| Step: 1
Training loss: 0.992646336555481
Validation loss: 2.1700156132380166

Epoch: 5| Step: 2
Training loss: 1.151282548904419
Validation loss: 2.2730614940325418

Epoch: 5| Step: 3
Training loss: 1.3592519760131836
Validation loss: 2.1653667440017066

Epoch: 5| Step: 4
Training loss: 1.0200185775756836
Validation loss: 2.158916691939036

Epoch: 5| Step: 5
Training loss: 0.8581903576850891
Validation loss: 2.2244869470596313

Epoch: 5| Step: 6
Training loss: 1.4516756534576416
Validation loss: 2.2657609283924103

Epoch: 5| Step: 7
Training loss: 0.9511850476264954
Validation loss: 2.151791979869207

Epoch: 5| Step: 8
Training loss: 1.068371057510376
Validation loss: 2.1898112247387567

Epoch: 5| Step: 9
Training loss: 0.9502745866775513
Validation loss: 2.180341531833013

Epoch: 5| Step: 10
Training loss: 0.7675157189369202
Validation loss: 2.2272509237130484

Epoch: 5| Step: 11
Training loss: 0.3795090913772583
Validation loss: 2.1301902532577515

Epoch: 155| Step: 0
Training loss: 1.0812095403671265
Validation loss: 2.1348472932974496

Epoch: 5| Step: 1
Training loss: 0.9563972353935242
Validation loss: 2.078756699959437

Epoch: 5| Step: 2
Training loss: 1.1567941904067993
Validation loss: 2.217172155777613

Epoch: 5| Step: 3
Training loss: 0.8107982873916626
Validation loss: 2.2499278585116067

Epoch: 5| Step: 4
Training loss: 1.204397439956665
Validation loss: 2.1483260293801627

Epoch: 5| Step: 5
Training loss: 0.7103002667427063
Validation loss: 2.237094213565191

Epoch: 5| Step: 6
Training loss: 0.8746500015258789
Validation loss: 2.2782846043507257

Epoch: 5| Step: 7
Training loss: 1.3167227506637573
Validation loss: 2.273376375436783

Epoch: 5| Step: 8
Training loss: 0.6701844930648804
Validation loss: 2.1083990136782327

Epoch: 5| Step: 9
Training loss: 1.3183104991912842
Validation loss: 2.1797547191381454

Epoch: 5| Step: 10
Training loss: 1.119879961013794
Validation loss: 2.195293759306272

Epoch: 5| Step: 11
Training loss: 1.888584017753601
Validation loss: 2.1720536847909293

Epoch: 156| Step: 0
Training loss: 1.2245361804962158
Validation loss: 2.1937613089879355

Epoch: 5| Step: 1
Training loss: 0.9912182092666626
Validation loss: 2.2339322914679847

Epoch: 5| Step: 2
Training loss: 0.675747275352478
Validation loss: 2.078278327981631

Epoch: 5| Step: 3
Training loss: 1.3224868774414062
Validation loss: 2.2473229467868805

Epoch: 5| Step: 4
Training loss: 0.8543604016304016
Validation loss: 2.2201880117257438

Epoch: 5| Step: 5
Training loss: 0.9948158264160156
Validation loss: 2.2990954567988715

Epoch: 5| Step: 6
Training loss: 1.375645399093628
Validation loss: 2.3706523974736533

Epoch: 5| Step: 7
Training loss: 1.3628991842269897
Validation loss: 2.3244783033927283

Epoch: 5| Step: 8
Training loss: 1.5414512157440186
Validation loss: 2.330671896537145

Epoch: 5| Step: 9
Training loss: 1.1247612237930298
Validation loss: 2.2279029289881387

Epoch: 5| Step: 10
Training loss: 0.7685452103614807
Validation loss: 2.1346954504648843

Epoch: 5| Step: 11
Training loss: 1.157731533050537
Validation loss: 2.2067624976237616

Epoch: 157| Step: 0
Training loss: 0.987109363079071
Validation loss: 2.1238858302434287

Epoch: 5| Step: 1
Training loss: 0.8544839024543762
Validation loss: 2.0666452000538507

Epoch: 5| Step: 2
Training loss: 1.215989112854004
Validation loss: 2.152177611986796

Epoch: 5| Step: 3
Training loss: 0.9449633359909058
Validation loss: 2.149215911825498

Epoch: 5| Step: 4
Training loss: 0.8238948583602905
Validation loss: 2.221124609311422

Epoch: 5| Step: 5
Training loss: 1.1041265726089478
Validation loss: 2.1287847558657327

Epoch: 5| Step: 6
Training loss: 1.2418105602264404
Validation loss: 2.2063983529806137

Epoch: 5| Step: 7
Training loss: 1.229313611984253
Validation loss: 2.2487675150235495

Epoch: 5| Step: 8
Training loss: 1.1237128973007202
Validation loss: 2.1956032564242682

Epoch: 5| Step: 9
Training loss: 0.8258184194564819
Validation loss: 2.015048469106356

Epoch: 5| Step: 10
Training loss: 1.215327262878418
Validation loss: 2.1492483069499335

Epoch: 5| Step: 11
Training loss: 0.5474619269371033
Validation loss: 2.0725400497515998

Epoch: 158| Step: 0
Training loss: 0.9847198724746704
Validation loss: 2.215859899918238

Epoch: 5| Step: 1
Training loss: 1.0644279718399048
Validation loss: 2.107922539114952

Epoch: 5| Step: 2
Training loss: 1.275194764137268
Validation loss: 2.0742941151062646

Epoch: 5| Step: 3
Training loss: 1.1369807720184326
Validation loss: 2.2039380371570587

Epoch: 5| Step: 4
Training loss: 1.2178369760513306
Validation loss: 2.227816710869471

Epoch: 5| Step: 5
Training loss: 0.9278469085693359
Validation loss: 2.222036893169085

Epoch: 5| Step: 6
Training loss: 0.9265843629837036
Validation loss: 2.127775857845942

Epoch: 5| Step: 7
Training loss: 0.7578251361846924
Validation loss: 2.1266857286294303

Epoch: 5| Step: 8
Training loss: 0.6094031929969788
Validation loss: 2.17457781235377

Epoch: 5| Step: 9
Training loss: 0.7532692551612854
Validation loss: 2.14959021906058

Epoch: 5| Step: 10
Training loss: 0.7884598970413208
Validation loss: 2.1066760271787643

Epoch: 5| Step: 11
Training loss: 0.5058689117431641
Validation loss: 2.0695006996393204

Epoch: 159| Step: 0
Training loss: 1.0835199356079102
Validation loss: 2.119703307747841

Epoch: 5| Step: 1
Training loss: 0.7938421964645386
Validation loss: 2.168319751818975

Epoch: 5| Step: 2
Training loss: 1.414680004119873
Validation loss: 2.160611614584923

Epoch: 5| Step: 3
Training loss: 1.0080032348632812
Validation loss: 2.2324070980151496

Epoch: 5| Step: 4
Training loss: 1.4128466844558716
Validation loss: 2.3121668150027594

Epoch: 5| Step: 5
Training loss: 1.443221092224121
Validation loss: 2.207829862833023

Epoch: 5| Step: 6
Training loss: 0.49521002173423767
Validation loss: 2.1090909838676453

Epoch: 5| Step: 7
Training loss: 1.3663957118988037
Validation loss: 2.0829388797283173

Epoch: 5| Step: 8
Training loss: 0.9467312693595886
Validation loss: 2.097507228453954

Epoch: 5| Step: 9
Training loss: 0.807217001914978
Validation loss: 2.139831264813741

Epoch: 5| Step: 10
Training loss: 1.0421158075332642
Validation loss: 2.2107003976901374

Epoch: 5| Step: 11
Training loss: 0.6218184232711792
Validation loss: 2.1631170163551965

Epoch: 160| Step: 0
Training loss: 1.18980872631073
Validation loss: 2.174720217784246

Epoch: 5| Step: 1
Training loss: 0.9118488430976868
Validation loss: 2.02926334242026

Epoch: 5| Step: 2
Training loss: 0.8210857510566711
Validation loss: 2.158856764435768

Epoch: 5| Step: 3
Training loss: 1.371915578842163
Validation loss: 2.115974729259809

Epoch: 5| Step: 4
Training loss: 0.8804025650024414
Validation loss: 2.163263941804568

Epoch: 5| Step: 5
Training loss: 0.8577634692192078
Validation loss: 2.1108754575252533

Epoch: 5| Step: 6
Training loss: 1.0415054559707642
Validation loss: 2.1406141420205436

Epoch: 5| Step: 7
Training loss: 0.8807520866394043
Validation loss: 2.1388825178146362

Epoch: 5| Step: 8
Training loss: 0.8513106107711792
Validation loss: 2.195716301600138

Epoch: 5| Step: 9
Training loss: 0.8766844868659973
Validation loss: 2.231444781025251

Epoch: 5| Step: 10
Training loss: 0.8694613575935364
Validation loss: 2.190646688143412

Epoch: 5| Step: 11
Training loss: 1.2356642484664917
Validation loss: 2.196541945139567

Epoch: 161| Step: 0
Training loss: 1.2305363416671753
Validation loss: 2.061758796374003

Epoch: 5| Step: 1
Training loss: 1.111742615699768
Validation loss: 2.1705634693304696

Epoch: 5| Step: 2
Training loss: 1.0899261236190796
Validation loss: 2.1232244074344635

Epoch: 5| Step: 3
Training loss: 0.5673717260360718
Validation loss: 2.107001379132271

Epoch: 5| Step: 4
Training loss: 0.5049606561660767
Validation loss: 2.125635633865992

Epoch: 5| Step: 5
Training loss: 0.4223906397819519
Validation loss: 2.118069032828013

Epoch: 5| Step: 6
Training loss: 0.9478391408920288
Validation loss: 2.0686374654372535

Epoch: 5| Step: 7
Training loss: 0.7168542146682739
Validation loss: 2.208921894431114

Epoch: 5| Step: 8
Training loss: 1.5405689477920532
Validation loss: 2.1929676135381064

Epoch: 5| Step: 9
Training loss: 1.1349573135375977
Validation loss: 2.141195148229599

Epoch: 5| Step: 10
Training loss: 1.4160802364349365
Validation loss: 2.1139566749334335

Epoch: 5| Step: 11
Training loss: 0.12761330604553223
Validation loss: 2.237870534261068

Epoch: 162| Step: 0
Training loss: 0.762830376625061
Validation loss: 2.170450141032537

Epoch: 5| Step: 1
Training loss: 0.6730334758758545
Validation loss: 2.216229274868965

Epoch: 5| Step: 2
Training loss: 1.2873424291610718
Validation loss: 2.189686636130015

Epoch: 5| Step: 3
Training loss: 1.1816562414169312
Validation loss: 2.077588841319084

Epoch: 5| Step: 4
Training loss: 1.1071465015411377
Validation loss: 2.1807575821876526

Epoch: 5| Step: 5
Training loss: 0.7574491500854492
Validation loss: 2.1765776524941125

Epoch: 5| Step: 6
Training loss: 1.1748387813568115
Validation loss: 2.092031473914782

Epoch: 5| Step: 7
Training loss: 0.9701004028320312
Validation loss: 2.1305616796016693

Epoch: 5| Step: 8
Training loss: 1.0566445589065552
Validation loss: 2.108136529723803

Epoch: 5| Step: 9
Training loss: 1.1106079816818237
Validation loss: 2.1704771717389426

Epoch: 5| Step: 10
Training loss: 1.0099602937698364
Validation loss: 2.24408949414889

Epoch: 5| Step: 11
Training loss: 0.8604886531829834
Validation loss: 2.200075546900431

Epoch: 163| Step: 0
Training loss: 1.0548208951950073
Validation loss: 2.1745574921369553

Epoch: 5| Step: 1
Training loss: 1.1756083965301514
Validation loss: 2.2185464004675546

Epoch: 5| Step: 2
Training loss: 0.7750192284584045
Validation loss: 2.148726840813955

Epoch: 5| Step: 3
Training loss: 1.0374062061309814
Validation loss: 2.1817928353945413

Epoch: 5| Step: 4
Training loss: 1.3231632709503174
Validation loss: 2.2147504339615502

Epoch: 5| Step: 5
Training loss: 0.900992214679718
Validation loss: 2.146102786064148

Epoch: 5| Step: 6
Training loss: 1.3303658962249756
Validation loss: 2.1858100593090057

Epoch: 5| Step: 7
Training loss: 1.040773630142212
Validation loss: 2.1737442910671234

Epoch: 5| Step: 8
Training loss: 0.6251122951507568
Validation loss: 2.2097491770982742

Epoch: 5| Step: 9
Training loss: 0.8494142293930054
Validation loss: 2.252901092171669

Epoch: 5| Step: 10
Training loss: 0.9334808588027954
Validation loss: 2.1412357091903687

Epoch: 5| Step: 11
Training loss: 1.2645888328552246
Validation loss: 2.0800281316041946

Epoch: 164| Step: 0
Training loss: 0.8641124963760376
Validation loss: 2.1877753138542175

Epoch: 5| Step: 1
Training loss: 0.9904672503471375
Validation loss: 2.084317604700724

Epoch: 5| Step: 2
Training loss: 0.5513846278190613
Validation loss: 2.202074964841207

Epoch: 5| Step: 3
Training loss: 0.7673618197441101
Validation loss: 2.229200065135956

Epoch: 5| Step: 4
Training loss: 0.9938861727714539
Validation loss: 2.1872820258140564

Epoch: 5| Step: 5
Training loss: 1.0482248067855835
Validation loss: 2.1140757501125336

Epoch: 5| Step: 6
Training loss: 0.9646109342575073
Validation loss: 2.090751717487971

Epoch: 5| Step: 7
Training loss: 1.2212817668914795
Validation loss: 2.196641912062963

Epoch: 5| Step: 8
Training loss: 0.9685457348823547
Validation loss: 2.1547423203786216

Epoch: 5| Step: 9
Training loss: 1.0312280654907227
Validation loss: 2.12796750664711

Epoch: 5| Step: 10
Training loss: 1.2097867727279663
Validation loss: 2.133500248193741

Epoch: 5| Step: 11
Training loss: 0.5279321670532227
Validation loss: 2.153990109761556

Epoch: 165| Step: 0
Training loss: 0.9169454574584961
Validation loss: 2.200259799758593

Epoch: 5| Step: 1
Training loss: 1.3076400756835938
Validation loss: 2.1735584139823914

Epoch: 5| Step: 2
Training loss: 0.9931545257568359
Validation loss: 2.1794649263223014

Epoch: 5| Step: 3
Training loss: 1.171088457107544
Validation loss: 2.1210666497548423

Epoch: 5| Step: 4
Training loss: 1.2384856939315796
Validation loss: 2.1529403924942017

Epoch: 5| Step: 5
Training loss: 0.9511879086494446
Validation loss: 2.097606837749481

Epoch: 5| Step: 6
Training loss: 0.8445949554443359
Validation loss: 2.107213189204534

Epoch: 5| Step: 7
Training loss: 1.0670560598373413
Validation loss: 2.09058678150177

Epoch: 5| Step: 8
Training loss: 1.1214679479599
Validation loss: 2.129771833618482

Epoch: 5| Step: 9
Training loss: 0.9220743179321289
Validation loss: 2.1044358064730964

Epoch: 5| Step: 10
Training loss: 0.5438737869262695
Validation loss: 2.199074625968933

Epoch: 5| Step: 11
Training loss: 1.4263633489608765
Validation loss: 2.141589110096296

Epoch: 166| Step: 0
Training loss: 0.7261652946472168
Validation loss: 2.1004890302817025

Epoch: 5| Step: 1
Training loss: 0.9759390950202942
Validation loss: 2.091812620560328

Epoch: 5| Step: 2
Training loss: 1.0981043577194214
Validation loss: 2.1402252117792764

Epoch: 5| Step: 3
Training loss: 0.8714343905448914
Validation loss: 2.0631003677845

Epoch: 5| Step: 4
Training loss: 0.5080217123031616
Validation loss: 2.2424477338790894

Epoch: 5| Step: 5
Training loss: 0.7594478726387024
Validation loss: 2.104375585913658

Epoch: 5| Step: 6
Training loss: 1.400133490562439
Validation loss: 2.149394209186236

Epoch: 5| Step: 7
Training loss: 0.7697589993476868
Validation loss: 2.151370416084925

Epoch: 5| Step: 8
Training loss: 1.1970312595367432
Validation loss: 2.032404839992523

Epoch: 5| Step: 9
Training loss: 0.8928718566894531
Validation loss: 2.229287102818489

Epoch: 5| Step: 10
Training loss: 1.1092324256896973
Validation loss: 2.1435780425866446

Epoch: 5| Step: 11
Training loss: 1.419796347618103
Validation loss: 2.234743262330691

Epoch: 167| Step: 0
Training loss: 1.0588886737823486
Validation loss: 2.1816025326649346

Epoch: 5| Step: 1
Training loss: 1.1510813236236572
Validation loss: 2.19151841600736

Epoch: 5| Step: 2
Training loss: 1.0642178058624268
Validation loss: 2.1300504157940545

Epoch: 5| Step: 3
Training loss: 0.8907086253166199
Validation loss: 2.1470967878897986

Epoch: 5| Step: 4
Training loss: 1.095641851425171
Validation loss: 2.1449042508999505

Epoch: 5| Step: 5
Training loss: 1.1341890096664429
Validation loss: 2.2029503881931305

Epoch: 5| Step: 6
Training loss: 0.9368888735771179
Validation loss: 2.0459462056557336

Epoch: 5| Step: 7
Training loss: 1.1545294523239136
Validation loss: 2.140037551522255

Epoch: 5| Step: 8
Training loss: 0.7925056219100952
Validation loss: 2.2365499635537467

Epoch: 5| Step: 9
Training loss: 0.9729029536247253
Validation loss: 2.2229469617207847

Epoch: 5| Step: 10
Training loss: 1.287121057510376
Validation loss: 2.22145610054334

Epoch: 5| Step: 11
Training loss: 0.6746944189071655
Validation loss: 2.2512218008438745

Epoch: 168| Step: 0
Training loss: 0.9061464071273804
Validation loss: 2.334150413672129

Epoch: 5| Step: 1
Training loss: 1.1516472101211548
Validation loss: 2.2391999463240304

Epoch: 5| Step: 2
Training loss: 0.8215425610542297
Validation loss: 2.189095894495646

Epoch: 5| Step: 3
Training loss: 0.8778945207595825
Validation loss: 2.098204811414083

Epoch: 5| Step: 4
Training loss: 0.600165605545044
Validation loss: 2.146948163708051

Epoch: 5| Step: 5
Training loss: 0.4848795533180237
Validation loss: 2.1860226889451346

Epoch: 5| Step: 6
Training loss: 0.8583766222000122
Validation loss: 2.1616431325674057

Epoch: 5| Step: 7
Training loss: 1.3049640655517578
Validation loss: 2.137725000580152

Epoch: 5| Step: 8
Training loss: 1.15360426902771
Validation loss: 2.1498059928417206

Epoch: 5| Step: 9
Training loss: 0.8783033490180969
Validation loss: 2.186192293961843

Epoch: 5| Step: 10
Training loss: 1.068752646446228
Validation loss: 2.2131888469060264

Epoch: 5| Step: 11
Training loss: 1.417768955230713
Validation loss: 2.218918432792028

Epoch: 169| Step: 0
Training loss: 1.215070128440857
Validation loss: 2.0807456026474633

Epoch: 5| Step: 1
Training loss: 1.1302722692489624
Validation loss: 2.3026370207468667

Epoch: 5| Step: 2
Training loss: 0.7083393931388855
Validation loss: 2.201313922802607

Epoch: 5| Step: 3
Training loss: 0.8154834508895874
Validation loss: 2.1573390861352286

Epoch: 5| Step: 4
Training loss: 0.6990835070610046
Validation loss: 2.192693422238032

Epoch: 5| Step: 5
Training loss: 1.0515477657318115
Validation loss: 2.125003844499588

Epoch: 5| Step: 6
Training loss: 0.9052374958992004
Validation loss: 2.2327879120906196

Epoch: 5| Step: 7
Training loss: 1.4848518371582031
Validation loss: 2.29811197022597

Epoch: 5| Step: 8
Training loss: 0.7515910863876343
Validation loss: 2.2662331412235894

Epoch: 5| Step: 9
Training loss: 0.9742996096611023
Validation loss: 2.2361981868743896

Epoch: 5| Step: 10
Training loss: 0.758825957775116
Validation loss: 2.1879736135403314

Epoch: 5| Step: 11
Training loss: 1.2595305442810059
Validation loss: 2.1825823336839676

Epoch: 170| Step: 0
Training loss: 1.1449072360992432
Validation loss: 2.1655971010526023

Epoch: 5| Step: 1
Training loss: 0.7031813263893127
Validation loss: 2.139099046587944

Epoch: 5| Step: 2
Training loss: 0.7155939340591431
Validation loss: 2.1627133389314017

Epoch: 5| Step: 3
Training loss: 1.2510806322097778
Validation loss: 2.215940256913503

Epoch: 5| Step: 4
Training loss: 0.4524073600769043
Validation loss: 2.1839103549718857

Epoch: 5| Step: 5
Training loss: 0.8163617253303528
Validation loss: 2.222751264770826

Epoch: 5| Step: 6
Training loss: 0.9114311337471008
Validation loss: 2.16838530699412

Epoch: 5| Step: 7
Training loss: 1.136165976524353
Validation loss: 2.225218266248703

Epoch: 5| Step: 8
Training loss: 0.7753920555114746
Validation loss: 2.219328631957372

Epoch: 5| Step: 9
Training loss: 1.0126705169677734
Validation loss: 2.1918377776940665

Epoch: 5| Step: 10
Training loss: 1.2450941801071167
Validation loss: 2.155031755566597

Epoch: 5| Step: 11
Training loss: 0.4574766159057617
Validation loss: 2.209434707959493

Epoch: 171| Step: 0
Training loss: 0.7919915914535522
Validation loss: 2.2643944025039673

Epoch: 5| Step: 1
Training loss: 0.9102020263671875
Validation loss: 2.3013085971275964

Epoch: 5| Step: 2
Training loss: 1.32656729221344
Validation loss: 2.3385604669650397

Epoch: 5| Step: 3
Training loss: 1.0389419794082642
Validation loss: 2.3566224624713263

Epoch: 5| Step: 4
Training loss: 1.395535945892334
Validation loss: 2.2922052343686423

Epoch: 5| Step: 5
Training loss: 0.7591880559921265
Validation loss: 2.180810570716858

Epoch: 5| Step: 6
Training loss: 1.5441396236419678
Validation loss: 2.2025003830591836

Epoch: 5| Step: 7
Training loss: 0.6332319378852844
Validation loss: 2.136832575003306

Epoch: 5| Step: 8
Training loss: 1.4022648334503174
Validation loss: 2.1523608515659967

Epoch: 5| Step: 9
Training loss: 0.8075309991836548
Validation loss: 2.2134503026803336

Epoch: 5| Step: 10
Training loss: 0.7626155614852905
Validation loss: 2.2078504910071692

Epoch: 5| Step: 11
Training loss: 1.0508371591567993
Validation loss: 2.236054619153341

Epoch: 172| Step: 0
Training loss: 1.257925033569336
Validation loss: 2.1622501413027444

Epoch: 5| Step: 1
Training loss: 0.7131224274635315
Validation loss: 2.2002090563376746

Epoch: 5| Step: 2
Training loss: 0.7528443336486816
Validation loss: 2.2960807333389917

Epoch: 5| Step: 3
Training loss: 0.6307984590530396
Validation loss: 2.161658967534701

Epoch: 5| Step: 4
Training loss: 1.0635740756988525
Validation loss: 2.165442963441213

Epoch: 5| Step: 5
Training loss: 0.9350941777229309
Validation loss: 2.2073802848656974

Epoch: 5| Step: 6
Training loss: 1.3587173223495483
Validation loss: 2.202456379930178

Epoch: 5| Step: 7
Training loss: 1.0322729349136353
Validation loss: 2.277694741884867

Epoch: 5| Step: 8
Training loss: 1.4949626922607422
Validation loss: 2.2527927458286285

Epoch: 5| Step: 9
Training loss: 0.5932503938674927
Validation loss: 2.249886085589727

Epoch: 5| Step: 10
Training loss: 0.7921186685562134
Validation loss: 2.170959269007047

Epoch: 5| Step: 11
Training loss: 0.2825474143028259
Validation loss: 2.15690187116464

Epoch: 173| Step: 0
Training loss: 1.4105818271636963
Validation loss: 2.141154686609904

Epoch: 5| Step: 1
Training loss: 1.0999212265014648
Validation loss: 2.1962805887063346

Epoch: 5| Step: 2
Training loss: 1.243579387664795
Validation loss: 2.1227558801571527

Epoch: 5| Step: 3
Training loss: 0.8146892786026001
Validation loss: 2.1424745619297028

Epoch: 5| Step: 4
Training loss: 0.8442916870117188
Validation loss: 2.116829971472422

Epoch: 5| Step: 5
Training loss: 0.5776971578598022
Validation loss: 2.1577489425738654

Epoch: 5| Step: 6
Training loss: 0.734986424446106
Validation loss: 2.212734341621399

Epoch: 5| Step: 7
Training loss: 0.9227384328842163
Validation loss: 2.2210091600815454

Epoch: 5| Step: 8
Training loss: 1.1371384859085083
Validation loss: 2.2201626201470694

Epoch: 5| Step: 9
Training loss: 0.9905179738998413
Validation loss: 2.209523782134056

Epoch: 5| Step: 10
Training loss: 0.6427723169326782
Validation loss: 2.2586266150077186

Epoch: 5| Step: 11
Training loss: 0.9567891359329224
Validation loss: 2.17225673298041

Epoch: 174| Step: 0
Training loss: 0.6545872092247009
Validation loss: 2.1207312643527985

Epoch: 5| Step: 1
Training loss: 1.0401941537857056
Validation loss: 2.125136141975721

Epoch: 5| Step: 2
Training loss: 1.1746900081634521
Validation loss: 2.2239539474248886

Epoch: 5| Step: 3
Training loss: 0.9093151092529297
Validation loss: 2.189003278811773

Epoch: 5| Step: 4
Training loss: 0.7822557687759399
Validation loss: 2.1366715182860694

Epoch: 5| Step: 5
Training loss: 1.1524890661239624
Validation loss: 2.130009805162748

Epoch: 5| Step: 6
Training loss: 0.9955169558525085
Validation loss: 2.195427576700846

Epoch: 5| Step: 7
Training loss: 1.1861317157745361
Validation loss: 2.277108614643415

Epoch: 5| Step: 8
Training loss: 0.6566183567047119
Validation loss: 2.1955467015504837

Epoch: 5| Step: 9
Training loss: 0.845577597618103
Validation loss: 2.258037363489469

Epoch: 5| Step: 10
Training loss: 0.6593121290206909
Validation loss: 2.1830366998910904

Epoch: 5| Step: 11
Training loss: 0.3327609896659851
Validation loss: 2.229994624853134

Epoch: 175| Step: 0
Training loss: 0.9579454660415649
Validation loss: 2.256844570239385

Epoch: 5| Step: 1
Training loss: 0.9755647778511047
Validation loss: 2.1983170807361603

Epoch: 5| Step: 2
Training loss: 0.5355662107467651
Validation loss: 2.2291103303432465

Epoch: 5| Step: 3
Training loss: 1.0877948999404907
Validation loss: 2.2013461043437323

Epoch: 5| Step: 4
Training loss: 0.7162501215934753
Validation loss: 2.2397870222727456

Epoch: 5| Step: 5
Training loss: 0.9541133046150208
Validation loss: 2.253550430138906

Epoch: 5| Step: 6
Training loss: 0.9054861068725586
Validation loss: 2.21807532509168

Epoch: 5| Step: 7
Training loss: 1.1652296781539917
Validation loss: 2.1721851179997125

Epoch: 5| Step: 8
Training loss: 0.9413453936576843
Validation loss: 2.181613579392433

Epoch: 5| Step: 9
Training loss: 0.5585728287696838
Validation loss: 2.1705161879460015

Epoch: 5| Step: 10
Training loss: 1.0200247764587402
Validation loss: 2.2137455691893897

Epoch: 5| Step: 11
Training loss: 1.1126940250396729
Validation loss: 2.2584562500317893

Epoch: 176| Step: 0
Training loss: 0.7762993574142456
Validation loss: 2.300505742430687

Epoch: 5| Step: 1
Training loss: 0.8579933047294617
Validation loss: 2.2177837590376535

Epoch: 5| Step: 2
Training loss: 0.9515589475631714
Validation loss: 2.280461842815081

Epoch: 5| Step: 3
Training loss: 1.0296627283096313
Validation loss: 2.2808895905812583

Epoch: 5| Step: 4
Training loss: 0.9783304333686829
Validation loss: 2.1111899465322495

Epoch: 5| Step: 5
Training loss: 0.7620158195495605
Validation loss: 2.1950937658548355

Epoch: 5| Step: 6
Training loss: 0.6472235918045044
Validation loss: 2.1626905699570975

Epoch: 5| Step: 7
Training loss: 1.1414685249328613
Validation loss: 2.140516142050425

Epoch: 5| Step: 8
Training loss: 0.7116373777389526
Validation loss: 2.166120926539103

Epoch: 5| Step: 9
Training loss: 0.6906487941741943
Validation loss: 2.163410017887751

Epoch: 5| Step: 10
Training loss: 0.8191716074943542
Validation loss: 2.1594807306925454

Epoch: 5| Step: 11
Training loss: 1.6854605674743652
Validation loss: 2.230731134613355

Epoch: 177| Step: 0
Training loss: 0.6276044249534607
Validation loss: 2.2360385159651437

Epoch: 5| Step: 1
Training loss: 1.009451150894165
Validation loss: 2.20411624511083

Epoch: 5| Step: 2
Training loss: 1.3650254011154175
Validation loss: 2.21462219953537

Epoch: 5| Step: 3
Training loss: 0.9740939140319824
Validation loss: 2.1681582083304725

Epoch: 5| Step: 4
Training loss: 0.8693410754203796
Validation loss: 2.1932289650042853

Epoch: 5| Step: 5
Training loss: 0.6950332522392273
Validation loss: 2.1248467713594437

Epoch: 5| Step: 6
Training loss: 0.8681546449661255
Validation loss: 2.168996647000313

Epoch: 5| Step: 7
Training loss: 0.5425125360488892
Validation loss: 2.185544192790985

Epoch: 5| Step: 8
Training loss: 0.9664192199707031
Validation loss: 2.235941161712011

Epoch: 5| Step: 9
Training loss: 0.9958814382553101
Validation loss: 2.120186318953832

Epoch: 5| Step: 10
Training loss: 0.920230507850647
Validation loss: 2.1823369016249976

Epoch: 5| Step: 11
Training loss: 0.44103503227233887
Validation loss: 2.148325761159261

Epoch: 178| Step: 0
Training loss: 0.8480603098869324
Validation loss: 2.153469701608022

Epoch: 5| Step: 1
Training loss: 0.89410001039505
Validation loss: 2.177911122639974

Epoch: 5| Step: 2
Training loss: 0.6440696716308594
Validation loss: 2.193673143784205

Epoch: 5| Step: 3
Training loss: 0.8916217088699341
Validation loss: 2.1590961615244546

Epoch: 5| Step: 4
Training loss: 0.9540302157402039
Validation loss: 2.2203564643859863

Epoch: 5| Step: 5
Training loss: 1.0900229215621948
Validation loss: 2.173060650626818

Epoch: 5| Step: 6
Training loss: 1.143538236618042
Validation loss: 2.1640853633483252

Epoch: 5| Step: 7
Training loss: 0.9578449130058289
Validation loss: 2.1890593667825065

Epoch: 5| Step: 8
Training loss: 0.9504894018173218
Validation loss: 2.227173258860906

Epoch: 5| Step: 9
Training loss: 0.6439161896705627
Validation loss: 2.2292310694853463

Epoch: 5| Step: 10
Training loss: 0.8035959005355835
Validation loss: 2.0584511359532676

Epoch: 5| Step: 11
Training loss: 0.685775101184845
Validation loss: 2.155232012271881

Epoch: 179| Step: 0
Training loss: 1.6337394714355469
Validation loss: 2.1152863750855126

Epoch: 5| Step: 1
Training loss: 0.5173423886299133
Validation loss: 2.0853984355926514

Epoch: 5| Step: 2
Training loss: 1.1463326215744019
Validation loss: 2.176294376452764

Epoch: 5| Step: 3
Training loss: 0.7541553974151611
Validation loss: 2.2354296346505484

Epoch: 5| Step: 4
Training loss: 0.842156708240509
Validation loss: 2.2800552447636924

Epoch: 5| Step: 5
Training loss: 0.7413640022277832
Validation loss: 2.2396618872880936

Epoch: 5| Step: 6
Training loss: 0.8891580700874329
Validation loss: 2.067508334914843

Epoch: 5| Step: 7
Training loss: 1.039555311203003
Validation loss: 2.198887382944425

Epoch: 5| Step: 8
Training loss: 0.6965662240982056
Validation loss: 2.1336074521144233

Epoch: 5| Step: 9
Training loss: 0.6192862391471863
Validation loss: 2.1379898885885873

Epoch: 5| Step: 10
Training loss: 0.8267402648925781
Validation loss: 2.20827188094457

Epoch: 5| Step: 11
Training loss: 0.8766484260559082
Validation loss: 2.141211912035942

Epoch: 180| Step: 0
Training loss: 0.7071155309677124
Validation loss: 2.162590498725573

Epoch: 5| Step: 1
Training loss: 1.0584657192230225
Validation loss: 2.277874062458674

Epoch: 5| Step: 2
Training loss: 0.7568311095237732
Validation loss: 2.2845077514648438

Epoch: 5| Step: 3
Training loss: 0.8177816271781921
Validation loss: 2.2746022641658783

Epoch: 5| Step: 4
Training loss: 0.8506864309310913
Validation loss: 2.2253003964821496

Epoch: 5| Step: 5
Training loss: 0.8547722697257996
Validation loss: 2.21371399362882

Epoch: 5| Step: 6
Training loss: 0.9583250880241394
Validation loss: 2.116801679134369

Epoch: 5| Step: 7
Training loss: 1.003883719444275
Validation loss: 2.215091362595558

Epoch: 5| Step: 8
Training loss: 0.9081940650939941
Validation loss: 2.230910211801529

Epoch: 5| Step: 9
Training loss: 1.320755958557129
Validation loss: 2.1731216311454773

Epoch: 5| Step: 10
Training loss: 0.9338012933731079
Validation loss: 2.162683844566345

Epoch: 5| Step: 11
Training loss: 0.6417121887207031
Validation loss: 2.17582930624485

Epoch: 181| Step: 0
Training loss: 0.9997684359550476
Validation loss: 2.2048248449961343

Epoch: 5| Step: 1
Training loss: 0.9425204992294312
Validation loss: 2.1700559109449387

Epoch: 5| Step: 2
Training loss: 0.7963409423828125
Validation loss: 2.234673966964086

Epoch: 5| Step: 3
Training loss: 0.8759845495223999
Validation loss: 2.2128293414910636

Epoch: 5| Step: 4
Training loss: 0.6434264779090881
Validation loss: 2.2098218500614166

Epoch: 5| Step: 5
Training loss: 0.969859778881073
Validation loss: 2.231681893269221

Epoch: 5| Step: 6
Training loss: 0.8439272046089172
Validation loss: 2.2207077741622925

Epoch: 5| Step: 7
Training loss: 0.9101723432540894
Validation loss: 2.109336793422699

Epoch: 5| Step: 8
Training loss: 0.9815926551818848
Validation loss: 2.1867237389087677

Epoch: 5| Step: 9
Training loss: 0.8795188665390015
Validation loss: 2.16185499727726

Epoch: 5| Step: 10
Training loss: 0.6538469195365906
Validation loss: 2.1731929928064346

Epoch: 5| Step: 11
Training loss: 1.7647228240966797
Validation loss: 2.1835778703292212

Epoch: 182| Step: 0
Training loss: 0.862123966217041
Validation loss: 2.1644373883803687

Epoch: 5| Step: 1
Training loss: 0.9705659747123718
Validation loss: 2.2145967930555344

Epoch: 5| Step: 2
Training loss: 0.8582416772842407
Validation loss: 2.2640050798654556

Epoch: 5| Step: 3
Training loss: 0.8568973541259766
Validation loss: 2.2161617279052734

Epoch: 5| Step: 4
Training loss: 1.014028787612915
Validation loss: 2.2393481185038886

Epoch: 5| Step: 5
Training loss: 1.169193148612976
Validation loss: 2.2672675599654517

Epoch: 5| Step: 6
Training loss: 1.0255126953125
Validation loss: 2.1271717846393585

Epoch: 5| Step: 7
Training loss: 0.8109227418899536
Validation loss: 2.1699526011943817

Epoch: 5| Step: 8
Training loss: 0.9421383738517761
Validation loss: 2.1094943583011627

Epoch: 5| Step: 9
Training loss: 0.7723183035850525
Validation loss: 2.161798968911171

Epoch: 5| Step: 10
Training loss: 0.7924829721450806
Validation loss: 2.246400664250056

Epoch: 5| Step: 11
Training loss: 1.2564624547958374
Validation loss: 2.2816300888856254

Epoch: 183| Step: 0
Training loss: 0.7497574090957642
Validation loss: 2.2556817134221396

Epoch: 5| Step: 1
Training loss: 0.7564979791641235
Validation loss: 2.289688229560852

Epoch: 5| Step: 2
Training loss: 0.8649640083312988
Validation loss: 2.235245073835055

Epoch: 5| Step: 3
Training loss: 0.5357238054275513
Validation loss: 2.1914375573396683

Epoch: 5| Step: 4
Training loss: 0.6799367070198059
Validation loss: 2.282502770423889

Epoch: 5| Step: 5
Training loss: 0.7778934240341187
Validation loss: 2.2291632195313773

Epoch: 5| Step: 6
Training loss: 1.1076924800872803
Validation loss: 2.2068863014380136

Epoch: 5| Step: 7
Training loss: 0.6749943494796753
Validation loss: 2.2794858515262604

Epoch: 5| Step: 8
Training loss: 1.1033023595809937
Validation loss: 2.198074887196223

Epoch: 5| Step: 9
Training loss: 1.2731691598892212
Validation loss: 2.20298133790493

Epoch: 5| Step: 10
Training loss: 1.3564974069595337
Validation loss: 2.1482072472572327

Epoch: 5| Step: 11
Training loss: 0.9908885955810547
Validation loss: 2.1435554126898446

Epoch: 184| Step: 0
Training loss: 0.7740090489387512
Validation loss: 2.1892286241054535

Epoch: 5| Step: 1
Training loss: 1.247408151626587
Validation loss: 2.2199038018782935

Epoch: 5| Step: 2
Training loss: 0.7215712070465088
Validation loss: 2.1789360344409943

Epoch: 5| Step: 3
Training loss: 0.5339399576187134
Validation loss: 2.1920708070198693

Epoch: 5| Step: 4
Training loss: 0.6106041669845581
Validation loss: 2.2192239463329315

Epoch: 5| Step: 5
Training loss: 0.7403943538665771
Validation loss: 2.224979887406031

Epoch: 5| Step: 6
Training loss: 0.833207905292511
Validation loss: 2.202344765265783

Epoch: 5| Step: 7
Training loss: 0.7128016352653503
Validation loss: 2.194082443912824

Epoch: 5| Step: 8
Training loss: 1.2956291437149048
Validation loss: 2.135620971520742

Epoch: 5| Step: 9
Training loss: 1.414254903793335
Validation loss: 2.20647161702315

Epoch: 5| Step: 10
Training loss: 0.9716211557388306
Validation loss: 2.142747645576795

Epoch: 5| Step: 11
Training loss: 1.3692885637283325
Validation loss: 2.1595817108949027

Epoch: 185| Step: 0
Training loss: 0.8084351420402527
Validation loss: 2.0989607671896615

Epoch: 5| Step: 1
Training loss: 1.3526804447174072
Validation loss: 2.2131690432627997

Epoch: 5| Step: 2
Training loss: 0.6200240254402161
Validation loss: 2.199195444583893

Epoch: 5| Step: 3
Training loss: 0.8705235719680786
Validation loss: 2.1550880620876947

Epoch: 5| Step: 4
Training loss: 0.6191002726554871
Validation loss: 2.2260223974784217

Epoch: 5| Step: 5
Training loss: 0.7799969911575317
Validation loss: 2.1664075205723443

Epoch: 5| Step: 6
Training loss: 1.505248785018921
Validation loss: 2.1789569556713104

Epoch: 5| Step: 7
Training loss: 0.8745368719100952
Validation loss: 2.232534353931745

Epoch: 5| Step: 8
Training loss: 0.550796627998352
Validation loss: 2.2072062542041144

Epoch: 5| Step: 9
Training loss: 0.8787476420402527
Validation loss: 2.1304983844359717

Epoch: 5| Step: 10
Training loss: 0.6328383684158325
Validation loss: 2.1709467271963754

Epoch: 5| Step: 11
Training loss: 0.3666614294052124
Validation loss: 2.210590491692225

Epoch: 186| Step: 0
Training loss: 1.1882432699203491
Validation loss: 2.1390044589837394

Epoch: 5| Step: 1
Training loss: 0.923662006855011
Validation loss: 2.189172883828481

Epoch: 5| Step: 2
Training loss: 0.8732494115829468
Validation loss: 2.159362996617953

Epoch: 5| Step: 3
Training loss: 0.781609833240509
Validation loss: 2.261242891351382

Epoch: 5| Step: 4
Training loss: 0.885240375995636
Validation loss: 2.196932772795359

Epoch: 5| Step: 5
Training loss: 0.6669923067092896
Validation loss: 2.213804935415586

Epoch: 5| Step: 6
Training loss: 0.8373411297798157
Validation loss: 2.083682417869568

Epoch: 5| Step: 7
Training loss: 0.6651695966720581
Validation loss: 2.1554823915163674

Epoch: 5| Step: 8
Training loss: 1.2273156642913818
Validation loss: 2.1641402741273246

Epoch: 5| Step: 9
Training loss: 0.9187936782836914
Validation loss: 2.1484858443339667

Epoch: 5| Step: 10
Training loss: 0.7022470831871033
Validation loss: 2.1578013648589454

Epoch: 5| Step: 11
Training loss: 0.8472097516059875
Validation loss: 2.1050554662942886

Epoch: 187| Step: 0
Training loss: 0.455376535654068
Validation loss: 2.1873027682304382

Epoch: 5| Step: 1
Training loss: 1.1582484245300293
Validation loss: 2.160314361254374

Epoch: 5| Step: 2
Training loss: 0.8964322805404663
Validation loss: 2.201231747865677

Epoch: 5| Step: 3
Training loss: 0.9114595651626587
Validation loss: 2.2546979635953903

Epoch: 5| Step: 4
Training loss: 1.3648608922958374
Validation loss: 2.145722190539042

Epoch: 5| Step: 5
Training loss: 0.6557285785675049
Validation loss: 2.177380214134852

Epoch: 5| Step: 6
Training loss: 0.9417740702629089
Validation loss: 2.1574055502812066

Epoch: 5| Step: 7
Training loss: 1.1097691059112549
Validation loss: 2.2031064927577972

Epoch: 5| Step: 8
Training loss: 0.723440945148468
Validation loss: 2.095293636123339

Epoch: 5| Step: 9
Training loss: 1.0242595672607422
Validation loss: 2.20813683172067

Epoch: 5| Step: 10
Training loss: 0.5345453023910522
Validation loss: 2.1656442483266196

Epoch: 5| Step: 11
Training loss: 0.9208289980888367
Validation loss: 2.082357486089071

Epoch: 188| Step: 0
Training loss: 0.6248945593833923
Validation loss: 2.2920939524968467

Epoch: 5| Step: 1
Training loss: 1.1288446187973022
Validation loss: 2.184130306045214

Epoch: 5| Step: 2
Training loss: 1.0326998233795166
Validation loss: 2.08586714665095

Epoch: 5| Step: 3
Training loss: 0.9640651941299438
Validation loss: 2.229784289995829

Epoch: 5| Step: 4
Training loss: 0.7350783348083496
Validation loss: 2.1880960365136466

Epoch: 5| Step: 5
Training loss: 1.0568418502807617
Validation loss: 2.1946027477582297

Epoch: 5| Step: 6
Training loss: 1.0460476875305176
Validation loss: 2.1405026614665985

Epoch: 5| Step: 7
Training loss: 0.6867550611495972
Validation loss: 2.205417970816294

Epoch: 5| Step: 8
Training loss: 0.8261960744857788
Validation loss: 2.256270339091619

Epoch: 5| Step: 9
Training loss: 1.0801734924316406
Validation loss: 2.176279495159785

Epoch: 5| Step: 10
Training loss: 0.9277101755142212
Validation loss: 2.2255534629027047

Epoch: 5| Step: 11
Training loss: 0.7370521426200867
Validation loss: 2.2156480103731155

Epoch: 189| Step: 0
Training loss: 0.8207724690437317
Validation loss: 2.113497257232666

Epoch: 5| Step: 1
Training loss: 1.127868890762329
Validation loss: 2.2065375298261642

Epoch: 5| Step: 2
Training loss: 0.8236145973205566
Validation loss: 2.2062061429023743

Epoch: 5| Step: 3
Training loss: 0.8339959979057312
Validation loss: 2.165037895242373

Epoch: 5| Step: 4
Training loss: 0.6889567971229553
Validation loss: 2.224420020977656

Epoch: 5| Step: 5
Training loss: 0.7798935770988464
Validation loss: 2.248263508081436

Epoch: 5| Step: 6
Training loss: 0.7694304585456848
Validation loss: 2.1665511777003608

Epoch: 5| Step: 7
Training loss: 0.6134400963783264
Validation loss: 2.1655742526054382

Epoch: 5| Step: 8
Training loss: 0.43705934286117554
Validation loss: 2.293914477030436

Epoch: 5| Step: 9
Training loss: 1.1789747476577759
Validation loss: 2.233296791712443

Epoch: 5| Step: 10
Training loss: 0.9746978878974915
Validation loss: 2.2083331247170768

Epoch: 5| Step: 11
Training loss: 0.6437308192253113
Validation loss: 2.2035269985596337

Epoch: 190| Step: 0
Training loss: 0.8786748051643372
Validation loss: 2.1750387897094092

Epoch: 5| Step: 1
Training loss: 0.5971469879150391
Validation loss: 2.1464208513498306

Epoch: 5| Step: 2
Training loss: 1.1205213069915771
Validation loss: 2.2471884191036224

Epoch: 5| Step: 3
Training loss: 0.6103410124778748
Validation loss: 2.265849232673645

Epoch: 5| Step: 4
Training loss: 0.9063909649848938
Validation loss: 2.2667545080184937

Epoch: 5| Step: 5
Training loss: 0.5245534777641296
Validation loss: 2.1890520552794137

Epoch: 5| Step: 6
Training loss: 0.7468905448913574
Validation loss: 2.2524030903975167

Epoch: 5| Step: 7
Training loss: 0.8073250651359558
Validation loss: 2.2801450391610465

Epoch: 5| Step: 8
Training loss: 1.421478509902954
Validation loss: 2.2034393747647605

Epoch: 5| Step: 9
Training loss: 0.7830667495727539
Validation loss: 2.1374079237381616

Epoch: 5| Step: 10
Training loss: 0.7094801068305969
Validation loss: 2.165761282046636

Epoch: 5| Step: 11
Training loss: 1.1949459314346313
Validation loss: 2.1435395628213882

Epoch: 191| Step: 0
Training loss: 1.0951191186904907
Validation loss: 2.1399273176987967

Epoch: 5| Step: 1
Training loss: 1.0409388542175293
Validation loss: 2.295441413919131

Epoch: 5| Step: 2
Training loss: 0.6980136632919312
Validation loss: 2.1671371161937714

Epoch: 5| Step: 3
Training loss: 0.878210723400116
Validation loss: 2.219456156094869

Epoch: 5| Step: 4
Training loss: 0.6656940579414368
Validation loss: 2.246213366587957

Epoch: 5| Step: 5
Training loss: 0.8732171058654785
Validation loss: 2.1589599748452506

Epoch: 5| Step: 6
Training loss: 0.7452685236930847
Validation loss: 2.166308214267095

Epoch: 5| Step: 7
Training loss: 0.718328595161438
Validation loss: 2.2246476113796234

Epoch: 5| Step: 8
Training loss: 1.0253174304962158
Validation loss: 2.2326808174451194

Epoch: 5| Step: 9
Training loss: 0.8036218881607056
Validation loss: 2.2156651268402734

Epoch: 5| Step: 10
Training loss: 0.7532846331596375
Validation loss: 2.24913160999616

Epoch: 5| Step: 11
Training loss: 1.1385629177093506
Validation loss: 2.2307955076297126

Epoch: 192| Step: 0
Training loss: 0.7603782415390015
Validation loss: 2.2560640076796212

Epoch: 5| Step: 1
Training loss: 0.7614390850067139
Validation loss: 2.1958508590857186

Epoch: 5| Step: 2
Training loss: 0.855789065361023
Validation loss: 2.128824681043625

Epoch: 5| Step: 3
Training loss: 0.7345370054244995
Validation loss: 2.2465777893861136

Epoch: 5| Step: 4
Training loss: 0.968130886554718
Validation loss: 2.092419366041819

Epoch: 5| Step: 5
Training loss: 0.7163491249084473
Validation loss: 2.081489086151123

Epoch: 5| Step: 6
Training loss: 1.3915125131607056
Validation loss: 2.1913283665974936

Epoch: 5| Step: 7
Training loss: 0.5220935940742493
Validation loss: 2.1674960801998773

Epoch: 5| Step: 8
Training loss: 0.7027595639228821
Validation loss: 2.1206162869930267

Epoch: 5| Step: 9
Training loss: 0.852098286151886
Validation loss: 2.29788930217425

Epoch: 5| Step: 10
Training loss: 1.0214483737945557
Validation loss: 2.2325233270724616

Epoch: 5| Step: 11
Training loss: 1.0631599426269531
Validation loss: 2.207486778497696

Epoch: 193| Step: 0
Training loss: 1.1521732807159424
Validation loss: 2.230176498492559

Epoch: 5| Step: 1
Training loss: 0.7426831126213074
Validation loss: 2.164240931471189

Epoch: 5| Step: 2
Training loss: 0.661221981048584
Validation loss: 2.217269003391266

Epoch: 5| Step: 3
Training loss: 0.8316540718078613
Validation loss: 2.173160766561826

Epoch: 5| Step: 4
Training loss: 0.6118124723434448
Validation loss: 2.1115065614382424

Epoch: 5| Step: 5
Training loss: 0.8471242189407349
Validation loss: 2.24346587061882

Epoch: 5| Step: 6
Training loss: 0.7655376195907593
Validation loss: 2.219305435816447

Epoch: 5| Step: 7
Training loss: 0.6310665011405945
Validation loss: 2.0781030853589377

Epoch: 5| Step: 8
Training loss: 0.7286224365234375
Validation loss: 2.144838194052378

Epoch: 5| Step: 9
Training loss: 0.6122569441795349
Validation loss: 2.1616528977950416

Epoch: 5| Step: 10
Training loss: 1.321822166442871
Validation loss: 2.179887364308039

Epoch: 5| Step: 11
Training loss: 0.6529740691184998
Validation loss: 2.1825690269470215

Epoch: 194| Step: 0
Training loss: 0.7827355265617371
Validation loss: 2.1438673039277396

Epoch: 5| Step: 1
Training loss: 1.042884111404419
Validation loss: 2.190932641426722

Epoch: 5| Step: 2
Training loss: 0.7011345624923706
Validation loss: 2.1942709187666574

Epoch: 5| Step: 3
Training loss: 0.9402238726615906
Validation loss: 2.1747324417034783

Epoch: 5| Step: 4
Training loss: 0.3616211712360382
Validation loss: 2.202166805664698

Epoch: 5| Step: 5
Training loss: 0.5885171890258789
Validation loss: 2.1740056027968726

Epoch: 5| Step: 6
Training loss: 0.8797087669372559
Validation loss: 2.2281851222117743

Epoch: 5| Step: 7
Training loss: 0.6259757280349731
Validation loss: 2.145904908577601

Epoch: 5| Step: 8
Training loss: 0.8963766098022461
Validation loss: 2.160770426193873

Epoch: 5| Step: 9
Training loss: 0.6249310374259949
Validation loss: 2.2670923123757043

Epoch: 5| Step: 10
Training loss: 1.444524884223938
Validation loss: 2.1784165849288306

Epoch: 5| Step: 11
Training loss: 0.6380065083503723
Validation loss: 2.2050736844539642

Epoch: 195| Step: 0
Training loss: 1.0860527753829956
Validation loss: 2.2645839850107827

Epoch: 5| Step: 1
Training loss: 0.8838841319084167
Validation loss: 2.251395990451177

Epoch: 5| Step: 2
Training loss: 0.7205173373222351
Validation loss: 2.2285949091116586

Epoch: 5| Step: 3
Training loss: 0.9431971311569214
Validation loss: 2.199097832043966

Epoch: 5| Step: 4
Training loss: 0.7888079285621643
Validation loss: 2.2313966850439706

Epoch: 5| Step: 5
Training loss: 0.850864052772522
Validation loss: 2.1935466080904007

Epoch: 5| Step: 6
Training loss: 0.9053239822387695
Validation loss: 2.184531663854917

Epoch: 5| Step: 7
Training loss: 1.1341298818588257
Validation loss: 2.141343414783478

Epoch: 5| Step: 8
Training loss: 0.7283870577812195
Validation loss: 2.1710658371448517

Epoch: 5| Step: 9
Training loss: 0.6734627485275269
Validation loss: 2.141140639781952

Epoch: 5| Step: 10
Training loss: 1.0980833768844604
Validation loss: 2.252127985159556

Epoch: 5| Step: 11
Training loss: 0.2736423909664154
Validation loss: 2.284911205371221

Epoch: 196| Step: 0
Training loss: 0.9744882583618164
Validation loss: 2.244814266761144

Epoch: 5| Step: 1
Training loss: 0.7352612018585205
Validation loss: 2.2520668109258017

Epoch: 5| Step: 2
Training loss: 0.5483992099761963
Validation loss: 2.1933212876319885

Epoch: 5| Step: 3
Training loss: 1.172615647315979
Validation loss: 2.2408726463715234

Epoch: 5| Step: 4
Training loss: 1.064915657043457
Validation loss: 2.1864432046810784

Epoch: 5| Step: 5
Training loss: 1.2188640832901
Validation loss: 2.20069686571757

Epoch: 5| Step: 6
Training loss: 0.9943153262138367
Validation loss: 2.180902729431788

Epoch: 5| Step: 7
Training loss: 0.8063830137252808
Validation loss: 2.2010943045218787

Epoch: 5| Step: 8
Training loss: 0.930972695350647
Validation loss: 2.251576046148936

Epoch: 5| Step: 9
Training loss: 0.803496241569519
Validation loss: 2.3726665576299033

Epoch: 5| Step: 10
Training loss: 1.1384613513946533
Validation loss: 2.3729643573363624

Epoch: 5| Step: 11
Training loss: 1.2575156688690186
Validation loss: 2.3210312028725943

Epoch: 197| Step: 0
Training loss: 0.6365761756896973
Validation loss: 2.2947944800059

Epoch: 5| Step: 1
Training loss: 0.9716598391532898
Validation loss: 2.1261729151010513

Epoch: 5| Step: 2
Training loss: 0.9470096826553345
Validation loss: 2.189685250322024

Epoch: 5| Step: 3
Training loss: 1.1430914402008057
Validation loss: 2.1594011733929315

Epoch: 5| Step: 4
Training loss: 1.0596015453338623
Validation loss: 2.1983350068330765

Epoch: 5| Step: 5
Training loss: 0.8761258125305176
Validation loss: 2.171223521232605

Epoch: 5| Step: 6
Training loss: 0.6596603393554688
Validation loss: 2.1568959951400757

Epoch: 5| Step: 7
Training loss: 0.5414993762969971
Validation loss: 2.2402265469233194

Epoch: 5| Step: 8
Training loss: 1.3413316011428833
Validation loss: 2.2123170693715415

Epoch: 5| Step: 9
Training loss: 0.7624320387840271
Validation loss: 2.2091720203558602

Epoch: 5| Step: 10
Training loss: 0.9656274914741516
Validation loss: 2.245385025938352

Epoch: 5| Step: 11
Training loss: 0.4756511449813843
Validation loss: 2.250706747174263

Epoch: 198| Step: 0
Training loss: 0.5624842047691345
Validation loss: 2.2229985197385154

Epoch: 5| Step: 1
Training loss: 0.8739288449287415
Validation loss: 2.2410789728164673

Epoch: 5| Step: 2
Training loss: 0.6272722482681274
Validation loss: 2.217051366964976

Epoch: 5| Step: 3
Training loss: 0.6536887884140015
Validation loss: 2.208710918823878

Epoch: 5| Step: 4
Training loss: 0.8139604330062866
Validation loss: 2.2592688451210656

Epoch: 5| Step: 5
Training loss: 0.6438891887664795
Validation loss: 2.201854482293129

Epoch: 5| Step: 6
Training loss: 1.0942516326904297
Validation loss: 2.2228476454814277

Epoch: 5| Step: 7
Training loss: 1.0506031513214111
Validation loss: 2.325821965932846

Epoch: 5| Step: 8
Training loss: 0.6568565964698792
Validation loss: 2.2549989024798074

Epoch: 5| Step: 9
Training loss: 1.3413867950439453
Validation loss: 2.2650001645088196

Epoch: 5| Step: 10
Training loss: 0.7102791666984558
Validation loss: 2.37458265821139

Epoch: 5| Step: 11
Training loss: 0.6435797214508057
Validation loss: 2.2968589266141257

Epoch: 199| Step: 0
Training loss: 0.8251228332519531
Validation loss: 2.1994586487611136

Epoch: 5| Step: 1
Training loss: 1.1132104396820068
Validation loss: 2.228031570712725

Epoch: 5| Step: 2
Training loss: 0.8360714912414551
Validation loss: 2.141368548075358

Epoch: 5| Step: 3
Training loss: 0.7653390169143677
Validation loss: 2.1900164435307183

Epoch: 5| Step: 4
Training loss: 1.2400050163269043
Validation loss: 2.2183579951524734

Epoch: 5| Step: 5
Training loss: 1.269883155822754
Validation loss: 2.2823540369669595

Epoch: 5| Step: 6
Training loss: 0.6952728033065796
Validation loss: 2.215458964308103

Epoch: 5| Step: 7
Training loss: 0.6180264949798584
Validation loss: 2.2054837296406427

Epoch: 5| Step: 8
Training loss: 0.5870763063430786
Validation loss: 2.2591756184895835

Epoch: 5| Step: 9
Training loss: 0.7536720037460327
Validation loss: 2.2731052339076996

Epoch: 5| Step: 10
Training loss: 0.8006669878959656
Validation loss: 2.299080342054367

Epoch: 5| Step: 11
Training loss: 0.5906323194503784
Validation loss: 2.310105045636495

Epoch: 200| Step: 0
Training loss: 0.6811909675598145
Validation loss: 2.1363793114821115

Epoch: 5| Step: 1
Training loss: 0.5864786505699158
Validation loss: 2.2026200791200004

Epoch: 5| Step: 2
Training loss: 0.7649227380752563
Validation loss: 2.081547369559606

Epoch: 5| Step: 3
Training loss: 1.071103811264038
Validation loss: 2.1667544891436896

Epoch: 5| Step: 4
Training loss: 1.0747160911560059
Validation loss: 2.14443376660347

Epoch: 5| Step: 5
Training loss: 1.0878181457519531
Validation loss: 2.215397576491038

Epoch: 5| Step: 6
Training loss: 0.8788543939590454
Validation loss: 2.239825800061226

Epoch: 5| Step: 7
Training loss: 0.5358480215072632
Validation loss: 2.179021586974462

Epoch: 5| Step: 8
Training loss: 0.8342220187187195
Validation loss: 2.2193650603294373

Epoch: 5| Step: 9
Training loss: 1.0898067951202393
Validation loss: 2.2180998226006827

Epoch: 5| Step: 10
Training loss: 1.2286609411239624
Validation loss: 2.271111845970154

Epoch: 5| Step: 11
Training loss: 1.2650506496429443
Validation loss: 2.258097395300865

Testing loss: 1.9727913081217154
