Epoch: 1| Step: 0
Training loss: 3.2718848868642407
Validation loss: 3.5938523841696774
Epoch: 7| Step: 1
Training loss: 4.242328002176606
Validation loss: 3.6123557080081996
Epoch: 7| Step: 2
Training loss: 3.337891196423298
Validation loss: 3.6016681218409587
Epoch: 7| Step: 3
Training loss: 3.356531829651242
Validation loss: 3.579945877414441
Epoch: 7| Step: 4
Training loss: 4.129117355796448
Validation loss: 3.580158505862913
Epoch: 7| Step: 5
Training loss: 3.2520026859023674
Validation loss: 3.5755019573545455
Epoch: 7| Step: 6
Training loss: 4.324782861098844
Validation loss: 3.579513732344565
Epoch: 7| Step: 7
Training loss: 4.029933034184286
Validation loss: 3.560529457523964
Epoch: 7| Step: 8
Training loss: 4.765723055471759
Validation loss: 3.5373570591147243
Epoch: 7| Step: 9
Training loss: 4.263157392802962
Validation loss: 3.5298971272667132
Epoch: 7| Step: 10
Training loss: 4.4223330634543
Validation loss: 3.5345504240571155
Epoch: 7| Step: 11
Training loss: 3.083472704100225
Validation loss: 3.515924596134789
Epoch: 7| Step: 12
Training loss: 4.426272951641328
Validation loss: 3.5107697400748146
Epoch: 7| Step: 13
Training loss: 3.7453305736960263
Validation loss: 3.515948469231551
Epoch: 7| Step: 14
Training loss: 4.335371320720451
Validation loss: 3.485114012217921
Epoch: 7| Step: 15
Training loss: 4.779663820136361
Validation loss: 3.516772946734846
Epoch: 2| Step: 0
Training loss: 2.9950245288487642
Validation loss: 3.503599152060434
Epoch: 7| Step: 1
Training loss: 4.149060448607753
Validation loss: 3.4927308880531496
Epoch: 7| Step: 2
Training loss: 3.797063501019429
Validation loss: 3.478452655454626
Epoch: 7| Step: 3
Training loss: 4.117127043481059
Validation loss: 3.46839290483521
Epoch: 7| Step: 4
Training loss: 3.862858362455651
Validation loss: 3.4806203534583307
Epoch: 7| Step: 5
Training loss: 3.9174741088556906
Validation loss: 3.4752065413865227
Epoch: 7| Step: 6
Training loss: 3.5417555105996223
Validation loss: 3.457041523542905
Epoch: 7| Step: 7
Training loss: 3.741330871013865
Validation loss: 3.4536614009595326
Epoch: 7| Step: 8
Training loss: 4.240000461362418
Validation loss: 3.4423335221636053
Epoch: 7| Step: 9
Training loss: 4.371282687633583
Validation loss: 3.4369013906488894
Epoch: 7| Step: 10
Training loss: 3.4375545150595572
Validation loss: 3.42815870414153
Epoch: 7| Step: 11
Training loss: 4.302062298567043
Validation loss: 3.425190843624757
Epoch: 7| Step: 12
Training loss: 3.8441759819371613
Validation loss: 3.399840676335704
Epoch: 7| Step: 13
Training loss: 4.302377292051358
Validation loss: 3.3990669734220433
Epoch: 7| Step: 14
Training loss: 3.4981354787948007
Validation loss: 3.3932871641564795
Epoch: 7| Step: 15
Training loss: 4.21934742406175
Validation loss: 3.3850900019485373
Epoch: 3| Step: 0
Training loss: 2.555649415886335
Validation loss: 3.3730119522348923
Epoch: 7| Step: 1
Training loss: 3.663617527993125
Validation loss: 3.3643219940656164
Epoch: 7| Step: 2
Training loss: 4.014451861179499
Validation loss: 3.3704337854280833
Epoch: 7| Step: 3
Training loss: 3.4472317356248507
Validation loss: 3.3478411398150585
Epoch: 7| Step: 4
Training loss: 3.22713614991722
Validation loss: 3.3532231985607197
Epoch: 7| Step: 5
Training loss: 3.80824041830583
Validation loss: 3.339518772656269
Epoch: 7| Step: 6
Training loss: 4.545976792591367
Validation loss: 3.32967110130654
Epoch: 7| Step: 7
Training loss: 3.4716608704219296
Validation loss: 3.33246377985794
Epoch: 7| Step: 8
Training loss: 4.211675519089829
Validation loss: 3.32078995118696
Epoch: 7| Step: 9
Training loss: 3.829234931566985
Validation loss: 3.2917723842421056
Epoch: 7| Step: 10
Training loss: 4.623470569014046
Validation loss: 3.29797727318224
Epoch: 7| Step: 11
Training loss: 3.5915711805450656
Validation loss: 3.2734520527291466
Epoch: 7| Step: 12
Training loss: 3.9793945300517346
Validation loss: 3.2781206242592655
Epoch: 7| Step: 13
Training loss: 3.6439447943047147
Validation loss: 3.260145368043425
Epoch: 7| Step: 14
Training loss: 4.221244696065086
Validation loss: 3.2669144384376625
Epoch: 7| Step: 15
Training loss: 3.3663089606231305
Validation loss: 3.258708424473254
Epoch: 4| Step: 0
Training loss: 3.663933790341649
Validation loss: 3.2065011684005675
Epoch: 7| Step: 1
Training loss: 3.666522081009772
Validation loss: 3.2151137157591387
Epoch: 7| Step: 2
Training loss: 4.278648087014711
Validation loss: 3.23509729060639
Epoch: 7| Step: 3
Training loss: 3.257814549141292
Validation loss: 3.2116279022883476
Epoch: 7| Step: 4
Training loss: 3.4566469485371303
Validation loss: 3.204787794422515
Epoch: 7| Step: 5
Training loss: 3.5474014227668182
Validation loss: 3.169336555288856
Epoch: 7| Step: 6
Training loss: 3.607179444598262
Validation loss: 3.188876937347405
Epoch: 7| Step: 7
Training loss: 3.3704568873546803
Validation loss: 3.1833113903429977
Epoch: 7| Step: 8
Training loss: 4.382982655314428
Validation loss: 3.1707938322275004
Epoch: 7| Step: 9
Training loss: 3.73665609879464
Validation loss: 3.1640589014010567
Epoch: 7| Step: 10
Training loss: 4.082526977225673
Validation loss: 3.135498478123925
Epoch: 7| Step: 11
Training loss: 3.3664813440764303
Validation loss: 3.140008961373243
Epoch: 7| Step: 12
Training loss: 3.64683455025567
Validation loss: 3.1259129754465076
Epoch: 7| Step: 13
Training loss: 3.5161598985439935
Validation loss: 3.133977031892623
Epoch: 7| Step: 14
Training loss: 3.3494095011430978
Validation loss: 3.0949860377649943
Epoch: 7| Step: 15
Training loss: 3.509918192592096
Validation loss: 3.089045565791184
Epoch: 5| Step: 0
Training loss: 4.265098008240544
Validation loss: 3.080191766081127
Epoch: 7| Step: 1
Training loss: 2.8853989656825814
Validation loss: 3.080363370072407
Epoch: 7| Step: 2
Training loss: 3.6226603093555405
Validation loss: 3.076945296138444
Epoch: 7| Step: 3
Training loss: 3.6338641213525875
Validation loss: 3.0681077398929024
Epoch: 7| Step: 4
Training loss: 3.3608958505544213
Validation loss: 3.027640263111079
Epoch: 7| Step: 5
Training loss: 3.07010345135573
Validation loss: 3.0423566952438468
Epoch: 7| Step: 6
Training loss: 3.0172696545408217
Validation loss: 3.0367072114938245
Epoch: 7| Step: 7
Training loss: 4.035985959212924
Validation loss: 3.0314058236517742
Epoch: 7| Step: 8
Training loss: 3.5335418555670097
Validation loss: 3.0046759462971435
Epoch: 7| Step: 9
Training loss: 3.6005023711739312
Validation loss: 3.005466196129428
Epoch: 7| Step: 10
Training loss: 3.8089747155217357
Validation loss: 2.9693608473471795
Epoch: 7| Step: 11
Training loss: 3.6246766571006406
Validation loss: 2.981673003857151
Epoch: 7| Step: 12
Training loss: 3.3963234826577606
Validation loss: 2.9622334078025867
Epoch: 7| Step: 13
Training loss: 3.3987885392512873
Validation loss: 2.9360897929245473
Epoch: 7| Step: 14
Training loss: 3.6024703662720343
Validation loss: 2.9601141915751104
Epoch: 7| Step: 15
Training loss: 3.159587643916504
Validation loss: 2.928565892750108
Epoch: 6| Step: 0
Training loss: 3.4491207329203815
Validation loss: 2.9052764025367885
Epoch: 7| Step: 1
Training loss: 3.813049902108447
Validation loss: 2.913422556713687
Epoch: 7| Step: 2
Training loss: 3.673911061788132
Validation loss: 2.898209863229956
Epoch: 7| Step: 3
Training loss: 3.182710377586251
Validation loss: 2.887921775826333
Epoch: 7| Step: 4
Training loss: 4.063215222122031
Validation loss: 2.8836521057421654
Epoch: 7| Step: 5
Training loss: 3.332229590466284
Validation loss: 2.8677399691370873
Epoch: 7| Step: 6
Training loss: 3.455270782326505
Validation loss: 2.8407018958328902
Epoch: 7| Step: 7
Training loss: 3.3660025580538697
Validation loss: 2.85245005828094
Epoch: 7| Step: 8
Training loss: 3.7778025903697245
Validation loss: 2.8355384878418386
Epoch: 7| Step: 9
Training loss: 2.286380381258275
Validation loss: 2.8112000130810597
Epoch: 7| Step: 10
Training loss: 3.1157862829094363
Validation loss: 2.790095252973841
Epoch: 7| Step: 11
Training loss: 3.752748626462738
Validation loss: 2.79785865741262
Epoch: 7| Step: 12
Training loss: 2.8713935124657115
Validation loss: 2.7925379740902088
Epoch: 7| Step: 13
Training loss: 3.46649701608122
Validation loss: 2.7797918725735045
Epoch: 7| Step: 14
Training loss: 2.9048888597878797
Validation loss: 2.7606923643338845
Epoch: 7| Step: 15
Training loss: 2.7550672315920064
Validation loss: 2.739232588028133
Epoch: 7| Step: 0
Training loss: 2.5197330837580814
Validation loss: 2.695128231525465
Epoch: 7| Step: 1
Training loss: 3.4624034110688844
Validation loss: 2.7206878873607456
Epoch: 7| Step: 2
Training loss: 3.781112416183999
Validation loss: 2.7216431660766514
Epoch: 7| Step: 3
Training loss: 3.7771504775803737
Validation loss: 2.677776889098242
Epoch: 7| Step: 4
Training loss: 3.4409565972825527
Validation loss: 2.691433929661223
Epoch: 7| Step: 5
Training loss: 2.9997739706721354
Validation loss: 2.623915873728376
Epoch: 7| Step: 6
Training loss: 3.02419159230815
Validation loss: 2.673964077797416
Epoch: 7| Step: 7
Training loss: 3.208150354757468
Validation loss: 2.6488374477186225
Epoch: 7| Step: 8
Training loss: 3.3038815356485047
Validation loss: 2.6342454135747873
Epoch: 7| Step: 9
Training loss: 2.907574259628866
Validation loss: 2.612807754185605
Epoch: 7| Step: 10
Training loss: 3.065614012407839
Validation loss: 2.597415097632822
Epoch: 7| Step: 11
Training loss: 3.6947929549378538
Validation loss: 2.5839959490424436
Epoch: 7| Step: 12
Training loss: 2.7504147303570137
Validation loss: 2.5938509848811346
Epoch: 7| Step: 13
Training loss: 2.9551476711805598
Validation loss: 2.5651286909650843
Epoch: 7| Step: 14
Training loss: 2.520098008868742
Validation loss: 2.529327888001492
Epoch: 7| Step: 15
Training loss: 3.0585405873712332
Validation loss: 2.5236333547267233
Epoch: 8| Step: 0
Training loss: 2.9642679210660647
Validation loss: 2.5331866889701176
Epoch: 7| Step: 1
Training loss: 2.8047062865241723
Validation loss: 2.521107515869509
Epoch: 7| Step: 2
Training loss: 2.7095921060943273
Validation loss: 2.49851756371718
Epoch: 7| Step: 3
Training loss: 2.750858259653407
Validation loss: 2.4615686884559516
Epoch: 7| Step: 4
Training loss: 2.619209260204819
Validation loss: 2.4915024832871837
Epoch: 7| Step: 5
Training loss: 3.2290472849446172
Validation loss: 2.4637262299595983
Epoch: 7| Step: 6
Training loss: 3.3842229215456308
Validation loss: 2.4500605324078424
Epoch: 7| Step: 7
Training loss: 2.6637426279396497
Validation loss: 2.4415030046584856
Epoch: 7| Step: 8
Training loss: 2.96782919005093
Validation loss: 2.428927484174808
Epoch: 7| Step: 9
Training loss: 3.5437075550154575
Validation loss: 2.41434569393253
Epoch: 7| Step: 10
Training loss: 2.68701291660488
Validation loss: 2.4031647272197842
Epoch: 7| Step: 11
Training loss: 3.0571893851453673
Validation loss: 2.39130472421198
Epoch: 7| Step: 12
Training loss: 3.045149877207722
Validation loss: 2.384483417502433
Epoch: 7| Step: 13
Training loss: 2.9488534865385905
Validation loss: 2.3851816485331176
Epoch: 7| Step: 14
Training loss: 3.1993236780717127
Validation loss: 2.3525733272197336
Epoch: 7| Step: 15
Training loss: 2.939412245355274
Validation loss: 2.3247871942069955
Epoch: 9| Step: 0
Training loss: 2.3908426023693403
Validation loss: 2.3372856596495044
Epoch: 7| Step: 1
Training loss: 2.1781039484613065
Validation loss: 2.3292386040138178
Epoch: 7| Step: 2
Training loss: 3.4745594211909396
Validation loss: 2.3087481846300366
Epoch: 7| Step: 3
Training loss: 2.7597147403029645
Validation loss: 2.293979461728728
Epoch: 7| Step: 4
Training loss: 2.8064510146024784
Validation loss: 2.2966498701575606
Epoch: 7| Step: 5
Training loss: 2.0517266700992085
Validation loss: 2.2735307518029244
Epoch: 7| Step: 6
Training loss: 2.9374665603357633
Validation loss: 2.2665160496712393
Epoch: 7| Step: 7
Training loss: 2.878856063260404
Validation loss: 2.259741220904346
Epoch: 7| Step: 8
Training loss: 3.159102708683469
Validation loss: 2.2197852465456243
Epoch: 7| Step: 9
Training loss: 2.5183302271596797
Validation loss: 2.228665225256111
Epoch: 7| Step: 10
Training loss: 2.9251902330925885
Validation loss: 2.2205381890224403
Epoch: 7| Step: 11
Training loss: 2.927165907015245
Validation loss: 2.218715300517601
Epoch: 7| Step: 12
Training loss: 3.248598676960981
Validation loss: 2.2040613057613587
Epoch: 7| Step: 13
Training loss: 2.6977830262144438
Validation loss: 2.1760691407901787
Epoch: 7| Step: 14
Training loss: 2.6243387025093163
Validation loss: 2.183546070770203
Epoch: 7| Step: 15
Training loss: 2.855565937021716
Validation loss: 2.1811794979012507
Epoch: 10| Step: 0
Training loss: 2.5703139841371097
Validation loss: 2.1762456737486655
Epoch: 7| Step: 1
Training loss: 3.182980643369044
Validation loss: 2.1596872507316696
Epoch: 7| Step: 2
Training loss: 2.5208075550957636
Validation loss: 2.154469196880302
Epoch: 7| Step: 3
Training loss: 2.0097796232961236
Validation loss: 2.1467752287449886
Epoch: 7| Step: 4
Training loss: 2.3291527444586033
Validation loss: 2.138842467070446
Epoch: 7| Step: 5
Training loss: 2.2430050519120175
Validation loss: 2.122479482011622
Epoch: 7| Step: 6
Training loss: 2.7952758650194185
Validation loss: 2.128649691969781
Epoch: 7| Step: 7
Training loss: 2.8001429044495847
Validation loss: 2.1120963016540304
Epoch: 7| Step: 8
Training loss: 2.3246014448263637
Validation loss: 2.0861341643286315
Epoch: 7| Step: 9
Training loss: 2.745565306607045
Validation loss: 2.094111669195867
Epoch: 7| Step: 10
Training loss: 3.10734760380286
Validation loss: 2.0815432444137234
Epoch: 7| Step: 11
Training loss: 3.0959367826350643
Validation loss: 2.073341957824384
Epoch: 7| Step: 12
Training loss: 2.5077397701376882
Validation loss: 2.080965414424563
Epoch: 7| Step: 13
Training loss: 2.5811459499567295
Validation loss: 2.091576408101511
Epoch: 7| Step: 14
Training loss: 2.715169192780141
Validation loss: 2.0772055219913423
Epoch: 7| Step: 15
Training loss: 2.4016709789031805
Validation loss: 2.0756087139843995
Epoch: 11| Step: 0
Training loss: 2.297820435137661
Validation loss: 2.072525268629703
Epoch: 7| Step: 1
Training loss: 2.5198213632028788
Validation loss: 2.0608229354834524
Epoch: 7| Step: 2
Training loss: 2.402102376085439
Validation loss: 2.059387633596607
Epoch: 7| Step: 3
Training loss: 3.4671526831055925
Validation loss: 2.063293908700119
Epoch: 7| Step: 4
Training loss: 2.4020294231928205
Validation loss: 2.0434835921238874
Epoch: 7| Step: 5
Training loss: 2.427698824093584
Validation loss: 2.0445953945847015
Epoch: 7| Step: 6
Training loss: 2.8203487658084274
Validation loss: 2.044684663589133
Epoch: 7| Step: 7
Training loss: 1.9208854670976376
Validation loss: 2.038708345461991
Epoch: 7| Step: 8
Training loss: 2.308683803499521
Validation loss: 2.025922044214439
Epoch: 7| Step: 9
Training loss: 2.5660500475194383
Validation loss: 2.0370818360230096
Epoch: 7| Step: 10
Training loss: 2.3062191803483025
Validation loss: 2.0329381323159383
Epoch: 7| Step: 11
Training loss: 2.6853208356577207
Validation loss: 2.0230797530987417
Epoch: 7| Step: 12
Training loss: 2.4569650710856
Validation loss: 2.019949169844646
Epoch: 7| Step: 13
Training loss: 2.5701408908683536
Validation loss: 2.024859193201408
Epoch: 7| Step: 14
Training loss: 2.8371809658223612
Validation loss: 2.0339628900052324
Epoch: 7| Step: 15
Training loss: 2.4887596161607233
Validation loss: 2.024212925687266
Epoch: 12| Step: 0
Training loss: 2.5136340300727733
Validation loss: 2.0359900395314385
Epoch: 7| Step: 1
Training loss: 2.378198678157337
Validation loss: 2.0328390204168
Epoch: 7| Step: 2
Training loss: 2.5312662948272293
Validation loss: 2.0294715373227223
Epoch: 7| Step: 3
Training loss: 2.3881088678792994
Validation loss: 2.0364250592973936
Epoch: 7| Step: 4
Training loss: 2.7227369868431888
Validation loss: 2.0360405933587873
Epoch: 7| Step: 5
Training loss: 2.7512118530401906
Validation loss: 2.040732655033788
Epoch: 7| Step: 6
Training loss: 2.4584593875269993
Validation loss: 2.0338561433357314
Epoch: 7| Step: 7
Training loss: 2.0806703969002656
Validation loss: 2.0399649519971974
Epoch: 7| Step: 8
Training loss: 2.833339036673995
Validation loss: 2.0207319881198105
Epoch: 7| Step: 9
Training loss: 2.991410675005705
Validation loss: 2.0302133046441315
Epoch: 7| Step: 10
Training loss: 2.556192777035155
Validation loss: 2.029709276587759
Epoch: 7| Step: 11
Training loss: 2.3876637587383365
Validation loss: 2.0225676425566252
Epoch: 7| Step: 12
Training loss: 2.081245889745554
Validation loss: 2.0249684769935006
Epoch: 7| Step: 13
Training loss: 1.985698468869642
Validation loss: 2.028200473981441
Epoch: 7| Step: 14
Training loss: 2.6295939618688045
Validation loss: 2.0234892847711916
Epoch: 7| Step: 15
Training loss: 2.5536748996620657
Validation loss: 2.031498620072127
Epoch: 13| Step: 0
Training loss: 2.3093193450126717
Validation loss: 2.0020283585194703
Epoch: 7| Step: 1
Training loss: 2.6168991613263466
Validation loss: 2.036876121822214
Epoch: 7| Step: 2
Training loss: 2.503154862091205
Validation loss: 2.032546531822128
Epoch: 7| Step: 3
Training loss: 2.0819700994332466
Validation loss: 2.043340295215491
Epoch: 7| Step: 4
Training loss: 2.351632456198334
Validation loss: 2.031297083879279
Epoch: 7| Step: 5
Training loss: 2.348109450686046
Validation loss: 2.036640917965514
Epoch: 7| Step: 6
Training loss: 2.9091257613435175
Validation loss: 2.028577586862599
Epoch: 7| Step: 7
Training loss: 2.290084662725632
Validation loss: 2.03936834473546
Epoch: 7| Step: 8
Training loss: 2.324671186760914
Validation loss: 2.0340178478533417
Epoch: 7| Step: 9
Training loss: 2.613219666717625
Validation loss: 2.046714498051965
Epoch: 7| Step: 10
Training loss: 2.5731429542358017
Validation loss: 2.0366444355672315
Epoch: 7| Step: 11
Training loss: 2.613223316137774
Validation loss: 2.048532064259532
Epoch: 7| Step: 12
Training loss: 2.371659992107651
Validation loss: 2.041730287592985
Epoch: 7| Step: 13
Training loss: 2.352199024726141
Validation loss: 2.042594147415465
Epoch: 7| Step: 14
Training loss: 2.2797988038217283
Validation loss: 2.0506470547256614
Epoch: 7| Step: 15
Training loss: 3.1508050162404864
Validation loss: 2.0409775208574197
Epoch: 14| Step: 0
Training loss: 2.991601313848573
Validation loss: 2.0571841452678576
Epoch: 7| Step: 1
Training loss: 2.4266727302112208
Validation loss: 2.053258108453533
Epoch: 7| Step: 2
Training loss: 2.4879606270940493
Validation loss: 2.0592741890880704
Epoch: 7| Step: 3
Training loss: 2.8840886627938396
Validation loss: 2.0566702253019398
Epoch: 7| Step: 4
Training loss: 2.054632033843196
Validation loss: 2.0397354448445686
Epoch: 7| Step: 5
Training loss: 1.8984029633320065
Validation loss: 2.0399290581051512
Epoch: 7| Step: 6
Training loss: 2.118042607780307
Validation loss: 2.0455191957797387
Epoch: 7| Step: 7
Training loss: 2.3764352978856
Validation loss: 2.0436197427905953
Epoch: 7| Step: 8
Training loss: 2.0867381184606324
Validation loss: 2.0501673442411716
Epoch: 7| Step: 9
Training loss: 2.6142381133690007
Validation loss: 2.058215814316822
Epoch: 7| Step: 10
Training loss: 2.8574961341704936
Validation loss: 2.02560634619349
Epoch: 7| Step: 11
Training loss: 2.2986513910929247
Validation loss: 2.0548246736171394
Epoch: 7| Step: 12
Training loss: 2.2660052802486463
Validation loss: 2.0654116194974685
Epoch: 7| Step: 13
Training loss: 3.1934955532890528
Validation loss: 2.0602011301570835
Epoch: 7| Step: 14
Training loss: 2.709318089574948
Validation loss: 2.0327922882292273
Epoch: 7| Step: 15
Training loss: 2.2986987911326566
Validation loss: 2.044902434410282
Epoch: 15| Step: 0
Training loss: 2.4825302088379444
Validation loss: 2.0646810663688604
Epoch: 7| Step: 1
Training loss: 2.1350768648555847
Validation loss: 2.0693429229727456
Epoch: 7| Step: 2
Training loss: 2.6294505220506807
Validation loss: 2.0581490271060545
Epoch: 7| Step: 3
Training loss: 2.4888638423707707
Validation loss: 2.0486515939223016
Epoch: 7| Step: 4
Training loss: 2.055229318636988
Validation loss: 2.0516496487876146
Epoch: 7| Step: 5
Training loss: 2.7022468154695063
Validation loss: 2.0443258250244996
Epoch: 7| Step: 6
Training loss: 2.4747509994867056
Validation loss: 2.0537989623527246
Epoch: 7| Step: 7
Training loss: 2.3523119369073577
Validation loss: 2.044609188403037
Epoch: 7| Step: 8
Training loss: 2.7322363637101708
Validation loss: 2.044428367581664
Epoch: 7| Step: 9
Training loss: 2.9361708860428917
Validation loss: 2.0606863182962387
Epoch: 7| Step: 10
Training loss: 2.1220053721224192
Validation loss: 2.0434180262110546
Epoch: 7| Step: 11
Training loss: 2.9409573277007834
Validation loss: 2.0553815057369027
Epoch: 7| Step: 12
Training loss: 1.9016204022734535
Validation loss: 2.065882519393517
Epoch: 7| Step: 13
Training loss: 2.1161730824083063
Validation loss: 2.064671649203947
Epoch: 7| Step: 14
Training loss: 3.0269272646978957
Validation loss: 2.0627052314322336
Epoch: 7| Step: 15
Training loss: 2.42460212982998
Validation loss: 2.0637121330152404
Epoch: 16| Step: 0
Training loss: 2.9544146915656184
Validation loss: 2.049852159668001
Epoch: 7| Step: 1
Training loss: 2.4334322904906034
Validation loss: 2.0630426354543694
Epoch: 7| Step: 2
Training loss: 2.4905922307212403
Validation loss: 2.049409822878111
Epoch: 7| Step: 3
Training loss: 2.5585984091679905
Validation loss: 2.0480833165543144
Epoch: 7| Step: 4
Training loss: 2.2232969731565704
Validation loss: 2.0568680693815833
Epoch: 7| Step: 5
Training loss: 2.5312150552480337
Validation loss: 2.041054025879825
Epoch: 7| Step: 6
Training loss: 2.6931167283000854
Validation loss: 2.06306568456334
Epoch: 7| Step: 7
Training loss: 2.4271242413873013
Validation loss: 2.046348100018666
Epoch: 7| Step: 8
Training loss: 2.5480599484480364
Validation loss: 2.038891966638157
Epoch: 7| Step: 9
Training loss: 2.788975220070577
Validation loss: 2.0437489122898285
Epoch: 7| Step: 10
Training loss: 2.457760652551817
Validation loss: 2.035513092209551
Epoch: 7| Step: 11
Training loss: 2.113875159331672
Validation loss: 2.0404162129237378
Epoch: 7| Step: 12
Training loss: 2.478946344752862
Validation loss: 2.039675523260611
Epoch: 7| Step: 13
Training loss: 2.5891587400074627
Validation loss: 2.0434207859349396
Epoch: 7| Step: 14
Training loss: 2.1924589352040673
Validation loss: 2.0509605113350964
Epoch: 7| Step: 15
Training loss: 2.1949760206298694
Validation loss: 2.039914894206466
Epoch: 17| Step: 0
Training loss: 2.404197511083947
Validation loss: 2.048679372691614
Epoch: 7| Step: 1
Training loss: 1.6144230014400611
Validation loss: 2.038508667328301
Epoch: 7| Step: 2
Training loss: 2.6467983158177124
Validation loss: 2.049367425597695
Epoch: 7| Step: 3
Training loss: 2.4459210208422006
Validation loss: 2.0521971773147034
Epoch: 7| Step: 4
Training loss: 2.7649869883336335
Validation loss: 2.0439579864448505
Epoch: 7| Step: 5
Training loss: 2.6134873381636927
Validation loss: 2.047014716378734
Epoch: 7| Step: 6
Training loss: 2.2262204626952267
Validation loss: 2.052287314786295
Epoch: 7| Step: 7
Training loss: 2.840282631900767
Validation loss: 2.036186962808064
Epoch: 7| Step: 8
Training loss: 2.8094701765697154
Validation loss: 2.048156772432158
Epoch: 7| Step: 9
Training loss: 2.2870470359378894
Validation loss: 2.0452574288638563
Epoch: 7| Step: 10
Training loss: 2.24619681743824
Validation loss: 2.0508168147633725
Epoch: 7| Step: 11
Training loss: 2.9636586752230927
Validation loss: 2.0332497040918236
Epoch: 7| Step: 12
Training loss: 2.287241344732815
Validation loss: 2.041607457809402
Epoch: 7| Step: 13
Training loss: 2.036533702291432
Validation loss: 2.03656849270322
Epoch: 7| Step: 14
Training loss: 2.5440946040946946
Validation loss: 2.0470585977125535
Epoch: 7| Step: 15
Training loss: 2.628289477704707
Validation loss: 2.0374191972964812
Epoch: 18| Step: 0
Training loss: 2.0883769083715893
Validation loss: 2.0394439885178524
Epoch: 7| Step: 1
Training loss: 2.6499211029687713
Validation loss: 2.05339187064861
Epoch: 7| Step: 2
Training loss: 2.7831570377214887
Validation loss: 2.0438780476574436
Epoch: 7| Step: 3
Training loss: 2.7732011721219125
Validation loss: 2.052814474158277
Epoch: 7| Step: 4
Training loss: 2.2720494178448027
Validation loss: 2.046809314476032
Epoch: 7| Step: 5
Training loss: 2.9410155342052384
Validation loss: 2.042888212916841
Epoch: 7| Step: 6
Training loss: 2.2404213572046228
Validation loss: 2.0504109227126164
Epoch: 7| Step: 7
Training loss: 2.69009061639456
Validation loss: 2.039898080552291
Epoch: 7| Step: 8
Training loss: 2.6909138487907356
Validation loss: 2.0294816400305153
Epoch: 7| Step: 9
Training loss: 2.8869220832376232
Validation loss: 2.0335362310928664
Epoch: 7| Step: 10
Training loss: 2.057652180305794
Validation loss: 2.0318664563735265
Epoch: 7| Step: 11
Training loss: 2.5497286670913346
Validation loss: 2.0484418133718623
Epoch: 7| Step: 12
Training loss: 1.9892783072627966
Validation loss: 2.0166006197043407
Epoch: 7| Step: 13
Training loss: 2.5431232551949345
Validation loss: 2.033392958594445
Epoch: 7| Step: 14
Training loss: 2.0752568924686816
Validation loss: 2.041814583392999
Epoch: 7| Step: 15
Training loss: 2.2135629331277746
Validation loss: 2.048169976569225
Epoch: 19| Step: 0
Training loss: 2.3285217971092815
Validation loss: 2.0566635880262063
Epoch: 7| Step: 1
Training loss: 1.9555886561429303
Validation loss: 2.0318257975694753
Epoch: 7| Step: 2
Training loss: 1.985129565855653
Validation loss: 2.0468686755980037
Epoch: 7| Step: 3
Training loss: 2.6946343052446773
Validation loss: 2.045054211311194
Epoch: 7| Step: 4
Training loss: 2.486410015282902
Validation loss: 2.049406363347883
Epoch: 7| Step: 5
Training loss: 2.5260954756101746
Validation loss: 2.0513560409312506
Epoch: 7| Step: 6
Training loss: 2.6999735901565267
Validation loss: 2.055381525414377
Epoch: 7| Step: 7
Training loss: 2.807299999066634
Validation loss: 2.0366436824578056
Epoch: 7| Step: 8
Training loss: 2.299633005136469
Validation loss: 2.0360206332473383
Epoch: 7| Step: 9
Training loss: 2.7432033472178126
Validation loss: 2.0456500925789025
Epoch: 7| Step: 10
Training loss: 2.220673278232254
Validation loss: 2.047696197122629
Epoch: 7| Step: 11
Training loss: 2.201431597573812
Validation loss: 2.043050806237123
Epoch: 7| Step: 12
Training loss: 2.590204596373464
Validation loss: 2.0566431468166906
Epoch: 7| Step: 13
Training loss: 3.274851200130413
Validation loss: 2.0536780021784447
Epoch: 7| Step: 14
Training loss: 2.4340919731648767
Validation loss: 2.02496790252702
Epoch: 7| Step: 15
Training loss: 2.1978447587482446
Validation loss: 2.0501357335621626
Epoch: 20| Step: 0
Training loss: 2.4150438011730704
Validation loss: 2.0356066579142156
Epoch: 7| Step: 1
Training loss: 2.319424751588999
Validation loss: 2.0352720900297467
Epoch: 7| Step: 2
Training loss: 2.785610252925052
Validation loss: 2.0469773753641
Epoch: 7| Step: 3
Training loss: 2.454249616256269
Validation loss: 2.0522595316735903
Epoch: 7| Step: 4
Training loss: 2.517227136547319
Validation loss: 2.05222062461702
Epoch: 7| Step: 5
Training loss: 2.613476299767381
Validation loss: 2.0440242835691467
Epoch: 7| Step: 6
Training loss: 2.353290113353001
Validation loss: 2.039034522529646
Epoch: 7| Step: 7
Training loss: 2.3939323734301956
Validation loss: 2.020457473526491
Epoch: 7| Step: 8
Training loss: 1.9069974715801694
Validation loss: 2.043561311459575
Epoch: 7| Step: 9
Training loss: 2.4404378938937654
Validation loss: 2.036050579079545
Epoch: 7| Step: 10
Training loss: 2.1073757163040407
Validation loss: 2.049899861065777
Epoch: 7| Step: 11
Training loss: 2.6816527164239417
Validation loss: 2.052934577550157
Epoch: 7| Step: 12
Training loss: 2.2951323457343444
Validation loss: 2.0601770416855705
Epoch: 7| Step: 13
Training loss: 2.780912314499297
Validation loss: 2.0455805927064263
Epoch: 7| Step: 14
Training loss: 2.6215242353559955
Validation loss: 2.0512395224253477
Epoch: 7| Step: 15
Training loss: 2.7971968652088783
Validation loss: 2.0415105032455516
Epoch: 21| Step: 0
Training loss: 2.6323864872324623
Validation loss: 2.0527379882614905
Epoch: 7| Step: 1
Training loss: 2.5428910250878647
Validation loss: 2.0564193746540522
Epoch: 7| Step: 2
Training loss: 2.617669633325531
Validation loss: 2.059439016648125
Epoch: 7| Step: 3
Training loss: 2.217276715344674
Validation loss: 2.0516221787854647
Epoch: 7| Step: 4
Training loss: 2.161949365444607
Validation loss: 2.042732624981693
Epoch: 7| Step: 5
Training loss: 2.6068895575245636
Validation loss: 2.014151536145562
Epoch: 7| Step: 6
Training loss: 2.8055022604971795
Validation loss: 2.038614389258933
Epoch: 7| Step: 7
Training loss: 2.292846676438011
Validation loss: 2.0396902564548354
Epoch: 7| Step: 8
Training loss: 2.14460551371301
Validation loss: 2.0402012638627913
Epoch: 7| Step: 9
Training loss: 2.0271070044436725
Validation loss: 2.045385403932035
Epoch: 7| Step: 10
Training loss: 2.7277293509358267
Validation loss: 2.044953570737523
Epoch: 7| Step: 11
Training loss: 2.9921686953757995
Validation loss: 2.045589124822297
Epoch: 7| Step: 12
Training loss: 2.789247394491827
Validation loss: 2.0462267094611954
Epoch: 7| Step: 13
Training loss: 2.1910755907579462
Validation loss: 2.0473038758144897
Epoch: 7| Step: 14
Training loss: 2.1405495957507963
Validation loss: 2.0565396172813433
Epoch: 7| Step: 15
Training loss: 2.534139890854425
Validation loss: 2.03678416756615
Epoch: 22| Step: 0
Training loss: 1.9062706367751414
Validation loss: 2.0476334776963405
Epoch: 7| Step: 1
Training loss: 1.8660655461581712
Validation loss: 2.057473461493693
Epoch: 7| Step: 2
Training loss: 2.628539650736813
Validation loss: 2.0304889797777386
Epoch: 7| Step: 3
Training loss: 2.9769067440066386
Validation loss: 2.052464332823569
Epoch: 7| Step: 4
Training loss: 2.4005627488951538
Validation loss: 2.052086015766274
Epoch: 7| Step: 5
Training loss: 2.537761648434529
Validation loss: 2.027572460446754
Epoch: 7| Step: 6
Training loss: 2.813550032530607
Validation loss: 2.052381401513587
Epoch: 7| Step: 7
Training loss: 1.764872027504549
Validation loss: 2.0487966017553956
Epoch: 7| Step: 8
Training loss: 3.133290699066781
Validation loss: 2.0500887315751766
Epoch: 7| Step: 9
Training loss: 2.45612360893605
Validation loss: 2.0406880225045776
Epoch: 7| Step: 10
Training loss: 2.151014634178814
Validation loss: 2.0281507575821056
Epoch: 7| Step: 11
Training loss: 2.484868414482441
Validation loss: 2.038691970439818
Epoch: 7| Step: 12
Training loss: 2.371023161338582
Validation loss: 2.0451090094694937
Epoch: 7| Step: 13
Training loss: 2.9517441200449146
Validation loss: 2.0337241869486147
Epoch: 7| Step: 14
Training loss: 2.121021810474332
Validation loss: 2.052723462713499
Epoch: 7| Step: 15
Training loss: 2.560553765305851
Validation loss: 2.044031379095775
Epoch: 23| Step: 0
Training loss: 3.0130949327242242
Validation loss: 2.0310596270891854
Epoch: 7| Step: 1
Training loss: 2.141128146773509
Validation loss: 2.0481027610163536
Epoch: 7| Step: 2
Training loss: 2.233302465861312
Validation loss: 2.0344413219806414
Epoch: 7| Step: 3
Training loss: 2.7901056299757037
Validation loss: 2.038526019935403
Epoch: 7| Step: 4
Training loss: 2.7188086667801463
Validation loss: 2.0365913159625477
Epoch: 7| Step: 5
Training loss: 1.7355882679641434
Validation loss: 2.0438313981496425
Epoch: 7| Step: 6
Training loss: 2.418060448899839
Validation loss: 2.049089198000144
Epoch: 7| Step: 7
Training loss: 1.8560110484238335
Validation loss: 2.0384847514528275
Epoch: 7| Step: 8
Training loss: 2.6283538827554414
Validation loss: 2.037970717384349
Epoch: 7| Step: 9
Training loss: 2.2820050805826826
Validation loss: 2.0127310613190623
Epoch: 7| Step: 10
Training loss: 2.594850789155507
Validation loss: 2.029392143214831
Epoch: 7| Step: 11
Training loss: 2.7358787543385694
Validation loss: 2.033413777840178
Epoch: 7| Step: 12
Training loss: 2.6366751660171013
Validation loss: 2.045740681362311
Epoch: 7| Step: 13
Training loss: 2.510889180352885
Validation loss: 2.0425866599052043
Epoch: 7| Step: 14
Training loss: 2.6928907931481407
Validation loss: 2.0572035037561904
Epoch: 7| Step: 15
Training loss: 2.192885825855796
Validation loss: 2.02009925864186
Epoch: 24| Step: 0
Training loss: 2.323207705844363
Validation loss: 2.0421606692789376
Epoch: 7| Step: 1
Training loss: 2.4274281487404243
Validation loss: 2.043016566005196
Epoch: 7| Step: 2
Training loss: 2.0482438729938472
Validation loss: 2.0392490621622485
Epoch: 7| Step: 3
Training loss: 2.7127706612413705
Validation loss: 2.041480441330141
Epoch: 7| Step: 4
Training loss: 2.9068332209975214
Validation loss: 2.0359970217794223
Epoch: 7| Step: 5
Training loss: 2.511568198430744
Validation loss: 2.0380000754688
Epoch: 7| Step: 6
Training loss: 2.6984715621379967
Validation loss: 2.0458329153209736
Epoch: 7| Step: 7
Training loss: 2.496062515851382
Validation loss: 2.030757457815258
Epoch: 7| Step: 8
Training loss: 2.1072921076604585
Validation loss: 2.046020101799333
Epoch: 7| Step: 9
Training loss: 2.1800447123430615
Validation loss: 2.0493745792711477
Epoch: 7| Step: 10
Training loss: 2.750333765756273
Validation loss: 2.0315917650746123
Epoch: 7| Step: 11
Training loss: 2.156144402171134
Validation loss: 2.034317195224142
Epoch: 7| Step: 12
Training loss: 2.702676195581717
Validation loss: 2.035793529860413
Epoch: 7| Step: 13
Training loss: 2.2603786365690945
Validation loss: 2.0542037776966104
Epoch: 7| Step: 14
Training loss: 2.6838464964960553
Validation loss: 2.0501551267506697
Epoch: 7| Step: 15
Training loss: 2.415356533040549
Validation loss: 2.029783313421334
Epoch: 25| Step: 0
Training loss: 2.437076629648583
Validation loss: 2.0419595644196886
Epoch: 7| Step: 1
Training loss: 2.464051810116218
Validation loss: 2.0527742930121406
Epoch: 7| Step: 2
Training loss: 2.3252894395715993
Validation loss: 2.028914059896181
Epoch: 7| Step: 3
Training loss: 1.979457077671026
Validation loss: 2.0548016551437702
Epoch: 7| Step: 4
Training loss: 2.5166724257582227
Validation loss: 2.046116037166597
Epoch: 7| Step: 5
Training loss: 2.4589919377241727
Validation loss: 2.0400573583213677
Epoch: 7| Step: 6
Training loss: 2.2828224719780805
Validation loss: 2.0462519049184777
Epoch: 7| Step: 7
Training loss: 2.812710224348101
Validation loss: 2.0494998641534994
Epoch: 7| Step: 8
Training loss: 2.276644617404908
Validation loss: 2.04041509690622
Epoch: 7| Step: 9
Training loss: 2.893981963844223
Validation loss: 2.031094212645867
Epoch: 7| Step: 10
Training loss: 2.9650020029405386
Validation loss: 2.049084206846753
Epoch: 7| Step: 11
Training loss: 1.818392285173114
Validation loss: 2.0339393781939332
Epoch: 7| Step: 12
Training loss: 2.0133903003153186
Validation loss: 2.0402027929691258
Epoch: 7| Step: 13
Training loss: 2.6623871756992137
Validation loss: 2.028467367993348
Epoch: 7| Step: 14
Training loss: 2.982689346480767
Validation loss: 2.0340707962797477
Epoch: 7| Step: 15
Training loss: 2.2470100457748265
Validation loss: 2.037134959974149
Epoch: 26| Step: 0
Training loss: 3.4355980900194103
Validation loss: 2.034431967139144
Epoch: 7| Step: 1
Training loss: 2.5101324741010425
Validation loss: 2.044457350717831
Epoch: 7| Step: 2
Training loss: 1.8784941857872164
Validation loss: 2.0432874380434245
Epoch: 7| Step: 3
Training loss: 2.5079637523447085
Validation loss: 2.03152776087647
Epoch: 7| Step: 4
Training loss: 2.185278936603224
Validation loss: 2.0369895288436553
Epoch: 7| Step: 5
Training loss: 2.861877013799555
Validation loss: 2.0451672974063606
Epoch: 7| Step: 6
Training loss: 2.464120991653033
Validation loss: 2.042117136182024
Epoch: 7| Step: 7
Training loss: 2.4971287451610635
Validation loss: 2.0313409249127212
Epoch: 7| Step: 8
Training loss: 2.52540516388168
Validation loss: 2.0343389319302743
Epoch: 7| Step: 9
Training loss: 2.26644156637885
Validation loss: 2.028244486928007
Epoch: 7| Step: 10
Training loss: 2.6098316272782234
Validation loss: 2.0355040457625324
Epoch: 7| Step: 11
Training loss: 2.124997531665042
Validation loss: 2.033013749972637
Epoch: 7| Step: 12
Training loss: 2.6831745558808993
Validation loss: 2.0329331721765316
Epoch: 7| Step: 13
Training loss: 1.750615488535201
Validation loss: 2.0370617019904715
Epoch: 7| Step: 14
Training loss: 2.199954192811744
Validation loss: 2.041784866070135
Epoch: 7| Step: 15
Training loss: 2.5274891170339098
Validation loss: 2.040123038085469
Epoch: 27| Step: 0
Training loss: 2.626257277437319
Validation loss: 2.0308632720874655
Epoch: 7| Step: 1
Training loss: 2.114484462086509
Validation loss: 2.0480459813603487
Epoch: 7| Step: 2
Training loss: 2.2485376480204704
Validation loss: 2.0234630362437236
Epoch: 7| Step: 3
Training loss: 2.4233301528776865
Validation loss: 2.0220351232722034
Epoch: 7| Step: 4
Training loss: 2.197078116999317
Validation loss: 2.0184399404988156
Epoch: 7| Step: 5
Training loss: 2.2586255573050553
Validation loss: 2.0343673014388366
Epoch: 7| Step: 6
Training loss: 2.0650531109868067
Validation loss: 2.041820548152976
Epoch: 7| Step: 7
Training loss: 2.869389740663628
Validation loss: 2.039374077356024
Epoch: 7| Step: 8
Training loss: 2.474136078455831
Validation loss: 2.028001763186727
Epoch: 7| Step: 9
Training loss: 2.404451267667966
Validation loss: 2.033637209999929
Epoch: 7| Step: 10
Training loss: 2.5740299879222746
Validation loss: 2.0225448846759853
Epoch: 7| Step: 11
Training loss: 2.6352105242254416
Validation loss: 2.0466378034399257
Epoch: 7| Step: 12
Training loss: 2.5463639197055805
Validation loss: 2.029097637002549
Epoch: 7| Step: 13
Training loss: 2.94476847595072
Validation loss: 2.0514497731559285
Epoch: 7| Step: 14
Training loss: 2.1824314797952913
Validation loss: 2.0353739126789243
Epoch: 7| Step: 15
Training loss: 2.716843034912945
Validation loss: 2.0372570006458313
Epoch: 28| Step: 0
Training loss: 2.4533829280083594
Validation loss: 2.0329516622043666
Epoch: 7| Step: 1
Training loss: 2.124364196803745
Validation loss: 2.041683244001102
Epoch: 7| Step: 2
Training loss: 2.626804730503127
Validation loss: 2.0284772142437455
Epoch: 7| Step: 3
Training loss: 2.328701895085396
Validation loss: 2.0343671678228343
Epoch: 7| Step: 4
Training loss: 2.41484328794151
Validation loss: 2.030616537132173
Epoch: 7| Step: 5
Training loss: 2.6424168934380523
Validation loss: 2.0241068069734083
Epoch: 7| Step: 6
Training loss: 2.4789163372268566
Validation loss: 2.026135894370494
Epoch: 7| Step: 7
Training loss: 2.751718417704779
Validation loss: 2.011355073608229
Epoch: 7| Step: 8
Training loss: 2.164404115671063
Validation loss: 2.0259810141290453
Epoch: 7| Step: 9
Training loss: 2.382874234759959
Validation loss: 2.0239426892637504
Epoch: 7| Step: 10
Training loss: 2.6445766878943586
Validation loss: 2.0303380075068893
Epoch: 7| Step: 11
Training loss: 2.5218094336248016
Validation loss: 2.021968031170014
Epoch: 7| Step: 12
Training loss: 2.4106031402316774
Validation loss: 2.000511434159353
Epoch: 7| Step: 13
Training loss: 2.7924815359845616
Validation loss: 2.0208582696787203
Epoch: 7| Step: 14
Training loss: 2.4247143252708314
Validation loss: 2.0311835526026636
Epoch: 7| Step: 15
Training loss: 2.187103017479932
Validation loss: 2.027590214528765
Epoch: 29| Step: 0
Training loss: 2.9185158090351146
Validation loss: 2.0287662172228886
Epoch: 7| Step: 1
Training loss: 2.424192144584155
Validation loss: 2.0372808698152
Epoch: 7| Step: 2
Training loss: 2.1417391585414833
Validation loss: 2.0448383612904895
Epoch: 7| Step: 3
Training loss: 2.624303089454849
Validation loss: 2.034050943476568
Epoch: 7| Step: 4
Training loss: 2.942722790887927
Validation loss: 2.015904525837673
Epoch: 7| Step: 5
Training loss: 2.45379959841411
Validation loss: 2.0276155028171177
Epoch: 7| Step: 6
Training loss: 2.45770497023201
Validation loss: 2.018195649143358
Epoch: 7| Step: 7
Training loss: 2.596025502871661
Validation loss: 2.0172928049013152
Epoch: 7| Step: 8
Training loss: 2.354473150327434
Validation loss: 2.012129016342806
Epoch: 7| Step: 9
Training loss: 2.3227111543029286
Validation loss: 2.0226096089932653
Epoch: 7| Step: 10
Training loss: 2.325049192667014
Validation loss: 2.033588764567002
Epoch: 7| Step: 11
Training loss: 2.0337383580827115
Validation loss: 2.019101626137133
Epoch: 7| Step: 12
Training loss: 2.1036192178675632
Validation loss: 2.0293911271148133
Epoch: 7| Step: 13
Training loss: 2.311502602422472
Validation loss: 2.039500855929127
Epoch: 7| Step: 14
Training loss: 2.3135524107712047
Validation loss: 2.024966346102171
Epoch: 7| Step: 15
Training loss: 2.828086810618149
Validation loss: 2.0295052747578106
Epoch: 30| Step: 0
Training loss: 2.2741389814597146
Validation loss: 2.036456467045275
Epoch: 7| Step: 1
Training loss: 2.8907581195593552
Validation loss: 2.035598082411337
Epoch: 7| Step: 2
Training loss: 2.7093450172815676
Validation loss: 2.026464921454518
Epoch: 7| Step: 3
Training loss: 3.1323027160334624
Validation loss: 2.0369116866082915
Epoch: 7| Step: 4
Training loss: 2.7470940061022735
Validation loss: 2.019218846959091
Epoch: 7| Step: 5
Training loss: 1.9767421595527812
Validation loss: 2.01681796746468
Epoch: 7| Step: 6
Training loss: 2.1583624181174703
Validation loss: 2.034135654205339
Epoch: 7| Step: 7
Training loss: 2.474180309309007
Validation loss: 2.024699090939686
Epoch: 7| Step: 8
Training loss: 2.0902312587942222
Validation loss: 2.033123451031177
Epoch: 7| Step: 9
Training loss: 2.2730014028817584
Validation loss: 2.0391120710728226
Epoch: 7| Step: 10
Training loss: 2.3557233024443773
Validation loss: 2.031373006879399
Epoch: 7| Step: 11
Training loss: 2.34505304353826
Validation loss: 2.024767218891213
Epoch: 7| Step: 12
Training loss: 2.015309508716731
Validation loss: 2.0376613063894577
Epoch: 7| Step: 13
Training loss: 2.202211664142228
Validation loss: 2.0348917110110984
Epoch: 7| Step: 14
Training loss: 2.750557582855077
Validation loss: 2.0338407976567496
Epoch: 7| Step: 15
Training loss: 2.699415715893785
Validation loss: 2.0311531210407883
Epoch: 31| Step: 0
Training loss: 1.7181674316761755
Validation loss: 2.037990848106746
Epoch: 7| Step: 1
Training loss: 3.2705480528093243
Validation loss: 2.039188611933555
Epoch: 7| Step: 2
Training loss: 2.564385720476264
Validation loss: 2.025186858523454
Epoch: 7| Step: 3
Training loss: 2.354350822695225
Validation loss: 2.0432704080550796
Epoch: 7| Step: 4
Training loss: 2.38741131363168
Validation loss: 2.0183907501893166
Epoch: 7| Step: 5
Training loss: 2.2107725048168567
Validation loss: 2.0189131860508436
Epoch: 7| Step: 6
Training loss: 2.015237105549432
Validation loss: 2.03264128234923
Epoch: 7| Step: 7
Training loss: 2.338906229286619
Validation loss: 2.0465756370081154
Epoch: 7| Step: 8
Training loss: 2.5788367936084766
Validation loss: 2.036217588350735
Epoch: 7| Step: 9
Training loss: 2.455467903314263
Validation loss: 2.0496397721769872
Epoch: 7| Step: 10
Training loss: 2.566000152926838
Validation loss: 2.050551360702769
Epoch: 7| Step: 11
Training loss: 2.1704307529429068
Validation loss: 2.0479119496586833
Epoch: 7| Step: 12
Training loss: 2.22195192785993
Validation loss: 2.0402651570216928
Epoch: 7| Step: 13
Training loss: 2.8484046486337573
Validation loss: 2.039458343168965
Epoch: 7| Step: 14
Training loss: 2.419147851047106
Validation loss: 2.047225466693869
Epoch: 7| Step: 15
Training loss: 2.886051993998124
Validation loss: 2.0369848059644404
Epoch: 32| Step: 0
Training loss: 2.2221295046007747
Validation loss: 2.029741429109301
Epoch: 7| Step: 1
Training loss: 2.2386559510617348
Validation loss: 2.0397470001174502
Epoch: 7| Step: 2
Training loss: 2.144579054780819
Validation loss: 2.0326397391556656
Epoch: 7| Step: 3
Training loss: 2.939379476340647
Validation loss: 2.0380152278614507
Epoch: 7| Step: 4
Training loss: 2.7561927772169903
Validation loss: 2.038305415221129
Epoch: 7| Step: 5
Training loss: 2.0947042539604626
Validation loss: 2.037394374222017
Epoch: 7| Step: 6
Training loss: 2.58631898768634
Validation loss: 2.023397101881816
Epoch: 7| Step: 7
Training loss: 2.1737431237943934
Validation loss: 2.0357269477975484
Epoch: 7| Step: 8
Training loss: 1.9271671654964704
Validation loss: 2.020636123091887
Epoch: 7| Step: 9
Training loss: 2.7508846073944038
Validation loss: 2.006808885277966
Epoch: 7| Step: 10
Training loss: 2.3765056254687305
Validation loss: 2.011335876352144
Epoch: 7| Step: 11
Training loss: 2.9307668910025875
Validation loss: 2.0350374313994464
Epoch: 7| Step: 12
Training loss: 2.477806091954613
Validation loss: 2.033480953126429
Epoch: 7| Step: 13
Training loss: 2.921658757821618
Validation loss: 2.013709754201036
Epoch: 7| Step: 14
Training loss: 2.2182322153173635
Validation loss: 2.010031542228622
Epoch: 7| Step: 15
Training loss: 2.2874810806909514
Validation loss: 2.009945992283844
Epoch: 33| Step: 0
Training loss: 2.6719018589030585
Validation loss: 2.0215358585150214
Epoch: 7| Step: 1
Training loss: 2.071151736040214
Validation loss: 2.0273898109839474
Epoch: 7| Step: 2
Training loss: 2.257617242415271
Validation loss: 2.0355907890621596
Epoch: 7| Step: 3
Training loss: 2.0841622674410805
Validation loss: 2.0050660262743083
Epoch: 7| Step: 4
Training loss: 2.612499627656317
Validation loss: 2.039787446668129
Epoch: 7| Step: 5
Training loss: 1.7832687716814992
Validation loss: 2.0321782754184365
Epoch: 7| Step: 6
Training loss: 2.4469688582658247
Validation loss: 2.030124006169839
Epoch: 7| Step: 7
Training loss: 2.244505212714451
Validation loss: 2.0277667022514057
Epoch: 7| Step: 8
Training loss: 2.3501057215508028
Validation loss: 2.030499955242129
Epoch: 7| Step: 9
Training loss: 2.4811240944999806
Validation loss: 2.0227990575736747
Epoch: 7| Step: 10
Training loss: 2.040036725106368
Validation loss: 2.036038475796562
Epoch: 7| Step: 11
Training loss: 3.2920207223529694
Validation loss: 2.0225733155916843
Epoch: 7| Step: 12
Training loss: 2.815184520006344
Validation loss: 2.016407160343822
Epoch: 7| Step: 13
Training loss: 2.7710518906138972
Validation loss: 2.0276305628714066
Epoch: 7| Step: 14
Training loss: 2.806156889256476
Validation loss: 2.0281177204039724
Epoch: 7| Step: 15
Training loss: 2.1791789237480623
Validation loss: 2.0098995248586475
Epoch: 34| Step: 0
Training loss: 2.083100979881391
Validation loss: 2.041743918182054
Epoch: 7| Step: 1
Training loss: 2.896209106946891
Validation loss: 2.034793704087789
Epoch: 7| Step: 2
Training loss: 2.191663213613519
Validation loss: 2.027840587406086
Epoch: 7| Step: 3
Training loss: 2.266081875741898
Validation loss: 2.0274365138504384
Epoch: 7| Step: 4
Training loss: 3.1515115350811445
Validation loss: 2.0336043670163986
Epoch: 7| Step: 5
Training loss: 2.2977271542833377
Validation loss: 2.042578215362716
Epoch: 7| Step: 6
Training loss: 2.3145941453939276
Validation loss: 2.0365370398869773
Epoch: 7| Step: 7
Training loss: 1.8981630731355976
Validation loss: 2.019651680751389
Epoch: 7| Step: 8
Training loss: 2.071774179068258
Validation loss: 2.0284255572926857
Epoch: 7| Step: 9
Training loss: 2.193192187737106
Validation loss: 2.0332560256802363
Epoch: 7| Step: 10
Training loss: 2.6278245352719978
Validation loss: 2.031609120806781
Epoch: 7| Step: 11
Training loss: 2.518813677188741
Validation loss: 2.0173323357835176
Epoch: 7| Step: 12
Training loss: 2.0145930524379243
Validation loss: 2.0232732312509065
Epoch: 7| Step: 13
Training loss: 2.8138813441297685
Validation loss: 2.0403075338728343
Epoch: 7| Step: 14
Training loss: 2.69049783333048
Validation loss: 2.017081522519766
Epoch: 7| Step: 15
Training loss: 2.8053231116798814
Validation loss: 2.0321654322368468
Epoch: 35| Step: 0
Training loss: 2.6162292548175947
Validation loss: 2.0333875255578873
Epoch: 7| Step: 1
Training loss: 1.9203906025534838
Validation loss: 2.0224629266534224
Epoch: 7| Step: 2
Training loss: 2.3016583725072906
Validation loss: 2.0272535207453894
Epoch: 7| Step: 3
Training loss: 2.302304241461468
Validation loss: 2.0339057952887023
Epoch: 7| Step: 4
Training loss: 2.6435766934344507
Validation loss: 2.026378961408372
Epoch: 7| Step: 5
Training loss: 2.373916579634379
Validation loss: 2.026468776085383
Epoch: 7| Step: 6
Training loss: 2.757225946830437
Validation loss: 2.0166721914275776
Epoch: 7| Step: 7
Training loss: 1.9566929081202886
Validation loss: 2.0309210465794925
Epoch: 7| Step: 8
Training loss: 2.8889782313038057
Validation loss: 2.0054516575580443
Epoch: 7| Step: 9
Training loss: 2.5063340056460284
Validation loss: 2.0327553062184904
Epoch: 7| Step: 10
Training loss: 1.8442537298507382
Validation loss: 2.026512944089195
Epoch: 7| Step: 11
Training loss: 2.9053697791274
Validation loss: 2.023196290558165
Epoch: 7| Step: 12
Training loss: 2.0796468798126173
Validation loss: 2.016210094113611
Epoch: 7| Step: 13
Training loss: 2.5879998871392016
Validation loss: 2.033592676463558
Epoch: 7| Step: 14
Training loss: 2.896653111919592
Validation loss: 2.025056161941538
Epoch: 7| Step: 15
Training loss: 2.273401109332085
Validation loss: 2.016532634272821
Epoch: 36| Step: 0
Training loss: 2.29295533678333
Validation loss: 2.0259556000696155
Epoch: 7| Step: 1
Training loss: 2.258146056777332
Validation loss: 2.0281919165308815
Epoch: 7| Step: 2
Training loss: 2.4945434149479255
Validation loss: 2.0189810760346862
Epoch: 7| Step: 3
Training loss: 2.4227370173951077
Validation loss: 2.025277475941319
Epoch: 7| Step: 4
Training loss: 3.326024211802301
Validation loss: 2.027739999593822
Epoch: 7| Step: 5
Training loss: 2.4477628186084757
Validation loss: 2.015560939425831
Epoch: 7| Step: 6
Training loss: 2.192387379936779
Validation loss: 2.021371274923129
Epoch: 7| Step: 7
Training loss: 3.1032559554481507
Validation loss: 2.026562003902605
Epoch: 7| Step: 8
Training loss: 2.0698253130341824
Validation loss: 2.0306888259289573
Epoch: 7| Step: 9
Training loss: 2.24634042463397
Validation loss: 2.012499487215241
Epoch: 7| Step: 10
Training loss: 2.029222738547432
Validation loss: 2.0080290294663494
Epoch: 7| Step: 11
Training loss: 2.019726387793424
Validation loss: 2.0290711216405706
Epoch: 7| Step: 12
Training loss: 2.9110314198943823
Validation loss: 2.0106494594941027
Epoch: 7| Step: 13
Training loss: 2.1500695150803226
Validation loss: 2.0180653211950217
Epoch: 7| Step: 14
Training loss: 2.5542317488459703
Validation loss: 2.0181805843198997
Epoch: 7| Step: 15
Training loss: 2.240643757378501
Validation loss: 2.021223853202822
Epoch: 37| Step: 0
Training loss: 2.6896970772619806
Validation loss: 2.020319977160084
Epoch: 7| Step: 1
Training loss: 2.095991159289403
Validation loss: 2.0260477150478517
Epoch: 7| Step: 2
Training loss: 2.6644338757253467
Validation loss: 2.028924673095123
Epoch: 7| Step: 3
Training loss: 2.6643522669918314
Validation loss: 2.0197099584033755
Epoch: 7| Step: 4
Training loss: 2.2267331777373833
Validation loss: 2.0294762819334173
Epoch: 7| Step: 5
Training loss: 2.4926984974632154
Validation loss: 1.9927540566748383
Epoch: 7| Step: 6
Training loss: 2.3143338329621046
Validation loss: 2.018116629573165
Epoch: 7| Step: 7
Training loss: 2.3081511768764544
Validation loss: 2.0101267956611624
Epoch: 7| Step: 8
Training loss: 2.876776105170047
Validation loss: 2.003890525355837
Epoch: 7| Step: 9
Training loss: 2.2934214260495995
Validation loss: 2.00962047212907
Epoch: 7| Step: 10
Training loss: 2.260773298078327
Validation loss: 2.0292511211480586
Epoch: 7| Step: 11
Training loss: 2.400388837150982
Validation loss: 2.029662436953943
Epoch: 7| Step: 12
Training loss: 2.1884245962078186
Validation loss: 2.0103253984954197
Epoch: 7| Step: 13
Training loss: 2.2679702721990456
Validation loss: 2.023716385081495
Epoch: 7| Step: 14
Training loss: 2.846387541291116
Validation loss: 2.0316332432674575
Epoch: 7| Step: 15
Training loss: 2.4880413137360526
Validation loss: 2.022322769536533
Epoch: 38| Step: 0
Training loss: 2.3216879521599343
Validation loss: 2.0254076691860834
Epoch: 7| Step: 1
Training loss: 2.740345306217512
Validation loss: 2.017367239235705
Epoch: 7| Step: 2
Training loss: 1.910808303720097
Validation loss: 2.021288279706197
Epoch: 7| Step: 3
Training loss: 2.5828867085268126
Validation loss: 2.030090710423164
Epoch: 7| Step: 4
Training loss: 2.390461535880196
Validation loss: 2.011176555109386
Epoch: 7| Step: 5
Training loss: 3.082483294736421
Validation loss: 2.040840941032113
Epoch: 7| Step: 6
Training loss: 2.721539874638181
Validation loss: 2.0246507866813443
Epoch: 7| Step: 7
Training loss: 2.2860355087619606
Validation loss: 2.0237448219755563
Epoch: 7| Step: 8
Training loss: 2.11002548925543
Validation loss: 2.0344694242564825
Epoch: 7| Step: 9
Training loss: 2.335250294113508
Validation loss: 2.0334495216630892
Epoch: 7| Step: 10
Training loss: 2.581215041249443
Validation loss: 2.0117621102395162
Epoch: 7| Step: 11
Training loss: 2.4796276679028737
Validation loss: 2.0264543836082995
Epoch: 7| Step: 12
Training loss: 2.4765988897784905
Validation loss: 2.0164463946584728
Epoch: 7| Step: 13
Training loss: 1.9462117640586551
Validation loss: 2.0299154647987883
Epoch: 7| Step: 14
Training loss: 2.2006748724900684
Validation loss: 2.0233367940962736
Epoch: 7| Step: 15
Training loss: 2.793688189272929
Validation loss: 2.0276044983516175
Epoch: 39| Step: 0
Training loss: 2.129977623369764
Validation loss: 2.021100391866872
Epoch: 7| Step: 1
Training loss: 2.478790147757299
Validation loss: 2.0246281971459967
Epoch: 7| Step: 2
Training loss: 2.419167167706448
Validation loss: 2.031484822844486
Epoch: 7| Step: 3
Training loss: 2.34454230585895
Validation loss: 2.0109885132149365
Epoch: 7| Step: 4
Training loss: 2.6113198165361933
Validation loss: 2.028598426539465
Epoch: 7| Step: 5
Training loss: 2.422106331882805
Validation loss: 2.0310057194629376
Epoch: 7| Step: 6
Training loss: 2.639067421835719
Validation loss: 2.0262267018408746
Epoch: 7| Step: 7
Training loss: 2.613538606798234
Validation loss: 2.026998967301029
Epoch: 7| Step: 8
Training loss: 1.828061877081963
Validation loss: 2.020322342498957
Epoch: 7| Step: 9
Training loss: 2.0904879994115233
Validation loss: 2.0189515863368546
Epoch: 7| Step: 10
Training loss: 2.582624820229731
Validation loss: 2.006957526274144
Epoch: 7| Step: 11
Training loss: 2.6022308682432818
Validation loss: 2.01714423855296
Epoch: 7| Step: 12
Training loss: 2.1319695787746498
Validation loss: 2.00937576881963
Epoch: 7| Step: 13
Training loss: 2.4652171872234474
Validation loss: 2.0138073295234364
Epoch: 7| Step: 14
Training loss: 2.464758241261445
Validation loss: 2.0259318967380575
Epoch: 7| Step: 15
Training loss: 3.075692081878766
Validation loss: 2.0293281956738727
Epoch: 40| Step: 0
Training loss: 2.2647519238092513
Validation loss: 2.0203370853413665
Epoch: 7| Step: 1
Training loss: 2.159336369081966
Validation loss: 2.0150193983647915
Epoch: 7| Step: 2
Training loss: 3.122474870908973
Validation loss: 2.022321161853242
Epoch: 7| Step: 3
Training loss: 2.1306918713881555
Validation loss: 2.026395814214889
Epoch: 7| Step: 4
Training loss: 2.47862999714565
Validation loss: 2.0136784347806223
Epoch: 7| Step: 5
Training loss: 2.6910750098064047
Validation loss: 2.0129213638629935
Epoch: 7| Step: 6
Training loss: 3.032705842254895
Validation loss: 1.9851825279710125
Epoch: 7| Step: 7
Training loss: 2.172349397731119
Validation loss: 2.0141545225570776
Epoch: 7| Step: 8
Training loss: 2.1736863082320457
Validation loss: 2.0206600455471126
Epoch: 7| Step: 9
Training loss: 2.6706388413605997
Validation loss: 2.018192576076612
Epoch: 7| Step: 10
Training loss: 2.589391976792768
Validation loss: 2.0278463165172713
Epoch: 7| Step: 11
Training loss: 2.3293077165708618
Validation loss: 2.020720307132517
Epoch: 7| Step: 12
Training loss: 2.332515493752393
Validation loss: 1.9966960165575687
Epoch: 7| Step: 13
Training loss: 1.9364174310291682
Validation loss: 2.0140528527317776
Epoch: 7| Step: 14
Training loss: 2.377271168604021
Validation loss: 2.012256380250848
Epoch: 7| Step: 15
Training loss: 2.4308588571377805
Validation loss: 2.0049463311455953
Epoch: 41| Step: 0
Training loss: 2.2409732734145233
Validation loss: 2.01898746144955
Epoch: 7| Step: 1
Training loss: 2.3502614423726698
Validation loss: 1.993094063399027
Epoch: 7| Step: 2
Training loss: 2.5197131187388435
Validation loss: 2.0012349863090004
Epoch: 7| Step: 3
Training loss: 3.2187135564722382
Validation loss: 2.012645812393488
Epoch: 7| Step: 4
Training loss: 2.3348620947031837
Validation loss: 2.0072560876409375
Epoch: 7| Step: 5
Training loss: 2.4994071257449453
Validation loss: 2.022921501233729
Epoch: 7| Step: 6
Training loss: 2.4607756061890105
Validation loss: 1.99076113148773
Epoch: 7| Step: 7
Training loss: 2.271698801378244
Validation loss: 2.0196313743838
Epoch: 7| Step: 8
Training loss: 2.322095192573729
Validation loss: 1.9892213288887999
Epoch: 7| Step: 9
Training loss: 1.728873109219761
Validation loss: 2.008108074992141
Epoch: 7| Step: 10
Training loss: 2.093912829999432
Validation loss: 2.008885497954557
Epoch: 7| Step: 11
Training loss: 1.801495193322572
Validation loss: 1.990658016019555
Epoch: 7| Step: 12
Training loss: 2.9220938371112077
Validation loss: 1.9858579574941073
Epoch: 7| Step: 13
Training loss: 2.393418518700388
Validation loss: 2.0051098871682314
Epoch: 7| Step: 14
Training loss: 2.815844348826843
Validation loss: 2.0049480919849176
Epoch: 7| Step: 15
Training loss: 2.653654558331512
Validation loss: 2.022340960524648
Epoch: 42| Step: 0
Training loss: 2.9365305822784715
Validation loss: 2.0140940430944925
Epoch: 7| Step: 1
Training loss: 2.7283751138211825
Validation loss: 2.014778757861342
Epoch: 7| Step: 2
Training loss: 2.235274553951476
Validation loss: 2.0241163228922763
Epoch: 7| Step: 3
Training loss: 2.792492891335041
Validation loss: 2.0223496676053236
Epoch: 7| Step: 4
Training loss: 2.500419104732305
Validation loss: 2.025313462118021
Epoch: 7| Step: 5
Training loss: 2.2080159109136646
Validation loss: 2.0197302093998424
Epoch: 7| Step: 6
Training loss: 2.4870828710108133
Validation loss: 2.0262180913446928
Epoch: 7| Step: 7
Training loss: 1.9066868891121538
Validation loss: 2.015724585394736
Epoch: 7| Step: 8
Training loss: 2.0160207433844395
Validation loss: 2.0307225289009936
Epoch: 7| Step: 9
Training loss: 2.8325408687488207
Validation loss: 2.0330085727766227
Epoch: 7| Step: 10
Training loss: 1.9951030863274315
Validation loss: 2.0307359350903353
Epoch: 7| Step: 11
Training loss: 2.2177130196663537
Validation loss: 2.0264535356596927
Epoch: 7| Step: 12
Training loss: 2.787394989499
Validation loss: 2.015909079187405
Epoch: 7| Step: 13
Training loss: 2.1405059335827317
Validation loss: 2.0148627298253703
Epoch: 7| Step: 14
Training loss: 2.731018273062319
Validation loss: 2.024858927302728
Epoch: 7| Step: 15
Training loss: 2.262643891706397
Validation loss: 2.0112001054543054
Epoch: 43| Step: 0
Training loss: 2.408506450128897
Validation loss: 2.021568819111903
Epoch: 7| Step: 1
Training loss: 2.5458227687019206
Validation loss: 2.034669609816663
Epoch: 7| Step: 2
Training loss: 2.782873986843089
Validation loss: 2.0275773792939167
Epoch: 7| Step: 3
Training loss: 2.26976749943587
Validation loss: 2.000609175921315
Epoch: 7| Step: 4
Training loss: 1.9421608147356901
Validation loss: 2.023841466285454
Epoch: 7| Step: 5
Training loss: 2.5264482518340956
Validation loss: 2.0253635773957743
Epoch: 7| Step: 6
Training loss: 2.4510227598754546
Validation loss: 2.0122237643121452
Epoch: 7| Step: 7
Training loss: 1.5908776373045195
Validation loss: 2.027746166680517
Epoch: 7| Step: 8
Training loss: 2.419825024702613
Validation loss: 2.0241547002902407
Epoch: 7| Step: 9
Training loss: 2.738378329875724
Validation loss: 2.0219678981971536
Epoch: 7| Step: 10
Training loss: 2.6482744644981087
Validation loss: 2.016935355781322
Epoch: 7| Step: 11
Training loss: 2.0945690318096735
Validation loss: 2.010286849718166
Epoch: 7| Step: 12
Training loss: 2.8605822740047344
Validation loss: 2.0206240305684857
Epoch: 7| Step: 13
Training loss: 2.547938493420448
Validation loss: 2.011323352421061
Epoch: 7| Step: 14
Training loss: 2.3702744100549165
Validation loss: 1.9981141318091293
Epoch: 7| Step: 15
Training loss: 2.5337638146240744
Validation loss: 2.0111221186986508
Epoch: 44| Step: 0
Training loss: 2.2440052705454683
Validation loss: 2.0121187881011298
Epoch: 7| Step: 1
Training loss: 2.1984691799242726
Validation loss: 2.0239418736047567
Epoch: 7| Step: 2
Training loss: 2.3236678295987168
Validation loss: 1.994402381052578
Epoch: 7| Step: 3
Training loss: 2.2495894587344423
Validation loss: 2.0015697763337004
Epoch: 7| Step: 4
Training loss: 2.3902061943266957
Validation loss: 2.0164007265144503
Epoch: 7| Step: 5
Training loss: 2.6911672366997617
Validation loss: 2.0161780777427523
Epoch: 7| Step: 6
Training loss: 2.3959823119795454
Validation loss: 2.014835211847105
Epoch: 7| Step: 7
Training loss: 2.4693512003453404
Validation loss: 2.008986429484703
Epoch: 7| Step: 8
Training loss: 3.0404328931476807
Validation loss: 2.020895892714465
Epoch: 7| Step: 9
Training loss: 1.9927338094191172
Validation loss: 2.032310089101673
Epoch: 7| Step: 10
Training loss: 1.8698461271411
Validation loss: 2.016951254485712
Epoch: 7| Step: 11
Training loss: 3.0614712602710843
Validation loss: 2.012511748599404
Epoch: 7| Step: 12
Training loss: 2.204395874547585
Validation loss: 2.014634727447173
Epoch: 7| Step: 13
Training loss: 2.452439036102541
Validation loss: 2.025122152531964
Epoch: 7| Step: 14
Training loss: 2.8536260793667916
Validation loss: 2.0082749123507124
Epoch: 7| Step: 15
Training loss: 2.1928275491981717
Validation loss: 2.020715184069783
Epoch: 45| Step: 0
Training loss: 3.0579587001868322
Validation loss: 2.007260871504817
Epoch: 7| Step: 1
Training loss: 2.476326242242734
Validation loss: 2.0120737173151118
Epoch: 7| Step: 2
Training loss: 2.1682962256190206
Validation loss: 2.0189705258595945
Epoch: 7| Step: 3
Training loss: 2.882823416836545
Validation loss: 2.0196474463645124
Epoch: 7| Step: 4
Training loss: 1.8687265987908563
Validation loss: 2.0220445782299272
Epoch: 7| Step: 5
Training loss: 2.383811566138403
Validation loss: 2.0104804878772367
Epoch: 7| Step: 6
Training loss: 2.697908870337181
Validation loss: 2.0141173774144203
Epoch: 7| Step: 7
Training loss: 2.08203250963699
Validation loss: 2.02209187726823
Epoch: 7| Step: 8
Training loss: 2.323186770303747
Validation loss: 2.0088299350821734
Epoch: 7| Step: 9
Training loss: 1.7399966573135013
Validation loss: 2.014135401180592
Epoch: 7| Step: 10
Training loss: 2.454852036874976
Validation loss: 2.012298095624335
Epoch: 7| Step: 11
Training loss: 1.9605462645267342
Validation loss: 2.026403490462511
Epoch: 7| Step: 12
Training loss: 2.7514888894385185
Validation loss: 2.0112189688847426
Epoch: 7| Step: 13
Training loss: 2.3259027102747813
Validation loss: 2.0062548385552788
Epoch: 7| Step: 14
Training loss: 2.549868550371965
Validation loss: 2.0056485244184716
Epoch: 7| Step: 15
Training loss: 2.8300184792498277
Validation loss: 1.9988354753356121
Epoch: 46| Step: 0
Training loss: 2.5824264247048108
Validation loss: 2.0078048341845145
Epoch: 7| Step: 1
Training loss: 2.6178500575176225
Validation loss: 2.007812806043096
Epoch: 7| Step: 2
Training loss: 2.4164011469582696
Validation loss: 2.0220355538325445
Epoch: 7| Step: 3
Training loss: 1.8187365606801171
Validation loss: 2.0221776842552446
Epoch: 7| Step: 4
Training loss: 1.8215054380936222
Validation loss: 2.0216559304514528
Epoch: 7| Step: 5
Training loss: 1.844743881023126
Validation loss: 2.0136718276149566
Epoch: 7| Step: 6
Training loss: 2.6532715198690453
Validation loss: 2.01908963965646
Epoch: 7| Step: 7
Training loss: 2.4847476127989947
Validation loss: 2.0177185072995307
Epoch: 7| Step: 8
Training loss: 2.5431292552073335
Validation loss: 2.0213411682687115
Epoch: 7| Step: 9
Training loss: 2.647251550041204
Validation loss: 2.019125645915801
Epoch: 7| Step: 10
Training loss: 2.5624145865743055
Validation loss: 2.023158212056996
Epoch: 7| Step: 11
Training loss: 3.0931724240391816
Validation loss: 2.015427698223802
Epoch: 7| Step: 12
Training loss: 2.5394688677215465
Validation loss: 2.025931905877864
Epoch: 7| Step: 13
Training loss: 2.3166187825731606
Validation loss: 2.023959152814814
Epoch: 7| Step: 14
Training loss: 2.3882746892607485
Validation loss: 2.0261425734539
Epoch: 7| Step: 15
Training loss: 2.329244254997418
Validation loss: 2.0082947622635983
Epoch: 47| Step: 0
Training loss: 2.7689173869562405
Validation loss: 2.007028650584805
Epoch: 7| Step: 1
Training loss: 2.4299918716985447
Validation loss: 1.994681630060902
Epoch: 7| Step: 2
Training loss: 2.731742594487823
Validation loss: 2.0104580373399985
Epoch: 7| Step: 3
Training loss: 2.638393023119528
Validation loss: 2.00927925507978
Epoch: 7| Step: 4
Training loss: 2.4385642638226135
Validation loss: 2.014962980804273
Epoch: 7| Step: 5
Training loss: 2.790619231385765
Validation loss: 1.9914035606605405
Epoch: 7| Step: 6
Training loss: 2.1459755958385385
Validation loss: 2.0038241932567042
Epoch: 7| Step: 7
Training loss: 2.589385623601638
Validation loss: 2.0170678075262747
Epoch: 7| Step: 8
Training loss: 2.6939596568076745
Validation loss: 1.9874038814190569
Epoch: 7| Step: 9
Training loss: 2.316336876793709
Validation loss: 1.9908022150705738
Epoch: 7| Step: 10
Training loss: 2.299865747762933
Validation loss: 2.0005561278607806
Epoch: 7| Step: 11
Training loss: 2.4263667630101056
Validation loss: 2.009257684348127
Epoch: 7| Step: 12
Training loss: 2.1450937224855866
Validation loss: 1.988088107692904
Epoch: 7| Step: 13
Training loss: 2.034754971648237
Validation loss: 1.9902101019770329
Epoch: 7| Step: 14
Training loss: 2.140575770348033
Validation loss: 1.9935085455889714
Epoch: 7| Step: 15
Training loss: 2.18140106115304
Validation loss: 1.9936140092867245
Epoch: 48| Step: 0
Training loss: 3.009884445152163
Validation loss: 1.9997192628235816
Epoch: 7| Step: 1
Training loss: 2.645570626820952
Validation loss: 2.002050953362804
Epoch: 7| Step: 2
Training loss: 3.0961225255629565
Validation loss: 2.0186345655362743
Epoch: 7| Step: 3
Training loss: 2.1804538049735838
Validation loss: 1.9977445157528175
Epoch: 7| Step: 4
Training loss: 2.0181301429000165
Validation loss: 2.009550185666605
Epoch: 7| Step: 5
Training loss: 2.2087254326085013
Validation loss: 2.0146696908668136
Epoch: 7| Step: 6
Training loss: 2.7362809868073543
Validation loss: 1.9992158435825254
Epoch: 7| Step: 7
Training loss: 2.3162261223836085
Validation loss: 2.0033070167615894
Epoch: 7| Step: 8
Training loss: 2.5033515399045596
Validation loss: 2.01143811957744
Epoch: 7| Step: 9
Training loss: 2.320996938129001
Validation loss: 2.001441346341024
Epoch: 7| Step: 10
Training loss: 2.481387087016121
Validation loss: 1.9888516277617065
Epoch: 7| Step: 11
Training loss: 2.2270779197158412
Validation loss: 1.9852435969730458
Epoch: 7| Step: 12
Training loss: 1.733900675479769
Validation loss: 1.9956982166824084
Epoch: 7| Step: 13
Training loss: 2.7385375682461093
Validation loss: 2.0121463944177087
Epoch: 7| Step: 14
Training loss: 2.197378360823191
Validation loss: 2.01308173408642
Epoch: 7| Step: 15
Training loss: 2.118690323340875
Validation loss: 2.006462967991576
Epoch: 49| Step: 0
Training loss: 2.813023751552862
Validation loss: 2.010657085144207
Epoch: 7| Step: 1
Training loss: 2.400167133551731
Validation loss: 1.989708376618534
Epoch: 7| Step: 2
Training loss: 2.176203743203654
Validation loss: 2.0044744819898606
Epoch: 7| Step: 3
Training loss: 1.6561002843594552
Validation loss: 2.0173957808207232
Epoch: 7| Step: 4
Training loss: 1.7806047977628388
Validation loss: 2.006208557721323
Epoch: 7| Step: 5
Training loss: 2.4014601160089537
Validation loss: 2.015877806221211
Epoch: 7| Step: 6
Training loss: 2.35005469157108
Validation loss: 2.0083817294289
Epoch: 7| Step: 7
Training loss: 2.3651378054320813
Validation loss: 2.030096157948624
Epoch: 7| Step: 8
Training loss: 2.170000433680056
Validation loss: 2.0190832905055056
Epoch: 7| Step: 9
Training loss: 2.3788870073113366
Validation loss: 2.0291047366649178
Epoch: 7| Step: 10
Training loss: 2.243916871392569
Validation loss: 2.0325018597687206
Epoch: 7| Step: 11
Training loss: 2.2392923092087695
Validation loss: 2.033576047298373
Epoch: 7| Step: 12
Training loss: 3.1257120465638972
Validation loss: 2.0383288675444415
Epoch: 7| Step: 13
Training loss: 2.5231455347616003
Validation loss: 2.0031511363254606
Epoch: 7| Step: 14
Training loss: 2.618329063944631
Validation loss: 2.0251322231176467
Epoch: 7| Step: 15
Training loss: 3.256255365466129
Validation loss: 2.0322987167228073
Epoch: 50| Step: 0
Training loss: 2.3708339090016968
Validation loss: 2.018589462152978
Epoch: 7| Step: 1
Training loss: 2.606182406713035
Validation loss: 2.020024369242205
Epoch: 7| Step: 2
Training loss: 2.321116812176376
Validation loss: 2.0203016831466774
Epoch: 7| Step: 3
Training loss: 2.9563013181204156
Validation loss: 2.015460240821383
Epoch: 7| Step: 4
Training loss: 2.336029255063274
Validation loss: 2.0076850028932234
Epoch: 7| Step: 5
Training loss: 2.8286523485375006
Validation loss: 2.0111431568872176
Epoch: 7| Step: 6
Training loss: 2.1266257854745656
Validation loss: 2.011067178976551
Epoch: 7| Step: 7
Training loss: 2.341904587610935
Validation loss: 2.0112920103088188
Epoch: 7| Step: 8
Training loss: 2.6525640606852114
Validation loss: 2.0033378426357773
Epoch: 7| Step: 9
Training loss: 2.406214329839104
Validation loss: 2.0077557069685494
Epoch: 7| Step: 10
Training loss: 2.3745270308311306
Validation loss: 2.0072115328772284
Epoch: 7| Step: 11
Training loss: 2.2792446780990456
Validation loss: 1.997054370007968
Epoch: 7| Step: 12
Training loss: 2.483641990152325
Validation loss: 1.9977725137838958
Epoch: 7| Step: 13
Training loss: 2.1086937828688326
Validation loss: 2.0039247519294165
Epoch: 7| Step: 14
Training loss: 2.3214560622379583
Validation loss: 1.9802062207334177
Epoch: 7| Step: 15
Training loss: 2.1727873717695303
Validation loss: 2.009692580459188
Epoch: 51| Step: 0
Training loss: 2.6738473851114217
Validation loss: 2.0064317420714457
Epoch: 7| Step: 1
Training loss: 2.5025741675911295
Validation loss: 1.9868187406539732
Epoch: 7| Step: 2
Training loss: 2.676365430784425
Validation loss: 2.002080087905351
Epoch: 7| Step: 3
Training loss: 2.3304859453590603
Validation loss: 1.997530460938652
Epoch: 7| Step: 4
Training loss: 2.839157588292208
Validation loss: 1.9859443551165
Epoch: 7| Step: 5
Training loss: 2.725297432162222
Validation loss: 1.9971121014319757
Epoch: 7| Step: 6
Training loss: 2.402787727330457
Validation loss: 2.001877822912658
Epoch: 7| Step: 7
Training loss: 1.8618032163347367
Validation loss: 1.9862617379585101
Epoch: 7| Step: 8
Training loss: 2.618750262203522
Validation loss: 1.9996143394146537
Epoch: 7| Step: 9
Training loss: 2.1451188413336975
Validation loss: 1.9895171148029318
Epoch: 7| Step: 10
Training loss: 2.532517574961045
Validation loss: 2.007392580489171
Epoch: 7| Step: 11
Training loss: 2.437497163428588
Validation loss: 2.0027995595071215
Epoch: 7| Step: 12
Training loss: 2.0303155950634526
Validation loss: 1.9846936868380203
Epoch: 7| Step: 13
Training loss: 2.1911839663124715
Validation loss: 2.0025586518922056
Epoch: 7| Step: 14
Training loss: 2.350549828347494
Validation loss: 1.9900879875205468
Epoch: 7| Step: 15
Training loss: 2.233359152611425
Validation loss: 2.0037811917806687
Epoch: 52| Step: 0
Training loss: 2.0615751331376533
Validation loss: 1.9883438597506078
Epoch: 7| Step: 1
Training loss: 2.380607209843958
Validation loss: 1.984550579226533
Epoch: 7| Step: 2
Training loss: 2.6470503423592326
Validation loss: 2.0072836448567375
Epoch: 7| Step: 3
Training loss: 3.0763527662588146
Validation loss: 1.9902591850283395
Epoch: 7| Step: 4
Training loss: 2.089688589450329
Validation loss: 2.0051193211723257
Epoch: 7| Step: 5
Training loss: 2.4520570410585845
Validation loss: 2.010654308343075
Epoch: 7| Step: 6
Training loss: 2.6246299482817537
Validation loss: 2.005342584181143
Epoch: 7| Step: 7
Training loss: 2.3625097607607763
Validation loss: 2.0157648988245187
Epoch: 7| Step: 8
Training loss: 2.455536938314312
Validation loss: 2.0319069975192092
Epoch: 7| Step: 9
Training loss: 2.5651958520191607
Validation loss: 2.012703381664857
Epoch: 7| Step: 10
Training loss: 2.290273508788012
Validation loss: 2.020171030006933
Epoch: 7| Step: 11
Training loss: 2.1282425992181224
Validation loss: 2.029998712610875
Epoch: 7| Step: 12
Training loss: 2.268071609671776
Validation loss: 2.027420986826658
Epoch: 7| Step: 13
Training loss: 2.6074023985403207
Validation loss: 2.0264049611549213
Epoch: 7| Step: 14
Training loss: 1.743986082332093
Validation loss: 2.017173495015854
Epoch: 7| Step: 15
Training loss: 2.8981689986820776
Validation loss: 2.0152913137614257
Epoch: 53| Step: 0
Training loss: 2.8738968432767202
Validation loss: 2.0205220115047218
Epoch: 7| Step: 1
Training loss: 2.498835483174644
Validation loss: 2.0008632768708727
Epoch: 7| Step: 2
Training loss: 2.2397485952984995
Validation loss: 2.0064473134889766
Epoch: 7| Step: 3
Training loss: 2.1113734068412566
Validation loss: 2.009681555936797
Epoch: 7| Step: 4
Training loss: 2.35522894959254
Validation loss: 2.0078317364819824
Epoch: 7| Step: 5
Training loss: 2.4284133759526227
Validation loss: 2.0017046829187244
Epoch: 7| Step: 6
Training loss: 2.0663035607016367
Validation loss: 2.0076941906581043
Epoch: 7| Step: 7
Training loss: 2.3452231291656944
Validation loss: 1.9885995271663923
Epoch: 7| Step: 8
Training loss: 2.218689716218617
Validation loss: 2.009671239369278
Epoch: 7| Step: 9
Training loss: 2.6590434027920886
Validation loss: 1.9914584369063613
Epoch: 7| Step: 10
Training loss: 2.616679674671018
Validation loss: 1.9949197362033069
Epoch: 7| Step: 11
Training loss: 2.192352797678728
Validation loss: 1.9930293692627714
Epoch: 7| Step: 12
Training loss: 2.3328005545758086
Validation loss: 1.9795520197615202
Epoch: 7| Step: 13
Training loss: 2.3379474272874505
Validation loss: 1.998862349731531
Epoch: 7| Step: 14
Training loss: 2.6491523610613075
Validation loss: 2.0011810551208553
Epoch: 7| Step: 15
Training loss: 2.7623989449223663
Validation loss: 1.9889967804560538
Epoch: 54| Step: 0
Training loss: 1.8699474287548201
Validation loss: 2.0090463272687566
Epoch: 7| Step: 1
Training loss: 2.625990907651874
Validation loss: 2.000848411130987
Epoch: 7| Step: 2
Training loss: 2.207087099162005
Validation loss: 2.0119940144944706
Epoch: 7| Step: 3
Training loss: 2.465943201609817
Validation loss: 2.007172936681198
Epoch: 7| Step: 4
Training loss: 2.085242452086657
Validation loss: 2.0046755173818345
Epoch: 7| Step: 5
Training loss: 2.358294915559214
Validation loss: 2.0064556106613862
Epoch: 7| Step: 6
Training loss: 2.4913405171978873
Validation loss: 2.0061437306558356
Epoch: 7| Step: 7
Training loss: 2.7886974619418154
Validation loss: 2.0069250605076667
Epoch: 7| Step: 8
Training loss: 2.550438944118879
Validation loss: 2.000499772234478
Epoch: 7| Step: 9
Training loss: 2.362673947828252
Validation loss: 2.0099848074061724
Epoch: 7| Step: 10
Training loss: 2.4375031300060033
Validation loss: 2.0283083243161535
Epoch: 7| Step: 11
Training loss: 2.493220674176107
Validation loss: 2.0160875349743246
Epoch: 7| Step: 12
Training loss: 2.5740527734807737
Validation loss: 2.0242798227837517
Epoch: 7| Step: 13
Training loss: 2.5211396044428662
Validation loss: 2.011498919740634
Epoch: 7| Step: 14
Training loss: 2.6820256567345826
Validation loss: 2.0278181204724954
Epoch: 7| Step: 15
Training loss: 2.291130928071425
Validation loss: 2.0186621371098785
Epoch: 55| Step: 0
Training loss: 2.632417100142668
Validation loss: 1.9914993207703786
Epoch: 7| Step: 1
Training loss: 2.2899703481162077
Validation loss: 1.9969945823274307
Epoch: 7| Step: 2
Training loss: 2.2525058144209624
Validation loss: 2.024166732953443
Epoch: 7| Step: 3
Training loss: 1.8704361367212552
Validation loss: 2.010803278984087
Epoch: 7| Step: 4
Training loss: 2.7100517298980003
Validation loss: 2.012771189455958
Epoch: 7| Step: 5
Training loss: 2.6828525191417683
Validation loss: 2.0056484415414793
Epoch: 7| Step: 6
Training loss: 1.9782813518136377
Validation loss: 2.0111407689896663
Epoch: 7| Step: 7
Training loss: 2.4339576804212903
Validation loss: 2.005351216453781
Epoch: 7| Step: 8
Training loss: 2.5902224532813607
Validation loss: 2.005184194561749
Epoch: 7| Step: 9
Training loss: 2.692505632711627
Validation loss: 1.9961539089806102
Epoch: 7| Step: 10
Training loss: 2.351107733973862
Validation loss: 2.016581705160895
Epoch: 7| Step: 11
Training loss: 2.7020263203116173
Validation loss: 2.0035753963291123
Epoch: 7| Step: 12
Training loss: 2.244530387477264
Validation loss: 1.9956597620851961
Epoch: 7| Step: 13
Training loss: 2.6080359946557805
Validation loss: 1.9779488479929705
Epoch: 7| Step: 14
Training loss: 1.9378779873227314
Validation loss: 1.997857845866026
Epoch: 7| Step: 15
Training loss: 2.5258968875465473
Validation loss: 1.9946145605453691
Epoch: 56| Step: 0
Training loss: 2.429819085093662
Validation loss: 1.9856696126943438
Epoch: 7| Step: 1
Training loss: 2.212669422106949
Validation loss: 2.0020402692248203
Epoch: 7| Step: 2
Training loss: 2.508209957582239
Validation loss: 1.9813753893449442
Epoch: 7| Step: 3
Training loss: 2.0484358100098508
Validation loss: 2.003069071930439
Epoch: 7| Step: 4
Training loss: 2.5789673325066045
Validation loss: 1.9900336321726826
Epoch: 7| Step: 5
Training loss: 2.4058068598140867
Validation loss: 2.001360021519006
Epoch: 7| Step: 6
Training loss: 2.2426933754650857
Validation loss: 1.9835988542426974
Epoch: 7| Step: 7
Training loss: 2.7694348317137516
Validation loss: 1.9947434203400032
Epoch: 7| Step: 8
Training loss: 2.6775204985588132
Validation loss: 1.9980114340861013
Epoch: 7| Step: 9
Training loss: 2.603369374613885
Validation loss: 2.00229625145231
Epoch: 7| Step: 10
Training loss: 1.8945300544656343
Validation loss: 1.987057035495769
Epoch: 7| Step: 11
Training loss: 2.9846582727655755
Validation loss: 2.0052405359507466
Epoch: 7| Step: 12
Training loss: 2.492141005701195
Validation loss: 1.9904629145902435
Epoch: 7| Step: 13
Training loss: 2.4378833958292914
Validation loss: 2.0063605424691726
Epoch: 7| Step: 14
Training loss: 1.8803981005428794
Validation loss: 1.9978286014372115
Epoch: 7| Step: 15
Training loss: 2.313522834363398
Validation loss: 1.992890478086996
Epoch: 57| Step: 0
Training loss: 2.3294862185641856
Validation loss: 1.998564017331874
Epoch: 7| Step: 1
Training loss: 2.50341849255468
Validation loss: 1.9876721849272747
Epoch: 7| Step: 2
Training loss: 2.7067832227644426
Validation loss: 1.9971941741624455
Epoch: 7| Step: 3
Training loss: 2.7711496292128603
Validation loss: 1.9917725756033289
Epoch: 7| Step: 4
Training loss: 2.710523238397176
Validation loss: 1.993315393859578
Epoch: 7| Step: 5
Training loss: 2.3010586375457867
Validation loss: 1.9959367559928514
Epoch: 7| Step: 6
Training loss: 2.1218139100304785
Validation loss: 2.0146940730473175
Epoch: 7| Step: 7
Training loss: 2.661527708658604
Validation loss: 1.9971632915041106
Epoch: 7| Step: 8
Training loss: 2.1675828194992754
Validation loss: 2.0121237598303683
Epoch: 7| Step: 9
Training loss: 1.885768864510618
Validation loss: 2.0074519273006737
Epoch: 7| Step: 10
Training loss: 2.446046176814511
Validation loss: 2.003285368946847
Epoch: 7| Step: 11
Training loss: 2.63570772355548
Validation loss: 1.9852014733534133
Epoch: 7| Step: 12
Training loss: 1.520634659980668
Validation loss: 2.0104295495949263
Epoch: 7| Step: 13
Training loss: 2.523775910636072
Validation loss: 2.004673627196458
Epoch: 7| Step: 14
Training loss: 2.948630651991326
Validation loss: 1.996027846871385
Epoch: 7| Step: 15
Training loss: 2.0836509716757114
Validation loss: 2.0067715705484765
Epoch: 58| Step: 0
Training loss: 2.6394324685338946
Validation loss: 2.0225214632606257
Epoch: 7| Step: 1
Training loss: 2.6141881352780287
Validation loss: 1.9995064287069677
Epoch: 7| Step: 2
Training loss: 2.197592206632712
Validation loss: 1.9981280904254841
Epoch: 7| Step: 3
Training loss: 3.0194930336965498
Validation loss: 2.0140074311317147
Epoch: 7| Step: 4
Training loss: 2.0333875706218967
Validation loss: 2.0227338519022795
Epoch: 7| Step: 5
Training loss: 2.5337013337063414
Validation loss: 2.021593215839363
Epoch: 7| Step: 6
Training loss: 1.8248546725375032
Validation loss: 2.018101618321194
Epoch: 7| Step: 7
Training loss: 2.967883495563346
Validation loss: 2.008777945277475
Epoch: 7| Step: 8
Training loss: 2.5896927687420006
Validation loss: 2.0046448678310753
Epoch: 7| Step: 9
Training loss: 2.3902279393183807
Validation loss: 2.0241095982551864
Epoch: 7| Step: 10
Training loss: 2.2779341336474874
Validation loss: 1.9949154495934087
Epoch: 7| Step: 11
Training loss: 2.2154473452775325
Validation loss: 2.0143961391158376
Epoch: 7| Step: 12
Training loss: 2.622854900365085
Validation loss: 2.0112808825278297
Epoch: 7| Step: 13
Training loss: 2.4287172201617575
Validation loss: 1.994559091652929
Epoch: 7| Step: 14
Training loss: 2.2233766484461674
Validation loss: 2.007155309208163
Epoch: 7| Step: 15
Training loss: 1.7336714408694844
Validation loss: 1.9909097015812192
Epoch: 59| Step: 0
Training loss: 2.5578017545088696
Validation loss: 1.9993074463708185
Epoch: 7| Step: 1
Training loss: 2.508576083767063
Validation loss: 2.0046297561996704
Epoch: 7| Step: 2
Training loss: 2.1649368668088376
Validation loss: 1.9820654602600492
Epoch: 7| Step: 3
Training loss: 2.8996286746419213
Validation loss: 1.9998328385711763
Epoch: 7| Step: 4
Training loss: 1.989301858001426
Validation loss: 1.9809772897508071
Epoch: 7| Step: 5
Training loss: 2.890813048148514
Validation loss: 2.000219171964362
Epoch: 7| Step: 6
Training loss: 2.651186885990775
Validation loss: 2.000975348620399
Epoch: 7| Step: 7
Training loss: 2.0752738955709398
Validation loss: 1.9980714312726253
Epoch: 7| Step: 8
Training loss: 1.6692158595260709
Validation loss: 1.992527928931976
Epoch: 7| Step: 9
Training loss: 2.621737223518663
Validation loss: 2.0040097542671758
Epoch: 7| Step: 10
Training loss: 2.3778587001724554
Validation loss: 1.995602527914313
Epoch: 7| Step: 11
Training loss: 2.2878259437019106
Validation loss: 1.9927902365383743
Epoch: 7| Step: 12
Training loss: 2.47135353423346
Validation loss: 1.9922889210475356
Epoch: 7| Step: 13
Training loss: 2.7172985367903935
Validation loss: 1.9939695015175116
Epoch: 7| Step: 14
Training loss: 2.3590896130690404
Validation loss: 1.985296309020737
Epoch: 7| Step: 15
Training loss: 2.0598087670163086
Validation loss: 1.9862891372603548
Epoch: 60| Step: 0
Training loss: 2.110688768213691
Validation loss: 1.9784762132790388
Epoch: 7| Step: 1
Training loss: 2.203883804699213
Validation loss: 1.9934683602202494
Epoch: 7| Step: 2
Training loss: 2.8625718886497835
Validation loss: 1.9967767348237613
Epoch: 7| Step: 3
Training loss: 2.2728881172137756
Validation loss: 1.9803969444051888
Epoch: 7| Step: 4
Training loss: 2.1930765188690398
Validation loss: 2.002517989289062
Epoch: 7| Step: 5
Training loss: 2.497607421397706
Validation loss: 2.000433412578555
Epoch: 7| Step: 6
Training loss: 2.1086530792268117
Validation loss: 2.0057004971392143
Epoch: 7| Step: 7
Training loss: 2.7179871289058655
Validation loss: 1.9936643667062912
Epoch: 7| Step: 8
Training loss: 2.3720260873553305
Validation loss: 1.9930709448290047
Epoch: 7| Step: 9
Training loss: 1.9798270545913648
Validation loss: 2.0098087217042693
Epoch: 7| Step: 10
Training loss: 2.4970816745134057
Validation loss: 2.006763844784179
Epoch: 7| Step: 11
Training loss: 2.9279164568755003
Validation loss: 2.015256599007535
Epoch: 7| Step: 12
Training loss: 2.711985624562201
Validation loss: 2.009162676550093
Epoch: 7| Step: 13
Training loss: 2.153533994145537
Validation loss: 1.9856874476719748
Epoch: 7| Step: 14
Training loss: 2.36847402530123
Validation loss: 2.008276537009083
Epoch: 7| Step: 15
Training loss: 2.4779092394115216
Validation loss: 1.9923557239773364
Epoch: 61| Step: 0
Training loss: 2.3770258444928536
Validation loss: 1.996995199530787
Epoch: 7| Step: 1
Training loss: 2.2287172833072284
Validation loss: 2.005858024707161
Epoch: 7| Step: 2
Training loss: 2.769726142428658
Validation loss: 2.0063485795998557
Epoch: 7| Step: 3
Training loss: 2.522709413726102
Validation loss: 1.9992787238200642
Epoch: 7| Step: 4
Training loss: 2.0184573596214173
Validation loss: 1.9907224420827785
Epoch: 7| Step: 5
Training loss: 2.56648604967141
Validation loss: 2.0048736818451216
Epoch: 7| Step: 6
Training loss: 2.543795637241536
Validation loss: 1.996979423751598
Epoch: 7| Step: 7
Training loss: 2.4655796409466944
Validation loss: 1.9997198457868703
Epoch: 7| Step: 8
Training loss: 2.356681954128783
Validation loss: 1.9697587815338489
Epoch: 7| Step: 9
Training loss: 2.4832110287377165
Validation loss: 1.9970429228639328
Epoch: 7| Step: 10
Training loss: 2.5558924268672354
Validation loss: 1.9968641788943118
Epoch: 7| Step: 11
Training loss: 2.27529443365615
Validation loss: 1.9798871970002394
Epoch: 7| Step: 12
Training loss: 2.5726313464977664
Validation loss: 1.9840713356888813
Epoch: 7| Step: 13
Training loss: 1.9666910455561275
Validation loss: 1.9973286142198312
Epoch: 7| Step: 14
Training loss: 2.1765627322227643
Validation loss: 1.9793261956362966
Epoch: 7| Step: 15
Training loss: 2.6358449434629123
Validation loss: 1.982370699995332
Epoch: 62| Step: 0
Training loss: 2.386970669052
Validation loss: 1.99378286883013
Epoch: 7| Step: 1
Training loss: 2.537991247872968
Validation loss: 1.9991364354927674
Epoch: 7| Step: 2
Training loss: 1.8503898416058084
Validation loss: 1.9799505024300517
Epoch: 7| Step: 3
Training loss: 2.615274487416426
Validation loss: 1.9806253610100717
Epoch: 7| Step: 4
Training loss: 2.3998535151282643
Validation loss: 1.9778727495958022
Epoch: 7| Step: 5
Training loss: 2.581218274085495
Validation loss: 2.0016893663531286
Epoch: 7| Step: 6
Training loss: 2.597528486049738
Validation loss: 1.9963248545757286
Epoch: 7| Step: 7
Training loss: 2.5442610356205018
Validation loss: 2.015182304367908
Epoch: 7| Step: 8
Training loss: 2.351188046877792
Validation loss: 1.9977852116304182
Epoch: 7| Step: 9
Training loss: 1.9367759336067483
Validation loss: 2.0019807893568853
Epoch: 7| Step: 10
Training loss: 2.7537162985797874
Validation loss: 2.0036901097191278
Epoch: 7| Step: 11
Training loss: 2.1692803341831883
Validation loss: 2.009988488362607
Epoch: 7| Step: 12
Training loss: 2.2547110933693895
Validation loss: 1.990009187949233
Epoch: 7| Step: 13
Training loss: 2.4275193920991307
Validation loss: 2.024141946258403
Epoch: 7| Step: 14
Training loss: 3.0527365617994406
Validation loss: 1.9980176794993947
Epoch: 7| Step: 15
Training loss: 1.9412484363910694
Validation loss: 1.9975257496027377
Epoch: 63| Step: 0
Training loss: 2.7291367410276104
Validation loss: 2.0019360220540334
Epoch: 7| Step: 1
Training loss: 2.321976703865363
Validation loss: 1.98316066938016
Epoch: 7| Step: 2
Training loss: 2.671399793695726
Validation loss: 2.0142055986281924
Epoch: 7| Step: 3
Training loss: 2.412376926425501
Validation loss: 1.9950184314330717
Epoch: 7| Step: 4
Training loss: 2.9105558594659846
Validation loss: 2.0023468337493244
Epoch: 7| Step: 5
Training loss: 2.046254537177721
Validation loss: 1.9858703542611564
Epoch: 7| Step: 6
Training loss: 2.496438923402455
Validation loss: 1.98664126104583
Epoch: 7| Step: 7
Training loss: 2.745428968031382
Validation loss: 1.976658777155691
Epoch: 7| Step: 8
Training loss: 2.2026698947810486
Validation loss: 2.000638467260904
Epoch: 7| Step: 9
Training loss: 2.5008589222747237
Validation loss: 1.9875640792076117
Epoch: 7| Step: 10
Training loss: 2.1722217530003154
Validation loss: 1.9957830635441873
Epoch: 7| Step: 11
Training loss: 2.4652467812274486
Validation loss: 1.995098498379179
Epoch: 7| Step: 12
Training loss: 2.894282156539019
Validation loss: 1.9859215224274933
Epoch: 7| Step: 13
Training loss: 2.143301745113242
Validation loss: 1.9880331976364365
Epoch: 7| Step: 14
Training loss: 1.515252608336819
Validation loss: 2.0016583884317667
Epoch: 7| Step: 15
Training loss: 1.9504570400941124
Validation loss: 1.9860121380029137
Epoch: 64| Step: 0
Training loss: 2.8352836927129643
Validation loss: 1.989669294439186
Epoch: 7| Step: 1
Training loss: 2.4561718527905727
Validation loss: 1.9980350723373217
Epoch: 7| Step: 2
Training loss: 2.82338093298278
Validation loss: 1.9792180100439358
Epoch: 7| Step: 3
Training loss: 2.0837556665225634
Validation loss: 1.9895943553255764
Epoch: 7| Step: 4
Training loss: 2.499821179670332
Validation loss: 1.986335308032281
Epoch: 7| Step: 5
Training loss: 2.3576522499670944
Validation loss: 1.9878561081589885
Epoch: 7| Step: 6
Training loss: 2.129103345234209
Validation loss: 2.0054686351066295
Epoch: 7| Step: 7
Training loss: 2.5222664114525646
Validation loss: 1.985450421789811
Epoch: 7| Step: 8
Training loss: 2.5928587703707233
Validation loss: 1.9959941898674203
Epoch: 7| Step: 9
Training loss: 2.7289296015699467
Validation loss: 1.975301871168636
Epoch: 7| Step: 10
Training loss: 2.236586643252315
Validation loss: 1.99120747392188
Epoch: 7| Step: 11
Training loss: 2.4061840097865828
Validation loss: 2.010617311684554
Epoch: 7| Step: 12
Training loss: 2.200135495608315
Validation loss: 1.9858574749206224
Epoch: 7| Step: 13
Training loss: 2.6459483825020076
Validation loss: 1.9883434336330397
Epoch: 7| Step: 14
Training loss: 1.4977897413416172
Validation loss: 1.9930383796868796
Epoch: 7| Step: 15
Training loss: 2.2187368902974276
Validation loss: 1.998102185484417
Epoch: 65| Step: 0
Training loss: 2.3134288468921125
Validation loss: 1.9980672861431341
Epoch: 7| Step: 1
Training loss: 2.1151200789324522
Validation loss: 1.985114457292725
Epoch: 7| Step: 2
Training loss: 2.308501833975503
Validation loss: 2.0065048353199404
Epoch: 7| Step: 3
Training loss: 2.474074597220113
Validation loss: 2.005812982442271
Epoch: 7| Step: 4
Training loss: 2.466327009356979
Validation loss: 1.9654572016416128
Epoch: 7| Step: 5
Training loss: 2.4449203225475378
Validation loss: 1.9949691896766657
Epoch: 7| Step: 6
Training loss: 2.617912260451842
Validation loss: 1.997201039649652
Epoch: 7| Step: 7
Training loss: 2.6203579502338066
Validation loss: 2.0092354752730723
Epoch: 7| Step: 8
Training loss: 2.404256614267399
Validation loss: 1.9825200491497295
Epoch: 7| Step: 9
Training loss: 2.8313937186507014
Validation loss: 2.0029933334498327
Epoch: 7| Step: 10
Training loss: 2.2037891442018793
Validation loss: 2.0030409422553066
Epoch: 7| Step: 11
Training loss: 2.147464712294886
Validation loss: 1.9933873191518432
Epoch: 7| Step: 12
Training loss: 2.434114795338039
Validation loss: 2.0053458134650524
Epoch: 7| Step: 13
Training loss: 2.2678236191871095
Validation loss: 1.994540391292162
Epoch: 7| Step: 14
Training loss: 2.295446769261687
Validation loss: 1.9899094102993524
Epoch: 7| Step: 15
Training loss: 2.5042477760148927
Validation loss: 1.9928256455567235
Epoch: 66| Step: 0
Training loss: 2.6150253246532587
Validation loss: 1.9872540757193802
Epoch: 7| Step: 1
Training loss: 1.9070839230374883
Validation loss: 1.9932268527915007
Epoch: 7| Step: 2
Training loss: 2.740495904472254
Validation loss: 1.9894698383868958
Epoch: 7| Step: 3
Training loss: 2.1525179866876645
Validation loss: 1.9885181646558208
Epoch: 7| Step: 4
Training loss: 2.22429094053383
Validation loss: 1.9907008418910481
Epoch: 7| Step: 5
Training loss: 2.5519387859488765
Validation loss: 1.9925310890293457
Epoch: 7| Step: 6
Training loss: 1.6932630676549287
Validation loss: 1.9907635463537927
Epoch: 7| Step: 7
Training loss: 2.627147431969317
Validation loss: 1.9967062719756832
Epoch: 7| Step: 8
Training loss: 2.1024892812630287
Validation loss: 1.9956673519755443
Epoch: 7| Step: 9
Training loss: 2.1581750652163465
Validation loss: 1.9921728511797694
Epoch: 7| Step: 10
Training loss: 2.183876524274852
Validation loss: 1.983381039388713
Epoch: 7| Step: 11
Training loss: 1.6643463036029043
Validation loss: 1.9781285784433331
Epoch: 7| Step: 12
Training loss: 2.3521849356625038
Validation loss: 1.9658379795653893
Epoch: 7| Step: 13
Training loss: 2.5780227178456028
Validation loss: 1.983172414755656
Epoch: 7| Step: 14
Training loss: 3.2293243041580357
Validation loss: 1.987741081102922
Epoch: 7| Step: 15
Training loss: 3.081795145523097
Validation loss: 1.9992684939345737
Epoch: 67| Step: 0
Training loss: 1.9458205084476783
Validation loss: 1.9718842964491667
Epoch: 7| Step: 1
Training loss: 2.224190180989962
Validation loss: 1.9799635926464814
Epoch: 7| Step: 2
Training loss: 2.3585584629650116
Validation loss: 1.988572781892653
Epoch: 7| Step: 3
Training loss: 2.4826179865125377
Validation loss: 1.9806287892915249
Epoch: 7| Step: 4
Training loss: 2.424468393161874
Validation loss: 1.9838159999355838
Epoch: 7| Step: 5
Training loss: 1.9873529151856926
Validation loss: 1.9820720812773647
Epoch: 7| Step: 6
Training loss: 2.719341608332134
Validation loss: 1.9878144441355914
Epoch: 7| Step: 7
Training loss: 2.2616667799175385
Validation loss: 1.9901717440958677
Epoch: 7| Step: 8
Training loss: 2.644880578819127
Validation loss: 1.9855229940864632
Epoch: 7| Step: 9
Training loss: 2.408400132287945
Validation loss: 1.9659680230953656
Epoch: 7| Step: 10
Training loss: 2.119022039092714
Validation loss: 1.9888250675192343
Epoch: 7| Step: 11
Training loss: 2.234843811790467
Validation loss: 1.9802155717626362
Epoch: 7| Step: 12
Training loss: 3.1129589799481527
Validation loss: 1.9806387614540946
Epoch: 7| Step: 13
Training loss: 2.272772727858542
Validation loss: 1.9833943615077079
Epoch: 7| Step: 14
Training loss: 2.34381266192276
Validation loss: 1.9945641551432003
Epoch: 7| Step: 15
Training loss: 2.657785487948787
Validation loss: 1.9903174506976642
Epoch: 68| Step: 0
Training loss: 2.6185075306225962
Validation loss: 1.9880539419000172
Epoch: 7| Step: 1
Training loss: 2.2298330814175054
Validation loss: 1.9893557003460456
Epoch: 7| Step: 2
Training loss: 2.752686488792106
Validation loss: 1.9871621314889736
Epoch: 7| Step: 3
Training loss: 2.8212273717402927
Validation loss: 1.9787530278976586
Epoch: 7| Step: 4
Training loss: 2.214649871467754
Validation loss: 1.976484376875728
Epoch: 7| Step: 5
Training loss: 2.2692259486320054
Validation loss: 1.9897267511641168
Epoch: 7| Step: 6
Training loss: 2.874337493193914
Validation loss: 1.973794536594776
Epoch: 7| Step: 7
Training loss: 1.8973941526179514
Validation loss: 1.9809555726643469
Epoch: 7| Step: 8
Training loss: 2.3136448474898135
Validation loss: 1.9836910698431778
Epoch: 7| Step: 9
Training loss: 1.972274108735498
Validation loss: 1.9850904454879377
Epoch: 7| Step: 10
Training loss: 2.184211984644798
Validation loss: 1.9889816757426588
Epoch: 7| Step: 11
Training loss: 2.414631501826276
Validation loss: 2.004305508249208
Epoch: 7| Step: 12
Training loss: 2.4464909940359325
Validation loss: 1.9997245576895581
Epoch: 7| Step: 13
Training loss: 2.5411854481226843
Validation loss: 2.0053571980048344
Epoch: 7| Step: 14
Training loss: 2.5323262693383537
Validation loss: 1.9925582854044745
Epoch: 7| Step: 15
Training loss: 2.114928218985212
Validation loss: 2.000349355577636
Epoch: 69| Step: 0
Training loss: 2.8194523818014465
Validation loss: 1.9954190055843135
Epoch: 7| Step: 1
Training loss: 2.434740901376559
Validation loss: 1.9935481787685432
Epoch: 7| Step: 2
Training loss: 2.593471466184011
Validation loss: 2.0064813245357582
Epoch: 7| Step: 3
Training loss: 1.898966397679696
Validation loss: 1.9989636029022864
Epoch: 7| Step: 4
Training loss: 2.5455730831734815
Validation loss: 2.003531877047222
Epoch: 7| Step: 5
Training loss: 2.6477935818433394
Validation loss: 2.002598952753571
Epoch: 7| Step: 6
Training loss: 2.084018124250797
Validation loss: 2.0000964548455715
Epoch: 7| Step: 7
Training loss: 2.558990494347076
Validation loss: 1.994889111634287
Epoch: 7| Step: 8
Training loss: 3.0850107080901292
Validation loss: 2.0023363019189304
Epoch: 7| Step: 9
Training loss: 2.341811128370927
Validation loss: 1.9944652765521054
Epoch: 7| Step: 10
Training loss: 2.1717096718633333
Validation loss: 1.9882004830968483
Epoch: 7| Step: 11
Training loss: 2.191906659387392
Validation loss: 2.0089430727912077
Epoch: 7| Step: 12
Training loss: 2.4702871824411248
Validation loss: 2.007183686693976
Epoch: 7| Step: 13
Training loss: 1.8243774737099228
Validation loss: 1.9962377555724888
Epoch: 7| Step: 14
Training loss: 2.2312034025054843
Validation loss: 1.996013529304253
Epoch: 7| Step: 15
Training loss: 2.135295386863409
Validation loss: 1.9870303129408158
Epoch: 70| Step: 0
Training loss: 2.2529792135323587
Validation loss: 2.0060902710603226
Epoch: 7| Step: 1
Training loss: 2.3776417144674022
Validation loss: 1.9953768234094675
Epoch: 7| Step: 2
Training loss: 2.1589667854952244
Validation loss: 2.000129495803747
Epoch: 7| Step: 3
Training loss: 2.27275457972681
Validation loss: 1.9750921561461916
Epoch: 7| Step: 4
Training loss: 2.5703564671985166
Validation loss: 2.002536898536584
Epoch: 7| Step: 5
Training loss: 2.4853554956071533
Validation loss: 2.0044184297023477
Epoch: 7| Step: 6
Training loss: 2.011034091624451
Validation loss: 2.0127797299199024
Epoch: 7| Step: 7
Training loss: 2.849814686690017
Validation loss: 2.017640973902413
Epoch: 7| Step: 8
Training loss: 2.2130892900948704
Validation loss: 2.017172378023179
Epoch: 7| Step: 9
Training loss: 2.8226548715139868
Validation loss: 1.9966444977798732
Epoch: 7| Step: 10
Training loss: 2.069975397267849
Validation loss: 1.992373685429342
Epoch: 7| Step: 11
Training loss: 2.4841794110926414
Validation loss: 2.0073900395215496
Epoch: 7| Step: 12
Training loss: 2.473072758166953
Validation loss: 2.0190249874609
Epoch: 7| Step: 13
Training loss: 2.448832358221088
Validation loss: 2.0064891175324218
Epoch: 7| Step: 14
Training loss: 2.631757485205941
Validation loss: 2.0062391881940638
Epoch: 7| Step: 15
Training loss: 2.083065498937508
Validation loss: 1.9983912713359882
Epoch: 71| Step: 0
Training loss: 2.4734111194083352
Validation loss: 2.0091048424083993
Epoch: 7| Step: 1
Training loss: 2.172109248201067
Validation loss: 1.9905658287400927
Epoch: 7| Step: 2
Training loss: 2.871342696211888
Validation loss: 1.9959933950443904
Epoch: 7| Step: 3
Training loss: 1.7255936748199483
Validation loss: 1.9812405885285638
Epoch: 7| Step: 4
Training loss: 2.3278110983787124
Validation loss: 1.9865105789187358
Epoch: 7| Step: 5
Training loss: 1.6976674682976816
Validation loss: 1.9959721844348215
Epoch: 7| Step: 6
Training loss: 2.165308294216481
Validation loss: 1.987121936675595
Epoch: 7| Step: 7
Training loss: 3.1042716160043367
Validation loss: 1.998447408024854
Epoch: 7| Step: 8
Training loss: 2.487642454736006
Validation loss: 1.9846907772191325
Epoch: 7| Step: 9
Training loss: 2.690611701250163
Validation loss: 1.9829379492013874
Epoch: 7| Step: 10
Training loss: 2.339509306427491
Validation loss: 1.9936949405344462
Epoch: 7| Step: 11
Training loss: 2.485868760650534
Validation loss: 1.9845692519081237
Epoch: 7| Step: 12
Training loss: 2.467461938071694
Validation loss: 1.9843771733813698
Epoch: 7| Step: 13
Training loss: 2.054888233199057
Validation loss: 1.9761580150733788
Epoch: 7| Step: 14
Training loss: 2.1707539031957874
Validation loss: 1.9895126679699187
Epoch: 7| Step: 15
Training loss: 2.6463007676737584
Validation loss: 1.9884401120920157
Epoch: 72| Step: 0
Training loss: 2.3153740833158944
Validation loss: 1.9794620305169488
Epoch: 7| Step: 1
Training loss: 2.612232767701571
Validation loss: 1.989285819635494
Epoch: 7| Step: 2
Training loss: 2.4808522325982643
Validation loss: 1.9717040118444822
Epoch: 7| Step: 3
Training loss: 2.536510417385204
Validation loss: 1.9846794785116426
Epoch: 7| Step: 4
Training loss: 2.037138634212812
Validation loss: 1.9875160913744856
Epoch: 7| Step: 5
Training loss: 2.2927624481299165
Validation loss: 2.005369381235905
Epoch: 7| Step: 6
Training loss: 2.3701075304963957
Validation loss: 1.9961213113848295
Epoch: 7| Step: 7
Training loss: 2.523000862444996
Validation loss: 1.9979427541100092
Epoch: 7| Step: 8
Training loss: 2.4219317029652436
Validation loss: 1.9945823185793408
Epoch: 7| Step: 9
Training loss: 2.6538166344318164
Validation loss: 2.0080402690815014
Epoch: 7| Step: 10
Training loss: 2.182511773006676
Validation loss: 1.998604972025437
Epoch: 7| Step: 11
Training loss: 2.3841418951037223
Validation loss: 1.991994506627688
Epoch: 7| Step: 12
Training loss: 2.2379331201509474
Validation loss: 2.0031941793500723
Epoch: 7| Step: 13
Training loss: 2.9772458230787793
Validation loss: 1.9951075016905042
Epoch: 7| Step: 14
Training loss: 2.088192638682154
Validation loss: 1.9918344233820109
Epoch: 7| Step: 15
Training loss: 2.1023229194666655
Validation loss: 1.9896925731371702
Epoch: 73| Step: 0
Training loss: 2.6350289362380845
Validation loss: 1.9843502562433806
Epoch: 7| Step: 1
Training loss: 2.3526050373104215
Validation loss: 1.9989924005960553
Epoch: 7| Step: 2
Training loss: 2.0983683196229785
Validation loss: 1.9800778650767565
Epoch: 7| Step: 3
Training loss: 2.3371046333704824
Validation loss: 1.9816024850066232
Epoch: 7| Step: 4
Training loss: 2.3372809077924614
Validation loss: 1.999625933092681
Epoch: 7| Step: 5
Training loss: 2.303192170818626
Validation loss: 1.9913643037299666
Epoch: 7| Step: 6
Training loss: 2.3228232417685164
Validation loss: 1.978394265562759
Epoch: 7| Step: 7
Training loss: 2.449960112733592
Validation loss: 1.9842192624834265
Epoch: 7| Step: 8
Training loss: 2.417067845248945
Validation loss: 1.986603231819948
Epoch: 7| Step: 9
Training loss: 2.2985895725046586
Validation loss: 1.9781106496270113
Epoch: 7| Step: 10
Training loss: 2.44122899747175
Validation loss: 1.971948155137495
Epoch: 7| Step: 11
Training loss: 2.2158177301384248
Validation loss: 1.982652971715011
Epoch: 7| Step: 12
Training loss: 1.9795939603292936
Validation loss: 1.967960517250007
Epoch: 7| Step: 13
Training loss: 2.645275467660162
Validation loss: 1.9845872677381804
Epoch: 7| Step: 14
Training loss: 3.261250024797725
Validation loss: 1.9958439394843803
Epoch: 7| Step: 15
Training loss: 2.054366982412172
Validation loss: 1.9782192638101217
Epoch: 74| Step: 0
Training loss: 2.587912920010095
Validation loss: 1.9956254811016498
Epoch: 7| Step: 1
Training loss: 2.3241504306529297
Validation loss: 1.9843039748154747
Epoch: 7| Step: 2
Training loss: 2.0562579169309383
Validation loss: 1.9803530069375703
Epoch: 7| Step: 3
Training loss: 2.7863327045582196
Validation loss: 1.9921810573508774
Epoch: 7| Step: 4
Training loss: 2.4378872099236517
Validation loss: 1.9890911528645703
Epoch: 7| Step: 5
Training loss: 2.2615351100020473
Validation loss: 1.972161936013966
Epoch: 7| Step: 6
Training loss: 2.4825110970947315
Validation loss: 1.973754741261301
Epoch: 7| Step: 7
Training loss: 2.4755377830622285
Validation loss: 1.9959774049504113
Epoch: 7| Step: 8
Training loss: 2.7815121302143884
Validation loss: 1.9894686657990168
Epoch: 7| Step: 9
Training loss: 2.3003068055894866
Validation loss: 1.9904869307045578
Epoch: 7| Step: 10
Training loss: 2.4783633450621614
Validation loss: 1.9931538483282445
Epoch: 7| Step: 11
Training loss: 2.2595776056855676
Validation loss: 1.9842123997915213
Epoch: 7| Step: 12
Training loss: 2.010851982568777
Validation loss: 1.9921806411606056
Epoch: 7| Step: 13
Training loss: 2.367084563884562
Validation loss: 1.9800728515173147
Epoch: 7| Step: 14
Training loss: 1.9705353770396807
Validation loss: 1.981934443858481
Epoch: 7| Step: 15
Training loss: 2.5720977612569733
Validation loss: 1.9809575447156824
Epoch: 75| Step: 0
Training loss: 2.307497748707575
Validation loss: 1.9815731996676393
Epoch: 7| Step: 1
Training loss: 1.9828163092826885
Validation loss: 1.9887856417428997
Epoch: 7| Step: 2
Training loss: 2.397539797105532
Validation loss: 1.989789185269767
Epoch: 7| Step: 3
Training loss: 2.4414110351515608
Validation loss: 1.9845653607428668
Epoch: 7| Step: 4
Training loss: 2.125157967474124
Validation loss: 1.9785438491441174
Epoch: 7| Step: 5
Training loss: 2.545198227932397
Validation loss: 1.9825259918247307
Epoch: 7| Step: 6
Training loss: 2.2906007773249235
Validation loss: 1.9961260667050775
Epoch: 7| Step: 7
Training loss: 2.4223022084148793
Validation loss: 1.9803096328451348
Epoch: 7| Step: 8
Training loss: 2.795512288322589
Validation loss: 2.013722214527532
Epoch: 7| Step: 9
Training loss: 2.2853634471370747
Validation loss: 2.0005803884817417
Epoch: 7| Step: 10
Training loss: 2.42065851977774
Validation loss: 2.003474638118756
Epoch: 7| Step: 11
Training loss: 2.371083493658316
Validation loss: 1.9984315740583194
Epoch: 7| Step: 12
Training loss: 1.7105686016493131
Validation loss: 2.012449252456942
Epoch: 7| Step: 13
Training loss: 3.1162409289335518
Validation loss: 1.9902914071039304
Epoch: 7| Step: 14
Training loss: 2.300521240050096
Validation loss: 2.002183117707923
Epoch: 7| Step: 15
Training loss: 2.494219582307874
Validation loss: 2.010298289337509
Epoch: 76| Step: 0
Training loss: 2.116831844623149
Validation loss: 1.9885612107447255
Epoch: 7| Step: 1
Training loss: 2.122641769545117
Validation loss: 1.9895882389433983
Epoch: 7| Step: 2
Training loss: 2.6635605683226067
Validation loss: 2.007111518145007
Epoch: 7| Step: 3
Training loss: 2.909525184565616
Validation loss: 1.9936505038912533
Epoch: 7| Step: 4
Training loss: 2.220287059232821
Validation loss: 2.011736121911768
Epoch: 7| Step: 5
Training loss: 2.5290701628304597
Validation loss: 1.9743454855419027
Epoch: 7| Step: 6
Training loss: 2.5843485303858627
Validation loss: 1.9888065997754671
Epoch: 7| Step: 7
Training loss: 2.2048332139166864
Validation loss: 1.9963178852742347
Epoch: 7| Step: 8
Training loss: 2.7772499208119794
Validation loss: 1.9893524503132445
Epoch: 7| Step: 9
Training loss: 2.0036127124571195
Validation loss: 1.977237449409676
Epoch: 7| Step: 10
Training loss: 2.6611187463791093
Validation loss: 1.9741293820609003
Epoch: 7| Step: 11
Training loss: 2.32913534271887
Validation loss: 1.9959090595370685
Epoch: 7| Step: 12
Training loss: 2.4135610312677103
Validation loss: 1.9919001468498485
Epoch: 7| Step: 13
Training loss: 2.225186535163282
Validation loss: 1.989399794180814
Epoch: 7| Step: 14
Training loss: 2.254062693437351
Validation loss: 1.9937770436160553
Epoch: 7| Step: 15
Training loss: 1.98336165378557
Validation loss: 1.9747165841279217
Epoch: 77| Step: 0
Training loss: 2.249080046033666
Validation loss: 1.9529830062868636
Epoch: 7| Step: 1
Training loss: 2.178316184017483
Validation loss: 1.9849721986016977
Epoch: 7| Step: 2
Training loss: 2.8202473218154602
Validation loss: 1.9682217763170675
Epoch: 7| Step: 3
Training loss: 2.218120109443078
Validation loss: 1.9809348118320083
Epoch: 7| Step: 4
Training loss: 2.8279599304921628
Validation loss: 1.9774868886507433
Epoch: 7| Step: 5
Training loss: 2.1206994015036846
Validation loss: 1.97579467094603
Epoch: 7| Step: 6
Training loss: 2.2443800782688257
Validation loss: 1.982673423394401
Epoch: 7| Step: 7
Training loss: 2.3457866720524287
Validation loss: 1.976492234542105
Epoch: 7| Step: 8
Training loss: 2.0714057770776217
Validation loss: 1.9744400037217729
Epoch: 7| Step: 9
Training loss: 2.481536875555145
Validation loss: 1.9779349490605331
Epoch: 7| Step: 10
Training loss: 1.8290911998546886
Validation loss: 1.9834204193164562
Epoch: 7| Step: 11
Training loss: 2.5572569638219997
Validation loss: 1.9885384306295493
Epoch: 7| Step: 12
Training loss: 2.4698285028635345
Validation loss: 1.9917760095990642
Epoch: 7| Step: 13
Training loss: 2.9893134833818804
Validation loss: 1.9755074147696376
Epoch: 7| Step: 14
Training loss: 2.4811785786148186
Validation loss: 1.9800743025718635
Epoch: 7| Step: 15
Training loss: 2.0292129866413258
Validation loss: 1.9970628295251307
Epoch: 78| Step: 0
Training loss: 1.4009023074738114
Validation loss: 1.9942068259748071
Epoch: 7| Step: 1
Training loss: 2.594378199969372
Validation loss: 1.9885200619808605
Epoch: 7| Step: 2
Training loss: 2.284485599538393
Validation loss: 1.988786216352184
Epoch: 7| Step: 3
Training loss: 2.4146428567978764
Validation loss: 1.9770220335663784
Epoch: 7| Step: 4
Training loss: 2.062071553436422
Validation loss: 1.9880062510575747
Epoch: 7| Step: 5
Training loss: 2.406932882535675
Validation loss: 1.9885018936586887
Epoch: 7| Step: 6
Training loss: 2.793942837812387
Validation loss: 1.9772177826312052
Epoch: 7| Step: 7
Training loss: 2.711144079423089
Validation loss: 1.9935653635413884
Epoch: 7| Step: 8
Training loss: 2.3842235952080966
Validation loss: 1.9992640027875204
Epoch: 7| Step: 9
Training loss: 2.6972978881409047
Validation loss: 1.9923551938386932
Epoch: 7| Step: 10
Training loss: 2.1666557116109266
Validation loss: 2.0062467956362307
Epoch: 7| Step: 11
Training loss: 2.770950018545903
Validation loss: 2.0022944591405953
Epoch: 7| Step: 12
Training loss: 2.1454664737710734
Validation loss: 1.9954259858985424
Epoch: 7| Step: 13
Training loss: 2.2368418274279915
Validation loss: 2.0028094471831204
Epoch: 7| Step: 14
Training loss: 2.314929304753093
Validation loss: 1.9963105370850045
Epoch: 7| Step: 15
Training loss: 2.492586396919063
Validation loss: 1.9966041918369224
Epoch: 79| Step: 0
Training loss: 2.371975729993454
Validation loss: 1.9838574113048184
Epoch: 7| Step: 1
Training loss: 2.543443017380164
Validation loss: 1.9758927899135754
Epoch: 7| Step: 2
Training loss: 1.9063858859298104
Validation loss: 2.0095925245200226
Epoch: 7| Step: 3
Training loss: 2.1983655016292585
Validation loss: 1.991789212407684
Epoch: 7| Step: 4
Training loss: 2.529757778046819
Validation loss: 1.9965634806938515
Epoch: 7| Step: 5
Training loss: 2.4777720292580163
Validation loss: 1.999050180540752
Epoch: 7| Step: 6
Training loss: 1.9962130098492816
Validation loss: 1.9947648805283245
Epoch: 7| Step: 7
Training loss: 2.3821658398272656
Validation loss: 1.9921745553869008
Epoch: 7| Step: 8
Training loss: 2.4191206497754854
Validation loss: 1.9929418716085512
Epoch: 7| Step: 9
Training loss: 2.2867861942084704
Validation loss: 1.9794519331744203
Epoch: 7| Step: 10
Training loss: 2.688577391662865
Validation loss: 1.9703282983449668
Epoch: 7| Step: 11
Training loss: 2.759901946440722
Validation loss: 1.9844239279610392
Epoch: 7| Step: 12
Training loss: 2.6873713617809885
Validation loss: 1.9818322371549302
Epoch: 7| Step: 13
Training loss: 2.1631557065850338
Validation loss: 1.9737534583974607
Epoch: 7| Step: 14
Training loss: 2.350424862054843
Validation loss: 1.9794540409397146
Epoch: 7| Step: 15
Training loss: 2.3222782529290282
Validation loss: 1.9831721831803972
Epoch: 80| Step: 0
Training loss: 2.1770673200635913
Validation loss: 1.9804649272287675
Epoch: 7| Step: 1
Training loss: 2.53011748798771
Validation loss: 1.9833676484832357
Epoch: 7| Step: 2
Training loss: 1.829644183290325
Validation loss: 1.9891495458297141
Epoch: 7| Step: 3
Training loss: 1.893707159080254
Validation loss: 1.9750101717490711
Epoch: 7| Step: 4
Training loss: 2.8933389656023794
Validation loss: 1.9827850565905947
Epoch: 7| Step: 5
Training loss: 2.9173933123095517
Validation loss: 1.9793758741138632
Epoch: 7| Step: 6
Training loss: 2.243008984796469
Validation loss: 1.9855698121537926
Epoch: 7| Step: 7
Training loss: 2.5620491747756335
Validation loss: 1.964307184577404
Epoch: 7| Step: 8
Training loss: 2.0410433096582334
Validation loss: 1.9823042450600667
Epoch: 7| Step: 9
Training loss: 2.5251098382306845
Validation loss: 1.9864093812098444
Epoch: 7| Step: 10
Training loss: 1.945017842110434
Validation loss: 1.9775471438162435
Epoch: 7| Step: 11
Training loss: 2.7345247064207765
Validation loss: 1.974678771096482
Epoch: 7| Step: 12
Training loss: 2.42309677316176
Validation loss: 1.9839835783772808
Epoch: 7| Step: 13
Training loss: 2.4528020172342266
Validation loss: 1.989812345540385
Epoch: 7| Step: 14
Training loss: 2.5329340289621567
Validation loss: 1.954843499870811
Epoch: 7| Step: 15
Training loss: 2.132362961116872
Validation loss: 1.9834485038491645
Epoch: 81| Step: 0
Training loss: 3.052082326496119
Validation loss: 1.9621382588754102
Epoch: 7| Step: 1
Training loss: 2.343835244218026
Validation loss: 1.966257443736056
Epoch: 7| Step: 2
Training loss: 1.6219698457419656
Validation loss: 1.992601665039702
Epoch: 7| Step: 3
Training loss: 2.4990858313943085
Validation loss: 1.988833072163501
Epoch: 7| Step: 4
Training loss: 2.0001710580152943
Validation loss: 1.9867412644665863
Epoch: 7| Step: 5
Training loss: 1.9057868645055125
Validation loss: 2.0068800878802104
Epoch: 7| Step: 6
Training loss: 2.294542230898669
Validation loss: 1.9862574334594836
Epoch: 7| Step: 7
Training loss: 2.1822865075632323
Validation loss: 1.9970824967442782
Epoch: 7| Step: 8
Training loss: 2.403357116839025
Validation loss: 1.989264576952526
Epoch: 7| Step: 9
Training loss: 2.683672819124914
Validation loss: 2.0070113157358835
Epoch: 7| Step: 10
Training loss: 2.641265069256901
Validation loss: 1.997826434340242
Epoch: 7| Step: 11
Training loss: 2.3392814253473433
Validation loss: 2.0014146379547433
Epoch: 7| Step: 12
Training loss: 2.824444815846334
Validation loss: 1.9936095463629322
Epoch: 7| Step: 13
Training loss: 2.2455212203394725
Validation loss: 2.0123085861938086
Epoch: 7| Step: 14
Training loss: 2.8345865021414602
Validation loss: 1.9932664541653333
Epoch: 7| Step: 15
Training loss: 1.7663088799102715
Validation loss: 1.9580693967473057
Epoch: 82| Step: 0
Training loss: 2.16309100768311
Validation loss: 1.9943559923116958
Epoch: 7| Step: 1
Training loss: 2.3924111070531686
Validation loss: 1.9730251825766592
Epoch: 7| Step: 2
Training loss: 2.591981307757053
Validation loss: 1.9759228187754925
Epoch: 7| Step: 3
Training loss: 2.6480589289432372
Validation loss: 1.976209700885514
Epoch: 7| Step: 4
Training loss: 2.308301258438125
Validation loss: 1.9869801756886902
Epoch: 7| Step: 5
Training loss: 2.354645593139913
Validation loss: 1.9950659423556572
Epoch: 7| Step: 6
Training loss: 2.0391759146649675
Validation loss: 1.9949421979982669
Epoch: 7| Step: 7
Training loss: 2.428710348499627
Validation loss: 1.9715737973687586
Epoch: 7| Step: 8
Training loss: 2.599014087963194
Validation loss: 1.9694189163059095
Epoch: 7| Step: 9
Training loss: 2.407436821287826
Validation loss: 1.9864897940746977
Epoch: 7| Step: 10
Training loss: 2.542604200540357
Validation loss: 1.9903414917170414
Epoch: 7| Step: 11
Training loss: 1.9144894493531612
Validation loss: 1.987885077430381
Epoch: 7| Step: 12
Training loss: 2.4913595612087627
Validation loss: 1.9658827218681632
Epoch: 7| Step: 13
Training loss: 1.8384642400098632
Validation loss: 1.9726353559473997
Epoch: 7| Step: 14
Training loss: 2.5995338021979117
Validation loss: 1.9725434538334337
Epoch: 7| Step: 15
Training loss: 2.560374331971424
Validation loss: 1.9883800422235511
Epoch: 83| Step: 0
Training loss: 2.826600143156653
Validation loss: 1.9736339345945677
Epoch: 7| Step: 1
Training loss: 2.7997704548068536
Validation loss: 1.98380048165217
Epoch: 7| Step: 2
Training loss: 2.6895178383304605
Validation loss: 1.9779921653307737
Epoch: 7| Step: 3
Training loss: 2.2788749768527743
Validation loss: 1.9608397671640125
Epoch: 7| Step: 4
Training loss: 1.699283502156151
Validation loss: 1.980903409014821
Epoch: 7| Step: 5
Training loss: 2.00279826863471
Validation loss: 1.9769475023894658
Epoch: 7| Step: 6
Training loss: 2.571580104677225
Validation loss: 1.9666379658599642
Epoch: 7| Step: 7
Training loss: 2.3981593464650337
Validation loss: 1.979315924122058
Epoch: 7| Step: 8
Training loss: 2.37761534193462
Validation loss: 1.9574359844686533
Epoch: 7| Step: 9
Training loss: 2.522285411013313
Validation loss: 1.961809410013374
Epoch: 7| Step: 10
Training loss: 2.595391271269645
Validation loss: 1.947103094321443
Epoch: 7| Step: 11
Training loss: 2.3940700068105287
Validation loss: 1.9763737766920144
Epoch: 7| Step: 12
Training loss: 1.9032826701278656
Validation loss: 1.9656440212719062
Epoch: 7| Step: 13
Training loss: 2.479153502186249
Validation loss: 1.9748898993022204
Epoch: 7| Step: 14
Training loss: 1.7675455501357835
Validation loss: 1.9728001867314402
Epoch: 7| Step: 15
Training loss: 2.4058502657904146
Validation loss: 1.982766553337234
Epoch: 84| Step: 0
Training loss: 2.9023258419177496
Validation loss: 1.9822834588421383
Epoch: 7| Step: 1
Training loss: 1.8396668561707348
Validation loss: 1.9852254109017122
Epoch: 7| Step: 2
Training loss: 2.354069688087953
Validation loss: 1.9948470929019408
Epoch: 7| Step: 3
Training loss: 2.395722682443253
Validation loss: 1.9897110883527689
Epoch: 7| Step: 4
Training loss: 2.523085058773515
Validation loss: 1.993423935201763
Epoch: 7| Step: 5
Training loss: 1.792469029817423
Validation loss: 1.9939898051375948
Epoch: 7| Step: 6
Training loss: 2.5472813381581467
Validation loss: 1.991762162312628
Epoch: 7| Step: 7
Training loss: 2.038940426033357
Validation loss: 1.9890227364948923
Epoch: 7| Step: 8
Training loss: 2.558058727905561
Validation loss: 1.965504990269533
Epoch: 7| Step: 9
Training loss: 2.481705484934229
Validation loss: 1.9849045117704747
Epoch: 7| Step: 10
Training loss: 2.7126792567215556
Validation loss: 1.9828547175625895
Epoch: 7| Step: 11
Training loss: 2.154396144762071
Validation loss: 1.9850486035429498
Epoch: 7| Step: 12
Training loss: 2.395540158675064
Validation loss: 1.9758950844222303
Epoch: 7| Step: 13
Training loss: 2.014718258378707
Validation loss: 1.9778949788748044
Epoch: 7| Step: 14
Training loss: 2.4435693542367165
Validation loss: 1.9852682268369062
Epoch: 7| Step: 15
Training loss: 2.688819029279731
Validation loss: 1.9870507107635724
Epoch: 85| Step: 0
Training loss: 2.9688042886689154
Validation loss: 1.9848238447992026
Epoch: 7| Step: 1
Training loss: 2.514302255449132
Validation loss: 1.9855395930793152
Epoch: 7| Step: 2
Training loss: 2.2108443277629393
Validation loss: 1.997259672383472
Epoch: 7| Step: 3
Training loss: 2.099347503654665
Validation loss: 1.9877455621707605
Epoch: 7| Step: 4
Training loss: 2.1910978974095876
Validation loss: 1.975267459188501
Epoch: 7| Step: 5
Training loss: 2.762633866738919
Validation loss: 1.9809758697735933
Epoch: 7| Step: 6
Training loss: 2.230471956748461
Validation loss: 1.9871464572529112
Epoch: 7| Step: 7
Training loss: 2.2053944687693443
Validation loss: 1.9747086317170113
Epoch: 7| Step: 8
Training loss: 2.7165177048952804
Validation loss: 1.993792707069098
Epoch: 7| Step: 9
Training loss: 2.655008003237169
Validation loss: 1.9908037366347044
Epoch: 7| Step: 10
Training loss: 2.531294739881183
Validation loss: 1.9759332118102215
Epoch: 7| Step: 11
Training loss: 2.023772458664022
Validation loss: 1.984184028985591
Epoch: 7| Step: 12
Training loss: 2.377011200470428
Validation loss: 1.9778478838014935
Epoch: 7| Step: 13
Training loss: 2.2887250111172532
Validation loss: 1.9719816924424913
Epoch: 7| Step: 14
Training loss: 1.958421529312474
Validation loss: 2.002061904478948
Epoch: 7| Step: 15
Training loss: 2.091901732024072
Validation loss: 1.9869324736792342
Epoch: 86| Step: 0
Training loss: 2.579481750453302
Validation loss: 1.9858406998268257
Epoch: 7| Step: 1
Training loss: 2.3161651846132543
Validation loss: 1.9735834626223534
Epoch: 7| Step: 2
Training loss: 3.027975929456857
Validation loss: 1.9938007332624736
Epoch: 7| Step: 3
Training loss: 2.0195907495466248
Validation loss: 1.9740579920164008
Epoch: 7| Step: 4
Training loss: 1.9409349203269175
Validation loss: 1.9826561787194932
Epoch: 7| Step: 5
Training loss: 1.947714307205103
Validation loss: 1.9924235596631277
Epoch: 7| Step: 6
Training loss: 2.1498426246709434
Validation loss: 1.9792645430175886
Epoch: 7| Step: 7
Training loss: 2.1268345262934507
Validation loss: 1.9683013685626867
Epoch: 7| Step: 8
Training loss: 2.5283078649751527
Validation loss: 1.962836112848289
Epoch: 7| Step: 9
Training loss: 2.624379675094027
Validation loss: 1.9807218809027554
Epoch: 7| Step: 10
Training loss: 2.401571307789741
Validation loss: 1.983260847857176
Epoch: 7| Step: 11
Training loss: 2.981208919346072
Validation loss: 1.9847532790907578
Epoch: 7| Step: 12
Training loss: 2.0665891166206247
Validation loss: 1.9730319006659651
Epoch: 7| Step: 13
Training loss: 2.385241261881148
Validation loss: 1.98552328709659
Epoch: 7| Step: 14
Training loss: 2.100219070270395
Validation loss: 1.9758016395340765
Epoch: 7| Step: 15
Training loss: 2.505363528281673
Validation loss: 1.9815042287383007
Epoch: 87| Step: 0
Training loss: 2.406368203170441
Validation loss: 1.9883188406120904
Epoch: 7| Step: 1
Training loss: 2.603761036117394
Validation loss: 1.9762413501887799
Epoch: 7| Step: 2
Training loss: 2.3108562091511793
Validation loss: 1.9755727010766462
Epoch: 7| Step: 3
Training loss: 1.9395984852571526
Validation loss: 1.9633877299688458
Epoch: 7| Step: 4
Training loss: 2.79104953795986
Validation loss: 1.9773951403745322
Epoch: 7| Step: 5
Training loss: 2.5234475150367244
Validation loss: 1.9740665294887945
Epoch: 7| Step: 6
Training loss: 2.5034535396006383
Validation loss: 1.973223404863736
Epoch: 7| Step: 7
Training loss: 2.424017567574071
Validation loss: 1.979882792401351
Epoch: 7| Step: 8
Training loss: 2.1189693821220272
Validation loss: 1.9802614521128756
Epoch: 7| Step: 9
Training loss: 2.440660335270327
Validation loss: 1.9933945866367861
Epoch: 7| Step: 10
Training loss: 2.0296723327774813
Validation loss: 1.9768890913208574
Epoch: 7| Step: 11
Training loss: 2.9158074521201423
Validation loss: 1.9961934223827331
Epoch: 7| Step: 12
Training loss: 2.084091112286779
Validation loss: 1.9951373028799912
Epoch: 7| Step: 13
Training loss: 2.0172403649244113
Validation loss: 1.9892022107241027
Epoch: 7| Step: 14
Training loss: 2.1828179525254017
Validation loss: 1.987051760236176
Epoch: 7| Step: 15
Training loss: 2.4468633346961615
Validation loss: 1.9746042587184458
Epoch: 88| Step: 0
Training loss: 2.264491567240971
Validation loss: 1.9749375814066148
Epoch: 7| Step: 1
Training loss: 2.3324123563174552
Validation loss: 2.004612356232896
Epoch: 7| Step: 2
Training loss: 2.9682946106835466
Validation loss: 1.9791902316087229
Epoch: 7| Step: 3
Training loss: 2.842619786619684
Validation loss: 1.9727200281689463
Epoch: 7| Step: 4
Training loss: 1.7892974299473416
Validation loss: 1.9757124172957126
Epoch: 7| Step: 5
Training loss: 1.9946832320287036
Validation loss: 1.975131965246193
Epoch: 7| Step: 6
Training loss: 3.0260969584803497
Validation loss: 1.9818571131416152
Epoch: 7| Step: 7
Training loss: 2.6428949655308145
Validation loss: 1.9593250668650875
Epoch: 7| Step: 8
Training loss: 2.0838406771568305
Validation loss: 1.9632422388745583
Epoch: 7| Step: 9
Training loss: 2.566928943840922
Validation loss: 1.9714835590509003
Epoch: 7| Step: 10
Training loss: 2.340101632250504
Validation loss: 1.9667774403161677
Epoch: 7| Step: 11
Training loss: 2.144749364548445
Validation loss: 1.9566420785253296
Epoch: 7| Step: 12
Training loss: 1.7768918311750592
Validation loss: 1.969805961612251
Epoch: 7| Step: 13
Training loss: 1.6548845672688162
Validation loss: 1.942145042948639
Epoch: 7| Step: 14
Training loss: 2.4144374716682866
Validation loss: 1.9786500671769514
Epoch: 7| Step: 15
Training loss: 2.6900592417380067
Validation loss: 1.9564531478552252
Epoch: 89| Step: 0
Training loss: 2.3433679905151363
Validation loss: 1.9485594250447837
Epoch: 7| Step: 1
Training loss: 2.5440364067183663
Validation loss: 1.9609412018597254
Epoch: 7| Step: 2
Training loss: 2.068975974473067
Validation loss: 1.984527419151008
Epoch: 7| Step: 3
Training loss: 2.3373837283994727
Validation loss: 1.9780893116285623
Epoch: 7| Step: 4
Training loss: 1.69032404507238
Validation loss: 1.9812676991284914
Epoch: 7| Step: 5
Training loss: 2.3030311969096746
Validation loss: 1.9885991230358142
Epoch: 7| Step: 6
Training loss: 2.633585830445718
Validation loss: 1.989378821454406
Epoch: 7| Step: 7
Training loss: 2.2507986134922278
Validation loss: 1.9882261318925676
Epoch: 7| Step: 8
Training loss: 2.3921173025604294
Validation loss: 1.9717208152148131
Epoch: 7| Step: 9
Training loss: 2.3279248862061404
Validation loss: 1.986613493725828
Epoch: 7| Step: 10
Training loss: 2.474534320370532
Validation loss: 1.9847715760218383
Epoch: 7| Step: 11
Training loss: 2.775745473857145
Validation loss: 1.9789964580740667
Epoch: 7| Step: 12
Training loss: 2.319515618040013
Validation loss: 1.97395283463257
Epoch: 7| Step: 13
Training loss: 2.6333272640142233
Validation loss: 1.9855205842818102
Epoch: 7| Step: 14
Training loss: 2.499375169872785
Validation loss: 1.9908368072264138
Epoch: 7| Step: 15
Training loss: 2.1703198031144
Validation loss: 1.9775534004559185
Epoch: 90| Step: 0
Training loss: 2.1513979957649956
Validation loss: 1.9718334395340924
Epoch: 7| Step: 1
Training loss: 2.49170864371809
Validation loss: 1.991145057815957
Epoch: 7| Step: 2
Training loss: 2.1324253499425
Validation loss: 1.9657047234366265
Epoch: 7| Step: 3
Training loss: 2.3548134671989445
Validation loss: 1.9634699564855302
Epoch: 7| Step: 4
Training loss: 1.8728715896132389
Validation loss: 1.9829400481992003
Epoch: 7| Step: 5
Training loss: 1.8532134474027868
Validation loss: 1.9740743521702988
Epoch: 7| Step: 6
Training loss: 2.534493522835946
Validation loss: 1.9677667930294849
Epoch: 7| Step: 7
Training loss: 2.5615046359036437
Validation loss: 1.962315050569664
Epoch: 7| Step: 8
Training loss: 2.612875685989165
Validation loss: 1.9817221167328587
Epoch: 7| Step: 9
Training loss: 2.0843522695420087
Validation loss: 1.9707686651177343
Epoch: 7| Step: 10
Training loss: 2.7582364283324368
Validation loss: 1.9746954863002917
Epoch: 7| Step: 11
Training loss: 2.1157156131784745
Validation loss: 1.971418574594071
Epoch: 7| Step: 12
Training loss: 3.007865608043725
Validation loss: 1.9698652530772414
Epoch: 7| Step: 13
Training loss: 2.673824290794594
Validation loss: 1.9555273820303707
Epoch: 7| Step: 14
Training loss: 2.1844946788915998
Validation loss: 1.9755134458274846
Epoch: 7| Step: 15
Training loss: 2.220149928348467
Validation loss: 1.9698102041327863
Epoch: 91| Step: 0
Training loss: 2.8413582269922744
Validation loss: 1.979138201195371
Epoch: 7| Step: 1
Training loss: 2.5322542435456747
Validation loss: 1.986389968987055
Epoch: 7| Step: 2
Training loss: 2.743687233174344
Validation loss: 1.9484642151406668
Epoch: 7| Step: 3
Training loss: 2.591760262846624
Validation loss: 1.9814436172804295
Epoch: 7| Step: 4
Training loss: 2.1559220216623722
Validation loss: 1.9776399586112026
Epoch: 7| Step: 5
Training loss: 2.112687286562018
Validation loss: 1.9724910975090444
Epoch: 7| Step: 6
Training loss: 2.04085838770827
Validation loss: 1.9659909422581932
Epoch: 7| Step: 7
Training loss: 2.564498215313084
Validation loss: 1.9897160244303926
Epoch: 7| Step: 8
Training loss: 1.9653465279938946
Validation loss: 1.9779539597516325
Epoch: 7| Step: 9
Training loss: 1.8376261635370492
Validation loss: 1.9809457642249826
Epoch: 7| Step: 10
Training loss: 2.7099172997612695
Validation loss: 1.9730135173802432
Epoch: 7| Step: 11
Training loss: 2.375273839322022
Validation loss: 1.9610326011038222
Epoch: 7| Step: 12
Training loss: 2.3188914047680056
Validation loss: 1.9600226987744873
Epoch: 7| Step: 13
Training loss: 2.1693050630638657
Validation loss: 1.9810204087531544
Epoch: 7| Step: 14
Training loss: 2.3896183063461023
Validation loss: 1.953555957440315
Epoch: 7| Step: 15
Training loss: 2.236570333499363
Validation loss: 1.9911335137530983
Epoch: 92| Step: 0
Training loss: 2.7656769828436936
Validation loss: 1.9767379821136701
Epoch: 7| Step: 1
Training loss: 2.0757014548197956
Validation loss: 1.9708727070536687
Epoch: 7| Step: 2
Training loss: 2.2045154918075274
Validation loss: 1.973761218180681
Epoch: 7| Step: 3
Training loss: 2.3257328519183864
Validation loss: 1.9762428989194003
Epoch: 7| Step: 4
Training loss: 2.6189984333489544
Validation loss: 1.9712431236871588
Epoch: 7| Step: 5
Training loss: 2.1083622514553366
Validation loss: 1.9650323838943866
Epoch: 7| Step: 6
Training loss: 2.232675506254603
Validation loss: 1.9770290828189188
Epoch: 7| Step: 7
Training loss: 2.8457927702828334
Validation loss: 1.9829543397984166
Epoch: 7| Step: 8
Training loss: 2.188415335837534
Validation loss: 1.9780661713325352
Epoch: 7| Step: 9
Training loss: 2.1323979572241276
Validation loss: 1.9618920399780289
Epoch: 7| Step: 10
Training loss: 2.2319302288690177
Validation loss: 1.981770782925104
Epoch: 7| Step: 11
Training loss: 2.286858965996567
Validation loss: 1.9752350472135674
Epoch: 7| Step: 12
Training loss: 2.2296929020538867
Validation loss: 1.9490831601487162
Epoch: 7| Step: 13
Training loss: 1.7292342421721059
Validation loss: 1.9840532039773355
Epoch: 7| Step: 14
Training loss: 2.662153617284142
Validation loss: 1.965615303063276
Epoch: 7| Step: 15
Training loss: 2.956181634672967
Validation loss: 1.9779326843275362
Epoch: 93| Step: 0
Training loss: 2.0634843038114963
Validation loss: 1.9910167215713412
Epoch: 7| Step: 1
Training loss: 2.7573859125297777
Validation loss: 1.9810172684584857
Epoch: 7| Step: 2
Training loss: 2.7457639840784216
Validation loss: 1.9873306051899002
Epoch: 7| Step: 3
Training loss: 2.438224000267854
Validation loss: 1.9914043269571389
Epoch: 7| Step: 4
Training loss: 2.049526797318353
Validation loss: 1.9787415998372626
Epoch: 7| Step: 5
Training loss: 2.2020283668416365
Validation loss: 1.9777342023656301
Epoch: 7| Step: 6
Training loss: 2.755673711133792
Validation loss: 1.9787054746637294
Epoch: 7| Step: 7
Training loss: 2.4699094922553058
Validation loss: 1.9783118083291569
Epoch: 7| Step: 8
Training loss: 2.2685026638258354
Validation loss: 1.9734442213948866
Epoch: 7| Step: 9
Training loss: 1.9254758023881462
Validation loss: 1.9677993553097741
Epoch: 7| Step: 10
Training loss: 2.6660983453570273
Validation loss: 1.9678902614679656
Epoch: 7| Step: 11
Training loss: 1.9602891070397528
Validation loss: 1.9715750317418308
Epoch: 7| Step: 12
Training loss: 2.717050569318527
Validation loss: 1.9724683806895642
Epoch: 7| Step: 13
Training loss: 2.08818909926626
Validation loss: 1.982315384469012
Epoch: 7| Step: 14
Training loss: 2.0172123535894473
Validation loss: 1.9820037074333223
Epoch: 7| Step: 15
Training loss: 2.4274183268611824
Validation loss: 1.9797689498853184
Epoch: 94| Step: 0
Training loss: 2.772459905556342
Validation loss: 1.9971604073353662
Epoch: 7| Step: 1
Training loss: 2.0500135746948374
Validation loss: 1.986618317457153
Epoch: 7| Step: 2
Training loss: 2.2724889500247563
Validation loss: 1.9879688802004043
Epoch: 7| Step: 3
Training loss: 2.4853529055128982
Validation loss: 1.9857827071709349
Epoch: 7| Step: 4
Training loss: 2.652902715602464
Validation loss: 2.0078329036776994
Epoch: 7| Step: 5
Training loss: 2.4223881331716255
Validation loss: 1.9833216967384812
Epoch: 7| Step: 6
Training loss: 2.1933632882033214
Validation loss: 1.965402539842905
Epoch: 7| Step: 7
Training loss: 2.301723216156527
Validation loss: 1.9834205673911078
Epoch: 7| Step: 8
Training loss: 2.247967119566987
Validation loss: 1.96342284021061
Epoch: 7| Step: 9
Training loss: 2.841543326586395
Validation loss: 1.9940375480577948
Epoch: 7| Step: 10
Training loss: 2.1146175087357886
Validation loss: 1.983843685636035
Epoch: 7| Step: 11
Training loss: 1.9448217056262007
Validation loss: 1.996829093495906
Epoch: 7| Step: 12
Training loss: 3.064565934875877
Validation loss: 2.0039705370310554
Epoch: 7| Step: 13
Training loss: 2.295675262806559
Validation loss: 1.9847133897363078
Epoch: 7| Step: 14
Training loss: 1.7515097645044457
Validation loss: 1.9890562849552897
Epoch: 7| Step: 15
Training loss: 1.969315220667959
Validation loss: 1.9925469849901147
Epoch: 95| Step: 0
Training loss: 2.5469189037447184
Validation loss: 1.9989876540828522
Epoch: 7| Step: 1
Training loss: 2.689939057464599
Validation loss: 1.98803161382874
Epoch: 7| Step: 2
Training loss: 1.7075566022436044
Validation loss: 1.994740298037284
Epoch: 7| Step: 3
Training loss: 2.249745990402425
Validation loss: 1.9838675279339075
Epoch: 7| Step: 4
Training loss: 2.3447092763445476
Validation loss: 1.9803352246531434
Epoch: 7| Step: 5
Training loss: 2.673533677690376
Validation loss: 1.9810700770073297
Epoch: 7| Step: 6
Training loss: 2.3128092790964434
Validation loss: 1.985030044456328
Epoch: 7| Step: 7
Training loss: 2.3795248395565554
Validation loss: 1.9834625324054338
Epoch: 7| Step: 8
Training loss: 2.5406791352795466
Validation loss: 1.9787361496244817
Epoch: 7| Step: 9
Training loss: 2.605685429520837
Validation loss: 1.9707909883552095
Epoch: 7| Step: 10
Training loss: 2.3923554982521074
Validation loss: 1.9655219157412553
Epoch: 7| Step: 11
Training loss: 1.8852606088815065
Validation loss: 1.9618700495071422
Epoch: 7| Step: 12
Training loss: 2.42082043730233
Validation loss: 1.9745165949049401
Epoch: 7| Step: 13
Training loss: 2.133803811447883
Validation loss: 1.9676765735456718
Epoch: 7| Step: 14
Training loss: 2.6020208648032748
Validation loss: 1.9724586721754087
Epoch: 7| Step: 15
Training loss: 2.165983703763318
Validation loss: 1.943780188468191
Epoch: 96| Step: 0
Training loss: 2.3139044131332813
Validation loss: 1.9757732760342654
Epoch: 7| Step: 1
Training loss: 2.847849479576685
Validation loss: 1.9654842813370037
Epoch: 7| Step: 2
Training loss: 2.006163636247151
Validation loss: 1.9780529198796692
Epoch: 7| Step: 3
Training loss: 2.6640183789131893
Validation loss: 1.958608375055182
Epoch: 7| Step: 4
Training loss: 2.2738706824942327
Validation loss: 1.975770529070317
Epoch: 7| Step: 5
Training loss: 2.676439368627507
Validation loss: 1.9724995054837076
Epoch: 7| Step: 6
Training loss: 2.1373660486199966
Validation loss: 1.9689335026265242
Epoch: 7| Step: 7
Training loss: 2.37127654676604
Validation loss: 1.9747961277902326
Epoch: 7| Step: 8
Training loss: 2.456715088897192
Validation loss: 1.9623076078949062
Epoch: 7| Step: 9
Training loss: 2.0902702680631
Validation loss: 1.9784550185904926
Epoch: 7| Step: 10
Training loss: 2.1387736535784834
Validation loss: 1.9766624639626076
Epoch: 7| Step: 11
Training loss: 2.070877746576526
Validation loss: 1.9993131864439915
Epoch: 7| Step: 12
Training loss: 2.4029538256097838
Validation loss: 1.9778201892777225
Epoch: 7| Step: 13
Training loss: 1.8747578782474235
Validation loss: 1.984196085483396
Epoch: 7| Step: 14
Training loss: 2.740744708414423
Validation loss: 1.9986937375498002
Epoch: 7| Step: 15
Training loss: 2.475579003318691
Validation loss: 2.004656048816858
Epoch: 97| Step: 0
Training loss: 2.6087275632689457
Validation loss: 1.9989249251887866
Epoch: 7| Step: 1
Training loss: 2.44726903478289
Validation loss: 2.0039622301756483
Epoch: 7| Step: 2
Training loss: 2.1078086406200187
Validation loss: 1.9990333731288188
Epoch: 7| Step: 3
Training loss: 2.1907071173019927
Validation loss: 1.9911200472282349
Epoch: 7| Step: 4
Training loss: 2.3571622463766486
Validation loss: 1.9891614907770319
Epoch: 7| Step: 5
Training loss: 2.117490739678285
Validation loss: 1.997388532616739
Epoch: 7| Step: 6
Training loss: 1.954562947233285
Validation loss: 2.0082567217287632
Epoch: 7| Step: 7
Training loss: 2.0758201035555657
Validation loss: 2.0085504134391523
Epoch: 7| Step: 8
Training loss: 2.5743189605518464
Validation loss: 2.002962779217883
Epoch: 7| Step: 9
Training loss: 2.46462484557489
Validation loss: 2.0027467736481475
Epoch: 7| Step: 10
Training loss: 2.2432095527603333
Validation loss: 1.9938709340719316
Epoch: 7| Step: 11
Training loss: 2.7322758055466663
Validation loss: 1.9924426667088755
Epoch: 7| Step: 12
Training loss: 2.584824060174716
Validation loss: 2.004238084016405
Epoch: 7| Step: 13
Training loss: 2.3222797929156753
Validation loss: 1.9855115432600408
Epoch: 7| Step: 14
Training loss: 2.0684226569418165
Validation loss: 1.9964086394699685
Epoch: 7| Step: 15
Training loss: 2.7330397479240784
Validation loss: 1.9871375539649396
Epoch: 98| Step: 0
Training loss: 2.735891913225384
Validation loss: 1.9934737910862095
Epoch: 7| Step: 1
Training loss: 2.443039492762203
Validation loss: 1.9690759303535974
Epoch: 7| Step: 2
Training loss: 2.107708081599245
Validation loss: 1.9937152590677216
Epoch: 7| Step: 3
Training loss: 2.729130887872036
Validation loss: 1.962705008191981
Epoch: 7| Step: 4
Training loss: 1.8634503365816133
Validation loss: 1.9789655974261104
Epoch: 7| Step: 5
Training loss: 2.4889761105743884
Validation loss: 1.9904164253521512
Epoch: 7| Step: 6
Training loss: 2.2937009509920396
Validation loss: 1.9727402610033495
Epoch: 7| Step: 7
Training loss: 1.8958428001866108
Validation loss: 1.969651050036514
Epoch: 7| Step: 8
Training loss: 2.676529160273558
Validation loss: 1.9797152929431296
Epoch: 7| Step: 9
Training loss: 2.3811735926907622
Validation loss: 1.961048926375225
Epoch: 7| Step: 10
Training loss: 2.850323133387104
Validation loss: 1.9685429806686092
Epoch: 7| Step: 11
Training loss: 2.4377689702236056
Validation loss: 1.9726953375886445
Epoch: 7| Step: 12
Training loss: 2.4330418237931926
Validation loss: 1.9626361994854724
Epoch: 7| Step: 13
Training loss: 1.92483565384464
Validation loss: 1.9709422708486632
Epoch: 7| Step: 14
Training loss: 1.9084947845371731
Validation loss: 1.964555361311815
Epoch: 7| Step: 15
Training loss: 2.2592439436726357
Validation loss: 1.952931782961441
Epoch: 99| Step: 0
Training loss: 2.682364414055719
Validation loss: 1.956028960088364
Epoch: 7| Step: 1
Training loss: 2.621301315889511
Validation loss: 1.9694138272636497
Epoch: 7| Step: 2
Training loss: 2.155298437708992
Validation loss: 1.967728830033444
Epoch: 7| Step: 3
Training loss: 2.3929756924151455
Validation loss: 1.9590931179812103
Epoch: 7| Step: 4
Training loss: 2.4052613444301154
Validation loss: 1.9713085856456272
Epoch: 7| Step: 5
Training loss: 2.0088004564881046
Validation loss: 1.9603829810132485
Epoch: 7| Step: 6
Training loss: 2.874903635814976
Validation loss: 1.9697923598114857
Epoch: 7| Step: 7
Training loss: 2.0114536147718303
Validation loss: 1.9580578639109
Epoch: 7| Step: 8
Training loss: 2.366670457630972
Validation loss: 1.965897843230756
Epoch: 7| Step: 9
Training loss: 1.8414543860920747
Validation loss: 1.9799333577006635
Epoch: 7| Step: 10
Training loss: 1.9009579226368647
Validation loss: 1.9671062354915712
Epoch: 7| Step: 11
Training loss: 2.154373236761431
Validation loss: 1.9773832455889184
Epoch: 7| Step: 12
Training loss: 1.9393858806711801
Validation loss: 1.9773354568260464
Epoch: 7| Step: 13
Training loss: 3.173614776483075
Validation loss: 1.977259451804989
Epoch: 7| Step: 14
Training loss: 2.27078627324702
Validation loss: 1.9902425924851863
Epoch: 7| Step: 15
Training loss: 2.451109525943834
Validation loss: 1.9813018068717674
Epoch: 100| Step: 0
Training loss: 2.4598382341494722
Validation loss: 1.9874018085038236
Epoch: 7| Step: 1
Training loss: 1.7487410376471122
Validation loss: 1.9828576997703242
Epoch: 7| Step: 2
Training loss: 2.348156461568388
Validation loss: 1.9835851190537073
Epoch: 7| Step: 3
Training loss: 2.505472678171617
Validation loss: 1.9741569206450897
Epoch: 7| Step: 4
Training loss: 2.5911587559874576
Validation loss: 1.9669586661853968
Epoch: 7| Step: 5
Training loss: 1.8349234519812365
Validation loss: 1.987806027621583
Epoch: 7| Step: 6
Training loss: 2.8446484498372766
Validation loss: 1.966679423994527
Epoch: 7| Step: 7
Training loss: 2.2958653105662523
Validation loss: 1.968499412763972
Epoch: 7| Step: 8
Training loss: 2.313299917076827
Validation loss: 1.9604762702065608
Epoch: 7| Step: 9
Training loss: 2.0844968471343126
Validation loss: 1.9644986124181625
Epoch: 7| Step: 10
Training loss: 2.262601742643408
Validation loss: 1.9576369214027147
Epoch: 7| Step: 11
Training loss: 2.88976048094077
Validation loss: 1.9451119144331386
Epoch: 7| Step: 12
Training loss: 2.6732582839299495
Validation loss: 1.9606831004641614
Epoch: 7| Step: 13
Training loss: 1.7513616577755418
Validation loss: 1.957051132985564
Epoch: 7| Step: 14
Training loss: 2.1573126565479113
Validation loss: 1.9645641014183093
Epoch: 7| Step: 15
Training loss: 2.492508344416296
Validation loss: 1.9457796052914413
