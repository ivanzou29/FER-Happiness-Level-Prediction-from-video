Epoch: 1| Step: 0
Training loss: 5.571280479431152
Validation loss: 4.064825812975566

Epoch: 6| Step: 1
Training loss: 4.923775672912598
Validation loss: 4.032137592633565

Epoch: 6| Step: 2
Training loss: 4.263528347015381
Validation loss: 3.997499148050944

Epoch: 6| Step: 3
Training loss: 3.8326754570007324
Validation loss: 3.9654224713643393

Epoch: 6| Step: 4
Training loss: 4.000791549682617
Validation loss: 3.935964504877726

Epoch: 6| Step: 5
Training loss: 5.319728374481201
Validation loss: 3.9005261262257895

Epoch: 6| Step: 6
Training loss: 4.383501052856445
Validation loss: 3.8750876585642495

Epoch: 6| Step: 7
Training loss: 4.288520812988281
Validation loss: 3.8409597476323447

Epoch: 6| Step: 8
Training loss: 3.6730599403381348
Validation loss: 3.8159534533818564

Epoch: 6| Step: 9
Training loss: 3.213567018508911
Validation loss: 3.7831310828526816

Epoch: 6| Step: 10
Training loss: 2.974698066711426
Validation loss: 3.7578513622283936

Epoch: 6| Step: 11
Training loss: 3.2431647777557373
Validation loss: 3.729520638783773

Epoch: 6| Step: 12
Training loss: 3.3488073348999023
Validation loss: 3.697023391723633

Epoch: 6| Step: 13
Training loss: 3.258232831954956
Validation loss: 3.6689050594965615

Epoch: 2| Step: 0
Training loss: 2.807555675506592
Validation loss: 3.642385482788086

Epoch: 6| Step: 1
Training loss: 4.097554683685303
Validation loss: 3.6098706324895224

Epoch: 6| Step: 2
Training loss: 3.4880921840667725
Validation loss: 3.581192215283712

Epoch: 6| Step: 3
Training loss: 4.192912578582764
Validation loss: 3.5455194314320884

Epoch: 6| Step: 4
Training loss: 3.508733034133911
Validation loss: 3.515664299329122

Epoch: 6| Step: 5
Training loss: 3.4249587059020996
Validation loss: 3.479765216509501

Epoch: 6| Step: 6
Training loss: 2.9113683700561523
Validation loss: 3.448620915412903

Epoch: 6| Step: 7
Training loss: 3.821812152862549
Validation loss: 3.407408038775126

Epoch: 6| Step: 8
Training loss: 3.5794341564178467
Validation loss: 3.3736477295557656

Epoch: 6| Step: 9
Training loss: 3.00070858001709
Validation loss: 3.3357876936594644

Epoch: 6| Step: 10
Training loss: 3.248262405395508
Validation loss: 3.296585520108541

Epoch: 6| Step: 11
Training loss: 3.2518715858459473
Validation loss: 3.251129627227783

Epoch: 6| Step: 12
Training loss: 4.239193916320801
Validation loss: 3.217220346132914

Epoch: 6| Step: 13
Training loss: 4.224810600280762
Validation loss: 3.1759302616119385

Epoch: 3| Step: 0
Training loss: 2.856631278991699
Validation loss: 3.1302818854649863

Epoch: 6| Step: 1
Training loss: 3.6231837272644043
Validation loss: 3.0858307679494223

Epoch: 6| Step: 2
Training loss: 4.019836902618408
Validation loss: 3.0457733869552612

Epoch: 6| Step: 3
Training loss: 3.276542901992798
Validation loss: 2.9938184022903442

Epoch: 6| Step: 4
Training loss: 3.300210475921631
Validation loss: 2.9522247314453125

Epoch: 6| Step: 5
Training loss: 3.5191781520843506
Validation loss: 2.9080357551574707

Epoch: 6| Step: 6
Training loss: 2.8662540912628174
Validation loss: 2.856210192044576

Epoch: 6| Step: 7
Training loss: 2.1350157260894775
Validation loss: 2.8126585880915322

Epoch: 6| Step: 8
Training loss: 2.715620517730713
Validation loss: 2.759574214617411

Epoch: 6| Step: 9
Training loss: 2.3688836097717285
Validation loss: 2.7032678524653115

Epoch: 6| Step: 10
Training loss: 3.0240299701690674
Validation loss: 2.6551231940587363

Epoch: 6| Step: 11
Training loss: 2.5616233348846436
Validation loss: 2.5981425841649375

Epoch: 6| Step: 12
Training loss: 1.9174304008483887
Validation loss: 2.5396310885747275

Epoch: 6| Step: 13
Training loss: 2.8631083965301514
Validation loss: 2.489091714223226

Epoch: 4| Step: 0
Training loss: 2.787754535675049
Validation loss: 2.42742121219635

Epoch: 6| Step: 1
Training loss: 2.5891261100769043
Validation loss: 2.362661520640055

Epoch: 6| Step: 2
Training loss: 1.9632933139801025
Validation loss: 2.3144336938858032

Epoch: 6| Step: 3
Training loss: 2.3251709938049316
Validation loss: 2.262592593828837

Epoch: 6| Step: 4
Training loss: 2.884305953979492
Validation loss: 2.213731606801351

Epoch: 6| Step: 5
Training loss: 2.141312599182129
Validation loss: 2.188913583755493

Epoch: 6| Step: 6
Training loss: 1.436244010925293
Validation loss: 2.148659348487854

Epoch: 6| Step: 7
Training loss: 1.9498703479766846
Validation loss: 2.1185750563939414

Epoch: 6| Step: 8
Training loss: 2.3145623207092285
Validation loss: 2.07994282245636

Epoch: 6| Step: 9
Training loss: 2.080167293548584
Validation loss: 2.0503591895103455

Epoch: 6| Step: 10
Training loss: 2.558563470840454
Validation loss: 2.0225412249565125

Epoch: 6| Step: 11
Training loss: 2.175703525543213
Validation loss: 2.0247801144917807

Epoch: 6| Step: 12
Training loss: 1.5629358291625977
Validation loss: 2.028640846411387

Epoch: 6| Step: 13
Training loss: 1.7872681617736816
Validation loss: 2.034529189268748

Epoch: 5| Step: 0
Training loss: 2.7189629077911377
Validation loss: 2.0493476589520774

Epoch: 6| Step: 1
Training loss: 2.7762293815612793
Validation loss: 2.0644810795783997

Epoch: 6| Step: 2
Training loss: 2.5308055877685547
Validation loss: 2.0737820068995156

Epoch: 6| Step: 3
Training loss: 1.9253814220428467
Validation loss: 2.0681320627530417

Epoch: 6| Step: 4
Training loss: 1.6642919778823853
Validation loss: 2.0649861494700112

Epoch: 6| Step: 5
Training loss: 2.4259233474731445
Validation loss: 2.0858850479125977

Epoch: 6| Step: 6
Training loss: 1.9267548322677612
Validation loss: 2.08532706896464

Epoch: 6| Step: 7
Training loss: 1.1983325481414795
Validation loss: 2.0898006161053977

Epoch: 6| Step: 8
Training loss: 2.126544237136841
Validation loss: 2.06216553846995

Epoch: 6| Step: 9
Training loss: 1.8964800834655762
Validation loss: 2.048934976259867

Epoch: 6| Step: 10
Training loss: 2.2569735050201416
Validation loss: 2.0400406320889792

Epoch: 6| Step: 11
Training loss: 1.7625315189361572
Validation loss: 2.0175239642461142

Epoch: 6| Step: 12
Training loss: 2.0178894996643066
Validation loss: 1.9986072182655334

Epoch: 6| Step: 13
Training loss: 2.33854603767395
Validation loss: 2.009983797868093

Epoch: 6| Step: 0
Training loss: 1.6007449626922607
Validation loss: 2.0102834502855935

Epoch: 6| Step: 1
Training loss: 1.7660406827926636
Validation loss: 2.0080187916755676

Epoch: 6| Step: 2
Training loss: 2.2506771087646484
Validation loss: 2.0203309456507363

Epoch: 6| Step: 3
Training loss: 3.0176334381103516
Validation loss: 2.013503909111023

Epoch: 6| Step: 4
Training loss: 2.4313488006591797
Validation loss: 2.022588590780894

Epoch: 6| Step: 5
Training loss: 2.0314064025878906
Validation loss: 2.0444144010543823

Epoch: 6| Step: 6
Training loss: 2.0004355907440186
Validation loss: 2.0595409870147705

Epoch: 6| Step: 7
Training loss: 2.1260221004486084
Validation loss: 2.048121531804403

Epoch: 6| Step: 8
Training loss: 2.1162798404693604
Validation loss: 2.036302864551544

Epoch: 6| Step: 9
Training loss: 2.037938117980957
Validation loss: 2.050467391808828

Epoch: 6| Step: 10
Training loss: 1.731693983078003
Validation loss: 2.0449838836987815

Epoch: 6| Step: 11
Training loss: 2.1050753593444824
Validation loss: 2.0402565598487854

Epoch: 6| Step: 12
Training loss: 2.1200108528137207
Validation loss: 2.023978034655253

Epoch: 6| Step: 13
Training loss: 1.9045984745025635
Validation loss: 2.019004503885905

Epoch: 7| Step: 0
Training loss: 1.7972030639648438
Validation loss: 2.001073201497396

Epoch: 6| Step: 1
Training loss: 2.3700366020202637
Validation loss: 2.0039419333140054

Epoch: 6| Step: 2
Training loss: 1.5270812511444092
Validation loss: 2.011570314566294

Epoch: 6| Step: 3
Training loss: 1.9366209506988525
Validation loss: 2.010621269543966

Epoch: 6| Step: 4
Training loss: 1.6223657131195068
Validation loss: 2.0133256713549295

Epoch: 6| Step: 5
Training loss: 2.5727336406707764
Validation loss: 2.001385668913523

Epoch: 6| Step: 6
Training loss: 2.3235955238342285
Validation loss: 1.9981025854746501

Epoch: 6| Step: 7
Training loss: 2.8888773918151855
Validation loss: 1.9954543312390645

Epoch: 6| Step: 8
Training loss: 1.9937143325805664
Validation loss: 2.000889221827189

Epoch: 6| Step: 9
Training loss: 1.3952128887176514
Validation loss: 2.0069092313448587

Epoch: 6| Step: 10
Training loss: 2.7843003273010254
Validation loss: 2.00262322028478

Epoch: 6| Step: 11
Training loss: 1.836058497428894
Validation loss: 2.016446590423584

Epoch: 6| Step: 12
Training loss: 1.3548078536987305
Validation loss: 2.00803812344869

Epoch: 6| Step: 13
Training loss: 1.9272336959838867
Validation loss: 2.006375312805176

Epoch: 8| Step: 0
Training loss: 2.0107390880584717
Validation loss: 2.01593546072642

Epoch: 6| Step: 1
Training loss: 2.887533187866211
Validation loss: 2.021981954574585

Epoch: 6| Step: 2
Training loss: 1.5718963146209717
Validation loss: 2.036603093147278

Epoch: 6| Step: 3
Training loss: 1.607457160949707
Validation loss: 2.030075947443644

Epoch: 6| Step: 4
Training loss: 1.8744378089904785
Validation loss: 2.0347991983095803

Epoch: 6| Step: 5
Training loss: 2.3325939178466797
Validation loss: 2.022344787915548

Epoch: 6| Step: 6
Training loss: 2.8526930809020996
Validation loss: 2.021332561969757

Epoch: 6| Step: 7
Training loss: 2.0857601165771484
Validation loss: 2.0196875731150308

Epoch: 6| Step: 8
Training loss: 1.627206563949585
Validation loss: 1.9897441665331523

Epoch: 6| Step: 9
Training loss: 1.8823180198669434
Validation loss: 2.0027098854382834

Epoch: 6| Step: 10
Training loss: 2.2341458797454834
Validation loss: 2.0036058028539023

Epoch: 6| Step: 11
Training loss: 1.9964520931243896
Validation loss: 1.992904265721639

Epoch: 6| Step: 12
Training loss: 1.649194598197937
Validation loss: 1.9972699284553528

Epoch: 6| Step: 13
Training loss: 2.2089741230010986
Validation loss: 1.9839455286661785

Epoch: 9| Step: 0
Training loss: 2.342005968093872
Validation loss: 1.9834165573120117

Epoch: 6| Step: 1
Training loss: 1.6683599948883057
Validation loss: 1.9928630590438843

Epoch: 6| Step: 2
Training loss: 2.3871238231658936
Validation loss: 1.9899836579958599

Epoch: 6| Step: 3
Training loss: 1.9740641117095947
Validation loss: 1.9880252480506897

Epoch: 6| Step: 4
Training loss: 2.1923134326934814
Validation loss: 1.989071826140086

Epoch: 6| Step: 5
Training loss: 1.3492274284362793
Validation loss: 2.001043657461802

Epoch: 6| Step: 6
Training loss: 2.2614338397979736
Validation loss: 1.9889233112335205

Epoch: 6| Step: 7
Training loss: 2.2942256927490234
Validation loss: 1.999837855497996

Epoch: 6| Step: 8
Training loss: 1.5268474817276
Validation loss: 1.9996470014254253

Epoch: 6| Step: 9
Training loss: 1.9475995302200317
Validation loss: 1.986051857471466

Epoch: 6| Step: 10
Training loss: 2.5794973373413086
Validation loss: 1.988914688428243

Epoch: 6| Step: 11
Training loss: 2.1306710243225098
Validation loss: 1.980796794096629

Epoch: 6| Step: 12
Training loss: 2.234790086746216
Validation loss: 1.9860389431317647

Epoch: 6| Step: 13
Training loss: 1.5552688837051392
Validation loss: 1.9903908371925354

Epoch: 10| Step: 0
Training loss: 1.9525947570800781
Validation loss: 1.9871243834495544

Epoch: 6| Step: 1
Training loss: 2.2258312702178955
Validation loss: 1.9812256296475728

Epoch: 6| Step: 2
Training loss: 2.1672592163085938
Validation loss: 1.9819989999135335

Epoch: 6| Step: 3
Training loss: 1.909342646598816
Validation loss: 1.9823599259058635

Epoch: 6| Step: 4
Training loss: 1.137644648551941
Validation loss: 1.9850021600723267

Epoch: 6| Step: 5
Training loss: 1.9708188772201538
Validation loss: 1.9737739165623982

Epoch: 6| Step: 6
Training loss: 1.8775861263275146
Validation loss: 1.979746441046397

Epoch: 6| Step: 7
Training loss: 2.048816680908203
Validation loss: 1.9850886861483257

Epoch: 6| Step: 8
Training loss: 2.1037681102752686
Validation loss: 1.9909541805585225

Epoch: 6| Step: 9
Training loss: 2.450470447540283
Validation loss: 1.977165957291921

Epoch: 6| Step: 10
Training loss: 2.0310521125793457
Validation loss: 1.9722177982330322

Epoch: 6| Step: 11
Training loss: 1.702888011932373
Validation loss: 1.9877502123514812

Epoch: 6| Step: 12
Training loss: 2.117717981338501
Validation loss: 1.9839090903600056

Epoch: 6| Step: 13
Training loss: 2.612905979156494
Validation loss: 1.983374536037445

Epoch: 11| Step: 0
Training loss: 2.6846649646759033
Validation loss: 1.9768001039822896

Epoch: 6| Step: 1
Training loss: 1.5728521347045898
Validation loss: 1.9794302980105083

Epoch: 6| Step: 2
Training loss: 1.6346708536148071
Validation loss: 1.9953688184420268

Epoch: 6| Step: 3
Training loss: 2.4111251831054688
Validation loss: 1.9895992477734883

Epoch: 6| Step: 4
Training loss: 1.4458460807800293
Validation loss: 1.994374414285024

Epoch: 6| Step: 5
Training loss: 2.1558330059051514
Validation loss: 1.9985223809878032

Epoch: 6| Step: 6
Training loss: 1.636702537536621
Validation loss: 1.9912506341934204

Epoch: 6| Step: 7
Training loss: 1.974181890487671
Validation loss: 2.0102100173632302

Epoch: 6| Step: 8
Training loss: 2.0708670616149902
Validation loss: 1.999781886736552

Epoch: 6| Step: 9
Training loss: 2.614985704421997
Validation loss: 2.002285043398539

Epoch: 6| Step: 10
Training loss: 2.6337828636169434
Validation loss: 1.9857141574223836

Epoch: 6| Step: 11
Training loss: 2.074779510498047
Validation loss: 1.992231508096059

Epoch: 6| Step: 12
Training loss: 1.676353931427002
Validation loss: 1.9858918984731038

Epoch: 6| Step: 13
Training loss: 1.6139683723449707
Validation loss: 1.9884594281514485

Epoch: 12| Step: 0
Training loss: 2.6189486980438232
Validation loss: 1.9718438386917114

Epoch: 6| Step: 1
Training loss: 1.3171883821487427
Validation loss: 1.9664175311724346

Epoch: 6| Step: 2
Training loss: 1.673008680343628
Validation loss: 1.9790863196055095

Epoch: 6| Step: 3
Training loss: 1.636581301689148
Validation loss: 1.9774576822916667

Epoch: 6| Step: 4
Training loss: 1.7846790552139282
Validation loss: 1.9808311263720195

Epoch: 6| Step: 5
Training loss: 1.4414042234420776
Validation loss: 1.9744306405385335

Epoch: 6| Step: 6
Training loss: 2.196958541870117
Validation loss: 1.9720758199691772

Epoch: 6| Step: 7
Training loss: 2.0925378799438477
Validation loss: 1.9790396690368652

Epoch: 6| Step: 8
Training loss: 2.130985736846924
Validation loss: 1.9708799719810486

Epoch: 6| Step: 9
Training loss: 2.0123836994171143
Validation loss: 1.9684590697288513

Epoch: 6| Step: 10
Training loss: 2.6993565559387207
Validation loss: 1.9777214328447978

Epoch: 6| Step: 11
Training loss: 2.602860450744629
Validation loss: 1.9742335478464763

Epoch: 6| Step: 12
Training loss: 2.189926862716675
Validation loss: 1.9792049328486125

Epoch: 6| Step: 13
Training loss: 2.005774736404419
Validation loss: 1.974393407503764

Epoch: 13| Step: 0
Training loss: 1.9834063053131104
Validation loss: 1.9729351202646892

Epoch: 6| Step: 1
Training loss: 2.125303268432617
Validation loss: 1.9895664254824321

Epoch: 6| Step: 2
Training loss: 1.8350368738174438
Validation loss: 1.972329060236613

Epoch: 6| Step: 3
Training loss: 1.8964924812316895
Validation loss: 1.9718680779139202

Epoch: 6| Step: 4
Training loss: 1.587092399597168
Validation loss: 1.9936644236246746

Epoch: 6| Step: 5
Training loss: 2.1119894981384277
Validation loss: 1.9721230864524841

Epoch: 6| Step: 6
Training loss: 1.6887850761413574
Validation loss: 1.9845734238624573

Epoch: 6| Step: 7
Training loss: 1.24176824092865
Validation loss: 1.98368106285731

Epoch: 6| Step: 8
Training loss: 1.7356314659118652
Validation loss: 1.9834511677424114

Epoch: 6| Step: 9
Training loss: 2.8882896900177
Validation loss: 1.970763365427653

Epoch: 6| Step: 10
Training loss: 1.902280569076538
Validation loss: 1.9976613124211628

Epoch: 6| Step: 11
Training loss: 2.2811384201049805
Validation loss: 1.9996270934740703

Epoch: 6| Step: 12
Training loss: 2.7959980964660645
Validation loss: 1.9956554770469666

Epoch: 6| Step: 13
Training loss: 1.9885296821594238
Validation loss: 1.9901191393534343

Epoch: 14| Step: 0
Training loss: 1.46061110496521
Validation loss: 1.9904151558876038

Epoch: 6| Step: 1
Training loss: 1.9951989650726318
Validation loss: 1.9818706115086873

Epoch: 6| Step: 2
Training loss: 1.708453893661499
Validation loss: 1.9775010148684184

Epoch: 6| Step: 3
Training loss: 2.0155932903289795
Validation loss: 1.9753437240918477

Epoch: 6| Step: 4
Training loss: 1.9233577251434326
Validation loss: 1.9698209563891094

Epoch: 6| Step: 5
Training loss: 2.1757888793945312
Validation loss: 1.9718496004740398

Epoch: 6| Step: 6
Training loss: 1.9347505569458008
Validation loss: 1.9869053959846497

Epoch: 6| Step: 7
Training loss: 1.9295300245285034
Validation loss: 1.9877567489941914

Epoch: 6| Step: 8
Training loss: 2.452948570251465
Validation loss: 1.970525284608205

Epoch: 6| Step: 9
Training loss: 2.1277389526367188
Validation loss: 1.9591992497444153

Epoch: 6| Step: 10
Training loss: 1.9819815158843994
Validation loss: 1.9773951570192974

Epoch: 6| Step: 11
Training loss: 2.1552109718322754
Validation loss: 1.9812535246213276

Epoch: 6| Step: 12
Training loss: 1.4485644102096558
Validation loss: 1.9661094148953755

Epoch: 6| Step: 13
Training loss: 2.5799548625946045
Validation loss: 1.9597330292065938

Epoch: 15| Step: 0
Training loss: 1.6041991710662842
Validation loss: 1.9612087210019429

Epoch: 6| Step: 1
Training loss: 1.5700749158859253
Validation loss: 1.964674711227417

Epoch: 6| Step: 2
Training loss: 2.2596631050109863
Validation loss: 1.9749010801315308

Epoch: 6| Step: 3
Training loss: 1.6309127807617188
Validation loss: 1.9594584703445435

Epoch: 6| Step: 4
Training loss: 2.237370491027832
Validation loss: 1.9756860335667927

Epoch: 6| Step: 5
Training loss: 2.294339179992676
Validation loss: 1.9835075934727986

Epoch: 6| Step: 6
Training loss: 1.5970507860183716
Validation loss: 1.991226851940155

Epoch: 6| Step: 7
Training loss: 1.7812129259109497
Validation loss: 1.9851142764091492

Epoch: 6| Step: 8
Training loss: 2.421041488647461
Validation loss: 1.983475665251414

Epoch: 6| Step: 9
Training loss: 2.43693208694458
Validation loss: 1.9675106604894002

Epoch: 6| Step: 10
Training loss: 2.4826273918151855
Validation loss: 1.9686569571495056

Epoch: 6| Step: 11
Training loss: 1.599165678024292
Validation loss: 1.9753934741020203

Epoch: 6| Step: 12
Training loss: 2.2240047454833984
Validation loss: 1.96298752228419

Epoch: 6| Step: 13
Training loss: 1.8264334201812744
Validation loss: 1.9807568788528442

Epoch: 16| Step: 0
Training loss: 1.681810975074768
Validation loss: 1.9720808068911235

Epoch: 6| Step: 1
Training loss: 1.5101252794265747
Validation loss: 1.9721479018529255

Epoch: 6| Step: 2
Training loss: 2.5680294036865234
Validation loss: 1.9684592088063557

Epoch: 6| Step: 3
Training loss: 2.440641164779663
Validation loss: 1.9730224609375

Epoch: 6| Step: 4
Training loss: 2.118647813796997
Validation loss: 1.9764812588691711

Epoch: 6| Step: 5
Training loss: 1.9558074474334717
Validation loss: 1.9602167805035908

Epoch: 6| Step: 6
Training loss: 1.870957851409912
Validation loss: 1.9636285305023193

Epoch: 6| Step: 7
Training loss: 2.3351478576660156
Validation loss: 1.9707599679629009

Epoch: 6| Step: 8
Training loss: 1.2491991519927979
Validation loss: 1.9776557485262554

Epoch: 6| Step: 9
Training loss: 1.9172430038452148
Validation loss: 1.9702273607254028

Epoch: 6| Step: 10
Training loss: 1.8407063484191895
Validation loss: 1.967459003130595

Epoch: 6| Step: 11
Training loss: 2.0597548484802246
Validation loss: 1.971402684847514

Epoch: 6| Step: 12
Training loss: 2.8542327880859375
Validation loss: 1.9622058073679607

Epoch: 6| Step: 13
Training loss: 1.4123730659484863
Validation loss: 1.9594032367070515

Epoch: 17| Step: 0
Training loss: 2.3757388591766357
Validation loss: 1.9627997875213623

Epoch: 6| Step: 1
Training loss: 2.3561763763427734
Validation loss: 1.9591510494550068

Epoch: 6| Step: 2
Training loss: 1.7439002990722656
Validation loss: 1.9845245281855266

Epoch: 6| Step: 3
Training loss: 1.5445525646209717
Validation loss: 1.9819331566492717

Epoch: 6| Step: 4
Training loss: 2.4218530654907227
Validation loss: 1.9668861627578735

Epoch: 6| Step: 5
Training loss: 1.9392707347869873
Validation loss: 1.9753108421961467

Epoch: 6| Step: 6
Training loss: 1.479626178741455
Validation loss: 1.9841610193252563

Epoch: 6| Step: 7
Training loss: 1.9631855487823486
Validation loss: 1.9720195929209392

Epoch: 6| Step: 8
Training loss: 2.627436637878418
Validation loss: 1.977424641450246

Epoch: 6| Step: 9
Training loss: 1.3897299766540527
Validation loss: 1.980541745821635

Epoch: 6| Step: 10
Training loss: 2.095057487487793
Validation loss: 1.9728294610977173

Epoch: 6| Step: 11
Training loss: 2.0078296661376953
Validation loss: 1.975447158018748

Epoch: 6| Step: 12
Training loss: 2.1012589931488037
Validation loss: 1.97097380956014

Epoch: 6| Step: 13
Training loss: 1.7628655433654785
Validation loss: 1.9712007443110149

Epoch: 18| Step: 0
Training loss: 2.437100410461426
Validation loss: 1.9696678519248962

Epoch: 6| Step: 1
Training loss: 1.5806288719177246
Validation loss: 1.9548879663149517

Epoch: 6| Step: 2
Training loss: 2.1138832569122314
Validation loss: 1.9779635071754456

Epoch: 6| Step: 3
Training loss: 1.8735079765319824
Validation loss: 1.96983140707016

Epoch: 6| Step: 4
Training loss: 2.794346809387207
Validation loss: 1.9609512686729431

Epoch: 6| Step: 5
Training loss: 2.0241518020629883
Validation loss: 1.9799209038416545

Epoch: 6| Step: 6
Training loss: 1.701225757598877
Validation loss: 1.975883940855662

Epoch: 6| Step: 7
Training loss: 2.113652467727661
Validation loss: 1.9743277629216511

Epoch: 6| Step: 8
Training loss: 1.9596428871154785
Validation loss: 1.970319151878357

Epoch: 6| Step: 9
Training loss: 1.868201494216919
Validation loss: 1.9496721625328064

Epoch: 6| Step: 10
Training loss: 1.5044362545013428
Validation loss: 1.9683774312337239

Epoch: 6| Step: 11
Training loss: 1.5653650760650635
Validation loss: 1.9548417329788208

Epoch: 6| Step: 12
Training loss: 1.9967812299728394
Validation loss: 1.9768942594528198

Epoch: 6| Step: 13
Training loss: 2.076340913772583
Validation loss: 1.9599557916323345

Epoch: 19| Step: 0
Training loss: 1.9116883277893066
Validation loss: 1.9565154314041138

Epoch: 6| Step: 1
Training loss: 1.9179496765136719
Validation loss: 1.9815324346224468

Epoch: 6| Step: 2
Training loss: 2.027439594268799
Validation loss: 1.9602837165196736

Epoch: 6| Step: 3
Training loss: 2.014460563659668
Validation loss: 1.9635677138964336

Epoch: 6| Step: 4
Training loss: 1.7230830192565918
Validation loss: 1.9804848829905193

Epoch: 6| Step: 5
Training loss: 2.2223165035247803
Validation loss: 1.9775111079216003

Epoch: 6| Step: 6
Training loss: 2.2445688247680664
Validation loss: 1.9733687043190002

Epoch: 6| Step: 7
Training loss: 1.857048749923706
Validation loss: 1.9761285384496052

Epoch: 6| Step: 8
Training loss: 1.6968674659729004
Validation loss: 1.9611336986223857

Epoch: 6| Step: 9
Training loss: 2.210371971130371
Validation loss: 1.9763139486312866

Epoch: 6| Step: 10
Training loss: 1.443367838859558
Validation loss: 1.9745449026425679

Epoch: 6| Step: 11
Training loss: 2.3622968196868896
Validation loss: 1.9782109260559082

Epoch: 6| Step: 12
Training loss: 2.622692108154297
Validation loss: 1.979457954565684

Epoch: 6| Step: 13
Training loss: 1.393743634223938
Validation loss: 1.9783615867296855

Epoch: 20| Step: 0
Training loss: 1.893523097038269
Validation loss: 1.984958291053772

Epoch: 6| Step: 1
Training loss: 2.22682523727417
Validation loss: 1.9781107703844707

Epoch: 6| Step: 2
Training loss: 1.9598991870880127
Validation loss: 1.969704508781433

Epoch: 6| Step: 3
Training loss: 2.300788402557373
Validation loss: 1.9580210049947102

Epoch: 6| Step: 4
Training loss: 1.9691716432571411
Validation loss: 1.976771593093872

Epoch: 6| Step: 5
Training loss: 2.023209571838379
Validation loss: 1.9522860447565715

Epoch: 6| Step: 6
Training loss: 1.605859398841858
Validation loss: 1.9624048272768657

Epoch: 6| Step: 7
Training loss: 2.112271308898926
Validation loss: 1.9655240972836812

Epoch: 6| Step: 8
Training loss: 2.3757762908935547
Validation loss: 1.9730785489082336

Epoch: 6| Step: 9
Training loss: 1.3634247779846191
Validation loss: 1.9649599194526672

Epoch: 6| Step: 10
Training loss: 1.9923068284988403
Validation loss: 1.9691095550855

Epoch: 6| Step: 11
Training loss: 1.680326223373413
Validation loss: 1.9538421233495076

Epoch: 6| Step: 12
Training loss: 2.0637128353118896
Validation loss: 1.96114714940389

Epoch: 6| Step: 13
Training loss: 2.065424919128418
Validation loss: 1.9770583311716716

Epoch: 21| Step: 0
Training loss: 2.499178647994995
Validation loss: 1.967700481414795

Epoch: 6| Step: 1
Training loss: 2.3724241256713867
Validation loss: 1.9817969004313152

Epoch: 6| Step: 2
Training loss: 2.2174417972564697
Validation loss: 1.9902172883351643

Epoch: 6| Step: 3
Training loss: 1.908988118171692
Validation loss: 1.978148102760315

Epoch: 6| Step: 4
Training loss: 2.1646571159362793
Validation loss: 1.976649284362793

Epoch: 6| Step: 5
Training loss: 1.3004462718963623
Validation loss: 1.9727667768796284

Epoch: 6| Step: 6
Training loss: 2.0393497943878174
Validation loss: 1.9696073333422344

Epoch: 6| Step: 7
Training loss: 1.4678741693496704
Validation loss: 1.9738211433092754

Epoch: 6| Step: 8
Training loss: 2.163492441177368
Validation loss: 1.9693650205930073

Epoch: 6| Step: 9
Training loss: 1.5028560161590576
Validation loss: 1.965965171655019

Epoch: 6| Step: 10
Training loss: 2.192392349243164
Validation loss: 1.9711762070655823

Epoch: 6| Step: 11
Training loss: 1.8653717041015625
Validation loss: 1.9648674329121907

Epoch: 6| Step: 12
Training loss: 1.9381515979766846
Validation loss: 1.9678420424461365

Epoch: 6| Step: 13
Training loss: 2.083404064178467
Validation loss: 1.9663004875183105

Epoch: 22| Step: 0
Training loss: 2.0939431190490723
Validation loss: 1.9692161480585735

Epoch: 6| Step: 1
Training loss: 1.8830015659332275
Validation loss: 1.9669334093729656

Epoch: 6| Step: 2
Training loss: 2.0845725536346436
Validation loss: 1.9702230493227642

Epoch: 6| Step: 3
Training loss: 2.210874557495117
Validation loss: 1.9708872437477112

Epoch: 6| Step: 4
Training loss: 1.9001290798187256
Validation loss: 1.9682212273279827

Epoch: 6| Step: 5
Training loss: 1.538781762123108
Validation loss: 1.9769957462946575

Epoch: 6| Step: 6
Training loss: 1.6197643280029297
Validation loss: 1.990954319636027

Epoch: 6| Step: 7
Training loss: 1.9143203496932983
Validation loss: 1.9775463938713074

Epoch: 6| Step: 8
Training loss: 1.9639828205108643
Validation loss: 1.9801052113374074

Epoch: 6| Step: 9
Training loss: 1.3438246250152588
Validation loss: 1.9866129755973816

Epoch: 6| Step: 10
Training loss: 2.1286919116973877
Validation loss: 1.9942457874615986

Epoch: 6| Step: 11
Training loss: 1.9942197799682617
Validation loss: 2.0082497199376426

Epoch: 6| Step: 12
Training loss: 2.1403369903564453
Validation loss: 2.010807832082113

Epoch: 6| Step: 13
Training loss: 2.708040714263916
Validation loss: 1.9993372162183125

Epoch: 23| Step: 0
Training loss: 1.8236136436462402
Validation loss: 1.992049554983775

Epoch: 6| Step: 1
Training loss: 2.8662803173065186
Validation loss: 1.9744426608085632

Epoch: 6| Step: 2
Training loss: 1.5187832117080688
Validation loss: 1.9751231670379639

Epoch: 6| Step: 3
Training loss: 1.6584147214889526
Validation loss: 1.954231599966685

Epoch: 6| Step: 4
Training loss: 2.054903268814087
Validation loss: 1.960378110408783

Epoch: 6| Step: 5
Training loss: 1.3663800954818726
Validation loss: 1.979624092578888

Epoch: 6| Step: 6
Training loss: 1.901322364807129
Validation loss: 1.9755179484685261

Epoch: 6| Step: 7
Training loss: 2.148651599884033
Validation loss: 1.957503120104472

Epoch: 6| Step: 8
Training loss: 2.0242810249328613
Validation loss: 1.9609410961469014

Epoch: 6| Step: 9
Training loss: 1.7661523818969727
Validation loss: 1.9623307784398396

Epoch: 6| Step: 10
Training loss: 2.3071141242980957
Validation loss: 1.9667503237724304

Epoch: 6| Step: 11
Training loss: 2.5569510459899902
Validation loss: 1.9678595264752705

Epoch: 6| Step: 12
Training loss: 2.1544039249420166
Validation loss: 1.9691701730092366

Epoch: 6| Step: 13
Training loss: 1.7888129949569702
Validation loss: 1.9695613582928975

Epoch: 24| Step: 0
Training loss: 1.5541553497314453
Validation loss: 1.9625480969746907

Epoch: 6| Step: 1
Training loss: 1.6509654521942139
Validation loss: 1.9519291917483013

Epoch: 6| Step: 2
Training loss: 1.8213427066802979
Validation loss: 1.969104031721751

Epoch: 6| Step: 3
Training loss: 1.8478716611862183
Validation loss: 1.9550700585047405

Epoch: 6| Step: 4
Training loss: 1.4821531772613525
Validation loss: 1.9816850423812866

Epoch: 6| Step: 5
Training loss: 1.6954901218414307
Validation loss: 1.9669135212898254

Epoch: 6| Step: 6
Training loss: 1.5390747785568237
Validation loss: 1.9767109553019206

Epoch: 6| Step: 7
Training loss: 2.0216400623321533
Validation loss: 1.9729936520258586

Epoch: 6| Step: 8
Training loss: 2.9841673374176025
Validation loss: 1.961994707584381

Epoch: 6| Step: 9
Training loss: 1.9614075422286987
Validation loss: 1.955975850423177

Epoch: 6| Step: 10
Training loss: 2.3805336952209473
Validation loss: 1.971863051255544

Epoch: 6| Step: 11
Training loss: 2.60919189453125
Validation loss: 1.969906469186147

Epoch: 6| Step: 12
Training loss: 1.8749823570251465
Validation loss: 1.9719810485839844

Epoch: 6| Step: 13
Training loss: 1.938591480255127
Validation loss: 1.9551460146903992

Epoch: 25| Step: 0
Training loss: 1.8450562953948975
Validation loss: 1.963528037071228

Epoch: 6| Step: 1
Training loss: 1.8160831928253174
Validation loss: 1.9626105427742004

Epoch: 6| Step: 2
Training loss: 2.959850311279297
Validation loss: 1.9689525763193767

Epoch: 6| Step: 3
Training loss: 2.446849822998047
Validation loss: 1.9695745905240376

Epoch: 6| Step: 4
Training loss: 2.595317840576172
Validation loss: 1.9523895382881165

Epoch: 6| Step: 5
Training loss: 2.2645857334136963
Validation loss: 1.9932849804560344

Epoch: 6| Step: 6
Training loss: 1.9106711149215698
Validation loss: 1.979182501633962

Epoch: 6| Step: 7
Training loss: 1.3718551397323608
Validation loss: 1.9659383495648701

Epoch: 6| Step: 8
Training loss: 2.2149691581726074
Validation loss: 1.971618910630544

Epoch: 6| Step: 9
Training loss: 1.4823427200317383
Validation loss: 1.9696924090385437

Epoch: 6| Step: 10
Training loss: 0.9041502475738525
Validation loss: 1.970733384291331

Epoch: 6| Step: 11
Training loss: 1.5307890176773071
Validation loss: 1.9623536070187886

Epoch: 6| Step: 12
Training loss: 2.038674831390381
Validation loss: 1.9744774500528972

Epoch: 6| Step: 13
Training loss: 1.8750699758529663
Validation loss: 1.96504940589269

Epoch: 26| Step: 0
Training loss: 1.7403438091278076
Validation loss: 1.9557806452115376

Epoch: 6| Step: 1
Training loss: 2.5013999938964844
Validation loss: 1.9607306917508442

Epoch: 6| Step: 2
Training loss: 2.1081156730651855
Validation loss: 1.9559181332588196

Epoch: 6| Step: 3
Training loss: 2.2116079330444336
Validation loss: 1.9504679242769878

Epoch: 6| Step: 4
Training loss: 1.7011198997497559
Validation loss: 1.9714600046475728

Epoch: 6| Step: 5
Training loss: 2.05460524559021
Validation loss: 1.9579354921976726

Epoch: 6| Step: 6
Training loss: 2.3842692375183105
Validation loss: 1.9556702772776287

Epoch: 6| Step: 7
Training loss: 2.122943878173828
Validation loss: 1.968241771062215

Epoch: 6| Step: 8
Training loss: 2.0785512924194336
Validation loss: 1.9677912990252178

Epoch: 6| Step: 9
Training loss: 1.3803178071975708
Validation loss: 1.9673213958740234

Epoch: 6| Step: 10
Training loss: 1.6355795860290527
Validation loss: 1.9722179969151814

Epoch: 6| Step: 11
Training loss: 1.7590535879135132
Validation loss: 1.9592377146085103

Epoch: 6| Step: 12
Training loss: 1.712030053138733
Validation loss: 1.9674399892489116

Epoch: 6| Step: 13
Training loss: 1.735166072845459
Validation loss: 1.9653300444285076

Epoch: 27| Step: 0
Training loss: 2.3703362941741943
Validation loss: 1.9502276182174683

Epoch: 6| Step: 1
Training loss: 1.5312995910644531
Validation loss: 1.9717528223991394

Epoch: 6| Step: 2
Training loss: 1.5714106559753418
Validation loss: 1.9596302111943562

Epoch: 6| Step: 3
Training loss: 1.7477097511291504
Validation loss: 1.9651625951131184

Epoch: 6| Step: 4
Training loss: 2.177191972732544
Validation loss: 1.954350769519806

Epoch: 6| Step: 5
Training loss: 1.8934097290039062
Validation loss: 1.9597219824790955

Epoch: 6| Step: 6
Training loss: 1.2677745819091797
Validation loss: 1.9707393248875935

Epoch: 6| Step: 7
Training loss: 2.395233392715454
Validation loss: 1.9675967892011006

Epoch: 6| Step: 8
Training loss: 1.5026545524597168
Validation loss: 1.9660459359486897

Epoch: 6| Step: 9
Training loss: 1.7636561393737793
Validation loss: 1.987438480059306

Epoch: 6| Step: 10
Training loss: 1.7014089822769165
Validation loss: 2.0019225676854453

Epoch: 6| Step: 11
Training loss: 2.729337215423584
Validation loss: 1.9880324999491374

Epoch: 6| Step: 12
Training loss: 2.6521835327148438
Validation loss: 1.9641125202178955

Epoch: 6| Step: 13
Training loss: 1.9361116886138916
Validation loss: 1.9757809241612752

Epoch: 28| Step: 0
Training loss: 2.47998046875
Validation loss: 1.9684742490450542

Epoch: 6| Step: 1
Training loss: 1.9005966186523438
Validation loss: 1.96359916528066

Epoch: 6| Step: 2
Training loss: 1.7311029434204102
Validation loss: 1.9585084517796834

Epoch: 6| Step: 3
Training loss: 2.3064475059509277
Validation loss: 1.9592754046122234

Epoch: 6| Step: 4
Training loss: 1.6276029348373413
Validation loss: 1.9576985438664753

Epoch: 6| Step: 5
Training loss: 2.1901280879974365
Validation loss: 1.946344017982483

Epoch: 6| Step: 6
Training loss: 2.1105899810791016
Validation loss: 1.957103967666626

Epoch: 6| Step: 7
Training loss: 2.3529839515686035
Validation loss: 1.9712073802947998

Epoch: 6| Step: 8
Training loss: 1.737922191619873
Validation loss: 1.9587299227714539

Epoch: 6| Step: 9
Training loss: 1.7061316967010498
Validation loss: 1.9596413175264995

Epoch: 6| Step: 10
Training loss: 1.525597333908081
Validation loss: 1.97394065062205

Epoch: 6| Step: 11
Training loss: 1.722420334815979
Validation loss: 1.9728879928588867

Epoch: 6| Step: 12
Training loss: 1.7903165817260742
Validation loss: 1.9856555660565693

Epoch: 6| Step: 13
Training loss: 1.9979153871536255
Validation loss: 1.9806039532025654

Epoch: 29| Step: 0
Training loss: 2.074984550476074
Validation loss: 1.9808907111485798

Epoch: 6| Step: 1
Training loss: 1.8755934238433838
Validation loss: 1.9855942130088806

Epoch: 6| Step: 2
Training loss: 1.7944661378860474
Validation loss: 1.9839994311332703

Epoch: 6| Step: 3
Training loss: 1.8648278713226318
Validation loss: 1.97564031680425

Epoch: 6| Step: 4
Training loss: 1.5949376821517944
Validation loss: 1.9620725115140278

Epoch: 6| Step: 5
Training loss: 2.071934700012207
Validation loss: 1.9686636130015056

Epoch: 6| Step: 6
Training loss: 1.7242319583892822
Validation loss: 1.966764231522878

Epoch: 6| Step: 7
Training loss: 2.0212981700897217
Validation loss: 1.9853744506835938

Epoch: 6| Step: 8
Training loss: 2.0699217319488525
Validation loss: 1.9564401904741924

Epoch: 6| Step: 9
Training loss: 2.1262712478637695
Validation loss: 1.9544731378555298

Epoch: 6| Step: 10
Training loss: 2.3279223442077637
Validation loss: 1.9682902296384175

Epoch: 6| Step: 11
Training loss: 1.8108426332473755
Validation loss: 1.960976004600525

Epoch: 6| Step: 12
Training loss: 1.4300589561462402
Validation loss: 1.9717809359232585

Epoch: 6| Step: 13
Training loss: 2.1204917430877686
Validation loss: 1.9650489290555317

Epoch: 30| Step: 0
Training loss: 1.7724850177764893
Validation loss: 1.9706708590189617

Epoch: 6| Step: 1
Training loss: 2.072246551513672
Validation loss: 1.9591801365216572

Epoch: 6| Step: 2
Training loss: 1.9457452297210693
Validation loss: 1.9650904138882954

Epoch: 6| Step: 3
Training loss: 2.1601152420043945
Validation loss: 1.9729524453481038

Epoch: 6| Step: 4
Training loss: 2.002063035964966
Validation loss: 1.9730403820673625

Epoch: 6| Step: 5
Training loss: 2.2527856826782227
Validation loss: 1.9567187229792278

Epoch: 6| Step: 6
Training loss: 1.961014747619629
Validation loss: 1.9812611937522888

Epoch: 6| Step: 7
Training loss: 1.7571569681167603
Validation loss: 2.0180657307306924

Epoch: 6| Step: 8
Training loss: 1.7024143934249878
Validation loss: 2.0124780734380088

Epoch: 6| Step: 9
Training loss: 1.99934983253479
Validation loss: 2.0211015144983926

Epoch: 6| Step: 10
Training loss: 2.25714111328125
Validation loss: 1.9990306893984477

Epoch: 6| Step: 11
Training loss: 2.0564723014831543
Validation loss: 1.9908641974131267

Epoch: 6| Step: 12
Training loss: 1.5132555961608887
Validation loss: 1.9863887429237366

Epoch: 6| Step: 13
Training loss: 1.8053418397903442
Validation loss: 1.966805358727773

Epoch: 31| Step: 0
Training loss: 1.7620142698287964
Validation loss: 1.9385414918263753

Epoch: 6| Step: 1
Training loss: 2.3520073890686035
Validation loss: 1.9568766951560974

Epoch: 6| Step: 2
Training loss: 1.9876588582992554
Validation loss: 1.9557726581891377

Epoch: 6| Step: 3
Training loss: 1.3557884693145752
Validation loss: 1.9610597689946492

Epoch: 6| Step: 4
Training loss: 1.721051573753357
Validation loss: 1.9746445616086323

Epoch: 6| Step: 5
Training loss: 2.165485382080078
Validation loss: 1.951783299446106

Epoch: 6| Step: 6
Training loss: 2.5450236797332764
Validation loss: 1.9509738683700562

Epoch: 6| Step: 7
Training loss: 1.393481969833374
Validation loss: 1.9505770603815715

Epoch: 6| Step: 8
Training loss: 2.851954460144043
Validation loss: 1.9490630626678467

Epoch: 6| Step: 9
Training loss: 1.236119270324707
Validation loss: 1.9602452913920085

Epoch: 6| Step: 10
Training loss: 1.6250414848327637
Validation loss: 1.9491776029268901

Epoch: 6| Step: 11
Training loss: 2.0245649814605713
Validation loss: 1.9591302275657654

Epoch: 6| Step: 12
Training loss: 2.2023777961730957
Validation loss: 1.9612746238708496

Epoch: 6| Step: 13
Training loss: 2.415048599243164
Validation loss: 1.9719454447428386

Epoch: 32| Step: 0
Training loss: 2.3737382888793945
Validation loss: 1.984911561012268

Epoch: 6| Step: 1
Training loss: 1.9783799648284912
Validation loss: 1.9706895748774211

Epoch: 6| Step: 2
Training loss: 1.7879608869552612
Validation loss: 1.9640181461970012

Epoch: 6| Step: 3
Training loss: 1.6760149002075195
Validation loss: 1.9558050632476807

Epoch: 6| Step: 4
Training loss: 1.6740617752075195
Validation loss: 1.9831270178159077

Epoch: 6| Step: 5
Training loss: 1.710710048675537
Validation loss: 1.9476636052131653

Epoch: 6| Step: 6
Training loss: 2.135460138320923
Validation loss: 1.9580508669217427

Epoch: 6| Step: 7
Training loss: 1.9839427471160889
Validation loss: 1.965772767861684

Epoch: 6| Step: 8
Training loss: 1.7392114400863647
Validation loss: 1.9665591716766357

Epoch: 6| Step: 9
Training loss: 1.6748011112213135
Validation loss: 1.937993009885152

Epoch: 6| Step: 10
Training loss: 1.899697184562683
Validation loss: 1.966525713602702

Epoch: 6| Step: 11
Training loss: 2.1818251609802246
Validation loss: 1.9563660621643066

Epoch: 6| Step: 12
Training loss: 2.0505635738372803
Validation loss: 1.962064266204834

Epoch: 6| Step: 13
Training loss: 1.9455000162124634
Validation loss: 1.9560930132865906

Epoch: 33| Step: 0
Training loss: 1.9171326160430908
Validation loss: 1.9795101086298625

Epoch: 6| Step: 1
Training loss: 1.2704625129699707
Validation loss: 1.956647515296936

Epoch: 6| Step: 2
Training loss: 1.6007132530212402
Validation loss: 1.9665669004122417

Epoch: 6| Step: 3
Training loss: 1.8926981687545776
Validation loss: 1.9683490594228108

Epoch: 6| Step: 4
Training loss: 2.5453572273254395
Validation loss: 1.9675218065579732

Epoch: 6| Step: 5
Training loss: 2.310220241546631
Validation loss: 1.9639102816581726

Epoch: 6| Step: 6
Training loss: 1.970197319984436
Validation loss: 1.9731456240018208

Epoch: 6| Step: 7
Training loss: 1.6234451532363892
Validation loss: 1.9484011729558308

Epoch: 6| Step: 8
Training loss: 2.426492214202881
Validation loss: 1.9756243626276653

Epoch: 6| Step: 9
Training loss: 1.6803803443908691
Validation loss: 1.944844384988149

Epoch: 6| Step: 10
Training loss: 2.469964027404785
Validation loss: 1.960660497347514

Epoch: 6| Step: 11
Training loss: 1.4089279174804688
Validation loss: 1.9430965781211853

Epoch: 6| Step: 12
Training loss: 1.944271445274353
Validation loss: 1.9603655536969502

Epoch: 6| Step: 13
Training loss: 1.7808502912521362
Validation loss: 1.9573285380999248

Epoch: 34| Step: 0
Training loss: 1.7299013137817383
Validation loss: 1.9677489797274272

Epoch: 6| Step: 1
Training loss: 1.824647307395935
Validation loss: 1.941776990890503

Epoch: 6| Step: 2
Training loss: 2.580625295639038
Validation loss: 1.9420472383499146

Epoch: 6| Step: 3
Training loss: 1.8937551975250244
Validation loss: 1.9588849544525146

Epoch: 6| Step: 4
Training loss: 1.8256996870040894
Validation loss: 1.9480652213096619

Epoch: 6| Step: 5
Training loss: 1.1521064043045044
Validation loss: 1.9497469862302144

Epoch: 6| Step: 6
Training loss: 1.531571626663208
Validation loss: 1.962052086989085

Epoch: 6| Step: 7
Training loss: 2.013198137283325
Validation loss: 1.965623100598653

Epoch: 6| Step: 8
Training loss: 2.040072441101074
Validation loss: 1.974594255288442

Epoch: 6| Step: 9
Training loss: 2.350231170654297
Validation loss: 1.9957861105600994

Epoch: 6| Step: 10
Training loss: 2.1171820163726807
Validation loss: 2.0130456686019897

Epoch: 6| Step: 11
Training loss: 1.029679298400879
Validation loss: 2.012861688931783

Epoch: 6| Step: 12
Training loss: 2.919745922088623
Validation loss: 1.99320654074351

Epoch: 6| Step: 13
Training loss: 1.9963628053665161
Validation loss: 1.9778849085172017

Epoch: 35| Step: 0
Training loss: 1.3089497089385986
Validation loss: 1.9589160482088726

Epoch: 6| Step: 1
Training loss: 2.341580867767334
Validation loss: 1.9701943198839824

Epoch: 6| Step: 2
Training loss: 2.164001226425171
Validation loss: 1.9392820596694946

Epoch: 6| Step: 3
Training loss: 1.6967058181762695
Validation loss: 1.9559627771377563

Epoch: 6| Step: 4
Training loss: 1.7642107009887695
Validation loss: 1.9635898272196453

Epoch: 6| Step: 5
Training loss: 1.6919203996658325
Validation loss: 1.967302143573761

Epoch: 6| Step: 6
Training loss: 2.151745080947876
Validation loss: 1.965002457300822

Epoch: 6| Step: 7
Training loss: 2.0535378456115723
Validation loss: 1.9662803212801616

Epoch: 6| Step: 8
Training loss: 2.314967155456543
Validation loss: 1.95922456185023

Epoch: 6| Step: 9
Training loss: 1.4926631450653076
Validation loss: 1.9527658224105835

Epoch: 6| Step: 10
Training loss: 1.9998202323913574
Validation loss: 1.9646500150362651

Epoch: 6| Step: 11
Training loss: 1.7697770595550537
Validation loss: 1.960480769475301

Epoch: 6| Step: 12
Training loss: 2.2487030029296875
Validation loss: 1.9684314131736755

Epoch: 6| Step: 13
Training loss: 1.6465075016021729
Validation loss: 1.9542307655016582

Epoch: 36| Step: 0
Training loss: 1.4641884565353394
Validation loss: 1.9569158752759297

Epoch: 6| Step: 1
Training loss: 1.2562382221221924
Validation loss: 1.9608970880508423

Epoch: 6| Step: 2
Training loss: 2.106949806213379
Validation loss: 1.9761081139246623

Epoch: 6| Step: 3
Training loss: 2.1115193367004395
Validation loss: 1.9695431391398113

Epoch: 6| Step: 4
Training loss: 1.7684564590454102
Validation loss: 1.9853760401407878

Epoch: 6| Step: 5
Training loss: 2.291907787322998
Validation loss: 1.9706978400548298

Epoch: 6| Step: 6
Training loss: 1.6219074726104736
Validation loss: 1.9786019523938496

Epoch: 6| Step: 7
Training loss: 1.540884017944336
Validation loss: 1.987338125705719

Epoch: 6| Step: 8
Training loss: 2.449366569519043
Validation loss: 1.9897446433703105

Epoch: 6| Step: 9
Training loss: 2.017777442932129
Validation loss: 2.0006773273150125

Epoch: 6| Step: 10
Training loss: 1.7250521183013916
Validation loss: 2.006669024626414

Epoch: 6| Step: 11
Training loss: 1.8419184684753418
Validation loss: 1.9819260438283284

Epoch: 6| Step: 12
Training loss: 2.7487826347351074
Validation loss: 1.9842158555984497

Epoch: 6| Step: 13
Training loss: 1.6017942428588867
Validation loss: 1.990946888923645

Epoch: 37| Step: 0
Training loss: 2.2545714378356934
Validation loss: 1.9567407965660095

Epoch: 6| Step: 1
Training loss: 1.660215973854065
Validation loss: 1.9766325155893962

Epoch: 6| Step: 2
Training loss: 1.1773240566253662
Validation loss: 1.9646770159403484

Epoch: 6| Step: 3
Training loss: 1.744626760482788
Validation loss: 1.9576152364412944

Epoch: 6| Step: 4
Training loss: 2.185760498046875
Validation loss: 1.9467598001162212

Epoch: 6| Step: 5
Training loss: 1.1221604347229004
Validation loss: 1.9622765978177388

Epoch: 6| Step: 6
Training loss: 1.9630818367004395
Validation loss: 1.9432797233263652

Epoch: 6| Step: 7
Training loss: 2.455484390258789
Validation loss: 1.958280086517334

Epoch: 6| Step: 8
Training loss: 1.4708240032196045
Validation loss: 1.9684650500615437

Epoch: 6| Step: 9
Training loss: 2.12255597114563
Validation loss: 1.9770611921946208

Epoch: 6| Step: 10
Training loss: 2.3254220485687256
Validation loss: 1.9854385654131572

Epoch: 6| Step: 11
Training loss: 2.125609874725342
Validation loss: 2.0004038214683533

Epoch: 6| Step: 12
Training loss: 2.1716511249542236
Validation loss: 1.9776095549265544

Epoch: 6| Step: 13
Training loss: 1.6859796047210693
Validation loss: 1.9699985980987549

Epoch: 38| Step: 0
Training loss: 1.5276747941970825
Validation loss: 1.9795767664909363

Epoch: 6| Step: 1
Training loss: 1.7690943479537964
Validation loss: 1.9755516250928242

Epoch: 6| Step: 2
Training loss: 1.9316294193267822
Validation loss: 1.9690128962198894

Epoch: 6| Step: 3
Training loss: 1.381425380706787
Validation loss: 1.9620704054832458

Epoch: 6| Step: 4
Training loss: 2.3734848499298096
Validation loss: 1.9724907477696736

Epoch: 6| Step: 5
Training loss: 1.7259247303009033
Validation loss: 1.9785815080006917

Epoch: 6| Step: 6
Training loss: 1.7835558652877808
Validation loss: 1.975443164507548

Epoch: 6| Step: 7
Training loss: 2.057976245880127
Validation loss: 1.9875897566477458

Epoch: 6| Step: 8
Training loss: 2.2942240238189697
Validation loss: 1.9699100852012634

Epoch: 6| Step: 9
Training loss: 1.8980052471160889
Validation loss: 1.9763662815093994

Epoch: 6| Step: 10
Training loss: 1.9991326332092285
Validation loss: 1.9820382793744404

Epoch: 6| Step: 11
Training loss: 2.0893301963806152
Validation loss: 1.9652979175249736

Epoch: 6| Step: 12
Training loss: 1.7765204906463623
Validation loss: 1.9639945030212402

Epoch: 6| Step: 13
Training loss: 1.7515511512756348
Validation loss: 1.9751704732577007

Epoch: 39| Step: 0
Training loss: 2.3560104370117188
Validation loss: 1.962982972462972

Epoch: 6| Step: 1
Training loss: 1.5679256916046143
Validation loss: 1.9523019591967266

Epoch: 6| Step: 2
Training loss: 2.0119900703430176
Validation loss: 1.9530932505925496

Epoch: 6| Step: 3
Training loss: 2.1233620643615723
Validation loss: 1.961263398329417

Epoch: 6| Step: 4
Training loss: 1.761340618133545
Validation loss: 1.9536402622858684

Epoch: 6| Step: 5
Training loss: 1.2342498302459717
Validation loss: 1.9610182841618855

Epoch: 6| Step: 6
Training loss: 1.4557803869247437
Validation loss: 1.9599228501319885

Epoch: 6| Step: 7
Training loss: 2.1104259490966797
Validation loss: 1.9743729035059612

Epoch: 6| Step: 8
Training loss: 2.24168062210083
Validation loss: 1.971340815226237

Epoch: 6| Step: 9
Training loss: 1.5616999864578247
Validation loss: 1.971557378768921

Epoch: 6| Step: 10
Training loss: 2.2434871196746826
Validation loss: 2.0029224952061973

Epoch: 6| Step: 11
Training loss: 1.8676531314849854
Validation loss: 2.009482661883036

Epoch: 6| Step: 12
Training loss: 2.572342872619629
Validation loss: 2.014008343219757

Epoch: 6| Step: 13
Training loss: 1.6408576965332031
Validation loss: 1.983060320218404

Epoch: 40| Step: 0
Training loss: 2.6433606147766113
Validation loss: 1.9865923722585042

Epoch: 6| Step: 1
Training loss: 1.7619545459747314
Validation loss: 1.9790932337443035

Epoch: 6| Step: 2
Training loss: 2.366684913635254
Validation loss: 1.979137361049652

Epoch: 6| Step: 3
Training loss: 1.9893888235092163
Validation loss: 1.9605376919110615

Epoch: 6| Step: 4
Training loss: 1.8085134029388428
Validation loss: 1.970724920431773

Epoch: 6| Step: 5
Training loss: 1.5076355934143066
Validation loss: 1.9414535164833069

Epoch: 6| Step: 6
Training loss: 1.6681255102157593
Validation loss: 1.9645418524742126

Epoch: 6| Step: 7
Training loss: 2.109710931777954
Validation loss: 1.9512158234914143

Epoch: 6| Step: 8
Training loss: 1.4728754758834839
Validation loss: 1.968402087688446

Epoch: 6| Step: 9
Training loss: 1.3279109001159668
Validation loss: 1.944680094718933

Epoch: 6| Step: 10
Training loss: 2.3174843788146973
Validation loss: 1.9443564613660176

Epoch: 6| Step: 11
Training loss: 2.055874824523926
Validation loss: 1.9624186754226685

Epoch: 6| Step: 12
Training loss: 1.4768296480178833
Validation loss: 1.9514093399047852

Epoch: 6| Step: 13
Training loss: 2.0691840648651123
Validation loss: 1.9607542554537456

Epoch: 41| Step: 0
Training loss: 1.5248616933822632
Validation loss: 1.937448779741923

Epoch: 6| Step: 1
Training loss: 1.8545829057693481
Validation loss: 1.9542599121729534

Epoch: 6| Step: 2
Training loss: 1.6702543497085571
Validation loss: 1.9840162992477417

Epoch: 6| Step: 3
Training loss: 2.3336031436920166
Validation loss: 1.982654909292857

Epoch: 6| Step: 4
Training loss: 2.2253737449645996
Validation loss: 1.9916809995969136

Epoch: 6| Step: 5
Training loss: 2.4264111518859863
Validation loss: 1.9950084686279297

Epoch: 6| Step: 6
Training loss: 2.010568857192993
Validation loss: 1.9984797437985737

Epoch: 6| Step: 7
Training loss: 1.9960331916809082
Validation loss: 1.991310993830363

Epoch: 6| Step: 8
Training loss: 1.5424025058746338
Validation loss: 1.9823137521743774

Epoch: 6| Step: 9
Training loss: 1.9017283916473389
Validation loss: 2.0013588468233743

Epoch: 6| Step: 10
Training loss: 2.16102933883667
Validation loss: 1.987132489681244

Epoch: 6| Step: 11
Training loss: 1.508932113647461
Validation loss: 1.9696635405222576

Epoch: 6| Step: 12
Training loss: 2.0546417236328125
Validation loss: 1.9580949743588765

Epoch: 6| Step: 13
Training loss: 1.2427725791931152
Validation loss: 1.954447587331136

Epoch: 42| Step: 0
Training loss: 2.445443868637085
Validation loss: 1.9670602083206177

Epoch: 6| Step: 1
Training loss: 1.8536407947540283
Validation loss: 1.9466883540153503

Epoch: 6| Step: 2
Training loss: 1.6048779487609863
Validation loss: 1.9542229572931926

Epoch: 6| Step: 3
Training loss: 1.7202355861663818
Validation loss: 1.966511607170105

Epoch: 6| Step: 4
Training loss: 2.413147449493408
Validation loss: 1.9623652497927349

Epoch: 6| Step: 5
Training loss: 2.1081554889678955
Validation loss: 1.944067935148875

Epoch: 6| Step: 6
Training loss: 1.8547337055206299
Validation loss: 1.955665608247121

Epoch: 6| Step: 7
Training loss: 1.6284821033477783
Validation loss: 1.957482397556305

Epoch: 6| Step: 8
Training loss: 1.2574188709259033
Validation loss: 1.947458803653717

Epoch: 6| Step: 9
Training loss: 2.1735568046569824
Validation loss: 1.966273268063863

Epoch: 6| Step: 10
Training loss: 2.1997947692871094
Validation loss: 1.9568949739138286

Epoch: 6| Step: 11
Training loss: 1.4837760925292969
Validation loss: 1.9763716061909993

Epoch: 6| Step: 12
Training loss: 1.9384040832519531
Validation loss: 1.9593189756075542

Epoch: 6| Step: 13
Training loss: 1.4526255130767822
Validation loss: 1.9645832180976868

Epoch: 43| Step: 0
Training loss: 1.5531578063964844
Validation loss: 1.9726533492406209

Epoch: 6| Step: 1
Training loss: 1.961097002029419
Validation loss: 1.9711631933848064

Epoch: 6| Step: 2
Training loss: 2.2091987133026123
Validation loss: 1.9678468306859334

Epoch: 6| Step: 3
Training loss: 2.4892001152038574
Validation loss: 1.959334671497345

Epoch: 6| Step: 4
Training loss: 1.9913899898529053
Validation loss: 1.9659418662389119

Epoch: 6| Step: 5
Training loss: 1.7414839267730713
Validation loss: 1.9539618293444316

Epoch: 6| Step: 6
Training loss: 2.1522598266601562
Validation loss: 1.9560829401016235

Epoch: 6| Step: 7
Training loss: 1.3975750207901
Validation loss: 1.9498557845751445

Epoch: 6| Step: 8
Training loss: 2.042668104171753
Validation loss: 1.964493989944458

Epoch: 6| Step: 9
Training loss: 1.6193625926971436
Validation loss: 1.9561234911282857

Epoch: 6| Step: 10
Training loss: 1.2005094289779663
Validation loss: 1.9627995292345684

Epoch: 6| Step: 11
Training loss: 1.368677020072937
Validation loss: 1.964474121729533

Epoch: 6| Step: 12
Training loss: 2.2771549224853516
Validation loss: 1.9638724724451702

Epoch: 6| Step: 13
Training loss: 2.0257568359375
Validation loss: 1.9595026175181072

Epoch: 44| Step: 0
Training loss: 2.516977310180664
Validation loss: 1.973084072271983

Epoch: 6| Step: 1
Training loss: 2.5917885303497314
Validation loss: 1.9743280013402302

Epoch: 6| Step: 2
Training loss: 1.606935739517212
Validation loss: 1.969706376393636

Epoch: 6| Step: 3
Training loss: 2.300609588623047
Validation loss: 1.9461386799812317

Epoch: 6| Step: 4
Training loss: 1.8463897705078125
Validation loss: 1.9539312720298767

Epoch: 6| Step: 5
Training loss: 1.2088232040405273
Validation loss: 1.9648520549138386

Epoch: 6| Step: 6
Training loss: 1.3202990293502808
Validation loss: 1.9377567172050476

Epoch: 6| Step: 7
Training loss: 2.087404727935791
Validation loss: 1.9644394516944885

Epoch: 6| Step: 8
Training loss: 1.27685546875
Validation loss: 1.9663663506507874

Epoch: 6| Step: 9
Training loss: 2.1649460792541504
Validation loss: 1.985229233900706

Epoch: 6| Step: 10
Training loss: 1.94596266746521
Validation loss: 1.9709957838058472

Epoch: 6| Step: 11
Training loss: 2.2156386375427246
Validation loss: 1.9751149813334148

Epoch: 6| Step: 12
Training loss: 1.9544568061828613
Validation loss: 1.9609251817067463

Epoch: 6| Step: 13
Training loss: 1.214174747467041
Validation loss: 1.9480384190877278

Epoch: 45| Step: 0
Training loss: 2.578080654144287
Validation loss: 1.9648601412773132

Epoch: 6| Step: 1
Training loss: 1.9488115310668945
Validation loss: 1.9587424596150715

Epoch: 6| Step: 2
Training loss: 1.3843810558319092
Validation loss: 1.9453625480333965

Epoch: 6| Step: 3
Training loss: 2.00313663482666
Validation loss: 1.9547794063886006

Epoch: 6| Step: 4
Training loss: 1.9247689247131348
Validation loss: 1.9655476808547974

Epoch: 6| Step: 5
Training loss: 2.4272301197052
Validation loss: 1.9610125223795574

Epoch: 6| Step: 6
Training loss: 1.5972888469696045
Validation loss: 1.9653433958689372

Epoch: 6| Step: 7
Training loss: 1.706230640411377
Validation loss: 1.9553877115249634

Epoch: 6| Step: 8
Training loss: 2.2536258697509766
Validation loss: 1.952755908171336

Epoch: 6| Step: 9
Training loss: 1.1861233711242676
Validation loss: 1.972894589106242

Epoch: 6| Step: 10
Training loss: 1.5453863143920898
Validation loss: 1.9551079869270325

Epoch: 6| Step: 11
Training loss: 2.1836955547332764
Validation loss: 1.9636659026145935

Epoch: 6| Step: 12
Training loss: 1.183767557144165
Validation loss: 1.9638313452402751

Epoch: 6| Step: 13
Training loss: 1.9818471670150757
Validation loss: 1.9561562935511272

Epoch: 46| Step: 0
Training loss: 2.155686616897583
Validation loss: 1.9642339944839478

Epoch: 6| Step: 1
Training loss: 1.943566083908081
Validation loss: 1.968623121579488

Epoch: 6| Step: 2
Training loss: 1.493030071258545
Validation loss: 1.9636529286702473

Epoch: 6| Step: 3
Training loss: 1.8092679977416992
Validation loss: 1.9663721323013306

Epoch: 6| Step: 4
Training loss: 1.7635855674743652
Validation loss: 1.971127450466156

Epoch: 6| Step: 5
Training loss: 2.0931801795959473
Validation loss: 1.9661316672960918

Epoch: 6| Step: 6
Training loss: 2.3866186141967773
Validation loss: 1.9753978649775188

Epoch: 6| Step: 7
Training loss: 1.5117392539978027
Validation loss: 1.9657291173934937

Epoch: 6| Step: 8
Training loss: 1.5448381900787354
Validation loss: 1.9864546656608582

Epoch: 6| Step: 9
Training loss: 2.244570016860962
Validation loss: 1.9937934676806133

Epoch: 6| Step: 10
Training loss: 1.1980805397033691
Validation loss: 1.9692935347557068

Epoch: 6| Step: 11
Training loss: 2.4142611026763916
Validation loss: 1.9602760076522827

Epoch: 6| Step: 12
Training loss: 2.1688613891601562
Validation loss: 1.9518613616625469

Epoch: 6| Step: 13
Training loss: 1.2946281433105469
Validation loss: 1.9465303023656209

Epoch: 47| Step: 0
Training loss: 1.8679234981536865
Validation loss: 1.961318850517273

Epoch: 6| Step: 1
Training loss: 2.496272563934326
Validation loss: 1.9558847149213154

Epoch: 6| Step: 2
Training loss: 1.7588419914245605
Validation loss: 1.954360842704773

Epoch: 6| Step: 3
Training loss: 2.4511537551879883
Validation loss: 1.9639007647832234

Epoch: 6| Step: 4
Training loss: 1.4960401058197021
Validation loss: 1.9664989312489827

Epoch: 6| Step: 5
Training loss: 1.4078540802001953
Validation loss: 1.9684646328290303

Epoch: 6| Step: 6
Training loss: 2.08449125289917
Validation loss: 1.9762042164802551

Epoch: 6| Step: 7
Training loss: 1.6432697772979736
Validation loss: 1.9675649801890056

Epoch: 6| Step: 8
Training loss: 2.1258604526519775
Validation loss: 1.9902994831403096

Epoch: 6| Step: 9
Training loss: 1.505646824836731
Validation loss: 1.9855931798617046

Epoch: 6| Step: 10
Training loss: 1.2359421253204346
Validation loss: 1.9603965878486633

Epoch: 6| Step: 11
Training loss: 1.5539038181304932
Validation loss: 1.971193830172221

Epoch: 6| Step: 12
Training loss: 2.1151275634765625
Validation loss: 1.9906384944915771

Epoch: 6| Step: 13
Training loss: 1.958009958267212
Validation loss: 1.9759440819422405

Epoch: 48| Step: 0
Training loss: 2.276350498199463
Validation loss: 1.9660444060961406

Epoch: 6| Step: 1
Training loss: 1.9763879776000977
Validation loss: 1.970231533050537

Epoch: 6| Step: 2
Training loss: 2.304731607437134
Validation loss: 1.969914714495341

Epoch: 6| Step: 3
Training loss: 2.2228331565856934
Validation loss: 1.949309726556142

Epoch: 6| Step: 4
Training loss: 2.1179134845733643
Validation loss: 1.976597289244334

Epoch: 6| Step: 5
Training loss: 1.7272653579711914
Validation loss: 1.958214024702708

Epoch: 6| Step: 6
Training loss: 1.7925764322280884
Validation loss: 1.960914969444275

Epoch: 6| Step: 7
Training loss: 1.882284164428711
Validation loss: 1.96563325325648

Epoch: 6| Step: 8
Training loss: 1.7941240072250366
Validation loss: 1.9673204620679219

Epoch: 6| Step: 9
Training loss: 1.297333002090454
Validation loss: 1.995914896329244

Epoch: 6| Step: 10
Training loss: 1.3577371835708618
Validation loss: 1.9724517067273457

Epoch: 6| Step: 11
Training loss: 1.462746262550354
Validation loss: 1.984356125195821

Epoch: 6| Step: 12
Training loss: 1.2823240756988525
Validation loss: 1.9662524859110515

Epoch: 6| Step: 13
Training loss: 2.0378799438476562
Validation loss: 1.9505932132403057

Epoch: 49| Step: 0
Training loss: 1.6825106143951416
Validation loss: 1.9594370325406392

Epoch: 6| Step: 1
Training loss: 1.8115756511688232
Validation loss: 1.9493072827657063

Epoch: 6| Step: 2
Training loss: 2.166329860687256
Validation loss: 1.9677736163139343

Epoch: 6| Step: 3
Training loss: 1.8741683959960938
Validation loss: 1.9516555468241374

Epoch: 6| Step: 4
Training loss: 2.2427215576171875
Validation loss: 1.9969245195388794

Epoch: 6| Step: 5
Training loss: 1.7346079349517822
Validation loss: 1.9906139572461445

Epoch: 6| Step: 6
Training loss: 1.9511982202529907
Validation loss: 1.9856008887290955

Epoch: 6| Step: 7
Training loss: 2.331516981124878
Validation loss: 1.9938385089238484

Epoch: 6| Step: 8
Training loss: 1.7871363162994385
Validation loss: 1.9927533467610676

Epoch: 6| Step: 9
Training loss: 1.1978809833526611
Validation loss: 1.9990268747011821

Epoch: 6| Step: 10
Training loss: 1.7782597541809082
Validation loss: 2.0056533018747964

Epoch: 6| Step: 11
Training loss: 1.495028018951416
Validation loss: 1.9875229795773823

Epoch: 6| Step: 12
Training loss: 1.9770398139953613
Validation loss: 1.9743326902389526

Epoch: 6| Step: 13
Training loss: 1.6868335008621216
Validation loss: 1.9681426684061687

Epoch: 50| Step: 0
Training loss: 1.2395884990692139
Validation loss: 1.9569195906321208

Epoch: 6| Step: 1
Training loss: 2.021254539489746
Validation loss: 1.9571239352226257

Epoch: 6| Step: 2
Training loss: 1.7218568325042725
Validation loss: 1.9310954610506694

Epoch: 6| Step: 3
Training loss: 1.6882706880569458
Validation loss: 1.9366128047307332

Epoch: 6| Step: 4
Training loss: 1.6246742010116577
Validation loss: 1.9441571434338887

Epoch: 6| Step: 5
Training loss: 2.140552043914795
Validation loss: 1.9511616230010986

Epoch: 6| Step: 6
Training loss: 1.7501347064971924
Validation loss: 1.947742760181427

Epoch: 6| Step: 7
Training loss: 2.50638484954834
Validation loss: 1.9542314012845357

Epoch: 6| Step: 8
Training loss: 1.7790687084197998
Validation loss: 1.9705674052238464

Epoch: 6| Step: 9
Training loss: 1.8620257377624512
Validation loss: 1.9777872959772747

Epoch: 6| Step: 10
Training loss: 1.771181583404541
Validation loss: 1.9765885869661968

Epoch: 6| Step: 11
Training loss: 2.0124568939208984
Validation loss: 1.9902549187342327

Epoch: 6| Step: 12
Training loss: 1.7002432346343994
Validation loss: 1.9864145517349243

Epoch: 6| Step: 13
Training loss: 1.793560266494751
Validation loss: 1.9860541621843975

Epoch: 51| Step: 0
Training loss: 1.6119539737701416
Validation loss: 1.9911800821622212

Epoch: 6| Step: 1
Training loss: 1.8512914180755615
Validation loss: 1.9854347507158916

Epoch: 6| Step: 2
Training loss: 1.6533195972442627
Validation loss: 1.9777293801307678

Epoch: 6| Step: 3
Training loss: 1.4795312881469727
Validation loss: 1.9665869275728862

Epoch: 6| Step: 4
Training loss: 1.9536181688308716
Validation loss: 1.9694489041964214

Epoch: 6| Step: 5
Training loss: 1.8770053386688232
Validation loss: 1.9678681095441182

Epoch: 6| Step: 6
Training loss: 2.3772900104522705
Validation loss: 1.9692219098409016

Epoch: 6| Step: 7
Training loss: 1.8841129541397095
Validation loss: 1.9583213527997334

Epoch: 6| Step: 8
Training loss: 1.9696009159088135
Validation loss: 1.9769038359324138

Epoch: 6| Step: 9
Training loss: 1.666664958000183
Validation loss: 1.9603267709414165

Epoch: 6| Step: 10
Training loss: 1.5841114521026611
Validation loss: 1.9486639499664307

Epoch: 6| Step: 11
Training loss: 2.474313735961914
Validation loss: 1.9621052344640095

Epoch: 6| Step: 12
Training loss: 1.487170934677124
Validation loss: 1.9712411562601726

Epoch: 6| Step: 13
Training loss: 1.5956840515136719
Validation loss: 1.9692479968070984

Epoch: 52| Step: 0
Training loss: 1.627026915550232
Validation loss: 1.9730455875396729

Epoch: 6| Step: 1
Training loss: 1.3464127779006958
Validation loss: 1.973566432793935

Epoch: 6| Step: 2
Training loss: 2.0561041831970215
Validation loss: 2.0032036503156028

Epoch: 6| Step: 3
Training loss: 1.648697018623352
Validation loss: 2.0031965573628745

Epoch: 6| Step: 4
Training loss: 2.1913113594055176
Validation loss: 2.008745769659678

Epoch: 6| Step: 5
Training loss: 1.3909547328948975
Validation loss: 1.9983492692311604

Epoch: 6| Step: 6
Training loss: 2.2078940868377686
Validation loss: 1.9870397448539734

Epoch: 6| Step: 7
Training loss: 1.5437328815460205
Validation loss: 1.9715167085329692

Epoch: 6| Step: 8
Training loss: 1.6840434074401855
Validation loss: 1.9814904530843098

Epoch: 6| Step: 9
Training loss: 2.586686611175537
Validation loss: 1.9619783560434978

Epoch: 6| Step: 10
Training loss: 2.0646274089813232
Validation loss: 1.9345898826917012

Epoch: 6| Step: 11
Training loss: 1.5967397689819336
Validation loss: 1.939122160275777

Epoch: 6| Step: 12
Training loss: 1.7393651008605957
Validation loss: 1.925917426745097

Epoch: 6| Step: 13
Training loss: 1.6250689029693604
Validation loss: 1.9579017162322998

Epoch: 53| Step: 0
Training loss: 1.7686249017715454
Validation loss: 1.9499417543411255

Epoch: 6| Step: 1
Training loss: 2.2570176124572754
Validation loss: 1.948449969291687

Epoch: 6| Step: 2
Training loss: 2.48111629486084
Validation loss: 1.9451432824134827

Epoch: 6| Step: 3
Training loss: 1.5653955936431885
Validation loss: 1.9766052961349487

Epoch: 6| Step: 4
Training loss: 1.1607630252838135
Validation loss: 1.9704329371452332

Epoch: 6| Step: 5
Training loss: 1.521681785583496
Validation loss: 2.0256980260213218

Epoch: 6| Step: 6
Training loss: 1.9342535734176636
Validation loss: 2.0270739595095315

Epoch: 6| Step: 7
Training loss: 2.04408597946167
Validation loss: 2.018949647744497

Epoch: 6| Step: 8
Training loss: 1.5864901542663574
Validation loss: 2.032678504784902

Epoch: 6| Step: 9
Training loss: 2.021791934967041
Validation loss: 2.0440330108006797

Epoch: 6| Step: 10
Training loss: 2.1312954425811768
Validation loss: 1.9967446525891621

Epoch: 6| Step: 11
Training loss: 1.8802359104156494
Validation loss: 1.9770138263702393

Epoch: 6| Step: 12
Training loss: 1.91031813621521
Validation loss: 1.9382665157318115

Epoch: 6| Step: 13
Training loss: 1.3088730573654175
Validation loss: 1.9543758630752563

Epoch: 54| Step: 0
Training loss: 1.8254677057266235
Validation loss: 1.9276830156644185

Epoch: 6| Step: 1
Training loss: 1.9730452299118042
Validation loss: 1.928167422612508

Epoch: 6| Step: 2
Training loss: 2.279510974884033
Validation loss: 1.9446582992871602

Epoch: 6| Step: 3
Training loss: 1.1700831651687622
Validation loss: 1.9491344491640727

Epoch: 6| Step: 4
Training loss: 1.9978291988372803
Validation loss: 1.965152124563853

Epoch: 6| Step: 5
Training loss: 2.174607276916504
Validation loss: 1.960994044939677

Epoch: 6| Step: 6
Training loss: 1.7584702968597412
Validation loss: 1.952199121316274

Epoch: 6| Step: 7
Training loss: 2.3527841567993164
Validation loss: 1.9456250071525574

Epoch: 6| Step: 8
Training loss: 2.0955100059509277
Validation loss: 1.931151807308197

Epoch: 6| Step: 9
Training loss: 1.5713309049606323
Validation loss: 1.9298047224680583

Epoch: 6| Step: 10
Training loss: 1.9988409280776978
Validation loss: 1.9365785717964172

Epoch: 6| Step: 11
Training loss: 1.8454060554504395
Validation loss: 1.9692393938700359

Epoch: 6| Step: 12
Training loss: 1.7086036205291748
Validation loss: 1.9939743280410767

Epoch: 6| Step: 13
Training loss: 1.2033783197402954
Validation loss: 2.025162080923716

Epoch: 55| Step: 0
Training loss: 1.4013988971710205
Validation loss: 2.0201563437779746

Epoch: 6| Step: 1
Training loss: 2.6526825428009033
Validation loss: 2.0175219575564065

Epoch: 6| Step: 2
Training loss: 1.9905644655227661
Validation loss: 2.021948496500651

Epoch: 6| Step: 3
Training loss: 1.7548048496246338
Validation loss: 2.006543755531311

Epoch: 6| Step: 4
Training loss: 1.903609275817871
Validation loss: 1.9960728287696838

Epoch: 6| Step: 5
Training loss: 1.8993507623672485
Validation loss: 1.9856501817703247

Epoch: 6| Step: 6
Training loss: 1.6460603475570679
Validation loss: 1.9962670008341472

Epoch: 6| Step: 7
Training loss: 1.6649916172027588
Validation loss: 1.9831137458483379

Epoch: 6| Step: 8
Training loss: 1.8286359310150146
Validation loss: 1.980299711227417

Epoch: 6| Step: 9
Training loss: 1.6354222297668457
Validation loss: 1.9603634874025981

Epoch: 6| Step: 10
Training loss: 1.430362582206726
Validation loss: 1.9532140890757244

Epoch: 6| Step: 11
Training loss: 2.5340964794158936
Validation loss: 1.949256459871928

Epoch: 6| Step: 12
Training loss: 1.1410044431686401
Validation loss: 1.9443190693855286

Epoch: 6| Step: 13
Training loss: 1.5150671005249023
Validation loss: 1.9454287588596344

Epoch: 56| Step: 0
Training loss: 1.7444002628326416
Validation loss: 1.9537104964256287

Epoch: 6| Step: 1
Training loss: 1.6726908683776855
Validation loss: 1.940385679403941

Epoch: 6| Step: 2
Training loss: 2.103255271911621
Validation loss: 1.9585330088933308

Epoch: 6| Step: 3
Training loss: 1.504989504814148
Validation loss: 1.9426522254943848

Epoch: 6| Step: 4
Training loss: 1.4131629467010498
Validation loss: 1.9622697631518047

Epoch: 6| Step: 5
Training loss: 1.6728512048721313
Validation loss: 1.9537549416224163

Epoch: 6| Step: 6
Training loss: 1.9936137199401855
Validation loss: 1.9791897336641948

Epoch: 6| Step: 7
Training loss: 1.683107852935791
Validation loss: 1.9663365483283997

Epoch: 6| Step: 8
Training loss: 1.0764343738555908
Validation loss: 1.9857106606165569

Epoch: 6| Step: 9
Training loss: 1.6775699853897095
Validation loss: 1.9812347491582234

Epoch: 6| Step: 10
Training loss: 1.752443552017212
Validation loss: 2.0194562872250876

Epoch: 6| Step: 11
Training loss: 1.988915205001831
Validation loss: 2.0194422801335654

Epoch: 6| Step: 12
Training loss: 2.4252495765686035
Validation loss: 2.01714297135671

Epoch: 6| Step: 13
Training loss: 2.168120861053467
Validation loss: 2.0250647266705832

Epoch: 57| Step: 0
Training loss: 1.4946978092193604
Validation loss: 2.024886687596639

Epoch: 6| Step: 1
Training loss: 1.2288620471954346
Validation loss: 1.99624898036321

Epoch: 6| Step: 2
Training loss: 1.3169527053833008
Validation loss: 1.9938068588574727

Epoch: 6| Step: 3
Training loss: 1.6347254514694214
Validation loss: 1.971391240755717

Epoch: 6| Step: 4
Training loss: 1.9231823682785034
Validation loss: 1.9670238097508748

Epoch: 6| Step: 5
Training loss: 2.158090114593506
Validation loss: 1.9745886127154033

Epoch: 6| Step: 6
Training loss: 1.5260931253433228
Validation loss: 1.953760027885437

Epoch: 6| Step: 7
Training loss: 1.608396291732788
Validation loss: 1.951834460099538

Epoch: 6| Step: 8
Training loss: 2.0963709354400635
Validation loss: 1.9385397632916768

Epoch: 6| Step: 9
Training loss: 1.8690218925476074
Validation loss: 1.94533375898997

Epoch: 6| Step: 10
Training loss: 1.6080139875411987
Validation loss: 1.9245538314183552

Epoch: 6| Step: 11
Training loss: 1.9927523136138916
Validation loss: 1.9338574210802715

Epoch: 6| Step: 12
Training loss: 2.659757614135742
Validation loss: 1.9484410881996155

Epoch: 6| Step: 13
Training loss: 1.6081655025482178
Validation loss: 1.9475991328557332

Epoch: 58| Step: 0
Training loss: 2.0676984786987305
Validation loss: 1.965215305487315

Epoch: 6| Step: 1
Training loss: 1.765869140625
Validation loss: 1.9897601803143818

Epoch: 6| Step: 2
Training loss: 1.570713758468628
Validation loss: 1.9697524110476177

Epoch: 6| Step: 3
Training loss: 2.013503074645996
Validation loss: 1.9869366884231567

Epoch: 6| Step: 4
Training loss: 1.7302254438400269
Validation loss: 1.9916733900705974

Epoch: 6| Step: 5
Training loss: 1.4148963689804077
Validation loss: 1.9831811587015789

Epoch: 6| Step: 6
Training loss: 1.641321063041687
Validation loss: 1.9688891967137654

Epoch: 6| Step: 7
Training loss: 2.275625467300415
Validation loss: 1.960271914800008

Epoch: 6| Step: 8
Training loss: 1.2681652307510376
Validation loss: 1.9761643012364705

Epoch: 6| Step: 9
Training loss: 1.940693974494934
Validation loss: 1.964775562286377

Epoch: 6| Step: 10
Training loss: 1.687448501586914
Validation loss: 1.9492500027020772

Epoch: 6| Step: 11
Training loss: 1.950272798538208
Validation loss: 1.9650830030441284

Epoch: 6| Step: 12
Training loss: 1.5404707193374634
Validation loss: 1.9584123293558757

Epoch: 6| Step: 13
Training loss: 1.7149862051010132
Validation loss: 1.9593997597694397

Epoch: 59| Step: 0
Training loss: 2.249772787094116
Validation loss: 1.9542953372001648

Epoch: 6| Step: 1
Training loss: 1.6969716548919678
Validation loss: 1.9711876114209492

Epoch: 6| Step: 2
Training loss: 1.481755018234253
Validation loss: 1.9547876318295796

Epoch: 6| Step: 3
Training loss: 1.1062757968902588
Validation loss: 1.9574252565701802

Epoch: 6| Step: 4
Training loss: 1.5917848348617554
Validation loss: 1.9465349117914836

Epoch: 6| Step: 5
Training loss: 1.3802448511123657
Validation loss: 1.971183756987254

Epoch: 6| Step: 6
Training loss: 2.104259490966797
Validation loss: 1.97229665517807

Epoch: 6| Step: 7
Training loss: 1.9726721048355103
Validation loss: 2.0053613980611167

Epoch: 6| Step: 8
Training loss: 1.5314908027648926
Validation loss: 1.9999498128890991

Epoch: 6| Step: 9
Training loss: 1.2405073642730713
Validation loss: 2.0183091958363852

Epoch: 6| Step: 10
Training loss: 2.11445951461792
Validation loss: 1.9969454209009807

Epoch: 6| Step: 11
Training loss: 1.8065358400344849
Validation loss: 1.9965799649556477

Epoch: 6| Step: 12
Training loss: 2.2077975273132324
Validation loss: 1.993647853533427

Epoch: 6| Step: 13
Training loss: 2.149463653564453
Validation loss: 2.010636826356252

Epoch: 60| Step: 0
Training loss: 1.4021981954574585
Validation loss: 1.9986989498138428

Epoch: 6| Step: 1
Training loss: 1.7912088632583618
Validation loss: 1.9865957101186116

Epoch: 6| Step: 2
Training loss: 1.596579909324646
Validation loss: 1.9599863092104595

Epoch: 6| Step: 3
Training loss: 1.9836190938949585
Validation loss: 1.9449541171391804

Epoch: 6| Step: 4
Training loss: 1.8307384252548218
Validation loss: 1.9483277599016826

Epoch: 6| Step: 5
Training loss: 1.4858287572860718
Validation loss: 1.9280193448066711

Epoch: 6| Step: 6
Training loss: 1.7333474159240723
Validation loss: 1.935396413008372

Epoch: 6| Step: 7
Training loss: 1.5131677389144897
Validation loss: 1.941559871037801

Epoch: 6| Step: 8
Training loss: 1.642455816268921
Validation loss: 1.9467543562253316

Epoch: 6| Step: 9
Training loss: 1.2549655437469482
Validation loss: 1.9449214935302734

Epoch: 6| Step: 10
Training loss: 2.486049175262451
Validation loss: 1.9500890175501506

Epoch: 6| Step: 11
Training loss: 2.2491683959960938
Validation loss: 1.9613361756006877

Epoch: 6| Step: 12
Training loss: 2.020761489868164
Validation loss: 1.972624957561493

Epoch: 6| Step: 13
Training loss: 1.6087665557861328
Validation loss: 1.969675858815511

Epoch: 61| Step: 0
Training loss: 2.086085319519043
Validation loss: 1.973408838113149

Epoch: 6| Step: 1
Training loss: 1.7708371877670288
Validation loss: 1.9963566263516743

Epoch: 6| Step: 2
Training loss: 2.210818290710449
Validation loss: 2.0054494539896646

Epoch: 6| Step: 3
Training loss: 1.6991921663284302
Validation loss: 1.9714921712875366

Epoch: 6| Step: 4
Training loss: 1.8917776346206665
Validation loss: 2.00626140832901

Epoch: 6| Step: 5
Training loss: 1.423231840133667
Validation loss: 2.0124098658561707

Epoch: 6| Step: 6
Training loss: 2.481109142303467
Validation loss: 2.014467418193817

Epoch: 6| Step: 7
Training loss: 0.792729914188385
Validation loss: 1.9856669505437214

Epoch: 6| Step: 8
Training loss: 1.520554780960083
Validation loss: 1.9675071438153584

Epoch: 6| Step: 9
Training loss: 1.425026535987854
Validation loss: 1.9553335309028625

Epoch: 6| Step: 10
Training loss: 1.9142780303955078
Validation loss: 1.9393857717514038

Epoch: 6| Step: 11
Training loss: 1.6155492067337036
Validation loss: 1.944668451944987

Epoch: 6| Step: 12
Training loss: 2.200995683670044
Validation loss: 1.9557339946428935

Epoch: 6| Step: 13
Training loss: 1.433438777923584
Validation loss: 1.9283225138982136

Epoch: 62| Step: 0
Training loss: 1.7583098411560059
Validation loss: 1.9417487978935242

Epoch: 6| Step: 1
Training loss: 2.10243558883667
Validation loss: 1.9564638137817383

Epoch: 6| Step: 2
Training loss: 1.855013132095337
Validation loss: 1.9499027927716572

Epoch: 6| Step: 3
Training loss: 1.9044075012207031
Validation loss: 1.97556738058726

Epoch: 6| Step: 4
Training loss: 1.2125483751296997
Validation loss: 1.9957231283187866

Epoch: 6| Step: 5
Training loss: 2.2777462005615234
Validation loss: 2.0297451615333557

Epoch: 6| Step: 6
Training loss: 1.0615419149398804
Validation loss: 2.0437330106894174

Epoch: 6| Step: 7
Training loss: 1.4931824207305908
Validation loss: 2.0310178995132446

Epoch: 6| Step: 8
Training loss: 1.8184304237365723
Validation loss: 2.040836056073507

Epoch: 6| Step: 9
Training loss: 2.277175188064575
Validation loss: 2.013098895549774

Epoch: 6| Step: 10
Training loss: 1.846039056777954
Validation loss: 2.000866154829661

Epoch: 6| Step: 11
Training loss: 2.0166163444519043
Validation loss: 1.978939712047577

Epoch: 6| Step: 12
Training loss: 1.183587670326233
Validation loss: 1.9718737999598186

Epoch: 6| Step: 13
Training loss: 1.7501511573791504
Validation loss: 1.9656377633412678

Epoch: 63| Step: 0
Training loss: 1.8015239238739014
Validation loss: 1.9230552117029827

Epoch: 6| Step: 1
Training loss: 2.1060070991516113
Validation loss: 1.944335808356603

Epoch: 6| Step: 2
Training loss: 2.055490732192993
Validation loss: 1.945249358812968

Epoch: 6| Step: 3
Training loss: 1.2484970092773438
Validation loss: 1.927349289258321

Epoch: 6| Step: 4
Training loss: 1.5403108596801758
Validation loss: 1.9386087656021118

Epoch: 6| Step: 5
Training loss: 1.6446442604064941
Validation loss: 1.9264192978541057

Epoch: 6| Step: 6
Training loss: 1.6891698837280273
Validation loss: 1.93498029311498

Epoch: 6| Step: 7
Training loss: 1.6280097961425781
Validation loss: 1.958587924639384

Epoch: 6| Step: 8
Training loss: 1.5243369340896606
Validation loss: 1.9557015299797058

Epoch: 6| Step: 9
Training loss: 1.6948357820510864
Validation loss: 1.9729209343592327

Epoch: 6| Step: 10
Training loss: 2.3907411098480225
Validation loss: 2.0038514137268066

Epoch: 6| Step: 11
Training loss: 1.8520673513412476
Validation loss: 2.0204047362009683

Epoch: 6| Step: 12
Training loss: 1.805861473083496
Validation loss: 2.0209676027297974

Epoch: 6| Step: 13
Training loss: 1.4220668077468872
Validation loss: 2.0506686170895896

Epoch: 64| Step: 0
Training loss: 1.164050817489624
Validation loss: 2.007258156935374

Epoch: 6| Step: 1
Training loss: 1.8242007493972778
Validation loss: 2.0000159740448

Epoch: 6| Step: 2
Training loss: 1.5564138889312744
Validation loss: 1.9774102767308552

Epoch: 6| Step: 3
Training loss: 1.4202767610549927
Validation loss: 1.9643551508585613

Epoch: 6| Step: 4
Training loss: 2.3635199069976807
Validation loss: 1.9571934342384338

Epoch: 6| Step: 5
Training loss: 1.6616706848144531
Validation loss: 1.9432836572329204

Epoch: 6| Step: 6
Training loss: 2.3737759590148926
Validation loss: 1.9642541607220967

Epoch: 6| Step: 7
Training loss: 1.9519195556640625
Validation loss: 1.9554803570111592

Epoch: 6| Step: 8
Training loss: 2.1315650939941406
Validation loss: 1.9682610034942627

Epoch: 6| Step: 9
Training loss: 1.5891201496124268
Validation loss: 1.954255998134613

Epoch: 6| Step: 10
Training loss: 1.2844676971435547
Validation loss: 1.9512653350830078

Epoch: 6| Step: 11
Training loss: 1.1354801654815674
Validation loss: 1.9615183472633362

Epoch: 6| Step: 12
Training loss: 1.4826898574829102
Validation loss: 1.9867339332898457

Epoch: 6| Step: 13
Training loss: 2.110595226287842
Validation loss: 1.9852508306503296

Epoch: 65| Step: 0
Training loss: 1.7497644424438477
Validation loss: 1.99937907854716

Epoch: 6| Step: 1
Training loss: 1.5044212341308594
Validation loss: 2.016904095808665

Epoch: 6| Step: 2
Training loss: 1.2670272588729858
Validation loss: 2.020813544591268

Epoch: 6| Step: 3
Training loss: 1.3476964235305786
Validation loss: 2.025054693222046

Epoch: 6| Step: 4
Training loss: 1.5672881603240967
Validation loss: 2.0054030219713845

Epoch: 6| Step: 5
Training loss: 1.7329461574554443
Validation loss: 2.0256811380386353

Epoch: 6| Step: 6
Training loss: 2.0049188137054443
Validation loss: 2.0004497369130454

Epoch: 6| Step: 7
Training loss: 1.306199073791504
Validation loss: 1.988252580165863

Epoch: 6| Step: 8
Training loss: 1.5607531070709229
Validation loss: 2.0126821597417197

Epoch: 6| Step: 9
Training loss: 2.119230270385742
Validation loss: 1.9915294249852498

Epoch: 6| Step: 10
Training loss: 1.583672285079956
Validation loss: 1.9970125158627827

Epoch: 6| Step: 11
Training loss: 2.2366766929626465
Validation loss: 1.9843553304672241

Epoch: 6| Step: 12
Training loss: 1.9260406494140625
Validation loss: 1.9510168830553691

Epoch: 6| Step: 13
Training loss: 1.8376795053482056
Validation loss: 1.9561989108721416

Epoch: 66| Step: 0
Training loss: 1.6666663885116577
Validation loss: 1.9449772040049236

Epoch: 6| Step: 1
Training loss: 1.4725252389907837
Validation loss: 1.953214426835378

Epoch: 6| Step: 2
Training loss: 1.421010971069336
Validation loss: 1.9648439089457195

Epoch: 6| Step: 3
Training loss: 1.728520154953003
Validation loss: 1.956508954366048

Epoch: 6| Step: 4
Training loss: 1.7968080043792725
Validation loss: 1.948249638080597

Epoch: 6| Step: 5
Training loss: 2.100393533706665
Validation loss: 1.958181917667389

Epoch: 6| Step: 6
Training loss: 1.854088544845581
Validation loss: 1.976653774579366

Epoch: 6| Step: 7
Training loss: 1.2161672115325928
Validation loss: 1.9511492848396301

Epoch: 6| Step: 8
Training loss: 1.5303187370300293
Validation loss: 1.9580846428871155

Epoch: 6| Step: 9
Training loss: 1.695846676826477
Validation loss: 1.9848225514094036

Epoch: 6| Step: 10
Training loss: 1.617304801940918
Validation loss: 1.9619885683059692

Epoch: 6| Step: 11
Training loss: 2.7285449504852295
Validation loss: 2.0043628017107644

Epoch: 6| Step: 12
Training loss: 1.509310007095337
Validation loss: 2.032353401184082

Epoch: 6| Step: 13
Training loss: 1.5042914152145386
Validation loss: 2.0023019909858704

Epoch: 67| Step: 0
Training loss: 1.2537895441055298
Validation loss: 1.9814216097195942

Epoch: 6| Step: 1
Training loss: 1.1982686519622803
Validation loss: 1.9702564279238384

Epoch: 6| Step: 2
Training loss: 1.3945083618164062
Validation loss: 1.9710037310918171

Epoch: 6| Step: 3
Training loss: 1.4329264163970947
Validation loss: 1.9729803601900737

Epoch: 6| Step: 4
Training loss: 2.2648215293884277
Validation loss: 1.941254695256551

Epoch: 6| Step: 5
Training loss: 2.0660171508789062
Validation loss: 1.950897753238678

Epoch: 6| Step: 6
Training loss: 1.4730191230773926
Validation loss: 1.9400888085365295

Epoch: 6| Step: 7
Training loss: 1.9057092666625977
Validation loss: 1.956784963607788

Epoch: 6| Step: 8
Training loss: 1.5240700244903564
Validation loss: 1.9415287574132283

Epoch: 6| Step: 9
Training loss: 1.9724256992340088
Validation loss: 1.940842827161153

Epoch: 6| Step: 10
Training loss: 1.8286375999450684
Validation loss: 1.9836994806925456

Epoch: 6| Step: 11
Training loss: 1.5058116912841797
Validation loss: 1.999513288338979

Epoch: 6| Step: 12
Training loss: 2.2898685932159424
Validation loss: 2.012604812781016

Epoch: 6| Step: 13
Training loss: 1.2915019989013672
Validation loss: 2.0174074371655784

Epoch: 68| Step: 0
Training loss: 1.5263278484344482
Validation loss: 2.0136269529660544

Epoch: 6| Step: 1
Training loss: 1.5729869604110718
Validation loss: 1.9876487453778584

Epoch: 6| Step: 2
Training loss: 2.719346046447754
Validation loss: 1.9935288230578105

Epoch: 6| Step: 3
Training loss: 1.2173256874084473
Validation loss: 1.975419044494629

Epoch: 6| Step: 4
Training loss: 1.6315531730651855
Validation loss: 1.9707137743632

Epoch: 6| Step: 5
Training loss: 1.9276314973831177
Validation loss: 1.9613818128903706

Epoch: 6| Step: 6
Training loss: 1.0948306322097778
Validation loss: 1.9664096236228943

Epoch: 6| Step: 7
Training loss: 1.9079382419586182
Validation loss: 1.961760143438975

Epoch: 6| Step: 8
Training loss: 1.6198467016220093
Validation loss: 1.9623459974924724

Epoch: 6| Step: 9
Training loss: 1.5188713073730469
Validation loss: 1.9860973954200745

Epoch: 6| Step: 10
Training loss: 1.857511043548584
Validation loss: 1.9583661556243896

Epoch: 6| Step: 11
Training loss: 1.6353237628936768
Validation loss: 1.9578171769777934

Epoch: 6| Step: 12
Training loss: 1.5036078691482544
Validation loss: 1.9535332918167114

Epoch: 6| Step: 13
Training loss: 1.452383279800415
Validation loss: 1.9781603813171387

Epoch: 69| Step: 0
Training loss: 1.9694808721542358
Validation loss: 1.9425767461458843

Epoch: 6| Step: 1
Training loss: 1.8447856903076172
Validation loss: 1.9544100364049275

Epoch: 6| Step: 2
Training loss: 2.0110526084899902
Validation loss: 1.9767675995826721

Epoch: 6| Step: 3
Training loss: 1.8678501844406128
Validation loss: 1.985432465871175

Epoch: 6| Step: 4
Training loss: 1.4210915565490723
Validation loss: 1.9884731769561768

Epoch: 6| Step: 5
Training loss: 1.753453254699707
Validation loss: 1.992881993452708

Epoch: 6| Step: 6
Training loss: 2.1301257610321045
Validation loss: 1.9904691775639851

Epoch: 6| Step: 7
Training loss: 1.6082072257995605
Validation loss: 1.9821287790934246

Epoch: 6| Step: 8
Training loss: 1.223246455192566
Validation loss: 1.9707562526067097

Epoch: 6| Step: 9
Training loss: 1.5527048110961914
Validation loss: 1.9848126967748005

Epoch: 6| Step: 10
Training loss: 1.3304193019866943
Validation loss: 1.9903768102327983

Epoch: 6| Step: 11
Training loss: 1.2344491481781006
Validation loss: 1.9829794367154439

Epoch: 6| Step: 12
Training loss: 1.131866216659546
Validation loss: 1.978939910729726

Epoch: 6| Step: 13
Training loss: 1.945629596710205
Validation loss: 1.9719386299451191

Epoch: 70| Step: 0
Training loss: 1.809543490409851
Validation loss: 1.9881696899731953

Epoch: 6| Step: 1
Training loss: 1.555285096168518
Validation loss: 1.9722670118014018

Epoch: 6| Step: 2
Training loss: 1.8019020557403564
Validation loss: 1.9883238673210144

Epoch: 6| Step: 3
Training loss: 1.322725772857666
Validation loss: 1.9801591436068218

Epoch: 6| Step: 4
Training loss: 1.9714163541793823
Validation loss: 1.9824622869491577

Epoch: 6| Step: 5
Training loss: 1.3642148971557617
Validation loss: 1.9820300738016765

Epoch: 6| Step: 6
Training loss: 1.562516689300537
Validation loss: 1.968017041683197

Epoch: 6| Step: 7
Training loss: 1.4237792491912842
Validation loss: 1.965448260307312

Epoch: 6| Step: 8
Training loss: 2.357800006866455
Validation loss: 1.9449611902236938

Epoch: 6| Step: 9
Training loss: 1.8904201984405518
Validation loss: 1.9331905643145244

Epoch: 6| Step: 10
Training loss: 1.0035713911056519
Validation loss: 1.934016505877177

Epoch: 6| Step: 11
Training loss: 1.6848465204238892
Validation loss: 1.9524686932563782

Epoch: 6| Step: 12
Training loss: 1.5172510147094727
Validation loss: 1.9503365556399028

Epoch: 6| Step: 13
Training loss: 1.5182141065597534
Validation loss: 1.9427653749783833

Epoch: 71| Step: 0
Training loss: 1.4525644779205322
Validation loss: 1.9856102069218953

Epoch: 6| Step: 1
Training loss: 2.1350622177124023
Validation loss: 2.01103142897288

Epoch: 6| Step: 2
Training loss: 1.809312105178833
Validation loss: 2.0474820137023926

Epoch: 6| Step: 3
Training loss: 1.8554596900939941
Validation loss: 2.0404659112294516

Epoch: 6| Step: 4
Training loss: 1.6068189144134521
Validation loss: 2.0197826822598777

Epoch: 6| Step: 5
Training loss: 1.0834860801696777
Validation loss: 1.951838235060374

Epoch: 6| Step: 6
Training loss: 1.7955536842346191
Validation loss: 1.9361244241396587

Epoch: 6| Step: 7
Training loss: 1.315122127532959
Validation loss: 1.9475922584533691

Epoch: 6| Step: 8
Training loss: 1.4709725379943848
Validation loss: 1.9168084859848022

Epoch: 6| Step: 9
Training loss: 1.7816005945205688
Validation loss: 1.9427531162897747

Epoch: 6| Step: 10
Training loss: 1.9000505208969116
Validation loss: 1.9731903274854024

Epoch: 6| Step: 11
Training loss: 2.016273021697998
Validation loss: 1.9606863061587017

Epoch: 6| Step: 12
Training loss: 1.6210294961929321
Validation loss: 1.951782723267873

Epoch: 6| Step: 13
Training loss: 1.197246789932251
Validation loss: 1.9675564368565877

Epoch: 72| Step: 0
Training loss: 1.5054502487182617
Validation loss: 1.9810951153437297

Epoch: 6| Step: 1
Training loss: 1.477921724319458
Validation loss: 1.97333562374115

Epoch: 6| Step: 2
Training loss: 2.281808853149414
Validation loss: 1.996638576189677

Epoch: 6| Step: 3
Training loss: 1.2275924682617188
Validation loss: 2.0006717443466187

Epoch: 6| Step: 4
Training loss: 1.410768985748291
Validation loss: 1.9935338695844014

Epoch: 6| Step: 5
Training loss: 2.0746288299560547
Validation loss: 2.0113415519396463

Epoch: 6| Step: 6
Training loss: 1.2792696952819824
Validation loss: 1.9845682978630066

Epoch: 6| Step: 7
Training loss: 2.1025209426879883
Validation loss: 1.9869288802146912

Epoch: 6| Step: 8
Training loss: 1.7274681329727173
Validation loss: 1.9481522639592488

Epoch: 6| Step: 9
Training loss: 1.5878820419311523
Validation loss: 1.9598645567893982

Epoch: 6| Step: 10
Training loss: 1.5999116897583008
Validation loss: 1.931739052136739

Epoch: 6| Step: 11
Training loss: 0.889817476272583
Validation loss: 1.9591651956240337

Epoch: 6| Step: 12
Training loss: 1.687945008277893
Validation loss: 1.9691316882769268

Epoch: 6| Step: 13
Training loss: 1.8611531257629395
Validation loss: 1.990895668665568

Epoch: 73| Step: 0
Training loss: 1.4223265647888184
Validation loss: 2.0047705372174582

Epoch: 6| Step: 1
Training loss: 2.1362035274505615
Validation loss: 2.0293543537457785

Epoch: 6| Step: 2
Training loss: 1.6784669160842896
Validation loss: 2.100428660710653

Epoch: 6| Step: 3
Training loss: 1.7161287069320679
Validation loss: 2.1164005597432456

Epoch: 6| Step: 4
Training loss: 1.5284168720245361
Validation loss: 2.1247071425120034

Epoch: 6| Step: 5
Training loss: 2.3387608528137207
Validation loss: 2.0926996072133384

Epoch: 6| Step: 6
Training loss: 1.746854543685913
Validation loss: 2.06569641828537

Epoch: 6| Step: 7
Training loss: 1.7592817544937134
Validation loss: 2.0300512115160623

Epoch: 6| Step: 8
Training loss: 1.5832021236419678
Validation loss: 1.9690363605817158

Epoch: 6| Step: 9
Training loss: 1.738959550857544
Validation loss: 1.9490958452224731

Epoch: 6| Step: 10
Training loss: 1.525571346282959
Validation loss: 1.9610757033030193

Epoch: 6| Step: 11
Training loss: 1.231612205505371
Validation loss: 1.9330366055170696

Epoch: 6| Step: 12
Training loss: 0.9888684749603271
Validation loss: 1.914509157339732

Epoch: 6| Step: 13
Training loss: 1.8545305728912354
Validation loss: 1.9491140047709148

Epoch: 74| Step: 0
Training loss: 1.5626270771026611
Validation loss: 1.9388894041379292

Epoch: 6| Step: 1
Training loss: 1.8266804218292236
Validation loss: 1.9710773626963298

Epoch: 6| Step: 2
Training loss: 1.5314662456512451
Validation loss: 1.9378018577893574

Epoch: 6| Step: 3
Training loss: 1.7897330522537231
Validation loss: 1.9491437474886577

Epoch: 6| Step: 4
Training loss: 1.4748308658599854
Validation loss: 1.9695090651512146

Epoch: 6| Step: 5
Training loss: 1.6968739032745361
Validation loss: 1.967714528242747

Epoch: 6| Step: 6
Training loss: 1.4968961477279663
Validation loss: 1.9898379842440288

Epoch: 6| Step: 7
Training loss: 1.0258455276489258
Validation loss: 2.017549455165863

Epoch: 6| Step: 8
Training loss: 1.0750503540039062
Validation loss: 2.009329299132029

Epoch: 6| Step: 9
Training loss: 1.4288114309310913
Validation loss: 2.038870374361674

Epoch: 6| Step: 10
Training loss: 2.104492664337158
Validation loss: 2.049559156099955

Epoch: 6| Step: 11
Training loss: 1.560796856880188
Validation loss: 2.055007596810659

Epoch: 6| Step: 12
Training loss: 2.222456455230713
Validation loss: 2.0576968789100647

Epoch: 6| Step: 13
Training loss: 1.3519010543823242
Validation loss: 2.041925092538198

Epoch: 75| Step: 0
Training loss: 0.8778383731842041
Validation loss: 2.039916435877482

Epoch: 6| Step: 1
Training loss: 1.7278571128845215
Validation loss: 2.0232223073641458

Epoch: 6| Step: 2
Training loss: 1.4768009185791016
Validation loss: 1.9943384726842244

Epoch: 6| Step: 3
Training loss: 1.9555904865264893
Validation loss: 1.9710907737414043

Epoch: 6| Step: 4
Training loss: 1.4230291843414307
Validation loss: 1.970719834168752

Epoch: 6| Step: 5
Training loss: 2.123633861541748
Validation loss: 1.9641042749087017

Epoch: 6| Step: 6
Training loss: 2.0657126903533936
Validation loss: 1.9429568847020466

Epoch: 6| Step: 7
Training loss: 1.8668079376220703
Validation loss: 1.9374028046925862

Epoch: 6| Step: 8
Training loss: 1.1482092142105103
Validation loss: 1.94967120885849

Epoch: 6| Step: 9
Training loss: 1.2242722511291504
Validation loss: 1.9465389649073284

Epoch: 6| Step: 10
Training loss: 1.5906431674957275
Validation loss: 1.955585519472758

Epoch: 6| Step: 11
Training loss: 1.5695374011993408
Validation loss: 1.96925284465154

Epoch: 6| Step: 12
Training loss: 1.8989408016204834
Validation loss: 2.0115180214246116

Epoch: 6| Step: 13
Training loss: 0.8959267139434814
Validation loss: 2.010549485683441

Epoch: 76| Step: 0
Training loss: 1.8521885871887207
Validation loss: 2.0238120555877686

Epoch: 6| Step: 1
Training loss: 1.8187363147735596
Validation loss: 2.045577605565389

Epoch: 6| Step: 2
Training loss: 1.2082977294921875
Validation loss: 2.0475316445032754

Epoch: 6| Step: 3
Training loss: 1.8179926872253418
Validation loss: 2.032525360584259

Epoch: 6| Step: 4
Training loss: 1.6448254585266113
Validation loss: 2.007869760195414

Epoch: 6| Step: 5
Training loss: 1.4322457313537598
Validation loss: 1.97755632797877

Epoch: 6| Step: 6
Training loss: 1.3439128398895264
Validation loss: 1.9541193048159282

Epoch: 6| Step: 7
Training loss: 1.142134428024292
Validation loss: 1.9756803512573242

Epoch: 6| Step: 8
Training loss: 1.667738914489746
Validation loss: 1.9876510699590046

Epoch: 6| Step: 9
Training loss: 1.2822329998016357
Validation loss: 1.9932266275087993

Epoch: 6| Step: 10
Training loss: 1.5710256099700928
Validation loss: 2.034571409225464

Epoch: 6| Step: 11
Training loss: 2.095611333847046
Validation loss: 2.061256011327108

Epoch: 6| Step: 12
Training loss: 1.438345193862915
Validation loss: 2.0478945771853128

Epoch: 6| Step: 13
Training loss: 2.000051259994507
Validation loss: 2.0366305708885193

Epoch: 77| Step: 0
Training loss: 2.0141232013702393
Validation loss: 2.0168673197428384

Epoch: 6| Step: 1
Training loss: 1.892114520072937
Validation loss: 1.9925712943077087

Epoch: 6| Step: 2
Training loss: 0.917001485824585
Validation loss: 1.951646129290263

Epoch: 6| Step: 3
Training loss: 1.5019108057022095
Validation loss: 1.951080898443858

Epoch: 6| Step: 4
Training loss: 1.6785626411437988
Validation loss: 1.922528823216756

Epoch: 6| Step: 5
Training loss: 1.5384643077850342
Validation loss: 1.9393905997276306

Epoch: 6| Step: 6
Training loss: 1.6553287506103516
Validation loss: 1.9359464248021443

Epoch: 6| Step: 7
Training loss: 1.655632495880127
Validation loss: 1.9566800196965535

Epoch: 6| Step: 8
Training loss: 1.0933146476745605
Validation loss: 1.948997954527537

Epoch: 6| Step: 9
Training loss: 1.618359088897705
Validation loss: 1.9603927334149678

Epoch: 6| Step: 10
Training loss: 1.9466023445129395
Validation loss: 1.9718284606933594

Epoch: 6| Step: 11
Training loss: 1.4194307327270508
Validation loss: 2.018188993136088

Epoch: 6| Step: 12
Training loss: 1.3571885824203491
Validation loss: 2.0362319151560464

Epoch: 6| Step: 13
Training loss: 1.0841172933578491
Validation loss: 2.0906419157981873

Epoch: 78| Step: 0
Training loss: 1.5697532892227173
Validation loss: 2.1068636178970337

Epoch: 6| Step: 1
Training loss: 1.2050827741622925
Validation loss: 2.110197126865387

Epoch: 6| Step: 2
Training loss: 1.1076785326004028
Validation loss: 2.065776824951172

Epoch: 6| Step: 3
Training loss: 1.7822221517562866
Validation loss: 2.0235335429509482

Epoch: 6| Step: 4
Training loss: 1.6355023384094238
Validation loss: 2.0116804440816245

Epoch: 6| Step: 5
Training loss: 1.5822739601135254
Validation loss: 1.9893804391225178

Epoch: 6| Step: 6
Training loss: 1.6264595985412598
Validation loss: 1.9500170350074768

Epoch: 6| Step: 7
Training loss: 1.2655924558639526
Validation loss: 1.9605416456858318

Epoch: 6| Step: 8
Training loss: 0.7917158603668213
Validation loss: 1.962678849697113

Epoch: 6| Step: 9
Training loss: 2.0653576850891113
Validation loss: 1.96083269516627

Epoch: 6| Step: 10
Training loss: 1.6985009908676147
Validation loss: 1.9439669450124104

Epoch: 6| Step: 11
Training loss: 1.481894612312317
Validation loss: 1.9688982367515564

Epoch: 6| Step: 12
Training loss: 1.5979561805725098
Validation loss: 1.9587051272392273

Epoch: 6| Step: 13
Training loss: 1.9040436744689941
Validation loss: 1.9783090154329936

Epoch: 79| Step: 0
Training loss: 1.0831339359283447
Validation loss: 1.9714692036310832

Epoch: 6| Step: 1
Training loss: 1.3817888498306274
Validation loss: 2.0065209666887918

Epoch: 6| Step: 2
Training loss: 1.8544962406158447
Validation loss: 2.01670249303182

Epoch: 6| Step: 3
Training loss: 1.3455110788345337
Validation loss: 2.0094124476114907

Epoch: 6| Step: 4
Training loss: 1.8933346271514893
Validation loss: 2.042465845743815

Epoch: 6| Step: 5
Training loss: 1.480993390083313
Validation loss: 2.057936191558838

Epoch: 6| Step: 6
Training loss: 1.582697868347168
Validation loss: 2.0249936978022256

Epoch: 6| Step: 7
Training loss: 1.9225058555603027
Validation loss: 2.019243081410726

Epoch: 6| Step: 8
Training loss: 1.5954887866973877
Validation loss: 2.041603763898214

Epoch: 6| Step: 9
Training loss: 1.4135255813598633
Validation loss: 2.0156602263450623

Epoch: 6| Step: 10
Training loss: 1.6862692832946777
Validation loss: 2.0079283118247986

Epoch: 6| Step: 11
Training loss: 1.102678894996643
Validation loss: 1.9812009533246357

Epoch: 6| Step: 12
Training loss: 1.2319632768630981
Validation loss: 1.9748378992080688

Epoch: 6| Step: 13
Training loss: 1.3746663331985474
Validation loss: 1.9383952021598816

Epoch: 80| Step: 0
Training loss: 1.4905500411987305
Validation loss: 1.948491136233012

Epoch: 6| Step: 1
Training loss: 1.8095676898956299
Validation loss: 1.9471366206804912

Epoch: 6| Step: 2
Training loss: 1.655468225479126
Validation loss: 1.9695855577786763

Epoch: 6| Step: 3
Training loss: 1.28004789352417
Validation loss: 1.9558191100756328

Epoch: 6| Step: 4
Training loss: 1.529820203781128
Validation loss: 1.9699743588765461

Epoch: 6| Step: 5
Training loss: 1.206597089767456
Validation loss: 2.0060731967290244

Epoch: 6| Step: 6
Training loss: 1.8876622915267944
Validation loss: 2.019399325052897

Epoch: 6| Step: 7
Training loss: 1.3711020946502686
Validation loss: 1.9981430967648823

Epoch: 6| Step: 8
Training loss: 2.048227310180664
Validation loss: 2.0276214480400085

Epoch: 6| Step: 9
Training loss: 1.1850190162658691
Validation loss: 2.0135065714518228

Epoch: 6| Step: 10
Training loss: 1.6289063692092896
Validation loss: 2.0324628154436746

Epoch: 6| Step: 11
Training loss: 1.080971360206604
Validation loss: 2.0269946257273355

Epoch: 6| Step: 12
Training loss: 1.19660484790802
Validation loss: 2.035489479700724

Epoch: 6| Step: 13
Training loss: 1.132571816444397
Validation loss: 1.9834278027216594

Epoch: 81| Step: 0
Training loss: 1.53778076171875
Validation loss: 1.999187966187795

Epoch: 6| Step: 1
Training loss: 1.634695053100586
Validation loss: 1.9953537980715434

Epoch: 6| Step: 2
Training loss: 1.4433952569961548
Validation loss: 1.9543954928716023

Epoch: 6| Step: 3
Training loss: 1.3255276679992676
Validation loss: 1.9449549317359924

Epoch: 6| Step: 4
Training loss: 1.5321968793869019
Validation loss: 1.9857641855875652

Epoch: 6| Step: 5
Training loss: 0.7984411120414734
Validation loss: 1.9876115123430889

Epoch: 6| Step: 6
Training loss: 1.202701449394226
Validation loss: 1.9846208095550537

Epoch: 6| Step: 7
Training loss: 1.798971176147461
Validation loss: 2.025229533513387

Epoch: 6| Step: 8
Training loss: 1.6574009656906128
Validation loss: 2.022729774316152

Epoch: 6| Step: 9
Training loss: 1.9569966793060303
Validation loss: 2.0167538126309714

Epoch: 6| Step: 10
Training loss: 1.166017770767212
Validation loss: 2.00257017215093

Epoch: 6| Step: 11
Training loss: 1.7022643089294434
Validation loss: 1.9770480195681255

Epoch: 6| Step: 12
Training loss: 1.4313604831695557
Validation loss: 2.010665476322174

Epoch: 6| Step: 13
Training loss: 1.6109771728515625
Validation loss: 1.9921342333157857

Epoch: 82| Step: 0
Training loss: 0.9684780836105347
Validation loss: 2.015353341897329

Epoch: 6| Step: 1
Training loss: 1.3112846612930298
Validation loss: 1.9923201600710552

Epoch: 6| Step: 2
Training loss: 1.821886658668518
Validation loss: 1.9655935764312744

Epoch: 6| Step: 3
Training loss: 1.3106598854064941
Validation loss: 1.948631723721822

Epoch: 6| Step: 4
Training loss: 1.7636264562606812
Validation loss: 1.9687756896018982

Epoch: 6| Step: 5
Training loss: 1.8155094385147095
Validation loss: 1.9783114592234294

Epoch: 6| Step: 6
Training loss: 1.526050329208374
Validation loss: 1.983051339785258

Epoch: 6| Step: 7
Training loss: 1.6269550323486328
Validation loss: 2.0021849075953164

Epoch: 6| Step: 8
Training loss: 1.6752638816833496
Validation loss: 2.038129727045695

Epoch: 6| Step: 9
Training loss: 1.2306674718856812
Validation loss: 2.1020649870236716

Epoch: 6| Step: 10
Training loss: 1.388597011566162
Validation loss: 2.1036686499913535

Epoch: 6| Step: 11
Training loss: 1.527627944946289
Validation loss: 2.0952476263046265

Epoch: 6| Step: 12
Training loss: 1.521075963973999
Validation loss: 2.0516619086265564

Epoch: 6| Step: 13
Training loss: 1.4528489112854004
Validation loss: 2.0054092605908713

Epoch: 83| Step: 0
Training loss: 1.1150153875350952
Validation loss: 1.969988465309143

Epoch: 6| Step: 1
Training loss: 1.727959394454956
Validation loss: 1.9255643884340923

Epoch: 6| Step: 2
Training loss: 1.209661841392517
Validation loss: 1.9482082724571228

Epoch: 6| Step: 3
Training loss: 1.3874536752700806
Validation loss: 1.9467011292775471

Epoch: 6| Step: 4
Training loss: 1.091659665107727
Validation loss: 1.9289505084355671

Epoch: 6| Step: 5
Training loss: 1.9732997417449951
Validation loss: 1.9381038546562195

Epoch: 6| Step: 6
Training loss: 1.490739107131958
Validation loss: 1.9902496933937073

Epoch: 6| Step: 7
Training loss: 1.2459133863449097
Validation loss: 2.0556981960932412

Epoch: 6| Step: 8
Training loss: 1.1513622999191284
Validation loss: 2.077042539914449

Epoch: 6| Step: 9
Training loss: 1.9793121814727783
Validation loss: 2.076831301053365

Epoch: 6| Step: 10
Training loss: 1.4255807399749756
Validation loss: 2.1251019636789956

Epoch: 6| Step: 11
Training loss: 1.3959827423095703
Validation loss: 2.0730173587799072

Epoch: 6| Step: 12
Training loss: 1.6274909973144531
Validation loss: 2.058303197224935

Epoch: 6| Step: 13
Training loss: 1.6720223426818848
Validation loss: 2.0438674489657083

Epoch: 84| Step: 0
Training loss: 1.0186779499053955
Validation loss: 2.0095983147621155

Epoch: 6| Step: 1
Training loss: 1.5672508478164673
Validation loss: 1.9708598454793294

Epoch: 6| Step: 2
Training loss: 1.6610932350158691
Validation loss: 1.9305028319358826

Epoch: 6| Step: 3
Training loss: 1.3242169618606567
Validation loss: 1.895780344804128

Epoch: 6| Step: 4
Training loss: 1.888453722000122
Validation loss: 1.919343113899231

Epoch: 6| Step: 5
Training loss: 1.5710604190826416
Validation loss: 1.9069491426150005

Epoch: 6| Step: 6
Training loss: 1.7464759349822998
Validation loss: 1.9480413993199666

Epoch: 6| Step: 7
Training loss: 1.7815141677856445
Validation loss: 1.91480153799057

Epoch: 6| Step: 8
Training loss: 1.5019705295562744
Validation loss: 1.9108329614003499

Epoch: 6| Step: 9
Training loss: 1.275399923324585
Validation loss: 1.9784849683443706

Epoch: 6| Step: 10
Training loss: 1.52815580368042
Validation loss: 2.025111516316732

Epoch: 6| Step: 11
Training loss: 1.6365007162094116
Validation loss: 2.108035445213318

Epoch: 6| Step: 12
Training loss: 1.6551127433776855
Validation loss: 2.1741798917452493

Epoch: 6| Step: 13
Training loss: 1.8361334800720215
Validation loss: 2.157116452852885

Epoch: 85| Step: 0
Training loss: 1.4412777423858643
Validation loss: 2.1903607845306396

Epoch: 6| Step: 1
Training loss: 1.4814422130584717
Validation loss: 2.154593348503113

Epoch: 6| Step: 2
Training loss: 1.5117499828338623
Validation loss: 2.116920312245687

Epoch: 6| Step: 3
Training loss: 1.2500128746032715
Validation loss: 2.0579360127449036

Epoch: 6| Step: 4
Training loss: 0.6527689099311829
Validation loss: 1.9955706199010212

Epoch: 6| Step: 5
Training loss: 1.7281553745269775
Validation loss: 1.9710075457890828

Epoch: 6| Step: 6
Training loss: 1.3216159343719482
Validation loss: 1.9450365702311199

Epoch: 6| Step: 7
Training loss: 1.9340965747833252
Validation loss: 1.9787715673446655

Epoch: 6| Step: 8
Training loss: 1.492241621017456
Validation loss: 1.9486260016759236

Epoch: 6| Step: 9
Training loss: 1.2113693952560425
Validation loss: 1.924597183863322

Epoch: 6| Step: 10
Training loss: 1.087308645248413
Validation loss: 1.9834829966227214

Epoch: 6| Step: 11
Training loss: 1.5255661010742188
Validation loss: 1.9693111578623455

Epoch: 6| Step: 12
Training loss: 2.2043263912200928
Validation loss: 1.9906028906504314

Epoch: 6| Step: 13
Training loss: 1.296621322631836
Validation loss: 1.9523506959279378

Epoch: 86| Step: 0
Training loss: 1.8916008472442627
Validation loss: 1.9803230166435242

Epoch: 6| Step: 1
Training loss: 1.3381644487380981
Validation loss: 1.9851257999738057

Epoch: 6| Step: 2
Training loss: 1.1302356719970703
Validation loss: 1.9546396732330322

Epoch: 6| Step: 3
Training loss: 1.4055027961730957
Validation loss: 2.0157392422358194

Epoch: 6| Step: 4
Training loss: 1.8066062927246094
Validation loss: 2.043534437815348

Epoch: 6| Step: 5
Training loss: 1.3263657093048096
Validation loss: 2.0316127936045327

Epoch: 6| Step: 6
Training loss: 1.6257786750793457
Validation loss: 2.0725953380266824

Epoch: 6| Step: 7
Training loss: 1.9143295288085938
Validation loss: 2.056441366672516

Epoch: 6| Step: 8
Training loss: 0.9229236245155334
Validation loss: 2.02983166774114

Epoch: 6| Step: 9
Training loss: 1.1626495122909546
Validation loss: 2.0178664127985635

Epoch: 6| Step: 10
Training loss: 1.3422718048095703
Validation loss: 1.982247253259023

Epoch: 6| Step: 11
Training loss: 1.1920404434204102
Validation loss: 1.9664063851038616

Epoch: 6| Step: 12
Training loss: 1.2546781301498413
Validation loss: 1.9440942009290059

Epoch: 6| Step: 13
Training loss: 1.2643775939941406
Validation loss: 1.9249967734018962

Epoch: 87| Step: 0
Training loss: 1.7366243600845337
Validation loss: 1.955621341864268

Epoch: 6| Step: 1
Training loss: 0.9151233434677124
Validation loss: 1.9817946751912434

Epoch: 6| Step: 2
Training loss: 1.3243634700775146
Validation loss: 1.9918268124262493

Epoch: 6| Step: 3
Training loss: 0.9722293615341187
Validation loss: 2.0561672846476235

Epoch: 6| Step: 4
Training loss: 1.4519950151443481
Validation loss: 2.0676878293355307

Epoch: 6| Step: 5
Training loss: 2.762338638305664
Validation loss: 2.067806522051493

Epoch: 6| Step: 6
Training loss: 1.1683034896850586
Validation loss: 2.0282904903093972

Epoch: 6| Step: 7
Training loss: 1.5990197658538818
Validation loss: 2.007839878400167

Epoch: 6| Step: 8
Training loss: 0.8082004189491272
Validation loss: 1.9885539412498474

Epoch: 6| Step: 9
Training loss: 1.6416906118392944
Validation loss: 1.9974505106608074

Epoch: 6| Step: 10
Training loss: 0.7334701418876648
Validation loss: 1.98616361618042

Epoch: 6| Step: 11
Training loss: 1.3133180141448975
Validation loss: 1.979548950990041

Epoch: 6| Step: 12
Training loss: 1.2651643753051758
Validation loss: 1.9709368546803792

Epoch: 6| Step: 13
Training loss: 1.522970199584961
Validation loss: 1.9716615875562031

Epoch: 88| Step: 0
Training loss: 1.64812171459198
Validation loss: 1.9894888401031494

Epoch: 6| Step: 1
Training loss: 0.9291450381278992
Validation loss: 2.032622992992401

Epoch: 6| Step: 2
Training loss: 1.4019469022750854
Validation loss: 2.0228748321533203

Epoch: 6| Step: 3
Training loss: 1.7626023292541504
Validation loss: 2.014038840929667

Epoch: 6| Step: 4
Training loss: 1.3888753652572632
Validation loss: 1.9613664944966633

Epoch: 6| Step: 5
Training loss: 1.1763497591018677
Validation loss: 1.992562731107076

Epoch: 6| Step: 6
Training loss: 1.1698920726776123
Validation loss: 2.002427081267039

Epoch: 6| Step: 7
Training loss: 1.2927937507629395
Validation loss: 1.9710739453633626

Epoch: 6| Step: 8
Training loss: 1.7220993041992188
Validation loss: 1.9616929690043132

Epoch: 6| Step: 9
Training loss: 1.4607547521591187
Validation loss: 1.9899340470631917

Epoch: 6| Step: 10
Training loss: 1.8335297107696533
Validation loss: 2.0007126530011496

Epoch: 6| Step: 11
Training loss: 0.8661222457885742
Validation loss: 1.9997929334640503

Epoch: 6| Step: 12
Training loss: 1.4859240055084229
Validation loss: 2.0617666045824685

Epoch: 6| Step: 13
Training loss: 0.6781971454620361
Validation loss: 2.0801098346710205

Epoch: 89| Step: 0
Training loss: 1.2192339897155762
Validation loss: 2.0382546186447144

Epoch: 6| Step: 1
Training loss: 1.3408315181732178
Validation loss: 2.0547358194986978

Epoch: 6| Step: 2
Training loss: 1.074590802192688
Validation loss: 2.0081907510757446

Epoch: 6| Step: 3
Training loss: 1.3480284214019775
Validation loss: 2.0134891470273337

Epoch: 6| Step: 4
Training loss: 0.783340334892273
Validation loss: 1.9601921439170837

Epoch: 6| Step: 5
Training loss: 1.400599718093872
Validation loss: 1.948780596256256

Epoch: 6| Step: 6
Training loss: 1.1753143072128296
Validation loss: 1.938528557618459

Epoch: 6| Step: 7
Training loss: 0.8401134014129639
Validation loss: 1.9671943585077922

Epoch: 6| Step: 8
Training loss: 1.8071112632751465
Validation loss: 1.952611267566681

Epoch: 6| Step: 9
Training loss: 1.8786768913269043
Validation loss: 1.9878053069114685

Epoch: 6| Step: 10
Training loss: 1.2332422733306885
Validation loss: 2.0214261213938394

Epoch: 6| Step: 11
Training loss: 2.1186957359313965
Validation loss: 1.9801458517710369

Epoch: 6| Step: 12
Training loss: 1.4280223846435547
Validation loss: 2.024291376272837

Epoch: 6| Step: 13
Training loss: 1.103043794631958
Validation loss: 2.01417867342631

Epoch: 90| Step: 0
Training loss: 1.5465360879898071
Validation loss: 2.0261674324671426

Epoch: 6| Step: 1
Training loss: 1.381773591041565
Validation loss: 2.0428839325904846

Epoch: 6| Step: 2
Training loss: 0.8574342131614685
Validation loss: 2.059473236401876

Epoch: 6| Step: 3
Training loss: 1.5915790796279907
Validation loss: 1.974747399489085

Epoch: 6| Step: 4
Training loss: 0.8482459783554077
Validation loss: 1.9782376686731975

Epoch: 6| Step: 5
Training loss: 1.3564363718032837
Validation loss: 1.9550410310427349

Epoch: 6| Step: 6
Training loss: 1.5140076875686646
Validation loss: 1.986316164334615

Epoch: 6| Step: 7
Training loss: 1.1788675785064697
Validation loss: 1.9753527442614238

Epoch: 6| Step: 8
Training loss: 2.216294288635254
Validation loss: 1.988896369934082

Epoch: 6| Step: 9
Training loss: 1.4661314487457275
Validation loss: 1.9976900617281597

Epoch: 6| Step: 10
Training loss: 1.1213457584381104
Validation loss: 1.9949048360188801

Epoch: 6| Step: 11
Training loss: 1.0981425046920776
Validation loss: 2.0270990133285522

Epoch: 6| Step: 12
Training loss: 0.8262345194816589
Validation loss: 2.0050177375475564

Epoch: 6| Step: 13
Training loss: 0.9032539129257202
Validation loss: 1.9997087319691975

Epoch: 91| Step: 0
Training loss: 1.3807930946350098
Validation loss: 1.9905836780865986

Epoch: 6| Step: 1
Training loss: 1.2089991569519043
Validation loss: 1.9644815723101299

Epoch: 6| Step: 2
Training loss: 0.803687572479248
Validation loss: 1.973015586535136

Epoch: 6| Step: 3
Training loss: 1.2397618293762207
Validation loss: 1.9587528308232625

Epoch: 6| Step: 4
Training loss: 1.608257532119751
Validation loss: 1.9704976081848145

Epoch: 6| Step: 5
Training loss: 1.7022026777267456
Validation loss: 2.0052528580029807

Epoch: 6| Step: 6
Training loss: 1.0353144407272339
Validation loss: 1.9900072813034058

Epoch: 6| Step: 7
Training loss: 1.2567821741104126
Validation loss: 1.9951725403467815

Epoch: 6| Step: 8
Training loss: 0.9785686135292053
Validation loss: 2.006441672643026

Epoch: 6| Step: 9
Training loss: 1.6210981607437134
Validation loss: 1.9561890363693237

Epoch: 6| Step: 10
Training loss: 1.577544093132019
Validation loss: 1.9391133387883503

Epoch: 6| Step: 11
Training loss: 0.9624393582344055
Validation loss: 1.9939502278963726

Epoch: 6| Step: 12
Training loss: 0.7436602711677551
Validation loss: 2.0223266084988913

Epoch: 6| Step: 13
Training loss: 1.279242992401123
Validation loss: 2.000271221001943

Epoch: 92| Step: 0
Training loss: 1.3342316150665283
Validation loss: 2.035066564877828

Epoch: 6| Step: 1
Training loss: 1.3831831216812134
Validation loss: 2.0172844529151917

Epoch: 6| Step: 2
Training loss: 0.999697208404541
Validation loss: 1.9768574237823486

Epoch: 6| Step: 3
Training loss: 0.9484683275222778
Validation loss: 2.0023699204126992

Epoch: 6| Step: 4
Training loss: 1.8106391429901123
Validation loss: 1.999035914738973

Epoch: 6| Step: 5
Training loss: 0.9806746244430542
Validation loss: 1.970207393169403

Epoch: 6| Step: 6
Training loss: 0.7728976011276245
Validation loss: 1.9666255116462708

Epoch: 6| Step: 7
Training loss: 0.8484819531440735
Validation loss: 1.9857601722081502

Epoch: 6| Step: 8
Training loss: 1.0282855033874512
Validation loss: 2.014469941457113

Epoch: 6| Step: 9
Training loss: 1.3391106128692627
Validation loss: 2.02127734820048

Epoch: 6| Step: 10
Training loss: 1.4834362268447876
Validation loss: 2.0105831623077393

Epoch: 6| Step: 11
Training loss: 1.6610257625579834
Validation loss: 1.9573488434155781

Epoch: 6| Step: 12
Training loss: 1.6299242973327637
Validation loss: 1.9840586980183919

Epoch: 6| Step: 13
Training loss: 1.3613054752349854
Validation loss: 1.964582363764445

Epoch: 93| Step: 0
Training loss: 1.369537115097046
Validation loss: 1.9359830617904663

Epoch: 6| Step: 1
Training loss: 1.3649624586105347
Validation loss: 1.9498564004898071

Epoch: 6| Step: 2
Training loss: 1.4337409734725952
Validation loss: 1.9647980332374573

Epoch: 6| Step: 3
Training loss: 1.0332705974578857
Validation loss: 1.9301528731981914

Epoch: 6| Step: 4
Training loss: 1.6860175132751465
Validation loss: 1.9533031781514485

Epoch: 6| Step: 5
Training loss: 1.4021368026733398
Validation loss: 1.9514452616373699

Epoch: 6| Step: 6
Training loss: 0.6506855487823486
Validation loss: 1.966135859489441

Epoch: 6| Step: 7
Training loss: 1.2699570655822754
Validation loss: 1.9941879510879517

Epoch: 6| Step: 8
Training loss: 1.0313256978988647
Validation loss: 2.0472859144210815

Epoch: 6| Step: 9
Training loss: 0.991184651851654
Validation loss: 2.073446055253347

Epoch: 6| Step: 10
Training loss: 1.3358771800994873
Validation loss: 2.0626202821731567

Epoch: 6| Step: 11
Training loss: 2.3476216793060303
Validation loss: 2.0049341917037964

Epoch: 6| Step: 12
Training loss: 0.6497920155525208
Validation loss: 1.9632266759872437

Epoch: 6| Step: 13
Training loss: 1.1459589004516602
Validation loss: 1.9788490931193035

Epoch: 94| Step: 0
Training loss: 0.9164096713066101
Validation loss: 1.9645396868387859

Epoch: 6| Step: 1
Training loss: 1.0797014236450195
Validation loss: 1.92026952902476

Epoch: 6| Step: 2
Training loss: 0.8969529867172241
Validation loss: 1.9411534865697224

Epoch: 6| Step: 3
Training loss: 1.4747405052185059
Validation loss: 1.9900269905726116

Epoch: 6| Step: 4
Training loss: 1.0231175422668457
Validation loss: 2.0258272091547647

Epoch: 6| Step: 5
Training loss: 1.2003026008605957
Validation loss: 2.0903286139170327

Epoch: 6| Step: 6
Training loss: 1.6827577352523804
Validation loss: 2.1116831302642822

Epoch: 6| Step: 7
Training loss: 1.4874485731124878
Validation loss: 2.1152435342470803

Epoch: 6| Step: 8
Training loss: 1.014370083808899
Validation loss: 2.076236089070638

Epoch: 6| Step: 9
Training loss: 1.3149856328964233
Validation loss: 1.989954948425293

Epoch: 6| Step: 10
Training loss: 1.6904902458190918
Validation loss: 2.0261797308921814

Epoch: 6| Step: 11
Training loss: 1.406088948249817
Validation loss: 1.9903566241264343

Epoch: 6| Step: 12
Training loss: 1.2075557708740234
Validation loss: 1.968035380045573

Epoch: 6| Step: 13
Training loss: 1.5194686651229858
Validation loss: 1.9812219341595967

Epoch: 95| Step: 0
Training loss: 0.746809720993042
Validation loss: 1.936078131198883

Epoch: 6| Step: 1
Training loss: 1.716721534729004
Validation loss: 1.9587022066116333

Epoch: 6| Step: 2
Training loss: 1.3599159717559814
Validation loss: 1.9782102505366008

Epoch: 6| Step: 3
Training loss: 0.7699504494667053
Validation loss: 1.980234702428182

Epoch: 6| Step: 4
Training loss: 1.4492912292480469
Validation loss: 2.0357854763666787

Epoch: 6| Step: 5
Training loss: 1.2528326511383057
Validation loss: 2.011863946914673

Epoch: 6| Step: 6
Training loss: 1.5636932849884033
Validation loss: 1.996188501516978

Epoch: 6| Step: 7
Training loss: 1.0451796054840088
Validation loss: 1.9771084189414978

Epoch: 6| Step: 8
Training loss: 0.7061300873756409
Validation loss: 1.9906585415204365

Epoch: 6| Step: 9
Training loss: 0.903416633605957
Validation loss: 1.978307028611501

Epoch: 6| Step: 10
Training loss: 1.4088306427001953
Validation loss: 1.9314711292584736

Epoch: 6| Step: 11
Training loss: 0.9763286709785461
Validation loss: 1.9700024724006653

Epoch: 6| Step: 12
Training loss: 1.5464911460876465
Validation loss: 2.023284375667572

Epoch: 6| Step: 13
Training loss: 1.2063229084014893
Validation loss: 1.9637538989384968

Epoch: 96| Step: 0
Training loss: 1.1774200201034546
Validation loss: 1.955568750699361

Epoch: 6| Step: 1
Training loss: 1.5128612518310547
Validation loss: 1.971592863400777

Epoch: 6| Step: 2
Training loss: 1.3108487129211426
Validation loss: 1.944915811220805

Epoch: 6| Step: 3
Training loss: 1.3608815670013428
Validation loss: 1.9652213255564372

Epoch: 6| Step: 4
Training loss: 1.0831940174102783
Validation loss: 1.9779183665911357

Epoch: 6| Step: 5
Training loss: 1.343416690826416
Validation loss: 1.9985911846160889

Epoch: 6| Step: 6
Training loss: 1.2404701709747314
Validation loss: 1.9578323364257812

Epoch: 6| Step: 7
Training loss: 0.6578251123428345
Validation loss: 1.9789896210034688

Epoch: 6| Step: 8
Training loss: 1.040727138519287
Validation loss: 1.9698555866877239

Epoch: 6| Step: 9
Training loss: 0.9760733246803284
Validation loss: 1.9491472641626995

Epoch: 6| Step: 10
Training loss: 1.1929559707641602
Validation loss: 1.9693957169850667

Epoch: 6| Step: 11
Training loss: 1.0066996812820435
Validation loss: 1.9826451738675435

Epoch: 6| Step: 12
Training loss: 1.1956455707550049
Validation loss: 2.005117336908976

Epoch: 6| Step: 13
Training loss: 1.3012356758117676
Validation loss: 2.0299265583356223

Epoch: 97| Step: 0
Training loss: 0.8576067686080933
Validation loss: 1.991239845752716

Epoch: 6| Step: 1
Training loss: 1.1339733600616455
Validation loss: 2.00991952419281

Epoch: 6| Step: 2
Training loss: 1.0772242546081543
Validation loss: 1.9709687034289043

Epoch: 6| Step: 3
Training loss: 0.8747349977493286
Validation loss: 1.9654362400372822

Epoch: 6| Step: 4
Training loss: 1.607332706451416
Validation loss: 1.9574788411458333

Epoch: 6| Step: 5
Training loss: 1.1280680894851685
Validation loss: 1.934515913327535

Epoch: 6| Step: 6
Training loss: 0.8380482196807861
Validation loss: 1.9389479955037434

Epoch: 6| Step: 7
Training loss: 1.1879205703735352
Validation loss: 1.9483571251233418

Epoch: 6| Step: 8
Training loss: 1.5212717056274414
Validation loss: 1.9982436100641887

Epoch: 6| Step: 9
Training loss: 0.9116657376289368
Validation loss: 1.9946771661440532

Epoch: 6| Step: 10
Training loss: 1.4700078964233398
Validation loss: 2.0994778076807656

Epoch: 6| Step: 11
Training loss: 1.0274595022201538
Validation loss: 2.0387656688690186

Epoch: 6| Step: 12
Training loss: 1.3081295490264893
Validation loss: 2.0256160298983255

Epoch: 6| Step: 13
Training loss: 1.2766810655593872
Validation loss: 1.994921863079071

Epoch: 98| Step: 0
Training loss: 1.1251040697097778
Validation loss: 1.9698870380719502

Epoch: 6| Step: 1
Training loss: 1.2417011260986328
Validation loss: 1.9403628309567769

Epoch: 6| Step: 2
Training loss: 1.502629041671753
Validation loss: 1.9053669969240825

Epoch: 6| Step: 3
Training loss: 1.3836891651153564
Validation loss: 1.919761300086975

Epoch: 6| Step: 4
Training loss: 0.9719916582107544
Validation loss: 1.9405502279599507

Epoch: 6| Step: 5
Training loss: 0.8957379460334778
Validation loss: 1.9726415673891704

Epoch: 6| Step: 6
Training loss: 0.49228304624557495
Validation loss: 2.011699299017588

Epoch: 6| Step: 7
Training loss: 1.0639541149139404
Validation loss: 2.047146260738373

Epoch: 6| Step: 8
Training loss: 1.5618255138397217
Validation loss: 2.0615256428718567

Epoch: 6| Step: 9
Training loss: 0.8582117557525635
Validation loss: 2.098016838232676

Epoch: 6| Step: 10
Training loss: 1.3490653038024902
Validation loss: 2.050553023815155

Epoch: 6| Step: 11
Training loss: 1.0618324279785156
Validation loss: 2.0152403910954795

Epoch: 6| Step: 12
Training loss: 1.1091322898864746
Validation loss: 2.006150742371877

Epoch: 6| Step: 13
Training loss: 1.4792003631591797
Validation loss: 1.9616997639338176

Epoch: 99| Step: 0
Training loss: 1.303215503692627
Validation loss: 1.983985702196757

Epoch: 6| Step: 1
Training loss: 1.0788301229476929
Validation loss: 1.9537480274836223

Epoch: 6| Step: 2
Training loss: 1.0416778326034546
Validation loss: 1.9527419209480286

Epoch: 6| Step: 3
Training loss: 1.3293195962905884
Validation loss: 1.9967397252718608

Epoch: 6| Step: 4
Training loss: 1.3072662353515625
Validation loss: 1.9836703538894653

Epoch: 6| Step: 5
Training loss: 1.1302598714828491
Validation loss: 2.0063838561375937

Epoch: 6| Step: 6
Training loss: 0.8370267748832703
Validation loss: 2.032544434070587

Epoch: 6| Step: 7
Training loss: 0.7786731719970703
Validation loss: 2.043956915537516

Epoch: 6| Step: 8
Training loss: 1.1943325996398926
Validation loss: 1.9835018316904705

Epoch: 6| Step: 9
Training loss: 0.7310202121734619
Validation loss: 1.9554437398910522

Epoch: 6| Step: 10
Training loss: 1.1771697998046875
Validation loss: 1.957685391108195

Epoch: 6| Step: 11
Training loss: 1.1277698278427124
Validation loss: 1.9592772920926411

Epoch: 6| Step: 12
Training loss: 1.3693368434906006
Validation loss: 1.975589911142985

Epoch: 6| Step: 13
Training loss: 0.999337911605835
Validation loss: 2.023076315720876

Epoch: 100| Step: 0
Training loss: 1.5263594388961792
Validation loss: 2.0813569823900857

Epoch: 6| Step: 1
Training loss: 1.137630581855774
Validation loss: 2.1056994795799255

Epoch: 6| Step: 2
Training loss: 1.2524418830871582
Validation loss: 2.1475236813227334

Epoch: 6| Step: 3
Training loss: 1.0122729539871216
Validation loss: 2.0756932497024536

Epoch: 6| Step: 4
Training loss: 0.8320745229721069
Validation loss: 2.053368926048279

Epoch: 6| Step: 5
Training loss: 1.35465407371521
Validation loss: 2.0072901248931885

Epoch: 6| Step: 6
Training loss: 1.0897750854492188
Validation loss: 1.9536455670992534

Epoch: 6| Step: 7
Training loss: 1.1994788646697998
Validation loss: 1.9349144498507183

Epoch: 6| Step: 8
Training loss: 0.6122556924819946
Validation loss: 1.9793148438135784

Epoch: 6| Step: 9
Training loss: 1.0004687309265137
Validation loss: 1.9759111603101094

Epoch: 6| Step: 10
Training loss: 1.3818453550338745
Validation loss: 1.9441491564114888

Epoch: 6| Step: 11
Training loss: 0.8316471576690674
Validation loss: 1.996478756268819

Epoch: 6| Step: 12
Training loss: 1.5946025848388672
Validation loss: 2.033906936645508

Epoch: 6| Step: 13
Training loss: 1.1085177659988403
Validation loss: 1.9918604890505474

Epoch: 101| Step: 0
Training loss: 1.3349807262420654
Validation loss: 2.0309518575668335

Epoch: 6| Step: 1
Training loss: 1.6071820259094238
Validation loss: 2.0184218287467957

Epoch: 6| Step: 2
Training loss: 1.1177222728729248
Validation loss: 1.9792911410331726

Epoch: 6| Step: 3
Training loss: 1.2330197095870972
Validation loss: 1.9469418327013652

Epoch: 6| Step: 4
Training loss: 1.39694082736969
Validation loss: 1.9290918111801147

Epoch: 6| Step: 5
Training loss: 1.5742343664169312
Validation loss: 1.9065867861111958

Epoch: 6| Step: 6
Training loss: 1.1994669437408447
Validation loss: 1.9882265329360962

Epoch: 6| Step: 7
Training loss: 0.9971604943275452
Validation loss: 2.012131671110789

Epoch: 6| Step: 8
Training loss: 1.336240291595459
Validation loss: 2.0044310887654624

Epoch: 6| Step: 9
Training loss: 0.6825113296508789
Validation loss: 2.08212282260259

Epoch: 6| Step: 10
Training loss: 0.689022421836853
Validation loss: 2.094927191734314

Epoch: 6| Step: 11
Training loss: 0.7173720598220825
Validation loss: 2.0536829233169556

Epoch: 6| Step: 12
Training loss: 1.0219323635101318
Validation loss: 2.0447834531466165

Epoch: 6| Step: 13
Training loss: 0.8973594903945923
Validation loss: 2.053378919760386

Epoch: 102| Step: 0
Training loss: 1.0726208686828613
Validation loss: 1.9650444984436035

Epoch: 6| Step: 1
Training loss: 0.967237114906311
Validation loss: 1.9913248817125957

Epoch: 6| Step: 2
Training loss: 0.6506068706512451
Validation loss: 1.980728546778361

Epoch: 6| Step: 3
Training loss: 1.1142367124557495
Validation loss: 1.9768196940422058

Epoch: 6| Step: 4
Training loss: 1.0967671871185303
Validation loss: 1.966686526934306

Epoch: 6| Step: 5
Training loss: 1.1286625862121582
Validation loss: 1.9834291537602742

Epoch: 6| Step: 6
Training loss: 1.6355606317520142
Validation loss: 1.945627232392629

Epoch: 6| Step: 7
Training loss: 0.7869772911071777
Validation loss: 2.0132415095965066

Epoch: 6| Step: 8
Training loss: 1.00893235206604
Validation loss: 2.052398224671682

Epoch: 6| Step: 9
Training loss: 1.1536874771118164
Validation loss: 2.05185866355896

Epoch: 6| Step: 10
Training loss: 0.8582934141159058
Validation loss: 2.0335381825764975

Epoch: 6| Step: 11
Training loss: 1.3929948806762695
Validation loss: 2.0720734198888144

Epoch: 6| Step: 12
Training loss: 0.7378398180007935
Validation loss: 2.0393224358558655

Epoch: 6| Step: 13
Training loss: 1.24293053150177
Validation loss: 2.044859290122986

Epoch: 103| Step: 0
Training loss: 0.7758249044418335
Validation loss: 2.037115474541982

Epoch: 6| Step: 1
Training loss: 1.2448654174804688
Validation loss: 1.9448375503222148

Epoch: 6| Step: 2
Training loss: 0.5131143927574158
Validation loss: 1.9725897709528606

Epoch: 6| Step: 3
Training loss: 0.9939598441123962
Validation loss: 1.968296229839325

Epoch: 6| Step: 4
Training loss: 1.1059942245483398
Validation loss: 1.9396637280782063

Epoch: 6| Step: 5
Training loss: 0.9054665565490723
Validation loss: 1.9473321835199993

Epoch: 6| Step: 6
Training loss: 0.983977198600769
Validation loss: 1.9975854555765789

Epoch: 6| Step: 7
Training loss: 0.9272499084472656
Validation loss: 2.0614384412765503

Epoch: 6| Step: 8
Training loss: 1.469133734703064
Validation loss: 2.1498398184776306

Epoch: 6| Step: 9
Training loss: 1.6795058250427246
Validation loss: 2.108856499195099

Epoch: 6| Step: 10
Training loss: 1.764439582824707
Validation loss: 2.1129993001619973

Epoch: 6| Step: 11
Training loss: 1.0497463941574097
Validation loss: 2.0531516472498574

Epoch: 6| Step: 12
Training loss: 1.9078071117401123
Validation loss: 1.9954172571500142

Epoch: 6| Step: 13
Training loss: 0.5151779651641846
Validation loss: 1.970752437909444

Epoch: 104| Step: 0
Training loss: 1.1641740798950195
Validation loss: 1.941186785697937

Epoch: 6| Step: 1
Training loss: 0.7100787162780762
Validation loss: 1.9275694092114766

Epoch: 6| Step: 2
Training loss: 1.2419941425323486
Validation loss: 1.9345130324363708

Epoch: 6| Step: 3
Training loss: 1.008204460144043
Validation loss: 1.9485377470652263

Epoch: 6| Step: 4
Training loss: 1.0751714706420898
Validation loss: 2.0140027006467185

Epoch: 6| Step: 5
Training loss: 0.9470341205596924
Validation loss: 2.1279449661572776

Epoch: 6| Step: 6
Training loss: 0.8323999643325806
Validation loss: 2.1292323668797812

Epoch: 6| Step: 7
Training loss: 1.3045423030853271
Validation loss: 2.1602914730707803

Epoch: 6| Step: 8
Training loss: 0.9693624973297119
Validation loss: 2.0846729079882302

Epoch: 6| Step: 9
Training loss: 1.3207926750183105
Validation loss: 1.9984994133313496

Epoch: 6| Step: 10
Training loss: 1.0083460807800293
Validation loss: 1.9549235304196675

Epoch: 6| Step: 11
Training loss: 0.9624639749526978
Validation loss: 1.9229134917259216

Epoch: 6| Step: 12
Training loss: 1.2190656661987305
Validation loss: 1.9184601306915283

Epoch: 6| Step: 13
Training loss: 1.7422155141830444
Validation loss: 1.8958986202875774

Epoch: 105| Step: 0
Training loss: 0.9954845309257507
Validation loss: 1.8918220003445942

Epoch: 6| Step: 1
Training loss: 1.6494486331939697
Validation loss: 1.9470178484916687

Epoch: 6| Step: 2
Training loss: 0.7241489291191101
Validation loss: 1.9588362177213032

Epoch: 6| Step: 3
Training loss: 1.0193166732788086
Validation loss: 1.9514256517092388

Epoch: 6| Step: 4
Training loss: 1.2873561382293701
Validation loss: 2.053902824719747

Epoch: 6| Step: 5
Training loss: 1.4441725015640259
Validation loss: 2.052847901980082

Epoch: 6| Step: 6
Training loss: 0.9683797359466553
Validation loss: 2.006858309110006

Epoch: 6| Step: 7
Training loss: 1.65346360206604
Validation loss: 1.9742963115374248

Epoch: 6| Step: 8
Training loss: 0.5538071393966675
Validation loss: 2.011681000391642

Epoch: 6| Step: 9
Training loss: 1.096535563468933
Validation loss: 2.010415256023407

Epoch: 6| Step: 10
Training loss: 1.2166231870651245
Validation loss: 1.9725305636723836

Epoch: 6| Step: 11
Training loss: 0.8762347102165222
Validation loss: 1.9609442551930745

Epoch: 6| Step: 12
Training loss: 0.6520642042160034
Validation loss: 1.9916853706041973

Epoch: 6| Step: 13
Training loss: 0.6146570444107056
Validation loss: 2.015180468559265

Epoch: 106| Step: 0
Training loss: 1.4943971633911133
Validation loss: 1.9669841925303142

Epoch: 6| Step: 1
Training loss: 0.9595628976821899
Validation loss: 1.9775561889012654

Epoch: 6| Step: 2
Training loss: 1.036861538887024
Validation loss: 1.9740610321362813

Epoch: 6| Step: 3
Training loss: 1.4460318088531494
Validation loss: 1.9463329513867695

Epoch: 6| Step: 4
Training loss: 1.0375304222106934
Validation loss: 1.9828169147173564

Epoch: 6| Step: 5
Training loss: 1.1738941669464111
Validation loss: 1.9605485995610554

Epoch: 6| Step: 6
Training loss: 0.705040693283081
Validation loss: 2.0441954731941223

Epoch: 6| Step: 7
Training loss: 0.979561984539032
Validation loss: 2.0721209247907004

Epoch: 6| Step: 8
Training loss: 0.790459394454956
Validation loss: 2.1075722773869834

Epoch: 6| Step: 9
Training loss: 1.0624456405639648
Validation loss: 2.1080174644788108

Epoch: 6| Step: 10
Training loss: 1.0224058628082275
Validation loss: 2.091082135836283

Epoch: 6| Step: 11
Training loss: 1.2105873823165894
Validation loss: 2.0299704869588218

Epoch: 6| Step: 12
Training loss: 0.7934666872024536
Validation loss: 1.9853126009305317

Epoch: 6| Step: 13
Training loss: 1.1618176698684692
Validation loss: 1.9558796485265095

Epoch: 107| Step: 0
Training loss: 1.0103530883789062
Validation loss: 1.8942996263504028

Epoch: 6| Step: 1
Training loss: 1.2178974151611328
Validation loss: 1.9128878116607666

Epoch: 6| Step: 2
Training loss: 0.8878363370895386
Validation loss: 1.9642860293388367

Epoch: 6| Step: 3
Training loss: 1.1860055923461914
Validation loss: 2.0021628737449646

Epoch: 6| Step: 4
Training loss: 0.8425649404525757
Validation loss: 2.080079436302185

Epoch: 6| Step: 5
Training loss: 0.7125244140625
Validation loss: 2.0802569588025412

Epoch: 6| Step: 6
Training loss: 1.4808342456817627
Validation loss: 2.067318836847941

Epoch: 6| Step: 7
Training loss: 1.420066475868225
Validation loss: 2.024216483036677

Epoch: 6| Step: 8
Training loss: 0.7703717350959778
Validation loss: 1.9758985837300618

Epoch: 6| Step: 9
Training loss: 0.9216855764389038
Validation loss: 1.9834906657536824

Epoch: 6| Step: 10
Training loss: 0.7025326490402222
Validation loss: 1.9389497637748718

Epoch: 6| Step: 11
Training loss: 0.8896524906158447
Validation loss: 1.9749920566876729

Epoch: 6| Step: 12
Training loss: 1.4945589303970337
Validation loss: 1.9524741768836975

Epoch: 6| Step: 13
Training loss: 1.5667688846588135
Validation loss: 2.0445357163747153

Epoch: 108| Step: 0
Training loss: 1.367940068244934
Validation loss: 2.072923759619395

Epoch: 6| Step: 1
Training loss: 1.0976104736328125
Validation loss: 2.0748722751935325

Epoch: 6| Step: 2
Training loss: 0.5942978858947754
Validation loss: 2.0348814924558005

Epoch: 6| Step: 3
Training loss: 1.2891210317611694
Validation loss: 2.0080042481422424

Epoch: 6| Step: 4
Training loss: 0.8748624324798584
Validation loss: 1.9567722082138062

Epoch: 6| Step: 5
Training loss: 1.340705394744873
Validation loss: 1.9591726859410603

Epoch: 6| Step: 6
Training loss: 1.340043067932129
Validation loss: 1.963053047657013

Epoch: 6| Step: 7
Training loss: 0.9963733553886414
Validation loss: 2.005943477153778

Epoch: 6| Step: 8
Training loss: 0.7048473358154297
Validation loss: 1.970602770646413

Epoch: 6| Step: 9
Training loss: 0.7752413153648376
Validation loss: 2.002572317918142

Epoch: 6| Step: 10
Training loss: 0.8465161323547363
Validation loss: 2.0345802903175354

Epoch: 6| Step: 11
Training loss: 0.6820884943008423
Validation loss: 1.9950026273727417

Epoch: 6| Step: 12
Training loss: 1.4839801788330078
Validation loss: 2.0385830402374268

Epoch: 6| Step: 13
Training loss: 1.031959056854248
Validation loss: 2.0466886162757874

Epoch: 109| Step: 0
Training loss: 1.3132672309875488
Validation loss: 2.0178315242131553

Epoch: 6| Step: 1
Training loss: 1.1320757865905762
Validation loss: 2.0161558389663696

Epoch: 6| Step: 2
Training loss: 0.8722171783447266
Validation loss: 1.993343710899353

Epoch: 6| Step: 3
Training loss: 0.7449904680252075
Validation loss: 2.049841662247976

Epoch: 6| Step: 4
Training loss: 1.197697639465332
Validation loss: 1.9495110114415486

Epoch: 6| Step: 5
Training loss: 1.0790070295333862
Validation loss: 1.959322492281596

Epoch: 6| Step: 6
Training loss: 1.078622817993164
Validation loss: 1.9348326325416565

Epoch: 6| Step: 7
Training loss: 0.7173680067062378
Validation loss: 1.9831291039784749

Epoch: 6| Step: 8
Training loss: 0.9062453508377075
Validation loss: 1.957144856452942

Epoch: 6| Step: 9
Training loss: 0.9328891038894653
Validation loss: 2.023619294166565

Epoch: 6| Step: 10
Training loss: 1.1297926902770996
Validation loss: 2.0094013611475625

Epoch: 6| Step: 11
Training loss: 1.0468180179595947
Validation loss: 2.007289230823517

Epoch: 6| Step: 12
Training loss: 1.0930697917938232
Validation loss: 1.9907832940419514

Epoch: 6| Step: 13
Training loss: 0.7371326684951782
Validation loss: 1.9790069659550984

Epoch: 110| Step: 0
Training loss: 0.747962474822998
Validation loss: 1.9749307036399841

Epoch: 6| Step: 1
Training loss: 0.6508957147598267
Validation loss: 1.9702978730201721

Epoch: 6| Step: 2
Training loss: 0.8497433662414551
Validation loss: 1.9865222374598186

Epoch: 6| Step: 3
Training loss: 0.8358564376831055
Validation loss: 2.006733258565267

Epoch: 6| Step: 4
Training loss: 1.525184154510498
Validation loss: 1.9882381359736125

Epoch: 6| Step: 5
Training loss: 1.0077285766601562
Validation loss: 2.0045552055040994

Epoch: 6| Step: 6
Training loss: 0.9639899134635925
Validation loss: 2.063337484995524

Epoch: 6| Step: 7
Training loss: 0.9082831144332886
Validation loss: 2.0287919441858926

Epoch: 6| Step: 8
Training loss: 1.2301932573318481
Validation loss: 2.0277082324028015

Epoch: 6| Step: 9
Training loss: 0.7453713417053223
Validation loss: 1.9867292245229085

Epoch: 6| Step: 10
Training loss: 0.7798970937728882
Validation loss: 1.9774444699287415

Epoch: 6| Step: 11
Training loss: 1.0225416421890259
Validation loss: 1.941030204296112

Epoch: 6| Step: 12
Training loss: 1.4039113521575928
Validation loss: 1.916265865166982

Epoch: 6| Step: 13
Training loss: 1.0868654251098633
Validation loss: 1.9320433537165325

Epoch: 111| Step: 0
Training loss: 1.7549879550933838
Validation loss: 1.9476218819618225

Epoch: 6| Step: 1
Training loss: 0.9103862047195435
Validation loss: 2.00151789188385

Epoch: 6| Step: 2
Training loss: 0.613943338394165
Validation loss: 2.0521176854769387

Epoch: 6| Step: 3
Training loss: 1.5486164093017578
Validation loss: 2.0711612900098166

Epoch: 6| Step: 4
Training loss: 0.6785460710525513
Validation loss: 2.0734461148579917

Epoch: 6| Step: 5
Training loss: 0.7058528661727905
Validation loss: 2.04070508480072

Epoch: 6| Step: 6
Training loss: 0.514967143535614
Validation loss: 2.0023568868637085

Epoch: 6| Step: 7
Training loss: 0.9547476768493652
Validation loss: 1.999889651934306

Epoch: 6| Step: 8
Training loss: 1.0607987642288208
Validation loss: 1.9836668769518535

Epoch: 6| Step: 9
Training loss: 0.9602968096733093
Validation loss: 1.9986483852068584

Epoch: 6| Step: 10
Training loss: 1.006977915763855
Validation loss: 1.9765128294626872

Epoch: 6| Step: 11
Training loss: 1.2685571908950806
Validation loss: 2.0300655166308084

Epoch: 6| Step: 12
Training loss: 0.8299976587295532
Validation loss: 2.0402546723683677

Epoch: 6| Step: 13
Training loss: 0.9880102872848511
Validation loss: 2.0515602231025696

Epoch: 112| Step: 0
Training loss: 0.7081574201583862
Validation loss: 1.9965832829475403

Epoch: 6| Step: 1
Training loss: 1.0039737224578857
Validation loss: 2.0256860057512918

Epoch: 6| Step: 2
Training loss: 0.8040956258773804
Validation loss: 1.9378528793652852

Epoch: 6| Step: 3
Training loss: 1.1755858659744263
Validation loss: 2.000897447268168

Epoch: 6| Step: 4
Training loss: 1.2132978439331055
Validation loss: 1.9804569880167644

Epoch: 6| Step: 5
Training loss: 1.1041806936264038
Validation loss: 1.990420937538147

Epoch: 6| Step: 6
Training loss: 0.8873622417449951
Validation loss: 2.009939650694529

Epoch: 6| Step: 7
Training loss: 0.9957499504089355
Validation loss: 2.0489304264386496

Epoch: 6| Step: 8
Training loss: 0.6437992453575134
Validation loss: 2.0514065623283386

Epoch: 6| Step: 9
Training loss: 0.6730952262878418
Validation loss: 2.0369054675102234

Epoch: 6| Step: 10
Training loss: 1.364442229270935
Validation loss: 2.0481271147727966

Epoch: 6| Step: 11
Training loss: 0.7662441730499268
Validation loss: 1.9595762689908345

Epoch: 6| Step: 12
Training loss: 0.9248498678207397
Validation loss: 1.9425561626752217

Epoch: 6| Step: 13
Training loss: 0.8008042573928833
Validation loss: 1.9279592037200928

Epoch: 113| Step: 0
Training loss: 0.6721833348274231
Validation loss: 1.9913799961407979

Epoch: 6| Step: 1
Training loss: 1.6193022727966309
Validation loss: 2.0034090677897134

Epoch: 6| Step: 2
Training loss: 0.8921348452568054
Validation loss: 2.0058864752451577

Epoch: 6| Step: 3
Training loss: 0.8347625732421875
Validation loss: 2.0195932189623513

Epoch: 6| Step: 4
Training loss: 0.7268855571746826
Validation loss: 2.0118751724561057

Epoch: 6| Step: 5
Training loss: 1.1586980819702148
Validation loss: 2.0374209880828857

Epoch: 6| Step: 6
Training loss: 0.6706912517547607
Validation loss: 2.027800500392914

Epoch: 6| Step: 7
Training loss: 0.7386457324028015
Validation loss: 1.9748787482579548

Epoch: 6| Step: 8
Training loss: 1.0008230209350586
Validation loss: 1.963297466437022

Epoch: 6| Step: 9
Training loss: 0.9630290269851685
Validation loss: 1.9846993486086528

Epoch: 6| Step: 10
Training loss: 1.3943766355514526
Validation loss: 1.9597933292388916

Epoch: 6| Step: 11
Training loss: 0.6242491006851196
Validation loss: 1.9439089894294739

Epoch: 6| Step: 12
Training loss: 0.5672723054885864
Validation loss: 1.9182281692822774

Epoch: 6| Step: 13
Training loss: 1.208387017250061
Validation loss: 1.9853874444961548

Epoch: 114| Step: 0
Training loss: 0.8290624618530273
Validation loss: 1.9617289503415425

Epoch: 6| Step: 1
Training loss: 1.0399363040924072
Validation loss: 1.9239060084025066

Epoch: 6| Step: 2
Training loss: 0.905420184135437
Validation loss: 1.9445748925209045

Epoch: 6| Step: 3
Training loss: 0.7374429106712341
Validation loss: 1.9755575060844421

Epoch: 6| Step: 4
Training loss: 1.3272725343704224
Validation loss: 1.972384552160899

Epoch: 6| Step: 5
Training loss: 0.704147219657898
Validation loss: 2.0243190924326577

Epoch: 6| Step: 6
Training loss: 1.4239397048950195
Validation loss: 2.003350257873535

Epoch: 6| Step: 7
Training loss: 1.4123427867889404
Validation loss: 1.9960994720458984

Epoch: 6| Step: 8
Training loss: 0.889613151550293
Validation loss: 2.031191070874532

Epoch: 6| Step: 9
Training loss: 0.5284692645072937
Validation loss: 1.9939148823420207

Epoch: 6| Step: 10
Training loss: 1.1286754608154297
Validation loss: 1.9467785954475403

Epoch: 6| Step: 11
Training loss: 0.37849342823028564
Validation loss: 1.988919456799825

Epoch: 6| Step: 12
Training loss: 1.0197572708129883
Validation loss: 1.975561797618866

Epoch: 6| Step: 13
Training loss: 0.6220707893371582
Validation loss: 2.0070176919301352

Epoch: 115| Step: 0
Training loss: 1.2561395168304443
Validation loss: 1.9626715183258057

Epoch: 6| Step: 1
Training loss: 1.3246065378189087
Validation loss: 1.9836546381314595

Epoch: 6| Step: 2
Training loss: 0.7093385457992554
Validation loss: 1.9337069988250732

Epoch: 6| Step: 3
Training loss: 0.760354220867157
Validation loss: 1.997441252072652

Epoch: 6| Step: 4
Training loss: 0.9197420477867126
Validation loss: 2.0172809958457947

Epoch: 6| Step: 5
Training loss: 0.9762177467346191
Validation loss: 1.9547466437021892

Epoch: 6| Step: 6
Training loss: 0.4573558568954468
Validation loss: 1.9444082578023274

Epoch: 6| Step: 7
Training loss: 1.1360602378845215
Validation loss: 1.9450163841247559

Epoch: 6| Step: 8
Training loss: 0.8023754954338074
Validation loss: 2.0081177949905396

Epoch: 6| Step: 9
Training loss: 0.6335945129394531
Validation loss: 1.9944155812263489

Epoch: 6| Step: 10
Training loss: 0.5477674007415771
Validation loss: 1.9842395782470703

Epoch: 6| Step: 11
Training loss: 0.6534899473190308
Validation loss: 2.057707448800405

Epoch: 6| Step: 12
Training loss: 1.0387482643127441
Validation loss: 2.065603792667389

Epoch: 6| Step: 13
Training loss: 1.4227616786956787
Validation loss: 2.0957125624020896

Epoch: 116| Step: 0
Training loss: 0.8944051265716553
Validation loss: 2.031018316745758

Epoch: 6| Step: 1
Training loss: 1.0678141117095947
Validation loss: 2.0270223220189414

Epoch: 6| Step: 2
Training loss: 0.8038169741630554
Validation loss: 2.003950913747152

Epoch: 6| Step: 3
Training loss: 0.8549975752830505
Validation loss: 1.9770358800888062

Epoch: 6| Step: 4
Training loss: 1.036833643913269
Validation loss: 1.9082282582918804

Epoch: 6| Step: 5
Training loss: 0.7403826713562012
Validation loss: 1.9405475656191509

Epoch: 6| Step: 6
Training loss: 1.0177741050720215
Validation loss: 1.9921014706293743

Epoch: 6| Step: 7
Training loss: 0.6067359447479248
Validation loss: 2.0274272759755454

Epoch: 6| Step: 8
Training loss: 1.1134499311447144
Validation loss: 2.0661925077438354

Epoch: 6| Step: 9
Training loss: 0.8626113533973694
Validation loss: 2.0414904356002808

Epoch: 6| Step: 10
Training loss: 0.5476849675178528
Validation loss: 2.0077325304349265

Epoch: 6| Step: 11
Training loss: 0.9958983659744263
Validation loss: 2.0220070083936057

Epoch: 6| Step: 12
Training loss: 1.2439160346984863
Validation loss: 1.9678582549095154

Epoch: 6| Step: 13
Training loss: 0.8734846711158752
Validation loss: 1.9103107849756877

Epoch: 117| Step: 0
Training loss: 0.6032310724258423
Validation loss: 1.951880931854248

Epoch: 6| Step: 1
Training loss: 0.8138724565505981
Validation loss: 1.9359256029129028

Epoch: 6| Step: 2
Training loss: 0.7241206765174866
Validation loss: 1.9488792419433594

Epoch: 6| Step: 3
Training loss: 0.8341862559318542
Validation loss: 2.032726228237152

Epoch: 6| Step: 4
Training loss: 1.255773901939392
Validation loss: 2.0735633969306946

Epoch: 6| Step: 5
Training loss: 1.022088646888733
Validation loss: 2.0506027142206826

Epoch: 6| Step: 6
Training loss: 0.7476385831832886
Validation loss: 2.0100682377815247

Epoch: 6| Step: 7
Training loss: 0.9920689463615417
Validation loss: 2.0482260982195535

Epoch: 6| Step: 8
Training loss: 0.9205434322357178
Validation loss: 2.0343854824701944

Epoch: 6| Step: 9
Training loss: 0.5215678811073303
Validation loss: 2.020681003729502

Epoch: 6| Step: 10
Training loss: 0.7138193845748901
Validation loss: 2.018964469432831

Epoch: 6| Step: 11
Training loss: 1.2590923309326172
Validation loss: 1.9816724061965942

Epoch: 6| Step: 12
Training loss: 0.7587783932685852
Validation loss: 1.9802560011545818

Epoch: 6| Step: 13
Training loss: 1.3710157871246338
Validation loss: 1.9533529082934062

Epoch: 118| Step: 0
Training loss: 0.7574303150177002
Validation loss: 1.9985506335894268

Epoch: 6| Step: 1
Training loss: 0.832196831703186
Validation loss: 1.9460972944895427

Epoch: 6| Step: 2
Training loss: 0.9474275708198547
Validation loss: 1.9679482181866963

Epoch: 6| Step: 3
Training loss: 0.8762882351875305
Validation loss: 2.0217992266019187

Epoch: 6| Step: 4
Training loss: 1.1785110235214233
Validation loss: 1.9651034474372864

Epoch: 6| Step: 5
Training loss: 0.5963515043258667
Validation loss: 2.003339926401774

Epoch: 6| Step: 6
Training loss: 0.6135531663894653
Validation loss: 2.0294365684191384

Epoch: 6| Step: 7
Training loss: 0.9059042930603027
Validation loss: 2.0262494683265686

Epoch: 6| Step: 8
Training loss: 1.0149002075195312
Validation loss: 2.0417595307032266

Epoch: 6| Step: 9
Training loss: 0.3864990472793579
Validation loss: 2.0344591538111367

Epoch: 6| Step: 10
Training loss: 1.271908164024353
Validation loss: 1.9823890328407288

Epoch: 6| Step: 11
Training loss: 0.7565878629684448
Validation loss: 1.9652832349141438

Epoch: 6| Step: 12
Training loss: 0.919836699962616
Validation loss: 1.955912470817566

Epoch: 6| Step: 13
Training loss: 1.4549068212509155
Validation loss: 1.9567039410273235

Epoch: 119| Step: 0
Training loss: 0.5661815404891968
Validation loss: 1.9797347784042358

Epoch: 6| Step: 1
Training loss: 1.0001928806304932
Validation loss: 2.018558700879415

Epoch: 6| Step: 2
Training loss: 0.47565433382987976
Validation loss: 2.020645260810852

Epoch: 6| Step: 3
Training loss: 0.6920238137245178
Validation loss: 1.979583203792572

Epoch: 6| Step: 4
Training loss: 0.6559954881668091
Validation loss: 2.0090039571126304

Epoch: 6| Step: 5
Training loss: 0.9442486763000488
Validation loss: 1.9731555183728535

Epoch: 6| Step: 6
Training loss: 1.268470287322998
Validation loss: 1.9680163264274597

Epoch: 6| Step: 7
Training loss: 1.0921554565429688
Validation loss: 1.9844846328099568

Epoch: 6| Step: 8
Training loss: 0.7229048609733582
Validation loss: 1.9898484349250793

Epoch: 6| Step: 9
Training loss: 0.8835000395774841
Validation loss: 1.9920204281806946

Epoch: 6| Step: 10
Training loss: 1.1473371982574463
Validation loss: 2.0422565937042236

Epoch: 6| Step: 11
Training loss: 0.4296345114707947
Validation loss: 1.9812507033348083

Epoch: 6| Step: 12
Training loss: 0.9233089685440063
Validation loss: 2.0660866697629294

Epoch: 6| Step: 13
Training loss: 1.284613847732544
Validation loss: 2.038603881994883

Epoch: 120| Step: 0
Training loss: 0.9841130971908569
Validation loss: 1.9977601369222004

Epoch: 6| Step: 1
Training loss: 0.6599396467208862
Validation loss: 2.0158367355664573

Epoch: 6| Step: 2
Training loss: 0.4140089452266693
Validation loss: 2.039915144443512

Epoch: 6| Step: 3
Training loss: 0.8165155649185181
Validation loss: 2.043836832046509

Epoch: 6| Step: 4
Training loss: 1.4910188913345337
Validation loss: 2.0214774211247764

Epoch: 6| Step: 5
Training loss: 0.9178562760353088
Validation loss: 2.0426247318585715

Epoch: 6| Step: 6
Training loss: 0.7491331696510315
Validation loss: 2.064010759194692

Epoch: 6| Step: 7
Training loss: 0.7576732039451599
Validation loss: 1.992035190264384

Epoch: 6| Step: 8
Training loss: 0.5272350907325745
Validation loss: 2.052339414755503

Epoch: 6| Step: 9
Training loss: 0.8626245856285095
Validation loss: 1.983417550722758

Epoch: 6| Step: 10
Training loss: 0.7407703399658203
Validation loss: 2.0016886989275613

Epoch: 6| Step: 11
Training loss: 0.7503167986869812
Validation loss: 1.9921463131904602

Epoch: 6| Step: 12
Training loss: 1.1426277160644531
Validation loss: 2.0648458003997803

Epoch: 6| Step: 13
Training loss: 1.0138142108917236
Validation loss: 2.007603724797567

Epoch: 121| Step: 0
Training loss: 0.6275274753570557
Validation loss: 1.9926291108131409

Epoch: 6| Step: 1
Training loss: 1.2391977310180664
Validation loss: 2.0079779426256814

Epoch: 6| Step: 2
Training loss: 0.8749289512634277
Validation loss: 2.012972275416056

Epoch: 6| Step: 3
Training loss: 0.6275134086608887
Validation loss: 2.044129033883413

Epoch: 6| Step: 4
Training loss: 0.696143388748169
Validation loss: 2.0533286134401956

Epoch: 6| Step: 5
Training loss: 0.861207127571106
Validation loss: 2.0739106933275857

Epoch: 6| Step: 6
Training loss: 0.6231178045272827
Validation loss: 2.078163743019104

Epoch: 6| Step: 7
Training loss: 1.042367696762085
Validation loss: 2.0620842377344766

Epoch: 6| Step: 8
Training loss: 1.1312637329101562
Validation loss: 2.031379481156667

Epoch: 6| Step: 9
Training loss: 0.7567844390869141
Validation loss: 1.9867193102836609

Epoch: 6| Step: 10
Training loss: 0.9556299448013306
Validation loss: 1.9839697082837422

Epoch: 6| Step: 11
Training loss: 1.462040901184082
Validation loss: 1.9837568600972493

Epoch: 6| Step: 12
Training loss: 0.7727258801460266
Validation loss: 1.9732964237531025

Epoch: 6| Step: 13
Training loss: 0.4047936201095581
Validation loss: 2.013140241305033

Epoch: 122| Step: 0
Training loss: 0.7944554686546326
Validation loss: 2.1003216902414956

Epoch: 6| Step: 1
Training loss: 0.840038001537323
Validation loss: 2.157985210418701

Epoch: 6| Step: 2
Training loss: 1.4535713195800781
Validation loss: 2.211647152900696

Epoch: 6| Step: 3
Training loss: 1.0813305377960205
Validation loss: 2.1652814944585166

Epoch: 6| Step: 4
Training loss: 0.7985324859619141
Validation loss: 2.0799575249354043

Epoch: 6| Step: 5
Training loss: 0.7006939649581909
Validation loss: 2.0062943498293557

Epoch: 6| Step: 6
Training loss: 0.7580040693283081
Validation loss: 1.961008111635844

Epoch: 6| Step: 7
Training loss: 0.7734178900718689
Validation loss: 1.9957585136095684

Epoch: 6| Step: 8
Training loss: 0.5916359424591064
Validation loss: 1.972455660502116

Epoch: 6| Step: 9
Training loss: 0.7770767211914062
Validation loss: 1.9576006134351094

Epoch: 6| Step: 10
Training loss: 1.4033479690551758
Validation loss: 1.967189868291219

Epoch: 6| Step: 11
Training loss: 0.6674584150314331
Validation loss: 2.0202491084734597

Epoch: 6| Step: 12
Training loss: 0.6425459384918213
Validation loss: 2.078002373377482

Epoch: 6| Step: 13
Training loss: 1.416212797164917
Validation loss: 2.076099773248037

Epoch: 123| Step: 0
Training loss: 0.7934376001358032
Validation loss: 2.029730200767517

Epoch: 6| Step: 1
Training loss: 1.4172031879425049
Validation loss: 2.0220441619555154

Epoch: 6| Step: 2
Training loss: 0.7883490920066833
Validation loss: 1.9795127511024475

Epoch: 6| Step: 3
Training loss: 0.5952895879745483
Validation loss: 1.997354805469513

Epoch: 6| Step: 4
Training loss: 0.38892024755477905
Validation loss: 1.9892278114954631

Epoch: 6| Step: 5
Training loss: 0.5701347589492798
Validation loss: 1.9911880294481914

Epoch: 6| Step: 6
Training loss: 0.9876046180725098
Validation loss: 2.0129144390424094

Epoch: 6| Step: 7
Training loss: 1.042981743812561
Validation loss: 2.078083594640096

Epoch: 6| Step: 8
Training loss: 0.9188793897628784
Validation loss: 2.092681606610616

Epoch: 6| Step: 9
Training loss: 0.7871055603027344
Validation loss: 2.0511075059572854

Epoch: 6| Step: 10
Training loss: 0.780074417591095
Validation loss: 2.0188000003496804

Epoch: 6| Step: 11
Training loss: 0.8910488486289978
Validation loss: 2.015041172504425

Epoch: 6| Step: 12
Training loss: 0.5893142223358154
Validation loss: 1.992098907629649

Epoch: 6| Step: 13
Training loss: 1.1958820819854736
Validation loss: 2.0036340753237405

Epoch: 124| Step: 0
Training loss: 0.716547966003418
Validation loss: 1.9887764652570088

Epoch: 6| Step: 1
Training loss: 0.47604236006736755
Validation loss: 2.005854368209839

Epoch: 6| Step: 2
Training loss: 0.9295673370361328
Validation loss: 2.00071128209432

Epoch: 6| Step: 3
Training loss: 0.8856388926506042
Validation loss: 2.0731579661369324

Epoch: 6| Step: 4
Training loss: 0.545813798904419
Validation loss: 2.0749043822288513

Epoch: 6| Step: 5
Training loss: 0.6902937293052673
Validation loss: 2.0764694015185037

Epoch: 6| Step: 6
Training loss: 0.813713788986206
Validation loss: 2.0537287394205728

Epoch: 6| Step: 7
Training loss: 1.2366275787353516
Validation loss: 1.965691328048706

Epoch: 6| Step: 8
Training loss: 1.0356370210647583
Validation loss: 2.031965454419454

Epoch: 6| Step: 9
Training loss: 0.4454924762248993
Validation loss: 1.9444467027982075

Epoch: 6| Step: 10
Training loss: 0.6977415084838867
Validation loss: 1.9759018421173096

Epoch: 6| Step: 11
Training loss: 0.8943337202072144
Validation loss: 1.956890861193339

Epoch: 6| Step: 12
Training loss: 1.017153024673462
Validation loss: 2.023439427216848

Epoch: 6| Step: 13
Training loss: 1.1647372245788574
Validation loss: 2.0619276762008667

Epoch: 125| Step: 0
Training loss: 0.7057889699935913
Validation loss: 2.033418615659078

Epoch: 6| Step: 1
Training loss: 0.5890257358551025
Validation loss: 2.058773100376129

Epoch: 6| Step: 2
Training loss: 0.6938596963882446
Validation loss: 2.0301454265912375

Epoch: 6| Step: 3
Training loss: 0.8149410486221313
Validation loss: 2.01885332663854

Epoch: 6| Step: 4
Training loss: 0.8301774263381958
Validation loss: 1.9527100324630737

Epoch: 6| Step: 5
Training loss: 0.6206621527671814
Validation loss: 1.9543312589327495

Epoch: 6| Step: 6
Training loss: 1.2703235149383545
Validation loss: 1.9800771276156108

Epoch: 6| Step: 7
Training loss: 1.2194809913635254
Validation loss: 1.9529030919075012

Epoch: 6| Step: 8
Training loss: 1.1263935565948486
Validation loss: 1.9679500857988994

Epoch: 6| Step: 9
Training loss: 0.5883816480636597
Validation loss: 1.9416284163792927

Epoch: 6| Step: 10
Training loss: 0.6464250087738037
Validation loss: 2.018800993760427

Epoch: 6| Step: 11
Training loss: 0.5061701536178589
Validation loss: 2.1126158038775125

Epoch: 6| Step: 12
Training loss: 1.065687656402588
Validation loss: 2.043222506841024

Epoch: 6| Step: 13
Training loss: 1.0353161096572876
Validation loss: 2.049285093943278

Epoch: 126| Step: 0
Training loss: 0.817470908164978
Validation loss: 2.021695295969645

Epoch: 6| Step: 1
Training loss: 0.4379616975784302
Validation loss: 2.0100674629211426

Epoch: 6| Step: 2
Training loss: 0.8087663650512695
Validation loss: 1.9843153754870098

Epoch: 6| Step: 3
Training loss: 1.401190996170044
Validation loss: 1.9713301062583923

Epoch: 6| Step: 4
Training loss: 0.8740696310997009
Validation loss: 1.9142573873202007

Epoch: 6| Step: 5
Training loss: 0.6524362564086914
Validation loss: 1.9864709774653118

Epoch: 6| Step: 6
Training loss: 0.8522220849990845
Validation loss: 1.994769275188446

Epoch: 6| Step: 7
Training loss: 0.9908657073974609
Validation loss: 1.9532862703005474

Epoch: 6| Step: 8
Training loss: 0.9576610922813416
Validation loss: 2.0716822346051535

Epoch: 6| Step: 9
Training loss: 0.6738293170928955
Validation loss: 2.024419923623403

Epoch: 6| Step: 10
Training loss: 0.5255173444747925
Validation loss: 2.0401769081751504

Epoch: 6| Step: 11
Training loss: 0.9194827079772949
Validation loss: 2.0881784756978354

Epoch: 6| Step: 12
Training loss: 0.9795525670051575
Validation loss: 2.0369090835253396

Epoch: 6| Step: 13
Training loss: 0.7035259008407593
Validation loss: 2.076926112174988

Epoch: 127| Step: 0
Training loss: 0.31623756885528564
Validation loss: 2.038786212603251

Epoch: 6| Step: 1
Training loss: 0.665400505065918
Validation loss: 1.9646734595298767

Epoch: 6| Step: 2
Training loss: 0.6988755464553833
Validation loss: 1.941461702187856

Epoch: 6| Step: 3
Training loss: 0.9394069314002991
Validation loss: 2.0099185506502786

Epoch: 6| Step: 4
Training loss: 0.8444527983665466
Validation loss: 2.006847898165385

Epoch: 6| Step: 5
Training loss: 0.6708185076713562
Validation loss: 1.9854812423388164

Epoch: 6| Step: 6
Training loss: 1.1739897727966309
Validation loss: 2.0079540411631265

Epoch: 6| Step: 7
Training loss: 0.6424198746681213
Validation loss: 2.0407771666844687

Epoch: 6| Step: 8
Training loss: 0.9976240396499634
Validation loss: 2.035619040330251

Epoch: 6| Step: 9
Training loss: 0.6635585427284241
Validation loss: 1.999858518441518

Epoch: 6| Step: 10
Training loss: 0.7583025693893433
Validation loss: 2.019497533639272

Epoch: 6| Step: 11
Training loss: 0.9247266054153442
Validation loss: 1.9409241477648418

Epoch: 6| Step: 12
Training loss: 0.8386718034744263
Validation loss: 2.0030269225438437

Epoch: 6| Step: 13
Training loss: 1.0304056406021118
Validation loss: 2.0099414189656577

Epoch: 128| Step: 0
Training loss: 1.1000144481658936
Validation loss: 1.9833263158798218

Epoch: 6| Step: 1
Training loss: 0.9679058194160461
Validation loss: 1.9818652073542278

Epoch: 6| Step: 2
Training loss: 0.41310709714889526
Validation loss: 1.9864099423090618

Epoch: 6| Step: 3
Training loss: 1.5037226676940918
Validation loss: 2.0380879243214927

Epoch: 6| Step: 4
Training loss: 0.988686203956604
Validation loss: 1.9989811182022095

Epoch: 6| Step: 5
Training loss: 0.9484513401985168
Validation loss: 2.0363657673199973

Epoch: 6| Step: 6
Training loss: 0.5164601802825928
Validation loss: 2.005973219871521

Epoch: 6| Step: 7
Training loss: 0.5729950666427612
Validation loss: 1.9699929157892864

Epoch: 6| Step: 8
Training loss: 0.6178703308105469
Validation loss: 1.9631235599517822

Epoch: 6| Step: 9
Training loss: 0.515861988067627
Validation loss: 1.9628626505533855

Epoch: 6| Step: 10
Training loss: 0.4810779094696045
Validation loss: 1.9785544276237488

Epoch: 6| Step: 11
Training loss: 0.7335658073425293
Validation loss: 2.0319881041844687

Epoch: 6| Step: 12
Training loss: 0.8876133561134338
Validation loss: 2.022609770298004

Epoch: 6| Step: 13
Training loss: 0.6481506824493408
Validation loss: 2.0293357769648233

Epoch: 129| Step: 0
Training loss: 0.8297327160835266
Validation loss: 2.010087251663208

Epoch: 6| Step: 1
Training loss: 1.3049423694610596
Validation loss: 2.0121949513753257

Epoch: 6| Step: 2
Training loss: 1.0673229694366455
Validation loss: 2.0157018105189004

Epoch: 6| Step: 3
Training loss: 0.25703445076942444
Validation loss: 1.9931180874506633

Epoch: 6| Step: 4
Training loss: 0.6111226081848145
Validation loss: 1.9798006812731426

Epoch: 6| Step: 5
Training loss: 0.39017847180366516
Validation loss: 2.002575178941091

Epoch: 6| Step: 6
Training loss: 1.1680632829666138
Validation loss: 1.9699282050132751

Epoch: 6| Step: 7
Training loss: 0.7473597526550293
Validation loss: 2.0086930990219116

Epoch: 6| Step: 8
Training loss: 0.5256137847900391
Validation loss: 1.9646618763605754

Epoch: 6| Step: 9
Training loss: 1.05398690700531
Validation loss: 2.0067339738210044

Epoch: 6| Step: 10
Training loss: 0.6674205660820007
Validation loss: 1.9508505860964458

Epoch: 6| Step: 11
Training loss: 0.7603111267089844
Validation loss: 1.9557750622431438

Epoch: 6| Step: 12
Training loss: 1.1408828496932983
Validation loss: 1.9690516193707783

Epoch: 6| Step: 13
Training loss: 0.3648308515548706
Validation loss: 1.9207874139149983

Epoch: 130| Step: 0
Training loss: 0.9248694181442261
Validation loss: 1.9499049385388691

Epoch: 6| Step: 1
Training loss: 0.8365960717201233
Validation loss: 1.9819610516230266

Epoch: 6| Step: 2
Training loss: 0.37067919969558716
Validation loss: 2.0156038999557495

Epoch: 6| Step: 3
Training loss: 0.6883858442306519
Validation loss: 1.970544119675954

Epoch: 6| Step: 4
Training loss: 0.6010785102844238
Validation loss: 1.9650834798812866

Epoch: 6| Step: 5
Training loss: 0.8704639673233032
Validation loss: 1.9916871388753254

Epoch: 6| Step: 6
Training loss: 1.0803970098495483
Validation loss: 2.005637228488922

Epoch: 6| Step: 7
Training loss: 0.8993785381317139
Validation loss: 1.9546008110046387

Epoch: 6| Step: 8
Training loss: 0.7897629737854004
Validation loss: 1.995996614297231

Epoch: 6| Step: 9
Training loss: 1.360748291015625
Validation loss: 2.056194543838501

Epoch: 6| Step: 10
Training loss: 0.3216063976287842
Validation loss: 2.07332181930542

Epoch: 6| Step: 11
Training loss: 0.5493190288543701
Validation loss: 2.0668700138727822

Epoch: 6| Step: 12
Training loss: 0.9019529819488525
Validation loss: 1.9952261845270793

Epoch: 6| Step: 13
Training loss: 0.48411011695861816
Validation loss: 1.9878665208816528

Epoch: 131| Step: 0
Training loss: 0.9505987167358398
Validation loss: 1.9391505718231201

Epoch: 6| Step: 1
Training loss: 0.769492506980896
Validation loss: 1.9525025486946106

Epoch: 6| Step: 2
Training loss: 1.001245141029358
Validation loss: 1.9548691511154175

Epoch: 6| Step: 3
Training loss: 0.9406170845031738
Validation loss: 1.972130278746287

Epoch: 6| Step: 4
Training loss: 0.6167112588882446
Validation loss: 1.9987914363543193

Epoch: 6| Step: 5
Training loss: 0.6077665090560913
Validation loss: 2.0984119375546775

Epoch: 6| Step: 6
Training loss: 0.7514705061912537
Validation loss: 2.096098025639852

Epoch: 6| Step: 7
Training loss: 0.7758971452713013
Validation loss: 2.105776866277059

Epoch: 6| Step: 8
Training loss: 0.9316728711128235
Validation loss: 2.0804874102274575

Epoch: 6| Step: 9
Training loss: 1.048782467842102
Validation loss: 2.037642776966095

Epoch: 6| Step: 10
Training loss: 0.5872277021408081
Validation loss: 2.030754725138346

Epoch: 6| Step: 11
Training loss: 0.7560954093933105
Validation loss: 1.9703642924626668

Epoch: 6| Step: 12
Training loss: 0.44015103578567505
Validation loss: 2.009482204914093

Epoch: 6| Step: 13
Training loss: 1.400821328163147
Validation loss: 1.9931594530741374

Epoch: 132| Step: 0
Training loss: 0.7336210608482361
Validation loss: 2.044164717197418

Epoch: 6| Step: 1
Training loss: 0.5575721263885498
Validation loss: 2.080295523007711

Epoch: 6| Step: 2
Training loss: 0.3168562650680542
Validation loss: 2.0660827358563743

Epoch: 6| Step: 3
Training loss: 0.6898919343948364
Validation loss: 2.1090686321258545

Epoch: 6| Step: 4
Training loss: 1.2399401664733887
Validation loss: 2.0780744552612305

Epoch: 6| Step: 5
Training loss: 0.4905100166797638
Validation loss: 2.026705741882324

Epoch: 6| Step: 6
Training loss: 0.9746567010879517
Validation loss: 1.991480569044749

Epoch: 6| Step: 7
Training loss: 0.9991294145584106
Validation loss: 1.9418697555859883

Epoch: 6| Step: 8
Training loss: 0.6515699625015259
Validation loss: 1.9109181960423787

Epoch: 6| Step: 9
Training loss: 0.7584068775177002
Validation loss: 1.9995767871538799

Epoch: 6| Step: 10
Training loss: 0.613611102104187
Validation loss: 2.035962402820587

Epoch: 6| Step: 11
Training loss: 0.7013792395591736
Validation loss: 2.105936646461487

Epoch: 6| Step: 12
Training loss: 1.4908711910247803
Validation loss: 2.097881038983663

Epoch: 6| Step: 13
Training loss: 1.1135265827178955
Validation loss: 2.099173684914907

Epoch: 133| Step: 0
Training loss: 0.8646087646484375
Validation loss: 2.068063577016195

Epoch: 6| Step: 1
Training loss: 0.8263655304908752
Validation loss: 2.010331392288208

Epoch: 6| Step: 2
Training loss: 0.9749163389205933
Validation loss: 1.982157548268636

Epoch: 6| Step: 3
Training loss: 0.8164858818054199
Validation loss: 1.9753068685531616

Epoch: 6| Step: 4
Training loss: 0.8180126547813416
Validation loss: 2.028795838356018

Epoch: 6| Step: 5
Training loss: 0.4368584156036377
Validation loss: 1.9988309343655903

Epoch: 6| Step: 6
Training loss: 0.603175699710846
Validation loss: 2.0079103310902915

Epoch: 6| Step: 7
Training loss: 0.9232097864151001
Validation loss: 2.0106032292048135

Epoch: 6| Step: 8
Training loss: 0.5056090354919434
Validation loss: 2.030234177907308

Epoch: 6| Step: 9
Training loss: 1.0823674201965332
Validation loss: 2.0078585545221963

Epoch: 6| Step: 10
Training loss: 0.49195396900177
Validation loss: 2.0181822180747986

Epoch: 6| Step: 11
Training loss: 0.7207651734352112
Validation loss: 2.0390608509381614

Epoch: 6| Step: 12
Training loss: 0.6755493879318237
Validation loss: 2.0101882815361023

Epoch: 6| Step: 13
Training loss: 0.981286883354187
Validation loss: 2.0594260692596436

Epoch: 134| Step: 0
Training loss: 0.5021672248840332
Validation loss: 2.065508226553599

Epoch: 6| Step: 1
Training loss: 0.767024040222168
Validation loss: 2.023997128009796

Epoch: 6| Step: 2
Training loss: 0.8013527393341064
Validation loss: 2.032053768634796

Epoch: 6| Step: 3
Training loss: 0.8912332057952881
Validation loss: 1.9982224504152934

Epoch: 6| Step: 4
Training loss: 0.6505553722381592
Validation loss: 1.9622841676076253

Epoch: 6| Step: 5
Training loss: 0.6315825581550598
Validation loss: 2.0057506163915

Epoch: 6| Step: 6
Training loss: 0.8513202667236328
Validation loss: 1.989719827969869

Epoch: 6| Step: 7
Training loss: 0.688064694404602
Validation loss: 2.0132851600646973

Epoch: 6| Step: 8
Training loss: 0.5035035610198975
Validation loss: 1.9996604720751445

Epoch: 6| Step: 9
Training loss: 0.6635005474090576
Validation loss: 2.000433842341105

Epoch: 6| Step: 10
Training loss: 0.6833053827285767
Validation loss: 1.9891197681427002

Epoch: 6| Step: 11
Training loss: 0.7816407680511475
Validation loss: 1.9955431421597798

Epoch: 6| Step: 12
Training loss: 0.6128624677658081
Validation loss: 2.0333786805470786

Epoch: 6| Step: 13
Training loss: 1.2408161163330078
Validation loss: 2.0286192496617637

Epoch: 135| Step: 0
Training loss: 1.0487143993377686
Validation loss: 1.9838210940361023

Epoch: 6| Step: 1
Training loss: 0.8442070484161377
Validation loss: 1.9803686539332073

Epoch: 6| Step: 2
Training loss: 0.38205599784851074
Validation loss: 2.0205620328585305

Epoch: 6| Step: 3
Training loss: 0.41464269161224365
Validation loss: 1.9996334711710613

Epoch: 6| Step: 4
Training loss: 0.4422093629837036
Validation loss: 2.062826653321584

Epoch: 6| Step: 5
Training loss: 0.8996679782867432
Validation loss: 2.087458074092865

Epoch: 6| Step: 6
Training loss: 1.0751452445983887
Validation loss: 2.1115790208180747

Epoch: 6| Step: 7
Training loss: 0.5414718985557556
Validation loss: 2.1363503535588584

Epoch: 6| Step: 8
Training loss: 0.3994236886501312
Validation loss: 2.104654610157013

Epoch: 6| Step: 9
Training loss: 1.1168475151062012
Validation loss: 2.0533835887908936

Epoch: 6| Step: 10
Training loss: 0.8551441431045532
Validation loss: 1.9676242272059123

Epoch: 6| Step: 11
Training loss: 0.6840023398399353
Validation loss: 1.9778374234835308

Epoch: 6| Step: 12
Training loss: 1.077207326889038
Validation loss: 1.972758670647939

Epoch: 6| Step: 13
Training loss: 0.7501504421234131
Validation loss: 1.9716354211171467

Epoch: 136| Step: 0
Training loss: 0.9603826403617859
Validation loss: 1.9848725199699402

Epoch: 6| Step: 1
Training loss: 1.0193538665771484
Validation loss: 1.9907511274019878

Epoch: 6| Step: 2
Training loss: 0.6655547618865967
Validation loss: 2.0815080801645913

Epoch: 6| Step: 3
Training loss: 0.8198108673095703
Validation loss: 2.105237364768982

Epoch: 6| Step: 4
Training loss: 0.9942487478256226
Validation loss: 2.1400734782218933

Epoch: 6| Step: 5
Training loss: 0.7456618547439575
Validation loss: 2.1924493312835693

Epoch: 6| Step: 6
Training loss: 0.7596849203109741
Validation loss: 2.100484291712443

Epoch: 6| Step: 7
Training loss: 0.5331969261169434
Validation loss: 2.0914231737454734

Epoch: 6| Step: 8
Training loss: 0.4039084315299988
Validation loss: 2.014608323574066

Epoch: 6| Step: 9
Training loss: 0.47406795620918274
Validation loss: 2.026299079259237

Epoch: 6| Step: 10
Training loss: 0.6787626147270203
Validation loss: 2.018355588118235

Epoch: 6| Step: 11
Training loss: 0.6287798881530762
Validation loss: 2.0250754753748574

Epoch: 6| Step: 12
Training loss: 0.9939545392990112
Validation loss: 2.0097672740618386

Epoch: 6| Step: 13
Training loss: 1.144782543182373
Validation loss: 2.0317929784456887

Epoch: 137| Step: 0
Training loss: 0.7213053703308105
Validation loss: 2.022109270095825

Epoch: 6| Step: 1
Training loss: 0.7525191903114319
Validation loss: 2.015043000380198

Epoch: 6| Step: 2
Training loss: 0.5344914197921753
Validation loss: 2.0371686617533364

Epoch: 6| Step: 3
Training loss: 0.4512518346309662
Validation loss: 2.004679799079895

Epoch: 6| Step: 4
Training loss: 0.7510247230529785
Validation loss: 2.040498157342275

Epoch: 6| Step: 5
Training loss: 0.8478105664253235
Validation loss: 2.041010777155558

Epoch: 6| Step: 6
Training loss: 0.7814339399337769
Validation loss: 2.055061141649882

Epoch: 6| Step: 7
Training loss: 0.726447343826294
Validation loss: 1.9886669913927715

Epoch: 6| Step: 8
Training loss: 1.1017850637435913
Validation loss: 1.9975009560585022

Epoch: 6| Step: 9
Training loss: 0.5284453630447388
Validation loss: 2.0002938906351724

Epoch: 6| Step: 10
Training loss: 0.7257409691810608
Validation loss: 1.99751220146815

Epoch: 6| Step: 11
Training loss: 0.9096806645393372
Validation loss: 2.027359406153361

Epoch: 6| Step: 12
Training loss: 0.41086116433143616
Validation loss: 2.069598933060964

Epoch: 6| Step: 13
Training loss: 0.8207127451896667
Validation loss: 2.0844353834788003

Epoch: 138| Step: 0
Training loss: 0.9706339836120605
Validation loss: 2.0877954761187234

Epoch: 6| Step: 1
Training loss: 0.9073834419250488
Validation loss: 2.0372294386227927

Epoch: 6| Step: 2
Training loss: 0.5469364523887634
Validation loss: 2.027973771095276

Epoch: 6| Step: 3
Training loss: 0.5339566469192505
Validation loss: 1.995622158050537

Epoch: 6| Step: 4
Training loss: 0.929212212562561
Validation loss: 2.0040237307548523

Epoch: 6| Step: 5
Training loss: 0.6203917264938354
Validation loss: 2.0284115076065063

Epoch: 6| Step: 6
Training loss: 0.605238676071167
Validation loss: 2.0628098050753274

Epoch: 6| Step: 7
Training loss: 0.7618078589439392
Validation loss: 2.0520795981089273

Epoch: 6| Step: 8
Training loss: 0.963845431804657
Validation loss: 2.0392318964004517

Epoch: 6| Step: 9
Training loss: 0.3526661694049835
Validation loss: 1.9921030203501384

Epoch: 6| Step: 10
Training loss: 0.5115043520927429
Validation loss: 2.033446033795675

Epoch: 6| Step: 11
Training loss: 0.8386208415031433
Validation loss: 2.0319932301839194

Epoch: 6| Step: 12
Training loss: 0.524969220161438
Validation loss: 2.0017473300298056

Epoch: 6| Step: 13
Training loss: 0.803672730922699
Validation loss: 1.99469127257665

Epoch: 139| Step: 0
Training loss: 0.2948877215385437
Validation loss: 2.0016878644625344

Epoch: 6| Step: 1
Training loss: 0.615681529045105
Validation loss: 1.9842427770296733

Epoch: 6| Step: 2
Training loss: 0.7443774938583374
Validation loss: 2.042985498905182

Epoch: 6| Step: 3
Training loss: 0.7128480076789856
Validation loss: 2.0403666694959006

Epoch: 6| Step: 4
Training loss: 0.6470576524734497
Validation loss: 2.018842657407125

Epoch: 6| Step: 5
Training loss: 0.8659307956695557
Validation loss: 2.0664019187291465

Epoch: 6| Step: 6
Training loss: 0.9971026182174683
Validation loss: 2.0429831743240356

Epoch: 6| Step: 7
Training loss: 0.5436509847640991
Validation loss: 2.0664380192756653

Epoch: 6| Step: 8
Training loss: 0.7161616086959839
Validation loss: 2.071124096711477

Epoch: 6| Step: 9
Training loss: 0.5525924563407898
Validation loss: 2.0461678306261697

Epoch: 6| Step: 10
Training loss: 0.6420935392379761
Validation loss: 2.007875065008799

Epoch: 6| Step: 11
Training loss: 1.2570844888687134
Validation loss: 1.9874452948570251

Epoch: 6| Step: 12
Training loss: 0.47822439670562744
Validation loss: 1.9880748788515727

Epoch: 6| Step: 13
Training loss: 0.7279666662216187
Validation loss: 2.0011316935221353

Epoch: 140| Step: 0
Training loss: 0.26955848932266235
Validation loss: 1.9955676992734273

Epoch: 6| Step: 1
Training loss: 0.8097892999649048
Validation loss: 2.0307565132776895

Epoch: 6| Step: 2
Training loss: 0.7238547801971436
Validation loss: 2.068737188975016

Epoch: 6| Step: 3
Training loss: 0.7412682175636292
Validation loss: 2.060281833012899

Epoch: 6| Step: 4
Training loss: 0.9868847131729126
Validation loss: 2.114657680193583

Epoch: 6| Step: 5
Training loss: 0.48395946621894836
Validation loss: 2.0131500363349915

Epoch: 6| Step: 6
Training loss: 0.815104067325592
Validation loss: 1.969486117362976

Epoch: 6| Step: 7
Training loss: 0.6863096356391907
Validation loss: 1.980807105700175

Epoch: 6| Step: 8
Training loss: 0.5003814101219177
Validation loss: 1.9982555508613586

Epoch: 6| Step: 9
Training loss: 0.5702261924743652
Validation loss: 2.0076290567715964

Epoch: 6| Step: 10
Training loss: 1.1117337942123413
Validation loss: 2.000858803590139

Epoch: 6| Step: 11
Training loss: 0.6449554562568665
Validation loss: 2.09150767326355

Epoch: 6| Step: 12
Training loss: 1.0129961967468262
Validation loss: 2.058661957581838

Epoch: 6| Step: 13
Training loss: 0.397847980260849
Validation loss: 2.158890962600708

Epoch: 141| Step: 0
Training loss: 0.853259265422821
Validation loss: 2.0539073745409646

Epoch: 6| Step: 1
Training loss: 0.6858656406402588
Validation loss: 2.0673510233561196

Epoch: 6| Step: 2
Training loss: 0.812829315662384
Validation loss: 2.015199363231659

Epoch: 6| Step: 3
Training loss: 0.6483643054962158
Validation loss: 2.013393501440684

Epoch: 6| Step: 4
Training loss: 0.8809707164764404
Validation loss: 1.9997679591178894

Epoch: 6| Step: 5
Training loss: 0.6621692776679993
Validation loss: 2.028524875640869

Epoch: 6| Step: 6
Training loss: 0.2518607974052429
Validation loss: 2.0363058050473533

Epoch: 6| Step: 7
Training loss: 0.530208945274353
Validation loss: 2.0153063337008157

Epoch: 6| Step: 8
Training loss: 0.6406464576721191
Validation loss: 2.039216677347819

Epoch: 6| Step: 9
Training loss: 0.5140236020088196
Validation loss: 2.02214252948761

Epoch: 6| Step: 10
Training loss: 0.6455242037773132
Validation loss: 2.069815695285797

Epoch: 6| Step: 11
Training loss: 0.7323219776153564
Validation loss: 2.057191630204519

Epoch: 6| Step: 12
Training loss: 1.5850774049758911
Validation loss: 2.0906209150950112

Epoch: 6| Step: 13
Training loss: 0.44239702820777893
Validation loss: 2.109705944856008

Epoch: 142| Step: 0
Training loss: 0.500859260559082
Validation loss: 2.047132949034373

Epoch: 6| Step: 1
Training loss: 1.0001029968261719
Validation loss: 2.0282686750094094

Epoch: 6| Step: 2
Training loss: 0.7230346202850342
Validation loss: 2.0158612926801047

Epoch: 6| Step: 3
Training loss: 0.679479718208313
Validation loss: 1.980713168780009

Epoch: 6| Step: 4
Training loss: 0.5768703818321228
Validation loss: 1.9524679978688557

Epoch: 6| Step: 5
Training loss: 1.037541151046753
Validation loss: 2.015525758266449

Epoch: 6| Step: 6
Training loss: 0.40520161390304565
Validation loss: 1.9808563192685444

Epoch: 6| Step: 7
Training loss: 0.9904047846794128
Validation loss: 2.016387681166331

Epoch: 6| Step: 8
Training loss: 0.7224547266960144
Validation loss: 2.08337672551473

Epoch: 6| Step: 9
Training loss: 0.5172679424285889
Validation loss: 2.103524068991343

Epoch: 6| Step: 10
Training loss: 0.7530680894851685
Validation loss: 2.0818447868029275

Epoch: 6| Step: 11
Training loss: 0.5380525588989258
Validation loss: 2.0438634157180786

Epoch: 6| Step: 12
Training loss: 0.4875398278236389
Validation loss: 2.080463190873464

Epoch: 6| Step: 13
Training loss: 0.9790581464767456
Validation loss: 2.0184966127077737

Epoch: 143| Step: 0
Training loss: 0.8022953271865845
Validation loss: 2.054615577061971

Epoch: 6| Step: 1
Training loss: 0.5777086019515991
Validation loss: 2.042068362236023

Epoch: 6| Step: 2
Training loss: 0.6621363162994385
Validation loss: 2.0423675576845803

Epoch: 6| Step: 3
Training loss: 0.7958822250366211
Validation loss: 2.036566178003947

Epoch: 6| Step: 4
Training loss: 1.1099443435668945
Validation loss: 2.070867955684662

Epoch: 6| Step: 5
Training loss: 0.7265644073486328
Validation loss: 2.0330989559491477

Epoch: 6| Step: 6
Training loss: 0.6909320950508118
Validation loss: 2.0301870902379355

Epoch: 6| Step: 7
Training loss: 0.5970457792282104
Validation loss: 2.071088989575704

Epoch: 6| Step: 8
Training loss: 0.7272120714187622
Validation loss: 2.0750962098439536

Epoch: 6| Step: 9
Training loss: 0.7426527738571167
Validation loss: 1.9916163682937622

Epoch: 6| Step: 10
Training loss: 0.8076391816139221
Validation loss: 1.9791046778361003

Epoch: 6| Step: 11
Training loss: 0.9225886464118958
Validation loss: 1.996313214302063

Epoch: 6| Step: 12
Training loss: 0.3703608512878418
Validation loss: 1.9692687789599101

Epoch: 6| Step: 13
Training loss: 0.6903235912322998
Validation loss: 2.0372785329818726

Epoch: 144| Step: 0
Training loss: 0.8183029294013977
Validation loss: 2.0509089628855386

Epoch: 6| Step: 1
Training loss: 0.981551468372345
Validation loss: 2.0545231302579245

Epoch: 6| Step: 2
Training loss: 0.5563705563545227
Validation loss: 2.0156904657681785

Epoch: 6| Step: 3
Training loss: 0.3792547583580017
Validation loss: 1.971303383509318

Epoch: 6| Step: 4
Training loss: 0.8741932511329651
Validation loss: 1.9329731464385986

Epoch: 6| Step: 5
Training loss: 0.49450457096099854
Validation loss: 1.987697144349416

Epoch: 6| Step: 6
Training loss: 0.6819611191749573
Validation loss: 2.0302364031473794

Epoch: 6| Step: 7
Training loss: 0.29117313027381897
Validation loss: 2.0555830597877502

Epoch: 6| Step: 8
Training loss: 0.9609367847442627
Validation loss: 2.0834312438964844

Epoch: 6| Step: 9
Training loss: 0.9391531944274902
Validation loss: 2.0787939627965293

Epoch: 6| Step: 10
Training loss: 0.6262840032577515
Validation loss: 2.037361482779185

Epoch: 6| Step: 11
Training loss: 0.47828418016433716
Validation loss: 1.9983781973520915

Epoch: 6| Step: 12
Training loss: 0.4847700893878937
Validation loss: 1.9943745334943135

Epoch: 6| Step: 13
Training loss: 0.837541401386261
Validation loss: 2.0184019406636557

Epoch: 145| Step: 0
Training loss: 0.8376100063323975
Validation loss: 2.0783863067626953

Epoch: 6| Step: 1
Training loss: 0.7198660969734192
Validation loss: 2.0480704506238303

Epoch: 6| Step: 2
Training loss: 0.49555566906929016
Validation loss: 2.0713184674580893

Epoch: 6| Step: 3
Training loss: 0.63205486536026
Validation loss: 2.077927509943644

Epoch: 6| Step: 4
Training loss: 0.5900638103485107
Validation loss: 2.0958609183629355

Epoch: 6| Step: 5
Training loss: 0.7620644569396973
Validation loss: 2.0529725551605225

Epoch: 6| Step: 6
Training loss: 0.9519892334938049
Validation loss: 2.0230132142702737

Epoch: 6| Step: 7
Training loss: 0.1702180951833725
Validation loss: 2.037618319193522

Epoch: 6| Step: 8
Training loss: 0.695672869682312
Validation loss: 2.062225659688314

Epoch: 6| Step: 9
Training loss: 0.4146004915237427
Validation loss: 2.0723368922869363

Epoch: 6| Step: 10
Training loss: 0.6017895936965942
Validation loss: 2.0275827844937644

Epoch: 6| Step: 11
Training loss: 0.7297642230987549
Validation loss: 2.0135586659113565

Epoch: 6| Step: 12
Training loss: 0.7397515177726746
Validation loss: 2.021634022394816

Epoch: 6| Step: 13
Training loss: 0.8966934680938721
Validation loss: 2.057714601357778

Epoch: 146| Step: 0
Training loss: 0.27348071336746216
Validation loss: 2.0568040211995444

Epoch: 6| Step: 1
Training loss: 0.840271532535553
Validation loss: 2.0843690435091653

Epoch: 6| Step: 2
Training loss: 0.810088038444519
Validation loss: 2.04694139957428

Epoch: 6| Step: 3
Training loss: 0.6793554425239563
Validation loss: 2.0425947308540344

Epoch: 6| Step: 4
Training loss: 0.3004251718521118
Validation loss: 2.060772101084391

Epoch: 6| Step: 5
Training loss: 0.8143410086631775
Validation loss: 2.0577955643335977

Epoch: 6| Step: 6
Training loss: 0.4799768924713135
Validation loss: 2.0259682337443032

Epoch: 6| Step: 7
Training loss: 0.6227962970733643
Validation loss: 2.0638397932052612

Epoch: 6| Step: 8
Training loss: 0.5410120487213135
Validation loss: 2.0461855928103128

Epoch: 6| Step: 9
Training loss: 1.019181728363037
Validation loss: 2.0746485392252603

Epoch: 6| Step: 10
Training loss: 0.8346682786941528
Validation loss: 2.060252328713735

Epoch: 6| Step: 11
Training loss: 0.6900118589401245
Validation loss: 2.046110212802887

Epoch: 6| Step: 12
Training loss: 0.6187585592269897
Validation loss: 2.053464949131012

Epoch: 6| Step: 13
Training loss: 0.7672220468521118
Validation loss: 2.0108030637105307

Epoch: 147| Step: 0
Training loss: 0.9463590383529663
Validation loss: 1.9935386180877686

Epoch: 6| Step: 1
Training loss: 0.7459765672683716
Validation loss: 2.022578994433085

Epoch: 6| Step: 2
Training loss: 0.38538068532943726
Validation loss: 2.0705930391947427

Epoch: 6| Step: 3
Training loss: 0.644605815410614
Validation loss: 2.0597525040308633

Epoch: 6| Step: 4
Training loss: 0.6221674680709839
Validation loss: 2.0762812892595925

Epoch: 6| Step: 5
Training loss: 0.6910767555236816
Validation loss: 2.065365731716156

Epoch: 6| Step: 6
Training loss: 0.6725108623504639
Validation loss: 2.1003455320994058

Epoch: 6| Step: 7
Training loss: 0.7156251668930054
Validation loss: 2.0785371462504068

Epoch: 6| Step: 8
Training loss: 0.4491077661514282
Validation loss: 2.1136625011761985

Epoch: 6| Step: 9
Training loss: 0.7304446697235107
Validation loss: 2.113310972849528

Epoch: 6| Step: 10
Training loss: 1.22039794921875
Validation loss: 2.0506339073181152

Epoch: 6| Step: 11
Training loss: 0.5812385678291321
Validation loss: 2.0490469535191855

Epoch: 6| Step: 12
Training loss: 0.3814874589443207
Validation loss: 2.0319567918777466

Epoch: 6| Step: 13
Training loss: 0.4673793315887451
Validation loss: 2.0441079139709473

Epoch: 148| Step: 0
Training loss: 0.560549259185791
Validation loss: 2.0372484723726907

Epoch: 6| Step: 1
Training loss: 0.79374098777771
Validation loss: 2.028046449025472

Epoch: 6| Step: 2
Training loss: 0.7710996866226196
Validation loss: 2.049238085746765

Epoch: 6| Step: 3
Training loss: 0.441692054271698
Validation loss: 2.0475443402926126

Epoch: 6| Step: 4
Training loss: 0.5981909036636353
Validation loss: 2.033860365549723

Epoch: 6| Step: 5
Training loss: 0.4894762635231018
Validation loss: 1.9479959607124329

Epoch: 6| Step: 6
Training loss: 1.1801459789276123
Validation loss: 2.0084349115689597

Epoch: 6| Step: 7
Training loss: 0.697495698928833
Validation loss: 2.016631563504537

Epoch: 6| Step: 8
Training loss: 0.25783613324165344
Validation loss: 2.0102906227111816

Epoch: 6| Step: 9
Training loss: 0.5928316116333008
Validation loss: 1.985962152481079

Epoch: 6| Step: 10
Training loss: 0.7053139209747314
Validation loss: 2.042983035246531

Epoch: 6| Step: 11
Training loss: 0.4910472631454468
Validation loss: 2.02564005057017

Epoch: 6| Step: 12
Training loss: 0.6293612718582153
Validation loss: 2.033767898877462

Epoch: 6| Step: 13
Training loss: 0.5490366816520691
Validation loss: 2.013241708278656

Epoch: 149| Step: 0
Training loss: 0.7389940023422241
Validation loss: 2.0149850447972617

Epoch: 6| Step: 1
Training loss: 0.7691693305969238
Validation loss: 2.044965902964274

Epoch: 6| Step: 2
Training loss: 0.5164731740951538
Validation loss: 2.0388254125912986

Epoch: 6| Step: 3
Training loss: 0.3063929080963135
Validation loss: 2.0718566179275513

Epoch: 6| Step: 4
Training loss: 0.9953267574310303
Validation loss: 2.0123541156450906

Epoch: 6| Step: 5
Training loss: 0.5021586418151855
Validation loss: 2.0458796421686807

Epoch: 6| Step: 6
Training loss: 0.5400745868682861
Validation loss: 2.0217245618502298

Epoch: 6| Step: 7
Training loss: 0.7009747624397278
Validation loss: 1.9962528745333354

Epoch: 6| Step: 8
Training loss: 0.6470442414283752
Validation loss: 2.01402215162913

Epoch: 6| Step: 9
Training loss: 0.25583982467651367
Validation loss: 2.0260924696922302

Epoch: 6| Step: 10
Training loss: 0.678926944732666
Validation loss: 2.043253262837728

Epoch: 6| Step: 11
Training loss: 0.6874064803123474
Validation loss: 2.062338431676229

Epoch: 6| Step: 12
Training loss: 0.45356035232543945
Validation loss: 2.1062334775924683

Epoch: 6| Step: 13
Training loss: 0.745855450630188
Validation loss: 2.0944389502207437

Epoch: 150| Step: 0
Training loss: 0.560051441192627
Validation loss: 2.0526293516159058

Epoch: 6| Step: 1
Training loss: 0.5681031942367554
Validation loss: 2.04187802473704

Epoch: 6| Step: 2
Training loss: 0.596598744392395
Validation loss: 1.991692026456197

Epoch: 6| Step: 3
Training loss: 1.0130811929702759
Validation loss: 2.0271084705988565

Epoch: 6| Step: 4
Training loss: 0.43898192048072815
Validation loss: 1.9799132148424785

Epoch: 6| Step: 5
Training loss: 1.0133644342422485
Validation loss: 2.013698617617289

Epoch: 6| Step: 6
Training loss: 0.5126129984855652
Validation loss: 2.053408940633138

Epoch: 6| Step: 7
Training loss: 0.6538809537887573
Validation loss: 2.0829080939292908

Epoch: 6| Step: 8
Training loss: 0.9532899260520935
Validation loss: 2.1663319865862527

Epoch: 6| Step: 9
Training loss: 0.7154810428619385
Validation loss: 2.1659679412841797

Epoch: 6| Step: 10
Training loss: 0.5503154993057251
Validation loss: 2.0634239514668784

Epoch: 6| Step: 11
Training loss: 0.3288635015487671
Validation loss: 2.036801278591156

Epoch: 6| Step: 12
Training loss: 0.6120806932449341
Validation loss: 2.052348037560781

Epoch: 6| Step: 13
Training loss: 0.657607913017273
Validation loss: 2.0269793272018433

Testing loss: 1.8723770371443933
