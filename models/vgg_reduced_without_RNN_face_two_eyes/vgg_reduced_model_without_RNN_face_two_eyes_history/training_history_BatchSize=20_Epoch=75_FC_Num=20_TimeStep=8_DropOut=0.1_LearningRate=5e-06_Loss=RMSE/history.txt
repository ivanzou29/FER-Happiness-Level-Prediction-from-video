Epoch: 1| Step: 0
Training loss: 5.618748221222083
Validation loss: 6.417000652472715

Epoch: 5| Step: 1
Training loss: 6.998427895711623
Validation loss: 6.385816012948132

Epoch: 5| Step: 2
Training loss: 7.144650315950182
Validation loss: 6.3535098836024435

Epoch: 5| Step: 3
Training loss: 6.581604678313759
Validation loss: 6.319243238084866

Epoch: 5| Step: 4
Training loss: 5.456106513060422
Validation loss: 6.286395089738145

Epoch: 5| Step: 5
Training loss: 6.177893376965034
Validation loss: 6.253970804860191

Epoch: 5| Step: 6
Training loss: 6.118135926835745
Validation loss: 6.2223269145347535

Epoch: 5| Step: 7
Training loss: 6.026038888344307
Validation loss: 6.192697711632819

Epoch: 5| Step: 8
Training loss: 6.919610404364783
Validation loss: 6.160423232707073

Epoch: 5| Step: 9
Training loss: 7.101972880744345
Validation loss: 6.12734996064631

Epoch: 5| Step: 10
Training loss: 5.392996003989605
Validation loss: 6.0949540472971355

Epoch: 5| Step: 11
Training loss: 6.600822524633501
Validation loss: 6.061066461292397

Epoch: 2| Step: 0
Training loss: 5.866511279273547
Validation loss: 6.0294569707057875

Epoch: 5| Step: 1
Training loss: 5.470501951518023
Validation loss: 5.993606677842837

Epoch: 5| Step: 2
Training loss: 5.911688344460595
Validation loss: 5.9581328160439995

Epoch: 5| Step: 3
Training loss: 6.9711061608583345
Validation loss: 5.92304865631551

Epoch: 5| Step: 4
Training loss: 6.830736861016762
Validation loss: 5.882496690653269

Epoch: 5| Step: 5
Training loss: 5.708800285156311
Validation loss: 5.844012956601853

Epoch: 5| Step: 6
Training loss: 5.533755322340273
Validation loss: 5.800417144342777

Epoch: 5| Step: 7
Training loss: 5.494018596727401
Validation loss: 5.758742859001527

Epoch: 5| Step: 8
Training loss: 6.365929826901578
Validation loss: 5.713920096212911

Epoch: 5| Step: 9
Training loss: 5.465227311302704
Validation loss: 5.667870564292771

Epoch: 5| Step: 10
Training loss: 5.723712706451652
Validation loss: 5.62329300304996

Epoch: 5| Step: 11
Training loss: 3.8038767865399814
Validation loss: 5.575990220299386

Epoch: 3| Step: 0
Training loss: 5.5097732408667675
Validation loss: 5.525148629365714

Epoch: 5| Step: 1
Training loss: 5.686117821727612
Validation loss: 5.4762912235015975

Epoch: 5| Step: 2
Training loss: 5.974647364724758
Validation loss: 5.41743868925887

Epoch: 5| Step: 3
Training loss: 5.0579975969905435
Validation loss: 5.370541475512861

Epoch: 5| Step: 4
Training loss: 5.150403216234135
Validation loss: 5.309035873434635

Epoch: 5| Step: 5
Training loss: 5.071212806179753
Validation loss: 5.250852969678325

Epoch: 5| Step: 6
Training loss: 5.526688931232021
Validation loss: 5.189395114094434

Epoch: 5| Step: 7
Training loss: 5.400558739471901
Validation loss: 5.1220466508976426

Epoch: 5| Step: 8
Training loss: 5.52606354570387
Validation loss: 5.053253041038831

Epoch: 5| Step: 9
Training loss: 4.817936192528232
Validation loss: 4.978798619903755

Epoch: 5| Step: 10
Training loss: 4.904527689896542
Validation loss: 4.909925594491198

Epoch: 5| Step: 11
Training loss: 4.052684487644762
Validation loss: 4.832794943234028

Epoch: 4| Step: 0
Training loss: 4.944615705193468
Validation loss: 4.7522396613260804

Epoch: 5| Step: 1
Training loss: 4.681862454655361
Validation loss: 4.664349392193585

Epoch: 5| Step: 2
Training loss: 5.117179113483108
Validation loss: 4.573387672075549

Epoch: 5| Step: 3
Training loss: 4.559733976334203
Validation loss: 4.479525386137572

Epoch: 5| Step: 4
Training loss: 4.1603795237913594
Validation loss: 4.383602984490121

Epoch: 5| Step: 5
Training loss: 3.837656913804793
Validation loss: 4.286386916476057

Epoch: 5| Step: 6
Training loss: 4.470808715373317
Validation loss: 4.183712845694222

Epoch: 5| Step: 7
Training loss: 4.387560008798802
Validation loss: 4.076896994141219

Epoch: 5| Step: 8
Training loss: 3.826190568723476
Validation loss: 3.98031342876901

Epoch: 5| Step: 9
Training loss: 4.131334469576594
Validation loss: 3.8650559892912995

Epoch: 5| Step: 10
Training loss: 3.716071438417836
Validation loss: 3.7542288565838677

Epoch: 5| Step: 11
Training loss: 3.4132341650127027
Validation loss: 3.637550299909535

Epoch: 5| Step: 0
Training loss: 3.023681946170377
Validation loss: 3.53937059286666

Epoch: 5| Step: 1
Training loss: 3.486776439574983
Validation loss: 3.429180881212762

Epoch: 5| Step: 2
Training loss: 3.956475206567162
Validation loss: 3.3322291313584667

Epoch: 5| Step: 3
Training loss: 2.7354350623746764
Validation loss: 3.2220808528895697

Epoch: 5| Step: 4
Training loss: 3.4794884873594554
Validation loss: 3.1187765553528157

Epoch: 5| Step: 5
Training loss: 2.922825786095829
Validation loss: 3.0294113940972727

Epoch: 5| Step: 6
Training loss: 3.784112650615897
Validation loss: 2.933569757775724

Epoch: 5| Step: 7
Training loss: 2.974546375471652
Validation loss: 2.8655984235978154

Epoch: 5| Step: 8
Training loss: 2.779018406914434
Validation loss: 2.791356099109987

Epoch: 5| Step: 9
Training loss: 2.4520173700535715
Validation loss: 2.7452411114741855

Epoch: 5| Step: 10
Training loss: 2.354716672760923
Validation loss: 2.721702445101256

Epoch: 5| Step: 11
Training loss: 3.6656321597862727
Validation loss: 2.697285141299957

Epoch: 6| Step: 0
Training loss: 3.1773312998242367
Validation loss: 2.6835851618274456

Epoch: 5| Step: 1
Training loss: 2.866426372067557
Validation loss: 2.699755492442094

Epoch: 5| Step: 2
Training loss: 2.5371293910692825
Validation loss: 2.703993082769376

Epoch: 5| Step: 3
Training loss: 2.729075762761155
Validation loss: 2.7202961424004006

Epoch: 5| Step: 4
Training loss: 2.5438554334230563
Validation loss: 2.755761378884727

Epoch: 5| Step: 5
Training loss: 3.0284741463164626
Validation loss: 2.7901593072135378

Epoch: 5| Step: 6
Training loss: 2.2503238021128134
Validation loss: 2.7975914071359265

Epoch: 5| Step: 7
Training loss: 3.746453451920526
Validation loss: 2.8182785611232264

Epoch: 5| Step: 8
Training loss: 2.4963131421641505
Validation loss: 2.7698216324173117

Epoch: 5| Step: 9
Training loss: 2.212612313043849
Validation loss: 2.7721819009940427

Epoch: 5| Step: 10
Training loss: 2.7699184389191247
Validation loss: 2.7614390597155896

Epoch: 5| Step: 11
Training loss: 3.4432448499548682
Validation loss: 2.7821071175558445

Epoch: 7| Step: 0
Training loss: 2.6315751153516476
Validation loss: 2.754421912719186

Epoch: 5| Step: 1
Training loss: 3.052139194919054
Validation loss: 2.768340255982044

Epoch: 5| Step: 2
Training loss: 2.4131464037851234
Validation loss: 2.771090143655058

Epoch: 5| Step: 3
Training loss: 2.597197482104001
Validation loss: 2.7540635048267723

Epoch: 5| Step: 4
Training loss: 3.5673412421869606
Validation loss: 2.7368041483740413

Epoch: 5| Step: 5
Training loss: 2.955266267040323
Validation loss: 2.7418908468634444

Epoch: 5| Step: 6
Training loss: 2.26441386506149
Validation loss: 2.729671141661504

Epoch: 5| Step: 7
Training loss: 2.8185987681484757
Validation loss: 2.6951782672277713

Epoch: 5| Step: 8
Training loss: 2.3010040330781036
Validation loss: 2.6853948339714644

Epoch: 5| Step: 9
Training loss: 3.2951466156404776
Validation loss: 2.6519758281109627

Epoch: 5| Step: 10
Training loss: 2.479534015099884
Validation loss: 2.6582312543895625

Epoch: 5| Step: 11
Training loss: 2.886650528572672
Validation loss: 2.6576205588525643

Epoch: 8| Step: 0
Training loss: 3.127117660168013
Validation loss: 2.675913675191698

Epoch: 5| Step: 1
Training loss: 2.7563246909334476
Validation loss: 2.67243986498053

Epoch: 5| Step: 2
Training loss: 2.424365037197915
Validation loss: 2.6739787729688533

Epoch: 5| Step: 3
Training loss: 2.819406633379311
Validation loss: 2.680926159921687

Epoch: 5| Step: 4
Training loss: 3.35075400677824
Validation loss: 2.6609708609573834

Epoch: 5| Step: 5
Training loss: 2.3789850231339016
Validation loss: 2.684207118760988

Epoch: 5| Step: 6
Training loss: 3.4071544881224005
Validation loss: 2.65564823814107

Epoch: 5| Step: 7
Training loss: 2.1529274372323357
Validation loss: 2.6691954972715606

Epoch: 5| Step: 8
Training loss: 2.9006936065970543
Validation loss: 2.6785747416036796

Epoch: 5| Step: 9
Training loss: 2.3667358370419938
Validation loss: 2.682922351478833

Epoch: 5| Step: 10
Training loss: 2.233881542429112
Validation loss: 2.671680302060608

Epoch: 5| Step: 11
Training loss: 1.6829742920578619
Validation loss: 2.675031091830234

Epoch: 9| Step: 0
Training loss: 3.130668838995202
Validation loss: 2.6690459713388526

Epoch: 5| Step: 1
Training loss: 2.5492368640776326
Validation loss: 2.674794737792825

Epoch: 5| Step: 2
Training loss: 3.1315728300963643
Validation loss: 2.6664102376391488

Epoch: 5| Step: 3
Training loss: 2.6344311546413435
Validation loss: 2.6508777557743426

Epoch: 5| Step: 4
Training loss: 2.761759928999265
Validation loss: 2.6477338480672405

Epoch: 5| Step: 5
Training loss: 2.2934004265189762
Validation loss: 2.648124470023825

Epoch: 5| Step: 6
Training loss: 2.8155252081220654
Validation loss: 2.656675162602923

Epoch: 5| Step: 7
Training loss: 2.8932618357647772
Validation loss: 2.648176178469531

Epoch: 5| Step: 8
Training loss: 2.8590614688932723
Validation loss: 2.6603326500929723

Epoch: 5| Step: 9
Training loss: 2.4838798557349406
Validation loss: 2.6467398807546823

Epoch: 5| Step: 10
Training loss: 2.345171179633992
Validation loss: 2.651549822076968

Epoch: 5| Step: 11
Training loss: 1.6241675959206525
Validation loss: 2.6465984324596463

Epoch: 10| Step: 0
Training loss: 2.933674695641736
Validation loss: 2.658686948643483

Epoch: 5| Step: 1
Training loss: 2.0454259504380956
Validation loss: 2.627710785733203

Epoch: 5| Step: 2
Training loss: 3.240842535650467
Validation loss: 2.6425241754761912

Epoch: 5| Step: 3
Training loss: 3.0304515612931744
Validation loss: 2.6406597722038243

Epoch: 5| Step: 4
Training loss: 2.3107128970427753
Validation loss: 2.652918667627507

Epoch: 5| Step: 5
Training loss: 2.47874667245831
Validation loss: 2.640030908813062

Epoch: 5| Step: 6
Training loss: 2.6118871052049117
Validation loss: 2.6566671642265507

Epoch: 5| Step: 7
Training loss: 2.9822111423790054
Validation loss: 2.6462075739735926

Epoch: 5| Step: 8
Training loss: 2.6332694090154436
Validation loss: 2.6320409691377247

Epoch: 5| Step: 9
Training loss: 2.60955755086319
Validation loss: 2.633554348442936

Epoch: 5| Step: 10
Training loss: 2.3777032826638873
Validation loss: 2.6330827712010842

Epoch: 5| Step: 11
Training loss: 3.2179739303528647
Validation loss: 2.6255773219775707

Epoch: 11| Step: 0
Training loss: 2.285805738697196
Validation loss: 2.6479459248228676

Epoch: 5| Step: 1
Training loss: 2.838581628547305
Validation loss: 2.6350984544595732

Epoch: 5| Step: 2
Training loss: 2.648740497912312
Validation loss: 2.6358419811441793

Epoch: 5| Step: 3
Training loss: 2.2420228904351873
Validation loss: 2.630021446815043

Epoch: 5| Step: 4
Training loss: 2.7702010922479436
Validation loss: 2.639579317611213

Epoch: 5| Step: 5
Training loss: 2.748414536250624
Validation loss: 2.6348772602641968

Epoch: 5| Step: 6
Training loss: 3.0130634398265554
Validation loss: 2.6096716919611564

Epoch: 5| Step: 7
Training loss: 2.323828399960849
Validation loss: 2.6452978122856963

Epoch: 5| Step: 8
Training loss: 2.694170546839105
Validation loss: 2.632054960423923

Epoch: 5| Step: 9
Training loss: 2.6391705903615432
Validation loss: 2.6326426876706734

Epoch: 5| Step: 10
Training loss: 2.883125102144244
Validation loss: 2.6243605364644487

Epoch: 5| Step: 11
Training loss: 3.7734055290684303
Validation loss: 2.6144432521747456

Epoch: 12| Step: 0
Training loss: 2.1154410841547406
Validation loss: 2.630460954878726

Epoch: 5| Step: 1
Training loss: 3.014603990450202
Validation loss: 2.6071806892544735

Epoch: 5| Step: 2
Training loss: 2.143029971192185
Validation loss: 2.633735217716934

Epoch: 5| Step: 3
Training loss: 2.4688161527244934
Validation loss: 2.6292710979253933

Epoch: 5| Step: 4
Training loss: 2.8131294393854
Validation loss: 2.6252606618224137

Epoch: 5| Step: 5
Training loss: 2.7177339606479833
Validation loss: 2.609608386599261

Epoch: 5| Step: 6
Training loss: 2.0077088325544468
Validation loss: 2.623060679452663

Epoch: 5| Step: 7
Training loss: 2.7117915058843884
Validation loss: 2.6293566064392992

Epoch: 5| Step: 8
Training loss: 2.4906275539791936
Validation loss: 2.63718268939973

Epoch: 5| Step: 9
Training loss: 3.1514482892608684
Validation loss: 2.6346772756202066

Epoch: 5| Step: 10
Training loss: 3.141525822592989
Validation loss: 2.6332768484487867

Epoch: 5| Step: 11
Training loss: 3.959546809996285
Validation loss: 2.633261618714085

Epoch: 13| Step: 0
Training loss: 2.688479222948647
Validation loss: 2.6293290144545227

Epoch: 5| Step: 1
Training loss: 2.8463880438619458
Validation loss: 2.613538743634881

Epoch: 5| Step: 2
Training loss: 2.8314972893716917
Validation loss: 2.611334689200308

Epoch: 5| Step: 3
Training loss: 2.311114540566239
Validation loss: 2.6288706062398317

Epoch: 5| Step: 4
Training loss: 2.5601322120560077
Validation loss: 2.616064717116629

Epoch: 5| Step: 5
Training loss: 2.1840118935928396
Validation loss: 2.609804133383441

Epoch: 5| Step: 6
Training loss: 2.195404593820102
Validation loss: 2.597262145623519

Epoch: 5| Step: 7
Training loss: 2.5654693704998506
Validation loss: 2.6083914793458005

Epoch: 5| Step: 8
Training loss: 3.095906440484341
Validation loss: 2.6172236046269752

Epoch: 5| Step: 9
Training loss: 3.2996672607055504
Validation loss: 2.611753559860014

Epoch: 5| Step: 10
Training loss: 2.473210614631057
Validation loss: 2.619594761228039

Epoch: 5| Step: 11
Training loss: 2.861966152468183
Validation loss: 2.6028519719657814

Epoch: 14| Step: 0
Training loss: 2.7086417291582245
Validation loss: 2.606772085844356

Epoch: 5| Step: 1
Training loss: 2.526207976749098
Validation loss: 2.618093153607408

Epoch: 5| Step: 2
Training loss: 3.074373544288224
Validation loss: 2.60898120748761

Epoch: 5| Step: 3
Training loss: 2.8123790291095623
Validation loss: 2.6162979360223853

Epoch: 5| Step: 4
Training loss: 2.6394683290963608
Validation loss: 2.624298346310679

Epoch: 5| Step: 5
Training loss: 2.558838251676371
Validation loss: 2.6122848785695116

Epoch: 5| Step: 6
Training loss: 2.7321268485461343
Validation loss: 2.597221464325856

Epoch: 5| Step: 7
Training loss: 2.7509008145965654
Validation loss: 2.594290554449308

Epoch: 5| Step: 8
Training loss: 2.069154926788583
Validation loss: 2.6063079569110514

Epoch: 5| Step: 9
Training loss: 2.5275176989259225
Validation loss: 2.6125700267429233

Epoch: 5| Step: 10
Training loss: 2.1581229216573625
Validation loss: 2.6040777814318994

Epoch: 5| Step: 11
Training loss: 4.568691285639309
Validation loss: 2.588527793898273

Epoch: 15| Step: 0
Training loss: 2.9711114425995038
Validation loss: 2.61023016296615

Epoch: 5| Step: 1
Training loss: 2.568574172636343
Validation loss: 2.5912199089669596

Epoch: 5| Step: 2
Training loss: 2.9959559203751738
Validation loss: 2.6093607843129836

Epoch: 5| Step: 3
Training loss: 2.035828345791421
Validation loss: 2.591556222643476

Epoch: 5| Step: 4
Training loss: 2.2567208895045527
Validation loss: 2.5980957959622746

Epoch: 5| Step: 5
Training loss: 2.291609457053275
Validation loss: 2.5964052213790865

Epoch: 5| Step: 6
Training loss: 2.68694903026603
Validation loss: 2.595772643984615

Epoch: 5| Step: 7
Training loss: 3.092689717794489
Validation loss: 2.603074990654999

Epoch: 5| Step: 8
Training loss: 2.4125653905357343
Validation loss: 2.603196330808585

Epoch: 5| Step: 9
Training loss: 3.0227248660512798
Validation loss: 2.6047010572813303

Epoch: 5| Step: 10
Training loss: 2.442498486146487
Validation loss: 2.617012693725905

Epoch: 5| Step: 11
Training loss: 2.570886704330373
Validation loss: 2.6048439607423175

Epoch: 16| Step: 0
Training loss: 3.005160026668908
Validation loss: 2.6039516907015727

Epoch: 5| Step: 1
Training loss: 2.8953841338994923
Validation loss: 2.61390776220889

Epoch: 5| Step: 2
Training loss: 3.0038975193407746
Validation loss: 2.5869442765307653

Epoch: 5| Step: 3
Training loss: 2.3942912792046194
Validation loss: 2.620043593946714

Epoch: 5| Step: 4
Training loss: 2.654625698939673
Validation loss: 2.6008294937274936

Epoch: 5| Step: 5
Training loss: 1.6612693734973236
Validation loss: 2.6030124255289366

Epoch: 5| Step: 6
Training loss: 2.091368388252553
Validation loss: 2.609760754637867

Epoch: 5| Step: 7
Training loss: 2.6927490428058345
Validation loss: 2.589292146255071

Epoch: 5| Step: 8
Training loss: 2.7958175109173
Validation loss: 2.594401725791289

Epoch: 5| Step: 9
Training loss: 2.5043394573936832
Validation loss: 2.594174993695469

Epoch: 5| Step: 10
Training loss: 3.0969566911841553
Validation loss: 2.6059913968927186

Epoch: 5| Step: 11
Training loss: 1.9043177833387435
Validation loss: 2.596558846249873

Epoch: 17| Step: 0
Training loss: 2.370357795136703
Validation loss: 2.587190341848837

Epoch: 5| Step: 1
Training loss: 2.564924163440877
Validation loss: 2.574857428995669

Epoch: 5| Step: 2
Training loss: 2.4715567942211134
Validation loss: 2.5780225482967696

Epoch: 5| Step: 3
Training loss: 2.7388534927488237
Validation loss: 2.5918925156778383

Epoch: 5| Step: 4
Training loss: 2.517532478433647
Validation loss: 2.565759047871817

Epoch: 5| Step: 5
Training loss: 2.8194543267271572
Validation loss: 2.5973224970442526

Epoch: 5| Step: 6
Training loss: 2.6342134003042132
Validation loss: 2.5820299880524367

Epoch: 5| Step: 7
Training loss: 3.1132824752977513
Validation loss: 2.5613218134339353

Epoch: 5| Step: 8
Training loss: 2.539051231946151
Validation loss: 2.5848394523178575

Epoch: 5| Step: 9
Training loss: 2.422595599859829
Validation loss: 2.569025175294215

Epoch: 5| Step: 10
Training loss: 2.4772300422242557
Validation loss: 2.5767411072350783

Epoch: 5| Step: 11
Training loss: 3.241973502209091
Validation loss: 2.588046749371895

Epoch: 18| Step: 0
Training loss: 2.504974280280527
Validation loss: 2.5833179963077044

Epoch: 5| Step: 1
Training loss: 2.6286012379069645
Validation loss: 2.5810262442984624

Epoch: 5| Step: 2
Training loss: 3.135656573642456
Validation loss: 2.5896711258393412

Epoch: 5| Step: 3
Training loss: 2.1381911203374324
Validation loss: 2.5660405316951302

Epoch: 5| Step: 4
Training loss: 2.249004673682853
Validation loss: 2.57454033378364

Epoch: 5| Step: 5
Training loss: 2.431065993222586
Validation loss: 2.5677607236292914

Epoch: 5| Step: 6
Training loss: 2.8784169333782064
Validation loss: 2.565739208688759

Epoch: 5| Step: 7
Training loss: 2.619227556553931
Validation loss: 2.5867702683695355

Epoch: 5| Step: 8
Training loss: 2.2569956638360447
Validation loss: 2.5727028886629983

Epoch: 5| Step: 9
Training loss: 2.5073147573914722
Validation loss: 2.60438249965168

Epoch: 5| Step: 10
Training loss: 3.200020676784471
Validation loss: 2.5891900711998934

Epoch: 5| Step: 11
Training loss: 1.9780220402684394
Validation loss: 2.5760868416134

Epoch: 19| Step: 0
Training loss: 3.1021442011968965
Validation loss: 2.5701777626751525

Epoch: 5| Step: 1
Training loss: 2.256538321969482
Validation loss: 2.5834372420076472

Epoch: 5| Step: 2
Training loss: 2.7197840686245383
Validation loss: 2.5666635927165395

Epoch: 5| Step: 3
Training loss: 2.797404574760132
Validation loss: 2.5491254611164784

Epoch: 5| Step: 4
Training loss: 2.3859828182730567
Validation loss: 2.576809749919811

Epoch: 5| Step: 5
Training loss: 2.124623994659493
Validation loss: 2.5774195351298594

Epoch: 5| Step: 6
Training loss: 2.166353080749117
Validation loss: 2.5538628440008617

Epoch: 5| Step: 7
Training loss: 2.6458992737089915
Validation loss: 2.5733206016179455

Epoch: 5| Step: 8
Training loss: 2.7452610104399717
Validation loss: 2.570651158648704

Epoch: 5| Step: 9
Training loss: 2.224705614481601
Validation loss: 2.551345486278395

Epoch: 5| Step: 10
Training loss: 2.9992156592887502
Validation loss: 2.5512167951618214

Epoch: 5| Step: 11
Training loss: 3.315619385451184
Validation loss: 2.576721344896524

Epoch: 20| Step: 0
Training loss: 2.907610995010031
Validation loss: 2.5700093354341336

Epoch: 5| Step: 1
Training loss: 2.3372258234637324
Validation loss: 2.565497649296623

Epoch: 5| Step: 2
Training loss: 2.1685806648040473
Validation loss: 2.572929275471504

Epoch: 5| Step: 3
Training loss: 2.5256423057712785
Validation loss: 2.578369988255096

Epoch: 5| Step: 4
Training loss: 1.9503962260952208
Validation loss: 2.5833669180891685

Epoch: 5| Step: 5
Training loss: 2.4634734151685973
Validation loss: 2.5785611833672784

Epoch: 5| Step: 6
Training loss: 3.329379566118601
Validation loss: 2.5958478287852893

Epoch: 5| Step: 7
Training loss: 2.7923158109158472
Validation loss: 2.585702848976819

Epoch: 5| Step: 8
Training loss: 2.3418544988088623
Validation loss: 2.600508253842705

Epoch: 5| Step: 9
Training loss: 2.976070012879001
Validation loss: 2.584725813481959

Epoch: 5| Step: 10
Training loss: 2.7303066833161687
Validation loss: 2.5896579297943307

Epoch: 5| Step: 11
Training loss: 2.489443042159481
Validation loss: 2.5721177792669394

Epoch: 21| Step: 0
Training loss: 2.375630646347405
Validation loss: 2.5784471869241457

Epoch: 5| Step: 1
Training loss: 2.82715122044876
Validation loss: 2.5659048363821095

Epoch: 5| Step: 2
Training loss: 2.8021155335420898
Validation loss: 2.569244286470716

Epoch: 5| Step: 3
Training loss: 2.8568272314123515
Validation loss: 2.55132870059477

Epoch: 5| Step: 4
Training loss: 1.8122534090868607
Validation loss: 2.5602402259760035

Epoch: 5| Step: 5
Training loss: 2.269944381536644
Validation loss: 2.5500787816313135

Epoch: 5| Step: 6
Training loss: 2.809669511440676
Validation loss: 2.5618977226582924

Epoch: 5| Step: 7
Training loss: 3.058647379398924
Validation loss: 2.5568634006085147

Epoch: 5| Step: 8
Training loss: 2.160788252193882
Validation loss: 2.552880716640931

Epoch: 5| Step: 9
Training loss: 2.71634848628973
Validation loss: 2.5667026064160647

Epoch: 5| Step: 10
Training loss: 2.2897733554542348
Validation loss: 2.566703094083556

Epoch: 5| Step: 11
Training loss: 3.5987969825595454
Validation loss: 2.5653355153639423

Epoch: 22| Step: 0
Training loss: 2.9844991448430416
Validation loss: 2.558197017904508

Epoch: 5| Step: 1
Training loss: 2.3801914495513454
Validation loss: 2.582454285086237

Epoch: 5| Step: 2
Training loss: 1.7405638377540535
Validation loss: 2.5839075301496797

Epoch: 5| Step: 3
Training loss: 2.6949582074380385
Validation loss: 2.6104883495168982

Epoch: 5| Step: 4
Training loss: 2.7094903870753644
Validation loss: 2.58972955972703

Epoch: 5| Step: 5
Training loss: 2.600827224888871
Validation loss: 2.6198509025070362

Epoch: 5| Step: 6
Training loss: 2.588939940568174
Validation loss: 2.5971227303543207

Epoch: 5| Step: 7
Training loss: 2.4461332168733496
Validation loss: 2.6096951903075074

Epoch: 5| Step: 8
Training loss: 3.421478387849397
Validation loss: 2.5836304844929656

Epoch: 5| Step: 9
Training loss: 2.4142479686414475
Validation loss: 2.575281424559993

Epoch: 5| Step: 10
Training loss: 2.3600976102654037
Validation loss: 2.5666138571305943

Epoch: 5| Step: 11
Training loss: 2.045016544340406
Validation loss: 2.556765528756474

Epoch: 23| Step: 0
Training loss: 2.9449095108819074
Validation loss: 2.5733739521184265

Epoch: 5| Step: 1
Training loss: 2.0508376340835204
Validation loss: 2.560796888896719

Epoch: 5| Step: 2
Training loss: 2.5487980047909002
Validation loss: 2.5650555343019654

Epoch: 5| Step: 3
Training loss: 2.61720225771259
Validation loss: 2.5735085124548296

Epoch: 5| Step: 4
Training loss: 2.5717907396977626
Validation loss: 2.5570251470986944

Epoch: 5| Step: 5
Training loss: 2.4979512402896793
Validation loss: 2.56410129261291

Epoch: 5| Step: 6
Training loss: 2.366612934344326
Validation loss: 2.548149542772599

Epoch: 5| Step: 7
Training loss: 2.405921517282007
Validation loss: 2.546840499769074

Epoch: 5| Step: 8
Training loss: 2.775733964100167
Validation loss: 2.5468926926448825

Epoch: 5| Step: 9
Training loss: 2.3218444493621213
Validation loss: 2.5406703533583617

Epoch: 5| Step: 10
Training loss: 2.9003102301042154
Validation loss: 2.5364342374394715

Epoch: 5| Step: 11
Training loss: 3.0083685819158204
Validation loss: 2.547099788083651

Epoch: 24| Step: 0
Training loss: 2.9008805089232443
Validation loss: 2.5580267707499074

Epoch: 5| Step: 1
Training loss: 2.353195991813051
Validation loss: 2.5417462372961954

Epoch: 5| Step: 2
Training loss: 2.855480439335684
Validation loss: 2.551184053342792

Epoch: 5| Step: 3
Training loss: 2.635932319061669
Validation loss: 2.5418620516507664

Epoch: 5| Step: 4
Training loss: 2.0540769416862026
Validation loss: 2.549640593257993

Epoch: 5| Step: 5
Training loss: 2.2771318445043667
Validation loss: 2.5595358902412713

Epoch: 5| Step: 6
Training loss: 2.6217759633143225
Validation loss: 2.564520907371789

Epoch: 5| Step: 7
Training loss: 3.0897613398657673
Validation loss: 2.5362430979893453

Epoch: 5| Step: 8
Training loss: 2.5814345878014056
Validation loss: 2.5652217831570523

Epoch: 5| Step: 9
Training loss: 2.0272235577479805
Validation loss: 2.54454551835667

Epoch: 5| Step: 10
Training loss: 2.7924758156025447
Validation loss: 2.5538224068912694

Epoch: 5| Step: 11
Training loss: 1.548706434743995
Validation loss: 2.55561847813745

Epoch: 25| Step: 0
Training loss: 2.087816627839805
Validation loss: 2.536015741532314

Epoch: 5| Step: 1
Training loss: 2.331549155341923
Validation loss: 2.5340100730822743

Epoch: 5| Step: 2
Training loss: 2.5071193414500534
Validation loss: 2.5552815087953493

Epoch: 5| Step: 3
Training loss: 2.6167248672848458
Validation loss: 2.5618859462499532

Epoch: 5| Step: 4
Training loss: 2.2506446974384176
Validation loss: 2.5381802459061062

Epoch: 5| Step: 5
Training loss: 2.370038421415998
Validation loss: 2.523097043843614

Epoch: 5| Step: 6
Training loss: 3.103714587854187
Validation loss: 2.5468310701447017

Epoch: 5| Step: 7
Training loss: 2.709162942052053
Validation loss: 2.537131049279207

Epoch: 5| Step: 8
Training loss: 2.7292574704815675
Validation loss: 2.5467406668467825

Epoch: 5| Step: 9
Training loss: 2.8760917912506234
Validation loss: 2.5560978642888066

Epoch: 5| Step: 10
Training loss: 2.6233428083714823
Validation loss: 2.5504795575646644

Epoch: 5| Step: 11
Training loss: 2.741375664415088
Validation loss: 2.5550351387563826

Epoch: 26| Step: 0
Training loss: 2.13213921843522
Validation loss: 2.5540439483405692

Epoch: 5| Step: 1
Training loss: 2.529468615971942
Validation loss: 2.5541425234497286

Epoch: 5| Step: 2
Training loss: 3.0535643090696523
Validation loss: 2.536029643674234

Epoch: 5| Step: 3
Training loss: 2.709021955145564
Validation loss: 2.5280862078305546

Epoch: 5| Step: 4
Training loss: 2.064035710890807
Validation loss: 2.5432221403121886

Epoch: 5| Step: 5
Training loss: 2.741000883278327
Validation loss: 2.5476239825180973

Epoch: 5| Step: 6
Training loss: 2.4367678594211655
Validation loss: 2.556625237939516

Epoch: 5| Step: 7
Training loss: 2.697702779846422
Validation loss: 2.542170472059722

Epoch: 5| Step: 8
Training loss: 1.9850248339082057
Validation loss: 2.5633757691928096

Epoch: 5| Step: 9
Training loss: 2.903722012237574
Validation loss: 2.5450421858927874

Epoch: 5| Step: 10
Training loss: 2.6906813488242425
Validation loss: 2.5409430557745094

Epoch: 5| Step: 11
Training loss: 1.6504818501738503
Validation loss: 2.5163074539151786

Epoch: 27| Step: 0
Training loss: 2.503616959021975
Validation loss: 2.502691092091325

Epoch: 5| Step: 1
Training loss: 1.7109817429487608
Validation loss: 2.5326855556485373

Epoch: 5| Step: 2
Training loss: 3.0185099820270067
Validation loss: 2.5230945239912894

Epoch: 5| Step: 3
Training loss: 2.367576642674012
Validation loss: 2.523968974264345

Epoch: 5| Step: 4
Training loss: 3.1033930145108353
Validation loss: 2.510051294438438

Epoch: 5| Step: 5
Training loss: 2.6543208578007307
Validation loss: 2.533754459835745

Epoch: 5| Step: 6
Training loss: 2.3590529266215725
Validation loss: 2.5296510387084026

Epoch: 5| Step: 7
Training loss: 3.19476895734197
Validation loss: 2.5357496157915453

Epoch: 5| Step: 8
Training loss: 1.9259514104788606
Validation loss: 2.564101102772015

Epoch: 5| Step: 9
Training loss: 2.675604643179557
Validation loss: 2.5510568786288004

Epoch: 5| Step: 10
Training loss: 2.2210561023893427
Validation loss: 2.545224858494952

Epoch: 5| Step: 11
Training loss: 2.5279696837671723
Validation loss: 2.5240410357591405

Epoch: 28| Step: 0
Training loss: 2.4754964658079768
Validation loss: 2.544134983013732

Epoch: 5| Step: 1
Training loss: 2.5328379230294105
Validation loss: 2.5456085527792363

Epoch: 5| Step: 2
Training loss: 2.963662858483961
Validation loss: 2.524614805482996

Epoch: 5| Step: 3
Training loss: 2.2432809748592635
Validation loss: 2.5443384648955196

Epoch: 5| Step: 4
Training loss: 3.1274113316396464
Validation loss: 2.5311608985634546

Epoch: 5| Step: 5
Training loss: 2.444075201304192
Validation loss: 2.5506657159956907

Epoch: 5| Step: 6
Training loss: 2.669536526490295
Validation loss: 2.5455120980232464

Epoch: 5| Step: 7
Training loss: 2.424439678150546
Validation loss: 2.5410210748409283

Epoch: 5| Step: 8
Training loss: 2.2609402332935273
Validation loss: 2.5404934924547287

Epoch: 5| Step: 9
Training loss: 2.5068195789785697
Validation loss: 2.529773057571104

Epoch: 5| Step: 10
Training loss: 2.302288915047816
Validation loss: 2.522002431146588

Epoch: 5| Step: 11
Training loss: 1.7655996135135672
Validation loss: 2.531914184306019

Epoch: 29| Step: 0
Training loss: 2.309433630997844
Validation loss: 2.513350254005253

Epoch: 5| Step: 1
Training loss: 2.54964348039804
Validation loss: 2.533063117525642

Epoch: 5| Step: 2
Training loss: 2.416678878051774
Validation loss: 2.5365206745379685

Epoch: 5| Step: 3
Training loss: 2.0303746611520834
Validation loss: 2.545759452105744

Epoch: 5| Step: 4
Training loss: 2.5307360468774385
Validation loss: 2.539310760098602

Epoch: 5| Step: 5
Training loss: 3.516180782891237
Validation loss: 2.5623258147701518

Epoch: 5| Step: 6
Training loss: 2.6775489926597538
Validation loss: 2.5723365729493937

Epoch: 5| Step: 7
Training loss: 2.6357628113772598
Validation loss: 2.567977724136039

Epoch: 5| Step: 8
Training loss: 2.804725582958719
Validation loss: 2.5677983395249204

Epoch: 5| Step: 9
Training loss: 2.6399053010428464
Validation loss: 2.569890750036103

Epoch: 5| Step: 10
Training loss: 1.561555042626921
Validation loss: 2.5461341818023855

Epoch: 5| Step: 11
Training loss: 1.786111722042651
Validation loss: 2.5353541010459026

Epoch: 30| Step: 0
Training loss: 2.023407453512739
Validation loss: 2.511303908448444

Epoch: 5| Step: 1
Training loss: 2.0728042290895075
Validation loss: 2.517681611950041

Epoch: 5| Step: 2
Training loss: 2.3985581755955616
Validation loss: 2.524374308663551

Epoch: 5| Step: 3
Training loss: 2.4427800822074213
Validation loss: 2.5313135362822066

Epoch: 5| Step: 4
Training loss: 2.8087044430116457
Validation loss: 2.5021943475604083

Epoch: 5| Step: 5
Training loss: 2.726970827848193
Validation loss: 2.5309025168820347

Epoch: 5| Step: 6
Training loss: 2.8060838204097767
Validation loss: 2.523173902067778

Epoch: 5| Step: 7
Training loss: 2.411608983079153
Validation loss: 2.526906297451995

Epoch: 5| Step: 8
Training loss: 3.0222627787424394
Validation loss: 2.5169357731184494

Epoch: 5| Step: 9
Training loss: 1.8629940939301324
Validation loss: 2.527983064286175

Epoch: 5| Step: 10
Training loss: 2.7571138788446823
Validation loss: 2.5157767382364664

Epoch: 5| Step: 11
Training loss: 3.6379025475785784
Validation loss: 2.520487932444322

Epoch: 31| Step: 0
Training loss: 2.39425732288832
Validation loss: 2.519291308902553

Epoch: 5| Step: 1
Training loss: 2.435733448459786
Validation loss: 2.513002383044148

Epoch: 5| Step: 2
Training loss: 2.972679669442077
Validation loss: 2.523700680703495

Epoch: 5| Step: 3
Training loss: 1.3902126515281075
Validation loss: 2.514852401214474

Epoch: 5| Step: 4
Training loss: 3.087137882140143
Validation loss: 2.5146161301398537

Epoch: 5| Step: 5
Training loss: 2.0373006056125824
Validation loss: 2.5309119607139494

Epoch: 5| Step: 6
Training loss: 2.8816618651891903
Validation loss: 2.528654372845474

Epoch: 5| Step: 7
Training loss: 2.4467253579558954
Validation loss: 2.53507400246048

Epoch: 5| Step: 8
Training loss: 2.4027400984654843
Validation loss: 2.502700193840663

Epoch: 5| Step: 9
Training loss: 2.6975020650974177
Validation loss: 2.513137033309279

Epoch: 5| Step: 10
Training loss: 2.603622399993057
Validation loss: 2.5257661151363706

Epoch: 5| Step: 11
Training loss: 2.9407278953006206
Validation loss: 2.5286493618931036

Epoch: 32| Step: 0
Training loss: 2.811363414411998
Validation loss: 2.5108094574225346

Epoch: 5| Step: 1
Training loss: 2.861840357840501
Validation loss: 2.514815857878651

Epoch: 5| Step: 2
Training loss: 2.316162817066173
Validation loss: 2.5313936161381907

Epoch: 5| Step: 3
Training loss: 2.502660480121058
Validation loss: 2.5248996801244874

Epoch: 5| Step: 4
Training loss: 2.9909297201916143
Validation loss: 2.528498374549706

Epoch: 5| Step: 5
Training loss: 2.35424529987995
Validation loss: 2.522401756570055

Epoch: 5| Step: 6
Training loss: 2.681777005988953
Validation loss: 2.5348531250849966

Epoch: 5| Step: 7
Training loss: 1.872606530004913
Validation loss: 2.5389620599687794

Epoch: 5| Step: 8
Training loss: 2.3344793457241795
Validation loss: 2.515526277962543

Epoch: 5| Step: 9
Training loss: 2.009503554151913
Validation loss: 2.532195332691705

Epoch: 5| Step: 10
Training loss: 2.5926667674620374
Validation loss: 2.5044299890650015

Epoch: 5| Step: 11
Training loss: 3.196129580166125
Validation loss: 2.534400027771219

Epoch: 33| Step: 0
Training loss: 2.5855787322229586
Validation loss: 2.5271919987129317

Epoch: 5| Step: 1
Training loss: 1.8687238557447543
Validation loss: 2.501661102461128

Epoch: 5| Step: 2
Training loss: 2.4385811779846684
Validation loss: 2.535684386552961

Epoch: 5| Step: 3
Training loss: 2.793777455444606
Validation loss: 2.5230425081649845

Epoch: 5| Step: 4
Training loss: 2.974256207746543
Validation loss: 2.5367251509763964

Epoch: 5| Step: 5
Training loss: 2.5657920160422556
Validation loss: 2.518184187420667

Epoch: 5| Step: 6
Training loss: 2.759857025036808
Validation loss: 2.520841926896341

Epoch: 5| Step: 7
Training loss: 2.677797501791688
Validation loss: 2.5031331654707953

Epoch: 5| Step: 8
Training loss: 2.1022960417858254
Validation loss: 2.5135920071504434

Epoch: 5| Step: 9
Training loss: 2.447233475384895
Validation loss: 2.5431864889890576

Epoch: 5| Step: 10
Training loss: 2.1318314640069875
Validation loss: 2.527753235682679

Epoch: 5| Step: 11
Training loss: 2.3746686001505077
Validation loss: 2.522372750436536

Epoch: 34| Step: 0
Training loss: 2.1578266074280874
Validation loss: 2.5308392450468546

Epoch: 5| Step: 1
Training loss: 2.375233488150161
Validation loss: 2.53865515742599

Epoch: 5| Step: 2
Training loss: 2.7054769173834
Validation loss: 2.5414711389740967

Epoch: 5| Step: 3
Training loss: 2.3340814163272956
Validation loss: 2.535496001751159

Epoch: 5| Step: 4
Training loss: 2.3218992825004645
Validation loss: 2.5783596355902487

Epoch: 5| Step: 5
Training loss: 2.48717278863568
Validation loss: 2.569670911136415

Epoch: 5| Step: 6
Training loss: 3.167255815278277
Validation loss: 2.5527817970546796

Epoch: 5| Step: 7
Training loss: 2.475271183146353
Validation loss: 2.5562489585749986

Epoch: 5| Step: 8
Training loss: 2.282070691617709
Validation loss: 2.5139219015955936

Epoch: 5| Step: 9
Training loss: 2.6458430452744266
Validation loss: 2.513753992896669

Epoch: 5| Step: 10
Training loss: 2.6950667559507244
Validation loss: 2.5272541649342877

Epoch: 5| Step: 11
Training loss: 2.520756670414018
Validation loss: 2.5318916865351153

Epoch: 35| Step: 0
Training loss: 2.67802640183691
Validation loss: 2.512456944636037

Epoch: 5| Step: 1
Training loss: 2.7163547180747103
Validation loss: 2.531558296675097

Epoch: 5| Step: 2
Training loss: 2.129048473962014
Validation loss: 2.5240162893283262

Epoch: 5| Step: 3
Training loss: 2.297773639542825
Validation loss: 2.5303971655278605

Epoch: 5| Step: 4
Training loss: 2.1738849368558966
Validation loss: 2.516783982399362

Epoch: 5| Step: 5
Training loss: 3.0952275918775376
Validation loss: 2.527020134467103

Epoch: 5| Step: 6
Training loss: 2.587021707013885
Validation loss: 2.519739103984617

Epoch: 5| Step: 7
Training loss: 2.623619079667495
Validation loss: 2.521123252044293

Epoch: 5| Step: 8
Training loss: 2.6362731104887325
Validation loss: 2.517144220297009

Epoch: 5| Step: 9
Training loss: 2.236348807559927
Validation loss: 2.506545958163787

Epoch: 5| Step: 10
Training loss: 2.3457012954692074
Validation loss: 2.532124870505302

Epoch: 5| Step: 11
Training loss: 1.6324895512011353
Validation loss: 2.530051646296012

Epoch: 36| Step: 0
Training loss: 2.8016544188671038
Validation loss: 2.5138690814812152

Epoch: 5| Step: 1
Training loss: 2.4216656994363737
Validation loss: 2.532240944441599

Epoch: 5| Step: 2
Training loss: 2.577360930071899
Validation loss: 2.527495496106309

Epoch: 5| Step: 3
Training loss: 1.9142199393158088
Validation loss: 2.538891494078613

Epoch: 5| Step: 4
Training loss: 2.3425797656309393
Validation loss: 2.5164707847072627

Epoch: 5| Step: 5
Training loss: 2.9413936052392553
Validation loss: 2.5235164736268048

Epoch: 5| Step: 6
Training loss: 1.8939307450761698
Validation loss: 2.5200204063906275

Epoch: 5| Step: 7
Training loss: 2.8490236450370974
Validation loss: 2.5307773611929854

Epoch: 5| Step: 8
Training loss: 2.42788423304326
Validation loss: 2.521139699010646

Epoch: 5| Step: 9
Training loss: 2.7371807417365317
Validation loss: 2.51196201069986

Epoch: 5| Step: 10
Training loss: 2.3053539282432434
Validation loss: 2.5431615050314496

Epoch: 5| Step: 11
Training loss: 2.2749366667598805
Validation loss: 2.5075926005924

Epoch: 37| Step: 0
Training loss: 1.8685403814732089
Validation loss: 2.510887039934077

Epoch: 5| Step: 1
Training loss: 1.7947381623968774
Validation loss: 2.5290570355262862

Epoch: 5| Step: 2
Training loss: 1.900486785870834
Validation loss: 2.5293992501728555

Epoch: 5| Step: 3
Training loss: 2.920783507121196
Validation loss: 2.561233451737674

Epoch: 5| Step: 4
Training loss: 2.573569880255508
Validation loss: 2.554088063350355

Epoch: 5| Step: 5
Training loss: 3.372727794829452
Validation loss: 2.5440939090453174

Epoch: 5| Step: 6
Training loss: 2.575921614076258
Validation loss: 2.549376458712135

Epoch: 5| Step: 7
Training loss: 2.2966012596963408
Validation loss: 2.5225377166519354

Epoch: 5| Step: 8
Training loss: 2.279912059828036
Validation loss: 2.5259982521547424

Epoch: 5| Step: 9
Training loss: 2.7637979108021176
Validation loss: 2.546624005515425

Epoch: 5| Step: 10
Training loss: 2.382545631347975
Validation loss: 2.49599626138832

Epoch: 5| Step: 11
Training loss: 3.271607681911268
Validation loss: 2.532219422498651

Epoch: 38| Step: 0
Training loss: 2.398871466427279
Validation loss: 2.524758338694613

Epoch: 5| Step: 1
Training loss: 2.440054801731986
Validation loss: 2.5306586292959565

Epoch: 5| Step: 2
Training loss: 2.3595176805212508
Validation loss: 2.5380971159033847

Epoch: 5| Step: 3
Training loss: 1.9906695997191426
Validation loss: 2.5377751613062687

Epoch: 5| Step: 4
Training loss: 2.544741058366879
Validation loss: 2.5209032645390756

Epoch: 5| Step: 5
Training loss: 2.5862295671543616
Validation loss: 2.536176279405709

Epoch: 5| Step: 6
Training loss: 2.1726683121462633
Validation loss: 2.494999006225933

Epoch: 5| Step: 7
Training loss: 1.8622507888683708
Validation loss: 2.5226648011766066

Epoch: 5| Step: 8
Training loss: 3.0262134041478053
Validation loss: 2.5274917268350383

Epoch: 5| Step: 9
Training loss: 2.638539862277597
Validation loss: 2.539810782478403

Epoch: 5| Step: 10
Training loss: 2.898558909708712
Validation loss: 2.5488947989949957

Epoch: 5| Step: 11
Training loss: 2.686662942806468
Validation loss: 2.56009740543576

Epoch: 39| Step: 0
Training loss: 2.2549388510116537
Validation loss: 2.5521428639741357

Epoch: 5| Step: 1
Training loss: 2.792580658952463
Validation loss: 2.5274212691197357

Epoch: 5| Step: 2
Training loss: 2.265867443924622
Validation loss: 2.55187968524992

Epoch: 5| Step: 3
Training loss: 2.809115768540345
Validation loss: 2.5790067571287962

Epoch: 5| Step: 4
Training loss: 2.381124930714251
Validation loss: 2.5646646862209135

Epoch: 5| Step: 5
Training loss: 3.3146165527622804
Validation loss: 2.568490693925818

Epoch: 5| Step: 6
Training loss: 2.239300400952397
Validation loss: 2.5561092826084817

Epoch: 5| Step: 7
Training loss: 2.397808775365078
Validation loss: 2.544040401387597

Epoch: 5| Step: 8
Training loss: 2.6013979931389346
Validation loss: 2.5286091501630956

Epoch: 5| Step: 9
Training loss: 2.068993144426378
Validation loss: 2.5107423299391005

Epoch: 5| Step: 10
Training loss: 1.9393182037229315
Validation loss: 2.5165217876310986

Epoch: 5| Step: 11
Training loss: 1.8034694904510225
Validation loss: 2.510028173268277

Epoch: 40| Step: 0
Training loss: 2.844115852045834
Validation loss: 2.516756687754258

Epoch: 5| Step: 1
Training loss: 2.750353183607974
Validation loss: 2.5234418776467287

Epoch: 5| Step: 2
Training loss: 2.155605717476252
Validation loss: 2.5129828705497967

Epoch: 5| Step: 3
Training loss: 2.8448180823331786
Validation loss: 2.5111024969709486

Epoch: 5| Step: 4
Training loss: 2.7081264905927664
Validation loss: 2.521573680475164

Epoch: 5| Step: 5
Training loss: 2.576171875
Validation loss: 2.505711765951759

Epoch: 5| Step: 6
Training loss: 2.844097744985609
Validation loss: 2.511525207466696

Epoch: 5| Step: 7
Training loss: 2.3067764384366054
Validation loss: 2.5153470369548403

Epoch: 5| Step: 8
Training loss: 2.036347668332808
Validation loss: 2.5055005080951416

Epoch: 5| Step: 9
Training loss: 1.8358685419646048
Validation loss: 2.5215541909714787

Epoch: 5| Step: 10
Training loss: 2.0693059813782666
Validation loss: 2.5327079012415092

Epoch: 5| Step: 11
Training loss: 3.0268834705537513
Validation loss: 2.509198052615324

Epoch: 41| Step: 0
Training loss: 3.092805814678964
Validation loss: 2.505414884198564

Epoch: 5| Step: 1
Training loss: 2.019138910488789
Validation loss: 2.5197498551981905

Epoch: 5| Step: 2
Training loss: 3.1015294455201006
Validation loss: 2.5253220086881893

Epoch: 5| Step: 3
Training loss: 2.0043828148447154
Validation loss: 2.511659794536252

Epoch: 5| Step: 4
Training loss: 2.7597002263294614
Validation loss: 2.5025577970900255

Epoch: 5| Step: 5
Training loss: 2.0169006569208348
Validation loss: 2.538817823309526

Epoch: 5| Step: 6
Training loss: 1.9747607194836791
Validation loss: 2.5288294494047814

Epoch: 5| Step: 7
Training loss: 3.075026758589271
Validation loss: 2.5147923736364803

Epoch: 5| Step: 8
Training loss: 2.3760347621827997
Validation loss: 2.504430718921901

Epoch: 5| Step: 9
Training loss: 2.098198335813059
Validation loss: 2.5014331643613334

Epoch: 5| Step: 10
Training loss: 2.2368807313967682
Validation loss: 2.51366174987793

Epoch: 5| Step: 11
Training loss: 2.005202678986211
Validation loss: 2.5042058772372324

Epoch: 42| Step: 0
Training loss: 3.058212392912097
Validation loss: 2.537589842359971

Epoch: 5| Step: 1
Training loss: 1.9971811576244753
Validation loss: 2.520615959778697

Epoch: 5| Step: 2
Training loss: 2.237372035624263
Validation loss: 2.542915945291039

Epoch: 5| Step: 3
Training loss: 3.1776143281719254
Validation loss: 2.5597013721098705

Epoch: 5| Step: 4
Training loss: 2.17627714522521
Validation loss: 2.491608088951956

Epoch: 5| Step: 5
Training loss: 2.1962380409675024
Validation loss: 2.5324929760832067

Epoch: 5| Step: 6
Training loss: 2.3012025508930796
Validation loss: 2.565060288236314

Epoch: 5| Step: 7
Training loss: 2.7798775704958305
Validation loss: 2.54672472847872

Epoch: 5| Step: 8
Training loss: 2.6081797894834664
Validation loss: 2.5662961807530453

Epoch: 5| Step: 9
Training loss: 2.1369755954946577
Validation loss: 2.573828471288881

Epoch: 5| Step: 10
Training loss: 2.408375977487317
Validation loss: 2.523113446445832

Epoch: 5| Step: 11
Training loss: 1.8504076869339847
Validation loss: 2.5487286154857216

Epoch: 43| Step: 0
Training loss: 2.712054371595405
Validation loss: 2.5590496404488308

Epoch: 5| Step: 1
Training loss: 3.3783572417964094
Validation loss: 2.5395140026372682

Epoch: 5| Step: 2
Training loss: 2.1372093181497647
Validation loss: 2.5581173732378875

Epoch: 5| Step: 3
Training loss: 2.1346126128117255
Validation loss: 2.5553947620727087

Epoch: 5| Step: 4
Training loss: 2.5382740850749617
Validation loss: 2.534414816785458

Epoch: 5| Step: 5
Training loss: 2.669905176229098
Validation loss: 2.5481491490182626

Epoch: 5| Step: 6
Training loss: 2.272752271861522
Validation loss: 2.5229408751779756

Epoch: 5| Step: 7
Training loss: 2.62105754707906
Validation loss: 2.528815295548197

Epoch: 5| Step: 8
Training loss: 2.5362725055987676
Validation loss: 2.523812308490936

Epoch: 5| Step: 9
Training loss: 1.977824475449079
Validation loss: 2.543301214389883

Epoch: 5| Step: 10
Training loss: 1.9106158306287389
Validation loss: 2.526268370113435

Epoch: 5| Step: 11
Training loss: 1.9141751003231824
Validation loss: 2.5296241263795727

Epoch: 44| Step: 0
Training loss: 2.8322356472576007
Validation loss: 2.505797231036927

Epoch: 5| Step: 1
Training loss: 2.4123521196175814
Validation loss: 2.5058215389432954

Epoch: 5| Step: 2
Training loss: 2.847185009555525
Validation loss: 2.5252639097525473

Epoch: 5| Step: 3
Training loss: 2.644097296807387
Validation loss: 2.5316703941785716

Epoch: 5| Step: 4
Training loss: 2.354192536698605
Validation loss: 2.518072915711421

Epoch: 5| Step: 5
Training loss: 2.512778810432524
Validation loss: 2.5315629702830806

Epoch: 5| Step: 6
Training loss: 2.548855345131232
Validation loss: 2.520028038234749

Epoch: 5| Step: 7
Training loss: 1.826034002148359
Validation loss: 2.497696375472347

Epoch: 5| Step: 8
Training loss: 1.893002677988132
Validation loss: 2.5428719607136294

Epoch: 5| Step: 9
Training loss: 2.0531710406153416
Validation loss: 2.5320080104892506

Epoch: 5| Step: 10
Training loss: 2.8166211769749476
Validation loss: 2.5231653426949037

Epoch: 5| Step: 11
Training loss: 2.6327014752531843
Validation loss: 2.5199947709516235

Epoch: 45| Step: 0
Training loss: 2.0425207985387512
Validation loss: 2.5552083727814185

Epoch: 5| Step: 1
Training loss: 2.168853963948992
Validation loss: 2.5623052879728445

Epoch: 5| Step: 2
Training loss: 2.766399555257449
Validation loss: 2.528918083036745

Epoch: 5| Step: 3
Training loss: 2.8567065518895003
Validation loss: 2.5799024388776832

Epoch: 5| Step: 4
Training loss: 1.9545242790300956
Validation loss: 2.5791958829327073

Epoch: 5| Step: 5
Training loss: 2.846998601882961
Validation loss: 2.596344515757988

Epoch: 5| Step: 6
Training loss: 2.9721327933606245
Validation loss: 2.6056916209709517

Epoch: 5| Step: 7
Training loss: 1.9815859681240584
Validation loss: 2.5630086649808894

Epoch: 5| Step: 8
Training loss: 2.780173103925899
Validation loss: 2.5397638574913026

Epoch: 5| Step: 9
Training loss: 2.351083294780638
Validation loss: 2.5438752148245616

Epoch: 5| Step: 10
Training loss: 2.2662105461343174
Validation loss: 2.533913302278754

Epoch: 5| Step: 11
Training loss: 2.6681670398666224
Validation loss: 2.5066078120873945

Epoch: 46| Step: 0
Training loss: 2.284047123331014
Validation loss: 2.5173887009405913

Epoch: 5| Step: 1
Training loss: 2.865500304526115
Validation loss: 2.5125350377184468

Epoch: 5| Step: 2
Training loss: 2.66685639143594
Validation loss: 2.5098915019053707

Epoch: 5| Step: 3
Training loss: 3.0033656949731746
Validation loss: 2.534477926846114

Epoch: 5| Step: 4
Training loss: 1.8003047552672211
Validation loss: 2.5130101034037478

Epoch: 5| Step: 5
Training loss: 2.4371229026774843
Validation loss: 2.5156212208405533

Epoch: 5| Step: 6
Training loss: 2.119153113262454
Validation loss: 2.5249959308289327

Epoch: 5| Step: 7
Training loss: 2.9330314574819365
Validation loss: 2.516289506738849

Epoch: 5| Step: 8
Training loss: 2.1666315026975504
Validation loss: 2.5039607065421623

Epoch: 5| Step: 9
Training loss: 2.4073966130669455
Validation loss: 2.5114387288878306

Epoch: 5| Step: 10
Training loss: 2.3718991365071633
Validation loss: 2.518795002455618

Epoch: 5| Step: 11
Training loss: 2.410110349542663
Validation loss: 2.5305508601736797

Epoch: 47| Step: 0
Training loss: 1.9440123108132588
Validation loss: 2.5105727504680604

Epoch: 5| Step: 1
Training loss: 2.13773412481897
Validation loss: 2.533870859015992

Epoch: 5| Step: 2
Training loss: 2.6441119944966247
Validation loss: 2.5205918635163904

Epoch: 5| Step: 3
Training loss: 2.7637482218087497
Validation loss: 2.546654471306619

Epoch: 5| Step: 4
Training loss: 2.487862208846933
Validation loss: 2.5504372458730513

Epoch: 5| Step: 5
Training loss: 2.1489197345866136
Validation loss: 2.568784002247649

Epoch: 5| Step: 6
Training loss: 2.453142396901639
Validation loss: 2.527470052433532

Epoch: 5| Step: 7
Training loss: 2.5578538596526754
Validation loss: 2.5609780730997334

Epoch: 5| Step: 8
Training loss: 2.862920512000329
Validation loss: 2.5242927723811173

Epoch: 5| Step: 9
Training loss: 2.789635692861912
Validation loss: 2.5239971670096066

Epoch: 5| Step: 10
Training loss: 1.995846727468294
Validation loss: 2.5282025948912894

Epoch: 5| Step: 11
Training loss: 2.0733610919594705
Validation loss: 2.5572590149286

Epoch: 48| Step: 0
Training loss: 2.397186549503166
Validation loss: 2.5299661268886764

Epoch: 5| Step: 1
Training loss: 2.9236952064080044
Validation loss: 2.534867108063858

Epoch: 5| Step: 2
Training loss: 2.622397449622971
Validation loss: 2.521487483488807

Epoch: 5| Step: 3
Training loss: 1.7152247950530266
Validation loss: 2.536967846469192

Epoch: 5| Step: 4
Training loss: 2.349209948904781
Validation loss: 2.5300940908054192

Epoch: 5| Step: 5
Training loss: 2.183832854962927
Validation loss: 2.5530905130983936

Epoch: 5| Step: 6
Training loss: 2.2575187095973597
Validation loss: 2.5052818847983325

Epoch: 5| Step: 7
Training loss: 2.6058525935104666
Validation loss: 2.54682790872611

Epoch: 5| Step: 8
Training loss: 2.7835879839447455
Validation loss: 2.521258829924378

Epoch: 5| Step: 9
Training loss: 2.2035579391282116
Validation loss: 2.5251150666825124

Epoch: 5| Step: 10
Training loss: 2.503249345565035
Validation loss: 2.5259939064675754

Epoch: 5| Step: 11
Training loss: 2.277699673355105
Validation loss: 2.517866372159503

Epoch: 49| Step: 0
Training loss: 2.9680647209699136
Validation loss: 2.5086889072500655

Epoch: 5| Step: 1
Training loss: 2.856039467696488
Validation loss: 2.5158305153310265

Epoch: 5| Step: 2
Training loss: 2.579961042036114
Validation loss: 2.5140005814138906

Epoch: 5| Step: 3
Training loss: 2.4083778584026208
Validation loss: 2.5010053798569882

Epoch: 5| Step: 4
Training loss: 2.357191882098435
Validation loss: 2.5273148674078567

Epoch: 5| Step: 5
Training loss: 2.3278505304338197
Validation loss: 2.5154490754906003

Epoch: 5| Step: 6
Training loss: 2.0561530974492506
Validation loss: 2.5298811975236064

Epoch: 5| Step: 7
Training loss: 2.6707299885466544
Validation loss: 2.52948385011502

Epoch: 5| Step: 8
Training loss: 2.159959780707146
Validation loss: 2.5229682131687734

Epoch: 5| Step: 9
Training loss: 2.198083506635345
Validation loss: 2.5374970642786945

Epoch: 5| Step: 10
Training loss: 1.8826302721154773
Validation loss: 2.5078689117266473

Epoch: 5| Step: 11
Training loss: 2.7509857491748453
Validation loss: 2.540268706378576

Epoch: 50| Step: 0
Training loss: 2.000923539553402
Validation loss: 2.5060880164726114

Epoch: 5| Step: 1
Training loss: 1.8440444193970027
Validation loss: 2.523019710791622

Epoch: 5| Step: 2
Training loss: 3.1744341368554805
Validation loss: 2.505851739647309

Epoch: 5| Step: 3
Training loss: 2.3701859925117947
Validation loss: 2.527243917341853

Epoch: 5| Step: 4
Training loss: 2.1639296287757275
Validation loss: 2.5280834414630715

Epoch: 5| Step: 5
Training loss: 2.7411261349380442
Validation loss: 2.546309593644405

Epoch: 5| Step: 6
Training loss: 3.161207177598796
Validation loss: 2.555024407712508

Epoch: 5| Step: 7
Training loss: 2.8328600282464063
Validation loss: 2.5576467144555504

Epoch: 5| Step: 8
Training loss: 2.3243883087113635
Validation loss: 2.574964759641072

Epoch: 5| Step: 9
Training loss: 2.339469561325631
Validation loss: 2.5580065919829935

Epoch: 5| Step: 10
Training loss: 1.4861460510297952
Validation loss: 2.5347395967442536

Epoch: 5| Step: 11
Training loss: 1.2059919703929554
Validation loss: 2.5159487348166767

Epoch: 51| Step: 0
Training loss: 2.780344783616538
Validation loss: 2.5262667617921286

Epoch: 5| Step: 1
Training loss: 2.7664120518672832
Validation loss: 2.5271386913851925

Epoch: 5| Step: 2
Training loss: 2.2456977826922673
Validation loss: 2.5270001208785

Epoch: 5| Step: 3
Training loss: 1.9507655426114103
Validation loss: 2.5285419726952387

Epoch: 5| Step: 4
Training loss: 2.6636317287988254
Validation loss: 2.5273081577001877

Epoch: 5| Step: 5
Training loss: 2.130610184823604
Validation loss: 2.5008998403780662

Epoch: 5| Step: 6
Training loss: 2.1601912373197916
Validation loss: 2.492474227562866

Epoch: 5| Step: 7
Training loss: 2.0664110958857407
Validation loss: 2.5074663646289217

Epoch: 5| Step: 8
Training loss: 2.1569023803989267
Validation loss: 2.531659721055673

Epoch: 5| Step: 9
Training loss: 3.4977830950324833
Validation loss: 2.5211897209285867

Epoch: 5| Step: 10
Training loss: 2.2717086668136433
Validation loss: 2.5107451431096774

Epoch: 5| Step: 11
Training loss: 0.8726626239704341
Validation loss: 2.5220968623932576

Epoch: 52| Step: 0
Training loss: 2.9776980819602197
Validation loss: 2.53888511624973

Epoch: 5| Step: 1
Training loss: 2.635660233129823
Validation loss: 2.5348272830202765

Epoch: 5| Step: 2
Training loss: 2.9118432806726964
Validation loss: 2.5420694475014063

Epoch: 5| Step: 3
Training loss: 2.7224486174695683
Validation loss: 2.514117035749439

Epoch: 5| Step: 4
Training loss: 1.8389617036666344
Validation loss: 2.5219419119906767

Epoch: 5| Step: 5
Training loss: 1.8354302537511165
Validation loss: 2.546165808326843

Epoch: 5| Step: 6
Training loss: 1.9639280092598659
Validation loss: 2.5769806913649953

Epoch: 5| Step: 7
Training loss: 2.379691860222532
Validation loss: 2.567313612078721

Epoch: 5| Step: 8
Training loss: 1.963200088323142
Validation loss: 2.584277931429252

Epoch: 5| Step: 9
Training loss: 2.9315205853796904
Validation loss: 2.5565019360589742

Epoch: 5| Step: 10
Training loss: 2.476707285791397
Validation loss: 2.5354939859324324

Epoch: 5| Step: 11
Training loss: 1.559137388179084
Validation loss: 2.53419199250259

Epoch: 53| Step: 0
Training loss: 3.113348334342328
Validation loss: 2.512914634924727

Epoch: 5| Step: 1
Training loss: 2.1569113339171757
Validation loss: 2.5043458557654454

Epoch: 5| Step: 2
Training loss: 2.6094022281162683
Validation loss: 2.5157302889696957

Epoch: 5| Step: 3
Training loss: 2.2207512225442185
Validation loss: 2.491802096088571

Epoch: 5| Step: 4
Training loss: 2.272510037877373
Validation loss: 2.4983096249261108

Epoch: 5| Step: 5
Training loss: 2.0488420891445003
Validation loss: 2.4968921934513784

Epoch: 5| Step: 6
Training loss: 2.192431966319803
Validation loss: 2.507569623140939

Epoch: 5| Step: 7
Training loss: 2.264895196641562
Validation loss: 2.5267621746439866

Epoch: 5| Step: 8
Training loss: 2.291869541782759
Validation loss: 2.499547380959421

Epoch: 5| Step: 9
Training loss: 2.947154635190625
Validation loss: 2.526406339821975

Epoch: 5| Step: 10
Training loss: 2.563965355185271
Validation loss: 2.503343865156136

Epoch: 5| Step: 11
Training loss: 1.8856481195789372
Validation loss: 2.5152956073636235

Epoch: 54| Step: 0
Training loss: 2.6900622551389843
Validation loss: 2.5062125896854957

Epoch: 5| Step: 1
Training loss: 2.5115326950433046
Validation loss: 2.52085238967082

Epoch: 5| Step: 2
Training loss: 2.0992571016250356
Validation loss: 2.5350703071560607

Epoch: 5| Step: 3
Training loss: 2.3876415909728492
Validation loss: 2.5403254766825354

Epoch: 5| Step: 4
Training loss: 2.4183257645169345
Validation loss: 2.55991044271549

Epoch: 5| Step: 5
Training loss: 2.4882257715864458
Validation loss: 2.597231344018876

Epoch: 5| Step: 6
Training loss: 2.1513216392207926
Validation loss: 2.6094674800238384

Epoch: 5| Step: 7
Training loss: 2.5861631911520067
Validation loss: 2.591258721632142

Epoch: 5| Step: 8
Training loss: 1.9926650129502599
Validation loss: 2.6102766184877377

Epoch: 5| Step: 9
Training loss: 2.7401174355839233
Validation loss: 2.5732683965806817

Epoch: 5| Step: 10
Training loss: 2.419923943987463
Validation loss: 2.5572558294971888

Epoch: 5| Step: 11
Training loss: 3.3622893710622677
Validation loss: 2.5491127332706087

Epoch: 55| Step: 0
Training loss: 1.7935725506459286
Validation loss: 2.5225871142312353

Epoch: 5| Step: 1
Training loss: 1.6547208960948
Validation loss: 2.5569891093497943

Epoch: 5| Step: 2
Training loss: 2.40836399899223
Validation loss: 2.512758208998772

Epoch: 5| Step: 3
Training loss: 2.548790147286509
Validation loss: 2.512295733320251

Epoch: 5| Step: 4
Training loss: 2.501767677980392
Validation loss: 2.5432305931219075

Epoch: 5| Step: 5
Training loss: 2.4219290450434037
Validation loss: 2.5385078059022543

Epoch: 5| Step: 6
Training loss: 2.76849526639275
Validation loss: 2.5541164759381654

Epoch: 5| Step: 7
Training loss: 2.470318645973933
Validation loss: 2.558843535443834

Epoch: 5| Step: 8
Training loss: 2.2510328041713037
Validation loss: 2.5316108634763865

Epoch: 5| Step: 9
Training loss: 2.9882981642699415
Validation loss: 2.5309513528098315

Epoch: 5| Step: 10
Training loss: 2.4161446983256343
Validation loss: 2.508599396521764

Epoch: 5| Step: 11
Training loss: 2.4188030818664084
Validation loss: 2.522342629389796

Epoch: 56| Step: 0
Training loss: 2.690569610557242
Validation loss: 2.510634267775815

Epoch: 5| Step: 1
Training loss: 2.022782031789961
Validation loss: 2.502465320007689

Epoch: 5| Step: 2
Training loss: 2.308110478611418
Validation loss: 2.5124224937086534

Epoch: 5| Step: 3
Training loss: 2.8655028006187684
Validation loss: 2.512534705597673

Epoch: 5| Step: 4
Training loss: 2.1985081122471892
Validation loss: 2.504875697670512

Epoch: 5| Step: 5
Training loss: 2.2674988462535612
Validation loss: 2.520265965939695

Epoch: 5| Step: 6
Training loss: 1.9462282407667608
Validation loss: 2.5244271391794912

Epoch: 5| Step: 7
Training loss: 2.7876518379220556
Validation loss: 2.5227861774403406

Epoch: 5| Step: 8
Training loss: 2.303263906692164
Validation loss: 2.4976802891988465

Epoch: 5| Step: 9
Training loss: 2.445140113482364
Validation loss: 2.510142288936951

Epoch: 5| Step: 10
Training loss: 1.854254459774337
Validation loss: 2.513440192353677

Epoch: 5| Step: 11
Training loss: 4.0014593323349015
Validation loss: 2.543765976845495

Epoch: 57| Step: 0
Training loss: 1.9926160762772025
Validation loss: 2.528851114119256

Epoch: 5| Step: 1
Training loss: 2.7708292987383003
Validation loss: 2.560334538962798

Epoch: 5| Step: 2
Training loss: 2.574144376800479
Validation loss: 2.5261613732253316

Epoch: 5| Step: 3
Training loss: 2.4308749422006763
Validation loss: 2.527549998590343

Epoch: 5| Step: 4
Training loss: 2.398929905747141
Validation loss: 2.539094619547818

Epoch: 5| Step: 5
Training loss: 2.9753745604586346
Validation loss: 2.5324794546400433

Epoch: 5| Step: 6
Training loss: 2.7459145456285654
Validation loss: 2.5228365683552396

Epoch: 5| Step: 7
Training loss: 1.6603384837941395
Validation loss: 2.5140591757503237

Epoch: 5| Step: 8
Training loss: 2.3019459080708393
Validation loss: 2.51464602374606

Epoch: 5| Step: 9
Training loss: 2.3717458415895174
Validation loss: 2.542145818092343

Epoch: 5| Step: 10
Training loss: 2.1349115906396245
Validation loss: 2.532530107705189

Epoch: 5| Step: 11
Training loss: 1.2257447158883195
Validation loss: 2.554374850678912

Epoch: 58| Step: 0
Training loss: 2.264271088252507
Validation loss: 2.5296576283171492

Epoch: 5| Step: 1
Training loss: 2.524663196422662
Validation loss: 2.5452719443009437

Epoch: 5| Step: 2
Training loss: 2.3243064543260696
Validation loss: 2.537096500731144

Epoch: 5| Step: 3
Training loss: 2.399980775438242
Validation loss: 2.527761832575292

Epoch: 5| Step: 4
Training loss: 2.2723341948701714
Validation loss: 2.5150154058346073

Epoch: 5| Step: 5
Training loss: 2.9133767965233246
Validation loss: 2.5391277207043075

Epoch: 5| Step: 6
Training loss: 2.499750029464616
Validation loss: 2.4952094671276486

Epoch: 5| Step: 7
Training loss: 2.2944507910779484
Validation loss: 2.5321749696527855

Epoch: 5| Step: 8
Training loss: 2.1016583615813804
Validation loss: 2.5112352039248753

Epoch: 5| Step: 9
Training loss: 2.8351728601250312
Validation loss: 2.505600307092672

Epoch: 5| Step: 10
Training loss: 1.9033259493967964
Validation loss: 2.514372673839581

Epoch: 5| Step: 11
Training loss: 2.0540522184336614
Validation loss: 2.5100995624598843

Epoch: 59| Step: 0
Training loss: 2.4552920543416086
Validation loss: 2.5102515100362446

Epoch: 5| Step: 1
Training loss: 1.8295878890602049
Validation loss: 2.526518471278569

Epoch: 5| Step: 2
Training loss: 2.998964766857317
Validation loss: 2.5376758584186723

Epoch: 5| Step: 3
Training loss: 2.596156187681354
Validation loss: 2.554250043925957

Epoch: 5| Step: 4
Training loss: 2.807214135471781
Validation loss: 2.55448456248852

Epoch: 5| Step: 5
Training loss: 2.882144343989781
Validation loss: 2.5635396468862313

Epoch: 5| Step: 6
Training loss: 2.0279535394496846
Validation loss: 2.575680716514487

Epoch: 5| Step: 7
Training loss: 2.872427909351493
Validation loss: 2.543057140839677

Epoch: 5| Step: 8
Training loss: 1.989029479370758
Validation loss: 2.5525101531832797

Epoch: 5| Step: 9
Training loss: 1.8248337683023748
Validation loss: 2.535730329267072

Epoch: 5| Step: 10
Training loss: 1.493999718897128
Validation loss: 2.5390774183568645

Epoch: 5| Step: 11
Training loss: 2.461974297966503
Validation loss: 2.548076537339394

Epoch: 60| Step: 0
Training loss: 2.186650356410225
Validation loss: 2.544357842344029

Epoch: 5| Step: 1
Training loss: 2.3598230201827577
Validation loss: 2.5241799261345816

Epoch: 5| Step: 2
Training loss: 2.2317170025725783
Validation loss: 2.5043439755264623

Epoch: 5| Step: 3
Training loss: 2.117551765214498
Validation loss: 2.5134002451839303

Epoch: 5| Step: 4
Training loss: 2.3084960503729266
Validation loss: 2.5197428887955073

Epoch: 5| Step: 5
Training loss: 2.0583158880979697
Validation loss: 2.531286584723178

Epoch: 5| Step: 6
Training loss: 2.868223413743682
Validation loss: 2.5228641004202346

Epoch: 5| Step: 7
Training loss: 2.3593913702996856
Validation loss: 2.5238160852254206

Epoch: 5| Step: 8
Training loss: 2.399334072072999
Validation loss: 2.5379695828969613

Epoch: 5| Step: 9
Training loss: 2.584918233290297
Validation loss: 2.5377642515860415

Epoch: 5| Step: 10
Training loss: 2.819519269563162
Validation loss: 2.5419884104144357

Epoch: 5| Step: 11
Training loss: 2.1546257646442792
Validation loss: 2.5169347784980856

Epoch: 61| Step: 0
Training loss: 2.323433161451218
Validation loss: 2.5227890716867343

Epoch: 5| Step: 1
Training loss: 1.885867730519662
Validation loss: 2.509282894193953

Epoch: 5| Step: 2
Training loss: 2.552074998076445
Validation loss: 2.535919591778169

Epoch: 5| Step: 3
Training loss: 2.471776531587541
Validation loss: 2.5255162797130133

Epoch: 5| Step: 4
Training loss: 2.8118936520865314
Validation loss: 2.5091906610083003

Epoch: 5| Step: 5
Training loss: 2.677173558556538
Validation loss: 2.517132250295715

Epoch: 5| Step: 6
Training loss: 2.087163671936374
Validation loss: 2.505558684681444

Epoch: 5| Step: 7
Training loss: 2.5147802225783256
Validation loss: 2.5148303709911666

Epoch: 5| Step: 8
Training loss: 2.383719949997967
Validation loss: 2.5097325225111584

Epoch: 5| Step: 9
Training loss: 2.0821693474809764
Validation loss: 2.5191123357860294

Epoch: 5| Step: 10
Training loss: 2.1668240661180365
Validation loss: 2.519084881022678

Epoch: 5| Step: 11
Training loss: 1.4849250175991533
Validation loss: 2.5334014932556523

Epoch: 62| Step: 0
Training loss: 2.1344364676833125
Validation loss: 2.543385816712111

Epoch: 5| Step: 1
Training loss: 2.496684164266893
Validation loss: 2.5204557472319116

Epoch: 5| Step: 2
Training loss: 2.13571673510211
Validation loss: 2.524660276780941

Epoch: 5| Step: 3
Training loss: 2.318913201606406
Validation loss: 2.511790850500823

Epoch: 5| Step: 4
Training loss: 2.736759301575855
Validation loss: 2.550090359352194

Epoch: 5| Step: 5
Training loss: 2.3966010701837117
Validation loss: 2.51736998603981

Epoch: 5| Step: 6
Training loss: 2.7290387208567237
Validation loss: 2.5170243776122487

Epoch: 5| Step: 7
Training loss: 2.0782684047236906
Validation loss: 2.5251295520733947

Epoch: 5| Step: 8
Training loss: 2.3627380251186962
Validation loss: 2.515100116348613

Epoch: 5| Step: 9
Training loss: 2.7206617627419423
Validation loss: 2.537216047237663

Epoch: 5| Step: 10
Training loss: 1.840195543223215
Validation loss: 2.5287217869664214

Epoch: 5| Step: 11
Training loss: 2.0064054672516556
Validation loss: 2.553502302722006

Epoch: 63| Step: 0
Training loss: 2.9143252829528823
Validation loss: 2.5336352989231745

Epoch: 5| Step: 1
Training loss: 2.29299360063594
Validation loss: 2.5221058350290364

Epoch: 5| Step: 2
Training loss: 2.3066912717370545
Validation loss: 2.5279026464971888

Epoch: 5| Step: 3
Training loss: 2.3593679263785727
Validation loss: 2.5486008777869156

Epoch: 5| Step: 4
Training loss: 2.5640569469477783
Validation loss: 2.5360301176540605

Epoch: 5| Step: 5
Training loss: 2.172599945929975
Validation loss: 2.5494323559919625

Epoch: 5| Step: 6
Training loss: 2.1523954797195017
Validation loss: 2.5611586393994816

Epoch: 5| Step: 7
Training loss: 2.2346907172528647
Validation loss: 2.559785090884295

Epoch: 5| Step: 8
Training loss: 2.6315006417620337
Validation loss: 2.5634057297381574

Epoch: 5| Step: 9
Training loss: 2.2551678543040707
Validation loss: 2.555646205125944

Epoch: 5| Step: 10
Training loss: 1.950647232041419
Validation loss: 2.5026253187626706

Epoch: 5| Step: 11
Training loss: 3.0015280328903415
Validation loss: 2.523025150287242

Epoch: 64| Step: 0
Training loss: 1.8840093330629977
Validation loss: 2.5247627494631875

Epoch: 5| Step: 1
Training loss: 2.4769926930990853
Validation loss: 2.504610288988241

Epoch: 5| Step: 2
Training loss: 2.1035308128949146
Validation loss: 2.5305401980316407

Epoch: 5| Step: 3
Training loss: 2.4615891335617897
Validation loss: 2.542202554293596

Epoch: 5| Step: 4
Training loss: 2.056258032878734
Validation loss: 2.5637230203015826

Epoch: 5| Step: 5
Training loss: 2.377626873686465
Validation loss: 2.539768179617304

Epoch: 5| Step: 6
Training loss: 2.6560236217298616
Validation loss: 2.5564225319710947

Epoch: 5| Step: 7
Training loss: 2.4766305619282623
Validation loss: 2.582604025881003

Epoch: 5| Step: 8
Training loss: 2.775498948476541
Validation loss: 2.560203787259775

Epoch: 5| Step: 9
Training loss: 2.1813912244839004
Validation loss: 2.5538251278731394

Epoch: 5| Step: 10
Training loss: 2.4476079434992375
Validation loss: 2.5325445506842743

Epoch: 5| Step: 11
Training loss: 2.7464443975931947
Validation loss: 2.551687845739786

Epoch: 65| Step: 0
Training loss: 1.7037359419289588
Validation loss: 2.5271499614522788

Epoch: 5| Step: 1
Training loss: 2.2052764127659055
Validation loss: 2.5244883857770164

Epoch: 5| Step: 2
Training loss: 2.2156459963386093
Validation loss: 2.553602587101393

Epoch: 5| Step: 3
Training loss: 2.367312185698816
Validation loss: 2.5307692671730773

Epoch: 5| Step: 4
Training loss: 2.6134263071077988
Validation loss: 2.5354135947938947

Epoch: 5| Step: 5
Training loss: 2.7001256454337734
Validation loss: 2.559942023221791

Epoch: 5| Step: 6
Training loss: 1.787507560020412
Validation loss: 2.5432144491683992

Epoch: 5| Step: 7
Training loss: 2.129726650804562
Validation loss: 2.5177222605961753

Epoch: 5| Step: 8
Training loss: 2.9496471775943034
Validation loss: 2.5490806016072334

Epoch: 5| Step: 9
Training loss: 3.090796862569021
Validation loss: 2.571785042179488

Epoch: 5| Step: 10
Training loss: 1.8743054693083123
Validation loss: 2.5280516751740483

Epoch: 5| Step: 11
Training loss: 1.822917073567663
Validation loss: 2.4855083543525405

Epoch: 66| Step: 0
Training loss: 2.6865805894048105
Validation loss: 2.5323161246529446

Epoch: 5| Step: 1
Training loss: 2.6845813250046953
Validation loss: 2.5479559291539577

Epoch: 5| Step: 2
Training loss: 2.6316699709961116
Validation loss: 2.521303575703339

Epoch: 5| Step: 3
Training loss: 2.607111971722612
Validation loss: 2.508898023766199

Epoch: 5| Step: 4
Training loss: 2.315010666791758
Validation loss: 2.531606806030001

Epoch: 5| Step: 5
Training loss: 1.8336215731862926
Validation loss: 2.4890725810295216

Epoch: 5| Step: 6
Training loss: 2.5090083898386553
Validation loss: 2.528999866932576

Epoch: 5| Step: 7
Training loss: 2.3967320843479913
Validation loss: 2.5119658487530976

Epoch: 5| Step: 8
Training loss: 2.2346357713595406
Validation loss: 2.503103229620118

Epoch: 5| Step: 9
Training loss: 1.9077472747475335
Validation loss: 2.5097510153101545

Epoch: 5| Step: 10
Training loss: 1.798252672231368
Validation loss: 2.5357835225797856

Epoch: 5| Step: 11
Training loss: 2.7574981423836036
Validation loss: 2.523657105203491

Epoch: 67| Step: 0
Training loss: 2.16898928155005
Validation loss: 2.5106571914607083

Epoch: 5| Step: 1
Training loss: 1.9209683148115717
Validation loss: 2.5998789291436513

Epoch: 5| Step: 2
Training loss: 2.3069581306669593
Validation loss: 2.6222338880571967

Epoch: 5| Step: 3
Training loss: 2.925975512993354
Validation loss: 2.6131896348374464

Epoch: 5| Step: 4
Training loss: 2.1619913815053966
Validation loss: 2.625352419553607

Epoch: 5| Step: 5
Training loss: 1.6637084297701716
Validation loss: 2.6257216884429715

Epoch: 5| Step: 6
Training loss: 2.8649214851312763
Validation loss: 2.6003423699211883

Epoch: 5| Step: 7
Training loss: 2.8226512394704093
Validation loss: 2.594516575760405

Epoch: 5| Step: 8
Training loss: 1.9322723497383159
Validation loss: 2.5969647971555667

Epoch: 5| Step: 9
Training loss: 2.050205578614325
Validation loss: 2.5600260484445565

Epoch: 5| Step: 10
Training loss: 2.9477740861000705
Validation loss: 2.528993356135747

Epoch: 5| Step: 11
Training loss: 0.8213405162101894
Validation loss: 2.554814552313086

Epoch: 68| Step: 0
Training loss: 2.424772141753243
Validation loss: 2.5336472850581533

Epoch: 5| Step: 1
Training loss: 2.0655753587075925
Validation loss: 2.542106599464192

Epoch: 5| Step: 2
Training loss: 2.1574820716440106
Validation loss: 2.517209120945076

Epoch: 5| Step: 3
Training loss: 2.532088341050194
Validation loss: 2.5005665494785014

Epoch: 5| Step: 4
Training loss: 2.418544029120553
Validation loss: 2.523752891585476

Epoch: 5| Step: 5
Training loss: 2.144790383613824
Validation loss: 2.5190173943494365

Epoch: 5| Step: 6
Training loss: 2.720798904255638
Validation loss: 2.510890216932133

Epoch: 5| Step: 7
Training loss: 2.7942943921596615
Validation loss: 2.5245954142200278

Epoch: 5| Step: 8
Training loss: 2.1703653920967274
Validation loss: 2.5092282364342875

Epoch: 5| Step: 9
Training loss: 1.9408483183257585
Validation loss: 2.507479482150352

Epoch: 5| Step: 10
Training loss: 2.463421249403796
Validation loss: 2.502407198540331

Epoch: 5| Step: 11
Training loss: 1.2035354310522886
Validation loss: 2.5287590996739904

Epoch: 69| Step: 0
Training loss: 2.2357487223631236
Validation loss: 2.5302195433463455

Epoch: 5| Step: 1
Training loss: 2.8705293476921487
Validation loss: 2.5681407221367567

Epoch: 5| Step: 2
Training loss: 2.268976718303995
Validation loss: 2.539585752123546

Epoch: 5| Step: 3
Training loss: 1.6733158355851765
Validation loss: 2.540549538255325

Epoch: 5| Step: 4
Training loss: 3.051007720317344
Validation loss: 2.5533989116980615

Epoch: 5| Step: 5
Training loss: 2.3543528480388933
Validation loss: 2.5468155360544795

Epoch: 5| Step: 6
Training loss: 2.2119808902708313
Validation loss: 2.5582046212882075

Epoch: 5| Step: 7
Training loss: 2.3438698292935047
Validation loss: 2.571349617872464

Epoch: 5| Step: 8
Training loss: 2.462246888605608
Validation loss: 2.5537815529157277

Epoch: 5| Step: 9
Training loss: 1.7566270009556526
Validation loss: 2.5493518822249888

Epoch: 5| Step: 10
Training loss: 2.1716240387970815
Validation loss: 2.5900261969573184

Epoch: 5| Step: 11
Training loss: 1.9441967564213873
Validation loss: 2.56836244609538

Epoch: 70| Step: 0
Training loss: 2.157891574656529
Validation loss: 2.6035575968246443

Epoch: 5| Step: 1
Training loss: 2.15155779270829
Validation loss: 2.5511973938789785

Epoch: 5| Step: 2
Training loss: 2.4140716848846813
Validation loss: 2.512881451366696

Epoch: 5| Step: 3
Training loss: 2.529211471470789
Validation loss: 2.518280708603425

Epoch: 5| Step: 4
Training loss: 2.770936251762972
Validation loss: 2.51439190688752

Epoch: 5| Step: 5
Training loss: 1.7953656035189802
Validation loss: 2.5144537021331494

Epoch: 5| Step: 6
Training loss: 2.542291178872197
Validation loss: 2.517443128250907

Epoch: 5| Step: 7
Training loss: 2.734612678007301
Validation loss: 2.5258201082471343

Epoch: 5| Step: 8
Training loss: 1.6489158044930634
Validation loss: 2.5126660124494586

Epoch: 5| Step: 9
Training loss: 2.424816879751869
Validation loss: 2.5356386310604977

Epoch: 5| Step: 10
Training loss: 2.5117595663358365
Validation loss: 2.5170041562729213

Epoch: 5| Step: 11
Training loss: 1.4166351857146946
Validation loss: 2.528087756051944

Epoch: 71| Step: 0
Training loss: 2.4237196265565695
Validation loss: 2.5287362241974747

Epoch: 5| Step: 1
Training loss: 2.1531481338830574
Validation loss: 2.526511387886983

Epoch: 5| Step: 2
Training loss: 2.273867746652465
Validation loss: 2.546933136414943

Epoch: 5| Step: 3
Training loss: 2.1857814032314398
Validation loss: 2.5609434874462482

Epoch: 5| Step: 4
Training loss: 1.9595769288384701
Validation loss: 2.574552715983977

Epoch: 5| Step: 5
Training loss: 2.520247483286941
Validation loss: 2.5832594519992047

Epoch: 5| Step: 6
Training loss: 1.725186451220096
Validation loss: 2.5890826664785562

Epoch: 5| Step: 7
Training loss: 3.3539202739814242
Validation loss: 2.6420992830702765

Epoch: 5| Step: 8
Training loss: 2.125387156504188
Validation loss: 2.6042743253706724

Epoch: 5| Step: 9
Training loss: 2.3420581051519016
Validation loss: 2.575675162592342

Epoch: 5| Step: 10
Training loss: 2.111733481482444
Validation loss: 2.5658649123320565

Epoch: 5| Step: 11
Training loss: 2.439537859285735
Validation loss: 2.561172599001504

Epoch: 72| Step: 0
Training loss: 2.4451131038599674
Validation loss: 2.552484306962221

Epoch: 5| Step: 1
Training loss: 2.6675903588161227
Validation loss: 2.5648218080184546

Epoch: 5| Step: 2
Training loss: 2.1439389381894287
Validation loss: 2.5295483477661427

Epoch: 5| Step: 3
Training loss: 2.1975223374343544
Validation loss: 2.519688055792294

Epoch: 5| Step: 4
Training loss: 2.2006836479192082
Validation loss: 2.505104609355935

Epoch: 5| Step: 5
Training loss: 2.681172129249411
Validation loss: 2.50329435174876

Epoch: 5| Step: 6
Training loss: 2.0485711677522223
Validation loss: 2.530210937136403

Epoch: 5| Step: 7
Training loss: 2.8783500061553617
Validation loss: 2.508012603191942

Epoch: 5| Step: 8
Training loss: 2.3200982505448766
Validation loss: 2.5119149866565382

Epoch: 5| Step: 9
Training loss: 1.8906843317983926
Validation loss: 2.5331883995002666

Epoch: 5| Step: 10
Training loss: 2.1882538722599008
Validation loss: 2.5389717868348223

Epoch: 5| Step: 11
Training loss: 2.1823506373872177
Validation loss: 2.535350206319561

Epoch: 73| Step: 0
Training loss: 2.5056171255542226
Validation loss: 2.5273215220681085

Epoch: 5| Step: 1
Training loss: 2.0868295198130546
Validation loss: 2.579051404256066

Epoch: 5| Step: 2
Training loss: 2.7656751725123243
Validation loss: 2.6326030832801437

Epoch: 5| Step: 3
Training loss: 2.3365851177545847
Validation loss: 2.6265394374327347

Epoch: 5| Step: 4
Training loss: 2.0651475501744905
Validation loss: 2.665337579040937

Epoch: 5| Step: 5
Training loss: 2.241417303952243
Validation loss: 2.646283300439822

Epoch: 5| Step: 6
Training loss: 2.7302545509855833
Validation loss: 2.6218767280557764

Epoch: 5| Step: 7
Training loss: 1.4628637334289845
Validation loss: 2.630724221174996

Epoch: 5| Step: 8
Training loss: 2.0901176487056676
Validation loss: 2.6000738189989576

Epoch: 5| Step: 9
Training loss: 2.3682704752187247
Validation loss: 2.554225852699584

Epoch: 5| Step: 10
Training loss: 2.553918938708824
Validation loss: 2.5504432520493237

Epoch: 5| Step: 11
Training loss: 1.740416100943104
Validation loss: 2.5368494395481225

Epoch: 74| Step: 0
Training loss: 1.7929885630458258
Validation loss: 2.5155261831837348

Epoch: 5| Step: 1
Training loss: 2.4186039646430055
Validation loss: 2.5440069678041715

Epoch: 5| Step: 2
Training loss: 3.069776803765864
Validation loss: 2.530054049278927

Epoch: 5| Step: 3
Training loss: 2.2211644105409136
Validation loss: 2.5624909245710237

Epoch: 5| Step: 4
Training loss: 1.981956509995471
Validation loss: 2.5115471084665466

Epoch: 5| Step: 5
Training loss: 2.476701702453691
Validation loss: 2.521311987734423

Epoch: 5| Step: 6
Training loss: 1.9108612694121285
Validation loss: 2.487517308968877

Epoch: 5| Step: 7
Training loss: 2.2191757008675093
Validation loss: 2.516207408421387

Epoch: 5| Step: 8
Training loss: 2.6055834972272427
Validation loss: 2.5149714685253777

Epoch: 5| Step: 9
Training loss: 1.8496747272228973
Validation loss: 2.5217576985611507

Epoch: 5| Step: 10
Training loss: 2.2088655394303562
Validation loss: 2.5428174819138016

Epoch: 5| Step: 11
Training loss: 2.4263771787129276
Validation loss: 2.5485906458652905

Epoch: 75| Step: 0
Training loss: 2.137538271555792
Validation loss: 2.511535463819281

Epoch: 5| Step: 1
Training loss: 2.11920655319393
Validation loss: 2.538227143419856

Epoch: 5| Step: 2
Training loss: 1.887723224905186
Validation loss: 2.543896483906391

Epoch: 5| Step: 3
Training loss: 1.5034684770208067
Validation loss: 2.5308383049558616

Epoch: 5| Step: 4
Training loss: 2.2369056722153395
Validation loss: 2.5393113821267987

Epoch: 5| Step: 5
Training loss: 2.218524652776986
Validation loss: 2.510397107033621

Epoch: 5| Step: 6
Training loss: 2.576506783072102
Validation loss: 2.5567701990268334

Epoch: 5| Step: 7
Training loss: 2.2533066082485016
Validation loss: 2.5110036287776523

Epoch: 5| Step: 8
Training loss: 2.8103487052269336
Validation loss: 2.5871528927096166

Epoch: 5| Step: 9
Training loss: 2.3483332262474597
Validation loss: 2.5406434287215762

Epoch: 5| Step: 10
Training loss: 2.8988946518167134
Validation loss: 2.552580622795562

Epoch: 5| Step: 11
Training loss: 2.28746054776883
Validation loss: 2.5561634820102164

Testing loss: 2.1186142266549663
