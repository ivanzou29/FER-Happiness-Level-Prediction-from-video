Epoch: 1| Step: 0
Training loss: 8.395357811069097
Validation loss: 8.491998346930815

Epoch: 6| Step: 1
Training loss: 8.124931452535366
Validation loss: 8.460849807298905

Epoch: 6| Step: 2
Training loss: 7.9801652115854855
Validation loss: 8.42982906567973

Epoch: 6| Step: 3
Training loss: 7.997982486004552
Validation loss: 8.399784518308799

Epoch: 6| Step: 4
Training loss: 8.710080009644805
Validation loss: 8.37179982549244

Epoch: 6| Step: 5
Training loss: 8.743898716848669
Validation loss: 8.342625079003707

Epoch: 6| Step: 6
Training loss: 8.77263612560587
Validation loss: 8.312381676618122

Epoch: 6| Step: 7
Training loss: 7.928464778344864
Validation loss: 8.283827931037681

Epoch: 6| Step: 8
Training loss: 9.159638178313442
Validation loss: 8.25432993229769

Epoch: 6| Step: 9
Training loss: 8.140471766342126
Validation loss: 8.226773212532228

Epoch: 6| Step: 10
Training loss: 8.852590718357977
Validation loss: 8.193713676785311

Epoch: 6| Step: 11
Training loss: 7.802250601007248
Validation loss: 8.163450412224796

Epoch: 6| Step: 12
Training loss: 8.955428913862809
Validation loss: 8.135993679813117

Epoch: 6| Step: 13
Training loss: 7.820066404329009
Validation loss: 8.102027146476544

Epoch: 2| Step: 0
Training loss: 8.79581858388103
Validation loss: 8.068054927295373

Epoch: 6| Step: 1
Training loss: 7.734218896388688
Validation loss: 8.033281794128127

Epoch: 6| Step: 2
Training loss: 8.212987003373263
Validation loss: 7.999532209071031

Epoch: 6| Step: 3
Training loss: 8.183272107342667
Validation loss: 7.962120739394823

Epoch: 6| Step: 4
Training loss: 8.015762060231703
Validation loss: 7.924044079494457

Epoch: 6| Step: 5
Training loss: 8.068150159551465
Validation loss: 7.882458298598366

Epoch: 6| Step: 6
Training loss: 8.564043114829365
Validation loss: 7.842965095631391

Epoch: 6| Step: 7
Training loss: 8.279647268991946
Validation loss: 7.800970863173446

Epoch: 6| Step: 8
Training loss: 8.305813272561112
Validation loss: 7.753064851887598

Epoch: 6| Step: 9
Training loss: 7.558112014283659
Validation loss: 7.703089096883242

Epoch: 6| Step: 10
Training loss: 7.50530690947545
Validation loss: 7.658319725492202

Epoch: 6| Step: 11
Training loss: 6.6220906905240575
Validation loss: 7.603046101261234

Epoch: 6| Step: 12
Training loss: 7.9470657019735516
Validation loss: 7.5512222395447

Epoch: 6| Step: 13
Training loss: 6.62719517453256
Validation loss: 7.495509180676398

Epoch: 3| Step: 0
Training loss: 7.6133401241149725
Validation loss: 7.437175925324209

Epoch: 6| Step: 1
Training loss: 6.288512325508029
Validation loss: 7.3779110524320695

Epoch: 6| Step: 2
Training loss: 6.854733645594902
Validation loss: 7.31488963150128

Epoch: 6| Step: 3
Training loss: 7.356945114547004
Validation loss: 7.251843492121185

Epoch: 6| Step: 4
Training loss: 8.01679802652808
Validation loss: 7.180971138112833

Epoch: 6| Step: 5
Training loss: 7.649209035236656
Validation loss: 7.113731620003811

Epoch: 6| Step: 6
Training loss: 7.936524579045845
Validation loss: 7.037067950703199

Epoch: 6| Step: 7
Training loss: 6.465210171828753
Validation loss: 6.954577827831586

Epoch: 6| Step: 8
Training loss: 6.201501898206356
Validation loss: 6.86997071313145

Epoch: 6| Step: 9
Training loss: 7.515298626131992
Validation loss: 6.783619643908842

Epoch: 6| Step: 10
Training loss: 6.695152966302376
Validation loss: 6.691727202423912

Epoch: 6| Step: 11
Training loss: 6.23448880887662
Validation loss: 6.595262543815112

Epoch: 6| Step: 12
Training loss: 6.810271572350119
Validation loss: 6.493908840240209

Epoch: 6| Step: 13
Training loss: 6.7048969194309995
Validation loss: 6.3901221738945

Epoch: 4| Step: 0
Training loss: 6.900145443475324
Validation loss: 6.288775843056211

Epoch: 6| Step: 1
Training loss: 5.847118691891787
Validation loss: 6.178778516016888

Epoch: 6| Step: 2
Training loss: 5.433887728781211
Validation loss: 6.057668536973705

Epoch: 6| Step: 3
Training loss: 5.433928270278621
Validation loss: 5.939685994677894

Epoch: 6| Step: 4
Training loss: 6.136220502629022
Validation loss: 5.815677881589739

Epoch: 6| Step: 5
Training loss: 6.145322754766743
Validation loss: 5.6849013319934

Epoch: 6| Step: 6
Training loss: 6.490336056606433
Validation loss: 5.557301524569757

Epoch: 6| Step: 7
Training loss: 5.672476912578003
Validation loss: 5.414168099478592

Epoch: 6| Step: 8
Training loss: 5.087472241675079
Validation loss: 5.269823613408979

Epoch: 6| Step: 9
Training loss: 4.6949456653965
Validation loss: 5.1210146659527345

Epoch: 6| Step: 10
Training loss: 4.897481286566648
Validation loss: 4.957853000145634

Epoch: 6| Step: 11
Training loss: 5.262576525351499
Validation loss: 4.811344668602608

Epoch: 6| Step: 12
Training loss: 3.8464481219174202
Validation loss: 4.624828215149526

Epoch: 6| Step: 13
Training loss: 5.146898887778032
Validation loss: 4.472016907685584

Epoch: 5| Step: 0
Training loss: 4.427329645223584
Validation loss: 4.303976342916173

Epoch: 6| Step: 1
Training loss: 4.7041047048528535
Validation loss: 4.1258297480659625

Epoch: 6| Step: 2
Training loss: 3.3378290535664825
Validation loss: 3.958140934066227

Epoch: 6| Step: 3
Training loss: 3.852767662934112
Validation loss: 3.784132077153454

Epoch: 6| Step: 4
Training loss: 3.7102909850064876
Validation loss: 3.6324003908765197

Epoch: 6| Step: 5
Training loss: 3.957727218534411
Validation loss: 3.475773045204421

Epoch: 6| Step: 6
Training loss: 2.9540250506620565
Validation loss: 3.30518796000597

Epoch: 6| Step: 7
Training loss: 3.193531836656062
Validation loss: 3.1853299826251367

Epoch: 6| Step: 8
Training loss: 3.6812617666059695
Validation loss: 3.0613426045577565

Epoch: 6| Step: 9
Training loss: 3.635914780267502
Validation loss: 2.951774678665573

Epoch: 6| Step: 10
Training loss: 2.6594669384422662
Validation loss: 2.907555126434023

Epoch: 6| Step: 11
Training loss: 3.407299754919289
Validation loss: 2.855502802014778

Epoch: 6| Step: 12
Training loss: 2.5435574695355476
Validation loss: 2.7917402504480027

Epoch: 6| Step: 13
Training loss: 3.3098127873424894
Validation loss: 2.8051547172249114

Epoch: 6| Step: 0
Training loss: 2.285886572833097
Validation loss: 2.8371063009710515

Epoch: 6| Step: 1
Training loss: 2.8801710644886658
Validation loss: 2.852310925513117

Epoch: 6| Step: 2
Training loss: 2.774086116111403
Validation loss: 2.879968344615995

Epoch: 6| Step: 3
Training loss: 3.1314502522590146
Validation loss: 2.9153542335988734

Epoch: 6| Step: 4
Training loss: 2.6635283440853588
Validation loss: 2.952914168217426

Epoch: 6| Step: 5
Training loss: 3.4555354616235796
Validation loss: 2.9426138308494214

Epoch: 6| Step: 6
Training loss: 2.7476406380060983
Validation loss: 2.942543772369441

Epoch: 6| Step: 7
Training loss: 2.4528936775140657
Validation loss: 2.97009473093005

Epoch: 6| Step: 8
Training loss: 3.476894817114102
Validation loss: 2.937178898569535

Epoch: 6| Step: 9
Training loss: 3.273012994084845
Validation loss: 2.9316146073445934

Epoch: 6| Step: 10
Training loss: 2.6948378877592045
Validation loss: 2.935731003452594

Epoch: 6| Step: 11
Training loss: 2.0994158704435653
Validation loss: 2.8845689173159164

Epoch: 6| Step: 12
Training loss: 3.760958110402604
Validation loss: 2.867890634687856

Epoch: 6| Step: 13
Training loss: 3.4595032210739585
Validation loss: 2.856945527449012

Epoch: 7| Step: 0
Training loss: 3.166027673866647
Validation loss: 2.8308002190444688

Epoch: 6| Step: 1
Training loss: 1.8504741061196812
Validation loss: 2.8214592684799844

Epoch: 6| Step: 2
Training loss: 2.38898746030829
Validation loss: 2.813572255353986

Epoch: 6| Step: 3
Training loss: 2.5910724469755904
Validation loss: 2.8023651482394616

Epoch: 6| Step: 4
Training loss: 2.9458276111020236
Validation loss: 2.791555791522465

Epoch: 6| Step: 5
Training loss: 2.902566195315531
Validation loss: 2.787148596334599

Epoch: 6| Step: 6
Training loss: 2.6122648945567324
Validation loss: 2.761621778369299

Epoch: 6| Step: 7
Training loss: 2.845297591428542
Validation loss: 2.758757676927849

Epoch: 6| Step: 8
Training loss: 3.342619802971435
Validation loss: 2.7736052413145647

Epoch: 6| Step: 9
Training loss: 2.359901318992402
Validation loss: 2.761748878929758

Epoch: 6| Step: 10
Training loss: 3.000826086113069
Validation loss: 2.7846447518201525

Epoch: 6| Step: 11
Training loss: 2.5938158141828946
Validation loss: 2.7619435723792845

Epoch: 6| Step: 12
Training loss: 3.106834715799015
Validation loss: 2.7595608422212727

Epoch: 6| Step: 13
Training loss: 3.8354862359468447
Validation loss: 2.7351469421664185

Epoch: 8| Step: 0
Training loss: 2.5086750199118626
Validation loss: 2.755336222477815

Epoch: 6| Step: 1
Training loss: 2.8334331120892187
Validation loss: 2.7560477801796357

Epoch: 6| Step: 2
Training loss: 1.9239542188808672
Validation loss: 2.741965883579307

Epoch: 6| Step: 3
Training loss: 2.4100449596659153
Validation loss: 2.769409377873966

Epoch: 6| Step: 4
Training loss: 2.871094746492174
Validation loss: 2.763930971111739

Epoch: 6| Step: 5
Training loss: 2.845985791286833
Validation loss: 2.743352876047429

Epoch: 6| Step: 6
Training loss: 3.2089317721456982
Validation loss: 2.7547898915245277

Epoch: 6| Step: 7
Training loss: 2.9427036701716833
Validation loss: 2.757640181246838

Epoch: 6| Step: 8
Training loss: 3.0414975959784636
Validation loss: 2.7282324543663767

Epoch: 6| Step: 9
Training loss: 2.6320613163006126
Validation loss: 2.747879670313194

Epoch: 6| Step: 10
Training loss: 3.062548422917163
Validation loss: 2.7354883161827637

Epoch: 6| Step: 11
Training loss: 2.8703235241839704
Validation loss: 2.6993645768031698

Epoch: 6| Step: 12
Training loss: 2.561051587396647
Validation loss: 2.70730981315548

Epoch: 6| Step: 13
Training loss: 3.502550558178662
Validation loss: 2.71283704477289

Epoch: 9| Step: 0
Training loss: 2.7197419034295796
Validation loss: 2.7163782407398895

Epoch: 6| Step: 1
Training loss: 2.5167628019383756
Validation loss: 2.7358890374475773

Epoch: 6| Step: 2
Training loss: 2.527273940665513
Validation loss: 2.7170480538448825

Epoch: 6| Step: 3
Training loss: 2.843974680985044
Validation loss: 2.7141553266657503

Epoch: 6| Step: 4
Training loss: 2.4132344328740696
Validation loss: 2.7242194804847086

Epoch: 6| Step: 5
Training loss: 2.6123118063571225
Validation loss: 2.733198599479737

Epoch: 6| Step: 6
Training loss: 2.6695470651499176
Validation loss: 2.6821570847213576

Epoch: 6| Step: 7
Training loss: 2.5497008952328835
Validation loss: 2.702286724434755

Epoch: 6| Step: 8
Training loss: 2.3655726398030077
Validation loss: 2.7133094751713465

Epoch: 6| Step: 9
Training loss: 3.668700578866846
Validation loss: 2.7304289618900803

Epoch: 6| Step: 10
Training loss: 3.189119114763419
Validation loss: 2.724555179325837

Epoch: 6| Step: 11
Training loss: 3.175760679659318
Validation loss: 2.676724663443006

Epoch: 6| Step: 12
Training loss: 2.749412647292205
Validation loss: 2.6978375829547434

Epoch: 6| Step: 13
Training loss: 3.0209259720552066
Validation loss: 2.7031652340990924

Epoch: 10| Step: 0
Training loss: 3.1267091273479557
Validation loss: 2.7033327055937026

Epoch: 6| Step: 1
Training loss: 3.296545220102948
Validation loss: 2.6841707826204035

Epoch: 6| Step: 2
Training loss: 3.129139714097438
Validation loss: 2.701753102821509

Epoch: 6| Step: 3
Training loss: 2.305747819515861
Validation loss: 2.7161947790303316

Epoch: 6| Step: 4
Training loss: 2.961639240619483
Validation loss: 2.689520985308884

Epoch: 6| Step: 5
Training loss: 2.3859832179717593
Validation loss: 2.7185809934271377

Epoch: 6| Step: 6
Training loss: 2.096030402603673
Validation loss: 2.692651409873168

Epoch: 6| Step: 7
Training loss: 2.5438244108146773
Validation loss: 2.6828177716975996

Epoch: 6| Step: 8
Training loss: 3.6267080558023257
Validation loss: 2.6882657874794464

Epoch: 6| Step: 9
Training loss: 2.7845977180364754
Validation loss: 2.698598699387913

Epoch: 6| Step: 10
Training loss: 3.045453331686992
Validation loss: 2.704511973861317

Epoch: 6| Step: 11
Training loss: 2.505937011657812
Validation loss: 2.6831979547631195

Epoch: 6| Step: 12
Training loss: 2.6656242558432433
Validation loss: 2.7053653201936294

Epoch: 6| Step: 13
Training loss: 2.0410815068613424
Validation loss: 2.703840275029105

Epoch: 11| Step: 0
Training loss: 2.419732111771222
Validation loss: 2.677313714312992

Epoch: 6| Step: 1
Training loss: 2.6585124534442954
Validation loss: 2.6898742508596993

Epoch: 6| Step: 2
Training loss: 3.0061547405036455
Validation loss: 2.6777511139839683

Epoch: 6| Step: 3
Training loss: 2.7263155500182816
Validation loss: 2.674524016532009

Epoch: 6| Step: 4
Training loss: 2.2348798701625143
Validation loss: 2.7164217161744544

Epoch: 6| Step: 5
Training loss: 2.080898069577282
Validation loss: 2.6514583827212785

Epoch: 6| Step: 6
Training loss: 3.084781633064786
Validation loss: 2.6602240211641055

Epoch: 6| Step: 7
Training loss: 2.339843648104912
Validation loss: 2.6635035639784923

Epoch: 6| Step: 8
Training loss: 2.164618245180749
Validation loss: 2.6408851390061443

Epoch: 6| Step: 9
Training loss: 3.5401272887712842
Validation loss: 2.670733083270814

Epoch: 6| Step: 10
Training loss: 2.944155356972728
Validation loss: 2.6820711557553256

Epoch: 6| Step: 11
Training loss: 3.0049818318304933
Validation loss: 2.626184166130473

Epoch: 6| Step: 12
Training loss: 2.3058311598969383
Validation loss: 2.698253173658492

Epoch: 6| Step: 13
Training loss: 3.4303136440823225
Validation loss: 2.6801673896905127

Epoch: 12| Step: 0
Training loss: 2.2243081978276615
Validation loss: 2.6627036140682026

Epoch: 6| Step: 1
Training loss: 2.0855451922169648
Validation loss: 2.669897444454434

Epoch: 6| Step: 2
Training loss: 3.0834034233031207
Validation loss: 2.677921985126123

Epoch: 6| Step: 3
Training loss: 2.3903746629676927
Validation loss: 2.6860873479579896

Epoch: 6| Step: 4
Training loss: 2.1188983831519104
Validation loss: 2.6437694930612246

Epoch: 6| Step: 5
Training loss: 2.918243599526393
Validation loss: 2.669218211081751

Epoch: 6| Step: 6
Training loss: 2.361363362569223
Validation loss: 2.6431489653548352

Epoch: 6| Step: 7
Training loss: 3.509323372465373
Validation loss: 2.6644872660514856

Epoch: 6| Step: 8
Training loss: 3.072702967222877
Validation loss: 2.660445785263533

Epoch: 6| Step: 9
Training loss: 2.926530362679342
Validation loss: 2.6493852808066607

Epoch: 6| Step: 10
Training loss: 2.8920540241455828
Validation loss: 2.6637786833377746

Epoch: 6| Step: 11
Training loss: 3.0404884111672557
Validation loss: 2.7118808596406248

Epoch: 6| Step: 12
Training loss: 2.7520503290253924
Validation loss: 2.6451865229133467

Epoch: 6| Step: 13
Training loss: 2.1994719825342455
Validation loss: 2.686483575397386

Epoch: 13| Step: 0
Training loss: 2.713437557358847
Validation loss: 2.687621860550634

Epoch: 6| Step: 1
Training loss: 2.660313000871093
Validation loss: 2.6386864974950672

Epoch: 6| Step: 2
Training loss: 2.32770293845586
Validation loss: 2.6634653415915848

Epoch: 6| Step: 3
Training loss: 2.3009645554167983
Validation loss: 2.633832030416719

Epoch: 6| Step: 4
Training loss: 3.163584430511474
Validation loss: 2.6464158916175755

Epoch: 6| Step: 5
Training loss: 2.6202960783251075
Validation loss: 2.6103703167193237

Epoch: 6| Step: 6
Training loss: 2.0768436697916535
Validation loss: 2.6512657675363416

Epoch: 6| Step: 7
Training loss: 1.6174235148675604
Validation loss: 2.6767654725013528

Epoch: 6| Step: 8
Training loss: 3.6084770638000045
Validation loss: 2.6563216704629027

Epoch: 6| Step: 9
Training loss: 2.78199912280049
Validation loss: 2.6278765977940135

Epoch: 6| Step: 10
Training loss: 2.950573176935073
Validation loss: 2.665219843291496

Epoch: 6| Step: 11
Training loss: 2.184556124576748
Validation loss: 2.65369909131355

Epoch: 6| Step: 12
Training loss: 3.2342651643393863
Validation loss: 2.6277148724697934

Epoch: 6| Step: 13
Training loss: 3.099538301110943
Validation loss: 2.6340747829616564

Epoch: 14| Step: 0
Training loss: 3.503035046854334
Validation loss: 2.6509904438059047

Epoch: 6| Step: 1
Training loss: 2.502081576645039
Validation loss: 2.644902423484202

Epoch: 6| Step: 2
Training loss: 2.651202983232476
Validation loss: 2.6581545565370344

Epoch: 6| Step: 3
Training loss: 2.58081423057587
Validation loss: 2.676545743487109

Epoch: 6| Step: 4
Training loss: 2.6287083544223506
Validation loss: 2.647276827513755

Epoch: 6| Step: 5
Training loss: 3.114729827871876
Validation loss: 2.695360605298937

Epoch: 6| Step: 6
Training loss: 2.8685994426638186
Validation loss: 2.657133830512224

Epoch: 6| Step: 7
Training loss: 2.2001905445465426
Validation loss: 2.6461822750246866

Epoch: 6| Step: 8
Training loss: 2.6521228816301776
Validation loss: 2.656676613451223

Epoch: 6| Step: 9
Training loss: 2.6021377798044147
Validation loss: 2.6662506037224216

Epoch: 6| Step: 10
Training loss: 3.0572676822863163
Validation loss: 2.6163763734636722

Epoch: 6| Step: 11
Training loss: 2.118647786153343
Validation loss: 2.631366947924716

Epoch: 6| Step: 12
Training loss: 2.5970693283727546
Validation loss: 2.60321847565403

Epoch: 6| Step: 13
Training loss: 2.3246884167988995
Validation loss: 2.5998328934667554

Epoch: 15| Step: 0
Training loss: 2.594910419512903
Validation loss: 2.629658153639914

Epoch: 6| Step: 1
Training loss: 2.5945775194186163
Validation loss: 2.5850786701826554

Epoch: 6| Step: 2
Training loss: 2.7575654953953976
Validation loss: 2.6071361599517027

Epoch: 6| Step: 3
Training loss: 3.082213653852634
Validation loss: 2.6140272352078675

Epoch: 6| Step: 4
Training loss: 2.281311138849225
Validation loss: 2.6159648715469173

Epoch: 6| Step: 5
Training loss: 1.7570019018589553
Validation loss: 2.635572810818358

Epoch: 6| Step: 6
Training loss: 2.8096936954247123
Validation loss: 2.636020566079581

Epoch: 6| Step: 7
Training loss: 2.6067502646281007
Validation loss: 2.617475928360152

Epoch: 6| Step: 8
Training loss: 2.932084793915158
Validation loss: 2.5826296822212655

Epoch: 6| Step: 9
Training loss: 2.632987630662213
Validation loss: 2.612996981621357

Epoch: 6| Step: 10
Training loss: 2.995898462966132
Validation loss: 2.5939727595626185

Epoch: 6| Step: 11
Training loss: 2.997073335419215
Validation loss: 2.674045461957245

Epoch: 6| Step: 12
Training loss: 2.3906514284754947
Validation loss: 2.6382523811951573

Epoch: 6| Step: 13
Training loss: 2.954420663292294
Validation loss: 2.6338022260250895

Epoch: 16| Step: 0
Training loss: 2.5812639951903815
Validation loss: 2.693831142669708

Epoch: 6| Step: 1
Training loss: 2.6362204751992695
Validation loss: 2.673067076076799

Epoch: 6| Step: 2
Training loss: 3.4615348489856617
Validation loss: 2.675844422868551

Epoch: 6| Step: 3
Training loss: 2.2914322704316588
Validation loss: 2.6230592971170554

Epoch: 6| Step: 4
Training loss: 2.489651624522358
Validation loss: 2.62927628926918

Epoch: 6| Step: 5
Training loss: 2.4885661921697118
Validation loss: 2.59619498011977

Epoch: 6| Step: 6
Training loss: 2.897028248837168
Validation loss: 2.604212544355

Epoch: 6| Step: 7
Training loss: 2.8768400855041416
Validation loss: 2.630514060403361

Epoch: 6| Step: 8
Training loss: 2.1191794396286907
Validation loss: 2.5896709493810435

Epoch: 6| Step: 9
Training loss: 3.4752293463021133
Validation loss: 2.5985916327484944

Epoch: 6| Step: 10
Training loss: 2.8660839982005433
Validation loss: 2.6168494618301485

Epoch: 6| Step: 11
Training loss: 2.293932632534666
Validation loss: 2.6224963798049457

Epoch: 6| Step: 12
Training loss: 2.5701535068487815
Validation loss: 2.621948148414038

Epoch: 6| Step: 13
Training loss: 2.301493044010435
Validation loss: 2.5941353936724942

Epoch: 17| Step: 0
Training loss: 3.041685095604934
Validation loss: 2.6488059058657085

Epoch: 6| Step: 1
Training loss: 2.720130482236664
Validation loss: 2.584497671356402

Epoch: 6| Step: 2
Training loss: 2.3336633948350536
Validation loss: 2.621041704353769

Epoch: 6| Step: 3
Training loss: 2.174032553000048
Validation loss: 2.6343846668987667

Epoch: 6| Step: 4
Training loss: 2.6941578036381872
Validation loss: 2.654869798100642

Epoch: 6| Step: 5
Training loss: 3.199384189003061
Validation loss: 2.6510559311478623

Epoch: 6| Step: 6
Training loss: 2.227256479363282
Validation loss: 2.620628774288294

Epoch: 6| Step: 7
Training loss: 2.472867983751554
Validation loss: 2.6409692483459986

Epoch: 6| Step: 8
Training loss: 3.6766466668542717
Validation loss: 2.6809637739443906

Epoch: 6| Step: 9
Training loss: 2.2525847741029112
Validation loss: 2.612723967277251

Epoch: 6| Step: 10
Training loss: 2.0029662308876843
Validation loss: 2.6658075905888823

Epoch: 6| Step: 11
Training loss: 2.4702196213539733
Validation loss: 2.627635707357169

Epoch: 6| Step: 12
Training loss: 1.627915847435732
Validation loss: 2.583436738272475

Epoch: 6| Step: 13
Training loss: 3.4698927088263987
Validation loss: 2.6140408402735256

Epoch: 18| Step: 0
Training loss: 2.5690648723591805
Validation loss: 2.6066785574379208

Epoch: 6| Step: 1
Training loss: 2.4444077252992065
Validation loss: 2.5963479631529034

Epoch: 6| Step: 2
Training loss: 2.332448132951238
Validation loss: 2.6111642257775767

Epoch: 6| Step: 3
Training loss: 2.69704481100805
Validation loss: 2.600022831229689

Epoch: 6| Step: 4
Training loss: 2.6729968654843956
Validation loss: 2.6000403914615338

Epoch: 6| Step: 5
Training loss: 3.308660044901049
Validation loss: 2.556393985688173

Epoch: 6| Step: 6
Training loss: 3.601864882744066
Validation loss: 2.6595841967627964

Epoch: 6| Step: 7
Training loss: 2.4959560111522263
Validation loss: 2.578806777356177

Epoch: 6| Step: 8
Training loss: 2.441914009698482
Validation loss: 2.584594177890797

Epoch: 6| Step: 9
Training loss: 2.386035378077922
Validation loss: 2.621869718525856

Epoch: 6| Step: 10
Training loss: 2.4170953655376355
Validation loss: 2.6045831016727976

Epoch: 6| Step: 11
Training loss: 1.8964579744396968
Validation loss: 2.6132635506570843

Epoch: 6| Step: 12
Training loss: 2.4968701798221815
Validation loss: 2.5947102833444053

Epoch: 6| Step: 13
Training loss: 2.559888672196134
Validation loss: 2.590751477364871

Epoch: 19| Step: 0
Training loss: 2.9843519918942936
Validation loss: 2.56933688090399

Epoch: 6| Step: 1
Training loss: 2.408234310644336
Validation loss: 2.6060749284839293

Epoch: 6| Step: 2
Training loss: 2.9070909165428414
Validation loss: 2.5822624376209022

Epoch: 6| Step: 3
Training loss: 2.2898066746428114
Validation loss: 2.5738079107882843

Epoch: 6| Step: 4
Training loss: 2.9091742785385266
Validation loss: 2.5716941235309183

Epoch: 6| Step: 5
Training loss: 2.8404548753546113
Validation loss: 2.565934337656915

Epoch: 6| Step: 6
Training loss: 1.8678091123772635
Validation loss: 2.5908170302957756

Epoch: 6| Step: 7
Training loss: 2.6161389428200574
Validation loss: 2.5861714267856124

Epoch: 6| Step: 8
Training loss: 2.277540456871036
Validation loss: 2.602418348269468

Epoch: 6| Step: 9
Training loss: 2.904174063265853
Validation loss: 2.581724316950893

Epoch: 6| Step: 10
Training loss: 2.187103126491063
Validation loss: 2.601167337612524

Epoch: 6| Step: 11
Training loss: 2.6610175039524924
Validation loss: 2.6633986972654498

Epoch: 6| Step: 12
Training loss: 2.4698939509927125
Validation loss: 2.647836412543714

Epoch: 6| Step: 13
Training loss: 3.233804403642946
Validation loss: 2.6471777726647163

Epoch: 20| Step: 0
Training loss: 3.009114882654725
Validation loss: 2.6407599104327235

Epoch: 6| Step: 1
Training loss: 2.3155259619575133
Validation loss: 2.618946930211077

Epoch: 6| Step: 2
Training loss: 2.6018475900416265
Validation loss: 2.619464259737357

Epoch: 6| Step: 3
Training loss: 2.3629735320712
Validation loss: 2.562705566720658

Epoch: 6| Step: 4
Training loss: 2.444429280734954
Validation loss: 2.554502412427648

Epoch: 6| Step: 5
Training loss: 3.3660198408642508
Validation loss: 2.590384632550862

Epoch: 6| Step: 6
Training loss: 1.722984991906016
Validation loss: 2.578943958640448

Epoch: 6| Step: 7
Training loss: 3.4560459952825844
Validation loss: 2.6119293380553428

Epoch: 6| Step: 8
Training loss: 3.0236754804293575
Validation loss: 2.595625050262517

Epoch: 6| Step: 9
Training loss: 2.3339158307468986
Validation loss: 2.6016805505555203

Epoch: 6| Step: 10
Training loss: 2.0238968611285713
Validation loss: 2.5907487779105396

Epoch: 6| Step: 11
Training loss: 2.1348487160750627
Validation loss: 2.5850366135297165

Epoch: 6| Step: 12
Training loss: 2.4088214164088426
Validation loss: 2.5839456299183476

Epoch: 6| Step: 13
Training loss: 3.07637648129072
Validation loss: 2.58549113037028

Epoch: 21| Step: 0
Training loss: 2.8730628079945695
Validation loss: 2.60271219962319

Epoch: 6| Step: 1
Training loss: 2.2411774277519383
Validation loss: 2.597409879622118

Epoch: 6| Step: 2
Training loss: 2.4141977019241465
Validation loss: 2.589559409986755

Epoch: 6| Step: 3
Training loss: 1.8391432673917911
Validation loss: 2.563484902020165

Epoch: 6| Step: 4
Training loss: 2.1316922218435317
Validation loss: 2.5680644553771694

Epoch: 6| Step: 5
Training loss: 2.854704497588969
Validation loss: 2.6348451791360645

Epoch: 6| Step: 6
Training loss: 2.9744679848824767
Validation loss: 2.6026272661579624

Epoch: 6| Step: 7
Training loss: 2.4321912027286956
Validation loss: 2.6554478200723803

Epoch: 6| Step: 8
Training loss: 2.981389654635253
Validation loss: 2.6307089200194524

Epoch: 6| Step: 9
Training loss: 2.6618179307289402
Validation loss: 2.720497972540581

Epoch: 6| Step: 10
Training loss: 2.322550609353392
Validation loss: 2.6403949795370534

Epoch: 6| Step: 11
Training loss: 2.7405458410612304
Validation loss: 2.6395178887359085

Epoch: 6| Step: 12
Training loss: 3.0192382986226227
Validation loss: 2.632558967012027

Epoch: 6| Step: 13
Training loss: 2.485433580885125
Validation loss: 2.593103489100452

Epoch: 22| Step: 0
Training loss: 2.4110461899689053
Validation loss: 2.612604149502227

Epoch: 6| Step: 1
Training loss: 2.0977487667999806
Validation loss: 2.5711399899125404

Epoch: 6| Step: 2
Training loss: 1.9249213660887554
Validation loss: 2.5447232102253374

Epoch: 6| Step: 3
Training loss: 3.1598755814407546
Validation loss: 2.5840868671261896

Epoch: 6| Step: 4
Training loss: 2.7749930304362436
Validation loss: 2.5802365066002526

Epoch: 6| Step: 5
Training loss: 2.883138664009798
Validation loss: 2.534548450998979

Epoch: 6| Step: 6
Training loss: 2.6539503128126603
Validation loss: 2.6028248699772276

Epoch: 6| Step: 7
Training loss: 2.6621554084542485
Validation loss: 2.578241580677764

Epoch: 6| Step: 8
Training loss: 2.316965894333659
Validation loss: 2.6092336924775132

Epoch: 6| Step: 9
Training loss: 2.6331875587708384
Validation loss: 2.5893067598662083

Epoch: 6| Step: 10
Training loss: 2.703931831386546
Validation loss: 2.6227487719922657

Epoch: 6| Step: 11
Training loss: 2.36985603217162
Validation loss: 2.5911515866827552

Epoch: 6| Step: 12
Training loss: 2.8056728151784376
Validation loss: 2.5360689327757164

Epoch: 6| Step: 13
Training loss: 2.417330409574064
Validation loss: 2.6040697283186516

Epoch: 23| Step: 0
Training loss: 2.222101071817023
Validation loss: 2.564883573441583

Epoch: 6| Step: 1
Training loss: 2.427914183902164
Validation loss: 2.555412835015083

Epoch: 6| Step: 2
Training loss: 3.323840324835849
Validation loss: 2.5820804500845873

Epoch: 6| Step: 3
Training loss: 2.633199691600454
Validation loss: 2.566873601729318

Epoch: 6| Step: 4
Training loss: 2.7700279231678144
Validation loss: 2.5895888872974484

Epoch: 6| Step: 5
Training loss: 3.070616573583842
Validation loss: 2.594032961566126

Epoch: 6| Step: 6
Training loss: 2.617484369094653
Validation loss: 2.6192391320388113

Epoch: 6| Step: 7
Training loss: 3.047006301007017
Validation loss: 2.547374637328131

Epoch: 6| Step: 8
Training loss: 2.049284935892059
Validation loss: 2.5967663533741367

Epoch: 6| Step: 9
Training loss: 2.3155691039717547
Validation loss: 2.5683907819986396

Epoch: 6| Step: 10
Training loss: 2.447986737053291
Validation loss: 2.599778610976422

Epoch: 6| Step: 11
Training loss: 3.0825061891467356
Validation loss: 2.547170220175541

Epoch: 6| Step: 12
Training loss: 2.2107125427323737
Validation loss: 2.58722504891836

Epoch: 6| Step: 13
Training loss: 1.7568816708628439
Validation loss: 2.5913537304669796

Epoch: 24| Step: 0
Training loss: 2.0963448913242657
Validation loss: 2.6038088946946827

Epoch: 6| Step: 1
Training loss: 1.9422302339598578
Validation loss: 2.6140436828872398

Epoch: 6| Step: 2
Training loss: 2.682614698988653
Validation loss: 2.5892368255660174

Epoch: 6| Step: 3
Training loss: 2.662955672264386
Validation loss: 2.584767502389193

Epoch: 6| Step: 4
Training loss: 3.1291465714609847
Validation loss: 2.5372764369905214

Epoch: 6| Step: 5
Training loss: 2.300465690073389
Validation loss: 2.558901811452902

Epoch: 6| Step: 6
Training loss: 2.6390103250860246
Validation loss: 2.5915836954685623

Epoch: 6| Step: 7
Training loss: 3.5043739508526413
Validation loss: 2.5471209697874655

Epoch: 6| Step: 8
Training loss: 1.9949600374430745
Validation loss: 2.578101279409698

Epoch: 6| Step: 9
Training loss: 2.0537013018749826
Validation loss: 2.587658174259642

Epoch: 6| Step: 10
Training loss: 2.7302460804794033
Validation loss: 2.5996043613384536

Epoch: 6| Step: 11
Training loss: 2.209650318737653
Validation loss: 2.57943431860294

Epoch: 6| Step: 12
Training loss: 2.8977935157860775
Validation loss: 2.588189564838955

Epoch: 6| Step: 13
Training loss: 2.295195296212047
Validation loss: 2.610799921939927

Epoch: 25| Step: 0
Training loss: 3.4893280543237717
Validation loss: 2.605239789473656

Epoch: 6| Step: 1
Training loss: 2.251960218406814
Validation loss: 2.552221727835711

Epoch: 6| Step: 2
Training loss: 2.9585224861243358
Validation loss: 2.6166428943534177

Epoch: 6| Step: 3
Training loss: 2.8481994027185813
Validation loss: 2.6480742648986677

Epoch: 6| Step: 4
Training loss: 1.6911626556690778
Validation loss: 2.660077542463058

Epoch: 6| Step: 5
Training loss: 3.2020102445210985
Validation loss: 2.701127021363821

Epoch: 6| Step: 6
Training loss: 2.0246698463589987
Validation loss: 2.6893494548407384

Epoch: 6| Step: 7
Training loss: 2.5639399692750495
Validation loss: 2.6930457788541

Epoch: 6| Step: 8
Training loss: 2.535730517314332
Validation loss: 2.6410678138611146

Epoch: 6| Step: 9
Training loss: 2.212217789232577
Validation loss: 2.6887508556790825

Epoch: 6| Step: 10
Training loss: 2.995742001332859
Validation loss: 2.5954765869668996

Epoch: 6| Step: 11
Training loss: 2.3699858086398526
Validation loss: 2.5541341728728155

Epoch: 6| Step: 12
Training loss: 2.2573558517177084
Validation loss: 2.5691487345490898

Epoch: 6| Step: 13
Training loss: 2.1570755856940806
Validation loss: 2.5992746765828247

Epoch: 26| Step: 0
Training loss: 3.157500972792958
Validation loss: 2.5399354813108546

Epoch: 6| Step: 1
Training loss: 1.9865576687403461
Validation loss: 2.6017216966891192

Epoch: 6| Step: 2
Training loss: 2.4929850387399735
Validation loss: 2.5595892525013038

Epoch: 6| Step: 3
Training loss: 2.7415645576485854
Validation loss: 2.6113668366147054

Epoch: 6| Step: 4
Training loss: 2.13325087964138
Validation loss: 2.556023842181511

Epoch: 6| Step: 5
Training loss: 2.4247055740164627
Validation loss: 2.581950591843088

Epoch: 6| Step: 6
Training loss: 2.4618699018004815
Validation loss: 2.571309461559797

Epoch: 6| Step: 7
Training loss: 2.4554673207321644
Validation loss: 2.545960260110557

Epoch: 6| Step: 8
Training loss: 2.5961575652093143
Validation loss: 2.523835047535391

Epoch: 6| Step: 9
Training loss: 2.758505844837418
Validation loss: 2.5437864365026224

Epoch: 6| Step: 10
Training loss: 2.1269421397644463
Validation loss: 2.5480594026307393

Epoch: 6| Step: 11
Training loss: 2.2829002786479693
Validation loss: 2.560632350725792

Epoch: 6| Step: 12
Training loss: 2.778142071254188
Validation loss: 2.547262961827858

Epoch: 6| Step: 13
Training loss: 2.9599813965908743
Validation loss: 2.6229839757676348

Epoch: 27| Step: 0
Training loss: 3.0061750438331165
Validation loss: 2.6096802492969435

Epoch: 6| Step: 1
Training loss: 2.3763771080122917
Validation loss: 2.606430448144553

Epoch: 6| Step: 2
Training loss: 2.437998207235577
Validation loss: 2.7044986439277934

Epoch: 6| Step: 3
Training loss: 2.0226106463934914
Validation loss: 2.6562769121788867

Epoch: 6| Step: 4
Training loss: 2.6873425282319685
Validation loss: 2.676969241272768

Epoch: 6| Step: 5
Training loss: 2.7631384236981047
Validation loss: 2.693970306427305

Epoch: 6| Step: 6
Training loss: 2.4957355367598146
Validation loss: 2.68857805675033

Epoch: 6| Step: 7
Training loss: 2.3368885566540616
Validation loss: 2.679812147616861

Epoch: 6| Step: 8
Training loss: 2.768504394935618
Validation loss: 2.6360768985124876

Epoch: 6| Step: 9
Training loss: 2.217598952329479
Validation loss: 2.630239314032167

Epoch: 6| Step: 10
Training loss: 2.5917249380677054
Validation loss: 2.5740678402433628

Epoch: 6| Step: 11
Training loss: 2.8844968429074704
Validation loss: 2.593651275594329

Epoch: 6| Step: 12
Training loss: 3.302114941819751
Validation loss: 2.572981896648232

Epoch: 6| Step: 13
Training loss: 1.785941320700576
Validation loss: 2.532089361104423

Epoch: 28| Step: 0
Training loss: 1.9903240389556058
Validation loss: 2.557832436706236

Epoch: 6| Step: 1
Training loss: 2.708781239567531
Validation loss: 2.56135634355901

Epoch: 6| Step: 2
Training loss: 2.8674899988906315
Validation loss: 2.58099921719326

Epoch: 6| Step: 3
Training loss: 2.2712857790172114
Validation loss: 2.549152752116165

Epoch: 6| Step: 4
Training loss: 2.7683857215304783
Validation loss: 2.5726159624037646

Epoch: 6| Step: 5
Training loss: 1.813074547040361
Validation loss: 2.5865151335468135

Epoch: 6| Step: 6
Training loss: 2.646484284911207
Validation loss: 2.5507254251210236

Epoch: 6| Step: 7
Training loss: 1.7979974309374624
Validation loss: 2.5659381007872613

Epoch: 6| Step: 8
Training loss: 1.8585617466753248
Validation loss: 2.5976194603783833

Epoch: 6| Step: 9
Training loss: 3.2000685088453515
Validation loss: 2.5822848889404413

Epoch: 6| Step: 10
Training loss: 2.8823274860883776
Validation loss: 2.5733419728339975

Epoch: 6| Step: 11
Training loss: 2.995460254286437
Validation loss: 2.56822076188951

Epoch: 6| Step: 12
Training loss: 2.139155419437377
Validation loss: 2.6295890658219454

Epoch: 6| Step: 13
Training loss: 2.561006622591881
Validation loss: 2.620353162037145

Epoch: 29| Step: 0
Training loss: 2.6809846724541946
Validation loss: 2.6019254017026685

Epoch: 6| Step: 1
Training loss: 2.4746246939578627
Validation loss: 2.5657483965262133

Epoch: 6| Step: 2
Training loss: 3.2790787552161897
Validation loss: 2.651322795198885

Epoch: 6| Step: 3
Training loss: 3.376125854333893
Validation loss: 2.5690541689833983

Epoch: 6| Step: 4
Training loss: 2.32146530541501
Validation loss: 2.5968932596812557

Epoch: 6| Step: 5
Training loss: 2.363746181184376
Validation loss: 2.573009293673974

Epoch: 6| Step: 6
Training loss: 1.6492898915757221
Validation loss: 2.6532466739212075

Epoch: 6| Step: 7
Training loss: 1.651295286448452
Validation loss: 2.5227937379137244

Epoch: 6| Step: 8
Training loss: 2.9875014939563798
Validation loss: 2.5972052084580284

Epoch: 6| Step: 9
Training loss: 1.88940018001413
Validation loss: 2.6009408171727046

Epoch: 6| Step: 10
Training loss: 2.8808179949358634
Validation loss: 2.614605699623362

Epoch: 6| Step: 11
Training loss: 2.2213965736506296
Validation loss: 2.5262504779727766

Epoch: 6| Step: 12
Training loss: 2.4604350227965397
Validation loss: 2.5984619267933304

Epoch: 6| Step: 13
Training loss: 2.6110803205509883
Validation loss: 2.5473634060423427

Epoch: 30| Step: 0
Training loss: 2.612867564942064
Validation loss: 2.5801450579670466

Epoch: 6| Step: 1
Training loss: 2.0456356344112687
Validation loss: 2.5950992705627502

Epoch: 6| Step: 2
Training loss: 2.632597419262109
Validation loss: 2.5715772769330507

Epoch: 6| Step: 3
Training loss: 3.410636387394089
Validation loss: 2.5804728750591854

Epoch: 6| Step: 4
Training loss: 2.1368823224210285
Validation loss: 2.5768125333700502

Epoch: 6| Step: 5
Training loss: 2.4952956761012177
Validation loss: 2.583673698296459

Epoch: 6| Step: 6
Training loss: 2.572638575136673
Validation loss: 2.53371438205741

Epoch: 6| Step: 7
Training loss: 2.110197683899951
Validation loss: 2.596269050715587

Epoch: 6| Step: 8
Training loss: 2.335562277164258
Validation loss: 2.5884303805237883

Epoch: 6| Step: 9
Training loss: 2.1069648819917557
Validation loss: 2.5698029187877056

Epoch: 6| Step: 10
Training loss: 2.295235600231769
Validation loss: 2.5791763936127956

Epoch: 6| Step: 11
Training loss: 2.070583800767546
Validation loss: 2.576508047724875

Epoch: 6| Step: 12
Training loss: 3.0733611911440653
Validation loss: 2.645416066665409

Epoch: 6| Step: 13
Training loss: 3.042110219168807
Validation loss: 2.602303797410309

Epoch: 31| Step: 0
Training loss: 2.073986665489716
Validation loss: 2.6200147171068227

Epoch: 6| Step: 1
Training loss: 1.5604928667369296
Validation loss: 2.6554501395093846

Epoch: 6| Step: 2
Training loss: 2.959850423745231
Validation loss: 2.584038981588501

Epoch: 6| Step: 3
Training loss: 3.1615218146212705
Validation loss: 2.604753555287126

Epoch: 6| Step: 4
Training loss: 2.7125359036227303
Validation loss: 2.645277555670139

Epoch: 6| Step: 5
Training loss: 3.1530834970304236
Validation loss: 2.640229867117767

Epoch: 6| Step: 6
Training loss: 1.9919415490410712
Validation loss: 2.615523322592904

Epoch: 6| Step: 7
Training loss: 1.7738447351944382
Validation loss: 2.5933645720385985

Epoch: 6| Step: 8
Training loss: 2.4444566880507126
Validation loss: 2.606540259428854

Epoch: 6| Step: 9
Training loss: 2.491629702528834
Validation loss: 2.591201802069389

Epoch: 6| Step: 10
Training loss: 2.7730459017388505
Validation loss: 2.5259898832591263

Epoch: 6| Step: 11
Training loss: 3.108008923275975
Validation loss: 2.612193308324586

Epoch: 6| Step: 12
Training loss: 2.7642489528359047
Validation loss: 2.5353233153043044

Epoch: 6| Step: 13
Training loss: 2.0106659439846193
Validation loss: 2.5999042163225003

Epoch: 32| Step: 0
Training loss: 2.828522206438276
Validation loss: 2.5302267478837104

Epoch: 6| Step: 1
Training loss: 2.2326473145616803
Validation loss: 2.5644802412626895

Epoch: 6| Step: 2
Training loss: 2.2750188302738477
Validation loss: 2.595980822402699

Epoch: 6| Step: 3
Training loss: 2.826371128569051
Validation loss: 2.5827920767116455

Epoch: 6| Step: 4
Training loss: 2.5026500961000364
Validation loss: 2.5335675214973703

Epoch: 6| Step: 5
Training loss: 2.461921035169618
Validation loss: 2.6062458029148328

Epoch: 6| Step: 6
Training loss: 2.566367603400037
Validation loss: 2.576137215682672

Epoch: 6| Step: 7
Training loss: 2.0603758537588335
Validation loss: 2.581330250869571

Epoch: 6| Step: 8
Training loss: 1.8548422307787589
Validation loss: 2.5753004688891803

Epoch: 6| Step: 9
Training loss: 2.3596066999033463
Validation loss: 2.601834379391159

Epoch: 6| Step: 10
Training loss: 2.324158329538971
Validation loss: 2.5357296240897225

Epoch: 6| Step: 11
Training loss: 2.9663439185782443
Validation loss: 2.6368826205347

Epoch: 6| Step: 12
Training loss: 2.865058295437439
Validation loss: 2.63533147792315

Epoch: 6| Step: 13
Training loss: 2.5798443234221056
Validation loss: 2.585680684747236

Epoch: 33| Step: 0
Training loss: 2.2830437701687516
Validation loss: 2.5967759708354383

Epoch: 6| Step: 1
Training loss: 2.9130752977617465
Validation loss: 2.555517359346778

Epoch: 6| Step: 2
Training loss: 2.279956189454104
Validation loss: 2.6060114823813234

Epoch: 6| Step: 3
Training loss: 2.2717695377013882
Validation loss: 2.61879816549674

Epoch: 6| Step: 4
Training loss: 1.8349081197286334
Validation loss: 2.5824128223438048

Epoch: 6| Step: 5
Training loss: 2.6370498562361124
Validation loss: 2.6106537447652776

Epoch: 6| Step: 6
Training loss: 2.2505818780201823
Validation loss: 2.606374892818427

Epoch: 6| Step: 7
Training loss: 2.561735271692586
Validation loss: 2.5520237870308597

Epoch: 6| Step: 8
Training loss: 2.8982966715281937
Validation loss: 2.524862007424333

Epoch: 6| Step: 9
Training loss: 3.048907888030136
Validation loss: 2.555685674653475

Epoch: 6| Step: 10
Training loss: 2.402425029589192
Validation loss: 2.595484218929853

Epoch: 6| Step: 11
Training loss: 2.139686322975866
Validation loss: 2.6046078015853644

Epoch: 6| Step: 12
Training loss: 2.474374665146834
Validation loss: 2.5398549569636693

Epoch: 6| Step: 13
Training loss: 2.751991591174564
Validation loss: 2.559144715447182

Epoch: 34| Step: 0
Training loss: 2.3791696186570683
Validation loss: 2.515766684765603

Epoch: 6| Step: 1
Training loss: 2.947825849412471
Validation loss: 2.543370244002911

Epoch: 6| Step: 2
Training loss: 2.1582974650619575
Validation loss: 2.6009228352412053

Epoch: 6| Step: 3
Training loss: 2.528903391509139
Validation loss: 2.5346022962188695

Epoch: 6| Step: 4
Training loss: 2.647524065695396
Validation loss: 2.5447724601738053

Epoch: 6| Step: 5
Training loss: 1.677015867909998
Validation loss: 2.547689545542612

Epoch: 6| Step: 6
Training loss: 2.922113419051572
Validation loss: 2.632038142186863

Epoch: 6| Step: 7
Training loss: 2.639081515147137
Validation loss: 2.539514385995051

Epoch: 6| Step: 8
Training loss: 2.0223692205935833
Validation loss: 2.689027854671131

Epoch: 6| Step: 9
Training loss: 2.3669058754969354
Validation loss: 2.670258045775968

Epoch: 6| Step: 10
Training loss: 2.642454157118557
Validation loss: 2.665875411858727

Epoch: 6| Step: 11
Training loss: 2.6233529873038615
Validation loss: 2.713944437566278

Epoch: 6| Step: 12
Training loss: 2.2391151352823044
Validation loss: 2.6944117713424176

Epoch: 6| Step: 13
Training loss: 2.8462846799269768
Validation loss: 2.724852600544106

Epoch: 35| Step: 0
Training loss: 2.713223859123459
Validation loss: 2.6036614551038655

Epoch: 6| Step: 1
Training loss: 2.515045383567181
Validation loss: 2.5519422115830444

Epoch: 6| Step: 2
Training loss: 2.4525377092952385
Validation loss: 2.5796369492591613

Epoch: 6| Step: 3
Training loss: 2.700881556247457
Validation loss: 2.49526569001672

Epoch: 6| Step: 4
Training loss: 2.963512418275227
Validation loss: 2.548821756445089

Epoch: 6| Step: 5
Training loss: 2.8695477741450106
Validation loss: 2.5520077648782142

Epoch: 6| Step: 6
Training loss: 2.0093582081426824
Validation loss: 2.5902591638745673

Epoch: 6| Step: 7
Training loss: 2.3896697884850213
Validation loss: 2.628595946969623

Epoch: 6| Step: 8
Training loss: 2.559062606135133
Validation loss: 2.6428548814083914

Epoch: 6| Step: 9
Training loss: 2.128662431386352
Validation loss: 2.618095536493074

Epoch: 6| Step: 10
Training loss: 2.8342034368944127
Validation loss: 2.6179822180134136

Epoch: 6| Step: 11
Training loss: 2.523747380837701
Validation loss: 2.540948943646916

Epoch: 6| Step: 12
Training loss: 2.7718090165637674
Validation loss: 2.603760990333895

Epoch: 6| Step: 13
Training loss: 2.244908399858418
Validation loss: 2.6165919371177284

Epoch: 36| Step: 0
Training loss: 3.3945743746811172
Validation loss: 2.613685808480521

Epoch: 6| Step: 1
Training loss: 2.0622299479928126
Validation loss: 2.6077204501189595

Epoch: 6| Step: 2
Training loss: 2.2830909721037957
Validation loss: 2.6403729320353624

Epoch: 6| Step: 3
Training loss: 2.837073736900548
Validation loss: 2.6571370607084344

Epoch: 6| Step: 4
Training loss: 2.1593296338848864
Validation loss: 2.656478153976831

Epoch: 6| Step: 5
Training loss: 2.568096747949702
Validation loss: 2.669104971345854

Epoch: 6| Step: 6
Training loss: 1.987275054485764
Validation loss: 2.6431240468035893

Epoch: 6| Step: 7
Training loss: 2.1469240718824842
Validation loss: 2.644932215470444

Epoch: 6| Step: 8
Training loss: 2.733892082076919
Validation loss: 2.6758793796635274

Epoch: 6| Step: 9
Training loss: 2.198439139749855
Validation loss: 2.615211416442394

Epoch: 6| Step: 10
Training loss: 2.4142803599990716
Validation loss: 2.6225787152361435

Epoch: 6| Step: 11
Training loss: 2.1910780934667575
Validation loss: 2.6437469175785213

Epoch: 6| Step: 12
Training loss: 3.0844064511876397
Validation loss: 2.57570516905705

Epoch: 6| Step: 13
Training loss: 1.922380148397237
Validation loss: 2.5791124321736074

Epoch: 37| Step: 0
Training loss: 3.2713803038483964
Validation loss: 2.583984728693247

Epoch: 6| Step: 1
Training loss: 2.328948624106076
Validation loss: 2.566914485345648

Epoch: 6| Step: 2
Training loss: 2.196909910442859
Validation loss: 2.5734856680349987

Epoch: 6| Step: 3
Training loss: 3.1038241272092857
Validation loss: 2.555551116589363

Epoch: 6| Step: 4
Training loss: 2.7477366062851676
Validation loss: 2.5358858082490308

Epoch: 6| Step: 5
Training loss: 1.936704656958229
Validation loss: 2.523719055404257

Epoch: 6| Step: 6
Training loss: 2.615570024028824
Validation loss: 2.5636319862357455

Epoch: 6| Step: 7
Training loss: 1.8817999558703296
Validation loss: 2.5801818195367314

Epoch: 6| Step: 8
Training loss: 1.8591743168601518
Validation loss: 2.5128975213717855

Epoch: 6| Step: 9
Training loss: 2.3010183319064477
Validation loss: 2.544084279858566

Epoch: 6| Step: 10
Training loss: 2.256885166530904
Validation loss: 2.6073664779588435

Epoch: 6| Step: 11
Training loss: 2.899614038763005
Validation loss: 2.5768831132614114

Epoch: 6| Step: 12
Training loss: 2.9251268212628307
Validation loss: 2.5984236040353577

Epoch: 6| Step: 13
Training loss: 2.3363239899946167
Validation loss: 2.5973305634280495

Epoch: 38| Step: 0
Training loss: 3.11538009063595
Validation loss: 2.6290769630238957

Epoch: 6| Step: 1
Training loss: 2.0354706563462615
Validation loss: 2.573303322304104

Epoch: 6| Step: 2
Training loss: 2.9413234096174086
Validation loss: 2.5869351217320666

Epoch: 6| Step: 3
Training loss: 2.4807156657678417
Validation loss: 2.5986324760917516

Epoch: 6| Step: 4
Training loss: 1.9258785571416257
Validation loss: 2.530037609217856

Epoch: 6| Step: 5
Training loss: 3.0197693803659416
Validation loss: 2.5909192521343702

Epoch: 6| Step: 6
Training loss: 2.983459332183362
Validation loss: 2.5419421020685258

Epoch: 6| Step: 7
Training loss: 2.9573247202044657
Validation loss: 2.5598940275282263

Epoch: 6| Step: 8
Training loss: 2.5001367531566876
Validation loss: 2.5582492742076104

Epoch: 6| Step: 9
Training loss: 2.4818543896747554
Validation loss: 2.564447376315474

Epoch: 6| Step: 10
Training loss: 2.2397047379582027
Validation loss: 2.528783153468086

Epoch: 6| Step: 11
Training loss: 2.046898761640466
Validation loss: 2.571527505036123

Epoch: 6| Step: 12
Training loss: 2.1883626054528387
Validation loss: 2.521574121715468

Epoch: 6| Step: 13
Training loss: 1.4441557508093874
Validation loss: 2.5526186997838525

Epoch: 39| Step: 0
Training loss: 1.5583590758674264
Validation loss: 2.58040919984435

Epoch: 6| Step: 1
Training loss: 2.6689887268354298
Validation loss: 2.573019625396546

Epoch: 6| Step: 2
Training loss: 2.5782294974679365
Validation loss: 2.6108436334745497

Epoch: 6| Step: 3
Training loss: 3.0041064132453847
Validation loss: 2.6108650475978625

Epoch: 6| Step: 4
Training loss: 1.5831225740133283
Validation loss: 2.586847074262238

Epoch: 6| Step: 5
Training loss: 2.266677296370471
Validation loss: 2.603776495632834

Epoch: 6| Step: 6
Training loss: 2.3202551632357102
Validation loss: 2.5455937507472766

Epoch: 6| Step: 7
Training loss: 1.7248688412989082
Validation loss: 2.6038657713943802

Epoch: 6| Step: 8
Training loss: 2.6887966842535582
Validation loss: 2.540234792976124

Epoch: 6| Step: 9
Training loss: 2.5226611191982276
Validation loss: 2.5581582045697138

Epoch: 6| Step: 10
Training loss: 2.1627594367723044
Validation loss: 2.588750149002206

Epoch: 6| Step: 11
Training loss: 3.097153919951288
Validation loss: 2.537592715807298

Epoch: 6| Step: 12
Training loss: 2.8041090514870914
Validation loss: 2.5622253736015423

Epoch: 6| Step: 13
Training loss: 2.632661266114965
Validation loss: 2.5641521617176237

Epoch: 40| Step: 0
Training loss: 1.9817592171033227
Validation loss: 2.6103403890617733

Epoch: 6| Step: 1
Training loss: 2.5687573954900382
Validation loss: 2.5738476344384416

Epoch: 6| Step: 2
Training loss: 2.837399948977758
Validation loss: 2.6028434188972085

Epoch: 6| Step: 3
Training loss: 2.864594245658666
Validation loss: 2.625716005797465

Epoch: 6| Step: 4
Training loss: 1.992737817487997
Validation loss: 2.602105199591146

Epoch: 6| Step: 5
Training loss: 2.964483467898803
Validation loss: 2.6419451872592474

Epoch: 6| Step: 6
Training loss: 2.659444884694278
Validation loss: 2.6547172088188087

Epoch: 6| Step: 7
Training loss: 1.9370272890373388
Validation loss: 2.644486968337909

Epoch: 6| Step: 8
Training loss: 2.8810500466562345
Validation loss: 2.627531390258201

Epoch: 6| Step: 9
Training loss: 2.8610934737401563
Validation loss: 2.61946733918022

Epoch: 6| Step: 10
Training loss: 2.310443582426739
Validation loss: 2.6016773813293006

Epoch: 6| Step: 11
Training loss: 2.033627571120745
Validation loss: 2.59270177288357

Epoch: 6| Step: 12
Training loss: 2.3976912440297182
Validation loss: 2.655088836586953

Epoch: 6| Step: 13
Training loss: 1.74240979884749
Validation loss: 2.583191549860811

Epoch: 41| Step: 0
Training loss: 2.7855160174534968
Validation loss: 2.5307360625789688

Epoch: 6| Step: 1
Training loss: 1.9215653332838114
Validation loss: 2.5383886607104285

Epoch: 6| Step: 2
Training loss: 3.1342477911468
Validation loss: 2.5857316595019215

Epoch: 6| Step: 3
Training loss: 2.1359830771929555
Validation loss: 2.528772837431548

Epoch: 6| Step: 4
Training loss: 1.8861682159713193
Validation loss: 2.563662079410651

Epoch: 6| Step: 5
Training loss: 3.299295991882696
Validation loss: 2.594717557673968

Epoch: 6| Step: 6
Training loss: 2.5740712981764324
Validation loss: 2.5890629407889603

Epoch: 6| Step: 7
Training loss: 2.0205729470832927
Validation loss: 2.585801027813093

Epoch: 6| Step: 8
Training loss: 2.3582580145500827
Validation loss: 2.56395115894411

Epoch: 6| Step: 9
Training loss: 2.329881248886117
Validation loss: 2.5754076962103145

Epoch: 6| Step: 10
Training loss: 2.39881362202504
Validation loss: 2.613579003706044

Epoch: 6| Step: 11
Training loss: 1.9231552573902373
Validation loss: 2.5958381887505824

Epoch: 6| Step: 12
Training loss: 2.25056800030684
Validation loss: 2.6169716893128396

Epoch: 6| Step: 13
Training loss: 2.7595500713380656
Validation loss: 2.5731256968933005

Epoch: 42| Step: 0
Training loss: 2.1784596693689084
Validation loss: 2.6600570772256957

Epoch: 6| Step: 1
Training loss: 1.8000244403875276
Validation loss: 2.5737491810349455

Epoch: 6| Step: 2
Training loss: 2.3962604197323847
Validation loss: 2.566173308710409

Epoch: 6| Step: 3
Training loss: 1.9977431677094126
Validation loss: 2.5710144630400213

Epoch: 6| Step: 4
Training loss: 2.7800334884492695
Validation loss: 2.5775272331439436

Epoch: 6| Step: 5
Training loss: 2.583029042032323
Validation loss: 2.570668730162482

Epoch: 6| Step: 6
Training loss: 2.4541446971935423
Validation loss: 2.5860977046394606

Epoch: 6| Step: 7
Training loss: 2.7764643955019026
Validation loss: 2.562231080745828

Epoch: 6| Step: 8
Training loss: 2.5284523279313733
Validation loss: 2.525883436982453

Epoch: 6| Step: 9
Training loss: 3.0337004834107923
Validation loss: 2.543685335529284

Epoch: 6| Step: 10
Training loss: 1.9017894650172211
Validation loss: 2.558293774906785

Epoch: 6| Step: 11
Training loss: 3.062596066583581
Validation loss: 2.5371518502266275

Epoch: 6| Step: 12
Training loss: 1.973555074951129
Validation loss: 2.58312229607077

Epoch: 6| Step: 13
Training loss: 2.477426564719011
Validation loss: 2.5736333541288623

Epoch: 43| Step: 0
Training loss: 2.209422748486754
Validation loss: 2.6083119981602088

Epoch: 6| Step: 1
Training loss: 2.1336992257976366
Validation loss: 2.5923837640713114

Epoch: 6| Step: 2
Training loss: 2.3165781301508614
Validation loss: 2.6628056579079327

Epoch: 6| Step: 3
Training loss: 2.460601783741749
Validation loss: 2.676022996214916

Epoch: 6| Step: 4
Training loss: 2.055410511753351
Validation loss: 2.6306777434508186

Epoch: 6| Step: 5
Training loss: 2.851472534432696
Validation loss: 2.6716283792222013

Epoch: 6| Step: 6
Training loss: 2.50683898093407
Validation loss: 2.653437116137168

Epoch: 6| Step: 7
Training loss: 2.3214064565590307
Validation loss: 2.639847635366217

Epoch: 6| Step: 8
Training loss: 1.7487363340049695
Validation loss: 2.594060925151318

Epoch: 6| Step: 9
Training loss: 2.7804126979304686
Validation loss: 2.632183524294115

Epoch: 6| Step: 10
Training loss: 3.1586792916587325
Validation loss: 2.5572201912415817

Epoch: 6| Step: 11
Training loss: 2.5084663085499814
Validation loss: 2.577231219485831

Epoch: 6| Step: 12
Training loss: 2.354760109250864
Validation loss: 2.549292994330025

Epoch: 6| Step: 13
Training loss: 2.5217049618183385
Validation loss: 2.5359523406880364

Epoch: 44| Step: 0
Training loss: 2.5343511916616848
Validation loss: 2.5570875243045434

Epoch: 6| Step: 1
Training loss: 2.6489149355336723
Validation loss: 2.5530818516895604

Epoch: 6| Step: 2
Training loss: 1.3740030489170056
Validation loss: 2.5671942752772723

Epoch: 6| Step: 3
Training loss: 2.8249291335137947
Validation loss: 2.5057583374998096

Epoch: 6| Step: 4
Training loss: 2.4509567105514267
Validation loss: 2.574086766195173

Epoch: 6| Step: 5
Training loss: 2.1184596219998966
Validation loss: 2.5513645535284892

Epoch: 6| Step: 6
Training loss: 2.6580936989554673
Validation loss: 2.626663468095926

Epoch: 6| Step: 7
Training loss: 2.996286000595284
Validation loss: 2.583316169702261

Epoch: 6| Step: 8
Training loss: 2.1732945914218615
Validation loss: 2.580624896168293

Epoch: 6| Step: 9
Training loss: 2.2807315603102687
Validation loss: 2.546184766105753

Epoch: 6| Step: 10
Training loss: 2.555689064168879
Validation loss: 2.6503630833236076

Epoch: 6| Step: 11
Training loss: 2.914715813840461
Validation loss: 2.5904237798656844

Epoch: 6| Step: 12
Training loss: 2.3634564799770192
Validation loss: 2.5600276433177407

Epoch: 6| Step: 13
Training loss: 1.9269147094633916
Validation loss: 2.5789865306587814

Epoch: 45| Step: 0
Training loss: 1.926420960560063
Validation loss: 2.5875066277976546

Epoch: 6| Step: 1
Training loss: 2.2448773880336286
Validation loss: 2.5664451437470137

Epoch: 6| Step: 2
Training loss: 1.8619963816311564
Validation loss: 2.5604409885311807

Epoch: 6| Step: 3
Training loss: 2.786008471720481
Validation loss: 2.5634325703070457

Epoch: 6| Step: 4
Training loss: 2.6629400041950593
Validation loss: 2.5687336889462236

Epoch: 6| Step: 5
Training loss: 2.6326489496794925
Validation loss: 2.5599938054059503

Epoch: 6| Step: 6
Training loss: 2.2852691361673876
Validation loss: 2.61709231682774

Epoch: 6| Step: 7
Training loss: 2.1395604068923157
Validation loss: 2.574207821071736

Epoch: 6| Step: 8
Training loss: 1.827624456235579
Validation loss: 2.5590882267592194

Epoch: 6| Step: 9
Training loss: 1.9621804845896857
Validation loss: 2.5432990934367807

Epoch: 6| Step: 10
Training loss: 2.724885353686438
Validation loss: 2.544138649533098

Epoch: 6| Step: 11
Training loss: 2.5599875810441146
Validation loss: 2.577982642356772

Epoch: 6| Step: 12
Training loss: 2.9818273724966233
Validation loss: 2.5872402539929906

Epoch: 6| Step: 13
Training loss: 2.8228851166448314
Validation loss: 2.546538597934431

Epoch: 46| Step: 0
Training loss: 2.1394026113205515
Validation loss: 2.5945023973578496

Epoch: 6| Step: 1
Training loss: 2.2599515187287524
Validation loss: 2.5000506475404527

Epoch: 6| Step: 2
Training loss: 2.71016328073416
Validation loss: 2.5251110656785873

Epoch: 6| Step: 3
Training loss: 2.6952101535991972
Validation loss: 2.566180338755644

Epoch: 6| Step: 4
Training loss: 2.0691771651129827
Validation loss: 2.5288692628396503

Epoch: 6| Step: 5
Training loss: 2.2839900244246127
Validation loss: 2.563962813505949

Epoch: 6| Step: 6
Training loss: 3.1694064752561335
Validation loss: 2.5669374346858977

Epoch: 6| Step: 7
Training loss: 2.0641184150231773
Validation loss: 2.570249423380671

Epoch: 6| Step: 8
Training loss: 1.8769093646327903
Validation loss: 2.6254549237795533

Epoch: 6| Step: 9
Training loss: 2.5215108502192565
Validation loss: 2.591426360058318

Epoch: 6| Step: 10
Training loss: 1.828986201439183
Validation loss: 2.6436388471848202

Epoch: 6| Step: 11
Training loss: 2.590856201751517
Validation loss: 2.6092033862788533

Epoch: 6| Step: 12
Training loss: 2.050492213634636
Validation loss: 2.6244323661695663

Epoch: 6| Step: 13
Training loss: 2.6876260594810817
Validation loss: 2.6598988920609634

Epoch: 47| Step: 0
Training loss: 3.1358831487411316
Validation loss: 2.677226442502276

Epoch: 6| Step: 1
Training loss: 2.355832705997491
Validation loss: 2.59031531028612

Epoch: 6| Step: 2
Training loss: 2.595910057619909
Validation loss: 2.5786883653803114

Epoch: 6| Step: 3
Training loss: 2.1448246211490254
Validation loss: 2.610204796947132

Epoch: 6| Step: 4
Training loss: 2.333355040676324
Validation loss: 2.6191056239942028

Epoch: 6| Step: 5
Training loss: 1.8185580070333387
Validation loss: 2.606254386745698

Epoch: 6| Step: 6
Training loss: 2.757232518577101
Validation loss: 2.5872133916339597

Epoch: 6| Step: 7
Training loss: 2.374217958691821
Validation loss: 2.591315831625389

Epoch: 6| Step: 8
Training loss: 2.4455895800113034
Validation loss: 2.5786389079521337

Epoch: 6| Step: 9
Training loss: 2.453955637262687
Validation loss: 2.559731096236334

Epoch: 6| Step: 10
Training loss: 2.0608152964977955
Validation loss: 2.6406936636580576

Epoch: 6| Step: 11
Training loss: 2.1999917983855912
Validation loss: 2.605630392067633

Epoch: 6| Step: 12
Training loss: 2.5273037513739784
Validation loss: 2.5775813367573472

Epoch: 6| Step: 13
Training loss: 2.167948954723816
Validation loss: 2.595177866402255

Epoch: 48| Step: 0
Training loss: 1.6295525528801662
Validation loss: 2.5423825042842427

Epoch: 6| Step: 1
Training loss: 2.1196668683431046
Validation loss: 2.5671124389101387

Epoch: 6| Step: 2
Training loss: 3.064604833870227
Validation loss: 2.546418147077543

Epoch: 6| Step: 3
Training loss: 2.939068639202287
Validation loss: 2.56179948861597

Epoch: 6| Step: 4
Training loss: 2.5551144304424076
Validation loss: 2.5759808419144066

Epoch: 6| Step: 5
Training loss: 2.675309678450394
Validation loss: 2.5029609153328543

Epoch: 6| Step: 6
Training loss: 2.222197205349721
Validation loss: 2.557584218825868

Epoch: 6| Step: 7
Training loss: 2.806255444221908
Validation loss: 2.5961424965442825

Epoch: 6| Step: 8
Training loss: 2.0849718008718745
Validation loss: 2.560388982595745

Epoch: 6| Step: 9
Training loss: 2.071241753238889
Validation loss: 2.5372714097863778

Epoch: 6| Step: 10
Training loss: 2.1211787254214727
Validation loss: 2.54557281780324

Epoch: 6| Step: 11
Training loss: 1.9694669114543968
Validation loss: 2.55850499899498

Epoch: 6| Step: 12
Training loss: 2.6988309589944772
Validation loss: 2.5469415262032937

Epoch: 6| Step: 13
Training loss: 1.7376904801718172
Validation loss: 2.521685910610568

Epoch: 49| Step: 0
Training loss: 1.6425292090572396
Validation loss: 2.585812291920164

Epoch: 6| Step: 1
Training loss: 3.052259021341704
Validation loss: 2.601211165187615

Epoch: 6| Step: 2
Training loss: 1.7819982596708934
Validation loss: 2.6149002025031676

Epoch: 6| Step: 3
Training loss: 2.11233798427149
Validation loss: 2.6230959723169787

Epoch: 6| Step: 4
Training loss: 1.762910494786441
Validation loss: 2.639024343416147

Epoch: 6| Step: 5
Training loss: 2.4208813997925573
Validation loss: 2.6955282226332278

Epoch: 6| Step: 6
Training loss: 2.153429259573848
Validation loss: 2.7033070997226654

Epoch: 6| Step: 7
Training loss: 1.7997224222839834
Validation loss: 2.659293910223567

Epoch: 6| Step: 8
Training loss: 3.6338835419221187
Validation loss: 2.652012530448275

Epoch: 6| Step: 9
Training loss: 2.780453685817228
Validation loss: 2.586312888136622

Epoch: 6| Step: 10
Training loss: 1.9004676544479855
Validation loss: 2.682071422435686

Epoch: 6| Step: 11
Training loss: 2.7611924334941156
Validation loss: 2.588190839136213

Epoch: 6| Step: 12
Training loss: 2.2460702911478747
Validation loss: 2.5708094370600563

Epoch: 6| Step: 13
Training loss: 2.0405270516458573
Validation loss: 2.535188757987279

Epoch: 50| Step: 0
Training loss: 2.2795104618890907
Validation loss: 2.5726173370906062

Epoch: 6| Step: 1
Training loss: 2.2885720831045346
Validation loss: 2.578603680802325

Epoch: 6| Step: 2
Training loss: 2.5049152691915264
Validation loss: 2.5583224786120167

Epoch: 6| Step: 3
Training loss: 1.985151724601911
Validation loss: 2.5711094356102056

Epoch: 6| Step: 4
Training loss: 2.5807117778501483
Validation loss: 2.558211063565495

Epoch: 6| Step: 5
Training loss: 2.6135175338691163
Validation loss: 2.5973709523414397

Epoch: 6| Step: 6
Training loss: 2.4264045934151306
Validation loss: 2.6128045879503214

Epoch: 6| Step: 7
Training loss: 2.023976140149274
Validation loss: 2.567147405817832

Epoch: 6| Step: 8
Training loss: 2.505987626418903
Validation loss: 2.5680190253686903

Epoch: 6| Step: 9
Training loss: 2.448777349143092
Validation loss: 2.591374178590105

Epoch: 6| Step: 10
Training loss: 2.3450878139882443
Validation loss: 2.595479335088543

Epoch: 6| Step: 11
Training loss: 3.1404043850821606
Validation loss: 2.601921278277549

Epoch: 6| Step: 12
Training loss: 2.1676500240795535
Validation loss: 2.5853670995132596

Epoch: 6| Step: 13
Training loss: 1.8832197579877954
Validation loss: 2.6075807139655667

Epoch: 51| Step: 0
Training loss: 2.2380100372198464
Validation loss: 2.587040737876813

Epoch: 6| Step: 1
Training loss: 2.2351380225794713
Validation loss: 2.538186674429404

Epoch: 6| Step: 2
Training loss: 2.1652458618674197
Validation loss: 2.5238972846338985

Epoch: 6| Step: 3
Training loss: 3.280158597089187
Validation loss: 2.5346108404854784

Epoch: 6| Step: 4
Training loss: 3.576064403508694
Validation loss: 2.543762052040386

Epoch: 6| Step: 5
Training loss: 2.166285065522869
Validation loss: 2.6002772366828664

Epoch: 6| Step: 6
Training loss: 1.7756033959798183
Validation loss: 2.580113655440559

Epoch: 6| Step: 7
Training loss: 1.9850848272536925
Validation loss: 2.5510864231040773

Epoch: 6| Step: 8
Training loss: 2.2311310594843925
Validation loss: 2.645624412838752

Epoch: 6| Step: 9
Training loss: 2.406740411102349
Validation loss: 2.5798450473463843

Epoch: 6| Step: 10
Training loss: 1.8773422869844487
Validation loss: 2.6101197723637877

Epoch: 6| Step: 11
Training loss: 1.8964333335851566
Validation loss: 2.654197049129224

Epoch: 6| Step: 12
Training loss: 2.207930930080104
Validation loss: 2.6176481989672946

Epoch: 6| Step: 13
Training loss: 2.44421381536721
Validation loss: 2.6404296983354447

Epoch: 52| Step: 0
Training loss: 2.306380035125296
Validation loss: 2.625912500150714

Epoch: 6| Step: 1
Training loss: 3.3332733307842135
Validation loss: 2.5595740539375953

Epoch: 6| Step: 2
Training loss: 1.9711588095482608
Validation loss: 2.577440791419724

Epoch: 6| Step: 3
Training loss: 2.1832810179676754
Validation loss: 2.5779521152058216

Epoch: 6| Step: 4
Training loss: 1.8270292992541888
Validation loss: 2.5847734518529806

Epoch: 6| Step: 5
Training loss: 2.3791593971297265
Validation loss: 2.578489150714814

Epoch: 6| Step: 6
Training loss: 1.9097986179060373
Validation loss: 2.54555063587529

Epoch: 6| Step: 7
Training loss: 2.349058319692989
Validation loss: 2.5926836878298825

Epoch: 6| Step: 8
Training loss: 2.020127346821355
Validation loss: 2.630732861077411

Epoch: 6| Step: 9
Training loss: 2.8571468489482785
Validation loss: 2.583399223184662

Epoch: 6| Step: 10
Training loss: 2.002001595259268
Validation loss: 2.6208448827233326

Epoch: 6| Step: 11
Training loss: 2.609521736085192
Validation loss: 2.519779226633257

Epoch: 6| Step: 12
Training loss: 2.7123755782460917
Validation loss: 2.5468099854953112

Epoch: 6| Step: 13
Training loss: 2.2971855524537723
Validation loss: 2.5965233342428364

Epoch: 53| Step: 0
Training loss: 3.016734655327156
Validation loss: 2.649168215672497

Epoch: 6| Step: 1
Training loss: 2.449456746342619
Validation loss: 2.6393761926639723

Epoch: 6| Step: 2
Training loss: 2.5076085658355662
Validation loss: 2.6533473142977604

Epoch: 6| Step: 3
Training loss: 2.198611241614613
Validation loss: 2.674787863225486

Epoch: 6| Step: 4
Training loss: 2.638667357219948
Validation loss: 2.62606558288877

Epoch: 6| Step: 5
Training loss: 2.2345386791965995
Validation loss: 2.5807347892651222

Epoch: 6| Step: 6
Training loss: 2.549337682542057
Validation loss: 2.614821933533375

Epoch: 6| Step: 7
Training loss: 2.061726974349478
Validation loss: 2.6149383901628607

Epoch: 6| Step: 8
Training loss: 3.2611998733522354
Validation loss: 2.587237443364715

Epoch: 6| Step: 9
Training loss: 1.6387468032165586
Validation loss: 2.599506241424223

Epoch: 6| Step: 10
Training loss: 2.121574895251952
Validation loss: 2.573491350207712

Epoch: 6| Step: 11
Training loss: 1.882484502437272
Validation loss: 2.623512202174946

Epoch: 6| Step: 12
Training loss: 2.0906880322178827
Validation loss: 2.5991192897169517

Epoch: 6| Step: 13
Training loss: 2.314723621126226
Validation loss: 2.604345793603397

Epoch: 54| Step: 0
Training loss: 2.124273624812715
Validation loss: 2.5410804984597806

Epoch: 6| Step: 1
Training loss: 2.404308377942629
Validation loss: 2.6271062756675327

Epoch: 6| Step: 2
Training loss: 2.5765323227687666
Validation loss: 2.5292275909007254

Epoch: 6| Step: 3
Training loss: 2.662018649149857
Validation loss: 2.580768678569913

Epoch: 6| Step: 4
Training loss: 2.395786970491595
Validation loss: 2.53865115232629

Epoch: 6| Step: 5
Training loss: 2.3984687132155647
Validation loss: 2.602012587706221

Epoch: 6| Step: 6
Training loss: 1.9611779783602445
Validation loss: 2.526026087971788

Epoch: 6| Step: 7
Training loss: 2.083301721968832
Validation loss: 2.574766973796904

Epoch: 6| Step: 8
Training loss: 2.3295686073590582
Validation loss: 2.551388016524489

Epoch: 6| Step: 9
Training loss: 2.5446171962428923
Validation loss: 2.600142968966467

Epoch: 6| Step: 10
Training loss: 1.8722078514616658
Validation loss: 2.618785836969221

Epoch: 6| Step: 11
Training loss: 1.2104344461331311
Validation loss: 2.6327586710904836

Epoch: 6| Step: 12
Training loss: 2.548354579154202
Validation loss: 2.708363141604981

Epoch: 6| Step: 13
Training loss: 2.987440522052738
Validation loss: 2.6437858759472705

Epoch: 55| Step: 0
Training loss: 1.8970338632339239
Validation loss: 2.6768057316829883

Epoch: 6| Step: 1
Training loss: 1.860927798920912
Validation loss: 2.6373951588263482

Epoch: 6| Step: 2
Training loss: 1.939690366988401
Validation loss: 2.6510550318133115

Epoch: 6| Step: 3
Training loss: 2.500620669566407
Validation loss: 2.6331961830453965

Epoch: 6| Step: 4
Training loss: 2.6090878996833213
Validation loss: 2.5811291232990214

Epoch: 6| Step: 5
Training loss: 2.0523245680965037
Validation loss: 2.555150323565175

Epoch: 6| Step: 6
Training loss: 1.7728290606444213
Validation loss: 2.522393560845024

Epoch: 6| Step: 7
Training loss: 1.9796044384181857
Validation loss: 2.531602560223242

Epoch: 6| Step: 8
Training loss: 2.355819347094038
Validation loss: 2.5429199964124503

Epoch: 6| Step: 9
Training loss: 2.4403180191851064
Validation loss: 2.568678532679014

Epoch: 6| Step: 10
Training loss: 2.996955757524798
Validation loss: 2.580028309173916

Epoch: 6| Step: 11
Training loss: 2.068321105199545
Validation loss: 2.6164089126550585

Epoch: 6| Step: 12
Training loss: 2.330305882951351
Validation loss: 2.6160830316607098

Epoch: 6| Step: 13
Training loss: 3.204296363087397
Validation loss: 2.5665396196537706

Epoch: 56| Step: 0
Training loss: 2.3331383101387413
Validation loss: 2.624431768101512

Epoch: 6| Step: 1
Training loss: 2.3993000877552384
Validation loss: 2.573936327278385

Epoch: 6| Step: 2
Training loss: 2.9608569775907863
Validation loss: 2.5268708641086963

Epoch: 6| Step: 3
Training loss: 1.9687655009310403
Validation loss: 2.6038251780087784

Epoch: 6| Step: 4
Training loss: 2.21070585621209
Validation loss: 2.578347005822249

Epoch: 6| Step: 5
Training loss: 2.185737335660552
Validation loss: 2.579052259365618

Epoch: 6| Step: 6
Training loss: 1.8937480133348374
Validation loss: 2.5624401891907906

Epoch: 6| Step: 7
Training loss: 2.5308230946668364
Validation loss: 2.6340670591559223

Epoch: 6| Step: 8
Training loss: 1.9592898920730974
Validation loss: 2.5984201326323166

Epoch: 6| Step: 9
Training loss: 3.311978281069691
Validation loss: 2.6536086918730786

Epoch: 6| Step: 10
Training loss: 2.2751896454292457
Validation loss: 2.6020898599494426

Epoch: 6| Step: 11
Training loss: 1.7864257839192246
Validation loss: 2.5833320207489945

Epoch: 6| Step: 12
Training loss: 1.9363225004488867
Validation loss: 2.5775627524984572

Epoch: 6| Step: 13
Training loss: 2.2174066049547108
Validation loss: 2.5408438200049743

Epoch: 57| Step: 0
Training loss: 2.199127791642821
Validation loss: 2.5777536760588307

Epoch: 6| Step: 1
Training loss: 2.251812946227951
Validation loss: 2.60899904630309

Epoch: 6| Step: 2
Training loss: 2.496002243346649
Validation loss: 2.586259712359563

Epoch: 6| Step: 3
Training loss: 2.274309233710216
Validation loss: 2.5702667618752777

Epoch: 6| Step: 4
Training loss: 2.15221802055217
Validation loss: 2.573193760415598

Epoch: 6| Step: 5
Training loss: 1.881226944386078
Validation loss: 2.581456876997611

Epoch: 6| Step: 6
Training loss: 2.503616101954934
Validation loss: 2.5407237091220627

Epoch: 6| Step: 7
Training loss: 3.078966984105056
Validation loss: 2.5823099867917327

Epoch: 6| Step: 8
Training loss: 1.8440540515607222
Validation loss: 2.5966116351252855

Epoch: 6| Step: 9
Training loss: 2.104416621504405
Validation loss: 2.5544581101271255

Epoch: 6| Step: 10
Training loss: 2.1379067641822984
Validation loss: 2.6003087166146384

Epoch: 6| Step: 11
Training loss: 2.2155605548907245
Validation loss: 2.5788291354910617

Epoch: 6| Step: 12
Training loss: 2.1342795220797908
Validation loss: 2.6114620306604843

Epoch: 6| Step: 13
Training loss: 2.6012362255518138
Validation loss: 2.6384850131605546

Epoch: 58| Step: 0
Training loss: 2.3447338836568337
Validation loss: 2.648862236420994

Epoch: 6| Step: 1
Training loss: 2.2786570405230346
Validation loss: 2.73274552975883

Epoch: 6| Step: 2
Training loss: 2.5951572874761797
Validation loss: 2.654474136013851

Epoch: 6| Step: 3
Training loss: 2.0142854482810977
Validation loss: 2.6269943744583215

Epoch: 6| Step: 4
Training loss: 2.104593126748373
Validation loss: 2.6346569901361385

Epoch: 6| Step: 5
Training loss: 2.447831389111898
Validation loss: 2.641643237562605

Epoch: 6| Step: 6
Training loss: 2.29965519186352
Validation loss: 2.6401239405062276

Epoch: 6| Step: 7
Training loss: 2.5046438954651458
Validation loss: 2.5593123574638996

Epoch: 6| Step: 8
Training loss: 2.0155824168830327
Validation loss: 2.571508591153651

Epoch: 6| Step: 9
Training loss: 2.7355757338523987
Validation loss: 2.5247226902732827

Epoch: 6| Step: 10
Training loss: 2.9085192281196623
Validation loss: 2.616259851742425

Epoch: 6| Step: 11
Training loss: 2.2579261196811724
Validation loss: 2.5918199643081836

Epoch: 6| Step: 12
Training loss: 1.9230639493944794
Validation loss: 2.5448277207916297

Epoch: 6| Step: 13
Training loss: 2.2285767128116714
Validation loss: 2.584145100526232

Epoch: 59| Step: 0
Training loss: 2.113873580306847
Validation loss: 2.603230213910326

Epoch: 6| Step: 1
Training loss: 2.3794622163091335
Validation loss: 2.5339087976654313

Epoch: 6| Step: 2
Training loss: 2.2313850511556708
Validation loss: 2.6080002656372887

Epoch: 6| Step: 3
Training loss: 1.7010256926733969
Validation loss: 2.572029012129814

Epoch: 6| Step: 4
Training loss: 3.0264477000523806
Validation loss: 2.5365964680890802

Epoch: 6| Step: 5
Training loss: 2.008133205820908
Validation loss: 2.5353742289276244

Epoch: 6| Step: 6
Training loss: 1.762135932060947
Validation loss: 2.6129189065680203

Epoch: 6| Step: 7
Training loss: 2.0367281475662438
Validation loss: 2.6066438769135347

Epoch: 6| Step: 8
Training loss: 2.6249982743030507
Validation loss: 2.5904312579786253

Epoch: 6| Step: 9
Training loss: 2.0581626368283508
Validation loss: 2.573414639817478

Epoch: 6| Step: 10
Training loss: 2.9768860808780357
Validation loss: 2.5935397541673293

Epoch: 6| Step: 11
Training loss: 2.2045287942301512
Validation loss: 2.6460250474653035

Epoch: 6| Step: 12
Training loss: 1.4969922746498487
Validation loss: 2.641870539727412

Epoch: 6| Step: 13
Training loss: 2.1047201152673103
Validation loss: 2.605124462739649

Epoch: 60| Step: 0
Training loss: 1.8433632525843606
Validation loss: 2.694192036105056

Epoch: 6| Step: 1
Training loss: 2.1334484675253877
Validation loss: 2.6484948586223243

Epoch: 6| Step: 2
Training loss: 2.579504302998588
Validation loss: 2.6403189186406157

Epoch: 6| Step: 3
Training loss: 2.558574740506673
Validation loss: 2.6133769521024934

Epoch: 6| Step: 4
Training loss: 2.8302779459520884
Validation loss: 2.5826391292292796

Epoch: 6| Step: 5
Training loss: 1.8945645988124782
Validation loss: 2.6004695639486486

Epoch: 6| Step: 6
Training loss: 2.257879236416384
Validation loss: 2.60248705804241

Epoch: 6| Step: 7
Training loss: 2.431060206990149
Validation loss: 2.647096802817174

Epoch: 6| Step: 8
Training loss: 2.179062620442238
Validation loss: 2.6068848627221395

Epoch: 6| Step: 9
Training loss: 2.208183163509304
Validation loss: 2.5816195607510477

Epoch: 6| Step: 10
Training loss: 2.1596940772323903
Validation loss: 2.64084439240926

Epoch: 6| Step: 11
Training loss: 2.1839212844133535
Validation loss: 2.6216983467398034

Epoch: 6| Step: 12
Training loss: 1.9614784132999463
Validation loss: 2.6262426765215108

Epoch: 6| Step: 13
Training loss: 2.672267594968942
Validation loss: 2.670798354333913

Epoch: 61| Step: 0
Training loss: 1.9969384483322494
Validation loss: 2.634153882781782

Epoch: 6| Step: 1
Training loss: 1.796550290166929
Validation loss: 2.5475055249534546

Epoch: 6| Step: 2
Training loss: 2.503785890730494
Validation loss: 2.609942939763046

Epoch: 6| Step: 3
Training loss: 2.09404775295806
Validation loss: 2.5848542525168723

Epoch: 6| Step: 4
Training loss: 2.2286829438447655
Validation loss: 2.593230965399107

Epoch: 6| Step: 5
Training loss: 2.1944274204200083
Validation loss: 2.6128728801246215

Epoch: 6| Step: 6
Training loss: 2.0716074222718257
Validation loss: 2.604665454144957

Epoch: 6| Step: 7
Training loss: 3.277093489029546
Validation loss: 2.5894901116661067

Epoch: 6| Step: 8
Training loss: 2.0849878099483115
Validation loss: 2.645986767822996

Epoch: 6| Step: 9
Training loss: 2.226756412026191
Validation loss: 2.65736246187917

Epoch: 6| Step: 10
Training loss: 2.0194070508533275
Validation loss: 2.61547292846854

Epoch: 6| Step: 11
Training loss: 2.1944508881078617
Validation loss: 2.600973389054932

Epoch: 6| Step: 12
Training loss: 2.551650549075474
Validation loss: 2.6302712964871873

Epoch: 6| Step: 13
Training loss: 2.348020807736169
Validation loss: 2.5891463394111955

Epoch: 62| Step: 0
Training loss: 2.2903303469465994
Validation loss: 2.589817497691896

Epoch: 6| Step: 1
Training loss: 2.1345890457262544
Validation loss: 2.57745126725657

Epoch: 6| Step: 2
Training loss: 2.1248152035413432
Validation loss: 2.565999115381562

Epoch: 6| Step: 3
Training loss: 1.9534618850086736
Validation loss: 2.549966507735367

Epoch: 6| Step: 4
Training loss: 2.2678886943463183
Validation loss: 2.5610380421814054

Epoch: 6| Step: 5
Training loss: 1.830166842041526
Validation loss: 2.634785404418572

Epoch: 6| Step: 6
Training loss: 2.597393831464293
Validation loss: 2.550644968782387

Epoch: 6| Step: 7
Training loss: 2.0405047347657193
Validation loss: 2.55824647832632

Epoch: 6| Step: 8
Training loss: 2.28837049003528
Validation loss: 2.6396770845026105

Epoch: 6| Step: 9
Training loss: 2.9753586945555135
Validation loss: 2.6152611318733685

Epoch: 6| Step: 10
Training loss: 2.2710441234876164
Validation loss: 2.561819249731781

Epoch: 6| Step: 11
Training loss: 2.508504516573165
Validation loss: 2.576321535581048

Epoch: 6| Step: 12
Training loss: 2.1687612923539765
Validation loss: 2.5876690694149245

Epoch: 6| Step: 13
Training loss: 2.3760263333515024
Validation loss: 2.606180012934942

Epoch: 63| Step: 0
Training loss: 2.4945340484785037
Validation loss: 2.707931405589989

Epoch: 6| Step: 1
Training loss: 1.7580575051694254
Validation loss: 2.7435699847002595

Epoch: 6| Step: 2
Training loss: 2.688791009296707
Validation loss: 2.897680370497486

Epoch: 6| Step: 3
Training loss: 2.4767339508685646
Validation loss: 2.929419896089876

Epoch: 6| Step: 4
Training loss: 1.8780972648514975
Validation loss: 2.9628344039930794

Epoch: 6| Step: 5
Training loss: 2.6978835075628522
Validation loss: 2.921095501012516

Epoch: 6| Step: 6
Training loss: 2.5258310026961244
Validation loss: 2.857436629644244

Epoch: 6| Step: 7
Training loss: 1.962133886118489
Validation loss: 2.715907792620314

Epoch: 6| Step: 8
Training loss: 1.921362955995846
Validation loss: 2.6933698351986344

Epoch: 6| Step: 9
Training loss: 2.00665439796288
Validation loss: 2.6214760484005666

Epoch: 6| Step: 10
Training loss: 2.2321520865113325
Validation loss: 2.6153699494543305

Epoch: 6| Step: 11
Training loss: 2.097183259457499
Validation loss: 2.541861484961578

Epoch: 6| Step: 12
Training loss: 2.8818938489606527
Validation loss: 2.6133579457674547

Epoch: 6| Step: 13
Training loss: 2.106505978930518
Validation loss: 2.620217962953773

Epoch: 64| Step: 0
Training loss: 2.8700611982566295
Validation loss: 2.6092172297067378

Epoch: 6| Step: 1
Training loss: 3.3244957276189337
Validation loss: 2.629367434599045

Epoch: 6| Step: 2
Training loss: 2.496803147066303
Validation loss: 2.6459422026535697

Epoch: 6| Step: 3
Training loss: 2.6653814099402964
Validation loss: 2.6538443648645216

Epoch: 6| Step: 4
Training loss: 2.192873213874643
Validation loss: 2.5730274861262887

Epoch: 6| Step: 5
Training loss: 1.8268358951106678
Validation loss: 2.6306503730191353

Epoch: 6| Step: 6
Training loss: 2.0302302221531052
Validation loss: 2.566050574024554

Epoch: 6| Step: 7
Training loss: 2.2330591555394745
Validation loss: 2.516793479208634

Epoch: 6| Step: 8
Training loss: 1.9937092074343725
Validation loss: 2.5969003289766666

Epoch: 6| Step: 9
Training loss: 2.7191707241703416
Validation loss: 2.727529738579063

Epoch: 6| Step: 10
Training loss: 1.9824990844724448
Validation loss: 2.785378980892853

Epoch: 6| Step: 11
Training loss: 2.7379920795902914
Validation loss: 2.7812968046557667

Epoch: 6| Step: 12
Training loss: 2.042418309122418
Validation loss: 2.724385234769491

Epoch: 6| Step: 13
Training loss: 1.6482069387598373
Validation loss: 2.704947942913292

Epoch: 65| Step: 0
Training loss: 2.001440721391137
Validation loss: 2.67333740605863

Epoch: 6| Step: 1
Training loss: 2.6157129489418764
Validation loss: 2.7258216485364226

Epoch: 6| Step: 2
Training loss: 1.7098666807259955
Validation loss: 2.605845411260673

Epoch: 6| Step: 3
Training loss: 3.06710624723232
Validation loss: 2.5882130240903436

Epoch: 6| Step: 4
Training loss: 2.8464372953728065
Validation loss: 2.584087635993994

Epoch: 6| Step: 5
Training loss: 2.5389802420569687
Validation loss: 2.5868484260255284

Epoch: 6| Step: 6
Training loss: 1.715218261976668
Validation loss: 2.5631604700332544

Epoch: 6| Step: 7
Training loss: 2.3035043556697166
Validation loss: 2.5732350223255716

Epoch: 6| Step: 8
Training loss: 1.895982324244199
Validation loss: 2.552146371075874

Epoch: 6| Step: 9
Training loss: 2.1929021343445743
Validation loss: 2.583401861102247

Epoch: 6| Step: 10
Training loss: 1.4766254714374762
Validation loss: 2.5745740692553145

Epoch: 6| Step: 11
Training loss: 2.5863169596260653
Validation loss: 2.5495965376668543

Epoch: 6| Step: 12
Training loss: 2.248138823563489
Validation loss: 2.5706821473448267

Epoch: 6| Step: 13
Training loss: 1.8791407321851714
Validation loss: 2.5102881930283414

Epoch: 66| Step: 0
Training loss: 2.3900325265370914
Validation loss: 2.580832899198495

Epoch: 6| Step: 1
Training loss: 1.973119337661637
Validation loss: 2.5473337676893095

Epoch: 6| Step: 2
Training loss: 2.7688577153111242
Validation loss: 2.5196375151706296

Epoch: 6| Step: 3
Training loss: 2.1716741016150394
Validation loss: 2.583375166482511

Epoch: 6| Step: 4
Training loss: 1.6642753930534873
Validation loss: 2.581356666460799

Epoch: 6| Step: 5
Training loss: 1.9119254502083864
Validation loss: 2.5805054743131635

Epoch: 6| Step: 6
Training loss: 1.6983873459921819
Validation loss: 2.646123469707383

Epoch: 6| Step: 7
Training loss: 1.96754079347464
Validation loss: 2.629069821548439

Epoch: 6| Step: 8
Training loss: 2.138567415934971
Validation loss: 2.6072158865458004

Epoch: 6| Step: 9
Training loss: 1.9739546025089112
Validation loss: 2.6323721165522227

Epoch: 6| Step: 10
Training loss: 2.6756655925620105
Validation loss: 2.5674623109725023

Epoch: 6| Step: 11
Training loss: 2.2992146312120663
Validation loss: 2.5745116063864737

Epoch: 6| Step: 12
Training loss: 2.2912738000910418
Validation loss: 2.593375902888876

Epoch: 6| Step: 13
Training loss: 2.876648803278277
Validation loss: 2.550177323028928

Epoch: 67| Step: 0
Training loss: 2.7915192370605126
Validation loss: 2.5129535936178686

Epoch: 6| Step: 1
Training loss: 2.175298284487753
Validation loss: 2.5216394559455666

Epoch: 6| Step: 2
Training loss: 2.420353663902844
Validation loss: 2.532457040345176

Epoch: 6| Step: 3
Training loss: 1.9654783888632872
Validation loss: 2.5508562576458558

Epoch: 6| Step: 4
Training loss: 1.8880582678580522
Validation loss: 2.5953341016764186

Epoch: 6| Step: 5
Training loss: 2.3923841997301882
Validation loss: 2.5792600579883587

Epoch: 6| Step: 6
Training loss: 2.4784717601023822
Validation loss: 2.6087058117226403

Epoch: 6| Step: 7
Training loss: 2.3840163894896413
Validation loss: 2.604203740173932

Epoch: 6| Step: 8
Training loss: 2.284222899668746
Validation loss: 2.5746879400891944

Epoch: 6| Step: 9
Training loss: 2.2949349650557527
Validation loss: 2.599525364321529

Epoch: 6| Step: 10
Training loss: 1.9148133342791032
Validation loss: 2.5233194266489956

Epoch: 6| Step: 11
Training loss: 2.2675974711168703
Validation loss: 2.588686800187879

Epoch: 6| Step: 12
Training loss: 1.7338127393310179
Validation loss: 2.6520999277639024

Epoch: 6| Step: 13
Training loss: 2.107335213478229
Validation loss: 2.688678763873695

Epoch: 68| Step: 0
Training loss: 1.8291260676415073
Validation loss: 2.7002851971364104

Epoch: 6| Step: 1
Training loss: 2.144388718723764
Validation loss: 2.6586380415208914

Epoch: 6| Step: 2
Training loss: 1.8316769775896442
Validation loss: 2.6656134035336

Epoch: 6| Step: 3
Training loss: 2.2982853302934645
Validation loss: 2.692850169437443

Epoch: 6| Step: 4
Training loss: 1.6484385124311909
Validation loss: 2.6094255651877933

Epoch: 6| Step: 5
Training loss: 2.3388964434169726
Validation loss: 2.596433928452863

Epoch: 6| Step: 6
Training loss: 1.5489788198580692
Validation loss: 2.606103075431117

Epoch: 6| Step: 7
Training loss: 1.8661999505007558
Validation loss: 2.6198014903152957

Epoch: 6| Step: 8
Training loss: 2.5649988039843055
Validation loss: 2.5698763120699755

Epoch: 6| Step: 9
Training loss: 2.792184487518923
Validation loss: 2.621552140639882

Epoch: 6| Step: 10
Training loss: 1.9701585121090368
Validation loss: 2.5568314323981025

Epoch: 6| Step: 11
Training loss: 2.404004919824628
Validation loss: 2.524443198650162

Epoch: 6| Step: 12
Training loss: 2.1155357533595778
Validation loss: 2.5675589238790493

Epoch: 6| Step: 13
Training loss: 3.2774544698315564
Validation loss: 2.593780885075907

Epoch: 69| Step: 0
Training loss: 2.351709000089053
Validation loss: 2.577492052467444

Epoch: 6| Step: 1
Training loss: 2.1149329536939474
Validation loss: 2.6147248633835036

Epoch: 6| Step: 2
Training loss: 2.2734029970467624
Validation loss: 2.5506609060222756

Epoch: 6| Step: 3
Training loss: 1.947084163984234
Validation loss: 2.587372995106833

Epoch: 6| Step: 4
Training loss: 1.4980989966843237
Validation loss: 2.5671381185050026

Epoch: 6| Step: 5
Training loss: 1.7494121654142891
Validation loss: 2.632750996249545

Epoch: 6| Step: 6
Training loss: 2.5195867014852396
Validation loss: 2.645049862743178

Epoch: 6| Step: 7
Training loss: 1.9465819969554254
Validation loss: 2.6553105057914688

Epoch: 6| Step: 8
Training loss: 2.895617159086233
Validation loss: 2.674157756942341

Epoch: 6| Step: 9
Training loss: 3.1272774599031443
Validation loss: 2.660426517748138

Epoch: 6| Step: 10
Training loss: 2.3796662117399734
Validation loss: 2.7848319087275897

Epoch: 6| Step: 11
Training loss: 1.759064495541621
Validation loss: 2.6430841390476596

Epoch: 6| Step: 12
Training loss: 2.2994861941087996
Validation loss: 2.5913344629277244

Epoch: 6| Step: 13
Training loss: 1.8418889755894157
Validation loss: 2.6599965619421133

Epoch: 70| Step: 0
Training loss: 1.394090641629576
Validation loss: 2.6245302052401254

Epoch: 6| Step: 1
Training loss: 2.206668033925965
Validation loss: 2.525795652594477

Epoch: 6| Step: 2
Training loss: 1.588168749786515
Validation loss: 2.5713659444756476

Epoch: 6| Step: 3
Training loss: 2.6443201879574283
Validation loss: 2.586470104430923

Epoch: 6| Step: 4
Training loss: 2.31156263169137
Validation loss: 2.6049272698044303

Epoch: 6| Step: 5
Training loss: 2.026658017533234
Validation loss: 2.6065205629514425

Epoch: 6| Step: 6
Training loss: 2.221462364885963
Validation loss: 2.6171878188403492

Epoch: 6| Step: 7
Training loss: 1.96451464223126
Validation loss: 2.593626440697757

Epoch: 6| Step: 8
Training loss: 2.148561231344745
Validation loss: 2.6287903290159944

Epoch: 6| Step: 9
Training loss: 3.4536041341623
Validation loss: 2.5876562086735366

Epoch: 6| Step: 10
Training loss: 2.2745151128797234
Validation loss: 2.621996023592636

Epoch: 6| Step: 11
Training loss: 2.064712262739114
Validation loss: 2.5722421438911804

Epoch: 6| Step: 12
Training loss: 2.374873509301214
Validation loss: 2.607269137858345

Epoch: 6| Step: 13
Training loss: 1.4565656393590625
Validation loss: 2.644793558940133

Epoch: 71| Step: 0
Training loss: 2.2886767794752982
Validation loss: 2.661265257359684

Epoch: 6| Step: 1
Training loss: 2.763701551298265
Validation loss: 2.6235646456181616

Epoch: 6| Step: 2
Training loss: 1.5633078203512143
Validation loss: 2.6411509544961325

Epoch: 6| Step: 3
Training loss: 1.8305369059581145
Validation loss: 2.596035620541506

Epoch: 6| Step: 4
Training loss: 2.0371553702936023
Validation loss: 2.56071884776589

Epoch: 6| Step: 5
Training loss: 2.140894963303077
Validation loss: 2.5928319202443846

Epoch: 6| Step: 6
Training loss: 1.5731250380711936
Validation loss: 2.57872725108904

Epoch: 6| Step: 7
Training loss: 2.4950512543270027
Validation loss: 2.5809656234387073

Epoch: 6| Step: 8
Training loss: 2.5690197693927943
Validation loss: 2.5874224621984716

Epoch: 6| Step: 9
Training loss: 2.382867731173423
Validation loss: 2.5913123813695154

Epoch: 6| Step: 10
Training loss: 1.8938301598230427
Validation loss: 2.6601071346190865

Epoch: 6| Step: 11
Training loss: 2.047251193587635
Validation loss: 2.6371323550746864

Epoch: 6| Step: 12
Training loss: 2.381057643380066
Validation loss: 2.543869632466545

Epoch: 6| Step: 13
Training loss: 2.0216315616705676
Validation loss: 2.5825292402337268

Epoch: 72| Step: 0
Training loss: 1.8309412725292222
Validation loss: 2.5518401879981827

Epoch: 6| Step: 1
Training loss: 2.516300276639168
Validation loss: 2.6233097871582434

Epoch: 6| Step: 2
Training loss: 2.026358363120846
Validation loss: 2.6099803321409136

Epoch: 6| Step: 3
Training loss: 2.2017872313245723
Validation loss: 2.675278457218848

Epoch: 6| Step: 4
Training loss: 1.9910070175514725
Validation loss: 2.6985721503736184

Epoch: 6| Step: 5
Training loss: 2.5395456646657024
Validation loss: 2.7085070823298443

Epoch: 6| Step: 6
Training loss: 1.9367892284426245
Validation loss: 2.711111043016332

Epoch: 6| Step: 7
Training loss: 1.7867040289108518
Validation loss: 2.5956897376456527

Epoch: 6| Step: 8
Training loss: 1.5990781542421977
Validation loss: 2.625843094355936

Epoch: 6| Step: 9
Training loss: 1.9256899427081682
Validation loss: 2.61345346260662

Epoch: 6| Step: 10
Training loss: 1.9737149560775584
Validation loss: 2.581839765488201

Epoch: 6| Step: 11
Training loss: 2.7343758719306646
Validation loss: 2.6067648527754486

Epoch: 6| Step: 12
Training loss: 2.173050596572402
Validation loss: 2.595496535661247

Epoch: 6| Step: 13
Training loss: 2.6310312828080367
Validation loss: 2.5652786014842186

Epoch: 73| Step: 0
Training loss: 2.1155594199988568
Validation loss: 2.5753334113501287

Epoch: 6| Step: 1
Training loss: 2.71459388955309
Validation loss: 2.526112448628091

Epoch: 6| Step: 2
Training loss: 2.219926334224252
Validation loss: 2.602410194589336

Epoch: 6| Step: 3
Training loss: 2.792377371968497
Validation loss: 2.580802513540447

Epoch: 6| Step: 4
Training loss: 2.8808074015438865
Validation loss: 2.5458750409727986

Epoch: 6| Step: 5
Training loss: 2.4335459402908053
Validation loss: 2.54262389204709

Epoch: 6| Step: 6
Training loss: 1.9175534546524602
Validation loss: 2.602778061991481

Epoch: 6| Step: 7
Training loss: 1.8113439095677075
Validation loss: 2.645298390614675

Epoch: 6| Step: 8
Training loss: 1.5503341068606817
Validation loss: 2.55121175454166

Epoch: 6| Step: 9
Training loss: 2.178843673294399
Validation loss: 2.62211039611374

Epoch: 6| Step: 10
Training loss: 1.4497224903920611
Validation loss: 2.642051928211782

Epoch: 6| Step: 11
Training loss: 2.0193907580030914
Validation loss: 2.643507999439569

Epoch: 6| Step: 12
Training loss: 1.751407329890129
Validation loss: 2.6854956493694013

Epoch: 6| Step: 13
Training loss: 1.904643773491554
Validation loss: 2.763222780796338

Epoch: 74| Step: 0
Training loss: 2.1378407435397917
Validation loss: 2.7584138598217236

Epoch: 6| Step: 1
Training loss: 2.15453945257114
Validation loss: 2.6791920254833648

Epoch: 6| Step: 2
Training loss: 1.825495597748371
Validation loss: 2.7170934051372235

Epoch: 6| Step: 3
Training loss: 2.6139350381205735
Validation loss: 2.6728282068431

Epoch: 6| Step: 4
Training loss: 2.3067342689104273
Validation loss: 2.6050176272830092

Epoch: 6| Step: 5
Training loss: 1.472006090161952
Validation loss: 2.5889839137414863

Epoch: 6| Step: 6
Training loss: 2.252819519921016
Validation loss: 2.614824980451959

Epoch: 6| Step: 7
Training loss: 2.723717897111306
Validation loss: 2.60309158767805

Epoch: 6| Step: 8
Training loss: 1.6731628734019848
Validation loss: 2.5150548948410902

Epoch: 6| Step: 9
Training loss: 2.1650202315444598
Validation loss: 2.6290798573941383

Epoch: 6| Step: 10
Training loss: 2.300275400508029
Validation loss: 2.5282235753881896

Epoch: 6| Step: 11
Training loss: 1.9981703734056329
Validation loss: 2.637373929980605

Epoch: 6| Step: 12
Training loss: 2.102114806933613
Validation loss: 2.6247902892373265

Epoch: 6| Step: 13
Training loss: 1.8982533809089672
Validation loss: 2.6249879503730447

Epoch: 75| Step: 0
Training loss: 2.257721790220698
Validation loss: 2.6276514498360237

Epoch: 6| Step: 1
Training loss: 2.3999412370481448
Validation loss: 2.6963969384884967

Epoch: 6| Step: 2
Training loss: 1.8111363904875082
Validation loss: 2.689776565284421

Epoch: 6| Step: 3
Training loss: 2.5505258803304374
Validation loss: 2.732527975513314

Epoch: 6| Step: 4
Training loss: 1.8223333315521644
Validation loss: 2.7343612379908517

Epoch: 6| Step: 5
Training loss: 2.614931050516686
Validation loss: 2.68191543952811

Epoch: 6| Step: 6
Training loss: 2.058389440021492
Validation loss: 2.6822686549313763

Epoch: 6| Step: 7
Training loss: 3.11214932837061
Validation loss: 2.6772273033605596

Epoch: 6| Step: 8
Training loss: 2.003759189139634
Validation loss: 2.6541688956985414

Epoch: 6| Step: 9
Training loss: 2.0762292920388434
Validation loss: 2.634044800288302

Epoch: 6| Step: 10
Training loss: 2.2587179196670397
Validation loss: 2.596311078468131

Epoch: 6| Step: 11
Training loss: 1.5439264729440394
Validation loss: 2.5841114400280505

Epoch: 6| Step: 12
Training loss: 1.406466064808579
Validation loss: 2.60971079357984

Epoch: 6| Step: 13
Training loss: 2.038650295642581
Validation loss: 2.623237487426725

Epoch: 76| Step: 0
Training loss: 1.6866695338565345
Validation loss: 2.638370326327643

Epoch: 6| Step: 1
Training loss: 1.6535312723040798
Validation loss: 2.6398006107914482

Epoch: 6| Step: 2
Training loss: 2.0293194326224593
Validation loss: 2.555823910371093

Epoch: 6| Step: 3
Training loss: 2.2252863924680386
Validation loss: 2.558150678714375

Epoch: 6| Step: 4
Training loss: 2.2673208269789242
Validation loss: 2.5457715255385187

Epoch: 6| Step: 5
Training loss: 1.8273625536371545
Validation loss: 2.6454488570040833

Epoch: 6| Step: 6
Training loss: 1.7159541886045577
Validation loss: 2.563320447255234

Epoch: 6| Step: 7
Training loss: 2.1747312357797175
Validation loss: 2.6285727574214777

Epoch: 6| Step: 8
Training loss: 2.4388502244870365
Validation loss: 2.6223548550073166

Epoch: 6| Step: 9
Training loss: 1.7634690887363778
Validation loss: 2.666899988775396

Epoch: 6| Step: 10
Training loss: 2.296091374217255
Validation loss: 2.68400510608682

Epoch: 6| Step: 11
Training loss: 2.8700590384123057
Validation loss: 2.6677556993082043

Epoch: 6| Step: 12
Training loss: 2.32372344052638
Validation loss: 2.663303494586666

Epoch: 6| Step: 13
Training loss: 2.3558188410734786
Validation loss: 2.670876396316066

Epoch: 77| Step: 0
Training loss: 1.445873502160503
Validation loss: 2.630042621692653

Epoch: 6| Step: 1
Training loss: 2.0444133603570958
Validation loss: 2.6431807615361085

Epoch: 6| Step: 2
Training loss: 2.7618851024808073
Validation loss: 2.616094765356792

Epoch: 6| Step: 3
Training loss: 1.527314246787858
Validation loss: 2.5736890140698425

Epoch: 6| Step: 4
Training loss: 1.9523156281972625
Validation loss: 2.615992593096631

Epoch: 6| Step: 5
Training loss: 2.2921726592974005
Validation loss: 2.5784199940847685

Epoch: 6| Step: 6
Training loss: 1.4701121892092774
Validation loss: 2.5729353797221792

Epoch: 6| Step: 7
Training loss: 2.1836241035876673
Validation loss: 2.605308272315734

Epoch: 6| Step: 8
Training loss: 2.014752694565159
Validation loss: 2.602586225949487

Epoch: 6| Step: 9
Training loss: 2.339210488244482
Validation loss: 2.5606015313758075

Epoch: 6| Step: 10
Training loss: 2.714431665555015
Validation loss: 2.6199287975260206

Epoch: 6| Step: 11
Training loss: 1.7719499171866975
Validation loss: 2.605152429293304

Epoch: 6| Step: 12
Training loss: 1.9480786247718151
Validation loss: 2.575561381690368

Epoch: 6| Step: 13
Training loss: 2.111498180954999
Validation loss: 2.5993685248941616

Epoch: 78| Step: 0
Training loss: 1.9532225317445027
Validation loss: 2.5614986168815896

Epoch: 6| Step: 1
Training loss: 2.728842407842714
Validation loss: 2.596325495697754

Epoch: 6| Step: 2
Training loss: 1.9927810682258893
Validation loss: 2.62315241567485

Epoch: 6| Step: 3
Training loss: 1.92294269460116
Validation loss: 2.611651571514598

Epoch: 6| Step: 4
Training loss: 2.3308120684380507
Validation loss: 2.6577990783316636

Epoch: 6| Step: 5
Training loss: 1.7132879685854217
Validation loss: 2.663567863477753

Epoch: 6| Step: 6
Training loss: 1.903339665775933
Validation loss: 2.729081455870917

Epoch: 6| Step: 7
Training loss: 1.9715590645564718
Validation loss: 2.668592596958606

Epoch: 6| Step: 8
Training loss: 1.935175824518733
Validation loss: 2.594636298425656

Epoch: 6| Step: 9
Training loss: 2.22917605484266
Validation loss: 2.6317555978528926

Epoch: 6| Step: 10
Training loss: 1.9090350084047225
Validation loss: 2.6023893140279504

Epoch: 6| Step: 11
Training loss: 2.6145044950678944
Validation loss: 2.627622172681791

Epoch: 6| Step: 12
Training loss: 1.8823299818532073
Validation loss: 2.6820330350065973

Epoch: 6| Step: 13
Training loss: 1.7573951056095665
Validation loss: 2.6207733640698256

Epoch: 79| Step: 0
Training loss: 2.102052879553976
Validation loss: 2.58088919678796

Epoch: 6| Step: 1
Training loss: 1.9401376059976516
Validation loss: 2.5705291131139467

Epoch: 6| Step: 2
Training loss: 2.146624990062639
Validation loss: 2.62262153348728

Epoch: 6| Step: 3
Training loss: 2.222472386054527
Validation loss: 2.5659321850819308

Epoch: 6| Step: 4
Training loss: 1.969080639882601
Validation loss: 2.657022289129033

Epoch: 6| Step: 5
Training loss: 2.4842317167985364
Validation loss: 2.5812865013762214

Epoch: 6| Step: 6
Training loss: 1.4534680361544945
Validation loss: 2.569291148610315

Epoch: 6| Step: 7
Training loss: 2.0152544967436516
Validation loss: 2.6708176660499734

Epoch: 6| Step: 8
Training loss: 1.8697290082401676
Validation loss: 2.6668226275931146

Epoch: 6| Step: 9
Training loss: 1.858462646786349
Validation loss: 2.6682578247207203

Epoch: 6| Step: 10
Training loss: 1.6881235171681925
Validation loss: 2.642916939370698

Epoch: 6| Step: 11
Training loss: 2.0222937691203637
Validation loss: 2.6249307290277226

Epoch: 6| Step: 12
Training loss: 2.459652907533319
Validation loss: 2.711143683692116

Epoch: 6| Step: 13
Training loss: 2.363985722739131
Validation loss: 2.6520955152648846

Epoch: 80| Step: 0
Training loss: 2.2641954844969994
Validation loss: 2.6521547649999238

Epoch: 6| Step: 1
Training loss: 2.118894895027093
Validation loss: 2.624019454803492

Epoch: 6| Step: 2
Training loss: 2.023879544198179
Validation loss: 2.5896247168927466

Epoch: 6| Step: 3
Training loss: 1.7240881126704242
Validation loss: 2.660768323662282

Epoch: 6| Step: 4
Training loss: 2.2557580173725804
Validation loss: 2.619687183842289

Epoch: 6| Step: 5
Training loss: 1.9449444771223534
Validation loss: 2.5997274836749327

Epoch: 6| Step: 6
Training loss: 1.751891068089887
Validation loss: 2.676411189345071

Epoch: 6| Step: 7
Training loss: 1.7156628713961708
Validation loss: 2.6225212898032675

Epoch: 6| Step: 8
Training loss: 3.1652308438020227
Validation loss: 2.6335893233933576

Epoch: 6| Step: 9
Training loss: 1.939073969263774
Validation loss: 2.6339432941484042

Epoch: 6| Step: 10
Training loss: 1.5059161342507112
Validation loss: 2.653301217884803

Epoch: 6| Step: 11
Training loss: 2.127721054122291
Validation loss: 2.6144666810375092

Epoch: 6| Step: 12
Training loss: 1.8522109815493804
Validation loss: 2.6036208737947306

Epoch: 6| Step: 13
Training loss: 2.372230722241903
Validation loss: 2.658925672286348

Epoch: 81| Step: 0
Training loss: 1.902615443573148
Validation loss: 2.6569840707154273

Epoch: 6| Step: 1
Training loss: 2.2067873119476964
Validation loss: 2.5873639262934103

Epoch: 6| Step: 2
Training loss: 1.6303097466885565
Validation loss: 2.5396423929642205

Epoch: 6| Step: 3
Training loss: 1.8022391485278328
Validation loss: 2.6416025252231763

Epoch: 6| Step: 4
Training loss: 1.7669362288378676
Validation loss: 2.622340171751063

Epoch: 6| Step: 5
Training loss: 2.0407242708464026
Validation loss: 2.5997614616618026

Epoch: 6| Step: 6
Training loss: 2.1701134872645307
Validation loss: 2.5499810311602995

Epoch: 6| Step: 7
Training loss: 3.1205938175170735
Validation loss: 2.5866235243707787

Epoch: 6| Step: 8
Training loss: 1.757944466617527
Validation loss: 2.6132136603692

Epoch: 6| Step: 9
Training loss: 1.8734294035341297
Validation loss: 2.650390137738207

Epoch: 6| Step: 10
Training loss: 2.2146528858113563
Validation loss: 2.695332682805813

Epoch: 6| Step: 11
Training loss: 1.5750068603850618
Validation loss: 2.738894145032866

Epoch: 6| Step: 12
Training loss: 1.8937347940268807
Validation loss: 2.7309462639564397

Epoch: 6| Step: 13
Training loss: 2.522109305122374
Validation loss: 2.7217414446538877

Epoch: 82| Step: 0
Training loss: 1.9087894596999933
Validation loss: 2.672069906818352

Epoch: 6| Step: 1
Training loss: 2.7794547126650326
Validation loss: 2.6872476414918465

Epoch: 6| Step: 2
Training loss: 2.4677293816556194
Validation loss: 2.62417453320914

Epoch: 6| Step: 3
Training loss: 1.797236265271427
Validation loss: 2.6083388565135

Epoch: 6| Step: 4
Training loss: 1.8837868476407729
Validation loss: 2.6261113932420455

Epoch: 6| Step: 5
Training loss: 2.4010371430879185
Validation loss: 2.593377098026384

Epoch: 6| Step: 6
Training loss: 2.2090301374017556
Validation loss: 2.5747328743137134

Epoch: 6| Step: 7
Training loss: 2.3811585736683103
Validation loss: 2.64527841190397

Epoch: 6| Step: 8
Training loss: 1.6661866291469853
Validation loss: 2.5573181544613517

Epoch: 6| Step: 9
Training loss: 0.9217335867314115
Validation loss: 2.558307738491927

Epoch: 6| Step: 10
Training loss: 1.9074565633525342
Validation loss: 2.5269368240601984

Epoch: 6| Step: 11
Training loss: 2.2123714689863156
Validation loss: 2.5444738384512795

Epoch: 6| Step: 12
Training loss: 2.2004404147349295
Validation loss: 2.6003067911540256

Epoch: 6| Step: 13
Training loss: 1.9262160609261234
Validation loss: 2.663157707490379

Epoch: 83| Step: 0
Training loss: 2.5497310047760546
Validation loss: 2.7035653227932532

Epoch: 6| Step: 1
Training loss: 2.1003680042980575
Validation loss: 2.7654122883233874

Epoch: 6| Step: 2
Training loss: 2.4723446907350737
Validation loss: 2.694268862147593

Epoch: 6| Step: 3
Training loss: 1.8966388737676374
Validation loss: 2.7586550627716826

Epoch: 6| Step: 4
Training loss: 1.9641966465164642
Validation loss: 2.7157646684685615

Epoch: 6| Step: 5
Training loss: 1.8625386995736941
Validation loss: 2.684669408614782

Epoch: 6| Step: 6
Training loss: 1.9828955474367977
Validation loss: 2.6339624687519803

Epoch: 6| Step: 7
Training loss: 1.8360132729335215
Validation loss: 2.6194552337632837

Epoch: 6| Step: 8
Training loss: 1.2306121258234184
Validation loss: 2.598444218262723

Epoch: 6| Step: 9
Training loss: 1.8559076372381746
Validation loss: 2.6032829819847834

Epoch: 6| Step: 10
Training loss: 2.6009049601308583
Validation loss: 2.6150412494136392

Epoch: 6| Step: 11
Training loss: 1.510096110386276
Validation loss: 2.5938079245353785

Epoch: 6| Step: 12
Training loss: 2.143467262240521
Validation loss: 2.55840732196178

Epoch: 6| Step: 13
Training loss: 2.3587645694705213
Validation loss: 2.5545338653501912

Epoch: 84| Step: 0
Training loss: 1.6752262930525448
Validation loss: 2.621089762851887

Epoch: 6| Step: 1
Training loss: 2.1800510554503343
Validation loss: 2.603415218018747

Epoch: 6| Step: 2
Training loss: 1.5730481966447452
Validation loss: 2.592474029935752

Epoch: 6| Step: 3
Training loss: 2.6181520421208586
Validation loss: 2.6309012353290746

Epoch: 6| Step: 4
Training loss: 1.098654079655268
Validation loss: 2.6793311116567744

Epoch: 6| Step: 5
Training loss: 2.1071822460640277
Validation loss: 2.697118830202441

Epoch: 6| Step: 6
Training loss: 2.1921578000830797
Validation loss: 2.6915095087552277

Epoch: 6| Step: 7
Training loss: 2.1194000507247814
Validation loss: 2.6926855877051494

Epoch: 6| Step: 8
Training loss: 1.9960520641057562
Validation loss: 2.628398398422696

Epoch: 6| Step: 9
Training loss: 2.1640794663848677
Validation loss: 2.6457907505563574

Epoch: 6| Step: 10
Training loss: 2.079262329020978
Validation loss: 2.5548631333572427

Epoch: 6| Step: 11
Training loss: 1.9096235847045904
Validation loss: 2.576304430632623

Epoch: 6| Step: 12
Training loss: 1.8221604295400131
Validation loss: 2.5668038302675513

Epoch: 6| Step: 13
Training loss: 2.417363252766368
Validation loss: 2.6409953382480533

Epoch: 85| Step: 0
Training loss: 1.5333506130544055
Validation loss: 2.638220344874426

Epoch: 6| Step: 1
Training loss: 2.472421354734399
Validation loss: 2.582962291487079

Epoch: 6| Step: 2
Training loss: 2.0196245123986643
Validation loss: 2.614837426431648

Epoch: 6| Step: 3
Training loss: 2.094691961398375
Validation loss: 2.5731244228567163

Epoch: 6| Step: 4
Training loss: 2.0477831041847834
Validation loss: 2.571333074814804

Epoch: 6| Step: 5
Training loss: 2.1640045488771587
Validation loss: 2.622479742703477

Epoch: 6| Step: 6
Training loss: 1.5270282390209207
Validation loss: 2.583074177284265

Epoch: 6| Step: 7
Training loss: 1.7945928261621482
Validation loss: 2.6307551479674096

Epoch: 6| Step: 8
Training loss: 1.6151653676358284
Validation loss: 2.58745869036884

Epoch: 6| Step: 9
Training loss: 2.109270333413075
Validation loss: 2.639294576971076

Epoch: 6| Step: 10
Training loss: 1.9462001874033545
Validation loss: 2.6064513649363428

Epoch: 6| Step: 11
Training loss: 2.1866348735700023
Validation loss: 2.655158323463264

Epoch: 6| Step: 12
Training loss: 0.650466593753229
Validation loss: 2.6437373732918372

Epoch: 6| Step: 13
Training loss: 2.910460181014507
Validation loss: 2.6471998835774504

Epoch: 86| Step: 0
Training loss: 1.7423595121168625
Validation loss: 2.6348816148824596

Epoch: 6| Step: 1
Training loss: 1.8809011421042359
Validation loss: 2.6108303770244805

Epoch: 6| Step: 2
Training loss: 2.6025950356023584
Validation loss: 2.7114266605605906

Epoch: 6| Step: 3
Training loss: 1.4958792350902266
Validation loss: 2.772417036557472

Epoch: 6| Step: 4
Training loss: 2.613963586881983
Validation loss: 2.735445390731096

Epoch: 6| Step: 5
Training loss: 1.7059059886184802
Validation loss: 2.71318561954027

Epoch: 6| Step: 6
Training loss: 1.9810655285368362
Validation loss: 2.7135627340620423

Epoch: 6| Step: 7
Training loss: 1.923883830391957
Validation loss: 2.742500149690061

Epoch: 6| Step: 8
Training loss: 1.7548341059731813
Validation loss: 2.647101111063882

Epoch: 6| Step: 9
Training loss: 2.228052330169586
Validation loss: 2.6746157853031276

Epoch: 6| Step: 10
Training loss: 1.858161851072913
Validation loss: 2.6549950047174793

Epoch: 6| Step: 11
Training loss: 1.4142566357963187
Validation loss: 2.623687067632592

Epoch: 6| Step: 12
Training loss: 1.785306494335648
Validation loss: 2.556864674977116

Epoch: 6| Step: 13
Training loss: 2.274097674497359
Validation loss: 2.6415074546160486

Epoch: 87| Step: 0
Training loss: 1.949517787095919
Validation loss: 2.6403059381045333

Epoch: 6| Step: 1
Training loss: 2.232523651339507
Validation loss: 2.612397200708034

Epoch: 6| Step: 2
Training loss: 1.7443932225400758
Validation loss: 2.584526775905035

Epoch: 6| Step: 3
Training loss: 2.662850201996482
Validation loss: 2.618243301522416

Epoch: 6| Step: 4
Training loss: 2.682980574251387
Validation loss: 2.5892912599977134

Epoch: 6| Step: 5
Training loss: 1.8542247577382502
Validation loss: 2.5766228355127567

Epoch: 6| Step: 6
Training loss: 1.9966467522449038
Validation loss: 2.5816488824489987

Epoch: 6| Step: 7
Training loss: 1.8879612845314515
Validation loss: 2.6119242339412896

Epoch: 6| Step: 8
Training loss: 1.694440837328186
Validation loss: 2.67939185762838

Epoch: 6| Step: 9
Training loss: 1.7306242242207275
Validation loss: 2.6898942971999182

Epoch: 6| Step: 10
Training loss: 1.427788979964257
Validation loss: 2.5908589394368335

Epoch: 6| Step: 11
Training loss: 1.9159247233907895
Validation loss: 2.6053279779581544

Epoch: 6| Step: 12
Training loss: 2.2787771539540262
Validation loss: 2.5531365589267727

Epoch: 6| Step: 13
Training loss: 1.8396386682202583
Validation loss: 2.5882530793494367

Epoch: 88| Step: 0
Training loss: 1.7233265375019322
Validation loss: 2.5969780287520106

Epoch: 6| Step: 1
Training loss: 1.7171824850021316
Validation loss: 2.645107114554347

Epoch: 6| Step: 2
Training loss: 3.1268100836856845
Validation loss: 2.583082038183087

Epoch: 6| Step: 3
Training loss: 2.0655926723518676
Validation loss: 2.5975386208119016

Epoch: 6| Step: 4
Training loss: 1.141166401754194
Validation loss: 2.5436089135236712

Epoch: 6| Step: 5
Training loss: 1.596349578236825
Validation loss: 2.683414429175652

Epoch: 6| Step: 6
Training loss: 2.177464599321612
Validation loss: 2.6627753048257503

Epoch: 6| Step: 7
Training loss: 1.8015231178657443
Validation loss: 2.639145664359977

Epoch: 6| Step: 8
Training loss: 1.6982781975094259
Validation loss: 2.6201769859531834

Epoch: 6| Step: 9
Training loss: 2.0670084373327757
Validation loss: 2.666524828675242

Epoch: 6| Step: 10
Training loss: 1.2383250520582445
Validation loss: 2.6623531462237535

Epoch: 6| Step: 11
Training loss: 2.1300001221419467
Validation loss: 2.7352500750522473

Epoch: 6| Step: 12
Training loss: 2.118374087314068
Validation loss: 2.6158248466490948

Epoch: 6| Step: 13
Training loss: 1.9990613642133712
Validation loss: 2.6579662986419503

Epoch: 89| Step: 0
Training loss: 1.8608711057873208
Validation loss: 2.685370288938678

Epoch: 6| Step: 1
Training loss: 1.786856144541754
Validation loss: 2.6239846854548032

Epoch: 6| Step: 2
Training loss: 1.8661505720834475
Validation loss: 2.592584233106528

Epoch: 6| Step: 3
Training loss: 2.6009044101255148
Validation loss: 2.67020524704096

Epoch: 6| Step: 4
Training loss: 2.211186802695787
Validation loss: 2.5526506429189073

Epoch: 6| Step: 5
Training loss: 2.099946829713093
Validation loss: 2.6081342659773545

Epoch: 6| Step: 6
Training loss: 2.3402451822015107
Validation loss: 2.6215431521696804

Epoch: 6| Step: 7
Training loss: 1.673204125409714
Validation loss: 2.6520183740068517

Epoch: 6| Step: 8
Training loss: 1.8389503593901462
Validation loss: 2.530289079035502

Epoch: 6| Step: 9
Training loss: 2.0625670451046574
Validation loss: 2.592024662114386

Epoch: 6| Step: 10
Training loss: 1.6503669330769886
Validation loss: 2.606836694780318

Epoch: 6| Step: 11
Training loss: 2.0020664983141483
Validation loss: 2.64010353131016

Epoch: 6| Step: 12
Training loss: 1.605125817569536
Validation loss: 2.7154709638039307

Epoch: 6| Step: 13
Training loss: 1.8949425319724473
Validation loss: 2.6365546281386667

Epoch: 90| Step: 0
Training loss: 1.8888978241104517
Validation loss: 2.6835037357016933

Epoch: 6| Step: 1
Training loss: 1.9789496921932017
Validation loss: 2.6410326520775933

Epoch: 6| Step: 2
Training loss: 1.8762654167014623
Validation loss: 2.5947062709686355

Epoch: 6| Step: 3
Training loss: 2.0445856001863207
Validation loss: 2.615208392765585

Epoch: 6| Step: 4
Training loss: 1.9204067421268596
Validation loss: 2.6743849923783025

Epoch: 6| Step: 5
Training loss: 1.5805335973917578
Validation loss: 2.6151138365252167

Epoch: 6| Step: 6
Training loss: 1.3734207187013623
Validation loss: 2.599100332005812

Epoch: 6| Step: 7
Training loss: 1.9196636224174881
Validation loss: 2.6835879455829392

Epoch: 6| Step: 8
Training loss: 1.805499864192124
Validation loss: 2.544197937862445

Epoch: 6| Step: 9
Training loss: 1.9026859923390185
Validation loss: 2.6071003881181856

Epoch: 6| Step: 10
Training loss: 1.577831203193445
Validation loss: 2.59694907904836

Epoch: 6| Step: 11
Training loss: 1.9258234046516132
Validation loss: 2.5930633095523916

Epoch: 6| Step: 12
Training loss: 2.87775703587988
Validation loss: 2.558499104930867

Epoch: 6| Step: 13
Training loss: 2.104151382642575
Validation loss: 2.6901831281409763

Epoch: 91| Step: 0
Training loss: 1.1100993410969497
Validation loss: 2.7008932231495986

Epoch: 6| Step: 1
Training loss: 1.8963632436896714
Validation loss: 2.7455096286032163

Epoch: 6| Step: 2
Training loss: 2.3059343488997137
Validation loss: 2.738366372839209

Epoch: 6| Step: 3
Training loss: 1.7568684395226906
Validation loss: 2.644926521516158

Epoch: 6| Step: 4
Training loss: 2.0535509570505246
Validation loss: 2.64885920990297

Epoch: 6| Step: 5
Training loss: 1.83530288441752
Validation loss: 2.5360534522373097

Epoch: 6| Step: 6
Training loss: 1.9984307689419176
Validation loss: 2.5931797090038105

Epoch: 6| Step: 7
Training loss: 1.8550726859357778
Validation loss: 2.507138899578924

Epoch: 6| Step: 8
Training loss: 1.8373421348177337
Validation loss: 2.625642228657582

Epoch: 6| Step: 9
Training loss: 1.6825104877207402
Validation loss: 2.5751431879027433

Epoch: 6| Step: 10
Training loss: 2.1736870760198137
Validation loss: 2.5796834377639613

Epoch: 6| Step: 11
Training loss: 2.305137047324042
Validation loss: 2.6486431780894693

Epoch: 6| Step: 12
Training loss: 1.8459404041014933
Validation loss: 2.656979868226695

Epoch: 6| Step: 13
Training loss: 2.2491269007085224
Validation loss: 2.7108890408189117

Epoch: 92| Step: 0
Training loss: 1.5313122795051575
Validation loss: 2.667194319218904

Epoch: 6| Step: 1
Training loss: 1.713276209652049
Validation loss: 2.6483128911264315

Epoch: 6| Step: 2
Training loss: 1.9539113407305109
Validation loss: 2.624615883349565

Epoch: 6| Step: 3
Training loss: 1.6221113205513937
Validation loss: 2.663511053234377

Epoch: 6| Step: 4
Training loss: 1.6289827982894118
Validation loss: 2.6193971254662354

Epoch: 6| Step: 5
Training loss: 2.383102449379951
Validation loss: 2.671667273107481

Epoch: 6| Step: 6
Training loss: 1.9610151298324454
Validation loss: 2.629535420266933

Epoch: 6| Step: 7
Training loss: 1.6495509432453344
Validation loss: 2.564351204025608

Epoch: 6| Step: 8
Training loss: 2.8130882495716216
Validation loss: 2.6437210953186736

Epoch: 6| Step: 9
Training loss: 2.0693808708695225
Validation loss: 2.6023884207789916

Epoch: 6| Step: 10
Training loss: 1.6437799545285592
Validation loss: 2.660836258442704

Epoch: 6| Step: 11
Training loss: 1.8304724985915455
Validation loss: 2.5560070056033255

Epoch: 6| Step: 12
Training loss: 1.6398895068279729
Validation loss: 2.613035409993287

Epoch: 6| Step: 13
Training loss: 1.2583783695338395
Validation loss: 2.539942568332451

Epoch: 93| Step: 0
Training loss: 2.087111467763432
Validation loss: 2.5795492072403388

Epoch: 6| Step: 1
Training loss: 1.6416866682096034
Validation loss: 2.626233393928164

Epoch: 6| Step: 2
Training loss: 1.7214334520633705
Validation loss: 2.650676722160963

Epoch: 6| Step: 3
Training loss: 2.042348151101177
Validation loss: 2.637919332064777

Epoch: 6| Step: 4
Training loss: 2.321677888330568
Validation loss: 2.5077511155012515

Epoch: 6| Step: 5
Training loss: 1.3451500629535775
Validation loss: 2.6104405220648643

Epoch: 6| Step: 6
Training loss: 1.4234618669553551
Validation loss: 2.6418990423081534

Epoch: 6| Step: 7
Training loss: 2.0024422992294095
Validation loss: 2.6643414393294957

Epoch: 6| Step: 8
Training loss: 1.3021098731833005
Validation loss: 2.6710838128011334

Epoch: 6| Step: 9
Training loss: 1.7547409688084297
Validation loss: 2.6809760907454137

Epoch: 6| Step: 10
Training loss: 2.7889694070105837
Validation loss: 2.7286373867645177

Epoch: 6| Step: 11
Training loss: 2.386023587195815
Validation loss: 2.6335835822825837

Epoch: 6| Step: 12
Training loss: 1.5935178849479688
Validation loss: 2.6928552160777754

Epoch: 6| Step: 13
Training loss: 1.5766745218453628
Validation loss: 2.5992356167089223

Epoch: 94| Step: 0
Training loss: 1.677207215592893
Validation loss: 2.6412197398835224

Epoch: 6| Step: 1
Training loss: 1.988294080531723
Validation loss: 2.673671393657533

Epoch: 6| Step: 2
Training loss: 1.757121717567306
Validation loss: 2.703934726456754

Epoch: 6| Step: 3
Training loss: 1.636435254292604
Validation loss: 2.5787179130250477

Epoch: 6| Step: 4
Training loss: 2.4749825910476155
Validation loss: 2.625319764173723

Epoch: 6| Step: 5
Training loss: 1.4984751739380167
Validation loss: 2.486391364864319

Epoch: 6| Step: 6
Training loss: 1.8387432330102313
Validation loss: 2.6312487568252054

Epoch: 6| Step: 7
Training loss: 1.8226941290760594
Validation loss: 2.5590105721872827

Epoch: 6| Step: 8
Training loss: 2.1665185975562564
Validation loss: 2.64706722283641

Epoch: 6| Step: 9
Training loss: 1.7900001700630321
Validation loss: 2.665935920390228

Epoch: 6| Step: 10
Training loss: 1.332188213866309
Validation loss: 2.6253578002736315

Epoch: 6| Step: 11
Training loss: 1.5693151998425647
Validation loss: 2.717370615092589

Epoch: 6| Step: 12
Training loss: 1.681849591854629
Validation loss: 2.765436888078591

Epoch: 6| Step: 13
Training loss: 2.2108296614049774
Validation loss: 2.7677267963873735

Epoch: 95| Step: 0
Training loss: 2.257713658898349
Validation loss: 2.822926796945411

Epoch: 6| Step: 1
Training loss: 1.6646842690406582
Validation loss: 2.7434654337371254

Epoch: 6| Step: 2
Training loss: 1.3496132614587673
Validation loss: 2.707022104986394

Epoch: 6| Step: 3
Training loss: 2.1243763176694253
Validation loss: 2.688863452768299

Epoch: 6| Step: 4
Training loss: 2.1796524974788127
Validation loss: 2.624693073009871

Epoch: 6| Step: 5
Training loss: 1.2196601990115348
Validation loss: 2.5725660561402415

Epoch: 6| Step: 6
Training loss: 2.232414612712378
Validation loss: 2.576159118821282

Epoch: 6| Step: 7
Training loss: 1.677554173056727
Validation loss: 2.660210726978859

Epoch: 6| Step: 8
Training loss: 2.288573645772144
Validation loss: 2.5877023074170498

Epoch: 6| Step: 9
Training loss: 1.9350262508533829
Validation loss: 2.6327051278546825

Epoch: 6| Step: 10
Training loss: 1.340311441454444
Validation loss: 2.6486198940130365

Epoch: 6| Step: 11
Training loss: 1.251270173374167
Validation loss: 2.6805188045277353

Epoch: 6| Step: 12
Training loss: 1.9605772135793311
Validation loss: 2.625189456460621

Epoch: 6| Step: 13
Training loss: 1.9893588460397613
Validation loss: 2.700904492770146

Epoch: 96| Step: 0
Training loss: 1.3626334501234905
Validation loss: 2.65670372322863

Epoch: 6| Step: 1
Training loss: 1.8303290228727225
Validation loss: 2.680514253507873

Epoch: 6| Step: 2
Training loss: 1.846961763929013
Validation loss: 2.757113936493994

Epoch: 6| Step: 3
Training loss: 1.450595910841994
Validation loss: 2.70292276202893

Epoch: 6| Step: 4
Training loss: 1.9975739308068943
Validation loss: 2.66428639057501

Epoch: 6| Step: 5
Training loss: 1.606578285719987
Validation loss: 2.741338469815297

Epoch: 6| Step: 6
Training loss: 1.9780624789561874
Validation loss: 2.6364322911763227

Epoch: 6| Step: 7
Training loss: 1.6436769708575916
Validation loss: 2.6504185861805363

Epoch: 6| Step: 8
Training loss: 1.8484522453745393
Validation loss: 2.637552810429502

Epoch: 6| Step: 9
Training loss: 2.12653116151252
Validation loss: 2.730913088785053

Epoch: 6| Step: 10
Training loss: 1.6205147685949595
Validation loss: 2.58582046720316

Epoch: 6| Step: 11
Training loss: 1.4926172406587752
Validation loss: 2.6456158816472355

Epoch: 6| Step: 12
Training loss: 1.4456859209324902
Validation loss: 2.5733503884736932

Epoch: 6| Step: 13
Training loss: 2.7086477146103762
Validation loss: 2.548302716390819

Epoch: 97| Step: 0
Training loss: 1.7228333258931299
Validation loss: 2.6137458756966314

Epoch: 6| Step: 1
Training loss: 1.4542370714488735
Validation loss: 2.6098370019334873

Epoch: 6| Step: 2
Training loss: 1.6885330429029506
Validation loss: 2.6043859211493063

Epoch: 6| Step: 3
Training loss: 1.5321968420974341
Validation loss: 2.617768051512679

Epoch: 6| Step: 4
Training loss: 1.727815475475104
Validation loss: 2.659675214820732

Epoch: 6| Step: 5
Training loss: 2.8413743376808087
Validation loss: 2.7134775653279775

Epoch: 6| Step: 6
Training loss: 1.8583682885182538
Validation loss: 2.733448925326607

Epoch: 6| Step: 7
Training loss: 2.1347527813328755
Validation loss: 2.788427813180146

Epoch: 6| Step: 8
Training loss: 1.9744769164199771
Validation loss: 2.664724273374216

Epoch: 6| Step: 9
Training loss: 1.7333685214187813
Validation loss: 2.635585950357569

Epoch: 6| Step: 10
Training loss: 1.7245499977612833
Validation loss: 2.6152438409779757

Epoch: 6| Step: 11
Training loss: 1.202465718944543
Validation loss: 2.5668029168943707

Epoch: 6| Step: 12
Training loss: 2.1622045370247513
Validation loss: 2.634747647694723

Epoch: 6| Step: 13
Training loss: 1.8453328079023514
Validation loss: 2.5723083384411196

Epoch: 98| Step: 0
Training loss: 1.8895105277114164
Validation loss: 2.6489725088284493

Epoch: 6| Step: 1
Training loss: 2.7556987150580534
Validation loss: 2.645796397594649

Epoch: 6| Step: 2
Training loss: 1.6783243725085086
Validation loss: 2.524861771353421

Epoch: 6| Step: 3
Training loss: 1.398893527046906
Validation loss: 2.572784997039436

Epoch: 6| Step: 4
Training loss: 1.3381468590167473
Validation loss: 2.5766931275920917

Epoch: 6| Step: 5
Training loss: 2.095670815367203
Validation loss: 2.6302023154211915

Epoch: 6| Step: 6
Training loss: 2.0565011610254618
Validation loss: 2.7159461694456946

Epoch: 6| Step: 7
Training loss: 1.6012712167232088
Validation loss: 2.688553566643383

Epoch: 6| Step: 8
Training loss: 1.6139962226133329
Validation loss: 2.660976020323615

Epoch: 6| Step: 9
Training loss: 1.814585702444195
Validation loss: 2.6320625542605574

Epoch: 6| Step: 10
Training loss: 2.4038196527047306
Validation loss: 2.5793975309745587

Epoch: 6| Step: 11
Training loss: 1.5568492180072748
Validation loss: 2.6059189864491876

Epoch: 6| Step: 12
Training loss: 1.2682200071825243
Validation loss: 2.680526750263761

Epoch: 6| Step: 13
Training loss: 1.46339185859821
Validation loss: 2.702360467711092

Epoch: 99| Step: 0
Training loss: 1.2610080477089425
Validation loss: 2.6417962510809847

Epoch: 6| Step: 1
Training loss: 2.2695816743537782
Validation loss: 2.632184082859935

Epoch: 6| Step: 2
Training loss: 1.5521085425597538
Validation loss: 2.706297657160089

Epoch: 6| Step: 3
Training loss: 1.9004901730535007
Validation loss: 2.6647407809326276

Epoch: 6| Step: 4
Training loss: 1.4695599534406862
Validation loss: 2.5801525735714366

Epoch: 6| Step: 5
Training loss: 1.3125798337362304
Validation loss: 2.676650896782063

Epoch: 6| Step: 6
Training loss: 1.9245678404191129
Validation loss: 2.637521729824231

Epoch: 6| Step: 7
Training loss: 2.0188067259952915
Validation loss: 2.666816205560502

Epoch: 6| Step: 8
Training loss: 1.3856541805266076
Validation loss: 2.646372347216641

Epoch: 6| Step: 9
Training loss: 1.4674210725059198
Validation loss: 2.6663354926301066

Epoch: 6| Step: 10
Training loss: 1.793340640259975
Validation loss: 2.7087291917293594

Epoch: 6| Step: 11
Training loss: 1.4011419560535217
Validation loss: 2.6194327217865445

Epoch: 6| Step: 12
Training loss: 2.818019452549739
Validation loss: 2.6494424989259056

Epoch: 6| Step: 13
Training loss: 1.5468403205452088
Validation loss: 2.7184744216569716

Epoch: 100| Step: 0
Training loss: 1.5053063155053745
Validation loss: 2.828279213538344

Epoch: 6| Step: 1
Training loss: 1.7070815299374298
Validation loss: 2.8018538843159533

Epoch: 6| Step: 2
Training loss: 2.2969437154235472
Validation loss: 2.7394516022392974

Epoch: 6| Step: 3
Training loss: 1.9053916249262222
Validation loss: 2.7710512883407166

Epoch: 6| Step: 4
Training loss: 1.4667664790147004
Validation loss: 2.702086659010049

Epoch: 6| Step: 5
Training loss: 1.5310696865495055
Validation loss: 2.663245022550569

Epoch: 6| Step: 6
Training loss: 1.2162621365575796
Validation loss: 2.5919732132281075

Epoch: 6| Step: 7
Training loss: 1.755334081776874
Validation loss: 2.6603259211283494

Epoch: 6| Step: 8
Training loss: 2.0584874279499092
Validation loss: 2.587133563166348

Epoch: 6| Step: 9
Training loss: 1.9976268636356915
Validation loss: 2.6422419290709587

Epoch: 6| Step: 10
Training loss: 1.345319097948011
Validation loss: 2.686269389668776

Epoch: 6| Step: 11
Training loss: 2.4437639006782756
Validation loss: 2.6528309377921624

Epoch: 6| Step: 12
Training loss: 1.6781528292999863
Validation loss: 2.643657680910653

Epoch: 6| Step: 13
Training loss: 1.7047559296101644
Validation loss: 2.632476905994366

Epoch: 101| Step: 0
Training loss: 1.2202118151910695
Validation loss: 2.676852937474292

Epoch: 6| Step: 1
Training loss: 2.256548359341513
Validation loss: 2.718410266097077

Epoch: 6| Step: 2
Training loss: 1.7806908248458477
Validation loss: 2.7364886443501177

Epoch: 6| Step: 3
Training loss: 1.7622018223677864
Validation loss: 2.7423238548293365

Epoch: 6| Step: 4
Training loss: 1.0456438939131274
Validation loss: 2.683874849407192

Epoch: 6| Step: 5
Training loss: 1.3721730909848526
Validation loss: 2.727725854713127

Epoch: 6| Step: 6
Training loss: 2.1973424465737352
Validation loss: 2.664446015407441

Epoch: 6| Step: 7
Training loss: 1.6145412152447136
Validation loss: 2.6503385549484335

Epoch: 6| Step: 8
Training loss: 2.3164925004363033
Validation loss: 2.653747696398614

Epoch: 6| Step: 9
Training loss: 1.6745811735874716
Validation loss: 2.619656816554875

Epoch: 6| Step: 10
Training loss: 1.405627261134967
Validation loss: 2.599918353803968

Epoch: 6| Step: 11
Training loss: 1.6919067910811225
Validation loss: 2.579314895544593

Epoch: 6| Step: 12
Training loss: 1.5639981526220001
Validation loss: 2.5648737201998264

Epoch: 6| Step: 13
Training loss: 1.8312630740795892
Validation loss: 2.5922186747112144

Epoch: 102| Step: 0
Training loss: 1.923980799779437
Validation loss: 2.6811903288158283

Epoch: 6| Step: 1
Training loss: 1.4169336329218036
Validation loss: 2.6287977357775687

Epoch: 6| Step: 2
Training loss: 1.4508365947168902
Validation loss: 2.6561449516318163

Epoch: 6| Step: 3
Training loss: 1.6248491657385824
Validation loss: 2.646958229650972

Epoch: 6| Step: 4
Training loss: 2.518604670040091
Validation loss: 2.6960003329931483

Epoch: 6| Step: 5
Training loss: 1.3008608865273803
Validation loss: 2.6554964081132937

Epoch: 6| Step: 6
Training loss: 1.7658703388814976
Validation loss: 2.676747153779475

Epoch: 6| Step: 7
Training loss: 1.9232429660126509
Validation loss: 2.607809773712836

Epoch: 6| Step: 8
Training loss: 1.9413078789762694
Validation loss: 2.5438187560990717

Epoch: 6| Step: 9
Training loss: 1.8301975858572177
Validation loss: 2.628305669827241

Epoch: 6| Step: 10
Training loss: 1.1728408901926493
Validation loss: 2.7111052828562823

Epoch: 6| Step: 11
Training loss: 1.9405639786271576
Validation loss: 2.779452825528503

Epoch: 6| Step: 12
Training loss: 1.5301767597442464
Validation loss: 2.795905387355469

Epoch: 6| Step: 13
Training loss: 1.4533548480958265
Validation loss: 2.8298288204376485

Epoch: 103| Step: 0
Training loss: 1.4171760802560673
Validation loss: 2.7743922493101856

Epoch: 6| Step: 1
Training loss: 2.000441740843332
Validation loss: 2.678165904637435

Epoch: 6| Step: 2
Training loss: 1.8811441207949204
Validation loss: 2.6710622640760295

Epoch: 6| Step: 3
Training loss: 2.3497044519481864
Validation loss: 2.614127622204767

Epoch: 6| Step: 4
Training loss: 1.66739810946864
Validation loss: 2.5424552824900997

Epoch: 6| Step: 5
Training loss: 1.3920127288000705
Validation loss: 2.6309550871379983

Epoch: 6| Step: 6
Training loss: 2.063322885678925
Validation loss: 2.6424192844648062

Epoch: 6| Step: 7
Training loss: 1.6938858005938568
Validation loss: 2.570509187077576

Epoch: 6| Step: 8
Training loss: 1.6402703764803486
Validation loss: 2.550893456881331

Epoch: 6| Step: 9
Training loss: 1.657238791066035
Validation loss: 2.5875496655303256

Epoch: 6| Step: 10
Training loss: 1.4045037341395843
Validation loss: 2.5937270504346

Epoch: 6| Step: 11
Training loss: 1.5701715206801001
Validation loss: 2.5807936602918025

Epoch: 6| Step: 12
Training loss: 1.53971655255938
Validation loss: 2.655293520586902

Epoch: 6| Step: 13
Training loss: 1.2168649130914047
Validation loss: 2.7198984928450956

Epoch: 104| Step: 0
Training loss: 1.5558659673345698
Validation loss: 2.7471387167328065

Epoch: 6| Step: 1
Training loss: 1.5989012402542022
Validation loss: 2.7320815577250843

Epoch: 6| Step: 2
Training loss: 1.5648287394846876
Validation loss: 2.9150871268633094

Epoch: 6| Step: 3
Training loss: 1.868408569989878
Validation loss: 2.7498699793278254

Epoch: 6| Step: 4
Training loss: 1.4683891015317823
Validation loss: 2.678590570411708

Epoch: 6| Step: 5
Training loss: 1.2841577796372725
Validation loss: 2.6121313190864783

Epoch: 6| Step: 6
Training loss: 2.1126078380620967
Validation loss: 2.629923940460449

Epoch: 6| Step: 7
Training loss: 1.6392342621997713
Validation loss: 2.6385874364120805

Epoch: 6| Step: 8
Training loss: 1.7629453191169633
Validation loss: 2.5581844555739592

Epoch: 6| Step: 9
Training loss: 1.2970115405902352
Validation loss: 2.611716516181705

Epoch: 6| Step: 10
Training loss: 1.801636862895014
Validation loss: 2.633179922906621

Epoch: 6| Step: 11
Training loss: 2.761353119167589
Validation loss: 2.6143951854919063

Epoch: 6| Step: 12
Training loss: 1.760537641834113
Validation loss: 2.6260647355221063

Epoch: 6| Step: 13
Training loss: 1.5674101925178638
Validation loss: 2.6512178513614466

Epoch: 105| Step: 0
Training loss: 1.6525559886502421
Validation loss: 2.703612105447565

Epoch: 6| Step: 1
Training loss: 2.39226082079626
Validation loss: 2.752669382661105

Epoch: 6| Step: 2
Training loss: 1.6844393206543329
Validation loss: 2.8532421303891264

Epoch: 6| Step: 3
Training loss: 1.5893953708028767
Validation loss: 2.9032552869871195

Epoch: 6| Step: 4
Training loss: 2.1086209680214663
Validation loss: 2.759493667510487

Epoch: 6| Step: 5
Training loss: 1.6369152451877216
Validation loss: 2.706207238051098

Epoch: 6| Step: 6
Training loss: 1.250930344548989
Validation loss: 2.6586993499627845

Epoch: 6| Step: 7
Training loss: 1.235753460671844
Validation loss: 2.620690274440441

Epoch: 6| Step: 8
Training loss: 2.1148304787012595
Validation loss: 2.572433230636782

Epoch: 6| Step: 9
Training loss: 1.656608254895154
Validation loss: 2.6758883638127697

Epoch: 6| Step: 10
Training loss: 1.3377406572255561
Validation loss: 2.5959440549583483

Epoch: 6| Step: 11
Training loss: 1.6838835358430597
Validation loss: 2.6196972101271174

Epoch: 6| Step: 12
Training loss: 1.7390394293256457
Validation loss: 2.6049035263258102

Epoch: 6| Step: 13
Training loss: 1.3854013552094477
Validation loss: 2.5829737064294864

Epoch: 106| Step: 0
Training loss: 1.3696902664229742
Validation loss: 2.6813212494175565

Epoch: 6| Step: 1
Training loss: 1.7444701017057413
Validation loss: 2.6282093169135425

Epoch: 6| Step: 2
Training loss: 1.9053792997403185
Validation loss: 2.664678582543797

Epoch: 6| Step: 3
Training loss: 1.6179778153604378
Validation loss: 2.710450310953981

Epoch: 6| Step: 4
Training loss: 1.7173370796013678
Validation loss: 2.7255493875984866

Epoch: 6| Step: 5
Training loss: 1.6798671182804776
Validation loss: 2.7468726553416887

Epoch: 6| Step: 6
Training loss: 1.5591493921157185
Validation loss: 2.65102490392955

Epoch: 6| Step: 7
Training loss: 1.3555321582397426
Validation loss: 2.658088930149726

Epoch: 6| Step: 8
Training loss: 1.3697924837562048
Validation loss: 2.6456836948482008

Epoch: 6| Step: 9
Training loss: 1.4508069325250161
Validation loss: 2.668344719731636

Epoch: 6| Step: 10
Training loss: 1.390712735269477
Validation loss: 2.6436019233736445

Epoch: 6| Step: 11
Training loss: 1.524210337699228
Validation loss: 2.614437985781299

Epoch: 6| Step: 12
Training loss: 2.3998711988537313
Validation loss: 2.6092272048485174

Epoch: 6| Step: 13
Training loss: 1.3756204419058364
Validation loss: 2.630766000579816

Epoch: 107| Step: 0
Training loss: 1.8803995586450737
Validation loss: 2.6895344153303444

Epoch: 6| Step: 1
Training loss: 1.4341923350124954
Validation loss: 2.695382475750857

Epoch: 6| Step: 2
Training loss: 1.7973653373095073
Validation loss: 2.741213242353524

Epoch: 6| Step: 3
Training loss: 1.3705076176606674
Validation loss: 2.706103761875705

Epoch: 6| Step: 4
Training loss: 1.7071586927943818
Validation loss: 2.73953441871131

Epoch: 6| Step: 5
Training loss: 1.5204875849148283
Validation loss: 2.6759228151467838

Epoch: 6| Step: 6
Training loss: 1.058824689948624
Validation loss: 2.698655823794013

Epoch: 6| Step: 7
Training loss: 1.5714267554210721
Validation loss: 2.7484443411453694

Epoch: 6| Step: 8
Training loss: 1.7592072103657048
Validation loss: 2.6137639670452635

Epoch: 6| Step: 9
Training loss: 2.321980400311586
Validation loss: 2.623353017598244

Epoch: 6| Step: 10
Training loss: 1.3901679327260463
Validation loss: 2.6346588452463746

Epoch: 6| Step: 11
Training loss: 2.1123621382111537
Validation loss: 2.641269341882576

Epoch: 6| Step: 12
Training loss: 1.494407959003819
Validation loss: 2.639292243336398

Epoch: 6| Step: 13
Training loss: 1.4034364316465244
Validation loss: 2.599146105468999

Epoch: 108| Step: 0
Training loss: 1.5813214252006402
Validation loss: 2.615980653878906

Epoch: 6| Step: 1
Training loss: 1.802272617637896
Validation loss: 2.657386611404698

Epoch: 6| Step: 2
Training loss: 1.9040630490458612
Validation loss: 2.5978512645362097

Epoch: 6| Step: 3
Training loss: 1.6632874882456994
Validation loss: 2.6138512218377015

Epoch: 6| Step: 4
Training loss: 1.6043021982911363
Validation loss: 2.6582641818779433

Epoch: 6| Step: 5
Training loss: 1.1954577488630502
Validation loss: 2.670882920168399

Epoch: 6| Step: 6
Training loss: 1.1713726238437905
Validation loss: 2.6618542211909406

Epoch: 6| Step: 7
Training loss: 1.409414249389599
Validation loss: 2.726802505670819

Epoch: 6| Step: 8
Training loss: 1.7501512189652657
Validation loss: 2.824301599295994

Epoch: 6| Step: 9
Training loss: 1.704866551297536
Validation loss: 2.7774614397697692

Epoch: 6| Step: 10
Training loss: 2.451892421640098
Validation loss: 2.7245029952817514

Epoch: 6| Step: 11
Training loss: 1.3037522670181183
Validation loss: 2.615640894979402

Epoch: 6| Step: 12
Training loss: 1.2913779069267584
Validation loss: 2.634936554088824

Epoch: 6| Step: 13
Training loss: 1.403214760608854
Validation loss: 2.6193842991431975

Epoch: 109| Step: 0
Training loss: 1.2126519648699012
Validation loss: 2.641790144247742

Epoch: 6| Step: 1
Training loss: 1.8931275506189744
Validation loss: 2.6439050621449516

Epoch: 6| Step: 2
Training loss: 1.1399652323524125
Validation loss: 2.6459417446083355

Epoch: 6| Step: 3
Training loss: 2.549977571725385
Validation loss: 2.581315241890489

Epoch: 6| Step: 4
Training loss: 1.1626166254424228
Validation loss: 2.5799955498733387

Epoch: 6| Step: 5
Training loss: 1.3663590019000733
Validation loss: 2.681422258725739

Epoch: 6| Step: 6
Training loss: 1.6531749465406342
Validation loss: 2.7083110710598453

Epoch: 6| Step: 7
Training loss: 1.6917557212177021
Validation loss: 2.7547922932004982

Epoch: 6| Step: 8
Training loss: 1.2804718445792285
Validation loss: 2.7751620236771606

Epoch: 6| Step: 9
Training loss: 1.304288471899757
Validation loss: 2.725925549687177

Epoch: 6| Step: 10
Training loss: 1.5997223493949844
Validation loss: 2.6837746875221478

Epoch: 6| Step: 11
Training loss: 1.4026820377793703
Validation loss: 2.676498368967121

Epoch: 6| Step: 12
Training loss: 1.6666519720701287
Validation loss: 2.628327470828114

Epoch: 6| Step: 13
Training loss: 1.6653895571349546
Validation loss: 2.578471921448217

Epoch: 110| Step: 0
Training loss: 1.3354518967066384
Validation loss: 2.644719788119355

Epoch: 6| Step: 1
Training loss: 1.3677400616783457
Validation loss: 2.683189779986953

Epoch: 6| Step: 2
Training loss: 1.5475978511015485
Validation loss: 2.5720382663328376

Epoch: 6| Step: 3
Training loss: 1.212262960250216
Validation loss: 2.6599965470035865

Epoch: 6| Step: 4
Training loss: 1.3145212776461477
Validation loss: 2.5638112070758545

Epoch: 6| Step: 5
Training loss: 1.5647854684154971
Validation loss: 2.52797532677883

Epoch: 6| Step: 6
Training loss: 1.5934058173037884
Validation loss: 2.5800704859683785

Epoch: 6| Step: 7
Training loss: 1.6052406316037364
Validation loss: 2.6093926800340177

Epoch: 6| Step: 8
Training loss: 1.632567829983698
Validation loss: 2.594550258249432

Epoch: 6| Step: 9
Training loss: 2.2926890317967232
Validation loss: 2.6731825486449523

Epoch: 6| Step: 10
Training loss: 1.2646612100434882
Validation loss: 2.6281974180739476

Epoch: 6| Step: 11
Training loss: 1.6076164637686683
Validation loss: 2.6933744972768983

Epoch: 6| Step: 12
Training loss: 1.7215923042646513
Validation loss: 2.727197188838846

Epoch: 6| Step: 13
Training loss: 1.360398488217809
Validation loss: 2.757898907482991

Epoch: 111| Step: 0
Training loss: 1.4110908686862218
Validation loss: 2.7861921212967755

Epoch: 6| Step: 1
Training loss: 1.1928784888995085
Validation loss: 2.81001257926415

Epoch: 6| Step: 2
Training loss: 1.2947339688266348
Validation loss: 2.8025456913295357

Epoch: 6| Step: 3
Training loss: 1.3317138204155496
Validation loss: 2.7776204975953984

Epoch: 6| Step: 4
Training loss: 1.4274841172759414
Validation loss: 2.726013376052479

Epoch: 6| Step: 5
Training loss: 1.4137454863053773
Validation loss: 2.690673211552259

Epoch: 6| Step: 6
Training loss: 2.341557405395749
Validation loss: 2.6360046776135264

Epoch: 6| Step: 7
Training loss: 1.4146698548379604
Validation loss: 2.663452660350627

Epoch: 6| Step: 8
Training loss: 1.605164213603601
Validation loss: 2.647683065231174

Epoch: 6| Step: 9
Training loss: 1.7120120362678675
Validation loss: 2.6514393945911148

Epoch: 6| Step: 10
Training loss: 1.2963182104367588
Validation loss: 2.6875994981785056

Epoch: 6| Step: 11
Training loss: 1.9610650374439917
Validation loss: 2.6207652826576533

Epoch: 6| Step: 12
Training loss: 1.5786863027545666
Validation loss: 2.673578533508078

Epoch: 6| Step: 13
Training loss: 1.5843838001134736
Validation loss: 2.6611239875857113

Epoch: 112| Step: 0
Training loss: 2.103842707204537
Validation loss: 2.7276385496656763

Epoch: 6| Step: 1
Training loss: 1.5507917812191614
Validation loss: 2.793794935691435

Epoch: 6| Step: 2
Training loss: 1.5558156276704085
Validation loss: 2.7828586512427522

Epoch: 6| Step: 3
Training loss: 1.2045130958431112
Validation loss: 2.808227826484434

Epoch: 6| Step: 4
Training loss: 1.4326399870906452
Validation loss: 2.9020787730367137

Epoch: 6| Step: 5
Training loss: 2.4079376841684716
Validation loss: 2.7840645225609757

Epoch: 6| Step: 6
Training loss: 1.5168810486800626
Validation loss: 2.6811579311305453

Epoch: 6| Step: 7
Training loss: 1.385277657478354
Validation loss: 2.668387429044239

Epoch: 6| Step: 8
Training loss: 1.2324495388015442
Validation loss: 2.6413321968235355

Epoch: 6| Step: 9
Training loss: 1.524430875422779
Validation loss: 2.6193615817581386

Epoch: 6| Step: 10
Training loss: 1.405982013174941
Validation loss: 2.6882194029317525

Epoch: 6| Step: 11
Training loss: 1.3669426835077696
Validation loss: 2.616634268671478

Epoch: 6| Step: 12
Training loss: 1.5607793871098665
Validation loss: 2.7091356898492203

Epoch: 6| Step: 13
Training loss: 1.3172736324145884
Validation loss: 2.717637985642735

Epoch: 113| Step: 0
Training loss: 1.226073975678864
Validation loss: 2.714729405471949

Epoch: 6| Step: 1
Training loss: 1.286669087102982
Validation loss: 2.711421978228413

Epoch: 6| Step: 2
Training loss: 1.5705299037161937
Validation loss: 2.736798097456786

Epoch: 6| Step: 3
Training loss: 1.7981443482737987
Validation loss: 2.754044535165768

Epoch: 6| Step: 4
Training loss: 1.2565989830414905
Validation loss: 2.7384123287852833

Epoch: 6| Step: 5
Training loss: 1.302468245516417
Validation loss: 2.710917535977688

Epoch: 6| Step: 6
Training loss: 1.2557445135435303
Validation loss: 2.606952250618059

Epoch: 6| Step: 7
Training loss: 1.536938746287199
Validation loss: 2.66892954559638

Epoch: 6| Step: 8
Training loss: 1.4447047424937765
Validation loss: 2.6796412338844884

Epoch: 6| Step: 9
Training loss: 2.2897261871489087
Validation loss: 2.6992697446416067

Epoch: 6| Step: 10
Training loss: 1.2785451762662128
Validation loss: 2.74593644032983

Epoch: 6| Step: 11
Training loss: 1.6869770228658985
Validation loss: 2.6714235485812634

Epoch: 6| Step: 12
Training loss: 1.8915060843426073
Validation loss: 2.757579674767206

Epoch: 6| Step: 13
Training loss: 1.328067374381743
Validation loss: 2.6977219136960473

Epoch: 114| Step: 0
Training loss: 1.8137898952479015
Validation loss: 2.675912628289895

Epoch: 6| Step: 1
Training loss: 1.2858368714869621
Validation loss: 2.6699611658136764

Epoch: 6| Step: 2
Training loss: 2.142706089145324
Validation loss: 2.652614079717847

Epoch: 6| Step: 3
Training loss: 1.7909067967421726
Validation loss: 2.6599903624462793

Epoch: 6| Step: 4
Training loss: 1.2558871869794148
Validation loss: 2.6720277917315087

Epoch: 6| Step: 5
Training loss: 1.8185741326422542
Validation loss: 2.578257039089403

Epoch: 6| Step: 6
Training loss: 1.3634367146425261
Validation loss: 2.644749334256214

Epoch: 6| Step: 7
Training loss: 1.283957481740933
Validation loss: 2.608887952475494

Epoch: 6| Step: 8
Training loss: 1.3289385828102493
Validation loss: 2.6056956393057034

Epoch: 6| Step: 9
Training loss: 1.2846439813152721
Validation loss: 2.729383028107543

Epoch: 6| Step: 10
Training loss: 1.439711403934998
Validation loss: 2.7356936227164437

Epoch: 6| Step: 11
Training loss: 1.4812628797784002
Validation loss: 2.7039261294117924

Epoch: 6| Step: 12
Training loss: 1.1852942610810038
Validation loss: 2.6084694423649104

Epoch: 6| Step: 13
Training loss: 1.2503644888665928
Validation loss: 2.6106645820045657

Epoch: 115| Step: 0
Training loss: 1.1588090466348653
Validation loss: 2.6982287566395735

Epoch: 6| Step: 1
Training loss: 2.118892307059808
Validation loss: 2.719071219457732

Epoch: 6| Step: 2
Training loss: 1.6771883092529665
Validation loss: 2.6243956793630288

Epoch: 6| Step: 3
Training loss: 1.3895775782948765
Validation loss: 2.75612240623578

Epoch: 6| Step: 4
Training loss: 1.2207057617159023
Validation loss: 2.77730356036231

Epoch: 6| Step: 5
Training loss: 1.3733504110419505
Validation loss: 2.672632597062496

Epoch: 6| Step: 6
Training loss: 1.323970084909808
Validation loss: 2.7159325262025695

Epoch: 6| Step: 7
Training loss: 1.6938318211685954
Validation loss: 2.7427947992144324

Epoch: 6| Step: 8
Training loss: 1.570564743203732
Validation loss: 2.7331391075567493

Epoch: 6| Step: 9
Training loss: 1.120338531149153
Validation loss: 2.7090204516563867

Epoch: 6| Step: 10
Training loss: 1.2192662441727309
Validation loss: 2.6319024827196076

Epoch: 6| Step: 11
Training loss: 1.515121691005679
Validation loss: 2.600256957903634

Epoch: 6| Step: 12
Training loss: 1.3964083137339025
Validation loss: 2.698479499188174

Epoch: 6| Step: 13
Training loss: 1.0464982450846883
Validation loss: 2.672954913663777

Epoch: 116| Step: 0
Training loss: 1.5222946183808728
Validation loss: 2.629600248137825

Epoch: 6| Step: 1
Training loss: 1.1670317192245236
Validation loss: 2.7306226869775463

Epoch: 6| Step: 2
Training loss: 1.3606542947372735
Validation loss: 2.658416313462738

Epoch: 6| Step: 3
Training loss: 1.5901164352921628
Validation loss: 2.711248213288308

Epoch: 6| Step: 4
Training loss: 1.3719923764286714
Validation loss: 2.7219281675720612

Epoch: 6| Step: 5
Training loss: 1.114785981101704
Validation loss: 2.6958872822626065

Epoch: 6| Step: 6
Training loss: 1.4343947997212223
Validation loss: 2.611250304396633

Epoch: 6| Step: 7
Training loss: 1.049260055853734
Validation loss: 2.821847415196413

Epoch: 6| Step: 8
Training loss: 1.2692497058602834
Validation loss: 2.9127021457446416

Epoch: 6| Step: 9
Training loss: 1.4620830104447395
Validation loss: 2.869000602198232

Epoch: 6| Step: 10
Training loss: 1.401510432029982
Validation loss: 2.837257211299835

Epoch: 6| Step: 11
Training loss: 2.0761585540200596
Validation loss: 2.7813859684886904

Epoch: 6| Step: 12
Training loss: 1.5245249461694355
Validation loss: 2.751251181718202

Epoch: 6| Step: 13
Training loss: 1.1255051750189538
Validation loss: 2.7365345011433857

Epoch: 117| Step: 0
Training loss: 2.3174540062283624
Validation loss: 2.706249966522287

Epoch: 6| Step: 1
Training loss: 1.0670137456635966
Validation loss: 2.681080899837961

Epoch: 6| Step: 2
Training loss: 1.1294899457777015
Validation loss: 2.6728842838632003

Epoch: 6| Step: 3
Training loss: 1.6233695727356225
Validation loss: 2.6812548117901978

Epoch: 6| Step: 4
Training loss: 1.1120029539233705
Validation loss: 2.7398076467217463

Epoch: 6| Step: 5
Training loss: 1.25582567706661
Validation loss: 2.6735605942438534

Epoch: 6| Step: 6
Training loss: 1.717775380630652
Validation loss: 2.6856320565326075

Epoch: 6| Step: 7
Training loss: 1.036470320486913
Validation loss: 2.6545208557405617

Epoch: 6| Step: 8
Training loss: 1.7123274361200254
Validation loss: 2.6679844630063996

Epoch: 6| Step: 9
Training loss: 1.2881801475332475
Validation loss: 2.7321797014323166

Epoch: 6| Step: 10
Training loss: 1.409249180423863
Validation loss: 2.690451177106214

Epoch: 6| Step: 11
Training loss: 1.5592616282744007
Validation loss: 2.7193230649827975

Epoch: 6| Step: 12
Training loss: 1.1162016994197494
Validation loss: 2.648227334474974

Epoch: 6| Step: 13
Training loss: 1.38167745267725
Validation loss: 2.7130066288643158

Epoch: 118| Step: 0
Training loss: 1.2433557834507456
Validation loss: 2.6951970909583802

Epoch: 6| Step: 1
Training loss: 1.159696648494045
Validation loss: 2.684664376189274

Epoch: 6| Step: 2
Training loss: 1.1707434722698857
Validation loss: 2.6584763266232994

Epoch: 6| Step: 3
Training loss: 2.188118656414025
Validation loss: 2.7474626481789017

Epoch: 6| Step: 4
Training loss: 1.4262278236316677
Validation loss: 2.651536761645814

Epoch: 6| Step: 5
Training loss: 1.138493519027015
Validation loss: 2.712273172484017

Epoch: 6| Step: 6
Training loss: 1.074269851856245
Validation loss: 2.744089407120444

Epoch: 6| Step: 7
Training loss: 1.3761886747245984
Validation loss: 2.730513587332482

Epoch: 6| Step: 8
Training loss: 1.084461718782784
Validation loss: 2.743768205632989

Epoch: 6| Step: 9
Training loss: 1.7233445918061612
Validation loss: 2.6993432759231957

Epoch: 6| Step: 10
Training loss: 1.2910054216544367
Validation loss: 2.7790053235470085

Epoch: 6| Step: 11
Training loss: 1.6746757079526295
Validation loss: 2.7414506753717487

Epoch: 6| Step: 12
Training loss: 1.6294955644386229
Validation loss: 2.7353277526567346

Epoch: 6| Step: 13
Training loss: 1.342508896171319
Validation loss: 2.749602664795347

Epoch: 119| Step: 0
Training loss: 1.175354788358456
Validation loss: 2.759876347089256

Epoch: 6| Step: 1
Training loss: 1.2940677915942573
Validation loss: 2.6642298790340537

Epoch: 6| Step: 2
Training loss: 1.7803687877304262
Validation loss: 2.684521628991056

Epoch: 6| Step: 3
Training loss: 1.0657371685697221
Validation loss: 2.698220494859982

Epoch: 6| Step: 4
Training loss: 1.1832803745687146
Validation loss: 2.68518470125328

Epoch: 6| Step: 5
Training loss: 1.1170991449163112
Validation loss: 2.7189342246359187

Epoch: 6| Step: 6
Training loss: 0.8641673240058285
Validation loss: 2.73808950350538

Epoch: 6| Step: 7
Training loss: 1.2024025667811629
Validation loss: 2.713846776482183

Epoch: 6| Step: 8
Training loss: 1.2393188461532911
Validation loss: 2.6932583855203607

Epoch: 6| Step: 9
Training loss: 2.06863496581578
Validation loss: 2.6549259251607795

Epoch: 6| Step: 10
Training loss: 1.200049047659822
Validation loss: 2.812740513442991

Epoch: 6| Step: 11
Training loss: 1.439842885638602
Validation loss: 2.7652204975646284

Epoch: 6| Step: 12
Training loss: 1.2086139660003252
Validation loss: 2.6818996303437523

Epoch: 6| Step: 13
Training loss: 1.7921680000395055
Validation loss: 2.7192176182850534

Epoch: 120| Step: 0
Training loss: 1.2545482857550336
Validation loss: 2.7470830633864485

Epoch: 6| Step: 1
Training loss: 1.2189955830732628
Validation loss: 2.6625996859041563

Epoch: 6| Step: 2
Training loss: 0.9934359528084629
Validation loss: 2.6195795770926344

Epoch: 6| Step: 3
Training loss: 1.3743456237068241
Validation loss: 2.7758536260209157

Epoch: 6| Step: 4
Training loss: 1.0707082643215082
Validation loss: 2.7519892664698196

Epoch: 6| Step: 5
Training loss: 1.5375328401609392
Validation loss: 2.6581766807853375

Epoch: 6| Step: 6
Training loss: 1.0233386042911665
Validation loss: 2.791035073036613

Epoch: 6| Step: 7
Training loss: 1.0015308464392516
Validation loss: 2.701940361442456

Epoch: 6| Step: 8
Training loss: 1.486824744691314
Validation loss: 2.781334965011701

Epoch: 6| Step: 9
Training loss: 1.1430394472171956
Validation loss: 2.74737950662158

Epoch: 6| Step: 10
Training loss: 1.4857603334532574
Validation loss: 2.8024895360605546

Epoch: 6| Step: 11
Training loss: 1.6355137725315494
Validation loss: 2.730571579349863

Epoch: 6| Step: 12
Training loss: 1.207818327145751
Validation loss: 2.721133272736634

Epoch: 6| Step: 13
Training loss: 2.2828062836799345
Validation loss: 2.780104068893935

Epoch: 121| Step: 0
Training loss: 1.1809700568567607
Validation loss: 2.704751805937282

Epoch: 6| Step: 1
Training loss: 1.451807963432546
Validation loss: 2.768505471412746

Epoch: 6| Step: 2
Training loss: 1.654872393341743
Validation loss: 2.8221926212218564

Epoch: 6| Step: 3
Training loss: 1.5584354176802844
Validation loss: 2.7377914883177734

Epoch: 6| Step: 4
Training loss: 0.8010034020407601
Validation loss: 2.7096664131196655

Epoch: 6| Step: 5
Training loss: 1.003736192126093
Validation loss: 2.746733198964979

Epoch: 6| Step: 6
Training loss: 1.4230957659506869
Validation loss: 2.706171424905551

Epoch: 6| Step: 7
Training loss: 1.380257525257172
Validation loss: 2.707072394839544

Epoch: 6| Step: 8
Training loss: 1.1658636917477085
Validation loss: 2.6981253132110457

Epoch: 6| Step: 9
Training loss: 1.6397577809356967
Validation loss: 2.645291751089963

Epoch: 6| Step: 10
Training loss: 0.7462195644849476
Validation loss: 2.6698570438932983

Epoch: 6| Step: 11
Training loss: 0.8270764460304925
Validation loss: 2.723901814931419

Epoch: 6| Step: 12
Training loss: 1.6402816413161323
Validation loss: 2.6473677583734676

Epoch: 6| Step: 13
Training loss: 2.1105359308925253
Validation loss: 2.7920895915627106

Epoch: 122| Step: 0
Training loss: 1.293476938373139
Validation loss: 2.7529435154609403

Epoch: 6| Step: 1
Training loss: 0.9226375594091157
Validation loss: 2.936454099769603

Epoch: 6| Step: 2
Training loss: 0.9978685910318836
Validation loss: 2.8192317649623906

Epoch: 6| Step: 3
Training loss: 1.8253780495985752
Validation loss: 2.7983211280854974

Epoch: 6| Step: 4
Training loss: 1.1800174883176926
Validation loss: 2.7675633794642542

Epoch: 6| Step: 5
Training loss: 1.2639813994807587
Validation loss: 2.784863014710328

Epoch: 6| Step: 6
Training loss: 1.4892634957627213
Validation loss: 2.768710869942451

Epoch: 6| Step: 7
Training loss: 1.2169164901893839
Validation loss: 2.7268546384228545

Epoch: 6| Step: 8
Training loss: 1.749296660091688
Validation loss: 2.6993430992738685

Epoch: 6| Step: 9
Training loss: 1.4096477151650537
Validation loss: 2.6238932017054144

Epoch: 6| Step: 10
Training loss: 1.1890080563566652
Validation loss: 2.7294927407106626

Epoch: 6| Step: 11
Training loss: 2.2170654134223913
Validation loss: 2.680127418226735

Epoch: 6| Step: 12
Training loss: 1.045311058511011
Validation loss: 2.6425703057518586

Epoch: 6| Step: 13
Training loss: 0.8858714487793995
Validation loss: 2.8204116451628054

Epoch: 123| Step: 0
Training loss: 1.0399883419080362
Validation loss: 2.806845398903028

Epoch: 6| Step: 1
Training loss: 1.4263125749078749
Validation loss: 2.7483546074097265

Epoch: 6| Step: 2
Training loss: 1.4749554966823926
Validation loss: 2.789375771988176

Epoch: 6| Step: 3
Training loss: 1.4621690261498854
Validation loss: 2.7462050377845095

Epoch: 6| Step: 4
Training loss: 1.276734419677396
Validation loss: 2.7696661582267144

Epoch: 6| Step: 5
Training loss: 1.2876879212352337
Validation loss: 2.7300032335711695

Epoch: 6| Step: 6
Training loss: 1.4395592079772526
Validation loss: 2.734848250352505

Epoch: 6| Step: 7
Training loss: 1.044054587687312
Validation loss: 2.6445393339152816

Epoch: 6| Step: 8
Training loss: 1.0794260771240158
Validation loss: 2.736443483805846

Epoch: 6| Step: 9
Training loss: 0.9443924895812341
Validation loss: 2.56276619311682

Epoch: 6| Step: 10
Training loss: 1.106665943635758
Validation loss: 2.7384761318308657

Epoch: 6| Step: 11
Training loss: 1.3483169042028809
Validation loss: 2.791001387698408

Epoch: 6| Step: 12
Training loss: 2.425741149276034
Validation loss: 2.6998231158772508

Epoch: 6| Step: 13
Training loss: 0.862608565532842
Validation loss: 2.729097588710794

Epoch: 124| Step: 0
Training loss: 0.8795301469425584
Validation loss: 2.6869911407028413

Epoch: 6| Step: 1
Training loss: 1.2462222711659767
Validation loss: 2.6183666400826655

Epoch: 6| Step: 2
Training loss: 0.6299511539732967
Validation loss: 2.693932737567583

Epoch: 6| Step: 3
Training loss: 2.036413701211443
Validation loss: 2.685737312731733

Epoch: 6| Step: 4
Training loss: 1.7094565474953314
Validation loss: 2.6326447083446256

Epoch: 6| Step: 5
Training loss: 1.0384245326575372
Validation loss: 2.7532433110946224

Epoch: 6| Step: 6
Training loss: 1.1875560144966377
Validation loss: 2.7074216090554306

Epoch: 6| Step: 7
Training loss: 1.1451863051520004
Validation loss: 2.7891578907330388

Epoch: 6| Step: 8
Training loss: 1.1343219040563814
Validation loss: 2.8901436619761944

Epoch: 6| Step: 9
Training loss: 1.5922771454825706
Validation loss: 2.732481862432902

Epoch: 6| Step: 10
Training loss: 1.245122118173448
Validation loss: 2.769967099119458

Epoch: 6| Step: 11
Training loss: 1.3161705100319112
Validation loss: 2.703132791085307

Epoch: 6| Step: 12
Training loss: 0.9842717252779697
Validation loss: 2.711878984091866

Epoch: 6| Step: 13
Training loss: 1.1687716272974429
Validation loss: 2.777321344599103

Epoch: 125| Step: 0
Training loss: 0.9585924143886821
Validation loss: 2.709006465500009

Epoch: 6| Step: 1
Training loss: 0.9229942897648926
Validation loss: 2.7780220644875415

Epoch: 6| Step: 2
Training loss: 2.1650398333543395
Validation loss: 2.665940429223232

Epoch: 6| Step: 3
Training loss: 1.726507470820415
Validation loss: 2.7275333807394726

Epoch: 6| Step: 4
Training loss: 1.1098016267795845
Validation loss: 2.78593511690076

Epoch: 6| Step: 5
Training loss: 1.0568649984526044
Validation loss: 2.725125959092519

Epoch: 6| Step: 6
Training loss: 0.7298213517401227
Validation loss: 2.678058229056942

Epoch: 6| Step: 7
Training loss: 1.46196567849448
Validation loss: 2.780391217635543

Epoch: 6| Step: 8
Training loss: 1.2089426159772394
Validation loss: 2.7279546584717598

Epoch: 6| Step: 9
Training loss: 1.1521007216913601
Validation loss: 2.805780691822445

Epoch: 6| Step: 10
Training loss: 1.27189542861766
Validation loss: 2.773459621574042

Epoch: 6| Step: 11
Training loss: 1.3199171569143813
Validation loss: 2.643557513408938

Epoch: 6| Step: 12
Training loss: 1.892243630342955
Validation loss: 2.741986650463638

Epoch: 6| Step: 13
Training loss: 1.0461025519709395
Validation loss: 2.7418130472252202

Epoch: 126| Step: 0
Training loss: 1.2329933062926282
Validation loss: 2.7325522605503068

Epoch: 6| Step: 1
Training loss: 1.1427849998013073
Validation loss: 2.7240284508943255

Epoch: 6| Step: 2
Training loss: 1.0100152834123057
Validation loss: 2.702422386981708

Epoch: 6| Step: 3
Training loss: 0.9666910441109153
Validation loss: 2.6060169411550413

Epoch: 6| Step: 4
Training loss: 1.4696496683581017
Validation loss: 2.736959910423323

Epoch: 6| Step: 5
Training loss: 1.7903595599479716
Validation loss: 2.678946434291424

Epoch: 6| Step: 6
Training loss: 1.0732475190381676
Validation loss: 2.7499594396432143

Epoch: 6| Step: 7
Training loss: 1.1554621512512833
Validation loss: 2.8151647871173524

Epoch: 6| Step: 8
Training loss: 0.8298281304382187
Validation loss: 2.842145460145374

Epoch: 6| Step: 9
Training loss: 2.070122015485218
Validation loss: 2.9870915589920157

Epoch: 6| Step: 10
Training loss: 1.2580148759183738
Validation loss: 2.8139123408110276

Epoch: 6| Step: 11
Training loss: 0.9549478703396449
Validation loss: 2.871771672285259

Epoch: 6| Step: 12
Training loss: 1.3321266028319512
Validation loss: 2.810257130405482

Epoch: 6| Step: 13
Training loss: 1.5362672158899193
Validation loss: 2.746738703575479

Epoch: 127| Step: 0
Training loss: 0.7903182358116927
Validation loss: 2.68676150325751

Epoch: 6| Step: 1
Training loss: 2.150096793546433
Validation loss: 2.7384112694999776

Epoch: 6| Step: 2
Training loss: 1.5468774660649534
Validation loss: 2.6982795932720585

Epoch: 6| Step: 3
Training loss: 1.1235309121633226
Validation loss: 2.6480419122312067

Epoch: 6| Step: 4
Training loss: 1.3421878605976443
Validation loss: 2.706114275599866

Epoch: 6| Step: 5
Training loss: 1.2705254989671384
Validation loss: 2.7455066254035123

Epoch: 6| Step: 6
Training loss: 1.2727185425520868
Validation loss: 2.68421972415583

Epoch: 6| Step: 7
Training loss: 1.0643330637565802
Validation loss: 2.740259432797049

Epoch: 6| Step: 8
Training loss: 1.3699120539956855
Validation loss: 2.7467757310169874

Epoch: 6| Step: 9
Training loss: 0.8307836070304411
Validation loss: 2.748055984709714

Epoch: 6| Step: 10
Training loss: 1.272908762123218
Validation loss: 2.811971869155695

Epoch: 6| Step: 11
Training loss: 0.9215279912065995
Validation loss: 2.7731954119695117

Epoch: 6| Step: 12
Training loss: 1.3273617514769882
Validation loss: 2.7804178143035916

Epoch: 6| Step: 13
Training loss: 1.3863728696342255
Validation loss: 2.80144888255125

Epoch: 128| Step: 0
Training loss: 1.313531288793691
Validation loss: 2.8464144426660587

Epoch: 6| Step: 1
Training loss: 1.042379662957668
Validation loss: 2.7077950798599875

Epoch: 6| Step: 2
Training loss: 0.8528970183205992
Validation loss: 2.717783876838332

Epoch: 6| Step: 3
Training loss: 1.169017716207451
Validation loss: 2.81547593806404

Epoch: 6| Step: 4
Training loss: 1.0208221097575705
Validation loss: 2.7583945995530006

Epoch: 6| Step: 5
Training loss: 1.612194369427723
Validation loss: 2.8429002575207645

Epoch: 6| Step: 6
Training loss: 1.5197011661405333
Validation loss: 2.687582924029253

Epoch: 6| Step: 7
Training loss: 0.8504907005066278
Validation loss: 2.7049908822470647

Epoch: 6| Step: 8
Training loss: 0.8656523923981086
Validation loss: 2.7329268335439343

Epoch: 6| Step: 9
Training loss: 0.9395367749697392
Validation loss: 2.737621334876498

Epoch: 6| Step: 10
Training loss: 1.0753503006906897
Validation loss: 2.771987450005662

Epoch: 6| Step: 11
Training loss: 2.2533517879467735
Validation loss: 2.710587991103113

Epoch: 6| Step: 12
Training loss: 0.932683492969785
Validation loss: 2.8543689869549427

Epoch: 6| Step: 13
Training loss: 1.1849260039907437
Validation loss: 2.90138564932629

Epoch: 129| Step: 0
Training loss: 1.359074219499425
Validation loss: 2.81212982284757

Epoch: 6| Step: 1
Training loss: 1.177212879625299
Validation loss: 2.8082119076868692

Epoch: 6| Step: 2
Training loss: 1.4885556426125173
Validation loss: 2.8073688607345426

Epoch: 6| Step: 3
Training loss: 0.9386284712187362
Validation loss: 2.849499587693156

Epoch: 6| Step: 4
Training loss: 1.1249581435152398
Validation loss: 2.7926831933075356

Epoch: 6| Step: 5
Training loss: 1.0831379102849892
Validation loss: 2.8405197017724824

Epoch: 6| Step: 6
Training loss: 1.3907805795114014
Validation loss: 2.738378315364789

Epoch: 6| Step: 7
Training loss: 1.3035167535188823
Validation loss: 2.684560735728682

Epoch: 6| Step: 8
Training loss: 0.855301583735778
Validation loss: 2.7728724230860498

Epoch: 6| Step: 9
Training loss: 0.8452259505945384
Validation loss: 2.6748084905884486

Epoch: 6| Step: 10
Training loss: 2.1113588399708485
Validation loss: 2.831015527039221

Epoch: 6| Step: 11
Training loss: 1.3214030079228418
Validation loss: 2.7488442217429765

Epoch: 6| Step: 12
Training loss: 1.0006177901247122
Validation loss: 2.8098324311003027

Epoch: 6| Step: 13
Training loss: 1.3627705751586319
Validation loss: 2.917302012498864

Epoch: 130| Step: 0
Training loss: 0.857071372582173
Validation loss: 2.9522671269230587

Epoch: 6| Step: 1
Training loss: 0.8789565686550782
Validation loss: 2.8693147644974863

Epoch: 6| Step: 2
Training loss: 1.5013758389524055
Validation loss: 2.921535982261941

Epoch: 6| Step: 3
Training loss: 2.060800719331533
Validation loss: 2.7987329431797496

Epoch: 6| Step: 4
Training loss: 1.0703057616084362
Validation loss: 2.785368523839089

Epoch: 6| Step: 5
Training loss: 1.5073450184070671
Validation loss: 2.7498900362628462

Epoch: 6| Step: 6
Training loss: 1.1466650747317715
Validation loss: 2.589463709991208

Epoch: 6| Step: 7
Training loss: 1.4498500220246044
Validation loss: 2.7007951784092

Epoch: 6| Step: 8
Training loss: 0.9641774150795491
Validation loss: 2.740832915297844

Epoch: 6| Step: 9
Training loss: 0.9733957750124891
Validation loss: 2.6745159935327125

Epoch: 6| Step: 10
Training loss: 1.3436949075450044
Validation loss: 2.7480616529582957

Epoch: 6| Step: 11
Training loss: 0.7170056447029044
Validation loss: 2.823967112986389

Epoch: 6| Step: 12
Training loss: 1.2571129601038482
Validation loss: 2.834473791787563

Epoch: 6| Step: 13
Training loss: 1.0707836367186552
Validation loss: 2.84779761529953

Epoch: 131| Step: 0
Training loss: 0.8798069386681451
Validation loss: 2.9356521584181285

Epoch: 6| Step: 1
Training loss: 1.0944313107158083
Validation loss: 2.889094908308847

Epoch: 6| Step: 2
Training loss: 1.1174832466115632
Validation loss: 2.8228237845329964

Epoch: 6| Step: 3
Training loss: 0.9779910815520753
Validation loss: 2.7626191379639176

Epoch: 6| Step: 4
Training loss: 1.0644394060003255
Validation loss: 2.7664364847310163

Epoch: 6| Step: 5
Training loss: 1.2796907008018101
Validation loss: 2.7413131464689284

Epoch: 6| Step: 6
Training loss: 0.94235991613215
Validation loss: 2.7901851841439496

Epoch: 6| Step: 7
Training loss: 0.8907911246113254
Validation loss: 2.758133621899645

Epoch: 6| Step: 8
Training loss: 1.3381320707659077
Validation loss: 2.754857483839459

Epoch: 6| Step: 9
Training loss: 1.2061333634510272
Validation loss: 2.724684803783414

Epoch: 6| Step: 10
Training loss: 0.9340600481253203
Validation loss: 2.7721080907093305

Epoch: 6| Step: 11
Training loss: 1.2201682421885949
Validation loss: 2.855780880589844

Epoch: 6| Step: 12
Training loss: 2.369176953973574
Validation loss: 2.7454121857610083

Epoch: 6| Step: 13
Training loss: 1.1498652296292922
Validation loss: 2.8050736043773483

Epoch: 132| Step: 0
Training loss: 0.9343256934179432
Validation loss: 2.721700214974242

Epoch: 6| Step: 1
Training loss: 0.9651836460666231
Validation loss: 2.7238727116059547

Epoch: 6| Step: 2
Training loss: 1.3142895079492822
Validation loss: 2.7180931642512474

Epoch: 6| Step: 3
Training loss: 0.9968844996271754
Validation loss: 2.73329337389355

Epoch: 6| Step: 4
Training loss: 1.2058307887755468
Validation loss: 2.7729901306677385

Epoch: 6| Step: 5
Training loss: 1.2416706089409495
Validation loss: 2.7317158002858744

Epoch: 6| Step: 6
Training loss: 1.1403900845186568
Validation loss: 2.7486455645229606

Epoch: 6| Step: 7
Training loss: 2.0082230797521765
Validation loss: 2.7195782916084297

Epoch: 6| Step: 8
Training loss: 0.8511347264958085
Validation loss: 2.8109715865201106

Epoch: 6| Step: 9
Training loss: 1.1287821665222295
Validation loss: 2.797383636881741

Epoch: 6| Step: 10
Training loss: 1.1857838527375923
Validation loss: 2.8324310932492547

Epoch: 6| Step: 11
Training loss: 1.1779175168387321
Validation loss: 2.7570471489580215

Epoch: 6| Step: 12
Training loss: 1.1742729067924416
Validation loss: 2.7404827096931066

Epoch: 6| Step: 13
Training loss: 1.0936238897372257
Validation loss: 2.6703369889495225

Epoch: 133| Step: 0
Training loss: 1.2313800162202644
Validation loss: 2.7035647054860887

Epoch: 6| Step: 1
Training loss: 1.9445264829253037
Validation loss: 2.651723947519743

Epoch: 6| Step: 2
Training loss: 1.689329850655157
Validation loss: 2.706197194559945

Epoch: 6| Step: 3
Training loss: 1.110009025674502
Validation loss: 2.691738158025563

Epoch: 6| Step: 4
Training loss: 1.0220783322991183
Validation loss: 2.745995727352366

Epoch: 6| Step: 5
Training loss: 1.0707075963001769
Validation loss: 2.8153426604240264

Epoch: 6| Step: 6
Training loss: 1.0893361540022073
Validation loss: 2.761360659623269

Epoch: 6| Step: 7
Training loss: 0.8606151995242831
Validation loss: 2.8104402558562356

Epoch: 6| Step: 8
Training loss: 1.1389968434525342
Validation loss: 2.7515327343692757

Epoch: 6| Step: 9
Training loss: 1.2071255150191778
Validation loss: 2.767459095988882

Epoch: 6| Step: 10
Training loss: 1.048186377569026
Validation loss: 2.791676469092928

Epoch: 6| Step: 11
Training loss: 1.1162004712299116
Validation loss: 2.769153377291758

Epoch: 6| Step: 12
Training loss: 0.8153655797919186
Validation loss: 2.7497865998669684

Epoch: 6| Step: 13
Training loss: 0.9617339144641462
Validation loss: 2.705465049935731

Epoch: 134| Step: 0
Training loss: 1.1117122904629406
Validation loss: 2.669491230619385

Epoch: 6| Step: 1
Training loss: 0.8054172577109999
Validation loss: 2.680204232295892

Epoch: 6| Step: 2
Training loss: 1.0402466759292823
Validation loss: 2.7366335160884034

Epoch: 6| Step: 3
Training loss: 1.1150537134070981
Validation loss: 2.7311686290546833

Epoch: 6| Step: 4
Training loss: 1.2606397331560784
Validation loss: 2.781666470895817

Epoch: 6| Step: 5
Training loss: 1.3549159349074755
Validation loss: 2.7001069259663795

Epoch: 6| Step: 6
Training loss: 1.8155262774155063
Validation loss: 2.722652791047054

Epoch: 6| Step: 7
Training loss: 0.8725031241112333
Validation loss: 2.778019961819793

Epoch: 6| Step: 8
Training loss: 0.9402393374215028
Validation loss: 2.8124629265496366

Epoch: 6| Step: 9
Training loss: 0.831734259527269
Validation loss: 2.8246902205951447

Epoch: 6| Step: 10
Training loss: 1.2749972474311586
Validation loss: 2.742763810128542

Epoch: 6| Step: 11
Training loss: 0.5918287262355436
Validation loss: 2.6939002128666036

Epoch: 6| Step: 12
Training loss: 1.216159610820006
Validation loss: 2.7986286284784847

Epoch: 6| Step: 13
Training loss: 0.9044393011194752
Validation loss: 2.800603629509355

Epoch: 135| Step: 0
Training loss: 1.0216524120869324
Validation loss: 2.79654896290293

Epoch: 6| Step: 1
Training loss: 1.4670003655868107
Validation loss: 2.7519646620209652

Epoch: 6| Step: 2
Training loss: 0.6864570379365575
Validation loss: 2.791047103416017

Epoch: 6| Step: 3
Training loss: 1.36604095339508
Validation loss: 2.7818178604418184

Epoch: 6| Step: 4
Training loss: 1.1828881606138109
Validation loss: 2.8454808707140824

Epoch: 6| Step: 5
Training loss: 1.1153611413423254
Validation loss: 2.8508083722396047

Epoch: 6| Step: 6
Training loss: 0.9456905838435374
Validation loss: 2.8162382642758526

Epoch: 6| Step: 7
Training loss: 1.4656934384632412
Validation loss: 2.799142085636828

Epoch: 6| Step: 8
Training loss: 1.0531684391107228
Validation loss: 2.748920749081174

Epoch: 6| Step: 9
Training loss: 0.8926005287614163
Validation loss: 2.7419681153385507

Epoch: 6| Step: 10
Training loss: 1.106036468415084
Validation loss: 2.6954137368470565

Epoch: 6| Step: 11
Training loss: 0.9197056996200329
Validation loss: 2.712002518442648

Epoch: 6| Step: 12
Training loss: 2.038678714107014
Validation loss: 2.779582162897886

Epoch: 6| Step: 13
Training loss: 1.1433893437656166
Validation loss: 2.7585881540966795

Epoch: 136| Step: 0
Training loss: 1.0851029956292892
Validation loss: 2.771951884651675

Epoch: 6| Step: 1
Training loss: 1.553198019418134
Validation loss: 2.7318847360977836

Epoch: 6| Step: 2
Training loss: 0.6888114168992598
Validation loss: 2.7353924556763785

Epoch: 6| Step: 3
Training loss: 1.5834008587274877
Validation loss: 2.7683839201472646

Epoch: 6| Step: 4
Training loss: 1.0390880266079963
Validation loss: 2.805894030768058

Epoch: 6| Step: 5
Training loss: 0.8737964527186474
Validation loss: 2.743613717207298

Epoch: 6| Step: 6
Training loss: 1.079747292481879
Validation loss: 2.724467568484349

Epoch: 6| Step: 7
Training loss: 1.0371038576830642
Validation loss: 2.813688408589751

Epoch: 6| Step: 8
Training loss: 0.8904419091739977
Validation loss: 2.800024067684459

Epoch: 6| Step: 9
Training loss: 0.8898180267125909
Validation loss: 2.814688572773814

Epoch: 6| Step: 10
Training loss: 1.1319065549212937
Validation loss: 2.8179930133584064

Epoch: 6| Step: 11
Training loss: 1.1687561238990318
Validation loss: 2.7819103357165913

Epoch: 6| Step: 12
Training loss: 0.621796264648138
Validation loss: 2.7837525014033884

Epoch: 6| Step: 13
Training loss: 1.9957208751726108
Validation loss: 2.7666066038743558

Epoch: 137| Step: 0
Training loss: 1.9835205641561107
Validation loss: 2.7300781640075398

Epoch: 6| Step: 1
Training loss: 1.2711235038215083
Validation loss: 2.730593946330828

Epoch: 6| Step: 2
Training loss: 0.7083976566803665
Validation loss: 2.719787165972754

Epoch: 6| Step: 3
Training loss: 0.7148040593702839
Validation loss: 2.7859874054066567

Epoch: 6| Step: 4
Training loss: 0.961920816620482
Validation loss: 2.7673221991172645

Epoch: 6| Step: 5
Training loss: 1.3145128891212492
Validation loss: 2.749028915842491

Epoch: 6| Step: 6
Training loss: 1.1339825079912722
Validation loss: 2.751880089770065

Epoch: 6| Step: 7
Training loss: 1.1884504831002636
Validation loss: 2.7399710077529322

Epoch: 6| Step: 8
Training loss: 0.8960834678851539
Validation loss: 2.7204716664536486

Epoch: 6| Step: 9
Training loss: 1.301008050065348
Validation loss: 2.6090330710780583

Epoch: 6| Step: 10
Training loss: 1.010786886655028
Validation loss: 2.8070485653242785

Epoch: 6| Step: 11
Training loss: 0.9993650089263103
Validation loss: 2.700979612564225

Epoch: 6| Step: 12
Training loss: 1.0290030072597383
Validation loss: 2.8382130470555014

Epoch: 6| Step: 13
Training loss: 1.0389032456963723
Validation loss: 2.7665248491715704

Epoch: 138| Step: 0
Training loss: 1.0521160850840627
Validation loss: 2.812788743632653

Epoch: 6| Step: 1
Training loss: 1.1801098705316315
Validation loss: 2.7726961819648586

Epoch: 6| Step: 2
Training loss: 0.9455902700356063
Validation loss: 2.829562838592553

Epoch: 6| Step: 3
Training loss: 2.118168564858055
Validation loss: 2.831332556817032

Epoch: 6| Step: 4
Training loss: 1.143117506733691
Validation loss: 2.7657939765875437

Epoch: 6| Step: 5
Training loss: 0.7474667363755494
Validation loss: 2.757205871200306

Epoch: 6| Step: 6
Training loss: 0.7160334458451278
Validation loss: 2.717371975042178

Epoch: 6| Step: 7
Training loss: 1.0963450572646474
Validation loss: 2.7703130467803927

Epoch: 6| Step: 8
Training loss: 0.9941168821606081
Validation loss: 2.7121412699232

Epoch: 6| Step: 9
Training loss: 1.4057929673850815
Validation loss: 2.7039366516032475

Epoch: 6| Step: 10
Training loss: 1.3500368183907956
Validation loss: 2.6833092595633654

Epoch: 6| Step: 11
Training loss: 1.2177012895565844
Validation loss: 2.7924355876099853

Epoch: 6| Step: 12
Training loss: 1.2072849932868228
Validation loss: 2.756719759976033

Epoch: 6| Step: 13
Training loss: 0.6730886631245685
Validation loss: 2.788253068340634

Epoch: 139| Step: 0
Training loss: 1.141564021867917
Validation loss: 2.8222928126168485

Epoch: 6| Step: 1
Training loss: 0.8093374030022945
Validation loss: 2.8334022167658572

Epoch: 6| Step: 2
Training loss: 1.0766080052208034
Validation loss: 2.786004834690541

Epoch: 6| Step: 3
Training loss: 1.1863994517910925
Validation loss: 2.825047330544227

Epoch: 6| Step: 4
Training loss: 0.8277509312326348
Validation loss: 2.813517534777917

Epoch: 6| Step: 5
Training loss: 0.7649369554160058
Validation loss: 2.728022828288131

Epoch: 6| Step: 6
Training loss: 0.8068857628705071
Validation loss: 2.8098622845381347

Epoch: 6| Step: 7
Training loss: 0.6005130630568342
Validation loss: 2.737228299945353

Epoch: 6| Step: 8
Training loss: 0.9176502405687914
Validation loss: 2.7452118544131254

Epoch: 6| Step: 9
Training loss: 0.9235460040123067
Validation loss: 2.8140199439519815

Epoch: 6| Step: 10
Training loss: 1.3045016401930498
Validation loss: 2.8296834961448414

Epoch: 6| Step: 11
Training loss: 0.8589440739203894
Validation loss: 2.838741265141699

Epoch: 6| Step: 12
Training loss: 1.955624499273678
Validation loss: 2.8239653118802

Epoch: 6| Step: 13
Training loss: 1.0625761790173964
Validation loss: 2.7731784753326973

Epoch: 140| Step: 0
Training loss: 0.8585932557206124
Validation loss: 2.7630704874699847

Epoch: 6| Step: 1
Training loss: 1.3773578454831028
Validation loss: 2.6911038771933824

Epoch: 6| Step: 2
Training loss: 1.0030471747800747
Validation loss: 2.8336854930883955

Epoch: 6| Step: 3
Training loss: 1.0346602493149388
Validation loss: 2.744741165497612

Epoch: 6| Step: 4
Training loss: 0.9766419645403556
Validation loss: 2.68558985820242

Epoch: 6| Step: 5
Training loss: 0.9579846984999119
Validation loss: 2.7195471110288243

Epoch: 6| Step: 6
Training loss: 1.173126061529981
Validation loss: 2.6756622362237583

Epoch: 6| Step: 7
Training loss: 1.8776699130486605
Validation loss: 2.717980155252034

Epoch: 6| Step: 8
Training loss: 1.0088290624821703
Validation loss: 2.9780776738946

Epoch: 6| Step: 9
Training loss: 0.8883913037409076
Validation loss: 2.8561114532903176

Epoch: 6| Step: 10
Training loss: 1.0487833421974482
Validation loss: 2.9522684863456035

Epoch: 6| Step: 11
Training loss: 1.1510903993995092
Validation loss: 2.848170411517546

Epoch: 6| Step: 12
Training loss: 0.9082124442986244
Validation loss: 2.819290173093851

Epoch: 6| Step: 13
Training loss: 0.7813435307782289
Validation loss: 2.7003464723738353

Epoch: 141| Step: 0
Training loss: 1.2926441718733446
Validation loss: 2.83719139297453

Epoch: 6| Step: 1
Training loss: 0.9900187421238397
Validation loss: 2.669572607830284

Epoch: 6| Step: 2
Training loss: 0.9060556269067466
Validation loss: 2.7672447590690004

Epoch: 6| Step: 3
Training loss: 1.1071865363228546
Validation loss: 2.7765337213911407

Epoch: 6| Step: 4
Training loss: 0.8249834680345812
Validation loss: 2.7235131760057847

Epoch: 6| Step: 5
Training loss: 1.0977783678212385
Validation loss: 2.781202194431653

Epoch: 6| Step: 6
Training loss: 1.8734303580077194
Validation loss: 2.895506014724182

Epoch: 6| Step: 7
Training loss: 1.2015929933803386
Validation loss: 2.920620722159054

Epoch: 6| Step: 8
Training loss: 0.8643090529257583
Validation loss: 2.8074787881989116

Epoch: 6| Step: 9
Training loss: 1.1010428751948187
Validation loss: 2.831632613264887

Epoch: 6| Step: 10
Training loss: 1.1401220283950542
Validation loss: 2.7771664762726007

Epoch: 6| Step: 11
Training loss: 1.059277978465918
Validation loss: 2.729994092732281

Epoch: 6| Step: 12
Training loss: 0.8488505866514773
Validation loss: 2.722072850776535

Epoch: 6| Step: 13
Training loss: 1.4983721483158423
Validation loss: 2.6439494888157333

Epoch: 142| Step: 0
Training loss: 0.975148390212777
Validation loss: 2.6992847013168175

Epoch: 6| Step: 1
Training loss: 0.6351372672572223
Validation loss: 2.6934920350457356

Epoch: 6| Step: 2
Training loss: 0.7562471720745083
Validation loss: 2.777252782377234

Epoch: 6| Step: 3
Training loss: 1.9260204855244376
Validation loss: 2.821320780602974

Epoch: 6| Step: 4
Training loss: 1.1460804008221328
Validation loss: 2.827155043485014

Epoch: 6| Step: 5
Training loss: 1.2485271359612362
Validation loss: 2.91111723801726

Epoch: 6| Step: 6
Training loss: 1.1907955417994245
Validation loss: 2.9361560263116036

Epoch: 6| Step: 7
Training loss: 0.79965424665665
Validation loss: 2.7808119468182855

Epoch: 6| Step: 8
Training loss: 1.3974961676911848
Validation loss: 2.78520870293103

Epoch: 6| Step: 9
Training loss: 0.9573013547310946
Validation loss: 2.7781161250575925

Epoch: 6| Step: 10
Training loss: 0.9323055046091707
Validation loss: 2.7078421269531496

Epoch: 6| Step: 11
Training loss: 1.356757263389083
Validation loss: 2.729797004143862

Epoch: 6| Step: 12
Training loss: 1.2404818550760133
Validation loss: 2.7361893220449858

Epoch: 6| Step: 13
Training loss: 0.8109701866662541
Validation loss: 2.6460357398360794

Epoch: 143| Step: 0
Training loss: 0.9836675129956498
Validation loss: 2.7908436050598104

Epoch: 6| Step: 1
Training loss: 0.6790316695242262
Validation loss: 2.7564247537287403

Epoch: 6| Step: 2
Training loss: 1.8352411775843314
Validation loss: 2.7513828846442676

Epoch: 6| Step: 3
Training loss: 1.0176044248378266
Validation loss: 2.8624823107443547

Epoch: 6| Step: 4
Training loss: 0.8259939448524931
Validation loss: 2.8405277734952143

Epoch: 6| Step: 5
Training loss: 1.1076384371308483
Validation loss: 2.811794319631807

Epoch: 6| Step: 6
Training loss: 0.9996246587159544
Validation loss: 2.79369486726641

Epoch: 6| Step: 7
Training loss: 1.1971814871218565
Validation loss: 2.724964435007

Epoch: 6| Step: 8
Training loss: 0.983492167759221
Validation loss: 2.7947546737635913

Epoch: 6| Step: 9
Training loss: 0.9397395405188543
Validation loss: 2.7868736361648336

Epoch: 6| Step: 10
Training loss: 0.8959689185571547
Validation loss: 2.661212892406531

Epoch: 6| Step: 11
Training loss: 0.8558481846839109
Validation loss: 2.657710642416798

Epoch: 6| Step: 12
Training loss: 0.9980532950178023
Validation loss: 2.8031740842765265

Epoch: 6| Step: 13
Training loss: 0.7533632210341881
Validation loss: 2.6958871496057704

Epoch: 144| Step: 0
Training loss: 0.7007051790215615
Validation loss: 2.729713229906253

Epoch: 6| Step: 1
Training loss: 1.0122775740086414
Validation loss: 2.7457740999199367

Epoch: 6| Step: 2
Training loss: 0.8736715109066331
Validation loss: 2.729723448899675

Epoch: 6| Step: 3
Training loss: 0.8122128199189534
Validation loss: 2.801318207170984

Epoch: 6| Step: 4
Training loss: 1.1696407126736716
Validation loss: 2.7392433932237097

Epoch: 6| Step: 5
Training loss: 0.6883764315899048
Validation loss: 2.8084298246505237

Epoch: 6| Step: 6
Training loss: 1.2149727314373322
Validation loss: 2.8159261956603783

Epoch: 6| Step: 7
Training loss: 0.9678857085758719
Validation loss: 2.8061656120769416

Epoch: 6| Step: 8
Training loss: 0.9983676462109199
Validation loss: 2.734980750425896

Epoch: 6| Step: 9
Training loss: 1.2118284823857852
Validation loss: 2.759549812145171

Epoch: 6| Step: 10
Training loss: 1.0553325799596736
Validation loss: 2.83009223592227

Epoch: 6| Step: 11
Training loss: 1.965345860782088
Validation loss: 2.767147977501146

Epoch: 6| Step: 12
Training loss: 0.779490396664368
Validation loss: 2.758151227196908

Epoch: 6| Step: 13
Training loss: 0.6634085183769473
Validation loss: 2.8585669621299044

Epoch: 145| Step: 0
Training loss: 0.701227382492364
Validation loss: 2.7620623930960555

Epoch: 6| Step: 1
Training loss: 0.6505737047010224
Validation loss: 2.822215233587221

Epoch: 6| Step: 2
Training loss: 1.0702965728242984
Validation loss: 2.72696086083006

Epoch: 6| Step: 3
Training loss: 0.7649376177441332
Validation loss: 2.8857117282832716

Epoch: 6| Step: 4
Training loss: 1.3267529749631188
Validation loss: 2.905088267689717

Epoch: 6| Step: 5
Training loss: 0.8533709510381966
Validation loss: 2.6701046021410693

Epoch: 6| Step: 6
Training loss: 0.6598168578506696
Validation loss: 2.817819396889758

Epoch: 6| Step: 7
Training loss: 1.090589589415796
Validation loss: 2.7862296084831106

Epoch: 6| Step: 8
Training loss: 1.9117645170893511
Validation loss: 2.8400816400192954

Epoch: 6| Step: 9
Training loss: 0.979978644079953
Validation loss: 2.848765188268457

Epoch: 6| Step: 10
Training loss: 0.9552175969985381
Validation loss: 2.7644923273979227

Epoch: 6| Step: 11
Training loss: 0.9724655883702363
Validation loss: 2.768129741118864

Epoch: 6| Step: 12
Training loss: 1.103507414930742
Validation loss: 2.783656518603004

Epoch: 6| Step: 13
Training loss: 0.7947277235021242
Validation loss: 2.803596943365176

Epoch: 146| Step: 0
Training loss: 1.0059930508868424
Validation loss: 2.7534932866252193

Epoch: 6| Step: 1
Training loss: 1.1581568588099194
Validation loss: 2.770523087382438

Epoch: 6| Step: 2
Training loss: 0.7889861268200564
Validation loss: 2.81841369844436

Epoch: 6| Step: 3
Training loss: 0.7494820554746969
Validation loss: 2.868245303014682

Epoch: 6| Step: 4
Training loss: 1.167350018279829
Validation loss: 2.7949932452707666

Epoch: 6| Step: 5
Training loss: 1.200909593681281
Validation loss: 2.849695983086528

Epoch: 6| Step: 6
Training loss: 0.9230169238939155
Validation loss: 2.824379634539634

Epoch: 6| Step: 7
Training loss: 0.7395081996811326
Validation loss: 2.8385958231854715

Epoch: 6| Step: 8
Training loss: 1.2091740719765423
Validation loss: 2.7120039689964277

Epoch: 6| Step: 9
Training loss: 0.6359863749850031
Validation loss: 2.796054542155051

Epoch: 6| Step: 10
Training loss: 0.5710875587806185
Validation loss: 2.7752039195791354

Epoch: 6| Step: 11
Training loss: 0.9061341047172938
Validation loss: 2.8419694461401566

Epoch: 6| Step: 12
Training loss: 0.9050480995252261
Validation loss: 2.829745620419936

Epoch: 6| Step: 13
Training loss: 1.7805719256165142
Validation loss: 2.7296720915200994

Epoch: 147| Step: 0
Training loss: 0.8166273629857818
Validation loss: 2.741864959788847

Epoch: 6| Step: 1
Training loss: 0.9774532375711568
Validation loss: 2.7519941469036002

Epoch: 6| Step: 2
Training loss: 0.8308361227766048
Validation loss: 2.8410515331046544

Epoch: 6| Step: 3
Training loss: 0.9860664549344053
Validation loss: 2.7683288230912844

Epoch: 6| Step: 4
Training loss: 0.8615233876866768
Validation loss: 2.7458256047496556

Epoch: 6| Step: 5
Training loss: 1.9679883058673493
Validation loss: 2.78854989435471

Epoch: 6| Step: 6
Training loss: 0.7218190059991284
Validation loss: 2.8453509536761854

Epoch: 6| Step: 7
Training loss: 0.5506629005057802
Validation loss: 2.868891556958784

Epoch: 6| Step: 8
Training loss: 1.0569118638154462
Validation loss: 2.899487013224053

Epoch: 6| Step: 9
Training loss: 0.9005357207521454
Validation loss: 2.8423633058996547

Epoch: 6| Step: 10
Training loss: 1.0357600340581599
Validation loss: 2.8867487305773585

Epoch: 6| Step: 11
Training loss: 0.7824737120286337
Validation loss: 2.715031079020159

Epoch: 6| Step: 12
Training loss: 0.7987656324047855
Validation loss: 2.6926331992276795

Epoch: 6| Step: 13
Training loss: 1.2073051364115457
Validation loss: 2.7608062805069338

Epoch: 148| Step: 0
Training loss: 1.0078101342934929
Validation loss: 2.845763503223715

Epoch: 6| Step: 1
Training loss: 0.8635840596897195
Validation loss: 2.8451850400303904

Epoch: 6| Step: 2
Training loss: 0.8912710891411415
Validation loss: 2.804602803232743

Epoch: 6| Step: 3
Training loss: 0.8383091590409215
Validation loss: 2.819438823658853

Epoch: 6| Step: 4
Training loss: 0.466912626335918
Validation loss: 2.727650947065236

Epoch: 6| Step: 5
Training loss: 0.7182436278844262
Validation loss: 2.7954214641669943

Epoch: 6| Step: 6
Training loss: 0.9705598905873292
Validation loss: 2.881880198506895

Epoch: 6| Step: 7
Training loss: 1.024009079062178
Validation loss: 2.8953833516278826

Epoch: 6| Step: 8
Training loss: 0.9911370912300985
Validation loss: 2.832414917662653

Epoch: 6| Step: 9
Training loss: 2.056792946415917
Validation loss: 2.735399966008575

Epoch: 6| Step: 10
Training loss: 0.6834751571237051
Validation loss: 2.855884387811561

Epoch: 6| Step: 11
Training loss: 0.8528708110708133
Validation loss: 2.7304074958621256

Epoch: 6| Step: 12
Training loss: 0.6641351772255885
Validation loss: 2.8491647890777814

Epoch: 6| Step: 13
Training loss: 0.728617193183168
Validation loss: 2.869586284139826

Epoch: 149| Step: 0
Training loss: 0.8481079163935603
Validation loss: 2.8225316257805497

Epoch: 6| Step: 1
Training loss: 0.8023105811345528
Validation loss: 2.8452533618717317

Epoch: 6| Step: 2
Training loss: 0.8566464195629515
Validation loss: 2.732901039674025

Epoch: 6| Step: 3
Training loss: 0.9307427708265382
Validation loss: 2.7686719902076797

Epoch: 6| Step: 4
Training loss: 1.8520611441634347
Validation loss: 2.7907513830850212

Epoch: 6| Step: 5
Training loss: 0.9091513329170601
Validation loss: 2.7750349145703286

Epoch: 6| Step: 6
Training loss: 0.6211118395588212
Validation loss: 2.7216136802550417

Epoch: 6| Step: 7
Training loss: 0.7282229083463507
Validation loss: 2.797123533888448

Epoch: 6| Step: 8
Training loss: 1.1468925724190486
Validation loss: 2.704439729169073

Epoch: 6| Step: 9
Training loss: 1.004207046509442
Validation loss: 2.767542603488448

Epoch: 6| Step: 10
Training loss: 0.7305454479077536
Validation loss: 2.773012800339141

Epoch: 6| Step: 11
Training loss: 0.8271761082296072
Validation loss: 2.696218506026786

Epoch: 6| Step: 12
Training loss: 0.6518337746199842
Validation loss: 2.7567155942145836

Epoch: 6| Step: 13
Training loss: 1.2623162050826964
Validation loss: 2.728526540236962

Epoch: 150| Step: 0
Training loss: 1.0639180089508296
Validation loss: 2.84848004963438

Epoch: 6| Step: 1
Training loss: 0.8419507941413494
Validation loss: 2.800481860955186

Epoch: 6| Step: 2
Training loss: 0.9313536067907348
Validation loss: 2.900358264541344

Epoch: 6| Step: 3
Training loss: 1.3048526864927188
Validation loss: 2.8718302986504307

Epoch: 6| Step: 4
Training loss: 0.9350132067150535
Validation loss: 2.873601656316862

Epoch: 6| Step: 5
Training loss: 0.39989291635283947
Validation loss: 2.8246106534939255

Epoch: 6| Step: 6
Training loss: 0.9036292625175791
Validation loss: 2.773679122787115

Epoch: 6| Step: 7
Training loss: 0.5184160180035934
Validation loss: 2.6775802616184357

Epoch: 6| Step: 8
Training loss: 1.271165142621756
Validation loss: 2.7892920847484444

Epoch: 6| Step: 9
Training loss: 0.7506267392585418
Validation loss: 2.7001079487708193

Epoch: 6| Step: 10
Training loss: 0.903205757094383
Validation loss: 2.7796317403889192

Epoch: 6| Step: 11
Training loss: 0.9111954155417269
Validation loss: 2.73672512241369

Epoch: 6| Step: 12
Training loss: 1.783244304870898
Validation loss: 2.7736892800821487

Epoch: 6| Step: 13
Training loss: 1.0362482033634601
Validation loss: 2.8314903847748214

Epoch: 151| Step: 0
Training loss: 0.6900594708825617
Validation loss: 2.7689755935557683

Epoch: 6| Step: 1
Training loss: 0.9562506158365498
Validation loss: 2.7577910598051143

Epoch: 6| Step: 2
Training loss: 0.7436311033725911
Validation loss: 2.7831823943855136

Epoch: 6| Step: 3
Training loss: 0.8933941806406417
Validation loss: 2.728373162226082

Epoch: 6| Step: 4
Training loss: 0.8137517603256007
Validation loss: 2.736436992823915

Epoch: 6| Step: 5
Training loss: 0.933347821265126
Validation loss: 2.6936924880305897

Epoch: 6| Step: 6
Training loss: 0.5757520795081447
Validation loss: 2.7759737265302697

Epoch: 6| Step: 7
Training loss: 0.6167605166503105
Validation loss: 2.7580910777018515

Epoch: 6| Step: 8
Training loss: 0.7837920222356044
Validation loss: 2.8181952562878743

Epoch: 6| Step: 9
Training loss: 0.5801746788971154
Validation loss: 2.720896374223819

Epoch: 6| Step: 10
Training loss: 0.8758580904896686
Validation loss: 2.7187630079404004

Epoch: 6| Step: 11
Training loss: 0.712345322332971
Validation loss: 2.887876093648275

Epoch: 6| Step: 12
Training loss: 1.165730759473543
Validation loss: 2.9159783686518868

Epoch: 6| Step: 13
Training loss: 1.9856257064092842
Validation loss: 2.8676973698567307

Epoch: 152| Step: 0
Training loss: 0.91522403830057
Validation loss: 2.8717242113112635

Epoch: 6| Step: 1
Training loss: 1.8236977202757492
Validation loss: 2.850791387939826

Epoch: 6| Step: 2
Training loss: 0.7495604657651534
Validation loss: 2.8568735906897493

Epoch: 6| Step: 3
Training loss: 1.007642746460887
Validation loss: 2.8211141135714075

Epoch: 6| Step: 4
Training loss: 0.8310686013909414
Validation loss: 2.783993914064062

Epoch: 6| Step: 5
Training loss: 0.905328940261029
Validation loss: 2.7651851900614695

Epoch: 6| Step: 6
Training loss: 0.6180841716709069
Validation loss: 2.7741461623047035

Epoch: 6| Step: 7
Training loss: 0.8593985467632596
Validation loss: 2.831536274767372

Epoch: 6| Step: 8
Training loss: 0.9162774921575791
Validation loss: 2.792197245854961

Epoch: 6| Step: 9
Training loss: 0.8850329670988916
Validation loss: 2.8387556549513144

Epoch: 6| Step: 10
Training loss: 0.8031070336139421
Validation loss: 2.816865189645749

Epoch: 6| Step: 11
Training loss: 0.8584395085253304
Validation loss: 2.8642431138037905

Epoch: 6| Step: 12
Training loss: 0.8035512512943565
Validation loss: 2.8835711493201144

Epoch: 6| Step: 13
Training loss: 0.9392856757968479
Validation loss: 2.700450728317922

Epoch: 153| Step: 0
Training loss: 0.5930537357669677
Validation loss: 2.7646556096425794

Epoch: 6| Step: 1
Training loss: 0.7734159986801833
Validation loss: 2.831592885433836

Epoch: 6| Step: 2
Training loss: 1.059065597498133
Validation loss: 2.725159933780589

Epoch: 6| Step: 3
Training loss: 0.5592433646690509
Validation loss: 2.705823855660063

Epoch: 6| Step: 4
Training loss: 0.5482732608416396
Validation loss: 2.712283940653779

Epoch: 6| Step: 5
Training loss: 1.8381519354825082
Validation loss: 2.720752592383323

Epoch: 6| Step: 6
Training loss: 0.8967542055242491
Validation loss: 2.8040989476983276

Epoch: 6| Step: 7
Training loss: 0.7173044761720141
Validation loss: 2.749929687294695

Epoch: 6| Step: 8
Training loss: 0.6058494109583213
Validation loss: 2.7633268934051363

Epoch: 6| Step: 9
Training loss: 1.2644392982082828
Validation loss: 2.793359731770993

Epoch: 6| Step: 10
Training loss: 0.7621252295850521
Validation loss: 2.861343053924187

Epoch: 6| Step: 11
Training loss: 0.9215175776303199
Validation loss: 2.8178559697666934

Epoch: 6| Step: 12
Training loss: 0.6745693387077487
Validation loss: 2.86046537861162

Epoch: 6| Step: 13
Training loss: 0.8862481906264414
Validation loss: 2.8277247586512537

Epoch: 154| Step: 0
Training loss: 0.7427261806945651
Validation loss: 2.8344075373163298

Epoch: 6| Step: 1
Training loss: 0.7652417995059605
Validation loss: 2.784883889769058

Epoch: 6| Step: 2
Training loss: 0.6712409731721493
Validation loss: 2.711001180144564

Epoch: 6| Step: 3
Training loss: 0.7576782264912901
Validation loss: 2.763355408646681

Epoch: 6| Step: 4
Training loss: 1.075158280541313
Validation loss: 2.8681861877453922

Epoch: 6| Step: 5
Training loss: 0.6158210984263439
Validation loss: 2.8311272381910912

Epoch: 6| Step: 6
Training loss: 0.8012631338771885
Validation loss: 2.7906480230767894

Epoch: 6| Step: 7
Training loss: 0.6798196642183318
Validation loss: 2.7724212217246404

Epoch: 6| Step: 8
Training loss: 0.8045834964835662
Validation loss: 2.804486153263561

Epoch: 6| Step: 9
Training loss: 1.1803913164272477
Validation loss: 2.8109724629637856

Epoch: 6| Step: 10
Training loss: 1.6855120075107055
Validation loss: 2.9543653840097552

Epoch: 6| Step: 11
Training loss: 1.2690527380948515
Validation loss: 2.9180874406744075

Epoch: 6| Step: 12
Training loss: 0.9242373441242925
Validation loss: 2.899605994479743

Epoch: 6| Step: 13
Training loss: 0.8703682790855853
Validation loss: 2.669590008269205

Epoch: 155| Step: 0
Training loss: 0.674994390958864
Validation loss: 2.7600507217736054

Epoch: 6| Step: 1
Training loss: 1.0374577111507473
Validation loss: 2.7559769585296334

Epoch: 6| Step: 2
Training loss: 0.8482383803480466
Validation loss: 2.8555194034423708

Epoch: 6| Step: 3
Training loss: 0.9596008681035378
Validation loss: 2.761096472374095

Epoch: 6| Step: 4
Training loss: 0.8538366626190838
Validation loss: 2.703819200462312

Epoch: 6| Step: 5
Training loss: 1.0284205837939167
Validation loss: 2.8594990965660623

Epoch: 6| Step: 6
Training loss: 0.9339332761231838
Validation loss: 2.841666523848574

Epoch: 6| Step: 7
Training loss: 0.8273728031464127
Validation loss: 2.8011716520016514

Epoch: 6| Step: 8
Training loss: 0.6883982079470958
Validation loss: 2.8885299926331154

Epoch: 6| Step: 9
Training loss: 0.681201257624336
Validation loss: 2.890471981912932

Epoch: 6| Step: 10
Training loss: 0.690306742943329
Validation loss: 2.893386635098923

Epoch: 6| Step: 11
Training loss: 0.6038788871932188
Validation loss: 2.8283376736702226

Epoch: 6| Step: 12
Training loss: 0.4943306598961876
Validation loss: 2.80263802144553

Epoch: 6| Step: 13
Training loss: 1.7777285651839392
Validation loss: 2.68538186046061

Epoch: 156| Step: 0
Training loss: 0.6862247951583004
Validation loss: 2.8197309716950674

Epoch: 6| Step: 1
Training loss: 1.2093342658385944
Validation loss: 2.5896260518616643

Epoch: 6| Step: 2
Training loss: 0.9229103998067593
Validation loss: 2.6207494381655914

Epoch: 6| Step: 3
Training loss: 0.6539275080462448
Validation loss: 2.7818143893452323

Epoch: 6| Step: 4
Training loss: 0.6077686068418086
Validation loss: 2.7487933661680217

Epoch: 6| Step: 5
Training loss: 0.8902930594799208
Validation loss: 2.7900475935938513

Epoch: 6| Step: 6
Training loss: 0.932178621879652
Validation loss: 2.935123293754836

Epoch: 6| Step: 7
Training loss: 0.8978536948111712
Validation loss: 2.872332551777296

Epoch: 6| Step: 8
Training loss: 0.8073043494099942
Validation loss: 2.8276069264946817

Epoch: 6| Step: 9
Training loss: 0.6426426353654091
Validation loss: 2.7914655717378705

Epoch: 6| Step: 10
Training loss: 0.516623339707803
Validation loss: 2.7663824046458454

Epoch: 6| Step: 11
Training loss: 1.0219322375211686
Validation loss: 2.679571521796075

Epoch: 6| Step: 12
Training loss: 1.8090129061734603
Validation loss: 2.679526618005755

Epoch: 6| Step: 13
Training loss: 0.9595112644804575
Validation loss: 2.756217271836844

Epoch: 157| Step: 0
Training loss: 0.7018003914260968
Validation loss: 2.7821981192719676

Epoch: 6| Step: 1
Training loss: 0.8630000903703061
Validation loss: 2.8901445144107356

Epoch: 6| Step: 2
Training loss: 0.5917665580814878
Validation loss: 2.8119047312038394

Epoch: 6| Step: 3
Training loss: 0.6241542338808223
Validation loss: 2.866408073235486

Epoch: 6| Step: 4
Training loss: 0.8264800955469321
Validation loss: 2.8512465628570216

Epoch: 6| Step: 5
Training loss: 0.6401113218482326
Validation loss: 2.851479529998347

Epoch: 6| Step: 6
Training loss: 0.9181498572072886
Validation loss: 2.804812301933474

Epoch: 6| Step: 7
Training loss: 1.0135947255082403
Validation loss: 2.8100167650014534

Epoch: 6| Step: 8
Training loss: 0.9250716052821489
Validation loss: 2.7153179532130705

Epoch: 6| Step: 9
Training loss: 0.7064226386808691
Validation loss: 2.8290935143595615

Epoch: 6| Step: 10
Training loss: 0.7798932310536242
Validation loss: 2.727222308140763

Epoch: 6| Step: 11
Training loss: 1.0898273972682495
Validation loss: 2.7798171049098297

Epoch: 6| Step: 12
Training loss: 0.5589862591533775
Validation loss: 2.768117223553426

Epoch: 6| Step: 13
Training loss: 1.784118551074373
Validation loss: 2.8957557439129333

Epoch: 158| Step: 0
Training loss: 0.5969480170281146
Validation loss: 2.8563419925447002

Epoch: 6| Step: 1
Training loss: 0.9034385480053265
Validation loss: 2.901953868255678

Epoch: 6| Step: 2
Training loss: 1.0860612098979032
Validation loss: 2.83771346489422

Epoch: 6| Step: 3
Training loss: 0.8985734256256077
Validation loss: 2.8825943475762643

Epoch: 6| Step: 4
Training loss: 0.5078667831751426
Validation loss: 2.8052922042356703

Epoch: 6| Step: 5
Training loss: 1.8085766785312354
Validation loss: 2.7694519634223407

Epoch: 6| Step: 6
Training loss: 0.5772598597963631
Validation loss: 2.7770702086069607

Epoch: 6| Step: 7
Training loss: 0.9548100444354861
Validation loss: 2.9477429198340004

Epoch: 6| Step: 8
Training loss: 0.7852526553357155
Validation loss: 2.8060184674941127

Epoch: 6| Step: 9
Training loss: 0.8881594008159696
Validation loss: 2.7665384224579634

Epoch: 6| Step: 10
Training loss: 0.8777661197695659
Validation loss: 2.83875012580158

Epoch: 6| Step: 11
Training loss: 0.6021802133496442
Validation loss: 2.7690422081872006

Epoch: 6| Step: 12
Training loss: 0.7972919271000368
Validation loss: 2.7775549828403236

Epoch: 6| Step: 13
Training loss: 0.9459948008396437
Validation loss: 2.8048456797361965

Epoch: 159| Step: 0
Training loss: 0.7153485709611971
Validation loss: 2.772506414302266

Epoch: 6| Step: 1
Training loss: 0.9795761604863172
Validation loss: 2.8696426842171436

Epoch: 6| Step: 2
Training loss: 0.814078704614126
Validation loss: 2.7619366233887424

Epoch: 6| Step: 3
Training loss: 0.5898451647204681
Validation loss: 2.80291824003557

Epoch: 6| Step: 4
Training loss: 1.8629369517585443
Validation loss: 2.854376699325872

Epoch: 6| Step: 5
Training loss: 0.962853328454514
Validation loss: 2.7562587060307884

Epoch: 6| Step: 6
Training loss: 0.5274756372620145
Validation loss: 2.8395299515122705

Epoch: 6| Step: 7
Training loss: 0.5163583741957087
Validation loss: 2.83764962461446

Epoch: 6| Step: 8
Training loss: 0.7602753878126798
Validation loss: 2.804848782321621

Epoch: 6| Step: 9
Training loss: 0.9966141781068085
Validation loss: 2.6844857781807296

Epoch: 6| Step: 10
Training loss: 0.7187486731475524
Validation loss: 2.824041168412614

Epoch: 6| Step: 11
Training loss: 0.7596517050880706
Validation loss: 2.8399829436851136

Epoch: 6| Step: 12
Training loss: 0.9462761499175444
Validation loss: 2.84330398080067

Epoch: 6| Step: 13
Training loss: 0.9129124114440705
Validation loss: 2.899252448797994

Epoch: 160| Step: 0
Training loss: 1.7075429188820463
Validation loss: 2.8217226485099007

Epoch: 6| Step: 1
Training loss: 0.6743080530885365
Validation loss: 2.8628099026678795

Epoch: 6| Step: 2
Training loss: 0.6543652854569978
Validation loss: 2.7845881427968995

Epoch: 6| Step: 3
Training loss: 0.4844374616404146
Validation loss: 2.795623883068698

Epoch: 6| Step: 4
Training loss: 0.7929631124963167
Validation loss: 2.752238966078483

Epoch: 6| Step: 5
Training loss: 0.9815466985004472
Validation loss: 2.801340683061211

Epoch: 6| Step: 6
Training loss: 0.9970180038196355
Validation loss: 2.7171896479873987

Epoch: 6| Step: 7
Training loss: 1.0974065965083304
Validation loss: 2.7584055406122037

Epoch: 6| Step: 8
Training loss: 1.061708828933768
Validation loss: 2.7538086064480716

Epoch: 6| Step: 9
Training loss: 0.9242983502429509
Validation loss: 2.7860571218879793

Epoch: 6| Step: 10
Training loss: 0.7619576495233877
Validation loss: 2.8041653372849766

Epoch: 6| Step: 11
Training loss: 0.8968472213962385
Validation loss: 2.8116429895226784

Epoch: 6| Step: 12
Training loss: 0.5907862882038619
Validation loss: 2.987689336525662

Epoch: 6| Step: 13
Training loss: 0.7588692601853498
Validation loss: 2.825412116471552

Epoch: 161| Step: 0
Training loss: 0.7640295337515898
Validation loss: 2.791147935888703

Epoch: 6| Step: 1
Training loss: 0.8189856561375825
Validation loss: 2.8845009481113637

Epoch: 6| Step: 2
Training loss: 1.0145911016042817
Validation loss: 2.7766861349417846

Epoch: 6| Step: 3
Training loss: 0.8281728262856168
Validation loss: 2.7370523478666167

Epoch: 6| Step: 4
Training loss: 0.5915464620537129
Validation loss: 2.8118818239501038

Epoch: 6| Step: 5
Training loss: 0.616140660844397
Validation loss: 2.654017344116518

Epoch: 6| Step: 6
Training loss: 0.6675713455632739
Validation loss: 2.786343557305336

Epoch: 6| Step: 7
Training loss: 0.7321948704204083
Validation loss: 2.776317780715128

Epoch: 6| Step: 8
Training loss: 1.747096036462555
Validation loss: 2.8083699738086576

Epoch: 6| Step: 9
Training loss: 0.49121770228435513
Validation loss: 2.7832882873712306

Epoch: 6| Step: 10
Training loss: 0.6881297435129261
Validation loss: 2.899496757207738

Epoch: 6| Step: 11
Training loss: 1.082472177725001
Validation loss: 2.798236962848258

Epoch: 6| Step: 12
Training loss: 0.9569548595847813
Validation loss: 2.849369993345594

Epoch: 6| Step: 13
Training loss: 0.7995244654311127
Validation loss: 2.8205246075081565

Epoch: 162| Step: 0
Training loss: 1.741749319217396
Validation loss: 2.7665240591898885

Epoch: 6| Step: 1
Training loss: 0.5786878835493696
Validation loss: 2.840327750286872

Epoch: 6| Step: 2
Training loss: 0.7241488738850042
Validation loss: 2.770191840197569

Epoch: 6| Step: 3
Training loss: 0.9256874391049535
Validation loss: 2.7977265352781977

Epoch: 6| Step: 4
Training loss: 0.7274464388266271
Validation loss: 2.812362766449899

Epoch: 6| Step: 5
Training loss: 0.678115693481151
Validation loss: 2.8178279284882315

Epoch: 6| Step: 6
Training loss: 0.8916148657918743
Validation loss: 2.8176862724037584

Epoch: 6| Step: 7
Training loss: 0.3835432512719226
Validation loss: 2.851500405110163

Epoch: 6| Step: 8
Training loss: 0.4929571794219037
Validation loss: 2.727523503189151

Epoch: 6| Step: 9
Training loss: 0.8883070983078336
Validation loss: 2.824601650003266

Epoch: 6| Step: 10
Training loss: 0.6316992775526893
Validation loss: 2.816285820801058

Epoch: 6| Step: 11
Training loss: 1.0101962029270368
Validation loss: 2.8111568210572857

Epoch: 6| Step: 12
Training loss: 0.9618461468727243
Validation loss: 2.8560166083430873

Epoch: 6| Step: 13
Training loss: 0.7566751813899613
Validation loss: 2.850036296278734

Epoch: 163| Step: 0
Training loss: 0.7419658932365958
Validation loss: 2.889526405864672

Epoch: 6| Step: 1
Training loss: 0.9222537410346884
Validation loss: 2.916843113784547

Epoch: 6| Step: 2
Training loss: 0.5164441047217495
Validation loss: 2.862410957361902

Epoch: 6| Step: 3
Training loss: 0.6183364892846495
Validation loss: 2.796636525079968

Epoch: 6| Step: 4
Training loss: 0.6359215174360715
Validation loss: 2.85574057033687

Epoch: 6| Step: 5
Training loss: 0.9771905329175044
Validation loss: 2.8166479817359447

Epoch: 6| Step: 6
Training loss: 1.697466909678756
Validation loss: 2.68181898279183

Epoch: 6| Step: 7
Training loss: 0.6454493139771742
Validation loss: 2.7931191286093755

Epoch: 6| Step: 8
Training loss: 0.8175677565396985
Validation loss: 2.7684155051866233

Epoch: 6| Step: 9
Training loss: 0.7842879927202809
Validation loss: 2.727817133792026

Epoch: 6| Step: 10
Training loss: 0.6217495556926789
Validation loss: 2.825223667438939

Epoch: 6| Step: 11
Training loss: 0.7984761253017209
Validation loss: 2.8684541431973027

Epoch: 6| Step: 12
Training loss: 0.4302534018209719
Validation loss: 2.9077694110250336

Epoch: 6| Step: 13
Training loss: 0.7717252717376857
Validation loss: 2.8948751872449283

Epoch: 164| Step: 0
Training loss: 0.7531212391106498
Validation loss: 2.8348512557140846

Epoch: 6| Step: 1
Training loss: 0.7704589596189948
Validation loss: 2.921305854294954

Epoch: 6| Step: 2
Training loss: 1.7173020939863457
Validation loss: 2.9043899517797724

Epoch: 6| Step: 3
Training loss: 0.5293000280983112
Validation loss: 2.8190932663275863

Epoch: 6| Step: 4
Training loss: 0.6321471920164985
Validation loss: 2.8063764100465067

Epoch: 6| Step: 5
Training loss: 0.5308505407725311
Validation loss: 2.8095254073511775

Epoch: 6| Step: 6
Training loss: 0.7375310891274377
Validation loss: 2.72166462029378

Epoch: 6| Step: 7
Training loss: 0.9420104877450989
Validation loss: 2.864461096265213

Epoch: 6| Step: 8
Training loss: 0.657834139216551
Validation loss: 2.741030587575063

Epoch: 6| Step: 9
Training loss: 0.6333596019149229
Validation loss: 2.8082792471215607

Epoch: 6| Step: 10
Training loss: 0.6847417293019852
Validation loss: 2.808318314290471

Epoch: 6| Step: 11
Training loss: 0.5575520332071519
Validation loss: 2.759858882378576

Epoch: 6| Step: 12
Training loss: 0.7354523081873515
Validation loss: 2.790679648029094

Epoch: 6| Step: 13
Training loss: 1.0039741700941855
Validation loss: 2.8923791734961606

Epoch: 165| Step: 0
Training loss: 0.8249900427130706
Validation loss: 2.7599815073637703

Epoch: 6| Step: 1
Training loss: 0.9637257511833734
Validation loss: 2.9117003711597707

Epoch: 6| Step: 2
Training loss: 0.6236091157668414
Validation loss: 2.839260917788359

Epoch: 6| Step: 3
Training loss: 0.4611752915033691
Validation loss: 2.8502525630382083

Epoch: 6| Step: 4
Training loss: 0.8583058729377716
Validation loss: 2.8189269349362487

Epoch: 6| Step: 5
Training loss: 1.744769658951009
Validation loss: 2.8962529562214887

Epoch: 6| Step: 6
Training loss: 0.6387104874350876
Validation loss: 2.782705304870839

Epoch: 6| Step: 7
Training loss: 0.7565351910017134
Validation loss: 2.797787679017255

Epoch: 6| Step: 8
Training loss: 0.5682319419599592
Validation loss: 2.7779581255117507

Epoch: 6| Step: 9
Training loss: 0.576761855315686
Validation loss: 2.8421775746395035

Epoch: 6| Step: 10
Training loss: 0.6193986228803157
Validation loss: 2.7847720501364033

Epoch: 6| Step: 11
Training loss: 0.7458023380964093
Validation loss: 2.710056143339823

Epoch: 6| Step: 12
Training loss: 0.8287789983264637
Validation loss: 2.7762024327737067

Epoch: 6| Step: 13
Training loss: 0.7255414125071135
Validation loss: 2.808127586079979

Epoch: 166| Step: 0
Training loss: 0.7624123569836069
Validation loss: 2.829617129510554

Epoch: 6| Step: 1
Training loss: 0.6972061473792638
Validation loss: 2.7715264698691264

Epoch: 6| Step: 2
Training loss: 0.7190251860206421
Validation loss: 2.8937231009038493

Epoch: 6| Step: 3
Training loss: 0.9149159416818727
Validation loss: 2.8343234622844298

Epoch: 6| Step: 4
Training loss: 1.8512760375340644
Validation loss: 2.8805607493308893

Epoch: 6| Step: 5
Training loss: 1.0147935838758892
Validation loss: 2.8792227403302535

Epoch: 6| Step: 6
Training loss: 0.877877544683467
Validation loss: 2.880412866505381

Epoch: 6| Step: 7
Training loss: 0.5703176994609278
Validation loss: 2.914056827379421

Epoch: 6| Step: 8
Training loss: 0.5080025830672517
Validation loss: 2.844156732222379

Epoch: 6| Step: 9
Training loss: 0.7038188689566753
Validation loss: 2.602900713615286

Epoch: 6| Step: 10
Training loss: 0.8470351936883252
Validation loss: 2.7229593802392467

Epoch: 6| Step: 11
Training loss: 0.7332996855588015
Validation loss: 2.6767056170234853

Epoch: 6| Step: 12
Training loss: 0.9826030829518111
Validation loss: 2.8062087160060076

Epoch: 6| Step: 13
Training loss: 0.7238395282405021
Validation loss: 2.779808799723064

Epoch: 167| Step: 0
Training loss: 0.7375797794316618
Validation loss: 2.855472006319749

Epoch: 6| Step: 1
Training loss: 0.946811527856802
Validation loss: 2.915716211678301

Epoch: 6| Step: 2
Training loss: 0.8457179255434825
Validation loss: 2.91126401158356

Epoch: 6| Step: 3
Training loss: 0.877240887774771
Validation loss: 3.0056224033077172

Epoch: 6| Step: 4
Training loss: 1.569094664869452
Validation loss: 2.889655546914659

Epoch: 6| Step: 5
Training loss: 0.5992969606131188
Validation loss: 2.899802805784193

Epoch: 6| Step: 6
Training loss: 0.8386549942172654
Validation loss: 2.84287286163251

Epoch: 6| Step: 7
Training loss: 0.6206270059589648
Validation loss: 2.745781712102282

Epoch: 6| Step: 8
Training loss: 0.5535716263379565
Validation loss: 2.814434728268907

Epoch: 6| Step: 9
Training loss: 0.6515487577969692
Validation loss: 2.820167199616113

Epoch: 6| Step: 10
Training loss: 0.9444402027658193
Validation loss: 2.8281994242561526

Epoch: 6| Step: 11
Training loss: 0.9286438028196058
Validation loss: 2.7511021110676412

Epoch: 6| Step: 12
Training loss: 0.7144883736851753
Validation loss: 2.8386334092366177

Epoch: 6| Step: 13
Training loss: 0.5014709650574236
Validation loss: 2.8072873164457586

Epoch: 168| Step: 0
Training loss: 0.7786169312555549
Validation loss: 2.7383416459864236

Epoch: 6| Step: 1
Training loss: 0.6560826769460137
Validation loss: 2.7714857657466925

Epoch: 6| Step: 2
Training loss: 0.8983548665400074
Validation loss: 2.8214067923318615

Epoch: 6| Step: 3
Training loss: 0.464901864402103
Validation loss: 2.8007567620548057

Epoch: 6| Step: 4
Training loss: 0.7817281023038312
Validation loss: 2.7435036278527978

Epoch: 6| Step: 5
Training loss: 0.7146363921712877
Validation loss: 2.7830944160513145

Epoch: 6| Step: 6
Training loss: 0.8828098668422083
Validation loss: 2.8403836541208736

Epoch: 6| Step: 7
Training loss: 0.656134527128895
Validation loss: 2.807440976127929

Epoch: 6| Step: 8
Training loss: 0.7717387492277625
Validation loss: 2.8206988181906443

Epoch: 6| Step: 9
Training loss: 0.7004407082909088
Validation loss: 2.8459033149466433

Epoch: 6| Step: 10
Training loss: 0.6494225064065708
Validation loss: 2.8880838170018746

Epoch: 6| Step: 11
Training loss: 0.7812394713646015
Validation loss: 2.785668025139205

Epoch: 6| Step: 12
Training loss: 0.6105945805261321
Validation loss: 2.7939096426528534

Epoch: 6| Step: 13
Training loss: 1.8372708936835453
Validation loss: 2.8289216607309746

Epoch: 169| Step: 0
Training loss: 0.7295488899796115
Validation loss: 2.752177835517317

Epoch: 6| Step: 1
Training loss: 1.0157718845669759
Validation loss: 2.8603686359000586

Epoch: 6| Step: 2
Training loss: 0.4894745245880713
Validation loss: 2.7588389128285566

Epoch: 6| Step: 3
Training loss: 0.5834974217100475
Validation loss: 2.8454411965818873

Epoch: 6| Step: 4
Training loss: 0.3932759170867817
Validation loss: 2.793483972933501

Epoch: 6| Step: 5
Training loss: 0.8953426296097572
Validation loss: 2.802281019382349

Epoch: 6| Step: 6
Training loss: 0.5004971535989496
Validation loss: 2.794312807723617

Epoch: 6| Step: 7
Training loss: 0.9139992781725982
Validation loss: 2.973898762887412

Epoch: 6| Step: 8
Training loss: 0.7866347327728197
Validation loss: 2.9014235176157253

Epoch: 6| Step: 9
Training loss: 0.6713193991462557
Validation loss: 2.821462747138079

Epoch: 6| Step: 10
Training loss: 0.6365861813199832
Validation loss: 2.782119829266889

Epoch: 6| Step: 11
Training loss: 1.7932114114878601
Validation loss: 2.8232522227793875

Epoch: 6| Step: 12
Training loss: 0.7724323098608419
Validation loss: 2.8371265955510956

Epoch: 6| Step: 13
Training loss: 0.6064298323714941
Validation loss: 2.7895869056806037

Epoch: 170| Step: 0
Training loss: 0.4710286071678907
Validation loss: 2.8538324248543723

Epoch: 6| Step: 1
Training loss: 0.8166028018879056
Validation loss: 2.856358171747734

Epoch: 6| Step: 2
Training loss: 0.6866374239975539
Validation loss: 2.871180291288022

Epoch: 6| Step: 3
Training loss: 0.8883012271134424
Validation loss: 2.8905667273344045

Epoch: 6| Step: 4
Training loss: 0.5969031082645011
Validation loss: 2.886914815683888

Epoch: 6| Step: 5
Training loss: 1.6084412764198643
Validation loss: 2.903157479084323

Epoch: 6| Step: 6
Training loss: 0.552160821431029
Validation loss: 2.933078766382636

Epoch: 6| Step: 7
Training loss: 0.6403328997228102
Validation loss: 2.9366084024045285

Epoch: 6| Step: 8
Training loss: 0.8131958842479694
Validation loss: 2.8858509677925017

Epoch: 6| Step: 9
Training loss: 0.8648923107321892
Validation loss: 2.7466851832481716

Epoch: 6| Step: 10
Training loss: 0.936192618166273
Validation loss: 2.7987243320752717

Epoch: 6| Step: 11
Training loss: 0.6937443269033707
Validation loss: 2.7602654229722448

Epoch: 6| Step: 12
Training loss: 0.8002800093806584
Validation loss: 2.813960875703034

Epoch: 6| Step: 13
Training loss: 0.9580508347863174
Validation loss: 2.720417607449882

Epoch: 171| Step: 0
Training loss: 0.6917455670346027
Validation loss: 2.734838217600181

Epoch: 6| Step: 1
Training loss: 0.6658045414662306
Validation loss: 2.754189276975159

Epoch: 6| Step: 2
Training loss: 0.6991384023182827
Validation loss: 2.838435947421008

Epoch: 6| Step: 3
Training loss: 0.7265532298163231
Validation loss: 2.931215977691605

Epoch: 6| Step: 4
Training loss: 1.2305570056084862
Validation loss: 2.9643812191537573

Epoch: 6| Step: 5
Training loss: 0.7181902654752436
Validation loss: 2.9372002874835306

Epoch: 6| Step: 6
Training loss: 0.6795402893601961
Validation loss: 2.9224239384499624

Epoch: 6| Step: 7
Training loss: 0.5242565351760137
Validation loss: 2.7456813772138666

Epoch: 6| Step: 8
Training loss: 0.8641915333651602
Validation loss: 2.73238787426539

Epoch: 6| Step: 9
Training loss: 0.6450171517523885
Validation loss: 2.726737001331134

Epoch: 6| Step: 10
Training loss: 1.6749374292557908
Validation loss: 2.7462891481572838

Epoch: 6| Step: 11
Training loss: 0.7160042270183992
Validation loss: 2.6863443418243245

Epoch: 6| Step: 12
Training loss: 0.6874270617201256
Validation loss: 2.8081583844901816

Epoch: 6| Step: 13
Training loss: 0.7889398158414997
Validation loss: 2.829538178431652

Epoch: 172| Step: 0
Training loss: 0.5750215847690965
Validation loss: 2.7604967117699943

Epoch: 6| Step: 1
Training loss: 0.6339758552171538
Validation loss: 2.837139677004696

Epoch: 6| Step: 2
Training loss: 1.6753870360322
Validation loss: 2.858349405990506

Epoch: 6| Step: 3
Training loss: 0.7572722721546025
Validation loss: 2.8937887113658176

Epoch: 6| Step: 4
Training loss: 0.6177518654505292
Validation loss: 2.8090321389253385

Epoch: 6| Step: 5
Training loss: 0.6014715596607746
Validation loss: 2.819601996226494

Epoch: 6| Step: 6
Training loss: 0.5736288037418181
Validation loss: 2.7237275550387845

Epoch: 6| Step: 7
Training loss: 0.9039779331332811
Validation loss: 2.7384911500709896

Epoch: 6| Step: 8
Training loss: 0.7756582418076317
Validation loss: 2.8596952846119477

Epoch: 6| Step: 9
Training loss: 0.573718313534802
Validation loss: 2.7088923586486855

Epoch: 6| Step: 10
Training loss: 0.3671362415004467
Validation loss: 2.7878770775626394

Epoch: 6| Step: 11
Training loss: 0.8717569127663412
Validation loss: 2.893661285919043

Epoch: 6| Step: 12
Training loss: 0.9777105068657059
Validation loss: 2.86194011926553

Epoch: 6| Step: 13
Training loss: 0.44675631447584513
Validation loss: 2.6967272155512143

Epoch: 173| Step: 0
Training loss: 0.9533380051533951
Validation loss: 2.815714207462808

Epoch: 6| Step: 1
Training loss: 0.5954959696802284
Validation loss: 2.7572218683043452

Epoch: 6| Step: 2
Training loss: 0.7231757693655962
Validation loss: 2.8171229197991288

Epoch: 6| Step: 3
Training loss: 0.6882032785405735
Validation loss: 2.8966856783852792

Epoch: 6| Step: 4
Training loss: 0.7336139387738827
Validation loss: 2.822046861452778

Epoch: 6| Step: 5
Training loss: 0.46809761425633556
Validation loss: 2.7473000363587174

Epoch: 6| Step: 6
Training loss: 0.8314704975438562
Validation loss: 2.7886635773754342

Epoch: 6| Step: 7
Training loss: 0.6158583368285141
Validation loss: 2.7034321575547815

Epoch: 6| Step: 8
Training loss: 0.8253879299742665
Validation loss: 2.7985587140130184

Epoch: 6| Step: 9
Training loss: 0.6703946416716968
Validation loss: 2.785642320218046

Epoch: 6| Step: 10
Training loss: 1.5667394725980923
Validation loss: 2.8397948319018664

Epoch: 6| Step: 11
Training loss: 0.6920573299452208
Validation loss: 2.8319538254951713

Epoch: 6| Step: 12
Training loss: 0.6247311967734971
Validation loss: 2.761514198393349

Epoch: 6| Step: 13
Training loss: 0.936666945042235
Validation loss: 2.855083956277341

Epoch: 174| Step: 0
Training loss: 0.5842773060047074
Validation loss: 2.7890587173564487

Epoch: 6| Step: 1
Training loss: 0.7080984754720782
Validation loss: 2.822802289121295

Epoch: 6| Step: 2
Training loss: 1.0125813581016108
Validation loss: 2.8864074181249215

Epoch: 6| Step: 3
Training loss: 0.7268405505321144
Validation loss: 2.8455627378850332

Epoch: 6| Step: 4
Training loss: 0.61978657236864
Validation loss: 2.7397450204766804

Epoch: 6| Step: 5
Training loss: 0.5493114149078787
Validation loss: 2.8161915041620342

Epoch: 6| Step: 6
Training loss: 0.7475452783197299
Validation loss: 2.76265926793788

Epoch: 6| Step: 7
Training loss: 1.6987212055564485
Validation loss: 2.7967900524345497

Epoch: 6| Step: 8
Training loss: 0.46610948396035495
Validation loss: 2.7624191985820437

Epoch: 6| Step: 9
Training loss: 0.4164296986345675
Validation loss: 2.8304865410547713

Epoch: 6| Step: 10
Training loss: 0.6049021869595296
Validation loss: 2.891500776811135

Epoch: 6| Step: 11
Training loss: 0.6213715609737517
Validation loss: 2.8625672800300377

Epoch: 6| Step: 12
Training loss: 0.5706666082231026
Validation loss: 2.9096410376351276

Epoch: 6| Step: 13
Training loss: 0.6367759912890268
Validation loss: 2.860006460702708

Epoch: 175| Step: 0
Training loss: 0.6918949619849135
Validation loss: 2.956135569233512

Epoch: 6| Step: 1
Training loss: 1.6895567051881943
Validation loss: 2.8635080481024753

Epoch: 6| Step: 2
Training loss: 0.8949412110269914
Validation loss: 2.953364636690882

Epoch: 6| Step: 3
Training loss: 0.6070905069814485
Validation loss: 2.813597585062866

Epoch: 6| Step: 4
Training loss: 0.6365486807205664
Validation loss: 2.8332164871207177

Epoch: 6| Step: 5
Training loss: 0.7821627053854734
Validation loss: 2.820906205881828

Epoch: 6| Step: 6
Training loss: 0.8162720127262868
Validation loss: 2.917103671078528

Epoch: 6| Step: 7
Training loss: 0.5896952865401863
Validation loss: 2.8807430127453153

Epoch: 6| Step: 8
Training loss: 0.7291003378718075
Validation loss: 2.7773282121741443

Epoch: 6| Step: 9
Training loss: 0.8014409395066892
Validation loss: 2.7913828653344877

Epoch: 6| Step: 10
Training loss: 0.7716276011729802
Validation loss: 2.815744887610541

Epoch: 6| Step: 11
Training loss: 0.3732121286310319
Validation loss: 2.859317160544266

Epoch: 6| Step: 12
Training loss: 0.7038137241736009
Validation loss: 2.8238277912161682

Epoch: 6| Step: 13
Training loss: 0.6315704212324291
Validation loss: 2.749991835957749

Epoch: 176| Step: 0
Training loss: 0.660757547144198
Validation loss: 2.751786821916279

Epoch: 6| Step: 1
Training loss: 0.8125353585398998
Validation loss: 2.833691340623061

Epoch: 6| Step: 2
Training loss: 0.7006922492047609
Validation loss: 2.849740994267831

Epoch: 6| Step: 3
Training loss: 0.552620596346322
Validation loss: 2.839360261991243

Epoch: 6| Step: 4
Training loss: 0.5651111397261734
Validation loss: 2.898765785291647

Epoch: 6| Step: 5
Training loss: 0.9109500812165532
Validation loss: 2.8155621565714894

Epoch: 6| Step: 6
Training loss: 0.7236786080102482
Validation loss: 2.853792936447926

Epoch: 6| Step: 7
Training loss: 0.6434229482938567
Validation loss: 2.92128172374471

Epoch: 6| Step: 8
Training loss: 0.6209140013657739
Validation loss: 2.83167684507945

Epoch: 6| Step: 9
Training loss: 0.6415329987979986
Validation loss: 2.877927050305071

Epoch: 6| Step: 10
Training loss: 0.7247529825792001
Validation loss: 2.821500927593433

Epoch: 6| Step: 11
Training loss: 0.6014831540181672
Validation loss: 2.7955013005974525

Epoch: 6| Step: 12
Training loss: 1.7305506564146322
Validation loss: 2.709671179141151

Epoch: 6| Step: 13
Training loss: 0.5687431796157524
Validation loss: 2.7851157022728508

Epoch: 177| Step: 0
Training loss: 0.7202975985295159
Validation loss: 2.699163926741397

Epoch: 6| Step: 1
Training loss: 0.470587118582242
Validation loss: 2.807934453315137

Epoch: 6| Step: 2
Training loss: 1.6466002870351633
Validation loss: 2.9105590814595512

Epoch: 6| Step: 3
Training loss: 0.9158670268283772
Validation loss: 2.9257333749029693

Epoch: 6| Step: 4
Training loss: 0.7863119549138043
Validation loss: 2.9332818933513765

Epoch: 6| Step: 5
Training loss: 0.9685559847577456
Validation loss: 2.81474289647698

Epoch: 6| Step: 6
Training loss: 0.6506672863589265
Validation loss: 2.7953810155868313

Epoch: 6| Step: 7
Training loss: 0.9518885487664857
Validation loss: 2.782849384158382

Epoch: 6| Step: 8
Training loss: 0.7473554478454993
Validation loss: 2.8227669135392666

Epoch: 6| Step: 9
Training loss: 0.696902632058579
Validation loss: 2.780957553075496

Epoch: 6| Step: 10
Training loss: 0.7853915872456966
Validation loss: 2.737067504579981

Epoch: 6| Step: 11
Training loss: 0.7812776179200435
Validation loss: 2.7777486900290107

Epoch: 6| Step: 12
Training loss: 0.577560768067878
Validation loss: 2.8234524001499075

Epoch: 6| Step: 13
Training loss: 0.6664893291961335
Validation loss: 2.8147010526362237

Epoch: 178| Step: 0
Training loss: 0.6733841912573678
Validation loss: 2.9187985303875346

Epoch: 6| Step: 1
Training loss: 0.7022405571918902
Validation loss: 2.8958954953078613

Epoch: 6| Step: 2
Training loss: 0.9357420652003677
Validation loss: 2.7764861351650274

Epoch: 6| Step: 3
Training loss: 0.5800619925879097
Validation loss: 2.836657500142021

Epoch: 6| Step: 4
Training loss: 0.42758933965862833
Validation loss: 2.866316036656464

Epoch: 6| Step: 5
Training loss: 0.5668178772666532
Validation loss: 2.8180292526136457

Epoch: 6| Step: 6
Training loss: 0.6782214258785636
Validation loss: 2.8337737797615916

Epoch: 6| Step: 7
Training loss: 0.6150856928321654
Validation loss: 2.8137889875289352

Epoch: 6| Step: 8
Training loss: 1.6503115302099098
Validation loss: 2.801126697328286

Epoch: 6| Step: 9
Training loss: 0.6686232633912246
Validation loss: 2.8669616859757907

Epoch: 6| Step: 10
Training loss: 0.5474459800895248
Validation loss: 2.8544723504832663

Epoch: 6| Step: 11
Training loss: 0.6220005541243953
Validation loss: 2.8810732728678783

Epoch: 6| Step: 12
Training loss: 0.5446235633220027
Validation loss: 2.8051742513866587

Epoch: 6| Step: 13
Training loss: 0.6755226169544007
Validation loss: 2.693863159304712

Epoch: 179| Step: 0
Training loss: 0.827276010594917
Validation loss: 2.7569153274634197

Epoch: 6| Step: 1
Training loss: 0.7201399424770115
Validation loss: 2.837242015588403

Epoch: 6| Step: 2
Training loss: 0.836139405012261
Validation loss: 2.7265597746943833

Epoch: 6| Step: 3
Training loss: 0.4923594794973442
Validation loss: 2.7980560991354513

Epoch: 6| Step: 4
Training loss: 0.4609395204920047
Validation loss: 2.8448346483374793

Epoch: 6| Step: 5
Training loss: 0.6252860606722133
Validation loss: 2.90476645611504

Epoch: 6| Step: 6
Training loss: 0.8165470713673559
Validation loss: 2.805717073854358

Epoch: 6| Step: 7
Training loss: 0.4159394673588266
Validation loss: 2.7928728562901286

Epoch: 6| Step: 8
Training loss: 0.6451452163118635
Validation loss: 2.8236898135339548

Epoch: 6| Step: 9
Training loss: 0.638045864522467
Validation loss: 2.768739860751472

Epoch: 6| Step: 10
Training loss: 0.5871435342015091
Validation loss: 2.756947180818427

Epoch: 6| Step: 11
Training loss: 0.7553689632373397
Validation loss: 2.8623030076965033

Epoch: 6| Step: 12
Training loss: 0.4248091949574532
Validation loss: 2.905311651753228

Epoch: 6| Step: 13
Training loss: 1.6380352106560094
Validation loss: 2.9368727941045427

Epoch: 180| Step: 0
Training loss: 0.5720055415511961
Validation loss: 2.8908877828936728

Epoch: 6| Step: 1
Training loss: 0.8178736444689703
Validation loss: 2.9523098340273095

Epoch: 6| Step: 2
Training loss: 0.7764699040246693
Validation loss: 2.8910164507874305

Epoch: 6| Step: 3
Training loss: 1.530350635093133
Validation loss: 2.8617919754211734

Epoch: 6| Step: 4
Training loss: 0.7556523475715006
Validation loss: 2.7271837257302893

Epoch: 6| Step: 5
Training loss: 0.6838757832333893
Validation loss: 2.748507253496521

Epoch: 6| Step: 6
Training loss: 0.6513743936348836
Validation loss: 2.7711300846367353

Epoch: 6| Step: 7
Training loss: 0.5033890783417193
Validation loss: 2.7232380577854434

Epoch: 6| Step: 8
Training loss: 0.6856732374277326
Validation loss: 2.8174935551061653

Epoch: 6| Step: 9
Training loss: 0.6692595474736338
Validation loss: 2.6678403764840963

Epoch: 6| Step: 10
Training loss: 0.8264987740712383
Validation loss: 2.8800935820104345

Epoch: 6| Step: 11
Training loss: 0.6959147470400794
Validation loss: 2.900448905795973

Epoch: 6| Step: 12
Training loss: 0.5362800159812482
Validation loss: 2.9359050505995015

Epoch: 6| Step: 13
Training loss: 0.49971578387955257
Validation loss: 2.735302533463109

Epoch: 181| Step: 0
Training loss: 0.5059606973514883
Validation loss: 2.824242809398946

Epoch: 6| Step: 1
Training loss: 0.5496028983812937
Validation loss: 2.8244358962398457

Epoch: 6| Step: 2
Training loss: 0.6749973932851685
Validation loss: 2.803879177741907

Epoch: 6| Step: 3
Training loss: 0.812198179379536
Validation loss: 2.8512486533329455

Epoch: 6| Step: 4
Training loss: 1.5493267165982179
Validation loss: 2.866402098364261

Epoch: 6| Step: 5
Training loss: 0.5379550726240734
Validation loss: 2.825238238616308

Epoch: 6| Step: 6
Training loss: 0.7415869039513934
Validation loss: 2.8655060594031263

Epoch: 6| Step: 7
Training loss: 0.620750860415664
Validation loss: 2.866303448806042

Epoch: 6| Step: 8
Training loss: 0.8210811828174213
Validation loss: 2.8455357656180067

Epoch: 6| Step: 9
Training loss: 0.7692331811518637
Validation loss: 2.86925560201712

Epoch: 6| Step: 10
Training loss: 0.6478531513993908
Validation loss: 2.9292558479208384

Epoch: 6| Step: 11
Training loss: 0.6333775764203639
Validation loss: 2.851439841780844

Epoch: 6| Step: 12
Training loss: 0.4769538929376192
Validation loss: 2.770064488680502

Epoch: 6| Step: 13
Training loss: 0.6795380307418659
Validation loss: 2.8376095609197156

Epoch: 182| Step: 0
Training loss: 0.9909253239793361
Validation loss: 2.8516187827770003

Epoch: 6| Step: 1
Training loss: 0.7487392955900072
Validation loss: 2.7834435574374385

Epoch: 6| Step: 2
Training loss: 0.7328049941990095
Validation loss: 2.738900833305878

Epoch: 6| Step: 3
Training loss: 0.6446596653486444
Validation loss: 2.7269165625309357

Epoch: 6| Step: 4
Training loss: 0.6547623985255638
Validation loss: 2.796253284423427

Epoch: 6| Step: 5
Training loss: 0.7218955082477925
Validation loss: 2.8737901270386343

Epoch: 6| Step: 6
Training loss: 0.916104212790152
Validation loss: 2.9437012654216743

Epoch: 6| Step: 7
Training loss: 0.7077695669328056
Validation loss: 3.021920585091254

Epoch: 6| Step: 8
Training loss: 0.5924356871519937
Validation loss: 2.892457370954972

Epoch: 6| Step: 9
Training loss: 0.6895701711575968
Validation loss: 2.7781617238349785

Epoch: 6| Step: 10
Training loss: 1.647193837292052
Validation loss: 2.7867008614685593

Epoch: 6| Step: 11
Training loss: 0.6029356110642973
Validation loss: 2.765321431139264

Epoch: 6| Step: 12
Training loss: 0.8279953621213824
Validation loss: 2.760929079300208

Epoch: 6| Step: 13
Training loss: 0.6435772627024285
Validation loss: 2.7185516577387054

Epoch: 183| Step: 0
Training loss: 0.5019823948976099
Validation loss: 2.7988364305392945

Epoch: 6| Step: 1
Training loss: 0.6607737164666653
Validation loss: 2.8075831774434663

Epoch: 6| Step: 2
Training loss: 1.5573524369680416
Validation loss: 2.8594185803259062

Epoch: 6| Step: 3
Training loss: 0.5799446080739666
Validation loss: 2.7972776808592332

Epoch: 6| Step: 4
Training loss: 0.7421877007735131
Validation loss: 2.863368971080697

Epoch: 6| Step: 5
Training loss: 0.7142575054048081
Validation loss: 2.7594611811473255

Epoch: 6| Step: 6
Training loss: 0.5551113604609595
Validation loss: 2.8608488443118785

Epoch: 6| Step: 7
Training loss: 0.5425717116568017
Validation loss: 2.819835097607081

Epoch: 6| Step: 8
Training loss: 0.7199454110697207
Validation loss: 2.728028232275488

Epoch: 6| Step: 9
Training loss: 0.7319444651747461
Validation loss: 2.7837748407683858

Epoch: 6| Step: 10
Training loss: 0.744494016342763
Validation loss: 2.6886219226003067

Epoch: 6| Step: 11
Training loss: 0.8895133593254556
Validation loss: 2.8209561558349514

Epoch: 6| Step: 12
Training loss: 0.49088220232679347
Validation loss: 2.918266570567376

Epoch: 6| Step: 13
Training loss: 0.6508880637484078
Validation loss: 2.866965331184744

Epoch: 184| Step: 0
Training loss: 0.7680989990303342
Validation loss: 2.9366860851579655

Epoch: 6| Step: 1
Training loss: 0.56680475882812
Validation loss: 2.7988887619687204

Epoch: 6| Step: 2
Training loss: 0.441147179659696
Validation loss: 2.835787065927995

Epoch: 6| Step: 3
Training loss: 0.41009909822010904
Validation loss: 2.901475368294626

Epoch: 6| Step: 4
Training loss: 1.5420756785503313
Validation loss: 2.866134990875201

Epoch: 6| Step: 5
Training loss: 0.7521426667948218
Validation loss: 2.860754142537099

Epoch: 6| Step: 6
Training loss: 0.6060608460595638
Validation loss: 2.837481384104245

Epoch: 6| Step: 7
Training loss: 0.4185156586394048
Validation loss: 2.809607098828843

Epoch: 6| Step: 8
Training loss: 0.6776357793409777
Validation loss: 2.751481654091283

Epoch: 6| Step: 9
Training loss: 0.7457938265504305
Validation loss: 2.869554337913134

Epoch: 6| Step: 10
Training loss: 0.5650865373337318
Validation loss: 2.9070445311168704

Epoch: 6| Step: 11
Training loss: 0.8431286113144186
Validation loss: 2.9020900692465648

Epoch: 6| Step: 12
Training loss: 0.5632490892263229
Validation loss: 2.8682915193065277

Epoch: 6| Step: 13
Training loss: 0.5056254313576725
Validation loss: 2.852987008519928

Epoch: 185| Step: 0
Training loss: 0.5678372951168195
Validation loss: 2.8723173479486315

Epoch: 6| Step: 1
Training loss: 0.44571600585298166
Validation loss: 2.899085713552276

Epoch: 6| Step: 2
Training loss: 0.5564385833815383
Validation loss: 2.7595053602036277

Epoch: 6| Step: 3
Training loss: 0.6772735744145758
Validation loss: 2.8278564690951455

Epoch: 6| Step: 4
Training loss: 0.5428052697279397
Validation loss: 2.734402073317423

Epoch: 6| Step: 5
Training loss: 0.5471375788688755
Validation loss: 2.7072668372132727

Epoch: 6| Step: 6
Training loss: 0.5536114638657549
Validation loss: 2.809830182533874

Epoch: 6| Step: 7
Training loss: 0.664200936641452
Validation loss: 2.8351980739384244

Epoch: 6| Step: 8
Training loss: 1.7140197859860629
Validation loss: 2.7600361591771607

Epoch: 6| Step: 9
Training loss: 0.6041235716566284
Validation loss: 2.7411775676425267

Epoch: 6| Step: 10
Training loss: 0.4661853727339981
Validation loss: 2.802130423413685

Epoch: 6| Step: 11
Training loss: 0.5023173039002413
Validation loss: 2.7482944603833697

Epoch: 6| Step: 12
Training loss: 0.5123529944439478
Validation loss: 2.826672695718789

Epoch: 6| Step: 13
Training loss: 0.6987362907375047
Validation loss: 2.788046145002082

Epoch: 186| Step: 0
Training loss: 0.396615180626476
Validation loss: 2.793438759406008

Epoch: 6| Step: 1
Training loss: 0.5272241527431362
Validation loss: 2.8685537854301426

Epoch: 6| Step: 2
Training loss: 0.44928608265336856
Validation loss: 2.6775970906078363

Epoch: 6| Step: 3
Training loss: 0.6291929740542588
Validation loss: 2.848234657742046

Epoch: 6| Step: 4
Training loss: 0.6291744063282384
Validation loss: 2.773812396720242

Epoch: 6| Step: 5
Training loss: 0.6566171527323198
Validation loss: 2.869696826140769

Epoch: 6| Step: 6
Training loss: 0.5315835130273316
Validation loss: 2.800788428928285

Epoch: 6| Step: 7
Training loss: 0.5650260156364018
Validation loss: 2.823182200275381

Epoch: 6| Step: 8
Training loss: 0.6254657202291569
Validation loss: 2.8107615007423483

Epoch: 6| Step: 9
Training loss: 0.5569868115519414
Validation loss: 2.7678974822543

Epoch: 6| Step: 10
Training loss: 1.7077445279316998
Validation loss: 2.86315705366997

Epoch: 6| Step: 11
Training loss: 0.5585139290926221
Validation loss: 2.780578889493777

Epoch: 6| Step: 12
Training loss: 0.47993048313524067
Validation loss: 2.7313080363214417

Epoch: 6| Step: 13
Training loss: 0.5729255126501397
Validation loss: 2.8092122818298635

Epoch: 187| Step: 0
Training loss: 0.5992819920555303
Validation loss: 2.793965422811159

Epoch: 6| Step: 1
Training loss: 0.670041665802878
Validation loss: 2.793268588673064

Epoch: 6| Step: 2
Training loss: 0.7102278636583124
Validation loss: 2.753861779108651

Epoch: 6| Step: 3
Training loss: 0.6825754046443221
Validation loss: 2.818606705276229

Epoch: 6| Step: 4
Training loss: 0.5736833009201494
Validation loss: 2.8713521758917437

Epoch: 6| Step: 5
Training loss: 0.5999956905687067
Validation loss: 2.7500902941358616

Epoch: 6| Step: 6
Training loss: 0.6101461079984214
Validation loss: 2.8426069260892923

Epoch: 6| Step: 7
Training loss: 0.6864315530379917
Validation loss: 2.883231776071487

Epoch: 6| Step: 8
Training loss: 0.6678269218990381
Validation loss: 2.849621757705276

Epoch: 6| Step: 9
Training loss: 0.6069421376296763
Validation loss: 2.770544271281889

Epoch: 6| Step: 10
Training loss: 0.6554524252567095
Validation loss: 2.8349888163216486

Epoch: 6| Step: 11
Training loss: 1.6505805814775987
Validation loss: 2.855917113067505

Epoch: 6| Step: 12
Training loss: 0.6023194640888014
Validation loss: 2.7478444870576095

Epoch: 6| Step: 13
Training loss: 0.8219939664308332
Validation loss: 2.8173972690857076

Epoch: 188| Step: 0
Training loss: 0.5814917195092189
Validation loss: 2.8048312292931126

Epoch: 6| Step: 1
Training loss: 0.4535965931823327
Validation loss: 2.8555822876059547

Epoch: 6| Step: 2
Training loss: 0.4674870962514266
Validation loss: 2.8899684263438385

Epoch: 6| Step: 3
Training loss: 0.4078936704336711
Validation loss: 2.798030437013082

Epoch: 6| Step: 4
Training loss: 0.5133385682871204
Validation loss: 2.858619465051562

Epoch: 6| Step: 5
Training loss: 0.8770716869520341
Validation loss: 2.8489197769671013

Epoch: 6| Step: 6
Training loss: 0.46959022875137263
Validation loss: 2.8892528129463377

Epoch: 6| Step: 7
Training loss: 0.7660100708117697
Validation loss: 2.7928191173814123

Epoch: 6| Step: 8
Training loss: 0.6636308501318595
Validation loss: 2.8547404517663764

Epoch: 6| Step: 9
Training loss: 0.44091817152455887
Validation loss: 2.8514853967841964

Epoch: 6| Step: 10
Training loss: 0.7709737125793809
Validation loss: 2.716992690897763

Epoch: 6| Step: 11
Training loss: 0.5271851477714663
Validation loss: 2.709110036152684

Epoch: 6| Step: 12
Training loss: 0.5953577510025785
Validation loss: 2.7478875803378138

Epoch: 6| Step: 13
Training loss: 1.6588181073048842
Validation loss: 2.7315105293606794

Epoch: 189| Step: 0
Training loss: 0.3625518901451607
Validation loss: 2.7532052665264732

Epoch: 6| Step: 1
Training loss: 0.7014907281946695
Validation loss: 2.807584394622802

Epoch: 6| Step: 2
Training loss: 0.5881216919468467
Validation loss: 2.883598695976586

Epoch: 6| Step: 3
Training loss: 0.37773050189867985
Validation loss: 2.8916399643037987

Epoch: 6| Step: 4
Training loss: 0.6379475116768212
Validation loss: 2.803290058834651

Epoch: 6| Step: 5
Training loss: 0.5207893798083687
Validation loss: 2.8321287782910476

Epoch: 6| Step: 6
Training loss: 1.6495784047512354
Validation loss: 2.7382868296466163

Epoch: 6| Step: 7
Training loss: 0.7882344272646855
Validation loss: 2.771379665541109

Epoch: 6| Step: 8
Training loss: 0.5870640415499151
Validation loss: 2.7229280486643646

Epoch: 6| Step: 9
Training loss: 0.6192216308742352
Validation loss: 2.7680422389931993

Epoch: 6| Step: 10
Training loss: 0.4663331349890294
Validation loss: 2.7650956762637007

Epoch: 6| Step: 11
Training loss: 0.5896396157412529
Validation loss: 2.84109858337516

Epoch: 6| Step: 12
Training loss: 0.39583993789115346
Validation loss: 2.699126135731931

Epoch: 6| Step: 13
Training loss: 0.7515841284671306
Validation loss: 2.7860514738910136

Epoch: 190| Step: 0
Training loss: 0.4499090281561901
Validation loss: 2.778385115562168

Epoch: 6| Step: 1
Training loss: 0.6147963887335695
Validation loss: 2.8336902047719477

Epoch: 6| Step: 2
Training loss: 0.3429887318275559
Validation loss: 2.8421677180310105

Epoch: 6| Step: 3
Training loss: 0.45284983073666585
Validation loss: 2.806079926183342

Epoch: 6| Step: 4
Training loss: 0.567961143642112
Validation loss: 2.8132210125203914

Epoch: 6| Step: 5
Training loss: 0.7274119835796532
Validation loss: 2.8099643862719867

Epoch: 6| Step: 6
Training loss: 0.48106336628391194
Validation loss: 2.803078164028677

Epoch: 6| Step: 7
Training loss: 0.6640905486522412
Validation loss: 2.728862226167322

Epoch: 6| Step: 8
Training loss: 0.4689661957945821
Validation loss: 2.778672356137817

Epoch: 6| Step: 9
Training loss: 1.6575360613276082
Validation loss: 2.7759879407043604

Epoch: 6| Step: 10
Training loss: 0.671586684532181
Validation loss: 2.7816696136196915

Epoch: 6| Step: 11
Training loss: 0.6786385696580611
Validation loss: 2.896026321310837

Epoch: 6| Step: 12
Training loss: 0.6314368424701486
Validation loss: 2.7731338549668814

Epoch: 6| Step: 13
Training loss: 0.501638588526177
Validation loss: 2.90559259451442

Epoch: 191| Step: 0
Training loss: 0.5145879778736051
Validation loss: 2.79741741582376

Epoch: 6| Step: 1
Training loss: 0.7784062317793798
Validation loss: 2.8545106462422765

Epoch: 6| Step: 2
Training loss: 0.7807579016577267
Validation loss: 2.880940560958797

Epoch: 6| Step: 3
Training loss: 0.3910763421872854
Validation loss: 2.793922442889624

Epoch: 6| Step: 4
Training loss: 0.5742377453211782
Validation loss: 2.738624859563513

Epoch: 6| Step: 5
Training loss: 0.4160910166451166
Validation loss: 2.7944466902022524

Epoch: 6| Step: 6
Training loss: 0.7575257928945273
Validation loss: 2.8420499254190847

Epoch: 6| Step: 7
Training loss: 0.47995578706290387
Validation loss: 2.8321167540522723

Epoch: 6| Step: 8
Training loss: 0.5336016608303881
Validation loss: 2.823697300104383

Epoch: 6| Step: 9
Training loss: 0.45022905599777424
Validation loss: 2.761855118912975

Epoch: 6| Step: 10
Training loss: 1.5763570116641268
Validation loss: 2.903645842456675

Epoch: 6| Step: 11
Training loss: 0.5145181856602268
Validation loss: 2.765030475515189

Epoch: 6| Step: 12
Training loss: 0.6212306801384261
Validation loss: 2.7931990237331235

Epoch: 6| Step: 13
Training loss: 0.7596965454391583
Validation loss: 2.768212123087501

Epoch: 192| Step: 0
Training loss: 0.47520069287033656
Validation loss: 2.716611101210239

Epoch: 6| Step: 1
Training loss: 0.5463880823576874
Validation loss: 2.733508221528499

Epoch: 6| Step: 2
Training loss: 0.44234149731514183
Validation loss: 2.7216582400660077

Epoch: 6| Step: 3
Training loss: 0.4832862492625593
Validation loss: 2.76761209542894

Epoch: 6| Step: 4
Training loss: 0.6825353657987995
Validation loss: 2.7021854068610796

Epoch: 6| Step: 5
Training loss: 0.36927849349598874
Validation loss: 2.8511356400062104

Epoch: 6| Step: 6
Training loss: 0.6748969184791008
Validation loss: 2.772596993041094

Epoch: 6| Step: 7
Training loss: 0.5864276107772253
Validation loss: 2.9375204667264407

Epoch: 6| Step: 8
Training loss: 0.5773241837299966
Validation loss: 2.781285703622767

Epoch: 6| Step: 9
Training loss: 0.8171800660475382
Validation loss: 2.7739550756783196

Epoch: 6| Step: 10
Training loss: 0.7361691654952567
Validation loss: 2.833189895215403

Epoch: 6| Step: 11
Training loss: 0.6950823156404776
Validation loss: 2.779363328036954

Epoch: 6| Step: 12
Training loss: 0.4093646448587459
Validation loss: 2.6987315730587347

Epoch: 6| Step: 13
Training loss: 1.60301819681654
Validation loss: 2.7443708112837175

Epoch: 193| Step: 0
Training loss: 0.46727316590873175
Validation loss: 2.7690406511853474

Epoch: 6| Step: 1
Training loss: 0.710056597576082
Validation loss: 2.881887423603605

Epoch: 6| Step: 2
Training loss: 0.5252675192306564
Validation loss: 2.775861327496744

Epoch: 6| Step: 3
Training loss: 0.6589143346119096
Validation loss: 2.770206155760104

Epoch: 6| Step: 4
Training loss: 0.407246907043889
Validation loss: 2.72428228860121

Epoch: 6| Step: 5
Training loss: 0.4716479051832793
Validation loss: 2.8467506255901824

Epoch: 6| Step: 6
Training loss: 0.8558335245077136
Validation loss: 2.843028245935644

Epoch: 6| Step: 7
Training loss: 0.5387935243802235
Validation loss: 2.8591060963634516

Epoch: 6| Step: 8
Training loss: 1.5311554860121066
Validation loss: 2.860915417033009

Epoch: 6| Step: 9
Training loss: 0.4818171367216799
Validation loss: 2.908676952586354

Epoch: 6| Step: 10
Training loss: 0.7626269672557878
Validation loss: 2.83307130854871

Epoch: 6| Step: 11
Training loss: 0.7328141852971526
Validation loss: 2.870226116953686

Epoch: 6| Step: 12
Training loss: 0.6121379375792637
Validation loss: 2.863238741570863

Epoch: 6| Step: 13
Training loss: 0.6781170558903605
Validation loss: 2.838380446215678

Epoch: 194| Step: 0
Training loss: 0.6449446306193958
Validation loss: 2.8809521193581156

Epoch: 6| Step: 1
Training loss: 0.6360110462971844
Validation loss: 2.918508810769295

Epoch: 6| Step: 2
Training loss: 0.3464485257428018
Validation loss: 2.7982017311275698

Epoch: 6| Step: 3
Training loss: 1.6498799453754875
Validation loss: 2.7782828973754854

Epoch: 6| Step: 4
Training loss: 0.5330002227500035
Validation loss: 2.756269533026143

Epoch: 6| Step: 5
Training loss: 0.6338006064093985
Validation loss: 2.7884103847908035

Epoch: 6| Step: 6
Training loss: 0.4748887860455181
Validation loss: 2.8404608348583182

Epoch: 6| Step: 7
Training loss: 0.5250931929571911
Validation loss: 2.868587986866744

Epoch: 6| Step: 8
Training loss: 0.7441247653022036
Validation loss: 2.7352248188232595

Epoch: 6| Step: 9
Training loss: 0.3965175971783993
Validation loss: 2.802162968143282

Epoch: 6| Step: 10
Training loss: 0.4750576649346886
Validation loss: 2.7260488993736196

Epoch: 6| Step: 11
Training loss: 0.41622702729923294
Validation loss: 2.7973528263808674

Epoch: 6| Step: 12
Training loss: 0.5004930449468415
Validation loss: 2.867162331895952

Epoch: 6| Step: 13
Training loss: 0.6070054764351317
Validation loss: 2.8672764597162

Epoch: 195| Step: 0
Training loss: 0.7301512247374273
Validation loss: 2.818867123715725

Epoch: 6| Step: 1
Training loss: 0.4914808043915813
Validation loss: 2.756175202661676

Epoch: 6| Step: 2
Training loss: 0.4630655207772928
Validation loss: 2.8672147328593236

Epoch: 6| Step: 3
Training loss: 0.9261991949729905
Validation loss: 2.808211313383346

Epoch: 6| Step: 4
Training loss: 0.8174586107118196
Validation loss: 2.8726905862891394

Epoch: 6| Step: 5
Training loss: 0.5488584788335196
Validation loss: 2.904824840629178

Epoch: 6| Step: 6
Training loss: 0.4604371151187883
Validation loss: 2.8464496639573573

Epoch: 6| Step: 7
Training loss: 0.674437051486758
Validation loss: 2.8005802183480597

Epoch: 6| Step: 8
Training loss: 0.2999758651085088
Validation loss: 2.8897170144319526

Epoch: 6| Step: 9
Training loss: 0.5259512140545258
Validation loss: 2.851361397397375

Epoch: 6| Step: 10
Training loss: 0.38933336335352453
Validation loss: 2.797111984243331

Epoch: 6| Step: 11
Training loss: 0.7152792432660972
Validation loss: 2.79201927140789

Epoch: 6| Step: 12
Training loss: 1.4757722223267256
Validation loss: 2.847957642229532

Epoch: 6| Step: 13
Training loss: 0.5897079210328672
Validation loss: 2.7735576979689296

Epoch: 196| Step: 0
Training loss: 0.5131948017961666
Validation loss: 2.724616346270577

Epoch: 6| Step: 1
Training loss: 0.43370553027807895
Validation loss: 2.8451942018443486

Epoch: 6| Step: 2
Training loss: 0.5210224348736605
Validation loss: 2.8806852298839716

Epoch: 6| Step: 3
Training loss: 0.5581768320670426
Validation loss: 2.777466404205508

Epoch: 6| Step: 4
Training loss: 0.45766812153816744
Validation loss: 2.744056072267402

Epoch: 6| Step: 5
Training loss: 0.4106096395757855
Validation loss: 2.726942981307121

Epoch: 6| Step: 6
Training loss: 1.5551447363708664
Validation loss: 2.8399753041604017

Epoch: 6| Step: 7
Training loss: 0.5152783239909542
Validation loss: 2.8335816798107762

Epoch: 6| Step: 8
Training loss: 0.6341621464640481
Validation loss: 2.758429986772007

Epoch: 6| Step: 9
Training loss: 0.41825804992677024
Validation loss: 2.764915217179896

Epoch: 6| Step: 10
Training loss: 0.703516617964362
Validation loss: 2.7822188500792544

Epoch: 6| Step: 11
Training loss: 0.5925346786072295
Validation loss: 2.789026432890502

Epoch: 6| Step: 12
Training loss: 0.6188818453951633
Validation loss: 2.8779473745930666

Epoch: 6| Step: 13
Training loss: 0.6974787025891835
Validation loss: 2.855911213644311

Epoch: 197| Step: 0
Training loss: 0.5413984466034412
Validation loss: 2.7669632542059786

Epoch: 6| Step: 1
Training loss: 0.4865423136831476
Validation loss: 2.8165988300739553

Epoch: 6| Step: 2
Training loss: 1.5372695160832193
Validation loss: 2.723966431955196

Epoch: 6| Step: 3
Training loss: 0.7146318882571353
Validation loss: 2.6980491419097303

Epoch: 6| Step: 4
Training loss: 0.5437307705164635
Validation loss: 2.696770742558989

Epoch: 6| Step: 5
Training loss: 0.7993469418872422
Validation loss: 2.825961203764858

Epoch: 6| Step: 6
Training loss: 1.0045326149118763
Validation loss: 2.699041748131989

Epoch: 6| Step: 7
Training loss: 0.5017967128857335
Validation loss: 2.820748926775308

Epoch: 6| Step: 8
Training loss: 0.4298918324918978
Validation loss: 2.881202020473214

Epoch: 6| Step: 9
Training loss: 0.42623076202518134
Validation loss: 2.8873126185224662

Epoch: 6| Step: 10
Training loss: 0.9676702696531339
Validation loss: 2.968928388623425

Epoch: 6| Step: 11
Training loss: 0.7026084273887564
Validation loss: 2.921511486376688

Epoch: 6| Step: 12
Training loss: 0.7864572933434353
Validation loss: 2.812196573914763

Epoch: 6| Step: 13
Training loss: 0.5442665836101392
Validation loss: 2.7311735757920506

Epoch: 198| Step: 0
Training loss: 0.340747705283943
Validation loss: 2.7856336044556365

Epoch: 6| Step: 1
Training loss: 0.9842216432792019
Validation loss: 2.761491801259228

Epoch: 6| Step: 2
Training loss: 0.8177003232397575
Validation loss: 2.7279967258588473

Epoch: 6| Step: 3
Training loss: 0.7415638763119174
Validation loss: 2.781936475065534

Epoch: 6| Step: 4
Training loss: 0.5262445933410826
Validation loss: 2.8481929432031885

Epoch: 6| Step: 5
Training loss: 0.6571085173433807
Validation loss: 2.772792730468382

Epoch: 6| Step: 6
Training loss: 0.6788703786067195
Validation loss: 2.8875704598465486

Epoch: 6| Step: 7
Training loss: 0.7795013312499085
Validation loss: 2.8431262495499787

Epoch: 6| Step: 8
Training loss: 0.31823700033099417
Validation loss: 2.800813129408549

Epoch: 6| Step: 9
Training loss: 0.5644902411800781
Validation loss: 2.846148712384226

Epoch: 6| Step: 10
Training loss: 0.5665305691793399
Validation loss: 2.9412292724432394

Epoch: 6| Step: 11
Training loss: 1.5489385692957698
Validation loss: 2.865756198177398

Epoch: 6| Step: 12
Training loss: 0.6212369645744826
Validation loss: 2.7484723312833954

Epoch: 6| Step: 13
Training loss: 0.5780979614120909
Validation loss: 2.812664959626344

Epoch: 199| Step: 0
Training loss: 0.672760712313269
Validation loss: 2.8434942780261543

Epoch: 6| Step: 1
Training loss: 0.38317449153583427
Validation loss: 2.8514911660107667

Epoch: 6| Step: 2
Training loss: 0.476273527240083
Validation loss: 2.808342955617145

Epoch: 6| Step: 3
Training loss: 1.4528238948474441
Validation loss: 2.7468883075760644

Epoch: 6| Step: 4
Training loss: 0.4266087426631963
Validation loss: 2.8238181238511393

Epoch: 6| Step: 5
Training loss: 0.5321972760183472
Validation loss: 2.7428465917858342

Epoch: 6| Step: 6
Training loss: 0.6090690627314563
Validation loss: 2.790926412869973

Epoch: 6| Step: 7
Training loss: 0.610555190641722
Validation loss: 2.8926471956958544

Epoch: 6| Step: 8
Training loss: 0.37372814503693186
Validation loss: 2.8078119978836167

Epoch: 6| Step: 9
Training loss: 0.5770433720777806
Validation loss: 2.7520948580650497

Epoch: 6| Step: 10
Training loss: 0.5231177079069644
Validation loss: 2.8183702031150273

Epoch: 6| Step: 11
Training loss: 0.641286717566426
Validation loss: 2.8115211054854212

Epoch: 6| Step: 12
Training loss: 0.4207655482261118
Validation loss: 2.8197032802348367

Epoch: 6| Step: 13
Training loss: 0.7770561568048008
Validation loss: 2.8321213140088086

Epoch: 200| Step: 0
Training loss: 0.7060334346205414
Validation loss: 2.84384613433546

Epoch: 6| Step: 1
Training loss: 0.562777080109718
Validation loss: 2.8941787457033286

Epoch: 6| Step: 2
Training loss: 0.8617795423020521
Validation loss: 2.855633843516015

Epoch: 6| Step: 3
Training loss: 0.5625085565128154
Validation loss: 2.8338869245912446

Epoch: 6| Step: 4
Training loss: 0.6097771466942656
Validation loss: 2.7803630914894852

Epoch: 6| Step: 5
Training loss: 1.5249671494744792
Validation loss: 2.8237752183629885

Epoch: 6| Step: 6
Training loss: 0.5673418407781021
Validation loss: 2.8304003279149015

Epoch: 6| Step: 7
Training loss: 0.5127288226120955
Validation loss: 2.855185881318463

Epoch: 6| Step: 8
Training loss: 0.7216210451161444
Validation loss: 2.8922536574837467

Epoch: 6| Step: 9
Training loss: 0.5081701633046978
Validation loss: 2.8450106945853637

Epoch: 6| Step: 10
Training loss: 0.5888360364781532
Validation loss: 2.8417384959863066

Epoch: 6| Step: 11
Training loss: 0.5431920971266043
Validation loss: 2.790032639238501

Epoch: 6| Step: 12
Training loss: 0.6095223370966057
Validation loss: 2.77611474852898

Epoch: 6| Step: 13
Training loss: 0.7813382671084338
Validation loss: 2.8279935690335933

Epoch: 201| Step: 0
Training loss: 0.7655965838705878
Validation loss: 2.8838757326351883

Epoch: 6| Step: 1
Training loss: 0.6156676689116384
Validation loss: 2.8305898080520535

Epoch: 6| Step: 2
Training loss: 0.478494978478769
Validation loss: 2.7345793002872543

Epoch: 6| Step: 3
Training loss: 0.5241906739858948
Validation loss: 2.8148844183529307

Epoch: 6| Step: 4
Training loss: 0.6012049020837661
Validation loss: 2.9119785687964463

Epoch: 6| Step: 5
Training loss: 0.5195158762557336
Validation loss: 2.8815502928767023

Epoch: 6| Step: 6
Training loss: 0.8275572792120749
Validation loss: 2.846606877106303

Epoch: 6| Step: 7
Training loss: 0.43963222668662477
Validation loss: 2.8710305412410384

Epoch: 6| Step: 8
Training loss: 0.5083328808589652
Validation loss: 2.8580719944192823

Epoch: 6| Step: 9
Training loss: 0.4395481600256317
Validation loss: 2.7922002984543277

Epoch: 6| Step: 10
Training loss: 0.5455537639403119
Validation loss: 2.8412397994398035

Epoch: 6| Step: 11
Training loss: 0.5896613994941423
Validation loss: 2.7178816157569283

Epoch: 6| Step: 12
Training loss: 0.4782545662146984
Validation loss: 2.7751928514477777

Epoch: 6| Step: 13
Training loss: 1.491887406935639
Validation loss: 2.776457726157041

Epoch: 202| Step: 0
Training loss: 0.7984005032980217
Validation loss: 2.7948663769571658

Epoch: 6| Step: 1
Training loss: 0.6771299981884692
Validation loss: 2.840876220628562

Epoch: 6| Step: 2
Training loss: 0.6270837855627852
Validation loss: 2.8100404510663597

Epoch: 6| Step: 3
Training loss: 0.44523593177396065
Validation loss: 2.956098885736642

Epoch: 6| Step: 4
Training loss: 0.7069652379027163
Validation loss: 2.758650323760696

Epoch: 6| Step: 5
Training loss: 0.4854293545987117
Validation loss: 2.776399561921033

Epoch: 6| Step: 6
Training loss: 0.49476181910653433
Validation loss: 2.7704321970059462

Epoch: 6| Step: 7
Training loss: 1.6105231476487847
Validation loss: 2.8323057265293383

Epoch: 6| Step: 8
Training loss: 0.5801272644396601
Validation loss: 2.68763478998272

Epoch: 6| Step: 9
Training loss: 0.599669288847751
Validation loss: 2.7222827160746195

Epoch: 6| Step: 10
Training loss: 0.5018330590002315
Validation loss: 2.803893448857205

Epoch: 6| Step: 11
Training loss: 0.5216675911561048
Validation loss: 2.756250185688961

Epoch: 6| Step: 12
Training loss: 0.5692299274663392
Validation loss: 2.8704348822377628

Epoch: 6| Step: 13
Training loss: 0.5158059351808505
Validation loss: 2.9074962910710234

Epoch: 203| Step: 0
Training loss: 0.4718562520325919
Validation loss: 2.853996617525712

Epoch: 6| Step: 1
Training loss: 0.8480224521516706
Validation loss: 2.871592077488378

Epoch: 6| Step: 2
Training loss: 0.5861907411732391
Validation loss: 2.898716545553472

Epoch: 6| Step: 3
Training loss: 0.4566463414626537
Validation loss: 2.7109691020724975

Epoch: 6| Step: 4
Training loss: 0.42538589530956694
Validation loss: 2.7630084747891366

Epoch: 6| Step: 5
Training loss: 0.6162916514498302
Validation loss: 2.7131063120609262

Epoch: 6| Step: 6
Training loss: 0.7041181543858199
Validation loss: 2.7446607139855796

Epoch: 6| Step: 7
Training loss: 0.5768104505949971
Validation loss: 2.7475443915870135

Epoch: 6| Step: 8
Training loss: 0.7593701664649128
Validation loss: 2.7669514494178364

Epoch: 6| Step: 9
Training loss: 0.4603768187607887
Validation loss: 2.7058970399583586

Epoch: 6| Step: 10
Training loss: 1.4620546363818367
Validation loss: 2.7470178473677076

Epoch: 6| Step: 11
Training loss: 0.6702319170124956
Validation loss: 2.8749112378115265

Epoch: 6| Step: 12
Training loss: 0.7619434514326849
Validation loss: 2.798124322028437

Epoch: 6| Step: 13
Training loss: 0.47794367025769063
Validation loss: 2.8078958053557352

Epoch: 204| Step: 0
Training loss: 0.5009552949254147
Validation loss: 2.876867157928654

Epoch: 6| Step: 1
Training loss: 0.6747769958732281
Validation loss: 2.7710845207187567

Epoch: 6| Step: 2
Training loss: 0.7164301960810844
Validation loss: 2.7733429082222245

Epoch: 6| Step: 3
Training loss: 1.5599487839140933
Validation loss: 2.807852996211472

Epoch: 6| Step: 4
Training loss: 0.3467773299994717
Validation loss: 2.8059089147503284

Epoch: 6| Step: 5
Training loss: 0.731199419277428
Validation loss: 2.7733597005758335

Epoch: 6| Step: 6
Training loss: 0.7087290070131002
Validation loss: 2.7476969091440298

Epoch: 6| Step: 7
Training loss: 0.40358533303304095
Validation loss: 2.813771151340725

Epoch: 6| Step: 8
Training loss: 0.548403592705314
Validation loss: 2.8032033352943797

Epoch: 6| Step: 9
Training loss: 0.49235904065754804
Validation loss: 2.8082519521345084

Epoch: 6| Step: 10
Training loss: 0.5618462737466114
Validation loss: 2.784894263031227

Epoch: 6| Step: 11
Training loss: 0.5011002832123019
Validation loss: 2.873855515056081

Epoch: 6| Step: 12
Training loss: 0.6338095169410966
Validation loss: 2.859793154743732

Epoch: 6| Step: 13
Training loss: 0.3894025748761886
Validation loss: 2.8313387600737676

Epoch: 205| Step: 0
Training loss: 0.7301570614941474
Validation loss: 2.921254328391389

Epoch: 6| Step: 1
Training loss: 0.6077706172997084
Validation loss: 2.9065040696086792

Epoch: 6| Step: 2
Training loss: 0.5536913994465468
Validation loss: 2.86161369139912

Epoch: 6| Step: 3
Training loss: 0.6990910418792501
Validation loss: 2.8028655727041762

Epoch: 6| Step: 4
Training loss: 0.6983836424200478
Validation loss: 2.8057415326694946

Epoch: 6| Step: 5
Training loss: 1.4965905542426559
Validation loss: 2.827607376191435

Epoch: 6| Step: 6
Training loss: 0.5192661899931696
Validation loss: 2.8773730339102017

Epoch: 6| Step: 7
Training loss: 0.40196169148057254
Validation loss: 2.7847852633711256

Epoch: 6| Step: 8
Training loss: 0.6494579787929347
Validation loss: 2.82914869914204

Epoch: 6| Step: 9
Training loss: 0.4691535484191969
Validation loss: 2.7788372647174846

Epoch: 6| Step: 10
Training loss: 0.5839846556799989
Validation loss: 2.833954537302724

Epoch: 6| Step: 11
Training loss: 0.6967272563379975
Validation loss: 2.843121735196445

Epoch: 6| Step: 12
Training loss: 0.6051704410196093
Validation loss: 2.874521505923333

Epoch: 6| Step: 13
Training loss: 0.41087465494673503
Validation loss: 2.8122545205822966

Epoch: 206| Step: 0
Training loss: 0.5687440442203108
Validation loss: 2.7527279183904017

Epoch: 6| Step: 1
Training loss: 0.6020641959645744
Validation loss: 2.7771687369773206

Epoch: 6| Step: 2
Training loss: 0.41058779221316244
Validation loss: 2.7753172257820613

Epoch: 6| Step: 3
Training loss: 0.4765436762859965
Validation loss: 2.805590825021798

Epoch: 6| Step: 4
Training loss: 0.3296326333985902
Validation loss: 2.8124980078796114

Epoch: 6| Step: 5
Training loss: 0.4201818326891022
Validation loss: 2.847938192230859

Epoch: 6| Step: 6
Training loss: 0.4550906658491142
Validation loss: 2.846026044234497

Epoch: 6| Step: 7
Training loss: 0.6082127319831608
Validation loss: 2.7702537351092587

Epoch: 6| Step: 8
Training loss: 0.7438636724974634
Validation loss: 2.755439508230854

Epoch: 6| Step: 9
Training loss: 0.3776159438127261
Validation loss: 2.7875957318618556

Epoch: 6| Step: 10
Training loss: 0.300780085771958
Validation loss: 2.876557715980244

Epoch: 6| Step: 11
Training loss: 1.5706420097234537
Validation loss: 2.7546810133481334

Epoch: 6| Step: 12
Training loss: 0.6247395926620357
Validation loss: 2.8798411838355245

Epoch: 6| Step: 13
Training loss: 0.7494684561007644
Validation loss: 2.9389263842854323

Epoch: 207| Step: 0
Training loss: 0.6804945966014154
Validation loss: 2.8175508992229976

Epoch: 6| Step: 1
Training loss: 0.6167474457525918
Validation loss: 2.836647260138549

Epoch: 6| Step: 2
Training loss: 0.5455564133751093
Validation loss: 2.828502770303232

Epoch: 6| Step: 3
Training loss: 0.5348299242796426
Validation loss: 2.863657282640033

Epoch: 6| Step: 4
Training loss: 0.4917499019863184
Validation loss: 2.8048208872636287

Epoch: 6| Step: 5
Training loss: 1.4229991786522818
Validation loss: 2.8108124650560735

Epoch: 6| Step: 6
Training loss: 0.4567098383991667
Validation loss: 2.9372427536892376

Epoch: 6| Step: 7
Training loss: 0.3311589844740078
Validation loss: 2.948871381567613

Epoch: 6| Step: 8
Training loss: 0.4895076760887398
Validation loss: 2.9143126843110085

Epoch: 6| Step: 9
Training loss: 0.5504182742276084
Validation loss: 2.883556307915874

Epoch: 6| Step: 10
Training loss: 0.596203603158919
Validation loss: 2.8599848696168406

Epoch: 6| Step: 11
Training loss: 0.46155032137311114
Validation loss: 2.8594638970458264

Epoch: 6| Step: 12
Training loss: 0.6064969837824455
Validation loss: 2.8143029968191184

Epoch: 6| Step: 13
Training loss: 0.4703666307341914
Validation loss: 2.8665319207778124

Epoch: 208| Step: 0
Training loss: 0.3504093968903217
Validation loss: 2.8495037851517653

Epoch: 6| Step: 1
Training loss: 0.7328219935731504
Validation loss: 2.827129434665554

Epoch: 6| Step: 2
Training loss: 0.5632779781336472
Validation loss: 2.843957453276679

Epoch: 6| Step: 3
Training loss: 0.4266459058606959
Validation loss: 2.835069732032684

Epoch: 6| Step: 4
Training loss: 0.7143683181410154
Validation loss: 2.918164486258768

Epoch: 6| Step: 5
Training loss: 0.46329429183537785
Validation loss: 2.8979068349145387

Epoch: 6| Step: 6
Training loss: 0.45296636632770443
Validation loss: 2.801346456264871

Epoch: 6| Step: 7
Training loss: 1.64472094096478
Validation loss: 2.8429560269061205

Epoch: 6| Step: 8
Training loss: 0.2769767724232931
Validation loss: 2.903628585604545

Epoch: 6| Step: 9
Training loss: 0.5852204067369531
Validation loss: 2.765104255573278

Epoch: 6| Step: 10
Training loss: 0.3652992598889276
Validation loss: 2.8793929028173566

Epoch: 6| Step: 11
Training loss: 0.4259097054271571
Validation loss: 2.8531973554914747

Epoch: 6| Step: 12
Training loss: 0.7964430741719231
Validation loss: 2.9352599591962742

Epoch: 6| Step: 13
Training loss: 0.4697251190988169
Validation loss: 2.9189162479951807

Epoch: 209| Step: 0
Training loss: 0.39421616615782196
Validation loss: 2.8153240860192397

Epoch: 6| Step: 1
Training loss: 0.6610669958353601
Validation loss: 2.845799277135804

Epoch: 6| Step: 2
Training loss: 0.6404708351162735
Validation loss: 2.8161345838930334

Epoch: 6| Step: 3
Training loss: 0.4917360384810751
Validation loss: 2.822691079072733

Epoch: 6| Step: 4
Training loss: 0.874897303685411
Validation loss: 2.793324979103481

Epoch: 6| Step: 5
Training loss: 0.4643443333908186
Validation loss: 2.7275716959722818

Epoch: 6| Step: 6
Training loss: 0.5880170413746191
Validation loss: 2.7526832696717762

Epoch: 6| Step: 7
Training loss: 0.5752288860373643
Validation loss: 2.8177186233605265

Epoch: 6| Step: 8
Training loss: 0.5694103421361014
Validation loss: 2.8313811720215414

Epoch: 6| Step: 9
Training loss: 1.4947720658172465
Validation loss: 2.8593643549597645

Epoch: 6| Step: 10
Training loss: 0.4880880049730028
Validation loss: 2.7852962934856467

Epoch: 6| Step: 11
Training loss: 0.49331351555613784
Validation loss: 2.7449627894720803

Epoch: 6| Step: 12
Training loss: 0.43623185286719707
Validation loss: 2.8175243710149562

Epoch: 6| Step: 13
Training loss: 0.5544521208473585
Validation loss: 2.8092532314322574

Epoch: 210| Step: 0
Training loss: 0.4642269466091243
Validation loss: 2.8880932004556974

Epoch: 6| Step: 1
Training loss: 0.4427498480087355
Validation loss: 2.819452212677408

Epoch: 6| Step: 2
Training loss: 0.725407245961178
Validation loss: 2.824148273072312

Epoch: 6| Step: 3
Training loss: 0.4503582310007082
Validation loss: 2.8328587167248296

Epoch: 6| Step: 4
Training loss: 0.6012502082618146
Validation loss: 2.7557755278861578

Epoch: 6| Step: 5
Training loss: 0.5782488870622386
Validation loss: 2.843749371203678

Epoch: 6| Step: 6
Training loss: 0.7210940409584327
Validation loss: 2.831000578548436

Epoch: 6| Step: 7
Training loss: 1.4650808727348688
Validation loss: 2.7865264076164853

Epoch: 6| Step: 8
Training loss: 0.5915748507041148
Validation loss: 2.827762770243427

Epoch: 6| Step: 9
Training loss: 0.6669261894135676
Validation loss: 2.840338410712494

Epoch: 6| Step: 10
Training loss: 0.4457874442337712
Validation loss: 2.818609665833255

Epoch: 6| Step: 11
Training loss: 0.5560095974776504
Validation loss: 2.8085436367751173

Epoch: 6| Step: 12
Training loss: 0.502971699265469
Validation loss: 2.8543831170049305

Epoch: 6| Step: 13
Training loss: 0.5032978969166984
Validation loss: 2.889435449477138

Epoch: 211| Step: 0
Training loss: 0.4992696374976629
Validation loss: 2.8965298937811133

Epoch: 6| Step: 1
Training loss: 0.4782432715296095
Validation loss: 2.8458176247054747

Epoch: 6| Step: 2
Training loss: 0.36974071993476015
Validation loss: 2.8699032207391766

Epoch: 6| Step: 3
Training loss: 0.6198966768139695
Validation loss: 2.931880377772196

Epoch: 6| Step: 4
Training loss: 0.4566465535688647
Validation loss: 2.878118095707214

Epoch: 6| Step: 5
Training loss: 0.44893076414471716
Validation loss: 2.8060612054993714

Epoch: 6| Step: 6
Training loss: 0.6100338284305266
Validation loss: 2.7683318374173487

Epoch: 6| Step: 7
Training loss: 0.40889717491379307
Validation loss: 2.765136215782041

Epoch: 6| Step: 8
Training loss: 1.4001508478231377
Validation loss: 2.8928532577950543

Epoch: 6| Step: 9
Training loss: 0.4843149917101295
Validation loss: 2.7772463438512656

Epoch: 6| Step: 10
Training loss: 0.48426922289221636
Validation loss: 2.852665114063656

Epoch: 6| Step: 11
Training loss: 0.29578017083972197
Validation loss: 2.902240229352468

Epoch: 6| Step: 12
Training loss: 0.4313951027054133
Validation loss: 2.7980354501633986

Epoch: 6| Step: 13
Training loss: 0.6526761150556171
Validation loss: 2.815216095164011

Epoch: 212| Step: 0
Training loss: 0.5928235103568031
Validation loss: 2.726922529728628

Epoch: 6| Step: 1
Training loss: 1.4948975883287339
Validation loss: 2.8212300055970987

Epoch: 6| Step: 2
Training loss: 0.4459021495876783
Validation loss: 2.8272823110979455

Epoch: 6| Step: 3
Training loss: 0.4424291422248928
Validation loss: 2.7651457146757545

Epoch: 6| Step: 4
Training loss: 0.6335147211009813
Validation loss: 2.7884270864056613

Epoch: 6| Step: 5
Training loss: 0.502599722755301
Validation loss: 2.881638285193955

Epoch: 6| Step: 6
Training loss: 0.5112821740470329
Validation loss: 2.8360589091617183

Epoch: 6| Step: 7
Training loss: 0.42949072059981064
Validation loss: 2.8011271654620824

Epoch: 6| Step: 8
Training loss: 0.32238150160594725
Validation loss: 2.8888251122338784

Epoch: 6| Step: 9
Training loss: 0.4291547420227717
Validation loss: 2.845760529025764

Epoch: 6| Step: 10
Training loss: 0.6070013522489716
Validation loss: 2.869305762794279

Epoch: 6| Step: 11
Training loss: 0.699624822755934
Validation loss: 2.8395776847023777

Epoch: 6| Step: 12
Training loss: 0.49447921792573774
Validation loss: 2.8256897250325883

Epoch: 6| Step: 13
Training loss: 0.747679458305788
Validation loss: 2.8882620698957355

Epoch: 213| Step: 0
Training loss: 0.5122325734478381
Validation loss: 2.880422743990418

Epoch: 6| Step: 1
Training loss: 0.590731830118931
Validation loss: 2.8897260625601175

Epoch: 6| Step: 2
Training loss: 0.7613915547644297
Validation loss: 2.9396288577384007

Epoch: 6| Step: 3
Training loss: 0.650094683793504
Validation loss: 2.8047811480147375

Epoch: 6| Step: 4
Training loss: 1.3524297676960135
Validation loss: 2.7984420392943714

Epoch: 6| Step: 5
Training loss: 0.39904656326865495
Validation loss: 2.8041541992484724

Epoch: 6| Step: 6
Training loss: 0.5024864836435969
Validation loss: 2.75422766863682

Epoch: 6| Step: 7
Training loss: 0.5872784592531672
Validation loss: 2.7344360635387805

Epoch: 6| Step: 8
Training loss: 0.5581700512088704
Validation loss: 2.821093027697034

Epoch: 6| Step: 9
Training loss: 0.594617636340907
Validation loss: 2.816653511949628

Epoch: 6| Step: 10
Training loss: 0.5958700977889609
Validation loss: 2.781412055619876

Epoch: 6| Step: 11
Training loss: 0.5130964181538955
Validation loss: 2.801903535730345

Epoch: 6| Step: 12
Training loss: 0.4564201965081775
Validation loss: 2.855092995861019

Epoch: 6| Step: 13
Training loss: 0.7687906487115499
Validation loss: 3.0100112210821823

Epoch: 214| Step: 0
Training loss: 0.5430084049371728
Validation loss: 2.858609387123116

Epoch: 6| Step: 1
Training loss: 0.3284736098411845
Validation loss: 2.8420330495673283

Epoch: 6| Step: 2
Training loss: 0.4686325084942532
Validation loss: 2.8414418561353125

Epoch: 6| Step: 3
Training loss: 0.423868291683093
Validation loss: 2.7260719448259816

Epoch: 6| Step: 4
Training loss: 0.3846269154195664
Validation loss: 2.8896541580361874

Epoch: 6| Step: 5
Training loss: 0.8565586063000076
Validation loss: 2.790841654433562

Epoch: 6| Step: 6
Training loss: 1.4240192551918336
Validation loss: 2.8277142755122826

Epoch: 6| Step: 7
Training loss: 0.4410024162862068
Validation loss: 2.7708349777637467

Epoch: 6| Step: 8
Training loss: 0.4467728744866968
Validation loss: 2.8664148937229137

Epoch: 6| Step: 9
Training loss: 0.7291123960371217
Validation loss: 2.8659486372250207

Epoch: 6| Step: 10
Training loss: 0.8406057759749317
Validation loss: 2.855834290450772

Epoch: 6| Step: 11
Training loss: 0.45168301911095693
Validation loss: 2.8389453472570985

Epoch: 6| Step: 12
Training loss: 0.6751522157491596
Validation loss: 2.932340121278245

Epoch: 6| Step: 13
Training loss: 0.4550510120091797
Validation loss: 2.84527422680043

Epoch: 215| Step: 0
Training loss: 0.4436980311090625
Validation loss: 2.8379165707736926

Epoch: 6| Step: 1
Training loss: 0.7315209302534862
Validation loss: 2.8272041100097396

Epoch: 6| Step: 2
Training loss: 0.8009623997181947
Validation loss: 2.7195326749130704

Epoch: 6| Step: 3
Training loss: 0.4864163299604258
Validation loss: 2.8610789185063648

Epoch: 6| Step: 4
Training loss: 0.7955749977862936
Validation loss: 2.9225782068392205

Epoch: 6| Step: 5
Training loss: 0.3139837564850026
Validation loss: 2.767148878595192

Epoch: 6| Step: 6
Training loss: 0.7316565011374794
Validation loss: 2.8416727884474637

Epoch: 6| Step: 7
Training loss: 0.6057301603021014
Validation loss: 2.832779610511832

Epoch: 6| Step: 8
Training loss: 1.376363295171633
Validation loss: 2.8560465355544835

Epoch: 6| Step: 9
Training loss: 0.4600942948865472
Validation loss: 2.902368243367831

Epoch: 6| Step: 10
Training loss: 0.5426186729752991
Validation loss: 2.8323652820249565

Epoch: 6| Step: 11
Training loss: 0.5229881692408914
Validation loss: 2.796211490743936

Epoch: 6| Step: 12
Training loss: 0.4956983056521784
Validation loss: 2.762284727612666

Epoch: 6| Step: 13
Training loss: 0.4554166067122792
Validation loss: 2.8981607515796575

Epoch: 216| Step: 0
Training loss: 0.5297917941332428
Validation loss: 2.875354012517629

Epoch: 6| Step: 1
Training loss: 0.4812977005491684
Validation loss: 2.8943206806614357

Epoch: 6| Step: 2
Training loss: 0.40775383859882247
Validation loss: 2.8436661522769104

Epoch: 6| Step: 3
Training loss: 0.6244743998146479
Validation loss: 2.7838855642909874

Epoch: 6| Step: 4
Training loss: 0.5269393217797109
Validation loss: 2.838365886506781

Epoch: 6| Step: 5
Training loss: 0.3644542011273719
Validation loss: 2.8441830259967165

Epoch: 6| Step: 6
Training loss: 0.633964949126317
Validation loss: 2.8848464806412286

Epoch: 6| Step: 7
Training loss: 1.407418803757729
Validation loss: 2.842664252853025

Epoch: 6| Step: 8
Training loss: 0.4575680083136209
Validation loss: 2.8975872153276945

Epoch: 6| Step: 9
Training loss: 0.3656442351865
Validation loss: 2.9540126347883926

Epoch: 6| Step: 10
Training loss: 0.7260517663312518
Validation loss: 2.763863672581269

Epoch: 6| Step: 11
Training loss: 0.5470055560539416
Validation loss: 2.8554549593055394

Epoch: 6| Step: 12
Training loss: 0.5885542865401657
Validation loss: 2.840982550740547

Epoch: 6| Step: 13
Training loss: 0.6586191011846312
Validation loss: 2.8402791902828253

Epoch: 217| Step: 0
Training loss: 0.6358412798697017
Validation loss: 2.76844900603429

Epoch: 6| Step: 1
Training loss: 0.4200701961723271
Validation loss: 2.828308703671787

Epoch: 6| Step: 2
Training loss: 0.4179643648577099
Validation loss: 2.812466303305626

Epoch: 6| Step: 3
Training loss: 0.3988938803273419
Validation loss: 2.824454797612309

Epoch: 6| Step: 4
Training loss: 0.5087178595979351
Validation loss: 2.8319317819951357

Epoch: 6| Step: 5
Training loss: 0.5699323667589369
Validation loss: 2.8233950914506405

Epoch: 6| Step: 6
Training loss: 0.5534750891940557
Validation loss: 2.8129210827992015

Epoch: 6| Step: 7
Training loss: 0.31913985785738797
Validation loss: 2.8068467721289116

Epoch: 6| Step: 8
Training loss: 0.5478671746570897
Validation loss: 2.7987923612082106

Epoch: 6| Step: 9
Training loss: 0.7194269558250936
Validation loss: 2.780345341000866

Epoch: 6| Step: 10
Training loss: 0.3885568995042246
Validation loss: 2.8070885626666957

Epoch: 6| Step: 11
Training loss: 0.3143627321151343
Validation loss: 2.794047370121332

Epoch: 6| Step: 12
Training loss: 1.455234432145708
Validation loss: 2.866072989874928

Epoch: 6| Step: 13
Training loss: 0.45182617435508504
Validation loss: 2.837910451905103

Epoch: 218| Step: 0
Training loss: 0.35784657578439033
Validation loss: 2.86564022103153

Epoch: 6| Step: 1
Training loss: 0.593363159047078
Validation loss: 2.7689151266900853

Epoch: 6| Step: 2
Training loss: 0.5380729216785878
Validation loss: 2.7672000861029766

Epoch: 6| Step: 3
Training loss: 0.3479156490794546
Validation loss: 2.7805442771932714

Epoch: 6| Step: 4
Training loss: 0.5291736642369848
Validation loss: 2.841939734225081

Epoch: 6| Step: 5
Training loss: 1.339389735224026
Validation loss: 2.796060098888083

Epoch: 6| Step: 6
Training loss: 0.7089004677126183
Validation loss: 2.768115816759277

Epoch: 6| Step: 7
Training loss: 0.4919257149005016
Validation loss: 2.75297905213589

Epoch: 6| Step: 8
Training loss: 0.47666210947103527
Validation loss: 2.841222750948042

Epoch: 6| Step: 9
Training loss: 0.5041857099746019
Validation loss: 2.8802370112522238

Epoch: 6| Step: 10
Training loss: 0.4550270412080922
Validation loss: 2.8536730058609514

Epoch: 6| Step: 11
Training loss: 0.30282109156841724
Validation loss: 2.9230267707676765

Epoch: 6| Step: 12
Training loss: 0.7851869188078983
Validation loss: 2.9291648568102118

Epoch: 6| Step: 13
Training loss: 0.5558254496984242
Validation loss: 2.8126954046114765

Epoch: 219| Step: 0
Training loss: 0.5030311556186411
Validation loss: 2.8701333859646243

Epoch: 6| Step: 1
Training loss: 0.8386725132108693
Validation loss: 2.7942709423585406

Epoch: 6| Step: 2
Training loss: 0.35024048938813096
Validation loss: 2.815992193520989

Epoch: 6| Step: 3
Training loss: 0.4387968630909396
Validation loss: 2.835022665804455

Epoch: 6| Step: 4
Training loss: 1.3564035671503336
Validation loss: 2.8684221705086554

Epoch: 6| Step: 5
Training loss: 0.73957195183678
Validation loss: 2.781468129265893

Epoch: 6| Step: 6
Training loss: 0.4183189493659908
Validation loss: 2.865138791879476

Epoch: 6| Step: 7
Training loss: 0.3059523810098099
Validation loss: 2.782138568222645

Epoch: 6| Step: 8
Training loss: 0.6836756411956426
Validation loss: 2.8170146029383534

Epoch: 6| Step: 9
Training loss: 0.5520145055464801
Validation loss: 2.830236022911112

Epoch: 6| Step: 10
Training loss: 0.6113361443429312
Validation loss: 2.891891531945457

Epoch: 6| Step: 11
Training loss: 0.44162169405954727
Validation loss: 2.9030203837039243

Epoch: 6| Step: 12
Training loss: 0.5626129460851937
Validation loss: 2.7502557317718366

Epoch: 6| Step: 13
Training loss: 0.38908383567555943
Validation loss: 2.781019822786279

Epoch: 220| Step: 0
Training loss: 0.7215705758126513
Validation loss: 2.902876013189199

Epoch: 6| Step: 1
Training loss: 0.5997166242579206
Validation loss: 2.7455233202575875

Epoch: 6| Step: 2
Training loss: 0.47942602007939844
Validation loss: 2.778575840324386

Epoch: 6| Step: 3
Training loss: 0.43525734074782213
Validation loss: 2.723026741174842

Epoch: 6| Step: 4
Training loss: 0.4087272090565873
Validation loss: 2.8057008292310472

Epoch: 6| Step: 5
Training loss: 0.3829998803375097
Validation loss: 2.806350002758419

Epoch: 6| Step: 6
Training loss: 0.45572403677823353
Validation loss: 2.7331647974096245

Epoch: 6| Step: 7
Training loss: 0.39786892882523023
Validation loss: 2.81431660794265

Epoch: 6| Step: 8
Training loss: 0.39203393520927127
Validation loss: 2.7697297577946802

Epoch: 6| Step: 9
Training loss: 0.45762937483146054
Validation loss: 2.81114433959585

Epoch: 6| Step: 10
Training loss: 0.5497770692112027
Validation loss: 2.824904686099133

Epoch: 6| Step: 11
Training loss: 0.49220239525917053
Validation loss: 2.867349174854279

Epoch: 6| Step: 12
Training loss: 1.4051251044862545
Validation loss: 2.8439451297424356

Epoch: 6| Step: 13
Training loss: 0.3873064411410261
Validation loss: 2.871472627375905

Epoch: 221| Step: 0
Training loss: 0.49435836156342555
Validation loss: 2.8569971004841226

Epoch: 6| Step: 1
Training loss: 1.3951686396237202
Validation loss: 2.9027927987431514

Epoch: 6| Step: 2
Training loss: 0.5357263410437968
Validation loss: 2.8705354247156265

Epoch: 6| Step: 3
Training loss: 0.5527791251140045
Validation loss: 2.828949037214431

Epoch: 6| Step: 4
Training loss: 0.3338280027296903
Validation loss: 2.9295690080204473

Epoch: 6| Step: 5
Training loss: 0.3281646772646109
Validation loss: 2.7996935290688154

Epoch: 6| Step: 6
Training loss: 0.425390046314585
Validation loss: 2.7911158393111477

Epoch: 6| Step: 7
Training loss: 0.49727469029220595
Validation loss: 2.860960272533954

Epoch: 6| Step: 8
Training loss: 0.3475467209316784
Validation loss: 2.880497789697826

Epoch: 6| Step: 9
Training loss: 0.4325452619914645
Validation loss: 2.8379682515837046

Epoch: 6| Step: 10
Training loss: 0.7796181993895845
Validation loss: 2.864882565677427

Epoch: 6| Step: 11
Training loss: 0.5139238443027526
Validation loss: 2.8518564569161775

Epoch: 6| Step: 12
Training loss: 0.40635127859190207
Validation loss: 2.950909962909235

Epoch: 6| Step: 13
Training loss: 0.3035441980450569
Validation loss: 2.905052581000468

Epoch: 222| Step: 0
Training loss: 0.6133985953836991
Validation loss: 2.8441780522727096

Epoch: 6| Step: 1
Training loss: 0.4637080672551806
Validation loss: 2.940153046644558

Epoch: 6| Step: 2
Training loss: 1.3682732330920306
Validation loss: 2.7937152425152796

Epoch: 6| Step: 3
Training loss: 0.5418780782363559
Validation loss: 2.8923285885605936

Epoch: 6| Step: 4
Training loss: 0.41262120286915693
Validation loss: 2.8731723864309027

Epoch: 6| Step: 5
Training loss: 0.6347719162849287
Validation loss: 2.7449504268318146

Epoch: 6| Step: 6
Training loss: 0.5775046757925744
Validation loss: 2.7875305442105964

Epoch: 6| Step: 7
Training loss: 0.47315415253516657
Validation loss: 2.8422498274294297

Epoch: 6| Step: 8
Training loss: 0.6339297616014878
Validation loss: 2.821622732608694

Epoch: 6| Step: 9
Training loss: 0.5939461484462245
Validation loss: 2.8568003724529087

Epoch: 6| Step: 10
Training loss: 0.46925326987312627
Validation loss: 2.8751000787758834

Epoch: 6| Step: 11
Training loss: 0.5661435011108238
Validation loss: 2.968561427501971

Epoch: 6| Step: 12
Training loss: 0.6916315606028605
Validation loss: 2.917983470847273

Epoch: 6| Step: 13
Training loss: 0.4375929903932187
Validation loss: 2.789987092050935

Epoch: 223| Step: 0
Training loss: 0.5013970586469825
Validation loss: 2.8202862936477224

Epoch: 6| Step: 1
Training loss: 0.7563367809599836
Validation loss: 2.814186819529836

Epoch: 6| Step: 2
Training loss: 0.8499995596267457
Validation loss: 2.8033574597987068

Epoch: 6| Step: 3
Training loss: 0.46413062395160526
Validation loss: 2.824374161661272

Epoch: 6| Step: 4
Training loss: 0.5454952272683645
Validation loss: 2.9377224208954895

Epoch: 6| Step: 5
Training loss: 0.4887205970193117
Validation loss: 2.846084488881482

Epoch: 6| Step: 6
Training loss: 1.331549280401364
Validation loss: 2.9774662091067086

Epoch: 6| Step: 7
Training loss: 0.575659132576092
Validation loss: 2.9472858756052

Epoch: 6| Step: 8
Training loss: 0.5505594659228673
Validation loss: 2.8189891341582896

Epoch: 6| Step: 9
Training loss: 0.5098610273514873
Validation loss: 2.8470727700394285

Epoch: 6| Step: 10
Training loss: 0.4165591955661992
Validation loss: 2.875605657609606

Epoch: 6| Step: 11
Training loss: 0.4626559535846579
Validation loss: 2.8422741116718355

Epoch: 6| Step: 12
Training loss: 0.4441974130525106
Validation loss: 2.8777117172556768

Epoch: 6| Step: 13
Training loss: 0.531493243460715
Validation loss: 2.783770615573162

Epoch: 224| Step: 0
Training loss: 0.5846548919719053
Validation loss: 2.911706798963259

Epoch: 6| Step: 1
Training loss: 1.2698087887734857
Validation loss: 2.7894659810147693

Epoch: 6| Step: 2
Training loss: 0.49212709692018236
Validation loss: 2.7287064278292994

Epoch: 6| Step: 3
Training loss: 0.4731097764673939
Validation loss: 2.793494484956012

Epoch: 6| Step: 4
Training loss: 0.5530416221062031
Validation loss: 2.784277764480308

Epoch: 6| Step: 5
Training loss: 0.4934774630491624
Validation loss: 2.8270452837443814

Epoch: 6| Step: 6
Training loss: 0.41364492197095654
Validation loss: 2.8871064775284037

Epoch: 6| Step: 7
Training loss: 0.4057002382489775
Validation loss: 2.916468849739956

Epoch: 6| Step: 8
Training loss: 0.4961544810690824
Validation loss: 2.957411868796844

Epoch: 6| Step: 9
Training loss: 0.46279792018285393
Validation loss: 2.9103108955956976

Epoch: 6| Step: 10
Training loss: 0.6886657022166015
Validation loss: 2.8590365489221563

Epoch: 6| Step: 11
Training loss: 0.6184642478706146
Validation loss: 2.80624013727688

Epoch: 6| Step: 12
Training loss: 0.2657502664383479
Validation loss: 2.732058897488506

Epoch: 6| Step: 13
Training loss: 0.6356166123743575
Validation loss: 2.779297832918661

Epoch: 225| Step: 0
Training loss: 0.41662452802565536
Validation loss: 2.7540008889388248

Epoch: 6| Step: 1
Training loss: 0.7190279630467921
Validation loss: 2.8217595721379

Epoch: 6| Step: 2
Training loss: 0.4590965945448026
Validation loss: 2.9339575273178204

Epoch: 6| Step: 3
Training loss: 0.4642242663456008
Validation loss: 2.862553620703833

Epoch: 6| Step: 4
Training loss: 1.3383847848511903
Validation loss: 2.879672413933258

Epoch: 6| Step: 5
Training loss: 0.7058910006017969
Validation loss: 2.89969468592313

Epoch: 6| Step: 6
Training loss: 0.5700222478674076
Validation loss: 2.8916477490410024

Epoch: 6| Step: 7
Training loss: 0.4980425366979405
Validation loss: 2.842724499924985

Epoch: 6| Step: 8
Training loss: 0.6546492808983161
Validation loss: 2.9443896911336633

Epoch: 6| Step: 9
Training loss: 0.5758030373580312
Validation loss: 2.7778709401296684

Epoch: 6| Step: 10
Training loss: 0.7981651558329707
Validation loss: 2.822227637927382

Epoch: 6| Step: 11
Training loss: 0.32721160734277616
Validation loss: 2.8238571308331553

Epoch: 6| Step: 12
Training loss: 0.5582875299407477
Validation loss: 2.9341368123899088

Epoch: 6| Step: 13
Training loss: 0.549940129836209
Validation loss: 2.8038046464769026

Epoch: 226| Step: 0
Training loss: 0.4965822413021157
Validation loss: 2.8209680867842644

Epoch: 6| Step: 1
Training loss: 0.7015830616815852
Validation loss: 2.9170563482910685

Epoch: 6| Step: 2
Training loss: 0.7320808939349445
Validation loss: 2.853468772508765

Epoch: 6| Step: 3
Training loss: 0.41229656000046144
Validation loss: 2.8814602017354645

Epoch: 6| Step: 4
Training loss: 0.42801047693780847
Validation loss: 2.7543251097826174

Epoch: 6| Step: 5
Training loss: 0.6440985411990069
Validation loss: 2.7579040079901636

Epoch: 6| Step: 6
Training loss: 0.4916784136252488
Validation loss: 2.76695687790331

Epoch: 6| Step: 7
Training loss: 0.48100565553203317
Validation loss: 2.8398935487658226

Epoch: 6| Step: 8
Training loss: 1.3221030649531529
Validation loss: 2.8829830570647106

Epoch: 6| Step: 9
Training loss: 0.3055515630718895
Validation loss: 2.8936165116282417

Epoch: 6| Step: 10
Training loss: 0.5278390042305805
Validation loss: 2.8719943271180695

Epoch: 6| Step: 11
Training loss: 0.5005995910425683
Validation loss: 2.815683837456513

Epoch: 6| Step: 12
Training loss: 0.5531758678343789
Validation loss: 2.896555273140506

Epoch: 6| Step: 13
Training loss: 0.646524157265281
Validation loss: 2.8797624230189585

Epoch: 227| Step: 0
Training loss: 0.7389205505961949
Validation loss: 2.8735404663555437

Epoch: 6| Step: 1
Training loss: 0.5070488102345134
Validation loss: 2.782047071789532

Epoch: 6| Step: 2
Training loss: 0.625692984729475
Validation loss: 2.760836894359954

Epoch: 6| Step: 3
Training loss: 0.5719656825474968
Validation loss: 2.717404321169429

Epoch: 6| Step: 4
Training loss: 0.5690334818782273
Validation loss: 2.735097277478705

Epoch: 6| Step: 5
Training loss: 0.5764071226746759
Validation loss: 2.775683987723749

Epoch: 6| Step: 6
Training loss: 0.4360307819279463
Validation loss: 2.744887396767493

Epoch: 6| Step: 7
Training loss: 0.56417898100801
Validation loss: 2.895754467738726

Epoch: 6| Step: 8
Training loss: 0.5435056159142557
Validation loss: 2.868711394006597

Epoch: 6| Step: 9
Training loss: 0.6368489512618574
Validation loss: 2.9317097512773778

Epoch: 6| Step: 10
Training loss: 1.3866621838705033
Validation loss: 2.9085608425254654

Epoch: 6| Step: 11
Training loss: 0.5935681215092155
Validation loss: 2.837947129914194

Epoch: 6| Step: 12
Training loss: 0.5888087305309293
Validation loss: 2.8501182068743995

Epoch: 6| Step: 13
Training loss: 0.5237721469448399
Validation loss: 2.7628641662380646

Epoch: 228| Step: 0
Training loss: 0.5858722396111657
Validation loss: 2.802461227593436

Epoch: 6| Step: 1
Training loss: 0.42221324218157125
Validation loss: 2.7514741154457805

Epoch: 6| Step: 2
Training loss: 0.7116972248997196
Validation loss: 2.7386783342779957

Epoch: 6| Step: 3
Training loss: 0.5856818086312814
Validation loss: 2.7641095824658612

Epoch: 6| Step: 4
Training loss: 0.6736549486619392
Validation loss: 2.8157203886786166

Epoch: 6| Step: 5
Training loss: 0.6641769310586052
Validation loss: 2.8593198426977087

Epoch: 6| Step: 6
Training loss: 0.5275683454558705
Validation loss: 2.8772250977287976

Epoch: 6| Step: 7
Training loss: 0.5829129293602364
Validation loss: 2.884009342842471

Epoch: 6| Step: 8
Training loss: 0.5168474329800999
Validation loss: 2.839926962002844

Epoch: 6| Step: 9
Training loss: 0.34649473817760407
Validation loss: 2.8449661253536553

Epoch: 6| Step: 10
Training loss: 0.483700713621287
Validation loss: 2.822164052787641

Epoch: 6| Step: 11
Training loss: 0.7281255009858205
Validation loss: 2.7829996527642926

Epoch: 6| Step: 12
Training loss: 0.5826935807880228
Validation loss: 2.7472688377401724

Epoch: 6| Step: 13
Training loss: 1.3980291185852867
Validation loss: 2.822653491901085

Epoch: 229| Step: 0
Training loss: 0.4230847145410162
Validation loss: 2.7954231699456

Epoch: 6| Step: 1
Training loss: 0.5781116999565464
Validation loss: 2.8509017805951693

Epoch: 6| Step: 2
Training loss: 0.6393816908619585
Validation loss: 2.90945827639475

Epoch: 6| Step: 3
Training loss: 0.6320985604976949
Validation loss: 2.9092736461124584

Epoch: 6| Step: 4
Training loss: 0.5867618610985739
Validation loss: 2.9417670756017587

Epoch: 6| Step: 5
Training loss: 0.510808703319872
Validation loss: 2.816622658297346

Epoch: 6| Step: 6
Training loss: 0.5992654814520684
Validation loss: 2.8336199073225763

Epoch: 6| Step: 7
Training loss: 0.6276707330333301
Validation loss: 2.831309722539966

Epoch: 6| Step: 8
Training loss: 0.5081695475177089
Validation loss: 2.758358217878161

Epoch: 6| Step: 9
Training loss: 1.3863587677837452
Validation loss: 2.8458798017007947

Epoch: 6| Step: 10
Training loss: 0.4581433646670272
Validation loss: 2.8162209515541594

Epoch: 6| Step: 11
Training loss: 0.657023042679735
Validation loss: 2.809578147844552

Epoch: 6| Step: 12
Training loss: 0.6107918577914966
Validation loss: 2.7982543442350836

Epoch: 6| Step: 13
Training loss: 0.5486516159599784
Validation loss: 2.810164986990019

Epoch: 230| Step: 0
Training loss: 0.49176359844265927
Validation loss: 2.8297237141856577

Epoch: 6| Step: 1
Training loss: 0.6322300903485861
Validation loss: 2.8730069868031802

Epoch: 6| Step: 2
Training loss: 0.3887939836391268
Validation loss: 2.818812400200483

Epoch: 6| Step: 3
Training loss: 0.7312288868130283
Validation loss: 2.812658234842734

Epoch: 6| Step: 4
Training loss: 0.45191212816835885
Validation loss: 2.7242557419195417

Epoch: 6| Step: 5
Training loss: 0.7115029821353483
Validation loss: 2.8573855373656034

Epoch: 6| Step: 6
Training loss: 1.3812729190633783
Validation loss: 2.8193951609229

Epoch: 6| Step: 7
Training loss: 0.3431617623839915
Validation loss: 2.845525236379927

Epoch: 6| Step: 8
Training loss: 0.5340411409288804
Validation loss: 2.85371789861562

Epoch: 6| Step: 9
Training loss: 0.3614809280208078
Validation loss: 2.7463275923812662

Epoch: 6| Step: 10
Training loss: 0.48265885312559925
Validation loss: 2.7600914145732465

Epoch: 6| Step: 11
Training loss: 0.4767279884796038
Validation loss: 2.8385066925600673

Epoch: 6| Step: 12
Training loss: 0.3316639383162287
Validation loss: 2.823212384058162

Epoch: 6| Step: 13
Training loss: 0.2685697377929433
Validation loss: 2.8654550000665893

Epoch: 231| Step: 0
Training loss: 0.46513735690844976
Validation loss: 2.89930984791167

Epoch: 6| Step: 1
Training loss: 0.6570335433502633
Validation loss: 2.855185533386368

Epoch: 6| Step: 2
Training loss: 0.3822207645840044
Validation loss: 2.8092709407127194

Epoch: 6| Step: 3
Training loss: 0.5310069818594458
Validation loss: 2.8478941432133844

Epoch: 6| Step: 4
Training loss: 0.6029408504835476
Validation loss: 2.8663193915588097

Epoch: 6| Step: 5
Training loss: 0.46888014258338606
Validation loss: 2.7295835239730795

Epoch: 6| Step: 6
Training loss: 0.48799607150654056
Validation loss: 2.8542834534152677

Epoch: 6| Step: 7
Training loss: 0.5070453424361512
Validation loss: 2.789272895236016

Epoch: 6| Step: 8
Training loss: 0.42411226864635615
Validation loss: 2.775885061650314

Epoch: 6| Step: 9
Training loss: 0.5108649432725763
Validation loss: 2.812648190020465

Epoch: 6| Step: 10
Training loss: 0.5913425123974568
Validation loss: 2.870995635347892

Epoch: 6| Step: 11
Training loss: 0.46618174480297464
Validation loss: 2.8547186120587127

Epoch: 6| Step: 12
Training loss: 1.3061857016038263
Validation loss: 2.874092083084279

Epoch: 6| Step: 13
Training loss: 0.5528745170296188
Validation loss: 2.909078363415008

Epoch: 232| Step: 0
Training loss: 0.5464820812687103
Validation loss: 2.8204264102661725

Epoch: 6| Step: 1
Training loss: 0.3425947848611192
Validation loss: 2.854907758706907

Epoch: 6| Step: 2
Training loss: 0.578541013172162
Validation loss: 2.8547525616661127

Epoch: 6| Step: 3
Training loss: 0.6056625056192956
Validation loss: 2.884653056950206

Epoch: 6| Step: 4
Training loss: 0.39107312247499826
Validation loss: 2.8175894993645403

Epoch: 6| Step: 5
Training loss: 0.7502600695790091
Validation loss: 2.819648460206141

Epoch: 6| Step: 6
Training loss: 0.3764595397496416
Validation loss: 2.880371480026603

Epoch: 6| Step: 7
Training loss: 0.32709312540732516
Validation loss: 2.877935417522538

Epoch: 6| Step: 8
Training loss: 1.3110708903125905
Validation loss: 2.794428417719375

Epoch: 6| Step: 9
Training loss: 0.3911981954799175
Validation loss: 2.9221585929995646

Epoch: 6| Step: 10
Training loss: 0.5551476517582377
Validation loss: 2.842973302614083

Epoch: 6| Step: 11
Training loss: 0.463728649131175
Validation loss: 2.8852493476325964

Epoch: 6| Step: 12
Training loss: 0.3642606147065157
Validation loss: 2.840201822730124

Epoch: 6| Step: 13
Training loss: 0.5240504533341904
Validation loss: 2.880055226308643

Epoch: 233| Step: 0
Training loss: 0.6979556476088239
Validation loss: 2.889752546735963

Epoch: 6| Step: 1
Training loss: 0.5126438660013855
Validation loss: 2.902257426001982

Epoch: 6| Step: 2
Training loss: 1.313305652943125
Validation loss: 2.855903616727624

Epoch: 6| Step: 3
Training loss: 0.39938371165270564
Validation loss: 2.81144809125062

Epoch: 6| Step: 4
Training loss: 0.6232599832689283
Validation loss: 2.857454360147993

Epoch: 6| Step: 5
Training loss: 0.4366775001875806
Validation loss: 2.8344355337344407

Epoch: 6| Step: 6
Training loss: 0.447454837272952
Validation loss: 2.859931877676522

Epoch: 6| Step: 7
Training loss: 0.492383781532021
Validation loss: 2.8825873930586927

Epoch: 6| Step: 8
Training loss: 0.48550618278149477
Validation loss: 2.806925781035273

Epoch: 6| Step: 9
Training loss: 0.48374106854811305
Validation loss: 2.797542300616127

Epoch: 6| Step: 10
Training loss: 0.542331211491361
Validation loss: 2.7443440390207026

Epoch: 6| Step: 11
Training loss: 0.6071006931562367
Validation loss: 2.91059580647318

Epoch: 6| Step: 12
Training loss: 0.43254419404180033
Validation loss: 2.8697263060578972

Epoch: 6| Step: 13
Training loss: 0.5491888415249786
Validation loss: 2.829455995068194

Epoch: 234| Step: 0
Training loss: 0.5653763714625483
Validation loss: 2.8255510929204264

Epoch: 6| Step: 1
Training loss: 0.3976386420467948
Validation loss: 2.858495177384964

Epoch: 6| Step: 2
Training loss: 0.3681143972557094
Validation loss: 2.803100406080961

Epoch: 6| Step: 3
Training loss: 0.4890127272461077
Validation loss: 2.823112485693343

Epoch: 6| Step: 4
Training loss: 0.5537712696718042
Validation loss: 2.793781260145559

Epoch: 6| Step: 5
Training loss: 0.4350697765347383
Validation loss: 2.758851126813855

Epoch: 6| Step: 6
Training loss: 0.4662269720573064
Validation loss: 2.7970358662011092

Epoch: 6| Step: 7
Training loss: 1.2724618274981299
Validation loss: 2.7489752449613065

Epoch: 6| Step: 8
Training loss: 0.5794011542415742
Validation loss: 2.7797126521573117

Epoch: 6| Step: 9
Training loss: 0.6132307335524847
Validation loss: 2.873535785442706

Epoch: 6| Step: 10
Training loss: 0.5304152156912872
Validation loss: 2.9218031114516636

Epoch: 6| Step: 11
Training loss: 0.39939706854821344
Validation loss: 2.8767574785035386

Epoch: 6| Step: 12
Training loss: 0.6300835104875938
Validation loss: 2.871291533078284

Epoch: 6| Step: 13
Training loss: 0.4823854409486871
Validation loss: 2.9057379103945724

Epoch: 235| Step: 0
Training loss: 0.4653999463182557
Validation loss: 2.834637388556651

Epoch: 6| Step: 1
Training loss: 0.6271699904662018
Validation loss: 2.87496790660692

Epoch: 6| Step: 2
Training loss: 0.5650906246221018
Validation loss: 2.827330040246254

Epoch: 6| Step: 3
Training loss: 0.7047676818973256
Validation loss: 2.883182491553743

Epoch: 6| Step: 4
Training loss: 0.5266764056335428
Validation loss: 2.849449691847789

Epoch: 6| Step: 5
Training loss: 0.703270091875368
Validation loss: 2.8817163466507805

Epoch: 6| Step: 6
Training loss: 0.6512867021377761
Validation loss: 2.9687951000870303

Epoch: 6| Step: 7
Training loss: 0.7795239645899841
Validation loss: 3.077371689068458

Epoch: 6| Step: 8
Training loss: 0.7685786513745316
Validation loss: 2.935553426559694

Epoch: 6| Step: 9
Training loss: 0.3926021511639831
Validation loss: 2.9138632289466586

Epoch: 6| Step: 10
Training loss: 0.40721529206338875
Validation loss: 2.838286184776854

Epoch: 6| Step: 11
Training loss: 0.4496043830548059
Validation loss: 2.779199079775397

Epoch: 6| Step: 12
Training loss: 0.40971481546434996
Validation loss: 2.7958127354082474

Epoch: 6| Step: 13
Training loss: 1.4313213413898764
Validation loss: 2.71997982286468

Epoch: 236| Step: 0
Training loss: 1.3414161730639769
Validation loss: 2.7782430931940736

Epoch: 6| Step: 1
Training loss: 0.5610020082407211
Validation loss: 2.796260915503856

Epoch: 6| Step: 2
Training loss: 0.5933165222726012
Validation loss: 2.84455739950209

Epoch: 6| Step: 3
Training loss: 0.3468901733997574
Validation loss: 2.919675478538435

Epoch: 6| Step: 4
Training loss: 0.5748455752452377
Validation loss: 2.8860935743833465

Epoch: 6| Step: 5
Training loss: 0.6394215654660879
Validation loss: 2.9948661109406776

Epoch: 6| Step: 6
Training loss: 0.40343183772030944
Validation loss: 2.900640111740148

Epoch: 6| Step: 7
Training loss: 0.42535300110331864
Validation loss: 2.8378080254068485

Epoch: 6| Step: 8
Training loss: 0.44066936458958306
Validation loss: 2.8168067947119217

Epoch: 6| Step: 9
Training loss: 0.26906807119469917
Validation loss: 2.7474862082322957

Epoch: 6| Step: 10
Training loss: 0.4190736942943833
Validation loss: 2.856466554742062

Epoch: 6| Step: 11
Training loss: 0.4420004364740797
Validation loss: 2.8513775769894143

Epoch: 6| Step: 12
Training loss: 0.8257192539701088
Validation loss: 2.7744657088040996

Epoch: 6| Step: 13
Training loss: 0.5451253968963193
Validation loss: 2.8278816497809536

Epoch: 237| Step: 0
Training loss: 0.42597126002030805
Validation loss: 2.8569862518647366

Epoch: 6| Step: 1
Training loss: 1.2705910352679175
Validation loss: 2.985332834611175

Epoch: 6| Step: 2
Training loss: 0.6168977805881334
Validation loss: 2.9436036134945365

Epoch: 6| Step: 3
Training loss: 0.6446497028049242
Validation loss: 2.997724265966604

Epoch: 6| Step: 4
Training loss: 0.6406022974969334
Validation loss: 3.0218949305111504

Epoch: 6| Step: 5
Training loss: 0.6143204940569172
Validation loss: 2.93734238925455

Epoch: 6| Step: 6
Training loss: 0.42488444664765296
Validation loss: 2.9100906125716226

Epoch: 6| Step: 7
Training loss: 0.5873709881944477
Validation loss: 2.8252475565354147

Epoch: 6| Step: 8
Training loss: 0.6084902282343986
Validation loss: 2.85528259087999

Epoch: 6| Step: 9
Training loss: 0.7729392325165275
Validation loss: 2.8725709190279307

Epoch: 6| Step: 10
Training loss: 0.48524245142875405
Validation loss: 2.804084323356139

Epoch: 6| Step: 11
Training loss: 0.40981100174800306
Validation loss: 2.828141003417651

Epoch: 6| Step: 12
Training loss: 0.5459994800935443
Validation loss: 2.977072043872425

Epoch: 6| Step: 13
Training loss: 0.658300918875616
Validation loss: 2.9795598835414223

Epoch: 238| Step: 0
Training loss: 1.4219870889938695
Validation loss: 3.0185994712940842

Epoch: 6| Step: 1
Training loss: 0.6705117256368163
Validation loss: 3.013148778486478

Epoch: 6| Step: 2
Training loss: 0.5785891757241374
Validation loss: 2.977775933809168

Epoch: 6| Step: 3
Training loss: 0.4261364111755807
Validation loss: 2.912074388395774

Epoch: 6| Step: 4
Training loss: 0.3484028290062191
Validation loss: 2.803552743347908

Epoch: 6| Step: 5
Training loss: 0.8489083741510961
Validation loss: 2.780114631507833

Epoch: 6| Step: 6
Training loss: 0.8552516156549032
Validation loss: 2.8225517928645547

Epoch: 6| Step: 7
Training loss: 0.3677045347361546
Validation loss: 2.8032354990125596

Epoch: 6| Step: 8
Training loss: 0.5362164652726985
Validation loss: 2.8027685573146024

Epoch: 6| Step: 9
Training loss: 0.40695572956062415
Validation loss: 2.8145832893791356

Epoch: 6| Step: 10
Training loss: 0.6278978401995052
Validation loss: 2.8660622241352423

Epoch: 6| Step: 11
Training loss: 0.7734263255535495
Validation loss: 2.896850549072756

Epoch: 6| Step: 12
Training loss: 0.29904410093386047
Validation loss: 2.7883849901642366

Epoch: 6| Step: 13
Training loss: 0.4598237175163619
Validation loss: 2.91839909646274

Epoch: 239| Step: 0
Training loss: 0.3258427884278012
Validation loss: 2.8146175889745515

Epoch: 6| Step: 1
Training loss: 1.3627385149429614
Validation loss: 2.792834142184411

Epoch: 6| Step: 2
Training loss: 0.4113249884591785
Validation loss: 2.9010352517587266

Epoch: 6| Step: 3
Training loss: 0.312374936350724
Validation loss: 2.835061911075693

Epoch: 6| Step: 4
Training loss: 0.31676420520762905
Validation loss: 2.7854736489682828

Epoch: 6| Step: 5
Training loss: 0.4027556560824833
Validation loss: 2.8645429065048043

Epoch: 6| Step: 6
Training loss: 0.4706249884495221
Validation loss: 2.7998906789737164

Epoch: 6| Step: 7
Training loss: 0.5592513581772309
Validation loss: 2.831521048353819

Epoch: 6| Step: 8
Training loss: 0.4090533004437348
Validation loss: 2.7969727170557137

Epoch: 6| Step: 9
Training loss: 0.5079827243428101
Validation loss: 2.760779466119833

Epoch: 6| Step: 10
Training loss: 0.3921534200504364
Validation loss: 2.932085742574503

Epoch: 6| Step: 11
Training loss: 0.41072056414561914
Validation loss: 2.773655025924292

Epoch: 6| Step: 12
Training loss: 0.6496958644634921
Validation loss: 2.8328461835976384

Epoch: 6| Step: 13
Training loss: 0.5402029661369736
Validation loss: 2.8673121038069467

Epoch: 240| Step: 0
Training loss: 0.34608957275211927
Validation loss: 2.8258541115713394

Epoch: 6| Step: 1
Training loss: 0.39392099300699013
Validation loss: 2.772822911038647

Epoch: 6| Step: 2
Training loss: 0.5888663271364725
Validation loss: 2.809253669922179

Epoch: 6| Step: 3
Training loss: 0.5069032010701126
Validation loss: 2.889525635759106

Epoch: 6| Step: 4
Training loss: 1.2784869942867005
Validation loss: 2.8474789718195335

Epoch: 6| Step: 5
Training loss: 0.5274495336608821
Validation loss: 2.863567343206223

Epoch: 6| Step: 6
Training loss: 0.5397079584057624
Validation loss: 2.8839170412679223

Epoch: 6| Step: 7
Training loss: 0.46660581373638893
Validation loss: 2.9204599010264145

Epoch: 6| Step: 8
Training loss: 0.4323306027844322
Validation loss: 2.8209383931357

Epoch: 6| Step: 9
Training loss: 0.5883657873440208
Validation loss: 2.8900151889670274

Epoch: 6| Step: 10
Training loss: 0.42483313454276267
Validation loss: 2.8792445597805756

Epoch: 6| Step: 11
Training loss: 0.6148482306776409
Validation loss: 2.8785838028944823

Epoch: 6| Step: 12
Training loss: 0.3803221410314523
Validation loss: 2.8400703770017093

Epoch: 6| Step: 13
Training loss: 0.42924844678665536
Validation loss: 2.8260535562735956

Epoch: 241| Step: 0
Training loss: 1.2570820458523273
Validation loss: 2.8390423021173663

Epoch: 6| Step: 1
Training loss: 0.6660800578253467
Validation loss: 2.8523925966531127

Epoch: 6| Step: 2
Training loss: 0.4524317074449809
Validation loss: 2.8241751752334823

Epoch: 6| Step: 3
Training loss: 0.4962803947595573
Validation loss: 2.92641159350155

Epoch: 6| Step: 4
Training loss: 0.42264273334544095
Validation loss: 2.8400283186803565

Epoch: 6| Step: 5
Training loss: 0.5494549792662669
Validation loss: 2.7736837788155486

Epoch: 6| Step: 6
Training loss: 0.48549464244813295
Validation loss: 2.8390224691202564

Epoch: 6| Step: 7
Training loss: 0.5741624609936665
Validation loss: 2.844224771404789

Epoch: 6| Step: 8
Training loss: 0.2998957914917945
Validation loss: 2.8185014484043807

Epoch: 6| Step: 9
Training loss: 0.4770004105306254
Validation loss: 2.8542222808839997

Epoch: 6| Step: 10
Training loss: 0.619724660077618
Validation loss: 2.9638777119398876

Epoch: 6| Step: 11
Training loss: 0.4400488989924712
Validation loss: 2.8235710108254457

Epoch: 6| Step: 12
Training loss: 0.5034453775842093
Validation loss: 2.913357442287608

Epoch: 6| Step: 13
Training loss: 0.622105667810294
Validation loss: 2.850284920777788

Epoch: 242| Step: 0
Training loss: 0.48928345633971276
Validation loss: 2.8273116851391027

Epoch: 6| Step: 1
Training loss: 0.7497863465212523
Validation loss: 2.869774437014349

Epoch: 6| Step: 2
Training loss: 0.4764233995893459
Validation loss: 2.863661854815364

Epoch: 6| Step: 3
Training loss: 0.5787706378445634
Validation loss: 2.85859955937109

Epoch: 6| Step: 4
Training loss: 0.42984810341974267
Validation loss: 2.8212675835643606

Epoch: 6| Step: 5
Training loss: 0.4654354528917659
Validation loss: 2.8253173801754228

Epoch: 6| Step: 6
Training loss: 0.4253084900363573
Validation loss: 2.965313887146724

Epoch: 6| Step: 7
Training loss: 0.48745413344365407
Validation loss: 2.854251447286264

Epoch: 6| Step: 8
Training loss: 0.2732306651807426
Validation loss: 2.850006975198877

Epoch: 6| Step: 9
Training loss: 1.2502130803647042
Validation loss: 2.88009798322556

Epoch: 6| Step: 10
Training loss: 0.4150610525252175
Validation loss: 2.7842047065922886

Epoch: 6| Step: 11
Training loss: 0.5428551205081126
Validation loss: 2.8992610559963476

Epoch: 6| Step: 12
Training loss: 0.5115682366013969
Validation loss: 2.8091837369871113

Epoch: 6| Step: 13
Training loss: 0.5365120080064447
Validation loss: 2.827375266946607

Epoch: 243| Step: 0
Training loss: 0.3561042303373424
Validation loss: 2.781397819162676

Epoch: 6| Step: 1
Training loss: 0.4241342449850194
Validation loss: 2.841040259945534

Epoch: 6| Step: 2
Training loss: 0.4334362534420512
Validation loss: 2.76983517520203

Epoch: 6| Step: 3
Training loss: 0.4743321554967304
Validation loss: 2.843930319075071

Epoch: 6| Step: 4
Training loss: 0.39824563436994953
Validation loss: 2.860591580978679

Epoch: 6| Step: 5
Training loss: 1.2516015283640487
Validation loss: 2.851487487085027

Epoch: 6| Step: 6
Training loss: 0.36713289301215896
Validation loss: 2.8340321455087873

Epoch: 6| Step: 7
Training loss: 0.5905237131210613
Validation loss: 2.829916061980788

Epoch: 6| Step: 8
Training loss: 0.40394248726062165
Validation loss: 2.8044588780354975

Epoch: 6| Step: 9
Training loss: 0.4899534507215349
Validation loss: 2.824202682146907

Epoch: 6| Step: 10
Training loss: 0.5046070459917169
Validation loss: 2.8199201259844524

Epoch: 6| Step: 11
Training loss: 0.6876952370944492
Validation loss: 2.812736133976494

Epoch: 6| Step: 12
Training loss: 0.6161571062034373
Validation loss: 2.781385189871212

Epoch: 6| Step: 13
Training loss: 0.7063299252006443
Validation loss: 2.790553658695915

Epoch: 244| Step: 0
Training loss: 0.5436349527829862
Validation loss: 2.783626127166271

Epoch: 6| Step: 1
Training loss: 0.4413645733088179
Validation loss: 2.9278711953320764

Epoch: 6| Step: 2
Training loss: 0.5964509865959783
Validation loss: 2.881967960144272

Epoch: 6| Step: 3
Training loss: 0.7889638782471232
Validation loss: 2.9586723876580927

Epoch: 6| Step: 4
Training loss: 0.7775798036642859
Validation loss: 2.918493180340682

Epoch: 6| Step: 5
Training loss: 0.4706015259561145
Validation loss: 2.893723622717494

Epoch: 6| Step: 6
Training loss: 0.40843134072058807
Validation loss: 2.803910426713071

Epoch: 6| Step: 7
Training loss: 0.713910687291496
Validation loss: 2.825823780232283

Epoch: 6| Step: 8
Training loss: 0.3517683380263619
Validation loss: 2.852431770108264

Epoch: 6| Step: 9
Training loss: 0.5092786311629821
Validation loss: 2.7427789207924698

Epoch: 6| Step: 10
Training loss: 0.49487559125459774
Validation loss: 2.881279362813702

Epoch: 6| Step: 11
Training loss: 0.4657248953095339
Validation loss: 2.9022680369410954

Epoch: 6| Step: 12
Training loss: 1.2953162419871358
Validation loss: 2.8492034908911488

Epoch: 6| Step: 13
Training loss: 0.4835887495777641
Validation loss: 2.879594476459595

Epoch: 245| Step: 0
Training loss: 0.40167606840698505
Validation loss: 2.841645940069269

Epoch: 6| Step: 1
Training loss: 0.3974109215161477
Validation loss: 2.788913341704623

Epoch: 6| Step: 2
Training loss: 0.4638759893284997
Validation loss: 2.898252606385497

Epoch: 6| Step: 3
Training loss: 0.3430048387001272
Validation loss: 2.835405774531207

Epoch: 6| Step: 4
Training loss: 0.4901819391057996
Validation loss: 2.8719561953130546

Epoch: 6| Step: 5
Training loss: 0.4255023007538001
Validation loss: 2.801747147105586

Epoch: 6| Step: 6
Training loss: 1.3734856415905243
Validation loss: 2.8264688099885147

Epoch: 6| Step: 7
Training loss: 0.44213314463690384
Validation loss: 2.8184195917631163

Epoch: 6| Step: 8
Training loss: 0.5545645026724656
Validation loss: 2.898450935380614

Epoch: 6| Step: 9
Training loss: 0.49811746433641474
Validation loss: 2.891654290127904

Epoch: 6| Step: 10
Training loss: 0.5100835050210641
Validation loss: 2.915056374486212

Epoch: 6| Step: 11
Training loss: 0.36903609960643263
Validation loss: 2.944523240980412

Epoch: 6| Step: 12
Training loss: 0.5372528994141629
Validation loss: 2.869557730572206

Epoch: 6| Step: 13
Training loss: 0.5868793801011178
Validation loss: 2.86539658995427

Epoch: 246| Step: 0
Training loss: 0.4005557208333503
Validation loss: 2.8333167935804915

Epoch: 6| Step: 1
Training loss: 0.2959589125269402
Validation loss: 2.826795107252098

Epoch: 6| Step: 2
Training loss: 0.3189885527715348
Validation loss: 2.9032061370800863

Epoch: 6| Step: 3
Training loss: 0.4981858452283823
Validation loss: 2.713580233152801

Epoch: 6| Step: 4
Training loss: 0.47671939268415825
Validation loss: 2.806462532893437

Epoch: 6| Step: 5
Training loss: 0.3972971998361844
Validation loss: 2.743613601341335

Epoch: 6| Step: 6
Training loss: 1.293399566145742
Validation loss: 2.7809636115023446

Epoch: 6| Step: 7
Training loss: 0.38958888925408763
Validation loss: 2.738776103756711

Epoch: 6| Step: 8
Training loss: 0.24757735803881967
Validation loss: 2.8631852547173775

Epoch: 6| Step: 9
Training loss: 0.5081252675448719
Validation loss: 2.9848565450432467

Epoch: 6| Step: 10
Training loss: 0.4502964857696669
Validation loss: 2.816123422644392

Epoch: 6| Step: 11
Training loss: 0.6365851747784391
Validation loss: 2.8627956337666687

Epoch: 6| Step: 12
Training loss: 0.6702142194355655
Validation loss: 2.828468189527488

Epoch: 6| Step: 13
Training loss: 0.4783965604920801
Validation loss: 2.7176554146280325

Epoch: 247| Step: 0
Training loss: 0.2645009604708823
Validation loss: 2.7524876902227335

Epoch: 6| Step: 1
Training loss: 0.41676570986753064
Validation loss: 2.761505046743404

Epoch: 6| Step: 2
Training loss: 0.5066255048085297
Validation loss: 2.753097769017668

Epoch: 6| Step: 3
Training loss: 0.5065627638988526
Validation loss: 2.806749094453401

Epoch: 6| Step: 4
Training loss: 0.563337179891256
Validation loss: 2.7762419298567966

Epoch: 6| Step: 5
Training loss: 0.518347661131083
Validation loss: 2.7533395314858833

Epoch: 6| Step: 6
Training loss: 0.5307481583281668
Validation loss: 2.8959963270097346

Epoch: 6| Step: 7
Training loss: 0.46346127066481224
Validation loss: 2.863456731105339

Epoch: 6| Step: 8
Training loss: 0.557900699085947
Validation loss: 2.859054992223398

Epoch: 6| Step: 9
Training loss: 0.621866812723984
Validation loss: 2.863894741641491

Epoch: 6| Step: 10
Training loss: 0.4870701074259436
Validation loss: 2.796411344431869

Epoch: 6| Step: 11
Training loss: 1.3155183599387728
Validation loss: 2.8814358202412618

Epoch: 6| Step: 12
Training loss: 0.6891899795425352
Validation loss: 2.789277254557778

Epoch: 6| Step: 13
Training loss: 0.5847190140142594
Validation loss: 2.840988635018844

Epoch: 248| Step: 0
Training loss: 0.34507567367045766
Validation loss: 2.903020082568766

Epoch: 6| Step: 1
Training loss: 0.3918606478969584
Validation loss: 2.892616754240007

Epoch: 6| Step: 2
Training loss: 0.4291564954861015
Validation loss: 2.977925159731704

Epoch: 6| Step: 3
Training loss: 0.6764007330916441
Validation loss: 2.928443244350673

Epoch: 6| Step: 4
Training loss: 0.7152846597342497
Validation loss: 2.9133795243827136

Epoch: 6| Step: 5
Training loss: 0.5140659575650428
Validation loss: 2.868698941332534

Epoch: 6| Step: 6
Training loss: 1.29361392978005
Validation loss: 2.764697147336886

Epoch: 6| Step: 7
Training loss: 0.4718267870897721
Validation loss: 2.8558931813695603

Epoch: 6| Step: 8
Training loss: 0.5686303505435096
Validation loss: 2.838963935077445

Epoch: 6| Step: 9
Training loss: 0.5867024832145502
Validation loss: 2.8685100529870073

Epoch: 6| Step: 10
Training loss: 0.6485772269581238
Validation loss: 2.8767267238658447

Epoch: 6| Step: 11
Training loss: 0.5443733489912642
Validation loss: 2.900929739326436

Epoch: 6| Step: 12
Training loss: 0.4754735042197692
Validation loss: 2.796780774679965

Epoch: 6| Step: 13
Training loss: 0.517111341049392
Validation loss: 2.8982360715013415

Epoch: 249| Step: 0
Training loss: 0.6916615074225738
Validation loss: 2.965466219125467

Epoch: 6| Step: 1
Training loss: 0.6796349252997261
Validation loss: 2.9493213088369337

Epoch: 6| Step: 2
Training loss: 0.5097339371811263
Validation loss: 2.922805651520724

Epoch: 6| Step: 3
Training loss: 0.40434299887748004
Validation loss: 2.878829451234944

Epoch: 6| Step: 4
Training loss: 0.6486939991501279
Validation loss: 2.7603305923189723

Epoch: 6| Step: 5
Training loss: 0.4383503619694991
Validation loss: 2.836266532705179

Epoch: 6| Step: 6
Training loss: 0.5259749555935059
Validation loss: 2.7574899140787688

Epoch: 6| Step: 7
Training loss: 0.5620988899191492
Validation loss: 2.7632412452523405

Epoch: 6| Step: 8
Training loss: 1.2600566202642116
Validation loss: 2.8338247368594356

Epoch: 6| Step: 9
Training loss: 0.48917194762728805
Validation loss: 2.7892769625119254

Epoch: 6| Step: 10
Training loss: 0.34773026439300053
Validation loss: 2.856996822314909

Epoch: 6| Step: 11
Training loss: 0.3907978057099843
Validation loss: 2.878088701746181

Epoch: 6| Step: 12
Training loss: 0.5779373276731808
Validation loss: 2.91750064007584

Epoch: 6| Step: 13
Training loss: 0.43510780955183814
Validation loss: 3.036273817647146

Epoch: 250| Step: 0
Training loss: 1.1657816845512525
Validation loss: 2.8083612861336382

Epoch: 6| Step: 1
Training loss: 0.4677100407400026
Validation loss: 2.8914382752764203

Epoch: 6| Step: 2
Training loss: 0.5200508502250905
Validation loss: 2.8727241436852013

Epoch: 6| Step: 3
Training loss: 0.41289947124954557
Validation loss: 2.8642030821915836

Epoch: 6| Step: 4
Training loss: 0.4777237860565836
Validation loss: 2.7859656400430732

Epoch: 6| Step: 5
Training loss: 0.33890058369382253
Validation loss: 2.773348410164982

Epoch: 6| Step: 6
Training loss: 0.37872681842654216
Validation loss: 2.8733336415552504

Epoch: 6| Step: 7
Training loss: 0.3466264280860005
Validation loss: 2.879683066696036

Epoch: 6| Step: 8
Training loss: 0.564966516093335
Validation loss: 2.834472474003188

Epoch: 6| Step: 9
Training loss: 0.5471209381768496
Validation loss: 2.92827384242024

Epoch: 6| Step: 10
Training loss: 0.35365907909249034
Validation loss: 2.954350360240102

Epoch: 6| Step: 11
Training loss: 0.3568396490328923
Validation loss: 2.9757076848221575

Epoch: 6| Step: 12
Training loss: 0.6919020259992364
Validation loss: 2.8685515551886436

Epoch: 6| Step: 13
Training loss: 0.4461457337456461
Validation loss: 2.9597624742943354

Epoch: 251| Step: 0
Training loss: 0.5552856551311254
Validation loss: 2.8576904643459256

Epoch: 6| Step: 1
Training loss: 0.4127011321741135
Validation loss: 2.8880678568051104

Epoch: 6| Step: 2
Training loss: 0.408377705891136
Validation loss: 2.832267397100454

Epoch: 6| Step: 3
Training loss: 0.6592643852921105
Validation loss: 2.7805570389215113

Epoch: 6| Step: 4
Training loss: 0.35235914463152235
Validation loss: 2.8682897875943927

Epoch: 6| Step: 5
Training loss: 1.196117553872735
Validation loss: 2.932874365323272

Epoch: 6| Step: 6
Training loss: 0.48332969099623585
Validation loss: 2.933997087989026

Epoch: 6| Step: 7
Training loss: 0.5205686150799783
Validation loss: 2.8410866110853497

Epoch: 6| Step: 8
Training loss: 0.6421187593744591
Validation loss: 2.9301370233473767

Epoch: 6| Step: 9
Training loss: 0.4506227197999445
Validation loss: 2.917116584590136

Epoch: 6| Step: 10
Training loss: 0.37866081075242747
Validation loss: 2.8158127524903356

Epoch: 6| Step: 11
Training loss: 0.48885831683863057
Validation loss: 2.805803847158466

Epoch: 6| Step: 12
Training loss: 0.7203465435067742
Validation loss: 2.793312432188925

Epoch: 6| Step: 13
Training loss: 0.5867873577127742
Validation loss: 2.7824425730073097

Epoch: 252| Step: 0
Training loss: 0.5012801590786282
Validation loss: 2.790124571650076

Epoch: 6| Step: 1
Training loss: 0.5686149153788953
Validation loss: 2.8702391306180663

Epoch: 6| Step: 2
Training loss: 0.4878211333093103
Validation loss: 2.893960077008199

Epoch: 6| Step: 3
Training loss: 0.4597773418375793
Validation loss: 2.892688708753347

Epoch: 6| Step: 4
Training loss: 1.1730490334840593
Validation loss: 2.898185588792083

Epoch: 6| Step: 5
Training loss: 0.5724168649222268
Validation loss: 2.8652493113080992

Epoch: 6| Step: 6
Training loss: 0.3576625159811721
Validation loss: 2.8693798667441572

Epoch: 6| Step: 7
Training loss: 0.5325493909648062
Validation loss: 2.8076462294693605

Epoch: 6| Step: 8
Training loss: 0.4368893926320762
Validation loss: 2.8546672344967403

Epoch: 6| Step: 9
Training loss: 0.2634081192420948
Validation loss: 2.869848431939092

Epoch: 6| Step: 10
Training loss: 0.302655215835183
Validation loss: 2.8509314966757073

Epoch: 6| Step: 11
Training loss: 0.4720216384308156
Validation loss: 2.841370198137614

Epoch: 6| Step: 12
Training loss: 0.46294520253535293
Validation loss: 2.7971601571710027

Epoch: 6| Step: 13
Training loss: 0.4893725902064442
Validation loss: 2.7985222794218036

Epoch: 253| Step: 0
Training loss: 0.3746663834807207
Validation loss: 2.9599100173770543

Epoch: 6| Step: 1
Training loss: 0.445838684275712
Validation loss: 2.9663420833586196

Epoch: 6| Step: 2
Training loss: 0.4793466009011342
Validation loss: 2.8740625373409237

Epoch: 6| Step: 3
Training loss: 0.44419714468236243
Validation loss: 2.8678414467815996

Epoch: 6| Step: 4
Training loss: 0.43407839246840296
Validation loss: 2.8976487888580555

Epoch: 6| Step: 5
Training loss: 0.5098309822132228
Validation loss: 2.8745869325975706

Epoch: 6| Step: 6
Training loss: 0.24994500866710131
Validation loss: 2.815412172211639

Epoch: 6| Step: 7
Training loss: 0.4238824589792149
Validation loss: 2.794619696965278

Epoch: 6| Step: 8
Training loss: 0.3567336496991807
Validation loss: 2.7686457973875247

Epoch: 6| Step: 9
Training loss: 0.6506360252611517
Validation loss: 2.8338341176892463

Epoch: 6| Step: 10
Training loss: 0.21662033041022538
Validation loss: 2.822294213525277

Epoch: 6| Step: 11
Training loss: 0.6750442587506404
Validation loss: 2.7498510638278333

Epoch: 6| Step: 12
Training loss: 1.1849842024607256
Validation loss: 2.78452942060008

Epoch: 6| Step: 13
Training loss: 0.4684737663150607
Validation loss: 2.843952996131569

Epoch: 254| Step: 0
Training loss: 0.5864853904088272
Validation loss: 2.7723296912501407

Epoch: 6| Step: 1
Training loss: 0.5541680012115624
Validation loss: 2.8831894790911536

Epoch: 6| Step: 2
Training loss: 0.4680301861564658
Validation loss: 2.887299213887212

Epoch: 6| Step: 3
Training loss: 0.38791206508055615
Validation loss: 2.8310239627254727

Epoch: 6| Step: 4
Training loss: 1.264181656284436
Validation loss: 2.862874153482969

Epoch: 6| Step: 5
Training loss: 0.39647469720163203
Validation loss: 2.803110952919785

Epoch: 6| Step: 6
Training loss: 0.4231211307410705
Validation loss: 2.9030382190623447

Epoch: 6| Step: 7
Training loss: 0.6821866185125369
Validation loss: 2.8293492598641157

Epoch: 6| Step: 8
Training loss: 0.4232948921739847
Validation loss: 2.805091580863892

Epoch: 6| Step: 9
Training loss: 0.42845845010566597
Validation loss: 2.7322857386332893

Epoch: 6| Step: 10
Training loss: 0.34755503863547305
Validation loss: 2.8773304712736776

Epoch: 6| Step: 11
Training loss: 0.4263764517140677
Validation loss: 2.9010928073578204

Epoch: 6| Step: 12
Training loss: 0.5222314348349493
Validation loss: 2.8899800036353454

Epoch: 6| Step: 13
Training loss: 0.368713394061478
Validation loss: 2.7747305850965054

Epoch: 255| Step: 0
Training loss: 0.46401575219098373
Validation loss: 2.83668830397886

Epoch: 6| Step: 1
Training loss: 0.38181572199623615
Validation loss: 2.824226882381171

Epoch: 6| Step: 2
Training loss: 0.4478842109927565
Validation loss: 2.8693133242268707

Epoch: 6| Step: 3
Training loss: 0.3869303692650647
Validation loss: 2.90779629114694

Epoch: 6| Step: 4
Training loss: 1.1988612831976861
Validation loss: 2.808627422415645

Epoch: 6| Step: 5
Training loss: 0.35170350955598245
Validation loss: 2.839483197117218

Epoch: 6| Step: 6
Training loss: 0.5578374477759398
Validation loss: 2.855175415502486

Epoch: 6| Step: 7
Training loss: 0.3905717813478966
Validation loss: 2.8208210240991893

Epoch: 6| Step: 8
Training loss: 0.47718927721593196
Validation loss: 2.7916718003714505

Epoch: 6| Step: 9
Training loss: 0.35618673900624026
Validation loss: 2.9252707320770943

Epoch: 6| Step: 10
Training loss: 0.4560796661397963
Validation loss: 2.816258822112778

Epoch: 6| Step: 11
Training loss: 0.5168792901097482
Validation loss: 2.8747337190351856

Epoch: 6| Step: 12
Training loss: 0.48567546574900194
Validation loss: 3.014197372337777

Epoch: 6| Step: 13
Training loss: 0.3653721269121988
Validation loss: 2.854937600112495

Epoch: 256| Step: 0
Training loss: 0.34292966320134655
Validation loss: 2.841221688036226

Epoch: 6| Step: 1
Training loss: 0.4136589170737243
Validation loss: 2.8137790032316508

Epoch: 6| Step: 2
Training loss: 0.2809546297174257
Validation loss: 2.832350635277134

Epoch: 6| Step: 3
Training loss: 0.400556874069487
Validation loss: 2.8202913940428953

Epoch: 6| Step: 4
Training loss: 0.48074466257410553
Validation loss: 2.7959775283930974

Epoch: 6| Step: 5
Training loss: 0.6680911883299678
Validation loss: 2.8182780923134994

Epoch: 6| Step: 6
Training loss: 0.5304234750834627
Validation loss: 2.854817341797594

Epoch: 6| Step: 7
Training loss: 0.5791904066100768
Validation loss: 2.763117513783813

Epoch: 6| Step: 8
Training loss: 0.6203227505929951
Validation loss: 2.83451098389605

Epoch: 6| Step: 9
Training loss: 0.44109688104051337
Validation loss: 2.746585691548487

Epoch: 6| Step: 10
Training loss: 0.40658949458163435
Validation loss: 2.8429475986706887

Epoch: 6| Step: 11
Training loss: 1.2192064555348927
Validation loss: 2.7551494560849497

Epoch: 6| Step: 12
Training loss: 0.5282349579236048
Validation loss: 2.8838130382829097

Epoch: 6| Step: 13
Training loss: 0.54719185505544
Validation loss: 2.934958488023485

Epoch: 257| Step: 0
Training loss: 0.32644063190547806
Validation loss: 2.878756115059784

Epoch: 6| Step: 1
Training loss: 0.3199060815771773
Validation loss: 2.8378634327904773

Epoch: 6| Step: 2
Training loss: 1.2433554478810114
Validation loss: 2.8310146427644978

Epoch: 6| Step: 3
Training loss: 0.5010377426416776
Validation loss: 2.8050726269291513

Epoch: 6| Step: 4
Training loss: 0.5683755774007414
Validation loss: 2.8128315624196754

Epoch: 6| Step: 5
Training loss: 0.4326758764684701
Validation loss: 2.820510392365822

Epoch: 6| Step: 6
Training loss: 0.3859098432260703
Validation loss: 2.8656676904569207

Epoch: 6| Step: 7
Training loss: 0.41901841670670104
Validation loss: 2.824123354576211

Epoch: 6| Step: 8
Training loss: 0.44779969691564026
Validation loss: 2.9781885386490767

Epoch: 6| Step: 9
Training loss: 0.44532454624948486
Validation loss: 2.869590729165289

Epoch: 6| Step: 10
Training loss: 0.5489056081141002
Validation loss: 2.83477160936025

Epoch: 6| Step: 11
Training loss: 0.3765543275951433
Validation loss: 2.896613452767915

Epoch: 6| Step: 12
Training loss: 0.5832587489629987
Validation loss: 2.7664404491259487

Epoch: 6| Step: 13
Training loss: 0.44628832794062223
Validation loss: 2.8225353917216633

Epoch: 258| Step: 0
Training loss: 0.5131382364106143
Validation loss: 2.853719987281181

Epoch: 6| Step: 1
Training loss: 1.1833171962031732
Validation loss: 2.8878348691671336

Epoch: 6| Step: 2
Training loss: 0.46147168450886233
Validation loss: 2.849770345971807

Epoch: 6| Step: 3
Training loss: 0.36565171331648194
Validation loss: 2.857179253777785

Epoch: 6| Step: 4
Training loss: 0.4624276723238888
Validation loss: 2.876579044535515

Epoch: 6| Step: 5
Training loss: 0.38681674447799647
Validation loss: 2.826723794884661

Epoch: 6| Step: 6
Training loss: 0.4841699319943848
Validation loss: 2.987958025437051

Epoch: 6| Step: 7
Training loss: 0.40210301873175147
Validation loss: 2.809792253613891

Epoch: 6| Step: 8
Training loss: 0.4508932334865958
Validation loss: 2.826698477366629

Epoch: 6| Step: 9
Training loss: 0.4188391633261123
Validation loss: 2.878847864353469

Epoch: 6| Step: 10
Training loss: 0.3884503102050772
Validation loss: 2.8852280556263183

Epoch: 6| Step: 11
Training loss: 0.5470469885542133
Validation loss: 2.8143477410223245

Epoch: 6| Step: 12
Training loss: 0.5520034918242736
Validation loss: 2.84374730316146

Epoch: 6| Step: 13
Training loss: 0.26971505297302817
Validation loss: 2.863630675071215

Epoch: 259| Step: 0
Training loss: 0.34681930954105666
Validation loss: 2.8663241327777436

Epoch: 6| Step: 1
Training loss: 0.3802263917510113
Validation loss: 2.908095413102319

Epoch: 6| Step: 2
Training loss: 0.43461488645173174
Validation loss: 2.90444961621655

Epoch: 6| Step: 3
Training loss: 0.2976485263893717
Validation loss: 2.8562131816736405

Epoch: 6| Step: 4
Training loss: 0.5938226504801853
Validation loss: 2.7903311699691127

Epoch: 6| Step: 5
Training loss: 0.42533560713222013
Validation loss: 2.8383930739027257

Epoch: 6| Step: 6
Training loss: 0.6155542420131487
Validation loss: 2.864950639700078

Epoch: 6| Step: 7
Training loss: 0.31450069849515894
Validation loss: 2.9100740084025505

Epoch: 6| Step: 8
Training loss: 0.6218220501311178
Validation loss: 2.8454957431342875

Epoch: 6| Step: 9
Training loss: 0.4670356714288873
Validation loss: 2.861600235812446

Epoch: 6| Step: 10
Training loss: 1.1267885719368445
Validation loss: 2.8824292818136192

Epoch: 6| Step: 11
Training loss: 0.41210603034664484
Validation loss: 2.9312259822205813

Epoch: 6| Step: 12
Training loss: 0.5504133470229662
Validation loss: 2.907438110541308

Epoch: 6| Step: 13
Training loss: 0.30894464751010564
Validation loss: 2.8141988780179767

Epoch: 260| Step: 0
Training loss: 0.5126352329474607
Validation loss: 2.8759332469016305

Epoch: 6| Step: 1
Training loss: 0.39300889251927607
Validation loss: 2.827752427768393

Epoch: 6| Step: 2
Training loss: 0.49683298017256167
Validation loss: 2.8086115483271383

Epoch: 6| Step: 3
Training loss: 0.45078402936531464
Validation loss: 2.876255286569833

Epoch: 6| Step: 4
Training loss: 0.3987436614235316
Validation loss: 2.8449414450681934

Epoch: 6| Step: 5
Training loss: 0.48305223185903484
Validation loss: 2.881063052806132

Epoch: 6| Step: 6
Training loss: 0.25606435470896316
Validation loss: 2.855262230512043

Epoch: 6| Step: 7
Training loss: 0.373455762217107
Validation loss: 2.8409306170486097

Epoch: 6| Step: 8
Training loss: 0.36366145429421853
Validation loss: 2.892256254137692

Epoch: 6| Step: 9
Training loss: 0.5169196204376244
Validation loss: 2.9940868620867938

Epoch: 6| Step: 10
Training loss: 0.4788810735808758
Validation loss: 2.832052675363459

Epoch: 6| Step: 11
Training loss: 0.40317549426231286
Validation loss: 2.839741155353202

Epoch: 6| Step: 12
Training loss: 0.5348979298650506
Validation loss: 2.8173252816058874

Epoch: 6| Step: 13
Training loss: 1.2050484478973387
Validation loss: 2.8979589130568333

Epoch: 261| Step: 0
Training loss: 0.34667474447675456
Validation loss: 2.748346525229615

Epoch: 6| Step: 1
Training loss: 0.5646895867009919
Validation loss: 2.8344229164545496

Epoch: 6| Step: 2
Training loss: 0.478261794673172
Validation loss: 2.8613718699994366

Epoch: 6| Step: 3
Training loss: 0.328777255317286
Validation loss: 2.904950429019614

Epoch: 6| Step: 4
Training loss: 0.4543115765988208
Validation loss: 2.8579769086534483

Epoch: 6| Step: 5
Training loss: 0.4376767176261846
Validation loss: 2.8606312394610636

Epoch: 6| Step: 6
Training loss: 0.5231044335919965
Validation loss: 2.9300885142213495

Epoch: 6| Step: 7
Training loss: 0.6125786273469193
Validation loss: 2.9171201262605457

Epoch: 6| Step: 8
Training loss: 0.5248866447052761
Validation loss: 2.8541018253581165

Epoch: 6| Step: 9
Training loss: 0.2956615418760003
Validation loss: 2.945232656730626

Epoch: 6| Step: 10
Training loss: 0.3637176476671715
Validation loss: 2.8657519551938027

Epoch: 6| Step: 11
Training loss: 0.35392183602140737
Validation loss: 2.9156805460423514

Epoch: 6| Step: 12
Training loss: 0.46123572578156136
Validation loss: 2.845485451148495

Epoch: 6| Step: 13
Training loss: 1.1584527967218456
Validation loss: 2.9161379789117303

Epoch: 262| Step: 0
Training loss: 0.35038194592464056
Validation loss: 2.9631656258423877

Epoch: 6| Step: 1
Training loss: 0.19122573553692693
Validation loss: 2.873318332388089

Epoch: 6| Step: 2
Training loss: 0.39290768279683097
Validation loss: 2.8728706795098766

Epoch: 6| Step: 3
Training loss: 0.3746983188852063
Validation loss: 2.904855496133141

Epoch: 6| Step: 4
Training loss: 0.6576221970043618
Validation loss: 2.8900183788625937

Epoch: 6| Step: 5
Training loss: 0.48799834638944684
Validation loss: 2.8678981167179827

Epoch: 6| Step: 6
Training loss: 0.48737414214828456
Validation loss: 2.833528432486778

Epoch: 6| Step: 7
Training loss: 0.3490935628212818
Validation loss: 2.861380160642992

Epoch: 6| Step: 8
Training loss: 0.34280554031498633
Validation loss: 2.858902702862376

Epoch: 6| Step: 9
Training loss: 1.1596172377883853
Validation loss: 2.8409895861232393

Epoch: 6| Step: 10
Training loss: 0.4176441964673213
Validation loss: 2.9332456826711697

Epoch: 6| Step: 11
Training loss: 0.44512908906244875
Validation loss: 2.8531514030424256

Epoch: 6| Step: 12
Training loss: 0.3801958809298369
Validation loss: 2.864039592578471

Epoch: 6| Step: 13
Training loss: 0.3232355952671112
Validation loss: 2.900097682557371

Epoch: 263| Step: 0
Training loss: 0.4985866538714067
Validation loss: 2.8377399864043626

Epoch: 6| Step: 1
Training loss: 0.35127506161605665
Validation loss: 2.9276937931939084

Epoch: 6| Step: 2
Training loss: 0.4720592353856403
Validation loss: 2.8636472987598776

Epoch: 6| Step: 3
Training loss: 0.44170750828010324
Validation loss: 2.8725298760622557

Epoch: 6| Step: 4
Training loss: 0.39638645860992866
Validation loss: 2.8419268216795084

Epoch: 6| Step: 5
Training loss: 0.5478328762845573
Validation loss: 2.8567972567416304

Epoch: 6| Step: 6
Training loss: 0.5412065465192143
Validation loss: 2.835715026816479

Epoch: 6| Step: 7
Training loss: 0.46846319007284254
Validation loss: 2.8467680457717313

Epoch: 6| Step: 8
Training loss: 0.5356136233124205
Validation loss: 2.94007540143349

Epoch: 6| Step: 9
Training loss: 0.33377981334927465
Validation loss: 2.9674785434447464

Epoch: 6| Step: 10
Training loss: 0.2830860158889386
Validation loss: 2.8998251692370887

Epoch: 6| Step: 11
Training loss: 0.5365991839586437
Validation loss: 2.9406949652828884

Epoch: 6| Step: 12
Training loss: 0.5060107325048956
Validation loss: 2.9488329906678667

Epoch: 6| Step: 13
Training loss: 1.0708640132521683
Validation loss: 2.897282290503968

Epoch: 264| Step: 0
Training loss: 0.5727931380758629
Validation loss: 2.986252638447212

Epoch: 6| Step: 1
Training loss: 1.172202102785774
Validation loss: 2.915864797900097

Epoch: 6| Step: 2
Training loss: 0.34436596605875325
Validation loss: 2.97206811020111

Epoch: 6| Step: 3
Training loss: 0.4004290306466237
Validation loss: 2.9137912245574884

Epoch: 6| Step: 4
Training loss: 0.3492954805636829
Validation loss: 2.9217357364316277

Epoch: 6| Step: 5
Training loss: 0.5008512046384381
Validation loss: 2.9762665608989507

Epoch: 6| Step: 6
Training loss: 0.4203637570463752
Validation loss: 2.866107082272505

Epoch: 6| Step: 7
Training loss: 0.4531875106838879
Validation loss: 2.78207069603967

Epoch: 6| Step: 8
Training loss: 0.3816531395007282
Validation loss: 2.864153497987703

Epoch: 6| Step: 9
Training loss: 0.6441463592810752
Validation loss: 2.903584286617663

Epoch: 6| Step: 10
Training loss: 0.3894254577053143
Validation loss: 2.8769438295199103

Epoch: 6| Step: 11
Training loss: 0.4210685156230685
Validation loss: 2.868795042993313

Epoch: 6| Step: 12
Training loss: 0.3043600915316493
Validation loss: 2.89840393869552

Epoch: 6| Step: 13
Training loss: 0.5341945276517795
Validation loss: 2.924790612358314

Epoch: 265| Step: 0
Training loss: 0.3739352607870411
Validation loss: 2.936999251248562

Epoch: 6| Step: 1
Training loss: 0.5457681626684606
Validation loss: 2.9596034712716994

Epoch: 6| Step: 2
Training loss: 0.4136521807513165
Validation loss: 2.922313133750675

Epoch: 6| Step: 3
Training loss: 0.37145637061684017
Validation loss: 2.837439259398545

Epoch: 6| Step: 4
Training loss: 0.37882560186318787
Validation loss: 2.8741209372442773

Epoch: 6| Step: 5
Training loss: 0.5122371697445746
Validation loss: 2.859751219744216

Epoch: 6| Step: 6
Training loss: 0.5093350985760249
Validation loss: 2.897739117190746

Epoch: 6| Step: 7
Training loss: 0.4256614201461864
Validation loss: 2.8701128263592888

Epoch: 6| Step: 8
Training loss: 0.48369043952018115
Validation loss: 2.9552993439483095

Epoch: 6| Step: 9
Training loss: 0.4900685368017577
Validation loss: 2.9125271759075106

Epoch: 6| Step: 10
Training loss: 1.265223639626109
Validation loss: 2.9791586326721986

Epoch: 6| Step: 11
Training loss: 0.5622599407384163
Validation loss: 2.901052154211587

Epoch: 6| Step: 12
Training loss: 0.2715783402549786
Validation loss: 2.9043718237271556

Epoch: 6| Step: 13
Training loss: 0.4442850607784846
Validation loss: 2.9990372304993587

Epoch: 266| Step: 0
Training loss: 1.1335368504299512
Validation loss: 2.8654729167000252

Epoch: 6| Step: 1
Training loss: 0.30707503484635534
Validation loss: 2.8672447510702104

Epoch: 6| Step: 2
Training loss: 0.5670406077777747
Validation loss: 2.8616203289098006

Epoch: 6| Step: 3
Training loss: 0.5955674564148524
Validation loss: 2.8486300784361522

Epoch: 6| Step: 4
Training loss: 0.3822146437730585
Validation loss: 2.9066629560764787

Epoch: 6| Step: 5
Training loss: 0.4369014323783195
Validation loss: 2.930042540335804

Epoch: 6| Step: 6
Training loss: 0.5575049399255417
Validation loss: 2.9500971481792724

Epoch: 6| Step: 7
Training loss: 0.49835802718233085
Validation loss: 2.9939975559188117

Epoch: 6| Step: 8
Training loss: 0.4838057834290602
Validation loss: 3.018207175849714

Epoch: 6| Step: 9
Training loss: 0.5594380273953925
Validation loss: 2.9674964935401995

Epoch: 6| Step: 10
Training loss: 0.44644100682786353
Validation loss: 2.9435593086351353

Epoch: 6| Step: 11
Training loss: 0.4929244261824442
Validation loss: 2.9171507751517862

Epoch: 6| Step: 12
Training loss: 0.513961768209079
Validation loss: 2.8441582690596614

Epoch: 6| Step: 13
Training loss: 0.48155444844599127
Validation loss: 2.8875546619476267

Epoch: 267| Step: 0
Training loss: 0.41491907517083426
Validation loss: 2.935522915659252

Epoch: 6| Step: 1
Training loss: 0.45254769216186513
Validation loss: 2.895840834646778

Epoch: 6| Step: 2
Training loss: 0.5681122442477445
Validation loss: 2.925635707275773

Epoch: 6| Step: 3
Training loss: 0.6337553229851427
Validation loss: 2.9659400491218197

Epoch: 6| Step: 4
Training loss: 1.0734191693069317
Validation loss: 2.929168411044546

Epoch: 6| Step: 5
Training loss: 0.3691978813857111
Validation loss: 2.909526741504121

Epoch: 6| Step: 6
Training loss: 0.4396328367891129
Validation loss: 2.790508497368646

Epoch: 6| Step: 7
Training loss: 0.6304998170366861
Validation loss: 2.8847799229767963

Epoch: 6| Step: 8
Training loss: 0.5118283452907134
Validation loss: 2.815612229555717

Epoch: 6| Step: 9
Training loss: 0.5794966380916234
Validation loss: 2.842306490338962

Epoch: 6| Step: 10
Training loss: 0.4273721912132184
Validation loss: 2.9327311528067743

Epoch: 6| Step: 11
Training loss: 0.46826278479557193
Validation loss: 2.8886232610587754

Epoch: 6| Step: 12
Training loss: 0.529270354447589
Validation loss: 3.0226356303850253

Epoch: 6| Step: 13
Training loss: 0.45937765600773084
Validation loss: 2.9385177256138415

Epoch: 268| Step: 0
Training loss: 0.3312205796402224
Validation loss: 2.8936427816764465

Epoch: 6| Step: 1
Training loss: 0.48425072952436127
Validation loss: 2.9134569808841673

Epoch: 6| Step: 2
Training loss: 1.0971585160015025
Validation loss: 2.876862047337411

Epoch: 6| Step: 3
Training loss: 0.3496556491169892
Validation loss: 2.947652816197532

Epoch: 6| Step: 4
Training loss: 0.498421292654354
Validation loss: 2.8389193548976106

Epoch: 6| Step: 5
Training loss: 0.3141461052330006
Validation loss: 2.89635740427569

Epoch: 6| Step: 6
Training loss: 0.5711216607951121
Validation loss: 2.8707710897916825

Epoch: 6| Step: 7
Training loss: 0.4749272228002
Validation loss: 2.841703551902296

Epoch: 6| Step: 8
Training loss: 0.4580081541145531
Validation loss: 2.859293215612149

Epoch: 6| Step: 9
Training loss: 0.3570652208924017
Validation loss: 2.9106908388277235

Epoch: 6| Step: 10
Training loss: 0.46004694237851235
Validation loss: 2.8511219607554192

Epoch: 6| Step: 11
Training loss: 0.5084544305966039
Validation loss: 2.9124592315701987

Epoch: 6| Step: 12
Training loss: 0.5777301986780677
Validation loss: 2.949899018170307

Epoch: 6| Step: 13
Training loss: 0.5285389107750224
Validation loss: 2.8737467231748397

Epoch: 269| Step: 0
Training loss: 0.4310724653165407
Validation loss: 2.887692711744792

Epoch: 6| Step: 1
Training loss: 1.1441997269264539
Validation loss: 2.958155711756286

Epoch: 6| Step: 2
Training loss: 0.38805340197123434
Validation loss: 2.9014308446960353

Epoch: 6| Step: 3
Training loss: 0.49605507587261755
Validation loss: 2.9005616690981166

Epoch: 6| Step: 4
Training loss: 0.27170978766078796
Validation loss: 2.8785130833168386

Epoch: 6| Step: 5
Training loss: 0.4872337396686863
Validation loss: 2.81502318052569

Epoch: 6| Step: 6
Training loss: 0.48476855379337236
Validation loss: 2.7736251982452833

Epoch: 6| Step: 7
Training loss: 0.38543634965829177
Validation loss: 2.8859489078568195

Epoch: 6| Step: 8
Training loss: 0.29817654749837424
Validation loss: 2.8189117813767948

Epoch: 6| Step: 9
Training loss: 0.42399228340450507
Validation loss: 2.904141998095029

Epoch: 6| Step: 10
Training loss: 0.5646089648895443
Validation loss: 2.9179686546751222

Epoch: 6| Step: 11
Training loss: 0.5212434362094283
Validation loss: 2.9990699174020845

Epoch: 6| Step: 12
Training loss: 0.7729616338873831
Validation loss: 2.95382752715922

Epoch: 6| Step: 13
Training loss: 0.508694015674925
Validation loss: 2.7836529784245356

Epoch: 270| Step: 0
Training loss: 0.3614614086221845
Validation loss: 2.8934566340857715

Epoch: 6| Step: 1
Training loss: 0.49300409120812033
Validation loss: 2.8583395773445934

Epoch: 6| Step: 2
Training loss: 0.607994275994712
Validation loss: 2.892432299090645

Epoch: 6| Step: 3
Training loss: 0.5628869527131793
Validation loss: 2.9667087162623864

Epoch: 6| Step: 4
Training loss: 0.5686987948161234
Validation loss: 2.8994840393153374

Epoch: 6| Step: 5
Training loss: 0.35951350487025835
Validation loss: 2.8691533388981836

Epoch: 6| Step: 6
Training loss: 1.1589646818919832
Validation loss: 2.867960646328743

Epoch: 6| Step: 7
Training loss: 0.5300512814454033
Validation loss: 2.8917505633214935

Epoch: 6| Step: 8
Training loss: 0.31064954296147823
Validation loss: 2.9773690373349413

Epoch: 6| Step: 9
Training loss: 0.4899465620329616
Validation loss: 2.9294588533823576

Epoch: 6| Step: 10
Training loss: 0.3649824773161909
Validation loss: 2.9468719779060106

Epoch: 6| Step: 11
Training loss: 0.3793595738550461
Validation loss: 2.874386832598658

Epoch: 6| Step: 12
Training loss: 0.4628469551186134
Validation loss: 2.9216549904418256

Epoch: 6| Step: 13
Training loss: 0.5182819115971186
Validation loss: 2.771646657524745

Epoch: 271| Step: 0
Training loss: 0.35699124268601806
Validation loss: 2.867318949860742

Epoch: 6| Step: 1
Training loss: 0.4165124568083882
Validation loss: 2.768626593946053

Epoch: 6| Step: 2
Training loss: 0.3297438876125632
Validation loss: 2.7623011556323758

Epoch: 6| Step: 3
Training loss: 0.6074060272406367
Validation loss: 2.8047938419679195

Epoch: 6| Step: 4
Training loss: 0.4032121933669557
Validation loss: 2.8447237827764553

Epoch: 6| Step: 5
Training loss: 0.46629041067092936
Validation loss: 2.8720343815712246

Epoch: 6| Step: 6
Training loss: 1.1185665555617115
Validation loss: 2.9337366088812953

Epoch: 6| Step: 7
Training loss: 0.35269839841561756
Validation loss: 2.912491866879438

Epoch: 6| Step: 8
Training loss: 0.41163227975653716
Validation loss: 3.003325870503233

Epoch: 6| Step: 9
Training loss: 0.32308947133578514
Validation loss: 2.887120970362643

Epoch: 6| Step: 10
Training loss: 0.30554808832687
Validation loss: 2.8325621640015863

Epoch: 6| Step: 11
Training loss: 0.6494612827199384
Validation loss: 2.9243592497826856

Epoch: 6| Step: 12
Training loss: 0.45744652099408045
Validation loss: 2.8642639583223004

Epoch: 6| Step: 13
Training loss: 0.4162359057437363
Validation loss: 2.861425585166491

Epoch: 272| Step: 0
Training loss: 0.4152004511586349
Validation loss: 2.8970278784977777

Epoch: 6| Step: 1
Training loss: 0.28059435292629625
Validation loss: 2.926473280209799

Epoch: 6| Step: 2
Training loss: 0.5296234587268133
Validation loss: 2.9837092111306176

Epoch: 6| Step: 3
Training loss: 0.4463236855864194
Validation loss: 2.840395069783526

Epoch: 6| Step: 4
Training loss: 0.46467263414093946
Validation loss: 2.775624733558143

Epoch: 6| Step: 5
Training loss: 0.5717803407715941
Validation loss: 2.889758253315277

Epoch: 6| Step: 6
Training loss: 0.6166633601572555
Validation loss: 2.9085283953626195

Epoch: 6| Step: 7
Training loss: 1.062287814326663
Validation loss: 2.8833170296827313

Epoch: 6| Step: 8
Training loss: 0.4464986964054023
Validation loss: 2.990578759293341

Epoch: 6| Step: 9
Training loss: 0.4872203899241194
Validation loss: 2.8850690630001985

Epoch: 6| Step: 10
Training loss: 0.312981199282599
Validation loss: 2.873795644080447

Epoch: 6| Step: 11
Training loss: 0.574055810763738
Validation loss: 2.90234555723152

Epoch: 6| Step: 12
Training loss: 0.5281460628033772
Validation loss: 2.915315878380193

Epoch: 6| Step: 13
Training loss: 0.3656867178969038
Validation loss: 2.8983543089300845

Epoch: 273| Step: 0
Training loss: 0.5357306245174175
Validation loss: 2.900242054363273

Epoch: 6| Step: 1
Training loss: 0.3993551681859957
Validation loss: 2.9322096483991245

Epoch: 6| Step: 2
Training loss: 0.360862927350177
Validation loss: 2.885552431807575

Epoch: 6| Step: 3
Training loss: 0.6153882031152752
Validation loss: 2.9962471562535056

Epoch: 6| Step: 4
Training loss: 0.3610198071585718
Validation loss: 2.959710396139823

Epoch: 6| Step: 5
Training loss: 0.2712957152065187
Validation loss: 3.001575784622388

Epoch: 6| Step: 6
Training loss: 0.49289789854430976
Validation loss: 2.956524475023015

Epoch: 6| Step: 7
Training loss: 0.301955408381308
Validation loss: 2.9608405239090563

Epoch: 6| Step: 8
Training loss: 1.0703191826604792
Validation loss: 2.9885552706607705

Epoch: 6| Step: 9
Training loss: 0.41258889815385746
Validation loss: 2.984926116280318

Epoch: 6| Step: 10
Training loss: 0.3478563782810001
Validation loss: 2.9410456503496842

Epoch: 6| Step: 11
Training loss: 0.3902383416540336
Validation loss: 2.960084468521269

Epoch: 6| Step: 12
Training loss: 0.4538645464177389
Validation loss: 2.884479409501689

Epoch: 6| Step: 13
Training loss: 0.644145225753686
Validation loss: 2.84043296078099

Epoch: 274| Step: 0
Training loss: 0.4076575872911807
Validation loss: 2.9115837538744795

Epoch: 6| Step: 1
Training loss: 0.31055282491106356
Validation loss: 2.8612822961880227

Epoch: 6| Step: 2
Training loss: 0.34732861028118506
Validation loss: 2.960759676757845

Epoch: 6| Step: 3
Training loss: 0.3670724729186367
Validation loss: 2.9167333095747963

Epoch: 6| Step: 4
Training loss: 0.35818454274075184
Validation loss: 2.9144498347770136

Epoch: 6| Step: 5
Training loss: 0.37465123011367885
Validation loss: 2.903510795612169

Epoch: 6| Step: 6
Training loss: 0.3317003059380621
Validation loss: 2.8635660249338546

Epoch: 6| Step: 7
Training loss: 1.182935928496053
Validation loss: 2.871375577419994

Epoch: 6| Step: 8
Training loss: 0.6071339013537077
Validation loss: 2.829570225364295

Epoch: 6| Step: 9
Training loss: 0.3991971347877064
Validation loss: 2.8783639080394767

Epoch: 6| Step: 10
Training loss: 0.6066069947971718
Validation loss: 2.835651603979195

Epoch: 6| Step: 11
Training loss: 0.40410987473019516
Validation loss: 2.910649077397997

Epoch: 6| Step: 12
Training loss: 0.4196581700032747
Validation loss: 2.8083572960198184

Epoch: 6| Step: 13
Training loss: 0.38601223148721897
Validation loss: 2.9172808454631083

Epoch: 275| Step: 0
Training loss: 1.1140035327430746
Validation loss: 2.906558714299788

Epoch: 6| Step: 1
Training loss: 0.36531918606868247
Validation loss: 2.9157155984020413

Epoch: 6| Step: 2
Training loss: 0.41927491851459203
Validation loss: 2.8403275684157463

Epoch: 6| Step: 3
Training loss: 0.48151988289583203
Validation loss: 2.927338983813382

Epoch: 6| Step: 4
Training loss: 0.297159021439056
Validation loss: 2.9016084009010528

Epoch: 6| Step: 5
Training loss: 0.3303391141464251
Validation loss: 2.8867022867038714

Epoch: 6| Step: 6
Training loss: 0.5376303625595477
Validation loss: 2.7646142294296876

Epoch: 6| Step: 7
Training loss: 0.49453552208090235
Validation loss: 2.809559634332803

Epoch: 6| Step: 8
Training loss: 0.4234844871436117
Validation loss: 2.8201928505213387

Epoch: 6| Step: 9
Training loss: 0.5316434413098163
Validation loss: 2.866892287520518

Epoch: 6| Step: 10
Training loss: 0.3447396273203997
Validation loss: 2.8738116697132647

Epoch: 6| Step: 11
Training loss: 0.30107951547799594
Validation loss: 2.845304574244893

Epoch: 6| Step: 12
Training loss: 0.44775255841600403
Validation loss: 2.934369143479163

Epoch: 6| Step: 13
Training loss: 0.61302835875251
Validation loss: 2.8950066015270384

Epoch: 276| Step: 0
Training loss: 0.30930827509795955
Validation loss: 2.9200599323070713

Epoch: 6| Step: 1
Training loss: 0.4313387440854793
Validation loss: 2.8766526434134065

Epoch: 6| Step: 2
Training loss: 0.553612271353567
Validation loss: 2.8512499076177638

Epoch: 6| Step: 3
Training loss: 0.2662260464070167
Validation loss: 2.858687368512219

Epoch: 6| Step: 4
Training loss: 0.6753477790087116
Validation loss: 2.841095492403299

Epoch: 6| Step: 5
Training loss: 0.34165425185970694
Validation loss: 2.907590809740849

Epoch: 6| Step: 6
Training loss: 0.5144317286509108
Validation loss: 2.839233612743256

Epoch: 6| Step: 7
Training loss: 0.3301001998472028
Validation loss: 2.8416723829269714

Epoch: 6| Step: 8
Training loss: 0.26875350528471503
Validation loss: 2.9291055330179754

Epoch: 6| Step: 9
Training loss: 0.254419043709048
Validation loss: 2.927983445389995

Epoch: 6| Step: 10
Training loss: 0.47051510676536995
Validation loss: 3.018339605453044

Epoch: 6| Step: 11
Training loss: 1.078903249063814
Validation loss: 2.9469587479331736

Epoch: 6| Step: 12
Training loss: 0.4877986353945052
Validation loss: 2.8909992834869027

Epoch: 6| Step: 13
Training loss: 0.25429481704746437
Validation loss: 2.868029021375656

Epoch: 277| Step: 0
Training loss: 0.44819280148712587
Validation loss: 2.8487699238313517

Epoch: 6| Step: 1
Training loss: 0.36810804188759494
Validation loss: 2.931718086983054

Epoch: 6| Step: 2
Training loss: 0.5063714340939439
Validation loss: 2.9054332392150757

Epoch: 6| Step: 3
Training loss: 0.5697222228566619
Validation loss: 2.9163719618728625

Epoch: 6| Step: 4
Training loss: 0.3936182164867236
Validation loss: 2.947131579202988

Epoch: 6| Step: 5
Training loss: 0.39347516716586894
Validation loss: 2.92673202976788

Epoch: 6| Step: 6
Training loss: 0.30278617661801155
Validation loss: 2.881696890089116

Epoch: 6| Step: 7
Training loss: 0.3682367470629625
Validation loss: 2.9505068629114497

Epoch: 6| Step: 8
Training loss: 0.3291634068548978
Validation loss: 2.876399901859312

Epoch: 6| Step: 9
Training loss: 0.43092414459048006
Validation loss: 2.8894658144316865

Epoch: 6| Step: 10
Training loss: 0.48092779854947115
Validation loss: 2.961526360917371

Epoch: 6| Step: 11
Training loss: 0.3824732503388565
Validation loss: 2.8466170114866247

Epoch: 6| Step: 12
Training loss: 1.118339371577267
Validation loss: 2.8811516530539145

Epoch: 6| Step: 13
Training loss: 0.3716276243613098
Validation loss: 2.852659193985576

Epoch: 278| Step: 0
Training loss: 0.40614475207377687
Validation loss: 2.8846004768540636

Epoch: 6| Step: 1
Training loss: 0.5404397812573825
Validation loss: 2.8719442893972134

Epoch: 6| Step: 2
Training loss: 0.2531788309572307
Validation loss: 2.857560281971513

Epoch: 6| Step: 3
Training loss: 1.0763298237226424
Validation loss: 2.8982558763327586

Epoch: 6| Step: 4
Training loss: 0.3343230198181884
Validation loss: 2.876730494831696

Epoch: 6| Step: 5
Training loss: 0.4467622681455837
Validation loss: 2.883126948987411

Epoch: 6| Step: 6
Training loss: 0.35018693112897853
Validation loss: 2.7890750161681734

Epoch: 6| Step: 7
Training loss: 0.33040395151008284
Validation loss: 2.947335112847797

Epoch: 6| Step: 8
Training loss: 0.4096820269640271
Validation loss: 2.931582232356923

Epoch: 6| Step: 9
Training loss: 0.5285923622286782
Validation loss: 2.9268610497690095

Epoch: 6| Step: 10
Training loss: 0.5048385984440704
Validation loss: 2.977558893688401

Epoch: 6| Step: 11
Training loss: 0.3734392229942253
Validation loss: 2.841096275636306

Epoch: 6| Step: 12
Training loss: 0.44495286975907794
Validation loss: 2.958661482077387

Epoch: 6| Step: 13
Training loss: 0.32828817397472815
Validation loss: 2.845114398102187

Epoch: 279| Step: 0
Training loss: 0.6991976942589581
Validation loss: 2.8671355974729678

Epoch: 6| Step: 1
Training loss: 0.4176265706292823
Validation loss: 2.904219242607008

Epoch: 6| Step: 2
Training loss: 0.5931282552663953
Validation loss: 2.8809726705741188

Epoch: 6| Step: 3
Training loss: 0.3698489543256924
Validation loss: 2.8787737832720577

Epoch: 6| Step: 4
Training loss: 0.5332573105104845
Validation loss: 2.906841805749105

Epoch: 6| Step: 5
Training loss: 0.41099761769725046
Validation loss: 2.985500037091132

Epoch: 6| Step: 6
Training loss: 1.0256623407664631
Validation loss: 2.8947381526086207

Epoch: 6| Step: 7
Training loss: 0.3367205298923262
Validation loss: 2.8922288311561086

Epoch: 6| Step: 8
Training loss: 0.4565661745752538
Validation loss: 2.8818210182161397

Epoch: 6| Step: 9
Training loss: 0.45596172030503795
Validation loss: 2.9299957384505975

Epoch: 6| Step: 10
Training loss: 0.38563590215175325
Validation loss: 2.908220532332963

Epoch: 6| Step: 11
Training loss: 0.25830604533436347
Validation loss: 2.907310579448667

Epoch: 6| Step: 12
Training loss: 0.3951421483707504
Validation loss: 2.963257068093183

Epoch: 6| Step: 13
Training loss: 0.2745838929422915
Validation loss: 2.904063834764716

Epoch: 280| Step: 0
Training loss: 0.385011584677357
Validation loss: 3.013636577512391

Epoch: 6| Step: 1
Training loss: 0.31308472288661193
Validation loss: 2.9282192501395827

Epoch: 6| Step: 2
Training loss: 1.1140554847870927
Validation loss: 2.901228473522658

Epoch: 6| Step: 3
Training loss: 0.4568743151021643
Validation loss: 2.882700062448342

Epoch: 6| Step: 4
Training loss: 0.393404096468565
Validation loss: 2.9243953666784925

Epoch: 6| Step: 5
Training loss: 0.44558095369238043
Validation loss: 2.9013602163495786

Epoch: 6| Step: 6
Training loss: 0.4100571648940075
Validation loss: 2.9306132299363536

Epoch: 6| Step: 7
Training loss: 0.41135583478110094
Validation loss: 2.897213728057058

Epoch: 6| Step: 8
Training loss: 0.43762843767159965
Validation loss: 2.8570433318310604

Epoch: 6| Step: 9
Training loss: 0.6682676795293371
Validation loss: 2.8543008137013577

Epoch: 6| Step: 10
Training loss: 0.577668705858321
Validation loss: 2.886583310444195

Epoch: 6| Step: 11
Training loss: 0.5178714137154572
Validation loss: 2.829862731641892

Epoch: 6| Step: 12
Training loss: 0.45569120703144084
Validation loss: 2.8801599858361056

Epoch: 6| Step: 13
Training loss: 0.3557925164638124
Validation loss: 2.9021055689441613

Epoch: 281| Step: 0
Training loss: 0.44203340655947276
Validation loss: 2.9069364277165683

Epoch: 6| Step: 1
Training loss: 0.4254237257564516
Validation loss: 2.8836842970135144

Epoch: 6| Step: 2
Training loss: 0.3576371842048453
Validation loss: 2.9200073365768167

Epoch: 6| Step: 3
Training loss: 1.009928529684552
Validation loss: 2.8146896315878185

Epoch: 6| Step: 4
Training loss: 0.3603335740476493
Validation loss: 2.938475304879363

Epoch: 6| Step: 5
Training loss: 0.3462388903250569
Validation loss: 2.906102863812078

Epoch: 6| Step: 6
Training loss: 0.3291830307277063
Validation loss: 2.902424732035129

Epoch: 6| Step: 7
Training loss: 0.40990851050246024
Validation loss: 2.8865976820125967

Epoch: 6| Step: 8
Training loss: 0.3895019408827722
Validation loss: 2.8733985836013614

Epoch: 6| Step: 9
Training loss: 0.42803578665446435
Validation loss: 2.8511042117774297

Epoch: 6| Step: 10
Training loss: 0.29925797905000473
Validation loss: 2.888779169428096

Epoch: 6| Step: 11
Training loss: 0.44073063280869573
Validation loss: 2.7865202044216484

Epoch: 6| Step: 12
Training loss: 0.4656034880667642
Validation loss: 2.947174805661126

Epoch: 6| Step: 13
Training loss: 0.4328571282799991
Validation loss: 2.863598440381566

Epoch: 282| Step: 0
Training loss: 0.5104212144402555
Validation loss: 2.9331872813393436

Epoch: 6| Step: 1
Training loss: 0.5009216516454332
Validation loss: 2.9367644965135327

Epoch: 6| Step: 2
Training loss: 0.37308717679726655
Validation loss: 2.8980031609168058

Epoch: 6| Step: 3
Training loss: 0.5566084735352158
Validation loss: 2.856600278470946

Epoch: 6| Step: 4
Training loss: 0.35545919216846555
Validation loss: 2.9312874862779106

Epoch: 6| Step: 5
Training loss: 0.3817181027344858
Validation loss: 2.8135262347780556

Epoch: 6| Step: 6
Training loss: 0.5177139967590074
Validation loss: 2.9210063982820245

Epoch: 6| Step: 7
Training loss: 0.3251590422144259
Validation loss: 2.9390586208092797

Epoch: 6| Step: 8
Training loss: 0.47102903424510395
Validation loss: 2.901719927758185

Epoch: 6| Step: 9
Training loss: 0.36375515288540816
Validation loss: 2.871625689234276

Epoch: 6| Step: 10
Training loss: 1.1052474484486476
Validation loss: 2.935857069894245

Epoch: 6| Step: 11
Training loss: 0.6899449482669607
Validation loss: 2.9776108731953923

Epoch: 6| Step: 12
Training loss: 0.3206720195372725
Validation loss: 2.975433362390372

Epoch: 6| Step: 13
Training loss: 0.32000848252259434
Validation loss: 3.0168400690039965

Epoch: 283| Step: 0
Training loss: 0.4811398850831929
Validation loss: 3.0461568654479385

Epoch: 6| Step: 1
Training loss: 0.3127991198441984
Validation loss: 2.933251778776572

Epoch: 6| Step: 2
Training loss: 0.2456625915594915
Validation loss: 2.899960004048394

Epoch: 6| Step: 3
Training loss: 0.2905765011015847
Validation loss: 2.8856946258153995

Epoch: 6| Step: 4
Training loss: 0.4046063183398152
Validation loss: 2.902716823609179

Epoch: 6| Step: 5
Training loss: 0.24023137439621645
Validation loss: 2.900968517611723

Epoch: 6| Step: 6
Training loss: 0.3544469126643983
Validation loss: 2.9246314471379007

Epoch: 6| Step: 7
Training loss: 1.1146909655834467
Validation loss: 2.8958798869025033

Epoch: 6| Step: 8
Training loss: 0.355958056873576
Validation loss: 2.9712304042993267

Epoch: 6| Step: 9
Training loss: 0.5303333452361797
Validation loss: 2.913478932656005

Epoch: 6| Step: 10
Training loss: 0.467243587354984
Validation loss: 2.9165002412090164

Epoch: 6| Step: 11
Training loss: 0.49237635183427203
Validation loss: 2.9309091826700344

Epoch: 6| Step: 12
Training loss: 0.27535225891813153
Validation loss: 2.8824215342155326

Epoch: 6| Step: 13
Training loss: 0.38565730839049245
Validation loss: 2.9226047876051027

Epoch: 284| Step: 0
Training loss: 0.4138583273702089
Validation loss: 2.864188057186314

Epoch: 6| Step: 1
Training loss: 0.5198205414920922
Validation loss: 2.8183229989964533

Epoch: 6| Step: 2
Training loss: 0.435779287143033
Validation loss: 2.9339664796423905

Epoch: 6| Step: 3
Training loss: 0.41382044788835065
Validation loss: 2.8499562237818568

Epoch: 6| Step: 4
Training loss: 1.038060558507678
Validation loss: 2.9816119000362957

Epoch: 6| Step: 5
Training loss: 0.6276314651651625
Validation loss: 2.9713283786217413

Epoch: 6| Step: 6
Training loss: 0.525235319759456
Validation loss: 3.009721964016711

Epoch: 6| Step: 7
Training loss: 0.7647856178830776
Validation loss: 2.9889880306514316

Epoch: 6| Step: 8
Training loss: 0.3427939123575724
Validation loss: 2.876362325792402

Epoch: 6| Step: 9
Training loss: 0.3751838154101105
Validation loss: 2.9459892460103867

Epoch: 6| Step: 10
Training loss: 0.6240217181974554
Validation loss: 2.917642543658862

Epoch: 6| Step: 11
Training loss: 0.562714906541362
Validation loss: 2.8512104113176067

Epoch: 6| Step: 12
Training loss: 0.36095964355580296
Validation loss: 2.8609101112731157

Epoch: 6| Step: 13
Training loss: 0.43009350408763103
Validation loss: 2.902098448952011

Epoch: 285| Step: 0
Training loss: 0.38180233546552345
Validation loss: 2.876207319327318

Epoch: 6| Step: 1
Training loss: 0.4733368568334039
Validation loss: 2.88149991775487

Epoch: 6| Step: 2
Training loss: 0.30040335758443365
Validation loss: 2.9344582602402656

Epoch: 6| Step: 3
Training loss: 0.5306075081789748
Validation loss: 2.9783887625604297

Epoch: 6| Step: 4
Training loss: 0.40393440842009803
Validation loss: 2.9458698315407483

Epoch: 6| Step: 5
Training loss: 0.37207619970274725
Validation loss: 2.8951882437434717

Epoch: 6| Step: 6
Training loss: 0.9660042335958491
Validation loss: 2.89658125588673

Epoch: 6| Step: 7
Training loss: 0.33836560684204475
Validation loss: 2.871662137261743

Epoch: 6| Step: 8
Training loss: 0.5380816450830522
Validation loss: 2.8442284038410395

Epoch: 6| Step: 9
Training loss: 0.3355281575925467
Validation loss: 2.857934585502508

Epoch: 6| Step: 10
Training loss: 0.6820341794015519
Validation loss: 2.8067899313412807

Epoch: 6| Step: 11
Training loss: 0.46558326111683657
Validation loss: 2.8999569484102086

Epoch: 6| Step: 12
Training loss: 0.5729885807563844
Validation loss: 2.8940419526986294

Epoch: 6| Step: 13
Training loss: 0.4134871966652735
Validation loss: 2.9440310630878592

Epoch: 286| Step: 0
Training loss: 0.33531370576924363
Validation loss: 2.994181938574815

Epoch: 6| Step: 1
Training loss: 0.9434594205954988
Validation loss: 2.9523130508311324

Epoch: 6| Step: 2
Training loss: 0.5085174362659064
Validation loss: 2.94447032649183

Epoch: 6| Step: 3
Training loss: 0.34654078320085646
Validation loss: 2.9438846678818646

Epoch: 6| Step: 4
Training loss: 0.44189469985537183
Validation loss: 2.9103398685430735

Epoch: 6| Step: 5
Training loss: 0.4116528409432884
Validation loss: 2.9915917503164637

Epoch: 6| Step: 6
Training loss: 0.4056957021321057
Validation loss: 2.8581272731237815

Epoch: 6| Step: 7
Training loss: 0.44533583931244003
Validation loss: 2.879549655937244

Epoch: 6| Step: 8
Training loss: 0.43147001735401386
Validation loss: 2.884310614796148

Epoch: 6| Step: 9
Training loss: 0.5832975552576826
Validation loss: 2.897318717501284

Epoch: 6| Step: 10
Training loss: 0.46344967975932577
Validation loss: 2.9027414507217766

Epoch: 6| Step: 11
Training loss: 0.4261645420468067
Validation loss: 2.921888123617092

Epoch: 6| Step: 12
Training loss: 0.4662127491181058
Validation loss: 2.944741528496568

Epoch: 6| Step: 13
Training loss: 0.6078858887757929
Validation loss: 2.931924682924852

Epoch: 287| Step: 0
Training loss: 0.44851496755063075
Validation loss: 2.959104280801609

Epoch: 6| Step: 1
Training loss: 1.0629475156005237
Validation loss: 2.9622600356293725

Epoch: 6| Step: 2
Training loss: 0.4840409295858361
Validation loss: 2.9488356587774467

Epoch: 6| Step: 3
Training loss: 0.3382785312464046
Validation loss: 2.9554173152386314

Epoch: 6| Step: 4
Training loss: 0.2740467640742621
Validation loss: 2.9201496898699837

Epoch: 6| Step: 5
Training loss: 0.3764955777735589
Validation loss: 2.878973605965223

Epoch: 6| Step: 6
Training loss: 0.5501378948570045
Validation loss: 2.866512305702116

Epoch: 6| Step: 7
Training loss: 0.7495956125432267
Validation loss: 2.9058868017183044

Epoch: 6| Step: 8
Training loss: 0.5501146814687009
Validation loss: 2.835306144613894

Epoch: 6| Step: 9
Training loss: 0.4166636546343972
Validation loss: 2.9970385186298967

Epoch: 6| Step: 10
Training loss: 0.342361659317575
Validation loss: 2.9011884797145266

Epoch: 6| Step: 11
Training loss: 0.5061168825304572
Validation loss: 2.9947370220119347

Epoch: 6| Step: 12
Training loss: 0.6621644213814655
Validation loss: 3.0327858065662543

Epoch: 6| Step: 13
Training loss: 0.4886044157625014
Validation loss: 2.969005453262126

Epoch: 288| Step: 0
Training loss: 0.3395308117045186
Validation loss: 3.0282953813435483

Epoch: 6| Step: 1
Training loss: 0.5229803907718983
Validation loss: 2.825587657132413

Epoch: 6| Step: 2
Training loss: 0.48146136026931663
Validation loss: 2.828653001761562

Epoch: 6| Step: 3
Training loss: 0.6395630291709474
Validation loss: 2.800028140630547

Epoch: 6| Step: 4
Training loss: 0.8212210573760391
Validation loss: 2.86152734681346

Epoch: 6| Step: 5
Training loss: 0.4008621788484439
Validation loss: 2.84776956884817

Epoch: 6| Step: 6
Training loss: 0.37264273756948657
Validation loss: 2.8698660580685056

Epoch: 6| Step: 7
Training loss: 0.5969852345715748
Validation loss: 2.9817044224346785

Epoch: 6| Step: 8
Training loss: 0.4851714630936032
Validation loss: 3.0383466647328747

Epoch: 6| Step: 9
Training loss: 0.7442801837765352
Validation loss: 2.9753831077114463

Epoch: 6| Step: 10
Training loss: 0.5140592035808211
Validation loss: 2.8932834120002067

Epoch: 6| Step: 11
Training loss: 0.29358510350299966
Validation loss: 2.8648414680465626

Epoch: 6| Step: 12
Training loss: 0.4437707345443455
Validation loss: 2.8397439259610997

Epoch: 6| Step: 13
Training loss: 1.074936505593865
Validation loss: 2.7765400613891713

Epoch: 289| Step: 0
Training loss: 0.7728441062106753
Validation loss: 2.806431786667869

Epoch: 6| Step: 1
Training loss: 0.5303148566099821
Validation loss: 2.858254579695493

Epoch: 6| Step: 2
Training loss: 0.41082420455367197
Validation loss: 2.814854646411606

Epoch: 6| Step: 3
Training loss: 0.3755356023408785
Validation loss: 2.848547525211305

Epoch: 6| Step: 4
Training loss: 0.46991958934706896
Validation loss: 2.8733398647706156

Epoch: 6| Step: 5
Training loss: 0.5138265862658642
Validation loss: 2.9992141091623097

Epoch: 6| Step: 6
Training loss: 1.0853027025214965
Validation loss: 2.954783570980222

Epoch: 6| Step: 7
Training loss: 0.4464918214405632
Validation loss: 2.8981214489811213

Epoch: 6| Step: 8
Training loss: 0.4828602116043679
Validation loss: 2.7897163002359586

Epoch: 6| Step: 9
Training loss: 0.3617438322067398
Validation loss: 2.8749874639928867

Epoch: 6| Step: 10
Training loss: 0.4207063488850024
Validation loss: 2.8733387999102757

Epoch: 6| Step: 11
Training loss: 0.45775615228198857
Validation loss: 2.8727968315893135

Epoch: 6| Step: 12
Training loss: 0.35669709810371114
Validation loss: 2.8184010235376276

Epoch: 6| Step: 13
Training loss: 0.42722368454066273
Validation loss: 2.9476094349785766

Epoch: 290| Step: 0
Training loss: 1.0360584286263834
Validation loss: 2.879329434627653

Epoch: 6| Step: 1
Training loss: 0.4433249909768093
Validation loss: 3.058324289611694

Epoch: 6| Step: 2
Training loss: 0.5168812793133468
Validation loss: 3.0192694112500065

Epoch: 6| Step: 3
Training loss: 0.5365573334931172
Validation loss: 2.895185224244085

Epoch: 6| Step: 4
Training loss: 0.47439785549204194
Validation loss: 2.8845877483869904

Epoch: 6| Step: 5
Training loss: 0.5329465703003363
Validation loss: 2.8302192310567578

Epoch: 6| Step: 6
Training loss: 0.5281606210737988
Validation loss: 2.879688199878538

Epoch: 6| Step: 7
Training loss: 0.6316890870177496
Validation loss: 2.8958804494926413

Epoch: 6| Step: 8
Training loss: 0.4287529231825402
Validation loss: 2.8069744933559173

Epoch: 6| Step: 9
Training loss: 0.49374215264663474
Validation loss: 2.8496181739774125

Epoch: 6| Step: 10
Training loss: 0.46562232202361453
Validation loss: 2.9478905253155516

Epoch: 6| Step: 11
Training loss: 0.41861233227512373
Validation loss: 2.8408394755301445

Epoch: 6| Step: 12
Training loss: 0.5829456238669829
Validation loss: 2.9193473667499448

Epoch: 6| Step: 13
Training loss: 0.5906584715062997
Validation loss: 2.8707270173944504

Epoch: 291| Step: 0
Training loss: 0.39600486134184654
Validation loss: 2.893945742002046

Epoch: 6| Step: 1
Training loss: 0.3157136188397087
Validation loss: 2.947222022359084

Epoch: 6| Step: 2
Training loss: 0.4249657687257873
Validation loss: 2.889457851913331

Epoch: 6| Step: 3
Training loss: 0.5132833541757312
Validation loss: 2.8616460873043996

Epoch: 6| Step: 4
Training loss: 0.30062032085274687
Validation loss: 2.815185211643006

Epoch: 6| Step: 5
Training loss: 0.5222786558661205
Validation loss: 2.9765854615187743

Epoch: 6| Step: 6
Training loss: 0.4259209010135706
Validation loss: 2.9293392398258415

Epoch: 6| Step: 7
Training loss: 0.4687703763983498
Validation loss: 2.878162482918791

Epoch: 6| Step: 8
Training loss: 0.567221009496741
Validation loss: 2.9324621734824534

Epoch: 6| Step: 9
Training loss: 0.5315391090444965
Validation loss: 2.8387959684264037

Epoch: 6| Step: 10
Training loss: 0.48675409681577914
Validation loss: 2.955886827652852

Epoch: 6| Step: 11
Training loss: 0.9584099939340291
Validation loss: 2.933927406134127

Epoch: 6| Step: 12
Training loss: 0.39169833540549354
Validation loss: 2.940348333193867

Epoch: 6| Step: 13
Training loss: 0.34828933122859446
Validation loss: 2.9224055823353465

Epoch: 292| Step: 0
Training loss: 0.5251696380661114
Validation loss: 2.9074224205961325

Epoch: 6| Step: 1
Training loss: 0.35866457752871417
Validation loss: 2.9436302473867677

Epoch: 6| Step: 2
Training loss: 0.31883878826994233
Validation loss: 2.9495118254498705

Epoch: 6| Step: 3
Training loss: 0.5173081467618029
Validation loss: 2.935228632979647

Epoch: 6| Step: 4
Training loss: 0.4004037622296942
Validation loss: 2.959970952269501

Epoch: 6| Step: 5
Training loss: 0.35174451990339
Validation loss: 2.9387931682748354

Epoch: 6| Step: 6
Training loss: 0.5122959870658759
Validation loss: 2.8537540462385564

Epoch: 6| Step: 7
Training loss: 0.5405554070635326
Validation loss: 2.922764539033849

Epoch: 6| Step: 8
Training loss: 0.567968174909172
Validation loss: 2.8377270897558926

Epoch: 6| Step: 9
Training loss: 0.9855727523085643
Validation loss: 2.8897878310915797

Epoch: 6| Step: 10
Training loss: 0.5147651959751951
Validation loss: 2.887850183937941

Epoch: 6| Step: 11
Training loss: 0.5484558689269081
Validation loss: 2.868340103796047

Epoch: 6| Step: 12
Training loss: 0.47986254402801776
Validation loss: 2.9211551643139755

Epoch: 6| Step: 13
Training loss: 0.4536498745878053
Validation loss: 2.863602228635541

Epoch: 293| Step: 0
Training loss: 0.5708127114360204
Validation loss: 2.9295269867052864

Epoch: 6| Step: 1
Training loss: 0.5650823972760186
Validation loss: 2.8454074989700344

Epoch: 6| Step: 2
Training loss: 0.36837570218969756
Validation loss: 2.886635634172538

Epoch: 6| Step: 3
Training loss: 0.4741981514442996
Validation loss: 2.8308915434130326

Epoch: 6| Step: 4
Training loss: 0.30816995517175455
Validation loss: 2.8824411857782852

Epoch: 6| Step: 5
Training loss: 0.3117000951897467
Validation loss: 2.825012250327947

Epoch: 6| Step: 6
Training loss: 0.29832524640073055
Validation loss: 2.864690013401819

Epoch: 6| Step: 7
Training loss: 0.3819392813227617
Validation loss: 2.9436644809662806

Epoch: 6| Step: 8
Training loss: 0.4889229334626888
Validation loss: 3.001550326834834

Epoch: 6| Step: 9
Training loss: 0.3101698067726674
Validation loss: 2.887760660865992

Epoch: 6| Step: 10
Training loss: 0.3955190774702645
Validation loss: 2.9644350114410494

Epoch: 6| Step: 11
Training loss: 0.47461780493514116
Validation loss: 2.9436509954673022

Epoch: 6| Step: 12
Training loss: 1.078039691148347
Validation loss: 2.8816684427323906

Epoch: 6| Step: 13
Training loss: 0.31383874950700336
Validation loss: 2.9120552711228163

Epoch: 294| Step: 0
Training loss: 0.4635685170001601
Validation loss: 2.813454190621744

Epoch: 6| Step: 1
Training loss: 0.2992776593616985
Validation loss: 2.911814745729731

Epoch: 6| Step: 2
Training loss: 0.4913014353209978
Validation loss: 2.910069393082149

Epoch: 6| Step: 3
Training loss: 0.3961687758077589
Validation loss: 2.9730213423979857

Epoch: 6| Step: 4
Training loss: 1.0058862182590818
Validation loss: 2.8833145490119008

Epoch: 6| Step: 5
Training loss: 0.31188524097530984
Validation loss: 2.921232237810146

Epoch: 6| Step: 6
Training loss: 0.3688288386167714
Validation loss: 2.8949864519073474

Epoch: 6| Step: 7
Training loss: 0.27996263982809616
Validation loss: 2.9993921962254886

Epoch: 6| Step: 8
Training loss: 0.5352292533142813
Validation loss: 2.9165301881375876

Epoch: 6| Step: 9
Training loss: 0.40523653896526945
Validation loss: 2.926945276952839

Epoch: 6| Step: 10
Training loss: 0.5025811923084798
Validation loss: 2.950646600065792

Epoch: 6| Step: 11
Training loss: 0.3982349890881064
Validation loss: 2.974231317732571

Epoch: 6| Step: 12
Training loss: 0.5086159439049445
Validation loss: 2.82593810110477

Epoch: 6| Step: 13
Training loss: 0.33134879492337227
Validation loss: 2.89467466396344

Epoch: 295| Step: 0
Training loss: 0.4336734732803033
Validation loss: 2.8326041928975907

Epoch: 6| Step: 1
Training loss: 1.0103320187902336
Validation loss: 2.9380673476113746

Epoch: 6| Step: 2
Training loss: 0.4443043121150101
Validation loss: 2.972800920920303

Epoch: 6| Step: 3
Training loss: 0.4114451003864074
Validation loss: 2.8776935868444764

Epoch: 6| Step: 4
Training loss: 0.4372744319343072
Validation loss: 2.998568444956823

Epoch: 6| Step: 5
Training loss: 0.4804940255812849
Validation loss: 3.0258709481297643

Epoch: 6| Step: 6
Training loss: 0.4411488178997422
Validation loss: 2.9403657799630682

Epoch: 6| Step: 7
Training loss: 0.2704640019053485
Validation loss: 2.941054081193552

Epoch: 6| Step: 8
Training loss: 0.38021339996654774
Validation loss: 2.912321946427655

Epoch: 6| Step: 9
Training loss: 0.2800233103636879
Validation loss: 2.921275126575364

Epoch: 6| Step: 10
Training loss: 0.392661033719634
Validation loss: 2.913584570261379

Epoch: 6| Step: 11
Training loss: 0.4910528637733304
Validation loss: 2.8877880987578424

Epoch: 6| Step: 12
Training loss: 0.33394258918147074
Validation loss: 2.833796552116692

Epoch: 6| Step: 13
Training loss: 0.5317376367093919
Validation loss: 2.9277236663439288

Epoch: 296| Step: 0
Training loss: 0.3698221203079906
Validation loss: 2.948082846191302

Epoch: 6| Step: 1
Training loss: 1.0202634674020943
Validation loss: 3.011480075401868

Epoch: 6| Step: 2
Training loss: 0.4802761156923535
Validation loss: 2.9040994788725585

Epoch: 6| Step: 3
Training loss: 0.4195831174417425
Validation loss: 2.967680889166542

Epoch: 6| Step: 4
Training loss: 0.2981291681074274
Validation loss: 2.890567950811266

Epoch: 6| Step: 5
Training loss: 0.3174705266789211
Validation loss: 2.896587799551124

Epoch: 6| Step: 6
Training loss: 0.3514119143642243
Validation loss: 2.883883696787208

Epoch: 6| Step: 7
Training loss: 0.3634506158930312
Validation loss: 2.953270493140942

Epoch: 6| Step: 8
Training loss: 0.37249779361353036
Validation loss: 2.8950836437047256

Epoch: 6| Step: 9
Training loss: 0.4144781653401807
Validation loss: 2.845631588272544

Epoch: 6| Step: 10
Training loss: 0.5610548900722602
Validation loss: 2.903448935819358

Epoch: 6| Step: 11
Training loss: 0.33538486801882816
Validation loss: 2.9709362813831324

Epoch: 6| Step: 12
Training loss: 0.456982944250598
Validation loss: 2.9066320325453328

Epoch: 6| Step: 13
Training loss: 0.2762443620011496
Validation loss: 2.972709277662129

Epoch: 297| Step: 0
Training loss: 0.9886585465297317
Validation loss: 2.9716341431172104

Epoch: 6| Step: 1
Training loss: 0.6195867718017776
Validation loss: 2.9839018068768084

Epoch: 6| Step: 2
Training loss: 0.4373332795869011
Validation loss: 3.0065296955021954

Epoch: 6| Step: 3
Training loss: 0.3612602170073592
Validation loss: 2.911626348043466

Epoch: 6| Step: 4
Training loss: 0.45263067774357546
Validation loss: 2.844675339720957

Epoch: 6| Step: 5
Training loss: 0.49369965731222754
Validation loss: 2.8249503454835145

Epoch: 6| Step: 6
Training loss: 0.6060735327703944
Validation loss: 2.8563435645607083

Epoch: 6| Step: 7
Training loss: 0.47780834009069945
Validation loss: 2.846905756371434

Epoch: 6| Step: 8
Training loss: 0.5115747904480831
Validation loss: 2.890088940652096

Epoch: 6| Step: 9
Training loss: 0.46699342619804646
Validation loss: 2.888547298418111

Epoch: 6| Step: 10
Training loss: 0.49136905135166575
Validation loss: 2.976274411334878

Epoch: 6| Step: 11
Training loss: 0.5674992505879433
Validation loss: 3.0323445287456354

Epoch: 6| Step: 12
Training loss: 0.42922718360594736
Validation loss: 2.900530091431503

Epoch: 6| Step: 13
Training loss: 0.5666311935466685
Validation loss: 2.976827641356755

Epoch: 298| Step: 0
Training loss: 0.30066381366487
Validation loss: 2.953575059615378

Epoch: 6| Step: 1
Training loss: 0.7050789914957993
Validation loss: 2.928526747591986

Epoch: 6| Step: 2
Training loss: 0.5378635175269658
Validation loss: 2.807862548721721

Epoch: 6| Step: 3
Training loss: 0.6499134868122246
Validation loss: 2.8409889147554637

Epoch: 6| Step: 4
Training loss: 0.37684048565776884
Validation loss: 2.773571387269517

Epoch: 6| Step: 5
Training loss: 0.36965228753864915
Validation loss: 2.929927087100097

Epoch: 6| Step: 6
Training loss: 0.37823864040978783
Validation loss: 2.8447429753851603

Epoch: 6| Step: 7
Training loss: 0.525671079296386
Validation loss: 2.978051067874295

Epoch: 6| Step: 8
Training loss: 0.5245749228633724
Validation loss: 2.896427619568381

Epoch: 6| Step: 9
Training loss: 0.3950940452055012
Validation loss: 2.8871336463716943

Epoch: 6| Step: 10
Training loss: 0.9620954158636081
Validation loss: 2.922733554737156

Epoch: 6| Step: 11
Training loss: 0.390536221906245
Validation loss: 2.9551262911484786

Epoch: 6| Step: 12
Training loss: 0.5073181386955956
Validation loss: 2.917029117588421

Epoch: 6| Step: 13
Training loss: 0.28578141022141157
Validation loss: 2.8992203360474154

Epoch: 299| Step: 0
Training loss: 0.4415803076628484
Validation loss: 2.8244385130358363

Epoch: 6| Step: 1
Training loss: 0.5022332563842055
Validation loss: 2.815691923926061

Epoch: 6| Step: 2
Training loss: 0.5763290449530442
Validation loss: 2.8332392078547435

Epoch: 6| Step: 3
Training loss: 0.35717193536229325
Validation loss: 2.833394012549393

Epoch: 6| Step: 4
Training loss: 0.39104987879513337
Validation loss: 2.916020149147389

Epoch: 6| Step: 5
Training loss: 0.31789352408170224
Validation loss: 2.92492150448625

Epoch: 6| Step: 6
Training loss: 0.48841666823350643
Validation loss: 2.9396801291646026

Epoch: 6| Step: 7
Training loss: 0.44606311178466096
Validation loss: 2.993756114658809

Epoch: 6| Step: 8
Training loss: 0.36409882867656657
Validation loss: 2.9467969639337506

Epoch: 6| Step: 9
Training loss: 0.4999236406192877
Validation loss: 2.938322290351818

Epoch: 6| Step: 10
Training loss: 0.42870918221429355
Validation loss: 2.979282528062594

Epoch: 6| Step: 11
Training loss: 0.35545269437308813
Validation loss: 2.922567737622104

Epoch: 6| Step: 12
Training loss: 1.0723823525518765
Validation loss: 2.9300010954124653

Epoch: 6| Step: 13
Training loss: 0.39353136320073884
Validation loss: 2.878392250004376

Epoch: 300| Step: 0
Training loss: 0.42674869902981777
Validation loss: 2.7972950824119978

Epoch: 6| Step: 1
Training loss: 0.48132418642814906
Validation loss: 2.8310628423521806

Epoch: 6| Step: 2
Training loss: 0.47175687549293016
Validation loss: 2.782238259630663

Epoch: 6| Step: 3
Training loss: 0.9801433372771998
Validation loss: 2.8794464336079844

Epoch: 6| Step: 4
Training loss: 0.3133719914554022
Validation loss: 2.8337723634945466

Epoch: 6| Step: 5
Training loss: 0.3138925044846453
Validation loss: 2.8952550287747902

Epoch: 6| Step: 6
Training loss: 0.4346389373429475
Validation loss: 2.8947137182246023

Epoch: 6| Step: 7
Training loss: 0.5191231178563712
Validation loss: 2.9037342599767046

Epoch: 6| Step: 8
Training loss: 0.4752087517095004
Validation loss: 2.8940467308830504

Epoch: 6| Step: 9
Training loss: 0.26302668435919185
Validation loss: 2.9883575762141055

Epoch: 6| Step: 10
Training loss: 0.3843120283011338
Validation loss: 2.8570487421293236

Epoch: 6| Step: 11
Training loss: 0.29465397926286596
Validation loss: 2.8730372764345806

Epoch: 6| Step: 12
Training loss: 0.23707236389187789
Validation loss: 2.8884096333954337

Epoch: 6| Step: 13
Training loss: 0.4981558886132396
Validation loss: 2.956713398589543

Epoch: 301| Step: 0
Training loss: 0.43838741356269967
Validation loss: 2.9230140464985506

Epoch: 6| Step: 1
Training loss: 0.3272374274080472
Validation loss: 2.834177555271563

Epoch: 6| Step: 2
Training loss: 0.35232543813144557
Validation loss: 2.881465028364266

Epoch: 6| Step: 3
Training loss: 0.2634025894057312
Validation loss: 2.897330786586133

Epoch: 6| Step: 4
Training loss: 0.43458125068528825
Validation loss: 2.813089746879942

Epoch: 6| Step: 5
Training loss: 0.4263625595114205
Validation loss: 2.8687877710718963

Epoch: 6| Step: 6
Training loss: 0.38636867977614314
Validation loss: 2.9173548340714133

Epoch: 6| Step: 7
Training loss: 0.445193827024885
Validation loss: 3.016052268532389

Epoch: 6| Step: 8
Training loss: 0.47513204608902276
Validation loss: 2.8658311981151807

Epoch: 6| Step: 9
Training loss: 0.25741380149209603
Validation loss: 2.913066745020899

Epoch: 6| Step: 10
Training loss: 0.471227235370705
Validation loss: 2.9045083491233346

Epoch: 6| Step: 11
Training loss: 0.9324438443290558
Validation loss: 2.947491218590483

Epoch: 6| Step: 12
Training loss: 0.42114815086326546
Validation loss: 3.002954432274404

Epoch: 6| Step: 13
Training loss: 0.612811643764242
Validation loss: 2.991282738797239

Epoch: 302| Step: 0
Training loss: 0.3873245426538454
Validation loss: 3.002905815877339

Epoch: 6| Step: 1
Training loss: 0.9747890696633993
Validation loss: 2.95947497909615

Epoch: 6| Step: 2
Training loss: 0.3667253873506415
Validation loss: 2.926633621549186

Epoch: 6| Step: 3
Training loss: 0.4099972007818731
Validation loss: 3.0110869447935644

Epoch: 6| Step: 4
Training loss: 0.4469396244351192
Validation loss: 2.870659481776959

Epoch: 6| Step: 5
Training loss: 0.3331817553019059
Validation loss: 3.06731814292303

Epoch: 6| Step: 6
Training loss: 0.4461420263566927
Validation loss: 2.9137992569534696

Epoch: 6| Step: 7
Training loss: 0.3197478924011491
Validation loss: 2.880667283717646

Epoch: 6| Step: 8
Training loss: 0.20826989439838853
Validation loss: 2.99010669411572

Epoch: 6| Step: 9
Training loss: 0.5908781669601231
Validation loss: 2.8646251097436073

Epoch: 6| Step: 10
Training loss: 0.6009388700758242
Validation loss: 2.8230183619425553

Epoch: 6| Step: 11
Training loss: 0.5744081561093929
Validation loss: 2.923453953239808

Epoch: 6| Step: 12
Training loss: 0.42794878040865975
Validation loss: 2.890656424686662

Epoch: 6| Step: 13
Training loss: 0.48972461231163184
Validation loss: 2.991535696777424

Epoch: 303| Step: 0
Training loss: 0.3612873982339514
Validation loss: 2.8910402566751907

Epoch: 6| Step: 1
Training loss: 0.3679961977884056
Validation loss: 2.8620358508637227

Epoch: 6| Step: 2
Training loss: 0.3936108343241121
Validation loss: 2.9230619253515133

Epoch: 6| Step: 3
Training loss: 0.5994997203848523
Validation loss: 2.889498489406772

Epoch: 6| Step: 4
Training loss: 0.5500009298316725
Validation loss: 2.855695570231477

Epoch: 6| Step: 5
Training loss: 0.5188196801875645
Validation loss: 2.9155032607786326

Epoch: 6| Step: 6
Training loss: 0.9349722799996135
Validation loss: 2.933093546870713

Epoch: 6| Step: 7
Training loss: 0.44729504217832433
Validation loss: 2.9136819872288786

Epoch: 6| Step: 8
Training loss: 0.3245412876778964
Validation loss: 2.9513923904298442

Epoch: 6| Step: 9
Training loss: 0.3053186677214098
Validation loss: 2.941816810436017

Epoch: 6| Step: 10
Training loss: 0.5754107604482154
Validation loss: 2.922494859954691

Epoch: 6| Step: 11
Training loss: 0.4257035490759524
Validation loss: 2.9688406545617685

Epoch: 6| Step: 12
Training loss: 0.3809618689712218
Validation loss: 2.958558374003197

Epoch: 6| Step: 13
Training loss: 0.4259245919939628
Validation loss: 2.904802132639885

Epoch: 304| Step: 0
Training loss: 0.44206681238932466
Validation loss: 2.871722564691965

Epoch: 6| Step: 1
Training loss: 0.3933657436366701
Validation loss: 2.9360804002114693

Epoch: 6| Step: 2
Training loss: 0.3060781824068166
Validation loss: 2.895780430225908

Epoch: 6| Step: 3
Training loss: 0.32774291044448617
Validation loss: 2.944985544420741

Epoch: 6| Step: 4
Training loss: 0.2513612404144247
Validation loss: 2.9292793294765476

Epoch: 6| Step: 5
Training loss: 0.3702340256157454
Validation loss: 2.9652152048656406

Epoch: 6| Step: 6
Training loss: 0.43047364884650813
Validation loss: 2.9688984214757532

Epoch: 6| Step: 7
Training loss: 0.34622842136168713
Validation loss: 2.978747869723731

Epoch: 6| Step: 8
Training loss: 0.24437385100267742
Validation loss: 2.8875579508901534

Epoch: 6| Step: 9
Training loss: 0.5283300712657228
Validation loss: 2.949086113446108

Epoch: 6| Step: 10
Training loss: 0.30176040500156825
Validation loss: 2.993314034634111

Epoch: 6| Step: 11
Training loss: 0.47899152485033436
Validation loss: 2.861919778491727

Epoch: 6| Step: 12
Training loss: 0.3284935470945938
Validation loss: 2.9219522448986224

Epoch: 6| Step: 13
Training loss: 0.9315506033919965
Validation loss: 2.9244462801453426

Epoch: 305| Step: 0
Training loss: 0.40029049993806715
Validation loss: 2.9809069630060208

Epoch: 6| Step: 1
Training loss: 0.36244160000869446
Validation loss: 2.948646311330975

Epoch: 6| Step: 2
Training loss: 0.342665022091098
Validation loss: 2.966240367549577

Epoch: 6| Step: 3
Training loss: 0.4782547220015933
Validation loss: 2.9129541111291313

Epoch: 6| Step: 4
Training loss: 0.8775951864233991
Validation loss: 2.8980103183937356

Epoch: 6| Step: 5
Training loss: 0.32713536478370253
Validation loss: 2.9536970011804375

Epoch: 6| Step: 6
Training loss: 0.5711906935292319
Validation loss: 2.897177820931187

Epoch: 6| Step: 7
Training loss: 0.5102958114427456
Validation loss: 2.9161685427416058

Epoch: 6| Step: 8
Training loss: 0.45337706165039543
Validation loss: 2.9595141852416393

Epoch: 6| Step: 9
Training loss: 0.4940801138636524
Validation loss: 2.967420367249302

Epoch: 6| Step: 10
Training loss: 0.45663996191441647
Validation loss: 2.9522309202902703

Epoch: 6| Step: 11
Training loss: 0.4133167388620199
Validation loss: 2.8954166734664053

Epoch: 6| Step: 12
Training loss: 0.45738169284311786
Validation loss: 2.852475191833691

Epoch: 6| Step: 13
Training loss: 0.45272125146126974
Validation loss: 2.9380232838633584

Epoch: 306| Step: 0
Training loss: 0.3520178283421971
Validation loss: 2.842214036803314

Epoch: 6| Step: 1
Training loss: 0.560534726320265
Validation loss: 2.868790721396522

Epoch: 6| Step: 2
Training loss: 0.4359782353719337
Validation loss: 2.9515723531709006

Epoch: 6| Step: 3
Training loss: 0.476682897899395
Validation loss: 2.9532483729404806

Epoch: 6| Step: 4
Training loss: 0.36733746002796247
Validation loss: 2.9975871873763493

Epoch: 6| Step: 5
Training loss: 0.37986682769957314
Validation loss: 2.9818778117394555

Epoch: 6| Step: 6
Training loss: 0.4153678937758143
Validation loss: 2.9697988163275384

Epoch: 6| Step: 7
Training loss: 0.4602620299537181
Validation loss: 2.9042003062273443

Epoch: 6| Step: 8
Training loss: 0.4529904461731085
Validation loss: 2.931345288341726

Epoch: 6| Step: 9
Training loss: 0.4050958818978275
Validation loss: 2.9247437264315135

Epoch: 6| Step: 10
Training loss: 0.3371786654130778
Validation loss: 2.9100086968413237

Epoch: 6| Step: 11
Training loss: 0.39657478992846407
Validation loss: 2.9511036624089932

Epoch: 6| Step: 12
Training loss: 1.0304392315133963
Validation loss: 2.8945549034288205

Epoch: 6| Step: 13
Training loss: 0.3554796908864214
Validation loss: 2.881925051724758

Epoch: 307| Step: 0
Training loss: 0.27499539848292526
Validation loss: 2.9246443274112712

Epoch: 6| Step: 1
Training loss: 0.5257610164110339
Validation loss: 2.9807204127356743

Epoch: 6| Step: 2
Training loss: 0.6618764461973419
Validation loss: 2.9404456067337947

Epoch: 6| Step: 3
Training loss: 0.335041992790232
Validation loss: 2.953831018086621

Epoch: 6| Step: 4
Training loss: 0.9112890177093146
Validation loss: 3.036686731105417

Epoch: 6| Step: 5
Training loss: 0.3468333373953474
Validation loss: 2.913641605202063

Epoch: 6| Step: 6
Training loss: 0.18863756092862508
Validation loss: 2.8673965003733604

Epoch: 6| Step: 7
Training loss: 0.4231510291270827
Validation loss: 2.9807469016123047

Epoch: 6| Step: 8
Training loss: 0.4702847944698061
Validation loss: 2.9356175742198576

Epoch: 6| Step: 9
Training loss: 0.532141834479325
Validation loss: 3.020961329061425

Epoch: 6| Step: 10
Training loss: 0.5263612424836756
Validation loss: 2.8784592866830616

Epoch: 6| Step: 11
Training loss: 0.35097333495832483
Validation loss: 2.9486810796191225

Epoch: 6| Step: 12
Training loss: 0.42025039596924746
Validation loss: 2.984380658795116

Epoch: 6| Step: 13
Training loss: 0.34316961102676125
Validation loss: 2.935588228091374

Epoch: 308| Step: 0
Training loss: 0.39984916734025583
Validation loss: 2.982215646051786

Epoch: 6| Step: 1
Training loss: 0.4086978415070282
Validation loss: 2.9809721208753355

Epoch: 6| Step: 2
Training loss: 0.4426737453936475
Validation loss: 2.947276154792772

Epoch: 6| Step: 3
Training loss: 0.4220334567845938
Validation loss: 2.9177236866890346

Epoch: 6| Step: 4
Training loss: 0.2746382371215179
Validation loss: 2.8255939573796134

Epoch: 6| Step: 5
Training loss: 0.9139729317365214
Validation loss: 2.911345578070589

Epoch: 6| Step: 6
Training loss: 0.5009575555776264
Validation loss: 2.892706758917459

Epoch: 6| Step: 7
Training loss: 0.4142815891980114
Validation loss: 2.9518714208646495

Epoch: 6| Step: 8
Training loss: 0.48923707107162184
Validation loss: 2.877681518251533

Epoch: 6| Step: 9
Training loss: 0.5943537202670032
Validation loss: 2.903668737392441

Epoch: 6| Step: 10
Training loss: 0.4704580658377612
Validation loss: 2.87854421229288

Epoch: 6| Step: 11
Training loss: 0.5965410436705286
Validation loss: 2.9281141201537757

Epoch: 6| Step: 12
Training loss: 0.4707366171670224
Validation loss: 2.902222293247996

Epoch: 6| Step: 13
Training loss: 0.5309823989070317
Validation loss: 2.8367005469752775

Epoch: 309| Step: 0
Training loss: 0.43196811594126927
Validation loss: 2.9104151941257936

Epoch: 6| Step: 1
Training loss: 0.38383959177919164
Validation loss: 2.8458759200417645

Epoch: 6| Step: 2
Training loss: 0.49429828405443194
Validation loss: 2.9792850622024045

Epoch: 6| Step: 3
Training loss: 0.3287161089467124
Validation loss: 3.0353956942247224

Epoch: 6| Step: 4
Training loss: 0.3020113154866681
Validation loss: 3.0200350704219936

Epoch: 6| Step: 5
Training loss: 0.3736536374148719
Validation loss: 2.9398082700263255

Epoch: 6| Step: 6
Training loss: 0.3503206359639921
Validation loss: 2.95585342123646

Epoch: 6| Step: 7
Training loss: 0.33632870008395094
Validation loss: 2.9748537861131648

Epoch: 6| Step: 8
Training loss: 0.52663752986291
Validation loss: 2.940020757978169

Epoch: 6| Step: 9
Training loss: 0.9417248262038793
Validation loss: 2.8911656192044553

Epoch: 6| Step: 10
Training loss: 0.2416596197191555
Validation loss: 2.9318401650824866

Epoch: 6| Step: 11
Training loss: 0.4136165160401069
Validation loss: 2.888479078907672

Epoch: 6| Step: 12
Training loss: 0.4053142481099286
Validation loss: 2.9788069919177143

Epoch: 6| Step: 13
Training loss: 0.45303327355489104
Validation loss: 2.990090135600004

Epoch: 310| Step: 0
Training loss: 0.4461947952980048
Validation loss: 2.9232922820888407

Epoch: 6| Step: 1
Training loss: 0.9144664100226219
Validation loss: 2.9398855303193736

Epoch: 6| Step: 2
Training loss: 0.3621591856769443
Validation loss: 2.95886662650757

Epoch: 6| Step: 3
Training loss: 0.3836046314444206
Validation loss: 3.0587233917446692

Epoch: 6| Step: 4
Training loss: 0.3968065766051499
Validation loss: 2.9713066736962057

Epoch: 6| Step: 5
Training loss: 0.3604134607264354
Validation loss: 2.9199737101943426

Epoch: 6| Step: 6
Training loss: 0.40073714729349963
Validation loss: 2.868949549652793

Epoch: 6| Step: 7
Training loss: 0.34543889395051397
Validation loss: 2.8432096030745573

Epoch: 6| Step: 8
Training loss: 0.4713736858506397
Validation loss: 2.884451960800571

Epoch: 6| Step: 9
Training loss: 0.36911129708825763
Validation loss: 2.927695869801655

Epoch: 6| Step: 10
Training loss: 0.4398779616932353
Validation loss: 2.914897291185402

Epoch: 6| Step: 11
Training loss: 0.3956172273725074
Validation loss: 2.8832623717408854

Epoch: 6| Step: 12
Training loss: 0.6101800051862528
Validation loss: 2.8973684472936054

Epoch: 6| Step: 13
Training loss: 0.44307045618383534
Validation loss: 2.853563945830249

Epoch: 311| Step: 0
Training loss: 0.3645487382914833
Validation loss: 2.8963393219844815

Epoch: 6| Step: 1
Training loss: 0.9569380734297254
Validation loss: 2.9080386656508557

Epoch: 6| Step: 2
Training loss: 0.3685533807566593
Validation loss: 2.9371998139798468

Epoch: 6| Step: 3
Training loss: 0.32706074464553997
Validation loss: 2.940271301294433

Epoch: 6| Step: 4
Training loss: 0.3751908849626719
Validation loss: 2.90461289705203

Epoch: 6| Step: 5
Training loss: 0.2802874996897613
Validation loss: 2.8703797782609324

Epoch: 6| Step: 6
Training loss: 0.30735554543043303
Validation loss: 2.9346418612152667

Epoch: 6| Step: 7
Training loss: 0.5082080474310182
Validation loss: 2.8742286089553266

Epoch: 6| Step: 8
Training loss: 0.26636621896008544
Validation loss: 2.9260918283061543

Epoch: 6| Step: 9
Training loss: 0.36744234696818695
Validation loss: 2.9225453034591404

Epoch: 6| Step: 10
Training loss: 0.3646528132400361
Validation loss: 2.8969230431143047

Epoch: 6| Step: 11
Training loss: 0.39188897675285894
Validation loss: 2.8651783042089844

Epoch: 6| Step: 12
Training loss: 0.47813981538146
Validation loss: 2.8940290186081166

Epoch: 6| Step: 13
Training loss: 0.5332692702630232
Validation loss: 2.932436630613678

Epoch: 312| Step: 0
Training loss: 0.8592176813568834
Validation loss: 2.9736466831829618

Epoch: 6| Step: 1
Training loss: 0.4796708467556314
Validation loss: 2.8950775770335833

Epoch: 6| Step: 2
Training loss: 0.41988369080571164
Validation loss: 2.927537052561814

Epoch: 6| Step: 3
Training loss: 0.5007869964127084
Validation loss: 2.912899872885084

Epoch: 6| Step: 4
Training loss: 0.47525363725678055
Validation loss: 2.907806758885197

Epoch: 6| Step: 5
Training loss: 0.3347051327688215
Validation loss: 2.985227506350024

Epoch: 6| Step: 6
Training loss: 0.49941178829673366
Validation loss: 2.872064888992386

Epoch: 6| Step: 7
Training loss: 0.4358918914727296
Validation loss: 2.9694336890285666

Epoch: 6| Step: 8
Training loss: 0.3058321798226607
Validation loss: 2.8925345497189046

Epoch: 6| Step: 9
Training loss: 0.37616873449676375
Validation loss: 2.9536914584912406

Epoch: 6| Step: 10
Training loss: 0.28917765256852873
Validation loss: 2.958072722511924

Epoch: 6| Step: 11
Training loss: 0.3471020878815287
Validation loss: 2.895602900898775

Epoch: 6| Step: 12
Training loss: 0.4990431749953251
Validation loss: 2.97617968402904

Epoch: 6| Step: 13
Training loss: 0.28836967590420837
Validation loss: 2.977252990252205

Epoch: 313| Step: 0
Training loss: 0.3842590986910684
Validation loss: 2.978886909065251

Epoch: 6| Step: 1
Training loss: 0.3580303120553782
Validation loss: 2.8526538171510736

Epoch: 6| Step: 2
Training loss: 0.4647365414382627
Validation loss: 2.9030388213288667

Epoch: 6| Step: 3
Training loss: 0.2603645304306983
Validation loss: 2.890034809518895

Epoch: 6| Step: 4
Training loss: 0.9456004500243606
Validation loss: 2.94233000807421

Epoch: 6| Step: 5
Training loss: 0.32831021031819985
Validation loss: 2.9529390495194443

Epoch: 6| Step: 6
Training loss: 0.6305498479896648
Validation loss: 3.084253989914941

Epoch: 6| Step: 7
Training loss: 0.4534212327979751
Validation loss: 2.9776360685836916

Epoch: 6| Step: 8
Training loss: 0.4886212500337796
Validation loss: 3.0118489449640546

Epoch: 6| Step: 9
Training loss: 0.33361570746099745
Validation loss: 2.9343891310021504

Epoch: 6| Step: 10
Training loss: 0.4477286960905288
Validation loss: 2.8961972252706842

Epoch: 6| Step: 11
Training loss: 0.324404973242088
Validation loss: 2.9384892739041835

Epoch: 6| Step: 12
Training loss: 0.2991900029329755
Validation loss: 2.970999685144723

Epoch: 6| Step: 13
Training loss: 0.45040238390722764
Validation loss: 2.9366157770095516

Epoch: 314| Step: 0
Training loss: 0.4200064640456
Validation loss: 2.948636136812525

Epoch: 6| Step: 1
Training loss: 0.37191841449080404
Validation loss: 3.002401834217727

Epoch: 6| Step: 2
Training loss: 0.3575883904805279
Validation loss: 3.006116962198829

Epoch: 6| Step: 3
Training loss: 0.4413217784434035
Validation loss: 2.983542361120312

Epoch: 6| Step: 4
Training loss: 0.4070499137655752
Validation loss: 2.941016804250757

Epoch: 6| Step: 5
Training loss: 0.40733539032780913
Validation loss: 3.009232183535674

Epoch: 6| Step: 6
Training loss: 0.4036976709202275
Validation loss: 2.991668045199474

Epoch: 6| Step: 7
Training loss: 0.3616624265120443
Validation loss: 2.935608464498272

Epoch: 6| Step: 8
Training loss: 0.38423290262300464
Validation loss: 2.91916726864754

Epoch: 6| Step: 9
Training loss: 0.6390218913040189
Validation loss: 2.9282113658608275

Epoch: 6| Step: 10
Training loss: 0.45837686794327953
Validation loss: 2.9306816075973616

Epoch: 6| Step: 11
Training loss: 0.28968496574601943
Validation loss: 2.971622937433942

Epoch: 6| Step: 12
Training loss: 0.4453780142794266
Validation loss: 2.9359880709323503

Epoch: 6| Step: 13
Training loss: 0.9475607500756473
Validation loss: 2.964133451045292

Epoch: 315| Step: 0
Training loss: 0.5329627029491923
Validation loss: 2.9707323650164232

Epoch: 6| Step: 1
Training loss: 0.4680606541637323
Validation loss: 2.9361537391513846

Epoch: 6| Step: 2
Training loss: 0.34791677336015414
Validation loss: 2.9893226952974623

Epoch: 6| Step: 3
Training loss: 0.3396470827203968
Validation loss: 2.9078983021600955

Epoch: 6| Step: 4
Training loss: 0.2790491833131312
Validation loss: 2.8779746713219616

Epoch: 6| Step: 5
Training loss: 0.4814166201694425
Validation loss: 2.893028744480599

Epoch: 6| Step: 6
Training loss: 0.4110350503919107
Validation loss: 2.86635650317114

Epoch: 6| Step: 7
Training loss: 0.8918270565478158
Validation loss: 2.9552975825450623

Epoch: 6| Step: 8
Training loss: 0.3224238614094399
Validation loss: 2.8970588359641023

Epoch: 6| Step: 9
Training loss: 0.4530588299022059
Validation loss: 2.971967178664078

Epoch: 6| Step: 10
Training loss: 0.45689145419944815
Validation loss: 2.956150288207437

Epoch: 6| Step: 11
Training loss: 0.5511100274741036
Validation loss: 2.973467976261432

Epoch: 6| Step: 12
Training loss: 0.37078326437331016
Validation loss: 2.923173245411189

Epoch: 6| Step: 13
Training loss: 0.2719655883528147
Validation loss: 2.8205297779138143

Epoch: 316| Step: 0
Training loss: 0.398312474250643
Validation loss: 2.807440976127929

Epoch: 6| Step: 1
Training loss: 0.3747471910896922
Validation loss: 2.8628162320409767

Epoch: 6| Step: 2
Training loss: 0.294210244864666
Validation loss: 2.8965425697700335

Epoch: 6| Step: 3
Training loss: 0.581900793214786
Validation loss: 2.873558567657215

Epoch: 6| Step: 4
Training loss: 0.3846317774919669
Validation loss: 2.8644053918306986

Epoch: 6| Step: 5
Training loss: 0.2967853285232189
Validation loss: 2.9442856783818514

Epoch: 6| Step: 6
Training loss: 0.40077219203655134
Validation loss: 2.9910967825090884

Epoch: 6| Step: 7
Training loss: 0.4981780085245153
Validation loss: 2.9596420715409377

Epoch: 6| Step: 8
Training loss: 0.3868485627824509
Validation loss: 2.9580267536895626

Epoch: 6| Step: 9
Training loss: 0.3805035616323275
Validation loss: 2.8990850830514376

Epoch: 6| Step: 10
Training loss: 0.6473472806156124
Validation loss: 2.9366993455515535

Epoch: 6| Step: 11
Training loss: 0.19677495836653214
Validation loss: 2.813514145160191

Epoch: 6| Step: 12
Training loss: 0.9538665450797067
Validation loss: 2.8745507981257616

Epoch: 6| Step: 13
Training loss: 0.3876820136799314
Validation loss: 2.8946893385437535

Epoch: 317| Step: 0
Training loss: 0.4056068978877085
Validation loss: 2.895278264553717

Epoch: 6| Step: 1
Training loss: 0.2978571281538467
Validation loss: 2.878059141804838

Epoch: 6| Step: 2
Training loss: 0.34739784752959113
Validation loss: 2.9162846224207075

Epoch: 6| Step: 3
Training loss: 0.4535839945985561
Validation loss: 2.918243082097187

Epoch: 6| Step: 4
Training loss: 0.44394148201051425
Validation loss: 2.946034445005982

Epoch: 6| Step: 5
Training loss: 0.32897950351127647
Validation loss: 2.9452695834998774

Epoch: 6| Step: 6
Training loss: 0.40319057345279596
Validation loss: 2.970681629525323

Epoch: 6| Step: 7
Training loss: 0.43658805215339586
Validation loss: 2.9528818989153036

Epoch: 6| Step: 8
Training loss: 0.401980263671538
Validation loss: 2.891369409334186

Epoch: 6| Step: 9
Training loss: 0.3342307002217
Validation loss: 2.9799114087823284

Epoch: 6| Step: 10
Training loss: 0.3294821103945717
Validation loss: 2.9077930250955677

Epoch: 6| Step: 11
Training loss: 0.42654375167838404
Validation loss: 2.947910084172281

Epoch: 6| Step: 12
Training loss: 0.6417939291089477
Validation loss: 2.8478729905130584

Epoch: 6| Step: 13
Training loss: 0.9939218216629615
Validation loss: 2.9707838085553244

Epoch: 318| Step: 0
Training loss: 0.38023193712865755
Validation loss: 2.9077180142282604

Epoch: 6| Step: 1
Training loss: 0.2907989898919569
Validation loss: 2.987577401173384

Epoch: 6| Step: 2
Training loss: 0.1969438326564135
Validation loss: 3.0148835398933187

Epoch: 6| Step: 3
Training loss: 0.3535547392898537
Validation loss: 2.916601906920335

Epoch: 6| Step: 4
Training loss: 0.39219506397020215
Validation loss: 2.950536532022182

Epoch: 6| Step: 5
Training loss: 0.49116931534178004
Validation loss: 3.004462420066816

Epoch: 6| Step: 6
Training loss: 0.8846442200353033
Validation loss: 2.929101219006802

Epoch: 6| Step: 7
Training loss: 0.3281855186783265
Validation loss: 2.97135467038943

Epoch: 6| Step: 8
Training loss: 0.3952554156434859
Validation loss: 3.002802784623779

Epoch: 6| Step: 9
Training loss: 0.46207897637700657
Validation loss: 2.995684592879067

Epoch: 6| Step: 10
Training loss: 0.46020582285044187
Validation loss: 2.922099820495797

Epoch: 6| Step: 11
Training loss: 0.43358055300862564
Validation loss: 2.9592255379712955

Epoch: 6| Step: 12
Training loss: 0.5301509034156747
Validation loss: 2.954785238552751

Epoch: 6| Step: 13
Training loss: 0.3280440412282228
Validation loss: 2.96322373135661

Epoch: 319| Step: 0
Training loss: 0.42848220319301505
Validation loss: 2.9730336655225695

Epoch: 6| Step: 1
Training loss: 0.424850882287606
Validation loss: 2.97596490422956

Epoch: 6| Step: 2
Training loss: 0.29578902484733055
Validation loss: 2.8466655890070407

Epoch: 6| Step: 3
Training loss: 0.3407217063464161
Validation loss: 2.9178581846670775

Epoch: 6| Step: 4
Training loss: 0.850874001287348
Validation loss: 3.0569210228568435

Epoch: 6| Step: 5
Training loss: 0.291966440347843
Validation loss: 2.971254904869609

Epoch: 6| Step: 6
Training loss: 0.2684441217487278
Validation loss: 2.977570277211307

Epoch: 6| Step: 7
Training loss: 0.48261195465178014
Validation loss: 2.9220180510455767

Epoch: 6| Step: 8
Training loss: 0.37338744590201833
Validation loss: 2.9030186590203235

Epoch: 6| Step: 9
Training loss: 0.40540890555224
Validation loss: 2.9902351856126774

Epoch: 6| Step: 10
Training loss: 0.5006622458710192
Validation loss: 2.9329929134405974

Epoch: 6| Step: 11
Training loss: 0.37023541416747646
Validation loss: 2.9016655343009874

Epoch: 6| Step: 12
Training loss: 0.48564056450094234
Validation loss: 2.961876524869633

Epoch: 6| Step: 13
Training loss: 0.5206008455825779
Validation loss: 2.946291773374105

Epoch: 320| Step: 0
Training loss: 0.8517013576581399
Validation loss: 2.965732968840116

Epoch: 6| Step: 1
Training loss: 0.5736965737577476
Validation loss: 2.9093571259099438

Epoch: 6| Step: 2
Training loss: 0.30992524891645096
Validation loss: 2.977235706257129

Epoch: 6| Step: 3
Training loss: 0.43877083264312206
Validation loss: 3.0701922133472674

Epoch: 6| Step: 4
Training loss: 0.3153995936538072
Validation loss: 2.9186436810077034

Epoch: 6| Step: 5
Training loss: 0.26092571414668125
Validation loss: 2.899107685050179

Epoch: 6| Step: 6
Training loss: 0.39128956530701386
Validation loss: 2.9537727412552277

Epoch: 6| Step: 7
Training loss: 0.46205046819220025
Validation loss: 2.913792083711257

Epoch: 6| Step: 8
Training loss: 0.36790886490881713
Validation loss: 2.907313080648087

Epoch: 6| Step: 9
Training loss: 0.40274344655132954
Validation loss: 2.9482483065089835

Epoch: 6| Step: 10
Training loss: 0.32838056466463134
Validation loss: 2.9340955471862373

Epoch: 6| Step: 11
Training loss: 0.411020023341991
Validation loss: 2.9396820350980875

Epoch: 6| Step: 12
Training loss: 0.3835714562924236
Validation loss: 2.8917699659807092

Epoch: 6| Step: 13
Training loss: 0.40177412356960573
Validation loss: 2.9803627031957878

Epoch: 321| Step: 0
Training loss: 0.46202931166014255
Validation loss: 2.9887758066001076

Epoch: 6| Step: 1
Training loss: 0.28159753202574705
Validation loss: 2.925892860446633

Epoch: 6| Step: 2
Training loss: 0.3143405594360913
Validation loss: 2.8173758874165684

Epoch: 6| Step: 3
Training loss: 0.3883491594885272
Validation loss: 2.916244003915434

Epoch: 6| Step: 4
Training loss: 0.8624275785254631
Validation loss: 2.893612378159318

Epoch: 6| Step: 5
Training loss: 0.3707796875944467
Validation loss: 2.9142782354737515

Epoch: 6| Step: 6
Training loss: 0.44487002625757227
Validation loss: 2.9775644586751415

Epoch: 6| Step: 7
Training loss: 0.5121445958692666
Validation loss: 2.900751484044309

Epoch: 6| Step: 8
Training loss: 0.552434320861252
Validation loss: 2.8628282244989967

Epoch: 6| Step: 9
Training loss: 0.4438681686915576
Validation loss: 2.867813346945527

Epoch: 6| Step: 10
Training loss: 0.3852458609742967
Validation loss: 2.8372275620804426

Epoch: 6| Step: 11
Training loss: 0.5273701413932842
Validation loss: 2.9029232386191657

Epoch: 6| Step: 12
Training loss: 0.4590082365286004
Validation loss: 2.916757763847781

Epoch: 6| Step: 13
Training loss: 0.4292434478641838
Validation loss: 2.9277502275393594

Epoch: 322| Step: 0
Training loss: 0.27742089286679766
Validation loss: 2.940837181941305

Epoch: 6| Step: 1
Training loss: 0.490726239395345
Validation loss: 3.020658387127824

Epoch: 6| Step: 2
Training loss: 0.8725302104037254
Validation loss: 2.914969786263295

Epoch: 6| Step: 3
Training loss: 0.3249526392834073
Validation loss: 2.940863624698519

Epoch: 6| Step: 4
Training loss: 0.39634593181435174
Validation loss: 2.9939337831283037

Epoch: 6| Step: 5
Training loss: 0.3505174787832249
Validation loss: 2.9736480996459815

Epoch: 6| Step: 6
Training loss: 0.33817136270390585
Validation loss: 2.818185654201302

Epoch: 6| Step: 7
Training loss: 0.3843088488527107
Validation loss: 2.8758383648088763

Epoch: 6| Step: 8
Training loss: 0.313771379585889
Validation loss: 2.860763726754862

Epoch: 6| Step: 9
Training loss: 0.4448896709572986
Validation loss: 2.8422404184530285

Epoch: 6| Step: 10
Training loss: 0.40841844346436296
Validation loss: 2.831269477906359

Epoch: 6| Step: 11
Training loss: 0.2165022213758019
Validation loss: 2.89525678553246

Epoch: 6| Step: 12
Training loss: 0.4332128690512917
Validation loss: 2.937323909919585

Epoch: 6| Step: 13
Training loss: 0.4692962801176835
Validation loss: 2.8999832980453273

Epoch: 323| Step: 0
Training loss: 0.3627524680612996
Validation loss: 2.8454418948290523

Epoch: 6| Step: 1
Training loss: 0.40565876853989163
Validation loss: 2.9436427880462914

Epoch: 6| Step: 2
Training loss: 0.3758946713525791
Validation loss: 2.9316275721493854

Epoch: 6| Step: 3
Training loss: 0.4307349875386241
Validation loss: 2.8427109968639592

Epoch: 6| Step: 4
Training loss: 0.41241752710379187
Validation loss: 2.85824415292072

Epoch: 6| Step: 5
Training loss: 0.39973481596880006
Validation loss: 2.9343017455230993

Epoch: 6| Step: 6
Training loss: 0.4252770439521316
Validation loss: 2.9265075515501042

Epoch: 6| Step: 7
Training loss: 0.36741227513984753
Validation loss: 2.906839932963103

Epoch: 6| Step: 8
Training loss: 0.40244736309498075
Validation loss: 2.9577091368925617

Epoch: 6| Step: 9
Training loss: 0.9024925604643068
Validation loss: 2.86781962370794

Epoch: 6| Step: 10
Training loss: 0.2786295327502014
Validation loss: 2.984893514117195

Epoch: 6| Step: 11
Training loss: 0.37932060631037906
Validation loss: 2.926058366908246

Epoch: 6| Step: 12
Training loss: 0.38165704385351135
Validation loss: 2.9118070353791246

Epoch: 6| Step: 13
Training loss: 0.3628377771238318
Validation loss: 2.925529791734664

Epoch: 324| Step: 0
Training loss: 0.5168207349048487
Validation loss: 2.8617481327032466

Epoch: 6| Step: 1
Training loss: 0.41824851967138615
Validation loss: 2.999671706144721

Epoch: 6| Step: 2
Training loss: 0.34896697797553383
Validation loss: 2.9025423881289756

Epoch: 6| Step: 3
Training loss: 0.8309723827877573
Validation loss: 2.9472698989409105

Epoch: 6| Step: 4
Training loss: 0.2705913373436705
Validation loss: 2.915295760089319

Epoch: 6| Step: 5
Training loss: 0.33698411296219294
Validation loss: 2.926572155465544

Epoch: 6| Step: 6
Training loss: 0.4532876216173673
Validation loss: 2.76252377299901

Epoch: 6| Step: 7
Training loss: 0.3397461871711447
Validation loss: 2.8904218447666676

Epoch: 6| Step: 8
Training loss: 0.3454468633998803
Validation loss: 2.9293587055082737

Epoch: 6| Step: 9
Training loss: 0.322196074407758
Validation loss: 2.9283420033146523

Epoch: 6| Step: 10
Training loss: 0.3360555796138598
Validation loss: 2.9676042989534217

Epoch: 6| Step: 11
Training loss: 0.34193618115390584
Validation loss: 2.964735160651752

Epoch: 6| Step: 12
Training loss: 0.3173032220667843
Validation loss: 3.0071024795676093

Epoch: 6| Step: 13
Training loss: 0.4522778715082469
Validation loss: 2.872892353562641

Epoch: 325| Step: 0
Training loss: 0.5387302425151566
Validation loss: 2.9497043908712595

Epoch: 6| Step: 1
Training loss: 0.2420955914257093
Validation loss: 2.892470476927967

Epoch: 6| Step: 2
Training loss: 0.5790224584167022
Validation loss: 2.9042955068051866

Epoch: 6| Step: 3
Training loss: 0.3088686237950699
Validation loss: 2.9586593734814066

Epoch: 6| Step: 4
Training loss: 0.3022636198961804
Validation loss: 2.929397460143856

Epoch: 6| Step: 5
Training loss: 0.24938557043116366
Validation loss: 2.874538605749312

Epoch: 6| Step: 6
Training loss: 0.4500757749655392
Validation loss: 2.9013799382249204

Epoch: 6| Step: 7
Training loss: 0.3874615942473239
Validation loss: 2.9311417831475524

Epoch: 6| Step: 8
Training loss: 0.3585245186123862
Validation loss: 2.9276286711134136

Epoch: 6| Step: 9
Training loss: 0.9237356643700022
Validation loss: 2.921933845022663

Epoch: 6| Step: 10
Training loss: 0.40269734298396925
Validation loss: 2.90985903320931

Epoch: 6| Step: 11
Training loss: 0.2558854359174416
Validation loss: 2.9632702766320542

Epoch: 6| Step: 12
Training loss: 0.5166064949016511
Validation loss: 3.0118893691706554

Epoch: 6| Step: 13
Training loss: 0.3933651943590788
Validation loss: 2.954567841020439

Epoch: 326| Step: 0
Training loss: 0.86606153642626
Validation loss: 2.880123990268557

Epoch: 6| Step: 1
Training loss: 0.3622221737080199
Validation loss: 2.9421555441567615

Epoch: 6| Step: 2
Training loss: 0.3732735708986916
Validation loss: 2.867135472739461

Epoch: 6| Step: 3
Training loss: 0.5038566269208891
Validation loss: 2.897180605189483

Epoch: 6| Step: 4
Training loss: 0.2752920339513674
Validation loss: 2.832195015918746

Epoch: 6| Step: 5
Training loss: 0.31075314802768017
Validation loss: 2.9219150370474427

Epoch: 6| Step: 6
Training loss: 0.38625870901616255
Validation loss: 2.892806925665743

Epoch: 6| Step: 7
Training loss: 0.34022496207144043
Validation loss: 2.9114608127717645

Epoch: 6| Step: 8
Training loss: 0.4296534784893376
Validation loss: 2.90957238401534

Epoch: 6| Step: 9
Training loss: 0.5190199436883505
Validation loss: 2.9357045686066194

Epoch: 6| Step: 10
Training loss: 0.4251505528986231
Validation loss: 3.0275330186970617

Epoch: 6| Step: 11
Training loss: 0.4502797409626417
Validation loss: 2.914534052517852

Epoch: 6| Step: 12
Training loss: 0.43801514065823594
Validation loss: 2.866025212697209

Epoch: 6| Step: 13
Training loss: 0.5721714606294923
Validation loss: 2.8502643713554083

Epoch: 327| Step: 0
Training loss: 0.30599313152231017
Validation loss: 2.853777313591846

Epoch: 6| Step: 1
Training loss: 0.45759469537494696
Validation loss: 2.854941566880329

Epoch: 6| Step: 2
Training loss: 0.32152261332782944
Validation loss: 2.9242330273758608

Epoch: 6| Step: 3
Training loss: 0.36978140221261147
Validation loss: 2.9684011421690437

Epoch: 6| Step: 4
Training loss: 0.23451197118643108
Validation loss: 2.9295884586123555

Epoch: 6| Step: 5
Training loss: 0.5388217056509282
Validation loss: 2.896386612836918

Epoch: 6| Step: 6
Training loss: 0.30852657504438935
Validation loss: 2.9873762900517304

Epoch: 6| Step: 7
Training loss: 0.33610107076945916
Validation loss: 2.9337272359698696

Epoch: 6| Step: 8
Training loss: 0.8831735058507856
Validation loss: 2.938749602185407

Epoch: 6| Step: 9
Training loss: 0.3462003375839602
Validation loss: 2.975285133353753

Epoch: 6| Step: 10
Training loss: 0.4511461457021168
Validation loss: 2.9348468296909727

Epoch: 6| Step: 11
Training loss: 0.3623777865881362
Validation loss: 2.9186516455906695

Epoch: 6| Step: 12
Training loss: 0.4458002798656306
Validation loss: 2.9066924028467565

Epoch: 6| Step: 13
Training loss: 0.31119323737591487
Validation loss: 2.927839111463427

Epoch: 328| Step: 0
Training loss: 0.8561827236392897
Validation loss: 2.946819146046017

Epoch: 6| Step: 1
Training loss: 0.4287529231825402
Validation loss: 2.9410307341820974

Epoch: 6| Step: 2
Training loss: 0.42391021214850544
Validation loss: 2.988380194461641

Epoch: 6| Step: 3
Training loss: 0.40164323581454703
Validation loss: 2.9921973670683903

Epoch: 6| Step: 4
Training loss: 0.4020980714491783
Validation loss: 2.9425778295335445

Epoch: 6| Step: 5
Training loss: 0.34028736844895596
Validation loss: 2.9063174742382536

Epoch: 6| Step: 6
Training loss: 0.4446722748885067
Validation loss: 3.0177094497827834

Epoch: 6| Step: 7
Training loss: 0.38675485307574325
Validation loss: 2.818060936903595

Epoch: 6| Step: 8
Training loss: 0.4345382507155327
Validation loss: 2.9892056898964645

Epoch: 6| Step: 9
Training loss: 0.4047360269621553
Validation loss: 2.9871383176718145

Epoch: 6| Step: 10
Training loss: 0.4604838773885168
Validation loss: 2.9418483501518806

Epoch: 6| Step: 11
Training loss: 0.5524834106940935
Validation loss: 2.9676397020878187

Epoch: 6| Step: 12
Training loss: 0.4697808057906893
Validation loss: 2.8889875774664437

Epoch: 6| Step: 13
Training loss: 0.3038913154364725
Validation loss: 2.8798264335942494

Epoch: 329| Step: 0
Training loss: 0.9274088398844257
Validation loss: 2.8728177731104325

Epoch: 6| Step: 1
Training loss: 0.3137288133337327
Validation loss: 2.894460920062027

Epoch: 6| Step: 2
Training loss: 0.43031511420935886
Validation loss: 2.911381542487429

Epoch: 6| Step: 3
Training loss: 0.46583481931989634
Validation loss: 2.9973166439003545

Epoch: 6| Step: 4
Training loss: 0.3447686836942027
Validation loss: 2.9158940290958846

Epoch: 6| Step: 5
Training loss: 0.4915868030222378
Validation loss: 2.9663121704582345

Epoch: 6| Step: 6
Training loss: 0.5647211725342296
Validation loss: 2.9013778016949

Epoch: 6| Step: 7
Training loss: 0.388392707592915
Validation loss: 2.903866121748476

Epoch: 6| Step: 8
Training loss: 0.4374072112732207
Validation loss: 2.916865469197217

Epoch: 6| Step: 9
Training loss: 0.39185796700653625
Validation loss: 2.9216420153854354

Epoch: 6| Step: 10
Training loss: 0.4248670159577648
Validation loss: 2.9563944646204154

Epoch: 6| Step: 11
Training loss: 0.4222364643201783
Validation loss: 2.843835584868729

Epoch: 6| Step: 12
Training loss: 0.3036887353957148
Validation loss: 2.7878644348627586

Epoch: 6| Step: 13
Training loss: 0.39922188236926254
Validation loss: 2.957392171236023

Epoch: 330| Step: 0
Training loss: 0.43543443810853966
Validation loss: 2.94439649292949

Epoch: 6| Step: 1
Training loss: 0.40724271746822016
Validation loss: 2.797922069821759

Epoch: 6| Step: 2
Training loss: 0.3006651270251456
Validation loss: 2.875031429616546

Epoch: 6| Step: 3
Training loss: 0.389086439935817
Validation loss: 2.8486639750627365

Epoch: 6| Step: 4
Training loss: 0.3061900503492692
Validation loss: 2.931591950990316

Epoch: 6| Step: 5
Training loss: 0.31308596034534775
Validation loss: 2.973671110394114

Epoch: 6| Step: 6
Training loss: 0.448828403217173
Validation loss: 2.9623332764057615

Epoch: 6| Step: 7
Training loss: 0.2855561470164974
Validation loss: 2.879892609015707

Epoch: 6| Step: 8
Training loss: 0.45811708362812165
Validation loss: 2.940195118815336

Epoch: 6| Step: 9
Training loss: 0.38787768324115357
Validation loss: 2.920712489640765

Epoch: 6| Step: 10
Training loss: 0.33808998885611474
Validation loss: 2.8064874028957822

Epoch: 6| Step: 11
Training loss: 0.9331542700477633
Validation loss: 2.92601591492499

Epoch: 6| Step: 12
Training loss: 0.23348512196978183
Validation loss: 2.921631651619755

Epoch: 6| Step: 13
Training loss: 0.3293637326609779
Validation loss: 2.8894475239855053

Epoch: 331| Step: 0
Training loss: 0.5201937244926998
Validation loss: 2.959449991620784

Epoch: 6| Step: 1
Training loss: 0.3388972859936098
Validation loss: 2.9448740368875814

Epoch: 6| Step: 2
Training loss: 0.2932572025608072
Validation loss: 2.901300200762559

Epoch: 6| Step: 3
Training loss: 0.40526586318693875
Validation loss: 2.9946667764026196

Epoch: 6| Step: 4
Training loss: 0.48860064931987196
Validation loss: 2.893549743709918

Epoch: 6| Step: 5
Training loss: 0.5514950286834848
Validation loss: 2.905485962005315

Epoch: 6| Step: 6
Training loss: 0.3781920121452844
Validation loss: 2.9647023900659577

Epoch: 6| Step: 7
Training loss: 0.8745835539399684
Validation loss: 2.9005817525892237

Epoch: 6| Step: 8
Training loss: 0.4476830812305651
Validation loss: 2.9005138024269868

Epoch: 6| Step: 9
Training loss: 0.34470866645850073
Validation loss: 2.9712086585366007

Epoch: 6| Step: 10
Training loss: 0.3109326275966111
Validation loss: 2.980086515822094

Epoch: 6| Step: 11
Training loss: 0.5072830374399585
Validation loss: 2.9364671446979385

Epoch: 6| Step: 12
Training loss: 0.40444431288700156
Validation loss: 2.9682604068134677

Epoch: 6| Step: 13
Training loss: 0.3217520233518978
Validation loss: 2.9666321545282908

Epoch: 332| Step: 0
Training loss: 0.27408701185704104
Validation loss: 2.9950879998034394

Epoch: 6| Step: 1
Training loss: 0.3719259267284296
Validation loss: 2.918546320733402

Epoch: 6| Step: 2
Training loss: 0.5387865548886877
Validation loss: 2.90894783071853

Epoch: 6| Step: 3
Training loss: 0.39654042641700715
Validation loss: 2.9369565853399244

Epoch: 6| Step: 4
Training loss: 0.38946194117447497
Validation loss: 2.9471993578991587

Epoch: 6| Step: 5
Training loss: 0.25823210757018267
Validation loss: 2.9408527071249715

Epoch: 6| Step: 6
Training loss: 0.43302663883480313
Validation loss: 2.8552705388957187

Epoch: 6| Step: 7
Training loss: 0.43203767147431094
Validation loss: 2.945428132638232

Epoch: 6| Step: 8
Training loss: 0.37129611470660295
Validation loss: 2.8447223440240066

Epoch: 6| Step: 9
Training loss: 0.44959909674249987
Validation loss: 2.8750294946456814

Epoch: 6| Step: 10
Training loss: 0.4022684489773568
Validation loss: 2.894078269448427

Epoch: 6| Step: 11
Training loss: 0.35171795692845886
Validation loss: 2.8855733082987025

Epoch: 6| Step: 12
Training loss: 0.2952585130622201
Validation loss: 2.9001152481549366

Epoch: 6| Step: 13
Training loss: 0.8154993084636214
Validation loss: 2.8241139696310724

Epoch: 333| Step: 0
Training loss: 0.4249805130417904
Validation loss: 2.8835534278202215

Epoch: 6| Step: 1
Training loss: 0.35720668631059405
Validation loss: 2.942620690765127

Epoch: 6| Step: 2
Training loss: 0.24969754698953572
Validation loss: 2.959448152126081

Epoch: 6| Step: 3
Training loss: 0.3952906824959304
Validation loss: 2.9461467988005974

Epoch: 6| Step: 4
Training loss: 0.32512379911025685
Validation loss: 2.9646045854726673

Epoch: 6| Step: 5
Training loss: 0.4364469320345208
Validation loss: 2.912858797929172

Epoch: 6| Step: 6
Training loss: 0.293406934476723
Validation loss: 2.8853032931055567

Epoch: 6| Step: 7
Training loss: 0.46848006423459565
Validation loss: 2.9164830059173545

Epoch: 6| Step: 8
Training loss: 0.23729547239393814
Validation loss: 2.870330681463784

Epoch: 6| Step: 9
Training loss: 0.47480446530285514
Validation loss: 2.81927662826573

Epoch: 6| Step: 10
Training loss: 0.2885290326727687
Validation loss: 2.9206307629817454

Epoch: 6| Step: 11
Training loss: 0.3745720527521775
Validation loss: 2.9121064549172844

Epoch: 6| Step: 12
Training loss: 0.8830395971904651
Validation loss: 2.8671846173208713

Epoch: 6| Step: 13
Training loss: 0.5056976590096147
Validation loss: 2.8506396746952953

Epoch: 334| Step: 0
Training loss: 0.18630380331803728
Validation loss: 2.8237246709495065

Epoch: 6| Step: 1
Training loss: 0.4923826769201023
Validation loss: 2.852972662634186

Epoch: 6| Step: 2
Training loss: 0.4266169684431171
Validation loss: 2.85644143824301

Epoch: 6| Step: 3
Training loss: 0.3024842490280648
Validation loss: 2.922155478984019

Epoch: 6| Step: 4
Training loss: 0.4519269660362498
Validation loss: 2.9536067428428208

Epoch: 6| Step: 5
Training loss: 0.5130240703293457
Validation loss: 2.9243409737568657

Epoch: 6| Step: 6
Training loss: 0.4742104694579896
Validation loss: 2.927476216259517

Epoch: 6| Step: 7
Training loss: 0.3875460397380436
Validation loss: 2.913020638904034

Epoch: 6| Step: 8
Training loss: 0.3909538982498513
Validation loss: 2.869304156333506

Epoch: 6| Step: 9
Training loss: 0.824115258539857
Validation loss: 2.9254870875900596

Epoch: 6| Step: 10
Training loss: 0.539740260758552
Validation loss: 2.864587906342526

Epoch: 6| Step: 11
Training loss: 0.3304242683576871
Validation loss: 2.970062487744419

Epoch: 6| Step: 12
Training loss: 0.377277333671739
Validation loss: 2.915885770801739

Epoch: 6| Step: 13
Training loss: 0.3301192489377298
Validation loss: 3.000002053048173

Epoch: 335| Step: 0
Training loss: 0.3598373383030737
Validation loss: 2.914864914557483

Epoch: 6| Step: 1
Training loss: 0.4164778062842328
Validation loss: 2.8974201648236124

Epoch: 6| Step: 2
Training loss: 0.4152065702012687
Validation loss: 2.9160337488011936

Epoch: 6| Step: 3
Training loss: 0.24912505974747343
Validation loss: 2.8548095471023713

Epoch: 6| Step: 4
Training loss: 0.42778157709685904
Validation loss: 2.916725952817458

Epoch: 6| Step: 5
Training loss: 0.2927319396105764
Validation loss: 3.0189490305997433

Epoch: 6| Step: 6
Training loss: 0.4976490151973851
Validation loss: 2.9511740831980764

Epoch: 6| Step: 7
Training loss: 0.8585865218298238
Validation loss: 2.9901337643006625

Epoch: 6| Step: 8
Training loss: 0.4047600493335138
Validation loss: 2.926316229782182

Epoch: 6| Step: 9
Training loss: 0.4979818862700124
Validation loss: 2.9358022937835604

Epoch: 6| Step: 10
Training loss: 0.2987676322394368
Validation loss: 2.9568619001398453

Epoch: 6| Step: 11
Training loss: 0.3502481581328414
Validation loss: 2.90166419225416

Epoch: 6| Step: 12
Training loss: 0.46490747351593437
Validation loss: 2.9610032583431556

Epoch: 6| Step: 13
Training loss: 0.3266839444974295
Validation loss: 2.88422977168689

Epoch: 336| Step: 0
Training loss: 0.4898763618382172
Validation loss: 2.8997385373033002

Epoch: 6| Step: 1
Training loss: 0.3266570771076501
Validation loss: 2.98700620754854

Epoch: 6| Step: 2
Training loss: 0.5133055914879928
Validation loss: 2.9643096643816476

Epoch: 6| Step: 3
Training loss: 0.37580487182985706
Validation loss: 2.9997242959809145

Epoch: 6| Step: 4
Training loss: 0.4237718676660773
Validation loss: 2.938460375664228

Epoch: 6| Step: 5
Training loss: 0.35303507858392513
Validation loss: 3.0156013342895607

Epoch: 6| Step: 6
Training loss: 0.40432156842143036
Validation loss: 2.9064762205180013

Epoch: 6| Step: 7
Training loss: 0.8236759079533488
Validation loss: 2.897264405997297

Epoch: 6| Step: 8
Training loss: 0.46667400642424534
Validation loss: 2.9491127921432367

Epoch: 6| Step: 9
Training loss: 0.5084366117632609
Validation loss: 2.9877889788694962

Epoch: 6| Step: 10
Training loss: 0.3948887630961078
Validation loss: 2.9909502597279323

Epoch: 6| Step: 11
Training loss: 0.45317108643406007
Validation loss: 2.998732524257472

Epoch: 6| Step: 12
Training loss: 0.648110548573781
Validation loss: 3.102542546195977

Epoch: 6| Step: 13
Training loss: 0.474333019409402
Validation loss: 2.9539656880554834

Epoch: 337| Step: 0
Training loss: 0.42825980117792345
Validation loss: 2.969954102586458

Epoch: 6| Step: 1
Training loss: 0.5272370407081871
Validation loss: 2.9242063391114077

Epoch: 6| Step: 2
Training loss: 0.5795610737268313
Validation loss: 2.9338036405787253

Epoch: 6| Step: 3
Training loss: 0.49271473574628677
Validation loss: 3.0057669681773542

Epoch: 6| Step: 4
Training loss: 0.3525379846614518
Validation loss: 2.9693629384985196

Epoch: 6| Step: 5
Training loss: 0.4489976255772515
Validation loss: 2.9354537167364447

Epoch: 6| Step: 6
Training loss: 0.2791727230259623
Validation loss: 2.980450218079741

Epoch: 6| Step: 7
Training loss: 0.40063651373352244
Validation loss: 2.9033060510830215

Epoch: 6| Step: 8
Training loss: 0.26448594626388544
Validation loss: 2.9435247363422756

Epoch: 6| Step: 9
Training loss: 0.47581409096711785
Validation loss: 2.8667420501186247

Epoch: 6| Step: 10
Training loss: 0.7555100375454784
Validation loss: 2.8793027717744897

Epoch: 6| Step: 11
Training loss: 0.3873960363222216
Validation loss: 2.8702410272855015

Epoch: 6| Step: 12
Training loss: 0.42258307410522905
Validation loss: 2.855898482536222

Epoch: 6| Step: 13
Training loss: 0.49721258259627826
Validation loss: 2.98672101546832

Epoch: 338| Step: 0
Training loss: 0.49543523260651384
Validation loss: 2.9278275345835563

Epoch: 6| Step: 1
Training loss: 0.4170267238206958
Validation loss: 2.820851536010733

Epoch: 6| Step: 2
Training loss: 0.7827834529398742
Validation loss: 2.927762388333292

Epoch: 6| Step: 3
Training loss: 0.2623315866955272
Validation loss: 2.9065032629868304

Epoch: 6| Step: 4
Training loss: 0.33787673304230126
Validation loss: 2.8830901083773774

Epoch: 6| Step: 5
Training loss: 0.5004713399857583
Validation loss: 2.9929340384101906

Epoch: 6| Step: 6
Training loss: 0.42857193485582057
Validation loss: 3.0280183692636986

Epoch: 6| Step: 7
Training loss: 0.5297642294974062
Validation loss: 2.94573411698009

Epoch: 6| Step: 8
Training loss: 0.346338625489911
Validation loss: 2.967680688320666

Epoch: 6| Step: 9
Training loss: 0.4870340822912794
Validation loss: 2.862418467597388

Epoch: 6| Step: 10
Training loss: 0.5276869045906182
Validation loss: 2.8521024009971883

Epoch: 6| Step: 11
Training loss: 0.3766818083122195
Validation loss: 2.9048358662515246

Epoch: 6| Step: 12
Training loss: 0.4162193838092198
Validation loss: 2.907441882675781

Epoch: 6| Step: 13
Training loss: 0.33016227462117304
Validation loss: 2.9692859901978603

Epoch: 339| Step: 0
Training loss: 0.38127956197599633
Validation loss: 2.9261782775328142

Epoch: 6| Step: 1
Training loss: 0.36750136819571816
Validation loss: 2.905239886776688

Epoch: 6| Step: 2
Training loss: 0.3636083463420106
Validation loss: 2.9769692264060215

Epoch: 6| Step: 3
Training loss: 0.38336328859354774
Validation loss: 3.030160268903091

Epoch: 6| Step: 4
Training loss: 0.42321469262088024
Validation loss: 2.9734709964481825

Epoch: 6| Step: 5
Training loss: 0.2630482114888776
Validation loss: 2.91999840949725

Epoch: 6| Step: 6
Training loss: 0.4218180582683855
Validation loss: 3.0464305455705016

Epoch: 6| Step: 7
Training loss: 0.5127450101471058
Validation loss: 2.9294398495589284

Epoch: 6| Step: 8
Training loss: 0.38038511825778104
Validation loss: 2.96319437701699

Epoch: 6| Step: 9
Training loss: 0.33105055769873515
Validation loss: 2.851610080548478

Epoch: 6| Step: 10
Training loss: 0.8125382927894201
Validation loss: 2.85656543272629

Epoch: 6| Step: 11
Training loss: 0.5067364074942924
Validation loss: 2.8995893302716964

Epoch: 6| Step: 12
Training loss: 0.4797369338170079
Validation loss: 2.864180482223024

Epoch: 6| Step: 13
Training loss: 0.31575553998896955
Validation loss: 2.9262706854826623

Epoch: 340| Step: 0
Training loss: 0.3883891587010826
Validation loss: 3.016223327628397

Epoch: 6| Step: 1
Training loss: 0.46863452760662855
Validation loss: 3.0283016010302153

Epoch: 6| Step: 2
Training loss: 0.6143817139857285
Validation loss: 3.0354373364780063

Epoch: 6| Step: 3
Training loss: 0.6884786402894179
Validation loss: 2.9745899115476924

Epoch: 6| Step: 4
Training loss: 0.4007987942489982
Validation loss: 2.904584058506956

Epoch: 6| Step: 5
Training loss: 0.34582821150897436
Validation loss: 2.906579822706993

Epoch: 6| Step: 6
Training loss: 0.5201799745153987
Validation loss: 2.8722565179946162

Epoch: 6| Step: 7
Training loss: 0.5502668643639255
Validation loss: 2.8848135601340683

Epoch: 6| Step: 8
Training loss: 0.43717777784006767
Validation loss: 2.9044037016612045

Epoch: 6| Step: 9
Training loss: 0.47528615037061156
Validation loss: 2.9891782656776824

Epoch: 6| Step: 10
Training loss: 0.3388363167280686
Validation loss: 2.933306927634366

Epoch: 6| Step: 11
Training loss: 0.30792460747951084
Validation loss: 2.9623467036850117

Epoch: 6| Step: 12
Training loss: 0.8377390904548668
Validation loss: 3.130013576717811

Epoch: 6| Step: 13
Training loss: 0.40655000319982304
Validation loss: 2.9670890043147597

Epoch: 341| Step: 0
Training loss: 0.4231133828758868
Validation loss: 3.012464722021851

Epoch: 6| Step: 1
Training loss: 0.7301684491579052
Validation loss: 2.9581909324508575

Epoch: 6| Step: 2
Training loss: 0.35636407631918143
Validation loss: 2.881561462713257

Epoch: 6| Step: 3
Training loss: 0.30947720544468194
Validation loss: 2.845783526616338

Epoch: 6| Step: 4
Training loss: 0.3184413687309076
Validation loss: 2.867487726249025

Epoch: 6| Step: 5
Training loss: 0.3896236937656725
Validation loss: 2.8785794683851464

Epoch: 6| Step: 6
Training loss: 0.3187228742912943
Validation loss: 2.8902613505598764

Epoch: 6| Step: 7
Training loss: 0.37752102780670843
Validation loss: 2.8553943128576873

Epoch: 6| Step: 8
Training loss: 0.48832218761494506
Validation loss: 2.8651101939883366

Epoch: 6| Step: 9
Training loss: 0.5355952334951846
Validation loss: 3.026939342108198

Epoch: 6| Step: 10
Training loss: 0.3931855015374196
Validation loss: 3.0334460637520673

Epoch: 6| Step: 11
Training loss: 0.6784994550588918
Validation loss: 2.973113310168572

Epoch: 6| Step: 12
Training loss: 0.3867706687831691
Validation loss: 2.8509510935086784

Epoch: 6| Step: 13
Training loss: 0.31841194561293173
Validation loss: 2.8525692072860864

Epoch: 342| Step: 0
Training loss: 0.5366802929200744
Validation loss: 2.810004617861464

Epoch: 6| Step: 1
Training loss: 0.501763363603687
Validation loss: 2.822343808051485

Epoch: 6| Step: 2
Training loss: 0.44722314491268933
Validation loss: 2.81468162694407

Epoch: 6| Step: 3
Training loss: 0.30729974989308295
Validation loss: 2.889174143654349

Epoch: 6| Step: 4
Training loss: 0.3314273053809235
Validation loss: 2.8442480328874318

Epoch: 6| Step: 5
Training loss: 0.40970786881314625
Validation loss: 2.940027596912916

Epoch: 6| Step: 6
Training loss: 0.4313906813329983
Validation loss: 2.9930392680618674

Epoch: 6| Step: 7
Training loss: 0.5984910109377917
Validation loss: 2.923912412370945

Epoch: 6| Step: 8
Training loss: 0.3794437607255128
Validation loss: 2.9276561018286875

Epoch: 6| Step: 9
Training loss: 0.4232166995553959
Validation loss: 2.9045116872729095

Epoch: 6| Step: 10
Training loss: 0.8234655907488417
Validation loss: 2.8200650656974298

Epoch: 6| Step: 11
Training loss: 0.4345196983779946
Validation loss: 2.869572658224473

Epoch: 6| Step: 12
Training loss: 0.3887571691729019
Validation loss: 2.8364139013117686

Epoch: 6| Step: 13
Training loss: 0.6087405986177421
Validation loss: 2.8212109628978634

Epoch: 343| Step: 0
Training loss: 0.4768300634237815
Validation loss: 2.836021751364335

Epoch: 6| Step: 1
Training loss: 0.3667899881677177
Validation loss: 2.8870988388258088

Epoch: 6| Step: 2
Training loss: 0.7682428951437646
Validation loss: 2.9569689510204515

Epoch: 6| Step: 3
Training loss: 0.3340303712815982
Validation loss: 2.9299979354842445

Epoch: 6| Step: 4
Training loss: 0.3004383634575089
Validation loss: 2.886160377112143

Epoch: 6| Step: 5
Training loss: 0.40160425985777537
Validation loss: 2.9445565465264085

Epoch: 6| Step: 6
Training loss: 0.40805793991146766
Validation loss: 2.957999282208352

Epoch: 6| Step: 7
Training loss: 0.31730533534510647
Validation loss: 2.877249003913396

Epoch: 6| Step: 8
Training loss: 0.3299282907652095
Validation loss: 2.8822975215615734

Epoch: 6| Step: 9
Training loss: 0.5804368011595272
Validation loss: 2.8508811241127945

Epoch: 6| Step: 10
Training loss: 0.4228607247221149
Validation loss: 2.912596401098151

Epoch: 6| Step: 11
Training loss: 0.26625256174493833
Validation loss: 2.908523190120909

Epoch: 6| Step: 12
Training loss: 0.4607837226519337
Validation loss: 2.952056112727027

Epoch: 6| Step: 13
Training loss: 0.40235967512002146
Validation loss: 3.05177308589928

Epoch: 344| Step: 0
Training loss: 0.34872319949138764
Validation loss: 2.927056802287747

Epoch: 6| Step: 1
Training loss: 0.5690110917309235
Validation loss: 2.977308471865734

Epoch: 6| Step: 2
Training loss: 0.4335172259187244
Validation loss: 2.9395214322117695

Epoch: 6| Step: 3
Training loss: 0.2653175847090863
Validation loss: 3.0113315358094983

Epoch: 6| Step: 4
Training loss: 0.324221863789141
Validation loss: 2.882133465942544

Epoch: 6| Step: 5
Training loss: 0.36637461755525014
Validation loss: 2.8928718151637676

Epoch: 6| Step: 6
Training loss: 0.5246777715002598
Validation loss: 2.7964295044899576

Epoch: 6| Step: 7
Training loss: 0.4601697508510445
Validation loss: 2.879629264321349

Epoch: 6| Step: 8
Training loss: 0.33563148621910466
Validation loss: 2.9075120489516446

Epoch: 6| Step: 9
Training loss: 0.5127840964327648
Validation loss: 2.9592228255175113

Epoch: 6| Step: 10
Training loss: 0.49048913362212
Validation loss: 2.916793498051808

Epoch: 6| Step: 11
Training loss: 0.880621021443159
Validation loss: 2.9535405911067873

Epoch: 6| Step: 12
Training loss: 0.4564251752858594
Validation loss: 2.995396247320496

Epoch: 6| Step: 13
Training loss: 0.35827370533774805
Validation loss: 2.9107315348259797

Epoch: 345| Step: 0
Training loss: 0.3614554309820059
Validation loss: 2.8950503317586964

Epoch: 6| Step: 1
Training loss: 0.39717076462154827
Validation loss: 2.9291996257188417

Epoch: 6| Step: 2
Training loss: 0.45944325660105867
Validation loss: 2.885306226542494

Epoch: 6| Step: 3
Training loss: 0.9344016055398695
Validation loss: 2.863781713973092

Epoch: 6| Step: 4
Training loss: 0.2915234583139444
Validation loss: 2.8684200786955474

Epoch: 6| Step: 5
Training loss: 0.3869829527651311
Validation loss: 2.891567592041255

Epoch: 6| Step: 6
Training loss: 0.4410526581074683
Validation loss: 2.9398853546072248

Epoch: 6| Step: 7
Training loss: 0.43478746453584943
Validation loss: 2.956640448670834

Epoch: 6| Step: 8
Training loss: 0.3440169576600113
Validation loss: 2.929488532197609

Epoch: 6| Step: 9
Training loss: 0.2792666092059543
Validation loss: 2.8964062313857646

Epoch: 6| Step: 10
Training loss: 0.5051842975470117
Validation loss: 2.8862830191521973

Epoch: 6| Step: 11
Training loss: 0.33680112853314215
Validation loss: 2.9162527381000074

Epoch: 6| Step: 12
Training loss: 0.41913047557818484
Validation loss: 2.8738149743839827

Epoch: 6| Step: 13
Training loss: 0.3648848671789445
Validation loss: 2.877652437429496

Epoch: 346| Step: 0
Training loss: 0.41624694983478877
Validation loss: 2.9972646746979246

Epoch: 6| Step: 1
Training loss: 0.4520628582438639
Validation loss: 3.0130800567231293

Epoch: 6| Step: 2
Training loss: 0.3998552790742764
Validation loss: 3.030671225019765

Epoch: 6| Step: 3
Training loss: 0.5120843935066508
Validation loss: 2.969537958346481

Epoch: 6| Step: 4
Training loss: 0.3558622843752202
Validation loss: 2.9136658672163938

Epoch: 6| Step: 5
Training loss: 0.7927727668498102
Validation loss: 2.968080117121987

Epoch: 6| Step: 6
Training loss: 0.3047000931313688
Validation loss: 2.9449133024855403

Epoch: 6| Step: 7
Training loss: 0.31948959666688426
Validation loss: 2.9551682711657805

Epoch: 6| Step: 8
Training loss: 0.43275773152894026
Validation loss: 2.9842634995753756

Epoch: 6| Step: 9
Training loss: 0.28251063428122375
Validation loss: 2.9823278359420433

Epoch: 6| Step: 10
Training loss: 0.4053469671625061
Validation loss: 2.9831572439839613

Epoch: 6| Step: 11
Training loss: 0.4865479642672764
Validation loss: 2.9922889048206764

Epoch: 6| Step: 12
Training loss: 0.3730735170127977
Validation loss: 2.9561779650567446

Epoch: 6| Step: 13
Training loss: 0.38023152563698126
Validation loss: 2.979851901782145

Epoch: 347| Step: 0
Training loss: 0.28507211828868656
Validation loss: 2.99530811445472

Epoch: 6| Step: 1
Training loss: 0.44159284378076474
Validation loss: 2.9851463080098117

Epoch: 6| Step: 2
Training loss: 0.30828002482817046
Validation loss: 2.9043179451187338

Epoch: 6| Step: 3
Training loss: 0.45644249447959395
Validation loss: 3.023570857035375

Epoch: 6| Step: 4
Training loss: 0.44430352396691186
Validation loss: 2.9807483946874216

Epoch: 6| Step: 5
Training loss: 0.42268389401666717
Validation loss: 2.874585011150864

Epoch: 6| Step: 6
Training loss: 0.32352974078536517
Validation loss: 2.964085055895352

Epoch: 6| Step: 7
Training loss: 0.7504746206873197
Validation loss: 2.945637395800172

Epoch: 6| Step: 8
Training loss: 0.32340340181188154
Validation loss: 2.957723169578198

Epoch: 6| Step: 9
Training loss: 0.32587826242631934
Validation loss: 3.045126297413742

Epoch: 6| Step: 10
Training loss: 0.5035108153214846
Validation loss: 2.979044375988564

Epoch: 6| Step: 11
Training loss: 0.4147687323319668
Validation loss: 2.976542889120758

Epoch: 6| Step: 12
Training loss: 0.211339109068334
Validation loss: 2.9399766018643563

Epoch: 6| Step: 13
Training loss: 0.35413590699677405
Validation loss: 2.9244172431366136

Epoch: 348| Step: 0
Training loss: 0.4070747879378243
Validation loss: 2.897319787263108

Epoch: 6| Step: 1
Training loss: 0.4363835428505901
Validation loss: 2.873356376970059

Epoch: 6| Step: 2
Training loss: 0.43686539741735636
Validation loss: 2.8875578132775708

Epoch: 6| Step: 3
Training loss: 0.39682071494754106
Validation loss: 2.9685439858146534

Epoch: 6| Step: 4
Training loss: 0.4519352420575862
Validation loss: 2.876703959835132

Epoch: 6| Step: 5
Training loss: 0.39292491949009845
Validation loss: 2.9705853995881926

Epoch: 6| Step: 6
Training loss: 0.43244927378953074
Validation loss: 2.872767839641009

Epoch: 6| Step: 7
Training loss: 0.3404427106229882
Validation loss: 2.8948542680225158

Epoch: 6| Step: 8
Training loss: 0.7192841493854988
Validation loss: 2.9801806522716294

Epoch: 6| Step: 9
Training loss: 0.3911857204527816
Validation loss: 3.0382537288633995

Epoch: 6| Step: 10
Training loss: 0.5097749497302533
Validation loss: 2.9725128553629596

Epoch: 6| Step: 11
Training loss: 0.22337989164513475
Validation loss: 2.961890638430497

Epoch: 6| Step: 12
Training loss: 0.22908661900116395
Validation loss: 2.988101569863596

Epoch: 6| Step: 13
Training loss: 0.32986576539933254
Validation loss: 2.9931166677783163

Epoch: 349| Step: 0
Training loss: 0.30569466385902583
Validation loss: 2.9615133726998932

Epoch: 6| Step: 1
Training loss: 0.35929666577636044
Validation loss: 2.9098354768726766

Epoch: 6| Step: 2
Training loss: 0.8062897812839334
Validation loss: 2.912946976729663

Epoch: 6| Step: 3
Training loss: 0.37290700317449965
Validation loss: 2.9766968757688437

Epoch: 6| Step: 4
Training loss: 0.36601256020157463
Validation loss: 2.910308001015833

Epoch: 6| Step: 5
Training loss: 0.4898527111103821
Validation loss: 2.9843587958143947

Epoch: 6| Step: 6
Training loss: 0.3608673456884602
Validation loss: 2.9478690791698017

Epoch: 6| Step: 7
Training loss: 0.3563257304225922
Validation loss: 2.9505373670087263

Epoch: 6| Step: 8
Training loss: 0.355180770423634
Validation loss: 2.9239592164983574

Epoch: 6| Step: 9
Training loss: 0.3412978862343524
Validation loss: 2.925607266110542

Epoch: 6| Step: 10
Training loss: 0.44026346728269344
Validation loss: 2.898614183988975

Epoch: 6| Step: 11
Training loss: 0.3735599484662078
Validation loss: 2.8886425746749724

Epoch: 6| Step: 12
Training loss: 0.3153957195120931
Validation loss: 2.8981001966998825

Epoch: 6| Step: 13
Training loss: 0.5011723305037845
Validation loss: 2.9602913264658306

Epoch: 350| Step: 0
Training loss: 0.5774537906902489
Validation loss: 2.9245561887948144

Epoch: 6| Step: 1
Training loss: 0.3396509983170213
Validation loss: 2.8822722579216187

Epoch: 6| Step: 2
Training loss: 0.32184413743433316
Validation loss: 2.9074963594054686

Epoch: 6| Step: 3
Training loss: 0.28995484436285157
Validation loss: 2.904613444270231

Epoch: 6| Step: 4
Training loss: 0.38970061600552985
Validation loss: 2.9215716036186414

Epoch: 6| Step: 5
Training loss: 0.26303484221565354
Validation loss: 2.936039527743052

Epoch: 6| Step: 6
Training loss: 0.3794623747545097
Validation loss: 2.87490837669882

Epoch: 6| Step: 7
Training loss: 0.4000261089625465
Validation loss: 2.896585090174054

Epoch: 6| Step: 8
Training loss: 0.46147233031883367
Validation loss: 2.9118090823768514

Epoch: 6| Step: 9
Training loss: 0.8634377937440653
Validation loss: 2.889755654416698

Epoch: 6| Step: 10
Training loss: 0.4323092499186564
Validation loss: 2.860495620456582

Epoch: 6| Step: 11
Training loss: 0.2950650682254749
Validation loss: 2.9472160090809334

Epoch: 6| Step: 12
Training loss: 0.32988846425646245
Validation loss: 2.8884484421967374

Epoch: 6| Step: 13
Training loss: 0.469373256868054
Validation loss: 2.875015631923472

Epoch: 351| Step: 0
Training loss: 0.5261834837858451
Validation loss: 2.8094570935750993

Epoch: 6| Step: 1
Training loss: 0.2754975104721422
Validation loss: 2.942453860642558

Epoch: 6| Step: 2
Training loss: 0.4768545787833442
Validation loss: 2.908549243560191

Epoch: 6| Step: 3
Training loss: 0.3339706998111194
Validation loss: 2.908940618192836

Epoch: 6| Step: 4
Training loss: 0.5644826386335501
Validation loss: 2.916182550488819

Epoch: 6| Step: 5
Training loss: 0.3143202933534106
Validation loss: 2.948457585144904

Epoch: 6| Step: 6
Training loss: 0.5077840063464106
Validation loss: 3.0170561140399275

Epoch: 6| Step: 7
Training loss: 0.6235310697010884
Validation loss: 3.022266617928836

Epoch: 6| Step: 8
Training loss: 0.3934626128443934
Validation loss: 2.95211380427071

Epoch: 6| Step: 9
Training loss: 0.3561370352615731
Validation loss: 2.945631541166564

Epoch: 6| Step: 10
Training loss: 0.8797744870584271
Validation loss: 2.9929861890204634

Epoch: 6| Step: 11
Training loss: 0.42683402980497875
Validation loss: 2.9099444489349358

Epoch: 6| Step: 12
Training loss: 0.4470569840257182
Validation loss: 2.95723981302362

Epoch: 6| Step: 13
Training loss: 0.3270681937575182
Validation loss: 2.8420044708458394

Epoch: 352| Step: 0
Training loss: 0.29123832834784896
Validation loss: 2.961231388212291

Epoch: 6| Step: 1
Training loss: 0.29496034788088693
Validation loss: 2.938551531944947

Epoch: 6| Step: 2
Training loss: 0.41932122498329244
Validation loss: 2.959321680766888

Epoch: 6| Step: 3
Training loss: 0.3354608125640438
Validation loss: 3.029264265024686

Epoch: 6| Step: 4
Training loss: 0.4331982845383384
Validation loss: 3.0557270021215825

Epoch: 6| Step: 5
Training loss: 0.4120907349913363
Validation loss: 2.9747632079360873

Epoch: 6| Step: 6
Training loss: 0.3260395786819794
Validation loss: 2.9024932535308317

Epoch: 6| Step: 7
Training loss: 0.3799807267885452
Validation loss: 2.925260123073405

Epoch: 6| Step: 8
Training loss: 0.7295463164034636
Validation loss: 2.974577995630717

Epoch: 6| Step: 9
Training loss: 0.37557043955106856
Validation loss: 2.935828362304683

Epoch: 6| Step: 10
Training loss: 0.35313052071838535
Validation loss: 2.9390493459912492

Epoch: 6| Step: 11
Training loss: 0.4466225944964598
Validation loss: 2.955380690053736

Epoch: 6| Step: 12
Training loss: 0.5241227290847822
Validation loss: 2.912266850451156

Epoch: 6| Step: 13
Training loss: 0.44946292377826125
Validation loss: 2.9571109628284677

Epoch: 353| Step: 0
Training loss: 0.3700298518304317
Validation loss: 2.9103008328221724

Epoch: 6| Step: 1
Training loss: 0.38323212026854386
Validation loss: 2.921038475578112

Epoch: 6| Step: 2
Training loss: 0.5021118328769724
Validation loss: 2.9982681971400433

Epoch: 6| Step: 3
Training loss: 0.45536660804314405
Validation loss: 2.949078810447546

Epoch: 6| Step: 4
Training loss: 0.2764253588810485
Validation loss: 2.88691689409601

Epoch: 6| Step: 5
Training loss: 0.382361087507315
Validation loss: 2.938324913911519

Epoch: 6| Step: 6
Training loss: 0.30677755906526205
Validation loss: 2.9659439612136596

Epoch: 6| Step: 7
Training loss: 0.7522669942171673
Validation loss: 2.9172079719325037

Epoch: 6| Step: 8
Training loss: 0.34140421519775177
Validation loss: 2.880120375510585

Epoch: 6| Step: 9
Training loss: 0.46598931211895217
Validation loss: 2.886395578701442

Epoch: 6| Step: 10
Training loss: 0.3984477097942236
Validation loss: 2.927400013003139

Epoch: 6| Step: 11
Training loss: 0.4691749553840369
Validation loss: 2.886143470054875

Epoch: 6| Step: 12
Training loss: 0.43027847571070454
Validation loss: 3.0001835237105094

Epoch: 6| Step: 13
Training loss: 0.4446521681731542
Validation loss: 2.881511363589405

Epoch: 354| Step: 0
Training loss: 0.3830259078603223
Validation loss: 2.983254240539737

Epoch: 6| Step: 1
Training loss: 0.4808484569707664
Validation loss: 2.971935878361436

Epoch: 6| Step: 2
Training loss: 0.2775470633162259
Validation loss: 2.963302405989449

Epoch: 6| Step: 3
Training loss: 0.4481815637885066
Validation loss: 2.94931567708583

Epoch: 6| Step: 4
Training loss: 0.7453601685960723
Validation loss: 2.9086996713089373

Epoch: 6| Step: 5
Training loss: 0.48174306084941115
Validation loss: 2.97089465123939

Epoch: 6| Step: 6
Training loss: 0.34131361448772757
Validation loss: 2.9350103961255734

Epoch: 6| Step: 7
Training loss: 0.4047894816978542
Validation loss: 2.9679765195611814

Epoch: 6| Step: 8
Training loss: 0.3403807376724001
Validation loss: 2.9096052975303346

Epoch: 6| Step: 9
Training loss: 0.31465568889310647
Validation loss: 2.872093542152707

Epoch: 6| Step: 10
Training loss: 0.32812887144075503
Validation loss: 2.8617743065048042

Epoch: 6| Step: 11
Training loss: 0.5169476105452235
Validation loss: 2.928503137882187

Epoch: 6| Step: 12
Training loss: 0.39731659013732046
Validation loss: 2.890308919585373

Epoch: 6| Step: 13
Training loss: 0.43088525813667844
Validation loss: 2.932138948320127

Epoch: 355| Step: 0
Training loss: 0.32125882177448783
Validation loss: 2.924515494950103

Epoch: 6| Step: 1
Training loss: 0.3414161087114131
Validation loss: 2.9697888882206005

Epoch: 6| Step: 2
Training loss: 0.7407019756249076
Validation loss: 2.90583947403039

Epoch: 6| Step: 3
Training loss: 0.44772713184904583
Validation loss: 3.0378983726956945

Epoch: 6| Step: 4
Training loss: 0.3088288437796116
Validation loss: 2.926628869412931

Epoch: 6| Step: 5
Training loss: 0.38524940014272
Validation loss: 2.912079382609147

Epoch: 6| Step: 6
Training loss: 0.20522786078190713
Validation loss: 2.9996100278220195

Epoch: 6| Step: 7
Training loss: 0.353653728001848
Validation loss: 2.910233573825054

Epoch: 6| Step: 8
Training loss: 0.3685321738316354
Validation loss: 2.9490109132539137

Epoch: 6| Step: 9
Training loss: 0.4385634848029235
Validation loss: 3.063397541999001

Epoch: 6| Step: 10
Training loss: 0.27075963056736374
Validation loss: 2.949861017821844

Epoch: 6| Step: 11
Training loss: 0.370135505645698
Validation loss: 2.9886603087982255

Epoch: 6| Step: 12
Training loss: 0.4154899033422568
Validation loss: 2.891403038547412

Epoch: 6| Step: 13
Training loss: 0.38105033586560105
Validation loss: 3.0278071945017433

Epoch: 356| Step: 0
Training loss: 0.32814893181130167
Validation loss: 2.9240774058164916

Epoch: 6| Step: 1
Training loss: 0.5007049538133601
Validation loss: 2.962893119514235

Epoch: 6| Step: 2
Training loss: 0.66519777081908
Validation loss: 3.0042455355114335

Epoch: 6| Step: 3
Training loss: 0.4708282494340842
Validation loss: 2.9997237528664114

Epoch: 6| Step: 4
Training loss: 0.44616463761027986
Validation loss: 3.00324180076854

Epoch: 6| Step: 5
Training loss: 0.3233403405474018
Validation loss: 2.9882320757374905

Epoch: 6| Step: 6
Training loss: 0.43008051151788046
Validation loss: 3.0227119698987797

Epoch: 6| Step: 7
Training loss: 0.5586839616396534
Validation loss: 2.9307159517536117

Epoch: 6| Step: 8
Training loss: 0.4113358202555878
Validation loss: 2.9419910040479507

Epoch: 6| Step: 9
Training loss: 0.4878275632762488
Validation loss: 2.919392828500686

Epoch: 6| Step: 10
Training loss: 0.4831062898306947
Validation loss: 2.9028225448620226

Epoch: 6| Step: 11
Training loss: 0.4103249883966544
Validation loss: 2.928149281512711

Epoch: 6| Step: 12
Training loss: 0.34486354019216675
Validation loss: 2.8945588982720665

Epoch: 6| Step: 13
Training loss: 0.474753715010456
Validation loss: 2.9231070574534046

Epoch: 357| Step: 0
Training loss: 0.42760254731454395
Validation loss: 2.948124589540594

Epoch: 6| Step: 1
Training loss: 0.4383920702845349
Validation loss: 2.977296887144655

Epoch: 6| Step: 2
Training loss: 0.40002350142103893
Validation loss: 3.0380520485099938

Epoch: 6| Step: 3
Training loss: 0.5630620426714303
Validation loss: 2.9015267113317176

Epoch: 6| Step: 4
Training loss: 0.41854353625973534
Validation loss: 2.9172730133485314

Epoch: 6| Step: 5
Training loss: 0.3407108819818094
Validation loss: 2.8738001655579453

Epoch: 6| Step: 6
Training loss: 0.580340444932441
Validation loss: 2.937514081880621

Epoch: 6| Step: 7
Training loss: 0.4742708608033979
Validation loss: 2.91625989166383

Epoch: 6| Step: 8
Training loss: 0.4545799278874147
Validation loss: 2.8786991757472395

Epoch: 6| Step: 9
Training loss: 0.3494881147934202
Validation loss: 2.994552315255467

Epoch: 6| Step: 10
Training loss: 0.8978525994464761
Validation loss: 3.0066181800707947

Epoch: 6| Step: 11
Training loss: 0.5390422098515267
Validation loss: 3.0420625812188615

Epoch: 6| Step: 12
Training loss: 0.5813181303969938
Validation loss: 3.0180632858618193

Epoch: 6| Step: 13
Training loss: 0.38186021030087575
Validation loss: 2.92745329033703

Epoch: 358| Step: 0
Training loss: 0.3454978354885848
Validation loss: 2.9106723404585995

Epoch: 6| Step: 1
Training loss: 0.4474449464562258
Validation loss: 2.869110169583404

Epoch: 6| Step: 2
Training loss: 0.4439038533807689
Validation loss: 2.8956036488035193

Epoch: 6| Step: 3
Training loss: 0.6020183074930219
Validation loss: 2.926257921002018

Epoch: 6| Step: 4
Training loss: 0.36024523150949916
Validation loss: 2.858267912009424

Epoch: 6| Step: 5
Training loss: 0.33512687465452157
Validation loss: 2.9996397543884474

Epoch: 6| Step: 6
Training loss: 0.7485904163086515
Validation loss: 2.9753778858770996

Epoch: 6| Step: 7
Training loss: 0.4379537477349698
Validation loss: 3.0809507099547724

Epoch: 6| Step: 8
Training loss: 0.45509394016535626
Validation loss: 2.8992856713461475

Epoch: 6| Step: 9
Training loss: 0.45976113679391867
Validation loss: 3.0160893690493134

Epoch: 6| Step: 10
Training loss: 0.4289711963836415
Validation loss: 2.852430000906207

Epoch: 6| Step: 11
Training loss: 0.3015480670538729
Validation loss: 2.995415151074519

Epoch: 6| Step: 12
Training loss: 0.47644876467436237
Validation loss: 2.9474163551962067

Epoch: 6| Step: 13
Training loss: 0.4905365548321807
Validation loss: 2.9024938285295456

Epoch: 359| Step: 0
Training loss: 0.48789123217481545
Validation loss: 2.858714084641495

Epoch: 6| Step: 1
Training loss: 0.7095939600789609
Validation loss: 2.883159971446139

Epoch: 6| Step: 2
Training loss: 0.5924251230626973
Validation loss: 2.9338941424532514

Epoch: 6| Step: 3
Training loss: 0.34580001981791986
Validation loss: 2.985878956565333

Epoch: 6| Step: 4
Training loss: 0.5135449735007557
Validation loss: 2.9827112616651434

Epoch: 6| Step: 5
Training loss: 0.38103019600453936
Validation loss: 3.0670632211358893

Epoch: 6| Step: 6
Training loss: 0.44268030938105374
Validation loss: 2.9539903452721266

Epoch: 6| Step: 7
Training loss: 0.29693586578834774
Validation loss: 2.879310886582024

Epoch: 6| Step: 8
Training loss: 0.3791280274388211
Validation loss: 2.8730389776235854

Epoch: 6| Step: 9
Training loss: 0.41275119069214766
Validation loss: 2.844997300145053

Epoch: 6| Step: 10
Training loss: 0.4167952954906791
Validation loss: 2.920848536939319

Epoch: 6| Step: 11
Training loss: 0.4407666729366215
Validation loss: 2.9643644767251125

Epoch: 6| Step: 12
Training loss: 0.2729075746380707
Validation loss: 3.0639406565487883

Epoch: 6| Step: 13
Training loss: 0.35588749126490454
Validation loss: 3.019525459682083

Epoch: 360| Step: 0
Training loss: 0.5817654918219394
Validation loss: 3.0486929401450387

Epoch: 6| Step: 1
Training loss: 0.45072401202347095
Validation loss: 3.043679803538824

Epoch: 6| Step: 2
Training loss: 0.5884699707472357
Validation loss: 3.0560850310837147

Epoch: 6| Step: 3
Training loss: 0.5896160368279552
Validation loss: 3.005058566922813

Epoch: 6| Step: 4
Training loss: 0.3805440330829984
Validation loss: 2.8975703200901526

Epoch: 6| Step: 5
Training loss: 0.4372514972650227
Validation loss: 2.9140669589992902

Epoch: 6| Step: 6
Training loss: 0.8788363280563314
Validation loss: 2.885641018147799

Epoch: 6| Step: 7
Training loss: 0.45013978495703677
Validation loss: 2.879939010932431

Epoch: 6| Step: 8
Training loss: 0.29994151320160267
Validation loss: 2.809464992882379

Epoch: 6| Step: 9
Training loss: 0.39195593118375893
Validation loss: 2.898506842346696

Epoch: 6| Step: 10
Training loss: 0.44356268367841467
Validation loss: 2.8673147646233192

Epoch: 6| Step: 11
Training loss: 0.4232173685314529
Validation loss: 2.93252050795326

Epoch: 6| Step: 12
Training loss: 0.5700938707153012
Validation loss: 2.878310108617561

Epoch: 6| Step: 13
Training loss: 0.48019010325794537
Validation loss: 2.9359576863584116

Epoch: 361| Step: 0
Training loss: 0.35113956654985395
Validation loss: 2.965725747029525

Epoch: 6| Step: 1
Training loss: 0.3296230949300512
Validation loss: 2.9697090875140106

Epoch: 6| Step: 2
Training loss: 0.27410556380934076
Validation loss: 2.908993728190323

Epoch: 6| Step: 3
Training loss: 0.2800819194541988
Validation loss: 2.9716219345366013

Epoch: 6| Step: 4
Training loss: 0.3360573310929871
Validation loss: 2.957411398529185

Epoch: 6| Step: 5
Training loss: 0.4248494617938224
Validation loss: 2.9421739526275705

Epoch: 6| Step: 6
Training loss: 0.3292520218753068
Validation loss: 2.9618074720962086

Epoch: 6| Step: 7
Training loss: 0.490983975042128
Validation loss: 2.9332220973973855

Epoch: 6| Step: 8
Training loss: 0.3851262256921011
Validation loss: 3.0197606166170097

Epoch: 6| Step: 9
Training loss: 0.4010832215945761
Validation loss: 2.9860709066912667

Epoch: 6| Step: 10
Training loss: 0.7443135778931992
Validation loss: 2.9682334048889145

Epoch: 6| Step: 11
Training loss: 0.5531764335210678
Validation loss: 3.031321036433904

Epoch: 6| Step: 12
Training loss: 0.3510348917404517
Validation loss: 3.0704695618555764

Epoch: 6| Step: 13
Training loss: 0.5145666068237656
Validation loss: 2.9209964539766364

Epoch: 362| Step: 0
Training loss: 0.34204378201811114
Validation loss: 2.9158881011148323

Epoch: 6| Step: 1
Training loss: 0.44018050289808053
Validation loss: 2.921097609517494

Epoch: 6| Step: 2
Training loss: 0.4665659888124939
Validation loss: 2.938818196173787

Epoch: 6| Step: 3
Training loss: 0.34224770377791125
Validation loss: 2.8818683542729113

Epoch: 6| Step: 4
Training loss: 0.3249202630456378
Validation loss: 2.948758915974892

Epoch: 6| Step: 5
Training loss: 0.5551756738882372
Validation loss: 2.9203544372845696

Epoch: 6| Step: 6
Training loss: 0.5384126976088099
Validation loss: 2.9802332260512685

Epoch: 6| Step: 7
Training loss: 0.3407053931321939
Validation loss: 2.9646748062000894

Epoch: 6| Step: 8
Training loss: 0.7214779294339986
Validation loss: 2.9817307693033164

Epoch: 6| Step: 9
Training loss: 0.36557062755490677
Validation loss: 2.911804756386629

Epoch: 6| Step: 10
Training loss: 0.4758136995020581
Validation loss: 2.9731039010112466

Epoch: 6| Step: 11
Training loss: 0.28691369479307083
Validation loss: 2.926155477238602

Epoch: 6| Step: 12
Training loss: 0.2693034605455503
Validation loss: 2.9654827543391926

Epoch: 6| Step: 13
Training loss: 0.32225288597128626
Validation loss: 2.9415672497974565

Epoch: 363| Step: 0
Training loss: 0.39305351662677973
Validation loss: 2.9123499442807814

Epoch: 6| Step: 1
Training loss: 0.3745100277460907
Validation loss: 2.9235158654588136

Epoch: 6| Step: 2
Training loss: 0.8548425620950552
Validation loss: 2.810446264866602

Epoch: 6| Step: 3
Training loss: 0.38729734197394433
Validation loss: 2.913339663283355

Epoch: 6| Step: 4
Training loss: 0.5057909120161824
Validation loss: 2.9565358387330587

Epoch: 6| Step: 5
Training loss: 0.38670576439835735
Validation loss: 2.883225904973474

Epoch: 6| Step: 6
Training loss: 0.3916828137816368
Validation loss: 2.9473298008738036

Epoch: 6| Step: 7
Training loss: 0.39940135907628166
Validation loss: 3.081576547090665

Epoch: 6| Step: 8
Training loss: 0.384416954728162
Validation loss: 2.9860731023887968

Epoch: 6| Step: 9
Training loss: 0.348218548839449
Validation loss: 2.9254851452429613

Epoch: 6| Step: 10
Training loss: 0.33881201830915736
Validation loss: 2.8552439436326558

Epoch: 6| Step: 11
Training loss: 0.34517545353944007
Validation loss: 2.888689785193167

Epoch: 6| Step: 12
Training loss: 0.3172436453075368
Validation loss: 2.967564530178496

Epoch: 6| Step: 13
Training loss: 0.36294269167716275
Validation loss: 2.8378750826258408

Epoch: 364| Step: 0
Training loss: 0.5579952421498241
Validation loss: 2.8803470893166145

Epoch: 6| Step: 1
Training loss: 0.4712574176305736
Validation loss: 2.802274921962673

Epoch: 6| Step: 2
Training loss: 0.4847754084777921
Validation loss: 2.912217804876981

Epoch: 6| Step: 3
Training loss: 0.8723924817073074
Validation loss: 2.9733518972016912

Epoch: 6| Step: 4
Training loss: 0.47153999992876705
Validation loss: 2.9770849775590533

Epoch: 6| Step: 5
Training loss: 0.5499597740635195
Validation loss: 2.9623134640154336

Epoch: 6| Step: 6
Training loss: 0.47157515479134177
Validation loss: 2.8817065287565655

Epoch: 6| Step: 7
Training loss: 0.2752587022730991
Validation loss: 2.91845242918674

Epoch: 6| Step: 8
Training loss: 0.5045248566733672
Validation loss: 2.8305508657742493

Epoch: 6| Step: 9
Training loss: 0.5062112946490289
Validation loss: 2.8034784656230767

Epoch: 6| Step: 10
Training loss: 0.4887196670690465
Validation loss: 2.8232126866684792

Epoch: 6| Step: 11
Training loss: 0.2997513515483302
Validation loss: 2.8556455182608604

Epoch: 6| Step: 12
Training loss: 0.425260575437156
Validation loss: 2.8775975476126976

Epoch: 6| Step: 13
Training loss: 0.37870551228879423
Validation loss: 2.896708806663839

Epoch: 365| Step: 0
Training loss: 0.4463903199565721
Validation loss: 2.9431104447188576

Epoch: 6| Step: 1
Training loss: 0.7370529856740973
Validation loss: 2.9348202650241495

Epoch: 6| Step: 2
Training loss: 0.4124089097103959
Validation loss: 2.9314218499210964

Epoch: 6| Step: 3
Training loss: 0.474235968614976
Validation loss: 2.9195782751648665

Epoch: 6| Step: 4
Training loss: 0.3683550918346266
Validation loss: 2.9308832195318195

Epoch: 6| Step: 5
Training loss: 0.4100482616862633
Validation loss: 2.8963978352118946

Epoch: 6| Step: 6
Training loss: 0.2950024905140053
Validation loss: 2.8604587106376944

Epoch: 6| Step: 7
Training loss: 0.35324098657068315
Validation loss: 2.8399158942614267

Epoch: 6| Step: 8
Training loss: 0.35171172895503255
Validation loss: 2.933404353394658

Epoch: 6| Step: 9
Training loss: 0.26236120766858445
Validation loss: 2.8686084535095424

Epoch: 6| Step: 10
Training loss: 0.3577607846263963
Validation loss: 2.908720176750444

Epoch: 6| Step: 11
Training loss: 0.31691604329640616
Validation loss: 2.936667452850698

Epoch: 6| Step: 12
Training loss: 0.36438943157112663
Validation loss: 2.965734402481314

Epoch: 6| Step: 13
Training loss: 0.39596243267244813
Validation loss: 2.9242683441090276

Epoch: 366| Step: 0
Training loss: 0.5941608914562332
Validation loss: 2.9201116970115164

Epoch: 6| Step: 1
Training loss: 0.4485041698381046
Validation loss: 2.936468849736156

Epoch: 6| Step: 2
Training loss: 0.31349075142665556
Validation loss: 2.9038739216034437

Epoch: 6| Step: 3
Training loss: 0.5554107195752096
Validation loss: 2.8435580849078628

Epoch: 6| Step: 4
Training loss: 0.30059846055067463
Validation loss: 2.887768118934612

Epoch: 6| Step: 5
Training loss: 0.7085926665746782
Validation loss: 2.918045989362879

Epoch: 6| Step: 6
Training loss: 0.27412059472680406
Validation loss: 2.922484825536504

Epoch: 6| Step: 7
Training loss: 0.2965303101469943
Validation loss: 2.9635473339560723

Epoch: 6| Step: 8
Training loss: 0.3727840676221581
Validation loss: 2.9909634256825255

Epoch: 6| Step: 9
Training loss: 0.44624602195825924
Validation loss: 3.0153644165878895

Epoch: 6| Step: 10
Training loss: 0.3705291066261772
Validation loss: 3.0266931240743133

Epoch: 6| Step: 11
Training loss: 0.37967274013134844
Validation loss: 2.905573120047889

Epoch: 6| Step: 12
Training loss: 0.407838375542222
Validation loss: 2.944110264097959

Epoch: 6| Step: 13
Training loss: 0.4097516380228441
Validation loss: 2.9434990194768424

Epoch: 367| Step: 0
Training loss: 0.4381274594388925
Validation loss: 2.8818170057153414

Epoch: 6| Step: 1
Training loss: 0.5216684195252403
Validation loss: 2.9035307765910754

Epoch: 6| Step: 2
Training loss: 0.7602771125833598
Validation loss: 3.0289850851325437

Epoch: 6| Step: 3
Training loss: 0.2299885515546102
Validation loss: 2.956985063414723

Epoch: 6| Step: 4
Training loss: 0.39969792806519255
Validation loss: 2.8890330149286028

Epoch: 6| Step: 5
Training loss: 0.3471580858071308
Validation loss: 3.047449354502491

Epoch: 6| Step: 6
Training loss: 0.6851222578988048
Validation loss: 3.0251772636830583

Epoch: 6| Step: 7
Training loss: 0.4597917962545821
Validation loss: 3.0025734195419753

Epoch: 6| Step: 8
Training loss: 0.2603815992904455
Validation loss: 2.8942796303491427

Epoch: 6| Step: 9
Training loss: 0.5305820641821749
Validation loss: 2.956815899054228

Epoch: 6| Step: 10
Training loss: 0.7970420811838334
Validation loss: 2.8765760055023266

Epoch: 6| Step: 11
Training loss: 0.467502380074343
Validation loss: 2.887145386425983

Epoch: 6| Step: 12
Training loss: 0.45598335443407395
Validation loss: 2.9296993136697576

Epoch: 6| Step: 13
Training loss: 0.5191479753443209
Validation loss: 3.1005408128072993

Epoch: 368| Step: 0
Training loss: 0.5888147030242435
Validation loss: 3.152367233699412

Epoch: 6| Step: 1
Training loss: 0.6013893770074467
Validation loss: 2.991908951053974

Epoch: 6| Step: 2
Training loss: 0.3154071291955962
Validation loss: 2.940166872548011

Epoch: 6| Step: 3
Training loss: 0.30512014873778437
Validation loss: 2.91302445837339

Epoch: 6| Step: 4
Training loss: 0.42872840307020565
Validation loss: 2.896728464183654

Epoch: 6| Step: 5
Training loss: 0.5409230728032572
Validation loss: 2.8940461404756324

Epoch: 6| Step: 6
Training loss: 0.8257308035087956
Validation loss: 2.9074184297603334

Epoch: 6| Step: 7
Training loss: 0.4408815016087312
Validation loss: 2.887159218433379

Epoch: 6| Step: 8
Training loss: 0.47207138825287287
Validation loss: 2.9144849564748743

Epoch: 6| Step: 9
Training loss: 0.3082150054498417
Validation loss: 2.909125228633338

Epoch: 6| Step: 10
Training loss: 0.41243503232339973
Validation loss: 3.0257817133187337

Epoch: 6| Step: 11
Training loss: 0.3639616388579508
Validation loss: 3.0185823055679424

Epoch: 6| Step: 12
Training loss: 0.491551533314185
Validation loss: 3.107429995107601

Epoch: 6| Step: 13
Training loss: 0.5441506236322263
Validation loss: 2.9884253905528104

Epoch: 369| Step: 0
Training loss: 0.5662076930900224
Validation loss: 2.972728165280043

Epoch: 6| Step: 1
Training loss: 0.4101353957914532
Validation loss: 2.9707616850000833

Epoch: 6| Step: 2
Training loss: 0.3351141354081372
Validation loss: 2.898531614902293

Epoch: 6| Step: 3
Training loss: 0.4837233251171323
Validation loss: 2.9163828075879357

Epoch: 6| Step: 4
Training loss: 0.5641305126915713
Validation loss: 2.9003390289409716

Epoch: 6| Step: 5
Training loss: 0.32450009972948446
Validation loss: 2.9566224662662277

Epoch: 6| Step: 6
Training loss: 0.3611693987306618
Validation loss: 3.033077593562043

Epoch: 6| Step: 7
Training loss: 0.3959035706528405
Validation loss: 2.9559888862853474

Epoch: 6| Step: 8
Training loss: 0.38461037229059586
Validation loss: 3.0542633204412573

Epoch: 6| Step: 9
Training loss: 0.5597163304454514
Validation loss: 3.05763383517855

Epoch: 6| Step: 10
Training loss: 0.7405685837903271
Validation loss: 3.060965276737829

Epoch: 6| Step: 11
Training loss: 0.40820914816177206
Validation loss: 3.0287935718945085

Epoch: 6| Step: 12
Training loss: 0.4360438193286166
Validation loss: 2.987059180006456

Epoch: 6| Step: 13
Training loss: 0.3830354391713763
Validation loss: 2.936565277508574

Epoch: 370| Step: 0
Training loss: 0.44482954505721345
Validation loss: 2.9160593127082204

Epoch: 6| Step: 1
Training loss: 0.36914948548678045
Validation loss: 2.9391908175849175

Epoch: 6| Step: 2
Training loss: 0.5160623487389384
Validation loss: 2.866733996761271

Epoch: 6| Step: 3
Training loss: 0.5326720446938564
Validation loss: 2.8688051613218724

Epoch: 6| Step: 4
Training loss: 0.35517122581986144
Validation loss: 2.8487874920732295

Epoch: 6| Step: 5
Training loss: 0.4459533430358048
Validation loss: 2.9992520141611756

Epoch: 6| Step: 6
Training loss: 0.2552728117371108
Validation loss: 2.974234524187283

Epoch: 6| Step: 7
Training loss: 0.3717550909839198
Validation loss: 2.9943931955809027

Epoch: 6| Step: 8
Training loss: 0.8070817900173364
Validation loss: 2.9895168301477097

Epoch: 6| Step: 9
Training loss: 0.49210247940341184
Validation loss: 3.0339181306614913

Epoch: 6| Step: 10
Training loss: 0.335280974506852
Validation loss: 2.917141471544617

Epoch: 6| Step: 11
Training loss: 0.45928362566905906
Validation loss: 2.969966946855713

Epoch: 6| Step: 12
Training loss: 0.36266089354652237
Validation loss: 2.9392670125752045

Epoch: 6| Step: 13
Training loss: 0.3287146130071313
Validation loss: 2.872325648502008

Epoch: 371| Step: 0
Training loss: 0.5207250259956164
Validation loss: 2.889869701237693

Epoch: 6| Step: 1
Training loss: 0.46843371847202886
Validation loss: 2.8764532258763924

Epoch: 6| Step: 2
Training loss: 0.3685113700473871
Validation loss: 2.911284307875817

Epoch: 6| Step: 3
Training loss: 0.3448429613575389
Validation loss: 2.9315231472521868

Epoch: 6| Step: 4
Training loss: 0.3029516855266956
Validation loss: 2.8939062517136374

Epoch: 6| Step: 5
Training loss: 0.44590629340130233
Validation loss: 3.00242884648756

Epoch: 6| Step: 6
Training loss: 0.5134932638987555
Validation loss: 3.0167031872542633

Epoch: 6| Step: 7
Training loss: 0.6100958937173666
Validation loss: 2.9737589157417674

Epoch: 6| Step: 8
Training loss: 0.261248122715023
Validation loss: 2.9458106148440417

Epoch: 6| Step: 9
Training loss: 0.35687004807438794
Validation loss: 2.9271730067589115

Epoch: 6| Step: 10
Training loss: 0.7081244010956429
Validation loss: 2.9304901244305133

Epoch: 6| Step: 11
Training loss: 0.5653898393099203
Validation loss: 2.8480388870932978

Epoch: 6| Step: 12
Training loss: 0.5420544287882176
Validation loss: 2.9729018241513594

Epoch: 6| Step: 13
Training loss: 0.4255349207880377
Validation loss: 2.9958674126934044

Epoch: 372| Step: 0
Training loss: 0.5453251266110695
Validation loss: 2.9769844830712677

Epoch: 6| Step: 1
Training loss: 0.5117185752810114
Validation loss: 3.036451366977105

Epoch: 6| Step: 2
Training loss: 0.4442980404297388
Validation loss: 2.9913939178124926

Epoch: 6| Step: 3
Training loss: 0.3657139164653206
Validation loss: 2.947610365160572

Epoch: 6| Step: 4
Training loss: 0.38964040647562465
Validation loss: 2.9719521369109154

Epoch: 6| Step: 5
Training loss: 0.34765783588176297
Validation loss: 2.9454922945846387

Epoch: 6| Step: 6
Training loss: 0.40943616599394217
Validation loss: 2.943935716714158

Epoch: 6| Step: 7
Training loss: 0.3079058549158908
Validation loss: 2.932111925451281

Epoch: 6| Step: 8
Training loss: 0.36453743600317956
Validation loss: 2.9225418907319862

Epoch: 6| Step: 9
Training loss: 0.7580991772989253
Validation loss: 2.927836112065181

Epoch: 6| Step: 10
Training loss: 0.33926893269833486
Validation loss: 2.9336613403065064

Epoch: 6| Step: 11
Training loss: 0.4906756174497334
Validation loss: 2.9234780930447024

Epoch: 6| Step: 12
Training loss: 0.35064620241191785
Validation loss: 2.9549622514038103

Epoch: 6| Step: 13
Training loss: 0.3467632998794753
Validation loss: 2.999664619030808

Epoch: 373| Step: 0
Training loss: 0.3686580430152377
Validation loss: 2.998660874838499

Epoch: 6| Step: 1
Training loss: 0.3876645630910343
Validation loss: 2.919091733304156

Epoch: 6| Step: 2
Training loss: 0.3790429645356902
Validation loss: 2.9196200177549403

Epoch: 6| Step: 3
Training loss: 0.27676422391692007
Validation loss: 2.9512752680630547

Epoch: 6| Step: 4
Training loss: 0.37725568892965444
Validation loss: 2.9462103111928952

Epoch: 6| Step: 5
Training loss: 0.36759337860791735
Validation loss: 2.9114237301612103

Epoch: 6| Step: 6
Training loss: 0.3937430297900683
Validation loss: 2.9546331090306808

Epoch: 6| Step: 7
Training loss: 0.39484000635580113
Validation loss: 2.8986667566381312

Epoch: 6| Step: 8
Training loss: 0.36926624643178846
Validation loss: 2.8684450556756023

Epoch: 6| Step: 9
Training loss: 0.4357102092121171
Validation loss: 2.943542096786869

Epoch: 6| Step: 10
Training loss: 0.3789099466989049
Validation loss: 2.8999145528109507

Epoch: 6| Step: 11
Training loss: 0.6016402751632801
Validation loss: 2.950769928498146

Epoch: 6| Step: 12
Training loss: 0.3462487241914291
Validation loss: 2.9473834729422776

Epoch: 6| Step: 13
Training loss: 0.40664398822254755
Validation loss: 3.0074963820497267

Epoch: 374| Step: 0
Training loss: 0.3209759540234086
Validation loss: 3.0006484814290357

Epoch: 6| Step: 1
Training loss: 0.3960189342379328
Validation loss: 2.9841053359877137

Epoch: 6| Step: 2
Training loss: 0.30280389295220966
Validation loss: 2.9534998929938756

Epoch: 6| Step: 3
Training loss: 0.793299450998947
Validation loss: 2.9618924764082837

Epoch: 6| Step: 4
Training loss: 0.4727397876405051
Validation loss: 2.915294710554074

Epoch: 6| Step: 5
Training loss: 0.3676387773310344
Validation loss: 2.9866513529949756

Epoch: 6| Step: 6
Training loss: 0.13161568787502143
Validation loss: 2.9442226508315703

Epoch: 6| Step: 7
Training loss: 0.36493738104336004
Validation loss: 3.0098343564288124

Epoch: 6| Step: 8
Training loss: 0.4872542146830254
Validation loss: 2.9851343011169797

Epoch: 6| Step: 9
Training loss: 0.38348877785438473
Validation loss: 3.0511727824657653

Epoch: 6| Step: 10
Training loss: 0.530219256195494
Validation loss: 2.91863828958536

Epoch: 6| Step: 11
Training loss: 0.455754869735322
Validation loss: 3.0295745964975356

Epoch: 6| Step: 12
Training loss: 0.36106803399708814
Validation loss: 2.9204386616344506

Epoch: 6| Step: 13
Training loss: 0.3982182815957325
Validation loss: 2.9539135077023375

Epoch: 375| Step: 0
Training loss: 0.432667214835696
Validation loss: 2.971200380126307

Epoch: 6| Step: 1
Training loss: 0.3227199934832672
Validation loss: 3.0027360228243722

Epoch: 6| Step: 2
Training loss: 0.5375510601808534
Validation loss: 2.933406696883243

Epoch: 6| Step: 3
Training loss: 0.4456808340397681
Validation loss: 2.986204535232829

Epoch: 6| Step: 4
Training loss: 0.3777910515476693
Validation loss: 2.9258103006344176

Epoch: 6| Step: 5
Training loss: 0.39314430365299297
Validation loss: 3.076455271750728

Epoch: 6| Step: 6
Training loss: 0.30288017207683765
Validation loss: 2.9796923104753956

Epoch: 6| Step: 7
Training loss: 0.3755832943796042
Validation loss: 3.002159295234009

Epoch: 6| Step: 8
Training loss: 0.46634371160915916
Validation loss: 2.9903939152869485

Epoch: 6| Step: 9
Training loss: 0.3761332396000616
Validation loss: 2.9640090564876

Epoch: 6| Step: 10
Training loss: 0.8552247139170825
Validation loss: 3.0663477671365382

Epoch: 6| Step: 11
Training loss: 0.2642763626117634
Validation loss: 2.9785916678305258

Epoch: 6| Step: 12
Training loss: 0.2749686965682208
Validation loss: 2.9831302170541685

Epoch: 6| Step: 13
Training loss: 0.6029392440626739
Validation loss: 3.0256676412644357

Epoch: 376| Step: 0
Training loss: 0.2934122670286277
Validation loss: 3.03672893140699

Epoch: 6| Step: 1
Training loss: 0.3016115593411419
Validation loss: 2.9573122106906533

Epoch: 6| Step: 2
Training loss: 0.2942625342805163
Validation loss: 3.011461074565712

Epoch: 6| Step: 3
Training loss: 0.6456635672469118
Validation loss: 2.943907924770607

Epoch: 6| Step: 4
Training loss: 0.29907271404621993
Validation loss: 2.9152141269275593

Epoch: 6| Step: 5
Training loss: 0.4742615763699717
Validation loss: 2.8577449995703565

Epoch: 6| Step: 6
Training loss: 0.3440477209009324
Validation loss: 2.9271393812431494

Epoch: 6| Step: 7
Training loss: 0.48563119059560467
Validation loss: 3.009737767596651

Epoch: 6| Step: 8
Training loss: 0.3462006819199337
Validation loss: 2.965821866682037

Epoch: 6| Step: 9
Training loss: 0.5350485644625068
Validation loss: 2.9468660043664756

Epoch: 6| Step: 10
Training loss: 0.26532828363798316
Validation loss: 3.036041170039619

Epoch: 6| Step: 11
Training loss: 0.5411669247592084
Validation loss: 3.0009317937826694

Epoch: 6| Step: 12
Training loss: 0.3790570185265775
Validation loss: 2.977884728158261

Epoch: 6| Step: 13
Training loss: 0.32022492444364126
Validation loss: 2.987322298987124

Epoch: 377| Step: 0
Training loss: 0.38313517303402356
Validation loss: 2.967576326964972

Epoch: 6| Step: 1
Training loss: 0.7398139343376722
Validation loss: 2.8712649754958663

Epoch: 6| Step: 2
Training loss: 0.23633652664256913
Validation loss: 2.9713115817246636

Epoch: 6| Step: 3
Training loss: 0.2944788478912114
Validation loss: 2.9444456570300916

Epoch: 6| Step: 4
Training loss: 0.5171095544446193
Validation loss: 3.033606069131942

Epoch: 6| Step: 5
Training loss: 0.440602896521498
Validation loss: 3.0776794872835644

Epoch: 6| Step: 6
Training loss: 0.4895929038011929
Validation loss: 3.0325413473465277

Epoch: 6| Step: 7
Training loss: 0.32931838547940057
Validation loss: 2.9510697844288205

Epoch: 6| Step: 8
Training loss: 0.34287092121394813
Validation loss: 3.017246554860404

Epoch: 6| Step: 9
Training loss: 0.3252968844312933
Validation loss: 2.9678767342063175

Epoch: 6| Step: 10
Training loss: 0.2818542717715336
Validation loss: 3.042203285399688

Epoch: 6| Step: 11
Training loss: 0.45731973916726576
Validation loss: 2.9612808363986165

Epoch: 6| Step: 12
Training loss: 0.4446638636898667
Validation loss: 3.003331493591637

Epoch: 6| Step: 13
Training loss: 0.34232165785472735
Validation loss: 2.9223294916114284

Epoch: 378| Step: 0
Training loss: 0.4668680559737303
Validation loss: 3.029226958572527

Epoch: 6| Step: 1
Training loss: 0.7098996058527305
Validation loss: 3.0210451556074833

Epoch: 6| Step: 2
Training loss: 0.3247969997503212
Validation loss: 2.9987112827088724

Epoch: 6| Step: 3
Training loss: 0.5101162227332593
Validation loss: 3.003598095284254

Epoch: 6| Step: 4
Training loss: 0.3877456209610602
Validation loss: 2.935620457379938

Epoch: 6| Step: 5
Training loss: 0.4158387860467503
Validation loss: 2.9645482629313196

Epoch: 6| Step: 6
Training loss: 0.38739644020376995
Validation loss: 2.927399008529442

Epoch: 6| Step: 7
Training loss: 0.4191804772706306
Validation loss: 2.9153572730988886

Epoch: 6| Step: 8
Training loss: 0.30375938397107466
Validation loss: 2.982235646007619

Epoch: 6| Step: 9
Training loss: 0.23415157477073098
Validation loss: 2.9792385937382035

Epoch: 6| Step: 10
Training loss: 0.4657204478957999
Validation loss: 3.0006302198086403

Epoch: 6| Step: 11
Training loss: 0.3072234161468053
Validation loss: 2.890643770998931

Epoch: 6| Step: 12
Training loss: 0.28626650398268944
Validation loss: 2.992667482555151

Epoch: 6| Step: 13
Training loss: 0.42283771307204027
Validation loss: 3.0692836341524083

Epoch: 379| Step: 0
Training loss: 0.44543100754454357
Validation loss: 2.99309400566719

Epoch: 6| Step: 1
Training loss: 0.26078367438997907
Validation loss: 2.9991564889367526

Epoch: 6| Step: 2
Training loss: 0.3522067630512742
Validation loss: 2.9550633334512217

Epoch: 6| Step: 3
Training loss: 0.21563437379281689
Validation loss: 3.0194967579650234

Epoch: 6| Step: 4
Training loss: 0.3514242854224584
Validation loss: 3.0138888195485127

Epoch: 6| Step: 5
Training loss: 0.45921362163721247
Validation loss: 3.0106858569812767

Epoch: 6| Step: 6
Training loss: 0.4041295465484402
Validation loss: 3.0029861238133404

Epoch: 6| Step: 7
Training loss: 0.32312193878317524
Validation loss: 2.975558254212072

Epoch: 6| Step: 8
Training loss: 0.7466899626651269
Validation loss: 2.9880991495867106

Epoch: 6| Step: 9
Training loss: 0.42640374551598803
Validation loss: 3.1026938014295387

Epoch: 6| Step: 10
Training loss: 0.37326055668173963
Validation loss: 3.0379925881798284

Epoch: 6| Step: 11
Training loss: 0.34946765904399985
Validation loss: 3.0062002377479162

Epoch: 6| Step: 12
Training loss: 0.3233886340908908
Validation loss: 2.9872441771506884

Epoch: 6| Step: 13
Training loss: 0.4439032659326279
Validation loss: 2.918883126358884

Epoch: 380| Step: 0
Training loss: 0.7122630243901413
Validation loss: 2.9784908906503738

Epoch: 6| Step: 1
Training loss: 0.5030637691982741
Validation loss: 2.9094088215403717

Epoch: 6| Step: 2
Training loss: 0.32182705253581284
Validation loss: 3.023028047815776

Epoch: 6| Step: 3
Training loss: 0.33717746113353897
Validation loss: 2.9731871389434112

Epoch: 6| Step: 4
Training loss: 0.4776046645461066
Validation loss: 2.9472789591358475

Epoch: 6| Step: 5
Training loss: 0.3912120984765365
Validation loss: 3.0373272882032425

Epoch: 6| Step: 6
Training loss: 0.3869115753324965
Validation loss: 3.0180828244418403

Epoch: 6| Step: 7
Training loss: 0.3022026807330991
Validation loss: 2.9320918004347956

Epoch: 6| Step: 8
Training loss: 0.3106137689482787
Validation loss: 3.0403183382861574

Epoch: 6| Step: 9
Training loss: 0.3414083070496625
Validation loss: 2.9662115923140093

Epoch: 6| Step: 10
Training loss: 0.5171653973330969
Validation loss: 2.9514684589106652

Epoch: 6| Step: 11
Training loss: 0.45974211134373455
Validation loss: 2.926102936753813

Epoch: 6| Step: 12
Training loss: 0.34052063410509936
Validation loss: 2.9306471816850754

Epoch: 6| Step: 13
Training loss: 0.39565668012383076
Validation loss: 2.9248497655384726

Epoch: 381| Step: 0
Training loss: 0.2770457749020322
Validation loss: 2.889445694934519

Epoch: 6| Step: 1
Training loss: 0.3485242957905216
Validation loss: 3.0637909250938415

Epoch: 6| Step: 2
Training loss: 0.35972963333268987
Validation loss: 2.8673136282332954

Epoch: 6| Step: 3
Training loss: 0.4117931219171284
Validation loss: 2.936413043050548

Epoch: 6| Step: 4
Training loss: 0.4380089320116868
Validation loss: 2.9001335809350315

Epoch: 6| Step: 5
Training loss: 0.4191383859480382
Validation loss: 2.9764153284783545

Epoch: 6| Step: 6
Training loss: 0.4388111766321993
Validation loss: 2.996048709376655

Epoch: 6| Step: 7
Training loss: 0.21226239033109823
Validation loss: 2.9191175018433353

Epoch: 6| Step: 8
Training loss: 0.3829591431301867
Validation loss: 2.9834711660124746

Epoch: 6| Step: 9
Training loss: 0.36562220743531154
Validation loss: 2.988848663513976

Epoch: 6| Step: 10
Training loss: 0.4674562402124067
Validation loss: 2.943431736074133

Epoch: 6| Step: 11
Training loss: 0.7066832471048018
Validation loss: 2.8985990220517293

Epoch: 6| Step: 12
Training loss: 0.30026452154621885
Validation loss: 2.911954865854294

Epoch: 6| Step: 13
Training loss: 0.442465768071894
Validation loss: 2.8993804850892695

Epoch: 382| Step: 0
Training loss: 0.3845967343283485
Validation loss: 2.9095875297413056

Epoch: 6| Step: 1
Training loss: 0.326832690099151
Validation loss: 2.9576453004315573

Epoch: 6| Step: 2
Training loss: 0.3666157024178774
Validation loss: 2.9589001063401112

Epoch: 6| Step: 3
Training loss: 0.2755763192123873
Validation loss: 2.9759826629383204

Epoch: 6| Step: 4
Training loss: 0.6047772057600624
Validation loss: 2.9488419113076096

Epoch: 6| Step: 5
Training loss: 0.4211771456035388
Validation loss: 2.9615633729994655

Epoch: 6| Step: 6
Training loss: 0.4054179473979568
Validation loss: 3.015936721739996

Epoch: 6| Step: 7
Training loss: 0.32669362579537176
Validation loss: 2.9583642760973348

Epoch: 6| Step: 8
Training loss: 0.38102953117544197
Validation loss: 2.9706393604344794

Epoch: 6| Step: 9
Training loss: 0.39853506202762073
Validation loss: 2.9654318218336164

Epoch: 6| Step: 10
Training loss: 0.25166422522752196
Validation loss: 2.8955350809169556

Epoch: 6| Step: 11
Training loss: 0.4637407953834631
Validation loss: 2.923538822257955

Epoch: 6| Step: 12
Training loss: 0.4964962775531687
Validation loss: 2.8945534208051815

Epoch: 6| Step: 13
Training loss: 0.3604081065570759
Validation loss: 2.9405564038352945

Epoch: 383| Step: 0
Training loss: 0.3738376365097337
Validation loss: 2.991601247435261

Epoch: 6| Step: 1
Training loss: 0.4397955175213419
Validation loss: 3.0249799659422894

Epoch: 6| Step: 2
Training loss: 0.3253489752739996
Validation loss: 3.0307309338781425

Epoch: 6| Step: 3
Training loss: 0.3086695276246912
Validation loss: 2.9115545612917693

Epoch: 6| Step: 4
Training loss: 0.27474656781663953
Validation loss: 2.961953719322523

Epoch: 6| Step: 5
Training loss: 0.39938608085530863
Validation loss: 2.919971913873254

Epoch: 6| Step: 6
Training loss: 0.24648990987617897
Validation loss: 2.9987420782673917

Epoch: 6| Step: 7
Training loss: 0.3735931949778877
Validation loss: 3.0098044004919293

Epoch: 6| Step: 8
Training loss: 0.6928661687674572
Validation loss: 2.9892059291759865

Epoch: 6| Step: 9
Training loss: 0.21662597105949927
Validation loss: 2.911938763572829

Epoch: 6| Step: 10
Training loss: 0.33674449246950106
Validation loss: 2.92387199496355

Epoch: 6| Step: 11
Training loss: 0.34441768219040714
Validation loss: 3.0363921632094635

Epoch: 6| Step: 12
Training loss: 0.37729818728517284
Validation loss: 2.8883063287310873

Epoch: 6| Step: 13
Training loss: 0.25146965837036067
Validation loss: 2.9555223210536883

Epoch: 384| Step: 0
Training loss: 0.2842420398172959
Validation loss: 2.9303079312662397

Epoch: 6| Step: 1
Training loss: 0.44488414440312374
Validation loss: 2.9483683793820883

Epoch: 6| Step: 2
Training loss: 0.2882774104661264
Validation loss: 2.9591884630783265

Epoch: 6| Step: 3
Training loss: 0.3112463002387156
Validation loss: 2.948334685613373

Epoch: 6| Step: 4
Training loss: 0.3223031224485687
Validation loss: 2.9797219823700054

Epoch: 6| Step: 5
Training loss: 0.49694603826024275
Validation loss: 2.994799132406908

Epoch: 6| Step: 6
Training loss: 0.3557739624295663
Validation loss: 2.967110378501217

Epoch: 6| Step: 7
Training loss: 0.4171297619187451
Validation loss: 2.944377841935945

Epoch: 6| Step: 8
Training loss: 0.3140824781298075
Validation loss: 2.960155145492744

Epoch: 6| Step: 9
Training loss: 0.29745266577878615
Validation loss: 2.9566109886503513

Epoch: 6| Step: 10
Training loss: 0.341892556013445
Validation loss: 2.9411984421339454

Epoch: 6| Step: 11
Training loss: 0.31686001488279436
Validation loss: 2.9946457846672967

Epoch: 6| Step: 12
Training loss: 0.3103688407491143
Validation loss: 3.028325180612387

Epoch: 6| Step: 13
Training loss: 0.6288907777766687
Validation loss: 2.99354375077009

Epoch: 385| Step: 0
Training loss: 0.3141635959805718
Validation loss: 2.9460055398494016

Epoch: 6| Step: 1
Training loss: 0.37485242959993537
Validation loss: 2.97689682625674

Epoch: 6| Step: 2
Training loss: 0.2934588465578927
Validation loss: 2.997615906662058

Epoch: 6| Step: 3
Training loss: 0.40416326480430087
Validation loss: 2.9401076423527615

Epoch: 6| Step: 4
Training loss: 0.4555616634077036
Validation loss: 3.002423248178206

Epoch: 6| Step: 5
Training loss: 0.3154882961186519
Validation loss: 2.929023348656076

Epoch: 6| Step: 6
Training loss: 0.4052071022989096
Validation loss: 2.8543776042055717

Epoch: 6| Step: 7
Training loss: 0.3599708841391234
Validation loss: 2.9985193466352005

Epoch: 6| Step: 8
Training loss: 0.35243946475506044
Validation loss: 3.0021758665974763

Epoch: 6| Step: 9
Training loss: 0.45559986641716943
Validation loss: 2.9768134384309173

Epoch: 6| Step: 10
Training loss: 0.65455378712392
Validation loss: 2.97429118434385

Epoch: 6| Step: 11
Training loss: 0.31707765434199
Validation loss: 2.9377943527244965

Epoch: 6| Step: 12
Training loss: 0.2631932329383709
Validation loss: 2.964930704388856

Epoch: 6| Step: 13
Training loss: 0.28688660886957795
Validation loss: 2.9874722983593602

Epoch: 386| Step: 0
Training loss: 0.32963002277882925
Validation loss: 2.9375956499475797

Epoch: 6| Step: 1
Training loss: 0.34668603810685894
Validation loss: 2.9677957707801506

Epoch: 6| Step: 2
Training loss: 0.6147793979728374
Validation loss: 2.9906636633212345

Epoch: 6| Step: 3
Training loss: 0.35490580407145106
Validation loss: 3.0026616236848755

Epoch: 6| Step: 4
Training loss: 0.2815529066350376
Validation loss: 2.96667947677104

Epoch: 6| Step: 5
Training loss: 0.5636394404162333
Validation loss: 3.000531109844864

Epoch: 6| Step: 6
Training loss: 0.4328575585938606
Validation loss: 3.043588440541518

Epoch: 6| Step: 7
Training loss: 0.3583345278269058
Validation loss: 3.022859293005221

Epoch: 6| Step: 8
Training loss: 0.3762671400519436
Validation loss: 2.942239954759893

Epoch: 6| Step: 9
Training loss: 0.3699095050229945
Validation loss: 2.9900629321251158

Epoch: 6| Step: 10
Training loss: 0.3738688057157095
Validation loss: 2.9815309030988124

Epoch: 6| Step: 11
Training loss: 0.3697799515099746
Validation loss: 2.979608080691877

Epoch: 6| Step: 12
Training loss: 0.28947253400258105
Validation loss: 2.986552457697766

Epoch: 6| Step: 13
Training loss: 0.3267130559446064
Validation loss: 2.9528435870716354

Epoch: 387| Step: 0
Training loss: 0.36930151364919855
Validation loss: 3.0188054787202234

Epoch: 6| Step: 1
Training loss: 0.4485497676397174
Validation loss: 2.9132562771462784

Epoch: 6| Step: 2
Training loss: 0.40103009029706166
Validation loss: 2.9357202292174316

Epoch: 6| Step: 3
Training loss: 0.35414629999204783
Validation loss: 3.0288922359157766

Epoch: 6| Step: 4
Training loss: 0.39240314132869875
Validation loss: 2.9721522194253063

Epoch: 6| Step: 5
Training loss: 0.4161918517614328
Validation loss: 2.9459543919992006

Epoch: 6| Step: 6
Training loss: 0.6083142756607947
Validation loss: 2.913348181124401

Epoch: 6| Step: 7
Training loss: 0.3619084826645045
Validation loss: 3.0292370198163683

Epoch: 6| Step: 8
Training loss: 0.41661340452551154
Validation loss: 2.9463045724425343

Epoch: 6| Step: 9
Training loss: 0.317745717251636
Validation loss: 2.963743706885148

Epoch: 6| Step: 10
Training loss: 0.2750413587203717
Validation loss: 2.98888711210369

Epoch: 6| Step: 11
Training loss: 0.38939383083138346
Validation loss: 2.987644315503281

Epoch: 6| Step: 12
Training loss: 0.4288487831903918
Validation loss: 2.9951818770354848

Epoch: 6| Step: 13
Training loss: 0.36787235025870285
Validation loss: 2.97045189779379

Epoch: 388| Step: 0
Training loss: 0.42495626617257015
Validation loss: 2.917160446512851

Epoch: 6| Step: 1
Training loss: 0.465546821585273
Validation loss: 2.9803729827280567

Epoch: 6| Step: 2
Training loss: 0.3340094038301918
Validation loss: 2.934135512280761

Epoch: 6| Step: 3
Training loss: 0.5227162530551718
Validation loss: 2.980281558976663

Epoch: 6| Step: 4
Training loss: 0.6437796632173047
Validation loss: 2.979337478400359

Epoch: 6| Step: 5
Training loss: 0.3968971809436547
Validation loss: 2.9894223097834605

Epoch: 6| Step: 6
Training loss: 0.400775556914289
Validation loss: 2.9063836890751626

Epoch: 6| Step: 7
Training loss: 0.24351844089606806
Validation loss: 2.9386173585169297

Epoch: 6| Step: 8
Training loss: 0.6112931945376409
Validation loss: 2.922579702438604

Epoch: 6| Step: 9
Training loss: 0.39045614407673657
Validation loss: 2.9742353926015057

Epoch: 6| Step: 10
Training loss: 0.3607827891254595
Validation loss: 2.911826645558206

Epoch: 6| Step: 11
Training loss: 0.5780270725513201
Validation loss: 2.916136152975062

Epoch: 6| Step: 12
Training loss: 0.3708362087216859
Validation loss: 3.0387771524785157

Epoch: 6| Step: 13
Training loss: 0.4619208530951125
Validation loss: 2.958550986937965

Epoch: 389| Step: 0
Training loss: 0.3458411593107064
Validation loss: 3.0246882517095384

Epoch: 6| Step: 1
Training loss: 0.3416384302466131
Validation loss: 2.9806411713289256

Epoch: 6| Step: 2
Training loss: 0.3978781045666136
Validation loss: 2.9748810485225254

Epoch: 6| Step: 3
Training loss: 0.4326926826410218
Validation loss: 2.9883528424498653

Epoch: 6| Step: 4
Training loss: 0.3834844841497838
Validation loss: 2.934430216038522

Epoch: 6| Step: 5
Training loss: 0.441074449182452
Validation loss: 3.0003730952535443

Epoch: 6| Step: 6
Training loss: 0.652692553072434
Validation loss: 2.985349166614593

Epoch: 6| Step: 7
Training loss: 0.44470286886286176
Validation loss: 3.0734751737994546

Epoch: 6| Step: 8
Training loss: 0.49513355957891714
Validation loss: 3.0606305910827616

Epoch: 6| Step: 9
Training loss: 0.45180656740655306
Validation loss: 3.0422805053517346

Epoch: 6| Step: 10
Training loss: 0.3684947908750181
Validation loss: 3.0433353958944607

Epoch: 6| Step: 11
Training loss: 0.4958423818702934
Validation loss: 2.9432480353729007

Epoch: 6| Step: 12
Training loss: 0.2939599499273874
Validation loss: 2.934701641781083

Epoch: 6| Step: 13
Training loss: 0.35165172080548207
Validation loss: 2.956756780628065

Epoch: 390| Step: 0
Training loss: 0.4309886133311747
Validation loss: 2.985872209341822

Epoch: 6| Step: 1
Training loss: 0.4929459797819172
Validation loss: 2.9452400772000535

Epoch: 6| Step: 2
Training loss: 0.6462128175483182
Validation loss: 3.03044425768919

Epoch: 6| Step: 3
Training loss: 0.68878366100768
Validation loss: 2.984271741748399

Epoch: 6| Step: 4
Training loss: 0.24473310676464807
Validation loss: 2.96267789958429

Epoch: 6| Step: 5
Training loss: 0.31306448260285163
Validation loss: 2.961675553613516

Epoch: 6| Step: 6
Training loss: 0.23516580365820386
Validation loss: 2.9745200451207374

Epoch: 6| Step: 7
Training loss: 0.24888213393439806
Validation loss: 2.919462966154439

Epoch: 6| Step: 8
Training loss: 0.24956220799062886
Validation loss: 2.9273964023258103

Epoch: 6| Step: 9
Training loss: 0.24792472955804962
Validation loss: 2.9371245665101764

Epoch: 6| Step: 10
Training loss: 0.33897223479648736
Validation loss: 3.0067323801284496

Epoch: 6| Step: 11
Training loss: 0.3767840742625636
Validation loss: 2.97648252044318

Epoch: 6| Step: 12
Training loss: 0.3828525133046204
Validation loss: 2.979077735765081

Epoch: 6| Step: 13
Training loss: 0.2758968516226845
Validation loss: 2.9924540720522144

Epoch: 391| Step: 0
Training loss: 0.37460407575532617
Validation loss: 2.966633627918307

Epoch: 6| Step: 1
Training loss: 0.33020791205169725
Validation loss: 2.9228740350972666

Epoch: 6| Step: 2
Training loss: 0.3927288240640317
Validation loss: 2.893768512070656

Epoch: 6| Step: 3
Training loss: 0.43738418135991364
Validation loss: 2.8802957550265122

Epoch: 6| Step: 4
Training loss: 0.3588303709883843
Validation loss: 2.9067797981200973

Epoch: 6| Step: 5
Training loss: 0.40937421813191305
Validation loss: 2.956725776243497

Epoch: 6| Step: 6
Training loss: 0.42621483730475546
Validation loss: 3.015446026750362

Epoch: 6| Step: 7
Training loss: 0.36163451118105716
Validation loss: 2.945962174838541

Epoch: 6| Step: 8
Training loss: 0.4116492391898748
Validation loss: 2.953410799167278

Epoch: 6| Step: 9
Training loss: 0.31263553541232036
Validation loss: 2.9639386993277714

Epoch: 6| Step: 10
Training loss: 0.5370819084774004
Validation loss: 2.8998616328060502

Epoch: 6| Step: 11
Training loss: 0.4379304743524849
Validation loss: 2.9681540978658054

Epoch: 6| Step: 12
Training loss: 0.6601859091692884
Validation loss: 2.9835157106016896

Epoch: 6| Step: 13
Training loss: 0.31434684047133543
Validation loss: 2.952726925993892

Epoch: 392| Step: 0
Training loss: 0.39495509580499344
Validation loss: 2.9637043689833433

Epoch: 6| Step: 1
Training loss: 0.6620232180012953
Validation loss: 3.0057180932056435

Epoch: 6| Step: 2
Training loss: 0.39283857673271444
Validation loss: 2.991285648008659

Epoch: 6| Step: 3
Training loss: 0.26332009478883867
Validation loss: 3.0092786774185414

Epoch: 6| Step: 4
Training loss: 0.3906031983967303
Validation loss: 3.010232983609534

Epoch: 6| Step: 5
Training loss: 0.21289169241261396
Validation loss: 2.896043390207171

Epoch: 6| Step: 6
Training loss: 0.38869717769594303
Validation loss: 2.9786352248229986

Epoch: 6| Step: 7
Training loss: 0.5619893405147769
Validation loss: 2.9721551072534

Epoch: 6| Step: 8
Training loss: 0.2131692130969672
Validation loss: 2.9537820236530004

Epoch: 6| Step: 9
Training loss: 0.5379625791738112
Validation loss: 2.9666021373960105

Epoch: 6| Step: 10
Training loss: 0.3288169331820038
Validation loss: 3.121388281021481

Epoch: 6| Step: 11
Training loss: 0.6394517902041086
Validation loss: 3.124266144098182

Epoch: 6| Step: 12
Training loss: 0.5525422318314736
Validation loss: 3.0883420436905795

Epoch: 6| Step: 13
Training loss: 0.3400460222245226
Validation loss: 3.018778152281896

Epoch: 393| Step: 0
Training loss: 0.2702298716125477
Validation loss: 2.917482484526849

Epoch: 6| Step: 1
Training loss: 0.5492785360209899
Validation loss: 2.9441461791912804

Epoch: 6| Step: 2
Training loss: 0.5869084261149126
Validation loss: 2.9394092172108257

Epoch: 6| Step: 3
Training loss: 0.3106086717454955
Validation loss: 2.9433058590612933

Epoch: 6| Step: 4
Training loss: 0.2452019852548737
Validation loss: 2.916117593762858

Epoch: 6| Step: 5
Training loss: 0.3862790584744299
Validation loss: 2.985675987557322

Epoch: 6| Step: 6
Training loss: 0.3797857557720181
Validation loss: 3.0068464304802975

Epoch: 6| Step: 7
Training loss: 0.47475707342252915
Validation loss: 3.0939243665680154

Epoch: 6| Step: 8
Training loss: 0.2672233038888872
Validation loss: 3.0814377052439057

Epoch: 6| Step: 9
Training loss: 0.4885089190907567
Validation loss: 3.025629239803339

Epoch: 6| Step: 10
Training loss: 0.3265190903316868
Validation loss: 2.948422719881

Epoch: 6| Step: 11
Training loss: 0.3608846055943543
Validation loss: 2.9912854088954983

Epoch: 6| Step: 12
Training loss: 0.6694243560532057
Validation loss: 2.9300080933529604

Epoch: 6| Step: 13
Training loss: 0.41391100001246667
Validation loss: 2.9459563208503816

Epoch: 394| Step: 0
Training loss: 0.3626508062004217
Validation loss: 2.865534958418

Epoch: 6| Step: 1
Training loss: 0.3940670568579343
Validation loss: 2.8922578547195177

Epoch: 6| Step: 2
Training loss: 0.3691394139830086
Validation loss: 3.014674997331136

Epoch: 6| Step: 3
Training loss: 0.4621562040822786
Validation loss: 2.946956185995393

Epoch: 6| Step: 4
Training loss: 0.2840041047474576
Validation loss: 3.0170702855688902

Epoch: 6| Step: 5
Training loss: 0.44194123247912065
Validation loss: 2.931774010145172

Epoch: 6| Step: 6
Training loss: 0.41943865629789095
Validation loss: 3.0115861480059927

Epoch: 6| Step: 7
Training loss: 0.35556270070438284
Validation loss: 3.02588539354705

Epoch: 6| Step: 8
Training loss: 0.3150186961355285
Validation loss: 2.979783098873984

Epoch: 6| Step: 9
Training loss: 0.45051821301824657
Validation loss: 2.9291092094187094

Epoch: 6| Step: 10
Training loss: 0.46334491440252423
Validation loss: 2.887756285089828

Epoch: 6| Step: 11
Training loss: 0.6648151620171605
Validation loss: 2.992469289606678

Epoch: 6| Step: 12
Training loss: 0.45472743065492865
Validation loss: 3.0378572350726736

Epoch: 6| Step: 13
Training loss: 0.32188662582067806
Validation loss: 2.9841274005643372

Epoch: 395| Step: 0
Training loss: 0.3027631561380229
Validation loss: 2.9650798933084395

Epoch: 6| Step: 1
Training loss: 0.34568519330259484
Validation loss: 3.0403654285024033

Epoch: 6| Step: 2
Training loss: 0.4828058020117876
Validation loss: 2.977401254779764

Epoch: 6| Step: 3
Training loss: 0.4050635104361752
Validation loss: 2.892890083959692

Epoch: 6| Step: 4
Training loss: 0.35535387132156054
Validation loss: 2.9789417466487245

Epoch: 6| Step: 5
Training loss: 0.3746749542083071
Validation loss: 3.008678757410869

Epoch: 6| Step: 6
Training loss: 0.3118961341019338
Validation loss: 3.033559921905191

Epoch: 6| Step: 7
Training loss: 0.5525280462888106
Validation loss: 3.0404850916154844

Epoch: 6| Step: 8
Training loss: 0.26656067363475583
Validation loss: 3.074593624151705

Epoch: 6| Step: 9
Training loss: 0.2994462520368955
Validation loss: 3.0705923740737933

Epoch: 6| Step: 10
Training loss: 0.3739075643067588
Validation loss: 3.0404118775876365

Epoch: 6| Step: 11
Training loss: 0.3937696149269773
Validation loss: 3.0911189235853933

Epoch: 6| Step: 12
Training loss: 0.3411107943160522
Validation loss: 2.938460253958358

Epoch: 6| Step: 13
Training loss: 0.45986375369219634
Validation loss: 2.979758588412644

Epoch: 396| Step: 0
Training loss: 0.4302597916456977
Validation loss: 2.9704110701953232

Epoch: 6| Step: 1
Training loss: 0.21157287344018788
Validation loss: 3.0583485861942736

Epoch: 6| Step: 2
Training loss: 0.34059862725941076
Validation loss: 2.9094343617109795

Epoch: 6| Step: 3
Training loss: 0.294915205520096
Validation loss: 2.9933240440142383

Epoch: 6| Step: 4
Training loss: 0.42166188826636614
Validation loss: 2.935932985971935

Epoch: 6| Step: 5
Training loss: 0.4905234164871157
Validation loss: 3.0559404280092273

Epoch: 6| Step: 6
Training loss: 0.41474530763598755
Validation loss: 3.016420513107169

Epoch: 6| Step: 7
Training loss: 0.4638167183173641
Validation loss: 3.051185076464461

Epoch: 6| Step: 8
Training loss: 0.26826472494234443
Validation loss: 3.088741950005694

Epoch: 6| Step: 9
Training loss: 0.6424960283980463
Validation loss: 3.030998429284045

Epoch: 6| Step: 10
Training loss: 0.36804913819114593
Validation loss: 3.0722525746496174

Epoch: 6| Step: 11
Training loss: 0.3421136968095334
Validation loss: 2.9503764795925287

Epoch: 6| Step: 12
Training loss: 0.2608579742860161
Validation loss: 2.9046662093010345

Epoch: 6| Step: 13
Training loss: 0.39481956975494026
Validation loss: 2.912603331712478

Epoch: 397| Step: 0
Training loss: 0.39546414357927295
Validation loss: 2.8680007571162203

Epoch: 6| Step: 1
Training loss: 0.39531431763121805
Validation loss: 2.910254450769044

Epoch: 6| Step: 2
Training loss: 0.3393209316325391
Validation loss: 2.916320839315965

Epoch: 6| Step: 3
Training loss: 0.4401887289515115
Validation loss: 2.9731497436417604

Epoch: 6| Step: 4
Training loss: 0.2824503925113446
Validation loss: 2.928765086451147

Epoch: 6| Step: 5
Training loss: 0.30068871697239236
Validation loss: 2.982612115820993

Epoch: 6| Step: 6
Training loss: 0.3206218063463135
Validation loss: 2.9896446159718666

Epoch: 6| Step: 7
Training loss: 0.56524987400531
Validation loss: 3.019429680948936

Epoch: 6| Step: 8
Training loss: 0.40457127422834654
Validation loss: 3.0770713177452618

Epoch: 6| Step: 9
Training loss: 0.30851901634286266
Validation loss: 2.950992736159403

Epoch: 6| Step: 10
Training loss: 0.3561140846850533
Validation loss: 2.9611292284621404

Epoch: 6| Step: 11
Training loss: 0.5347814988092412
Validation loss: 2.9136388775880433

Epoch: 6| Step: 12
Training loss: 0.689055914641937
Validation loss: 2.9599130245481216

Epoch: 6| Step: 13
Training loss: 0.4652580530657534
Validation loss: 2.9159750913241633

Epoch: 398| Step: 0
Training loss: 0.4841874590177311
Validation loss: 3.0009525958932204

Epoch: 6| Step: 1
Training loss: 0.3934840477335878
Validation loss: 2.980101969871008

Epoch: 6| Step: 2
Training loss: 0.24842032907034817
Validation loss: 2.9676469861901627

Epoch: 6| Step: 3
Training loss: 0.4429601476732207
Validation loss: 3.0518692297369565

Epoch: 6| Step: 4
Training loss: 0.2918239734123759
Validation loss: 2.949475706245395

Epoch: 6| Step: 5
Training loss: 0.2306521058112767
Validation loss: 2.9119721006552077

Epoch: 6| Step: 6
Training loss: 0.3275151602861554
Validation loss: 2.8810101934060883

Epoch: 6| Step: 7
Training loss: 0.3370551767464396
Validation loss: 2.947106419656287

Epoch: 6| Step: 8
Training loss: 0.2688195742882703
Validation loss: 2.942119773589011

Epoch: 6| Step: 9
Training loss: 0.40365317143158674
Validation loss: 2.9515915914501654

Epoch: 6| Step: 10
Training loss: 0.44125603339417313
Validation loss: 2.9384981448089937

Epoch: 6| Step: 11
Training loss: 0.5639924542162396
Validation loss: 2.9581842295363354

Epoch: 6| Step: 12
Training loss: 0.22942534751682872
Validation loss: 2.9993831609662753

Epoch: 6| Step: 13
Training loss: 0.37540485462287265
Validation loss: 2.976250325918146

Epoch: 399| Step: 0
Training loss: 0.2953484336748852
Validation loss: 3.020121514652516

Epoch: 6| Step: 1
Training loss: 0.27700610494771877
Validation loss: 2.9856801000425413

Epoch: 6| Step: 2
Training loss: 0.7239751379317682
Validation loss: 2.9481395372090695

Epoch: 6| Step: 3
Training loss: 0.2702648710725639
Validation loss: 2.918128278627921

Epoch: 6| Step: 4
Training loss: 0.42934742387843045
Validation loss: 2.8988021113997595

Epoch: 6| Step: 5
Training loss: 0.3407342796715644
Validation loss: 2.9618394160797914

Epoch: 6| Step: 6
Training loss: 0.2802299306244297
Validation loss: 2.9875481132133843

Epoch: 6| Step: 7
Training loss: 0.44496778899316153
Validation loss: 2.9320413585406935

Epoch: 6| Step: 8
Training loss: 0.45436429862495187
Validation loss: 2.978916415572277

Epoch: 6| Step: 9
Training loss: 0.3582795073129534
Validation loss: 2.9416783423547774

Epoch: 6| Step: 10
Training loss: 0.3179216945237283
Validation loss: 2.970155951882735

Epoch: 6| Step: 11
Training loss: 0.5046629731445422
Validation loss: 2.9193289776790112

Epoch: 6| Step: 12
Training loss: 0.524103452734955
Validation loss: 3.0522785623406374

Epoch: 6| Step: 13
Training loss: 0.41853419052113006
Validation loss: 2.9957481294346135

Epoch: 400| Step: 0
Training loss: 0.26993254490036345
Validation loss: 2.979199740530816

Epoch: 6| Step: 1
Training loss: 0.331508112157986
Validation loss: 2.9249054939674464

Epoch: 6| Step: 2
Training loss: 0.1601251944228815
Validation loss: 2.9229635974889394

Epoch: 6| Step: 3
Training loss: 0.4172755937755022
Validation loss: 2.944649632719951

Epoch: 6| Step: 4
Training loss: 0.46537119329362353
Validation loss: 3.0069906325655817

Epoch: 6| Step: 5
Training loss: 0.30339121778887707
Validation loss: 3.048977327086718

Epoch: 6| Step: 6
Training loss: 0.36389932045208784
Validation loss: 3.0839573684034947

Epoch: 6| Step: 7
Training loss: 0.3209607960530036
Validation loss: 2.931098320241955

Epoch: 6| Step: 8
Training loss: 0.29350390829460504
Validation loss: 2.954683609046573

Epoch: 6| Step: 9
Training loss: 0.5949008730051083
Validation loss: 2.975910212081796

Epoch: 6| Step: 10
Training loss: 0.3939899092146949
Validation loss: 2.949099412402572

Epoch: 6| Step: 11
Training loss: 0.34967132104803955
Validation loss: 2.9482461095975276

Epoch: 6| Step: 12
Training loss: 0.2564721377448681
Validation loss: 2.974268485674572

Epoch: 6| Step: 13
Training loss: 0.2590367121912706
Validation loss: 2.924189407428348

Testing loss: 2.923644156365672
