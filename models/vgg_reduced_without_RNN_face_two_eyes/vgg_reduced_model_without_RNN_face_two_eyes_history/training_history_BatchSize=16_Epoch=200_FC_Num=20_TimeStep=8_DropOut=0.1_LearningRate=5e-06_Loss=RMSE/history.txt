Epoch: 1| Step: 0
Training loss: 6.921504094711313
Validation loss: 6.257791316726396

Epoch: 6| Step: 1
Training loss: 6.719668019586758
Validation loss: 6.231737845865296

Epoch: 6| Step: 2
Training loss: 5.578608473226867
Validation loss: 6.205113986492741

Epoch: 6| Step: 3
Training loss: 6.489814407210661
Validation loss: 6.17896149136698

Epoch: 6| Step: 4
Training loss: 6.047991509083434
Validation loss: 6.154889726185507

Epoch: 6| Step: 5
Training loss: 5.8687100117613955
Validation loss: 6.128323697699942

Epoch: 6| Step: 6
Training loss: 6.412401177014774
Validation loss: 6.101745967410453

Epoch: 6| Step: 7
Training loss: 6.202086854249645
Validation loss: 6.0770208537547585

Epoch: 6| Step: 8
Training loss: 6.365077056298469
Validation loss: 6.050755454152701

Epoch: 6| Step: 9
Training loss: 6.85593058451495
Validation loss: 6.022979494618457

Epoch: 6| Step: 10
Training loss: 6.083269232146581
Validation loss: 5.998757339645806

Epoch: 6| Step: 11
Training loss: 5.294878468041831
Validation loss: 5.972667640024838

Epoch: 6| Step: 12
Training loss: 5.85368669200732
Validation loss: 5.9461678396369

Epoch: 6| Step: 13
Training loss: 5.933305081646698
Validation loss: 5.917238028792145

Epoch: 2| Step: 0
Training loss: 5.030570606303026
Validation loss: 5.888892339709408

Epoch: 6| Step: 1
Training loss: 6.670754832231378
Validation loss: 5.857923946845048

Epoch: 6| Step: 2
Training loss: 5.8026646905526365
Validation loss: 5.8298578899112865

Epoch: 6| Step: 3
Training loss: 6.761357959485567
Validation loss: 5.796316580939467

Epoch: 6| Step: 4
Training loss: 5.001306553840046
Validation loss: 5.763418131936776

Epoch: 6| Step: 5
Training loss: 5.986024474864087
Validation loss: 5.727490914075469

Epoch: 6| Step: 6
Training loss: 5.9899624469579775
Validation loss: 5.69323835031638

Epoch: 6| Step: 7
Training loss: 5.106525711590969
Validation loss: 5.656427229603906

Epoch: 6| Step: 8
Training loss: 4.937568953793143
Validation loss: 5.617514878850184

Epoch: 6| Step: 9
Training loss: 5.726873579332125
Validation loss: 5.581252502691456

Epoch: 6| Step: 10
Training loss: 5.620136447213959
Validation loss: 5.543141400670706

Epoch: 6| Step: 11
Training loss: 6.269475272335771
Validation loss: 5.49794580650148

Epoch: 6| Step: 12
Training loss: 5.730553624435365
Validation loss: 5.453992481330489

Epoch: 6| Step: 13
Training loss: 5.760528876078038
Validation loss: 5.410505086621618

Epoch: 3| Step: 0
Training loss: 5.014614680844269
Validation loss: 5.362058214367952

Epoch: 6| Step: 1
Training loss: 5.5720287530708985
Validation loss: 5.312556726489419

Epoch: 6| Step: 2
Training loss: 5.754682541616449
Validation loss: 5.262874439537106

Epoch: 6| Step: 3
Training loss: 4.877481855850454
Validation loss: 5.210957845012366

Epoch: 6| Step: 4
Training loss: 4.7618853795701614
Validation loss: 5.157590379759779

Epoch: 6| Step: 5
Training loss: 5.836745690043737
Validation loss: 5.102599961010195

Epoch: 6| Step: 6
Training loss: 5.184878318778753
Validation loss: 5.038462837280297

Epoch: 6| Step: 7
Training loss: 4.465625017084719
Validation loss: 4.976148459369461

Epoch: 6| Step: 8
Training loss: 5.493047307786994
Validation loss: 4.915007774758229

Epoch: 6| Step: 9
Training loss: 4.757124125976867
Validation loss: 4.845069164180061

Epoch: 6| Step: 10
Training loss: 5.155385077789337
Validation loss: 4.77878254236677

Epoch: 6| Step: 11
Training loss: 4.969360697901654
Validation loss: 4.7091712993670365

Epoch: 6| Step: 12
Training loss: 4.284575347334018
Validation loss: 4.62799511404612

Epoch: 6| Step: 13
Training loss: 4.736582829813759
Validation loss: 4.5465701286120295

Epoch: 4| Step: 0
Training loss: 4.991425027661208
Validation loss: 4.46505419084187

Epoch: 6| Step: 1
Training loss: 3.956272003450117
Validation loss: 4.380331913871314

Epoch: 6| Step: 2
Training loss: 4.815241639599148
Validation loss: 4.292583602182972

Epoch: 6| Step: 3
Training loss: 3.852673352974747
Validation loss: 4.199587405087016

Epoch: 6| Step: 4
Training loss: 4.939692143411337
Validation loss: 4.108044485083451

Epoch: 6| Step: 5
Training loss: 4.026674971750886
Validation loss: 3.9996303745198736

Epoch: 6| Step: 6
Training loss: 2.821772654421069
Validation loss: 3.903013897982408

Epoch: 6| Step: 7
Training loss: 4.367272664503906
Validation loss: 3.8032301370783297

Epoch: 6| Step: 8
Training loss: 3.7946329914894403
Validation loss: 3.6876432962107786

Epoch: 6| Step: 9
Training loss: 3.4348336716185504
Validation loss: 3.5932297924413694

Epoch: 6| Step: 10
Training loss: 3.6316199529502002
Validation loss: 3.492636951081538

Epoch: 6| Step: 11
Training loss: 3.6775214751010092
Validation loss: 3.3858235667303234

Epoch: 6| Step: 12
Training loss: 3.3368144613555786
Validation loss: 3.2916488807938116

Epoch: 6| Step: 13
Training loss: 2.770533284933131
Validation loss: 3.180940273473707

Epoch: 5| Step: 0
Training loss: 3.562538012920825
Validation loss: 3.0746411199412713

Epoch: 6| Step: 1
Training loss: 2.868642827444322
Validation loss: 2.989822289534622

Epoch: 6| Step: 2
Training loss: 3.050504742741083
Validation loss: 2.895137900042246

Epoch: 6| Step: 3
Training loss: 3.293547917632623
Validation loss: 2.8036084804684043

Epoch: 6| Step: 4
Training loss: 2.6567628253237006
Validation loss: 2.734399719126549

Epoch: 6| Step: 5
Training loss: 2.7418430905455926
Validation loss: 2.6858661031859286

Epoch: 6| Step: 6
Training loss: 2.0221860101040283
Validation loss: 2.6514706267709838

Epoch: 6| Step: 7
Training loss: 2.7555698861839892
Validation loss: 2.628494993844966

Epoch: 6| Step: 8
Training loss: 2.708018201442838
Validation loss: 2.6338280323782026

Epoch: 6| Step: 9
Training loss: 2.7245349942244124
Validation loss: 2.61406352029261

Epoch: 6| Step: 10
Training loss: 3.2949257824054334
Validation loss: 2.6061075429305323

Epoch: 6| Step: 11
Training loss: 2.189840427141666
Validation loss: 2.6319962772934393

Epoch: 6| Step: 12
Training loss: 3.1220231182408114
Validation loss: 2.657228820568033

Epoch: 6| Step: 13
Training loss: 1.9963456982131857
Validation loss: 2.6798400390627775

Epoch: 6| Step: 0
Training loss: 2.549195899592079
Validation loss: 2.693966692641429

Epoch: 6| Step: 1
Training loss: 2.741678739557865
Validation loss: 2.711691657124888

Epoch: 6| Step: 2
Training loss: 3.155049161694239
Validation loss: 2.7222545296401885

Epoch: 6| Step: 3
Training loss: 2.272439324604463
Validation loss: 2.7327556428979873

Epoch: 6| Step: 4
Training loss: 2.2470176853083244
Validation loss: 2.7071677022638143

Epoch: 6| Step: 5
Training loss: 3.6161741480963485
Validation loss: 2.7123323309624108

Epoch: 6| Step: 6
Training loss: 3.4755446412006443
Validation loss: 2.7125608950106597

Epoch: 6| Step: 7
Training loss: 1.9412156439379762
Validation loss: 2.6784388206596472

Epoch: 6| Step: 8
Training loss: 2.5354428827272497
Validation loss: 2.6739192229143685

Epoch: 6| Step: 9
Training loss: 2.903929081032458
Validation loss: 2.6520428194206342

Epoch: 6| Step: 10
Training loss: 3.0543311025807096
Validation loss: 2.650584488115155

Epoch: 6| Step: 11
Training loss: 2.7471214314087082
Validation loss: 2.6272110028949522

Epoch: 6| Step: 12
Training loss: 2.418732801272732
Validation loss: 2.627808105801378

Epoch: 6| Step: 13
Training loss: 1.9870808093336982
Validation loss: 2.6212362297131784

Epoch: 7| Step: 0
Training loss: 2.3621548072479377
Validation loss: 2.6124643095216

Epoch: 6| Step: 1
Training loss: 2.640915081636346
Validation loss: 2.600542290388491

Epoch: 6| Step: 2
Training loss: 2.566455672207729
Validation loss: 2.609493580330001

Epoch: 6| Step: 3
Training loss: 2.4609941748496276
Validation loss: 2.604375301904541

Epoch: 6| Step: 4
Training loss: 2.6453136824882915
Validation loss: 2.5899475598518973

Epoch: 6| Step: 5
Training loss: 3.216631590367006
Validation loss: 2.5977803518532534

Epoch: 6| Step: 6
Training loss: 1.5361338989486781
Validation loss: 2.5938226161121696

Epoch: 6| Step: 7
Training loss: 2.6425087434015913
Validation loss: 2.592461844457475

Epoch: 6| Step: 8
Training loss: 3.201402154335531
Validation loss: 2.592415661741299

Epoch: 6| Step: 9
Training loss: 2.082112781295289
Validation loss: 2.61769158362664

Epoch: 6| Step: 10
Training loss: 2.6411629755186885
Validation loss: 2.6123518875944187

Epoch: 6| Step: 11
Training loss: 3.056902226475195
Validation loss: 2.611276797748612

Epoch: 6| Step: 12
Training loss: 2.660119682430382
Validation loss: 2.620186798046837

Epoch: 6| Step: 13
Training loss: 2.9534898966443204
Validation loss: 2.61178027251813

Epoch: 8| Step: 0
Training loss: 2.4176682884869707
Validation loss: 2.593777545338409

Epoch: 6| Step: 1
Training loss: 2.9533148810482595
Validation loss: 2.581410766779868

Epoch: 6| Step: 2
Training loss: 2.559667277618917
Validation loss: 2.6074549755038503

Epoch: 6| Step: 3
Training loss: 2.2662817693672834
Validation loss: 2.6020902111816726

Epoch: 6| Step: 4
Training loss: 2.3620665904517324
Validation loss: 2.589606579660639

Epoch: 6| Step: 5
Training loss: 2.5633452347312553
Validation loss: 2.5986891067487563

Epoch: 6| Step: 6
Training loss: 3.0950015840541747
Validation loss: 2.5828808777933694

Epoch: 6| Step: 7
Training loss: 2.4664523865012944
Validation loss: 2.580570933356956

Epoch: 6| Step: 8
Training loss: 2.558836574534087
Validation loss: 2.5807138257127256

Epoch: 6| Step: 9
Training loss: 2.833718853322053
Validation loss: 2.576893067075691

Epoch: 6| Step: 10
Training loss: 2.559136579165472
Validation loss: 2.5764255509648457

Epoch: 6| Step: 11
Training loss: 3.1823107796369228
Validation loss: 2.5932187375080304

Epoch: 6| Step: 12
Training loss: 2.3661593479982765
Validation loss: 2.5849971386803263

Epoch: 6| Step: 13
Training loss: 2.74445625200533
Validation loss: 2.585380809288345

Epoch: 9| Step: 0
Training loss: 2.367167557736234
Validation loss: 2.5782923172111243

Epoch: 6| Step: 1
Training loss: 3.0653010423687066
Validation loss: 2.560600600271848

Epoch: 6| Step: 2
Training loss: 1.864409546949246
Validation loss: 2.5724290444907147

Epoch: 6| Step: 3
Training loss: 2.6273665886282482
Validation loss: 2.5762024155340013

Epoch: 6| Step: 4
Training loss: 2.8142139722353483
Validation loss: 2.5957009205690413

Epoch: 6| Step: 5
Training loss: 2.7798623041315627
Validation loss: 2.578998502467848

Epoch: 6| Step: 6
Training loss: 2.5466660489918755
Validation loss: 2.5733868301921885

Epoch: 6| Step: 7
Training loss: 2.7632687979027466
Validation loss: 2.580933491881215

Epoch: 6| Step: 8
Training loss: 2.8773276816175013
Validation loss: 2.579490608204643

Epoch: 6| Step: 9
Training loss: 3.171564096331441
Validation loss: 2.577190877283834

Epoch: 6| Step: 10
Training loss: 2.169475739606509
Validation loss: 2.56624188179854

Epoch: 6| Step: 11
Training loss: 2.1921063561080376
Validation loss: 2.5845990208033838

Epoch: 6| Step: 12
Training loss: 2.5010242271424357
Validation loss: 2.582317049846304

Epoch: 6| Step: 13
Training loss: 2.826796667585383
Validation loss: 2.5794433613776553

Epoch: 10| Step: 0
Training loss: 3.168618169747162
Validation loss: 2.5804192247526414

Epoch: 6| Step: 1
Training loss: 1.8816804767211113
Validation loss: 2.568484845982659

Epoch: 6| Step: 2
Training loss: 2.2063630029197543
Validation loss: 2.5680970883579826

Epoch: 6| Step: 3
Training loss: 2.7904069155307694
Validation loss: 2.585628371955358

Epoch: 6| Step: 4
Training loss: 2.599190762102284
Validation loss: 2.586182612454927

Epoch: 6| Step: 5
Training loss: 3.1552738908716016
Validation loss: 2.58230436249372

Epoch: 6| Step: 6
Training loss: 2.1745699621801684
Validation loss: 2.5705884420112652

Epoch: 6| Step: 7
Training loss: 3.003924504932747
Validation loss: 2.5845968530245855

Epoch: 6| Step: 8
Training loss: 2.475436655693807
Validation loss: 2.575317025035809

Epoch: 6| Step: 9
Training loss: 2.6835444416696848
Validation loss: 2.5730545429142313

Epoch: 6| Step: 10
Training loss: 2.4980924958573665
Validation loss: 2.567708374601187

Epoch: 6| Step: 11
Training loss: 2.938236550049681
Validation loss: 2.5627752016737566

Epoch: 6| Step: 12
Training loss: 2.245561672711785
Validation loss: 2.5708839067361793

Epoch: 6| Step: 13
Training loss: 2.6934983492177547
Validation loss: 2.574215562400716

Epoch: 11| Step: 0
Training loss: 2.1024213546214194
Validation loss: 2.5782790937515445

Epoch: 6| Step: 1
Training loss: 2.5140417578240437
Validation loss: 2.563620361170167

Epoch: 6| Step: 2
Training loss: 2.4631850862954137
Validation loss: 2.5711705129425715

Epoch: 6| Step: 3
Training loss: 3.0029295287093456
Validation loss: 2.5700191496594518

Epoch: 6| Step: 4
Training loss: 2.7887872298289156
Validation loss: 2.579196283502165

Epoch: 6| Step: 5
Training loss: 2.5468363378667784
Validation loss: 2.572723417450773

Epoch: 6| Step: 6
Training loss: 2.5542215744845826
Validation loss: 2.5688208335892946

Epoch: 6| Step: 7
Training loss: 2.2654490435444545
Validation loss: 2.5981394994675404

Epoch: 6| Step: 8
Training loss: 1.9856116579043999
Validation loss: 2.587058094393256

Epoch: 6| Step: 9
Training loss: 3.00656490461037
Validation loss: 2.5831852583337263

Epoch: 6| Step: 10
Training loss: 2.5995820443130366
Validation loss: 2.5934729370682037

Epoch: 6| Step: 11
Training loss: 3.1170479879494457
Validation loss: 2.583571628121717

Epoch: 6| Step: 12
Training loss: 2.6410453506961202
Validation loss: 2.570297102026921

Epoch: 6| Step: 13
Training loss: 2.9427030220096335
Validation loss: 2.5885142370314744

Epoch: 12| Step: 0
Training loss: 2.755030366069065
Validation loss: 2.568553318683417

Epoch: 6| Step: 1
Training loss: 1.6700363744554771
Validation loss: 2.563582602593493

Epoch: 6| Step: 2
Training loss: 2.313098933009386
Validation loss: 2.5690093906488833

Epoch: 6| Step: 3
Training loss: 2.7014430110666807
Validation loss: 2.538415335317728

Epoch: 6| Step: 4
Training loss: 2.6238948675529015
Validation loss: 2.5509097975800343

Epoch: 6| Step: 5
Training loss: 2.2795228037127604
Validation loss: 2.560878380121564

Epoch: 6| Step: 6
Training loss: 2.7495087271477465
Validation loss: 2.5602015755437675

Epoch: 6| Step: 7
Training loss: 2.9962072239043582
Validation loss: 2.5542670632109448

Epoch: 6| Step: 8
Training loss: 2.8962785849644423
Validation loss: 2.558486120857672

Epoch: 6| Step: 9
Training loss: 2.5725702729557565
Validation loss: 2.5592211703880543

Epoch: 6| Step: 10
Training loss: 3.242981595147411
Validation loss: 2.5686003481299085

Epoch: 6| Step: 11
Training loss: 2.5797204831727933
Validation loss: 2.5585126635876883

Epoch: 6| Step: 12
Training loss: 2.403829273458046
Validation loss: 2.5579550686087194

Epoch: 6| Step: 13
Training loss: 2.297400797133242
Validation loss: 2.5481429425062356

Epoch: 13| Step: 0
Training loss: 2.5138244819703632
Validation loss: 2.548207860626615

Epoch: 6| Step: 1
Training loss: 3.286047924470071
Validation loss: 2.552454930454631

Epoch: 6| Step: 2
Training loss: 2.532290397925133
Validation loss: 2.5409954675240933

Epoch: 6| Step: 3
Training loss: 1.9871953910746547
Validation loss: 2.559308367223942

Epoch: 6| Step: 4
Training loss: 2.1188073524657196
Validation loss: 2.5348380290245927

Epoch: 6| Step: 5
Training loss: 2.39168430370602
Validation loss: 2.551904373641435

Epoch: 6| Step: 6
Training loss: 2.9612750261117995
Validation loss: 2.53276700216851

Epoch: 6| Step: 7
Training loss: 2.6284649097291077
Validation loss: 2.5496652526795027

Epoch: 6| Step: 8
Training loss: 2.5905857317885346
Validation loss: 2.5450701725247087

Epoch: 6| Step: 9
Training loss: 2.4082542098444257
Validation loss: 2.5567766488038193

Epoch: 6| Step: 10
Training loss: 2.5445709103616836
Validation loss: 2.5665380868865775

Epoch: 6| Step: 11
Training loss: 2.811900520013883
Validation loss: 2.562923303392012

Epoch: 6| Step: 12
Training loss: 2.450002249891844
Validation loss: 2.547078832415084

Epoch: 6| Step: 13
Training loss: 2.807725031896166
Validation loss: 2.5541062155493495

Epoch: 14| Step: 0
Training loss: 2.8374611200702216
Validation loss: 2.5444047489799404

Epoch: 6| Step: 1
Training loss: 2.7159368057258866
Validation loss: 2.5501704981781987

Epoch: 6| Step: 2
Training loss: 2.4244177483066824
Validation loss: 2.5509662804472906

Epoch: 6| Step: 3
Training loss: 2.265932049169312
Validation loss: 2.558300655748588

Epoch: 6| Step: 4
Training loss: 2.4252397359739555
Validation loss: 2.5521062006542214

Epoch: 6| Step: 5
Training loss: 2.41013686112035
Validation loss: 2.5589925285360473

Epoch: 6| Step: 6
Training loss: 2.1831383955419215
Validation loss: 2.5628556725761618

Epoch: 6| Step: 7
Training loss: 3.0777569081149374
Validation loss: 2.563551028184307

Epoch: 6| Step: 8
Training loss: 2.3048515649362673
Validation loss: 2.549319695124331

Epoch: 6| Step: 9
Training loss: 2.8108260365344404
Validation loss: 2.564689925514792

Epoch: 6| Step: 10
Training loss: 2.697630131846668
Validation loss: 2.559269706600269

Epoch: 6| Step: 11
Training loss: 2.864412799729791
Validation loss: 2.544787044471502

Epoch: 6| Step: 12
Training loss: 3.037159772743024
Validation loss: 2.5482887447623623

Epoch: 6| Step: 13
Training loss: 2.0362580990381445
Validation loss: 2.5337383692053677

Epoch: 15| Step: 0
Training loss: 3.095761656583885
Validation loss: 2.5404433188203823

Epoch: 6| Step: 1
Training loss: 2.682109394485168
Validation loss: 2.5435900654295382

Epoch: 6| Step: 2
Training loss: 2.1036801924657778
Validation loss: 2.5346795071235317

Epoch: 6| Step: 3
Training loss: 2.897875955068532
Validation loss: 2.5301527070335337

Epoch: 6| Step: 4
Training loss: 2.288444149096752
Validation loss: 2.5546408677195447

Epoch: 6| Step: 5
Training loss: 2.583439752991431
Validation loss: 2.526948138271539

Epoch: 6| Step: 6
Training loss: 2.2871655620967104
Validation loss: 2.525594145993793

Epoch: 6| Step: 7
Training loss: 2.4899900309045226
Validation loss: 2.5390243292653656

Epoch: 6| Step: 8
Training loss: 3.0683522263801195
Validation loss: 2.537398206613995

Epoch: 6| Step: 9
Training loss: 2.3821504267190137
Validation loss: 2.5314924335943045

Epoch: 6| Step: 10
Training loss: 2.2385703228062606
Validation loss: 2.5396696489627604

Epoch: 6| Step: 11
Training loss: 2.294263743729883
Validation loss: 2.534779242885937

Epoch: 6| Step: 12
Training loss: 2.6193001035060037
Validation loss: 2.5320779521667975

Epoch: 6| Step: 13
Training loss: 2.7644864772300997
Validation loss: 2.539252531325231

Epoch: 16| Step: 0
Training loss: 2.1662540287391985
Validation loss: 2.5468060224744766

Epoch: 6| Step: 1
Training loss: 3.0921925949972238
Validation loss: 2.543331091126953

Epoch: 6| Step: 2
Training loss: 2.5078125
Validation loss: 2.5366359285588427

Epoch: 6| Step: 3
Training loss: 2.0837073816839378
Validation loss: 2.5201480396373603

Epoch: 6| Step: 4
Training loss: 2.400637732653034
Validation loss: 2.526868410921969

Epoch: 6| Step: 5
Training loss: 2.4813995777465827
Validation loss: 2.5271735785069303

Epoch: 6| Step: 6
Training loss: 1.7994547362447268
Validation loss: 2.5307658325059816

Epoch: 6| Step: 7
Training loss: 2.210787063710695
Validation loss: 2.534498053846918

Epoch: 6| Step: 8
Training loss: 3.235540207769978
Validation loss: 2.5364754041114277

Epoch: 6| Step: 9
Training loss: 2.6591665972983902
Validation loss: 2.533600065553008

Epoch: 6| Step: 10
Training loss: 2.347197578295789
Validation loss: 2.5275958494129083

Epoch: 6| Step: 11
Training loss: 3.133486553936942
Validation loss: 2.525881501983129

Epoch: 6| Step: 12
Training loss: 3.224059235324447
Validation loss: 2.535993237058204

Epoch: 6| Step: 13
Training loss: 2.023225397606872
Validation loss: 2.534566018039502

Epoch: 17| Step: 0
Training loss: 2.2176904431850795
Validation loss: 2.535003861293322

Epoch: 6| Step: 1
Training loss: 2.180176820146029
Validation loss: 2.541562271058742

Epoch: 6| Step: 2
Training loss: 2.5741014931446036
Validation loss: 2.5463475186240436

Epoch: 6| Step: 3
Training loss: 2.7050534464126987
Validation loss: 2.5494898301324667

Epoch: 6| Step: 4
Training loss: 2.155631598653009
Validation loss: 2.545720203298081

Epoch: 6| Step: 5
Training loss: 2.2466073419264005
Validation loss: 2.5542418298246212

Epoch: 6| Step: 6
Training loss: 2.2722582298395864
Validation loss: 2.5521708311275604

Epoch: 6| Step: 7
Training loss: 2.452420662035096
Validation loss: 2.5590671557555953

Epoch: 6| Step: 8
Training loss: 2.788758504419427
Validation loss: 2.5505921555161493

Epoch: 6| Step: 9
Training loss: 2.9123336940976334
Validation loss: 2.555171838980035

Epoch: 6| Step: 10
Training loss: 3.086927037994716
Validation loss: 2.5437303097124517

Epoch: 6| Step: 11
Training loss: 2.482391333223311
Validation loss: 2.5265089461470627

Epoch: 6| Step: 12
Training loss: 2.9900747464638604
Validation loss: 2.5338726977421815

Epoch: 6| Step: 13
Training loss: 2.5471191289245962
Validation loss: 2.525426444940141

Epoch: 18| Step: 0
Training loss: 2.4951468090829754
Validation loss: 2.541917754627315

Epoch: 6| Step: 1
Training loss: 1.9786067237479867
Validation loss: 2.544262222593034

Epoch: 6| Step: 2
Training loss: 2.507747375973681
Validation loss: 2.5313439763838095

Epoch: 6| Step: 3
Training loss: 2.918258795564263
Validation loss: 2.5233891406705604

Epoch: 6| Step: 4
Training loss: 3.042751240822258
Validation loss: 2.5244156680664624

Epoch: 6| Step: 5
Training loss: 2.6975748049286854
Validation loss: 2.5269058846621064

Epoch: 6| Step: 6
Training loss: 2.354172484354128
Validation loss: 2.534579203038569

Epoch: 6| Step: 7
Training loss: 2.5552834098683723
Validation loss: 2.533408167218968

Epoch: 6| Step: 8
Training loss: 3.0911999606391163
Validation loss: 2.5151145369762977

Epoch: 6| Step: 9
Training loss: 1.8216147287590037
Validation loss: 2.5222702869964757

Epoch: 6| Step: 10
Training loss: 2.371670245956254
Validation loss: 2.528901631662675

Epoch: 6| Step: 11
Training loss: 2.511443174915829
Validation loss: 2.5272575572044857

Epoch: 6| Step: 12
Training loss: 2.1994188668249635
Validation loss: 2.5226712160758327

Epoch: 6| Step: 13
Training loss: 2.8832484796933993
Validation loss: 2.5109813788425033

Epoch: 19| Step: 0
Training loss: 2.6251349641527177
Validation loss: 2.525152420882301

Epoch: 6| Step: 1
Training loss: 2.595983256199332
Validation loss: 2.5211573516007197

Epoch: 6| Step: 2
Training loss: 2.4204075459090473
Validation loss: 2.5346650136010473

Epoch: 6| Step: 3
Training loss: 2.3516754427430007
Validation loss: 2.5274151610672955

Epoch: 6| Step: 4
Training loss: 2.4525386814251715
Validation loss: 2.522440190660059

Epoch: 6| Step: 5
Training loss: 2.0987998075862833
Validation loss: 2.510737977629606

Epoch: 6| Step: 6
Training loss: 2.4134962288096227
Validation loss: 2.5230179350290216

Epoch: 6| Step: 7
Training loss: 2.537371732730266
Validation loss: 2.5254119927214576

Epoch: 6| Step: 8
Training loss: 2.9399241732206476
Validation loss: 2.529952372051144

Epoch: 6| Step: 9
Training loss: 1.997660579982536
Validation loss: 2.518540053850812

Epoch: 6| Step: 10
Training loss: 2.8851271023841605
Validation loss: 2.5282741054704845

Epoch: 6| Step: 11
Training loss: 2.091028636975265
Validation loss: 2.5238454073713887

Epoch: 6| Step: 12
Training loss: 2.9571865348407194
Validation loss: 2.5240538231238983

Epoch: 6| Step: 13
Training loss: 2.9807301577901293
Validation loss: 2.531404184425707

Epoch: 20| Step: 0
Training loss: 2.8660856619236585
Validation loss: 2.523286387797581

Epoch: 6| Step: 1
Training loss: 2.827136799684596
Validation loss: 2.5345348974070396

Epoch: 6| Step: 2
Training loss: 3.0603175269044414
Validation loss: 2.533146308804908

Epoch: 6| Step: 3
Training loss: 2.6797883929507664
Validation loss: 2.5420860481299816

Epoch: 6| Step: 4
Training loss: 2.3013777421082655
Validation loss: 2.544370328479896

Epoch: 6| Step: 5
Training loss: 3.0945655441406346
Validation loss: 2.5422307206762462

Epoch: 6| Step: 6
Training loss: 1.677641718374186
Validation loss: 2.5415599571298797

Epoch: 6| Step: 7
Training loss: 2.719084269703142
Validation loss: 2.525204019518958

Epoch: 6| Step: 8
Training loss: 2.845835329858425
Validation loss: 2.545834506253619

Epoch: 6| Step: 9
Training loss: 2.4488824008044916
Validation loss: 2.535873390025127

Epoch: 6| Step: 10
Training loss: 1.8005805245030633
Validation loss: 2.532418377770061

Epoch: 6| Step: 11
Training loss: 2.3371123864602232
Validation loss: 2.5166493022605962

Epoch: 6| Step: 12
Training loss: 2.0336875961286336
Validation loss: 2.5160282830587843

Epoch: 6| Step: 13
Training loss: 2.6077707807290538
Validation loss: 2.5183878115229987

Epoch: 21| Step: 0
Training loss: 2.2773680383031563
Validation loss: 2.516396556236705

Epoch: 6| Step: 1
Training loss: 3.1958652009000974
Validation loss: 2.504833571437711

Epoch: 6| Step: 2
Training loss: 2.4080053095077836
Validation loss: 2.5257175250696364

Epoch: 6| Step: 3
Training loss: 2.579839795040093
Validation loss: 2.5384249155660186

Epoch: 6| Step: 4
Training loss: 2.5763226306640497
Validation loss: 2.52981062572376

Epoch: 6| Step: 5
Training loss: 2.8747405888826107
Validation loss: 2.5278721236926063

Epoch: 6| Step: 6
Training loss: 2.4316794518737535
Validation loss: 2.531182119456175

Epoch: 6| Step: 7
Training loss: 2.2224320498056667
Validation loss: 2.529868168669339

Epoch: 6| Step: 8
Training loss: 2.235343029827533
Validation loss: 2.537454019327225

Epoch: 6| Step: 9
Training loss: 2.719743130700208
Validation loss: 2.511755753675186

Epoch: 6| Step: 10
Training loss: 2.2221198482244486
Validation loss: 2.5394153056418713

Epoch: 6| Step: 11
Training loss: 2.8912402348862667
Validation loss: 2.5364645475485084

Epoch: 6| Step: 12
Training loss: 3.0763600512880696
Validation loss: 2.5490204993055117

Epoch: 6| Step: 13
Training loss: 1.4223142511342184
Validation loss: 2.53033528852917

Epoch: 22| Step: 0
Training loss: 3.00109430064148
Validation loss: 2.5147620669867154

Epoch: 6| Step: 1
Training loss: 2.384674445431359
Validation loss: 2.5239907161216455

Epoch: 6| Step: 2
Training loss: 2.6557912991463732
Validation loss: 2.495035686518009

Epoch: 6| Step: 3
Training loss: 2.745978796602698
Validation loss: 2.525151240663273

Epoch: 6| Step: 4
Training loss: 2.7173780290030582
Validation loss: 2.514338146435553

Epoch: 6| Step: 5
Training loss: 2.5870484331254633
Validation loss: 2.495543497373859

Epoch: 6| Step: 6
Training loss: 2.30623902935944
Validation loss: 2.5202637546505664

Epoch: 6| Step: 7
Training loss: 2.3329992282177776
Validation loss: 2.518962076249714

Epoch: 6| Step: 8
Training loss: 2.1774548543636323
Validation loss: 2.5012287458120146

Epoch: 6| Step: 9
Training loss: 2.108335337681879
Validation loss: 2.512278334801594

Epoch: 6| Step: 10
Training loss: 2.8001905853259257
Validation loss: 2.522875090323945

Epoch: 6| Step: 11
Training loss: 2.039606365298513
Validation loss: 2.5220078629888687

Epoch: 6| Step: 12
Training loss: 2.6994405343433314
Validation loss: 2.52364251688696

Epoch: 6| Step: 13
Training loss: 2.63365870610389
Validation loss: 2.5202506130099067

Epoch: 23| Step: 0
Training loss: 2.075923585444556
Validation loss: 2.509428967013948

Epoch: 6| Step: 1
Training loss: 2.530446337052689
Validation loss: 2.5157117650961793

Epoch: 6| Step: 2
Training loss: 2.669870349579401
Validation loss: 2.519268296194281

Epoch: 6| Step: 3
Training loss: 2.3330413317757417
Validation loss: 2.507588583515211

Epoch: 6| Step: 4
Training loss: 1.8382929200508438
Validation loss: 2.5192780517785964

Epoch: 6| Step: 5
Training loss: 2.2088170751329606
Validation loss: 2.520281996742437

Epoch: 6| Step: 6
Training loss: 3.574999914636144
Validation loss: 2.518938729257207

Epoch: 6| Step: 7
Training loss: 2.2178682536287186
Validation loss: 2.5208120318897316

Epoch: 6| Step: 8
Training loss: 2.3423505546914263
Validation loss: 2.522826271317233

Epoch: 6| Step: 9
Training loss: 2.4075725933471515
Validation loss: 2.508922477828543

Epoch: 6| Step: 10
Training loss: 3.283003565562947
Validation loss: 2.5350540838046305

Epoch: 6| Step: 11
Training loss: 2.0425965533553248
Validation loss: 2.53038338162596

Epoch: 6| Step: 12
Training loss: 2.3333149863838774
Validation loss: 2.496595973918382

Epoch: 6| Step: 13
Training loss: 2.8991634148775662
Validation loss: 2.514137388970743

Epoch: 24| Step: 0
Training loss: 2.590851784639697
Validation loss: 2.4943671027835683

Epoch: 6| Step: 1
Training loss: 2.585148348065609
Validation loss: 2.497884491073485

Epoch: 6| Step: 2
Training loss: 1.5824569317831327
Validation loss: 2.5077884946250557

Epoch: 6| Step: 3
Training loss: 2.6061289807222043
Validation loss: 2.518425261559314

Epoch: 6| Step: 4
Training loss: 2.4871793070578048
Validation loss: 2.5103804452480563

Epoch: 6| Step: 5
Training loss: 2.6801184482874234
Validation loss: 2.5080574684484565

Epoch: 6| Step: 6
Training loss: 2.551779862610433
Validation loss: 2.5121161194500563

Epoch: 6| Step: 7
Training loss: 2.4454866292459667
Validation loss: 2.5056391535240525

Epoch: 6| Step: 8
Training loss: 2.1211553462798896
Validation loss: 2.522349277476024

Epoch: 6| Step: 9
Training loss: 2.6180342030574977
Validation loss: 2.503010653623616

Epoch: 6| Step: 10
Training loss: 2.8347252811222456
Validation loss: 2.510826794902477

Epoch: 6| Step: 11
Training loss: 2.3852398625002382
Validation loss: 2.5054006892619536

Epoch: 6| Step: 12
Training loss: 3.1654301454425227
Validation loss: 2.5129138403271356

Epoch: 6| Step: 13
Training loss: 2.3498411246629476
Validation loss: 2.511032382491435

Epoch: 25| Step: 0
Training loss: 2.168080260012295
Validation loss: 2.505818303981509

Epoch: 6| Step: 1
Training loss: 1.8624056952238668
Validation loss: 2.5204125886054736

Epoch: 6| Step: 2
Training loss: 2.698229286806384
Validation loss: 2.5059586245395704

Epoch: 6| Step: 3
Training loss: 2.6986858984723066
Validation loss: 2.515332356998299

Epoch: 6| Step: 4
Training loss: 3.415591249011255
Validation loss: 2.512699281877411

Epoch: 6| Step: 5
Training loss: 2.609258957526846
Validation loss: 2.494528505041259

Epoch: 6| Step: 6
Training loss: 2.976998204659666
Validation loss: 2.5063598640442355

Epoch: 6| Step: 7
Training loss: 2.2849116789528723
Validation loss: 2.5260705900338865

Epoch: 6| Step: 8
Training loss: 3.0377737416436927
Validation loss: 2.506217219391231

Epoch: 6| Step: 9
Training loss: 2.1236738667080384
Validation loss: 2.519164050251566

Epoch: 6| Step: 10
Training loss: 2.73250319582795
Validation loss: 2.4923036203467364

Epoch: 6| Step: 11
Training loss: 2.7231711033562136
Validation loss: 2.5018594025948326

Epoch: 6| Step: 12
Training loss: 1.2547443951810102
Validation loss: 2.507273567577079

Epoch: 6| Step: 13
Training loss: 1.785034041948306
Validation loss: 2.506614335453167

Epoch: 26| Step: 0
Training loss: 1.8483280307474717
Validation loss: 2.5097173663891463

Epoch: 6| Step: 1
Training loss: 2.76815335495001
Validation loss: 2.504280415478255

Epoch: 6| Step: 2
Training loss: 2.7653173932922295
Validation loss: 2.501119283615439

Epoch: 6| Step: 3
Training loss: 2.4380766357694266
Validation loss: 2.5145845650767606

Epoch: 6| Step: 4
Training loss: 2.2961354005611168
Validation loss: 2.5129428963443186

Epoch: 6| Step: 5
Training loss: 2.593947069885426
Validation loss: 2.496543298554282

Epoch: 6| Step: 6
Training loss: 2.5986557493233327
Validation loss: 2.515724843573153

Epoch: 6| Step: 7
Training loss: 2.8602968824792314
Validation loss: 2.507610633782704

Epoch: 6| Step: 8
Training loss: 2.3051883476575767
Validation loss: 2.5053350425817245

Epoch: 6| Step: 9
Training loss: 2.201807372077619
Validation loss: 2.5288499984793806

Epoch: 6| Step: 10
Training loss: 2.2216380490603584
Validation loss: 2.5254769916522277

Epoch: 6| Step: 11
Training loss: 2.818593946649657
Validation loss: 2.530041472857765

Epoch: 6| Step: 12
Training loss: 2.3733733780657915
Validation loss: 2.524005255195439

Epoch: 6| Step: 13
Training loss: 2.8357717082004807
Validation loss: 2.525150752839247

Epoch: 27| Step: 0
Training loss: 2.2404889308840743
Validation loss: 2.531711410728106

Epoch: 6| Step: 1
Training loss: 2.8208661579455487
Validation loss: 2.5276629459116107

Epoch: 6| Step: 2
Training loss: 2.7273209618146637
Validation loss: 2.5212793244683493

Epoch: 6| Step: 3
Training loss: 2.225686848098982
Validation loss: 2.5169843235338516

Epoch: 6| Step: 4
Training loss: 2.0489243592970556
Validation loss: 2.511883150359421

Epoch: 6| Step: 5
Training loss: 2.685760644901034
Validation loss: 2.4955256954453118

Epoch: 6| Step: 6
Training loss: 2.8105846240787105
Validation loss: 2.486284965306349

Epoch: 6| Step: 7
Training loss: 2.1030648119449307
Validation loss: 2.5017581161906643

Epoch: 6| Step: 8
Training loss: 3.4374711468959545
Validation loss: 2.4958960067275884

Epoch: 6| Step: 9
Training loss: 3.1827728523702654
Validation loss: 2.5035476150012426

Epoch: 6| Step: 10
Training loss: 2.609517716028407
Validation loss: 2.508631983326765

Epoch: 6| Step: 11
Training loss: 1.4959610763167799
Validation loss: 2.50472916893458

Epoch: 6| Step: 12
Training loss: 1.8979963253094199
Validation loss: 2.511872867742467

Epoch: 6| Step: 13
Training loss: 2.2972098385426967
Validation loss: 2.517525383569712

Epoch: 28| Step: 0
Training loss: 2.4330514269880132
Validation loss: 2.489100095437437

Epoch: 6| Step: 1
Training loss: 1.87395346363305
Validation loss: 2.4995615097782973

Epoch: 6| Step: 2
Training loss: 3.4911975524218937
Validation loss: 2.4992002797534867

Epoch: 6| Step: 3
Training loss: 2.502416301322242
Validation loss: 2.524733140900163

Epoch: 6| Step: 4
Training loss: 1.4544753496658664
Validation loss: 2.5270187742871584

Epoch: 6| Step: 5
Training loss: 2.6311694715051637
Validation loss: 2.5263596534493784

Epoch: 6| Step: 6
Training loss: 2.4098249359178023
Validation loss: 2.5388447673069923

Epoch: 6| Step: 7
Training loss: 2.79243534569954
Validation loss: 2.519142203641785

Epoch: 6| Step: 8
Training loss: 2.7681220899072656
Validation loss: 2.504823672344412

Epoch: 6| Step: 9
Training loss: 1.9772264172224077
Validation loss: 2.519255677759182

Epoch: 6| Step: 10
Training loss: 2.348085284898628
Validation loss: 2.5087732631591235

Epoch: 6| Step: 11
Training loss: 2.8371497051445584
Validation loss: 2.4934905421534888

Epoch: 6| Step: 12
Training loss: 2.370583795198941
Validation loss: 2.5117041160746503

Epoch: 6| Step: 13
Training loss: 2.6248137998390826
Validation loss: 2.509125252057476

Epoch: 29| Step: 0
Training loss: 2.5830390106220826
Validation loss: 2.5262712328441808

Epoch: 6| Step: 1
Training loss: 1.7789611164623267
Validation loss: 2.5060709355821342

Epoch: 6| Step: 2
Training loss: 2.0062335147358628
Validation loss: 2.530597021705561

Epoch: 6| Step: 3
Training loss: 2.367083455937248
Validation loss: 2.5185586791976333

Epoch: 6| Step: 4
Training loss: 2.586984935119436
Validation loss: 2.5118155216067026

Epoch: 6| Step: 5
Training loss: 2.1540247173750684
Validation loss: 2.5009129128976797

Epoch: 6| Step: 6
Training loss: 2.67381260980935
Validation loss: 2.5002790613190804

Epoch: 6| Step: 7
Training loss: 2.8903547830836835
Validation loss: 2.5157978796148197

Epoch: 6| Step: 8
Training loss: 1.9410030936521612
Validation loss: 2.5198286723751844

Epoch: 6| Step: 9
Training loss: 2.6658508026259784
Validation loss: 2.5140399875743267

Epoch: 6| Step: 10
Training loss: 2.3199135793835306
Validation loss: 2.515170891569805

Epoch: 6| Step: 11
Training loss: 2.5112721949460943
Validation loss: 2.528004563350623

Epoch: 6| Step: 12
Training loss: 2.1982401267829634
Validation loss: 2.4987305915184357

Epoch: 6| Step: 13
Training loss: 3.725103512548238
Validation loss: 2.505504334239399

Epoch: 30| Step: 0
Training loss: 3.188459364186006
Validation loss: 2.5149750274621696

Epoch: 6| Step: 1
Training loss: 2.451135885878725
Validation loss: 2.4967510728951847

Epoch: 6| Step: 2
Training loss: 2.2015992420777413
Validation loss: 2.499429184597444

Epoch: 6| Step: 3
Training loss: 2.411105323038415
Validation loss: 2.509228505648248

Epoch: 6| Step: 4
Training loss: 2.595248605216074
Validation loss: 2.5019528391210315

Epoch: 6| Step: 5
Training loss: 2.2918170070462915
Validation loss: 2.5018957420834242

Epoch: 6| Step: 6
Training loss: 2.864245659548459
Validation loss: 2.4825404529278425

Epoch: 6| Step: 7
Training loss: 2.5706426993924016
Validation loss: 2.4995639023298737

Epoch: 6| Step: 8
Training loss: 2.133335817852163
Validation loss: 2.5164302382243164

Epoch: 6| Step: 9
Training loss: 1.895670691699486
Validation loss: 2.4925945591311325

Epoch: 6| Step: 10
Training loss: 2.460593063228627
Validation loss: 2.4927740572724097

Epoch: 6| Step: 11
Training loss: 2.8778889280707154
Validation loss: 2.4991984035931325

Epoch: 6| Step: 12
Training loss: 1.673414288243182
Validation loss: 2.5086168245157023

Epoch: 6| Step: 13
Training loss: 3.0667172413954105
Validation loss: 2.501399745090368

Epoch: 31| Step: 0
Training loss: 2.579582403527151
Validation loss: 2.495263157983527

Epoch: 6| Step: 1
Training loss: 2.25307910888327
Validation loss: 2.492458978453768

Epoch: 6| Step: 2
Training loss: 2.5689881226000364
Validation loss: 2.506456676088697

Epoch: 6| Step: 3
Training loss: 2.6029664796186975
Validation loss: 2.50667837133448

Epoch: 6| Step: 4
Training loss: 2.8132446151081165
Validation loss: 2.5222641113301916

Epoch: 6| Step: 5
Training loss: 2.737792925207887
Validation loss: 2.526103875616613

Epoch: 6| Step: 6
Training loss: 2.5759171713550186
Validation loss: 2.5149956146869386

Epoch: 6| Step: 7
Training loss: 2.8200406183875204
Validation loss: 2.532505587401884

Epoch: 6| Step: 8
Training loss: 2.623671422529589
Validation loss: 2.5307685252853793

Epoch: 6| Step: 9
Training loss: 2.2065813804502667
Validation loss: 2.537002815747732

Epoch: 6| Step: 10
Training loss: 2.5266237722125973
Validation loss: 2.527438437620511

Epoch: 6| Step: 11
Training loss: 2.0731438619303586
Validation loss: 2.5337677980439928

Epoch: 6| Step: 12
Training loss: 2.275595672929726
Validation loss: 2.5075013392512355

Epoch: 6| Step: 13
Training loss: 2.0789921607694954
Validation loss: 2.509455909865616

Epoch: 32| Step: 0
Training loss: 2.60279006177061
Validation loss: 2.535557594133654

Epoch: 6| Step: 1
Training loss: 2.212149028634856
Validation loss: 2.5363285937539675

Epoch: 6| Step: 2
Training loss: 2.327158067869813
Validation loss: 2.5022741464682188

Epoch: 6| Step: 3
Training loss: 1.923151476221877
Validation loss: 2.5091462198482444

Epoch: 6| Step: 4
Training loss: 2.3989116187660766
Validation loss: 2.501520314477435

Epoch: 6| Step: 5
Training loss: 2.5419616111179693
Validation loss: 2.501622865366703

Epoch: 6| Step: 6
Training loss: 3.0862360170093193
Validation loss: 2.5204141178918067

Epoch: 6| Step: 7
Training loss: 2.748067523632001
Validation loss: 2.4910621214805246

Epoch: 6| Step: 8
Training loss: 2.6569848334439863
Validation loss: 2.5078391512428118

Epoch: 6| Step: 9
Training loss: 1.9704869797341051
Validation loss: 2.4944637032576997

Epoch: 6| Step: 10
Training loss: 2.818250837767358
Validation loss: 2.50478372656727

Epoch: 6| Step: 11
Training loss: 2.598656666792055
Validation loss: 2.4918159758019165

Epoch: 6| Step: 12
Training loss: 2.147058550721673
Validation loss: 2.507174893111009

Epoch: 6| Step: 13
Training loss: 2.3092890949299534
Validation loss: 2.505359309373271

Epoch: 33| Step: 0
Training loss: 2.7927616496097123
Validation loss: 2.5178685894995483

Epoch: 6| Step: 1
Training loss: 2.407374329896704
Validation loss: 2.4897568986689045

Epoch: 6| Step: 2
Training loss: 2.9076129629637815
Validation loss: 2.4802940647561105

Epoch: 6| Step: 3
Training loss: 2.5520752783408174
Validation loss: 2.5049728843353356

Epoch: 6| Step: 4
Training loss: 2.0225903715070648
Validation loss: 2.4974478092029035

Epoch: 6| Step: 5
Training loss: 2.412038800523726
Validation loss: 2.5034112386437557

Epoch: 6| Step: 6
Training loss: 1.8816228883559494
Validation loss: 2.502621420735646

Epoch: 6| Step: 7
Training loss: 2.952942857726186
Validation loss: 2.5078954316525883

Epoch: 6| Step: 8
Training loss: 2.7891636250432503
Validation loss: 2.5154892073285833

Epoch: 6| Step: 9
Training loss: 2.6907951203727456
Validation loss: 2.5053161048046393

Epoch: 6| Step: 10
Training loss: 2.4082898497918293
Validation loss: 2.511426466670178

Epoch: 6| Step: 11
Training loss: 1.651245257062547
Validation loss: 2.5012123823919574

Epoch: 6| Step: 12
Training loss: 1.666343880231526
Validation loss: 2.531316293232933

Epoch: 6| Step: 13
Training loss: 2.990741111231325
Validation loss: 2.5109256502768784

Epoch: 34| Step: 0
Training loss: 2.926670973071476
Validation loss: 2.526459929979869

Epoch: 6| Step: 1
Training loss: 2.41092811726038
Validation loss: 2.5049995499265956

Epoch: 6| Step: 2
Training loss: 2.107523692078193
Validation loss: 2.5235223273633736

Epoch: 6| Step: 3
Training loss: 2.144403394768491
Validation loss: 2.5166064099388623

Epoch: 6| Step: 4
Training loss: 2.5756404117381395
Validation loss: 2.5246085017649045

Epoch: 6| Step: 5
Training loss: 2.6999548696348956
Validation loss: 2.5121983475159686

Epoch: 6| Step: 6
Training loss: 2.7062772331012845
Validation loss: 2.5029856814103058

Epoch: 6| Step: 7
Training loss: 2.373858729760443
Validation loss: 2.5051161550163905

Epoch: 6| Step: 8
Training loss: 2.7461483598599643
Validation loss: 2.507020930364776

Epoch: 6| Step: 9
Training loss: 2.6823901013333615
Validation loss: 2.4987069282680667

Epoch: 6| Step: 10
Training loss: 1.8019499389435036
Validation loss: 2.4849097997821543

Epoch: 6| Step: 11
Training loss: 2.5019050968750856
Validation loss: 2.4946479251574867

Epoch: 6| Step: 12
Training loss: 2.108177240596956
Validation loss: 2.490502332843923

Epoch: 6| Step: 13
Training loss: 2.6825315102808953
Validation loss: 2.4865340441995274

Epoch: 35| Step: 0
Training loss: 1.8069637854978804
Validation loss: 2.4961120572958495

Epoch: 6| Step: 1
Training loss: 3.447376005226458
Validation loss: 2.491062137432126

Epoch: 6| Step: 2
Training loss: 2.675741688233997
Validation loss: 2.5060742494980457

Epoch: 6| Step: 3
Training loss: 2.3756217142798453
Validation loss: 2.4965517900349967

Epoch: 6| Step: 4
Training loss: 2.7637882491233716
Validation loss: 2.5092507236184867

Epoch: 6| Step: 5
Training loss: 2.737591840344369
Validation loss: 2.5113292844999786

Epoch: 6| Step: 6
Training loss: 2.2056688272689393
Validation loss: 2.5183597019345836

Epoch: 6| Step: 7
Training loss: 2.30242042892756
Validation loss: 2.514673483517058

Epoch: 6| Step: 8
Training loss: 1.772257878885878
Validation loss: 2.515706623719766

Epoch: 6| Step: 9
Training loss: 2.0871790930505427
Validation loss: 2.5485873170712656

Epoch: 6| Step: 10
Training loss: 2.0823623937821405
Validation loss: 2.549758784098748

Epoch: 6| Step: 11
Training loss: 2.6627781252594724
Validation loss: 2.552452221634044

Epoch: 6| Step: 12
Training loss: 2.4918833579905626
Validation loss: 2.548595432460787

Epoch: 6| Step: 13
Training loss: 2.6521387035006674
Validation loss: 2.532155648055147

Epoch: 36| Step: 0
Training loss: 2.265204870798545
Validation loss: 2.542140452725871

Epoch: 6| Step: 1
Training loss: 1.7102829887510804
Validation loss: 2.54065770827694

Epoch: 6| Step: 2
Training loss: 2.3000068332736467
Validation loss: 2.5392054825651473

Epoch: 6| Step: 3
Training loss: 2.9066695043859134
Validation loss: 2.504313768540003

Epoch: 6| Step: 4
Training loss: 2.3482945442470644
Validation loss: 2.510189336294907

Epoch: 6| Step: 5
Training loss: 2.564761396765568
Validation loss: 2.514202481820687

Epoch: 6| Step: 6
Training loss: 2.226614754046926
Validation loss: 2.504851830720315

Epoch: 6| Step: 7
Training loss: 2.190518721370981
Validation loss: 2.495620961353586

Epoch: 6| Step: 8
Training loss: 2.5232744193747916
Validation loss: 2.4921597406481615

Epoch: 6| Step: 9
Training loss: 2.8172428407062715
Validation loss: 2.4862799069188286

Epoch: 6| Step: 10
Training loss: 2.9557940012449126
Validation loss: 2.4932587811430054

Epoch: 6| Step: 11
Training loss: 2.6707054389250615
Validation loss: 2.498240169376905

Epoch: 6| Step: 12
Training loss: 2.2402597041805876
Validation loss: 2.492603693762555

Epoch: 6| Step: 13
Training loss: 2.424578136441363
Validation loss: 2.509125473772192

Epoch: 37| Step: 0
Training loss: 2.790990852048473
Validation loss: 2.500957925377772

Epoch: 6| Step: 1
Training loss: 2.6280819194224736
Validation loss: 2.498685443496516

Epoch: 6| Step: 2
Training loss: 2.070883618159393
Validation loss: 2.4942880545596693

Epoch: 6| Step: 3
Training loss: 2.1096087290936594
Validation loss: 2.4957798943081753

Epoch: 6| Step: 4
Training loss: 1.919434649560095
Validation loss: 2.4876772448397335

Epoch: 6| Step: 5
Training loss: 2.1495290861502223
Validation loss: 2.4921994502977878

Epoch: 6| Step: 6
Training loss: 2.347711800475007
Validation loss: 2.4926398015328957

Epoch: 6| Step: 7
Training loss: 2.5658086490300676
Validation loss: 2.503090601131883

Epoch: 6| Step: 8
Training loss: 2.0793308975500624
Validation loss: 2.517901028724433

Epoch: 6| Step: 9
Training loss: 2.6082898470470064
Validation loss: 2.5178964126111496

Epoch: 6| Step: 10
Training loss: 3.3639991339683553
Validation loss: 2.5305305997099743

Epoch: 6| Step: 11
Training loss: 2.6751489045241863
Validation loss: 2.5201171982220303

Epoch: 6| Step: 12
Training loss: 1.9520757069094379
Validation loss: 2.5413380446899043

Epoch: 6| Step: 13
Training loss: 2.5677302877378705
Validation loss: 2.5235780848029363

Epoch: 38| Step: 0
Training loss: 2.239152615551245
Validation loss: 2.5041630574061258

Epoch: 6| Step: 1
Training loss: 2.389571512509558
Validation loss: 2.5253110215655945

Epoch: 6| Step: 2
Training loss: 2.4903718558863495
Validation loss: 2.5053232183834213

Epoch: 6| Step: 3
Training loss: 2.801798147746867
Validation loss: 2.5126670522493004

Epoch: 6| Step: 4
Training loss: 2.7123837529600294
Validation loss: 2.498908742518881

Epoch: 6| Step: 5
Training loss: 2.159275641135952
Validation loss: 2.500568849695457

Epoch: 6| Step: 6
Training loss: 1.6781296713993117
Validation loss: 2.4885027520857737

Epoch: 6| Step: 7
Training loss: 2.5048784341457835
Validation loss: 2.50386925728024

Epoch: 6| Step: 8
Training loss: 2.5765433343714683
Validation loss: 2.4883277844799165

Epoch: 6| Step: 9
Training loss: 1.6034052970000299
Validation loss: 2.492602737258216

Epoch: 6| Step: 10
Training loss: 2.601916039991029
Validation loss: 2.504198665276931

Epoch: 6| Step: 11
Training loss: 2.911376042075984
Validation loss: 2.4892164994896246

Epoch: 6| Step: 12
Training loss: 2.79811656821972
Validation loss: 2.5094064022520577

Epoch: 6| Step: 13
Training loss: 2.517937681152616
Validation loss: 2.507475484700925

Epoch: 39| Step: 0
Training loss: 2.5837479740572267
Validation loss: 2.504043011989603

Epoch: 6| Step: 1
Training loss: 2.0584069299346233
Validation loss: 2.5107679688455358

Epoch: 6| Step: 2
Training loss: 1.7233580113580258
Validation loss: 2.4835209048134845

Epoch: 6| Step: 3
Training loss: 2.3135567389942913
Validation loss: 2.507133922889616

Epoch: 6| Step: 4
Training loss: 1.9070724214065657
Validation loss: 2.492605734303918

Epoch: 6| Step: 5
Training loss: 2.6473852897482617
Validation loss: 2.5050600025150627

Epoch: 6| Step: 6
Training loss: 2.3540832594778185
Validation loss: 2.5190661964693826

Epoch: 6| Step: 7
Training loss: 2.7908555365979923
Validation loss: 2.5084811672948177

Epoch: 6| Step: 8
Training loss: 2.8257038016195724
Validation loss: 2.513558978766654

Epoch: 6| Step: 9
Training loss: 2.4718648840387387
Validation loss: 2.504358053484057

Epoch: 6| Step: 10
Training loss: 2.8582661464198065
Validation loss: 2.535341402021768

Epoch: 6| Step: 11
Training loss: 3.099135518284633
Validation loss: 2.513060864276305

Epoch: 6| Step: 12
Training loss: 1.928154154700853
Validation loss: 2.516133195869949

Epoch: 6| Step: 13
Training loss: 2.4127742947410726
Validation loss: 2.4901580200457105

Epoch: 40| Step: 0
Training loss: 2.1188579880643217
Validation loss: 2.505206012262127

Epoch: 6| Step: 1
Training loss: 2.2850620348166055
Validation loss: 2.499710415916607

Epoch: 6| Step: 2
Training loss: 3.1501965779319643
Validation loss: 2.4884288989565992

Epoch: 6| Step: 3
Training loss: 2.6939748789657516
Validation loss: 2.503500109508551

Epoch: 6| Step: 4
Training loss: 3.2641509165094544
Validation loss: 2.5015412824732857

Epoch: 6| Step: 5
Training loss: 1.7333234743913846
Validation loss: 2.4955746584046303

Epoch: 6| Step: 6
Training loss: 3.01791595246902
Validation loss: 2.498106541441738

Epoch: 6| Step: 7
Training loss: 2.9360412871656636
Validation loss: 2.499424295895574

Epoch: 6| Step: 8
Training loss: 1.513732908925752
Validation loss: 2.487072134360737

Epoch: 6| Step: 9
Training loss: 1.9601688170229747
Validation loss: 2.487207521403627

Epoch: 6| Step: 10
Training loss: 2.2321423666817264
Validation loss: 2.5015930345471853

Epoch: 6| Step: 11
Training loss: 1.985629008393869
Validation loss: 2.5029975245889373

Epoch: 6| Step: 12
Training loss: 2.6640105927631916
Validation loss: 2.490456006528299

Epoch: 6| Step: 13
Training loss: 2.1298776632646375
Validation loss: 2.4837905548220007

Epoch: 41| Step: 0
Training loss: 2.6146284203359036
Validation loss: 2.497443990604405

Epoch: 6| Step: 1
Training loss: 2.661816318471515
Validation loss: 2.5051886755369654

Epoch: 6| Step: 2
Training loss: 2.312800619844547
Validation loss: 2.5103008881986586

Epoch: 6| Step: 3
Training loss: 3.0921188832631294
Validation loss: 2.5321709641113586

Epoch: 6| Step: 4
Training loss: 1.290547296064548
Validation loss: 2.532945504639082

Epoch: 6| Step: 5
Training loss: 2.329555609568857
Validation loss: 2.4979509459989084

Epoch: 6| Step: 6
Training loss: 1.834723797833657
Validation loss: 2.5315646851144087

Epoch: 6| Step: 7
Training loss: 2.0574799914215687
Validation loss: 2.5073532365297893

Epoch: 6| Step: 8
Training loss: 2.939657190279558
Validation loss: 2.519775560150668

Epoch: 6| Step: 9
Training loss: 2.2047708194163635
Validation loss: 2.5187264983261604

Epoch: 6| Step: 10
Training loss: 2.2238989173641235
Validation loss: 2.4928594817328724

Epoch: 6| Step: 11
Training loss: 2.5100702598130593
Validation loss: 2.5147691775473477

Epoch: 6| Step: 12
Training loss: 2.326399502959323
Validation loss: 2.50837864333214

Epoch: 6| Step: 13
Training loss: 3.3164063937812838
Validation loss: 2.5185797104486705

Epoch: 42| Step: 0
Training loss: 2.8088740393323888
Validation loss: 2.5158952682350146

Epoch: 6| Step: 1
Training loss: 2.504010226609672
Validation loss: 2.4924858815498925

Epoch: 6| Step: 2
Training loss: 1.823852240851753
Validation loss: 2.4999551133258784

Epoch: 6| Step: 3
Training loss: 2.514138487431505
Validation loss: 2.47931776200732

Epoch: 6| Step: 4
Training loss: 2.849138457597581
Validation loss: 2.494282287541618

Epoch: 6| Step: 5
Training loss: 2.872111984619901
Validation loss: 2.5007548146398393

Epoch: 6| Step: 6
Training loss: 2.227227790888782
Validation loss: 2.479689780644676

Epoch: 6| Step: 7
Training loss: 1.9769643744431469
Validation loss: 2.5151207301977574

Epoch: 6| Step: 8
Training loss: 2.3767848084535967
Validation loss: 2.499926565999126

Epoch: 6| Step: 9
Training loss: 2.6657711154473884
Validation loss: 2.494878434256495

Epoch: 6| Step: 10
Training loss: 2.200026477307601
Validation loss: 2.4913953121978327

Epoch: 6| Step: 11
Training loss: 2.026213284818193
Validation loss: 2.490123168855787

Epoch: 6| Step: 12
Training loss: 2.9809046835212243
Validation loss: 2.4881724798442213

Epoch: 6| Step: 13
Training loss: 2.2730503866952274
Validation loss: 2.497138101898085

Epoch: 43| Step: 0
Training loss: 2.5637948091144476
Validation loss: 2.5100813255205354

Epoch: 6| Step: 1
Training loss: 2.3119681494211783
Validation loss: 2.4866752452122833

Epoch: 6| Step: 2
Training loss: 2.6171658187651383
Validation loss: 2.507236434355647

Epoch: 6| Step: 3
Training loss: 2.016865429922024
Validation loss: 2.5026382353994605

Epoch: 6| Step: 4
Training loss: 2.13494207799453
Validation loss: 2.47734874033919

Epoch: 6| Step: 5
Training loss: 2.103503610617384
Validation loss: 2.5005549768522872

Epoch: 6| Step: 6
Training loss: 2.3086125458599276
Validation loss: 2.5277050768233544

Epoch: 6| Step: 7
Training loss: 1.9612052096424315
Validation loss: 2.5341041705591505

Epoch: 6| Step: 8
Training loss: 2.3692140874456404
Validation loss: 2.5593453194027114

Epoch: 6| Step: 9
Training loss: 2.0442092659460616
Validation loss: 2.564185386872868

Epoch: 6| Step: 10
Training loss: 2.9868058295980178
Validation loss: 2.5671141106456505

Epoch: 6| Step: 11
Training loss: 2.9870057020308556
Validation loss: 2.5542629250771314

Epoch: 6| Step: 12
Training loss: 2.2250103810957573
Validation loss: 2.5411158783097005

Epoch: 6| Step: 13
Training loss: 3.0685256534154877
Validation loss: 2.559133753198978

Epoch: 44| Step: 0
Training loss: 2.1170047244747674
Validation loss: 2.5350590840563814

Epoch: 6| Step: 1
Training loss: 2.9862567501383035
Validation loss: 2.515693426682437

Epoch: 6| Step: 2
Training loss: 2.2140114917680873
Validation loss: 2.51035887043587

Epoch: 6| Step: 3
Training loss: 2.195931995450633
Validation loss: 2.485444228687503

Epoch: 6| Step: 4
Training loss: 2.823098874751346
Validation loss: 2.490130397645439

Epoch: 6| Step: 5
Training loss: 1.9959998062034314
Validation loss: 2.477828303018205

Epoch: 6| Step: 6
Training loss: 2.245089152037875
Validation loss: 2.500114851538664

Epoch: 6| Step: 7
Training loss: 2.7427882218500637
Validation loss: 2.493320649934152

Epoch: 6| Step: 8
Training loss: 2.4993961558647353
Validation loss: 2.5051660249961483

Epoch: 6| Step: 9
Training loss: 2.1419773702699416
Validation loss: 2.5140755661932492

Epoch: 6| Step: 10
Training loss: 2.885889742156106
Validation loss: 2.486788570963074

Epoch: 6| Step: 11
Training loss: 2.611384092314647
Validation loss: 2.497225493401957

Epoch: 6| Step: 12
Training loss: 2.476497420650243
Validation loss: 2.4882890590383497

Epoch: 6| Step: 13
Training loss: 2.5930998573362323
Validation loss: 2.499294308562354

Epoch: 45| Step: 0
Training loss: 2.5902438077724677
Validation loss: 2.4910806970510158

Epoch: 6| Step: 1
Training loss: 2.7386700711933334
Validation loss: 2.485356279030192

Epoch: 6| Step: 2
Training loss: 2.6455710774204486
Validation loss: 2.496198402244648

Epoch: 6| Step: 3
Training loss: 1.9845934770116505
Validation loss: 2.4949190323610737

Epoch: 6| Step: 4
Training loss: 1.6083152022188034
Validation loss: 2.510621586161755

Epoch: 6| Step: 5
Training loss: 2.708115397756964
Validation loss: 2.483074927700104

Epoch: 6| Step: 6
Training loss: 2.667495439806171
Validation loss: 2.525650109425308

Epoch: 6| Step: 7
Training loss: 1.8482301236165777
Validation loss: 2.520956735244

Epoch: 6| Step: 8
Training loss: 2.1268253340570573
Validation loss: 2.5359105191584717

Epoch: 6| Step: 9
Training loss: 2.1280630139077434
Validation loss: 2.532700990092686

Epoch: 6| Step: 10
Training loss: 2.7225278717379804
Validation loss: 2.5147778445035076

Epoch: 6| Step: 11
Training loss: 3.048868319572089
Validation loss: 2.5227409952640785

Epoch: 6| Step: 12
Training loss: 2.018330023101604
Validation loss: 2.5283922774808234

Epoch: 6| Step: 13
Training loss: 2.459410566099447
Validation loss: 2.5262373832049083

Epoch: 46| Step: 0
Training loss: 1.9697181501005598
Validation loss: 2.528805325340216

Epoch: 6| Step: 1
Training loss: 1.8096439616269226
Validation loss: 2.5431066847746613

Epoch: 6| Step: 2
Training loss: 2.755068356588471
Validation loss: 2.553804748640401

Epoch: 6| Step: 3
Training loss: 2.632159234114481
Validation loss: 2.524712160908174

Epoch: 6| Step: 4
Training loss: 2.8912027967189315
Validation loss: 2.5360921690745184

Epoch: 6| Step: 5
Training loss: 2.878136955178414
Validation loss: 2.5129596656641917

Epoch: 6| Step: 6
Training loss: 2.7282811735181696
Validation loss: 2.5272363308734285

Epoch: 6| Step: 7
Training loss: 2.1975067142041156
Validation loss: 2.5174119814121223

Epoch: 6| Step: 8
Training loss: 3.273333782291835
Validation loss: 2.5029085961885893

Epoch: 6| Step: 9
Training loss: 1.9470624291590146
Validation loss: 2.5066120526733937

Epoch: 6| Step: 10
Training loss: 1.4580810691994839
Validation loss: 2.4866841299331854

Epoch: 6| Step: 11
Training loss: 2.50678001374123
Validation loss: 2.493337854030237

Epoch: 6| Step: 12
Training loss: 1.7838495927366846
Validation loss: 2.489869174482345

Epoch: 6| Step: 13
Training loss: 2.5239589849123005
Validation loss: 2.482076993606187

Epoch: 47| Step: 0
Training loss: 3.0145875401303868
Validation loss: 2.47954888696536

Epoch: 6| Step: 1
Training loss: 2.2343451224510287
Validation loss: 2.486598077838893

Epoch: 6| Step: 2
Training loss: 2.3273240318116106
Validation loss: 2.4965509464590103

Epoch: 6| Step: 3
Training loss: 1.8931848519940095
Validation loss: 2.4831002121725176

Epoch: 6| Step: 4
Training loss: 2.706826558706874
Validation loss: 2.484295937741617

Epoch: 6| Step: 5
Training loss: 2.420214077331744
Validation loss: 2.488745501859219

Epoch: 6| Step: 6
Training loss: 1.8930522376025423
Validation loss: 2.4891507452587667

Epoch: 6| Step: 7
Training loss: 2.8917755311670112
Validation loss: 2.480729697611387

Epoch: 6| Step: 8
Training loss: 2.033244635518257
Validation loss: 2.4823247578910204

Epoch: 6| Step: 9
Training loss: 2.477004243461291
Validation loss: 2.488002807432637

Epoch: 6| Step: 10
Training loss: 2.6167906502995453
Validation loss: 2.484397488218369

Epoch: 6| Step: 11
Training loss: 2.348901504088544
Validation loss: 2.5175260543864018

Epoch: 6| Step: 12
Training loss: 2.565750014945079
Validation loss: 2.4957738441505954

Epoch: 6| Step: 13
Training loss: 2.2493126137093293
Validation loss: 2.4980666314149857

Epoch: 48| Step: 0
Training loss: 3.0244572617596117
Validation loss: 2.5116656640406654

Epoch: 6| Step: 1
Training loss: 1.7783298314115776
Validation loss: 2.5247624779709645

Epoch: 6| Step: 2
Training loss: 1.8124201526812074
Validation loss: 2.548048252337509

Epoch: 6| Step: 3
Training loss: 2.5218693729607295
Validation loss: 2.5299575001837287

Epoch: 6| Step: 4
Training loss: 2.09963356181563
Validation loss: 2.5494953242027956

Epoch: 6| Step: 5
Training loss: 2.4732327866317227
Validation loss: 2.5533659119017487

Epoch: 6| Step: 6
Training loss: 2.4460771723977137
Validation loss: 2.532035658613897

Epoch: 6| Step: 7
Training loss: 2.273292982614042
Validation loss: 2.5364187395476905

Epoch: 6| Step: 8
Training loss: 2.300135575320715
Validation loss: 2.5335504023721267

Epoch: 6| Step: 9
Training loss: 3.052304326064748
Validation loss: 2.5324245286737663

Epoch: 6| Step: 10
Training loss: 1.8372700501927324
Validation loss: 2.510355158536429

Epoch: 6| Step: 11
Training loss: 2.1691843834572513
Validation loss: 2.5261286900792386

Epoch: 6| Step: 12
Training loss: 3.030344247682175
Validation loss: 2.5184786073736554

Epoch: 6| Step: 13
Training loss: 2.5264158830347574
Validation loss: 2.510662721048713

Epoch: 49| Step: 0
Training loss: 2.9677882192581864
Validation loss: 2.4932860182626326

Epoch: 6| Step: 1
Training loss: 2.522732568308828
Validation loss: 2.5012218668339066

Epoch: 6| Step: 2
Training loss: 2.4757702640327017
Validation loss: 2.492603167685214

Epoch: 6| Step: 3
Training loss: 1.978629317034372
Validation loss: 2.4887728682035295

Epoch: 6| Step: 4
Training loss: 2.293113482974792
Validation loss: 2.513442741646906

Epoch: 6| Step: 5
Training loss: 2.3618250372135297
Validation loss: 2.4783594810254055

Epoch: 6| Step: 6
Training loss: 2.254781833930242
Validation loss: 2.4855301128971115

Epoch: 6| Step: 7
Training loss: 2.5171552470134095
Validation loss: 2.4640830146162958

Epoch: 6| Step: 8
Training loss: 2.663074657051191
Validation loss: 2.4651590378392454

Epoch: 6| Step: 9
Training loss: 2.1306989209037788
Validation loss: 2.4876632841311204

Epoch: 6| Step: 10
Training loss: 1.8093852541934377
Validation loss: 2.4712079362982844

Epoch: 6| Step: 11
Training loss: 2.4581025764224322
Validation loss: 2.487348029192505

Epoch: 6| Step: 12
Training loss: 2.595510046489557
Validation loss: 2.485818855208528

Epoch: 6| Step: 13
Training loss: 2.5795014377271297
Validation loss: 2.498964238183022

Epoch: 50| Step: 0
Training loss: 2.037107268320459
Validation loss: 2.4788829951052627

Epoch: 6| Step: 1
Training loss: 2.1922414347511423
Validation loss: 2.4948201240928727

Epoch: 6| Step: 2
Training loss: 2.157534120186016
Validation loss: 2.5072402301156376

Epoch: 6| Step: 3
Training loss: 2.5182152911766824
Validation loss: 2.523299702601227

Epoch: 6| Step: 4
Training loss: 2.1581265673285084
Validation loss: 2.51836782006012

Epoch: 6| Step: 5
Training loss: 2.535685573622563
Validation loss: 2.526364859653772

Epoch: 6| Step: 6
Training loss: 2.754171242375884
Validation loss: 2.5312690891126914

Epoch: 6| Step: 7
Training loss: 2.320095064912102
Validation loss: 2.530628300679809

Epoch: 6| Step: 8
Training loss: 2.176044112648935
Validation loss: 2.524943647290871

Epoch: 6| Step: 9
Training loss: 2.243330076233236
Validation loss: 2.4948661623180794

Epoch: 6| Step: 10
Training loss: 2.0637837662871754
Validation loss: 2.4984191823879907

Epoch: 6| Step: 11
Training loss: 3.1369335438307653
Validation loss: 2.5048066661184345

Epoch: 6| Step: 12
Training loss: 2.0004467465216225
Validation loss: 2.5114025986851645

Epoch: 6| Step: 13
Training loss: 2.970987701328929
Validation loss: 2.5032059934595745

Epoch: 51| Step: 0
Training loss: 2.252237478998207
Validation loss: 2.528463376053122

Epoch: 6| Step: 1
Training loss: 2.6497016522866064
Validation loss: 2.5099346019893076

Epoch: 6| Step: 2
Training loss: 2.3371180992467324
Validation loss: 2.498833272798559

Epoch: 6| Step: 3
Training loss: 2.740266393255564
Validation loss: 2.4830985798915663

Epoch: 6| Step: 4
Training loss: 2.56877883560814
Validation loss: 2.480347814139921

Epoch: 6| Step: 5
Training loss: 3.186789788803149
Validation loss: 2.4895068732827776

Epoch: 6| Step: 6
Training loss: 2.4135179615352103
Validation loss: 2.4710898598017117

Epoch: 6| Step: 7
Training loss: 1.938756104883338
Validation loss: 2.4901429881362507

Epoch: 6| Step: 8
Training loss: 2.469126805389166
Validation loss: 2.5016229606722655

Epoch: 6| Step: 9
Training loss: 2.282274199197964
Validation loss: 2.4870155345128393

Epoch: 6| Step: 10
Training loss: 1.8376808492711885
Validation loss: 2.495524572868638

Epoch: 6| Step: 11
Training loss: 2.8869757634656183
Validation loss: 2.4905821314320904

Epoch: 6| Step: 12
Training loss: 1.9257985824207347
Validation loss: 2.4848608505567955

Epoch: 6| Step: 13
Training loss: 1.7152268105715616
Validation loss: 2.5092178954291198

Epoch: 52| Step: 0
Training loss: 2.1329841963857232
Validation loss: 2.4854976428756226

Epoch: 6| Step: 1
Training loss: 2.196721395274843
Validation loss: 2.5158066377953467

Epoch: 6| Step: 2
Training loss: 2.4312764458088316
Validation loss: 2.4985985244986217

Epoch: 6| Step: 3
Training loss: 3.251739916527952
Validation loss: 2.497897782200009

Epoch: 6| Step: 4
Training loss: 1.8306080184362479
Validation loss: 2.5116393302673585

Epoch: 6| Step: 5
Training loss: 2.765828615441072
Validation loss: 2.505482947405771

Epoch: 6| Step: 6
Training loss: 2.208609605697861
Validation loss: 2.539832568645164

Epoch: 6| Step: 7
Training loss: 2.365695697327688
Validation loss: 2.51849388827199

Epoch: 6| Step: 8
Training loss: 1.9654027549386623
Validation loss: 2.502229110024328

Epoch: 6| Step: 9
Training loss: 2.2149811017541277
Validation loss: 2.5155494789176323

Epoch: 6| Step: 10
Training loss: 2.0418261511137694
Validation loss: 2.507673249780601

Epoch: 6| Step: 11
Training loss: 2.811295399721169
Validation loss: 2.508961985523463

Epoch: 6| Step: 12
Training loss: 2.46480128618954
Validation loss: 2.515150100394941

Epoch: 6| Step: 13
Training loss: 2.4252884958654897
Validation loss: 2.5054363588436526

Epoch: 53| Step: 0
Training loss: 2.322858139692088
Validation loss: 2.5239616534664804

Epoch: 6| Step: 1
Training loss: 2.8404409418182803
Validation loss: 2.502319864934603

Epoch: 6| Step: 2
Training loss: 2.731498469523197
Validation loss: 2.4883076473255166

Epoch: 6| Step: 3
Training loss: 1.9951128854579168
Validation loss: 2.490191195244512

Epoch: 6| Step: 4
Training loss: 2.1879719906187507
Validation loss: 2.464512209754129

Epoch: 6| Step: 5
Training loss: 1.9473235983526338
Validation loss: 2.5045336781793295

Epoch: 6| Step: 6
Training loss: 2.1989457552170784
Validation loss: 2.486348813578436

Epoch: 6| Step: 7
Training loss: 1.9753266945576202
Validation loss: 2.502331091953688

Epoch: 6| Step: 8
Training loss: 1.8876153620145526
Validation loss: 2.499419971572454

Epoch: 6| Step: 9
Training loss: 2.487022093290908
Validation loss: 2.4742437472424235

Epoch: 6| Step: 10
Training loss: 1.9440477541799808
Validation loss: 2.482951046067146

Epoch: 6| Step: 11
Training loss: 2.4966257212005676
Validation loss: 2.4934978966371015

Epoch: 6| Step: 12
Training loss: 3.6331311814186513
Validation loss: 2.488047382696742

Epoch: 6| Step: 13
Training loss: 2.2651149833410993
Validation loss: 2.4718074858488244

Epoch: 54| Step: 0
Training loss: 2.7457618132921238
Validation loss: 2.5279707212020157

Epoch: 6| Step: 1
Training loss: 2.9117476445251826
Validation loss: 2.53359429391484

Epoch: 6| Step: 2
Training loss: 2.2025652235161557
Validation loss: 2.5370725844889526

Epoch: 6| Step: 3
Training loss: 2.7221221180976034
Validation loss: 2.5028262693125063

Epoch: 6| Step: 4
Training loss: 1.7266318190800458
Validation loss: 2.5152266287651046

Epoch: 6| Step: 5
Training loss: 2.7546332948472125
Validation loss: 2.5307942831849197

Epoch: 6| Step: 6
Training loss: 2.5547007522472596
Validation loss: 2.5090243223168684

Epoch: 6| Step: 7
Training loss: 2.1755876163908034
Validation loss: 2.5053665100622737

Epoch: 6| Step: 8
Training loss: 2.4111711785627215
Validation loss: 2.507798809834128

Epoch: 6| Step: 9
Training loss: 2.052469543156716
Validation loss: 2.501486209339062

Epoch: 6| Step: 10
Training loss: 2.0280903817676994
Validation loss: 2.5103201049552726

Epoch: 6| Step: 11
Training loss: 2.299411955585971
Validation loss: 2.4996545235026515

Epoch: 6| Step: 12
Training loss: 2.4949793947397203
Validation loss: 2.492164149319466

Epoch: 6| Step: 13
Training loss: 1.936825296380324
Validation loss: 2.512516454702872

Epoch: 55| Step: 0
Training loss: 1.9675819322716974
Validation loss: 2.506851487507162

Epoch: 6| Step: 1
Training loss: 2.258996778306019
Validation loss: 2.4730272381387084

Epoch: 6| Step: 2
Training loss: 2.875041132093673
Validation loss: 2.509952080080481

Epoch: 6| Step: 3
Training loss: 2.9546190145978786
Validation loss: 2.5116039069911076

Epoch: 6| Step: 4
Training loss: 2.1883758971158582
Validation loss: 2.4954083794709763

Epoch: 6| Step: 5
Training loss: 2.000882550065469
Validation loss: 2.49622239172881

Epoch: 6| Step: 6
Training loss: 1.7659736896641636
Validation loss: 2.480460067293284

Epoch: 6| Step: 7
Training loss: 1.8121346730338974
Validation loss: 2.459735467806774

Epoch: 6| Step: 8
Training loss: 2.2009090886143423
Validation loss: 2.4903104882669576

Epoch: 6| Step: 9
Training loss: 2.644006313587678
Validation loss: 2.474878976412522

Epoch: 6| Step: 10
Training loss: 2.562111615777435
Validation loss: 2.4916026386807775

Epoch: 6| Step: 11
Training loss: 2.833720536047268
Validation loss: 2.486293475840329

Epoch: 6| Step: 12
Training loss: 2.5778365465111563
Validation loss: 2.4764763047935547

Epoch: 6| Step: 13
Training loss: 2.2506890831203124
Validation loss: 2.480877235399161

Epoch: 56| Step: 0
Training loss: 1.8887097454515018
Validation loss: 2.505168087028646

Epoch: 6| Step: 1
Training loss: 2.7016170463107816
Validation loss: 2.508543864526085

Epoch: 6| Step: 2
Training loss: 2.3229141805547115
Validation loss: 2.5411269182857885

Epoch: 6| Step: 3
Training loss: 1.8763954056442245
Validation loss: 2.522865836914833

Epoch: 6| Step: 4
Training loss: 2.41865532268372
Validation loss: 2.5516236235038163

Epoch: 6| Step: 5
Training loss: 2.791966996241067
Validation loss: 2.55383943097105

Epoch: 6| Step: 6
Training loss: 1.9072044359555596
Validation loss: 2.5432308626426425

Epoch: 6| Step: 7
Training loss: 2.608572465296232
Validation loss: 2.5653913824452417

Epoch: 6| Step: 8
Training loss: 2.34628291274141
Validation loss: 2.5671877897590942

Epoch: 6| Step: 9
Training loss: 2.2354826415874096
Validation loss: 2.550969691810422

Epoch: 6| Step: 10
Training loss: 2.25593821730459
Validation loss: 2.532125251058553

Epoch: 6| Step: 11
Training loss: 2.9877287709258624
Validation loss: 2.5378094520483216

Epoch: 6| Step: 12
Training loss: 2.4754476354365837
Validation loss: 2.5231327309819562

Epoch: 6| Step: 13
Training loss: 2.0838069250321074
Validation loss: 2.493827909752004

Epoch: 57| Step: 0
Training loss: 2.6831225740895834
Validation loss: 2.4927541792070684

Epoch: 6| Step: 1
Training loss: 2.7574019950542397
Validation loss: 2.476535351721763

Epoch: 6| Step: 2
Training loss: 2.15183159191924
Validation loss: 2.503154814467587

Epoch: 6| Step: 3
Training loss: 2.197926549904344
Validation loss: 2.484160072098657

Epoch: 6| Step: 4
Training loss: 2.488492803997407
Validation loss: 2.4988252740831496

Epoch: 6| Step: 5
Training loss: 2.3849931588064797
Validation loss: 2.5034526983503005

Epoch: 6| Step: 6
Training loss: 2.207228390151387
Validation loss: 2.502921416107374

Epoch: 6| Step: 7
Training loss: 2.4980432482015305
Validation loss: 2.4972442379401687

Epoch: 6| Step: 8
Training loss: 2.2012930754606588
Validation loss: 2.4879812781405346

Epoch: 6| Step: 9
Training loss: 2.3575860118850978
Validation loss: 2.480483904614549

Epoch: 6| Step: 10
Training loss: 1.842694966677642
Validation loss: 2.4963492917870758

Epoch: 6| Step: 11
Training loss: 2.1527696247014805
Validation loss: 2.465915743048157

Epoch: 6| Step: 12
Training loss: 2.7346130267492867
Validation loss: 2.4851843677134506

Epoch: 6| Step: 13
Training loss: 2.3688335675719627
Validation loss: 2.5066335725459687

Epoch: 58| Step: 0
Training loss: 2.228755045407458
Validation loss: 2.50016827017016

Epoch: 6| Step: 1
Training loss: 2.6695301854123388
Validation loss: 2.500812914925031

Epoch: 6| Step: 2
Training loss: 2.2482159217093542
Validation loss: 2.502897832168916

Epoch: 6| Step: 3
Training loss: 2.1236965445290505
Validation loss: 2.48369066741884

Epoch: 6| Step: 4
Training loss: 1.6438487034161327
Validation loss: 2.5036378618439743

Epoch: 6| Step: 5
Training loss: 2.6806566804600087
Validation loss: 2.504461567081264

Epoch: 6| Step: 6
Training loss: 1.6907039884775965
Validation loss: 2.482187599714574

Epoch: 6| Step: 7
Training loss: 2.1951049489368213
Validation loss: 2.4962516499913288

Epoch: 6| Step: 8
Training loss: 3.256014906584338
Validation loss: 2.483558552618493

Epoch: 6| Step: 9
Training loss: 2.1285784267738417
Validation loss: 2.507287125899658

Epoch: 6| Step: 10
Training loss: 1.8520871477406045
Validation loss: 2.5055797854034583

Epoch: 6| Step: 11
Training loss: 3.007926482976229
Validation loss: 2.50309866559181

Epoch: 6| Step: 12
Training loss: 2.53677612653342
Validation loss: 2.4892958125210436

Epoch: 6| Step: 13
Training loss: 2.336905798636402
Validation loss: 2.489401269318069

Epoch: 59| Step: 0
Training loss: 2.669293143326481
Validation loss: 2.5087381241179463

Epoch: 6| Step: 1
Training loss: 2.4181815255608843
Validation loss: 2.4921096582323967

Epoch: 6| Step: 2
Training loss: 2.155914169917378
Validation loss: 2.500013971289696

Epoch: 6| Step: 3
Training loss: 2.3164434060112873
Validation loss: 2.5111157458280404

Epoch: 6| Step: 4
Training loss: 2.0634826862264197
Validation loss: 2.5254155644805305

Epoch: 6| Step: 5
Training loss: 2.3438130688128878
Validation loss: 2.515328162709265

Epoch: 6| Step: 6
Training loss: 2.2567417021108964
Validation loss: 2.546602527108628

Epoch: 6| Step: 7
Training loss: 2.2443964374976946
Validation loss: 2.5641080571384767

Epoch: 6| Step: 8
Training loss: 2.4886991667908847
Validation loss: 2.542303151550168

Epoch: 6| Step: 9
Training loss: 1.9391037241129347
Validation loss: 2.5057460236971845

Epoch: 6| Step: 10
Training loss: 1.8711331229955146
Validation loss: 2.4999718028703626

Epoch: 6| Step: 11
Training loss: 2.9186742866710573
Validation loss: 2.4930720179683403

Epoch: 6| Step: 12
Training loss: 2.577026040487055
Validation loss: 2.4964238258499662

Epoch: 6| Step: 13
Training loss: 2.484532381267037
Validation loss: 2.489598363301598

Epoch: 60| Step: 0
Training loss: 2.936004582684758
Validation loss: 2.4715833540920227

Epoch: 6| Step: 1
Training loss: 1.9711199226108376
Validation loss: 2.485012356556618

Epoch: 6| Step: 2
Training loss: 2.04555090089667
Validation loss: 2.4822389228607706

Epoch: 6| Step: 3
Training loss: 2.045121818029389
Validation loss: 2.5135271949103783

Epoch: 6| Step: 4
Training loss: 2.400063823804984
Validation loss: 2.520342492691562

Epoch: 6| Step: 5
Training loss: 2.4954097568808873
Validation loss: 2.534801793409908

Epoch: 6| Step: 6
Training loss: 2.51379849486235
Validation loss: 2.530706182389748

Epoch: 6| Step: 7
Training loss: 2.0042042650065293
Validation loss: 2.519160162042096

Epoch: 6| Step: 8
Training loss: 1.8145675705211588
Validation loss: 2.5116020242750827

Epoch: 6| Step: 9
Training loss: 2.744353913947467
Validation loss: 2.5064511986544984

Epoch: 6| Step: 10
Training loss: 2.8172257457301475
Validation loss: 2.48339929354412

Epoch: 6| Step: 11
Training loss: 2.2978195013102765
Validation loss: 2.4879067706582787

Epoch: 6| Step: 12
Training loss: 2.29622241240881
Validation loss: 2.478614895322871

Epoch: 6| Step: 13
Training loss: 2.209037152780483
Validation loss: 2.48944419142148

Epoch: 61| Step: 0
Training loss: 2.245301214626464
Validation loss: 2.4858892692268535

Epoch: 6| Step: 1
Training loss: 2.016810578605027
Validation loss: 2.482485278400617

Epoch: 6| Step: 2
Training loss: 2.437861489120479
Validation loss: 2.4902831866897115

Epoch: 6| Step: 3
Training loss: 1.9751682113286486
Validation loss: 2.4971623210443563

Epoch: 6| Step: 4
Training loss: 2.3744445954456004
Validation loss: 2.5022751627961046

Epoch: 6| Step: 5
Training loss: 2.0217621101100667
Validation loss: 2.4767948526998422

Epoch: 6| Step: 6
Training loss: 2.3274305703269396
Validation loss: 2.483288589390206

Epoch: 6| Step: 7
Training loss: 2.8684637986575643
Validation loss: 2.468452194214561

Epoch: 6| Step: 8
Training loss: 2.1079745694821597
Validation loss: 2.502667291634383

Epoch: 6| Step: 9
Training loss: 2.179951204051292
Validation loss: 2.5149488231414425

Epoch: 6| Step: 10
Training loss: 2.7103956049209055
Validation loss: 2.5056319893009746

Epoch: 6| Step: 11
Training loss: 2.943136934558765
Validation loss: 2.538558471732592

Epoch: 6| Step: 12
Training loss: 2.4003099718193543
Validation loss: 2.529917385815637

Epoch: 6| Step: 13
Training loss: 2.063037224363954
Validation loss: 2.546967830409371

Epoch: 62| Step: 0
Training loss: 1.4760057317989468
Validation loss: 2.5173358825354817

Epoch: 6| Step: 1
Training loss: 2.2267635856977175
Validation loss: 2.5127380106530532

Epoch: 6| Step: 2
Training loss: 2.6898280860961106
Validation loss: 2.519508964972303

Epoch: 6| Step: 3
Training loss: 1.9881371706338529
Validation loss: 2.500630013237514

Epoch: 6| Step: 4
Training loss: 2.5489066977831705
Validation loss: 2.5018101496744793

Epoch: 6| Step: 5
Training loss: 1.827749556111316
Validation loss: 2.5128698089494885

Epoch: 6| Step: 6
Training loss: 2.0466937501753497
Validation loss: 2.496198720620201

Epoch: 6| Step: 7
Training loss: 2.214791325885583
Validation loss: 2.4966063353715056

Epoch: 6| Step: 8
Training loss: 3.081903143131299
Validation loss: 2.538697131351625

Epoch: 6| Step: 9
Training loss: 2.473608523617428
Validation loss: 2.52152373314951

Epoch: 6| Step: 10
Training loss: 1.9233751102496317
Validation loss: 2.5242394746657486

Epoch: 6| Step: 11
Training loss: 2.998621623959375
Validation loss: 2.5460466703401075

Epoch: 6| Step: 12
Training loss: 2.0538211054690874
Validation loss: 2.494056120705294

Epoch: 6| Step: 13
Training loss: 2.56051307498787
Validation loss: 2.5105865046454467

Epoch: 63| Step: 0
Training loss: 1.9974905005695829
Validation loss: 2.502125512010316

Epoch: 6| Step: 1
Training loss: 1.917488985987418
Validation loss: 2.49972373707544

Epoch: 6| Step: 2
Training loss: 2.732728647785352
Validation loss: 2.495679603092046

Epoch: 6| Step: 3
Training loss: 2.09607203383825
Validation loss: 2.5013415392905096

Epoch: 6| Step: 4
Training loss: 2.7586274496357404
Validation loss: 2.495020835295113

Epoch: 6| Step: 5
Training loss: 2.3898579482635403
Validation loss: 2.478706611026556

Epoch: 6| Step: 6
Training loss: 2.7212887015370195
Validation loss: 2.4774247041481834

Epoch: 6| Step: 7
Training loss: 1.5021983567780552
Validation loss: 2.4927248161292765

Epoch: 6| Step: 8
Training loss: 2.464624361893564
Validation loss: 2.471516937801833

Epoch: 6| Step: 9
Training loss: 2.449440004615781
Validation loss: 2.4892005679369027

Epoch: 6| Step: 10
Training loss: 2.510106068835865
Validation loss: 2.4888219959441296

Epoch: 6| Step: 11
Training loss: 2.4403258351564814
Validation loss: 2.4702723674180396

Epoch: 6| Step: 12
Training loss: 1.8692339292893803
Validation loss: 2.471624720683296

Epoch: 6| Step: 13
Training loss: 2.344327829975098
Validation loss: 2.489308542917172

Epoch: 64| Step: 0
Training loss: 1.8541414352014673
Validation loss: 2.5001450496556448

Epoch: 6| Step: 1
Training loss: 2.239168480589737
Validation loss: 2.5047931340296397

Epoch: 6| Step: 2
Training loss: 2.487069641917483
Validation loss: 2.507773948682097

Epoch: 6| Step: 3
Training loss: 2.9657392795359017
Validation loss: 2.508757717144141

Epoch: 6| Step: 4
Training loss: 2.136274943733458
Validation loss: 2.51923856390559

Epoch: 6| Step: 5
Training loss: 1.4568103285304468
Validation loss: 2.5108109213403473

Epoch: 6| Step: 6
Training loss: 2.762655441951164
Validation loss: 2.5314997640076315

Epoch: 6| Step: 7
Training loss: 2.6257464846097442
Validation loss: 2.488222401959593

Epoch: 6| Step: 8
Training loss: 2.1337141988440327
Validation loss: 2.4800531314470287

Epoch: 6| Step: 9
Training loss: 1.5995357435930397
Validation loss: 2.495534883039677

Epoch: 6| Step: 10
Training loss: 2.26571602474071
Validation loss: 2.510460981133542

Epoch: 6| Step: 11
Training loss: 2.457321077122018
Validation loss: 2.5096603826679837

Epoch: 6| Step: 12
Training loss: 1.6538618612481844
Validation loss: 2.491553693355733

Epoch: 6| Step: 13
Training loss: 3.066527540395791
Validation loss: 2.4696688813110232

Epoch: 65| Step: 0
Training loss: 1.317030761371087
Validation loss: 2.503016559285441

Epoch: 6| Step: 1
Training loss: 2.205734547169746
Validation loss: 2.5285114968966136

Epoch: 6| Step: 2
Training loss: 2.5781390565431197
Validation loss: 2.4855320313489204

Epoch: 6| Step: 3
Training loss: 2.176643022853768
Validation loss: 2.524961627379065

Epoch: 6| Step: 4
Training loss: 2.1932916537366456
Validation loss: 2.507991922997261

Epoch: 6| Step: 5
Training loss: 2.45329643670961
Validation loss: 2.533511042845195

Epoch: 6| Step: 6
Training loss: 2.952958198155902
Validation loss: 2.5293319012390345

Epoch: 6| Step: 7
Training loss: 2.279491007692373
Validation loss: 2.482532225646485

Epoch: 6| Step: 8
Training loss: 2.248181349827871
Validation loss: 2.4972106154213

Epoch: 6| Step: 9
Training loss: 2.065204811930809
Validation loss: 2.5133564594791764

Epoch: 6| Step: 10
Training loss: 2.6002486293463796
Validation loss: 2.5093812482414823

Epoch: 6| Step: 11
Training loss: 1.7130643958721772
Validation loss: 2.5043325552260263

Epoch: 6| Step: 12
Training loss: 2.775540008927273
Validation loss: 2.5380379355611318

Epoch: 6| Step: 13
Training loss: 2.3469952304890773
Validation loss: 2.503018805655838

Epoch: 66| Step: 0
Training loss: 2.3181625321209878
Validation loss: 2.5178593255819117

Epoch: 6| Step: 1
Training loss: 1.8934107662315107
Validation loss: 2.524128208171774

Epoch: 6| Step: 2
Training loss: 2.8784967801578145
Validation loss: 2.510664066349141

Epoch: 6| Step: 3
Training loss: 2.1779671172575084
Validation loss: 2.48470955121604

Epoch: 6| Step: 4
Training loss: 1.9860175836174623
Validation loss: 2.480409684566815

Epoch: 6| Step: 5
Training loss: 1.988676560230989
Validation loss: 2.5050675371752202

Epoch: 6| Step: 6
Training loss: 1.4390866189565314
Validation loss: 2.461342777203944

Epoch: 6| Step: 7
Training loss: 2.2964623528203423
Validation loss: 2.4823002979311526

Epoch: 6| Step: 8
Training loss: 2.7982072267939757
Validation loss: 2.4833916051372866

Epoch: 6| Step: 9
Training loss: 2.0466611328215865
Validation loss: 2.517966055841491

Epoch: 6| Step: 10
Training loss: 2.6927142459846283
Validation loss: 2.46605739146232

Epoch: 6| Step: 11
Training loss: 2.266209388869806
Validation loss: 2.475290198283236

Epoch: 6| Step: 12
Training loss: 3.0379250562614177
Validation loss: 2.47905450187857

Epoch: 6| Step: 13
Training loss: 1.80940627102356
Validation loss: 2.5236736694930406

Epoch: 67| Step: 0
Training loss: 2.6405654087904327
Validation loss: 2.4979725882087784

Epoch: 6| Step: 1
Training loss: 1.9550545888240518
Validation loss: 2.5294280068514867

Epoch: 6| Step: 2
Training loss: 1.7882511348030141
Validation loss: 2.4985726732463167

Epoch: 6| Step: 3
Training loss: 2.4568876336703767
Validation loss: 2.4989502292219137

Epoch: 6| Step: 4
Training loss: 2.7350468273442985
Validation loss: 2.5689894373572524

Epoch: 6| Step: 5
Training loss: 2.6581380977707063
Validation loss: 2.5447422763457284

Epoch: 6| Step: 6
Training loss: 2.2692920342074383
Validation loss: 2.5400089866874693

Epoch: 6| Step: 7
Training loss: 2.2641407281117347
Validation loss: 2.5502734299462135

Epoch: 6| Step: 8
Training loss: 1.5322807112802865
Validation loss: 2.551616942678884

Epoch: 6| Step: 9
Training loss: 2.4611153674561277
Validation loss: 2.554964577428694

Epoch: 6| Step: 10
Training loss: 1.5984260924110287
Validation loss: 2.513059868122327

Epoch: 6| Step: 11
Training loss: 2.5744117583419435
Validation loss: 2.5221357737816494

Epoch: 6| Step: 12
Training loss: 2.5003863989721746
Validation loss: 2.4898546994059

Epoch: 6| Step: 13
Training loss: 2.306210186208888
Validation loss: 2.5035710737794217

Epoch: 68| Step: 0
Training loss: 1.79749751710256
Validation loss: 2.481461578079633

Epoch: 6| Step: 1
Training loss: 2.4550833690651035
Validation loss: 2.489919748813159

Epoch: 6| Step: 2
Training loss: 2.274998499272449
Validation loss: 2.4861856895735612

Epoch: 6| Step: 3
Training loss: 1.6607201190851895
Validation loss: 2.4977749220905103

Epoch: 6| Step: 4
Training loss: 2.1092081639751665
Validation loss: 2.481817228371277

Epoch: 6| Step: 5
Training loss: 2.5196135751448474
Validation loss: 2.4883197200562033

Epoch: 6| Step: 6
Training loss: 2.3682396693794137
Validation loss: 2.492253397326482

Epoch: 6| Step: 7
Training loss: 2.803390330469645
Validation loss: 2.479619831587304

Epoch: 6| Step: 8
Training loss: 2.5683972490078197
Validation loss: 2.4935430907774108

Epoch: 6| Step: 9
Training loss: 2.808779990185091
Validation loss: 2.521471657340483

Epoch: 6| Step: 10
Training loss: 2.5846284163193665
Validation loss: 2.4824384903370484

Epoch: 6| Step: 11
Training loss: 1.7294196744221226
Validation loss: 2.518227615014078

Epoch: 6| Step: 12
Training loss: 1.6352966248339282
Validation loss: 2.47518767213692

Epoch: 6| Step: 13
Training loss: 2.3605856915454067
Validation loss: 2.5354283230424013

Epoch: 69| Step: 0
Training loss: 2.6593876875362925
Validation loss: 2.5236407061348265

Epoch: 6| Step: 1
Training loss: 3.0966037727705995
Validation loss: 2.5403880410387973

Epoch: 6| Step: 2
Training loss: 1.9367430654263489
Validation loss: 2.5364241131008773

Epoch: 6| Step: 3
Training loss: 1.7616512175682277
Validation loss: 2.55415257755478

Epoch: 6| Step: 4
Training loss: 2.037397735463231
Validation loss: 2.5445482355944056

Epoch: 6| Step: 5
Training loss: 1.5637636796702092
Validation loss: 2.5785794714890424

Epoch: 6| Step: 6
Training loss: 2.105624106484255
Validation loss: 2.6107893820540538

Epoch: 6| Step: 7
Training loss: 2.043597910410361
Validation loss: 2.574564191363591

Epoch: 6| Step: 8
Training loss: 2.8858887507726174
Validation loss: 2.61041840423583

Epoch: 6| Step: 9
Training loss: 2.5067600406678854
Validation loss: 2.56376455475538

Epoch: 6| Step: 10
Training loss: 2.352257711356731
Validation loss: 2.526342351786708

Epoch: 6| Step: 11
Training loss: 2.3858968814972252
Validation loss: 2.5382219693740717

Epoch: 6| Step: 12
Training loss: 2.0382611684223004
Validation loss: 2.5082108289220786

Epoch: 6| Step: 13
Training loss: 2.181410460595441
Validation loss: 2.471164456245475

Epoch: 70| Step: 0
Training loss: 2.4570071851464594
Validation loss: 2.47562596917625

Epoch: 6| Step: 1
Training loss: 2.212669853113142
Validation loss: 2.500454591110587

Epoch: 6| Step: 2
Training loss: 2.649609871703569
Validation loss: 2.4749973698483245

Epoch: 6| Step: 3
Training loss: 1.840286622735926
Validation loss: 2.493430470429095

Epoch: 6| Step: 4
Training loss: 1.9621972524780598
Validation loss: 2.4979563307191444

Epoch: 6| Step: 5
Training loss: 3.018364645172214
Validation loss: 2.4888424881680935

Epoch: 6| Step: 6
Training loss: 2.0985657835241476
Validation loss: 2.47851203375101

Epoch: 6| Step: 7
Training loss: 2.557850876918165
Validation loss: 2.488109684513486

Epoch: 6| Step: 8
Training loss: 1.7219490796888803
Validation loss: 2.509112891431052

Epoch: 6| Step: 9
Training loss: 2.6146277820309556
Validation loss: 2.5089477473038313

Epoch: 6| Step: 10
Training loss: 2.070369849220432
Validation loss: 2.5261884404175046

Epoch: 6| Step: 11
Training loss: 2.144245288453647
Validation loss: 2.5302518124467888

Epoch: 6| Step: 12
Training loss: 2.2815685311114815
Validation loss: 2.539442039879823

Epoch: 6| Step: 13
Training loss: 2.2167654699041957
Validation loss: 2.532145133905555

Epoch: 71| Step: 0
Training loss: 1.828234351384459
Validation loss: 2.5126139467885458

Epoch: 6| Step: 1
Training loss: 2.299793698553895
Validation loss: 2.483951452526683

Epoch: 6| Step: 2
Training loss: 1.5520547783121548
Validation loss: 2.510517080100627

Epoch: 6| Step: 3
Training loss: 2.210981712303635
Validation loss: 2.5225574309052856

Epoch: 6| Step: 4
Training loss: 2.255506981742673
Validation loss: 2.502868619846837

Epoch: 6| Step: 5
Training loss: 1.8556031509711453
Validation loss: 2.496537003539159

Epoch: 6| Step: 6
Training loss: 2.6620574296793698
Validation loss: 2.478903240879692

Epoch: 6| Step: 7
Training loss: 2.3643068216342336
Validation loss: 2.509814262661012

Epoch: 6| Step: 8
Training loss: 2.115756180949053
Validation loss: 2.499365551234251

Epoch: 6| Step: 9
Training loss: 2.241101364083445
Validation loss: 2.509498544377783

Epoch: 6| Step: 10
Training loss: 2.3314327833093538
Validation loss: 2.5097090619512774

Epoch: 6| Step: 11
Training loss: 2.753720800770512
Validation loss: 2.505448317318071

Epoch: 6| Step: 12
Training loss: 2.534980379890192
Validation loss: 2.4725305124527313

Epoch: 6| Step: 13
Training loss: 2.2696360893787464
Validation loss: 2.477589936636882

Epoch: 72| Step: 0
Training loss: 2.9700041681639324
Validation loss: 2.497004653690041

Epoch: 6| Step: 1
Training loss: 2.3328629996064625
Validation loss: 2.5051537955223773

Epoch: 6| Step: 2
Training loss: 1.7283836185027732
Validation loss: 2.4997028174195104

Epoch: 6| Step: 3
Training loss: 1.926704479471255
Validation loss: 2.5440719172725887

Epoch: 6| Step: 4
Training loss: 3.4373264615730315
Validation loss: 2.530524412797039

Epoch: 6| Step: 5
Training loss: 1.9033910230299247
Validation loss: 2.525264806679039

Epoch: 6| Step: 6
Training loss: 2.234099791324012
Validation loss: 2.570488828043023

Epoch: 6| Step: 7
Training loss: 1.5820091716968285
Validation loss: 2.559338891625072

Epoch: 6| Step: 8
Training loss: 2.097018523214934
Validation loss: 2.578120098687339

Epoch: 6| Step: 9
Training loss: 1.9151645523965684
Validation loss: 2.539188151062616

Epoch: 6| Step: 10
Training loss: 2.0884660689702943
Validation loss: 2.5263185539425677

Epoch: 6| Step: 11
Training loss: 2.2400123599256387
Validation loss: 2.5413206964589237

Epoch: 6| Step: 12
Training loss: 2.388850332535482
Validation loss: 2.542211479413106

Epoch: 6| Step: 13
Training loss: 2.138956129440114
Validation loss: 2.4936115178638625

Epoch: 73| Step: 0
Training loss: 2.4760573199821443
Validation loss: 2.5128273423307683

Epoch: 6| Step: 1
Training loss: 2.2928635217283344
Validation loss: 2.505658802500033

Epoch: 6| Step: 2
Training loss: 1.7369784498618352
Validation loss: 2.4826715735452893

Epoch: 6| Step: 3
Training loss: 2.5483467202825643
Validation loss: 2.4776807600917503

Epoch: 6| Step: 4
Training loss: 2.519360345766133
Validation loss: 2.476407580739859

Epoch: 6| Step: 5
Training loss: 1.7224042712492191
Validation loss: 2.482289380515248

Epoch: 6| Step: 6
Training loss: 2.102255100860559
Validation loss: 2.5154432622053204

Epoch: 6| Step: 7
Training loss: 2.1550639110744325
Validation loss: 2.4991204780956577

Epoch: 6| Step: 8
Training loss: 2.9774671566526663
Validation loss: 2.4886188687250224

Epoch: 6| Step: 9
Training loss: 2.073356492300598
Validation loss: 2.4852401218773768

Epoch: 6| Step: 10
Training loss: 2.6202422121796833
Validation loss: 2.461739594066511

Epoch: 6| Step: 11
Training loss: 2.0590595102107554
Validation loss: 2.515501520826557

Epoch: 6| Step: 12
Training loss: 1.4566825060707058
Validation loss: 2.4946042164971853

Epoch: 6| Step: 13
Training loss: 2.3927793083464524
Validation loss: 2.5094940790700777

Epoch: 74| Step: 0
Training loss: 2.027205916406779
Validation loss: 2.522993948330591

Epoch: 6| Step: 1
Training loss: 2.6402927167044967
Validation loss: 2.5267454340222835

Epoch: 6| Step: 2
Training loss: 1.9450265452086155
Validation loss: 2.503393159330085

Epoch: 6| Step: 3
Training loss: 1.8479404996978621
Validation loss: 2.5262993487773318

Epoch: 6| Step: 4
Training loss: 2.490607930008846
Validation loss: 2.5612818295815947

Epoch: 6| Step: 5
Training loss: 2.3115906860728965
Validation loss: 2.583758339735406

Epoch: 6| Step: 6
Training loss: 2.3783202804210806
Validation loss: 2.5564049596849108

Epoch: 6| Step: 7
Training loss: 1.9938545582299603
Validation loss: 2.5453869269573564

Epoch: 6| Step: 8
Training loss: 2.152771728944655
Validation loss: 2.5418053703816867

Epoch: 6| Step: 9
Training loss: 1.7356087360437398
Validation loss: 2.5255428306695182

Epoch: 6| Step: 10
Training loss: 2.2673109424513265
Validation loss: 2.531193296951215

Epoch: 6| Step: 11
Training loss: 2.3670025743825858
Validation loss: 2.525889674592135

Epoch: 6| Step: 12
Training loss: 2.654168244445747
Validation loss: 2.4951500260294193

Epoch: 6| Step: 13
Training loss: 2.2726069765332495
Validation loss: 2.4689085543294045

Epoch: 75| Step: 0
Training loss: 2.218642326213822
Validation loss: 2.4866604798864698

Epoch: 6| Step: 1
Training loss: 2.542298493778755
Validation loss: 2.493069898114851

Epoch: 6| Step: 2
Training loss: 2.2547713657360395
Validation loss: 2.4919810114892784

Epoch: 6| Step: 3
Training loss: 2.1194211993839143
Validation loss: 2.5025138057997367

Epoch: 6| Step: 4
Training loss: 2.6625637637817454
Validation loss: 2.491478606902159

Epoch: 6| Step: 5
Training loss: 2.0580499209400385
Validation loss: 2.473315544278658

Epoch: 6| Step: 6
Training loss: 1.7581452457416313
Validation loss: 2.4733552271224397

Epoch: 6| Step: 7
Training loss: 1.8413457550612289
Validation loss: 2.4885130194932183

Epoch: 6| Step: 8
Training loss: 2.5833232838424953
Validation loss: 2.4980150528452456

Epoch: 6| Step: 9
Training loss: 2.550820787015325
Validation loss: 2.5014329777071085

Epoch: 6| Step: 10
Training loss: 2.0756830768678785
Validation loss: 2.520210036677969

Epoch: 6| Step: 11
Training loss: 2.002149142461587
Validation loss: 2.5198617486773567

Epoch: 6| Step: 12
Training loss: 2.2204258996513
Validation loss: 2.497826553344009

Epoch: 6| Step: 13
Training loss: 2.0959781917718754
Validation loss: 2.4985819450581266

Epoch: 76| Step: 0
Training loss: 2.4938331838706875
Validation loss: 2.5176669692804428

Epoch: 6| Step: 1
Training loss: 1.94544669917849
Validation loss: 2.48977083965821

Epoch: 6| Step: 2
Training loss: 2.6797524491605076
Validation loss: 2.4868177005353247

Epoch: 6| Step: 3
Training loss: 1.93989931258211
Validation loss: 2.5048225935947017

Epoch: 6| Step: 4
Training loss: 1.4847030277198972
Validation loss: 2.47829703831813

Epoch: 6| Step: 5
Training loss: 2.1320563572418347
Validation loss: 2.5022077269578467

Epoch: 6| Step: 6
Training loss: 1.850283281443178
Validation loss: 2.5152840867066693

Epoch: 6| Step: 7
Training loss: 2.5901139292458524
Validation loss: 2.5164545717192053

Epoch: 6| Step: 8
Training loss: 2.4368809623087646
Validation loss: 2.517351557103293

Epoch: 6| Step: 9
Training loss: 2.3526032131469856
Validation loss: 2.494682506065845

Epoch: 6| Step: 10
Training loss: 2.6407918482329045
Validation loss: 2.4962473520090738

Epoch: 6| Step: 11
Training loss: 1.7713784519479836
Validation loss: 2.5036567170872273

Epoch: 6| Step: 12
Training loss: 1.8997304147904788
Validation loss: 2.522818663688926

Epoch: 6| Step: 13
Training loss: 2.430792161838938
Validation loss: 2.4956956843489495

Epoch: 77| Step: 0
Training loss: 2.964254730377837
Validation loss: 2.508899623423936

Epoch: 6| Step: 1
Training loss: 2.3242770147633913
Validation loss: 2.5024976333876277

Epoch: 6| Step: 2
Training loss: 2.2230778781979184
Validation loss: 2.5054103640319463

Epoch: 6| Step: 3
Training loss: 2.1577524672657553
Validation loss: 2.5151256120886183

Epoch: 6| Step: 4
Training loss: 2.887533152996821
Validation loss: 2.4875218516656776

Epoch: 6| Step: 5
Training loss: 2.0807526690158777
Validation loss: 2.497322158336671

Epoch: 6| Step: 6
Training loss: 2.1500827108042984
Validation loss: 2.487333235909446

Epoch: 6| Step: 7
Training loss: 1.4474862737449545
Validation loss: 2.4565772287538428

Epoch: 6| Step: 8
Training loss: 1.9961368683041687
Validation loss: 2.481384813055862

Epoch: 6| Step: 9
Training loss: 2.422699228131258
Validation loss: 2.4691309896469305

Epoch: 6| Step: 10
Training loss: 2.207878773768384
Validation loss: 2.497614230782018

Epoch: 6| Step: 11
Training loss: 2.1041602206996974
Validation loss: 2.501377425613792

Epoch: 6| Step: 12
Training loss: 1.8393933824196789
Validation loss: 2.5128202262752994

Epoch: 6| Step: 13
Training loss: 1.65230313154216
Validation loss: 2.525279063046818

Epoch: 78| Step: 0
Training loss: 1.9777497958705288
Validation loss: 2.563018932366372

Epoch: 6| Step: 1
Training loss: 1.5533693178999541
Validation loss: 2.5412781658197283

Epoch: 6| Step: 2
Training loss: 2.398205773904833
Validation loss: 2.5470110148988105

Epoch: 6| Step: 3
Training loss: 2.5847525748629208
Validation loss: 2.5619312911353327

Epoch: 6| Step: 4
Training loss: 2.245674213535847
Validation loss: 2.534992731950462

Epoch: 6| Step: 5
Training loss: 2.21811441263664
Validation loss: 2.546619901772804

Epoch: 6| Step: 6
Training loss: 3.12109283332668
Validation loss: 2.5349163927464993

Epoch: 6| Step: 7
Training loss: 1.5988794694601993
Validation loss: 2.503834152572299

Epoch: 6| Step: 8
Training loss: 2.0153619165760666
Validation loss: 2.5143261354183153

Epoch: 6| Step: 9
Training loss: 1.9678738779034384
Validation loss: 2.5285191816885133

Epoch: 6| Step: 10
Training loss: 2.2787729689235134
Validation loss: 2.5195558847410817

Epoch: 6| Step: 11
Training loss: 2.149055308898104
Validation loss: 2.513395114888956

Epoch: 6| Step: 12
Training loss: 2.47174566535805
Validation loss: 2.525705788426386

Epoch: 6| Step: 13
Training loss: 1.9183738265195203
Validation loss: 2.527034404518924

Epoch: 79| Step: 0
Training loss: 2.679494333673014
Validation loss: 2.505519670477114

Epoch: 6| Step: 1
Training loss: 2.172071928248882
Validation loss: 2.5183789676475894

Epoch: 6| Step: 2
Training loss: 2.3565233188432906
Validation loss: 2.4948241537656077

Epoch: 6| Step: 3
Training loss: 2.6102095314486125
Validation loss: 2.5070166191450007

Epoch: 6| Step: 4
Training loss: 1.3113114106786619
Validation loss: 2.488167305517778

Epoch: 6| Step: 5
Training loss: 2.5060304388586023
Validation loss: 2.4966079588210937

Epoch: 6| Step: 6
Training loss: 2.388385995770977
Validation loss: 2.50196983298074

Epoch: 6| Step: 7
Training loss: 1.8736939650001943
Validation loss: 2.470290238732334

Epoch: 6| Step: 8
Training loss: 1.8001175524155772
Validation loss: 2.4927955770521875

Epoch: 6| Step: 9
Training loss: 2.2496536836070997
Validation loss: 2.510563309265861

Epoch: 6| Step: 10
Training loss: 1.8849377805524392
Validation loss: 2.5246000180844996

Epoch: 6| Step: 11
Training loss: 2.2317450991867642
Validation loss: 2.4753682719890824

Epoch: 6| Step: 12
Training loss: 2.380467596200902
Validation loss: 2.5375379318383784

Epoch: 6| Step: 13
Training loss: 1.6772447433355189
Validation loss: 2.4918390267592234

Epoch: 80| Step: 0
Training loss: 2.1536200143972364
Validation loss: 2.4908311555133316

Epoch: 6| Step: 1
Training loss: 2.5274865701169573
Validation loss: 2.507594557627674

Epoch: 6| Step: 2
Training loss: 1.7695998290122228
Validation loss: 2.5082090624782705

Epoch: 6| Step: 3
Training loss: 1.7531367527640882
Validation loss: 2.512750029261573

Epoch: 6| Step: 4
Training loss: 2.243380133021181
Validation loss: 2.528022749585187

Epoch: 6| Step: 5
Training loss: 1.5410689234732955
Validation loss: 2.566240929514616

Epoch: 6| Step: 6
Training loss: 2.4520611248020767
Validation loss: 2.5521029932212036

Epoch: 6| Step: 7
Training loss: 2.0901713747280204
Validation loss: 2.519270394002989

Epoch: 6| Step: 8
Training loss: 1.9719302815035002
Validation loss: 2.534486640073677

Epoch: 6| Step: 9
Training loss: 2.9711428987027397
Validation loss: 2.5350551026655053

Epoch: 6| Step: 10
Training loss: 2.080422071219031
Validation loss: 2.5374508403532414

Epoch: 6| Step: 11
Training loss: 2.1807522924591125
Validation loss: 2.5265391354806552

Epoch: 6| Step: 12
Training loss: 2.30425524779901
Validation loss: 2.496862190732537

Epoch: 6| Step: 13
Training loss: 2.1551606010902526
Validation loss: 2.492609400897482

Epoch: 81| Step: 0
Training loss: 2.5688201374957553
Validation loss: 2.471993998971875

Epoch: 6| Step: 1
Training loss: 1.9843462243584435
Validation loss: 2.4741683201598565

Epoch: 6| Step: 2
Training loss: 2.8646138877395115
Validation loss: 2.485142635215026

Epoch: 6| Step: 3
Training loss: 2.69007687894873
Validation loss: 2.4915212858861313

Epoch: 6| Step: 4
Training loss: 2.2256121832658793
Validation loss: 2.48112998819504

Epoch: 6| Step: 5
Training loss: 1.8268924046462882
Validation loss: 2.5006175073296726

Epoch: 6| Step: 6
Training loss: 1.8715605661150052
Validation loss: 2.493351711249662

Epoch: 6| Step: 7
Training loss: 1.4535705539624417
Validation loss: 2.5185966552298575

Epoch: 6| Step: 8
Training loss: 1.7491306461637572
Validation loss: 2.5220204755318445

Epoch: 6| Step: 9
Training loss: 1.8503596265602993
Validation loss: 2.5071014632214643

Epoch: 6| Step: 10
Training loss: 2.5751788327236254
Validation loss: 2.5081350529096382

Epoch: 6| Step: 11
Training loss: 1.9684892512021468
Validation loss: 2.5370667972569807

Epoch: 6| Step: 12
Training loss: 2.142380711407257
Validation loss: 2.507311968106432

Epoch: 6| Step: 13
Training loss: 1.779108466715937
Validation loss: 2.5252654911753583

Epoch: 82| Step: 0
Training loss: 1.411907978390392
Validation loss: 2.5237334779548415

Epoch: 6| Step: 1
Training loss: 1.8895973376084967
Validation loss: 2.55139302370081

Epoch: 6| Step: 2
Training loss: 2.3971182211128452
Validation loss: 2.5431098488660804

Epoch: 6| Step: 3
Training loss: 2.357095387628985
Validation loss: 2.5243992188322864

Epoch: 6| Step: 4
Training loss: 2.129331997637886
Validation loss: 2.534664394351891

Epoch: 6| Step: 5
Training loss: 1.6865150968326617
Validation loss: 2.5094385787491444

Epoch: 6| Step: 6
Training loss: 2.11646824404808
Validation loss: 2.509123193277032

Epoch: 6| Step: 7
Training loss: 1.741190124490023
Validation loss: 2.5283825492050274

Epoch: 6| Step: 8
Training loss: 2.0744889652660237
Validation loss: 2.491275927569341

Epoch: 6| Step: 9
Training loss: 2.4205617974518234
Validation loss: 2.486549113906652

Epoch: 6| Step: 10
Training loss: 2.2939961355920118
Validation loss: 2.5331055704007457

Epoch: 6| Step: 11
Training loss: 3.006343651341839
Validation loss: 2.5271371936850158

Epoch: 6| Step: 12
Training loss: 2.2888973033260664
Validation loss: 2.502561337954336

Epoch: 6| Step: 13
Training loss: 1.6379173096498896
Validation loss: 2.505473534603564

Epoch: 83| Step: 0
Training loss: 2.7394277047359905
Validation loss: 2.4999888817222047

Epoch: 6| Step: 1
Training loss: 1.9985279387887327
Validation loss: 2.506567133802636

Epoch: 6| Step: 2
Training loss: 2.1954366302692674
Validation loss: 2.5092469388177863

Epoch: 6| Step: 3
Training loss: 1.8512459657407458
Validation loss: 2.5160999205205137

Epoch: 6| Step: 4
Training loss: 2.3403484838151347
Validation loss: 2.510618974651374

Epoch: 6| Step: 5
Training loss: 2.0565154208684
Validation loss: 2.5248027529330006

Epoch: 6| Step: 6
Training loss: 1.622218612698817
Validation loss: 2.5103570817600653

Epoch: 6| Step: 7
Training loss: 1.559797773213808
Validation loss: 2.506383375771307

Epoch: 6| Step: 8
Training loss: 2.8438858167472705
Validation loss: 2.539812088871408

Epoch: 6| Step: 9
Training loss: 1.9600230968827181
Validation loss: 2.5187860692977857

Epoch: 6| Step: 10
Training loss: 1.9185137625034863
Validation loss: 2.4925045341927454

Epoch: 6| Step: 11
Training loss: 1.667526365126052
Validation loss: 2.5038672735282193

Epoch: 6| Step: 12
Training loss: 2.09849159472084
Validation loss: 2.5097084998767967

Epoch: 6| Step: 13
Training loss: 2.527736721706819
Validation loss: 2.546588577359813

Epoch: 84| Step: 0
Training loss: 2.567022101657473
Validation loss: 2.5536901800164187

Epoch: 6| Step: 1
Training loss: 1.7683412706422896
Validation loss: 2.5432582286138

Epoch: 6| Step: 2
Training loss: 1.8868029715811625
Validation loss: 2.5420517134709857

Epoch: 6| Step: 3
Training loss: 1.8228467074094241
Validation loss: 2.5000160932022912

Epoch: 6| Step: 4
Training loss: 2.0489642713493357
Validation loss: 2.5283216326884346

Epoch: 6| Step: 5
Training loss: 2.2447269958479743
Validation loss: 2.5101922648529755

Epoch: 6| Step: 6
Training loss: 2.321171970647969
Validation loss: 2.497543192716852

Epoch: 6| Step: 7
Training loss: 1.7934804946523635
Validation loss: 2.539462334866975

Epoch: 6| Step: 8
Training loss: 1.4774162609555868
Validation loss: 2.5646877099206704

Epoch: 6| Step: 9
Training loss: 2.7202386397973046
Validation loss: 2.531518042858043

Epoch: 6| Step: 10
Training loss: 2.4695674653431414
Validation loss: 2.50408865055502

Epoch: 6| Step: 11
Training loss: 2.001709326809071
Validation loss: 2.5175529105830416

Epoch: 6| Step: 12
Training loss: 2.0290839750868126
Validation loss: 2.501874507053011

Epoch: 6| Step: 13
Training loss: 2.1085743832909016
Validation loss: 2.527226488084599

Epoch: 85| Step: 0
Training loss: 2.049522144169147
Validation loss: 2.4833500665275863

Epoch: 6| Step: 1
Training loss: 1.7212191791863907
Validation loss: 2.497715048863015

Epoch: 6| Step: 2
Training loss: 2.289907254002571
Validation loss: 2.5141606936216814

Epoch: 6| Step: 3
Training loss: 1.940112598238722
Validation loss: 2.507588520129326

Epoch: 6| Step: 4
Training loss: 2.303319492694143
Validation loss: 2.4964035550336314

Epoch: 6| Step: 5
Training loss: 2.481820574672586
Validation loss: 2.494795396413119

Epoch: 6| Step: 6
Training loss: 1.8002938957822403
Validation loss: 2.485042314456984

Epoch: 6| Step: 7
Training loss: 1.590450836419544
Validation loss: 2.5032625526482533

Epoch: 6| Step: 8
Training loss: 2.1907006962169144
Validation loss: 2.4809382917886054

Epoch: 6| Step: 9
Training loss: 2.579261298181965
Validation loss: 2.4962876811181767

Epoch: 6| Step: 10
Training loss: 1.9937698961180004
Validation loss: 2.5281216398577526

Epoch: 6| Step: 11
Training loss: 2.2437749154665347
Validation loss: 2.5504107437434786

Epoch: 6| Step: 12
Training loss: 2.106393020256698
Validation loss: 2.595429011085032

Epoch: 6| Step: 13
Training loss: 2.1772967390632134
Validation loss: 2.640692173932945

Epoch: 86| Step: 0
Training loss: 2.6668712318953434
Validation loss: 2.6124661195495866

Epoch: 6| Step: 1
Training loss: 2.1582457663349723
Validation loss: 2.5807454057035653

Epoch: 6| Step: 2
Training loss: 2.652219339635602
Validation loss: 2.5953611708855657

Epoch: 6| Step: 3
Training loss: 1.9408164404459716
Validation loss: 2.5542242658715835

Epoch: 6| Step: 4
Training loss: 1.998096513923959
Validation loss: 2.5075185728288565

Epoch: 6| Step: 5
Training loss: 2.12326281729382
Validation loss: 2.5075961581169244

Epoch: 6| Step: 6
Training loss: 1.8373589390177887
Validation loss: 2.509609984483801

Epoch: 6| Step: 7
Training loss: 1.4521620646531923
Validation loss: 2.5020416188527954

Epoch: 6| Step: 8
Training loss: 1.7804394266376093
Validation loss: 2.4821808440623347

Epoch: 6| Step: 9
Training loss: 2.1177898830980935
Validation loss: 2.499836908424836

Epoch: 6| Step: 10
Training loss: 1.6777858171137072
Validation loss: 2.4963420571290107

Epoch: 6| Step: 11
Training loss: 2.1516112034645163
Validation loss: 2.5010847122659197

Epoch: 6| Step: 12
Training loss: 1.9685941361990775
Validation loss: 2.4822931744027583

Epoch: 6| Step: 13
Training loss: 2.9896844897729045
Validation loss: 2.5056679846563203

Epoch: 87| Step: 0
Training loss: 1.6459706728003978
Validation loss: 2.549024474472331

Epoch: 6| Step: 1
Training loss: 2.8330673953144925
Validation loss: 2.5640496166276745

Epoch: 6| Step: 2
Training loss: 2.620368868654278
Validation loss: 2.5278643111786865

Epoch: 6| Step: 3
Training loss: 1.7343149260693298
Validation loss: 2.548409060427306

Epoch: 6| Step: 4
Training loss: 1.9821966033875653
Validation loss: 2.551500593852784

Epoch: 6| Step: 5
Training loss: 1.8578520235649107
Validation loss: 2.5532904332825717

Epoch: 6| Step: 6
Training loss: 2.4540036322730807
Validation loss: 2.5001913633221746

Epoch: 6| Step: 7
Training loss: 1.7943267001537835
Validation loss: 2.5068014449889717

Epoch: 6| Step: 8
Training loss: 1.658935385192459
Validation loss: 2.4815824796779204

Epoch: 6| Step: 9
Training loss: 2.352523455284987
Validation loss: 2.483010691179971

Epoch: 6| Step: 10
Training loss: 2.1707861936091857
Validation loss: 2.474705397928994

Epoch: 6| Step: 11
Training loss: 2.002496472568715
Validation loss: 2.4966711452055192

Epoch: 6| Step: 12
Training loss: 1.5434011891541268
Validation loss: 2.50002150526334

Epoch: 6| Step: 13
Training loss: 2.3186983087335507
Validation loss: 2.5175466681015335

Epoch: 88| Step: 0
Training loss: 2.5881174355207275
Validation loss: 2.5495959142515945

Epoch: 6| Step: 1
Training loss: 1.7933056749576881
Validation loss: 2.5275751761636793

Epoch: 6| Step: 2
Training loss: 2.453030432560931
Validation loss: 2.519185920332171

Epoch: 6| Step: 3
Training loss: 1.9195691674368545
Validation loss: 2.537665803625629

Epoch: 6| Step: 4
Training loss: 1.2839190896766275
Validation loss: 2.5343708688974322

Epoch: 6| Step: 5
Training loss: 1.942198194626252
Validation loss: 2.552615103821102

Epoch: 6| Step: 6
Training loss: 2.0519210699639645
Validation loss: 2.5449244044679964

Epoch: 6| Step: 7
Training loss: 2.0250174345043024
Validation loss: 2.5242729418112733

Epoch: 6| Step: 8
Training loss: 1.9037523009398414
Validation loss: 2.5576664532799267

Epoch: 6| Step: 9
Training loss: 1.891379402912358
Validation loss: 2.5508719676906617

Epoch: 6| Step: 10
Training loss: 1.9611517800510962
Validation loss: 2.5586536196627336

Epoch: 6| Step: 11
Training loss: 2.1562639318928314
Validation loss: 2.547883612188825

Epoch: 6| Step: 12
Training loss: 2.419368505131669
Validation loss: 2.5155724150727714

Epoch: 6| Step: 13
Training loss: 2.2067036883580204
Validation loss: 2.532133207354662

Epoch: 89| Step: 0
Training loss: 1.95382921874657
Validation loss: 2.536438573072306

Epoch: 6| Step: 1
Training loss: 2.518189633416473
Validation loss: 2.5030476749079593

Epoch: 6| Step: 2
Training loss: 1.5370505102342449
Validation loss: 2.527256629538928

Epoch: 6| Step: 3
Training loss: 1.962219670191932
Validation loss: 2.5122840130586552

Epoch: 6| Step: 4
Training loss: 2.1374881900215703
Validation loss: 2.508478838691368

Epoch: 6| Step: 5
Training loss: 1.271064466292691
Validation loss: 2.483259338411529

Epoch: 6| Step: 6
Training loss: 1.8115866102529445
Validation loss: 2.515571577875194

Epoch: 6| Step: 7
Training loss: 1.9434913782115466
Validation loss: 2.528648420987964

Epoch: 6| Step: 8
Training loss: 2.5375136126073254
Validation loss: 2.5533869677040775

Epoch: 6| Step: 9
Training loss: 1.7541414031008886
Validation loss: 2.563360348928266

Epoch: 6| Step: 10
Training loss: 1.8966059385521081
Validation loss: 2.5687732512944694

Epoch: 6| Step: 11
Training loss: 2.3222374942445687
Validation loss: 2.562933861824624

Epoch: 6| Step: 12
Training loss: 1.8239674037647542
Validation loss: 2.571834727976651

Epoch: 6| Step: 13
Training loss: 2.72005273585527
Validation loss: 2.5706477077083116

Epoch: 90| Step: 0
Training loss: 2.4456720544863946
Validation loss: 2.540223811694344

Epoch: 6| Step: 1
Training loss: 2.251487346297627
Validation loss: 2.5239388486514436

Epoch: 6| Step: 2
Training loss: 2.142555980863518
Validation loss: 2.5294480679955704

Epoch: 6| Step: 3
Training loss: 2.116168350474231
Validation loss: 2.518896073112045

Epoch: 6| Step: 4
Training loss: 1.86760882488232
Validation loss: 2.500574975651535

Epoch: 6| Step: 5
Training loss: 2.057839879901611
Validation loss: 2.464651004531861

Epoch: 6| Step: 6
Training loss: 2.137322432967146
Validation loss: 2.5311980379524615

Epoch: 6| Step: 7
Training loss: 1.2647691823692655
Validation loss: 2.467425043139294

Epoch: 6| Step: 8
Training loss: 1.960223793760487
Validation loss: 2.5015248099034677

Epoch: 6| Step: 9
Training loss: 2.0764720337323492
Validation loss: 2.4963790101735146

Epoch: 6| Step: 10
Training loss: 1.7119339780198526
Validation loss: 2.5060299314561925

Epoch: 6| Step: 11
Training loss: 1.996439506311689
Validation loss: 2.521021738709425

Epoch: 6| Step: 12
Training loss: 2.287958809955338
Validation loss: 2.5189206509643562

Epoch: 6| Step: 13
Training loss: 1.886417973081533
Validation loss: 2.5244749867351084

Epoch: 91| Step: 0
Training loss: 1.8783054461886994
Validation loss: 2.506506622443692

Epoch: 6| Step: 1
Training loss: 2.4958794968994824
Validation loss: 2.5354733496551534

Epoch: 6| Step: 2
Training loss: 2.0966080474341
Validation loss: 2.5232492855021498

Epoch: 6| Step: 3
Training loss: 2.1921827059290284
Validation loss: 2.547239086440113

Epoch: 6| Step: 4
Training loss: 1.788700183678549
Validation loss: 2.5524704360619768

Epoch: 6| Step: 5
Training loss: 3.05742848148122
Validation loss: 2.5743987233253596

Epoch: 6| Step: 6
Training loss: 2.018026414756937
Validation loss: 2.620652534503366

Epoch: 6| Step: 7
Training loss: 1.388641528778505
Validation loss: 2.589612916965145

Epoch: 6| Step: 8
Training loss: 1.6091754382207368
Validation loss: 2.5623747166966973

Epoch: 6| Step: 9
Training loss: 1.8062020424148792
Validation loss: 2.5294979923760863

Epoch: 6| Step: 10
Training loss: 2.1143514070652007
Validation loss: 2.536226412113676

Epoch: 6| Step: 11
Training loss: 2.3062384090804278
Validation loss: 2.5191470146443216

Epoch: 6| Step: 12
Training loss: 1.7487450595919536
Validation loss: 2.4746195475051334

Epoch: 6| Step: 13
Training loss: 1.4118194493497587
Validation loss: 2.4915569388640395

Epoch: 92| Step: 0
Training loss: 2.262557379906504
Validation loss: 2.5116268000722126

Epoch: 6| Step: 1
Training loss: 2.194760724974952
Validation loss: 2.5238680634602835

Epoch: 6| Step: 2
Training loss: 1.7733771360097708
Validation loss: 2.5101815478968232

Epoch: 6| Step: 3
Training loss: 1.8551156762138579
Validation loss: 2.509205456077769

Epoch: 6| Step: 4
Training loss: 2.049597407561069
Validation loss: 2.516943797164392

Epoch: 6| Step: 5
Training loss: 1.7498228119657593
Validation loss: 2.5448341696072414

Epoch: 6| Step: 6
Training loss: 2.3231820495185214
Validation loss: 2.570965514862908

Epoch: 6| Step: 7
Training loss: 2.5370402102774117
Validation loss: 2.527904230199021

Epoch: 6| Step: 8
Training loss: 2.333181433047551
Validation loss: 2.5586642578349554

Epoch: 6| Step: 9
Training loss: 1.8212896515791608
Validation loss: 2.5203175503104105

Epoch: 6| Step: 10
Training loss: 1.684173554952667
Validation loss: 2.520692243384577

Epoch: 6| Step: 11
Training loss: 1.398981681093006
Validation loss: 2.504517970988305

Epoch: 6| Step: 12
Training loss: 1.5335694476790063
Validation loss: 2.5089725334738917

Epoch: 6| Step: 13
Training loss: 2.3026378763442583
Validation loss: 2.5296134996026627

Epoch: 93| Step: 0
Training loss: 2.2468589474418965
Validation loss: 2.5126344189342777

Epoch: 6| Step: 1
Training loss: 2.2824416510152687
Validation loss: 2.513817779724905

Epoch: 6| Step: 2
Training loss: 2.1342718141336228
Validation loss: 2.494055037298311

Epoch: 6| Step: 3
Training loss: 1.911988485409369
Validation loss: 2.4891018634692053

Epoch: 6| Step: 4
Training loss: 2.190778400965335
Validation loss: 2.4854620708486865

Epoch: 6| Step: 5
Training loss: 2.058835907506197
Validation loss: 2.4958967709214233

Epoch: 6| Step: 6
Training loss: 1.7320241030630343
Validation loss: 2.493387824124378

Epoch: 6| Step: 7
Training loss: 1.9084145185811823
Validation loss: 2.4961313912464274

Epoch: 6| Step: 8
Training loss: 2.343267162179159
Validation loss: 2.5058339078763203

Epoch: 6| Step: 9
Training loss: 1.4638565195418907
Validation loss: 2.5334397251810605

Epoch: 6| Step: 10
Training loss: 1.6630588424007593
Validation loss: 2.573761532303607

Epoch: 6| Step: 11
Training loss: 1.717521714096845
Validation loss: 2.5727887964842155

Epoch: 6| Step: 12
Training loss: 1.975571576234566
Validation loss: 2.6117862365201097

Epoch: 6| Step: 13
Training loss: 1.9273861277745359
Validation loss: 2.5964230165117934

Epoch: 94| Step: 0
Training loss: 2.052765269822812
Validation loss: 2.650516785308531

Epoch: 6| Step: 1
Training loss: 2.7065166738445083
Validation loss: 2.5657466232335566

Epoch: 6| Step: 2
Training loss: 1.830442540904682
Validation loss: 2.5441166112902645

Epoch: 6| Step: 3
Training loss: 2.138069911181315
Validation loss: 2.543811773601408

Epoch: 6| Step: 4
Training loss: 1.4637833075638913
Validation loss: 2.4816555277939707

Epoch: 6| Step: 5
Training loss: 2.0007625556617614
Validation loss: 2.477899056357033

Epoch: 6| Step: 6
Training loss: 2.407065612488261
Validation loss: 2.486417286830649

Epoch: 6| Step: 7
Training loss: 2.0737228231735974
Validation loss: 2.470718371679735

Epoch: 6| Step: 8
Training loss: 2.0708364147672493
Validation loss: 2.4692772250014636

Epoch: 6| Step: 9
Training loss: 1.6799225398780249
Validation loss: 2.5212759674959146

Epoch: 6| Step: 10
Training loss: 1.850144241483467
Validation loss: 2.482000243613953

Epoch: 6| Step: 11
Training loss: 2.118992222806332
Validation loss: 2.520343895890247

Epoch: 6| Step: 12
Training loss: 2.0074872298921185
Validation loss: 2.52311532844666

Epoch: 6| Step: 13
Training loss: 1.9347783939118128
Validation loss: 2.5708959781015075

Epoch: 95| Step: 0
Training loss: 2.123266859685844
Validation loss: 2.565837934596648

Epoch: 6| Step: 1
Training loss: 1.8967434581414002
Validation loss: 2.5675940085153424

Epoch: 6| Step: 2
Training loss: 1.9272786290641115
Validation loss: 2.5759035963259773

Epoch: 6| Step: 3
Training loss: 1.7549698966723954
Validation loss: 2.594365135081605

Epoch: 6| Step: 4
Training loss: 2.245788659646403
Validation loss: 2.5699620186686998

Epoch: 6| Step: 5
Training loss: 2.0798852105744343
Validation loss: 2.5893290657022368

Epoch: 6| Step: 6
Training loss: 1.79638943953229
Validation loss: 2.5568583652922183

Epoch: 6| Step: 7
Training loss: 2.0210687034892287
Validation loss: 2.564127072101012

Epoch: 6| Step: 8
Training loss: 2.21627626733764
Validation loss: 2.5160044666254677

Epoch: 6| Step: 9
Training loss: 1.6473117256543375
Validation loss: 2.475847961483573

Epoch: 6| Step: 10
Training loss: 1.8344821437238028
Validation loss: 2.4932232879724494

Epoch: 6| Step: 11
Training loss: 1.6976025842785378
Validation loss: 2.491124930118946

Epoch: 6| Step: 12
Training loss: 1.716117924264084
Validation loss: 2.4822962639355612

Epoch: 6| Step: 13
Training loss: 1.996925374859759
Validation loss: 2.4947056659271385

Epoch: 96| Step: 0
Training loss: 1.6824090245493246
Validation loss: 2.4819522136255205

Epoch: 6| Step: 1
Training loss: 1.3812345132779467
Validation loss: 2.5161633280800815

Epoch: 6| Step: 2
Training loss: 1.8999406805315198
Validation loss: 2.5016716136879222

Epoch: 6| Step: 3
Training loss: 2.986188407508669
Validation loss: 2.5108324289642066

Epoch: 6| Step: 4
Training loss: 2.047353673976535
Validation loss: 2.544410136901728

Epoch: 6| Step: 5
Training loss: 1.7407340243317433
Validation loss: 2.564292513371177

Epoch: 6| Step: 6
Training loss: 1.3787937280493996
Validation loss: 2.5807434040578885

Epoch: 6| Step: 7
Training loss: 1.945773640710185
Validation loss: 2.571141226295482

Epoch: 6| Step: 8
Training loss: 1.8882432547910548
Validation loss: 2.6092950576444975

Epoch: 6| Step: 9
Training loss: 1.8367080045618591
Validation loss: 2.579671222674693

Epoch: 6| Step: 10
Training loss: 1.907365753829408
Validation loss: 2.595511822411901

Epoch: 6| Step: 11
Training loss: 2.213334472533396
Validation loss: 2.588432928880567

Epoch: 6| Step: 12
Training loss: 1.7870892299496413
Validation loss: 2.536378085037357

Epoch: 6| Step: 13
Training loss: 1.9723576385799615
Validation loss: 2.519543788198575

Epoch: 97| Step: 0
Training loss: 1.996620481983323
Validation loss: 2.525773116056476

Epoch: 6| Step: 1
Training loss: 2.2051597559832166
Validation loss: 2.507198016820471

Epoch: 6| Step: 2
Training loss: 1.6953648150410288
Validation loss: 2.465654533025634

Epoch: 6| Step: 3
Training loss: 1.9541986794957342
Validation loss: 2.5092438191242135

Epoch: 6| Step: 4
Training loss: 2.2791061779226878
Validation loss: 2.539133847530221

Epoch: 6| Step: 5
Training loss: 1.9730069594649604
Validation loss: 2.4674842744562575

Epoch: 6| Step: 6
Training loss: 1.9541054667939506
Validation loss: 2.4678922684216094

Epoch: 6| Step: 7
Training loss: 1.4123973842919653
Validation loss: 2.529134227182242

Epoch: 6| Step: 8
Training loss: 2.2189629680883725
Validation loss: 2.525937978182931

Epoch: 6| Step: 9
Training loss: 1.2224623553793053
Validation loss: 2.5012873672828233

Epoch: 6| Step: 10
Training loss: 1.6776231011647902
Validation loss: 2.5860025372734907

Epoch: 6| Step: 11
Training loss: 2.283037504351791
Validation loss: 2.576997545110135

Epoch: 6| Step: 12
Training loss: 1.7146343546522707
Validation loss: 2.5842842741128305

Epoch: 6| Step: 13
Training loss: 2.0007635089723745
Validation loss: 2.556452880991173

Epoch: 98| Step: 0
Training loss: 1.9739515829516079
Validation loss: 2.528505870796938

Epoch: 6| Step: 1
Training loss: 2.0160156581134347
Validation loss: 2.5110420830371623

Epoch: 6| Step: 2
Training loss: 2.172133835113307
Validation loss: 2.5304617890806638

Epoch: 6| Step: 3
Training loss: 1.5992030185359922
Validation loss: 2.5095127794723586

Epoch: 6| Step: 4
Training loss: 1.7749355895485048
Validation loss: 2.4729619934461495

Epoch: 6| Step: 5
Training loss: 1.5323725108748725
Validation loss: 2.470595591420176

Epoch: 6| Step: 6
Training loss: 2.145892380084117
Validation loss: 2.4729778849976394

Epoch: 6| Step: 7
Training loss: 2.9275473954218754
Validation loss: 2.499676588120258

Epoch: 6| Step: 8
Training loss: 1.5127301442991858
Validation loss: 2.4918299850047765

Epoch: 6| Step: 9
Training loss: 1.8022152699883753
Validation loss: 2.508538811421745

Epoch: 6| Step: 10
Training loss: 1.7861281405847182
Validation loss: 2.493665601661365

Epoch: 6| Step: 11
Training loss: 1.4825459505007152
Validation loss: 2.558284657374578

Epoch: 6| Step: 12
Training loss: 1.3251895103243236
Validation loss: 2.5296843596468985

Epoch: 6| Step: 13
Training loss: 1.804788099515348
Validation loss: 2.612896383899561

Epoch: 99| Step: 0
Training loss: 2.184693743544453
Validation loss: 2.6419246116439865

Epoch: 6| Step: 1
Training loss: 1.6242797429099272
Validation loss: 2.644455578546388

Epoch: 6| Step: 2
Training loss: 1.4368940817887945
Validation loss: 2.6510895060861275

Epoch: 6| Step: 3
Training loss: 2.5396786925072896
Validation loss: 2.6298571109755295

Epoch: 6| Step: 4
Training loss: 1.5702128971832032
Validation loss: 2.5854765451420234

Epoch: 6| Step: 5
Training loss: 1.6863126462889186
Validation loss: 2.538753001594616

Epoch: 6| Step: 6
Training loss: 2.0949291495858917
Validation loss: 2.6016681332760214

Epoch: 6| Step: 7
Training loss: 1.1432424325832267
Validation loss: 2.51314148819138

Epoch: 6| Step: 8
Training loss: 1.8398348085222616
Validation loss: 2.5291638667066514

Epoch: 6| Step: 9
Training loss: 2.115818721404772
Validation loss: 2.5463161206356735

Epoch: 6| Step: 10
Training loss: 1.9292290641080743
Validation loss: 2.5083320847906343

Epoch: 6| Step: 11
Training loss: 1.547750976374877
Validation loss: 2.4725159197977185

Epoch: 6| Step: 12
Training loss: 2.1103633119467
Validation loss: 2.5112987145344206

Epoch: 6| Step: 13
Training loss: 2.0665515062589757
Validation loss: 2.535616056636327

Epoch: 100| Step: 0
Training loss: 1.824680572146438
Validation loss: 2.5431464426644954

Epoch: 6| Step: 1
Training loss: 2.0358030495855095
Validation loss: 2.5287110110420117

Epoch: 6| Step: 2
Training loss: 1.6593482351209978
Validation loss: 2.544425472894912

Epoch: 6| Step: 3
Training loss: 2.146009370070565
Validation loss: 2.5451376748584478

Epoch: 6| Step: 4
Training loss: 2.1214229546051016
Validation loss: 2.5516801528607496

Epoch: 6| Step: 5
Training loss: 1.362518490657102
Validation loss: 2.551441553087193

Epoch: 6| Step: 6
Training loss: 1.985558825030437
Validation loss: 2.5212973385680266

Epoch: 6| Step: 7
Training loss: 0.9221609932771895
Validation loss: 2.501755161876149

Epoch: 6| Step: 8
Training loss: 1.2962107508427327
Validation loss: 2.562970947780658

Epoch: 6| Step: 9
Training loss: 2.35233707281335
Validation loss: 2.4989655261766393

Epoch: 6| Step: 10
Training loss: 2.3681672841472934
Validation loss: 2.5064709839464485

Epoch: 6| Step: 11
Training loss: 1.292506847105207
Validation loss: 2.5115770900204923

Epoch: 6| Step: 12
Training loss: 1.99072211730815
Validation loss: 2.538955193232782

Epoch: 6| Step: 13
Training loss: 1.4621627483975626
Validation loss: 2.537230455711746

Epoch: 101| Step: 0
Training loss: 1.3680157577655576
Validation loss: 2.537942336040376

Epoch: 6| Step: 1
Training loss: 1.8550902934347036
Validation loss: 2.522435417444947

Epoch: 6| Step: 2
Training loss: 2.024695399416589
Validation loss: 2.5062892086294797

Epoch: 6| Step: 3
Training loss: 2.2823651867064356
Validation loss: 2.4725749046118852

Epoch: 6| Step: 4
Training loss: 1.864791609854625
Validation loss: 2.5537300376591126

Epoch: 6| Step: 5
Training loss: 2.00937932846054
Validation loss: 2.571843009493296

Epoch: 6| Step: 6
Training loss: 1.7569101687955024
Validation loss: 2.58426792917782

Epoch: 6| Step: 7
Training loss: 1.8448373206973145
Validation loss: 2.5322324392552362

Epoch: 6| Step: 8
Training loss: 1.480676641437219
Validation loss: 2.6147431911116397

Epoch: 6| Step: 9
Training loss: 1.8166636294884915
Validation loss: 2.6563230467083474

Epoch: 6| Step: 10
Training loss: 1.5152815596807883
Validation loss: 2.597954823250202

Epoch: 6| Step: 11
Training loss: 1.900545809801118
Validation loss: 2.608383142485264

Epoch: 6| Step: 12
Training loss: 2.13327300860627
Validation loss: 2.6115998550207777

Epoch: 6| Step: 13
Training loss: 1.2864316044346018
Validation loss: 2.547026241625111

Epoch: 102| Step: 0
Training loss: 1.3293384169982256
Validation loss: 2.5649140934627956

Epoch: 6| Step: 1
Training loss: 1.7134171028043268
Validation loss: 2.472424207489337

Epoch: 6| Step: 2
Training loss: 2.37420128894045
Validation loss: 2.509475156844641

Epoch: 6| Step: 3
Training loss: 1.8065721323587618
Validation loss: 2.5025713889006216

Epoch: 6| Step: 4
Training loss: 2.5786373669670195
Validation loss: 2.535650784025484

Epoch: 6| Step: 5
Training loss: 2.1605507902510968
Validation loss: 2.517756662679586

Epoch: 6| Step: 6
Training loss: 1.5618838812127918
Validation loss: 2.485524725237029

Epoch: 6| Step: 7
Training loss: 1.7330098321000713
Validation loss: 2.5521887517422877

Epoch: 6| Step: 8
Training loss: 1.6874653847994157
Validation loss: 2.5062898348895204

Epoch: 6| Step: 9
Training loss: 1.3317976492264534
Validation loss: 2.5180096430332526

Epoch: 6| Step: 10
Training loss: 1.9137523166236337
Validation loss: 2.538292369933626

Epoch: 6| Step: 11
Training loss: 1.3253605064255132
Validation loss: 2.5958175002503583

Epoch: 6| Step: 12
Training loss: 1.760488820901538
Validation loss: 2.5835831326540575

Epoch: 6| Step: 13
Training loss: 1.4396377921212204
Validation loss: 2.6648376396181463

Epoch: 103| Step: 0
Training loss: 1.7683203724713645
Validation loss: 2.602265958788566

Epoch: 6| Step: 1
Training loss: 1.4306998915628732
Validation loss: 2.6279245766606905

Epoch: 6| Step: 2
Training loss: 1.5474549564591202
Validation loss: 2.591040103359067

Epoch: 6| Step: 3
Training loss: 1.7250904004278842
Validation loss: 2.527455440924602

Epoch: 6| Step: 4
Training loss: 2.519035538989455
Validation loss: 2.5601228527303896

Epoch: 6| Step: 5
Training loss: 1.657494635134569
Validation loss: 2.543487808374295

Epoch: 6| Step: 6
Training loss: 1.54901652976095
Validation loss: 2.5542719791807467

Epoch: 6| Step: 7
Training loss: 1.8850832340472101
Validation loss: 2.5869827386196405

Epoch: 6| Step: 8
Training loss: 1.7495852387610127
Validation loss: 2.546888152480538

Epoch: 6| Step: 9
Training loss: 1.4906869903406201
Validation loss: 2.5128246935791427

Epoch: 6| Step: 10
Training loss: 1.3065862031331712
Validation loss: 2.570711586066922

Epoch: 6| Step: 11
Training loss: 2.020500968526954
Validation loss: 2.5505659665853306

Epoch: 6| Step: 12
Training loss: 1.9652071364624344
Validation loss: 2.507448179851156

Epoch: 6| Step: 13
Training loss: 1.5677187930885057
Validation loss: 2.5502758138752677

Epoch: 104| Step: 0
Training loss: 1.5590989290845554
Validation loss: 2.563084527934623

Epoch: 6| Step: 1
Training loss: 1.4956310542773572
Validation loss: 2.561996379457646

Epoch: 6| Step: 2
Training loss: 1.2823693572906623
Validation loss: 2.524243048083914

Epoch: 6| Step: 3
Training loss: 1.9813100017523313
Validation loss: 2.5867534168516153

Epoch: 6| Step: 4
Training loss: 1.7212666899537492
Validation loss: 2.5458499117080984

Epoch: 6| Step: 5
Training loss: 2.280988704400899
Validation loss: 2.5335103056814554

Epoch: 6| Step: 6
Training loss: 1.3039424390667764
Validation loss: 2.618426326757159

Epoch: 6| Step: 7
Training loss: 1.6691251583083577
Validation loss: 2.64338938160179

Epoch: 6| Step: 8
Training loss: 1.8643329459347462
Validation loss: 2.6173086109891743

Epoch: 6| Step: 9
Training loss: 2.2369698349236624
Validation loss: 2.5702367769506056

Epoch: 6| Step: 10
Training loss: 1.7494425566979304
Validation loss: 2.5406496222735178

Epoch: 6| Step: 11
Training loss: 1.697491770121831
Validation loss: 2.58161221873045

Epoch: 6| Step: 12
Training loss: 1.9369999024800288
Validation loss: 2.535278912962848

Epoch: 6| Step: 13
Training loss: 1.6986414838632942
Validation loss: 2.508559039618374

Epoch: 105| Step: 0
Training loss: 1.815176730208287
Validation loss: 2.5773846728932455

Epoch: 6| Step: 1
Training loss: 1.6796477557071166
Validation loss: 2.5671306421937645

Epoch: 6| Step: 2
Training loss: 1.5607885524492235
Validation loss: 2.5281633780465986

Epoch: 6| Step: 3
Training loss: 1.0452705728421847
Validation loss: 2.498596743307411

Epoch: 6| Step: 4
Training loss: 1.96143787580678
Validation loss: 2.571227647989901

Epoch: 6| Step: 5
Training loss: 1.757656310877806
Validation loss: 2.6017279892104606

Epoch: 6| Step: 6
Training loss: 2.0183470332685856
Validation loss: 2.582000886139347

Epoch: 6| Step: 7
Training loss: 2.4005007737962383
Validation loss: 2.5912487884975017

Epoch: 6| Step: 8
Training loss: 1.522078157059857
Validation loss: 2.576930553519961

Epoch: 6| Step: 9
Training loss: 1.854810610046051
Validation loss: 2.592640528412345

Epoch: 6| Step: 10
Training loss: 1.6442298159851798
Validation loss: 2.543170786155049

Epoch: 6| Step: 11
Training loss: 1.7383023721504627
Validation loss: 2.57836586183505

Epoch: 6| Step: 12
Training loss: 1.9601666884678404
Validation loss: 2.5720725483073186

Epoch: 6| Step: 13
Training loss: 1.5058736243854027
Validation loss: 2.548408545870072

Epoch: 106| Step: 0
Training loss: 1.4638612427695754
Validation loss: 2.5544283518653716

Epoch: 6| Step: 1
Training loss: 1.246070311514235
Validation loss: 2.536507378220864

Epoch: 6| Step: 2
Training loss: 1.7506035036607859
Validation loss: 2.5907776281831003

Epoch: 6| Step: 3
Training loss: 1.5167332952487116
Validation loss: 2.538321926001976

Epoch: 6| Step: 4
Training loss: 1.1360028821344483
Validation loss: 2.5080613025745855

Epoch: 6| Step: 5
Training loss: 2.4945165579363477
Validation loss: 2.5561382906629775

Epoch: 6| Step: 6
Training loss: 1.9347100628631024
Validation loss: 2.5348976446150098

Epoch: 6| Step: 7
Training loss: 1.7724734471407722
Validation loss: 2.540432565243186

Epoch: 6| Step: 8
Training loss: 1.2057597058289364
Validation loss: 2.5432607519243176

Epoch: 6| Step: 9
Training loss: 1.7589983521714552
Validation loss: 2.6535796786451846

Epoch: 6| Step: 10
Training loss: 1.8513760372223607
Validation loss: 2.6651935432441367

Epoch: 6| Step: 11
Training loss: 1.8758809245492551
Validation loss: 2.6757358370823154

Epoch: 6| Step: 12
Training loss: 2.0573508982441133
Validation loss: 2.6927797958561994

Epoch: 6| Step: 13
Training loss: 1.9218589968131357
Validation loss: 2.6681179528058805

Epoch: 107| Step: 0
Training loss: 1.5673313215597902
Validation loss: 2.5650230795086557

Epoch: 6| Step: 1
Training loss: 2.3555962826948718
Validation loss: 2.548662568582561

Epoch: 6| Step: 2
Training loss: 1.7229768969314763
Validation loss: 2.5274512588927793

Epoch: 6| Step: 3
Training loss: 1.8060377610062028
Validation loss: 2.52339761267475

Epoch: 6| Step: 4
Training loss: 1.596427463593286
Validation loss: 2.5521384382461965

Epoch: 6| Step: 5
Training loss: 1.3847878350762073
Validation loss: 2.506860887209873

Epoch: 6| Step: 6
Training loss: 1.5371134853671615
Validation loss: 2.5286951397463504

Epoch: 6| Step: 7
Training loss: 1.2812321824486388
Validation loss: 2.5073758356166596

Epoch: 6| Step: 8
Training loss: 1.522836733006223
Validation loss: 2.5020755576066636

Epoch: 6| Step: 9
Training loss: 1.551207207666643
Validation loss: 2.4636857606927856

Epoch: 6| Step: 10
Training loss: 1.8797751973052987
Validation loss: 2.5757347046419787

Epoch: 6| Step: 11
Training loss: 1.6886740944587688
Validation loss: 2.5855416324322382

Epoch: 6| Step: 12
Training loss: 1.2361359891400119
Validation loss: 2.5614194064745948

Epoch: 6| Step: 13
Training loss: 1.9182369254462248
Validation loss: 2.5737488259350947

Epoch: 108| Step: 0
Training loss: 2.1705518026227
Validation loss: 2.6120598052569575

Epoch: 6| Step: 1
Training loss: 1.6617521626099858
Validation loss: 2.5771457546345924

Epoch: 6| Step: 2
Training loss: 2.301092104159712
Validation loss: 2.584727224005437

Epoch: 6| Step: 3
Training loss: 1.4967505703936628
Validation loss: 2.5736540279617457

Epoch: 6| Step: 4
Training loss: 1.7150702185755473
Validation loss: 2.543369908096922

Epoch: 6| Step: 5
Training loss: 1.6531639858905727
Validation loss: 2.578607656593981

Epoch: 6| Step: 6
Training loss: 1.119499961059079
Validation loss: 2.565017363084866

Epoch: 6| Step: 7
Training loss: 1.1438474728266523
Validation loss: 2.5732994927353743

Epoch: 6| Step: 8
Training loss: 1.7187219790862172
Validation loss: 2.559480485306563

Epoch: 6| Step: 9
Training loss: 1.9229462902009402
Validation loss: 2.4752981044917526

Epoch: 6| Step: 10
Training loss: 1.2701815773476202
Validation loss: 2.585042593117492

Epoch: 6| Step: 11
Training loss: 1.4695013843281945
Validation loss: 2.504357974149494

Epoch: 6| Step: 12
Training loss: 1.4923622867813715
Validation loss: 2.5753599964574967

Epoch: 6| Step: 13
Training loss: 1.6607254309214332
Validation loss: 2.548392672507995

Epoch: 109| Step: 0
Training loss: 1.2792349065084423
Validation loss: 2.602141276789237

Epoch: 6| Step: 1
Training loss: 1.3127176467636965
Validation loss: 2.5592985390966585

Epoch: 6| Step: 2
Training loss: 2.2523309501525066
Validation loss: 2.638068622684704

Epoch: 6| Step: 3
Training loss: 1.7255306699199735
Validation loss: 2.619621943796083

Epoch: 6| Step: 4
Training loss: 1.7180024341925717
Validation loss: 2.611555912693759

Epoch: 6| Step: 5
Training loss: 1.491026261741189
Validation loss: 2.5689045645317297

Epoch: 6| Step: 6
Training loss: 1.4568931370951814
Validation loss: 2.5930615626013966

Epoch: 6| Step: 7
Training loss: 1.5815567623713476
Validation loss: 2.614132243197214

Epoch: 6| Step: 8
Training loss: 1.4932168336254081
Validation loss: 2.597973506359738

Epoch: 6| Step: 9
Training loss: 1.5332053020486136
Validation loss: 2.5514235649274375

Epoch: 6| Step: 10
Training loss: 1.787622797022575
Validation loss: 2.5033179994139743

Epoch: 6| Step: 11
Training loss: 1.2082118214424686
Validation loss: 2.57412113666456

Epoch: 6| Step: 12
Training loss: 1.6789487411781039
Validation loss: 2.5399143609305423

Epoch: 6| Step: 13
Training loss: 1.928156504072262
Validation loss: 2.5034734755636516

Epoch: 110| Step: 0
Training loss: 1.09905216605909
Validation loss: 2.5317758241651465

Epoch: 6| Step: 1
Training loss: 1.619455488671488
Validation loss: 2.5579112222425806

Epoch: 6| Step: 2
Training loss: 1.092621357198503
Validation loss: 2.5899649045596522

Epoch: 6| Step: 3
Training loss: 1.5031068733375417
Validation loss: 2.5428072189070563

Epoch: 6| Step: 4
Training loss: 1.5555791550314497
Validation loss: 2.5541985809008394

Epoch: 6| Step: 5
Training loss: 1.65025771469257
Validation loss: 2.6209343957948947

Epoch: 6| Step: 6
Training loss: 1.38308135614087
Validation loss: 2.6332793684954785

Epoch: 6| Step: 7
Training loss: 2.642151882082702
Validation loss: 2.603708674529755

Epoch: 6| Step: 8
Training loss: 1.6701829137394772
Validation loss: 2.5472173168209555

Epoch: 6| Step: 9
Training loss: 1.6856092527656086
Validation loss: 2.625123278432729

Epoch: 6| Step: 10
Training loss: 1.714017838597806
Validation loss: 2.5156054130723624

Epoch: 6| Step: 11
Training loss: 1.6795320660731718
Validation loss: 2.607483427580863

Epoch: 6| Step: 12
Training loss: 1.5862043184476773
Validation loss: 2.543828925205682

Epoch: 6| Step: 13
Training loss: 1.431135517855713
Validation loss: 2.571805742458387

Epoch: 111| Step: 0
Training loss: 1.3664706285337145
Validation loss: 2.541042287668572

Epoch: 6| Step: 1
Training loss: 1.8054208957960947
Validation loss: 2.5553535736354576

Epoch: 6| Step: 2
Training loss: 2.294208042239557
Validation loss: 2.6037097275711845

Epoch: 6| Step: 3
Training loss: 1.6946323981903384
Validation loss: 2.6273779618910056

Epoch: 6| Step: 4
Training loss: 1.7719525409396633
Validation loss: 2.6481964691820017

Epoch: 6| Step: 5
Training loss: 1.4904844141787972
Validation loss: 2.600703925429683

Epoch: 6| Step: 6
Training loss: 1.1618719291133426
Validation loss: 2.6070900695219517

Epoch: 6| Step: 7
Training loss: 0.8546398100719796
Validation loss: 2.603680257511803

Epoch: 6| Step: 8
Training loss: 1.6825599417133692
Validation loss: 2.613406890601092

Epoch: 6| Step: 9
Training loss: 1.6474127454328795
Validation loss: 2.6084328509552446

Epoch: 6| Step: 10
Training loss: 1.1817158824820797
Validation loss: 2.509359387720931

Epoch: 6| Step: 11
Training loss: 1.6515181983917526
Validation loss: 2.5244154319538112

Epoch: 6| Step: 12
Training loss: 1.4920964238198797
Validation loss: 2.5594451031459657

Epoch: 6| Step: 13
Training loss: 1.6125906512188508
Validation loss: 2.549438933437222

Epoch: 112| Step: 0
Training loss: 1.863137997412686
Validation loss: 2.591518951593525

Epoch: 6| Step: 1
Training loss: 1.592098053131437
Validation loss: 2.569862411343749

Epoch: 6| Step: 2
Training loss: 1.4876646832256242
Validation loss: 2.553009228550346

Epoch: 6| Step: 3
Training loss: 2.202556780322458
Validation loss: 2.5622212173036822

Epoch: 6| Step: 4
Training loss: 1.459908352418376
Validation loss: 2.5164548875319985

Epoch: 6| Step: 5
Training loss: 1.0268177382883363
Validation loss: 2.6057180335928956

Epoch: 6| Step: 6
Training loss: 1.143471080352618
Validation loss: 2.669946684834856

Epoch: 6| Step: 7
Training loss: 1.5032100502744026
Validation loss: 2.624542711178442

Epoch: 6| Step: 8
Training loss: 1.798985113030374
Validation loss: 2.698077949406467

Epoch: 6| Step: 9
Training loss: 1.4508437431322796
Validation loss: 2.6141970578357445

Epoch: 6| Step: 10
Training loss: 1.6303582980695466
Validation loss: 2.6227765733444564

Epoch: 6| Step: 11
Training loss: 1.7929893608820116
Validation loss: 2.6183809206948414

Epoch: 6| Step: 12
Training loss: 1.3109784616611335
Validation loss: 2.473025502801603

Epoch: 6| Step: 13
Training loss: 1.7457185551219014
Validation loss: 2.499346043567725

Epoch: 113| Step: 0
Training loss: 1.506872328728579
Validation loss: 2.5692173132872784

Epoch: 6| Step: 1
Training loss: 1.762882364339512
Validation loss: 2.5546253286217975

Epoch: 6| Step: 2
Training loss: 1.241958693058538
Validation loss: 2.503037467121368

Epoch: 6| Step: 3
Training loss: 2.0058278765707858
Validation loss: 2.556723775694157

Epoch: 6| Step: 4
Training loss: 1.5201566924091472
Validation loss: 2.566901056209904

Epoch: 6| Step: 5
Training loss: 1.2298806374482019
Validation loss: 2.612224568597124

Epoch: 6| Step: 6
Training loss: 1.0168248058795826
Validation loss: 2.5940602894445677

Epoch: 6| Step: 7
Training loss: 1.7281383382824
Validation loss: 2.633434972934243

Epoch: 6| Step: 8
Training loss: 2.1410072152498585
Validation loss: 2.6033732667938176

Epoch: 6| Step: 9
Training loss: 1.335215099950675
Validation loss: 2.62043220975996

Epoch: 6| Step: 10
Training loss: 1.5241775671372908
Validation loss: 2.607438836774769

Epoch: 6| Step: 11
Training loss: 1.9519340851629814
Validation loss: 2.578367788269133

Epoch: 6| Step: 12
Training loss: 1.25286165738073
Validation loss: 2.5757863544617554

Epoch: 6| Step: 13
Training loss: 1.4044258578386082
Validation loss: 2.5015057638558025

Epoch: 114| Step: 0
Training loss: 1.1161085667561916
Validation loss: 2.560706006848905

Epoch: 6| Step: 1
Training loss: 2.2309618937522244
Validation loss: 2.5582995995483393

Epoch: 6| Step: 2
Training loss: 1.2864502302936491
Validation loss: 2.5034123814932614

Epoch: 6| Step: 3
Training loss: 1.6286512582377703
Validation loss: 2.522828649680796

Epoch: 6| Step: 4
Training loss: 1.2400691365380259
Validation loss: 2.5512127903130124

Epoch: 6| Step: 5
Training loss: 1.7420881439753255
Validation loss: 2.4964508135561183

Epoch: 6| Step: 6
Training loss: 1.420179257159828
Validation loss: 2.5796675797018165

Epoch: 6| Step: 7
Training loss: 1.348489166719785
Validation loss: 2.5391216564623127

Epoch: 6| Step: 8
Training loss: 1.6880232388311438
Validation loss: 2.590024823839387

Epoch: 6| Step: 9
Training loss: 1.0272336835607487
Validation loss: 2.6117193841472237

Epoch: 6| Step: 10
Training loss: 1.4572648175674514
Validation loss: 2.62829466342801

Epoch: 6| Step: 11
Training loss: 1.4009580433598863
Validation loss: 2.6059740330555634

Epoch: 6| Step: 12
Training loss: 1.8039762077792607
Validation loss: 2.6159342787669653

Epoch: 6| Step: 13
Training loss: 1.6265919297017535
Validation loss: 2.580186855538374

Epoch: 115| Step: 0
Training loss: 1.167273528211006
Validation loss: 2.5850141399938806

Epoch: 6| Step: 1
Training loss: 2.066079472626121
Validation loss: 2.5726802784260703

Epoch: 6| Step: 2
Training loss: 1.3486138963304999
Validation loss: 2.5203571552909394

Epoch: 6| Step: 3
Training loss: 1.012357708857842
Validation loss: 2.5368777378089744

Epoch: 6| Step: 4
Training loss: 1.9691617020544276
Validation loss: 2.5232526949675957

Epoch: 6| Step: 5
Training loss: 1.2630051706922556
Validation loss: 2.507513977219739

Epoch: 6| Step: 6
Training loss: 1.7971877116224908
Validation loss: 2.561812021586222

Epoch: 6| Step: 7
Training loss: 1.351102541236162
Validation loss: 2.5472449909589883

Epoch: 6| Step: 8
Training loss: 1.3109163994165132
Validation loss: 2.5603951283835302

Epoch: 6| Step: 9
Training loss: 1.5713816177487354
Validation loss: 2.5866737278083236

Epoch: 6| Step: 10
Training loss: 1.7345536973327358
Validation loss: 2.610330966193179

Epoch: 6| Step: 11
Training loss: 1.3902677441435098
Validation loss: 2.5845516521162955

Epoch: 6| Step: 12
Training loss: 1.5029545138107494
Validation loss: 2.648469442739439

Epoch: 6| Step: 13
Training loss: 1.1022796460822064
Validation loss: 2.6008376141673555

Epoch: 116| Step: 0
Training loss: 1.2152097095621444
Validation loss: 2.6111107419286514

Epoch: 6| Step: 1
Training loss: 1.2942092798999465
Validation loss: 2.6084420521740106

Epoch: 6| Step: 2
Training loss: 1.5824420160213846
Validation loss: 2.6305190302582147

Epoch: 6| Step: 3
Training loss: 1.273534478549442
Validation loss: 2.599377758198625

Epoch: 6| Step: 4
Training loss: 1.4359141184965178
Validation loss: 2.5430750358312757

Epoch: 6| Step: 5
Training loss: 1.3236324396424193
Validation loss: 2.5395657397676006

Epoch: 6| Step: 6
Training loss: 1.3134978452184898
Validation loss: 2.512763044084653

Epoch: 6| Step: 7
Training loss: 1.783242967877039
Validation loss: 2.5138743530705585

Epoch: 6| Step: 8
Training loss: 1.0671700896466838
Validation loss: 2.546779669789326

Epoch: 6| Step: 9
Training loss: 1.0449637431375531
Validation loss: 2.5627809696144097

Epoch: 6| Step: 10
Training loss: 1.1419907323424487
Validation loss: 2.5548159599087596

Epoch: 6| Step: 11
Training loss: 2.236299766127505
Validation loss: 2.5748920708169494

Epoch: 6| Step: 12
Training loss: 1.585965912663053
Validation loss: 2.590371777621744

Epoch: 6| Step: 13
Training loss: 1.7601361323941187
Validation loss: 2.618338503558297

Epoch: 117| Step: 0
Training loss: 1.2240428435456776
Validation loss: 2.5811000574141367

Epoch: 6| Step: 1
Training loss: 1.253986771989865
Validation loss: 2.6340654449983476

Epoch: 6| Step: 2
Training loss: 0.9548806140333629
Validation loss: 2.5891293345365822

Epoch: 6| Step: 3
Training loss: 1.649520373715527
Validation loss: 2.5491354025097555

Epoch: 6| Step: 4
Training loss: 1.5733526606638815
Validation loss: 2.523180591272273

Epoch: 6| Step: 5
Training loss: 1.3734520955877971
Validation loss: 2.4961342805806463

Epoch: 6| Step: 6
Training loss: 1.4692842850942103
Validation loss: 2.515567218124814

Epoch: 6| Step: 7
Training loss: 1.0935277440546316
Validation loss: 2.4905118740273298

Epoch: 6| Step: 8
Training loss: 2.0184398779033397
Validation loss: 2.5167798378953057

Epoch: 6| Step: 9
Training loss: 1.3664882070435198
Validation loss: 2.4987820837579617

Epoch: 6| Step: 10
Training loss: 1.4451814334311306
Validation loss: 2.5713671575698065

Epoch: 6| Step: 11
Training loss: 1.3367757565478464
Validation loss: 2.60290095787464

Epoch: 6| Step: 12
Training loss: 1.6604619002871754
Validation loss: 2.5604144968303513

Epoch: 6| Step: 13
Training loss: 1.3571763948727986
Validation loss: 2.6283691069112276

Epoch: 118| Step: 0
Training loss: 1.6150411469499941
Validation loss: 2.576896559768258

Epoch: 6| Step: 1
Training loss: 1.1910950301122312
Validation loss: 2.584515260198353

Epoch: 6| Step: 2
Training loss: 2.1192890168018756
Validation loss: 2.648757705161202

Epoch: 6| Step: 3
Training loss: 1.611020848424069
Validation loss: 2.6176707111108644

Epoch: 6| Step: 4
Training loss: 1.0572183267246877
Validation loss: 2.6073907019267364

Epoch: 6| Step: 5
Training loss: 1.1930774411873548
Validation loss: 2.6480463089759207

Epoch: 6| Step: 6
Training loss: 1.2735039629296063
Validation loss: 2.5632576481427156

Epoch: 6| Step: 7
Training loss: 1.5872884173830841
Validation loss: 2.64629844021748

Epoch: 6| Step: 8
Training loss: 1.5351531438820358
Validation loss: 2.5891011258430434

Epoch: 6| Step: 9
Training loss: 1.4333219764318688
Validation loss: 2.5809444077259176

Epoch: 6| Step: 10
Training loss: 1.2124836065226288
Validation loss: 2.583850998438563

Epoch: 6| Step: 11
Training loss: 1.6888502158720295
Validation loss: 2.543391484107822

Epoch: 6| Step: 12
Training loss: 1.293811857430938
Validation loss: 2.538813018279644

Epoch: 6| Step: 13
Training loss: 0.9827306728534395
Validation loss: 2.5998903385902463

Epoch: 119| Step: 0
Training loss: 1.7265614643352734
Validation loss: 2.594585912125397

Epoch: 6| Step: 1
Training loss: 1.4558761149458088
Validation loss: 2.541312245114677

Epoch: 6| Step: 2
Training loss: 2.2871134405319866
Validation loss: 2.618604938552905

Epoch: 6| Step: 3
Training loss: 1.0669727427711209
Validation loss: 2.6177192868905363

Epoch: 6| Step: 4
Training loss: 1.2806870223851434
Validation loss: 2.6096284176020417

Epoch: 6| Step: 5
Training loss: 1.248754834842582
Validation loss: 2.6556736638748775

Epoch: 6| Step: 6
Training loss: 1.003069101838021
Validation loss: 2.5492380799084695

Epoch: 6| Step: 7
Training loss: 1.2147573949412505
Validation loss: 2.592499213076024

Epoch: 6| Step: 8
Training loss: 1.0599143036803684
Validation loss: 2.561363448880249

Epoch: 6| Step: 9
Training loss: 1.421283808618931
Validation loss: 2.613920581200743

Epoch: 6| Step: 10
Training loss: 1.6143514487172816
Validation loss: 2.65490693938004

Epoch: 6| Step: 11
Training loss: 1.4481285909806576
Validation loss: 2.4663186635433823

Epoch: 6| Step: 12
Training loss: 1.215615226882835
Validation loss: 2.534841321008047

Epoch: 6| Step: 13
Training loss: 1.174991380375839
Validation loss: 2.5266335151237107

Epoch: 120| Step: 0
Training loss: 1.494449598491783
Validation loss: 2.5779161233769354

Epoch: 6| Step: 1
Training loss: 0.8563463421382037
Validation loss: 2.5868518822352753

Epoch: 6| Step: 2
Training loss: 1.5183939857944648
Validation loss: 2.5454762055870885

Epoch: 6| Step: 3
Training loss: 1.7137127668146592
Validation loss: 2.5698565974470755

Epoch: 6| Step: 4
Training loss: 1.2054812655043352
Validation loss: 2.518387030486189

Epoch: 6| Step: 5
Training loss: 2.27065460714982
Validation loss: 2.532463897241881

Epoch: 6| Step: 6
Training loss: 1.220395273681211
Validation loss: 2.544830609488295

Epoch: 6| Step: 7
Training loss: 1.1691840238001028
Validation loss: 2.576121142979394

Epoch: 6| Step: 8
Training loss: 1.1555497394521363
Validation loss: 2.5993704663367305

Epoch: 6| Step: 9
Training loss: 1.040817499541728
Validation loss: 2.578140459110651

Epoch: 6| Step: 10
Training loss: 1.3739788425043735
Validation loss: 2.5852628751800033

Epoch: 6| Step: 11
Training loss: 1.1972854886421915
Validation loss: 2.6242445358186046

Epoch: 6| Step: 12
Training loss: 1.3779309419427537
Validation loss: 2.6101943536112526

Epoch: 6| Step: 13
Training loss: 1.2861928730281544
Validation loss: 2.5733267860090474

Epoch: 121| Step: 0
Training loss: 1.4577131951006455
Validation loss: 2.5970952396210683

Epoch: 6| Step: 1
Training loss: 2.082619761014892
Validation loss: 2.54699641213316

Epoch: 6| Step: 2
Training loss: 1.0160616596239802
Validation loss: 2.4882363755008896

Epoch: 6| Step: 3
Training loss: 1.8692419648476712
Validation loss: 2.5441367752746573

Epoch: 6| Step: 4
Training loss: 0.9628780588564223
Validation loss: 2.565193760786941

Epoch: 6| Step: 5
Training loss: 1.1771273084319926
Validation loss: 2.60378076109996

Epoch: 6| Step: 6
Training loss: 1.299435489305294
Validation loss: 2.4960605179350996

Epoch: 6| Step: 7
Training loss: 1.4445151939345644
Validation loss: 2.590271298352394

Epoch: 6| Step: 8
Training loss: 1.0919127155465278
Validation loss: 2.5724002355885585

Epoch: 6| Step: 9
Training loss: 1.5338988456846574
Validation loss: 2.579249574091868

Epoch: 6| Step: 10
Training loss: 0.9949084241696949
Validation loss: 2.6473610039600746

Epoch: 6| Step: 11
Training loss: 1.4819419596654306
Validation loss: 2.5445308702090084

Epoch: 6| Step: 12
Training loss: 1.132747885078
Validation loss: 2.5288492756701846

Epoch: 6| Step: 13
Training loss: 1.1851866927540207
Validation loss: 2.6275476172984296

Epoch: 122| Step: 0
Training loss: 1.5333740916570913
Validation loss: 2.574466938409326

Epoch: 6| Step: 1
Training loss: 0.860016669954596
Validation loss: 2.543988267141753

Epoch: 6| Step: 2
Training loss: 1.16808571118228
Validation loss: 2.579447274255014

Epoch: 6| Step: 3
Training loss: 2.379009275914597
Validation loss: 2.5751083758611832

Epoch: 6| Step: 4
Training loss: 1.2130227132181834
Validation loss: 2.5913064929222136

Epoch: 6| Step: 5
Training loss: 1.0303919141001963
Validation loss: 2.6065850332978546

Epoch: 6| Step: 6
Training loss: 1.2993349391528703
Validation loss: 2.6031374817694357

Epoch: 6| Step: 7
Training loss: 0.9482077406687373
Validation loss: 2.5860053876588127

Epoch: 6| Step: 8
Training loss: 1.1442608302284996
Validation loss: 2.5724114039036667

Epoch: 6| Step: 9
Training loss: 1.2349356331827799
Validation loss: 2.5383271859441683

Epoch: 6| Step: 10
Training loss: 1.434173300530302
Validation loss: 2.5422803940356764

Epoch: 6| Step: 11
Training loss: 1.0677276361472883
Validation loss: 2.5274914124013104

Epoch: 6| Step: 12
Training loss: 0.9324640437907762
Validation loss: 2.5978388901371243

Epoch: 6| Step: 13
Training loss: 1.4684141870869598
Validation loss: 2.531264175563726

Epoch: 123| Step: 0
Training loss: 1.1623322088912398
Validation loss: 2.5843033866385516

Epoch: 6| Step: 1
Training loss: 1.212514035645094
Validation loss: 2.578715801939888

Epoch: 6| Step: 2
Training loss: 2.120802492268471
Validation loss: 2.5907765698853176

Epoch: 6| Step: 3
Training loss: 1.3514266193860265
Validation loss: 2.5762208939237223

Epoch: 6| Step: 4
Training loss: 1.363408604660402
Validation loss: 2.5701350157582943

Epoch: 6| Step: 5
Training loss: 1.4448076345839775
Validation loss: 2.5835630919716985

Epoch: 6| Step: 6
Training loss: 0.9768469434383497
Validation loss: 2.655955129974018

Epoch: 6| Step: 7
Training loss: 1.0647037316090777
Validation loss: 2.6358024078647015

Epoch: 6| Step: 8
Training loss: 1.2978394380782432
Validation loss: 2.5720969656315176

Epoch: 6| Step: 9
Training loss: 0.8876624777987872
Validation loss: 2.6037538480982043

Epoch: 6| Step: 10
Training loss: 1.2932808029839542
Validation loss: 2.568071449298914

Epoch: 6| Step: 11
Training loss: 1.18589096480631
Validation loss: 2.5469260805464415

Epoch: 6| Step: 12
Training loss: 1.444235240425707
Validation loss: 2.5367654905564616

Epoch: 6| Step: 13
Training loss: 1.4321146722730673
Validation loss: 2.5430722701433552

Epoch: 124| Step: 0
Training loss: 1.6040314043495303
Validation loss: 2.576099393768277

Epoch: 6| Step: 1
Training loss: 1.2380902838040182
Validation loss: 2.5882952833193427

Epoch: 6| Step: 2
Training loss: 1.051150572584688
Validation loss: 2.6743141180342898

Epoch: 6| Step: 3
Training loss: 1.0368604918161053
Validation loss: 2.5760852952453877

Epoch: 6| Step: 4
Training loss: 1.2076565502401801
Validation loss: 2.540385945026806

Epoch: 6| Step: 5
Training loss: 0.8598100428045963
Validation loss: 2.4873486522338135

Epoch: 6| Step: 6
Training loss: 1.1564466463869556
Validation loss: 2.5576356914094145

Epoch: 6| Step: 7
Training loss: 1.1772648269131154
Validation loss: 2.561335182616549

Epoch: 6| Step: 8
Training loss: 1.9087695995990814
Validation loss: 2.589687214182322

Epoch: 6| Step: 9
Training loss: 1.4236062378011682
Validation loss: 2.5714862002747223

Epoch: 6| Step: 10
Training loss: 1.6921826842460546
Validation loss: 2.5974873729297316

Epoch: 6| Step: 11
Training loss: 1.4965631530467163
Validation loss: 2.6513081974330857

Epoch: 6| Step: 12
Training loss: 1.023828329925342
Validation loss: 2.7363516647484456

Epoch: 6| Step: 13
Training loss: 0.8831258572130841
Validation loss: 2.659497433872447

Epoch: 125| Step: 0
Training loss: 1.7707118123563226
Validation loss: 2.718385006896635

Epoch: 6| Step: 1
Training loss: 1.106226792603942
Validation loss: 2.630659707999689

Epoch: 6| Step: 2
Training loss: 1.1177503861725477
Validation loss: 2.548077344363786

Epoch: 6| Step: 3
Training loss: 1.3376339854216766
Validation loss: 2.584202456143948

Epoch: 6| Step: 4
Training loss: 1.5760286211716452
Validation loss: 2.610061859674228

Epoch: 6| Step: 5
Training loss: 0.7597367543518517
Validation loss: 2.5798217430436816

Epoch: 6| Step: 6
Training loss: 0.7918776348163514
Validation loss: 2.54216202354053

Epoch: 6| Step: 7
Training loss: 1.9757290013812125
Validation loss: 2.630112755175088

Epoch: 6| Step: 8
Training loss: 1.168034733468124
Validation loss: 2.5807040637066008

Epoch: 6| Step: 9
Training loss: 0.9363993859894836
Validation loss: 2.573136468268303

Epoch: 6| Step: 10
Training loss: 1.4443293346282473
Validation loss: 2.607284949966255

Epoch: 6| Step: 11
Training loss: 1.466894072907233
Validation loss: 2.6342233562152026

Epoch: 6| Step: 12
Training loss: 1.171139295429069
Validation loss: 2.683229276365189

Epoch: 6| Step: 13
Training loss: 1.2464334150541103
Validation loss: 2.6186919941088465

Epoch: 126| Step: 0
Training loss: 1.1956348358563311
Validation loss: 2.6188969281842462

Epoch: 6| Step: 1
Training loss: 1.3067132447822496
Validation loss: 2.5759730287614846

Epoch: 6| Step: 2
Training loss: 1.433595163620088
Validation loss: 2.6050890598705405

Epoch: 6| Step: 3
Training loss: 1.2102465227120855
Validation loss: 2.589285750616164

Epoch: 6| Step: 4
Training loss: 1.04452330216071
Validation loss: 2.5706597492674335

Epoch: 6| Step: 5
Training loss: 1.228608290144659
Validation loss: 2.601399581741468

Epoch: 6| Step: 6
Training loss: 1.8374878526143374
Validation loss: 2.5405336627127677

Epoch: 6| Step: 7
Training loss: 1.0954326220937183
Validation loss: 2.5920486232107813

Epoch: 6| Step: 8
Training loss: 1.5603085217691623
Validation loss: 2.5761560801575443

Epoch: 6| Step: 9
Training loss: 1.3790125819372923
Validation loss: 2.591358468741594

Epoch: 6| Step: 10
Training loss: 1.3142983967601567
Validation loss: 2.6346306564792306

Epoch: 6| Step: 11
Training loss: 0.9136375026100544
Validation loss: 2.6827541261282857

Epoch: 6| Step: 12
Training loss: 1.068389613196107
Validation loss: 2.6908771528179085

Epoch: 6| Step: 13
Training loss: 1.0838272118260386
Validation loss: 2.634433432248144

Epoch: 127| Step: 0
Training loss: 1.1962990273819665
Validation loss: 2.69552316625574

Epoch: 6| Step: 1
Training loss: 1.0371909818852325
Validation loss: 2.6513436276002045

Epoch: 6| Step: 2
Training loss: 1.2453257905832402
Validation loss: 2.520215302887337

Epoch: 6| Step: 3
Training loss: 1.3444611641384536
Validation loss: 2.558256962865403

Epoch: 6| Step: 4
Training loss: 1.4307379693740805
Validation loss: 2.5545667178409484

Epoch: 6| Step: 5
Training loss: 1.1589304809588168
Validation loss: 2.6507797311661747

Epoch: 6| Step: 6
Training loss: 1.303370650668601
Validation loss: 2.593886467587626

Epoch: 6| Step: 7
Training loss: 1.187381236512066
Validation loss: 2.6594985245893423

Epoch: 6| Step: 8
Training loss: 1.2307856560376762
Validation loss: 2.5535865378972873

Epoch: 6| Step: 9
Training loss: 0.9207378421367104
Validation loss: 2.5623062029492734

Epoch: 6| Step: 10
Training loss: 2.038856700581925
Validation loss: 2.5462945381954816

Epoch: 6| Step: 11
Training loss: 0.7643198839654928
Validation loss: 2.663279995517467

Epoch: 6| Step: 12
Training loss: 1.3350460357443719
Validation loss: 2.83037370955123

Epoch: 6| Step: 13
Training loss: 1.5947095189115261
Validation loss: 2.8589080957427364

Epoch: 128| Step: 0
Training loss: 1.6472512989719332
Validation loss: 2.7414251646293653

Epoch: 6| Step: 1
Training loss: 0.8747873729125907
Validation loss: 2.6376067900771094

Epoch: 6| Step: 2
Training loss: 1.5373336453885513
Validation loss: 2.634674832321105

Epoch: 6| Step: 3
Training loss: 0.8884074058628517
Validation loss: 2.573734228201007

Epoch: 6| Step: 4
Training loss: 1.2760711770310806
Validation loss: 2.538491819756114

Epoch: 6| Step: 5
Training loss: 1.1932036802427575
Validation loss: 2.6279544779537805

Epoch: 6| Step: 6
Training loss: 1.4562356939963792
Validation loss: 2.610138452129167

Epoch: 6| Step: 7
Training loss: 2.2319499907958456
Validation loss: 2.5733916324310155

Epoch: 6| Step: 8
Training loss: 1.0804190071885815
Validation loss: 2.5274111912183477

Epoch: 6| Step: 9
Training loss: 0.8312178741786629
Validation loss: 2.541226299367385

Epoch: 6| Step: 10
Training loss: 1.5292540016839125
Validation loss: 2.5740865963870885

Epoch: 6| Step: 11
Training loss: 1.167385759584467
Validation loss: 2.6373368807907984

Epoch: 6| Step: 12
Training loss: 0.6885044822713187
Validation loss: 2.582794261390274

Epoch: 6| Step: 13
Training loss: 1.4770441632083142
Validation loss: 2.645599915628631

Epoch: 129| Step: 0
Training loss: 0.9049638303093905
Validation loss: 2.584204977916691

Epoch: 6| Step: 1
Training loss: 1.454835930451847
Validation loss: 2.6017541366118575

Epoch: 6| Step: 2
Training loss: 1.338154564877869
Validation loss: 2.5452149486640523

Epoch: 6| Step: 3
Training loss: 1.1995974262801414
Validation loss: 2.5423102319715745

Epoch: 6| Step: 4
Training loss: 1.3023778150070204
Validation loss: 2.6065807952866877

Epoch: 6| Step: 5
Training loss: 1.2647317630608939
Validation loss: 2.6638886515255176

Epoch: 6| Step: 6
Training loss: 0.6813180591988791
Validation loss: 2.5756524145279114

Epoch: 6| Step: 7
Training loss: 2.0035143017183437
Validation loss: 2.621719475165991

Epoch: 6| Step: 8
Training loss: 1.3627740304438087
Validation loss: 2.5658966131316747

Epoch: 6| Step: 9
Training loss: 1.077392771755662
Validation loss: 2.630971950056703

Epoch: 6| Step: 10
Training loss: 1.0419701070689449
Validation loss: 2.5789895659875746

Epoch: 6| Step: 11
Training loss: 1.498856983200284
Validation loss: 2.5970017758366923

Epoch: 6| Step: 12
Training loss: 0.6243460571942965
Validation loss: 2.596139657288819

Epoch: 6| Step: 13
Training loss: 1.1040984918432557
Validation loss: 2.565850401381042

Epoch: 130| Step: 0
Training loss: 0.9973934296395576
Validation loss: 2.6189769795209465

Epoch: 6| Step: 1
Training loss: 1.0755714915662993
Validation loss: 2.566640501590811

Epoch: 6| Step: 2
Training loss: 1.100606896134042
Validation loss: 2.597185701282331

Epoch: 6| Step: 3
Training loss: 1.1509933058761959
Validation loss: 2.622496001001442

Epoch: 6| Step: 4
Training loss: 1.1717993139621428
Validation loss: 2.633682424206128

Epoch: 6| Step: 5
Training loss: 0.9882352313157203
Validation loss: 2.5788415548812793

Epoch: 6| Step: 6
Training loss: 0.9874507746921796
Validation loss: 2.55839008171025

Epoch: 6| Step: 7
Training loss: 1.3879100571658909
Validation loss: 2.590794054749777

Epoch: 6| Step: 8
Training loss: 1.1095395033389324
Validation loss: 2.548677060460377

Epoch: 6| Step: 9
Training loss: 1.160705744533763
Validation loss: 2.596617894120663

Epoch: 6| Step: 10
Training loss: 1.1214408735862222
Validation loss: 2.638093942957818

Epoch: 6| Step: 11
Training loss: 1.2096888842090678
Validation loss: 2.656868926102432

Epoch: 6| Step: 12
Training loss: 2.0903830714723193
Validation loss: 2.6347543741169317

Epoch: 6| Step: 13
Training loss: 0.8113702475679387
Validation loss: 2.66533996441455

Epoch: 131| Step: 0
Training loss: 0.9003812247424834
Validation loss: 2.6572094848637335

Epoch: 6| Step: 1
Training loss: 1.0537973674296033
Validation loss: 2.615859625717528

Epoch: 6| Step: 2
Training loss: 1.7848058978634331
Validation loss: 2.6642143676070287

Epoch: 6| Step: 3
Training loss: 0.9584657467018359
Validation loss: 2.615391797509696

Epoch: 6| Step: 4
Training loss: 0.6535869333749372
Validation loss: 2.530406136212631

Epoch: 6| Step: 5
Training loss: 0.8308086456895857
Validation loss: 2.5539261736345016

Epoch: 6| Step: 6
Training loss: 2.021541104465164
Validation loss: 2.5642816970987017

Epoch: 6| Step: 7
Training loss: 1.1610576582858656
Validation loss: 2.5437593652051382

Epoch: 6| Step: 8
Training loss: 1.2599914821457945
Validation loss: 2.627057782703596

Epoch: 6| Step: 9
Training loss: 1.0279766497501976
Validation loss: 2.573328889933968

Epoch: 6| Step: 10
Training loss: 1.0884628023968197
Validation loss: 2.583701327990786

Epoch: 6| Step: 11
Training loss: 1.2687045648266146
Validation loss: 2.620283157830366

Epoch: 6| Step: 12
Training loss: 1.0363787647676304
Validation loss: 2.6264494270041974

Epoch: 6| Step: 13
Training loss: 1.2338329525378917
Validation loss: 2.7152663672668975

Epoch: 132| Step: 0
Training loss: 1.5357046142856565
Validation loss: 2.6437068463734725

Epoch: 6| Step: 1
Training loss: 1.0159406904946682
Validation loss: 2.644479605519349

Epoch: 6| Step: 2
Training loss: 0.9544011000166451
Validation loss: 2.6231152262129536

Epoch: 6| Step: 3
Training loss: 1.4294544300983019
Validation loss: 2.684932147328391

Epoch: 6| Step: 4
Training loss: 1.107454867939552
Validation loss: 2.585566422036584

Epoch: 6| Step: 5
Training loss: 0.9765467528027247
Validation loss: 2.594331852250761

Epoch: 6| Step: 6
Training loss: 2.0279146246987665
Validation loss: 2.559914703661785

Epoch: 6| Step: 7
Training loss: 1.387822831889989
Validation loss: 2.615728884707288

Epoch: 6| Step: 8
Training loss: 0.8965739286484776
Validation loss: 2.601495262705248

Epoch: 6| Step: 9
Training loss: 0.8461462538218499
Validation loss: 2.6276943820151626

Epoch: 6| Step: 10
Training loss: 1.1500157521039789
Validation loss: 2.7660153359571606

Epoch: 6| Step: 11
Training loss: 1.2090646843435708
Validation loss: 2.696463666174432

Epoch: 6| Step: 12
Training loss: 1.288555022252449
Validation loss: 2.7296715820174455

Epoch: 6| Step: 13
Training loss: 1.3734956661748958
Validation loss: 2.7327338243533363

Epoch: 133| Step: 0
Training loss: 1.3828130172469901
Validation loss: 2.704346221072471

Epoch: 6| Step: 1
Training loss: 0.9666486838465825
Validation loss: 2.621906683165452

Epoch: 6| Step: 2
Training loss: 1.0507375715175546
Validation loss: 2.596301696512436

Epoch: 6| Step: 3
Training loss: 1.0168215818623862
Validation loss: 2.5335418388450917

Epoch: 6| Step: 4
Training loss: 0.9850111222970476
Validation loss: 2.554604423019852

Epoch: 6| Step: 5
Training loss: 1.4409723223133384
Validation loss: 2.577993216180865

Epoch: 6| Step: 6
Training loss: 1.1486488718675478
Validation loss: 2.604212757974275

Epoch: 6| Step: 7
Training loss: 1.0225282663294986
Validation loss: 2.540328257092607

Epoch: 6| Step: 8
Training loss: 2.0473945482460736
Validation loss: 2.538389177298795

Epoch: 6| Step: 9
Training loss: 1.4855099806114862
Validation loss: 2.5163564309738495

Epoch: 6| Step: 10
Training loss: 1.244646433680283
Validation loss: 2.5425665830872886

Epoch: 6| Step: 11
Training loss: 0.9372796117500993
Validation loss: 2.74265136852767

Epoch: 6| Step: 12
Training loss: 0.9859486671456156
Validation loss: 2.7475008590414585

Epoch: 6| Step: 13
Training loss: 1.2019721613911607
Validation loss: 2.8137436836721985

Epoch: 134| Step: 0
Training loss: 2.1048021269737873
Validation loss: 2.8741778843027497

Epoch: 6| Step: 1
Training loss: 1.3895519274013124
Validation loss: 2.729373259162741

Epoch: 6| Step: 2
Training loss: 0.6828434559594193
Validation loss: 2.6830836833500995

Epoch: 6| Step: 3
Training loss: 1.0524709509965824
Validation loss: 2.638116627065118

Epoch: 6| Step: 4
Training loss: 1.1888506887415067
Validation loss: 2.572038629393546

Epoch: 6| Step: 5
Training loss: 1.370726968335566
Validation loss: 2.627240980370896

Epoch: 6| Step: 6
Training loss: 1.10642414123266
Validation loss: 2.608157164948724

Epoch: 6| Step: 7
Training loss: 1.3426788851653337
Validation loss: 2.599733429472572

Epoch: 6| Step: 8
Training loss: 1.2327534128395978
Validation loss: 2.618249554336866

Epoch: 6| Step: 9
Training loss: 0.965998803781673
Validation loss: 2.60299322520608

Epoch: 6| Step: 10
Training loss: 0.9752902173665913
Validation loss: 2.6184383762283945

Epoch: 6| Step: 11
Training loss: 1.2790766635672581
Validation loss: 2.585765667725728

Epoch: 6| Step: 12
Training loss: 1.0794811288934254
Validation loss: 2.606931490271206

Epoch: 6| Step: 13
Training loss: 0.8811664257596387
Validation loss: 2.6459631224710574

Epoch: 135| Step: 0
Training loss: 1.1137448065194613
Validation loss: 2.742924488869093

Epoch: 6| Step: 1
Training loss: 1.501743416103856
Validation loss: 2.7682838231190843

Epoch: 6| Step: 2
Training loss: 0.8557538119339021
Validation loss: 2.6804248177287677

Epoch: 6| Step: 3
Training loss: 1.0350268013105517
Validation loss: 2.7123036895125274

Epoch: 6| Step: 4
Training loss: 1.226687868356613
Validation loss: 2.688647091934351

Epoch: 6| Step: 5
Training loss: 1.4784849861628904
Validation loss: 2.6508648306893994

Epoch: 6| Step: 6
Training loss: 1.0370359233126134
Validation loss: 2.5979015339704064

Epoch: 6| Step: 7
Training loss: 0.8025850403074767
Validation loss: 2.585591426561009

Epoch: 6| Step: 8
Training loss: 0.9986228102286254
Validation loss: 2.526359747821759

Epoch: 6| Step: 9
Training loss: 0.6666188794135287
Validation loss: 2.554403788982504

Epoch: 6| Step: 10
Training loss: 1.1272746508405724
Validation loss: 2.577515192835

Epoch: 6| Step: 11
Training loss: 1.1232704006493064
Validation loss: 2.586318588220048

Epoch: 6| Step: 12
Training loss: 1.9721687545453683
Validation loss: 2.5997883930660017

Epoch: 6| Step: 13
Training loss: 0.9835118642206792
Validation loss: 2.573579267879085

Epoch: 136| Step: 0
Training loss: 0.7250926418965928
Validation loss: 2.619431257894565

Epoch: 6| Step: 1
Training loss: 1.1120045083558334
Validation loss: 2.6692920119523134

Epoch: 6| Step: 2
Training loss: 1.0089058083764715
Validation loss: 2.6185722976638335

Epoch: 6| Step: 3
Training loss: 0.8387603158785445
Validation loss: 2.691088269647161

Epoch: 6| Step: 4
Training loss: 0.8721885472848004
Validation loss: 2.676672986911075

Epoch: 6| Step: 5
Training loss: 1.468342988454804
Validation loss: 2.6090389347478102

Epoch: 6| Step: 6
Training loss: 0.9073816665759761
Validation loss: 2.602856204598423

Epoch: 6| Step: 7
Training loss: 1.009795433799769
Validation loss: 2.5780776819067572

Epoch: 6| Step: 8
Training loss: 0.90285018646818
Validation loss: 2.6478507593227834

Epoch: 6| Step: 9
Training loss: 1.9772364255309198
Validation loss: 2.5375864913055723

Epoch: 6| Step: 10
Training loss: 1.209991971927209
Validation loss: 2.573965937192691

Epoch: 6| Step: 11
Training loss: 1.1790360932232864
Validation loss: 2.6147435254471123

Epoch: 6| Step: 12
Training loss: 0.7435191204842245
Validation loss: 2.6106871848097253

Epoch: 6| Step: 13
Training loss: 1.0540424776366821
Validation loss: 2.589600625956077

Epoch: 137| Step: 0
Training loss: 0.6262881356085361
Validation loss: 2.6252097091467363

Epoch: 6| Step: 1
Training loss: 0.7803212940116205
Validation loss: 2.681951250616079

Epoch: 6| Step: 2
Training loss: 0.9058093282109343
Validation loss: 2.6102010671891147

Epoch: 6| Step: 3
Training loss: 1.0321890861182597
Validation loss: 2.5910557001178653

Epoch: 6| Step: 4
Training loss: 1.2765566766202185
Validation loss: 2.545303390296166

Epoch: 6| Step: 5
Training loss: 1.2733592377935306
Validation loss: 2.6970577910335636

Epoch: 6| Step: 6
Training loss: 1.121185405320747
Validation loss: 2.5959422487174377

Epoch: 6| Step: 7
Training loss: 1.3908942744116994
Validation loss: 2.602577538411646

Epoch: 6| Step: 8
Training loss: 0.9120783341086192
Validation loss: 2.662147079503027

Epoch: 6| Step: 9
Training loss: 1.0337683820646928
Validation loss: 2.666562053496048

Epoch: 6| Step: 10
Training loss: 1.9032071952420841
Validation loss: 2.607731253834673

Epoch: 6| Step: 11
Training loss: 0.9084194787032115
Validation loss: 2.6724531355038645

Epoch: 6| Step: 12
Training loss: 0.9819669181977331
Validation loss: 2.6548497866458516

Epoch: 6| Step: 13
Training loss: 0.6415154386225073
Validation loss: 2.6068234789267595

Epoch: 138| Step: 0
Training loss: 1.1105012146978763
Validation loss: 2.606273056099053

Epoch: 6| Step: 1
Training loss: 0.8029441837755045
Validation loss: 2.605868543828808

Epoch: 6| Step: 2
Training loss: 0.8714096112500243
Validation loss: 2.617846596696034

Epoch: 6| Step: 3
Training loss: 1.0647686691850835
Validation loss: 2.555281543784436

Epoch: 6| Step: 4
Training loss: 0.8793710793392188
Validation loss: 2.604082858962316

Epoch: 6| Step: 5
Training loss: 0.639806177622099
Validation loss: 2.664312058260961

Epoch: 6| Step: 6
Training loss: 1.7981523700390563
Validation loss: 2.591134449280439

Epoch: 6| Step: 7
Training loss: 0.9992969843202528
Validation loss: 2.591908425424584

Epoch: 6| Step: 8
Training loss: 0.7658382041065068
Validation loss: 2.5849274413490977

Epoch: 6| Step: 9
Training loss: 1.2665535616988726
Validation loss: 2.615225304038717

Epoch: 6| Step: 10
Training loss: 0.7839063118015909
Validation loss: 2.6014622391176805

Epoch: 6| Step: 11
Training loss: 1.412914505625701
Validation loss: 2.5977286651384293

Epoch: 6| Step: 12
Training loss: 0.9736738894568082
Validation loss: 2.5858517543256654

Epoch: 6| Step: 13
Training loss: 1.0035315382049521
Validation loss: 2.633345160477874

Epoch: 139| Step: 0
Training loss: 0.9708478731422764
Validation loss: 2.6497112575707207

Epoch: 6| Step: 1
Training loss: 1.1768850423958734
Validation loss: 2.669522206945437

Epoch: 6| Step: 2
Training loss: 1.366626602647833
Validation loss: 2.638357464223536

Epoch: 6| Step: 3
Training loss: 0.9891360660812787
Validation loss: 2.5999747501272066

Epoch: 6| Step: 4
Training loss: 0.8072697954394084
Validation loss: 2.599065275164406

Epoch: 6| Step: 5
Training loss: 0.9347892034532335
Validation loss: 2.605730057957098

Epoch: 6| Step: 6
Training loss: 0.8285832486754148
Validation loss: 2.62851974117361

Epoch: 6| Step: 7
Training loss: 1.812708480946606
Validation loss: 2.6070747058642945

Epoch: 6| Step: 8
Training loss: 0.6910132029109791
Validation loss: 2.6198875505762045

Epoch: 6| Step: 9
Training loss: 1.0279113593941875
Validation loss: 2.653423750509339

Epoch: 6| Step: 10
Training loss: 0.9877239963137384
Validation loss: 2.644033410503268

Epoch: 6| Step: 11
Training loss: 1.091427216707329
Validation loss: 2.6201891335320298

Epoch: 6| Step: 12
Training loss: 1.2069019137225814
Validation loss: 2.5932731649713263

Epoch: 6| Step: 13
Training loss: 1.0430685274209544
Validation loss: 2.5424999971117828

Epoch: 140| Step: 0
Training loss: 0.8846045341113309
Validation loss: 2.5397558586052282

Epoch: 6| Step: 1
Training loss: 0.7753710227813877
Validation loss: 2.5607383068696286

Epoch: 6| Step: 2
Training loss: 0.6669814638138672
Validation loss: 2.603443676087215

Epoch: 6| Step: 3
Training loss: 1.5010246909472382
Validation loss: 2.559271243720551

Epoch: 6| Step: 4
Training loss: 0.9193068471163305
Validation loss: 2.5854915607024247

Epoch: 6| Step: 5
Training loss: 0.8795333659515436
Validation loss: 2.6027723063525983

Epoch: 6| Step: 6
Training loss: 0.9849671596048422
Validation loss: 2.665267686646414

Epoch: 6| Step: 7
Training loss: 0.925019284640151
Validation loss: 2.594636152934709

Epoch: 6| Step: 8
Training loss: 1.1310225453039562
Validation loss: 2.685875660508232

Epoch: 6| Step: 9
Training loss: 1.7247254277513862
Validation loss: 2.6374521172803798

Epoch: 6| Step: 10
Training loss: 0.8136417729472556
Validation loss: 2.6176844186799846

Epoch: 6| Step: 11
Training loss: 1.1007930692710985
Validation loss: 2.5636823764105254

Epoch: 6| Step: 12
Training loss: 1.1597601217497158
Validation loss: 2.5920038895195163

Epoch: 6| Step: 13
Training loss: 0.8316987138764598
Validation loss: 2.6305432751601785

Epoch: 141| Step: 0
Training loss: 1.0933027170321796
Validation loss: 2.5781677396680283

Epoch: 6| Step: 1
Training loss: 1.2042768340000736
Validation loss: 2.6020555611302427

Epoch: 6| Step: 2
Training loss: 0.8229552432969488
Validation loss: 2.6318396214994313

Epoch: 6| Step: 3
Training loss: 0.7287249226124054
Validation loss: 2.6289059476960883

Epoch: 6| Step: 4
Training loss: 0.8738149042540502
Validation loss: 2.59340383525357

Epoch: 6| Step: 5
Training loss: 0.8173422672329016
Validation loss: 2.701102909836043

Epoch: 6| Step: 6
Training loss: 0.5962401923886491
Validation loss: 2.6172175239624824

Epoch: 6| Step: 7
Training loss: 0.9141657844291146
Validation loss: 2.6326669111286334

Epoch: 6| Step: 8
Training loss: 0.6386630556390068
Validation loss: 2.579284006714754

Epoch: 6| Step: 9
Training loss: 1.274628252175471
Validation loss: 2.636961176524138

Epoch: 6| Step: 10
Training loss: 1.159059822036229
Validation loss: 2.600351748759191

Epoch: 6| Step: 11
Training loss: 1.914145393912133
Validation loss: 2.5948502838076393

Epoch: 6| Step: 12
Training loss: 1.1295599183446885
Validation loss: 2.6414129973758547

Epoch: 6| Step: 13
Training loss: 0.886015087679495
Validation loss: 2.5978049252443727

Epoch: 142| Step: 0
Training loss: 1.1739210450626114
Validation loss: 2.645069768066016

Epoch: 6| Step: 1
Training loss: 0.7559305004790886
Validation loss: 2.617076617117248

Epoch: 6| Step: 2
Training loss: 0.8189766315391436
Validation loss: 2.681292143329718

Epoch: 6| Step: 3
Training loss: 1.7623775629032654
Validation loss: 2.621539438543147

Epoch: 6| Step: 4
Training loss: 0.8129470768931404
Validation loss: 2.632097881164815

Epoch: 6| Step: 5
Training loss: 1.0613186944985538
Validation loss: 2.6327354502888207

Epoch: 6| Step: 6
Training loss: 0.8793178018649661
Validation loss: 2.6490503162930215

Epoch: 6| Step: 7
Training loss: 0.9448337130599359
Validation loss: 2.606456639844212

Epoch: 6| Step: 8
Training loss: 1.1482504348471674
Validation loss: 2.6162876992654223

Epoch: 6| Step: 9
Training loss: 1.384312435828899
Validation loss: 2.6576979486686643

Epoch: 6| Step: 10
Training loss: 0.9890850552703458
Validation loss: 2.5917965070412325

Epoch: 6| Step: 11
Training loss: 0.8499238232529706
Validation loss: 2.680703714676186

Epoch: 6| Step: 12
Training loss: 1.159266840575709
Validation loss: 2.639182424671895

Epoch: 6| Step: 13
Training loss: 0.5283055893967158
Validation loss: 2.613479766376203

Epoch: 143| Step: 0
Training loss: 0.9337852632740115
Validation loss: 2.7049432860920253

Epoch: 6| Step: 1
Training loss: 0.5657613832219452
Validation loss: 2.6585108989697597

Epoch: 6| Step: 2
Training loss: 0.9957339066917619
Validation loss: 2.6916297557728974

Epoch: 6| Step: 3
Training loss: 1.4191222320129124
Validation loss: 2.749488017077665

Epoch: 6| Step: 4
Training loss: 1.702351735811029
Validation loss: 2.644348754295753

Epoch: 6| Step: 5
Training loss: 0.9916690763609858
Validation loss: 2.6850530144864218

Epoch: 6| Step: 6
Training loss: 0.6248679021473036
Validation loss: 2.6593215237719705

Epoch: 6| Step: 7
Training loss: 0.5409984379320986
Validation loss: 2.604354932973359

Epoch: 6| Step: 8
Training loss: 0.9949843867433177
Validation loss: 2.622367386472654

Epoch: 6| Step: 9
Training loss: 0.7692702572113821
Validation loss: 2.6492669411163443

Epoch: 6| Step: 10
Training loss: 1.5596519453627558
Validation loss: 2.6273072411765197

Epoch: 6| Step: 11
Training loss: 0.9342005844378987
Validation loss: 2.554477445811345

Epoch: 6| Step: 12
Training loss: 0.9579226021391266
Validation loss: 2.5988832257769827

Epoch: 6| Step: 13
Training loss: 0.9329205563833142
Validation loss: 2.637319621626956

Epoch: 144| Step: 0
Training loss: 1.1426236657090092
Validation loss: 2.5883711228454236

Epoch: 6| Step: 1
Training loss: 1.9113896606194407
Validation loss: 2.608298698374092

Epoch: 6| Step: 2
Training loss: 0.7206467190304081
Validation loss: 2.692689173696053

Epoch: 6| Step: 3
Training loss: 1.2991679499931597
Validation loss: 2.660567383964133

Epoch: 6| Step: 4
Training loss: 1.1986615504946663
Validation loss: 2.6677704007099132

Epoch: 6| Step: 5
Training loss: 0.8474783996485035
Validation loss: 2.600176299671382

Epoch: 6| Step: 6
Training loss: 0.7078741960394644
Validation loss: 2.6833398246291726

Epoch: 6| Step: 7
Training loss: 0.6966353915425332
Validation loss: 2.6507326456866784

Epoch: 6| Step: 8
Training loss: 1.0474777763758727
Validation loss: 2.5786861386992324

Epoch: 6| Step: 9
Training loss: 0.6343672690836561
Validation loss: 2.653602761969453

Epoch: 6| Step: 10
Training loss: 0.5679110302252417
Validation loss: 2.583474122076981

Epoch: 6| Step: 11
Training loss: 0.7788396273083217
Validation loss: 2.6054837418505703

Epoch: 6| Step: 12
Training loss: 1.1889181202318353
Validation loss: 2.5394640952186633

Epoch: 6| Step: 13
Training loss: 1.0304745157006772
Validation loss: 2.577533399733659

Epoch: 145| Step: 0
Training loss: 1.0948373022225781
Validation loss: 2.6177474756093573

Epoch: 6| Step: 1
Training loss: 0.9322745607536537
Validation loss: 2.651212950283791

Epoch: 6| Step: 2
Training loss: 0.9028031802067753
Validation loss: 2.6794671059774893

Epoch: 6| Step: 3
Training loss: 0.7003894999506223
Validation loss: 2.6550202907833365

Epoch: 6| Step: 4
Training loss: 1.7718526337572669
Validation loss: 2.7122449113290177

Epoch: 6| Step: 5
Training loss: 0.9164756807138112
Validation loss: 2.6312053087657055

Epoch: 6| Step: 6
Training loss: 1.17188893627781
Validation loss: 2.627004826638452

Epoch: 6| Step: 7
Training loss: 0.9145891677450213
Validation loss: 2.6642528775413696

Epoch: 6| Step: 8
Training loss: 0.8416679265859509
Validation loss: 2.558918442641281

Epoch: 6| Step: 9
Training loss: 0.8540705223558152
Validation loss: 2.655176850994404

Epoch: 6| Step: 10
Training loss: 1.1949309195020008
Validation loss: 2.581584189566717

Epoch: 6| Step: 11
Training loss: 0.7806368138050812
Validation loss: 2.5687743960024156

Epoch: 6| Step: 12
Training loss: 0.6890094831835554
Validation loss: 2.5526814025970967

Epoch: 6| Step: 13
Training loss: 0.5292973817492097
Validation loss: 2.536261663834656

Epoch: 146| Step: 0
Training loss: 0.7104263983663104
Validation loss: 2.5723351247363615

Epoch: 6| Step: 1
Training loss: 1.0890053973558973
Validation loss: 2.6260460177280485

Epoch: 6| Step: 2
Training loss: 1.1139971656420826
Validation loss: 2.5450228800116745

Epoch: 6| Step: 3
Training loss: 0.734076703138402
Validation loss: 2.6714770520801507

Epoch: 6| Step: 4
Training loss: 1.0103096004011443
Validation loss: 2.6325581292825646

Epoch: 6| Step: 5
Training loss: 0.9425048116667382
Validation loss: 2.590101287756329

Epoch: 6| Step: 6
Training loss: 0.9051009490156819
Validation loss: 2.703152636201152

Epoch: 6| Step: 7
Training loss: 0.7912709518720046
Validation loss: 2.692660205246169

Epoch: 6| Step: 8
Training loss: 0.7789337535964871
Validation loss: 2.6808296045955884

Epoch: 6| Step: 9
Training loss: 1.7903626893929376
Validation loss: 2.654692159360105

Epoch: 6| Step: 10
Training loss: 0.5784376690749422
Validation loss: 2.629397447939229

Epoch: 6| Step: 11
Training loss: 0.9471714248224463
Validation loss: 2.6957488513033603

Epoch: 6| Step: 12
Training loss: 1.1681370438495224
Validation loss: 2.6839206872137837

Epoch: 6| Step: 13
Training loss: 0.6025476686923366
Validation loss: 2.6089452362970578

Epoch: 147| Step: 0
Training loss: 0.6236505483798777
Validation loss: 2.5908649285926635

Epoch: 6| Step: 1
Training loss: 0.9770366890733168
Validation loss: 2.5931905579755905

Epoch: 6| Step: 2
Training loss: 1.208774579260791
Validation loss: 2.679325995050869

Epoch: 6| Step: 3
Training loss: 1.3628004040407613
Validation loss: 2.585340663418831

Epoch: 6| Step: 4
Training loss: 0.6128700724572296
Validation loss: 2.5772196095073214

Epoch: 6| Step: 5
Training loss: 0.8989904940890779
Validation loss: 2.597406039700147

Epoch: 6| Step: 6
Training loss: 0.9596715512281128
Validation loss: 2.610792129277504

Epoch: 6| Step: 7
Training loss: 0.7835838553050195
Validation loss: 2.648734692128311

Epoch: 6| Step: 8
Training loss: 0.8307601101811415
Validation loss: 2.5980307249367263

Epoch: 6| Step: 9
Training loss: 1.765931296998381
Validation loss: 2.639899250044312

Epoch: 6| Step: 10
Training loss: 0.7816900158575767
Validation loss: 2.5661082334236873

Epoch: 6| Step: 11
Training loss: 0.548819925375942
Validation loss: 2.6846023433694493

Epoch: 6| Step: 12
Training loss: 1.1574062030927257
Validation loss: 2.655521651995502

Epoch: 6| Step: 13
Training loss: 0.7494699671544984
Validation loss: 2.4886031089873866

Epoch: 148| Step: 0
Training loss: 0.867354540159042
Validation loss: 2.54791853107458

Epoch: 6| Step: 1
Training loss: 0.7036398803850664
Validation loss: 2.6490468962327083

Epoch: 6| Step: 2
Training loss: 1.922465908110383
Validation loss: 2.6124427564028987

Epoch: 6| Step: 3
Training loss: 0.7058146003915511
Validation loss: 2.572426773773947

Epoch: 6| Step: 4
Training loss: 1.0990054164159448
Validation loss: 2.6070693559979645

Epoch: 6| Step: 5
Training loss: 0.8595053833975419
Validation loss: 2.6328413421228287

Epoch: 6| Step: 6
Training loss: 0.602930717603312
Validation loss: 2.597344714918043

Epoch: 6| Step: 7
Training loss: 0.8428390318273263
Validation loss: 2.680976831826703

Epoch: 6| Step: 8
Training loss: 0.6253023369996034
Validation loss: 2.6797175132323714

Epoch: 6| Step: 9
Training loss: 1.062786400285799
Validation loss: 2.6038830768032097

Epoch: 6| Step: 10
Training loss: 0.9431987491437595
Validation loss: 2.687027645739754

Epoch: 6| Step: 11
Training loss: 1.0020857159962286
Validation loss: 2.666580993547681

Epoch: 6| Step: 12
Training loss: 0.6579901466704399
Validation loss: 2.6281419902408056

Epoch: 6| Step: 13
Training loss: 0.6475784862479106
Validation loss: 2.603847214496629

Epoch: 149| Step: 0
Training loss: 0.7209158896062562
Validation loss: 2.6277436646910237

Epoch: 6| Step: 1
Training loss: 1.0982142214714146
Validation loss: 2.661338405308385

Epoch: 6| Step: 2
Training loss: 0.855815660343117
Validation loss: 2.671535001839251

Epoch: 6| Step: 3
Training loss: 0.7939622790411148
Validation loss: 2.590482990589219

Epoch: 6| Step: 4
Training loss: 0.7202065677490603
Validation loss: 2.657850777965062

Epoch: 6| Step: 5
Training loss: 0.8772536274793392
Validation loss: 2.66816419534376

Epoch: 6| Step: 6
Training loss: 0.6361909094315416
Validation loss: 2.5769724571987433

Epoch: 6| Step: 7
Training loss: 2.011391029700374
Validation loss: 2.723594310548087

Epoch: 6| Step: 8
Training loss: 0.9986655749373162
Validation loss: 2.7271294500785546

Epoch: 6| Step: 9
Training loss: 0.9219597599698162
Validation loss: 2.7310989227528197

Epoch: 6| Step: 10
Training loss: 0.8381521532636952
Validation loss: 2.7322739003677987

Epoch: 6| Step: 11
Training loss: 0.5239648866591214
Validation loss: 2.734118073518105

Epoch: 6| Step: 12
Training loss: 0.6228939335054715
Validation loss: 2.6186495971854966

Epoch: 6| Step: 13
Training loss: 0.9564982272828142
Validation loss: 2.6192539540463335

Epoch: 150| Step: 0
Training loss: 0.8558320967811732
Validation loss: 2.545900887957721

Epoch: 6| Step: 1
Training loss: 0.8456498408986223
Validation loss: 2.6194709192176173

Epoch: 6| Step: 2
Training loss: 1.0716713403231057
Validation loss: 2.582469877921031

Epoch: 6| Step: 3
Training loss: 1.0625103781698166
Validation loss: 2.558433640301896

Epoch: 6| Step: 4
Training loss: 1.7472926723843776
Validation loss: 2.5632742355670812

Epoch: 6| Step: 5
Training loss: 1.0409356349537844
Validation loss: 2.620785963745281

Epoch: 6| Step: 6
Training loss: 0.6747128635319506
Validation loss: 2.5750287353739387

Epoch: 6| Step: 7
Training loss: 0.8448496117026053
Validation loss: 2.635740227620227

Epoch: 6| Step: 8
Training loss: 0.7027188717635926
Validation loss: 2.7085078012073454

Epoch: 6| Step: 9
Training loss: 0.8307520385910033
Validation loss: 2.729656187713847

Epoch: 6| Step: 10
Training loss: 0.8145866010231241
Validation loss: 2.6402722486125594

Epoch: 6| Step: 11
Training loss: 1.1868337970992193
Validation loss: 2.6251345554561345

Epoch: 6| Step: 12
Training loss: 0.8086087137947756
Validation loss: 2.606136558619181

Epoch: 6| Step: 13
Training loss: 0.5718802759312801
Validation loss: 2.585515090540309

Epoch: 151| Step: 0
Training loss: 0.9576926301060589
Validation loss: 2.533111484333723

Epoch: 6| Step: 1
Training loss: 0.8354740462412635
Validation loss: 2.6846601578253306

Epoch: 6| Step: 2
Training loss: 0.7552057638891949
Validation loss: 2.5670721621384587

Epoch: 6| Step: 3
Training loss: 0.9061721571014068
Validation loss: 2.6277339942296356

Epoch: 6| Step: 4
Training loss: 0.46772565179492226
Validation loss: 2.603204508739155

Epoch: 6| Step: 5
Training loss: 0.7069180645628887
Validation loss: 2.6140824606939583

Epoch: 6| Step: 6
Training loss: 0.9297342689354724
Validation loss: 2.625300163182843

Epoch: 6| Step: 7
Training loss: 0.702318746526942
Validation loss: 2.560152319745161

Epoch: 6| Step: 8
Training loss: 0.6680134986924083
Validation loss: 2.68189863763647

Epoch: 6| Step: 9
Training loss: 0.767717576887848
Validation loss: 2.6564921848367167

Epoch: 6| Step: 10
Training loss: 1.715325707071853
Validation loss: 2.6424506834078385

Epoch: 6| Step: 11
Training loss: 0.8965445438048152
Validation loss: 2.656860760052602

Epoch: 6| Step: 12
Training loss: 0.8713165135218314
Validation loss: 2.650991238237462

Epoch: 6| Step: 13
Training loss: 1.0791622645363197
Validation loss: 2.636019736987421

Epoch: 152| Step: 0
Training loss: 1.6365652809024747
Validation loss: 2.6429864079788272

Epoch: 6| Step: 1
Training loss: 0.6341819309656648
Validation loss: 2.6500028562230487

Epoch: 6| Step: 2
Training loss: 0.9346100769831142
Validation loss: 2.629135915351698

Epoch: 6| Step: 3
Training loss: 0.8955251843879701
Validation loss: 2.642945738882154

Epoch: 6| Step: 4
Training loss: 0.7534590269262509
Validation loss: 2.61149144333639

Epoch: 6| Step: 5
Training loss: 0.9053096496516092
Validation loss: 2.635553436851597

Epoch: 6| Step: 6
Training loss: 0.5461515818959144
Validation loss: 2.641756962537623

Epoch: 6| Step: 7
Training loss: 0.5196537074275117
Validation loss: 2.6752173950415754

Epoch: 6| Step: 8
Training loss: 1.1849069895236595
Validation loss: 2.6116173069794555

Epoch: 6| Step: 9
Training loss: 0.7617846338194045
Validation loss: 2.6075544573618994

Epoch: 6| Step: 10
Training loss: 0.6061064284695726
Validation loss: 2.7191851622076864

Epoch: 6| Step: 11
Training loss: 0.6614527188961418
Validation loss: 2.74201303997598

Epoch: 6| Step: 12
Training loss: 0.9170754814302879
Validation loss: 2.7210239970616295

Epoch: 6| Step: 13
Training loss: 0.7112054843749054
Validation loss: 2.6209841542798933

Epoch: 153| Step: 0
Training loss: 0.740111006066015
Validation loss: 2.6385113987100848

Epoch: 6| Step: 1
Training loss: 1.1516939044239596
Validation loss: 2.6824783754025225

Epoch: 6| Step: 2
Training loss: 0.7562601766610925
Validation loss: 2.7012880437791282

Epoch: 6| Step: 3
Training loss: 0.858053127093419
Validation loss: 2.6650885939290654

Epoch: 6| Step: 4
Training loss: 0.8176803503087664
Validation loss: 2.556684905024019

Epoch: 6| Step: 5
Training loss: 0.844699219718691
Validation loss: 2.5674993856863284

Epoch: 6| Step: 6
Training loss: 0.7108342022310994
Validation loss: 2.6368978858660457

Epoch: 6| Step: 7
Training loss: 0.583115943069693
Validation loss: 2.6984842849678152

Epoch: 6| Step: 8
Training loss: 0.9725260819808673
Validation loss: 2.723420935598845

Epoch: 6| Step: 9
Training loss: 1.3439546030103464
Validation loss: 2.7100808790086375

Epoch: 6| Step: 10
Training loss: 1.7210220578257993
Validation loss: 2.7258051318610033

Epoch: 6| Step: 11
Training loss: 0.5339872302946648
Validation loss: 2.640381164127496

Epoch: 6| Step: 12
Training loss: 0.8315278442225902
Validation loss: 2.6138594386430025

Epoch: 6| Step: 13
Training loss: 0.8058283228029723
Validation loss: 2.6276222029269536

Epoch: 154| Step: 0
Training loss: 0.6150716172751899
Validation loss: 2.6334981506613486

Epoch: 6| Step: 1
Training loss: 1.0415027044318839
Validation loss: 2.646783512940908

Epoch: 6| Step: 2
Training loss: 0.5838702291229623
Validation loss: 2.616492548290401

Epoch: 6| Step: 3
Training loss: 1.1635153079597575
Validation loss: 2.5995004785410956

Epoch: 6| Step: 4
Training loss: 0.5400406076916185
Validation loss: 2.633264172728256

Epoch: 6| Step: 5
Training loss: 1.677569024816288
Validation loss: 2.56947183823517

Epoch: 6| Step: 6
Training loss: 1.0423056677036076
Validation loss: 2.626517735057623

Epoch: 6| Step: 7
Training loss: 0.7688192956597895
Validation loss: 2.677398430553734

Epoch: 6| Step: 8
Training loss: 0.8028047628241469
Validation loss: 2.7481046560756432

Epoch: 6| Step: 9
Training loss: 0.7109111739094632
Validation loss: 2.622411738590216

Epoch: 6| Step: 10
Training loss: 0.981551769043694
Validation loss: 2.6622160089993807

Epoch: 6| Step: 11
Training loss: 0.7400009068921692
Validation loss: 2.646341565397507

Epoch: 6| Step: 12
Training loss: 0.6387748518586458
Validation loss: 2.699106408232026

Epoch: 6| Step: 13
Training loss: 0.6900230839917588
Validation loss: 2.633051664241308

Epoch: 155| Step: 0
Training loss: 0.6641258209556591
Validation loss: 2.692514649932497

Epoch: 6| Step: 1
Training loss: 1.2383512362849924
Validation loss: 2.676157978203485

Epoch: 6| Step: 2
Training loss: 0.8479300553360625
Validation loss: 2.6209271335847846

Epoch: 6| Step: 3
Training loss: 0.6038701272403468
Validation loss: 2.6723383302857986

Epoch: 6| Step: 4
Training loss: 0.8062745526737438
Validation loss: 2.58597866613346

Epoch: 6| Step: 5
Training loss: 0.9375412296130095
Validation loss: 2.6888830337469423

Epoch: 6| Step: 6
Training loss: 0.7417721037623233
Validation loss: 2.7197038139337

Epoch: 6| Step: 7
Training loss: 0.45721909338884964
Validation loss: 2.6843950240513736

Epoch: 6| Step: 8
Training loss: 0.562314691749398
Validation loss: 2.677722384599644

Epoch: 6| Step: 9
Training loss: 1.1568110367843358
Validation loss: 2.7427499743086

Epoch: 6| Step: 10
Training loss: 1.7016481067991611
Validation loss: 2.669523695467191

Epoch: 6| Step: 11
Training loss: 0.8881891637357989
Validation loss: 2.678090590052288

Epoch: 6| Step: 12
Training loss: 0.7645854899681782
Validation loss: 2.627274920147755

Epoch: 6| Step: 13
Training loss: 0.5997248982530832
Validation loss: 2.6546193671506457

Epoch: 156| Step: 0
Training loss: 0.7667968889917576
Validation loss: 2.712142192955744

Epoch: 6| Step: 1
Training loss: 0.8056820029370892
Validation loss: 2.6604674423817074

Epoch: 6| Step: 2
Training loss: 0.8353966362534544
Validation loss: 2.626317087388131

Epoch: 6| Step: 3
Training loss: 0.5932180129541327
Validation loss: 2.6102381285683753

Epoch: 6| Step: 4
Training loss: 1.043968093380853
Validation loss: 2.6046169247798123

Epoch: 6| Step: 5
Training loss: 0.7830613309973443
Validation loss: 2.6633365421331536

Epoch: 6| Step: 6
Training loss: 0.5046442231794325
Validation loss: 2.6302904978593276

Epoch: 6| Step: 7
Training loss: 0.769841591468295
Validation loss: 2.6294237131089178

Epoch: 6| Step: 8
Training loss: 1.5975718580868588
Validation loss: 2.644164517779779

Epoch: 6| Step: 9
Training loss: 0.7623621253136612
Validation loss: 2.7010799602869233

Epoch: 6| Step: 10
Training loss: 1.1601711490586344
Validation loss: 2.6234966090414096

Epoch: 6| Step: 11
Training loss: 0.8879957372674784
Validation loss: 2.6706189555058013

Epoch: 6| Step: 12
Training loss: 0.5655059235985201
Validation loss: 2.5943228460547005

Epoch: 6| Step: 13
Training loss: 0.9095928101709227
Validation loss: 2.5719806858007943

Epoch: 157| Step: 0
Training loss: 0.6317591907993538
Validation loss: 2.5814263832352826

Epoch: 6| Step: 1
Training loss: 0.7111901473621215
Validation loss: 2.506418508190496

Epoch: 6| Step: 2
Training loss: 0.8688360816516457
Validation loss: 2.618335756664583

Epoch: 6| Step: 3
Training loss: 0.7394616111917302
Validation loss: 2.684110322455844

Epoch: 6| Step: 4
Training loss: 0.6256682876184176
Validation loss: 2.655090048843974

Epoch: 6| Step: 5
Training loss: 0.6049722912645975
Validation loss: 2.6477334916340314

Epoch: 6| Step: 6
Training loss: 1.0269372520221278
Validation loss: 2.7547303177507514

Epoch: 6| Step: 7
Training loss: 1.0382913581809619
Validation loss: 2.748077081524676

Epoch: 6| Step: 8
Training loss: 1.6751575509745817
Validation loss: 2.789087290079342

Epoch: 6| Step: 9
Training loss: 0.8882957920303315
Validation loss: 2.723729189005001

Epoch: 6| Step: 10
Training loss: 0.6331857122325049
Validation loss: 2.762621784546463

Epoch: 6| Step: 11
Training loss: 0.7431343463666078
Validation loss: 2.6663852831283203

Epoch: 6| Step: 12
Training loss: 0.7579773399166683
Validation loss: 2.736518920374866

Epoch: 6| Step: 13
Training loss: 0.8576872812398848
Validation loss: 2.613205312282259

Epoch: 158| Step: 0
Training loss: 1.6229352304411384
Validation loss: 2.7383224767174466

Epoch: 6| Step: 1
Training loss: 0.8873399751411291
Validation loss: 2.632711436881698

Epoch: 6| Step: 2
Training loss: 0.6947287348471185
Validation loss: 2.664694344775836

Epoch: 6| Step: 3
Training loss: 0.4560950545226649
Validation loss: 2.6275631939529345

Epoch: 6| Step: 4
Training loss: 1.070640625046319
Validation loss: 2.639590886643905

Epoch: 6| Step: 5
Training loss: 0.8979249902208142
Validation loss: 2.6209952975040163

Epoch: 6| Step: 6
Training loss: 0.4563095556868743
Validation loss: 2.6036007202619222

Epoch: 6| Step: 7
Training loss: 0.58020269937936
Validation loss: 2.674021834384905

Epoch: 6| Step: 8
Training loss: 0.67123708826217
Validation loss: 2.6488233677158894

Epoch: 6| Step: 9
Training loss: 0.7325700533701794
Validation loss: 2.6208449585317664

Epoch: 6| Step: 10
Training loss: 0.5270665888583043
Validation loss: 2.634613341880976

Epoch: 6| Step: 11
Training loss: 0.46313811176802544
Validation loss: 2.6873788880256897

Epoch: 6| Step: 12
Training loss: 1.1851466601592948
Validation loss: 2.585541294320679

Epoch: 6| Step: 13
Training loss: 0.8028307483302303
Validation loss: 2.6500586215318975

Epoch: 159| Step: 0
Training loss: 0.7415569638617491
Validation loss: 2.6010583459708654

Epoch: 6| Step: 1
Training loss: 1.6155567885264002
Validation loss: 2.688613365268648

Epoch: 6| Step: 2
Training loss: 0.4442951896344398
Validation loss: 2.692198143641147

Epoch: 6| Step: 3
Training loss: 0.8729713629169187
Validation loss: 2.7583596008371565

Epoch: 6| Step: 4
Training loss: 0.7009673603991852
Validation loss: 2.6688027518878368

Epoch: 6| Step: 5
Training loss: 0.4699572276375714
Validation loss: 2.692036887494785

Epoch: 6| Step: 6
Training loss: 0.8533614169903702
Validation loss: 2.6896468466526713

Epoch: 6| Step: 7
Training loss: 0.6641845590948642
Validation loss: 2.7056156804085894

Epoch: 6| Step: 8
Training loss: 0.9859885660479635
Validation loss: 2.641163208716958

Epoch: 6| Step: 9
Training loss: 0.7073664002597672
Validation loss: 2.585494342490632

Epoch: 6| Step: 10
Training loss: 0.7153191158443696
Validation loss: 2.629923592945476

Epoch: 6| Step: 11
Training loss: 0.4782678390761253
Validation loss: 2.621771765015141

Epoch: 6| Step: 12
Training loss: 0.9144945020411321
Validation loss: 2.6242437030059764

Epoch: 6| Step: 13
Training loss: 1.1113568186617317
Validation loss: 2.6529951311669007

Epoch: 160| Step: 0
Training loss: 1.0303304792043975
Validation loss: 2.6158514455763915

Epoch: 6| Step: 1
Training loss: 0.5817930258875486
Validation loss: 2.7445405173206314

Epoch: 6| Step: 2
Training loss: 0.5267471329367036
Validation loss: 2.7572991430980824

Epoch: 6| Step: 3
Training loss: 0.7131825724571842
Validation loss: 2.734565154230305

Epoch: 6| Step: 4
Training loss: 0.7664316560070917
Validation loss: 2.6987852713662495

Epoch: 6| Step: 5
Training loss: 1.6904940006180111
Validation loss: 2.626387320355017

Epoch: 6| Step: 6
Training loss: 0.6596563127844672
Validation loss: 2.6858348641157943

Epoch: 6| Step: 7
Training loss: 0.5847967614782187
Validation loss: 2.6327208777539326

Epoch: 6| Step: 8
Training loss: 0.5854467243971831
Validation loss: 2.657222016449927

Epoch: 6| Step: 9
Training loss: 0.5232379020353096
Validation loss: 2.6616274088825054

Epoch: 6| Step: 10
Training loss: 0.9020577510057752
Validation loss: 2.646823147232437

Epoch: 6| Step: 11
Training loss: 0.5318645120790263
Validation loss: 2.738896103639452

Epoch: 6| Step: 12
Training loss: 0.9999633424715759
Validation loss: 2.6636782431518196

Epoch: 6| Step: 13
Training loss: 0.5861932832005756
Validation loss: 2.6878365889919613

Epoch: 161| Step: 0
Training loss: 0.7654019244883286
Validation loss: 2.6607675022814954

Epoch: 6| Step: 1
Training loss: 0.7343714693674479
Validation loss: 2.678348811147801

Epoch: 6| Step: 2
Training loss: 0.6834181641824806
Validation loss: 2.672496790228291

Epoch: 6| Step: 3
Training loss: 0.7498832850239393
Validation loss: 2.7757311868631023

Epoch: 6| Step: 4
Training loss: 0.7990581302575556
Validation loss: 2.648667587143131

Epoch: 6| Step: 5
Training loss: 0.623308228592374
Validation loss: 2.7046898665363632

Epoch: 6| Step: 6
Training loss: 0.9696905430983586
Validation loss: 2.6905699059328203

Epoch: 6| Step: 7
Training loss: 1.729890886184339
Validation loss: 2.658632264823732

Epoch: 6| Step: 8
Training loss: 0.9719483890606638
Validation loss: 2.609440755110793

Epoch: 6| Step: 9
Training loss: 0.8160454349724604
Validation loss: 2.6339535829774343

Epoch: 6| Step: 10
Training loss: 0.47667830264065303
Validation loss: 2.597691738870986

Epoch: 6| Step: 11
Training loss: 1.082057470561702
Validation loss: 2.62168916173242

Epoch: 6| Step: 12
Training loss: 0.6565265753902497
Validation loss: 2.686637385124377

Epoch: 6| Step: 13
Training loss: 0.7055417805634447
Validation loss: 2.6775983817164115

Epoch: 162| Step: 0
Training loss: 0.7315284671550446
Validation loss: 2.6660274444802483

Epoch: 6| Step: 1
Training loss: 0.5160945719320582
Validation loss: 2.6807214430855932

Epoch: 6| Step: 2
Training loss: 0.6953239011365568
Validation loss: 2.7418226124280634

Epoch: 6| Step: 3
Training loss: 0.5130554097201839
Validation loss: 2.6508005378546837

Epoch: 6| Step: 4
Training loss: 0.7929870152366452
Validation loss: 2.6132553699924452

Epoch: 6| Step: 5
Training loss: 0.770003778832316
Validation loss: 2.6294320550411725

Epoch: 6| Step: 6
Training loss: 1.2683666815281494
Validation loss: 2.6531454156660006

Epoch: 6| Step: 7
Training loss: 0.6230765787057568
Validation loss: 2.6835671413829356

Epoch: 6| Step: 8
Training loss: 0.6643112165636224
Validation loss: 2.651062915969155

Epoch: 6| Step: 9
Training loss: 1.612837834417011
Validation loss: 2.6426080484474648

Epoch: 6| Step: 10
Training loss: 0.7191002862941663
Validation loss: 2.7054015552688777

Epoch: 6| Step: 11
Training loss: 0.7917712711359283
Validation loss: 2.7160870456398847

Epoch: 6| Step: 12
Training loss: 0.8458516825171767
Validation loss: 2.7242751414431314

Epoch: 6| Step: 13
Training loss: 0.7630479219768673
Validation loss: 2.681511335226742

Epoch: 163| Step: 0
Training loss: 0.8469676371790423
Validation loss: 2.7131920929200914

Epoch: 6| Step: 1
Training loss: 1.0348210781815748
Validation loss: 2.655061104185671

Epoch: 6| Step: 2
Training loss: 0.40708646491312667
Validation loss: 2.5659722629444452

Epoch: 6| Step: 3
Training loss: 0.6984901894786335
Validation loss: 2.588124697673786

Epoch: 6| Step: 4
Training loss: 0.6838756960762622
Validation loss: 2.6363691234730826

Epoch: 6| Step: 5
Training loss: 0.4264771435472701
Validation loss: 2.6528770873125618

Epoch: 6| Step: 6
Training loss: 0.9176736885023393
Validation loss: 2.6984197572184825

Epoch: 6| Step: 7
Training loss: 0.9322415698921658
Validation loss: 2.727941038870517

Epoch: 6| Step: 8
Training loss: 0.6457913651725226
Validation loss: 2.6746910083128377

Epoch: 6| Step: 9
Training loss: 0.6699731212177821
Validation loss: 2.645256044581903

Epoch: 6| Step: 10
Training loss: 0.6483093043077289
Validation loss: 2.598507680918171

Epoch: 6| Step: 11
Training loss: 0.8503699044755251
Validation loss: 2.6256839678561863

Epoch: 6| Step: 12
Training loss: 0.56377285418315
Validation loss: 2.643845003794348

Epoch: 6| Step: 13
Training loss: 1.6637805825280825
Validation loss: 2.6424456457672982

Epoch: 164| Step: 0
Training loss: 0.6094371323821574
Validation loss: 2.645848707219511

Epoch: 6| Step: 1
Training loss: 0.6453005274661864
Validation loss: 2.6427684789621457

Epoch: 6| Step: 2
Training loss: 0.5660729315412458
Validation loss: 2.5973144153363594

Epoch: 6| Step: 3
Training loss: 1.6028543611929285
Validation loss: 2.6010824377255792

Epoch: 6| Step: 4
Training loss: 0.9464603737477375
Validation loss: 2.627895620090521

Epoch: 6| Step: 5
Training loss: 0.6042594399967578
Validation loss: 2.6238350175323375

Epoch: 6| Step: 6
Training loss: 0.562362945602116
Validation loss: 2.7140907029915837

Epoch: 6| Step: 7
Training loss: 0.9444610607486887
Validation loss: 2.711490102067201

Epoch: 6| Step: 8
Training loss: 0.46849972083287994
Validation loss: 2.7106287887648794

Epoch: 6| Step: 9
Training loss: 1.0415099153197782
Validation loss: 2.6955271170121384

Epoch: 6| Step: 10
Training loss: 0.6378520404945408
Validation loss: 2.6861588436261394

Epoch: 6| Step: 11
Training loss: 0.6602218189067964
Validation loss: 2.673632900485029

Epoch: 6| Step: 12
Training loss: 0.9269720860859665
Validation loss: 2.5865393607611

Epoch: 6| Step: 13
Training loss: 0.5310962398388761
Validation loss: 2.673391554984075

Epoch: 165| Step: 0
Training loss: 0.5745833141399747
Validation loss: 2.622387282134392

Epoch: 6| Step: 1
Training loss: 0.6029675905839776
Validation loss: 2.606972523043917

Epoch: 6| Step: 2
Training loss: 0.7461476331496767
Validation loss: 2.7007354288110377

Epoch: 6| Step: 3
Training loss: 1.0241589514925715
Validation loss: 2.648481595582818

Epoch: 6| Step: 4
Training loss: 0.8507864679574119
Validation loss: 2.6952097850153924

Epoch: 6| Step: 5
Training loss: 0.5444785334766657
Validation loss: 2.6857119089916113

Epoch: 6| Step: 6
Training loss: 1.596689990649097
Validation loss: 2.611424438861192

Epoch: 6| Step: 7
Training loss: 0.7797554598070131
Validation loss: 2.6809251483265566

Epoch: 6| Step: 8
Training loss: 0.8669551503725947
Validation loss: 2.639857013086164

Epoch: 6| Step: 9
Training loss: 0.5963529950481605
Validation loss: 2.575376799091304

Epoch: 6| Step: 10
Training loss: 0.6572507765958717
Validation loss: 2.5791855759510383

Epoch: 6| Step: 11
Training loss: 0.5615284264384354
Validation loss: 2.661601969108392

Epoch: 6| Step: 12
Training loss: 0.5267114309811247
Validation loss: 2.6046952410550297

Epoch: 6| Step: 13
Training loss: 0.6745436697694189
Validation loss: 2.690758496619442

Epoch: 166| Step: 0
Training loss: 0.5790203481402755
Validation loss: 2.6440318024300606

Epoch: 6| Step: 1
Training loss: 0.6786613610912128
Validation loss: 2.622081784507997

Epoch: 6| Step: 2
Training loss: 0.4364916045254363
Validation loss: 2.638473454339276

Epoch: 6| Step: 3
Training loss: 0.27471756357234695
Validation loss: 2.586329174055939

Epoch: 6| Step: 4
Training loss: 0.6629567982650258
Validation loss: 2.61383379239553

Epoch: 6| Step: 5
Training loss: 0.48529786210052
Validation loss: 2.662445696424722

Epoch: 6| Step: 6
Training loss: 0.8265199040937237
Validation loss: 2.6687618210684843

Epoch: 6| Step: 7
Training loss: 0.7560206199387169
Validation loss: 2.602419111721356

Epoch: 6| Step: 8
Training loss: 1.0156388501910185
Validation loss: 2.720194407322226

Epoch: 6| Step: 9
Training loss: 0.5734416088403996
Validation loss: 2.6087315540791796

Epoch: 6| Step: 10
Training loss: 0.4294167966364353
Validation loss: 2.5807673159235827

Epoch: 6| Step: 11
Training loss: 1.649341281258551
Validation loss: 2.655680456997212

Epoch: 6| Step: 12
Training loss: 0.6474706036290618
Validation loss: 2.6698035525800203

Epoch: 6| Step: 13
Training loss: 0.9029037587384925
Validation loss: 2.6176014055747094

Epoch: 167| Step: 0
Training loss: 0.7906242626925563
Validation loss: 2.6182868736154945

Epoch: 6| Step: 1
Training loss: 0.8460645013686763
Validation loss: 2.649046851231885

Epoch: 6| Step: 2
Training loss: 0.5247443098765657
Validation loss: 2.653780264002805

Epoch: 6| Step: 3
Training loss: 0.591806745289492
Validation loss: 2.6579957947048336

Epoch: 6| Step: 4
Training loss: 0.5279575590340184
Validation loss: 2.637565962703319

Epoch: 6| Step: 5
Training loss: 0.8524475398101381
Validation loss: 2.6529344398171193

Epoch: 6| Step: 6
Training loss: 0.6703328687511955
Validation loss: 2.65500587797981

Epoch: 6| Step: 7
Training loss: 0.9309945095260931
Validation loss: 2.6796086246904607

Epoch: 6| Step: 8
Training loss: 1.619364429646971
Validation loss: 2.6001651283547975

Epoch: 6| Step: 9
Training loss: 0.6064666891707243
Validation loss: 2.587770609441933

Epoch: 6| Step: 10
Training loss: 0.6351598131893946
Validation loss: 2.7288467763322166

Epoch: 6| Step: 11
Training loss: 0.546094009770453
Validation loss: 2.6545568417941863

Epoch: 6| Step: 12
Training loss: 0.58732692015481
Validation loss: 2.685801553383327

Epoch: 6| Step: 13
Training loss: 0.7574319178764836
Validation loss: 2.7507342745435372

Epoch: 168| Step: 0
Training loss: 0.8076547154998519
Validation loss: 2.685987963894946

Epoch: 6| Step: 1
Training loss: 0.7452969915347977
Validation loss: 2.64347759012741

Epoch: 6| Step: 2
Training loss: 0.329645640983703
Validation loss: 2.6569330272261973

Epoch: 6| Step: 3
Training loss: 0.7687269936197144
Validation loss: 2.6733641759499593

Epoch: 6| Step: 4
Training loss: 0.5001361184804263
Validation loss: 2.6458683211849237

Epoch: 6| Step: 5
Training loss: 0.4577121715821695
Validation loss: 2.627839203005275

Epoch: 6| Step: 6
Training loss: 0.5533744691252074
Validation loss: 2.694019482933683

Epoch: 6| Step: 7
Training loss: 0.4296088059930247
Validation loss: 2.6452460550854986

Epoch: 6| Step: 8
Training loss: 0.7300883644002355
Validation loss: 2.688643286251575

Epoch: 6| Step: 9
Training loss: 0.9921061865459982
Validation loss: 2.648791309230791

Epoch: 6| Step: 10
Training loss: 0.4536371296669234
Validation loss: 2.6572650465958425

Epoch: 6| Step: 11
Training loss: 1.5834046983530394
Validation loss: 2.701736564022281

Epoch: 6| Step: 12
Training loss: 0.7162555032621872
Validation loss: 2.716245484223279

Epoch: 6| Step: 13
Training loss: 0.6284262679588686
Validation loss: 2.6795305478589304

Epoch: 169| Step: 0
Training loss: 0.940437451545459
Validation loss: 2.6876247731897047

Epoch: 6| Step: 1
Training loss: 0.6232859950866396
Validation loss: 2.6456081765157617

Epoch: 6| Step: 2
Training loss: 0.7403049888245902
Validation loss: 2.668108540377942

Epoch: 6| Step: 3
Training loss: 0.678845728381338
Validation loss: 2.561433384047154

Epoch: 6| Step: 4
Training loss: 0.5100096195379608
Validation loss: 2.694102036676045

Epoch: 6| Step: 5
Training loss: 0.8969324525514741
Validation loss: 2.6335482526749683

Epoch: 6| Step: 6
Training loss: 1.567789128482702
Validation loss: 2.671538296429731

Epoch: 6| Step: 7
Training loss: 0.5573216872878842
Validation loss: 2.6643425131492138

Epoch: 6| Step: 8
Training loss: 0.791047083853122
Validation loss: 2.706217516439124

Epoch: 6| Step: 9
Training loss: 0.742982017486876
Validation loss: 2.641689229040535

Epoch: 6| Step: 10
Training loss: 0.7081584901625703
Validation loss: 2.6813260658221947

Epoch: 6| Step: 11
Training loss: 0.5211940628793164
Validation loss: 2.5928951677864203

Epoch: 6| Step: 12
Training loss: 0.5864656229960771
Validation loss: 2.6592950607938084

Epoch: 6| Step: 13
Training loss: 0.6681762952891849
Validation loss: 2.689361356463773

Epoch: 170| Step: 0
Training loss: 0.733502092414373
Validation loss: 2.634100156710924

Epoch: 6| Step: 1
Training loss: 0.5756916695918919
Validation loss: 2.69289539703165

Epoch: 6| Step: 2
Training loss: 0.642072646922457
Validation loss: 2.6194573878641236

Epoch: 6| Step: 3
Training loss: 0.6850496755116001
Validation loss: 2.574708528287344

Epoch: 6| Step: 4
Training loss: 0.5631067659175822
Validation loss: 2.6422690816774907

Epoch: 6| Step: 5
Training loss: 0.6971170603734524
Validation loss: 2.6079661207319353

Epoch: 6| Step: 6
Training loss: 0.511857632725499
Validation loss: 2.661146729225843

Epoch: 6| Step: 7
Training loss: 1.5349941022430342
Validation loss: 2.615715014976044

Epoch: 6| Step: 8
Training loss: 0.8154671117909034
Validation loss: 2.682059095849104

Epoch: 6| Step: 9
Training loss: 0.6682391595328658
Validation loss: 2.714112546961165

Epoch: 6| Step: 10
Training loss: 0.5635408202874203
Validation loss: 2.660546422157516

Epoch: 6| Step: 11
Training loss: 0.4482171544084711
Validation loss: 2.730858072404165

Epoch: 6| Step: 12
Training loss: 0.9795063660528197
Validation loss: 2.657843183055907

Epoch: 6| Step: 13
Training loss: 0.4706006393612281
Validation loss: 2.6534945688507774

Epoch: 171| Step: 0
Training loss: 0.3281522353540381
Validation loss: 2.635795623814277

Epoch: 6| Step: 1
Training loss: 0.857779599863411
Validation loss: 2.6612490268727593

Epoch: 6| Step: 2
Training loss: 0.5166276085098023
Validation loss: 2.6535658495188597

Epoch: 6| Step: 3
Training loss: 1.7003450716639648
Validation loss: 2.620423793684971

Epoch: 6| Step: 4
Training loss: 0.36609877839748173
Validation loss: 2.710921566904464

Epoch: 6| Step: 5
Training loss: 0.6555992487604028
Validation loss: 2.6480428350980234

Epoch: 6| Step: 6
Training loss: 0.5358823319670533
Validation loss: 2.658503186371119

Epoch: 6| Step: 7
Training loss: 0.468293221759474
Validation loss: 2.7086086182194933

Epoch: 6| Step: 8
Training loss: 0.4386005014050093
Validation loss: 2.6436565836581596

Epoch: 6| Step: 9
Training loss: 0.9859241224732551
Validation loss: 2.675612499549736

Epoch: 6| Step: 10
Training loss: 0.480591859009744
Validation loss: 2.7178167444091956

Epoch: 6| Step: 11
Training loss: 0.6030578111372779
Validation loss: 2.648505653547192

Epoch: 6| Step: 12
Training loss: 0.4505573728293226
Validation loss: 2.6805490752840746

Epoch: 6| Step: 13
Training loss: 0.6785532377070649
Validation loss: 2.7859094714974337

Epoch: 172| Step: 0
Training loss: 0.3866189384737617
Validation loss: 2.7965294253290747

Epoch: 6| Step: 1
Training loss: 0.5160477090429713
Validation loss: 2.732067216929675

Epoch: 6| Step: 2
Training loss: 0.4913090177567164
Validation loss: 2.6779564399747167

Epoch: 6| Step: 3
Training loss: 0.5837931240089825
Validation loss: 2.6994246658710543

Epoch: 6| Step: 4
Training loss: 0.4689824005039635
Validation loss: 2.7055501037227665

Epoch: 6| Step: 5
Training loss: 0.5196230814377358
Validation loss: 2.6703346378010693

Epoch: 6| Step: 6
Training loss: 0.6996692932131704
Validation loss: 2.5614440494577075

Epoch: 6| Step: 7
Training loss: 0.7439594198358045
Validation loss: 2.6538356205260927

Epoch: 6| Step: 8
Training loss: 1.2374896578886418
Validation loss: 2.6408581000679723

Epoch: 6| Step: 9
Training loss: 0.5380484953936641
Validation loss: 2.59164195974007

Epoch: 6| Step: 10
Training loss: 0.46387162055858694
Validation loss: 2.646042782961203

Epoch: 6| Step: 11
Training loss: 1.5825516963186372
Validation loss: 2.6503519436312346

Epoch: 6| Step: 12
Training loss: 0.5435739890045966
Validation loss: 2.5860005627459675

Epoch: 6| Step: 13
Training loss: 0.6662221012393532
Validation loss: 2.70464289683722

Epoch: 173| Step: 0
Training loss: 1.0505411093474135
Validation loss: 2.678160585503089

Epoch: 6| Step: 1
Training loss: 0.48931619444312524
Validation loss: 2.7974033389466957

Epoch: 6| Step: 2
Training loss: 0.7249408796474853
Validation loss: 2.627643752516648

Epoch: 6| Step: 3
Training loss: 0.43444997428598064
Validation loss: 2.6839854451062957

Epoch: 6| Step: 4
Training loss: 0.7332340061226567
Validation loss: 2.7058654153619766

Epoch: 6| Step: 5
Training loss: 0.6606881972357874
Validation loss: 2.5949604013762317

Epoch: 6| Step: 6
Training loss: 0.6197045101999487
Validation loss: 2.6376074529517655

Epoch: 6| Step: 7
Training loss: 0.769439459423836
Validation loss: 2.6115056093854294

Epoch: 6| Step: 8
Training loss: 0.7829819364546867
Validation loss: 2.6043155678459247

Epoch: 6| Step: 9
Training loss: 0.6465007860572798
Validation loss: 2.585376167646176

Epoch: 6| Step: 10
Training loss: 0.5303531818599778
Validation loss: 2.646098406471951

Epoch: 6| Step: 11
Training loss: 0.4396203634143943
Validation loss: 2.676318988460224

Epoch: 6| Step: 12
Training loss: 0.6660588941194603
Validation loss: 2.696526428186515

Epoch: 6| Step: 13
Training loss: 1.5494233535416866
Validation loss: 2.7014613388357427

Epoch: 174| Step: 0
Training loss: 0.7414726830516155
Validation loss: 2.6909025077950184

Epoch: 6| Step: 1
Training loss: 0.7003069885663453
Validation loss: 2.694721322947246

Epoch: 6| Step: 2
Training loss: 0.7022826765449337
Validation loss: 2.7216586853684315

Epoch: 6| Step: 3
Training loss: 0.5955662304283715
Validation loss: 2.6637733578504412

Epoch: 6| Step: 4
Training loss: 0.959610309384531
Validation loss: 2.6201181884490725

Epoch: 6| Step: 5
Training loss: 0.764209918757116
Validation loss: 2.5972410094816403

Epoch: 6| Step: 6
Training loss: 1.5657238318034943
Validation loss: 2.5947506058449616

Epoch: 6| Step: 7
Training loss: 0.7363070780935984
Validation loss: 2.5705789661745286

Epoch: 6| Step: 8
Training loss: 0.7900613185166683
Validation loss: 2.6581276185212435

Epoch: 6| Step: 9
Training loss: 0.3630273813818316
Validation loss: 2.6746827035409213

Epoch: 6| Step: 10
Training loss: 0.4538720319919308
Validation loss: 2.6801695394741567

Epoch: 6| Step: 11
Training loss: 0.5094963912012476
Validation loss: 2.694066696845156

Epoch: 6| Step: 12
Training loss: 0.5913415548397437
Validation loss: 2.6721234048106774

Epoch: 6| Step: 13
Training loss: 0.7004373469940997
Validation loss: 2.69986697563918

Epoch: 175| Step: 0
Training loss: 1.0111230694642384
Validation loss: 2.6503819142448894

Epoch: 6| Step: 1
Training loss: 0.5709784290862318
Validation loss: 2.6300967101530106

Epoch: 6| Step: 2
Training loss: 0.7629909357629933
Validation loss: 2.597849918498128

Epoch: 6| Step: 3
Training loss: 0.7546523755352533
Validation loss: 2.623644433371727

Epoch: 6| Step: 4
Training loss: 0.47390180991306724
Validation loss: 2.6345463296935194

Epoch: 6| Step: 5
Training loss: 0.6620951963273759
Validation loss: 2.6236028661935484

Epoch: 6| Step: 6
Training loss: 0.5051109049604523
Validation loss: 2.6672602578958484

Epoch: 6| Step: 7
Training loss: 0.7114561515614543
Validation loss: 2.622664994963944

Epoch: 6| Step: 8
Training loss: 0.614084750056288
Validation loss: 2.6872140894958165

Epoch: 6| Step: 9
Training loss: 0.6938453583004809
Validation loss: 2.7180716008010712

Epoch: 6| Step: 10
Training loss: 0.7890174021910975
Validation loss: 2.6600932423303973

Epoch: 6| Step: 11
Training loss: 0.6043969789628948
Validation loss: 2.7382938313977414

Epoch: 6| Step: 12
Training loss: 1.551381184873669
Validation loss: 2.6651384673608427

Epoch: 6| Step: 13
Training loss: 0.5456674049390313
Validation loss: 2.6764539926376494

Epoch: 176| Step: 0
Training loss: 0.7883480349964963
Validation loss: 2.6644687436070202

Epoch: 6| Step: 1
Training loss: 0.7379150693528995
Validation loss: 2.5571517647093103

Epoch: 6| Step: 2
Training loss: 0.6108067638487369
Validation loss: 2.6637690019817377

Epoch: 6| Step: 3
Training loss: 1.4863025397405745
Validation loss: 2.7076893236393507

Epoch: 6| Step: 4
Training loss: 0.6464361535841769
Validation loss: 2.6636170194726105

Epoch: 6| Step: 5
Training loss: 0.5161790472045923
Validation loss: 2.7163294982745767

Epoch: 6| Step: 6
Training loss: 0.7230860076652024
Validation loss: 2.759433576078059

Epoch: 6| Step: 7
Training loss: 0.6128328713119725
Validation loss: 2.7013486711002943

Epoch: 6| Step: 8
Training loss: 0.661809037319372
Validation loss: 2.7304084272729425

Epoch: 6| Step: 9
Training loss: 0.6136797685315831
Validation loss: 2.754795892104414

Epoch: 6| Step: 10
Training loss: 0.7131592962792442
Validation loss: 2.697268807135161

Epoch: 6| Step: 11
Training loss: 0.6416389071252154
Validation loss: 2.6708762996111797

Epoch: 6| Step: 12
Training loss: 0.9054173886968756
Validation loss: 2.6848280139920684

Epoch: 6| Step: 13
Training loss: 0.5628005920031538
Validation loss: 2.6705945462163587

Epoch: 177| Step: 0
Training loss: 0.616068465361962
Validation loss: 2.7107907419487267

Epoch: 6| Step: 1
Training loss: 0.5773215510290806
Validation loss: 2.7081219712947764

Epoch: 6| Step: 2
Training loss: 0.4890341637784378
Validation loss: 2.7693019641109107

Epoch: 6| Step: 3
Training loss: 0.6258417421741976
Validation loss: 2.717935505899716

Epoch: 6| Step: 4
Training loss: 0.7662470878807103
Validation loss: 2.7226723041544556

Epoch: 6| Step: 5
Training loss: 0.9819448841267245
Validation loss: 2.672877066168496

Epoch: 6| Step: 6
Training loss: 0.6486578647332277
Validation loss: 2.6903086483331426

Epoch: 6| Step: 7
Training loss: 0.6107794398654006
Validation loss: 2.681680559091124

Epoch: 6| Step: 8
Training loss: 1.5352844495363585
Validation loss: 2.60233019860865

Epoch: 6| Step: 9
Training loss: 0.8966971084740394
Validation loss: 2.641862718384996

Epoch: 6| Step: 10
Training loss: 0.5481666026317868
Validation loss: 2.5843764834417033

Epoch: 6| Step: 11
Training loss: 0.2839057887088805
Validation loss: 2.6364098789480477

Epoch: 6| Step: 12
Training loss: 0.3564680745421149
Validation loss: 2.617599819214705

Epoch: 6| Step: 13
Training loss: 0.43392615421346276
Validation loss: 2.6593248708492627

Epoch: 178| Step: 0
Training loss: 1.4198592433207968
Validation loss: 2.6798701988642324

Epoch: 6| Step: 1
Training loss: 0.4753111372407116
Validation loss: 2.6336298729323997

Epoch: 6| Step: 2
Training loss: 0.5373185461400121
Validation loss: 2.6419025618667145

Epoch: 6| Step: 3
Training loss: 0.8320465086491481
Validation loss: 2.7125676115900235

Epoch: 6| Step: 4
Training loss: 0.5119070623880532
Validation loss: 2.719037738642438

Epoch: 6| Step: 5
Training loss: 0.7590129428735016
Validation loss: 2.655446787548159

Epoch: 6| Step: 6
Training loss: 0.7189085412356854
Validation loss: 2.6368398530252297

Epoch: 6| Step: 7
Training loss: 0.7784266381288856
Validation loss: 2.6122521777238097

Epoch: 6| Step: 8
Training loss: 0.5408691869096701
Validation loss: 2.5863738829864884

Epoch: 6| Step: 9
Training loss: 0.49582229155846724
Validation loss: 2.6572916269894282

Epoch: 6| Step: 10
Training loss: 0.53455946008484
Validation loss: 2.609825202038425

Epoch: 6| Step: 11
Training loss: 0.9456700681244924
Validation loss: 2.543716156755489

Epoch: 6| Step: 12
Training loss: 0.5185271577298293
Validation loss: 2.6619159929579803

Epoch: 6| Step: 13
Training loss: 0.6153521712627122
Validation loss: 2.7028211595591576

Epoch: 179| Step: 0
Training loss: 0.4916407863896128
Validation loss: 2.691263328858245

Epoch: 6| Step: 1
Training loss: 0.4766284396720003
Validation loss: 2.632334136519644

Epoch: 6| Step: 2
Training loss: 0.8762759034250228
Validation loss: 2.6493664428016004

Epoch: 6| Step: 3
Training loss: 0.7130040744756029
Validation loss: 2.6966523162151894

Epoch: 6| Step: 4
Training loss: 0.5765677950649523
Validation loss: 2.652666509557187

Epoch: 6| Step: 5
Training loss: 1.4797152813697192
Validation loss: 2.690620178383743

Epoch: 6| Step: 6
Training loss: 0.5244749236353521
Validation loss: 2.68144407244293

Epoch: 6| Step: 7
Training loss: 0.7673414802245832
Validation loss: 2.6963673909180916

Epoch: 6| Step: 8
Training loss: 0.4812324626006085
Validation loss: 2.7518072258831743

Epoch: 6| Step: 9
Training loss: 0.5680235299790791
Validation loss: 2.616738017945892

Epoch: 6| Step: 10
Training loss: 0.6296479016293512
Validation loss: 2.6124275763297233

Epoch: 6| Step: 11
Training loss: 0.7413757703844981
Validation loss: 2.658303562782869

Epoch: 6| Step: 12
Training loss: 0.3837486420523509
Validation loss: 2.5734785498607176

Epoch: 6| Step: 13
Training loss: 0.4364424252702645
Validation loss: 2.7152495522317976

Epoch: 180| Step: 0
Training loss: 0.7491908476947188
Validation loss: 2.6683059710120878

Epoch: 6| Step: 1
Training loss: 0.5259507607450259
Validation loss: 2.6839068145493745

Epoch: 6| Step: 2
Training loss: 0.7179036340251956
Validation loss: 2.6825713422329773

Epoch: 6| Step: 3
Training loss: 0.528724839894738
Validation loss: 2.694398527857483

Epoch: 6| Step: 4
Training loss: 0.912358611401176
Validation loss: 2.713990426373914

Epoch: 6| Step: 5
Training loss: 0.5114914192587463
Validation loss: 2.685127083075477

Epoch: 6| Step: 6
Training loss: 0.39837743268977394
Validation loss: 2.6681697056732547

Epoch: 6| Step: 7
Training loss: 0.5547154647869983
Validation loss: 2.583630672898874

Epoch: 6| Step: 8
Training loss: 0.5244878791557696
Validation loss: 2.6942425801887437

Epoch: 6| Step: 9
Training loss: 0.5641789545958925
Validation loss: 2.7076408576898383

Epoch: 6| Step: 10
Training loss: 0.38611673448014006
Validation loss: 2.689845296412605

Epoch: 6| Step: 11
Training loss: 0.589128983284839
Validation loss: 2.7063311928072924

Epoch: 6| Step: 12
Training loss: 0.4901096899739562
Validation loss: 2.6613117384180964

Epoch: 6| Step: 13
Training loss: 1.4457315198392353
Validation loss: 2.68919492104031

Epoch: 181| Step: 0
Training loss: 0.7118205360965822
Validation loss: 2.708272718093595

Epoch: 6| Step: 1
Training loss: 0.47241422273227224
Validation loss: 2.6962780978136345

Epoch: 6| Step: 2
Training loss: 0.652606659864416
Validation loss: 2.6278358007033025

Epoch: 6| Step: 3
Training loss: 1.0093020291716885
Validation loss: 2.6575102864326836

Epoch: 6| Step: 4
Training loss: 0.6656411424210701
Validation loss: 2.677347538795755

Epoch: 6| Step: 5
Training loss: 0.44914225051328277
Validation loss: 2.6574921489849612

Epoch: 6| Step: 6
Training loss: 0.667439502053286
Validation loss: 2.656785073335963

Epoch: 6| Step: 7
Training loss: 0.538373949680938
Validation loss: 2.7329830005255245

Epoch: 6| Step: 8
Training loss: 0.519718480611794
Validation loss: 2.6184388314970013

Epoch: 6| Step: 9
Training loss: 1.4410318855077595
Validation loss: 2.6645785491001663

Epoch: 6| Step: 10
Training loss: 0.45104285042528863
Validation loss: 2.642776545715722

Epoch: 6| Step: 11
Training loss: 0.46900364053488564
Validation loss: 2.6647456869533106

Epoch: 6| Step: 12
Training loss: 0.6211648096664644
Validation loss: 2.7401835626525552

Epoch: 6| Step: 13
Training loss: 0.5334613440290428
Validation loss: 2.669067327913891

Epoch: 182| Step: 0
Training loss: 0.9796340854812922
Validation loss: 2.6213481948231725

Epoch: 6| Step: 1
Training loss: 0.5500168602699996
Validation loss: 2.658050540204381

Epoch: 6| Step: 2
Training loss: 0.6000414357182823
Validation loss: 2.677635823594271

Epoch: 6| Step: 3
Training loss: 0.5084542254491154
Validation loss: 2.643903559199868

Epoch: 6| Step: 4
Training loss: 0.46317274614564957
Validation loss: 2.648211729315905

Epoch: 6| Step: 5
Training loss: 0.43427211517281444
Validation loss: 2.751450950589739

Epoch: 6| Step: 6
Training loss: 0.6069702235590247
Validation loss: 2.797314117455947

Epoch: 6| Step: 7
Training loss: 0.860568829921737
Validation loss: 2.768297244239974

Epoch: 6| Step: 8
Training loss: 0.8307136167468026
Validation loss: 2.745368713486574

Epoch: 6| Step: 9
Training loss: 0.6637104223057497
Validation loss: 2.703871879223247

Epoch: 6| Step: 10
Training loss: 0.5044606434127551
Validation loss: 2.6512392541265033

Epoch: 6| Step: 11
Training loss: 0.5427682629942937
Validation loss: 2.5676067298662693

Epoch: 6| Step: 12
Training loss: 1.5343217207288031
Validation loss: 2.594781586208745

Epoch: 6| Step: 13
Training loss: 0.5421348315335447
Validation loss: 2.6232238694667305

Epoch: 183| Step: 0
Training loss: 0.6220479628831365
Validation loss: 2.604028733733173

Epoch: 6| Step: 1
Training loss: 0.5619744388733815
Validation loss: 2.7057917969803893

Epoch: 6| Step: 2
Training loss: 0.5222354865954141
Validation loss: 2.7302173067595765

Epoch: 6| Step: 3
Training loss: 1.3986013732027338
Validation loss: 2.728944395686758

Epoch: 6| Step: 4
Training loss: 0.5815124759959344
Validation loss: 2.7808902522103347

Epoch: 6| Step: 5
Training loss: 0.7337531845829496
Validation loss: 2.739733722073928

Epoch: 6| Step: 6
Training loss: 0.4263497852753029
Validation loss: 2.6856371315325602

Epoch: 6| Step: 7
Training loss: 0.6493611708592147
Validation loss: 2.6519145814997134

Epoch: 6| Step: 8
Training loss: 0.778679165504139
Validation loss: 2.5263574828836526

Epoch: 6| Step: 9
Training loss: 0.8269795827547823
Validation loss: 2.556885453312145

Epoch: 6| Step: 10
Training loss: 1.0285428667644205
Validation loss: 2.580961112420035

Epoch: 6| Step: 11
Training loss: 0.6312218678692653
Validation loss: 2.679611546039624

Epoch: 6| Step: 12
Training loss: 0.5118937884598301
Validation loss: 2.6436086648447814

Epoch: 6| Step: 13
Training loss: 0.5432032346403027
Validation loss: 2.6755546678083615

Epoch: 184| Step: 0
Training loss: 0.4954683762533606
Validation loss: 2.6828317092388505

Epoch: 6| Step: 1
Training loss: 0.8675123413923035
Validation loss: 2.6614734975204897

Epoch: 6| Step: 2
Training loss: 0.6791844973144545
Validation loss: 2.677705882871757

Epoch: 6| Step: 3
Training loss: 1.5575592508572604
Validation loss: 2.7012048858589353

Epoch: 6| Step: 4
Training loss: 0.5134506619531538
Validation loss: 2.6255208361584743

Epoch: 6| Step: 5
Training loss: 0.5560239353928357
Validation loss: 2.626054483876971

Epoch: 6| Step: 6
Training loss: 0.6348710662125076
Validation loss: 2.6207212059241445

Epoch: 6| Step: 7
Training loss: 0.5903910945755688
Validation loss: 2.6790978734828403

Epoch: 6| Step: 8
Training loss: 0.5281354259838746
Validation loss: 2.6558991967221406

Epoch: 6| Step: 9
Training loss: 0.5247657775651517
Validation loss: 2.669235368198404

Epoch: 6| Step: 10
Training loss: 0.5517494403575277
Validation loss: 2.6841902942045888

Epoch: 6| Step: 11
Training loss: 0.7837457085450878
Validation loss: 2.722789015011769

Epoch: 6| Step: 12
Training loss: 0.5114204760471686
Validation loss: 2.7486464030132374

Epoch: 6| Step: 13
Training loss: 0.2488679213266806
Validation loss: 2.730878065261102

Epoch: 185| Step: 0
Training loss: 1.5386126485302944
Validation loss: 2.6895402364629275

Epoch: 6| Step: 1
Training loss: 0.5356884002108293
Validation loss: 2.754006703666187

Epoch: 6| Step: 2
Training loss: 0.5557809180558194
Validation loss: 2.6953679618104913

Epoch: 6| Step: 3
Training loss: 0.843937958868716
Validation loss: 2.6717917297355975

Epoch: 6| Step: 4
Training loss: 0.3965727233170155
Validation loss: 2.6732096917042885

Epoch: 6| Step: 5
Training loss: 0.6831541555313314
Validation loss: 2.642529118984075

Epoch: 6| Step: 6
Training loss: 0.9282981685322435
Validation loss: 2.6505613710093603

Epoch: 6| Step: 7
Training loss: 0.49109587639479685
Validation loss: 2.6390423819311706

Epoch: 6| Step: 8
Training loss: 0.7510913617274876
Validation loss: 2.699891245382432

Epoch: 6| Step: 9
Training loss: 0.4600868133849062
Validation loss: 2.7589814011584184

Epoch: 6| Step: 10
Training loss: 0.5969590252755805
Validation loss: 2.6832056778304048

Epoch: 6| Step: 11
Training loss: 0.44344893571814314
Validation loss: 2.6657518715161284

Epoch: 6| Step: 12
Training loss: 0.647324767832294
Validation loss: 2.8246114483319564

Epoch: 6| Step: 13
Training loss: 0.35197676516787363
Validation loss: 2.656772143337393

Epoch: 186| Step: 0
Training loss: 0.521845774488967
Validation loss: 2.616313048075554

Epoch: 6| Step: 1
Training loss: 0.6955482426166854
Validation loss: 2.6308500407279194

Epoch: 6| Step: 2
Training loss: 0.643816719486477
Validation loss: 2.650263544089355

Epoch: 6| Step: 3
Training loss: 0.5230510480741329
Validation loss: 2.629478630343217

Epoch: 6| Step: 4
Training loss: 0.7143626026936802
Validation loss: 2.6464143450528486

Epoch: 6| Step: 5
Training loss: 0.5942123018727906
Validation loss: 2.725383631215347

Epoch: 6| Step: 6
Training loss: 0.47705484191353276
Validation loss: 2.605005454718504

Epoch: 6| Step: 7
Training loss: 0.44701356740177506
Validation loss: 2.635886852755439

Epoch: 6| Step: 8
Training loss: 0.5083469805944001
Validation loss: 2.6578613181081465

Epoch: 6| Step: 9
Training loss: 0.9632968935349822
Validation loss: 2.6585011535894574

Epoch: 6| Step: 10
Training loss: 1.3550193107467667
Validation loss: 2.673087999160484

Epoch: 6| Step: 11
Training loss: 0.7175716609591009
Validation loss: 2.634852727228382

Epoch: 6| Step: 12
Training loss: 0.4681086603325575
Validation loss: 2.6841015286749776

Epoch: 6| Step: 13
Training loss: 0.7789374648471186
Validation loss: 2.669337206999985

Epoch: 187| Step: 0
Training loss: 0.4627458370089494
Validation loss: 2.6317046841063165

Epoch: 6| Step: 1
Training loss: 0.7290891787818279
Validation loss: 2.6369657273652978

Epoch: 6| Step: 2
Training loss: 0.5689312132670653
Validation loss: 2.716488917411892

Epoch: 6| Step: 3
Training loss: 0.5158333213058413
Validation loss: 2.6622437713499556

Epoch: 6| Step: 4
Training loss: 0.9561996583839449
Validation loss: 2.645207598927646

Epoch: 6| Step: 5
Training loss: 1.3679853454663784
Validation loss: 2.648877372709554

Epoch: 6| Step: 6
Training loss: 0.5772299152314847
Validation loss: 2.7008206021170578

Epoch: 6| Step: 7
Training loss: 0.2623339866016483
Validation loss: 2.681093416184141

Epoch: 6| Step: 8
Training loss: 0.5786083881155181
Validation loss: 2.689817774626265

Epoch: 6| Step: 9
Training loss: 0.45929131491692965
Validation loss: 2.7403551810533258

Epoch: 6| Step: 10
Training loss: 0.5560396932731514
Validation loss: 2.792007330610677

Epoch: 6| Step: 11
Training loss: 0.47488411066885583
Validation loss: 2.7432178615619343

Epoch: 6| Step: 12
Training loss: 0.4357160573226504
Validation loss: 2.6772113032251483

Epoch: 6| Step: 13
Training loss: 0.2884006526923433
Validation loss: 2.7361458702482904

Epoch: 188| Step: 0
Training loss: 0.5224652726893739
Validation loss: 2.700470725575289

Epoch: 6| Step: 1
Training loss: 0.6359599453950788
Validation loss: 2.7037245098481475

Epoch: 6| Step: 2
Training loss: 0.6166654866009668
Validation loss: 2.6254909601210294

Epoch: 6| Step: 3
Training loss: 0.40524856307206214
Validation loss: 2.721323103780676

Epoch: 6| Step: 4
Training loss: 0.4730905161476896
Validation loss: 2.6779505194702606

Epoch: 6| Step: 5
Training loss: 0.5057805415994976
Validation loss: 2.6389625778840697

Epoch: 6| Step: 6
Training loss: 1.3769336022690704
Validation loss: 2.7054746702098047

Epoch: 6| Step: 7
Training loss: 0.9026377145410295
Validation loss: 2.69429448017387

Epoch: 6| Step: 8
Training loss: 0.4106812341641962
Validation loss: 2.6772902491618726

Epoch: 6| Step: 9
Training loss: 0.4721234526453575
Validation loss: 2.636984322442601

Epoch: 6| Step: 10
Training loss: 0.430208618434907
Validation loss: 2.6612733352376265

Epoch: 6| Step: 11
Training loss: 0.4155283657827931
Validation loss: 2.6529627037058074

Epoch: 6| Step: 12
Training loss: 0.5454379683381421
Validation loss: 2.6307772987286056

Epoch: 6| Step: 13
Training loss: 0.6836134335545042
Validation loss: 2.735427494032486

Epoch: 189| Step: 0
Training loss: 0.6400504908910645
Validation loss: 2.6382762537999205

Epoch: 6| Step: 1
Training loss: 0.5786128691981656
Validation loss: 2.6155224262331807

Epoch: 6| Step: 2
Training loss: 0.42183865284639704
Validation loss: 2.677098260583092

Epoch: 6| Step: 3
Training loss: 0.42649994136411884
Validation loss: 2.7136625505833285

Epoch: 6| Step: 4
Training loss: 0.6141210746492162
Validation loss: 2.725186719534332

Epoch: 6| Step: 5
Training loss: 0.5868471078876657
Validation loss: 2.6888195317451165

Epoch: 6| Step: 6
Training loss: 0.5016269440412459
Validation loss: 2.672024743120715

Epoch: 6| Step: 7
Training loss: 0.6443238589382417
Validation loss: 2.670426792342433

Epoch: 6| Step: 8
Training loss: 0.9910291683608317
Validation loss: 2.6973693371021574

Epoch: 6| Step: 9
Training loss: 0.5497349750778019
Validation loss: 2.602210677222243

Epoch: 6| Step: 10
Training loss: 0.6597874982786706
Validation loss: 2.6191205150297794

Epoch: 6| Step: 11
Training loss: 0.5252070052894146
Validation loss: 2.6552221516104586

Epoch: 6| Step: 12
Training loss: 0.5433741915099853
Validation loss: 2.6665855459947987

Epoch: 6| Step: 13
Training loss: 1.3474656564585934
Validation loss: 2.5908074443951463

Epoch: 190| Step: 0
Training loss: 0.5546315124624583
Validation loss: 2.678735339584024

Epoch: 6| Step: 1
Training loss: 0.3820586664702363
Validation loss: 2.6275322371518754

Epoch: 6| Step: 2
Training loss: 0.5534544927830484
Validation loss: 2.719390676726915

Epoch: 6| Step: 3
Training loss: 0.5884746299532136
Validation loss: 2.6309710967185853

Epoch: 6| Step: 4
Training loss: 0.6348296617338499
Validation loss: 2.6876184452185656

Epoch: 6| Step: 5
Training loss: 0.5174023023702314
Validation loss: 2.6340912336872466

Epoch: 6| Step: 6
Training loss: 1.4144085202562455
Validation loss: 2.69704538560755

Epoch: 6| Step: 7
Training loss: 0.507620085428735
Validation loss: 2.7193107172923416

Epoch: 6| Step: 8
Training loss: 0.47151451298959607
Validation loss: 2.7058691894799694

Epoch: 6| Step: 9
Training loss: 0.623063377233579
Validation loss: 2.6787676219387264

Epoch: 6| Step: 10
Training loss: 0.5947756191122006
Validation loss: 2.732777504890464

Epoch: 6| Step: 11
Training loss: 0.9553140298209079
Validation loss: 2.701869842244353

Epoch: 6| Step: 12
Training loss: 0.7206930351067925
Validation loss: 2.7221207897163473

Epoch: 6| Step: 13
Training loss: 0.38272409002061464
Validation loss: 2.7929013401957654

Epoch: 191| Step: 0
Training loss: 0.49470632385952745
Validation loss: 2.6609903261261394

Epoch: 6| Step: 1
Training loss: 0.48057247996004654
Validation loss: 2.624284873917473

Epoch: 6| Step: 2
Training loss: 0.7006310207302219
Validation loss: 2.695308946984939

Epoch: 6| Step: 3
Training loss: 0.4185422723720504
Validation loss: 2.6781047747577924

Epoch: 6| Step: 4
Training loss: 0.4602543569231164
Validation loss: 2.6645981146725815

Epoch: 6| Step: 5
Training loss: 0.5327283261391098
Validation loss: 2.7402333164190384

Epoch: 6| Step: 6
Training loss: 0.5227581569157465
Validation loss: 2.6741645031099335

Epoch: 6| Step: 7
Training loss: 0.8872089795357323
Validation loss: 2.7570932691384593

Epoch: 6| Step: 8
Training loss: 0.5111519389788444
Validation loss: 2.7828419590454003

Epoch: 6| Step: 9
Training loss: 0.665063193803484
Validation loss: 2.61651479701504

Epoch: 6| Step: 10
Training loss: 0.5118749249170642
Validation loss: 2.752482507495923

Epoch: 6| Step: 11
Training loss: 0.5051498149788797
Validation loss: 2.687694882564558

Epoch: 6| Step: 12
Training loss: 1.3997195882625888
Validation loss: 2.7318387285249512

Epoch: 6| Step: 13
Training loss: 0.7511217153131075
Validation loss: 2.663317877406732

Epoch: 192| Step: 0
Training loss: 0.5535054035629431
Validation loss: 2.7321603144026527

Epoch: 6| Step: 1
Training loss: 0.8371909895222934
Validation loss: 2.697603190312963

Epoch: 6| Step: 2
Training loss: 0.4245125829575094
Validation loss: 2.734373706635669

Epoch: 6| Step: 3
Training loss: 0.37198307486455245
Validation loss: 2.643151438404874

Epoch: 6| Step: 4
Training loss: 0.5581752569931586
Validation loss: 2.6317409972439743

Epoch: 6| Step: 5
Training loss: 0.516434756140014
Validation loss: 2.598683196789169

Epoch: 6| Step: 6
Training loss: 0.3097910770768945
Validation loss: 2.6336331319566177

Epoch: 6| Step: 7
Training loss: 0.6551675497764136
Validation loss: 2.578936570482461

Epoch: 6| Step: 8
Training loss: 0.6124249451252886
Validation loss: 2.654733299622187

Epoch: 6| Step: 9
Training loss: 1.4165249454444084
Validation loss: 2.6888933931353267

Epoch: 6| Step: 10
Training loss: 0.496985392633108
Validation loss: 2.7265603867953474

Epoch: 6| Step: 11
Training loss: 0.8790748943020584
Validation loss: 2.647965440718604

Epoch: 6| Step: 12
Training loss: 0.5432436130708234
Validation loss: 2.635181436607765

Epoch: 6| Step: 13
Training loss: 0.5155395668229762
Validation loss: 2.730086111054407

Epoch: 193| Step: 0
Training loss: 0.4490012927939446
Validation loss: 2.656556549334842

Epoch: 6| Step: 1
Training loss: 0.5810846144718935
Validation loss: 2.679722554947915

Epoch: 6| Step: 2
Training loss: 0.311187706730627
Validation loss: 2.556119325091185

Epoch: 6| Step: 3
Training loss: 1.340735091733087
Validation loss: 2.539603855424619

Epoch: 6| Step: 4
Training loss: 0.5066559753210172
Validation loss: 2.6098489159669547

Epoch: 6| Step: 5
Training loss: 0.5889105583148706
Validation loss: 2.6261755566559595

Epoch: 6| Step: 6
Training loss: 0.893106984196371
Validation loss: 2.6081898904750016

Epoch: 6| Step: 7
Training loss: 0.47837332341817645
Validation loss: 2.652855473080174

Epoch: 6| Step: 8
Training loss: 0.4400568227489773
Validation loss: 2.6195972337612354

Epoch: 6| Step: 9
Training loss: 0.49436693700974166
Validation loss: 2.6763401904908144

Epoch: 6| Step: 10
Training loss: 0.4050069093409197
Validation loss: 2.679872689924103

Epoch: 6| Step: 11
Training loss: 0.48069971627412933
Validation loss: 2.745596539055852

Epoch: 6| Step: 12
Training loss: 0.49105635347387944
Validation loss: 2.691684717722106

Epoch: 6| Step: 13
Training loss: 0.5328888578319902
Validation loss: 2.6930404743543725

Epoch: 194| Step: 0
Training loss: 0.8087325414692342
Validation loss: 2.677591102527169

Epoch: 6| Step: 1
Training loss: 0.4268797082767015
Validation loss: 2.706590639543688

Epoch: 6| Step: 2
Training loss: 0.3401717652833245
Validation loss: 2.7062689958923247

Epoch: 6| Step: 3
Training loss: 0.4726739990432801
Validation loss: 2.6648351419593697

Epoch: 6| Step: 4
Training loss: 0.4704712577608559
Validation loss: 2.6663352392788906

Epoch: 6| Step: 5
Training loss: 0.7082447576305246
Validation loss: 2.726852940754246

Epoch: 6| Step: 6
Training loss: 0.4370734144593899
Validation loss: 2.7138967202432696

Epoch: 6| Step: 7
Training loss: 0.47535123262214485
Validation loss: 2.6707110481615217

Epoch: 6| Step: 8
Training loss: 1.3356478192991168
Validation loss: 2.6993079311067176

Epoch: 6| Step: 9
Training loss: 0.5861359832281314
Validation loss: 2.758637734372822

Epoch: 6| Step: 10
Training loss: 0.6178828318364039
Validation loss: 2.6582819029836524

Epoch: 6| Step: 11
Training loss: 0.4390169819217127
Validation loss: 2.689365582229114

Epoch: 6| Step: 12
Training loss: 0.7267292610676322
Validation loss: 2.694187950650394

Epoch: 6| Step: 13
Training loss: 0.39636627091895504
Validation loss: 2.6506099736660933

Epoch: 195| Step: 0
Training loss: 0.3446393429480291
Validation loss: 2.630130764160492

Epoch: 6| Step: 1
Training loss: 0.4479412323477004
Validation loss: 2.681032323411686

Epoch: 6| Step: 2
Training loss: 0.46351906010512045
Validation loss: 2.6550885896456404

Epoch: 6| Step: 3
Training loss: 0.6755441679756363
Validation loss: 2.619401790257679

Epoch: 6| Step: 4
Training loss: 0.6179028240778911
Validation loss: 2.6650739075537846

Epoch: 6| Step: 5
Training loss: 0.4813839948809813
Validation loss: 2.6396911444521614

Epoch: 6| Step: 6
Training loss: 0.5114572453794801
Validation loss: 2.6537244421359647

Epoch: 6| Step: 7
Training loss: 0.5801680780916142
Validation loss: 2.671267405054431

Epoch: 6| Step: 8
Training loss: 1.3183651168133066
Validation loss: 2.7033636616214065

Epoch: 6| Step: 9
Training loss: 0.33640009058067744
Validation loss: 2.73256799481235

Epoch: 6| Step: 10
Training loss: 0.606426932874915
Validation loss: 2.6498376526676113

Epoch: 6| Step: 11
Training loss: 0.38439433584193267
Validation loss: 2.628442762157431

Epoch: 6| Step: 12
Training loss: 0.6274489346657419
Validation loss: 2.644226732851162

Epoch: 6| Step: 13
Training loss: 0.9419852727722834
Validation loss: 2.705645288532477

Epoch: 196| Step: 0
Training loss: 0.39350748844001227
Validation loss: 2.6914117422726074

Epoch: 6| Step: 1
Training loss: 0.6440937753901033
Validation loss: 2.653713361475511

Epoch: 6| Step: 2
Training loss: 0.5257555747033644
Validation loss: 2.709190795338842

Epoch: 6| Step: 3
Training loss: 0.5285069388093778
Validation loss: 2.7353089835554973

Epoch: 6| Step: 4
Training loss: 0.4752832816559164
Validation loss: 2.730710769718434

Epoch: 6| Step: 5
Training loss: 0.3702595218152709
Validation loss: 2.6750575068344262

Epoch: 6| Step: 6
Training loss: 0.33427189280071706
Validation loss: 2.6738744173949125

Epoch: 6| Step: 7
Training loss: 0.4782737587781711
Validation loss: 2.686536394404869

Epoch: 6| Step: 8
Training loss: 1.3285792303295738
Validation loss: 2.5980697876306027

Epoch: 6| Step: 9
Training loss: 0.4024268869966604
Validation loss: 2.694422301193785

Epoch: 6| Step: 10
Training loss: 0.8866544859869327
Validation loss: 2.6803857099478066

Epoch: 6| Step: 11
Training loss: 0.43711851722354267
Validation loss: 2.643863099597144

Epoch: 6| Step: 12
Training loss: 0.6451244052410433
Validation loss: 2.6503144761392887

Epoch: 6| Step: 13
Training loss: 0.705391726930784
Validation loss: 2.704438046815947

Epoch: 197| Step: 0
Training loss: 0.3612607944750132
Validation loss: 2.645223537270282

Epoch: 6| Step: 1
Training loss: 0.46554554126879416
Validation loss: 2.6925090861189322

Epoch: 6| Step: 2
Training loss: 0.5972650032713843
Validation loss: 2.675435599395899

Epoch: 6| Step: 3
Training loss: 0.6227611496462082
Validation loss: 2.6934935693318867

Epoch: 6| Step: 4
Training loss: 0.4805031740835984
Validation loss: 2.711599674026455

Epoch: 6| Step: 5
Training loss: 0.3217556009775815
Validation loss: 2.6613258931053423

Epoch: 6| Step: 6
Training loss: 0.5971981362234545
Validation loss: 2.7542931683950513

Epoch: 6| Step: 7
Training loss: 1.5313188187062567
Validation loss: 2.7651892999527465

Epoch: 6| Step: 8
Training loss: 0.4525057079418844
Validation loss: 2.760339445557507

Epoch: 6| Step: 9
Training loss: 0.6103091538001081
Validation loss: 2.6695434629573818

Epoch: 6| Step: 10
Training loss: 0.4310950373996427
Validation loss: 2.712850095713012

Epoch: 6| Step: 11
Training loss: 0.5310208443467519
Validation loss: 2.6943564668255586

Epoch: 6| Step: 12
Training loss: 0.5075236452635805
Validation loss: 2.5903260792128444

Epoch: 6| Step: 13
Training loss: 0.34768364830496246
Validation loss: 2.7004285972585547

Epoch: 198| Step: 0
Training loss: 0.6110521369953524
Validation loss: 2.675223559250667

Epoch: 6| Step: 1
Training loss: 0.5470104594721308
Validation loss: 2.678084788545439

Epoch: 6| Step: 2
Training loss: 0.5371513766425491
Validation loss: 2.6807061530805876

Epoch: 6| Step: 3
Training loss: 0.46635505484754236
Validation loss: 2.6153099499267367

Epoch: 6| Step: 4
Training loss: 0.4634139084936546
Validation loss: 2.6066897618164155

Epoch: 6| Step: 5
Training loss: 0.6346194054847442
Validation loss: 2.7054650793106654

Epoch: 6| Step: 6
Training loss: 0.3501132339140254
Validation loss: 2.711683201902588

Epoch: 6| Step: 7
Training loss: 0.764437279710012
Validation loss: 2.6665603994017526

Epoch: 6| Step: 8
Training loss: 0.796125920088397
Validation loss: 2.6996289616413653

Epoch: 6| Step: 9
Training loss: 0.3461132956813131
Validation loss: 2.673202259349615

Epoch: 6| Step: 10
Training loss: 1.214692428339408
Validation loss: 2.7152767430721134

Epoch: 6| Step: 11
Training loss: 0.39463170349594795
Validation loss: 2.666686942102918

Epoch: 6| Step: 12
Training loss: 0.43644336418332225
Validation loss: 2.704048660438643

Epoch: 6| Step: 13
Training loss: 0.3331087915796642
Validation loss: 2.654816079650995

Epoch: 199| Step: 0
Training loss: 0.9733328553311816
Validation loss: 2.7232540720312075

Epoch: 6| Step: 1
Training loss: 0.4726853795178657
Validation loss: 2.6960314100588376

Epoch: 6| Step: 2
Training loss: 0.34973065707399176
Validation loss: 2.698252024973773

Epoch: 6| Step: 3
Training loss: 0.48411697775618157
Validation loss: 2.708344567104419

Epoch: 6| Step: 4
Training loss: 0.38659207359680064
Validation loss: 2.628696079931605

Epoch: 6| Step: 5
Training loss: 0.3213666225144147
Validation loss: 2.7620878139368776

Epoch: 6| Step: 6
Training loss: 0.4018971825939669
Validation loss: 2.6530844431826277

Epoch: 6| Step: 7
Training loss: 1.4093561412285411
Validation loss: 2.682632503644012

Epoch: 6| Step: 8
Training loss: 0.5440460330984339
Validation loss: 2.6510107991658014

Epoch: 6| Step: 9
Training loss: 0.3545285881416658
Validation loss: 2.6688773756875586

Epoch: 6| Step: 10
Training loss: 0.6354752784545605
Validation loss: 2.6365465046700853

Epoch: 6| Step: 11
Training loss: 0.39760124110857104
Validation loss: 2.702923702910817

Epoch: 6| Step: 12
Training loss: 0.28983695441245805
Validation loss: 2.649987516433774

Epoch: 6| Step: 13
Training loss: 0.6183918417277107
Validation loss: 2.663126806344935

Epoch: 200| Step: 0
Training loss: 0.5060086122220936
Validation loss: 2.6865219288152344

Epoch: 6| Step: 1
Training loss: 0.38636112052944954
Validation loss: 2.643792158531686

Epoch: 6| Step: 2
Training loss: 1.3245656507155166
Validation loss: 2.6145050270137777

Epoch: 6| Step: 3
Training loss: 0.5045386198137011
Validation loss: 2.665364414371

Epoch: 6| Step: 4
Training loss: 0.36589645106644964
Validation loss: 2.6530793433572515

Epoch: 6| Step: 5
Training loss: 0.4745117526653974
Validation loss: 2.7650592462355794

Epoch: 6| Step: 6
Training loss: 0.29089491215948216
Validation loss: 2.717117667255954

Epoch: 6| Step: 7
Training loss: 0.36540144908598904
Validation loss: 2.7034090219979907

Epoch: 6| Step: 8
Training loss: 0.5530153510686049
Validation loss: 2.662613371105399

Epoch: 6| Step: 9
Training loss: 0.4132353059437474
Validation loss: 2.662136675740613

Epoch: 6| Step: 10
Training loss: 0.41469004597920806
Validation loss: 2.7068221840395625

Epoch: 6| Step: 11
Training loss: 0.47124475364901475
Validation loss: 2.674679643099688

Epoch: 6| Step: 12
Training loss: 0.43807729031399983
Validation loss: 2.6166469945795803

Epoch: 6| Step: 13
Training loss: 0.8080797266245479
Validation loss: 2.6831288089957672

Testing loss: 2.604234577565038
