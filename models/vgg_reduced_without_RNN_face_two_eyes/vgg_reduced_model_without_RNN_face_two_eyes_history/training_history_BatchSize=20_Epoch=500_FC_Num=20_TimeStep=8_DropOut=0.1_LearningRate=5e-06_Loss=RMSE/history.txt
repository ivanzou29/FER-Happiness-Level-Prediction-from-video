Epoch: 1| Step: 0
Training loss: 8.275252563678995
Validation loss: 7.654968756560675

Epoch: 5| Step: 1
Training loss: 8.150218619006342
Validation loss: 7.619683721007643

Epoch: 5| Step: 2
Training loss: 8.326977505813511
Validation loss: 7.580326256134665

Epoch: 5| Step: 3
Training loss: 7.417634479369501
Validation loss: 7.5442843627457234

Epoch: 5| Step: 4
Training loss: 6.9523341039832225
Validation loss: 7.509763624887982

Epoch: 5| Step: 5
Training loss: 7.628697733805524
Validation loss: 7.476570908007915

Epoch: 5| Step: 6
Training loss: 6.686786363974956
Validation loss: 7.437726378000956

Epoch: 5| Step: 7
Training loss: 7.255118306284439
Validation loss: 7.404098165950495

Epoch: 5| Step: 8
Training loss: 6.905648183708623
Validation loss: 7.369917222605851

Epoch: 5| Step: 9
Training loss: 8.007920635702806
Validation loss: 7.334008214702709

Epoch: 5| Step: 10
Training loss: 7.719437170907974
Validation loss: 7.298139333272871

Epoch: 5| Step: 11
Training loss: 6.770726348814235
Validation loss: 7.258615351503729

Epoch: 2| Step: 0
Training loss: 6.998975951357155
Validation loss: 7.223985664152789

Epoch: 5| Step: 1
Training loss: 7.25011786003338
Validation loss: 7.182584867700767

Epoch: 5| Step: 2
Training loss: 6.636813301728621
Validation loss: 7.147275969979482

Epoch: 5| Step: 3
Training loss: 7.279877234461315
Validation loss: 7.107542065775366

Epoch: 5| Step: 4
Training loss: 7.412751896970191
Validation loss: 7.065416684651708

Epoch: 5| Step: 5
Training loss: 6.743879581086781
Validation loss: 7.0239754917373265

Epoch: 5| Step: 6
Training loss: 7.120537682279733
Validation loss: 6.978516866315689

Epoch: 5| Step: 7
Training loss: 7.432451345808629
Validation loss: 6.937802259487662

Epoch: 5| Step: 8
Training loss: 7.231319433091599
Validation loss: 6.8888550414857

Epoch: 5| Step: 9
Training loss: 7.653125857333302
Validation loss: 6.840117479007026

Epoch: 5| Step: 10
Training loss: 6.096963983665578
Validation loss: 6.7913667304463345

Epoch: 5| Step: 11
Training loss: 8.100891026597301
Validation loss: 6.739536676338714

Epoch: 3| Step: 0
Training loss: 7.056779012793329
Validation loss: 6.680718212654513

Epoch: 5| Step: 1
Training loss: 6.717404252943315
Validation loss: 6.626209064734519

Epoch: 5| Step: 2
Training loss: 6.4325637409774865
Validation loss: 6.5742631632316515

Epoch: 5| Step: 3
Training loss: 7.206107558524195
Validation loss: 6.506548834786478

Epoch: 5| Step: 4
Training loss: 6.334610994193243
Validation loss: 6.44570729289236

Epoch: 5| Step: 5
Training loss: 6.434081716277644
Validation loss: 6.378754283234045

Epoch: 5| Step: 6
Training loss: 6.336269233570569
Validation loss: 6.308871255445918

Epoch: 5| Step: 7
Training loss: 6.331476976820481
Validation loss: 6.239395516635785

Epoch: 5| Step: 8
Training loss: 6.214659299097371
Validation loss: 6.167467512074293

Epoch: 5| Step: 9
Training loss: 6.6068909939514695
Validation loss: 6.0893751628460295

Epoch: 5| Step: 10
Training loss: 5.668053214287092
Validation loss: 6.004734423140793

Epoch: 5| Step: 11
Training loss: 4.420900486835454
Validation loss: 5.92246904304157

Epoch: 4| Step: 0
Training loss: 5.82961976056195
Validation loss: 5.840191143339311

Epoch: 5| Step: 1
Training loss: 5.453553978079
Validation loss: 5.750005093171448

Epoch: 5| Step: 2
Training loss: 6.3817228883684525
Validation loss: 5.650218318839757

Epoch: 5| Step: 3
Training loss: 5.659118936391995
Validation loss: 5.554986422579677

Epoch: 5| Step: 4
Training loss: 6.0085137680974
Validation loss: 5.44981915118468

Epoch: 5| Step: 5
Training loss: 5.268996430015549
Validation loss: 5.346086968906295

Epoch: 5| Step: 6
Training loss: 4.972379498448094
Validation loss: 5.236384029960315

Epoch: 5| Step: 7
Training loss: 5.252496579880398
Validation loss: 5.121664520277291

Epoch: 5| Step: 8
Training loss: 4.74775622728522
Validation loss: 4.99234728888273

Epoch: 5| Step: 9
Training loss: 4.911443015189637
Validation loss: 4.87522594221754

Epoch: 5| Step: 10
Training loss: 5.219405264462347
Validation loss: 4.747935616138914

Epoch: 5| Step: 11
Training loss: 4.027963170721339
Validation loss: 4.622031470610485

Epoch: 5| Step: 0
Training loss: 4.461301344482268
Validation loss: 4.49449329409925

Epoch: 5| Step: 1
Training loss: 4.321955390894138
Validation loss: 4.3279330122653015

Epoch: 5| Step: 2
Training loss: 4.390568091407216
Validation loss: 4.20410741317525

Epoch: 5| Step: 3
Training loss: 4.588988035258334
Validation loss: 4.063196562691481

Epoch: 5| Step: 4
Training loss: 4.128829796551512
Validation loss: 3.918445338848729

Epoch: 5| Step: 5
Training loss: 4.167536276034145
Validation loss: 3.7696730407506687

Epoch: 5| Step: 6
Training loss: 4.329237812083016
Validation loss: 3.6235505527693044

Epoch: 5| Step: 7
Training loss: 3.345194281850487
Validation loss: 3.478303332011298

Epoch: 5| Step: 8
Training loss: 3.909097960830683
Validation loss: 3.347532456259423

Epoch: 5| Step: 9
Training loss: 1.8848160336725663
Validation loss: 3.225873108400746

Epoch: 5| Step: 10
Training loss: 2.656815233116967
Validation loss: 3.092772473888289

Epoch: 5| Step: 11
Training loss: 2.9039519053173035
Validation loss: 2.9677081806472483

Epoch: 6| Step: 0
Training loss: 2.791594566059413
Validation loss: 2.886158174243844

Epoch: 5| Step: 1
Training loss: 2.4200272925863446
Validation loss: 2.8066781009870043

Epoch: 5| Step: 2
Training loss: 3.0774761619853193
Validation loss: 2.733917906566754

Epoch: 5| Step: 3
Training loss: 2.684456898835465
Validation loss: 2.7001534815716077

Epoch: 5| Step: 4
Training loss: 3.2770849041572263
Validation loss: 2.675702395054551

Epoch: 5| Step: 5
Training loss: 2.4340156691524077
Validation loss: 2.667833982967039

Epoch: 5| Step: 6
Training loss: 2.634983786111419
Validation loss: 2.6849657870385513

Epoch: 5| Step: 7
Training loss: 2.8251028194114602
Validation loss: 2.734759047649763

Epoch: 5| Step: 8
Training loss: 3.032047913920083
Validation loss: 2.7813091414660707

Epoch: 5| Step: 9
Training loss: 2.8355697519504384
Validation loss: 2.8223529876950337

Epoch: 5| Step: 10
Training loss: 3.6569076337908286
Validation loss: 2.8387315120848076

Epoch: 5| Step: 11
Training loss: 3.044004369364145
Validation loss: 2.851589335136779

Epoch: 7| Step: 0
Training loss: 2.5315380168051567
Validation loss: 2.8671200403909944

Epoch: 5| Step: 1
Training loss: 3.1819704750077116
Validation loss: 2.842846028082458

Epoch: 5| Step: 2
Training loss: 3.3862076211941003
Validation loss: 2.831142087764773

Epoch: 5| Step: 3
Training loss: 2.684094067262558
Validation loss: 2.825294398831485

Epoch: 5| Step: 4
Training loss: 3.2575686429828483
Validation loss: 2.7771217554348206

Epoch: 5| Step: 5
Training loss: 3.0054180175687955
Validation loss: 2.766177002009282

Epoch: 5| Step: 6
Training loss: 2.9236325776396126
Validation loss: 2.72526548591406

Epoch: 5| Step: 7
Training loss: 3.0069750127689776
Validation loss: 2.6957366277948

Epoch: 5| Step: 8
Training loss: 2.3368731509882634
Validation loss: 2.7209293502370704

Epoch: 5| Step: 9
Training loss: 2.3142882984557347
Validation loss: 2.696595506709597

Epoch: 5| Step: 10
Training loss: 2.637441307246461
Validation loss: 2.6749609996353136

Epoch: 5| Step: 11
Training loss: 1.0163938693114263
Validation loss: 2.6578091664174694

Epoch: 8| Step: 0
Training loss: 2.447830999512191
Validation loss: 2.673442685545651

Epoch: 5| Step: 1
Training loss: 2.525597371358775
Validation loss: 2.6796554659901863

Epoch: 5| Step: 2
Training loss: 2.973819780657461
Validation loss: 2.6729504612614594

Epoch: 5| Step: 3
Training loss: 2.4698119957606237
Validation loss: 2.6652649545739324

Epoch: 5| Step: 4
Training loss: 2.56184490483055
Validation loss: 2.664468903926637

Epoch: 5| Step: 5
Training loss: 2.9411559384695214
Validation loss: 2.6452536936737374

Epoch: 5| Step: 6
Training loss: 2.683608675586223
Validation loss: 2.669350239882947

Epoch: 5| Step: 7
Training loss: 3.1631246801714235
Validation loss: 2.6582240865994127

Epoch: 5| Step: 8
Training loss: 2.8858555392289373
Validation loss: 2.672195402346422

Epoch: 5| Step: 9
Training loss: 3.0895233566900258
Validation loss: 2.636159940302429

Epoch: 5| Step: 10
Training loss: 2.5559039005189033
Validation loss: 2.6798287327567163

Epoch: 5| Step: 11
Training loss: 1.0912614031323709
Validation loss: 2.6393054509286813

Epoch: 9| Step: 0
Training loss: 2.2886406311204754
Validation loss: 2.6590076007466585

Epoch: 5| Step: 1
Training loss: 2.4749870222888135
Validation loss: 2.65834284968053

Epoch: 5| Step: 2
Training loss: 3.017129315329378
Validation loss: 2.667179726379067

Epoch: 5| Step: 3
Training loss: 2.8378907930252013
Validation loss: 2.657828415530165

Epoch: 5| Step: 4
Training loss: 3.2851799092024834
Validation loss: 2.654966373326442

Epoch: 5| Step: 5
Training loss: 2.410817258139309
Validation loss: 2.655446428409205

Epoch: 5| Step: 6
Training loss: 3.423047983843467
Validation loss: 2.642381467641939

Epoch: 5| Step: 7
Training loss: 2.6175142454326252
Validation loss: 2.6566858158494373

Epoch: 5| Step: 8
Training loss: 2.5767320973855194
Validation loss: 2.6471251665634

Epoch: 5| Step: 9
Training loss: 2.123178711336141
Validation loss: 2.655729534545402

Epoch: 5| Step: 10
Training loss: 2.902690717820332
Validation loss: 2.6505482569843917

Epoch: 5| Step: 11
Training loss: 1.5970919855435615
Validation loss: 2.653487856239635

Epoch: 10| Step: 0
Training loss: 3.246753097757113
Validation loss: 2.6569630021218624

Epoch: 5| Step: 1
Training loss: 2.3692832205708467
Validation loss: 2.6572089278198967

Epoch: 5| Step: 2
Training loss: 2.4415337857313535
Validation loss: 2.6487369311821753

Epoch: 5| Step: 3
Training loss: 2.412126276984052
Validation loss: 2.6504230576931747

Epoch: 5| Step: 4
Training loss: 2.615851491148279
Validation loss: 2.6257343362576315

Epoch: 5| Step: 5
Training loss: 3.029952725334379
Validation loss: 2.634591939794345

Epoch: 5| Step: 6
Training loss: 2.77293516096047
Validation loss: 2.6337059987621148

Epoch: 5| Step: 7
Training loss: 3.1929304949002058
Validation loss: 2.647448768714397

Epoch: 5| Step: 8
Training loss: 2.0626277306047776
Validation loss: 2.6413081600250767

Epoch: 5| Step: 9
Training loss: 2.834568165986147
Validation loss: 2.653868976878156

Epoch: 5| Step: 10
Training loss: 2.8562090914611815
Validation loss: 2.6606250299476586

Epoch: 5| Step: 11
Training loss: 1.1960708107670284
Validation loss: 2.658396567865139

Epoch: 11| Step: 0
Training loss: 2.732332262228926
Validation loss: 2.640523032000984

Epoch: 5| Step: 1
Training loss: 2.5075286039050195
Validation loss: 2.610782004108625

Epoch: 5| Step: 2
Training loss: 2.541851683172731
Validation loss: 2.624694212253819

Epoch: 5| Step: 3
Training loss: 2.385723599561747
Validation loss: 2.6413999846071126

Epoch: 5| Step: 4
Training loss: 2.425109180470217
Validation loss: 2.6356262392591905

Epoch: 5| Step: 5
Training loss: 3.3882851679565773
Validation loss: 2.6010524872256995

Epoch: 5| Step: 6
Training loss: 2.89491242693017
Validation loss: 2.6346787649758006

Epoch: 5| Step: 7
Training loss: 2.9788213854330836
Validation loss: 2.6693137015025066

Epoch: 5| Step: 8
Training loss: 2.1288698525773357
Validation loss: 2.644010991319644

Epoch: 5| Step: 9
Training loss: 3.0257644570118813
Validation loss: 2.6351007465692664

Epoch: 5| Step: 10
Training loss: 2.407909564141829
Validation loss: 2.6454892848443166

Epoch: 5| Step: 11
Training loss: 3.104794756606603
Validation loss: 2.641821595792218

Epoch: 12| Step: 0
Training loss: 2.5569358521173857
Validation loss: 2.6284979531056014

Epoch: 5| Step: 1
Training loss: 2.9234800775017784
Validation loss: 2.6347116097657866

Epoch: 5| Step: 2
Training loss: 2.8972899435030026
Validation loss: 2.61453191673717

Epoch: 5| Step: 3
Training loss: 3.324783008349914
Validation loss: 2.5959624387456173

Epoch: 5| Step: 4
Training loss: 2.5376991719971325
Validation loss: 2.6247033299724465

Epoch: 5| Step: 5
Training loss: 2.497195673702317
Validation loss: 2.6194231875116594

Epoch: 5| Step: 6
Training loss: 2.7974400295889685
Validation loss: 2.6037271408466998

Epoch: 5| Step: 7
Training loss: 3.0342112755335933
Validation loss: 2.62069992540579

Epoch: 5| Step: 8
Training loss: 2.1361489381763104
Validation loss: 2.5903522189855024

Epoch: 5| Step: 9
Training loss: 2.8975252839269743
Validation loss: 2.6241784058876934

Epoch: 5| Step: 10
Training loss: 1.861345032878348
Validation loss: 2.639002717362807

Epoch: 5| Step: 11
Training loss: 2.0326054672148164
Validation loss: 2.6037885556698686

Epoch: 13| Step: 0
Training loss: 2.974507420897224
Validation loss: 2.627871887561805

Epoch: 5| Step: 1
Training loss: 2.579925555700265
Validation loss: 2.620920504336797

Epoch: 5| Step: 2
Training loss: 2.7328048121418895
Validation loss: 2.6215563961316772

Epoch: 5| Step: 3
Training loss: 2.056524811442679
Validation loss: 2.6274830147847252

Epoch: 5| Step: 4
Training loss: 2.7399105171572318
Validation loss: 2.6234447208780014

Epoch: 5| Step: 5
Training loss: 2.5203335689602926
Validation loss: 2.615772439818667

Epoch: 5| Step: 6
Training loss: 3.2160612561099886
Validation loss: 2.5951439279297466

Epoch: 5| Step: 7
Training loss: 2.657665369266104
Validation loss: 2.6134169200734787

Epoch: 5| Step: 8
Training loss: 2.7047497050747693
Validation loss: 2.5928774633809826

Epoch: 5| Step: 9
Training loss: 2.5653910261885096
Validation loss: 2.631050544708889

Epoch: 5| Step: 10
Training loss: 2.338261599574443
Validation loss: 2.6038436167932932

Epoch: 5| Step: 11
Training loss: 4.129332376972893
Validation loss: 2.5771464292058988

Epoch: 14| Step: 0
Training loss: 2.644433609978558
Validation loss: 2.588712921976084

Epoch: 5| Step: 1
Training loss: 2.8065579693541802
Validation loss: 2.590423616880931

Epoch: 5| Step: 2
Training loss: 2.832446427002781
Validation loss: 2.6373478004871496

Epoch: 5| Step: 3
Training loss: 2.2497317896035045
Validation loss: 2.6317269401179004

Epoch: 5| Step: 4
Training loss: 3.0005502196236273
Validation loss: 2.6189079171806555

Epoch: 5| Step: 5
Training loss: 2.797945212083424
Validation loss: 2.619128449800712

Epoch: 5| Step: 6
Training loss: 2.9359941884121037
Validation loss: 2.6191192595738584

Epoch: 5| Step: 7
Training loss: 2.596872862666934
Validation loss: 2.629482752111929

Epoch: 5| Step: 8
Training loss: 2.5213892510257097
Validation loss: 2.599404842623958

Epoch: 5| Step: 9
Training loss: 2.459727931600883
Validation loss: 2.5930887149139497

Epoch: 5| Step: 10
Training loss: 2.3812483860120537
Validation loss: 2.618027481107898

Epoch: 5| Step: 11
Training loss: 3.039139538256775
Validation loss: 2.5880547774933107

Epoch: 15| Step: 0
Training loss: 3.167650387873852
Validation loss: 2.6266593759414585

Epoch: 5| Step: 1
Training loss: 2.9618588425758454
Validation loss: 2.6038993710986786

Epoch: 5| Step: 2
Training loss: 3.4798986308362485
Validation loss: 2.595269405429016

Epoch: 5| Step: 3
Training loss: 2.3739125623275723
Validation loss: 2.590479447187619

Epoch: 5| Step: 4
Training loss: 2.815944088754681
Validation loss: 2.5732071991773067

Epoch: 5| Step: 5
Training loss: 2.4164113096177426
Validation loss: 2.5978398843740864

Epoch: 5| Step: 6
Training loss: 2.347925459521758
Validation loss: 2.5946758372026983

Epoch: 5| Step: 7
Training loss: 2.44389141093136
Validation loss: 2.627441145367513

Epoch: 5| Step: 8
Training loss: 2.5418428662203287
Validation loss: 2.572691055527324

Epoch: 5| Step: 9
Training loss: 1.9546546744221176
Validation loss: 2.572832400889309

Epoch: 5| Step: 10
Training loss: 2.5626408608030737
Validation loss: 2.600926131428694

Epoch: 5| Step: 11
Training loss: 2.3721440862472853
Validation loss: 2.5930413193378024

Epoch: 16| Step: 0
Training loss: 2.1176718970631025
Validation loss: 2.5807213589075095

Epoch: 5| Step: 1
Training loss: 1.8557853348338473
Validation loss: 2.5990634481594896

Epoch: 5| Step: 2
Training loss: 3.227172202817157
Validation loss: 2.6407572545747002

Epoch: 5| Step: 3
Training loss: 2.2239184290382847
Validation loss: 2.5907130482201772

Epoch: 5| Step: 4
Training loss: 2.3581822898491547
Validation loss: 2.5783713868441454

Epoch: 5| Step: 5
Training loss: 2.611179846902755
Validation loss: 2.5594948499515597

Epoch: 5| Step: 6
Training loss: 2.324250549611768
Validation loss: 2.623457851107562

Epoch: 5| Step: 7
Training loss: 3.0174545509689263
Validation loss: 2.618035508362108

Epoch: 5| Step: 8
Training loss: 3.6636137535039475
Validation loss: 2.638559338560285

Epoch: 5| Step: 9
Training loss: 2.2169192645867373
Validation loss: 2.591943824356538

Epoch: 5| Step: 10
Training loss: 2.901489789356788
Validation loss: 2.6130134319839042

Epoch: 5| Step: 11
Training loss: 2.118607611358692
Validation loss: 2.6358011848524567

Epoch: 17| Step: 0
Training loss: 2.616168469991737
Validation loss: 2.5847509491255796

Epoch: 5| Step: 1
Training loss: 2.4132703944511937
Validation loss: 2.6066579206759797

Epoch: 5| Step: 2
Training loss: 2.3668616545859757
Validation loss: 2.6174560333197965

Epoch: 5| Step: 3
Training loss: 2.282711867060225
Validation loss: 2.610580029035202

Epoch: 5| Step: 4
Training loss: 2.591973673145202
Validation loss: 2.5866997815950468

Epoch: 5| Step: 5
Training loss: 2.277862751417309
Validation loss: 2.613621106593265

Epoch: 5| Step: 6
Training loss: 2.7336201525053903
Validation loss: 2.5977699465237487

Epoch: 5| Step: 7
Training loss: 2.998852510341944
Validation loss: 2.5735319067371254

Epoch: 5| Step: 8
Training loss: 2.4384136932787044
Validation loss: 2.572260233632788

Epoch: 5| Step: 9
Training loss: 2.747773569664889
Validation loss: 2.590603338733116

Epoch: 5| Step: 10
Training loss: 3.0584802521246917
Validation loss: 2.575662712506688

Epoch: 5| Step: 11
Training loss: 3.5922052131604385
Validation loss: 2.5650253025589116

Epoch: 18| Step: 0
Training loss: 2.5017453776698346
Validation loss: 2.6293986229258146

Epoch: 5| Step: 1
Training loss: 2.9361570819234117
Validation loss: 2.5740599093637

Epoch: 5| Step: 2
Training loss: 2.781289261101487
Validation loss: 2.6006774733436298

Epoch: 5| Step: 3
Training loss: 2.6103284544373273
Validation loss: 2.6371570816211407

Epoch: 5| Step: 4
Training loss: 2.7969177924777155
Validation loss: 2.596985093991424

Epoch: 5| Step: 5
Training loss: 2.958882204816126
Validation loss: 2.5898818736772924

Epoch: 5| Step: 6
Training loss: 2.1213102282918834
Validation loss: 2.6017945675830663

Epoch: 5| Step: 7
Training loss: 2.5627496179095335
Validation loss: 2.611052691423876

Epoch: 5| Step: 8
Training loss: 2.6812883494375592
Validation loss: 2.606554662002629

Epoch: 5| Step: 9
Training loss: 2.714997167849249
Validation loss: 2.614757928426717

Epoch: 5| Step: 10
Training loss: 2.3522357167116303
Validation loss: 2.595627411675047

Epoch: 5| Step: 11
Training loss: 2.4702808124746607
Validation loss: 2.5960094652892365

Epoch: 19| Step: 0
Training loss: 3.0332155442336703
Validation loss: 2.5880304992110403

Epoch: 5| Step: 1
Training loss: 2.102757564376416
Validation loss: 2.5459476139892674

Epoch: 5| Step: 2
Training loss: 2.9650888454770232
Validation loss: 2.595366468333509

Epoch: 5| Step: 3
Training loss: 2.5709725781717667
Validation loss: 2.5704403645443388

Epoch: 5| Step: 4
Training loss: 2.4259924558630725
Validation loss: 2.5463723464808927

Epoch: 5| Step: 5
Training loss: 2.3970535709154226
Validation loss: 2.5843110439100823

Epoch: 5| Step: 6
Training loss: 3.3258554663161037
Validation loss: 2.5691437697114625

Epoch: 5| Step: 7
Training loss: 2.3256063470499924
Validation loss: 2.566010785806024

Epoch: 5| Step: 8
Training loss: 2.25375000727818
Validation loss: 2.543921054521859

Epoch: 5| Step: 9
Training loss: 2.795212747191703
Validation loss: 2.5986165769295155

Epoch: 5| Step: 10
Training loss: 1.946011153542997
Validation loss: 2.561429290456873

Epoch: 5| Step: 11
Training loss: 1.5901084885682706
Validation loss: 2.616735151684466

Epoch: 20| Step: 0
Training loss: 2.6095779248670405
Validation loss: 2.591890829261955

Epoch: 5| Step: 1
Training loss: 2.863415973819301
Validation loss: 2.5818192187658044

Epoch: 5| Step: 2
Training loss: 2.6047236851385276
Validation loss: 2.5554902490504325

Epoch: 5| Step: 3
Training loss: 2.0470052197216964
Validation loss: 2.599019974236854

Epoch: 5| Step: 4
Training loss: 2.125659840182467
Validation loss: 2.586495853008036

Epoch: 5| Step: 5
Training loss: 1.7879949324661915
Validation loss: 2.5673467653650075

Epoch: 5| Step: 6
Training loss: 3.1381337167952714
Validation loss: 2.590273726008169

Epoch: 5| Step: 7
Training loss: 1.9636385123926665
Validation loss: 2.5773703539938873

Epoch: 5| Step: 8
Training loss: 3.1250094604348986
Validation loss: 2.6102496449670283

Epoch: 5| Step: 9
Training loss: 3.17491883301801
Validation loss: 2.5897837766643197

Epoch: 5| Step: 10
Training loss: 2.4649317706029974
Validation loss: 2.568053507994606

Epoch: 5| Step: 11
Training loss: 3.3611729268536403
Validation loss: 2.572819662903875

Epoch: 21| Step: 0
Training loss: 3.3807201654344445
Validation loss: 2.5837445213851584

Epoch: 5| Step: 1
Training loss: 2.578157829306841
Validation loss: 2.566534897489281

Epoch: 5| Step: 2
Training loss: 2.156398270526377
Validation loss: 2.5529822511582716

Epoch: 5| Step: 3
Training loss: 2.704486305691589
Validation loss: 2.538825598204252

Epoch: 5| Step: 4
Training loss: 2.07388182236618
Validation loss: 2.5473585274371517

Epoch: 5| Step: 5
Training loss: 2.748287187709008
Validation loss: 2.578649463675408

Epoch: 5| Step: 6
Training loss: 2.2782345006342895
Validation loss: 2.562419676878666

Epoch: 5| Step: 7
Training loss: 2.9711369605863025
Validation loss: 2.602619834538731

Epoch: 5| Step: 8
Training loss: 1.9508752912495604
Validation loss: 2.5834149352895865

Epoch: 5| Step: 9
Training loss: 2.1263942632338018
Validation loss: 2.602372418591852

Epoch: 5| Step: 10
Training loss: 3.050087042645243
Validation loss: 2.5510800095637873

Epoch: 5| Step: 11
Training loss: 2.9063251444628344
Validation loss: 2.585646498672727

Epoch: 22| Step: 0
Training loss: 2.16628704657907
Validation loss: 2.559682547427446

Epoch: 5| Step: 1
Training loss: 2.31185976393135
Validation loss: 2.548210725999174

Epoch: 5| Step: 2
Training loss: 2.7631215117026318
Validation loss: 2.5707917158034013

Epoch: 5| Step: 3
Training loss: 2.9346608178119302
Validation loss: 2.540436901873067

Epoch: 5| Step: 4
Training loss: 2.7404863346387622
Validation loss: 2.564535449087389

Epoch: 5| Step: 5
Training loss: 2.136495351881403
Validation loss: 2.613106775470409

Epoch: 5| Step: 6
Training loss: 2.627378748338206
Validation loss: 2.565842650300476

Epoch: 5| Step: 7
Training loss: 2.115834609766612
Validation loss: 2.563093453980331

Epoch: 5| Step: 8
Training loss: 2.614843429050249
Validation loss: 2.6127311800467896

Epoch: 5| Step: 9
Training loss: 3.252318802169059
Validation loss: 2.5972158111203014

Epoch: 5| Step: 10
Training loss: 2.3698377220513267
Validation loss: 2.5930378062496593

Epoch: 5| Step: 11
Training loss: 1.7519895960180996
Validation loss: 2.6072574749385056

Epoch: 23| Step: 0
Training loss: 2.728166256097792
Validation loss: 2.564929306860581

Epoch: 5| Step: 1
Training loss: 2.3097603524152888
Validation loss: 2.5551794844122524

Epoch: 5| Step: 2
Training loss: 2.2375585111501133
Validation loss: 2.550591064965205

Epoch: 5| Step: 3
Training loss: 2.4800963595343797
Validation loss: 2.5993192698582632

Epoch: 5| Step: 4
Training loss: 2.5844080340524034
Validation loss: 2.5386365836494664

Epoch: 5| Step: 5
Training loss: 2.7456008229970252
Validation loss: 2.534642947857384

Epoch: 5| Step: 6
Training loss: 2.2081681555626527
Validation loss: 2.5489534934283347

Epoch: 5| Step: 7
Training loss: 2.566123261664407
Validation loss: 2.5863212730932665

Epoch: 5| Step: 8
Training loss: 3.0466511962074914
Validation loss: 2.5485551709876764

Epoch: 5| Step: 9
Training loss: 2.4745560951187597
Validation loss: 2.5707571964850104

Epoch: 5| Step: 10
Training loss: 2.815286315802979
Validation loss: 2.593199805615561

Epoch: 5| Step: 11
Training loss: 1.0633715252808862
Validation loss: 2.5862546036785163

Epoch: 24| Step: 0
Training loss: 2.886609066336394
Validation loss: 2.571721789221912

Epoch: 5| Step: 1
Training loss: 2.3059062257014085
Validation loss: 2.5698575715849357

Epoch: 5| Step: 2
Training loss: 2.001579376316319
Validation loss: 2.5937394827510754

Epoch: 5| Step: 3
Training loss: 2.3825067042509622
Validation loss: 2.5232162024244165

Epoch: 5| Step: 4
Training loss: 2.0090743675006033
Validation loss: 2.5661012883491683

Epoch: 5| Step: 5
Training loss: 3.4699994835317267
Validation loss: 2.6030658467911563

Epoch: 5| Step: 6
Training loss: 2.344445595833896
Validation loss: 2.6021455220308716

Epoch: 5| Step: 7
Training loss: 2.860875637483561
Validation loss: 2.6126820818709193

Epoch: 5| Step: 8
Training loss: 1.9657549404260253
Validation loss: 2.569660865558755

Epoch: 5| Step: 9
Training loss: 2.6695822532544056
Validation loss: 2.594791628330822

Epoch: 5| Step: 10
Training loss: 2.5454619998946586
Validation loss: 2.557347634370556

Epoch: 5| Step: 11
Training loss: 2.7807284091096514
Validation loss: 2.590802739622142

Epoch: 25| Step: 0
Training loss: 2.559508275252101
Validation loss: 2.5714874017226235

Epoch: 5| Step: 1
Training loss: 2.7255460489512213
Validation loss: 2.6051076822820134

Epoch: 5| Step: 2
Training loss: 2.390288884089506
Validation loss: 2.5627311218518307

Epoch: 5| Step: 3
Training loss: 1.9085158342719475
Validation loss: 2.5796738952117777

Epoch: 5| Step: 4
Training loss: 1.9545782557269535
Validation loss: 2.5940780508793595

Epoch: 5| Step: 5
Training loss: 3.3624137441923754
Validation loss: 2.5883764921689343

Epoch: 5| Step: 6
Training loss: 2.7184696272177153
Validation loss: 2.6092007744467645

Epoch: 5| Step: 7
Training loss: 2.043018464455463
Validation loss: 2.5892668743732234

Epoch: 5| Step: 8
Training loss: 3.2433318175429604
Validation loss: 2.5278351908813796

Epoch: 5| Step: 9
Training loss: 2.722493192806088
Validation loss: 2.5934206512194367

Epoch: 5| Step: 10
Training loss: 1.9512002234552246
Validation loss: 2.5436852964752887

Epoch: 5| Step: 11
Training loss: 2.3973239960571733
Validation loss: 2.637382457699287

Epoch: 26| Step: 0
Training loss: 2.7949452482535078
Validation loss: 2.5842880316650017

Epoch: 5| Step: 1
Training loss: 2.4712846516411773
Validation loss: 2.565137660910003

Epoch: 5| Step: 2
Training loss: 2.7037209972813647
Validation loss: 2.553758921029593

Epoch: 5| Step: 3
Training loss: 2.815460427202765
Validation loss: 2.5638284922425156

Epoch: 5| Step: 4
Training loss: 3.118295878829853
Validation loss: 2.541128630572401

Epoch: 5| Step: 5
Training loss: 2.268810689655619
Validation loss: 2.5784984510805575

Epoch: 5| Step: 6
Training loss: 2.1079935707269306
Validation loss: 2.57121127028189

Epoch: 5| Step: 7
Training loss: 2.4232790906870556
Validation loss: 2.5460428134301853

Epoch: 5| Step: 8
Training loss: 2.4101145043614216
Validation loss: 2.589531827451758

Epoch: 5| Step: 9
Training loss: 2.277065358232038
Validation loss: 2.539419655744831

Epoch: 5| Step: 10
Training loss: 2.6154806008353315
Validation loss: 2.5732094499024405

Epoch: 5| Step: 11
Training loss: 1.694981555894635
Validation loss: 2.584285638748778

Epoch: 27| Step: 0
Training loss: 2.534268592642086
Validation loss: 2.5855340057005125

Epoch: 5| Step: 1
Training loss: 1.8629440546322633
Validation loss: 2.577939545097418

Epoch: 5| Step: 2
Training loss: 3.136936887992107
Validation loss: 2.592882501543721

Epoch: 5| Step: 3
Training loss: 2.2472764591650125
Validation loss: 2.6179326415334745

Epoch: 5| Step: 4
Training loss: 2.3284678366751526
Validation loss: 2.5871041653958073

Epoch: 5| Step: 5
Training loss: 3.1609447047348995
Validation loss: 2.598248433850172

Epoch: 5| Step: 6
Training loss: 2.2814808558877875
Validation loss: 2.585699456544217

Epoch: 5| Step: 7
Training loss: 2.624143733286494
Validation loss: 2.578283050778757

Epoch: 5| Step: 8
Training loss: 2.1457832725635924
Validation loss: 2.5969245052094694

Epoch: 5| Step: 9
Training loss: 2.405715288473334
Validation loss: 2.594656749394419

Epoch: 5| Step: 10
Training loss: 2.5936670864594977
Validation loss: 2.6039844004107144

Epoch: 5| Step: 11
Training loss: 3.326745548829257
Validation loss: 2.5555217947722455

Epoch: 28| Step: 0
Training loss: 2.6019953004001457
Validation loss: 2.591192604805757

Epoch: 5| Step: 1
Training loss: 2.088919918470129
Validation loss: 2.6147877333383036

Epoch: 5| Step: 2
Training loss: 2.5707545494566855
Validation loss: 2.5948603486341275

Epoch: 5| Step: 3
Training loss: 2.9035687948136895
Validation loss: 2.5416454772899773

Epoch: 5| Step: 4
Training loss: 2.6867544337656946
Validation loss: 2.589834896972009

Epoch: 5| Step: 5
Training loss: 2.4138932153301833
Validation loss: 2.552360264032202

Epoch: 5| Step: 6
Training loss: 2.17022159130608
Validation loss: 2.608541599212037

Epoch: 5| Step: 7
Training loss: 2.320422648374611
Validation loss: 2.5896820278699892

Epoch: 5| Step: 8
Training loss: 1.7989477393260467
Validation loss: 2.569864276503958

Epoch: 5| Step: 9
Training loss: 2.300415320837945
Validation loss: 2.560657373716711

Epoch: 5| Step: 10
Training loss: 3.0382091432246123
Validation loss: 2.560049975318427

Epoch: 5| Step: 11
Training loss: 4.259003470905553
Validation loss: 2.5199835832063604

Epoch: 29| Step: 0
Training loss: 2.557278127433742
Validation loss: 2.546590836007214

Epoch: 5| Step: 1
Training loss: 2.30056176166833
Validation loss: 2.552236255942798

Epoch: 5| Step: 2
Training loss: 2.335596372262026
Validation loss: 2.553998992409155

Epoch: 5| Step: 3
Training loss: 2.5136361167753325
Validation loss: 2.574418735019974

Epoch: 5| Step: 4
Training loss: 1.654668808958484
Validation loss: 2.582184064212578

Epoch: 5| Step: 5
Training loss: 2.4220629219242036
Validation loss: 2.5674029756133696

Epoch: 5| Step: 6
Training loss: 2.640354390922148
Validation loss: 2.5715721970296257

Epoch: 5| Step: 7
Training loss: 2.680973556245856
Validation loss: 2.585852822322429

Epoch: 5| Step: 8
Training loss: 2.7351319055637004
Validation loss: 2.5649381102952225

Epoch: 5| Step: 9
Training loss: 3.2373130832753123
Validation loss: 2.5760421180390485

Epoch: 5| Step: 10
Training loss: 2.685059170914536
Validation loss: 2.5750040410760078

Epoch: 5| Step: 11
Training loss: 1.473784239858989
Validation loss: 2.6063042997136074

Epoch: 30| Step: 0
Training loss: 2.141840123476183
Validation loss: 2.600511730098447

Epoch: 5| Step: 1
Training loss: 2.2005004400327834
Validation loss: 2.571527269386074

Epoch: 5| Step: 2
Training loss: 2.3091739758041196
Validation loss: 2.542397481307442

Epoch: 5| Step: 3
Training loss: 2.395590617836061
Validation loss: 2.5872706600345676

Epoch: 5| Step: 4
Training loss: 2.8495464566391826
Validation loss: 2.581630458302873

Epoch: 5| Step: 5
Training loss: 2.5769994879867526
Validation loss: 2.566306500792268

Epoch: 5| Step: 6
Training loss: 2.677419698242984
Validation loss: 2.5620936211068073

Epoch: 5| Step: 7
Training loss: 3.084545275346767
Validation loss: 2.574599828766542

Epoch: 5| Step: 8
Training loss: 2.8338485885048272
Validation loss: 2.562174600006606

Epoch: 5| Step: 9
Training loss: 1.631900441363336
Validation loss: 2.5701062603795104

Epoch: 5| Step: 10
Training loss: 2.149475290898707
Validation loss: 2.556238086893416

Epoch: 5| Step: 11
Training loss: 3.5248606444604604
Validation loss: 2.5985328285223774

Epoch: 31| Step: 0
Training loss: 2.906640139409145
Validation loss: 2.5794688874037193

Epoch: 5| Step: 1
Training loss: 2.0372525070686187
Validation loss: 2.5788830808199483

Epoch: 5| Step: 2
Training loss: 2.750802876572452
Validation loss: 2.534366353338114

Epoch: 5| Step: 3
Training loss: 1.9175223707065412
Validation loss: 2.542613053923166

Epoch: 5| Step: 4
Training loss: 2.1411212429477113
Validation loss: 2.5553669118419986

Epoch: 5| Step: 5
Training loss: 2.226283005689829
Validation loss: 2.599158718255566

Epoch: 5| Step: 6
Training loss: 2.440677723333424
Validation loss: 2.5798841389557765

Epoch: 5| Step: 7
Training loss: 2.801606252299924
Validation loss: 2.595088906161677

Epoch: 5| Step: 8
Training loss: 2.1724905335600897
Validation loss: 2.5633052010557105

Epoch: 5| Step: 9
Training loss: 2.7445220139215323
Validation loss: 2.5569113172079336

Epoch: 5| Step: 10
Training loss: 3.1168310587837484
Validation loss: 2.5507180019635998

Epoch: 5| Step: 11
Training loss: 1.4519509115091918
Validation loss: 2.611439343264087

Epoch: 32| Step: 0
Training loss: 2.05854267440641
Validation loss: 2.5871619545832383

Epoch: 5| Step: 1
Training loss: 2.2059744946552162
Validation loss: 2.574649336773925

Epoch: 5| Step: 2
Training loss: 2.3540474065319303
Validation loss: 2.5959625420679506

Epoch: 5| Step: 3
Training loss: 2.2000434914538234
Validation loss: 2.5663955742446056

Epoch: 5| Step: 4
Training loss: 2.722717196905726
Validation loss: 2.5809537569793344

Epoch: 5| Step: 5
Training loss: 1.8450457658751525
Validation loss: 2.578407514871913

Epoch: 5| Step: 6
Training loss: 3.0844053690148634
Validation loss: 2.61712150300733

Epoch: 5| Step: 7
Training loss: 2.6220528543413217
Validation loss: 2.5306839604385614

Epoch: 5| Step: 8
Training loss: 2.072470867840336
Validation loss: 2.5410286162442834

Epoch: 5| Step: 9
Training loss: 2.9683622408156647
Validation loss: 2.5820495558651033

Epoch: 5| Step: 10
Training loss: 2.554300261380182
Validation loss: 2.5422179075117315

Epoch: 5| Step: 11
Training loss: 3.492137251456164
Validation loss: 2.6156409652417176

Epoch: 33| Step: 0
Training loss: 2.061369846392375
Validation loss: 2.5742042861400924

Epoch: 5| Step: 1
Training loss: 2.0474347230149545
Validation loss: 2.5578577201137915

Epoch: 5| Step: 2
Training loss: 3.077571296268888
Validation loss: 2.5383429774462045

Epoch: 5| Step: 3
Training loss: 1.8090526418834103
Validation loss: 2.585053249507947

Epoch: 5| Step: 4
Training loss: 2.026541784646799
Validation loss: 2.596559638205709

Epoch: 5| Step: 5
Training loss: 2.694603514372831
Validation loss: 2.5898639300343143

Epoch: 5| Step: 6
Training loss: 3.550361700839382
Validation loss: 2.5752300037819524

Epoch: 5| Step: 7
Training loss: 2.458676998449092
Validation loss: 2.5852499064033645

Epoch: 5| Step: 8
Training loss: 2.905858003165004
Validation loss: 2.5529245326678134

Epoch: 5| Step: 9
Training loss: 2.015277448157995
Validation loss: 2.594879000426945

Epoch: 5| Step: 10
Training loss: 2.409669304473414
Validation loss: 2.584077194749664

Epoch: 5| Step: 11
Training loss: 2.094124717772952
Validation loss: 2.554432719180327

Epoch: 34| Step: 0
Training loss: 2.0557828239150173
Validation loss: 2.5750487113098246

Epoch: 5| Step: 1
Training loss: 2.669088773643881
Validation loss: 2.557935972812504

Epoch: 5| Step: 2
Training loss: 2.820242334058359
Validation loss: 2.553732219969624

Epoch: 5| Step: 3
Training loss: 2.6000373654248174
Validation loss: 2.589643738216812

Epoch: 5| Step: 4
Training loss: 3.082982292468419
Validation loss: 2.6020064123179987

Epoch: 5| Step: 5
Training loss: 1.8540325187703584
Validation loss: 2.5703145097687967

Epoch: 5| Step: 6
Training loss: 2.1245359026181863
Validation loss: 2.5687818037200563

Epoch: 5| Step: 7
Training loss: 2.542098545424319
Validation loss: 2.5391608116483857

Epoch: 5| Step: 8
Training loss: 1.842875774475237
Validation loss: 2.585196935480131

Epoch: 5| Step: 9
Training loss: 2.8620552883605885
Validation loss: 2.5792403226533263

Epoch: 5| Step: 10
Training loss: 2.45929791767158
Validation loss: 2.5894131770025495

Epoch: 5| Step: 11
Training loss: 2.239540797576322
Validation loss: 2.614535739105808

Epoch: 35| Step: 0
Training loss: 2.390722335130411
Validation loss: 2.567752815825915

Epoch: 5| Step: 1
Training loss: 2.122432054705936
Validation loss: 2.571555543374717

Epoch: 5| Step: 2
Training loss: 1.614678172945962
Validation loss: 2.5887702224398397

Epoch: 5| Step: 3
Training loss: 3.016015378361358
Validation loss: 2.5658871083531634

Epoch: 5| Step: 4
Training loss: 2.547006521749066
Validation loss: 2.631190880664779

Epoch: 5| Step: 5
Training loss: 2.53901949332568
Validation loss: 2.5768161071306994

Epoch: 5| Step: 6
Training loss: 2.4695207382601136
Validation loss: 2.576943436949863

Epoch: 5| Step: 7
Training loss: 2.3968432965227278
Validation loss: 2.5670239127679615

Epoch: 5| Step: 8
Training loss: 2.787553480516254
Validation loss: 2.60102073366671

Epoch: 5| Step: 9
Training loss: 2.474733658148281
Validation loss: 2.5792099028267077

Epoch: 5| Step: 10
Training loss: 2.6783851595099435
Validation loss: 2.544263499368791

Epoch: 5| Step: 11
Training loss: 1.68728212433548
Validation loss: 2.5768698440193

Epoch: 36| Step: 0
Training loss: 2.489958049926357
Validation loss: 2.5952904140873128

Epoch: 5| Step: 1
Training loss: 2.0313875591943096
Validation loss: 2.5784007493333045

Epoch: 5| Step: 2
Training loss: 2.2226351182197894
Validation loss: 2.5542117228949706

Epoch: 5| Step: 3
Training loss: 2.6032604827977526
Validation loss: 2.5631441919327145

Epoch: 5| Step: 4
Training loss: 2.376359951760425
Validation loss: 2.5705383379353437

Epoch: 5| Step: 5
Training loss: 2.7766523613929515
Validation loss: 2.5482779970038565

Epoch: 5| Step: 6
Training loss: 2.8329722978534884
Validation loss: 2.5716855325045995

Epoch: 5| Step: 7
Training loss: 2.972909843866494
Validation loss: 2.5899937213725868

Epoch: 5| Step: 8
Training loss: 2.1203816660518937
Validation loss: 2.551930227682511

Epoch: 5| Step: 9
Training loss: 2.8574273819260845
Validation loss: 2.591185899485434

Epoch: 5| Step: 10
Training loss: 1.877550552033008
Validation loss: 2.5644086227177616

Epoch: 5| Step: 11
Training loss: 2.5181775145310827
Validation loss: 2.5627780042433166

Epoch: 37| Step: 0
Training loss: 2.634397397562659
Validation loss: 2.51593575226693

Epoch: 5| Step: 1
Training loss: 2.3542078290283337
Validation loss: 2.5777730874988576

Epoch: 5| Step: 2
Training loss: 2.1059358039845733
Validation loss: 2.573362594962727

Epoch: 5| Step: 3
Training loss: 2.642521104105799
Validation loss: 2.5780759941606806

Epoch: 5| Step: 4
Training loss: 2.376908990705714
Validation loss: 2.6334709642051832

Epoch: 5| Step: 5
Training loss: 2.991276136603747
Validation loss: 2.581496032707608

Epoch: 5| Step: 6
Training loss: 1.8157346078482106
Validation loss: 2.6149119908941523

Epoch: 5| Step: 7
Training loss: 2.9186020742175445
Validation loss: 2.5469404106867706

Epoch: 5| Step: 8
Training loss: 2.152115659172462
Validation loss: 2.577822461342715

Epoch: 5| Step: 9
Training loss: 2.4749887562506006
Validation loss: 2.593116795948358

Epoch: 5| Step: 10
Training loss: 2.746257923585333
Validation loss: 2.571277485575236

Epoch: 5| Step: 11
Training loss: 0.8132005752287489
Validation loss: 2.5710461583036586

Epoch: 38| Step: 0
Training loss: 2.6731058598373405
Validation loss: 2.5738118360927107

Epoch: 5| Step: 1
Training loss: 2.3130366759404413
Validation loss: 2.5689785983239912

Epoch: 5| Step: 2
Training loss: 3.060818736180631
Validation loss: 2.5971250483296577

Epoch: 5| Step: 3
Training loss: 2.5997606974294625
Validation loss: 2.5558838332549634

Epoch: 5| Step: 4
Training loss: 2.242309460662535
Validation loss: 2.533006564876906

Epoch: 5| Step: 5
Training loss: 2.346604097175191
Validation loss: 2.5845135151568823

Epoch: 5| Step: 6
Training loss: 2.9657478009636793
Validation loss: 2.566432867584694

Epoch: 5| Step: 7
Training loss: 1.810978415210484
Validation loss: 2.561960593880894

Epoch: 5| Step: 8
Training loss: 2.1836973653650356
Validation loss: 2.549989087573868

Epoch: 5| Step: 9
Training loss: 2.5774667535334124
Validation loss: 2.5913146106186966

Epoch: 5| Step: 10
Training loss: 2.2500659085263264
Validation loss: 2.557107671475048

Epoch: 5| Step: 11
Training loss: 1.8089711267245252
Validation loss: 2.5864029856267745

Epoch: 39| Step: 0
Training loss: 3.3308320833620106
Validation loss: 2.554146650110401

Epoch: 5| Step: 1
Training loss: 2.9895621552642098
Validation loss: 2.591512166617781

Epoch: 5| Step: 2
Training loss: 2.1350292939939157
Validation loss: 2.534508820844823

Epoch: 5| Step: 3
Training loss: 2.3205231336555485
Validation loss: 2.5730768429296806

Epoch: 5| Step: 4
Training loss: 1.7961454817932643
Validation loss: 2.517718291246521

Epoch: 5| Step: 5
Training loss: 2.4682771254001112
Validation loss: 2.5765828346389235

Epoch: 5| Step: 6
Training loss: 2.4743860350206424
Validation loss: 2.576388519872026

Epoch: 5| Step: 7
Training loss: 2.4005108051307156
Validation loss: 2.5689879717896065

Epoch: 5| Step: 8
Training loss: 2.262634302863561
Validation loss: 2.560835445000568

Epoch: 5| Step: 9
Training loss: 2.4461587532346734
Validation loss: 2.5705068180486257

Epoch: 5| Step: 10
Training loss: 1.917128369104236
Validation loss: 2.5421840279275467

Epoch: 5| Step: 11
Training loss: 1.2017030115402667
Validation loss: 2.5979415125042427

Epoch: 40| Step: 0
Training loss: 2.608796746603286
Validation loss: 2.635850155779013

Epoch: 5| Step: 1
Training loss: 2.7525743226039765
Validation loss: 2.5444808152279434

Epoch: 5| Step: 2
Training loss: 2.7154196149025585
Validation loss: 2.6217867735248657

Epoch: 5| Step: 3
Training loss: 2.7901287017725247
Validation loss: 2.6091299608191623

Epoch: 5| Step: 4
Training loss: 2.2274992461369156
Validation loss: 2.582911369768342

Epoch: 5| Step: 5
Training loss: 2.250273793834163
Validation loss: 2.619545975622967

Epoch: 5| Step: 6
Training loss: 2.676690920161305
Validation loss: 2.590678050437889

Epoch: 5| Step: 7
Training loss: 2.264271088252507
Validation loss: 2.6082179041438955

Epoch: 5| Step: 8
Training loss: 1.9336792589796987
Validation loss: 2.636476832465225

Epoch: 5| Step: 9
Training loss: 2.22198615674669
Validation loss: 2.5969680792404164

Epoch: 5| Step: 10
Training loss: 2.0610486328147117
Validation loss: 2.59701253616295

Epoch: 5| Step: 11
Training loss: 3.3524461839468453
Validation loss: 2.5966542809276287

Epoch: 41| Step: 0
Training loss: 1.8882779772804696
Validation loss: 2.6254690863780445

Epoch: 5| Step: 1
Training loss: 2.473500088196848
Validation loss: 2.6066440979557006

Epoch: 5| Step: 2
Training loss: 1.9837967638394127
Validation loss: 2.526334023353203

Epoch: 5| Step: 3
Training loss: 2.1437938096266067
Validation loss: 2.5152808994604077

Epoch: 5| Step: 4
Training loss: 2.8625627269285445
Validation loss: 2.5998015415120173

Epoch: 5| Step: 5
Training loss: 2.9691890994143595
Validation loss: 2.5681022292911906

Epoch: 5| Step: 6
Training loss: 2.216574125820097
Validation loss: 2.5487836811970186

Epoch: 5| Step: 7
Training loss: 2.773115112479644
Validation loss: 2.572234639932426

Epoch: 5| Step: 8
Training loss: 2.717523232284385
Validation loss: 2.554128346510947

Epoch: 5| Step: 9
Training loss: 1.976855049044687
Validation loss: 2.5743612964855345

Epoch: 5| Step: 10
Training loss: 2.4951998403935014
Validation loss: 2.570712664217974

Epoch: 5| Step: 11
Training loss: 2.6577339963627593
Validation loss: 2.6067840253183028

Epoch: 42| Step: 0
Training loss: 2.513412829776868
Validation loss: 2.605502870442082

Epoch: 5| Step: 1
Training loss: 2.142451043476571
Validation loss: 2.6035318300201227

Epoch: 5| Step: 2
Training loss: 2.903040272243157
Validation loss: 2.646629337033322

Epoch: 5| Step: 3
Training loss: 2.6785357699972545
Validation loss: 2.6468003613405777

Epoch: 5| Step: 4
Training loss: 2.616696804221339
Validation loss: 2.591254489224353

Epoch: 5| Step: 5
Training loss: 1.7172294132577535
Validation loss: 2.6272036805192887

Epoch: 5| Step: 6
Training loss: 1.9608742753129238
Validation loss: 2.669943339911059

Epoch: 5| Step: 7
Training loss: 2.2231094086116117
Validation loss: 2.6385085975170033

Epoch: 5| Step: 8
Training loss: 1.8682357846105544
Validation loss: 2.5989450608540805

Epoch: 5| Step: 9
Training loss: 2.814688106895526
Validation loss: 2.606860931292672

Epoch: 5| Step: 10
Training loss: 2.712080393035681
Validation loss: 2.5876302988843234

Epoch: 5| Step: 11
Training loss: 2.872972519857006
Validation loss: 2.583856976925419

Epoch: 43| Step: 0
Training loss: 2.9587023509370507
Validation loss: 2.592390947212518

Epoch: 5| Step: 1
Training loss: 2.4775308827651235
Validation loss: 2.5820271929133365

Epoch: 5| Step: 2
Training loss: 2.3442359929072616
Validation loss: 2.5751312868975944

Epoch: 5| Step: 3
Training loss: 2.100213280700885
Validation loss: 2.5801488870008096

Epoch: 5| Step: 4
Training loss: 2.713715726476968
Validation loss: 2.5651201250899853

Epoch: 5| Step: 5
Training loss: 2.6731933553615095
Validation loss: 2.5748998602434874

Epoch: 5| Step: 6
Training loss: 1.9120493987577296
Validation loss: 2.5217149364627676

Epoch: 5| Step: 7
Training loss: 2.162799452847185
Validation loss: 2.5789415819516845

Epoch: 5| Step: 8
Training loss: 2.6109894652020795
Validation loss: 2.5593757152750447

Epoch: 5| Step: 9
Training loss: 2.2499861186976857
Validation loss: 2.6015840554322867

Epoch: 5| Step: 10
Training loss: 2.2723216041567014
Validation loss: 2.555809050895416

Epoch: 5| Step: 11
Training loss: 0.8782783130107338
Validation loss: 2.5754965976131503

Epoch: 44| Step: 0
Training loss: 2.6765331687589446
Validation loss: 2.5774364438193036

Epoch: 5| Step: 1
Training loss: 2.5160948510052976
Validation loss: 2.585639596473263

Epoch: 5| Step: 2
Training loss: 1.8561877975574093
Validation loss: 2.555004601819696

Epoch: 5| Step: 3
Training loss: 3.0177671107891904
Validation loss: 2.5271071530126537

Epoch: 5| Step: 4
Training loss: 1.9291543571568301
Validation loss: 2.5349728694789455

Epoch: 5| Step: 5
Training loss: 2.075356151855256
Validation loss: 2.5690208907895893

Epoch: 5| Step: 6
Training loss: 3.0722816112803253
Validation loss: 2.535168272047726

Epoch: 5| Step: 7
Training loss: 2.015833999089098
Validation loss: 2.59257757736644

Epoch: 5| Step: 8
Training loss: 1.9269230612701083
Validation loss: 2.5867862365024012

Epoch: 5| Step: 9
Training loss: 2.3268600201899448
Validation loss: 2.5899388836188075

Epoch: 5| Step: 10
Training loss: 2.7045864498449776
Validation loss: 2.5785113035606075

Epoch: 5| Step: 11
Training loss: 2.7924813652270593
Validation loss: 2.619911598104646

Epoch: 45| Step: 0
Training loss: 2.7314711492119135
Validation loss: 2.553231192675636

Epoch: 5| Step: 1
Training loss: 1.8284907830923731
Validation loss: 2.557245768169477

Epoch: 5| Step: 2
Training loss: 2.488514073377122
Validation loss: 2.5560201965975806

Epoch: 5| Step: 3
Training loss: 2.5155734418241376
Validation loss: 2.5338204013395176

Epoch: 5| Step: 4
Training loss: 1.8444972706063878
Validation loss: 2.5678958914594827

Epoch: 5| Step: 5
Training loss: 2.394942430349828
Validation loss: 2.5215313722626935

Epoch: 5| Step: 6
Training loss: 2.4784248161063505
Validation loss: 2.5731579568336937

Epoch: 5| Step: 7
Training loss: 2.573014992342227
Validation loss: 2.5909007137019673

Epoch: 5| Step: 8
Training loss: 2.285807824775346
Validation loss: 2.583089895212163

Epoch: 5| Step: 9
Training loss: 2.5216611863719876
Validation loss: 2.6295415631162524

Epoch: 5| Step: 10
Training loss: 2.8877729212601158
Validation loss: 2.565183897118652

Epoch: 5| Step: 11
Training loss: 2.1598893564637813
Validation loss: 2.569549702444421

Epoch: 46| Step: 0
Training loss: 2.5959892258795234
Validation loss: 2.573659196394018

Epoch: 5| Step: 1
Training loss: 2.3057265186373597
Validation loss: 2.598909677013085

Epoch: 5| Step: 2
Training loss: 3.045099455112808
Validation loss: 2.6351183595561767

Epoch: 5| Step: 3
Training loss: 1.495466773227433
Validation loss: 2.57911889155752

Epoch: 5| Step: 4
Training loss: 3.009530347258817
Validation loss: 2.6915183447686806

Epoch: 5| Step: 5
Training loss: 2.583840433207388
Validation loss: 2.6333583828080736

Epoch: 5| Step: 6
Training loss: 1.9378685139319485
Validation loss: 2.6247671304074656

Epoch: 5| Step: 7
Training loss: 1.862995245714003
Validation loss: 2.622970784462001

Epoch: 5| Step: 8
Training loss: 2.423362521223608
Validation loss: 2.631282497667435

Epoch: 5| Step: 9
Training loss: 2.242351778505254
Validation loss: 2.6016179404399002

Epoch: 5| Step: 10
Training loss: 2.568088578137427
Validation loss: 2.6126261917921165

Epoch: 5| Step: 11
Training loss: 3.6272593067535404
Validation loss: 2.53452646263076

Epoch: 47| Step: 0
Training loss: 2.464728641391543
Validation loss: 2.5523811101733362

Epoch: 5| Step: 1
Training loss: 1.9501704337147763
Validation loss: 2.5400357459649308

Epoch: 5| Step: 2
Training loss: 2.446511069329856
Validation loss: 2.531759306999064

Epoch: 5| Step: 3
Training loss: 1.7749633274856884
Validation loss: 2.582199826030111

Epoch: 5| Step: 4
Training loss: 2.4485362682371195
Validation loss: 2.6321011798280387

Epoch: 5| Step: 5
Training loss: 2.4932355919037894
Validation loss: 2.564249592800653

Epoch: 5| Step: 6
Training loss: 2.6759933944472367
Validation loss: 2.62252472930391

Epoch: 5| Step: 7
Training loss: 2.5178942189680242
Validation loss: 2.609506664647206

Epoch: 5| Step: 8
Training loss: 2.456058958743801
Validation loss: 2.5914199083512854

Epoch: 5| Step: 9
Training loss: 2.410937017414789
Validation loss: 2.60945330291032

Epoch: 5| Step: 10
Training loss: 2.4392497311562926
Validation loss: 2.598440976273411

Epoch: 5| Step: 11
Training loss: 3.6320721271764027
Validation loss: 2.5428192204091284

Epoch: 48| Step: 0
Training loss: 2.7566153113376064
Validation loss: 2.5674812391859216

Epoch: 5| Step: 1
Training loss: 2.290741392667945
Validation loss: 2.620101009228428

Epoch: 5| Step: 2
Training loss: 1.8830839729081221
Validation loss: 2.6137238618531042

Epoch: 5| Step: 3
Training loss: 2.1866823030509757
Validation loss: 2.6275578593372377

Epoch: 5| Step: 4
Training loss: 3.44055234466813
Validation loss: 2.6942305489539677

Epoch: 5| Step: 5
Training loss: 2.9028911254103775
Validation loss: 2.7116259269686394

Epoch: 5| Step: 6
Training loss: 1.7964839343895551
Validation loss: 2.654088867136177

Epoch: 5| Step: 7
Training loss: 1.8580797957622928
Validation loss: 2.65191024361269

Epoch: 5| Step: 8
Training loss: 2.584198611973447
Validation loss: 2.6472697088675305

Epoch: 5| Step: 9
Training loss: 1.8225909859507952
Validation loss: 2.5678528415543607

Epoch: 5| Step: 10
Training loss: 2.7531182210018255
Validation loss: 2.6002020443302163

Epoch: 5| Step: 11
Training loss: 1.7211585075534965
Validation loss: 2.5659359249862317

Epoch: 49| Step: 0
Training loss: 2.052360696653661
Validation loss: 2.567419091286724

Epoch: 5| Step: 1
Training loss: 2.312260795799853
Validation loss: 2.5905092169791515

Epoch: 5| Step: 2
Training loss: 2.027046666952303
Validation loss: 2.620467083108766

Epoch: 5| Step: 3
Training loss: 2.1966229528883106
Validation loss: 2.5496361164311314

Epoch: 5| Step: 4
Training loss: 2.758024558756742
Validation loss: 2.5809643840640555

Epoch: 5| Step: 5
Training loss: 1.3400620263248595
Validation loss: 2.5602103409123056

Epoch: 5| Step: 6
Training loss: 2.92733140937234
Validation loss: 2.6170496017034592

Epoch: 5| Step: 7
Training loss: 2.700082555144555
Validation loss: 2.551863876301089

Epoch: 5| Step: 8
Training loss: 2.116139169980286
Validation loss: 2.5301772069501873

Epoch: 5| Step: 9
Training loss: 2.0595906863916413
Validation loss: 2.5403506175794126

Epoch: 5| Step: 10
Training loss: 2.6589818033985195
Validation loss: 2.6053470924414173

Epoch: 5| Step: 11
Training loss: 4.278057160825351
Validation loss: 2.5358089905693557

Epoch: 50| Step: 0
Training loss: 3.1266755761817384
Validation loss: 2.572181960985015

Epoch: 5| Step: 1
Training loss: 1.9795089291888848
Validation loss: 2.636245217835219

Epoch: 5| Step: 2
Training loss: 2.3048412207076954
Validation loss: 2.56854733164933

Epoch: 5| Step: 3
Training loss: 2.0123296013953826
Validation loss: 2.549525354348206

Epoch: 5| Step: 4
Training loss: 2.304622532850206
Validation loss: 2.6145027016495472

Epoch: 5| Step: 5
Training loss: 2.7767444076584806
Validation loss: 2.549139985436132

Epoch: 5| Step: 6
Training loss: 2.2475232161531093
Validation loss: 2.5482146088662363

Epoch: 5| Step: 7
Training loss: 1.7965342322935944
Validation loss: 2.5572918052181253

Epoch: 5| Step: 8
Training loss: 2.4160417757338273
Validation loss: 2.5347863031732265

Epoch: 5| Step: 9
Training loss: 2.562619648442868
Validation loss: 2.549040811563422

Epoch: 5| Step: 10
Training loss: 2.504297948898635
Validation loss: 2.56407739966986

Epoch: 5| Step: 11
Training loss: 2.035347664117992
Validation loss: 2.5441076342829807

Epoch: 51| Step: 0
Training loss: 2.3662564804222166
Validation loss: 2.5939628253318108

Epoch: 5| Step: 1
Training loss: 2.415002238744484
Validation loss: 2.563676713183978

Epoch: 5| Step: 2
Training loss: 2.6583817847289932
Validation loss: 2.59514479113461

Epoch: 5| Step: 3
Training loss: 1.7540767731214129
Validation loss: 2.58525409868761

Epoch: 5| Step: 4
Training loss: 1.9500679199910256
Validation loss: 2.6295468899296908

Epoch: 5| Step: 5
Training loss: 2.507742051890908
Validation loss: 2.607936493074533

Epoch: 5| Step: 6
Training loss: 2.178947623958713
Validation loss: 2.606500978757981

Epoch: 5| Step: 7
Training loss: 2.189715652992574
Validation loss: 2.690301026892808

Epoch: 5| Step: 8
Training loss: 2.8575336802075504
Validation loss: 2.554773786139477

Epoch: 5| Step: 9
Training loss: 2.473584330882229
Validation loss: 2.563709613197374

Epoch: 5| Step: 10
Training loss: 2.546063252840231
Validation loss: 2.550818255605401

Epoch: 5| Step: 11
Training loss: 2.083686442650184
Validation loss: 2.613383938796508

Epoch: 52| Step: 0
Training loss: 2.14443219065528
Validation loss: 2.5618280851813635

Epoch: 5| Step: 1
Training loss: 2.3174476276887206
Validation loss: 2.566199880322064

Epoch: 5| Step: 2
Training loss: 2.3392029459547286
Validation loss: 2.5832319406382496

Epoch: 5| Step: 3
Training loss: 2.590454673919823
Validation loss: 2.5980762151769556

Epoch: 5| Step: 4
Training loss: 2.7058940662193924
Validation loss: 2.5926829713219797

Epoch: 5| Step: 5
Training loss: 3.0098380266376856
Validation loss: 2.628089675938083

Epoch: 5| Step: 6
Training loss: 2.041661852876347
Validation loss: 2.596923828125

Epoch: 5| Step: 7
Training loss: 2.469557811059609
Validation loss: 2.6348481350349324

Epoch: 5| Step: 8
Training loss: 2.503303062401555
Validation loss: 2.5250081015762182

Epoch: 5| Step: 9
Training loss: 2.0803757718747278
Validation loss: 2.6035097527062137

Epoch: 5| Step: 10
Training loss: 2.1787182693665854
Validation loss: 2.6233998522954916

Epoch: 5| Step: 11
Training loss: 1.8952306341367624
Validation loss: 2.564314176771117

Epoch: 53| Step: 0
Training loss: 2.420694174079788
Validation loss: 2.55855204230329

Epoch: 5| Step: 1
Training loss: 2.4013109918063753
Validation loss: 2.6232283608261993

Epoch: 5| Step: 2
Training loss: 1.7819894293226466
Validation loss: 2.6777088693655684

Epoch: 5| Step: 3
Training loss: 3.4913074997572653
Validation loss: 2.7328715087382567

Epoch: 5| Step: 4
Training loss: 1.7188611081363498
Validation loss: 2.6867875847886893

Epoch: 5| Step: 5
Training loss: 2.8167039605404867
Validation loss: 2.73628823693496

Epoch: 5| Step: 6
Training loss: 2.008914748855751
Validation loss: 2.639877311295263

Epoch: 5| Step: 7
Training loss: 2.640824169344865
Validation loss: 2.643092509277711

Epoch: 5| Step: 8
Training loss: 1.9665860590606379
Validation loss: 2.6644095756887713

Epoch: 5| Step: 9
Training loss: 2.664985206090578
Validation loss: 2.6026052575105605

Epoch: 5| Step: 10
Training loss: 1.5361959804538445
Validation loss: 2.654089786028905

Epoch: 5| Step: 11
Training loss: 2.2579223183716444
Validation loss: 2.5687838630269604

Epoch: 54| Step: 0
Training loss: 2.143877774092498
Validation loss: 2.6163775542978804

Epoch: 5| Step: 1
Training loss: 2.354966041984242
Validation loss: 2.5938352777640916

Epoch: 5| Step: 2
Training loss: 2.1825762239234816
Validation loss: 2.6293916863414566

Epoch: 5| Step: 3
Training loss: 2.681899334013259
Validation loss: 2.6046017868197064

Epoch: 5| Step: 4
Training loss: 2.7991651823224055
Validation loss: 2.64899489352165

Epoch: 5| Step: 5
Training loss: 3.148261962237821
Validation loss: 2.6549898374701844

Epoch: 5| Step: 6
Training loss: 2.2187937342672006
Validation loss: 2.650378098595295

Epoch: 5| Step: 7
Training loss: 2.2402681117024343
Validation loss: 2.608473665882379

Epoch: 5| Step: 8
Training loss: 2.3524017357243667
Validation loss: 2.6470718688892716

Epoch: 5| Step: 9
Training loss: 2.20412254746047
Validation loss: 2.6549160169500086

Epoch: 5| Step: 10
Training loss: 2.121981552662244
Validation loss: 2.579012500323417

Epoch: 5| Step: 11
Training loss: 2.351171720865691
Validation loss: 2.5632814867181737

Epoch: 55| Step: 0
Training loss: 2.543527661853468
Validation loss: 2.581829388259518

Epoch: 5| Step: 1
Training loss: 2.124202578652471
Validation loss: 2.6440755544470282

Epoch: 5| Step: 2
Training loss: 1.6265587300047117
Validation loss: 2.6614609001032825

Epoch: 5| Step: 3
Training loss: 2.1938206500987736
Validation loss: 2.6662880670983866

Epoch: 5| Step: 4
Training loss: 2.1196429101234875
Validation loss: 2.680689145348958

Epoch: 5| Step: 5
Training loss: 2.4329818519639814
Validation loss: 2.7513311769409854

Epoch: 5| Step: 6
Training loss: 2.432565732187386
Validation loss: 2.6693133963316087

Epoch: 5| Step: 7
Training loss: 3.0486898641375957
Validation loss: 2.6118300418494256

Epoch: 5| Step: 8
Training loss: 2.22424002537737
Validation loss: 2.718001216874705

Epoch: 5| Step: 9
Training loss: 2.4420930674546093
Validation loss: 2.662661168021696

Epoch: 5| Step: 10
Training loss: 2.6818075885181427
Validation loss: 2.6279807991265556

Epoch: 5| Step: 11
Training loss: 3.3384462879539805
Validation loss: 2.5762845010651367

Epoch: 56| Step: 0
Training loss: 1.7953334000369425
Validation loss: 2.581371282663905

Epoch: 5| Step: 1
Training loss: 2.2989743558126268
Validation loss: 2.621862959047903

Epoch: 5| Step: 2
Training loss: 2.687077954886763
Validation loss: 2.6254681101714628

Epoch: 5| Step: 3
Training loss: 2.3291408703444048
Validation loss: 2.5570563553167136

Epoch: 5| Step: 4
Training loss: 2.310016638955966
Validation loss: 2.5939917202807337

Epoch: 5| Step: 5
Training loss: 2.206487916216166
Validation loss: 2.60028717353259

Epoch: 5| Step: 6
Training loss: 1.8727248693696548
Validation loss: 2.6081381929443124

Epoch: 5| Step: 7
Training loss: 1.9219202796130084
Validation loss: 2.5974586622004123

Epoch: 5| Step: 8
Training loss: 2.817498829798214
Validation loss: 2.5336316446502662

Epoch: 5| Step: 9
Training loss: 2.2444062104866176
Validation loss: 2.5930846406485664

Epoch: 5| Step: 10
Training loss: 2.798679047026322
Validation loss: 2.5933966453414934

Epoch: 5| Step: 11
Training loss: 2.38853323183984
Validation loss: 2.61726561662234

Epoch: 57| Step: 0
Training loss: 1.9714447229130492
Validation loss: 2.579643788574853

Epoch: 5| Step: 1
Training loss: 2.3623830049801913
Validation loss: 2.5901475002321064

Epoch: 5| Step: 2
Training loss: 2.8967737733670855
Validation loss: 2.6007756178246693

Epoch: 5| Step: 3
Training loss: 2.4763889191744517
Validation loss: 2.6231216037508

Epoch: 5| Step: 4
Training loss: 2.5270839363049205
Validation loss: 2.596268212755482

Epoch: 5| Step: 5
Training loss: 2.188009802132082
Validation loss: 2.6014333316785563

Epoch: 5| Step: 6
Training loss: 2.6782877744618916
Validation loss: 2.5840985346705225

Epoch: 5| Step: 7
Training loss: 2.3369611965707398
Validation loss: 2.615818158897953

Epoch: 5| Step: 8
Training loss: 1.8657360101385159
Validation loss: 2.6110559329725174

Epoch: 5| Step: 9
Training loss: 2.015866050796386
Validation loss: 2.576757010294456

Epoch: 5| Step: 10
Training loss: 2.1393159079519117
Validation loss: 2.564117924945315

Epoch: 5| Step: 11
Training loss: 2.8453024514705354
Validation loss: 2.6269827159174564

Epoch: 58| Step: 0
Training loss: 2.514530773187686
Validation loss: 2.5582114480046756

Epoch: 5| Step: 1
Training loss: 1.8173202348089197
Validation loss: 2.547358437742484

Epoch: 5| Step: 2
Training loss: 2.3387261015640988
Validation loss: 2.580408248938968

Epoch: 5| Step: 3
Training loss: 2.6706704441652644
Validation loss: 2.5543739834192225

Epoch: 5| Step: 4
Training loss: 2.0827128312802383
Validation loss: 2.6090326979349916

Epoch: 5| Step: 5
Training loss: 2.0041263452017537
Validation loss: 2.5786305018671456

Epoch: 5| Step: 6
Training loss: 2.0616228955165083
Validation loss: 2.609503128043061

Epoch: 5| Step: 7
Training loss: 2.2371563439744784
Validation loss: 2.5944709771596894

Epoch: 5| Step: 8
Training loss: 2.6776054457017304
Validation loss: 2.5898223845385475

Epoch: 5| Step: 9
Training loss: 1.943716719854577
Validation loss: 2.573828718307225

Epoch: 5| Step: 10
Training loss: 2.8312133449851102
Validation loss: 2.600973664050325

Epoch: 5| Step: 11
Training loss: 2.520034526860901
Validation loss: 2.616441550158597

Epoch: 59| Step: 0
Training loss: 1.6960009042989372
Validation loss: 2.59279297404044

Epoch: 5| Step: 1
Training loss: 2.30139897964016
Validation loss: 2.6010222633003717

Epoch: 5| Step: 2
Training loss: 1.9516431756673105
Validation loss: 2.5729090977504665

Epoch: 5| Step: 3
Training loss: 2.211735988968824
Validation loss: 2.653500427864471

Epoch: 5| Step: 4
Training loss: 2.9310431433853426
Validation loss: 2.6156162992550707

Epoch: 5| Step: 5
Training loss: 2.3831337634029777
Validation loss: 2.5761669815398758

Epoch: 5| Step: 6
Training loss: 2.1553951172040566
Validation loss: 2.6172440593927897

Epoch: 5| Step: 7
Training loss: 2.7211471162481056
Validation loss: 2.5416604508391702

Epoch: 5| Step: 8
Training loss: 2.4070681877731674
Validation loss: 2.5679957317330935

Epoch: 5| Step: 9
Training loss: 2.36267505784335
Validation loss: 2.5744695816206318

Epoch: 5| Step: 10
Training loss: 2.0496134602916927
Validation loss: 2.574245597456233

Epoch: 5| Step: 11
Training loss: 3.680902559888744
Validation loss: 2.5376215009931253

Epoch: 60| Step: 0
Training loss: 2.8183030342926267
Validation loss: 2.5795088204160765

Epoch: 5| Step: 1
Training loss: 2.303880970668419
Validation loss: 2.5888305761242005

Epoch: 5| Step: 2
Training loss: 1.7625006655428015
Validation loss: 2.538500883150226

Epoch: 5| Step: 3
Training loss: 1.9706634426753025
Validation loss: 2.60270512893782

Epoch: 5| Step: 4
Training loss: 2.274834482229269
Validation loss: 2.573027354856932

Epoch: 5| Step: 5
Training loss: 2.5580493143918943
Validation loss: 2.5643778933016703

Epoch: 5| Step: 6
Training loss: 2.45434481670956
Validation loss: 2.5750639072685124

Epoch: 5| Step: 7
Training loss: 2.6923812185455023
Validation loss: 2.561824597150376

Epoch: 5| Step: 8
Training loss: 2.5636470367423443
Validation loss: 2.553458078385746

Epoch: 5| Step: 9
Training loss: 2.085904696203028
Validation loss: 2.5573074699011973

Epoch: 5| Step: 10
Training loss: 2.1251456266880506
Validation loss: 2.6135980654475026

Epoch: 5| Step: 11
Training loss: 1.7547351942773366
Validation loss: 2.5876593912331036

Epoch: 61| Step: 0
Training loss: 2.759712666882852
Validation loss: 2.6137514247370466

Epoch: 5| Step: 1
Training loss: 3.1094297471330585
Validation loss: 2.6434331066712753

Epoch: 5| Step: 2
Training loss: 2.007939434863106
Validation loss: 2.648981944249081

Epoch: 5| Step: 3
Training loss: 2.9463164138915223
Validation loss: 2.64820880521397

Epoch: 5| Step: 4
Training loss: 2.3061191056485475
Validation loss: 2.5858510167161324

Epoch: 5| Step: 5
Training loss: 1.9174273128733166
Validation loss: 2.5757957957146984

Epoch: 5| Step: 6
Training loss: 1.8350563044835981
Validation loss: 2.602846907300725

Epoch: 5| Step: 7
Training loss: 2.3151284821945852
Validation loss: 2.5992221596438156

Epoch: 5| Step: 8
Training loss: 1.7444220611664285
Validation loss: 2.6122520256082087

Epoch: 5| Step: 9
Training loss: 2.3033129715007985
Validation loss: 2.602832862058958

Epoch: 5| Step: 10
Training loss: 2.295142733720902
Validation loss: 2.638566736723939

Epoch: 5| Step: 11
Training loss: 2.545488413052852
Validation loss: 2.5608482425970296

Epoch: 62| Step: 0
Training loss: 2.1257668401810856
Validation loss: 2.6253627874571683

Epoch: 5| Step: 1
Training loss: 2.0022285681320677
Validation loss: 2.5677741250565096

Epoch: 5| Step: 2
Training loss: 2.361747004080962
Validation loss: 2.572446993895576

Epoch: 5| Step: 3
Training loss: 2.8323768983573046
Validation loss: 2.556560533559562

Epoch: 5| Step: 4
Training loss: 2.6195565959410723
Validation loss: 2.6075585375914563

Epoch: 5| Step: 5
Training loss: 2.152995210010606
Validation loss: 2.5729693447285396

Epoch: 5| Step: 6
Training loss: 1.8811450079835423
Validation loss: 2.6376466338208697

Epoch: 5| Step: 7
Training loss: 2.651880867165129
Validation loss: 2.596087076930668

Epoch: 5| Step: 8
Training loss: 2.015534154929531
Validation loss: 2.579445856993034

Epoch: 5| Step: 9
Training loss: 2.183866589583121
Validation loss: 2.611712187601788

Epoch: 5| Step: 10
Training loss: 2.4560434269125557
Validation loss: 2.5549406651414817

Epoch: 5| Step: 11
Training loss: 2.4405576650242446
Validation loss: 2.5800340500945462

Epoch: 63| Step: 0
Training loss: 2.051646952695775
Validation loss: 2.579185837862891

Epoch: 5| Step: 1
Training loss: 2.508303490225688
Validation loss: 2.5915702830011127

Epoch: 5| Step: 2
Training loss: 2.1067531539370092
Validation loss: 2.625619118960934

Epoch: 5| Step: 3
Training loss: 2.9985925233810704
Validation loss: 2.5901515580232015

Epoch: 5| Step: 4
Training loss: 1.9393739559307233
Validation loss: 2.592994005264726

Epoch: 5| Step: 5
Training loss: 2.430906229304744
Validation loss: 2.546834847849495

Epoch: 5| Step: 6
Training loss: 2.433916440972899
Validation loss: 2.600869377601086

Epoch: 5| Step: 7
Training loss: 2.4321588538515844
Validation loss: 2.5756776734294617

Epoch: 5| Step: 8
Training loss: 2.0531029919238777
Validation loss: 2.584808214434481

Epoch: 5| Step: 9
Training loss: 1.946466678031382
Validation loss: 2.5282311392478283

Epoch: 5| Step: 10
Training loss: 2.3057153511078665
Validation loss: 2.598300064345768

Epoch: 5| Step: 11
Training loss: 2.490816893418564
Validation loss: 2.587897390680646

Epoch: 64| Step: 0
Training loss: 1.6869260730340137
Validation loss: 2.59476352330804

Epoch: 5| Step: 1
Training loss: 2.3965979862408733
Validation loss: 2.6220718071221154

Epoch: 5| Step: 2
Training loss: 2.322912127799716
Validation loss: 2.6162455633496124

Epoch: 5| Step: 3
Training loss: 1.7755156453076322
Validation loss: 2.5957036837617165

Epoch: 5| Step: 4
Training loss: 2.4765027156316637
Validation loss: 2.623039754979555

Epoch: 5| Step: 5
Training loss: 2.5367527241923895
Validation loss: 2.6433100357588364

Epoch: 5| Step: 6
Training loss: 1.8112862567945285
Validation loss: 2.600996244128394

Epoch: 5| Step: 7
Training loss: 2.2404242304576774
Validation loss: 2.568726979142466

Epoch: 5| Step: 8
Training loss: 2.8381056891151695
Validation loss: 2.598024469345051

Epoch: 5| Step: 9
Training loss: 2.3632071995759154
Validation loss: 2.6061630544026544

Epoch: 5| Step: 10
Training loss: 2.3073549513106757
Validation loss: 2.6236131539232215

Epoch: 5| Step: 11
Training loss: 2.33872334908042
Validation loss: 2.587691051537135

Epoch: 65| Step: 0
Training loss: 2.211591105009983
Validation loss: 2.5697594639977175

Epoch: 5| Step: 1
Training loss: 2.566001639558145
Validation loss: 2.5554812614611233

Epoch: 5| Step: 2
Training loss: 1.9973653486794414
Validation loss: 2.613326341727532

Epoch: 5| Step: 3
Training loss: 1.9971963185148653
Validation loss: 2.602052014398858

Epoch: 5| Step: 4
Training loss: 1.8380676897720165
Validation loss: 2.5886511610016036

Epoch: 5| Step: 5
Training loss: 1.6748063957717236
Validation loss: 2.646845351184107

Epoch: 5| Step: 6
Training loss: 2.5229840417418483
Validation loss: 2.625260639118137

Epoch: 5| Step: 7
Training loss: 2.297430684867341
Validation loss: 2.589175994079883

Epoch: 5| Step: 8
Training loss: 3.161937913964336
Validation loss: 2.605137443162673

Epoch: 5| Step: 9
Training loss: 2.372969512306353
Validation loss: 2.5772656501653537

Epoch: 5| Step: 10
Training loss: 2.3835113001004
Validation loss: 2.6418408147427472

Epoch: 5| Step: 11
Training loss: 2.1103618432694398
Validation loss: 2.5938195962262895

Epoch: 66| Step: 0
Training loss: 2.215236729873054
Validation loss: 2.6158658386581415

Epoch: 5| Step: 1
Training loss: 1.8340257796386146
Validation loss: 2.6082187611174668

Epoch: 5| Step: 2
Training loss: 2.925977631562284
Validation loss: 2.564525296236037

Epoch: 5| Step: 3
Training loss: 1.6477015149485938
Validation loss: 2.5681345175205217

Epoch: 5| Step: 4
Training loss: 2.358308664828664
Validation loss: 2.6044717584549457

Epoch: 5| Step: 5
Training loss: 2.2563745480131687
Validation loss: 2.5773606737561567

Epoch: 5| Step: 6
Training loss: 2.271653356851315
Validation loss: 2.5915681478862855

Epoch: 5| Step: 7
Training loss: 2.5404921981430455
Validation loss: 2.5977314720639697

Epoch: 5| Step: 8
Training loss: 2.878932419635976
Validation loss: 2.5859551443552538

Epoch: 5| Step: 9
Training loss: 2.086148483521797
Validation loss: 2.551564204037703

Epoch: 5| Step: 10
Training loss: 2.536831670984577
Validation loss: 2.667195961746413

Epoch: 5| Step: 11
Training loss: 0.6498396088710586
Validation loss: 2.634397793509454

Epoch: 67| Step: 0
Training loss: 2.0891099443661787
Validation loss: 2.6322693495615153

Epoch: 5| Step: 1
Training loss: 1.721348341692958
Validation loss: 2.6391386178849574

Epoch: 5| Step: 2
Training loss: 2.256440692990327
Validation loss: 2.7531994717557136

Epoch: 5| Step: 3
Training loss: 2.3698899357021896
Validation loss: 2.7148881794246487

Epoch: 5| Step: 4
Training loss: 1.927536974600526
Validation loss: 2.707817444207076

Epoch: 5| Step: 5
Training loss: 2.669472221903042
Validation loss: 2.729782949757501

Epoch: 5| Step: 6
Training loss: 2.1703975784400735
Validation loss: 2.5886700647594454

Epoch: 5| Step: 7
Training loss: 3.1497928551275245
Validation loss: 2.655419432992141

Epoch: 5| Step: 8
Training loss: 2.1169155269918516
Validation loss: 2.5737314915991236

Epoch: 5| Step: 9
Training loss: 2.200865648931069
Validation loss: 2.6151077661500275

Epoch: 5| Step: 10
Training loss: 2.2541832712329306
Validation loss: 2.5730046412965635

Epoch: 5| Step: 11
Training loss: 2.1576237379817056
Validation loss: 2.569705601614178

Epoch: 68| Step: 0
Training loss: 1.6508840331229546
Validation loss: 2.562027255699973

Epoch: 5| Step: 1
Training loss: 2.3099369588729655
Validation loss: 2.5656883710499314

Epoch: 5| Step: 2
Training loss: 2.168918600866865
Validation loss: 2.607248604835827

Epoch: 5| Step: 3
Training loss: 2.419241771927229
Validation loss: 2.6516443977603728

Epoch: 5| Step: 4
Training loss: 2.7071917157413896
Validation loss: 2.6215615497010947

Epoch: 5| Step: 5
Training loss: 2.055349961157367
Validation loss: 2.5696040996718383

Epoch: 5| Step: 6
Training loss: 1.5123443491899369
Validation loss: 2.5840210319719636

Epoch: 5| Step: 7
Training loss: 2.381094291181795
Validation loss: 2.607000477393638

Epoch: 5| Step: 8
Training loss: 2.5571147808320718
Validation loss: 2.5343273827861204

Epoch: 5| Step: 9
Training loss: 2.5469579390612576
Validation loss: 2.5641915468065353

Epoch: 5| Step: 10
Training loss: 2.2497768291421316
Validation loss: 2.675705107187947

Epoch: 5| Step: 11
Training loss: 3.527501099584288
Validation loss: 2.569990132067991

Epoch: 69| Step: 0
Training loss: 2.2427384500449574
Validation loss: 2.572259372403311

Epoch: 5| Step: 1
Training loss: 1.9461868956030886
Validation loss: 2.590483243689148

Epoch: 5| Step: 2
Training loss: 2.1454826982058797
Validation loss: 2.59720919784866

Epoch: 5| Step: 3
Training loss: 2.4057079546870663
Validation loss: 2.5208466203722972

Epoch: 5| Step: 4
Training loss: 2.5841572790909253
Validation loss: 2.561685556761123

Epoch: 5| Step: 5
Training loss: 2.377800745669914
Validation loss: 2.5618268733868117

Epoch: 5| Step: 6
Training loss: 1.65026985042557
Validation loss: 2.6122910695894563

Epoch: 5| Step: 7
Training loss: 2.289385359457136
Validation loss: 2.572509742455158

Epoch: 5| Step: 8
Training loss: 2.3090644266252407
Validation loss: 2.5876761178418954

Epoch: 5| Step: 9
Training loss: 2.2068241528595536
Validation loss: 2.6204803893734736

Epoch: 5| Step: 10
Training loss: 2.256300159013037
Validation loss: 2.632708987984849

Epoch: 5| Step: 11
Training loss: 2.7293726913690466
Validation loss: 2.59159595790664

Epoch: 70| Step: 0
Training loss: 2.162534318772908
Validation loss: 2.5939916934731104

Epoch: 5| Step: 1
Training loss: 2.6017504558311746
Validation loss: 2.635616714564625

Epoch: 5| Step: 2
Training loss: 2.094756155094
Validation loss: 2.592315244449172

Epoch: 5| Step: 3
Training loss: 2.3354207873981565
Validation loss: 2.616353348988552

Epoch: 5| Step: 4
Training loss: 2.346333211846865
Validation loss: 2.6075613186966455

Epoch: 5| Step: 5
Training loss: 1.600418501004326
Validation loss: 2.560612436905727

Epoch: 5| Step: 6
Training loss: 1.8473816359083486
Validation loss: 2.5981505724349128

Epoch: 5| Step: 7
Training loss: 2.519735165409748
Validation loss: 2.6840388314393886

Epoch: 5| Step: 8
Training loss: 2.5984261884689714
Validation loss: 2.582276290831364

Epoch: 5| Step: 9
Training loss: 1.8129706593794148
Validation loss: 2.5808772145035763

Epoch: 5| Step: 10
Training loss: 2.356442074826827
Validation loss: 2.634203101176393

Epoch: 5| Step: 11
Training loss: 2.3379591546973617
Validation loss: 2.6760935060541784

Epoch: 71| Step: 0
Training loss: 2.0292781942790916
Validation loss: 2.6079399822838645

Epoch: 5| Step: 1
Training loss: 1.952169993569237
Validation loss: 2.6398685395077

Epoch: 5| Step: 2
Training loss: 1.4622543846008544
Validation loss: 2.564638764944166

Epoch: 5| Step: 3
Training loss: 1.793284668858922
Validation loss: 2.6500734398520245

Epoch: 5| Step: 4
Training loss: 2.0423969467854493
Validation loss: 2.6736914128606224

Epoch: 5| Step: 5
Training loss: 2.4171310723985955
Validation loss: 2.6702946233178904

Epoch: 5| Step: 6
Training loss: 2.963356338543269
Validation loss: 2.666576795007322

Epoch: 5| Step: 7
Training loss: 2.5955122510826296
Validation loss: 2.6182130161381956

Epoch: 5| Step: 8
Training loss: 2.41378506050743
Validation loss: 2.6831468620034613

Epoch: 5| Step: 9
Training loss: 2.0404882598442002
Validation loss: 2.5999714068833475

Epoch: 5| Step: 10
Training loss: 2.296582365532755
Validation loss: 2.635217652829259

Epoch: 5| Step: 11
Training loss: 2.5719687276751473
Validation loss: 2.6557842108037124

Epoch: 72| Step: 0
Training loss: 2.560738493080433
Validation loss: 2.5960193649014482

Epoch: 5| Step: 1
Training loss: 2.009015505892745
Validation loss: 2.5471508075709464

Epoch: 5| Step: 2
Training loss: 2.469437515521785
Validation loss: 2.622429686816803

Epoch: 5| Step: 3
Training loss: 2.471915810654436
Validation loss: 2.6070937313327494

Epoch: 5| Step: 4
Training loss: 2.1190424039377502
Validation loss: 2.548480146290208

Epoch: 5| Step: 5
Training loss: 1.947411442752163
Validation loss: 2.6514306273343777

Epoch: 5| Step: 6
Training loss: 1.878816281264322
Validation loss: 2.578020467469277

Epoch: 5| Step: 7
Training loss: 1.6873552472231272
Validation loss: 2.5895118711702403

Epoch: 5| Step: 8
Training loss: 2.507108785702844
Validation loss: 2.627452397319077

Epoch: 5| Step: 9
Training loss: 2.35223865610007
Validation loss: 2.582808419447651

Epoch: 5| Step: 10
Training loss: 1.9673358743113223
Validation loss: 2.6098646591558765

Epoch: 5| Step: 11
Training loss: 3.598522699087047
Validation loss: 2.595121733322061

Epoch: 73| Step: 0
Training loss: 2.450776743861912
Validation loss: 2.68345168254524

Epoch: 5| Step: 1
Training loss: 2.6059701600082676
Validation loss: 2.7770396127333243

Epoch: 5| Step: 2
Training loss: 2.7855776431907073
Validation loss: 2.8041521268035923

Epoch: 5| Step: 3
Training loss: 3.0410806971100666
Validation loss: 2.808938717514143

Epoch: 5| Step: 4
Training loss: 2.0224008150618156
Validation loss: 2.813575030546484

Epoch: 5| Step: 5
Training loss: 2.5479908938342493
Validation loss: 2.821668673942905

Epoch: 5| Step: 6
Training loss: 1.5393326420595894
Validation loss: 2.8002438209165135

Epoch: 5| Step: 7
Training loss: 1.9637706700626703
Validation loss: 2.636657303459126

Epoch: 5| Step: 8
Training loss: 1.741786414536563
Validation loss: 2.586611196113246

Epoch: 5| Step: 9
Training loss: 2.263424245144308
Validation loss: 2.6383844873714986

Epoch: 5| Step: 10
Training loss: 2.1821260108681004
Validation loss: 2.641495766110589

Epoch: 5| Step: 11
Training loss: 1.364711153678405
Validation loss: 2.63289069447297

Epoch: 74| Step: 0
Training loss: 1.7485084307944312
Validation loss: 2.616537432810018

Epoch: 5| Step: 1
Training loss: 2.4757296247748446
Validation loss: 2.715136234619235

Epoch: 5| Step: 2
Training loss: 1.9225677854297214
Validation loss: 2.5970158602646785

Epoch: 5| Step: 3
Training loss: 2.2787719226646845
Validation loss: 2.66382290535563

Epoch: 5| Step: 4
Training loss: 2.4200035493998073
Validation loss: 2.6111175558729878

Epoch: 5| Step: 5
Training loss: 2.0029159984371923
Validation loss: 2.650928188860588

Epoch: 5| Step: 6
Training loss: 1.9139804121826833
Validation loss: 2.555005080055666

Epoch: 5| Step: 7
Training loss: 2.276612571736423
Validation loss: 2.5910959529708237

Epoch: 5| Step: 8
Training loss: 1.9628159238350895
Validation loss: 2.629617191522456

Epoch: 5| Step: 9
Training loss: 1.9161042203650565
Validation loss: 2.6017764655515268

Epoch: 5| Step: 10
Training loss: 3.304234106105998
Validation loss: 2.632066796533512

Epoch: 5| Step: 11
Training loss: 2.440886272751926
Validation loss: 2.6459470609317446

Epoch: 75| Step: 0
Training loss: 2.3140370184031807
Validation loss: 2.6574291865584536

Epoch: 5| Step: 1
Training loss: 2.0585657222801457
Validation loss: 2.650567899888139

Epoch: 5| Step: 2
Training loss: 1.7734527587234192
Validation loss: 2.694031701327292

Epoch: 5| Step: 3
Training loss: 1.9972201936994758
Validation loss: 2.7978436268532474

Epoch: 5| Step: 4
Training loss: 2.5672083142784006
Validation loss: 2.7307634317412957

Epoch: 5| Step: 5
Training loss: 2.1219048117339794
Validation loss: 2.7671922456430313

Epoch: 5| Step: 6
Training loss: 2.3798692880527184
Validation loss: 2.7258426769037754

Epoch: 5| Step: 7
Training loss: 2.7126049882813255
Validation loss: 2.697153677011006

Epoch: 5| Step: 8
Training loss: 1.881200076229703
Validation loss: 2.639637504740345

Epoch: 5| Step: 9
Training loss: 2.152001106141384
Validation loss: 2.62032900103486

Epoch: 5| Step: 10
Training loss: 2.207212403551337
Validation loss: 2.6004843859745024

Epoch: 5| Step: 11
Training loss: 0.8773586635392077
Validation loss: 2.5403503321109895

Epoch: 76| Step: 0
Training loss: 2.4641247651355433
Validation loss: 2.6400825650617095

Epoch: 5| Step: 1
Training loss: 2.121781211431987
Validation loss: 2.6310311355539144

Epoch: 5| Step: 2
Training loss: 2.313096871543861
Validation loss: 2.6028890845535635

Epoch: 5| Step: 3
Training loss: 2.11282518581356
Validation loss: 2.6444500939347146

Epoch: 5| Step: 4
Training loss: 2.387597853967051
Validation loss: 2.626843906103294

Epoch: 5| Step: 5
Training loss: 2.024682681806118
Validation loss: 2.6166263643024097

Epoch: 5| Step: 6
Training loss: 2.2276780930897275
Validation loss: 2.625441881105246

Epoch: 5| Step: 7
Training loss: 2.2668165559389246
Validation loss: 2.653901161186723

Epoch: 5| Step: 8
Training loss: 2.3430433098001244
Validation loss: 2.645102630299513

Epoch: 5| Step: 9
Training loss: 2.2249038675521766
Validation loss: 2.605628318037246

Epoch: 5| Step: 10
Training loss: 2.4326698178080735
Validation loss: 2.662856711936966

Epoch: 5| Step: 11
Training loss: 1.914399160244507
Validation loss: 2.6666921053110153

Epoch: 77| Step: 0
Training loss: 2.1725190669058203
Validation loss: 2.6654597111535345

Epoch: 5| Step: 1
Training loss: 1.94613924038406
Validation loss: 2.6709479792880177

Epoch: 5| Step: 2
Training loss: 2.4455173394448946
Validation loss: 2.664526797319436

Epoch: 5| Step: 3
Training loss: 2.1959813955384004
Validation loss: 2.6922561123119975

Epoch: 5| Step: 4
Training loss: 2.1951172222562056
Validation loss: 2.6833389694340277

Epoch: 5| Step: 5
Training loss: 1.966664375152977
Validation loss: 2.6660356420713356

Epoch: 5| Step: 6
Training loss: 2.1126403400822795
Validation loss: 2.539120553159954

Epoch: 5| Step: 7
Training loss: 2.975469914356836
Validation loss: 2.6034157865726373

Epoch: 5| Step: 8
Training loss: 1.8265074396115053
Validation loss: 2.59789489950092

Epoch: 5| Step: 9
Training loss: 1.752188880393279
Validation loss: 2.6237520059290453

Epoch: 5| Step: 10
Training loss: 2.432714410567206
Validation loss: 2.611232709223266

Epoch: 5| Step: 11
Training loss: 0.7910360074655035
Validation loss: 2.5647335746527475

Epoch: 78| Step: 0
Training loss: 1.5141344901686367
Validation loss: 2.5992762817705657

Epoch: 5| Step: 1
Training loss: 1.7184045617886594
Validation loss: 2.6637584068980766

Epoch: 5| Step: 2
Training loss: 2.014717548348051
Validation loss: 2.6275739727925638

Epoch: 5| Step: 3
Training loss: 1.9084896626081327
Validation loss: 2.6497203941806355

Epoch: 5| Step: 4
Training loss: 2.5097091965324725
Validation loss: 2.590622145801133

Epoch: 5| Step: 5
Training loss: 1.8308615132476647
Validation loss: 2.628687924619425

Epoch: 5| Step: 6
Training loss: 1.8794406440213571
Validation loss: 2.625194044737

Epoch: 5| Step: 7
Training loss: 2.418059955904299
Validation loss: 2.5909064190289026

Epoch: 5| Step: 8
Training loss: 2.773420135013859
Validation loss: 2.6526510091575815

Epoch: 5| Step: 9
Training loss: 2.8016887136390305
Validation loss: 2.6717453491997625

Epoch: 5| Step: 10
Training loss: 2.397377600066332
Validation loss: 2.6561243289315515

Epoch: 5| Step: 11
Training loss: 1.4020046578600642
Validation loss: 2.654859403238876

Epoch: 79| Step: 0
Training loss: 2.391196986566446
Validation loss: 2.6438048852284055

Epoch: 5| Step: 1
Training loss: 1.6761925110427882
Validation loss: 2.6274318556655425

Epoch: 5| Step: 2
Training loss: 2.5875306537673697
Validation loss: 2.687228843405525

Epoch: 5| Step: 3
Training loss: 2.55006358871461
Validation loss: 2.623988145752527

Epoch: 5| Step: 4
Training loss: 1.9942150494383428
Validation loss: 2.6230293665320765

Epoch: 5| Step: 5
Training loss: 2.156828650631764
Validation loss: 2.6000624638475647

Epoch: 5| Step: 6
Training loss: 1.7110966995934207
Validation loss: 2.6236030327967796

Epoch: 5| Step: 7
Training loss: 1.9558525876155446
Validation loss: 2.6022987087737675

Epoch: 5| Step: 8
Training loss: 1.8274742337561765
Validation loss: 2.6434161278260215

Epoch: 5| Step: 9
Training loss: 2.3025689166728176
Validation loss: 2.666593346978581

Epoch: 5| Step: 10
Training loss: 2.766560886459716
Validation loss: 2.64457939250631

Epoch: 5| Step: 11
Training loss: 1.115313578931394
Validation loss: 2.6477857254711394

Epoch: 80| Step: 0
Training loss: 1.7521670411835628
Validation loss: 2.5924470072191763

Epoch: 5| Step: 1
Training loss: 2.0667809649619153
Validation loss: 2.7084039874519843

Epoch: 5| Step: 2
Training loss: 1.8157984875572402
Validation loss: 2.610074240827115

Epoch: 5| Step: 3
Training loss: 2.5653593346308403
Validation loss: 2.6225971055030777

Epoch: 5| Step: 4
Training loss: 2.245040513928354
Validation loss: 2.608738393277942

Epoch: 5| Step: 5
Training loss: 2.5551246945584536
Validation loss: 2.58603312112936

Epoch: 5| Step: 6
Training loss: 2.114731155515382
Validation loss: 2.615039387984344

Epoch: 5| Step: 7
Training loss: 1.9802369352626574
Validation loss: 2.6446342128917677

Epoch: 5| Step: 8
Training loss: 2.1685022745821976
Validation loss: 2.602418947579219

Epoch: 5| Step: 9
Training loss: 2.1975775603232925
Validation loss: 2.6346390686482426

Epoch: 5| Step: 10
Training loss: 1.946103406320916
Validation loss: 2.6805012971419155

Epoch: 5| Step: 11
Training loss: 2.757171988739237
Validation loss: 2.66577481217428

Epoch: 81| Step: 0
Training loss: 2.285186297879371
Validation loss: 2.6873058537285845

Epoch: 5| Step: 1
Training loss: 1.8558326123491293
Validation loss: 2.670704657797034

Epoch: 5| Step: 2
Training loss: 1.8188920270384854
Validation loss: 2.63359034185454

Epoch: 5| Step: 3
Training loss: 2.747993691044302
Validation loss: 2.6588879071572284

Epoch: 5| Step: 4
Training loss: 2.1844869298458804
Validation loss: 2.63479699073033

Epoch: 5| Step: 5
Training loss: 2.0261110295547113
Validation loss: 2.6852898122115456

Epoch: 5| Step: 6
Training loss: 2.5766104208501797
Validation loss: 2.737796267063038

Epoch: 5| Step: 7
Training loss: 1.7175049173431856
Validation loss: 2.6476171155018258

Epoch: 5| Step: 8
Training loss: 1.9745554628945607
Validation loss: 2.7021303680628246

Epoch: 5| Step: 9
Training loss: 1.9685339430677251
Validation loss: 2.5669528412020806

Epoch: 5| Step: 10
Training loss: 2.1438836681632676
Validation loss: 2.6056282532237702

Epoch: 5| Step: 11
Training loss: 1.2421742564521026
Validation loss: 2.591709188181985

Epoch: 82| Step: 0
Training loss: 2.460192370762837
Validation loss: 2.6525261263350153

Epoch: 5| Step: 1
Training loss: 2.013037151420223
Validation loss: 2.6692794067741348

Epoch: 5| Step: 2
Training loss: 2.259549327577808
Validation loss: 2.6742228589781845

Epoch: 5| Step: 3
Training loss: 2.7701707109806164
Validation loss: 2.725246169989696

Epoch: 5| Step: 4
Training loss: 2.8339981720244785
Validation loss: 2.681483024009484

Epoch: 5| Step: 5
Training loss: 2.132071677300272
Validation loss: 2.683455839875186

Epoch: 5| Step: 6
Training loss: 1.8844885113437537
Validation loss: 2.7155582869002295

Epoch: 5| Step: 7
Training loss: 2.628445317074539
Validation loss: 2.6327206966344003

Epoch: 5| Step: 8
Training loss: 1.8308519419003821
Validation loss: 2.65169679432395

Epoch: 5| Step: 9
Training loss: 1.6545021623336205
Validation loss: 2.689811954094314

Epoch: 5| Step: 10
Training loss: 1.809057913553813
Validation loss: 2.638266493921995

Epoch: 5| Step: 11
Training loss: 0.9925990415108469
Validation loss: 2.721239386271927

Epoch: 83| Step: 0
Training loss: 2.841137870593266
Validation loss: 2.7638661364609813

Epoch: 5| Step: 1
Training loss: 1.4750561170086327
Validation loss: 2.7016758185486

Epoch: 5| Step: 2
Training loss: 2.22300291123502
Validation loss: 2.8796599879600433

Epoch: 5| Step: 3
Training loss: 2.258901155414207
Validation loss: 2.8481984906442674

Epoch: 5| Step: 4
Training loss: 2.830446418086585
Validation loss: 2.9373306604368308

Epoch: 5| Step: 5
Training loss: 2.0141591500944456
Validation loss: 2.8070430480386337

Epoch: 5| Step: 6
Training loss: 2.437413629811179
Validation loss: 2.77434685713085

Epoch: 5| Step: 7
Training loss: 2.18908132889442
Validation loss: 2.654997683749772

Epoch: 5| Step: 8
Training loss: 2.0814386780590053
Validation loss: 2.628347340272128

Epoch: 5| Step: 9
Training loss: 1.598496046140743
Validation loss: 2.5803016490691952

Epoch: 5| Step: 10
Training loss: 1.9693610438969469
Validation loss: 2.5758300238231904

Epoch: 5| Step: 11
Training loss: 0.8278137917830748
Validation loss: 2.6545818064580513

Epoch: 84| Step: 0
Training loss: 2.728805188028531
Validation loss: 2.6745815065608154

Epoch: 5| Step: 1
Training loss: 2.4201075842091666
Validation loss: 2.7362641593214736

Epoch: 5| Step: 2
Training loss: 2.4444996028032953
Validation loss: 2.706258475427666

Epoch: 5| Step: 3
Training loss: 2.8266152414406407
Validation loss: 2.6884315377024115

Epoch: 5| Step: 4
Training loss: 1.9746221132556177
Validation loss: 2.6611056134528397

Epoch: 5| Step: 5
Training loss: 1.9205807925994938
Validation loss: 2.6550081117449813

Epoch: 5| Step: 6
Training loss: 2.1841105769044744
Validation loss: 2.5983046733422763

Epoch: 5| Step: 7
Training loss: 1.7731138765929433
Validation loss: 2.5558125063239663

Epoch: 5| Step: 8
Training loss: 1.8583722014988249
Validation loss: 2.6342212707566603

Epoch: 5| Step: 9
Training loss: 2.298773052687022
Validation loss: 2.6645345223086707

Epoch: 5| Step: 10
Training loss: 2.243642301817163
Validation loss: 2.5980075646420757

Epoch: 5| Step: 11
Training loss: 2.09672210181395
Validation loss: 2.724203172892072

Epoch: 85| Step: 0
Training loss: 2.300218289838641
Validation loss: 2.5902784087311286

Epoch: 5| Step: 1
Training loss: 1.780336312979613
Validation loss: 2.644754149651763

Epoch: 5| Step: 2
Training loss: 2.0385520559236876
Validation loss: 2.6692916770059214

Epoch: 5| Step: 3
Training loss: 1.7367738509950343
Validation loss: 2.581958536960401

Epoch: 5| Step: 4
Training loss: 1.6816313385568575
Validation loss: 2.5821084854031957

Epoch: 5| Step: 5
Training loss: 2.3169307018547762
Validation loss: 2.606820075871729

Epoch: 5| Step: 6
Training loss: 2.2166630775977123
Validation loss: 2.5875972403960885

Epoch: 5| Step: 7
Training loss: 2.4514803870838606
Validation loss: 2.5976743425011675

Epoch: 5| Step: 8
Training loss: 2.2373694781375875
Validation loss: 2.6422250666430145

Epoch: 5| Step: 9
Training loss: 2.2940562072426487
Validation loss: 2.5881552353417616

Epoch: 5| Step: 10
Training loss: 2.7146959442959364
Validation loss: 2.62038517037795

Epoch: 5| Step: 11
Training loss: 1.351058248488238
Validation loss: 2.581324943858479

Epoch: 86| Step: 0
Training loss: 2.022160307433602
Validation loss: 2.598635733133419

Epoch: 5| Step: 1
Training loss: 2.1895851007001323
Validation loss: 2.6017851404914483

Epoch: 5| Step: 2
Training loss: 2.051369660750199
Validation loss: 2.6271055420782083

Epoch: 5| Step: 3
Training loss: 3.0699277835764334
Validation loss: 2.6681638751485877

Epoch: 5| Step: 4
Training loss: 2.0466438920103136
Validation loss: 2.6618143964503918

Epoch: 5| Step: 5
Training loss: 1.852982310676443
Validation loss: 2.6454041626054368

Epoch: 5| Step: 6
Training loss: 2.051113021898373
Validation loss: 2.6583495089259044

Epoch: 5| Step: 7
Training loss: 1.4344660212739706
Validation loss: 2.6825296660575573

Epoch: 5| Step: 8
Training loss: 1.7987317650714356
Validation loss: 2.556472290963002

Epoch: 5| Step: 9
Training loss: 2.1947240074626935
Validation loss: 2.6224526730955966

Epoch: 5| Step: 10
Training loss: 2.318269903036045
Validation loss: 2.6612015704216896

Epoch: 5| Step: 11
Training loss: 2.107606612797526
Validation loss: 2.6133379224439715

Epoch: 87| Step: 0
Training loss: 2.02011519056419
Validation loss: 2.6675558520055835

Epoch: 5| Step: 1
Training loss: 2.035255942218495
Validation loss: 2.6173991521021627

Epoch: 5| Step: 2
Training loss: 2.3501997639586882
Validation loss: 2.601908888872945

Epoch: 5| Step: 3
Training loss: 1.7249197761567452
Validation loss: 2.6333152524914887

Epoch: 5| Step: 4
Training loss: 2.35718288016091
Validation loss: 2.6388019649232404

Epoch: 5| Step: 5
Training loss: 2.1877677753586426
Validation loss: 2.6363075595056777

Epoch: 5| Step: 6
Training loss: 2.527543544979025
Validation loss: 2.578332750061042

Epoch: 5| Step: 7
Training loss: 2.3512369228325887
Validation loss: 2.6240552269245483

Epoch: 5| Step: 8
Training loss: 1.8375031633414722
Validation loss: 2.594922578179787

Epoch: 5| Step: 9
Training loss: 1.8430695652119844
Validation loss: 2.660485608087116

Epoch: 5| Step: 10
Training loss: 1.9645889147304674
Validation loss: 2.6156846813288714

Epoch: 5| Step: 11
Training loss: 2.3123873090349902
Validation loss: 2.6337904957809952

Epoch: 88| Step: 0
Training loss: 2.4398526306674753
Validation loss: 2.626064092431153

Epoch: 5| Step: 1
Training loss: 1.91279136333183
Validation loss: 2.6993119572888857

Epoch: 5| Step: 2
Training loss: 1.840373616951877
Validation loss: 2.703763074298016

Epoch: 5| Step: 3
Training loss: 1.9263762817972623
Validation loss: 2.63179888206728

Epoch: 5| Step: 4
Training loss: 1.441552131527888
Validation loss: 2.6720869378103713

Epoch: 5| Step: 5
Training loss: 2.039387644133212
Validation loss: 2.692963539489598

Epoch: 5| Step: 6
Training loss: 2.671176216702348
Validation loss: 2.6302809160748977

Epoch: 5| Step: 7
Training loss: 2.0214643247043087
Validation loss: 2.639643119781252

Epoch: 5| Step: 8
Training loss: 2.6073832876943417
Validation loss: 2.629731531014447

Epoch: 5| Step: 9
Training loss: 1.6696346638291235
Validation loss: 2.66289973310342

Epoch: 5| Step: 10
Training loss: 2.414228711378337
Validation loss: 2.584437247237402

Epoch: 5| Step: 11
Training loss: 2.4498059604644205
Validation loss: 2.649993529401833

Epoch: 89| Step: 0
Training loss: 1.733209372941853
Validation loss: 2.6486295444774135

Epoch: 5| Step: 1
Training loss: 2.216273900659975
Validation loss: 2.6269852420020605

Epoch: 5| Step: 2
Training loss: 2.523804534579861
Validation loss: 2.6030716437603156

Epoch: 5| Step: 3
Training loss: 1.9810838816222698
Validation loss: 2.7043888503806475

Epoch: 5| Step: 4
Training loss: 1.9269447757981624
Validation loss: 2.7170893212119696

Epoch: 5| Step: 5
Training loss: 1.839356311284483
Validation loss: 2.6699224182292065

Epoch: 5| Step: 6
Training loss: 1.6162360151944157
Validation loss: 2.71576355645421

Epoch: 5| Step: 7
Training loss: 2.036571632869344
Validation loss: 2.75253703391292

Epoch: 5| Step: 8
Training loss: 2.4577272821144156
Validation loss: 2.6808053920342334

Epoch: 5| Step: 9
Training loss: 2.7579596374855653
Validation loss: 2.6893950035668652

Epoch: 5| Step: 10
Training loss: 1.9600972963045036
Validation loss: 2.631009449462639

Epoch: 5| Step: 11
Training loss: 1.8646258415050978
Validation loss: 2.625870802416385

Epoch: 90| Step: 0
Training loss: 1.9301755342065994
Validation loss: 2.66890206123385

Epoch: 5| Step: 1
Training loss: 1.9522825331476483
Validation loss: 2.604531534701337

Epoch: 5| Step: 2
Training loss: 1.8261101207389399
Validation loss: 2.60457305534734

Epoch: 5| Step: 3
Training loss: 1.9781706529022678
Validation loss: 2.6588079627216765

Epoch: 5| Step: 4
Training loss: 2.4346737248644654
Validation loss: 2.744614004843345

Epoch: 5| Step: 5
Training loss: 1.9859323473007382
Validation loss: 2.694630806634835

Epoch: 5| Step: 6
Training loss: 2.6206393579971734
Validation loss: 2.6712996660934

Epoch: 5| Step: 7
Training loss: 2.6306597231048086
Validation loss: 2.638209406196744

Epoch: 5| Step: 8
Training loss: 2.123257202847686
Validation loss: 2.6461085316572053

Epoch: 5| Step: 9
Training loss: 2.4809336309262267
Validation loss: 2.6157317406778655

Epoch: 5| Step: 10
Training loss: 1.7764378513166326
Validation loss: 2.666953456378128

Epoch: 5| Step: 11
Training loss: 2.006681012116078
Validation loss: 2.6856640414485984

Epoch: 91| Step: 0
Training loss: 2.304560253703873
Validation loss: 2.800181911298346

Epoch: 5| Step: 1
Training loss: 2.8714461544992407
Validation loss: 2.8728228009892445

Epoch: 5| Step: 2
Training loss: 1.8601991766246666
Validation loss: 2.85017536861887

Epoch: 5| Step: 3
Training loss: 1.979655563470231
Validation loss: 2.819021290441719

Epoch: 5| Step: 4
Training loss: 1.8976086349450054
Validation loss: 2.694629844424166

Epoch: 5| Step: 5
Training loss: 1.7562298240724499
Validation loss: 2.6284956174442278

Epoch: 5| Step: 6
Training loss: 2.3548491059898513
Validation loss: 2.6333152864437346

Epoch: 5| Step: 7
Training loss: 2.471796497974435
Validation loss: 2.585080806814523

Epoch: 5| Step: 8
Training loss: 1.739148418706707
Validation loss: 2.5859994679197458

Epoch: 5| Step: 9
Training loss: 2.4626859720558056
Validation loss: 2.5758461021996246

Epoch: 5| Step: 10
Training loss: 1.8109041620696138
Validation loss: 2.5347568254126536

Epoch: 5| Step: 11
Training loss: 2.5657552186581505
Validation loss: 2.595678072450408

Epoch: 92| Step: 0
Training loss: 2.126162940053337
Validation loss: 2.6257832357756064

Epoch: 5| Step: 1
Training loss: 2.2228044886171836
Validation loss: 2.548677261194523

Epoch: 5| Step: 2
Training loss: 1.8835783860898383
Validation loss: 2.5439344956258956

Epoch: 5| Step: 3
Training loss: 1.7408772147153537
Validation loss: 2.5963445808032177

Epoch: 5| Step: 4
Training loss: 1.7917722478703941
Validation loss: 2.6498463277224835

Epoch: 5| Step: 5
Training loss: 2.0272590751825867
Validation loss: 2.6360622050136113

Epoch: 5| Step: 6
Training loss: 1.9023373582172523
Validation loss: 2.64596583692915

Epoch: 5| Step: 7
Training loss: 2.387592661392609
Validation loss: 2.6646406379803094

Epoch: 5| Step: 8
Training loss: 3.0408603871142947
Validation loss: 2.600335302342706

Epoch: 5| Step: 9
Training loss: 2.1763989652059457
Validation loss: 2.5657982456818376

Epoch: 5| Step: 10
Training loss: 1.8896904519311815
Validation loss: 2.6596721221702775

Epoch: 5| Step: 11
Training loss: 1.2156850961770556
Validation loss: 2.5877286157339614

Epoch: 93| Step: 0
Training loss: 1.891594378172663
Validation loss: 2.5626169581200173

Epoch: 5| Step: 1
Training loss: 1.9972760605161748
Validation loss: 2.6181350169502817

Epoch: 5| Step: 2
Training loss: 2.281960259221073
Validation loss: 2.6586532790874604

Epoch: 5| Step: 3
Training loss: 2.0445531824237975
Validation loss: 2.608661934889822

Epoch: 5| Step: 4
Training loss: 2.0147224002192132
Validation loss: 2.5593469632188577

Epoch: 5| Step: 5
Training loss: 2.2613471323790377
Validation loss: 2.571605797603745

Epoch: 5| Step: 6
Training loss: 1.5004197169241726
Validation loss: 2.6062220123672746

Epoch: 5| Step: 7
Training loss: 1.9458529782443752
Validation loss: 2.6042340854818766

Epoch: 5| Step: 8
Training loss: 2.5489194188631035
Validation loss: 2.605290678955638

Epoch: 5| Step: 9
Training loss: 2.3750281081293116
Validation loss: 2.6123842373438277

Epoch: 5| Step: 10
Training loss: 1.8262773615923853
Validation loss: 2.6131987356740396

Epoch: 5| Step: 11
Training loss: 1.4556130878752183
Validation loss: 2.632565616008484

Epoch: 94| Step: 0
Training loss: 1.8614411614950739
Validation loss: 2.5735634764252056

Epoch: 5| Step: 1
Training loss: 1.8839561819379016
Validation loss: 2.5694162725215857

Epoch: 5| Step: 2
Training loss: 1.5142588012802298
Validation loss: 2.6492021670207304

Epoch: 5| Step: 3
Training loss: 1.9741180140612573
Validation loss: 2.5379680994166804

Epoch: 5| Step: 4
Training loss: 1.939879033554783
Validation loss: 2.634827907420898

Epoch: 5| Step: 5
Training loss: 2.2648143501913176
Validation loss: 2.671489271313867

Epoch: 5| Step: 6
Training loss: 2.3280539277768475
Validation loss: 2.557938271927508

Epoch: 5| Step: 7
Training loss: 1.963057750969792
Validation loss: 2.595938701287246

Epoch: 5| Step: 8
Training loss: 2.1799443138079724
Validation loss: 2.6063326347600744

Epoch: 5| Step: 9
Training loss: 2.1516907630869295
Validation loss: 2.593047284297718

Epoch: 5| Step: 10
Training loss: 2.4761240477786637
Validation loss: 2.663593489603132

Epoch: 5| Step: 11
Training loss: 1.6043822981665075
Validation loss: 2.621602133706229

Epoch: 95| Step: 0
Training loss: 2.2758304547413077
Validation loss: 2.635929126948558

Epoch: 5| Step: 1
Training loss: 2.0444928933475133
Validation loss: 2.549308117800253

Epoch: 5| Step: 2
Training loss: 2.085095982343431
Validation loss: 2.692022879525498

Epoch: 5| Step: 3
Training loss: 2.163393103014375
Validation loss: 2.7070940899401594

Epoch: 5| Step: 4
Training loss: 2.2106999246045875
Validation loss: 2.7012074271193423

Epoch: 5| Step: 5
Training loss: 2.3417728476926256
Validation loss: 2.6258505359131763

Epoch: 5| Step: 6
Training loss: 2.048263311945575
Validation loss: 2.621368105799703

Epoch: 5| Step: 7
Training loss: 1.6383580122078847
Validation loss: 2.5742387515165563

Epoch: 5| Step: 8
Training loss: 2.0884742884497345
Validation loss: 2.6341200391807504

Epoch: 5| Step: 9
Training loss: 1.9916087787254648
Validation loss: 2.594291228391817

Epoch: 5| Step: 10
Training loss: 1.9418211710393496
Validation loss: 2.5658792528497663

Epoch: 5| Step: 11
Training loss: 1.5709403381868383
Validation loss: 2.6250801149888674

Epoch: 96| Step: 0
Training loss: 1.8641758336725849
Validation loss: 2.599931539801855

Epoch: 5| Step: 1
Training loss: 1.9988753017444154
Validation loss: 2.581784165833872

Epoch: 5| Step: 2
Training loss: 2.2011658093860524
Validation loss: 2.618356536616326

Epoch: 5| Step: 3
Training loss: 1.9247745877355429
Validation loss: 2.669905853409451

Epoch: 5| Step: 4
Training loss: 1.8019756071787396
Validation loss: 2.638101865848802

Epoch: 5| Step: 5
Training loss: 2.532669517062957
Validation loss: 2.6319379853969243

Epoch: 5| Step: 6
Training loss: 2.2509917087003983
Validation loss: 2.655255660773525

Epoch: 5| Step: 7
Training loss: 1.9906053431332378
Validation loss: 2.7071585577111557

Epoch: 5| Step: 8
Training loss: 1.843933096377419
Validation loss: 2.6771793175100993

Epoch: 5| Step: 9
Training loss: 1.922459769255874
Validation loss: 2.6334182389570726

Epoch: 5| Step: 10
Training loss: 1.6251012330433943
Validation loss: 2.6031883551072688

Epoch: 5| Step: 11
Training loss: 2.0919955290168555
Validation loss: 2.554977252794248

Epoch: 97| Step: 0
Training loss: 1.6636476671258407
Validation loss: 2.600709842256587

Epoch: 5| Step: 1
Training loss: 1.7679932501996338
Validation loss: 2.643246145460096

Epoch: 5| Step: 2
Training loss: 1.691929830868227
Validation loss: 2.6631956023095333

Epoch: 5| Step: 3
Training loss: 1.867646101173484
Validation loss: 2.6180299892717485

Epoch: 5| Step: 4
Training loss: 2.397455169608642
Validation loss: 2.642597507613422

Epoch: 5| Step: 5
Training loss: 1.8224226218543502
Validation loss: 2.5688687166376565

Epoch: 5| Step: 6
Training loss: 2.1162739151551397
Validation loss: 2.639356505988382

Epoch: 5| Step: 7
Training loss: 1.892863627060223
Validation loss: 2.5933939716237666

Epoch: 5| Step: 8
Training loss: 2.1718165986696105
Validation loss: 2.64351147176092

Epoch: 5| Step: 9
Training loss: 2.402412326733357
Validation loss: 2.6732479011134744

Epoch: 5| Step: 10
Training loss: 2.5768682017434448
Validation loss: 2.6683840635513905

Epoch: 5| Step: 11
Training loss: 1.778408729160969
Validation loss: 2.6351841508624987

Epoch: 98| Step: 0
Training loss: 2.9002936247458138
Validation loss: 2.6450690544815596

Epoch: 5| Step: 1
Training loss: 2.1708118937990175
Validation loss: 2.667543082212592

Epoch: 5| Step: 2
Training loss: 1.850010668234093
Validation loss: 2.593909459785078

Epoch: 5| Step: 3
Training loss: 1.8258530935207418
Validation loss: 2.6217453019348715

Epoch: 5| Step: 4
Training loss: 1.9404897694916377
Validation loss: 2.6229734015192983

Epoch: 5| Step: 5
Training loss: 1.4234513149156378
Validation loss: 2.645929399883967

Epoch: 5| Step: 6
Training loss: 1.6614070713023603
Validation loss: 2.600458401532173

Epoch: 5| Step: 7
Training loss: 1.7883747894634674
Validation loss: 2.5977862791630777

Epoch: 5| Step: 8
Training loss: 2.3439772432153485
Validation loss: 2.5594227619861387

Epoch: 5| Step: 9
Training loss: 1.9407692061700799
Validation loss: 2.5391124583489066

Epoch: 5| Step: 10
Training loss: 1.7896956610222956
Validation loss: 2.6169459141307363

Epoch: 5| Step: 11
Training loss: 1.5448334447965144
Validation loss: 2.61434155874974

Epoch: 99| Step: 0
Training loss: 1.8359356169995331
Validation loss: 2.5729825414237513

Epoch: 5| Step: 1
Training loss: 2.0322246853967783
Validation loss: 2.6151767882962282

Epoch: 5| Step: 2
Training loss: 2.182839142098171
Validation loss: 2.623570832739367

Epoch: 5| Step: 3
Training loss: 1.7808737106398902
Validation loss: 2.636535754976758

Epoch: 5| Step: 4
Training loss: 1.751479068780225
Validation loss: 2.6983093592073715

Epoch: 5| Step: 5
Training loss: 1.6056222215793992
Validation loss: 2.6350467872145424

Epoch: 5| Step: 6
Training loss: 1.9534747611632537
Validation loss: 2.659970482881162

Epoch: 5| Step: 7
Training loss: 1.9089165469632934
Validation loss: 2.6869747143835654

Epoch: 5| Step: 8
Training loss: 2.797443864819962
Validation loss: 2.6501921596073057

Epoch: 5| Step: 9
Training loss: 2.0662550988108452
Validation loss: 2.624698922511336

Epoch: 5| Step: 10
Training loss: 1.4490611358234697
Validation loss: 2.625977860073659

Epoch: 5| Step: 11
Training loss: 2.2801432603031992
Validation loss: 2.5794974248012688

Epoch: 100| Step: 0
Training loss: 1.9153415688057607
Validation loss: 2.6030269373068906

Epoch: 5| Step: 1
Training loss: 2.1943164887391897
Validation loss: 2.580554511007648

Epoch: 5| Step: 2
Training loss: 1.4061653111705883
Validation loss: 2.6406697339062823

Epoch: 5| Step: 3
Training loss: 2.0485164670759537
Validation loss: 2.6334942313324774

Epoch: 5| Step: 4
Training loss: 1.8644160048208078
Validation loss: 2.6014565989463927

Epoch: 5| Step: 5
Training loss: 1.2784003690942272
Validation loss: 2.5958525971258646

Epoch: 5| Step: 6
Training loss: 2.089617964767239
Validation loss: 2.6199385498814522

Epoch: 5| Step: 7
Training loss: 2.4694549905985412
Validation loss: 2.6241678856654733

Epoch: 5| Step: 8
Training loss: 2.114486942693843
Validation loss: 2.580184992064906

Epoch: 5| Step: 9
Training loss: 2.0131966800713106
Validation loss: 2.5912907251585717

Epoch: 5| Step: 10
Training loss: 2.096515935180862
Validation loss: 2.585387387495423

Epoch: 5| Step: 11
Training loss: 2.501251193708281
Validation loss: 2.6382589631273135

Epoch: 101| Step: 0
Training loss: 2.1698019988616277
Validation loss: 2.7248072763122213

Epoch: 5| Step: 1
Training loss: 2.0382657303078546
Validation loss: 2.7152573707238647

Epoch: 5| Step: 2
Training loss: 2.4054135937266103
Validation loss: 2.6909213208268983

Epoch: 5| Step: 3
Training loss: 1.4304174008781014
Validation loss: 2.6528485603830987

Epoch: 5| Step: 4
Training loss: 1.466340706467582
Validation loss: 2.621609534251202

Epoch: 5| Step: 5
Training loss: 1.7570323654042355
Validation loss: 2.615376649746624

Epoch: 5| Step: 6
Training loss: 2.339480567729133
Validation loss: 2.549350724899236

Epoch: 5| Step: 7
Training loss: 2.058107148483152
Validation loss: 2.5637288442328106

Epoch: 5| Step: 8
Training loss: 1.8343400214270484
Validation loss: 2.603860033420384

Epoch: 5| Step: 9
Training loss: 2.1767814706823367
Validation loss: 2.5784385413429476

Epoch: 5| Step: 10
Training loss: 2.3941124305552486
Validation loss: 2.55327684689416

Epoch: 5| Step: 11
Training loss: 0.7491853183451391
Validation loss: 2.516853597205969

Epoch: 102| Step: 0
Training loss: 1.3981677599708744
Validation loss: 2.6027681537352083

Epoch: 5| Step: 1
Training loss: 1.9083649206531854
Validation loss: 2.6364138071306105

Epoch: 5| Step: 2
Training loss: 2.068840223114007
Validation loss: 2.563176717024805

Epoch: 5| Step: 3
Training loss: 2.378835091364414
Validation loss: 2.6060138267583084

Epoch: 5| Step: 4
Training loss: 1.6959626669463514
Validation loss: 2.6636160124924393

Epoch: 5| Step: 5
Training loss: 2.0732895661096076
Validation loss: 2.6781886017175074

Epoch: 5| Step: 6
Training loss: 1.626175821827798
Validation loss: 2.650530356741555

Epoch: 5| Step: 7
Training loss: 2.3043770273860313
Validation loss: 2.686754045534695

Epoch: 5| Step: 8
Training loss: 2.076931374008908
Validation loss: 2.6640996548176954

Epoch: 5| Step: 9
Training loss: 1.6357535563970584
Validation loss: 2.6767510988470677

Epoch: 5| Step: 10
Training loss: 2.233037801898354
Validation loss: 2.6638326238082985

Epoch: 5| Step: 11
Training loss: 1.2119645224247833
Validation loss: 2.596443822620656

Epoch: 103| Step: 0
Training loss: 2.0236611261109205
Validation loss: 2.6163048997280813

Epoch: 5| Step: 1
Training loss: 2.1172066437816466
Validation loss: 2.642055902525677

Epoch: 5| Step: 2
Training loss: 1.2801714753984914
Validation loss: 2.620592646445728

Epoch: 5| Step: 3
Training loss: 1.8455023116410174
Validation loss: 2.5751492714747317

Epoch: 5| Step: 4
Training loss: 1.6301300793798184
Validation loss: 2.6377064604501865

Epoch: 5| Step: 5
Training loss: 2.186340787822618
Validation loss: 2.5896459957550237

Epoch: 5| Step: 6
Training loss: 1.5328958968905015
Validation loss: 2.585605857457987

Epoch: 5| Step: 7
Training loss: 2.2314251187201695
Validation loss: 2.675435376611066

Epoch: 5| Step: 8
Training loss: 2.2525872084727157
Validation loss: 2.609172893166664

Epoch: 5| Step: 9
Training loss: 1.8062316101616422
Validation loss: 2.608637041066109

Epoch: 5| Step: 10
Training loss: 1.7376330592300127
Validation loss: 2.61998536978221

Epoch: 5| Step: 11
Training loss: 1.765804855503497
Validation loss: 2.686488841074531

Epoch: 104| Step: 0
Training loss: 2.0577199626904377
Validation loss: 2.656038350667661

Epoch: 5| Step: 1
Training loss: 1.6561829895282878
Validation loss: 2.613962758394631

Epoch: 5| Step: 2
Training loss: 1.6610129625433574
Validation loss: 2.5971059842598145

Epoch: 5| Step: 3
Training loss: 1.9375091675572238
Validation loss: 2.6590974094318334

Epoch: 5| Step: 4
Training loss: 1.61657629579785
Validation loss: 2.684763102514291

Epoch: 5| Step: 5
Training loss: 2.1190760448829065
Validation loss: 2.6744309816907372

Epoch: 5| Step: 6
Training loss: 1.7351132445521498
Validation loss: 2.568722303539745

Epoch: 5| Step: 7
Training loss: 2.1824857736235286
Validation loss: 2.6367069083995767

Epoch: 5| Step: 8
Training loss: 2.0677114593969077
Validation loss: 2.54373954970754

Epoch: 5| Step: 9
Training loss: 2.4560457566935043
Validation loss: 2.576804811408594

Epoch: 5| Step: 10
Training loss: 1.4986062727504275
Validation loss: 2.6247125120016204

Epoch: 5| Step: 11
Training loss: 1.2160365881309227
Validation loss: 2.5967955920292773

Epoch: 105| Step: 0
Training loss: 1.9891273481970884
Validation loss: 2.635387146574603

Epoch: 5| Step: 1
Training loss: 1.6190089780807138
Validation loss: 2.6396152589749535

Epoch: 5| Step: 2
Training loss: 1.7497690593380733
Validation loss: 2.589135646151317

Epoch: 5| Step: 3
Training loss: 1.8078706750106537
Validation loss: 2.5934535320549634

Epoch: 5| Step: 4
Training loss: 1.5769065458851919
Validation loss: 2.6387163446021837

Epoch: 5| Step: 5
Training loss: 1.949943392494381
Validation loss: 2.5808526146570543

Epoch: 5| Step: 6
Training loss: 2.0489015520609675
Validation loss: 2.6744988925779642

Epoch: 5| Step: 7
Training loss: 1.5180473240548427
Validation loss: 2.640255753623006

Epoch: 5| Step: 8
Training loss: 2.135595720429249
Validation loss: 2.6280419193279574

Epoch: 5| Step: 9
Training loss: 2.6562017099815454
Validation loss: 2.6571881058861337

Epoch: 5| Step: 10
Training loss: 2.0313647898003753
Validation loss: 2.6815668231600442

Epoch: 5| Step: 11
Training loss: 0.930304699071559
Validation loss: 2.7386472732207214

Epoch: 106| Step: 0
Training loss: 1.718985801473923
Validation loss: 2.66276698900576

Epoch: 5| Step: 1
Training loss: 1.857347809832136
Validation loss: 2.690988638359504

Epoch: 5| Step: 2
Training loss: 1.9949266937478516
Validation loss: 2.5858205209878316

Epoch: 5| Step: 3
Training loss: 2.0359007193111363
Validation loss: 2.67023039651225

Epoch: 5| Step: 4
Training loss: 1.8496512677162436
Validation loss: 2.5856706187664025

Epoch: 5| Step: 5
Training loss: 2.1712596213611284
Validation loss: 2.5703888855688803

Epoch: 5| Step: 6
Training loss: 2.2521973582528774
Validation loss: 2.619442055026794

Epoch: 5| Step: 7
Training loss: 1.6959778495277782
Validation loss: 2.599858926191959

Epoch: 5| Step: 8
Training loss: 1.5903168145524316
Validation loss: 2.567147727003466

Epoch: 5| Step: 9
Training loss: 1.6863494058750306
Validation loss: 2.5784501419802335

Epoch: 5| Step: 10
Training loss: 1.9158943596747373
Validation loss: 2.627388185686251

Epoch: 5| Step: 11
Training loss: 0.8865894777955332
Validation loss: 2.6135174977591533

Epoch: 107| Step: 0
Training loss: 1.8992397669669274
Validation loss: 2.630862599696331

Epoch: 5| Step: 1
Training loss: 1.7349087005690826
Validation loss: 2.6331764558246

Epoch: 5| Step: 2
Training loss: 2.4185298336476846
Validation loss: 2.5702041286205195

Epoch: 5| Step: 3
Training loss: 2.4514681329307346
Validation loss: 2.627126657268389

Epoch: 5| Step: 4
Training loss: 1.5303885703238829
Validation loss: 2.5960314724547047

Epoch: 5| Step: 5
Training loss: 1.596751061573694
Validation loss: 2.603128399184604

Epoch: 5| Step: 6
Training loss: 2.2621575491532773
Validation loss: 2.6274817179543817

Epoch: 5| Step: 7
Training loss: 1.367039176524652
Validation loss: 2.70299843214368

Epoch: 5| Step: 8
Training loss: 1.8029710277487114
Validation loss: 2.56385345304194

Epoch: 5| Step: 9
Training loss: 1.8097478426432856
Validation loss: 2.5437298625520746

Epoch: 5| Step: 10
Training loss: 1.3637688319569456
Validation loss: 2.5931027075819983

Epoch: 5| Step: 11
Training loss: 2.1468217912546357
Validation loss: 2.6504033724863185

Epoch: 108| Step: 0
Training loss: 1.1730391251558592
Validation loss: 2.5923246082593017

Epoch: 5| Step: 1
Training loss: 2.0274886298184187
Validation loss: 2.571896425407472

Epoch: 5| Step: 2
Training loss: 1.836473167678313
Validation loss: 2.64436716221455

Epoch: 5| Step: 3
Training loss: 2.150643842238232
Validation loss: 2.603286431639415

Epoch: 5| Step: 4
Training loss: 1.9289871983713922
Validation loss: 2.594030499132447

Epoch: 5| Step: 5
Training loss: 1.5404699251383447
Validation loss: 2.5610405790055197

Epoch: 5| Step: 6
Training loss: 2.386121409784646
Validation loss: 2.6091648862384518

Epoch: 5| Step: 7
Training loss: 2.118450731055232
Validation loss: 2.6159546334866057

Epoch: 5| Step: 8
Training loss: 1.9851209184729435
Validation loss: 2.5525428799381675

Epoch: 5| Step: 9
Training loss: 1.5554241179764563
Validation loss: 2.5644422125602326

Epoch: 5| Step: 10
Training loss: 1.810989408102926
Validation loss: 2.626588314397775

Epoch: 5| Step: 11
Training loss: 1.385095123990566
Validation loss: 2.582367517809679

Epoch: 109| Step: 0
Training loss: 2.018823968341204
Validation loss: 2.648297710349166

Epoch: 5| Step: 1
Training loss: 1.738667854436418
Validation loss: 2.681290183399771

Epoch: 5| Step: 2
Training loss: 2.0050552375775847
Validation loss: 2.6401030007592645

Epoch: 5| Step: 3
Training loss: 1.766085066819143
Validation loss: 2.6524987229330073

Epoch: 5| Step: 4
Training loss: 1.520436544346765
Validation loss: 2.571286597602649

Epoch: 5| Step: 5
Training loss: 1.6757613316488162
Validation loss: 2.595382016127679

Epoch: 5| Step: 6
Training loss: 1.8432645643603862
Validation loss: 2.5552160200482117

Epoch: 5| Step: 7
Training loss: 2.5416258094713893
Validation loss: 2.529128696736902

Epoch: 5| Step: 8
Training loss: 1.4757286017958882
Validation loss: 2.4951508541535756

Epoch: 5| Step: 9
Training loss: 1.8131374027599871
Validation loss: 2.5209107873120105

Epoch: 5| Step: 10
Training loss: 2.197734433494465
Validation loss: 2.6089156654518373

Epoch: 5| Step: 11
Training loss: 1.2446694200999844
Validation loss: 2.610795580425304

Epoch: 110| Step: 0
Training loss: 1.8708857856766337
Validation loss: 2.56627112371091

Epoch: 5| Step: 1
Training loss: 1.6568020314510385
Validation loss: 2.6220047945518994

Epoch: 5| Step: 2
Training loss: 1.7413908501239772
Validation loss: 2.579760181243391

Epoch: 5| Step: 3
Training loss: 1.6820354286209271
Validation loss: 2.6635355983023996

Epoch: 5| Step: 4
Training loss: 1.4458688026203723
Validation loss: 2.6692506122598534

Epoch: 5| Step: 5
Training loss: 2.122243214992175
Validation loss: 2.5510125710097746

Epoch: 5| Step: 6
Training loss: 1.560906704130139
Validation loss: 2.579728026969957

Epoch: 5| Step: 7
Training loss: 1.8766051733038964
Validation loss: 2.5744032226902305

Epoch: 5| Step: 8
Training loss: 1.8192295897233868
Validation loss: 2.543271770871715

Epoch: 5| Step: 9
Training loss: 1.5638747461754934
Validation loss: 2.582817031170208

Epoch: 5| Step: 10
Training loss: 2.495934709667033
Validation loss: 2.6175552565272056

Epoch: 5| Step: 11
Training loss: 1.9461598217015026
Validation loss: 2.6084836514844003

Epoch: 111| Step: 0
Training loss: 1.4925470368403089
Validation loss: 2.5863298808010593

Epoch: 5| Step: 1
Training loss: 1.6038673005946813
Validation loss: 2.6037812837908896

Epoch: 5| Step: 2
Training loss: 1.6711499790114153
Validation loss: 2.579691424521825

Epoch: 5| Step: 3
Training loss: 2.3870717488418007
Validation loss: 2.6143475036093173

Epoch: 5| Step: 4
Training loss: 1.79053726380791
Validation loss: 2.5260018781432003

Epoch: 5| Step: 5
Training loss: 2.101553877915631
Validation loss: 2.551051031609248

Epoch: 5| Step: 6
Training loss: 1.9112225698095675
Validation loss: 2.6138962885307877

Epoch: 5| Step: 7
Training loss: 1.2917800463885796
Validation loss: 2.561861214452927

Epoch: 5| Step: 8
Training loss: 1.9539374530898266
Validation loss: 2.6030706553379157

Epoch: 5| Step: 9
Training loss: 1.8707075576586332
Validation loss: 2.6004340633251934

Epoch: 5| Step: 10
Training loss: 1.580112980291935
Validation loss: 2.590758758975525

Epoch: 5| Step: 11
Training loss: 2.322931320988115
Validation loss: 2.580341268900105

Epoch: 112| Step: 0
Training loss: 2.023162469620026
Validation loss: 2.629762008617815

Epoch: 5| Step: 1
Training loss: 1.6877842416500708
Validation loss: 2.642577314881856

Epoch: 5| Step: 2
Training loss: 2.144091507204361
Validation loss: 2.573528631434603

Epoch: 5| Step: 3
Training loss: 1.6238080568337603
Validation loss: 2.5422105962809614

Epoch: 5| Step: 4
Training loss: 1.5922606746191783
Validation loss: 2.6449501648674816

Epoch: 5| Step: 5
Training loss: 1.7226269085865702
Validation loss: 2.635398933793269

Epoch: 5| Step: 6
Training loss: 1.9000252571434948
Validation loss: 2.6482128021735347

Epoch: 5| Step: 7
Training loss: 1.496250393388612
Validation loss: 2.6579989790042613

Epoch: 5| Step: 8
Training loss: 2.0002804797910847
Validation loss: 2.6310503578107935

Epoch: 5| Step: 9
Training loss: 2.272859899812574
Validation loss: 2.703109608865481

Epoch: 5| Step: 10
Training loss: 1.4071850952561629
Validation loss: 2.559292891399805

Epoch: 5| Step: 11
Training loss: 1.1645133662261347
Validation loss: 2.6038304887583643

Epoch: 113| Step: 0
Training loss: 1.4510540715454348
Validation loss: 2.721878681406655

Epoch: 5| Step: 1
Training loss: 1.629924428510236
Validation loss: 2.731835543020946

Epoch: 5| Step: 2
Training loss: 1.609938291468852
Validation loss: 2.615810206490185

Epoch: 5| Step: 3
Training loss: 1.8627568752646775
Validation loss: 2.6382960087818326

Epoch: 5| Step: 4
Training loss: 1.589837301555181
Validation loss: 2.6509931250114565

Epoch: 5| Step: 5
Training loss: 1.7669483727953184
Validation loss: 2.64257056514075

Epoch: 5| Step: 6
Training loss: 2.3078842492853417
Validation loss: 2.6982869050090406

Epoch: 5| Step: 7
Training loss: 1.4971071003613579
Validation loss: 2.554762416289428

Epoch: 5| Step: 8
Training loss: 2.0382320422969142
Validation loss: 2.663753674339172

Epoch: 5| Step: 9
Training loss: 2.2155936988158325
Validation loss: 2.6294793254907303

Epoch: 5| Step: 10
Training loss: 2.2445045753750192
Validation loss: 2.6042666238038947

Epoch: 5| Step: 11
Training loss: 0.6839546776669105
Validation loss: 2.660892095381883

Epoch: 114| Step: 0
Training loss: 2.0735085056223386
Validation loss: 2.628704563999213

Epoch: 5| Step: 1
Training loss: 1.6706727598408502
Validation loss: 2.6610610737594778

Epoch: 5| Step: 2
Training loss: 1.8977674392785369
Validation loss: 2.755188032675207

Epoch: 5| Step: 3
Training loss: 2.070004307102016
Validation loss: 2.8808087912391294

Epoch: 5| Step: 4
Training loss: 1.7075462001062918
Validation loss: 2.818419577664282

Epoch: 5| Step: 5
Training loss: 2.028874578217733
Validation loss: 2.7349705982952504

Epoch: 5| Step: 6
Training loss: 1.8648975967029273
Validation loss: 2.6962750176719426

Epoch: 5| Step: 7
Training loss: 1.7444420839133088
Validation loss: 2.6295899498310806

Epoch: 5| Step: 8
Training loss: 1.7742949442122093
Validation loss: 2.5550192987866533

Epoch: 5| Step: 9
Training loss: 1.3708573270667102
Validation loss: 2.572250153754034

Epoch: 5| Step: 10
Training loss: 1.8698973205242015
Validation loss: 2.6209788707074084

Epoch: 5| Step: 11
Training loss: 1.664793829883285
Validation loss: 2.5868807990092186

Epoch: 115| Step: 0
Training loss: 1.8818788865022995
Validation loss: 2.753804775379551

Epoch: 5| Step: 1
Training loss: 2.1581367309852464
Validation loss: 2.6922884059658867

Epoch: 5| Step: 2
Training loss: 1.7686156879017865
Validation loss: 2.647558627219415

Epoch: 5| Step: 3
Training loss: 1.4274961426744606
Validation loss: 2.5650152562154322

Epoch: 5| Step: 4
Training loss: 2.4760189001320314
Validation loss: 2.673664538495074

Epoch: 5| Step: 5
Training loss: 1.5912882173538165
Validation loss: 2.7031157094689213

Epoch: 5| Step: 6
Training loss: 1.7754275545784448
Validation loss: 2.6780341583656013

Epoch: 5| Step: 7
Training loss: 1.7553577152002346
Validation loss: 2.6788373401137764

Epoch: 5| Step: 8
Training loss: 1.8803230384504712
Validation loss: 2.7175528422730375

Epoch: 5| Step: 9
Training loss: 1.795729429539024
Validation loss: 2.7413812413872747

Epoch: 5| Step: 10
Training loss: 2.1747670849143153
Validation loss: 2.6831282832500807

Epoch: 5| Step: 11
Training loss: 1.3823707004117722
Validation loss: 2.661123937189543

Epoch: 116| Step: 0
Training loss: 2.3229751465511077
Validation loss: 2.660455127717857

Epoch: 5| Step: 1
Training loss: 1.6229907598790672
Validation loss: 2.62207238867954

Epoch: 5| Step: 2
Training loss: 1.7444920372730657
Validation loss: 2.614967953684343

Epoch: 5| Step: 3
Training loss: 1.6810935589353861
Validation loss: 2.621402811323778

Epoch: 5| Step: 4
Training loss: 1.3987574291287634
Validation loss: 2.605196105936472

Epoch: 5| Step: 5
Training loss: 1.3182489193456668
Validation loss: 2.6014372114803304

Epoch: 5| Step: 6
Training loss: 1.7945048747534558
Validation loss: 2.5484728647191597

Epoch: 5| Step: 7
Training loss: 1.8384196931688914
Validation loss: 2.5768017041125324

Epoch: 5| Step: 8
Training loss: 1.505442441622343
Validation loss: 2.5283442958157423

Epoch: 5| Step: 9
Training loss: 2.0701375635481183
Validation loss: 2.5737825987994545

Epoch: 5| Step: 10
Training loss: 1.6066378678053095
Validation loss: 2.6180095728999593

Epoch: 5| Step: 11
Training loss: 2.13087951482806
Validation loss: 2.534666107084947

Epoch: 117| Step: 0
Training loss: 1.8288488014841975
Validation loss: 2.6366961857336495

Epoch: 5| Step: 1
Training loss: 2.542734442960612
Validation loss: 2.624370768229389

Epoch: 5| Step: 2
Training loss: 1.8790774198035265
Validation loss: 2.712334414964032

Epoch: 5| Step: 3
Training loss: 1.7965155200452423
Validation loss: 2.589394297852065

Epoch: 5| Step: 4
Training loss: 1.9812836484729228
Validation loss: 2.7066836149956637

Epoch: 5| Step: 5
Training loss: 1.4343906443289185
Validation loss: 2.6958495779791107

Epoch: 5| Step: 6
Training loss: 1.727747238839214
Validation loss: 2.653835217185301

Epoch: 5| Step: 7
Training loss: 1.438498109033301
Validation loss: 2.5443071807222495

Epoch: 5| Step: 8
Training loss: 1.9625625260226958
Validation loss: 2.620711348448659

Epoch: 5| Step: 9
Training loss: 0.9709263013495323
Validation loss: 2.666538564515795

Epoch: 5| Step: 10
Training loss: 1.5687166522003733
Validation loss: 2.5915443203454536

Epoch: 5| Step: 11
Training loss: 2.100565961231142
Validation loss: 2.6050095694482707

Epoch: 118| Step: 0
Training loss: 1.7542866929310252
Validation loss: 2.6058599701636127

Epoch: 5| Step: 1
Training loss: 1.7062232857314117
Validation loss: 2.6627817515270116

Epoch: 5| Step: 2
Training loss: 1.4843086629399769
Validation loss: 2.654900548392952

Epoch: 5| Step: 3
Training loss: 1.3675534439801718
Validation loss: 2.641440459372779

Epoch: 5| Step: 4
Training loss: 1.6912513291945102
Validation loss: 2.6616029843153037

Epoch: 5| Step: 5
Training loss: 2.1867551352856127
Validation loss: 2.714489880375793

Epoch: 5| Step: 6
Training loss: 1.3776081664442565
Validation loss: 2.6398535848786016

Epoch: 5| Step: 7
Training loss: 1.780045219018463
Validation loss: 2.6975877860866078

Epoch: 5| Step: 8
Training loss: 2.4841705813969432
Validation loss: 2.6576765680135446

Epoch: 5| Step: 9
Training loss: 2.0629466180149443
Validation loss: 2.5800813207575266

Epoch: 5| Step: 10
Training loss: 1.2703703469481453
Validation loss: 2.5987059802592767

Epoch: 5| Step: 11
Training loss: 1.7383446156814397
Validation loss: 2.572935205977104

Epoch: 119| Step: 0
Training loss: 2.05825855052353
Validation loss: 2.5868109296932054

Epoch: 5| Step: 1
Training loss: 1.1728969949503452
Validation loss: 2.6122160709359745

Epoch: 5| Step: 2
Training loss: 1.6655354316490445
Validation loss: 2.6514137146896934

Epoch: 5| Step: 3
Training loss: 1.8207692895213448
Validation loss: 2.694755876350407

Epoch: 5| Step: 4
Training loss: 1.442506943657888
Validation loss: 2.5934477135870493

Epoch: 5| Step: 5
Training loss: 2.501432961821642
Validation loss: 2.5980105165682783

Epoch: 5| Step: 6
Training loss: 1.3646054545155277
Validation loss: 2.653227095779422

Epoch: 5| Step: 7
Training loss: 1.6548048228167065
Validation loss: 2.586637795887737

Epoch: 5| Step: 8
Training loss: 1.6743106391386897
Validation loss: 2.606054759621783

Epoch: 5| Step: 9
Training loss: 1.839202315493898
Validation loss: 2.6646089338355803

Epoch: 5| Step: 10
Training loss: 1.1657692602645668
Validation loss: 2.5982875659142564

Epoch: 5| Step: 11
Training loss: 1.6967729878541211
Validation loss: 2.53317988573021

Epoch: 120| Step: 0
Training loss: 1.669303413664316
Validation loss: 2.5896704008258236

Epoch: 5| Step: 1
Training loss: 1.8648965739394474
Validation loss: 2.551936045438231

Epoch: 5| Step: 2
Training loss: 0.9953288114399873
Validation loss: 2.560047480197522

Epoch: 5| Step: 3
Training loss: 1.6368281434858618
Validation loss: 2.631457046855988

Epoch: 5| Step: 4
Training loss: 2.1187043896832414
Validation loss: 2.5726336054496066

Epoch: 5| Step: 5
Training loss: 1.6845160345648766
Validation loss: 2.5765723437045467

Epoch: 5| Step: 6
Training loss: 1.7525688118696323
Validation loss: 2.612300177359327

Epoch: 5| Step: 7
Training loss: 1.982794845899263
Validation loss: 2.590207296394929

Epoch: 5| Step: 8
Training loss: 1.743440664876201
Validation loss: 2.635858944708053

Epoch: 5| Step: 9
Training loss: 1.5993173633131639
Validation loss: 2.638387446835566

Epoch: 5| Step: 10
Training loss: 1.2565561974705841
Validation loss: 2.606361849951536

Epoch: 5| Step: 11
Training loss: 1.6543063148850723
Validation loss: 2.585995495809491

Epoch: 121| Step: 0
Training loss: 1.7339972007227282
Validation loss: 2.6151343761695567

Epoch: 5| Step: 1
Training loss: 1.7203476849387087
Validation loss: 2.577189161974607

Epoch: 5| Step: 2
Training loss: 1.024131714172964
Validation loss: 2.617326275386839

Epoch: 5| Step: 3
Training loss: 2.187845366326045
Validation loss: 2.5501412781056443

Epoch: 5| Step: 4
Training loss: 1.6872311130630384
Validation loss: 2.594865647104505

Epoch: 5| Step: 5
Training loss: 1.6988616217290728
Validation loss: 2.635930468616405

Epoch: 5| Step: 6
Training loss: 1.6470104386231046
Validation loss: 2.5899787012289837

Epoch: 5| Step: 7
Training loss: 1.7271450665173693
Validation loss: 2.58210142947271

Epoch: 5| Step: 8
Training loss: 1.7163538095261996
Validation loss: 2.5540091832156917

Epoch: 5| Step: 9
Training loss: 1.9472920713474937
Validation loss: 2.5744664522124983

Epoch: 5| Step: 10
Training loss: 1.5431786503046176
Validation loss: 2.606889568956702

Epoch: 5| Step: 11
Training loss: 1.145049983353721
Validation loss: 2.6145176302999413

Epoch: 122| Step: 0
Training loss: 1.2240237063000843
Validation loss: 2.523049233153913

Epoch: 5| Step: 1
Training loss: 1.7679278454534666
Validation loss: 2.548124880378626

Epoch: 5| Step: 2
Training loss: 2.4581965607780227
Validation loss: 2.589096897582025

Epoch: 5| Step: 3
Training loss: 1.4724530552892061
Validation loss: 2.582295697126876

Epoch: 5| Step: 4
Training loss: 1.3509006092294653
Validation loss: 2.56208903033242

Epoch: 5| Step: 5
Training loss: 1.324669505233552
Validation loss: 2.5809458049199145

Epoch: 5| Step: 6
Training loss: 1.7450569368708697
Validation loss: 2.5620462841670677

Epoch: 5| Step: 7
Training loss: 1.0117942752411513
Validation loss: 2.5946447407153643

Epoch: 5| Step: 8
Training loss: 1.5203893440170226
Validation loss: 2.6031488387721007

Epoch: 5| Step: 9
Training loss: 2.0389833398412422
Validation loss: 2.6052387065456593

Epoch: 5| Step: 10
Training loss: 1.7054216491094571
Validation loss: 2.6074343258373527

Epoch: 5| Step: 11
Training loss: 1.7544533740653836
Validation loss: 2.5412175310646625

Epoch: 123| Step: 0
Training loss: 1.9658592436299658
Validation loss: 2.654134768339756

Epoch: 5| Step: 1
Training loss: 1.7764228866593996
Validation loss: 2.611272860284386

Epoch: 5| Step: 2
Training loss: 1.4393485249955482
Validation loss: 2.654113999018375

Epoch: 5| Step: 3
Training loss: 2.068647413216844
Validation loss: 2.7741104778051264

Epoch: 5| Step: 4
Training loss: 1.649980952413029
Validation loss: 2.7348214466210083

Epoch: 5| Step: 5
Training loss: 1.5904700243084988
Validation loss: 2.7049691078445726

Epoch: 5| Step: 6
Training loss: 1.385719132450038
Validation loss: 2.6965691295398906

Epoch: 5| Step: 7
Training loss: 1.556896997493162
Validation loss: 2.612927700393132

Epoch: 5| Step: 8
Training loss: 1.181482376977782
Validation loss: 2.623341748063755

Epoch: 5| Step: 9
Training loss: 1.4664419179002042
Validation loss: 2.6057077476469535

Epoch: 5| Step: 10
Training loss: 1.9620278659167691
Validation loss: 2.6270302308594755

Epoch: 5| Step: 11
Training loss: 0.7018078440862433
Validation loss: 2.6585815705917093

Epoch: 124| Step: 0
Training loss: 1.6841959219380922
Validation loss: 2.559272004517117

Epoch: 5| Step: 1
Training loss: 1.489741532610397
Validation loss: 2.5486405850495433

Epoch: 5| Step: 2
Training loss: 2.2095738171765715
Validation loss: 2.5802345584609014

Epoch: 5| Step: 3
Training loss: 1.6896915333726004
Validation loss: 2.6033554390356657

Epoch: 5| Step: 4
Training loss: 1.2715485024871234
Validation loss: 2.6092273571404627

Epoch: 5| Step: 5
Training loss: 1.4880764237077342
Validation loss: 2.6017122235139074

Epoch: 5| Step: 6
Training loss: 1.3979046621626794
Validation loss: 2.6461248399942674

Epoch: 5| Step: 7
Training loss: 2.0787954754652267
Validation loss: 2.553258221908026

Epoch: 5| Step: 8
Training loss: 1.4268807130449426
Validation loss: 2.6329509121426025

Epoch: 5| Step: 9
Training loss: 1.5162943512294413
Validation loss: 2.5492676571530697

Epoch: 5| Step: 10
Training loss: 1.0385851803422177
Validation loss: 2.635133031928848

Epoch: 5| Step: 11
Training loss: 1.3402908513425833
Validation loss: 2.665418415926722

Epoch: 125| Step: 0
Training loss: 0.9795522471733306
Validation loss: 2.7143233498017234

Epoch: 5| Step: 1
Training loss: 2.2557408949879516
Validation loss: 2.773665126002267

Epoch: 5| Step: 2
Training loss: 2.089270739565738
Validation loss: 2.7173471375759903

Epoch: 5| Step: 3
Training loss: 1.13607061726399
Validation loss: 2.687731049090804

Epoch: 5| Step: 4
Training loss: 2.082271712339384
Validation loss: 2.6273737082662496

Epoch: 5| Step: 5
Training loss: 1.587980335887355
Validation loss: 2.5958690547220176

Epoch: 5| Step: 6
Training loss: 1.3754851612384742
Validation loss: 2.6029104801550433

Epoch: 5| Step: 7
Training loss: 1.7527634055664627
Validation loss: 2.6067359812741167

Epoch: 5| Step: 8
Training loss: 1.5830667756552381
Validation loss: 2.6660432471776185

Epoch: 5| Step: 9
Training loss: 1.6511257001829283
Validation loss: 2.6093728071192133

Epoch: 5| Step: 10
Training loss: 1.1774298177646996
Validation loss: 2.5630667571431727

Epoch: 5| Step: 11
Training loss: 1.9941345274530307
Validation loss: 2.5707927050437998

Epoch: 126| Step: 0
Training loss: 1.7315936081533703
Validation loss: 2.5816787117401465

Epoch: 5| Step: 1
Training loss: 1.5704952911724144
Validation loss: 2.589324642148722

Epoch: 5| Step: 2
Training loss: 1.3509813062389608
Validation loss: 2.5999306418875747

Epoch: 5| Step: 3
Training loss: 1.7447643980106395
Validation loss: 2.642068671425604

Epoch: 5| Step: 4
Training loss: 2.251967100048788
Validation loss: 2.7189232855049514

Epoch: 5| Step: 5
Training loss: 1.5254840895461663
Validation loss: 2.6584178156766884

Epoch: 5| Step: 6
Training loss: 1.5241931312867776
Validation loss: 2.73712127829587

Epoch: 5| Step: 7
Training loss: 1.3135861943094451
Validation loss: 2.5490669655005678

Epoch: 5| Step: 8
Training loss: 1.6548748425413682
Validation loss: 2.6692296553746284

Epoch: 5| Step: 9
Training loss: 1.7971590563944841
Validation loss: 2.6288498621613883

Epoch: 5| Step: 10
Training loss: 1.8216132236027545
Validation loss: 2.625188237964433

Epoch: 5| Step: 11
Training loss: 1.73239820393214
Validation loss: 2.5789707337947845

Epoch: 127| Step: 0
Training loss: 1.2967564632062756
Validation loss: 2.533597038581369

Epoch: 5| Step: 1
Training loss: 1.4503420360593113
Validation loss: 2.6528735411226156

Epoch: 5| Step: 2
Training loss: 1.958354814560404
Validation loss: 2.679924588331565

Epoch: 5| Step: 3
Training loss: 1.8154714496440467
Validation loss: 2.595241259646497

Epoch: 5| Step: 4
Training loss: 1.6221997268559891
Validation loss: 2.5580657491836294

Epoch: 5| Step: 5
Training loss: 1.4540024436027637
Validation loss: 2.5484197218738918

Epoch: 5| Step: 6
Training loss: 2.2356515718906684
Validation loss: 2.601022746442902

Epoch: 5| Step: 7
Training loss: 1.4429905566027459
Validation loss: 2.644401915264566

Epoch: 5| Step: 8
Training loss: 1.3914727188161011
Validation loss: 2.6886743633734085

Epoch: 5| Step: 9
Training loss: 1.3913358521684682
Validation loss: 2.6669504466655516

Epoch: 5| Step: 10
Training loss: 1.4286267457197543
Validation loss: 2.6846528977834447

Epoch: 5| Step: 11
Training loss: 1.3660550904565867
Validation loss: 2.6492518370517804

Epoch: 128| Step: 0
Training loss: 1.5017654043683688
Validation loss: 2.6652106144495584

Epoch: 5| Step: 1
Training loss: 1.4846369462026834
Validation loss: 2.658476169679067

Epoch: 5| Step: 2
Training loss: 1.4570935110744467
Validation loss: 2.638156704104001

Epoch: 5| Step: 3
Training loss: 1.408333739256189
Validation loss: 2.6779114645865922

Epoch: 5| Step: 4
Training loss: 1.9445072330449207
Validation loss: 2.658143060824509

Epoch: 5| Step: 5
Training loss: 1.712822072169925
Validation loss: 2.5880621434599265

Epoch: 5| Step: 6
Training loss: 2.3866190538327805
Validation loss: 2.6127370734388533

Epoch: 5| Step: 7
Training loss: 1.125144684282765
Validation loss: 2.5856668228825392

Epoch: 5| Step: 8
Training loss: 1.7635103914297023
Validation loss: 2.584523643299653

Epoch: 5| Step: 9
Training loss: 1.125697714296006
Validation loss: 2.6050717548462745

Epoch: 5| Step: 10
Training loss: 1.2920035363907734
Validation loss: 2.6052385654599366

Epoch: 5| Step: 11
Training loss: 0.42750947517914784
Validation loss: 2.5870218068533215

Epoch: 129| Step: 0
Training loss: 1.6125111069407627
Validation loss: 2.6635545002003176

Epoch: 5| Step: 1
Training loss: 1.363654186753636
Validation loss: 2.600395039967296

Epoch: 5| Step: 2
Training loss: 1.1469021349615058
Validation loss: 2.5473583226993193

Epoch: 5| Step: 3
Training loss: 1.6903459075317617
Validation loss: 2.588989515854781

Epoch: 5| Step: 4
Training loss: 1.4210191603301021
Validation loss: 2.6926113617859797

Epoch: 5| Step: 5
Training loss: 1.5509554287121878
Validation loss: 2.6076494820034357

Epoch: 5| Step: 6
Training loss: 1.1921833443225511
Validation loss: 2.6213235579068597

Epoch: 5| Step: 7
Training loss: 1.4014385564089231
Validation loss: 2.643369001376001

Epoch: 5| Step: 8
Training loss: 1.2939801826816795
Validation loss: 2.5682541471519817

Epoch: 5| Step: 9
Training loss: 1.8554027666104804
Validation loss: 2.700733814038101

Epoch: 5| Step: 10
Training loss: 1.4276617321315377
Validation loss: 2.556524776809451

Epoch: 5| Step: 11
Training loss: 3.870207622587082
Validation loss: 2.611925346426015

Epoch: 130| Step: 0
Training loss: 1.7121822758549843
Validation loss: 2.705853461506045

Epoch: 5| Step: 1
Training loss: 1.5352719484172581
Validation loss: 2.6960912565361466

Epoch: 5| Step: 2
Training loss: 1.1005533343870457
Validation loss: 2.636933249708518

Epoch: 5| Step: 3
Training loss: 1.3416671579174462
Validation loss: 2.660789840015029

Epoch: 5| Step: 4
Training loss: 1.383270575735234
Validation loss: 2.6457485888769137

Epoch: 5| Step: 5
Training loss: 2.0266564881964286
Validation loss: 2.5692440158123118

Epoch: 5| Step: 6
Training loss: 1.3323628300960002
Validation loss: 2.636850349062096

Epoch: 5| Step: 7
Training loss: 1.3891038611726028
Validation loss: 2.624055260996608

Epoch: 5| Step: 8
Training loss: 1.6737325456320258
Validation loss: 2.6167775226808843

Epoch: 5| Step: 9
Training loss: 1.409599426738458
Validation loss: 2.625863296602559

Epoch: 5| Step: 10
Training loss: 1.8541521721891294
Validation loss: 2.6903360690925093

Epoch: 5| Step: 11
Training loss: 1.6174238096803353
Validation loss: 2.682418688139905

Epoch: 131| Step: 0
Training loss: 1.4386215810195688
Validation loss: 2.6401545314283164

Epoch: 5| Step: 1
Training loss: 1.5421317232475031
Validation loss: 2.7011836105242537

Epoch: 5| Step: 2
Training loss: 1.3934507484944039
Validation loss: 2.6928483396590797

Epoch: 5| Step: 3
Training loss: 1.1950001027893278
Validation loss: 2.6937231086102655

Epoch: 5| Step: 4
Training loss: 1.440778311228033
Validation loss: 2.6949409302458363

Epoch: 5| Step: 5
Training loss: 1.5118204718380432
Validation loss: 2.6928291859367484

Epoch: 5| Step: 6
Training loss: 1.600550932207587
Validation loss: 2.670206177129175

Epoch: 5| Step: 7
Training loss: 1.5353547179079647
Validation loss: 2.728823903571712

Epoch: 5| Step: 8
Training loss: 2.354124378285893
Validation loss: 2.570696097739538

Epoch: 5| Step: 9
Training loss: 1.405722752382509
Validation loss: 2.6556127269949372

Epoch: 5| Step: 10
Training loss: 1.3514723995804345
Validation loss: 2.5834214531317956

Epoch: 5| Step: 11
Training loss: 1.1570184576858664
Validation loss: 2.6167645468496574

Epoch: 132| Step: 0
Training loss: 1.5336632688042926
Validation loss: 2.542891431376252

Epoch: 5| Step: 1
Training loss: 1.4796154612937649
Validation loss: 2.629250714056437

Epoch: 5| Step: 2
Training loss: 1.3790288767982772
Validation loss: 2.5577193185544944

Epoch: 5| Step: 3
Training loss: 1.6907941666615496
Validation loss: 2.603222467277682

Epoch: 5| Step: 4
Training loss: 1.2433644123556604
Validation loss: 2.697439915032355

Epoch: 5| Step: 5
Training loss: 1.9295611629751432
Validation loss: 2.652800489304027

Epoch: 5| Step: 6
Training loss: 1.5108767981500784
Validation loss: 2.7262065403695637

Epoch: 5| Step: 7
Training loss: 1.486770784526874
Validation loss: 2.691015860227657

Epoch: 5| Step: 8
Training loss: 1.3154150969808398
Validation loss: 2.686368985198389

Epoch: 5| Step: 9
Training loss: 1.7608283725830527
Validation loss: 2.6823608624072874

Epoch: 5| Step: 10
Training loss: 1.7097274472717772
Validation loss: 2.658865232130159

Epoch: 5| Step: 11
Training loss: 1.224552621697522
Validation loss: 2.6043668224980503

Epoch: 133| Step: 0
Training loss: 1.2214901271644372
Validation loss: 2.6846865002895184

Epoch: 5| Step: 1
Training loss: 1.580915193960253
Validation loss: 2.56147722053985

Epoch: 5| Step: 2
Training loss: 1.1339790914414405
Validation loss: 2.6783082821423587

Epoch: 5| Step: 3
Training loss: 1.4995478902396115
Validation loss: 2.612943664550809

Epoch: 5| Step: 4
Training loss: 1.5456645352451244
Validation loss: 2.6121808839736933

Epoch: 5| Step: 5
Training loss: 2.0340540385161856
Validation loss: 2.5708836478426402

Epoch: 5| Step: 6
Training loss: 1.2555296184642086
Validation loss: 2.53485920737676

Epoch: 5| Step: 7
Training loss: 1.3927869814015077
Validation loss: 2.5803215495345064

Epoch: 5| Step: 8
Training loss: 1.383931714594915
Validation loss: 2.5916996400786

Epoch: 5| Step: 9
Training loss: 2.1942452113601396
Validation loss: 2.6651562284884203

Epoch: 5| Step: 10
Training loss: 1.3191711187297586
Validation loss: 2.597567422442774

Epoch: 5| Step: 11
Training loss: 1.3005207705952857
Validation loss: 2.750958225169718

Epoch: 134| Step: 0
Training loss: 1.7313794221943446
Validation loss: 2.5908233799768245

Epoch: 5| Step: 1
Training loss: 1.511720090564853
Validation loss: 2.549172895749593

Epoch: 5| Step: 2
Training loss: 1.2351221648115085
Validation loss: 2.6122964620015066

Epoch: 5| Step: 3
Training loss: 1.499528572387785
Validation loss: 2.6003431263419636

Epoch: 5| Step: 4
Training loss: 2.2117208973326075
Validation loss: 2.636689257044737

Epoch: 5| Step: 5
Training loss: 1.0502331520260166
Validation loss: 2.6443726019178624

Epoch: 5| Step: 6
Training loss: 1.3754718144426115
Validation loss: 2.611265236423732

Epoch: 5| Step: 7
Training loss: 1.7236529384226915
Validation loss: 2.658356612849971

Epoch: 5| Step: 8
Training loss: 1.277838654841689
Validation loss: 2.594806241597258

Epoch: 5| Step: 9
Training loss: 1.4466561335225614
Validation loss: 2.6312974859077087

Epoch: 5| Step: 10
Training loss: 1.206248155898824
Validation loss: 2.6725020091207177

Epoch: 5| Step: 11
Training loss: 0.36871391944233106
Validation loss: 2.6651317318928407

Epoch: 135| Step: 0
Training loss: 1.5542570505459363
Validation loss: 2.5976779028580443

Epoch: 5| Step: 1
Training loss: 1.6591112146286981
Validation loss: 2.692898447837941

Epoch: 5| Step: 2
Training loss: 1.0919869518478604
Validation loss: 2.6092164073269353

Epoch: 5| Step: 3
Training loss: 1.5001130856165683
Validation loss: 2.662774763869206

Epoch: 5| Step: 4
Training loss: 1.290951864309925
Validation loss: 2.6734555014757246

Epoch: 5| Step: 5
Training loss: 1.5986111126209344
Validation loss: 2.691272924227838

Epoch: 5| Step: 6
Training loss: 1.627926611940331
Validation loss: 2.6245876169984794

Epoch: 5| Step: 7
Training loss: 1.620304733743329
Validation loss: 2.664384265012275

Epoch: 5| Step: 8
Training loss: 1.9437443797530094
Validation loss: 2.612570756808853

Epoch: 5| Step: 9
Training loss: 1.201066175322689
Validation loss: 2.718349522293536

Epoch: 5| Step: 10
Training loss: 1.0619566594024823
Validation loss: 2.645806032074974

Epoch: 5| Step: 11
Training loss: 1.268934749437767
Validation loss: 2.717298672057815

Epoch: 136| Step: 0
Training loss: 2.304296221088757
Validation loss: 2.6367450288946532

Epoch: 5| Step: 1
Training loss: 1.5147000666168475
Validation loss: 2.6448149498396316

Epoch: 5| Step: 2
Training loss: 1.043528488775602
Validation loss: 2.6751692208869344

Epoch: 5| Step: 3
Training loss: 1.1791433127598898
Validation loss: 2.581003158503357

Epoch: 5| Step: 4
Training loss: 1.7751581524520685
Validation loss: 2.6462053065008755

Epoch: 5| Step: 5
Training loss: 0.9167790596868162
Validation loss: 2.6586600010759476

Epoch: 5| Step: 6
Training loss: 1.4297959750354807
Validation loss: 2.7229596903426923

Epoch: 5| Step: 7
Training loss: 1.7978780186088135
Validation loss: 2.677253641037545

Epoch: 5| Step: 8
Training loss: 1.1347756048869992
Validation loss: 2.5944278283293913

Epoch: 5| Step: 9
Training loss: 1.2721383892897902
Validation loss: 2.5505024950924753

Epoch: 5| Step: 10
Training loss: 1.3566240998900192
Validation loss: 2.6556180239578544

Epoch: 5| Step: 11
Training loss: 0.27500248333503285
Validation loss: 2.5862573654404253

Epoch: 137| Step: 0
Training loss: 1.576197287202206
Validation loss: 2.709192533409647

Epoch: 5| Step: 1
Training loss: 0.8489438662242194
Validation loss: 2.7031215675052906

Epoch: 5| Step: 2
Training loss: 1.2742840813892686
Validation loss: 2.6989200903419617

Epoch: 5| Step: 3
Training loss: 1.423515128438168
Validation loss: 2.66324309783044

Epoch: 5| Step: 4
Training loss: 1.3246252285664746
Validation loss: 2.688382561986358

Epoch: 5| Step: 5
Training loss: 1.133970733991542
Validation loss: 2.619958790074034

Epoch: 5| Step: 6
Training loss: 1.5909754219098855
Validation loss: 2.5243631363927035

Epoch: 5| Step: 7
Training loss: 1.429816651894668
Validation loss: 2.6629295886084394

Epoch: 5| Step: 8
Training loss: 2.0171010135515894
Validation loss: 2.6093026301537905

Epoch: 5| Step: 9
Training loss: 1.6822718411469262
Validation loss: 2.5654923908502694

Epoch: 5| Step: 10
Training loss: 1.5036389398191083
Validation loss: 2.6357008563420883

Epoch: 5| Step: 11
Training loss: 0.6228713263614423
Validation loss: 2.594304573183291

Epoch: 138| Step: 0
Training loss: 2.040214359390499
Validation loss: 2.6261136024081657

Epoch: 5| Step: 1
Training loss: 1.132482493772631
Validation loss: 2.653409344009329

Epoch: 5| Step: 2
Training loss: 1.6728764324488519
Validation loss: 2.6046405984049867

Epoch: 5| Step: 3
Training loss: 1.6921831069283422
Validation loss: 2.656017446622701

Epoch: 5| Step: 4
Training loss: 1.3108558347451766
Validation loss: 2.7082337996948698

Epoch: 5| Step: 5
Training loss: 1.0453955601649187
Validation loss: 2.6875294269754555

Epoch: 5| Step: 6
Training loss: 1.1000154060672083
Validation loss: 2.603229263708843

Epoch: 5| Step: 7
Training loss: 1.3809148839344707
Validation loss: 2.6331794286873738

Epoch: 5| Step: 8
Training loss: 1.2245990077405813
Validation loss: 2.6431231767172005

Epoch: 5| Step: 9
Training loss: 1.3891269887708977
Validation loss: 2.6423239951103663

Epoch: 5| Step: 10
Training loss: 1.9791594923458236
Validation loss: 2.633176736888547

Epoch: 5| Step: 11
Training loss: 0.514972505113277
Validation loss: 2.7163878955061884

Epoch: 139| Step: 0
Training loss: 1.3584768024495593
Validation loss: 2.644605875018859

Epoch: 5| Step: 1
Training loss: 1.466567020210146
Validation loss: 2.5667290835305003

Epoch: 5| Step: 2
Training loss: 2.00569343809131
Validation loss: 2.6234439521848043

Epoch: 5| Step: 3
Training loss: 1.20766607583839
Validation loss: 2.658926200949515

Epoch: 5| Step: 4
Training loss: 1.2613168554667948
Validation loss: 2.6321120646325067

Epoch: 5| Step: 5
Training loss: 1.6437274481673179
Validation loss: 2.6333854421658844

Epoch: 5| Step: 6
Training loss: 1.5931848758237277
Validation loss: 2.720446415438261

Epoch: 5| Step: 7
Training loss: 1.45570669230774
Validation loss: 2.7319934900903475

Epoch: 5| Step: 8
Training loss: 1.6827207634165142
Validation loss: 2.7314315157266718

Epoch: 5| Step: 9
Training loss: 1.4996632356900488
Validation loss: 2.677203173249575

Epoch: 5| Step: 10
Training loss: 0.9772783631087661
Validation loss: 2.5685716896634383

Epoch: 5| Step: 11
Training loss: 0.48256284376136366
Validation loss: 2.618726621294327

Epoch: 140| Step: 0
Training loss: 1.095685390934082
Validation loss: 2.628307533200021

Epoch: 5| Step: 1
Training loss: 1.7544277579783922
Validation loss: 2.6299838445563717

Epoch: 5| Step: 2
Training loss: 1.5201240697217488
Validation loss: 2.6628753836264005

Epoch: 5| Step: 3
Training loss: 1.019959575375608
Validation loss: 2.640860609118546

Epoch: 5| Step: 4
Training loss: 1.2604381569956036
Validation loss: 2.6100679341728084

Epoch: 5| Step: 5
Training loss: 1.8072257419255742
Validation loss: 2.6304681039070505

Epoch: 5| Step: 6
Training loss: 1.2777970002751018
Validation loss: 2.7124787565650523

Epoch: 5| Step: 7
Training loss: 1.3108876633747681
Validation loss: 2.6358271732694525

Epoch: 5| Step: 8
Training loss: 1.7996821493740596
Validation loss: 2.5984457436784645

Epoch: 5| Step: 9
Training loss: 1.3230947039293128
Validation loss: 2.670741143671354

Epoch: 5| Step: 10
Training loss: 1.112513119909525
Validation loss: 2.721195303312183

Epoch: 5| Step: 11
Training loss: 1.3269525177027515
Validation loss: 2.6087250766255123

Epoch: 141| Step: 0
Training loss: 1.2729423824195505
Validation loss: 2.5668320440502095

Epoch: 5| Step: 1
Training loss: 0.9279347414181396
Validation loss: 2.6773806801408346

Epoch: 5| Step: 2
Training loss: 1.6691010895199676
Validation loss: 2.6272378381969195

Epoch: 5| Step: 3
Training loss: 1.1150646180728843
Validation loss: 2.7076129242521043

Epoch: 5| Step: 4
Training loss: 0.9359851678545257
Validation loss: 2.5939569256674826

Epoch: 5| Step: 5
Training loss: 1.5667912112437756
Validation loss: 2.6202968403593396

Epoch: 5| Step: 6
Training loss: 1.4456129431974234
Validation loss: 2.6306755947613913

Epoch: 5| Step: 7
Training loss: 1.1017420737351684
Validation loss: 2.590271651187182

Epoch: 5| Step: 8
Training loss: 1.671726255841247
Validation loss: 2.572144181327773

Epoch: 5| Step: 9
Training loss: 2.0809405764115785
Validation loss: 2.6710130554191025

Epoch: 5| Step: 10
Training loss: 1.0220982182369185
Validation loss: 2.6219911095693744

Epoch: 5| Step: 11
Training loss: 0.682976711264319
Validation loss: 2.7088418385384614

Epoch: 142| Step: 0
Training loss: 1.6372820993126054
Validation loss: 2.5854247738334277

Epoch: 5| Step: 1
Training loss: 1.6056840664047074
Validation loss: 2.6684649310005244

Epoch: 5| Step: 2
Training loss: 1.2511552240869763
Validation loss: 2.595984400389099

Epoch: 5| Step: 3
Training loss: 1.0572252049094715
Validation loss: 2.660022607136028

Epoch: 5| Step: 4
Training loss: 1.1892103125874716
Validation loss: 2.697390436281377

Epoch: 5| Step: 5
Training loss: 1.1826014624006138
Validation loss: 2.6501534678447545

Epoch: 5| Step: 6
Training loss: 1.3136767153348745
Validation loss: 2.6503077517254288

Epoch: 5| Step: 7
Training loss: 1.03156206437789
Validation loss: 2.5984306003511835

Epoch: 5| Step: 8
Training loss: 1.4507326511342946
Validation loss: 2.6312595016899922

Epoch: 5| Step: 9
Training loss: 1.1671566899125747
Validation loss: 2.6268533548272166

Epoch: 5| Step: 10
Training loss: 1.2279188104375
Validation loss: 2.696178418811138

Epoch: 5| Step: 11
Training loss: 3.9664560732249075
Validation loss: 2.674676010678242

Epoch: 143| Step: 0
Training loss: 1.96860449116993
Validation loss: 2.634525160848346

Epoch: 5| Step: 1
Training loss: 1.2086690513070413
Validation loss: 2.658475975367148

Epoch: 5| Step: 2
Training loss: 1.3381077499738805
Validation loss: 2.6605276370422977

Epoch: 5| Step: 3
Training loss: 1.4588465287175332
Validation loss: 2.6529388509207963

Epoch: 5| Step: 4
Training loss: 0.8108012340330191
Validation loss: 2.6510237272863466

Epoch: 5| Step: 5
Training loss: 1.4917676245055969
Validation loss: 2.6039427406675757

Epoch: 5| Step: 6
Training loss: 1.4561612802092743
Validation loss: 2.700174687762646

Epoch: 5| Step: 7
Training loss: 1.1012710293895547
Validation loss: 2.6573052012060105

Epoch: 5| Step: 8
Training loss: 1.5713129604838578
Validation loss: 2.6284882854193126

Epoch: 5| Step: 9
Training loss: 1.1597707602469776
Validation loss: 2.677164207651945

Epoch: 5| Step: 10
Training loss: 1.2691341776873402
Validation loss: 2.5927774911814083

Epoch: 5| Step: 11
Training loss: 1.0724735023764274
Validation loss: 2.5746402192847344

Epoch: 144| Step: 0
Training loss: 0.9999613754442573
Validation loss: 2.5877598913027846

Epoch: 5| Step: 1
Training loss: 1.5669658165607108
Validation loss: 2.5933604599006714

Epoch: 5| Step: 2
Training loss: 0.9415939903627387
Validation loss: 2.5944875947625436

Epoch: 5| Step: 3
Training loss: 1.315035731986885
Validation loss: 2.665530683034713

Epoch: 5| Step: 4
Training loss: 1.1432827333777225
Validation loss: 2.6431371300118984

Epoch: 5| Step: 5
Training loss: 1.0870206083188354
Validation loss: 2.6374077544269428

Epoch: 5| Step: 6
Training loss: 1.9011639142031422
Validation loss: 2.6888897873042406

Epoch: 5| Step: 7
Training loss: 1.3883183669160921
Validation loss: 2.627317733703899

Epoch: 5| Step: 8
Training loss: 1.1558130830633242
Validation loss: 2.708590489185572

Epoch: 5| Step: 9
Training loss: 1.2704165145124922
Validation loss: 2.7206805050930374

Epoch: 5| Step: 10
Training loss: 1.4676474633284315
Validation loss: 2.598810701375381

Epoch: 5| Step: 11
Training loss: 1.491355304437372
Validation loss: 2.578554630124185

Epoch: 145| Step: 0
Training loss: 1.6273406850535979
Validation loss: 2.7270043169079994

Epoch: 5| Step: 1
Training loss: 1.1244878132805582
Validation loss: 2.6410892424591705

Epoch: 5| Step: 2
Training loss: 1.2940508414367202
Validation loss: 2.6244926605715495

Epoch: 5| Step: 3
Training loss: 1.1647586660953164
Validation loss: 2.721330689446085

Epoch: 5| Step: 4
Training loss: 1.705044286158348
Validation loss: 2.7063850156245675

Epoch: 5| Step: 5
Training loss: 1.0022134721493368
Validation loss: 2.7321147514325923

Epoch: 5| Step: 6
Training loss: 1.0646366626100254
Validation loss: 2.7365711584357517

Epoch: 5| Step: 7
Training loss: 1.5004860567324056
Validation loss: 2.663856364131073

Epoch: 5| Step: 8
Training loss: 0.9325553833619827
Validation loss: 2.7625798524561134

Epoch: 5| Step: 9
Training loss: 0.7889584009979544
Validation loss: 2.7544418932296075

Epoch: 5| Step: 10
Training loss: 2.1737935765238108
Validation loss: 2.7298810159863316

Epoch: 5| Step: 11
Training loss: 1.6749530871070388
Validation loss: 2.6407506939168033

Epoch: 146| Step: 0
Training loss: 1.2646746894144245
Validation loss: 2.6384995387996626

Epoch: 5| Step: 1
Training loss: 1.2103531935174383
Validation loss: 2.6590714560458886

Epoch: 5| Step: 2
Training loss: 0.9241444729570008
Validation loss: 2.695624833738276

Epoch: 5| Step: 3
Training loss: 1.1912434451071974
Validation loss: 2.661403783598759

Epoch: 5| Step: 4
Training loss: 1.110651812726175
Validation loss: 2.7045593315093432

Epoch: 5| Step: 5
Training loss: 1.6211767703939222
Validation loss: 2.5938820594658565

Epoch: 5| Step: 6
Training loss: 1.3600730857424892
Validation loss: 2.6285063773427306

Epoch: 5| Step: 7
Training loss: 1.2783045523701422
Validation loss: 2.5786412348379115

Epoch: 5| Step: 8
Training loss: 1.9993097186960762
Validation loss: 2.5918356330309775

Epoch: 5| Step: 9
Training loss: 1.0336042753968229
Validation loss: 2.6804032440319903

Epoch: 5| Step: 10
Training loss: 1.187310655456193
Validation loss: 2.7591756706202255

Epoch: 5| Step: 11
Training loss: 1.641839150341245
Validation loss: 2.7056276536733037

Epoch: 147| Step: 0
Training loss: 1.2567436462994503
Validation loss: 2.764014980553893

Epoch: 5| Step: 1
Training loss: 1.44665984166787
Validation loss: 2.794226431279044

Epoch: 5| Step: 2
Training loss: 1.0466157962399405
Validation loss: 2.749334836479893

Epoch: 5| Step: 3
Training loss: 1.629519047722069
Validation loss: 2.578933619835766

Epoch: 5| Step: 4
Training loss: 0.9458352842324816
Validation loss: 2.6379198517572022

Epoch: 5| Step: 5
Training loss: 1.3789736809601414
Validation loss: 2.607110638086566

Epoch: 5| Step: 6
Training loss: 1.3723186444671696
Validation loss: 2.591978099843066

Epoch: 5| Step: 7
Training loss: 1.4499610994316752
Validation loss: 2.669968854615961

Epoch: 5| Step: 8
Training loss: 1.2963538903858978
Validation loss: 2.688771704747694

Epoch: 5| Step: 9
Training loss: 1.1565277693861868
Validation loss: 2.647743970750349

Epoch: 5| Step: 10
Training loss: 1.32409644898393
Validation loss: 2.5867068288227504

Epoch: 5| Step: 11
Training loss: 3.8632210166563286
Validation loss: 2.5760799967105465

Epoch: 148| Step: 0
Training loss: 0.9436563849597022
Validation loss: 2.639875407168822

Epoch: 5| Step: 1
Training loss: 1.4515638271362676
Validation loss: 2.798003539107009

Epoch: 5| Step: 2
Training loss: 1.3627847461459213
Validation loss: 2.703607938693569

Epoch: 5| Step: 3
Training loss: 1.5558698749116107
Validation loss: 2.7513399472078186

Epoch: 5| Step: 4
Training loss: 1.4391108899259355
Validation loss: 2.696893882317006

Epoch: 5| Step: 5
Training loss: 1.3756972192493133
Validation loss: 2.622272171594987

Epoch: 5| Step: 6
Training loss: 1.4475385689085398
Validation loss: 2.620485188710489

Epoch: 5| Step: 7
Training loss: 1.3923669256319873
Validation loss: 2.7165381909241644

Epoch: 5| Step: 8
Training loss: 1.1260325144143803
Validation loss: 2.5909322845537774

Epoch: 5| Step: 9
Training loss: 1.9064651117741729
Validation loss: 2.6030880538070953

Epoch: 5| Step: 10
Training loss: 1.4294171520668144
Validation loss: 2.5390550270948724

Epoch: 5| Step: 11
Training loss: 0.49118504541310193
Validation loss: 2.5921842567771534

Epoch: 149| Step: 0
Training loss: 0.8864479491674917
Validation loss: 2.6792993329267643

Epoch: 5| Step: 1
Training loss: 0.7865273569566872
Validation loss: 2.6132179598516605

Epoch: 5| Step: 2
Training loss: 1.2853212569495163
Validation loss: 2.5859470367255786

Epoch: 5| Step: 3
Training loss: 1.4945914193069267
Validation loss: 2.621662155957069

Epoch: 5| Step: 4
Training loss: 1.500304509089777
Validation loss: 2.6463087147953317

Epoch: 5| Step: 5
Training loss: 1.206375042457726
Validation loss: 2.6359695839639365

Epoch: 5| Step: 6
Training loss: 1.06067062414675
Validation loss: 2.635327546242487

Epoch: 5| Step: 7
Training loss: 1.204872447658906
Validation loss: 2.6309315181394877

Epoch: 5| Step: 8
Training loss: 1.0679027411398458
Validation loss: 2.7589590626779286

Epoch: 5| Step: 9
Training loss: 0.9879157555258314
Validation loss: 2.636098661623348

Epoch: 5| Step: 10
Training loss: 2.09595168773649
Validation loss: 2.6333094277886273

Epoch: 5| Step: 11
Training loss: 1.4536455924146565
Validation loss: 2.607072316715944

Epoch: 150| Step: 0
Training loss: 1.2793087092427347
Validation loss: 2.566439120828742

Epoch: 5| Step: 1
Training loss: 0.9027714892111308
Validation loss: 2.6555371954935847

Epoch: 5| Step: 2
Training loss: 1.1604037550659332
Validation loss: 2.6434901868102796

Epoch: 5| Step: 3
Training loss: 1.560225395156548
Validation loss: 2.6526248129393144

Epoch: 5| Step: 4
Training loss: 1.3045127888729215
Validation loss: 2.6298201220973296

Epoch: 5| Step: 5
Training loss: 0.8918669223219112
Validation loss: 2.605478785246244

Epoch: 5| Step: 6
Training loss: 2.050896690389269
Validation loss: 2.5915008122853016

Epoch: 5| Step: 7
Training loss: 1.2823610838077262
Validation loss: 2.664106832901694

Epoch: 5| Step: 8
Training loss: 0.7794961316059819
Validation loss: 2.6256355394277335

Epoch: 5| Step: 9
Training loss: 1.0674956629394765
Validation loss: 2.694145569223649

Epoch: 5| Step: 10
Training loss: 1.282802385669009
Validation loss: 2.615469521474684

Epoch: 5| Step: 11
Training loss: 1.5257485100534018
Validation loss: 2.6680613511465117

Epoch: 151| Step: 0
Training loss: 1.1313249489419792
Validation loss: 2.6745532297034016

Epoch: 5| Step: 1
Training loss: 1.1220026352727341
Validation loss: 2.598022630137054

Epoch: 5| Step: 2
Training loss: 0.9691460630424976
Validation loss: 2.563960248577006

Epoch: 5| Step: 3
Training loss: 1.0750037082342019
Validation loss: 2.6361708121165757

Epoch: 5| Step: 4
Training loss: 1.4988228629554001
Validation loss: 2.670753064985194

Epoch: 5| Step: 5
Training loss: 1.9704458410897385
Validation loss: 2.608888816844552

Epoch: 5| Step: 6
Training loss: 1.0157652537998267
Validation loss: 2.608505606725896

Epoch: 5| Step: 7
Training loss: 1.5413873608490836
Validation loss: 2.6104537538561328

Epoch: 5| Step: 8
Training loss: 0.7590468667102047
Validation loss: 2.5386342709670515

Epoch: 5| Step: 9
Training loss: 1.3035713492540906
Validation loss: 2.6285039623219264

Epoch: 5| Step: 10
Training loss: 1.3878979035048953
Validation loss: 2.6748783119545174

Epoch: 5| Step: 11
Training loss: 1.154742934118449
Validation loss: 2.615313455887873

Epoch: 152| Step: 0
Training loss: 1.8241776455612286
Validation loss: 2.699408480816457

Epoch: 5| Step: 1
Training loss: 1.4878529009815138
Validation loss: 2.6530074654804956

Epoch: 5| Step: 2
Training loss: 1.018454030111421
Validation loss: 2.525969472161529

Epoch: 5| Step: 3
Training loss: 0.9754689311599135
Validation loss: 2.64552588941881

Epoch: 5| Step: 4
Training loss: 1.115524067306616
Validation loss: 2.5724575518561994

Epoch: 5| Step: 5
Training loss: 0.797681960869375
Validation loss: 2.5340759687324113

Epoch: 5| Step: 6
Training loss: 0.9542046669857285
Validation loss: 2.6133606256690665

Epoch: 5| Step: 7
Training loss: 1.1361132185454488
Validation loss: 2.673009434549807

Epoch: 5| Step: 8
Training loss: 1.3713898950257626
Validation loss: 2.647201302092024

Epoch: 5| Step: 9
Training loss: 1.4534424465819495
Validation loss: 2.571405504958324

Epoch: 5| Step: 10
Training loss: 1.1762627917738384
Validation loss: 2.6626895002825255

Epoch: 5| Step: 11
Training loss: 0.7552166949280618
Validation loss: 2.558990269188655

Epoch: 153| Step: 0
Training loss: 1.1151583724170748
Validation loss: 2.643808263222354

Epoch: 5| Step: 1
Training loss: 1.1134416966515788
Validation loss: 2.71729327597923

Epoch: 5| Step: 2
Training loss: 1.8873645001210388
Validation loss: 2.5955575328570157

Epoch: 5| Step: 3
Training loss: 1.11066560489616
Validation loss: 2.6109911506965036

Epoch: 5| Step: 4
Training loss: 0.9694646844751902
Validation loss: 2.612675694059308

Epoch: 5| Step: 5
Training loss: 1.018963593634676
Validation loss: 2.6074121215485495

Epoch: 5| Step: 6
Training loss: 1.305252501077088
Validation loss: 2.6809722445302313

Epoch: 5| Step: 7
Training loss: 1.3652505287011518
Validation loss: 2.6805381240398733

Epoch: 5| Step: 8
Training loss: 1.0642381363490412
Validation loss: 2.640898150550098

Epoch: 5| Step: 9
Training loss: 0.9966041603603257
Validation loss: 2.708841581828178

Epoch: 5| Step: 10
Training loss: 1.6590129191451473
Validation loss: 2.683351242013566

Epoch: 5| Step: 11
Training loss: 0.7268774928987483
Validation loss: 2.666818772140356

Epoch: 154| Step: 0
Training loss: 1.182225610621416
Validation loss: 2.6680300860524464

Epoch: 5| Step: 1
Training loss: 0.9834269848101688
Validation loss: 2.6724723348978796

Epoch: 5| Step: 2
Training loss: 1.2620644110672383
Validation loss: 2.620620764454413

Epoch: 5| Step: 3
Training loss: 1.315449352726289
Validation loss: 2.6531032997205437

Epoch: 5| Step: 4
Training loss: 0.8596504116898048
Validation loss: 2.6906326983522995

Epoch: 5| Step: 5
Training loss: 1.288099125468524
Validation loss: 2.673786944157441

Epoch: 5| Step: 6
Training loss: 0.9821107041681703
Validation loss: 2.685544884883259

Epoch: 5| Step: 7
Training loss: 0.9509830483250472
Validation loss: 2.5114495453007684

Epoch: 5| Step: 8
Training loss: 1.0086081860585476
Validation loss: 2.635899881434795

Epoch: 5| Step: 9
Training loss: 1.947290969423519
Validation loss: 2.6137124443791953

Epoch: 5| Step: 10
Training loss: 1.2389993119934488
Validation loss: 2.6665129853211442

Epoch: 5| Step: 11
Training loss: 1.254233724548207
Validation loss: 2.6428394437470972

Epoch: 155| Step: 0
Training loss: 1.0145291798974554
Validation loss: 2.6242713030328133

Epoch: 5| Step: 1
Training loss: 1.0285392738228427
Validation loss: 2.6210386570817517

Epoch: 5| Step: 2
Training loss: 1.4965052424733172
Validation loss: 2.6000176846379612

Epoch: 5| Step: 3
Training loss: 1.1807238845247103
Validation loss: 2.6494235975855784

Epoch: 5| Step: 4
Training loss: 1.2324376415084495
Validation loss: 2.644055829496798

Epoch: 5| Step: 5
Training loss: 1.859634894151182
Validation loss: 2.5977298793061845

Epoch: 5| Step: 6
Training loss: 1.298283467067653
Validation loss: 2.7291632475115684

Epoch: 5| Step: 7
Training loss: 0.813622872520217
Validation loss: 2.6914747734186824

Epoch: 5| Step: 8
Training loss: 1.0733639176870444
Validation loss: 2.6597522722001434

Epoch: 5| Step: 9
Training loss: 1.2463800466135173
Validation loss: 2.7186890701248134

Epoch: 5| Step: 10
Training loss: 0.9336586135613199
Validation loss: 2.650125380165086

Epoch: 5| Step: 11
Training loss: 0.825843547394759
Validation loss: 2.679287253128633

Epoch: 156| Step: 0
Training loss: 1.0373103922200622
Validation loss: 2.6420821997746318

Epoch: 5| Step: 1
Training loss: 1.5592539830159247
Validation loss: 2.6615415673326495

Epoch: 5| Step: 2
Training loss: 1.010403518329031
Validation loss: 2.5775579349063653

Epoch: 5| Step: 3
Training loss: 1.1925692025983838
Validation loss: 2.6150044897386167

Epoch: 5| Step: 4
Training loss: 1.0694557157695912
Validation loss: 2.6465322004550598

Epoch: 5| Step: 5
Training loss: 0.7853540958875026
Validation loss: 2.6489272888460573

Epoch: 5| Step: 6
Training loss: 1.1244523516813785
Validation loss: 2.6765352843460337

Epoch: 5| Step: 7
Training loss: 0.9037099626781976
Validation loss: 2.628460283698838

Epoch: 5| Step: 8
Training loss: 1.0652866844480202
Validation loss: 2.637992426928625

Epoch: 5| Step: 9
Training loss: 1.9918101233793435
Validation loss: 2.656400201328113

Epoch: 5| Step: 10
Training loss: 0.9002175319889966
Validation loss: 2.686126439297254

Epoch: 5| Step: 11
Training loss: 1.0996334960893746
Validation loss: 2.6323068814327923

Epoch: 157| Step: 0
Training loss: 1.1255453695188014
Validation loss: 2.680611553963336

Epoch: 5| Step: 1
Training loss: 1.3812853467742487
Validation loss: 2.699159134805913

Epoch: 5| Step: 2
Training loss: 1.1264149985924172
Validation loss: 2.739041384818494

Epoch: 5| Step: 3
Training loss: 1.026483850354874
Validation loss: 2.748615808795086

Epoch: 5| Step: 4
Training loss: 0.7699116575046001
Validation loss: 2.623982474496319

Epoch: 5| Step: 5
Training loss: 1.1786351341518257
Validation loss: 2.65756772024416

Epoch: 5| Step: 6
Training loss: 1.3090145516282512
Validation loss: 2.6786411974918294

Epoch: 5| Step: 7
Training loss: 1.783508074152631
Validation loss: 2.659515845263099

Epoch: 5| Step: 8
Training loss: 0.8779723907031332
Validation loss: 2.65208133004216

Epoch: 5| Step: 9
Training loss: 1.245378055546171
Validation loss: 2.52694965574009

Epoch: 5| Step: 10
Training loss: 1.166052685121502
Validation loss: 2.6085598370942096

Epoch: 5| Step: 11
Training loss: 1.2464048182706535
Validation loss: 2.714274171500532

Epoch: 158| Step: 0
Training loss: 1.1746333909822457
Validation loss: 2.6524064923198494

Epoch: 5| Step: 1
Training loss: 1.21907713974428
Validation loss: 2.4985601888484457

Epoch: 5| Step: 2
Training loss: 1.2758377015985665
Validation loss: 2.6976269464551916

Epoch: 5| Step: 3
Training loss: 0.8926244010031175
Validation loss: 2.615782433636727

Epoch: 5| Step: 4
Training loss: 0.7079924062170776
Validation loss: 2.654333986870146

Epoch: 5| Step: 5
Training loss: 1.137933089003806
Validation loss: 2.6657494566985225

Epoch: 5| Step: 6
Training loss: 1.2497706679733487
Validation loss: 2.5555619775880296

Epoch: 5| Step: 7
Training loss: 1.292293452908855
Validation loss: 2.5799875217020163

Epoch: 5| Step: 8
Training loss: 1.1953348394562793
Validation loss: 2.658896197747453

Epoch: 5| Step: 9
Training loss: 1.9244108140616614
Validation loss: 2.6200347330069755

Epoch: 5| Step: 10
Training loss: 1.1767616113625143
Validation loss: 2.5993142862116985

Epoch: 5| Step: 11
Training loss: 1.0804430050378941
Validation loss: 2.649349711961071

Epoch: 159| Step: 0
Training loss: 1.1272998719324199
Validation loss: 2.7488226754580527

Epoch: 5| Step: 1
Training loss: 1.3603782021350674
Validation loss: 2.657982295026863

Epoch: 5| Step: 2
Training loss: 1.0408934330037054
Validation loss: 2.58400038341543

Epoch: 5| Step: 3
Training loss: 0.8779785006895298
Validation loss: 2.5730180501590136

Epoch: 5| Step: 4
Training loss: 0.9464832338963084
Validation loss: 2.6585800198942073

Epoch: 5| Step: 5
Training loss: 0.9048062696221981
Validation loss: 2.6038466880037685

Epoch: 5| Step: 6
Training loss: 1.7195289927237711
Validation loss: 2.768680185280244

Epoch: 5| Step: 7
Training loss: 1.0470382790841182
Validation loss: 2.6153557359656636

Epoch: 5| Step: 8
Training loss: 1.1077988401789465
Validation loss: 2.670404825387185

Epoch: 5| Step: 9
Training loss: 1.324403913037399
Validation loss: 2.595524357174062

Epoch: 5| Step: 10
Training loss: 1.0771281844834977
Validation loss: 2.6701688468541174

Epoch: 5| Step: 11
Training loss: 2.222977278174153
Validation loss: 2.664641465623438

Epoch: 160| Step: 0
Training loss: 0.8906376151814386
Validation loss: 2.6440242166696626

Epoch: 5| Step: 1
Training loss: 1.3893130253514483
Validation loss: 2.6967623879034486

Epoch: 5| Step: 2
Training loss: 1.7522886161277245
Validation loss: 2.717355882261749

Epoch: 5| Step: 3
Training loss: 1.2124764784271636
Validation loss: 2.7337908057173457

Epoch: 5| Step: 4
Training loss: 1.2749192212264944
Validation loss: 2.6993836510317895

Epoch: 5| Step: 5
Training loss: 2.0904438618875583
Validation loss: 2.740068687601304

Epoch: 5| Step: 6
Training loss: 1.077527143043583
Validation loss: 2.7487356393244373

Epoch: 5| Step: 7
Training loss: 1.3980363664767728
Validation loss: 2.8771086886202766

Epoch: 5| Step: 8
Training loss: 1.5086620092136056
Validation loss: 2.97449129654652

Epoch: 5| Step: 9
Training loss: 1.6969841656775058
Validation loss: 3.0114372144917647

Epoch: 5| Step: 10
Training loss: 1.0570486694614825
Validation loss: 2.850357257330037

Epoch: 5| Step: 11
Training loss: 0.5502730114625728
Validation loss: 2.7488535998534878

Epoch: 161| Step: 0
Training loss: 1.365953422528638
Validation loss: 2.7274351645390995

Epoch: 5| Step: 1
Training loss: 1.459792315591514
Validation loss: 2.6566650029033236

Epoch: 5| Step: 2
Training loss: 1.1057267174474275
Validation loss: 2.7372973130437885

Epoch: 5| Step: 3
Training loss: 1.4007925736266944
Validation loss: 2.8615931712569616

Epoch: 5| Step: 4
Training loss: 0.8404311853635269
Validation loss: 2.74406440239841

Epoch: 5| Step: 5
Training loss: 2.209515872764505
Validation loss: 2.6879264877566467

Epoch: 5| Step: 6
Training loss: 0.858006896902699
Validation loss: 2.5898290607847088

Epoch: 5| Step: 7
Training loss: 0.9642865197365036
Validation loss: 2.7395214151170992

Epoch: 5| Step: 8
Training loss: 1.0348215965723189
Validation loss: 2.6949776593522636

Epoch: 5| Step: 9
Training loss: 1.382000528514888
Validation loss: 2.8209243596790303

Epoch: 5| Step: 10
Training loss: 1.4086874712222985
Validation loss: 2.7722336068001376

Epoch: 5| Step: 11
Training loss: 0.8531692116149138
Validation loss: 2.8075873243429923

Epoch: 162| Step: 0
Training loss: 0.9756393647098636
Validation loss: 2.6711846290697374

Epoch: 5| Step: 1
Training loss: 0.7970855659085354
Validation loss: 2.658370245156084

Epoch: 5| Step: 2
Training loss: 0.9573751337788686
Validation loss: 2.693715423072944

Epoch: 5| Step: 3
Training loss: 0.7828044304650705
Validation loss: 2.7160642409878193

Epoch: 5| Step: 4
Training loss: 1.1597440353342139
Validation loss: 2.6277059202022586

Epoch: 5| Step: 5
Training loss: 0.9761739033971429
Validation loss: 2.617703575760424

Epoch: 5| Step: 6
Training loss: 1.1989813454698401
Validation loss: 2.6430433737315453

Epoch: 5| Step: 7
Training loss: 1.3592389795061108
Validation loss: 2.643685254866587

Epoch: 5| Step: 8
Training loss: 1.8022791658693402
Validation loss: 2.65976160962052

Epoch: 5| Step: 9
Training loss: 1.2724868877162507
Validation loss: 2.6990195171842006

Epoch: 5| Step: 10
Training loss: 1.0198170929889663
Validation loss: 2.637155356345563

Epoch: 5| Step: 11
Training loss: 1.0096623203699973
Validation loss: 2.7443900704279556

Epoch: 163| Step: 0
Training loss: 1.3545017805908035
Validation loss: 2.7377748841995304

Epoch: 5| Step: 1
Training loss: 1.2834562983783697
Validation loss: 2.7792158760640286

Epoch: 5| Step: 2
Training loss: 1.3237389339456365
Validation loss: 2.685950390642592

Epoch: 5| Step: 3
Training loss: 1.3730414486773777
Validation loss: 2.747699309788894

Epoch: 5| Step: 4
Training loss: 0.9121199940098028
Validation loss: 2.677964849591065

Epoch: 5| Step: 5
Training loss: 0.8694681300639662
Validation loss: 2.5956711414319487

Epoch: 5| Step: 6
Training loss: 2.0280015058493057
Validation loss: 2.6936194073264086

Epoch: 5| Step: 7
Training loss: 1.0907862153354881
Validation loss: 2.6752110971361716

Epoch: 5| Step: 8
Training loss: 0.7493932972154461
Validation loss: 2.635446534471298

Epoch: 5| Step: 9
Training loss: 1.0397875557840313
Validation loss: 2.6742128328106896

Epoch: 5| Step: 10
Training loss: 0.8768968457894677
Validation loss: 2.642052702771061

Epoch: 5| Step: 11
Training loss: 0.9382741275107281
Validation loss: 2.673317101786829

Epoch: 164| Step: 0
Training loss: 0.8533841518516507
Validation loss: 2.692542295421847

Epoch: 5| Step: 1
Training loss: 1.3674106960671142
Validation loss: 2.6745771051518474

Epoch: 5| Step: 2
Training loss: 1.7244668385410555
Validation loss: 2.735957245580274

Epoch: 5| Step: 3
Training loss: 1.1347408324798103
Validation loss: 2.7499119751742818

Epoch: 5| Step: 4
Training loss: 1.1890453522858078
Validation loss: 2.6688718147081945

Epoch: 5| Step: 5
Training loss: 0.8698060649357764
Validation loss: 2.6644273025267324

Epoch: 5| Step: 6
Training loss: 0.8523678252598869
Validation loss: 2.7170748098826953

Epoch: 5| Step: 7
Training loss: 0.9826718992448086
Validation loss: 2.690986550747587

Epoch: 5| Step: 8
Training loss: 1.4065786613412228
Validation loss: 2.741412641087139

Epoch: 5| Step: 9
Training loss: 1.1094776697064848
Validation loss: 2.6910989047895937

Epoch: 5| Step: 10
Training loss: 1.1602062895287566
Validation loss: 2.647369765931904

Epoch: 5| Step: 11
Training loss: 1.11907868272148
Validation loss: 2.6727902107226678

Epoch: 165| Step: 0
Training loss: 1.6683908683289164
Validation loss: 2.629854402555103

Epoch: 5| Step: 1
Training loss: 0.7563307127954112
Validation loss: 2.717754728102312

Epoch: 5| Step: 2
Training loss: 1.3437688959256904
Validation loss: 2.6505580091177463

Epoch: 5| Step: 3
Training loss: 1.0980158315291986
Validation loss: 2.6936389316044727

Epoch: 5| Step: 4
Training loss: 1.1078006157284686
Validation loss: 2.792522777173057

Epoch: 5| Step: 5
Training loss: 0.92955557905001
Validation loss: 2.7259986243362295

Epoch: 5| Step: 6
Training loss: 0.9513932740016839
Validation loss: 2.71169522530871

Epoch: 5| Step: 7
Training loss: 1.2710488975597252
Validation loss: 2.714680391881036

Epoch: 5| Step: 8
Training loss: 1.0881200579290546
Validation loss: 2.6976292038486145

Epoch: 5| Step: 9
Training loss: 1.0518321628200364
Validation loss: 2.712553684008087

Epoch: 5| Step: 10
Training loss: 1.1610855850098964
Validation loss: 2.65287518502752

Epoch: 5| Step: 11
Training loss: 0.9942292958943808
Validation loss: 2.717145172105333

Epoch: 166| Step: 0
Training loss: 1.3407747020590441
Validation loss: 2.640513893664189

Epoch: 5| Step: 1
Training loss: 1.0801428004624523
Validation loss: 2.720833495248631

Epoch: 5| Step: 2
Training loss: 1.1486393757583808
Validation loss: 2.6951492075821

Epoch: 5| Step: 3
Training loss: 0.6666863830948998
Validation loss: 2.643640447981579

Epoch: 5| Step: 4
Training loss: 1.6866980872538442
Validation loss: 2.686002968638804

Epoch: 5| Step: 5
Training loss: 1.279514905681002
Validation loss: 2.5886921765316306

Epoch: 5| Step: 6
Training loss: 0.9207638979030456
Validation loss: 2.7019524759995255

Epoch: 5| Step: 7
Training loss: 1.2717103537575154
Validation loss: 2.672166046293194

Epoch: 5| Step: 8
Training loss: 0.9529124163583015
Validation loss: 2.6472677462642826

Epoch: 5| Step: 9
Training loss: 1.2586404669797562
Validation loss: 2.7570552200452907

Epoch: 5| Step: 10
Training loss: 1.1412014484419055
Validation loss: 2.595311667549173

Epoch: 5| Step: 11
Training loss: 0.9651171648221054
Validation loss: 2.7244957721320597

Epoch: 167| Step: 0
Training loss: 1.273002175655139
Validation loss: 2.5991732496386355

Epoch: 5| Step: 1
Training loss: 0.7799494790564137
Validation loss: 2.6320738355211506

Epoch: 5| Step: 2
Training loss: 1.5392689832638526
Validation loss: 2.6847379596716223

Epoch: 5| Step: 3
Training loss: 1.8290999331571427
Validation loss: 2.581857010757076

Epoch: 5| Step: 4
Training loss: 0.8302688917970202
Validation loss: 2.7239698710054405

Epoch: 5| Step: 5
Training loss: 0.8876072805333852
Validation loss: 2.610354614636594

Epoch: 5| Step: 6
Training loss: 0.8809769714757758
Validation loss: 2.735983057839193

Epoch: 5| Step: 7
Training loss: 0.7127366827313069
Validation loss: 2.666184060687807

Epoch: 5| Step: 8
Training loss: 1.2560877851830254
Validation loss: 2.6662267505855963

Epoch: 5| Step: 9
Training loss: 0.9523321512468866
Validation loss: 2.704819605624099

Epoch: 5| Step: 10
Training loss: 0.9870766094220826
Validation loss: 2.5844731482519685

Epoch: 5| Step: 11
Training loss: 1.449838346480915
Validation loss: 2.6251991362953384

Epoch: 168| Step: 0
Training loss: 1.6596440501227696
Validation loss: 2.6884846620799108

Epoch: 5| Step: 1
Training loss: 1.2100149762984407
Validation loss: 2.6196547081237487

Epoch: 5| Step: 2
Training loss: 1.1083746684882598
Validation loss: 2.61162628396596

Epoch: 5| Step: 3
Training loss: 1.1838824735189497
Validation loss: 2.6103427048140544

Epoch: 5| Step: 4
Training loss: 1.0650111984058184
Validation loss: 2.6081274518567406

Epoch: 5| Step: 5
Training loss: 0.8048355558908056
Validation loss: 2.7586939360385654

Epoch: 5| Step: 6
Training loss: 1.2350503064152998
Validation loss: 2.7200691925041527

Epoch: 5| Step: 7
Training loss: 1.027572838366458
Validation loss: 2.712036543980871

Epoch: 5| Step: 8
Training loss: 0.8913635738497986
Validation loss: 2.7036829062144117

Epoch: 5| Step: 9
Training loss: 1.2820109457003983
Validation loss: 2.831871038706477

Epoch: 5| Step: 10
Training loss: 0.8341525263418277
Validation loss: 2.743097214174554

Epoch: 5| Step: 11
Training loss: 0.4643206498081273
Validation loss: 2.718284473902968

Epoch: 169| Step: 0
Training loss: 0.6639826782721948
Validation loss: 2.7086652857969957

Epoch: 5| Step: 1
Training loss: 0.9835187730398666
Validation loss: 2.6910463451445144

Epoch: 5| Step: 2
Training loss: 1.1428715255802984
Validation loss: 2.762766627135937

Epoch: 5| Step: 3
Training loss: 1.8944014986576776
Validation loss: 2.741009074099956

Epoch: 5| Step: 4
Training loss: 0.8980361041816511
Validation loss: 2.664312185032765

Epoch: 5| Step: 5
Training loss: 0.9686864093705709
Validation loss: 2.5890065062996004

Epoch: 5| Step: 6
Training loss: 0.9514962647786195
Validation loss: 2.673949757854371

Epoch: 5| Step: 7
Training loss: 0.820210259741886
Validation loss: 2.7273976323124813

Epoch: 5| Step: 8
Training loss: 1.194754476503334
Validation loss: 2.6504140434458052

Epoch: 5| Step: 9
Training loss: 1.224658241087937
Validation loss: 2.6525138122541736

Epoch: 5| Step: 10
Training loss: 0.9497782937896472
Validation loss: 2.7359155947049594

Epoch: 5| Step: 11
Training loss: 0.8671167018273911
Validation loss: 2.7419378958598886

Epoch: 170| Step: 0
Training loss: 1.1643293958037297
Validation loss: 2.727496683929903

Epoch: 5| Step: 1
Training loss: 0.6861838834559384
Validation loss: 2.654480595390639

Epoch: 5| Step: 2
Training loss: 1.1181701393462056
Validation loss: 2.594341628073598

Epoch: 5| Step: 3
Training loss: 1.239537753808556
Validation loss: 2.6052228171947416

Epoch: 5| Step: 4
Training loss: 1.9185865226961778
Validation loss: 2.6707629218815656

Epoch: 5| Step: 5
Training loss: 0.932130408947764
Validation loss: 2.626151180644454

Epoch: 5| Step: 6
Training loss: 0.8133661715009471
Validation loss: 2.621137589278957

Epoch: 5| Step: 7
Training loss: 0.9119397808279374
Validation loss: 2.7010563209441183

Epoch: 5| Step: 8
Training loss: 0.8462750481035667
Validation loss: 2.590610676362704

Epoch: 5| Step: 9
Training loss: 1.0505526836498789
Validation loss: 2.637724809271006

Epoch: 5| Step: 10
Training loss: 0.9015900738233179
Validation loss: 2.649539579424242

Epoch: 5| Step: 11
Training loss: 0.4058171680815876
Validation loss: 2.716356786190334

Epoch: 171| Step: 0
Training loss: 1.1522915585870208
Validation loss: 2.731633008614171

Epoch: 5| Step: 1
Training loss: 0.7429242944102963
Validation loss: 2.7342763828477676

Epoch: 5| Step: 2
Training loss: 0.7973365942745868
Validation loss: 2.7141835093675946

Epoch: 5| Step: 3
Training loss: 1.0798337359841026
Validation loss: 2.66766131125143

Epoch: 5| Step: 4
Training loss: 0.7227419828130579
Validation loss: 2.6779465613312214

Epoch: 5| Step: 5
Training loss: 1.1491755494919433
Validation loss: 2.690803401259158

Epoch: 5| Step: 6
Training loss: 0.7026253514434039
Validation loss: 2.6509243327757432

Epoch: 5| Step: 7
Training loss: 0.7717915370156888
Validation loss: 2.7133344960464063

Epoch: 5| Step: 8
Training loss: 0.9846579432674656
Validation loss: 2.6004981612145404

Epoch: 5| Step: 9
Training loss: 1.8850700172149724
Validation loss: 2.605394851345759

Epoch: 5| Step: 10
Training loss: 0.9323073586505458
Validation loss: 2.615980726030831

Epoch: 5| Step: 11
Training loss: 1.110068950401729
Validation loss: 2.601491184421794

Epoch: 172| Step: 0
Training loss: 0.9195549753607578
Validation loss: 2.657537002682671

Epoch: 5| Step: 1
Training loss: 0.7940000020202521
Validation loss: 2.6469275672373564

Epoch: 5| Step: 2
Training loss: 0.42149685760765676
Validation loss: 2.571248202078337

Epoch: 5| Step: 3
Training loss: 0.8547710900863744
Validation loss: 2.6477917415634034

Epoch: 5| Step: 4
Training loss: 0.8219405231537711
Validation loss: 2.653387311048122

Epoch: 5| Step: 5
Training loss: 1.1030353952817307
Validation loss: 2.6941769442277206

Epoch: 5| Step: 6
Training loss: 0.8997455197408497
Validation loss: 2.6729208960813113

Epoch: 5| Step: 7
Training loss: 0.7873039289133462
Validation loss: 2.65523816078606

Epoch: 5| Step: 8
Training loss: 0.8181444127028713
Validation loss: 2.66634418852343

Epoch: 5| Step: 9
Training loss: 2.0761060731208714
Validation loss: 2.762094208672966

Epoch: 5| Step: 10
Training loss: 0.993017615339728
Validation loss: 2.74260261487402

Epoch: 5| Step: 11
Training loss: 0.6051354506089983
Validation loss: 2.754792347292275

Epoch: 173| Step: 0
Training loss: 0.7953759098818147
Validation loss: 2.7322640254117694

Epoch: 5| Step: 1
Training loss: 0.8232740077049334
Validation loss: 2.6706119511561752

Epoch: 5| Step: 2
Training loss: 1.62720032424811
Validation loss: 2.7624751902598232

Epoch: 5| Step: 3
Training loss: 0.6549105371283113
Validation loss: 2.678458934041398

Epoch: 5| Step: 4
Training loss: 0.8923293086189057
Validation loss: 2.673165201320834

Epoch: 5| Step: 5
Training loss: 1.0711687658572389
Validation loss: 2.67175449225992

Epoch: 5| Step: 6
Training loss: 1.21047635065334
Validation loss: 2.7350100043332937

Epoch: 5| Step: 7
Training loss: 0.8957070365118304
Validation loss: 2.6327126028425716

Epoch: 5| Step: 8
Training loss: 0.7910380795906268
Validation loss: 2.6346994122592693

Epoch: 5| Step: 9
Training loss: 1.0649559583198784
Validation loss: 2.686433517668822

Epoch: 5| Step: 10
Training loss: 1.2376754674875132
Validation loss: 2.622875979706114

Epoch: 5| Step: 11
Training loss: 0.6116577332370053
Validation loss: 2.7010627516749723

Epoch: 174| Step: 0
Training loss: 0.9852585535982457
Validation loss: 2.6508260550564438

Epoch: 5| Step: 1
Training loss: 0.8685010292561021
Validation loss: 2.764009104217086

Epoch: 5| Step: 2
Training loss: 0.867042495013908
Validation loss: 2.7074871514198375

Epoch: 5| Step: 3
Training loss: 0.8336393549420059
Validation loss: 2.6326228336647537

Epoch: 5| Step: 4
Training loss: 0.6217135569664034
Validation loss: 2.6695566846175263

Epoch: 5| Step: 5
Training loss: 1.207075939153625
Validation loss: 2.722705010552616

Epoch: 5| Step: 6
Training loss: 1.224052825959626
Validation loss: 2.616975238600062

Epoch: 5| Step: 7
Training loss: 0.8680499144476806
Validation loss: 2.6901927236707133

Epoch: 5| Step: 8
Training loss: 0.9673213576465672
Validation loss: 2.6556066481932583

Epoch: 5| Step: 9
Training loss: 1.6402185572392738
Validation loss: 2.6659968858742658

Epoch: 5| Step: 10
Training loss: 0.8718777195057449
Validation loss: 2.745442602193624

Epoch: 5| Step: 11
Training loss: 0.8082270873598127
Validation loss: 2.723020969738806

Epoch: 175| Step: 0
Training loss: 0.636155938725724
Validation loss: 2.7008782717038096

Epoch: 5| Step: 1
Training loss: 0.7828511424625264
Validation loss: 2.7099861725786396

Epoch: 5| Step: 2
Training loss: 1.2909237458145755
Validation loss: 2.6859659947571677

Epoch: 5| Step: 3
Training loss: 1.7667736941732888
Validation loss: 2.6535051712226303

Epoch: 5| Step: 4
Training loss: 0.8567386068449812
Validation loss: 2.6686542872017007

Epoch: 5| Step: 5
Training loss: 1.1819446519392534
Validation loss: 2.679951813232586

Epoch: 5| Step: 6
Training loss: 0.921998613766106
Validation loss: 2.6038249185753313

Epoch: 5| Step: 7
Training loss: 0.6944952887889557
Validation loss: 2.6569898509960095

Epoch: 5| Step: 8
Training loss: 0.7365059068809386
Validation loss: 2.6706905156205627

Epoch: 5| Step: 9
Training loss: 1.2092409616558035
Validation loss: 2.648867910664179

Epoch: 5| Step: 10
Training loss: 0.8253945014310149
Validation loss: 2.670366645979796

Epoch: 5| Step: 11
Training loss: 0.9495593429309068
Validation loss: 2.7173367331180636

Epoch: 176| Step: 0
Training loss: 1.0338772339573614
Validation loss: 2.6714511371539325

Epoch: 5| Step: 1
Training loss: 1.3393240496280612
Validation loss: 2.719025104678986

Epoch: 5| Step: 2
Training loss: 1.6696098883909505
Validation loss: 2.6782130382345435

Epoch: 5| Step: 3
Training loss: 0.6167705914415778
Validation loss: 2.589234653996725

Epoch: 5| Step: 4
Training loss: 0.8927850128738658
Validation loss: 2.712875690240583

Epoch: 5| Step: 5
Training loss: 1.1036675002650742
Validation loss: 2.645902938127462

Epoch: 5| Step: 6
Training loss: 0.9616751901908879
Validation loss: 2.6726896928993624

Epoch: 5| Step: 7
Training loss: 0.7871418607837521
Validation loss: 2.645158132745881

Epoch: 5| Step: 8
Training loss: 1.1014719175065435
Validation loss: 2.6848506806526924

Epoch: 5| Step: 9
Training loss: 0.7144040282218115
Validation loss: 2.6047962432233702

Epoch: 5| Step: 10
Training loss: 0.8440012734276986
Validation loss: 2.629690063831925

Epoch: 5| Step: 11
Training loss: 0.6986768530022388
Validation loss: 2.6297371029874075

Epoch: 177| Step: 0
Training loss: 1.8010442380370153
Validation loss: 2.6614520352183932

Epoch: 5| Step: 1
Training loss: 1.0787289351509588
Validation loss: 2.6448515825269623

Epoch: 5| Step: 2
Training loss: 1.0119673964672757
Validation loss: 2.6723733273672865

Epoch: 5| Step: 3
Training loss: 0.8375341906614236
Validation loss: 2.696033521399724

Epoch: 5| Step: 4
Training loss: 0.8419418387157873
Validation loss: 2.6286261618578357

Epoch: 5| Step: 5
Training loss: 0.7004200509523064
Validation loss: 2.5903838847270793

Epoch: 5| Step: 6
Training loss: 0.9948199635953251
Validation loss: 2.662565894199491

Epoch: 5| Step: 7
Training loss: 1.0583654629093031
Validation loss: 2.5826407139845684

Epoch: 5| Step: 8
Training loss: 0.7644565385324154
Validation loss: 2.701228459543149

Epoch: 5| Step: 9
Training loss: 0.9494329140272209
Validation loss: 2.597016269561145

Epoch: 5| Step: 10
Training loss: 0.7626677641246586
Validation loss: 2.7039692870364784

Epoch: 5| Step: 11
Training loss: 0.9028964971259149
Validation loss: 2.6457543561567283

Epoch: 178| Step: 0
Training loss: 0.5958286840973266
Validation loss: 2.681277790236784

Epoch: 5| Step: 1
Training loss: 0.8584922765274416
Validation loss: 2.672947172128106

Epoch: 5| Step: 2
Training loss: 1.8354832513388497
Validation loss: 2.7607240337813534

Epoch: 5| Step: 3
Training loss: 0.6912012820123223
Validation loss: 2.6049736807012858

Epoch: 5| Step: 4
Training loss: 1.2881697366452258
Validation loss: 2.6633644158905327

Epoch: 5| Step: 5
Training loss: 0.6703617887004254
Validation loss: 2.655777010225175

Epoch: 5| Step: 6
Training loss: 1.203494968750869
Validation loss: 2.605346734022315

Epoch: 5| Step: 7
Training loss: 0.900358054674601
Validation loss: 2.600465965392513

Epoch: 5| Step: 8
Training loss: 0.8818360388872969
Validation loss: 2.6676751417850584

Epoch: 5| Step: 9
Training loss: 0.9308556662680525
Validation loss: 2.6090866413035987

Epoch: 5| Step: 10
Training loss: 0.9101468851156151
Validation loss: 2.646938672551564

Epoch: 5| Step: 11
Training loss: 0.24407109605643812
Validation loss: 2.750463453889941

Epoch: 179| Step: 0
Training loss: 1.0258746648643582
Validation loss: 2.706111790341242

Epoch: 5| Step: 1
Training loss: 0.7748474986252414
Validation loss: 2.6905754386806198

Epoch: 5| Step: 2
Training loss: 1.2268045757523045
Validation loss: 2.6572141206602633

Epoch: 5| Step: 3
Training loss: 0.6907853393502673
Validation loss: 2.577115001704897

Epoch: 5| Step: 4
Training loss: 0.8967925562165968
Validation loss: 2.603589510221024

Epoch: 5| Step: 5
Training loss: 1.0942655165898858
Validation loss: 2.651126928900698

Epoch: 5| Step: 6
Training loss: 0.7303331626675417
Validation loss: 2.633770248728727

Epoch: 5| Step: 7
Training loss: 0.8192879591160517
Validation loss: 2.7177362781012504

Epoch: 5| Step: 8
Training loss: 1.6733641365275964
Validation loss: 2.6374420266612444

Epoch: 5| Step: 9
Training loss: 1.001007168929946
Validation loss: 2.6418424241495955

Epoch: 5| Step: 10
Training loss: 0.6939312577803896
Validation loss: 2.689375755067046

Epoch: 5| Step: 11
Training loss: 1.2050509210171423
Validation loss: 2.683237821249414

Epoch: 180| Step: 0
Training loss: 0.9032676227770988
Validation loss: 2.618634392395079

Epoch: 5| Step: 1
Training loss: 1.242627959464785
Validation loss: 2.639396061736085

Epoch: 5| Step: 2
Training loss: 0.805194731906309
Validation loss: 2.6322549367278625

Epoch: 5| Step: 3
Training loss: 0.8539474407567553
Validation loss: 2.5758436532329605

Epoch: 5| Step: 4
Training loss: 1.0295647231030343
Validation loss: 2.7600077788098223

Epoch: 5| Step: 5
Training loss: 1.1571998818456468
Validation loss: 2.621105487795309

Epoch: 5| Step: 6
Training loss: 0.7920281981761036
Validation loss: 2.6314510481585103

Epoch: 5| Step: 7
Training loss: 0.7169824095048624
Validation loss: 2.674674361601847

Epoch: 5| Step: 8
Training loss: 1.7030469544053393
Validation loss: 2.657510604173348

Epoch: 5| Step: 9
Training loss: 0.7514281186455228
Validation loss: 2.753672567783367

Epoch: 5| Step: 10
Training loss: 0.524232459990505
Validation loss: 2.709340181020643

Epoch: 5| Step: 11
Training loss: 0.53873300848628
Validation loss: 2.750599629600739

Epoch: 181| Step: 0
Training loss: 0.6782372887106074
Validation loss: 2.6907702627929213

Epoch: 5| Step: 1
Training loss: 0.5656563628969881
Validation loss: 2.7301463171882068

Epoch: 5| Step: 2
Training loss: 0.9940860935686326
Validation loss: 2.6689330369537

Epoch: 5| Step: 3
Training loss: 0.5542000253814339
Validation loss: 2.730826023869243

Epoch: 5| Step: 4
Training loss: 0.5802575293138329
Validation loss: 2.6799799923541383

Epoch: 5| Step: 5
Training loss: 0.7590887197251122
Validation loss: 2.6078241007070484

Epoch: 5| Step: 6
Training loss: 0.9349054674309197
Validation loss: 2.6746712082975317

Epoch: 5| Step: 7
Training loss: 0.8469974049299855
Validation loss: 2.685445207000743

Epoch: 5| Step: 8
Training loss: 1.7155024278001498
Validation loss: 2.732552813141451

Epoch: 5| Step: 9
Training loss: 1.1545198228471636
Validation loss: 2.603002418938274

Epoch: 5| Step: 10
Training loss: 1.1138452540122254
Validation loss: 2.6703044075022024

Epoch: 5| Step: 11
Training loss: 0.5945969363605524
Validation loss: 2.63234174842024

Epoch: 182| Step: 0
Training loss: 0.7320871631027843
Validation loss: 2.6751030315331747

Epoch: 5| Step: 1
Training loss: 0.7980294560395353
Validation loss: 2.7622010431735573

Epoch: 5| Step: 2
Training loss: 0.9185058645664438
Validation loss: 2.6986041365290276

Epoch: 5| Step: 3
Training loss: 0.855870609740737
Validation loss: 2.6613722424602075

Epoch: 5| Step: 4
Training loss: 0.4922621231426766
Validation loss: 2.7013144851959354

Epoch: 5| Step: 5
Training loss: 1.2479003438163336
Validation loss: 2.736388850894015

Epoch: 5| Step: 6
Training loss: 0.6031041887873159
Validation loss: 2.5945186605878408

Epoch: 5| Step: 7
Training loss: 0.713369590077024
Validation loss: 2.663063193768382

Epoch: 5| Step: 8
Training loss: 0.8070971510975704
Validation loss: 2.6525459643188656

Epoch: 5| Step: 9
Training loss: 0.8782251389174746
Validation loss: 2.688634810274655

Epoch: 5| Step: 10
Training loss: 1.795890870319498
Validation loss: 2.6723716675766

Epoch: 5| Step: 11
Training loss: 1.4253156345887479
Validation loss: 2.6538067932029215

Epoch: 183| Step: 0
Training loss: 0.7878567765416249
Validation loss: 2.6605895777596484

Epoch: 5| Step: 1
Training loss: 0.741047877694191
Validation loss: 2.6500391135538117

Epoch: 5| Step: 2
Training loss: 1.215352580478016
Validation loss: 2.6456427442936534

Epoch: 5| Step: 3
Training loss: 0.4602113273054654
Validation loss: 2.6902462545403742

Epoch: 5| Step: 4
Training loss: 1.0545479576199221
Validation loss: 2.717621784774282

Epoch: 5| Step: 5
Training loss: 0.8516220981845777
Validation loss: 2.7129197655786403

Epoch: 5| Step: 6
Training loss: 0.774982412200216
Validation loss: 2.7369682802999495

Epoch: 5| Step: 7
Training loss: 0.9525641995919105
Validation loss: 2.6814000373007985

Epoch: 5| Step: 8
Training loss: 1.0707638756358182
Validation loss: 2.688553987869196

Epoch: 5| Step: 9
Training loss: 1.696231013102517
Validation loss: 2.7492158812247482

Epoch: 5| Step: 10
Training loss: 0.6948911912050437
Validation loss: 2.634063295300976

Epoch: 5| Step: 11
Training loss: 1.172242323209423
Validation loss: 2.6674581125611936

Epoch: 184| Step: 0
Training loss: 1.1799385359483892
Validation loss: 2.7302628540937133

Epoch: 5| Step: 1
Training loss: 0.7116951311465629
Validation loss: 2.7149623122272004

Epoch: 5| Step: 2
Training loss: 1.651924747521878
Validation loss: 2.738441088950274

Epoch: 5| Step: 3
Training loss: 0.8634547408788741
Validation loss: 2.712957785543821

Epoch: 5| Step: 4
Training loss: 1.0070631804927084
Validation loss: 2.6250198340801965

Epoch: 5| Step: 5
Training loss: 0.6607605465044766
Validation loss: 2.7250630683483332

Epoch: 5| Step: 6
Training loss: 1.0443662503125377
Validation loss: 2.752455839397058

Epoch: 5| Step: 7
Training loss: 0.9930985840824686
Validation loss: 2.719770722227613

Epoch: 5| Step: 8
Training loss: 0.9151132201411104
Validation loss: 2.7261752898415366

Epoch: 5| Step: 9
Training loss: 1.0150810545705315
Validation loss: 2.747085905748418

Epoch: 5| Step: 10
Training loss: 0.8991422128460332
Validation loss: 2.7050321168808575

Epoch: 5| Step: 11
Training loss: 1.099441000479128
Validation loss: 2.6616207839647457

Epoch: 185| Step: 0
Training loss: 0.6809926491857385
Validation loss: 2.6752250074664055

Epoch: 5| Step: 1
Training loss: 0.8972628336403407
Validation loss: 2.703175968726009

Epoch: 5| Step: 2
Training loss: 0.8654627789141431
Validation loss: 2.746521176264487

Epoch: 5| Step: 3
Training loss: 1.1249157556144433
Validation loss: 2.757835146745266

Epoch: 5| Step: 4
Training loss: 0.9006022703120559
Validation loss: 2.7195157620585206

Epoch: 5| Step: 5
Training loss: 0.8109733838206988
Validation loss: 2.7247905748426713

Epoch: 5| Step: 6
Training loss: 0.8636572868947441
Validation loss: 2.63870178250885

Epoch: 5| Step: 7
Training loss: 1.0881570322053595
Validation loss: 2.700853231065055

Epoch: 5| Step: 8
Training loss: 0.6501312884375194
Validation loss: 2.6691200095884704

Epoch: 5| Step: 9
Training loss: 1.6873361719927251
Validation loss: 2.696541698483298

Epoch: 5| Step: 10
Training loss: 0.7156875299845659
Validation loss: 2.5730962510441384

Epoch: 5| Step: 11
Training loss: 0.5932718409549929
Validation loss: 2.630952345865139

Epoch: 186| Step: 0
Training loss: 0.7344401716167963
Validation loss: 2.6638467128912264

Epoch: 5| Step: 1
Training loss: 0.7722548102478798
Validation loss: 2.6691016737518125

Epoch: 5| Step: 2
Training loss: 0.5576927013674088
Validation loss: 2.702030169646106

Epoch: 5| Step: 3
Training loss: 1.0213376700265246
Validation loss: 2.672887796071133

Epoch: 5| Step: 4
Training loss: 1.0259797647202193
Validation loss: 2.6530749811640377

Epoch: 5| Step: 5
Training loss: 0.748626962146745
Validation loss: 2.7101740682834876

Epoch: 5| Step: 6
Training loss: 0.454271034693205
Validation loss: 2.686410023088612

Epoch: 5| Step: 7
Training loss: 1.071164258643681
Validation loss: 2.688082273377718

Epoch: 5| Step: 8
Training loss: 0.954558748094874
Validation loss: 2.730348343347755

Epoch: 5| Step: 9
Training loss: 1.6303305859373274
Validation loss: 2.6821154465549735

Epoch: 5| Step: 10
Training loss: 0.610523950264765
Validation loss: 2.669674779828993

Epoch: 5| Step: 11
Training loss: 1.3352312597071374
Validation loss: 2.605500106203434

Epoch: 187| Step: 0
Training loss: 1.1822501131841356
Validation loss: 2.6965153023669735

Epoch: 5| Step: 1
Training loss: 1.035481009732394
Validation loss: 2.636559511250593

Epoch: 5| Step: 2
Training loss: 1.73969963583423
Validation loss: 2.7242141327574063

Epoch: 5| Step: 3
Training loss: 0.6055432673713352
Validation loss: 2.6739270359392693

Epoch: 5| Step: 4
Training loss: 0.7412384792030835
Validation loss: 2.7378666845541177

Epoch: 5| Step: 5
Training loss: 0.49811875067778977
Validation loss: 2.7212868653269413

Epoch: 5| Step: 6
Training loss: 0.8401333331827272
Validation loss: 2.6413077763973543

Epoch: 5| Step: 7
Training loss: 0.6584048089528508
Validation loss: 2.6888474332050047

Epoch: 5| Step: 8
Training loss: 0.829292877374502
Validation loss: 2.6389293417981015

Epoch: 5| Step: 9
Training loss: 0.6380633567081648
Validation loss: 2.6273325857575047

Epoch: 5| Step: 10
Training loss: 0.7738453724001533
Validation loss: 2.7044947577016827

Epoch: 5| Step: 11
Training loss: 0.7950166463008859
Validation loss: 2.5959551124163567

Epoch: 188| Step: 0
Training loss: 0.9670436967919945
Validation loss: 2.636539703694998

Epoch: 5| Step: 1
Training loss: 0.762649905993729
Validation loss: 2.6124455969528864

Epoch: 5| Step: 2
Training loss: 0.9919889056081423
Validation loss: 2.729254059933237

Epoch: 5| Step: 3
Training loss: 1.8046258032354987
Validation loss: 2.7370456115226243

Epoch: 5| Step: 4
Training loss: 0.6908484973286221
Validation loss: 2.5512037681852706

Epoch: 5| Step: 5
Training loss: 0.584739018856175
Validation loss: 2.723071401899038

Epoch: 5| Step: 6
Training loss: 0.5784580199457334
Validation loss: 2.620694501006623

Epoch: 5| Step: 7
Training loss: 0.6243042411078435
Validation loss: 2.632482196678829

Epoch: 5| Step: 8
Training loss: 0.8539399373353992
Validation loss: 2.723295781585983

Epoch: 5| Step: 9
Training loss: 0.961621606973275
Validation loss: 2.65859141282898

Epoch: 5| Step: 10
Training loss: 0.5929399284826942
Validation loss: 2.721976649199854

Epoch: 5| Step: 11
Training loss: 0.8109823137370351
Validation loss: 2.5808440656647207

Epoch: 189| Step: 0
Training loss: 1.0252511647163627
Validation loss: 2.5801801832190976

Epoch: 5| Step: 1
Training loss: 0.6731054660226071
Validation loss: 2.6311816513958344

Epoch: 5| Step: 2
Training loss: 0.5725675443925311
Validation loss: 2.6563551825847327

Epoch: 5| Step: 3
Training loss: 0.9491099856507994
Validation loss: 2.705552214979015

Epoch: 5| Step: 4
Training loss: 0.9366447044039994
Validation loss: 2.7590645459570386

Epoch: 5| Step: 5
Training loss: 1.5947294778324164
Validation loss: 2.6755952570889106

Epoch: 5| Step: 6
Training loss: 0.63048920533229
Validation loss: 2.757404387249685

Epoch: 5| Step: 7
Training loss: 0.7226117094593092
Validation loss: 2.608513867028237

Epoch: 5| Step: 8
Training loss: 0.6899297217846292
Validation loss: 2.756770694549363

Epoch: 5| Step: 9
Training loss: 0.9815339157572077
Validation loss: 2.797188451808926

Epoch: 5| Step: 10
Training loss: 0.7252510704840012
Validation loss: 2.6792764339139077

Epoch: 5| Step: 11
Training loss: 1.7346762318246025
Validation loss: 2.634503852314599

Epoch: 190| Step: 0
Training loss: 0.7364828822366727
Validation loss: 2.6841081166111618

Epoch: 5| Step: 1
Training loss: 0.6572195338968755
Validation loss: 2.675966650858139

Epoch: 5| Step: 2
Training loss: 0.6849737352709906
Validation loss: 2.7522330465511597

Epoch: 5| Step: 3
Training loss: 0.787621040730226
Validation loss: 2.641279226064075

Epoch: 5| Step: 4
Training loss: 0.5113680270998713
Validation loss: 2.729449280576172

Epoch: 5| Step: 5
Training loss: 0.3900238370335343
Validation loss: 2.730928497829253

Epoch: 5| Step: 6
Training loss: 0.9661444418075426
Validation loss: 2.63162739056621

Epoch: 5| Step: 7
Training loss: 0.7300435833135529
Validation loss: 2.691102681159457

Epoch: 5| Step: 8
Training loss: 1.501682450567539
Validation loss: 2.6723120222305

Epoch: 5| Step: 9
Training loss: 1.0578785412231153
Validation loss: 2.727196857361593

Epoch: 5| Step: 10
Training loss: 1.0387396059767136
Validation loss: 2.7042336000604275

Epoch: 5| Step: 11
Training loss: 1.043090813169708
Validation loss: 2.773564872145089

Epoch: 191| Step: 0
Training loss: 1.519327341240023
Validation loss: 2.7785740884505947

Epoch: 5| Step: 1
Training loss: 1.1055154419868198
Validation loss: 2.782551161046367

Epoch: 5| Step: 2
Training loss: 0.7180096088526209
Validation loss: 2.8024945483238333

Epoch: 5| Step: 3
Training loss: 0.7921587184515556
Validation loss: 2.76247805274542

Epoch: 5| Step: 4
Training loss: 1.0243431335855147
Validation loss: 2.6768897997197416

Epoch: 5| Step: 5
Training loss: 0.8956501389014795
Validation loss: 2.650916703032544

Epoch: 5| Step: 6
Training loss: 1.1497175388087697
Validation loss: 2.749611892189622

Epoch: 5| Step: 7
Training loss: 0.8763198775156447
Validation loss: 2.6134770409834696

Epoch: 5| Step: 8
Training loss: 0.46513706858395737
Validation loss: 2.6094296539126063

Epoch: 5| Step: 9
Training loss: 0.6641441295043542
Validation loss: 2.595700970321844

Epoch: 5| Step: 10
Training loss: 0.6094930974524096
Validation loss: 2.6081371912064553

Epoch: 5| Step: 11
Training loss: 0.5531028355182471
Validation loss: 2.6121941069493437

Epoch: 192| Step: 0
Training loss: 0.5931893763763201
Validation loss: 2.7411021396856707

Epoch: 5| Step: 1
Training loss: 0.9694613029583258
Validation loss: 2.7170890433439587

Epoch: 5| Step: 2
Training loss: 0.6646707329834521
Validation loss: 2.6872355604555986

Epoch: 5| Step: 3
Training loss: 0.6305505805815925
Validation loss: 2.636756881626522

Epoch: 5| Step: 4
Training loss: 0.7069481226490848
Validation loss: 2.7000583680637407

Epoch: 5| Step: 5
Training loss: 0.9381479567248282
Validation loss: 2.629253253075236

Epoch: 5| Step: 6
Training loss: 0.7769669812991696
Validation loss: 2.678589543099686

Epoch: 5| Step: 7
Training loss: 0.9935537828306711
Validation loss: 2.6859647890383442

Epoch: 5| Step: 8
Training loss: 0.7782334263645467
Validation loss: 2.692028964661258

Epoch: 5| Step: 9
Training loss: 1.658761261913989
Validation loss: 2.727354614125445

Epoch: 5| Step: 10
Training loss: 0.7331222644049167
Validation loss: 2.706849925623016

Epoch: 5| Step: 11
Training loss: 0.5506013075789816
Validation loss: 2.575472428523007

Epoch: 193| Step: 0
Training loss: 1.0735814649056403
Validation loss: 2.6821665367395555

Epoch: 5| Step: 1
Training loss: 0.6925087237238969
Validation loss: 2.620419468115192

Epoch: 5| Step: 2
Training loss: 0.5846840230082992
Validation loss: 2.666419570372459

Epoch: 5| Step: 3
Training loss: 1.1476224745006007
Validation loss: 2.717518209520971

Epoch: 5| Step: 4
Training loss: 0.7491006624879099
Validation loss: 2.712831965728435

Epoch: 5| Step: 5
Training loss: 0.8447239517436173
Validation loss: 2.7624004697058915

Epoch: 5| Step: 6
Training loss: 0.7837964329205461
Validation loss: 2.619559861097171

Epoch: 5| Step: 7
Training loss: 1.5762097662586492
Validation loss: 2.639182541358533

Epoch: 5| Step: 8
Training loss: 0.6183062445635407
Validation loss: 2.705100324518989

Epoch: 5| Step: 9
Training loss: 0.5105295705161146
Validation loss: 2.690218633461019

Epoch: 5| Step: 10
Training loss: 0.8581923930799807
Validation loss: 2.699234892028151

Epoch: 5| Step: 11
Training loss: 0.23500408147503946
Validation loss: 2.7433221358858315

Epoch: 194| Step: 0
Training loss: 0.761653447408618
Validation loss: 2.665698431985455

Epoch: 5| Step: 1
Training loss: 1.7836797772855246
Validation loss: 2.685685443424374

Epoch: 5| Step: 2
Training loss: 0.7002769646061294
Validation loss: 2.6197514856390534

Epoch: 5| Step: 3
Training loss: 0.7560532195644373
Validation loss: 2.716935835026249

Epoch: 5| Step: 4
Training loss: 0.5606290644027372
Validation loss: 2.670414385964006

Epoch: 5| Step: 5
Training loss: 0.8455589471071722
Validation loss: 2.7060716477753646

Epoch: 5| Step: 6
Training loss: 0.8362159265324899
Validation loss: 2.677354952222269

Epoch: 5| Step: 7
Training loss: 1.1244480050407129
Validation loss: 2.6786086057928844

Epoch: 5| Step: 8
Training loss: 0.6017607572756498
Validation loss: 2.605514754728487

Epoch: 5| Step: 9
Training loss: 0.5271276808415667
Validation loss: 2.590900782718094

Epoch: 5| Step: 10
Training loss: 0.9118144111819839
Validation loss: 2.686625441853356

Epoch: 5| Step: 11
Training loss: 0.7545190800933294
Validation loss: 2.72559866861805

Epoch: 195| Step: 0
Training loss: 1.2101258049343486
Validation loss: 2.6608458907343495

Epoch: 5| Step: 1
Training loss: 0.8604318882209245
Validation loss: 2.6219092974959985

Epoch: 5| Step: 2
Training loss: 0.7932785631622322
Validation loss: 2.695908223536306

Epoch: 5| Step: 3
Training loss: 0.599723308064676
Validation loss: 2.630265650108954

Epoch: 5| Step: 4
Training loss: 0.6737070389464125
Validation loss: 2.6547708357195012

Epoch: 5| Step: 5
Training loss: 0.8781176610891127
Validation loss: 2.6413925906180458

Epoch: 5| Step: 6
Training loss: 0.5126824658918786
Validation loss: 2.7432042344491356

Epoch: 5| Step: 7
Training loss: 1.7148478514463694
Validation loss: 2.7285753487977518

Epoch: 5| Step: 8
Training loss: 0.6375639285028671
Validation loss: 2.6379124819065036

Epoch: 5| Step: 9
Training loss: 0.8535791369099804
Validation loss: 2.668339351235854

Epoch: 5| Step: 10
Training loss: 0.6766574669629121
Validation loss: 2.6236517656809286

Epoch: 5| Step: 11
Training loss: 0.5988309199497519
Validation loss: 2.759968466929888

Epoch: 196| Step: 0
Training loss: 0.5420985486941956
Validation loss: 2.565159220354817

Epoch: 5| Step: 1
Training loss: 0.7724046457567766
Validation loss: 2.701244593239333

Epoch: 5| Step: 2
Training loss: 0.9826686541598894
Validation loss: 2.6912937482215424

Epoch: 5| Step: 3
Training loss: 0.770506884208091
Validation loss: 2.7010855616131337

Epoch: 5| Step: 4
Training loss: 0.6247638017657152
Validation loss: 2.6837477993789554

Epoch: 5| Step: 5
Training loss: 0.767320157641693
Validation loss: 2.752904019704662

Epoch: 5| Step: 6
Training loss: 0.7490843905996922
Validation loss: 2.6605926618760702

Epoch: 5| Step: 7
Training loss: 0.8364150207504351
Validation loss: 2.674953612997891

Epoch: 5| Step: 8
Training loss: 0.8137554592763948
Validation loss: 2.6339359358006464

Epoch: 5| Step: 9
Training loss: 0.8136681449024483
Validation loss: 2.7147580213298563

Epoch: 5| Step: 10
Training loss: 0.7371073679853729
Validation loss: 2.722432715253275

Epoch: 5| Step: 11
Training loss: 3.2564984422677354
Validation loss: 2.6589861633734126

Epoch: 197| Step: 0
Training loss: 0.6053201062261713
Validation loss: 2.7201270858092617

Epoch: 5| Step: 1
Training loss: 0.7264578549079279
Validation loss: 2.7026794779403627

Epoch: 5| Step: 2
Training loss: 0.9100116402017803
Validation loss: 2.7437837669594556

Epoch: 5| Step: 3
Training loss: 0.8968327994171048
Validation loss: 2.7273349888213843

Epoch: 5| Step: 4
Training loss: 0.9539033182085053
Validation loss: 2.7344067417300595

Epoch: 5| Step: 5
Training loss: 0.5979100604694773
Validation loss: 2.7040326242968797

Epoch: 5| Step: 6
Training loss: 0.684661793820382
Validation loss: 2.585690001507553

Epoch: 5| Step: 7
Training loss: 1.6090887611425766
Validation loss: 2.6925949033436436

Epoch: 5| Step: 8
Training loss: 0.8354916676049308
Validation loss: 2.599385940499383

Epoch: 5| Step: 9
Training loss: 0.7784833366409015
Validation loss: 2.6961014555816645

Epoch: 5| Step: 10
Training loss: 0.7321428504970431
Validation loss: 2.788895538775135

Epoch: 5| Step: 11
Training loss: 0.9658871773156665
Validation loss: 2.5988531639260994

Epoch: 198| Step: 0
Training loss: 0.9135826351037025
Validation loss: 2.765517327894117

Epoch: 5| Step: 1
Training loss: 0.7141840658067743
Validation loss: 2.7690652689324224

Epoch: 5| Step: 2
Training loss: 1.0414633870458465
Validation loss: 2.7817425738134083

Epoch: 5| Step: 3
Training loss: 0.7290512447739245
Validation loss: 2.70448915976314

Epoch: 5| Step: 4
Training loss: 1.0066469534992186
Validation loss: 2.6870648859859467

Epoch: 5| Step: 5
Training loss: 0.5923282767981446
Validation loss: 2.650423642400053

Epoch: 5| Step: 6
Training loss: 0.5988926533609426
Validation loss: 2.550335255568749

Epoch: 5| Step: 7
Training loss: 1.5826834382199886
Validation loss: 2.6137939695226198

Epoch: 5| Step: 8
Training loss: 0.9942428746129989
Validation loss: 2.7080451237331773

Epoch: 5| Step: 9
Training loss: 0.6689949184318817
Validation loss: 2.6545441441918203

Epoch: 5| Step: 10
Training loss: 0.8940883689532582
Validation loss: 2.582756671582917

Epoch: 5| Step: 11
Training loss: 0.8180856542837697
Validation loss: 2.551588521724649

Epoch: 199| Step: 0
Training loss: 0.7787978025065465
Validation loss: 2.577127408154701

Epoch: 5| Step: 1
Training loss: 0.7833503717909671
Validation loss: 2.691201750834705

Epoch: 5| Step: 2
Training loss: 1.1453711646903701
Validation loss: 2.6643190903583807

Epoch: 5| Step: 3
Training loss: 0.7523987477641456
Validation loss: 2.690869023521611

Epoch: 5| Step: 4
Training loss: 1.0245966280436238
Validation loss: 2.7034449305314845

Epoch: 5| Step: 5
Training loss: 1.5709669732568672
Validation loss: 2.7149986204620378

Epoch: 5| Step: 6
Training loss: 0.7573841496752429
Validation loss: 2.6659526887388783

Epoch: 5| Step: 7
Training loss: 0.8601501090430801
Validation loss: 2.6023140204624964

Epoch: 5| Step: 8
Training loss: 0.6402429045969579
Validation loss: 2.6503883948395206

Epoch: 5| Step: 9
Training loss: 0.797047278537152
Validation loss: 2.6158384879374283

Epoch: 5| Step: 10
Training loss: 0.478327422207961
Validation loss: 2.6097989908548382

Epoch: 5| Step: 11
Training loss: 0.5818305981798589
Validation loss: 2.6535493173663904

Epoch: 200| Step: 0
Training loss: 1.6117666306736003
Validation loss: 2.622382952226952

Epoch: 5| Step: 1
Training loss: 0.6397690753887978
Validation loss: 2.6344259018088803

Epoch: 5| Step: 2
Training loss: 0.7360940252476442
Validation loss: 2.6302664885685614

Epoch: 5| Step: 3
Training loss: 0.48634912836152216
Validation loss: 2.6813308785132643

Epoch: 5| Step: 4
Training loss: 0.7156171939873883
Validation loss: 2.621552527158567

Epoch: 5| Step: 5
Training loss: 0.9207675229947161
Validation loss: 2.6904821594992314

Epoch: 5| Step: 6
Training loss: 0.8941316669993635
Validation loss: 2.644899599012216

Epoch: 5| Step: 7
Training loss: 0.8160796173700835
Validation loss: 2.5921698950778462

Epoch: 5| Step: 8
Training loss: 0.580308296956673
Validation loss: 2.663480969273127

Epoch: 5| Step: 9
Training loss: 0.6140778100432313
Validation loss: 2.6293039422588915

Epoch: 5| Step: 10
Training loss: 0.9825874628929195
Validation loss: 2.646113389629999

Epoch: 5| Step: 11
Training loss: 1.0182282170570154
Validation loss: 2.6711305432585606

Epoch: 201| Step: 0
Training loss: 0.5845791648757818
Validation loss: 2.688663762978328

Epoch: 5| Step: 1
Training loss: 0.9200745798026304
Validation loss: 2.642781537617997

Epoch: 5| Step: 2
Training loss: 0.7359397126830706
Validation loss: 2.676940403300439

Epoch: 5| Step: 3
Training loss: 0.6982079984390899
Validation loss: 2.6311145631331043

Epoch: 5| Step: 4
Training loss: 1.6129221666669808
Validation loss: 2.659369439620926

Epoch: 5| Step: 5
Training loss: 0.8491679129873706
Validation loss: 2.726437493840705

Epoch: 5| Step: 6
Training loss: 0.9139501388480413
Validation loss: 2.6558748690929397

Epoch: 5| Step: 7
Training loss: 0.6407315002863627
Validation loss: 2.672033290375597

Epoch: 5| Step: 8
Training loss: 0.8279224003972591
Validation loss: 2.7022202471534076

Epoch: 5| Step: 9
Training loss: 0.6303609999388539
Validation loss: 2.7194057674913332

Epoch: 5| Step: 10
Training loss: 0.6377859241083109
Validation loss: 2.6428615834378038

Epoch: 5| Step: 11
Training loss: 0.6080135640510441
Validation loss: 2.7014376164127354

Epoch: 202| Step: 0
Training loss: 0.5393495486499372
Validation loss: 2.673485796470051

Epoch: 5| Step: 1
Training loss: 0.576797146074401
Validation loss: 2.7296753759902814

Epoch: 5| Step: 2
Training loss: 0.6527204054336935
Validation loss: 2.800000992275244

Epoch: 5| Step: 3
Training loss: 0.8675485838661686
Validation loss: 2.742976706346696

Epoch: 5| Step: 4
Training loss: 0.7370683505999398
Validation loss: 2.6065820262924397

Epoch: 5| Step: 5
Training loss: 0.635232442717545
Validation loss: 2.7100250071606977

Epoch: 5| Step: 6
Training loss: 0.8603593910372053
Validation loss: 2.632555793449909

Epoch: 5| Step: 7
Training loss: 0.5861385763381317
Validation loss: 2.6662691510468473

Epoch: 5| Step: 8
Training loss: 1.509859030376915
Validation loss: 2.7276166355580598

Epoch: 5| Step: 9
Training loss: 1.1964848572234683
Validation loss: 2.714513426520012

Epoch: 5| Step: 10
Training loss: 0.5177980639437347
Validation loss: 2.6744821703831123

Epoch: 5| Step: 11
Training loss: 0.43238393725697705
Validation loss: 2.7009137835512003

Epoch: 203| Step: 0
Training loss: 1.5075285649163324
Validation loss: 2.7673700362545133

Epoch: 5| Step: 1
Training loss: 0.6500524151282672
Validation loss: 2.633255888206509

Epoch: 5| Step: 2
Training loss: 0.8393908676840446
Validation loss: 2.754479372525379

Epoch: 5| Step: 3
Training loss: 0.6576639111798361
Validation loss: 2.68039548694654

Epoch: 5| Step: 4
Training loss: 0.7717263916527044
Validation loss: 2.7017569378376396

Epoch: 5| Step: 5
Training loss: 0.9354107783641288
Validation loss: 2.7567630640628282

Epoch: 5| Step: 6
Training loss: 0.673376069951274
Validation loss: 2.641532655429489

Epoch: 5| Step: 7
Training loss: 0.6435040467037956
Validation loss: 2.6716496445055444

Epoch: 5| Step: 8
Training loss: 0.8301828475416276
Validation loss: 2.7231176524471383

Epoch: 5| Step: 9
Training loss: 0.9253076879291833
Validation loss: 2.7162581969463866

Epoch: 5| Step: 10
Training loss: 0.708121623395662
Validation loss: 2.6657118255081804

Epoch: 5| Step: 11
Training loss: 0.44200896578105864
Validation loss: 2.6788605024633654

Epoch: 204| Step: 0
Training loss: 0.8038276226121102
Validation loss: 2.7166573703251866

Epoch: 5| Step: 1
Training loss: 0.6620934858638052
Validation loss: 2.6844085574319263

Epoch: 5| Step: 2
Training loss: 0.7256921456851679
Validation loss: 2.6816458594374613

Epoch: 5| Step: 3
Training loss: 0.6785864626681799
Validation loss: 2.6242418064635054

Epoch: 5| Step: 4
Training loss: 0.915779001870721
Validation loss: 2.681646685536707

Epoch: 5| Step: 5
Training loss: 0.5888324683030346
Validation loss: 2.723466822746671

Epoch: 5| Step: 6
Training loss: 0.8283883161992728
Validation loss: 2.642442397611887

Epoch: 5| Step: 7
Training loss: 1.464930986985687
Validation loss: 2.7124039076266397

Epoch: 5| Step: 8
Training loss: 0.6536847795735667
Validation loss: 2.8013515344046924

Epoch: 5| Step: 9
Training loss: 0.8479669941830738
Validation loss: 2.6780420409936943

Epoch: 5| Step: 10
Training loss: 0.8229796148118579
Validation loss: 2.748518519448052

Epoch: 5| Step: 11
Training loss: 1.4728310074059219
Validation loss: 2.6599006660755644

Epoch: 205| Step: 0
Training loss: 0.6898644708824209
Validation loss: 2.720846628319202

Epoch: 5| Step: 1
Training loss: 0.4482084606505357
Validation loss: 2.673777564689742

Epoch: 5| Step: 2
Training loss: 0.6333656483696312
Validation loss: 2.6985008694692874

Epoch: 5| Step: 3
Training loss: 0.5093880493739235
Validation loss: 2.6810120551841283

Epoch: 5| Step: 4
Training loss: 0.7348832340003043
Validation loss: 2.6382266651878274

Epoch: 5| Step: 5
Training loss: 0.5282996943993364
Validation loss: 2.704822907418104

Epoch: 5| Step: 6
Training loss: 0.727568965015733
Validation loss: 2.7253041100618005

Epoch: 5| Step: 7
Training loss: 1.1521274169618398
Validation loss: 2.7398327374280047

Epoch: 5| Step: 8
Training loss: 0.8475950368410073
Validation loss: 2.6681738570288376

Epoch: 5| Step: 9
Training loss: 0.5819894916480436
Validation loss: 2.6061126203181812

Epoch: 5| Step: 10
Training loss: 1.5161197287503807
Validation loss: 2.656763389939425

Epoch: 5| Step: 11
Training loss: 0.6767243876604423
Validation loss: 2.705388130575259

Epoch: 206| Step: 0
Training loss: 0.7581827891087641
Validation loss: 2.6353437252781475

Epoch: 5| Step: 1
Training loss: 0.6749971062986725
Validation loss: 2.695380957282341

Epoch: 5| Step: 2
Training loss: 0.7555499959215987
Validation loss: 2.6711885116919047

Epoch: 5| Step: 3
Training loss: 0.7868721275489257
Validation loss: 2.736577445812679

Epoch: 5| Step: 4
Training loss: 0.7926789679750491
Validation loss: 2.680985546927295

Epoch: 5| Step: 5
Training loss: 1.7484652737754425
Validation loss: 2.7259428090668414

Epoch: 5| Step: 6
Training loss: 0.682839113323518
Validation loss: 2.7636765946167094

Epoch: 5| Step: 7
Training loss: 0.5398252867703252
Validation loss: 2.660515808064479

Epoch: 5| Step: 8
Training loss: 0.4447183158421523
Validation loss: 2.6694046259898596

Epoch: 5| Step: 9
Training loss: 0.489044401790674
Validation loss: 2.6053053286582113

Epoch: 5| Step: 10
Training loss: 0.9681130437931508
Validation loss: 2.6179352826003974

Epoch: 5| Step: 11
Training loss: 0.6627456623426131
Validation loss: 2.7349806850455685

Epoch: 207| Step: 0
Training loss: 1.4646085423144504
Validation loss: 2.69052435494344

Epoch: 5| Step: 1
Training loss: 0.6776319970630102
Validation loss: 2.7742286126919256

Epoch: 5| Step: 2
Training loss: 0.6907002567697271
Validation loss: 2.681430105460341

Epoch: 5| Step: 3
Training loss: 0.7607527647642002
Validation loss: 2.7737434916873336

Epoch: 5| Step: 4
Training loss: 0.58052333611068
Validation loss: 2.7855486314755806

Epoch: 5| Step: 5
Training loss: 0.6047333958677522
Validation loss: 2.709200728728482

Epoch: 5| Step: 6
Training loss: 0.7305421435362326
Validation loss: 2.7328215337000192

Epoch: 5| Step: 7
Training loss: 0.5033158976753895
Validation loss: 2.737567316966581

Epoch: 5| Step: 8
Training loss: 0.795473661750371
Validation loss: 2.6629998296104223

Epoch: 5| Step: 9
Training loss: 1.042880622483741
Validation loss: 2.6327138442696003

Epoch: 5| Step: 10
Training loss: 0.8561488892381224
Validation loss: 2.6050163879110912

Epoch: 5| Step: 11
Training loss: 0.506430167645889
Validation loss: 2.662623187246503

Epoch: 208| Step: 0
Training loss: 0.6912666438480577
Validation loss: 2.6878739991293146

Epoch: 5| Step: 1
Training loss: 0.8997153441296538
Validation loss: 2.7015591589938452

Epoch: 5| Step: 2
Training loss: 1.668506115868745
Validation loss: 2.70282033993175

Epoch: 5| Step: 3
Training loss: 0.7713932804456882
Validation loss: 2.76804297829762

Epoch: 5| Step: 4
Training loss: 0.7307499227115931
Validation loss: 2.7350748383617614

Epoch: 5| Step: 5
Training loss: 0.6413208043826925
Validation loss: 2.7848285055978423

Epoch: 5| Step: 6
Training loss: 0.7404891811046728
Validation loss: 2.6636063976774134

Epoch: 5| Step: 7
Training loss: 0.9611804623992651
Validation loss: 2.7226576510936136

Epoch: 5| Step: 8
Training loss: 0.956096426156942
Validation loss: 2.68193418225481

Epoch: 5| Step: 9
Training loss: 0.6267307398088343
Validation loss: 2.7182996055265565

Epoch: 5| Step: 10
Training loss: 0.5052603927479651
Validation loss: 2.6462627660629314

Epoch: 5| Step: 11
Training loss: 0.6999775482732458
Validation loss: 2.6479440077403837

Epoch: 209| Step: 0
Training loss: 0.8657986284324866
Validation loss: 2.7919093009971427

Epoch: 5| Step: 1
Training loss: 0.6215029154469001
Validation loss: 2.6595332255885697

Epoch: 5| Step: 2
Training loss: 1.571646052953839
Validation loss: 2.7589945002670753

Epoch: 5| Step: 3
Training loss: 0.7174936177305481
Validation loss: 2.782668202175493

Epoch: 5| Step: 4
Training loss: 0.6236421617236635
Validation loss: 2.7080551016771492

Epoch: 5| Step: 5
Training loss: 0.8987413970471856
Validation loss: 2.736723989876796

Epoch: 5| Step: 6
Training loss: 0.8503495072818319
Validation loss: 2.631413515406071

Epoch: 5| Step: 7
Training loss: 0.9469996127980779
Validation loss: 2.620193948567984

Epoch: 5| Step: 8
Training loss: 0.6567874025034078
Validation loss: 2.6622756771723233

Epoch: 5| Step: 9
Training loss: 0.47333748645482754
Validation loss: 2.6904261981920716

Epoch: 5| Step: 10
Training loss: 0.5705198146311123
Validation loss: 2.6557279859232117

Epoch: 5| Step: 11
Training loss: 0.489947322378619
Validation loss: 2.7030169956041306

Epoch: 210| Step: 0
Training loss: 1.5240628255124553
Validation loss: 2.701922062659489

Epoch: 5| Step: 1
Training loss: 0.726741358574091
Validation loss: 2.6305350368279794

Epoch: 5| Step: 2
Training loss: 0.41030007520052514
Validation loss: 2.721515860005158

Epoch: 5| Step: 3
Training loss: 0.7795444181411612
Validation loss: 2.755008475128495

Epoch: 5| Step: 4
Training loss: 0.7188966021090417
Validation loss: 2.6535686235859828

Epoch: 5| Step: 5
Training loss: 0.4586653229523722
Validation loss: 2.7408137163341872

Epoch: 5| Step: 6
Training loss: 0.7640779396166584
Validation loss: 2.5864956705719724

Epoch: 5| Step: 7
Training loss: 0.7492075946124557
Validation loss: 2.6355347223690986

Epoch: 5| Step: 8
Training loss: 0.8806552015964113
Validation loss: 2.6272013720666494

Epoch: 5| Step: 9
Training loss: 0.8801527889866961
Validation loss: 2.6255021901607973

Epoch: 5| Step: 10
Training loss: 0.7941866387107179
Validation loss: 2.698503457452221

Epoch: 5| Step: 11
Training loss: 0.9417799211998952
Validation loss: 2.696669438772895

Epoch: 211| Step: 0
Training loss: 1.011114816577349
Validation loss: 2.71064393197355

Epoch: 5| Step: 1
Training loss: 0.7683798604463649
Validation loss: 2.7492652511169036

Epoch: 5| Step: 2
Training loss: 0.7029596770159552
Validation loss: 2.7896814416428093

Epoch: 5| Step: 3
Training loss: 1.400318989856803
Validation loss: 2.7929100901883714

Epoch: 5| Step: 4
Training loss: 0.6308573436409101
Validation loss: 2.76141061642082

Epoch: 5| Step: 5
Training loss: 0.9071409515622596
Validation loss: 2.7540061337368766

Epoch: 5| Step: 6
Training loss: 0.6091092092454463
Validation loss: 2.733789017876645

Epoch: 5| Step: 7
Training loss: 0.5056739673550585
Validation loss: 2.692228072752399

Epoch: 5| Step: 8
Training loss: 0.9096254429933414
Validation loss: 2.6547520621241714

Epoch: 5| Step: 9
Training loss: 0.6081885745856674
Validation loss: 2.7608579942603777

Epoch: 5| Step: 10
Training loss: 0.7964784720194142
Validation loss: 2.69111883864692

Epoch: 5| Step: 11
Training loss: 0.7451673418316577
Validation loss: 2.656032564576138

Epoch: 212| Step: 0
Training loss: 1.6031694491583988
Validation loss: 2.7103996182979926

Epoch: 5| Step: 1
Training loss: 0.725159510790302
Validation loss: 2.691970153406962

Epoch: 5| Step: 2
Training loss: 0.43561197658210615
Validation loss: 2.736873959818942

Epoch: 5| Step: 3
Training loss: 0.6589255966447234
Validation loss: 2.8248434048689415

Epoch: 5| Step: 4
Training loss: 1.0598583480367256
Validation loss: 2.795188466350457

Epoch: 5| Step: 5
Training loss: 0.8428146688159708
Validation loss: 2.783015005435394

Epoch: 5| Step: 6
Training loss: 0.7169802480528107
Validation loss: 2.7110323967205123

Epoch: 5| Step: 7
Training loss: 0.6867261779869487
Validation loss: 2.7274074065123606

Epoch: 5| Step: 8
Training loss: 0.6158516103701928
Validation loss: 2.640520184033625

Epoch: 5| Step: 9
Training loss: 0.8148037821110293
Validation loss: 2.706961824922289

Epoch: 5| Step: 10
Training loss: 0.8728303576813194
Validation loss: 2.698625781911108

Epoch: 5| Step: 11
Training loss: 0.4254428323563144
Validation loss: 2.6498863360782123

Epoch: 213| Step: 0
Training loss: 0.5196517001613589
Validation loss: 2.757565671917497

Epoch: 5| Step: 1
Training loss: 0.8007893259525122
Validation loss: 2.7568087205434066

Epoch: 5| Step: 2
Training loss: 0.5889410475533268
Validation loss: 2.7245193010798032

Epoch: 5| Step: 3
Training loss: 1.3961053934236156
Validation loss: 2.720650841511136

Epoch: 5| Step: 4
Training loss: 1.0114307361822847
Validation loss: 2.662516554630255

Epoch: 5| Step: 5
Training loss: 0.6839480762446547
Validation loss: 2.811430325014673

Epoch: 5| Step: 6
Training loss: 0.8694055046472419
Validation loss: 2.7781781652431805

Epoch: 5| Step: 7
Training loss: 0.6691055662788213
Validation loss: 2.6918314693377474

Epoch: 5| Step: 8
Training loss: 0.5744849386008829
Validation loss: 2.7414794290276276

Epoch: 5| Step: 9
Training loss: 0.7019979344810355
Validation loss: 2.8212883899653147

Epoch: 5| Step: 10
Training loss: 0.603924017443724
Validation loss: 2.6578477542070784

Epoch: 5| Step: 11
Training loss: 0.18957670841239566
Validation loss: 2.702401963042839

Epoch: 214| Step: 0
Training loss: 0.6262350515762984
Validation loss: 2.6632477902658356

Epoch: 5| Step: 1
Training loss: 0.826369890872624
Validation loss: 2.6708294754377366

Epoch: 5| Step: 2
Training loss: 0.6125314101125601
Validation loss: 2.5926473564149135

Epoch: 5| Step: 3
Training loss: 0.9172762592265548
Validation loss: 2.6438132682065656

Epoch: 5| Step: 4
Training loss: 0.6145492856783258
Validation loss: 2.6526561734708696

Epoch: 5| Step: 5
Training loss: 0.7681369445964643
Validation loss: 2.720216939972473

Epoch: 5| Step: 6
Training loss: 0.8205457809805603
Validation loss: 2.7462222420596634

Epoch: 5| Step: 7
Training loss: 0.7069467314895712
Validation loss: 2.7278602794288545

Epoch: 5| Step: 8
Training loss: 0.6786499435132489
Validation loss: 2.641355415388373

Epoch: 5| Step: 9
Training loss: 1.3947793862692746
Validation loss: 2.661576152117206

Epoch: 5| Step: 10
Training loss: 0.6576869310149817
Validation loss: 2.640851795456611

Epoch: 5| Step: 11
Training loss: 0.36190008310410327
Validation loss: 2.669287516223908

Epoch: 215| Step: 0
Training loss: 0.8068944056132733
Validation loss: 2.6903397431428595

Epoch: 5| Step: 1
Training loss: 0.8974546612840765
Validation loss: 2.593871081256883

Epoch: 5| Step: 2
Training loss: 1.5219956837767106
Validation loss: 2.691716826318954

Epoch: 5| Step: 3
Training loss: 0.5878796497220301
Validation loss: 2.725689869503601

Epoch: 5| Step: 4
Training loss: 0.4745647896126514
Validation loss: 2.7320394768762393

Epoch: 5| Step: 5
Training loss: 0.6454516687951843
Validation loss: 2.7349707145273707

Epoch: 5| Step: 6
Training loss: 0.7614003616440367
Validation loss: 2.788078615409469

Epoch: 5| Step: 7
Training loss: 0.8910619099062459
Validation loss: 2.811365354333065

Epoch: 5| Step: 8
Training loss: 0.9515402078757811
Validation loss: 2.799607336377916

Epoch: 5| Step: 9
Training loss: 0.5166925880123471
Validation loss: 2.638994791529865

Epoch: 5| Step: 10
Training loss: 0.6084610614417217
Validation loss: 2.7393742228913123

Epoch: 5| Step: 11
Training loss: 0.7525555464055262
Validation loss: 2.7851781750601177

Epoch: 216| Step: 0
Training loss: 0.5547572884512769
Validation loss: 2.6749910399028414

Epoch: 5| Step: 1
Training loss: 0.49094925388613986
Validation loss: 2.6325567972167

Epoch: 5| Step: 2
Training loss: 0.4339367824110614
Validation loss: 2.65302398977614

Epoch: 5| Step: 3
Training loss: 0.5697096420982072
Validation loss: 2.670150613090748

Epoch: 5| Step: 4
Training loss: 0.3982936000892112
Validation loss: 2.7074177196865055

Epoch: 5| Step: 5
Training loss: 1.5387543500502554
Validation loss: 2.669014386519545

Epoch: 5| Step: 6
Training loss: 0.759102931950153
Validation loss: 2.632114793374975

Epoch: 5| Step: 7
Training loss: 0.9265474456541928
Validation loss: 2.7098715754257894

Epoch: 5| Step: 8
Training loss: 0.4279385606271518
Validation loss: 2.7277024335473756

Epoch: 5| Step: 9
Training loss: 0.7357095401772238
Validation loss: 2.6727217806629135

Epoch: 5| Step: 10
Training loss: 0.8057292380124343
Validation loss: 2.682529373499923

Epoch: 5| Step: 11
Training loss: 1.0770991876986034
Validation loss: 2.6805657114540407

Epoch: 217| Step: 0
Training loss: 0.8126057042540636
Validation loss: 2.6360943165525392

Epoch: 5| Step: 1
Training loss: 0.6716413978961803
Validation loss: 2.6781975039353236

Epoch: 5| Step: 2
Training loss: 0.4600961085655939
Validation loss: 2.701805255633009

Epoch: 5| Step: 3
Training loss: 0.6365076662996842
Validation loss: 2.7573696065411553

Epoch: 5| Step: 4
Training loss: 0.6211670646342088
Validation loss: 2.6921980587720316

Epoch: 5| Step: 5
Training loss: 0.49380871025343287
Validation loss: 2.7796775215860423

Epoch: 5| Step: 6
Training loss: 0.46795902273929874
Validation loss: 2.741557259874399

Epoch: 5| Step: 7
Training loss: 0.6302464817785703
Validation loss: 2.720446948578535

Epoch: 5| Step: 8
Training loss: 0.6169159207207072
Validation loss: 2.750491365692524

Epoch: 5| Step: 9
Training loss: 0.7736454693713055
Validation loss: 2.7467774236054314

Epoch: 5| Step: 10
Training loss: 1.5158927916864176
Validation loss: 2.7350242461583267

Epoch: 5| Step: 11
Training loss: 0.5549348091810388
Validation loss: 2.7573478710776196

Epoch: 218| Step: 0
Training loss: 0.5263842578165308
Validation loss: 2.7500280610011125

Epoch: 5| Step: 1
Training loss: 1.437363493699071
Validation loss: 2.7259435998761714

Epoch: 5| Step: 2
Training loss: 0.5365039534445343
Validation loss: 2.665032871006639

Epoch: 5| Step: 3
Training loss: 0.5512367691562863
Validation loss: 2.7003278169777705

Epoch: 5| Step: 4
Training loss: 0.8903673368137862
Validation loss: 2.695229979647802

Epoch: 5| Step: 5
Training loss: 0.7463816940935067
Validation loss: 2.7360824558179697

Epoch: 5| Step: 6
Training loss: 0.6187040552748418
Validation loss: 2.719373306353378

Epoch: 5| Step: 7
Training loss: 0.4022794135051843
Validation loss: 2.724355097382435

Epoch: 5| Step: 8
Training loss: 0.6074781238478886
Validation loss: 2.749691331764416

Epoch: 5| Step: 9
Training loss: 0.7959672207744448
Validation loss: 2.7243979222727073

Epoch: 5| Step: 10
Training loss: 0.7054228851177963
Validation loss: 2.719967357630131

Epoch: 5| Step: 11
Training loss: 0.45603353055118284
Validation loss: 2.732340515394251

Epoch: 219| Step: 0
Training loss: 0.6385389650504465
Validation loss: 2.7302604272018804

Epoch: 5| Step: 1
Training loss: 0.5693851927296121
Validation loss: 2.6865018942886794

Epoch: 5| Step: 2
Training loss: 0.8362759769436385
Validation loss: 2.7455730568609185

Epoch: 5| Step: 3
Training loss: 0.5764639162795748
Validation loss: 2.728374909923252

Epoch: 5| Step: 4
Training loss: 0.5850801426041166
Validation loss: 2.6615943102555364

Epoch: 5| Step: 5
Training loss: 0.6118382771959999
Validation loss: 2.7770580604435375

Epoch: 5| Step: 6
Training loss: 0.5941415298926531
Validation loss: 2.7471783568498753

Epoch: 5| Step: 7
Training loss: 0.284897203227114
Validation loss: 2.6756958551076147

Epoch: 5| Step: 8
Training loss: 0.7853389166909828
Validation loss: 2.716280769563587

Epoch: 5| Step: 9
Training loss: 1.5576813974568986
Validation loss: 2.6835051794488423

Epoch: 5| Step: 10
Training loss: 0.8383954001544391
Validation loss: 2.7472502297723507

Epoch: 5| Step: 11
Training loss: 0.15843547430379962
Validation loss: 2.6427365349776095

Epoch: 220| Step: 0
Training loss: 0.4568666014832196
Validation loss: 2.7416025789552525

Epoch: 5| Step: 1
Training loss: 0.5112352197930947
Validation loss: 2.7715897794344393

Epoch: 5| Step: 2
Training loss: 0.611060208731756
Validation loss: 2.699233357325113

Epoch: 5| Step: 3
Training loss: 0.6727549534774429
Validation loss: 2.7306453227524328

Epoch: 5| Step: 4
Training loss: 0.5831962293765278
Validation loss: 2.6611516082753175

Epoch: 5| Step: 5
Training loss: 0.6430014749127405
Validation loss: 2.6570015760284753

Epoch: 5| Step: 6
Training loss: 0.6359643972646309
Validation loss: 2.6521189785879526

Epoch: 5| Step: 7
Training loss: 0.5163208283428136
Validation loss: 2.7560476720453604

Epoch: 5| Step: 8
Training loss: 0.607994275994712
Validation loss: 2.6862852655885474

Epoch: 5| Step: 9
Training loss: 1.5508069245257394
Validation loss: 2.720098522782632

Epoch: 5| Step: 10
Training loss: 0.8134858679267817
Validation loss: 2.744313740728188

Epoch: 5| Step: 11
Training loss: 0.4230123306781334
Validation loss: 2.7450329109354468

Epoch: 221| Step: 0
Training loss: 0.5042622809212483
Validation loss: 2.7401950549682703

Epoch: 5| Step: 1
Training loss: 0.926361803316237
Validation loss: 2.6808896162686096

Epoch: 5| Step: 2
Training loss: 1.3978513203037464
Validation loss: 2.731625858868664

Epoch: 5| Step: 3
Training loss: 0.6184054802715299
Validation loss: 2.693129306747571

Epoch: 5| Step: 4
Training loss: 0.6607126904251105
Validation loss: 2.7399620633213884

Epoch: 5| Step: 5
Training loss: 0.684120476654617
Validation loss: 2.6598155120400624

Epoch: 5| Step: 6
Training loss: 0.5330406472397072
Validation loss: 2.6906847787286994

Epoch: 5| Step: 7
Training loss: 0.542691331427463
Validation loss: 2.6179019692924324

Epoch: 5| Step: 8
Training loss: 0.6548017916461456
Validation loss: 2.6246039000889954

Epoch: 5| Step: 9
Training loss: 0.3179464646386569
Validation loss: 2.7084480346941944

Epoch: 5| Step: 10
Training loss: 0.576604544907943
Validation loss: 2.642166255968542

Epoch: 5| Step: 11
Training loss: 0.5939576639122359
Validation loss: 2.723049589666585

Epoch: 222| Step: 0
Training loss: 0.42021275581197526
Validation loss: 2.722905013086958

Epoch: 5| Step: 1
Training loss: 0.5514757093490976
Validation loss: 2.7171969453992237

Epoch: 5| Step: 2
Training loss: 0.7956945614548236
Validation loss: 2.798030674889398

Epoch: 5| Step: 3
Training loss: 0.6851353945543016
Validation loss: 2.726332387896357

Epoch: 5| Step: 4
Training loss: 0.47358130735377585
Validation loss: 2.7080923755757462

Epoch: 5| Step: 5
Training loss: 0.3495857401269775
Validation loss: 2.6610664233404493

Epoch: 5| Step: 6
Training loss: 1.446084141300043
Validation loss: 2.6558207557766615

Epoch: 5| Step: 7
Training loss: 0.8028776314799341
Validation loss: 2.656330698320835

Epoch: 5| Step: 8
Training loss: 0.6570509609391011
Validation loss: 2.6760066213623284

Epoch: 5| Step: 9
Training loss: 0.7980427880539623
Validation loss: 2.6372525878015063

Epoch: 5| Step: 10
Training loss: 0.6597500516364572
Validation loss: 2.6875505553525

Epoch: 5| Step: 11
Training loss: 0.34253995502228185
Validation loss: 2.7531782409969976

Epoch: 223| Step: 0
Training loss: 0.7675280372642783
Validation loss: 2.7860133959661972

Epoch: 5| Step: 1
Training loss: 0.5088523195741436
Validation loss: 2.682329441779839

Epoch: 5| Step: 2
Training loss: 0.6417727075206913
Validation loss: 2.6782631049496546

Epoch: 5| Step: 3
Training loss: 1.4446667027446307
Validation loss: 2.697467985119363

Epoch: 5| Step: 4
Training loss: 0.6919512567304336
Validation loss: 2.7102700620190867

Epoch: 5| Step: 5
Training loss: 0.5165314942347288
Validation loss: 2.7064816906533635

Epoch: 5| Step: 6
Training loss: 0.4154540018517668
Validation loss: 2.713697023880589

Epoch: 5| Step: 7
Training loss: 0.7528624349955139
Validation loss: 2.757666039112391

Epoch: 5| Step: 8
Training loss: 0.49330996630665724
Validation loss: 2.6458226163652094

Epoch: 5| Step: 9
Training loss: 1.090280643521462
Validation loss: 2.7231916195881323

Epoch: 5| Step: 10
Training loss: 0.5424645916858349
Validation loss: 2.707711208244438

Epoch: 5| Step: 11
Training loss: 0.4492089809516494
Validation loss: 2.656383355850941

Epoch: 224| Step: 0
Training loss: 0.5965680456528196
Validation loss: 2.6072776649780898

Epoch: 5| Step: 1
Training loss: 0.5989223110036862
Validation loss: 2.6974247197938586

Epoch: 5| Step: 2
Training loss: 1.4732951996616528
Validation loss: 2.6730178299984826

Epoch: 5| Step: 3
Training loss: 0.4893399624564971
Validation loss: 2.7317361832497933

Epoch: 5| Step: 4
Training loss: 0.41905251934162185
Validation loss: 2.696975942898081

Epoch: 5| Step: 5
Training loss: 0.5743378496245237
Validation loss: 2.704644072191534

Epoch: 5| Step: 6
Training loss: 0.5855902342110356
Validation loss: 2.6621581866313315

Epoch: 5| Step: 7
Training loss: 0.940262253731904
Validation loss: 2.6230425461813627

Epoch: 5| Step: 8
Training loss: 0.6195924957134942
Validation loss: 2.7240383192369606

Epoch: 5| Step: 9
Training loss: 0.8995117730859317
Validation loss: 2.6387527268957482

Epoch: 5| Step: 10
Training loss: 0.6185159269377682
Validation loss: 2.6654326382539604

Epoch: 5| Step: 11
Training loss: 0.5497555211038461
Validation loss: 2.657632015707698

Epoch: 225| Step: 0
Training loss: 0.5686419856028702
Validation loss: 2.664808618169872

Epoch: 5| Step: 1
Training loss: 0.5362881572637115
Validation loss: 2.7349313587755075

Epoch: 5| Step: 2
Training loss: 1.299065039115812
Validation loss: 2.6936096045659994

Epoch: 5| Step: 3
Training loss: 0.45924295486877464
Validation loss: 2.7021010780389076

Epoch: 5| Step: 4
Training loss: 0.482111564634967
Validation loss: 2.7017520769629635

Epoch: 5| Step: 5
Training loss: 0.4843541725357009
Validation loss: 2.681351485180585

Epoch: 5| Step: 6
Training loss: 0.5693692022587441
Validation loss: 2.6312001231156157

Epoch: 5| Step: 7
Training loss: 0.8243820607170033
Validation loss: 2.62965623833609

Epoch: 5| Step: 8
Training loss: 0.5610507733833239
Validation loss: 2.695742207057618

Epoch: 5| Step: 9
Training loss: 0.6461312980765561
Validation loss: 2.7116180393893603

Epoch: 5| Step: 10
Training loss: 0.7115909382092511
Validation loss: 2.700009025599853

Epoch: 5| Step: 11
Training loss: 1.1236549920303862
Validation loss: 2.6983908134740813

Epoch: 226| Step: 0
Training loss: 0.7309889139829877
Validation loss: 2.715538034923224

Epoch: 5| Step: 1
Training loss: 0.5733495348574431
Validation loss: 2.6622967429027726

Epoch: 5| Step: 2
Training loss: 1.3101020888232482
Validation loss: 2.7043558104295404

Epoch: 5| Step: 3
Training loss: 0.41500358878732585
Validation loss: 2.5628423810969787

Epoch: 5| Step: 4
Training loss: 0.4739353432860936
Validation loss: 2.6462567220934945

Epoch: 5| Step: 5
Training loss: 0.7081252428207587
Validation loss: 2.6274583786796275

Epoch: 5| Step: 6
Training loss: 0.4606597516163769
Validation loss: 2.6295539621078796

Epoch: 5| Step: 7
Training loss: 1.0139756528463217
Validation loss: 2.5257812142876053

Epoch: 5| Step: 8
Training loss: 0.6330976432470822
Validation loss: 2.6561056920663217

Epoch: 5| Step: 9
Training loss: 0.5139097236012539
Validation loss: 2.7145111026556767

Epoch: 5| Step: 10
Training loss: 0.7914715241968607
Validation loss: 2.69173836469871

Epoch: 5| Step: 11
Training loss: 0.7467323087110637
Validation loss: 2.490216567031915

Epoch: 227| Step: 0
Training loss: 0.6870402402725542
Validation loss: 2.6873664896722467

Epoch: 5| Step: 1
Training loss: 0.5358944833913953
Validation loss: 2.6782566435844353

Epoch: 5| Step: 2
Training loss: 0.355428148403204
Validation loss: 2.5971279821337596

Epoch: 5| Step: 3
Training loss: 0.8299519880610081
Validation loss: 2.733192642349554

Epoch: 5| Step: 4
Training loss: 0.9275956542052687
Validation loss: 2.7281658009336196

Epoch: 5| Step: 5
Training loss: 1.3639976127721083
Validation loss: 2.7024807630854712

Epoch: 5| Step: 6
Training loss: 0.6589197621216325
Validation loss: 2.6315410045347902

Epoch: 5| Step: 7
Training loss: 0.5949147745611678
Validation loss: 2.7275017866571103

Epoch: 5| Step: 8
Training loss: 0.5769967591477322
Validation loss: 2.7173246432780154

Epoch: 5| Step: 9
Training loss: 0.5258577957095601
Validation loss: 2.7510731691065957

Epoch: 5| Step: 10
Training loss: 0.5339046795525813
Validation loss: 2.6640248300642915

Epoch: 5| Step: 11
Training loss: 0.7861116205048305
Validation loss: 2.6551394890028504

Epoch: 228| Step: 0
Training loss: 0.7095561598635052
Validation loss: 2.7641348155646437

Epoch: 5| Step: 1
Training loss: 0.4486968284176031
Validation loss: 2.636770889331857

Epoch: 5| Step: 2
Training loss: 1.4054643343590525
Validation loss: 2.7729513252627807

Epoch: 5| Step: 3
Training loss: 0.6751926482757451
Validation loss: 2.678095768368758

Epoch: 5| Step: 4
Training loss: 0.6327838184779868
Validation loss: 2.746164005370241

Epoch: 5| Step: 5
Training loss: 0.557409404783565
Validation loss: 2.6654820878304726

Epoch: 5| Step: 6
Training loss: 0.4187885871587759
Validation loss: 2.6910634922970464

Epoch: 5| Step: 7
Training loss: 0.6452376222927134
Validation loss: 2.6738606449338858

Epoch: 5| Step: 8
Training loss: 0.7135298280128307
Validation loss: 2.6099538294348945

Epoch: 5| Step: 9
Training loss: 0.6585755016473133
Validation loss: 2.674869595525027

Epoch: 5| Step: 10
Training loss: 0.8150589334207899
Validation loss: 2.652967492959708

Epoch: 5| Step: 11
Training loss: 0.45414323513003446
Validation loss: 2.826689614073108

Epoch: 229| Step: 0
Training loss: 0.7920357613388963
Validation loss: 2.7608492506308937

Epoch: 5| Step: 1
Training loss: 1.3970166879092738
Validation loss: 2.741181017716124

Epoch: 5| Step: 2
Training loss: 0.8041503743183214
Validation loss: 2.6754832377931996

Epoch: 5| Step: 3
Training loss: 0.6319824709181585
Validation loss: 2.6591866285682033

Epoch: 5| Step: 4
Training loss: 0.6631392175227123
Validation loss: 2.6055992547502838

Epoch: 5| Step: 5
Training loss: 0.43188875066062665
Validation loss: 2.6262894729263597

Epoch: 5| Step: 6
Training loss: 0.9415081491365831
Validation loss: 2.646627173143119

Epoch: 5| Step: 7
Training loss: 0.6761075593628171
Validation loss: 2.706402858443277

Epoch: 5| Step: 8
Training loss: 0.44450303174176775
Validation loss: 2.6996473642821717

Epoch: 5| Step: 9
Training loss: 0.512680925439879
Validation loss: 2.6311718727527955

Epoch: 5| Step: 10
Training loss: 0.5082196290886365
Validation loss: 2.728619682059029

Epoch: 5| Step: 11
Training loss: 0.42373591180186027
Validation loss: 2.7068930770010877

Epoch: 230| Step: 0
Training loss: 0.7030913027000146
Validation loss: 2.7729697034441574

Epoch: 5| Step: 1
Training loss: 0.7299475212699444
Validation loss: 2.7764439544816817

Epoch: 5| Step: 2
Training loss: 0.6368086113735675
Validation loss: 2.716122565287149

Epoch: 5| Step: 3
Training loss: 0.6720217832755752
Validation loss: 2.7182091142029656

Epoch: 5| Step: 4
Training loss: 0.30920469191382277
Validation loss: 2.63026666985709

Epoch: 5| Step: 5
Training loss: 0.608376050999527
Validation loss: 2.619832910070242

Epoch: 5| Step: 6
Training loss: 1.4507522900576597
Validation loss: 2.6390282244175816

Epoch: 5| Step: 7
Training loss: 0.8780444858334218
Validation loss: 2.6591668644078856

Epoch: 5| Step: 8
Training loss: 0.6560860156488922
Validation loss: 2.7122355970969036

Epoch: 5| Step: 9
Training loss: 0.574036653670905
Validation loss: 2.67672569889334

Epoch: 5| Step: 10
Training loss: 0.5884352027900899
Validation loss: 2.751132887069732

Epoch: 5| Step: 11
Training loss: 0.5770459802246759
Validation loss: 2.6913981444481765

Epoch: 231| Step: 0
Training loss: 0.8386389318569244
Validation loss: 2.7322805903030027

Epoch: 5| Step: 1
Training loss: 0.5344551673228947
Validation loss: 2.6152237504245206

Epoch: 5| Step: 2
Training loss: 0.6103567138454489
Validation loss: 2.7476293865326364

Epoch: 5| Step: 3
Training loss: 0.4868339910363457
Validation loss: 2.688192692282543

Epoch: 5| Step: 4
Training loss: 0.7316768264572011
Validation loss: 2.6853903097117513

Epoch: 5| Step: 5
Training loss: 0.7933993744075761
Validation loss: 2.6020261219679433

Epoch: 5| Step: 6
Training loss: 1.4074348544396564
Validation loss: 2.6434443018263147

Epoch: 5| Step: 7
Training loss: 0.5492968746527654
Validation loss: 2.5857738316306387

Epoch: 5| Step: 8
Training loss: 0.4436586353108636
Validation loss: 2.593114437995977

Epoch: 5| Step: 9
Training loss: 0.5999470111177648
Validation loss: 2.691272328094121

Epoch: 5| Step: 10
Training loss: 0.46573926112560926
Validation loss: 2.6601625499379997

Epoch: 5| Step: 11
Training loss: 0.6853833560521188
Validation loss: 2.6919610236536076

Epoch: 232| Step: 0
Training loss: 0.5198025389498137
Validation loss: 2.7360247585194686

Epoch: 5| Step: 1
Training loss: 0.5995155285883383
Validation loss: 2.754654824533178

Epoch: 5| Step: 2
Training loss: 0.5309147899187159
Validation loss: 2.644609582549454

Epoch: 5| Step: 3
Training loss: 0.7590450213553046
Validation loss: 2.7185653061084647

Epoch: 5| Step: 4
Training loss: 0.4574781498876489
Validation loss: 2.6967122815293623

Epoch: 5| Step: 5
Training loss: 0.5019361144274612
Validation loss: 2.6815396535543514

Epoch: 5| Step: 6
Training loss: 0.45695172131447204
Validation loss: 2.6637736412800073

Epoch: 5| Step: 7
Training loss: 1.317626251961262
Validation loss: 2.580329599766194

Epoch: 5| Step: 8
Training loss: 0.7172182595964066
Validation loss: 2.6568739064831375

Epoch: 5| Step: 9
Training loss: 0.6554794556172003
Validation loss: 2.5954981891148345

Epoch: 5| Step: 10
Training loss: 0.5787561167894264
Validation loss: 2.702522438525487

Epoch: 5| Step: 11
Training loss: 0.7042123228617336
Validation loss: 2.685275347305516

Epoch: 233| Step: 0
Training loss: 1.2943787046901674
Validation loss: 2.709178526140639

Epoch: 5| Step: 1
Training loss: 0.9867012753302193
Validation loss: 2.687513310746934

Epoch: 5| Step: 2
Training loss: 0.6051687666477393
Validation loss: 2.7563610093474993

Epoch: 5| Step: 3
Training loss: 0.44388475252576154
Validation loss: 2.695283721917623

Epoch: 5| Step: 4
Training loss: 0.45070377854332744
Validation loss: 2.6845064309407225

Epoch: 5| Step: 5
Training loss: 0.40325596552395787
Validation loss: 2.690487956427436

Epoch: 5| Step: 6
Training loss: 0.5785271560374907
Validation loss: 2.6571955923798924

Epoch: 5| Step: 7
Training loss: 0.6174803895963841
Validation loss: 2.6207105391522547

Epoch: 5| Step: 8
Training loss: 0.5232618236381458
Validation loss: 2.6833865563719885

Epoch: 5| Step: 9
Training loss: 0.5689110978403754
Validation loss: 2.711177668710977

Epoch: 5| Step: 10
Training loss: 0.5429540398889787
Validation loss: 2.734545115674101

Epoch: 5| Step: 11
Training loss: 0.46836913848703243
Validation loss: 2.735072328568863

Epoch: 234| Step: 0
Training loss: 0.5395654184418706
Validation loss: 2.649218821921648

Epoch: 5| Step: 1
Training loss: 0.5327058925978038
Validation loss: 2.70182095202026

Epoch: 5| Step: 2
Training loss: 0.32490059955611467
Validation loss: 2.6831997170757327

Epoch: 5| Step: 3
Training loss: 0.4767043574838436
Validation loss: 2.692015255557947

Epoch: 5| Step: 4
Training loss: 0.513554519765874
Validation loss: 2.6811988709353582

Epoch: 5| Step: 5
Training loss: 0.5905190700823862
Validation loss: 2.686870693485216

Epoch: 5| Step: 6
Training loss: 1.398926505576274
Validation loss: 2.6966387042936617

Epoch: 5| Step: 7
Training loss: 0.5226360562333618
Validation loss: 2.621939763726881

Epoch: 5| Step: 8
Training loss: 0.8833136022511342
Validation loss: 2.62770456488376

Epoch: 5| Step: 9
Training loss: 0.536799171341798
Validation loss: 2.6360012575860705

Epoch: 5| Step: 10
Training loss: 0.6443569294405715
Validation loss: 2.733744379621257

Epoch: 5| Step: 11
Training loss: 0.45102421709919593
Validation loss: 2.6456892332249913

Epoch: 235| Step: 0
Training loss: 0.449657955246243
Validation loss: 2.7192280831319557

Epoch: 5| Step: 1
Training loss: 0.6558137760817047
Validation loss: 2.6920088161300053

Epoch: 5| Step: 2
Training loss: 0.39788589441770583
Validation loss: 2.642876081263808

Epoch: 5| Step: 3
Training loss: 0.8220688319357176
Validation loss: 2.6772342347438958

Epoch: 5| Step: 4
Training loss: 0.631488639744463
Validation loss: 2.752179106076572

Epoch: 5| Step: 5
Training loss: 0.4367299967291781
Validation loss: 2.654056222844521

Epoch: 5| Step: 6
Training loss: 0.42028312225911846
Validation loss: 2.690026363689133

Epoch: 5| Step: 7
Training loss: 0.4437004659434467
Validation loss: 2.702341418170171

Epoch: 5| Step: 8
Training loss: 0.7491057946238311
Validation loss: 2.6465889641434135

Epoch: 5| Step: 9
Training loss: 0.6767272942337673
Validation loss: 2.702906355348382

Epoch: 5| Step: 10
Training loss: 1.407061618136198
Validation loss: 2.6794439340415575

Epoch: 5| Step: 11
Training loss: 0.3783966649119205
Validation loss: 2.6433118547306154

Epoch: 236| Step: 0
Training loss: 0.6018955002617957
Validation loss: 2.694714207980459

Epoch: 5| Step: 1
Training loss: 1.4547453019636136
Validation loss: 2.6936782673949162

Epoch: 5| Step: 2
Training loss: 0.5175074978990146
Validation loss: 2.7416115035408377

Epoch: 5| Step: 3
Training loss: 0.6925779640640786
Validation loss: 2.642831892153128

Epoch: 5| Step: 4
Training loss: 0.5392564894436498
Validation loss: 2.6797807749537985

Epoch: 5| Step: 5
Training loss: 0.4544538546512564
Validation loss: 2.693606556409188

Epoch: 5| Step: 6
Training loss: 0.43904937846712466
Validation loss: 2.6814098921068417

Epoch: 5| Step: 7
Training loss: 0.5251599624443549
Validation loss: 2.5992584488434725

Epoch: 5| Step: 8
Training loss: 0.5313916017644007
Validation loss: 2.7430597097362712

Epoch: 5| Step: 9
Training loss: 0.43844354585923234
Validation loss: 2.6445965178947217

Epoch: 5| Step: 10
Training loss: 0.5948159286930902
Validation loss: 2.7346544976666576

Epoch: 5| Step: 11
Training loss: 0.3993370149723455
Validation loss: 2.704812642094274

Epoch: 237| Step: 0
Training loss: 0.6928744917524807
Validation loss: 2.7436752811705722

Epoch: 5| Step: 1
Training loss: 0.8316696527449132
Validation loss: 2.7082768336540513

Epoch: 5| Step: 2
Training loss: 0.34908794966005663
Validation loss: 2.7249651787075857

Epoch: 5| Step: 3
Training loss: 0.7378629276374369
Validation loss: 2.6979675668655037

Epoch: 5| Step: 4
Training loss: 0.45168295313033935
Validation loss: 2.79438067407273

Epoch: 5| Step: 5
Training loss: 0.6718534865372687
Validation loss: 2.6705147253150834

Epoch: 5| Step: 6
Training loss: 0.5582668708510413
Validation loss: 2.649213592785265

Epoch: 5| Step: 7
Training loss: 0.4968115652125705
Validation loss: 2.6239759854738467

Epoch: 5| Step: 8
Training loss: 0.47749537480695675
Validation loss: 2.70544366489861

Epoch: 5| Step: 9
Training loss: 0.5897609324135294
Validation loss: 2.6481889516205808

Epoch: 5| Step: 10
Training loss: 1.4100778827395442
Validation loss: 2.620941574598682

Epoch: 5| Step: 11
Training loss: 0.6215783154300879
Validation loss: 2.6648470486878013

Epoch: 238| Step: 0
Training loss: 0.5691845857900214
Validation loss: 2.654014106380256

Epoch: 5| Step: 1
Training loss: 0.5706236787260538
Validation loss: 2.680869673050916

Epoch: 5| Step: 2
Training loss: 0.4481881634770213
Validation loss: 2.7044621028968403

Epoch: 5| Step: 3
Training loss: 1.3081784172834483
Validation loss: 2.7121572691094857

Epoch: 5| Step: 4
Training loss: 0.5441224445008714
Validation loss: 2.766773994549029

Epoch: 5| Step: 5
Training loss: 0.4585685794557828
Validation loss: 2.7139040667743823

Epoch: 5| Step: 6
Training loss: 0.22821888853202374
Validation loss: 2.723915389082897

Epoch: 5| Step: 7
Training loss: 0.5974017330588971
Validation loss: 2.7558862877245174

Epoch: 5| Step: 8
Training loss: 0.7750878884102657
Validation loss: 2.6517329235978218

Epoch: 5| Step: 9
Training loss: 0.825663164225565
Validation loss: 2.699424187460191

Epoch: 5| Step: 10
Training loss: 0.487123046536306
Validation loss: 2.707075829664081

Epoch: 5| Step: 11
Training loss: 0.3250561551034267
Validation loss: 2.8020041370663087

Epoch: 239| Step: 0
Training loss: 0.5084452281849904
Validation loss: 2.802432968467779

Epoch: 5| Step: 1
Training loss: 0.5794356670529636
Validation loss: 2.761615476066692

Epoch: 5| Step: 2
Training loss: 1.4265419798729955
Validation loss: 2.7632336380264557

Epoch: 5| Step: 3
Training loss: 0.8688009219717083
Validation loss: 2.7272439522260776

Epoch: 5| Step: 4
Training loss: 0.3178977779315868
Validation loss: 2.7445966095113676

Epoch: 5| Step: 5
Training loss: 0.46578632286710686
Validation loss: 2.807937195163158

Epoch: 5| Step: 6
Training loss: 0.6966456587565623
Validation loss: 2.6492405651937627

Epoch: 5| Step: 7
Training loss: 0.46120209292634184
Validation loss: 2.737896597016622

Epoch: 5| Step: 8
Training loss: 0.48307339307516484
Validation loss: 2.7400584201780194

Epoch: 5| Step: 9
Training loss: 0.3833677780010933
Validation loss: 2.654560868489473

Epoch: 5| Step: 10
Training loss: 0.3035827930611253
Validation loss: 2.7025810495562803

Epoch: 5| Step: 11
Training loss: 0.34179950168145284
Validation loss: 2.7033540430218403

Epoch: 240| Step: 0
Training loss: 1.2824826242708716
Validation loss: 2.7982024695639933

Epoch: 5| Step: 1
Training loss: 0.3990762863227346
Validation loss: 2.7550873444402617

Epoch: 5| Step: 2
Training loss: 0.4534090072860345
Validation loss: 2.7194310756586804

Epoch: 5| Step: 3
Training loss: 0.5469060616527504
Validation loss: 2.76914398541854

Epoch: 5| Step: 4
Training loss: 0.6011710689308756
Validation loss: 2.8263699335394183

Epoch: 5| Step: 5
Training loss: 0.3976853695383279
Validation loss: 2.7176402264140944

Epoch: 5| Step: 6
Training loss: 0.38826784383245805
Validation loss: 2.677459609952595

Epoch: 5| Step: 7
Training loss: 0.6214789869265522
Validation loss: 2.7103745483382577

Epoch: 5| Step: 8
Training loss: 0.4220000717413873
Validation loss: 2.7277999081224316

Epoch: 5| Step: 9
Training loss: 0.6609590828981157
Validation loss: 2.7774731176250276

Epoch: 5| Step: 10
Training loss: 0.868712278960526
Validation loss: 2.771711917682905

Epoch: 5| Step: 11
Training loss: 0.8449846347563033
Validation loss: 2.784630940366324

Epoch: 241| Step: 0
Training loss: 0.5191205344463895
Validation loss: 2.7394579881680863

Epoch: 5| Step: 1
Training loss: 0.4836093635072245
Validation loss: 2.7452041899886317

Epoch: 5| Step: 2
Training loss: 0.6789240001820703
Validation loss: 2.786107029858515

Epoch: 5| Step: 3
Training loss: 0.6715604134336837
Validation loss: 2.7725897876967487

Epoch: 5| Step: 4
Training loss: 0.42198804824184655
Validation loss: 2.6955758818418856

Epoch: 5| Step: 5
Training loss: 0.5615926417952817
Validation loss: 2.681861303426806

Epoch: 5| Step: 6
Training loss: 0.6938585230857558
Validation loss: 2.6759670128116078

Epoch: 5| Step: 7
Training loss: 0.5775060433323386
Validation loss: 2.7609162916121983

Epoch: 5| Step: 8
Training loss: 0.5738333881674341
Validation loss: 2.7098475490366667

Epoch: 5| Step: 9
Training loss: 0.5378111814563643
Validation loss: 2.650006878592003

Epoch: 5| Step: 10
Training loss: 1.2931162585796858
Validation loss: 2.781359652525757

Epoch: 5| Step: 11
Training loss: 0.6036554069736307
Validation loss: 2.6991484909372145

Epoch: 242| Step: 0
Training loss: 1.3221479219821144
Validation loss: 2.7628454619519194

Epoch: 5| Step: 1
Training loss: 0.5560683403844645
Validation loss: 2.6727841709883102

Epoch: 5| Step: 2
Training loss: 0.4770135464774027
Validation loss: 2.6932173210379773

Epoch: 5| Step: 3
Training loss: 0.7427393417697907
Validation loss: 2.6962177875571185

Epoch: 5| Step: 4
Training loss: 0.49177167371879943
Validation loss: 2.66280557583271

Epoch: 5| Step: 5
Training loss: 0.586535466566533
Validation loss: 2.734651300911936

Epoch: 5| Step: 6
Training loss: 0.6260464490897194
Validation loss: 2.7184718563406776

Epoch: 5| Step: 7
Training loss: 0.294783945229619
Validation loss: 2.7147264889794673

Epoch: 5| Step: 8
Training loss: 0.44505972129319693
Validation loss: 2.730235510502489

Epoch: 5| Step: 9
Training loss: 0.3834065868349156
Validation loss: 2.701742531679831

Epoch: 5| Step: 10
Training loss: 0.797711737157162
Validation loss: 2.6900271687500545

Epoch: 5| Step: 11
Training loss: 0.3451156797521845
Validation loss: 2.695295250878909

Epoch: 243| Step: 0
Training loss: 0.794386062184886
Validation loss: 2.704711389757501

Epoch: 5| Step: 1
Training loss: 0.47776558151067766
Validation loss: 2.721662674836897

Epoch: 5| Step: 2
Training loss: 0.4621116102846568
Validation loss: 2.7006900345642686

Epoch: 5| Step: 3
Training loss: 0.6616260260929502
Validation loss: 2.6660710404706975

Epoch: 5| Step: 4
Training loss: 0.6491615665008554
Validation loss: 2.7907835586060177

Epoch: 5| Step: 5
Training loss: 0.6367683157321662
Validation loss: 2.753340097945157

Epoch: 5| Step: 6
Training loss: 0.4598510837780242
Validation loss: 2.6878462021386125

Epoch: 5| Step: 7
Training loss: 0.46619934080393144
Validation loss: 2.672427059048897

Epoch: 5| Step: 8
Training loss: 0.5126355526927913
Validation loss: 2.759205388076169

Epoch: 5| Step: 9
Training loss: 1.3804277449575049
Validation loss: 2.7566141076902917

Epoch: 5| Step: 10
Training loss: 0.5342576215893873
Validation loss: 2.696725272364842

Epoch: 5| Step: 11
Training loss: 0.3105682389690046
Validation loss: 2.6745572002929103

Epoch: 244| Step: 0
Training loss: 0.6245714387233982
Validation loss: 2.745462781932098

Epoch: 5| Step: 1
Training loss: 0.5904715020670053
Validation loss: 2.740617199215721

Epoch: 5| Step: 2
Training loss: 0.47999752786615657
Validation loss: 2.759083085047598

Epoch: 5| Step: 3
Training loss: 0.4540837930463589
Validation loss: 2.754478662039237

Epoch: 5| Step: 4
Training loss: 0.7387179339657844
Validation loss: 2.769447289518219

Epoch: 5| Step: 5
Training loss: 0.5509372787778067
Validation loss: 2.766587095428139

Epoch: 5| Step: 6
Training loss: 1.3340247666148835
Validation loss: 2.7187541837404297

Epoch: 5| Step: 7
Training loss: 0.4463401114151177
Validation loss: 2.735479938146244

Epoch: 5| Step: 8
Training loss: 0.7617718017883557
Validation loss: 2.6171867028989575

Epoch: 5| Step: 9
Training loss: 0.5663229256211165
Validation loss: 2.721245435279542

Epoch: 5| Step: 10
Training loss: 0.8902232954031285
Validation loss: 2.7178423049577343

Epoch: 5| Step: 11
Training loss: 0.3420508394865885
Validation loss: 2.6274705304030617

Epoch: 245| Step: 0
Training loss: 0.6357760793907378
Validation loss: 2.6586432016776627

Epoch: 5| Step: 1
Training loss: 0.5521020136377931
Validation loss: 2.6951674417723392

Epoch: 5| Step: 2
Training loss: 0.5654029642223735
Validation loss: 2.720783927102823

Epoch: 5| Step: 3
Training loss: 0.4951086852417716
Validation loss: 2.830864396267819

Epoch: 5| Step: 4
Training loss: 1.2777245563443538
Validation loss: 2.6760745627961455

Epoch: 5| Step: 5
Training loss: 0.46293264914538895
Validation loss: 2.6630936815899733

Epoch: 5| Step: 6
Training loss: 0.39334748448088436
Validation loss: 2.698699323376562

Epoch: 5| Step: 7
Training loss: 0.665608077214708
Validation loss: 2.7050604956244078

Epoch: 5| Step: 8
Training loss: 0.6916591806657736
Validation loss: 2.771462510076241

Epoch: 5| Step: 9
Training loss: 0.3950245106009561
Validation loss: 2.7527323788918534

Epoch: 5| Step: 10
Training loss: 0.549500620153492
Validation loss: 2.7129172023334616

Epoch: 5| Step: 11
Training loss: 0.4074410255737194
Validation loss: 2.725021181695024

Epoch: 246| Step: 0
Training loss: 0.42155211066132886
Validation loss: 2.6995344515617714

Epoch: 5| Step: 1
Training loss: 0.5952301148606255
Validation loss: 2.6221535894996917

Epoch: 5| Step: 2
Training loss: 0.38928373856249365
Validation loss: 2.6278229702049014

Epoch: 5| Step: 3
Training loss: 0.7972283421442864
Validation loss: 2.7859850127939128

Epoch: 5| Step: 4
Training loss: 0.5532637309005054
Validation loss: 2.7203307105719667

Epoch: 5| Step: 5
Training loss: 0.5598590897916073
Validation loss: 2.7175761260986286

Epoch: 5| Step: 6
Training loss: 1.2251347292554728
Validation loss: 2.6894426901990496

Epoch: 5| Step: 7
Training loss: 0.36766153538475926
Validation loss: 2.658583752776541

Epoch: 5| Step: 8
Training loss: 0.5779380753898871
Validation loss: 2.6932890331662427

Epoch: 5| Step: 9
Training loss: 0.6342885028894106
Validation loss: 2.7033620226953032

Epoch: 5| Step: 10
Training loss: 0.5463952821498566
Validation loss: 2.6752283680665725

Epoch: 5| Step: 11
Training loss: 0.7390933540468663
Validation loss: 2.7055553763526823

Epoch: 247| Step: 0
Training loss: 0.5222025294626512
Validation loss: 2.6454727022195836

Epoch: 5| Step: 1
Training loss: 0.302329438632282
Validation loss: 2.7184850373631937

Epoch: 5| Step: 2
Training loss: 0.39725744113350736
Validation loss: 2.6645614775734874

Epoch: 5| Step: 3
Training loss: 0.4418930137987585
Validation loss: 2.6307367996249087

Epoch: 5| Step: 4
Training loss: 0.6194158958999243
Validation loss: 2.6839647328181715

Epoch: 5| Step: 5
Training loss: 0.8596111319986034
Validation loss: 2.674478894276715

Epoch: 5| Step: 6
Training loss: 0.6250012636171919
Validation loss: 2.6519781805519815

Epoch: 5| Step: 7
Training loss: 0.39083130157135093
Validation loss: 2.749160797499857

Epoch: 5| Step: 8
Training loss: 0.4090813311445411
Validation loss: 2.7773113400856997

Epoch: 5| Step: 9
Training loss: 0.3127552897053997
Validation loss: 2.7469667843936465

Epoch: 5| Step: 10
Training loss: 1.3202787767426074
Validation loss: 2.7660491531897873

Epoch: 5| Step: 11
Training loss: 0.4291143409378596
Validation loss: 2.6991662674994163

Epoch: 248| Step: 0
Training loss: 0.47539577559703383
Validation loss: 2.692276122467911

Epoch: 5| Step: 1
Training loss: 0.5729603635134153
Validation loss: 2.7691632211460746

Epoch: 5| Step: 2
Training loss: 0.323054198489961
Validation loss: 2.702894619953286

Epoch: 5| Step: 3
Training loss: 0.654101100498878
Validation loss: 2.6739917943743445

Epoch: 5| Step: 4
Training loss: 0.6971891345214833
Validation loss: 2.6758117878231698

Epoch: 5| Step: 5
Training loss: 0.47935617541736814
Validation loss: 2.712198940539692

Epoch: 5| Step: 6
Training loss: 0.5433438878214163
Validation loss: 2.7235737025157927

Epoch: 5| Step: 7
Training loss: 0.5127344606984485
Validation loss: 2.632181995785691

Epoch: 5| Step: 8
Training loss: 1.2973599733562458
Validation loss: 2.7203069481965567

Epoch: 5| Step: 9
Training loss: 0.5007239108057454
Validation loss: 2.6831024771555962

Epoch: 5| Step: 10
Training loss: 0.5404051217802123
Validation loss: 2.7105894240892416

Epoch: 5| Step: 11
Training loss: 0.49138645805443854
Validation loss: 2.7330965050486173

Epoch: 249| Step: 0
Training loss: 0.6003101739237657
Validation loss: 2.666553987913942

Epoch: 5| Step: 1
Training loss: 0.5957414958665448
Validation loss: 2.7070040497323857

Epoch: 5| Step: 2
Training loss: 0.850020876796379
Validation loss: 2.658230039827941

Epoch: 5| Step: 3
Training loss: 0.3817104513895676
Validation loss: 2.717377919329974

Epoch: 5| Step: 4
Training loss: 0.6426224157032465
Validation loss: 2.836628065285531

Epoch: 5| Step: 5
Training loss: 0.4118954975833688
Validation loss: 2.6735212095566863

Epoch: 5| Step: 6
Training loss: 0.538285649341162
Validation loss: 2.689367432846285

Epoch: 5| Step: 7
Training loss: 0.5899800275800394
Validation loss: 2.7771054598009575

Epoch: 5| Step: 8
Training loss: 1.2420265525338405
Validation loss: 2.719169164185503

Epoch: 5| Step: 9
Training loss: 0.5217738687441309
Validation loss: 2.7600885676084634

Epoch: 5| Step: 10
Training loss: 0.5825127267879773
Validation loss: 2.6824525223186644

Epoch: 5| Step: 11
Training loss: 0.5901716722852295
Validation loss: 2.7346343398860222

Epoch: 250| Step: 0
Training loss: 0.47626881852604075
Validation loss: 2.6407266292540017

Epoch: 5| Step: 1
Training loss: 0.39320086909995555
Validation loss: 2.7094225539419794

Epoch: 5| Step: 2
Training loss: 0.5570493034444038
Validation loss: 2.7645340436227315

Epoch: 5| Step: 3
Training loss: 0.5305843671106919
Validation loss: 2.782144409837773

Epoch: 5| Step: 4
Training loss: 0.5989813482313303
Validation loss: 2.71329644474718

Epoch: 5| Step: 5
Training loss: 1.2549697311520258
Validation loss: 2.6701284057539274

Epoch: 5| Step: 6
Training loss: 0.6444388814686958
Validation loss: 2.777377783400932

Epoch: 5| Step: 7
Training loss: 0.5746602547406607
Validation loss: 2.6921304688969125

Epoch: 5| Step: 8
Training loss: 0.37718545345835236
Validation loss: 2.6745744531601616

Epoch: 5| Step: 9
Training loss: 0.4105963389527498
Validation loss: 2.681403284574535

Epoch: 5| Step: 10
Training loss: 0.7465133286095551
Validation loss: 2.7523363278429938

Epoch: 5| Step: 11
Training loss: 0.5862476291079863
Validation loss: 2.630845037514243

Epoch: 251| Step: 0
Training loss: 0.46533300793956556
Validation loss: 2.673505831925934

Epoch: 5| Step: 1
Training loss: 0.40664189949532165
Validation loss: 2.7192330497645254

Epoch: 5| Step: 2
Training loss: 0.6143988370103309
Validation loss: 2.6907938872827093

Epoch: 5| Step: 3
Training loss: 0.6772181498972111
Validation loss: 2.6855294003929577

Epoch: 5| Step: 4
Training loss: 1.3058564209170054
Validation loss: 2.7919735929571106

Epoch: 5| Step: 5
Training loss: 0.4895505505265842
Validation loss: 2.738199026893133

Epoch: 5| Step: 6
Training loss: 0.5753934094891892
Validation loss: 2.6722930484489695

Epoch: 5| Step: 7
Training loss: 0.8312479549755668
Validation loss: 2.6821742498135803

Epoch: 5| Step: 8
Training loss: 0.4281536990661116
Validation loss: 2.6217455823297335

Epoch: 5| Step: 9
Training loss: 0.8231944367847285
Validation loss: 2.617617371589455

Epoch: 5| Step: 10
Training loss: 0.5452948220346961
Validation loss: 2.611977233328188

Epoch: 5| Step: 11
Training loss: 0.238814219093974
Validation loss: 2.6062812891727813

Epoch: 252| Step: 0
Training loss: 0.5584734273580919
Validation loss: 2.6426528690779407

Epoch: 5| Step: 1
Training loss: 0.46442461752449954
Validation loss: 2.682244240548312

Epoch: 5| Step: 2
Training loss: 0.5778503280974076
Validation loss: 2.762151393787467

Epoch: 5| Step: 3
Training loss: 0.6599130803368157
Validation loss: 2.6299478244501326

Epoch: 5| Step: 4
Training loss: 0.4379623558511275
Validation loss: 2.7934850966833977

Epoch: 5| Step: 5
Training loss: 0.6118249306537784
Validation loss: 2.7743245385297293

Epoch: 5| Step: 6
Training loss: 0.5704460249015445
Validation loss: 2.7417207050698775

Epoch: 5| Step: 7
Training loss: 1.2473068311738031
Validation loss: 2.657780782131698

Epoch: 5| Step: 8
Training loss: 0.45529344891950807
Validation loss: 2.6886616310708886

Epoch: 5| Step: 9
Training loss: 0.4863511198804497
Validation loss: 2.6925885833636003

Epoch: 5| Step: 10
Training loss: 0.38201047610727284
Validation loss: 2.6779799549317893

Epoch: 5| Step: 11
Training loss: 0.49848492375842157
Validation loss: 2.6308634266377275

Epoch: 253| Step: 0
Training loss: 0.813826944607229
Validation loss: 2.7133031595057453

Epoch: 5| Step: 1
Training loss: 1.1971139734004732
Validation loss: 2.665110313960601

Epoch: 5| Step: 2
Training loss: 0.5660060652721269
Validation loss: 2.7634513919798493

Epoch: 5| Step: 3
Training loss: 0.5120792720510509
Validation loss: 2.73596420609101

Epoch: 5| Step: 4
Training loss: 0.6266500150297792
Validation loss: 2.6932520892283485

Epoch: 5| Step: 5
Training loss: 0.5978256434318344
Validation loss: 2.75642357883009

Epoch: 5| Step: 6
Training loss: 0.5001963587477771
Validation loss: 2.707636477000327

Epoch: 5| Step: 7
Training loss: 0.40756676091910926
Validation loss: 2.6926024813970635

Epoch: 5| Step: 8
Training loss: 0.5248007600649413
Validation loss: 2.6520249330114303

Epoch: 5| Step: 9
Training loss: 0.3188995622852284
Validation loss: 2.7507968383913637

Epoch: 5| Step: 10
Training loss: 0.44635927411795784
Validation loss: 2.750462865167452

Epoch: 5| Step: 11
Training loss: 0.4618314382841634
Validation loss: 2.762934365508988

Epoch: 254| Step: 0
Training loss: 0.47441005838588196
Validation loss: 2.8018829292947025

Epoch: 5| Step: 1
Training loss: 0.4799160142776993
Validation loss: 2.7445779942847195

Epoch: 5| Step: 2
Training loss: 0.7323362987115639
Validation loss: 2.67248524655218

Epoch: 5| Step: 3
Training loss: 0.5295311103341106
Validation loss: 2.729881667371873

Epoch: 5| Step: 4
Training loss: 0.5832047377485498
Validation loss: 2.7386922886053693

Epoch: 5| Step: 5
Training loss: 0.5399218357877147
Validation loss: 2.7456154549213734

Epoch: 5| Step: 6
Training loss: 0.5089145732570276
Validation loss: 2.7212482699486706

Epoch: 5| Step: 7
Training loss: 0.5311474701169845
Validation loss: 2.6937474115806235

Epoch: 5| Step: 8
Training loss: 1.2008481961949085
Validation loss: 2.6250234443889187

Epoch: 5| Step: 9
Training loss: 0.4128772758700651
Validation loss: 2.6762146684600063

Epoch: 5| Step: 10
Training loss: 0.555903190553337
Validation loss: 2.6747087171500206

Epoch: 5| Step: 11
Training loss: 0.916604737154984
Validation loss: 2.6878066553327944

Epoch: 255| Step: 0
Training loss: 0.6549296493460185
Validation loss: 2.771487595581162

Epoch: 5| Step: 1
Training loss: 0.5255721959047482
Validation loss: 2.74285919932601

Epoch: 5| Step: 2
Training loss: 0.4390690460260119
Validation loss: 2.6905388507054884

Epoch: 5| Step: 3
Training loss: 0.8808952036673873
Validation loss: 2.7326323523814184

Epoch: 5| Step: 4
Training loss: 0.4449767972222653
Validation loss: 2.723862007485102

Epoch: 5| Step: 5
Training loss: 0.5676387400069899
Validation loss: 2.6682761924174345

Epoch: 5| Step: 6
Training loss: 0.5438183511327823
Validation loss: 2.66998776119918

Epoch: 5| Step: 7
Training loss: 0.5406754729243247
Validation loss: 2.6711042939705356

Epoch: 5| Step: 8
Training loss: 0.7004571741574198
Validation loss: 2.681745326625374

Epoch: 5| Step: 9
Training loss: 0.6137308792896147
Validation loss: 2.7537921133355057

Epoch: 5| Step: 10
Training loss: 1.2346928826989334
Validation loss: 2.7145587908810573

Epoch: 5| Step: 11
Training loss: 0.1918767576261407
Validation loss: 2.747947761575657

Epoch: 256| Step: 0
Training loss: 0.6106388240018581
Validation loss: 2.6940358662989587

Epoch: 5| Step: 1
Training loss: 0.7388398010357479
Validation loss: 2.717481002764611

Epoch: 5| Step: 2
Training loss: 0.302382849597325
Validation loss: 2.6843766574758283

Epoch: 5| Step: 3
Training loss: 0.4008620115709034
Validation loss: 2.7307327790460456

Epoch: 5| Step: 4
Training loss: 1.2515094702983758
Validation loss: 2.6198943454852013

Epoch: 5| Step: 5
Training loss: 0.543450313502604
Validation loss: 2.680564844255929

Epoch: 5| Step: 6
Training loss: 0.6316489837791707
Validation loss: 2.6840239082452193

Epoch: 5| Step: 7
Training loss: 0.6503810251804785
Validation loss: 2.764916596859204

Epoch: 5| Step: 8
Training loss: 0.521807424087683
Validation loss: 2.6930453989076657

Epoch: 5| Step: 9
Training loss: 0.5943573806509814
Validation loss: 2.8018796922410565

Epoch: 5| Step: 10
Training loss: 0.7469374993641639
Validation loss: 2.704401853930735

Epoch: 5| Step: 11
Training loss: 0.3918143286577914
Validation loss: 2.6960487355332474

Epoch: 257| Step: 0
Training loss: 0.364612641745957
Validation loss: 2.688866925631517

Epoch: 5| Step: 1
Training loss: 0.5100006204956619
Validation loss: 2.619234338004097

Epoch: 5| Step: 2
Training loss: 0.4572560825131052
Validation loss: 2.6746520395443123

Epoch: 5| Step: 3
Training loss: 0.46734357287353506
Validation loss: 2.6502649309773902

Epoch: 5| Step: 4
Training loss: 1.287535855803225
Validation loss: 2.679218240026963

Epoch: 5| Step: 5
Training loss: 0.5671668372055426
Validation loss: 2.6606031762218922

Epoch: 5| Step: 6
Training loss: 0.4347730013897654
Validation loss: 2.692619006202005

Epoch: 5| Step: 7
Training loss: 0.48476280562005913
Validation loss: 2.738776401187657

Epoch: 5| Step: 8
Training loss: 0.6717239476224885
Validation loss: 2.7978081380815154

Epoch: 5| Step: 9
Training loss: 0.777431233912968
Validation loss: 2.762590571971376

Epoch: 5| Step: 10
Training loss: 0.31918669780109765
Validation loss: 2.619226297356553

Epoch: 5| Step: 11
Training loss: 0.796445094810208
Validation loss: 2.7160329578873825

Epoch: 258| Step: 0
Training loss: 0.6472795097045163
Validation loss: 2.694790989645062

Epoch: 5| Step: 1
Training loss: 1.286413580647588
Validation loss: 2.6768322739096004

Epoch: 5| Step: 2
Training loss: 0.6965530772404
Validation loss: 2.6629808044011543

Epoch: 5| Step: 3
Training loss: 0.5876517586814097
Validation loss: 2.5763920093927624

Epoch: 5| Step: 4
Training loss: 0.4469862152636725
Validation loss: 2.6228076014266

Epoch: 5| Step: 5
Training loss: 0.6826682446858613
Validation loss: 2.7331578006923536

Epoch: 5| Step: 6
Training loss: 0.7710764518737729
Validation loss: 2.75544127841858

Epoch: 5| Step: 7
Training loss: 0.5537099417756561
Validation loss: 2.688328740880094

Epoch: 5| Step: 8
Training loss: 0.4021931894310466
Validation loss: 2.7423741566019912

Epoch: 5| Step: 9
Training loss: 0.42743519113304446
Validation loss: 2.6991580490743408

Epoch: 5| Step: 10
Training loss: 0.49512376348278
Validation loss: 2.676400369639227

Epoch: 5| Step: 11
Training loss: 0.6044493923537935
Validation loss: 2.6363906505512604

Epoch: 259| Step: 0
Training loss: 0.48770933608492895
Validation loss: 2.626480218800131

Epoch: 5| Step: 1
Training loss: 0.5329466262202399
Validation loss: 2.6380170023150677

Epoch: 5| Step: 2
Training loss: 0.7645986645553425
Validation loss: 2.6949292707509938

Epoch: 5| Step: 3
Training loss: 0.41903470381705155
Validation loss: 2.691745753253298

Epoch: 5| Step: 4
Training loss: 0.6046811549521629
Validation loss: 2.664247359110895

Epoch: 5| Step: 5
Training loss: 0.22967260857401423
Validation loss: 2.6434685540749356

Epoch: 5| Step: 6
Training loss: 0.5331185521834899
Validation loss: 2.653468822731206

Epoch: 5| Step: 7
Training loss: 1.2065434133605262
Validation loss: 2.682984132484731

Epoch: 5| Step: 8
Training loss: 0.4891206469109369
Validation loss: 2.660072541938756

Epoch: 5| Step: 9
Training loss: 0.39475051527853366
Validation loss: 2.6528154795454646

Epoch: 5| Step: 10
Training loss: 0.4749331841406373
Validation loss: 2.743085067660014

Epoch: 5| Step: 11
Training loss: 0.4087070658063891
Validation loss: 2.666108126310645

Epoch: 260| Step: 0
Training loss: 0.3395231313037617
Validation loss: 2.706031948816842

Epoch: 5| Step: 1
Training loss: 0.626151311944874
Validation loss: 2.68236501772438

Epoch: 5| Step: 2
Training loss: 0.5703840080267197
Validation loss: 2.596159034571666

Epoch: 5| Step: 3
Training loss: 0.49284665308080317
Validation loss: 2.7376544868157735

Epoch: 5| Step: 4
Training loss: 0.4808320013663599
Validation loss: 2.674744730576047

Epoch: 5| Step: 5
Training loss: 1.2273535637611905
Validation loss: 2.8151960025644245

Epoch: 5| Step: 6
Training loss: 0.6924172031056028
Validation loss: 2.6634135495313394

Epoch: 5| Step: 7
Training loss: 0.32337385417542064
Validation loss: 2.7685647093038135

Epoch: 5| Step: 8
Training loss: 0.33370525006521723
Validation loss: 2.8150409170285937

Epoch: 5| Step: 9
Training loss: 0.5531037245715889
Validation loss: 2.6898145264312125

Epoch: 5| Step: 10
Training loss: 0.5713078944044908
Validation loss: 2.675684505300848

Epoch: 5| Step: 11
Training loss: 0.4765590761405647
Validation loss: 2.699709044044238

Epoch: 261| Step: 0
Training loss: 0.6174264035016004
Validation loss: 2.7217944773089484

Epoch: 5| Step: 1
Training loss: 0.8749139947857402
Validation loss: 2.736719303637423

Epoch: 5| Step: 2
Training loss: 0.4845360826474581
Validation loss: 2.681106051039168

Epoch: 5| Step: 3
Training loss: 0.7134331715837227
Validation loss: 2.74127292506345

Epoch: 5| Step: 4
Training loss: 0.5710004028345614
Validation loss: 2.7657291838137197

Epoch: 5| Step: 5
Training loss: 0.6603675368734112
Validation loss: 2.8254304944669353

Epoch: 5| Step: 6
Training loss: 0.6621459680758413
Validation loss: 2.71237335510054

Epoch: 5| Step: 7
Training loss: 1.1919893432563253
Validation loss: 2.6674541574738027

Epoch: 5| Step: 8
Training loss: 0.41056418341565776
Validation loss: 2.691220897683168

Epoch: 5| Step: 9
Training loss: 0.3755624050597974
Validation loss: 2.632258054042903

Epoch: 5| Step: 10
Training loss: 0.5117224773242115
Validation loss: 2.652533369444672

Epoch: 5| Step: 11
Training loss: 1.032168643881971
Validation loss: 2.6898285957594257

Epoch: 262| Step: 0
Training loss: 0.37738859885505815
Validation loss: 2.727504911663063

Epoch: 5| Step: 1
Training loss: 0.6166617411554223
Validation loss: 2.720989857553218

Epoch: 5| Step: 2
Training loss: 0.5401540844128768
Validation loss: 2.8330823995227723

Epoch: 5| Step: 3
Training loss: 0.7572697140862586
Validation loss: 2.846112391379138

Epoch: 5| Step: 4
Training loss: 0.4897961576665059
Validation loss: 2.789666513812957

Epoch: 5| Step: 5
Training loss: 0.8008633827330238
Validation loss: 2.738528310792281

Epoch: 5| Step: 6
Training loss: 1.1532353976367382
Validation loss: 2.6499066024492066

Epoch: 5| Step: 7
Training loss: 0.5410903713771857
Validation loss: 2.647100857748176

Epoch: 5| Step: 8
Training loss: 0.5744793618398722
Validation loss: 2.6958019438767975

Epoch: 5| Step: 9
Training loss: 0.6305027712655934
Validation loss: 2.771616234755419

Epoch: 5| Step: 10
Training loss: 0.6350775319173031
Validation loss: 2.62256901815366

Epoch: 5| Step: 11
Training loss: 0.3581788224324174
Validation loss: 2.6773999851934067

Epoch: 263| Step: 0
Training loss: 0.6300705740772408
Validation loss: 2.7223724954404034

Epoch: 5| Step: 1
Training loss: 0.6759896590962715
Validation loss: 2.748726109020243

Epoch: 5| Step: 2
Training loss: 0.7693862778482394
Validation loss: 2.760615915029171

Epoch: 5| Step: 3
Training loss: 0.49469508851448796
Validation loss: 2.736539728594776

Epoch: 5| Step: 4
Training loss: 0.5347870715837622
Validation loss: 2.7025201447847955

Epoch: 5| Step: 5
Training loss: 1.2767077154444373
Validation loss: 2.5962981533996308

Epoch: 5| Step: 6
Training loss: 0.6422715310763782
Validation loss: 2.653710707350987

Epoch: 5| Step: 7
Training loss: 0.8397360799214322
Validation loss: 2.7775323681242923

Epoch: 5| Step: 8
Training loss: 0.4395828564205867
Validation loss: 2.6585458295869415

Epoch: 5| Step: 9
Training loss: 0.4282150876845494
Validation loss: 2.6922199069460255

Epoch: 5| Step: 10
Training loss: 0.27046021411104476
Validation loss: 2.662467702929399

Epoch: 5| Step: 11
Training loss: 0.6079542764486465
Validation loss: 2.7797011981388575

Epoch: 264| Step: 0
Training loss: 0.6095323359507392
Validation loss: 2.7504135312198943

Epoch: 5| Step: 1
Training loss: 0.401375336575909
Validation loss: 2.6330272594516906

Epoch: 5| Step: 2
Training loss: 0.5353428313508128
Validation loss: 2.708607345560137

Epoch: 5| Step: 3
Training loss: 1.2289255789408626
Validation loss: 2.671512939877532

Epoch: 5| Step: 4
Training loss: 0.5693943000311195
Validation loss: 2.684768312363057

Epoch: 5| Step: 5
Training loss: 0.3902188287488831
Validation loss: 2.755612548617724

Epoch: 5| Step: 6
Training loss: 0.4720265315709295
Validation loss: 2.6653699379429083

Epoch: 5| Step: 7
Training loss: 0.4046779992302862
Validation loss: 2.6370601706156362

Epoch: 5| Step: 8
Training loss: 0.5021467317888274
Validation loss: 2.707022303153148

Epoch: 5| Step: 9
Training loss: 0.787402720725078
Validation loss: 2.7108776991053816

Epoch: 5| Step: 10
Training loss: 0.48928100470055386
Validation loss: 2.7460653340663304

Epoch: 5| Step: 11
Training loss: 0.539960058686643
Validation loss: 2.720391676712961

Epoch: 265| Step: 0
Training loss: 0.44815393381070195
Validation loss: 2.6970809994876106

Epoch: 5| Step: 1
Training loss: 0.6037788681173621
Validation loss: 2.758628713623352

Epoch: 5| Step: 2
Training loss: 0.34522345503840446
Validation loss: 2.6276145735737155

Epoch: 5| Step: 3
Training loss: 0.4616863342627793
Validation loss: 2.6970121304600254

Epoch: 5| Step: 4
Training loss: 0.48898723681298556
Validation loss: 2.584973869296187

Epoch: 5| Step: 5
Training loss: 0.6525505332087015
Validation loss: 2.5862745889349363

Epoch: 5| Step: 6
Training loss: 0.7626748369230562
Validation loss: 2.675496285293558

Epoch: 5| Step: 7
Training loss: 0.4760528403152659
Validation loss: 2.6443238846182773

Epoch: 5| Step: 8
Training loss: 0.4176379525814394
Validation loss: 2.619206954188233

Epoch: 5| Step: 9
Training loss: 0.40569830994638334
Validation loss: 2.6473580789184825

Epoch: 5| Step: 10
Training loss: 1.1373214958897142
Validation loss: 2.7168844991850927

Epoch: 5| Step: 11
Training loss: 0.5641297995026948
Validation loss: 2.6563167451438785

Epoch: 266| Step: 0
Training loss: 0.37613741913966664
Validation loss: 2.8048864132928197

Epoch: 5| Step: 1
Training loss: 0.5269850464604879
Validation loss: 2.72781177672969

Epoch: 5| Step: 2
Training loss: 0.4501123413947988
Validation loss: 2.698328798008297

Epoch: 5| Step: 3
Training loss: 0.47626939734057544
Validation loss: 2.7054033361655154

Epoch: 5| Step: 4
Training loss: 1.2616897437951131
Validation loss: 2.704250145629247

Epoch: 5| Step: 5
Training loss: 0.49952957255654856
Validation loss: 2.7331989156906777

Epoch: 5| Step: 6
Training loss: 0.7345416103233687
Validation loss: 2.6843171012416382

Epoch: 5| Step: 7
Training loss: 0.46232443196430895
Validation loss: 2.645297312819659

Epoch: 5| Step: 8
Training loss: 0.4220953295353291
Validation loss: 2.6642985905867325

Epoch: 5| Step: 9
Training loss: 0.30963189508324673
Validation loss: 2.712473464431703

Epoch: 5| Step: 10
Training loss: 0.3840270918003982
Validation loss: 2.6368142419171385

Epoch: 5| Step: 11
Training loss: 0.2157417085177084
Validation loss: 2.721975713079038

Epoch: 267| Step: 0
Training loss: 0.48269944950710125
Validation loss: 2.620961024358185

Epoch: 5| Step: 1
Training loss: 0.47746656994859055
Validation loss: 2.6991440007725473

Epoch: 5| Step: 2
Training loss: 0.3400968508009009
Validation loss: 2.685725946178241

Epoch: 5| Step: 3
Training loss: 1.1792783217030478
Validation loss: 2.6085038586917566

Epoch: 5| Step: 4
Training loss: 0.3292483220445054
Validation loss: 2.6946502129866254

Epoch: 5| Step: 5
Training loss: 0.7322885620861707
Validation loss: 2.6526299847936095

Epoch: 5| Step: 6
Training loss: 0.26349519532236915
Validation loss: 2.6520978975657754

Epoch: 5| Step: 7
Training loss: 0.5442363296109645
Validation loss: 2.6319517960581327

Epoch: 5| Step: 8
Training loss: 0.5333726215296107
Validation loss: 2.668541589381993

Epoch: 5| Step: 9
Training loss: 0.49750695976104814
Validation loss: 2.7325123682640884

Epoch: 5| Step: 10
Training loss: 0.5984821970211099
Validation loss: 2.706797943410096

Epoch: 5| Step: 11
Training loss: 0.3741669541352887
Validation loss: 2.7774735754388735

Epoch: 268| Step: 0
Training loss: 0.5911591370103684
Validation loss: 2.715042641212939

Epoch: 5| Step: 1
Training loss: 0.4067284627510155
Validation loss: 2.595828801258799

Epoch: 5| Step: 2
Training loss: 1.1372323465375453
Validation loss: 2.6402289941963066

Epoch: 5| Step: 3
Training loss: 0.44676063381277165
Validation loss: 2.6906378303780167

Epoch: 5| Step: 4
Training loss: 0.46317609201429066
Validation loss: 2.6363168631500713

Epoch: 5| Step: 5
Training loss: 0.7290996429884071
Validation loss: 2.6324447842923933

Epoch: 5| Step: 6
Training loss: 0.5382214494991995
Validation loss: 2.5865199306147115

Epoch: 5| Step: 7
Training loss: 0.673892938565121
Validation loss: 2.622267921053137

Epoch: 5| Step: 8
Training loss: 0.5567679544011032
Validation loss: 2.6529696123609416

Epoch: 5| Step: 9
Training loss: 0.45955614229429875
Validation loss: 2.678300722990295

Epoch: 5| Step: 10
Training loss: 0.34194765307497765
Validation loss: 2.660289393233188

Epoch: 5| Step: 11
Training loss: 0.25138834558226836
Validation loss: 2.6513127086608717

Epoch: 269| Step: 0
Training loss: 1.2271343768933998
Validation loss: 2.7533680022341507

Epoch: 5| Step: 1
Training loss: 0.4267135352727841
Validation loss: 2.7057278143273877

Epoch: 5| Step: 2
Training loss: 0.3527973106229872
Validation loss: 2.691699997033199

Epoch: 5| Step: 3
Training loss: 0.5956964461155431
Validation loss: 2.7338713917862134

Epoch: 5| Step: 4
Training loss: 0.4424933322845954
Validation loss: 2.7252579221366235

Epoch: 5| Step: 5
Training loss: 0.4196717515378069
Validation loss: 2.6930181090226135

Epoch: 5| Step: 6
Training loss: 0.4695748224843909
Validation loss: 2.5911713079736995

Epoch: 5| Step: 7
Training loss: 0.3568859146773984
Validation loss: 2.642905358585962

Epoch: 5| Step: 8
Training loss: 0.5683516668996482
Validation loss: 2.7104179404800863

Epoch: 5| Step: 9
Training loss: 0.4915568838022999
Validation loss: 2.6871861008366413

Epoch: 5| Step: 10
Training loss: 0.590507058573824
Validation loss: 2.7199471056110034

Epoch: 5| Step: 11
Training loss: 0.6051361893437106
Validation loss: 2.698905805230953

Epoch: 270| Step: 0
Training loss: 0.490272034190284
Validation loss: 2.6542557092599055

Epoch: 5| Step: 1
Training loss: 0.6750088726449557
Validation loss: 2.6768284514295404

Epoch: 5| Step: 2
Training loss: 1.174188898028151
Validation loss: 2.646927927532161

Epoch: 5| Step: 3
Training loss: 0.45281054009960503
Validation loss: 2.705976485305515

Epoch: 5| Step: 4
Training loss: 0.550037016489913
Validation loss: 2.689392495470396

Epoch: 5| Step: 5
Training loss: 0.5861429490074436
Validation loss: 2.772180517763586

Epoch: 5| Step: 6
Training loss: 0.5257175662057938
Validation loss: 2.6716352619194246

Epoch: 5| Step: 7
Training loss: 0.29670097872370466
Validation loss: 2.6208219543618365

Epoch: 5| Step: 8
Training loss: 0.5283046304064068
Validation loss: 2.7567751070690103

Epoch: 5| Step: 9
Training loss: 0.5268032270804083
Validation loss: 2.6807489804388647

Epoch: 5| Step: 10
Training loss: 0.39942305351900925
Validation loss: 2.685759339222215

Epoch: 5| Step: 11
Training loss: 0.34835545809918406
Validation loss: 2.7053980926149457

Epoch: 271| Step: 0
Training loss: 0.6418236242235361
Validation loss: 2.6381846800994944

Epoch: 5| Step: 1
Training loss: 0.625769070472253
Validation loss: 2.6299248847943826

Epoch: 5| Step: 2
Training loss: 0.4397455386997611
Validation loss: 2.675454721691578

Epoch: 5| Step: 3
Training loss: 0.28746423395181886
Validation loss: 2.7132086387794345

Epoch: 5| Step: 4
Training loss: 0.44597760106407097
Validation loss: 2.7307342160125057

Epoch: 5| Step: 5
Training loss: 1.154609031230654
Validation loss: 2.726508186477048

Epoch: 5| Step: 6
Training loss: 0.419106992454741
Validation loss: 2.7064542609605935

Epoch: 5| Step: 7
Training loss: 0.37881604330158236
Validation loss: 2.719316584278881

Epoch: 5| Step: 8
Training loss: 0.3906791268041692
Validation loss: 2.6444953792060675

Epoch: 5| Step: 9
Training loss: 0.6977061741855215
Validation loss: 2.664185865124435

Epoch: 5| Step: 10
Training loss: 0.3733443028180979
Validation loss: 2.7317166003337126

Epoch: 5| Step: 11
Training loss: 0.4696280996815844
Validation loss: 2.7361781033567385

Epoch: 272| Step: 0
Training loss: 0.41522898199503394
Validation loss: 2.687205738399521

Epoch: 5| Step: 1
Training loss: 0.5251781218223817
Validation loss: 2.687358238857935

Epoch: 5| Step: 2
Training loss: 1.1324269658132489
Validation loss: 2.6602403699334136

Epoch: 5| Step: 3
Training loss: 0.44261513645328815
Validation loss: 2.700338356869319

Epoch: 5| Step: 4
Training loss: 0.5294499475058146
Validation loss: 2.7559692123012502

Epoch: 5| Step: 5
Training loss: 0.46760066909428083
Validation loss: 2.70541829932292

Epoch: 5| Step: 6
Training loss: 0.5844007302805798
Validation loss: 2.765878008460302

Epoch: 5| Step: 7
Training loss: 0.5367430113704795
Validation loss: 2.7630906319438466

Epoch: 5| Step: 8
Training loss: 0.275836299880768
Validation loss: 2.765114385088153

Epoch: 5| Step: 9
Training loss: 0.7980941347682663
Validation loss: 2.6551426617619955

Epoch: 5| Step: 10
Training loss: 0.6699549052378536
Validation loss: 2.7198225587697316

Epoch: 5| Step: 11
Training loss: 0.6141172894211786
Validation loss: 2.6319720212424955

Epoch: 273| Step: 0
Training loss: 0.7077126775755537
Validation loss: 2.6775218713284414

Epoch: 5| Step: 1
Training loss: 0.4938970576163721
Validation loss: 2.685229266256729

Epoch: 5| Step: 2
Training loss: 0.6318446634860402
Validation loss: 2.6686325215636844

Epoch: 5| Step: 3
Training loss: 0.4245372588146944
Validation loss: 2.745476462965029

Epoch: 5| Step: 4
Training loss: 0.42127633886882326
Validation loss: 2.7803409033610036

Epoch: 5| Step: 5
Training loss: 0.5626025371343101
Validation loss: 2.774339806720986

Epoch: 5| Step: 6
Training loss: 0.4169983159849985
Validation loss: 2.6660230364015285

Epoch: 5| Step: 7
Training loss: 0.3629245853034636
Validation loss: 2.625577113880126

Epoch: 5| Step: 8
Training loss: 0.5284108421058014
Validation loss: 2.6101513238864373

Epoch: 5| Step: 9
Training loss: 1.2049914163465785
Validation loss: 2.60760225774572

Epoch: 5| Step: 10
Training loss: 0.4898203587156542
Validation loss: 2.566178898681867

Epoch: 5| Step: 11
Training loss: 0.5427432792771091
Validation loss: 2.6297732997473404

Epoch: 274| Step: 0
Training loss: 1.2460001369219071
Validation loss: 2.620820805853745

Epoch: 5| Step: 1
Training loss: 0.6180933810980855
Validation loss: 2.6368251374057055

Epoch: 5| Step: 2
Training loss: 0.3989810228328338
Validation loss: 2.614598153871476

Epoch: 5| Step: 3
Training loss: 0.4614691335506399
Validation loss: 2.639143729592534

Epoch: 5| Step: 4
Training loss: 0.6120437723241687
Validation loss: 2.67924794335331

Epoch: 5| Step: 5
Training loss: 0.5386522362817276
Validation loss: 2.7026718215477628

Epoch: 5| Step: 6
Training loss: 0.3821757723864053
Validation loss: 2.749837700794005

Epoch: 5| Step: 7
Training loss: 0.5859520973930382
Validation loss: 2.657042078588536

Epoch: 5| Step: 8
Training loss: 0.7856464279275195
Validation loss: 2.6916722838418963

Epoch: 5| Step: 9
Training loss: 0.47432789874040815
Validation loss: 2.6436531378314454

Epoch: 5| Step: 10
Training loss: 0.3037061292261566
Validation loss: 2.6345152362439133

Epoch: 5| Step: 11
Training loss: 0.3683262273087169
Validation loss: 2.654261783670109

Epoch: 275| Step: 0
Training loss: 1.0950001792385007
Validation loss: 2.6656238608080214

Epoch: 5| Step: 1
Training loss: 0.4324682250505877
Validation loss: 2.63871605283404

Epoch: 5| Step: 2
Training loss: 0.4218582750466671
Validation loss: 2.6535136770496495

Epoch: 5| Step: 3
Training loss: 0.5023019372793724
Validation loss: 2.6814038903119846

Epoch: 5| Step: 4
Training loss: 0.42917604351293487
Validation loss: 2.652017785905706

Epoch: 5| Step: 5
Training loss: 0.5587135399906696
Validation loss: 2.7482786336168443

Epoch: 5| Step: 6
Training loss: 0.6364658298040543
Validation loss: 2.66853151208742

Epoch: 5| Step: 7
Training loss: 0.6270562203038763
Validation loss: 2.700888011302001

Epoch: 5| Step: 8
Training loss: 0.4526634825660977
Validation loss: 2.7090174905136775

Epoch: 5| Step: 9
Training loss: 0.5201587472742831
Validation loss: 2.591366216338621

Epoch: 5| Step: 10
Training loss: 0.4633271456752381
Validation loss: 2.6292999108874633

Epoch: 5| Step: 11
Training loss: 0.3286100957072741
Validation loss: 2.697346444177121

Epoch: 276| Step: 0
Training loss: 0.3608681508938149
Validation loss: 2.697105559494142

Epoch: 5| Step: 1
Training loss: 0.4656315707056735
Validation loss: 2.659452956895274

Epoch: 5| Step: 2
Training loss: 0.5473293869046262
Validation loss: 2.7173321231188745

Epoch: 5| Step: 3
Training loss: 0.44653468812223174
Validation loss: 2.6185958413306687

Epoch: 5| Step: 4
Training loss: 0.3478886866692206
Validation loss: 2.642427829736136

Epoch: 5| Step: 5
Training loss: 0.4759558114720225
Validation loss: 2.6548908627254084

Epoch: 5| Step: 6
Training loss: 0.5216332269600744
Validation loss: 2.702578686025354

Epoch: 5| Step: 7
Training loss: 0.407501987469981
Validation loss: 2.700623749721867

Epoch: 5| Step: 8
Training loss: 1.1134477457393612
Validation loss: 2.6604250670778127

Epoch: 5| Step: 9
Training loss: 0.562013283071984
Validation loss: 2.734317557321903

Epoch: 5| Step: 10
Training loss: 0.43663869953259943
Validation loss: 2.651213163863052

Epoch: 5| Step: 11
Training loss: 0.27201381351389936
Validation loss: 2.8083313955155056

Epoch: 277| Step: 0
Training loss: 0.7659497253612706
Validation loss: 2.6976644196779254

Epoch: 5| Step: 1
Training loss: 1.1072687382924453
Validation loss: 2.7221746798719124

Epoch: 5| Step: 2
Training loss: 0.26412374136173966
Validation loss: 2.675388389018728

Epoch: 5| Step: 3
Training loss: 0.3991410457887371
Validation loss: 2.6685018197710355

Epoch: 5| Step: 4
Training loss: 0.5411405728928608
Validation loss: 2.6170843493123526

Epoch: 5| Step: 5
Training loss: 0.4883647694684145
Validation loss: 2.6401653943186894

Epoch: 5| Step: 6
Training loss: 0.3611607344268842
Validation loss: 2.6318307134591783

Epoch: 5| Step: 7
Training loss: 0.379493867298125
Validation loss: 2.6280592545410046

Epoch: 5| Step: 8
Training loss: 0.38939350555678226
Validation loss: 2.6741097197249957

Epoch: 5| Step: 9
Training loss: 0.3914470986315149
Validation loss: 2.633816909501384

Epoch: 5| Step: 10
Training loss: 0.4173127847064654
Validation loss: 2.631973281890812

Epoch: 5| Step: 11
Training loss: 0.44453303398753163
Validation loss: 2.624968615601647

Epoch: 278| Step: 0
Training loss: 0.4260431936309735
Validation loss: 2.632589630745725

Epoch: 5| Step: 1
Training loss: 0.2789355254636535
Validation loss: 2.616269074795891

Epoch: 5| Step: 2
Training loss: 0.3289148497193432
Validation loss: 2.6506933022114825

Epoch: 5| Step: 3
Training loss: 0.5268666970627107
Validation loss: 2.6203049270074605

Epoch: 5| Step: 4
Training loss: 0.6449460862049627
Validation loss: 2.680716014143244

Epoch: 5| Step: 5
Training loss: 0.7342039680170058
Validation loss: 2.696423774180841

Epoch: 5| Step: 6
Training loss: 0.6760574393839887
Validation loss: 2.6990648916791224

Epoch: 5| Step: 7
Training loss: 0.5560150914888448
Validation loss: 2.6665823533219797

Epoch: 5| Step: 8
Training loss: 1.1400156875835992
Validation loss: 2.722608652524333

Epoch: 5| Step: 9
Training loss: 0.40939531130307144
Validation loss: 2.641146659111225

Epoch: 5| Step: 10
Training loss: 0.3977734511059906
Validation loss: 2.7254153027045316

Epoch: 5| Step: 11
Training loss: 0.25036582407370467
Validation loss: 2.604679695457905

Epoch: 279| Step: 0
Training loss: 0.4720136356697615
Validation loss: 2.6814737251801635

Epoch: 5| Step: 1
Training loss: 1.1945110950553481
Validation loss: 2.661052293405081

Epoch: 5| Step: 2
Training loss: 0.3536427727605702
Validation loss: 2.6248914718899505

Epoch: 5| Step: 3
Training loss: 0.49237883345658007
Validation loss: 2.6884702494665285

Epoch: 5| Step: 4
Training loss: 0.41299785639897013
Validation loss: 2.6328265249178737

Epoch: 5| Step: 5
Training loss: 0.5274323000560598
Validation loss: 2.7253393838264572

Epoch: 5| Step: 6
Training loss: 0.48985006459134384
Validation loss: 2.620805568174006

Epoch: 5| Step: 7
Training loss: 0.6596564031415814
Validation loss: 2.6898797314878182

Epoch: 5| Step: 8
Training loss: 0.41231186579062373
Validation loss: 2.7209656044051225

Epoch: 5| Step: 9
Training loss: 0.437211946617854
Validation loss: 2.6630106291540305

Epoch: 5| Step: 10
Training loss: 0.4069048665184816
Validation loss: 2.7472464076382113

Epoch: 5| Step: 11
Training loss: 0.29969779479211806
Validation loss: 2.683235640603469

Epoch: 280| Step: 0
Training loss: 0.4509314685082428
Validation loss: 2.6172616027665696

Epoch: 5| Step: 1
Training loss: 0.3443439943579473
Validation loss: 2.693145791433347

Epoch: 5| Step: 2
Training loss: 0.4389157209396434
Validation loss: 2.6866173144825325

Epoch: 5| Step: 3
Training loss: 0.4814965953944213
Validation loss: 2.6707544895879374

Epoch: 5| Step: 4
Training loss: 0.45032186653302014
Validation loss: 2.7448230044309008

Epoch: 5| Step: 5
Training loss: 0.5969459701207157
Validation loss: 2.6519528804637904

Epoch: 5| Step: 6
Training loss: 1.1408660320465756
Validation loss: 2.745275698454761

Epoch: 5| Step: 7
Training loss: 0.39977697472994983
Validation loss: 2.71093416167978

Epoch: 5| Step: 8
Training loss: 0.7726531241790522
Validation loss: 2.764118560170761

Epoch: 5| Step: 9
Training loss: 0.36977975002304714
Validation loss: 2.7173566262167848

Epoch: 5| Step: 10
Training loss: 0.523062728402271
Validation loss: 2.686543410853384

Epoch: 5| Step: 11
Training loss: 0.3276792632222251
Validation loss: 2.6999410425625032

Epoch: 281| Step: 0
Training loss: 0.43726260692815083
Validation loss: 2.690528937030512

Epoch: 5| Step: 1
Training loss: 0.6142589526628305
Validation loss: 2.6253390547357616

Epoch: 5| Step: 2
Training loss: 0.4463667019478956
Validation loss: 2.6706030273723926

Epoch: 5| Step: 3
Training loss: 0.5551862220822458
Validation loss: 2.731686700204777

Epoch: 5| Step: 4
Training loss: 0.5143080278647892
Validation loss: 2.657184492547142

Epoch: 5| Step: 5
Training loss: 0.48163935095749255
Validation loss: 2.6723182860766816

Epoch: 5| Step: 6
Training loss: 0.39129815274525676
Validation loss: 2.665569565268522

Epoch: 5| Step: 7
Training loss: 0.41604762782546184
Validation loss: 2.751752186810815

Epoch: 5| Step: 8
Training loss: 0.3532085982254911
Validation loss: 2.8195420055443225

Epoch: 5| Step: 9
Training loss: 0.47726866510858884
Validation loss: 2.7436135072002363

Epoch: 5| Step: 10
Training loss: 1.066348399175606
Validation loss: 2.677046684034063

Epoch: 5| Step: 11
Training loss: 0.40482483820026516
Validation loss: 2.6336461114331935

Epoch: 282| Step: 0
Training loss: 0.4758735116284529
Validation loss: 2.647490513081854

Epoch: 5| Step: 1
Training loss: 0.4632469608425411
Validation loss: 2.6854524575021834

Epoch: 5| Step: 2
Training loss: 0.4709955154152803
Validation loss: 2.628670449945022

Epoch: 5| Step: 3
Training loss: 0.39981981853556936
Validation loss: 2.7257855354902976

Epoch: 5| Step: 4
Training loss: 0.6100381763816016
Validation loss: 2.683816040842171

Epoch: 5| Step: 5
Training loss: 0.44121820951280494
Validation loss: 2.677375006959387

Epoch: 5| Step: 6
Training loss: 1.1488420980434506
Validation loss: 2.6705064149955815

Epoch: 5| Step: 7
Training loss: 0.475502680515231
Validation loss: 2.692779061712376

Epoch: 5| Step: 8
Training loss: 0.5819628886585358
Validation loss: 2.6613219699651265

Epoch: 5| Step: 9
Training loss: 0.5852803423388363
Validation loss: 2.6919453325096176

Epoch: 5| Step: 10
Training loss: 0.4981186310182671
Validation loss: 2.653033317176979

Epoch: 5| Step: 11
Training loss: 0.6640912218053378
Validation loss: 2.6963539875618223

Epoch: 283| Step: 0
Training loss: 0.5395951334817986
Validation loss: 2.742174508986897

Epoch: 5| Step: 1
Training loss: 0.6576624157689732
Validation loss: 2.671912622465755

Epoch: 5| Step: 2
Training loss: 0.4654067981132487
Validation loss: 2.7201467375525348

Epoch: 5| Step: 3
Training loss: 0.3774661590237125
Validation loss: 2.7816905233568865

Epoch: 5| Step: 4
Training loss: 0.486562526852332
Validation loss: 2.7437624705848775

Epoch: 5| Step: 5
Training loss: 0.5654894281692634
Validation loss: 2.6587489882890063

Epoch: 5| Step: 6
Training loss: 0.6355668864883302
Validation loss: 2.7213521923928043

Epoch: 5| Step: 7
Training loss: 1.0413678630785312
Validation loss: 2.737181741614276

Epoch: 5| Step: 8
Training loss: 0.565170861335599
Validation loss: 2.709335033088233

Epoch: 5| Step: 9
Training loss: 0.4148122010384408
Validation loss: 2.790818800325011

Epoch: 5| Step: 10
Training loss: 0.5782846024299342
Validation loss: 2.7764480387619748

Epoch: 5| Step: 11
Training loss: 0.39609670242924705
Validation loss: 2.7821690723160692

Epoch: 284| Step: 0
Training loss: 1.0597459216875171
Validation loss: 2.6875013048331473

Epoch: 5| Step: 1
Training loss: 0.3896719177361097
Validation loss: 2.7084208266479806

Epoch: 5| Step: 2
Training loss: 0.44871009556261365
Validation loss: 2.6773005569338504

Epoch: 5| Step: 3
Training loss: 0.44710316268601746
Validation loss: 2.664341994882112

Epoch: 5| Step: 4
Training loss: 0.6550723817740748
Validation loss: 2.6052247085168507

Epoch: 5| Step: 5
Training loss: 0.40827034209754026
Validation loss: 2.6757731082541794

Epoch: 5| Step: 6
Training loss: 0.3766616326744017
Validation loss: 2.642409455300896

Epoch: 5| Step: 7
Training loss: 0.433417000701801
Validation loss: 2.731140996269444

Epoch: 5| Step: 8
Training loss: 0.4289465150537492
Validation loss: 2.6557860810806586

Epoch: 5| Step: 9
Training loss: 0.5123490099507492
Validation loss: 2.741505526287616

Epoch: 5| Step: 10
Training loss: 0.427784694690366
Validation loss: 2.770014366980247

Epoch: 5| Step: 11
Training loss: 0.4333171649661392
Validation loss: 2.804702007854771

Epoch: 285| Step: 0
Training loss: 0.32088020073213197
Validation loss: 2.69284033067504

Epoch: 5| Step: 1
Training loss: 0.520981735703777
Validation loss: 2.675307079170521

Epoch: 5| Step: 2
Training loss: 0.6146833343830155
Validation loss: 2.691152976880351

Epoch: 5| Step: 3
Training loss: 0.44597868696423293
Validation loss: 2.715751807116858

Epoch: 5| Step: 4
Training loss: 0.38783177201110197
Validation loss: 2.702414711480669

Epoch: 5| Step: 5
Training loss: 0.2958375975252251
Validation loss: 2.6592781421312344

Epoch: 5| Step: 6
Training loss: 1.0711026581575334
Validation loss: 2.7647455544921646

Epoch: 5| Step: 7
Training loss: 0.353991067587772
Validation loss: 2.7147401492616385

Epoch: 5| Step: 8
Training loss: 0.46478122002103883
Validation loss: 2.6778928142690424

Epoch: 5| Step: 9
Training loss: 0.4843949652218008
Validation loss: 2.6659508367731086

Epoch: 5| Step: 10
Training loss: 0.47546701687319237
Validation loss: 2.699648909789187

Epoch: 5| Step: 11
Training loss: 0.21544141002589526
Validation loss: 2.7097638032711044

Epoch: 286| Step: 0
Training loss: 0.34343549038799764
Validation loss: 2.711543163028234

Epoch: 5| Step: 1
Training loss: 0.4715174362360705
Validation loss: 2.708234437946447

Epoch: 5| Step: 2
Training loss: 1.1636751797857414
Validation loss: 2.708023601329588

Epoch: 5| Step: 3
Training loss: 0.3862118336730912
Validation loss: 2.700262420905683

Epoch: 5| Step: 4
Training loss: 0.37650855932473715
Validation loss: 2.668138870020916

Epoch: 5| Step: 5
Training loss: 0.48262512311659683
Validation loss: 2.6736218726091563

Epoch: 5| Step: 6
Training loss: 0.39341218323035926
Validation loss: 2.71215045628071

Epoch: 5| Step: 7
Training loss: 0.4411727996865119
Validation loss: 2.740456548318137

Epoch: 5| Step: 8
Training loss: 0.45936868689214866
Validation loss: 2.7084387220760875

Epoch: 5| Step: 9
Training loss: 0.35009898633717546
Validation loss: 2.705693547905041

Epoch: 5| Step: 10
Training loss: 0.6953809683017494
Validation loss: 2.718443893505202

Epoch: 5| Step: 11
Training loss: 0.57122491981826
Validation loss: 2.7953004827182433

Epoch: 287| Step: 0
Training loss: 0.5834157976262915
Validation loss: 2.674704247239617

Epoch: 5| Step: 1
Training loss: 0.5106613357764115
Validation loss: 2.6960609244646894

Epoch: 5| Step: 2
Training loss: 0.3895772041851837
Validation loss: 2.6295112302970356

Epoch: 5| Step: 3
Training loss: 0.4513408129920793
Validation loss: 2.6484386927959265

Epoch: 5| Step: 4
Training loss: 0.5621993267942135
Validation loss: 2.7088098229111868

Epoch: 5| Step: 5
Training loss: 0.4194498292136632
Validation loss: 2.671278807098427

Epoch: 5| Step: 6
Training loss: 1.0708066259138544
Validation loss: 2.6572641157164805

Epoch: 5| Step: 7
Training loss: 0.49645178182902455
Validation loss: 2.677218969350197

Epoch: 5| Step: 8
Training loss: 0.3855400811459638
Validation loss: 2.743724602311633

Epoch: 5| Step: 9
Training loss: 0.45720144510024097
Validation loss: 2.7453489528053114

Epoch: 5| Step: 10
Training loss: 0.448014843701211
Validation loss: 2.77220044911608

Epoch: 5| Step: 11
Training loss: 0.4752546405876706
Validation loss: 2.673341642289159

Epoch: 288| Step: 0
Training loss: 0.6277105681789693
Validation loss: 2.6461326656327526

Epoch: 5| Step: 1
Training loss: 1.1734865424705547
Validation loss: 2.709840679077879

Epoch: 5| Step: 2
Training loss: 0.6560375005816499
Validation loss: 2.6666328283984293

Epoch: 5| Step: 3
Training loss: 0.4294141767084051
Validation loss: 2.683438418287404

Epoch: 5| Step: 4
Training loss: 0.4464601151357683
Validation loss: 2.669795299581635

Epoch: 5| Step: 5
Training loss: 0.7199007028083746
Validation loss: 2.8033577503776934

Epoch: 5| Step: 6
Training loss: 0.3635363349778621
Validation loss: 2.7406981355136666

Epoch: 5| Step: 7
Training loss: 0.6058818023485517
Validation loss: 2.7677482134542464

Epoch: 5| Step: 8
Training loss: 0.5147959083476037
Validation loss: 2.676741690797629

Epoch: 5| Step: 9
Training loss: 0.3347051105086883
Validation loss: 2.6347927490828975

Epoch: 5| Step: 10
Training loss: 0.36912023901783664
Validation loss: 2.6089681605157753

Epoch: 5| Step: 11
Training loss: 0.39899469198314924
Validation loss: 2.6577739831644136

Epoch: 289| Step: 0
Training loss: 0.7579050695766926
Validation loss: 2.6626291194465024

Epoch: 5| Step: 1
Training loss: 0.5813126704567755
Validation loss: 2.6409541118717628

Epoch: 5| Step: 2
Training loss: 0.3829590263984382
Validation loss: 2.722875355497376

Epoch: 5| Step: 3
Training loss: 0.3171490674154146
Validation loss: 2.744516548300514

Epoch: 5| Step: 4
Training loss: 0.27119795695529786
Validation loss: 2.7233550435122633

Epoch: 5| Step: 5
Training loss: 0.3565727110728755
Validation loss: 2.762027376116138

Epoch: 5| Step: 6
Training loss: 0.4568407199539161
Validation loss: 2.713069883300935

Epoch: 5| Step: 7
Training loss: 0.33985886594983167
Validation loss: 2.6675521205063415

Epoch: 5| Step: 8
Training loss: 1.108640185641068
Validation loss: 2.6404399807007914

Epoch: 5| Step: 9
Training loss: 0.36856538871265737
Validation loss: 2.728032678540077

Epoch: 5| Step: 10
Training loss: 0.4732350990057365
Validation loss: 2.7347606968200737

Epoch: 5| Step: 11
Training loss: 0.45313146191955067
Validation loss: 2.767981730204671

Epoch: 290| Step: 0
Training loss: 0.3269588091685462
Validation loss: 2.7028639599364803

Epoch: 5| Step: 1
Training loss: 0.43509945319011384
Validation loss: 2.7071271478456813

Epoch: 5| Step: 2
Training loss: 0.4560381704602759
Validation loss: 2.795402832021655

Epoch: 5| Step: 3
Training loss: 0.49226991780825946
Validation loss: 2.684978468419105

Epoch: 5| Step: 4
Training loss: 0.47649533158023827
Validation loss: 2.7135518611391856

Epoch: 5| Step: 5
Training loss: 0.47354929079440294
Validation loss: 2.697808993828587

Epoch: 5| Step: 6
Training loss: 0.3546577886497121
Validation loss: 2.6620890447969576

Epoch: 5| Step: 7
Training loss: 0.4883395961234024
Validation loss: 2.600426911951889

Epoch: 5| Step: 8
Training loss: 1.1246764989486053
Validation loss: 2.739503331098059

Epoch: 5| Step: 9
Training loss: 0.6289305593400851
Validation loss: 2.702583990182852

Epoch: 5| Step: 10
Training loss: 0.4083811905446861
Validation loss: 2.7258383072442585

Epoch: 5| Step: 11
Training loss: 0.23150283163122662
Validation loss: 2.7226416479345814

Epoch: 291| Step: 0
Training loss: 0.5880791244694972
Validation loss: 2.7916853332369924

Epoch: 5| Step: 1
Training loss: 1.117360135058181
Validation loss: 2.729050818864978

Epoch: 5| Step: 2
Training loss: 0.474965107414212
Validation loss: 2.6633824275612

Epoch: 5| Step: 3
Training loss: 0.41082480303102037
Validation loss: 2.6201965949383075

Epoch: 5| Step: 4
Training loss: 0.4680561334352985
Validation loss: 2.607122031126807

Epoch: 5| Step: 5
Training loss: 0.46077505579032185
Validation loss: 2.665495057570551

Epoch: 5| Step: 6
Training loss: 0.5719150341591854
Validation loss: 2.6151354360062693

Epoch: 5| Step: 7
Training loss: 0.30109557534789444
Validation loss: 2.6258297812174414

Epoch: 5| Step: 8
Training loss: 0.485030653417454
Validation loss: 2.6871975869059956

Epoch: 5| Step: 9
Training loss: 0.41728725312302256
Validation loss: 2.664994521448541

Epoch: 5| Step: 10
Training loss: 0.3897815371851558
Validation loss: 2.700453965558741

Epoch: 5| Step: 11
Training loss: 0.1949910952601159
Validation loss: 2.6647469060011217

Epoch: 292| Step: 0
Training loss: 0.3065171934862498
Validation loss: 2.6545858275021033

Epoch: 5| Step: 1
Training loss: 0.9815543194866835
Validation loss: 2.684477903372132

Epoch: 5| Step: 2
Training loss: 0.6180303588712627
Validation loss: 2.6329173737871256

Epoch: 5| Step: 3
Training loss: 0.5142815746318634
Validation loss: 2.707025756389994

Epoch: 5| Step: 4
Training loss: 0.5364617900058032
Validation loss: 2.711449548182188

Epoch: 5| Step: 5
Training loss: 0.34986126738729834
Validation loss: 2.6479637037271795

Epoch: 5| Step: 6
Training loss: 0.4518067488035845
Validation loss: 2.688421446279953

Epoch: 5| Step: 7
Training loss: 0.35758766123261676
Validation loss: 2.6256309197630086

Epoch: 5| Step: 8
Training loss: 0.5010949305445221
Validation loss: 2.6126715609847833

Epoch: 5| Step: 9
Training loss: 0.3852899145358294
Validation loss: 2.6731894254825344

Epoch: 5| Step: 10
Training loss: 0.4171260467015464
Validation loss: 2.747432539756444

Epoch: 5| Step: 11
Training loss: 0.3602316638825486
Validation loss: 2.755785001368041

Epoch: 293| Step: 0
Training loss: 0.3633431822786385
Validation loss: 2.711658411243989

Epoch: 5| Step: 1
Training loss: 0.402156304703508
Validation loss: 2.6650591185902957

Epoch: 5| Step: 2
Training loss: 0.44821058839272826
Validation loss: 2.727603098036478

Epoch: 5| Step: 3
Training loss: 0.37954410466819527
Validation loss: 2.663344285494455

Epoch: 5| Step: 4
Training loss: 0.49974108489186847
Validation loss: 2.655952264891572

Epoch: 5| Step: 5
Training loss: 0.553934445759788
Validation loss: 2.666649476880062

Epoch: 5| Step: 6
Training loss: 1.048219187899815
Validation loss: 2.691629445750662

Epoch: 5| Step: 7
Training loss: 0.3316372272510607
Validation loss: 2.665839563688212

Epoch: 5| Step: 8
Training loss: 0.6137439415937628
Validation loss: 2.6185187374991488

Epoch: 5| Step: 9
Training loss: 0.3646458662991626
Validation loss: 2.688873900900685

Epoch: 5| Step: 10
Training loss: 0.43083651111077687
Validation loss: 2.708362503383734

Epoch: 5| Step: 11
Training loss: 0.32137655672729754
Validation loss: 2.734423555215518

Epoch: 294| Step: 0
Training loss: 0.5386419729186543
Validation loss: 2.6910717981981747

Epoch: 5| Step: 1
Training loss: 1.1028737589857134
Validation loss: 2.6980423302761984

Epoch: 5| Step: 2
Training loss: 0.4155000168884127
Validation loss: 2.716058966813279

Epoch: 5| Step: 3
Training loss: 0.3472138923069695
Validation loss: 2.726556047433762

Epoch: 5| Step: 4
Training loss: 0.5676748341700608
Validation loss: 2.6886657101436113

Epoch: 5| Step: 5
Training loss: 0.41832215529144673
Validation loss: 2.7194593096222794

Epoch: 5| Step: 6
Training loss: 0.396028942998745
Validation loss: 2.6740989390013197

Epoch: 5| Step: 7
Training loss: 0.48275263640495286
Validation loss: 2.764973015811629

Epoch: 5| Step: 8
Training loss: 0.35058117706552144
Validation loss: 2.671379080512617

Epoch: 5| Step: 9
Training loss: 0.3916787240357123
Validation loss: 2.726310149923696

Epoch: 5| Step: 10
Training loss: 0.37835641668007164
Validation loss: 2.6983743681937913

Epoch: 5| Step: 11
Training loss: 0.2273792884683335
Validation loss: 2.716988968794145

Epoch: 295| Step: 0
Training loss: 0.3556746421049064
Validation loss: 2.684406307424247

Epoch: 5| Step: 1
Training loss: 0.48613419553652704
Validation loss: 2.6883535323494723

Epoch: 5| Step: 2
Training loss: 0.44213181337106133
Validation loss: 2.6754359595646724

Epoch: 5| Step: 3
Training loss: 0.4449210537843435
Validation loss: 2.6774064783087703

Epoch: 5| Step: 4
Training loss: 0.4054155399343444
Validation loss: 2.8317359437115135

Epoch: 5| Step: 5
Training loss: 0.37008131351591195
Validation loss: 2.782758503696489

Epoch: 5| Step: 6
Training loss: 0.28443392625163366
Validation loss: 2.77163976511934

Epoch: 5| Step: 7
Training loss: 0.5136348000262484
Validation loss: 2.737751861058641

Epoch: 5| Step: 8
Training loss: 0.3025658661486268
Validation loss: 2.7619103630963187

Epoch: 5| Step: 9
Training loss: 1.1096952271682583
Validation loss: 2.7664404742624926

Epoch: 5| Step: 10
Training loss: 0.3078421602627284
Validation loss: 2.6983686176602206

Epoch: 5| Step: 11
Training loss: 0.5243931203173381
Validation loss: 2.692632476111986

Epoch: 296| Step: 0
Training loss: 0.47218412669483445
Validation loss: 2.747623153370051

Epoch: 5| Step: 1
Training loss: 0.41912046741318093
Validation loss: 2.6785921911161545

Epoch: 5| Step: 2
Training loss: 0.6496183834036247
Validation loss: 2.7026179688908

Epoch: 5| Step: 3
Training loss: 0.45564184351322173
Validation loss: 2.7248146517594223

Epoch: 5| Step: 4
Training loss: 0.4722955446570658
Validation loss: 2.692357973268513

Epoch: 5| Step: 5
Training loss: 0.46173397045576686
Validation loss: 2.6639947108857265

Epoch: 5| Step: 6
Training loss: 0.28987900655756776
Validation loss: 2.6763246638801834

Epoch: 5| Step: 7
Training loss: 0.450195147003342
Validation loss: 2.7850095256377703

Epoch: 5| Step: 8
Training loss: 0.6264742391926862
Validation loss: 2.8027982237097095

Epoch: 5| Step: 9
Training loss: 0.4068755688641347
Validation loss: 2.7984220286015664

Epoch: 5| Step: 10
Training loss: 1.1658859308596834
Validation loss: 2.6882575357298935

Epoch: 5| Step: 11
Training loss: 0.4516563621567838
Validation loss: 2.6985727062416807

Epoch: 297| Step: 0
Training loss: 0.4761982448120166
Validation loss: 2.7915878581315163

Epoch: 5| Step: 1
Training loss: 0.43476047427133047
Validation loss: 2.63486865280277

Epoch: 5| Step: 2
Training loss: 1.0762584395304797
Validation loss: 2.751392033856686

Epoch: 5| Step: 3
Training loss: 0.45994365359996553
Validation loss: 2.7417191144357793

Epoch: 5| Step: 4
Training loss: 0.45388522994043784
Validation loss: 2.7445028443843267

Epoch: 5| Step: 5
Training loss: 0.3684251502040431
Validation loss: 2.673894338482247

Epoch: 5| Step: 6
Training loss: 0.6917873560693749
Validation loss: 2.7091299841595617

Epoch: 5| Step: 7
Training loss: 0.32038301761639887
Validation loss: 2.7559686932418925

Epoch: 5| Step: 8
Training loss: 0.5467381442353999
Validation loss: 2.7039787362857255

Epoch: 5| Step: 9
Training loss: 0.3742631189089376
Validation loss: 2.7132072309756796

Epoch: 5| Step: 10
Training loss: 0.5071502475372737
Validation loss: 2.7082837350901023

Epoch: 5| Step: 11
Training loss: 0.4705636542006276
Validation loss: 2.7435805503756097

Epoch: 298| Step: 0
Training loss: 0.3026050168198917
Validation loss: 2.6801281799288765

Epoch: 5| Step: 1
Training loss: 0.4010085942722028
Validation loss: 2.6841102743418013

Epoch: 5| Step: 2
Training loss: 0.3864325803554305
Validation loss: 2.7208218079673845

Epoch: 5| Step: 3
Training loss: 0.4578206832987613
Validation loss: 2.740967315150973

Epoch: 5| Step: 4
Training loss: 0.3658143604647723
Validation loss: 2.7125154752626814

Epoch: 5| Step: 5
Training loss: 0.3775435256496852
Validation loss: 2.746967218360598

Epoch: 5| Step: 6
Training loss: 0.6494728004451505
Validation loss: 2.6883386626686425

Epoch: 5| Step: 7
Training loss: 0.34771016592217463
Validation loss: 2.749669542831675

Epoch: 5| Step: 8
Training loss: 0.4426976109122487
Validation loss: 2.696064996027152

Epoch: 5| Step: 9
Training loss: 1.0067811168468446
Validation loss: 2.736541002784539

Epoch: 5| Step: 10
Training loss: 0.35073662284959733
Validation loss: 2.753676070746037

Epoch: 5| Step: 11
Training loss: 0.3483982846725613
Validation loss: 2.778214526941996

Epoch: 299| Step: 0
Training loss: 0.5517502775774915
Validation loss: 2.7936162700407148

Epoch: 5| Step: 1
Training loss: 0.5364077337407283
Validation loss: 2.807762270509812

Epoch: 5| Step: 2
Training loss: 0.4076235000713772
Validation loss: 2.8047650183942507

Epoch: 5| Step: 3
Training loss: 0.4242406147473417
Validation loss: 2.637854294385746

Epoch: 5| Step: 4
Training loss: 0.4058628254689614
Validation loss: 2.7954081945953817

Epoch: 5| Step: 5
Training loss: 0.33935959628222784
Validation loss: 2.7394679822436823

Epoch: 5| Step: 6
Training loss: 0.4868755094258651
Validation loss: 2.7732415967354487

Epoch: 5| Step: 7
Training loss: 0.5092055360636962
Validation loss: 2.7657056498576837

Epoch: 5| Step: 8
Training loss: 0.5716619334381755
Validation loss: 2.69724966270517

Epoch: 5| Step: 9
Training loss: 0.32538099973073287
Validation loss: 2.704677782605053

Epoch: 5| Step: 10
Training loss: 1.0424028211349055
Validation loss: 2.787700120872802

Epoch: 5| Step: 11
Training loss: 0.38989555916694596
Validation loss: 2.879431177641053

Epoch: 300| Step: 0
Training loss: 0.4821548958693291
Validation loss: 2.7151864729704025

Epoch: 5| Step: 1
Training loss: 0.44312051396863367
Validation loss: 2.772392473655345

Epoch: 5| Step: 2
Training loss: 1.0693469181977593
Validation loss: 2.722674964026814

Epoch: 5| Step: 3
Training loss: 0.3936502421121181
Validation loss: 2.733455779562298

Epoch: 5| Step: 4
Training loss: 0.36992221417356125
Validation loss: 2.704334036423764

Epoch: 5| Step: 5
Training loss: 0.369916030853738
Validation loss: 2.788045503642701

Epoch: 5| Step: 6
Training loss: 0.38571630463500683
Validation loss: 2.7008211317750934

Epoch: 5| Step: 7
Training loss: 0.4075752430470824
Validation loss: 2.767736831956688

Epoch: 5| Step: 8
Training loss: 0.5561429124255183
Validation loss: 2.7446051768890225

Epoch: 5| Step: 9
Training loss: 0.4622804829587177
Validation loss: 2.6774262655169365

Epoch: 5| Step: 10
Training loss: 0.43973642330562157
Validation loss: 2.7492264215886815

Epoch: 5| Step: 11
Training loss: 0.6907999645598158
Validation loss: 2.6857594076501576

Epoch: 301| Step: 0
Training loss: 0.5058753110518465
Validation loss: 2.6184323780571064

Epoch: 5| Step: 1
Training loss: 0.7193323761403618
Validation loss: 2.670110614452187

Epoch: 5| Step: 2
Training loss: 1.2284593432805424
Validation loss: 2.693757733822937

Epoch: 5| Step: 3
Training loss: 0.6233217117514758
Validation loss: 2.651098829051592

Epoch: 5| Step: 4
Training loss: 0.48027316819067467
Validation loss: 2.707989485016378

Epoch: 5| Step: 5
Training loss: 0.4226974312116056
Validation loss: 2.7979240723202072

Epoch: 5| Step: 6
Training loss: 0.697351103172707
Validation loss: 2.8274605639681583

Epoch: 5| Step: 7
Training loss: 0.70630887047821
Validation loss: 2.7779630318432313

Epoch: 5| Step: 8
Training loss: 0.2930160102872218
Validation loss: 2.786145099372571

Epoch: 5| Step: 9
Training loss: 0.339313455080384
Validation loss: 2.629734658875976

Epoch: 5| Step: 10
Training loss: 0.43297648094981667
Validation loss: 2.5835237214985556

Epoch: 5| Step: 11
Training loss: 0.27115423039054287
Validation loss: 2.625260374234892

Epoch: 302| Step: 0
Training loss: 0.7605936985267406
Validation loss: 2.679442580794306

Epoch: 5| Step: 1
Training loss: 0.5151124487488468
Validation loss: 2.696585943173412

Epoch: 5| Step: 2
Training loss: 1.0436002840950442
Validation loss: 2.64888483206276

Epoch: 5| Step: 3
Training loss: 0.33451673676653804
Validation loss: 2.640508133749367

Epoch: 5| Step: 4
Training loss: 0.4882728270757892
Validation loss: 2.664595262611614

Epoch: 5| Step: 5
Training loss: 0.43597838917597276
Validation loss: 2.6954705417756757

Epoch: 5| Step: 6
Training loss: 0.46380152187352697
Validation loss: 2.703891017179834

Epoch: 5| Step: 7
Training loss: 0.5873478256128833
Validation loss: 2.6839646365848657

Epoch: 5| Step: 8
Training loss: 0.4477779502611299
Validation loss: 2.648227904661737

Epoch: 5| Step: 9
Training loss: 0.4863351109014442
Validation loss: 2.6431359009973843

Epoch: 5| Step: 10
Training loss: 0.4115695219664656
Validation loss: 2.6813300856609805

Epoch: 5| Step: 11
Training loss: 0.33394191985192384
Validation loss: 2.701193499806109

Epoch: 303| Step: 0
Training loss: 0.3405140919318054
Validation loss: 2.6461413472026987

Epoch: 5| Step: 1
Training loss: 0.32798440509668975
Validation loss: 2.6082363480573516

Epoch: 5| Step: 2
Training loss: 0.38909465473079974
Validation loss: 2.670895049135429

Epoch: 5| Step: 3
Training loss: 0.44158948622822225
Validation loss: 2.7067094898790334

Epoch: 5| Step: 4
Training loss: 0.44495149669556244
Validation loss: 2.6890717612089885

Epoch: 5| Step: 5
Training loss: 0.4234525537102368
Validation loss: 2.694680000579932

Epoch: 5| Step: 6
Training loss: 0.3951607016919406
Validation loss: 2.74337268007559

Epoch: 5| Step: 7
Training loss: 0.6270030111745536
Validation loss: 2.7468521351562436

Epoch: 5| Step: 8
Training loss: 0.5855092327292334
Validation loss: 2.69996280600396

Epoch: 5| Step: 9
Training loss: 0.3900241617824481
Validation loss: 2.7379732307900007

Epoch: 5| Step: 10
Training loss: 1.1134387523934224
Validation loss: 2.6054718192948427

Epoch: 5| Step: 11
Training loss: 0.278813149971152
Validation loss: 2.6528685176574665

Epoch: 304| Step: 0
Training loss: 0.6627277873362869
Validation loss: 2.6727884898643612

Epoch: 5| Step: 1
Training loss: 0.5719638328138715
Validation loss: 2.633393013304046

Epoch: 5| Step: 2
Training loss: 1.0098330329516398
Validation loss: 2.6573430411649883

Epoch: 5| Step: 3
Training loss: 0.29424329083036826
Validation loss: 2.669274174137661

Epoch: 5| Step: 4
Training loss: 0.37455745253654177
Validation loss: 2.7223781587795575

Epoch: 5| Step: 5
Training loss: 0.5475184878184675
Validation loss: 2.768009774003385

Epoch: 5| Step: 6
Training loss: 0.3607457390544815
Validation loss: 2.6807028252880105

Epoch: 5| Step: 7
Training loss: 0.3269461732442082
Validation loss: 2.7820255184141325

Epoch: 5| Step: 8
Training loss: 0.6742721421549109
Validation loss: 2.7749632386186884

Epoch: 5| Step: 9
Training loss: 0.46316285317150396
Validation loss: 2.6911270225600346

Epoch: 5| Step: 10
Training loss: 0.5448379178469368
Validation loss: 2.627614316489078

Epoch: 5| Step: 11
Training loss: 0.6613694729528086
Validation loss: 2.6694902109696734

Epoch: 305| Step: 0
Training loss: 0.46029480886550833
Validation loss: 2.671625121926572

Epoch: 5| Step: 1
Training loss: 0.4066292020015974
Validation loss: 2.6324263194195194

Epoch: 5| Step: 2
Training loss: 0.40443828892295597
Validation loss: 2.684419348560965

Epoch: 5| Step: 3
Training loss: 0.3589099902438492
Validation loss: 2.6898258332353717

Epoch: 5| Step: 4
Training loss: 1.078608915666386
Validation loss: 2.737460453729056

Epoch: 5| Step: 5
Training loss: 0.49285117317517513
Validation loss: 2.737508856237941

Epoch: 5| Step: 6
Training loss: 0.3436968177056792
Validation loss: 2.750199202345216

Epoch: 5| Step: 7
Training loss: 0.4051611135700626
Validation loss: 2.684664353987376

Epoch: 5| Step: 8
Training loss: 0.626961823875473
Validation loss: 2.6142474670547453

Epoch: 5| Step: 9
Training loss: 0.3884443450962949
Validation loss: 2.6410279314559086

Epoch: 5| Step: 10
Training loss: 0.5633741050934863
Validation loss: 2.6955845055183456

Epoch: 5| Step: 11
Training loss: 0.3324120525697497
Validation loss: 2.678799851986552

Epoch: 306| Step: 0
Training loss: 0.44571824578890096
Validation loss: 2.727964305041236

Epoch: 5| Step: 1
Training loss: 1.0232385340052164
Validation loss: 2.65279204485143

Epoch: 5| Step: 2
Training loss: 0.5464342793755126
Validation loss: 2.6984142571210143

Epoch: 5| Step: 3
Training loss: 0.4581623426729197
Validation loss: 2.6868455222998056

Epoch: 5| Step: 4
Training loss: 0.32418238194567767
Validation loss: 2.7015341632769667

Epoch: 5| Step: 5
Training loss: 0.4443038928874723
Validation loss: 2.6995904393305463

Epoch: 5| Step: 6
Training loss: 0.6360917309715183
Validation loss: 2.725315894764971

Epoch: 5| Step: 7
Training loss: 0.4543333057021993
Validation loss: 2.7114039742561302

Epoch: 5| Step: 8
Training loss: 0.5462150951904645
Validation loss: 2.660273776676789

Epoch: 5| Step: 9
Training loss: 0.4010169178480915
Validation loss: 2.7316643567179266

Epoch: 5| Step: 10
Training loss: 0.6107866125293469
Validation loss: 2.6726285604250384

Epoch: 5| Step: 11
Training loss: 0.3921445093491099
Validation loss: 2.682596583148977

Epoch: 307| Step: 0
Training loss: 0.4353848143004502
Validation loss: 2.790706014934525

Epoch: 5| Step: 1
Training loss: 0.607853432578853
Validation loss: 2.695285568471325

Epoch: 5| Step: 2
Training loss: 0.4651108463259084
Validation loss: 2.7644798939797597

Epoch: 5| Step: 3
Training loss: 0.49929067842723746
Validation loss: 2.6890549338406284

Epoch: 5| Step: 4
Training loss: 1.0326749609061445
Validation loss: 2.6495605814439287

Epoch: 5| Step: 5
Training loss: 0.49279509990794196
Validation loss: 2.73708329999272

Epoch: 5| Step: 6
Training loss: 0.43745706551915503
Validation loss: 2.735788561247129

Epoch: 5| Step: 7
Training loss: 0.5772208541130412
Validation loss: 2.6398067184640106

Epoch: 5| Step: 8
Training loss: 0.6308616897965708
Validation loss: 2.718033524447079

Epoch: 5| Step: 9
Training loss: 0.6027350207539806
Validation loss: 2.6399946156299956

Epoch: 5| Step: 10
Training loss: 0.5927729850151434
Validation loss: 2.671413255319288

Epoch: 5| Step: 11
Training loss: 0.8376526394570385
Validation loss: 2.666595854166708

Epoch: 308| Step: 0
Training loss: 0.32314097269081116
Validation loss: 2.6875471842859837

Epoch: 5| Step: 1
Training loss: 0.4629487753610371
Validation loss: 2.629930176835472

Epoch: 5| Step: 2
Training loss: 0.3211718174315642
Validation loss: 2.6006015648672545

Epoch: 5| Step: 3
Training loss: 1.0243940469624706
Validation loss: 2.6365912211153963

Epoch: 5| Step: 4
Training loss: 0.42334609153563496
Validation loss: 2.632611611358928

Epoch: 5| Step: 5
Training loss: 0.4086110390384235
Validation loss: 2.652036314774994

Epoch: 5| Step: 6
Training loss: 0.4567226770201503
Validation loss: 2.710376699819045

Epoch: 5| Step: 7
Training loss: 0.3231079191493025
Validation loss: 2.7325000110985704

Epoch: 5| Step: 8
Training loss: 0.5486682373864892
Validation loss: 2.710866111819485

Epoch: 5| Step: 9
Training loss: 0.5999209560541745
Validation loss: 2.73805867159853

Epoch: 5| Step: 10
Training loss: 0.5404094784635288
Validation loss: 2.7758658886069956

Epoch: 5| Step: 11
Training loss: 0.5458117366721222
Validation loss: 2.7016068386707124

Epoch: 309| Step: 0
Training loss: 0.5258795296356275
Validation loss: 2.6536369167598606

Epoch: 5| Step: 1
Training loss: 0.5543155766478192
Validation loss: 2.6967989411721836

Epoch: 5| Step: 2
Training loss: 0.28119839088798926
Validation loss: 2.680602685703984

Epoch: 5| Step: 3
Training loss: 0.4585897169309488
Validation loss: 2.7123957109985377

Epoch: 5| Step: 4
Training loss: 0.3728373673196207
Validation loss: 2.62818715206867

Epoch: 5| Step: 5
Training loss: 1.0285689441900676
Validation loss: 2.7184922435952243

Epoch: 5| Step: 6
Training loss: 0.4004637488604711
Validation loss: 2.827051412073749

Epoch: 5| Step: 7
Training loss: 0.6532862587394387
Validation loss: 2.6691589995736695

Epoch: 5| Step: 8
Training loss: 0.39661844927514395
Validation loss: 2.7352882131867298

Epoch: 5| Step: 9
Training loss: 0.37939415812627447
Validation loss: 2.708385882723682

Epoch: 5| Step: 10
Training loss: 0.4382023282995138
Validation loss: 2.7285165170073276

Epoch: 5| Step: 11
Training loss: 0.45657648789677685
Validation loss: 2.6891139344537254

Epoch: 310| Step: 0
Training loss: 0.2722798227469572
Validation loss: 2.6868526100384678

Epoch: 5| Step: 1
Training loss: 0.5857394837523434
Validation loss: 2.7490124012808557

Epoch: 5| Step: 2
Training loss: 1.1035955619554094
Validation loss: 2.795357948048905

Epoch: 5| Step: 3
Training loss: 0.40627395119121185
Validation loss: 2.661247216428224

Epoch: 5| Step: 4
Training loss: 0.4666724098936396
Validation loss: 2.613249291498744

Epoch: 5| Step: 5
Training loss: 0.6295937754734751
Validation loss: 2.78475793074124

Epoch: 5| Step: 6
Training loss: 0.4067647863501112
Validation loss: 2.8107694794398514

Epoch: 5| Step: 7
Training loss: 0.5250993509745905
Validation loss: 2.72514644238059

Epoch: 5| Step: 8
Training loss: 0.43134765694091187
Validation loss: 2.781829187899724

Epoch: 5| Step: 9
Training loss: 0.33852257919299555
Validation loss: 2.71232379716051

Epoch: 5| Step: 10
Training loss: 0.4291385438494634
Validation loss: 2.679744894082219

Epoch: 5| Step: 11
Training loss: 0.40122170143518554
Validation loss: 2.738921296998554

Epoch: 311| Step: 0
Training loss: 0.35561889579508627
Validation loss: 2.739775064718933

Epoch: 5| Step: 1
Training loss: 0.6984815494036548
Validation loss: 2.696146418616078

Epoch: 5| Step: 2
Training loss: 0.41411005502799053
Validation loss: 2.7147185774746743

Epoch: 5| Step: 3
Training loss: 0.9814149462808518
Validation loss: 2.7038351680623434

Epoch: 5| Step: 4
Training loss: 0.44001295246761946
Validation loss: 2.808017659250205

Epoch: 5| Step: 5
Training loss: 0.538099589927544
Validation loss: 2.7433389671537443

Epoch: 5| Step: 6
Training loss: 0.5333906968629601
Validation loss: 2.747630529036542

Epoch: 5| Step: 7
Training loss: 0.3497269395468094
Validation loss: 2.737509534839532

Epoch: 5| Step: 8
Training loss: 0.2934412134766344
Validation loss: 2.698419978105697

Epoch: 5| Step: 9
Training loss: 0.3418151850564402
Validation loss: 2.7020042242167275

Epoch: 5| Step: 10
Training loss: 0.42022080538007245
Validation loss: 2.6248222964551697

Epoch: 5| Step: 11
Training loss: 0.6720509853094992
Validation loss: 2.6225388622707637

Epoch: 312| Step: 0
Training loss: 0.4785833816824987
Validation loss: 2.7106324572992366

Epoch: 5| Step: 1
Training loss: 0.34271352738886185
Validation loss: 2.7173601814782082

Epoch: 5| Step: 2
Training loss: 0.4916069906463237
Validation loss: 2.7349596760861394

Epoch: 5| Step: 3
Training loss: 0.4076019496290376
Validation loss: 2.6772722215970175

Epoch: 5| Step: 4
Training loss: 0.6023118937141871
Validation loss: 2.7645106953351752

Epoch: 5| Step: 5
Training loss: 0.4829581982173582
Validation loss: 2.7408049595033868

Epoch: 5| Step: 6
Training loss: 0.5738294929919157
Validation loss: 2.7111803032191752

Epoch: 5| Step: 7
Training loss: 1.0288673967051083
Validation loss: 2.6480151958477345

Epoch: 5| Step: 8
Training loss: 0.4275303532605149
Validation loss: 2.7362078963157304

Epoch: 5| Step: 9
Training loss: 0.5395292942377343
Validation loss: 2.6328686558199177

Epoch: 5| Step: 10
Training loss: 0.45042102641637316
Validation loss: 2.681072907575685

Epoch: 5| Step: 11
Training loss: 0.38984885355756493
Validation loss: 2.681449262807043

Epoch: 313| Step: 0
Training loss: 0.4105037488708116
Validation loss: 2.681715899154433

Epoch: 5| Step: 1
Training loss: 0.5090094325235228
Validation loss: 2.791110635772676

Epoch: 5| Step: 2
Training loss: 0.9555886743101917
Validation loss: 2.745776252606723

Epoch: 5| Step: 3
Training loss: 0.3856298162261582
Validation loss: 2.678891236953

Epoch: 5| Step: 4
Training loss: 0.4444047141032834
Validation loss: 2.6449402793807715

Epoch: 5| Step: 5
Training loss: 0.3079427903264631
Validation loss: 2.6920205952896636

Epoch: 5| Step: 6
Training loss: 0.46119178611375594
Validation loss: 2.6771536024991933

Epoch: 5| Step: 7
Training loss: 0.4682346371963016
Validation loss: 2.7061244331989034

Epoch: 5| Step: 8
Training loss: 0.5257840296769599
Validation loss: 2.7203977239538104

Epoch: 5| Step: 9
Training loss: 0.3416317786260608
Validation loss: 2.6278187135201136

Epoch: 5| Step: 10
Training loss: 0.3725166147162186
Validation loss: 2.740824593467924

Epoch: 5| Step: 11
Training loss: 0.25749067970185574
Validation loss: 2.716691725172619

Epoch: 314| Step: 0
Training loss: 0.37322121186455776
Validation loss: 2.758456449459785

Epoch: 5| Step: 1
Training loss: 0.4210864220372612
Validation loss: 2.71836953771312

Epoch: 5| Step: 2
Training loss: 0.42470021333394936
Validation loss: 2.667270418206775

Epoch: 5| Step: 3
Training loss: 0.4037110511842373
Validation loss: 2.7020999273135247

Epoch: 5| Step: 4
Training loss: 0.3267936376802991
Validation loss: 2.735593099392865

Epoch: 5| Step: 5
Training loss: 0.4221603170491677
Validation loss: 2.6332869701187183

Epoch: 5| Step: 6
Training loss: 0.979709042155626
Validation loss: 2.7177941955146503

Epoch: 5| Step: 7
Training loss: 0.3215340952473446
Validation loss: 2.7447596529421343

Epoch: 5| Step: 8
Training loss: 0.32053035212827374
Validation loss: 2.700354573138698

Epoch: 5| Step: 9
Training loss: 0.5925380987481038
Validation loss: 2.652230033253285

Epoch: 5| Step: 10
Training loss: 0.28415155435372275
Validation loss: 2.707929017380747

Epoch: 5| Step: 11
Training loss: 0.19872193939125876
Validation loss: 2.7508359527132433

Epoch: 315| Step: 0
Training loss: 0.4035162645982989
Validation loss: 2.711863338594551

Epoch: 5| Step: 1
Training loss: 0.3109180104075745
Validation loss: 2.728883140095526

Epoch: 5| Step: 2
Training loss: 0.4477370330726321
Validation loss: 2.6649168812873465

Epoch: 5| Step: 3
Training loss: 0.29951361029655443
Validation loss: 2.7281619466003626

Epoch: 5| Step: 4
Training loss: 0.7042961327945059
Validation loss: 2.727394767611152

Epoch: 5| Step: 5
Training loss: 0.4089761924471629
Validation loss: 2.6910481429242985

Epoch: 5| Step: 6
Training loss: 0.3199961309459854
Validation loss: 2.655939884408393

Epoch: 5| Step: 7
Training loss: 0.4322862931189481
Validation loss: 2.6429068245108858

Epoch: 5| Step: 8
Training loss: 1.0532595540013359
Validation loss: 2.7094259234566636

Epoch: 5| Step: 9
Training loss: 0.33286795937601776
Validation loss: 2.6893936996524976

Epoch: 5| Step: 10
Training loss: 0.46717054980604966
Validation loss: 2.7042371652276294

Epoch: 5| Step: 11
Training loss: 0.27625951927492587
Validation loss: 2.7146638989051124

Epoch: 316| Step: 0
Training loss: 0.25837640070062634
Validation loss: 2.733943821653106

Epoch: 5| Step: 1
Training loss: 0.34599338350626146
Validation loss: 2.773975692610668

Epoch: 5| Step: 2
Training loss: 0.5003640816264693
Validation loss: 2.7054030240496942

Epoch: 5| Step: 3
Training loss: 0.30180235105044967
Validation loss: 2.7211251462121253

Epoch: 5| Step: 4
Training loss: 0.534661893069789
Validation loss: 2.675412481657505

Epoch: 5| Step: 5
Training loss: 0.3670501249095671
Validation loss: 2.6696023068429313

Epoch: 5| Step: 6
Training loss: 0.44017398626514426
Validation loss: 2.594045595384277

Epoch: 5| Step: 7
Training loss: 0.3285875012741875
Validation loss: 2.6731953546736076

Epoch: 5| Step: 8
Training loss: 0.3629418089610684
Validation loss: 2.6797173278750015

Epoch: 5| Step: 9
Training loss: 0.3274449157981844
Validation loss: 2.708459676338752

Epoch: 5| Step: 10
Training loss: 0.9603150996015662
Validation loss: 2.6994446891296846

Epoch: 5| Step: 11
Training loss: 0.6374751787402416
Validation loss: 2.770417118840308

Epoch: 317| Step: 0
Training loss: 0.3478941692666044
Validation loss: 2.755758898746547

Epoch: 5| Step: 1
Training loss: 0.37463349074783453
Validation loss: 2.7906912456536666

Epoch: 5| Step: 2
Training loss: 0.9643458885006727
Validation loss: 2.707021730671375

Epoch: 5| Step: 3
Training loss: 0.47114110490392885
Validation loss: 2.693562489597101

Epoch: 5| Step: 4
Training loss: 0.6673550156500087
Validation loss: 2.6760968952610016

Epoch: 5| Step: 5
Training loss: 0.584359294251914
Validation loss: 2.7757377040606386

Epoch: 5| Step: 6
Training loss: 0.46636892198105406
Validation loss: 2.8153660511557237

Epoch: 5| Step: 7
Training loss: 0.3219483403102812
Validation loss: 2.826191478310635

Epoch: 5| Step: 8
Training loss: 0.4876892162792918
Validation loss: 2.7638025115896494

Epoch: 5| Step: 9
Training loss: 0.46044994689948554
Validation loss: 2.7859381870590565

Epoch: 5| Step: 10
Training loss: 0.4553509986954453
Validation loss: 2.746662806248575

Epoch: 5| Step: 11
Training loss: 0.20120766700926054
Validation loss: 2.7439152128375417

Epoch: 318| Step: 0
Training loss: 0.3431356640845309
Validation loss: 2.7231280457616265

Epoch: 5| Step: 1
Training loss: 0.6097875323566518
Validation loss: 2.7026855795147107

Epoch: 5| Step: 2
Training loss: 0.5061126134029881
Validation loss: 2.783740835615814

Epoch: 5| Step: 3
Training loss: 0.3122091966827774
Validation loss: 2.790655035844774

Epoch: 5| Step: 4
Training loss: 0.33371029589079054
Validation loss: 2.7757346261988

Epoch: 5| Step: 5
Training loss: 0.40674967480806506
Validation loss: 2.7322972568964277

Epoch: 5| Step: 6
Training loss: 0.9104980350915194
Validation loss: 2.785851772042692

Epoch: 5| Step: 7
Training loss: 0.4486365816774249
Validation loss: 2.7855026008362374

Epoch: 5| Step: 8
Training loss: 0.39400590724679946
Validation loss: 2.7138618431665544

Epoch: 5| Step: 9
Training loss: 0.44836573674523816
Validation loss: 2.7335628393300215

Epoch: 5| Step: 10
Training loss: 0.3360528082674775
Validation loss: 2.728842342315318

Epoch: 5| Step: 11
Training loss: 0.31631785205789664
Validation loss: 2.731596032299662

Epoch: 319| Step: 0
Training loss: 0.42448608026159534
Validation loss: 2.737938928905963

Epoch: 5| Step: 1
Training loss: 0.4999539383890778
Validation loss: 2.6465825511932377

Epoch: 5| Step: 2
Training loss: 0.4089482638531048
Validation loss: 2.6550287917564175

Epoch: 5| Step: 3
Training loss: 0.47403731229553214
Validation loss: 2.6843217050267425

Epoch: 5| Step: 4
Training loss: 0.6264890575412332
Validation loss: 2.7997096666174652

Epoch: 5| Step: 5
Training loss: 0.412927276947835
Validation loss: 2.735775833974217

Epoch: 5| Step: 6
Training loss: 0.3496848616274657
Validation loss: 2.7537742096109037

Epoch: 5| Step: 7
Training loss: 0.9010036144416955
Validation loss: 2.8137056274451515

Epoch: 5| Step: 8
Training loss: 0.4786666164791104
Validation loss: 2.738145648031219

Epoch: 5| Step: 9
Training loss: 0.3727039538546067
Validation loss: 2.7324025151382876

Epoch: 5| Step: 10
Training loss: 0.39904996136807475
Validation loss: 2.7130795388556725

Epoch: 5| Step: 11
Training loss: 0.49005958207045863
Validation loss: 2.728471413838764

Epoch: 320| Step: 0
Training loss: 0.4323509378666354
Validation loss: 2.69877807877036

Epoch: 5| Step: 1
Training loss: 0.3026792168359189
Validation loss: 2.637183175334872

Epoch: 5| Step: 2
Training loss: 0.4325410935278355
Validation loss: 2.7149032256932206

Epoch: 5| Step: 3
Training loss: 0.6231006850201963
Validation loss: 2.6313362661674273

Epoch: 5| Step: 4
Training loss: 0.26047443543872817
Validation loss: 2.713922936323445

Epoch: 5| Step: 5
Training loss: 0.9527132677130785
Validation loss: 2.7052104894614537

Epoch: 5| Step: 6
Training loss: 0.4967778062827655
Validation loss: 2.7052557564447874

Epoch: 5| Step: 7
Training loss: 0.4015429406653364
Validation loss: 2.742906506964952

Epoch: 5| Step: 8
Training loss: 0.4366548071711643
Validation loss: 2.74764329540072

Epoch: 5| Step: 9
Training loss: 0.2597187688343499
Validation loss: 2.6865944852393313

Epoch: 5| Step: 10
Training loss: 0.381003641046062
Validation loss: 2.699891057730615

Epoch: 5| Step: 11
Training loss: 0.0795002034665674
Validation loss: 2.670037989590204

Epoch: 321| Step: 0
Training loss: 0.41631027317983516
Validation loss: 2.6683114587108383

Epoch: 5| Step: 1
Training loss: 0.522261251632423
Validation loss: 2.687936481250429

Epoch: 5| Step: 2
Training loss: 0.5134141224550078
Validation loss: 2.672843504747095

Epoch: 5| Step: 3
Training loss: 0.45209825867598313
Validation loss: 2.7030168559468164

Epoch: 5| Step: 4
Training loss: 0.8964297874303483
Validation loss: 2.693491987099279

Epoch: 5| Step: 5
Training loss: 0.4523343060550243
Validation loss: 2.6964233726053157

Epoch: 5| Step: 6
Training loss: 0.5672023834293445
Validation loss: 2.7921970145972974

Epoch: 5| Step: 7
Training loss: 0.494818271791698
Validation loss: 2.781458257528927

Epoch: 5| Step: 8
Training loss: 0.36030663104211275
Validation loss: 2.7181264703085413

Epoch: 5| Step: 9
Training loss: 0.24657691723647596
Validation loss: 2.682101075644778

Epoch: 5| Step: 10
Training loss: 0.5369065612735227
Validation loss: 2.7286148653981144

Epoch: 5| Step: 11
Training loss: 0.5964874357433521
Validation loss: 2.7917189605047246

Epoch: 322| Step: 0
Training loss: 0.3894637968233068
Validation loss: 2.6934517375922193

Epoch: 5| Step: 1
Training loss: 0.641657230278912
Validation loss: 2.7945742494230643

Epoch: 5| Step: 2
Training loss: 0.4935344853434931
Validation loss: 2.7175934549549687

Epoch: 5| Step: 3
Training loss: 0.5292607537926294
Validation loss: 2.8982706938777283

Epoch: 5| Step: 4
Training loss: 0.5344784195971009
Validation loss: 2.7964934793888823

Epoch: 5| Step: 5
Training loss: 0.4661337000228551
Validation loss: 2.798726571816867

Epoch: 5| Step: 6
Training loss: 0.4262726599020261
Validation loss: 2.76073956790238

Epoch: 5| Step: 7
Training loss: 0.9571948476042965
Validation loss: 2.843756997096358

Epoch: 5| Step: 8
Training loss: 0.3711334608815324
Validation loss: 2.746753383688438

Epoch: 5| Step: 9
Training loss: 0.5880131134481529
Validation loss: 2.7126042009077773

Epoch: 5| Step: 10
Training loss: 0.5383966175572509
Validation loss: 2.6982599258530104

Epoch: 5| Step: 11
Training loss: 0.6654121148039939
Validation loss: 2.7014822332233477

Epoch: 323| Step: 0
Training loss: 0.3885269853444851
Validation loss: 2.748975696679936

Epoch: 5| Step: 1
Training loss: 0.4354764428090578
Validation loss: 2.683001234895278

Epoch: 5| Step: 2
Training loss: 0.9997142741179517
Validation loss: 2.750760778762467

Epoch: 5| Step: 3
Training loss: 0.4762375458518199
Validation loss: 2.7188942750380223

Epoch: 5| Step: 4
Training loss: 0.39366057606641414
Validation loss: 2.69976735187089

Epoch: 5| Step: 5
Training loss: 0.3588510508556587
Validation loss: 2.7660491603726727

Epoch: 5| Step: 6
Training loss: 0.4265252708425702
Validation loss: 2.6816196056485913

Epoch: 5| Step: 7
Training loss: 0.3708054275764108
Validation loss: 2.687365266098785

Epoch: 5| Step: 8
Training loss: 0.382917895697336
Validation loss: 2.6470831312178187

Epoch: 5| Step: 9
Training loss: 0.33702428369303783
Validation loss: 2.6810998114290543

Epoch: 5| Step: 10
Training loss: 0.581869371675832
Validation loss: 2.686701471144316

Epoch: 5| Step: 11
Training loss: 0.2540904330749166
Validation loss: 2.6601402816255844

Epoch: 324| Step: 0
Training loss: 0.45978617334591615
Validation loss: 2.6906200934648545

Epoch: 5| Step: 1
Training loss: 0.43614255259631163
Validation loss: 2.7427086294202767

Epoch: 5| Step: 2
Training loss: 0.30820804345445324
Validation loss: 2.6881205005101068

Epoch: 5| Step: 3
Training loss: 0.37421800617311335
Validation loss: 2.7368804751725655

Epoch: 5| Step: 4
Training loss: 0.4324834371438286
Validation loss: 2.6597335188260285

Epoch: 5| Step: 5
Training loss: 0.37646998935057535
Validation loss: 2.690271622848713

Epoch: 5| Step: 6
Training loss: 0.5893915476655391
Validation loss: 2.694632104328373

Epoch: 5| Step: 7
Training loss: 0.9960482717865655
Validation loss: 2.6673931694327817

Epoch: 5| Step: 8
Training loss: 0.4284676663207881
Validation loss: 2.7020912913428545

Epoch: 5| Step: 9
Training loss: 0.3904147917676355
Validation loss: 2.7178717122669993

Epoch: 5| Step: 10
Training loss: 0.35661583570919064
Validation loss: 2.7339072962810502

Epoch: 5| Step: 11
Training loss: 0.9190353689952655
Validation loss: 2.693389848145289

Epoch: 325| Step: 0
Training loss: 0.5049791668381043
Validation loss: 2.6607652453498005

Epoch: 5| Step: 1
Training loss: 0.4814276856451266
Validation loss: 2.6628921899002385

Epoch: 5| Step: 2
Training loss: 0.41267869142279584
Validation loss: 2.697595375892131

Epoch: 5| Step: 3
Training loss: 0.39192745508660043
Validation loss: 2.6509875283899427

Epoch: 5| Step: 4
Training loss: 0.9731096796435784
Validation loss: 2.7248218412517637

Epoch: 5| Step: 5
Training loss: 0.4358755334271601
Validation loss: 2.7013582159364136

Epoch: 5| Step: 6
Training loss: 0.5587831722883752
Validation loss: 2.7648022284492977

Epoch: 5| Step: 7
Training loss: 0.44093680948788694
Validation loss: 2.6953595032947257

Epoch: 5| Step: 8
Training loss: 0.3753852454841035
Validation loss: 2.6563064943177506

Epoch: 5| Step: 9
Training loss: 0.4923558931054779
Validation loss: 2.7293746604479545

Epoch: 5| Step: 10
Training loss: 0.47023799280719664
Validation loss: 2.708370862602982

Epoch: 5| Step: 11
Training loss: 0.6671889142059418
Validation loss: 2.6617196894730712

Epoch: 326| Step: 0
Training loss: 0.3960986774747536
Validation loss: 2.6829226421422563

Epoch: 5| Step: 1
Training loss: 0.6109234625332943
Validation loss: 2.658141408965763

Epoch: 5| Step: 2
Training loss: 0.4058920310194671
Validation loss: 2.5780854771214456

Epoch: 5| Step: 3
Training loss: 0.3504983160241034
Validation loss: 2.7225900347341514

Epoch: 5| Step: 4
Training loss: 0.5470856941890789
Validation loss: 2.7145371261629987

Epoch: 5| Step: 5
Training loss: 0.4607763008532298
Validation loss: 2.7715300470432784

Epoch: 5| Step: 6
Training loss: 0.588065238697325
Validation loss: 2.713580712728804

Epoch: 5| Step: 7
Training loss: 0.405013292765581
Validation loss: 2.6736696399265876

Epoch: 5| Step: 8
Training loss: 0.3592836637114762
Validation loss: 2.6584579939796096

Epoch: 5| Step: 9
Training loss: 0.3456581215741833
Validation loss: 2.617300613767787

Epoch: 5| Step: 10
Training loss: 1.029298843874125
Validation loss: 2.595560744001789

Epoch: 5| Step: 11
Training loss: 0.5152854090151513
Validation loss: 2.6800416058126735

Epoch: 327| Step: 0
Training loss: 0.9461365568019906
Validation loss: 2.662450938750326

Epoch: 5| Step: 1
Training loss: 0.38094606635559547
Validation loss: 2.6675187974653016

Epoch: 5| Step: 2
Training loss: 0.43266616440720834
Validation loss: 2.712185432282974

Epoch: 5| Step: 3
Training loss: 0.6733962734552094
Validation loss: 2.742320587319464

Epoch: 5| Step: 4
Training loss: 0.3322688767063047
Validation loss: 2.677139639107689

Epoch: 5| Step: 5
Training loss: 0.3188847028115193
Validation loss: 2.7089312125785643

Epoch: 5| Step: 6
Training loss: 0.3186407776305036
Validation loss: 2.674130489769963

Epoch: 5| Step: 7
Training loss: 0.33371951660502575
Validation loss: 2.7180509910995667

Epoch: 5| Step: 8
Training loss: 0.39512095428345767
Validation loss: 2.687269304413488

Epoch: 5| Step: 9
Training loss: 0.464380706839324
Validation loss: 2.6384036334638905

Epoch: 5| Step: 10
Training loss: 0.5222440465493745
Validation loss: 2.668920013199885

Epoch: 5| Step: 11
Training loss: 0.18669140827032968
Validation loss: 2.6629563027157226

Epoch: 328| Step: 0
Training loss: 0.3976061131735608
Validation loss: 2.6772213107421936

Epoch: 5| Step: 1
Training loss: 0.39577793269041633
Validation loss: 2.7356520150349546

Epoch: 5| Step: 2
Training loss: 0.3811768406886399
Validation loss: 2.6901686267693994

Epoch: 5| Step: 3
Training loss: 0.37277495375013775
Validation loss: 2.642581771468386

Epoch: 5| Step: 4
Training loss: 0.5453691731818621
Validation loss: 2.6743440727031884

Epoch: 5| Step: 5
Training loss: 0.27981969277358826
Validation loss: 2.6750708349302794

Epoch: 5| Step: 6
Training loss: 0.32368274411738307
Validation loss: 2.6560379523366184

Epoch: 5| Step: 7
Training loss: 0.4732981964734645
Validation loss: 2.7117386970603317

Epoch: 5| Step: 8
Training loss: 0.9724608075597109
Validation loss: 2.678680938949542

Epoch: 5| Step: 9
Training loss: 0.40790515957786466
Validation loss: 2.6807312781517876

Epoch: 5| Step: 10
Training loss: 0.4507929544235064
Validation loss: 2.757660631963843

Epoch: 5| Step: 11
Training loss: 0.5468351894602171
Validation loss: 2.7571276642020535

Epoch: 329| Step: 0
Training loss: 0.42076402540397595
Validation loss: 2.7252967796809813

Epoch: 5| Step: 1
Training loss: 0.4401848021303669
Validation loss: 2.5960085354048976

Epoch: 5| Step: 2
Training loss: 0.5528761611087964
Validation loss: 2.6178341118959207

Epoch: 5| Step: 3
Training loss: 1.0161826143527997
Validation loss: 2.6763896686658617

Epoch: 5| Step: 4
Training loss: 0.37533597995006757
Validation loss: 2.635735229920208

Epoch: 5| Step: 5
Training loss: 0.3550101665263391
Validation loss: 2.705422665244539

Epoch: 5| Step: 6
Training loss: 0.45562060198342264
Validation loss: 2.691411985881213

Epoch: 5| Step: 7
Training loss: 0.3906197166085569
Validation loss: 2.6657304585664283

Epoch: 5| Step: 8
Training loss: 0.3941534329498719
Validation loss: 2.7341042084803937

Epoch: 5| Step: 9
Training loss: 0.3777514685596572
Validation loss: 2.7322838116463943

Epoch: 5| Step: 10
Training loss: 0.413514494383589
Validation loss: 2.671144422772171

Epoch: 5| Step: 11
Training loss: 0.44908412076949816
Validation loss: 2.7229263376026767

Epoch: 330| Step: 0
Training loss: 0.5213877842062185
Validation loss: 2.681559002757714

Epoch: 5| Step: 1
Training loss: 0.34335917233058605
Validation loss: 2.7222368381609576

Epoch: 5| Step: 2
Training loss: 0.33337057049701063
Validation loss: 2.7202803115941565

Epoch: 5| Step: 3
Training loss: 0.4170964845393507
Validation loss: 2.652375016475283

Epoch: 5| Step: 4
Training loss: 0.3000517830264767
Validation loss: 2.6274480871013894

Epoch: 5| Step: 5
Training loss: 0.9862255383009523
Validation loss: 2.701478912637174

Epoch: 5| Step: 6
Training loss: 0.38663013483332104
Validation loss: 2.699317871423101

Epoch: 5| Step: 7
Training loss: 0.5262089705612759
Validation loss: 2.6902403684678293

Epoch: 5| Step: 8
Training loss: 0.5118715189255315
Validation loss: 2.7066621074575474

Epoch: 5| Step: 9
Training loss: 0.5973830751909763
Validation loss: 2.7515491760381883

Epoch: 5| Step: 10
Training loss: 0.47525511089829614
Validation loss: 2.649800987688137

Epoch: 5| Step: 11
Training loss: 0.29672048964952163
Validation loss: 2.711992833412176

Epoch: 331| Step: 0
Training loss: 0.3538342720587687
Validation loss: 2.675316180352275

Epoch: 5| Step: 1
Training loss: 0.37333925383349326
Validation loss: 2.6963863021372974

Epoch: 5| Step: 2
Training loss: 0.4553899228962139
Validation loss: 2.6765393188030933

Epoch: 5| Step: 3
Training loss: 0.40999587420388073
Validation loss: 2.6735212262775128

Epoch: 5| Step: 4
Training loss: 1.0729795764639647
Validation loss: 2.687678046575655

Epoch: 5| Step: 5
Training loss: 0.35287584190660093
Validation loss: 2.6962125943052904

Epoch: 5| Step: 6
Training loss: 0.404300450111099
Validation loss: 2.711398789939949

Epoch: 5| Step: 7
Training loss: 0.6378938795148027
Validation loss: 2.765386387935759

Epoch: 5| Step: 8
Training loss: 0.34997927953489416
Validation loss: 2.797503288921642

Epoch: 5| Step: 9
Training loss: 0.6027099268189283
Validation loss: 2.8101200665981447

Epoch: 5| Step: 10
Training loss: 0.43648137993004327
Validation loss: 2.7320155199918177

Epoch: 5| Step: 11
Training loss: 0.2646066273675294
Validation loss: 2.674479566584591

Epoch: 332| Step: 0
Training loss: 0.2856967324054682
Validation loss: 2.7008140586248426

Epoch: 5| Step: 1
Training loss: 0.4936052973484249
Validation loss: 2.6616603466091076

Epoch: 5| Step: 2
Training loss: 0.6427193344468927
Validation loss: 2.716764119414946

Epoch: 5| Step: 3
Training loss: 0.37590985387555076
Validation loss: 2.70758016579751

Epoch: 5| Step: 4
Training loss: 0.4692268806842985
Validation loss: 2.764154082557049

Epoch: 5| Step: 5
Training loss: 0.5452485558037257
Validation loss: 2.8162015575109245

Epoch: 5| Step: 6
Training loss: 0.5023416878048348
Validation loss: 2.7721142867348987

Epoch: 5| Step: 7
Training loss: 0.3240014002631388
Validation loss: 2.7747419038951135

Epoch: 5| Step: 8
Training loss: 0.33444271649758817
Validation loss: 2.7577752082904143

Epoch: 5| Step: 9
Training loss: 0.6056158809939833
Validation loss: 2.7763218669701137

Epoch: 5| Step: 10
Training loss: 0.9354732858787762
Validation loss: 2.7172890278393633

Epoch: 5| Step: 11
Training loss: 0.3035112810253612
Validation loss: 2.662232528379154

Epoch: 333| Step: 0
Training loss: 0.3468836010047008
Validation loss: 2.7384542500350286

Epoch: 5| Step: 1
Training loss: 0.2640228055429155
Validation loss: 2.7355254087505125

Epoch: 5| Step: 2
Training loss: 0.31503856254485935
Validation loss: 2.6750377169591237

Epoch: 5| Step: 3
Training loss: 0.3906775439209285
Validation loss: 2.743159774753383

Epoch: 5| Step: 4
Training loss: 0.4516256783187591
Validation loss: 2.767213113997598

Epoch: 5| Step: 5
Training loss: 0.4922863845794736
Validation loss: 2.7429583807256437

Epoch: 5| Step: 6
Training loss: 0.29843959607891146
Validation loss: 2.7290945055693894

Epoch: 5| Step: 7
Training loss: 0.5426949009419776
Validation loss: 2.6995337560542363

Epoch: 5| Step: 8
Training loss: 0.969814269679641
Validation loss: 2.791906465128633

Epoch: 5| Step: 9
Training loss: 0.35269866247188497
Validation loss: 2.6888015870223922

Epoch: 5| Step: 10
Training loss: 0.31059316374123425
Validation loss: 2.6880346161985997

Epoch: 5| Step: 11
Training loss: 0.4607620713623633
Validation loss: 2.7080637589811025

Epoch: 334| Step: 0
Training loss: 0.5523318385198176
Validation loss: 2.726531235334372

Epoch: 5| Step: 1
Training loss: 0.3233824480354361
Validation loss: 2.6770459084671767

Epoch: 5| Step: 2
Training loss: 0.44754049858454853
Validation loss: 2.7638563006975616

Epoch: 5| Step: 3
Training loss: 0.36211021941743926
Validation loss: 2.7373132559253994

Epoch: 5| Step: 4
Training loss: 0.33137393288456735
Validation loss: 2.6719210882840856

Epoch: 5| Step: 5
Training loss: 0.8528663382864021
Validation loss: 2.769871693048403

Epoch: 5| Step: 6
Training loss: 0.4193048779267785
Validation loss: 2.7458528726854072

Epoch: 5| Step: 7
Training loss: 0.3441857264015686
Validation loss: 2.7520597395269384

Epoch: 5| Step: 8
Training loss: 0.35153560535555284
Validation loss: 2.8046143999552995

Epoch: 5| Step: 9
Training loss: 0.3535117259785307
Validation loss: 2.7400611864402684

Epoch: 5| Step: 10
Training loss: 0.46564595540146797
Validation loss: 2.671878803540473

Epoch: 5| Step: 11
Training loss: 0.3635190165148552
Validation loss: 2.6446059839534692

Epoch: 335| Step: 0
Training loss: 0.35864484252630324
Validation loss: 2.715641210146958

Epoch: 5| Step: 1
Training loss: 0.3299581433793549
Validation loss: 2.715609655128382

Epoch: 5| Step: 2
Training loss: 0.991789309881084
Validation loss: 2.6418965304835784

Epoch: 5| Step: 3
Training loss: 0.34902820551881
Validation loss: 2.673774482777844

Epoch: 5| Step: 4
Training loss: 0.3812459890748709
Validation loss: 2.7102679947569257

Epoch: 5| Step: 5
Training loss: 0.47845467938377184
Validation loss: 2.665421829888505

Epoch: 5| Step: 6
Training loss: 0.36572817707860467
Validation loss: 2.759171940614051

Epoch: 5| Step: 7
Training loss: 0.31422450361480464
Validation loss: 2.7192553602264407

Epoch: 5| Step: 8
Training loss: 0.39052057777871946
Validation loss: 2.722062092134765

Epoch: 5| Step: 9
Training loss: 0.4192279493621369
Validation loss: 2.742038001815283

Epoch: 5| Step: 10
Training loss: 0.48869327708702226
Validation loss: 2.6734454464195134

Epoch: 5| Step: 11
Training loss: 0.31888875652593673
Validation loss: 2.712237860645047

Epoch: 336| Step: 0
Training loss: 0.48670396491505497
Validation loss: 2.6904459117993302

Epoch: 5| Step: 1
Training loss: 0.34196480031919196
Validation loss: 2.755295964213366

Epoch: 5| Step: 2
Training loss: 0.2583524367488306
Validation loss: 2.779843285383514

Epoch: 5| Step: 3
Training loss: 0.35553451600426755
Validation loss: 2.7513681931262637

Epoch: 5| Step: 4
Training loss: 0.49623478364076323
Validation loss: 2.782431680052504

Epoch: 5| Step: 5
Training loss: 0.44597252235744383
Validation loss: 2.704282817687408

Epoch: 5| Step: 6
Training loss: 0.5073176393642183
Validation loss: 2.7913467321163883

Epoch: 5| Step: 7
Training loss: 0.35847588723518026
Validation loss: 2.722688898212797

Epoch: 5| Step: 8
Training loss: 0.2531570679166733
Validation loss: 2.6452412668736596

Epoch: 5| Step: 9
Training loss: 0.9091652644700503
Validation loss: 2.7606270308080827

Epoch: 5| Step: 10
Training loss: 0.48157697506091496
Validation loss: 2.647943812655591

Epoch: 5| Step: 11
Training loss: 0.4550993918496337
Validation loss: 2.66621910129175

Epoch: 337| Step: 0
Training loss: 0.43960433054067466
Validation loss: 2.6860818152116024

Epoch: 5| Step: 1
Training loss: 0.48698947168010465
Validation loss: 2.7186806366647915

Epoch: 5| Step: 2
Training loss: 0.4613672935919155
Validation loss: 2.708819247940418

Epoch: 5| Step: 3
Training loss: 0.330879390070621
Validation loss: 2.746152746038022

Epoch: 5| Step: 4
Training loss: 0.8110599961860591
Validation loss: 2.7647847661099525

Epoch: 5| Step: 5
Training loss: 0.29324265709307507
Validation loss: 2.7282630514061506

Epoch: 5| Step: 6
Training loss: 0.25042819070138156
Validation loss: 2.6958382116850435

Epoch: 5| Step: 7
Training loss: 0.3776089196618519
Validation loss: 2.7016410650004716

Epoch: 5| Step: 8
Training loss: 0.32912902264684823
Validation loss: 2.7006430357625293

Epoch: 5| Step: 9
Training loss: 0.45034982673495144
Validation loss: 2.6648553617446797

Epoch: 5| Step: 10
Training loss: 0.35170990714603934
Validation loss: 2.663655116609433

Epoch: 5| Step: 11
Training loss: 0.3831352897121046
Validation loss: 2.6226760136254805

Epoch: 338| Step: 0
Training loss: 0.48044074372335077
Validation loss: 2.73848357929212

Epoch: 5| Step: 1
Training loss: 0.8755121094864547
Validation loss: 2.7164620349222104

Epoch: 5| Step: 2
Training loss: 0.47873477199429293
Validation loss: 2.700747243475679

Epoch: 5| Step: 3
Training loss: 0.4342868866503548
Validation loss: 2.7807471020688106

Epoch: 5| Step: 4
Training loss: 0.3694509584327457
Validation loss: 2.729984020307488

Epoch: 5| Step: 5
Training loss: 0.4574932632315082
Validation loss: 2.755763127236608

Epoch: 5| Step: 6
Training loss: 0.27901101321954824
Validation loss: 2.740267513452705

Epoch: 5| Step: 7
Training loss: 0.42841146171572453
Validation loss: 2.682491100020397

Epoch: 5| Step: 8
Training loss: 0.4117186805102527
Validation loss: 2.705308961716519

Epoch: 5| Step: 9
Training loss: 0.3641897961315166
Validation loss: 2.6861223785583106

Epoch: 5| Step: 10
Training loss: 0.49777700555081345
Validation loss: 2.656949815004111

Epoch: 5| Step: 11
Training loss: 0.17401732103278758
Validation loss: 2.7381227731307454

Epoch: 339| Step: 0
Training loss: 0.36190897675022177
Validation loss: 2.709254681542019

Epoch: 5| Step: 1
Training loss: 0.32284343822339756
Validation loss: 2.678319865629862

Epoch: 5| Step: 2
Training loss: 0.33084336008993137
Validation loss: 2.7597747752188004

Epoch: 5| Step: 3
Training loss: 0.4257868145220354
Validation loss: 2.7368841302973053

Epoch: 5| Step: 4
Training loss: 0.4786008486468821
Validation loss: 2.739827719305135

Epoch: 5| Step: 5
Training loss: 0.3305128158336703
Validation loss: 2.726713105335178

Epoch: 5| Step: 6
Training loss: 0.46417542506104137
Validation loss: 2.6997208116850864

Epoch: 5| Step: 7
Training loss: 1.0655188588729396
Validation loss: 2.721349087699762

Epoch: 5| Step: 8
Training loss: 0.6881204752898896
Validation loss: 2.6881063187656715

Epoch: 5| Step: 9
Training loss: 0.4134753040263936
Validation loss: 2.743670769737255

Epoch: 5| Step: 10
Training loss: 0.40523979323121967
Validation loss: 2.7891577429230234

Epoch: 5| Step: 11
Training loss: 0.858482729925277
Validation loss: 2.7629570673500505

Epoch: 340| Step: 0
Training loss: 0.4323981529283288
Validation loss: 2.7888688591022097

Epoch: 5| Step: 1
Training loss: 0.4335568042857772
Validation loss: 2.783408925439533

Epoch: 5| Step: 2
Training loss: 0.4454382835896198
Validation loss: 2.780155773864224

Epoch: 5| Step: 3
Training loss: 0.302609251683243
Validation loss: 2.672639213269084

Epoch: 5| Step: 4
Training loss: 0.5192944553503094
Validation loss: 2.697104572383616

Epoch: 5| Step: 5
Training loss: 0.5646057978403658
Validation loss: 2.753879022125483

Epoch: 5| Step: 6
Training loss: 0.9552309814951933
Validation loss: 2.70030795478063

Epoch: 5| Step: 7
Training loss: 0.36833017178871647
Validation loss: 2.6821849054860816

Epoch: 5| Step: 8
Training loss: 0.3819197930944599
Validation loss: 2.701726003846736

Epoch: 5| Step: 9
Training loss: 0.4927469888272882
Validation loss: 2.7603525346227804

Epoch: 5| Step: 10
Training loss: 0.3902284134876258
Validation loss: 2.6221167647297947

Epoch: 5| Step: 11
Training loss: 0.17523020096058145
Validation loss: 2.689232349222101

Epoch: 341| Step: 0
Training loss: 0.5562513630025216
Validation loss: 2.797532324028936

Epoch: 5| Step: 1
Training loss: 0.49942006811321077
Validation loss: 2.6799802444154515

Epoch: 5| Step: 2
Training loss: 0.47544438881695583
Validation loss: 2.7680578917482705

Epoch: 5| Step: 3
Training loss: 0.5125736346496548
Validation loss: 2.7159644724985315

Epoch: 5| Step: 4
Training loss: 0.49872477154514977
Validation loss: 2.677877305934922

Epoch: 5| Step: 5
Training loss: 0.4385303727671748
Validation loss: 2.646118551685598

Epoch: 5| Step: 6
Training loss: 0.9372635225229672
Validation loss: 2.696956324907451

Epoch: 5| Step: 7
Training loss: 0.47366263698784994
Validation loss: 2.693597935620344

Epoch: 5| Step: 8
Training loss: 0.4182424273195841
Validation loss: 2.694170406723219

Epoch: 5| Step: 9
Training loss: 0.36014428936012116
Validation loss: 2.710795447359113

Epoch: 5| Step: 10
Training loss: 0.4924714465263242
Validation loss: 2.727420154624278

Epoch: 5| Step: 11
Training loss: 0.7390670227815661
Validation loss: 2.7177402587064297

Epoch: 342| Step: 0
Training loss: 0.3497919852433487
Validation loss: 2.747767835745963

Epoch: 5| Step: 1
Training loss: 0.48209281849686153
Validation loss: 2.630042196761448

Epoch: 5| Step: 2
Training loss: 0.41288503536601956
Validation loss: 2.68057006597023

Epoch: 5| Step: 3
Training loss: 0.5565680740994042
Validation loss: 2.648856460906526

Epoch: 5| Step: 4
Training loss: 0.5410975039663363
Validation loss: 2.646781193415691

Epoch: 5| Step: 5
Training loss: 0.4893809180797075
Validation loss: 2.6368579931344387

Epoch: 5| Step: 6
Training loss: 0.4255444979614406
Validation loss: 2.6093970086545824

Epoch: 5| Step: 7
Training loss: 0.5034655928632042
Validation loss: 2.767645297315504

Epoch: 5| Step: 8
Training loss: 0.4261351872919203
Validation loss: 2.693430485845912

Epoch: 5| Step: 9
Training loss: 0.5160653228276006
Validation loss: 2.7500384140221596

Epoch: 5| Step: 10
Training loss: 0.91189641324708
Validation loss: 2.7195746570583377

Epoch: 5| Step: 11
Training loss: 0.3733455600645155
Validation loss: 2.75010463125411

Epoch: 343| Step: 0
Training loss: 0.3873376613937053
Validation loss: 2.696212411924147

Epoch: 5| Step: 1
Training loss: 0.42456932124612584
Validation loss: 2.692239149870847

Epoch: 5| Step: 2
Training loss: 0.38053089550772756
Validation loss: 2.636018651630017

Epoch: 5| Step: 3
Training loss: 0.8024228273404086
Validation loss: 2.6163061413465067

Epoch: 5| Step: 4
Training loss: 0.566765138774753
Validation loss: 2.714374009437506

Epoch: 5| Step: 5
Training loss: 0.5116317908094774
Validation loss: 2.7837002494282115

Epoch: 5| Step: 6
Training loss: 0.42211386311609284
Validation loss: 2.7877552341850724

Epoch: 5| Step: 7
Training loss: 0.5838430992890148
Validation loss: 2.8327872624283903

Epoch: 5| Step: 8
Training loss: 0.5704974828174768
Validation loss: 2.8091543183799836

Epoch: 5| Step: 9
Training loss: 0.5345595437116083
Validation loss: 2.7235337680822824

Epoch: 5| Step: 10
Training loss: 0.8738682784983034
Validation loss: 2.7168317034290013

Epoch: 5| Step: 11
Training loss: 0.28256595888069047
Validation loss: 2.729437102442671

Epoch: 344| Step: 0
Training loss: 0.506281819933016
Validation loss: 2.706977990504052

Epoch: 5| Step: 1
Training loss: 0.5644584840302344
Validation loss: 2.6666745853803207

Epoch: 5| Step: 2
Training loss: 0.6203737944484221
Validation loss: 2.6404894242855326

Epoch: 5| Step: 3
Training loss: 0.9034300371493194
Validation loss: 2.7250478740301474

Epoch: 5| Step: 4
Training loss: 0.5441781441158221
Validation loss: 2.6783656946524643

Epoch: 5| Step: 5
Training loss: 0.49110491842787024
Validation loss: 2.7271912623108823

Epoch: 5| Step: 6
Training loss: 0.6325607269898484
Validation loss: 2.745687969356065

Epoch: 5| Step: 7
Training loss: 0.4160937562742673
Validation loss: 2.81739509707659

Epoch: 5| Step: 8
Training loss: 0.5032915017553304
Validation loss: 2.712175194825597

Epoch: 5| Step: 9
Training loss: 0.3417433560569023
Validation loss: 2.7095175825482323

Epoch: 5| Step: 10
Training loss: 0.541210235958684
Validation loss: 2.6318235492591673

Epoch: 5| Step: 11
Training loss: 0.2854197734584782
Validation loss: 2.606488483443516

Epoch: 345| Step: 0
Training loss: 0.5437186023811277
Validation loss: 2.637934320254483

Epoch: 5| Step: 1
Training loss: 0.3439614772518166
Validation loss: 2.651720302384203

Epoch: 5| Step: 2
Training loss: 0.4716691989403855
Validation loss: 2.6190327264880473

Epoch: 5| Step: 3
Training loss: 0.3199361707127315
Validation loss: 2.6618697874232096

Epoch: 5| Step: 4
Training loss: 0.3356240717734744
Validation loss: 2.7728636743500847

Epoch: 5| Step: 5
Training loss: 0.43735871417852995
Validation loss: 2.7224798742857605

Epoch: 5| Step: 6
Training loss: 0.428806772143483
Validation loss: 2.7042188323935217

Epoch: 5| Step: 7
Training loss: 0.39738883599369945
Validation loss: 2.709879614723868

Epoch: 5| Step: 8
Training loss: 0.28641719811758043
Validation loss: 2.6199499440143463

Epoch: 5| Step: 9
Training loss: 0.3895837256825693
Validation loss: 2.633065342671377

Epoch: 5| Step: 10
Training loss: 0.8210088771289035
Validation loss: 2.6296987449086737

Epoch: 5| Step: 11
Training loss: 0.4655777081532729
Validation loss: 2.7220324326602716

Epoch: 346| Step: 0
Training loss: 0.5386627760817856
Validation loss: 2.6423733733654737

Epoch: 5| Step: 1
Training loss: 0.2968386326650056
Validation loss: 2.608775837192559

Epoch: 5| Step: 2
Training loss: 0.48065388221918925
Validation loss: 2.621260784074232

Epoch: 5| Step: 3
Training loss: 0.34007208377336795
Validation loss: 2.679258017418795

Epoch: 5| Step: 4
Training loss: 0.9431219335244534
Validation loss: 2.6234549032016137

Epoch: 5| Step: 5
Training loss: 0.427273959749739
Validation loss: 2.689558527147786

Epoch: 5| Step: 6
Training loss: 0.3874103834752221
Validation loss: 2.7421896953519633

Epoch: 5| Step: 7
Training loss: 0.47572449970510733
Validation loss: 2.783713009178416

Epoch: 5| Step: 8
Training loss: 0.3540226582789335
Validation loss: 2.7380131432885633

Epoch: 5| Step: 9
Training loss: 0.4716722633930646
Validation loss: 2.7575291460121814

Epoch: 5| Step: 10
Training loss: 0.38388211818394485
Validation loss: 2.7632101223625933

Epoch: 5| Step: 11
Training loss: 0.09474468057931505
Validation loss: 2.7700320043562634

Epoch: 347| Step: 0
Training loss: 0.43095616406029974
Validation loss: 2.6953847571376257

Epoch: 5| Step: 1
Training loss: 0.37528525867428797
Validation loss: 2.7379063754618094

Epoch: 5| Step: 2
Training loss: 0.4962292583752754
Validation loss: 2.6577783787604234

Epoch: 5| Step: 3
Training loss: 0.422159452262004
Validation loss: 2.7276486453196362

Epoch: 5| Step: 4
Training loss: 0.4669538577123328
Validation loss: 2.692665078844426

Epoch: 5| Step: 5
Training loss: 0.29082389250345797
Validation loss: 2.662875241863817

Epoch: 5| Step: 6
Training loss: 0.9647014991824527
Validation loss: 2.7486827361414865

Epoch: 5| Step: 7
Training loss: 0.4263515677498309
Validation loss: 2.7935100182105037

Epoch: 5| Step: 8
Training loss: 0.4516936748542316
Validation loss: 2.7403656793713185

Epoch: 5| Step: 9
Training loss: 0.6184694762056759
Validation loss: 2.7433675416881615

Epoch: 5| Step: 10
Training loss: 0.4204788772117562
Validation loss: 2.654999131773084

Epoch: 5| Step: 11
Training loss: 0.3698847904166539
Validation loss: 2.627026774568761

Epoch: 348| Step: 0
Training loss: 0.9332474900402751
Validation loss: 2.6813728104322303

Epoch: 5| Step: 1
Training loss: 0.4578745796634912
Validation loss: 2.698336560603971

Epoch: 5| Step: 2
Training loss: 0.4755539462317562
Validation loss: 2.759289238973357

Epoch: 5| Step: 3
Training loss: 0.46337345550193265
Validation loss: 2.6079481872402512

Epoch: 5| Step: 4
Training loss: 0.29807005825846256
Validation loss: 2.67092083184096

Epoch: 5| Step: 5
Training loss: 0.373119367176778
Validation loss: 2.7522489714944993

Epoch: 5| Step: 6
Training loss: 0.5009847420959774
Validation loss: 2.7422607788844147

Epoch: 5| Step: 7
Training loss: 0.45465890460203273
Validation loss: 2.7322175951879695

Epoch: 5| Step: 8
Training loss: 0.42495398693079356
Validation loss: 2.7408998840868395

Epoch: 5| Step: 9
Training loss: 0.3838104940938782
Validation loss: 2.698262344710295

Epoch: 5| Step: 10
Training loss: 0.3476143500978182
Validation loss: 2.634222454905113

Epoch: 5| Step: 11
Training loss: 0.6498402967863428
Validation loss: 2.655872718346242

Epoch: 349| Step: 0
Training loss: 0.385304533480842
Validation loss: 2.63870052883987

Epoch: 5| Step: 1
Training loss: 0.48318461303282695
Validation loss: 2.6542804971076914

Epoch: 5| Step: 2
Training loss: 0.4864967084638036
Validation loss: 2.6874704544158443

Epoch: 5| Step: 3
Training loss: 0.3693662690487877
Validation loss: 2.69481517976624

Epoch: 5| Step: 4
Training loss: 0.4379089691920495
Validation loss: 2.732513302592954

Epoch: 5| Step: 5
Training loss: 0.38771166634839427
Validation loss: 2.6774274231364377

Epoch: 5| Step: 6
Training loss: 0.8333704383854565
Validation loss: 2.694255507345884

Epoch: 5| Step: 7
Training loss: 0.37723665000950973
Validation loss: 2.688423648585559

Epoch: 5| Step: 8
Training loss: 0.39604470816535814
Validation loss: 2.673603472898287

Epoch: 5| Step: 9
Training loss: 0.3849522094666128
Validation loss: 2.703102038217971

Epoch: 5| Step: 10
Training loss: 0.34674026604722896
Validation loss: 2.7703611334849123

Epoch: 5| Step: 11
Training loss: 0.313411182941759
Validation loss: 2.783268203420665

Epoch: 350| Step: 0
Training loss: 0.3990006300746752
Validation loss: 2.6631550478573667

Epoch: 5| Step: 1
Training loss: 0.38985464428680267
Validation loss: 2.7520258298050315

Epoch: 5| Step: 2
Training loss: 0.3766791974082005
Validation loss: 2.699948449143083

Epoch: 5| Step: 3
Training loss: 0.36961810198253464
Validation loss: 2.7014043325937775

Epoch: 5| Step: 4
Training loss: 0.3067341680047522
Validation loss: 2.71070931580048

Epoch: 5| Step: 5
Training loss: 0.39034734394806264
Validation loss: 2.695323096360464

Epoch: 5| Step: 6
Training loss: 0.37536480166783215
Validation loss: 2.771755679263539

Epoch: 5| Step: 7
Training loss: 0.42287853762809857
Validation loss: 2.7157899703299577

Epoch: 5| Step: 8
Training loss: 0.8050839826952868
Validation loss: 2.7134363492027265

Epoch: 5| Step: 9
Training loss: 0.48630284622860864
Validation loss: 2.7930938746027714

Epoch: 5| Step: 10
Training loss: 0.37329209341887815
Validation loss: 2.8053527439785153

Epoch: 5| Step: 11
Training loss: 0.5957242367865024
Validation loss: 2.7120715910477196

Epoch: 351| Step: 0
Training loss: 0.3013972378061235
Validation loss: 2.711840469118235

Epoch: 5| Step: 1
Training loss: 0.36804915843458524
Validation loss: 2.7388258939726464

Epoch: 5| Step: 2
Training loss: 0.3988862595889167
Validation loss: 2.7092988542873133

Epoch: 5| Step: 3
Training loss: 0.37695656414143175
Validation loss: 2.6802790501369986

Epoch: 5| Step: 4
Training loss: 0.5315370905935024
Validation loss: 2.64637221207773

Epoch: 5| Step: 5
Training loss: 0.42968819358076127
Validation loss: 2.7366907141365013

Epoch: 5| Step: 6
Training loss: 0.4124050255014611
Validation loss: 2.7882990535738807

Epoch: 5| Step: 7
Training loss: 0.780567977752879
Validation loss: 2.7566197475302068

Epoch: 5| Step: 8
Training loss: 0.4457320027604005
Validation loss: 2.81447212871107

Epoch: 5| Step: 9
Training loss: 0.42560304184566955
Validation loss: 2.7339922682525617

Epoch: 5| Step: 10
Training loss: 0.5568389539258936
Validation loss: 2.8433893380252684

Epoch: 5| Step: 11
Training loss: 0.28309884617912945
Validation loss: 2.7322917413705476

Epoch: 352| Step: 0
Training loss: 0.8485633110497116
Validation loss: 2.6463269964629097

Epoch: 5| Step: 1
Training loss: 0.37728888624203477
Validation loss: 2.6783660915173964

Epoch: 5| Step: 2
Training loss: 0.6037180045833278
Validation loss: 2.6716950673870192

Epoch: 5| Step: 3
Training loss: 0.4001908525001503
Validation loss: 2.678977876055919

Epoch: 5| Step: 4
Training loss: 0.5785181667521893
Validation loss: 2.6419808783521446

Epoch: 5| Step: 5
Training loss: 0.44795872986108043
Validation loss: 2.658965166684848

Epoch: 5| Step: 6
Training loss: 0.3114354000238933
Validation loss: 2.6784083665684535

Epoch: 5| Step: 7
Training loss: 0.3261464046195887
Validation loss: 2.73616569376386

Epoch: 5| Step: 8
Training loss: 0.4059713765340471
Validation loss: 2.7038846464487194

Epoch: 5| Step: 9
Training loss: 0.3843316666282143
Validation loss: 2.733188604287482

Epoch: 5| Step: 10
Training loss: 0.41424892835069815
Validation loss: 2.7042499399123163

Epoch: 5| Step: 11
Training loss: 0.40513967121892813
Validation loss: 2.693419395185582

Epoch: 353| Step: 0
Training loss: 0.7892479253771258
Validation loss: 2.750617669559561

Epoch: 5| Step: 1
Training loss: 0.4165148716832577
Validation loss: 2.694350973181569

Epoch: 5| Step: 2
Training loss: 0.362968741099587
Validation loss: 2.7416761850831475

Epoch: 5| Step: 3
Training loss: 0.3264277933259916
Validation loss: 2.643528885909807

Epoch: 5| Step: 4
Training loss: 0.40952161100091566
Validation loss: 2.7490109991647076

Epoch: 5| Step: 5
Training loss: 0.5143946215385476
Validation loss: 2.6845095874944134

Epoch: 5| Step: 6
Training loss: 0.3598133813430782
Validation loss: 2.599246077321742

Epoch: 5| Step: 7
Training loss: 0.4595345790863077
Validation loss: 2.665831674790132

Epoch: 5| Step: 8
Training loss: 0.5591497521843438
Validation loss: 2.6956261420090897

Epoch: 5| Step: 9
Training loss: 0.5581531520975598
Validation loss: 2.744935386026952

Epoch: 5| Step: 10
Training loss: 0.38311648463607495
Validation loss: 2.708209652399692

Epoch: 5| Step: 11
Training loss: 0.5348358308839399
Validation loss: 2.7394846449991013

Epoch: 354| Step: 0
Training loss: 0.26700684200942815
Validation loss: 2.7392003108317104

Epoch: 5| Step: 1
Training loss: 0.33650286363088894
Validation loss: 2.762827832632815

Epoch: 5| Step: 2
Training loss: 0.8478787740977426
Validation loss: 2.7064100638107003

Epoch: 5| Step: 3
Training loss: 0.435989924324269
Validation loss: 2.7419837231105406

Epoch: 5| Step: 4
Training loss: 0.34171635360470554
Validation loss: 2.6847666916867543

Epoch: 5| Step: 5
Training loss: 0.30984458446149854
Validation loss: 2.712942887771582

Epoch: 5| Step: 6
Training loss: 0.3986577939659004
Validation loss: 2.709627074791409

Epoch: 5| Step: 7
Training loss: 0.40774499473329745
Validation loss: 2.7391902269263704

Epoch: 5| Step: 8
Training loss: 0.49446173928168025
Validation loss: 2.7520465857521184

Epoch: 5| Step: 9
Training loss: 0.5448390938833667
Validation loss: 2.798646429836612

Epoch: 5| Step: 10
Training loss: 0.47519616167311673
Validation loss: 2.7349245009732654

Epoch: 5| Step: 11
Training loss: 0.2797660221926872
Validation loss: 2.7336243716321236

Epoch: 355| Step: 0
Training loss: 0.2800253590952973
Validation loss: 2.7752585973617623

Epoch: 5| Step: 1
Training loss: 0.3984598452716116
Validation loss: 2.7186133836351902

Epoch: 5| Step: 2
Training loss: 0.33856163210561296
Validation loss: 2.7346110868714266

Epoch: 5| Step: 3
Training loss: 0.3535261310681231
Validation loss: 2.7123839580600624

Epoch: 5| Step: 4
Training loss: 0.4190164074450733
Validation loss: 2.662543183336204

Epoch: 5| Step: 5
Training loss: 0.5152982774834147
Validation loss: 2.7812738167532376

Epoch: 5| Step: 6
Training loss: 0.35626366572353474
Validation loss: 2.712122164544138

Epoch: 5| Step: 7
Training loss: 0.4078100767100161
Validation loss: 2.682092419726918

Epoch: 5| Step: 8
Training loss: 0.8189792879836894
Validation loss: 2.7604047355154093

Epoch: 5| Step: 9
Training loss: 0.49888104163334557
Validation loss: 2.753396194876121

Epoch: 5| Step: 10
Training loss: 0.41238825975198773
Validation loss: 2.700343290186621

Epoch: 5| Step: 11
Training loss: 0.1717366940891274
Validation loss: 2.723725541757634

Epoch: 356| Step: 0
Training loss: 0.36097037673437016
Validation loss: 2.686342796058933

Epoch: 5| Step: 1
Training loss: 0.542931370168892
Validation loss: 2.7465242687791824

Epoch: 5| Step: 2
Training loss: 0.5279753681816849
Validation loss: 2.655284691230596

Epoch: 5| Step: 3
Training loss: 0.5281832758786842
Validation loss: 2.6172578223350804

Epoch: 5| Step: 4
Training loss: 0.3895884685211916
Validation loss: 2.710440909922083

Epoch: 5| Step: 5
Training loss: 0.43639796969285
Validation loss: 2.7062985234539276

Epoch: 5| Step: 6
Training loss: 0.44901919701006293
Validation loss: 2.7192591595991273

Epoch: 5| Step: 7
Training loss: 0.35632391129444285
Validation loss: 2.723481143172033

Epoch: 5| Step: 8
Training loss: 0.28916446073214713
Validation loss: 2.721951875648494

Epoch: 5| Step: 9
Training loss: 0.3380402029960207
Validation loss: 2.6737847929574183

Epoch: 5| Step: 10
Training loss: 0.777664501781805
Validation loss: 2.656358668030558

Epoch: 5| Step: 11
Training loss: 0.44300808202117936
Validation loss: 2.626451995207339

Epoch: 357| Step: 0
Training loss: 0.4486388070316752
Validation loss: 2.725835719702794

Epoch: 5| Step: 1
Training loss: 0.2629042294568692
Validation loss: 2.7030003285553064

Epoch: 5| Step: 2
Training loss: 0.4207699395893158
Validation loss: 2.7908895191332026

Epoch: 5| Step: 3
Training loss: 0.5744810219046228
Validation loss: 2.6940790606763594

Epoch: 5| Step: 4
Training loss: 0.4949770847709585
Validation loss: 2.8197516449896063

Epoch: 5| Step: 5
Training loss: 0.3429543216251167
Validation loss: 2.684093989539403

Epoch: 5| Step: 6
Training loss: 0.48847393048907
Validation loss: 2.7039450428746274

Epoch: 5| Step: 7
Training loss: 0.37933384472561665
Validation loss: 2.6692209632991046

Epoch: 5| Step: 8
Training loss: 0.40270383702409346
Validation loss: 2.6903920101197616

Epoch: 5| Step: 9
Training loss: 0.8916196789943063
Validation loss: 2.7057338686410524

Epoch: 5| Step: 10
Training loss: 0.31876120921602447
Validation loss: 2.719263269491489

Epoch: 5| Step: 11
Training loss: 0.4964012184404379
Validation loss: 2.763573476524671

Epoch: 358| Step: 0
Training loss: 0.6138405163244818
Validation loss: 2.9028582726552545

Epoch: 5| Step: 1
Training loss: 0.6192546462715185
Validation loss: 2.8142683756978624

Epoch: 5| Step: 2
Training loss: 0.4978683301242804
Validation loss: 2.801056643060946

Epoch: 5| Step: 3
Training loss: 0.5469558656032922
Validation loss: 2.7204668244115937

Epoch: 5| Step: 4
Training loss: 0.4112077042242452
Validation loss: 2.674405132533143

Epoch: 5| Step: 5
Training loss: 0.3747081017895225
Validation loss: 2.682744957605584

Epoch: 5| Step: 6
Training loss: 0.9040096148026016
Validation loss: 2.668976514763935

Epoch: 5| Step: 7
Training loss: 0.38081596322725425
Validation loss: 2.6374916733403917

Epoch: 5| Step: 8
Training loss: 0.5530203628705695
Validation loss: 2.652852859288923

Epoch: 5| Step: 9
Training loss: 0.42097679524000675
Validation loss: 2.6619240166142157

Epoch: 5| Step: 10
Training loss: 0.3556812615297445
Validation loss: 2.680038833200409

Epoch: 5| Step: 11
Training loss: 0.25344251686521113
Validation loss: 2.672465971048195

Epoch: 359| Step: 0
Training loss: 0.4934016646792391
Validation loss: 2.7311698548279395

Epoch: 5| Step: 1
Training loss: 0.2241084109771448
Validation loss: 2.7857533796097584

Epoch: 5| Step: 2
Training loss: 0.3996277403130481
Validation loss: 2.784164476838136

Epoch: 5| Step: 3
Training loss: 0.4684767403431694
Validation loss: 2.7619941606473692

Epoch: 5| Step: 4
Training loss: 0.27379860875362794
Validation loss: 2.768986370826905

Epoch: 5| Step: 5
Training loss: 0.8650034301336997
Validation loss: 2.612541713716201

Epoch: 5| Step: 6
Training loss: 0.3628413500556561
Validation loss: 2.606720036263558

Epoch: 5| Step: 7
Training loss: 0.5187849550075253
Validation loss: 2.6346252758442676

Epoch: 5| Step: 8
Training loss: 0.4503295764425201
Validation loss: 2.5922958556789304

Epoch: 5| Step: 9
Training loss: 0.364355590623985
Validation loss: 2.644988450122487

Epoch: 5| Step: 10
Training loss: 0.38485463076290083
Validation loss: 2.6787226750043325

Epoch: 5| Step: 11
Training loss: 0.1766613649713888
Validation loss: 2.747392509181225

Epoch: 360| Step: 0
Training loss: 0.43477949615587597
Validation loss: 2.8007080550939913

Epoch: 5| Step: 1
Training loss: 0.391949145011928
Validation loss: 2.7430554218265377

Epoch: 5| Step: 2
Training loss: 0.9546554659949145
Validation loss: 2.727781910277027

Epoch: 5| Step: 3
Training loss: 0.48594843738672444
Validation loss: 2.7307398147176536

Epoch: 5| Step: 4
Training loss: 0.2806697130795833
Validation loss: 2.7178475464304785

Epoch: 5| Step: 5
Training loss: 0.3910310923197174
Validation loss: 2.6620862460233674

Epoch: 5| Step: 6
Training loss: 0.3475002624661669
Validation loss: 2.7041717112415284

Epoch: 5| Step: 7
Training loss: 0.45920137186256704
Validation loss: 2.7363472864576948

Epoch: 5| Step: 8
Training loss: 0.5097417131567
Validation loss: 2.6362611877532003

Epoch: 5| Step: 9
Training loss: 0.5369010937603392
Validation loss: 2.6776786147307363

Epoch: 5| Step: 10
Training loss: 0.3530525631160427
Validation loss: 2.6643495638089028

Epoch: 5| Step: 11
Training loss: 0.3975711828949894
Validation loss: 2.724134712392604

Epoch: 361| Step: 0
Training loss: 0.31143144068296136
Validation loss: 2.704235109884515

Epoch: 5| Step: 1
Training loss: 0.3542965435796195
Validation loss: 2.7198824990186368

Epoch: 5| Step: 2
Training loss: 0.5806751197560253
Validation loss: 2.720879725420487

Epoch: 5| Step: 3
Training loss: 0.32856681007677085
Validation loss: 2.696821569839521

Epoch: 5| Step: 4
Training loss: 0.3508790260100273
Validation loss: 2.707022912332338

Epoch: 5| Step: 5
Training loss: 0.4554857548570462
Validation loss: 2.6015022641254637

Epoch: 5| Step: 6
Training loss: 0.9475925785823969
Validation loss: 2.6796321548070052

Epoch: 5| Step: 7
Training loss: 0.5627998506521421
Validation loss: 2.681639111715928

Epoch: 5| Step: 8
Training loss: 0.3303201002908519
Validation loss: 2.6192847545772415

Epoch: 5| Step: 9
Training loss: 0.3255352042522789
Validation loss: 2.7115141725206704

Epoch: 5| Step: 10
Training loss: 0.41620266430426844
Validation loss: 2.807518015118957

Epoch: 5| Step: 11
Training loss: 0.7550516075533975
Validation loss: 2.821995836010417

Epoch: 362| Step: 0
Training loss: 0.4557827581956749
Validation loss: 2.748867592874504

Epoch: 5| Step: 1
Training loss: 0.42211435733377395
Validation loss: 2.6929114257153164

Epoch: 5| Step: 2
Training loss: 0.4041222457791888
Validation loss: 2.8263094678952374

Epoch: 5| Step: 3
Training loss: 0.46283663664218117
Validation loss: 2.736453438067018

Epoch: 5| Step: 4
Training loss: 0.5226902823779519
Validation loss: 2.6389006076240227

Epoch: 5| Step: 5
Training loss: 0.5450866340759273
Validation loss: 2.677332077394228

Epoch: 5| Step: 6
Training loss: 0.4081641913286112
Validation loss: 2.738254069920347

Epoch: 5| Step: 7
Training loss: 0.4569332148074857
Validation loss: 2.7615582726600794

Epoch: 5| Step: 8
Training loss: 0.4358034276396822
Validation loss: 2.741608260546188

Epoch: 5| Step: 9
Training loss: 0.8420167003117105
Validation loss: 2.751462139499512

Epoch: 5| Step: 10
Training loss: 0.44977286620056667
Validation loss: 2.836787482636892

Epoch: 5| Step: 11
Training loss: 0.316595750740077
Validation loss: 2.721043656930667

Epoch: 363| Step: 0
Training loss: 0.41182438546642425
Validation loss: 2.759853004391529

Epoch: 5| Step: 1
Training loss: 0.42128051268099426
Validation loss: 2.6246980122533103

Epoch: 5| Step: 2
Training loss: 0.3986516264943169
Validation loss: 2.6260384972833264

Epoch: 5| Step: 3
Training loss: 0.4867887651713512
Validation loss: 2.6534546935200165

Epoch: 5| Step: 4
Training loss: 0.3518847895593582
Validation loss: 2.622179843880955

Epoch: 5| Step: 5
Training loss: 0.5575603983967443
Validation loss: 2.7801932602596824

Epoch: 5| Step: 6
Training loss: 0.3282373553874518
Validation loss: 2.740658039196898

Epoch: 5| Step: 7
Training loss: 0.4005116907704181
Validation loss: 2.76386186106218

Epoch: 5| Step: 8
Training loss: 0.48760720076904246
Validation loss: 2.7230982264370738

Epoch: 5| Step: 9
Training loss: 0.3666407593150353
Validation loss: 2.6962707216789696

Epoch: 5| Step: 10
Training loss: 0.9110989579660476
Validation loss: 2.667662964663101

Epoch: 5| Step: 11
Training loss: 0.34676029181660317
Validation loss: 2.6818042583880497

Epoch: 364| Step: 0
Training loss: 0.4284842550084672
Validation loss: 2.7043371955480855

Epoch: 5| Step: 1
Training loss: 0.3872985924006954
Validation loss: 2.6785336708253524

Epoch: 5| Step: 2
Training loss: 0.45857317746757975
Validation loss: 2.6665208777918092

Epoch: 5| Step: 3
Training loss: 0.4537098004790373
Validation loss: 2.7266689560300765

Epoch: 5| Step: 4
Training loss: 0.36769559890410086
Validation loss: 2.6681335532363404

Epoch: 5| Step: 5
Training loss: 0.41873473096879593
Validation loss: 2.657910067594997

Epoch: 5| Step: 6
Training loss: 0.7890313397288541
Validation loss: 2.7272225594783164

Epoch: 5| Step: 7
Training loss: 0.2340431009130034
Validation loss: 2.7181083024220314

Epoch: 5| Step: 8
Training loss: 0.3710980465288897
Validation loss: 2.6705325622832725

Epoch: 5| Step: 9
Training loss: 0.4391173881622469
Validation loss: 2.6616946984508734

Epoch: 5| Step: 10
Training loss: 0.463691919242222
Validation loss: 2.7368423011500758

Epoch: 5| Step: 11
Training loss: 0.2949330030956548
Validation loss: 2.666880957864478

Epoch: 365| Step: 0
Training loss: 0.45110214817539407
Validation loss: 2.715358961511777

Epoch: 5| Step: 1
Training loss: 0.33974295250388103
Validation loss: 2.734678393289832

Epoch: 5| Step: 2
Training loss: 0.3777497920585479
Validation loss: 2.7142731430544176

Epoch: 5| Step: 3
Training loss: 0.32005893160904075
Validation loss: 2.731401417897467

Epoch: 5| Step: 4
Training loss: 0.34228853014536137
Validation loss: 2.7027370233252177

Epoch: 5| Step: 5
Training loss: 0.29937830622525763
Validation loss: 2.7161398266109904

Epoch: 5| Step: 6
Training loss: 0.3492048469865247
Validation loss: 2.7242239366122263

Epoch: 5| Step: 7
Training loss: 0.7770055293864668
Validation loss: 2.708868081535613

Epoch: 5| Step: 8
Training loss: 0.3835832854667389
Validation loss: 2.7136276137541935

Epoch: 5| Step: 9
Training loss: 0.3606187610317931
Validation loss: 2.7521070045205924

Epoch: 5| Step: 10
Training loss: 0.5541147848332627
Validation loss: 2.730106553489007

Epoch: 5| Step: 11
Training loss: 0.19505105640122367
Validation loss: 2.745863386162406

Epoch: 366| Step: 0
Training loss: 0.35144787085215595
Validation loss: 2.7420710278996068

Epoch: 5| Step: 1
Training loss: 0.39582670565962697
Validation loss: 2.7241284108842856

Epoch: 5| Step: 2
Training loss: 0.47412612236648416
Validation loss: 2.7239911689505454

Epoch: 5| Step: 3
Training loss: 0.7426928757124119
Validation loss: 2.7848305781542946

Epoch: 5| Step: 4
Training loss: 0.5253928655980772
Validation loss: 2.7238426451371476

Epoch: 5| Step: 5
Training loss: 0.337757569504235
Validation loss: 2.766404640091711

Epoch: 5| Step: 6
Training loss: 0.36219489806735256
Validation loss: 2.71725972572987

Epoch: 5| Step: 7
Training loss: 0.49277988993577804
Validation loss: 2.726436182136492

Epoch: 5| Step: 8
Training loss: 0.39598290436742584
Validation loss: 2.729540556613858

Epoch: 5| Step: 9
Training loss: 0.45450198659263347
Validation loss: 2.6608655378877977

Epoch: 5| Step: 10
Training loss: 0.500932925816794
Validation loss: 2.681606306396844

Epoch: 5| Step: 11
Training loss: 0.10312112273527928
Validation loss: 2.7285401350707703

Epoch: 367| Step: 0
Training loss: 0.501344482478407
Validation loss: 2.733818190058068

Epoch: 5| Step: 1
Training loss: 0.3997185625975474
Validation loss: 2.7429665276744664

Epoch: 5| Step: 2
Training loss: 0.327663164734358
Validation loss: 2.678019442827917

Epoch: 5| Step: 3
Training loss: 0.3383343379627465
Validation loss: 2.6736260489394676

Epoch: 5| Step: 4
Training loss: 0.31034952766802887
Validation loss: 2.6947484075738153

Epoch: 5| Step: 5
Training loss: 0.27457037983924865
Validation loss: 2.7098266531634376

Epoch: 5| Step: 6
Training loss: 0.32748435694702976
Validation loss: 2.731828917451632

Epoch: 5| Step: 7
Training loss: 0.4390516524145746
Validation loss: 2.6965373200246554

Epoch: 5| Step: 8
Training loss: 0.41376282986113533
Validation loss: 2.746340364802146

Epoch: 5| Step: 9
Training loss: 0.3753890165518798
Validation loss: 2.6697423949490684

Epoch: 5| Step: 10
Training loss: 0.3057933570480527
Validation loss: 2.6772140305277174

Epoch: 5| Step: 11
Training loss: 1.6624884526131367
Validation loss: 2.6867406829592455

Epoch: 368| Step: 0
Training loss: 0.35267201291654915
Validation loss: 2.677294601584471

Epoch: 5| Step: 1
Training loss: 0.3834647441471678
Validation loss: 2.610698619319277

Epoch: 5| Step: 2
Training loss: 0.3063823438322212
Validation loss: 2.6906489343497992

Epoch: 5| Step: 3
Training loss: 0.6054057919163763
Validation loss: 2.7017452709883405

Epoch: 5| Step: 4
Training loss: 0.4016136656348198
Validation loss: 2.7571945686859345

Epoch: 5| Step: 5
Training loss: 0.27338697784166055
Validation loss: 2.7687909276103007

Epoch: 5| Step: 6
Training loss: 0.4462787952535889
Validation loss: 2.7860256084858985

Epoch: 5| Step: 7
Training loss: 0.40414403707854735
Validation loss: 2.8149768060651303

Epoch: 5| Step: 8
Training loss: 0.29752964070464566
Validation loss: 2.7594477098504226

Epoch: 5| Step: 9
Training loss: 0.7987835039207208
Validation loss: 2.720219872490051

Epoch: 5| Step: 10
Training loss: 0.3374454785389565
Validation loss: 2.6200983191592897

Epoch: 5| Step: 11
Training loss: 0.30083393279585635
Validation loss: 2.6919895162049974

Epoch: 369| Step: 0
Training loss: 0.5169324193978531
Validation loss: 2.703424326911204

Epoch: 5| Step: 1
Training loss: 0.3896574244024519
Validation loss: 2.6433357304982703

Epoch: 5| Step: 2
Training loss: 0.3955387433048948
Validation loss: 2.7175992781277483

Epoch: 5| Step: 3
Training loss: 0.42616866798487923
Validation loss: 2.75674791834033

Epoch: 5| Step: 4
Training loss: 0.7598773707412306
Validation loss: 2.7370299901093924

Epoch: 5| Step: 5
Training loss: 0.4247500855881917
Validation loss: 2.819351837532672

Epoch: 5| Step: 6
Training loss: 0.3638178850845893
Validation loss: 2.766870677896655

Epoch: 5| Step: 7
Training loss: 0.3246977840626994
Validation loss: 2.727443505368462

Epoch: 5| Step: 8
Training loss: 0.3378607896631323
Validation loss: 2.7945312433169036

Epoch: 5| Step: 9
Training loss: 0.33081967950017827
Validation loss: 2.7104463599589725

Epoch: 5| Step: 10
Training loss: 0.43625712965465074
Validation loss: 2.767860730193783

Epoch: 5| Step: 11
Training loss: 0.5052637548296731
Validation loss: 2.7231196844180254

Epoch: 370| Step: 0
Training loss: 0.3829719444960327
Validation loss: 2.7246636169940928

Epoch: 5| Step: 1
Training loss: 0.38674250443068
Validation loss: 2.72354888148405

Epoch: 5| Step: 2
Training loss: 0.429171790243632
Validation loss: 2.8068436363595435

Epoch: 5| Step: 3
Training loss: 0.49589438449905615
Validation loss: 2.8132408685106896

Epoch: 5| Step: 4
Training loss: 0.39982419770030947
Validation loss: 2.821628809342773

Epoch: 5| Step: 5
Training loss: 0.7271457095201312
Validation loss: 2.800684992414342

Epoch: 5| Step: 6
Training loss: 0.3042556685826283
Validation loss: 2.714422962685197

Epoch: 5| Step: 7
Training loss: 0.3384717783559547
Validation loss: 2.8309820998589483

Epoch: 5| Step: 8
Training loss: 0.4236094354464354
Validation loss: 2.8469750209173017

Epoch: 5| Step: 9
Training loss: 0.41681227722596736
Validation loss: 2.8060193384042957

Epoch: 5| Step: 10
Training loss: 0.49062552178713514
Validation loss: 2.8355426355801367

Epoch: 5| Step: 11
Training loss: 0.3474310456273606
Validation loss: 2.7342632888499385

Epoch: 371| Step: 0
Training loss: 0.29388200198488
Validation loss: 2.735716098517479

Epoch: 5| Step: 1
Training loss: 0.41717564569554627
Validation loss: 2.808859139231793

Epoch: 5| Step: 2
Training loss: 0.40492211246354715
Validation loss: 2.7710091253077844

Epoch: 5| Step: 3
Training loss: 0.4257611261214316
Validation loss: 2.736453189392444

Epoch: 5| Step: 4
Training loss: 0.43096033056583727
Validation loss: 2.7016455473379324

Epoch: 5| Step: 5
Training loss: 0.4502808330342548
Validation loss: 2.758211508641245

Epoch: 5| Step: 6
Training loss: 0.7197544294368742
Validation loss: 2.700340255149079

Epoch: 5| Step: 7
Training loss: 0.3310912570616486
Validation loss: 2.7369429237780234

Epoch: 5| Step: 8
Training loss: 0.33536608469584006
Validation loss: 2.7479636245910815

Epoch: 5| Step: 9
Training loss: 0.30803601045771983
Validation loss: 2.7483568159082967

Epoch: 5| Step: 10
Training loss: 0.36455264189373315
Validation loss: 2.7064694752430922

Epoch: 5| Step: 11
Training loss: 0.5114607998023867
Validation loss: 2.683617818947494

Epoch: 372| Step: 0
Training loss: 0.7645501357380482
Validation loss: 2.7407836218601966

Epoch: 5| Step: 1
Training loss: 0.5066517107360292
Validation loss: 2.700470869042936

Epoch: 5| Step: 2
Training loss: 0.3737841605200797
Validation loss: 2.6839984808854505

Epoch: 5| Step: 3
Training loss: 0.28244057958772234
Validation loss: 2.7843823777831376

Epoch: 5| Step: 4
Training loss: 0.25895619303789896
Validation loss: 2.717302671583402

Epoch: 5| Step: 5
Training loss: 0.3305806279468798
Validation loss: 2.6743228808497546

Epoch: 5| Step: 6
Training loss: 0.5786351710818494
Validation loss: 2.7370135628486514

Epoch: 5| Step: 7
Training loss: 0.3176464101240265
Validation loss: 2.6829925744762835

Epoch: 5| Step: 8
Training loss: 0.33553808331768026
Validation loss: 2.718011748538568

Epoch: 5| Step: 9
Training loss: 0.2708049753210283
Validation loss: 2.7343173538671004

Epoch: 5| Step: 10
Training loss: 0.48739962522604224
Validation loss: 2.715673028179544

Epoch: 5| Step: 11
Training loss: 0.38963428748880397
Validation loss: 2.74178491301662

Epoch: 373| Step: 0
Training loss: 0.280649112842156
Validation loss: 2.7362868827563505

Epoch: 5| Step: 1
Training loss: 0.37757855251737166
Validation loss: 2.7130504915331572

Epoch: 5| Step: 2
Training loss: 0.38305691292961563
Validation loss: 2.67856298861612

Epoch: 5| Step: 3
Training loss: 0.5484908890345651
Validation loss: 2.697381836792928

Epoch: 5| Step: 4
Training loss: 0.35471763482824636
Validation loss: 2.701355643559512

Epoch: 5| Step: 5
Training loss: 0.4164365689403071
Validation loss: 2.7539707437813696

Epoch: 5| Step: 6
Training loss: 0.7389474113810834
Validation loss: 2.737411872542619

Epoch: 5| Step: 7
Training loss: 0.38251435093978975
Validation loss: 2.806482149984525

Epoch: 5| Step: 8
Training loss: 0.5382301704963884
Validation loss: 2.7045077423767236

Epoch: 5| Step: 9
Training loss: 0.33815353837215845
Validation loss: 2.7720714804803386

Epoch: 5| Step: 10
Training loss: 0.2901727387607128
Validation loss: 2.7663579820775954

Epoch: 5| Step: 11
Training loss: 0.2781705620767968
Validation loss: 2.7266875058932656

Epoch: 374| Step: 0
Training loss: 0.30207657258371773
Validation loss: 2.660873185771391

Epoch: 5| Step: 1
Training loss: 0.36756719072316724
Validation loss: 2.706751480067606

Epoch: 5| Step: 2
Training loss: 0.2748535817671937
Validation loss: 2.7768494371349015

Epoch: 5| Step: 3
Training loss: 0.35046688598055475
Validation loss: 2.692434346163945

Epoch: 5| Step: 4
Training loss: 0.31098720833714755
Validation loss: 2.7158008086871206

Epoch: 5| Step: 5
Training loss: 0.42384943051558127
Validation loss: 2.6966094982934905

Epoch: 5| Step: 6
Training loss: 0.8512186528622486
Validation loss: 2.6697879098148136

Epoch: 5| Step: 7
Training loss: 0.3279450468064141
Validation loss: 2.692935079377555

Epoch: 5| Step: 8
Training loss: 0.38543880459209157
Validation loss: 2.7327863710527307

Epoch: 5| Step: 9
Training loss: 0.45403386093314185
Validation loss: 2.6958615393442957

Epoch: 5| Step: 10
Training loss: 0.5766756344752089
Validation loss: 2.7878325641720947

Epoch: 5| Step: 11
Training loss: 0.2257629542214245
Validation loss: 2.75340076974908

Epoch: 375| Step: 0
Training loss: 0.39071793404385424
Validation loss: 2.7154271073077485

Epoch: 5| Step: 1
Training loss: 0.30632773308119626
Validation loss: 2.7333892098875614

Epoch: 5| Step: 2
Training loss: 0.8129015077213511
Validation loss: 2.723582018696263

Epoch: 5| Step: 3
Training loss: 0.3697770702364716
Validation loss: 2.6573711086307923

Epoch: 5| Step: 4
Training loss: 0.4113857551334862
Validation loss: 2.678449557953043

Epoch: 5| Step: 5
Training loss: 0.20615585157914784
Validation loss: 2.709610893851011

Epoch: 5| Step: 6
Training loss: 0.4043201310845062
Validation loss: 2.7203319740949534

Epoch: 5| Step: 7
Training loss: 0.4132850113176547
Validation loss: 2.727233665661006

Epoch: 5| Step: 8
Training loss: 0.5470036763986482
Validation loss: 2.7282204419395706

Epoch: 5| Step: 9
Training loss: 0.32274934704860053
Validation loss: 2.7380247843999705

Epoch: 5| Step: 10
Training loss: 0.4936135839985792
Validation loss: 2.6964744477428

Epoch: 5| Step: 11
Training loss: 0.17733821104029077
Validation loss: 2.721110192759497

Epoch: 376| Step: 0
Training loss: 0.3454378155264631
Validation loss: 2.6893091691920072

Epoch: 5| Step: 1
Training loss: 0.48102143916571694
Validation loss: 2.7936549661958994

Epoch: 5| Step: 2
Training loss: 0.23814473384528503
Validation loss: 2.6723660246522893

Epoch: 5| Step: 3
Training loss: 0.2853319854600509
Validation loss: 2.67664433131711

Epoch: 5| Step: 4
Training loss: 0.38841405780914307
Validation loss: 2.752745013331248

Epoch: 5| Step: 5
Training loss: 0.28937368139291986
Validation loss: 2.782399893516804

Epoch: 5| Step: 6
Training loss: 0.30337615128586726
Validation loss: 2.7617142086899977

Epoch: 5| Step: 7
Training loss: 0.7088783121773244
Validation loss: 2.741910686812841

Epoch: 5| Step: 8
Training loss: 0.3520484638534652
Validation loss: 2.7128572290286073

Epoch: 5| Step: 9
Training loss: 0.2912348491182453
Validation loss: 2.805955888703704

Epoch: 5| Step: 10
Training loss: 0.39501068520278004
Validation loss: 2.7191663803227475

Epoch: 5| Step: 11
Training loss: 0.42977904298296526
Validation loss: 2.756604518134081

Epoch: 377| Step: 0
Training loss: 0.42807949200196904
Validation loss: 2.7387514495207377

Epoch: 5| Step: 1
Training loss: 0.3273959120567163
Validation loss: 2.82412799779091

Epoch: 5| Step: 2
Training loss: 0.3878489077167245
Validation loss: 2.7046948763935736

Epoch: 5| Step: 3
Training loss: 0.4445421013069132
Validation loss: 2.7318112770677176

Epoch: 5| Step: 4
Training loss: 0.3228387533555759
Validation loss: 2.7703513118164507

Epoch: 5| Step: 5
Training loss: 0.3381233957079836
Validation loss: 2.744587546231878

Epoch: 5| Step: 6
Training loss: 0.43908555659237275
Validation loss: 2.6712854973161977

Epoch: 5| Step: 7
Training loss: 0.4286002013930499
Validation loss: 2.7392175826746805

Epoch: 5| Step: 8
Training loss: 0.25885599098611684
Validation loss: 2.7999921509087766

Epoch: 5| Step: 9
Training loss: 0.27173386231789126
Validation loss: 2.7112328939160575

Epoch: 5| Step: 10
Training loss: 0.7459116608675429
Validation loss: 2.7335470599162557

Epoch: 5| Step: 11
Training loss: 0.42726729858092993
Validation loss: 2.748722032338507

Epoch: 378| Step: 0
Training loss: 0.2792616335102775
Validation loss: 2.758581383914288

Epoch: 5| Step: 1
Training loss: 0.4268468070040485
Validation loss: 2.7285246688485363

Epoch: 5| Step: 2
Training loss: 0.3484443881974812
Validation loss: 2.782526987498455

Epoch: 5| Step: 3
Training loss: 0.3579489984811902
Validation loss: 2.7538802774706097

Epoch: 5| Step: 4
Training loss: 0.45692724691060715
Validation loss: 2.8022880243085773

Epoch: 5| Step: 5
Training loss: 0.3603103944993184
Validation loss: 2.738027683331969

Epoch: 5| Step: 6
Training loss: 0.3874910522781485
Validation loss: 2.766150954355566

Epoch: 5| Step: 7
Training loss: 0.3217194523926414
Validation loss: 2.7541341646722657

Epoch: 5| Step: 8
Training loss: 0.8062535204551782
Validation loss: 2.7151013643177255

Epoch: 5| Step: 9
Training loss: 0.5040767292585028
Validation loss: 2.708294898763006

Epoch: 5| Step: 10
Training loss: 0.48994017508285365
Validation loss: 2.786098982316664

Epoch: 5| Step: 11
Training loss: 0.42614275783018646
Validation loss: 2.7490720917375135

Epoch: 379| Step: 0
Training loss: 0.35266227365469677
Validation loss: 2.713196977236046

Epoch: 5| Step: 1
Training loss: 0.3584997673127019
Validation loss: 2.7084580735066024

Epoch: 5| Step: 2
Training loss: 0.47209315215143816
Validation loss: 2.805075222832491

Epoch: 5| Step: 3
Training loss: 0.25416723190046736
Validation loss: 2.6965084684385037

Epoch: 5| Step: 4
Training loss: 0.4131616473427146
Validation loss: 2.7628859769585303

Epoch: 5| Step: 5
Training loss: 0.3704769228223196
Validation loss: 2.707422456643578

Epoch: 5| Step: 6
Training loss: 0.28679574977120936
Validation loss: 2.7294107223664352

Epoch: 5| Step: 7
Training loss: 0.7400248691529726
Validation loss: 2.7314139655192844

Epoch: 5| Step: 8
Training loss: 0.3893358319882227
Validation loss: 2.7418371630665797

Epoch: 5| Step: 9
Training loss: 0.3837978759996086
Validation loss: 2.7182275810950944

Epoch: 5| Step: 10
Training loss: 0.34804532428571533
Validation loss: 2.715287484696109

Epoch: 5| Step: 11
Training loss: 0.34760948466682773
Validation loss: 2.767462646113974

Epoch: 380| Step: 0
Training loss: 0.7728589138310895
Validation loss: 2.7799366839834847

Epoch: 5| Step: 1
Training loss: 0.4173844433379098
Validation loss: 2.640044319667061

Epoch: 5| Step: 2
Training loss: 0.4531581143085098
Validation loss: 2.671432354346157

Epoch: 5| Step: 3
Training loss: 0.41076081542521165
Validation loss: 2.6883074301587007

Epoch: 5| Step: 4
Training loss: 0.31031568786812225
Validation loss: 2.6996028569802926

Epoch: 5| Step: 5
Training loss: 0.2426752516435643
Validation loss: 2.809756562202313

Epoch: 5| Step: 6
Training loss: 0.34955634881781267
Validation loss: 2.772891650862075

Epoch: 5| Step: 7
Training loss: 0.530489152339008
Validation loss: 2.742466138067336

Epoch: 5| Step: 8
Training loss: 0.47932916111229
Validation loss: 2.75068259798567

Epoch: 5| Step: 9
Training loss: 0.3787187131857616
Validation loss: 2.789805640084352

Epoch: 5| Step: 10
Training loss: 0.3000463077448623
Validation loss: 2.7272463563043887

Epoch: 5| Step: 11
Training loss: 0.4755109222593712
Validation loss: 2.764055800083882

Epoch: 381| Step: 0
Training loss: 0.4775915604580929
Validation loss: 2.728785434818436

Epoch: 5| Step: 1
Training loss: 0.3559278939334927
Validation loss: 2.7009724037439433

Epoch: 5| Step: 2
Training loss: 0.4688622340307982
Validation loss: 2.810364608386188

Epoch: 5| Step: 3
Training loss: 0.706230300020916
Validation loss: 2.8083465601801088

Epoch: 5| Step: 4
Training loss: 0.43206657348041344
Validation loss: 2.7581602783217503

Epoch: 5| Step: 5
Training loss: 0.4625018454849952
Validation loss: 2.7132804907217296

Epoch: 5| Step: 6
Training loss: 0.37731520898265747
Validation loss: 2.7264529864771636

Epoch: 5| Step: 7
Training loss: 0.45124826156196807
Validation loss: 2.7643833390381154

Epoch: 5| Step: 8
Training loss: 0.43269932916438036
Validation loss: 2.6717816795723777

Epoch: 5| Step: 9
Training loss: 0.5033545023948597
Validation loss: 2.7117907805507717

Epoch: 5| Step: 10
Training loss: 0.3877901974888585
Validation loss: 2.732428102847481

Epoch: 5| Step: 11
Training loss: 0.3398111152326031
Validation loss: 2.73471998309131

Epoch: 382| Step: 0
Training loss: 0.4348805038430616
Validation loss: 2.697718640035094

Epoch: 5| Step: 1
Training loss: 0.32045829757763306
Validation loss: 2.7556510249952484

Epoch: 5| Step: 2
Training loss: 0.3243172047969058
Validation loss: 2.8131106172973834

Epoch: 5| Step: 3
Training loss: 0.38246914003584354
Validation loss: 2.8132551239164982

Epoch: 5| Step: 4
Training loss: 0.7123412223046455
Validation loss: 2.7592286030407847

Epoch: 5| Step: 5
Training loss: 0.45041328498895367
Validation loss: 2.7458741637007944

Epoch: 5| Step: 6
Training loss: 0.3196485196956905
Validation loss: 2.777596771117848

Epoch: 5| Step: 7
Training loss: 0.286473354754928
Validation loss: 2.7437368781486375

Epoch: 5| Step: 8
Training loss: 0.3158508771969932
Validation loss: 2.7407343529082895

Epoch: 5| Step: 9
Training loss: 0.2509064038250426
Validation loss: 2.7296665233787953

Epoch: 5| Step: 10
Training loss: 0.4717407660892095
Validation loss: 2.732626288591089

Epoch: 5| Step: 11
Training loss: 0.2183347575551335
Validation loss: 2.716927118239538

Epoch: 383| Step: 0
Training loss: 0.3995129712294269
Validation loss: 2.6723250461814434

Epoch: 5| Step: 1
Training loss: 0.4773552975920139
Validation loss: 2.7604205899240695

Epoch: 5| Step: 2
Training loss: 0.7137578001113883
Validation loss: 2.7094111144266964

Epoch: 5| Step: 3
Training loss: 0.32367506747060565
Validation loss: 2.7820207799342938

Epoch: 5| Step: 4
Training loss: 0.4193558537622383
Validation loss: 2.7346459172779256

Epoch: 5| Step: 5
Training loss: 0.3351314766715811
Validation loss: 2.6615864946198142

Epoch: 5| Step: 6
Training loss: 0.25616374366747624
Validation loss: 2.6856845297935665

Epoch: 5| Step: 7
Training loss: 0.34274015781314365
Validation loss: 2.653795349780564

Epoch: 5| Step: 8
Training loss: 0.42230982800528005
Validation loss: 2.7684796573758925

Epoch: 5| Step: 9
Training loss: 0.33326530010617655
Validation loss: 2.6725130564861663

Epoch: 5| Step: 10
Training loss: 0.3122395025745804
Validation loss: 2.7312214786602897

Epoch: 5| Step: 11
Training loss: 0.5785229833780161
Validation loss: 2.7375066897921636

Epoch: 384| Step: 0
Training loss: 0.3794875454385591
Validation loss: 2.6479618541864616

Epoch: 5| Step: 1
Training loss: 0.432443105836346
Validation loss: 2.7061189414189757

Epoch: 5| Step: 2
Training loss: 0.5171078830990823
Validation loss: 2.726211696526501

Epoch: 5| Step: 3
Training loss: 0.3672026976017254
Validation loss: 2.7153870366015322

Epoch: 5| Step: 4
Training loss: 0.7377227608419838
Validation loss: 2.749599868390185

Epoch: 5| Step: 5
Training loss: 0.3001839788874901
Validation loss: 2.813925357197135

Epoch: 5| Step: 6
Training loss: 0.35903537292530374
Validation loss: 2.8040290385439577

Epoch: 5| Step: 7
Training loss: 0.24501076321898818
Validation loss: 2.6259049414924283

Epoch: 5| Step: 8
Training loss: 0.31558409180250774
Validation loss: 2.7541035845241666

Epoch: 5| Step: 9
Training loss: 0.3235391480130237
Validation loss: 2.667557494310482

Epoch: 5| Step: 10
Training loss: 0.33966547576128064
Validation loss: 2.746794754493756

Epoch: 5| Step: 11
Training loss: 0.42940433882270035
Validation loss: 2.7611221107832646

Epoch: 385| Step: 0
Training loss: 0.37854864017835377
Validation loss: 2.750266091159953

Epoch: 5| Step: 1
Training loss: 0.2501413124766527
Validation loss: 2.796068760832255

Epoch: 5| Step: 2
Training loss: 0.4007190009066289
Validation loss: 2.6877470568276314

Epoch: 5| Step: 3
Training loss: 0.33699130955691514
Validation loss: 2.7173981246931755

Epoch: 5| Step: 4
Training loss: 0.44598129311383394
Validation loss: 2.7220106595463864

Epoch: 5| Step: 5
Training loss: 0.3330222878987645
Validation loss: 2.6901430470013246

Epoch: 5| Step: 6
Training loss: 0.6877965070987427
Validation loss: 2.719717310416592

Epoch: 5| Step: 7
Training loss: 0.49270186719085735
Validation loss: 2.6805650147307936

Epoch: 5| Step: 8
Training loss: 0.5166647859764736
Validation loss: 2.6933239996055143

Epoch: 5| Step: 9
Training loss: 0.3672063700920237
Validation loss: 2.857749504728488

Epoch: 5| Step: 10
Training loss: 0.40622491025475876
Validation loss: 2.7835090121107404

Epoch: 5| Step: 11
Training loss: 0.11120587044291302
Validation loss: 2.8026128514402293

Epoch: 386| Step: 0
Training loss: 0.4122622780287197
Validation loss: 2.808682913817277

Epoch: 5| Step: 1
Training loss: 0.3317318295538424
Validation loss: 2.7444636977175056

Epoch: 5| Step: 2
Training loss: 0.32554676206956173
Validation loss: 2.7681529063608696

Epoch: 5| Step: 3
Training loss: 0.7476245295413574
Validation loss: 2.755000711753647

Epoch: 5| Step: 4
Training loss: 0.31412701252567005
Validation loss: 2.717364714658264

Epoch: 5| Step: 5
Training loss: 0.34028404039774485
Validation loss: 2.746995899807703

Epoch: 5| Step: 6
Training loss: 0.42310169037436385
Validation loss: 2.717247683074475

Epoch: 5| Step: 7
Training loss: 0.3976850885152956
Validation loss: 2.7322051966940255

Epoch: 5| Step: 8
Training loss: 0.31557872074118376
Validation loss: 2.764573175593221

Epoch: 5| Step: 9
Training loss: 0.4011320924580641
Validation loss: 2.7092612633157285

Epoch: 5| Step: 10
Training loss: 0.2617810730247633
Validation loss: 2.7481727634524784

Epoch: 5| Step: 11
Training loss: 0.349101502195594
Validation loss: 2.754758979676331

Epoch: 387| Step: 0
Training loss: 0.3422012117329853
Validation loss: 2.736154903399204

Epoch: 5| Step: 1
Training loss: 0.4627080951823458
Validation loss: 2.8222889935539075

Epoch: 5| Step: 2
Training loss: 0.7246497623673522
Validation loss: 2.791624707053736

Epoch: 5| Step: 3
Training loss: 0.30764133419149065
Validation loss: 2.732535766380282

Epoch: 5| Step: 4
Training loss: 0.35199365668243676
Validation loss: 2.7173442896977558

Epoch: 5| Step: 5
Training loss: 0.42810996648748356
Validation loss: 2.762951393705007

Epoch: 5| Step: 6
Training loss: 0.3621868137158926
Validation loss: 2.784411936813577

Epoch: 5| Step: 7
Training loss: 0.29581083757315013
Validation loss: 2.6515403208632056

Epoch: 5| Step: 8
Training loss: 0.4301846835614926
Validation loss: 2.740115684500055

Epoch: 5| Step: 9
Training loss: 0.31996430102911205
Validation loss: 2.7683675318122725

Epoch: 5| Step: 10
Training loss: 0.45481478557927135
Validation loss: 2.7084928587857573

Epoch: 5| Step: 11
Training loss: 0.7222808275123753
Validation loss: 2.7075745045269657

Epoch: 388| Step: 0
Training loss: 0.3370185689967789
Validation loss: 2.7244751709184545

Epoch: 5| Step: 1
Training loss: 0.4913593924883857
Validation loss: 2.7907597411385314

Epoch: 5| Step: 2
Training loss: 0.3645373133724517
Validation loss: 2.781933064822875

Epoch: 5| Step: 3
Training loss: 0.39320175968011195
Validation loss: 2.723356506258016

Epoch: 5| Step: 4
Training loss: 0.403208239041932
Validation loss: 2.701244343162261

Epoch: 5| Step: 5
Training loss: 0.3531135780884096
Validation loss: 2.7145164640089776

Epoch: 5| Step: 6
Training loss: 0.5231164830379306
Validation loss: 2.685353782416686

Epoch: 5| Step: 7
Training loss: 0.42875836225201125
Validation loss: 2.7083693880958

Epoch: 5| Step: 8
Training loss: 0.7655380744634565
Validation loss: 2.7122599539477865

Epoch: 5| Step: 9
Training loss: 0.3299857241620449
Validation loss: 2.706897502932761

Epoch: 5| Step: 10
Training loss: 0.40584861660338895
Validation loss: 2.753148830136044

Epoch: 5| Step: 11
Training loss: 0.22970202977421678
Validation loss: 2.7050399502150366

Epoch: 389| Step: 0
Training loss: 0.74470350548452
Validation loss: 2.7068197489762973

Epoch: 5| Step: 1
Training loss: 0.38887517011755834
Validation loss: 2.7002307707865305

Epoch: 5| Step: 2
Training loss: 0.3949759592514612
Validation loss: 2.765190165759483

Epoch: 5| Step: 3
Training loss: 0.49968499453204557
Validation loss: 2.76267009502007

Epoch: 5| Step: 4
Training loss: 0.318265561750444
Validation loss: 2.688864878859482

Epoch: 5| Step: 5
Training loss: 0.31449535631244807
Validation loss: 2.712614696761502

Epoch: 5| Step: 6
Training loss: 0.3672333140909546
Validation loss: 2.7564400237616606

Epoch: 5| Step: 7
Training loss: 0.4068797988432812
Validation loss: 2.680933385590091

Epoch: 5| Step: 8
Training loss: 0.3147943789295634
Validation loss: 2.705395782952542

Epoch: 5| Step: 9
Training loss: 0.3168217909077658
Validation loss: 2.7506103994162148

Epoch: 5| Step: 10
Training loss: 0.32741367348930456
Validation loss: 2.7887959179246224

Epoch: 5| Step: 11
Training loss: 0.47809788122124536
Validation loss: 2.7441616541734364

Epoch: 390| Step: 0
Training loss: 0.26749867282966017
Validation loss: 2.711733584819965

Epoch: 5| Step: 1
Training loss: 0.33836574996759494
Validation loss: 2.7161400094827823

Epoch: 5| Step: 2
Training loss: 0.418751598468975
Validation loss: 2.6162212618910905

Epoch: 5| Step: 3
Training loss: 0.38174449089037227
Validation loss: 2.76166280413718

Epoch: 5| Step: 4
Training loss: 0.4144983157329599
Validation loss: 2.7687874957947805

Epoch: 5| Step: 5
Training loss: 0.43295658825492755
Validation loss: 2.699498016293574

Epoch: 5| Step: 6
Training loss: 0.24810169395176385
Validation loss: 2.6838760782733306

Epoch: 5| Step: 7
Training loss: 0.4679466675402584
Validation loss: 2.7750843012379747

Epoch: 5| Step: 8
Training loss: 0.6952241991530593
Validation loss: 2.696667014802958

Epoch: 5| Step: 9
Training loss: 0.28092439665485586
Validation loss: 2.7738088905359866

Epoch: 5| Step: 10
Training loss: 0.3593014766284806
Validation loss: 2.7418831514171123

Epoch: 5| Step: 11
Training loss: 0.33183832734646757
Validation loss: 2.732446539083348

Epoch: 391| Step: 0
Training loss: 0.3352782078687723
Validation loss: 2.7506702935562717

Epoch: 5| Step: 1
Training loss: 0.535703448912595
Validation loss: 2.726438674373957

Epoch: 5| Step: 2
Training loss: 0.2786200131132194
Validation loss: 2.730342609218687

Epoch: 5| Step: 3
Training loss: 0.32066679178368973
Validation loss: 2.6882691354727135

Epoch: 5| Step: 4
Training loss: 0.3667216084600088
Validation loss: 2.6979528385423017

Epoch: 5| Step: 5
Training loss: 0.2852578439411358
Validation loss: 2.8008324810398677

Epoch: 5| Step: 6
Training loss: 0.38317845816359336
Validation loss: 2.765557229025284

Epoch: 5| Step: 7
Training loss: 0.3296131154074402
Validation loss: 2.764170567750598

Epoch: 5| Step: 8
Training loss: 0.2645316200456549
Validation loss: 2.774858152069076

Epoch: 5| Step: 9
Training loss: 0.6541721054223619
Validation loss: 2.7606257533414325

Epoch: 5| Step: 10
Training loss: 0.3510086995877986
Validation loss: 2.768961167588904

Epoch: 5| Step: 11
Training loss: 0.689956049348657
Validation loss: 2.8173474147078092

Epoch: 392| Step: 0
Training loss: 0.3618066248427438
Validation loss: 2.7046439766940154

Epoch: 5| Step: 1
Training loss: 0.4131082659519317
Validation loss: 2.7144429558218417

Epoch: 5| Step: 2
Training loss: 0.5379675373171197
Validation loss: 2.672193261017915

Epoch: 5| Step: 3
Training loss: 0.9367952240818096
Validation loss: 2.69195353236156

Epoch: 5| Step: 4
Training loss: 0.23166083107832244
Validation loss: 2.6467225102527534

Epoch: 5| Step: 5
Training loss: 0.4270083916049487
Validation loss: 2.745253081991348

Epoch: 5| Step: 6
Training loss: 0.31015403660289526
Validation loss: 2.791925949657689

Epoch: 5| Step: 7
Training loss: 0.37284899751191575
Validation loss: 2.7842097696128487

Epoch: 5| Step: 8
Training loss: 0.5385749381121953
Validation loss: 2.7927982269374274

Epoch: 5| Step: 9
Training loss: 0.40472934462378335
Validation loss: 2.7962271510125594

Epoch: 5| Step: 10
Training loss: 0.26323804132898687
Validation loss: 2.709327248838525

Epoch: 5| Step: 11
Training loss: 0.16398133813482219
Validation loss: 2.728704450986994

Epoch: 393| Step: 0
Training loss: 0.42940978699183757
Validation loss: 2.732974916506097

Epoch: 5| Step: 1
Training loss: 0.45624072836247376
Validation loss: 2.700525503911707

Epoch: 5| Step: 2
Training loss: 0.39135005418073565
Validation loss: 2.732450280122536

Epoch: 5| Step: 3
Training loss: 0.4068788283324726
Validation loss: 2.6784434364029637

Epoch: 5| Step: 4
Training loss: 0.3659174646028457
Validation loss: 2.726836177130761

Epoch: 5| Step: 5
Training loss: 0.37803128082030557
Validation loss: 2.7772988782102344

Epoch: 5| Step: 6
Training loss: 0.4794349092352106
Validation loss: 2.7913659821082883

Epoch: 5| Step: 7
Training loss: 0.7572803398520084
Validation loss: 2.8032802533122663

Epoch: 5| Step: 8
Training loss: 0.42084564798422397
Validation loss: 2.6782035166248646

Epoch: 5| Step: 9
Training loss: 0.40103506933293176
Validation loss: 2.7275698858445936

Epoch: 5| Step: 10
Training loss: 0.5818083163361067
Validation loss: 2.6439839467757844

Epoch: 5| Step: 11
Training loss: 0.3402605789026917
Validation loss: 2.690132251136222

Epoch: 394| Step: 0
Training loss: 0.41538547196276154
Validation loss: 2.7076419143375037

Epoch: 5| Step: 1
Training loss: 0.3200329397987771
Validation loss: 2.743563814732573

Epoch: 5| Step: 2
Training loss: 0.4348918111314388
Validation loss: 2.7912976723298604

Epoch: 5| Step: 3
Training loss: 0.44542045288629695
Validation loss: 2.771335984053119

Epoch: 5| Step: 4
Training loss: 0.4169389034059488
Validation loss: 2.7717656966616784

Epoch: 5| Step: 5
Training loss: 0.300374734803018
Validation loss: 2.73555681029916

Epoch: 5| Step: 6
Training loss: 0.6951441185909382
Validation loss: 2.665462323763243

Epoch: 5| Step: 7
Training loss: 0.4964178783626517
Validation loss: 2.67943021245351

Epoch: 5| Step: 8
Training loss: 0.5793753068628908
Validation loss: 2.6630729765437327

Epoch: 5| Step: 9
Training loss: 0.34928424997535407
Validation loss: 2.7133572064828813

Epoch: 5| Step: 10
Training loss: 0.30635215164986723
Validation loss: 2.76571122446366

Epoch: 5| Step: 11
Training loss: 0.34301969588633957
Validation loss: 2.6911847891306535

Epoch: 395| Step: 0
Training loss: 0.4324834888261325
Validation loss: 2.7420489356814537

Epoch: 5| Step: 1
Training loss: 0.31677764711930545
Validation loss: 2.70684556934344

Epoch: 5| Step: 2
Training loss: 0.2950425437985499
Validation loss: 2.7357991533432373

Epoch: 5| Step: 3
Training loss: 0.30677701261651513
Validation loss: 2.73128949419764

Epoch: 5| Step: 4
Training loss: 0.34973476867694525
Validation loss: 2.746674050831205

Epoch: 5| Step: 5
Training loss: 0.5086041075886755
Validation loss: 2.655524143450415

Epoch: 5| Step: 6
Training loss: 0.2890605797574983
Validation loss: 2.7116476186092293

Epoch: 5| Step: 7
Training loss: 0.2948646110873086
Validation loss: 2.7592100685283034

Epoch: 5| Step: 8
Training loss: 0.22747056773293106
Validation loss: 2.7485731353458007

Epoch: 5| Step: 9
Training loss: 0.3333019065446744
Validation loss: 2.7523514130227875

Epoch: 5| Step: 10
Training loss: 0.42735930768413766
Validation loss: 2.7458162687569243

Epoch: 5| Step: 11
Training loss: 1.3582781608859735
Validation loss: 2.7424697241681164

Epoch: 396| Step: 0
Training loss: 0.4871316575840296
Validation loss: 2.800165616825424

Epoch: 5| Step: 1
Training loss: 0.39074552583970185
Validation loss: 2.7788059053847625

Epoch: 5| Step: 2
Training loss: 0.35506951266042996
Validation loss: 2.7355345674214573

Epoch: 5| Step: 3
Training loss: 0.4205866320315473
Validation loss: 2.750250270321389

Epoch: 5| Step: 4
Training loss: 0.4653015126711018
Validation loss: 2.7604806976569383

Epoch: 5| Step: 5
Training loss: 0.413263089045976
Validation loss: 2.6797169237958904

Epoch: 5| Step: 6
Training loss: 0.5378403561884926
Validation loss: 2.7291613874796896

Epoch: 5| Step: 7
Training loss: 0.376697651364433
Validation loss: 2.746730056051671

Epoch: 5| Step: 8
Training loss: 0.3010705324653202
Validation loss: 2.8252176582128716

Epoch: 5| Step: 9
Training loss: 0.6778088839246742
Validation loss: 2.7351642995332908

Epoch: 5| Step: 10
Training loss: 0.31826460194108414
Validation loss: 2.7630584719027103

Epoch: 5| Step: 11
Training loss: 0.15206821907615223
Validation loss: 2.8265091932677984

Epoch: 397| Step: 0
Training loss: 0.35527827850449345
Validation loss: 2.766995070875047

Epoch: 5| Step: 1
Training loss: 0.37382531957261267
Validation loss: 2.7359385461549266

Epoch: 5| Step: 2
Training loss: 0.4104896643472329
Validation loss: 2.7236732251039277

Epoch: 5| Step: 3
Training loss: 0.3468658055126497
Validation loss: 2.7935063838349814

Epoch: 5| Step: 4
Training loss: 0.23435420897773357
Validation loss: 2.720385662324218

Epoch: 5| Step: 5
Training loss: 0.5149444365850824
Validation loss: 2.7566042334379897

Epoch: 5| Step: 6
Training loss: 0.43596256416487233
Validation loss: 2.7674471640891696

Epoch: 5| Step: 7
Training loss: 0.610703536208318
Validation loss: 2.7385371946112356

Epoch: 5| Step: 8
Training loss: 0.4100068864883709
Validation loss: 2.7974347383820217

Epoch: 5| Step: 9
Training loss: 0.3890855207871282
Validation loss: 2.741770166445541

Epoch: 5| Step: 10
Training loss: 0.36599208141317796
Validation loss: 2.801152770842997

Epoch: 5| Step: 11
Training loss: 0.3826653723293328
Validation loss: 2.769063148700796

Epoch: 398| Step: 0
Training loss: 0.5799732049145756
Validation loss: 2.871217106528463

Epoch: 5| Step: 1
Training loss: 0.3202668134160411
Validation loss: 2.785259849472716

Epoch: 5| Step: 2
Training loss: 0.3166940228144495
Validation loss: 2.734005636063594

Epoch: 5| Step: 3
Training loss: 0.4679282296649462
Validation loss: 2.7004373893733358

Epoch: 5| Step: 4
Training loss: 0.3385309205428219
Validation loss: 2.727717773322882

Epoch: 5| Step: 5
Training loss: 0.3865217227136356
Validation loss: 2.7480415646036978

Epoch: 5| Step: 6
Training loss: 0.3638813231052151
Validation loss: 2.823125751724126

Epoch: 5| Step: 7
Training loss: 0.3465253244520011
Validation loss: 2.7963549203220963

Epoch: 5| Step: 8
Training loss: 0.3581171413045366
Validation loss: 2.725453104618207

Epoch: 5| Step: 9
Training loss: 0.42109861282626543
Validation loss: 2.8037427765107923

Epoch: 5| Step: 10
Training loss: 0.35996691015279864
Validation loss: 2.74138261479194

Epoch: 5| Step: 11
Training loss: 0.3706584183935282
Validation loss: 2.7221814019252353

Epoch: 399| Step: 0
Training loss: 0.39844613907367904
Validation loss: 2.721540444066032

Epoch: 5| Step: 1
Training loss: 0.4692853572544043
Validation loss: 2.7983523929731464

Epoch: 5| Step: 2
Training loss: 0.3636918567449616
Validation loss: 2.780201578590608

Epoch: 5| Step: 3
Training loss: 0.3732488993905072
Validation loss: 2.8103628091668615

Epoch: 5| Step: 4
Training loss: 0.2743307781426874
Validation loss: 2.7602923539198576

Epoch: 5| Step: 5
Training loss: 0.5203752474137102
Validation loss: 2.8123330137342224

Epoch: 5| Step: 6
Training loss: 0.28579499284123355
Validation loss: 2.7997231003106333

Epoch: 5| Step: 7
Training loss: 0.40941796841690414
Validation loss: 2.7957452165122163

Epoch: 5| Step: 8
Training loss: 0.31282411694749196
Validation loss: 2.7672025667566937

Epoch: 5| Step: 9
Training loss: 0.30879902350074906
Validation loss: 2.751006646579186

Epoch: 5| Step: 10
Training loss: 0.6380026808251886
Validation loss: 2.8269582206761323

Epoch: 5| Step: 11
Training loss: 0.37563931090375496
Validation loss: 2.8153428368520554

Epoch: 400| Step: 0
Training loss: 0.47104902735238113
Validation loss: 2.836223777004182

Epoch: 5| Step: 1
Training loss: 0.30063732221097805
Validation loss: 2.7724793296813934

Epoch: 5| Step: 2
Training loss: 0.30307513102074146
Validation loss: 2.725871934126649

Epoch: 5| Step: 3
Training loss: 0.3556044602454444
Validation loss: 2.7940273990637063

Epoch: 5| Step: 4
Training loss: 0.34210278581579434
Validation loss: 2.7931193811305053

Epoch: 5| Step: 5
Training loss: 0.47976347480047343
Validation loss: 2.7537406059932605

Epoch: 5| Step: 6
Training loss: 0.3810162734588743
Validation loss: 2.7569704472276166

Epoch: 5| Step: 7
Training loss: 0.3471203863958932
Validation loss: 2.8104229286261706

Epoch: 5| Step: 8
Training loss: 0.39340117989073714
Validation loss: 2.7886797894391675

Epoch: 5| Step: 9
Training loss: 0.6515926674278633
Validation loss: 2.7802539177582197

Epoch: 5| Step: 10
Training loss: 0.33632552115997516
Validation loss: 2.81989417667774

Epoch: 5| Step: 11
Training loss: 0.5143849170512155
Validation loss: 2.7369173347222917

Epoch: 401| Step: 0
Training loss: 0.621942935280812
Validation loss: 2.8157674953067664

Epoch: 5| Step: 1
Training loss: 0.4472163144044578
Validation loss: 2.821892377730182

Epoch: 5| Step: 2
Training loss: 0.34467837291333603
Validation loss: 2.8285557259063676

Epoch: 5| Step: 3
Training loss: 0.2871253340042025
Validation loss: 2.61663445470101

Epoch: 5| Step: 4
Training loss: 0.44254002083011196
Validation loss: 2.7574895466144946

Epoch: 5| Step: 5
Training loss: 0.3155797949607616
Validation loss: 2.673007223260798

Epoch: 5| Step: 6
Training loss: 0.35227639512420716
Validation loss: 2.785987683534383

Epoch: 5| Step: 7
Training loss: 0.6607715515594023
Validation loss: 2.6831636486739847

Epoch: 5| Step: 8
Training loss: 0.3755123096015427
Validation loss: 2.788287064779697

Epoch: 5| Step: 9
Training loss: 0.32791188676243305
Validation loss: 2.7626402026770567

Epoch: 5| Step: 10
Training loss: 0.44807979659012037
Validation loss: 2.8151854657135735

Epoch: 5| Step: 11
Training loss: 0.34931839922900854
Validation loss: 2.7500858004507607

Epoch: 402| Step: 0
Training loss: 0.43537805475789193
Validation loss: 2.732288760000572

Epoch: 5| Step: 1
Training loss: 0.3639169688630092
Validation loss: 2.800633602604434

Epoch: 5| Step: 2
Training loss: 0.4260107524291665
Validation loss: 2.767393753489972

Epoch: 5| Step: 3
Training loss: 0.3321765918142891
Validation loss: 2.756179279132294

Epoch: 5| Step: 4
Training loss: 0.6275782810639803
Validation loss: 2.7897281368887215

Epoch: 5| Step: 5
Training loss: 0.299664219060378
Validation loss: 2.7353823631810545

Epoch: 5| Step: 6
Training loss: 0.3948092472654397
Validation loss: 2.7328126294830506

Epoch: 5| Step: 7
Training loss: 0.4161318227186278
Validation loss: 2.739615949042546

Epoch: 5| Step: 8
Training loss: 0.27634671138758543
Validation loss: 2.798501726184172

Epoch: 5| Step: 9
Training loss: 0.4490878038703548
Validation loss: 2.7691844871958566

Epoch: 5| Step: 10
Training loss: 0.3804832361741674
Validation loss: 2.7350747511909903

Epoch: 5| Step: 11
Training loss: 0.3789370022908421
Validation loss: 2.8001261272576587

Epoch: 403| Step: 0
Training loss: 0.2879239289522103
Validation loss: 2.7748859008323374

Epoch: 5| Step: 1
Training loss: 0.3653993692874946
Validation loss: 2.72802990372224

Epoch: 5| Step: 2
Training loss: 0.3539626314502107
Validation loss: 2.794587857102585

Epoch: 5| Step: 3
Training loss: 0.29207052500463115
Validation loss: 2.735899778026523

Epoch: 5| Step: 4
Training loss: 0.47827830755206613
Validation loss: 2.646742406749466

Epoch: 5| Step: 5
Training loss: 0.43733997483717835
Validation loss: 2.663381864348659

Epoch: 5| Step: 6
Training loss: 0.38443620008466844
Validation loss: 2.738135906721073

Epoch: 5| Step: 7
Training loss: 0.3525605023487601
Validation loss: 2.756944017119312

Epoch: 5| Step: 8
Training loss: 0.2736255135607616
Validation loss: 2.794148197427795

Epoch: 5| Step: 9
Training loss: 0.7012857116268992
Validation loss: 2.7942864570761565

Epoch: 5| Step: 10
Training loss: 0.4193935175302388
Validation loss: 2.7236920707404773

Epoch: 5| Step: 11
Training loss: 0.36972359133663624
Validation loss: 2.7411907989410897

Epoch: 404| Step: 0
Training loss: 0.4465081242797248
Validation loss: 2.6633805924576475

Epoch: 5| Step: 1
Training loss: 0.6828580985130992
Validation loss: 2.6929224963338787

Epoch: 5| Step: 2
Training loss: 0.23235026626838448
Validation loss: 2.748370590971434

Epoch: 5| Step: 3
Training loss: 0.39218130980693944
Validation loss: 2.6928057969616277

Epoch: 5| Step: 4
Training loss: 0.5110489633285239
Validation loss: 2.705883775588834

Epoch: 5| Step: 5
Training loss: 0.2979955106499479
Validation loss: 2.8251709623284067

Epoch: 5| Step: 6
Training loss: 0.3958726683530808
Validation loss: 2.6940251136896367

Epoch: 5| Step: 7
Training loss: 0.4005591061299969
Validation loss: 2.792236783518277

Epoch: 5| Step: 8
Training loss: 0.4610961705619026
Validation loss: 2.7865288764128877

Epoch: 5| Step: 9
Training loss: 0.3285503128734719
Validation loss: 2.66762786668408

Epoch: 5| Step: 10
Training loss: 0.4002452493382095
Validation loss: 2.6918245810776487

Epoch: 5| Step: 11
Training loss: 0.6709655994630737
Validation loss: 2.6660735500130635

Epoch: 405| Step: 0
Training loss: 0.327379583432279
Validation loss: 2.677413041904811

Epoch: 5| Step: 1
Training loss: 0.3229307420288159
Validation loss: 2.7835464533476872

Epoch: 5| Step: 2
Training loss: 0.5119697013696655
Validation loss: 2.721733119199674

Epoch: 5| Step: 3
Training loss: 0.36877467670955355
Validation loss: 2.7373805830005082

Epoch: 5| Step: 4
Training loss: 0.666520115022975
Validation loss: 2.722968218173609

Epoch: 5| Step: 5
Training loss: 0.35504825579718857
Validation loss: 2.7058489567683806

Epoch: 5| Step: 6
Training loss: 0.29610108842034516
Validation loss: 2.751640224424085

Epoch: 5| Step: 7
Training loss: 0.29296311690954896
Validation loss: 2.720325357025865

Epoch: 5| Step: 8
Training loss: 0.42264172851662135
Validation loss: 2.7183771425837695

Epoch: 5| Step: 9
Training loss: 0.4049162244098889
Validation loss: 2.781946120137585

Epoch: 5| Step: 10
Training loss: 0.3924733112154293
Validation loss: 2.7409583993408613

Epoch: 5| Step: 11
Training loss: 0.346049108704647
Validation loss: 2.7873054333853498

Epoch: 406| Step: 0
Training loss: 0.6012914963675883
Validation loss: 2.7409263348035777

Epoch: 5| Step: 1
Training loss: 0.3574070745019858
Validation loss: 2.8166933094171593

Epoch: 5| Step: 2
Training loss: 0.43077542688130427
Validation loss: 2.758263555568049

Epoch: 5| Step: 3
Training loss: 0.28918020326433636
Validation loss: 2.7788822117622773

Epoch: 5| Step: 4
Training loss: 0.4380301601159312
Validation loss: 2.6850597517787196

Epoch: 5| Step: 5
Training loss: 0.38644952746878297
Validation loss: 2.769858211412801

Epoch: 5| Step: 6
Training loss: 0.45777532537249915
Validation loss: 2.708435560400115

Epoch: 5| Step: 7
Training loss: 0.34591466821449973
Validation loss: 2.7597204493996

Epoch: 5| Step: 8
Training loss: 0.3276046305149274
Validation loss: 2.697567296082862

Epoch: 5| Step: 9
Training loss: 0.33546272261756777
Validation loss: 2.780141734648459

Epoch: 5| Step: 10
Training loss: 0.30929228033211936
Validation loss: 2.73453051170271

Epoch: 5| Step: 11
Training loss: 0.333969963610516
Validation loss: 2.7405990716801654

Epoch: 407| Step: 0
Training loss: 0.5210228066715208
Validation loss: 2.7257642041868135

Epoch: 5| Step: 1
Training loss: 0.7263171694449286
Validation loss: 2.737250732296583

Epoch: 5| Step: 2
Training loss: 0.5230522161186844
Validation loss: 2.701469050141219

Epoch: 5| Step: 3
Training loss: 0.4133699851872433
Validation loss: 2.6915651282821713

Epoch: 5| Step: 4
Training loss: 0.30528618608385744
Validation loss: 2.6947677135447456

Epoch: 5| Step: 5
Training loss: 0.32061440498663296
Validation loss: 2.7285809300880657

Epoch: 5| Step: 6
Training loss: 0.30466340043053
Validation loss: 2.798666190453892

Epoch: 5| Step: 7
Training loss: 0.4206584237239982
Validation loss: 2.786219076182104

Epoch: 5| Step: 8
Training loss: 0.193344520229435
Validation loss: 2.7903767613821486

Epoch: 5| Step: 9
Training loss: 0.4973447150947011
Validation loss: 2.733993102152987

Epoch: 5| Step: 10
Training loss: 0.3819955555597368
Validation loss: 2.798665295957975

Epoch: 5| Step: 11
Training loss: 0.6037712666811725
Validation loss: 2.75038785077839

Epoch: 408| Step: 0
Training loss: 0.38829486139951297
Validation loss: 2.7251255508104304

Epoch: 5| Step: 1
Training loss: 0.23713504551747383
Validation loss: 2.7900303996388582

Epoch: 5| Step: 2
Training loss: 0.38673150397953465
Validation loss: 2.732595678604766

Epoch: 5| Step: 3
Training loss: 0.7230682023672859
Validation loss: 2.7367618279710695

Epoch: 5| Step: 4
Training loss: 0.3994733398025805
Validation loss: 2.82363015949383

Epoch: 5| Step: 5
Training loss: 0.23021549922843004
Validation loss: 2.793043847841722

Epoch: 5| Step: 6
Training loss: 0.4430824288659188
Validation loss: 2.8791020023594127

Epoch: 5| Step: 7
Training loss: 0.3788995447253736
Validation loss: 2.7970781838547563

Epoch: 5| Step: 8
Training loss: 0.36644200473874744
Validation loss: 2.817367865722782

Epoch: 5| Step: 9
Training loss: 0.3993630598190698
Validation loss: 2.7806996719006953

Epoch: 5| Step: 10
Training loss: 0.368426586018594
Validation loss: 2.7471458839629093

Epoch: 5| Step: 11
Training loss: 0.30201717452451493
Validation loss: 2.7790106820155955

Epoch: 409| Step: 0
Training loss: 0.41575865353348457
Validation loss: 2.7212723252737647

Epoch: 5| Step: 1
Training loss: 0.30815885779508795
Validation loss: 2.7579298165559156

Epoch: 5| Step: 2
Training loss: 0.3775119888220859
Validation loss: 2.825561246568285

Epoch: 5| Step: 3
Training loss: 0.33701739730627167
Validation loss: 2.8002192927953202

Epoch: 5| Step: 4
Training loss: 0.4676208884459441
Validation loss: 2.758659441668214

Epoch: 5| Step: 5
Training loss: 0.42318988682867176
Validation loss: 2.902913475337838

Epoch: 5| Step: 6
Training loss: 0.6100654358630513
Validation loss: 2.7886023831992204

Epoch: 5| Step: 7
Training loss: 0.39212970839772404
Validation loss: 2.7317826871126867

Epoch: 5| Step: 8
Training loss: 0.45046495815114185
Validation loss: 2.6955681131387865

Epoch: 5| Step: 9
Training loss: 0.27977580908695066
Validation loss: 2.7219962620430387

Epoch: 5| Step: 10
Training loss: 0.36412420200191054
Validation loss: 2.745144482375925

Epoch: 5| Step: 11
Training loss: 0.16041419726077072
Validation loss: 2.7455096901145013

Epoch: 410| Step: 0
Training loss: 0.3135611755642702
Validation loss: 2.7599482618742757

Epoch: 5| Step: 1
Training loss: 0.236632954437577
Validation loss: 2.8013547153297655

Epoch: 5| Step: 2
Training loss: 0.4714790059489536
Validation loss: 2.7976601526850473

Epoch: 5| Step: 3
Training loss: 0.340928571498475
Validation loss: 2.777232093194042

Epoch: 5| Step: 4
Training loss: 0.35193143136319016
Validation loss: 2.74327708421503

Epoch: 5| Step: 5
Training loss: 0.29734698221170835
Validation loss: 2.820762080659551

Epoch: 5| Step: 6
Training loss: 0.6519047293462655
Validation loss: 2.684316990217784

Epoch: 5| Step: 7
Training loss: 0.39453417710833055
Validation loss: 2.6663093172239183

Epoch: 5| Step: 8
Training loss: 0.45225533525600015
Validation loss: 2.681690173931195

Epoch: 5| Step: 9
Training loss: 0.41057634184371333
Validation loss: 2.648997837381619

Epoch: 5| Step: 10
Training loss: 0.4766683773558048
Validation loss: 2.711839725481537

Epoch: 5| Step: 11
Training loss: 0.21792838225287484
Validation loss: 2.781919884463517

Epoch: 411| Step: 0
Training loss: 0.4126931706312919
Validation loss: 2.7855636063371363

Epoch: 5| Step: 1
Training loss: 0.38965145865203693
Validation loss: 2.8419812049816935

Epoch: 5| Step: 2
Training loss: 0.3817346345810747
Validation loss: 2.793897930384829

Epoch: 5| Step: 3
Training loss: 0.43996257498191804
Validation loss: 2.7847817371130787

Epoch: 5| Step: 4
Training loss: 0.17352679205096758
Validation loss: 2.790361844392406

Epoch: 5| Step: 5
Training loss: 0.33365304585185185
Validation loss: 2.7193624018666123

Epoch: 5| Step: 6
Training loss: 0.6527089450158367
Validation loss: 2.74415641952078

Epoch: 5| Step: 7
Training loss: 0.3561677662151598
Validation loss: 2.7231747440501852

Epoch: 5| Step: 8
Training loss: 0.18083210939404795
Validation loss: 2.818200089043739

Epoch: 5| Step: 9
Training loss: 0.42725104628825994
Validation loss: 2.7346436450324547

Epoch: 5| Step: 10
Training loss: 0.4631922258396703
Validation loss: 2.782551539481572

Epoch: 5| Step: 11
Training loss: 0.405762269608437
Validation loss: 2.7592069614290415

Epoch: 412| Step: 0
Training loss: 0.26996983213899955
Validation loss: 2.7229124885435576

Epoch: 5| Step: 1
Training loss: 0.6515521883434449
Validation loss: 2.781978008271784

Epoch: 5| Step: 2
Training loss: 0.3331517219024626
Validation loss: 2.7826171972105604

Epoch: 5| Step: 3
Training loss: 0.31407214714530335
Validation loss: 2.7765553460201624

Epoch: 5| Step: 4
Training loss: 0.24505799175251444
Validation loss: 2.790406559521471

Epoch: 5| Step: 5
Training loss: 0.3244191435175434
Validation loss: 2.726187861517265

Epoch: 5| Step: 6
Training loss: 0.24333172881455273
Validation loss: 2.7767727636474224

Epoch: 5| Step: 7
Training loss: 0.31566149576146957
Validation loss: 2.7407476225925036

Epoch: 5| Step: 8
Training loss: 0.4712712669886025
Validation loss: 2.7890054997907057

Epoch: 5| Step: 9
Training loss: 0.414037307836599
Validation loss: 2.6921938153128444

Epoch: 5| Step: 10
Training loss: 0.4098433799901958
Validation loss: 2.8030519879265423

Epoch: 5| Step: 11
Training loss: 0.2034163677795378
Validation loss: 2.759368345944542

Epoch: 413| Step: 0
Training loss: 0.33263375089288
Validation loss: 2.8320470454334563

Epoch: 5| Step: 1
Training loss: 0.3577277120555786
Validation loss: 2.7336155663326833

Epoch: 5| Step: 2
Training loss: 0.3584294942345914
Validation loss: 2.7837715077179577

Epoch: 5| Step: 3
Training loss: 0.34877066998771966
Validation loss: 2.6910606129120045

Epoch: 5| Step: 4
Training loss: 0.3360400930372942
Validation loss: 2.7623344896829747

Epoch: 5| Step: 5
Training loss: 0.26826036450822227
Validation loss: 2.6950176059263415

Epoch: 5| Step: 6
Training loss: 0.330278899848655
Validation loss: 2.7421293044186834

Epoch: 5| Step: 7
Training loss: 0.6274849605657785
Validation loss: 2.7635856120707105

Epoch: 5| Step: 8
Training loss: 0.35819777190390334
Validation loss: 2.7125244808996714

Epoch: 5| Step: 9
Training loss: 0.2690774442042659
Validation loss: 2.7999563274781014

Epoch: 5| Step: 10
Training loss: 0.28601402446900226
Validation loss: 2.7520704332396355

Epoch: 5| Step: 11
Training loss: 0.21314245605577115
Validation loss: 2.8038961273404612

Epoch: 414| Step: 0
Training loss: 0.4455905180292935
Validation loss: 2.71243297652313

Epoch: 5| Step: 1
Training loss: 0.25048545553238355
Validation loss: 2.7624227623764708

Epoch: 5| Step: 2
Training loss: 0.2571290667772788
Validation loss: 2.7751372702901933

Epoch: 5| Step: 3
Training loss: 0.3691209051122738
Validation loss: 2.8120117823393267

Epoch: 5| Step: 4
Training loss: 0.4064959918372355
Validation loss: 2.776032686964521

Epoch: 5| Step: 5
Training loss: 0.28702909943299837
Validation loss: 2.779689250886168

Epoch: 5| Step: 6
Training loss: 0.24648649423356228
Validation loss: 2.7753971143624745

Epoch: 5| Step: 7
Training loss: 0.39784145651385394
Validation loss: 2.7086355713171155

Epoch: 5| Step: 8
Training loss: 0.30216983948693693
Validation loss: 2.6931398821886026

Epoch: 5| Step: 9
Training loss: 0.5439710354158985
Validation loss: 2.7681877920241282

Epoch: 5| Step: 10
Training loss: 0.3913930780322549
Validation loss: 2.714565250007627

Epoch: 5| Step: 11
Training loss: 0.3578847170918598
Validation loss: 2.795426853357726

Epoch: 415| Step: 0
Training loss: 0.3959481884146703
Validation loss: 2.688389786089903

Epoch: 5| Step: 1
Training loss: 0.4150951213002717
Validation loss: 2.7233142358720404

Epoch: 5| Step: 2
Training loss: 0.3577987268454011
Validation loss: 2.7350513602669952

Epoch: 5| Step: 3
Training loss: 0.3169098014267666
Validation loss: 2.7120838618096066

Epoch: 5| Step: 4
Training loss: 0.4570232618889081
Validation loss: 2.7921276435491715

Epoch: 5| Step: 5
Training loss: 0.1965252892458711
Validation loss: 2.7838019029203456

Epoch: 5| Step: 6
Training loss: 0.3269143818787519
Validation loss: 2.794172158443979

Epoch: 5| Step: 7
Training loss: 0.4453106261096812
Validation loss: 2.7802091072303456

Epoch: 5| Step: 8
Training loss: 0.3798785957161228
Validation loss: 2.7840889004173417

Epoch: 5| Step: 9
Training loss: 0.6060229564526701
Validation loss: 2.7571073896863156

Epoch: 5| Step: 10
Training loss: 0.3622402329191101
Validation loss: 2.7893267772568184

Epoch: 5| Step: 11
Training loss: 0.4015964122657554
Validation loss: 2.697366059330407

Epoch: 416| Step: 0
Training loss: 0.31812738964779624
Validation loss: 2.6848992767953237

Epoch: 5| Step: 1
Training loss: 0.34694920124256673
Validation loss: 2.7303455927137406

Epoch: 5| Step: 2
Training loss: 0.3816084513382658
Validation loss: 2.7410221612424794

Epoch: 5| Step: 3
Training loss: 0.42092521918605413
Validation loss: 2.7013237488244126

Epoch: 5| Step: 4
Training loss: 0.41195382893511395
Validation loss: 2.7459064743554236

Epoch: 5| Step: 5
Training loss: 0.657180897910368
Validation loss: 2.76818512205371

Epoch: 5| Step: 6
Training loss: 0.3265985906999787
Validation loss: 2.7541419467211017

Epoch: 5| Step: 7
Training loss: 0.4241321545589657
Validation loss: 2.790950805537808

Epoch: 5| Step: 8
Training loss: 0.35430039190630835
Validation loss: 2.711980902901603

Epoch: 5| Step: 9
Training loss: 0.3899786178828464
Validation loss: 2.755146867226297

Epoch: 5| Step: 10
Training loss: 0.42782050184480896
Validation loss: 2.687911120469969

Epoch: 5| Step: 11
Training loss: 0.39114892156662695
Validation loss: 2.760035244963155

Epoch: 417| Step: 0
Training loss: 0.3510251813445646
Validation loss: 2.665768644749037

Epoch: 5| Step: 1
Training loss: 0.2698161651038982
Validation loss: 2.7110191611414067

Epoch: 5| Step: 2
Training loss: 0.3741858505727498
Validation loss: 2.716279032371097

Epoch: 5| Step: 3
Training loss: 0.3105003993927112
Validation loss: 2.697545137684743

Epoch: 5| Step: 4
Training loss: 0.28915128117745353
Validation loss: 2.774502810193727

Epoch: 5| Step: 5
Training loss: 0.4139240681264463
Validation loss: 2.732901788484841

Epoch: 5| Step: 6
Training loss: 0.4293997928452314
Validation loss: 2.8148515195630806

Epoch: 5| Step: 7
Training loss: 0.33948608738829966
Validation loss: 2.785194699885621

Epoch: 5| Step: 8
Training loss: 0.28628344688159735
Validation loss: 2.7864606619614234

Epoch: 5| Step: 9
Training loss: 0.5943511379277583
Validation loss: 2.7576661291714046

Epoch: 5| Step: 10
Training loss: 0.35329780401480815
Validation loss: 2.722125179940942

Epoch: 5| Step: 11
Training loss: 0.38531234549390136
Validation loss: 2.8189995228804317

Epoch: 418| Step: 0
Training loss: 0.45783131010712264
Validation loss: 2.7360242865083593

Epoch: 5| Step: 1
Training loss: 0.30317029024757947
Validation loss: 2.704574824586079

Epoch: 5| Step: 2
Training loss: 0.2811926412373114
Validation loss: 2.7805566101969896

Epoch: 5| Step: 3
Training loss: 0.628003224387365
Validation loss: 2.7880061238940868

Epoch: 5| Step: 4
Training loss: 0.3920198713029528
Validation loss: 2.778387723885957

Epoch: 5| Step: 5
Training loss: 0.4006995893126426
Validation loss: 2.7057692984039314

Epoch: 5| Step: 6
Training loss: 0.3473940728680081
Validation loss: 2.7435632933262175

Epoch: 5| Step: 7
Training loss: 0.3970182986138096
Validation loss: 2.7153399702355205

Epoch: 5| Step: 8
Training loss: 0.3657038725853678
Validation loss: 2.72137264020329

Epoch: 5| Step: 9
Training loss: 0.44005606085551313
Validation loss: 2.753087539360263

Epoch: 5| Step: 10
Training loss: 0.41820275360666737
Validation loss: 2.816865552891035

Epoch: 5| Step: 11
Training loss: 0.25411276121920323
Validation loss: 2.724960639943499

Epoch: 419| Step: 0
Training loss: 0.353461224495841
Validation loss: 2.747406809756272

Epoch: 5| Step: 1
Training loss: 0.746536762469338
Validation loss: 2.762206243629876

Epoch: 5| Step: 2
Training loss: 0.32655716029277965
Validation loss: 2.756801527986225

Epoch: 5| Step: 3
Training loss: 0.2251889670438303
Validation loss: 2.728816713702091

Epoch: 5| Step: 4
Training loss: 0.31265698304631334
Validation loss: 2.7256689711647266

Epoch: 5| Step: 5
Training loss: 0.4040918429253509
Validation loss: 2.7399309878116047

Epoch: 5| Step: 6
Training loss: 0.29800903660078676
Validation loss: 2.7248125663655993

Epoch: 5| Step: 7
Training loss: 0.34747826381324914
Validation loss: 2.7338952506499377

Epoch: 5| Step: 8
Training loss: 0.23302914920651327
Validation loss: 2.7459959842069526

Epoch: 5| Step: 9
Training loss: 0.2598498215140926
Validation loss: 2.7634899928762606

Epoch: 5| Step: 10
Training loss: 0.4410458502873621
Validation loss: 2.757808656482702

Epoch: 5| Step: 11
Training loss: 0.13044159658055593
Validation loss: 2.8354987128161833

Epoch: 420| Step: 0
Training loss: 0.5651724169134971
Validation loss: 2.780407831650648

Epoch: 5| Step: 1
Training loss: 0.38925433963617945
Validation loss: 2.8046449287888593

Epoch: 5| Step: 2
Training loss: 0.2857501234202815
Validation loss: 2.794341689340496

Epoch: 5| Step: 3
Training loss: 0.39505329152850593
Validation loss: 2.7709494019102143

Epoch: 5| Step: 4
Training loss: 0.34505385512370934
Validation loss: 2.765483105426433

Epoch: 5| Step: 5
Training loss: 0.37563141672934214
Validation loss: 2.7878414084678136

Epoch: 5| Step: 6
Training loss: 0.2140151779048706
Validation loss: 2.7862835457905812

Epoch: 5| Step: 7
Training loss: 0.3163939461847188
Validation loss: 2.7848871251751257

Epoch: 5| Step: 8
Training loss: 0.4527999764573863
Validation loss: 2.8947628973599353

Epoch: 5| Step: 9
Training loss: 0.25339353586945323
Validation loss: 2.845296655729849

Epoch: 5| Step: 10
Training loss: 0.28281925098517874
Validation loss: 2.746932775637004

Epoch: 5| Step: 11
Training loss: 0.24509692013300405
Validation loss: 2.7980767763577936

Epoch: 421| Step: 0
Training loss: 0.34364011482059015
Validation loss: 2.7194449698446914

Epoch: 5| Step: 1
Training loss: 0.36209021952804193
Validation loss: 2.7648924739295877

Epoch: 5| Step: 2
Training loss: 0.35944357507991326
Validation loss: 2.7776943116098916

Epoch: 5| Step: 3
Training loss: 0.5693027754952005
Validation loss: 2.7925551101519517

Epoch: 5| Step: 4
Training loss: 0.38320136269135974
Validation loss: 2.8232049454641115

Epoch: 5| Step: 5
Training loss: 0.3850958128705718
Validation loss: 2.7853264134711258

Epoch: 5| Step: 6
Training loss: 0.3898655566153942
Validation loss: 2.7458965000958218

Epoch: 5| Step: 7
Training loss: 0.29838751429222615
Validation loss: 2.7675987714896038

Epoch: 5| Step: 8
Training loss: 0.4325329976365903
Validation loss: 2.7395982282593834

Epoch: 5| Step: 9
Training loss: 0.30394958736255495
Validation loss: 2.7839702204942194

Epoch: 5| Step: 10
Training loss: 0.3667407869431255
Validation loss: 2.7245086979467286

Epoch: 5| Step: 11
Training loss: 0.37914168525325886
Validation loss: 2.6952902198644635

Epoch: 422| Step: 0
Training loss: 0.3751907062396697
Validation loss: 2.800616991519296

Epoch: 5| Step: 1
Training loss: 0.4521406597350076
Validation loss: 2.730240997435372

Epoch: 5| Step: 2
Training loss: 0.6030293947254469
Validation loss: 2.715211246051532

Epoch: 5| Step: 3
Training loss: 0.2720172646886312
Validation loss: 2.716607612619399

Epoch: 5| Step: 4
Training loss: 0.34739544547696555
Validation loss: 2.7682066827090033

Epoch: 5| Step: 5
Training loss: 0.3599772175891518
Validation loss: 2.8263869099423924

Epoch: 5| Step: 6
Training loss: 0.4477436559537593
Validation loss: 2.82106614192221

Epoch: 5| Step: 7
Training loss: 0.35870524898232053
Validation loss: 2.791731144506842

Epoch: 5| Step: 8
Training loss: 0.30701545111700623
Validation loss: 2.835859628664378

Epoch: 5| Step: 9
Training loss: 0.5137846210165662
Validation loss: 2.77237675758367

Epoch: 5| Step: 10
Training loss: 0.33541778905850544
Validation loss: 2.7492866891464853

Epoch: 5| Step: 11
Training loss: 0.3474095251291523
Validation loss: 2.824812492966987

Epoch: 423| Step: 0
Training loss: 0.42808855973693793
Validation loss: 2.7814115805962625

Epoch: 5| Step: 1
Training loss: 0.289510714507264
Validation loss: 2.8219815684346776

Epoch: 5| Step: 2
Training loss: 0.4735317948360326
Validation loss: 2.8769182046401194

Epoch: 5| Step: 3
Training loss: 0.17774242340980345
Validation loss: 2.8146532610986323

Epoch: 5| Step: 4
Training loss: 0.2993981030534994
Validation loss: 2.8511609008037113

Epoch: 5| Step: 5
Training loss: 0.3155556300384996
Validation loss: 2.8087825189996165

Epoch: 5| Step: 6
Training loss: 0.35535141821492783
Validation loss: 2.7425572036519665

Epoch: 5| Step: 7
Training loss: 0.5912947838176269
Validation loss: 2.775477451628016

Epoch: 5| Step: 8
Training loss: 0.36443013878199715
Validation loss: 2.800199213207276

Epoch: 5| Step: 9
Training loss: 0.39460141908203883
Validation loss: 2.8962152364184157

Epoch: 5| Step: 10
Training loss: 0.4292467110562837
Validation loss: 2.830313603213997

Epoch: 5| Step: 11
Training loss: 0.4426835745077708
Validation loss: 2.8109027671682547

Epoch: 424| Step: 0
Training loss: 0.5492232994010546
Validation loss: 2.776196056221471

Epoch: 5| Step: 1
Training loss: 0.19588179588944107
Validation loss: 2.7617033257024484

Epoch: 5| Step: 2
Training loss: 0.46201891041836707
Validation loss: 2.757032790291236

Epoch: 5| Step: 3
Training loss: 0.32179232433682764
Validation loss: 2.7979287590131015

Epoch: 5| Step: 4
Training loss: 0.4140105844736409
Validation loss: 2.7178506021240114

Epoch: 5| Step: 5
Training loss: 0.4038117488198142
Validation loss: 2.8508599099447465

Epoch: 5| Step: 6
Training loss: 0.3656849453357163
Validation loss: 2.8271612559079005

Epoch: 5| Step: 7
Training loss: 0.3011059556554809
Validation loss: 2.834974726267698

Epoch: 5| Step: 8
Training loss: 0.37184115985160926
Validation loss: 2.796523084468949

Epoch: 5| Step: 9
Training loss: 0.2739787602998241
Validation loss: 2.7798031426044463

Epoch: 5| Step: 10
Training loss: 0.6431445839646215
Validation loss: 2.7872630635877305

Epoch: 5| Step: 11
Training loss: 0.20649029576403938
Validation loss: 2.738963544138492

Epoch: 425| Step: 0
Training loss: 0.3397753416467088
Validation loss: 2.7558914496314606

Epoch: 5| Step: 1
Training loss: 0.3496246973867679
Validation loss: 2.7349742541562985

Epoch: 5| Step: 2
Training loss: 0.39867723022189255
Validation loss: 2.742997632172949

Epoch: 5| Step: 3
Training loss: 0.3169919233150639
Validation loss: 2.7909580204302236

Epoch: 5| Step: 4
Training loss: 0.5135196126518684
Validation loss: 2.6782749519817854

Epoch: 5| Step: 5
Training loss: 0.36482730150413706
Validation loss: 2.7900107630085684

Epoch: 5| Step: 6
Training loss: 0.5858924594098318
Validation loss: 2.7840599124388454

Epoch: 5| Step: 7
Training loss: 0.3979710485169585
Validation loss: 2.8354966913086357

Epoch: 5| Step: 8
Training loss: 0.47383239316472453
Validation loss: 2.837534301679318

Epoch: 5| Step: 9
Training loss: 0.4354287231029447
Validation loss: 2.8073659449407136

Epoch: 5| Step: 10
Training loss: 0.35853308037704856
Validation loss: 2.7933660691428734

Epoch: 5| Step: 11
Training loss: 0.20670545783237862
Validation loss: 2.7446176243326046

Epoch: 426| Step: 0
Training loss: 0.37893841793723637
Validation loss: 2.718910762447783

Epoch: 5| Step: 1
Training loss: 0.369714563238514
Validation loss: 2.6975951365245003

Epoch: 5| Step: 2
Training loss: 0.7601187309579985
Validation loss: 2.7419411239725866

Epoch: 5| Step: 3
Training loss: 0.3357000176896496
Validation loss: 2.737352577432002

Epoch: 5| Step: 4
Training loss: 0.3046877812115276
Validation loss: 2.752129232575901

Epoch: 5| Step: 5
Training loss: 0.3934973208737326
Validation loss: 2.783235766124612

Epoch: 5| Step: 6
Training loss: 0.3039675667889637
Validation loss: 2.7688371786682775

Epoch: 5| Step: 7
Training loss: 0.4455907019568376
Validation loss: 2.8523398258708483

Epoch: 5| Step: 8
Training loss: 0.3807789252972931
Validation loss: 2.8400384240674086

Epoch: 5| Step: 9
Training loss: 0.3677508719516274
Validation loss: 2.7238407194713594

Epoch: 5| Step: 10
Training loss: 0.3566724915489309
Validation loss: 2.759274503145796

Epoch: 5| Step: 11
Training loss: 0.3158458527173909
Validation loss: 2.7169588352891485

Epoch: 427| Step: 0
Training loss: 0.4380280169405582
Validation loss: 2.6653297967446803

Epoch: 5| Step: 1
Training loss: 0.4515760353726125
Validation loss: 2.6945723139243265

Epoch: 5| Step: 2
Training loss: 0.41818051900468656
Validation loss: 2.7054027817009145

Epoch: 5| Step: 3
Training loss: 0.32952659847834687
Validation loss: 2.70854535495599

Epoch: 5| Step: 4
Training loss: 0.6950816939387624
Validation loss: 2.7288575246068265

Epoch: 5| Step: 5
Training loss: 0.3003032155343355
Validation loss: 2.7541017359256568

Epoch: 5| Step: 6
Training loss: 0.3543429520326601
Validation loss: 2.7566124788014723

Epoch: 5| Step: 7
Training loss: 0.4127435008853768
Validation loss: 2.696904210934

Epoch: 5| Step: 8
Training loss: 0.44423077355374346
Validation loss: 2.7846388690731705

Epoch: 5| Step: 9
Training loss: 0.3464728799695769
Validation loss: 2.754938683297681

Epoch: 5| Step: 10
Training loss: 0.24781498620324255
Validation loss: 2.7816389004841673

Epoch: 5| Step: 11
Training loss: 0.5149124308087417
Validation loss: 2.6397405343237503

Epoch: 428| Step: 0
Training loss: 0.3941457772650693
Validation loss: 2.714600172939654

Epoch: 5| Step: 1
Training loss: 0.3709360289444071
Validation loss: 2.68810935837713

Epoch: 5| Step: 2
Training loss: 0.3746863682835583
Validation loss: 2.7018760541110396

Epoch: 5| Step: 3
Training loss: 0.34549690820232515
Validation loss: 2.7476174516770424

Epoch: 5| Step: 4
Training loss: 0.5962338444182508
Validation loss: 2.791813132491065

Epoch: 5| Step: 5
Training loss: 0.35218510069279463
Validation loss: 2.7865550508678005

Epoch: 5| Step: 6
Training loss: 0.31771913755004333
Validation loss: 2.817557626432226

Epoch: 5| Step: 7
Training loss: 0.43727513051976785
Validation loss: 2.7646623182380607

Epoch: 5| Step: 8
Training loss: 0.43188100482172276
Validation loss: 2.752863725871339

Epoch: 5| Step: 9
Training loss: 0.4091795418313434
Validation loss: 2.720240597228394

Epoch: 5| Step: 10
Training loss: 0.3086577602587824
Validation loss: 2.7113312610263125

Epoch: 5| Step: 11
Training loss: 0.3584396795923269
Validation loss: 2.745238118836739

Epoch: 429| Step: 0
Training loss: 0.32777425775662855
Validation loss: 2.762616622629379

Epoch: 5| Step: 1
Training loss: 0.4650807297523284
Validation loss: 2.7616382121312517

Epoch: 5| Step: 2
Training loss: 0.32484034046110394
Validation loss: 2.7680677197598422

Epoch: 5| Step: 3
Training loss: 0.2661928810270784
Validation loss: 2.733674728096841

Epoch: 5| Step: 4
Training loss: 0.2764361130457322
Validation loss: 2.7303925277556487

Epoch: 5| Step: 5
Training loss: 0.3390894993346968
Validation loss: 2.805474577313168

Epoch: 5| Step: 6
Training loss: 0.29650596218402725
Validation loss: 2.7997819650998883

Epoch: 5| Step: 7
Training loss: 0.4839492434111761
Validation loss: 2.8144659059275368

Epoch: 5| Step: 8
Training loss: 0.3714960828474496
Validation loss: 2.748704447965152

Epoch: 5| Step: 9
Training loss: 0.32327946796543733
Validation loss: 2.7904343209902716

Epoch: 5| Step: 10
Training loss: 0.29057809081971975
Validation loss: 2.773284069706554

Epoch: 5| Step: 11
Training loss: 1.193820545848241
Validation loss: 2.736807905235552

Epoch: 430| Step: 0
Training loss: 0.4397174464142669
Validation loss: 2.8050428748013143

Epoch: 5| Step: 1
Training loss: 0.37403570807425834
Validation loss: 2.8508696215094025

Epoch: 5| Step: 2
Training loss: 0.26448828436715677
Validation loss: 2.778744075841476

Epoch: 5| Step: 3
Training loss: 0.2930005755622275
Validation loss: 2.7446915694533094

Epoch: 5| Step: 4
Training loss: 0.37403415435497156
Validation loss: 2.791213252601111

Epoch: 5| Step: 5
Training loss: 0.40434817665908834
Validation loss: 2.8555429103699566

Epoch: 5| Step: 6
Training loss: 0.4243022007643953
Validation loss: 2.7914523011551493

Epoch: 5| Step: 7
Training loss: 0.4391191018433541
Validation loss: 2.7133578508516734

Epoch: 5| Step: 8
Training loss: 0.4348422453371444
Validation loss: 2.737671879085708

Epoch: 5| Step: 9
Training loss: 0.39878123546702254
Validation loss: 2.75282278188257

Epoch: 5| Step: 10
Training loss: 0.5700934786439139
Validation loss: 2.7820408514653967

Epoch: 5| Step: 11
Training loss: 0.3593400440630395
Validation loss: 2.8012446362002765

Epoch: 431| Step: 0
Training loss: 0.30217398182279326
Validation loss: 2.786775743225911

Epoch: 5| Step: 1
Training loss: 0.37959247074930713
Validation loss: 2.858831430406044

Epoch: 5| Step: 2
Training loss: 0.3005110034403792
Validation loss: 2.8230394123225606

Epoch: 5| Step: 3
Training loss: 0.44375134252963006
Validation loss: 2.869699657832194

Epoch: 5| Step: 4
Training loss: 0.44814572096180644
Validation loss: 2.8542567166975594

Epoch: 5| Step: 5
Training loss: 0.375912311563117
Validation loss: 2.766830896239039

Epoch: 5| Step: 6
Training loss: 0.5204525572915623
Validation loss: 2.8271563787354284

Epoch: 5| Step: 7
Training loss: 0.19360408325881773
Validation loss: 2.8176135131243916

Epoch: 5| Step: 8
Training loss: 0.35062305179605485
Validation loss: 2.9178967413811407

Epoch: 5| Step: 9
Training loss: 0.3076156979479375
Validation loss: 2.8909474510907067

Epoch: 5| Step: 10
Training loss: 0.5253736642134842
Validation loss: 2.8776500727011087

Epoch: 5| Step: 11
Training loss: 0.6676495107091458
Validation loss: 2.851119751720991

Epoch: 432| Step: 0
Training loss: 0.33937022225123775
Validation loss: 2.8472738336263443

Epoch: 5| Step: 1
Training loss: 0.39828613622458436
Validation loss: 2.7903501741954297

Epoch: 5| Step: 2
Training loss: 0.3014941004528607
Validation loss: 2.7593926575708845

Epoch: 5| Step: 3
Training loss: 0.3734680913421898
Validation loss: 2.8041392209286147

Epoch: 5| Step: 4
Training loss: 0.33086475336416565
Validation loss: 2.826751280511971

Epoch: 5| Step: 5
Training loss: 0.37371947285046125
Validation loss: 2.824108151512241

Epoch: 5| Step: 6
Training loss: 0.3155018868503281
Validation loss: 2.7904627550270305

Epoch: 5| Step: 7
Training loss: 0.32852459599315004
Validation loss: 2.753401022304937

Epoch: 5| Step: 8
Training loss: 0.3264349145204427
Validation loss: 2.8020469859340857

Epoch: 5| Step: 9
Training loss: 0.3040102988948641
Validation loss: 2.8167338681151666

Epoch: 5| Step: 10
Training loss: 0.5347289168226391
Validation loss: 2.760383970438855

Epoch: 5| Step: 11
Training loss: 0.431388367002807
Validation loss: 2.8165904675753604

Epoch: 433| Step: 0
Training loss: 0.5573939796958257
Validation loss: 2.816671470961527

Epoch: 5| Step: 1
Training loss: 0.3576668905306065
Validation loss: 2.7991073195842073

Epoch: 5| Step: 2
Training loss: 0.32018615975770537
Validation loss: 2.8068286246114957

Epoch: 5| Step: 3
Training loss: 0.4425534388769196
Validation loss: 2.7681342629319112

Epoch: 5| Step: 4
Training loss: 0.3338208272159937
Validation loss: 2.7257176340875553

Epoch: 5| Step: 5
Training loss: 0.4042839932808262
Validation loss: 2.770883697157216

Epoch: 5| Step: 6
Training loss: 0.4480793476393343
Validation loss: 2.718675919323708

Epoch: 5| Step: 7
Training loss: 0.37711933404967063
Validation loss: 2.686495408365271

Epoch: 5| Step: 8
Training loss: 0.24391701185199627
Validation loss: 2.6780021231262796

Epoch: 5| Step: 9
Training loss: 0.2993968961190412
Validation loss: 2.7504117216776494

Epoch: 5| Step: 10
Training loss: 0.39559528655068604
Validation loss: 2.8349587719390303

Epoch: 5| Step: 11
Training loss: 0.4518460277909158
Validation loss: 2.749428776455531

Epoch: 434| Step: 0
Training loss: 0.3484147936859523
Validation loss: 2.7552388928070126

Epoch: 5| Step: 1
Training loss: 0.37952080273687877
Validation loss: 2.745666409157145

Epoch: 5| Step: 2
Training loss: 0.2975198242851181
Validation loss: 2.770077219792213

Epoch: 5| Step: 3
Training loss: 0.32686159454705205
Validation loss: 2.721843866461458

Epoch: 5| Step: 4
Training loss: 0.3673109699195979
Validation loss: 2.6980764103634214

Epoch: 5| Step: 5
Training loss: 0.3590255780073732
Validation loss: 2.7357801659741834

Epoch: 5| Step: 6
Training loss: 0.3288540461196332
Validation loss: 2.6974593711470813

Epoch: 5| Step: 7
Training loss: 0.411031805755743
Validation loss: 2.7423403734449323

Epoch: 5| Step: 8
Training loss: 0.3535418421681736
Validation loss: 2.7244590325846127

Epoch: 5| Step: 9
Training loss: 0.424155535124062
Validation loss: 2.800116438374664

Epoch: 5| Step: 10
Training loss: 0.42538558004170796
Validation loss: 2.7792104929700217

Epoch: 5| Step: 11
Training loss: 1.0328996930273617
Validation loss: 2.75231806634532

Epoch: 435| Step: 0
Training loss: 0.3883018649364212
Validation loss: 2.7769497548568194

Epoch: 5| Step: 1
Training loss: 0.4851596998009141
Validation loss: 2.740339567631012

Epoch: 5| Step: 2
Training loss: 0.31849583234710177
Validation loss: 2.7557836063025487

Epoch: 5| Step: 3
Training loss: 0.425090877549895
Validation loss: 2.7148856216970634

Epoch: 5| Step: 4
Training loss: 0.25160956801323164
Validation loss: 2.693002339194106

Epoch: 5| Step: 5
Training loss: 0.3167598655710358
Validation loss: 2.748820619119784

Epoch: 5| Step: 6
Training loss: 0.3781174383116709
Validation loss: 2.6664013333242225

Epoch: 5| Step: 7
Training loss: 0.5526570781672439
Validation loss: 2.753453311692207

Epoch: 5| Step: 8
Training loss: 0.21199731905272184
Validation loss: 2.7541134767594992

Epoch: 5| Step: 9
Training loss: 0.3570312700334205
Validation loss: 2.739864318033693

Epoch: 5| Step: 10
Training loss: 0.31823141650805703
Validation loss: 2.745432941050618

Epoch: 5| Step: 11
Training loss: 0.33227007635324823
Validation loss: 2.784184265311358

Epoch: 436| Step: 0
Training loss: 0.3770517605618413
Validation loss: 2.7844239993766386

Epoch: 5| Step: 1
Training loss: 0.34035689975945427
Validation loss: 2.8548765529482085

Epoch: 5| Step: 2
Training loss: 0.39052696905287454
Validation loss: 2.8086298487947086

Epoch: 5| Step: 3
Training loss: 0.22671915261977535
Validation loss: 2.7513974930407636

Epoch: 5| Step: 4
Training loss: 0.271553168054165
Validation loss: 2.785540892589641

Epoch: 5| Step: 5
Training loss: 0.311490454766322
Validation loss: 2.773006889333328

Epoch: 5| Step: 6
Training loss: 0.3841753464391957
Validation loss: 2.787522926649684

Epoch: 5| Step: 7
Training loss: 0.28215334777488615
Validation loss: 2.807868085624821

Epoch: 5| Step: 8
Training loss: 0.6043498375436769
Validation loss: 2.7939101315518626

Epoch: 5| Step: 9
Training loss: 0.37425848047156846
Validation loss: 2.7824004362080936

Epoch: 5| Step: 10
Training loss: 0.3703412306380175
Validation loss: 2.7426269809428354

Epoch: 5| Step: 11
Training loss: 0.49653751320027556
Validation loss: 2.7496536065621284

Epoch: 437| Step: 0
Training loss: 0.2763464822190854
Validation loss: 2.78652795128294

Epoch: 5| Step: 1
Training loss: 0.4217392385112679
Validation loss: 2.8057160718456595

Epoch: 5| Step: 2
Training loss: 0.3606394623049753
Validation loss: 2.7883288276014238

Epoch: 5| Step: 3
Training loss: 0.4516801324499232
Validation loss: 2.8208476128679276

Epoch: 5| Step: 4
Training loss: 0.3822315050057997
Validation loss: 2.8395588525083917

Epoch: 5| Step: 5
Training loss: 0.4918174260627563
Validation loss: 2.7499526987920664

Epoch: 5| Step: 6
Training loss: 0.5552167382477868
Validation loss: 2.744003603807526

Epoch: 5| Step: 7
Training loss: 0.335049964929319
Validation loss: 2.828108181560942

Epoch: 5| Step: 8
Training loss: 0.4672235111404514
Validation loss: 2.7836317229841474

Epoch: 5| Step: 9
Training loss: 0.32450890483893224
Validation loss: 2.750476019292644

Epoch: 5| Step: 10
Training loss: 0.4281468253593887
Validation loss: 2.7935600739622077

Epoch: 5| Step: 11
Training loss: 0.19510009660224734
Validation loss: 2.7668939218964863

Epoch: 438| Step: 0
Training loss: 0.24010707614870844
Validation loss: 2.797021837127203

Epoch: 5| Step: 1
Training loss: 0.3004439059900417
Validation loss: 2.7396668081777444

Epoch: 5| Step: 2
Training loss: 0.5915404667607589
Validation loss: 2.738288215486861

Epoch: 5| Step: 3
Training loss: 0.413736070761495
Validation loss: 2.7701211614023733

Epoch: 5| Step: 4
Training loss: 0.376414096444874
Validation loss: 2.77294527440799

Epoch: 5| Step: 5
Training loss: 0.4330250903077783
Validation loss: 2.6906953933138213

Epoch: 5| Step: 6
Training loss: 0.3248677021130143
Validation loss: 2.8167739977269304

Epoch: 5| Step: 7
Training loss: 0.46361742222142666
Validation loss: 2.8392624957628216

Epoch: 5| Step: 8
Training loss: 0.24783837574177675
Validation loss: 2.785144072903287

Epoch: 5| Step: 9
Training loss: 0.32271948557267777
Validation loss: 2.8164383123215626

Epoch: 5| Step: 10
Training loss: 0.27868073533038085
Validation loss: 2.761443865889375

Epoch: 5| Step: 11
Training loss: 0.6519410952217589
Validation loss: 2.7375603387590024

Epoch: 439| Step: 0
Training loss: 0.40328170185145085
Validation loss: 2.806771825928382

Epoch: 5| Step: 1
Training loss: 0.4195437836151153
Validation loss: 2.8137425079935126

Epoch: 5| Step: 2
Training loss: 0.323694414113195
Validation loss: 2.7510353617443637

Epoch: 5| Step: 3
Training loss: 0.34714825623851897
Validation loss: 2.775750384099641

Epoch: 5| Step: 4
Training loss: 0.2948651164429147
Validation loss: 2.7768447255972672

Epoch: 5| Step: 5
Training loss: 0.3063391886481175
Validation loss: 2.7720418221133922

Epoch: 5| Step: 6
Training loss: 0.4010009208226274
Validation loss: 2.7535079126876427

Epoch: 5| Step: 7
Training loss: 0.3640151250901052
Validation loss: 2.766710190593437

Epoch: 5| Step: 8
Training loss: 0.530203124384846
Validation loss: 2.7203954014643497

Epoch: 5| Step: 9
Training loss: 0.3956190729827206
Validation loss: 2.8015746904098373

Epoch: 5| Step: 10
Training loss: 0.38414113443281506
Validation loss: 2.7875557399245925

Epoch: 5| Step: 11
Training loss: 0.21236186902493998
Validation loss: 2.828216066527653

Epoch: 440| Step: 0
Training loss: 0.4694838342828875
Validation loss: 2.807456602065159

Epoch: 5| Step: 1
Training loss: 0.41905200373329055
Validation loss: 2.7829305022272193

Epoch: 5| Step: 2
Training loss: 0.355154170757338
Validation loss: 2.786695991910137

Epoch: 5| Step: 3
Training loss: 0.2902080672856901
Validation loss: 2.8384273622695693

Epoch: 5| Step: 4
Training loss: 0.45898609566873283
Validation loss: 2.6905676241556393

Epoch: 5| Step: 5
Training loss: 0.5620221651566332
Validation loss: 2.8077092588503874

Epoch: 5| Step: 6
Training loss: 0.3728046729456494
Validation loss: 2.762406583216291

Epoch: 5| Step: 7
Training loss: 0.3594052675189152
Validation loss: 2.7295230797763588

Epoch: 5| Step: 8
Training loss: 0.2795241438259328
Validation loss: 2.767214330984346

Epoch: 5| Step: 9
Training loss: 0.22979344824385362
Validation loss: 2.7788916457947748

Epoch: 5| Step: 10
Training loss: 0.5263007693594401
Validation loss: 2.885336693482887

Epoch: 5| Step: 11
Training loss: 0.10466625296924517
Validation loss: 2.8024166658144694

Epoch: 441| Step: 0
Training loss: 0.21665113722797444
Validation loss: 2.8133131088095613

Epoch: 5| Step: 1
Training loss: 0.43066757442919507
Validation loss: 2.7715840804499714

Epoch: 5| Step: 2
Training loss: 0.38320968420109897
Validation loss: 2.773610574399306

Epoch: 5| Step: 3
Training loss: 0.3794129120487133
Validation loss: 2.722095083221748

Epoch: 5| Step: 4
Training loss: 0.3472548964809528
Validation loss: 2.718537643879449

Epoch: 5| Step: 5
Training loss: 0.343669101559079
Validation loss: 2.73615008911107

Epoch: 5| Step: 6
Training loss: 0.2803055482340451
Validation loss: 2.7344144073553105

Epoch: 5| Step: 7
Training loss: 0.4136451561271499
Validation loss: 2.7818078042488605

Epoch: 5| Step: 8
Training loss: 0.32638612437712006
Validation loss: 2.7705156005491745

Epoch: 5| Step: 9
Training loss: 0.5771885323837953
Validation loss: 2.774418624199234

Epoch: 5| Step: 10
Training loss: 0.35938922190513584
Validation loss: 2.7295623096973802

Epoch: 5| Step: 11
Training loss: 0.40283158735770996
Validation loss: 2.7514211168851004

Epoch: 442| Step: 0
Training loss: 0.3771127748148433
Validation loss: 2.8069158961957146

Epoch: 5| Step: 1
Training loss: 0.45222602656387795
Validation loss: 2.705491299984579

Epoch: 5| Step: 2
Training loss: 0.28699855871619545
Validation loss: 2.722893714127025

Epoch: 5| Step: 3
Training loss: 0.6273055942661158
Validation loss: 2.7127640513623743

Epoch: 5| Step: 4
Training loss: 0.3870740472126606
Validation loss: 2.7013110540781593

Epoch: 5| Step: 5
Training loss: 0.3010972579965496
Validation loss: 2.7763198274215295

Epoch: 5| Step: 6
Training loss: 0.3170356260047493
Validation loss: 2.739648016225256

Epoch: 5| Step: 7
Training loss: 0.40001195353290103
Validation loss: 2.7971796796849415

Epoch: 5| Step: 8
Training loss: 0.5258370527155058
Validation loss: 2.8248557589849765

Epoch: 5| Step: 9
Training loss: 0.3815522371703677
Validation loss: 2.9064143247191248

Epoch: 5| Step: 10
Training loss: 0.4249070142955265
Validation loss: 2.7979285424312543

Epoch: 5| Step: 11
Training loss: 0.6013534727697721
Validation loss: 2.8183292908097175

Epoch: 443| Step: 0
Training loss: 0.3810964775535256
Validation loss: 2.7474199640500965

Epoch: 5| Step: 1
Training loss: 0.3829377028021284
Validation loss: 2.80043743085738

Epoch: 5| Step: 2
Training loss: 0.524110674341391
Validation loss: 2.749335284526165

Epoch: 5| Step: 3
Training loss: 0.3384951657368403
Validation loss: 2.687863552654027

Epoch: 5| Step: 4
Training loss: 0.3582259966454987
Validation loss: 2.720818594960306

Epoch: 5| Step: 5
Training loss: 0.4119165520843762
Validation loss: 2.799610654123535

Epoch: 5| Step: 6
Training loss: 0.34921685886084347
Validation loss: 2.7938026943827072

Epoch: 5| Step: 7
Training loss: 0.41196630805871115
Validation loss: 2.7865839433730883

Epoch: 5| Step: 8
Training loss: 0.5509028740104898
Validation loss: 2.813380763991551

Epoch: 5| Step: 9
Training loss: 0.41985352425649225
Validation loss: 2.7621075807447886

Epoch: 5| Step: 10
Training loss: 0.3896970407867452
Validation loss: 2.726939436717847

Epoch: 5| Step: 11
Training loss: 0.15029404375213598
Validation loss: 2.7518778155102557

Epoch: 444| Step: 0
Training loss: 0.3101458329149731
Validation loss: 2.7382988922377964

Epoch: 5| Step: 1
Training loss: 0.5828757591790726
Validation loss: 2.688587519449163

Epoch: 5| Step: 2
Training loss: 0.3441330444505587
Validation loss: 2.775377370617917

Epoch: 5| Step: 3
Training loss: 0.3064842311247158
Validation loss: 2.7357320669544434

Epoch: 5| Step: 4
Training loss: 0.2703953175108624
Validation loss: 2.8061717116629685

Epoch: 5| Step: 5
Training loss: 0.2964695244488795
Validation loss: 2.7591482175127466

Epoch: 5| Step: 6
Training loss: 0.42116053446207835
Validation loss: 2.736019791506176

Epoch: 5| Step: 7
Training loss: 0.44817090766312123
Validation loss: 2.7911190105463204

Epoch: 5| Step: 8
Training loss: 0.33048640625593523
Validation loss: 2.7655201584938736

Epoch: 5| Step: 9
Training loss: 0.37963784760511404
Validation loss: 2.709954342762481

Epoch: 5| Step: 10
Training loss: 0.3440683256447792
Validation loss: 2.7467068511857353

Epoch: 5| Step: 11
Training loss: 0.12306670755683352
Validation loss: 2.7896191231214904

Epoch: 445| Step: 0
Training loss: 0.4273921869363981
Validation loss: 2.697528101704291

Epoch: 5| Step: 1
Training loss: 0.48910680027888404
Validation loss: 2.7581594031048478

Epoch: 5| Step: 2
Training loss: 0.3623699119239614
Validation loss: 2.740237217215353

Epoch: 5| Step: 3
Training loss: 0.3463003205149184
Validation loss: 2.77358744399517

Epoch: 5| Step: 4
Training loss: 0.37379330958256685
Validation loss: 2.7881771146225964

Epoch: 5| Step: 5
Training loss: 0.5610769868798956
Validation loss: 2.754598410628642

Epoch: 5| Step: 6
Training loss: 0.30360475750894045
Validation loss: 2.850982112260193

Epoch: 5| Step: 7
Training loss: 0.42951670633493755
Validation loss: 2.7880485465353413

Epoch: 5| Step: 8
Training loss: 0.34513895152906077
Validation loss: 2.8001162077710355

Epoch: 5| Step: 9
Training loss: 0.3132977198316893
Validation loss: 2.7094137744849607

Epoch: 5| Step: 10
Training loss: 0.3727626416744601
Validation loss: 2.7635227014835317

Epoch: 5| Step: 11
Training loss: 0.2679803150673062
Validation loss: 2.7034582068670687

Epoch: 446| Step: 0
Training loss: 0.4024549904529886
Validation loss: 2.787258191447405

Epoch: 5| Step: 1
Training loss: 0.37487612108684326
Validation loss: 2.720280782685222

Epoch: 5| Step: 2
Training loss: 0.3406592592456931
Validation loss: 2.7198778714198832

Epoch: 5| Step: 3
Training loss: 0.6256050519020955
Validation loss: 2.7770721939466374

Epoch: 5| Step: 4
Training loss: 0.30618593801258454
Validation loss: 2.7302841065880536

Epoch: 5| Step: 5
Training loss: 0.4298642228581719
Validation loss: 2.7621874126088044

Epoch: 5| Step: 6
Training loss: 0.30248369482328374
Validation loss: 2.809534391974215

Epoch: 5| Step: 7
Training loss: 0.35523046115105955
Validation loss: 2.744096397686067

Epoch: 5| Step: 8
Training loss: 0.4279184163227112
Validation loss: 2.748302792126319

Epoch: 5| Step: 9
Training loss: 0.24370864798608735
Validation loss: 2.7135980249996767

Epoch: 5| Step: 10
Training loss: 0.3108679353350713
Validation loss: 2.700621476439261

Epoch: 5| Step: 11
Training loss: 0.768623746413398
Validation loss: 2.688031195847444

Epoch: 447| Step: 0
Training loss: 0.2592856770413705
Validation loss: 2.77935144009422

Epoch: 5| Step: 1
Training loss: 0.4022248657285613
Validation loss: 2.731316798140385

Epoch: 5| Step: 2
Training loss: 0.2388593040781121
Validation loss: 2.7606174120094504

Epoch: 5| Step: 3
Training loss: 0.5089649914017016
Validation loss: 2.764525002585489

Epoch: 5| Step: 4
Training loss: 0.5168499700904403
Validation loss: 2.75003689322144

Epoch: 5| Step: 5
Training loss: 0.3931583462871434
Validation loss: 2.75998939350297

Epoch: 5| Step: 6
Training loss: 0.3671412134418674
Validation loss: 2.719522918071803

Epoch: 5| Step: 7
Training loss: 0.42100091735440887
Validation loss: 2.669592642885229

Epoch: 5| Step: 8
Training loss: 0.3268475301625895
Validation loss: 2.6929846731876608

Epoch: 5| Step: 9
Training loss: 0.3909675050254784
Validation loss: 2.7400636427192824

Epoch: 5| Step: 10
Training loss: 0.36230522217415484
Validation loss: 2.739036118619165

Epoch: 5| Step: 11
Training loss: 0.23408542864533838
Validation loss: 2.7744418837358484

Epoch: 448| Step: 0
Training loss: 0.27421189052338246
Validation loss: 2.791698129438677

Epoch: 5| Step: 1
Training loss: 0.4479030581188709
Validation loss: 2.7574891287138885

Epoch: 5| Step: 2
Training loss: 0.462095196878071
Validation loss: 2.705493459020484

Epoch: 5| Step: 3
Training loss: 0.5541177160350977
Validation loss: 2.702184452854987

Epoch: 5| Step: 4
Training loss: 0.46012214702663734
Validation loss: 2.7078272689061444

Epoch: 5| Step: 5
Training loss: 0.49411550465538084
Validation loss: 2.723342907434285

Epoch: 5| Step: 6
Training loss: 0.436860877915279
Validation loss: 2.7525333237832363

Epoch: 5| Step: 7
Training loss: 0.30476800148552463
Validation loss: 2.7189499207870385

Epoch: 5| Step: 8
Training loss: 0.33523941697663157
Validation loss: 2.736331120121125

Epoch: 5| Step: 9
Training loss: 0.35854702397846816
Validation loss: 2.69295526524565

Epoch: 5| Step: 10
Training loss: 0.4513417869429569
Validation loss: 2.7915645688636204

Epoch: 5| Step: 11
Training loss: 0.6603882737379052
Validation loss: 2.809212815805204

Epoch: 449| Step: 0
Training loss: 0.31796293792286545
Validation loss: 2.7985381397444797

Epoch: 5| Step: 1
Training loss: 0.5935463305051647
Validation loss: 2.790567802164831

Epoch: 5| Step: 2
Training loss: 0.27892617654007784
Validation loss: 2.7301152773186903

Epoch: 5| Step: 3
Training loss: 0.3795017792907538
Validation loss: 2.7604483110785316

Epoch: 5| Step: 4
Training loss: 0.644286693068381
Validation loss: 2.715396294293251

Epoch: 5| Step: 5
Training loss: 0.3628634028905827
Validation loss: 2.7334940844654927

Epoch: 5| Step: 6
Training loss: 0.2426594934044092
Validation loss: 2.772549135015241

Epoch: 5| Step: 7
Training loss: 0.36373704598815787
Validation loss: 2.767599579111675

Epoch: 5| Step: 8
Training loss: 0.28867956520336685
Validation loss: 2.790661646341403

Epoch: 5| Step: 9
Training loss: 0.5067082062223305
Validation loss: 2.7691440535796903

Epoch: 5| Step: 10
Training loss: 0.37806320788959985
Validation loss: 2.824883368287258

Epoch: 5| Step: 11
Training loss: 0.37274885006784153
Validation loss: 2.757513031806252

Epoch: 450| Step: 0
Training loss: 0.2651227662857037
Validation loss: 2.721510702251954

Epoch: 5| Step: 1
Training loss: 0.4027761154670321
Validation loss: 2.7534543435434427

Epoch: 5| Step: 2
Training loss: 0.4273709708685232
Validation loss: 2.8357510501041627

Epoch: 5| Step: 3
Training loss: 0.3673854051059421
Validation loss: 2.7803267471710496

Epoch: 5| Step: 4
Training loss: 0.5637493828391611
Validation loss: 2.7551266971216744

Epoch: 5| Step: 5
Training loss: 0.3752196185426881
Validation loss: 2.7828306107214638

Epoch: 5| Step: 6
Training loss: 0.380247220789768
Validation loss: 2.776177958828048

Epoch: 5| Step: 7
Training loss: 0.35952736900121524
Validation loss: 2.7318667615273045

Epoch: 5| Step: 8
Training loss: 0.3459402553410714
Validation loss: 2.84014000761884

Epoch: 5| Step: 9
Training loss: 0.38095991323750455
Validation loss: 2.881580344465049

Epoch: 5| Step: 10
Training loss: 0.3028167243442407
Validation loss: 2.7612283604909247

Epoch: 5| Step: 11
Training loss: 0.3941625061615351
Validation loss: 2.7608902986727006

Epoch: 451| Step: 0
Training loss: 0.49176288635753806
Validation loss: 2.6525986276974844

Epoch: 5| Step: 1
Training loss: 0.342304049635705
Validation loss: 2.73251657092371

Epoch: 5| Step: 2
Training loss: 0.4060044280008029
Validation loss: 2.695911801555714

Epoch: 5| Step: 3
Training loss: 0.3941639994409389
Validation loss: 2.7952719735053897

Epoch: 5| Step: 4
Training loss: 0.36927843296783985
Validation loss: 2.8077554136886445

Epoch: 5| Step: 5
Training loss: 0.44261150049083114
Validation loss: 2.806385068467837

Epoch: 5| Step: 6
Training loss: 0.5073806687231265
Validation loss: 2.82097584469147

Epoch: 5| Step: 7
Training loss: 0.3861065845525287
Validation loss: 2.7719626682700262

Epoch: 5| Step: 8
Training loss: 0.24638728392328674
Validation loss: 2.7965226049075143

Epoch: 5| Step: 9
Training loss: 0.2679364109822471
Validation loss: 2.793319729890983

Epoch: 5| Step: 10
Training loss: 0.3134019947194837
Validation loss: 2.769626585301899

Epoch: 5| Step: 11
Training loss: 0.2316900319613752
Validation loss: 2.6866682635954127

Epoch: 452| Step: 0
Training loss: 0.3826140259032315
Validation loss: 2.726185831833253

Epoch: 5| Step: 1
Training loss: 0.2813704285811649
Validation loss: 2.74216440522557

Epoch: 5| Step: 2
Training loss: 0.3226061668966279
Validation loss: 2.7482678944252004

Epoch: 5| Step: 3
Training loss: 0.2917608409933302
Validation loss: 2.7376819740266756

Epoch: 5| Step: 4
Training loss: 0.4599096994552548
Validation loss: 2.7650295108573513

Epoch: 5| Step: 5
Training loss: 0.2642838193920317
Validation loss: 2.7857689310659777

Epoch: 5| Step: 6
Training loss: 0.3985020828264434
Validation loss: 2.835461340969689

Epoch: 5| Step: 7
Training loss: 0.4294209607275641
Validation loss: 2.7705625614479863

Epoch: 5| Step: 8
Training loss: 0.33665524921712875
Validation loss: 2.811302799154773

Epoch: 5| Step: 9
Training loss: 0.31333994042163754
Validation loss: 2.7748064128263272

Epoch: 5| Step: 10
Training loss: 0.44537036921288276
Validation loss: 2.784040629770969

Epoch: 5| Step: 11
Training loss: 0.4054717899862707
Validation loss: 2.721149606028298

Epoch: 453| Step: 0
Training loss: 0.3364514145961564
Validation loss: 2.805193381701113

Epoch: 5| Step: 1
Training loss: 0.25253331118095246
Validation loss: 2.8153713263051974

Epoch: 5| Step: 2
Training loss: 0.38299894658185346
Validation loss: 2.8597310996189282

Epoch: 5| Step: 3
Training loss: 0.36309937056736663
Validation loss: 2.8186602732551442

Epoch: 5| Step: 4
Training loss: 0.39606844879542014
Validation loss: 2.7822049462445086

Epoch: 5| Step: 5
Training loss: 0.44984304750685117
Validation loss: 2.7694121829731912

Epoch: 5| Step: 6
Training loss: 0.34621378795333113
Validation loss: 2.7429105379639864

Epoch: 5| Step: 7
Training loss: 0.4554079031501009
Validation loss: 2.7619215527953487

Epoch: 5| Step: 8
Training loss: 0.27972320882776247
Validation loss: 2.7515719790334217

Epoch: 5| Step: 9
Training loss: 0.5596295337063064
Validation loss: 2.696656965250861

Epoch: 5| Step: 10
Training loss: 0.3403269850850734
Validation loss: 2.697789551282236

Epoch: 5| Step: 11
Training loss: 0.18221556005758882
Validation loss: 2.7801439393352907

Epoch: 454| Step: 0
Training loss: 0.32780422698455686
Validation loss: 2.8812224319915476

Epoch: 5| Step: 1
Training loss: 0.40042795146848265
Validation loss: 2.7956187696506167

Epoch: 5| Step: 2
Training loss: 0.3702098358065132
Validation loss: 2.7627879675920957

Epoch: 5| Step: 3
Training loss: 0.31107562414194223
Validation loss: 2.7755181866904794

Epoch: 5| Step: 4
Training loss: 0.47918525086175207
Validation loss: 2.708009973197962

Epoch: 5| Step: 5
Training loss: 0.343147551867248
Validation loss: 2.797178433117722

Epoch: 5| Step: 6
Training loss: 0.5084808060128382
Validation loss: 2.782973100403497

Epoch: 5| Step: 7
Training loss: 0.35850527467664656
Validation loss: 2.8115710384415484

Epoch: 5| Step: 8
Training loss: 0.25282056951198856
Validation loss: 2.7701662749721345

Epoch: 5| Step: 9
Training loss: 0.35716830571650454
Validation loss: 2.8030570629765483

Epoch: 5| Step: 10
Training loss: 0.41012242495615814
Validation loss: 2.7616192531333374

Epoch: 5| Step: 11
Training loss: 0.19922076018572127
Validation loss: 2.7665606135605336

Epoch: 455| Step: 0
Training loss: 0.24544198907127865
Validation loss: 2.7870426361569414

Epoch: 5| Step: 1
Training loss: 0.5171946706591686
Validation loss: 2.803767287980102

Epoch: 5| Step: 2
Training loss: 0.39844969188512164
Validation loss: 2.7826684859899635

Epoch: 5| Step: 3
Training loss: 0.32323760061092455
Validation loss: 2.789461597058851

Epoch: 5| Step: 4
Training loss: 0.4086655001251587
Validation loss: 2.7141342553298173

Epoch: 5| Step: 5
Training loss: 0.22600495037315882
Validation loss: 2.7495848494057933

Epoch: 5| Step: 6
Training loss: 0.535361591677993
Validation loss: 2.70917925217364

Epoch: 5| Step: 7
Training loss: 0.324162420871816
Validation loss: 2.732723543912374

Epoch: 5| Step: 8
Training loss: 0.2965046680928891
Validation loss: 2.7341932872157226

Epoch: 5| Step: 9
Training loss: 0.3136512768586711
Validation loss: 2.756828694565461

Epoch: 5| Step: 10
Training loss: 0.3210558407163255
Validation loss: 2.7955557590639786

Epoch: 5| Step: 11
Training loss: 0.6657780645903505
Validation loss: 2.7346571567825104

Epoch: 456| Step: 0
Training loss: 0.38517843650690703
Validation loss: 2.7863071626435945

Epoch: 5| Step: 1
Training loss: 0.31771664009282896
Validation loss: 2.825853629956654

Epoch: 5| Step: 2
Training loss: 0.42603773738600514
Validation loss: 2.864222737359954

Epoch: 5| Step: 3
Training loss: 0.4695429611649716
Validation loss: 2.800175312633603

Epoch: 5| Step: 4
Training loss: 0.30220041253353974
Validation loss: 2.754993857032449

Epoch: 5| Step: 5
Training loss: 0.3598338390713121
Validation loss: 2.6680495890801583

Epoch: 5| Step: 6
Training loss: 0.47849753209377516
Validation loss: 2.7020991626139574

Epoch: 5| Step: 7
Training loss: 0.4191692260767696
Validation loss: 2.7972451609734073

Epoch: 5| Step: 8
Training loss: 0.33542987262404866
Validation loss: 2.7402219511490475

Epoch: 5| Step: 9
Training loss: 0.34721806589923865
Validation loss: 2.708449919954459

Epoch: 5| Step: 10
Training loss: 0.5234495702462104
Validation loss: 2.768315983460879

Epoch: 5| Step: 11
Training loss: 0.7473532147279756
Validation loss: 2.8546298038781726

Epoch: 457| Step: 0
Training loss: 0.376267892500801
Validation loss: 2.777271754480294

Epoch: 5| Step: 1
Training loss: 0.3717404202161349
Validation loss: 2.752696377097828

Epoch: 5| Step: 2
Training loss: 0.29765085430711524
Validation loss: 2.6763203395750272

Epoch: 5| Step: 3
Training loss: 0.33067985852947024
Validation loss: 2.6934468857027443

Epoch: 5| Step: 4
Training loss: 0.32388582716364045
Validation loss: 2.661077540579

Epoch: 5| Step: 5
Training loss: 0.595765857832852
Validation loss: 2.701848807459799

Epoch: 5| Step: 6
Training loss: 0.43280176913733637
Validation loss: 2.6972173529487247

Epoch: 5| Step: 7
Training loss: 0.30631226373775067
Validation loss: 2.677291340051066

Epoch: 5| Step: 8
Training loss: 0.4879110229723929
Validation loss: 2.7667504192126895

Epoch: 5| Step: 9
Training loss: 0.4166197710667636
Validation loss: 2.7741832178351093

Epoch: 5| Step: 10
Training loss: 0.2607956734994659
Validation loss: 2.7101737677135476

Epoch: 5| Step: 11
Training loss: 0.7228755721212489
Validation loss: 2.7369183945858033

Epoch: 458| Step: 0
Training loss: 0.6463678952300428
Validation loss: 2.6827566700545162

Epoch: 5| Step: 1
Training loss: 0.37528688662601195
Validation loss: 2.700383786458103

Epoch: 5| Step: 2
Training loss: 0.42378384055549867
Validation loss: 2.727838776799436

Epoch: 5| Step: 3
Training loss: 0.4925368295492328
Validation loss: 2.7657206136264185

Epoch: 5| Step: 4
Training loss: 0.3079297007205413
Validation loss: 2.706998016608472

Epoch: 5| Step: 5
Training loss: 0.33691342118796525
Validation loss: 2.7198905671652738

Epoch: 5| Step: 6
Training loss: 0.33078844059916124
Validation loss: 2.766308926214576

Epoch: 5| Step: 7
Training loss: 0.40500181356659787
Validation loss: 2.8102543908209245

Epoch: 5| Step: 8
Training loss: 0.3820583154495054
Validation loss: 2.804381234281313

Epoch: 5| Step: 9
Training loss: 0.3957625145888402
Validation loss: 2.793704336619577

Epoch: 5| Step: 10
Training loss: 0.42251421927050403
Validation loss: 2.763303137669093

Epoch: 5| Step: 11
Training loss: 0.674850749363497
Validation loss: 2.7206769961608384

Epoch: 459| Step: 0
Training loss: 0.3685759206213751
Validation loss: 2.7126561377746703

Epoch: 5| Step: 1
Training loss: 0.5544127468861406
Validation loss: 2.7087571741680114

Epoch: 5| Step: 2
Training loss: 0.3462892402179432
Validation loss: 2.774421760810682

Epoch: 5| Step: 3
Training loss: 0.41931198542096093
Validation loss: 2.793797858537331

Epoch: 5| Step: 4
Training loss: 0.37787525267975863
Validation loss: 2.735875268530134

Epoch: 5| Step: 5
Training loss: 0.3501293428731171
Validation loss: 2.790857042274753

Epoch: 5| Step: 6
Training loss: 0.45728366760811917
Validation loss: 2.7168350454720964

Epoch: 5| Step: 7
Training loss: 0.2788265376154038
Validation loss: 2.732029761064091

Epoch: 5| Step: 8
Training loss: 0.2865838151698283
Validation loss: 2.6648298484061645

Epoch: 5| Step: 9
Training loss: 0.3579979511740466
Validation loss: 2.7187019230622034

Epoch: 5| Step: 10
Training loss: 0.25487681999323797
Validation loss: 2.7340998992588585

Epoch: 5| Step: 11
Training loss: 0.3017961915927055
Validation loss: 2.7311093693543067

Epoch: 460| Step: 0
Training loss: 0.2778942795996573
Validation loss: 2.7398375379935933

Epoch: 5| Step: 1
Training loss: 0.388870035388123
Validation loss: 2.7570952364352497

Epoch: 5| Step: 2
Training loss: 0.37100704585631183
Validation loss: 2.743961452368148

Epoch: 5| Step: 3
Training loss: 0.3251907531601953
Validation loss: 2.697046722655912

Epoch: 5| Step: 4
Training loss: 0.2915359300566307
Validation loss: 2.751968304330743

Epoch: 5| Step: 5
Training loss: 0.5152707183259483
Validation loss: 2.7729270716089105

Epoch: 5| Step: 6
Training loss: 0.26804353098727735
Validation loss: 2.7915759902195987

Epoch: 5| Step: 7
Training loss: 0.3763853946670617
Validation loss: 2.766487349928663

Epoch: 5| Step: 8
Training loss: 0.4124374530073666
Validation loss: 2.789718500917078

Epoch: 5| Step: 9
Training loss: 0.3326746037062104
Validation loss: 2.757364699594197

Epoch: 5| Step: 10
Training loss: 0.3556407679932136
Validation loss: 2.7818248651158237

Epoch: 5| Step: 11
Training loss: 0.3508470460827446
Validation loss: 2.750876449588739

Epoch: 461| Step: 0
Training loss: 0.31405003698491807
Validation loss: 2.795102397741052

Epoch: 5| Step: 1
Training loss: 0.24992257647879468
Validation loss: 2.754706659176461

Epoch: 5| Step: 2
Training loss: 0.5668757367365885
Validation loss: 2.76227666820913

Epoch: 5| Step: 3
Training loss: 0.23268412372456326
Validation loss: 2.7496722903927306

Epoch: 5| Step: 4
Training loss: 0.3945016377732931
Validation loss: 2.734718301203147

Epoch: 5| Step: 5
Training loss: 0.37524100347633405
Validation loss: 2.79738455309476

Epoch: 5| Step: 6
Training loss: 0.31748937138466576
Validation loss: 2.7509971133091824

Epoch: 5| Step: 7
Training loss: 0.38817084909306665
Validation loss: 2.704775855554822

Epoch: 5| Step: 8
Training loss: 0.3264467143628589
Validation loss: 2.7999055522929455

Epoch: 5| Step: 9
Training loss: 0.3542486778374593
Validation loss: 2.7337091561655824

Epoch: 5| Step: 10
Training loss: 0.3345552774002814
Validation loss: 2.813727100555363

Epoch: 5| Step: 11
Training loss: 0.42091589092700993
Validation loss: 2.7794844456186154

Epoch: 462| Step: 0
Training loss: 0.3385239547595599
Validation loss: 2.7266900252256505

Epoch: 5| Step: 1
Training loss: 0.3727626416744601
Validation loss: 2.7578105764409346

Epoch: 5| Step: 2
Training loss: 0.3439328509298498
Validation loss: 2.7355931175500015

Epoch: 5| Step: 3
Training loss: 0.4408777499522794
Validation loss: 2.7909570238009063

Epoch: 5| Step: 4
Training loss: 0.2838282821239033
Validation loss: 2.752268162877899

Epoch: 5| Step: 5
Training loss: 0.3528749128943568
Validation loss: 2.765809507375603

Epoch: 5| Step: 6
Training loss: 0.33213540855711987
Validation loss: 2.7791258097385367

Epoch: 5| Step: 7
Training loss: 0.5210451998534278
Validation loss: 2.718526516787206

Epoch: 5| Step: 8
Training loss: 0.2910027469115371
Validation loss: 2.827367941197834

Epoch: 5| Step: 9
Training loss: 0.3081884257361287
Validation loss: 2.838043947359665

Epoch: 5| Step: 10
Training loss: 0.3227117282934301
Validation loss: 2.790011393234389

Epoch: 5| Step: 11
Training loss: 0.1552023334964965
Validation loss: 2.8462718900543247

Epoch: 463| Step: 0
Training loss: 0.34977871507148534
Validation loss: 2.7977430676544333

Epoch: 5| Step: 1
Training loss: 0.3332750808459616
Validation loss: 2.8129528670048063

Epoch: 5| Step: 2
Training loss: 0.2552498699303724
Validation loss: 2.759921210588006

Epoch: 5| Step: 3
Training loss: 0.41322288317366934
Validation loss: 2.744684236560671

Epoch: 5| Step: 4
Training loss: 0.433042571135717
Validation loss: 2.751018241735409

Epoch: 5| Step: 5
Training loss: 0.6060092359459075
Validation loss: 2.7773006308884063

Epoch: 5| Step: 6
Training loss: 0.38858690722874917
Validation loss: 2.785918792587631

Epoch: 5| Step: 7
Training loss: 0.38073145356472093
Validation loss: 2.747663430052787

Epoch: 5| Step: 8
Training loss: 0.2548882787125634
Validation loss: 2.7851531433116676

Epoch: 5| Step: 9
Training loss: 0.43721816658186674
Validation loss: 2.789608525273304

Epoch: 5| Step: 10
Training loss: 0.3572626019584975
Validation loss: 2.803992320748805

Epoch: 5| Step: 11
Training loss: 0.32852440322233645
Validation loss: 2.8220656028185696

Epoch: 464| Step: 0
Training loss: 0.3465060806786746
Validation loss: 2.808818314743958

Epoch: 5| Step: 1
Training loss: 0.32248465290812633
Validation loss: 2.8538646480195498

Epoch: 5| Step: 2
Training loss: 0.3801278155347073
Validation loss: 2.831754161389693

Epoch: 5| Step: 3
Training loss: 0.3734547646972799
Validation loss: 2.8338574294076335

Epoch: 5| Step: 4
Training loss: 0.5288593694062678
Validation loss: 2.7712768340772436

Epoch: 5| Step: 5
Training loss: 0.2458596554231211
Validation loss: 2.793841704414554

Epoch: 5| Step: 6
Training loss: 0.21983897406644073
Validation loss: 2.712069810866906

Epoch: 5| Step: 7
Training loss: 0.33198570612289857
Validation loss: 2.745824577267414

Epoch: 5| Step: 8
Training loss: 0.34574467468573883
Validation loss: 2.7886117558487484

Epoch: 5| Step: 9
Training loss: 0.3538332823926865
Validation loss: 2.7327375795401263

Epoch: 5| Step: 10
Training loss: 0.3684131781240255
Validation loss: 2.7777813630610746

Epoch: 5| Step: 11
Training loss: 0.37494229826453707
Validation loss: 2.7819909455371197

Epoch: 465| Step: 0
Training loss: 0.372715988009497
Validation loss: 2.830806174308467

Epoch: 5| Step: 1
Training loss: 0.3881249341488596
Validation loss: 2.804156516133756

Epoch: 5| Step: 2
Training loss: 0.5017730152266678
Validation loss: 2.80396850565008

Epoch: 5| Step: 3
Training loss: 0.459017715866428
Validation loss: 2.734120119113891

Epoch: 5| Step: 4
Training loss: 0.39189253197470614
Validation loss: 2.7414945848187573

Epoch: 5| Step: 5
Training loss: 0.2492673390057619
Validation loss: 2.7310013403987585

Epoch: 5| Step: 6
Training loss: 0.26171519148955275
Validation loss: 2.688503706342741

Epoch: 5| Step: 7
Training loss: 0.284664291436603
Validation loss: 2.7341858426016215

Epoch: 5| Step: 8
Training loss: 0.3855167937597501
Validation loss: 2.7295457974596036

Epoch: 5| Step: 9
Training loss: 0.38423245663451167
Validation loss: 2.7310279015354637

Epoch: 5| Step: 10
Training loss: 0.3056880466204373
Validation loss: 2.7107162055463436

Epoch: 5| Step: 11
Training loss: 0.20728239984422012
Validation loss: 2.689261664891735

Epoch: 466| Step: 0
Training loss: 0.3524363148766251
Validation loss: 2.7315905935479856

Epoch: 5| Step: 1
Training loss: 0.3976099545673262
Validation loss: 2.7532859265927616

Epoch: 5| Step: 2
Training loss: 0.37117326787977517
Validation loss: 2.7170621411985354

Epoch: 5| Step: 3
Training loss: 0.31861738269780193
Validation loss: 2.7272240274348705

Epoch: 5| Step: 4
Training loss: 0.3912671723421068
Validation loss: 2.7290402023969484

Epoch: 5| Step: 5
Training loss: 0.3635662355655681
Validation loss: 2.712811389458976

Epoch: 5| Step: 6
Training loss: 0.30474317482150176
Validation loss: 2.7883769563221814

Epoch: 5| Step: 7
Training loss: 0.4883689801558112
Validation loss: 2.7191479088462347

Epoch: 5| Step: 8
Training loss: 0.2610366387401859
Validation loss: 2.669515917931866

Epoch: 5| Step: 9
Training loss: 0.3883542051798069
Validation loss: 2.706460853215091

Epoch: 5| Step: 10
Training loss: 0.27286521424183385
Validation loss: 2.7510606172643906

Epoch: 5| Step: 11
Training loss: 0.15907762918300414
Validation loss: 2.693594926174832

Epoch: 467| Step: 0
Training loss: 0.3270100998543641
Validation loss: 2.723792876451303

Epoch: 5| Step: 1
Training loss: 0.37989573714130687
Validation loss: 2.734009850961918

Epoch: 5| Step: 2
Training loss: 0.2666696594239225
Validation loss: 2.727814690157146

Epoch: 5| Step: 3
Training loss: 0.3517452506745863
Validation loss: 2.7555081589550947

Epoch: 5| Step: 4
Training loss: 0.32621118457132986
Validation loss: 2.7642192033504225

Epoch: 5| Step: 5
Training loss: 0.3834353265490875
Validation loss: 2.737859177360055

Epoch: 5| Step: 6
Training loss: 0.31051114914483824
Validation loss: 2.7452512111491503

Epoch: 5| Step: 7
Training loss: 0.5339589613118115
Validation loss: 2.734254263982523

Epoch: 5| Step: 8
Training loss: 0.24629286627740038
Validation loss: 2.7012404890303405

Epoch: 5| Step: 9
Training loss: 0.3291215749027049
Validation loss: 2.8128507536704137

Epoch: 5| Step: 10
Training loss: 0.3609680649997994
Validation loss: 2.744900136079555

Epoch: 5| Step: 11
Training loss: 0.32486043189051467
Validation loss: 2.8094818239196053

Epoch: 468| Step: 0
Training loss: 0.2765922842852135
Validation loss: 2.7537989385812955

Epoch: 5| Step: 1
Training loss: 0.33542911741395515
Validation loss: 2.755794071078934

Epoch: 5| Step: 2
Training loss: 0.3715090987104003
Validation loss: 2.7381894490321694

Epoch: 5| Step: 3
Training loss: 0.3008548349311831
Validation loss: 2.8188468597867367

Epoch: 5| Step: 4
Training loss: 0.3585257654840373
Validation loss: 2.7385589197620637

Epoch: 5| Step: 5
Training loss: 0.3157646243339893
Validation loss: 2.7288916949198794

Epoch: 5| Step: 6
Training loss: 0.25319435382211775
Validation loss: 2.744261805708415

Epoch: 5| Step: 7
Training loss: 0.34018823549498445
Validation loss: 2.779910579433638

Epoch: 5| Step: 8
Training loss: 0.3173424328279418
Validation loss: 2.7131150850614136

Epoch: 5| Step: 9
Training loss: 0.3011153087608328
Validation loss: 2.746110991147553

Epoch: 5| Step: 10
Training loss: 0.4896802163814814
Validation loss: 2.776467290078459

Epoch: 5| Step: 11
Training loss: 0.36882225314756595
Validation loss: 2.711300073539093

Epoch: 469| Step: 0
Training loss: 0.5083359001699377
Validation loss: 2.832425057226984

Epoch: 5| Step: 1
Training loss: 0.33060661308057626
Validation loss: 2.7723441964375777

Epoch: 5| Step: 2
Training loss: 0.2930603138570993
Validation loss: 2.8018037072712243

Epoch: 5| Step: 3
Training loss: 0.37273261929164286
Validation loss: 2.7487918103455558

Epoch: 5| Step: 4
Training loss: 0.3150458702302574
Validation loss: 2.73365332753033

Epoch: 5| Step: 5
Training loss: 0.32370070929126965
Validation loss: 2.7054204400574453

Epoch: 5| Step: 6
Training loss: 0.32588956802298447
Validation loss: 2.6859583591452325

Epoch: 5| Step: 7
Training loss: 0.3282659659261575
Validation loss: 2.7684711423509767

Epoch: 5| Step: 8
Training loss: 0.32790818317148496
Validation loss: 2.7998069795994533

Epoch: 5| Step: 9
Training loss: 0.3764523356891778
Validation loss: 2.74889647855236

Epoch: 5| Step: 10
Training loss: 0.43712646000994365
Validation loss: 2.8040618393440675

Epoch: 5| Step: 11
Training loss: 0.27038220129859103
Validation loss: 2.7965724131397494

Epoch: 470| Step: 0
Training loss: 0.32440612158567467
Validation loss: 2.772386704656256

Epoch: 5| Step: 1
Training loss: 0.23210605834676504
Validation loss: 2.772179496466044

Epoch: 5| Step: 2
Training loss: 0.2947493041954855
Validation loss: 2.7525831430450958

Epoch: 5| Step: 3
Training loss: 0.47261362435312243
Validation loss: 2.711848608812994

Epoch: 5| Step: 4
Training loss: 0.31522308291568474
Validation loss: 2.7034248156380976

Epoch: 5| Step: 5
Training loss: 0.3339114862512524
Validation loss: 2.7119807453906732

Epoch: 5| Step: 6
Training loss: 0.4345042832177724
Validation loss: 2.7938998966554767

Epoch: 5| Step: 7
Training loss: 0.5266414345459317
Validation loss: 2.784616533072276

Epoch: 5| Step: 8
Training loss: 0.26834847596092726
Validation loss: 2.8378098929907516

Epoch: 5| Step: 9
Training loss: 0.5498773990881411
Validation loss: 2.7949214911310665

Epoch: 5| Step: 10
Training loss: 0.329738430862128
Validation loss: 2.7386087538283017

Epoch: 5| Step: 11
Training loss: 0.46493960442100746
Validation loss: 2.790851258051086

Epoch: 471| Step: 0
Training loss: 0.36696756147315457
Validation loss: 2.7166471131524044

Epoch: 5| Step: 1
Training loss: 0.2795130153442275
Validation loss: 2.729261545298664

Epoch: 5| Step: 2
Training loss: 0.33740785320989647
Validation loss: 2.7516881717285937

Epoch: 5| Step: 3
Training loss: 0.4463785194540243
Validation loss: 2.7628469577241743

Epoch: 5| Step: 4
Training loss: 0.2800806691840267
Validation loss: 2.743910944366798

Epoch: 5| Step: 5
Training loss: 0.3289562776262549
Validation loss: 2.846766531281012

Epoch: 5| Step: 6
Training loss: 0.3115504022964221
Validation loss: 2.776958945041048

Epoch: 5| Step: 7
Training loss: 0.19203004589898306
Validation loss: 2.7924698924334437

Epoch: 5| Step: 8
Training loss: 0.40092369507759634
Validation loss: 2.6981641528249254

Epoch: 5| Step: 9
Training loss: 0.4079697777024017
Validation loss: 2.8008939293860307

Epoch: 5| Step: 10
Training loss: 0.4027372676475383
Validation loss: 2.838526529160946

Epoch: 5| Step: 11
Training loss: 0.7193311332233547
Validation loss: 2.8202674277412183

Epoch: 472| Step: 0
Training loss: 0.23902709892050822
Validation loss: 2.8011877313854083

Epoch: 5| Step: 1
Training loss: 0.30800662140262175
Validation loss: 2.807852515047133

Epoch: 5| Step: 2
Training loss: 0.21193594753627115
Validation loss: 2.783242872523196

Epoch: 5| Step: 3
Training loss: 0.21912374244433538
Validation loss: 2.800840252157706

Epoch: 5| Step: 4
Training loss: 0.5764535764859383
Validation loss: 2.8473463059862745

Epoch: 5| Step: 5
Training loss: 0.24158481240705215
Validation loss: 2.777346600738078

Epoch: 5| Step: 6
Training loss: 0.28264577545698155
Validation loss: 2.874958193516494

Epoch: 5| Step: 7
Training loss: 0.3085198857237091
Validation loss: 2.7745755793225433

Epoch: 5| Step: 8
Training loss: 0.3341101470954044
Validation loss: 2.7824002898242695

Epoch: 5| Step: 9
Training loss: 0.1881582903318174
Validation loss: 2.7575356846134844

Epoch: 5| Step: 10
Training loss: 0.6549498530840198
Validation loss: 2.7686154403165544

Epoch: 5| Step: 11
Training loss: 0.3236237316895021
Validation loss: 2.775259306107617

Epoch: 473| Step: 0
Training loss: 0.2654450873145424
Validation loss: 2.778719568868148

Epoch: 5| Step: 1
Training loss: 0.36962572144278955
Validation loss: 2.80261152221947

Epoch: 5| Step: 2
Training loss: 0.3110924253334954
Validation loss: 2.7191731098128717

Epoch: 5| Step: 3
Training loss: 0.33925258256903285
Validation loss: 2.7569342665613883

Epoch: 5| Step: 4
Training loss: 0.37571352390010565
Validation loss: 2.731225799697753

Epoch: 5| Step: 5
Training loss: 0.36299388553787165
Validation loss: 2.763369410917404

Epoch: 5| Step: 6
Training loss: 0.530137608450831
Validation loss: 2.748293954333093

Epoch: 5| Step: 7
Training loss: 0.47010006399947435
Validation loss: 2.7597818880351164

Epoch: 5| Step: 8
Training loss: 0.47460231069323017
Validation loss: 2.811242875197154

Epoch: 5| Step: 9
Training loss: 0.3886034919735503
Validation loss: 2.8147320967598226

Epoch: 5| Step: 10
Training loss: 0.3660833517983896
Validation loss: 2.7130885645896448

Epoch: 5| Step: 11
Training loss: 0.2304653070483611
Validation loss: 2.7104971873476322

Epoch: 474| Step: 0
Training loss: 0.5572369777429438
Validation loss: 2.717581238314653

Epoch: 5| Step: 1
Training loss: 0.31039158519228616
Validation loss: 2.7109124570014154

Epoch: 5| Step: 2
Training loss: 0.4847002475619053
Validation loss: 2.7056601916061767

Epoch: 5| Step: 3
Training loss: 0.40715240242352463
Validation loss: 2.723213303005211

Epoch: 5| Step: 4
Training loss: 0.33239991533519914
Validation loss: 2.7774450763830916

Epoch: 5| Step: 5
Training loss: 0.32043674431926206
Validation loss: 2.7840709667281884

Epoch: 5| Step: 6
Training loss: 0.37222138789464587
Validation loss: 2.7719223593988547

Epoch: 5| Step: 7
Training loss: 0.3605838223555331
Validation loss: 2.846063560083484

Epoch: 5| Step: 8
Training loss: 0.33447898246184277
Validation loss: 2.803597230375998

Epoch: 5| Step: 9
Training loss: 0.43972518976259395
Validation loss: 2.7663354122870967

Epoch: 5| Step: 10
Training loss: 0.29803368675481334
Validation loss: 2.763167641946384

Epoch: 5| Step: 11
Training loss: 0.22196140957295044
Validation loss: 2.70873277115048

Epoch: 475| Step: 0
Training loss: 0.5630733164399293
Validation loss: 2.7575455735430245

Epoch: 5| Step: 1
Training loss: 0.5527343480410081
Validation loss: 2.670169092400785

Epoch: 5| Step: 2
Training loss: 0.4978540683113092
Validation loss: 2.705605230837115

Epoch: 5| Step: 3
Training loss: 0.27936401093822116
Validation loss: 2.760125999022175

Epoch: 5| Step: 4
Training loss: 0.4992101659618825
Validation loss: 2.800764788761472

Epoch: 5| Step: 5
Training loss: 0.32178848085246914
Validation loss: 2.8258135958883828

Epoch: 5| Step: 6
Training loss: 0.3930877490202338
Validation loss: 2.873457017742039

Epoch: 5| Step: 7
Training loss: 0.32651262130556885
Validation loss: 2.7872785531594304

Epoch: 5| Step: 8
Training loss: 0.4564024357047018
Validation loss: 2.7572507997680504

Epoch: 5| Step: 9
Training loss: 0.3567643501453764
Validation loss: 2.77021519618621

Epoch: 5| Step: 10
Training loss: 0.4022422217997482
Validation loss: 2.7475591686323426

Epoch: 5| Step: 11
Training loss: 0.2677314486091825
Validation loss: 2.6680475412317137

Epoch: 476| Step: 0
Training loss: 0.5173399179144449
Validation loss: 2.7287672031994408

Epoch: 5| Step: 1
Training loss: 0.48255273071289556
Validation loss: 2.742229979386204

Epoch: 5| Step: 2
Training loss: 0.25202639202016913
Validation loss: 2.7975727894426483

Epoch: 5| Step: 3
Training loss: 0.37252429489300437
Validation loss: 2.847513381032341

Epoch: 5| Step: 4
Training loss: 0.6426814961407555
Validation loss: 2.898871479293661

Epoch: 5| Step: 5
Training loss: 0.49592344109090736
Validation loss: 2.801905765839636

Epoch: 5| Step: 6
Training loss: 0.43820782010614606
Validation loss: 2.8479549772806085

Epoch: 5| Step: 7
Training loss: 0.2899779952267432
Validation loss: 2.7885788819702606

Epoch: 5| Step: 8
Training loss: 0.39570885717188525
Validation loss: 2.6413527657706135

Epoch: 5| Step: 9
Training loss: 0.46277451165464956
Validation loss: 2.713530290888532

Epoch: 5| Step: 10
Training loss: 0.559155508485295
Validation loss: 2.702446361754041

Epoch: 5| Step: 11
Training loss: 0.5478809369213992
Validation loss: 2.7248058362201024

Epoch: 477| Step: 0
Training loss: 0.5400958453879763
Validation loss: 2.7800069381320833

Epoch: 5| Step: 1
Training loss: 0.4324443290966248
Validation loss: 2.8707994202067333

Epoch: 5| Step: 2
Training loss: 0.7235812478992262
Validation loss: 2.9104509891369417

Epoch: 5| Step: 3
Training loss: 0.44099687480684174
Validation loss: 2.8566484636626694

Epoch: 5| Step: 4
Training loss: 0.36482734234855935
Validation loss: 2.819821939398655

Epoch: 5| Step: 5
Training loss: 0.39559457086390104
Validation loss: 2.730627707464544

Epoch: 5| Step: 6
Training loss: 0.4137408428677028
Validation loss: 2.7300684102858437

Epoch: 5| Step: 7
Training loss: 0.5025067968051202
Validation loss: 2.695623562319554

Epoch: 5| Step: 8
Training loss: 0.4532932593915544
Validation loss: 2.7038448492465403

Epoch: 5| Step: 9
Training loss: 0.2417953300118581
Validation loss: 2.6752991476380403

Epoch: 5| Step: 10
Training loss: 0.2733777662153839
Validation loss: 2.734030761848466

Epoch: 5| Step: 11
Training loss: 0.3462349954342436
Validation loss: 2.8364836181866

Epoch: 478| Step: 0
Training loss: 0.41997284690754183
Validation loss: 2.7830108397689988

Epoch: 5| Step: 1
Training loss: 0.4956481163579805
Validation loss: 2.6983334515186526

Epoch: 5| Step: 2
Training loss: 0.3407340500758727
Validation loss: 2.772753553276616

Epoch: 5| Step: 3
Training loss: 0.35695526015539997
Validation loss: 2.7575010748821063

Epoch: 5| Step: 4
Training loss: 0.40028521382994986
Validation loss: 2.6836263163227225

Epoch: 5| Step: 5
Training loss: 0.4707800616310433
Validation loss: 2.683373902638114

Epoch: 5| Step: 6
Training loss: 0.35819554627699246
Validation loss: 2.6525944182609225

Epoch: 5| Step: 7
Training loss: 0.3092911240519278
Validation loss: 2.7300338653471465

Epoch: 5| Step: 8
Training loss: 0.542500795108898
Validation loss: 2.705018506730115

Epoch: 5| Step: 9
Training loss: 0.28076934804087383
Validation loss: 2.7000343316156044

Epoch: 5| Step: 10
Training loss: 0.36229296559910207
Validation loss: 2.789007644042624

Epoch: 5| Step: 11
Training loss: 0.24283429654308258
Validation loss: 2.789306275571525

Epoch: 479| Step: 0
Training loss: 0.3026035887712135
Validation loss: 2.746358172300849

Epoch: 5| Step: 1
Training loss: 0.525043415363444
Validation loss: 2.754952854553888

Epoch: 5| Step: 2
Training loss: 0.3393656228282181
Validation loss: 2.7624778297881054

Epoch: 5| Step: 3
Training loss: 0.36019147506207005
Validation loss: 2.797857296745278

Epoch: 5| Step: 4
Training loss: 0.3138175488323964
Validation loss: 2.758896478682928

Epoch: 5| Step: 5
Training loss: 0.26225453662130344
Validation loss: 2.784219831402276

Epoch: 5| Step: 6
Training loss: 0.2988934040449901
Validation loss: 2.792443168645824

Epoch: 5| Step: 7
Training loss: 0.44813672655582626
Validation loss: 2.713078586849527

Epoch: 5| Step: 8
Training loss: 0.30624278799634724
Validation loss: 2.7693726476712266

Epoch: 5| Step: 9
Training loss: 0.3626548534992618
Validation loss: 2.77242305273329

Epoch: 5| Step: 10
Training loss: 0.38434395703512464
Validation loss: 2.7903756078993904

Epoch: 5| Step: 11
Training loss: 0.451835161275882
Validation loss: 2.8751145733933288

Epoch: 480| Step: 0
Training loss: 0.34236383554166855
Validation loss: 2.775499084486708

Epoch: 5| Step: 1
Training loss: 0.36454912660980976
Validation loss: 2.8035873763209627

Epoch: 5| Step: 2
Training loss: 0.43313337061996693
Validation loss: 2.795270189448745

Epoch: 5| Step: 3
Training loss: 0.31682589453299487
Validation loss: 2.795732165229266

Epoch: 5| Step: 4
Training loss: 0.30323890974186574
Validation loss: 2.8036145643578365

Epoch: 5| Step: 5
Training loss: 0.24950314113258407
Validation loss: 2.825912780063024

Epoch: 5| Step: 6
Training loss: 0.35842394413212164
Validation loss: 2.786330896951357

Epoch: 5| Step: 7
Training loss: 0.3036343149756307
Validation loss: 2.8145946473280845

Epoch: 5| Step: 8
Training loss: 0.46255240981105467
Validation loss: 2.822590507630728

Epoch: 5| Step: 9
Training loss: 0.2629531105907848
Validation loss: 2.8931661759783442

Epoch: 5| Step: 10
Training loss: 0.38478266489473145
Validation loss: 2.7810357329166955

Epoch: 5| Step: 11
Training loss: 0.2598164874310672
Validation loss: 2.763880907113218

Epoch: 481| Step: 0
Training loss: 0.25791910163939913
Validation loss: 2.7274169676018842

Epoch: 5| Step: 1
Training loss: 0.3835728936828292
Validation loss: 2.7297237655131767

Epoch: 5| Step: 2
Training loss: 0.3238515267929666
Validation loss: 2.714326453381226

Epoch: 5| Step: 3
Training loss: 0.5770705117225496
Validation loss: 2.7010835130664184

Epoch: 5| Step: 4
Training loss: 0.3658587173368028
Validation loss: 2.6971221009081954

Epoch: 5| Step: 5
Training loss: 0.4576619027499435
Validation loss: 2.7212369349050243

Epoch: 5| Step: 6
Training loss: 0.2655728934173863
Validation loss: 2.725208223040239

Epoch: 5| Step: 7
Training loss: 0.30103720883871465
Validation loss: 2.802222068831196

Epoch: 5| Step: 8
Training loss: 0.3270504705154797
Validation loss: 2.8128192296587056

Epoch: 5| Step: 9
Training loss: 0.3415859552550976
Validation loss: 2.7521034363920363

Epoch: 5| Step: 10
Training loss: 0.27395454296540755
Validation loss: 2.728265538333612

Epoch: 5| Step: 11
Training loss: 0.3037756823251329
Validation loss: 2.734350622159282

Epoch: 482| Step: 0
Training loss: 0.2926183767094685
Validation loss: 2.7109728544276956

Epoch: 5| Step: 1
Training loss: 0.29010563866580286
Validation loss: 2.766808341077633

Epoch: 5| Step: 2
Training loss: 0.3141417531465444
Validation loss: 2.7638652163252697

Epoch: 5| Step: 3
Training loss: 0.2504914192464186
Validation loss: 2.7705551751182433

Epoch: 5| Step: 4
Training loss: 0.39156952153735225
Validation loss: 2.802111385635198

Epoch: 5| Step: 5
Training loss: 0.3965033164925913
Validation loss: 2.807874142595132

Epoch: 5| Step: 6
Training loss: 0.3423770231637721
Validation loss: 2.806381056075174

Epoch: 5| Step: 7
Training loss: 0.2936484780293415
Validation loss: 2.793061119277229

Epoch: 5| Step: 8
Training loss: 0.26806783762620895
Validation loss: 2.7454677318614316

Epoch: 5| Step: 9
Training loss: 0.521979793146514
Validation loss: 2.757042663008676

Epoch: 5| Step: 10
Training loss: 0.295484133198403
Validation loss: 2.741126790899553

Epoch: 5| Step: 11
Training loss: 0.562041015921941
Validation loss: 2.7254420349191606

Epoch: 483| Step: 0
Training loss: 0.6030049308287413
Validation loss: 2.711469475313777

Epoch: 5| Step: 1
Training loss: 0.3983831555573361
Validation loss: 2.7609501928884335

Epoch: 5| Step: 2
Training loss: 0.2537872916100092
Validation loss: 2.7091468408442534

Epoch: 5| Step: 3
Training loss: 0.3724605686323943
Validation loss: 2.781704561898402

Epoch: 5| Step: 4
Training loss: 0.37909359577186197
Validation loss: 2.7687054377199622

Epoch: 5| Step: 5
Training loss: 0.401930383719204
Validation loss: 2.8232160013049503

Epoch: 5| Step: 6
Training loss: 0.29538185677659673
Validation loss: 2.817651745738608

Epoch: 5| Step: 7
Training loss: 0.41384801167615015
Validation loss: 2.75255237604006

Epoch: 5| Step: 8
Training loss: 0.2944151839388918
Validation loss: 2.779428835908522

Epoch: 5| Step: 9
Training loss: 0.3990371529961627
Validation loss: 2.771085237702025

Epoch: 5| Step: 10
Training loss: 0.41228436194501517
Validation loss: 2.813953536213517

Epoch: 5| Step: 11
Training loss: 0.5697643310666086
Validation loss: 2.714672802270215

Epoch: 484| Step: 0
Training loss: 0.286427967311608
Validation loss: 2.729605691604999

Epoch: 5| Step: 1
Training loss: 0.41773235017347465
Validation loss: 2.8314041565898096

Epoch: 5| Step: 2
Training loss: 0.3792954834776004
Validation loss: 2.7692790631759134

Epoch: 5| Step: 3
Training loss: 0.4357628906748544
Validation loss: 2.7780627586621347

Epoch: 5| Step: 4
Training loss: 0.37906906719761496
Validation loss: 2.827863308793005

Epoch: 5| Step: 5
Training loss: 0.44386373727873046
Validation loss: 2.7579121089881697

Epoch: 5| Step: 6
Training loss: 0.320293449207492
Validation loss: 2.7209640417983745

Epoch: 5| Step: 7
Training loss: 0.4380046794632678
Validation loss: 2.7986877079639623

Epoch: 5| Step: 8
Training loss: 0.30008745061302183
Validation loss: 2.727539029720646

Epoch: 5| Step: 9
Training loss: 0.2974699233182555
Validation loss: 2.834657115558262

Epoch: 5| Step: 10
Training loss: 0.3115866067871178
Validation loss: 2.7992651687564947

Epoch: 5| Step: 11
Training loss: 0.24306469154596036
Validation loss: 2.7991891341080466

Epoch: 485| Step: 0
Training loss: 0.24968355983781107
Validation loss: 2.7968179458964895

Epoch: 5| Step: 1
Training loss: 0.40494930680047597
Validation loss: 2.7627908908801615

Epoch: 5| Step: 2
Training loss: 0.2706088762127299
Validation loss: 2.7745299108662818

Epoch: 5| Step: 3
Training loss: 0.3468868550001705
Validation loss: 2.7410709719999966

Epoch: 5| Step: 4
Training loss: 0.5514709537168302
Validation loss: 2.690432958952847

Epoch: 5| Step: 5
Training loss: 0.33170692086746634
Validation loss: 2.7876718778179126

Epoch: 5| Step: 6
Training loss: 0.2955707838454857
Validation loss: 2.728462420786557

Epoch: 5| Step: 7
Training loss: 0.28980317461560107
Validation loss: 2.771780391169472

Epoch: 5| Step: 8
Training loss: 0.36116512849263377
Validation loss: 2.7754580162719993

Epoch: 5| Step: 9
Training loss: 0.37041322650034253
Validation loss: 2.772019316519278

Epoch: 5| Step: 10
Training loss: 0.3528754407425228
Validation loss: 2.7833547700315333

Epoch: 5| Step: 11
Training loss: 0.4400797635899002
Validation loss: 2.7095485137441684

Epoch: 486| Step: 0
Training loss: 0.3948524414059964
Validation loss: 2.7453157779888975

Epoch: 5| Step: 1
Training loss: 0.3334707806253438
Validation loss: 2.767026361217758

Epoch: 5| Step: 2
Training loss: 0.2664665746768932
Validation loss: 2.719812459633653

Epoch: 5| Step: 3
Training loss: 0.35366491463841737
Validation loss: 2.7623646802253314

Epoch: 5| Step: 4
Training loss: 0.3319229847042283
Validation loss: 2.758693975649767

Epoch: 5| Step: 5
Training loss: 0.4651893965520897
Validation loss: 2.836470341082058

Epoch: 5| Step: 6
Training loss: 0.3823343911407147
Validation loss: 2.8165121071824624

Epoch: 5| Step: 7
Training loss: 0.3225084026114389
Validation loss: 2.8204768301164225

Epoch: 5| Step: 8
Training loss: 0.24591743874555239
Validation loss: 2.756711150969006

Epoch: 5| Step: 9
Training loss: 0.2728522713719569
Validation loss: 2.8007390982534224

Epoch: 5| Step: 10
Training loss: 0.3273072383975611
Validation loss: 2.7110631182586102

Epoch: 5| Step: 11
Training loss: 0.28637997104521284
Validation loss: 2.7631937860306643

Epoch: 487| Step: 0
Training loss: 0.29326441786137186
Validation loss: 2.7228566574414947

Epoch: 5| Step: 1
Training loss: 0.3566974740820434
Validation loss: 2.815255168402034

Epoch: 5| Step: 2
Training loss: 0.3321043607216151
Validation loss: 2.7826664350281374

Epoch: 5| Step: 3
Training loss: 0.3673944498801658
Validation loss: 2.8446649679387934

Epoch: 5| Step: 4
Training loss: 0.34447131554687166
Validation loss: 2.819718633879583

Epoch: 5| Step: 5
Training loss: 0.40297408864751105
Validation loss: 2.762054178388364

Epoch: 5| Step: 6
Training loss: 0.24891159687657122
Validation loss: 2.7840491614045577

Epoch: 5| Step: 7
Training loss: 0.35991841156611565
Validation loss: 2.7819679847957537

Epoch: 5| Step: 8
Training loss: 0.26645868965485
Validation loss: 2.6895601855660103

Epoch: 5| Step: 9
Training loss: 0.27459735111485684
Validation loss: 2.6777136625884244

Epoch: 5| Step: 10
Training loss: 0.36844814278694515
Validation loss: 2.773639739637032

Epoch: 5| Step: 11
Training loss: 0.559445884944337
Validation loss: 2.776572265636449

Epoch: 488| Step: 0
Training loss: 0.3345850846057505
Validation loss: 2.8043995517273492

Epoch: 5| Step: 1
Training loss: 0.2172563683802265
Validation loss: 2.767465873170142

Epoch: 5| Step: 2
Training loss: 0.468306936043891
Validation loss: 2.7709517537293147

Epoch: 5| Step: 3
Training loss: 0.3354937483593085
Validation loss: 2.8405205586072233

Epoch: 5| Step: 4
Training loss: 0.3238668025240751
Validation loss: 2.7851056365862092

Epoch: 5| Step: 5
Training loss: 0.37320160777434597
Validation loss: 2.7807089675843226

Epoch: 5| Step: 6
Training loss: 0.31380497731922824
Validation loss: 2.7535577107088334

Epoch: 5| Step: 7
Training loss: 0.24753495203174797
Validation loss: 2.7592719181574266

Epoch: 5| Step: 8
Training loss: 0.35169237704816364
Validation loss: 2.726986583385516

Epoch: 5| Step: 9
Training loss: 0.35552470846194373
Validation loss: 2.784267642245213

Epoch: 5| Step: 10
Training loss: 0.49995851344610215
Validation loss: 2.720472272621202

Epoch: 5| Step: 11
Training loss: 0.3343210809675766
Validation loss: 2.918425020890447

Epoch: 489| Step: 0
Training loss: 0.4362414172292865
Validation loss: 2.7956084575031457

Epoch: 5| Step: 1
Training loss: 0.36398251846013585
Validation loss: 2.8278217750262593

Epoch: 5| Step: 2
Training loss: 0.277697082891655
Validation loss: 2.743888606290315

Epoch: 5| Step: 3
Training loss: 0.5117414047234992
Validation loss: 2.7467676875909826

Epoch: 5| Step: 4
Training loss: 0.41026871365505657
Validation loss: 2.763490305621124

Epoch: 5| Step: 5
Training loss: 0.3889881744781485
Validation loss: 2.780807888595533

Epoch: 5| Step: 6
Training loss: 0.2786218181255573
Validation loss: 2.792769859363784

Epoch: 5| Step: 7
Training loss: 0.40108299868075875
Validation loss: 2.813147989436357

Epoch: 5| Step: 8
Training loss: 0.3197592283420412
Validation loss: 2.749564194103704

Epoch: 5| Step: 9
Training loss: 0.2862199774244229
Validation loss: 2.7818996585075046

Epoch: 5| Step: 10
Training loss: 0.22380816984848065
Validation loss: 2.778079075499863

Epoch: 5| Step: 11
Training loss: 0.5837624680047353
Validation loss: 2.815131863373408

Epoch: 490| Step: 0
Training loss: 0.3411542464327877
Validation loss: 2.7119295117280795

Epoch: 5| Step: 1
Training loss: 0.41035736239663495
Validation loss: 2.7582254181714467

Epoch: 5| Step: 2
Training loss: 0.38310940575406044
Validation loss: 2.7520707960129576

Epoch: 5| Step: 3
Training loss: 0.3441414446609903
Validation loss: 2.7322827136268386

Epoch: 5| Step: 4
Training loss: 0.3147899056294276
Validation loss: 2.745010491514973

Epoch: 5| Step: 5
Training loss: 0.2845410805208
Validation loss: 2.7486126246637443

Epoch: 5| Step: 6
Training loss: 0.22641395763706615
Validation loss: 2.7787865111834806

Epoch: 5| Step: 7
Training loss: 0.32412831067690573
Validation loss: 2.821003734948779

Epoch: 5| Step: 8
Training loss: 0.32158473361513545
Validation loss: 2.776913906050669

Epoch: 5| Step: 9
Training loss: 0.37411452098181897
Validation loss: 2.7794651848198404

Epoch: 5| Step: 10
Training loss: 0.4530509033129285
Validation loss: 2.7932660138053453

Epoch: 5| Step: 11
Training loss: 0.21620425426764148
Validation loss: 2.7366722411526005

Epoch: 491| Step: 0
Training loss: 0.2651852164690505
Validation loss: 2.7572483137637884

Epoch: 5| Step: 1
Training loss: 0.3136183040948626
Validation loss: 2.7076632306485195

Epoch: 5| Step: 2
Training loss: 0.30903748105325307
Validation loss: 2.732264247198729

Epoch: 5| Step: 3
Training loss: 0.26932675440723297
Validation loss: 2.7170409059383123

Epoch: 5| Step: 4
Training loss: 0.327552227376691
Validation loss: 2.7806673975603413

Epoch: 5| Step: 5
Training loss: 0.27749636306183645
Validation loss: 2.7790676012546074

Epoch: 5| Step: 6
Training loss: 0.3447606553463572
Validation loss: 2.736621772862135

Epoch: 5| Step: 7
Training loss: 0.25050052070087675
Validation loss: 2.7119161688018374

Epoch: 5| Step: 8
Training loss: 0.3053191801763553
Validation loss: 2.753047399765925

Epoch: 5| Step: 9
Training loss: 0.47615011539451824
Validation loss: 2.7618715674724372

Epoch: 5| Step: 10
Training loss: 0.32523022713399824
Validation loss: 2.786801102610896

Epoch: 5| Step: 11
Training loss: 0.26611185335948623
Validation loss: 2.759554391216059

Epoch: 492| Step: 0
Training loss: 0.3216957949859798
Validation loss: 2.7278491739764963

Epoch: 5| Step: 1
Training loss: 0.29987036268362366
Validation loss: 2.759310768333176

Epoch: 5| Step: 2
Training loss: 0.31451826427883023
Validation loss: 2.817325228714723

Epoch: 5| Step: 3
Training loss: 0.39596070156147206
Validation loss: 2.772276098797643

Epoch: 5| Step: 4
Training loss: 0.3251638540453928
Validation loss: 2.7917831216312083

Epoch: 5| Step: 5
Training loss: 0.2611799387324567
Validation loss: 2.750441786652255

Epoch: 5| Step: 6
Training loss: 0.3245879105358236
Validation loss: 2.7517006521149874

Epoch: 5| Step: 7
Training loss: 0.3377771242058978
Validation loss: 2.778742585051461

Epoch: 5| Step: 8
Training loss: 0.30462384170261925
Validation loss: 2.7783795592343763

Epoch: 5| Step: 9
Training loss: 0.3147672186285917
Validation loss: 2.7491293417551543

Epoch: 5| Step: 10
Training loss: 0.4787787823204823
Validation loss: 2.7499607112274305

Epoch: 5| Step: 11
Training loss: 0.3795234922493315
Validation loss: 2.7563755192797035

Epoch: 493| Step: 0
Training loss: 0.520865140579467
Validation loss: 2.767728788429242

Epoch: 5| Step: 1
Training loss: 0.42096904330597
Validation loss: 2.8755963094090222

Epoch: 5| Step: 2
Training loss: 0.36931605938655027
Validation loss: 2.839743684582489

Epoch: 5| Step: 3
Training loss: 0.3330329930246534
Validation loss: 2.7940959158712717

Epoch: 5| Step: 4
Training loss: 0.396571783944615
Validation loss: 2.8037196006096297

Epoch: 5| Step: 5
Training loss: 0.465018584126148
Validation loss: 2.648988201384492

Epoch: 5| Step: 6
Training loss: 0.4701776697788573
Validation loss: 2.7431339358681597

Epoch: 5| Step: 7
Training loss: 0.279384892606428
Validation loss: 2.7187153642282462

Epoch: 5| Step: 8
Training loss: 0.34393728096296633
Validation loss: 2.767998339747609

Epoch: 5| Step: 9
Training loss: 0.34689764773692144
Validation loss: 2.8452047078668015

Epoch: 5| Step: 10
Training loss: 0.3062375693815173
Validation loss: 2.8133990722775306

Epoch: 5| Step: 11
Training loss: 0.5494145148933466
Validation loss: 2.8507909628083326

Epoch: 494| Step: 0
Training loss: 0.33393113230567695
Validation loss: 2.7567413742669875

Epoch: 5| Step: 1
Training loss: 0.279237967727975
Validation loss: 2.7612036189070444

Epoch: 5| Step: 2
Training loss: 0.4711723047051157
Validation loss: 2.7554703872080215

Epoch: 5| Step: 3
Training loss: 0.264125321042777
Validation loss: 2.730892856097819

Epoch: 5| Step: 4
Training loss: 0.4710243047388089
Validation loss: 2.7715727147044484

Epoch: 5| Step: 5
Training loss: 0.3779154930110541
Validation loss: 2.8004720739786078

Epoch: 5| Step: 6
Training loss: 0.4378200620478755
Validation loss: 2.7404600065494105

Epoch: 5| Step: 7
Training loss: 0.3214523688846893
Validation loss: 2.7591717821966886

Epoch: 5| Step: 8
Training loss: 0.3710982272229399
Validation loss: 2.8024809294093447

Epoch: 5| Step: 9
Training loss: 0.36137459945788464
Validation loss: 2.8005643518543017

Epoch: 5| Step: 10
Training loss: 0.39697997589682815
Validation loss: 2.839168337086316

Epoch: 5| Step: 11
Training loss: 0.6288319419416086
Validation loss: 2.7561560024400333

Epoch: 495| Step: 0
Training loss: 0.33105490130302256
Validation loss: 2.7919322582607644

Epoch: 5| Step: 1
Training loss: 0.33960376684851246
Validation loss: 2.8239425868870316

Epoch: 5| Step: 2
Training loss: 0.37822571823886014
Validation loss: 2.7994698930926827

Epoch: 5| Step: 3
Training loss: 0.28295851041739317
Validation loss: 2.758592227001593

Epoch: 5| Step: 4
Training loss: 0.20194623112671586
Validation loss: 2.757430294161094

Epoch: 5| Step: 5
Training loss: 0.26483924434283845
Validation loss: 2.79304107714639

Epoch: 5| Step: 6
Training loss: 0.3349008089153741
Validation loss: 2.8077103379871193

Epoch: 5| Step: 7
Training loss: 0.40468129480973203
Validation loss: 2.7933204518361054

Epoch: 5| Step: 8
Training loss: 0.23117227988096456
Validation loss: 2.8380056324229264

Epoch: 5| Step: 9
Training loss: 0.3041314528713983
Validation loss: 2.77341986995341

Epoch: 5| Step: 10
Training loss: 0.4623069785689461
Validation loss: 2.826994499623098

Epoch: 5| Step: 11
Training loss: 0.3807167372999084
Validation loss: 2.743298699404461

Epoch: 496| Step: 0
Training loss: 0.3076246714816922
Validation loss: 2.756127421723454

Epoch: 5| Step: 1
Training loss: 0.31444200057734834
Validation loss: 2.8097431022327894

Epoch: 5| Step: 2
Training loss: 0.4665317660440088
Validation loss: 2.6963741846774085

Epoch: 5| Step: 3
Training loss: 0.37581611281243943
Validation loss: 2.78787536004026

Epoch: 5| Step: 4
Training loss: 0.3396312334157645
Validation loss: 2.6907663161279785

Epoch: 5| Step: 5
Training loss: 0.23177422117407526
Validation loss: 2.735097295639133

Epoch: 5| Step: 6
Training loss: 0.3233920323391536
Validation loss: 2.7807088943478897

Epoch: 5| Step: 7
Training loss: 0.3102783625746244
Validation loss: 2.7616638724896743

Epoch: 5| Step: 8
Training loss: 0.3940881563769289
Validation loss: 2.7941782539913183

Epoch: 5| Step: 9
Training loss: 0.28024900642273337
Validation loss: 2.724631725297087

Epoch: 5| Step: 10
Training loss: 0.3406238262786242
Validation loss: 2.741896654664807

Epoch: 5| Step: 11
Training loss: 0.4300454642690544
Validation loss: 2.765778312815879

Epoch: 497| Step: 0
Training loss: 0.3410135393636051
Validation loss: 2.771268198598511

Epoch: 5| Step: 1
Training loss: 0.2435061717715037
Validation loss: 2.738331709472568

Epoch: 5| Step: 2
Training loss: 0.5043689466488985
Validation loss: 2.7152992982382838

Epoch: 5| Step: 3
Training loss: 0.3764259526094953
Validation loss: 2.7743615701935735

Epoch: 5| Step: 4
Training loss: 0.2900640431958776
Validation loss: 2.753805821528734

Epoch: 5| Step: 5
Training loss: 0.2938948933396225
Validation loss: 2.7071372337566886

Epoch: 5| Step: 6
Training loss: 0.3652320290556447
Validation loss: 2.800891052959614

Epoch: 5| Step: 7
Training loss: 0.37639699440768576
Validation loss: 2.705119141636097

Epoch: 5| Step: 8
Training loss: 0.20856196057687423
Validation loss: 2.6909866596504592

Epoch: 5| Step: 9
Training loss: 0.2354216570170535
Validation loss: 2.6716529315179764

Epoch: 5| Step: 10
Training loss: 0.3130794636324183
Validation loss: 2.6874345874957934

Epoch: 5| Step: 11
Training loss: 0.20979816425916317
Validation loss: 2.7553504926402717

Epoch: 498| Step: 0
Training loss: 0.4823436287501967
Validation loss: 2.837778395945038

Epoch: 5| Step: 1
Training loss: 0.2789948037024243
Validation loss: 2.7774265132113243

Epoch: 5| Step: 2
Training loss: 0.26207179839116257
Validation loss: 2.7451564623613884

Epoch: 5| Step: 3
Training loss: 0.3356039809104264
Validation loss: 2.769667420763363

Epoch: 5| Step: 4
Training loss: 0.3137373745418331
Validation loss: 2.7638034263546953

Epoch: 5| Step: 5
Training loss: 0.29949821190467446
Validation loss: 2.763908307820914

Epoch: 5| Step: 6
Training loss: 0.28023842516466957
Validation loss: 2.760373836161064

Epoch: 5| Step: 7
Training loss: 0.3166533082520268
Validation loss: 2.727537660271739

Epoch: 5| Step: 8
Training loss: 0.3094014329888807
Validation loss: 2.721294556958099

Epoch: 5| Step: 9
Training loss: 0.2882141086784126
Validation loss: 2.783596467002437

Epoch: 5| Step: 10
Training loss: 0.31986096585990476
Validation loss: 2.771391490896908

Epoch: 5| Step: 11
Training loss: 0.17424504505033195
Validation loss: 2.77086976154063

Epoch: 499| Step: 0
Training loss: 0.25546039894290123
Validation loss: 2.7576873055661397

Epoch: 5| Step: 1
Training loss: 0.3490597330869947
Validation loss: 2.81205915952093

Epoch: 5| Step: 2
Training loss: 0.26571137762895486
Validation loss: 2.778372712135617

Epoch: 5| Step: 3
Training loss: 0.363357002809926
Validation loss: 2.7352520507957294

Epoch: 5| Step: 4
Training loss: 0.32024957457461306
Validation loss: 2.7716233243514403

Epoch: 5| Step: 5
Training loss: 0.3490354846482629
Validation loss: 2.7880665241195794

Epoch: 5| Step: 6
Training loss: 0.3053206321273633
Validation loss: 2.7663320474513244

Epoch: 5| Step: 7
Training loss: 0.2883410601095099
Validation loss: 2.7516306608568115

Epoch: 5| Step: 8
Training loss: 0.33485582220447946
Validation loss: 2.7854959816626086

Epoch: 5| Step: 9
Training loss: 0.46223051751787697
Validation loss: 2.744332679915106

Epoch: 5| Step: 10
Training loss: 0.3081708497141243
Validation loss: 2.8325265069884527

Epoch: 5| Step: 11
Training loss: 0.27045110941391537
Validation loss: 2.8160675980993735

Epoch: 500| Step: 0
Training loss: 0.32202164633329655
Validation loss: 2.7611112848267307

Epoch: 5| Step: 1
Training loss: 0.3567935862096236
Validation loss: 2.8109665434296245

Epoch: 5| Step: 2
Training loss: 0.37917972802452465
Validation loss: 2.810903088774444

Epoch: 5| Step: 3
Training loss: 0.28110644862619627
Validation loss: 2.7758633459097375

Epoch: 5| Step: 4
Training loss: 0.29354864585075513
Validation loss: 2.7960373851391935

Epoch: 5| Step: 5
Training loss: 0.31739824697672026
Validation loss: 2.7888002637433984

Epoch: 5| Step: 6
Training loss: 0.3140331923631335
Validation loss: 2.7619430076845357

Epoch: 5| Step: 7
Training loss: 0.24311389175721587
Validation loss: 2.7944475256144696

Epoch: 5| Step: 8
Training loss: 0.37291333669457943
Validation loss: 2.8399418425201937

Epoch: 5| Step: 9
Training loss: 0.4205930447166148
Validation loss: 2.777978598302587

Epoch: 5| Step: 10
Training loss: 0.3704422300991554
Validation loss: 2.7310892181443274

Epoch: 5| Step: 11
Training loss: 0.3057021339765045
Validation loss: 2.760092188400082

Testing loss: 2.662401920596428
