Epoch: 1| Step: 0
Training loss: 3.7956700325012207
Validation loss: 3.9162340438623224
Epoch: 7| Step: 1
Training loss: 4.360623359680176
Validation loss: 3.913092949407564
Epoch: 7| Step: 2
Training loss: 4.146368503570557
Validation loss: 3.906502814601651
Epoch: 7| Step: 3
Training loss: 3.6441617012023926
Validation loss: 3.900320354983103
Epoch: 7| Step: 4
Training loss: 3.976330280303955
Validation loss: 3.897437431829439
Epoch: 7| Step: 5
Training loss: 4.6610517501831055
Validation loss: 3.8913745142573077
Epoch: 7| Step: 6
Training loss: 3.582294464111328
Validation loss: 3.88664168591122
Epoch: 7| Step: 7
Training loss: 5.0414276123046875
Validation loss: 3.8805101432388636
Epoch: 7| Step: 8
Training loss: 4.662964820861816
Validation loss: 3.8760365788027538
Epoch: 7| Step: 9
Training loss: 3.8704781532287598
Validation loss: 3.87009182250757
Epoch: 7| Step: 10
Training loss: 3.4724037647247314
Validation loss: 3.8631610475855767
Epoch: 7| Step: 11
Training loss: 4.196383953094482
Validation loss: 3.8596851396903715
Epoch: 7| Step: 12
Training loss: 3.8916614055633545
Validation loss: 3.8560149892628623
Epoch: 7| Step: 13
Training loss: 3.965541124343872
Validation loss: 3.848313410505116
Epoch: 7| Step: 14
Training loss: 4.2090535163879395
Validation loss: 3.8413673476349537
Epoch: 7| Step: 15
Training loss: 4.282061576843262
Validation loss: 3.8382013650249234
Epoch: 2| Step: 0
Training loss: 4.5788445472717285
Validation loss: 3.83214860854389
Epoch: 7| Step: 1
Training loss: 4.437172889709473
Validation loss: 3.8264919116342666
Epoch: 7| Step: 2
Training loss: 4.349991798400879
Validation loss: 3.8213281425640737
Epoch: 7| Step: 3
Training loss: 4.2371039390563965
Validation loss: 3.81704246740547
Epoch: 7| Step: 4
Training loss: 3.5897514820098877
Validation loss: 3.808867574595719
Epoch: 7| Step: 5
Training loss: 4.6077141761779785
Validation loss: 3.8041259247622046
Epoch: 7| Step: 6
Training loss: 3.4075751304626465
Validation loss: 3.7979325236176416
Epoch: 7| Step: 7
Training loss: 3.124969959259033
Validation loss: 3.79284117376204
Epoch: 7| Step: 8
Training loss: 4.430424690246582
Validation loss: 3.7849533163386284
Epoch: 7| Step: 9
Training loss: 3.901315212249756
Validation loss: 3.779954948013635
Epoch: 7| Step: 10
Training loss: 3.745222806930542
Validation loss: 3.7752367609696424
Epoch: 7| Step: 11
Training loss: 3.801703691482544
Validation loss: 3.7677640537563843
Epoch: 7| Step: 12
Training loss: 4.0203938484191895
Validation loss: 3.7631082414723127
Epoch: 7| Step: 13
Training loss: 4.492847442626953
Validation loss: 3.7567354123369396
Epoch: 7| Step: 14
Training loss: 3.626720905303955
Validation loss: 3.749150373952852
Epoch: 7| Step: 15
Training loss: 4.252494812011719
Validation loss: 3.7458336867874475
Epoch: 3| Step: 0
Training loss: 3.5321075916290283
Validation loss: 3.739499500329546
Epoch: 7| Step: 1
Training loss: 4.4701032638549805
Validation loss: 3.7340800436280612
Epoch: 7| Step: 2
Training loss: 4.091336250305176
Validation loss: 3.726376713608666
Epoch: 7| Step: 3
Training loss: 3.5360946655273438
Validation loss: 3.718821110485269
Epoch: 7| Step: 4
Training loss: 3.545370578765869
Validation loss: 3.7137245102752026
Epoch: 7| Step: 5
Training loss: 3.7580313682556152
Validation loss: 3.7078149490219228
Epoch: 7| Step: 6
Training loss: 5.065396308898926
Validation loss: 3.701923531594036
Epoch: 7| Step: 7
Training loss: 3.5339198112487793
Validation loss: 3.6958033952781624
Epoch: 7| Step: 8
Training loss: 4.867142677307129
Validation loss: 3.6899247581152608
Epoch: 7| Step: 9
Training loss: 4.43756628036499
Validation loss: 3.6809069338462335
Epoch: 7| Step: 10
Training loss: 3.323765993118286
Validation loss: 3.677889403679388
Epoch: 7| Step: 11
Training loss: 3.697216510772705
Validation loss: 3.669985273759142
Epoch: 7| Step: 12
Training loss: 3.1964783668518066
Validation loss: 3.661909418998005
Epoch: 7| Step: 13
Training loss: 4.192453861236572
Validation loss: 3.6557601098534014
Epoch: 7| Step: 14
Training loss: 4.066099166870117
Validation loss: 3.6522366623226685
Epoch: 7| Step: 15
Training loss: 4.012930870056152
Validation loss: 3.6427508000847246
Epoch: 4| Step: 0
Training loss: 3.8219192028045654
Validation loss: 3.6358938577363817
Epoch: 7| Step: 1
Training loss: 4.828548431396484
Validation loss: 3.629660671563457
Epoch: 7| Step: 2
Training loss: 3.0318520069122314
Validation loss: 3.623420320826469
Epoch: 7| Step: 3
Training loss: 3.501014232635498
Validation loss: 3.6144747408173923
Epoch: 7| Step: 4
Training loss: 4.25898551940918
Validation loss: 3.607849083358435
Epoch: 7| Step: 5
Training loss: 3.550243854522705
Validation loss: 3.6002894133972605
Epoch: 7| Step: 6
Training loss: 3.481856107711792
Validation loss: 3.5902081239137718
Epoch: 7| Step: 7
Training loss: 3.7714035511016846
Validation loss: 3.58505969939472
Epoch: 7| Step: 8
Training loss: 3.9378483295440674
Validation loss: 3.579949926129348
Epoch: 7| Step: 9
Training loss: 4.2988996505737305
Validation loss: 3.5708456433934272
Epoch: 7| Step: 10
Training loss: 2.9541115760803223
Validation loss: 3.5644392384041983
Epoch: 7| Step: 11
Training loss: 4.252188682556152
Validation loss: 3.5572790139013057
Epoch: 7| Step: 12
Training loss: 4.376855850219727
Validation loss: 3.5512875104122026
Epoch: 7| Step: 13
Training loss: 4.153563022613525
Validation loss: 3.541362880802841
Epoch: 7| Step: 14
Training loss: 3.815945863723755
Validation loss: 3.533226424841572
Epoch: 7| Step: 15
Training loss: 3.9000117778778076
Validation loss: 3.52648539508847
Epoch: 5| Step: 0
Training loss: 4.020215034484863
Validation loss: 3.519779958313318
Epoch: 7| Step: 1
Training loss: 3.763751268386841
Validation loss: 3.5121863454365903
Epoch: 7| Step: 2
Training loss: 3.3691132068634033
Validation loss: 3.5022378842607678
Epoch: 7| Step: 3
Training loss: 3.3484578132629395
Validation loss: 3.4935799571249984
Epoch: 7| Step: 4
Training loss: 5.036139488220215
Validation loss: 3.4879724602047486
Epoch: 7| Step: 5
Training loss: 3.7811813354492188
Validation loss: 3.480883509135075
Epoch: 7| Step: 6
Training loss: 3.5888638496398926
Validation loss: 3.470729829596101
Epoch: 7| Step: 7
Training loss: 3.417548418045044
Validation loss: 3.4605088868587135
Epoch: 7| Step: 8
Training loss: 3.951801300048828
Validation loss: 3.456755785633334
Epoch: 7| Step: 9
Training loss: 3.501265048980713
Validation loss: 3.4441686911548643
Epoch: 7| Step: 10
Training loss: 3.617159366607666
Validation loss: 3.4350101913479594
Epoch: 7| Step: 11
Training loss: 4.303930759429932
Validation loss: 3.431426881886215
Epoch: 7| Step: 12
Training loss: 3.2710533142089844
Validation loss: 3.4210546222522105
Epoch: 7| Step: 13
Training loss: 4.068691253662109
Validation loss: 3.4112019693251137
Epoch: 7| Step: 14
Training loss: 3.746858596801758
Validation loss: 3.400800943374634
Epoch: 7| Step: 15
Training loss: 3.5954577922821045
Validation loss: 3.390989123488502
Epoch: 6| Step: 0
Training loss: 3.441420793533325
Validation loss: 3.3864278244457657
Epoch: 7| Step: 1
Training loss: 2.9732065200805664
Validation loss: 3.3751309020913762
Epoch: 7| Step: 2
Training loss: 4.010695457458496
Validation loss: 3.3627014245918327
Epoch: 7| Step: 3
Training loss: 2.971198558807373
Validation loss: 3.350455251529062
Epoch: 7| Step: 4
Training loss: 3.5169754028320312
Validation loss: 3.34229306694415
Epoch: 7| Step: 5
Training loss: 3.576568603515625
Validation loss: 3.3341406403685645
Epoch: 7| Step: 6
Training loss: 4.578710079193115
Validation loss: 3.322956085205078
Epoch: 7| Step: 7
Training loss: 4.624233245849609
Validation loss: 3.3114430424120784
Epoch: 7| Step: 8
Training loss: 3.104351043701172
Validation loss: 3.3032016256730334
Epoch: 7| Step: 9
Training loss: 3.3512158393859863
Validation loss: 3.2942819801165903
Epoch: 7| Step: 10
Training loss: 3.4838085174560547
Validation loss: 3.2796326918567686
Epoch: 7| Step: 11
Training loss: 4.431332588195801
Validation loss: 3.268167658675489
Epoch: 7| Step: 12
Training loss: 3.3045296669006348
Validation loss: 3.2589267123517374
Epoch: 7| Step: 13
Training loss: 3.903393268585205
Validation loss: 3.247091773602602
Epoch: 7| Step: 14
Training loss: 3.4977011680603027
Validation loss: 3.2398456480863285
Epoch: 7| Step: 15
Training loss: 3.760739803314209
Validation loss: 3.2257725815121217
Epoch: 7| Step: 0
Training loss: 4.084626197814941
Validation loss: 3.217019852974432
Epoch: 7| Step: 1
Training loss: 2.629836320877075
Validation loss: 3.20690687268758
Epoch: 7| Step: 2
Training loss: 4.193499565124512
Validation loss: 3.1955004733243433
Epoch: 7| Step: 3
Training loss: 3.314419984817505
Validation loss: 3.1803165511261646
Epoch: 7| Step: 4
Training loss: 3.709590435028076
Validation loss: 3.168367365281359
Epoch: 7| Step: 5
Training loss: 3.576913356781006
Validation loss: 3.1590216760155108
Epoch: 7| Step: 6
Training loss: 3.608760118484497
Validation loss: 3.1509232006484655
Epoch: 7| Step: 7
Training loss: 2.617159843444824
Validation loss: 3.138131148523564
Epoch: 7| Step: 8
Training loss: 3.1327056884765625
Validation loss: 3.1248783979484505
Epoch: 7| Step: 9
Training loss: 3.19057035446167
Validation loss: 3.1137769942660984
Epoch: 7| Step: 10
Training loss: 4.378909111022949
Validation loss: 3.1008077456796768
Epoch: 7| Step: 11
Training loss: 3.0201785564422607
Validation loss: 3.09074463089593
Epoch: 7| Step: 12
Training loss: 3.3281517028808594
Validation loss: 3.07931572413273
Epoch: 7| Step: 13
Training loss: 4.286545276641846
Validation loss: 3.066875713334667
Epoch: 7| Step: 14
Training loss: 3.442110776901245
Validation loss: 3.0537307142353742
Epoch: 7| Step: 15
Training loss: 3.8545327186584473
Validation loss: 3.0399887767627085
Epoch: 8| Step: 0
Training loss: 2.81040358543396
Validation loss: 3.0300177464382254
Epoch: 7| Step: 1
Training loss: 3.093000888824463
Validation loss: 3.0171982813224516
Epoch: 7| Step: 2
Training loss: 2.746899366378784
Validation loss: 3.0048023076366177
Epoch: 7| Step: 3
Training loss: 3.770087718963623
Validation loss: 2.993250507244961
Epoch: 7| Step: 4
Training loss: 3.311190128326416
Validation loss: 2.9812111837400805
Epoch: 7| Step: 5
Training loss: 3.491144895553589
Validation loss: 2.9680767127935836
Epoch: 7| Step: 6
Training loss: 3.753267765045166
Validation loss: 2.9556455577877787
Epoch: 7| Step: 7
Training loss: 4.000686168670654
Validation loss: 2.9435427943579584
Epoch: 7| Step: 8
Training loss: 2.9820263385772705
Validation loss: 2.9283129843018894
Epoch: 7| Step: 9
Training loss: 3.1459407806396484
Validation loss: 2.9180265742240192
Epoch: 7| Step: 10
Training loss: 4.061387062072754
Validation loss: 2.9030986844206885
Epoch: 7| Step: 11
Training loss: 3.033289909362793
Validation loss: 2.8906055748891486
Epoch: 7| Step: 12
Training loss: 3.492385149002075
Validation loss: 2.8841298569878226
Epoch: 7| Step: 13
Training loss: 3.0176894664764404
Validation loss: 2.8671323601290477
Epoch: 7| Step: 14
Training loss: 3.992424726486206
Validation loss: 2.8504126346368586
Epoch: 7| Step: 15
Training loss: 3.121666431427002
Validation loss: 2.842275652096426
Epoch: 9| Step: 0
Training loss: 2.9396862983703613
Validation loss: 2.82397170375577
Epoch: 7| Step: 1
Training loss: 3.9294097423553467
Validation loss: 2.8127447735491415
Epoch: 7| Step: 2
Training loss: 2.467278003692627
Validation loss: 2.8018380360637636
Epoch: 7| Step: 3
Training loss: 2.9244136810302734
Validation loss: 2.787917804374969
Epoch: 7| Step: 4
Training loss: 3.806495189666748
Validation loss: 2.7747943092593186
Epoch: 7| Step: 5
Training loss: 3.478954792022705
Validation loss: 2.761542683882679
Epoch: 7| Step: 6
Training loss: 4.117745399475098
Validation loss: 2.750105773802284
Epoch: 7| Step: 7
Training loss: 3.6469643115997314
Validation loss: 2.7347061496844396
Epoch: 7| Step: 8
Training loss: 2.5942223072052
Validation loss: 2.7231559135931
Epoch: 7| Step: 9
Training loss: 2.279388427734375
Validation loss: 2.707200251037268
Epoch: 7| Step: 10
Training loss: 3.433882474899292
Validation loss: 2.6958211720418586
Epoch: 7| Step: 11
Training loss: 3.12428617477417
Validation loss: 2.6791035665882577
Epoch: 7| Step: 12
Training loss: 3.4758903980255127
Validation loss: 2.6630984724854394
Epoch: 7| Step: 13
Training loss: 2.6474757194519043
Validation loss: 2.65362829613171
Epoch: 7| Step: 14
Training loss: 3.4324474334716797
Validation loss: 2.6412888242186403
Epoch: 7| Step: 15
Training loss: 2.86892032623291
Validation loss: 2.623699021853989
Epoch: 10| Step: 0
Training loss: 3.4551239013671875
Validation loss: 2.6092460138334643
Epoch: 7| Step: 1
Training loss: 2.86688232421875
Validation loss: 2.5955912638053618
Epoch: 7| Step: 2
Training loss: 2.6703572273254395
Validation loss: 2.5846748626489435
Epoch: 7| Step: 3
Training loss: 3.524618148803711
Validation loss: 2.57107237603167
Epoch: 7| Step: 4
Training loss: 2.613778829574585
Validation loss: 2.5551763284120628
Epoch: 7| Step: 5
Training loss: 3.5609374046325684
Validation loss: 2.5409169077015608
Epoch: 7| Step: 6
Training loss: 3.4512035846710205
Validation loss: 2.5305627164223212
Epoch: 7| Step: 7
Training loss: 3.243114471435547
Validation loss: 2.5125863003216202
Epoch: 7| Step: 8
Training loss: 3.9328131675720215
Validation loss: 2.492752469700875
Epoch: 7| Step: 9
Training loss: 2.4763870239257812
Validation loss: 2.4753087647527243
Epoch: 7| Step: 10
Training loss: 2.4144139289855957
Validation loss: 2.464608863103304
Epoch: 7| Step: 11
Training loss: 2.341083526611328
Validation loss: 2.4439294063787664
Epoch: 7| Step: 12
Training loss: 2.1640429496765137
Validation loss: 2.4282005999585707
Epoch: 7| Step: 13
Training loss: 3.309032440185547
Validation loss: 2.4109890838321166
Epoch: 7| Step: 14
Training loss: 2.86006498336792
Validation loss: 2.3949982571087296
Epoch: 7| Step: 15
Training loss: 3.2337069511413574
Validation loss: 2.3843752943354546
Epoch: 11| Step: 0
Training loss: 2.663515567779541
Validation loss: 2.3732024525566926
Epoch: 7| Step: 1
Training loss: 2.1018242835998535
Validation loss: 2.3516187616389432
Epoch: 7| Step: 2
Training loss: 3.23523211479187
Validation loss: 2.34034581836179
Epoch: 7| Step: 3
Training loss: 4.158137321472168
Validation loss: 2.319520001788791
Epoch: 7| Step: 4
Training loss: 2.4214351177215576
Validation loss: 2.30546444954632
Epoch: 7| Step: 5
Training loss: 3.129889726638794
Validation loss: 2.2899910391663476
Epoch: 7| Step: 6
Training loss: 2.8296656608581543
Validation loss: 2.277854696452189
Epoch: 7| Step: 7
Training loss: 2.5191447734832764
Validation loss: 2.253997466547026
Epoch: 7| Step: 8
Training loss: 3.1320273876190186
Validation loss: 2.2407738527805687
Epoch: 7| Step: 9
Training loss: 2.6210639476776123
Validation loss: 2.226519437144986
Epoch: 7| Step: 10
Training loss: 2.50925350189209
Validation loss: 2.209708862167468
Epoch: 7| Step: 11
Training loss: 2.97324800491333
Validation loss: 2.1900320670587554
Epoch: 7| Step: 12
Training loss: 2.16351318359375
Validation loss: 2.176719834478639
Epoch: 7| Step: 13
Training loss: 2.79410982131958
Validation loss: 2.1603900339963626
Epoch: 7| Step: 14
Training loss: 2.727574586868286
Validation loss: 2.1486351232734515
Epoch: 7| Step: 15
Training loss: 2.6784539222717285
Validation loss: 2.134808905690694
Epoch: 12| Step: 0
Training loss: 2.7939453125
Validation loss: 2.117654145192757
Epoch: 7| Step: 1
Training loss: 2.599127769470215
Validation loss: 2.100129899361151
Epoch: 7| Step: 2
Training loss: 2.5975308418273926
Validation loss: 2.0909380089464804
Epoch: 7| Step: 3
Training loss: 2.8561465740203857
Validation loss: 2.077102004195289
Epoch: 7| Step: 4
Training loss: 2.496703863143921
Validation loss: 2.0709862434606756
Epoch: 7| Step: 5
Training loss: 2.5981764793395996
Validation loss: 2.0477296637116575
Epoch: 7| Step: 6
Training loss: 2.7168428897857666
Validation loss: 2.033033949008091
Epoch: 7| Step: 7
Training loss: 2.5360493659973145
Validation loss: 2.0241342002539326
Epoch: 7| Step: 8
Training loss: 2.695435047149658
Validation loss: 2.004550390106311
Epoch: 7| Step: 9
Training loss: 2.570957660675049
Validation loss: 1.996513750913332
Epoch: 7| Step: 10
Training loss: 1.7049356698989868
Validation loss: 1.9796981820099646
Epoch: 7| Step: 11
Training loss: 2.472189426422119
Validation loss: 1.9603063391266966
Epoch: 7| Step: 12
Training loss: 2.719160556793213
Validation loss: 1.9499592609542737
Epoch: 7| Step: 13
Training loss: 2.2556004524230957
Validation loss: 1.9386204626920411
Epoch: 7| Step: 14
Training loss: 2.9817135334014893
Validation loss: 1.9199407160710946
Epoch: 7| Step: 15
Training loss: 2.128974437713623
Validation loss: 1.9028031105617824
Epoch: 13| Step: 0
Training loss: 1.906725287437439
Validation loss: 1.891466506093526
Epoch: 7| Step: 1
Training loss: 3.3445885181427
Validation loss: 1.8706291287923031
Epoch: 7| Step: 2
Training loss: 2.0583341121673584
Validation loss: 1.8663761075452077
Epoch: 7| Step: 3
Training loss: 2.7369608879089355
Validation loss: 1.847001873331962
Epoch: 7| Step: 4
Training loss: 1.915635108947754
Validation loss: 1.833209004333551
Epoch: 7| Step: 5
Training loss: 2.699713945388794
Validation loss: 1.8176489845454264
Epoch: 7| Step: 6
Training loss: 2.3911197185516357
Validation loss: 1.8131783951958307
Epoch: 7| Step: 7
Training loss: 2.1977951526641846
Validation loss: 1.7933859070427984
Epoch: 7| Step: 8
Training loss: 1.9869632720947266
Validation loss: 1.7892587399311204
Epoch: 7| Step: 9
Training loss: 2.3828063011169434
Validation loss: 1.7796812769320371
Epoch: 7| Step: 10
Training loss: 2.2836575508117676
Validation loss: 1.773164484998305
Epoch: 7| Step: 11
Training loss: 1.9795726537704468
Validation loss: 1.7673656220058742
Epoch: 7| Step: 12
Training loss: 2.0705459117889404
Validation loss: 1.750547932206298
Epoch: 7| Step: 13
Training loss: 2.7878360748291016
Validation loss: 1.7532081192345927
Epoch: 7| Step: 14
Training loss: 2.273904323577881
Validation loss: 1.7407243166038457
Epoch: 7| Step: 15
Training loss: 2.363194704055786
Validation loss: 1.7365626165335126
Epoch: 14| Step: 0
Training loss: 2.283973217010498
Validation loss: 1.724507342139594
Epoch: 7| Step: 1
Training loss: 2.5450620651245117
Validation loss: 1.7211474874894397
Epoch: 7| Step: 2
Training loss: 2.3341643810272217
Validation loss: 1.7209398351984917
Epoch: 7| Step: 3
Training loss: 2.1413490772247314
Validation loss: 1.7146605424743762
Epoch: 7| Step: 4
Training loss: 2.192875385284424
Validation loss: 1.7118074705274842
Epoch: 7| Step: 5
Training loss: 2.0134997367858887
Validation loss: 1.7266055405568734
Epoch: 7| Step: 6
Training loss: 2.4151644706726074
Validation loss: 1.7155418395996094
Epoch: 7| Step: 7
Training loss: 2.2377331256866455
Validation loss: 1.7138353860635551
Epoch: 7| Step: 8
Training loss: 1.9489399194717407
Validation loss: 1.7069372547616204
Epoch: 7| Step: 9
Training loss: 2.271146059036255
Validation loss: 1.7093805494925958
Epoch: 7| Step: 10
Training loss: 1.689408302307129
Validation loss: 1.7028480622408202
Epoch: 7| Step: 11
Training loss: 2.630795478820801
Validation loss: 1.7131996695086253
Epoch: 7| Step: 12
Training loss: 2.180936336517334
Validation loss: 1.7151615962707738
Epoch: 7| Step: 13
Training loss: 2.3733177185058594
Validation loss: 1.7144025761446506
Epoch: 7| Step: 14
Training loss: 1.7585780620574951
Validation loss: 1.7183568992203089
Epoch: 7| Step: 15
Training loss: 2.294614315032959
Validation loss: 1.7234021819752754
Epoch: 15| Step: 0
Training loss: 1.822974443435669
Validation loss: 1.7173000685602642
Epoch: 7| Step: 1
Training loss: 1.7610366344451904
Validation loss: 1.729058840291963
Epoch: 7| Step: 2
Training loss: 2.0596764087677
Validation loss: 1.7281648598128942
Epoch: 7| Step: 3
Training loss: 2.1677896976470947
Validation loss: 1.728279535718959
Epoch: 7| Step: 4
Training loss: 2.968639373779297
Validation loss: 1.7210038891799158
Epoch: 7| Step: 5
Training loss: 2.541490077972412
Validation loss: 1.7335629600415128
Epoch: 7| Step: 6
Training loss: 2.2033164501190186
Validation loss: 1.7338273859710145
Epoch: 7| Step: 7
Training loss: 2.105573892593384
Validation loss: 1.7434672614653333
Epoch: 7| Step: 8
Training loss: 1.9514681100845337
Validation loss: 1.7459503412246704
Epoch: 7| Step: 9
Training loss: 2.094252109527588
Validation loss: 1.7500337542389794
Epoch: 7| Step: 10
Training loss: 1.8564643859863281
Validation loss: 1.7441232641823858
Epoch: 7| Step: 11
Training loss: 1.6361287832260132
Validation loss: 1.759153172266569
Epoch: 7| Step: 12
Training loss: 1.775914192199707
Validation loss: 1.7573268928116175
Epoch: 7| Step: 13
Training loss: 2.0320334434509277
Validation loss: 1.7664621879728577
Epoch: 7| Step: 14
Training loss: 2.7884013652801514
Validation loss: 1.7629091027829287
Epoch: 7| Step: 15
Training loss: 2.192139148712158
Validation loss: 1.7743629354367154
Epoch: 16| Step: 0
Training loss: 1.9021224975585938
Validation loss: 1.756140728648618
Epoch: 7| Step: 1
Training loss: 2.4798309803009033
Validation loss: 1.7624903136877705
Epoch: 7| Step: 2
Training loss: 1.6775057315826416
Validation loss: 1.7707943847711138
Epoch: 7| Step: 3
Training loss: 2.3467319011688232
Validation loss: 1.7754379673827467
Epoch: 7| Step: 4
Training loss: 2.7603442668914795
Validation loss: 1.764641653719566
Epoch: 7| Step: 5
Training loss: 2.3200278282165527
Validation loss: 1.7619828122982877
Epoch: 7| Step: 6
Training loss: 2.186734676361084
Validation loss: 1.767373706797044
Epoch: 7| Step: 7
Training loss: 1.8801740407943726
Validation loss: 1.76233073361486
Epoch: 7| Step: 8
Training loss: 1.4639841318130493
Validation loss: 1.759910440273422
Epoch: 7| Step: 9
Training loss: 2.300462245941162
Validation loss: 1.758687208024718
Epoch: 7| Step: 10
Training loss: 1.875073790550232
Validation loss: 1.7612038988003629
Epoch: 7| Step: 11
Training loss: 1.9940707683563232
Validation loss: 1.7688066684942452
Epoch: 7| Step: 12
Training loss: 2.205806255340576
Validation loss: 1.767292913773077
Epoch: 7| Step: 13
Training loss: 2.2007508277893066
Validation loss: 1.7752112458935745
Epoch: 7| Step: 14
Training loss: 2.223611354827881
Validation loss: 1.7783643273140888
Epoch: 7| Step: 15
Training loss: 1.9457565546035767
Validation loss: 1.7805620251799659
Epoch: 17| Step: 0
Training loss: 1.8932256698608398
Validation loss: 1.7845469901887634
Epoch: 7| Step: 1
Training loss: 2.2982661724090576
Validation loss: 1.788908483313142
Epoch: 7| Step: 2
Training loss: 2.0805575847625732
Validation loss: 1.79515007416979
Epoch: 7| Step: 3
Training loss: 2.4408726692199707
Validation loss: 1.79272426118096
Epoch: 7| Step: 4
Training loss: 1.4959867000579834
Validation loss: 1.7908965966684356
Epoch: 7| Step: 5
Training loss: 2.852156162261963
Validation loss: 1.8117055001018716
Epoch: 7| Step: 6
Training loss: 2.1554572582244873
Validation loss: 1.7984600247239038
Epoch: 7| Step: 7
Training loss: 1.6867029666900635
Validation loss: 1.8052620913484971
Epoch: 7| Step: 8
Training loss: 2.0348706245422363
Validation loss: 1.8140166714894685
Epoch: 7| Step: 9
Training loss: 1.5226268768310547
Validation loss: 1.804490671741019
Epoch: 7| Step: 10
Training loss: 2.1705076694488525
Validation loss: 1.8148277534855355
Epoch: 7| Step: 11
Training loss: 2.7669754028320312
Validation loss: 1.8146836431764013
Epoch: 7| Step: 12
Training loss: 1.8315941095352173
Validation loss: 1.8165821960504107
Epoch: 7| Step: 13
Training loss: 2.334507703781128
Validation loss: 1.8065668241583186
Epoch: 7| Step: 14
Training loss: 2.141857862472534
Validation loss: 1.804500185328422
Epoch: 7| Step: 15
Training loss: 1.9641069173812866
Validation loss: 1.823731930135823
Epoch: 18| Step: 0
Training loss: 1.8861134052276611
Validation loss: 1.8087729790227876
Epoch: 7| Step: 1
Training loss: 2.3367419242858887
Validation loss: 1.8106774889307915
Epoch: 7| Step: 2
Training loss: 2.0983097553253174
Validation loss: 1.803397738676277
Epoch: 7| Step: 3
Training loss: 2.4042763710021973
Validation loss: 1.8028028783180732
Epoch: 7| Step: 4
Training loss: 2.200239896774292
Validation loss: 1.805935546648588
Epoch: 7| Step: 5
Training loss: 1.9928995370864868
Validation loss: 1.8004059448516627
Epoch: 7| Step: 6
Training loss: 2.4805407524108887
Validation loss: 1.8189010800217553
Epoch: 7| Step: 7
Training loss: 2.0437071323394775
Validation loss: 1.8059821669146312
Epoch: 7| Step: 8
Training loss: 2.0930652618408203
Validation loss: 1.808095073528427
Epoch: 7| Step: 9
Training loss: 1.68991219997406
Validation loss: 1.7960985135689056
Epoch: 7| Step: 10
Training loss: 2.208038568496704
Validation loss: 1.8007202980329664
Epoch: 7| Step: 11
Training loss: 2.343235492706299
Validation loss: 1.8065347885913987
Epoch: 7| Step: 12
Training loss: 1.7601133584976196
Validation loss: 1.7924599184406746
Epoch: 7| Step: 13
Training loss: 2.026456594467163
Validation loss: 1.7958178760336458
Epoch: 7| Step: 14
Training loss: 2.0763144493103027
Validation loss: 1.7924898991481863
Epoch: 7| Step: 15
Training loss: 1.986528992652893
Validation loss: 1.7915179060517454
Epoch: 19| Step: 0
Training loss: 1.866213083267212
Validation loss: 1.7952509355201995
Epoch: 7| Step: 1
Training loss: 2.279498338699341
Validation loss: 1.79584713033635
Epoch: 7| Step: 2
Training loss: 2.057826519012451
Validation loss: 1.7934356730618923
Epoch: 7| Step: 3
Training loss: 1.8550083637237549
Validation loss: 1.8017671219736553
Epoch: 7| Step: 4
Training loss: 2.0184054374694824
Validation loss: 1.7914762188204758
Epoch: 7| Step: 5
Training loss: 1.9031788110733032
Validation loss: 1.7771769933563342
Epoch: 7| Step: 6
Training loss: 1.749510407447815
Validation loss: 1.7906992589827064
Epoch: 7| Step: 7
Training loss: 2.027345657348633
Validation loss: 1.7851375667311304
Epoch: 7| Step: 8
Training loss: 2.5758278369903564
Validation loss: 1.7802228773240563
Epoch: 7| Step: 9
Training loss: 2.604337215423584
Validation loss: 1.7827681586039152
Epoch: 7| Step: 10
Training loss: 1.9919300079345703
Validation loss: 1.7896303650286558
Epoch: 7| Step: 11
Training loss: 2.020559787750244
Validation loss: 1.7958339444167322
Epoch: 7| Step: 12
Training loss: 2.1020708084106445
Validation loss: 1.7999985629706075
Epoch: 7| Step: 13
Training loss: 1.9850471019744873
Validation loss: 1.7978875577020987
Epoch: 7| Step: 14
Training loss: 2.0763421058654785
Validation loss: 1.79192508038857
Epoch: 7| Step: 15
Training loss: 2.423011064529419
Validation loss: 1.7949906407500342
Epoch: 20| Step: 0
Training loss: 2.372941732406616
Validation loss: 1.7835536757819086
Epoch: 7| Step: 1
Training loss: 2.054407835006714
Validation loss: 1.7926159179467949
Epoch: 7| Step: 2
Training loss: 1.9865400791168213
Validation loss: 1.7963306672281498
Epoch: 7| Step: 3
Training loss: 1.9886729717254639
Validation loss: 1.807151327887885
Epoch: 7| Step: 4
Training loss: 2.5001730918884277
Validation loss: 1.8098166023226951
Epoch: 7| Step: 5
Training loss: 2.0489001274108887
Validation loss: 1.8042613893961734
Epoch: 7| Step: 6
Training loss: 2.3087539672851562
Validation loss: 1.8085842467040467
Epoch: 7| Step: 7
Training loss: 2.0599379539489746
Validation loss: 1.8141948585029986
Epoch: 7| Step: 8
Training loss: 2.6723339557647705
Validation loss: 1.8080128508506061
Epoch: 7| Step: 9
Training loss: 1.8943026065826416
Validation loss: 1.8128229877073987
Epoch: 7| Step: 10
Training loss: 1.8005437850952148
Validation loss: 1.8149813705211064
Epoch: 7| Step: 11
Training loss: 1.9062671661376953
Validation loss: 1.809169018011299
Epoch: 7| Step: 12
Training loss: 2.2050716876983643
Validation loss: 1.824602553312727
Epoch: 7| Step: 13
Training loss: 1.6428606510162354
Validation loss: 1.8129051014673796
Epoch: 7| Step: 14
Training loss: 1.6387373208999634
Validation loss: 1.8067917669419762
Epoch: 7| Step: 15
Training loss: 2.5050923824310303
Validation loss: 1.8106318686505873
Epoch: 21| Step: 0
Training loss: 1.651445746421814
Validation loss: 1.8072424895471806
Epoch: 7| Step: 1
Training loss: 1.741565465927124
Validation loss: 1.8138049635098135
Epoch: 7| Step: 2
Training loss: 1.9387906789779663
Validation loss: 1.8007242662443532
Epoch: 7| Step: 3
Training loss: 2.625871181488037
Validation loss: 1.798337350646369
Epoch: 7| Step: 4
Training loss: 1.8559297323226929
Validation loss: 1.802263831920761
Epoch: 7| Step: 5
Training loss: 2.2453343868255615
Validation loss: 1.7988513407947349
Epoch: 7| Step: 6
Training loss: 1.8875497579574585
Validation loss: 1.79227435931885
Epoch: 7| Step: 7
Training loss: 2.319791316986084
Validation loss: 1.7854788166155917
Epoch: 7| Step: 8
Training loss: 2.565682888031006
Validation loss: 1.80205767789333
Epoch: 7| Step: 9
Training loss: 2.33646559715271
Validation loss: 1.7973390774761173
Epoch: 7| Step: 10
Training loss: 2.1677517890930176
Validation loss: 1.7917599455058146
Epoch: 7| Step: 11
Training loss: 1.8314456939697266
Validation loss: 1.7863575974814325
Epoch: 7| Step: 12
Training loss: 2.210850715637207
Validation loss: 1.7855341194344938
Epoch: 7| Step: 13
Training loss: 2.0992445945739746
Validation loss: 1.7867708574953696
Epoch: 7| Step: 14
Training loss: 2.095827579498291
Validation loss: 1.792085582403828
Epoch: 7| Step: 15
Training loss: 1.9524673223495483
Validation loss: 1.7860746177838003
Epoch: 22| Step: 0
Training loss: 2.4866766929626465
Validation loss: 1.786309545846294
Epoch: 7| Step: 1
Training loss: 1.7109588384628296
Validation loss: 1.7925267794149384
Epoch: 7| Step: 2
Training loss: 1.8656429052352905
Validation loss: 1.7752401760156207
Epoch: 7| Step: 3
Training loss: 2.136547327041626
Validation loss: 1.786945052284131
Epoch: 7| Step: 4
Training loss: 2.4846253395080566
Validation loss: 1.7849204780386507
Epoch: 7| Step: 5
Training loss: 2.180353879928589
Validation loss: 1.7864937293443748
Epoch: 7| Step: 6
Training loss: 2.4346086978912354
Validation loss: 1.788669641069371
Epoch: 7| Step: 7
Training loss: 1.820486307144165
Validation loss: 1.7766243090732492
Epoch: 7| Step: 8
Training loss: 2.428661346435547
Validation loss: 1.7862141389640973
Epoch: 7| Step: 9
Training loss: 2.027926445007324
Validation loss: 1.7827279156060527
Epoch: 7| Step: 10
Training loss: 1.5730890035629272
Validation loss: 1.7913138454766582
Epoch: 7| Step: 11
Training loss: 2.5374069213867188
Validation loss: 1.785251445907483
Epoch: 7| Step: 12
Training loss: 1.9357378482818604
Validation loss: 1.7860822626155057
Epoch: 7| Step: 13
Training loss: 1.4838300943374634
Validation loss: 1.7830458939504281
Epoch: 7| Step: 14
Training loss: 1.7334331274032593
Validation loss: 1.7783680656831042
Epoch: 7| Step: 15
Training loss: 2.575756311416626
Validation loss: 1.7876902647155652
Epoch: 23| Step: 0
Training loss: 2.296607494354248
Validation loss: 1.791396570720261
Epoch: 7| Step: 1
Training loss: 1.7273900508880615
Validation loss: 1.7842532825126922
Epoch: 7| Step: 2
Training loss: 1.9159667491912842
Validation loss: 1.786957548676635
Epoch: 7| Step: 3
Training loss: 1.939549207687378
Validation loss: 1.7920165027645851
Epoch: 7| Step: 4
Training loss: 1.542083978652954
Validation loss: 1.7937602936792716
Epoch: 7| Step: 5
Training loss: 1.935718297958374
Validation loss: 1.8030096978592358
Epoch: 7| Step: 6
Training loss: 2.057283401489258
Validation loss: 1.8041769652057895
Epoch: 7| Step: 7
Training loss: 1.911098837852478
Validation loss: 1.8064510299147463
Epoch: 7| Step: 8
Training loss: 1.4865484237670898
Validation loss: 1.8005522583886016
Epoch: 7| Step: 9
Training loss: 2.3888235092163086
Validation loss: 1.7970205348172634
Epoch: 7| Step: 10
Training loss: 1.840256690979004
Validation loss: 1.7937886543411146
Epoch: 7| Step: 11
Training loss: 2.25616455078125
Validation loss: 1.800816086556414
Epoch: 7| Step: 12
Training loss: 2.3235268592834473
Validation loss: 1.7951333368424889
Epoch: 7| Step: 13
Training loss: 2.7268757820129395
Validation loss: 1.79814054640077
Epoch: 7| Step: 14
Training loss: 2.370227336883545
Validation loss: 1.8044621001044623
Epoch: 7| Step: 15
Training loss: 2.7364935874938965
Validation loss: 1.8008686244058951
Epoch: 24| Step: 0
Training loss: 1.7430469989776611
Validation loss: 1.7895890963163308
Epoch: 7| Step: 1
Training loss: 2.327855348587036
Validation loss: 1.8037217881182115
Epoch: 7| Step: 2
Training loss: 1.9343597888946533
Validation loss: 1.8024799369221969
Epoch: 7| Step: 3
Training loss: 2.0814805030822754
Validation loss: 1.8107554166437052
Epoch: 7| Step: 4
Training loss: 2.078946590423584
Validation loss: 1.810442838737433
Epoch: 7| Step: 5
Training loss: 2.248570203781128
Validation loss: 1.7978852086787602
Epoch: 7| Step: 6
Training loss: 1.7923476696014404
Validation loss: 1.8147819479592413
Epoch: 7| Step: 7
Training loss: 2.077198028564453
Validation loss: 1.809667313699242
Epoch: 7| Step: 8
Training loss: 1.626158356666565
Validation loss: 1.7997092806178032
Epoch: 7| Step: 9
Training loss: 1.6695626974105835
Validation loss: 1.807411450276272
Epoch: 7| Step: 10
Training loss: 2.1953110694885254
Validation loss: 1.8013051808309213
Epoch: 7| Step: 11
Training loss: 2.346000909805298
Validation loss: 1.8104428576050902
Epoch: 7| Step: 12
Training loss: 2.2547197341918945
Validation loss: 1.818384521299129
Epoch: 7| Step: 13
Training loss: 2.7104735374450684
Validation loss: 1.8153160475998473
Epoch: 7| Step: 14
Training loss: 1.6707302331924438
Validation loss: 1.8079720143791582
Epoch: 7| Step: 15
Training loss: 2.543569564819336
Validation loss: 1.8072619721186247
Epoch: 25| Step: 0
Training loss: 2.2667927742004395
Validation loss: 1.8128465328285162
Epoch: 7| Step: 1
Training loss: 2.383790969848633
Validation loss: 1.8114429995310393
Epoch: 7| Step: 2
Training loss: 1.5633480548858643
Validation loss: 1.8171296908701067
Epoch: 7| Step: 3
Training loss: 1.937309980392456
Validation loss: 1.808681056653853
Epoch: 7| Step: 4
Training loss: 2.7414658069610596
Validation loss: 1.7999346950928943
Epoch: 7| Step: 5
Training loss: 2.6131958961486816
Validation loss: 1.8135159015655518
Epoch: 7| Step: 6
Training loss: 1.9582250118255615
Validation loss: 1.8125027092240698
Epoch: 7| Step: 7
Training loss: 2.29992413520813
Validation loss: 1.8111939215831618
Epoch: 7| Step: 8
Training loss: 1.6898250579833984
Validation loss: 1.8065813822711971
Epoch: 7| Step: 9
Training loss: 1.4567610025405884
Validation loss: 1.8139634055199383
Epoch: 7| Step: 10
Training loss: 1.8034074306488037
Validation loss: 1.8241620964283565
Epoch: 7| Step: 11
Training loss: 1.8735182285308838
Validation loss: 1.8344889141672807
Epoch: 7| Step: 12
Training loss: 2.664374589920044
Validation loss: 1.8275736132971674
Epoch: 7| Step: 13
Training loss: 2.2969908714294434
Validation loss: 1.819895936430787
Epoch: 7| Step: 14
Training loss: 1.6091101169586182
Validation loss: 1.823860521796796
Epoch: 7| Step: 15
Training loss: 2.0481514930725098
Validation loss: 1.8167433798741952
Epoch: 26| Step: 0
Training loss: 1.7139770984649658
Validation loss: 1.8055151246434493
Epoch: 7| Step: 1
Training loss: 2.4237189292907715
Validation loss: 1.8195072566862587
Epoch: 7| Step: 2
Training loss: 2.291673183441162
Validation loss: 1.814936026394796
Epoch: 7| Step: 3
Training loss: 2.3245785236358643
Validation loss: 1.8000639033832138
Epoch: 7| Step: 4
Training loss: 2.2865853309631348
Validation loss: 1.8126369851956265
Epoch: 7| Step: 5
Training loss: 2.8115127086639404
Validation loss: 1.8141028246433615
Epoch: 7| Step: 6
Training loss: 2.097689151763916
Validation loss: 1.8066932263134194
Epoch: 7| Step: 7
Training loss: 1.612810730934143
Validation loss: 1.8066194031735976
Epoch: 7| Step: 8
Training loss: 1.6896507740020752
Validation loss: 1.807656295007939
Epoch: 7| Step: 9
Training loss: 1.8981659412384033
Validation loss: 1.8003547586125435
Epoch: 7| Step: 10
Training loss: 1.6288576126098633
Validation loss: 1.8039568688372056
Epoch: 7| Step: 11
Training loss: 1.7616325616836548
Validation loss: 1.7883327590475837
Epoch: 7| Step: 12
Training loss: 2.2563838958740234
Validation loss: 1.7909021025938954
Epoch: 7| Step: 13
Training loss: 1.9007737636566162
Validation loss: 1.7885203635949882
Epoch: 7| Step: 14
Training loss: 2.3278932571411133
Validation loss: 1.7853395381419779
Epoch: 7| Step: 15
Training loss: 2.269707202911377
Validation loss: 1.7777852308835915
Epoch: 27| Step: 0
Training loss: 2.6624579429626465
Validation loss: 1.7873470791809851
Epoch: 7| Step: 1
Training loss: 2.3875937461853027
Validation loss: 1.777701945613614
Epoch: 7| Step: 2
Training loss: 2.2069478034973145
Validation loss: 1.7848423908082702
Epoch: 7| Step: 3
Training loss: 2.3054792881011963
Validation loss: 1.786844565714006
Epoch: 7| Step: 4
Training loss: 2.4651448726654053
Validation loss: 1.797689246616775
Epoch: 7| Step: 5
Training loss: 1.8807001113891602
Validation loss: 1.784022740322909
Epoch: 7| Step: 6
Training loss: 1.6647192239761353
Validation loss: 1.7913888838651368
Epoch: 7| Step: 7
Training loss: 1.7427572011947632
Validation loss: 1.7881693273997135
Epoch: 7| Step: 8
Training loss: 2.1508750915527344
Validation loss: 1.7867252492218566
Epoch: 7| Step: 9
Training loss: 2.492636203765869
Validation loss: 1.7866475453479684
Epoch: 7| Step: 10
Training loss: 1.6702587604522705
Validation loss: 1.7951046417085388
Epoch: 7| Step: 11
Training loss: 1.808321237564087
Validation loss: 1.7786254239596908
Epoch: 7| Step: 12
Training loss: 1.966518759727478
Validation loss: 1.7790120334076367
Epoch: 7| Step: 13
Training loss: 2.386805534362793
Validation loss: 1.776423449996564
Epoch: 7| Step: 14
Training loss: 2.022465705871582
Validation loss: 1.7831087412594033
Epoch: 7| Step: 15
Training loss: 1.5548522472381592
Validation loss: 1.7895545127580492
Epoch: 28| Step: 0
Training loss: 2.0731301307678223
Validation loss: 1.7777498403041483
Epoch: 7| Step: 1
Training loss: 1.3563282489776611
Validation loss: 1.78863218533907
Epoch: 7| Step: 2
Training loss: 1.4531471729278564
Validation loss: 1.7841113128250452
Epoch: 7| Step: 3
Training loss: 2.283874034881592
Validation loss: 1.792799650336341
Epoch: 7| Step: 4
Training loss: 2.4774224758148193
Validation loss: 1.7984984761519398
Epoch: 7| Step: 5
Training loss: 1.987148642539978
Validation loss: 1.7868345727165826
Epoch: 7| Step: 6
Training loss: 2.100578784942627
Validation loss: 1.7861762981620624
Epoch: 7| Step: 7
Training loss: 1.689426064491272
Validation loss: 1.7952206846621397
Epoch: 7| Step: 8
Training loss: 2.1348581314086914
Validation loss: 1.8001586001553982
Epoch: 7| Step: 9
Training loss: 2.8384556770324707
Validation loss: 1.7944971477385048
Epoch: 7| Step: 10
Training loss: 1.9691540002822876
Validation loss: 1.7963875051882627
Epoch: 7| Step: 11
Training loss: 2.071808099746704
Validation loss: 1.8004887052577176
Epoch: 7| Step: 12
Training loss: 2.3822436332702637
Validation loss: 1.8010566680551432
Epoch: 7| Step: 13
Training loss: 1.8929170370101929
Validation loss: 1.796234859837045
Epoch: 7| Step: 14
Training loss: 2.235720634460449
Validation loss: 1.7930016157438429
Epoch: 7| Step: 15
Training loss: 2.3745789527893066
Validation loss: 1.792685647662595
Epoch: 29| Step: 0
Training loss: 1.803041696548462
Validation loss: 1.7977963008468958
Epoch: 7| Step: 1
Training loss: 1.577593445777893
Validation loss: 1.805536357618922
Epoch: 7| Step: 2
Training loss: 2.212904453277588
Validation loss: 1.8008968710041733
Epoch: 7| Step: 3
Training loss: 2.3919034004211426
Validation loss: 1.7936850674718403
Epoch: 7| Step: 4
Training loss: 2.140406847000122
Validation loss: 1.80467273348527
Epoch: 7| Step: 5
Training loss: 2.0316147804260254
Validation loss: 1.794132604015817
Epoch: 7| Step: 6
Training loss: 1.787632942199707
Validation loss: 1.7955189274369383
Epoch: 7| Step: 7
Training loss: 1.6782490015029907
Validation loss: 1.8032738382010152
Epoch: 7| Step: 8
Training loss: 3.0639920234680176
Validation loss: 1.7961670880695042
Epoch: 7| Step: 9
Training loss: 1.9353084564208984
Validation loss: 1.8062267423533707
Epoch: 7| Step: 10
Training loss: 2.059330701828003
Validation loss: 1.8143787409761827
Epoch: 7| Step: 11
Training loss: 1.8679546117782593
Validation loss: 1.8164149068242355
Epoch: 7| Step: 12
Training loss: 2.2767481803894043
Validation loss: 1.8100918214098156
Epoch: 7| Step: 13
Training loss: 2.070432186126709
Validation loss: 1.818929052181381
Epoch: 7| Step: 14
Training loss: 2.3145432472229004
Validation loss: 1.8138906423994106
Epoch: 7| Step: 15
Training loss: 1.9265934228897095
Validation loss: 1.8139954462325831
Epoch: 30| Step: 0
Training loss: 2.9465081691741943
Validation loss: 1.8250772146869907
Epoch: 7| Step: 1
Training loss: 2.399275541305542
Validation loss: 1.8267808655183093
Epoch: 7| Step: 2
Training loss: 2.336719512939453
Validation loss: 1.8188684621303202
Epoch: 7| Step: 3
Training loss: 1.5141615867614746
Validation loss: 1.8167590709041348
Epoch: 7| Step: 4
Training loss: 1.8402173519134521
Validation loss: 1.810848954770205
Epoch: 7| Step: 5
Training loss: 1.9877678155899048
Validation loss: 1.8141963413293414
Epoch: 7| Step: 6
Training loss: 1.8490123748779297
Validation loss: 1.8023723149471145
Epoch: 7| Step: 7
Training loss: 2.110279083251953
Validation loss: 1.8161084128798342
Epoch: 7| Step: 8
Training loss: 1.9950904846191406
Validation loss: 1.814314814780256
Epoch: 7| Step: 9
Training loss: 2.2596065998077393
Validation loss: 1.809321784287048
Epoch: 7| Step: 10
Training loss: 1.9151897430419922
Validation loss: 1.8045331857187286
Epoch: 7| Step: 11
Training loss: 1.928889513015747
Validation loss: 1.8156597974489062
Epoch: 7| Step: 12
Training loss: 1.9429309368133545
Validation loss: 1.8115691701285273
Epoch: 7| Step: 13
Training loss: 2.066692352294922
Validation loss: 1.8042375586873336
Epoch: 7| Step: 14
Training loss: 2.143447160720825
Validation loss: 1.8162994007412478
Epoch: 7| Step: 15
Training loss: 1.9592475891113281
Validation loss: 1.8213614791417294
Epoch: 31| Step: 0
Training loss: 2.0217981338500977
Validation loss: 1.7929261133825178
Epoch: 7| Step: 1
Training loss: 2.3377814292907715
Validation loss: 1.8158671469997159
Epoch: 7| Step: 2
Training loss: 2.200209379196167
Validation loss: 1.8127588934177974
Epoch: 7| Step: 3
Training loss: 2.019670248031616
Validation loss: 1.8052875558249384
Epoch: 7| Step: 4
Training loss: 2.282468557357788
Validation loss: 1.8201954347624196
Epoch: 7| Step: 5
Training loss: 1.8385404348373413
Validation loss: 1.8119036516697287
Epoch: 7| Step: 6
Training loss: 1.961814522743225
Validation loss: 1.8141390265320703
Epoch: 7| Step: 7
Training loss: 2.349700927734375
Validation loss: 1.806663707005892
Epoch: 7| Step: 8
Training loss: 1.4796531200408936
Validation loss: 1.8240950219065166
Epoch: 7| Step: 9
Training loss: 2.257594585418701
Validation loss: 1.8169461720281368
Epoch: 7| Step: 10
Training loss: 1.986811637878418
Validation loss: 1.8034099057423982
Epoch: 7| Step: 11
Training loss: 2.3097119331359863
Validation loss: 1.8219012725267478
Epoch: 7| Step: 12
Training loss: 2.219801902770996
Validation loss: 1.8194095882580434
Epoch: 7| Step: 13
Training loss: 1.948991060256958
Validation loss: 1.8078428343903246
Epoch: 7| Step: 14
Training loss: 1.9084444046020508
Validation loss: 1.8132938832687817
Epoch: 7| Step: 15
Training loss: 1.926774024963379
Validation loss: 1.8077984422230893
Epoch: 32| Step: 0
Training loss: 2.4414591789245605
Validation loss: 1.810449622517867
Epoch: 7| Step: 1
Training loss: 2.1586596965789795
Validation loss: 1.8103227246579507
Epoch: 7| Step: 2
Training loss: 2.0513954162597656
Validation loss: 1.7966254314930319
Epoch: 7| Step: 3
Training loss: 2.706275463104248
Validation loss: 1.8015143159482119
Epoch: 7| Step: 4
Training loss: 2.246432065963745
Validation loss: 1.8040858052617355
Epoch: 7| Step: 5
Training loss: 1.7765090465545654
Validation loss: 1.791752499642132
Epoch: 7| Step: 6
Training loss: 2.4355201721191406
Validation loss: 1.8008758249900323
Epoch: 7| Step: 7
Training loss: 1.9866740703582764
Validation loss: 1.8057621503047805
Epoch: 7| Step: 8
Training loss: 2.1494879722595215
Validation loss: 1.8098823672575917
Epoch: 7| Step: 9
Training loss: 2.022563934326172
Validation loss: 1.8070472933405595
Epoch: 7| Step: 10
Training loss: 2.0226354598999023
Validation loss: 1.8185903039767588
Epoch: 7| Step: 11
Training loss: 1.6650307178497314
Validation loss: 1.79801875910313
Epoch: 7| Step: 12
Training loss: 2.2616143226623535
Validation loss: 1.7972116744775566
Epoch: 7| Step: 13
Training loss: 1.3325430154800415
Validation loss: 1.801645882695699
Epoch: 7| Step: 14
Training loss: 2.1520817279815674
Validation loss: 1.7947328536630534
Epoch: 7| Step: 15
Training loss: 1.7776496410369873
Validation loss: 1.7886442657854917
Epoch: 33| Step: 0
Training loss: 1.9277490377426147
Validation loss: 1.8025535010605407
Epoch: 7| Step: 1
Training loss: 2.0903306007385254
Validation loss: 1.7994493683465094
Epoch: 7| Step: 2
Training loss: 2.5416319370269775
Validation loss: 1.802306020002571
Epoch: 7| Step: 3
Training loss: 1.8202203512191772
Validation loss: 1.7896599675254
Epoch: 7| Step: 4
Training loss: 1.8427423238754272
Validation loss: 1.803156171771262
Epoch: 7| Step: 5
Training loss: 1.7953603267669678
Validation loss: 1.8007606653858432
Epoch: 7| Step: 6
Training loss: 1.6697406768798828
Validation loss: 1.7956833968059622
Epoch: 7| Step: 7
Training loss: 1.9349559545516968
Validation loss: 1.801280691469316
Epoch: 7| Step: 8
Training loss: 2.0725364685058594
Validation loss: 1.7981708838785295
Epoch: 7| Step: 9
Training loss: 2.139986753463745
Validation loss: 1.8047168683662689
Epoch: 7| Step: 10
Training loss: 2.3095691204071045
Validation loss: 1.8153705939972142
Epoch: 7| Step: 11
Training loss: 2.087803363800049
Validation loss: 1.8013053163350057
Epoch: 7| Step: 12
Training loss: 2.128563642501831
Validation loss: 1.8089380024148405
Epoch: 7| Step: 13
Training loss: 2.175663471221924
Validation loss: 1.8060913874948625
Epoch: 7| Step: 14
Training loss: 2.432068109512329
Validation loss: 1.8010097999366925
Epoch: 7| Step: 15
Training loss: 1.999569296836853
Validation loss: 1.8162148324705714
Epoch: 34| Step: 0
Training loss: 1.851020097732544
Validation loss: 1.8036757922001023
Epoch: 7| Step: 1
Training loss: 2.5286905765533447
Validation loss: 1.8046200601317042
Epoch: 7| Step: 2
Training loss: 2.161224126815796
Validation loss: 1.8061233956179172
Epoch: 7| Step: 3
Training loss: 2.176600217819214
Validation loss: 1.8082798693677504
Epoch: 7| Step: 4
Training loss: 1.7326186895370483
Validation loss: 1.7948090524124585
Epoch: 7| Step: 5
Training loss: 2.1796467304229736
Validation loss: 1.7997413676419705
Epoch: 7| Step: 6
Training loss: 2.578834295272827
Validation loss: 1.8030541431989602
Epoch: 7| Step: 7
Training loss: 1.7381887435913086
Validation loss: 1.8103844236126907
Epoch: 7| Step: 8
Training loss: 2.388894557952881
Validation loss: 1.8129230694805119
Epoch: 7| Step: 9
Training loss: 1.8010002374649048
Validation loss: 1.805339496770351
Epoch: 7| Step: 10
Training loss: 2.0240182876586914
Validation loss: 1.8061249453386814
Epoch: 7| Step: 11
Training loss: 1.4756933450698853
Validation loss: 1.7965828600547296
Epoch: 7| Step: 12
Training loss: 2.467808246612549
Validation loss: 1.794984784915293
Epoch: 7| Step: 13
Training loss: 1.4775863885879517
Validation loss: 1.8025163986700043
Epoch: 7| Step: 14
Training loss: 2.234605312347412
Validation loss: 1.7933602110087443
Epoch: 7| Step: 15
Training loss: 2.3201346397399902
Validation loss: 1.8013079852508984
Epoch: 35| Step: 0
Training loss: 1.7482208013534546
Validation loss: 1.8006636581832556
Epoch: 7| Step: 1
Training loss: 2.0840516090393066
Validation loss: 1.7966568024038412
Epoch: 7| Step: 2
Training loss: 2.2547316551208496
Validation loss: 1.7892624216971638
Epoch: 7| Step: 3
Training loss: 2.5013468265533447
Validation loss: 1.8072532561185548
Epoch: 7| Step: 4
Training loss: 1.4024423360824585
Validation loss: 1.801531410045761
Epoch: 7| Step: 5
Training loss: 2.416041851043701
Validation loss: 1.8039045668334412
Epoch: 7| Step: 6
Training loss: 2.1794662475585938
Validation loss: 1.7966821896944114
Epoch: 7| Step: 7
Training loss: 1.9382346868515015
Validation loss: 1.8043325822130383
Epoch: 7| Step: 8
Training loss: 2.001146078109741
Validation loss: 1.8108134672796126
Epoch: 7| Step: 9
Training loss: 2.6535937786102295
Validation loss: 1.8180013560562682
Epoch: 7| Step: 10
Training loss: 2.942544937133789
Validation loss: 1.811652871344587
Epoch: 7| Step: 11
Training loss: 1.2467329502105713
Validation loss: 1.8118060029667915
Epoch: 7| Step: 12
Training loss: 2.352914333343506
Validation loss: 1.8123888935116554
Epoch: 7| Step: 13
Training loss: 1.3386647701263428
Validation loss: 1.8077519265867823
Epoch: 7| Step: 14
Training loss: 2.275458574295044
Validation loss: 1.8097838034732736
Epoch: 7| Step: 15
Training loss: 1.7093684673309326
Validation loss: 1.8024758949554225
Epoch: 36| Step: 0
Training loss: 2.0877766609191895
Validation loss: 1.8032857265403803
Epoch: 7| Step: 1
Training loss: 2.201030731201172
Validation loss: 1.808261574601098
Epoch: 7| Step: 2
Training loss: 1.8979564905166626
Validation loss: 1.8101120998533509
Epoch: 7| Step: 3
Training loss: 2.799856185913086
Validation loss: 1.8037580603318248
Epoch: 7| Step: 4
Training loss: 2.123194932937622
Validation loss: 1.8013413149675876
Epoch: 7| Step: 5
Training loss: 2.549436092376709
Validation loss: 1.8070698007405233
Epoch: 7| Step: 6
Training loss: 1.6248042583465576
Validation loss: 1.8009466987719638
Epoch: 7| Step: 7
Training loss: 1.7500728368759155
Validation loss: 1.8058154651586957
Epoch: 7| Step: 8
Training loss: 1.7073720693588257
Validation loss: 1.7901177277667917
Epoch: 7| Step: 9
Training loss: 2.3644022941589355
Validation loss: 1.7877701263633563
Epoch: 7| Step: 10
Training loss: 1.620069146156311
Validation loss: 1.7932176246917506
Epoch: 7| Step: 11
Training loss: 2.3959238529205322
Validation loss: 1.7920224194904026
Epoch: 7| Step: 12
Training loss: 1.8660526275634766
Validation loss: 1.8001717371906307
Epoch: 7| Step: 13
Training loss: 1.770533800125122
Validation loss: 1.7825806432490727
Epoch: 7| Step: 14
Training loss: 2.169851779937744
Validation loss: 1.7835144113293655
Epoch: 7| Step: 15
Training loss: 2.0417802333831787
Validation loss: 1.7910203968020653
Epoch: 37| Step: 0
Training loss: 2.1559898853302
Validation loss: 1.8026826244464023
Epoch: 7| Step: 1
Training loss: 1.882989525794983
Validation loss: 1.8024371236348324
Epoch: 7| Step: 2
Training loss: 1.287269949913025
Validation loss: 1.8010754422318163
Epoch: 7| Step: 3
Training loss: 1.4257166385650635
Validation loss: 1.799893807164199
Epoch: 7| Step: 4
Training loss: 2.2649385929107666
Validation loss: 1.8094370639581474
Epoch: 7| Step: 5
Training loss: 1.94363534450531
Validation loss: 1.796042480057092
Epoch: 7| Step: 6
Training loss: 2.280287027359009
Validation loss: 1.793039881068168
Epoch: 7| Step: 7
Training loss: 2.5681307315826416
Validation loss: 1.8025910013871227
Epoch: 7| Step: 8
Training loss: 1.893958330154419
Validation loss: 1.8019552213682546
Epoch: 7| Step: 9
Training loss: 2.332350969314575
Validation loss: 1.7885300667165853
Epoch: 7| Step: 10
Training loss: 1.9257125854492188
Validation loss: 1.778127577665041
Epoch: 7| Step: 11
Training loss: 1.8600780963897705
Validation loss: 1.7854041358549817
Epoch: 7| Step: 12
Training loss: 2.0647449493408203
Validation loss: 1.7870871094490985
Epoch: 7| Step: 13
Training loss: 2.6732418537139893
Validation loss: 1.7908039264541735
Epoch: 7| Step: 14
Training loss: 2.0256009101867676
Validation loss: 1.7971155480515184
Epoch: 7| Step: 15
Training loss: 2.2746715545654297
Validation loss: 1.7899223660393584
Epoch: 38| Step: 0
Training loss: 2.0074350833892822
Validation loss: 1.79367346729306
Epoch: 7| Step: 1
Training loss: 2.4737133979797363
Validation loss: 1.7912628187550057
Epoch: 7| Step: 2
Training loss: 1.8168147802352905
Validation loss: 1.7939516829072142
Epoch: 7| Step: 3
Training loss: 1.8932182788848877
Validation loss: 1.7936199225967737
Epoch: 7| Step: 4
Training loss: 1.9051525592803955
Validation loss: 1.8037117333720913
Epoch: 7| Step: 5
Training loss: 2.511708974838257
Validation loss: 1.7968569813872413
Epoch: 7| Step: 6
Training loss: 2.1660618782043457
Validation loss: 1.7988560011060974
Epoch: 7| Step: 7
Training loss: 2.4797377586364746
Validation loss: 1.8060830685732177
Epoch: 7| Step: 8
Training loss: 1.6559820175170898
Validation loss: 1.8045147726004072
Epoch: 7| Step: 9
Training loss: 1.9906238317489624
Validation loss: 1.7978639559780094
Epoch: 7| Step: 10
Training loss: 2.1403777599334717
Validation loss: 1.7971179802640735
Epoch: 7| Step: 11
Training loss: 1.9998438358306885
Validation loss: 1.7914008674004096
Epoch: 7| Step: 12
Training loss: 2.1671483516693115
Validation loss: 1.809742294627128
Epoch: 7| Step: 13
Training loss: 1.7927381992340088
Validation loss: 1.7965799021206315
Epoch: 7| Step: 14
Training loss: 2.159414291381836
Validation loss: 1.8003159384075686
Epoch: 7| Step: 15
Training loss: 1.7848056554794312
Validation loss: 1.8032658631853062
Epoch: 39| Step: 0
Training loss: 2.176685094833374
Validation loss: 1.808881540092633
Epoch: 7| Step: 1
Training loss: 2.143118381500244
Validation loss: 1.8126626117623967
Epoch: 7| Step: 2
Training loss: 2.2435200214385986
Validation loss: 1.8286558243868163
Epoch: 7| Step: 3
Training loss: 1.5739593505859375
Validation loss: 1.8140775394096649
Epoch: 7| Step: 4
Training loss: 2.4916558265686035
Validation loss: 1.8076098085307388
Epoch: 7| Step: 5
Training loss: 2.268265962600708
Validation loss: 1.832024627452274
Epoch: 7| Step: 6
Training loss: 2.4759488105773926
Validation loss: 1.8128369060351694
Epoch: 7| Step: 7
Training loss: 1.413831353187561
Validation loss: 1.816056567130329
Epoch: 7| Step: 8
Training loss: 2.479708671569824
Validation loss: 1.8158126752153576
Epoch: 7| Step: 9
Training loss: 2.0918872356414795
Validation loss: 1.8120941944259534
Epoch: 7| Step: 10
Training loss: 1.5040277242660522
Validation loss: 1.8133878450599505
Epoch: 7| Step: 11
Training loss: 1.8196380138397217
Validation loss: 1.8096002134487783
Epoch: 7| Step: 12
Training loss: 2.0331671237945557
Validation loss: 1.8126687540424813
Epoch: 7| Step: 13
Training loss: 1.9224399328231812
Validation loss: 1.8121375059909959
Epoch: 7| Step: 14
Training loss: 2.1367554664611816
Validation loss: 1.8248371434726303
Epoch: 7| Step: 15
Training loss: 2.1477200984954834
Validation loss: 1.8158265420858808
Epoch: 40| Step: 0
Training loss: 1.8749240636825562
Validation loss: 1.8154842150297097
Epoch: 7| Step: 1
Training loss: 1.7659536600112915
Validation loss: 1.8135709573896668
Epoch: 7| Step: 2
Training loss: 2.776357412338257
Validation loss: 1.819654309492317
Epoch: 7| Step: 3
Training loss: 2.0614402294158936
Validation loss: 1.8131583543132535
Epoch: 7| Step: 4
Training loss: 1.7920875549316406
Validation loss: 1.8255282803405104
Epoch: 7| Step: 5
Training loss: 1.9746720790863037
Validation loss: 1.8358709006000766
Epoch: 7| Step: 6
Training loss: 2.254467487335205
Validation loss: 1.8177473613684125
Epoch: 7| Step: 7
Training loss: 2.1618399620056152
Validation loss: 1.8259961176261628
Epoch: 7| Step: 8
Training loss: 1.738551139831543
Validation loss: 1.8220384215279448
Epoch: 7| Step: 9
Training loss: 1.7395368814468384
Validation loss: 1.8281269776735374
Epoch: 7| Step: 10
Training loss: 2.329011917114258
Validation loss: 1.8059183376298533
Epoch: 7| Step: 11
Training loss: 2.207650661468506
Validation loss: 1.8188346444274024
Epoch: 7| Step: 12
Training loss: 2.0587317943573
Validation loss: 1.829864348439004
Epoch: 7| Step: 13
Training loss: 2.0155136585235596
Validation loss: 1.8193207353139096
Epoch: 7| Step: 14
Training loss: 2.0741844177246094
Validation loss: 1.8213703306458837
Epoch: 7| Step: 15
Training loss: 2.017824411392212
Validation loss: 1.828341254227453
Epoch: 41| Step: 0
Training loss: 1.9145482778549194
Validation loss: 1.8201091658297202
Epoch: 7| Step: 1
Training loss: 1.7458469867706299
Validation loss: 1.819830849016313
Epoch: 7| Step: 2
Training loss: 2.217174530029297
Validation loss: 1.8148648936113865
Epoch: 7| Step: 3
Training loss: 2.2319400310516357
Validation loss: 1.8110579398038575
Epoch: 7| Step: 4
Training loss: 2.129286766052246
Validation loss: 1.8201757592262982
Epoch: 7| Step: 5
Training loss: 2.496241807937622
Validation loss: 1.8071936840633693
Epoch: 7| Step: 6
Training loss: 2.3676226139068604
Validation loss: 1.8081293063198063
Epoch: 7| Step: 7
Training loss: 2.5635602474212646
Validation loss: 1.803724384136337
Epoch: 7| Step: 8
Training loss: 1.711106538772583
Validation loss: 1.8181715165968422
Epoch: 7| Step: 9
Training loss: 2.3138668537139893
Validation loss: 1.8144618375695867
Epoch: 7| Step: 10
Training loss: 2.6840853691101074
Validation loss: 1.8164554345521995
Epoch: 7| Step: 11
Training loss: 1.292628526687622
Validation loss: 1.8104026669220958
Epoch: 7| Step: 12
Training loss: 1.623936414718628
Validation loss: 1.8017564060019076
Epoch: 7| Step: 13
Training loss: 2.1510751247406006
Validation loss: 1.8071221361914984
Epoch: 7| Step: 14
Training loss: 1.7612558603286743
Validation loss: 1.8085592959424575
Epoch: 7| Step: 15
Training loss: 1.6336114406585693
Validation loss: 1.8050811985413806
Epoch: 42| Step: 0
Training loss: 2.121307134628296
Validation loss: 1.814005157072767
Epoch: 7| Step: 1
Training loss: 1.6996151208877563
Validation loss: 1.8184087019172503
Epoch: 7| Step: 2
Training loss: 2.311197280883789
Validation loss: 1.8135005630177559
Epoch: 7| Step: 3
Training loss: 1.86492919921875
Validation loss: 1.8006055303614774
Epoch: 7| Step: 4
Training loss: 2.213334560394287
Validation loss: 1.8092298833586329
Epoch: 7| Step: 5
Training loss: 1.460026741027832
Validation loss: 1.808480338226977
Epoch: 7| Step: 6
Training loss: 1.9455816745758057
Validation loss: 1.8051090960879979
Epoch: 7| Step: 7
Training loss: 2.1651298999786377
Validation loss: 1.8076199370322468
Epoch: 7| Step: 8
Training loss: 1.6036020517349243
Validation loss: 1.8032340608912407
Epoch: 7| Step: 9
Training loss: 1.7991101741790771
Validation loss: 1.8046672618646415
Epoch: 7| Step: 10
Training loss: 2.310464859008789
Validation loss: 1.8043638853718051
Epoch: 7| Step: 11
Training loss: 2.406165838241577
Validation loss: 1.796565695632276
Epoch: 7| Step: 12
Training loss: 2.3846137523651123
Validation loss: 1.8039852286414277
Epoch: 7| Step: 13
Training loss: 1.6253137588500977
Validation loss: 1.8045289850921082
Epoch: 7| Step: 14
Training loss: 2.017993927001953
Validation loss: 1.8079920792751174
Epoch: 7| Step: 15
Training loss: 2.777510404586792
Validation loss: 1.8105337525443208
Epoch: 43| Step: 0
Training loss: 1.7177886962890625
Validation loss: 1.813817146013109
Epoch: 7| Step: 1
Training loss: 1.7839876413345337
Validation loss: 1.8119420868029696
Epoch: 7| Step: 2
Training loss: 1.9470586776733398
Validation loss: 1.8172227247155828
Epoch: 7| Step: 3
Training loss: 1.738654375076294
Validation loss: 1.8239381922234734
Epoch: 7| Step: 4
Training loss: 2.225247859954834
Validation loss: 1.8194396633038419
Epoch: 7| Step: 5
Training loss: 2.095334053039551
Validation loss: 1.823988393056307
Epoch: 7| Step: 6
Training loss: 1.7883856296539307
Validation loss: 1.8297843975986507
Epoch: 7| Step: 7
Training loss: 1.492882490158081
Validation loss: 1.8196468902148788
Epoch: 7| Step: 8
Training loss: 1.8441846370697021
Validation loss: 1.8146139143182218
Epoch: 7| Step: 9
Training loss: 2.1201539039611816
Validation loss: 1.8237646166369212
Epoch: 7| Step: 10
Training loss: 2.1630983352661133
Validation loss: 1.8223279071368759
Epoch: 7| Step: 11
Training loss: 2.493191719055176
Validation loss: 1.8246260521223219
Epoch: 7| Step: 12
Training loss: 2.7265005111694336
Validation loss: 1.8304402605235148
Epoch: 7| Step: 13
Training loss: 2.151546001434326
Validation loss: 1.8394803108928872
Epoch: 7| Step: 14
Training loss: 2.282440423965454
Validation loss: 1.8082831163200543
Epoch: 7| Step: 15
Training loss: 2.1533405780792236
Validation loss: 1.8230968276373773
Epoch: 44| Step: 0
Training loss: 1.9506251811981201
Validation loss: 1.8086892477900005
Epoch: 7| Step: 1
Training loss: 2.160642147064209
Validation loss: 1.812828654007946
Epoch: 7| Step: 2
Training loss: 1.717989206314087
Validation loss: 1.8121872051156682
Epoch: 7| Step: 3
Training loss: 2.617835283279419
Validation loss: 1.8224728913615933
Epoch: 7| Step: 4
Training loss: 1.6527293920516968
Validation loss: 1.8093878348096668
Epoch: 7| Step: 5
Training loss: 2.0360636711120605
Validation loss: 1.8130595915609127
Epoch: 7| Step: 6
Training loss: 2.149594783782959
Validation loss: 1.8076589296190002
Epoch: 7| Step: 7
Training loss: 1.447685956954956
Validation loss: 1.806492433273535
Epoch: 7| Step: 8
Training loss: 2.087334394454956
Validation loss: 1.8096639466800277
Epoch: 7| Step: 9
Training loss: 2.5368995666503906
Validation loss: 1.8139925912129793
Epoch: 7| Step: 10
Training loss: 1.3866928815841675
Validation loss: 1.815532590845506
Epoch: 7| Step: 11
Training loss: 2.2194268703460693
Validation loss: 1.8202987214644177
Epoch: 7| Step: 12
Training loss: 2.1652345657348633
Validation loss: 1.8183638363433399
Epoch: 7| Step: 13
Training loss: 1.684302568435669
Validation loss: 1.8045034674431781
Epoch: 7| Step: 14
Training loss: 2.8494391441345215
Validation loss: 1.805903993064551
Epoch: 7| Step: 15
Training loss: 1.962930679321289
Validation loss: 1.8020405649281235
Epoch: 45| Step: 0
Training loss: 2.245666980743408
Validation loss: 1.8008250589850996
Epoch: 7| Step: 1
Training loss: 2.1384994983673096
Validation loss: 1.799171634715238
Epoch: 7| Step: 2
Training loss: 2.3890180587768555
Validation loss: 1.792369923145651
Epoch: 7| Step: 3
Training loss: 2.046220064163208
Validation loss: 1.8017423272990494
Epoch: 7| Step: 4
Training loss: 1.8026994466781616
Validation loss: 1.801033830471176
Epoch: 7| Step: 5
Training loss: 2.690699815750122
Validation loss: 1.7852816204372928
Epoch: 7| Step: 6
Training loss: 1.7143491506576538
Validation loss: 1.8000182342186248
Epoch: 7| Step: 7
Training loss: 1.675819754600525
Validation loss: 1.7903592089097278
Epoch: 7| Step: 8
Training loss: 1.7459266185760498
Validation loss: 1.7965978255374826
Epoch: 7| Step: 9
Training loss: 2.3798422813415527
Validation loss: 1.7840017268983581
Epoch: 7| Step: 10
Training loss: 1.433510422706604
Validation loss: 1.7832653796930107
Epoch: 7| Step: 11
Training loss: 1.8356853723526
Validation loss: 1.7857917950307722
Epoch: 7| Step: 12
Training loss: 1.615125298500061
Validation loss: 1.7855934762268615
Epoch: 7| Step: 13
Training loss: 2.4852821826934814
Validation loss: 1.7769594475519743
Epoch: 7| Step: 14
Training loss: 2.4673359394073486
Validation loss: 1.785224288487606
Epoch: 7| Step: 15
Training loss: 2.013793468475342
Validation loss: 1.7848559695182087
Epoch: 46| Step: 0
Training loss: 2.4126522541046143
Validation loss: 1.796030089151945
Epoch: 7| Step: 1
Training loss: 1.7737863063812256
Validation loss: 1.7879638903432613
Epoch: 7| Step: 2
Training loss: 2.084933280944824
Validation loss: 1.8081223681676302
Epoch: 7| Step: 3
Training loss: 2.2860748767852783
Validation loss: 1.797781322499831
Epoch: 7| Step: 4
Training loss: 1.4425207376480103
Validation loss: 1.7899758086787712
Epoch: 7| Step: 5
Training loss: 2.122751235961914
Validation loss: 1.8106090988186623
Epoch: 7| Step: 6
Training loss: 1.492072582244873
Validation loss: 1.8087453396200277
Epoch: 7| Step: 7
Training loss: 1.9624178409576416
Validation loss: 1.8009389758967667
Epoch: 7| Step: 8
Training loss: 2.0974535942077637
Validation loss: 1.8271601963386261
Epoch: 7| Step: 9
Training loss: 2.345816135406494
Validation loss: 1.8224441216146345
Epoch: 7| Step: 10
Training loss: 2.1932573318481445
Validation loss: 1.8163542207196461
Epoch: 7| Step: 11
Training loss: 2.085859537124634
Validation loss: 1.814920862801641
Epoch: 7| Step: 12
Training loss: 2.0858845710754395
Validation loss: 1.8257524829974277
Epoch: 7| Step: 13
Training loss: 2.3447201251983643
Validation loss: 1.8124462786338311
Epoch: 7| Step: 14
Training loss: 1.9662513732910156
Validation loss: 1.8313049721203263
Epoch: 7| Step: 15
Training loss: 2.0189049243927
Validation loss: 1.8291319274216247
Epoch: 47| Step: 0
Training loss: 2.0981132984161377
Validation loss: 1.8226637994642738
Epoch: 7| Step: 1
Training loss: 2.3324782848358154
Validation loss: 1.820004806244116
Epoch: 7| Step: 2
Training loss: 2.1838784217834473
Validation loss: 1.8411108040981154
Epoch: 7| Step: 3
Training loss: 1.8698428869247437
Validation loss: 1.8393127189265739
Epoch: 7| Step: 4
Training loss: 1.8129276037216187
Validation loss: 1.844372523774346
Epoch: 7| Step: 5
Training loss: 2.262939929962158
Validation loss: 1.831843473070817
Epoch: 7| Step: 6
Training loss: 1.7219778299331665
Validation loss: 1.8397000822231924
Epoch: 7| Step: 7
Training loss: 1.954502820968628
Validation loss: 1.842772506123824
Epoch: 7| Step: 8
Training loss: 1.7781026363372803
Validation loss: 1.836534926359602
Epoch: 7| Step: 9
Training loss: 2.0268077850341797
Validation loss: 1.8447118714558992
Epoch: 7| Step: 10
Training loss: 1.6885879039764404
Validation loss: 1.8450560938540121
Epoch: 7| Step: 11
Training loss: 2.550800323486328
Validation loss: 1.8302446886789885
Epoch: 7| Step: 12
Training loss: 2.252126932144165
Validation loss: 1.827724713215725
Epoch: 7| Step: 13
Training loss: 2.0984742641448975
Validation loss: 1.8156372780422512
Epoch: 7| Step: 14
Training loss: 1.9989200830459595
Validation loss: 1.80873264340188
Epoch: 7| Step: 15
Training loss: 2.0702834129333496
Validation loss: 1.8130507863682808
Epoch: 48| Step: 0
Training loss: 2.1392760276794434
Validation loss: 1.808169321190539
Epoch: 7| Step: 1
Training loss: 2.4567363262176514
Validation loss: 1.8054340245912401
Epoch: 7| Step: 2
Training loss: 2.640329122543335
Validation loss: 1.794487537239953
Epoch: 7| Step: 3
Training loss: 1.8235172033309937
Validation loss: 1.7929815517055046
Epoch: 7| Step: 4
Training loss: 2.44122052192688
Validation loss: 1.7999264550723617
Epoch: 7| Step: 5
Training loss: 1.409556269645691
Validation loss: 1.792580757209723
Epoch: 7| Step: 6
Training loss: 2.237372875213623
Validation loss: 1.7928313591497407
Epoch: 7| Step: 7
Training loss: 2.2192680835723877
Validation loss: 1.7886153845478305
Epoch: 7| Step: 8
Training loss: 1.889497995376587
Validation loss: 1.7981306280163551
Epoch: 7| Step: 9
Training loss: 1.693198800086975
Validation loss: 1.8049298807871428
Epoch: 7| Step: 10
Training loss: 1.973719835281372
Validation loss: 1.794532452555869
Epoch: 7| Step: 11
Training loss: 2.1457698345184326
Validation loss: 1.7914221312502305
Epoch: 7| Step: 12
Training loss: 1.514000654220581
Validation loss: 1.7992244572948208
Epoch: 7| Step: 13
Training loss: 1.841973066329956
Validation loss: 1.7947456262094512
Epoch: 7| Step: 14
Training loss: 1.9361854791641235
Validation loss: 1.7984099473884638
Epoch: 7| Step: 15
Training loss: 2.1721739768981934
Validation loss: 1.8075032071243944
Epoch: 49| Step: 0
Training loss: 2.4760613441467285
Validation loss: 1.8033703008144022
Epoch: 7| Step: 1
Training loss: 2.3450889587402344
Validation loss: 1.7955417856038045
Epoch: 7| Step: 2
Training loss: 2.0585763454437256
Validation loss: 1.7901513542202736
Epoch: 7| Step: 3
Training loss: 2.1278793811798096
Validation loss: 1.8014935975452122
Epoch: 7| Step: 4
Training loss: 1.4453078508377075
Validation loss: 1.8009421190769552
Epoch: 7| Step: 5
Training loss: 1.5842375755310059
Validation loss: 1.78794868729955
Epoch: 7| Step: 6
Training loss: 2.019622325897217
Validation loss: 1.8051000293210255
Epoch: 7| Step: 7
Training loss: 2.6002728939056396
Validation loss: 1.8137196482514306
Epoch: 7| Step: 8
Training loss: 2.3803818225860596
Validation loss: 1.7887435594051004
Epoch: 7| Step: 9
Training loss: 2.9112141132354736
Validation loss: 1.8015349065657142
Epoch: 7| Step: 10
Training loss: 1.7833538055419922
Validation loss: 1.7990093351268082
Epoch: 7| Step: 11
Training loss: 1.6840801239013672
Validation loss: 1.8065521734223948
Epoch: 7| Step: 12
Training loss: 1.2793290615081787
Validation loss: 1.7997506368074485
Epoch: 7| Step: 13
Training loss: 2.214884042739868
Validation loss: 1.8088158909365428
Epoch: 7| Step: 14
Training loss: 1.49019455909729
Validation loss: 1.8167281794033463
Epoch: 7| Step: 15
Training loss: 2.137991428375244
Validation loss: 1.8207676702266118
Epoch: 50| Step: 0
Training loss: 2.0255215167999268
Validation loss: 1.8230910112531922
Epoch: 7| Step: 1
Training loss: 1.6263278722763062
Validation loss: 1.8198948995672541
Epoch: 7| Step: 2
Training loss: 2.3662161827087402
Validation loss: 1.823006450701103
Epoch: 7| Step: 3
Training loss: 1.6049745082855225
Validation loss: 1.8328764978930248
Epoch: 7| Step: 4
Training loss: 1.918103814125061
Validation loss: 1.8267225773214437
Epoch: 7| Step: 5
Training loss: 1.5971343517303467
Validation loss: 1.833549785957062
Epoch: 7| Step: 6
Training loss: 1.9252357482910156
Validation loss: 1.834472757449253
Epoch: 7| Step: 7
Training loss: 1.9429184198379517
Validation loss: 1.8420791574519315
Epoch: 7| Step: 8
Training loss: 2.4053447246551514
Validation loss: 1.833684437566524
Epoch: 7| Step: 9
Training loss: 2.4341864585876465
Validation loss: 1.8352045807049429
Epoch: 7| Step: 10
Training loss: 2.2080116271972656
Validation loss: 1.8491354048680917
Epoch: 7| Step: 11
Training loss: 2.103187084197998
Validation loss: 1.8371087955913956
Epoch: 7| Step: 12
Training loss: 2.045285701751709
Validation loss: 1.834218727598945
Epoch: 7| Step: 13
Training loss: 1.8845911026000977
Validation loss: 1.8377059466547245
Epoch: 7| Step: 14
Training loss: 2.141993284225464
Validation loss: 1.8363869524688172
Epoch: 7| Step: 15
Training loss: 2.4238712787628174
Validation loss: 1.8340426949288349
Epoch: 51| Step: 0
Training loss: 2.6701340675354004
Validation loss: 1.8202735279961455
Epoch: 7| Step: 1
Training loss: 2.0556702613830566
Validation loss: 1.8260504273201923
Epoch: 7| Step: 2
Training loss: 1.9418996572494507
Validation loss: 1.8162501621589386
Epoch: 7| Step: 3
Training loss: 2.141171932220459
Validation loss: 1.812636339407173
Epoch: 7| Step: 4
Training loss: 1.9195630550384521
Validation loss: 1.8026599197936573
Epoch: 7| Step: 5
Training loss: 2.150907039642334
Validation loss: 1.8054791294413506
Epoch: 7| Step: 6
Training loss: 1.6879031658172607
Validation loss: 1.7975094438456802
Epoch: 7| Step: 7
Training loss: 1.645491361618042
Validation loss: 1.7934266097254032
Epoch: 7| Step: 8
Training loss: 1.7740825414657593
Validation loss: 1.7933798428062055
Epoch: 7| Step: 9
Training loss: 2.2210114002227783
Validation loss: 1.7901186479938973
Epoch: 7| Step: 10
Training loss: 2.4490857124328613
Validation loss: 1.7870495062080218
Epoch: 7| Step: 11
Training loss: 1.9798429012298584
Validation loss: 1.7977938240380595
Epoch: 7| Step: 12
Training loss: 2.4005725383758545
Validation loss: 1.795564246692246
Epoch: 7| Step: 13
Training loss: 1.6510956287384033
Validation loss: 1.7872859514016899
Epoch: 7| Step: 14
Training loss: 1.4309648275375366
Validation loss: 1.7837487321963412
Epoch: 7| Step: 15
Training loss: 2.3783340454101562
Validation loss: 1.7866121779242865
Epoch: 52| Step: 0
Training loss: 1.574724555015564
Validation loss: 1.805378239789455
Epoch: 7| Step: 1
Training loss: 1.929266333580017
Validation loss: 1.792696144941042
Epoch: 7| Step: 2
Training loss: 1.6567522287368774
Validation loss: 1.7960842942162383
Epoch: 7| Step: 3
Training loss: 2.0109410285949707
Validation loss: 1.8163557172679214
Epoch: 7| Step: 4
Training loss: 2.3496146202087402
Validation loss: 1.8017309149392218
Epoch: 7| Step: 5
Training loss: 2.0767722129821777
Validation loss: 1.805731096713663
Epoch: 7| Step: 6
Training loss: 2.0641045570373535
Validation loss: 1.8039320870269118
Epoch: 7| Step: 7
Training loss: 2.011547327041626
Validation loss: 1.8084897892080622
Epoch: 7| Step: 8
Training loss: 1.8360950946807861
Validation loss: 1.8186329182961005
Epoch: 7| Step: 9
Training loss: 2.038208484649658
Validation loss: 1.8164696916401815
Epoch: 7| Step: 10
Training loss: 2.265458345413208
Validation loss: 1.8244368601188385
Epoch: 7| Step: 11
Training loss: 2.793671131134033
Validation loss: 1.8097923273662868
Epoch: 7| Step: 12
Training loss: 2.2921104431152344
Validation loss: 1.8075300986818272
Epoch: 7| Step: 13
Training loss: 1.6670652627944946
Validation loss: 1.8098758021704584
Epoch: 7| Step: 14
Training loss: 2.396941900253296
Validation loss: 1.8076241651027323
Epoch: 7| Step: 15
Training loss: 1.446177363395691
Validation loss: 1.809050331870429
Epoch: 53| Step: 0
Training loss: 1.7766504287719727
Validation loss: 1.8182413372204458
Epoch: 7| Step: 1
Training loss: 1.827380895614624
Validation loss: 1.8109104195944696
Epoch: 7| Step: 2
Training loss: 2.556830644607544
Validation loss: 1.8121778853505635
Epoch: 7| Step: 3
Training loss: 1.802411675453186
Validation loss: 1.8230954717389114
Epoch: 7| Step: 4
Training loss: 2.4144537448883057
Validation loss: 1.823902665282325
Epoch: 7| Step: 5
Training loss: 1.8038976192474365
Validation loss: 1.8137281661410984
Epoch: 7| Step: 6
Training loss: 1.998125433921814
Validation loss: 1.8210440942709394
Epoch: 7| Step: 7
Training loss: 2.1432347297668457
Validation loss: 1.8188046174083683
Epoch: 7| Step: 8
Training loss: 1.516189694404602
Validation loss: 1.8106234493873101
Epoch: 7| Step: 9
Training loss: 1.7203842401504517
Validation loss: 1.8218532706336152
Epoch: 7| Step: 10
Training loss: 2.0360655784606934
Validation loss: 1.827776781946635
Epoch: 7| Step: 11
Training loss: 2.2149646282196045
Validation loss: 1.8196327686309814
Epoch: 7| Step: 12
Training loss: 2.148615598678589
Validation loss: 1.818090440558015
Epoch: 7| Step: 13
Training loss: 2.1686272621154785
Validation loss: 1.8257195074781238
Epoch: 7| Step: 14
Training loss: 1.927147626876831
Validation loss: 1.8273388035863423
Epoch: 7| Step: 15
Training loss: 2.293053150177002
Validation loss: 1.830075910623125
Epoch: 54| Step: 0
Training loss: 2.4254581928253174
Validation loss: 1.8268366211609874
Epoch: 7| Step: 1
Training loss: 2.042891502380371
Validation loss: 1.8146583090583197
Epoch: 7| Step: 2
Training loss: 2.249943256378174
Validation loss: 1.82375953351851
Epoch: 7| Step: 3
Training loss: 1.658502221107483
Validation loss: 1.8121749377079148
Epoch: 7| Step: 4
Training loss: 1.7026695013046265
Validation loss: 1.818823691752317
Epoch: 7| Step: 5
Training loss: 2.423476457595825
Validation loss: 1.8204351757927764
Epoch: 7| Step: 6
Training loss: 2.3198254108428955
Validation loss: 1.824160658198295
Epoch: 7| Step: 7
Training loss: 1.9214891195297241
Validation loss: 1.8108116173915725
Epoch: 7| Step: 8
Training loss: 1.6471048593521118
Validation loss: 1.8215549884082602
Epoch: 7| Step: 9
Training loss: 1.7435438632965088
Validation loss: 1.814269206506743
Epoch: 7| Step: 10
Training loss: 1.975804328918457
Validation loss: 1.815288377322739
Epoch: 7| Step: 11
Training loss: 1.7230087518692017
Validation loss: 1.8116629972732325
Epoch: 7| Step: 12
Training loss: 2.1489691734313965
Validation loss: 1.811509402535802
Epoch: 7| Step: 13
Training loss: 1.7373889684677124
Validation loss: 1.8265481869951428
Epoch: 7| Step: 14
Training loss: 2.435488224029541
Validation loss: 1.816671877456226
Epoch: 7| Step: 15
Training loss: 2.1913750171661377
Validation loss: 1.8238836535446936
Epoch: 55| Step: 0
Training loss: 2.2333548069000244
Validation loss: 1.8141671779344408
Epoch: 7| Step: 1
Training loss: 1.7632191181182861
Validation loss: 1.8399407083182027
Epoch: 7| Step: 2
Training loss: 2.1806411743164062
Validation loss: 1.8293651745473738
Epoch: 7| Step: 3
Training loss: 1.6199924945831299
Validation loss: 1.8291045607422753
Epoch: 7| Step: 4
Training loss: 2.481724977493286
Validation loss: 1.8266580482181027
Epoch: 7| Step: 5
Training loss: 1.7756904363632202
Validation loss: 1.8185581629224818
Epoch: 7| Step: 6
Training loss: 1.8934189081192017
Validation loss: 1.8272499986689725
Epoch: 7| Step: 7
Training loss: 1.8356155157089233
Validation loss: 1.8134112383821885
Epoch: 7| Step: 8
Training loss: 2.279658317565918
Validation loss: 1.8157780170440674
Epoch: 7| Step: 9
Training loss: 1.8236923217773438
Validation loss: 1.8122030522325914
Epoch: 7| Step: 10
Training loss: 1.5797895193099976
Validation loss: 1.8157226902117831
Epoch: 7| Step: 11
Training loss: 2.1687469482421875
Validation loss: 1.8185034604381314
Epoch: 7| Step: 12
Training loss: 2.12471866607666
Validation loss: 1.819695416114313
Epoch: 7| Step: 13
Training loss: 2.208836317062378
Validation loss: 1.8259978808945032
Epoch: 7| Step: 14
Training loss: 2.246096134185791
Validation loss: 1.8180322938685796
Epoch: 7| Step: 15
Training loss: 2.143690347671509
Validation loss: 1.812580173821758
Epoch: 56| Step: 0
Training loss: 1.6165904998779297
Validation loss: 1.810524873596301
Epoch: 7| Step: 1
Training loss: 2.1576321125030518
Validation loss: 1.8167375111751418
Epoch: 7| Step: 2
Training loss: 1.8438234329223633
Validation loss: 1.8086377862546084
Epoch: 7| Step: 3
Training loss: 1.8315250873565674
Validation loss: 1.810635448359757
Epoch: 7| Step: 4
Training loss: 2.4086928367614746
Validation loss: 1.8142552667384526
Epoch: 7| Step: 5
Training loss: 1.6436529159545898
Validation loss: 1.8046250008850646
Epoch: 7| Step: 6
Training loss: 2.091890573501587
Validation loss: 1.8064090708176868
Epoch: 7| Step: 7
Training loss: 1.7636535167694092
Validation loss: 1.8069377648744651
Epoch: 7| Step: 8
Training loss: 1.6484994888305664
Validation loss: 1.8141933602394817
Epoch: 7| Step: 9
Training loss: 2.621311664581299
Validation loss: 1.8209750112012135
Epoch: 7| Step: 10
Training loss: 2.378690719604492
Validation loss: 1.8015914186299276
Epoch: 7| Step: 11
Training loss: 2.2682621479034424
Validation loss: 1.808183164905301
Epoch: 7| Step: 12
Training loss: 1.8059335947036743
Validation loss: 1.807400415269591
Epoch: 7| Step: 13
Training loss: 1.8545048236846924
Validation loss: 1.8110830457948095
Epoch: 7| Step: 14
Training loss: 2.485193967819214
Validation loss: 1.8114610807501155
Epoch: 7| Step: 15
Training loss: 1.9698703289031982
Validation loss: 1.8094638783297092
Epoch: 57| Step: 0
Training loss: 1.779396653175354
Validation loss: 1.8148226463537422
Epoch: 7| Step: 1
Training loss: 2.6519227027893066
Validation loss: 1.8269726158046036
Epoch: 7| Step: 2
Training loss: 2.1106038093566895
Validation loss: 1.8181307041387764
Epoch: 7| Step: 3
Training loss: 1.4036859273910522
Validation loss: 1.8219440000520335
Epoch: 7| Step: 4
Training loss: 2.68800950050354
Validation loss: 1.8188728763045168
Epoch: 7| Step: 5
Training loss: 1.7917592525482178
Validation loss: 1.8069767154377998
Epoch: 7| Step: 6
Training loss: 2.527859926223755
Validation loss: 1.8105946204645171
Epoch: 7| Step: 7
Training loss: 1.7506964206695557
Validation loss: 1.8196549458469418
Epoch: 7| Step: 8
Training loss: 1.5981271266937256
Validation loss: 1.806627781271077
Epoch: 7| Step: 9
Training loss: 1.667341947555542
Validation loss: 1.8193906314081425
Epoch: 7| Step: 10
Training loss: 2.5950374603271484
Validation loss: 1.8105691259713481
Epoch: 7| Step: 11
Training loss: 2.2579755783081055
Validation loss: 1.80606011092234
Epoch: 7| Step: 12
Training loss: 1.6909770965576172
Validation loss: 1.8078928722752083
Epoch: 7| Step: 13
Training loss: 2.0129284858703613
Validation loss: 1.8071398940875376
Epoch: 7| Step: 14
Training loss: 2.1836912631988525
Validation loss: 1.807948083328686
Epoch: 7| Step: 15
Training loss: 1.6946014165878296
Validation loss: 1.7992013169707155
Epoch: 58| Step: 0
Training loss: 2.319741725921631
Validation loss: 1.8071611021920073
Epoch: 7| Step: 1
Training loss: 1.8936970233917236
Validation loss: 1.8052196794276616
Epoch: 7| Step: 2
Training loss: 2.38010311126709
Validation loss: 1.8103381206663391
Epoch: 7| Step: 3
Training loss: 1.9881938695907593
Validation loss: 1.8133002965570353
Epoch: 7| Step: 4
Training loss: 2.4984822273254395
Validation loss: 1.8182028712128564
Epoch: 7| Step: 5
Training loss: 1.9216731786727905
Validation loss: 1.8153072638477352
Epoch: 7| Step: 6
Training loss: 2.058246612548828
Validation loss: 1.811846528979514
Epoch: 7| Step: 7
Training loss: 1.5867650508880615
Validation loss: 1.8192140327083122
Epoch: 7| Step: 8
Training loss: 1.8118343353271484
Validation loss: 1.817329602275821
Epoch: 7| Step: 9
Training loss: 1.50336754322052
Validation loss: 1.8266600130273283
Epoch: 7| Step: 10
Training loss: 1.6176891326904297
Validation loss: 1.8380538576798473
Epoch: 7| Step: 11
Training loss: 1.8762518167495728
Validation loss: 1.8352958547125617
Epoch: 7| Step: 12
Training loss: 2.3773128986358643
Validation loss: 1.8303867509896807
Epoch: 7| Step: 13
Training loss: 1.9998613595962524
Validation loss: 1.8367908000946045
Epoch: 7| Step: 14
Training loss: 2.1927075386047363
Validation loss: 1.8457271229448935
Epoch: 7| Step: 15
Training loss: 2.2132489681243896
Validation loss: 1.8405806280726151
Epoch: 59| Step: 0
Training loss: 2.445814847946167
Validation loss: 1.8351124096259797
Epoch: 7| Step: 1
Training loss: 2.1668477058410645
Validation loss: 1.8506327653102737
Epoch: 7| Step: 2
Training loss: 1.766493558883667
Validation loss: 1.8427091056494405
Epoch: 7| Step: 3
Training loss: 2.1310994625091553
Validation loss: 1.8428246546134674
Epoch: 7| Step: 4
Training loss: 1.8020975589752197
Validation loss: 1.8499825035067772
Epoch: 7| Step: 5
Training loss: 1.4161723852157593
Validation loss: 1.8546733101494879
Epoch: 7| Step: 6
Training loss: 1.941444993019104
Validation loss: 1.838330261998897
Epoch: 7| Step: 7
Training loss: 2.1217472553253174
Validation loss: 1.853357694131865
Epoch: 7| Step: 8
Training loss: 2.4303650856018066
Validation loss: 1.8488819942199926
Epoch: 7| Step: 9
Training loss: 2.1554489135742188
Validation loss: 1.8454897558088783
Epoch: 7| Step: 10
Training loss: 1.724652886390686
Validation loss: 1.8433225446467778
Epoch: 7| Step: 11
Training loss: 2.0370802879333496
Validation loss: 1.8355867005080628
Epoch: 7| Step: 12
Training loss: 1.7588783502578735
Validation loss: 1.8449496845547244
Epoch: 7| Step: 13
Training loss: 1.9974247217178345
Validation loss: 1.837743296040048
Epoch: 7| Step: 14
Training loss: 2.282865524291992
Validation loss: 1.823549726884142
Epoch: 7| Step: 15
Training loss: 2.10011887550354
Validation loss: 1.8410534292673892
Epoch: 60| Step: 0
Training loss: 1.9392181634902954
Validation loss: 1.831464110518531
Epoch: 7| Step: 1
Training loss: 1.9712636470794678
Validation loss: 1.8317533396988464
Epoch: 7| Step: 2
Training loss: 2.2135097980499268
Validation loss: 1.8319182421663682
Epoch: 7| Step: 3
Training loss: 2.2183775901794434
Validation loss: 1.822401960119069
Epoch: 7| Step: 4
Training loss: 2.1565613746643066
Validation loss: 1.8291533936699518
Epoch: 7| Step: 5
Training loss: 1.841153860092163
Validation loss: 1.8198155267633123
Epoch: 7| Step: 6
Training loss: 1.8065335750579834
Validation loss: 1.8248166231800327
Epoch: 7| Step: 7
Training loss: 2.2814338207244873
Validation loss: 1.8236328046098889
Epoch: 7| Step: 8
Training loss: 2.1642754077911377
Validation loss: 1.8294597735507883
Epoch: 7| Step: 9
Training loss: 1.9936033487319946
Validation loss: 1.8360113960375888
Epoch: 7| Step: 10
Training loss: 2.218451499938965
Validation loss: 1.8246921258007023
Epoch: 7| Step: 11
Training loss: 1.6073169708251953
Validation loss: 1.8342235800173643
Epoch: 7| Step: 12
Training loss: 1.8362782001495361
Validation loss: 1.8239500668409059
Epoch: 7| Step: 13
Training loss: 2.298732042312622
Validation loss: 1.8154516580293505
Epoch: 7| Step: 14
Training loss: 1.7111456394195557
Validation loss: 1.8210840516810796
Epoch: 7| Step: 15
Training loss: 1.9474989175796509
Validation loss: 1.8271185562764998
Epoch: 61| Step: 0
Training loss: 2.1308839321136475
Validation loss: 1.8243678713873994
Epoch: 7| Step: 1
Training loss: 1.6001322269439697
Validation loss: 1.8000490013643993
Epoch: 7| Step: 2
Training loss: 2.6014957427978516
Validation loss: 1.812095706411403
Epoch: 7| Step: 3
Training loss: 2.671515941619873
Validation loss: 1.8240381950954738
Epoch: 7| Step: 4
Training loss: 2.5337319374084473
Validation loss: 1.8208735632381852
Epoch: 7| Step: 5
Training loss: 1.5119506120681763
Validation loss: 1.8067959444128352
Epoch: 7| Step: 6
Training loss: 1.4886738061904907
Validation loss: 1.8117165462576228
Epoch: 7| Step: 7
Training loss: 2.1787524223327637
Validation loss: 1.8138626753855094
Epoch: 7| Step: 8
Training loss: 2.389542818069458
Validation loss: 1.8070534887931329
Epoch: 7| Step: 9
Training loss: 1.865804672241211
Validation loss: 1.8137993692494125
Epoch: 7| Step: 10
Training loss: 2.090773582458496
Validation loss: 1.805551950880092
Epoch: 7| Step: 11
Training loss: 1.5174694061279297
Validation loss: 1.800445378255501
Epoch: 7| Step: 12
Training loss: 2.147834062576294
Validation loss: 1.8063387870788574
Epoch: 7| Step: 13
Training loss: 1.978986144065857
Validation loss: 1.8064162130836103
Epoch: 7| Step: 14
Training loss: 1.9650386571884155
Validation loss: 1.8003089350762127
Epoch: 7| Step: 15
Training loss: 1.376089334487915
Validation loss: 1.813632385336238
Epoch: 62| Step: 0
Training loss: 2.114262104034424
Validation loss: 1.8004205441303391
Epoch: 7| Step: 1
Training loss: 1.82040274143219
Validation loss: 1.7887269781647825
Epoch: 7| Step: 2
Training loss: 2.0206215381622314
Validation loss: 1.8020264493475715
Epoch: 7| Step: 3
Training loss: 1.8890384435653687
Validation loss: 1.8091748909984562
Epoch: 7| Step: 4
Training loss: 2.196357011795044
Validation loss: 1.8056620728197714
Epoch: 7| Step: 5
Training loss: 1.7026522159576416
Validation loss: 1.8043125979334331
Epoch: 7| Step: 6
Training loss: 1.531360387802124
Validation loss: 1.8050144842202716
Epoch: 7| Step: 7
Training loss: 1.916467308998108
Validation loss: 1.8099263897902673
Epoch: 7| Step: 8
Training loss: 2.3401310443878174
Validation loss: 1.8030416939755995
Epoch: 7| Step: 9
Training loss: 1.6587765216827393
Validation loss: 1.8082520378579339
Epoch: 7| Step: 10
Training loss: 1.9626054763793945
Validation loss: 1.8029145422599298
Epoch: 7| Step: 11
Training loss: 2.6600804328918457
Validation loss: 1.8096939711261997
Epoch: 7| Step: 12
Training loss: 1.7132880687713623
Validation loss: 1.817040679266127
Epoch: 7| Step: 13
Training loss: 2.3375027179718018
Validation loss: 1.8142975260027878
Epoch: 7| Step: 14
Training loss: 2.1998887062072754
Validation loss: 1.8158931560653577
Epoch: 7| Step: 15
Training loss: 1.931579351425171
Validation loss: 1.8058970866443442
Epoch: 63| Step: 0
Training loss: 2.3785228729248047
Validation loss: 1.8074558570230608
Epoch: 7| Step: 1
Training loss: 2.178581714630127
Validation loss: 1.8184343705074393
Epoch: 7| Step: 2
Training loss: 1.629489541053772
Validation loss: 1.8045341162372837
Epoch: 7| Step: 3
Training loss: 2.245974540710449
Validation loss: 1.8037463092117858
Epoch: 7| Step: 4
Training loss: 2.345391035079956
Validation loss: 1.8026084153772257
Epoch: 7| Step: 5
Training loss: 2.4364190101623535
Validation loss: 1.81050241250786
Epoch: 7| Step: 6
Training loss: 1.607476830482483
Validation loss: 1.805120967274947
Epoch: 7| Step: 7
Training loss: 1.4932780265808105
Validation loss: 1.8008714837136028
Epoch: 7| Step: 8
Training loss: 1.5210679769515991
Validation loss: 1.8085849259397109
Epoch: 7| Step: 9
Training loss: 2.393080949783325
Validation loss: 1.8146473641018215
Epoch: 7| Step: 10
Training loss: 2.3653934001922607
Validation loss: 1.8220718027018814
Epoch: 7| Step: 11
Training loss: 2.160249948501587
Validation loss: 1.8154104793672081
Epoch: 7| Step: 12
Training loss: 1.718389868736267
Validation loss: 1.821785528882802
Epoch: 7| Step: 13
Training loss: 1.730067491531372
Validation loss: 1.8050184404249672
Epoch: 7| Step: 14
Training loss: 1.8884756565093994
Validation loss: 1.805554686690406
Epoch: 7| Step: 15
Training loss: 1.9609447717666626
Validation loss: 1.8089610638378335
Epoch: 64| Step: 0
Training loss: 1.330096960067749
Validation loss: 1.8138366054287918
Epoch: 7| Step: 1
Training loss: 2.5789341926574707
Validation loss: 1.814497879083208
Epoch: 7| Step: 2
Training loss: 1.7180531024932861
Validation loss: 1.8077582686925107
Epoch: 7| Step: 3
Training loss: 2.1561131477355957
Validation loss: 1.8126829991237723
Epoch: 7| Step: 4
Training loss: 2.0234169960021973
Validation loss: 1.810262064281985
Epoch: 7| Step: 5
Training loss: 2.3100123405456543
Validation loss: 1.8240808437196472
Epoch: 7| Step: 6
Training loss: 1.9776935577392578
Validation loss: 1.8254829430751662
Epoch: 7| Step: 7
Training loss: 2.239020586013794
Validation loss: 1.8116107141371254
Epoch: 7| Step: 8
Training loss: 1.7450029850006104
Validation loss: 1.8136516354924483
Epoch: 7| Step: 9
Training loss: 1.8037770986557007
Validation loss: 1.7936371161783342
Epoch: 7| Step: 10
Training loss: 2.253413200378418
Validation loss: 1.8044888107039088
Epoch: 7| Step: 11
Training loss: 1.9127910137176514
Validation loss: 1.804330748619793
Epoch: 7| Step: 12
Training loss: 1.551763892173767
Validation loss: 1.813651733261218
Epoch: 7| Step: 13
Training loss: 1.6679506301879883
Validation loss: 1.8105138265829293
Epoch: 7| Step: 14
Training loss: 2.6338891983032227
Validation loss: 1.8141201623052143
Epoch: 7| Step: 15
Training loss: 2.1745312213897705
Validation loss: 1.8246473931580138
Epoch: 65| Step: 0
Training loss: 1.8465064764022827
Validation loss: 1.8107309658750355
Epoch: 7| Step: 1
Training loss: 1.8555059432983398
Validation loss: 1.8159340748684012
Epoch: 7| Step: 2
Training loss: 1.691080093383789
Validation loss: 1.821037559200534
Epoch: 7| Step: 3
Training loss: 1.6897294521331787
Validation loss: 1.8328270774951083
Epoch: 7| Step: 4
Training loss: 2.02376389503479
Validation loss: 1.8373702104143101
Epoch: 7| Step: 5
Training loss: 1.9526174068450928
Validation loss: 1.8209029667669063
Epoch: 7| Step: 6
Training loss: 2.5854389667510986
Validation loss: 1.834048386100385
Epoch: 7| Step: 7
Training loss: 1.5225803852081299
Validation loss: 1.835031894471148
Epoch: 7| Step: 8
Training loss: 1.9282993078231812
Validation loss: 1.826088450795455
Epoch: 7| Step: 9
Training loss: 2.4089183807373047
Validation loss: 1.836025887256046
Epoch: 7| Step: 10
Training loss: 1.786778211593628
Validation loss: 1.8257759543631573
Epoch: 7| Step: 11
Training loss: 1.938184380531311
Validation loss: 1.8328255826620747
Epoch: 7| Step: 12
Training loss: 2.0440011024475098
Validation loss: 1.824729485477475
Epoch: 7| Step: 13
Training loss: 2.5458765029907227
Validation loss: 1.820595505426256
Epoch: 7| Step: 14
Training loss: 2.405853748321533
Validation loss: 1.8287807557222655
Epoch: 7| Step: 15
Training loss: 1.7101929187774658
Validation loss: 1.8229985991827875
Epoch: 66| Step: 0
Training loss: 2.0306894779205322
Validation loss: 1.8231249027114977
Epoch: 7| Step: 1
Training loss: 1.8538967370986938
Validation loss: 1.8330708733565515
Epoch: 7| Step: 2
Training loss: 1.9946413040161133
Validation loss: 1.8376126263639052
Epoch: 7| Step: 3
Training loss: 1.9020665884017944
Validation loss: 1.8276594371246777
Epoch: 7| Step: 4
Training loss: 2.4571475982666016
Validation loss: 1.821608632588558
Epoch: 7| Step: 5
Training loss: 1.4602019786834717
Validation loss: 1.839887804264645
Epoch: 7| Step: 6
Training loss: 1.678673505783081
Validation loss: 1.822555382474721
Epoch: 7| Step: 7
Training loss: 1.8674209117889404
Validation loss: 1.8181057696719822
Epoch: 7| Step: 8
Training loss: 1.9098058938980103
Validation loss: 1.8182212603177956
Epoch: 7| Step: 9
Training loss: 1.929316520690918
Validation loss: 1.8265267824955125
Epoch: 7| Step: 10
Training loss: 1.7143604755401611
Validation loss: 1.8406287122973435
Epoch: 7| Step: 11
Training loss: 2.1422293186187744
Validation loss: 1.846842047121885
Epoch: 7| Step: 12
Training loss: 1.6849603652954102
Validation loss: 1.8281330659235124
Epoch: 7| Step: 13
Training loss: 2.8608288764953613
Validation loss: 1.8304558006121958
Epoch: 7| Step: 14
Training loss: 2.37312912940979
Validation loss: 1.8288958690149322
Epoch: 7| Step: 15
Training loss: 2.143289566040039
Validation loss: 1.8239492255149128
Epoch: 67| Step: 0
Training loss: 1.9881374835968018
Validation loss: 1.8253219093350197
Epoch: 7| Step: 1
Training loss: 1.9034162759780884
Validation loss: 1.82737325249816
Epoch: 7| Step: 2
Training loss: 2.4091506004333496
Validation loss: 1.8378317098823382
Epoch: 7| Step: 3
Training loss: 2.115652561187744
Validation loss: 1.8361243987254958
Epoch: 7| Step: 4
Training loss: 2.389219284057617
Validation loss: 1.826281011533394
Epoch: 7| Step: 5
Training loss: 1.6255028247833252
Validation loss: 1.82207365087468
Epoch: 7| Step: 6
Training loss: 2.286449909210205
Validation loss: 1.8333029052336438
Epoch: 7| Step: 7
Training loss: 1.9662879705429077
Validation loss: 1.8122042426102454
Epoch: 7| Step: 8
Training loss: 1.519326090812683
Validation loss: 1.8119841796888723
Epoch: 7| Step: 9
Training loss: 2.3510966300964355
Validation loss: 1.800715085413816
Epoch: 7| Step: 10
Training loss: 1.8492435216903687
Validation loss: 1.7952976775683944
Epoch: 7| Step: 11
Training loss: 1.3777951002120972
Validation loss: 1.8051661450228245
Epoch: 7| Step: 12
Training loss: 2.229463577270508
Validation loss: 1.8131516417153448
Epoch: 7| Step: 13
Training loss: 1.9348728656768799
Validation loss: 1.815903541853102
Epoch: 7| Step: 14
Training loss: 2.0218892097473145
Validation loss: 1.8033620950987013
Epoch: 7| Step: 15
Training loss: 2.1968846321105957
Validation loss: 1.8122222003319282
Epoch: 68| Step: 0
Training loss: 2.025108814239502
Validation loss: 1.8053661962207272
Epoch: 7| Step: 1
Training loss: 2.399407386779785
Validation loss: 1.8101162344431705
Epoch: 7| Step: 2
Training loss: 1.9426380395889282
Validation loss: 1.8013499211921966
Epoch: 7| Step: 3
Training loss: 2.1054956912994385
Validation loss: 1.8109962485677047
Epoch: 7| Step: 4
Training loss: 2.3967089653015137
Validation loss: 1.809065450009682
Epoch: 7| Step: 5
Training loss: 1.656343698501587
Validation loss: 1.8196962274235786
Epoch: 7| Step: 6
Training loss: 2.1748435497283936
Validation loss: 1.8135289125305285
Epoch: 7| Step: 7
Training loss: 2.278069496154785
Validation loss: 1.82849990549705
Epoch: 7| Step: 8
Training loss: 1.7869583368301392
Validation loss: 1.8208405491259458
Epoch: 7| Step: 9
Training loss: 1.8915249109268188
Validation loss: 1.8197484273704694
Epoch: 7| Step: 10
Training loss: 1.5640103816986084
Validation loss: 1.8091840349512993
Epoch: 7| Step: 11
Training loss: 1.9590847492218018
Validation loss: 1.8141355334426001
Epoch: 7| Step: 12
Training loss: 1.8931045532226562
Validation loss: 1.8191961684672953
Epoch: 7| Step: 13
Training loss: 1.719347357749939
Validation loss: 1.8361674555771643
Epoch: 7| Step: 14
Training loss: 1.8219836950302124
Validation loss: 1.819600366002364
Epoch: 7| Step: 15
Training loss: 2.359792470932007
Validation loss: 1.831221240887539
Epoch: 69| Step: 0
Training loss: 1.8070732355117798
Validation loss: 1.8389800658328928
Epoch: 7| Step: 1
Training loss: 1.7160062789916992
Validation loss: 1.8221493058925053
Epoch: 7| Step: 2
Training loss: 2.2322943210601807
Validation loss: 1.8315140291941252
Epoch: 7| Step: 3
Training loss: 1.6621685028076172
Validation loss: 1.811418279469442
Epoch: 7| Step: 4
Training loss: 1.646083116531372
Validation loss: 1.8194731739785175
Epoch: 7| Step: 5
Training loss: 1.6450674533843994
Validation loss: 1.826899277220527
Epoch: 7| Step: 6
Training loss: 1.7643390893936157
Validation loss: 1.8228172312537543
Epoch: 7| Step: 7
Training loss: 2.4701876640319824
Validation loss: 1.823823733295468
Epoch: 7| Step: 8
Training loss: 2.2214605808258057
Validation loss: 1.8134718653109434
Epoch: 7| Step: 9
Training loss: 1.9487106800079346
Validation loss: 1.821145420451816
Epoch: 7| Step: 10
Training loss: 2.5038251876831055
Validation loss: 1.8148928640557707
Epoch: 7| Step: 11
Training loss: 2.2244536876678467
Validation loss: 1.8021960918851894
Epoch: 7| Step: 12
Training loss: 1.955592393875122
Validation loss: 1.8076847825976585
Epoch: 7| Step: 13
Training loss: 2.100461483001709
Validation loss: 1.8043262006567538
Epoch: 7| Step: 14
Training loss: 2.287306785583496
Validation loss: 1.7987439718177851
Epoch: 7| Step: 15
Training loss: 1.7286360263824463
Validation loss: 1.8093329659468835
Epoch: 70| Step: 0
Training loss: 1.950741171836853
Validation loss: 1.8095392297497757
Epoch: 7| Step: 1
Training loss: 2.6963727474212646
Validation loss: 1.8086134581257114
Epoch: 7| Step: 2
Training loss: 1.6987342834472656
Validation loss: 1.814714805685359
Epoch: 7| Step: 3
Training loss: 1.6336414813995361
Validation loss: 1.8177866669867535
Epoch: 7| Step: 4
Training loss: 1.97202467918396
Validation loss: 1.8135296775282717
Epoch: 7| Step: 5
Training loss: 2.0450708866119385
Validation loss: 1.8220232802329304
Epoch: 7| Step: 6
Training loss: 1.9778740406036377
Validation loss: 1.823488509912285
Epoch: 7| Step: 7
Training loss: 2.716017246246338
Validation loss: 1.8254816635049504
Epoch: 7| Step: 8
Training loss: 1.8489916324615479
Validation loss: 1.8208040333480286
Epoch: 7| Step: 9
Training loss: 1.6806671619415283
Validation loss: 1.8259439279707215
Epoch: 7| Step: 10
Training loss: 1.8621670007705688
Validation loss: 1.8305446432648802
Epoch: 7| Step: 11
Training loss: 2.108612060546875
Validation loss: 1.8258266860632588
Epoch: 7| Step: 12
Training loss: 1.6299842596054077
Validation loss: 1.8235518229093484
Epoch: 7| Step: 13
Training loss: 2.1119332313537598
Validation loss: 1.824790378268674
Epoch: 7| Step: 14
Training loss: 2.4161763191223145
Validation loss: 1.827921440275453
Epoch: 7| Step: 15
Training loss: 1.5381664037704468
Validation loss: 1.830510973072738
Epoch: 71| Step: 0
Training loss: 1.9109547138214111
Validation loss: 1.8266177546206137
Epoch: 7| Step: 1
Training loss: 2.120783567428589
Validation loss: 1.8280063361572705
Epoch: 7| Step: 2
Training loss: 2.197779893875122
Validation loss: 1.8288278691202617
Epoch: 7| Step: 3
Training loss: 3.08024263381958
Validation loss: 1.8322317514488164
Epoch: 7| Step: 4
Training loss: 1.6577918529510498
Validation loss: 1.8131898873143917
Epoch: 7| Step: 5
Training loss: 1.5014894008636475
Validation loss: 1.8213244590827886
Epoch: 7| Step: 6
Training loss: 2.2396163940429688
Validation loss: 1.8108868744733522
Epoch: 7| Step: 7
Training loss: 1.6422008275985718
Validation loss: 1.8254787818991023
Epoch: 7| Step: 8
Training loss: 2.2986807823181152
Validation loss: 1.827544429319368
Epoch: 7| Step: 9
Training loss: 1.9439653158187866
Validation loss: 1.8245164790599466
Epoch: 7| Step: 10
Training loss: 1.4365160465240479
Validation loss: 1.8224100723541041
Epoch: 7| Step: 11
Training loss: 2.5248584747314453
Validation loss: 1.817316790278867
Epoch: 7| Step: 12
Training loss: 1.6930831670761108
Validation loss: 1.8121610991388775
Epoch: 7| Step: 13
Training loss: 2.2994437217712402
Validation loss: 1.8161042268327672
Epoch: 7| Step: 14
Training loss: 1.625784158706665
Validation loss: 1.8129121828422272
Epoch: 7| Step: 15
Training loss: 1.8130146265029907
Validation loss: 1.8269084752034799
Epoch: 72| Step: 0
Training loss: 1.9073947668075562
Validation loss: 1.8153810423912762
Epoch: 7| Step: 1
Training loss: 2.2717480659484863
Validation loss: 1.8113249977715582
Epoch: 7| Step: 2
Training loss: 2.043964147567749
Validation loss: 1.8077927776377836
Epoch: 7| Step: 3
Training loss: 1.7854658365249634
Validation loss: 1.7966845387177501
Epoch: 7| Step: 4
Training loss: 1.8691418170928955
Validation loss: 1.8069123132623357
Epoch: 7| Step: 5
Training loss: 2.2668519020080566
Validation loss: 1.7980533014956137
Epoch: 7| Step: 6
Training loss: 2.121757984161377
Validation loss: 1.7964738084257936
Epoch: 7| Step: 7
Training loss: 1.9016796350479126
Validation loss: 1.7944200184705446
Epoch: 7| Step: 8
Training loss: 2.2346322536468506
Validation loss: 1.789581894016952
Epoch: 7| Step: 9
Training loss: 1.9744510650634766
Validation loss: 1.7853206842065714
Epoch: 7| Step: 10
Training loss: 2.039635181427002
Validation loss: 1.7980230197632054
Epoch: 7| Step: 11
Training loss: 1.671558141708374
Validation loss: 1.7870217330164189
Epoch: 7| Step: 12
Training loss: 2.2357208728790283
Validation loss: 1.8015480830515032
Epoch: 7| Step: 13
Training loss: 1.8663145303726196
Validation loss: 1.7938427564909132
Epoch: 7| Step: 14
Training loss: 1.4930869340896606
Validation loss: 1.8020225703287467
Epoch: 7| Step: 15
Training loss: 2.1746649742126465
Validation loss: 1.7842134168679766
Epoch: 73| Step: 0
Training loss: 2.145704507827759
Validation loss: 1.7990270750128108
Epoch: 7| Step: 1
Training loss: 3.059731960296631
Validation loss: 1.810173260222236
Epoch: 7| Step: 2
Training loss: 1.8901828527450562
Validation loss: 1.812208210821632
Epoch: 7| Step: 3
Training loss: 1.6225366592407227
Validation loss: 1.812179498535266
Epoch: 7| Step: 4
Training loss: 1.9894939661026
Validation loss: 1.808392578749348
Epoch: 7| Step: 5
Training loss: 1.619296669960022
Validation loss: 1.8274578207688366
Epoch: 7| Step: 6
Training loss: 1.847865343093872
Validation loss: 1.8257510679231272
Epoch: 7| Step: 7
Training loss: 2.1281888484954834
Validation loss: 1.8252008681674656
Epoch: 7| Step: 8
Training loss: 2.09908390045166
Validation loss: 1.828424548931259
Epoch: 7| Step: 9
Training loss: 1.5086489915847778
Validation loss: 1.8226611168264486
Epoch: 7| Step: 10
Training loss: 1.3079640865325928
Validation loss: 1.830893801270629
Epoch: 7| Step: 11
Training loss: 1.7944166660308838
Validation loss: 1.8366932645976115
Epoch: 7| Step: 12
Training loss: 2.2606959342956543
Validation loss: 1.8436913704700608
Epoch: 7| Step: 13
Training loss: 2.469586133956909
Validation loss: 1.8418175187899912
Epoch: 7| Step: 14
Training loss: 1.4697027206420898
Validation loss: 1.8467159845846162
Epoch: 7| Step: 15
Training loss: 2.576577663421631
Validation loss: 1.8444415999831056
Epoch: 74| Step: 0
Training loss: 1.8880488872528076
Validation loss: 1.8511529517688339
Epoch: 7| Step: 1
Training loss: 2.4056427478790283
Validation loss: 1.8343035711658944
Epoch: 7| Step: 2
Training loss: 2.0679850578308105
Validation loss: 1.8461482370500084
Epoch: 7| Step: 3
Training loss: 2.098759174346924
Validation loss: 1.8462525168768793
Epoch: 7| Step: 4
Training loss: 2.4655730724334717
Validation loss: 1.8414876461029053
Epoch: 7| Step: 5
Training loss: 1.2570677995681763
Validation loss: 1.839738749771667
Epoch: 7| Step: 6
Training loss: 1.9341119527816772
Validation loss: 1.8307327881133815
Epoch: 7| Step: 7
Training loss: 1.3782504796981812
Validation loss: 1.826567121546903
Epoch: 7| Step: 8
Training loss: 1.6463104486465454
Validation loss: 1.8165843203771028
Epoch: 7| Step: 9
Training loss: 2.410353422164917
Validation loss: 1.817943729942651
Epoch: 7| Step: 10
Training loss: 2.068087577819824
Validation loss: 1.8204080166576577
Epoch: 7| Step: 11
Training loss: 2.373368501663208
Validation loss: 1.8183114494351174
Epoch: 7| Step: 12
Training loss: 2.2335731983184814
Validation loss: 1.8225469760757556
Epoch: 7| Step: 13
Training loss: 1.7344220876693726
Validation loss: 1.8213307394398202
Epoch: 7| Step: 14
Training loss: 1.8505685329437256
Validation loss: 1.8186776758097916
Epoch: 7| Step: 15
Training loss: 1.9248263835906982
Validation loss: 1.8268276804642711
Epoch: 75| Step: 0
Training loss: 1.8851642608642578
Validation loss: 1.824767297120403
Epoch: 7| Step: 1
Training loss: 2.063922643661499
Validation loss: 1.815277281424982
Epoch: 7| Step: 2
Training loss: 1.6208209991455078
Validation loss: 1.8098099257448594
Epoch: 7| Step: 3
Training loss: 2.742600202560425
Validation loss: 1.8343913486535601
Epoch: 7| Step: 4
Training loss: 1.9866831302642822
Validation loss: 1.8031135934719937
Epoch: 7| Step: 5
Training loss: 1.827813744544983
Validation loss: 1.811628744756575
Epoch: 7| Step: 6
Training loss: 1.5993821620941162
Validation loss: 1.823971605987
Epoch: 7| Step: 7
Training loss: 1.5301932096481323
Validation loss: 1.8178422957015552
Epoch: 7| Step: 8
Training loss: 2.394430160522461
Validation loss: 1.8194374309169303
Epoch: 7| Step: 9
Training loss: 1.9503475427627563
Validation loss: 1.8126709178197298
Epoch: 7| Step: 10
Training loss: 2.0304510593414307
Validation loss: 1.8136514365244254
Epoch: 7| Step: 11
Training loss: 2.255927324295044
Validation loss: 1.8035431448504222
Epoch: 7| Step: 12
Training loss: 1.8863807916641235
Validation loss: 1.8142671190577446
Epoch: 7| Step: 13
Training loss: 2.1786253452301025
Validation loss: 1.8132878927875766
Epoch: 7| Step: 14
Training loss: 1.689072847366333
Validation loss: 1.8157691621094298
Epoch: 7| Step: 15
Training loss: 2.182774066925049
Validation loss: 1.8188968296531294
Epoch: 76| Step: 0
Training loss: 2.794166088104248
Validation loss: 1.8217166516420653
Epoch: 7| Step: 1
Training loss: 1.536370873451233
Validation loss: 1.8103278678098171
Epoch: 7| Step: 2
Training loss: 2.2249393463134766
Validation loss: 1.8181997906389853
Epoch: 7| Step: 3
Training loss: 2.1753413677215576
Validation loss: 1.8244660295170845
Epoch: 7| Step: 4
Training loss: 1.9582719802856445
Validation loss: 1.8169016915259601
Epoch: 7| Step: 5
Training loss: 2.280118465423584
Validation loss: 1.803752558694469
Epoch: 7| Step: 6
Training loss: 1.8936452865600586
Validation loss: 1.7935907875033592
Epoch: 7| Step: 7
Training loss: 2.07743501663208
Validation loss: 1.796308140102908
Epoch: 7| Step: 8
Training loss: 1.4783265590667725
Validation loss: 1.7990633532297697
Epoch: 7| Step: 9
Training loss: 1.5046489238739014
Validation loss: 1.8033806874597673
Epoch: 7| Step: 10
Training loss: 2.2022197246551514
Validation loss: 1.8073829541103446
Epoch: 7| Step: 11
Training loss: 1.99569571018219
Validation loss: 1.796322850014666
Epoch: 7| Step: 12
Training loss: 1.808463454246521
Validation loss: 1.7928969011032323
Epoch: 7| Step: 13
Training loss: 1.714426040649414
Validation loss: 1.819071387215484
Epoch: 7| Step: 14
Training loss: 2.206296443939209
Validation loss: 1.818053640049996
Epoch: 7| Step: 15
Training loss: 1.9223299026489258
Validation loss: 1.8094744356416113
Epoch: 77| Step: 0
Training loss: 1.9512302875518799
Validation loss: 1.8189601435078133
Epoch: 7| Step: 1
Training loss: 2.1797492504119873
Validation loss: 1.8278193696797322
Epoch: 7| Step: 2
Training loss: 2.161227226257324
Validation loss: 1.8247976954892384
Epoch: 7| Step: 3
Training loss: 2.02333402633667
Validation loss: 1.8356297307734868
Epoch: 7| Step: 4
Training loss: 1.6337878704071045
Validation loss: 1.8282139232690386
Epoch: 7| Step: 5
Training loss: 1.8772859573364258
Validation loss: 1.8288497238708057
Epoch: 7| Step: 6
Training loss: 2.2808594703674316
Validation loss: 1.8347064213787052
Epoch: 7| Step: 7
Training loss: 1.8075729608535767
Validation loss: 1.8374540291244177
Epoch: 7| Step: 8
Training loss: 2.1727542877197266
Validation loss: 1.838717243654265
Epoch: 7| Step: 9
Training loss: 1.7199945449829102
Validation loss: 1.836889616877055
Epoch: 7| Step: 10
Training loss: 1.2846044301986694
Validation loss: 1.8414122235003134
Epoch: 7| Step: 11
Training loss: 2.5113704204559326
Validation loss: 1.8441449103595542
Epoch: 7| Step: 12
Training loss: 1.9393062591552734
Validation loss: 1.8337427574953586
Epoch: 7| Step: 13
Training loss: 2.148284435272217
Validation loss: 1.8512317791259547
Epoch: 7| Step: 14
Training loss: 2.244391918182373
Validation loss: 1.8225852165290777
Epoch: 7| Step: 15
Training loss: 1.8050880432128906
Validation loss: 1.8373489645745258
Epoch: 78| Step: 0
Training loss: 1.9750797748565674
Validation loss: 1.8286954001557054
Epoch: 7| Step: 1
Training loss: 1.9223411083221436
Validation loss: 1.8245551697641826
Epoch: 7| Step: 2
Training loss: 2.0719680786132812
Validation loss: 1.8203380245098966
Epoch: 7| Step: 3
Training loss: 1.7983890771865845
Validation loss: 1.817221561781794
Epoch: 7| Step: 4
Training loss: 1.9171947240829468
Validation loss: 1.8134591442217929
Epoch: 7| Step: 5
Training loss: 2.057504177093506
Validation loss: 1.8101691530762816
Epoch: 7| Step: 6
Training loss: 1.6719512939453125
Validation loss: 1.8041226177764453
Epoch: 7| Step: 7
Training loss: 1.8823812007904053
Validation loss: 1.809354256382949
Epoch: 7| Step: 8
Training loss: 1.9406328201293945
Validation loss: 1.7988496306988833
Epoch: 7| Step: 9
Training loss: 2.1837780475616455
Validation loss: 1.8096869146223549
Epoch: 7| Step: 10
Training loss: 2.2526814937591553
Validation loss: 1.7971068903696623
Epoch: 7| Step: 11
Training loss: 2.2626795768737793
Validation loss: 1.8076507050356418
Epoch: 7| Step: 12
Training loss: 1.746185064315796
Validation loss: 1.810176514893127
Epoch: 7| Step: 13
Training loss: 1.9637949466705322
Validation loss: 1.7970861814004913
Epoch: 7| Step: 14
Training loss: 1.856706976890564
Validation loss: 1.8107732886033092
Epoch: 7| Step: 15
Training loss: 2.2752301692962646
Validation loss: 1.8018875465118627
Epoch: 79| Step: 0
Training loss: 2.1417346000671387
Validation loss: 1.8009241982329665
Epoch: 7| Step: 1
Training loss: 2.061065435409546
Validation loss: 1.8198112223645766
Epoch: 7| Step: 2
Training loss: 1.750322699546814
Validation loss: 1.8029836056043775
Epoch: 7| Step: 3
Training loss: 1.6762338876724243
Validation loss: 1.8093047776668192
Epoch: 7| Step: 4
Training loss: 1.5745866298675537
Validation loss: 1.8016074938739803
Epoch: 7| Step: 5
Training loss: 1.884190559387207
Validation loss: 1.813856208067146
Epoch: 7| Step: 6
Training loss: 2.127023935317993
Validation loss: 1.8158764513276464
Epoch: 7| Step: 7
Training loss: 1.809960961341858
Validation loss: 1.8035620468125926
Epoch: 7| Step: 8
Training loss: 1.7396373748779297
Validation loss: 1.8123837597936177
Epoch: 7| Step: 9
Training loss: 2.3667502403259277
Validation loss: 1.8097026356690222
Epoch: 7| Step: 10
Training loss: 2.4645416736602783
Validation loss: 1.8189642823857368
Epoch: 7| Step: 11
Training loss: 2.3663992881774902
Validation loss: 1.8149586195568386
Epoch: 7| Step: 12
Training loss: 2.1874496936798096
Validation loss: 1.8182981443062103
Epoch: 7| Step: 13
Training loss: 1.8205840587615967
Validation loss: 1.8154290305624763
Epoch: 7| Step: 14
Training loss: 1.926177978515625
Validation loss: 1.8154284739665847
Epoch: 7| Step: 15
Training loss: 1.8414589166641235
Validation loss: 1.8220773437897937
Epoch: 80| Step: 0
Training loss: 2.3028135299682617
Validation loss: 1.8156578575106834
Epoch: 7| Step: 1
Training loss: 2.1590800285339355
Validation loss: 1.8116065272324378
Epoch: 7| Step: 2
Training loss: 1.8203563690185547
Validation loss: 1.8165660573424196
Epoch: 7| Step: 3
Training loss: 1.460695505142212
Validation loss: 1.8205425490578302
Epoch: 7| Step: 4
Training loss: 1.961029291152954
Validation loss: 1.805730116453102
Epoch: 7| Step: 5
Training loss: 1.9321784973144531
Validation loss: 1.816363560210029
Epoch: 7| Step: 6
Training loss: 1.8205726146697998
Validation loss: 1.8270940583386868
Epoch: 7| Step: 7
Training loss: 1.8855342864990234
Validation loss: 1.8243986513974855
Epoch: 7| Step: 8
Training loss: 2.223092555999756
Validation loss: 1.8296683109063896
Epoch: 7| Step: 9
Training loss: 1.924239158630371
Validation loss: 1.8185175254190569
Epoch: 7| Step: 10
Training loss: 2.177485466003418
Validation loss: 1.8153727063172156
Epoch: 7| Step: 11
Training loss: 2.646885395050049
Validation loss: 1.8226546246370823
Epoch: 7| Step: 12
Training loss: 1.552392840385437
Validation loss: 1.8050955362457166
Epoch: 7| Step: 13
Training loss: 1.8665454387664795
Validation loss: 1.8140328162008053
Epoch: 7| Step: 14
Training loss: 1.7842237949371338
Validation loss: 1.813330006256378
Epoch: 7| Step: 15
Training loss: 2.057343006134033
Validation loss: 1.8229736192620916
Epoch: 81| Step: 0
Training loss: 1.674783706665039
Validation loss: 1.812406346094694
Epoch: 7| Step: 1
Training loss: 2.227128267288208
Validation loss: 1.822149275018157
Epoch: 7| Step: 2
Training loss: 2.022141695022583
Validation loss: 1.8181015004356988
Epoch: 7| Step: 3
Training loss: 2.2738707065582275
Validation loss: 1.8205366349048753
Epoch: 7| Step: 4
Training loss: 1.5657196044921875
Validation loss: 1.813340263401004
Epoch: 7| Step: 5
Training loss: 2.129032611846924
Validation loss: 1.8209574934389952
Epoch: 7| Step: 6
Training loss: 1.8816394805908203
Validation loss: 1.8194671260367195
Epoch: 7| Step: 7
Training loss: 2.3700013160705566
Validation loss: 1.8114738910318278
Epoch: 7| Step: 8
Training loss: 1.799269676208496
Validation loss: 1.8155510151128975
Epoch: 7| Step: 9
Training loss: 1.9920343160629272
Validation loss: 1.797606988776502
Epoch: 7| Step: 10
Training loss: 1.864084005355835
Validation loss: 1.791328714905883
Epoch: 7| Step: 11
Training loss: 1.7857698202133179
Validation loss: 1.799671437242906
Epoch: 7| Step: 12
Training loss: 1.568220853805542
Validation loss: 1.7858320671877415
Epoch: 7| Step: 13
Training loss: 2.305258274078369
Validation loss: 1.7981285705840846
Epoch: 7| Step: 14
Training loss: 2.3043057918548584
Validation loss: 1.8075154024920017
Epoch: 7| Step: 15
Training loss: 1.8148231506347656
Validation loss: 1.8015856991568915
Epoch: 82| Step: 0
Training loss: 1.8190882205963135
Validation loss: 1.799365508470604
Epoch: 7| Step: 1
Training loss: 2.4377784729003906
Validation loss: 1.8170277403412962
Epoch: 7| Step: 2
Training loss: 2.13889741897583
Validation loss: 1.813456043922644
Epoch: 7| Step: 3
Training loss: 2.169647693634033
Validation loss: 1.8161705809531452
Epoch: 7| Step: 4
Training loss: 2.0318262577056885
Validation loss: 1.8229264209596374
Epoch: 7| Step: 5
Training loss: 2.5685431957244873
Validation loss: 1.8357106653048838
Epoch: 7| Step: 6
Training loss: 1.9887348413467407
Validation loss: 1.835343968096397
Epoch: 7| Step: 7
Training loss: 1.7757141590118408
Validation loss: 1.841782917221673
Epoch: 7| Step: 8
Training loss: 2.2274887561798096
Validation loss: 1.8232016700634854
Epoch: 7| Step: 9
Training loss: 2.4497804641723633
Validation loss: 1.8301878104106986
Epoch: 7| Step: 10
Training loss: 1.277846097946167
Validation loss: 1.8332265486820138
Epoch: 7| Step: 11
Training loss: 1.8390226364135742
Validation loss: 1.8293082422489741
Epoch: 7| Step: 12
Training loss: 1.152647852897644
Validation loss: 1.829568571323971
Epoch: 7| Step: 13
Training loss: 2.2689621448516846
Validation loss: 1.8400790476970534
Epoch: 7| Step: 14
Training loss: 1.6863996982574463
Validation loss: 1.8216463516084411
Epoch: 7| Step: 15
Training loss: 1.777862787246704
Validation loss: 1.8270772858489333
Epoch: 83| Step: 0
Training loss: 2.0901741981506348
Validation loss: 1.8151458424629925
Epoch: 7| Step: 1
Training loss: 1.714353322982788
Validation loss: 1.8232599368198312
Epoch: 7| Step: 2
Training loss: 2.127821445465088
Validation loss: 1.825432842583965
Epoch: 7| Step: 3
Training loss: 1.5149027109146118
Validation loss: 1.8250469878423128
Epoch: 7| Step: 4
Training loss: 2.073270559310913
Validation loss: 1.820566667069634
Epoch: 7| Step: 5
Training loss: 2.2778828144073486
Validation loss: 1.8093192886105545
Epoch: 7| Step: 6
Training loss: 1.9090566635131836
Validation loss: 1.8158722035318828
Epoch: 7| Step: 7
Training loss: 2.176567316055298
Validation loss: 1.8112064016808709
Epoch: 7| Step: 8
Training loss: 1.586909532546997
Validation loss: 1.8129722120092928
Epoch: 7| Step: 9
Training loss: 1.862249732017517
Validation loss: 1.809566086144756
Epoch: 7| Step: 10
Training loss: 2.430457830429077
Validation loss: 1.809832948574917
Epoch: 7| Step: 11
Training loss: 2.329869031906128
Validation loss: 1.811326427425412
Epoch: 7| Step: 12
Training loss: 1.742283582687378
Validation loss: 1.8117805650765948
Epoch: 7| Step: 13
Training loss: 2.2135417461395264
Validation loss: 1.8154546005262746
Epoch: 7| Step: 14
Training loss: 1.5928840637207031
Validation loss: 1.8168394900054383
Epoch: 7| Step: 15
Training loss: 1.945387601852417
Validation loss: 1.8072121623608706
Epoch: 84| Step: 0
Training loss: 2.144113779067993
Validation loss: 1.8189898034651502
Epoch: 7| Step: 1
Training loss: 2.2269511222839355
Validation loss: 1.8283928581278959
Epoch: 7| Step: 2
Training loss: 1.970113754272461
Validation loss: 1.811568495180967
Epoch: 7| Step: 3
Training loss: 1.4731193780899048
Validation loss: 1.8221216622016412
Epoch: 7| Step: 4
Training loss: 1.7227325439453125
Validation loss: 1.8106125215832278
Epoch: 7| Step: 5
Training loss: 2.251183032989502
Validation loss: 1.8226701690138674
Epoch: 7| Step: 6
Training loss: 2.117615222930908
Validation loss: 1.8173239068161668
Epoch: 7| Step: 7
Training loss: 2.1125011444091797
Validation loss: 1.7982024769131228
Epoch: 7| Step: 8
Training loss: 2.1573665142059326
Validation loss: 1.8059349334497246
Epoch: 7| Step: 9
Training loss: 1.7077312469482422
Validation loss: 1.808440433131705
Epoch: 7| Step: 10
Training loss: 1.587308645248413
Validation loss: 1.8093149284664676
Epoch: 7| Step: 11
Training loss: 1.3160254955291748
Validation loss: 1.8050752869612878
Epoch: 7| Step: 12
Training loss: 2.24983286857605
Validation loss: 1.808105820374523
Epoch: 7| Step: 13
Training loss: 2.1967711448669434
Validation loss: 1.809128068333907
Epoch: 7| Step: 14
Training loss: 2.1066384315490723
Validation loss: 1.8115150079452733
Epoch: 7| Step: 15
Training loss: 2.263683319091797
Validation loss: 1.8176207182218702
Epoch: 85| Step: 0
Training loss: 2.1051039695739746
Validation loss: 1.8295623973119173
Epoch: 7| Step: 1
Training loss: 1.8913023471832275
Validation loss: 1.8150651995226634
Epoch: 7| Step: 2
Training loss: 2.2614641189575195
Validation loss: 1.8094183043610277
Epoch: 7| Step: 3
Training loss: 1.674215316772461
Validation loss: 1.823655266555951
Epoch: 7| Step: 4
Training loss: 1.8061622381210327
Validation loss: 1.8089651118079535
Epoch: 7| Step: 5
Training loss: 2.1697919368743896
Validation loss: 1.8166445793865396
Epoch: 7| Step: 6
Training loss: 2.256411075592041
Validation loss: 1.8115293550834382
Epoch: 7| Step: 7
Training loss: 2.101045608520508
Validation loss: 1.8128762511040668
Epoch: 7| Step: 8
Training loss: 2.3364288806915283
Validation loss: 1.8158257110513372
Epoch: 7| Step: 9
Training loss: 1.5530887842178345
Validation loss: 1.8285887121296616
Epoch: 7| Step: 10
Training loss: 1.8508059978485107
Validation loss: 1.8210611935142134
Epoch: 7| Step: 11
Training loss: 2.08031964302063
Validation loss: 1.8254944669256965
Epoch: 7| Step: 12
Training loss: 1.7653262615203857
Validation loss: 1.8307866175397693
Epoch: 7| Step: 13
Training loss: 2.1121175289154053
Validation loss: 1.8393281904055918
Epoch: 7| Step: 14
Training loss: 1.7066437005996704
Validation loss: 1.8258912331766362
Epoch: 7| Step: 15
Training loss: 1.8949064016342163
Validation loss: 1.8389674502310993
Epoch: 86| Step: 0
Training loss: 1.6206703186035156
Validation loss: 1.8354447857081462
Epoch: 7| Step: 1
Training loss: 2.3821122646331787
Validation loss: 1.8416109222302335
Epoch: 7| Step: 2
Training loss: 2.370661973953247
Validation loss: 1.831284554742223
Epoch: 7| Step: 3
Training loss: 2.1424758434295654
Validation loss: 1.8254151395756564
Epoch: 7| Step: 4
Training loss: 1.891077995300293
Validation loss: 1.8323375887150386
Epoch: 7| Step: 5
Training loss: 1.472495436668396
Validation loss: 1.8221725842935577
Epoch: 7| Step: 6
Training loss: 2.0103554725646973
Validation loss: 1.8265665280733177
Epoch: 7| Step: 7
Training loss: 1.9530715942382812
Validation loss: 1.8254281333882174
Epoch: 7| Step: 8
Training loss: 2.152712345123291
Validation loss: 1.8107088932888113
Epoch: 7| Step: 9
Training loss: 1.9646602869033813
Validation loss: 1.813401922047567
Epoch: 7| Step: 10
Training loss: 1.9711246490478516
Validation loss: 1.8221511223333344
Epoch: 7| Step: 11
Training loss: 1.8700584173202515
Validation loss: 1.8151161259026836
Epoch: 7| Step: 12
Training loss: 2.117374897003174
Validation loss: 1.8127919932921155
Epoch: 7| Step: 13
Training loss: 2.2048463821411133
Validation loss: 1.807322960963352
Epoch: 7| Step: 14
Training loss: 1.7900409698486328
Validation loss: 1.8061128288721866
Epoch: 7| Step: 15
Training loss: 1.607635498046875
Validation loss: 1.8021340576007212
Epoch: 87| Step: 0
Training loss: 2.2046077251434326
Validation loss: 1.809026574059356
Epoch: 7| Step: 1
Training loss: 1.6879810094833374
Validation loss: 1.8105596595530888
Epoch: 7| Step: 2
Training loss: 1.9595390558242798
Validation loss: 1.7934565947210188
Epoch: 7| Step: 3
Training loss: 2.1446099281311035
Validation loss: 1.8113106008913877
Epoch: 7| Step: 4
Training loss: 1.9737167358398438
Validation loss: 1.801552843704498
Epoch: 7| Step: 5
Training loss: 1.9208072423934937
Validation loss: 1.8043264021976388
Epoch: 7| Step: 6
Training loss: 1.5787760019302368
Validation loss: 1.786506820068085
Epoch: 7| Step: 7
Training loss: 1.5928500890731812
Validation loss: 1.7968708542611103
Epoch: 7| Step: 8
Training loss: 2.31412672996521
Validation loss: 1.801250845408268
Epoch: 7| Step: 9
Training loss: 1.7545945644378662
Validation loss: 1.8076815279267675
Epoch: 7| Step: 10
Training loss: 1.9436544179916382
Validation loss: 1.8106163311347687
Epoch: 7| Step: 11
Training loss: 2.049029588699341
Validation loss: 1.806251968411233
Epoch: 7| Step: 12
Training loss: 2.312589645385742
Validation loss: 1.818535027744101
Epoch: 7| Step: 13
Training loss: 2.081533193588257
Validation loss: 1.8154663610801423
Epoch: 7| Step: 14
Training loss: 2.0029220581054688
Validation loss: 1.8129824708691604
Epoch: 7| Step: 15
Training loss: 1.9430402517318726
Validation loss: 1.8068438339576447
Epoch: 88| Step: 0
Training loss: 1.8671338558197021
Validation loss: 1.8112941585856377
Epoch: 7| Step: 1
Training loss: 1.9419505596160889
Validation loss: 1.8042421057927522
Epoch: 7| Step: 2
Training loss: 2.205453395843506
Validation loss: 1.807668976646533
Epoch: 7| Step: 3
Training loss: 1.9579594135284424
Validation loss: 1.805220758314613
Epoch: 7| Step: 4
Training loss: 1.4723546504974365
Validation loss: 1.8095264554881363
Epoch: 7| Step: 5
Training loss: 2.054391384124756
Validation loss: 1.8116364573403227
Epoch: 7| Step: 6
Training loss: 2.210197925567627
Validation loss: 1.805634216438952
Epoch: 7| Step: 7
Training loss: 1.6428006887435913
Validation loss: 1.8248303090925697
Epoch: 7| Step: 8
Training loss: 1.6741092205047607
Validation loss: 1.8203360193924938
Epoch: 7| Step: 9
Training loss: 2.0234811305999756
Validation loss: 1.8257578954422216
Epoch: 7| Step: 10
Training loss: 2.0132639408111572
Validation loss: 1.8112560930869561
Epoch: 7| Step: 11
Training loss: 2.5360116958618164
Validation loss: 1.813111019649094
Epoch: 7| Step: 12
Training loss: 1.918536901473999
Validation loss: 1.8066913729948963
Epoch: 7| Step: 13
Training loss: 1.509948492050171
Validation loss: 1.815220002647784
Epoch: 7| Step: 14
Training loss: 1.7750194072723389
Validation loss: 1.8227017517570112
Epoch: 7| Step: 15
Training loss: 2.5892860889434814
Validation loss: 1.8151035934901065
Epoch: 89| Step: 0
Training loss: 2.2166006565093994
Validation loss: 1.8269668808943933
Epoch: 7| Step: 1
Training loss: 1.5727403163909912
Validation loss: 1.822045942004636
Epoch: 7| Step: 2
Training loss: 1.684259057044983
Validation loss: 1.8302717860654103
Epoch: 7| Step: 3
Training loss: 1.9884874820709229
Validation loss: 1.826417148542061
Epoch: 7| Step: 4
Training loss: 2.041618824005127
Validation loss: 1.8365092354712726
Epoch: 7| Step: 5
Training loss: 2.0818185806274414
Validation loss: 1.8318430777076338
Epoch: 7| Step: 6
Training loss: 1.796902060508728
Validation loss: 1.8251044827399494
Epoch: 7| Step: 7
Training loss: 1.9558284282684326
Validation loss: 1.8387676408822589
Epoch: 7| Step: 8
Training loss: 2.219460964202881
Validation loss: 1.8294168839351737
Epoch: 7| Step: 9
Training loss: 1.6863930225372314
Validation loss: 1.8323698532667092
Epoch: 7| Step: 10
Training loss: 1.7968699932098389
Validation loss: 1.8352648834530398
Epoch: 7| Step: 11
Training loss: 1.8131227493286133
Validation loss: 1.8358185651491015
Epoch: 7| Step: 12
Training loss: 2.174241304397583
Validation loss: 1.8387374723557945
Epoch: 7| Step: 13
Training loss: 2.674250364303589
Validation loss: 1.842864844438841
Epoch: 7| Step: 14
Training loss: 1.5222795009613037
Validation loss: 1.8411941819911382
Epoch: 7| Step: 15
Training loss: 2.237947940826416
Validation loss: 1.8213541490568532
Epoch: 90| Step: 0
Training loss: 1.8649122714996338
Validation loss: 1.8330523058664885
Epoch: 7| Step: 1
Training loss: 2.209599018096924
Validation loss: 1.8333686375789504
Epoch: 7| Step: 2
Training loss: 1.686252236366272
Validation loss: 1.8354155262597174
Epoch: 7| Step: 3
Training loss: 1.6213476657867432
Validation loss: 1.825479337637373
Epoch: 7| Step: 4
Training loss: 2.3060994148254395
Validation loss: 1.818730342302391
Epoch: 7| Step: 5
Training loss: 1.8256438970565796
Validation loss: 1.8129358831927074
Epoch: 7| Step: 6
Training loss: 2.3890318870544434
Validation loss: 1.8130126934257342
Epoch: 7| Step: 7
Training loss: 1.8921301364898682
Validation loss: 1.827235763879131
Epoch: 7| Step: 8
Training loss: 1.9613513946533203
Validation loss: 1.825591971548341
Epoch: 7| Step: 9
Training loss: 1.9193599224090576
Validation loss: 1.8119645444609278
Epoch: 7| Step: 10
Training loss: 1.6641604900360107
Validation loss: 1.816777699285274
Epoch: 7| Step: 11
Training loss: 1.8794174194335938
Validation loss: 1.8177147357583903
Epoch: 7| Step: 12
Training loss: 2.1140944957733154
Validation loss: 1.8291493302626576
Epoch: 7| Step: 13
Training loss: 2.6554789543151855
Validation loss: 1.8260332791925333
Epoch: 7| Step: 14
Training loss: 1.670668601989746
Validation loss: 1.826619048770383
Epoch: 7| Step: 15
Training loss: 1.7569137811660767
Validation loss: 1.8336532853490157
Epoch: 91| Step: 0
Training loss: 1.659000039100647
Validation loss: 1.8278375392337498
Epoch: 7| Step: 1
Training loss: 2.0582518577575684
Validation loss: 1.8227198355489498
Epoch: 7| Step: 2
Training loss: 1.7804620265960693
Validation loss: 1.8200769201457072
Epoch: 7| Step: 3
Training loss: 1.6239856481552124
Validation loss: 1.8191227175348954
Epoch: 7| Step: 4
Training loss: 1.7146615982055664
Validation loss: 1.823138446258984
Epoch: 7| Step: 5
Training loss: 2.881608486175537
Validation loss: 1.8236541027645412
Epoch: 7| Step: 6
Training loss: 1.8240811824798584
Validation loss: 1.8388388894444747
Epoch: 7| Step: 7
Training loss: 1.7522436380386353
Validation loss: 1.836991128304022
Epoch: 7| Step: 8
Training loss: 1.795015573501587
Validation loss: 1.823814637369389
Epoch: 7| Step: 9
Training loss: 2.1405327320098877
Validation loss: 1.8372210272782141
Epoch: 7| Step: 10
Training loss: 2.073004961013794
Validation loss: 1.8391070434515424
Epoch: 7| Step: 11
Training loss: 1.6145124435424805
Validation loss: 1.8229898523083694
Epoch: 7| Step: 12
Training loss: 1.716489553451538
Validation loss: 1.8420167861224936
Epoch: 7| Step: 13
Training loss: 2.506169080734253
Validation loss: 1.8468942204825312
Epoch: 7| Step: 14
Training loss: 2.303450107574463
Validation loss: 1.835652709864884
Epoch: 7| Step: 15
Training loss: 1.8418461084365845
Validation loss: 1.8338805128344529
Epoch: 92| Step: 0
Training loss: 2.2498342990875244
Validation loss: 1.8235667300738876
Epoch: 7| Step: 1
Training loss: 1.931541085243225
Validation loss: 1.8177892664353625
Epoch: 7| Step: 2
Training loss: 1.6755479574203491
Validation loss: 1.8254137999719853
Epoch: 7| Step: 3
Training loss: 1.5531833171844482
Validation loss: 1.8104652380771775
Epoch: 7| Step: 4
Training loss: 2.0087995529174805
Validation loss: 1.8075684034567086
Epoch: 7| Step: 5
Training loss: 2.115208148956299
Validation loss: 1.8039760658209272
Epoch: 7| Step: 6
Training loss: 1.9095265865325928
Validation loss: 1.8075572312307016
Epoch: 7| Step: 7
Training loss: 1.7347478866577148
Validation loss: 1.8135521969349264
Epoch: 7| Step: 8
Training loss: 2.016967296600342
Validation loss: 1.8160013492158849
Epoch: 7| Step: 9
Training loss: 2.1312055587768555
Validation loss: 1.811992815072588
Epoch: 7| Step: 10
Training loss: 2.424668312072754
Validation loss: 1.808850431613785
Epoch: 7| Step: 11
Training loss: 1.3693783283233643
Validation loss: 1.821297947451365
Epoch: 7| Step: 12
Training loss: 1.9714266061782837
Validation loss: 1.8109635474870531
Epoch: 7| Step: 13
Training loss: 1.3793598413467407
Validation loss: 1.8149988882833248
Epoch: 7| Step: 14
Training loss: 2.8687543869018555
Validation loss: 1.8131873444687547
Epoch: 7| Step: 15
Training loss: 2.111804246902466
Validation loss: 1.8261735053371182
Epoch: 93| Step: 0
Training loss: 1.861161470413208
Validation loss: 1.8180041930658355
Epoch: 7| Step: 1
Training loss: 2.2231392860412598
Validation loss: 1.8096247491219062
Epoch: 7| Step: 2
Training loss: 2.0305583477020264
Validation loss: 1.8096864017651235
Epoch: 7| Step: 3
Training loss: 1.3070647716522217
Validation loss: 1.8129523477965979
Epoch: 7| Step: 4
Training loss: 1.5437769889831543
Validation loss: 1.8027516620622264
Epoch: 7| Step: 5
Training loss: 1.640865683555603
Validation loss: 1.7861021559873074
Epoch: 7| Step: 6
Training loss: 1.8833690881729126
Validation loss: 1.805979698682003
Epoch: 7| Step: 7
Training loss: 1.9412500858306885
Validation loss: 1.803856713308705
Epoch: 7| Step: 8
Training loss: 1.7098993062973022
Validation loss: 1.8096265569865275
Epoch: 7| Step: 9
Training loss: 2.094738245010376
Validation loss: 1.8107280302390778
Epoch: 7| Step: 10
Training loss: 3.0756678581237793
Validation loss: 1.8045397353686874
Epoch: 7| Step: 11
Training loss: 1.9379602670669556
Validation loss: 1.798811427123255
Epoch: 7| Step: 12
Training loss: 1.8344011306762695
Validation loss: 1.813734397613745
Epoch: 7| Step: 13
Training loss: 1.8189913034439087
Validation loss: 1.8194601381425377
Epoch: 7| Step: 14
Training loss: 2.384469985961914
Validation loss: 1.8144129094460029
Epoch: 7| Step: 15
Training loss: 2.0105788707733154
Validation loss: 1.8086008956964068
Epoch: 94| Step: 0
Training loss: 1.9845901727676392
Validation loss: 1.807783081377153
Epoch: 7| Step: 1
Training loss: 1.7327200174331665
Validation loss: 1.8320284035566041
Epoch: 7| Step: 2
Training loss: 1.8617340326309204
Validation loss: 1.8197776765274487
Epoch: 7| Step: 3
Training loss: 2.3013317584991455
Validation loss: 1.822156451588912
Epoch: 7| Step: 4
Training loss: 2.1207098960876465
Validation loss: 1.822524584454598
Epoch: 7| Step: 5
Training loss: 2.0548043251037598
Validation loss: 1.8205755408719289
Epoch: 7| Step: 6
Training loss: 1.410035490989685
Validation loss: 1.803128087263313
Epoch: 7| Step: 7
Training loss: 2.092531204223633
Validation loss: 1.827305202861484
Epoch: 7| Step: 8
Training loss: 1.7536245584487915
Validation loss: 1.8257078155339193
Epoch: 7| Step: 9
Training loss: 2.2418084144592285
Validation loss: 1.831443441857537
Epoch: 7| Step: 10
Training loss: 2.4949679374694824
Validation loss: 1.8291416957224016
Epoch: 7| Step: 11
Training loss: 1.8382208347320557
Validation loss: 1.829554687301032
Epoch: 7| Step: 12
Training loss: 1.6578525304794312
Validation loss: 1.825299349620188
Epoch: 7| Step: 13
Training loss: 1.9808489084243774
Validation loss: 1.8190214908380302
Epoch: 7| Step: 14
Training loss: 1.988071084022522
Validation loss: 1.8245250312544459
Epoch: 7| Step: 15
Training loss: 1.849475622177124
Validation loss: 1.822601286627406
Epoch: 95| Step: 0
Training loss: 2.5392284393310547
Validation loss: 1.817364264735215
Epoch: 7| Step: 1
Training loss: 2.3319220542907715
Validation loss: 1.8042280691133128
Epoch: 7| Step: 2
Training loss: 1.592599630355835
Validation loss: 1.821077103237454
Epoch: 7| Step: 3
Training loss: 1.8471721410751343
Validation loss: 1.803474411689978
Epoch: 7| Step: 4
Training loss: 2.0016283988952637
Validation loss: 1.8055208569807972
Epoch: 7| Step: 5
Training loss: 1.8703835010528564
Validation loss: 1.8013272817186314
Epoch: 7| Step: 6
Training loss: 2.1491758823394775
Validation loss: 1.7976096371094958
Epoch: 7| Step: 7
Training loss: 1.7294450998306274
Validation loss: 1.7969836494047864
Epoch: 7| Step: 8
Training loss: 1.3217180967330933
Validation loss: 1.8009124128080958
Epoch: 7| Step: 9
Training loss: 1.8201580047607422
Validation loss: 1.7985523398831593
Epoch: 7| Step: 10
Training loss: 1.8865283727645874
Validation loss: 1.8042151567747267
Epoch: 7| Step: 11
Training loss: 1.8341619968414307
Validation loss: 1.8033828709622939
Epoch: 7| Step: 12
Training loss: 2.1467654705047607
Validation loss: 1.7944727475694615
Epoch: 7| Step: 13
Training loss: 2.473066806793213
Validation loss: 1.802965529531026
Epoch: 7| Step: 14
Training loss: 1.525499939918518
Validation loss: 1.813244144693553
Epoch: 7| Step: 15
Training loss: 2.3159706592559814
Validation loss: 1.8102340475260783
Epoch: 96| Step: 0
Training loss: 1.604116439819336
Validation loss: 1.8218272204021755
Epoch: 7| Step: 1
Training loss: 1.9750621318817139
Validation loss: 1.8173420583601478
Epoch: 7| Step: 2
Training loss: 1.622800588607788
Validation loss: 1.827394942585513
Epoch: 7| Step: 3
Training loss: 1.7971115112304688
Validation loss: 1.8229840419275298
Epoch: 7| Step: 4
Training loss: 1.311982274055481
Validation loss: 1.843645112977611
Epoch: 7| Step: 5
Training loss: 2.25484037399292
Validation loss: 1.831010171835371
Epoch: 7| Step: 6
Training loss: 1.7412344217300415
Validation loss: 1.8327694959777723
Epoch: 7| Step: 7
Training loss: 2.1304492950439453
Validation loss: 1.8340566938729594
Epoch: 7| Step: 8
Training loss: 1.3654123544692993
Validation loss: 1.819664931125778
Epoch: 7| Step: 9
Training loss: 2.193770170211792
Validation loss: 1.8279938852186683
Epoch: 7| Step: 10
Training loss: 2.323272943496704
Validation loss: 1.8248388364160661
Epoch: 7| Step: 11
Training loss: 1.9985994100570679
Validation loss: 1.826225015756895
Epoch: 7| Step: 12
Training loss: 2.3705999851226807
Validation loss: 1.8187376252181238
Epoch: 7| Step: 13
Training loss: 2.3602192401885986
Validation loss: 1.8120876199049916
Epoch: 7| Step: 14
Training loss: 1.9985339641571045
Validation loss: 1.8119299111606406
Epoch: 7| Step: 15
Training loss: 2.153261661529541
Validation loss: 1.8161916089572494
Epoch: 97| Step: 0
Training loss: 2.315067768096924
Validation loss: 1.8125929437952935
Epoch: 7| Step: 1
Training loss: 2.2516369819641113
Validation loss: 1.823827801848487
Epoch: 7| Step: 2
Training loss: 1.8627666234970093
Validation loss: 1.809423896906187
Epoch: 7| Step: 3
Training loss: 2.310497760772705
Validation loss: 1.8193427410057124
Epoch: 7| Step: 4
Training loss: 1.4757201671600342
Validation loss: 1.8076515334973233
Epoch: 7| Step: 5
Training loss: 1.8493629693984985
Validation loss: 1.801352348259027
Epoch: 7| Step: 6
Training loss: 1.8160831928253174
Validation loss: 1.799432449203601
Epoch: 7| Step: 7
Training loss: 1.944584608078003
Validation loss: 1.7939847321819058
Epoch: 7| Step: 8
Training loss: 2.0411462783813477
Validation loss: 1.7993903040028305
Epoch: 7| Step: 9
Training loss: 1.6392399072647095
Validation loss: 1.8034009255951258
Epoch: 7| Step: 10
Training loss: 1.9063606262207031
Validation loss: 1.7958163014418786
Epoch: 7| Step: 11
Training loss: 2.5347535610198975
Validation loss: 1.8041103400772425
Epoch: 7| Step: 12
Training loss: 2.005532741546631
Validation loss: 1.8084070682525635
Epoch: 7| Step: 13
Training loss: 2.118195056915283
Validation loss: 1.8062433356003795
Epoch: 7| Step: 14
Training loss: 1.2536998987197876
Validation loss: 1.8170177979434994
Epoch: 7| Step: 15
Training loss: 1.9727909564971924
Validation loss: 1.8288859737862786
Epoch: 98| Step: 0
Training loss: 1.6783368587493896
Validation loss: 1.8031596442778333
Epoch: 7| Step: 1
Training loss: 1.3221946954727173
Validation loss: 1.8211592598784743
Epoch: 7| Step: 2
Training loss: 1.6406095027923584
Validation loss: 1.8272376369229324
Epoch: 7| Step: 3
Training loss: 2.452542304992676
Validation loss: 1.8166050765154174
Epoch: 7| Step: 4
Training loss: 2.1701853275299072
Validation loss: 1.825875815727728
Epoch: 7| Step: 5
Training loss: 1.2479314804077148
Validation loss: 1.8331345242562054
Epoch: 7| Step: 6
Training loss: 1.5926249027252197
Validation loss: 1.8269771268899493
Epoch: 7| Step: 7
Training loss: 2.0929529666900635
Validation loss: 1.8228071121860752
Epoch: 7| Step: 8
Training loss: 2.426926374435425
Validation loss: 1.8371741934645949
Epoch: 7| Step: 9
Training loss: 2.0196611881256104
Validation loss: 1.843274995577421
Epoch: 7| Step: 10
Training loss: 2.8263096809387207
Validation loss: 1.8277408287679549
Epoch: 7| Step: 11
Training loss: 2.030363082885742
Validation loss: 1.8285152208890847
Epoch: 7| Step: 12
Training loss: 2.00459361076355
Validation loss: 1.8305263279153288
Epoch: 7| Step: 13
Training loss: 1.7822288274765015
Validation loss: 1.8322461594780572
Epoch: 7| Step: 14
Training loss: 1.9561243057250977
Validation loss: 1.816298906751674
Epoch: 7| Step: 15
Training loss: 1.9692662954330444
Validation loss: 1.823178637799599
Epoch: 99| Step: 0
Training loss: 1.809462308883667
Validation loss: 1.8221087730188164
Epoch: 7| Step: 1
Training loss: 2.029874086380005
Validation loss: 1.822752032348578
Epoch: 7| Step: 2
Training loss: 2.3471128940582275
Validation loss: 1.8194096843115717
Epoch: 7| Step: 3
Training loss: 2.1421642303466797
Validation loss: 1.8279160638507321
Epoch: 7| Step: 4
Training loss: 1.367852807044983
Validation loss: 1.816825553667631
Epoch: 7| Step: 5
Training loss: 1.4472593069076538
Validation loss: 1.8245886332697148
Epoch: 7| Step: 6
Training loss: 2.3962957859039307
Validation loss: 1.8144918928901068
Epoch: 7| Step: 7
Training loss: 1.647495985031128
Validation loss: 1.8268316306656214
Epoch: 7| Step: 8
Training loss: 1.9455196857452393
Validation loss: 1.83230244255752
Epoch: 7| Step: 9
Training loss: 2.0931332111358643
Validation loss: 1.830257469801594
Epoch: 7| Step: 10
Training loss: 1.7328770160675049
Validation loss: 1.827535766491787
Epoch: 7| Step: 11
Training loss: 2.3600220680236816
Validation loss: 1.845398758812774
Epoch: 7| Step: 12
Training loss: 1.5885090827941895
Validation loss: 1.8457282438552638
Epoch: 7| Step: 13
Training loss: 2.5589702129364014
Validation loss: 1.8483461373143917
Epoch: 7| Step: 14
Training loss: 1.8153473138809204
Validation loss: 1.8557020048443362
Epoch: 7| Step: 15
Training loss: 2.122661590576172
Validation loss: 1.8341794880174047
Epoch: 100| Step: 0
Training loss: 2.121044397354126
Validation loss: 1.8198111889173658
Epoch: 7| Step: 1
Training loss: 2.284684419631958
Validation loss: 1.8171095633678298
Epoch: 7| Step: 2
Training loss: 2.090658664703369
Validation loss: 1.8091386084933934
Epoch: 7| Step: 3
Training loss: 1.7319116592407227
Validation loss: 1.8089770593231531
Epoch: 7| Step: 4
Training loss: 2.0917274951934814
Validation loss: 1.7924292524941534
Epoch: 7| Step: 5
Training loss: 2.3166122436523438
Validation loss: 1.791367615727212
Epoch: 7| Step: 6
Training loss: 1.6758487224578857
Validation loss: 1.7985894182603137
Epoch: 7| Step: 7
Training loss: 2.2293357849121094
Validation loss: 1.783216365807348
Epoch: 7| Step: 8
Training loss: 1.5316227674484253
Validation loss: 1.7753869595287515
Epoch: 7| Step: 9
Training loss: 1.8458993434906006
Validation loss: 1.7778667940510262
Epoch: 7| Step: 10
Training loss: 1.9786326885223389
Validation loss: 1.7786952754576428
Epoch: 7| Step: 11
Training loss: 1.8841159343719482
Validation loss: 1.7624323222276976
Epoch: 7| Step: 12
Training loss: 1.849966287612915
Validation loss: 1.7674293723895396
Epoch: 7| Step: 13
Training loss: 2.394351005554199
Validation loss: 1.7848890488096278
Epoch: 7| Step: 14
Training loss: 1.7783124446868896
Validation loss: 1.7847708283568458
Epoch: 7| Step: 15
Training loss: 1.4515119791030884
Validation loss: 1.7808503186960014
